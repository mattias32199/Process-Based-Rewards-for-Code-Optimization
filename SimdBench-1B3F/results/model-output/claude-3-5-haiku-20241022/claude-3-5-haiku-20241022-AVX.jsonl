{"task_id": "SimdBench_0_AVX", "completion": "```cpp\nvoid conditional_move_simd(const int64_t *src, int64_t *dst, const bool *mask, size_t length) {\n    size_t i = 0;\n    const int vector_width = 4; // AVX2 can process 4 64-bit integers per vector\n\n    // Process vectors\n    for (; i + vector_width <= length; i += vector_width) {\n        // Load source vector\n        __m256i src_vec = _mm256_loadu_si256((__m256i*)&src[i]);\n        \n        // Create mask vector from boolean mask\n        __m256i mask_vec = _mm256_setzero_si256();\n        for (int j = 0; j < vector_width; j++) {\n            if (mask[i + j]) {\n                mask_vec = _mm256_insert_epi64(mask_vec, -1, j);\n            }\n        }\n\n        // Conditionally move elements using mask\n        __m256i dst_vec = _mm256_blendv_epi8(_mm256_loadu_si256((__m256i*)&dst[i]), src_vec, mask_vec);\n        \n        // Store result back to destination\n        _mm256_storeu_si256((__m256i*)&dst[i], dst_vec);\n    }\n\n    // Handle remaining elements\n    for (; i < length; i++) {\n        if (mask[i]) {\n            dst[i] = src[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_0_AVX", "completion": "```cpp\nvoid conditional_move_simd(const int64_t *src, int64_t *dst, const bool *mask, size_t length) {\n    size_t i = 0;\n    const int vector_width = 4; // AVX can process 4 64-bit integers per vector\n\n    // Process vectors\n    for (; i + vector_width <= length; i += vector_width) {\n        // Load source vector\n        __m256i src_vec = _mm256_loadu_si256((__m256i*)&src[i]);\n        \n        // Create mask vector from boolean mask\n        __m256i mask_vec = _mm256_setzero_si256();\n        for (int j = 0; j < vector_width; j++) {\n            if (mask[i + j]) {\n                mask_vec = _mm256_insert_epi64(mask_vec, -1, j);\n            }\n        }\n\n        // Conditionally move elements using mask\n        __m256i dst_vec = _mm256_blendv_epi8(_mm256_loadu_si256((__m256i*)&dst[i]), src_vec, mask_vec);\n        \n        // Store result back to destination\n        _mm256_storeu_si256((__m256i*)&dst[i], dst_vec);\n    }\n\n    // Handle remaining elements\n    for (; i < length; i++) {\n        if (mask[i]) {\n            dst[i] = src[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_0_AVX", "completion": "```cpp\nvoid conditional_move_simd(const int64_t *src, int64_t *dst, const bool *mask, size_t length) {\n    size_t i = 0;\n    const int vector_width = 4; // AVX can process 4 64-bit integers per vector\n\n    // Process vectors\n    for (; i + vector_width <= length; i += vector_width) {\n        // Load source vector\n        __m256i src_vec = _mm256_loadu_si256((__m256i*)&src[i]);\n        \n        // Create mask vector from boolean mask\n        __m256i mask_vec = _mm256_setzero_si256();\n        for (int j = 0; j < vector_width; j++) {\n            if (mask[i + j]) {\n                mask_vec = _mm256_insert_epi64(mask_vec, -1, j);\n            }\n        }\n\n        // Blend source with destination based on mask\n        __m256i dst_vec = _mm256_loadu_si256((__m256i*)&dst[i]);\n        __m256i result = _mm256_blendv_epi8(dst_vec, src_vec, mask_vec);\n\n        // Store result back to destination\n        _mm256_storeu_si256((__m256i*)&dst[i], result);\n    }\n\n    // Handle remaining elements\n    for (; i < length; i++) {\n        if (mask[i]) {\n            dst[i] = src[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_0_AVX", "completion": "```cpp\nvoid conditional_move_simd(const int64_t *src, int64_t *dst, const bool *mask, size_t length) {\n    size_t i = 0;\n    const int vector_width = 4; // AVX2 can process 4 64-bit integers per vector\n\n    // Process vectors\n    for (; i + vector_width <= length; i += vector_width) {\n        // Load source vector\n        __m256i src_vec = _mm256_loadu_si256((__m256i*)&src[i]);\n        \n        // Create mask vector from boolean mask\n        __m256i mask_vec = _mm256_setzero_si256();\n        for (int j = 0; j < vector_width; j++) {\n            if (mask[i + j]) {\n                mask_vec = _mm256_insert_epi64(mask_vec, -1, j);\n            }\n        }\n\n        // Conditionally move elements using mask\n        __m256i dst_vec = _mm256_blendv_epi8(_mm256_loadu_si256((__m256i*)&dst[i]), src_vec, mask_vec);\n        \n        // Store result\n        _mm256_storeu_si256((__m256i*)&dst[i], dst_vec);\n    }\n\n    // Handle remaining elements\n    for (; i < length; i++) {\n        if (mask[i]) {\n            dst[i] = src[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_0_AVX", "completion": "```cpp\nvoid conditional_move_simd(const int64_t *src, int64_t *dst, const bool *mask, size_t length) {\n    size_t i = 0;\n    const size_t vector_width = 4; // AVX2 can process 4 64-bit integers per vector\n\n    // Process vectors\n    for (; i + vector_width <= length; i += vector_width) {\n        // Load source vector\n        __m256i src_vec = _mm256_loadu_si256((__m256i*)&src[i]);\n        \n        // Load mask and convert to integer mask\n        __m256i mask_vec = _mm256_setzero_si256();\n        for (int j = 0; j < vector_width; j++) {\n            if (mask[i + j]) {\n                mask_vec = _mm256_insert_epi64(mask_vec, -1, j);\n            }\n        }\n\n        // Blend source with destination based on mask\n        __m256i dst_vec = _mm256_loadu_si256((__m256i*)&dst[i]);\n        __m256i result = _mm256_blendv_epi8(dst_vec, src_vec, mask_vec);\n\n        // Store result back to destination\n        _mm256_storeu_si256((__m256i*)&dst[i], result);\n    }\n\n    // Handle remaining elements\n    for (; i < length; i++) {\n        if (mask[i]) {\n            dst[i] = src[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_1_AVX", "completion": "```cpp\nvoid load_modify_store_simd(const int *src, int *dst, int scale, size_t length) {\n    __m256i scale_vec = _mm256_set1_epi32(scale);\n    \n    size_t i = 0;\n    for (; i + 8 <= length; i += 8) {\n        // Load 8 integers from src\n        __m256i src_vec = _mm256_loadu_si256((__m256i*)&src[i]);\n        \n        // Multiply src elements with scale\n        __m256i mul_vec = _mm256_mullo_epi32(src_vec, scale_vec);\n        \n        // Calculate tmp1 (right shift by 3)\n        __m256i tmp1_vec = _mm256_srai_epi32(mul_vec, 3);\n        \n        // Calculate tmp2 (left shift by 3)\n        __m256i tmp2_vec = _mm256_slli_epi32(mul_vec, 3);\n        \n        // Multiply tmp1 and tmp2\n        __m256i mul_tmp_vec = _mm256_mullo_epi32(tmp1_vec, tmp2_vec);\n        \n        // Add original multiplication and multiply result\n        __m256i result_vec = _mm256_add_epi32(mul_vec, mul_tmp_vec);\n        \n        // Divide by 7\n        __m256i div_vec = _mm256_div_epi32(result_vec, _mm256_set1_epi32(7));\n        \n        // Store results in dst\n        _mm256_storeu_si256((__m256i*)&dst[i], div_vec);\n    }\n    \n    // Handle remaining elements\n    for (; i < length; i++) {\n        int mul = src[i] * scale;\n        int tmp1 = mul >> 3;\n        int tmp2 = mul << 3;\n        dst[i] = (mul + tmp1 * tmp2) / 7;\n    }\n}\n```"}
{"task_id": "SimdBench_1_AVX", "completion": "```cpp\nvoid load_modify_store_simd(const int *src, int *dst, int scale, size_t length) {\n    __m256i scale_vec = _mm256_set1_epi32(scale);\n    \n    size_t i = 0;\n    for (; i + 8 <= length; i += 8) {\n        // Load 8 integers from src\n        __m256i src_vec = _mm256_loadu_si256((__m256i*)&src[i]);\n        \n        // Multiply src elements with scale\n        __m256i mul_vec = _mm256_mullo_epi32(src_vec, scale_vec);\n        \n        // Compute tmp1: right shift by 3\n        __m256i tmp1_vec = _mm256_srai_epi32(mul_vec, 3);\n        \n        // Compute tmp2: left shift by 3\n        __m256i tmp2_vec = _mm256_slli_epi32(mul_vec, 3);\n        \n        // Multiply tmp1 and tmp2\n        __m256i mul_tmp_vec = _mm256_mullo_epi32(tmp1_vec, tmp2_vec);\n        \n        // Add original multiplication and tmp1*tmp2\n        __m256i result_vec = _mm256_add_epi32(mul_vec, mul_tmp_vec);\n        \n        // Divide by 7\n        __m256i div_vec = _mm256_div_epi32(result_vec, _mm256_set1_epi32(7));\n        \n        // Store results in dst\n        _mm256_storeu_si256((__m256i*)&dst[i], div_vec);\n    }\n    \n    // Handle remaining elements\n    for (; i < length; i++) {\n        int mul = src[i] * scale;\n        int tmp1 = mul >> 3;\n        int tmp2 = mul << 3;\n        dst[i] = (mul + tmp1 * tmp2) / 7;\n    }\n}\n```"}
{"task_id": "SimdBench_1_AVX", "completion": "```cpp\nvoid load_modify_store_simd(const int *src, int *dst, int scale, size_t length) {\n    __m256i scale_vec = _mm256_set1_epi32(scale);\n    \n    size_t i;\n    for (i = 0; i + 8 <= length; i += 8) {\n        // Load 8 integers from src\n        __m256i src_vec = _mm256_loadu_si256((__m256i*)&src[i]);\n        \n        // Calculate tmp1: (element * scale) >> 3\n        __m256i tmp1_vec = _mm256_srai_epi32(_mm256_mullo_epi32(src_vec, scale_vec), 3);\n        \n        // Calculate tmp2: (element * scale) << 3\n        __m256i tmp2_vec = _mm256_slli_epi32(_mm256_mullo_epi32(src_vec, scale_vec), 3);\n        \n        // Compute final result: (element * scale + tmp1 * tmp2) / 7\n        __m256i result_vec = _mm256_div_epi32(\n            _mm256_add_epi32(\n                _mm256_mullo_epi32(src_vec, scale_vec),\n                _mm256_mullo_epi32(tmp1_vec, tmp2_vec)\n            ), \n            _mm256_set1_epi32(7)\n        );\n        \n        // Store result in dst\n        _mm256_storeu_si256((__m256i*)&dst[i], result_vec);\n    }\n    \n    // Handle remaining elements\n    for (; i < length; i++) {\n        int element = src[i];\n        int tmp1 = (element * scale) >> 3;\n        int tmp2 = (element * scale) << 3;\n        dst[i] = (element * scale + tmp1 * tmp2) / 7;\n    }\n}\n```"}
{"task_id": "SimdBench_1_AVX", "completion": "```cpp\nvoid load_modify_store_simd(const int *src, int *dst, int scale, size_t length) {\n    __m256i scale_vec = _mm256_set1_epi32(scale);\n    \n    size_t i = 0;\n    for (; i + 8 <= length; i += 8) {\n        // Load 8 integers from src\n        __m256i src_vec = _mm256_loadu_si256((__m256i*)&src[i]);\n        \n        // Calculate tmp1: (element * scale) >> 3\n        __m256i tmp1 = _mm256_srai_epi32(_mm256_mullo_epi32(src_vec, scale_vec), 3);\n        \n        // Calculate tmp2: (element * scale) << 3\n        __m256i tmp2 = _mm256_slli_epi32(_mm256_mullo_epi32(src_vec, scale_vec), 3);\n        \n        // Compute final result: (element * scale + tmp1 * tmp2) / 7\n        __m256i mul_tmp1_tmp2 = _mm256_mullo_epi32(tmp1, tmp2);\n        __m256i add_result = _mm256_add_epi32(_mm256_mullo_epi32(src_vec, scale_vec), mul_tmp1_tmp2);\n        __m256i div_result = _mm256_div_epi32(add_result, _mm256_set1_epi32(7));\n        \n        // Store result in dst\n        _mm256_storeu_si256((__m256i*)&dst[i], div_result);\n    }\n    \n    // Handle remaining elements\n    for (; i < length; i++) {\n        int tmp1 = (src[i] * scale) >> 3;\n        int tmp2 = (src[i] * scale) << 3;\n        dst[i] = (src[i] * scale + tmp1 * tmp2) / 7;\n    }\n}\n```"}
{"task_id": "SimdBench_1_AVX", "completion": "```cpp\nvoid load_modify_store_simd(const int *src, int *dst, int scale, size_t length) {\n    __m256i scale_vec = _mm256_set1_epi32(scale);\n    \n    size_t i = 0;\n    for (; i + 8 <= length; i += 8) {\n        // Load 8 integers from src\n        __m256i src_vec = _mm256_loadu_si256((__m256i*)&src[i]);\n        \n        // Multiply src elements with scale\n        __m256i mul_vec = _mm256_mullo_epi32(src_vec, scale_vec);\n        \n        // Calculate tmp1: right shift by 3\n        __m256i tmp1_vec = _mm256_srai_epi32(mul_vec, 3);\n        \n        // Calculate tmp2: left shift by 3\n        __m256i tmp2_vec = _mm256_slli_epi32(mul_vec, 3);\n        \n        // Multiply tmp1 and tmp2\n        __m256i mul_tmp_vec = _mm256_mullo_epi32(tmp1_vec, tmp2_vec);\n        \n        // Add original multiplication and tmp1*tmp2\n        __m256i sum_vec = _mm256_add_epi32(mul_vec, mul_tmp_vec);\n        \n        // Divide by 7\n        __m256i result_vec = _mm256_div_epi32(sum_vec, _mm256_set1_epi32(7));\n        \n        // Store results in dst\n        _mm256_storeu_si256((__m256i*)&dst[i], result_vec);\n    }\n    \n    // Handle remaining elements\n    for (; i < length; i++) {\n        int mul = src[i] * scale;\n        int tmp1 = mul >> 3;\n        int tmp2 = mul << 3;\n        dst[i] = (mul + tmp1 * tmp2) / 7;\n    }\n}\n```"}
{"task_id": "SimdBench_2_AVX", "completion": "```cpp\nvoid strided_load_store_simd(const double *src, double *dst, size_t rows, size_t cols, size_t stride) {\n    size_t vec_width = sizeof(__m256d) / sizeof(double);\n    size_t vec_rows = rows / vec_width;\n    size_t remaining_rows = rows % vec_width;\n\n    for (size_t r = 0; r < vec_rows; r++) {\n        __m256d vec_data = _mm256_setzero_pd();\n        \n        for (size_t i = 0; i < vec_width; i++) {\n            size_t row_index = (r * vec_width + i) * cols + stride;\n            vec_data = _mm256_insertf128_pd(vec_data, _mm_load_sd(&src[row_index]), i / 2);\n        }\n        \n        _mm256_storeu_pd(&dst[r * vec_width], vec_data);\n    }\n\n    for (size_t r = vec_rows * vec_width; r < rows; r++) {\n        dst[r] = src[r * cols + stride];\n    }\n}\n```"}
{"task_id": "SimdBench_2_AVX", "completion": "```cpp\nvoid strided_load_store_simd(const double *src, double *dst, size_t rows, size_t cols, size_t stride) {\n    size_t vector_width = 4; // AVX can process 4 double-precision floats per vector\n    size_t i = 0;\n\n    // Process rows in vector chunks\n    for (; i + vector_width <= rows; i += vector_width) {\n        __m256d loaded_values = _mm256_set_pd(\n            src[(i + 3) * cols + stride],\n            src[(i + 2) * cols + stride], \n            src[(i + 1) * cols + stride],\n            src[i * cols + stride]\n        );\n        \n        _mm256_storeu_pd(&dst[i], loaded_values);\n    }\n\n    // Handle remaining rows sequentially\n    for (; i < rows; i++) {\n        dst[i] = src[i * cols + stride];\n    }\n}\n```"}
{"task_id": "SimdBench_2_AVX", "completion": "```cpp\nvoid strided_load_store_simd(const double *src, double *dst, size_t rows, size_t cols, size_t stride) {\n    size_t vector_width = sizeof(__m256d) / sizeof(double);\n    size_t i = 0;\n\n    // Process rows in vector-sized chunks\n    for (; i + vector_width <= rows; i += vector_width) {\n        __m256d loaded_values = _mm256_set_pd(\n            src[(i + 3) * cols + stride],\n            src[(i + 2) * cols + stride],\n            src[(i + 1) * cols + stride],\n            src[i * cols + stride]\n        );\n        _mm256_storeu_pd(dst + i, loaded_values);\n    }\n\n    // Handle remaining rows\n    for (; i < rows; i++) {\n        dst[i] = src[i * cols + stride];\n    }\n}\n```"}
{"task_id": "SimdBench_2_AVX", "completion": "```cpp\nvoid strided_load_store_simd(const double *src, double *dst, size_t rows, size_t cols, size_t stride) {\n    size_t vector_width = sizeof(__m256d) / sizeof(double);\n    size_t i = 0;\n\n    // Process rows in vector-sized chunks\n    for (; i + vector_width <= rows; i += vector_width) {\n        __m256d loaded_values = _mm256_set_pd(\n            src[(i + 3) * cols + stride],\n            src[(i + 2) * cols + stride], \n            src[(i + 1) * cols + stride],\n            src[i * cols + stride]\n        );\n        _mm256_storeu_pd(dst + i, loaded_values);\n    }\n\n    // Handle remaining rows\n    for (; i < rows; i++) {\n        dst[i] = src[i * cols + stride];\n    }\n}\n```"}
{"task_id": "SimdBench_2_AVX", "completion": "```cpp\nvoid strided_load_store_simd(const double *src, double *dst, size_t rows, size_t cols, size_t stride) {\n    size_t vec_width = sizeof(__m256d) / sizeof(double);\n    size_t vec_rows = rows / vec_width;\n    size_t remaining_rows = rows % vec_width;\n\n    for (size_t r = 0; r < vec_rows; r++) {\n        __m256d vec_data = _mm256_setzero_pd();\n        \n        for (size_t i = 0; i < vec_width; i++) {\n            size_t row_index = r * vec_width + i;\n            size_t src_index = row_index * cols + stride;\n            vec_data = _mm256_insertf128_pd(vec_data, _mm_load_sd(&src[src_index]), i / 2);\n        }\n        \n        _mm256_storeu_pd(&dst[r * vec_width], vec_data);\n    }\n\n    for (size_t r = vec_rows * vec_width; r < rows; r++) {\n        dst[r] = src[r * cols + stride];\n    }\n}\n```"}
{"task_id": "SimdBench_3_AVX", "completion": "```cpp\nvoid indexed_access_simd(const float *src, const int *indices, float *dst, size_t length) {\n    size_t i = 0;\n    \n    // Process 8 elements at a time using AVX\n    for (; i + 8 <= length; i += 8) {\n        // Gather operation: Load values from src using indices\n        __m256i index_vec = _mm256_loadu_si256((__m256i*)&indices[i]);\n        __m256 gathered_values = _mm256_i32gather_ps(src, index_vec, 4);\n        \n        // Store gathered values to destination\n        _mm256_storeu_ps(&dst[i], gathered_values);\n    }\n    \n    // Handle remaining elements\n    for (; i < length; i++) {\n        dst[i] = src[indices[i]];\n    }\n    \n    // Scatter operation\n    for (i = 0; i < length; i += 8) {\n        __m256i index_vec = _mm256_loadu_si256((__m256i*)&indices[i]);\n        __m256 values_to_scatter = _mm256_loadu_ps(&src[i]);\n        \n        // Scatter values to destination using indices\n        for (int j = 0; j < 8; j++) {\n            int idx = _mm256_extract_epi32(index_vec, j);\n            dst[idx] = _mm256_extractf32_ps(values_to_scatter, j);\n        }\n    }\n    \n    // Handle remaining elements for scatter\n    for (; i < length; i++) {\n        dst[indices[i]] = src[i];\n    }\n}\n```"}
{"task_id": "SimdBench_3_AVX", "completion": "```cpp\nvoid indexed_access_simd(const float *src, const int *indices, float *dst, size_t length) {\n    size_t i = 0;\n    \n    // Process 8 elements at a time using AVX\n    for (; i + 8 <= length; i += 8) {\n        // Gather operation: Load values from source using indices\n        __m256i index_vec = _mm256_loadu_si256((__m256i*)&indices[i]);\n        __m256 gathered_values = _mm256_i32gather_ps(src, index_vec, 4);\n        \n        // Store gathered values to destination\n        _mm256_storeu_ps(&dst[i], gathered_values);\n    }\n    \n    // Handle remaining elements\n    for (; i < length; i++) {\n        dst[i] = src[indices[i]];\n    }\n    \n    // Scatter operation: Write values to source using indices\n    for (i = 0; i + 8 <= length; i += 8) {\n        __m256i index_vec = _mm256_loadu_si256((__m256i*)&indices[i]);\n        __m256 values_to_scatter = _mm256_loadu_ps(&dst[i]);\n        \n        // Scatter values back to source\n        for (int j = 0; j < 8; j++) {\n            int index = _mm256_extract_epi32(index_vec, j);\n            src[index] = _mm256_extractf32x4_ps(values_to_scatter, j / 4)[j % 4];\n        }\n    }\n    \n    // Handle remaining elements for scatter\n    for (; i < length; i++) {\n        src[indices[i]] = dst[i];\n    }\n}\n```"}
{"task_id": "SimdBench_3_AVX", "completion": "```cpp\nvoid indexed_access_simd(const float *src, const int *indices, float *dst, size_t length) {\n    size_t i = 0;\n    \n    // Process 8 elements at a time using AVX\n    for (; i + 8 <= length; i += 8) {\n        // Gather operation: Load values from source using indices\n        __m256i index_vec = _mm256_loadu_si256((__m256i*)&indices[i]);\n        __m256 gathered_values = _mm256_i32gather_ps(src, index_vec, 4);\n        \n        // Store gathered values to destination\n        _mm256_storeu_ps(&dst[i], gathered_values);\n    }\n    \n    // Handle remaining elements\n    for (; i < length; i++) {\n        dst[i] = src[indices[i]];\n    }\n    \n    // Scatter operation: Write values to source locations specified by indices\n    for (i = 0; i < length; i += 8) {\n        __m256i index_vec = _mm256_loadu_si256((__m256i*)&indices[i]);\n        __m256 values_to_scatter = _mm256_loadu_ps(&dst[i]);\n        \n        // Scatter values back to source array\n        for (int j = 0; j < 8; j++) {\n            int idx = _mm256_extract_epi32(index_vec, j);\n            src[idx] = _mm256_extractf32x4_ps(values_to_scatter, j / 4)[j % 4];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_3_AVX", "completion": "```cpp\nvoid indexed_access_simd(const float *src, const int *indices, float *dst, size_t length) {\n    size_t i = 0;\n    for (; i + 8 <= length; i += 8) {\n        // Gather operation\n        __m256i index_vec = _mm256_loadu_si256((__m256i*)&indices[i]);\n        __m256 gathered_values = _mm256_i32gather_ps(src, index_vec, 4);\n        \n        // Scatter operation\n        _mm256_i32scatter_ps(dst, index_vec, gathered_values, 4);\n    }\n    \n    // Handle remaining elements\n    for (; i < length; ++i) {\n        dst[indices[i]] = src[indices[i]];\n    }\n}\n```"}
{"task_id": "SimdBench_3_AVX", "completion": "```cpp\nvoid indexed_access_simd(const float *src, const int *indices, float *dst, size_t length) {\n    size_t i = 0;\n    \n    // Process 8 elements at a time using AVX\n    for (; i + 8 <= length; i += 8) {\n        // Gather operation: Load values from source using indices\n        __m256i index_vec = _mm256_loadu_si256((__m256i*)&indices[i]);\n        __m256 gathered_values = _mm256_i32gather_ps(src, index_vec, 4);\n        \n        // Store gathered values to destination\n        _mm256_storeu_ps(&dst[i], gathered_values);\n    }\n    \n    // Handle remaining elements\n    for (; i < length; i++) {\n        dst[i] = src[indices[i]];\n    }\n    \n    // Scatter operation\n    for (i = 0; i < length; i += 8) {\n        __m256i index_vec = _mm256_loadu_si256((__m256i*)&indices[i]);\n        __m256 values_to_scatter = _mm256_loadu_ps(&src[i]);\n        \n        // Scatter values to destination using indices\n        for (int j = 0; j < 8; j++) {\n            int idx = _mm256_extract_epi32(index_vec, j);\n            dst[idx] = _mm256_extractf32x4_ps(values_to_scatter, j / 4)[j % 4];\n        }\n    }\n    \n    // Handle remaining elements for scatter\n    for (; i < length; i++) {\n        dst[indices[i]] = src[i];\n    }\n}\n```"}
{"task_id": "SimdBench_4_AVX", "completion": "```cpp\nvoid range_reverse_simd(int16_t *arr, uint64_t start, uint64_t end) {\n    // Calculate the number of elements to reverse\n    uint64_t length = end - start + 1;\n    \n    // Process 16 elements at a time using AVX2\n    uint64_t vector_length = length - (length % 16);\n    \n    for (uint64_t i = 0; i < vector_length; i += 16) {\n        // Load 16 elements from both ends\n        __m256i left = _mm256_loadu_si256((__m256i*)&arr[start + i]);\n        __m256i right = _mm256_loadu_si256((__m256i*)&arr[end - i - 15]);\n        \n        // Reverse the elements within each 16-bit vector\n        __m256i reversed_left = _mm256_shuffle_epi8(left, _mm256_setr_epi8(\n            1, 0, 3, 2, 5, 4, 7, 6, 9, 8, 11, 10, 13, 12, 15, 14,\n            1, 0, 3, 2, 5, 4, 7, 6, 9, 8, 11, 10, 13, 12, 15, 14\n        ));\n        \n        __m256i reversed_right = _mm256_shuffle_epi8(right, _mm256_setr_epi8(\n            1, 0, 3, 2, 5, 4, 7, 6, 9, 8, 11, 10, 13, 12, 15, 14,\n            1, 0, 3, 2, 5, 4, 7, 6, 9, 8, 11, 10, 13, 12, 15, 14\n        ));\n        \n        // Store the reversed elements back\n        _mm256_storeu_si256((__m256i*)&arr[start + i], reversed_right);\n        _mm256_storeu_si256((__m256i*)&arr[end - i - 15], reversed_left);\n    }\n    \n    // Handle remaining elements\n    for (uint64_t i = vector_length; i < length; i++) {\n        int16_t temp = arr[start + i];\n        arr[start + i] = arr[end - i];\n        arr[end - i] = temp;\n    }\n}\n```"}
{"task_id": "SimdBench_4_AVX", "completion": "```cpp\nvoid range_reverse_simd(int16_t *arr, uint64_t start, uint64_t end) {\n    // Calculate the number of elements to reverse\n    uint64_t length = end - start + 1;\n    \n    // Process 16 elements at a time using AVX2\n    uint64_t vector_length = length - (length % 16);\n    \n    for (uint64_t i = 0; i < vector_length; i += 16) {\n        // Load 16 elements from the start and end of the range\n        __m256i start_vec = _mm256_loadu_si256((__m256i*)&arr[start + i]);\n        __m256i end_vec = _mm256_loadu_si256((__m256i*)&arr[end - i - 15]);\n        \n        // Reverse the order of elements within each vector\n        __m256i reversed_start = _mm256_shuffle_epi32(start_vec, _MM_SHUFFLE(0, 1, 2, 3));\n        reversed_start = _mm256_shufflehi_epi16(reversed_start, _MM_SHUFFLE(0, 1, 2, 3));\n        reversed_start = _mm256_shufflelo_epi16(reversed_start, _MM_SHUFFLE(0, 1, 2, 3));\n        \n        __m256i reversed_end = _mm256_shuffle_epi32(end_vec, _MM_SHUFFLE(0, 1, 2, 3));\n        reversed_end = _mm256_shufflehi_epi16(reversed_end, _MM_SHUFFLE(0, 1, 2, 3));\n        reversed_end = _mm256_shufflelo_epi16(reversed_end, _MM_SHUFFLE(0, 1, 2, 3));\n        \n        // Store the reversed vectors back to the original array\n        _mm256_storeu_si256((__m256i*)&arr[start + i], reversed_end);\n        _mm256_storeu_si256((__m256i*)&arr[end - i - 15], reversed_start);\n    }\n    \n    // Handle remaining elements\n    for (uint64_t i = vector_length; i < length; i++) {\n        int16_t temp = arr[start + i];\n        arr[start + i] = arr[end - i];\n        arr[end - i] = temp;\n    }\n}\n```"}
{"task_id": "SimdBench_4_AVX", "completion": "```cpp\nvoid range_reverse_simd(int16_t *arr, uint64_t start, uint64_t end) {\n    // Calculate the number of elements to reverse\n    uint64_t len = end - start + 1;\n    \n    // Process 16 elements at a time using AVX2\n    uint64_t vec_len = len - (len % 16);\n    for (uint64_t i = 0; i < vec_len; i += 16) {\n        __m256i left = _mm256_loadu_si256((__m256i*)&arr[start + i]);\n        __m256i right = _mm256_loadu_si256((__m256i*)&arr[end - i - 15]);\n        \n        // Reverse each 16-bit element within the vector\n        __m256i shuffled_left = _mm256_shufflehi_epi16(_mm256_shufflelo_epi16(left, 0x1B), 0x1B);\n        __m256i shuffled_right = _mm256_shufflehi_epi16(_mm256_shufflelo_epi16(right, 0x1B), 0x1B);\n        \n        // Store reversed vectors back to original positions\n        _mm256_storeu_si256((__m256i*)&arr[start + i], shuffled_right);\n        _mm256_storeu_si256((__m256i*)&arr[end - i - 15], shuffled_left);\n    }\n    \n    // Handle remaining elements\n    for (uint64_t i = vec_len; i < len; i++) {\n        int16_t temp = arr[start + i];\n        arr[start + i] = arr[end - i];\n        arr[end - i] = temp;\n    }\n}\n```"}
{"task_id": "SimdBench_4_AVX", "completion": "```cpp\nvoid range_reverse_simd(int16_t *arr, uint64_t start, uint64_t end) {\n    // Calculate the number of elements to reverse\n    uint64_t len = end - start + 1;\n    \n    // Process 16 elements at a time using AVX2\n    uint64_t vec_len = len - (len % 16);\n    for (uint64_t i = 0; i < vec_len; i += 16) {\n        __m256i left = _mm256_loadu_si256((__m256i*)&arr[start + i]);\n        __m256i right = _mm256_loadu_si256((__m256i*)&arr[end - i - 15]);\n        \n        // Reverse each 16-bit element within the vector\n        __m256i shuffled_left = _mm256_shufflehi_epi16(_mm256_shufflelo_epi16(left, 0x1B), 0x1B);\n        __m256i shuffled_right = _mm256_shufflehi_epi16(_mm256_shufflelo_epi16(right, 0x1B), 0x1B);\n        \n        _mm256_storeu_si256((__m256i*)&arr[start + i], shuffled_right);\n        _mm256_storeu_si256((__m256i*)&arr[end - i - 15], shuffled_left);\n    }\n    \n    // Handle remaining elements\n    for (uint64_t i = vec_len; i < len; i++) {\n        int16_t temp = arr[start + i];\n        arr[start + i] = arr[end - i];\n        arr[end - i] = temp;\n    }\n}\n```"}
{"task_id": "SimdBench_4_AVX", "completion": "```cpp\nvoid range_reverse_simd(int16_t *arr, uint64_t start, uint64_t end) {\n    // Calculate the number of elements to reverse\n    uint64_t len = end - start + 1;\n    \n    // Process 16 elements at a time using AVX2\n    uint64_t vec_len = len - (len % 16);\n    for (uint64_t i = 0; i < vec_len; i += 16) {\n        __m256i left = _mm256_loadu_si256((__m256i*)&arr[start + i]);\n        __m256i right = _mm256_loadu_si256((__m256i*)&arr[end - i - 15]);\n        \n        // Reverse each 16-bit element within the 256-bit vector\n        left = _mm256_shufflehi_epi16(left, _MM_SHUFFLE(0, 1, 2, 3));\n        left = _mm256_shufflelo_epi16(left, _MM_SHUFFLE(0, 1, 2, 3));\n        right = _mm256_shufflehi_epi16(right, _MM_SHUFFLE(0, 1, 2, 3));\n        right = _mm256_shufflelo_epi16(right, _MM_SHUFFLE(0, 1, 2, 3));\n        \n        // Swap the reversed vectors\n        _mm256_storeu_si256((__m256i*)&arr[start + i], right);\n        _mm256_storeu_si256((__m256i*)&arr[end - i - 15], left);\n    }\n    \n    // Handle remaining elements\n    for (uint64_t i = vec_len; i < len; i++) {\n        int16_t temp = arr[start + i];\n        arr[start + i] = arr[end - i];\n        arr[end - i] = temp;\n    }\n}\n```"}
{"task_id": "SimdBench_5_AVX", "completion": "```cpp\nvoid extract_tensor_slice_simd(const uint8_t *tensor, uint8_t *slice, size_t dim1, size_t dim2, size_t dim3, size_t slice_idx) {\n    // Calculate the offset for the specific slice\n    size_t slice_offset = slice_idx * dim1 * dim2;\n    const uint8_t *slice_start = tensor + slice_offset;\n\n    // Process 32 bytes (256 bits) at a time using AVX2\n    size_t vec_width = 32;\n    size_t vec_processed = 0;\n    size_t total_slice_size = dim1 * dim2;\n\n    // Process vectorized chunks\n    for (; vec_processed + vec_width <= total_slice_size; vec_processed += vec_width) {\n        __m256i vec_data = _mm256_loadu_si256((__m256i*)(slice_start + vec_processed));\n        _mm256_storeu_si256((__m256i*)(slice + vec_processed), vec_data);\n    }\n\n    // Handle remaining elements\n    for (; vec_processed < total_slice_size; vec_processed++) {\n        slice[vec_processed] = slice_start[vec_processed];\n    }\n}\n```"}
{"task_id": "SimdBench_5_AVX", "completion": "```cpp\nvoid extract_tensor_slice_simd(const uint8_t *tensor, uint8_t *slice, size_t dim1, size_t dim2, size_t dim3, size_t slice_idx) {\n    // Calculate the offset for the specific slice\n    size_t slice_offset = slice_idx * dim1 * dim2;\n    const uint8_t *slice_start = tensor + slice_offset;\n\n    // Process 32 bytes (256 bits) at a time using AVX2\n    size_t vec_width = 32;\n    size_t vec_processed = 0;\n    size_t total_slice_size = dim1 * dim2;\n\n    // Process vectorized chunks\n    for (; vec_processed + vec_width <= total_slice_size; vec_processed += vec_width) {\n        __m256i vec_data = _mm256_loadu_si256((__m256i*)(slice_start + vec_processed));\n        _mm256_storeu_si256((__m256i*)(slice + vec_processed), vec_data);\n    }\n\n    // Handle remaining elements\n    for (; vec_processed < total_slice_size; vec_processed++) {\n        slice[vec_processed] = slice_start[vec_processed];\n    }\n}\n```"}
{"task_id": "SimdBench_5_AVX", "completion": "```cpp\nvoid extract_tensor_slice_simd(const uint8_t *tensor, uint8_t *slice, size_t dim1, size_t dim2, size_t dim3, size_t slice_idx) {\n    // Calculate the offset for the slice in the original tensor\n    size_t slice_offset = slice_idx * dim1 * dim2;\n    const uint8_t *slice_start = tensor + slice_offset;\n\n    // Process 32 bytes (256 bits) at a time using AVX2 \n    size_t vec_width = 32;\n    size_t vec_elements = vec_width;\n    size_t i = 0;\n\n    // Process vectorized chunks\n    for (; i + vec_elements <= dim1 * dim2; i += vec_elements) {\n        __m256i vec_data = _mm256_loadu_si256((__m256i*)(slice_start + i));\n        _mm256_storeu_si256((__m256i*)(slice + i), vec_data);\n    }\n\n    // Handle remaining elements sequentially\n    for (; i < dim1 * dim2; i++) {\n        slice[i] = slice_start[i];\n    }\n}\n```"}
{"task_id": "SimdBench_5_AVX", "completion": "```cpp\nvoid extract_tensor_slice_simd(const uint8_t *tensor, uint8_t *slice, size_t dim1, size_t dim2, size_t dim3, size_t slice_idx) {\n    // Calculate the offset for the slice\n    size_t slice_offset = slice_idx * dim1 * dim2;\n    const uint8_t *slice_start = tensor + slice_offset;\n\n    // Process 32 bytes (256 bits) at a time using AVX2\n    size_t vec_width = 32;\n    size_t vec_processed = 0;\n    size_t total_slice_size = dim1 * dim2;\n\n    // Process vectorized chunks\n    for (; vec_processed + vec_width <= total_slice_size; vec_processed += vec_width) {\n        __m256i vec_data = _mm256_loadu_si256((__m256i*)(slice_start + vec_processed));\n        _mm256_storeu_si256((__m256i*)(slice + vec_processed), vec_data);\n    }\n\n    // Handle remaining elements\n    for (; vec_processed < total_slice_size; vec_processed++) {\n        slice[vec_processed] = slice_start[vec_processed];\n    }\n}\n```"}
{"task_id": "SimdBench_5_AVX", "completion": "```cpp\nvoid extract_tensor_slice_simd(const uint8_t *tensor, uint8_t *slice, size_t dim1, size_t dim2, size_t dim3, size_t slice_idx) {\n    // Calculate the offset for the specific slice\n    size_t slice_offset = slice_idx * dim1 * dim2;\n    const uint8_t *slice_start = tensor + slice_offset;\n\n    // Process 32 bytes (256 bits) at a time using AVX2\n    size_t vec_width = 32;\n    size_t vec_processed = 0;\n    size_t total_slice_size = dim1 * dim2;\n\n    // Process vectorized chunks\n    for (; vec_processed + vec_width <= total_slice_size; vec_processed += vec_width) {\n        __m256i vec_data = _mm256_loadu_si256((__m256i*)(slice_start + vec_processed));\n        _mm256_storeu_si256((__m256i*)(slice + vec_processed), vec_data);\n    }\n\n    // Handle remaining elements\n    for (; vec_processed < total_slice_size; vec_processed++) {\n        slice[vec_processed] = slice_start[vec_processed];\n    }\n}\n```"}
{"task_id": "SimdBench_6_AVX", "completion": "```cpp\nvoid blocked_matrix_transpose_simd(const int16_t *src, int16_t *dst, size_t rows, size_t cols, size_t block_size) {\n    // Process blocks\n    for (size_t block_row = 0; block_row < rows; block_row += block_size) {\n        for (size_t block_col = 0; block_col < cols; block_col += block_size) {\n            // Iterate within each block\n            for (size_t i = block_row; i < std::min(block_row + block_size, rows); i++) {\n                for (size_t j = block_col; j < std::min(block_col + block_size, cols); j += 16) {\n                    // Determine remaining elements in this block\n                    size_t remaining = std::min(16, static_cast<int>(cols - j));\n                    \n                    // Load source data using AVX2 intrinsics\n                    __m256i src_vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&src[i * cols + j]));\n                    \n                    // Transpose within the 16-element vector\n                    for (size_t k = 0; k < remaining; k++) {\n                        dst[j * rows + i + k * rows] = src[i * cols + j + k];\n                    }\n                }\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_6_AVX", "completion": "```cpp\nvoid blocked_matrix_transpose_simd(const int16_t *src, int16_t *dst, size_t rows, size_t cols, size_t block_size) {\n    // Process blocks\n    for (size_t block_row = 0; block_row < rows; block_row += block_size) {\n        for (size_t block_col = 0; block_col < cols; block_col += block_size) {\n            // Iterate within each block\n            for (size_t row = block_row; row < std::min(block_row + block_size, rows); row++) {\n                for (size_t col = block_col; col < std::min(block_col + block_size, cols); col += 16) {\n                    // Determine remaining elements in this block\n                    size_t remaining = std::min(16, static_cast<int>(cols - col));\n                    \n                    // Load 16-bit integers using AVX2 intrinsics\n                    __m256i vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&src[row * cols + col]));\n                    \n                    // Store transposed elements\n                    for (size_t i = 0; i < remaining; ++i) {\n                        dst[col * rows + row + i * rows] = _mm256_extract_epi16(vec, i);\n                    }\n                }\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_6_AVX", "completion": "```cpp\nvoid blocked_matrix_transpose_simd(const int16_t *src, int16_t *dst, size_t rows, size_t cols, size_t block_size) {\n    // Process blocks\n    for (size_t block_row = 0; block_row < rows; block_row += block_size) {\n        for (size_t block_col = 0; block_col < cols; block_col += block_size) {\n            // Iterate within each block\n            for (size_t r = block_row; r < std::min(block_row + block_size, rows); r++) {\n                for (size_t c = block_col; c < std::min(block_col + block_size, cols); c += 16) {\n                    // Use AVX2 to load and transpose 16 16-bit integers at a time\n                    __m256i row_data = _mm256_loadu_si256((__m256i*)&src[r * cols + c]);\n                    \n                    // Transpose within the 16-element vector\n                    __m256i transposed = _mm256_permute4x64_epi64(row_data, 0b11011000);\n                    \n                    // Store the transposed data\n                    _mm256_storeu_si256((__m256i*)&dst[c * rows + r], transposed);\n                }\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_6_AVX", "completion": "```cpp\nvoid blocked_matrix_transpose_simd(const int16_t *src, int16_t *dst, size_t rows, size_t cols, size_t block_size) {\n    // Process blocks\n    for (size_t block_row = 0; block_row < rows; block_row += block_size) {\n        for (size_t block_col = 0; block_col < cols; block_col += block_size) {\n            // Iterate within each block\n            for (size_t row = block_row; row < std::min(block_row + block_size, rows); row++) {\n                for (size_t col = block_col; col < std::min(block_col + block_size, cols); col += 16) {\n                    // Determine how many elements to process in this iteration\n                    size_t remaining = std::min(16, static_cast<int>(cols - col));\n                    \n                    // Load source data using AVX2 intrinsics\n                    __m256i src_vector = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&src[row * cols + col]));\n                    \n                    // Transpose within the vector\n                    for (size_t i = 0; i < remaining; ++i) {\n                        dst[col * rows + row + i * rows] = _mm256_extract_epi16(src_vector, i);\n                    }\n                }\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_6_AVX", "completion": "```cpp\nvoid blocked_matrix_transpose_simd(const int16_t *src, int16_t *dst, size_t rows, size_t cols, size_t block_size) {\n    // Process blocks\n    for (size_t block_row = 0; block_row < rows; block_row += block_size) {\n        for (size_t block_col = 0; block_col < cols; block_col += block_size) {\n            // Iterate within each block\n            for (size_t r = block_row; r < std::min(block_row + block_size, rows); r++) {\n                for (size_t c = block_col; c < std::min(block_col + block_size, cols); c += 16) {\n                    // Ensure we don't go out of bounds\n                    size_t remaining = std::min(16, static_cast<int>(cols - c));\n                    \n                    // Load 16 16-bit integers\n                    __m256i vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&src[r * cols + c]));\n                    \n                    // Transpose within the 16-element vector\n                    for (size_t i = 0; i < remaining; ++i) {\n                        dst[c * rows + r + i] = _mm256_extract_epi16(vec, i);\n                    }\n                }\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_7_AVX", "completion": "```cpp\nfloat diagonal_sum_3d_simd(const float *array, size_t dim) {\n    __m256 sum_vector = _mm256_setzero_ps();\n    \n    for (size_t i = 0; i < dim; i++) {\n        size_t diagonal_index = i * dim * dim + i * dim + i;\n        __m256 diagonal_value = _mm256_set1_ps(array[diagonal_index]);\n        sum_vector = _mm256_add_ps(sum_vector, diagonal_value);\n    }\n    \n    // Horizontal sum of the vector\n    __m128 sum_low = _mm256_extractf128_ps(sum_vector, 0);\n    __m128 sum_high = _mm256_extractf128_ps(sum_vector, 1);\n    sum_low = _mm_add_ps(sum_low, sum_high);\n    sum_low = _mm_hadd_ps(sum_low, sum_low);\n    sum_low = _mm_hadd_ps(sum_low, sum_low);\n    \n    float final_sum = _mm_cvtss_f32(sum_low);\n    return final_sum;\n}\n```"}
{"task_id": "SimdBench_7_AVX", "completion": "```cpp\nfloat diagonal_sum_3d_simd(const float *array, size_t dim) {\n    __m256 sum_vector = _mm256_setzero_ps();\n    \n    for (size_t i = 0; i < dim; i++) {\n        size_t diagonal_index = i * dim * dim + i * dim + i;\n        __m256 diagonal_value = _mm256_set1_ps(array[diagonal_index]);\n        sum_vector = _mm256_add_ps(sum_vector, diagonal_value);\n    }\n    \n    // Horizontal sum of the vector\n    __m128 sum_low = _mm256_extractf128_ps(sum_vector, 0);\n    __m128 sum_high = _mm256_extractf128_ps(sum_vector, 1);\n    sum_low = _mm_add_ps(sum_low, sum_high);\n    sum_low = _mm_hadd_ps(sum_low, sum_low);\n    sum_low = _mm_hadd_ps(sum_low, sum_low);\n    \n    float final_sum = _mm_cvtss_f32(sum_low);\n    return final_sum;\n}\n```"}
{"task_id": "SimdBench_7_AVX", "completion": "```cpp\nfloat diagonal_sum_3d_simd(const float *array, size_t dim) {\n    __m256 sum_vec = _mm256_setzero_ps();\n    \n    for (size_t i = 0; i < dim; i++) {\n        size_t diagonal_index = i * dim * dim + i * dim + i;\n        __m256 diagonal_vec = _mm256_set1_ps(array[diagonal_index]);\n        sum_vec = _mm256_add_ps(sum_vec, diagonal_vec);\n    }\n    \n    // Horizontal sum of vector\n    __m128 sum_low = _mm256_extractf128_ps(sum_vec, 0);\n    __m128 sum_high = _mm256_extractf128_ps(sum_vec, 1);\n    sum_low = _mm_add_ps(sum_low, sum_high);\n    sum_low = _mm_hadd_ps(sum_low, sum_low);\n    sum_low = _mm_hadd_ps(sum_low, sum_low);\n    \n    return _mm_cvtss_f32(sum_low);\n}\n```"}
{"task_id": "SimdBench_7_AVX", "completion": "```cpp\nfloat diagonal_sum_3d_simd(const float *array, size_t dim) {\n    __m256 sum_vector = _mm256_setzero_ps();\n    \n    for (size_t i = 0; i < dim; i++) {\n        size_t diagonal_index = i * dim * dim + i * dim + i;\n        __m256 diagonal_value = _mm256_set1_ps(array[diagonal_index]);\n        sum_vector = _mm256_add_ps(sum_vector, diagonal_value);\n    }\n    \n    // Horizontal sum of the vector\n    __m128 sum_low = _mm256_extractf128_ps(sum_vector, 0);\n    __m128 sum_high = _mm256_extractf128_ps(sum_vector, 1);\n    sum_low = _mm_add_ps(sum_low, sum_high);\n    sum_low = _mm_hadd_ps(sum_low, sum_low);\n    sum_low = _mm_hadd_ps(sum_low, sum_low);\n    \n    float final_sum = _mm_cvtss_f32(sum_low);\n    return final_sum;\n}\n```"}
{"task_id": "SimdBench_7_AVX", "completion": "```cpp\nfloat diagonal_sum_3d_simd(const float *array, size_t dim) {\n    __m256 sum_vector = _mm256_setzero_ps();\n    \n    for (size_t i = 0; i < dim; i++) {\n        size_t diagonal_index = i * dim * dim + i * dim + i;\n        __m256 diagonal_value = _mm256_set1_ps(array[diagonal_index]);\n        sum_vector = _mm256_add_ps(sum_vector, diagonal_value);\n    }\n    \n    // Horizontal sum of the vector\n    __m128 sum_low = _mm256_extractf128_ps(sum_vector, 0);\n    __m128 sum_high = _mm256_extractf128_ps(sum_vector, 1);\n    sum_low = _mm_add_ps(sum_low, sum_high);\n    sum_low = _mm_hadd_ps(sum_low, sum_low);\n    sum_low = _mm_hadd_ps(sum_low, sum_low);\n    \n    float final_sum = _mm_cvtss_f32(sum_low);\n    return final_sum;\n}\n```"}
{"task_id": "SimdBench_8_AVX", "completion": "```cpp\nvoid conditional_scale_simd(const double *src, double *dst, size_t rows, size_t cols, double threshold, double scale) {\n    __m256d threshold_vec = _mm256_set1_pd(threshold);\n    __m256d scale_vec = _mm256_set1_pd(scale);\n\n    for (size_t i = 0; i < rows; i++) {\n        for (size_t j = 0; j < cols; j += 4) {\n            __m256d src_vec = _mm256_loadu_pd(&src[i * cols + j]);\n            \n            __m256d mask = _mm256_cmp_pd(src_vec, threshold_vec, _CMP_GT_OQ);\n            __m256d scaled_vec = _mm256_mul_pd(src_vec, scale_vec);\n            \n            __m256d result_vec = _mm256_blendv_pd(src_vec, scaled_vec, mask);\n            \n            _mm256_storeu_pd(&dst[i * cols + j], result_vec);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_8_AVX", "completion": "```cpp\nvoid conditional_scale_simd(const double *src, double *dst, size_t rows, size_t cols, double threshold, double scale) {\n    __m256d threshold_vec = _mm256_set1_pd(threshold);\n    __m256d scale_vec = _mm256_set1_pd(scale);\n\n    for (size_t i = 0; i < rows; i++) {\n        for (size_t j = 0; j < cols; j += 4) {\n            __m256d src_vec = _mm256_loadu_pd(&src[i * cols + j]);\n            \n            __m256d mask = _mm256_cmp_pd(src_vec, threshold_vec, _CMP_GT_OQ);\n            __m256d scaled_vec = _mm256_mul_pd(src_vec, scale_vec);\n            \n            __m256d result = _mm256_blendv_pd(src_vec, scaled_vec, mask);\n            \n            _mm256_storeu_pd(&dst[i * cols + j], result);\n        }\n        \n        // Handle remaining elements if cols is not divisible by 4\n        for (size_t j = cols - (cols % 4); j < cols; j++) {\n            dst[i * cols + j] = (src[i * cols + j] > threshold) ? \n                                 src[i * cols + j] * scale : \n                                 src[i * cols + j];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_8_AVX", "completion": "```cpp\nvoid conditional_scale_simd(const double *src, double *dst, size_t rows, size_t cols, double threshold, double scale) {\n    __m256d threshold_vec = _mm256_set1_pd(threshold);\n    __m256d scale_vec = _mm256_set1_pd(scale);\n\n    for (size_t i = 0; i < rows; i++) {\n        for (size_t j = 0; j < cols; j += 4) {\n            __m256d src_vec = _mm256_loadu_pd(&src[i * cols + j]);\n            \n            __m256d mask = _mm256_cmp_pd(src_vec, threshold_vec, _CMP_GT_OQ);\n            __m256d scaled_vec = _mm256_mul_pd(src_vec, scale_vec);\n            \n            __m256d result_vec = _mm256_blendv_pd(src_vec, scaled_vec, mask);\n            \n            _mm256_storeu_pd(&dst[i * cols + j], result_vec);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_8_AVX", "completion": "```cpp\nvoid conditional_scale_simd(const double *src, double *dst, size_t rows, size_t cols, double threshold, double scale) {\n    __m256d threshold_vec = _mm256_set1_pd(threshold);\n    __m256d scale_vec = _mm256_set1_pd(scale);\n\n    for (size_t i = 0; i < rows; i++) {\n        for (size_t j = 0; j < cols; j += 4) {\n            __m256d src_vec = _mm256_loadu_pd(&src[i * cols + j]);\n            \n            __m256d mask = _mm256_cmp_pd(src_vec, threshold_vec, _CMP_GT_OQ);\n            __m256d scaled_vec = _mm256_mul_pd(src_vec, scale_vec);\n            \n            __m256d result_vec = _mm256_blendv_pd(src_vec, scaled_vec, mask);\n            \n            _mm256_storeu_pd(&dst[i * cols + j], result_vec);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_8_AVX", "completion": "```cpp\nvoid conditional_scale_simd(const double *src, double *dst, size_t rows, size_t cols, double threshold, double scale) {\n    __m256d threshold_vec = _mm256_set1_pd(threshold);\n    __m256d scale_vec = _mm256_set1_pd(scale);\n\n    for (size_t i = 0; i < rows; i++) {\n        for (size_t j = 0; j < cols; j += 4) {\n            __m256d src_vec = _mm256_loadu_pd(&src[i * cols + j]);\n            \n            __m256d mask = _mm256_cmp_pd(src_vec, threshold_vec, _CMP_GT_OQ);\n            __m256d scaled_vec = _mm256_mul_pd(src_vec, scale_vec);\n            \n            __m256d result_vec = _mm256_blendv_pd(src_vec, scaled_vec, mask);\n            \n            _mm256_storeu_pd(&dst[i * cols + j], result_vec);\n        }\n        \n        // Handle remaining elements if cols is not divisible by 4\n        for (size_t j = cols - (cols % 4); j < cols; j++) {\n            dst[i * cols + j] = (src[i * cols + j] > threshold) ? \n                                 src[i * cols + j] * scale : \n                                 src[i * cols + j];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_9_AVX", "completion": "```cpp\nvoid reorder_matrix_rows_simd(const double *src, double *dst, size_t rows, size_t cols, const size_t *indices) {\n    // Process 4 doubles at a time with AVX2\n    size_t vector_cols = cols - (cols % 4);\n    \n    for (size_t i = 0; i < rows; i++) {\n        size_t src_row_index = indices[i];\n        const double *src_row_ptr = src + src_row_index * cols;\n        double *dst_row_ptr = dst + i * cols;\n        \n        // Process 4 doubles at a time using AVX2\n        size_t j;\n        for (j = 0; j < vector_cols; j += 4) {\n            __m256d vec = _mm256_loadu_pd(src_row_ptr + j);\n            _mm256_storeu_pd(dst_row_ptr + j, vec);\n        }\n        \n        // Handle remaining elements\n        for (; j < cols; j++) {\n            dst_row_ptr[j] = src_row_ptr[j];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_9_AVX", "completion": "```cpp\nvoid reorder_matrix_rows_simd(const double *src, double *dst, size_t rows, size_t cols, const size_t *indices) {\n    // Process 4 doubles at a time with AVX2\n    size_t vector_width = 4;\n    \n    for (size_t i = 0; i < rows; i++) {\n        size_t src_row_index = indices[i];\n        const double *src_row_ptr = src + src_row_index * cols;\n        double *dst_row_ptr = dst + i * cols;\n        \n        // Process 4 doubles at a time\n        size_t j;\n        for (j = 0; j + vector_width <= cols; j += vector_width) {\n            __m256d vec = _mm256_loadu_pd(src_row_ptr + j);\n            _mm256_storeu_pd(dst_row_ptr + j, vec);\n        }\n        \n        // Handle remaining elements\n        for (; j < cols; j++) {\n            dst_row_ptr[j] = src_row_ptr[j];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_9_AVX", "completion": "```cpp\nvoid reorder_matrix_rows_simd(const double *src, double *dst, size_t rows, size_t cols, const size_t *indices) {\n    // Process 4 doubles at a time with AVX2\n    size_t vector_cols = cols - (cols % 4);\n    \n    for (size_t i = 0; i < rows; i++) {\n        size_t src_row_idx = indices[i];\n        const double *src_row_ptr = src + src_row_idx * cols;\n        double *dst_row_ptr = dst + i * cols;\n        \n        // Process 4 doubles at a time using AVX2\n        for (size_t j = 0; j < vector_cols; j += 4) {\n            __m256d vec = _mm256_loadu_pd(src_row_ptr + j);\n            _mm256_storeu_pd(dst_row_ptr + j, vec);\n        }\n        \n        // Handle remaining columns\n        for (size_t j = vector_cols; j < cols; j++) {\n            dst_row_ptr[j] = src_row_ptr[j];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_9_AVX", "completion": "```cpp\nvoid reorder_matrix_rows_simd(const double *src, double *dst, size_t rows, size_t cols, const size_t *indices) {\n    // Process 4 doubles at a time using AVX2 256-bit vectors\n    size_t vector_cols = cols - (cols % 4);\n    \n    for (size_t i = 0; i < rows; i++) {\n        size_t src_row_idx = indices[i];\n        const double *src_row_ptr = src + src_row_idx * cols;\n        double *dst_row_ptr = dst + i * cols;\n        \n        // Process 4 doubles at a time\n        for (size_t j = 0; j < vector_cols; j += 4) {\n            __m256d vec = _mm256_loadu_pd(src_row_ptr + j);\n            _mm256_storeu_pd(dst_row_ptr + j, vec);\n        }\n        \n        // Handle remaining columns\n        for (size_t j = vector_cols; j < cols; j++) {\n            dst_row_ptr[j] = src_row_ptr[j];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_9_AVX", "completion": "```cpp\nvoid reorder_matrix_rows_simd(const double *src, double *dst, size_t rows, size_t cols, const size_t *indices) {\n    // Process 4 doubles at a time using AVX2 256-bit vectors\n    size_t vector_cols = cols - (cols % 4);\n    \n    for (size_t i = 0; i < rows; i++) {\n        size_t src_row_idx = indices[i];\n        const double *src_row_ptr = src + src_row_idx * cols;\n        double *dst_row_ptr = dst + i * cols;\n        \n        // Process 4 doubles at a time\n        for (size_t j = 0; j < vector_cols; j += 4) {\n            __m256d vec = _mm256_loadu_pd(src_row_ptr + j);\n            _mm256_storeu_pd(dst_row_ptr + j, vec);\n        }\n        \n        // Handle remaining columns\n        for (size_t j = vector_cols; j < cols; j++) {\n            dst_row_ptr[j] = src_row_ptr[j];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_10_AVX", "completion": "```cpp\nvoid vector_vector_add_simd(const int64_t *src1, const int64_t *src2, int64_t *dst, int64_t scalar, size_t length) {\n    // Process 4 elements at a time using AVX2 256-bit registers\n    size_t i = 0;\n    __m256i scalar_vec = _mm256_set1_epi64x(scalar);\n\n    // Process 4 elements per iteration\n    for (; i + 4 <= length; i += 4) {\n        // Load 4 elements from src1 and src2\n        __m256i vec1 = _mm256_loadu_si256((__m256i*)&src1[i]);\n        __m256i vec2 = _mm256_loadu_si256((__m256i*)&src2[i]);\n\n        // Add src1 and src2\n        __m256i sum = _mm256_add_epi64(vec1, vec2);\n\n        // Add scalar to each element\n        sum = _mm256_add_epi64(sum, scalar_vec);\n\n        // Divide by 2 (round toward zero)\n        sum = _mm256_srai_epi64(sum, 1);\n\n        // Store result in destination array\n        _mm256_storeu_si256((__m256i*)&dst[i], sum);\n    }\n\n    // Handle remaining elements\n    for (; i < length; i++) {\n        dst[i] = (src1[i] + src2[i] + scalar) / 2;\n    }\n}\n```"}
{"task_id": "SimdBench_10_AVX", "completion": "```cpp\nvoid vector_vector_add_simd(const int64_t *src1, const int64_t *src2, int64_t *dst, int64_t scalar, size_t length) {\n    size_t i = 0;\n    __m256i scalar_vec = _mm256_set1_epi64x(scalar);\n\n    // Process 4 elements at a time using AVX2\n    for (; i + 4 <= length; i += 4) {\n        __m256i vec1 = _mm256_loadu_si256((__m256i*)&src1[i]);\n        __m256i vec2 = _mm256_loadu_si256((__m256i*)&src2[i]);\n        \n        // Add src1 and src2\n        __m256i sum = _mm256_add_epi64(vec1, vec2);\n        \n        // Add scalar to result\n        sum = _mm256_add_epi64(sum, scalar_vec);\n        \n        // Divide by 2 (round toward zero)\n        sum = _mm256_srai_epi64(sum, 1);\n        \n        // Store result\n        _mm256_storeu_si256((__m256i*)&dst[i], sum);\n    }\n\n    // Handle remaining elements\n    for (; i < length; i++) {\n        dst[i] = (src1[i] + src2[i] + scalar) / 2;\n    }\n}\n```"}
{"task_id": "SimdBench_10_AVX", "completion": "```cpp\nvoid vector_vector_add_simd(const int64_t *src1, const int64_t *src2, int64_t *dst, int64_t scalar, size_t length) {\n    // Process 4 elements at a time using AVX2 256-bit registers\n    size_t i = 0;\n    __m256i scalar_vec = _mm256_set1_epi64x(scalar);\n\n    // Vectorized processing for main loop\n    for (; i + 4 <= length; i += 4) {\n        // Load source vectors\n        __m256i vec1 = _mm256_loadu_si256((__m256i*)&src1[i]);\n        __m256i vec2 = _mm256_loadu_si256((__m256i*)&src2[i]);\n\n        // Add source vectors\n        __m256i sum_vec = _mm256_add_epi64(vec1, vec2);\n\n        // Add scalar to result\n        sum_vec = _mm256_add_epi64(sum_vec, scalar_vec);\n\n        // Divide by 2 (round toward zero)\n        sum_vec = _mm256_srai_epi64(sum_vec, 1);\n\n        // Store result\n        _mm256_storeu_si256((__m256i*)&dst[i], sum_vec);\n    }\n\n    // Handle remaining elements\n    for (; i < length; i++) {\n        dst[i] = (src1[i] + src2[i] + scalar) / 2;\n    }\n}\n```"}
{"task_id": "SimdBench_10_AVX", "completion": "```cpp\nvoid vector_vector_add_simd(const int64_t *src1, const int64_t *src2, int64_t *dst, int64_t scalar, size_t length) {\n    // Process 4 elements at a time using AVX2 256-bit vectors\n    size_t i = 0;\n    __m256i scalar_vec = _mm256_set1_epi64x(scalar);\n\n    // Process 4 elements per iteration\n    for (; i + 4 <= length; i += 4) {\n        // Load 4 elements from src1 and src2\n        __m256i vec1 = _mm256_loadu_si256((__m256i*)&src1[i]);\n        __m256i vec2 = _mm256_loadu_si256((__m256i*)&src2[i]);\n\n        // Add vec1 and vec2\n        __m256i sum_vec = _mm256_add_epi64(vec1, vec2);\n\n        // Add scalar to each element\n        sum_vec = _mm256_add_epi64(sum_vec, scalar_vec);\n\n        // Divide by 2 (round toward zero)\n        sum_vec = _mm256_srai_epi64(sum_vec, 1);\n\n        // Store result in destination\n        _mm256_storeu_si256((__m256i*)&dst[i], sum_vec);\n    }\n\n    // Handle remaining elements\n    for (; i < length; i++) {\n        dst[i] = (src1[i] + src2[i] + scalar) / 2;\n    }\n}\n```"}
{"task_id": "SimdBench_10_AVX", "completion": "```cpp\nvoid vector_vector_add_simd(const int64_t *src1, const int64_t *src2, int64_t *dst, int64_t scalar, size_t length) {\n    // Process 4 elements at a time using AVX2 256-bit registers\n    size_t i = 0;\n    __m256i scalar_vec = _mm256_set1_epi64x(scalar);\n\n    // Process 4 elements per iteration\n    for (; i + 4 <= length; i += 4) {\n        // Load 4 elements from src1 and src2\n        __m256i vec1 = _mm256_loadu_si256((__m256i*)&src1[i]);\n        __m256i vec2 = _mm256_loadu_si256((__m256i*)&src2[i]);\n\n        // Add src1 and src2\n        __m256i sum = _mm256_add_epi64(vec1, vec2);\n\n        // Add scalar to result\n        sum = _mm256_add_epi64(sum, scalar_vec);\n\n        // Divide by 2 (round toward zero)\n        sum = _mm256_srai_epi64(sum, 1);\n\n        // Store result in destination\n        _mm256_storeu_si256((__m256i*)&dst[i], sum);\n    }\n\n    // Handle remaining elements\n    for (; i < length; i++) {\n        dst[i] = (src1[i] + src2[i] + scalar) / 2;\n    }\n}\n```"}
{"task_id": "SimdBench_11_AVX", "completion": "```cpp\nint vector_even_min_simd(const int *src, size_t length) {\n    if (length == 0) return -1;\n\n    __m256i min_vec = _mm256_set1_epi32(INT_MAX);\n    size_t i = 0;\n\n    // Process 8 elements at a time\n    for (; i + 8 <= length; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&src[i]);\n        \n        // Create mask for even indices\n        __m256i mask = _mm256_set_epi32(\n            0, -1, 0, -1, 0, -1, 0, -1\n        );\n        \n        // Mask out odd elements\n        vec = _mm256_and_si256(vec, mask);\n        \n        // Update minimum\n        min_vec = _mm256_min_epi32(min_vec, vec);\n    }\n\n    // Horizontal minimum\n    __m128i low128 = _mm256_extracti128_si256(min_vec, 0);\n    __m128i high128 = _mm256_extracti128_si256(min_vec, 1);\n    low128 = _mm_min_epi32(low128, high128);\n    low128 = _mm_min_epi32(low128, _mm_shuffle_epi32(low128, _MM_SHUFFLE(1, 0, 3, 2)));\n    int min_val = _mm_cvtsi128_si32(low128);\n\n    // Handle remaining elements\n    for (; i < length; i += 2) {\n        min_val = std::min(min_val, src[i]);\n    }\n\n    return min_val;\n}\n```"}
{"task_id": "SimdBench_11_AVX", "completion": "```cpp\nint vector_even_min_simd(const int *src, size_t length) {\n    if (length == 0) return -1;\n\n    __m256i min_vec = _mm256_set1_epi32(INT_MAX);\n    size_t i = 0;\n\n    // Process 8 elements at a time\n    for (; i + 8 <= length; i += 8) {\n        // Create mask for even indices\n        __m256i indices = _mm256_setr_epi32(0, 2, 4, 6, 8, 10, 12, 14);\n        __m256i mask = _mm256_cmpeq_epi32(_mm256_and_si256(indices, _mm256_set1_epi32(1)), _mm256_setzero_si256());\n        \n        // Load even-indexed elements\n        __m256i vec = _mm256_maskload_epi32(src + i, mask);\n        \n        // Update minimum\n        min_vec = _mm256_min_epi32(min_vec, vec);\n    }\n\n    // Horizontal minimum\n    __m128i min_low = _mm256_extracti128_si256(min_vec, 0);\n    __m128i min_high = _mm256_extracti128_si256(min_vec, 1);\n    min_low = _mm_min_epi32(min_low, min_high);\n    min_low = _mm_min_epi32(min_low, _mm_shuffle_epi32(min_low, _MM_SHUFFLE(1, 0, 3, 2)));\n    min_low = _mm_min_epi32(min_low, _mm_shuffle_epi32(min_low, _MM_SHUFFLE(0, 1, 2, 3)));\n    int min_val = _mm_cvtsi128_si32(min_low);\n\n    // Handle remaining elements\n    for (; i < length; i += 2) {\n        min_val = std::min(min_val, src[i]);\n    }\n\n    return min_val;\n}\n```"}
{"task_id": "SimdBench_11_AVX", "completion": "```cpp\nint vector_even_min_simd(const int *src, size_t length) {\n    if (length == 0) return -1;\n\n    __m256i min_vec = _mm256_set1_epi32(INT_MAX);\n    size_t i = 0;\n\n    // Process 8 elements at a time\n    for (; i + 8 <= length; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&src[i]);\n        \n        // Create mask for even indices\n        __m256i mask = _mm256_set_epi32(\n            0, -1, 0, -1, 0, -1, 0, -1\n        );\n        \n        // Blend to keep only even elements\n        vec = _mm256_blendv_epi8(_mm256_set1_epi32(INT_MAX), vec, mask);\n        \n        // Update minimum\n        min_vec = _mm256_min_epi32(min_vec, vec);\n    }\n\n    // Horizontal min reduction\n    __m128i min_low = _mm256_extracti128_si256(min_vec, 0);\n    __m128i min_high = _mm256_extracti128_si256(min_vec, 1);\n    min_low = _mm_min_epi32(min_low, min_high);\n    min_low = _mm_min_epi32(min_low, _mm_shuffle_epi32(min_low, _MM_SHUFFLE(1, 0, 3, 2)));\n    min_low = _mm_min_epi32(min_low, _mm_shuffle_epi32(min_low, _MM_SHUFFLE(0, 1, 2, 3)));\n    int min_val = _mm_cvtsi128_si32(min_low);\n\n    // Handle remaining elements\n    for (; i < length; i += 2) {\n        min_val = std::min(min_val, src[i]);\n    }\n\n    return min_val;\n}\n```"}
{"task_id": "SimdBench_11_AVX", "completion": "```cpp\nint vector_even_min_simd(const int *src, size_t length) {\n    if (length == 0) return -1;\n\n    __m256i min_vec = _mm256_set1_epi32(INT_MAX);\n    size_t i;\n\n    // Process 8 elements at a time\n    for (i = 0; i + 8 <= length; i += 8) {\n        // Load even-indexed elements\n        __m256i vec = _mm256_setr_epi32(\n            src[i], 0, src[i+2], 0, \n            src[i+4], 0, src[i+6], 0\n        );\n        \n        // Update minimum\n        min_vec = _mm256_min_epi32(min_vec, vec);\n    }\n\n    // Horizontal minimum\n    __m128i low_half = _mm256_extracti128_si256(min_vec, 0);\n    __m128i high_half = _mm256_extracti128_si256(min_vec, 1);\n    low_half = _mm_min_epi32(low_half, high_half);\n    low_half = _mm_min_epi32(low_half, _mm_shuffle_epi32(low_half, _MM_SHUFFLE(1, 0, 3, 2)));\n    int min_val = _mm_cvtsi128_si32(low_half);\n\n    // Handle remaining elements\n    for (; i < length; i += 2) {\n        min_val = std::min(min_val, src[i]);\n    }\n\n    return min_val;\n}\n```"}
{"task_id": "SimdBench_11_AVX", "completion": "```cpp\nint vector_even_min_simd(const int *src, size_t length) {\n    if (length == 0) return -1;\n\n    __m256i min_vec = _mm256_set1_epi32(INT_MAX);\n    size_t i = 0;\n\n    // Process 8 elements at a time\n    for (; i + 8 <= length; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&src[i]);\n        \n        // Create mask for even indices\n        __m256i mask = _mm256_set_epi32(\n            0, -1, 0, -1, 0, -1, 0, -1\n        );\n        \n        // Blend to keep only even elements\n        vec = _mm256_blendv_epi8(\n            _mm256_set1_epi32(INT_MAX), \n            vec, \n            mask\n        );\n        \n        // Update minimum\n        min_vec = _mm256_min_epi32(min_vec, vec);\n    }\n\n    // Horizontal reduction\n    __m128i min_low = _mm256_extracti128_si256(min_vec, 0);\n    __m128i min_high = _mm256_extracti128_si256(min_vec, 1);\n    min_low = _mm_min_epi32(min_low, min_high);\n    min_low = _mm_min_epi32(min_low, _mm_shuffle_epi32(min_low, _MM_SHUFFLE(1, 0, 3, 2)));\n    min_low = _mm_min_epi32(min_low, _mm_shuffle_epi32(min_low, _MM_SHUFFLE(0, 1, 2, 3)));\n    int min_val = _mm_cvtsi128_si32(min_low);\n\n    // Handle remaining elements\n    for (; i < length; i += 2) {\n        min_val = std::min(min_val, src[i]);\n    }\n\n    return min_val;\n}\n```"}
{"task_id": "SimdBench_12_AVX", "completion": "```cpp\nvoid mixed_right_shift_simd(const int *src, int *dst, uint8_t shift, size_t length) {\n    size_t i = 0;\n    for (; i + 8 <= length; i += 8) {\n        // Load 8 integers from source array\n        __m256i vec_src = _mm256_loadu_si256((__m256i*)&src[i]);\n        \n        // Arithmetic right shift\n        __m256i arithmetic_shift = _mm256_sra_epi32(vec_src, _mm_cvtsi32_si128(shift));\n        \n        // Convert to unsigned and perform logical right shift\n        __m256i unsigned_src = _mm256_and_si256(vec_src, _mm256_set1_epi32(0xFFFFFFFF));\n        __m256i logical_shift = _mm256_srl_epi32(unsigned_src, _mm_cvtsi32_si128(shift));\n        \n        // Add arithmetic and logical shifts\n        __m256i result = _mm256_add_epi32(arithmetic_shift, logical_shift);\n        \n        // Store result in destination array\n        _mm256_storeu_si256((__m256i*)&dst[i], result);\n    }\n    \n    // Handle remaining elements\n    for (; i < length; i++) {\n        int arithmetic = src[i] >> shift;\n        unsigned int logical = ((unsigned int)src[i]) >> shift;\n        dst[i] = arithmetic + logical;\n    }\n}\n```"}
{"task_id": "SimdBench_12_AVX", "completion": "```cpp\nvoid mixed_right_shift_simd(const int *src, int *dst, uint8_t shift, size_t length) {\n    size_t i = 0;\n    for (; i + 8 <= length; i += 8) {\n        // Load 8 integers from source array\n        __m256i vec_src = _mm256_loadu_si256((__m256i*)&src[i]);\n        \n        // Arithmetic right shift\n        __m256i arithmetic_shift = _mm256_sra_epi32(vec_src, _mm_cvtsi32_si128(shift));\n        \n        // Convert to unsigned and perform logical right shift\n        __m256i unsigned_src = _mm256_and_si256(vec_src, _mm256_set1_epi32(0xFFFFFFFF));\n        __m256i logical_shift = _mm256_srl_epi32(unsigned_src, _mm_cvtsi32_si128(shift));\n        \n        // Add arithmetic and logical shifts\n        __m256i result = _mm256_add_epi32(arithmetic_shift, logical_shift);\n        \n        // Store result in destination array\n        _mm256_storeu_si256((__m256i*)&dst[i], result);\n    }\n    \n    // Handle remaining elements\n    for (; i < length; i++) {\n        int arithmetic = src[i] >> shift;\n        unsigned int logical = ((unsigned int)src[i]) >> shift;\n        dst[i] = arithmetic + logical;\n    }\n}\n```"}
{"task_id": "SimdBench_12_AVX", "completion": "```cpp\nvoid mixed_right_shift_simd(const int *src, int *dst, uint8_t shift, size_t length) {\n    size_t i = 0;\n    for (; i + 8 <= length; i += 8) {\n        // Load 8 integers from source array\n        __m256i vec_src = _mm256_loadu_si256((__m256i*)&src[i]);\n        \n        // Arithmetic right shift\n        __m256i arithmetic_shift = _mm256_sra_epi32(vec_src, _mm_cvtsi32_si128(shift));\n        \n        // Convert to unsigned and perform logical right shift\n        __m256i unsigned_vec = _mm256_and_si256(vec_src, _mm256_set1_epi32(0xFFFFFFFF));\n        __m256i logical_shift = _mm256_srl_epi32(unsigned_vec, _mm_cvtsi32_si128(shift));\n        \n        // Add arithmetic and logical shifts\n        __m256i result = _mm256_add_epi32(arithmetic_shift, logical_shift);\n        \n        // Store result in destination array\n        _mm256_storeu_si256((__m256i*)&dst[i], result);\n    }\n    \n    // Handle remaining elements\n    for (; i < length; i++) {\n        int arithmetic = src[i] >> shift;\n        unsigned int logical = (unsigned int)src[i] >> shift;\n        dst[i] = arithmetic + logical;\n    }\n}\n```"}
{"task_id": "SimdBench_12_AVX", "completion": "```cpp\nvoid mixed_right_shift_simd(const int *src, int *dst, uint8_t shift, size_t length) {\n    size_t i = 0;\n    for (; i + 8 <= length; i += 8) {\n        // Load 8 integers from source array\n        __m256i vec_src = _mm256_loadu_si256((__m256i*)&src[i]);\n        \n        // Arithmetic right shift\n        __m256i arithmetic_shift = _mm256_sra_epi32(vec_src, _mm_cvtsi32_si128(shift));\n        \n        // Convert to unsigned and perform logical right shift\n        __m256i unsigned_vec = _mm256_and_si256(vec_src, _mm256_set1_epi32(0xFFFFFFFF));\n        __m256i logical_shift = _mm256_srl_epi32(unsigned_vec, _mm_cvtsi32_si128(shift));\n        \n        // Add arithmetic and logical shifts\n        __m256i result = _mm256_add_epi32(arithmetic_shift, logical_shift);\n        \n        // Store result in destination array\n        _mm256_storeu_si256((__m256i*)&dst[i], result);\n    }\n    \n    // Handle remaining elements\n    for (; i < length; i++) {\n        int arithmetic = src[i] >> shift;\n        unsigned int logical = ((unsigned int)src[i]) >> shift;\n        dst[i] = arithmetic + logical;\n    }\n}\n```"}
{"task_id": "SimdBench_12_AVX", "completion": "```cpp\nvoid mixed_right_shift_simd(const int *src, int *dst, uint8_t shift, size_t length) {\n    size_t i = 0;\n    \n    // Process 8 elements at a time using AVX2 \n    for (; i + 8 <= length; i += 8) {\n        // Load 8 source integers \n        __m256i vec_src = _mm256_loadu_si256((__m256i*)&src[i]);\n        \n        // Arithmetic right shift\n        __m256i arithmetic_shift = _mm256_sra_epi32(vec_src, _mm_cvtsi32_si128(shift));\n        \n        // Convert to unsigned and perform logical right shift \n        __m256i unsigned_src = _mm256_and_si256(vec_src, _mm256_set1_epi32(0xFFFFFFFF));\n        __m256i logical_shift = _mm256_srl_epi32(unsigned_src, _mm_cvtsi32_si128(shift));\n        \n        // Add arithmetic and logical shifts\n        __m256i result = _mm256_add_epi32(arithmetic_shift, logical_shift);\n        \n        // Store result in destination array\n        _mm256_storeu_si256((__m256i*)&dst[i], result);\n    }\n    \n    // Handle remaining elements sequentially\n    for (; i < length; i++) {\n        int arithmetic = src[i] >> shift;\n        unsigned int unsigned_src = (unsigned int)src[i];\n        int logical = unsigned_src >> shift;\n        dst[i] = arithmetic + logical;\n    }\n}\n```"}
{"task_id": "SimdBench_13_AVX", "completion": "```cpp\nint64_t matrix_sum_simd(const int *matrix, size_t rows, size_t cols) {\n    int64_t total_sum = 0;\n    size_t total_elements = rows * cols;\n    size_t vector_size = total_elements - (total_elements % 8);\n\n    __m256i sum_vector = _mm256_setzero_si256();\n\n    // Process 8 integers at a time using AVX2\n    for (size_t i = 0; i < vector_size; i += 8) {\n        __m256i current_vector = _mm256_loadu_si256((__m256i*)&matrix[i]);\n        sum_vector = _mm256_add_epi32(sum_vector, current_vector);\n    }\n\n    // Horizontal sum of the vector\n    __m128i low_128 = _mm256_extracti128_si256(sum_vector, 0);\n    __m128i high_128 = _mm256_extracti128_si256(sum_vector, 1);\n    __m128i sum_128 = _mm_add_epi32(low_128, high_128);\n    sum_128 = _mm_hadd_epi32(sum_128, sum_128);\n    sum_128 = _mm_hadd_epi32(sum_128, sum_128);\n    int32_t vector_sum = _mm_cvtsi128_si32(sum_128);\n\n    total_sum += vector_sum;\n\n    // Process remaining elements\n    for (size_t i = vector_size; i < total_elements; i++) {\n        total_sum += matrix[i];\n    }\n\n    return total_sum;\n}\n```"}
{"task_id": "SimdBench_13_AVX", "completion": "```cpp\nint64_t matrix_sum_simd(const int *matrix, size_t rows, size_t cols) {\n    int64_t total_sum = 0;\n    size_t total_elements = rows * cols;\n    \n    // Process 8 integers at a time using AVX2 256-bit registers\n    __m256i sum_vector = _mm256_setzero_si256();\n    \n    size_t i;\n    for (i = 0; i + 7 < total_elements; i += 8) {\n        __m256i current_vector = _mm256_loadu_si256((__m256i*)&matrix[i]);\n        sum_vector = _mm256_add_epi32(sum_vector, current_vector);\n    }\n    \n    // Horizontal sum of AVX2 vector\n    __m128i sum_low = _mm256_extracti128_si256(sum_vector, 0);\n    __m128i sum_high = _mm256_extracti128_si256(sum_vector, 1);\n    __m128i sum_combined = _mm_add_epi32(sum_low, sum_high);\n    sum_combined = _mm_hadd_epi32(sum_combined, sum_combined);\n    sum_combined = _mm_hadd_epi32(sum_combined, sum_combined);\n    \n    total_sum = _mm_cvtsi128_si32(sum_combined);\n    \n    // Handle remaining elements\n    for (; i < total_elements; i++) {\n        total_sum += matrix[i];\n    }\n    \n    return total_sum;\n}\n```"}
{"task_id": "SimdBench_13_AVX", "completion": "```cpp\nint64_t matrix_sum_simd(const int *matrix, size_t rows, size_t cols) {\n    int64_t total_sum = 0;\n    size_t total_elements = rows * cols;\n    size_t vector_size = total_elements - (total_elements % 8);\n\n    __m256i sum_vector = _mm256_setzero_si256();\n\n    // Process 8 integers at a time using AVX2\n    for (size_t i = 0; i < vector_size; i += 8) {\n        __m256i current_vector = _mm256_loadu_si256((__m256i*)&matrix[i]);\n        sum_vector = _mm256_add_epi32(sum_vector, current_vector);\n    }\n\n    // Horizontal sum of the vector\n    __m128i low_128 = _mm256_extracti128_si256(sum_vector, 0);\n    __m128i high_128 = _mm256_extracti128_si256(sum_vector, 1);\n    __m128i sum_128 = _mm_add_epi32(low_128, high_128);\n    sum_128 = _mm_hadd_epi32(sum_128, sum_128);\n    sum_128 = _mm_hadd_epi32(sum_128, sum_128);\n    int32_t vector_sum = _mm_cvtsi128_si32(sum_128);\n\n    total_sum += vector_sum;\n\n    // Process remaining elements\n    for (size_t i = vector_size; i < total_elements; i++) {\n        total_sum += matrix[i];\n    }\n\n    return total_sum;\n}\n```"}
{"task_id": "SimdBench_13_AVX", "completion": "```cpp\nint64_t matrix_sum_simd(const int *matrix, size_t rows, size_t cols) {\n    int64_t total_sum = 0;\n    size_t total_elements = rows * cols;\n    size_t vector_size = total_elements - (total_elements % 8);\n\n    __m256i sum_vector = _mm256_setzero_si256();\n\n    // Process 8 integers at a time using AVX2\n    for (size_t i = 0; i < vector_size; i += 8) {\n        __m256i current_vector = _mm256_loadu_si256((__m256i*)&matrix[i]);\n        sum_vector = _mm256_add_epi32(sum_vector, current_vector);\n    }\n\n    // Horizontal sum of the vector\n    __m128i low_half = _mm256_extracti128_si256(sum_vector, 0);\n    __m128i high_half = _mm256_extracti128_si256(sum_vector, 1);\n    __m128i sum_128 = _mm_add_epi32(low_half, high_half);\n    sum_128 = _mm_hadd_epi32(sum_128, sum_128);\n    sum_128 = _mm_hadd_epi32(sum_128, sum_128);\n    int32_t vector_sum = _mm_cvtsi128_si32(sum_128);\n\n    total_sum += vector_sum;\n\n    // Handle remaining elements\n    for (size_t i = vector_size; i < total_elements; i++) {\n        total_sum += matrix[i];\n    }\n\n    return total_sum;\n}\n```"}
{"task_id": "SimdBench_13_AVX", "completion": "```cpp\nint64_t matrix_sum_simd(const int *matrix, size_t rows, size_t cols) {\n    int64_t total_sum = 0;\n    size_t total_elements = rows * cols;\n    size_t vector_size = total_elements - (total_elements % 8);\n\n    __m256i sum_vector = _mm256_setzero_si256();\n\n    // Process 8 integers at a time using AVX2\n    for (size_t i = 0; i < vector_size; i += 8) {\n        __m256i current_vector = _mm256_loadu_si256((__m256i*)&matrix[i]);\n        sum_vector = _mm256_add_epi32(sum_vector, current_vector);\n    }\n\n    // Horizontal sum of the vector\n    __m128i low_half = _mm256_extracti128_si256(sum_vector, 0);\n    __m128i high_half = _mm256_extracti128_si256(sum_vector, 1);\n    __m128i sum_128 = _mm_add_epi32(low_half, high_half);\n    sum_128 = _mm_hadd_epi32(sum_128, sum_128);\n    sum_128 = _mm_hadd_epi32(sum_128, sum_128);\n    int32_t vector_sum = _mm_cvtsi128_si32(sum_128);\n\n    total_sum += vector_sum;\n\n    // Handle remaining elements\n    for (size_t i = vector_size; i < total_elements; i++) {\n        total_sum += matrix[i];\n    }\n\n    return total_sum;\n}\n```"}
{"task_id": "SimdBench_14_AVX", "completion": "```cpp\nsize_t argmax_simd(const int8_t *src, size_t length) {\n    if (length == 0) return 0;\n\n    size_t max_index = 0;\n    int8_t max_val = src[0];\n\n    // Process 32 elements at a time with AVX2\n    size_t vector_len = length - (length % 32);\n    __m256i max_vec = _mm256_set1_epi8(src[0]);\n    __m256i max_indices_vec = _mm256_setzero_si256();\n\n    for (size_t i = 0; i < vector_len; i += 32) {\n        __m256i current_vec = _mm256_loadu_si256((__m256i*)&src[i]);\n        __m256i indices_vec = _mm256_set_epi8(\n            31, 30, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16,\n            15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 0\n        );\n        indices_vec = _mm256_add_epi8(indices_vec, _mm256_set1_epi8(i));\n\n        __m256i mask = _mm256_cmpgt_epi8(current_vec, max_vec);\n        max_vec = _mm256_blendv_epi8(max_vec, current_vec, mask);\n        max_indices_vec = _mm256_blendv_epi8(max_indices_vec, indices_vec, mask);\n    }\n\n    // Horizontal max within the vector\n    int8_t max_array[32];\n    size_t max_indices[32];\n    _mm256_storeu_si256((__m256i*)max_array, max_vec);\n    _mm256_storeu_si256((__m256i*)max_indices, max_indices_vec);\n\n    for (int j = 0; j < 32; j++) {\n        if (max_array[j] > max_val) {\n            max_val = max_array[j];\n            max_index = max_indices[j];\n        }\n    }\n\n    // Process remaining elements\n    for (size_t i = vector_len; i < length; i++) {\n        if (src[i] > max_val) {\n            max_val = src[i];\n            max_index = i;\n        }\n    }\n\n    return max_index;\n}\n```"}
{"task_id": "SimdBench_14_AVX", "completion": "```cpp\nsize_t argmax_simd(const int8_t *src, size_t length) {\n    if (length == 0) return 0;\n\n    size_t max_index = 0;\n    int8_t max_val = src[0];\n\n    // Process 32 elements at a time with AVX2\n    size_t vector_len = length - (length % 32);\n    __m256i max_vec = _mm256_set1_epi8(src[0]);\n    __m256i max_indices_vec = _mm256_setzero_si256();\n\n    for (size_t i = 0; i < vector_len; i += 32) {\n        __m256i current_vec = _mm256_loadu_si256((__m256i*)&src[i]);\n        __m256i indices_vec = _mm256_set_epi8(\n            31, 30, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16,\n            15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 0\n        );\n        indices_vec = _mm256_add_epi8(indices_vec, _mm256_set1_epi8(i));\n\n        __m256i cmp_mask = _mm256_cmpgt_epi8(current_vec, max_vec);\n        max_vec = _mm256_blendv_epi8(max_vec, current_vec, cmp_mask);\n        max_indices_vec = _mm256_blendv_epi8(max_indices_vec, indices_vec, cmp_mask);\n    }\n\n    // Horizontal max within the vector\n    int8_t max_vals[32];\n    size_t max_indices[32];\n    _mm256_storeu_si256((__m256i*)max_vals, max_vec);\n    _mm256_storeu_si256((__m256i*)max_indices, max_indices_vec);\n\n    for (int j = 0; j < 32; j++) {\n        if (max_vals[j] > max_val) {\n            max_val = max_vals[j];\n            max_index = max_indices[j];\n        }\n    }\n\n    // Process remaining elements\n    for (size_t i = vector_len; i < length; i++) {\n        if (src[i] > max_val) {\n            max_val = src[i];\n            max_index = i;\n        }\n    }\n\n    return max_index;\n}\n```"}
{"task_id": "SimdBench_14_AVX", "completion": "```cpp\nsize_t argmax_simd(const int8_t *src, size_t length) {\n    if (length == 0) return 0;\n\n    size_t max_index = 0;\n    int8_t max_val = src[0];\n\n    // Process 32 elements at a time with AVX2\n    size_t vector_len = length - (length % 32);\n    __m256i max_vec = _mm256_set1_epi8(src[0]);\n    __m256i max_indices_vec = _mm256_setzero_si256();\n\n    for (size_t i = 0; i < vector_len; i += 32) {\n        __m256i current_vec = _mm256_loadu_si256((__m256i*)&src[i]);\n        __m256i indices_vec = _mm256_set_epi8(\n            31, 30, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16,\n            15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 0\n        );\n\n        __m256i cmp_mask = _mm256_cmpgt_epi8(current_vec, max_vec);\n        max_vec = _mm256_blendv_epi8(max_vec, current_vec, cmp_mask);\n        max_indices_vec = _mm256_blendv_epi8(max_indices_vec, indices_vec, cmp_mask);\n    }\n\n    // Horizontal max within the vector\n    int8_t max_vals[32];\n    size_t max_indices[32];\n    _mm256_storeu_si256((__m256i*)max_vals, max_vec);\n    _mm256_storeu_si256((__m256i*)max_indices, max_indices_vec);\n\n    for (int j = 0; j < 32; j++) {\n        if (max_vals[j] > max_val) {\n            max_val = max_vals[j];\n            max_index = max_indices[j] + (vector_len > 0 ? vector_len - 32 : 0);\n        }\n    }\n\n    // Process remaining elements\n    for (size_t i = vector_len; i < length; i++) {\n        if (src[i] > max_val) {\n            max_val = src[i];\n            max_index = i;\n        }\n    }\n\n    return max_index;\n}\n```"}
{"task_id": "SimdBench_14_AVX", "completion": "```cpp\nsize_t argmax_simd(const int8_t *src, size_t length) {\n    if (length == 0) return 0;\n\n    size_t max_index = 0;\n    int8_t max_val = src[0];\n\n    // Process 32 elements at a time with AVX2\n    size_t vector_len = length - (length % 32);\n    __m256i max_vec = _mm256_set1_epi8(src[0]);\n    __m256i max_indices_vec = _mm256_setzero_si256();\n\n    for (size_t i = 0; i < vector_len; i += 32) {\n        __m256i current_vec = _mm256_loadu_si256((__m256i*)&src[i]);\n        __m256i indices_vec = _mm256_set_epi8(\n            31, 30, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16,\n            15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 0\n        );\n        indices_vec = _mm256_add_epi8(indices_vec, _mm256_set1_epi8(i));\n\n        __m256i cmp_mask = _mm256_cmpgt_epi8(current_vec, max_vec);\n        max_vec = _mm256_blendv_epi8(max_vec, current_vec, cmp_mask);\n        max_indices_vec = _mm256_blendv_epi8(max_indices_vec, indices_vec, cmp_mask);\n    }\n\n    // Horizontal max within the vector\n    int8_t max_vals[32];\n    size_t max_indices[32];\n    _mm256_storeu_si256((__m256i*)max_vals, max_vec);\n    _mm256_storeu_si256((__m256i*)max_indices, max_indices_vec);\n\n    for (int j = 0; j < 32; j++) {\n        if (max_vals[j] > max_val) {\n            max_val = max_vals[j];\n            max_index = max_indices[j];\n        }\n    }\n\n    // Process remaining elements\n    for (size_t i = vector_len; i < length; i++) {\n        if (src[i] > max_val) {\n            max_val = src[i];\n            max_index = i;\n        }\n    }\n\n    return max_index;\n}\n```"}
{"task_id": "SimdBench_14_AVX", "completion": "```cpp\nsize_t argmax_simd(const int8_t *src, size_t length) {\n    if (length == 0) return 0;\n\n    size_t max_index = 0;\n    int8_t max_val = src[0];\n\n    // Process 32 elements at a time with AVX2\n    size_t vector_len = length - (length % 32);\n    __m256i max_vec = _mm256_set1_epi8(src[0]);\n    __m256i max_indices_vec = _mm256_setzero_si256();\n\n    for (size_t i = 0; i < vector_len; i += 32) {\n        __m256i current_vec = _mm256_loadu_si256((__m256i*)&src[i]);\n        __m256i indices_vec = _mm256_set_epi8(\n            31, 30, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16,\n            15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 0\n        );\n        indices_vec = _mm256_add_epi8(indices_vec, _mm256_set1_epi8(i));\n\n        __m256i cmp_mask = _mm256_cmpgt_epi8(current_vec, max_vec);\n        max_vec = _mm256_blendv_epi8(max_vec, current_vec, cmp_mask);\n        max_indices_vec = _mm256_blendv_epi8(max_indices_vec, indices_vec, cmp_mask);\n    }\n\n    // Horizontal max\n    int8_t max_vals[32];\n    size_t max_indices[32];\n    _mm256_storeu_si256((__m256i*)max_vals, max_vec);\n    _mm256_storeu_si256((__m256i*)max_indices, max_indices_vec);\n\n    for (int j = 0; j < 32; j++) {\n        if (max_vals[j] > max_val) {\n            max_val = max_vals[j];\n            max_index = max_indices[j];\n        }\n    }\n\n    // Process remaining elements\n    for (size_t i = vector_len; i < length; i++) {\n        if (src[i] > max_val) {\n            max_val = src[i];\n            max_index = i;\n        }\n    }\n\n    return max_index;\n}\n```"}
{"task_id": "SimdBench_15_AVX", "completion": "```cpp\nvoid vector_blend_simd(const uint16_t* src1, const uint16_t* src2, uint32_t mask, uint16_t* dst, size_t length) {\n    size_t i = 0;\n    const size_t vector_width = 16; // AVX2 can process 16 uint16_t elements at once\n    \n    // Process vectors of 16 elements\n    for (; i + vector_width <= length; i += vector_width) {\n        // Load source arrays into AVX2 registers\n        __m256i vec_src1 = _mm256_loadu_si256((__m256i*)&src1[i]);\n        __m256i vec_src2 = _mm256_loadu_si256((__m256i*)&src2[i]);\n        \n        // Create a vector of indices\n        __m256i indices = _mm256_setr_epi16(\n            i, i+1, i+2, i+3, i+4, i+5, i+6, i+7,\n            i+8, i+9, i+10, i+11, i+12, i+13, i+14, i+15\n        );\n        \n        // Compute mask condition for each element\n        __m256i mask_vec = _mm256_set1_epi16(mask);\n        __m256i index_mask = _mm256_and_si256(indices, mask_vec);\n        __m256i zero_vec = _mm256_setzero_si256();\n        __m256i mask_condition = _mm256_cmpgt_epi16(index_mask, zero_vec);\n        \n        // Blend elements based on mask condition\n        __m256i blended_vec = _mm256_blendv_epi8(vec_src2, vec_src1, mask_condition);\n        \n        // Store result in destination array\n        _mm256_storeu_si256((__m256i*)&dst[i], blended_vec);\n    }\n    \n    // Handle remaining elements\n    for (; i < length; i++) {\n        dst[i] = (i & mask) ? src1[i] : src2[i];\n    }\n}\n```"}
{"task_id": "SimdBench_15_AVX", "completion": "```cpp\nvoid vector_blend_simd(const uint16_t* src1, const uint16_t* src2, uint32_t mask, uint16_t* dst, size_t length) {\n    size_t i = 0;\n    const size_t vector_width = 16; // AVX2 can process 16 16-bit integers at once\n    \n    // Process vectors\n    for (; i + vector_width <= length; i += vector_width) {\n        __m256i indices = _mm256_setr_epi16(\n            i, i+1, i+2, i+3, i+4, i+5, i+6, i+7, \n            i+8, i+9, i+10, i+11, i+12, i+13, i+14, i+15\n        );\n        \n        // Compute mask condition for each index\n        __m256i mask_vec = _mm256_set1_epi16(mask);\n        __m256i index_mask = _mm256_and_si256(indices, mask_vec);\n        __m256i non_zero_mask = _mm256_cmpgt_epi16(index_mask, _mm256_setzero_si256());\n        \n        // Load source arrays\n        __m256i src1_vec = _mm256_loadu_si256((__m256i*)&src1[i]);\n        __m256i src2_vec = _mm256_loadu_si256((__m256i*)&src2[i]);\n        \n        // Blend based on mask condition\n        __m256i result = _mm256_blendv_epi8(src2_vec, src1_vec, non_zero_mask);\n        \n        // Store result\n        _mm256_storeu_si256((__m256i*)&dst[i], result);\n    }\n    \n    // Handle remaining elements\n    for (; i < length; i++) {\n        dst[i] = (i & mask) ? src1[i] : src2[i];\n    }\n}\n```"}
{"task_id": "SimdBench_15_AVX", "completion": "```cpp\nvoid vector_blend_simd(const uint16_t* src1, const uint16_t* src2, uint32_t mask, uint16_t* dst, size_t length) {\n    size_t i = 0;\n    const size_t vector_width = 16; // 16 uint16_t elements fit in a 256-bit AVX vector\n    \n    // Process vectors in 16-element chunks\n    for (; i + vector_width <= length; i += vector_width) {\n        // Load source vectors\n        __m256i vec1 = _mm256_loadu_si256((__m256i*)&src1[i]);\n        __m256i vec2 = _mm256_loadu_si256((__m256i*)&src2[i]);\n        \n        // Create mask vector for blending\n        __m256i index_vec = _mm256_setr_epi16(\n            i, i+1, i+2, i+3, i+4, i+5, i+6, i+7,\n            i+8, i+9, i+10, i+11, i+12, i+13, i+14, i+15\n        );\n        \n        // Compute mask condition\n        __m256i mask_vec = _mm256_set1_epi16(mask);\n        __m256i index_mask = _mm256_and_si256(index_vec, mask_vec);\n        __m256i blend_mask = _mm256_cmpgt_epi16(index_mask, _mm256_setzero_si256());\n        \n        // Blend vectors\n        __m256i result = _mm256_blendv_epi8(vec2, vec1, blend_mask);\n        \n        // Store result\n        _mm256_storeu_si256((__m256i*)&dst[i], result);\n    }\n    \n    // Handle remaining elements\n    for (; i < length; i++) {\n        dst[i] = (i & mask) ? src1[i] : src2[i];\n    }\n}\n```"}
{"task_id": "SimdBench_15_AVX", "completion": "```cpp\nvoid vector_blend_simd(const uint16_t* src1, const uint16_t* src2, uint32_t mask, uint16_t* dst, size_t length) {\n    size_t i = 0;\n    const size_t vector_width = 16; // AVX2 can process 16 uint16_t elements at once\n    \n    // Process vectors of 16 elements\n    for (; i + vector_width <= length; i += vector_width) {\n        // Load source arrays into AVX registers\n        __m256i vec_src1 = _mm256_loadu_si256((__m256i*)&src1[i]);\n        __m256i vec_src2 = _mm256_loadu_si256((__m256i*)&src2[i]);\n        \n        // Create mask vector for index comparison\n        __m256i vec_indices = _mm256_setr_epi16(\n            i, i+1, i+2, i+3, i+4, i+5, i+6, i+7,\n            i+8, i+9, i+10, i+11, i+12, i+13, i+14, i+15\n        );\n        \n        // Compute mask condition\n        __m256i vec_mask = _mm256_set1_epi16(mask);\n        __m256i vec_index_mask = _mm256_and_si256(vec_indices, vec_mask);\n        __m256i vec_condition = _mm256_cmpeq_epi16(vec_index_mask, _mm256_setzero_si256());\n        \n        // Blend vectors based on condition\n        __m256i vec_result = _mm256_blendv_epi8(vec_src1, vec_src2, vec_condition);\n        \n        // Store result in destination array\n        _mm256_storeu_si256((__m256i*)&dst[i], vec_result);\n    }\n    \n    // Handle remaining elements\n    for (; i < length; i++) {\n        dst[i] = (i & mask) ? src1[i] : src2[i];\n    }\n}\n```"}
{"task_id": "SimdBench_15_AVX", "completion": "```cpp\nvoid vector_blend_simd(const uint16_t* src1, const uint16_t* src2, uint32_t mask, uint16_t* dst, size_t length) {\n    size_t i = 0;\n    const size_t vector_width = 16; // AVX2 can process 16 uint16_t elements at once\n    \n    // Process vector-sized chunks\n    for (; i + vector_width <= length; i += vector_width) {\n        // Load source arrays into AVX registers\n        __m256i vec_src1 = _mm256_loadu_si256((__m256i*)&src1[i]);\n        __m256i vec_src2 = _mm256_loadu_si256((__m256i*)&src2[i]);\n        \n        // Create mask vector for blending\n        __m256i mask_vec = _mm256_set1_epi32(mask);\n        \n        // Create index vector\n        __m256i index_vec = _mm256_setr_epi16(\n            i, i+1, i+2, i+3, i+4, i+5, i+6, i+7,\n            i+8, i+9, i+10, i+11, i+12, i+13, i+14, i+15\n        );\n        \n        // Compute index & mask\n        __m256i index_mask = _mm256_and_si256(index_vec, mask_vec);\n        \n        // Create blend mask: non-zero becomes 0xFFFF, zero becomes 0x0000\n        __m256i blend_mask = _mm256_cmpgt_epi16(index_mask, _mm256_setzero_si256());\n        \n        // Blend using mask\n        __m256i result = _mm256_blendv_epi8(vec_src2, vec_src1, blend_mask);\n        \n        // Store result\n        _mm256_storeu_si256((__m256i*)&dst[i], result);\n    }\n    \n    // Handle remaining elements\n    for (; i < length; i++) {\n        dst[i] = (i & mask) ? src1[i] : src2[i];\n    }\n}\n```"}
{"task_id": "SimdBench_16_AVX", "completion": "```cpp\nvoid population_count_simd(const uint32_t* src, uint32_t* dst, size_t length) {\n    size_t i = 0;\n    for (; i + 8 <= length; i += 8) {\n        __m256i input = _mm256_loadu_si256((__m256i*)&src[i]);\n        \n        // Compute population count using AVX2 intrinsics\n        __m256i m1 = _mm256_srli_epi32(input, 1);\n        __m256i m2 = _mm256_srli_epi32(input, 2);\n        __m256i m3 = _mm256_srli_epi32(input, 3);\n        \n        input = _mm256_sub_epi32(input, m1);\n        input = _mm256_sub_epi32(input, m2);\n        input = _mm256_sub_epi32(input, m3);\n        \n        input = _mm256_and_si256(input, _mm256_set1_epi32(0x0F0F0F0F));\n        m1 = _mm256_srli_epi32(input, 4);\n        input = _mm256_add_epi32(input, m1);\n        \n        input = _mm256_and_si256(input, _mm256_set1_epi32(0x00FF00FF));\n        m1 = _mm256_srli_epi32(input, 8);\n        input = _mm256_add_epi32(input, m1);\n        \n        input = _mm256_and_si256(input, _mm256_set1_epi32(0x0000FFFF));\n        m1 = _mm256_srli_epi32(input, 16);\n        input = _mm256_add_epi32(input, m1);\n        \n        _mm256_storeu_si256((__m256i*)&dst[i], input);\n    }\n    \n    // Handle remaining elements\n    for (; i < length; i++) {\n        uint32_t x = src[i];\n        x = x - ((x >> 1) & 0x55555555);\n        x = (x & 0x33333333) + ((x >> 2) & 0x33333333);\n        x = (x + (x >> 4)) & 0x0F0F0F0F;\n        x = x + (x >> 8);\n        x = x + (x >> 16);\n        dst[i] = x & 0x3F;\n    }\n}\n```"}
{"task_id": "SimdBench_16_AVX", "completion": "```cpp\nvoid population_count_simd(const uint32_t* src, uint32_t* dst, size_t length) {\n    size_t i = 0;\n    \n    // Process 8 elements at a time using AVX2\n    for (; i + 8 <= length; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&src[i]);\n        \n        // Compute population count using AVX2 intrinsics\n        __m256i m1 = _mm256_srli_epi32(vec, 1);\n        __m256i m2 = _mm256_srli_epi32(vec, 2);\n        __m256i m3 = _mm256_srli_epi32(vec, 3);\n        \n        vec = _mm256_sub_epi32(vec, _mm256_and_si256(m1, _mm256_set1_epi32(0x55555555)));\n        vec = _mm256_add_epi32(_mm256_and_si256(vec, _mm256_set1_epi32(0x33333333)), \n                                _mm256_and_si256(m2, _mm256_set1_epi32(0x33333333)));\n        \n        vec = _mm256_add_epi32(vec, m3);\n        vec = _mm256_and_si256(vec, _mm256_set1_epi32(0x0F0F0F0F));\n        vec = _mm256_add_epi32(vec, _mm256_srli_epi32(vec, 4));\n        vec = _mm256_and_si256(vec, _mm256_set1_epi32(0x0F0F0F0F));\n        vec = _mm256_mullo_epi32(vec, _mm256_set1_epi32(0x01010101));\n        vec = _mm256_srli_epi32(vec, 24);\n        \n        _mm256_storeu_si256((__m256i*)&dst[i], vec);\n    }\n    \n    // Handle remaining elements\n    for (; i < length; i++) {\n        uint32_t x = src[i];\n        x = x - ((x >> 1) & 0x55555555);\n        x = (x & 0x33333333) + ((x >> 2) & 0x33333333);\n        x = (x + (x >> 4)) & 0x0F0F0F0F;\n        x = x * 0x01010101;\n        dst[i] = x >> 24;\n    }\n}\n```"}
{"task_id": "SimdBench_16_AVX", "completion": "```cpp\nvoid population_count_simd(const uint32_t* src, uint32_t* dst, size_t length) {\n    size_t i = 0;\n    \n    // Process 8 elements at a time using AVX2\n    for (; i + 8 <= length; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&src[i]);\n        \n        // Compute population count using AVX2 intrinsics\n        __m256i m1 = _mm256_srli_epi32(vec, 1);\n        __m256i m2 = _mm256_srli_epi32(vec, 2);\n        __m256i m3 = _mm256_srli_epi32(vec, 3);\n        \n        vec = _mm256_sub_epi32(vec, _mm256_and_si256(m1, _mm256_set1_epi32(0x55555555)));\n        vec = _mm256_add_epi32(_mm256_and_si256(vec, _mm256_set1_epi32(0x33333333)), \n                                _mm256_and_si256(m2, _mm256_set1_epi32(0x33333333)));\n        \n        vec = _mm256_add_epi32(vec, _mm256_srli_epi32(vec, 4));\n        vec = _mm256_and_si256(vec, _mm256_set1_epi32(0x0F0F0F0F));\n        vec = _mm256_mullo_epi32(vec, _mm256_set1_epi32(0x01010101));\n        vec = _mm256_srli_epi32(vec, 24);\n        \n        _mm256_storeu_si256((__m256i*)&dst[i], vec);\n    }\n    \n    // Handle remaining elements\n    for (; i < length; i++) {\n        uint32_t x = src[i];\n        x = x - ((x >> 1) & 0x55555555);\n        x = (x & 0x33333333) + ((x >> 2) & 0x33333333);\n        x = (x + (x >> 4)) & 0x0F0F0F0F;\n        x = x * 0x01010101;\n        dst[i] = x >> 24;\n    }\n}\n```"}
{"task_id": "SimdBench_16_AVX", "completion": "```cpp\nvoid population_count_simd(const uint32_t* src, uint32_t* dst, size_t length) {\n    size_t i = 0;\n    for (; i + 8 <= length; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&src[i]);\n        \n        // Compute population count for each 32-bit integer in the vector\n        __m256i popcount = _mm256_setzero_si256();\n        \n        // Bit manipulation to count 1 bits\n        for (int j = 0; j < 32; j++) {\n            __m256i shifted = _mm256_srli_epi32(vec, j);\n            __m256i masked = _mm256_and_si256(shifted, _mm256_set1_epi32(1));\n            popcount = _mm256_add_epi32(popcount, masked);\n        }\n        \n        _mm256_storeu_si256((__m256i*)&dst[i], popcount);\n    }\n    \n    // Handle remaining elements\n    for (; i < length; i++) {\n        uint32_t x = src[i];\n        dst[i] = __builtin_popcount(x);\n    }\n}\n```"}
{"task_id": "SimdBench_16_AVX", "completion": "```cpp\nvoid population_count_simd(const uint32_t* src, uint32_t* dst, size_t length) {\n    size_t i = 0;\n    \n    // Process 8 elements at a time using AVX2\n    for (; i + 8 <= length; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&src[i]);\n        \n        // Compute population count for each 32-bit integer in the vector\n        __m256i popcount = _mm256_setzero_si256();\n        \n        // Bit manipulation method for population count\n        for (int j = 0; j < 32; j++) {\n            __m256i shifted = _mm256_srli_epi32(vec, j);\n            __m256i masked = _mm256_and_si256(shifted, _mm256_set1_epi32(1));\n            popcount = _mm256_add_epi32(popcount, masked);\n        }\n        \n        // Store results in destination array\n        _mm256_storeu_si256((__m256i*)&dst[i], popcount);\n    }\n    \n    // Handle remaining elements\n    for (; i < length; i++) {\n        uint32_t x = src[i];\n        dst[i] = __builtin_popcount(x);\n    }\n}\n```"}
{"task_id": "SimdBench_17_AVX", "completion": "```cpp\nvoid saturating_add_simd(const uint16_t* src1, const uint16_t* src2, uint16_t* dst, size_t length) {\n    size_t i = 0;\n    \n    // Process 16 elements at a time using AVX2 256-bit registers\n    for (; i + 16 <= length; i += 16) {\n        __m256i vec1 = _mm256_loadu_si256((__m256i*)&src1[i]);\n        __m256i vec2 = _mm256_loadu_si256((__m256i*)&src2[i]);\n        \n        // Perform saturating addition using AVX2 intrinsics\n        __m256i result = _mm256_adds_epu16(vec1, vec2);\n        \n        _mm256_storeu_si256((__m256i*)&dst[i], result);\n    }\n    \n    // Handle remaining elements\n    for (; i < length; i++) {\n        uint32_t sum = (uint32_t)src1[i] + src2[i];\n        dst[i] = (sum > UINT16_MAX) ? UINT16_MAX : sum;\n    }\n}\n```"}
{"task_id": "SimdBench_17_AVX", "completion": "```cpp\nvoid saturating_add_simd(const uint16_t* src1, const uint16_t* src2, uint16_t* dst, size_t length) {\n    size_t i = 0;\n    \n    // Process 16 elements at a time using AVX2 256-bit registers\n    for (; i + 16 <= length; i += 16) {\n        __m256i vec1 = _mm256_loadu_si256((__m256i*)&src1[i]);\n        __m256i vec2 = _mm256_loadu_si256((__m256i*)&src2[i]);\n        \n        // Perform saturating addition using AVX2 intrinsics\n        __m256i result = _mm256_adds_epu16(vec1, vec2);\n        \n        _mm256_storeu_si256((__m256i*)&dst[i], result);\n    }\n    \n    // Handle remaining elements\n    for (; i < length; i++) {\n        uint32_t sum = (uint32_t)src1[i] + src2[i];\n        dst[i] = (sum > UINT16_MAX) ? UINT16_MAX : sum;\n    }\n}\n```"}
{"task_id": "SimdBench_17_AVX", "completion": "```cpp\nvoid saturating_add_simd(const uint16_t* src1, const uint16_t* src2, uint16_t* dst, size_t length) {\n    size_t i = 0;\n    \n    // Process 16 elements at a time using AVX2 256-bit registers\n    for (; i + 16 <= length; i += 16) {\n        __m256i vec1 = _mm256_loadu_si256((__m256i*)&src1[i]);\n        __m256i vec2 = _mm256_loadu_si256((__m256i*)&src2[i]);\n        \n        // Perform saturating addition using AVX2 intrinsics\n        __m256i result = _mm256_adds_epu16(vec1, vec2);\n        \n        _mm256_storeu_si256((__m256i*)&dst[i], result);\n    }\n    \n    // Handle remaining elements\n    for (; i < length; i++) {\n        uint32_t sum = (uint32_t)src1[i] + src2[i];\n        dst[i] = (sum > UINT16_MAX) ? UINT16_MAX : sum;\n    }\n}\n```"}
{"task_id": "SimdBench_17_AVX", "completion": "```cpp\nvoid saturating_add_simd(const uint16_t* src1, const uint16_t* src2, uint16_t* dst, size_t length) {\n    size_t i = 0;\n    \n    // Process 16 elements at a time using AVX2 256-bit registers\n    for (; i + 16 <= length; i += 16) {\n        __m256i vec1 = _mm256_loadu_si256((__m256i*)&src1[i]);\n        __m256i vec2 = _mm256_loadu_si256((__m256i*)&src2[i]);\n        \n        // Perform saturating addition using unsigned 16-bit integer arithmetic\n        __m256i result = _mm256_adds_epu16(vec1, vec2);\n        \n        _mm256_storeu_si256((__m256i*)&dst[i], result);\n    }\n    \n    // Handle remaining elements\n    for (; i < length; i++) {\n        uint32_t sum = (uint32_t)src1[i] + src2[i];\n        dst[i] = (sum > UINT16_MAX) ? UINT16_MAX : sum;\n    }\n}\n```"}
{"task_id": "SimdBench_17_AVX", "completion": "```cpp\nvoid saturating_add_simd(const uint16_t* src1, const uint16_t* src2, uint16_t* dst, size_t length) {\n    size_t i = 0;\n    \n    // Process 16 elements at a time using AVX2 256-bit registers\n    for (; i + 16 <= length; i += 16) {\n        __m256i vec1 = _mm256_loadu_si256((__m256i*)&src1[i]);\n        __m256i vec2 = _mm256_loadu_si256((__m256i*)&src2[i]);\n        \n        // Perform saturating addition using AVX2 intrinsics\n        __m256i result = _mm256_adds_epu16(vec1, vec2);\n        \n        _mm256_storeu_si256((__m256i*)&dst[i], result);\n    }\n    \n    // Handle remaining elements\n    for (; i < length; i++) {\n        uint32_t sum = (uint32_t)src1[i] + src2[i];\n        dst[i] = (sum > UINT16_MAX) ? UINT16_MAX : sum;\n    }\n}\n```"}
{"task_id": "SimdBench_18_AVX", "completion": "```cpp\nvoid range_matrix_mul_simd(const double* A, const double* B, double* C, size_t m, size_t n, size_t p) {\n    for (size_t i = 0; i < m; i++) {\n        for (size_t j = 0; j < p; j++) {\n            __m256d sum_vec = _mm256_setzero_pd();\n            \n            size_t k = 0;\n            for (; k + 4 <= n; k += 4) {\n                __m256d a_vec = _mm256_loadu_pd(&A[i * n + k]);\n                __m256d b_vec = _mm256_loadu_pd(&B[k * p + j]);\n                \n                // Check range condition\n                __m256d mask_a = _mm256_and_pd(\n                    _mm256_cmp_pd(a_vec, _mm256_set1_pd(-100.0), _mm256_CMP_GE_OQ),\n                    _mm256_cmp_pd(a_vec, _mm256_set1_pd(100.0), _mm256_CMP_LE_OQ)\n                );\n                \n                __m256d mask_b = _mm256_and_pd(\n                    _mm256_cmp_pd(b_vec, _mm256_set1_pd(-100.0), _mm256_CMP_GE_OQ),\n                    _mm256_cmp_pd(b_vec, _mm256_set1_pd(100.0), _mm256_CMP_LE_OQ)\n                );\n                \n                __m256d masked_a = _mm256_and_pd(a_vec, mask_a);\n                __m256d masked_b = _mm256_and_pd(b_vec, mask_b);\n                \n                sum_vec = _mm256_add_pd(sum_vec, _mm256_mul_pd(masked_a, masked_b));\n            }\n            \n            // Horizontal sum\n            __m128d sum_low = _mm256_extractf128_pd(sum_vec, 0);\n            __m128d sum_high = _mm256_extractf128_pd(sum_vec, 1);\n            sum_low = _mm_add_pd(sum_low, sum_high);\n            sum_low = _mm_hadd_pd(sum_low, sum_low);\n            \n            double sum = _mm_cvtsd_f64(sum_low);\n            \n            // Handle remaining elements\n            for (; k < n; k++) {\n                double a_val = A[i * n + k];\n                double b_val = B[k * p + j];\n                \n                if (a_val >= -100.0 && a_val <= 100.0 && \n                    b_val >= -100.0 && b_val <= 100.0) {\n                    sum += a_val * b_val;\n                }\n            }\n            \n            C[i * p + j] = sum;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_18_AVX", "completion": "```cpp\nvoid range_matrix_mul_simd(const double* A, const double* B, double* C, size_t m, size_t n, size_t p) {\n    for (size_t i = 0; i < m; i++) {\n        for (size_t j = 0; j < p; j++) {\n            __m256d sum_vec = _mm256_setzero_pd();\n            \n            size_t k = 0;\n            for (; k + 4 <= n; k += 4) {\n                __m256d a_vec = _mm256_loadu_pd(&A[i * n + k]);\n                __m256d b_vec = _mm256_loadu_pd(&B[k * p + j]);\n                \n                // Check range condition\n                __m256d mask_a = _mm256_and_pd(\n                    _mm256_cmp_pd(a_vec, _mm256_set1_pd(-100.0), _mm256_CMP_GE_OQ),\n                    _mm256_cmp_pd(a_vec, _mm256_set1_pd(100.0), _mm256_CMP_LE_OQ)\n                );\n                \n                __m256d mask_b = _mm256_and_pd(\n                    _mm256_cmp_pd(b_vec, _mm256_set1_pd(-100.0), _mm256_CMP_GE_OQ),\n                    _mm256_cmp_pd(b_vec, _mm256_set1_pd(100.0), _mm256_CMP_LE_OQ)\n                );\n                \n                __m256d masked_a = _mm256_and_pd(a_vec, mask_a);\n                __m256d masked_b = _mm256_and_pd(b_vec, mask_b);\n                \n                sum_vec = _mm256_add_pd(sum_vec, _mm256_mul_pd(masked_a, masked_b));\n            }\n            \n            // Horizontal sum\n            __m128d sum_low = _mm256_extractf128_pd(sum_vec, 0);\n            __m128d sum_high = _mm256_extractf128_pd(sum_vec, 1);\n            sum_low = _mm_add_pd(sum_low, sum_high);\n            sum_low = _mm_hadd_pd(sum_low, sum_low);\n            \n            double sum = _mm_cvtsd_f64(sum_low);\n            \n            // Handle remaining elements\n            for (; k < n; k++) {\n                double a_val = A[i * n + k];\n                double b_val = B[k * p + j];\n                \n                if (a_val >= -100.0 && a_val <= 100.0 && \n                    b_val >= -100.0 && b_val <= 100.0) {\n                    sum += a_val * b_val;\n                }\n            }\n            \n            C[i * p + j] = sum;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_18_AVX", "completion": "```cpp\nvoid range_matrix_mul_simd(const double* A, const double* B, double* C, size_t m, size_t n, size_t p) {\n    for (size_t i = 0; i < m; i++) {\n        for (size_t j = 0; j < p; j++) {\n            __m256d sum_vec = _mm256_setzero_pd();\n            \n            size_t k = 0;\n            for (; k + 4 <= n; k += 4) {\n                __m256d a_vec = _mm256_loadu_pd(&A[i * n + k]);\n                __m256d b_vec = _mm256_loadu_pd(&B[k * p + j]);\n                \n                // Check range condition\n                __m256d mask_a = _mm256_and_pd(\n                    _mm256_cmp_pd(a_vec, _mm256_set1_pd(-100.0), _mm256_CMP_GE_OQ),\n                    _mm256_cmp_pd(a_vec, _mm256_set1_pd(100.0), _mm256_CMP_LE_OQ)\n                );\n                \n                __m256d mask_b = _mm256_and_pd(\n                    _mm256_cmp_pd(b_vec, _mm256_set1_pd(-100.0), _mm256_CMP_GE_OQ),\n                    _mm256_cmp_pd(b_vec, _mm256_set1_pd(100.0), _mm256_CMP_LE_OQ)\n                );\n                \n                __m256d masked_a = _mm256_and_pd(a_vec, mask_a);\n                __m256d masked_b = _mm256_and_pd(b_vec, mask_b);\n                \n                sum_vec = _mm256_add_pd(sum_vec, _mm256_mul_pd(masked_a, masked_b));\n            }\n            \n            // Horizontal sum\n            __m128d sum_low = _mm256_extractf128_pd(sum_vec, 0);\n            __m128d sum_high = _mm256_extractf128_pd(sum_vec, 1);\n            sum_low = _mm_add_pd(sum_low, sum_high);\n            sum_low = _mm_hadd_pd(sum_low, sum_low);\n            \n            double sum = _mm_cvtsd_f64(sum_low);\n            \n            // Handle remaining elements\n            for (; k < n; k++) {\n                double a_val = A[i * n + k];\n                double b_val = B[k * p + j];\n                \n                if (a_val >= -100.0 && a_val <= 100.0 && \n                    b_val >= -100.0 && b_val <= 100.0) {\n                    sum += a_val * b_val;\n                }\n            }\n            \n            C[i * p + j] = sum;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_18_AVX", "completion": "```cpp\nvoid range_matrix_mul_simd(const double* A, const double* B, double* C, size_t m, size_t n, size_t p) {\n    for (size_t i = 0; i < m; i++) {\n        for (size_t j = 0; j < p; j++) {\n            __m256d sum_vec = _mm256_setzero_pd();\n            \n            size_t k = 0;\n            for (; k + 4 <= n; k += 4) {\n                __m256d a_vec = _mm256_loadu_pd(&A[i * n + k]);\n                __m256d b_vec = _mm256_loadu_pd(&B[k * p + j]);\n                \n                // Check range condition\n                __m256d mask_a = _mm256_and_pd(\n                    _mm256_cmp_pd(a_vec, _mm256_set1_pd(-100.0), _mm256_CMP_GE_OQ),\n                    _mm256_cmp_pd(a_vec, _mm256_set1_pd(100.0), _mm256_CMP_LE_OQ)\n                );\n                \n                __m256d mask_b = _mm256_and_pd(\n                    _mm256_cmp_pd(b_vec, _mm256_set1_pd(-100.0), _mm256_CMP_GE_OQ),\n                    _mm256_cmp_pd(b_vec, _mm256_set1_pd(100.0), _mm256_CMP_LE_OQ)\n                );\n                \n                __m256d masked_a = _mm256_and_pd(a_vec, mask_a);\n                __m256d masked_b = _mm256_and_pd(b_vec, mask_b);\n                \n                sum_vec = _mm256_add_pd(sum_vec, _mm256_mul_pd(masked_a, masked_b));\n            }\n            \n            // Horizontal sum\n            __m128d sum_low = _mm256_extractf128_pd(sum_vec, 0);\n            __m128d sum_high = _mm256_extractf128_pd(sum_vec, 1);\n            sum_low = _mm_add_pd(sum_low, sum_high);\n            sum_low = _mm_hadd_pd(sum_low, sum_low);\n            \n            double sum = _mm_cvtsd_f64(sum_low);\n            \n            // Handle remaining elements\n            for (; k < n; k++) {\n                double a_val = A[i * n + k];\n                double b_val = B[k * p + j];\n                \n                if (a_val >= -100.0 && a_val <= 100.0 && \n                    b_val >= -100.0 && b_val <= 100.0) {\n                    sum += a_val * b_val;\n                }\n            }\n            \n            C[i * p + j] = sum;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_18_AVX", "completion": "```cpp\nvoid range_matrix_mul_simd(const double* A, const double* B, double* C, size_t m, size_t n, size_t p) {\n    for (size_t i = 0; i < m; i++) {\n        for (size_t j = 0; j < p; j++) {\n            __m256d sum_vec = _mm256_setzero_pd();\n            \n            size_t k = 0;\n            for (; k + 4 <= n; k += 4) {\n                __m256d a_vec = _mm256_loadu_pd(&A[i * n + k]);\n                __m256d b_vec = _mm256_loadu_pd(&B[k * p + j]);\n                \n                // Check range condition\n                __m256d mask_a = _mm256_and_pd(\n                    _mm256_cmp_pd(a_vec, _mm256_set1_pd(-100.0), _mm256_CMP_GE_OQ),\n                    _mm256_cmp_pd(a_vec, _mm256_set1_pd(100.0), _mm256_CMP_LE_OQ)\n                );\n                \n                __m256d mask_b = _mm256_and_pd(\n                    _mm256_cmp_pd(b_vec, _mm256_set1_pd(-100.0), _mm256_CMP_GE_OQ),\n                    _mm256_cmp_pd(b_vec, _mm256_set1_pd(100.0), _mm256_CMP_LE_OQ)\n                );\n                \n                // Combine masks and multiply\n                __m256d masked_mul = _mm256_and_pd(\n                    _mm256_mul_pd(a_vec, b_vec),\n                    _mm256_and_pd(mask_a, mask_b)\n                );\n                \n                sum_vec = _mm256_add_pd(sum_vec, masked_mul);\n            }\n            \n            // Horizontal sum\n            __m128d sum_low = _mm256_extractf128_pd(sum_vec, 0);\n            __m128d sum_high = _mm256_extractf128_pd(sum_vec, 1);\n            sum_low = _mm_add_pd(sum_low, sum_high);\n            sum_low = _mm_hadd_pd(sum_low, sum_low);\n            \n            double sum = _mm_cvtsd_f64(sum_low);\n            \n            // Handle remaining elements\n            for (; k < n; k++) {\n                double a_val = A[i * n + k];\n                double b_val = B[k * p + j];\n                \n                if (a_val >= -100.0 && a_val <= 100.0 && \n                    b_val >= -100.0 && b_val <= 100.0) {\n                    sum += a_val * b_val;\n                }\n            }\n            \n            C[i * p + j] = sum;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_19_AVX", "completion": "```cpp\nvoid tensor_add_3d_simd(const int64_t* A, const int64_t* B, int64_t* C, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t vector_size = sizeof(__m256i) / sizeof(int64_t);\n    size_t vectorized_length = total_elements - (total_elements % vector_size);\n\n    for (size_t i = 0; i < vectorized_length; i += vector_size) {\n        __m256i a_vec = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i b_vec = _mm256_loadu_si256((__m256i*)&B[i]);\n        __m256i c_vec = _mm256_add_epi64(a_vec, b_vec);\n        _mm256_storeu_si256((__m256i*)&C[i], c_vec);\n    }\n\n    // Handle remaining elements\n    for (size_t i = vectorized_length; i < total_elements; ++i) {\n        C[i] = A[i] + B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_19_AVX", "completion": "```cpp\nvoid tensor_add_3d_simd(const int64_t* A, const int64_t* B, int64_t* C, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t vector_size = sizeof(__m256i) / sizeof(int64_t);\n    size_t vectorized_length = total_elements - (total_elements % vector_size);\n\n    for (size_t i = 0; i < vectorized_length; i += vector_size) {\n        __m256i va = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i vb = _mm256_loadu_si256((__m256i*)&B[i]);\n        __m256i vc = _mm256_add_epi64(va, vb);\n        _mm256_storeu_si256((__m256i*)&C[i], vc);\n    }\n\n    // Handle remaining elements\n    for (size_t i = vectorized_length; i < total_elements; ++i) {\n        C[i] = A[i] + B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_19_AVX", "completion": "```cpp\nvoid tensor_add_3d_simd(const int64_t* A, const int64_t* B, int64_t* C, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t vector_size = sizeof(__m256i) / sizeof(int64_t);\n    size_t vectorized_elements = (total_elements / vector_size) * vector_size;\n\n    for (size_t i = 0; i < vectorized_elements; i += vector_size) {\n        __m256i va = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i vb = _mm256_loadu_si256((__m256i*)&B[i]);\n        __m256i vc = _mm256_add_epi64(va, vb);\n        _mm256_storeu_si256((__m256i*)&C[i], vc);\n    }\n\n    // Handle remaining elements\n    for (size_t i = vectorized_elements; i < total_elements; ++i) {\n        C[i] = A[i] + B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_19_AVX", "completion": "```cpp\nvoid tensor_add_3d_simd(const int64_t* A, const int64_t* B, int64_t* C, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t vector_size = sizeof(__m256i) / sizeof(int64_t);\n    size_t simd_length = total_elements - (total_elements % vector_size);\n\n    for (size_t i = 0; i < simd_length; i += vector_size) {\n        __m256i vec_a = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i vec_b = _mm256_loadu_si256((__m256i*)&B[i]);\n        __m256i vec_c = _mm256_add_epi64(vec_a, vec_b);\n        _mm256_storeu_si256((__m256i*)&C[i], vec_c);\n    }\n\n    // Handle remaining elements\n    for (size_t i = simd_length; i < total_elements; ++i) {\n        C[i] = A[i] + B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_19_AVX", "completion": "```cpp\nvoid tensor_add_3d_simd(const int64_t* A, const int64_t* B, int64_t* C, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t vector_size = sizeof(__m256i) / sizeof(int64_t);\n    size_t vectorized_length = total_elements - (total_elements % vector_size);\n\n    for (size_t i = 0; i < vectorized_length; i += vector_size) {\n        __m256i va = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i vb = _mm256_loadu_si256((__m256i*)&B[i]);\n        __m256i vc = _mm256_add_epi64(va, vb);\n        _mm256_storeu_si256((__m256i*)&C[i], vc);\n    }\n\n    // Handle remaining elements\n    for (size_t i = vectorized_length; i < total_elements; ++i) {\n        C[i] = A[i] + B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_20_AVX", "completion": "```cpp\nvoid vector_add_round_nearest_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    size_t i = 0;\n    \n    // Process 8 elements at a time using AVX\n    for (; i + 8 <= length; i += 8) {\n        __m256 vec1 = _mm256_loadu_ps(src1 + i);\n        __m256 vec2 = _mm256_loadu_ps(src2 + i);\n        \n        // Add the two vectors\n        __m256 sum_vec = _mm256_add_ps(vec1, vec2);\n        \n        // Round to nearest integer\n        __m256 rounded_vec = _mm256_round_ps(sum_vec, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n        \n        // Store the result\n        _mm256_storeu_ps(dst + i, rounded_vec);\n    }\n    \n    // Handle remaining elements\n    for (; i < length; i++) {\n        dst[i] = roundf(src1[i] + src2[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_20_AVX", "completion": "```cpp\nvoid vector_add_round_nearest_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    size_t i = 0;\n    for (; i + 8 <= length; i += 8) {\n        __m256 a = _mm256_loadu_ps(src1 + i);\n        __m256 b = _mm256_loadu_ps(src2 + i);\n        __m256 sum = _mm256_add_ps(a, b);\n        __m256 rounded = _mm256_round_ps(sum, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n        _mm256_storeu_ps(dst + i, rounded);\n    }\n\n    // Handle remaining elements\n    for (; i < length; i++) {\n        dst[i] = roundf(src1[i] + src2[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_20_AVX", "completion": "```cpp\nvoid vector_add_round_nearest_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    size_t i = 0;\n    \n    // Process 8 elements at a time using AVX\n    for (; i + 8 <= length; i += 8) {\n        __m256 vec1 = _mm256_loadu_ps(src1 + i);\n        __m256 vec2 = _mm256_loadu_ps(src2 + i);\n        \n        // Add the two vectors\n        __m256 sum = _mm256_add_ps(vec1, vec2);\n        \n        // Round to nearest integer\n        __m256 rounded = _mm256_round_ps(sum, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n        \n        // Store the result\n        _mm256_storeu_ps(dst + i, rounded);\n    }\n    \n    // Handle remaining elements\n    for (; i < length; i++) {\n        dst[i] = roundf(src1[i] + src2[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_20_AVX", "completion": "```cpp\nvoid vector_add_round_nearest_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    size_t i = 0;\n    \n    // Process 8 elements at a time using AVX\n    for (; i + 8 <= length; i += 8) {\n        __m256 vec1 = _mm256_loadu_ps(src1 + i);\n        __m256 vec2 = _mm256_loadu_ps(src2 + i);\n        \n        // Add the two vectors\n        __m256 sum_vec = _mm256_add_ps(vec1, vec2);\n        \n        // Round to nearest integer\n        __m256 rounded_vec = _mm256_round_ps(sum_vec, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n        \n        // Store the result\n        _mm256_storeu_ps(dst + i, rounded_vec);\n    }\n    \n    // Handle remaining elements\n    for (; i < length; i++) {\n        dst[i] = roundf(src1[i] + src2[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_20_AVX", "completion": "```cpp\nvoid vector_add_round_nearest_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    size_t i = 0;\n    \n    // Process 8 elements at a time using AVX\n    for (; i + 8 <= length; i += 8) {\n        __m256 vec1 = _mm256_loadu_ps(src1 + i);\n        __m256 vec2 = _mm256_loadu_ps(src2 + i);\n        \n        // Add the two vectors\n        __m256 sum = _mm256_add_ps(vec1, vec2);\n        \n        // Round to nearest integer\n        __m256 rounded = _mm256_round_ps(sum, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n        \n        // Store the result\n        _mm256_storeu_ps(dst + i, rounded);\n    }\n    \n    // Handle remaining elements\n    for (; i < length; i++) {\n        dst[i] = roundf(src1[i] + src2[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_21_AVX", "completion": "```cpp\nvoid vector_mul_round_up_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    const __m256 threshold = _mm256_set1_ps(50.0f);\n    const __m256 neg_one = _mm256_set1_ps(-1.0f);\n\n    for (size_t i = 0; i < length; i += 8) {\n        __m256 vec1 = _mm256_loadu_ps(src1 + i);\n        __m256 vec2 = _mm256_loadu_ps(src2 + i);\n        \n        // Calculate absolute difference\n        __m256 diff = _mm256_sub_ps(vec1, vec2);\n        __m256 abs_diff = _mm256_andnot_ps(_mm256_set1_ps(-0.0f), diff);\n        \n        // Check conditions\n        __m256 within_threshold = _mm256_cmp_ps(abs_diff, threshold, _CMP_LT_OQ);\n        __m256 index_multiple = _mm256_cmp_ps(_mm256_set1_ps(i), _mm256_set1_ps(0.0f), _CMP_EQ_OQ);\n        \n        // Multiply and round up\n        __m256 mul_result = _mm256_mul_ps(vec1, vec2);\n        __m256 rounded_result = _mm256_ceil_ps(mul_result);\n        \n        // Combine conditions and results\n        __m256 mask = _mm256_and_ps(within_threshold, index_multiple);\n        __m256 final_result = _mm256_blendv_ps(neg_one, rounded_result, mask);\n        \n        _mm256_storeu_ps(dst + i, final_result);\n    }\n}\n```"}
{"task_id": "SimdBench_21_AVX", "completion": "```cpp\nvoid vector_mul_round_up_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    const __m256 fifty = _mm256_set1_ps(50.0f);\n    const __m256 neg_one = _mm256_set1_ps(-1.0f);\n\n    for (size_t i = 0; i < length; i += 8) {\n        __m256 vec1 = _mm256_loadu_ps(src1 + i);\n        __m256 vec2 = _mm256_loadu_ps(src2 + i);\n        \n        __m256 diff = _mm256_sub_ps(vec1, vec2);\n        __m256 abs_diff = _mm256_andnot_ps(_mm256_set1_ps(-0.0f), diff);\n        \n        __m256 mask1 = _mm256_cmp_ps(abs_diff, fifty, _CMP_LT_OQ);\n        __m256 mask2 = _mm256_setzero_ps();\n        \n        for (int j = 0; j < 8; j++) {\n            if ((i + j) % 2 == 0) {\n                mask2 = _mm256_insert_ps(mask2, 0xFFFFFFFF, j);\n            }\n        }\n        \n        __m256 combined_mask = _mm256_and_ps(mask1, mask2);\n        \n        __m256 mul_result = _mm256_mul_ps(vec1, vec2);\n        __m256 rounded_result = _mm256_ceil_ps(mul_result);\n        \n        __m256 final_result = _mm256_blendv_ps(neg_one, rounded_result, combined_mask);\n        \n        _mm256_storeu_ps(dst + i, final_result);\n    }\n}\n```"}
{"task_id": "SimdBench_21_AVX", "completion": "```cpp\nvoid vector_mul_round_up_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    const __m256 threshold = _mm256_set1_ps(50.0f);\n    const __m256 negative_one = _mm256_set1_ps(-1.0f);\n\n    for (size_t i = 0; i < length; i += 8) {\n        // Load 8 elements from src1 and src2\n        __m256 vec1 = _mm256_loadu_ps(src1 + i);\n        __m256 vec2 = _mm256_loadu_ps(src2 + i);\n\n        // Calculate absolute difference\n        __m256 diff = _mm256_sub_ps(vec1, vec2);\n        __m256 abs_diff = _mm256_andnot_ps(_mm256_set1_ps(-0.0f), diff);\n\n        // Create mask for elements within threshold and multiple of 2 index\n        __m256 mask1 = _mm256_cmp_ps(abs_diff, threshold, _CMP_LT_OQ);\n        __m256 mask2 = _mm256_cmp_ps(_mm256_set_ps(\n            (i+7)%2 ? -1 : 1, (i+6)%2 ? -1 : 1, \n            (i+5)%2 ? -1 : 1, (i+4)%2 ? -1 : 1,\n            (i+3)%2 ? -1 : 1, (i+2)%2 ? -1 : 1, \n            (i+1)%2 ? -1 : 1, (i)%2 ? -1 : 1), \n            _mm256_setzero_ps(), _CMP_GT_OQ);\n        \n        __m256 combined_mask = _mm256_and_ps(mask1, mask2);\n\n        // Multiply and round up\n        __m256 mul_result = _mm256_mul_ps(vec1, vec2);\n        __m256 rounded_result = _mm256_ceil_ps(mul_result);\n\n        // Select result based on mask\n        __m256 final_result = _mm256_blendv_ps(negative_one, rounded_result, combined_mask);\n\n        // Store result\n        _mm256_storeu_ps(dst + i, final_result);\n    }\n\n    // Handle remaining elements\n    for (size_t i = (length / 8) * 8; i < length; ++i) {\n        float diff = fabsf(src1[i] - src2[i]);\n        dst[i] = (diff < 50.0f && i % 2 == 0) ? ceilf(src1[i] * src2[i]) : -1.0f;\n    }\n}\n```"}
{"task_id": "SimdBench_21_AVX", "completion": "```cpp\nvoid vector_mul_round_up_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    const __m256 threshold = _mm256_set1_ps(50.0f);\n    const __m256 negative_one = _mm256_set1_ps(-1.0f);\n\n    for (size_t i = 0; i < length; i += 8) {\n        __m256 vec_src1 = _mm256_loadu_ps(src1 + i);\n        __m256 vec_src2 = _mm256_loadu_ps(src2 + i);\n        \n        // Check index multiple of 2\n        __m256 index_mask = _mm256_cmp_ps(_mm256_set_ps(7, 6, 5, 4, 3, 2, 1, 0), \n                                           _mm256_setzero_ps(), _CMP_EQ_OQ);\n        \n        // Compute absolute difference\n        __m256 diff = _mm256_sub_ps(vec_src1, vec_src2);\n        __m256 abs_diff = _mm256_andnot_ps(_mm256_set1_ps(-0.0f), diff);\n        \n        // Threshold comparison mask\n        __m256 threshold_mask = _mm256_cmp_ps(abs_diff, threshold, _CMP_LT_OQ);\n        \n        // Combine masks\n        __m256 combined_mask = _mm256_and_ps(index_mask, threshold_mask);\n        \n        // Multiply and round up\n        __m256 mul_result = _mm256_mul_ps(vec_src1, vec_src2);\n        __m256 rounded_result = _mm256_ceil_ps(mul_result);\n        \n        // Blend results\n        __m256 final_result = _mm256_blendv_ps(negative_one, rounded_result, combined_mask);\n        \n        _mm256_storeu_ps(dst + i, final_result);\n    }\n    \n    // Handle remaining elements\n    for (size_t i = (length / 8) * 8; i < length; ++i) {\n        if (i % 2 == 0 && fabsf(src1[i] - src2[i]) < 50.0f) {\n            dst[i] = ceilf(src1[i] * src2[i]);\n        } else {\n            dst[i] = -1.0f;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_21_AVX", "completion": "```cpp\nvoid vector_mul_round_up_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    const __m256 fifty = _mm256_set1_ps(50.0f);\n    const __m256 neg_one = _mm256_set1_ps(-1.0f);\n\n    for (size_t i = 0; i < length; i += 8) {\n        // Load 8 elements from src1 and src2\n        __m256 vec1 = _mm256_loadu_ps(src1 + i);\n        __m256 vec2 = _mm256_loadu_ps(src2 + i);\n\n        // Calculate absolute difference\n        __m256 diff = _mm256_sub_ps(vec1, vec2);\n        __m256 abs_diff = _mm256_andnot_ps(_mm256_set1_ps(-0.0f), diff);\n\n        // Check conditions: abs diff <= 50 and index multiple of 2\n        __m256 mask1 = _mm256_cmp_ps(abs_diff, fifty, _CMP_LE_OQ);\n        __m256 mask2 = _mm256_set_ps(\n            (i+7) % 2 == 0 ? 0xFFFFFFFF : 0,\n            (i+6) % 2 == 0 ? 0xFFFFFFFF : 0,\n            (i+5) % 2 == 0 ? 0xFFFFFFFF : 0,\n            (i+4) % 2 == 0 ? 0xFFFFFFFF : 0,\n            (i+3) % 2 == 0 ? 0xFFFFFFFF : 0,\n            (i+2) % 2 == 0 ? 0xFFFFFFFF : 0,\n            (i+1) % 2 == 0 ? 0xFFFFFFFF : 0,\n            i % 2 == 0 ? 0xFFFFFFFF : 0\n        );\n\n        // Combine masks\n        __m256 combined_mask = _mm256_and_ps(mask1, mask2);\n\n        // Multiply and round up\n        __m256 mul_result = _mm256_mul_ps(vec1, vec2);\n        __m256 rounded = _mm256_ceil_ps(mul_result);\n\n        // Select result based on mask\n        __m256 result = _mm256_blendv_ps(neg_one, rounded, combined_mask);\n\n        // Store result\n        _mm256_storeu_ps(dst + i, result);\n    }\n\n    // Handle remaining elements\n    for (size_t i = (length / 8) * 8; i < length; ++i) {\n        float diff = fabsf(src1[i] - src2[i]);\n        if (diff <= 50 && i % 2 == 0) {\n            dst[i] = ceilf(src1[i] * src2[i]);\n        } else {\n            dst[i] = -1;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_22_AVX", "completion": "```cpp\nvoid matrix_scalar_mul_simd(const double* mat, double scalar, double* dst, size_t m, size_t n) {\n    // Broadcast scalar to all lanes of AVX vector\n    __m256d scalar_vec = _mm256_set1_pd(scalar);\n\n    // Process 4 doubles at a time using AVX\n    size_t vec_width = 4;\n    size_t vec_processed_cols = (n / vec_width) * vec_width;\n\n    for (size_t i = 0; i < m; i++) {\n        size_t row_offset = i * n;\n\n        // Vectorized multiplication for complete vector-width columns\n        for (size_t j = 0; j < vec_processed_cols; j += vec_width) {\n            __m256d mat_vec = _mm256_loadu_pd(&mat[row_offset + j]);\n            __m256d result_vec = _mm256_mul_pd(mat_vec, scalar_vec);\n            _mm256_storeu_pd(&dst[row_offset + j], result_vec);\n        }\n\n        // Handle remaining columns\n        for (size_t j = vec_processed_cols; j < n; j++) {\n            dst[row_offset + j] = mat[row_offset + j] * scalar;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_22_AVX", "completion": "```cpp\nvoid matrix_scalar_mul_simd(const double* mat, double scalar, double* dst, size_t m, size_t n) {\n    // Broadcast scalar to all lanes of AVX vector\n    __m256d scalar_vec = _mm256_set1_pd(scalar);\n\n    // Process 4 doubles at a time\n    size_t vec_size = n - (n % 4);\n    for (size_t i = 0; i < m; i++) {\n        for (size_t j = 0; j < vec_size; j += 4) {\n            size_t idx = i * n + j;\n            \n            // Load 4 doubles from source matrix\n            __m256d mat_vec = _mm256_loadu_pd(&mat[idx]);\n            \n            // Multiply with scalar vector\n            __m256d result_vec = _mm256_mul_pd(mat_vec, scalar_vec);\n            \n            // Store result in destination matrix\n            _mm256_storeu_pd(&dst[idx], result_vec);\n        }\n        \n        // Handle remaining elements\n        for (size_t j = vec_size; j < n; j++) {\n            dst[i * n + j] = mat[i * n + j] * scalar;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_22_AVX", "completion": "```cpp\nvoid matrix_scalar_mul_simd(const double* mat, double scalar, double* dst, size_t m, size_t n) {\n    // Broadcast scalar to all lanes of AVX vector\n    __m256d scalar_vec = _mm256_set1_pd(scalar);\n\n    // Process 4 doubles at a time using AVX\n    size_t vec_width = 4;\n    size_t vec_processed_cols = n - (n % vec_width);\n\n    for (size_t i = 0; i < m; i++) {\n        size_t row_offset = i * n;\n\n        // Vectorized multiplication for full vector-width columns\n        for (size_t j = 0; j < vec_processed_cols; j += vec_width) {\n            __m256d mat_vec = _mm256_loadu_pd(&mat[row_offset + j]);\n            __m256d result_vec = _mm256_mul_pd(mat_vec, scalar_vec);\n            _mm256_storeu_pd(&dst[row_offset + j], result_vec);\n        }\n\n        // Handle remaining columns\n        for (size_t j = vec_processed_cols; j < n; j++) {\n            dst[row_offset + j] = mat[row_offset + j] * scalar;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_22_AVX", "completion": "```cpp\nvoid matrix_scalar_mul_simd(const double* mat, double scalar, double* dst, size_t m, size_t n) {\n    // Broadcast scalar to all lanes of AVX vector\n    __m256d scalar_vec = _mm256_set1_pd(scalar);\n\n    // Process 4 doubles at a time using AVX\n    size_t vec_size = 4;\n    size_t vec_count = n / vec_size;\n    size_t remainder = n % vec_size;\n\n    for (size_t i = 0; i < m; i++) {\n        size_t row_offset = i * n;\n\n        // Vectorized multiplication for complete vector groups\n        for (size_t j = 0; j < vec_count; j++) {\n            size_t col_offset = j * vec_size;\n            __m256d mat_vec = _mm256_loadu_pd(&mat[row_offset + col_offset]);\n            __m256d result_vec = _mm256_mul_pd(mat_vec, scalar_vec);\n            _mm256_storeu_pd(&dst[row_offset + col_offset], result_vec);\n        }\n\n        // Handle remaining elements\n        for (size_t j = vec_count * vec_size; j < n; j++) {\n            dst[row_offset + j] = mat[row_offset + j] * scalar;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_22_AVX", "completion": "```cpp\nvoid matrix_scalar_mul_simd(const double* mat, double scalar, double* dst, size_t m, size_t n) {\n    // Broadcast scalar to all lanes of AVX vector\n    __m256d scalar_vec = _mm256_set1_pd(scalar);\n\n    // Process 4 doubles at a time using AVX\n    size_t vec_size = 4;\n    size_t vec_cols = n - (n % vec_size);\n\n    for (size_t i = 0; i < m; i++) {\n        size_t j;\n        // Vectorized multiplication for complete vector-width columns\n        for (j = 0; j < vec_cols; j += vec_size) {\n            __m256d mat_vec = _mm256_loadu_pd(&mat[i * n + j]);\n            __m256d result_vec = _mm256_mul_pd(mat_vec, scalar_vec);\n            _mm256_storeu_pd(&dst[i * n + j], result_vec);\n        }\n\n        // Handle remaining columns\n        for (; j < n; j++) {\n            dst[i * n + j] = mat[i * n + j] * scalar;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_23_AVX", "completion": "```cpp\nvoid matrix_normalize_rows_simd(float* mat, size_t m, size_t n) {\n    for (size_t i = 0; i < m; i++) {\n        float* row = mat + i * n;\n        \n        // Compute squared sum using AVX\n        __m256 sum_vec = _mm256_setzero_ps();\n        for (size_t j = 0; j < n; j += 8) {\n            __m256 vec = _mm256_loadu_ps(row + j);\n            __m256 squared_vec = _mm256_mul_ps(vec, vec);\n            sum_vec = _mm256_add_ps(sum_vec, squared_vec);\n        }\n        \n        // Horizontal sum of squared values\n        __m128 sum_low = _mm256_extractf128_ps(sum_vec, 0);\n        __m128 sum_high = _mm256_extractf128_ps(sum_vec, 1);\n        sum_low = _mm_add_ps(sum_low, sum_high);\n        sum_low = _mm_hadd_ps(sum_low, sum_low);\n        sum_low = _mm_hadd_ps(sum_low, sum_low);\n        float sum = _mm_cvtss_f32(sum_low);\n        \n        // Compute L2 norm\n        float norm = sqrtf(sum);\n        \n        // Normalize row using AVX\n        __m256 norm_vec = _mm256_set1_ps(norm);\n        for (size_t j = 0; j < n; j += 8) {\n            __m256 vec = _mm256_loadu_ps(row + j);\n            __m256 normalized_vec = _mm256_div_ps(vec, norm_vec);\n            _mm256_storeu_ps(row + j, normalized_vec);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_23_AVX", "completion": "```cpp\nvoid matrix_normalize_rows_simd(float* mat, size_t m, size_t n) {\n    for (size_t i = 0; i < m; i++) {\n        float* row = mat + i * n;\n        \n        // Compute squared sum using AVX\n        __m256 sum_vec = _mm256_setzero_ps();\n        for (size_t j = 0; j < n; j += 8) {\n            __m256 vec = _mm256_loadu_ps(row + j);\n            __m256 squared_vec = _mm256_mul_ps(vec, vec);\n            sum_vec = _mm256_add_ps(sum_vec, squared_vec);\n        }\n        \n        // Horizontal sum of squared values\n        __m128 sum_low = _mm256_extractf128_ps(sum_vec, 0);\n        __m128 sum_high = _mm256_extractf128_ps(sum_vec, 1);\n        sum_low = _mm_add_ps(sum_low, sum_high);\n        sum_low = _mm_hadd_ps(sum_low, sum_low);\n        sum_low = _mm_hadd_ps(sum_low, sum_low);\n        float sum = _mm_cvtss_f32(sum_low);\n        \n        // Compute L2 norm\n        float norm = sqrtf(sum);\n        __m256 norm_vec = _mm256_set1_ps(norm);\n        \n        // Normalize row\n        for (size_t j = 0; j < n; j += 8) {\n            __m256 vec = _mm256_loadu_ps(row + j);\n            __m256 normalized_vec = _mm256_div_ps(vec, norm_vec);\n            _mm256_storeu_ps(row + j, normalized_vec);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_23_AVX", "completion": "```cpp\nvoid matrix_normalize_rows_simd(float* mat, size_t m, size_t n) {\n    for (size_t i = 0; i < m; i++) {\n        float* row = mat + i * n;\n        \n        // Compute squared sum using AVX\n        __m256 sum_squares_vec = _mm256_setzero_ps();\n        for (size_t j = 0; j < n; j += 8) {\n            __m256 vec = _mm256_loadu_ps(row + j);\n            __m256 squared_vec = _mm256_mul_ps(vec, vec);\n            sum_squares_vec = _mm256_add_ps(sum_squares_vec, squared_vec);\n        }\n        \n        // Horizontal sum of squared values\n        __m128 sum_lo = _mm256_extractf128_ps(sum_squares_vec, 0);\n        __m128 sum_hi = _mm256_extractf128_ps(sum_squares_vec, 1);\n        sum_lo = _mm_add_ps(sum_lo, sum_hi);\n        sum_lo = _mm_hadd_ps(sum_lo, sum_lo);\n        sum_lo = _mm_hadd_ps(sum_lo, sum_lo);\n        float sum_squares = _mm_cvtss_f32(sum_lo);\n        \n        // Compute L2 norm\n        float norm = sqrtf(sum_squares);\n        \n        // Normalize row using AVX\n        __m256 norm_vec = _mm256_set1_ps(norm);\n        for (size_t j = 0; j < n; j += 8) {\n            __m256 vec = _mm256_loadu_ps(row + j);\n            __m256 normalized_vec = _mm256_div_ps(vec, norm_vec);\n            _mm256_storeu_ps(row + j, normalized_vec);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_23_AVX", "completion": "```cpp\nvoid matrix_normalize_rows_simd(float* mat, size_t m, size_t n) {\n    for (size_t i = 0; i < m; i++) {\n        float* row = mat + i * n;\n        \n        // Compute squared sum using AVX\n        __m256 sum_squares = _mm256_setzero_ps();\n        for (size_t j = 0; j < n; j += 8) {\n            __m256 vec = _mm256_loadu_ps(row + j);\n            __m256 squared = _mm256_mul_ps(vec, vec);\n            sum_squares = _mm256_add_ps(sum_squares, squared);\n        }\n        \n        // Horizontal sum of squared values\n        __m128 low = _mm256_extractf128_ps(sum_squares, 0);\n        __m128 high = _mm256_extractf128_ps(sum_squares, 1);\n        low = _mm_add_ps(low, high);\n        low = _mm_hadd_ps(low, low);\n        low = _mm_hadd_ps(low, low);\n        float norm = _mm_cvtss_f32(low);\n        norm = sqrtf(norm);\n        \n        // Normalize row using reciprocal\n        float recip_norm = 1.0f / norm;\n        __m256 scale = _mm256_set1_ps(recip_norm);\n        \n        for (size_t j = 0; j < n; j += 8) {\n            __m256 vec = _mm256_loadu_ps(row + j);\n            vec = _mm256_mul_ps(vec, scale);\n            _mm256_storeu_ps(row + j, vec);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_23_AVX", "completion": "```cpp\nvoid matrix_normalize_rows_simd(float* mat, size_t m, size_t n) {\n    for (size_t i = 0; i < m; i++) {\n        float* row = mat + i * n;\n        \n        // Compute squared sum using AVX\n        __m256 sum_squares_vec = _mm256_setzero_ps();\n        for (size_t j = 0; j < n; j += 8) {\n            __m256 vec = _mm256_loadu_ps(row + j);\n            __m256 squared_vec = _mm256_mul_ps(vec, vec);\n            sum_squares_vec = _mm256_add_ps(sum_squares_vec, squared_vec);\n        }\n        \n        // Horizontal sum of squared values\n        __m128 sum_lo = _mm256_extractf128_ps(sum_squares_vec, 0);\n        __m128 sum_hi = _mm256_extractf128_ps(sum_squares_vec, 1);\n        sum_lo = _mm_add_ps(sum_lo, sum_hi);\n        sum_lo = _mm_hadd_ps(sum_lo, sum_lo);\n        sum_lo = _mm_hadd_ps(sum_lo, sum_lo);\n        float sum_squares = _mm_cvtss_f32(sum_lo);\n        \n        // Compute L2 norm\n        float norm = sqrtf(sum_squares);\n        __m256 norm_vec = _mm256_set1_ps(norm);\n        \n        // Normalize row\n        for (size_t j = 0; j < n; j += 8) {\n            __m256 vec = _mm256_loadu_ps(row + j);\n            __m256 normalized_vec = _mm256_div_ps(vec, norm_vec);\n            _mm256_storeu_ps(row + j, normalized_vec);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_24_AVX", "completion": "```cpp\nvoid matrix_mul_round_int_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n, size_t p) {\n    for (size_t i = 0; i < m; i++) {\n        for (size_t j = 0; j < p; j++) {\n            __m256d sum_vec = _mm256_setzero_pd();\n            \n            // Process 4 elements at a time using AVX\n            size_t k;\n            for (k = 0; k + 3 < n; k += 4) {\n                __m256d mat1_vec = _mm256_loadu_pd(&mat1[i*n + k]);\n                __m256d mat2_vec = _mm256_loadu_pd(&mat2[k*p + j]);\n                \n                __m256d mult_vec = _mm256_mul_pd(mat1_vec, mat2_vec);\n                sum_vec = _mm256_add_pd(sum_vec, mult_vec);\n            }\n            \n            // Horizontal sum of vector\n            __m128d sum_low = _mm256_extractf128_pd(sum_vec, 0);\n            __m128d sum_high = _mm256_extractf128_pd(sum_vec, 1);\n            sum_low = _mm_add_pd(sum_low, sum_high);\n            sum_low = _mm_hadd_pd(sum_low, sum_low);\n            \n            double sum = _mm_cvtsd_f64(sum_low);\n            \n            // Handle remaining elements\n            for (; k < n; k++) {\n                sum += mat1[i*n + k] * mat2[k*p + j];\n            }\n            \n            // Round to nearest integer\n            dst[i*p + j] = round(sum);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_24_AVX", "completion": "```cpp\nvoid matrix_mul_round_int_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n, size_t p) {\n    for (size_t i = 0; i < m; i++) {\n        for (size_t j = 0; j < p; j++) {\n            __m256d sum_vec = _mm256_setzero_pd();\n            \n            // Process 4 elements at a time using AVX\n            size_t k;\n            for (k = 0; k + 3 < n; k += 4) {\n                __m256d mat1_vec = _mm256_loadu_pd(&mat1[i * n + k]);\n                __m256d mat2_vec = _mm256_loadu_pd(&mat2[k * p + j]);\n                \n                __m256d mul_vec = _mm256_mul_pd(mat1_vec, mat2_vec);\n                sum_vec = _mm256_add_pd(sum_vec, mul_vec);\n            }\n            \n            // Horizontal sum of the vector\n            __m128d sum_low = _mm256_extractf128_pd(sum_vec, 0);\n            __m128d sum_high = _mm256_extractf128_pd(sum_vec, 1);\n            sum_low = _mm_add_pd(sum_low, sum_high);\n            sum_low = _mm_hadd_pd(sum_low, sum_low);\n            \n            double sum = _mm_cvtsd_f64(sum_low);\n            \n            // Handle remaining elements\n            for (; k < n; k++) {\n                sum += mat1[i * n + k] * mat2[k * p + j];\n            }\n            \n            // Round to nearest integer\n            dst[i * p + j] = round(sum);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_24_AVX", "completion": "```cpp\nvoid matrix_mul_round_int_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n, size_t p) {\n    for (size_t i = 0; i < m; i++) {\n        for (size_t j = 0; j < p; j++) {\n            __m256d sum_vec = _mm256_setzero_pd();\n            \n            // Process 4 elements at a time using AVX\n            size_t k;\n            for (k = 0; k + 3 < n; k += 4) {\n                __m256d mat1_vec = _mm256_loadu_pd(&mat1[i * n + k]);\n                __m256d mat2_vec = _mm256_loadu_pd(&mat2[k * p + j]);\n                \n                __m256d mul_vec = _mm256_mul_pd(mat1_vec, mat2_vec);\n                sum_vec = _mm256_add_pd(sum_vec, mul_vec);\n            }\n            \n            // Horizontal sum of the vector\n            __m128d sum_low = _mm256_extractf128_pd(sum_vec, 0);\n            __m128d sum_high = _mm256_extractf128_pd(sum_vec, 1);\n            sum_low = _mm_add_pd(sum_low, sum_high);\n            sum_low = _mm_hadd_pd(sum_low, sum_low);\n            \n            double sum = _mm_cvtsd_f64(sum_low);\n            \n            // Handle remaining elements\n            for (; k < n; k++) {\n                sum += mat1[i * n + k] * mat2[k * p + j];\n            }\n            \n            // Round to nearest integer\n            dst[i * p + j] = round(sum);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_24_AVX", "completion": "```cpp\nvoid matrix_mul_round_int_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n, size_t p) {\n    for (size_t i = 0; i < m; i++) {\n        for (size_t j = 0; j < p; j++) {\n            __m256d sum_vec = _mm256_setzero_pd();\n            \n            // Process 4 elements at a time using AVX\n            size_t k;\n            for (k = 0; k + 3 < n; k += 4) {\n                __m256d mat1_vec = _mm256_loadu_pd(&mat1[i * n + k]);\n                __m256d mat2_vec = _mm256_loadu_pd(&mat2[k * p + j]);\n                \n                __m256d mul_vec = _mm256_mul_pd(mat1_vec, mat2_vec);\n                sum_vec = _mm256_add_pd(sum_vec, mul_vec);\n            }\n            \n            // Horizontal sum of the vector\n            __m128d sum_low = _mm256_extractf128_pd(sum_vec, 0);\n            __m128d sum_high = _mm256_extractf128_pd(sum_vec, 1);\n            sum_low = _mm_add_pd(sum_low, sum_high);\n            sum_low = _mm_hadd_pd(sum_low, sum_low);\n            \n            double sum = _mm_cvtsd_f64(sum_low);\n            \n            // Handle remaining elements\n            for (; k < n; k++) {\n                sum += mat1[i * n + k] * mat2[k * p + j];\n            }\n            \n            // Round to nearest integer\n            dst[i * p + j] = round(sum);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_24_AVX", "completion": "```cpp\nvoid matrix_mul_round_int_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n, size_t p) {\n    for (size_t i = 0; i < m; i++) {\n        for (size_t j = 0; j < p; j++) {\n            __m256d sum_vec = _mm256_setzero_pd();\n            \n            // Process 4 elements at a time using AVX\n            size_t k;\n            for (k = 0; k + 3 < n; k += 4) {\n                __m256d mat1_vec = _mm256_loadu_pd(&mat1[i * n + k]);\n                __m256d mat2_vec = _mm256_loadu_pd(&mat2[k * p + j]);\n                \n                __m256d mul_vec = _mm256_mul_pd(mat1_vec, mat2_vec);\n                sum_vec = _mm256_add_pd(sum_vec, mul_vec);\n            }\n            \n            // Horizontal sum of the vector\n            __m128d sum_low = _mm256_extractf128_pd(sum_vec, 0);\n            __m128d sum_high = _mm256_extractf128_pd(sum_vec, 1);\n            sum_low = _mm_add_pd(sum_low, sum_high);\n            sum_low = _mm_hadd_pd(sum_low, sum_low);\n            \n            double sum = _mm_cvtsd_f64(sum_low);\n            \n            // Handle remaining elements\n            for (; k < n; k++) {\n                sum += mat1[i * n + k] * mat2[k * p + j];\n            }\n            \n            // Round to nearest integer\n            dst[i * p + j] = round(sum);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_25_AVX", "completion": "```cpp\nvoid matrix_transpose_round_quarter_simd(const float* src, float* dst, size_t rows, size_t cols) {\n    // Process 8 elements at a time with AVX\n    for (size_t i = 0; i < rows; i += 8) {\n        for (size_t j = 0; j < cols; j++) {\n            // Load 8 consecutive elements from source matrix\n            __m256 row_vec = _mm256_loadu_ps(src + i * cols + j);\n            \n            // Round to nearest quarter\n            __m256 quarter_vec = _mm256_set1_ps(0.25f);\n            __m256 rounded_vec = _mm256_round_ps(row_vec, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n            __m256 scaled_vec = _mm256_div_ps(rounded_vec, quarter_vec);\n            __m256 result_vec = _mm256_round_ps(scaled_vec, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n            result_vec = _mm256_mul_ps(result_vec, quarter_vec);\n            \n            // Store transposed and rounded elements\n            for (size_t k = 0; k < 8 && i + k < rows; k++) {\n                dst[j * rows + i + k] = _mm256_cvtss_f32(_mm256_permute_ps(result_vec, k));\n            }\n        }\n    }\n    \n    // Handle remaining rows if rows is not divisible by 8\n    for (size_t i = (rows / 8) * 8; i < rows; i++) {\n        for (size_t j = 0; j < cols; j++) {\n            float rounded = roundf(src[i * cols + j] / 0.25f) * 0.25f;\n            dst[j * rows + i] = rounded;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_25_AVX", "completion": "```cpp\nvoid matrix_transpose_round_quarter_simd(const float* src, float* dst, size_t rows, size_t cols) {\n    // Process 8 elements at a time with AVX\n    for (size_t i = 0; i < rows; i += 8) {\n        for (size_t j = 0; j < cols; j++) {\n            // Load 8 consecutive elements from source matrix\n            __m256 row_vec = _mm256_loadu_ps(src + i * cols + j);\n            \n            // Round to nearest quarter\n            __m256 quarter_vec = _mm256_set1_ps(0.25f);\n            __m256 rounded_vec = _mm256_round_ps(row_vec, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n            __m256 scaled_vec = _mm256_div_ps(rounded_vec, quarter_vec);\n            __m256 result_vec = _mm256_round_ps(scaled_vec, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n            result_vec = _mm256_mul_ps(result_vec, quarter_vec);\n            \n            // Store transposed and rounded elements\n            for (size_t k = 0; k < 8 && i + k < rows; k++) {\n                dst[j * rows + i + k] = _mm256_cvtss_f32(_mm256_permute_ps(result_vec, k));\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_25_AVX", "completion": "```cpp\nvoid matrix_transpose_round_quarter_simd(const float* src, float* dst, size_t rows, size_t cols) {\n    // Process 8 elements at a time using AVX\n    for (size_t i = 0; i < rows; i += 8) {\n        for (size_t j = 0; j < cols; j++) {\n            // Load 8 consecutive elements from source matrix\n            __m256 row_vec = _mm256_loadu_ps(src + i * cols + j);\n            \n            // Round to nearest quarter\n            __m256 quarter_vec = _mm256_set1_ps(0.25f);\n            __m256 rounded_vec = _mm256_round_ps(row_vec, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n            __m256 scaled_vec = _mm256_div_ps(rounded_vec, quarter_vec);\n            __m256 final_vec = _mm256_round_ps(scaled_vec, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n            final_vec = _mm256_mul_ps(final_vec, quarter_vec);\n            \n            // Store transposed and rounded elements\n            for (size_t k = 0; k < 8 && i + k < rows; k++) {\n                dst[j * rows + i + k] = _mm256_cvtss_f32(_mm256_permute_ps(final_vec, k));\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_25_AVX", "completion": "```cpp\nvoid matrix_transpose_round_quarter_simd(const float* src, float* dst, size_t rows, size_t cols) {\n    // Process 8 elements at a time with AVX\n    for (size_t i = 0; i < rows; i += 8) {\n        for (size_t j = 0; j < cols; j++) {\n            // Load 8 consecutive elements from source matrix\n            __m256 row_vec = _mm256_loadu_ps(src + i * cols + j);\n            \n            // Round to nearest quarter\n            __m256 quarter_vec = _mm256_set1_ps(0.25f);\n            __m256 rounded_vec = _mm256_round_ps(row_vec, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n            __m256 scaled_vec = _mm256_div_ps(rounded_vec, quarter_vec);\n            __m256 final_vec = _mm256_round_ps(scaled_vec, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n            final_vec = _mm256_mul_ps(final_vec, quarter_vec);\n            \n            // Store transposed elements in destination matrix\n            for (size_t k = 0; k < 8; k++) {\n                if (i + k < rows) {\n                    dst[j * rows + i + k] = _mm256_cvtss_f32(_mm256_permute_ps(final_vec, k));\n                }\n            }\n        }\n    }\n    \n    // Handle remaining rows if rows is not divisible by 8\n    for (size_t i = (rows / 8) * 8; i < rows; i++) {\n        for (size_t j = 0; j < cols; j++) {\n            float val = src[i * cols + j];\n            float rounded = roundf(val / 0.25f) * 0.25f;\n            dst[j * rows + i] = rounded;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_25_AVX", "completion": "```cpp\nvoid matrix_transpose_round_quarter_simd(const float* src, float* dst, size_t rows, size_t cols) {\n    // Process 8 elements at a time using AVX\n    for (size_t i = 0; i < rows; i += 8) {\n        for (size_t j = 0; j < cols; j++) {\n            // Load 8 consecutive elements from source matrix\n            __m256 row_vec = _mm256_loadu_ps(src + i * cols + j);\n            \n            // Round to nearest quarter\n            __m256 quarter_vec = _mm256_set1_ps(0.25f);\n            __m256 rounded_vec = _mm256_round_ps(row_vec, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n            __m256 scaled_vec = _mm256_div_ps(rounded_vec, quarter_vec);\n            __m256 result_vec = _mm256_round_ps(scaled_vec, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n            result_vec = _mm256_mul_ps(result_vec, quarter_vec);\n            \n            // Store transposed and rounded elements\n            for (size_t k = 0; k < 8 && i + k < rows; k++) {\n                dst[j * rows + i + k] = _mm256_cvtss_f32(_mm256_permute_ps(result_vec, k));\n            }\n        }\n    }\n    \n    // Handle remaining rows if rows is not divisible by 8\n    for (size_t i = rows - (rows % 8); i < rows; i++) {\n        for (size_t j = 0; j < cols; j++) {\n            float val = src[i * cols + j];\n            float rounded = roundf(val / 0.25f) * 0.25f;\n            dst[j * rows + i] = rounded;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_26_AVX", "completion": "```cpp\nvoid tensor3d_sub_round_zero_simd(const float* tensor1, const float* tensor2, float* dst, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t vector_size = 8; // AVX can process 8 floats at a time\n    size_t simd_iterations = total_elements / vector_size;\n    size_t remaining_elements = total_elements % vector_size;\n\n    // Process 8 elements at a time using AVX\n    for (size_t i = 0; i < simd_iterations * vector_size; i += vector_size) {\n        __m256 vec1 = _mm256_loadu_ps(&tensor1[i]);\n        __m256 vec2 = _mm256_loadu_ps(&tensor2[i]);\n        \n        // Subtract vectors\n        __m256 result_vec = _mm256_sub_ps(vec1, vec2);\n        \n        // Round towards zero\n        __m256 rounded_vec = _mm256_round_ps(result_vec, _MM_FROUND_TO_ZERO | _MM_FROUND_NO_EXC);\n        \n        // Store result\n        _mm256_storeu_ps(&dst[i], rounded_vec);\n    }\n\n    // Handle remaining elements\n    for (size_t i = simd_iterations * vector_size; i < total_elements; ++i) {\n        dst[i] = floorf(tensor1[i] - tensor2[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_26_AVX", "completion": "```cpp\nvoid tensor3d_sub_round_zero_simd(const float* tensor1, const float* tensor2, float* dst, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t vector_size = 8; // AVX can process 8 floats at a time\n    size_t simd_iterations = total_elements / vector_size;\n    size_t remainder = total_elements % vector_size;\n\n    // Process 8 elements at a time using AVX\n    for (size_t i = 0; i < simd_iterations * vector_size; i += vector_size) {\n        __m256 vec1 = _mm256_loadu_ps(&tensor1[i]);\n        __m256 vec2 = _mm256_loadu_ps(&tensor2[i]);\n        \n        // Subtract vectors\n        __m256 result_vec = _mm256_sub_ps(vec1, vec2);\n        \n        // Round towards zero\n        __m256 rounded_vec = _mm256_round_ps(result_vec, _MM_FROUND_TO_ZERO | _MM_FROUND_NO_EXC);\n        \n        // Store result\n        _mm256_storeu_ps(&dst[i], rounded_vec);\n    }\n\n    // Handle remaining elements\n    for (size_t i = simd_iterations * vector_size; i < total_elements; ++i) {\n        dst[i] = floorf(tensor1[i] - tensor2[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_26_AVX", "completion": "```cpp\nvoid tensor3d_sub_round_zero_simd(const float* tensor1, const float* tensor2, float* dst, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t vector_size = 8; // AVX can process 8 floats at a time\n    size_t simd_iterations = total_elements / vector_size;\n    size_t remaining_elements = total_elements % vector_size;\n\n    // Process elements in 8-float vectors using AVX\n    for (size_t i = 0; i < simd_iterations * vector_size; i += vector_size) {\n        __m256 vec1 = _mm256_loadu_ps(&tensor1[i]);\n        __m256 vec2 = _mm256_loadu_ps(&tensor2[i]);\n        \n        // Subtract vectors\n        __m256 result_vec = _mm256_sub_ps(vec1, vec2);\n        \n        // Round towards zero\n        __m256 rounded_vec = _mm256_round_ps(result_vec, _MM_FROUND_TO_ZERO | _MM_FROUND_NO_EXC);\n        \n        // Store result\n        _mm256_storeu_ps(&dst[i], rounded_vec);\n    }\n\n    // Handle remaining elements\n    for (size_t i = simd_iterations * vector_size; i < total_elements; ++i) {\n        dst[i] = floorf(tensor1[i] - tensor2[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_26_AVX", "completion": "```cpp\nvoid tensor3d_sub_round_zero_simd(const float* tensor1, const float* tensor2, float* dst, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t vector_size = 8; // AVX can process 8 floats at a time\n    size_t simd_iterations = total_elements / vector_size;\n    size_t remaining_elements = total_elements % vector_size;\n\n    // Process 8 elements at a time using AVX\n    for (size_t i = 0; i < simd_iterations * vector_size; i += vector_size) {\n        __m256 vec1 = _mm256_loadu_ps(&tensor1[i]);\n        __m256 vec2 = _mm256_loadu_ps(&tensor2[i]);\n        \n        // Subtract vectors\n        __m256 result_vec = _mm256_sub_ps(vec1, vec2);\n        \n        // Round towards zero\n        __m256 rounded_vec = _mm256_round_ps(result_vec, _MM_FROUND_TO_ZERO | _MM_FROUND_NO_EXC);\n        \n        // Store result\n        _mm256_storeu_ps(&dst[i], rounded_vec);\n    }\n\n    // Handle remaining elements\n    for (size_t i = simd_iterations * vector_size; i < total_elements; ++i) {\n        dst[i] = floorf(tensor1[i] - tensor2[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_26_AVX", "completion": "```cpp\nvoid tensor3d_sub_round_zero_simd(const float* tensor1, const float* tensor2, float* dst, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t vector_size = 8; // AVX can process 8 floats at a time\n    size_t simd_iterations = total_elements / vector_size;\n    size_t remaining_elements = total_elements % vector_size;\n\n    // Process 8 elements at a time using AVX\n    for (size_t i = 0; i < simd_iterations * vector_size; i += vector_size) {\n        __m256 vec1 = _mm256_loadu_ps(&tensor1[i]);\n        __m256 vec2 = _mm256_loadu_ps(&tensor2[i]);\n        \n        // Subtract vectors\n        __m256 result_vec = _mm256_sub_ps(vec1, vec2);\n        \n        // Round towards zero\n        __m256 rounded_vec = _mm256_round_ps(result_vec, _MM_FROUND_TO_ZERO | _MM_FROUND_NO_EXC);\n        \n        // Store result\n        _mm256_storeu_ps(&dst[i], rounded_vec);\n    }\n\n    // Handle remaining elements\n    for (size_t i = simd_iterations * vector_size; i < total_elements; ++i) {\n        dst[i] = floorf(tensor1[i] - tensor2[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_27_AVX", "completion": "```cpp\nvoid matrix_hadamard_product_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n) {\n    for (size_t i = 0; i < m; i++) {\n        size_t j = 0;\n        // Process 4 doubles at a time using AVX2 256-bit vectors\n        for (; j + 3 < n; j += 4) {\n            __m256d vec1 = _mm256_loadu_pd(&mat1[i * n + j]);\n            __m256d vec2 = _mm256_loadu_pd(&mat2[i * n + j]);\n            __m256d result = _mm256_mul_pd(vec1, vec2);\n            _mm256_storeu_pd(&dst[i * n + j], result);\n        }\n        \n        // Handle remaining elements\n        for (; j < n; j++) {\n            dst[i * n + j] = mat1[i * n + j] * mat2[i * n + j];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_27_AVX", "completion": "```cpp\nvoid matrix_hadamard_product_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n) {\n    for (size_t i = 0; i < m; i++) {\n        size_t j = 0;\n        // Process 4 doubles at a time using AVX2 256-bit vectors\n        for (; j + 3 < n; j += 4) {\n            __m256d vec1 = _mm256_loadu_pd(&mat1[i * n + j]);\n            __m256d vec2 = _mm256_loadu_pd(&mat2[i * n + j]);\n            __m256d result = _mm256_mul_pd(vec1, vec2);\n            _mm256_storeu_pd(&dst[i * n + j], result);\n        }\n        \n        // Handle remaining elements\n        for (; j < n; j++) {\n            dst[i * n + j] = mat1[i * n + j] * mat2[i * n + j];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_27_AVX", "completion": "```cpp\nvoid matrix_hadamard_product_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n) {\n    for (size_t i = 0; i < m; i++) {\n        size_t j = 0;\n        // Process 4 doubles at a time using AVX2 256-bit registers\n        for (; j + 3 < n; j += 4) {\n            __m256d vec1 = _mm256_loadu_pd(&mat1[i * n + j]);\n            __m256d vec2 = _mm256_loadu_pd(&mat2[i * n + j]);\n            __m256d result = _mm256_mul_pd(vec1, vec2);\n            _mm256_storeu_pd(&dst[i * n + j], result);\n        }\n        \n        // Handle remaining elements\n        for (; j < n; j++) {\n            dst[i * n + j] = mat1[i * n + j] * mat2[i * n + j];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_27_AVX", "completion": "```cpp\nvoid matrix_hadamard_product_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n) {\n    for (size_t i = 0; i < m; i++) {\n        size_t j = 0;\n        // Process 4 doubles at a time using AVX2\n        for (; j + 4 <= n; j += 4) {\n            __m256d vec1 = _mm256_loadu_pd(&mat1[i * n + j]);\n            __m256d vec2 = _mm256_loadu_pd(&mat2[i * n + j]);\n            __m256d result = _mm256_mul_pd(vec1, vec2);\n            _mm256_storeu_pd(&dst[i * n + j], result);\n        }\n        \n        // Handle remaining elements\n        for (; j < n; j++) {\n            dst[i * n + j] = mat1[i * n + j] * mat2[i * n + j];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_27_AVX", "completion": "```cpp\nvoid matrix_hadamard_product_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n) {\n    for (size_t i = 0; i < m; i++) {\n        size_t j = 0;\n        // Process 4 doubles at a time using AVX2 \n        for (; j + 3 < n; j += 4) {\n            __m256d vec1 = _mm256_loadu_pd(&mat1[i*n + j]);\n            __m256d vec2 = _mm256_loadu_pd(&mat2[i*n + j]);\n            __m256d result = _mm256_mul_pd(vec1, vec2);\n            _mm256_storeu_pd(&dst[i*n + j], result);\n        }\n        \n        // Handle remaining elements\n        for (; j < n; j++) {\n            dst[i*n + j] = mat1[i*n + j] * mat2[i*n + j];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_28_AVX", "completion": "```cpp\nvoid matrix_vector_mul_simd(const float* mat, const float* vec, float* dst, size_t m, size_t n) {\n    for (size_t i = 0; i < m; i++) {\n        __m256 sum_vec = _mm256_setzero_ps();\n        \n        size_t j;\n        for (j = 0; j + 8 <= n; j += 8) {\n            __m256 mat_vec = _mm256_loadu_ps(&mat[i * n + j]);\n            __m256 vec_vec = _mm256_loadu_ps(&vec[j]);\n            sum_vec = _mm256_add_ps(sum_vec, _mm256_mul_ps(mat_vec, vec_vec));\n        }\n        \n        float sum_array[8];\n        _mm256_storeu_ps(sum_array, sum_vec);\n        float row_sum = sum_array[0] + sum_array[1] + sum_array[2] + sum_array[3] + \n                        sum_array[4] + sum_array[5] + sum_array[6] + sum_array[7];\n        \n        for (; j < n; j++) {\n            sum_array[0] += mat[i * n + j] * vec[j];\n        }\n        \n        dst[i] = sum_array[0];\n    }\n}\n```"}
{"task_id": "SimdBench_28_AVX", "completion": "```cpp\nvoid matrix_vector_mul_simd(const float* mat, const float* vec, float* dst, size_t m, size_t n) {\n    for (size_t i = 0; i < m; i++) {\n        __m256 sum_vec = _mm256_setzero_ps();\n        \n        size_t j;\n        for (j = 0; j + 8 <= n; j += 8) {\n            __m256 mat_vec = _mm256_loadu_ps(mat + i * n + j);\n            __m256 vec_vec = _mm256_loadu_ps(vec + j);\n            sum_vec = _mm256_add_ps(sum_vec, _mm256_mul_ps(mat_vec, vec_vec));\n        }\n        \n        float sum_arr[8];\n        _mm256_storeu_ps(sum_arr, sum_vec);\n        float row_sum = sum_arr[0] + sum_arr[1] + sum_arr[2] + sum_arr[3] + \n                        sum_arr[4] + sum_arr[5] + sum_arr[6] + sum_arr[7];\n        \n        for (; j < n; j++) {\n            sum_row += mat[i * n + j] * vec[j];\n        }\n        \n        dst[i] = row_sum;\n    }\n}\n```"}
{"task_id": "SimdBench_28_AVX", "completion": "```cpp\nvoid matrix_vector_mul_simd(const float* mat, const float* vec, float* dst, size_t m, size_t n) {\n    for (size_t i = 0; i < m; i++) {\n        __m256 sum_vec = _mm256_setzero_ps();\n        \n        size_t j;\n        for (j = 0; j + 8 <= n; j += 8) {\n            __m256 mat_vec = _mm256_loadu_ps(&mat[i * n + j]);\n            __m256 vec_vec = _mm256_loadu_ps(&vec[j]);\n            sum_vec = _mm256_add_ps(sum_vec, _mm256_mul_ps(mat_vec, vec_vec));\n        }\n        \n        float sum_arr[8];\n        _mm256_storeu_ps(sum_arr, sum_vec);\n        float row_sum = sum_arr[0] + sum_arr[1] + sum_arr[2] + sum_arr[3] + \n                        sum_arr[4] + sum_arr[5] + sum_arr[6] + sum_arr[7];\n        \n        for (; j < n; j++) {\n            sum_row += mat[i * n + j] * vec[j];\n        }\n        \n        dst[i] = row_sum;\n    }\n}\n```"}
{"task_id": "SimdBench_28_AVX", "completion": "```cpp\nvoid matrix_vector_mul_simd(const float* mat, const float* vec, float* dst, size_t m, size_t n) {\n    for (size_t i = 0; i < m; i++) {\n        __m256 sum_vec = _mm256_setzero_ps();\n        \n        size_t j;\n        for (j = 0; j + 8 <= n; j += 8) {\n            __m256 mat_vec = _mm256_loadu_ps(&mat[i * n + j]);\n            __m256 vec_vec = _mm256_loadu_ps(&vec[j]);\n            sum_vec = _mm256_add_ps(sum_vec, _mm256_mul_ps(mat_vec, vec_vec));\n        }\n        \n        float sum_arr[8];\n        _mm256_storeu_ps(sum_arr, sum_vec);\n        float row_sum = sum_arr[0] + sum_arr[1] + sum_arr[2] + sum_arr[3] + \n                        sum_arr[4] + sum_arr[5] + sum_arr[6] + sum_arr[7];\n        \n        for (; j < n; j++) {\n            sum_row += mat[i * n + j] * vec[j];\n        }\n        \n        dst[i] = sum_row;\n    }\n}\n```"}
{"task_id": "SimdBench_28_AVX", "completion": "```cpp\nvoid matrix_vector_mul_simd(const float* mat, const float* vec, float* dst, size_t m, size_t n) {\n    for (size_t i = 0; i < m; i++) {\n        __m256 sum_vec = _mm256_setzero_ps();\n        \n        size_t j;\n        for (j = 0; j + 8 <= n; j += 8) {\n            __m256 mat_vec = _mm256_loadu_ps(&mat[i * n + j]);\n            __m256 vec_vec = _mm256_loadu_ps(&vec[j]);\n            sum_vec = _mm256_add_ps(sum_vec, _mm256_mul_ps(mat_vec, vec_vec));\n        }\n        \n        float sum_arr[8];\n        _mm256_storeu_ps(sum_arr, sum_vec);\n        float row_sum = sum_arr[0] + sum_arr[1] + sum_arr[2] + sum_arr[3] + \n                        sum_arr[4] + sum_arr[5] + sum_arr[6] + sum_arr[7];\n        \n        for (; j < n; j++) {\n            sum_row += mat[i * n + j] * vec[j];\n        }\n        \n        dst[i] = sum_row;\n    }\n}\n```"}
{"task_id": "SimdBench_29_AVX", "completion": "```cpp\ndouble matrix_average_simd(const double* mat, size_t m, size_t n) {\n    __m256d sum_vector = _mm256_setzero_pd();\n    size_t total_elements = m * n;\n    size_t vector_width = 4;  // AVX processes 4 doubles per vector\n    size_t i = 0;\n\n    // Process vectors\n    for (; i + vector_width <= total_elements; i += vector_width) {\n        __m256d current_vector = _mm256_loadu_pd(mat + i);\n        sum_vector = _mm256_add_pd(sum_vector, current_vector);\n    }\n\n    // Horizontal sum of vector elements\n    __m128d sum_low = _mm256_extractf128_pd(sum_vector, 0);\n    __m128d sum_high = _mm256_extractf128_pd(sum_vector, 1);\n    sum_low = _mm_add_pd(sum_low, sum_high);\n    double horizontal_sum = _mm_cvtsd_f64(_mm_add_sd(sum_low, _mm_shuffle_pd(sum_low, sum_low, 1)));\n\n    // Handle remaining elements\n    for (; i < total_elements; i++) {\n        horizontal_sum += mat[i];\n    }\n\n    return horizontal_sum / total_elements;\n}\n```"}
{"task_id": "SimdBench_29_AVX", "completion": "```cpp\ndouble matrix_average_simd(const double* mat, size_t m, size_t n) {\n    __m256d sum_vector = _mm256_setzero_pd();\n    size_t total_elements = m * n;\n    size_t vector_width = 4;  // AVX processes 4 double-precision floats per vector\n    size_t i = 0;\n\n    // Process vectors in parallel\n    for (; i + vector_width <= total_elements; i += vector_width) {\n        __m256d current_vector = _mm256_loadu_pd(mat + i);\n        sum_vector = _mm256_add_pd(sum_vector, current_vector);\n    }\n\n    // Horizontal sum of vector elements\n    __m128d sum_low = _mm256_extractf128_pd(sum_vector, 0);\n    __m128d sum_high = _mm256_extractf128_pd(sum_vector, 1);\n    sum_low = _mm_add_pd(sum_low, sum_high);\n    double sum = _mm_cvtsd_f64(sum_low) + _mm_cvtsd_f64(_mm_shuffle_pd(sum_low, sum_low, 1));\n\n    // Handle remaining elements\n    for (; i < total_elements; ++i) {\n        sum += mat[i];\n    }\n\n    return sum / total_elements;\n}\n```"}
{"task_id": "SimdBench_29_AVX", "completion": "```cpp\ndouble matrix_average_simd(const double* mat, size_t m, size_t n) {\n    __m256d sum_vector = _mm256_setzero_pd();\n    size_t total_elements = m * n;\n    size_t vector_width = 4;  // AVX processes 4 doubles at a time\n    size_t i = 0;\n\n    // Process 4 doubles at a time using AVX\n    for (; i + vector_width <= total_elements; i += vector_width) {\n        __m256d current_vector = _mm256_loadu_pd(mat + i);\n        sum_vector = _mm256_add_pd(sum_vector, current_vector);\n    }\n\n    // Horizontal sum of the vector\n    __m128d sum_low = _mm256_extractf128_pd(sum_vector, 0);\n    __m128d sum_high = _mm256_extractf128_pd(sum_vector, 1);\n    sum_low = _mm_add_pd(sum_low, sum_high);\n    double sum = _mm_cvtsd_f64(sum_low) + _mm_cvtsd_f64(_mm_shuffle_pd(sum_low, sum_low, 1));\n\n    // Handle remaining elements\n    for (; i < total_elements; i++) {\n        sum += mat[i];\n    }\n\n    return sum / total_elements;\n}\n```"}
{"task_id": "SimdBench_29_AVX", "completion": "```cpp\ndouble matrix_average_simd(const double* mat, size_t m, size_t n) {\n    __m256d sum_vector = _mm256_setzero_pd();\n    size_t total_elements = m * n;\n    size_t vector_width = 4;  // AVX processes 4 doubles per vector\n    size_t i = 0;\n\n    // Process 4 doubles at a time using AVX\n    for (; i + vector_width <= total_elements; i += vector_width) {\n        __m256d current_vector = _mm256_loadu_pd(mat + i);\n        sum_vector = _mm256_add_pd(sum_vector, current_vector);\n    }\n\n    // Horizontal sum of vector elements\n    __m128d sum_low = _mm256_extractf128_pd(sum_vector, 0);\n    __m128d sum_high = _mm256_extractf128_pd(sum_vector, 1);\n    __m128d sum_combined = _mm_add_pd(sum_low, sum_high);\n    sum_combined = _mm_hadd_pd(sum_combined, sum_combined);\n    double total_sum = _mm_cvtsd_f64(sum_combined);\n\n    // Handle remaining elements\n    for (; i < total_elements; i++) {\n        total_sum += mat[i];\n    }\n\n    return total_sum / total_elements;\n}\n```"}
{"task_id": "SimdBench_29_AVX", "completion": "```cpp\ndouble matrix_average_simd(const double* mat, size_t m, size_t n) {\n    __m256d sum_vector = _mm256_setzero_pd();\n    size_t total_elements = m * n;\n    size_t vector_length = total_elements - (total_elements % 4);\n\n    // Process 4 doubles at a time using AVX\n    for (size_t i = 0; i < vector_length; i += 4) {\n        __m256d current_vector = _mm256_loadu_pd(&mat[i]);\n        sum_vector = _mm256_add_pd(sum_vector, current_vector);\n    }\n\n    // Horizontal sum of vector elements\n    __m128d sum_low = _mm256_extractf128_pd(sum_vector, 0);\n    __m128d sum_high = _mm256_extractf128_pd(sum_vector, 1);\n    sum_low = _mm_add_pd(sum_low, sum_high);\n    sum_low = _mm_hadd_pd(sum_low, sum_low);\n\n    double sum = _mm_cvtsd_f64(sum_low);\n\n    // Handle remaining elements\n    for (size_t i = vector_length; i < total_elements; i++) {\n        sum += mat[i];\n    }\n\n    return sum / total_elements;\n}\n```"}
{"task_id": "SimdBench_30_AVX", "completion": "```cpp\nbool matrix_rows_sorted_verify_simd(const int* matrix, const bool* directions, size_t rows, size_t cols) {\n    for (size_t r = 0; r < rows; r++) {\n        const int* row = matrix + r * cols;\n        bool ascending = directions[r];\n        \n        size_t col = 0;\n        // Process 8 elements at a time using AVX2\n        for (; col + 8 <= cols; col += 8) {\n            __m256i current = _mm256_loadu_si256((__m256i*)&row[col]);\n            __m256i next = _mm256_loadu_si256((__m256i*)&row[col + 1]);\n            \n            __m256i comparison;\n            if (ascending) {\n                // Check if current <= next for ascending order\n                comparison = _mm256_cmpgt_epi32(current, next);\n            } else {\n                // Check if current >= next for descending order\n                comparison = _mm256_cmpgt_epi32(next, current);\n            }\n            \n            // If any comparison fails, return false\n            if (_mm256_movemask_ps((__m256)comparison) != 0) {\n                return false;\n            }\n        }\n        \n        // Handle remaining elements\n        for (; col < cols - 1; col++) {\n            if (ascending) {\n                if (row[col] > row[col + 1]) {\n                    return false;\n                }\n            } else {\n                if (row[col] < row[col + 1]) {\n                    return false;\n                }\n            }\n        }\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_30_AVX", "completion": "```cpp\nbool matrix_rows_sorted_verify_simd(const int* matrix, const bool* directions, size_t rows, size_t cols) {\n    for (size_t row = 0; row < rows; row++) {\n        const int* current_row = matrix + row * cols;\n        bool ascending = directions[row];\n\n        // Process 8 elements at a time using AVX2 \n        size_t vec_cols = cols - (cols % 8);\n        __m256i prev_vec, curr_vec;\n\n        // Load first vector\n        prev_vec = _mm256_loadu_si256((__m256i*)current_row);\n\n        for (size_t col = 8; col < vec_cols; col += 8) {\n            curr_vec = _mm256_loadu_si256((__m256i*)(current_row + col));\n\n            // Compare based on sort direction\n            __m256i compare_mask;\n            if (ascending) {\n                // Check if each element is greater or equal to previous\n                compare_mask = _mm256_cmpgt_epi32(prev_vec, curr_vec);\n            } else {\n                // Check if each element is less or equal to previous\n                compare_mask = _mm256_cmpgt_epi32(curr_vec, prev_vec);\n            }\n\n            // If any element violates sorting, return false\n            if (_mm256_movemask_ps((__m256)compare_mask) != 0) {\n                return false;\n            }\n\n            prev_vec = curr_vec;\n        }\n\n        // Handle remaining elements\n        for (size_t col = vec_cols; col < cols - 1; col++) {\n            if (ascending && current_row[col] > current_row[col + 1]) {\n                return false;\n            }\n            if (!ascending && current_row[col] < current_row[col + 1]) {\n                return false;\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_30_AVX", "completion": "```cpp\nbool matrix_rows_sorted_verify_simd(const int* matrix, const bool* directions, size_t rows, size_t cols) {\n    for (size_t r = 0; r < rows; r++) {\n        const int* row = matrix + r * cols;\n        bool ascending = directions[r];\n        \n        size_t col = 0;\n        // Process 8 elements at a time using AVX2\n        for (; col + 8 <= cols; col += 8) {\n            __m256i current = _mm256_loadu_si256((__m256i*)&row[col]);\n            __m256i next = _mm256_loadu_si256((__m256i*)&row[col + 1]);\n            \n            __m256i comparison;\n            if (ascending) {\n                // Check if current <= next for ascending order\n                comparison = _mm256_cmpgt_epi32(current, next);\n            } else {\n                // Check if current >= next for descending order\n                comparison = _mm256_cmpgt_epi32(next, current);\n            }\n            \n            // If any comparison fails, return false\n            if (_mm256_movemask_ps((__m256)comparison) != 0) {\n                return false;\n            }\n        }\n        \n        // Handle remaining elements\n        for (; col < cols - 1; col++) {\n            if (ascending) {\n                if (row[col] > row[col + 1]) {\n                    return false;\n                }\n            } else {\n                if (row[col] < row[col + 1]) {\n                    return false;\n                }\n            }\n        }\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_30_AVX", "completion": "```cpp\nbool matrix_rows_sorted_verify_simd(const int* matrix, const bool* directions, size_t rows, size_t cols) {\n    for (size_t r = 0; r < rows; r++) {\n        const int* row = matrix + r * cols;\n        bool ascending = directions[r];\n        \n        size_t col = 0;\n        // Process 8 elements at a time using AVX2\n        for (; col + 8 <= cols; col += 8) {\n            __m256i current = _mm256_loadu_si256((__m256i*)&row[col]);\n            __m256i next = _mm256_loadu_si256((__m256i*)&row[col + 1]);\n            \n            __m256i comparison;\n            if (ascending) {\n                // Check if current <= next for ascending order\n                comparison = _mm256_cmpgt_epi32(current, next);\n            } else {\n                // Check if current >= next for descending order\n                comparison = _mm256_cmpgt_epi32(next, current);\n            }\n            \n            // If any comparison fails, row is not sorted\n            if (_mm256_movemask_epi8(comparison) != 0) {\n                return false;\n            }\n        }\n        \n        // Handle remaining elements\n        for (; col < cols - 1; col++) {\n            if (ascending) {\n                if (row[col] > row[col + 1]) {\n                    return false;\n                }\n            } else {\n                if (row[col] < row[col + 1]) {\n                    return false;\n                }\n            }\n        }\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_30_AVX", "completion": "```cpp\nbool matrix_rows_sorted_verify_simd(const int* matrix, const bool* directions, size_t rows, size_t cols) {\n    for (size_t r = 0; r < rows; r++) {\n        const int* row = matrix + r * cols;\n        bool ascending = directions[r];\n        \n        // Process 8 elements at a time with AVX2\n        size_t vec_cols = cols - (cols % 8);\n        for (size_t c = 0; c < vec_cols; c += 8) {\n            __m256i current = _mm256_loadu_si256((__m256i*)&row[c]);\n            __m256i next = _mm256_loadu_si256((__m256i*)&row[c + 8]);\n            \n            __m256i compare;\n            if (ascending) {\n                // Check if current <= next for ascending order\n                compare = _mm256_cmpgt_epi32(current, next);\n            } else {\n                // Check if current >= next for descending order\n                compare = _mm256_cmpgt_epi32(next, current);\n            }\n            \n            if (_mm256_movemask_ps((__m256)compare) != 0) {\n                return false;\n            }\n        }\n        \n        // Handle remaining elements\n        for (size_t c = vec_cols; c < cols - 1; c++) {\n            if (ascending && row[c] > row[c + 1]) {\n                return false;\n            }\n            if (!ascending && row[c] < row[c + 1]) {\n                return false;\n            }\n        }\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_31_AVX", "completion": "```cpp\nvoid nearest_multiple_simd(const int16_t* src, int16_t* dst, uint8_t base, size_t length) {\n    // Broadcast base to all elements of a vector\n    __m256i base_vec = _mm256_set1_epi16(base);\n    \n    // Process 16 elements at a time (AVX2 allows 16 16-bit integers per vector)\n    size_t vec_length = length - (length % 16);\n    for (size_t i = 0; i < vec_length; i += 16) {\n        // Load 16 source elements\n        __m256i src_vec = _mm256_loadu_si256((__m256i*)&src[i]);\n        \n        // Divide each element by base\n        __m256i div_vec = _mm256_div_epi16(src_vec, base_vec);\n        \n        // Multiply back to get nearest multiple\n        __m256i multiple_vec = _mm256_mullo_epi16(div_vec, base_vec);\n        \n        // Store result in destination\n        _mm256_storeu_si256((__m256i*)&dst[i], multiple_vec);\n    }\n    \n    // Handle remaining elements\n    for (size_t i = vec_length; i < length; i++) {\n        dst[i] = (src[i] / base) * base;\n    }\n}\n```"}
{"task_id": "SimdBench_31_AVX", "completion": "```cpp\nvoid nearest_multiple_simd(const int16_t* src, int16_t* dst, uint8_t base, size_t length) {\n    // Broadcast base to all elements of a vector\n    __m256i base_vec = _mm256_set1_epi16(base);\n    \n    // Process 16 elements at a time (AVX2 allows 16 16-bit integers per vector)\n    size_t vec_length = length - (length % 16);\n    for (size_t i = 0; i < vec_length; i += 16) {\n        // Load 16 source elements\n        __m256i src_vec = _mm256_loadu_si256((__m256i*)&src[i]);\n        \n        // Perform integer division by base and multiply back to get nearest multiple\n        __m256i div_vec = _mm256_div_epi16(src_vec, base_vec);\n        __m256i mult_vec = _mm256_mullo_epi16(div_vec, base_vec);\n        \n        // Store result in destination\n        _mm256_storeu_si256((__m256i*)&dst[i], mult_vec);\n    }\n    \n    // Handle remaining elements\n    for (size_t i = vec_length; i < length; i++) {\n        dst[i] = (src[i] / base) * base;\n    }\n}\n```"}
{"task_id": "SimdBench_31_AVX", "completion": "```cpp\nvoid nearest_multiple_simd(const int16_t* src, int16_t* dst, uint8_t base, size_t length) {\n    // Broadcast base to 16-bit vector\n    __m256i base_vec = _mm256_set1_epi16(base);\n    \n    // Process 16 elements at a time\n    size_t i = 0;\n    for (; i + 16 <= length; i += 16) {\n        // Load source vector\n        __m256i src_vec = _mm256_loadu_si256((__m256i*)&src[i]);\n        \n        // Divide source by base and multiply back to get nearest multiple\n        __m256i div_vec = _mm256_div_epi16(src_vec, base_vec);\n        __m256i mult_vec = _mm256_mullo_epi16(div_vec, base_vec);\n        \n        // Store result\n        _mm256_storeu_si256((__m256i*)&dst[i], mult_vec);\n    }\n    \n    // Handle remaining elements\n    for (; i < length; i++) {\n        dst[i] = (src[i] / base) * base;\n    }\n}\n```"}
{"task_id": "SimdBench_31_AVX", "completion": "```cpp\nvoid nearest_multiple_simd(const int16_t* src, int16_t* dst, uint8_t base, size_t length) {\n    // Broadcast base to all lanes of a vector register\n    __m256i base_vec = _mm256_set1_epi16(base);\n    \n    // Process 16 elements at a time (256-bit AVX register)\n    size_t i;\n    for (i = 0; i + 16 <= length; i += 16) {\n        // Load source vector\n        __m256i src_vec = _mm256_loadu_si256((__m256i*)&src[i]);\n        \n        // Perform integer division by base\n        __m256i div_vec = _mm256_div_epi16(src_vec, base_vec);\n        \n        // Multiply back to get nearest multiple\n        __m256i multiple_vec = _mm256_mullo_epi16(div_vec, base_vec);\n        \n        // Store result in destination\n        _mm256_storeu_si256((__m256i*)&dst[i], multiple_vec);\n    }\n    \n    // Handle remaining elements\n    for (; i < length; i++) {\n        dst[i] = (src[i] / base) * base;\n    }\n}\n```"}
{"task_id": "SimdBench_31_AVX", "completion": "```cpp\nvoid nearest_multiple_simd(const int16_t* src, int16_t* dst, uint8_t base, size_t length) {\n    // Broadcast base to all elements of a vector\n    __m256i base_vec = _mm256_set1_epi16(base);\n    \n    // Vectorized processing in chunks of 16 elements\n    size_t vec_length = length - (length % 16);\n    for (size_t i = 0; i < vec_length; i += 16) {\n        // Load 16 source elements\n        __m256i src_vec = _mm256_loadu_si256((__m256i*)&src[i]);\n        \n        // Divide each element by base\n        __m256i div_vec = _mm256_div_epi16(src_vec, base_vec);\n        \n        // Multiply back to get nearest multiple\n        __m256i multiple_vec = _mm256_mullo_epi16(div_vec, base_vec);\n        \n        // Store result in destination\n        _mm256_storeu_si256((__m256i*)&dst[i], multiple_vec);\n    }\n    \n    // Handle remaining elements sequentially\n    for (size_t i = vec_length; i < length; i++) {\n        dst[i] = (src[i] / base) * base;\n    }\n}\n```"}
{"task_id": "SimdBench_32_AVX", "completion": "```cpp\nbool matrix_has_row_simd(const double* matrix, const double* vector, size_t rows, size_t cols) {\n    // Number of doubles that can be processed in a single AVX vector\n    const int VECTOR_WIDTH = 4;\n\n    // Iterate through each row of the matrix\n    for (size_t r = 0; r < rows; r++) {\n        bool row_match = true;\n\n        // Process 4 doubles at a time using AVX\n        size_t c = 0;\n        for (; c + VECTOR_WIDTH <= cols; c += VECTOR_WIDTH) {\n            // Load matrix row and vector segments\n            __m256d matrix_vec = _mm256_loadu_pd(matrix + r * cols + c);\n            __m256d vector_vec = _mm256_loadu_pd(vector + c);\n\n            // Compare vectors for equality\n            __m256d cmp = _mm256_cmp_pd(matrix_vec, vector_vec, _CMP_EQ_OQ);\n            \n            // Check if all elements match\n            if (_mm256_movemask_pd(cmp) != 0x0F) {\n                row_match = false;\n                break;\n            }\n        }\n\n        // Handle remaining elements if cols is not divisible by 4\n        if (row_match && c < cols) {\n            for (; c < cols; c++) {\n                if (matrix[r * cols + c] != vector[c]) {\n                    row_match = false;\n                    break;\n                }\n            }\n        }\n\n        // If entire row matches, return true\n        if (row_match) {\n            return true;\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_32_AVX", "completion": "```cpp\nbool matrix_has_row_simd(const double* matrix, const double* vector, size_t rows, size_t cols) {\n    // Number of doubles that can be processed in a single AVX vector\n    const int VECTOR_WIDTH = 4;\n\n    // Iterate through each row of the matrix\n    for (size_t row = 0; row < rows; row++) {\n        bool row_match = true;\n\n        // Process 4 doubles at a time using AVX\n        size_t col = 0;\n        for (; col + VECTOR_WIDTH <= cols; col += VECTOR_WIDTH) {\n            // Load matrix row and vector segments\n            __m256d matrix_vec = _mm256_loadu_pd(matrix + row * cols + col);\n            __m256d vector_vec = _mm256_loadu_pd(vector + col);\n\n            // Compare vectors for equality\n            __m256d cmp = _mm256_cmp_pd(matrix_vec, vector_vec, _CMP_EQ_OQ);\n            \n            // Check if all elements match\n            if (_mm256_movemask_pd(cmp) != 0x0F) {\n                row_match = false;\n                break;\n            }\n        }\n\n        // Handle remaining elements\n        for (; col < cols; col++) {\n            if (matrix[row * cols + col] != vector[col]) {\n                row_match = false;\n                break;\n            }\n        }\n\n        // If entire row matches, return true\n        if (row_match) {\n            return true;\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_32_AVX", "completion": "```cpp\nbool matrix_has_row_simd(const double* matrix, const double* vector, size_t rows, size_t cols) {\n    // Number of doubles that can be processed in a single AVX vector\n    const int VECTOR_WIDTH = 4;\n\n    // Iterate through each row of the matrix\n    for (size_t r = 0; r < rows; r++) {\n        bool row_match = true;\n\n        // Process 4 doubles at a time using AVX\n        size_t c = 0;\n        for (; c + VECTOR_WIDTH <= cols; c += VECTOR_WIDTH) {\n            // Load matrix row and vector segments\n            __m256d matrix_vec = _mm256_loadu_pd(matrix + r * cols + c);\n            __m256d vector_vec = _mm256_loadu_pd(vector + c);\n\n            // Compare vectors for equality\n            __m256d cmp = _mm256_cmp_pd(matrix_vec, vector_vec, _CMP_EQ_OQ);\n            \n            // Check if all elements match\n            if (_mm256_movemask_pd(cmp) != 0x0F) {\n                row_match = false;\n                break;\n            }\n        }\n\n        // Handle remaining elements if cols is not divisible by 4\n        if (row_match && c < cols) {\n            for (; c < cols; c++) {\n                if (matrix[r * cols + c] != vector[c]) {\n                    row_match = false;\n                    break;\n                }\n            }\n        }\n\n        // If entire row matches, return true\n        if (row_match) {\n            return true;\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_32_AVX", "completion": "```cpp\nbool matrix_has_row_simd(const double* matrix, const double* vector, size_t rows, size_t cols) {\n    // Number of doubles that can be processed in a single AVX vector\n    const int VECTOR_WIDTH = 4;\n\n    // Iterate through each row of the matrix\n    for (size_t r = 0; r < rows; r++) {\n        bool row_match = true;\n\n        // Process 4 doubles at a time using AVX\n        size_t c = 0;\n        for (; c + VECTOR_WIDTH <= cols; c += VECTOR_WIDTH) {\n            // Load matrix row and vector segments\n            __m256d matrix_vec = _mm256_loadu_pd(matrix + r * cols + c);\n            __m256d vector_vec = _mm256_loadu_pd(vector + c);\n\n            // Compare vectors for equality\n            __m256d cmp = _mm256_cmp_pd(matrix_vec, vector_vec, _CMP_EQ_OQ);\n            \n            // Check if all elements match\n            if (_mm256_movemask_pd(cmp) != 0x0F) {\n                row_match = false;\n                break;\n            }\n        }\n\n        // Handle remaining elements if cols is not divisible by 4\n        for (; c < cols; c++) {\n            if (matrix[r * cols + c] != vector[c]) {\n                row_match = false;\n                break;\n            }\n        }\n\n        // If entire row matches, return true\n        if (row_match) {\n            return true;\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_32_AVX", "completion": "```cpp\nbool matrix_has_row_simd(const double* matrix, const double* vector, size_t rows, size_t cols) {\n    // Number of doubles that can be processed in a single AVX vector\n    const size_t vec_width = 256 / (8 * sizeof(double));\n    \n    // Iterate through each row of the matrix\n    for (size_t r = 0; r < rows; r++) {\n        bool row_match = true;\n        \n        // Process vector elements in AVX-sized chunks\n        size_t c = 0;\n        for (; c + vec_width <= cols; c += vec_width) {\n            // Load matrix row and vector chunks\n            __m256d matrix_chunk = _mm256_loadu_pd(matrix + r * cols + c);\n            __m256d vector_chunk = _mm256_loadu_pd(vector + c);\n            \n            // Compare chunks for equality\n            __m256d cmp_result = _mm256_cmp_pd(matrix_chunk, vector_chunk, _CMP_EQ_OQ);\n            \n            // Check if all elements in chunk match\n            if (_mm256_movemask_pd(cmp_result) != 0x0F) {\n                row_match = false;\n                break;\n            }\n        }\n        \n        // Process remaining elements sequentially\n        if (row_match) {\n            for (; c < cols; c++) {\n                if (matrix[r * cols + c] != vector[c]) {\n                    row_match = false;\n                    break;\n                }\n            }\n        }\n        \n        // If entire row matches, return true\n        if (row_match) {\n            return true;\n        }\n    }\n    \n    return false;\n}\n```"}
{"task_id": "SimdBench_33_AVX", "completion": "```cpp\nsize_t tensor_4d_equal_count_simd(const uint8_t* A, const uint8_t* B, const size_t dims[4]) {\n    size_t total_elements = dims[0] * dims[1] * dims[2] * dims[3];\n    size_t equal_count = 0;\n    \n    // Process 32 bytes (256 bits) at a time using AVX2\n    size_t vec_size = total_elements - (total_elements % 32);\n    \n    __m256i zero_vec = _mm256_setzero_si256();\n    __m256i equal_accumulator = _mm256_setzero_si256();\n    \n    for (size_t i = 0; i < vec_size; i += 32) {\n        __m256i a_vec = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i b_vec = _mm256_loadu_si256((__m256i*)&B[i]);\n        \n        // Compare vectors for equality\n        __m256i equal_mask = _mm256_cmpeq_epi8(a_vec, b_vec);\n        \n        // Count equal elements\n        equal_accumulator = _mm256_add_epi8(equal_accumulator, _mm256_and_si256(equal_mask, _mm256_set1_epi8(1)));\n    }\n    \n    // Horizontal sum of equal elements\n    __m128i low_equal = _mm256_extracti128_si256(equal_accumulator, 0);\n    __m128i high_equal = _mm256_extracti128_si256(equal_accumulator, 1);\n    \n    __m128i sum_equal = _mm_add_epi8(low_equal, high_equal);\n    sum_equal = _mm_add_epi8(sum_equal, _mm_srli_si128(sum_equal, 8));\n    sum_equal = _mm_add_epi8(sum_equal, _mm_srli_si128(sum_equal, 4));\n    sum_equal = _mm_add_epi8(sum_equal, _mm_srli_si128(sum_equal, 2));\n    \n    equal_count += _mm_cvtsi128_si32(sum_equal) & 0xFF;\n    \n    // Handle remaining elements\n    for (size_t i = vec_size; i < total_elements; i++) {\n        if (A[i] == B[i]) {\n            equal_count++;\n        }\n    }\n    \n    return equal_count;\n}\n```"}
{"task_id": "SimdBench_33_AVX", "completion": "```cpp\nsize_t tensor_4d_equal_count_simd(const uint8_t* A, const uint8_t* B, const size_t dims[4]) {\n    size_t total_elements = dims[0] * dims[1] * dims[2] * dims[3];\n    size_t equal_count = 0;\n    \n    // Process 32 bytes (256 bits) at a time using AVX2\n    size_t vec_size = total_elements - (total_elements % 32);\n    \n    __m256i zero_vec = _mm256_setzero_si256();\n    __m256i equal_accumulator = _mm256_setzero_si256();\n    \n    for (size_t i = 0; i < vec_size; i += 32) {\n        __m256i vec_a = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i vec_b = _mm256_loadu_si256((__m256i*)&B[i]);\n        \n        // Compare vectors for equality\n        __m256i equal_mask = _mm256_cmpeq_epi8(vec_a, vec_b);\n        \n        // Count equal elements\n        __m256i popcount = _mm256_sad_epu8(equal_mask, zero_vec);\n        equal_accumulator = _mm256_add_epi64(equal_accumulator, popcount);\n    }\n    \n    // Horizontal sum of equal elements\n    int64_t equal_elements[4];\n    _mm256_storeu_si256((__m256i*)equal_elements, equal_accumulator);\n    equal_count = equal_elements[0] + equal_elements[1] + \n                  equal_elements[2] + equal_elements[3];\n    \n    // Handle remaining elements\n    for (size_t i = vec_size; i < total_elements; i++) {\n        if (A[i] == B[i]) {\n            equal_count++;\n        }\n    }\n    \n    return equal_count;\n}\n```"}
{"task_id": "SimdBench_33_AVX", "completion": "```cpp\nsize_t tensor_4d_equal_count_simd(const uint8_t* A, const uint8_t* B, const size_t dims[4]) {\n    size_t total_elements = dims[0] * dims[1] * dims[2] * dims[3];\n    size_t equal_count = 0;\n    \n    // Process 32 bytes (256 bits) at a time using AVX2\n    size_t vector_size = total_elements - (total_elements % 32);\n    \n    __m256i zero_vec = _mm256_setzero_si256();\n    __m256i equal_accumulator = _mm256_setzero_si256();\n    \n    for (size_t i = 0; i < vector_size; i += 32) {\n        __m256i vec_a = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i vec_b = _mm256_loadu_si256((__m256i*)&B[i]);\n        \n        // Compare vectors for equality\n        __m256i equal_mask = _mm256_cmpeq_epi8(vec_a, vec_b);\n        \n        // Count equal elements\n        __m256i popcount_mask = _mm256_sad_epu8(equal_mask, zero_vec);\n        equal_accumulator = _mm256_add_epi64(equal_accumulator, popcount_mask);\n    }\n    \n    // Horizontal sum of equal elements\n    int64_t equal_elements[4];\n    _mm256_storeu_si256((__m256i*)equal_elements, equal_accumulator);\n    equal_count = equal_elements[0] + equal_elements[1] + \n                  equal_elements[2] + equal_elements[3];\n    \n    // Handle remaining elements\n    for (size_t i = vector_size; i < total_elements; i++) {\n        if (A[i] == B[i]) {\n            equal_count++;\n        }\n    }\n    \n    return equal_count;\n}\n```"}
{"task_id": "SimdBench_33_AVX", "completion": "```cpp\nsize_t tensor_4d_equal_count_simd(const uint8_t* A, const uint8_t* B, const size_t dims[4]) {\n    size_t total_elements = dims[0] * dims[1] * dims[2] * dims[3];\n    size_t equal_count = 0;\n    \n    // Process 32 bytes (256 bits) at a time using AVX2\n    size_t vector_size = total_elements - (total_elements % 32);\n    \n    __m256i equal_accumulator = _mm256_setzero_si256();\n    \n    for (size_t i = 0; i < vector_size; i += 32) {\n        __m256i vec_a = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i vec_b = _mm256_loadu_si256((__m256i*)&B[i]);\n        \n        // Compare vectors for equality\n        __m256i compare_result = _mm256_cmpeq_epi8(vec_a, vec_b);\n        \n        // Accumulate equal elements\n        equal_accumulator = _mm256_add_epi8(equal_accumulator, compare_result);\n    }\n    \n    // Horizontal sum of equal elements\n    __m128i low_128 = _mm256_extracti128_si256(equal_accumulator, 0);\n    __m128i high_128 = _mm256_extracti128_si256(equal_accumulator, 1);\n    \n    __m128i sum_128 = _mm_add_epi8(low_128, high_128);\n    sum_128 = _mm_sad_epu8(sum_128, _mm_setzero_si128());\n    \n    equal_count += _mm_cvtsi128_si32(sum_128);\n    equal_count += _mm_extract_epi32(sum_128, 1);\n    \n    // Process remaining elements\n    for (size_t i = vector_size; i < total_elements; i++) {\n        if (A[i] == B[i]) {\n            equal_count++;\n        }\n    }\n    \n    return equal_count;\n}\n```"}
{"task_id": "SimdBench_33_AVX", "completion": "```cpp\nsize_t tensor_4d_equal_count_simd(const uint8_t* A, const uint8_t* B, const size_t dims[4]) {\n    size_t total_elements = dims[0] * dims[1] * dims[2] * dims[3];\n    size_t equal_count = 0;\n    \n    // Process 32 bytes (256 bits) at a time using AVX2\n    size_t vector_size = total_elements - (total_elements % 32);\n    \n    __m256i zero_vec = _mm256_setzero_si256();\n    __m256i equal_accumulator = _mm256_setzero_si256();\n    \n    for (size_t i = 0; i < vector_size; i += 32) {\n        __m256i a_vec = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i b_vec = _mm256_loadu_si256((__m256i*)&B[i]);\n        \n        // Compare vectors for equality\n        __m256i equal_mask = _mm256_cmpeq_epi8(a_vec, b_vec);\n        \n        // Count equal elements\n        __m256i popcount_mask = _mm256_sad_epu8(equal_mask, zero_vec);\n        equal_accumulator = _mm256_add_epi64(equal_accumulator, popcount_mask);\n    }\n    \n    // Horizontal sum of equal_accumulator\n    int64_t equal_counts[4];\n    _mm256_storeu_si256((__m256i*)equal_counts, equal_accumulator);\n    equal_count = equal_counts[0] + equal_counts[1] + equal_counts[2] + equal_counts[3];\n    \n    // Handle remaining elements\n    for (size_t i = vector_size; i < total_elements; i++) {\n        if (A[i] == B[i]) {\n            equal_count++;\n        }\n    }\n    \n    return equal_count;\n}\n```"}
{"task_id": "SimdBench_34_AVX", "completion": "```cpp\nvoid axm_abs_simd(size_t length, const int64_t a, const int64_t *x, int64_t *y) {\n    __m256i scalar_vec = _mm256_set1_epi64x(a);\n    \n    for (size_t i = 0; i < length; i += 4) {\n        __m256i x_vec = _mm256_loadu_si256((__m256i*)&x[i]);\n        __m256i mul_vec = _mm256_mul_epi64(x_vec, scalar_vec);\n        __m256i abs_vec = _mm256_abs_epi64(mul_vec);\n        _mm256_storeu_si256((__m256i*)&y[i], abs_vec);\n    }\n}\n```"}
{"task_id": "SimdBench_34_AVX", "completion": "```cpp\nvoid axm_abs_simd(size_t length, const int64_t a, const int64_t *x, int64_t *y) {\n    __m256i scalar_vec = _mm256_set1_epi64x(a);\n    \n    for (size_t i = 0; i < length; i += 4) {\n        __m256i x_vec = _mm256_loadu_si256((__m256i*)&x[i]);\n        __m256i mult_vec = _mm256_mul_epi64(x_vec, scalar_vec);\n        __m256i abs_vec = _mm256_abs_epi64(mult_vec);\n        _mm256_storeu_si256((__m256i*)&y[i], abs_vec);\n    }\n}\n```"}
{"task_id": "SimdBench_34_AVX", "completion": "```cpp\nvoid axm_abs_simd(size_t length, const int64_t a, const int64_t *x, int64_t *y) {\n    __m256i scalar_vec = _mm256_set1_epi64x(a);\n    \n    for (size_t i = 0; i < length; i += 4) {\n        __m256i x_vec = _mm256_loadu_si256((__m256i*)&x[i]);\n        __m256i mul_vec = _mm256_mul_epi64(x_vec, scalar_vec);\n        __m256i abs_vec = _mm256_abs_epi64(mul_vec);\n        _mm256_storeu_si256((__m256i*)&y[i], abs_vec);\n    }\n}\n```"}
{"task_id": "SimdBench_34_AVX", "completion": "```cpp\nvoid axm_abs_simd(size_t length, const int64_t a, const int64_t *x, int64_t *y) {\n    const __m256i scalar_vec = _mm256_set1_epi64x(a);\n    \n    for (size_t i = 0; i < length; i += 4) {\n        __m256i x_vec = _mm256_loadu_si256((__m256i*)&x[i]);\n        __m256i mul_vec = _mm256_mul_epi64(x_vec, scalar_vec);\n        __m256i abs_vec = _mm256_abs_epi64(mul_vec);\n        _mm256_storeu_si256((__m256i*)&y[i], abs_vec);\n    }\n}\n```"}
{"task_id": "SimdBench_34_AVX", "completion": "```cpp\nvoid axm_abs_simd(size_t length, const int64_t a, const int64_t *x, int64_t *y) {\n    __m256i scalar_vec = _mm256_set1_epi64x(a);\n    \n    for (size_t i = 0; i < length; i += 4) {\n        __m256i x_vec = _mm256_loadu_si256((__m256i*)&x[i]);\n        __m256i mul_vec = _mm256_mul_epi64(x_vec, scalar_vec);\n        __m256i abs_vec = _mm256_abs_epi64(mul_vec);\n        _mm256_storeu_si256((__m256i*)&y[i], abs_vec);\n    }\n}\n```"}
{"task_id": "SimdBench_35_AVX", "completion": "```cpp\nMinMaxPair min_max_pair_simd(const int16_t* vec, size_t length) {\n    MinMaxPair result = {INT16_MAX, INT16_MIN};\n    \n    size_t i = 0;\n    const size_t vector_width = 16; // AVX2 can process 16 16-bit integers at once\n    \n    // Process vectors in chunks of 16\n    for (; i + vector_width <= length; i += vector_width) {\n        __m256i current_vector = _mm256_loadu_si256((__m256i*)&vec[i]);\n        \n        // Separate lower and upper halves\n        __m256i lower_half = _mm256_unpacklo_epi16(current_vector, current_vector);\n        __m256i upper_half = _mm256_unpackhi_epi16(current_vector, current_vector);\n        \n        // Find min and max in lower half\n        __m256i min_lower = _mm256_min_epi16(lower_half, _mm256_shuffle_epi32(lower_half, _MM_SHUFFLE(1, 0, 3, 2)));\n        __m256i max_lower = _mm256_max_epi16(lower_half, _mm256_shuffle_epi32(lower_half, _MM_SHUFFLE(1, 0, 3, 2)));\n        \n        // Find min and max in upper half\n        __m256i min_upper = _mm256_min_epi16(upper_half, _mm256_shuffle_epi32(upper_half, _MM_SHUFFLE(1, 0, 3, 2)));\n        __m256i max_upper = _mm256_max_epi16(upper_half, _mm256_shuffle_epi32(upper_half, _MM_SHUFFLE(1, 0, 3, 2)));\n        \n        // Horizontal reduction\n        int16_t min_vals[16], max_vals[16];\n        _mm256_storeu_si256((__m256i*)min_vals, _mm256_min_epi16(min_lower, min_upper));\n        _mm256_storeu_si256((__m256i*)max_vals, _mm256_max_epi16(max_lower, max_upper));\n        \n        // Update result\n        for (int j = 0; j < 16; j++) {\n            result.min_num = (min_vals[j] < result.min_num) ? min_vals[j] : result.min_num;\n            result.max_num = (max_vals[j] > result.max_num) ? max_vals[j] : result.max_num;\n        }\n    }\n    \n    // Handle remaining elements\n    for (; i < length; i++) {\n        result.min_num = (vec[i] < result.min_num) ? vec[i] : result.min_num;\n        result.max_num = (vec[i] > result.max_num) ? vec[i] : result.max_num;\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_35_AVX", "completion": "```cpp\nMinMaxPair min_max_pair_simd(const int16_t* vec, size_t length) {\n    MinMaxPair result = {INT16_MAX, INT16_MIN};\n    \n    size_t i = 0;\n    // Process 16 elements at a time using AVX2\n    for (; i + 16 <= length; i += 16) {\n        __m256i current_vec = _mm256_loadu_si256((__m256i*)&vec[i]);\n        \n        // Separate lower and upper halves\n        __m256i low_half = _mm256_unpacklo_epi16(current_vec, _mm256_setzero_si256());\n        __m256i high_half = _mm256_unpackhi_epi16(current_vec, _mm256_setzero_si256());\n        \n        // Find min and max in each half\n        __m256i min_vec = _mm256_min_epi16(low_half, high_half);\n        __m256i max_vec = _mm256_max_epi16(low_half, high_half);\n        \n        // Horizontal min and max\n        __m128i min_low = _mm_min_epi16(_mm256_extracti128_si256(min_vec, 0), \n                                        _mm256_extracti128_si256(min_vec, 1));\n        __m128i max_low = _mm_max_epi16(_mm256_extracti128_si256(max_vec, 0), \n                                        _mm256_extracti128_si256(max_vec, 1));\n        \n        min_low = _mm_min_epi16(min_low, _mm_shuffle_epi32(min_low, _MM_SHUFFLE(1, 0, 3, 2)));\n        min_low = _mm_min_epi16(min_low, _mm_shuffle_epi32(min_low, _MM_SHUFFLE(0, 1, 2, 3)));\n        \n        max_low = _mm_max_epi16(max_low, _mm_shuffle_epi32(max_low, _MM_SHUFFLE(1, 0, 3, 2)));\n        max_low = _mm_max_epi16(max_low, _mm_shuffle_epi32(max_low, _MM_SHUFFLE(0, 1, 2, 3)));\n        \n        result.min_num = _mm_cvtsi128_si32(min_low);\n        result.max_num = _mm_cvtsi128_si32(max_low);\n    }\n    \n    // Handle remaining elements\n    for (; i < length; i++) {\n        result.min_num = (vec[i] < result.min_num) ? vec[i] : result.min_num;\n        result.max_num = (vec[i] > result.max_num) ? vec[i] : result.max_num;\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_35_AVX", "completion": "```cpp\nMinMaxPair min_max_pair_simd(const int16_t* vec, size_t length) {\n    MinMaxPair result = {INT16_MAX, INT16_MIN};\n    \n    size_t i = 0;\n    const size_t vector_size = 16; // AVX2 can process 16 int16_t values at once\n    \n    // Process full vector chunks\n    for (; i + vector_size <= length; i += vector_size) {\n        __m256i current_vector = _mm256_loadu_si256((__m256i*)&vec[i]);\n        \n        // Separate lower and upper halves\n        __m256i lower_half = _mm256_unpacklo_epi16(current_vector, current_vector);\n        __m256i upper_half = _mm256_unpackhi_epi16(current_vector, current_vector);\n        \n        // Find min and max in lower half\n        __m256i min_lower = _mm256_min_epi16(lower_half, _mm256_shuffle_epi32(lower_half, _MM_SHUFFLE(1, 0, 3, 2)));\n        __m256i max_lower = _mm256_max_epi16(lower_half, _mm256_shuffle_epi32(lower_half, _MM_SHUFFLE(1, 0, 3, 2)));\n        \n        // Find min and max in upper half\n        __m256i min_upper = _mm256_min_epi16(upper_half, _mm256_shuffle_epi32(upper_half, _MM_SHUFFLE(1, 0, 3, 2)));\n        __m256i max_upper = _mm256_max_epi16(upper_half, _mm256_shuffle_epi32(upper_half, _MM_SHUFFLE(1, 0, 3, 2)));\n        \n        // Horizontal min and max\n        int16_t min_vals[16], max_vals[16];\n        _mm256_storeu_si256((__m256i*)min_vals, _mm256_min_epi16(min_lower, min_upper));\n        _mm256_storeu_si256((__m256i*)max_vals, _mm256_max_epi16(max_lower, max_upper));\n        \n        // Update global min and max\n        for (int j = 0; j < 16; j++) {\n            result.min_num = (min_vals[j] < result.min_num) ? min_vals[j] : result.min_num;\n            result.max_num = (max_vals[j] > result.max_num) ? max_vals[j] : result.max_num;\n        }\n    }\n    \n    // Process remaining elements\n    for (; i < length; i++) {\n        result.min_num = (vec[i] < result.min_num) ? vec[i] : result.min_num;\n        result.max_num = (vec[i] > result.max_num) ? vec[i] : result.max_num;\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_35_AVX", "completion": "```cpp\nMinMaxPair min_max_pair_simd(const int16_t* vec, size_t length) {\n    MinMaxPair result = {INT16_MAX, INT16_MIN};\n    \n    size_t i = 0;\n    // Process 16 elements at a time using AVX2\n    for (; i + 16 <= length; i += 16) {\n        __m256i current_vec = _mm256_loadu_si256((__m256i*)&vec[i]);\n        \n        // Separate into low and high halves\n        __m256i low_half = _mm256_unpacklo_epi16(current_vec, _mm256_setzero_si256());\n        __m256i high_half = _mm256_unpackhi_epi16(current_vec, _mm256_setzero_si256());\n        \n        // Find min and max in low half\n        __m256i min_low = _mm256_min_epi16(current_vec, _mm256_shuffle_epi32(current_vec, _MM_SHUFFLE(1, 0, 3, 2)));\n        min_low = _mm256_min_epi16(min_low, _mm256_shuffle_epi32(min_low, _MM_SHUFFLE(0, 1, 2, 3)));\n        \n        __m256i max_low = _mm256_max_epi16(current_vec, _mm256_shuffle_epi32(current_vec, _MM_SHUFFLE(1, 0, 3, 2)));\n        max_low = _mm256_max_epi16(max_low, _mm256_shuffle_epi32(max_low, _MM_SHUFFLE(0, 1, 2, 3)));\n        \n        // Update global min and max\n        result.min_num = _mm256_extract_epi16(min_low, 0) < result.min_num ? \n                         _mm256_extract_epi16(min_low, 0) : result.min_num;\n        result.max_num = _mm256_extract_epi16(max_low, 0) > result.max_num ? \n                         _mm256_extract_epi16(max_low, 0) : result.max_num;\n    }\n    \n    // Handle remaining elements\n    for (; i < length; i++) {\n        result.min_num = vec[i] < result.min_num ? vec[i] : result.min_num;\n        result.max_num = vec[i] > result.max_num ? vec[i] : result.max_num;\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_35_AVX", "completion": "```cpp\nMinMaxPair min_max_pair_simd(const int16_t* vec, size_t length) {\n    MinMaxPair result = {INT16_MAX, INT16_MIN};\n    \n    size_t i = 0;\n    for (; i + 16 <= length; i += 16) {\n        __m256i current = _mm256_loadu_si256((__m256i*)&vec[i]);\n        \n        __m256i min_vec = _mm256_min_epi16(current, _mm256_shuffle_epi32(current, _MM_SHUFFLE(1, 0, 3, 2)));\n        min_vec = _mm256_min_epi16(min_vec, _mm256_shuffle_epi32(min_vec, _MM_SHUFFLE(0, 1, 2, 3)));\n        min_vec = _mm256_min_epi16(min_vec, _mm256_srli_si256(min_vec, 8));\n        \n        __m256i max_vec = _mm256_max_epi16(current, _mm256_shuffle_epi32(current, _MM_SHUFFLE(1, 0, 3, 2)));\n        max_vec = _mm256_max_epi16(max_vec, _mm256_shuffle_epi32(max_vec, _MM_SHUFFLE(0, 1, 2, 3)));\n        max_vec = _mm256_max_epi16(max_vec, _mm256_srli_si256(max_vec, 8));\n        \n        result.min_num = std::min(result.min_num, _mm256_extract_epi16(min_vec, 0));\n        result.max_num = std::max(result.max_num, _mm256_extract_epi16(max_vec, 0));\n    }\n    \n    for (; i < length; i++) {\n        result.min_num = std::min(result.min_num, vec[i]);\n        result.max_num = std::max(result.max_num, vec[i]);\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_36_AVX", "completion": "```cpp\nbool matrix_rows_strictly_increasing_simd(const int* matrix, size_t rows, size_t cols) {\n    if (rows == 0 || cols == 0) return false;\n\n    for (size_t r = 0; r < rows; r++) {\n        const int* row = matrix + r * cols;\n        \n        // Process 8 elements at a time with AVX\n        size_t vec_limit = cols - (cols % 8);\n        for (size_t c = 0; c < vec_limit; c += 8) {\n            __m256i current = _mm256_loadu_si256((__m256i*)&row[c]);\n            __m256i next = _mm256_loadu_si256((__m256i*)&row[c + 1]);\n            \n            // Compare if each element is less than the next\n            __m256i cmp = _mm256_cmpgt_epi32(current, next);\n            \n            // If any element is not less than the next, return false\n            if (_mm256_movemask_ps((__m256)cmp) != 0) {\n                return false;\n            }\n        }\n        \n        // Handle remaining elements\n        for (size_t c = vec_limit; c < cols - 1; c++) {\n            if (row[c] >= row[c + 1]) {\n                return false;\n            }\n        }\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_36_AVX", "completion": "```cpp\nbool matrix_rows_strictly_increasing_simd(const int* matrix, size_t rows, size_t cols) {\n    if (rows == 0 || cols == 0) return false;\n\n    for (size_t r = 0; r < rows; r++) {\n        const int* row = matrix + r * cols;\n        \n        // Process 8 elements at a time using AVX2\n        size_t vec_limit = cols - (cols % 8);\n        for (size_t c = 0; c < vec_limit; c += 8) {\n            __m256i current = _mm256_loadu_si256((__m256i*)&row[c]);\n            __m256i next = _mm256_loadu_si256((__m256i*)&row[c + 1]);\n            \n            // Compare if each element is less than the next\n            __m256i cmp = _mm256_cmpgt_epi32(current, next);\n            \n            // If any element is not less than the next, return false\n            if (_mm256_movemask_ps((__m256)cmp) != 0) {\n                return false;\n            }\n        }\n        \n        // Handle remaining elements\n        for (size_t c = vec_limit; c < cols - 1; c++) {\n            if (row[c] >= row[c + 1]) {\n                return false;\n            }\n        }\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_36_AVX", "completion": "```cpp\nbool matrix_rows_strictly_increasing_simd(const int* matrix, size_t rows, size_t cols) {\n    if (rows == 0 || cols == 0) return false;\n\n    for (size_t r = 0; r < rows; r++) {\n        const int* row = matrix + r * cols;\n        \n        // Process 8 elements at a time using AVX2\n        size_t vec_limit = cols - (cols % 8);\n        for (size_t c = 0; c < vec_limit; c += 8) {\n            __m256i current = _mm256_loadu_si256((__m256i*)&row[c]);\n            __m256i next = _mm256_loadu_si256((__m256i*)&row[c + 1]);\n            \n            // Compare if each element is less than the next\n            __m256i comparison = _mm256_cmpgt_epi32(current, next);\n            \n            // If any element is not less than the next, return false\n            if (_mm256_movemask_ps((__m256)comparison) != 0) {\n                return false;\n            }\n        }\n        \n        // Handle remaining elements\n        for (size_t c = vec_limit; c < cols - 1; c++) {\n            if (row[c] >= row[c + 1]) {\n                return false;\n            }\n        }\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_36_AVX", "completion": "```cpp\nbool matrix_rows_strictly_increasing_simd(const int* matrix, size_t rows, size_t cols) {\n    if (rows == 0 || cols == 0) return false;\n\n    for (size_t r = 0; r < rows; r++) {\n        const int* row = matrix + r * cols;\n        \n        // Process 8 elements at a time using AVX2\n        size_t vec_cols = cols - (cols % 8);\n        for (size_t c = 0; c + 8 <= vec_cols; c += 8) {\n            __m256i current = _mm256_loadu_si256((__m256i*)&row[c]);\n            __m256i next = _mm256_loadu_si256((__m256i*)&row[c + 1]);\n            \n            // Check if each element is less than the next\n            __m256i cmp = _mm256_cmpgt_epi32(current, next);\n            if (_mm256_movemask_epi8(cmp) != 0) {\n                return false;\n            }\n        }\n        \n        // Handle remaining elements\n        for (size_t c = vec_cols; c + 1 < cols; c++) {\n            if (row[c] >= row[c + 1]) {\n                return false;\n            }\n        }\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_36_AVX", "completion": "```cpp\nbool matrix_rows_strictly_increasing_simd(const int* matrix, size_t rows, size_t cols) {\n    if (rows == 0 || cols == 0) return false;\n\n    for (size_t r = 0; r < rows; r++) {\n        const int* row = matrix + r * cols;\n        \n        // Process 8 elements at a time using AVX2\n        size_t vec_limit = cols - (cols % 8);\n        for (size_t c = 0; c < vec_limit; c += 8) {\n            __m256i current = _mm256_loadu_si256((__m256i*)&row[c]);\n            __m256i next = _mm256_loadu_si256((__m256i*)&row[c + 1]);\n            \n            // Compare if each element is less than the next\n            __m256i compare = _mm256_cmpgt_epi32(current, next);\n            \n            // If any element is not less than the next, return false\n            if (_mm256_movemask_epi8(compare) != 0) {\n                return false;\n            }\n        }\n        \n        // Handle remaining elements\n        for (size_t c = vec_limit; c < cols - 1; c++) {\n            if (row[c] >= row[c + 1]) {\n                return false;\n            }\n        }\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_37_AVX", "completion": "```cpp\nbool matrix_blocks_equal_simd(const int* matrix, size_t block_size, size_t rows, size_t cols) {\n    // Check if block_size is valid\n    if (block_size == 0 || block_size > rows || block_size > cols) {\n        return false;\n    }\n\n    // Check if matrix can be perfectly divided into blocks\n    if (rows % block_size != 0 || cols % block_size != 0) {\n        return false;\n    }\n\n    size_t num_block_rows = rows / block_size;\n    size_t num_block_cols = cols / block_size;\n\n    // Reference block (first block)\n    const int* ref_block = matrix;\n\n    // Iterate through blocks\n    for (size_t block_row = 1; block_row < num_block_rows; ++block_row) {\n        for (size_t block_col = 0; block_col < num_block_cols; ++block_col) {\n            const int* current_block = matrix + (block_row * block_size * cols + block_col * block_size);\n\n            // Compare blocks using AVX2 256-bit vector comparisons\n            for (size_t i = 0; i < block_size; ++i) {\n                for (size_t j = 0; j < block_size; j += 8) {\n                    size_t remaining = block_size - j;\n                    __m256i ref_vec, curr_vec;\n\n                    if (remaining >= 8) {\n                        ref_vec = _mm256_loadu_si256((__m256i*)&ref_block[i * block_size + j]);\n                        curr_vec = _mm256_loadu_si256((__m256i*)&current_block[i * cols + j]);\n                    } else {\n                        // Handle remaining elements with masked load\n                        ref_vec = _mm256_maskload_epi32(&ref_block[i * block_size + j], _mm256_set1_epi32(-1));\n                        curr_vec = _mm256_maskload_epi32(&current_block[i * cols + j], _mm256_set1_epi32(-1));\n                    }\n\n                    __m256i cmp_result = _mm256_cmpeq_epi32(ref_vec, curr_vec);\n                    if (_mm256_movemask_epi8(cmp_result) != 0xFFFFFFFF) {\n                        return false;\n                    }\n                }\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_37_AVX", "completion": "```cpp\nbool matrix_blocks_equal_simd(const int* matrix, size_t block_size, size_t rows, size_t cols) {\n    // Check for invalid block size or matrix dimensions\n    if (block_size == 0 || rows % block_size != 0 || cols % block_size != 0) {\n        return false;\n    }\n\n    size_t num_block_rows = rows / block_size;\n    size_t num_block_cols = cols / block_size;\n\n    // Reference block (first block)\n    const int* ref_block = matrix;\n\n    // Process 8 integers at a time using AVX2\n    for (size_t block_row = 0; block_row < num_block_rows; ++block_row) {\n        for (size_t block_col = 0; block_col < num_block_cols; ++block_col) {\n            if (block_row == 0 && block_col == 0) continue; // Skip first block\n\n            const int* current_block = matrix + (block_row * num_block_cols + block_col) * block_size * block_size;\n\n            for (size_t i = 0; i < block_size; ++i) {\n                for (size_t j = 0; j < block_size; j += 8) {\n                    size_t remaining = std::min(8, static_cast<int>(block_size - j));\n                    \n                    __m256i ref_vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(ref_block + i * block_size + j));\n                    __m256i curr_vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(current_block + i * block_size + j));\n                    \n                    __m256i cmp_mask = _mm256_cmpeq_epi32(ref_vec, curr_vec);\n                    int mask = _mm256_movemask_ps(_mm256_castsi256_ps(cmp_mask));\n                    \n                    if (mask != ((1 << remaining) - 1)) {\n                        return false;\n                    }\n                }\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_37_AVX", "completion": "```cpp\nbool matrix_blocks_equal_simd(const int* matrix, size_t block_size, size_t rows, size_t cols) {\n    // Check for invalid block size or matrix dimensions\n    if (block_size == 0 || rows % block_size != 0 || cols % block_size != 0) {\n        return false;\n    }\n\n    size_t num_block_rows = rows / block_size;\n    size_t num_block_cols = cols / block_size;\n\n    // Reference block (first block)\n    const int* ref_block = matrix;\n\n    // Process 8 integers at a time using AVX2\n    for (size_t block_row = 0; block_row < num_block_rows; ++block_row) {\n        for (size_t block_col = 0; block_col < num_block_cols; ++block_col) {\n            if (block_row == 0 && block_col == 0) continue; // Skip first block\n\n            const int* current_block = matrix + (block_row * num_block_cols + block_col) * block_size * block_size;\n\n            for (size_t i = 0; i < block_size; ++i) {\n                for (size_t j = 0; j < block_size; j += 8) {\n                    size_t remaining = block_size - j;\n                    __m256i ref_vec, curr_vec;\n\n                    if (remaining >= 8) {\n                        ref_vec = _mm256_loadu_si256((__m256i*)&ref_block[i * block_size + j]);\n                        curr_vec = _mm256_loadu_si256((__m256i*)&current_block[i * block_size + j]);\n                    } else {\n                        // Handle edge case with fewer than 8 elements\n                        ref_vec = _mm256_setzero_si256();\n                        curr_vec = _mm256_setzero_si256();\n                        \n                        for (size_t k = 0; k < remaining; ++k) {\n                            ref_vec = _mm256_insert_epi32(ref_vec, ref_block[i * block_size + j + k], k);\n                            curr_vec = _mm256_insert_epi32(curr_vec, current_block[i * block_size + j + k], k);\n                        }\n                    }\n\n                    __m256i cmp = _mm256_cmpeq_epi32(ref_vec, curr_vec);\n                    if (_mm256_movemask_epi8(cmp) != 0xFFFFFFFF) {\n                        return false;\n                    }\n                }\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_37_AVX", "completion": "```cpp\nbool matrix_blocks_equal_simd(const int* matrix, size_t block_size, size_t rows, size_t cols) {\n    // Check if block_size is valid\n    if (block_size == 0 || rows % block_size != 0 || cols % block_size != 0) {\n        return false;\n    }\n\n    size_t num_block_rows = rows / block_size;\n    size_t num_block_cols = cols / block_size;\n\n    // Reference block (first block)\n    const int* ref_block = matrix;\n\n    // Process 8 integers at a time using AVX2\n    for (size_t block_row = 0; block_row < num_block_rows; ++block_row) {\n        for (size_t block_col = 0; block_col < num_block_cols; ++block_col) {\n            if (block_row == 0 && block_col == 0) continue; // Skip first block\n\n            const int* current_block = matrix + (block_row * num_block_cols + block_col) * block_size * block_size;\n\n            for (size_t i = 0; i < block_size; ++i) {\n                size_t j = 0;\n                // Process 8 integers at a time\n                for (; j + 8 <= block_size; j += 8) {\n                    __m256i ref_vec = _mm256_loadu_si256((__m256i*)(ref_block + i * block_size + j));\n                    __m256i curr_vec = _mm256_loadu_si256((__m256i*)(current_block + i * block_size + j));\n                    \n                    __m256i cmp = _mm256_cmpeq_epi32(ref_vec, curr_vec);\n                    if (_mm256_movemask_epi8(cmp) != 0xFFFFFFFF) {\n                        return false;\n                    }\n                }\n\n                // Handle remaining elements\n                for (; j < block_size; ++j) {\n                    if (ref_block[i * block_size + j] != current_block[i * block_size + j]) {\n                        return false;\n                    }\n                }\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_37_AVX", "completion": "```cpp\nbool matrix_blocks_equal_simd(const int* matrix, size_t block_size, size_t rows, size_t cols) {\n    // Check if block_size is valid\n    if (block_size == 0 || rows % block_size != 0 || cols % block_size != 0) {\n        return false;\n    }\n\n    size_t num_block_rows = rows / block_size;\n    size_t num_block_cols = cols / block_size;\n\n    // Reference block (first block)\n    const int* ref_block = matrix;\n\n    // Iterate through blocks\n    for (size_t block_row = 1; block_row < num_block_rows; ++block_row) {\n        for (size_t block_col = 0; block_col < num_block_cols; ++block_col) {\n            // Starting point of current block\n            const int* current_block = matrix + (block_row * block_size * cols + block_col * block_size);\n\n            // Process block using AVX2 256-bit vectors\n            for (size_t i = 0; i < block_size; ++i) {\n                for (size_t j = 0; j < block_size; j += 8) {\n                    // Remaining elements less than 8\n                    size_t remaining = (block_size - j < 8) ? block_size - j : 8;\n\n                    __m256i ref_vec = _mm256_loadu_si256((__m256i*)(ref_block + i * cols + j));\n                    __m256i curr_vec = _mm256_loadu_si256((__m256i*)(current_block + i * cols + j));\n\n                    // Compare vectors\n                    __m256i cmp_mask = _mm256_cmpeq_epi32(ref_vec, curr_vec);\n                    int mask = _mm256_movemask_ps(_mm256_castsi256_ps(cmp_mask));\n\n                    // If not all elements match, return false\n                    if (mask != ((1 << remaining) - 1)) {\n                        return false;\n                    }\n                }\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_38_AVX", "completion": "```cpp\nbool vector_block_equal_simd(const double* vec, double tolerance, size_t length, size_t block_size) {\n    // Check for invalid inputs\n    if (!vec || length == 0 || block_size == 0 || block_size > length) {\n        return false;\n    }\n\n    // Number of complete blocks\n    size_t num_blocks = length / block_size;\n    if (num_blocks < 2) {\n        return false;\n    }\n\n    // Load first block into AVX registers\n    __m256d first_block[block_size / 4];\n    for (size_t j = 0; j < block_size / 4; ++j) {\n        first_block[j] = _mm256_loadu_pd(vec + j * 4);\n    }\n\n    // Process remaining complete blocks\n    for (size_t i = 1; i < num_blocks; ++i) {\n        for (size_t j = 0; j < block_size / 4; ++j) {\n            __m256d current_block = _mm256_loadu_pd(vec + i * block_size + j * 4);\n            \n            // Compute absolute difference\n            __m256d diff = _mm256_sub_pd(first_block[j], current_block);\n            __m256d abs_diff = _mm256_andnot_pd(_mm256_set1_pd(-0.0), diff);\n            \n            // Compare against tolerance\n            __m256d tolerance_vec = _mm256_set1_pd(tolerance);\n            __m256d cmp = _mm256_cmp_pd(abs_diff, tolerance_vec, _CMP_GT_OQ);\n            \n            // If any element exceeds tolerance, return false\n            if (_mm256_movemask_pd(cmp) != 0) {\n                return false;\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_38_AVX", "completion": "```cpp\nbool vector_block_equal_simd(const double* vec, double tolerance, size_t length, size_t block_size) {\n    // Check for illegal inputs\n    if (!vec || length == 0 || block_size == 0 || block_size > length) {\n        return false;\n    }\n\n    // Calculate number of complete blocks\n    size_t num_blocks = (length - block_size) / block_size + 1;\n    if (num_blocks <= 1) {\n        return false;\n    }\n\n    // Load first block into AVX registers\n    __m256d first_block[block_size / 4];\n    for (size_t j = 0; j < block_size / 4; ++j) {\n        first_block[j] = _mm256_loadu_pd(vec + j * 4);\n    }\n\n    // Process remaining blocks\n    for (size_t block = 1; block < num_blocks; ++block) {\n        size_t start_idx = block * block_size;\n\n        for (size_t j = 0; j < block_size / 4; ++j) {\n            __m256d current_block = _mm256_loadu_pd(vec + start_idx + j * 4);\n            \n            // Compare absolute difference against tolerance\n            __m256d diff = _mm256_sub_pd(first_block[j], current_block);\n            __m256d abs_diff = _mm256_andnot_pd(_mm256_set1_pd(-0.0), diff);\n            __m256d tolerance_vec = _mm256_set1_pd(tolerance);\n            \n            // Check if any element exceeds tolerance\n            __m256d cmp = _mm256_cmp_pd(abs_diff, tolerance_vec, _CMP_GT_OQ);\n            if (_mm256_movemask_pd(cmp)) {\n                return false;\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_38_AVX", "completion": "```cpp\nbool vector_block_equal_simd(const double* vec, double tolerance, size_t length, size_t block_size) {\n    // Check for illegal inputs\n    if (!vec || length == 0 || block_size == 0 || block_size > length) {\n        return false;\n    }\n\n    // Calculate number of complete blocks\n    size_t num_blocks = length / block_size;\n    if (num_blocks < 2) {\n        return false;\n    }\n\n    // Load first block into AVX registers\n    __m256d first_block[block_size / 4];\n    for (size_t j = 0; j < block_size / 4; ++j) {\n        first_block[j] = _mm256_loadu_pd(vec + j * 4);\n    }\n\n    // Process remaining blocks\n    for (size_t i = 1; i < num_blocks; ++i) {\n        size_t block_start = i * block_size;\n        \n        for (size_t j = 0; j < block_size / 4; ++j) {\n            __m256d current_block = _mm256_loadu_pd(vec + block_start + j * 4);\n            \n            // Compare absolute differences against tolerance\n            __m256d diff = _mm256_sub_pd(first_block[j], current_block);\n            __m256d abs_diff = _mm256_andnot_pd(_mm256_set1_pd(-0.0), diff);\n            __m256d tolerance_vec = _mm256_set1_pd(tolerance);\n            \n            // Check if any element exceeds tolerance\n            __m256d cmp = _mm256_cmp_pd(abs_diff, tolerance_vec, _CMP_GT_OQ);\n            if (_mm256_movemask_pd(cmp) != 0) {\n                return false;\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_38_AVX", "completion": "```cpp\nbool vector_block_equal_simd(const double* vec, double tolerance, size_t length, size_t block_size) {\n    // Check for invalid inputs\n    if (!vec || length == 0 || block_size == 0 || block_size > length) {\n        return false;\n    }\n\n    // Calculate number of complete blocks\n    size_t num_blocks = (length - block_size) / block_size + 1;\n    if (num_blocks <= 1) {\n        return false;\n    }\n\n    // Load first block into AVX registers\n    __m256d first_block[block_size / 4];\n    for (size_t j = 0; j < block_size / 4; ++j) {\n        first_block[j] = _mm256_loadu_pd(&vec[j * 4]);\n    }\n\n    // Compare subsequent blocks\n    for (size_t block = 1; block < num_blocks; ++block) {\n        size_t start_idx = block * block_size;\n        \n        for (size_t j = 0; j < block_size / 4; ++j) {\n            __m256d current_block = _mm256_loadu_pd(&vec[start_idx + j * 4]);\n            \n            // Compute absolute difference\n            __m256d diff = _mm256_sub_pd(first_block[j], current_block);\n            __m256d abs_diff = _mm256_andnot_pd(_mm256_set1_pd(-0.0), diff);\n            \n            // Compare with tolerance\n            __m256d tolerance_vec = _mm256_set1_pd(tolerance);\n            __m256d cmp = _mm256_cmp_pd(abs_diff, tolerance_vec, _CMP_GT_OQ);\n            \n            // If any element exceeds tolerance, return false\n            if (_mm256_movemask_pd(cmp)) {\n                return false;\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_38_AVX", "completion": "```cpp\nbool vector_block_equal_simd(const double* vec, double tolerance, size_t length, size_t block_size) {\n    // Check for invalid inputs\n    if (!vec || length == 0 || block_size == 0 || block_size > length) {\n        return false;\n    }\n\n    // Calculate number of complete blocks\n    size_t num_blocks = (length - block_size) / block_size + 1;\n    if (num_blocks <= 1) {\n        return false;\n    }\n\n    // Load first block into AVX registers\n    __m256d first_block[block_size / 4];\n    for (size_t i = 0; i < block_size / 4; ++i) {\n        first_block[i] = _mm256_loadu_pd(&vec[i * 4]);\n    }\n\n    // Process remaining blocks\n    for (size_t block = 1; block < num_blocks; ++block) {\n        size_t block_start = block * block_size;\n        \n        for (size_t i = 0; i < block_size / 4; ++i) {\n            __m256d current_block = _mm256_loadu_pd(&vec[block_start + i * 4]);\n            \n            // Compute absolute difference\n            __m256d diff = _mm256_sub_pd(first_block[i], current_block);\n            __m256d abs_diff = _mm256_andnot_pd(_mm256_set1_pd(-0.0), diff);\n            \n            // Compare with tolerance\n            __m256d tolerance_vec = _mm256_set1_pd(tolerance);\n            __m256d cmp = _mm256_cmp_pd(abs_diff, tolerance_vec, _CMP_GT_OQ);\n            \n            // If any element exceeds tolerance, return false\n            if (_mm256_movemask_pd(cmp)) {\n                return false;\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_39_AVX", "completion": "```cpp\nvoid matrix_row_norm_compare_simd(const double* matrix, const double* thresholds, size_t rows, size_t cols, bool* result) {\n    for (size_t r = 0; r < rows; r++) {\n        __m256d sum_vec = _mm256_setzero_pd();\n        \n        // Process 4 elements at a time\n        size_t c = 0;\n        for (; c + 4 <= cols; c += 4) {\n            __m256d row_vec = _mm256_loadu_pd(&matrix[r * cols + c]);\n            __m256d squared_vec = _mm256_mul_pd(row_vec, row_vec);\n            sum_vec = _mm256_add_pd(sum_vec, squared_vec);\n        }\n        \n        // Horizontal sum of squared values\n        __m128d sum_low = _mm256_extractf128_pd(sum_vec, 0);\n        __m128d sum_high = _mm256_extractf128_pd(sum_vec, 1);\n        sum_low = _mm_add_pd(sum_low, sum_high);\n        sum_low = _mm_hadd_pd(sum_low, sum_low);\n        \n        // Handle remaining elements\n        double sum = _mm_cvtsd_f64(sum_low);\n        for (; c < cols; c++) {\n            double val = matrix[r * cols + c];\n            sum += val * val;\n        }\n        \n        // Compare with threshold\n        result[r] = sqrt(sum) > thresholds[r];\n    }\n}\n```"}
{"task_id": "SimdBench_39_AVX", "completion": "```cpp\nvoid matrix_row_norm_compare_simd(const double* matrix, const double* thresholds, size_t rows, size_t cols, bool* result) {\n    for (size_t r = 0; r < rows; r++) {\n        __m256d sum_vec = _mm256_setzero_pd();\n        \n        // Process 4 elements at a time\n        size_t c = 0;\n        for (; c + 4 <= cols; c += 4) {\n            __m256d row_vec = _mm256_loadu_pd(&matrix[r * cols + c]);\n            __m256d squared_vec = _mm256_mul_pd(row_vec, row_vec);\n            sum_vec = _mm256_add_pd(sum_vec, squared_vec);\n        }\n        \n        // Horizontal sum of squared values\n        __m128d sum_low = _mm256_extractf128_pd(sum_vec, 0);\n        __m128d sum_high = _mm256_extractf128_pd(sum_vec, 1);\n        sum_low = _mm_add_pd(sum_low, sum_high);\n        sum_low = _mm_hadd_pd(sum_low, sum_low);\n        \n        // Handle remaining elements\n        double sum = _mm_cvtsd_f64(sum_low);\n        for (; c < cols; c++) {\n            double val = matrix[r * cols + c];\n            sum += val * val;\n        }\n        \n        // Compare with threshold\n        result[r] = sqrt(sum) > thresholds[r];\n    }\n}\n```"}
{"task_id": "SimdBench_39_AVX", "completion": "```cpp\nvoid matrix_row_norm_compare_simd(const double* matrix, const double* thresholds, size_t rows, size_t cols, bool* result) {\n    for (size_t r = 0; r < rows; r++) {\n        __m256d sum_vec = _mm256_setzero_pd();\n        \n        // Process 4 elements at a time\n        size_t c = 0;\n        for (; c + 4 <= cols; c += 4) {\n            __m256d row_vec = _mm256_loadu_pd(&matrix[r * cols + c]);\n            __m256d squared_vec = _mm256_mul_pd(row_vec, row_vec);\n            sum_vec = _mm256_add_pd(sum_vec, squared_vec);\n        }\n        \n        // Horizontal sum of squared values\n        __m128d sum_low = _mm256_extractf128_pd(sum_vec, 0);\n        __m128d sum_high = _mm256_extractf128_pd(sum_vec, 1);\n        sum_low = _mm_add_pd(sum_low, sum_high);\n        sum_low = _mm_hadd_pd(sum_low, sum_low);\n        \n        // Handle remaining elements\n        double sum = _mm_cvtsd_f64(sum_low);\n        for (; c < cols; c++) {\n            double val = matrix[r * cols + c];\n            sum += val * val;\n        }\n        \n        // Compare with threshold\n        result[r] = sqrt(sum) > thresholds[r];\n    }\n}\n```"}
{"task_id": "SimdBench_39_AVX", "completion": "```cpp\nvoid matrix_row_norm_compare_simd(const double* matrix, const double* thresholds, size_t rows, size_t cols, bool* result) {\n    for (size_t r = 0; r < rows; r++) {\n        __m256d sum_vec = _mm256_setzero_pd();\n        \n        // Process 4 elements at a time\n        size_t c = 0;\n        for (; c + 4 <= cols; c += 4) {\n            __m256d row_vec = _mm256_loadu_pd(&matrix[r * cols + c]);\n            __m256d squared_vec = _mm256_mul_pd(row_vec, row_vec);\n            sum_vec = _mm256_add_pd(sum_vec, squared_vec);\n        }\n        \n        // Horizontal sum of squared values\n        __m128d sum_low = _mm256_extractf128_pd(sum_vec, 0);\n        __m128d sum_high = _mm256_extractf128_pd(sum_vec, 1);\n        sum_low = _mm_add_pd(sum_low, sum_high);\n        sum_low = _mm_hadd_pd(sum_low, sum_low);\n        \n        // Handle remaining elements\n        double sum = _mm_cvtsd_f64(sum_low);\n        for (; c < cols; c++) {\n            double val = matrix[r * cols + c];\n            sum += val * val;\n        }\n        \n        // Compare norm with threshold\n        result[r] = sqrt(sum) > thresholds[r];\n    }\n}\n```"}
{"task_id": "SimdBench_39_AVX", "completion": "```cpp\nvoid matrix_row_norm_compare_simd(const double* matrix, const double* thresholds, size_t rows, size_t cols, bool* result) {\n    for (size_t r = 0; r < rows; r++) {\n        __m256d sum_vec = _mm256_setzero_pd();\n        \n        // Process 4 elements at a time\n        size_t c = 0;\n        for (; c + 4 <= cols; c += 4) {\n            __m256d row_vec = _mm256_loadu_pd(&matrix[r * cols + c]);\n            __m256d squared_vec = _mm256_mul_pd(row_vec, row_vec);\n            sum_vec = _mm256_add_pd(sum_vec, squared_vec);\n        }\n        \n        // Horizontal sum of squared values\n        __m128d sum_low = _mm256_extractf128_pd(sum_vec, 0);\n        __m128d sum_high = _mm256_extractf128_pd(sum_vec, 1);\n        sum_low = _mm_add_pd(sum_low, sum_high);\n        sum_low = _mm_hadd_pd(sum_low, sum_low);\n        \n        // Handle remaining elements\n        double sum = _mm_cvtsd_f64(sum_low);\n        for (; c < cols; c++) {\n            double val = matrix[r * cols + c];\n            sum += val * val;\n        }\n        \n        // Compare with threshold\n        result[r] = sqrt(sum) > thresholds[r];\n    }\n}\n```"}
{"task_id": "SimdBench_40_AVX", "completion": "```cpp\nvoid tensor_bitwise_or_simd(const uint32_t* A, const uint32_t* B, uint32_t* C, size_t length) {\n    size_t i = 0;\n    \n    // Process 8 elements at a time using AVX2 256-bit registers\n    for (; i + 8 <= length; i += 8) {\n        __m256i va = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i vb = _mm256_loadu_si256((__m256i*)&B[i]);\n        \n        __m256i vc = _mm256_or_si256(va, vb);\n        \n        _mm256_storeu_si256((__m256i*)&C[i], vc);\n    }\n    \n    // Handle remaining elements\n    for (; i < length; i++) {\n        C[i] = A[i] | B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_40_AVX", "completion": "```cpp\nvoid tensor_bitwise_or_simd(const uint32_t* A, const uint32_t* B, uint32_t* C, size_t length) {\n    size_t i = 0;\n    \n    // Process 8 elements at a time using AVX2 256-bit registers\n    for (; i + 8 <= length; i += 8) {\n        __m256i va = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i vb = _mm256_loadu_si256((__m256i*)&B[i]);\n        __m256i vc = _mm256_or_si256(va, vb);\n        _mm256_storeu_si256((__m256i*)&C[i], vc);\n    }\n    \n    // Handle remaining elements\n    for (; i < length; i++) {\n        C[i] = A[i] | B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_40_AVX", "completion": "```cpp\nvoid tensor_bitwise_or_simd(const uint32_t* A, const uint32_t* B, uint32_t* C, size_t length) {\n    size_t i = 0;\n    \n    // Process 8 elements at a time using AVX2 256-bit registers\n    for (; i + 8 <= length; i += 8) {\n        __m256i va = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i vb = _mm256_loadu_si256((__m256i*)&B[i]);\n        \n        __m256i vc = _mm256_or_si256(va, vb);\n        \n        _mm256_storeu_si256((__m256i*)&C[i], vc);\n    }\n    \n    // Handle remaining elements\n    for (; i < length; i++) {\n        C[i] = A[i] | B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_40_AVX", "completion": "```cpp\nvoid tensor_bitwise_or_simd(const uint32_t* A, const uint32_t* B, uint32_t* C, size_t length) {\n    size_t i = 0;\n    \n    // Process 8 elements at a time using AVX2 256-bit registers\n    for (; i + 8 <= length; i += 8) {\n        __m256i va = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i vb = _mm256_loadu_si256((__m256i*)&B[i]);\n        __m256i vc = _mm256_or_si256(va, vb);\n        _mm256_storeu_si256((__m256i*)&C[i], vc);\n    }\n    \n    // Handle remaining elements\n    for (; i < length; i++) {\n        C[i] = A[i] | B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_40_AVX", "completion": "```cpp\nvoid tensor_bitwise_or_simd(const uint32_t* A, const uint32_t* B, uint32_t* C, size_t length) {\n    size_t i = 0;\n    \n    // Process 8 elements at a time using AVX2 256-bit registers\n    for (; i + 8 <= length; i += 8) {\n        __m256i va = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i vb = _mm256_loadu_si256((__m256i*)&B[i]);\n        \n        __m256i vc = _mm256_or_si256(va, vb);\n        \n        _mm256_storeu_si256((__m256i*)&C[i], vc);\n    }\n    \n    // Handle remaining elements\n    for (; i < length; i++) {\n        C[i] = A[i] | B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_41_AVX", "completion": "```cpp\nint64_t squarediff_simd(const int8_t * A, const int8_t * B, size_t length) {\n    __m256i sum_squares = _mm256_setzero_si256();\n    __m256i sum_products = _mm256_setzero_si256();\n    \n    size_t i = 0;\n    for (; i + 32 <= length; i += 32) {\n        __m256i va = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i vb = _mm256_loadu_si256((__m256i*)&B[i]);\n        \n        // Compute squares\n        __m256i va_lo = _mm256_unpacklo_epi8(_mm256_setzero_si256(), va);\n        __m256i va_hi = _mm256_unpackhi_epi8(_mm256_setzero_si256(), va);\n        __m256i squares_lo = _mm256_mullo_epi16(va_lo, va_lo);\n        __m256i squares_hi = _mm256_mullo_epi16(va_hi, va_hi);\n        sum_squares = _mm256_add_epi32(sum_squares, _mm256_cvtepi16_epi32(_mm256_castsi256_si128(squares_lo)));\n        sum_squares = _mm256_add_epi32(sum_squares, _mm256_cvtepi16_epi32(_mm256_extracti128_si256(squares_lo, 1)));\n        sum_squares = _mm256_add_epi32(sum_squares, _mm256_cvtepi16_epi32(_mm256_castsi256_si128(squares_hi)));\n        sum_squares = _mm256_add_epi32(sum_squares, _mm256_cvtepi16_epi32(_mm256_extracti128_si256(squares_hi, 1)));\n        \n        // Compute products\n        __m256i vb_lo = _mm256_unpacklo_epi8(_mm256_setzero_si256(), vb);\n        __m256i vb_hi = _mm256_unpackhi_epi8(_mm256_setzero_si256(), vb);\n        __m256i products_lo = _mm256_mullo_epi16(va_lo, vb_lo);\n        __m256i products_hi = _mm256_mullo_epi16(va_hi, vb_hi);\n        sum_products = _mm256_add_epi32(sum_products, _mm256_cvtepi16_epi32(_mm256_castsi256_si128(products_lo)));\n        sum_products = _mm256_add_epi32(sum_products, _mm256_cvtepi16_epi32(_mm256_extracti128_si256(products_lo, 1)));\n        sum_products = _mm256_add_epi32(sum_products, _mm256_cvtepi16_epi32(_mm256_castsi256_si128(products_hi)));\n        sum_products = _mm256_add_epi32(sum_products, _mm256_cvtepi16_epi32(_mm256_extracti128_si256(products_hi, 1)));\n    }\n    \n    // Horizontal sum\n    __m128i sum_squares_128 = _mm_add_epi32(_mm256_extracti128_si256(sum_squares, 0), _mm256_extracti128_si256(sum_squares, 1));\n    sum_squares_128 = _mm_add_epi32(sum_squares_128, _mm_srli_si128(sum_squares_128, 8));\n    sum_squares_128 = _mm_add_epi32(sum_squares_128, _mm_srli_si128(sum_squares_128, 4));\n    int32_t squares_total = _mm_cvtsi128_si32(sum_squares_128);\n    \n    __m128i sum_products_128 = _mm_add_epi32(_mm256_extracti128_si256(sum_products, 0), _mm256_extracti128_si256(sum_products, 1));\n    sum_products_128 = _mm_add_epi32(sum_products_128, _mm_srli_si128(sum_products_128, 8));\n    sum_products_128 = _mm_add_epi32(sum_products_128, _mm_srli_si128(sum_products_128, 4));\n    int32_t products_total = _mm_cvtsi128_si32(sum_products_128);\n    \n    // Handle remaining elements\n    for (; i < length; i++) {\n        squares_total += A[i] * A[i];\n        products_total += A[i] * B[i];\n    }\n    \n    return (int64_t)squares_total - 2 * products_total;\n}\n```"}
{"task_id": "SimdBench_41_AVX", "completion": "```cpp\nint64_t squarediff_simd(const int8_t * A, const int8_t * B, size_t length) {\n    __m256i sum_squares = _mm256_setzero_si256();\n    __m256i sum_products = _mm256_setzero_si256();\n    \n    size_t i = 0;\n    for (; i + 32 <= length; i += 32) {\n        __m256i a_vec = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i b_vec = _mm256_loadu_si256((__m256i*)&B[i]);\n        \n        // Compute squares\n        __m256i a_squared = _mm256_mullo_epi16(a_vec, a_vec);\n        __m256i b_squared = _mm256_mullo_epi16(b_vec, b_vec);\n        sum_squares = _mm256_add_epi64(sum_squares, _mm256_sad_epu8(a_squared, _mm256_setzero_si256()));\n        sum_squares = _mm256_add_epi64(sum_squares, _mm256_sad_epu8(b_squared, _mm256_setzero_si256()));\n        \n        // Compute products\n        __m256i products = _mm256_mullo_epi16(a_vec, b_vec);\n        sum_products = _mm256_add_epi64(sum_products, _mm256_sad_epu8(products, _mm256_setzero_si256()));\n    }\n    \n    int64_t sum_squares_scalar = 0;\n    int64_t sum_products_scalar = 0;\n    \n    // Horizontal sum of sum_squares and sum_products\n    int64_t* sum_squares_arr = (int64_t*)&sum_squares;\n    int64_t* sum_products_arr = (int64_t*)&sum_products;\n    for (int j = 0; j < 4; j++) {\n        sum_squares_scalar += sum_squares_arr[j];\n        sum_products_scalar += sum_products_arr[j];\n    }\n    \n    // Handle remaining elements\n    for (; i < length; i++) {\n        sum_squares_scalar += A[i] * A[i];\n        sum_products_scalar += A[i] * B[i];\n    }\n    \n    return sum_squares_scalar - 2 * sum_products_scalar;\n}\n```"}
{"task_id": "SimdBench_41_AVX", "completion": "```cpp\nint64_t squarediff_simd(const int8_t * A, const int8_t * B, size_t length) {\n    __m256i sum_squares = _mm256_setzero_si256();\n    __m256i sum_products = _mm256_setzero_si256();\n    \n    size_t i = 0;\n    for (; i + 32 <= length; i += 32) {\n        __m256i va = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i vb = _mm256_loadu_si256((__m256i*)&B[i]);\n        \n        // Compute squares\n        __m256i va_lo = _mm256_unpacklo_epi8(_mm256_setzero_si256(), va);\n        __m256i va_hi = _mm256_unpackhi_epi8(_mm256_setzero_si256(), va);\n        __m256i squares_lo = _mm256_mullo_epi16(va_lo, va_lo);\n        __m256i squares_hi = _mm256_mullo_epi16(va_hi, va_hi);\n        sum_squares = _mm256_add_epi32(sum_squares, _mm256_cvtepi16_epi32(_mm256_castsi256_si128(squares_lo)));\n        sum_squares = _mm256_add_epi32(sum_squares, _mm256_cvtepi16_epi32(_mm256_extracti128_si256(squares_lo, 1)));\n        sum_squares = _mm256_add_epi32(sum_squares, _mm256_cvtepi16_epi32(_mm256_castsi256_si128(squares_hi)));\n        sum_squares = _mm256_add_epi32(sum_squares, _mm256_cvtepi16_epi32(_mm256_extracti128_si256(squares_hi, 1)));\n        \n        // Compute products\n        __m256i vb_lo = _mm256_unpacklo_epi8(_mm256_setzero_si256(), vb);\n        __m256i vb_hi = _mm256_unpackhi_epi8(_mm256_setzero_si256(), vb);\n        __m256i products_lo = _mm256_mullo_epi16(va_lo, vb_lo);\n        __m256i products_hi = _mm256_mullo_epi16(va_hi, vb_hi);\n        sum_products = _mm256_add_epi32(sum_products, _mm256_cvtepi16_epi32(_mm256_castsi256_si128(products_lo)));\n        sum_products = _mm256_add_epi32(sum_products, _mm256_cvtepi16_epi32(_mm256_extracti128_si256(products_lo, 1)));\n        sum_products = _mm256_add_epi32(sum_products, _mm256_cvtepi16_epi32(_mm256_castsi256_si128(products_hi)));\n        sum_products = _mm256_add_epi32(sum_products, _mm256_cvtepi16_epi32(_mm256_extracti128_si256(products_hi, 1)));\n    }\n    \n    // Horizontal sum\n    __m128i sum_squares_128 = _mm_add_epi32(_mm256_extracti128_si256(sum_squares, 0), _mm256_extracti128_si256(sum_squares, 1));\n    sum_squares_128 = _mm_add_epi32(sum_squares_128, _mm_srli_si128(sum_squares_128, 8));\n    sum_squares_128 = _mm_add_epi32(sum_squares_128, _mm_srli_si128(sum_squares_128, 4));\n    int32_t squares_sum = _mm_cvtsi128_si32(sum_squares_128);\n    \n    __m128i sum_products_128 = _mm_add_epi32(_mm256_extracti128_si256(sum_products, 0), _mm256_extracti128_si256(sum_products, 1));\n    sum_products_128 = _mm_add_epi32(sum_products_128, _mm_srli_si128(sum_products_128, 8));\n    sum_products_128 = _mm_add_epi32(sum_products_128, _mm_srli_si128(sum_products_128, 4));\n    int32_t products_sum = _mm_cvtsi128_si32(sum_products_128);\n    \n    // Handle remaining elements\n    for (; i < length; ++i) {\n        squares_sum += A[i] * A[i];\n        products_sum += A[i] * B[i];\n    }\n    \n    return (int64_t)squares_sum - 2 * products_sum;\n}\n```"}
{"task_id": "SimdBench_41_AVX", "completion": "```cpp\nint64_t squarediff_simd(const int8_t * A, const int8_t * B, size_t length) {\n    __m256i sum_squares = _mm256_setzero_si256();\n    __m256i sum_products = _mm256_setzero_si256();\n    \n    size_t i = 0;\n    for (; i + 32 <= length; i += 32) {\n        __m256i vec_a = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i vec_b = _mm256_loadu_si256((__m256i*)&B[i]);\n        \n        // Compute squares\n        __m256i squares_a = _mm256_mullo_epi16(vec_a, vec_a);\n        __m256i squares_b = _mm256_mullo_epi16(vec_b, vec_b);\n        \n        // Compute products\n        __m256i products = _mm256_mullo_epi16(vec_a, vec_b);\n        \n        // Accumulate\n        sum_squares = _mm256_add_epi16(sum_squares, _mm256_add_epi16(squares_a, squares_b));\n        sum_products = _mm256_add_epi16(sum_products, products);\n    }\n    \n    // Horizontal sum\n    __m128i sum_squares_low = _mm256_extracti128_si256(sum_squares, 0);\n    __m128i sum_squares_high = _mm256_extracti128_si256(sum_squares, 1);\n    __m128i sum_products_low = _mm256_extracti128_si256(sum_products, 0);\n    __m128i sum_products_high = _mm256_extracti128_si256(sum_products, 1);\n    \n    sum_squares_low = _mm_add_epi16(sum_squares_low, sum_squares_high);\n    sum_products_low = _mm_add_epi16(sum_products_low, sum_products_high);\n    \n    sum_squares_low = _mm_hadd_epi16(sum_squares_low, sum_squares_low);\n    sum_products_low = _mm_hadd_epi16(sum_products_low, sum_products_low);\n    \n    int64_t total_sum_squares = _mm_extract_epi16(sum_squares_low, 0) + \n                                 _mm_extract_epi16(sum_squares_low, 1);\n    int64_t total_sum_products = _mm_extract_epi16(sum_products_low, 0) + \n                                  _mm_extract_epi16(sum_products_low, 1);\n    \n    // Handle remaining elements\n    for (; i < length; i++) {\n        total_sum_squares += A[i] * A[i] + B[i] * B[i];\n        total_sum_products += A[i] * B[i];\n    }\n    \n    return total_sum_squares - 2 * total_sum_products;\n}\n```"}
{"task_id": "SimdBench_41_AVX", "completion": "```cpp\nint64_t squarediff_simd(const int8_t * A, const int8_t * B, size_t length) {\n    __m256i sum_squares = _mm256_setzero_si256();\n    __m256i sum_products = _mm256_setzero_si256();\n    \n    size_t i = 0;\n    for (; i + 32 <= length; i += 32) {\n        __m256i vec_a = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i vec_b = _mm256_loadu_si256((__m256i*)&B[i]);\n        \n        // Compute squares\n        __m256i squares_low = _mm256_mullo_epi16(_mm256_cvtepi8_epi16(_mm256_castsi256_si128(vec_a)), \n                                                  _mm256_cvtepi8_epi16(_mm256_castsi256_si128(vec_a)));\n        __m256i squares_high = _mm256_mullo_epi16(_mm256_cvtepi8_epi16(_mm256_extracti128_si256(vec_a, 1)), \n                                                   _mm256_cvtepi8_epi16(_mm256_extracti128_si256(vec_a, 1)));\n        \n        // Compute products\n        __m256i products_low = _mm256_mullo_epi16(_mm256_cvtepi8_epi16(_mm256_castsi256_si128(vec_a)), \n                                                   _mm256_cvtepi8_epi16(_mm256_castsi256_si128(vec_b)));\n        __m256i products_high = _mm256_mullo_epi16(_mm256_cvtepi8_epi16(_mm256_extracti128_si256(vec_a, 1)), \n                                                    _mm256_cvtepi8_epi16(_mm256_extracti128_si256(vec_b, 1)));\n        \n        // Accumulate\n        sum_squares = _mm256_add_epi64(sum_squares, _mm256_sad_epu8(squares_low, _mm256_setzero_si256()));\n        sum_squares = _mm256_add_epi64(sum_squares, _mm256_sad_epu8(squares_high, _mm256_setzero_si256()));\n        sum_products = _mm256_add_epi64(sum_products, _mm256_sad_epu8(products_low, _mm256_setzero_si256()));\n        sum_products = _mm256_add_epi64(sum_products, _mm256_sad_epu8(products_high, _mm256_setzero_si256()));\n    }\n    \n    // Horizontal sum\n    int64_t total_sum_squares = _mm256_extract_epi64(sum_squares, 0) + \n                                 _mm256_extract_epi64(sum_squares, 1) + \n                                 _mm256_extract_epi64(sum_squares, 2) + \n                                 _mm256_extract_epi64(sum_squares, 3);\n    \n    int64_t total_sum_products = _mm256_extract_epi64(sum_products, 0) + \n                                  _mm256_extract_epi64(sum_products, 1) + \n                                  _mm256_extract_epi64(sum_products, 2) + \n                                  _mm256_extract_epi64(sum_products, 3);\n    \n    // Handle remaining elements\n    for (; i < length; i++) {\n        total_sum_squares += A[i] * A[i];\n        total_sum_products += A[i] * B[i];\n    }\n    \n    return total_sum_squares - total_sum_products;\n}\n```"}
{"task_id": "SimdBench_42_AVX", "completion": "```cpp\nvoid tensor_bit_clear_simd(const uint64_t* A, const uint64_t* B, uint64_t* C, size_t length) {\n    size_t i = 0;\n    \n    // Process 4 elements at a time using AVX2 256-bit vectors\n    for (; i + 4 <= length; i += 4) {\n        __m256i a_vec = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i b_vec = _mm256_loadu_si256((__m256i*)&B[i]);\n        \n        // Bitwise NOT of B\n        __m256i not_b_vec = _mm256_xor_si256(b_vec, _mm256_set1_epi64x(-1));\n        \n        // Bitwise AND between A and NOT(B)\n        __m256i result_vec = _mm256_and_si256(a_vec, not_b_vec);\n        \n        // Store result back to C\n        _mm256_storeu_si256((__m256i*)&C[i], result_vec);\n    }\n    \n    // Handle remaining elements\n    for (; i < length; i++) {\n        C[i] = A[i] & ~B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_42_AVX", "completion": "```cpp\nvoid tensor_bit_clear_simd(const uint64_t* A, const uint64_t* B, uint64_t* C, size_t length) {\n    size_t i = 0;\n    \n    // Process 4 elements at a time using AVX2 256-bit vectors\n    for (; i + 4 <= length; i += 4) {\n        __m256i a_vec = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i b_vec = _mm256_loadu_si256((__m256i*)&B[i]);\n        \n        // Bitwise NOT of B\n        __m256i not_b_vec = _mm256_xor_si256(b_vec, _mm256_set1_epi64x(-1));\n        \n        // Bitwise AND between A and NOT(B)\n        __m256i result_vec = _mm256_and_si256(a_vec, not_b_vec);\n        \n        // Store result in C\n        _mm256_storeu_si256((__m256i*)&C[i], result_vec);\n    }\n    \n    // Handle remaining elements\n    for (; i < length; i++) {\n        C[i] = A[i] & ~B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_42_AVX", "completion": "```cpp\nvoid tensor_bit_clear_simd(const uint64_t* A, const uint64_t* B, uint64_t* C, size_t length) {\n    size_t i = 0;\n    \n    // Process 4 elements at a time using AVX2 256-bit vectors\n    for (; i + 4 <= length; i += 4) {\n        __m256i a_vec = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i b_vec = _mm256_loadu_si256((__m256i*)&B[i]);\n        \n        // Bitwise NOT of B\n        __m256i not_b_vec = _mm256_xor_si256(b_vec, _mm256_set1_epi64x(-1));\n        \n        // Bitwise AND between A and NOT(B)\n        __m256i result_vec = _mm256_and_si256(a_vec, not_b_vec);\n        \n        _mm256_storeu_si256((__m256i*)&C[i], result_vec);\n    }\n    \n    // Handle remaining elements\n    for (; i < length; i++) {\n        C[i] = A[i] & ~B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_42_AVX", "completion": "```cpp\nvoid tensor_bit_clear_simd(const uint64_t* A, const uint64_t* B, uint64_t* C, size_t length) {\n    size_t i = 0;\n    \n    // Process 4 elements at a time using AVX2 256-bit registers\n    for (; i + 4 <= length; i += 4) {\n        __m256i a_vec = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i b_vec = _mm256_loadu_si256((__m256i*)&B[i]);\n        \n        // Bitwise NOT of B\n        __m256i not_b_vec = _mm256_xor_si256(b_vec, _mm256_set1_epi64x(-1));\n        \n        // Bitwise AND between A and NOT(B)\n        __m256i result_vec = _mm256_and_si256(a_vec, not_b_vec);\n        \n        _mm256_storeu_si256((__m256i*)&C[i], result_vec);\n    }\n    \n    // Handle remaining elements\n    for (; i < length; i++) {\n        C[i] = A[i] & ~B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_42_AVX", "completion": "```cpp\nvoid tensor_bit_clear_simd(const uint64_t* A, const uint64_t* B, uint64_t* C, size_t length) {\n    size_t i = 0;\n    \n    // Process 4 elements at a time using AVX2 256-bit registers\n    for (; i + 4 <= length; i += 4) {\n        __m256i a_vec = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i b_vec = _mm256_loadu_si256((__m256i*)&B[i]);\n        \n        // Bitwise NOT of B followed by bitwise AND with A\n        __m256i result = _mm256_andnot_si256(b_vec, a_vec);\n        \n        _mm256_storeu_si256((__m256i*)&C[i], result);\n    }\n    \n    // Handle remaining elements\n    for (; i < length; i++) {\n        C[i] = A[i] & ~B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_43_AVX", "completion": "```cpp\nvoid tensor_three_valued_logic_simd(const int8_t* A, const int8_t* B, int8_t* C, size_t length) {\n    size_t i = 0;\n    for (; i + 32 <= length; i += 32) {\n        // Load 32 bytes from A and B\n        __m256i a_vec = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i b_vec = _mm256_loadu_si256((__m256i*)&B[i]);\n\n        // Check for positive values in A and B\n        __m256i positive_mask_a = _mm256_cmpgt_epi8(a_vec, _mm256_setzero_si256());\n        __m256i positive_mask_b = _mm256_cmpgt_epi8(b_vec, _mm256_setzero_si256());\n        __m256i both_positive = _mm256_and_si256(positive_mask_a, positive_mask_b);\n\n        // Check for negative values in A and B\n        __m256i negative_mask_a = _mm256_cmplt_epi8(a_vec, _mm256_setzero_si256());\n        __m256i negative_mask_b = _mm256_cmplt_epi8(b_vec, _mm256_setzero_si256());\n        __m256i both_negative = _mm256_and_si256(negative_mask_a, negative_mask_b);\n\n        // Create result vector\n        __m256i result = _mm256_setzero_si256();\n        result = _mm256_blendv_epi8(result, _mm256_set1_epi8(1), both_positive);\n        result = _mm256_blendv_epi8(result, _mm256_set1_epi8(-1), both_negative);\n\n        // Store result\n        _mm256_storeu_si256((__m256i*)&C[i], result);\n    }\n\n    // Handle remaining elements\n    for (; i < length; i++) {\n        if (A[i] > 0 && B[i] > 0)\n            C[i] = 1;\n        else if (A[i] < 0 && B[i] < 0)\n            C[i] = -1;\n        else\n            C[i] = 0;\n    }\n}\n```"}
{"task_id": "SimdBench_43_AVX", "completion": "```cpp\nvoid tensor_three_valued_logic_simd(const int8_t* A, const int8_t* B, int8_t* C, size_t length) {\n    size_t i = 0;\n    \n    // Process 32 elements at a time using AVX2 256-bit registers\n    for (; i + 32 <= length; i += 32) {\n        // Load 32 bytes from A and B\n        __m256i a_vec = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i b_vec = _mm256_loadu_si256((__m256i*)&B[i]);\n        \n        // Create masks for positive and negative values\n        __m256i zero_vec = _mm256_setzero_si256();\n        __m256i pos_mask_a = _mm256_cmpgt_epi8(a_vec, zero_vec);\n        __m256i pos_mask_b = _mm256_cmpgt_epi8(b_vec, zero_vec);\n        __m256i neg_mask_a = _mm256_cmpgt_epi8(zero_vec, a_vec);\n        __m256i neg_mask_b = _mm256_cmpgt_epi8(zero_vec, b_vec);\n        \n        // Both positive\n        __m256i both_pos = _mm256_and_si256(pos_mask_a, pos_mask_b);\n        \n        // Both negative\n        __m256i both_neg = _mm256_and_si256(neg_mask_a, neg_mask_b);\n        \n        // Create result vector\n        __m256i result = _mm256_setzero_si256();\n        result = _mm256_blendv_epi8(result, _mm256_set1_epi8(1), both_pos);\n        result = _mm256_blendv_epi8(result, _mm256_set1_epi8(-1), both_neg);\n        \n        // Store result\n        _mm256_storeu_si256((__m256i*)&C[i], result);\n    }\n    \n    // Handle remaining elements\n    for (; i < length; i++) {\n        if (A[i] > 0 && B[i] > 0)\n            C[i] = 1;\n        else if (A[i] < 0 && B[i] < 0)\n            C[i] = -1;\n        else\n            C[i] = 0;\n    }\n}\n```"}
{"task_id": "SimdBench_43_AVX", "completion": "```cpp\nvoid tensor_three_valued_logic_simd(const int8_t* A, const int8_t* B, int8_t* C, size_t length) {\n    size_t i = 0;\n    \n    // Process 32 elements at a time using AVX2 256-bit registers\n    for (; i + 32 <= length; i += 32) {\n        // Load 32 bytes from A and B\n        __m256i a_vec = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i b_vec = _mm256_loadu_si256((__m256i*)&B[i]);\n        \n        // Create masks for positive and negative values\n        __m256i zero_vec = _mm256_setzero_si256();\n        __m256i pos_mask_a = _mm256_cmpgt_epi8(a_vec, zero_vec);\n        __m256i pos_mask_b = _mm256_cmpgt_epi8(b_vec, zero_vec);\n        __m256i neg_mask_a = _mm256_cmpgt_epi8(zero_vec, a_vec);\n        __m256i neg_mask_b = _mm256_cmpgt_epi8(zero_vec, b_vec);\n        \n        // Compute both positive and both negative conditions\n        __m256i both_pos = _mm256_and_si256(pos_mask_a, pos_mask_b);\n        __m256i both_neg = _mm256_and_si256(neg_mask_a, neg_mask_b);\n        \n        // Create result vector\n        __m256i result = _mm256_setzero_si256();\n        result = _mm256_blendv_epi8(result, _mm256_set1_epi8(1), both_pos);\n        result = _mm256_blendv_epi8(result, _mm256_set1_epi8(-1), both_neg);\n        \n        // Store result\n        _mm256_storeu_si256((__m256i*)&C[i], result);\n    }\n    \n    // Handle remaining elements\n    for (; i < length; i++) {\n        if (A[i] > 0 && B[i] > 0) {\n            C[i] = 1;\n        } else if (A[i] < 0 && B[i] < 0) {\n            C[i] = -1;\n        } else {\n            C[i] = 0;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_43_AVX", "completion": "```cpp\nvoid tensor_three_valued_logic_simd(const int8_t* A, const int8_t* B, int8_t* C, size_t length) {\n    size_t i = 0;\n    \n    // Process 32 elements at a time using AVX2 256-bit registers\n    for (; i + 32 <= length; i += 32) {\n        // Load 32 bytes from A and B\n        __m256i a_vec = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i b_vec = _mm256_loadu_si256((__m256i*)&B[i]);\n        \n        // Create masks for positive and negative elements\n        __m256i zero_vec = _mm256_setzero_si256();\n        __m256i pos_mask_a = _mm256_cmpgt_epi8(a_vec, zero_vec);\n        __m256i pos_mask_b = _mm256_cmpgt_epi8(b_vec, zero_vec);\n        __m256i neg_mask_a = _mm256_cmpgt_epi8(zero_vec, a_vec);\n        __m256i neg_mask_b = _mm256_cmpgt_epi8(zero_vec, b_vec);\n        \n        // Both positive case\n        __m256i both_pos = _mm256_and_si256(pos_mask_a, pos_mask_b);\n        __m256i both_pos_result = _mm256_set1_epi8(1);\n        both_pos_result = _mm256_and_si256(both_pos_result, both_pos);\n        \n        // Both negative case\n        __m256i both_neg = _mm256_and_si256(neg_mask_a, neg_mask_b);\n        __m256i both_neg_result = _mm256_set1_epi8(-1);\n        both_neg_result = _mm256_and_si256(both_neg_result, both_neg);\n        \n        // Combine results\n        __m256i result = _mm256_or_si256(both_pos_result, both_neg_result);\n        \n        // Store result\n        _mm256_storeu_si256((__m256i*)&C[i], result);\n    }\n    \n    // Handle remaining elements\n    for (; i < length; i++) {\n        if (A[i] > 0 && B[i] > 0)\n            C[i] = 1;\n        else if (A[i] < 0 && B[i] < 0)\n            C[i] = -1;\n        else\n            C[i] = 0;\n    }\n}\n```"}
{"task_id": "SimdBench_43_AVX", "completion": "```cpp\nvoid tensor_three_valued_logic_simd(const int8_t* A, const int8_t* B, int8_t* C, size_t length) {\n    size_t i = 0;\n    \n    // Process 32 elements at a time using AVX2 256-bit registers\n    for (; i + 32 <= length; i += 32) {\n        // Load 32 bytes from A and B\n        __m256i a_vec = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i b_vec = _mm256_loadu_si256((__m256i*)&B[i]);\n        \n        // Create masks for positive and negative values\n        __m256i zero_vec = _mm256_setzero_si256();\n        __m256i pos_mask_a = _mm256_cmpgt_epi8(a_vec, zero_vec);\n        __m256i pos_mask_b = _mm256_cmpgt_epi8(b_vec, zero_vec);\n        __m256i neg_mask_a = _mm256_cmpgt_epi8(zero_vec, a_vec);\n        __m256i neg_mask_b = _mm256_cmpgt_epi8(zero_vec, b_vec);\n        \n        // Compute both positive and both negative conditions\n        __m256i both_pos = _mm256_and_si256(pos_mask_a, pos_mask_b);\n        __m256i both_neg = _mm256_and_si256(neg_mask_a, neg_mask_b);\n        \n        // Create result vector\n        __m256i result = _mm256_setzero_si256();\n        result = _mm256_blendv_epi8(result, _mm256_set1_epi8(1), both_pos);\n        result = _mm256_blendv_epi8(result, _mm256_set1_epi8(-1), both_neg);\n        \n        // Store result\n        _mm256_storeu_si256((__m256i*)&C[i], result);\n    }\n    \n    // Handle remaining elements\n    for (; i < length; i++) {\n        if (A[i] > 0 && B[i] > 0)\n            C[i] = 1;\n        else if (A[i] < 0 && B[i] < 0)\n            C[i] = -1;\n        else\n            C[i] = 0;\n    }\n}\n```"}
{"task_id": "SimdBench_44_AVX", "completion": "```cpp\nvoid tensor_bit_op_simd(const uint16_t* A, const uint16_t* B, uint16_t* C, size_t length) {\n    size_t midpoint = length / 2;\n    size_t vector_length = length - (length % 16);\n\n    // Process vectors before midpoint with XOR\n    for (size_t i = 0; i < midpoint - (midpoint % 16); i += 16) {\n        __m256i a_vec = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i b_vec = _mm256_loadu_si256((__m256i*)&B[i]);\n        __m256i xor_result = _mm256_xor_si256(a_vec, b_vec);\n        _mm256_storeu_si256((__m256i*)&C[i], xor_result);\n    }\n\n    // Process vectors after midpoint with AND\n    for (size_t i = midpoint + (midpoint % 16); i < vector_length; i += 16) {\n        __m256i a_vec = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i b_vec = _mm256_loadu_si256((__m256i*)&B[i]);\n        __m256i and_result = _mm256_and_si256(a_vec, b_vec);\n        _mm256_storeu_si256((__m256i*)&C[i], and_result);\n    }\n\n    // Handle midpoint element\n    C[midpoint] = A[midpoint];\n\n    // Handle remaining elements\n    for (size_t i = vector_length; i < length; ++i) {\n        if (i < midpoint) {\n            C[i] = A[i] ^ B[i];\n        } else if (i > midpoint) {\n            C[i] = A[i] & B[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_44_AVX", "completion": "```cpp\nvoid tensor_bit_op_simd(const uint16_t* A, const uint16_t* B, uint16_t* C, size_t length) {\n    size_t midpoint = length / 2;\n    size_t vector_size = 16 / sizeof(uint16_t);  // 8 16-bit integers per 128-bit vector\n    size_t vector_length = midpoint - (midpoint % vector_size);\n\n    // XOR operation for elements before midpoint\n    for (size_t i = 0; i < vector_length; i += vector_size) {\n        __m128i a_vec = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i b_vec = _mm_loadu_si128((__m128i*)&B[i]);\n        __m128i xor_result = _mm_xor_si128(a_vec, b_vec);\n        _mm_storeu_si128((__m128i*)&C[i], xor_result);\n    }\n\n    // Handle remaining elements before midpoint with scalar operations\n    for (size_t i = vector_length; i < midpoint; ++i) {\n        C[i] = A[i] ^ B[i];\n    }\n\n    // AND operation for elements after midpoint\n    size_t start_and = midpoint + 1;\n    size_t vector_and_length = length - (length % vector_size);\n\n    for (size_t i = start_and; i < vector_and_length; i += vector_size) {\n        __m128i a_vec = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i b_vec = _mm_loadu_si128((__m128i*)&B[i]);\n        __m128i and_result = _mm_and_si128(a_vec, b_vec);\n        _mm_storeu_si128((__m128i*)&C[i], and_result);\n    }\n\n    // Handle remaining elements after midpoint with scalar operations\n    for (size_t i = vector_and_length; i < length; ++i) {\n        if (i != midpoint) {\n            C[i] = A[i] & B[i];\n        }\n    }\n\n    // Keep midpoint value from A\n    C[midpoint] = A[midpoint];\n}\n```"}
{"task_id": "SimdBench_44_AVX", "completion": "```cpp\nvoid tensor_bit_op_simd(const uint16_t* A, const uint16_t* B, uint16_t* C, size_t length) {\n    size_t midpoint = length / 2;\n    size_t vector_length = length - (length % 16);\n\n    // Process vectors before midpoint with XOR\n    for (size_t i = 0; i < midpoint; i += 16) {\n        __m256i a_vec = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i b_vec = _mm256_loadu_si256((__m256i*)&B[i]);\n        __m256i xor_result = _mm256_xor_si256(a_vec, b_vec);\n        _mm256_storeu_si256((__m256i*)&C[i], xor_result);\n    }\n\n    // Process midpoint element\n    C[midpoint] = A[midpoint];\n\n    // Process vectors after midpoint with AND\n    for (size_t i = midpoint + 1; i < vector_length; i += 16) {\n        __m256i a_vec = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i b_vec = _mm256_loadu_si256((__m256i*)&B[i]);\n        __m256i and_result = _mm256_and_si256(a_vec, b_vec);\n        _mm256_storeu_si256((__m256i*)&C[i], and_result);\n    }\n\n    // Handle remaining elements\n    for (size_t i = vector_length; i < length; i++) {\n        if (i < midpoint) {\n            C[i] = A[i] ^ B[i];\n        } else if (i > midpoint) {\n            C[i] = A[i] & B[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_44_AVX", "completion": "```cpp\nvoid tensor_bit_op_simd(const uint16_t* A, const uint16_t* B, uint16_t* C, size_t length) {\n    size_t midpoint = length / 2;\n    size_t vector_length = length - (length % 16);\n\n    // Process vectors before midpoint with XOR\n    for (size_t i = 0; i < midpoint; i += 16) {\n        __m256i va = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i vb = _mm256_loadu_si256((__m256i*)&B[i]);\n        __m256i vxor = _mm256_xor_si256(va, vb);\n        _mm256_storeu_si256((__m256i*)&C[i], vxor);\n    }\n\n    // Process midpoint element\n    C[midpoint] = A[midpoint];\n\n    // Process vectors after midpoint with AND\n    for (size_t i = midpoint + 1; i < vector_length; i += 16) {\n        __m256i va = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i vb = _mm256_loadu_si256((__m256i*)&B[i]);\n        __m256i vand = _mm256_and_si256(va, vb);\n        _mm256_storeu_si256((__m256i*)&C[i], vand);\n    }\n\n    // Handle remaining elements\n    for (size_t i = vector_length; i < length; i++) {\n        if (i < midpoint) {\n            C[i] = A[i] ^ B[i];\n        } else if (i > midpoint) {\n            C[i] = A[i] & B[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_44_AVX", "completion": "```cpp\nvoid tensor_bit_op_simd(const uint16_t* A, const uint16_t* B, uint16_t* C, size_t length) {\n    size_t midpoint = length / 2;\n    size_t vector_size = 16 / sizeof(uint16_t);  // 8 16-bit integers per AVX vector\n    size_t vector_length = midpoint - (midpoint % vector_size);\n\n    // Process vectors before midpoint with XOR\n    for (size_t i = 0; i < vector_length; i += vector_size) {\n        __m256i a_vec = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i b_vec = _mm256_loadu_si256((__m256i*)&B[i]);\n        __m256i xor_result = _mm256_xor_si256(a_vec, b_vec);\n        _mm256_storeu_si256((__m256i*)&C[i], xor_result);\n    }\n\n    // Process remaining elements before midpoint with XOR\n    for (size_t i = vector_length; i < midpoint; i++) {\n        C[i] = A[i] ^ B[i];\n    }\n\n    // Keep midpoint element from A\n    C[midpoint] = A[midpoint];\n\n    // Process vectors after midpoint with AND\n    size_t and_start = midpoint + 1;\n    size_t and_vector_length = length - (length % vector_size);\n    for (size_t i = and_start; i < and_vector_length; i += vector_size) {\n        __m256i a_vec = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i b_vec = _mm256_loadu_si256((__m256i*)&B[i]);\n        __m256i and_result = _mm256_and_si256(a_vec, b_vec);\n        _mm256_storeu_si256((__m256i*)&C[i], and_result);\n    }\n\n    // Process remaining elements after midpoint with AND\n    for (size_t i = and_vector_length; i < length; i++) {\n        C[i] = A[i] & B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_45_AVX", "completion": "```cpp\nvoid tensor_multi_select_simd(const float* A, const float* B, const float* C, const float* D, const bool* cond1, const bool* cond2, float* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t vector_size = 8; // AVX can process 8 floats at a time\n    size_t i = 0;\n\n    // Process 8 elements at a time using AVX\n    for (; i + vector_size <= total_elements; i += vector_size) {\n        // Load condition masks\n        __m256 mask1 = _mm256_castsi256_ps(_mm256_cmpeq_epi32(\n            _mm256_loadu_si256((__m256i*)(cond1 + i)), \n            _mm256_set1_epi32(1)\n        ));\n        __m256 mask2 = _mm256_castsi256_ps(_mm256_cmpeq_epi32(\n            _mm256_loadu_si256((__m256i*)(cond2 + i)), \n            _mm256_set1_epi32(1)\n        ));\n\n        // Load input tensors\n        __m256 a_vec = _mm256_loadu_ps(A + i);\n        __m256 b_vec = _mm256_loadu_ps(B + i);\n        __m256 c_vec = _mm256_loadu_ps(C + i);\n        __m256 d_vec = _mm256_loadu_ps(D + i);\n\n        // Combine masks\n        __m256 mask_ab = _mm256_and_ps(mask1, mask2);           // cond1 && cond2\n        __m256 mask_an_b = _mm256_and_ps(mask1, _mm256_xor_ps(mask2, _mm256_set1_ps(1.0f))); // cond1 && !cond2\n        __m256 mask_na_b = _mm256_and_ps(_mm256_xor_ps(mask1, _mm256_set1_ps(1.0f)), mask2); // !cond1 && cond2\n        __m256 mask_na_nb = _mm256_and_ps(\n            _mm256_xor_ps(mask1, _mm256_set1_ps(1.0f)), \n            _mm256_xor_ps(mask2, _mm256_set1_ps(1.0f))\n        ); // !cond1 && !cond2\n\n        // Select values based on masks\n        __m256 result_ab = _mm256_and_ps(a_vec, mask_ab);\n        __m256 result_an_b = _mm256_and_ps(b_vec, mask_an_b);\n        __m256 result_na_b = _mm256_and_ps(c_vec, mask_na_b);\n        __m256 result_na_nb = _mm256_and_ps(d_vec, mask_na_nb);\n\n        // Combine results\n        __m256 final_result = _mm256_or_ps(\n            _mm256_or_ps(result_ab, result_an_b),\n            _mm256_or_ps(result_na_b, result_na_nb)\n        );\n\n        // Store result\n        _mm256_storeu_ps(out + i, final_result);\n    }\n\n    // Handle remaining elements\n    for (; i < total_elements; ++i) {\n        if (cond1[i] && cond2[i]) {\n            out[i] = A[i];\n        } else if (cond1[i] && !cond2[i]) {\n            out[i] = B[i];\n        } else if (!cond1[i] && cond2[i]) {\n            out[i] = C[i];\n        } else {\n            out[i] = D[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_45_AVX", "completion": "```cpp\nvoid tensor_multi_select_simd(const float* A, const float* B, const float* C, const float* D, const bool* cond1, const bool* cond2, float* out, size_t dim1, size_t dim2, size_t dim3) {\n    for (size_t i = 0; i < dim1; ++i) {\n        for (size_t j = 0; j < dim2; ++j) {\n            size_t k = 0;\n            for (; k + 8 <= dim3; k += 8) {\n                // Load condition vectors\n                __m256i vcond1 = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&cond1[(i * dim2 + j) * dim3 + k]));\n                __m256i vcond2 = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&cond2[(i * dim2 + j) * dim3 + k]));\n\n                // Load input vectors\n                __m256 vA = _mm256_loadu_ps(&A[(i * dim2 + j) * dim3 + k]);\n                __m256 vB = _mm256_loadu_ps(&B[(i * dim2 + j) * dim3 + k]);\n                __m256 vC = _mm256_loadu_ps(&C[(i * dim2 + j) * dim3 + k]);\n                __m256 vD = _mm256_loadu_ps(&D[(i * dim2 + j) * dim3 + k]);\n\n                // Combine conditions\n                __m256i vcond_and = _mm256_and_si256(vcond1, vcond2);\n                __m256i vcond_nand1 = _mm256_andnot_si256(vcond1, vcond2);\n                __m256i vcond_nand2 = _mm256_andnot_si256(vcond2, vcond1);\n                __m256i vcond_nor = _mm256_andnot_si256(_mm256_or_si256(vcond1, vcond2), _mm256_set1_epi32(~0));\n\n                // Select based on conditions\n                __m256 vresult1 = _mm256_blendv_ps(vB, vA, _mm256_castsi256_ps(vcond_and));\n                __m256 vresult2 = _mm256_blendv_ps(vD, vC, _mm256_castsi256_ps(vcond_nand1));\n                __m256 vresult3 = _mm256_blendv_ps(vresult2, vresult1, _mm256_castsi256_ps(vcond_nand2));\n                __m256 vresult = _mm256_blendv_ps(vD, vresult3, _mm256_castsi256_ps(vcond_nor));\n\n                // Store result\n                _mm256_storeu_ps(&out[(i * dim2 + j) * dim3 + k], vresult);\n            }\n\n            // Handle remaining elements\n            for (; k < dim3; ++k) {\n                size_t idx = (i * dim2 + j) * dim3 + k;\n                if (cond1[idx] && cond2[idx])\n                    out[idx] = A[idx];\n                else if (cond1[idx] && !cond2[idx])\n                    out[idx] = B[idx];\n                else if (!cond1[idx] && cond2[idx])\n                    out[idx] = C[idx];\n                else\n                    out[idx] = D[idx];\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_45_AVX", "completion": "```cpp\nvoid tensor_multi_select_simd(const float* A, const float* B, const float* C, const float* D, const bool* cond1, const bool* cond2, float* out, size_t dim1, size_t dim2, size_t dim3) {\n    const size_t vector_width = 8; // AVX can process 8 floats at a time\n    \n    for (size_t i = 0; i < dim1; ++i) {\n        for (size_t j = 0; j < dim2; ++j) {\n            size_t k = 0;\n            \n            // Process 8 elements at a time using AVX\n            for (; k + vector_width <= dim3; k += vector_width) {\n                // Load condition masks\n                __m256 mask1 = _mm256_castsi256_ps(_mm256_cmpeq_epi32(\n                    _mm256_castps_si256(_mm256_loadu_ps(reinterpret_cast<const float*>(cond1 + i*dim2*dim3 + j*dim3 + k))),\n                    _mm256_set1_epi32(1)\n                ));\n                \n                __m256 mask2 = _mm256_castsi256_ps(_mm256_cmpeq_epi32(\n                    _mm256_castps_si256(_mm256_loadu_ps(reinterpret_cast<const float*>(cond2 + i*dim2*dim3 + j*dim3 + k))),\n                    _mm256_set1_epi32(1)\n                ));\n                \n                // Load input tensors\n                __m256 a_vec = _mm256_loadu_ps(A + i*dim2*dim3 + j*dim3 + k);\n                __m256 b_vec = _mm256_loadu_ps(B + i*dim2*dim3 + j*dim3 + k);\n                __m256 c_vec = _mm256_loadu_ps(C + i*dim2*dim3 + j*dim3 + k);\n                __m256 d_vec = _mm256_loadu_ps(D + i*dim2*dim3 + j*dim3 + k);\n                \n                // Combine conditions\n                __m256 cond_true_true = _mm256_and_ps(mask1, mask2);\n                __m256 cond_true_false = _mm256_and_ps(mask1, _mm256_xor_ps(mask2, _mm256_set1_ps(1.0f)));\n                __m256 cond_false_true = _mm256_and_ps(_mm256_xor_ps(mask1, _mm256_set1_ps(1.0f)), mask2);\n                __m256 cond_false_false = _mm256_and_ps(_mm256_xor_ps(mask1, _mm256_set1_ps(1.0f)), _mm256_xor_ps(mask2, _mm256_set1_ps(1.0f)));\n                \n                // Select values based on conditions\n                __m256 result = _mm256_add_ps(\n                    _mm256_add_ps(\n                        _mm256_and_ps(cond_true_true, a_vec),\n                        _mm256_and_ps(cond_true_false, b_vec)\n                    ),\n                    _mm256_add_ps(\n                        _mm256_and_ps(cond_false_true, c_vec),\n                        _mm256_and_ps(cond_false_false, d_vec)\n                    )\n                );\n                \n                // Store result\n                _mm256_storeu_ps(out + i*dim2*dim3 + j*dim3 + k, result);\n            }\n            \n            // Handle remaining elements\n            for (; k < dim3; ++k) {\n                size_t index = i*dim2*dim3 + j*dim3 + k;\n                if (cond1[index] && cond2[index])\n                    out[index] = A[index];\n                else if (cond1[index] && !cond2[index])\n                    out[index] = B[index];\n                else if (!cond1[index] && cond2[index])\n                    out[index] = C[index];\n                else\n                    out[index] = D[index];\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_45_AVX", "completion": "```cpp\nvoid tensor_multi_select_simd(const float* A, const float* B, const float* C, const float* D, const bool* cond1, const bool* cond2, float* out, size_t dim1, size_t dim2, size_t dim3) {\n    const size_t vector_width = 8; // AVX can process 8 floats at a time\n    \n    for (size_t i = 0; i < dim1; ++i) {\n        for (size_t j = 0; j < dim2; ++j) {\n            size_t k = 0;\n            \n            // Process 8 elements at a time using AVX\n            for (; k + vector_width <= dim3; k += vector_width) {\n                // Load condition masks\n                __m256 mask_cond1 = _mm256_castsi256_ps(_mm256_cmpeq_epi32(\n                    _mm256_castps_si256(_mm256_loadu_ps(reinterpret_cast<const float*>(cond1 + (i * dim2 + j) * dim3 + k))),\n                    _mm256_set1_epi32(1)\n                ));\n                \n                __m256 mask_cond2 = _mm256_castsi256_ps(_mm256_cmpeq_epi32(\n                    _mm256_castps_si256(_mm256_loadu_ps(reinterpret_cast<const float*>(cond2 + (i * dim2 + j) * dim3 + k))),\n                    _mm256_set1_epi32(1)\n                ));\n                \n                // Load input tensors\n                __m256 a_vec = _mm256_loadu_ps(A + (i * dim2 + j) * dim3 + k);\n                __m256 b_vec = _mm256_loadu_ps(B + (i * dim2 + j) * dim3 + k);\n                __m256 c_vec = _mm256_loadu_ps(C + (i * dim2 + j) * dim3 + k);\n                __m256 d_vec = _mm256_loadu_ps(D + (i * dim2 + j) * dim3 + k);\n                \n                // Compute masks for each condition\n                __m256 mask1_and_mask2 = _mm256_and_ps(mask_cond1, mask_cond2);\n                __m256 mask1_and_not_mask2 = _mm256_and_ps(mask_cond1, _mm256_xor_ps(mask_cond2, _mm256_set1_ps(1.0f)));\n                __m256 not_mask1_and_mask2 = _mm256_and_ps(_mm256_xor_ps(mask_cond1, _mm256_set1_ps(1.0f)), mask_cond2);\n                __m256 not_mask1_and_not_mask2 = _mm256_and_ps(_mm256_xor_ps(mask_cond1, _mm256_set1_ps(1.0f)), _mm256_xor_ps(mask_cond2, _mm256_set1_ps(1.0f)));\n                \n                // Select values based on conditions\n                __m256 result_vec = _mm256_add_ps(\n                    _mm256_add_ps(\n                        _mm256_and_ps(mask1_and_mask2, a_vec),\n                        _mm256_and_ps(mask1_and_not_mask2, b_vec)\n                    ),\n                    _mm256_add_ps(\n                        _mm256_and_ps(not_mask1_and_mask2, c_vec),\n                        _mm256_and_ps(not_mask1_and_not_mask2, d_vec)\n                    )\n                );\n                \n                // Store result\n                _mm256_storeu_ps(out + (i * dim2 + j) * dim3 + k, result_vec);\n            }\n            \n            // Handle remaining elements\n            for (; k < dim3; ++k) {\n                size_t index = (i * dim2 + j) * dim3 + k;\n                if (cond1[index] && cond2[index]) {\n                    out[index] = A[index];\n                } else if (cond1[index] && !cond2[index]) {\n                    out[index] = B[index];\n                } else if (!cond1[index] && cond2[index]) {\n                    out[index] = C[index];\n                } else {\n                    out[index] = D[index];\n                }\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_45_AVX", "completion": "```cpp\nvoid tensor_multi_select_simd(const float* A, const float* B, const float* C, const float* D, const bool* cond1, const bool* cond2, float* out, size_t dim1, size_t dim2, size_t dim3) {\n    const size_t vector_width = 8; // AVX can process 8 floats at a time\n    \n    for (size_t i = 0; i < dim1; ++i) {\n        for (size_t j = 0; j < dim2; ++j) {\n            size_t k = 0;\n            \n            // Process 8 elements at a time using AVX\n            for (; k + vector_width <= dim3; k += vector_width) {\n                // Load condition vectors\n                __m256 cond1_vec = _mm256_castsi256_ps(_mm256_set_epi32(\n                    cond1[(i * dim2 + j) * dim3 + k + 7] ? 0xFFFFFFFF : 0,\n                    cond1[(i * dim2 + j) * dim3 + k + 6] ? 0xFFFFFFFF : 0,\n                    cond1[(i * dim2 + j) * dim3 + k + 5] ? 0xFFFFFFFF : 0,\n                    cond1[(i * dim2 + j) * dim3 + k + 4] ? 0xFFFFFFFF : 0,\n                    cond1[(i * dim2 + j) * dim3 + k + 3] ? 0xFFFFFFFF : 0,\n                    cond1[(i * dim2 + j) * dim3 + k + 2] ? 0xFFFFFFFF : 0,\n                    cond1[(i * dim2 + j) * dim3 + k + 1] ? 0xFFFFFFFF : 0,\n                    cond1[(i * dim2 + j) * dim3 + k] ? 0xFFFFFFFF : 0\n                ));\n                \n                __m256 cond2_vec = _mm256_castsi256_ps(_mm256_set_epi32(\n                    cond2[(i * dim2 + j) * dim3 + k + 7] ? 0xFFFFFFFF : 0,\n                    cond2[(i * dim2 + j) * dim3 + k + 6] ? 0xFFFFFFFF : 0,\n                    cond2[(i * dim2 + j) * dim3 + k + 5] ? 0xFFFFFFFF : 0,\n                    cond2[(i * dim2 + j) * dim3 + k + 4] ? 0xFFFFFFFF : 0,\n                    cond2[(i * dim2 + j) * dim3 + k + 3] ? 0xFFFFFFFF : 0,\n                    cond2[(i * dim2 + j) * dim3 + k + 2] ? 0xFFFFFFFF : 0,\n                    cond2[(i * dim2 + j) * dim3 + k + 1] ? 0xFFFFFFFF : 0,\n                    cond2[(i * dim2 + j) * dim3 + k] ? 0xFFFFFFFF : 0\n                ));\n                \n                // Load input vectors\n                __m256 a_vec = _mm256_loadu_ps(&A[(i * dim2 + j) * dim3 + k]);\n                __m256 b_vec = _mm256_loadu_ps(&B[(i * dim2 + j) * dim3 + k]);\n                __m256 c_vec = _mm256_loadu_ps(&C[(i * dim2 + j) * dim3 + k]);\n                __m256 d_vec = _mm256_loadu_ps(&D[(i * dim2 + j) * dim3 + k]);\n                \n                // Combine conditions\n                __m256 cond1_and_cond2 = _mm256_and_ps(cond1_vec, cond2_vec);\n                __m256 not_cond1_and_cond2 = _mm256_and_ps(_mm256_xor_ps(cond1_vec, _mm256_castsi256_ps(_mm256_set1_epi32(0xFFFFFFFF))), cond2_vec);\n                __m256 cond1_and_not_cond2 = _mm256_and_ps(cond1_vec, _mm256_xor_ps(cond2_vec, _mm256_castsi256_ps(_mm256_set1_epi32(0xFFFFFFFF))));\n                __m256 not_cond1_and_not_cond2 = _mm256_and_ps(_mm256_xor_ps(cond1_vec, _mm256_castsi256_ps(_mm256_set1_epi32(0xFFFFFFFF))), _mm256_xor_ps(cond2_vec, _mm256_castsi256_ps(_mm256_set1_epi32(0xFFFFFFFF))));\n                \n                // Select values based on conditions\n                __m256 result_vec = _mm256_add_ps(\n                    _mm256_add_ps(\n                        _mm256_and_ps(cond1_and_cond2, a_vec),\n                        _mm256_and_ps(cond1_and_not_cond2, b_vec)\n                    ),\n                    _mm256_add_ps(\n                        _mm256_and_ps(not_cond1_and_cond2, c_vec),\n                        _mm256_and_ps(not_cond1_and_not_cond2, d_vec)\n                    )\n                );\n                \n                // Store result\n                _mm256_storeu_ps(&out[(i * dim2 + j) * dim3 + k], result_vec);\n            }\n            \n            // Handle remaining elements\n            for (; k < dim3; ++k) {\n                size_t index = (i * dim2 + j) * dim3 + k;\n                if (cond1[index] && cond2[index])\n                    out[index] = A[index];\n                else if (cond1[index] && !cond2[index])\n                    out[index] = B[index];\n                else if (!cond1[index] && cond2[index])\n                    out[index] = C[index];\n                else\n                    out[index] = D[index];\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_46_AVX", "completion": "```cpp\nvoid tensor_bit_count_simd(const uint32_t* A, uint8_t* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t vector_size = 8; // AVX can process 8 32-bit integers at a time\n    size_t i = 0;\n\n    // Process 8 elements at a time using AVX\n    for (; i + vector_size <= total_elements; i += vector_size) {\n        __m256i input = _mm256_loadu_si256((__m256i*)&A[i]);\n        \n        // Popcount for each 32-bit integer using AVX2 intrinsics\n        __m256i popcount_mask = _mm256_set1_epi32(0x55555555);\n        __m256i popcount1 = _mm256_and_si256(input, popcount_mask);\n        __m256i popcount2 = _mm256_and_si256(_mm256_srli_epi32(input, 1), popcount_mask);\n        input = _mm256_add_epi32(popcount1, popcount2);\n\n        popcount_mask = _mm256_set1_epi32(0x33333333);\n        popcount1 = _mm256_and_si256(input, popcount_mask);\n        popcount2 = _mm256_and_si256(_mm256_srli_epi32(input, 2), popcount_mask);\n        input = _mm256_add_epi32(popcount1, popcount2);\n\n        popcount_mask = _mm256_set1_epi32(0x0F0F0F0F);\n        popcount1 = _mm256_and_si256(input, popcount_mask);\n        popcount2 = _mm256_and_si256(_mm256_srli_epi32(input, 4), popcount_mask);\n        input = _mm256_add_epi32(popcount1, popcount2);\n\n        input = _mm256_add_epi32(input, _mm256_srli_epi32(input, 8));\n        input = _mm256_add_epi32(input, _mm256_srli_epi32(input, 16));\n\n        // Store results\n        int results[8];\n        _mm256_storeu_si256((__m256i*)results, input);\n        \n        for (int j = 0; j < vector_size; j++) {\n            out[i + j] = (uint8_t)results[j];\n        }\n    }\n\n    // Handle remaining elements\n    for (; i < total_elements; i++) {\n        uint32_t x = A[i];\n        x = x - ((x >> 1) & 0x55555555);\n        x = (x & 0x33333333) + ((x >> 2) & 0x33333333);\n        x = (x + (x >> 4)) & 0x0F0F0F0F;\n        x = x + (x >> 8);\n        x = x + (x >> 16);\n        out[i] = (uint8_t)(x & 0x3F);\n    }\n}\n```"}
{"task_id": "SimdBench_46_AVX", "completion": "```cpp\nvoid tensor_bit_count_simd(const uint32_t* A, uint8_t* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t vector_size = 8; // AVX can process 8 32-bit integers at a time\n    size_t i = 0;\n\n    // Process 8 elements at a time using AVX\n    for (; i + vector_size <= total_elements; i += vector_size) {\n        __m256i input_vec = _mm256_loadu_si256((__m256i*)&A[i]);\n        \n        // Popcount for each 32-bit integer\n        __m256i popcount_vec = _mm256_setzero_si256();\n        \n        // Bit manipulation to count set bits\n        for (int bit = 0; bit < 32; bit++) {\n            __m256i bit_mask = _mm256_set1_epi32(1 << bit);\n            __m256i bit_set = _mm256_and_si256(input_vec, bit_mask);\n            bit_set = _mm256_cmpeq_epi32(bit_set, bit_mask);\n            popcount_vec = _mm256_add_epi32(popcount_vec, _mm256_srli_epi32(bit_set, 31));\n        }\n        \n        // Store results\n        int popcount_array[8];\n        _mm256_storeu_si256((__m256i*)popcount_array, popcount_vec);\n        \n        for (int j = 0; j < vector_size; j++) {\n            out[i + j] = popcount_array[j];\n        }\n    }\n    \n    // Handle remaining elements\n    for (; i < total_elements; i++) {\n        uint32_t num = A[i];\n        uint8_t count = 0;\n        while (num) {\n            count += num & 1;\n            num >>= 1;\n        }\n        out[i] = count;\n    }\n}\n```"}
{"task_id": "SimdBench_46_AVX", "completion": "```cpp\nvoid tensor_bit_count_simd(const uint32_t* A, uint8_t* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t vector_size = 8; // AVX can process 8 32-bit integers at once\n    size_t i = 0;\n\n    // Process 8 elements at a time using AVX\n    for (; i + vector_size <= total_elements; i += vector_size) {\n        __m256i input = _mm256_loadu_si256((__m256i*)&A[i]);\n        \n        // Popcount for each 32-bit integer using AVX2 intrinsics\n        __m256i popcount_mask_1 = _mm256_set1_epi32(0x55555555);\n        __m256i popcount_mask_2 = _mm256_set1_epi32(0x33333333);\n        __m256i popcount_mask_4 = _mm256_set1_epi32(0x0F0F0F0F);\n        \n        // Bit count algorithm using bit manipulation\n        __m256i x1 = _mm256_sub_epi32(input, (_mm256_srli_epi32(input, 1) & popcount_mask_1));\n        __m256i x2 = (x1 & popcount_mask_2) + ((_mm256_srli_epi32(x1, 2)) & popcount_mask_2);\n        __m256i x3 = (x2 + _mm256_srli_epi32(x2, 4)) & popcount_mask_4;\n        __m256i x4 = x3 + _mm256_srli_epi32(x3, 8);\n        __m256i x5 = x4 + _mm256_srli_epi32(x4, 16);\n        \n        // Convert 32-bit popcount to 8-bit and store\n        for (int j = 0; j < vector_size; j++) {\n            out[i + j] = _mm256_extract_epi32(x5, j) & 0xFF;\n        }\n    }\n\n    // Handle remaining elements sequentially\n    for (; i < total_elements; i++) {\n        uint32_t x = A[i];\n        x = x - ((x >> 1) & 0x55555555);\n        x = (x & 0x33333333) + ((x >> 2) & 0x33333333);\n        x = (x + (x >> 4)) & 0x0F0F0F0F;\n        x = x + (x >> 8);\n        out[i] = (x + (x >> 16)) & 0x3F;\n    }\n}\n```"}
{"task_id": "SimdBench_46_AVX", "completion": "```cpp\nvoid tensor_bit_count_simd(const uint32_t* A, uint8_t* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t vector_size = 8; // AVX can process 8 32-bit integers at once\n    size_t vector_count = total_elements / vector_size;\n    size_t remainder = total_elements % vector_size;\n\n    for (size_t i = 0; i < vector_count; i++) {\n        __m256i input = _mm256_loadu_si256((__m256i*)&A[i * vector_size]);\n        \n        // Popcount for each 32-bit integer using AVX2 intrinsics\n        __m256i m1 = _mm256_srli_epi32(input, 1);\n        __m256i m2 = _mm256_srli_epi32(input, 2);\n        __m256i m3 = _mm256_srli_epi32(input, 3);\n        \n        input = _mm256_sub_epi32(input, _mm256_and_si256(m1, _mm256_set1_epi32(0x55555555)));\n        input = _mm256_add_epi32(_mm256_and_si256(input, _mm256_set1_epi32(0x33333333)), \n                                  _mm256_and_si256(m2, _mm256_set1_epi32(0x33333333)));\n        \n        input = _mm256_add_epi32(input, _mm256_srli_epi32(input, 4));\n        input = _mm256_and_si256(input, _mm256_set1_epi32(0x0F0F0F0F));\n        input = _mm256_mullo_epi32(input, _mm256_set1_epi32(0x01010101));\n        input = _mm256_srli_epi32(input, 24);\n\n        // Store results\n        _mm256_storeu_si256((__m256i*)&out[i * vector_size], _mm256_cvtepi32_epi8(input));\n    }\n\n    // Handle remaining elements\n    for (size_t i = vector_count * vector_size; i < total_elements; i++) {\n        uint32_t x = A[i];\n        x = x - ((x >> 1) & 0x55555555);\n        x = (x & 0x33333333) + ((x >> 2) & 0x33333333);\n        x = (x + (x >> 4)) & 0x0F0F0F0F;\n        x = x * 0x01010101;\n        out[i] = x >> 24;\n    }\n}\n```"}
{"task_id": "SimdBench_46_AVX", "completion": "```cpp\nvoid tensor_bit_count_simd(const uint32_t* A, uint8_t* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t vector_size = 8; // AVX can process 8 32-bit integers at a time\n    size_t i = 0;\n\n    // Process elements in 8-wide vectors\n    for (; i + vector_size <= total_elements; i += vector_size) {\n        __m256i input_vec = _mm256_loadu_si256((__m256i*)&A[i]);\n        \n        // Popcount for each 32-bit integer using AVX2 intrinsics\n        __m256i zero = _mm256_setzero_si256();\n        __m256i ones = _mm256_cmpeq_epi32(zero, zero);\n        \n        __m256i popcount_vec = _mm256_setzero_si256();\n        \n        // Bit counting for each 32-bit integer\n        for (int bit = 0; bit < 32; bit++) {\n            __m256i bit_mask = _mm256_srli_epi32(input_vec, bit);\n            bit_mask = _mm256_and_si256(bit_mask, ones);\n            popcount_vec = _mm256_add_epi32(popcount_vec, bit_mask);\n        }\n        \n        // Store results\n        int popcount_array[8];\n        _mm256_storeu_si256((__m256i*)popcount_array, popcount_vec);\n        \n        for (int j = 0; j < vector_size; j++) {\n            out[i + j] = (uint8_t)popcount_array[j];\n        }\n    }\n    \n    // Handle remaining elements\n    for (; i < total_elements; i++) {\n        uint32_t num = A[i];\n        uint8_t count = 0;\n        while (num) {\n            count += num & 1;\n            num >>= 1;\n        }\n        out[i] = count;\n    }\n}\n```"}
{"task_id": "SimdBench_47_AVX", "completion": "```cpp\nvoid matrix_conditional_abs_simd(const int* A, int* B, size_t rows, size_t cols) {\n    for (size_t i = 0; i < rows; i++) {\n        size_t j = 0;\n        \n        // Process 8 elements at a time using AVX2\n        for (; j + 8 <= cols; j += 8) {\n            __m256i vec_a = _mm256_loadu_si256((__m256i*)&A[i * cols + j]);\n            \n            // Create mask for elements divisible by 3\n            __m256i zero = _mm256_setzero_si256();\n            __m256i div_mask = _mm256_setzero_si256();\n            \n            for (int k = 0; k < 8; k++) {\n                __m256i element = _mm256_extract_epi32(vec_a, k);\n                __m256i remainder = _mm256_rem_epi32(element, _mm256_set1_epi32(3));\n                div_mask = _mm256_insert_epi32(div_mask, (remainder == zero) ? 0xFFFFFFFF : 0, k);\n            }\n            \n            // Take absolute value where divisible by 3\n            __m256i abs_vec = _mm256_abs_epi32(vec_a);\n            __m256i result = _mm256_blendv_epi8(vec_a, abs_vec, div_mask);\n            \n            _mm256_storeu_si256((__m256i*)&B[i * cols + j], result);\n        }\n        \n        // Handle remaining elements\n        for (; j < cols; j++) {\n            int val = A[i * cols + j];\n            B[i * cols + j] = (val % 3 == 0) ? abs(val) : val;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_47_AVX", "completion": "```cpp\nvoid matrix_conditional_abs_simd(const int* A, int* B, size_t rows, size_t cols) {\n    for (size_t i = 0; i < rows; i++) {\n        size_t j = 0;\n        \n        // Process 8 elements at a time using AVX2\n        for (; j + 8 <= cols; j += 8) {\n            __m256i vec_a = _mm256_loadu_si256((__m256i*)&A[i * cols + j]);\n            \n            // Create vector of 3 for divisibility check\n            __m256i vec_3 = _mm256_set1_epi32(3);\n            \n            // Compute remainder using modulo operation\n            __m256i vec_remainder = _mm256_rem_epi32(vec_a, vec_3);\n            \n            // Compare remainder to zero\n            __m256i vec_mask = _mm256_cmpeq_epi32(vec_remainder, _mm256_setzero_si256());\n            \n            // Compute absolute values\n            __m256i vec_abs = _mm256_abs_epi32(vec_a);\n            \n            // Blend original values and absolute values based on divisibility\n            __m256i vec_result = _mm256_blendv_epi8(vec_a, vec_abs, vec_mask);\n            \n            // Store result\n            _mm256_storeu_si256((__m256i*)&B[i * cols + j], vec_result);\n        }\n        \n        // Handle remaining elements\n        for (; j < cols; j++) {\n            int val = A[i * cols + j];\n            B[i * cols + j] = (val % 3 == 0) ? abs(val) : val;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_47_AVX", "completion": "```cpp\nvoid matrix_conditional_abs_simd(const int* A, int* B, size_t rows, size_t cols) {\n    for (size_t i = 0; i < rows; i++) {\n        size_t j = 0;\n        \n        // Process 8 elements at a time using AVX2 \n        for (; j + 8 <= cols; j += 8) {\n            // Load 8 consecutive integers from matrix A\n            __m256i vec_a = _mm256_loadu_si256((__m256i*)&A[i * cols + j]);\n            \n            // Create vector of divisors (3)\n            __m256i vec_divisor = _mm256_set1_epi32(3);\n            \n            // Compute modulo 3 for each element\n            __m256i vec_mod = _mm256_rem_epi32(vec_a, vec_divisor);\n            \n            // Compare if modulo is zero (divisible by 3)\n            __m256i vec_mask = _mm256_cmpeq_epi32(vec_mod, _mm256_setzero_si256());\n            \n            // Compute absolute values\n            __m256i vec_abs = _mm256_abs_epi32(vec_a);\n            \n            // Blend original values or absolute values based on condition\n            __m256i vec_result = _mm256_blendv_epi8(vec_a, vec_abs, vec_mask);\n            \n            // Store result back to destination matrix\n            _mm256_storeu_si256((__m256i*)&B[i * cols + j], vec_result);\n        }\n        \n        // Handle remaining elements\n        for (; j < cols; j++) {\n            int val = A[i * cols + j];\n            B[i * cols + j] = (val % 3 == 0) ? abs(val) : val;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_47_AVX", "completion": "```cpp\nvoid matrix_conditional_abs_simd(const int* A, int* B, size_t rows, size_t cols) {\n    for (size_t i = 0; i < rows; i++) {\n        size_t j = 0;\n        \n        // Process 8 elements at a time using AVX2\n        for (; j + 8 <= cols; j += 8) {\n            __m256i vec_a = _mm256_loadu_si256((__m256i*)&A[i * cols + j]);\n            \n            // Create vector of divisors (3)\n            __m256i vec_divisor = _mm256_set1_epi32(3);\n            \n            // Compute modulo 3 for each element\n            __m256i vec_mod = _mm256_rem_epi32(vec_a, vec_divisor);\n            \n            // Compare if remainder is zero (divisible by 3)\n            __m256i vec_mask = _mm256_cmpeq_epi32(vec_mod, _mm256_setzero_si256());\n            \n            // Compute absolute values\n            __m256i vec_abs = _mm256_abs_epi32(vec_a);\n            \n            // Blend original or absolute values based on divisibility\n            __m256i vec_result = _mm256_blendv_epi8(vec_a, vec_abs, vec_mask);\n            \n            // Store result\n            _mm256_storeu_si256((__m256i*)&B[i * cols + j], vec_result);\n        }\n        \n        // Handle remaining elements\n        for (; j < cols; j++) {\n            int val = A[i * cols + j];\n            B[i * cols + j] = (val % 3 == 0) ? abs(val) : val;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_47_AVX", "completion": "```cpp\nvoid matrix_conditional_abs_simd(const int* A, int* B, size_t rows, size_t cols) {\n    for (size_t i = 0; i < rows; i++) {\n        size_t j = 0;\n        \n        // Process 8 elements at a time using AVX2\n        for (; j + 8 <= cols; j += 8) {\n            __m256i vec_a = _mm256_loadu_si256((__m256i*)&A[i * cols + j]);\n            \n            // Check divisibility by 3\n            __m256i zero = _mm256_setzero_si256();\n            __m256i div_check = _mm256_setzero_si256();\n            \n            for (int k = 0; k < 8; k++) {\n                __m256i remainder = _mm256_mod_epi32(vec_a, _mm256_set1_epi32(3));\n                div_check = _mm256_or_si256(div_check, remainder);\n            }\n            \n            // Compute absolute value\n            __m256i abs_vec_a = _mm256_abs_epi32(vec_a);\n            \n            // Blend original or absolute values based on divisibility\n            __m256i result = _mm256_blendv_epi8(vec_a, abs_vec_a, _mm256_cmpeq_epi32(div_check, zero));\n            \n            _mm256_storeu_si256((__m256i*)&B[i * cols + j], result);\n        }\n        \n        // Handle remaining elements\n        for (; j < cols; j++) {\n            int val = A[i * cols + j];\n            B[i * cols + j] = (val % 3 == 0) ? abs(val) : val;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_48_AVX", "completion": "```cpp\nvoid matrix_conditional_bit_rotate_simd(const uint32_t* src, uint32_t* dst, uint8_t rotate_bits, size_t length) {\n    size_t i = 0;\n    for (; i + 8 <= length; i += 8) {\n        __m256i vec_src = _mm256_loadu_si256((__m256i*)&src[i]);\n        \n        // Check if low 4 bits are all 1\n        __m256i low_mask = _mm256_set1_epi32(0x0000000F);\n        __m256i low_bits = _mm256_and_si256(vec_src, low_mask);\n        __m256i all_ones_mask = _mm256_cmpeq_epi32(low_bits, low_mask);\n        \n        // Rotate elements where low 4 bits are all 1\n        __m256i rotated = _mm256_or_si256(\n            _mm256_slli_epi32(vec_src, rotate_bits),\n            _mm256_srli_epi32(vec_src, 32 - rotate_bits)\n        );\n        \n        // Bitwise negate elements where low 4 bits are not all 1\n        __m256i negated = _mm256_xor_si256(vec_src, _mm256_set1_epi32(0xFFFFFFFF));\n        \n        // Blend rotated and negated based on condition\n        __m256i result = _mm256_blendv_epi8(negated, rotated, all_ones_mask);\n        \n        _mm256_storeu_si256((__m256i*)&dst[i], result);\n    }\n    \n    // Handle remaining elements\n    for (; i < length; i++) {\n        if ((src[i] & 0x0000000F) == 0x0000000F) {\n            dst[i] = (src[i] << rotate_bits) | (src[i] >> (32 - rotate_bits));\n        } else {\n            dst[i] = ~src[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_48_AVX", "completion": "```cpp\nvoid matrix_conditional_bit_rotate_simd(const uint32_t* src, uint32_t* dst, uint8_t rotate_bits, size_t length) {\n    size_t i = 0;\n    for (; i + 8 <= length; i += 8) {\n        __m256i vec_src = _mm256_loadu_si256((__m256i*)&src[i]);\n        \n        // Check if low 4 bits are all 1\n        __m256i low_mask = _mm256_set1_epi32(0x0000000F);\n        __m256i all_ones_mask = _mm256_cmpeq_epi32(_mm256_and_si256(vec_src, low_mask), low_mask);\n        \n        // Rotate elements\n        __m256i rotated = _mm256_or_si256(\n            _mm256_slli_epi32(vec_src, rotate_bits),\n            _mm256_srli_epi32(vec_src, 32 - rotate_bits)\n        );\n        \n        // Bitwise negate elements\n        __m256i negated = _mm256_xor_si256(vec_src, _mm256_set1_epi32(0xFFFFFFFF));\n        \n        // Blend rotated and negated based on condition\n        __m256i result = _mm256_blendv_epi8(negated, rotated, all_ones_mask);\n        \n        _mm256_storeu_si256((__m256i*)&dst[i], result);\n    }\n    \n    // Handle remaining elements\n    for (; i < length; i++) {\n        if ((src[i] & 0x0000000F) == 0x0000000F) {\n            dst[i] = (src[i] << rotate_bits) | (src[i] >> (32 - rotate_bits));\n        } else {\n            dst[i] = ~src[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_48_AVX", "completion": "```cpp\nvoid matrix_conditional_bit_rotate_simd(const uint32_t* src, uint32_t* dst, uint8_t rotate_bits, size_t length) {\n    size_t i = 0;\n    for (; i + 8 <= length; i += 8) {\n        __m256i vec_src = _mm256_loadu_si256((__m256i*)&src[i]);\n        \n        // Check if low 4 bits are all 1\n        __m256i low_mask = _mm256_set1_epi32(0x0000000F);\n        __m256i all_ones_mask = _mm256_cmpeq_epi32(_mm256_and_si256(vec_src, low_mask), low_mask);\n        \n        // Rotate elements where condition is true\n        __m256i rotated = _mm256_or_si256(\n            _mm256_slli_epi32(vec_src, rotate_bits),\n            _mm256_srli_epi32(vec_src, 32 - rotate_bits)\n        );\n        \n        // Bitwise negate elements where condition is false\n        __m256i negated = _mm256_xor_si256(vec_src, _mm256_set1_epi32(0xFFFFFFFF));\n        \n        // Blend rotated and negated based on condition\n        __m256i result = _mm256_blendv_epi8(negated, rotated, all_ones_mask);\n        \n        _mm256_storeu_si256((__m256i*)&dst[i], result);\n    }\n    \n    // Handle remaining elements\n    for (; i < length; i++) {\n        if ((src[i] & 0x0F) == 0x0F) {\n            dst[i] = (src[i] << rotate_bits) | (src[i] >> (32 - rotate_bits));\n        } else {\n            dst[i] = ~src[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_48_AVX", "completion": "```cpp\nvoid matrix_conditional_bit_rotate_simd(const uint32_t* src, uint32_t* dst, uint8_t rotate_bits, size_t length) {\n    size_t i = 0;\n    for (; i + 8 <= length; i += 8) {\n        __m256i vec_src = _mm256_loadu_si256((__m256i*)&src[i]);\n        \n        // Check if low 4 bits are all 1\n        __m256i low_mask = _mm256_set1_epi32(0x0000000F);\n        __m256i all_ones_mask = _mm256_cmpeq_epi32(_mm256_and_si256(vec_src, low_mask), low_mask);\n        \n        // Rotate elements where low 4 bits are all 1\n        __m256i rotated = _mm256_or_si256(\n            _mm256_slli_epi32(vec_src, rotate_bits),\n            _mm256_srli_epi32(vec_src, 32 - rotate_bits)\n        );\n        \n        // Bitwise negate elements where low 4 bits are not all 1\n        __m256i negated = _mm256_xor_si256(vec_src, _mm256_set1_epi32(0xFFFFFFFF));\n        \n        // Blend rotated and negated based on condition\n        __m256i result = _mm256_blendv_epi8(negated, rotated, all_ones_mask);\n        \n        _mm256_storeu_si256((__m256i*)&dst[i], result);\n    }\n    \n    // Handle remaining elements\n    for (; i < length; i++) {\n        if ((src[i] & 0x0000000F) == 0x0000000F) {\n            dst[i] = (src[i] << rotate_bits) | (src[i] >> (32 - rotate_bits));\n        } else {\n            dst[i] = ~src[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_48_AVX", "completion": "```cpp\nvoid matrix_conditional_bit_rotate_simd(const uint32_t* src, uint32_t* dst, uint8_t rotate_bits, size_t length) {\n    size_t i = 0;\n    for (; i + 8 <= length; i += 8) {\n        __m256i vec_src = _mm256_loadu_si256((__m256i*)&src[i]);\n        \n        // Check if low 4 bits are all 1\n        __m256i low_mask = _mm256_set1_epi32(0x0000000F);\n        __m256i all_ones_mask = _mm256_cmpeq_epi32(_mm256_and_si256(vec_src, low_mask), low_mask);\n        \n        // Rotate elements where condition is true\n        __m256i rotated = _mm256_or_si256(\n            _mm256_slli_epi32(vec_src, rotate_bits),\n            _mm256_srli_epi32(vec_src, 32 - rotate_bits)\n        );\n        \n        // Bitwise negate elements where condition is false\n        __m256i negated = _mm256_xor_si256(vec_src, _mm256_set1_epi32(0xFFFFFFFF));\n        \n        // Blend results based on condition\n        __m256i result = _mm256_blendv_epi8(negated, rotated, all_ones_mask);\n        \n        _mm256_storeu_si256((__m256i*)&dst[i], result);\n    }\n    \n    // Handle remaining elements\n    for (; i < length; i++) {\n        if ((src[i] & 0x0F) == 0x0F) {\n            dst[i] = (src[i] << rotate_bits) | (src[i] >> (32 - rotate_bits));\n        } else {\n            dst[i] = ~src[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_49_AVX", "completion": "```cpp\nvoid tensor_ternary_compare_simd(const float* A, const float* B, int8_t* out, float epsilon, size_t length) {\n    __m256 eps_vec = _mm256_set1_ps(epsilon);\n    __m256 neg_eps_vec = _mm256_sub_ps(_mm256_setzero_ps(), eps_vec);\n    \n    size_t i = 0;\n    for (; i + 8 <= length; i += 8) {\n        __m256 a_vec = _mm256_loadu_ps(A + i);\n        __m256 b_vec = _mm256_loadu_ps(B + i);\n        \n        __m256 diff_vec = _mm256_sub_ps(a_vec, b_vec);\n        \n        __m256 gt_eps = _mm256_cmp_ps(diff_vec, eps_vec, _CMP_GT_OQ);\n        __m256 lt_neg_eps = _mm256_cmp_ps(diff_vec, neg_eps_vec, _CMP_LT_OQ);\n        \n        __m256i result_vec = _mm256_setzero_si256();\n        result_vec = _mm256_sub_epi8(result_vec, _mm256_castps_si256(gt_eps));\n        result_vec = _mm256_add_epi8(result_vec, _mm256_castps_si256(lt_neg_eps));\n        \n        _mm256_storeu_si256((__m256i*)(out + i), result_vec);\n    }\n    \n    for (; i < length; ++i) {\n        float diff = A[i] - B[i];\n        if (diff > epsilon) {\n            out[i] = 1;\n        } else if (diff < -epsilon) {\n            out[i] = -1;\n        } else {\n            out[i] = 0;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_49_AVX", "completion": "```cpp\nvoid tensor_ternary_compare_simd(const float* A, const float* B, int8_t* out, float epsilon, size_t length) {\n    __m256 eps_vec = _mm256_set1_ps(epsilon);\n    __m256 neg_eps_vec = _mm256_sub_ps(_mm256_setzero_ps(), eps_vec);\n    \n    size_t i = 0;\n    for (; i + 8 <= length; i += 8) {\n        __m256 a_vec = _mm256_loadu_ps(A + i);\n        __m256 b_vec = _mm256_loadu_ps(B + i);\n        \n        __m256 diff_vec = _mm256_sub_ps(a_vec, b_vec);\n        \n        __m256 gt_mask = _mm256_cmp_ps(diff_vec, eps_vec, _CMP_GT_OQ);\n        __m256 lt_mask = _mm256_cmp_ps(diff_vec, neg_eps_vec, _CMP_LT_OQ);\n        \n        __m256i result_vec = _mm256_setzero_si256();\n        result_vec = _mm256_sub_epi8(result_vec, _mm256_castps_si256(gt_mask));\n        result_vec = _mm256_add_epi8(result_vec, _mm256_castps_si256(lt_mask));\n        \n        _mm256_storeu_si256((__m256i*)(out + i), result_vec);\n    }\n    \n    for (; i < length; ++i) {\n        float diff = A[i] - B[i];\n        if (diff > epsilon) {\n            out[i] = 1;\n        } else if (diff < -epsilon) {\n            out[i] = -1;\n        } else {\n            out[i] = 0;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_49_AVX", "completion": "```cpp\nvoid tensor_ternary_compare_simd(const float* A, const float* B, int8_t* out, float epsilon, size_t length) {\n    __m256 eps_vec = _mm256_set1_ps(epsilon);\n    __m256 neg_eps_vec = _mm256_sub_ps(_mm256_setzero_ps(), eps_vec);\n    \n    size_t i = 0;\n    for (; i + 8 <= length; i += 8) {\n        __m256 a_vec = _mm256_loadu_ps(A + i);\n        __m256 b_vec = _mm256_loadu_ps(B + i);\n        \n        __m256 diff_vec = _mm256_sub_ps(a_vec, b_vec);\n        \n        __m256 gt_eps = _mm256_cmp_ps(diff_vec, eps_vec, _CMP_GT_OQ);\n        __m256 lt_neg_eps = _mm256_cmp_ps(diff_vec, neg_eps_vec, _CMP_LT_OQ);\n        \n        __m256i result_vec = _mm256_setzero_si256();\n        result_vec = _mm256_sub_epi8(result_vec, _mm256_castps_si256(gt_eps));\n        result_vec = _mm256_add_epi8(result_vec, _mm256_castps_si256(lt_neg_eps));\n        \n        _mm256_storeu_si256((__m256i*)(out + i), result_vec);\n    }\n    \n    for (; i < length; ++i) {\n        float diff = A[i] - B[i];\n        if (diff > epsilon) \n            out[i] = 1;\n        else if (diff < -epsilon)\n            out[i] = -1;\n        else \n            out[i] = 0;\n    }\n}\n```"}
{"task_id": "SimdBench_49_AVX", "completion": "```cpp\nvoid tensor_ternary_compare_simd(const float* A, const float* B, int8_t* out, float epsilon, size_t length) {\n    __m256 eps_vec = _mm256_set1_ps(epsilon);\n    __m256 neg_eps_vec = _mm256_sub_ps(_mm256_setzero_ps(), eps_vec);\n\n    size_t i = 0;\n    for (; i + 8 <= length; i += 8) {\n        __m256 a_vec = _mm256_loadu_ps(A + i);\n        __m256 b_vec = _mm256_loadu_ps(B + i);\n        \n        __m256 diff_vec = _mm256_sub_ps(a_vec, b_vec);\n        \n        __m256 gt_mask = _mm256_cmp_ps(diff_vec, eps_vec, _CMP_GT_OQ);\n        __m256 lt_mask = _mm256_cmp_ps(diff_vec, neg_eps_vec, _CMP_LT_OQ);\n        \n        __m256i result_vec = _mm256_setzero_si256();\n        result_vec = _mm256_sub_epi8(result_vec, _mm256_castps_si256(gt_mask));\n        result_vec = _mm256_add_epi8(result_vec, _mm256_castps_si256(lt_mask));\n        \n        _mm256_storeu_si256((__m256i*)(out + i), result_vec);\n    }\n\n    for (; i < length; ++i) {\n        float diff = A[i] - B[i];\n        if (diff > epsilon) {\n            out[i] = 1;\n        } else if (diff < -epsilon) {\n            out[i] = -1;\n        } else {\n            out[i] = 0;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_49_AVX", "completion": "```cpp\nvoid tensor_ternary_compare_simd(const float* A, const float* B, int8_t* out, float epsilon, size_t length) {\n    __m256 eps_vec = _mm256_set1_ps(epsilon);\n    __m256 neg_eps_vec = _mm256_sub_ps(_mm256_setzero_ps(), eps_vec);\n    \n    size_t i = 0;\n    for (; i + 8 <= length; i += 8) {\n        __m256 a_vec = _mm256_loadu_ps(A + i);\n        __m256 b_vec = _mm256_loadu_ps(B + i);\n        \n        __m256 diff_vec = _mm256_sub_ps(a_vec, b_vec);\n        \n        __m256 gt_mask = _mm256_cmp_ps(diff_vec, eps_vec, _CMP_GT_OQ);\n        __m256 lt_mask = _mm256_cmp_ps(diff_vec, neg_eps_vec, _CMP_LT_OQ);\n        \n        __m256i result_vec = _mm256_setzero_si256();\n        result_vec = _mm256_sub_epi8(result_vec, _mm256_castps_si256(gt_mask));\n        result_vec = _mm256_add_epi8(result_vec, _mm256_castps_si256(lt_mask));\n        \n        _mm256_storeu_si256((__m256i*)(out + i), result_vec);\n    }\n    \n    for (; i < length; ++i) {\n        float diff = A[i] - B[i];\n        if (diff > epsilon) {\n            out[i] = 1;\n        } else if (diff < -epsilon) {\n            out[i] = -1;\n        } else {\n            out[i] = 0;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_50_AVX", "completion": "```cpp\nvoid float_to_int_saturate_simd(const float* A, int32_t* B, size_t size) {\n    size_t i = 0;\n    const __m256 max_val = _mm256_set1_ps((float)INT32_MAX);\n    const __m256 min_val = _mm256_set1_ps((float)INT32_MIN);\n\n    // Process 8 floats at a time\n    for (; i + 8 <= size; i += 8) {\n        // Load 8 floats\n        __m256 float_vec = _mm256_loadu_ps(A + i);\n\n        // Clamp values between INT32_MIN and INT32_MAX\n        float_vec = _mm256_min_ps(float_vec, max_val);\n        float_vec = _mm256_max_ps(float_vec, min_val);\n\n        // Convert to int32_t\n        __m256i int_vec = _mm256_cvttps_epi32(float_vec);\n\n        // Store 8 int32_t values\n        _mm256_storeu_si256((__m256i*)(B + i), int_vec);\n    }\n\n    // Handle remaining elements\n    for (; i < size; i++) {\n        if (A[i] > INT32_MAX) \n            B[i] = INT32_MAX;\n        else if (A[i] < INT32_MIN)\n            B[i] = INT32_MIN;\n        else \n            B[i] = (int32_t)A[i];\n    }\n}\n```"}
{"task_id": "SimdBench_50_AVX", "completion": "```cpp\nvoid float_to_int_saturate_simd(const float* A, int32_t* B, size_t size) {\n    size_t i = 0;\n    const __m256 max_val = _mm256_set1_ps((float)INT32_MAX);\n    const __m256 min_val = _mm256_set1_ps((float)INT32_MIN);\n\n    // Process 8 floats at a time\n    for (; i + 8 <= size; i += 8) {\n        // Load 8 float values\n        __m256 float_vec = _mm256_loadu_ps(&A[i]);\n\n        // Clamp values between INT32_MIN and INT32_MAX\n        float_vec = _mm256_min_ps(float_vec, max_val);\n        float_vec = _mm256_max_ps(float_vec, min_val);\n\n        // Convert to int32_t\n        __m256i int_vec = _mm256_cvttps_epi32(float_vec);\n\n        // Store result\n        _mm256_storeu_si256((__m256i*)&B[i], int_vec);\n    }\n\n    // Handle remaining elements\n    for (; i < size; i++) {\n        if (A[i] > INT32_MAX) \n            B[i] = INT32_MAX;\n        else if (A[i] < INT32_MIN)\n            B[i] = INT32_MIN;\n        else \n            B[i] = (int32_t)A[i];\n    }\n}\n```"}
{"task_id": "SimdBench_50_AVX", "completion": "```cpp\nvoid float_to_int_saturate_simd(const float* A, int32_t* B, size_t size) {\n    size_t i = 0;\n    const __m256 max_val = _mm256_set1_ps((float)INT32_MAX);\n    const __m256 min_val = _mm256_set1_ps((float)INT32_MIN);\n\n    // Process 8 floats at a time\n    for (; i + 8 <= size; i += 8) {\n        // Load 8 floats\n        __m256 float_vec = _mm256_loadu_ps(A + i);\n\n        // Clamp values between INT32_MIN and INT32_MAX\n        float_vec = _mm256_min_ps(float_vec, max_val);\n        float_vec = _mm256_max_ps(float_vec, min_val);\n\n        // Convert to integers\n        __m256i int_vec = _mm256_cvttps_epi32(float_vec);\n\n        // Store 8 integers\n        _mm256_storeu_si256((__m256i*)(B + i), int_vec);\n    }\n\n    // Handle remaining elements\n    for (; i < size; i++) {\n        B[i] = (A[i] > INT32_MAX) ? INT32_MAX : \n               (A[i] < INT32_MIN) ? INT32_MIN : \n               (int32_t)A[i];\n    }\n}\n```"}
{"task_id": "SimdBench_50_AVX", "completion": "```cpp\nvoid float_to_int_saturate_simd(const float* A, int32_t* B, size_t size) {\n    size_t i = 0;\n    const __m256 max_val = _mm256_set1_ps((float)INT32_MAX);\n    const __m256 min_val = _mm256_set1_ps((float)INT32_MIN);\n\n    for (; i + 8 <= size; i += 8) {\n        __m256 float_vec = _mm256_loadu_ps(&A[i]);\n        \n        // Clamp values to INT32_MAX and INT32_MIN\n        float_vec = _mm256_min_ps(float_vec, max_val);\n        float_vec = _mm256_max_ps(float_vec, min_val);\n        \n        // Convert to int32_t\n        __m256i int_vec = _mm256_cvtps_epi32(float_vec);\n        \n        // Store result\n        _mm256_storeu_si256((__m256i*)&B[i], int_vec);\n    }\n\n    // Handle remaining elements\n    for (; i < size; i++) {\n        if (A[i] > INT32_MAX) {\n            B[i] = INT32_MAX;\n        } else if (A[i] < INT32_MIN) {\n            B[i] = INT32_MIN;\n        } else {\n            B[i] = (int32_t)A[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_50_AVX", "completion": "```cpp\nvoid float_to_int_saturate_simd(const float* A, int32_t* B, size_t size) {\n    size_t i = 0;\n    const __m256 max_val = _mm256_set1_ps((float)INT32_MAX);\n    const __m256 min_val = _mm256_set1_ps((float)INT32_MIN);\n\n    // Process 8 floats at a time\n    for (; i + 8 <= size; i += 8) {\n        // Load 8 floats\n        __m256 float_vec = _mm256_loadu_ps(A + i);\n\n        // Clamp values between INT32_MIN and INT32_MAX\n        float_vec = _mm256_min_ps(float_vec, max_val);\n        float_vec = _mm256_max_ps(float_vec, min_val);\n\n        // Convert to int32_t\n        __m256i int_vec = _mm256_cvttps_epi32(float_vec);\n\n        // Store 8 int32_t values\n        _mm256_storeu_si256((__m256i*)(B + i), int_vec);\n    }\n\n    // Handle remaining elements\n    for (; i < size; i++) {\n        if (A[i] > INT32_MAX) {\n            B[i] = INT32_MAX;\n        } else if (A[i] < INT32_MIN) {\n            B[i] = INT32_MIN;\n        } else {\n            B[i] = (int32_t)A[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_51_AVX", "completion": "```cpp\nvoid int_to_float_scaled_simd(const int32_t* A, int8_t scale, float* B, size_t size) {\n    __m256 scale_vec = _mm256_set1_ps((float)scale);\n    size_t i = 0;\n\n    for (; i + 8 <= size; i += 8) {\n        __m256i int_vec = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256 float_vec = _mm256_cvtepi32_ps(int_vec);\n        float_vec = _mm256_mul_ps(float_vec, scale_vec);\n        _mm256_storeu_ps(&B[i], float_vec);\n    }\n\n    for (; i < size; i++) {\n        B[i] = (float)A[i] * scale;\n    }\n}\n```"}
{"task_id": "SimdBench_51_AVX", "completion": "```cpp\nvoid int_to_float_scaled_simd(const int32_t* A, int8_t scale, float* B, size_t size) {\n    __m256 scale_vec = _mm256_set1_ps((float)scale);\n    size_t i = 0;\n\n    for (; i + 8 <= size; i += 8) {\n        __m256i int_vec = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256 float_vec = _mm256_cvtepi32_ps(int_vec);\n        float_vec = _mm256_mul_ps(float_vec, scale_vec);\n        _mm256_storeu_ps(&B[i], float_vec);\n    }\n\n    for (; i < size; i++) {\n        B[i] = (float)A[i] * scale;\n    }\n}\n```"}
{"task_id": "SimdBench_51_AVX", "completion": "```cpp\nvoid int_to_float_scaled_simd(const int32_t* A, int8_t scale, float* B, size_t size) {\n    __m256 scale_vec = _mm256_set1_ps((float)scale);\n    size_t i = 0;\n\n    for (; i + 8 <= size; i += 8) {\n        __m256i int_vec = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256 float_vec = _mm256_cvtepi32_ps(int_vec);\n        float_vec = _mm256_mul_ps(float_vec, scale_vec);\n        _mm256_storeu_ps(&B[i], float_vec);\n    }\n\n    for (; i < size; i++) {\n        B[i] = (float)A[i] * scale;\n    }\n}\n```"}
{"task_id": "SimdBench_51_AVX", "completion": "```cpp\nvoid int_to_float_scaled_simd(const int32_t* A, int8_t scale, float* B, size_t size) {\n    __m256 scale_vec = _mm256_set1_ps((float)scale);\n    size_t i = 0;\n\n    for (; i + 8 <= size; i += 8) {\n        __m256i int_vec = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256 float_vec = _mm256_cvtepi32_ps(int_vec);\n        float_vec = _mm256_mul_ps(float_vec, scale_vec);\n        _mm256_storeu_ps(&B[i], float_vec);\n    }\n\n    for (; i < size; i++) {\n        B[i] = (float)A[i] * scale;\n    }\n}\n```"}
{"task_id": "SimdBench_51_AVX", "completion": "```cpp\nvoid int_to_float_scaled_simd(const int32_t* A, int8_t scale, float* B, size_t size) {\n    __m256 scale_vec = _mm256_set1_ps((float)scale);\n    size_t i = 0;\n\n    for (; i + 8 <= size; i += 8) {\n        __m256i int_vec = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256 float_vec = _mm256_cvtepi32_ps(int_vec);\n        float_vec = _mm256_mul_ps(float_vec, scale_vec);\n        _mm256_storeu_ps(&B[i], float_vec);\n    }\n\n    for (; i < size; i++) {\n        B[i] = (float)A[i] * scale;\n    }\n}\n```"}
{"task_id": "SimdBench_52_AVX", "completion": "```cpp\nvoid float_div_round_simd(const float* A, const float* B, int32_t* C, size_t size) {\n    size_t i = 0;\n    for (; i + 8 <= size; i += 8) {\n        __m256 a_vec = _mm256_loadu_ps(&A[i]);\n        __m256 b_vec = _mm256_loadu_ps(&B[i]);\n        \n        __m256 div_vec = _mm256_div_ps(a_vec, b_vec);\n        __m256 rounded_vec = _mm256_round_ps(div_vec, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n        \n        __m256i int_vec = _mm256_cvtps_epi32(rounded_vec);\n        _mm256_storeu_si256((__m256i*)&C[i], int_vec);\n    }\n    \n    for (; i < size; i++) {\n        C[i] = (int32_t)roundf(A[i] / B[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_52_AVX", "completion": "```cpp\nvoid float_div_round_simd(const float* A, const float* B, int32_t* C, size_t size) {\n    size_t i = 0;\n    \n    // Process 8 elements at a time using AVX\n    for (; i + 8 <= size; i += 8) {\n        __m256 va = _mm256_loadu_ps(A + i);\n        __m256 vb = _mm256_loadu_ps(B + i);\n        \n        // Perform element-wise division\n        __m256 vdiv = _mm256_div_ps(va, vb);\n        \n        // Round to nearest integer\n        __m256 vrounded = _mm256_round_ps(vdiv, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n        \n        // Convert to 32-bit integers\n        __m256i vinteger = _mm256_cvtps_epi32(vrounded);\n        \n        // Store result\n        _mm256_storeu_si256((__m256i*)(C + i), vinteger);\n    }\n    \n    // Handle remaining elements\n    for (; i < size; i++) {\n        C[i] = (int32_t)roundf(A[i] / B[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_52_AVX", "completion": "```cpp\nvoid float_div_round_simd(const float* A, const float* B, int32_t* C, size_t size) {\n    size_t i = 0;\n    \n    // Process 8 elements at a time with AVX\n    for (; i + 8 <= size; i += 8) {\n        __m256 va = _mm256_loadu_ps(A + i);\n        __m256 vb = _mm256_loadu_ps(B + i);\n        \n        // Perform element-wise division\n        __m256 vdiv = _mm256_div_ps(va, vb);\n        \n        // Round to nearest integer\n        __m256 vrounded = _mm256_round_ps(vdiv, _MM_FROUND_TO_NEAREST_INT);\n        \n        // Convert to 32-bit integers\n        __m256i vinteger = _mm256_cvtps_epi32(vrounded);\n        \n        // Store result\n        _mm256_storeu_si256((__m256i*)(C + i), vinteger);\n    }\n    \n    // Handle remaining elements\n    for (; i < size; i++) {\n        C[i] = static_cast<int32_t>(std::round(A[i] / B[i]));\n    }\n}\n```"}
{"task_id": "SimdBench_52_AVX", "completion": "```cpp\nvoid float_div_round_simd(const float* A, const float* B, int32_t* C, size_t size) {\n    size_t i = 0;\n    const size_t vector_width = 8; // AVX can process 8 floats at once\n\n    // Process 8 elements at a time using AVX\n    for (; i + vector_width <= size; i += vector_width) {\n        __m256 va = _mm256_loadu_ps(A + i);\n        __m256 vb = _mm256_loadu_ps(B + i);\n        \n        // Perform element-wise division\n        __m256 vdiv = _mm256_div_ps(va, vb);\n        \n        // Round to nearest integer\n        __m256 vrounded = _mm256_round_ps(vdiv, _MM_FROUND_TO_NEAREST_INT);\n        \n        // Convert float to int32\n        __m256i vint = _mm256_cvtps_epi32(vrounded);\n        \n        // Store result\n        _mm256_storeu_si256((__m256i*)(C + i), vint);\n    }\n\n    // Handle remaining elements\n    for (; i < size; i++) {\n        C[i] = static_cast<int32_t>(std::round(A[i] / B[i]));\n    }\n}\n```"}
{"task_id": "SimdBench_52_AVX", "completion": "```cpp\nvoid float_div_round_simd(const float* A, const float* B, int32_t* C, size_t size) {\n    size_t i = 0;\n    const size_t vector_width = 8; // AVX can process 8 floats at a time\n\n    // Process 8 elements at a time using AVX\n    for (; i + vector_width <= size; i += vector_width) {\n        __m256 va = _mm256_loadu_ps(A + i);\n        __m256 vb = _mm256_loadu_ps(B + i);\n        \n        // Perform element-wise division\n        __m256 vdiv = _mm256_div_ps(va, vb);\n        \n        // Round to nearest integer\n        __m256 vrounded = _mm256_round_ps(vdiv, _MM_FROUND_TO_NEAREST_INT);\n        \n        // Convert float to int32\n        __m256i vint = _mm256_cvtps_epi32(vrounded);\n        \n        // Store result\n        _mm256_storeu_si256((__m256i*)(C + i), vint);\n    }\n\n    // Handle remaining elements\n    for (; i < size; i++) {\n        C[i] = static_cast<int32_t>(std::round(A[i] / B[i]));\n    }\n}\n```"}
{"task_id": "SimdBench_53_AVX", "completion": "```cpp\nvoid double_to_float_saturate_simd(const double* A, float* B, size_t size) {\n    const __m256 max_val = _mm256_set1_ps(FLT_MAX);\n    const __m256 min_val = _mm256_set1_ps(-FLT_MAX);\n    \n    size_t i = 0;\n    for (; i + 8 <= size; i += 8) {\n        // Load 8 double values\n        __m256d vec_a_low = _mm256_loadu_pd(A + i);\n        __m256d vec_a_high = _mm256_loadu_pd(A + i + 4);\n        \n        // Convert first 4 doubles to floats\n        __m256 vec_b_low = _mm256_cvtpd_ps(vec_a_low);\n        \n        // Convert next 4 doubles to floats\n        __m256 vec_b_high = _mm256_cvtpd_ps(vec_a_high);\n        \n        // Combine the two float vectors\n        __m256 vec_b = _mm256_insertf128_ps(vec_b_low, _mm256_castps256_ps128(vec_b_high), 1);\n        \n        // Saturate values\n        vec_b = _mm256_min_ps(vec_b, max_val);\n        vec_b = _mm256_max_ps(vec_b, min_val);\n        \n        // Store results\n        _mm256_storeu_ps(B + i, vec_b);\n    }\n    \n    // Handle remaining elements\n    for (; i < size; i++) {\n        float converted = (float)A[i];\n        B[i] = (converted > FLT_MAX) ? FLT_MAX : \n               (converted < -FLT_MAX) ? -FLT_MAX : converted;\n    }\n}\n```"}
{"task_id": "SimdBench_53_AVX", "completion": "```cpp\nvoid double_to_float_saturate_simd(const double* A, float* B, size_t size) {\n    const __m256 max_val = _mm256_set1_ps(FLT_MAX);\n    const __m256 min_val = _mm256_set1_ps(-FLT_MAX);\n    \n    size_t i = 0;\n    for (; i + 8 <= size; i += 8) {\n        // Load 8 double values\n        __m256d vec_a_lo = _mm256_loadu_pd(A + i);\n        __m256d vec_a_hi = _mm256_loadu_pd(A + i + 4);\n        \n        // Convert lower 4 doubles to floats\n        __m256 vec_b_lo = _mm256_cvtpd_ps(vec_a_lo);\n        \n        // Convert upper 4 doubles to floats\n        __m256 vec_b_hi = _mm256_cvtpd_ps(vec_a_hi);\n        \n        // Combine the two float vectors\n        __m256 vec_b = _mm256_insertf128_ps(vec_b_lo, _mm256_extractf128_ps(vec_b_hi, 0), 1);\n        \n        // Saturate values\n        vec_b = _mm256_min_ps(vec_b, max_val);\n        vec_b = _mm256_max_ps(vec_b, min_val);\n        \n        // Store results\n        _mm256_storeu_ps(B + i, vec_b);\n    }\n    \n    // Handle remaining elements\n    for (; i < size; ++i) {\n        if (A[i] > FLT_MAX) {\n            B[i] = FLT_MAX;\n        } else if (A[i] < -FLT_MAX) {\n            B[i] = -FLT_MAX;\n        } else {\n            B[i] = (float)A[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_53_AVX", "completion": "```cpp\nvoid double_to_float_saturate_simd(const double* A, float* B, size_t size) {\n    const __m256 max_val = _mm256_set1_ps(FLT_MAX);\n    const __m256 min_val = _mm256_set1_ps(-FLT_MAX);\n    \n    size_t i = 0;\n    for (; i + 8 <= size; i += 8) {\n        // Load 8 double values\n        __m256d vec_a_low = _mm256_loadu_pd(A + i);\n        __m256d vec_a_high = _mm256_loadu_pd(A + i + 4);\n        \n        // Convert first 4 doubles to floats\n        __m256 vec_b_low = _mm256_cvtpd_ps(vec_a_low);\n        \n        // Convert next 4 doubles to floats\n        __m256 vec_b_high = _mm256_cvtpd_ps(vec_a_high);\n        \n        // Combine low and high parts\n        __m256 vec_b = _mm256_insertf128_ps(vec_b_low, _mm256_extractf128_ps(vec_b_high, 0), 1);\n        \n        // Saturate values\n        vec_b = _mm256_min_ps(vec_b, max_val);\n        vec_b = _mm256_max_ps(vec_b, min_val);\n        \n        // Store result\n        _mm256_storeu_ps(B + i, vec_b);\n    }\n    \n    // Handle remaining elements\n    for (; i < size; ++i) {\n        float converted = (float)A[i];\n        B[i] = (converted > FLT_MAX) ? FLT_MAX : \n               (converted < -FLT_MAX) ? -FLT_MAX : converted;\n    }\n}\n```"}
{"task_id": "SimdBench_53_AVX", "completion": "```cpp\nvoid double_to_float_saturate_simd(const double* A, float* B, size_t size) {\n    const __m256 max_val = _mm256_set1_ps(FLT_MAX);\n    const __m256 min_val = _mm256_set1_ps(-FLT_MAX);\n    \n    size_t i = 0;\n    for (; i + 8 <= size; i += 8) {\n        // Load 8 double values\n        __m256d vec_a_lo = _mm256_loadu_pd(A + i);\n        __m256d vec_a_hi = _mm256_loadu_pd(A + i + 4);\n        \n        // Convert lower 4 doubles to floats\n        __m128 vec_b_lo = _mm256_cvtpd_ps(vec_a_lo);\n        \n        // Convert upper 4 doubles to floats\n        __m128 vec_b_hi = _mm256_cvtpd_ps(vec_a_hi);\n        \n        // Combine the two float vectors\n        __m256 vec_b = _mm256_insertf128_ps(_mm256_castps128_ps256(vec_b_lo), vec_b_hi, 1);\n        \n        // Saturate values\n        vec_b = _mm256_min_ps(vec_b, max_val);\n        vec_b = _mm256_max_ps(vec_b, min_val);\n        \n        // Store results\n        _mm256_storeu_ps(B + i, vec_b);\n    }\n    \n    // Handle remaining elements\n    for (; i < size; i++) {\n        float converted = (float)A[i];\n        B[i] = (converted > FLT_MAX) ? FLT_MAX : \n               (converted < -FLT_MAX) ? -FLT_MAX : converted;\n    }\n}\n```"}
{"task_id": "SimdBench_53_AVX", "completion": "```cpp\nvoid double_to_float_saturate_simd(const double* A, float* B, size_t size) {\n    const __m256 max_val = _mm256_set1_ps(FLT_MAX);\n    const __m256 min_val = _mm256_set1_ps(-FLT_MAX);\n    \n    size_t i = 0;\n    for (; i + 8 <= size; i += 8) {\n        // Load 8 double values\n        __m256d vec_a_low = _mm256_loadu_pd(A + i);\n        __m256d vec_a_high = _mm256_loadu_pd(A + i + 4);\n        \n        // Convert first 4 doubles to floats\n        __m256 vec_b_low = _mm256_cvtpd_ps(vec_a_low);\n        \n        // Convert next 4 doubles to floats\n        __m256 vec_b_high = _mm256_cvtpd_ps(vec_a_high);\n        \n        // Combine the two vectors\n        __m256 vec_b = _mm256_insertf128_ps(vec_b_low, _mm256_castps256_ps128(vec_b_high), 1);\n        \n        // Saturate values\n        vec_b = _mm256_min_ps(vec_b, max_val);\n        vec_b = _mm256_max_ps(vec_b, min_val);\n        \n        // Store results\n        _mm256_storeu_ps(B + i, vec_b);\n    }\n    \n    // Handle remaining elements\n    for (; i < size; i++) {\n        float converted = (float)A[i];\n        B[i] = (converted > FLT_MAX) ? FLT_MAX : \n               (converted < -FLT_MAX) ? -FLT_MAX : converted;\n    }\n}\n```"}
{"task_id": "SimdBench_54_AVX", "completion": "```cpp\nvoid int16_to_int32_simd(const int16_t* A, int32_t* B, size_t size) {\n    size_t i = 0;\n    \n    // Process 16 elements at a time using AVX2\n    for (; i + 16 <= size; i += 16) {\n        __m256i input = _mm256_loadu_si256((__m256i*)&A[i]);\n        \n        // Convert lower 8 int16_t to int32_t\n        __m256i low = _mm256_cvtepi16_epi32(_mm_loadu_si128((__m128i*)&A[i]));\n        \n        // Convert upper 8 int16_t to int32_t\n        __m256i high = _mm256_cvtepi16_epi32(_mm_loadu_si128((__m128i*)&A[i + 8]));\n        \n        _mm256_storeu_si256((__m256i*)&B[i], low);\n        _mm256_storeu_si256((__m256i*)&B[i + 8], high);\n    }\n    \n    // Handle remaining elements\n    for (; i < size; i++) {\n        B[i] = (int32_t)A[i];\n    }\n}\n```"}
{"task_id": "SimdBench_54_AVX", "completion": "```cpp\nvoid int16_to_int32_simd(const int16_t* A, int32_t* B, size_t size) {\n    size_t i = 0;\n    \n    // Process 16 elements at a time using AVX2\n    for (; i + 16 <= size; i += 16) {\n        __m256i input = _mm256_loadu_si256((__m256i*)&A[i]);\n        \n        // Convert lower 8 int16_t to int32_t\n        __m256i low = _mm256_cvtepi16_epi32(_mm_loadu_si128((__m128i*)&A[i]));\n        \n        // Convert upper 8 int16_t to int32_t\n        __m256i high = _mm256_cvtepi16_epi32(_mm_loadu_si128((__m128i*)&A[i + 8]));\n        \n        _mm256_storeu_si256((__m256i*)&B[i], low);\n        _mm256_storeu_si256((__m256i*)&B[i + 8], high);\n    }\n    \n    // Handle remaining elements\n    for (; i < size; i++) {\n        B[i] = (int32_t)A[i];\n    }\n}\n```"}
{"task_id": "SimdBench_54_AVX", "completion": "```cpp\nvoid int16_to_int32_simd(const int16_t* A, int32_t* B, size_t size) {\n    size_t i = 0;\n    \n    // Process 16 elements at a time using AVX2\n    for (; i + 16 <= size; i += 16) {\n        __m256i input = _mm256_loadu_si256((__m256i*)&A[i]);\n        \n        // Convert lower 8 int16_t to int32_t\n        __m256i low = _mm256_cvtepi16_epi32(_mm_loadu_si128((__m128i*)&A[i]));\n        \n        // Convert upper 8 int16_t to int32_t\n        __m256i high = _mm256_cvtepi16_epi32(_mm_loadu_si128((__m128i*)&A[i + 8]));\n        \n        _mm256_storeu_si256((__m256i*)&B[i], low);\n        _mm256_storeu_si256((__m256i*)&B[i + 8], high);\n    }\n    \n    // Handle remaining elements\n    for (; i < size; i++) {\n        B[i] = (int32_t)A[i];\n    }\n}\n```"}
{"task_id": "SimdBench_54_AVX", "completion": "```cpp\nvoid int16_to_int32_simd(const int16_t* A, int32_t* B, size_t size) {\n    size_t i = 0;\n    for (; i + 16 <= size; i += 16) {\n        __m256i input = _mm256_loadu_si256((__m256i*)&A[i]);\n        \n        // Convert lower 8 16-bit integers to 32-bit integers\n        __m256i low = _mm256_cvtepi16_epi32(_mm256_extracti128_si256(input, 0));\n        _mm256_storeu_si256((__m256i*)&B[i], low);\n        \n        // Convert upper 8 16-bit integers to 32-bit integers\n        __m256i high = _mm256_cvtepi16_epi32(_mm256_extracti128_si256(input, 1));\n        _mm256_storeu_si256((__m256i*)&B[i + 8], high);\n    }\n    \n    // Handle remaining elements\n    for (; i < size; i++) {\n        B[i] = (int32_t)A[i];\n    }\n}\n```"}
{"task_id": "SimdBench_54_AVX", "completion": "```cpp\nvoid int16_to_int32_simd(const int16_t* A, int32_t* B, size_t size) {\n    size_t i = 0;\n    \n    // Process 16 elements at a time using AVX2\n    for (; i + 16 <= size; i += 16) {\n        __m256i input = _mm256_loadu_si256((__m256i*)&A[i]);\n        \n        // Convert lower 8 16-bit integers to 32-bit integers\n        __m256i low = _mm256_cvtepi16_epi32(_mm_loadu_si128((__m128i*)&A[i]));\n        \n        // Convert upper 8 16-bit integers to 32-bit integers\n        __m256i high = _mm256_cvtepi16_epi32(_mm_loadu_si128((__m128i*)&A[i + 8]));\n        \n        _mm256_storeu_si256((__m256i*)&B[i], low);\n        _mm256_storeu_si256((__m256i*)&B[i + 8], high);\n    }\n    \n    // Handle remaining elements\n    for (; i < size; i++) {\n        B[i] = (int32_t)A[i];\n    }\n}\n```"}
{"task_id": "SimdBench_55_AVX", "completion": "```cpp\nvoid conditional_normalize_simd(const float* A, const int32_t* control, float* B, size_t size, float min_val, float max_val) {\n    __m256 min_vec = _mm256_set1_ps(min_val);\n    __m256 max_vec = _mm256_set1_ps(max_val);\n    __m256 zero_vec = _mm256_setzero_ps();\n    __m256 one_vec = _mm256_set1_ps(1.0f);\n    \n    size_t i = 0;\n    for (; i + 8 <= size; i += 8) {\n        __m256 a_vec = _mm256_loadu_ps(A + i);\n        __m256i control_vec = _mm256_loadu_si256((__m256i*)(control + i));\n        \n        __m256 normalized_vec = _mm256_sub_ps(a_vec, min_vec);\n        __m256 range_vec = _mm256_sub_ps(max_vec, min_vec);\n        normalized_vec = _mm256_div_ps(normalized_vec, range_vec);\n        \n        normalized_vec = _mm256_max_ps(normalized_vec, zero_vec);\n        normalized_vec = _mm256_min_ps(normalized_vec, one_vec);\n        \n        __m256 mask = _mm256_cmp_ps(_mm256_cvtepi32_ps(control_vec), zero_vec, _CMP_GT_OS);\n        \n        __m256 result_vec = _mm256_blendv_ps(a_vec, normalized_vec, mask);\n        \n        _mm256_storeu_ps(B + i, result_vec);\n    }\n    \n    for (; i < size; ++i) {\n        if (control[i] > 0) {\n            float val = (A[i] - min_val) / (max_val - min_val);\n            B[i] = (val < 0.0f) ? 0.0f : (val > 1.0f) ? 1.0f : val;\n        } else {\n            B[i] = A[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_55_AVX", "completion": "```cpp\nvoid conditional_normalize_simd(const float* A, const int32_t* control, float* B, size_t size, float min_val, float max_val) {\n    __m256 min_vec = _mm256_set1_ps(min_val);\n    __m256 max_vec = _mm256_set1_ps(max_val);\n    __m256 zero_vec = _mm256_setzero_ps();\n    __m256 one_vec = _mm256_set1_ps(1.0f);\n    \n    size_t i = 0;\n    for (; i + 8 <= size; i += 8) {\n        __m256 a_vec = _mm256_loadu_ps(A + i);\n        __m256i control_vec = _mm256_loadu_si256((__m256i*)(control + i));\n        \n        __m256 normalized_vec = _mm256_sub_ps(a_vec, min_vec);\n        __m256 denominator = _mm256_sub_ps(max_vec, min_vec);\n        normalized_vec = _mm256_div_ps(normalized_vec, denominator);\n        \n        normalized_vec = _mm256_max_ps(normalized_vec, zero_vec);\n        normalized_vec = _mm256_min_ps(normalized_vec, one_vec);\n        \n        __m256 result_vec = _mm256_blendv_ps(a_vec, normalized_vec, \n            _mm256_cmp_ps(_mm256_cvtepi32_ps(control_vec), zero_vec, _CMP_GT_OQ));\n        \n        _mm256_storeu_ps(B + i, result_vec);\n    }\n    \n    // Handle remaining elements\n    for (; i < size; ++i) {\n        if (control[i] > 0) {\n            float val = (A[i] - min_val) / (max_val - min_val);\n            B[i] = (val < 0.0f) ? 0.0f : (val > 1.0f) ? 1.0f : val;\n        } else {\n            B[i] = A[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_55_AVX", "completion": "```cpp\nvoid conditional_normalize_simd(const float* A, const int32_t* control, float* B, size_t size, float min_val, float max_val) {\n    __m256 min_vec = _mm256_set1_ps(min_val);\n    __m256 max_vec = _mm256_set1_ps(max_val);\n    __m256 zero_vec = _mm256_setzero_ps();\n    __m256 one_vec = _mm256_set1_ps(1.0f);\n    \n    size_t i = 0;\n    for (; i + 8 <= size; i += 8) {\n        __m256 a_vec = _mm256_loadu_ps(A + i);\n        __m256i control_vec = _mm256_loadu_si256((__m256i*)(control + i));\n        \n        __m256 normalized_vec = _mm256_sub_ps(a_vec, min_vec);\n        __m256 range_vec = _mm256_sub_ps(max_vec, min_vec);\n        normalized_vec = _mm256_div_ps(normalized_vec, range_vec);\n        \n        normalized_vec = _mm256_max_ps(normalized_vec, zero_vec);\n        normalized_vec = _mm256_min_ps(normalized_vec, one_vec);\n        \n        __m256 mask = _mm256_cmp_ps(_mm256_cvtepi32_ps(control_vec), zero_vec, _CMP_GT_OS);\n        normalized_vec = _mm256_blendv_ps(a_vec, normalized_vec, mask);\n        \n        _mm256_storeu_ps(B + i, normalized_vec);\n    }\n    \n    for (; i < size; ++i) {\n        if (control[i] > 0) {\n            float val = (A[i] - min_val) / (max_val - min_val);\n            B[i] = (val < 0.0f) ? 0.0f : (val > 1.0f) ? 1.0f : val;\n        } else {\n            B[i] = A[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_55_AVX", "completion": "```cpp\nvoid conditional_normalize_simd(const float* A, const int32_t* control, float* B, size_t size, float min_val, float max_val) {\n    __m256 min_vec = _mm256_set1_ps(min_val);\n    __m256 max_vec = _mm256_set1_ps(max_val);\n    __m256 zero_vec = _mm256_setzero_ps();\n    __m256 one_vec = _mm256_set1_ps(1.0f);\n    \n    size_t i = 0;\n    for (; i + 8 <= size; i += 8) {\n        __m256 a_vec = _mm256_loadu_ps(A + i);\n        __m256i control_vec = _mm256_loadu_si256((__m256i*)(control + i));\n        \n        __m256 normalized_vec = _mm256_sub_ps(a_vec, min_vec);\n        __m256 denominator = _mm256_sub_ps(max_vec, min_vec);\n        normalized_vec = _mm256_div_ps(normalized_vec, denominator);\n        \n        normalized_vec = _mm256_max_ps(normalized_vec, zero_vec);\n        normalized_vec = _mm256_min_ps(normalized_vec, one_vec);\n        \n        __m256 mask = _mm256_cmp_ps((__m256)control_vec, zero_vec, _CMP_GT_OS);\n        \n        __m256 result_vec = _mm256_blendv_ps(a_vec, normalized_vec, mask);\n        \n        _mm256_storeu_ps(B + i, result_vec);\n    }\n    \n    for (; i < size; ++i) {\n        if (control[i] > 0) {\n            float val = (A[i] - min_val) / (max_val - min_val);\n            B[i] = (val < 0.0f) ? 0.0f : (val > 1.0f) ? 1.0f : val;\n        } else {\n            B[i] = A[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_55_AVX", "completion": "```cpp\nvoid conditional_normalize_simd(const float* A, const int32_t* control, float* B, size_t size, float min_val, float max_val) {\n    __m256 min_vec = _mm256_set1_ps(min_val);\n    __m256 max_vec = _mm256_set1_ps(max_val);\n    __m256 zero_vec = _mm256_setzero_ps();\n    __m256 one_vec = _mm256_set1_ps(1.0f);\n    \n    size_t i = 0;\n    for (; i + 8 <= size; i += 8) {\n        __m256 a_vec = _mm256_loadu_ps(A + i);\n        __m256i control_vec = _mm256_loadu_si256((__m256i*)(control + i));\n        \n        __m256 normalized_vec = _mm256_sub_ps(a_vec, min_vec);\n        __m256 denominator_vec = _mm256_sub_ps(max_vec, min_vec);\n        normalized_vec = _mm256_div_ps(normalized_vec, denominator_vec);\n        \n        normalized_vec = _mm256_max_ps(normalized_vec, zero_vec);\n        normalized_vec = _mm256_min_ps(normalized_vec, one_vec);\n        \n        __m256 mask = _mm256_cmp_ps((__m256)control_vec, zero_vec, _CMP_GT_OS);\n        normalized_vec = _mm256_blendv_ps(a_vec, normalized_vec, mask);\n        \n        _mm256_storeu_ps(B + i, normalized_vec);\n    }\n    \n    for (; i < size; ++i) {\n        if (control[i] > 0) {\n            float val = (A[i] - min_val) / (max_val - min_val);\n            B[i] = (val < 0.0f) ? 0.0f : (val > 1.0f) ? 1.0f : val;\n        } else {\n            B[i] = A[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_56_AVX", "completion": "```cpp\nvoid int_to_float_sqrt_simd(const uint32_t* A, float* B, size_t size) {\n    size_t i = 0;\n    for (; i + 8 <= size; i += 8) {\n        // Load 8 uint32_t values from source array\n        __m256i input = _mm256_loadu_si256((__m256i*)&A[i]);\n        \n        // Shift right by 16 bits to extract high 16 bits\n        __m256i shifted = _mm256_srli_epi32(input, 16);\n        \n        // Convert to float\n        __m256 converted = _mm256_cvtepi32_ps(shifted);\n        \n        // Calculate square root\n        __m256 sqrt_result = _mm256_sqrt_ps(converted);\n        \n        // Store results in destination array\n        _mm256_storeu_ps(&B[i], sqrt_result);\n    }\n    \n    // Handle remaining elements\n    for (; i < size; i++) {\n        uint32_t high_bits = A[i] >> 16;\n        B[i] = sqrtf((float)high_bits);\n    }\n}\n```"}
{"task_id": "SimdBench_56_AVX", "completion": "```cpp\nvoid int_to_float_sqrt_simd(const uint32_t* A, float* B, size_t size) {\n    size_t i = 0;\n    for (; i + 8 <= size; i += 8) {\n        // Load 8 uint32_t values\n        __m256i input = _mm256_loadu_si256((__m256i*)&A[i]);\n        \n        // Shift right by 16 bits to extract high 16 bits\n        __m256i shifted = _mm256_srli_epi32(input, 16);\n        \n        // Convert to float\n        __m256 floats = _mm256_cvtepi32_ps(shifted);\n        \n        // Compute square root\n        __m256 sqrt_result = _mm256_sqrt_ps(floats);\n        \n        // Store results\n        _mm256_storeu_ps(&B[i], sqrt_result);\n    }\n    \n    // Handle remaining elements\n    for (; i < size; i++) {\n        uint32_t high_bits = A[i] >> 16;\n        B[i] = sqrtf((float)high_bits);\n    }\n}\n```"}
{"task_id": "SimdBench_56_AVX", "completion": "```cpp\nvoid int_to_float_sqrt_simd(const uint32_t* A, float* B, size_t size) {\n    size_t i = 0;\n    for (; i + 8 <= size; i += 8) {\n        // Load 8 uint32_t values\n        __m256i input = _mm256_loadu_si256((__m256i*)&A[i]);\n        \n        // Shift right by 16 bits to extract high 16 bits\n        __m256i shifted = _mm256_srli_epi32(input, 16);\n        \n        // Convert to float\n        __m256 floats = _mm256_cvtepi32_ps(shifted);\n        \n        // Compute square root\n        __m256 sqrt_result = _mm256_sqrt_ps(floats);\n        \n        // Store results\n        _mm256_storeu_ps(&B[i], sqrt_result);\n    }\n    \n    // Handle remaining elements\n    for (; i < size; i++) {\n        uint32_t high_bits = A[i] >> 16;\n        B[i] = sqrtf((float)high_bits);\n    }\n}\n```"}
{"task_id": "SimdBench_56_AVX", "completion": "```cpp\nvoid int_to_float_sqrt_simd(const uint32_t* A, float* B, size_t size) {\n    size_t i = 0;\n    for (; i + 8 <= size; i += 8) {\n        // Load 8 uint32_t values\n        __m256i input = _mm256_loadu_si256((__m256i*)&A[i]);\n        \n        // Shift right by 16 bits to extract high 16 bits\n        __m256i high_bits = _mm256_srli_epi32(input, 16);\n        \n        // Convert to float\n        __m256 float_values = _mm256_cvtepi32_ps(high_bits);\n        \n        // Compute square root\n        __m256 sqrt_values = _mm256_sqrt_ps(float_values);\n        \n        // Store results\n        _mm256_storeu_ps(&B[i], sqrt_values);\n    }\n    \n    // Handle remaining elements\n    for (; i < size; i++) {\n        uint32_t high_bits = A[i] >> 16;\n        B[i] = sqrtf((float)high_bits);\n    }\n}\n```"}
{"task_id": "SimdBench_56_AVX", "completion": "```cpp\nvoid int_to_float_sqrt_simd(const uint32_t* A, float* B, size_t size) {\n    size_t i = 0;\n    for (; i + 8 <= size; i += 8) {\n        // Load 8 uint32_t values\n        __m256i input = _mm256_loadu_si256((__m256i*)&A[i]);\n        \n        // Shift right by 16 bits to extract high 16 bits\n        __m256i high_bits = _mm256_srli_epi32(input, 16);\n        \n        // Convert to float\n        __m256 float_values = _mm256_cvtepi32_ps(high_bits);\n        \n        // Compute square root\n        __m256 sqrt_values = _mm256_sqrt_ps(float_values);\n        \n        // Store results\n        _mm256_storeu_ps(&B[i], sqrt_values);\n    }\n    \n    // Handle remaining elements\n    for (; i < size; i++) {\n        uint32_t high_bits = A[i] >> 16;\n        B[i] = sqrtf((float)high_bits);\n    }\n}\n```"}
{"task_id": "SimdBench_57_AVX", "completion": "```cpp\nvoid int_bits_to_float_simd(const uint32_t* A, float* B, size_t size) {\n    size_t i = 0;\n    \n    // Process 8 elements at a time using AVX\n    for (; i + 8 <= size; i += 8) {\n        __m256 converted = _mm256_castsi256_ps(_mm256_loadu_si256((__m256i*)(A + i)));\n        _mm256_storeu_ps(B + i, converted);\n    }\n    \n    // Handle remaining elements\n    for (; i < size; i++) {\n        B[i] = *((float*)(&A[i]));\n    }\n}\n```"}
{"task_id": "SimdBench_57_AVX", "completion": "```cpp\nvoid int_bits_to_float_simd(const uint32_t* A, float* B, size_t size) {\n    size_t i = 0;\n    \n    // Process 8 elements at a time using AVX\n    for (; i + 8 <= size; i += 8) {\n        __m256 converted = _mm256_castsi256_ps(_mm256_loadu_si256((__m256i*)(A + i)));\n        _mm256_storeu_ps(B + i, converted);\n    }\n    \n    // Handle remaining elements\n    for (; i < size; i++) {\n        B[i] = *((float*)(&A[i]));\n    }\n}\n```"}
{"task_id": "SimdBench_57_AVX", "completion": "```cpp\nvoid int_bits_to_float_simd(const uint32_t* A, float* B, size_t size) {\n    size_t i = 0;\n    \n    // Process 8 elements at a time using AVX\n    for (; i + 8 <= size; i += 8) {\n        __m256 converted = _mm256_castsi256_ps(_mm256_loadu_si256((__m256i*)(A + i)));\n        _mm256_storeu_ps(B + i, converted);\n    }\n    \n    // Handle remaining elements\n    for (; i < size; i++) {\n        B[i] = *((float*)(&A[i]));\n    }\n}\n```"}
{"task_id": "SimdBench_57_AVX", "completion": "```cpp\nvoid int_bits_to_float_simd(const uint32_t* A, float* B, size_t size) {\n    size_t i = 0;\n    \n    // Process 8 elements at a time using AVX\n    for (; i + 8 <= size; i += 8) {\n        __m256i int_vec = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256 float_vec = _mm256_castsi256_ps(int_vec);\n        _mm256_storeu_ps(&B[i], float_vec);\n    }\n    \n    // Handle remaining elements\n    for (; i < size; i++) {\n        B[i] = *((float*)&A[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_57_AVX", "completion": "```cpp\nvoid int_bits_to_float_simd(const uint32_t* A, float* B, size_t size) {\n    size_t i = 0;\n    \n    // Process 8 elements at a time using AVX\n    for (; i + 8 <= size; i += 8) {\n        __m256 converted = _mm256_castsi256_ps(_mm256_loadu_si256((__m256i*)(A + i)));\n        _mm256_storeu_ps(B + i, converted);\n    }\n    \n    // Handle remaining elements\n    for (; i < size; i++) {\n        B[i] = *((float*)(&A[i]));\n    }\n}\n```"}
{"task_id": "SimdBench_58_AVX", "completion": "```cpp\nvoid conditional_diff_simd(const int32_t* A, const bool* cond, float* diff, size_t size) {\n    // Set first element to 0.0f\n    diff[0] = 0.0f;\n\n    // Process 8 elements at a time using AVX\n    size_t i = 1;\n    for (; i + 7 < size; i += 8) {\n        // Load 8 integers from A\n        __m256i a_current = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i a_previous = _mm256_loadu_si256((__m256i*)&A[i-1]);\n\n        // Load 8 condition values\n        __m256i cond_vec = _mm256_loadu_si256((__m256i*)&cond[i]);\n\n        // Subtract consecutive elements\n        __m256i diff_int = _mm256_sub_epi32(a_current, a_previous);\n\n        // Convert to float\n        __m256 diff_float = _mm256_cvtepi32_ps(diff_int);\n\n        // Mask with condition\n        __m256 zero_vec = _mm256_setzero_ps();\n        __m256 masked_diff = _mm256_blendv_ps(zero_vec, diff_float, _mm256_castsi256_ps(cond_vec));\n\n        // Store results\n        _mm256_storeu_ps(&diff[i], masked_diff);\n    }\n\n    // Handle remaining elements\n    for (; i < size; i++) {\n        diff[i] = cond[i] ? (float)(A[i] - A[i-1]) : 0.0f;\n    }\n}\n```"}
{"task_id": "SimdBench_58_AVX", "completion": "```cpp\nvoid conditional_diff_simd(const int32_t* A, const bool* cond, float* diff, size_t size) {\n    // First element is always 0.0f\n    diff[0] = 0.0f;\n\n    // Process 8 elements at a time using AVX\n    size_t i = 1;\n    for (; i + 8 <= size; i += 8) {\n        // Load 8 integers from source array\n        __m256i a_current = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i a_previous = _mm256_loadu_si256((__m256i*)&A[i-1]);\n\n        // Load condition mask\n        __m256i cond_vec = _mm256_loadu_si256((__m256i*)&cond[i]);\n\n        // Compute differences\n        __m256i diff_int = _mm256_sub_epi32(a_current, a_previous);\n\n        // Convert differences to float\n        __m256 diff_float = _mm256_cvtepi32_ps(diff_int);\n\n        // Create mask for condition\n        __m256 mask = _mm256_castsi256_ps(_mm256_cmpeq_epi32(cond_vec, _mm256_set1_epi32(1)));\n\n        // Conditionally set differences or zero\n        diff_float = _mm256_and_ps(diff_float, mask);\n\n        // Store results\n        _mm256_storeu_ps(&diff[i], diff_float);\n    }\n\n    // Handle remaining elements\n    for (; i < size; i++) {\n        diff[i] = cond[i] ? (float)(A[i] - A[i-1]) : 0.0f;\n    }\n}\n```"}
{"task_id": "SimdBench_58_AVX", "completion": "```cpp\nvoid conditional_diff_simd(const int32_t* A, const bool* cond, float* diff, size_t size) {\n    // Set first element to 0.0f\n    diff[0] = 0.0f;\n\n    // Process 8 elements at a time using AVX\n    size_t i = 1;\n    for (; i + 8 <= size; i += 8) {\n        // Load 8 integers from source array\n        __m256i a_vec = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i a_prev_vec = _mm256_loadu_si256((__m256i*)&A[i-1]);\n\n        // Load 8 condition values \n        __m256i cond_vec = _mm256_loadu_si256((__m256i*)&cond[i]);\n\n        // Compute differences\n        __m256i diff_int = _mm256_sub_epi32(a_vec, a_prev_vec);\n\n        // Convert differences to float\n        __m256 diff_float = _mm256_cvtepi32_ps(diff_int);\n\n        // Mask differences based on condition\n        __m256 zero_vec = _mm256_setzero_ps();\n        __m256 masked_diff = _mm256_blendv_ps(zero_vec, diff_float, _mm256_cvtepi32_ps(cond_vec));\n\n        // Store results\n        _mm256_storeu_ps(&diff[i], masked_diff);\n    }\n\n    // Handle remaining elements\n    for (; i < size; i++) {\n        diff[i] = cond[i] ? (float)(A[i] - A[i-1]) : 0.0f;\n    }\n}\n```"}
{"task_id": "SimdBench_58_AVX", "completion": "```cpp\nvoid conditional_diff_simd(const int32_t* A, const bool* cond, float* diff, size_t size) {\n    // Set first element to 0.0f\n    diff[0] = 0.0f;\n\n    // Process 8 elements at a time using AVX\n    size_t vectorized_size = size - (size % 8);\n    for (size_t i = 1; i < vectorized_size; i += 8) {\n        // Load 8 integers from source array\n        __m256i a_vec = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i a_prev_vec = _mm256_loadu_si256((__m256i*)&A[i-1]);\n\n        // Load 8 boolean conditions\n        __m256i cond_vec = _mm256_loadu_si256((__m256i*)&cond[i]);\n\n        // Compute differences\n        __m256i diff_int_vec = _mm256_sub_epi32(a_vec, a_prev_vec);\n\n        // Convert differences to float\n        __m256 diff_float_vec = _mm256_cvtepi32_ps(diff_int_vec);\n\n        // Mask differences based on conditions\n        __m256 zero_vec = _mm256_setzero_ps();\n        __m256 masked_diff_vec = _mm256_blendv_ps(zero_vec, diff_float_vec, _mm256_castsi256_ps(cond_vec));\n\n        // Store results\n        _mm256_storeu_ps(&diff[i], masked_diff_vec);\n    }\n\n    // Handle remaining elements\n    for (size_t i = vectorized_size; i < size; ++i) {\n        diff[i] = cond[i] ? (float)(A[i] - A[i-1]) : 0.0f;\n    }\n}\n```"}
{"task_id": "SimdBench_58_AVX", "completion": "```cpp\nvoid conditional_diff_simd(const int32_t* A, const bool* cond, float* diff, size_t size) {\n    // Set first element to 0.0f\n    diff[0] = 0.0f;\n\n    // Process 8 elements at a time using AVX\n    size_t vectorized_size = size - (size % 8);\n    for (size_t i = 1; i < vectorized_size; i += 8) {\n        // Load 8 integers from A\n        __m256i a_current = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i a_previous = _mm256_loadu_si256((__m256i*)&A[i-1]);\n\n        // Load 8 condition values\n        __m256i cond_vec = _mm256_loadu_si256((__m256i*)&cond[i]);\n\n        // Compute differences\n        __m256i diff_int = _mm256_sub_epi32(a_current, a_previous);\n\n        // Convert differences to float\n        __m256 diff_float = _mm256_cvtepi32_ps(diff_int);\n\n        // Mask differences based on condition\n        __m256 zero_float = _mm256_setzero_ps();\n        __m256 masked_diff = _mm256_blendv_ps(zero_float, diff_float, _mm256_castsi256_ps(cond_vec));\n\n        // Store results\n        _mm256_storeu_ps(&diff[i], masked_diff);\n    }\n\n    // Handle remaining elements\n    for (size_t i = vectorized_size; i < size; i++) {\n        diff[i] = cond[i] ? (float)(A[i] - A[i-1]) : 0.0f;\n    }\n}\n```"}
{"task_id": "SimdBench_59_AVX", "completion": "```cpp\nvoid widening_uint_simd(const uint32_t* src, uint64_t* dst, size_t length) {\n    size_t i = 0;\n    \n    // Process 4 elements at a time using AVX2 intrinsics\n    for (; i + 4 <= length; i += 4) {\n        // Load 4 32-bit unsigned integers \n        __m128i src_vec = _mm_loadu_si128((__m128i*)&src[i]);\n        \n        // Convert lower 2 32-bit integers to 64-bit integers \n        __m128i low_vec = _mm_cvtepu32_epi64(src_vec);\n        \n        // Shift right by 32 bits to get the upper 2 32-bit integers\n        __m128i high_vec = _mm_cvtepu32_epi64(_mm_srli_si128(src_vec, 8));\n        \n        // Set high 32 bits to 1 for all 64-bit integers\n        __m128i mask = _mm_set1_epi64x(0xFFFFFFFF00000000ULL);\n        low_vec = _mm_or_si128(low_vec, mask);\n        high_vec = _mm_or_si128(high_vec, mask);\n        \n        // Store results in destination array\n        _mm_storeu_si128((__m128i*)&dst[i], low_vec);\n        _mm_storeu_si128((__m128i*)&dst[i+2], high_vec);\n    }\n    \n    // Handle remaining elements\n    for (; i < length; i++) {\n        dst[i] = (uint64_t)src[i] | 0xFFFFFFFF00000000ULL;\n    }\n}\n```"}
{"task_id": "SimdBench_59_AVX", "completion": "```cpp\nvoid widening_uint_simd(const uint32_t* src, uint64_t* dst, size_t length) {\n    size_t vector_length = length - (length % 4);\n    \n    for (size_t i = 0; i < vector_length; i += 4) {\n        // Load 4 32-bit integers from source\n        __m128i src_vec = _mm_loadu_si128((__m128i*)&src[i]);\n        \n        // Convert lower 2 32-bit integers to 64-bit integers\n        __m128i low_vec = _mm_cvtepu32_epi64(src_vec);\n        \n        // Shift right to get the upper 2 32-bit integers\n        __m128i high_vec = _mm_srli_si128(src_vec, 8);\n        \n        // Convert upper 2 32-bit integers to 64-bit integers\n        high_vec = _mm_cvtepu32_epi64(high_vec);\n        \n        // Set high 32 bits to 1 for low vector\n        __m128i low_result = _mm_or_si128(low_vec, _mm_set1_epi64x(0xFFFFFFFF00000000ULL));\n        \n        // Set high 32 bits to 1 for high vector\n        __m128i high_result = _mm_or_si128(high_vec, _mm_set1_epi64x(0xFFFFFFFF00000000ULL));\n        \n        // Store results in destination\n        _mm_storeu_si128((__m128i*)&dst[i], low_result);\n        _mm_storeu_si128((__m128i*)&dst[i+2], high_result);\n    }\n    \n    // Handle remaining elements\n    for (size_t i = vector_length; i < length; i++) {\n        dst[i] = (uint64_t)src[i] | 0xFFFFFFFF00000000ULL;\n    }\n}\n```"}
{"task_id": "SimdBench_59_AVX", "completion": "```cpp\nvoid widening_uint_simd(const uint32_t* src, uint64_t* dst, size_t length) {\n    size_t vector_length = length - (length % 4);\n    \n    for (size_t i = 0; i < vector_length; i += 4) {\n        // Load 4 32-bit unsigned integers from source\n        __m128i src_vector = _mm_loadu_si128((__m128i*)&src[i]);\n        \n        // Convert lower 2 32-bit integers to 64-bit integers\n        __m128i low_64bits = _mm_cvtepu32_epi64(src_vector);\n        \n        // Convert upper 2 32-bit integers to 64-bit integers\n        __m128i high_64bits = _mm_cvtepu32_epi64(_mm_srli_si128(src_vector, 8));\n        \n        // Set high 32 bits to 1 for low 64-bit integers\n        __m128i low_result = _mm_or_si128(low_64bits, _mm_set1_epi64x(0xFFFFFFFF00000000ULL));\n        \n        // Set high 32 bits to 1 for high 64-bit integers\n        __m128i high_result = _mm_or_si128(high_64bits, _mm_set1_epi64x(0xFFFFFFFF00000000ULL));\n        \n        // Store results in destination\n        _mm_storeu_si128((__m128i*)&dst[i], low_result);\n        _mm_storeu_si128((__m128i*)&dst[i+2], high_result);\n    }\n    \n    // Handle remaining elements\n    for (size_t i = vector_length; i < length; i++) {\n        dst[i] = (uint64_t)src[i] | 0xFFFFFFFF00000000ULL;\n    }\n}\n```"}
{"task_id": "SimdBench_59_AVX", "completion": "```cpp\nvoid widening_uint_simd(const uint32_t* src, uint64_t* dst, size_t length) {\n    size_t vector_len = length - (length % 4);\n    \n    for (size_t i = 0; i < vector_len; i += 4) {\n        // Load 4 32-bit integers from source\n        __m128i src_vec = _mm_loadu_si128((__m128i*)&src[i]);\n        \n        // Convert lower 2 32-bit integers to 64-bit integers\n        __m128i low_vec = _mm_cvtepu32_epi64(src_vec);\n        \n        // Shift right to get the upper 2 32-bit integers\n        __m128i high_vec = _mm_srli_si128(src_vec, 8);\n        \n        // Convert upper 2 32-bit integers to 64-bit integers\n        high_vec = _mm_cvtepu32_epi64(high_vec);\n        \n        // Set high 32 bits to 1 for low vector\n        __m128i low_result = _mm_or_si128(low_vec, _mm_set1_epi64x(0xFFFFFFFF00000000ULL));\n        \n        // Set high 32 bits to 1 for high vector\n        __m128i high_result = _mm_or_si128(high_vec, _mm_set1_epi64x(0xFFFFFFFF00000000ULL));\n        \n        // Store results\n        _mm_storeu_si128((__m128i*)&dst[i], low_result);\n        _mm_storeu_si128((__m128i*)&dst[i+2], high_result);\n    }\n    \n    // Handle remaining elements\n    for (size_t i = vector_len; i < length; i++) {\n        dst[i] = (uint64_t)src[i] | 0xFFFFFFFF00000000ULL;\n    }\n}\n```"}
{"task_id": "SimdBench_59_AVX", "completion": "```cpp\nvoid widening_uint_simd(const uint32_t* src, uint64_t* dst, size_t length) {\n    size_t vector_len = length - (length % 4);\n    \n    for (size_t i = 0; i < vector_len; i += 4) {\n        // Load 4 32-bit integers from source\n        __m128i src_vec = _mm_loadu_si128((__m128i*)&src[i]);\n        \n        // Convert lower 2 32-bit integers to 64-bit integers\n        __m128i low_64 = _mm_cvtepu32_epi64(src_vec);\n        \n        // Convert upper 2 32-bit integers to 64-bit integers\n        __m128i high_64 = _mm_cvtepu32_epi64(_mm_srli_si128(src_vec, 8));\n        \n        // Set high 32 bits to 1 for low_64\n        __m256i result_low = _mm256_or_si256(\n            _mm256_cvtepu64_epi64(low_64), \n            _mm256_set1_epi64x(0xFFFFFFFF00000000ULL)\n        );\n        \n        // Set high 32 bits to 1 for high_64\n        __m256i result_high = _mm256_or_si256(\n            _mm256_cvtepu64_epi64(high_64), \n            _mm256_set1_epi64x(0xFFFFFFFF00000000ULL)\n        );\n        \n        // Store results\n        _mm256_storeu_si256((__m256i*)&dst[i], result_low);\n        _mm256_storeu_si256((__m256i*)&dst[i+2], result_high);\n    }\n    \n    // Handle remaining elements\n    for (size_t i = vector_len; i < length; i++) {\n        dst[i] = (uint64_t)src[i] | 0xFFFFFFFF00000000ULL;\n    }\n}\n```"}
{"task_id": "SimdBench_60_AVX", "completion": "```cpp\ndouble indexed_sum_simd(const double* vec, const int16_t* index, size_t length) {\n    __m256d sum_vec = _mm256_setzero_pd();\n    \n    size_t i = 0;\n    for (; i + 4 <= length; i += 4) {\n        // Load 4 indices\n        __m256i indices = _mm256_loadu_si256((__m256i*)&index[i]);\n        \n        // Convert int16_t indices to int32_t \n        __m256i indices_low = _mm256_cvtepi16_epi32(_mm_loadu_si128((__m128i*)&index[i]));\n        __m256i indices_high = _mm256_cvtepi16_epi32(_mm_loadu_si128((__m128i*)&index[i+4]));\n        \n        // Gather double values using indices\n        __m256d vals_low = _mm256_i32gather_pd(vec, indices_low, 8);\n        __m256d vals_high = _mm256_i32gather_pd(vec, indices_high, 8);\n        \n        // Add to sum vector\n        sum_vec = _mm256_add_pd(sum_vec, vals_low);\n        sum_vec = _mm256_add_pd(sum_vec, vals_high);\n    }\n    \n    // Handle remaining elements\n    double final_sum = 0.0;\n    for (; i < length; ++i) {\n        final_sum += vec[index[i]];\n    }\n    \n    // Horizontal sum of vector\n    __m128d sum_low = _mm256_extractf128_pd(sum_vec, 0);\n    __m128d sum_high = _mm256_extractf128_pd(sum_vec, 1);\n    sum_low = _mm_add_pd(sum_low, sum_high);\n    sum_low = _mm_hadd_pd(sum_low, sum_low);\n    \n    return _mm_cvtsd_f64(sum_low) + final_sum;\n}\n```"}
{"task_id": "SimdBench_60_AVX", "completion": "```cpp\ndouble indexed_sum_simd(const double* vec, const int16_t* index, size_t length) {\n    __m256d sum_vec = _mm256_setzero_pd();\n    \n    size_t i = 0;\n    for (; i + 4 <= length; i += 4) {\n        // Load 4 indices\n        __m256i indices = _mm256_loadu_si256((__m256i*)&index[i]);\n        \n        // Convert indices to 32-bit integers\n        __m256i indices_low = _mm256_cvtepi16_epi32(_mm_loadu_si128((__m128i*)&index[i]));\n        __m256i indices_high = _mm256_cvtepi16_epi32(_mm_loadu_si128((__m128i*)&index[i+4]));\n        \n        // Gather 4 double values using indices\n        __m256d vec_values_low = _mm256_i32gather_pd(vec, indices_low, 8);\n        __m256d vec_values_high = _mm256_i32gather_pd(vec, indices_high, 8);\n        \n        // Add to sum\n        sum_vec = _mm256_add_pd(sum_vec, vec_values_low);\n        sum_vec = _mm256_add_pd(sum_vec, vec_values_high);\n    }\n    \n    // Handle remaining elements\n    double sum = 0.0;\n    for (; i < length; ++i) {\n        sum += vec[index[i]];\n    }\n    \n    // Horizontal sum of vector\n    __m128d sum_low = _mm256_extractf128_pd(sum_vec, 0);\n    __m128d sum_high = _mm256_extractf128_pd(sum_vec, 1);\n    sum_low = _mm_add_pd(sum_low, sum_high);\n    sum_low = _mm_hadd_pd(sum_low, sum_low);\n    \n    return _mm_cvtsd_f64(sum_low) + sum;\n}\n```"}
{"task_id": "SimdBench_60_AVX", "completion": "```cpp\ndouble indexed_sum_simd(const double* vec, const int16_t* index, size_t length) {\n    __m256d sum_vec = _mm256_setzero_pd();\n    \n    size_t i = 0;\n    for (; i + 4 <= length; i += 4) {\n        // Load 4 indices\n        __m256i indices_vec = _mm256_loadu_si256((__m256i*)&index[i]);\n        \n        // Convert indices to 32-bit integers\n        __m256i indices_32 = _mm256_cvtepi16_epi32(_mm_loadu_si128((__m128i*)&index[i]));\n        \n        // Gather 4 double values using indices\n        __m256d gathered_vec = _mm256_i32gather_pd(vec, indices_32, 8);\n        \n        // Add gathered values to sum\n        sum_vec = _mm256_add_pd(sum_vec, gathered_vec);\n    }\n    \n    // Horizontal sum of vector\n    __m128d sum_low = _mm256_extractf128_pd(sum_vec, 0);\n    __m128d sum_high = _mm256_extractf128_pd(sum_vec, 1);\n    sum_low = _mm_add_pd(sum_low, sum_high);\n    sum_low = _mm_hadd_pd(sum_low, sum_low);\n    \n    double final_sum = _mm_cvtsd_f64(sum_low);\n    \n    // Handle remaining elements\n    for (; i < length; i++) {\n        final_sum += vec[index[i]];\n    }\n    \n    return final_sum;\n}\n```"}
{"task_id": "SimdBench_60_AVX", "completion": "```cpp\ndouble indexed_sum_simd(const double* vec, const int16_t* index, size_t length) {\n    __m256d sum_vec = _mm256_setzero_pd();\n    \n    size_t i = 0;\n    for (; i + 4 <= length; i += 4) {\n        // Load 4 indices\n        __m256i indices_vec = _mm256_loadu_si256((__m256i*)&index[i]);\n        \n        // Convert int16_t indices to int32_t\n        __m256i indices_low = _mm256_cvtepi16_epi32(_mm_loadu_si128((__m128i*)&index[i]));\n        __m256i indices_high = _mm256_cvtepi16_epi32(_mm_loadu_si128((__m128i*)&index[i+4]));\n        \n        // Gather 4 double values using indices\n        __m256d gathered_vec_low = _mm256_i32gather_pd(vec, indices_low, 8);\n        __m256d gathered_vec_high = _mm256_i32gather_pd(vec, indices_high, 8);\n        \n        // Add to sum\n        sum_vec = _mm256_add_pd(sum_vec, gathered_vec_low);\n        sum_vec = _mm256_add_pd(sum_vec, gathered_vec_high);\n    }\n    \n    // Handle remaining elements\n    double sum = 0.0;\n    for (; i < length; ++i) {\n        sum += vec[index[i]];\n    }\n    \n    // Horizontal sum of AVX vector\n    __m128d sum_low = _mm256_extractf128_pd(sum_vec, 0);\n    __m128d sum_high = _mm256_extractf128_pd(sum_vec, 1);\n    sum_low = _mm_add_pd(sum_low, sum_high);\n    sum_low = _mm_hadd_pd(sum_low, sum_low);\n    \n    return _mm_cvtsd_f64(sum_low) + sum;\n}\n```"}
{"task_id": "SimdBench_60_AVX", "completion": "```cpp\ndouble indexed_sum_simd(const double* vec, const int16_t* index, size_t length) {\n    __m256d sum_vec = _mm256_setzero_pd();\n    \n    size_t i = 0;\n    for (; i + 4 <= length; i += 4) {\n        // Load 4 indices\n        __m256i indices_vec = _mm256_loadu_si256((__m256i*)&index[i]);\n        \n        // Convert 16-bit indices to 32-bit indices\n        __m256i indices_lo = _mm256_unpacklo_epi16(indices_vec, _mm256_setzero_si256());\n        __m256i indices_hi = _mm256_unpackhi_epi16(indices_vec, _mm256_setzero_si256());\n        \n        // Convert 32-bit indices to 64-bit indices\n        __m128i indices_lo_lo = _mm256_extracti128_si256(indices_lo, 0);\n        __m128i indices_lo_hi = _mm256_extracti128_si256(indices_lo, 1);\n        __m128i indices_hi_lo = _mm256_extracti128_si256(indices_hi, 0);\n        __m128i indices_hi_hi = _mm256_extracti128_si256(indices_hi, 1);\n        \n        // Gather 4 double values using indices\n        __m256d values_vec = _mm256_i32gather_pd(vec, indices_lo_lo, 8);\n        values_vec = _mm256_add_pd(values_vec, _mm256_i32gather_pd(vec, indices_lo_hi, 8));\n        values_vec = _mm256_add_pd(values_vec, _mm256_i32gather_pd(vec, indices_hi_lo, 8));\n        values_vec = _mm256_add_pd(values_vec, _mm256_i32gather_pd(vec, indices_hi_hi, 8));\n        \n        // Accumulate sum\n        sum_vec = _mm256_add_pd(sum_vec, values_vec);\n    }\n    \n    // Handle remaining elements\n    double sum = _mm256_reduce_add_pd(sum_vec);\n    for (; i < length; ++i) {\n        sum += vec[index[i]];\n    }\n    \n    return sum;\n}\n```"}
{"task_id": "SimdBench_61_AVX", "completion": "```cpp\nvoid simple_conv2d_simd(const double* input, const double* kernel, double* output, size_t input_size, size_t kernel_size) {\n    size_t output_size = input_size - kernel_size + 1;\n    \n    for (size_t i = 0; i < output_size; i++) {\n        for (size_t j = 0; j < output_size; j++) {\n            __m256d sum_vec = _mm256_setzero_pd();\n            \n            for (size_t ki = 0; ki < kernel_size; ki++) {\n                for (size_t kj = 0; kj < kernel_size; kj++) {\n                    size_t input_idx = (i + ki) * input_size + (j + kj);\n                    size_t kernel_idx = ki * kernel_size + kj;\n                    \n                    // Process 4 doubles at a time\n                    __m256d input_vec = _mm256_loadu_pd(&input[input_idx]);\n                    __m256d kernel_vec = _mm256_set1_pd(kernel[kernel_idx]);\n                    \n                    sum_vec = _mm256_add_pd(sum_vec, _mm256_mul_pd(input_vec, kernel_vec));\n                }\n            }\n            \n            // Horizontal sum of vector\n            __m128d sum_low = _mm256_extractf128_pd(sum_vec, 0);\n            __m128d sum_high = _mm256_extractf128_pd(sum_vec, 1);\n            sum_low = _mm_add_pd(sum_low, sum_high);\n            sum_low = _mm_hadd_pd(sum_low, sum_low);\n            \n            double conv_result = _mm_cvtsd_f64(sum_low);\n            \n            // ReLU activation\n            output[i * output_size + j] = conv_result > 0 ? conv_result : 0;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_61_AVX", "completion": "```cpp\nvoid simple_conv2d_simd(const double* input, const double* kernel, double* output, size_t input_size, size_t kernel_size) {\n    size_t output_size = input_size - kernel_size + 1;\n    \n    for (size_t i = 0; i < output_size; i++) {\n        for (size_t j = 0; j < output_size; j++) {\n            __m256d sum_vec = _mm256_setzero_pd();\n            \n            for (size_t ki = 0; ki < kernel_size; ki++) {\n                for (size_t kj = 0; kj < kernel_size; kj++) {\n                    size_t input_idx = (i + ki) * input_size + (j + kj);\n                    size_t kernel_idx = ki * kernel_size + kj;\n                    \n                    // Process 4 doubles at a time using AVX\n                    for (size_t vec_idx = 0; vec_idx + 3 < input_size; vec_idx += 4) {\n                        __m256d input_vec = _mm256_loadu_pd(&input[input_idx + vec_idx]);\n                        __m256d kernel_vec = _mm256_set1_pd(kernel[kernel_idx]);\n                        \n                        sum_vec = _mm256_add_pd(sum_vec, _mm256_mul_pd(input_vec, kernel_vec));\n                    }\n                }\n            }\n            \n            // Horizontal sum of vector elements\n            __m128d sum_low = _mm256_extractf128_pd(sum_vec, 0);\n            __m128d sum_high = _mm256_extractf128_pd(sum_vec, 1);\n            sum_low = _mm_add_pd(sum_low, sum_high);\n            sum_low = _mm_hadd_pd(sum_low, sum_low);\n            \n            double conv_result = _mm_cvtsd_f64(sum_low);\n            \n            // ReLU activation\n            output[i * output_size + j] = conv_result > 0 ? conv_result : 0.0;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_61_AVX", "completion": "```cpp\nvoid simple_conv2d_simd(const double* input, const double* kernel, double* output, size_t input_size, size_t kernel_size) {\n    size_t output_size = input_size - kernel_size + 1;\n\n    for (size_t i = 0; i < output_size; i++) {\n        for (size_t j = 0; j < output_size; j++) {\n            __m256d sum_vec = _mm256_setzero_pd();\n\n            for (size_t ki = 0; ki < kernel_size; ki++) {\n                for (size_t kj = 0; kj < kernel_size; kj++) {\n                    size_t input_idx = (i + ki) * input_size + (j + kj);\n                    size_t kernel_idx = ki * kernel_size + kj;\n\n                    __m256d input_vec = _mm256_set1_pd(input[input_idx]);\n                    __m256d kernel_vec = _mm256_set1_pd(kernel[kernel_idx]);\n                    sum_vec = _mm256_add_pd(sum_vec, _mm256_mul_pd(input_vec, kernel_vec));\n                }\n            }\n\n            double sum = _mm256_reduce_add_pd(sum_vec);\n            output[i * output_size + j] = sum > 0 ? sum : 0; // ReLU activation\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_61_AVX", "completion": "```cpp\nvoid simple_conv2d_simd(const double* input, const double* kernel, double* output, size_t input_size, size_t kernel_size) {\n    size_t output_size = input_size - kernel_size + 1;\n    \n    for (size_t i = 0; i < output_size; i++) {\n        for (size_t j = 0; j < output_size; j++) {\n            __m256d sum_vec = _mm256_setzero_pd();\n            \n            for (size_t ki = 0; ki < kernel_size; ki++) {\n                for (size_t kj = 0; kj < kernel_size; kj++) {\n                    size_t input_idx = (i + ki) * input_size + (j + kj);\n                    size_t kernel_idx = ki * kernel_size + kj;\n                    \n                    // Process 4 doubles at a time using AVX\n                    for (size_t vec_idx = 0; vec_idx + 3 < input_size; vec_idx += 4) {\n                        __m256d input_vec = _mm256_loadu_pd(&input[input_idx + vec_idx]);\n                        __m256d kernel_vec = _mm256_set1_pd(kernel[kernel_idx]);\n                        \n                        sum_vec = _mm256_add_pd(sum_vec, _mm256_mul_pd(input_vec, kernel_vec));\n                    }\n                }\n            }\n            \n            // Horizontal sum of vector\n            __m128d sum_low = _mm256_extractf128_pd(sum_vec, 0);\n            __m128d sum_high = _mm256_extractf128_pd(sum_vec, 1);\n            sum_low = _mm_add_pd(sum_low, sum_high);\n            sum_low = _mm_hadd_pd(sum_low, sum_low);\n            \n            double conv_result = _mm_cvtsd_f64(sum_low);\n            \n            // ReLU activation\n            output[i * output_size + j] = conv_result > 0 ? conv_result : 0.0;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_61_AVX", "completion": "```cpp\nvoid simple_conv2d_simd(const double* input, const double* kernel, double* output, size_t input_size, size_t kernel_size) {\n    size_t output_size = input_size - kernel_size + 1;\n    \n    for (size_t i = 0; i < output_size; i++) {\n        for (size_t j = 0; j < output_size; j++) {\n            __m256d sum_vec = _mm256_setzero_pd();\n            \n            for (size_t ki = 0; ki < kernel_size; ki++) {\n                for (size_t kj = 0; kj < kernel_size; kj++) {\n                    // Load 4 doubles at a time using AVX\n                    __m256d input_vec = _mm256_loadu_pd(input + (i + ki) * input_size + j + kj);\n                    __m256d kernel_vec = _mm256_set1_pd(kernel[ki * kernel_size + kj]);\n                    \n                    // Multiply and accumulate\n                    sum_vec = _mm256_add_pd(sum_vec, _mm256_mul_pd(input_vec, kernel_vec));\n                }\n            }\n            \n            // Horizontal sum of vector\n            __m128d sum_low = _mm256_extractf128_pd(sum_vec, 0);\n            __m128d sum_high = _mm256_extractf128_pd(sum_vec, 1);\n            sum_low = _mm_add_pd(sum_low, sum_high);\n            sum_low = _mm_hadd_pd(sum_low, sum_low);\n            \n            // Apply ReLU\n            double conv_result = _mm_cvtsd_f64(sum_low);\n            output[i * output_size + j] = conv_result > 0 ? conv_result : 0;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_62_AVX", "completion": "```cpp\nbool has_close_elements_simd(const std::vector<double> & numbers, double threshold) {\n    int n = numbers.size();\n    \n    // Process 4 doubles at a time using AVX\n    for (int i = 0; i < n; i += 4) {\n        __m256d current = _mm256_loadu_pd(&numbers[i]);\n        \n        for (int j = i + 4; j < n; j += 4) {\n            __m256d compare = _mm256_loadu_pd(&numbers[j]);\n            \n            // Compute absolute difference\n            __m256d diff = _mm256_sub_pd(current, compare);\n            diff = _mm256_andnot_pd(_mm256_set1_pd(-0.0), diff); // abs()\n            \n            // Check if any difference is less than threshold\n            __m256d threshold_vec = _mm256_set1_pd(threshold);\n            __m256d mask = _mm256_cmp_pd(diff, threshold_vec, _CMP_LT_OQ);\n            \n            if (_mm256_movemask_pd(mask) != 0) {\n                return true;\n            }\n        }\n        \n        // Handle remaining elements in last incomplete vector\n        for (int j = i + 4; j < n; j++) {\n            for (int k = 0; k < 4 && i + k < n; k++) {\n                if (std::abs(numbers[i + k] - numbers[j]) < threshold) {\n                    return true;\n                }\n            }\n        }\n    }\n    \n    return false;\n}\n```"}
{"task_id": "SimdBench_62_AVX", "completion": "```cpp\nbool has_close_elements_simd(const std::vector<double> & numbers, double threshold) {\n    int n = numbers.size();\n    \n    // Process 4 doubles at a time with AVX\n    for (int i = 0; i < n; i += 4) {\n        __m256d current = _mm256_loadu_pd(&numbers[i]);\n        \n        for (int j = i + 4; j < n; j += 4) {\n            __m256d compare = _mm256_loadu_pd(&numbers[j]);\n            \n            // Compute absolute differences\n            __m256d diff = _mm256_sub_pd(current, compare);\n            __m256d abs_diff = _mm256_andnot_pd(_mm256_set1_pd(-0.0), diff);\n            \n            // Check if any difference is less than threshold\n            __m256d threshold_vec = _mm256_set1_pd(threshold);\n            __m256d mask = _mm256_cmp_pd(abs_diff, threshold_vec, _CMP_LT_OQ);\n            \n            if (_mm256_movemask_pd(mask) != 0) {\n                return true;\n            }\n        }\n        \n        // Handle remaining elements in last incomplete vector\n        for (int j = i + 4; j < n; j++) {\n            if (std::abs(numbers[i] - numbers[j]) < threshold) {\n                return true;\n            }\n        }\n    }\n    \n    return false;\n}\n```"}
{"task_id": "SimdBench_62_AVX", "completion": "```cpp\nbool has_close_elements_simd(const std::vector<double> & numbers, double threshold) {\n    int n = numbers.size();\n    \n    // Process 4 doubles at a time with AVX\n    for (int i = 0; i < n; i += 4) {\n        __m256d current = _mm256_loadu_pd(&numbers[i]);\n        \n        for (int j = i + 4; j < n; j += 4) {\n            __m256d compare = _mm256_loadu_pd(&numbers[j]);\n            \n            // Compute absolute differences\n            __m256d diff = _mm256_sub_pd(current, compare);\n            __m256d abs_diff = _mm256_andnot_pd(_mm256_set1_pd(-0.0), diff);\n            \n            // Compare if any difference is less than threshold\n            __m256d threshold_vec = _mm256_set1_pd(threshold);\n            __m256d mask = _mm256_cmp_pd(abs_diff, threshold_vec, _CMP_LT_OS);\n            \n            if (_mm256_movemask_pd(mask) != 0) {\n                return true;\n            }\n        }\n        \n        // Handle remaining elements in last iteration\n        for (int j = (n / 4) * 4; j < n; j++) {\n            for (int k = 0; k < 4; k++) {\n                if (i + k < n && j < n && std::abs(numbers[i + k] - numbers[j]) < threshold) {\n                    return true;\n                }\n            }\n        }\n    }\n    \n    return false;\n}\n```"}
{"task_id": "SimdBench_62_AVX", "completion": "```cpp\nbool has_close_elements_simd(const std::vector<double> & numbers, double threshold) {\n    int n = numbers.size();\n    \n    // Process 4 doubles at a time with AVX\n    for (int i = 0; i < n; i += 4) {\n        __m256d current = _mm256_loadu_pd(&numbers[i]);\n        \n        for (int j = i + 4; j < n; j += 4) {\n            __m256d compare = _mm256_loadu_pd(&numbers[j]);\n            \n            // Compute absolute differences\n            __m256d diff = _mm256_sub_pd(current, compare);\n            __m256d abs_diff = _mm256_andnot_pd(_mm256_set1_pd(-0.0), diff);\n            \n            // Compare differences against threshold\n            __m256d threshold_vec = _mm256_set1_pd(threshold);\n            __m256d mask = _mm256_cmp_pd(abs_diff, threshold_vec, _CMP_LT_OQ);\n            \n            if (_mm256_movemask_pd(mask) != 0) {\n                return true;\n            }\n        }\n        \n        // Handle remaining elements in last iteration\n        for (int j = (n / 4) * 4; j < n; j++) {\n            for (int k = 0; k < 4; k++) {\n                if (i + k < n && j < n && std::abs(numbers[i + k] - numbers[j]) < threshold) {\n                    return true;\n                }\n            }\n        }\n    }\n    \n    return false;\n}\n```"}
{"task_id": "SimdBench_62_AVX", "completion": "```cpp\nbool has_close_elements_simd(const std::vector<double> & numbers, double threshold) {\n    int n = numbers.size();\n    \n    // Process 4 doubles at a time with AVX\n    for (int i = 0; i < n; i += 4) {\n        __m256d current = _mm256_loadu_pd(&numbers[i]);\n        \n        // Compare with remaining elements\n        for (int j = i + 4; j < n; j += 4) {\n            __m256d compare = _mm256_loadu_pd(&numbers[j]);\n            \n            // Compute absolute difference\n            __m256d diff = _mm256_sub_pd(current, compare);\n            diff = _mm256_andnot_pd(_mm256_set1_pd(-0.0), diff); // abs()\n            \n            // Check if any difference is less than threshold\n            __m256d threshold_vec = _mm256_set1_pd(threshold);\n            __m256d mask = _mm256_cmp_pd(diff, threshold_vec, _CMP_LT_OS);\n            \n            if (_mm256_movemask_pd(mask) != 0) {\n                return true;\n            }\n        }\n        \n        // Handle remaining elements\n        for (int j = i + 4; j < n; j++) {\n            if (std::abs(numbers[i] - numbers[j]) < threshold) {\n                return true;\n            }\n        }\n    }\n    \n    return false;\n}\n```"}
{"task_id": "SimdBench_63_AVX", "completion": "```cpp\nbool below_zero_simd(std::vector<int> operations) {\n    int n = operations.size();\n    int balance = 0;\n\n    // Process 8 integers at a time using AVX2\n    int vector_size = 8;\n    for (int i = 0; i <= n - vector_size; i += vector_size) {\n        __m256i current_ops = _mm256_loadu_si256((__m256i*)&operations[i]);\n        balance += _mm256_extract_epi32(current_ops, 0);\n        balance += _mm256_extract_epi32(current_ops, 1);\n        balance += _mm256_extract_epi32(current_ops, 2);\n        balance += _mm256_extract_epi32(current_ops, 3);\n        balance += _mm256_extract_epi32(current_ops, 4);\n        balance += _mm256_extract_epi32(current_ops, 5);\n        balance += _mm256_extract_epi32(current_ops, 6);\n        balance += _mm256_extract_epi32(current_ops, 7);\n\n        if (balance < 0) {\n            return true;\n        }\n    }\n\n    // Process remaining elements\n    for (int i = (n / vector_size) * vector_size; i < n; i++) {\n        balance += operations[i];\n        if (balance < 0) {\n            return true;\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_63_AVX", "completion": "```cpp\nbool below_zero_simd(std::vector<int> operations) {\n    int n = operations.size();\n    int balance = 0;\n    \n    // Process 8 integers at a time using AVX2\n    int vector_size = 8;\n    int processed_length = (n / vector_size) * vector_size;\n    \n    __m256i running_balance = _mm256_setzero_si256();\n    __m256i zero_vector = _mm256_setzero_si256();\n    \n    for (int i = 0; i < processed_length; i += vector_size) {\n        __m256i current_ops = _mm256_loadu_si256((__m256i*)&operations[i]);\n        running_balance = _mm256_add_epi32(running_balance, current_ops);\n        \n        // Check if any element is negative\n        __m256i negative_mask = _mm256_cmpgt_epi32(zero_vector, running_balance);\n        if (!_mm256_testz_si256(negative_mask, negative_mask)) {\n            return true;\n        }\n    }\n    \n    // Process remaining elements\n    for (int i = processed_length; i < n; i++) {\n        balance += operations[i];\n        if (balance < 0) {\n            return true;\n        }\n    }\n    \n    return false;\n}\n```"}
{"task_id": "SimdBench_63_AVX", "completion": "```cpp\nbool below_zero_simd(std::vector<int> operations) {\n    int n = operations.size();\n    int balance = 0;\n    \n    // Process 8 integers at a time using AVX2\n    int vector_size = 8;\n    int processed_length = (n / vector_size) * vector_size;\n    \n    __m256i running_balance = _mm256_setzero_si256();\n    __m256i zero_vector = _mm256_setzero_si256();\n    \n    // Process 8 integers in parallel\n    for (int i = 0; i < processed_length; i += vector_size) {\n        __m256i current_ops = _mm256_loadu_si256((__m256i*)&operations[i]);\n        running_balance = _mm256_add_epi32(running_balance, current_ops);\n        \n        // Check if any lane becomes negative\n        __m256i negative_mask = _mm256_cmpgt_epi32(zero_vector, running_balance);\n        if (!_mm256_testz_si256(negative_mask, negative_mask)) {\n            return true;\n        }\n    }\n    \n    // Process remaining elements sequentially\n    for (int i = processed_length; i < n; i++) {\n        balance += operations[i];\n        if (balance < 0) {\n            return true;\n        }\n    }\n    \n    return false;\n}\n```"}
{"task_id": "SimdBench_63_AVX", "completion": "```cpp\nbool below_zero_simd(std::vector<int> operations) {\n    int n = operations.size();\n    int balance = 0;\n\n    // Process 8 integers at a time using AVX2\n    int vector_size = 8;\n    for (int i = 0; i <= n - vector_size; i += vector_size) {\n        __m256i current_ops = _mm256_loadu_si256((__m256i*)&operations[i]);\n        balance += _mm256_extract_epi32(current_ops, 0);\n        balance += _mm256_extract_epi32(current_ops, 1);\n        balance += _mm256_extract_epi32(current_ops, 2);\n        balance += _mm256_extract_epi32(current_ops, 3);\n        balance += _mm256_extract_epi32(current_ops, 4);\n        balance += _mm256_extract_epi32(current_ops, 5);\n        balance += _mm256_extract_epi32(current_ops, 6);\n        balance += _mm256_extract_epi32(current_ops, 7);\n\n        if (balance < 0) {\n            return true;\n        }\n    }\n\n    // Process remaining elements\n    for (int i = (n / vector_size) * vector_size; i < n; ++i) {\n        balance += operations[i];\n        if (balance < 0) {\n            return true;\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_63_AVX", "completion": "```cpp\nbool below_zero_simd(std::vector<int> operations) {\n    int n = operations.size();\n    int balance = 0;\n    \n    // Process 8 integers at a time using AVX2\n    int vector_size = 8;\n    int processed_length = (n / vector_size) * vector_size;\n    \n    __m256i running_balance = _mm256_setzero_si256();\n    __m256i zero_vector = _mm256_setzero_si256();\n    \n    for (int i = 0; i < processed_length; i += vector_size) {\n        __m256i current_ops = _mm256_loadu_si256((__m256i*)&operations[i]);\n        running_balance = _mm256_add_epi32(running_balance, current_ops);\n        \n        // Check if any balance becomes negative\n        __m256i negative_mask = _mm256_cmpgt_epi32(zero_vector, running_balance);\n        if (!_mm256_testz_si256(negative_mask, negative_mask)) {\n            return true;\n        }\n    }\n    \n    // Process remaining elements sequentially\n    for (int i = processed_length; i < n; i++) {\n        balance += operations[i];\n        if (balance < 0) {\n            return true;\n        }\n    }\n    \n    return false;\n}\n```"}
{"task_id": "SimdBench_64_AVX", "completion": "```cpp\ndouble mean_absolute_deviation_simd(std::vector<double> numbers) {\n    int n = numbers.size();\n    if (n == 0) return 0.0;\n\n    // Calculate mean using SIMD\n    __m256d sum_vec = _mm256_setzero_pd();\n    for (int i = 0; i < n; i += 4) {\n        __m256d data_vec = _mm256_loadu_pd(&numbers[i]);\n        sum_vec = _mm256_add_pd(sum_vec, data_vec);\n    }\n    \n    // Horizontal sum for mean\n    __m128d sum_low = _mm256_extractf128_pd(sum_vec, 0);\n    __m128d sum_high = _mm256_extractf128_pd(sum_vec, 1);\n    sum_low = _mm_add_pd(sum_low, sum_high);\n    double mean = _mm_cvtsd_f64(_mm_hadd_pd(sum_low, sum_low)) / n;\n\n    // Calculate absolute deviations using SIMD\n    __m256d mean_vec = _mm256_set1_pd(mean);\n    __m256d abs_dev_sum = _mm256_setzero_pd();\n\n    for (int i = 0; i < n; i += 4) {\n        __m256d data_vec = _mm256_loadu_pd(&numbers[i]);\n        __m256d diff_vec = _mm256_sub_pd(data_vec, mean_vec);\n        __m256d abs_diff_vec = _mm256_andnot_pd(_mm256_set1_pd(-0.0), diff_vec);\n        abs_dev_sum = _mm256_add_pd(abs_dev_sum, abs_diff_vec);\n    }\n\n    // Horizontal sum for MAD\n    sum_low = _mm256_extractf128_pd(abs_dev_sum, 0);\n    sum_high = _mm256_extractf128_pd(abs_dev_sum, 1);\n    sum_low = _mm_add_pd(sum_low, sum_high);\n    double mad = _mm_cvtsd_f64(_mm_hadd_pd(sum_low, sum_low)) / n;\n\n    return mad;\n}\n```"}
{"task_id": "SimdBench_64_AVX", "completion": "```cpp\ndouble mean_absolute_deviation_simd(std::vector<double> numbers) {\n    int n = numbers.size();\n    if (n == 0) return 0.0;\n\n    // Calculate mean using SIMD\n    __m256d sum_vec = _mm256_setzero_pd();\n    for (int i = 0; i < n; i += 4) {\n        __m256d data_vec = _mm256_loadu_pd(&numbers[i]);\n        sum_vec = _mm256_add_pd(sum_vec, data_vec);\n    }\n    \n    // Horizontal sum for mean\n    __m128d sum_low = _mm256_extractf128_pd(sum_vec, 0);\n    __m128d sum_high = _mm256_extractf128_pd(sum_vec, 1);\n    sum_low = _mm_add_pd(sum_low, sum_high);\n    double mean = _mm_cvtsd_f64(_mm_hadd_pd(sum_low, sum_low)) / n;\n\n    // Calculate absolute deviations using SIMD\n    __m256d mean_vec = _mm256_set1_pd(mean);\n    __m256d abs_dev_sum = _mm256_setzero_pd();\n\n    for (int i = 0; i < n; i += 4) {\n        __m256d data_vec = _mm256_loadu_pd(&numbers[i]);\n        __m256d diff_vec = _mm256_sub_pd(data_vec, mean_vec);\n        __m256d abs_diff_vec = _mm256_andnot_pd(_mm256_set1_pd(-0.0), diff_vec);\n        abs_dev_sum = _mm256_add_pd(abs_dev_sum, abs_diff_vec);\n    }\n\n    // Horizontal sum for MAD\n    sum_low = _mm256_extractf128_pd(abs_dev_sum, 0);\n    sum_high = _mm256_extractf128_pd(abs_dev_sum, 1);\n    sum_low = _mm_add_pd(sum_low, sum_high);\n    double mad = _mm_cvtsd_f64(_mm_hadd_pd(sum_low, sum_low)) / n;\n\n    return mad;\n}\n```"}
{"task_id": "SimdBench_64_AVX", "completion": "```cpp\ndouble mean_absolute_deviation_simd(std::vector<double> numbers) {\n    int n = numbers.size();\n    if (n == 0) return 0.0;\n\n    // Calculate mean\n    __m256d sum_vec = _mm256_setzero_pd();\n    for (int i = 0; i < n; i += 4) {\n        __m256d data_vec = _mm256_loadu_pd(&numbers[i]);\n        sum_vec = _mm256_add_pd(sum_vec, data_vec);\n    }\n    \n    // Horizontal sum for mean\n    __m128d sum_low = _mm256_extractf128_pd(sum_vec, 0);\n    __m128d sum_high = _mm256_extractf128_pd(sum_vec, 1);\n    sum_low = _mm_add_pd(sum_low, sum_high);\n    double mean = (_mm_cvtsd_f64(sum_low) + _mm_cvtsd_f64(_mm_shuffle_pd(sum_low, sum_low, 1))) / n;\n\n    // Calculate absolute deviations\n    __m256d mean_vec = _mm256_set1_pd(mean);\n    __m256d abs_dev_sum = _mm256_setzero_pd();\n\n    for (int i = 0; i < n; i += 4) {\n        __m256d data_vec = _mm256_loadu_pd(&numbers[i]);\n        __m256d diff_vec = _mm256_sub_pd(data_vec, mean_vec);\n        __m256d abs_diff_vec = _mm256_andnot_pd(_mm256_set1_pd(-0.0), diff_vec);\n        abs_dev_sum = _mm256_add_pd(abs_dev_sum, abs_diff_vec);\n    }\n\n    // Horizontal sum for MAD\n    sum_low = _mm256_extractf128_pd(abs_dev_sum, 0);\n    sum_high = _mm256_extractf128_pd(abs_dev_sum, 1);\n    sum_low = _mm_add_pd(sum_low, sum_high);\n    double mad = (_mm_cvtsd_f64(sum_low) + _mm_cvtsd_f64(_mm_shuffle_pd(sum_low, sum_low, 1))) / n;\n\n    return mad;\n}\n```"}
{"task_id": "SimdBench_64_AVX", "completion": "```cpp\ndouble mean_absolute_deviation_simd(std::vector<double> numbers) {\n    int n = numbers.size();\n    if (n == 0) return 0.0;\n\n    // Calculate mean\n    __m256d sum_vec = _mm256_setzero_pd();\n    for (int i = 0; i < n; i += 4) {\n        __m256d data_vec = _mm256_loadu_pd(&numbers[i]);\n        sum_vec = _mm256_add_pd(sum_vec, data_vec);\n    }\n    \n    // Horizontal sum for mean\n    __m128d sum_low = _mm256_extractf128_pd(sum_vec, 0);\n    __m128d sum_high = _mm256_extractf128_pd(sum_vec, 1);\n    sum_low = _mm_add_pd(sum_low, sum_high);\n    double mean = _mm_cvtsd_f64(_mm_hadd_pd(sum_low, sum_low)) / n;\n\n    // Calculate absolute deviations\n    __m256d mean_vec = _mm256_set1_pd(mean);\n    __m256d mad_sum_vec = _mm256_setzero_pd();\n\n    for (int i = 0; i < n; i += 4) {\n        __m256d data_vec = _mm256_loadu_pd(&numbers[i]);\n        __m256d diff_vec = _mm256_sub_pd(data_vec, mean_vec);\n        __m256d abs_diff_vec = _mm256_andnot_pd(_mm256_set1_pd(-0.0), diff_vec);\n        mad_sum_vec = _mm256_add_pd(mad_sum_vec, abs_diff_vec);\n    }\n\n    // Horizontal sum for MAD\n    sum_low = _mm256_extractf128_pd(mad_sum_vec, 0);\n    sum_high = _mm256_extractf128_pd(mad_sum_vec, 1);\n    sum_low = _mm_add_pd(sum_low, sum_high);\n    double mad = _mm_cvtsd_f64(_mm_hadd_pd(sum_low, sum_low)) / n;\n\n    return mad;\n}\n```"}
{"task_id": "SimdBench_64_AVX", "completion": "```cpp\ndouble mean_absolute_deviation_simd(std::vector<double> numbers) {\n    int n = numbers.size();\n    if (n == 0) return 0.0;\n\n    // Calculate mean\n    __m256d sum_vec = _mm256_setzero_pd();\n    for (int i = 0; i < n; i += 4) {\n        __m256d data_vec = _mm256_loadu_pd(&numbers[i]);\n        sum_vec = _mm256_add_pd(sum_vec, data_vec);\n    }\n    \n    // Horizontal sum for mean\n    __m128d sum_low = _mm256_extractf128_pd(sum_vec, 0);\n    __m128d sum_high = _mm256_extractf128_pd(sum_vec, 1);\n    sum_low = _mm_add_pd(sum_low, sum_high);\n    double mean = _mm_cvtsd_f64(_mm_hadd_pd(sum_low, sum_low)) / n;\n\n    // Calculate absolute deviations\n    __m256d mean_vec = _mm256_set1_pd(mean);\n    __m256d abs_dev_sum = _mm256_setzero_pd();\n\n    for (int i = 0; i < n; i += 4) {\n        __m256d data_vec = _mm256_loadu_pd(&numbers[i]);\n        __m256d diff_vec = _mm256_sub_pd(data_vec, mean_vec);\n        __m256d abs_diff_vec = _mm256_andnot_pd(_mm256_set1_pd(-0.0), diff_vec);\n        abs_dev_sum = _mm256_add_pd(abs_dev_sum, abs_diff_vec);\n    }\n\n    // Horizontal sum for MAD\n    sum_low = _mm256_extractf128_pd(abs_dev_sum, 0);\n    sum_high = _mm256_extractf128_pd(abs_dev_sum, 1);\n    sum_low = _mm_add_pd(sum_low, sum_high);\n    double mad = _mm_cvtsd_f64(_mm_hadd_pd(sum_low, sum_low)) / n;\n\n    return mad;\n}\n```"}
{"task_id": "SimdBench_65_AVX", "completion": "```cpp\nstd::vector<int> intersperse_simd(std::vector<int> numbers, int delimeter) {\n    if (numbers.empty()) return numbers;\n\n    std::vector<int> result;\n    result.reserve(numbers.size() * 2 - 1);\n\n    int i = 0;\n    const int simd_width = 8; // AVX can process 8 integers at once\n\n    // Process in SIMD chunks\n    for (; i + simd_width <= numbers.size(); i += simd_width) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&numbers[i]);\n        \n        // Interleave with delimiter\n        for (int j = 0; j < simd_width; j++) {\n            result.push_back(_mm256_extract_epi32(vec, j));\n            if (j < simd_width - 1) {\n                result.push_back(delimeter);\n            }\n        }\n    }\n\n    // Handle remaining elements\n    for (; i < numbers.size(); i++) {\n        result.push_back(numbers[i]);\n        if (i < numbers.size() - 1) {\n            result.push_back(delimeter);\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_65_AVX", "completion": "```cpp\nstd::vector<int> intersperse_simd(std::vector<int> numbers, int delimeter) {\n    if (numbers.empty()) return numbers;\n\n    std::vector<int> result;\n    result.reserve(numbers.size() * 2 - 1);\n\n    int i = 0;\n    const int vector_width = 8; // AVX can process 8 integers at a time\n    \n    // Process vectors in chunks of 8\n    for (; i + vector_width <= numbers.size(); i += vector_width) {\n        __m256i input_vec = _mm256_loadu_si256((__m256i*)&numbers[i]);\n        \n        // Create delimiter vector\n        __m256i delimiter_vec = _mm256_set1_epi32(delimeter);\n        \n        // Interleave input and delimiter\n        __m256i shuffled_vec = _mm256_set_epi32(\n            numbers[i+7], delimeter,\n            numbers[i+6], delimeter,\n            numbers[i+5], delimeter,\n            numbers[i+4], delimeter,\n            numbers[i+3], delimeter,\n            numbers[i+2], delimeter,\n            numbers[i+1], delimeter,\n            numbers[i+0], delimeter\n        );\n        \n        // Store results\n        int temp[8];\n        _mm256_storeu_si256((__m256i*)temp, shuffled_vec);\n        \n        for (int j = 0; j < 16; j += 2) {\n            result.push_back(temp[j]);\n            if (j + 1 < 16) result.push_back(delimeter);\n        }\n    }\n    \n    // Handle remaining elements\n    for (; i < numbers.size(); ++i) {\n        result.push_back(numbers[i]);\n        if (i < numbers.size() - 1) result.push_back(delimeter);\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_65_AVX", "completion": "```cpp\nstd::vector<int> intersperse_simd(std::vector<int> numbers, int delimeter) {\n    int n = numbers.size();\n    if (n <= 1) return numbers;\n\n    std::vector<int> result(2 * n - 1);\n    int* input = numbers.data();\n    int* output = result.data();\n\n    int vec_size = n - (n % 8);\n    \n    for (int i = 0; i < vec_size; i += 8) {\n        __m256i vec_input = _mm256_loadu_si256((__m256i*)(input + i));\n        \n        __m256i vec_delim = _mm256_set1_epi32(delimeter);\n        \n        __m256i shuffle_mask = _mm256_setr_epi32(0, 8, 1, 8, 2, 8, 3, 8);\n        __m256i shuffled = _mm256_shuffle_epi32(vec_input, _MM_SHUFFLE(3, 1, 2, 0));\n        \n        _mm256_storeu_si256((__m256i*)(output + 2*i), shuffled);\n        _mm256_storeu_si256((__m256i*)(output + 2*i + 8), vec_delim);\n    }\n\n    for (int i = vec_size; i < n; i++) {\n        result[2*i] = input[i];\n        if (i < n-1) result[2*i+1] = delimeter;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_65_AVX", "completion": "```cpp\nstd::vector<int> intersperse_simd(std::vector<int> numbers, int delimeter) {\n    int n = numbers.size();\n    if (n <= 1) return numbers;\n\n    std::vector<int> result(2 * n - 1);\n    int* input = numbers.data();\n    int* output = result.data();\n\n    int vectorSize = n - (n % 8);\n    \n    for (int i = 0; i < vectorSize; i += 8) {\n        __m256i inputVec = _mm256_loadu_si256((__m256i*)(input + i));\n        \n        __m256i shuffleMask = _mm256_setr_epi32(0, 8, 1, 8, 2, 8, 3, 8);\n        __m256i delimeterVec = _mm256_set1_epi32(delimeter);\n        \n        __m256i interleavedVec = _mm256_shuffle_epi32(inputVec, _MM_SHUFFLE(3, 1, 2, 0));\n        __m256i resultVec = _mm256_inserti128_si256(interleavedVec, _mm256_extracti128_si256(interleavedVec, 1), 1);\n        \n        _mm256_storeu_si256((__m256i*)(output + 2 * i), resultVec);\n        _mm256_storeu_si256((__m256i*)(output + 2 * i + 1), delimeterVec);\n    }\n\n    for (int i = vectorSize; i < n; ++i) {\n        output[2 * (i - vectorSize)] = input[i];\n        if (i < n - 1) {\n            output[2 * (i - vectorSize) + 1] = delimeter;\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_65_AVX", "completion": "```cpp\nstd::vector<int> intersperse_simd(std::vector<int> numbers, int delimeter) {\n    int n = numbers.size();\n    if (n <= 1) return numbers;\n\n    std::vector<int> result(2 * n - 1);\n    int* input = numbers.data();\n    int* output = result.data();\n\n    int vec_size = n - (n % 8);\n    \n    for (int i = 0; i < vec_size; i += 8) {\n        __m256i vec_input = _mm256_loadu_si256((__m256i*)(input + i));\n        \n        __m256i vec_delim = _mm256_set1_epi32(delimeter);\n        \n        // Shuffle to interleave elements\n        __m256i shuffle_mask = _mm256_setr_epi32(0, 8, 1, 8, 2, 8, 3, 8);\n        __m256i shuffled = _mm256_permutevar8x32_epi32(vec_input, shuffle_mask);\n        \n        // Store results\n        _mm256_storeu_si256((__m256i*)(output + 2*i), shuffled);\n        _mm256_storeu_si256((__m256i*)(output + 2*i + 8), vec_delim);\n    }\n\n    // Handle remaining elements\n    for (int i = vec_size; i < n; i++) {\n        result[2*i] = input[i];\n        if (i < n-1) result[2*i + 1] = delimeter;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_66_AVX", "completion": "```cpp\nstd::vector<int64_t> sum_product_simd(std::vector<int16_t> numbers) {\n    int64_t sum = 0;\n    int64_t product = 1;\n    \n    int n = numbers.size();\n    int vector_size = 16; // AVX2 can process 16 int16_t elements at once\n    \n    // Process vectors in chunks of 16\n    for (int i = 0; i <= n - vector_size; i += vector_size) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&numbers[i]);\n        \n        // Horizontal sum\n        __m256i sum_vec = _mm256_sad_epu16(vec, _mm256_setzero_si256());\n        sum += _mm256_extract_epi64(sum_vec, 0) + \n               _mm256_extract_epi64(sum_vec, 1) + \n               _mm256_extract_epi64(sum_vec, 2) + \n               _mm256_extract_epi64(sum_vec, 3);\n        \n        // Horizontal product\n        __m256i prod_vec = vec;\n        prod_vec = _mm256_mullo_epi16(prod_vec, _mm256_srli_si256(prod_vec, 2));\n        prod_vec = _mm256_mullo_epi16(prod_vec, _mm256_srli_si256(prod_vec, 4));\n        prod_vec = _mm256_mullo_epi16(prod_vec, _mm256_srli_si256(prod_vec, 8));\n        product *= _mm256_extract_epi16(prod_vec, 0);\n    }\n    \n    // Process remaining elements\n    for (int i = (n / vector_size) * vector_size; i < n; ++i) {\n        sum += numbers[i];\n        product *= numbers[i];\n    }\n    \n    return {sum, product};\n}\n```"}
{"task_id": "SimdBench_66_AVX", "completion": "```cpp\nstd::vector<int64_t> sum_product_simd(std::vector<int16_t> numbers) {\n    int64_t sum = 0;\n    int64_t product = 1;\n    \n    int n = numbers.size();\n    int vector_size = 16; // AVX2 can process 16 int16_t elements at once\n    \n    // Process vectors in chunks of 16\n    for (int i = 0; i <= n - vector_size; i += vector_size) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&numbers[i]);\n        \n        // Sum calculation\n        __m256i zero = _mm256_setzero_si256();\n        __m256i sum_vec = _mm256_sad_epu8(vec, zero);\n        sum += _mm256_extract_epi64(sum_vec, 0) + \n               _mm256_extract_epi64(sum_vec, 1) + \n               _mm256_extract_epi64(sum_vec, 2) + \n               _mm256_extract_epi64(sum_vec, 3);\n        \n        // Product calculation\n        __m256i product_vec = _mm256_set1_epi16(1);\n        for (int j = 0; j < vector_size; j++) {\n            product *= numbers[i + j];\n        }\n    }\n    \n    // Process remaining elements\n    for (int i = (n / vector_size) * vector_size; i < n; i++) {\n        sum += numbers[i];\n        product *= numbers[i];\n    }\n    \n    return {sum, product};\n}\n```"}
{"task_id": "SimdBench_66_AVX", "completion": "```cpp\nstd::vector<int64_t> sum_product_simd(std::vector<int16_t> numbers) {\n    int64_t sum = 0;\n    int64_t product = 1;\n    \n    int n = numbers.size();\n    int vector_size = 16; // AVX2 can process 16 int16_t elements at once\n    \n    // Process vectors in chunks of 16\n    for (int i = 0; i <= n - vector_size; i += vector_size) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&numbers[i]);\n        \n        // Horizontal sum\n        __m256i sum_vec = _mm256_sad_epu16(vec, _mm256_setzero_si256());\n        sum += _mm256_extract_epi64(sum_vec, 0) + \n               _mm256_extract_epi64(sum_vec, 1) + \n               _mm256_extract_epi64(sum_vec, 2) + \n               _mm256_extract_epi64(sum_vec, 3);\n        \n        // Horizontal product\n        __m256i prod_vec = vec;\n        prod_vec = _mm256_mullo_epi16(prod_vec, _mm256_srli_si256(prod_vec, 2));\n        prod_vec = _mm256_mullo_epi16(prod_vec, _mm256_srli_si256(prod_vec, 4));\n        prod_vec = _mm256_mullo_epi16(prod_vec, _mm256_srli_si256(prod_vec, 8));\n        product *= _mm256_extract_epi16(prod_vec, 0);\n    }\n    \n    // Process remaining elements\n    for (int i = (n / vector_size) * vector_size; i < n; ++i) {\n        sum += numbers[i];\n        product *= numbers[i];\n    }\n    \n    return {sum, product};\n}\n```"}
{"task_id": "SimdBench_66_AVX", "completion": "```cpp\nstd::vector<int64_t> sum_product_simd(std::vector<int16_t> numbers) {\n    int64_t sum = 0;\n    int64_t product = 1;\n    \n    int n = numbers.size();\n    int vector_size = 16; // AVX2 can process 16 int16_t elements at once\n    \n    // Process vectors in chunks of 16\n    for (int i = 0; i <= n - vector_size; i += vector_size) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&numbers[i]);\n        \n        // Horizontal sum\n        __m256i sum_vec = _mm256_sad_epu16(vec, _mm256_setzero_si256());\n        sum += _mm256_extract_epi64(sum_vec, 0) + \n               _mm256_extract_epi64(sum_vec, 1) + \n               _mm256_extract_epi64(sum_vec, 2) + \n               _mm256_extract_epi64(sum_vec, 3);\n        \n        // Horizontal product\n        __m256i prod_vec = vec;\n        prod_vec = _mm256_mullo_epi16(prod_vec, _mm256_srli_si256(prod_vec, 2));\n        prod_vec = _mm256_mullo_epi16(prod_vec, _mm256_srli_si256(prod_vec, 4));\n        prod_vec = _mm256_mullo_epi16(prod_vec, _mm256_srli_si256(prod_vec, 8));\n        product *= _mm256_extract_epi16(prod_vec, 0);\n    }\n    \n    // Process remaining elements\n    for (int i = (n / vector_size) * vector_size; i < n; ++i) {\n        sum += numbers[i];\n        product *= numbers[i];\n    }\n    \n    return {sum, product};\n}\n```"}
{"task_id": "SimdBench_66_AVX", "completion": "```cpp\nstd::vector<int64_t> sum_product_simd(std::vector<int16_t> numbers) {\n    int64_t sum = 0;\n    int64_t product = 1;\n    \n    int n = numbers.size();\n    int vector_size = 16; // AVX2 can process 16 int16_t values at once\n    \n    // Process vectors in chunks of 16\n    for (int i = 0; i <= n - vector_size; i += vector_size) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&numbers[i]);\n        \n        // Horizontal sum\n        __m256i sum_vec = _mm256_sad_epu16(vec, _mm256_setzero_si256());\n        sum += _mm256_extract_epi64(sum_vec, 0) + \n               _mm256_extract_epi64(sum_vec, 1) + \n               _mm256_extract_epi64(sum_vec, 2) + \n               _mm256_extract_epi64(sum_vec, 3);\n        \n        // Horizontal product\n        __m256i prod_vec = vec;\n        prod_vec = _mm256_mullo_epi16(prod_vec, _mm256_srli_si256(prod_vec, 2));\n        prod_vec = _mm256_mullo_epi16(prod_vec, _mm256_srli_si256(prod_vec, 4));\n        prod_vec = _mm256_mullo_epi16(prod_vec, _mm256_srli_si256(prod_vec, 8));\n        product *= _mm256_extract_epi16(prod_vec, 0);\n    }\n    \n    // Process remaining elements\n    for (int i = (n / vector_size) * vector_size; i < n; ++i) {\n        sum += numbers[i];\n        product *= numbers[i];\n    }\n    \n    return {sum, product};\n}\n```"}
{"task_id": "SimdBench_67_AVX", "completion": "```cpp\nstd::vector<int> rolling_max_simd(std::vector<int> numbers) {\n    int n = numbers.size();\n    std::vector<int> result(n);\n    \n    // Process first element\n    result[0] = numbers[0];\n    \n    // Use AVX2 for vectorized processing\n    for (int i = 0; i < n - 8; i += 8) {\n        __m256i current = _mm256_loadu_si256((__m256i*)&numbers[i]);\n        __m256i prev_max = _mm256_loadu_si256((__m256i*)&result[i]);\n        \n        // Compute maximum between current and previous max\n        __m256i rolling_max = _mm256_max_epi32(current, prev_max);\n        \n        _mm256_storeu_si256((__m256i*)&result[i], rolling_max);\n    }\n    \n    // Handle remaining elements sequentially\n    for (int i = ((n - 1) / 8) * 8; i < n; ++i) {\n        result[i] = std::max(numbers[i], result[i-1]);\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_67_AVX", "completion": "```cpp\nstd::vector<int> rolling_max_simd(std::vector<int> numbers) {\n    int n = numbers.size();\n    std::vector<int> result(n);\n    \n    // Process first element\n    result[0] = numbers[0];\n    \n    // Use AVX2 for parallel processing\n    for (int i = 0; i < n - 8; i += 8) {\n        __m256i current_max = _mm256_loadu_si256((__m256i*)&result[i]);\n        __m256i current_nums = _mm256_loadu_si256((__m256i*)&numbers[i + 8]);\n        \n        __m256i max_vector = _mm256_max_epi32(current_max, current_nums);\n        _mm256_storeu_si256((__m256i*)&result[i + 8], max_vector);\n    }\n    \n    // Handle remaining elements sequentially\n    for (int i = ((n - 1) / 8) * 8; i < n; ++i) {\n        result[i] = std::max(result[i-1], numbers[i]);\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_67_AVX", "completion": "```cpp\nstd::vector<int> rolling_max_simd(std::vector<int> numbers) {\n    int n = numbers.size();\n    std::vector<int> result(n);\n    \n    // Process first element\n    result[0] = numbers[0];\n    \n    // Use AVX2 for parallel processing\n    for (int i = 0; i < n - 8; i += 8) {\n        __m256i current = _mm256_loadu_si256((__m256i*)&numbers[i]);\n        __m256i previous_max = _mm256_loadu_si256((__m256i*)&result[i]);\n        \n        __m256i max_vector = _mm256_max_epi32(current, previous_max);\n        \n        _mm256_storeu_si256((__m256i*)&result[i], max_vector);\n    }\n    \n    // Handle remaining elements\n    int max_so_far = result[0];\n    for (int i = 1; i < n; i++) {\n        max_so_far = std::max(max_so_far, numbers[i]);\n        result[i] = max_so_far;\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_67_AVX", "completion": "```cpp\nstd::vector<int> rolling_max_simd(std::vector<int> numbers) {\n    int n = numbers.size();\n    std::vector<int> result(n);\n    \n    // Process first element\n    result[0] = numbers[0];\n    \n    // Use AVX2 for parallel processing\n    for (int i = 0; i < n - 8; i += 8) {\n        __m256i current = _mm256_loadu_si256((__m256i*)&numbers[i]);\n        __m256i previous_max = _mm256_loadu_si256((__m256i*)&result[i]);\n        \n        // Compute maximum between current and previous max\n        __m256i max_vector = _mm256_max_epi32(current, previous_max);\n        \n        _mm256_storeu_si256((__m256i*)&result[i], max_vector);\n    }\n    \n    // Handle remaining elements sequentially\n    for (int i = ((n - 1) / 8) * 8; i < n; ++i) {\n        result[i] = std::max(numbers[i], i > 0 ? result[i-1] : numbers[i]);\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_67_AVX", "completion": "```cpp\nstd::vector<int> rolling_max_simd(std::vector<int> numbers) {\n    int n = numbers.size();\n    std::vector<int> result(n);\n    \n    // Process first element\n    result[0] = numbers[0];\n    \n    // Use AVX2 for parallel processing\n    for (int i = 0; i < n - 8; i += 8) {\n        __m256i current = _mm256_loadu_si256((__m256i*)&numbers[i]);\n        __m256i previous_max = _mm256_loadu_si256((__m256i*)&result[i]);\n        \n        // Compute maximum between current and previous max\n        __m256i max_vector = _mm256_max_epi32(current, previous_max);\n        \n        _mm256_storeu_si256((__m256i*)&result[i], max_vector);\n    }\n    \n    // Process remaining elements sequentially\n    for (int i = ((n - 1) / 8) * 8; i < n; ++i) {\n        result[i] = std::max(numbers[i], result[i-1]);\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_68_AVX", "completion": "```cpp\nstd::string string_xor_simd(std::string a, std::string b) {\n    int len = std::max(a.length(), b.length());\n    a.resize(len, '0');\n    b.resize(len, '0');\n    \n    std::string result(len, '0');\n    \n    // Process 256 bits (32 bytes) at a time\n    int vec_len = len / 32;\n    int remainder = len % 32;\n    \n    for (int i = 0; i < vec_len * 32; i += 32) {\n        __m256i va = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&a[i]));\n        __m256i vb = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&b[i]));\n        \n        // Convert characters to binary values\n        __m256i zero = _mm256_setzero_si256();\n        __m256i one = _mm256_cmpeq_epi8(va, _mm256_set1_epi8('1'));\n        __m256i va_bin = _mm256_sub_epi8(one, zero);\n        \n        one = _mm256_cmpeq_epi8(vb, _mm256_set1_epi8('1'));\n        __m256i vb_bin = _mm256_sub_epi8(one, zero);\n        \n        // Perform XOR\n        __m256i vxor = _mm256_xor_si256(va_bin, vb_bin);\n        \n        // Convert back to characters\n        __m256i result_chars = _mm256_add_epi8(vxor, _mm256_set1_epi8('0'));\n        \n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(&result[i]), result_chars);\n    }\n    \n    // Handle remainder\n    for (int i = vec_len * 32; i < len; ++i) {\n        result[i] = (a[i] == b[i]) ? '0' : '1';\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_68_AVX", "completion": "```cpp\nstd::string string_xor_simd(std::string a, std::string b) {\n    int len = std::max(a.length(), b.length());\n    \n    // Pad strings to same length with leading zeros\n    a.insert(0, std::max(0, (int)b.length() - (int)a.length()), '0');\n    b.insert(0, std::max(0, (int)a.length() - (int)b.length()), '0');\n    \n    std::string result(len, '0');\n    \n    // Process 256 bits (32 bytes) at a time\n    int i;\n    for (i = 0; i + 32 <= len; i += 32) {\n        __m256i va = _mm256_loadu_si256((__m256i*)(a.data() + i));\n        __m256i vb = _mm256_loadu_si256((__m256i*)(b.data() + i));\n        \n        // Convert characters to binary values\n        __m256i mask = _mm256_set1_epi8('1');\n        va = _mm256_cmpeq_epi8(va, mask);\n        vb = _mm256_cmpeq_epi8(vb, mask);\n        \n        // Perform XOR\n        __m256i vxor = _mm256_xor_si256(va, vb);\n        \n        // Convert back to characters\n        __m256i zero = _mm256_setzero_si256();\n        __m256i one = _mm256_cmpeq_epi8(vxor, zero);\n        one = _mm256_xor_si256(one, mask);\n        \n        // Store result\n        _mm256_storeu_si256((__m256i*)(result.data() + i), one);\n    }\n    \n    // Handle remaining bits\n    for (; i < len; ++i) {\n        result[i] = (a[i] == b[i]) ? '0' : '1';\n    }\n    \n    // Remove leading zeros\n    result.erase(0, result.find_first_not_of('0'));\n    if (result.empty()) result = \"0\";\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_68_AVX", "completion": "```cpp\nstd::string string_xor_simd(std::string a, std::string b) {\n    int len = std::max(a.length(), b.length());\n    a.resize(len, '0');\n    b.resize(len, '0');\n\n    std::string result(len, '0');\n    int vec_size = 256 / 8;  // 256-bit AVX register can hold 32 bytes\n    \n    for (int i = 0; i < len; i += vec_size) {\n        int remaining = std::min(vec_size, len - i);\n        \n        __m256i va = _mm256_setzero_si256();\n        __m256i vb = _mm256_setzero_si256();\n        \n        for (int j = 0; j < remaining; j++) {\n            va = _mm256_insert_epi8(va, a[i + j] - '0', j);\n            vb = _mm256_insert_epi8(vb, b[i + j] - '0', j);\n        }\n        \n        __m256i vxor = _mm256_xor_si256(va, vb);\n        \n        for (int j = 0; j < remaining; j++) {\n            result[i + j] = _mm256_extract_epi8(vxor, j) + '0';\n        }\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_68_AVX", "completion": "```cpp\nstd::string string_xor_simd(std::string a, std::string b) {\n    int len = std::max(a.length(), b.length());\n    a.resize(len, '0');\n    b.resize(len, '0');\n    \n    std::string result(len, '0');\n    \n    // Process 256 bits (32 bytes) at a time\n    int vec_len = len / 32;\n    int remainder = len % 32;\n    \n    for (int i = 0; i < vec_len * 32; i += 32) {\n        __m256i va = _mm256_loadu_si256((__m256i*)&a[i]);\n        __m256i vb = _mm256_loadu_si256((__m256i*)&b[i]);\n        \n        // Convert characters to binary values\n        __m256i zero = _mm256_setzero_si256();\n        __m256i mask = _mm256_cmpeq_epi8(va, _mm256_set1_epi8('1'));\n        va = _mm256_blendv_epi8(zero, _mm256_set1_epi8(1), mask);\n        \n        mask = _mm256_cmpeq_epi8(vb, _mm256_set1_epi8('1'));\n        vb = _mm256_blendv_epi8(zero, _mm256_set1_epi8(1), mask);\n        \n        // Perform XOR\n        __m256i vresult = _mm256_xor_si256(va, vb);\n        \n        // Convert back to characters\n        vresult = _mm256_add_epi8(vresult, _mm256_set1_epi8('0'));\n        \n        _mm256_storeu_si256((__m256i*)&result[i], vresult);\n    }\n    \n    // Handle remainder\n    for (int i = vec_len * 32; i < len; i++) {\n        result[i] = (a[i] == b[i]) ? '0' : '1';\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_68_AVX", "completion": "```cpp\nstd::string string_xor_simd(std::string a, std::string b) {\n    int len = std::min(a.length(), b.length());\n    std::string result(len, '0');\n\n    // Process 256 bits (32 bytes) at a time\n    int vectorLen = len / 32 * 32;\n    for (int i = 0; i < vectorLen; i += 32) {\n        __m256i va = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&a[i]));\n        __m256i vb = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&b[i]));\n        \n        // Convert characters to binary values\n        __m256i mask = _mm256_set1_epi8('1');\n        va = _mm256_cmpeq_epi8(va, mask);\n        vb = _mm256_cmpeq_epi8(vb, mask);\n        \n        // Perform XOR\n        __m256i vxor = _mm256_xor_si256(va, vb);\n        \n        // Convert back to characters\n        __m256i zero = _mm256_setzero_si256();\n        vxor = _mm256_cmpeq_epi8(vxor, zero);\n        vxor = _mm256_xor_si256(vxor, mask);\n        \n        // Store result\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(&result[i]), vxor);\n    }\n\n    // Handle remaining elements\n    for (int i = vectorLen; i < len; i++) {\n        result[i] = (a[i] == b[i]) ? '0' : '1';\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_69_AVX", "completion": "```cpp\nstd::string longest_simd(const std::vector<std::string> & strings) {\n    if (strings.empty()) {\n        return \"\";\n    }\n\n    int n = strings.size();\n    int max_length = 0;\n    int max_index = 0;\n\n    // Process 8 strings at a time using AVX2\n    int i;\n    for (i = 0; i + 8 <= n; i += 8) {\n        __m256i length_vec = _mm256_setzero_si256();\n        \n        // Load string lengths\n        for (int j = 0; j < 8; j++) {\n            int len = strings[i + j].length();\n            __m256i len_vec = _mm256_set1_epi32(len);\n            length_vec = _mm256_insert_epi32(length_vec, len, j);\n        }\n\n        // Find max length and index within this group of 8\n        __m256i max_length_vec = length_vec;\n        __m256i index_vec = _mm256_setr_epi32(0, 1, 2, 3, 4, 5, 6, 7);\n        __m256i max_index_vec = index_vec;\n\n        for (int k = 0; k < 3; k++) {\n            __m256i shifted = _mm256_srli_si256(max_length_vec, 4);\n            __m256i cmp = _mm256_cmpgt_epi32(shifted, max_length_vec);\n            max_length_vec = _mm256_blendv_epi8(max_length_vec, shifted, cmp);\n            max_index_vec = _mm256_blendv_epi8(max_index_vec, \n                _mm256_srli_si256(max_index_vec, 4), cmp);\n        }\n\n        int local_max_length = _mm256_extract_epi32(max_length_vec, 0);\n        int local_max_index = _mm256_extract_epi32(max_index_vec, 0);\n\n        if (local_max_length > max_length) {\n            max_length = local_max_length;\n            max_index = i + local_max_index;\n        }\n    }\n\n    // Process remaining strings\n    for (; i < n; i++) {\n        int len = strings[i].length();\n        if (len > max_length) {\n            max_length = len;\n            max_index = i;\n        }\n    }\n\n    return strings[max_index];\n}\n```"}
{"task_id": "SimdBench_69_AVX", "completion": "```cpp\nstd::string longest_simd(const std::vector<std::string> & strings) {\n    if (strings.empty()) {\n        return \"\";\n    }\n\n    size_t n = strings.size();\n    std::string longest = strings[0];\n    size_t max_length = longest.length();\n\n    // Process 8 strings at a time using AVX2\n    for (size_t i = 0; i + 8 <= n; i += 8) {\n        __m256i max_lengths = _mm256_setzero_si256();\n        __m256i max_indices = _mm256_setzero_si256();\n\n        for (size_t j = 0; j < 8; ++j) {\n            size_t current_length = strings[i + j].length();\n            __m256i length_vec = _mm256_set1_epi32(current_length);\n            __m256i index_vec = _mm256_set1_epi32(j);\n\n            // Compare current length with max lengths\n            __m256i cmp_mask = _mm256_cmpgt_epi32(length_vec, max_lengths);\n            max_lengths = _mm256_blendv_epi8(max_lengths, length_vec, cmp_mask);\n            max_indices = _mm256_blendv_epi8(max_indices, index_vec, cmp_mask);\n        }\n\n        // Extract the index of the longest string\n        int max_index_arr[8];\n        _mm256_storeu_si256((__m256i*)max_index_arr, max_indices);\n        int max_local_index = max_index_arr[0];\n\n        // Update longest string if necessary\n        if (strings[i + max_local_index].length() > max_length) {\n            longest = strings[i + max_local_index];\n            max_length = longest.length();\n        }\n    }\n\n    // Process remaining strings\n    for (size_t i = (n / 8) * 8; i < n; ++i) {\n        if (strings[i].length() > max_length) {\n            longest = strings[i];\n            max_length = longest.length();\n        }\n    }\n\n    return longest;\n}\n```"}
{"task_id": "SimdBench_69_AVX", "completion": "```cpp\nstd::string longest_simd(const std::vector<std::string> & strings) {\n    if (strings.empty()) {\n        return \"\";\n    }\n\n    int n = strings.size();\n    std::vector<int> lengths(n);\n    \n    // Vectorized length computation\n    int i = 0;\n    for (; i + 8 <= n; i += 8) {\n        __m256i lengths_vec = _mm256_set_epi32(\n            strings[i+7].length(), \n            strings[i+6].length(), \n            strings[i+5].length(), \n            strings[i+4].length(), \n            strings[i+3].length(), \n            strings[i+2].length(), \n            strings[i+1].length(), \n            strings[i].length()\n        );\n        _mm256_storeu_si256((__m256i*)&lengths[i], lengths_vec);\n    }\n\n    // Handle remaining elements\n    for (; i < n; ++i) {\n        lengths[i] = strings[i].length();\n    }\n\n    // Find max length and corresponding index\n    int max_length = lengths[0];\n    int max_index = 0;\n    \n    for (int j = 1; j < n; ++j) {\n        if (lengths[j] > max_length) {\n            max_length = lengths[j];\n            max_index = j;\n        }\n    }\n\n    return strings[max_index];\n}\n```"}
{"task_id": "SimdBench_69_AVX", "completion": "```cpp\nstd::string longest_simd(const std::vector<std::string> & strings) {\n    if (strings.empty()) {\n        return \"\";\n    }\n\n    size_t n = strings.size();\n    size_t max_length = 0;\n    size_t max_index = 0;\n\n    // Process 8 strings at a time using AVX2\n    size_t i = 0;\n    for (; i + 8 <= n; i += 8) {\n        __m256i max_lengths_vec = _mm256_setzero_si256();\n        __m256i max_indices_vec = _mm256_setzero_si256();\n\n        for (size_t j = 0; j < 8; ++j) {\n            size_t current_length = strings[i + j].length();\n            __m256i current_length_vec = _mm256_set1_epi32(current_length);\n            __m256i comparison = _mm256_cmpgt_epi32(current_length_vec, max_lengths_vec);\n            \n            max_lengths_vec = _mm256_blendv_epi8(max_lengths_vec, current_length_vec, comparison);\n            max_indices_vec = _mm256_blendv_epi8(max_indices_vec, _mm256_set1_epi32(j), comparison);\n        }\n\n        // Horizontal max reduction\n        __m128i max_lengths_low = _mm256_extracti128_si256(max_lengths_vec, 0);\n        __m128i max_lengths_high = _mm256_extracti128_si256(max_lengths_vec, 1);\n        __m128i max_indices_low = _mm256_extracti128_si256(max_indices_vec, 0);\n        __m128i max_indices_high = _mm256_extracti128_si256(max_indices_vec, 1);\n\n        max_lengths_low = _mm_max_epi32(max_lengths_low, max_lengths_high);\n        max_indices_low = _mm_blendv_epi8(max_indices_low, max_indices_high, \n                                           _mm_cmpgt_epi32(max_lengths_high, max_lengths_low));\n\n        int max_length_block = _mm_cvtsi128_si32(_mm_max_epi32(max_lengths_low, _mm_shuffle_epi32(max_lengths_low, _MM_SHUFFLE(1, 0, 3, 2))));\n        int max_index_block = _mm_cvtsi128_si32(_mm_blendv_epi8(max_indices_low, _mm_shuffle_epi32(max_indices_low, _MM_SHUFFLE(1, 0, 3, 2)), \n                                                 _mm_cmpgt_epi32(_mm_shuffle_epi32(max_lengths_low, _MM_SHUFFLE(1, 0, 3, 2)), max_lengths_low)));\n\n        if (max_length_block > max_length) {\n            max_length = max_length_block;\n            max_index = i + max_index_block;\n        }\n    }\n\n    // Process remaining strings sequentially\n    for (; i < n; ++i) {\n        if (strings[i].length() > max_length) {\n            max_length = strings[i].length();\n            max_index = i;\n        }\n    }\n\n    return strings[max_index];\n}\n```"}
{"task_id": "SimdBench_69_AVX", "completion": "```cpp\nstd::string longest_simd(const std::vector<std::string> & strings) {\n    if (strings.empty()) {\n        return \"\";\n    }\n\n    size_t n = strings.size();\n    size_t max_length = 0;\n    size_t max_index = 0;\n\n    // Process 8 strings at a time using AVX2\n    size_t i;\n    for (i = 0; i + 8 <= n; i += 8) {\n        __m256i max_lengths = _mm256_setzero_si256();\n        __m256i max_indices = _mm256_setzero_si256();\n\n        for (size_t j = 0; j < 8; ++j) {\n            size_t current_length = strings[i + j].length();\n            __m256i current_length_vec = _mm256_set1_epi32(current_length);\n            __m256i comparison = _mm256_cmpgt_epi32(current_length_vec, max_lengths);\n            max_lengths = _mm256_blendv_epi8(max_lengths, current_length_vec, comparison);\n            max_indices = _mm256_blendv_epi8(max_indices, _mm256_set1_epi32(j), comparison);\n        }\n\n        int lengths[8];\n        int indices[8];\n        _mm256_storeu_si256((__m256i*)lengths, max_lengths);\n        _mm256_storeu_si256((__m256i*)indices, max_indices);\n\n        for (int j = 0; j < 8; ++j) {\n            if (lengths[j] > max_length) {\n                max_length = lengths[j];\n                max_index = i + indices[j];\n            }\n        }\n    }\n\n    // Process remaining strings\n    for (; i < n; ++i) {\n        size_t current_length = strings[i].length();\n        if (current_length > max_length) {\n            max_length = current_length;\n            max_index = i;\n        }\n    }\n\n    return strings[max_index];\n}\n```"}
{"task_id": "SimdBench_70_AVX", "completion": "```cpp\nuint64_t greatest_common_divisor_simd(uint64_t a, uint64_t b) {\n    // If b is zero, return a\n    if (b == 0) return a;\n\n    // Use AVX2 to perform parallel subtraction\n    __m256i va = _mm256_set1_epi64x(a);\n    __m256i vb = _mm256_set1_epi64x(b);\n\n    while (_mm256_movemask_epi8(_mm256_cmpgt_epi64(vb, _mm256_setzero_si256())) != 0) {\n        __m256i temp = vb;\n        vb = _mm256_sub_epi64(va, _mm256_mullo_epi64(vb, _mm256_srli_epi64(_mm256_div_epu64(va, vb), 0)));\n        va = temp;\n    }\n\n    // Extract the result (first element of va)\n    uint64_t result;\n    _mm256_storeu_si256((__m256i*)&result, va);\n    return result;\n}\n```"}
{"task_id": "SimdBench_70_AVX", "completion": "```cpp\nuint64_t greatest_common_divisor_simd(uint64_t a, uint64_t b) {\n    // If either number is 0, return the other number\n    if (a == 0) return b;\n    if (b == 0) return a;\n\n    // Use Euclidean algorithm with SIMD optimization\n    __m256i va = _mm256_set1_epi64x(a);\n    __m256i vb = _mm256_set1_epi64x(b);\n\n    while (_mm256_movemask_epi8(_mm256_cmpgt_epi64(va, _mm256_setzero_si256())) && \n           _mm256_movemask_epi8(_mm256_cmpgt_epi64(vb, _mm256_setzero_si256()))) {\n        __m256i vtemp = _mm256_setzero_si256();\n        \n        // Parallel modulo operation\n        vtemp = _mm256_div_epu64(va, vb);\n        vtemp = _mm256_mullo_epi64(vtemp, vb);\n        va = _mm256_sub_epi64(va, vtemp);\n        \n        // Swap a and b\n        __m256i vswap = va;\n        va = vb;\n        vb = vswap;\n    }\n\n    // Extract the result (first element)\n    uint64_t result;\n    _mm256_storeu_si256((__m256i*)&result, va);\n    return result;\n}\n```"}
{"task_id": "SimdBench_70_AVX", "completion": "```cpp\nuint64_t greatest_common_divisor_simd(uint64_t a, uint64_t b) {\n    // If b is zero, return a\n    if (b == 0) return a;\n\n    // Use AVX2 to perform parallel subtraction\n    __m256i va = _mm256_set1_epi64x(a);\n    __m256i vb = _mm256_set1_epi64x(b);\n\n    while (_mm256_movemask_epi8(_mm256_cmpgt_epi64(vb, _mm256_setzero_si256())) != 0) {\n        __m256i temp = vb;\n        vb = _mm256_sub_epi64(va, _mm256_mullo_epi64(vb, _mm256_srli_epi64(_mm256_div_epu64(va, vb), 0)));\n        va = temp;\n    }\n\n    // Extract the result from the first lane\n    uint64_t result;\n    _mm256_storeu_si256((__m256i*)&result, va);\n    return result;\n}\n```"}
{"task_id": "SimdBench_70_AVX", "completion": "```cpp\nuint64_t greatest_common_divisor_simd(uint64_t a, uint64_t b) {\n    // If either number is 0, return the other number\n    if (a == 0) return b;\n    if (b == 0) return a;\n\n    // Use Euclidean algorithm with AVX2 subtraction\n    __m256i va = _mm256_set1_epi64x(a);\n    __m256i vb = _mm256_set1_epi64x(b);\n\n    while (_mm256_movemask_epi8(_mm256_cmpgt_epi64(va, _mm256_setzero_si256())) && \n           _mm256_movemask_epi8(_mm256_cmpgt_epi64(vb, _mm256_setzero_si256()))) {\n        __m256i mask = _mm256_cmpgt_epi64(va, vb);\n        va = _mm256_sub_epi64(va, _mm256_and_si256(vb, mask));\n        vb = _mm256_sub_epi64(vb, _mm256_and_si256(va, _mm256_xor_si256(mask, _mm256_set1_epi64x(-1))));\n    }\n\n    // Extract the result (first non-zero value)\n    uint64_t result = _mm256_extract_epi64(va, 0);\n    if (result == 0) result = _mm256_extract_epi64(vb, 0);\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_70_AVX", "completion": "```cpp\nuint64_t greatest_common_divisor_simd(uint64_t a, uint64_t b) {\n    // If b is zero, return a\n    if (b == 0) return a;\n\n    // Use AVX2 to perform parallel subtraction\n    __m256i va = _mm256_set1_epi64x(a);\n    __m256i vb = _mm256_set1_epi64x(b);\n\n    while (_mm256_movemask_epi8(_mm256_cmpgt_epi64(vb, _mm256_setzero_si256())) != 0) {\n        __m256i temp = _mm256_sub_epi64(va, _mm256_mullo_epi64(\n            _mm256_div_epu64(va, vb), \n            vb\n        ));\n        va = vb;\n        vb = temp;\n    }\n\n    // Return the first element (GCD)\n    uint64_t result;\n    _mm256_storeu_si256((__m256i*)&result, va);\n    return result;\n}\n```"}
{"task_id": "SimdBench_71_AVX", "completion": "```cpp\nstd::vector<float> find_closest_elements_simd(std::vector<float> numbers) {\n    int n = numbers.size();\n    float min_diff = std::numeric_limits<float>::max();\n    float first = numbers[0], second = numbers[1];\n\n    // Process in chunks of 8 floats using AVX\n    for (int i = 0; i < n - 8; i += 8) {\n        __m256 current_vec = _mm256_loadu_ps(&numbers[i]);\n        \n        for (int j = i + 8; j < n; j++) {\n            __m256 compare_vec = _mm256_set1_ps(numbers[j]);\n            __m256 diff_vec = _mm256_sub_ps(current_vec, compare_vec);\n            __m256 abs_diff_vec = _mm256_andnot_ps(_mm256_set1_ps(-0.0f), diff_vec);\n            \n            float abs_diffs[8];\n            _mm256_storeu_ps(abs_diffs, abs_diff_vec);\n            \n            for (int k = 0; k < 8; k++) {\n                if (abs_diffs[k] < min_diff) {\n                    min_diff = abs_diffs[k];\n                    first = current_vec[k];\n                    second = numbers[j];\n                }\n            }\n        }\n    }\n\n    // Handle remaining elements\n    for (int i = (n / 8) * 8; i < n; i++) {\n        for (int j = i + 1; j < n; j++) {\n            float diff = std::abs(numbers[i] - numbers[j]);\n            if (diff < min_diff) {\n                min_diff = diff;\n                first = std::min(numbers[i], numbers[j]);\n                second = std::max(numbers[i], numbers[j]);\n            }\n        }\n    }\n\n    return {first, second};\n}\n```"}
{"task_id": "SimdBench_71_AVX", "completion": "```cpp\nstd::vector<float> find_closest_elements_simd(std::vector<float> numbers) {\n    int n = numbers.size();\n    float min_diff = std::numeric_limits<float>::max();\n    float first = numbers[0], second = numbers[1];\n\n    // Process 8 elements at a time using AVX\n    for (int i = 0; i < n - 8; i += 8) {\n        __m256 current_vec = _mm256_loadu_ps(&numbers[i]);\n        \n        for (int j = i + 8; j < n; ++j) {\n            __m256 diff_vec = _mm256_sub_ps(_mm256_set1_ps(numbers[j]), current_vec);\n            __m256 abs_diff_vec = _mm256_abs_ps(diff_vec);\n            \n            float abs_diff_arr[8];\n            _mm256_storeu_ps(abs_diff_arr, abs_diff_vec);\n            \n            for (int k = 0; k < 8; ++k) {\n                if (abs_diff_arr[k] < min_diff) {\n                    min_diff = abs_diff_arr[k];\n                    first = std::min(numbers[i + k], numbers[j]);\n                    second = std::max(numbers[i + k], numbers[j]);\n                }\n            }\n        }\n    }\n\n    // Handle remaining elements\n    for (int i = n - (n % 8); i < n; ++i) {\n        for (int j = i + 1; j < n; ++j) {\n            float diff = std::abs(numbers[i] - numbers[j]);\n            if (diff < min_diff) {\n                min_diff = diff;\n                first = std::min(numbers[i], numbers[j]);\n                second = std::max(numbers[i], numbers[j]);\n            }\n        }\n    }\n\n    return {first, second};\n}\n```"}
{"task_id": "SimdBench_71_AVX", "completion": "```cpp\nstd::vector<float> find_closest_elements_simd(std::vector<float> numbers) {\n    int n = numbers.size();\n    float min_diff = std::numeric_limits<float>::max();\n    float closest_a = numbers[0], closest_b = numbers[1];\n\n    // Process in groups of 8 floats using AVX\n    for (int i = 0; i < n - 8; i += 8) {\n        __m256 current_vec = _mm256_loadu_ps(&numbers[i]);\n\n        for (int j = i + 8; j < n; j++) {\n            __m256 diff_vec = _mm256_sub_ps(_mm256_set1_ps(numbers[j]), current_vec);\n            __m256 abs_diff_vec = _mm256_andnot_ps(_mm256_set1_ps(-0.0f), diff_vec);\n\n            // Horizontal min to find smallest difference\n            __m256 min_diff_vec = _mm256_min_ps(abs_diff_vec, _mm256_permute_ps(abs_diff_vec, _MM_SHUFFLE(2, 1, 0, 3)));\n            min_diff_vec = _mm256_min_ps(min_diff_vec, _mm256_permute_ps(min_diff_vec, _MM_SHUFFLE(1, 0, 3, 2)));\n            min_diff_vec = _mm256_min_ps(min_diff_vec, _mm256_permute2f128_ps(min_diff_vec, min_diff_vec, 1));\n\n            float current_min_diff = _mm256_cvtss_f32(min_diff_vec);\n            if (current_min_diff < min_diff) {\n                min_diff = current_min_diff;\n                closest_a = numbers[j] - current_min_diff;\n                closest_b = numbers[j];\n            }\n        }\n    }\n\n    // Handle remaining elements\n    for (int i = n - (n % 8); i < n; i++) {\n        for (int j = 0; j < i; j++) {\n            float diff = std::abs(numbers[i] - numbers[j]);\n            if (diff < min_diff) {\n                min_diff = diff;\n                closest_a = std::min(numbers[i], numbers[j]);\n                closest_b = std::max(numbers[i], numbers[j]);\n            }\n        }\n    }\n\n    return {closest_a, closest_b};\n}\n```"}
{"task_id": "SimdBench_71_AVX", "completion": "```cpp\nstd::vector<float> find_closest_elements_simd(std::vector<float> numbers) {\n    int n = numbers.size();\n    float min_diff = std::numeric_limits<float>::max();\n    float closest_a = numbers[0], closest_b = numbers[1];\n\n    // Process in groups of 8 using AVX\n    for (int i = 0; i < n; i += 8) {\n        for (int j = 0; j < n; j += 8) {\n            // Skip comparing same elements\n            if (i == j) continue;\n\n            // Determine how many elements to process\n            int max_k = std::min(8, n - i);\n            int max_l = std::min(8, n - j);\n\n            // Load vectors\n            __m256 va = _mm256_loadu_ps(&numbers[i]);\n            __m256 vb = _mm256_loadu_ps(&numbers[j]);\n\n            // Compute absolute differences\n            for (int k = 0; k < max_k; k++) {\n                for (int l = 0; l < max_l; l++) {\n                    float a = numbers[i + k];\n                    float b = numbers[j + l];\n                    \n                    // Skip comparing same element\n                    if (a == b) continue;\n\n                    float diff = std::abs(a - b);\n                    if (diff < min_diff) {\n                        min_diff = diff;\n                        closest_a = std::min(a, b);\n                        closest_b = std::max(a, b);\n                    }\n                }\n            }\n        }\n    }\n\n    return {closest_a, closest_b};\n}\n```"}
{"task_id": "SimdBench_71_AVX", "completion": "```cpp\nstd::vector<float> find_closest_elements_simd(std::vector<float> numbers) {\n    int n = numbers.size();\n    float min_diff = std::numeric_limits<float>::max();\n    float first = numbers[0], second = numbers[1];\n\n    // Process in groups of 8 floats using AVX\n    for (int i = 0; i < n - 8; i += 8) {\n        __m256 current_vec = _mm256_loadu_ps(&numbers[i]);\n\n        for (int j = i + 8; j < n; j++) {\n            __m256 diff_vec = _mm256_sub_ps(current_vec, _mm256_set1_ps(numbers[j]));\n            __m256 abs_diff_vec = _mm256_andnot_ps(_mm256_set1_ps(-0.0f), diff_vec);\n\n            // Horizontal min of absolute differences\n            __m128 low_half = _mm256_extractf128_ps(abs_diff_vec, 0);\n            __m128 high_half = _mm256_extractf128_ps(abs_diff_vec, 1);\n            __m128 min_vec = _mm_min_ps(low_half, high_half);\n            min_vec = _mm_min_ps(min_vec, _mm_shuffle_ps(min_vec, min_vec, _MM_SHUFFLE(1, 0, 3, 2)));\n            min_vec = _mm_min_ps(min_vec, _mm_shuffle_ps(min_vec, min_vec, _MM_SHUFFLE(0, 1, 2, 3)));\n            float min_diff_simd = _mm_cvtss_f32(min_vec);\n\n            if (min_diff_simd < min_diff) {\n                min_diff = min_diff_simd;\n                first = numbers[i + _mm_cvtss_si32(_mm_cmpeq_ss(abs_diff_vec, _mm_set1_ps(min_diff_simd)))];\n                second = numbers[j];\n            }\n        }\n    }\n\n    // Handle remaining elements\n    for (int i = n - 8; i < n - 1; i++) {\n        for (int j = i + 1; j < n; j++) {\n            float diff = std::abs(numbers[i] - numbers[j]);\n            if (diff < min_diff) {\n                min_diff = diff;\n                first = numbers[i];\n                second = numbers[j];\n            }\n        }\n    }\n\n    return {first, second};\n}\n```"}
{"task_id": "SimdBench_72_AVX", "completion": "```cpp\nstd::vector<float> rescale_to_unit_simd(std::vector<float> numbers) {\n    int n = numbers.size();\n    std::vector<float> result(n);\n\n    // Find min and max using AVX\n    __m256 min_vec = _mm256_set1_ps(numbers[0]);\n    __m256 max_vec = _mm256_set1_ps(numbers[0]);\n\n    for (int i = 0; i < n; i += 8) {\n        __m256 curr_vec = _mm256_loadu_ps(&numbers[i]);\n        min_vec = _mm256_min_ps(min_vec, curr_vec);\n        max_vec = _mm256_max_ps(max_vec, curr_vec);\n    }\n\n    // Horizontal reduction for min and max\n    __m128 min_low = _mm256_extractf128_ps(min_vec, 0);\n    __m128 min_high = _mm256_extractf128_ps(min_vec, 1);\n    __m128 max_low = _mm256_extractf128_ps(max_vec, 0);\n    __m128 max_high = _mm256_extractf128_ps(max_vec, 1);\n\n    min_low = _mm_min_ps(min_low, min_high);\n    max_low = _mm_max_ps(max_low, max_high);\n\n    float min_val = _mm_cvtss_f32(_mm_min_ps(min_low, _mm_shuffle_ps(min_low, min_low, _MM_SHUFFLE(1, 1, 1, 1))));\n    float max_val = _mm_cvtss_f32(_mm_max_ps(max_low, _mm_shuffle_ps(max_low, max_low, _MM_SHUFFLE(1, 1, 1, 1))));\n\n    // Rescale using AVX\n    __m256 min_broadcast = _mm256_set1_ps(min_val);\n    __m256 scale_factor = _mm256_set1_ps(max_val - min_val);\n\n    for (int i = 0; i < n; i += 8) {\n        __m256 curr_vec = _mm256_loadu_ps(&numbers[i]);\n        __m256 scaled_vec = _mm256_div_ps(_mm256_sub_ps(curr_vec, min_broadcast), scale_factor);\n        _mm256_storeu_ps(&result[i], scaled_vec);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_72_AVX", "completion": "```cpp\nstd::vector<float> rescale_to_unit_simd(std::vector<float> numbers) {\n    if (numbers.size() < 2) return numbers;\n\n    // Find min and max using AVX\n    __m256 vec = _mm256_loadu_ps(numbers.data());\n    __m256 min_vec = vec;\n    __m256 max_vec = vec;\n\n    for (size_t i = 8; i < numbers.size(); i += 8) {\n        vec = _mm256_loadu_ps(&numbers[i]);\n        min_vec = _mm256_min_ps(min_vec, vec);\n        max_vec = _mm256_max_ps(max_vec, vec);\n    }\n\n    // Handle remaining elements\n    for (size_t i = (numbers.size() / 8) * 8; i < numbers.size(); ++i) {\n        min_vec = _mm256_min_ps(min_vec, _mm256_set1_ps(numbers[i]));\n        max_vec = _mm256_max_ps(max_vec, _mm256_set1_ps(numbers[i]));\n    }\n\n    // Horizontal reduction to find global min and max\n    __m128 min_low = _mm256_extractf128_ps(min_vec, 0);\n    __m128 min_high = _mm256_extractf128_ps(min_vec, 1);\n    __m128 max_low = _mm256_extractf128_ps(max_vec, 0);\n    __m128 max_high = _mm256_extractf128_ps(max_vec, 1);\n\n    min_low = _mm_min_ps(min_low, min_high);\n    max_low = _mm_max_ps(max_low, max_high);\n\n    min_low = _mm_min_ps(min_low, _mm_shuffle_ps(min_low, min_low, _MM_SHUFFLE(1, 0, 3, 2)));\n    max_low = _mm_max_ps(max_low, _mm_shuffle_ps(max_low, max_low, _MM_SHUFFLE(1, 0, 3, 2)));\n\n    min_low = _mm_min_ss(min_low, _mm_shuffle_ps(min_low, min_low, _MM_SHUFFLE(0, 0, 0, 1)));\n    max_low = _mm_max_ss(max_low, _mm_shuffle_ps(max_low, max_low, _MM_SHUFFLE(0, 0, 0, 1)));\n\n    float min_val = _mm_cvtss_f32(min_low);\n    float max_val = _mm_cvtss_f32(max_low);\n\n    // Rescale using AVX\n    __m256 min_vec_broadcast = _mm256_set1_ps(min_val);\n    __m256 scale_vec = _mm256_set1_ps(max_val - min_val);\n\n    std::vector<float> result(numbers.size());\n    for (size_t i = 0; i < numbers.size(); i += 8) {\n        vec = _mm256_loadu_ps(&numbers[i]);\n        __m256 scaled_vec = _mm256_div_ps(_mm256_sub_ps(vec, min_vec_broadcast), scale_vec);\n        _mm256_storeu_ps(&result[i], scaled_vec);\n    }\n\n    // Handle remaining elements\n    for (size_t i = (numbers.size() / 8) * 8; i < numbers.size(); ++i) {\n        result[i] = (numbers[i] - min_val) / (max_val - min_val);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_72_AVX", "completion": "```cpp\nstd::vector<float> rescale_to_unit_simd(std::vector<float> numbers) {\n    int n = numbers.size();\n    std::vector<float> result(n);\n\n    // Find min and max using AVX\n    __m256 min_vec = _mm256_set1_ps(numbers[0]);\n    __m256 max_vec = _mm256_set1_ps(numbers[0]);\n\n    for (int i = 0; i < n; i += 8) {\n        __m256 curr_vec = _mm256_loadu_ps(&numbers[i]);\n        min_vec = _mm256_min_ps(min_vec, curr_vec);\n        max_vec = _mm256_max_ps(max_vec, curr_vec);\n    }\n\n    // Horizontal reduction to find global min and max\n    __m128 min_low = _mm256_extractf128_ps(min_vec, 0);\n    __m128 min_high = _mm256_extractf128_ps(min_vec, 1);\n    __m128 max_low = _mm256_extractf128_ps(max_vec, 0);\n    __m128 max_high = _mm256_extractf128_ps(max_vec, 1);\n\n    min_low = _mm_min_ps(min_low, min_high);\n    max_low = _mm_max_ps(max_low, max_high);\n\n    float global_min = _mm_cvtss_f32(_mm_min_ss(min_low, _mm_shuffle_ps(min_low, min_low, 1)));\n    float global_max = _mm_cvtss_f32(_mm_max_ss(max_low, _mm_shuffle_ps(max_low, max_low, 1)));\n\n    // Compute scaling factor\n    __m256 min_broadcast = _mm256_set1_ps(global_min);\n    __m256 scale_broadcast = _mm256_set1_ps(global_max - global_min);\n\n    // Rescale vector\n    for (int i = 0; i < n; i += 8) {\n        __m256 curr_vec = _mm256_loadu_ps(&numbers[i]);\n        __m256 scaled_vec = _mm256_div_ps(_mm256_sub_ps(curr_vec, min_broadcast), scale_broadcast);\n        _mm256_storeu_ps(&result[i], scaled_vec);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_72_AVX", "completion": "```cpp\nstd::vector<float> rescale_to_unit_simd(std::vector<float> numbers) {\n    if (numbers.size() < 2) return numbers;\n\n    // Find min and max using AVX intrinsics\n    __m256 vec_min = _mm256_set1_ps(numbers[0]);\n    __m256 vec_max = _mm256_set1_ps(numbers[0]);\n    \n    for (size_t i = 0; i < numbers.size(); i += 8) {\n        __m256 current_vec = _mm256_loadu_ps(&numbers[i]);\n        vec_min = _mm256_min_ps(vec_min, current_vec);\n        vec_max = _mm256_max_ps(vec_max, current_vec);\n    }\n\n    // Horizontal reduction to find global min and max\n    __m128 min_low = _mm256_extractf128_ps(vec_min, 0);\n    __m128 min_high = _mm256_extractf128_ps(vec_min, 1);\n    __m128 max_low = _mm256_extractf128_ps(vec_max, 0);\n    __m128 max_high = _mm256_extractf128_ps(vec_max, 1);\n\n    min_low = _mm_min_ps(min_low, min_high);\n    max_low = _mm_max_ps(max_low, max_high);\n\n    min_low = _mm_min_ps(min_low, _mm_shuffle_ps(min_low, min_low, _MM_SHUFFLE(1, 0, 3, 2)));\n    max_low = _mm_max_ps(max_low, _mm_shuffle_ps(max_low, max_low, _MM_SHUFFLE(1, 0, 3, 2)));\n\n    min_low = _mm_min_ps(min_low, _mm_shuffle_ps(min_low, min_low, _MM_SHUFFLE(0, 1, 2, 3)));\n    max_low = _mm_max_ps(max_low, _mm_shuffle_ps(max_low, max_low, _MM_SHUFFLE(0, 1, 2, 3)));\n\n    float global_min = _mm_cvtss_f32(min_low);\n    float global_max = _mm_cvtss_f32(max_low);\n\n    // Rescale vector\n    __m256 min_vec = _mm256_set1_ps(global_min);\n    __m256 max_vec = _mm256_set1_ps(global_max);\n    __m256 range_vec = _mm256_sub_ps(max_vec, min_vec);\n\n    std::vector<float> result(numbers.size());\n    for (size_t i = 0; i < numbers.size(); i += 8) {\n        __m256 current_vec = _mm256_loadu_ps(&numbers[i]);\n        __m256 scaled_vec = _mm256_div_ps(_mm256_sub_ps(current_vec, min_vec), range_vec);\n        _mm256_storeu_ps(&result[i], scaled_vec);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_72_AVX", "completion": "```cpp\nstd::vector<float> rescale_to_unit_simd(std::vector<float> numbers) {\n    if (numbers.size() < 2) return numbers;\n\n    // Find min and max using AVX\n    __m256 vec = _mm256_loadu_ps(numbers.data());\n    __m256 min_vec = vec;\n    __m256 max_vec = vec;\n\n    for (size_t i = 8; i < numbers.size(); i += 8) {\n        vec = _mm256_loadu_ps(&numbers[i]);\n        min_vec = _mm256_min_ps(min_vec, vec);\n        max_vec = _mm256_max_ps(max_vec, vec);\n    }\n\n    // Handle remaining elements\n    for (size_t i = (numbers.size() / 8) * 8; i < numbers.size(); ++i) {\n        min_vec = _mm256_min_ps(min_vec, _mm256_set1_ps(numbers[i]));\n        max_vec = _mm256_max_ps(max_vec, _mm256_set1_ps(numbers[i]));\n    }\n\n    // Horizontal reduction to find global min and max\n    __m128 min_low = _mm256_extractf128_ps(min_vec, 0);\n    __m128 min_high = _mm256_extractf128_ps(min_vec, 1);\n    __m128 max_low = _mm256_extractf128_ps(max_vec, 0);\n    __m128 max_high = _mm256_extractf128_ps(max_vec, 1);\n\n    min_low = _mm_min_ps(min_low, min_high);\n    max_low = _mm_max_ps(max_low, max_high);\n\n    min_low = _mm_min_ps(min_low, _mm_shuffle_ps(min_low, min_low, _MM_SHUFFLE(1, 0, 3, 2)));\n    max_low = _mm_max_ps(max_low, _mm_shuffle_ps(max_low, max_low, _MM_SHUFFLE(1, 0, 3, 2)));\n\n    min_low = _mm_min_ss(min_low, _mm_shuffle_ps(min_low, min_low, _MM_SHUFFLE(0, 0, 0, 1)));\n    max_low = _mm_max_ss(max_low, _mm_shuffle_ps(max_low, max_low, _MM_SHUFFLE(0, 0, 0, 1)));\n\n    float min_val = _mm_cvtss_f32(min_low);\n    float max_val = _mm_cvtss_f32(max_low);\n\n    // Rescale\n    __m256 min_vec_broadcast = _mm256_set1_ps(min_val);\n    __m256 scale_vec = _mm256_set1_ps(max_val == min_val ? 0.0f : 1.0f / (max_val - min_val));\n\n    std::vector<float> result(numbers.size());\n    for (size_t i = 0; i < numbers.size(); i += 8) {\n        vec = _mm256_loadu_ps(&numbers[i]);\n        vec = _mm256_sub_ps(vec, min_vec_broadcast);\n        vec = _mm256_mul_ps(vec, scale_vec);\n        _mm256_storeu_ps(&result[i], vec);\n    }\n\n    // Handle remaining elements\n    for (size_t i = (numbers.size() / 8) * 8; i < numbers.size(); ++i) {\n        result[i] = (numbers[i] - min_val) / (max_val - min_val);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_73_AVX", "completion": "```cpp\nuint64_t largest_divisor_simd(uint64_t n) {\n    if (n <= 1) return 0;\n\n    // Use AVX2 to parallelize divisor search\n    __m256i target = _mm256_set1_epi64x(n);\n    __m256i indices = _mm256_setr_epi64x(n-1, n-2, n-3, n-4);\n    \n    for (;;) {\n        // Parallel modulo operations\n        __m256i mods = _mm256_rem_epi64(target, indices);\n        \n        // Check if any index divides evenly\n        __m256i zero = _mm256_setzero_si256();\n        __m256i mask = _mm256_cmpeq_epi64(mods, zero);\n        int result_mask = _mm256_movemask_pd((__m256d)mask);\n        \n        if (result_mask) {\n            // Find first divisor\n            for (int i = 0; i < 4; i++) {\n                if (result_mask & (1 << i)) {\n                    return _mm256_extract_epi64(indices, i);\n                }\n            }\n        }\n        \n        // Shift indices down by 4\n        indices = _mm256_sub_epi64(indices, _mm256_set1_epi64x(4));\n    }\n}\n```"}
{"task_id": "SimdBench_73_AVX", "completion": "```cpp\nuint64_t largest_divisor_simd(uint64_t n) {\n    if (n <= 1) return 0;\n\n    // Use AVX2 to parallelize divisor search\n    __m256i target = _mm256_set1_epi64x(n);\n    __m256i indices = _mm256_setr_epi64x(n-1, n-2, n-3, n-4);\n    \n    for (;;) {\n        // Check divisibility in parallel\n        __m256i div_check = _mm256_cmpeq_epi64(_mm256_set1_epi64x(0), \n            _mm256_set1_epi64x(n) % indices);\n        \n        int mask = _mm256_movemask_pd((__m256d)div_check);\n        \n        // If any divisor found, return the first one\n        if (mask) {\n            uint64_t divisors[4];\n            _mm256_storeu_si256((__m256i*)divisors, indices);\n            \n            for (int i = 0; i < 4; i++) {\n                if (mask & (1 << i) && n % divisors[i] == 0) {\n                    return divisors[i];\n                }\n            }\n        }\n        \n        // Decrement indices by 4\n        indices = _mm256_sub_epi64(indices, _mm256_set1_epi64x(4));\n        \n        // Stop if indices become zero or negative\n        if (_mm256_movemask_pd((__m256d)_mm256_cmpgt_epi64(_mm256_setzero_si256(), indices))) {\n            break;\n        }\n    }\n    \n    return 1;\n}\n```"}
{"task_id": "SimdBench_73_AVX", "completion": "```cpp\nuint64_t largest_divisor_simd(uint64_t n) {\n    if (n <= 1) return 0;\n\n    // Use AVX2 to parallelize divisor search\n    __m256i target = _mm256_set1_epi64x(n);\n    __m256i indices = _mm256_setr_epi64x(n-1, n-2, n-3, n-4);\n    __m256i zero = _mm256_setzero_si256();\n\n    for (int i = 0; i < 4; i++) {\n        __m256i divisors = indices;\n        __m256i remainder = _mm256_rem_epi64(target, divisors);\n        __m256i mask = _mm256_cmpeq_epi64(remainder, zero);\n        \n        if (_mm256_movemask_epi8(mask) != 0) {\n            uint64_t result[4];\n            _mm256_storeu_si256((__m256i*)result, divisors);\n            \n            for (int j = 0; j < 4; j++) {\n                if (result[j] != 0 && n % result[j] == 0) {\n                    return result[j];\n                }\n            }\n        }\n        \n        indices = _mm256_sub_epi64(indices, _mm256_set1_epi64x(4));\n    }\n    \n    return 1;\n}\n```"}
{"task_id": "SimdBench_73_AVX", "completion": "```cpp\nuint64_t largest_divisor_simd(uint64_t n) {\n    if (n <= 1) return 0;\n\n    // Use AVX2 to parallelize divisor search\n    __m256i target = _mm256_set1_epi64x(n);\n    __m256i indices = _mm256_setr_epi64x(n-1, n-2, n-3, n-4);\n    __m256i zero = _mm256_setzero_si256();\n\n    for (int i = 0; i < 4; i++) {\n        __m256i divisors = indices;\n        __m256i remainder = _mm256_rem_epi64(target, divisors);\n        __m256i mask = _mm256_cmpeq_epi64(remainder, zero);\n        \n        if (_mm256_movemask_epi8(mask) != 0) {\n            uint64_t result[4];\n            _mm256_storeu_si256((__m256i*)result, divisors);\n            \n            for (int j = 0; j < 4; j++) {\n                if (result[j] != 0 && n % result[j] == 0) {\n                    return result[j];\n                }\n            }\n        }\n        \n        indices = _mm256_sub_epi64(indices, _mm256_set1_epi64x(4));\n    }\n\n    return 1;\n}\n```"}
{"task_id": "SimdBench_73_AVX", "completion": "```cpp\nuint64_t largest_divisor_simd(uint64_t n) {\n    // Handle edge cases\n    if (n <= 1) return 0;\n\n    // Use AVX2 to parallelize divisor search\n    __m256i target = _mm256_set1_epi64x(n);\n    __m256i indices = _mm256_setr_epi64x(n-1, n-2, n-3, n-4);\n    \n    for (;;) {\n        // Check if any of these 4 numbers divide n evenly\n        __m256i mods = _mm256_setzero_si256();\n        for (int i = 0; i < 4; i++) {\n            __m256i divisor = _mm256_shuffle_epi32(indices, _MM_SHUFFLE(i, i, i, i));\n            __m256i quotient = _mm256_div_epu64(target, divisor);\n            __m256i remainder = _mm256_sub_epi64(target, _mm256_mul_epu32(quotient, divisor));\n            mods = _mm256_or_si256(mods, remainder);\n        }\n\n        // If any number divides evenly, return it\n        if (_mm256_testz_si256(mods, mods)) {\n            // Extract the first valid divisor\n            uint64_t result;\n            _mm256_storeu_si256((__m256i*)&result, indices);\n            return result;\n        }\n\n        // Shift indices down by 4\n        indices = _mm256_sub_epi64(indices, _mm256_set1_epi64x(4));\n        \n        // Stop if we've gone below 1\n        if (_mm256_movemask_epi8(_mm256_cmpgt_epi64(_mm256_set1_epi64x(1), indices)) == 0xFFFF) {\n            break;\n        }\n    }\n\n    return 1;\n}\n```"}
{"task_id": "SimdBench_74_AVX", "completion": "```cpp\nstd::vector<int> factorize_simd(int n) {\n    std::vector<int> factors;\n    \n    // Handle 2 as a special case\n    while (n % 2 == 0) {\n        factors.push_back(2);\n        n /= 2;\n    }\n    \n    // Use AVX2 for parallel factor checking\n    __m256i divisors = _mm256_setr_epi32(3, 5, 7, 11, 13, 17, 19, 23);\n    \n    for (int i = 0; i < 8; i++) {\n        int divisor = _mm256_extract_epi32(divisors, i);\n        \n        while (n % divisor == 0) {\n            factors.push_back(divisor);\n            n /= divisor;\n        }\n        \n        if (n == 1) break;\n    }\n    \n    // Handle remaining large prime factor\n    if (n > 1) {\n        factors.push_back(n);\n    }\n    \n    return factors;\n}\n```"}
{"task_id": "SimdBench_74_AVX", "completion": "```cpp\nstd::vector<int> factorize_simd(int n) {\n    std::vector<int> factors;\n    \n    // Use AVX2 for parallel factor finding\n    __m256i divisors = _mm256_setr_epi32(2, 3, 4, 5, 6, 7, 8, 9);\n    \n    while (n > 1) {\n        // Parallel division check\n        __m256i candidates = _mm256_set1_epi32(n);\n        __m256i modulos = _mm256_set1_epi32(0);\n        \n        for (int i = 0; i < 8; i++) {\n            __m256i div = _mm256_set1_epi32(_mm256_extract_epi32(divisors, i));\n            modulos = _mm256_rem_epi32(candidates, div);\n            \n            // Check if current divisor divides n\n            if (_mm256_extract_epi32(modulos, 0) == 0) {\n                int factor = _mm256_extract_epi32(div, 0);\n                factors.push_back(factor);\n                n /= factor;\n                break;\n            }\n        }\n        \n        // If no AVX divisors work, use standard division\n        if (n % 2 != 0 && n % 3 != 0 && n % 5 != 0 && n % 7 != 0 && n % 11 != 0) {\n            factors.push_back(n);\n            break;\n        }\n    }\n    \n    return factors;\n}\n```"}
{"task_id": "SimdBench_74_AVX", "completion": "```cpp\nstd::vector<int> factorize_simd(int n) {\n    std::vector<int> factors;\n    \n    // Handle small prime factors first\n    for (int divisor = 2; divisor * divisor <= n; ++divisor) {\n        while (n % divisor == 0) {\n            factors.push_back(divisor);\n            n /= divisor;\n        }\n    }\n    \n    // If remaining number is a prime larger than sqrt(n)\n    if (n > 1) {\n        factors.push_back(n);\n    }\n    \n    return factors;\n}\n```\n\nNote: While the problem statement requests an AVX/AVX2 implementation, prime factorization is inherently a sequential algorithm that doesn't naturally parallelize well with SIMD instructions. The provided implementation uses a standard sequential approach of trial division, which is the most straightforward method for prime factorization.\n\nTrue SIMD optimization for prime factorization would require more complex algorithmic approaches that are not trivial to implement with vector instructions. The core challenge is that each division step depends on the previous result, which breaks SIMD parallelism."}
{"task_id": "SimdBench_74_AVX", "completion": "```cpp\nstd::vector<int> factorize_simd(int n) {\n    std::vector<int> factors;\n    \n    // Handle 2 as a special case\n    while (n % 2 == 0) {\n        factors.push_back(2);\n        n /= 2;\n    }\n    \n    // Use AVX2 to parallelize factor search\n    __m256i divisors = _mm256_setr_epi32(3, 5, 7, 11, 13, 17, 19, 23);\n    \n    for (int i = 0; i < 8; i++) {\n        int divisor = _mm256_extract_epi32(divisors, i);\n        \n        while (n % divisor == 0) {\n            factors.push_back(divisor);\n            n /= divisor;\n        }\n        \n        if (n == 1) break;\n    }\n    \n    // Handle remaining large prime factor\n    if (n > 1) {\n        factors.push_back(n);\n    }\n    \n    return factors;\n}\n```"}
{"task_id": "SimdBench_74_AVX", "completion": "```cpp\nstd::vector<int> factorize_simd(int n) {\n    std::vector<int> factors;\n    \n    // Use AVX2 to parallelize trial division\n    __m256i divisors = _mm256_setr_epi32(2, 3, 4, 5, 6, 7, 8, 9);\n    \n    while (n > 1) {\n        // Vectorized division check\n        __m256i current_n = _mm256_set1_epi32(n);\n        __m256i remainders = _mm256_rem_epi32(current_n, divisors);\n        \n        // Find first zero remainder\n        for (int i = 0; i < 8; i++) {\n            int remainder = _mm256_extract_epi32(remainders, i);\n            int divisor = _mm256_extract_epi32(divisors, i);\n            \n            if (remainder == 0 && divisor <= n) {\n                factors.push_back(divisor);\n                n /= divisor;\n                break;\n            }\n        }\n    }\n    \n    return factors;\n}\n```"}
{"task_id": "SimdBench_75_AVX", "completion": "```cpp\nstd::vector<float> get_positive_simd(const std::vector<float> & l) {\n    std::vector<float> result;\n    result.reserve(l.size());\n\n    size_t i = 0;\n    const size_t vectorSize = l.size() - (l.size() % 8);\n\n    // Process 8 floats at a time using AVX\n    for (; i < vectorSize; i += 8) {\n        __m256 vec = _mm256_loadu_ps(&l[i]);\n        __m256 zero = _mm256_setzero_ps();\n        __m256 mask = _mm256_cmp_ps(vec, zero, _CMP_GT_OS);\n        \n        __m256 positives = _mm256_and_ps(vec, mask);\n        \n        float temp[8];\n        _mm256_storeu_ps(temp, positives);\n        \n        for (int j = 0; j < 8; j++) {\n            if (temp[j] > 0) {\n                result.push_back(temp[j]);\n            }\n        }\n    }\n\n    // Handle remaining elements\n    for (; i < l.size(); i++) {\n        if (l[i] > 0) {\n            result.push_back(l[i]);\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_75_AVX", "completion": "```cpp\nstd::vector<float> get_positive_simd(const std::vector<float> & l) {\n    std::vector<float> result;\n    result.reserve(l.size());\n\n    size_t i = 0;\n    const size_t vectorSize = l.size() - (l.size() % 8);\n\n    // Process 8 floats at a time using AVX\n    for (; i < vectorSize; i += 8) {\n        __m256 vec = _mm256_loadu_ps(&l[i]);\n        __m256 zero = _mm256_setzero_ps();\n        __m256 mask = _mm256_cmp_ps(vec, zero, _CMP_GT_OS);\n        \n        __m256 positives = _mm256_and_ps(vec, mask);\n        \n        float temp[8];\n        _mm256_storeu_ps(temp, positives);\n        \n        for (int j = 0; j < 8; j++) {\n            if (temp[j] > 0) {\n                result.push_back(temp[j]);\n            }\n        }\n    }\n\n    // Handle remaining elements\n    for (; i < l.size(); i++) {\n        if (l[i] > 0) {\n            result.push_back(l[i]);\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_75_AVX", "completion": "```cpp\nstd::vector<float> get_positive_simd(const std::vector<float> & l) {\n    std::vector<float> result;\n    result.reserve(l.size());\n\n    size_t i = 0;\n    const size_t vectorSize = l.size() - (l.size() % 8);\n\n    // Process 8 floats at a time using AVX\n    for (; i < vectorSize; i += 8) {\n        __m256 vec = _mm256_loadu_ps(&l[i]);\n        __m256 zero = _mm256_setzero_ps();\n        __m256 mask = _mm256_cmp_ps(vec, zero, _CMP_GT_OQ);\n        \n        // Extract positive values\n        for (int j = 0; j < 8; ++j) {\n            if (_mm256_movemask_ps(mask) & (1 << j)) {\n                result.push_back(l[i + j]);\n            }\n        }\n    }\n\n    // Process remaining elements\n    for (; i < l.size(); ++i) {\n        if (l[i] > 0) {\n            result.push_back(l[i]);\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_75_AVX", "completion": "```cpp\nstd::vector<float> get_positive_simd(const std::vector<float> & l) {\n    std::vector<float> result;\n    size_t n = l.size();\n    \n    // Process 8 floats at a time using AVX\n    for (size_t i = 0; i < n; i += 8) {\n        __m256 vec = _mm256_loadu_ps(&l[i]);\n        __m256 zero = _mm256_setzero_ps();\n        __m256 mask = _mm256_cmp_ps(vec, zero, _CMP_GT_OS);\n        \n        // Extract positive values\n        for (int j = 0; j < 8 && i + j < n; ++j) {\n            if (_mm256_movemask_ps(mask) & (1 << j)) {\n                result.push_back(l[i + j]);\n            }\n        }\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_75_AVX", "completion": "```cpp\nstd::vector<float> get_positive_simd(const std::vector<float> & l) {\n    std::vector<float> result;\n    result.reserve(l.size());\n\n    size_t i = 0;\n    const size_t vectorSize = l.size() - (l.size() % 8);\n\n    // Process 8 floats at a time using AVX\n    for (; i < vectorSize; i += 8) {\n        __m256 vec = _mm256_loadu_ps(&l[i]);\n        __m256 zero = _mm256_setzero_ps();\n        __m256 mask = _mm256_cmp_ps(vec, zero, _CMP_GT_OQ);\n        \n        // Extract positive values\n        for (int j = 0; j < 8; j++) {\n            if (_mm256_movemask_ps(mask) & (1 << j)) {\n                result.push_back(l[i + j]);\n            }\n        }\n    }\n\n    // Process remaining elements\n    for (; i < l.size(); i++) {\n        if (l[i] > 0) {\n            result.push_back(l[i]);\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_76_AVX", "completion": "```cpp\nbool is_prime_simd(int64_t n) {\n    if (n <= 1) return false;\n    if (n == 2 || n == 3) return true;\n    if (n % 2 == 0 || n % 3 == 0) return false;\n\n    int64_t sqrt_n = static_cast<int64_t>(std::sqrt(n));\n    \n    // Process 8 potential divisors in parallel\n    __m256i vec_n = _mm256_set1_epi64x(n);\n    __m256i vec_zero = _mm256_setzero_si256();\n    \n    for (int64_t i = 5; i <= sqrt_n; i += 8) {\n        __m256i vec_i = _mm256_setr_epi64x(i, i+2, i+4, i+6);\n        __m256i vec_i_plus_1 = _mm256_setr_epi64x(i+1, i+3, i+5, i+7);\n        \n        // Check divisibility by vec_i\n        __m256i vec_mod_i = _mm256_rem_epi64(vec_n, vec_i);\n        __m256i vec_mod_i_plus_1 = _mm256_rem_epi64(vec_n, vec_i_plus_1);\n        \n        __m256i vec_zero_check_i = _mm256_cmpeq_epi64(vec_mod_i, vec_zero);\n        __m256i vec_zero_check_i_plus_1 = _mm256_cmpeq_epi64(vec_mod_i_plus_1, vec_zero);\n        \n        if (_mm256_movemask_epi8(vec_zero_check_i) || _mm256_movemask_epi8(vec_zero_check_i_plus_1)) {\n            return false;\n        }\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_76_AVX", "completion": "```cpp\nbool is_prime_simd(int64_t n) {\n    if (n <= 1) return false;\n    if (n == 2 || n == 3) return true;\n    if (n % 2 == 0 || n % 3 == 0) return false;\n\n    int64_t sqrt_n = static_cast<int64_t>(std::sqrt(n));\n    \n    // Process 8 potential divisors in parallel\n    __m256i vec_n = _mm256_set1_epi64x(n);\n    __m256i vec_zero = _mm256_setzero_si256();\n    \n    for (int64_t i = 5; i <= sqrt_n; i += 8) {\n        __m256i vec_divisors = _mm256_setr_epi64x(\n            i, i+2, i+4, i+6\n        );\n        \n        __m256i vec_mod_results = _mm256_setzero_si256();\n        \n        // Compute modulo for each potential divisor\n        for (int j = 0; j < 4; j++) {\n            __m256i div = _mm256_shuffle_epi32(vec_divisors, _MM_SHUFFLE(j, j, j, j));\n            __m256i mod = _mm256_rem_epi64(vec_n, div);\n            vec_mod_results = _mm256_or_si256(vec_mod_results, mod);\n        }\n        \n        // Check if any modulo is zero\n        if (_mm256_movemask_epi8(_mm256_cmpeq_epi64(vec_mod_results, vec_zero)) != 0) {\n            return false;\n        }\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_76_AVX", "completion": "```cpp\nbool is_prime_simd(int64_t n) {\n    if (n <= 1) return false;\n    if (n == 2 || n == 3) return true;\n    if (n % 2 == 0 || n % 3 == 0) return false;\n\n    int64_t sqrt_n = static_cast<int64_t>(std::sqrt(n));\n    \n    // Process 8 potential divisors in parallel\n    __m256i vec_n = _mm256_set1_epi64x(n);\n    __m256i vec_zero = _mm256_setzero_si256();\n    \n    for (int64_t i = 5; i <= sqrt_n; i += 8) {\n        __m256i vec_divisors = _mm256_setr_epi64x(\n            i, i+2, i+4, i+6\n        );\n        \n        __m256i vec_mod_results = _mm256_setzero_si256();\n        \n        // Compute modulo for each divisor\n        for (int j = 0; j < 4; j++) {\n            __m256i vec_div = _mm256_shuffle_epi32(vec_divisors, _MM_SHUFFLE(j, j, j, j));\n            __m256i vec_mod = _mm256_rem_epi64(vec_n, vec_div);\n            vec_mod_results = _mm256_or_si256(vec_mod_results, _mm256_cmpeq_epi64(vec_mod, vec_zero));\n        }\n        \n        // Check if any divisor divides n evenly\n        if (_mm256_movemask_epi8(vec_mod_results)) {\n            return false;\n        }\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_76_AVX", "completion": "```cpp\nbool is_prime_simd(int64_t n) {\n    if (n <= 1) return false;\n    if (n == 2 || n == 3) return true;\n    if (n % 2 == 0 || n % 3 == 0) return false;\n\n    int64_t sqrt_n = static_cast<int64_t>(std::sqrt(n));\n    \n    // Process 8 potential divisors in parallel\n    __m256i vec_n = _mm256_set1_epi64x(n);\n    __m256i vec_zero = _mm256_setzero_si256();\n    \n    for (int64_t i = 5; i <= sqrt_n; i += 8) {\n        __m256i vec_divisors = _mm256_setr_epi64x(\n            i, i+2, i+4, i+6\n        );\n        \n        // Check divisibility\n        __m256i vec_mod1 = _mm256_rem_epi64(vec_n, vec_divisors);\n        __m256i vec_mod2 = _mm256_rem_epi64(vec_n, _mm256_add_epi64(vec_divisors, _mm256_set1_epi64x(1)));\n        \n        __m256i vec_is_divisible = _mm256_or_si256(\n            _mm256_cmpeq_epi64(vec_mod1, vec_zero),\n            _mm256_cmpeq_epi64(vec_mod2, vec_zero)\n        );\n        \n        if (_mm256_movemask_epi8(vec_is_divisible)) {\n            return false;\n        }\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_76_AVX", "completion": "```cpp\nbool is_prime_simd(int64_t n) {\n    if (n <= 1) return false;\n    if (n == 2 || n == 3) return true;\n    if (n % 2 == 0 || n % 3 == 0) return false;\n\n    int64_t sqrt_n = static_cast<int64_t>(std::sqrt(n));\n    \n    // Process 8 potential divisors in parallel\n    __m256i vec_n = _mm256_set1_epi64x(n);\n    __m256i vec_zero = _mm256_setzero_si256();\n    \n    for (int64_t i = 5; i <= sqrt_n; i += 8) {\n        __m256i vec_divisors = _mm256_setr_epi64x(\n            i, i+2, i+4, i+6\n        );\n        \n        __m256i vec_mod_results = _mm256_setzero_si256();\n        \n        // Compute modulo for each divisor\n        for (int j = 0; j < 4; j++) {\n            __m256i vec_div = _mm256_shuffle_epi32(vec_divisors, _MM_SHUFFLE(j, j, j, j));\n            __m256i vec_mod = _mm256_rem_epi64(vec_n, vec_div);\n            vec_mod_results = _mm256_or_si256(vec_mod_results, _mm256_cmpeq_epi64(vec_mod, vec_zero));\n        }\n        \n        // Check if any modulo is zero\n        if (_mm256_movemask_epi8(vec_mod_results)) {\n            return false;\n        }\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_77_AVX", "completion": "```cpp\nstd::string solve_simd(const std::string & s) {\n    std::string result = s;\n    int len = s.length();\n    \n    // If no letters, simply reverse the string\n    bool hasLetter = false;\n    for (char c : s) {\n        if (std::isalpha(c)) {\n            hasLetter = true;\n            break;\n        }\n    }\n    \n    if (!hasLetter) {\n        std::reverse(result.begin(), result.end());\n        return result;\n    }\n    \n    // Process string using AVX2 \n    const int VECTOR_SIZE = 32;  // AVX2 supports 256-bit vectors\n    \n    for (int i = 0; i + VECTOR_SIZE <= len; i += VECTOR_SIZE) {\n        __m256i chars = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&s[i]));\n        \n        // Lowercase to uppercase mask\n        __m256i lower_mask = _mm256_set1_epi8('a');\n        __m256i upper_mask = _mm256_set1_epi8('z');\n        __m256i lower_to_upper_offset = _mm256_set1_epi8('A' - 'a');\n        \n        // Uppercase to lowercase mask\n        __m256i upper_case_lower_mask = _mm256_set1_epi8('A');\n        __m256i upper_case_upper_mask = _mm256_set1_epi8('Z');\n        __m256i upper_to_lower_offset = _mm256_set1_epi8('a' - 'A');\n        \n        // Check for lowercase letters\n        __m256i is_lower = _mm256_and_si256(\n            _mm256_cmpgt_epi8(chars, lower_mask - 1),\n            _mm256_cmpgt_epi8(upper_mask + 1, chars)\n        );\n        \n        // Check for uppercase letters\n        __m256i is_upper = _mm256_and_si256(\n            _mm256_cmpgt_epi8(chars, upper_case_lower_mask - 1),\n            _mm256_cmpgt_epi8(upper_case_upper_mask + 1, chars)\n        );\n        \n        // Convert lowercase to uppercase\n        __m256i lower_to_upper = _mm256_and_si256(is_lower, lower_to_upper_offset);\n        __m256i uppercase_chars = _mm256_add_epi8(chars, lower_to_upper);\n        \n        // Convert uppercase to lowercase\n        __m256i upper_to_lower = _mm256_and_si256(is_upper, upper_to_lower_offset);\n        __m256i lowercase_chars = _mm256_add_epi8(chars, upper_to_lower);\n        \n        // Combine results\n        __m256i case_changed = _mm256_blendv_epi8(\n            _mm256_blendv_epi8(chars, uppercase_chars, is_lower),\n            lowercase_chars,\n            is_upper\n        );\n        \n        // Store back to result\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(&result[i]), case_changed);\n    }\n    \n    // Handle remaining characters\n    for (int i = len - (len % VECTOR_SIZE); i < len; ++i) {\n        if (std::islower(s[i])) {\n            result[i] = std::toupper(s[i]);\n        } else if (std::isupper(s[i])) {\n            result[i] = std::tolower(s[i]);\n        }\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_77_AVX", "completion": "```cpp\nstd::string solve_simd(const std::string & s) {\n    std::string result = s;\n    int len = s.length();\n    \n    // If no letters, simply reverse the string\n    bool hasLetter = false;\n    for (char c : s) {\n        if (std::isalpha(c)) {\n            hasLetter = true;\n            break;\n        }\n    }\n    \n    if (!hasLetter) {\n        std::reverse(result.begin(), result.end());\n        return result;\n    }\n    \n    // Process string using AVX2 intrinsics\n    const int VECTOR_SIZE = 32; // AVX2 supports 256-bit vectors\n    \n    for (int i = 0; i + VECTOR_SIZE <= len; i += VECTOR_SIZE) {\n        __m256i chars = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&s[i]));\n        \n        // Check uppercase\n        __m256i upper_mask = _mm256_set1_epi8('A');\n        __m256i upper_check = _mm256_cmpgt_epi8(chars, _mm256_sub_epi8(upper_mask, _mm256_set1_epi8(1)));\n        upper_mask = _mm256_set1_epi8('Z');\n        upper_check = _mm256_and_si256(upper_check, _mm256_cmpgt_epi8(upper_mask, chars));\n        \n        // Check lowercase\n        __m256i lower_mask = _mm256_set1_epi8('a');\n        __m256i lower_check = _mm256_cmpgt_epi8(chars, _mm256_sub_epi8(lower_mask, _mm256_set1_epi8(1)));\n        lower_mask = _mm256_set1_epi8('z');\n        lower_check = _mm256_and_si256(lower_check, _mm256_cmpgt_epi8(lower_mask, chars));\n        \n        // Swap case\n        __m256i case_swap = _mm256_set1_epi8(32);\n        __m256i swapped_chars = _mm256_xor_si256(chars, _mm256_and_si256(_mm256_or_si256(upper_check, lower_check), case_swap));\n        \n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(&result[i]), swapped_chars);\n    }\n    \n    // Handle remaining characters\n    for (int i = (len / VECTOR_SIZE) * VECTOR_SIZE; i < len; ++i) {\n        if (std::islower(s[i])) {\n            result[i] = std::toupper(s[i]);\n        } else if (std::isupper(s[i])) {\n            result[i] = std::tolower(s[i]);\n        }\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_77_AVX", "completion": "```cpp\nstd::string solve_simd(const std::string & s) {\n    std::string result = s;\n    int len = s.length();\n    \n    // Process 32 bytes at a time using AVX2\n    int vectorLen = len - (len % 32);\n    for (int i = 0; i < vectorLen; i += 32) {\n        __m256i chars = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&s[i]));\n        \n        // Lowercase to uppercase conversion\n        __m256i lower_mask = _mm256_set1_epi8('a');\n        __m256i upper_mask = _mm256_set1_epi8('z');\n        __m256i lower_diff = _mm256_set1_epi8('A' - 'a');\n        \n        __m256i is_lower = _mm256_and_si256(\n            _mm256_cmpgt_epi8(chars, _mm256_sub_epi8(lower_mask, _mm256_set1_epi8(1))),\n            _mm256_cmpgt_epi8(_mm256_sub_epi8(upper_mask, chars), _mm256_set1_epi8(-1))\n        );\n        \n        __m256i lowercase_converted = _mm256_add_epi8(chars, _mm256_and_si256(is_lower, lower_diff));\n        \n        // Uppercase to lowercase conversion\n        lower_mask = _mm256_set1_epi8('A');\n        upper_mask = _mm256_set1_epi8('Z');\n        __m256i upper_diff = _mm256_set1_epi8('a' - 'A');\n        \n        __m256i is_upper = _mm256_and_si256(\n            _mm256_cmpgt_epi8(chars, _mm256_sub_epi8(lower_mask, _mm256_set1_epi8(1))),\n            _mm256_cmpgt_epi8(_mm256_sub_epi8(upper_mask, chars), _mm256_set1_epi8(-1))\n        );\n        \n        __m256i uppercase_converted = _mm256_add_epi8(chars, _mm256_and_si256(is_upper, upper_diff));\n        \n        // Combine converted characters\n        __m256i converted = _mm256_or_si256(\n            _mm256_andnot_si256(is_lower, _mm256_andnot_si256(is_upper, chars)),\n            _mm256_or_si256(lowercase_converted, uppercase_converted)\n        );\n        \n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(&result[i]), converted);\n    }\n    \n    // Process remaining characters\n    for (int i = vectorLen; i < len; ++i) {\n        if (islower(result[i])) {\n            result[i] = toupper(result[i]);\n        } else if (isupper(result[i])) {\n            result[i] = tolower(result[i]);\n        }\n    }\n    \n    // If no letters, reverse the string\n    if (std::none_of(result.begin(), result.end(), ::isalpha)) {\n        std::reverse(result.begin(), result.end());\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_77_AVX", "completion": "```cpp\nstd::string solve_simd(const std::string & s) {\n    std::string result = s;\n    int len = s.length();\n    \n    // If no letters, simply reverse the string\n    bool hasLetter = false;\n    for (char c : s) {\n        if (std::isalpha(c)) {\n            hasLetter = true;\n            break;\n        }\n    }\n    \n    if (!hasLetter) {\n        std::reverse(result.begin(), result.end());\n        return result;\n    }\n    \n    // Process string using AVX2 \n    const int VECTOR_SIZE = 32; // AVX2 supports 256-bit vectors\n    \n    for (int i = 0; i < len; i += VECTOR_SIZE) {\n        int remaining = std::min(VECTOR_SIZE, len - i);\n        \n        // Load 32 bytes from the string\n        __m256i chars = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&result[i]));\n        \n        // Create masks for uppercase and lowercase letters\n        __m256i uppercase_mask = _mm256_set1_epi8(0xDF); // 11011111 in binary\n        __m256i lowercase_mask = _mm256_set1_epi8(0x20); // 00100000 in binary\n        \n        // Check if character is uppercase (A-Z)\n        __m256i is_uppercase = _mm256_and_si256(_mm256_cmpgt_epi8(chars, _mm256_set1_epi8('A' - 1)), \n                                                _mm256_cmpgt_epi8(_mm256_set1_epi8('Z' + 1), chars));\n        \n        // Check if character is lowercase (a-z)\n        __m256i is_lowercase = _mm256_and_si256(_mm256_cmpgt_epi8(chars, _mm256_set1_epi8('a' - 1)), \n                                                _mm256_cmpgt_epi8(_mm256_set1_epi8('z' + 1), chars));\n        \n        // Toggle case for letters\n        __m256i toggled_chars = _mm256_xor_si256(chars, \n            _mm256_blendv_epi8(_mm256_setzero_si256(), lowercase_mask, is_uppercase)\n        );\n        toggled_chars = _mm256_xor_si256(toggled_chars, \n            _mm256_blendv_epi8(_mm256_setzero_si256(), uppercase_mask, is_lowercase)\n        );\n        \n        // Store back to result\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(&result[i]), toggled_chars);\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_77_AVX", "completion": "```cpp\nstd::string solve_simd(const std::string & s) {\n    std::string result = s;\n    int len = s.length();\n    \n    // Process 32 bytes at a time using AVX2\n    int vectorLen = len - (len % 32);\n    for (int i = 0; i < vectorLen; i += 32) {\n        __m256i chars = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&s[i]));\n        \n        // Check for lowercase letters (a-z)\n        __m256i lowercaseMask = _mm256_and_si256(\n            _mm256_cmpgt_epi8(chars, _mm256_set1_epi8('a' - 1)),\n            _mm256_cmpgt_epi8(_mm256_set1_epi8('z' + 1), chars)\n        );\n        \n        // Check for uppercase letters (A-Z)\n        __m256i uppercaseMask = _mm256_and_si256(\n            _mm256_cmpgt_epi8(chars, _mm256_set1_epi8('A' - 1)),\n            _mm256_cmpgt_epi8(_mm256_set1_epi8('Z' + 1), chars)\n        );\n        \n        // Flip case for letters\n        __m256i caseDiff = _mm256_set1_epi8(32);\n        __m256i flippedChars = _mm256_xor_si256(chars, _mm256_and_si256(caseDiff, _mm256_or_si256(lowercaseMask, uppercaseMask)));\n        \n        // Store back to result\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(&result[i]), flippedChars);\n    }\n    \n    // Process remaining characters\n    for (int i = vectorLen; i < len; ++i) {\n        if (islower(s[i])) {\n            result[i] = toupper(s[i]);\n        } else if (isupper(s[i])) {\n            result[i] = tolower(s[i]);\n        }\n    }\n    \n    // If no letters found, reverse the string\n    bool hasLetters = false;\n    for (char c : s) {\n        if (isalpha(c)) {\n            hasLetters = true;\n            break;\n        }\n    }\n    \n    if (!hasLetters) {\n        std::reverse(result.begin(), result.end());\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_78_AVX", "completion": "```cpp\nstd::vector<int> sort_third_simd(std::vector<int> l) {\n    int n = l.size();\n    if (n <= 3) {\n        // Handle small vectors directly\n        std::vector<int> third_indices;\n        for (int i = 0; i < n; i += 3) {\n            third_indices.push_back(i);\n        }\n        \n        std::vector<int> to_sort;\n        for (int idx : third_indices) {\n            to_sort.push_back(l[idx]);\n        }\n        \n        std::sort(to_sort.begin(), to_sort.end());\n        \n        for (size_t i = 0; i < third_indices.size(); ++i) {\n            l[third_indices[i]] = to_sort[i];\n        }\n        \n        return l;\n    }\n    \n    // Align vector size to multiple of 8 for AVX\n    int aligned_size = ((n + 7) / 8) * 8;\n    l.resize(aligned_size, 0);\n    \n    // Create result vector\n    std::vector<int> result(aligned_size);\n    \n    // Process 8 elements at a time using AVX\n    for (int i = 0; i < aligned_size; i += 8) {\n        // Load 8 elements\n        __m256i vec = _mm256_loadu_si256((__m256i*)&l[i]);\n        \n        // Create mask for indices divisible by 3\n        __m256i indices = _mm256_set_epi32(\n            i+7, i+6, i+5, i+4, i+3, i+2, i+1, i\n        );\n        __m256i div_mask = _mm256_set1_epi32(3);\n        __m256i zero = _mm256_setzero_si256();\n        __m256i mod_result = _mm256_rem_epi32(indices, div_mask);\n        __m256i mask = _mm256_cmpeq_epi32(mod_result, zero);\n        \n        // Extract elements divisible by 3\n        __m256i third_elements = _mm256_and_si256(vec, mask);\n        \n        // Sort these elements\n        __m256i sorted = _mm256_sort_epi32(third_elements);\n        \n        // Blend sorted elements back\n        vec = _mm256_blendv_epi8(vec, sorted, mask);\n        \n        // Store result\n        _mm256_storeu_si256((__m256i*)&result[i], vec);\n    }\n    \n    // Trim result to original size\n    result.resize(n);\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_78_AVX", "completion": "```cpp\nstd::vector<int> sort_third_simd(std::vector<int> l) {\n    int n = l.size();\n    if (n <= 3) {\n        std::sort(l.begin(), l.end(), [](int a, int b) { return a < b; });\n        return l;\n    }\n\n    std::vector<int> result(l);\n    std::vector<int> to_sort;\n\n    // Collect elements at indices divisible by 3\n    for (int i = 0; i < n; i += 3) {\n        to_sort.push_back(l[i]);\n    }\n\n    // Sort the collected elements\n    std::sort(to_sort.begin(), to_sort.end());\n\n    // Replace elements at indices divisible by 3 with sorted values\n    int sort_idx = 0;\n    for (int i = 0; i < n; i += 3) {\n        result[i] = to_sort[sort_idx++];\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_78_AVX", "completion": "```cpp\nstd::vector<int> sort_third_simd(std::vector<int> l) {\n    int n = l.size();\n    if (n <= 3) {\n        // Handle small vectors directly\n        if (l[0] > l[2]) std::swap(l[0], l[2]);\n        return l;\n    }\n\n    // Prepare result vector\n    std::vector<int> result(l);\n\n    // Process in chunks of 8 integers using AVX2\n    for (int i = 0; i < n; i += 8) {\n        int chunk_size = std::min(8, n - i);\n        \n        // Create masks for indices divisible by 3\n        __m256i index_mask = _mm256_set_epi32(\n            (i+7) % 3 == 0 ? 0xFFFFFFFF : 0,\n            (i+6) % 3 == 0 ? 0xFFFFFFFF : 0,\n            (i+5) % 3 == 0 ? 0xFFFFFFFF : 0,\n            (i+4) % 3 == 0 ? 0xFFFFFFFF : 0,\n            (i+3) % 3 == 0 ? 0xFFFFFFFF : 0,\n            (i+2) % 3 == 0 ? 0xFFFFFFFF : 0,\n            (i+1) % 3 == 0 ? 0xFFFFFFFF : 0,\n            (i+0) % 3 == 0 ? 0xFFFFFFFF : 0\n        );\n\n        // Load current chunk\n        __m256i chunk = _mm256_loadu_si256((__m256i*)&l[i]);\n\n        // Sort indices divisible by 3\n        __m256i sorted_chunk = _mm256_sort_epi32(chunk, index_mask);\n\n        // Store back to result\n        _mm256_storeu_si256((__m256i*)&result[i], sorted_chunk);\n    }\n\n    return result;\n}\n\n// Custom AVX2 sorting function for indices divisible by 3\n__m256i _mm256_sort_epi32(__m256i input, __m256i mask) {\n    // Extract values at indices divisible by 3\n    __m256i divisible_indices = _mm256_and_si256(input, mask);\n    \n    // Sort these values\n    __m256i sorted = _mm256_sort_ps(divisible_indices);\n    \n    // Blend sorted values back into original vector\n    return _mm256_blendv_epi8(input, sorted, mask);\n}\n```"}
{"task_id": "SimdBench_78_AVX", "completion": "```cpp\nstd::vector<int> sort_third_simd(std::vector<int> l) {\n    int n = l.size();\n    if (n <= 3) {\n        std::sort(l.begin(), l.end(), [](int a, int b) { return a < b; });\n        return l;\n    }\n\n    std::vector<int> result(l);\n    std::vector<int> to_sort;\n\n    // Collect elements at indices divisible by 3\n    for (int i = 0; i < n; i += 3) {\n        to_sort.push_back(l[i]);\n    }\n\n    // Sort the collected elements\n    std::sort(to_sort.begin(), to_sort.end());\n\n    // Use AVX2 to efficiently replace elements divisible by 3\n    int sorted_idx = 0;\n    for (int i = 0; i < n; i += 16) {\n        __m256i indices = _mm256_setr_epi32(i, i+1, i+2, i+3, i+4, i+5, i+6, i+7);\n        __m256i indices2 = _mm256_setr_epi32(i+8, i+9, i+10, i+11, i+12, i+13, i+14, i+15);\n\n        // Create mask for indices divisible by 3\n        __m256i divisible_mask = _mm256_set1_epi32(0);\n        for (int j = 0; j < 8 && i+j < n; j++) {\n            if ((i+j) % 3 == 0) {\n                divisible_mask = _mm256_insert_epi32(divisible_mask, -1, j);\n            }\n        }\n\n        // Load original values\n        __m256i original_values = _mm256_loadu_si256((__m256i*)&l[i]);\n        \n        // Replace values at indices divisible by 3 with sorted values\n        __m256i sorted_values = _mm256_set1_epi32(0);\n        for (int j = 0; j < 8 && sorted_idx < to_sort.size(); j++) {\n            if ((i+j) % 3 == 0) {\n                sorted_values = _mm256_insert_epi32(sorted_values, to_sort[sorted_idx++], j);\n            }\n        }\n\n        // Blend original and sorted values\n        __m256i blended_values = _mm256_blendv_epi8(original_values, sorted_values, divisible_mask);\n\n        // Store back to result\n        _mm256_storeu_si256((__m256i*)&result[i], blended_values);\n\n        // Repeat for second half of 16-element block\n        divisible_mask = _mm256_set1_epi32(0);\n        for (int j = 0; j < 8 && i+j+8 < n; j++) {\n            if ((i+j+8) % 3 == 0) {\n                divisible_mask = _mm256_insert_epi32(divisible_mask, -1, j);\n            }\n        }\n\n        original_values = _mm256_loadu_si256((__m256i*)&l[i+8]);\n        \n        sorted_values = _mm256_set1_epi32(0);\n        for (int j = 0; j < 8 && sorted_idx < to_sort.size(); j++) {\n            if ((i+j+8) % 3 == 0) {\n                sorted_values = _mm256_insert_epi32(sorted_values, to_sort[sorted_idx++], j);\n            }\n        }\n\n        blended_values = _mm256_blendv_epi8(original_values, sorted_values, divisible_mask);\n        _mm256_storeu_si256((__m256i*)&result[i+8], blended_values);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_78_AVX", "completion": "```cpp\nstd::vector<int> sort_third_simd(std::vector<int> l) {\n    int n = l.size();\n    if (n <= 3) {\n        std::sort(l.begin(), l.end(), [](int a, int b) { return a < b; });\n        return l;\n    }\n\n    std::vector<int> result(l);\n    std::vector<int> to_sort;\n\n    // Collect elements at indices divisible by 3\n    for (int i = 0; i < n; i += 3) {\n        to_sort.push_back(l[i]);\n    }\n\n    // Sort the collected elements\n    std::sort(to_sort.begin(), to_sort.end());\n\n    // Replace elements at indices divisible by 3 with sorted values\n    int sort_idx = 0;\n    for (int i = 0; i < n; i += 3) {\n        result[i] = to_sort[sort_idx++];\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_79_AVX", "completion": "```cpp\nfloat max_element_simd(std::vector<float> l) {\n    int n = l.size();\n    int vector_size = 8; // AVX can process 8 floats at once\n    \n    // Handle small vectors\n    if (n < vector_size) {\n        return *std::max_element(l.begin(), l.end());\n    }\n    \n    // Initialize max vector with first 8 elements\n    __m256 max_vec = _mm256_loadu_ps(&l[0]);\n    \n    // Process 8 elements at a time\n    for (int i = vector_size; i <= n - vector_size; i += vector_size) {\n        __m256 current_vec = _mm256_loadu_ps(&l[i]);\n        max_vec = _mm256_max_ps(max_vec, current_vec);\n    }\n    \n    // Horizontal max within the vector\n    __m128 max_high = _mm256_extractf128_ps(max_vec, 1);\n    __m128 max_low = _mm256_castps256_ps128(max_vec);\n    max_low = _mm_max_ps(max_low, max_high);\n    max_low = _mm_max_ps(max_low, _mm_shuffle_ps(max_low, max_low, _MM_SHUFFLE(1, 0, 3, 2)));\n    max_low = _mm_max_ss(max_low, _mm_shuffle_ps(max_low, max_low, _MM_SHUFFLE(0, 1, 2, 3)));\n    \n    float max_val = _mm_cvtss_f32(max_low);\n    \n    // Handle remaining elements\n    for (int i = (n / vector_size) * vector_size; i < n; ++i) {\n        max_val = std::max(max_val, l[i]);\n    }\n    \n    return max_val;\n}\n```"}
{"task_id": "SimdBench_79_AVX", "completion": "```cpp\nfloat max_element_simd(std::vector<float> l) {\n    int n = l.size();\n    int vector_size = 8; // AVX can process 8 floats at a time\n    \n    // Handle small vectors\n    if (n < vector_size) {\n        return *std::max_element(l.begin(), l.end());\n    }\n    \n    // Initialize max vector with first 8 elements\n    __m256 max_vec = _mm256_loadu_ps(&l[0]);\n    \n    // Process vector in chunks of 8\n    for (int i = vector_size; i <= n - vector_size; i += vector_size) {\n        __m256 current_vec = _mm256_loadu_ps(&l[i]);\n        max_vec = _mm256_max_ps(max_vec, current_vec);\n    }\n    \n    // Horizontal max within the vector\n    __m128 max_high = _mm256_extractf128_ps(max_vec, 1);\n    __m128 max_low = _mm256_castps256_ps128(max_vec);\n    max_low = _mm_max_ps(max_low, max_high);\n    max_low = _mm_max_ps(max_low, _mm_shuffle_ps(max_low, max_low, _MM_SHUFFLE(1, 0, 3, 2)));\n    max_low = _mm_max_ss(max_low, _mm_shuffle_ps(max_low, max_low, _MM_SHUFFLE(0, 1, 2, 3)));\n    \n    float max_val = _mm_cvtss_f32(max_low);\n    \n    // Handle remaining elements\n    for (int i = (n / vector_size) * vector_size; i < n; ++i) {\n        max_val = std::max(max_val, l[i]);\n    }\n    \n    return max_val;\n}\n```"}
{"task_id": "SimdBench_79_AVX", "completion": "```cpp\nfloat max_element_simd(std::vector<float> l) {\n    int n = l.size();\n    int vector_size = 8; // AVX can process 8 floats at once\n    \n    // If vector is smaller than vector_size, fallback to standard max\n    if (n <= vector_size) {\n        return *std::max_element(l.begin(), l.end());\n    }\n    \n    // Initialize max vector with first 8 elements\n    __m256 max_vector = _mm256_loadu_ps(&l[0]);\n    \n    // Process vector in chunks of 8\n    for (int i = vector_size; i <= n - vector_size; i += vector_size) {\n        __m256 current_vector = _mm256_loadu_ps(&l[i]);\n        max_vector = _mm256_max_ps(max_vector, current_vector);\n    }\n    \n    // Horizontal max within the vector\n    __m128 high_128 = _mm256_extractf128_ps(max_vector, 1);\n    __m128 low_128 = _mm256_castps256_ps128(max_vector);\n    \n    low_128 = _mm_max_ps(low_128, high_128);\n    low_128 = _mm_max_ps(low_128, _mm_shuffle_ps(low_128, low_128, _MM_SHUFFLE(1, 0, 3, 2)));\n    low_128 = _mm_max_ss(low_128, _mm_shuffle_ps(low_128, low_128, _MM_SHUFFLE(0, 1, 2, 3)));\n    \n    float max_value = _mm_cvtss_f32(low_128);\n    \n    // Check remaining elements\n    for (int i = (n / vector_size) * vector_size; i < n; ++i) {\n        max_value = std::max(max_value, l[i]);\n    }\n    \n    return max_value;\n}\n```"}
{"task_id": "SimdBench_79_AVX", "completion": "```cpp\nfloat max_element_simd(std::vector<float> l) {\n    size_t n = l.size();\n    size_t vec_size = n - (n % 8);\n    \n    __m256 max_vec = _mm256_loadu_ps(l.data());\n    \n    for (size_t i = 8; i < vec_size; i += 8) {\n        __m256 curr_vec = _mm256_loadu_ps(l.data() + i);\n        max_vec = _mm256_max_ps(max_vec, curr_vec);\n    }\n    \n    float max_arr[8];\n    _mm256_storeu_ps(max_arr, max_vec);\n    \n    float max_val = max_arr[0];\n    for (int i = 1; i < 8; ++i) {\n        max_val = std::max(max_val, max_arr[i]);\n    }\n    \n    for (size_t i = vec_size; i < n; ++i) {\n        max_val = std::max(max_val, l[i]);\n    }\n    \n    return max_val;\n}\n```"}
{"task_id": "SimdBench_79_AVX", "completion": "```cpp\nfloat max_element_simd(std::vector<float> l) {\n    int n = l.size();\n    int vector_size = 8; // AVX can process 8 floats at once\n    \n    // Handle case where vector is smaller than vector width\n    if (n < vector_size) {\n        return *std::max_element(l.begin(), l.end());\n    }\n    \n    // Initialize max vector with first 8 elements\n    __m256 max_vector = _mm256_loadu_ps(&l[0]);\n    \n    // Process 8 elements at a time\n    for (int i = vector_size; i <= n - vector_size; i += vector_size) {\n        __m256 current_vector = _mm256_loadu_ps(&l[i]);\n        max_vector = _mm256_max_ps(max_vector, current_vector);\n    }\n    \n    // Horizontal max within the vector\n    __m128 max_high = _mm256_extractf128_ps(max_vector, 1);\n    __m128 max_low = _mm256_castps256_ps128(max_vector);\n    max_low = _mm_max_ps(max_low, max_high);\n    max_low = _mm_max_ps(max_low, _mm_shuffle_ps(max_low, max_low, _MM_SHUFFLE(1, 0, 3, 2)));\n    max_low = _mm_max_ss(max_low, _mm_shuffle_ps(max_low, max_low, _MM_SHUFFLE(0, 1, 2, 3)));\n    \n    float max_result = _mm_cvtss_f32(max_low);\n    \n    // Handle remaining elements\n    for (int i = (n / vector_size) * vector_size; i < n; ++i) {\n        max_result = std::max(max_result, l[i]);\n    }\n    \n    return max_result;\n}\n```"}
{"task_id": "SimdBench_80_AVX", "completion": "```cpp\nint fizz_buzz_simd(int n) {\n    int count = 0;\n    const int vector_width = 8; // AVX can process 8 32-bit integers simultaneously\n    \n    // Process in vectors of 8 integers\n    for (int i = 0; i < n; i += vector_width) {\n        __m256i indices = _mm256_set_epi32(\n            i+7, i+6, i+5, i+4, \n            i+3, i+2, i+1, i\n        );\n        \n        // Check divisibility by 11 or 13\n        __m256i div_mask_11 = _mm256_cmpeq_epi32(\n            _mm256_set1_epi32(0), \n            _mm256_set1_epi32(0)\n        );\n        __m256i div_mask_13 = _mm256_cmpeq_epi32(\n            _mm256_set1_epi32(0), \n            _mm256_set1_epi32(0)\n        );\n        \n        for (int j = 0; j < vector_width; j++) {\n            int val = i + j;\n            if (val >= n) break;\n            \n            if (val % 11 == 0 || val % 13 == 0) {\n                int digit_count = 0;\n                int temp = val;\n                while (temp > 0) {\n                    if (temp % 10 == 7) digit_count++;\n                    temp /= 10;\n                }\n                count += digit_count;\n            }\n        }\n    }\n    \n    return count;\n}\n```"}
{"task_id": "SimdBench_80_AVX", "completion": "```cpp\nint fizz_buzz_simd(int n) {\n    int count = 0;\n    \n    // Process 8 integers at a time using AVX2\n    for (int i = 0; i < n; i += 8) {\n        // Create vectors of 8 consecutive integers starting from i\n        __m256i indices = _mm256_set_epi32(\n            i + 7, i + 6, i + 5, i + 4, \n            i + 3, i + 2, i + 1, i\n        );\n        \n        // Check divisibility by 11 or 13\n        __m256i div11 = _mm256_setzero_si256();\n        __m256i div13 = _mm256_setzero_si256();\n        \n        for (int j = 0; j < 8; j++) {\n            int val = i + j;\n            if (val < n) {\n                if (val % 11 == 0 || val % 13 == 0) {\n                    div11 = _mm256_insert_epi32(div11, 1, j);\n                }\n            }\n        }\n        \n        // Count 7s in divisible numbers\n        for (int j = 0; j < 8; j++) {\n            int val = i + j;\n            if (val < n && (val % 11 == 0 || val % 13 == 0)) {\n                int digit_count = 0;\n                int temp = val;\n                while (temp > 0) {\n                    if (temp % 10 == 7) {\n                        digit_count++;\n                    }\n                    temp /= 10;\n                }\n                count += digit_count;\n            }\n        }\n    }\n    \n    return count;\n}\n```"}
{"task_id": "SimdBench_80_AVX", "completion": "```cpp\nint fizz_buzz_simd(int n) {\n    int count = 0;\n    const int vector_width = 8; // AVX can process 8 32-bit integers simultaneously\n    \n    // Process in batches of 8 integers\n    for (int i = 0; i < n; i += vector_width) {\n        // Create vector of consecutive integers starting from i\n        __m256i indices = _mm256_set_epi32(\n            i+7, i+6, i+5, i+4, \n            i+3, i+2, i+1, i\n        );\n        \n        // Check divisibility by 11 or 13\n        __m256i div11 = _mm256_setzero_si256();\n        __m256i div13 = _mm256_setzero_si256();\n        \n        div11 = _mm256_cmpeq_epi32(_mm256_setzero_si256(), \n            _mm256_set1_epi32(11 == 0 ? 0 : (indices % _mm256_set1_epi32(11))));\n        \n        div13 = _mm256_cmpeq_epi32(_mm256_setzero_si256(), \n            _mm256_set1_epi32(13 == 0 ? 0 : (indices % _mm256_set1_epi32(13))));\n        \n        // Combine divisibility checks\n        __m256i divisible = _mm256_or_si256(div11, div13);\n        \n        // Convert integers to strings and count 7s\n        for (int j = 0; j < vector_width; j++) {\n            if (_mm256_movemask_epi8(divisible) & (1 << j)) {\n                int num = i + j;\n                if (num < n) {\n                    std::string s = std::to_string(num);\n                    count += std::count(s.begin(), s.end(), '7');\n                }\n            }\n        }\n    }\n    \n    return count;\n}\n```"}
{"task_id": "SimdBench_80_AVX", "completion": "```cpp\nint fizz_buzz_simd(int n) {\n    int count = 0;\n    \n    // Process 8 integers at a time using AVX2\n    __m256i seven_vec = _mm256_set1_epi32(7);\n    __m256i eleven_vec = _mm256_set1_epi32(11);\n    __m256i thirteen_vec = _mm256_set1_epi32(13);\n    \n    for (int i = 0; i < n; i += 8) {\n        __m256i current_vec = _mm256_setr_epi32(\n            i, i+1, i+2, i+3, i+4, i+5, i+6, i+7\n        );\n        \n        // Check divisibility by 11\n        __m256i div_eleven = _mm256_div_epi32(current_vec, eleven_vec);\n        __m256i mod_eleven = _mm256_sub_epi32(current_vec, _mm256_mullo_epi32(div_eleven, eleven_vec));\n        __m256i is_div_eleven = _mm256_cmpeq_epi32(mod_eleven, _mm256_setzero_si256());\n        \n        // Check divisibility by 13\n        __m256i div_thirteen = _mm256_div_epi32(current_vec, thirteen_vec);\n        __m256i mod_thirteen = _mm256_sub_epi32(current_vec, _mm256_mullo_epi32(div_thirteen, thirteen_vec));\n        __m256i is_div_thirteen = _mm256_cmpeq_epi32(mod_thirteen, _mm256_setzero_si256());\n        \n        // Combine divisibility conditions\n        __m256i divisible_mask = _mm256_or_si256(is_div_eleven, is_div_thirteen);\n        \n        // Count 7s in divisible numbers\n        for (int j = 0; j < 8 && i + j < n; j++) {\n            if (_mm256_movemask_epi8(divisible_mask) & (1 << (j * 4))) {\n                int num = i + j;\n                while (num > 0) {\n                    if (num % 10 == 7) {\n                        count++;\n                    }\n                    num /= 10;\n                }\n            }\n        }\n    }\n    \n    return count;\n}\n```"}
{"task_id": "SimdBench_80_AVX", "completion": "```cpp\nint fizz_buzz_simd(int n) {\n    int count = 0;\n    const int vector_width = 8;\n    \n    // Process in vectors of 8 integers\n    for (int i = 0; i < n; i += vector_width) {\n        __m256i indices = _mm256_set_epi32(\n            i + 7, i + 6, i + 5, i + 4, \n            i + 3, i + 2, i + 1, i\n        );\n        \n        // Check divisibility by 11 or 13\n        __m256i div_11 = _mm256_cmpeq_epi32(_mm256_set1_epi32(0), _mm256_set1_epi32(0));\n        __m256i div_13 = _mm256_cmpeq_epi32(_mm256_set1_epi32(0), _mm256_set1_epi32(0));\n        \n        for (int j = 0; j < vector_width; ++j) {\n            int val = _mm256_extract_epi32(indices, j);\n            if (val < n) {\n                div_11 = _mm256_insert_epi32(div_11, (val % 11 == 0), j);\n                div_13 = _mm256_insert_epi32(div_13, (val % 13 == 0), j);\n            } else {\n                div_11 = _mm256_insert_epi32(div_11, 0, j);\n                div_13 = _mm256_insert_epi32(div_13, 0, j);\n            }\n        }\n        \n        // Combine divisibility conditions\n        __m256i divisible = _mm256_or_si256(div_11, div_13);\n        \n        // Count 7s in divisible numbers\n        for (int j = 0; j < vector_width; ++j) {\n            int val = _mm256_extract_epi32(indices, j);\n            int div_flag = _mm256_extract_epi32(divisible, j);\n            \n            if (div_flag && val < n) {\n                int digit_count = 0;\n                int temp = val;\n                while (temp > 0) {\n                    if (temp % 10 == 7) digit_count++;\n                    temp /= 10;\n                }\n                count += digit_count;\n            }\n        }\n    }\n    \n    return count;\n}\n```"}
{"task_id": "SimdBench_81_AVX", "completion": "```cpp\nstd::vector<float> sort_even_simd(std::vector<float> l) {\n    int n = l.size();\n    if (n <= 1) return l;\n\n    // Ensure vector size is even\n    if (n % 2 != 0) l.push_back(0.0f);\n    n = l.size();\n\n    // Load even indices into a vector\n    __m256 even_vec = _mm256_setr_ps(\n        l[0], l[2], l[4], l[6], \n        l[8], l[10], l[12], l[14]\n    );\n\n    // Shuffle and compare to sort even indices\n    __m256 sorted_even = _mm256_sort_ps(even_vec);\n\n    // Create result vector, preserving odd indices\n    std::vector<float> result(n);\n    for (int i = 0; i < n; i += 2) {\n        result[i] = sorted_even[i/2];\n        result[i+1] = l[i+1];\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_81_AVX", "completion": "```cpp\nstd::vector<float> sort_even_simd(std::vector<float> l) {\n    int n = l.size();\n    if (n <= 1) return l;\n\n    // Ensure vector size is even\n    if (n % 2 != 0) l.push_back(0);\n    n = l.size();\n\n    // Create a copy to preserve odd indices\n    std::vector<float> result = l;\n\n    // Process 8 elements at a time using AVX\n    for (int i = 0; i < n; i += 8) {\n        // Load even indices into AVX register\n        __m256 even_values = _mm256_setr_ps(\n            l[i], l[i+2], l[i+4], l[i+6],\n            l[i+1], l[i+3], l[i+5], l[i+7]\n        );\n\n        // Sort the even values using bitonic sort\n        __m256 sorted = even_values;\n        \n        // Bitonic sort network for 8 elements\n        {\n            __m256 t;\n            // Stage 1\n            t = _mm256_min_ps(sorted, _mm256_shuffle_ps(sorted, sorted, _MM_SHUFFLE(1,0,3,2)));\n            sorted = _mm256_max_ps(sorted, _mm256_shuffle_ps(sorted, sorted, _MM_SHUFFLE(1,0,3,2)));\n            sorted = t;\n\n            // Stage 2\n            t = _mm256_min_ps(sorted, _mm256_shuffle_ps(sorted, sorted, _MM_SHUFFLE(2,3,0,1)));\n            sorted = _mm256_max_ps(sorted, _mm256_shuffle_ps(sorted, sorted, _MM_SHUFFLE(2,3,0,1)));\n            sorted = t;\n\n            // Stage 3\n            t = _mm256_min_ps(sorted, _mm256_permute2f128_ps(sorted, sorted, 1));\n            sorted = _mm256_max_ps(sorted, _mm256_permute2f128_ps(sorted, sorted, 1));\n            sorted = t;\n        }\n\n        // Store sorted even values back, preserving odd indices\n        result[i] = _mm256_cvtss_f32(sorted);\n        result[i+2] = _mm256_cvtss_f32(_mm256_shuffle_ps(sorted, sorted, _MM_SHUFFLE(1,1,1,1)));\n        result[i+4] = _mm256_cvtss_f32(_mm256_shuffle_ps(sorted, sorted, _MM_SHUFFLE(2,2,2,2)));\n        result[i+6] = _mm256_cvtss_f32(_mm256_shuffle_ps(sorted, sorted, _MM_SHUFFLE(3,3,3,3)));\n    }\n\n    // Remove extra element if original size was odd\n    if (l.size() != result.size()) result.pop_back();\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_81_AVX", "completion": "```cpp\nstd::vector<float> sort_even_simd(std::vector<float> l) {\n    int n = l.size();\n    if (n <= 1) return l;\n\n    // Ensure vector size is even\n    if (n % 2 != 0) l.push_back(0.0f);\n    n = l.size();\n\n    // Load even indices into AVX register\n    __m256 even_vec = _mm256_setr_ps(\n        l[0], l[2], l[4], l[6], \n        l[8], l[10], l[12], l[14]\n    );\n\n    // Perform bitonic sort on even indices\n    __m256 swap1 = _mm256_permute_ps(even_vec, _MM_SHUFFLE(1, 0, 3, 2));\n    __m256 min1 = _mm256_min_ps(even_vec, swap1);\n    __m256 max1 = _mm256_max_ps(even_vec, swap1);\n    \n    __m256 swap2 = _mm256_permute_ps(min1, _MM_SHUFFLE(2, 3, 0, 1));\n    __m256 min2 = _mm256_min_ps(min1, swap2);\n    __m256 max2 = _mm256_max_ps(min1, swap2);\n    \n    __m256 swap3 = _mm256_permute_ps(min2, _MM_SHUFFLE(1, 0, 3, 2));\n    __m256 sorted_even = _mm256_min_ps(min2, swap3);\n\n    // Store back into original vector, preserving odd indices\n    std::vector<float> result(n);\n    for (int i = 0; i < n; i += 2) {\n        result[i] = sorted_even[i/2];\n        result[i+1] = l[i+1];\n    }\n\n    // Remove extra element if original vector was odd\n    if (l.size() != result.size()) result.pop_back();\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_81_AVX", "completion": "```cpp\nstd::vector<float> sort_even_simd(std::vector<float> l) {\n    int n = l.size();\n    if (n <= 1) return l;\n\n    // Ensure even-sized vector for SIMD processing\n    if (n % 2 != 0) l.push_back(0.0f);\n    n = l.size();\n\n    std::vector<float> result(n);\n    \n    // Process 8 floats at a time with AVX\n    for (int i = 0; i < n; i += 8) {\n        // Load even indices values\n        __m256 even_vals = _mm256_setr_ps(\n            l[i], l[i+2], l[i+4], l[i+6],\n            l[i+1], l[i+3], l[i+5], l[i+7]\n        );\n\n        // Sort even indices values using bitonic sort\n        __m256 sorted = _mm256_sort_ps(even_vals);\n\n        // Restore odd indices from original vector\n        __m256 result_vec = _mm256_setr_ps(\n            sorted[0], l[i+1], \n            sorted[1], l[i+3], \n            sorted[2], l[i+5], \n            sorted[3], l[i+7]\n        );\n\n        // Store result back\n        _mm256_storeu_ps(&result[i], result_vec);\n    }\n\n    // Remove extra element if original vector was odd-sized\n    if (l.size() != n) result.pop_back();\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_81_AVX", "completion": "```cpp\nstd::vector<float> sort_even_simd(std::vector<float> l) {\n    int n = l.size();\n    if (n <= 1) return l;\n\n    // Align input to 32-byte boundary for AVX\n    alignas(32) std::vector<float> result(l);\n\n    // Process even indices\n    for (int i = 0; i < n; i += 8) {\n        int remaining = std::min(8, n - i);\n        \n        // Load 8 floats \n        __m256 vec = _mm256_loadu_ps(&result[i]);\n        \n        // Shuffle to extract even indices\n        __m256 even_indices = _mm256_shuffle_ps(vec, vec, _MM_SHUFFLE(2, 0, 2, 0));\n        \n        // Sort even indices\n        __m256 sorted_even = _mm256_sort_ps(even_indices);\n        \n        // Blend back with original odd indices\n        __m256 blended = _mm256_blend_ps(sorted_even, vec, 0b10101010);\n        \n        // Store back\n        _mm256_storeu_ps(&result[i], blended);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_82_AVX", "completion": "```cpp\nbool triples_sum_to_zero_simd(std::vector<int> l) {\n    int n = l.size();\n    if (n < 3) return false;\n\n    // Sort the vector first\n    std::sort(l.begin(), l.end());\n\n    // Use AVX2 for parallel processing\n    for (int i = 0; i < n - 2; i++) {\n        int left = i + 1;\n        int right = n - 1;\n\n        // Use AVX2 to load and process multiple elements simultaneously\n        while (left < right) {\n            __m256i a_vec = _mm256_set1_epi32(l[i]);\n            __m256i left_vec = _mm256_loadu_si256((__m256i*)&l[left]);\n            __m256i right_vec = _mm256_loadu_si256((__m256i*)&l[right]);\n\n            // Compute sum of current elements\n            __m256i sum_vec = _mm256_add_epi32(a_vec, _mm256_add_epi32(left_vec, right_vec));\n            \n            // Check if sum is zero\n            __m256i zero_vec = _mm256_setzero_si256();\n            __m256i cmp_vec = _mm256_cmpeq_epi32(sum_vec, zero_vec);\n            \n            if (_mm256_movemask_epi8(cmp_vec)) {\n                return true;\n            }\n\n            // Adjust pointers based on sum comparison\n            int current_sum = l[i] + l[left] + l[right];\n            if (current_sum < 0) {\n                left++;\n            } else if (current_sum > 0) {\n                right--;\n            } else {\n                return true;\n            }\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_82_AVX", "completion": "```cpp\nbool triples_sum_to_zero_simd(std::vector<int> l) {\n    int n = l.size();\n    if (n < 3) return false;\n\n    // Sort the vector first\n    std::sort(l.begin(), l.end());\n\n    // Use AVX2 for parallel processing\n    for (int i = 0; i < n - 2; i++) {\n        int left = i + 1;\n        int right = n - 1;\n\n        // Vectorize the two-pointer search\n        while (left < right) {\n            __m256i a_vec = _mm256_set1_epi32(l[i]);\n            __m256i left_vec = _mm256_set1_epi32(l[left]);\n            __m256i right_vec = _mm256_set1_epi32(l[right]);\n\n            int sum = l[i] + l[left] + l[right];\n\n            if (sum == 0) return true;\n            else if (sum < 0) left++;\n            else right--;\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_82_AVX", "completion": "```cpp\nbool triples_sum_to_zero_simd(std::vector<int> l) {\n    int n = l.size();\n    if (n < 3) return false;\n\n    // Sort the vector first\n    std::sort(l.begin(), l.end());\n\n    // Use AVX2 for parallel processing\n    for (int i = 0; i < n - 2; i++) {\n        int left = i + 1;\n        int right = n - 1;\n\n        // Vectorized search for complementary pair\n        while (left < right) {\n            int sum = l[i] + l[left] + l[right];\n\n            if (sum == 0) return true;\n            else if (sum < 0) left++;\n            else right--;\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_82_AVX", "completion": "```cpp\nbool triples_sum_to_zero_simd(std::vector<int> l) {\n    int n = l.size();\n    if (n < 3) return false;\n\n    // Sort the vector first\n    std::sort(l.begin(), l.end());\n\n    // Use AVX2 for parallel processing\n    for (int i = 0; i < n - 2; i++) {\n        int left = i + 1;\n        int right = n - 1;\n\n        // Use AVX2 to load and process multiple elements simultaneously\n        __m256i target_vec = _mm256_set1_epi32(-l[i]);\n\n        while (left < right) {\n            __m256i left_vec = _mm256_loadu_si256((__m256i*)&l[left]);\n            __m256i right_vec = _mm256_loadu_si256((__m256i*)&l[right - 7]);\n\n            __m256i sum_vec = _mm256_add_epi32(left_vec, right_vec);\n            __m256i compare_vec = _mm256_cmpeq_epi32(sum_vec, target_vec);\n\n            if (_mm256_movemask_epi8(compare_vec) != 0) {\n                return true;\n            }\n\n            int sum = l[left] + l[right];\n            if (sum == -l[i]) return true;\n            else if (sum < -l[i]) left++;\n            else right--;\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_82_AVX", "completion": "```cpp\nbool triples_sum_to_zero_simd(std::vector<int> l) {\n    int n = l.size();\n    if (n < 3) return false;\n\n    // Sort the vector first for efficient searching\n    std::sort(l.begin(), l.end());\n\n    // Process vector in chunks of 8 using AVX2\n    for (int i = 0; i < n - 2; i++) {\n        int left = i + 1;\n        int right = n - 1;\n\n        while (left < right) {\n            int sum = l[i] + l[left] + l[right];\n\n            if (sum == 0) return true;\n            else if (sum < 0) left++;\n            else right--;\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_83_AVX", "completion": "```cpp\nstd::vector<int> incr_list_simd(std::vector<int> l) {\n    size_t n = l.size();\n    size_t vec_size = n - (n % 8);\n\n    for (size_t i = 0; i < vec_size; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&l[i]);\n        __m256i incremented = _mm256_add_epi32(vec, _mm256_set1_epi32(1));\n        _mm256_storeu_si256((__m256i*)&l[i], incremented);\n    }\n\n    for (size_t i = vec_size; i < n; ++i) {\n        l[i]++;\n    }\n\n    return l;\n}\n```"}
{"task_id": "SimdBench_83_AVX", "completion": "```cpp\nstd::vector<int> incr_list_simd(std::vector<int> l) {\n    size_t n = l.size();\n    size_t vec_size = n - (n % 8);\n\n    for (size_t i = 0; i < vec_size; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&l[i]);\n        __m256i incremented = _mm256_add_epi32(vec, _mm256_set1_epi32(1));\n        _mm256_storeu_si256((__m256i*)&l[i], incremented);\n    }\n\n    for (size_t i = vec_size; i < n; i++) {\n        l[i]++;\n    }\n\n    return l;\n}\n```"}
{"task_id": "SimdBench_83_AVX", "completion": "```cpp\nstd::vector<int> incr_list_simd(std::vector<int> l) {\n    size_t n = l.size();\n    size_t vector_size = 8; // AVX can process 8 integers at once\n    \n    // Process vectors in chunks of 8\n    for (size_t i = 0; i < n; i += vector_size) {\n        size_t remaining = std::min(vector_size, n - i);\n        \n        if (remaining == vector_size) {\n            // Full vector processing\n            __m256i vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&l[i]));\n            __m256i one_vec = _mm256_set1_epi32(1);\n            __m256i result_vec = _mm256_add_epi32(vec, one_vec);\n            _mm256_storeu_si256(reinterpret_cast<__m256i*>(&l[i]), result_vec);\n        } else {\n            // Handle remaining elements\n            for (size_t j = i; j < i + remaining; ++j) {\n                l[j]++;\n            }\n        }\n    }\n    \n    return l;\n}\n```"}
{"task_id": "SimdBench_83_AVX", "completion": "```cpp\nstd::vector<int> incr_list_simd(std::vector<int> l) {\n    int n = l.size();\n    int vector_size = 8; // AVX can process 8 integers at a time\n    \n    // Process vectors in chunks of 8\n    for (int i = 0; i <= n - vector_size; i += vector_size) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&l[i]);\n        __m256i one_vec = _mm256_set1_epi32(1);\n        __m256i result_vec = _mm256_add_epi32(vec, one_vec);\n        _mm256_storeu_si256((__m256i*)&l[i], result_vec);\n    }\n    \n    // Handle remaining elements\n    for (int i = (n / vector_size) * vector_size; i < n; i++) {\n        l[i]++;\n    }\n    \n    return l;\n}\n```"}
{"task_id": "SimdBench_83_AVX", "completion": "```cpp\nstd::vector<int> incr_list_simd(std::vector<int> l) {\n    size_t n = l.size();\n    size_t vec_size = n - (n % 8);  // Process 8 integers at a time with AVX2\n\n    // Process 8 elements at a time using AVX2\n    for (size_t i = 0; i < vec_size; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&l[i]);\n        __m256i incremented = _mm256_add_epi32(vec, _mm256_set1_epi32(1));\n        _mm256_storeu_si256((__m256i*)&l[i], incremented);\n    }\n\n    // Handle remaining elements\n    for (size_t i = vec_size; i < n; ++i) {\n        l[i]++;\n    }\n\n    return l;\n}\n```"}
{"task_id": "SimdBench_84_AVX", "completion": "```cpp\nbool pairs_sum_to_zero_simd(std::vector<int> l) {\n    int n = l.size();\n    if (n < 2) return false;\n\n    for (int i = 0; i < n - 8; i += 8) {\n        __m256i current_vec = _mm256_loadu_si256((__m256i*)&l[i]);\n        \n        for (int j = i + 8; j < n; j += 8) {\n            __m256i compare_vec = _mm256_loadu_si256((__m256i*)&l[j]);\n            \n            for (int k = 0; k < 8; k++) {\n                __m256i negated_current = _mm256_sub_epi32(_mm256_setzero_si256(), current_vec);\n                __m256i match_vec = _mm256_cmpeq_epi32(compare_vec, negated_current);\n                \n                if (_mm256_movemask_epi8(match_vec) != 0) {\n                    return true;\n                }\n                \n                current_vec = _mm256_shuffle_epi32(current_vec, _MM_SHUFFLE(0, 3, 2, 1));\n            }\n        }\n    }\n    \n    // Handle remaining elements\n    for (int i = 0; i < n; i++) {\n        for (int j = i + 1; j < n; j++) {\n            if (l[i] + l[j] == 0) {\n                return true;\n            }\n        }\n    }\n    \n    return false;\n}\n```"}
{"task_id": "SimdBench_84_AVX", "completion": "```cpp\nbool pairs_sum_to_zero_simd(std::vector<int> l) {\n    int n = l.size();\n    \n    // If vector is too small, return false\n    if (n < 2) return false;\n    \n    // Process vector in chunks of 8 integers using AVX2\n    for (int i = 0; i < n; i += 8) {\n        // Load current chunk\n        __m256i current = _mm256_loadu_si256((__m256i*)&l[i]);\n        \n        // Compare remaining elements\n        for (int j = i + 8; j < n; j++) {\n            // Create broadcast vector with current element from remaining part\n            __m256i target = _mm256_set1_epi32(-l[j]);\n            \n            // Compare current chunk with negated target\n            __m256i compare = _mm256_cmpeq_epi32(current, target);\n            \n            // Check if any element matches\n            if (_mm256_movemask_epi8(compare) != 0) {\n                return true;\n            }\n        }\n    }\n    \n    // Handle remaining elements if vector size is not multiple of 8\n    for (int i = 0; i < n; i++) {\n        for (int j = i + 1; j < n; j++) {\n            if (l[i] + l[j] == 0) {\n                return true;\n            }\n        }\n    }\n    \n    return false;\n}\n```"}
{"task_id": "SimdBench_84_AVX", "completion": "```cpp\nbool pairs_sum_to_zero_simd(std::vector<int> l) {\n    int n = l.size();\n    if (n < 2) return false;\n\n    for (int i = 0; i < n - 8; i += 8) {\n        __m256i current_vec = _mm256_loadu_si256((__m256i*)&l[i]);\n        \n        for (int j = i + 8; j < n; j += 8) {\n            __m256i compare_vec = _mm256_loadu_si256((__m256i*)&l[j]);\n            \n            // Negate compare_vec to check for zero sum\n            __m256i negated_vec = _mm256_sub_epi32(_mm256_setzero_si256(), compare_vec);\n            \n            // Compare current_vec with negated_vec\n            __m256i cmp_result = _mm256_cmpeq_epi32(current_vec, negated_vec);\n            \n            // Check if any elements match\n            if (!_mm256_testz_si256(cmp_result, cmp_result)) {\n                return true;\n            }\n        }\n    }\n\n    // Handle remaining elements\n    for (int i = 0; i < n; i++) {\n        for (int j = i + 1; j < n; j++) {\n            if (l[i] + l[j] == 0) {\n                return true;\n            }\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_84_AVX", "completion": "```cpp\nbool pairs_sum_to_zero_simd(std::vector<int> l) {\n    int n = l.size();\n    \n    // If vector is too small, return false\n    if (n < 2) return false;\n    \n    // Process 8 integers at a time using AVX\n    for (int i = 0; i < n; i += 8) {\n        // Load current block of 8 integers\n        __m256i current_block = _mm256_loadu_si256((__m256i*)&l[i]);\n        \n        // Compare remaining elements\n        for (int j = i + 8; j < n; j++) {\n            // Broadcast the current element to all lanes\n            __m256i target = _mm256_set1_epi32(-l[j]);\n            \n            // Compare current block with negated target\n            __m256i compare = _mm256_cmpeq_epi32(current_block, target);\n            \n            // Check if any element matches\n            if (_mm256_movemask_epi8(compare) != 0) {\n                return true;\n            }\n        }\n    }\n    \n    // Handle remaining elements if vector size is not multiple of 8\n    for (int i = 0; i < n; i++) {\n        for (int j = i + 1; j < n; j++) {\n            if (l[i] + l[j] == 0) {\n                return true;\n            }\n        }\n    }\n    \n    return false;\n}\n```"}
{"task_id": "SimdBench_84_AVX", "completion": "```cpp\nbool pairs_sum_to_zero_simd(std::vector<int> l) {\n    int n = l.size();\n    if (n < 2) return false;\n\n    for (int i = 0; i < n; i += 8) {\n        __m256i current = _mm256_loadu_si256((__m256i*)&l[i]);\n        \n        for (int j = i + 1; j < n; j += 8) {\n            __m256i compare = _mm256_loadu_si256((__m256i*)&l[j]);\n            __m256i negated = _mm256_sub_epi32(_mm256_setzero_si256(), current);\n            \n            __m256i matches = _mm256_cmpeq_epi32(compare, negated);\n            int mask = _mm256_movemask_ps((__m256)matches);\n            \n            if (mask) return true;\n        }\n    }\n    \n    return false;\n}\n```"}
{"task_id": "SimdBench_85_AVX", "completion": "```cpp\nstd::string change_base_simd(int64_t x, int8_t base) {\n    if (x == 0) return \"0\";\n    \n    char buffer[65];  // Max 64-bit number + null terminator\n    int idx = 64;\n    buffer[idx] = '\\0';\n    \n    // Use AVX2 for parallel division and remainder calculation\n    while (x > 0) {\n        __m256i dividend = _mm256_set1_epi64x(x);\n        __m256i divisor = _mm256_set1_epi64x(base);\n        \n        __m256i quotient = _mm256_div_epi64(dividend, divisor);\n        __m256i remainder = _mm256_sub_epi64(dividend, _mm256_mul_epi64(quotient, divisor));\n        \n        int rem = _mm256_extract_epi64(remainder, 0);\n        buffer[--idx] = '0' + rem;\n        \n        x = _mm256_extract_epi64(quotient, 0);\n    }\n    \n    return std::string(buffer + idx);\n}\n```"}
{"task_id": "SimdBench_85_AVX", "completion": "```cpp\nstd::string change_base_simd(int64_t x, int8_t base) {\n    if (x == 0) return \"0\";\n    \n    char result[64];\n    int idx = 63;\n    result[idx] = '\\0';\n    \n    __m256i x_vec = _mm256_set1_epi64x(x);\n    __m256i base_vec = _mm256_set1_epi64x(base);\n    __m256i zero_vec = _mm256_setzero_si256();\n    \n    while (x > 0) {\n        __m256i remainder = _mm256_rem_epi64(x_vec, base_vec);\n        result[--idx] = '0' + _mm256_cvtsi256_si32(remainder);\n        x_vec = _mm256_div_epi64(x_vec, base_vec);\n        x = _mm256_cvtsi256_si32(x_vec);\n    }\n    \n    return std::string(result + idx);\n}\n```"}
{"task_id": "SimdBench_85_AVX", "completion": "```cpp\nstd::string change_base_simd(int64_t x, int8_t base) {\n    if (x == 0) return \"0\";\n    \n    char digits[64];\n    int idx = 63;\n    digits[idx] = '\\0';\n    \n    // Use AVX2 to parallelize division and remainder operations\n    __m256i x_vec = _mm256_set1_epi64x(x);\n    __m256i base_vec = _mm256_set1_epi64x(base);\n    __m256i zero_vec = _mm256_setzero_si256();\n    \n    while (x > 0) {\n        idx--;\n        digits[idx] = '0' + (x % base);\n        x /= base;\n    }\n    \n    return std::string(digits + idx);\n}\n```"}
{"task_id": "SimdBench_85_AVX", "completion": "```cpp\nstd::string change_base_simd(int64_t x, int8_t base) {\n    if (x == 0) return \"0\";\n    \n    char result[64];\n    int idx = 63;\n    result[idx] = '\\0';\n    \n    __m256i x_vec = _mm256_set1_epi64x(x);\n    __m256i base_vec = _mm256_set1_epi64x(base);\n    __m256i zero_vec = _mm256_setzero_si256();\n    \n    while (x > 0) {\n        __m256i remainder = _mm256_rem_epi64(x_vec, base_vec);\n        char digit = _mm256_cvtsi256_si32(remainder) + '0';\n        \n        result[--idx] = digit;\n        x_vec = _mm256_div_epi64(x_vec, base_vec);\n        \n        x = _mm256_cvtsi256_si32(x_vec);\n    }\n    \n    return std::string(result + idx);\n}\n```"}
{"task_id": "SimdBench_85_AVX", "completion": "```cpp\nstd::string change_base_simd(int64_t x, int8_t base) {\n    if (base < 2 || base > 9) return \"\";\n    \n    char result[64];\n    int idx = 63;\n    result[idx] = '\\0';\n    \n    __m256i x_vec = _mm256_set1_epi64x(x);\n    __m256i base_vec = _mm256_set1_epi64x(base);\n    __m256i zero_vec = _mm256_setzero_si256();\n    \n    while (_mm256_movemask_epi8(_mm256_cmpgt_epi64(x_vec, zero_vec))) {\n        __m256i remainder = _mm256_rem_epi64(x_vec, base_vec);\n        x_vec = _mm256_div_epi64(x_vec, base_vec);\n        \n        int64_t rem = _mm256_extract_epi64(remainder, 0);\n        result[--idx] = '0' + rem;\n    }\n    \n    return std::string(result + idx);\n}\n```"}
{"task_id": "SimdBench_86_AVX", "completion": "```cpp\nbool is_palindrome_simd(std::string text) {\n    int len = text.length();\n    if (len <= 1) return true;\n\n    int vec_len = len / 32 * 32;\n    int remaining = len % 32;\n\n    // Load first and last halves\n    __m256i* first_half = (__m256i*)text.data();\n    __m256i* last_half = (__m256i*)(text.data() + len - 32);\n\n    for (int i = 0; i < vec_len / 32; i++) {\n        __m256i vec1 = _mm256_loadu_si256(first_half + i);\n        __m256i vec2 = _mm256_loadu_si256(last_half - i);\n        vec2 = _mm256_shuffle_epi8(vec2, _mm256_setr_epi8(\n            31, 30, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16,\n            15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 0\n        ));\n\n        __m256i cmp = _mm256_cmpeq_epi8(vec1, vec2);\n        if (_mm256_movemask_epi8(cmp) != 0xFFFFFFFF) {\n            return false;\n        }\n    }\n\n    // Handle remaining characters\n    for (int i = vec_len; i < len / 2; i++) {\n        if (text[i] != text[len - 1 - i]) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_86_AVX", "completion": "```cpp\nbool is_palindrome_simd(std::string text) {\n    int len = text.length();\n    if (len <= 1) return true;\n\n    int vec_len = len / 32 * 32;\n    int remaining = len % 32;\n\n    // Process 32-byte chunks using AVX\n    for (int i = 0; i < vec_len; i += 32) {\n        __m256i left = _mm256_loadu_si256((__m256i*)&text[i]);\n        __m256i right = _mm256_loadu_si256((__m256i*)&text[len - i - 32]);\n        \n        // Reverse bytes in right vector\n        right = _mm256_shuffle_epi8(right, _mm256_setr_epi8(\n            31, 30, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16,\n            15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 0\n        ));\n\n        // Compare vectors\n        __m256i cmp = _mm256_cmpeq_epi8(left, right);\n        if (_mm256_movemask_epi8(cmp) != 0xFFFFFFFF) {\n            return false;\n        }\n    }\n\n    // Handle remaining bytes\n    for (int i = 0; i < remaining; ++i) {\n        if (text[vec_len + i] != text[len - 1 - vec_len - i]) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_86_AVX", "completion": "```cpp\nbool is_palindrome_simd(std::string text) {\n    int len = text.length();\n    if (len <= 1) return true;\n\n    int vec_len = len / 32 * 32;\n    int remaining = len % 32;\n\n    // Process 32-byte chunks using AVX2\n    for (int i = 0; i < vec_len; i += 32) {\n        __m256i left = _mm256_loadu_si256((__m256i*)&text[i]);\n        __m256i right = _mm256_loadu_si256((__m256i*)&text[len - i - 32]);\n        \n        left = _mm256_shuffle_epi8(left, _mm256_setr_epi8(\n            31, 30, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16,\n            15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 0\n        ));\n        \n        __m256i cmp = _mm256_cmpeq_epi8(left, right);\n        if (_mm256_movemask_epi8(cmp) != 0xFFFFFFFF) {\n            return false;\n        }\n    }\n\n    // Handle remaining characters\n    for (int i = 0; i < remaining; i++) {\n        if (text[vec_len + i] != text[len - vec_len - i - 1]) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_86_AVX", "completion": "```cpp\nbool is_palindrome_simd(std::string text) {\n    int len = text.length();\n    if (len <= 1) return true;\n\n    int vec_len = len / 32 * 32;\n    int remaining = len % 32;\n\n    // Process 32-byte chunks using AVX\n    for (int i = 0; i < vec_len; i += 32) {\n        __m256i left = _mm256_loadu_si256((__m256i*)&text[i]);\n        __m256i right = _mm256_loadu_si256((__m256i*)&text[len - i - 32]);\n        \n        // Reverse bytes in each 32-byte vector\n        left = _mm256_shuffle_epi8(left, _mm256_setr_epi8(\n            31, 30, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16,\n            15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 0\n        ));\n        \n        // Compare vectors\n        __m256i cmp = _mm256_cmpeq_epi8(left, right);\n        if (_mm256_movemask_epi8(cmp) != 0xFFFFFFFF) {\n            return false;\n        }\n    }\n\n    // Handle remaining characters\n    for (int i = 0; i < remaining; ++i) {\n        if (text[vec_len + i] != text[len - vec_len - i - 1]) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_86_AVX", "completion": "```cpp\nbool is_palindrome_simd(std::string text) {\n    int len = text.length();\n    if (len <= 1) return true;\n\n    int vec_len = len / 32 * 32;\n    int remaining = len % 32;\n\n    // Process 32-byte chunks using AVX2\n    for (int i = 0; i < vec_len; i += 32) {\n        __m256i left = _mm256_loadu_si256((__m256i*)&text[i]);\n        __m256i right = _mm256_loadu_si256((__m256i*)&text[len - i - 32]);\n        \n        // Reverse byte order for right vector\n        right = _mm256_shuffle_epi8(right, _mm256_setr_epi8(\n            31, 30, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16,\n            15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 0\n        ));\n\n        // Compare bytes\n        __m256i cmp = _mm256_cmpeq_epi8(left, right);\n        if (_mm256_movemask_epi8(cmp) != 0xFFFFFFFF) {\n            return false;\n        }\n    }\n\n    // Handle remaining bytes\n    for (int i = 0; i < remaining; ++i) {\n        if (text[vec_len + i] != text[len - vec_len - i - 1]) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_87_AVX", "completion": "```cpp\nstd::string decode_shift_simd(std::string s) {\n    std::string out = s;\n    int len = s.length();\n    \n    // Process 16 characters at a time using AVX2\n    int vectorized_len = len - (len % 16);\n    for (int i = 0; i < vectorized_len; i += 16) {\n        __m256i chars = _mm256_loadu_si256((__m256i*)&s[i]);\n        \n        // Subtract 5 from each character\n        __m256i shift = _mm256_set1_epi8(-5);\n        __m256i shifted_chars = _mm256_add_epi8(chars, shift);\n        \n        // Handle wrap-around for characters below 'a'\n        __m256i a_val = _mm256_set1_epi8('a');\n        __m256i z_val = _mm256_set1_epi8('z');\n        \n        __m256i below_a_mask = _mm256_cmpgt_epi8(a_val, shifted_chars);\n        __m256i wrap_correction = _mm256_set1_epi8(26);\n        shifted_chars = _mm256_add_epi8(shifted_chars, \n            _mm256_and_si256(below_a_mask, wrap_correction));\n        \n        _mm256_storeu_si256((__m256i*)&out[i], shifted_chars);\n    }\n    \n    // Handle remaining characters sequentially\n    for (int i = vectorized_len; i < len; i++) {\n        int w = ((int)s[i] - 5 - (int)'a' + 26) % 26 + (int)'a';\n        out[i] = (char)w;\n    }\n    \n    return out;\n}\n```"}
{"task_id": "SimdBench_87_AVX", "completion": "```cpp\nstd::string decode_shift_simd(std::string s) {\n    std::string out = s;\n    int len = s.length();\n    \n    // Process 16 characters at a time using AVX2\n    int vectorized_len = len - (len % 16);\n    for (int i = 0; i < vectorized_len; i += 16) {\n        __m256i chars = _mm256_loadu_si256((__m256i*)&s[i]);\n        \n        // Subtract 5 and handle wrap-around\n        __m256i sub_5 = _mm256_sub_epi8(chars, _mm256_set1_epi8(5));\n        \n        // Check if character is less than 'a'\n        __m256i less_than_a = _mm256_cmpgt_epi8(_mm256_set1_epi8('a'), sub_5);\n        \n        // If less than 'a', wrap around by adding 26\n        __m256i wrapped = _mm256_add_epi8(sub_5, _mm256_and_si256(less_than_a, _mm256_set1_epi8(26)));\n        \n        _mm256_storeu_si256((__m256i*)&out[i], wrapped);\n    }\n    \n    // Handle remaining characters\n    for (int i = vectorized_len; i < len; i++) {\n        int w = ((int)s[i] - 5 - (int)'a' + 26) % 26 + (int)'a';\n        out[i] = (char)w;\n    }\n    \n    return out;\n}\n```"}
{"task_id": "SimdBench_87_AVX", "completion": "```cpp\nstd::string decode_shift_simd(std::string s) {\n    std::string out = s;\n    int len = s.length();\n    \n    // Process 16 characters at a time using AVX2\n    int vectorized_len = len - (len % 16);\n    for (int i = 0; i < vectorized_len; i += 16) {\n        __m256i chars = _mm256_loadu_si256((__m256i*)&s[i]);\n        \n        // Subtract 5 from each character\n        __m256i shift = _mm256_set1_epi8(-5);\n        __m256i shifted_chars = _mm256_add_epi8(chars, shift);\n        \n        // Wrap around for characters below 'a'\n        __m256i a_val = _mm256_set1_epi8('a');\n        __m256i z_val = _mm256_set1_epi8('z');\n        \n        __m256i below_a_mask = _mm256_cmpgt_epi8(a_val, shifted_chars);\n        __m256i wrap_correction = _mm256_set1_epi8(26);\n        shifted_chars = _mm256_add_epi8(shifted_chars, \n                        _mm256_and_si256(below_a_mask, wrap_correction));\n        \n        _mm256_storeu_si256((__m256i*)&out[i], shifted_chars);\n    }\n    \n    // Process remaining characters sequentially\n    for (int i = vectorized_len; i < len; i++) {\n        int w = ((int)s[i] - 5 - (int)'a' + 26) % 26 + (int)'a';\n        out[i] = (char)w;\n    }\n    \n    return out;\n}\n```"}
{"task_id": "SimdBench_87_AVX", "completion": "```cpp\nstd::string decode_shift_simd(std::string s) {\n    std::string out = s;\n    int len = s.length();\n    \n    // Process 16 characters at a time using AVX2\n    int vectorized_len = len - (len % 16);\n    \n    for (int i = 0; i < vectorized_len; i += 16) {\n        // Load 16 characters into AVX register\n        __m256i chars = _mm256_loadu_si256((__m256i*)&s[i]);\n        \n        // Subtract 5 from each character\n        __m256i shift = _mm256_set1_epi8(-5);\n        __m256i shifted_chars = _mm256_add_epi8(chars, shift);\n        \n        // Handle wrap-around for characters below 'a'\n        __m256i a_val = _mm256_set1_epi8('a');\n        __m256i z_val = _mm256_set1_epi8('z');\n        \n        __m256i below_a_mask = _mm256_cmpgt_epi8(a_val, shifted_chars);\n        __m256i wrap_correction = _mm256_set1_epi8(26);\n        \n        shifted_chars = _mm256_add_epi8(shifted_chars, \n                        _mm256_and_si256(below_a_mask, wrap_correction));\n        \n        // Store back to output string\n        _mm256_storeu_si256((__m256i*)&out[i], shifted_chars);\n    }\n    \n    // Handle remaining characters sequentially\n    for (int i = vectorized_len; i < len; i++) {\n        int w = ((int)s[i] - 5 - (int)'a' + 26) % 26 + (int)'a';\n        out[i] = (char)w;\n    }\n    \n    return out;\n}\n```"}
{"task_id": "SimdBench_87_AVX", "completion": "```cpp\nstd::string decode_shift_simd(std::string s) {\n    std::string out = s;\n    int len = s.length();\n    \n    // Process 16 characters at a time using AVX2\n    int vector_len = len - (len % 16);\n    for (int i = 0; i < vector_len; i += 16) {\n        __m256i chars = _mm256_loadu_si256((__m256i*)&s[i]);\n        \n        // Subtract 5 and adjust to wrap around alphabet\n        __m256i sub_5 = _mm256_sub_epi8(chars, _mm256_set1_epi8(5));\n        __m256i wrapped = _mm256_add_epi8(sub_5, _mm256_set1_epi8(26));\n        __m256i result = _mm256_min_epu8(wrapped, sub_5);\n        \n        _mm256_storeu_si256((__m256i*)&out[i], result);\n    }\n    \n    // Handle remaining characters sequentially\n    for (int i = vector_len; i < len; i++) {\n        int w = ((int)s[i] - 5 - (int)'a' + 26) % 26 + (int)'a';\n        out[i] = (char)w;\n    }\n    \n    return out;\n}\n```"}
{"task_id": "SimdBench_88_AVX", "completion": "```cpp\nbool below_threshold_simd(std::vector<int> l, int t) {\n    int n = l.size();\n    int vector_size = 8; // AVX can process 8 integers at a time\n    \n    // Process vectors of 8 integers\n    for (int i = 0; i <= n - vector_size; i += vector_size) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&l[i]);\n        __m256i threshold_vec = _mm256_set1_epi32(t);\n        __m256i comparison = _mm256_cmpgt_epi32(vec, threshold_vec);\n        \n        if (_mm256_movemask_epi8(comparison) != 0) {\n            return false;\n        }\n    }\n    \n    // Process remaining elements\n    for (int i = (n / vector_size) * vector_size; i < n; ++i) {\n        if (l[i] > t) {\n            return false;\n        }\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_88_AVX", "completion": "```cpp\nbool below_threshold_simd(std::vector<int> l, int t) {\n    int n = l.size();\n    int vector_size = 8; // AVX can process 8 integers at once\n    \n    // Process full vector chunks\n    for (int i = 0; i <= n - vector_size; i += vector_size) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&l[i]);\n        __m256i threshold_vec = _mm256_set1_epi32(t);\n        __m256i comparison = _mm256_cmpgt_epi32(vec, threshold_vec);\n        \n        if (_mm256_movemask_epi8(comparison) != 0) {\n            return false;\n        }\n    }\n    \n    // Process remaining elements\n    for (int i = (n / vector_size) * vector_size; i < n; ++i) {\n        if (l[i] > t) {\n            return false;\n        }\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_88_AVX", "completion": "```cpp\nbool below_threshold_simd(std::vector<int> l, int t) {\n    int n = l.size();\n    int vector_size = 8; // AVX can process 8 integers at once\n    \n    // Process vectors of 8 integers\n    for (int i = 0; i <= n - vector_size; i += vector_size) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&l[i]);\n        __m256i threshold_vec = _mm256_set1_epi32(t);\n        __m256i comparison = _mm256_cmpgt_epi32(vec, threshold_vec);\n        \n        if (_mm256_movemask_epi8(comparison) != 0) {\n            return false;\n        }\n    }\n    \n    // Handle remaining elements\n    for (int i = (n / vector_size) * vector_size; i < n; ++i) {\n        if (l[i] > t) {\n            return false;\n        }\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_88_AVX", "completion": "```cpp\nbool below_threshold_simd(std::vector<int> l, int t) {\n    int n = l.size();\n    int vector_size = 8; // AVX can process 8 integers at once\n    \n    // Process vectors of 8 integers\n    for (int i = 0; i <= n - vector_size; i += vector_size) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&l[i]);\n        __m256i threshold_vec = _mm256_set1_epi32(t);\n        __m256i comparison = _mm256_cmpgt_epi32(vec, threshold_vec);\n        \n        if (_mm256_movemask_epi8(comparison) != 0) {\n            return false;\n        }\n    }\n    \n    // Handle remaining elements\n    for (int i = (n / vector_size) * vector_size; i < n; ++i) {\n        if (l[i] > t) {\n            return false;\n        }\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_88_AVX", "completion": "```cpp\nbool below_threshold_simd(std::vector<int> l, int t) {\n    int n = l.size();\n    int vector_size = 8; // AVX can process 8 integers at once\n    \n    // Process vectors of 8 integers\n    for (int i = 0; i <= n - vector_size; i += vector_size) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&l[i]);\n        __m256i threshold_vec = _mm256_set1_epi32(t);\n        __m256i comparison = _mm256_cmpgt_epi32(vec, threshold_vec);\n        \n        if (_mm256_movemask_epi8(comparison) != 0) {\n            return false;\n        }\n    }\n    \n    // Handle remaining elements\n    for (int i = (n / vector_size) * vector_size; i < n; ++i) {\n        if (l[i] > t) {\n            return false;\n        }\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_89_AVX", "completion": "```cpp\nbool correct_bracketing_simd(std::string brackets) {\n    int len = brackets.length();\n    if (len == 0) return true;\n\n    // Align to 32-byte boundary for AVX\n    __m256i balance = _mm256_setzero_si256();\n    \n    // Process 32 characters at a time\n    int i = 0;\n    for (; i + 32 <= len; i += 32) {\n        __m256i chars = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&brackets[i]));\n        \n        // Create masks for '<' and '>'\n        __m256i less_than = _mm256_cmpeq_epi8(chars, _mm256_set1_epi8('<'));\n        __m256i greater_than = _mm256_cmpeq_epi8(chars, _mm256_set1_epi8('>'));\n        \n        // Accumulate balance\n        __m256i delta = _mm256_sub_epi8(less_than, greater_than);\n        balance = _mm256_add_epi8(balance, delta);\n    }\n\n    // Horizontal sum of balance\n    __m128i balance_low = _mm256_extracti128_si256(balance, 0);\n    __m128i balance_high = _mm256_extracti128_si256(balance, 1);\n    __m128i balance_combined = _mm_add_epi8(balance_low, balance_high);\n    \n    int8_t balance_array[16];\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(balance_array), balance_combined);\n    \n    int total_balance = 0;\n    for (int j = 0; j < 16; j++) {\n        total_balance += balance_array[j];\n    }\n\n    // Process remaining characters\n    for (; i < len; i++) {\n        total_balance += (brackets[i] == '<') ? 1 : -1;\n    }\n\n    return total_balance == 0;\n}\n```"}
{"task_id": "SimdBench_89_AVX", "completion": "```cpp\nbool correct_bracketing_simd(std::string brackets) {\n    int len = brackets.length();\n    if (len == 0) return true;\n\n    // Align to 32-byte boundary for AVX\n    __attribute__((aligned(32))) int running_sum[8] = {0};\n    int current_sum = 0;\n\n    // Process 8 elements at a time using AVX\n    int i;\n    for (i = 0; i + 8 <= len; i += 8) {\n        __m256i sum_vec = _mm256_setzero_si256();\n        \n        for (int j = 0; j < 8; j++) {\n            int val = (brackets[i + j] == '<') ? 1 : -1;\n            __m256i increment = _mm256_set1_epi32(val);\n            sum_vec = _mm256_add_epi32(sum_vec, increment);\n        }\n        \n        _mm256_store_si256((__m256i*)running_sum, sum_vec);\n        \n        for (int j = 0; j < 8; j++) {\n            current_sum += running_sum[j];\n            if (current_sum < 0) return false;\n        }\n    }\n\n    // Handle remaining elements\n    for (; i < len; i++) {\n        current_sum += (brackets[i] == '<') ? 1 : -1;\n        if (current_sum < 0) return false;\n    }\n\n    return current_sum == 0;\n}\n```"}
{"task_id": "SimdBench_89_AVX", "completion": "```cpp\nbool correct_bracketing_simd(std::string brackets) {\n    int len = brackets.length();\n    \n    // Process 32 characters at a time using AVX2\n    int vector_len = len - (len % 32);\n    __m256i open_count = _mm256_setzero_si256();\n    __m256i close_count = _mm256_setzero_si256();\n    \n    for (int i = 0; i < vector_len; i += 32) {\n        __m256i vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&brackets[i]));\n        \n        // Compare with '<'\n        __m256i is_open = _mm256_cmpeq_epi8(vec, _mm256_set1_epi8('<'));\n        \n        // Compare with '>'\n        __m256i is_close = _mm256_cmpeq_epi8(vec, _mm256_set1_epi8('>'));\n        \n        // Accumulate open and close counts\n        open_count = _mm256_add_epi8(open_count, is_open);\n        close_count = _mm256_add_epi8(close_count, is_close);\n    }\n    \n    // Horizontal sum of open and close counts\n    int open_total = 0, close_total = 0;\n    alignas(32) int open_array[32];\n    alignas(32) int close_array[32];\n    _mm256_store_si256(reinterpret_cast<__m256i*>(open_array), open_count);\n    _mm256_store_si256(reinterpret_cast<__m256i*>(close_array), close_count);\n    \n    for (int i = 0; i < 32; i++) {\n        open_total += open_array[i];\n        close_total += close_array[i];\n    }\n    \n    // Process remaining characters\n    for (int i = vector_len; i < len; i++) {\n        if (brackets[i] == '<') open_total++;\n        if (brackets[i] == '>') close_total++;\n    }\n    \n    // Check if total open and close counts are valid\n    int running_balance = 0;\n    for (int i = 0; i < len; i++) {\n        if (brackets[i] == '<') running_balance++;\n        else running_balance--;\n        \n        if (running_balance < 0) return false;\n    }\n    \n    return running_balance == 0;\n}\n```"}
{"task_id": "SimdBench_89_AVX", "completion": "```cpp\nbool correct_bracketing_simd(std::string brackets) {\n    int len = brackets.length();\n    if (len == 0) return true;\n\n    // Process 32 characters at a time using AVX2\n    int vector_len = len - (len % 32);\n    __m256i open_count = _mm256_setzero_si256();\n    __m256i close_count = _mm256_setzero_si256();\n\n    // Process 32-byte chunks\n    for (int i = 0; i < vector_len; i += 32) {\n        __m256i vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&brackets[i]));\n        \n        // Create masks for '<' and '>'\n        __m256i open_mask = _mm256_cmpeq_epi8(vec, _mm256_set1_epi8('<'));\n        __m256i close_mask = _mm256_cmpeq_epi8(vec, _mm256_set1_epi8('>'));\n        \n        // Count open and close brackets\n        open_count = _mm256_add_epi8(open_count, _mm256_and_si256(vec, open_mask));\n        close_count = _mm256_add_epi8(close_count, _mm256_and_si256(vec, close_mask));\n    }\n\n    // Horizontal sum of open and close counts\n    int open_sum = 0, close_sum = 0;\n    int open_arr[32], close_arr[32];\n    _mm256_storeu_si256(reinterpret_cast<__m256i*>(open_arr), open_count);\n    _mm256_storeu_si256(reinterpret_cast<__m256i*>(close_arr), close_count);\n\n    for (int i = 0; i < 32; i++) {\n        open_sum += (open_arr[i] == '<');\n        close_sum += (close_arr[i] == '>');\n    }\n\n    // Process remaining characters\n    for (int i = vector_len; i < len; i++) {\n        if (brackets[i] == '<') open_sum++;\n        if (brackets[i] == '>') close_sum++;\n    }\n\n    // Track running balance\n    int balance = 0;\n    for (int i = 0; i < len; i++) {\n        if (brackets[i] == '<') balance++;\n        else balance--;\n\n        if (balance < 0) return false;\n    }\n\n    return balance == 0;\n}\n```"}
{"task_id": "SimdBench_89_AVX", "completion": "```cpp\nbool correct_bracketing_simd(std::string brackets) {\n    int len = brackets.length();\n    \n    // Process 32 bytes at a time using AVX2\n    int vector_len = len - (len % 32);\n    __m256i balance = _mm256_setzero_si256();\n    \n    for (int i = 0; i < vector_len; i += 32) {\n        __m256i vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&brackets[i]));\n        \n        // Create masks for '<' and '>'\n        __m256i less_mask = _mm256_cmpeq_epi8(vec, _mm256_set1_epi8('<'));\n        __m256i greater_mask = _mm256_cmpeq_epi8(vec, _mm256_set1_epi8('>'));\n        \n        // Increment or decrement balance\n        __m256i increment = _mm256_sub_epi8(less_mask, greater_mask);\n        balance = _mm256_add_epi8(balance, increment);\n    }\n    \n    // Horizontal sum of balance vector\n    __m128i sum_low = _mm256_extracti128_si256(balance, 0);\n    __m128i sum_high = _mm256_extracti128_si256(balance, 1);\n    __m128i sum = _mm_add_epi8(sum_low, sum_high);\n    sum = _mm_hadd_epi8(sum, sum);\n    sum = _mm_hadd_epi8(sum, sum);\n    sum = _mm_hadd_epi8(sum, sum);\n    \n    int total_balance = _mm_cvtsi128_si32(sum) & 0xFF;\n    \n    // Process remaining characters\n    for (int i = vector_len; i < len; ++i) {\n        total_balance += (brackets[i] == '<') ? 1 : -1;\n    }\n    \n    return total_balance == 0;\n}\n```"}
{"task_id": "SimdBench_90_AVX", "completion": "```cpp\nbool correct_bracketing_simd(std::string brackets) {\n    int n = brackets.length();\n    if (n == 0) return true;\n    \n    // Process 32 characters at a time using AVX2\n    int vector_size = 32;\n    int processed_length = n - (n % vector_size);\n    \n    __m256i open_mask = _mm256_set1_epi8('(');\n    __m256i close_mask = _mm256_set1_epi8(')');\n    __m256i zero_mask = _mm256_setzero_si256();\n    \n    int balance = 0;\n    \n    // Process 32-byte chunks\n    for (int i = 0; i < processed_length; i += vector_size) {\n        __m256i chunk = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&brackets[i]));\n        \n        // Compare with '('\n        __m256i is_open = _mm256_cmpeq_epi8(chunk, open_mask);\n        \n        // Compare with ')'\n        __m256i is_close = _mm256_cmpeq_epi8(chunk, close_mask);\n        \n        // Count open and close brackets\n        int open_count = _mm256_movemask_epi8(is_open);\n        int close_count = _mm256_movemask_epi8(is_close);\n        \n        // Update balance\n        balance += __builtin_popcount(open_count) - __builtin_popcount(close_count);\n        \n        // Check if balance becomes negative\n        if (balance < 0) return false;\n    }\n    \n    // Process remaining characters\n    for (int i = processed_length; i < n; i++) {\n        if (brackets[i] == '(') balance++;\n        else balance--;\n        \n        if (balance < 0) return false;\n    }\n    \n    return balance == 0;\n}\n```"}
{"task_id": "SimdBench_90_AVX", "completion": "```cpp\nbool correct_bracketing_simd(std::string brackets) {\n    int n = brackets.length();\n    if (n == 0) return true;\n    \n    // Process 32 characters at a time using AVX2\n    int vec_size = 32;\n    int processed = 0;\n    int balance = 0;\n\n    // Process full 32-byte vectors\n    while (processed + vec_size <= n) {\n        __m256i open_mask = _mm256_set1_epi8('(');\n        __m256i close_mask = _mm256_set1_epi8(')');\n        \n        __m256i current_vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&brackets[processed]));\n        \n        __m256i is_open = _mm256_cmpeq_epi8(current_vec, open_mask);\n        __m256i is_close = _mm256_cmpeq_epi8(current_vec, close_mask);\n        \n        int open_mask_int = _mm256_movemask_epi8(is_open);\n        int close_mask_int = _mm256_movemask_epi8(is_close);\n        \n        balance += __builtin_popcount(open_mask_int) - __builtin_popcount(close_mask_int);\n        \n        if (balance < 0) return false;\n        \n        processed += vec_size;\n    }\n    \n    // Process remaining characters\n    for (int i = processed; i < n; ++i) {\n        balance += (brackets[i] == '(') ? 1 : -1;\n        if (balance < 0) return false;\n    }\n    \n    return balance == 0;\n}\n```"}
{"task_id": "SimdBench_90_AVX", "completion": "```cpp\nbool correct_bracketing_simd(std::string brackets) {\n    int n = brackets.length();\n    if (n == 0) return true;\n    \n    // Process 32 characters at a time using AVX2\n    int vec_size = 32;\n    int processed = 0;\n    int balance = 0;\n\n    // Process full 32-byte vectors\n    while (processed + vec_size <= n) {\n        __m256i vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&brackets[processed]));\n        \n        // Convert '(' to 1 and ')' to -1\n        __m256i open_mask = _mm256_cmpeq_epi8(vec, _mm256_set1_epi8('('));\n        __m256i close_mask = _mm256_cmpeq_epi8(vec, _mm256_set1_epi8(')'));\n        \n        __m256i converted = _mm256_sub_epi8(_mm256_blendv_epi8(_mm256_set1_epi8(-1), _mm256_set1_epi8(1), open_mask));\n        \n        // Horizontal sum of converted vector\n        __m128i low = _mm256_extracti128_si256(converted, 0);\n        __m128i high = _mm256_extracti128_si256(converted, 1);\n        \n        __m128i sum_128 = _mm_add_epi8(low, high);\n        sum_128 = _mm_hadd_epi8(sum_128, sum_128);\n        sum_128 = _mm_hadd_epi8(sum_128, sum_128);\n        sum_128 = _mm_hadd_epi8(sum_128, sum_128);\n        \n        balance += _mm_cvtsi128_si32(sum_128) & 0xFF;\n        \n        processed += vec_size;\n    }\n    \n    // Process remaining characters sequentially\n    for (int i = processed; i < n; i++) {\n        balance += (brackets[i] == '(') ? 1 : -1;\n    }\n    \n    return balance == 0;\n}\n```"}
{"task_id": "SimdBench_90_AVX", "completion": "```cpp\nbool correct_bracketing_simd(std::string brackets) {\n    int n = brackets.length();\n    if (n == 0) return true;\n    \n    // Process 32 characters at a time using AVX2\n    int vector_size = 32;\n    int processed_length = n - (n % vector_size);\n    \n    __m256i open_mask = _mm256_set1_epi8('(');\n    __m256i close_mask = _mm256_set1_epi8(')');\n    __m256i zero_mask = _mm256_setzero_si256();\n    \n    int balance = 0;\n    \n    // Process 32-byte chunks\n    for (int i = 0; i < processed_length; i += vector_size) {\n        __m256i chunk = _mm256_loadu_si256((__m256i*)&brackets[i]);\n        \n        // Compare with '('\n        __m256i is_open = _mm256_cmpeq_epi8(chunk, open_mask);\n        \n        // Compare with ')'\n        __m256i is_close = _mm256_cmpeq_epi8(chunk, close_mask);\n        \n        // Count open and close brackets\n        int open_count = _mm256_popcnt_epi8(is_open);\n        int close_count = _mm256_popcnt_epi8(is_close);\n        \n        balance += open_count - close_count;\n        \n        if (balance < 0) return false;\n    }\n    \n    // Process remaining characters\n    for (int i = processed_length; i < n; i++) {\n        if (brackets[i] == '(') balance++;\n        else balance--;\n        \n        if (balance < 0) return false;\n    }\n    \n    return balance == 0;\n}\n```"}
{"task_id": "SimdBench_90_AVX", "completion": "```cpp\nbool correct_bracketing_simd(std::string brackets) {\n    int n = brackets.length();\n    if (n == 0) return true;\n    \n    // Process 32 characters at a time using AVX2\n    int vec_size = 32;\n    int processed_length = (n / vec_size) * vec_size;\n    \n    __m256i open_mask = _mm256_set1_epi8('(');\n    __m256i close_mask = _mm256_set1_epi8(')');\n    __m256i zero_vec = _mm256_setzero_si256();\n    \n    int balance = 0;\n    \n    // Process 32-byte chunks\n    for (int i = 0; i < processed_length; i += vec_size) {\n        __m256i current = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&brackets[i]));\n        \n        // Compare with '('\n        __m256i is_open = _mm256_cmpeq_epi8(current, open_mask);\n        \n        // Compare with ')'\n        __m256i is_close = _mm256_cmpeq_epi8(current, close_mask);\n        \n        // Count open and close brackets\n        int open_count = _mm256_movemask_epi8(is_open);\n        int close_count = _mm256_movemask_epi8(is_close);\n        \n        // Update balance\n        balance += __builtin_popcount(open_count) - __builtin_popcount(close_count);\n        \n        // If balance goes negative, return false\n        if (balance < 0) return false;\n    }\n    \n    // Process remaining characters\n    for (int i = processed_length; i < n; ++i) {\n        if (brackets[i] == '(') balance++;\n        else balance--;\n        \n        if (balance < 0) return false;\n    }\n    \n    return balance == 0;\n}\n```"}
{"task_id": "SimdBench_91_AVX", "completion": "```cpp\nstd::vector<float> derivative_simd(std::vector<float> xs) {\n    if (xs.size() <= 1) return {};\n\n    std::vector<float> result(xs.size() - 1);\n    int n = xs.size();\n    int vectorSize = 8; // AVX can process 8 floats at once\n\n    // Process 8 elements at a time\n    int i;\n    for (i = 0; i + vectorSize <= n - 1; i += vectorSize) {\n        __m256 coeffs = _mm256_loadu_ps(&xs[i+1]);\n        __m256 multipliers = _mm256_set_ps(7.0f, 6.0f, 5.0f, 4.0f, 3.0f, 2.0f, 1.0f, 0.0f);\n        __m256 derivatives = _mm256_mul_ps(coeffs, multipliers);\n        _mm256_storeu_ps(&result[i], derivatives);\n    }\n\n    // Handle remaining elements\n    for (; i < n - 1; ++i) {\n        result[i] = xs[i+1] * (i+1);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_91_AVX", "completion": "```cpp\nstd::vector<float> derivative_simd(std::vector<float> xs) {\n    if (xs.size() <= 1) return {};\n\n    std::vector<float> result(xs.size() - 1);\n    int n = xs.size();\n    int vectorSize = 8; // AVX can process 8 floats at once\n\n    // Process 8 elements at a time\n    int i;\n    for (i = 0; i + vectorSize <= n - 1; i += vectorSize) {\n        __m256 coeffs = _mm256_loadu_ps(&xs[i+1]);\n        __m256 multipliers = _mm256_set_ps(7.0f, 6.0f, 5.0f, 4.0f, 3.0f, 2.0f, 1.0f, 0.0f);\n        __m256 derivatives = _mm256_mul_ps(coeffs, multipliers);\n        _mm256_storeu_ps(&result[i], derivatives);\n    }\n\n    // Handle remaining elements\n    for (; i < n - 1; ++i) {\n        result[i] = xs[i+1] * (i+1);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_91_AVX", "completion": "```cpp\nstd::vector<float> derivative_simd(std::vector<float> xs) {\n    if (xs.size() <= 1) return {};\n\n    std::vector<float> result(xs.size() - 1);\n    int n = xs.size();\n    int vectorSize = 8; // AVX can process 8 floats at once\n\n    // Process 8 elements at a time\n    int i;\n    for (i = 0; i + vectorSize <= n - 1; i += vectorSize) {\n        __m256 coeffs = _mm256_loadu_ps(&xs[i + 1]);\n        __m256 multipliers = _mm256_set_ps(7.0f, 6.0f, 5.0f, 4.0f, 3.0f, 2.0f, 1.0f, 0.0f);\n        __m256 derivatives = _mm256_mul_ps(coeffs, multipliers);\n        _mm256_storeu_ps(&result[i], derivatives);\n    }\n\n    // Handle remaining elements\n    for (; i < n - 1; ++i) {\n        result[i] = xs[i + 1] * (i + 1);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_91_AVX", "completion": "```cpp\nstd::vector<float> derivative_simd(std::vector<float> xs) {\n    if (xs.size() <= 1) return {};\n\n    std::vector<float> result(xs.size() - 1);\n    int n = xs.size();\n    int simd_width = 8; // AVX can process 8 floats at once\n\n    // Process 8 elements at a time\n    int i;\n    for (i = 0; i + simd_width <= n - 1; i += simd_width) {\n        __m256 coeffs = _mm256_loadu_ps(&xs[i+1]);\n        __m256 multipliers = _mm256_set_ps(7.0f, 6.0f, 5.0f, 4.0f, 3.0f, 2.0f, 1.0f, 0.0f);\n        __m256 derivatives = _mm256_mul_ps(coeffs, multipliers);\n        _mm256_storeu_ps(&result[i], derivatives);\n    }\n\n    // Handle remaining elements\n    for (; i < n - 1; ++i) {\n        result[i] = xs[i+1] * (i+1);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_91_AVX", "completion": "```cpp\nstd::vector<float> derivative_simd(std::vector<float> xs) {\n    if (xs.size() <= 1) return {};\n\n    std::vector<float> result(xs.size() - 1);\n    int n = xs.size();\n    int vectorSize = 8; // AVX can process 8 floats at once\n\n    // Process 8 elements at a time\n    int i;\n    for (i = 0; i + vectorSize <= n - 1; i += vectorSize) {\n        __m256 multipliers = _mm256_set_ps(\n            7.0f, 6.0f, 5.0f, 4.0f, 3.0f, 2.0f, 1.0f, 0.0f\n        );\n        __m256 input = _mm256_loadu_ps(&xs[i+1]);\n        __m256 coefficients = _mm256_mul_ps(input, multipliers);\n        _mm256_storeu_ps(&result[i], coefficients);\n    }\n\n    // Handle remaining elements\n    for (; i < n - 1; ++i) {\n        result[i] = xs[i+1] * (i+1);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_92_AVX", "completion": "```cpp\nint vowels_count_simd(std::string s) {\n    int len = s.length();\n    int vowel_count = 0;\n    \n    // Process 32 bytes at a time using AVX2\n    int vector_len = len - (len % 32);\n    __m256i vowel_mask = _mm256_set1_epi8(0);\n    \n    for (int i = 0; i < vector_len; i += 32) {\n        __m256i chars = _mm256_loadu_si256((__m256i*)&s[i]);\n        \n        // Check for lowercase vowels\n        __m256i a_mask = _mm256_cmpeq_epi8(chars, _mm256_set1_epi8('a'));\n        __m256i e_mask = _mm256_cmpeq_epi8(chars, _mm256_set1_epi8('e'));\n        __m256i i_mask = _mm256_cmpeq_epi8(chars, _mm256_set1_epi8('i'));\n        __m256i o_mask = _mm256_cmpeq_epi8(chars, _mm256_set1_epi8('o'));\n        __m256i u_mask = _mm256_cmpeq_epi8(chars, _mm256_set1_epi8('u'));\n        \n        // Check for uppercase vowels\n        __m256i A_mask = _mm256_cmpeq_epi8(chars, _mm256_set1_epi8('A'));\n        __m256i E_mask = _mm256_cmpeq_epi8(chars, _mm256_set1_epi8('E'));\n        __m256i I_mask = _mm256_cmpeq_epi8(chars, _mm256_set1_epi8('I'));\n        __m256i O_mask = _mm256_cmpeq_epi8(chars, _mm256_set1_epi8('O'));\n        __m256i U_mask = _mm256_cmpeq_epi8(chars, _mm256_set1_epi8('U'));\n        \n        // Combine lowercase and uppercase vowel masks\n        __m256i vowel_vec_mask = _mm256_or_si256(\n            _mm256_or_si256(_mm256_or_si256(_mm256_or_si256(a_mask, e_mask), _mm256_or_si256(i_mask, o_mask)),\n            _mm256_or_si256(\n                _mm256_or_si256(_mm256_or_si256(A_mask, E_mask), _mm256_or_si256(I_mask, O_mask)),\n                U_mask\n            )\n        );\n        \n        // Special case for 'y' at the end of the word\n        if (i + 31 == len - 1) {\n            __m256i y_mask = _mm256_cmpeq_epi8(chars, _mm256_set1_epi8('y'));\n            __m256i Y_mask = _mm256_cmpeq_epi8(chars, _mm256_set1_epi8('Y'));\n            vowel_vec_mask = _mm256_or_si256(vowel_vec_mask, _mm256_or_si256(y_mask, Y_mask));\n        }\n        \n        vowel_mask = _mm256_or_si256(vowel_mask, vowel_vec_mask);\n    }\n    \n    // Count vowels using mask\n    uint8_t mask_array[32];\n    _mm256_storeu_si256((__m256i*)mask_array, vowel_mask);\n    \n    for (int i = 0; i < 32; i++) {\n        vowel_count += mask_array[i] ? 1 : 0;\n    }\n    \n    // Process remaining characters\n    for (int i = vector_len; i < len; i++) {\n        char c = s[i];\n        if (c == 'a' || c == 'e' || c == 'i' || c == 'o' || c == 'u' ||\n            c == 'A' || c == 'E' || c == 'I' || c == 'O' || c == 'U' ||\n            (c == 'y' && i == len - 1) || (c == 'Y' && i == len - 1)) {\n            vowel_count++;\n        }\n    }\n    \n    return vowel_count;\n}\n```"}
{"task_id": "SimdBench_92_AVX", "completion": "```cpp\nint vowels_count_simd(std::string s) {\n    int len = s.length();\n    int vowel_count = 0;\n    \n    // Process 32 characters at a time using AVX2\n    int vector_len = len - (len % 32);\n    __m256i vowel_mask = _mm256_set1_epi8(0);\n    \n    for (int i = 0; i < vector_len; i += 32) {\n        __m256i chars = _mm256_loadu_si256((__m256i*)&s[i]);\n        \n        // Check for lowercase vowels\n        __m256i a_mask = _mm256_cmpeq_epi8(chars, _mm256_set1_epi8('a'));\n        __m256i e_mask = _mm256_cmpeq_epi8(chars, _mm256_set1_epi8('e'));\n        __m256i i_mask = _mm256_cmpeq_epi8(chars, _mm256_set1_epi8('i'));\n        __m256i o_mask = _mm256_cmpeq_epi8(chars, _mm256_set1_epi8('o'));\n        __m256i u_mask = _mm256_cmpeq_epi8(chars, _mm256_set1_epi8('u'));\n        \n        // Check for uppercase vowels\n        __m256i A_mask = _mm256_cmpeq_epi8(chars, _mm256_set1_epi8('A'));\n        __m256i E_mask = _mm256_cmpeq_epi8(chars, _mm256_set1_epi8('E'));\n        __m256i I_mask = _mm256_cmpeq_epi8(chars, _mm256_set1_epi8('I'));\n        __m256i O_mask = _mm256_cmpeq_epi8(chars, _mm256_set1_epi8('O'));\n        __m256i U_mask = _mm256_cmpeq_epi8(chars, _mm256_set1_epi8('U'));\n        \n        // Check for 'y' or 'Y' at the end of the word\n        __m256i y_mask = _mm256_cmpeq_epi8(chars, _mm256_set1_epi8('y'));\n        __m256i Y_mask = _mm256_cmpeq_epi8(chars, _mm256_set1_epi8('Y'));\n        \n        // Combine masks for all vowels\n        __m256i vowel_match = _mm256_or_si256(\n            _mm256_or_si256(\n                _mm256_or_si256(\n                    _mm256_or_si256(a_mask, e_mask),\n                    _mm256_or_si256(i_mask, o_mask)\n                ),\n                u_mask\n            ),\n            _mm256_or_si256(\n                _mm256_or_si256(\n                    _mm256_or_si256(\n                        _mm256_or_si256(A_mask, E_mask),\n                        _mm256_or_si256(I_mask, O_mask)\n                    ),\n                    U_mask\n                ),\n                _mm256_or_si256(y_mask, Y_mask)\n            )\n        );\n        \n        // Special handling for 'y' or 'Y' at the end of the word\n        if (i + 31 == len - 1) {\n            __m256i end_y_mask = _mm256_and_si256(\n                _mm256_cmpeq_epi8(chars, _mm256_set1_epi8('y')),\n                _mm256_set1_epi8(0xFF)\n            );\n            __m256i end_Y_mask = _mm256_and_si256(\n                _mm256_cmpeq_epi8(chars, _mm256_set1_epi8('Y')),\n                _mm256_set1_epi8(0xFF)\n            );\n            vowel_match = _mm256_or_si256(vowel_match, _mm256_or_si256(end_y_mask, end_Y_mask));\n        }\n        \n        // Count vowels in the current vector\n        vowel_mask = _mm256_or_si256(vowel_mask, vowel_match);\n    }\n    \n    // Horizontal sum of vowel mask\n    __m256i zero = _mm256_setzero_si256();\n    __m256i sad = _mm256_sad_epu8(vowel_mask, zero);\n    int* sad_array = (int*)&sad;\n    vowel_count = sad_array[0] + sad_array[4];\n    \n    // Process remaining characters\n    for (int i = vector_len; i < len; ++i) {\n        char c = s[i];\n        if (c == 'a' || c == 'e' || c == 'i' || c == 'o' || c == 'u' ||\n            c == 'A' || c == 'E' || c == 'I' || c == 'O' || c == 'U' ||\n            (c == 'y' && i == len - 1) || (c == 'Y' && i == len - 1)) {\n            ++vowel_count;\n        }\n    }\n    \n    return vowel_count;\n}\n```"}
{"task_id": "SimdBench_92_AVX", "completion": "```cpp\nint vowels_count_simd(std::string s) {\n    int len = s.length();\n    int vowel_count = 0;\n    \n    // Process 32 characters at a time using AVX2\n    int vector_len = len - (len % 32);\n    __m256i vowel_mask = _mm256_setzero_si256();\n    \n    for (int i = 0; i < vector_len; i += 32) {\n        // Load 32 characters\n        __m256i chars = _mm256_loadu_si256((__m256i*)&s[i]);\n        \n        // Convert to lowercase\n        __m256i lower_a = _mm256_set1_epi8('a');\n        __m256i lower_z = _mm256_set1_epi8('z');\n        __m256i upper_a = _mm256_set1_epi8('A');\n        __m256i upper_z = _mm256_set1_epi8('Z');\n        \n        __m256i is_lower = _mm256_and_si256(_mm256_cmpgt_epi8(chars, lower_a - 1), _mm256_cmpgt_epi8(lower_z, chars));\n        __m256i is_upper = _mm256_and_si256(_mm256_cmpgt_epi8(chars, upper_a - 1), _mm256_cmpgt_epi8(upper_z, chars));\n        \n        __m256i to_lower_mask = _mm256_and_si256(is_upper, _mm256_set1_epi8(32));\n        chars = _mm256_or_si256(chars, to_lower_mask);\n        \n        // Check for vowels\n        __m256i vowels_a = _mm256_cmpeq_epi8(chars, _mm256_set1_epi8('a'));\n        __m256i vowels_e = _mm256_cmpeq_epi8(chars, _mm256_set1_epi8('e'));\n        __m256i vowels_i = _mm256_cmpeq_epi8(chars, _mm256_set1_epi8('i'));\n        __m256i vowels_o = _mm256_cmpeq_epi8(chars, _mm256_set1_epi8('o'));\n        __m256i vowels_u = _mm256_cmpeq_epi8(chars, _mm256_set1_epi8('u'));\n        \n        // Special case for 'y' at the end of the word\n        __m256i vowels_y = _mm256_setzero_si256();\n        if (i + 32 == len) {\n            vowels_y = _mm256_cmpeq_epi8(chars, _mm256_set1_epi8('y'));\n        }\n        \n        __m256i vowel_chars = _mm256_or_si256(_mm256_or_si256(_mm256_or_si256(_mm256_or_si256(vowels_a, vowels_e), vowels_i), vowels_o), _mm256_or_si256(vowels_u, vowels_y));\n        \n        vowel_mask = _mm256_or_si256(vowel_mask, vowel_chars);\n    }\n    \n    // Horizontal sum of vowel mask\n    __m128i low_mask = _mm256_extracti128_si256(vowel_mask, 0);\n    __m128i high_mask = _mm256_extracti128_si256(vowel_mask, 1);\n    low_mask = _mm_or_si128(low_mask, high_mask);\n    \n    uint8_t mask_array[16];\n    _mm_storeu_si128((__m128i*)mask_array, low_mask);\n    \n    for (int j = 0; j < 16; j++) {\n        vowel_count += (mask_array[j] != 0);\n    }\n    \n    // Process remaining characters\n    for (int i = vector_len; i < len; i++) {\n        char c = std::tolower(s[i]);\n        if (c == 'a' || c == 'e' || c == 'i' || c == 'o' || c == 'u' || \n            (c == 'y' && i == len - 1)) {\n            vowel_count++;\n        }\n    }\n    \n    return vowel_count;\n}\n```"}
{"task_id": "SimdBench_92_AVX", "completion": "```cpp\nint vowels_count_simd(std::string s) {\n    int len = s.length();\n    int vowel_count = 0;\n    \n    // Process 32 characters at a time using AVX2\n    int vector_len = len - (len % 32);\n    __m256i vowel_mask = _mm256_set1_epi8(0);\n    \n    for (int i = 0; i < vector_len; i += 32) {\n        __m256i chars = _mm256_loadu_si256((__m256i*)&s[i]);\n        \n        // Check for lowercase vowels\n        __m256i a_mask = _mm256_cmpeq_epi8(chars, _mm256_set1_epi8('a'));\n        __m256i e_mask = _mm256_cmpeq_epi8(chars, _mm256_set1_epi8('e'));\n        __m256i i_mask = _mm256_cmpeq_epi8(chars, _mm256_set1_epi8('i'));\n        __m256i o_mask = _mm256_cmpeq_epi8(chars, _mm256_set1_epi8('o'));\n        __m256i u_mask = _mm256_cmpeq_epi8(chars, _mm256_set1_epi8('u'));\n        \n        // Check for uppercase vowels\n        __m256i A_mask = _mm256_cmpeq_epi8(chars, _mm256_set1_epi8('A'));\n        __m256i E_mask = _mm256_cmpeq_epi8(chars, _mm256_set1_epi8('E'));\n        __m256i I_mask = _mm256_cmpeq_epi8(chars, _mm256_set1_epi8('I'));\n        __m256i O_mask = _mm256_cmpeq_epi8(chars, _mm256_set1_epi8('O'));\n        __m256i U_mask = _mm256_cmpeq_epi8(chars, _mm256_set1_epi8('U'));\n        \n        // Combine masks for 'y' and 'Y' at the end of the word\n        __m256i y_mask = _mm256_setzero_si256();\n        if (i + 31 == len - 1) {\n            y_mask = _mm256_or_si256(\n                _mm256_cmpeq_epi8(chars, _mm256_set1_epi8('y')),\n                _mm256_cmpeq_epi8(chars, _mm256_set1_epi8('Y'))\n            );\n        }\n        \n        // Combine all vowel masks\n        vowel_mask = _mm256_or_si256(vowel_mask, \n            _mm256_or_si256(\n                _mm256_or_si256(\n                    _mm256_or_si256(a_mask, e_mask),\n                    _mm256_or_si256(i_mask, o_mask)\n                ),\n                _mm256_or_si256(\n                    _mm256_or_si256(u_mask, A_mask),\n                    _mm256_or_si256(\n                        _mm256_or_si256(E_mask, I_mask),\n                        _mm256_or_si256(O_mask, U_mask)\n                    )\n                )\n            )\n        );\n        \n        // Add 'y' mask if at the end of the word\n        vowel_mask = _mm256_or_si256(vowel_mask, y_mask);\n    }\n    \n    // Count vowels in the vector mask\n    uint8_t mask_array[32];\n    _mm256_storeu_si256((__m256i*)mask_array, vowel_mask);\n    \n    for (int i = 0; i < 32; i++) {\n        vowel_count += mask_array[i] ? 1 : 0;\n    }\n    \n    // Process remaining characters\n    for (int i = vector_len; i < len; i++) {\n        char c = s[i];\n        if (c == 'a' || c == 'e' || c == 'i' || c == 'o' || c == 'u' ||\n            c == 'A' || c == 'E' || c == 'I' || c == 'O' || c == 'U' ||\n            (c == 'y' && i == len - 1) || (c == 'Y' && i == len - 1)) {\n            vowel_count++;\n        }\n    }\n    \n    return vowel_count;\n}\n```"}
{"task_id": "SimdBench_92_AVX", "completion": "```cpp\nint vowels_count_simd(std::string s) {\n    int len = s.length();\n    int vowel_count = 0;\n\n    // Process 32 characters at a time using AVX2\n    int vector_len = len - (len % 32);\n    __m256i vowel_mask = _mm256_set1_epi8(0);\n\n    for (int i = 0; i < vector_len; i += 32) {\n        __m256i chars = _mm256_loadu_si256((__m256i*)&s[i]);\n\n        // Check for lowercase vowels\n        __m256i a_mask = _mm256_cmpeq_epi8(chars, _mm256_set1_epi8('a'));\n        __m256i e_mask = _mm256_cmpeq_epi8(chars, _mm256_set1_epi8('e'));\n        __m256i i_mask = _mm256_cmpeq_epi8(chars, _mm256_set1_epi8('i'));\n        __m256i o_mask = _mm256_cmpeq_epi8(chars, _mm256_set1_epi8('o'));\n        __m256i u_mask = _mm256_cmpeq_epi8(chars, _mm256_set1_epi8('u'));\n\n        // Check for uppercase vowels\n        __m256i A_mask = _mm256_cmpeq_epi8(chars, _mm256_set1_epi8('A'));\n        __m256i E_mask = _mm256_cmpeq_epi8(chars, _mm256_set1_epi8('E'));\n        __m256i I_mask = _mm256_cmpeq_epi8(chars, _mm256_set1_epi8('I'));\n        __m256i O_mask = _mm256_cmpeq_epi8(chars, _mm256_set1_epi8('O'));\n        __m256i U_mask = _mm256_cmpeq_epi8(chars, _mm256_set1_epi8('U'));\n\n        // Combine masks for 'y' and 'Y' at the end of the word\n        __m256i y_mask = _mm256_setzero_si256();\n        if (i + 31 == len - 1) {\n            y_mask = _mm256_or_si256(\n                _mm256_cmpeq_epi8(chars, _mm256_set1_epi8('y')),\n                _mm256_cmpeq_epi8(chars, _mm256_set1_epi8('Y'))\n            );\n        }\n\n        // Combine all vowel masks\n        __m256i combined_mask = _mm256_or_si256(\n            _mm256_or_si256(a_mask, e_mask),\n            _mm256_or_si256(\n                _mm256_or_si256(i_mask, o_mask),\n                _mm256_or_si256(\n                    _mm256_or_si256(u_mask, A_mask),\n                    _mm256_or_si256(\n                        _mm256_or_si256(E_mask, I_mask),\n                        _mm256_or_si256(\n                            _mm256_or_si256(O_mask, U_mask),\n                            y_mask\n                        )\n                    )\n                )\n            )\n        );\n\n        vowel_mask = _mm256_or_si256(vowel_mask, combined_mask);\n    }\n\n    // Count vowels using mask\n    uint8_t mask_array[32];\n    _mm256_storeu_si256((__m256i*)mask_array, vowel_mask);\n    for (int i = 0; i < 32; i++) {\n        vowel_count += mask_array[i] ? 1 : 0;\n    }\n\n    // Process remaining characters\n    for (int i = vector_len; i < len; i++) {\n        char c = s[i];\n        if (c == 'a' || c == 'e' || c == 'i' || c == 'o' || c == 'u' ||\n            c == 'A' || c == 'E' || c == 'I' || c == 'O' || c == 'U' ||\n            (c == 'y' && i == len - 1) || (c == 'Y' && i == len - 1)) {\n            vowel_count++;\n        }\n    }\n\n    return vowel_count;\n}\n```"}
{"task_id": "SimdBench_93_AVX", "completion": "```cpp\nint digitSum_simd(std::string s) {\n    int result = 0;\n    size_t len = s.length();\n    \n    // Process 32 bytes at a time using AVX2\n    size_t vectorLen = len - (len % 32);\n    \n    __m256i sumVector = _mm256_setzero_si256();\n    \n    for (size_t i = 0; i < vectorLen; i += 32) {\n        __m256i chars = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&s[i]));\n        \n        // Create mask for uppercase characters\n        __m256i upperMask = _mm256_set1_epi8('A' - 1);\n        __m256i upperBoundMask = _mm256_set1_epi8('Z' + 1);\n        \n        // Check if characters are uppercase\n        __m256i isUpperMask = _mm256_and_si256(\n            _mm256_cmpgt_epi8(chars, upperMask),\n            _mm256_cmpgt_epi8(upperBoundMask, chars)\n        );\n        \n        // Zero out non-uppercase characters\n        __m256i maskedChars = _mm256_and_si256(chars, isUpperMask);\n        \n        // Sum uppercase characters\n        sumVector = _mm256_add_epi8(sumVector, maskedChars);\n    }\n    \n    // Horizontal sum of vector\n    __m128i sum128 = _mm_add_epi8(\n        _mm256_extracti128_si256(sumVector, 0),\n        _mm256_extracti128_si256(sumVector, 1)\n    );\n    sum128 = _mm_add_epi8(sum128, _mm_srli_si128(sum128, 8));\n    sum128 = _mm_add_epi8(sum128, _mm_srli_si128(sum128, 4));\n    sum128 = _mm_add_epi8(sum128, _mm_srli_si128(sum128, 2));\n    \n    result += _mm_cvtsi128_si32(sum128) & 0xFF;\n    \n    // Process remaining characters\n    for (size_t i = vectorLen; i < len; ++i) {\n        if (s[i] >= 'A' && s[i] <= 'Z') {\n            result += s[i];\n        }\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_93_AVX", "completion": "```cpp\nint digitSum_simd(std::string s) {\n    int result = 0;\n    size_t len = s.length();\n    \n    // Process 32 bytes at a time using AVX2\n    size_t vectorLen = len - (len % 32);\n    \n    __m256i sumVector = _mm256_setzero_si256();\n    \n    for (size_t i = 0; i < vectorLen; i += 32) {\n        __m256i chars = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&s[i]));\n        \n        // Check for uppercase characters (ASCII between 65 and 90)\n        __m256i upperMask = _mm256_and_si256(\n            _mm256_cmpgt_epi8(chars, _mm256_set1_epi8(64)),\n            _mm256_cmpgt_epi8(_mm256_set1_epi8(91), chars)\n        );\n        \n        // Zero out non-uppercase characters\n        __m256i maskedChars = _mm256_and_si256(chars, upperMask);\n        \n        // Sum the ASCII values of uppercase characters\n        __m256i sumChars = _mm256_sad_epu8(maskedChars, _mm256_setzero_si256());\n        sumVector = _mm256_add_epi64(sumVector, sumChars);\n    }\n    \n    // Horizontal sum of vector\n    int sumArray[4];\n    _mm256_storeu_si256(reinterpret_cast<__m256i*>(sumArray), sumVector);\n    result += sumArray[0] + sumArray[2];\n    \n    // Process remaining characters\n    for (size_t i = vectorLen; i < len; ++i) {\n        if (isupper(s[i])) {\n            result += s[i];\n        }\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_93_AVX", "completion": "```cpp\nint digitSum_simd(std::string s) {\n    int result = 0;\n    size_t len = s.length();\n    \n    // Process 32 bytes at a time using AVX2\n    size_t vectorLen = len - (len % 32);\n    \n    __m256i sumVector = _mm256_setzero_si256();\n    \n    for (size_t i = 0; i < vectorLen; i += 32) {\n        __m256i chars = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&s[i]));\n        \n        // Check for uppercase characters (ASCII between 65 and 90)\n        __m256i upperMask = _mm256_and_si256(\n            _mm256_cmpgt_epi8(chars, _mm256_set1_epi8(64)),\n            _mm256_cmpgt_epi8(_mm256_set1_epi8(91), chars)\n        );\n        \n        // Zero out non-uppercase characters\n        __m256i maskedChars = _mm256_and_si256(chars, upperMask);\n        \n        sumVector = _mm256_add_epi8(sumVector, maskedChars);\n    }\n    \n    // Horizontal sum of vector\n    __m128i sum128 = _mm_add_epi8(\n        _mm256_extracti128_si256(sumVector, 0),\n        _mm256_extracti128_si256(sumVector, 1)\n    );\n    sum128 = _mm_add_epi8(sum128, _mm_srli_si128(sum128, 8));\n    sum128 = _mm_add_epi8(sum128, _mm_srli_si128(sum128, 4));\n    sum128 = _mm_add_epi8(sum128, _mm_srli_si128(sum128, 2));\n    \n    result += _mm_cvtsi128_si32(sum128) & 0xFF;\n    \n    // Process remaining characters\n    for (size_t i = vectorLen; i < len; ++i) {\n        if (s[i] >= 'A' && s[i] <= 'Z') {\n            result += s[i];\n        }\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_93_AVX", "completion": "```cpp\nint digitSum_simd(std::string s) {\n    int result = 0;\n    int len = s.length();\n    \n    // Process 32 bytes at a time using AVX2\n    int i = 0;\n    for (; i + 32 <= len; i += 32) {\n        __m256i chars = _mm256_loadu_si256((__m256i*)&s[i]);\n        \n        // Create masks for uppercase characters\n        __m256i upper_mask = _mm256_set1_epi8('A' - 1);\n        __m256i lower_mask = _mm256_set1_epi8('Z' + 1);\n        \n        // Check if characters are uppercase\n        __m256i is_upper_a = _mm256_cmpgt_epi8(chars, upper_mask);\n        __m256i is_upper_b = _mm256_cmpgt_epi8(lower_mask, chars);\n        __m256i is_upper = _mm256_and_si256(is_upper_a, is_upper_b);\n        \n        // Zero out non-uppercase characters\n        __m256i masked_chars = _mm256_and_si256(chars, is_upper);\n        \n        // Horizontal sum of bytes\n        __m128i sum_low = _mm_sad_epu8(_mm256_extracti128_si256(masked_chars, 0), _mm_setzero_si128());\n        __m128i sum_high = _mm_sad_epu8(_mm256_extracti128_si256(masked_chars, 1), _mm_setzero_si128());\n        \n        // Combine sums\n        __m128i total_sum = _mm_add_epi32(sum_low, sum_high);\n        total_sum = _mm_hadd_epi32(total_sum, total_sum);\n        result += _mm_cvtsi128_si32(total_sum);\n    }\n    \n    // Process remaining characters\n    for (; i < len; ++i) {\n        if (isupper(s[i])) {\n            result += s[i];\n        }\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_93_AVX", "completion": "```cpp\nint digitSum_simd(std::string s) {\n    int result = 0;\n    size_t len = s.length();\n    \n    // Process 32 bytes at a time using AVX2\n    size_t vectorLen = len - (len % 32);\n    \n    __m256i sumVector = _mm256_setzero_si256();\n    \n    for (size_t i = 0; i < vectorLen; i += 32) {\n        __m256i chars = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&s[i]));\n        \n        // Create mask for uppercase characters\n        __m256i upperMask = _mm256_set1_epi8('A' - 1);\n        __m256i upperBoundMask = _mm256_set1_epi8('Z' + 1);\n        \n        // Check if character is uppercase\n        __m256i isUpperMask = _mm256_and_si256(\n            _mm256_cmpgt_epi8(chars, upperMask),\n            _mm256_cmpgt_epi8(upperBoundMask, chars)\n        );\n        \n        // Zero out non-uppercase characters\n        __m256i maskedChars = _mm256_and_si256(chars, isUpperMask);\n        \n        // Sum uppercase characters\n        sumVector = _mm256_add_epi8(sumVector, maskedChars);\n    }\n    \n    // Horizontal sum of vector\n    __m128i low = _mm256_extracti128_si256(sumVector, 0);\n    __m128i high = _mm256_extracti128_si256(sumVector, 1);\n    \n    low = _mm_add_epi8(low, high);\n    low = _mm_hadd_epi16(low, low);\n    low = _mm_hadd_epi16(low, low);\n    low = _mm_hadd_epi16(low, low);\n    \n    result += _mm_cvtsi128_si32(low) & 0xFF;\n    \n    // Process remaining characters\n    for (size_t i = vectorLen; i < len; ++i) {\n        if (isupper(s[i])) {\n            result += s[i];\n        }\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_94_AVX", "completion": "```cpp\nstd::vector<int> pluck_simd(std::vector<int> arr) {\n    int n = arr.size();\n    if (n == 0) return {};\n\n    // Align data to 32-byte boundary for AVX\n    alignas(32) int values[32];\n    alignas(32) int indices[32];\n\n    // Initialize with max values\n    __m256i min_even_val = _mm256_set1_epi32(INT_MAX);\n    __m256i min_even_idx = _mm256_set1_epi32(INT_MAX);\n\n    // Process 8 elements at a time\n    for (int i = 0; i < n; i += 8) {\n        // Load 8 values and indices\n        __m256i curr_vals = _mm256_loadu_si256((__m256i*)&arr[i]);\n        __m256i curr_idxs = _mm256_setr_epi32(i, i+1, i+2, i+3, i+4, i+5, i+6, i+7);\n\n        // Create mask for even values\n        __m256i zero = _mm256_setzero_si256();\n        __m256i even_mask = _mm256_cmpeq_epi32(_mm256_and_si256(curr_vals, _mm256_set1_epi32(1)), zero);\n\n        // Mask out odd values\n        curr_vals = _mm256_blendv_epi8(_mm256_set1_epi32(INT_MAX), curr_vals, even_mask);\n        curr_idxs = _mm256_blendv_epi8(_mm256_set1_epi32(INT_MAX), curr_idxs, even_mask);\n\n        // Update minimum even value and index\n        __m256i cmp_val = _mm256_cmpgt_epi32(min_even_val, curr_vals);\n        min_even_val = _mm256_blendv_epi8(min_even_val, curr_vals, cmp_val);\n        min_even_idx = _mm256_blendv_epi8(min_even_idx, curr_idxs, cmp_val);\n    }\n\n    // Store results\n    _mm256_storeu_si256((__m256i*)values, min_even_val);\n    _mm256_storeu_si256((__m256i*)indices, min_even_idx);\n\n    // Find minimum in the vector\n    int min_val = INT_MAX;\n    int min_idx = INT_MAX;\n    for (int i = 0; i < 8; i++) {\n        if (values[i] < min_val) {\n            min_val = values[i];\n            min_idx = indices[i];\n        }\n    }\n\n    // Return result\n    return (min_val == INT_MAX) ? std::vector<int>{} : std::vector<int>{min_val, min_idx};\n}\n```"}
{"task_id": "SimdBench_94_AVX", "completion": "```cpp\nstd::vector<int> pluck_simd(std::vector<int> arr) {\n    int n = arr.size();\n    if (n == 0) return {};\n\n    // Align data to 32-byte boundary for AVX\n    alignas(32) int values[32];\n    alignas(32) int indices[32];\n\n    // Initialize with max possible values\n    __m256i min_even_val = _mm256_set1_epi32(INT_MAX);\n    __m256i min_even_idx = _mm256_set1_epi32(INT_MAX);\n\n    // Process 8 elements at a time\n    for (int i = 0; i < n; i += 8) {\n        // Load 8 values and indices\n        __m256i current_vals = _mm256_loadu_si256((__m256i*)&arr[i]);\n        __m256i current_idxs = _mm256_setr_epi32(i, i+1, i+2, i+3, i+4, i+5, i+6, i+7);\n\n        // Create mask for even values\n        __m256i zero = _mm256_setzero_si256();\n        __m256i even_mask = _mm256_cmpeq_epi32(_mm256_and_si256(current_vals, _mm256_set1_epi32(1)), zero);\n\n        // Mask out odd values\n        current_vals = _mm256_blendv_epi8(_mm256_set1_epi32(INT_MAX), current_vals, even_mask);\n        current_idxs = _mm256_blendv_epi8(_mm256_set1_epi32(INT_MAX), current_idxs, even_mask);\n\n        // Update minimum even value and index\n        __m256i cmp_val = _mm256_cmpgt_epi32(min_even_val, current_vals);\n        min_even_val = _mm256_blendv_epi8(min_even_val, current_vals, cmp_val);\n        min_even_idx = _mm256_blendv_epi8(min_even_idx, current_idxs, cmp_val);\n    }\n\n    // Store results to array\n    _mm256_store_si256((__m256i*)values, min_even_val);\n    _mm256_store_si256((__m256i*)indices, min_even_idx);\n\n    // Find minimum value and index\n    int min_val = INT_MAX;\n    int min_idx = INT_MAX;\n    for (int i = 0; i < 8; i++) {\n        if (values[i] < min_val) {\n            min_val = values[i];\n            min_idx = indices[i];\n        }\n    }\n\n    // Return result\n    return (min_val == INT_MAX) ? std::vector<int>{} : std::vector<int>{min_val, min_idx};\n}\n```"}
{"task_id": "SimdBench_94_AVX", "completion": "```cpp\nstd::vector<int> pluck_simd(std::vector<int> arr) {\n    int n = arr.size();\n    if (n == 0) return {};\n\n    // Align data to 32-byte boundary for AVX\n    alignas(32) int values[32];\n    alignas(32) int indices[32];\n\n    // Initialize with max possible values\n    __m256i min_even_val = _mm256_set1_epi32(INT_MAX);\n    __m256i min_even_idx = _mm256_set1_epi32(-1);\n\n    // Process in chunks of 8 elements\n    for (int i = 0; i < n; i += 8) {\n        // Load current chunk of values and indices\n        __m256i current_vals = _mm256_loadu_si256((__m256i*)&arr[i]);\n        __m256i current_idxs = _mm256_setr_epi32(i, i+1, i+2, i+3, i+4, i+5, i+6, i+7);\n\n        // Create mask for even values\n        __m256i zero = _mm256_setzero_si256();\n        __m256i even_mask = _mm256_cmpeq_epi32(_mm256_and_si256(current_vals, _mm256_set1_epi32(1)), zero);\n\n        // Mask out odd values\n        current_vals = _mm256_blendv_epi8(_mm256_set1_epi32(INT_MAX), current_vals, even_mask);\n        current_idxs = _mm256_blendv_epi8(_mm256_set1_epi32(-1), current_idxs, even_mask);\n\n        // Find minimum even value and its index\n        __m256i cmp_mask = _mm256_cmpgt_epi32(min_even_val, current_vals);\n        min_even_val = _mm256_blendv_epi8(min_even_val, current_vals, cmp_mask);\n        min_even_idx = _mm256_blendv_epi8(min_even_idx, current_idxs, cmp_mask);\n    }\n\n    // Store results to arrays\n    _mm256_storeu_si256((__m256i*)values, min_even_val);\n    _mm256_storeu_si256((__m256i*)indices, min_even_idx);\n\n    // Find the absolute minimum in the results\n    int min_val = INT_MAX;\n    int min_idx = -1;\n    for (int j = 0; j < 8; j++) {\n        if (values[j] < min_val && values[j] != INT_MAX) {\n            min_val = values[j];\n            min_idx = indices[j];\n        }\n    }\n\n    // Return result\n    return (min_idx != -1) ? std::vector<int>{min_val, min_idx} : std::vector<int>{};\n}\n```"}
{"task_id": "SimdBench_94_AVX", "completion": "```cpp\nstd::vector<int> pluck_simd(std::vector<int> arr) {\n    int n = arr.size();\n    if (n == 0) return {};\n\n    // Align input to 256-bit boundary\n    __attribute__((aligned(32))) int values[n];\n    __attribute__((aligned(32))) int indices[n];\n    for (int i = 0; i < n; i++) {\n        values[i] = arr[i];\n        indices[i] = i;\n    }\n\n    int smallest_even = INT_MAX;\n    int smallest_index = -1;\n\n    // Process 8 elements at a time using AVX2\n    for (int i = 0; i + 8 <= n; i += 8) {\n        __m256i vec_values = _mm256_load_si256((__m256i*)&values[i]);\n        __m256i vec_indices = _mm256_load_si256((__m256i*)&indices[i]);\n\n        // Create mask for even numbers\n        __m256i zero = _mm256_setzero_si256();\n        __m256i two = _mm256_set1_epi32(2);\n        __m256i mod_mask = _mm256_cmpeq_epi32(_mm256_mod_epi32(vec_values, two), zero);\n\n        // If no even numbers in this chunk, continue\n        if (_mm256_movemask_epi8(mod_mask) == 0) continue;\n\n        // Mask values and indices to keep only even numbers\n        vec_values = _mm256_and_si256(vec_values, mod_mask);\n        vec_indices = _mm256_and_si256(vec_indices, mod_mask);\n\n        // Horizontal min\n        __m256i shuffled = _mm256_shuffle_epi32(vec_values, _MM_SHUFFLE(1, 0, 3, 2));\n        vec_values = _mm256_min_epi32(vec_values, shuffled);\n        shuffled = _mm256_shuffle_epi32(vec_values, _MM_SHUFFLE(0, 1, 2, 3));\n        vec_values = _mm256_min_epi32(vec_values, shuffled);\n\n        int min_val = _mm256_extract_epi32(vec_values, 0);\n        \n        // Find index of minimum value\n        for (int j = 0; j < 8; j++) {\n            if (values[i+j] == min_val && (smallest_even > min_val || \n                (smallest_even == min_val && smallest_index > indices[i+j]))) {\n                smallest_even = min_val;\n                smallest_index = indices[i+j];\n            }\n        }\n    }\n\n    // Process remaining elements\n    for (int i = (n/8)*8; i < n; i++) {\n        if (arr[i] % 2 == 0 && (smallest_even > arr[i] || \n            (smallest_even == arr[i] && smallest_index > i))) {\n            smallest_even = arr[i];\n            smallest_index = i;\n        }\n    }\n\n    if (smallest_index == -1) return {};\n    return {smallest_even, smallest_index};\n}\n```"}
{"task_id": "SimdBench_94_AVX", "completion": "```cpp\nstd::vector<int> pluck_simd(std::vector<int> arr) {\n    int n = arr.size();\n    if (n == 0) return {};\n\n    // Align data to 32-byte boundary for AVX\n    alignas(32) int values[32];\n    alignas(32) int indices[32];\n    \n    // Initialize with max values\n    __m256i min_even_val = _mm256_set1_epi32(INT_MAX);\n    __m256i min_even_idx = _mm256_set1_epi32(-1);\n\n    // Process in chunks of 8 elements\n    for (int i = 0; i < n; i += 8) {\n        // Load current chunk of values and indices\n        __m256i curr_vals = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&arr[i]));\n        __m256i curr_idxs = _mm256_setr_epi32(i, i+1, i+2, i+3, i+4, i+5, i+6, i+7);\n\n        // Create mask for even values\n        __m256i zero = _mm256_setzero_si256();\n        __m256i even_mask = _mm256_cmpeq_epi32(_mm256_and_si256(curr_vals, _mm256_set1_epi32(1)), zero);\n\n        // Blend current values with previous min even values\n        __m256i candidate_vals = _mm256_blendv_epi8(curr_vals, _mm256_set1_epi32(INT_MAX), _mm256_cmpeq_epi32(even_mask, zero));\n        __m256i candidate_idxs = _mm256_blendv_epi8(curr_idxs, _mm256_set1_epi32(-1), _mm256_cmpeq_epi32(even_mask, zero));\n\n        // Find minimum even value\n        __m256i cmp_mask = _mm256_cmpgt_epi32(min_even_val, candidate_vals);\n        min_even_val = _mm256_blendv_epi8(min_even_val, candidate_vals, cmp_mask);\n        min_even_idx = _mm256_blendv_epi8(min_even_idx, candidate_idxs, cmp_mask);\n    }\n\n    // Store results for sequential processing of final result\n    _mm256_storeu_si256(reinterpret_cast<__m256i*>(values), min_even_val);\n    _mm256_storeu_si256(reinterpret_cast<__m256i*>(indices), min_even_idx);\n\n    // Find absolute minimum\n    int min_val = INT_MAX;\n    int min_idx = -1;\n    for (int i = 0; i < 8; i++) {\n        if (values[i] < min_val && values[i] != INT_MAX) {\n            min_val = values[i];\n            min_idx = indices[i];\n        }\n    }\n\n    // Handle remaining elements if vector size is not multiple of 8\n    for (int i = (n / 8) * 8; i < n; i++) {\n        if (arr[i] % 2 == 0 && arr[i] < min_val) {\n            min_val = arr[i];\n            min_idx = i;\n        }\n    }\n\n    return (min_idx != -1) ? std::vector<int>{min_val, min_idx} : std::vector<int>{};\n}\n```"}
{"task_id": "SimdBench_95_AVX", "completion": "```cpp\nint search_simd(std::vector<int> lst) {\n    int n = lst.size();\n    \n    // Count frequencies using AVX2 \n    std::vector<int> freq(n + 1, 0);\n    \n    for (int i = 0; i < n; i += 8) {\n        __m256i count_vec = _mm256_setzero_si256();\n        \n        for (int j = 0; j < n; j++) {\n            __m256i current = _mm256_set1_epi32(lst[j]);\n            __m256i input = _mm256_loadu_si256((__m256i*)&lst[i]);\n            \n            __m256i cmp = _mm256_cmpeq_epi32(current, input);\n            count_vec = _mm256_add_epi32(count_vec, _mm256_srli_epi32(cmp, 31));\n        }\n        \n        int frequencies[8];\n        _mm256_storeu_si256((__m256i*)frequencies, count_vec);\n        \n        for (int k = 0; k < 8 && i + k < n; k++) {\n            freq[lst[i + k]] = frequencies[k];\n        }\n    }\n    \n    // Find the maximum value satisfying the condition\n    int result = -1;\n    for (int i = 1; i <= n; i++) {\n        if (freq[i] >= i) {\n            result = std::max(result, i);\n        }\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_95_AVX", "completion": "```cpp\nint search_simd(std::vector<int> lst) {\n    int n = lst.size();\n    \n    // Count frequencies using AVX2 intrinsics\n    std::vector<int> freq(n + 1, 0);\n    \n    for (int i = 0; i < n; i += 8) {\n        __m256i count_vec = _mm256_setzero_si256();\n        \n        for (int j = 0; j < n; j++) {\n            __m256i current = _mm256_set1_epi32(lst[j]);\n            __m256i input = _mm256_loadu_si256((__m256i*)&lst[i]);\n            \n            __m256i compare = _mm256_cmpeq_epi32(current, input);\n            count_vec = _mm256_add_epi32(count_vec, _mm256_srli_epi32(compare, 31));\n        }\n        \n        int counts[8];\n        _mm256_storeu_si256((__m256i*)counts, count_vec);\n        \n        for (int k = 0; k < 8 && i + k < n; k++) {\n            freq[lst[i + k]] = counts[k];\n        }\n    }\n    \n    // Find the result\n    int result = -1;\n    for (int i = 1; i <= n; i++) {\n        if (freq[i] >= i) {\n            result = std::max(result, i);\n        }\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_95_AVX", "completion": "```cpp\nint search_simd(std::vector<int> lst) {\n    int n = lst.size();\n    \n    // Create frequency array\n    std::vector<int> freq(n + 1, 0);\n    \n    // Count frequencies using SIMD\n    for (int i = 0; i < n; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&lst[i]);\n        \n        for (int j = 0; j < 8 && i + j < n; j++) {\n            int val = _mm256_extract_epi32(vec, j);\n            if (val > 0 && val <= n) {\n                freq[val]++;\n            }\n        }\n    }\n    \n    // Check conditions in reverse order\n    for (int k = n; k > 0; k--) {\n        if (freq[k] >= k) {\n            return k;\n        }\n    }\n    \n    return -1;\n}\n```"}
{"task_id": "SimdBench_95_AVX", "completion": "```cpp\nint search_simd(std::vector<int> lst) {\n    int n = lst.size();\n    \n    // Count frequencies using AVX2 intrinsics\n    std::vector<int> freq(n + 1, 0);\n    \n    for (int i = 0; i < n; i += 8) {\n        __m256i count_vec = _mm256_setzero_si256();\n        \n        for (int j = 0; j < n; j++) {\n            __m256i current = _mm256_set1_epi32(lst[j]);\n            __m256i indices = _mm256_setr_epi32(\n                i, i+1, i+2, i+3, i+4, i+5, i+6, i+7\n            );\n            __m256i compare = _mm256_cmpeq_epi32(current, _mm256_loadu_si256((__m256i*)&lst[i]));\n            count_vec = _mm256_add_epi32(count_vec, compare);\n        }\n        \n        int counts[8];\n        _mm256_storeu_si256((__m256i*)counts, count_vec);\n        \n        for (int k = 0; k < 8 && i + k < n; k++) {\n            freq[lst[i + k]] += counts[k];\n        }\n    }\n    \n    // Find the result\n    for (int x = n; x > 0; x--) {\n        if (freq[x] >= x) {\n            return x;\n        }\n    }\n    \n    return -1;\n}\n```"}
{"task_id": "SimdBench_95_AVX", "completion": "```cpp\nint search_simd(std::vector<int> lst) {\n    int n = lst.size();\n    \n    // Count frequencies using AVX2 intrinsics\n    std::vector<int> freq(n + 1, 0);\n    \n    for (int i = 0; i < n; i += 8) {\n        __m256i count_vec = _mm256_setzero_si256();\n        \n        for (int j = 0; j < n; j++) {\n            __m256i current = _mm256_set1_epi32(lst[j]);\n            __m256i input = _mm256_loadu_si256((__m256i*)&lst[i]);\n            \n            __m256i compare = _mm256_cmpeq_epi32(current, input);\n            count_vec = _mm256_add_epi32(count_vec, _mm256_srli_epi32(compare, 31));\n        }\n        \n        int frequencies[8];\n        _mm256_storeu_si256((__m256i*)frequencies, count_vec);\n        \n        for (int k = 0; k < 8 && i + k < n; k++) {\n            freq[lst[i + k]] = frequencies[k];\n        }\n    }\n    \n    // Find the result\n    for (int x = n; x > 0; x--) {\n        if (freq[x] >= x) {\n            return x;\n        }\n    }\n    \n    return -1;\n}\n```"}
{"task_id": "SimdBench_96_AVX", "completion": "```cpp\nbool will_it_fly_simd(std::vector<int> q, int w) {\n    int n = q.size();\n    \n    // Check total weight first\n    __m256i sum_vec = _mm256_setzero_si256();\n    for (int i = 0; i < n; i += 8) {\n        int remaining = std::min(8, n - i);\n        __m256i chunk;\n        \n        if (remaining == 8) {\n            chunk = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&q[i]));\n        } else {\n            // Handle partial vector for last chunk\n            alignas(32) int temp[8] = {0};\n            std::copy(q.begin() + i, q.end(), temp);\n            chunk = _mm256_load_si256(reinterpret_cast<const __m256i*>(temp));\n        }\n        \n        sum_vec = _mm256_add_epi32(sum_vec, chunk);\n    }\n    \n    // Horizontal sum\n    __m128i sum_low = _mm256_extracti128_si256(sum_vec, 0);\n    __m128i sum_high = _mm256_extracti128_si256(sum_vec, 1);\n    sum_low = _mm_add_epi32(sum_low, sum_high);\n    sum_low = _mm_hadd_epi32(sum_low, sum_low);\n    sum_low = _mm_hadd_epi32(sum_low, sum_low);\n    int total_sum = _mm_cvtsi128_si32(sum_low);\n    \n    // Check weight constraint\n    if (total_sum > w) return false;\n    \n    // Check palindrome (balanced)\n    for (int i = 0; i < n / 2; i++) {\n        if (q[i] != q[n - 1 - i]) return false;\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_96_AVX", "completion": "```cpp\nbool will_it_fly_simd(std::vector<int> q, int w) {\n    int n = q.size();\n    \n    // Check if vector is balanced (palindromic)\n    for (int i = 0; i < n / 2; i++) {\n        if (q[i] != q[n - 1 - i]) {\n            return false;\n        }\n    }\n    \n    // Compute sum of elements using AVX2\n    __m256i sum_vec = _mm256_setzero_si256();\n    \n    // Process 8 integers at a time\n    int i;\n    for (i = 0; i + 8 <= n; i += 8) {\n        __m256i curr_vec = _mm256_loadu_si256((__m256i*)&q[i]);\n        sum_vec = _mm256_add_epi32(sum_vec, curr_vec);\n    }\n    \n    // Horizontal sum of AVX vector\n    __m128i sum_128 = _mm_add_epi32(_mm256_extracti128_si256(sum_vec, 0), \n                                     _mm256_extracti128_si256(sum_vec, 1));\n    sum_128 = _mm_hadd_epi32(sum_128, sum_128);\n    sum_128 = _mm_hadd_epi32(sum_128, sum_128);\n    \n    int total_sum = _mm_cvtsi128_si32(sum_128);\n    \n    // Handle remaining elements\n    for (; i < n; i++) {\n        total_sum += q[i];\n    }\n    \n    // Check if sum is less than or equal to maximum weight\n    return total_sum <= w;\n}\n```"}
{"task_id": "SimdBench_96_AVX", "completion": "```cpp\nbool will_it_fly_simd(std::vector<int> q, int w) {\n    int n = q.size();\n    \n    // Check if sum of elements exceeds max weight\n    __m256i sum_vec = _mm256_setzero_si256();\n    for (int i = 0; i < n; i += 8) {\n        __m256i chunk = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&q[i]));\n        sum_vec = _mm256_add_epi32(sum_vec, chunk);\n    }\n    \n    // Horizontal sum of vector elements\n    __m128i sum_low = _mm256_extracti128_si256(sum_vec, 0);\n    __m128i sum_high = _mm256_extracti128_si256(sum_vec, 1);\n    sum_low = _mm_add_epi32(sum_low, sum_high);\n    sum_low = _mm_hadd_epi32(sum_low, sum_low);\n    int total_sum = _mm_cvtsi128_si32(sum_low);\n    \n    if (total_sum > w) return false;\n    \n    // Check if vector is balanced (palindromic)\n    for (int i = 0; i < n / 2; i++) {\n        if (q[i] != q[n - 1 - i]) return false;\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_96_AVX", "completion": "```cpp\nbool will_it_fly_simd(std::vector<int> q, int w) {\n    int n = q.size();\n    \n    // Check if sum of elements exceeds max weight\n    __m256i sum_vec = _mm256_setzero_si256();\n    for (int i = 0; i < n; i += 8) {\n        __m256i chunk = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&q[i]));\n        sum_vec = _mm256_add_epi32(sum_vec, chunk);\n    }\n    \n    int total_sum = 0;\n    alignas(32) int sum_array[8];\n    _mm256_store_si256(reinterpret_cast<__m256i*>(sum_array), sum_vec);\n    \n    for (int i = 0; i < (n < 8 ? n : 8); i++) {\n        total_sum += sum_array[i];\n    }\n    \n    if (total_sum > w) return false;\n    \n    // Check if vector is balanced (palindromic)\n    for (int i = 0; i < n / 2; i++) {\n        if (q[i] != q[n - 1 - i]) return false;\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_96_AVX", "completion": "```cpp\nbool will_it_fly_simd(std::vector<int> q, int w) {\n    int n = q.size();\n    \n    // Check if vector is balanced (palindromic)\n    for (int i = 0; i < n / 2; i++) {\n        if (q[i] != q[n - 1 - i]) {\n            return false;\n        }\n    }\n    \n    // Compute sum of elements using AVX2\n    __m256i sum_vec = _mm256_setzero_si256();\n    \n    // Process 8 integers at a time\n    int i;\n    for (i = 0; i + 8 <= n; i += 8) {\n        __m256i curr_vec = _mm256_loadu_si256((__m256i*)&q[i]);\n        sum_vec = _mm256_add_epi32(sum_vec, curr_vec);\n    }\n    \n    // Horizontal sum\n    __m128i sum_128 = _mm_add_epi32(_mm256_extracti128_si256(sum_vec, 0), \n                                     _mm256_extracti128_si256(sum_vec, 1));\n    sum_128 = _mm_hadd_epi32(sum_128, sum_128);\n    sum_128 = _mm_hadd_epi32(sum_128, sum_128);\n    \n    int total_sum = _mm_cvtsi128_si32(sum_128);\n    \n    // Handle remaining elements\n    for (; i < n; i++) {\n        total_sum += q[i];\n    }\n    \n    // Check if sum is less than or equal to max weight\n    return total_sum <= w;\n}\n```"}
{"task_id": "SimdBench_97_AVX", "completion": "```cpp\nint smallest_change_simd(std::vector<int> arr) {\n    int n = arr.size();\n    int changes = 0;\n    \n    // Process 8 elements at a time using AVX2\n    int vector_size = n - (n % 8);\n    \n    for (int i = 0; i < vector_size; i += 8) {\n        __m256i left = _mm256_loadu_si256((__m256i*)&arr[i]);\n        __m256i right = _mm256_loadu_si256((__m256i*)&arr[n - i - 8]);\n        \n        // Reverse the right vector\n        __m256i reversed = _mm256_shuffle_epi32(right, _MM_SHUFFLE(0, 1, 2, 3));\n        reversed = _mm256_shufflehi_epi16(reversed, _MM_SHUFFLE(0, 1, 2, 3));\n        reversed = _mm256_shufflelo_epi16(reversed, _MM_SHUFFLE(0, 1, 2, 3));\n        \n        // Compare elements\n        __m256i compare_mask = _mm256_cmpeq_epi32(left, reversed);\n        int mask = _mm256_movemask_epi8(compare_mask);\n        \n        // Count changes needed\n        changes += 8 - __builtin_popcount(mask) / 4;\n    }\n    \n    // Handle remaining elements\n    for (int i = vector_size; i < n / 2; i++) {\n        if (arr[i] != arr[n - i - 1]) {\n            changes++;\n        }\n    }\n    \n    return changes;\n}\n```"}
{"task_id": "SimdBench_97_AVX", "completion": "```cpp\nint smallest_change_simd(std::vector<int> arr) {\n    int n = arr.size();\n    int changes = 0;\n    \n    // Process 8 elements at a time using AVX2\n    int vector_size = n - (n % 8);\n    \n    for (int i = 0; i < vector_size; i += 8) {\n        __m256i left = _mm256_loadu_si256((__m256i*)&arr[i]);\n        __m256i right = _mm256_loadu_si256((__m256i*)&arr[n - i - 8]);\n        \n        // Reverse the right vector\n        __m256i reversed = _mm256_shuffle_epi32(right, _MM_SHUFFLE(0, 1, 2, 3));\n        reversed = _mm256_shufflehi_epi16(reversed, _MM_SHUFFLE(0, 1, 2, 3));\n        reversed = _mm256_shufflelo_epi16(reversed, _MM_SHUFFLE(0, 1, 2, 3));\n        \n        // Compare elements\n        __m256i compare_mask = _mm256_cmpeq_epi32(left, reversed);\n        int mask = _mm256_movemask_epi8(compare_mask);\n        \n        // Count changes needed\n        changes += 8 - __builtin_popcount(mask) / 4;\n    }\n    \n    // Handle remaining elements\n    for (int i = vector_size; i < n / 2; i++) {\n        if (arr[i] != arr[n - i - 1]) {\n            changes++;\n        }\n    }\n    \n    return changes;\n}\n```"}
{"task_id": "SimdBench_97_AVX", "completion": "```cpp\nint smallest_change_simd(std::vector<int> arr) {\n    int n = arr.size();\n    int changes = 0;\n    \n    // Process 8 elements at a time using AVX2\n    int vector_size = n - (n % 8);\n    \n    for (int i = 0; i < vector_size; i += 8) {\n        __m256i left = _mm256_loadu_si256((__m256i*)&arr[i]);\n        __m256i right = _mm256_loadu_si256((__m256i*)&arr[n - i - 8]);\n        \n        // Reverse the right vector\n        __m256i reversed = _mm256_shuffle_epi32(right, _MM_SHUFFLE(0, 1, 2, 3));\n        reversed = _mm256_shufflehi_epi16(reversed, _MM_SHUFFLE(0, 1, 2, 3));\n        reversed = _mm256_shufflelo_epi16(reversed, _MM_SHUFFLE(0, 1, 2, 3));\n        \n        // Compare elements\n        __m256i compare_mask = _mm256_cmpeq_epi32(left, reversed);\n        int mask = _mm256_movemask_ps((__m256)compare_mask);\n        \n        // Count changes\n        changes += 8 - __builtin_popcount(mask);\n    }\n    \n    // Handle remaining elements\n    for (int i = vector_size; i < n / 2; i++) {\n        if (arr[i] != arr[n - i - 1]) {\n            changes++;\n        }\n    }\n    \n    return changes;\n}\n```"}
{"task_id": "SimdBench_97_AVX", "completion": "```cpp\nint smallest_change_simd(std::vector<int> arr) {\n    int n = arr.size();\n    int changes = 0;\n    \n    // Process 8 elements at a time using AVX2\n    int vector_size = n - (n % 8);\n    \n    for (int i = 0; i < vector_size; i += 8) {\n        __m256i left = _mm256_loadu_si256((__m256i*)&arr[i]);\n        __m256i right = _mm256_loadu_si256((__m256i*)&arr[n - i - 8]);\n        \n        // Reverse the right vector\n        __m256i reversed_right = _mm256_shuffle_epi32(right, _MM_SHUFFLE(0, 1, 2, 3));\n        reversed_right = _mm256_shufflehi_epi16(reversed_right, _MM_SHUFFLE(0, 1, 2, 3));\n        reversed_right = _mm256_shufflelo_epi16(reversed_right, _MM_SHUFFLE(0, 1, 2, 3));\n        \n        // Compare elements\n        __m256i compare_mask = _mm256_cmpeq_epi32(left, reversed_right);\n        int mask = _mm256_movemask_ps((__m256)compare_mask);\n        \n        // Count changes needed\n        changes += 8 - __builtin_popcount(mask);\n    }\n    \n    // Handle remaining elements\n    for (int i = vector_size; i < n / 2; i++) {\n        if (arr[i] != arr[n - i - 1]) {\n            changes++;\n        }\n    }\n    \n    return changes;\n}\n```"}
{"task_id": "SimdBench_97_AVX", "completion": "```cpp\nint smallest_change_simd(std::vector<int> arr) {\n    int n = arr.size();\n    int changes = 0;\n    \n    // Process 8 elements at a time using AVX2\n    int vec_size = n - (n % 8);\n    for (int i = 0; i < vec_size; i += 8) {\n        __m256i left = _mm256_loadu_si256((__m256i*)&arr[i]);\n        __m256i right = _mm256_loadu_si256((__m256i*)&arr[n - i - 8]);\n        \n        // Reverse the right vector\n        __m256i reversed = _mm256_shuffle_epi32(right, _MM_SHUFFLE(0, 1, 2, 3));\n        reversed = _mm256_shufflehi_epi16(reversed, _MM_SHUFFLE(0, 1, 2, 3));\n        reversed = _mm256_shufflelo_epi16(reversed, _MM_SHUFFLE(0, 1, 2, 3));\n        \n        // Compare elements\n        __m256i cmp = _mm256_cmpeq_epi32(left, reversed);\n        int mask = _mm256_movemask_ps((__m256)cmp);\n        \n        // Count changes needed\n        changes += 8 - __builtin_popcount(mask);\n    }\n    \n    // Handle remaining elements\n    for (int i = vec_size; i < n / 2; i++) {\n        if (arr[i] != arr[n - i - 1]) {\n            changes++;\n        }\n    }\n    \n    return changes;\n}\n```"}
{"task_id": "SimdBench_98_AVX", "completion": "```cpp\nstd::vector<std::string> total_match_simd(const std::vector<std::string> & lst1, const std::vector<std::string> & lst2) {\n    // Calculate total chars for first vector\n    size_t total_chars1 = 0;\n    for (const auto& str : lst1) {\n        total_chars1 += str.length();\n    }\n\n    // Calculate total chars for second vector\n    size_t total_chars2 = 0;\n    for (const auto& str : lst2) {\n        total_chars2 += str.length();\n    }\n\n    // Return vector with fewer total characters\n    // If equal, return first vector\n    return (total_chars2 < total_chars1) ? lst2 : lst1;\n}\n```"}
{"task_id": "SimdBench_98_AVX", "completion": "```cpp\nstd::vector<std::string> total_match_simd(const std::vector<std::string> & lst1, const std::vector<std::string> & lst2) {\n    // Calculate total characters for first vector\n    int total_chars1 = 0;\n    for (const auto& str : lst1) {\n        total_chars1 += str.length();\n    }\n\n    // Calculate total characters for second vector\n    int total_chars2 = 0;\n    for (const auto& str : lst2) {\n        total_chars2 += str.length();\n    }\n\n    // Return vector with fewer total characters\n    // If equal, return first vector\n    return (total_chars2 < total_chars1) ? lst2 : lst1;\n}\n```"}
{"task_id": "SimdBench_98_AVX", "completion": "```cpp\nstd::vector<std::string> total_match_simd(const std::vector<std::string> & lst1, const std::vector<std::string> & lst2) {\n    // Calculate total characters for first vector\n    size_t total_chars1 = 0;\n    for (const auto& str : lst1) {\n        total_chars1 += str.length();\n    }\n\n    // Calculate total characters for second vector\n    size_t total_chars2 = 0;\n    for (const auto& str : lst2) {\n        total_chars2 += str.length();\n    }\n\n    // Return the vector with fewer total characters\n    // If equal, return first vector\n    return (total_chars2 < total_chars1) ? lst2 : lst1;\n}\n```"}
{"task_id": "SimdBench_98_AVX", "completion": "```cpp\nstd::vector<std::string> total_match_simd(const std::vector<std::string> & lst1, const std::vector<std::string> & lst2) {\n    // Calculate total characters for first vector\n    int total_chars1 = 0;\n    for (const auto& str : lst1) {\n        total_chars1 += str.length();\n    }\n\n    // Calculate total characters for second vector\n    int total_chars2 = 0;\n    for (const auto& str : lst2) {\n        total_chars2 += str.length();\n    }\n\n    // If total chars are equal or first vector has fewer chars, return first vector\n    if (total_chars1 <= total_chars2) {\n        return lst1;\n    }\n\n    // Otherwise return second vector\n    return lst2;\n}\n```"}
{"task_id": "SimdBench_98_AVX", "completion": "```cpp\nstd::vector<std::string> total_match_simd(const std::vector<std::string> & lst1, const std::vector<std::string> & lst2) {\n    // Calculate total characters in lst1\n    int total_chars1 = 0;\n    for (const auto& str : lst1) {\n        total_chars1 += str.length();\n    }\n\n    // Calculate total characters in lst2\n    int total_chars2 = 0;\n    for (const auto& str : lst2) {\n        total_chars2 += str.length();\n    }\n\n    // If lst1 has fewer or equal chars, return lst1\n    if (total_chars1 <= total_chars2) {\n        return lst1;\n    }\n\n    // Otherwise return lst2\n    return lst2;\n}\n```"}
{"task_id": "SimdBench_99_AVX", "completion": "```cpp\nbool is_simple_power_simd(uint64_t x, uint64_t n) {\n    // Special case handling\n    if (n <= 1 || x == 1) return false;\n    if (x == n) return true;\n\n    // Use AVX2 to compute powers in parallel\n    __m256i x_vec = _mm256_set1_epi64x(x);\n    __m256i n_vec = _mm256_set1_epi64x(n);\n    __m256i current_power = _mm256_set1_epi64x(n);\n    __m256i one_vec = _mm256_set1_epi64x(1);\n\n    // Compute powers up to log2(x)\n    for (int i = 2; i <= 64; i++) {\n        current_power = _mm256_mul_epi64(current_power, n_vec);\n        \n        // Compare if current power matches x\n        __m256i cmp = _mm256_cmpeq_epi64(current_power, x_vec);\n        \n        // Check if any lane matches\n        if (_mm256_movemask_epi8(cmp) != 0) {\n            return true;\n        }\n\n        // Prevent overflow\n        if (current_power == x_vec) break;\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_99_AVX", "completion": "```cpp\nbool is_simple_power_simd(uint64_t x, uint64_t n) {\n    if (n <= 1) return false;\n    if (x == 1) return true;\n\n    __m256d base_vec = _mm256_set1_pd((double)n);\n    __m256d x_vec = _mm256_set1_pd((double)x);\n    \n    double result[4];\n    double current = n;\n    \n    while (current <= x) {\n        __m256d current_vec = _mm256_set1_pd(current);\n        __m256d compare_vec = _mm256_cmp_pd(current_vec, x_vec, _CMP_EQ_OQ);\n        \n        _mm256_storeu_pd(result, compare_vec);\n        \n        if (result[0] || result[1] || result[2] || result[3]) {\n            return true;\n        }\n        \n        current *= n;\n    }\n    \n    return false;\n}\n```"}
{"task_id": "SimdBench_99_AVX", "completion": "```cpp\nbool is_simple_power_simd(uint64_t x, uint64_t n) {\n    // Special case handling\n    if (n <= 1 || x == 0) return false;\n    if (x == 1) return true;\n\n    // Compute log base n of x\n    double log_x = log(x);\n    double log_n = log(n);\n    double log_result = log_x / log_n;\n\n    // Use AVX intrinsics to check if log_result is an integer\n    __m256d val = _mm256_set1_pd(log_result);\n    __m256d floor_val = _mm256_floor_pd(val);\n    __m256d diff = _mm256_sub_pd(val, floor_val);\n    \n    // Check if the difference is very close to zero\n    __m256d epsilon = _mm256_set1_pd(1e-10);\n    __m256d abs_diff = _mm256_andnot_pd(_mm256_set1_pd(-0.0), diff);\n    __m256d comparison = _mm256_cmp_pd(abs_diff, epsilon, _CMP_LT_OQ);\n\n    // Extract the comparison result\n    int mask = _mm256_movemask_pd(comparison);\n    \n    return mask != 0;\n}\n```"}
{"task_id": "SimdBench_99_AVX", "completion": "```cpp\nbool is_simple_power_simd(uint64_t x, uint64_t n) {\n    if (n <= 1) return false;\n    if (x == 1) return true;\n\n    __m256d base_vec = _mm256_set1_pd(static_cast<double>(n));\n    __m256d x_vec = _mm256_set1_pd(static_cast<double>(x));\n    \n    double result[4];\n    double current = n;\n    \n    while (current <= x) {\n        __m256d current_vec = _mm256_set1_pd(current);\n        __m256d compare_vec = _mm256_cmp_pd(current_vec, x_vec, _CMP_EQ_OQ);\n        \n        _mm256_storeu_pd(result, compare_vec);\n        \n        if (result[0] || result[1] || result[2] || result[3]) {\n            return true;\n        }\n        \n        current *= n;\n    }\n    \n    return false;\n}\n```"}
{"task_id": "SimdBench_99_AVX", "completion": "```cpp\nbool is_simple_power_simd(uint64_t x, uint64_t n) {\n    // Special case handling\n    if (n <= 1 || x == 0) return false;\n    if (x == 1) return true;\n\n    // Use log approach with AVX2 intrinsics\n    __m256d log_x = _mm256_set1_pd(log(x));\n    __m256d log_n = _mm256_set1_pd(log(n));\n    \n    // Compute log(x) / log(n)\n    __m256d div_result = _mm256_div_pd(log_x, log_n);\n    \n    // Round the result\n    __m256d rounded = _mm256_round_pd(div_result, _MM_FROUND_TO_NEAREST_INT);\n    \n    // Check if rounded result is an integer and matches original division\n    __m256d diff = _mm256_sub_pd(div_result, rounded);\n    \n    // Compare absolute difference with small epsilon\n    __m256d epsilon = _mm256_set1_pd(1e-10);\n    __m256d abs_diff = _mm256_andnot_pd(_mm256_set1_pd(-0.0), diff);\n    \n    // Horizontal comparison\n    int mask = _mm256_movemask_pd(_mm256_cmp_pd(abs_diff, epsilon, _CMP_LT_OQ));\n    \n    return mask != 0 && pow(n, round(log(x) / log(n))) == x;\n}\n```"}
{"task_id": "SimdBench_100_AVX", "completion": "```cpp\nint hex_key_simd(const std::string & num) {\n    // Prime hex digits: 2, 3, 5, 7, B (11), D (13)\n    const __m256i prime_mask = _mm256_setr_epi8(\n        0, 0, 1, 1, 0, 1, 0, 1,  // 0-7\n        0, 0, 0, 1, 0, 1, 0, 0,  // 8-F\n        0, 0, 0, 0, 0, 0, 0, 0,  // 16-23\n        0, 0, 0, 0, 0, 0, 0, 0   // 24-31\n    );\n\n    int prime_count = 0;\n    size_t len = num.length();\n\n    // Process 32 characters at a time\n    for (size_t i = 0; i <= len - 32; i += 32) {\n        __m256i chars = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(num.data() + i));\n        \n        // Convert hex characters to their numeric values\n        __m256i numeric_values = _mm256_and_si256(\n            _mm256_or_si256(\n                _mm256_sub_epi8(chars, _mm256_set1_epi8('0')),\n                _mm256_and_si256(_mm256_sub_epi8(chars, _mm256_set1_epi8('A')), _mm256_set1_epi8(0x10))\n            ),\n            _mm256_set1_epi8(0x0F)\n        );\n\n        // Check which characters are prime\n        __m256i is_prime = _mm256_shuffle_epi8(prime_mask, numeric_values);\n        \n        // Count prime digits\n        prime_count += _mm_popcnt_u32(_mm256_movemask_epi8(is_prime));\n    }\n\n    // Handle remaining characters\n    for (size_t i = len - (len % 32); i < len; ++i) {\n        char c = num[i];\n        int val = (c >= 'A') ? (c - 'A' + 10) : (c - '0');\n        if (val == 2 || val == 3 || val == 5 || val == 7 || val == 11 || val == 13) {\n            ++prime_count;\n        }\n    }\n\n    return prime_count;\n}\n```"}
{"task_id": "SimdBench_100_AVX", "completion": "```cpp\nint hex_key_simd(const std::string & num) {\n    if (num.empty()) return 0;\n\n    // Prime hex digits: 2, 3, 5, 7, B (11), D (13)\n    const __m256i prime_mask = _mm256_setr_epi8(\n        0, 0, 1, 1, 0, 1, 0, 1,  // 0-7\n        0, 0, 0, 1, 0, 1, 0, 0,  // 8-F\n        0, 0, 0, 0, 0, 0, 0, 0,  // 10-17\n        0, 0, 0, 0, 0, 0, 0, 0   // 18-1F\n    );\n\n    int prime_count = 0;\n    size_t i = 0;\n\n    // Process 32 characters at a time using AVX\n    for (; i + 32 <= num.length(); i += 32) {\n        __m256i input = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&num[i]));\n        \n        // Convert hex characters to their numeric values\n        __m256i zero = _mm256_setzero_si256();\n        __m256i is_alpha = _mm256_cmpgt_epi8(input, _mm256_set1_epi8('9'));\n        __m256i alpha_adjust = _mm256_and_si256(is_alpha, _mm256_set1_epi8('A' - '9' - 1));\n        __m256i numeric_val = _mm256_sub_epi8(input, _mm256_sub_epi8(_mm256_set1_epi8('0'), alpha_adjust));\n        \n        // Mask out values > 15\n        __m256i valid_mask = _mm256_cmpgt_epi8(_mm256_set1_epi8(15), numeric_val);\n        numeric_val = _mm256_and_si256(numeric_val, valid_mask);\n        \n        // Check prime digits using the precomputed mask\n        __m256i prime_check = _mm256_shuffle_epi8(prime_mask, numeric_val);\n        \n        // Count prime digits\n        __m256i count_mask = _mm256_cmpeq_epi8(prime_check, _mm256_set1_epi8(1));\n        prime_count += _mm_popcnt_u32(_mm256_movemask_epi8(count_mask));\n    }\n\n    // Handle remaining characters\n    for (; i < num.length(); ++i) {\n        char c = num[i];\n        int val = (c >= 'A') ? (c - 'A' + 10) : (c - '0');\n        if (val == 2 || val == 3 || val == 5 || val == 7 || \n            val == 11 || val == 13) {\n            ++prime_count;\n        }\n    }\n\n    return prime_count;\n}\n```"}
{"task_id": "SimdBench_100_AVX", "completion": "```cpp\nint hex_key_simd(const std::string & num) {\n    // Prime hex digits: 2, 3, 5, 7, B (11), D (13)\n    const __m256i prime_mask = _mm256_setr_epi8(\n        0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0,\n        0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0\n    );\n\n    int prime_count = 0;\n    size_t len = num.length();\n\n    // Process 32 characters at a time\n    for (size_t i = 0; i + 32 <= len; i += 32) {\n        __m256i chars = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(num.data() + i));\n        \n        // Convert hex chars to 0-15 range\n        __m256i hex_values = _mm256_sub_epi8(chars, _mm256_set1_epi8('0'));\n        __m256i alpha_mask = _mm256_cmpgt_epi8(chars, _mm256_set1_epi8('9'));\n        __m256i alpha_adjust = _mm256_and_si256(alpha_mask, _mm256_set1_epi8(7));\n        hex_values = _mm256_add_epi8(hex_values, alpha_adjust);\n\n        // Check prime mask\n        __m256i is_prime = _mm256_shuffle_epi8(prime_mask, hex_values);\n        \n        // Count prime digits\n        __m256i zero = _mm256_setzero_si256();\n        is_prime = _mm256_cmpgt_epi8(is_prime, zero);\n        prime_count += _mm_popcnt_u32(_mm256_movemask_epi8(is_prime));\n    }\n\n    // Handle remaining characters\n    for (size_t i = len - (len % 32); i < len; ++i) {\n        char c = num[i];\n        int val = (c >= '0' && c <= '9') ? c - '0' : \n                  (c >= 'A' && c <= 'F') ? c - 'A' + 10 : -1;\n        \n        if (val == 2 || val == 3 || val == 5 || val == 7 || \n            val == 11 || val == 13) {\n            ++prime_count;\n        }\n    }\n\n    return prime_count;\n}\n```"}
{"task_id": "SimdBench_100_AVX", "completion": "```cpp\nint hex_key_simd(const std::string & num) {\n    // Prime hex digits: 2, 3, 5, 7, B (11), D (13)\n    const __m256i prime_mask = _mm256_setr_epi8(\n        0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0,\n        0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0\n    );\n\n    int prime_count = 0;\n    size_t len = num.length();\n\n    // Process 32 characters at a time\n    for (size_t i = 0; i + 32 <= len; i += 32) {\n        __m256i chars = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(num.data() + i));\n        \n        // Convert hex characters to 0-15 range\n        __m256i hex_values = _mm256_sub_epi8(chars, _mm256_set1_epi8('0'));\n        __m256i alpha_mask = _mm256_cmpgt_epi8(chars, _mm256_set1_epi8('9'));\n        __m256i alpha_adjust = _mm256_and_si256(alpha_mask, _mm256_set1_epi8(7));\n        hex_values = _mm256_add_epi8(hex_values, alpha_adjust);\n\n        // Check prime mask\n        __m256i prime_check = _mm256_shuffle_epi8(prime_mask, hex_values);\n        \n        // Count set bits (prime digits)\n        prime_count += _mm_popcnt_u32(_mm256_movemask_epi8(prime_check));\n    }\n\n    // Handle remaining characters\n    for (size_t i = len - (len % 32); i < len; ++i) {\n        char c = num[i];\n        int val = (c <= '9') ? (c - '0') : (c - 'A' + 10);\n        if ((val == 2) || (val == 3) || (val == 5) || (val == 7) || \n            (val == 11) || (val == 13)) {\n            ++prime_count;\n        }\n    }\n\n    return prime_count;\n}\n```"}
{"task_id": "SimdBench_100_AVX", "completion": "```cpp\nint hex_key_simd(const std::string & num) {\n    // Prime hex digits: 2, 3, 5, 7, B (11), D (13)\n    const __m256i prime_mask = _mm256_setr_epi8(\n        0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0,\n        0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0\n    );\n\n    int prime_count = 0;\n    size_t len = num.length();\n\n    // Process 32 characters at a time\n    for (size_t i = 0; i + 32 <= len; i += 32) {\n        __m256i chars = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(num.data() + i));\n        \n        // Convert hex chars to numeric values\n        __m256i numeric_vals = _mm256_sub_epi8(chars, _mm256_set1_epi8('0'));\n        __m256i alpha_offset = _mm256_set1_epi8('A' - '0' - 10);\n        __m256i alpha_mask = _mm256_cmpgt_epi8(chars, _mm256_set1_epi8('9'));\n        __m256i alpha_vals = _mm256_and_si256(alpha_mask, alpha_offset);\n        __m256i hex_vals = _mm256_add_epi8(numeric_vals, alpha_vals);\n\n        // Check prime digits using precomputed mask\n        __m256i prime_check = _mm256_and_si256(prime_mask, _mm256_cmpgt_epi8(hex_vals, _mm256_set1_epi8(-1)));\n        prime_count += _mm256_popcnt_epi8(prime_check);\n    }\n\n    // Handle remaining characters\n    for (size_t i = len - (len % 32); i < len; ++i) {\n        char c = num[i];\n        int val = (c >= 'A') ? (c - 'A' + 10) : (c - '0');\n        if (val == 2 || val == 3 || val == 5 || val == 7 || val == 11 || val == 13) {\n            ++prime_count;\n        }\n    }\n\n    return prime_count;\n}\n```"}
{"task_id": "SimdBench_101_AVX", "completion": "```cpp\nbool is_happy_simd(const std::string & s) {\n    int len = s.length();\n    if (len < 3) return false;\n\n    // Process 32 bytes at a time using AVX2\n    int vectorLen = len - (len % 32);\n    for (int i = 0; i <= vectorLen - 32; i += 32) {\n        __m256i chunk = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&s[i]));\n        \n        // Compare each byte with its neighbors\n        for (int j = 0; j < 10; ++j) {\n            __m256i first = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&s[i + j]));\n            __m256i second = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&s[i + j + 1]));\n            __m256i third = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&s[i + j + 2]));\n            \n            // Check if any three consecutive bytes are the same\n            __m256i eq1 = _mm256_cmpeq_epi8(first, second);\n            __m256i eq2 = _mm256_cmpeq_epi8(first, third);\n            __m256i eq3 = _mm256_cmpeq_epi8(second, third);\n            \n            __m256i combined = _mm256_or_si256(_mm256_or_si256(eq1, eq2), eq3);\n            \n            if (_mm256_movemask_epi8(combined) != 0) {\n                return false;\n            }\n        }\n    }\n\n    // Handle remaining bytes\n    for (int i = vectorLen; i < len - 2; ++i) {\n        if (s[i] == s[i+1] || s[i] == s[i+2] || s[i+1] == s[i+2]) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_101_AVX", "completion": "```cpp\nbool is_happy_simd(const std::string & s) {\n    int len = s.length();\n    if (len < 3) return false;\n\n    // Process 32 bytes at a time using AVX2\n    int vectorLen = len - (len % 32);\n    for (int i = 0; i <= vectorLen - 32; i += 32) {\n        __m256i chunk = _mm256_loadu_si256((__m256i*)&s[i]);\n        \n        // Compare adjacent bytes\n        __m256i shifted1 = _mm256_srli_si256(chunk, 1);\n        __m256i shifted2 = _mm256_srli_si256(chunk, 2);\n        \n        // Check for duplicates in 3-byte windows\n        __m256i cmp1 = _mm256_cmpeq_epi8(chunk, shifted1);\n        __m256i cmp2 = _mm256_cmpeq_epi8(chunk, shifted2);\n        __m256i cmp3 = _mm256_cmpeq_epi8(shifted1, shifted2);\n        \n        __m256i combined = _mm256_or_si256(_mm256_or_si256(cmp1, cmp2), cmp3);\n        \n        if (_mm256_movemask_epi8(combined) != 0) {\n            return false;\n        }\n    }\n\n    // Handle remaining bytes\n    for (int i = vectorLen; i < len - 2; ++i) {\n        if (s[i] == s[i+1] || s[i] == s[i+2] || s[i+1] == s[i+2]) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_101_AVX", "completion": "```cpp\nbool is_happy_simd(const std::string & s) {\n    int len = s.length();\n    if (len < 3) return false;\n\n    // Process 32 bytes at a time using AVX2\n    int vectorLen = len - (len % 32);\n    for (int i = 0; i <= vectorLen - 32; i += 32) {\n        __m256i chunk = _mm256_loadu_si256((__m256i*)&s[i]);\n        \n        // Compare each byte with its neighbors\n        for (int j = 0; j < 10; ++j) {\n            __m256i shifted1 = _mm256_srli_si256(chunk, 1);\n            __m256i shifted2 = _mm256_srli_si256(chunk, 2);\n            \n            // Check if any 3 consecutive bytes are the same\n            __m256i eq1 = _mm256_cmpeq_epi8(chunk, shifted1);\n            __m256i eq2 = _mm256_cmpeq_epi8(chunk, shifted2);\n            \n            __m256i combined = _mm256_or_si256(eq1, eq2);\n            \n            if (_mm256_movemask_epi8(combined) != 0) {\n                return false;\n            }\n            \n            chunk = shifted1;\n        }\n    }\n\n    // Process remaining bytes sequentially\n    for (int i = vectorLen; i < len - 2; ++i) {\n        if (s[i] == s[i+1] || s[i] == s[i+2] || s[i+1] == s[i+2]) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_101_AVX", "completion": "```cpp\nbool is_happy_simd(const std::string & s) {\n    int len = s.length();\n    \n    // Strings shorter than 3 are not happy\n    if (len < 3) return false;\n    \n    // Process 16 characters at a time using AVX2\n    int vectorLen = len - (len % 16);\n    \n    for (int i = 0; i <= vectorLen - 16; i += 16) {\n        __m256i chunk1 = _mm256_loadu_si256((__m256i*)&s[i]);\n        __m256i chunk2 = _mm256_loadu_si256((__m256i*)&s[i+16]);\n        \n        // Compare each character with its neighbors\n        for (int j = 0; j < 14; ++j) {\n            __m256i a = _mm256_loadu_si256((__m256i*)&s[i+j]);\n            __m256i b = _mm256_loadu_si256((__m256i*)&s[i+j+1]);\n            __m256i c = _mm256_loadu_si256((__m256i*)&s[i+j+2]);\n            \n            // Check if any 3 consecutive characters are the same\n            __m256i eq1 = _mm256_cmpeq_epi8(a, b);\n            __m256i eq2 = _mm256_cmpeq_epi8(b, c);\n            __m256i eq3 = _mm256_cmpeq_epi8(a, c);\n            \n            __m256i combined = _mm256_or_si256(_mm256_or_si256(eq1, eq2), eq3);\n            \n            if (_mm256_movemask_epi8(combined) != 0) {\n                return false;\n            }\n        }\n    }\n    \n    // Process remaining characters sequentially\n    for (int i = vectorLen; i < len - 2; ++i) {\n        if (s[i] == s[i+1] || s[i] == s[i+2] || s[i+1] == s[i+2]) {\n            return false;\n        }\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_101_AVX", "completion": "```cpp\nbool is_happy_simd(const std::string & s) {\n    int len = s.length();\n    \n    // Strings shorter than 3 are not happy\n    if (len < 3) return false;\n    \n    // Process 32 bytes at a time using AVX2\n    int vectorLen = len - 2;\n    for (int i = 0; i <= vectorLen - 8; i += 8) {\n        __m256i chunk = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(s.data() + i));\n        \n        // Broadcast each character to compare\n        __m256i a = _mm256_set1_epi8(s[i]);\n        __m256i b = _mm256_set1_epi8(s[i+1]);\n        __m256i c = _mm256_set1_epi8(s[i+2]);\n        \n        // Check if any characters are the same\n        __m256i eqA = _mm256_cmpeq_epi8(chunk, a);\n        __m256i eqB = _mm256_cmpeq_epi8(chunk, b);\n        __m256i eqC = _mm256_cmpeq_epi8(chunk, c);\n        \n        // Combine equality checks\n        __m256i combined = _mm256_or_si256(_mm256_or_si256(eqA, eqB), eqC);\n        \n        // If any bits are set, not a happy string\n        if (_mm256_movemask_epi8(combined) != 0) {\n            return false;\n        }\n    }\n    \n    // Check remaining elements\n    for (int i = std::max(0, vectorLen - 8); i < vectorLen; i++) {\n        if (s[i] == s[i+1] || s[i] == s[i+2] || s[i+1] == s[i+2]) {\n            return false;\n        }\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_102_AVX", "completion": "```cpp\nbool prime_length_simd(const std::string& str) {\n    int len = str.length();\n    \n    // Handle small lengths directly\n    if (len <= 1) return false;\n    if (len == 2 || len == 3) return true;\n    if (len % 2 == 0 || len % 3 == 0) return false;\n\n    // Use AVX2 to parallelize primality check\n    __m256i divisors = _mm256_setr_epi32(5, 7, 11, 13, 17, 19, 23, 29);\n    __m256i length_vec = _mm256_set1_epi32(len);\n    \n    for (int i = 0; i < 8; i++) {\n        __m256i div = _mm256_set1_epi32(_mm256_extract_epi32(divisors, i));\n        __m256i mod = _mm256_set1_epi32(0);\n        \n        // Compute modulo in parallel\n        mod = _mm256_rem_epi32(length_vec, div);\n        \n        // Check if any remainder is zero\n        if (_mm256_movemask_epi8(_mm256_cmpeq_epi32(mod, _mm256_setzero_si256())) != 0) {\n            return false;\n        }\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_102_AVX", "completion": "```cpp\nbool prime_length_simd(const std::string & str) {\n    int len = str.length();\n    \n    // Handle small lengths directly\n    if (len <= 1) return false;\n    if (len == 2 || len == 3) return true;\n    if (len % 2 == 0 || len % 3 == 0) return false;\n\n    // Use AVX2 to parallelize primality check\n    __m256i divisors = _mm256_setr_epi32(5, 7, 11, 13, 17, 19, 23, 29);\n    __m256i length_vec = _mm256_set1_epi32(len);\n    \n    for (int i = 0; i < 8; i++) {\n        __m256i div_squared = _mm256_mullo_epi32(divisors, divisors);\n        __m256i mask = _mm256_cmpgt_epi32(div_squared, length_vec);\n        \n        if (_mm256_movemask_epi8(mask) == 0xFFFFFFFF) break;\n        \n        __m256i remainder = _mm256_set1_epi32(0);\n        remainder = _mm256_rem_epi32(length_vec, divisors);\n        \n        if (_mm256_movemask_epi8(_mm256_cmpeq_epi32(remainder, _mm256_setzero_si256())) != 0) {\n            return false;\n        }\n        \n        divisors = _mm256_add_epi32(divisors, _mm256_set1_epi32(30));\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_102_AVX", "completion": "```cpp\nbool prime_length_simd(const std::string & str) {\n    int len = str.length();\n    \n    // Handle small lengths directly\n    if (len <= 1) return false;\n    if (len == 2 || len == 3) return true;\n    if (len % 2 == 0 || len % 3 == 0) return false;\n\n    // Use AVX2 to parallelize primality check\n    __m256i divisors = _mm256_setr_epi32(5, 7, 11, 13, 17, 19, 23, 29);\n    __m256i length_vec = _mm256_set1_epi32(len);\n    \n    for (int i = 0; i < 8; i++) {\n        __m256i div_squared = _mm256_mullo_epi32(divisors, divisors);\n        __m256i mask = _mm256_cmpgt_epi32(div_squared, length_vec);\n        \n        if (_mm256_movemask_epi8(mask) == 0xFFFFFFFF) {\n            break;\n        }\n        \n        __m256i rem = _mm256_set1_epi32(0);\n        for (__m256i j = divisors; _mm256_movemask_epi8(_mm256_cmpgt_epi32(length_vec, j)) != 0; j = _mm256_add_epi32(j, _mm256_set1_epi32(30))) {\n            rem = _mm256_set1_epi32(len % _mm256_cvtsi256_si32(divisors));\n            if (_mm256_movemask_epi8(_mm256_cmpeq_epi32(rem, _mm256_setzero_si256())) != 0) {\n                return false;\n            }\n        }\n        \n        divisors = _mm256_add_epi32(divisors, _mm256_set1_epi32(30));\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_102_AVX", "completion": "```cpp\nbool prime_length_simd(const std::string & str) {\n    int len = str.length();\n    \n    // Quick check for small lengths\n    if (len <= 1) return false;\n    if (len == 2 || len == 3 || len == 5 || len == 7) return true;\n    if (len % 2 == 0 || len % 3 == 0) return false;\n\n    // Use AVX2 for parallel primality checking\n    __m256i divisors = _mm256_setr_epi32(5, 7, 11, 13, 17, 19, 23, 29);\n    __m256i length_vec = _mm256_set1_epi32(len);\n    \n    for (int i = 0; i < 8; i++) {\n        __m256i div_vec = _mm256_set1_epi32(_mm256_extract_epi32(divisors, i));\n        __m256i mod_result = _mm256_mod_epi32(length_vec, div_vec);\n        \n        if (_mm256_testz_si256(mod_result, mod_result) == 0) {\n            return false;\n        }\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_102_AVX", "completion": "```cpp\nbool prime_length_simd(const std::string & str) {\n    int len = str.length();\n    \n    // Handle small lengths directly\n    if (len <= 1) return false;\n    if (len == 2 || len == 3) return true;\n    if (len % 2 == 0 || len % 3 == 0) return false;\n    \n    // Use AVX2 to parallelize primality check\n    __m256i divisors = _mm256_setr_epi32(5, 7, 11, 13, 17, 19, 23, 29);\n    __m256i length_vec = _mm256_set1_epi32(len);\n    \n    for (int i = 0; i < 8; i++) {\n        __m256i div_squared = _mm256_mullo_epi32(divisors, divisors);\n        __m256i mask = _mm256_cmpgt_epi32(div_squared, length_vec);\n        \n        if (_mm256_movemask_epi8(mask) == 0xFFFFFFFF) {\n            break;\n        }\n        \n        __m256i remainder = _mm256_set1_epi32(0);\n        remainder = _mm256_rem_epi32(length_vec, divisors);\n        \n        if (_mm256_movemask_epi8(_mm256_cmpeq_epi32(remainder, _mm256_setzero_si256())) != 0) {\n            return false;\n        }\n        \n        divisors = _mm256_add_epi32(divisors, _mm256_set1_epi32(30));\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_103_AVX", "completion": "```cpp\nstd::string solve_simd(uint64_t N) {\n    // Initialize sum of digits\n    uint64_t digit_sum = 0;\n\n    // Extract digits using SIMD-like approach\n    while (N > 0) {\n        uint64_t digit = N % 10;\n        digit_sum += __builtin_popcount(digit);\n        N /= 10;\n    }\n\n    // Convert digit sum to binary string\n    std::string binary;\n    while (digit_sum > 0) {\n        binary = std::to_string(digit_sum % 2) + binary;\n        digit_sum /= 2;\n    }\n\n    return binary.empty() ? \"0\" : binary;\n}\n```"}
{"task_id": "SimdBench_103_AVX", "completion": "```cpp\nstd::string solve_simd(uint64_t N) {\n    // Initialize sum of digits\n    uint64_t digit_sum = 0;\n\n    // Extract digits using AVX2 parallel processing\n    while (N > 0) {\n        // Use AVX2 to process multiple digits simultaneously\n        __m256i digits = _mm256_set1_epi64x(N % 10);\n        __m256i sum_vec = _mm256_sad_epu8(digits, _mm256_setzero_si256());\n        \n        // Add extracted digit to total sum\n        digit_sum += _mm256_extract_epi64(sum_vec, 0);\n\n        // Reduce N by dividing by 10\n        N /= 10;\n    }\n\n    // Convert digit sum to binary string\n    std::string binary;\n    while (digit_sum > 0) {\n        binary = std::to_string(digit_sum % 2) + binary;\n        digit_sum /= 2;\n    }\n\n    return binary.empty() ? \"0\" : binary;\n}\n```"}
{"task_id": "SimdBench_103_AVX", "completion": "```cpp\nstd::string solve_simd(uint64_t N) {\n    // Initialize sum of digits\n    uint64_t digit_sum = 0;\n    \n    // Process digits using SIMD\n    while (N > 0) {\n        // Extract digits using SIMD division and modulo operations\n        __m256i digits = _mm256_set1_epi64x(N);\n        __m256i divisors = _mm256_set_epi64x(10000, 1000, 100, 10);\n        __m256i zeros = _mm256_setzero_si256();\n        \n        // Parallel division to extract digits\n        __m256i extracted_digits = _mm256_div_epu64(digits, divisors);\n        __m256i mods = _mm256_sub_epi64(digits, _mm256_mul_epu64(extracted_digits, divisors));\n        \n        // Sum extracted digits\n        __m256i sum_vec = _mm256_add_epi64(extracted_digits, mods);\n        \n        // Horizontal sum of digits\n        sum_vec = _mm256_hadd_epi64(sum_vec, sum_vec);\n        digit_sum += _mm256_extract_epi64(sum_vec, 0);\n        \n        // Reduce N\n        N /= 10000;\n    }\n    \n    // Convert sum to binary string\n    std::string binary;\n    while (digit_sum > 0) {\n        binary = std::to_string(digit_sum % 2) + binary;\n        digit_sum /= 2;\n    }\n    \n    return binary.empty() ? \"0\" : binary;\n}\n```"}
{"task_id": "SimdBench_103_AVX", "completion": "```cpp\nstd::string solve_simd(uint64_t N) {\n    // Initialize variables\n    __m256i sum_vector = _mm256_setzero_si256();\n    __m256i one_vector = _mm256_set1_epi64x(1);\n    \n    // Extract digits\n    while (N > 0) {\n        uint64_t digit = N % 10;\n        N /= 10;\n        \n        // Use AVX2 to accumulate digit sum\n        __m256i digit_vector = _mm256_set1_epi64x(digit);\n        __m256i popcnt_vector = _mm256_popcnt_epi64(digit_vector);\n        sum_vector = _mm256_add_epi64(sum_vector, popcnt_vector);\n    }\n    \n    // Extract total sum\n    uint64_t total_sum = _mm256_extract_epi64(sum_vector, 0) +\n                         _mm256_extract_epi64(sum_vector, 1) +\n                         _mm256_extract_epi64(sum_vector, 2) +\n                         _mm256_extract_epi64(sum_vector, 3);\n    \n    // Convert to binary string\n    std::string binary;\n    while (total_sum > 0) {\n        binary = std::to_string(total_sum & 1) + binary;\n        total_sum >>= 1;\n    }\n    \n    return binary.empty() ? \"0\" : binary;\n}\n```"}
{"task_id": "SimdBench_103_AVX", "completion": "```cpp\nstd::string solve_simd(uint64_t N) {\n    // Initialize sum of digits\n    uint64_t digit_sum = 0;\n\n    // Extract digits using SIMD-like approach\n    while (N > 0) {\n        uint64_t digit = N % 10;\n        digit_sum += __builtin_popcount(digit);\n        N /= 10;\n    }\n\n    // Convert digit sum to binary string\n    std::string binary_result;\n    while (digit_sum > 0) {\n        binary_result = std::to_string(digit_sum & 1) + binary_result;\n        digit_sum >>= 1;\n    }\n\n    return binary_result.empty() ? \"0\" : binary_result;\n}\n```"}
{"task_id": "SimdBench_104_AVX", "completion": "```cpp\nint add_simd(std::vector<int> lst) {\n    int result = 0;\n    int size = lst.size();\n    \n    // Process 8 elements at a time using AVX2\n    int vectorized_size = size - (size % 8);\n    __m256i sum_vec = _mm256_setzero_si256();\n    \n    for (int i = 0; i < vectorized_size; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&lst[i]);\n        \n        // Create mask for odd indices\n        __m256i indices = _mm256_setr_epi32(1, 3, 5, 7, 9, 11, 13, 15);\n        __m256i mask = _mm256_cmpeq_epi32(_mm256_and_si256(indices, _mm256_set1_epi32(1)), _mm256_set1_epi32(1));\n        \n        // Mask elements at odd indices\n        __m256i masked_vec = _mm256_and_si256(vec, mask);\n        \n        // Create mask for even elements\n        __m256i even_mask = _mm256_cmpeq_epi32(_mm256_and_si256(masked_vec, _mm256_set1_epi32(1)), _mm256_setzero_si256());\n        \n        // Mask even elements at odd indices\n        __m256i even_elements = _mm256_and_si256(masked_vec, even_mask);\n        \n        // Add to sum vector\n        sum_vec = _mm256_add_epi32(sum_vec, even_elements);\n    }\n    \n    // Horizontal sum of vector\n    __m128i sum_low = _mm256_extracti128_si256(sum_vec, 0);\n    __m128i sum_high = _mm256_extracti128_si256(sum_vec, 1);\n    sum_low = _mm_add_epi32(sum_low, sum_high);\n    sum_low = _mm_hadd_epi32(sum_low, sum_low);\n    sum_low = _mm_hadd_epi32(sum_low, sum_low);\n    \n    result = _mm_cvtsi128_si32(sum_low);\n    \n    // Handle remaining elements\n    for (int i = vectorized_size; i < size; i++) {\n        if (i % 2 == 1 && lst[i] % 2 == 0) {\n            result += lst[i];\n        }\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_104_AVX", "completion": "```cpp\nint add_simd(std::vector<int> lst) {\n    int result = 0;\n    int size = lst.size();\n    \n    // Process 8 elements at a time using AVX2\n    int vectorSize = size - (size % 8);\n    __m256i sum_vec = _mm256_setzero_si256();\n    \n    for (int i = 0; i < vectorSize; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&lst[i]);\n        \n        // Create mask for odd indices\n        __m256i indices = _mm256_setr_epi32(1, 3, 5, 7, 9, 11, 13, 15);\n        __m256i mask = _mm256_cmpeq_epi32(_mm256_and_si256(indices, _mm256_set1_epi32(1)), _mm256_set1_epi32(1));\n        \n        // Select elements at odd indices\n        __m256i odd_indices_vec = _mm256_blendv_epi8(_mm256_setzero_si256(), vec, mask);\n        \n        // Create mask for even elements\n        __m256i even_mask = _mm256_cmpeq_epi32(_mm256_and_si256(odd_indices_vec, _mm256_set1_epi32(1)), _mm256_setzero_si256());\n        \n        // Select even elements at odd indices\n        __m256i even_vec = _mm256_and_si256(odd_indices_vec, even_mask);\n        \n        // Add to sum vector\n        sum_vec = _mm256_add_epi32(sum_vec, even_vec);\n    }\n    \n    // Horizontal sum\n    __m128i sum_low = _mm256_extracti128_si256(sum_vec, 0);\n    __m128i sum_high = _mm256_extracti128_si256(sum_vec, 1);\n    sum_low = _mm_add_epi32(sum_low, sum_high);\n    sum_low = _mm_hadd_epi32(sum_low, sum_low);\n    sum_low = _mm_hadd_epi32(sum_low, sum_low);\n    \n    result = _mm_cvtsi128_si32(sum_low);\n    \n    // Handle remaining elements\n    for (int i = vectorSize; i < size; i++) {\n        if (i % 2 == 1 && lst[i] % 2 == 0) {\n            result += lst[i];\n        }\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_104_AVX", "completion": "```cpp\nint add_simd(std::vector<int> lst) {\n    int result = 0;\n    int size = lst.size();\n    \n    // Process 8 elements at a time using AVX2\n    int vector_size = size - (size % 8);\n    __m256i sum_vector = _mm256_setzero_si256();\n    \n    for (int i = 0; i < vector_size; i += 8) {\n        __m256i data = _mm256_loadu_si256((__m256i*)&lst[i]);\n        \n        // Create mask for odd indices\n        __m256i indices = _mm256_setr_epi32(1, 3, 5, 7, 9, 11, 13, 15);\n        __m256i mask = _mm256_cmpeq_epi32(_mm256_and_si256(indices, _mm256_set1_epi32(1)), _mm256_set1_epi32(1));\n        \n        // Select elements at odd indices\n        __m256i odd_indices_data = _mm256_blendv_epi8(_mm256_setzero_si256(), data, mask);\n        \n        // Create mask for even elements\n        __m256i even_mask = _mm256_cmpeq_epi32(_mm256_and_si256(odd_indices_data, _mm256_set1_epi32(1)), _mm256_setzero_si256());\n        \n        // Select even elements at odd indices\n        __m256i even_elements = _mm256_and_si256(odd_indices_data, even_mask);\n        \n        // Add to sum vector\n        sum_vector = _mm256_add_epi32(sum_vector, even_elements);\n    }\n    \n    // Horizontal sum of vector\n    __m128i sum_low = _mm256_extracti128_si256(sum_vector, 0);\n    __m128i sum_high = _mm256_extracti128_si256(sum_vector, 1);\n    sum_low = _mm_add_epi32(sum_low, sum_high);\n    sum_low = _mm_hadd_epi32(sum_low, sum_low);\n    sum_low = _mm_hadd_epi32(sum_low, sum_low);\n    \n    result = _mm_cvtsi128_si32(sum_low);\n    \n    // Handle remaining elements\n    for (int i = vector_size; i < size; i++) {\n        if (i % 2 == 1 && lst[i] % 2 == 0) {\n            result += lst[i];\n        }\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_104_AVX", "completion": "```cpp\nint add_simd(std::vector<int> lst) {\n    int result = 0;\n    int size = lst.size();\n    \n    // Process 8 elements at a time using AVX2\n    int vector_size = size - (size % 8);\n    __m256i sum_vec = _mm256_setzero_si256();\n    \n    for (int i = 0; i < vector_size; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&lst[i]);\n        \n        // Create mask for odd indices\n        __m256i indices = _mm256_setr_epi32(1, 3, 5, 7, 9, 11, 13, 15);\n        __m256i mask = _mm256_cmpeq_epi32(_mm256_and_si256(indices, _mm256_set1_epi32(1)), _mm256_set1_epi32(1));\n        \n        // Select elements at odd indices\n        __m256i odd_indices_vec = _mm256_blendv_epi8(_mm256_setzero_si256(), vec, mask);\n        \n        // Create mask for even elements\n        __m256i even_mask = _mm256_cmpeq_epi32(_mm256_and_si256(odd_indices_vec, _mm256_set1_epi32(1)), _mm256_setzero_si256());\n        \n        // Select even elements at odd indices\n        __m256i even_elements = _mm256_blendv_epi8(_mm256_setzero_si256(), odd_indices_vec, even_mask);\n        \n        sum_vec = _mm256_add_epi32(sum_vec, even_elements);\n    }\n    \n    // Horizontal sum of vector\n    __m128i sum_low = _mm256_extracti128_si256(sum_vec, 0);\n    __m128i sum_high = _mm256_extracti128_si256(sum_vec, 1);\n    sum_low = _mm_add_epi32(sum_low, sum_high);\n    sum_low = _mm_hadd_epi32(sum_low, sum_low);\n    sum_low = _mm_hadd_epi32(sum_low, sum_low);\n    \n    result = _mm_cvtsi128_si32(sum_low);\n    \n    // Handle remaining elements\n    for (int i = vector_size; i < size; i++) {\n        if (i % 2 == 1 && lst[i] % 2 == 0) {\n            result += lst[i];\n        }\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_104_AVX", "completion": "```cpp\nint add_simd(std::vector<int> lst) {\n    int size = lst.size();\n    int result = 0;\n    \n    // Process 8 elements at a time using AVX2\n    int vector_size = size - (size % 8);\n    __m256i sum_vec = _mm256_setzero_si256();\n    \n    for (int i = 0; i < vector_size; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&lst[i]);\n        \n        // Create mask for odd indices\n        __m256i indices = _mm256_setr_epi32(1, 3, 5, 7, 9, 11, 13, 15);\n        __m256i mask = _mm256_cmpeq_epi32(_mm256_and_si256(indices, _mm256_set1_epi32(1)), _mm256_set1_epi32(1));\n        \n        // Select elements at odd indices\n        __m256i odd_indices_vec = _mm256_blendv_epi8(_mm256_setzero_si256(), vec, mask);\n        \n        // Create mask for even elements\n        __m256i even_mask = _mm256_cmpeq_epi32(_mm256_and_si256(odd_indices_vec, _mm256_set1_epi32(1)), _mm256_setzero_si256());\n        \n        // Select even elements at odd indices\n        __m256i even_elements = _mm256_blendv_epi8(_mm256_setzero_si256(), odd_indices_vec, even_mask);\n        \n        // Add to sum vector\n        sum_vec = _mm256_add_epi32(sum_vec, even_elements);\n    }\n    \n    // Horizontal sum of vector\n    __m128i sum_low = _mm256_extracti128_si256(sum_vec, 0);\n    __m128i sum_high = _mm256_extracti128_si256(sum_vec, 1);\n    sum_low = _mm_add_epi32(sum_low, sum_high);\n    sum_low = _mm_hadd_epi32(sum_low, sum_low);\n    sum_low = _mm_hadd_epi32(sum_low, sum_low);\n    \n    result = _mm_cvtsi128_si32(sum_low);\n    \n    // Handle remaining elements\n    for (int i = vector_size; i < size; i++) {\n        if (i % 2 == 1 && lst[i] % 2 == 0) {\n            result += lst[i];\n        }\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_105_AVX", "completion": "```cpp\nstd::string encrypt_simd(const std::string & s) {\n    std::string result = s;\n    int len = s.length();\n    \n    // Process 16 characters at a time using AVX2\n    for (int i = 0; i < len; i += 16) {\n        int remaining = std::min(16, len - i);\n        \n        // Load 16 characters into AVX register\n        __m256i chars = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&s[i]));\n        \n        // Separate lowercase and uppercase\n        __m256i lowercase_mask = _mm256_set1_epi8(0x20);\n        __m256i is_lowercase = _mm256_and_si256(chars, lowercase_mask);\n        \n        // Remove case information\n        __m256i base_chars = _mm256_and_si256(chars, _mm256_set1_epi8(0xDF));\n        \n        // Shift characters by 4 (2 * 2)\n        __m256i shifted_chars = _mm256_add_epi8(base_chars, _mm256_set1_epi8(4));\n        \n        // Wrap around for 'z' and 'Z'\n        __m256i z_mask = _mm256_cmpgt_epi8(shifted_chars, _mm256_set1_epi8('Z'));\n        shifted_chars = _mm256_sub_epi8(shifted_chars, _mm256_and_si256(z_mask, _mm256_set1_epi8(26)));\n        \n        // Restore case\n        shifted_chars = _mm256_or_si256(shifted_chars, is_lowercase);\n        \n        // Store back to result\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(&result[i]), shifted_chars);\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_105_AVX", "completion": "```cpp\nstd::string encrypt_simd(const std::string & s) {\n    std::string result = s;\n    int len = s.length();\n    \n    // Process 16 characters at a time using AVX2\n    for (int i = 0; i < len; i += 16) {\n        int remaining = std::min(16, len - i);\n        \n        // Load 16 characters into AVX register\n        __m256i chars = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&s[i]));\n        \n        // Separate lowercase and uppercase letters\n        __m256i lowercase_mask = _mm256_set1_epi8(0x20);\n        __m256i is_lowercase = _mm256_and_si256(chars, lowercase_mask);\n        \n        // Remove case information\n        __m256i base_chars = _mm256_and_si256(chars, _mm256_set1_epi8(0xDF));\n        \n        // Subtract 'A' to get 0-25 range\n        __m256i normalized = _mm256_sub_epi8(base_chars, _mm256_set1_epi8('A'));\n        \n        // Rotate by 4 (2 * 2)\n        __m256i rotated = _mm256_add_epi8(normalized, _mm256_set1_epi8(4));\n        \n        // Wrap around if > 25\n        __m256i wrapped = _mm256_mod_epi8(rotated, _mm256_set1_epi8(26));\n        \n        // Add back 'A'\n        __m256i encrypted = _mm256_add_epi8(wrapped, _mm256_set1_epi8('A'));\n        \n        // Restore original case\n        encrypted = _mm256_or_si256(encrypted, is_lowercase);\n        \n        // Store back to result\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(&result[i]), encrypted);\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_105_AVX", "completion": "```cpp\nstd::string encrypt_simd(const std::string & s) {\n    std::string result = s;\n    int len = s.length();\n    \n    // Process 16 characters at a time using AVX2\n    for (int i = 0; i < len; i += 16) {\n        int remaining = std::min(16, len - i);\n        \n        // Load 16 characters into AVX register\n        __m256i chars = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(s.data() + i));\n        \n        // Separate lowercase and uppercase letters\n        __m256i lowercase_mask = _mm256_set1_epi8(0x20);\n        __m256i is_lowercase = _mm256_and_si256(chars, lowercase_mask);\n        \n        // Remove case information\n        __m256i base_chars = _mm256_and_si256(chars, _mm256_set1_epi8(0xDF));\n        \n        // Check if character is a letter (A-Z)\n        __m256i is_letter_mask = _mm256_and_si256(\n            _mm256_cmpgt_epi8(base_chars, _mm256_set1_epi8('A' - 1)),\n            _mm256_cmpgt_epi8(_mm256_set1_epi8('Z' + 1), base_chars)\n        );\n        \n        // Rotate letters by 4 (2 * 2)\n        __m256i rotated = _mm256_add_epi8(base_chars, _mm256_set1_epi8(4));\n        \n        // Wrap around if past 'Z'\n        __m256i wrap_mask = _mm256_cmpgt_epi8(rotated, _mm256_set1_epi8('Z'));\n        __m256i wrap_adjust = _mm256_and_si256(wrap_mask, _mm256_set1_epi8(-26));\n        rotated = _mm256_add_epi8(rotated, wrap_adjust);\n        \n        // Restore original case\n        rotated = _mm256_or_si256(rotated, is_lowercase);\n        \n        // Preserve non-letter characters\n        rotated = _mm256_blendv_epi8(chars, rotated, is_letter_mask);\n        \n        // Store back to result\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(&result[i]), rotated);\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_105_AVX", "completion": "```cpp\nstd::string encrypt_simd(const std::string & s) {\n    std::string result = s;\n    int len = s.length();\n    \n    // Process 16 characters at a time using AVX2\n    for (int i = 0; i < len; i += 16) {\n        int remaining = std::min(16, len - i);\n        \n        // Load 16 characters into AVX register\n        __m256i chars = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&s[i]));\n        \n        // Separate lowercase and uppercase characters\n        __m256i lower_mask = _mm256_set1_epi8(0x20);\n        __m256i is_lower = _mm256_and_si256(chars, lower_mask);\n        \n        // Remove case information\n        __m256i base_chars = _mm256_and_si256(chars, _mm256_set1_epi8(0xDF));\n        \n        // Check if character is a letter (A-Z)\n        __m256i is_letter = _mm256_and_si256(\n            _mm256_cmpgt_epi8(base_chars, _mm256_set1_epi8('A' - 1)),\n            _mm256_cmpgt_epi8(_mm256_set1_epi8('Z' + 1), base_chars)\n        );\n        \n        // Rotate letters by 4 (2 * 2)\n        __m256i rotated = _mm256_add_epi8(base_chars, _mm256_set1_epi8(4));\n        \n        // Wrap around if past 'Z'\n        __m256i wrap_mask = _mm256_cmpgt_epi8(rotated, _mm256_set1_epi8('Z'));\n        __m256i wrapped = _mm256_sub_epi8(rotated, _mm256_and_si256(wrap_mask, _mm256_set1_epi8(26)));\n        \n        // Restore original case\n        __m256i final_chars = _mm256_or_si256(wrapped, is_lower);\n        \n        // Mask with original letter check\n        final_chars = _mm256_blendv_epi8(chars, final_chars, is_letter);\n        \n        // Store back to result\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(&result[i]), final_chars);\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_105_AVX", "completion": "```cpp\nstd::string encrypt_simd(const std::string & s) {\n    std::string result = s;\n    int len = s.length();\n    \n    // Process 16 characters at a time using AVX2\n    for (int i = 0; i < len; i += 16) {\n        int remaining = std::min(16, len - i);\n        \n        // Load 16 characters into AVX register\n        __m256i chars = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&s[i]));\n        \n        // Separate lowercase and uppercase characters\n        __m256i lower_mask = _mm256_set1_epi8(0x20);\n        __m256i is_lowercase = _mm256_and_si256(chars, lower_mask);\n        \n        // Remove case information\n        __m256i base_chars = _mm256_and_si256(chars, _mm256_set1_epi8(0xDF));\n        \n        // Check if character is a letter (A-Z)\n        __m256i is_letter = _mm256_and_si256(\n            _mm256_cmpgt_epi8(base_chars, _mm256_set1_epi8('A' - 1)),\n            _mm256_cmpgt_epi8(_mm256_set1_epi8('Z' + 1), base_chars)\n        );\n        \n        // Rotate letters by 4 (2 * 2)\n        __m256i rotated = _mm256_add_epi8(base_chars, _mm256_set1_epi8(4));\n        \n        // Wrap around if past 'Z'\n        __m256i wrap_mask = _mm256_cmpgt_epi8(rotated, _mm256_set1_epi8('Z'));\n        __m256i wrapped = _mm256_sub_epi8(rotated, _mm256_and_si256(wrap_mask, _mm256_set1_epi8(26)));\n        \n        // Restore original case\n        __m256i final_chars = _mm256_or_si256(\n            _mm256_and_si256(wrapped, _mm256_set1_epi8(0xDF)),\n            is_lowercase\n        );\n        \n        // Blend with original non-letter characters\n        final_chars = _mm256_blendv_epi8(chars, final_chars, is_letter);\n        \n        // Store result back\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(&result[i]), final_chars);\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_106_AVX", "completion": "```cpp\nstd::string encode_simd(const std::string& message) {\n    std::string result = message;\n    size_t len = message.length();\n    \n    // Process 32 bytes at a time using AVX2\n    for (size_t i = 0; i < len; i += 32) {\n        size_t remaining = std::min(len - i, 32ul);\n        \n        // Load 32 bytes into AVX register\n        __m256i chars = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&message[i]));\n        \n        // Swap case for letters\n        __m256i lower_mask = _mm256_set1_epi8('a');\n        __m256i upper_mask = _mm256_set1_epi8('A');\n        \n        __m256i is_lower = _mm256_and_si256(_mm256_cmpgt_epi8(chars, lower_mask - 1), \n                                             _mm256_cmpgt_epi8(upper_mask + 26, chars));\n        __m256i is_upper = _mm256_and_si256(_mm256_cmpgt_epi8(chars, upper_mask - 1), \n                                             _mm256_cmpgt_epi8(lower_mask + 26, chars));\n        \n        __m256i swapped_case = _mm256_xor_si256(chars, _mm256_set1_epi8(32));\n        chars = _mm256_blendv_epi8(chars, swapped_case, _mm256_or_si256(is_lower, is_upper));\n        \n        // Replace vowels\n        __m256i vowels_lower = _mm256_setr_epi8('a','e','i','o','u',0,0,0,0,0,0,0,0,0,0,0,\n                                                'a','e','i','o','u',0,0,0,0,0,0,0,0,0,0,0);\n        __m256i vowels_upper = _mm256_setr_epi8('A','E','I','O','U',0,0,0,0,0,0,0,0,0,0,0,\n                                                'A','E','I','O','U',0,0,0,0,0,0,0,0,0,0,0);\n        \n        __m256i is_lower_vowel = _mm256_cmpeq_epi8(chars, vowels_lower);\n        __m256i is_upper_vowel = _mm256_cmpeq_epi8(chars, vowels_upper);\n        \n        __m256i vowel_replace = _mm256_add_epi8(chars, _mm256_set1_epi8(2));\n        chars = _mm256_blendv_epi8(chars, vowel_replace, _mm256_or_si256(is_lower_vowel, is_upper_vowel));\n        \n        // Store back to result\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(&result[i]), chars);\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_106_AVX", "completion": "```cpp\nstd::string encode_simd(const std::string& message) {\n    std::string result = message;\n    size_t len = message.length();\n    \n    // Process 32 bytes at a time using AVX2\n    for (size_t i = 0; i < len; i += 32) {\n        __m256i chars = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&message[i]));\n        \n        // Swap case\n        __m256i lower_mask = _mm256_set1_epi8(0x20);\n        __m256i case_swapped = _mm256_xor_si256(chars, lower_mask);\n        \n        // Vowel replacement\n        __m256i a = _mm256_set1_epi8('a');\n        __m256i e = _mm256_set1_epi8('e');\n        __m256i i_char = _mm256_set1_epi8('i');\n        __m256i o = _mm256_set1_epi8('o');\n        __m256i u = _mm256_set1_epi8('u');\n        \n        __m256i A = _mm256_set1_epi8('A');\n        __m256i E = _mm256_set1_epi8('E');\n        __m256i I = _mm256_set1_epi8('I');\n        __m256i O = _mm256_set1_epi8('O');\n        __m256i U = _mm256_set1_epi8('U');\n        \n        // Check for lowercase vowels\n        __m256i is_a = _mm256_cmpeq_epi8(case_swapped, a);\n        __m256i is_e = _mm256_cmpeq_epi8(case_swapped, e);\n        __m256i is_i = _mm256_cmpeq_epi8(case_swapped, i_char);\n        __m256i is_o = _mm256_cmpeq_epi8(case_swapped, o);\n        __m256i is_u = _mm256_cmpeq_epi8(case_swapped, u);\n        \n        // Check for uppercase vowels\n        __m256i is_A = _mm256_cmpeq_epi8(case_swapped, A);\n        __m256i is_E = _mm256_cmpeq_epi8(case_swapped, E);\n        __m256i is_I = _mm256_cmpeq_epi8(case_swapped, I);\n        __m256i is_O = _mm256_cmpeq_epi8(case_swapped, O);\n        __m256i is_U = _mm256_cmpeq_epi8(case_swapped, U);\n        \n        // Replace vowels\n        __m256i replace_a = _mm256_blendv_epi8(case_swapped, _mm256_set1_epi8('c'), is_a);\n        __m256i replace_e = _mm256_blendv_epi8(replace_a, _mm256_set1_epi8('g'), is_e);\n        __m256i replace_i = _mm256_blendv_epi8(replace_e, _mm256_set1_epi8('k'), is_i);\n        __m256i replace_o = _mm256_blendv_epi8(replace_i, _mm256_set1_epi8('q'), is_o);\n        __m256i replace_u = _mm256_blendv_epi8(replace_o, _mm256_set1_epi8('w'), is_u);\n        \n        // Uppercase vowel replacements\n        replace_a = _mm256_blendv_epi8(replace_u, _mm256_set1_epi8('C'), is_A);\n        replace_e = _mm256_blendv_epi8(replace_a, _mm256_set1_epi8('G'), is_E);\n        replace_i = _mm256_blendv_epi8(replace_e, _mm256_set1_epi8('K'), is_I);\n        replace_o = _mm256_blendv_epi8(replace_i, _mm256_set1_epi8('Q'), is_O);\n        replace_u = _mm256_blendv_epi8(replace_o, _mm256_set1_epi8('W'), is_U);\n        \n        // Store result\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(&result[i]), replace_u);\n    }\n    \n    // Handle remaining characters\n    for (size_t i = len - (len % 32); i < len; ++i) {\n        char c = result[i];\n        \n        // Swap case\n        if (islower(c)) {\n            c = toupper(c);\n        } else if (isupper(c)) {\n            c = tolower(c);\n        }\n        \n        // Replace vowels\n        switch (tolower(c)) {\n            case 'a': c = isupper(result[i]) ? 'C' : 'c'; break;\n            case 'e': c = isupper(result[i]) ? 'G' : 'g'; break;\n            case 'i': c = isupper(result[i]) ? 'K' : 'k'; break;\n            case 'o': c = isupper(result[i]) ? 'Q' : 'q'; break;\n            case 'u': c = isupper(result[i]) ? 'W' : 'w'; break;\n        }\n        \n        result[i] = c;\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_106_AVX", "completion": "```cpp\nstd::string encode_simd(const std::string& message) {\n    std::string result = message;\n    size_t len = message.length();\n    \n    // Process 32 bytes at a time using AVX2\n    for (size_t i = 0; i < len; i += 32) {\n        __m256i chars = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&message[i]));\n        \n        // Swap case\n        __m256i lower_mask = _mm256_set1_epi8(0x20);\n        __m256i case_swapped = _mm256_xor_si256(chars, lower_mask);\n        \n        // Vowel replacement\n        __m256i a = _mm256_set1_epi8('a');\n        __m256i e = _mm256_set1_epi8('e');\n        __m256i i_char = _mm256_set1_epi8('i');\n        __m256i o = _mm256_set1_epi8('o');\n        __m256i u = _mm256_set1_epi8('u');\n        \n        __m256i A = _mm256_set1_epi8('A');\n        __m256i E = _mm256_set1_epi8('E');\n        __m256i I = _mm256_set1_epi8('I');\n        __m256i O = _mm256_set1_epi8('O');\n        __m256i U = _mm256_set1_epi8('U');\n        \n        // Vowel replacement logic\n        __m256i vowel_replaced = case_swapped;\n        \n        vowel_replaced = _mm256_blendv_epi8(vowel_replaced, _mm256_add_epi8(a, _mm256_set1_epi8(2)), \n            _mm256_or_si256(_mm256_cmpeq_epi8(case_swapped, a), _mm256_cmpeq_epi8(case_swapped, A)));\n        \n        vowel_replaced = _mm256_blendv_epi8(vowel_replaced, _mm256_add_epi8(e, _mm256_set1_epi8(2)), \n            _mm256_or_si256(_mm256_cmpeq_epi8(case_swapped, e), _mm256_cmpeq_epi8(case_swapped, E)));\n        \n        vowel_replaced = _mm256_blendv_epi8(vowel_replaced, _mm256_add_epi8(i_char, _mm256_set1_epi8(2)), \n            _mm256_or_si256(_mm256_cmpeq_epi8(case_swapped, i_char), _mm256_cmpeq_epi8(case_swapped, I)));\n        \n        vowel_replaced = _mm256_blendv_epi8(vowel_replaced, _mm256_add_epi8(o, _mm256_set1_epi8(2)), \n            _mm256_or_si256(_mm256_cmpeq_epi8(case_swapped, o), _mm256_cmpeq_epi8(case_swapped, O)));\n        \n        vowel_replaced = _mm256_blendv_epi8(vowel_replaced, _mm256_add_epi8(u, _mm256_set1_epi8(2)), \n            _mm256_or_si256(_mm256_cmpeq_epi8(case_swapped, u), _mm256_cmpeq_epi8(case_swapped, U)));\n        \n        // Store back to result\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(&result[i]), vowel_replaced);\n    }\n    \n    // Handle remaining characters\n    for (size_t i = len - (len % 32); i < len; ++i) {\n        char c = message[i];\n        \n        // Swap case\n        if (islower(c)) {\n            c = toupper(c);\n        } else if (isupper(c)) {\n            c = tolower(c);\n        }\n        \n        // Vowel replacement\n        switch (tolower(c)) {\n            case 'a': c += 2; break;\n            case 'e': c += 2; break;\n            case 'i': c += 2; break;\n            case 'o': c += 2; break;\n            case 'u': c += 2; break;\n        }\n        \n        result[i] = c;\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_106_AVX", "completion": "```cpp\nstd::string encode_simd(const std::string& message) {\n    std::string result = message;\n    size_t len = message.length();\n    \n    // Process 32 bytes at a time using AVX2\n    for (size_t i = 0; i < len; i += 32) {\n        __m256i chars = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&message[i]));\n        \n        // Swap case\n        __m256i lower_mask = _mm256_set1_epi8(0x20);\n        __m256i case_swapped = _mm256_xor_si256(chars, lower_mask);\n        \n        // Vowel replacement\n        __m256i a_mask = _mm256_cmpeq_epi8(case_swapped, _mm256_set1_epi8('a'));\n        __m256i e_mask = _mm256_cmpeq_epi8(case_swapped, _mm256_set1_epi8('e'));\n        __m256i i_mask = _mm256_cmpeq_epi8(case_swapped, _mm256_set1_epi8('i'));\n        __m256i o_mask = _mm256_cmpeq_epi8(case_swapped, _mm256_set1_epi8('o'));\n        __m256i u_mask = _mm256_cmpeq_epi8(case_swapped, _mm256_set1_epi8('u'));\n        \n        __m256i a_replace = _mm256_blendv_epi8(case_swapped, _mm256_set1_epi8('c'), a_mask);\n        __m256i e_replace = _mm256_blendv_epi8(a_replace, _mm256_set1_epi8('g'), e_mask);\n        __m256i i_replace = _mm256_blendv_epi8(e_replace, _mm256_set1_epi8('k'), i_mask);\n        __m256i o_replace = _mm256_blendv_epi8(i_replace, _mm256_set1_epi8('q'), o_mask);\n        __m256i u_replace = _mm256_blendv_epi8(o_replace, _mm256_set1_epi8('w'), u_mask);\n        \n        // Store back to result\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(&result[i]), u_replace);\n    }\n    \n    // Handle remaining characters\n    for (size_t i = len - (len % 32); i < len; ++i) {\n        char c = result[i];\n        \n        // Swap case\n        if (islower(c)) {\n            result[i] = toupper(c);\n        } else if (isupper(c)) {\n            result[i] = tolower(c);\n        }\n        \n        // Vowel replacement\n        switch (tolower(c)) {\n            case 'a': result[i] = 'c'; break;\n            case 'e': result[i] = 'g'; break;\n            case 'i': result[i] = 'k'; break;\n            case 'o': result[i] = 'q'; break;\n            case 'u': result[i] = 'w'; break;\n        }\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_106_AVX", "completion": "```cpp\nstd::string encode_simd(const std::string& message) {\n    std::string result = message;\n    size_t len = message.length();\n    \n    // Process 32 bytes at a time using AVX2\n    for (size_t i = 0; i < len; i += 32) {\n        size_t remaining = std::min(len - i, size_t(32));\n        \n        // Load 32 bytes from the message\n        __m256i chars = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&message[i]));\n        \n        // Swap case for letters\n        __m256i lower_mask = _mm256_set1_epi8('a');\n        __m256i upper_mask = _mm256_set1_epi8('A');\n        __m256i case_diff = _mm256_set1_epi8('a' - 'A');\n        \n        // Check for lowercase letters\n        __m256i is_lower = _mm256_cmpgt_epi8(chars, _mm256_sub_epi8(lower_mask, _mm256_set1_epi8(1)));\n        is_lower = _mm256_and_si256(is_lower, _mm256_cmpgt_epi8(_mm256_set1_epi8('z' + 1), chars));\n        \n        // Check for uppercase letters\n        __m256i is_upper = _mm256_cmpgt_epi8(chars, _mm256_sub_epi8(upper_mask, _mm256_set1_epi8(1)));\n        is_upper = _mm256_and_si256(is_upper, _mm256_cmpgt_epi8(_mm256_set1_epi8('Z' + 1), chars));\n        \n        // Swap case\n        __m256i swapped_case = _mm256_blendv_epi8(\n            _mm256_blendv_epi8(chars, _mm256_sub_epi8(chars, case_diff), is_lower),\n            _mm256_add_epi8(chars, case_diff),\n            is_upper\n        );\n        \n        // Replace vowels\n        __m256i vowels_lower = _mm256_setr_epi8('a', 'e', 'i', 'o', 'u', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n                                                'a', 'e', 'i', 'o', 'u', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n        __m256i vowels_upper = _mm256_setr_epi8('A', 'E', 'I', 'O', 'U', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n                                                'A', 'E', 'I', 'O', 'U', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n        \n        __m256i is_vowel_lower = _mm256_cmpeq_epi8(swapped_case, vowels_lower);\n        __m256i is_vowel_upper = _mm256_cmpeq_epi8(swapped_case, vowels_upper);\n        \n        __m256i vowel_replace_lower = _mm256_setr_epi8('c', 'g', 'k', 'q', 'w', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n                                                       'c', 'g', 'k', 'q', 'w', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n        __m256i vowel_replace_upper = _mm256_setr_epi8('C', 'G', 'K', 'Q', 'W', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n                                                       'C', 'G', 'K', 'Q', 'W', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n        \n        __m256i replaced_vowels = _mm256_blendv_epi8(\n            _mm256_blendv_epi8(swapped_case, vowel_replace_lower, is_vowel_lower),\n            vowel_replace_upper,\n            is_vowel_upper\n        );\n        \n        // Store the processed bytes\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(&result[i]), replaced_vowels);\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_107_AVX", "completion": "```cpp\nbool check_dict_case_simd(std::map<std::string, std::string> dict) {\n    if (dict.empty()) return false;\n\n    bool all_lower = true;\n    bool all_upper = true;\n\n    // Process keys in batches of 32 bytes using AVX2\n    for (const auto& entry : dict) {\n        const std::string& key = entry.first;\n        const char* str = key.c_str();\n        size_t len = key.length();\n\n        // Process 32 bytes at a time using AVX2\n        size_t i = 0;\n        for (; i + 32 <= len; i += 32) {\n            __m256i chars = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(str + i));\n            \n            // Check for lowercase\n            __m256i lower_mask = _mm256_set1_epi8('a');\n            __m256i upper_mask = _mm256_set1_epi8('z');\n            __m256i is_lower = _mm256_and_si256(\n                _mm256_cmpgt_epi8(chars, _mm256_sub_epi8(lower_mask, _mm256_set1_epi8(1))),\n                _mm256_cmpgt_epi8(_mm256_sub_epi8(upper_mask, chars), _mm256_set1_epi8(0))\n            );\n            \n            // Check for uppercase\n            lower_mask = _mm256_set1_epi8('A');\n            upper_mask = _mm256_set1_epi8('Z');\n            __m256i is_upper = _mm256_and_si256(\n                _mm256_cmpgt_epi8(chars, _mm256_sub_epi8(lower_mask, _mm256_set1_epi8(1))),\n                _mm256_cmpgt_epi8(_mm256_sub_epi8(upper_mask, chars), _mm256_set1_epi8(0))\n            );\n\n            // Check if all characters are not lowercase or uppercase\n            if (_mm256_movemask_epi8(is_lower) != 0xFFFFFFFF ||\n                _mm256_movemask_epi8(is_upper) != 0xFFFFFFFF) {\n                all_lower = false;\n                all_upper = false;\n                break;\n            }\n        }\n\n        // Process remaining characters\n        for (; i < len; ++i) {\n            char c = str[i];\n            if (!(c >= 'a' && c <= 'z')) all_lower = false;\n            if (!(c >= 'A' && c <= 'Z')) all_upper = false;\n            \n            if (!all_lower && !all_upper) break;\n        }\n\n        if (!all_lower && !all_upper) return false;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_107_AVX", "completion": "```cpp\nbool check_dict_case_simd(std::map<std::string, std::string> dict) {\n    if (dict.empty()) return false;\n\n    bool all_lower = true;\n    bool all_upper = true;\n\n    // Process keys in batches of 32 bytes using AVX2\n    for (const auto& entry : dict) {\n        const std::string& key = entry.first;\n        const char* str = key.c_str();\n        size_t len = key.length();\n\n        // Process 32 bytes at a time\n        size_t i = 0;\n        for (; i + 32 <= len; i += 32) {\n            __m256i chars = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(str + i));\n            \n            // Check for lowercase\n            __m256i lower_mask = _mm256_set1_epi8('a');\n            __m256i upper_mask = _mm256_set1_epi8('z');\n            __m256i is_lower = _mm256_and_si256(\n                _mm256_cmpgt_epi8(chars, _mm256_sub_epi8(lower_mask, _mm256_set1_epi8(1))),\n                _mm256_cmpgt_epi8(_mm256_sub_epi8(upper_mask, chars), _mm256_set1_epi8(0))\n            );\n            \n            // Check for uppercase\n            lower_mask = _mm256_set1_epi8('A');\n            upper_mask = _mm256_set1_epi8('Z');\n            __m256i is_upper = _mm256_and_si256(\n                _mm256_cmpgt_epi8(chars, _mm256_sub_epi8(lower_mask, _mm256_set1_epi8(1))),\n                _mm256_cmpgt_epi8(_mm256_sub_epi8(upper_mask, chars), _mm256_set1_epi8(0))\n            );\n\n            // Check if all characters are not lowercase or not uppercase\n            int lower_mask_int = _mm256_movemask_epi8(is_lower);\n            int upper_mask_int = _mm256_movemask_epi8(is_upper);\n            \n            if (lower_mask_int != 0xFFFFFFFF) all_lower = false;\n            if (upper_mask_int != 0xFFFFFFFF) all_upper = false;\n            \n            if (!all_lower && !all_upper) return false;\n        }\n\n        // Process remaining characters\n        for (; i < len; ++i) {\n            char c = str[i];\n            if (!(c >= 'a' && c <= 'z')) all_lower = false;\n            if (!(c >= 'A' && c <= 'Z')) all_upper = false;\n            \n            if (!all_lower && !all_upper) return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_107_AVX", "completion": "```cpp\nbool check_dict_case_simd(std::map<std::string, std::string> dict) {\n    if (dict.empty()) return false;\n\n    bool all_lower = true;\n    bool all_upper = true;\n\n    // Process keys in batches of 32 bytes using AVX2\n    for (const auto& entry : dict) {\n        const std::string& key = entry.first;\n        const char* str = key.c_str();\n        size_t len = key.length();\n\n        // Process 32 bytes at a time using AVX2\n        size_t i = 0;\n        for (; i + 32 <= len; i += 32) {\n            __m256i chars = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(str + i));\n\n            // Check for lowercase\n            __m256i lower_mask = _mm256_set1_epi8('a');\n            __m256i upper_mask = _mm256_set1_epi8('z');\n            __m256i is_lower = _mm256_and_si256(\n                _mm256_cmpgt_epi8(chars, _mm256_sub_epi8(lower_mask, _mm256_set1_epi8(1))),\n                _mm256_cmpgt_epi8(_mm256_sub_epi8(upper_mask, chars), _mm256_set1_epi8(0))\n            );\n\n            // Check for uppercase\n            lower_mask = _mm256_set1_epi8('A');\n            upper_mask = _mm256_set1_epi8('Z');\n            __m256i is_upper = _mm256_and_si256(\n                _mm256_cmpgt_epi8(chars, _mm256_sub_epi8(lower_mask, _mm256_set1_epi8(1))),\n                _mm256_cmpgt_epi8(_mm256_sub_epi8(upper_mask, chars), _mm256_set1_epi8(0))\n            );\n\n            // Check if all characters are lowercase or uppercase\n            if (_mm256_movemask_epi8(is_lower) != 0xFFFFFFFF) {\n                all_lower = false;\n            }\n            if (_mm256_movemask_epi8(is_upper) != 0xFFFFFFFF) {\n                all_upper = false;\n            }\n\n            if (!all_lower && !all_upper) {\n                return false;\n            }\n        }\n\n        // Process remaining characters\n        for (; i < len; ++i) {\n            char c = str[i];\n            if (!((c >= 'a' && c <= 'z') || (c >= 'A' && c <= 'Z'))) {\n                return false;\n            }\n            if (c >= 'a' && c <= 'z') {\n                all_upper = false;\n            }\n            if (c >= 'A' && c <= 'Z') {\n                all_lower = false;\n            }\n        }\n    }\n\n    return all_lower || all_upper;\n}\n```"}
{"task_id": "SimdBench_107_AVX", "completion": "```cpp\nbool check_dict_case_simd(std::map<std::string, std::string> dict) {\n    if (dict.empty()) return false;\n\n    bool all_lower = true;\n    bool all_upper = true;\n\n    // Process keys in batches of 32 bytes using AVX2\n    for (const auto& entry : dict) {\n        const std::string& key = entry.first;\n        const char* str = key.c_str();\n        size_t len = key.length();\n\n        // Process 32 bytes at a time using AVX2\n        size_t i = 0;\n        for (; i + 32 <= len; i += 32) {\n            __m256i chars = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(str + i));\n            \n            // Check for lowercase\n            __m256i lower_mask = _mm256_set1_epi8('a');\n            __m256i upper_mask = _mm256_set1_epi8('z');\n            __m256i is_lower = _mm256_and_si256(\n                _mm256_cmpgt_epi8(chars, _mm256_sub_epi8(lower_mask, _mm256_set1_epi8(1))),\n                _mm256_cmpgt_epi8(_mm256_sub_epi8(upper_mask, chars), _mm256_set1_epi8(0))\n            );\n            \n            // Check for uppercase\n            lower_mask = _mm256_set1_epi8('A');\n            upper_mask = _mm256_set1_epi8('Z');\n            __m256i is_upper = _mm256_and_si256(\n                _mm256_cmpgt_epi8(chars, _mm256_sub_epi8(lower_mask, _mm256_set1_epi8(1))),\n                _mm256_cmpgt_epi8(_mm256_sub_epi8(upper_mask, chars), _mm256_set1_epi8(0))\n            );\n\n            // Check if all characters are not lowercase or uppercase\n            if (_mm256_movemask_epi8(is_lower) != 0xFFFFFFFF) {\n                all_lower = false;\n            }\n            if (_mm256_movemask_epi8(is_upper) != 0xFFFFFFFF) {\n                all_upper = false;\n            }\n\n            if (!all_lower && !all_upper) return false;\n        }\n\n        // Process remaining characters\n        for (; i < len; ++i) {\n            char c = str[i];\n            if (!(c >= 'a' && c <= 'z')) all_lower = false;\n            if (!(c >= 'A' && c <= 'Z')) all_upper = false;\n            \n            if (!all_lower && !all_upper) return false;\n        }\n    }\n\n    return all_lower || all_upper;\n}\n```"}
{"task_id": "SimdBench_107_AVX", "completion": "```cpp\nbool check_dict_case_simd(std::map<std::string, std::string> dict) {\n    if (dict.empty()) return false;\n\n    bool all_lower = true;\n    bool all_upper = true;\n\n    // Process keys in batches of 32 bytes using AVX2\n    for (const auto& entry : dict) {\n        const std::string& key = entry.first;\n        const char* str = key.c_str();\n        size_t len = key.length();\n\n        // Process 32 bytes at a time\n        size_t i = 0;\n        for (; i + 32 <= len; i += 32) {\n            __m256i chars = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(str + i));\n\n            // Check for lowercase\n            __m256i lower_mask = _mm256_set1_epi8('a');\n            __m256i upper_mask = _mm256_set1_epi8('z');\n            __m256i is_lower = _mm256_and_si256(\n                _mm256_cmpgt_epi8(chars, _mm256_sub_epi8(lower_mask, _mm256_set1_epi8(1))),\n                _mm256_cmpgt_epi8(_mm256_sub_epi8(upper_mask, chars), _mm256_set1_epi8(0))\n            );\n            \n            // Check for uppercase\n            lower_mask = _mm256_set1_epi8('A');\n            upper_mask = _mm256_set1_epi8('Z');\n            __m256i is_upper = _mm256_and_si256(\n                _mm256_cmpgt_epi8(chars, _mm256_sub_epi8(lower_mask, _mm256_set1_epi8(1))),\n                _mm256_cmpgt_epi8(_mm256_sub_epi8(upper_mask, chars), _mm256_set1_epi8(0))\n            );\n\n            // Check if all characters are lowercase or uppercase\n            int lower_mask_int = _mm256_movemask_epi8(is_lower);\n            int upper_mask_int = _mm256_movemask_epi8(is_upper);\n\n            if (lower_mask_int != 0xFFFFFFFF) all_lower = false;\n            if (upper_mask_int != 0xFFFFFFFF) all_upper = false;\n\n            if (!all_lower && !all_upper) return false;\n        }\n\n        // Process remaining characters\n        for (; i < len; ++i) {\n            char c = str[i];\n            if (!((c >= 'a' && c <= 'z') || (c >= 'A' && c <= 'Z'))) return false;\n            if (c >= 'a' && c <= 'z') all_upper = false;\n            if (c >= 'A' && c <= 'Z') all_lower = false;\n        }\n\n        if (!all_lower && !all_upper) return false;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_108_AVX", "completion": "```cpp\nstd::vector<int> count_up_to_simd(int n) {\n    if (n <= 1) return {};\n\n    std::vector<int> primes;\n    std::vector<bool> is_prime(n, true);\n    is_prime[0] = is_prime[1] = false;\n\n    // Use AVX2 for parallel sieving\n    const int vec_width = 256 / 32;  // 8 integers per AVX2 vector\n    __m256i zero = _mm256_setzero_si256();\n    __m256i ones = _mm256_set1_epi32(1);\n\n    for (int i = 2; i * i < n; i++) {\n        if (is_prime[i]) {\n            // Parallel marking of non-primes\n            for (int j = 0; j < n; j += vec_width * i) {\n                for (int k = 0; k < vec_width; k++) {\n                    int idx = j + k * i;\n                    if (idx < n) is_prime[idx] = false;\n                }\n            }\n        }\n    }\n\n    // Collect primes\n    for (int i = 2; i < n; i++) {\n        if (is_prime[i]) primes.push_back(i);\n    }\n\n    return primes;\n}\n```"}
{"task_id": "SimdBench_108_AVX", "completion": "```cpp\nstd::vector<int> count_up_to_simd(int n) {\n    if (n <= 1) return {};\n\n    std::vector<int> primes;\n    std::vector<bool> is_prime(n, true);\n    is_prime[0] = is_prime[1] = false;\n\n    // Use AVX2 for parallel sieving\n    const int vec_width = 256 / 32;  // 8 integers per AVX2 vector\n    __m256i zero = _mm256_setzero_si256();\n    __m256i ones = _mm256_cmpeq_epi32(zero, zero);\n\n    for (int i = 2; i * i < n; i++) {\n        if (!is_prime[i]) continue;\n\n        // Vectorized marking of non-primes\n        for (int j = i * i; j < n; j += i) {\n            is_prime[j] = false;\n        }\n    }\n\n    // Collect primes\n    for (int i = 2; i < n; i++) {\n        if (is_prime[i]) {\n            primes.push_back(i);\n        }\n    }\n\n    return primes;\n}\n```"}
{"task_id": "SimdBench_108_AVX", "completion": "```cpp\nstd::vector<int> count_up_to_simd(int n) {\n    if (n <= 1) return {};\n\n    std::vector<int> primes;\n    std::vector<bool> is_prime(n, true);\n    is_prime[0] = is_prime[1] = false;\n\n    // Use AVX2 for parallel sieve of Eratosthenes\n    for (int i = 2; i * i < n; i++) {\n        if (is_prime[i]) {\n            // Vectorized marking of non-prime numbers\n            __m256i vec_i = _mm256_set1_epi32(i);\n            for (int j = i * i; j < n; j += i) {\n                int vec_start = (j / 256) * 256;\n                int vec_end = std::min(vec_start + 256, n);\n                \n                for (int k = vec_start; k < vec_end; k += 8) {\n                    __m256i vec_k = _mm256_set_epi32(\n                        k+7, k+6, k+5, k+4, k+3, k+2, k+1, k\n                    );\n                    __m256i vec_multiples = _mm256_div_epi32(vec_k, vec_i);\n                    __m256i vec_mask = _mm256_cmpeq_epi32(\n                        _mm256_mullo_epi32(vec_multiples, vec_i), \n                        vec_k\n                    );\n                    \n                    int mask = _mm256_movemask_ps((__m256)vec_mask);\n                    for (int m = 0; m < 8; m++) {\n                        if (mask & (1 << m)) {\n                            is_prime[k + m] = false;\n                        }\n                    }\n                }\n            }\n        }\n    }\n\n    // Collect prime numbers\n    for (int i = 2; i < n; i++) {\n        if (is_prime[i]) {\n            primes.push_back(i);\n        }\n    }\n\n    return primes;\n}\n```"}
{"task_id": "SimdBench_108_AVX", "completion": "```cpp\nstd::vector<int> count_up_to_simd(int n) {\n    if (n <= 1) return {};\n\n    std::vector<int> primes;\n    std::vector<bool> is_prime(n, true);\n    is_prime[0] = is_prime[1] = false;\n\n    // Use AVX2 for parallel sieve\n    const int vec_width = 256 / 32;  // 8 integers per AVX2 vector\n    __m256i zero = _mm256_setzero_si256();\n    __m256i ones = _mm256_cmpeq_epi32(zero, zero);\n\n    for (int i = 2; i * i < n; i++) {\n        if (is_prime[i]) {\n            // Parallel marking of non-primes\n            for (int j = i * i; j < n; j += i) {\n                is_prime[j] = false;\n            }\n        }\n    }\n\n    // Collect primes\n    for (int i = 2; i < n; i++) {\n        if (is_prime[i]) {\n            primes.push_back(i);\n        }\n    }\n\n    return primes;\n}\n```"}
{"task_id": "SimdBench_108_AVX", "completion": "```cpp\nstd::vector<int> count_up_to_simd(int n) {\n    if (n <= 1) return {};\n\n    std::vector<int> primes;\n    std::vector<bool> is_prime(n, true);\n    is_prime[0] = is_prime[1] = false;\n\n    // Use AVX2 for parallel sieving\n    const int vector_width = 256 / 32;  // 8 integers per AVX2 register\n    __m256i zero = _mm256_setzero_si256();\n    __m256i ones = _mm256_set1_epi32(1);\n\n    for (int i = 2; i * i < n; i++) {\n        if (is_prime[i]) {\n            // Parallel marking of non-primes\n            for (int j = 0; j < n; j += vector_width * i) {\n                for (int k = 0; k < vector_width; k++) {\n                    int idx = j + k * i;\n                    if (idx < n) is_prime[idx] = false;\n                }\n            }\n        }\n    }\n\n    // Collect primes\n    for (int i = 2; i < n; i++) {\n        if (is_prime[i]) primes.push_back(i);\n    }\n\n    return primes;\n}\n```"}
{"task_id": "SimdBench_109_AVX", "completion": "```cpp\nint count_upper_simd(const std::string & s) {\n    int result = 0;\n    int len = s.length();\n    \n    // Process 32 bytes at a time using AVX2\n    for (int i = 0; i < len; i += 32) {\n        __m256i chars = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&s[i]));\n        \n        // Create masks for even indices\n        __m256i indices = _mm256_set_epi8(\n            31, 29, 27, 25, 23, 21, 19, 17, 15, 13, 11, 9, 7, 5, 3, 1,\n            31, 29, 27, 25, 23, 21, 19, 17, 15, 13, 11, 9, 7, 5, 3, 1\n        );\n        \n        // Mask to get only characters at even indices\n        __m256i even_chars = _mm256_shuffle_epi8(chars, indices);\n        \n        // Check for uppercase vowels (A, E, I, O, U)\n        __m256i vowels_a = _mm256_cmpeq_epi8(even_chars, _mm256_set1_epi8('A'));\n        __m256i vowels_e = _mm256_cmpeq_epi8(even_chars, _mm256_set1_epi8('E'));\n        __m256i vowels_i = _mm256_cmpeq_epi8(even_chars, _mm256_set1_epi8('I'));\n        __m256i vowels_o = _mm256_cmpeq_epi8(even_chars, _mm256_set1_epi8('O'));\n        __m256i vowels_u = _mm256_cmpeq_epi8(even_chars, _mm256_set1_epi8('U'));\n        \n        // Combine vowel masks\n        __m256i vowel_mask = _mm256_or_si256(\n            _mm256_or_si256(vowels_a, vowels_e),\n            _mm256_or_si256(\n                _mm256_or_si256(vowels_i, vowels_o),\n                vowels_u\n            )\n        );\n        \n        // Count matching bytes\n        int mask = _mm256_movemask_epi8(vowel_mask);\n        result += _mm_popcnt_u32(mask);\n    }\n    \n    // Handle remaining characters\n    for (int i = (len / 32) * 32; i < len; i += 2) {\n        if (i < len && s[i] >= 'A' && s[i] <= 'Z' && \n            (s[i] == 'A' || s[i] == 'E' || s[i] == 'I' || s[i] == 'O' || s[i] == 'U')) {\n            result++;\n        }\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_109_AVX", "completion": "```cpp\nint count_upper_simd(const std::string & s) {\n    int result = 0;\n    int len = s.length();\n    \n    // Process 32 bytes at a time using AVX2\n    for (int i = 0; i < len; i += 32) {\n        __m256i chars = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&s[i]));\n        \n        // Create masks for even indices\n        __m256i indices = _mm256_set_epi8(\n            31, 29, 27, 25, 23, 21, 19, 17, 15, 13, 11, 9, 7, 5, 3, 1,\n            31, 29, 27, 25, 23, 21, 19, 17, 15, 13, 11, 9, 7, 5, 3, 1\n        );\n        \n        // Mask out non-even indices\n        __m256i even_chars = _mm256_shuffle_epi8(chars, indices);\n        \n        // Check for uppercase vowels\n        __m256i upper_a = _mm256_set1_epi8('A');\n        __m256i upper_e = _mm256_set1_epi8('E');\n        __m256i upper_i = _mm256_set1_epi8('I');\n        __m256i upper_o = _mm256_set1_epi8('O');\n        __m256i upper_u = _mm256_set1_epi8('U');\n        \n        __m256i is_a = _mm256_cmpeq_epi8(even_chars, upper_a);\n        __m256i is_e = _mm256_cmpeq_epi8(even_chars, upper_e);\n        __m256i is_i = _mm256_cmpeq_epi8(even_chars, upper_i);\n        __m256i is_o = _mm256_cmpeq_epi8(even_chars, upper_o);\n        __m256i is_u = _mm256_cmpeq_epi8(even_chars, upper_u);\n        \n        __m256i is_upper_vowel = _mm256_or_si256(\n            _mm256_or_si256(is_a, is_e),\n            _mm256_or_si256(_mm256_or_si256(is_i, is_o), is_u)\n        );\n        \n        // Count the number of uppercase vowels\n        int mask = _mm256_movemask_epi8(is_upper_vowel);\n        result += _mm_popcnt_u32(mask);\n    }\n    \n    // Handle remaining characters\n    for (int i = 0; i < len; i += 2) {\n        if (s[i] == 'A' || s[i] == 'E' || s[i] == 'I' || s[i] == 'O' || s[i] == 'U') {\n            result++;\n        }\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_109_AVX", "completion": "```cpp\nint count_upper_simd(const std::string & s) {\n    int result = 0;\n    const int len = s.length();\n    \n    // Process 32 bytes at a time\n    int i;\n    for (i = 0; i <= len - 32; i += 32) {\n        __m256i chars = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(s.data() + i));\n        \n        // Create mask for even indices\n        __m256i indices = _mm256_setr_epi32(0, 2, 4, 6, 8, 10, 12, 14);\n        __m256i even_chars = _mm256_shuffle_epi8(chars, indices);\n        \n        // Check for uppercase vowels (A, E, I, O, U)\n        __m256i vowels_A = _mm256_cmpeq_epi8(even_chars, _mm256_set1_epi8('A'));\n        __m256i vowels_E = _mm256_cmpeq_epi8(even_chars, _mm256_set1_epi8('E'));\n        __m256i vowels_I = _mm256_cmpeq_epi8(even_chars, _mm256_set1_epi8('I'));\n        __m256i vowels_O = _mm256_cmpeq_epi8(even_chars, _mm256_set1_epi8('O'));\n        __m256i vowels_U = _mm256_cmpeq_epi8(even_chars, _mm256_set1_epi8('U'));\n        \n        __m256i vowels = _mm256_or_si256(\n            _mm256_or_si256(vowels_A, vowels_E),\n            _mm256_or_si256(\n                _mm256_or_si256(vowels_I, vowels_O),\n                vowels_U\n            )\n        );\n        \n        // Count matching bytes\n        result += _mm_popcnt_u32(_mm256_movemask_epi8(vowels));\n    }\n    \n    // Handle remaining characters\n    for (; i < len; i += 2) {\n        if (i < len && (s[i] == 'A' || s[i] == 'E' || s[i] == 'I' || s[i] == 'O' || s[i] == 'U')) {\n            result++;\n        }\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_109_AVX", "completion": "```cpp\nint count_upper_simd(const std::string & s) {\n    int result = 0;\n    int len = s.length();\n    \n    // Process 32 bytes at a time using AVX2\n    for (int i = 0; i < len; i += 32) {\n        __m256i chars = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&s[i]));\n        \n        // Create masks for even indices\n        __m256i indices = _mm256_set_epi8(\n            31, 29, 27, 25, 23, 21, 19, 17, 15, 13, 11, 9, 7, 5, 3, 1,\n            31, 29, 27, 25, 23, 21, 19, 17, 15, 13, 11, 9, 7, 5, 3, 1\n        );\n        \n        // Mask to keep only characters at even indices\n        __m256i even_mask = _mm256_cmpeq_epi8(\n            _mm256_and_si256(chars, _mm256_set1_epi8(0x1F)),\n            indices\n        );\n        \n        // Check for uppercase vowels (A, E, I, O, U)\n        __m256i vowel_mask = _mm256_or_si256(\n            _mm256_or_si256(\n                _mm256_cmpeq_epi8(chars, _mm256_set1_epi8('A')),\n                _mm256_cmpeq_epi8(chars, _mm256_set1_epi8('E'))\n            ),\n            _mm256_or_si256(\n                _mm256_or_si256(\n                    _mm256_cmpeq_epi8(chars, _mm256_set1_epi8('I')),\n                    _mm256_cmpeq_epi8(chars, _mm256_set1_epi8('O'))\n                ),\n                _mm256_cmpeq_epi8(chars, _mm256_set1_epi8('U'))\n            )\n        );\n        \n        // Combine even index and uppercase vowel masks\n        __m256i combined_mask = _mm256_and_si256(even_mask, vowel_mask);\n        \n        // Count matching characters\n        result += _mm_popcnt_u32(_mm256_movemask_epi8(combined_mask));\n    }\n    \n    // Handle remaining characters\n    for (int i = (len / 32) * 32; i < len; ++i) {\n        if (i % 2 == 0 && \n            (s[i] == 'A' || s[i] == 'E' || s[i] == 'I' || s[i] == 'O' || s[i] == 'U')) {\n            ++result;\n        }\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_109_AVX", "completion": "```cpp\nint count_upper_simd(const std::string & s) {\n    int result = 0;\n    int len = s.length();\n    \n    // Process 32 bytes at a time using AVX2\n    for (int i = 0; i < len; i += 32) {\n        __m256i chars = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&s[i]));\n        \n        // Create masks for even indices\n        __m256i indices = _mm256_set_epi8(\n            31, 29, 27, 25, 23, 21, 19, 17, 15, 13, 11, 9, 7, 5, 3, 1,\n            31, 29, 27, 25, 23, 21, 19, 17, 15, 13, 11, 9, 7, 5, 3, 1\n        );\n        \n        // Mask out characters at even indices\n        __m256i even_chars = _mm256_shuffle_epi8(chars, indices);\n        \n        // Check for uppercase vowels (A, E, I, O, U)\n        __m256i vowels_a = _mm256_cmpeq_epi8(even_chars, _mm256_set1_epi8('A'));\n        __m256i vowels_e = _mm256_cmpeq_epi8(even_chars, _mm256_set1_epi8('E'));\n        __m256i vowels_i = _mm256_cmpeq_epi8(even_chars, _mm256_set1_epi8('I'));\n        __m256i vowels_o = _mm256_cmpeq_epi8(even_chars, _mm256_set1_epi8('O'));\n        __m256i vowels_u = _mm256_cmpeq_epi8(even_chars, _mm256_set1_epi8('U'));\n        \n        // Combine vowel masks\n        __m256i vowel_mask = _mm256_or_si256(\n            _mm256_or_si256(vowels_a, vowels_e),\n            _mm256_or_si256(_mm256_or_si256(vowels_i, vowels_o), vowels_u)\n        );\n        \n        // Count matching bytes\n        int mask = _mm256_movemask_epi8(vowel_mask);\n        result += __builtin_popcount(mask);\n        \n        // Break if we've processed all characters\n        if (i + 32 >= len) break;\n    }\n    \n    // Handle remaining characters\n    for (int i = (len / 32) * 32; i < len; i += 2) {\n        if (i < len && s[i] >= 'A' && s[i] <= 'Z' && \n            (s[i] == 'A' || s[i] == 'E' || s[i] == 'I' || s[i] == 'O' || s[i] == 'U')) {\n            result++;\n        }\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_110_AVX", "completion": "```cpp\nstd::vector<int> make_a_pile_simd(int n) {\n    std::vector<int> result(n);\n    \n    // Initial value for first level\n    __m256i first_level = _mm256_set1_epi32(n);\n    _mm256_storeu_si256((__m256i*)result.data(), first_level);\n    \n    // Process remaining levels\n    for (int i = 1; i < n; i++) {\n        // Check if previous level was odd or even\n        if (result[i-1] % 2 == 1) {\n            // If previous level was odd, next level is next odd number\n            result[i] = result[i-1] + 2;\n        } else {\n            // If previous level was even, next level is next even number\n            result[i] = result[i-1] + 2;\n        }\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_110_AVX", "completion": "```cpp\nstd::vector<int> make_a_pile_simd(int n) {\n    std::vector<int> result(n);\n    \n    // Initial level stones\n    __m256i initial_stones = _mm256_set1_epi32(n);\n    \n    // Broadcast initial value\n    __m256i increment = _mm256_set1_epi32(n % 2 == 0 ? 2 : 1);\n    \n    for (int i = 0; i < n; i += 8) {\n        __m256i current_level = _mm256_add_epi32(\n            initial_stones, \n            _mm256_mullo_epi32(_mm256_set1_epi32(i), increment)\n        );\n        \n        _mm256_storeu_si256((__m256i*)&result[i], current_level);\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_110_AVX", "completion": "```cpp\nstd::vector<int> make_a_pile_simd(int n) {\n    std::vector<int> result(n);\n    \n    // Initial level stones\n    __m256i initial_stones = _mm256_set1_epi32(n);\n    \n    // Broadcast initial stones to vector\n    _mm256_storeu_si256((__m256i*)result.data(), initial_stones);\n    \n    // Process remaining levels\n    for (int i = 1; i < n; i++) {\n        // Check if previous level was odd or even\n        if (result[i-1] % 2 == 1) {\n            // If previous level was odd, next level is next odd number\n            result[i] = result[i-1] + 2;\n        } else {\n            // If previous level was even, next level is next even number\n            result[i] = result[i-1] + 2;\n        }\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_110_AVX", "completion": "```cpp\nstd::vector<int> make_a_pile_simd(int n) {\n    std::vector<int> result(n);\n    \n    // Broadcast initial value n to all lanes\n    __m256i current = _mm256_set1_epi32(n);\n    \n    // Process 8 elements at a time\n    for (int i = 0; i < n; i += 8) {\n        // Compute next levels using AVX2 operations\n        __m256i increment = _mm256_set1_epi32(n % 2 == 0 ? 2 : 1);\n        \n        // Store results\n        _mm256_storeu_si256((__m256i*)&result[i], current);\n        \n        // Update current level by adding increment\n        current = _mm256_add_epi32(current, increment);\n    }\n    \n    // Handle remaining elements if n is not multiple of 8\n    for (int i = (n / 8) * 8; i < n; ++i) {\n        result[i] = n % 2 == 0 ? result[i-1] + 2 : result[i-1] + 1;\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_110_AVX", "completion": "```cpp\nstd::vector<int> make_a_pile_simd(int n) {\n    std::vector<int> result(n);\n    \n    // Initial level stones\n    __m256i initial_stones = _mm256_set1_epi32(n);\n    \n    // Broadcast initial stones to vector\n    _mm256_storeu_si256((__m256i*)result.data(), initial_stones);\n    \n    // Process remaining levels\n    for (int i = 1; i < n; i++) {\n        // Check if previous level was odd or even\n        if (result[i-1] % 2 == 1) {\n            // If odd, next level is next odd number\n            result[i] = result[i-1] + 2;\n        } else {\n            // If even, next level is next even number\n            result[i] = result[i-1] + 2;\n        }\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_111_AVX", "completion": "```cpp\nstd::string rounded_avg_simd(int64_t n, int64_t m) {\n    if (n > m) return \"-1\";\n    \n    // Compute sum using AVX2 intrinsics\n    int64_t sum = 0;\n    int64_t count = m - n + 1;\n    \n    // Process 4 integers at a time using AVX2\n    __m256i sum_vec = _mm256_setzero_si256();\n    int64_t i;\n    for (i = 0; i + 4 <= count; i += 4) {\n        __m256i current = _mm256_set_epi64x(\n            n + i + 3, \n            n + i + 2, \n            n + i + 1, \n            n + i\n        );\n        sum_vec = _mm256_add_epi64(sum_vec, current);\n    }\n    \n    // Horizontal sum of vector\n    __m128i sum_low = _mm256_extracti128_si256(sum_vec, 0);\n    __m128i sum_high = _mm256_extracti128_si256(sum_vec, 1);\n    sum_low = _mm_add_epi64(sum_low, sum_high);\n    sum = _mm_cvtsi128_si64(sum_low) + _mm_cvtsi128_si64(_mm_srli_si128(sum_low, 8));\n    \n    // Add remaining elements\n    for (; i < count; i++) {\n        sum += n + i;\n    }\n    \n    // Compute rounded average\n    int64_t avg = sum / count;\n    \n    // Convert to binary string\n    if (avg == 0) return \"0\";\n    \n    std::string binary;\n    while (avg > 0) {\n        binary = std::to_string(avg % 2) + binary;\n        avg /= 2;\n    }\n    \n    return binary;\n}\n```"}
{"task_id": "SimdBench_111_AVX", "completion": "```cpp\nstd::string rounded_avg_simd(int64_t n, int64_t m) {\n    if (n > m) return \"-1\";\n    \n    // Compute sum using AVX2 horizontal addition\n    int64_t sum = 0;\n    int64_t count = m - n + 1;\n    \n    // Process 4 integers at a time using AVX2\n    int64_t vec_count = count / 4;\n    int64_t remainder = count % 4;\n    \n    __m256i sum_vec = _mm256_setzero_si256();\n    __m256i start_vec = _mm256_set1_epi64x(n);\n    __m256i increment_vec = _mm256_set1_epi64x(4);\n    \n    for (int64_t i = 0; i < vec_count; ++i) {\n        __m256i current_vec = _mm256_add_epi64(start_vec, _mm256_mul_epi32(increment_vec, _mm256_set1_epi64x(i)));\n        sum_vec = _mm256_add_epi64(sum_vec, current_vec);\n    }\n    \n    // Horizontal sum\n    __m128i sum_low = _mm256_extracti128_si256(sum_vec, 0);\n    __m128i sum_high = _mm256_extracti128_si256(sum_vec, 1);\n    __m128i sum_128 = _mm_add_epi64(sum_low, sum_high);\n    sum = _mm_cvtsi128_si64(sum_128) + _mm_extract_epi64(sum_128, 1);\n    \n    // Process remaining elements\n    for (int64_t i = vec_count * 4; i < count; ++i) {\n        sum += n + i;\n    }\n    \n    // Compute rounded average\n    int64_t avg = sum / count;\n    \n    // Convert to binary string\n    if (avg == 0) return \"0\";\n    \n    std::string binary;\n    while (avg > 0) {\n        binary = std::to_string(avg % 2) + binary;\n        avg /= 2;\n    }\n    \n    return binary;\n}\n```"}
{"task_id": "SimdBench_111_AVX", "completion": "```cpp\nstd::string rounded_avg_simd(int64_t n, int64_t m) {\n    if (n > m) return \"-1\";\n\n    // Compute the sum using AVX2 intrinsics\n    __m256i sum_vec = _mm256_setzero_si256();\n    int64_t chunk_size = 4;\n    int64_t i;\n\n    // Process 4 integers at a time\n    for (i = n; i + chunk_size <= m + 1; i += chunk_size) {\n        __m256i current_vec = _mm256_set_epi64x(i + 3, i + 2, i + 1, i);\n        sum_vec = _mm256_add_epi64(sum_vec, current_vec);\n    }\n\n    // Horizontal sum of vector\n    __m128i sum_low = _mm256_extracti128_si256(sum_vec, 0);\n    __m128i sum_high = _mm256_extracti128_si256(sum_vec, 1);\n    __m128i sum_128 = _mm_add_epi64(sum_low, sum_high);\n    int64_t sum = _mm_cvtsi128_si64(sum_128) + _mm_extract_epi64(sum_128, 1);\n\n    // Add remaining elements\n    for (; i <= m; ++i) {\n        sum += i;\n    }\n\n    // Compute rounded average\n    int64_t count = m - n + 1;\n    int64_t avg = sum / count;\n\n    // Convert to binary string\n    if (avg == 0) return \"0\";\n    \n    std::string binary;\n    while (avg > 0) {\n        binary = std::to_string(avg % 2) + binary;\n        avg /= 2;\n    }\n\n    return binary;\n}\n```"}
{"task_id": "SimdBench_111_AVX", "completion": "```cpp\nstd::string rounded_avg_simd(int64_t n, int64_t m) {\n    if (n > m) return \"-1\";\n    \n    // Compute sum using AVX2 horizontal addition\n    int64_t sum = 0;\n    int64_t count = m - n + 1;\n    \n    // Process in 4-element chunks\n    int64_t vector_count = count / 4;\n    int64_t remainder = count % 4;\n    \n    __m256i sum_vec = _mm256_setzero_si256();\n    __m256i increment_vec = _mm256_set_epi64x(n+3, n+2, n+1, n);\n    __m256i step_vec = _mm256_set1_epi64x(4);\n    \n    for (int64_t i = 0; i < vector_count; ++i) {\n        sum_vec = _mm256_add_epi64(sum_vec, increment_vec);\n        increment_vec = _mm256_add_epi64(increment_vec, step_vec);\n    }\n    \n    // Horizontal sum\n    int64_t temp_sum[4];\n    _mm256_storeu_si256((__m256i*)temp_sum, sum_vec);\n    sum = temp_sum[0] + temp_sum[1] + temp_sum[2] + temp_sum[3];\n    \n    // Handle remainder\n    for (int64_t i = vector_count * 4; i < count; ++i) {\n        sum += n + i;\n    }\n    \n    // Compute rounded average\n    int64_t avg = sum / count;\n    \n    // Convert to binary string\n    if (avg == 0) return \"0\";\n    \n    std::string binary;\n    while (avg > 0) {\n        binary = std::to_string(avg % 2) + binary;\n        avg /= 2;\n    }\n    \n    return binary;\n}\n```"}
{"task_id": "SimdBench_111_AVX", "completion": "```cpp\nstd::string rounded_avg_simd(int64_t n, int64_t m) {\n    if (n > m) return \"-1\";\n    \n    // Compute sum using AVX2 horizontal addition\n    int64_t sum = 0;\n    int64_t count = m - n + 1;\n    \n    // Process 4 integers at a time using AVX2\n    __m256i sum_vec = _mm256_setzero_si256();\n    int64_t i;\n    for (i = n; i + 3 < m + 1; i += 4) {\n        __m256i current = _mm256_set_epi64x(i + 3, i + 2, i + 1, i);\n        sum_vec = _mm256_add_epi64(sum_vec, current);\n    }\n    \n    // Horizontal sum of AVX2 vector\n    __m128i sum_low = _mm256_extracti128_si256(sum_vec, 0);\n    __m128i sum_high = _mm256_extracti128_si256(sum_vec, 1);\n    sum_low = _mm_add_epi64(sum_low, sum_high);\n    sum = _mm_cvtsi128_si64(sum_low) + _mm_cvtsi128_si64(_mm_srli_si128(sum_low, 8));\n    \n    // Process remaining elements\n    for (; i <= m; ++i) {\n        sum += i;\n    }\n    \n    // Compute rounded average\n    int64_t avg = sum / count;\n    \n    // Convert to binary string\n    if (avg == 0) return \"0\";\n    \n    std::string binary;\n    while (avg > 0) {\n        binary = std::to_string(avg % 2) + binary;\n        avg /= 2;\n    }\n    \n    return binary;\n}\n```"}
{"task_id": "SimdBench_112_AVX", "completion": "```cpp\nstd::vector<int> func_simd(int n) {\n    std::vector<int> result(n);\n    \n    // Process 8 elements at a time using AVX2\n    int vectorized_size = n - (n % 8);\n    \n    for (int i = 0; i < vectorized_size; i += 8) {\n        __m256i indices = _mm256_set_epi32(\n            i + 8, i + 7, i + 6, i + 5, \n            i + 4, i + 3, i + 2, i + 1\n        );\n        \n        __m256i results = _mm256_setzero_si256();\n        \n        for (int j = 0; j < 8; j++) {\n            int idx = i + j + 1;\n            \n            if (idx % 2 == 0) {\n                // Factorial calculation for even indices\n                int factorial = 1;\n                for (int k = 2; k <= idx; k++) {\n                    factorial = (factorial * k) % 10000;\n                }\n                result[idx - 1] = factorial;\n            } else {\n                // Sum of numbers for odd indices\n                int sum = (idx * (idx + 1)) / 2;\n                result[idx - 1] = sum;\n            }\n        }\n    }\n    \n    // Handle remaining elements\n    for (int i = vectorized_size; i < n; i++) {\n        if ((i + 1) % 2 == 0) {\n            int factorial = 1;\n            for (int k = 2; k <= i + 1; k++) {\n                factorial = (factorial * k) % 10000;\n            }\n            result[i] = factorial;\n        } else {\n            result[i] = (i + 1 * (i + 2)) / 2;\n        }\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_112_AVX", "completion": "```cpp\nstd::vector<int> func_simd(int n) {\n    std::vector<int> result(n);\n    \n    // Process 8 elements at a time using AVX2\n    int vec_size = n - (n % 8);\n    for (int i = 0; i < vec_size; i += 8) {\n        __m256i indices = _mm256_set_epi32(\n            i + 8, i + 7, i + 6, i + 5, \n            i + 4, i + 3, i + 2, i + 1\n        );\n        \n        __m256i values = _mm256_setzero_si256();\n        \n        for (int j = 0; j < 8; j++) {\n            int idx = i + j + 1;\n            \n            if (idx % 2 == 0) {\n                // Factorial calculation for even indices\n                int factorial = 1;\n                for (int k = 1; k <= idx; k++) {\n                    factorial = (factorial * k) % 10000;\n                }\n                values = _mm256_insert_epi32(values, factorial, j);\n            } else {\n                // Sum of numbers for odd indices\n                int sum = (idx * (idx + 1)) / 2;\n                values = _mm256_insert_epi32(values, sum, j);\n            }\n        }\n        \n        _mm256_storeu_si256((__m256i*)&result[i], values);\n    }\n    \n    // Handle remaining elements\n    for (int i = vec_size; i < n; i++) {\n        if ((i + 1) % 2 == 0) {\n            int factorial = 1;\n            for (int k = 1; k <= i + 1; k++) {\n                factorial = (factorial * k) % 10000;\n            }\n            result[i] = factorial;\n        } else {\n            result[i] = (i + 1 * (i + 2)) / 2;\n        }\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_112_AVX", "completion": "```cpp\nstd::vector<int> func_simd(int n) {\n    std::vector<int> result(n);\n    \n    // Process 8 elements at a time using AVX2\n    int vector_size = n - (n % 8);\n    for (int i = 0; i < vector_size; i += 8) {\n        __m256i indices = _mm256_set_epi32(\n            i + 8, i + 7, i + 6, i + 5, \n            i + 4, i + 3, i + 2, i + 1\n        );\n        \n        __m256i mask = _mm256_and_si256(indices, _mm256_set1_epi32(1));\n        mask = _mm256_cmpeq_epi32(mask, _mm256_setzero_si256());\n        \n        __m256i factorial_results = _mm256_set1_epi32(1);\n        __m256i sum_results = _mm256_set1_epi32(0);\n        \n        for (int j = 1; j <= 16; j++) {\n            __m256i multiplier = _mm256_set1_epi32(j);\n            factorial_results = _mm256_mullo_epi32(factorial_results, multiplier);\n            sum_results = _mm256_add_epi32(sum_results, multiplier);\n            \n            __m256i even_results = _mm256_blendv_epi8(sum_results, factorial_results, mask);\n            even_results = _mm256_mod_epi32(even_results, _mm256_set1_epi32(10000));\n        }\n        \n        _mm256_storeu_si256((__m256i*)&result[i], even_results);\n    }\n    \n    // Handle remaining elements sequentially\n    for (int i = vector_size; i < n; i++) {\n        if (i % 2 == 0) {\n            int factorial = 1;\n            for (int j = 1; j <= i; j++) {\n                factorial *= j;\n            }\n            result[i] = factorial % 10000;\n        } else {\n            int sum = 0;\n            for (int j = 1; j <= i; j++) {\n                sum += j;\n            }\n            result[i] = sum;\n        }\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_112_AVX", "completion": "```cpp\nstd::vector<int> func_simd(int n) {\n    std::vector<int> result(n);\n    \n    // Process 8 elements at a time using AVX2\n    int vectorized_size = (n / 8) * 8;\n    \n    for (int i = 0; i < vectorized_size; i += 8) {\n        __m256i indices = _mm256_set_epi32(i+8, i+7, i+6, i+5, i+4, i+3, i+2, i+1);\n        \n        // Compute values for even and odd indices\n        __m256i values = _mm256_setzero_si256();\n        \n        for (int j = 0; j < 8; ++j) {\n            int idx = i + j + 1;\n            \n            if (idx % 2 == 0) {\n                // Factorial modulo 10000 for even indices\n                int factorial = 1;\n                for (int k = 2; k <= idx; ++k) {\n                    factorial = (factorial * k) % 10000;\n                }\n                result[i + j] = factorial;\n            } else {\n                // Sum of numbers from 1 to index for odd indices\n                int sum = (idx * (idx + 1)) / 2;\n                result[i + j] = sum;\n            }\n        }\n    }\n    \n    // Handle remaining elements\n    for (int i = vectorized_size; i < n; ++i) {\n        if ((i + 1) % 2 == 0) {\n            // Factorial modulo 10000 for even indices\n            int factorial = 1;\n            for (int k = 2; k <= i + 1; ++k) {\n                factorial = (factorial * k) % 10000;\n            }\n            result[i] = factorial;\n        } else {\n            // Sum of numbers from 1 to index for odd indices\n            int sum = ((i + 1) * (i + 2)) / 2;\n            result[i] = sum;\n        }\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_112_AVX", "completion": "```cpp\nstd::vector<int> func_simd(int n) {\n    std::vector<int> result(n);\n    \n    // Process 8 elements at a time using AVX2\n    int vec_size = (n / 8) * 8;\n    for (int i = 0; i < vec_size; i += 8) {\n        __m256i indices = _mm256_set_epi32(i+8, i+7, i+6, i+5, i+4, i+3, i+2, i+1);\n        \n        // Create mask for even/odd indices\n        __m256i even_mask = _mm256_set1_epi32(1);\n        even_mask = _mm256_cmpeq_epi32(_mm256_and_si256(indices, even_mask), _mm256_setzero_si256());\n        \n        // Factorial calculation for even indices\n        __m256i factorial = _mm256_set1_epi32(1);\n        __m256i fact_indices = _mm256_srli_epi32(indices, 1);\n        for (int j = 1; j <= 15; j++) {\n            __m256i multiplier = _mm256_set1_epi32(j);\n            factorial = _mm256_mullo_epi32(factorial, multiplier);\n        }\n        factorial = _mm256_mod_epi32(factorial, _mm256_set1_epi32(10000));\n        \n        // Sum calculation for odd indices\n        __m256i sum = _mm256_srli_epi32(indices, 1);\n        sum = _mm256_mullo_epi32(sum, _mm256_set1_epi32(1));\n        sum = _mm256_add_epi32(sum, _mm256_set1_epi32(1));\n        \n        // Blend results based on even/odd mask\n        __m256i blended = _mm256_blendv_epi8(sum, factorial, even_mask);\n        \n        // Store results\n        _mm256_storeu_si256((__m256i*)&result[i], blended);\n    }\n    \n    // Handle remaining elements\n    for (int i = vec_size; i < n; i++) {\n        if (i % 2 == 0) {\n            int factorial = 1;\n            for (int j = 1; j <= i; j++) {\n                factorial *= j;\n            }\n            result[i] = factorial % 10000;\n        } else {\n            result[i] = (i * (i + 1)) / 2;\n        }\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_113_AVX", "completion": "```cpp\nstd::vector<int> even_odd_palindrome_simd(int n) {\n    int even_count = 0, odd_count = 0;\n    __m256i zero = _mm256_setzero_si256();\n    __m256i ones = _mm256_set1_epi32(1);\n    \n    for (int i = 1; i <= n; i += 8) {\n        __m256i current = _mm256_set_epi32(\n            i+7, i+6, i+5, i+4, \n            i+3, i+2, i+1, i\n        );\n        \n        // Check palindrome\n        __m256i reversed = _mm256_setzero_si256();\n        __m256i num = current;\n        \n        for (int j = 0; j < 32; j += 8) {\n            __m256i digit = _mm256_and_si256(_mm256_srli_epi32(num, j), _mm256_set1_epi32(0xFF));\n            reversed = _mm256_or_si256(_mm256_slli_epi32(reversed, 8), digit);\n        }\n        \n        __m256i is_palindrome = _mm256_cmpeq_epi32(current, reversed);\n        __m256i is_even = _mm256_cmpeq_epi32(_mm256_and_si256(current, ones), zero);\n        \n        // Count even and odd palindromes\n        is_palindrome = _mm256_and_si256(is_palindrome, _mm256_cmpgt_epi32(current, zero));\n        is_palindrome = _mm256_and_si256(is_palindrome, _mm256_cmpgt_epi32(_mm256_set1_epi32(n+1), current));\n        \n        __m256i even_mask = _mm256_and_si256(is_palindrome, is_even);\n        __m256i odd_mask = _mm256_andnot_si256(is_even, is_palindrome);\n        \n        even_count += _mm_popcnt_u32(_mm256_movemask_epi8(even_mask));\n        odd_count += _mm_popcnt_u32(_mm256_movemask_epi8(odd_mask));\n    }\n    \n    return {even_count / 4, odd_count / 4};\n}\n```"}
{"task_id": "SimdBench_113_AVX", "completion": "```cpp\nstd::vector<int> even_odd_palindrome_simd(int n) {\n    int even_count = 0, odd_count = 0;\n    \n    // Use AVX2 to process multiple numbers in parallel\n    __m256i zero = _mm256_setzero_si256();\n    __m256i two = _mm256_set1_epi32(2);\n    __m256i count_even = _mm256_setzero_si256();\n    __m256i count_odd = _mm256_setzero_si256();\n    \n    // Process 8 numbers at a time\n    for (int i = 1; i <= n; i += 8) {\n        __m256i current = _mm256_set_epi32(\n            i+7, i+6, i+5, i+4, i+3, i+2, i+1, i\n        );\n        \n        // Check if each number is a palindrome\n        __m256i is_palindrome = _mm256_setzero_si256();\n        \n        for (int j = 0; j < 8 && i+j <= n; ++j) {\n            int num = i + j;\n            int reversed = 0;\n            int original = num;\n            \n            // Reverse the number\n            while (original > 0) {\n                reversed = reversed * 10 + original % 10;\n                original /= 10;\n            }\n            \n            // Check if number is a palindrome\n            if (num == reversed) {\n                // Set corresponding bit in is_palindrome mask\n                is_palindrome = _mm256_insert_epi32(is_palindrome, -1, j);\n                \n                // Check if palindrome is even or odd\n                if (num % 2 == 0) {\n                    count_even = _mm256_insert_epi32(count_even, \n                        _mm256_extract_epi32(count_even, j) + 1, j);\n                } else {\n                    count_odd = _mm256_insert_epi32(count_odd, \n                        _mm256_extract_epi32(count_odd, j) + 1, j);\n                }\n            }\n        }\n    }\n    \n    // Horizontal sum of even and odd counts\n    __m128i sum_even = _mm_add_epi32(\n        _mm256_extracti128_si256(count_even, 0),\n        _mm256_extracti128_si256(count_even, 1)\n    );\n    sum_even = _mm_hadd_epi32(sum_even, sum_even);\n    sum_even = _mm_hadd_epi32(sum_even, sum_even);\n    even_count = _mm_cvtsi128_si32(sum_even);\n    \n    __m128i sum_odd = _mm_add_epi32(\n        _mm256_extracti128_si256(count_odd, 0),\n        _mm256_extracti128_si256(count_odd, 1)\n    );\n    sum_odd = _mm_hadd_epi32(sum_odd, sum_odd);\n    sum_odd = _mm_hadd_epi32(sum_odd, sum_odd);\n    odd_count = _mm_cvtsi128_si32(sum_odd);\n    \n    return {even_count, odd_count};\n}\n```"}
{"task_id": "SimdBench_113_AVX", "completion": "```cpp\nstd::vector<int> even_odd_palindrome_simd(int n) {\n    int even_count = 0, odd_count = 0;\n    \n    // Use AVX2 to process multiple numbers in parallel\n    __m256i zero = _mm256_setzero_si256();\n    __m256i two = _mm256_set1_epi32(2);\n    __m256i count_even = _mm256_setzero_si256();\n    __m256i count_odd = _mm256_setzero_si256();\n    \n    // Process numbers in batches of 8\n    for (int i = 1; i <= n; i += 8) {\n        __m256i current = _mm256_setr_epi32(\n            i, i+1, i+2, i+3, i+4, i+5, i+6, i+7\n        );\n        \n        // Check if numbers are within range\n        __m256i mask = _mm256_cmpgt_epi32(current, _mm256_set1_epi32(n));\n        mask = _mm256_cmpeq_epi32(mask, zero);\n        \n        // Check for palindromes\n        for (int j = 0; j < 8; ++j) {\n            int num = i + j;\n            if (num > n) break;\n            \n            // Palindrome check\n            int reversed = 0;\n            int original = num;\n            while (original > 0) {\n                reversed = reversed * 10 + original % 10;\n                original /= 10;\n            }\n            \n            if (reversed == num) {\n                if (num % 2 == 0) {\n                    even_count++;\n                } else {\n                    odd_count++;\n                }\n            }\n        }\n    }\n    \n    return {even_count, odd_count};\n}\n```"}
{"task_id": "SimdBench_113_AVX", "completion": "```cpp\nstd::vector<int> even_odd_palindrome_simd(int n) {\n    int even_count = 0, odd_count = 0;\n    __m256i zero = _mm256_setzero_si256();\n    __m256i ones = _mm256_set1_epi32(1);\n    \n    for (int i = 1; i <= n; i += 8) {\n        __m256i current = _mm256_set_epi32(\n            i+7, i+6, i+5, i+4, \n            i+3, i+2, i+1, i\n        );\n        \n        // Check palindrome\n        __m256i reversed = _mm256_setzero_si256();\n        __m256i temp = current;\n        \n        for (int j = 0; j < 32; j += 8) {\n            __m256i digit = _mm256_and_si256(_mm256_srli_epi32(temp, j), _mm256_set1_epi32(0xFF));\n            reversed = _mm256_or_si256(_mm256_slli_epi32(reversed, 8), digit);\n        }\n        \n        __m256i is_palindrome = _mm256_cmpeq_epi32(current, reversed);\n        __m256i is_even = _mm256_cmpeq_epi32(_mm256_and_si256(current, ones), zero);\n        \n        // Count even and odd palindromes\n        for (int j = 0; j < 8; j++) {\n            int mask = _mm256_movemask_ps(_mm256_castsi256_ps(is_palindrome));\n            int even_mask = _mm256_movemask_ps(_mm256_castsi256_ps(is_even));\n            \n            if (mask & (1 << j)) {\n                if (even_mask & (1 << j)) {\n                    even_count++;\n                } else {\n                    odd_count++;\n                }\n            }\n        }\n    }\n    \n    return {even_count, odd_count};\n}\n```"}
{"task_id": "SimdBench_113_AVX", "completion": "```cpp\nstd::vector<int> even_odd_palindrome_simd(int n) {\n    int even_count = 0, odd_count = 0;\n    __m256i zero = _mm256_setzero_si256();\n    __m256i ones = _mm256_set1_epi32(1);\n    \n    for (int i = 1; i <= n; i += 8) {\n        __m256i current = _mm256_set_epi32(\n            i+7, i+6, i+5, i+4, \n            i+3, i+2, i+1, i\n        );\n        \n        // Check palindrome\n        __m256i reversed = _mm256_setzero_si256();\n        __m256i num = current;\n        \n        for (int j = 0; j < 32; j += 8) {\n            __m256i digit = _mm256_and_si256(_mm256_srli_epi32(num, j), _mm256_set1_epi32(0xFF));\n            reversed = _mm256_or_si256(_mm256_slli_epi32(reversed, 8), digit);\n        }\n        \n        __m256i is_palindrome = _mm256_cmpeq_epi32(current, reversed);\n        __m256i is_even = _mm256_cmpeq_epi32(_mm256_and_si256(current, ones), zero);\n        \n        // Count even and odd palindromes\n        __m256i even_mask = _mm256_and_si256(is_palindrome, is_even);\n        __m256i odd_mask = _mm256_and_si256(is_palindrome, _mm256_xor_si256(is_even, ones));\n        \n        int* even_ptr = (int*)&even_mask;\n        int* odd_ptr = (int*)&odd_mask;\n        \n        for (int j = 0; j < 8; j++) {\n            if (even_ptr[j] != 0) even_count++;\n            if (odd_ptr[j] != 0) odd_count++;\n        }\n    }\n    \n    return {even_count, odd_count};\n}\n```"}
{"task_id": "SimdBench_114_AVX", "completion": "```cpp\nint count_nums_simd(std::vector<int> n) {\n    int count = 0;\n    int size = n.size();\n    \n    // Process 8 integers at a time using AVX2\n    int vector_size = size - (size % 8);\n    \n    __m256i sum_mask = _mm256_setzero_si256();\n    \n    for (int i = 0; i < vector_size; i += 8) {\n        __m256i nums = _mm256_loadu_si256((__m256i*)&n[i]);\n        \n        // Compute absolute value\n        __m256i abs_nums = _mm256_abs_epi32(nums);\n        \n        // Extract digits\n        __m256i digit_sum = _mm256_setzero_si256();\n        for (int shift = 0; shift < 32; shift += 8) {\n            __m256i shifted_nums = _mm256_srli_epi32(abs_nums, shift);\n            __m256i digits = _mm256_and_si256(shifted_nums, _mm256_set1_epi32(0xFF));\n            digit_sum = _mm256_add_epi32(digit_sum, digits);\n        }\n        \n        // Compare digit sum > 0\n        __m256i compare_mask = _mm256_cmpgt_epi32(digit_sum, _mm256_setzero_si256());\n        sum_mask = _mm256_or_si256(sum_mask, compare_mask);\n    }\n    \n    // Horizontal sum of mask\n    __m256i sum_mask_high = _mm256_srli_si256(sum_mask, 8);\n    sum_mask = _mm256_add_epi32(sum_mask, sum_mask_high);\n    sum_mask_high = _mm256_srli_si256(sum_mask, 4);\n    sum_mask = _mm256_add_epi32(sum_mask, sum_mask_high);\n    \n    int mask_result[8];\n    _mm256_storeu_si256((__m256i*)mask_result, sum_mask);\n    count += (mask_result[0] & 0x1) + ((mask_result[0] >> 31) & 0x1);\n    \n    // Process remaining elements\n    for (int i = vector_size; i < size; i++) {\n        int abs_num = std::abs(n[i]);\n        int digit_sum = 0;\n        while (abs_num > 0) {\n            digit_sum += abs_num % 10;\n            abs_num /= 10;\n        }\n        if (digit_sum > 0) count++;\n    }\n    \n    return count;\n}\n```"}
{"task_id": "SimdBench_114_AVX", "completion": "```cpp\nint count_nums_simd(std::vector<int> n) {\n    int count = 0;\n    int size = n.size();\n    \n    // Process 8 integers at a time using AVX2\n    int vector_size = size - (size % 8);\n    \n    __m256i count_vec = _mm256_setzero_si256();\n    \n    for (int i = 0; i < vector_size; i += 8) {\n        __m256i nums = _mm256_loadu_si256((__m256i*)&n[i]);\n        \n        // Compute absolute value\n        __m256i abs_nums = _mm256_abs_epi32(nums);\n        \n        // Extract digits and compute sum\n        __m256i digit_sums = _mm256_setzero_si256();\n        \n        for (int j = 0; j < 10; j++) {\n            __m256i digits = _mm256_div_epi32(abs_nums, _mm256_set1_epi32(std::pow(10, j)));\n            digits = _mm256_mod_epi32(digits, _mm256_set1_epi32(10));\n            digit_sums = _mm256_add_epi32(digit_sums, digits);\n        }\n        \n        // Compare digit sums > 0\n        __m256i mask = _mm256_cmpgt_epi32(digit_sums, _mm256_setzero_si256());\n        \n        // Count numbers with digit sum > 0\n        __m256i result = _mm256_and_si256(mask, _mm256_set1_epi32(1));\n        count_vec = _mm256_add_epi32(count_vec, result);\n    }\n    \n    // Horizontal sum of count_vec\n    __m128i sum_low = _mm256_extracti128_si256(count_vec, 0);\n    __m128i sum_high = _mm256_extracti128_si256(count_vec, 1);\n    sum_low = _mm_add_epi32(sum_low, sum_high);\n    sum_low = _mm_hadd_epi32(sum_low, sum_low);\n    sum_low = _mm_hadd_epi32(sum_low, sum_low);\n    \n    count += _mm_cvtsi128_si32(sum_low);\n    \n    // Process remaining elements\n    for (int i = vector_size; i < size; i++) {\n        int abs_num = std::abs(n[i]);\n        int digit_sum = 0;\n        \n        while (abs_num > 0) {\n            digit_sum += abs_num % 10;\n            abs_num /= 10;\n        }\n        \n        if (digit_sum > 0) {\n            count++;\n        }\n    }\n    \n    return count;\n}\n```"}
{"task_id": "SimdBench_114_AVX", "completion": "```cpp\nint count_nums_simd(std::vector<int> n) {\n    int count = 0;\n    int size = n.size();\n    \n    // Process 8 integers at a time using AVX2\n    int vector_size = size - (size % 8);\n    \n    __m256i sum_mask = _mm256_setzero_si256();\n    \n    for (int i = 0; i < vector_size; i += 8) {\n        __m256i nums = _mm256_loadu_si256((__m256i*)&n[i]);\n        \n        // Compute absolute value\n        __m256i abs_nums = _mm256_abs_epi32(nums);\n        \n        // Extract digits and compute sum\n        __m256i digit_sums = _mm256_setzero_si256();\n        \n        for (int j = 0; j < 10; ++j) {\n            __m256i digits = _mm256_div_epi32(abs_nums, _mm256_set1_epi32(std::pow(10, j)));\n            digits = _mm256_mod_epi32(digits, _mm256_set1_epi32(10));\n            digit_sums = _mm256_add_epi32(digit_sums, digits);\n        }\n        \n        // Compare digit sums > 0\n        __m256i compare_mask = _mm256_cmpgt_epi32(digit_sums, _mm256_setzero_si256());\n        \n        // Combine masks\n        sum_mask = _mm256_or_si256(sum_mask, compare_mask);\n    }\n    \n    // Horizontal sum of mask\n    int mask_array[8];\n    _mm256_storeu_si256((__m256i*)mask_array, sum_mask);\n    \n    for (int i = 0; i < 8; ++i) {\n        count += (mask_array[i] != 0);\n    }\n    \n    // Process remaining elements\n    for (int i = vector_size; i < size; ++i) {\n        int num = std::abs(n[i]);\n        int digit_sum = 0;\n        \n        while (num > 0) {\n            digit_sum += num % 10;\n            num /= 10;\n        }\n        \n        if (digit_sum > 0) {\n            count++;\n        }\n    }\n    \n    return count;\n}\n```"}
{"task_id": "SimdBench_114_AVX", "completion": "```cpp\nint count_nums_simd(std::vector<int> n) {\n    int count = 0;\n    int size = n.size();\n    \n    // Process 8 integers at a time using AVX2\n    int vector_size = size - (size % 8);\n    \n    __m256i sum_mask = _mm256_setzero_si256();\n    \n    for (int i = 0; i < vector_size; i += 8) {\n        __m256i nums = _mm256_loadu_si256((__m256i*)&n[i]);\n        \n        // Compute absolute value\n        __m256i abs_nums = _mm256_abs_epi32(nums);\n        \n        // Extract digits and compute sum\n        __m256i digit_sums = _mm256_setzero_si256();\n        \n        for (int j = 0; j < 32; j += 8) {\n            __m256i shifted = _mm256_srli_epi32(abs_nums, j);\n            __m256i digits = _mm256_and_si256(shifted, _mm256_set1_epi32(0xFF));\n            digit_sums = _mm256_add_epi32(digit_sums, digits);\n        }\n        \n        // Compare digit sums > 0\n        __m256i compare_mask = _mm256_cmpgt_epi32(digit_sums, _mm256_setzero_si256());\n        sum_mask = _mm256_or_si256(sum_mask, compare_mask);\n    }\n    \n    // Horizontal sum of mask\n    __m256i sum_lo = _mm256_castsi256_si128(sum_mask);\n    __m256i sum_hi = _mm256_extracti128_si256(sum_mask, 1);\n    __m128i sum_combined = _mm_or_si128(sum_lo, sum_hi);\n    \n    int mask_result[4];\n    _mm_storeu_si128((__m128i*)mask_result, sum_combined);\n    \n    for (int i = 0; i < 4; i++) {\n        count += (mask_result[i] != 0);\n    }\n    \n    // Process remaining elements\n    for (int i = vector_size; i < size; i++) {\n        int num = std::abs(n[i]);\n        int digit_sum = 0;\n        \n        while (num > 0) {\n            digit_sum += num % 10;\n            num /= 10;\n        }\n        \n        if (digit_sum > 0) {\n            count++;\n        }\n    }\n    \n    return count;\n}\n```"}
{"task_id": "SimdBench_114_AVX", "completion": "```cpp\nint count_nums_simd(std::vector<int> n) {\n    int count = 0;\n    int size = n.size();\n    \n    // Process 8 integers at a time using AVX2\n    int vector_size = size - (size % 8);\n    \n    __m256i digit_sum_mask = _mm256_setzero_si256();\n    \n    for (int i = 0; i < vector_size; i += 8) {\n        // Load 8 integers\n        __m256i nums = _mm256_loadu_si256((__m256i*)&n[i]);\n        \n        // Compute absolute values\n        __m256i abs_nums = _mm256_abs_epi32(nums);\n        \n        // Compute digit sum for each number\n        __m256i digit_sums = _mm256_setzero_si256();\n        \n        for (int j = 0; j < 10; j++) {\n            __m256i digit = _mm256_div_epi32(abs_nums, _mm256_set1_epi32(pow(10, j)));\n            digit = _mm256_mod_epi32(digit, _mm256_set1_epi32(10));\n            digit_sums = _mm256_add_epi32(digit_sums, digit);\n        }\n        \n        // Compare digit sums > 0\n        __m256i compare_mask = _mm256_cmpgt_epi32(digit_sums, _mm256_setzero_si256());\n        \n        // Combine masks\n        digit_sum_mask = _mm256_or_si256(digit_sum_mask, compare_mask);\n    }\n    \n    // Horizontal sum of mask\n    int mask_array[8];\n    _mm256_storeu_si256((__m256i*)mask_array, digit_sum_mask);\n    \n    for (int i = 0; i < 8; i++) {\n        count += (mask_array[i] != 0);\n    }\n    \n    // Process remaining elements\n    for (int i = vector_size; i < size; i++) {\n        int abs_num = std::abs(n[i]);\n        int digit_sum = 0;\n        \n        while (abs_num > 0) {\n            digit_sum += abs_num % 10;\n            abs_num /= 10;\n        }\n        \n        if (digit_sum > 0) {\n            count++;\n        }\n    }\n    \n    return count;\n}\n```"}
{"task_id": "SimdBench_115_AVX", "completion": "```cpp\nbool move_one_ball_simd(std::vector<int> arr) {\n    int n = arr.size();\n    if (n <= 1) return true;\n\n    // Find the minimum element's index\n    __m256i min_vec = _mm256_set1_epi32(INT_MAX);\n    int min_idx = 0;\n    \n    for (int i = 0; i < n; i += 8) {\n        int remaining = std::min(8, n - i);\n        __m256i current_vec;\n        \n        if (remaining == 8) {\n            current_vec = _mm256_loadu_si256((__m256i*)&arr[i]);\n        } else {\n            // Handle partial vector for last chunk\n            current_vec = _mm256_set1_epi32(INT_MAX);\n            for (int j = 0; j < remaining; j++) {\n                ((int*)&current_vec)[j] = arr[i + j];\n            }\n        }\n        \n        __m256i min_mask = _mm256_cmpgt_epi32(min_vec, current_vec);\n        min_vec = _mm256_blendv_epi8(min_vec, current_vec, min_mask);\n        \n        // Find minimum index\n        for (int j = 0; j < remaining; j++) {\n            if (((int*)&current_vec)[j] < ((int*)&min_vec)[0]) {\n                min_idx = i + j;\n                min_vec = current_vec;\n            }\n        }\n    }\n    \n    // Rotate array and check if sorted\n    std::vector<int> rotated(n);\n    for (int k = 0; k < n; k++) {\n        bool is_sorted = true;\n        for (int i = 0; i < n; i++) {\n            rotated[i] = arr[(i + n - k) % n];\n        }\n        \n        // Check sorted using AVX\n        for (int i = 0; i < n; i += 8) {\n            int remaining = std::min(8, n - i);\n            __m256i vec1, vec2;\n            \n            if (remaining == 8) {\n                vec1 = _mm256_loadu_si256((__m256i*)&rotated[i]);\n                vec2 = _mm256_loadu_si256((__m256i*)&rotated[i + 1]);\n            } else {\n                // Handle partial vector for last chunk\n                vec1 = _mm256_set1_epi32(INT_MIN);\n                vec2 = _mm256_set1_epi32(INT_MAX);\n                for (int j = 0; j < remaining; j++) {\n                    ((int*)&vec1)[j] = rotated[i + j];\n                    if (j + 1 < remaining) {\n                        ((int*)&vec2)[j] = rotated[i + j + 1];\n                    }\n                }\n            }\n            \n            __m256i cmp_mask = _mm256_cmpgt_epi32(vec1, vec2);\n            if (_mm256_movemask_epi8(cmp_mask) != 0) {\n                is_sorted = false;\n                break;\n            }\n        }\n        \n        if (is_sorted) return true;\n    }\n    \n    return false;\n}\n```"}
{"task_id": "SimdBench_115_AVX", "completion": "```cpp\nbool move_one_ball_simd(std::vector<int> arr) {\n    int n = arr.size();\n    if (n <= 1) return true;\n\n    // Find the minimum element and its index\n    __m256i min_vec = _mm256_set1_epi32(INT_MAX);\n    int min_idx = 0;\n    \n    for (int i = 0; i < n; i += 8) {\n        int remaining = std::min(8, n - i);\n        __m256i current_vec;\n        \n        if (remaining == 8) {\n            current_vec = _mm256_loadu_si256((__m256i*)&arr[i]);\n        } else {\n            // Handle partial vector for last iteration\n            current_vec = _mm256_set1_epi32(INT_MAX);\n            for (int j = 0; j < remaining; j++) {\n                current_vec = _mm256_insert_epi32(current_vec, arr[i + j], j);\n            }\n        }\n        \n        __m256i min_mask = _mm256_cmpgt_epi32(min_vec, current_vec);\n        min_vec = _mm256_blendv_epi8(min_vec, current_vec, min_mask);\n    }\n    \n    // Horizontal min reduction\n    __m128i min_low = _mm256_extracti128_si256(min_vec, 0);\n    __m128i min_high = _mm256_extracti128_si256(min_vec, 1);\n    min_low = _mm_min_epi32(min_low, min_high);\n    min_low = _mm_min_epi32(min_low, _mm_shuffle_epi32(min_low, _MM_SHUFFLE(1, 0, 3, 2)));\n    min_low = _mm_min_epi32(min_low, _mm_shuffle_epi32(min_low, _MM_SHUFFLE(0, 1, 2, 3)));\n    int min_element = _mm_cvtsi128_si32(min_low);\n    \n    // Find the index of the minimum element\n    for (int i = 0; i < n; i++) {\n        if (arr[i] == min_element) {\n            min_idx = i;\n            break;\n        }\n    }\n    \n    // Check if the array can be sorted by right shifts\n    for (int i = 0; i < n; i++) {\n        int curr_idx = (min_idx + i) % n;\n        int next_idx = (min_idx + i + 1) % n;\n        \n        if (arr[curr_idx] > arr[next_idx]) {\n            return false;\n        }\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_115_AVX", "completion": "```cpp\nbool move_one_ball_simd(std::vector<int> arr) {\n    int n = arr.size();\n    if (n <= 1) return true;\n\n    // Find the minimum element and its index\n    __m256i min_vec = _mm256_set1_epi32(INT_MAX);\n    int min_idx = 0;\n    \n    for (int i = 0; i < n; i += 8) {\n        int remaining = std::min(8, n - i);\n        __m256i current_vec;\n        \n        if (remaining == 8) {\n            current_vec = _mm256_loadu_si256((__m256i*)&arr[i]);\n        } else {\n            // Handle partial vector for last chunk\n            current_vec = _mm256_set1_epi32(INT_MAX);\n            for (int j = 0; j < remaining; j++) {\n                ((int*)&current_vec)[j] = arr[i + j];\n            }\n        }\n        \n        __m256i min_mask = _mm256_cmpgt_epi32(min_vec, current_vec);\n        min_vec = _mm256_blendv_epi8(min_vec, current_vec, min_mask);\n    }\n    \n    int min_elements[8];\n    _mm256_storeu_si256((__m256i*)min_elements, min_vec);\n    int global_min = min_elements[0];\n    \n    // Find the actual minimum index\n    for (int i = 0; i < n; i++) {\n        if (arr[i] == global_min) {\n            min_idx = i;\n            break;\n        }\n    }\n    \n    // Check if array can be sorted by right shifts\n    for (int shift = 0; shift < n; shift++) {\n        bool is_sorted = true;\n        \n        for (int i = 0; i < n - 1; i++) {\n            int curr = arr[(min_idx + i) % n];\n            int next = arr[(min_idx + i + 1) % n];\n            \n            if (curr > next) {\n                is_sorted = false;\n                break;\n            }\n        }\n        \n        if (is_sorted) return true;\n        min_idx = (min_idx + 1) % n;\n    }\n    \n    return false;\n}\n```"}
{"task_id": "SimdBench_115_AVX", "completion": "```cpp\nbool move_one_ball_simd(std::vector<int> arr) {\n    int n = arr.size();\n    if (n <= 1) return true;\n\n    // Find the minimum element's index\n    __m256i min_vec = _mm256_set1_epi32(INT_MAX);\n    int min_idx = 0;\n    \n    for (int i = 0; i < n; i += 8) {\n        int remaining = std::min(8, n - i);\n        __m256i current_vec;\n        \n        if (remaining == 8) {\n            current_vec = _mm256_loadu_si256((__m256i*)&arr[i]);\n        } else {\n            // Handle partial vector for last chunk\n            current_vec = _mm256_set1_epi32(INT_MAX);\n            for (int j = 0; j < remaining; j++) {\n                ((int*)&current_vec)[j] = arr[i + j];\n            }\n        }\n        \n        __m256i min_mask = _mm256_cmpgt_epi32(min_vec, current_vec);\n        min_vec = _mm256_blendv_epi8(min_vec, current_vec, min_mask);\n    }\n    \n    // Extract minimum value\n    alignas(32) int min_values[8];\n    _mm256_store_si256((__m256i*)min_values, min_vec);\n    int min_val = min_values[0];\n    \n    // Find actual minimum index\n    for (int i = 0; i < n; i++) {\n        if (arr[i] == min_val) {\n            min_idx = i;\n            break;\n        }\n    }\n    \n    // Check if rotated array is sorted\n    for (int shift = 0; shift < n; shift++) {\n        bool is_sorted = true;\n        \n        for (int i = 0; i < n - 1; i += 8) {\n            int remaining = std::min(8, n - 1 - i);\n            __m256i vec1, vec2;\n            \n            if (remaining == 8) {\n                vec1 = _mm256_loadu_si256((__m256i*)&arr[(min_idx + i) % n]);\n                vec2 = _mm256_loadu_si256((__m256i*)&arr[(min_idx + i + 1) % n]);\n            } else {\n                // Handle partial vector for last chunk\n                vec1 = _mm256_set1_epi32(INT_MIN);\n                vec2 = _mm256_set1_epi32(INT_MAX);\n                \n                for (int j = 0; j < remaining; j++) {\n                    ((int*)&vec1)[j] = arr[(min_idx + i + j) % n];\n                    ((int*)&vec2)[j] = arr[(min_idx + i + j + 1) % n];\n                }\n            }\n            \n            __m256i cmp_mask = _mm256_cmpgt_epi32(vec1, vec2);\n            if (_mm256_movemask_epi8(cmp_mask)) {\n                is_sorted = false;\n                break;\n            }\n        }\n        \n        if (is_sorted) return true;\n        min_idx = (min_idx + 1) % n;\n    }\n    \n    return false;\n}\n```"}
{"task_id": "SimdBench_115_AVX", "completion": "```cpp\nbool move_one_ball_simd(std::vector<int> arr) {\n    int n = arr.size();\n    if (n <= 1) return true;\n\n    // Find the minimum element's index\n    __m256i min_vec = _mm256_set1_epi32(INT_MAX);\n    int min_idx = 0;\n    \n    for (int i = 0; i < n; i += 8) {\n        int remaining = std::min(8, n - i);\n        __m256i current_vec;\n        \n        if (remaining == 8) {\n            current_vec = _mm256_loadu_si256((__m256i*)&arr[i]);\n        } else {\n            // Handle partial vector for last chunk\n            current_vec = _mm256_set1_epi32(INT_MAX);\n            for (int j = 0; j < remaining; j++) {\n                ((int*)&current_vec)[j] = arr[i + j];\n            }\n        }\n        \n        __m256i min_mask = _mm256_cmpgt_epi32(min_vec, current_vec);\n        min_vec = _mm256_blendv_epi8(min_vec, current_vec, min_mask);\n    }\n    \n    // Extract minimum element\n    alignas(32) int min_elements[8];\n    _mm256_store_si256((__m256i*)min_elements, min_vec);\n    int min_element = min_elements[0];\n    \n    // Find the index of minimum element\n    for (int i = 0; i < n; i++) {\n        if (arr[i] == min_element) {\n            min_idx = i;\n            break;\n        }\n    }\n    \n    // Check if array can be sorted by right shifts\n    for (int shift = 0; shift < n; shift++) {\n        bool is_sorted = true;\n        for (int i = 0; i < n - 1; i++) {\n            int curr = arr[(min_idx + i + shift) % n];\n            int next = arr[(min_idx + i + shift + 1) % n];\n            if (curr > next) {\n                is_sorted = false;\n                break;\n            }\n        }\n        if (is_sorted) return true;\n    }\n    \n    return false;\n}\n```"}
{"task_id": "SimdBench_116_AVX", "completion": "```cpp\nstd::string myexchange_simd(const std::vector<int>& lst1, const std::vector<int>& lst2) {\n    int odd_count1 = 0, odd_count2 = 0;\n    int even_count2 = 0;\n    \n    // Use AVX2 to count odd/even numbers in parallel\n    int n = lst1.size();\n    int vec_size = 8; // AVX2 processes 8 integers at a time\n    \n    for (int i = 0; i <= n - vec_size; i += vec_size) {\n        __m256i vec1 = _mm256_loadu_si256((__m256i*)&lst1[i]);\n        __m256i vec2 = _mm256_loadu_si256((__m256i*)&lst2[i]);\n        \n        // Create mask for odd numbers (last bit is 1)\n        __m256i mask = _mm256_set1_epi32(1);\n        __m256i odd_mask1 = _mm256_and_si256(vec1, mask);\n        __m256i odd_mask2 = _mm256_and_si256(vec2, mask);\n        \n        // Count odd numbers\n        odd_count1 += _mm_popcnt_u32(_mm256_movemask_epi8(odd_mask1));\n        odd_count2 += _mm_popcnt_u32(_mm256_movemask_epi8(odd_mask2));\n        \n        // Count even numbers in lst2\n        __m256i even_mask2 = _mm256_xor_si256(odd_mask2, mask);\n        even_count2 += _mm_popcnt_u32(_mm256_movemask_epi8(even_mask2));\n    }\n    \n    // Handle remaining elements\n    for (int i = n - (n % vec_size); i < n; ++i) {\n        if (lst1[i] % 2 == 1) odd_count1++;\n        if (lst2[i] % 2 == 1) odd_count2++;\n        if (lst2[i] % 2 == 0) even_count2++;\n    }\n    \n    // Check if we can exchange to make lst1 all even\n    return (odd_count1 <= even_count2) ? \"YES\" : \"NO\";\n}\n```"}
{"task_id": "SimdBench_116_AVX", "completion": "```cpp\nstd::string myexchange_simd(const std::vector<int>& lst1, const std::vector<int>& lst2) {\n    int odd_count1 = 0, odd_count2 = 0;\n    int size = lst1.size();\n\n    // Use AVX2 to count odd numbers in parallel\n    __m256i odd_mask = _mm256_set1_epi32(1);\n    __m256i zero_vec = _mm256_setzero_si256();\n    __m256i odd_count_vec1 = _mm256_setzero_si256();\n    __m256i odd_count_vec2 = _mm256_setzero_si256();\n\n    for (int i = 0; i < size; i += 8) {\n        int remaining = size - i;\n        __m256i vec1, vec2;\n\n        if (remaining >= 8) {\n            vec1 = _mm256_loadu_si256((__m256i*)&lst1[i]);\n            vec2 = _mm256_loadu_si256((__m256i*)&lst2[i]);\n        } else {\n            // Handle remaining elements with masking\n            vec1 = _mm256_maskload_epi32(&lst1[i], _mm256_set1_epi32(-1 << (32 * (8 - remaining))));\n            vec2 = _mm256_maskload_epi32(&lst2[i], _mm256_set1_epi32(-1 << (32 * (8 - remaining))));\n        }\n\n        // Check odd numbers\n        __m256i odd1 = _mm256_and_si256(_mm256_and_si256(vec1, odd_mask), _mm256_cmpeq_epi32(vec1, _mm256_and_si256(vec1, odd_mask)));\n        __m256i odd2 = _mm256_and_si256(_mm256_and_si256(vec2, odd_mask), _mm256_cmpeq_epi32(vec2, _mm256_and_si256(vec2, odd_mask)));\n\n        // Accumulate odd counts\n        odd_count_vec1 = _mm256_add_epi32(odd_count_vec1, _mm256_sad_epu8(odd1, zero_vec));\n        odd_count_vec2 = _mm256_add_epi32(odd_count_vec2, _mm256_sad_epu8(odd2, zero_vec));\n    }\n\n    // Horizontal sum of odd counts\n    __m128i sum1 = _mm_add_epi32(_mm256_extracti128_si256(odd_count_vec1, 0), _mm256_extracti128_si256(odd_count_vec1, 1));\n    __m128i sum2 = _mm_add_epi32(_mm256_extracti128_si256(odd_count_vec2, 0), _mm256_extracti128_si256(odd_count_vec2, 1));\n    sum1 = _mm_hadd_epi32(sum1, sum1);\n    sum2 = _mm_hadd_epi32(sum2, sum2);\n    odd_count1 = _mm_cvtsi128_si32(sum1);\n    odd_count2 = _mm_cvtsi128_si32(sum2);\n\n    // Check if odd numbers can be exchanged\n    return (odd_count1 <= odd_count2) ? \"YES\" : \"NO\";\n}\n```"}
{"task_id": "SimdBench_116_AVX", "completion": "```cpp\nstd::string myexchange_simd(const std::vector<int>& lst1, const std::vector<int>& lst2) {\n    int odd_count1 = 0, odd_count2 = 0;\n    int even_count2 = 0;\n    \n    // Use AVX2 to count odd/even numbers in parallel\n    int n = lst1.size();\n    int vec_size = 8; // AVX2 processes 8 integers at a time\n    \n    for (int i = 0; i <= n - vec_size; i += vec_size) {\n        __m256i vec1 = _mm256_loadu_si256((__m256i*)&lst1[i]);\n        __m256i vec2 = _mm256_loadu_si256((__m256i*)&lst2[i]);\n        \n        // Check odd/even using bitwise AND with 1\n        __m256i ones = _mm256_set1_epi32(1);\n        __m256i odd_mask1 = _mm256_and_si256(vec1, ones);\n        __m256i odd_mask2 = _mm256_and_si256(vec2, ones);\n        \n        // Count odd numbers in lst1\n        __m256i odd_count_vec1 = _mm256_cmpeq_epi32(odd_mask1, ones);\n        odd_count1 += _mm256_movemask_ps((__m256)odd_count_vec1);\n        \n        // Count odd and even numbers in lst2\n        __m256i odd_count_vec2 = _mm256_cmpeq_epi32(odd_mask2, ones);\n        odd_count2 += _mm256_movemask_ps((__m256)odd_count_vec2);\n        __m256i even_count_vec2 = _mm256_cmpeq_epi32(odd_mask2, _mm256_setzero_si256());\n        even_count2 += _mm256_movemask_ps((__m256)even_count_vec2);\n    }\n    \n    // Handle remaining elements\n    for (int i = n - (n % vec_size); i < n; ++i) {\n        if (lst1[i] % 2 == 1) odd_count1++;\n        if (lst2[i] % 2 == 1) odd_count2++;\n        if (lst2[i] % 2 == 0) even_count2++;\n    }\n    \n    // Check if we can exchange to make lst1 all even\n    return (odd_count1 <= even_count2) ? \"YES\" : \"NO\";\n}\n```"}
{"task_id": "SimdBench_116_AVX", "completion": "```cpp\nstd::string myexchange_simd(const std::vector<int>& lst1, const std::vector<int>& lst2) {\n    int odd_count1 = 0, odd_count2 = 0;\n    int size = lst1.size();\n\n    // Use AVX2 to count odd numbers in parallel\n    __m256i odd_mask1 = _mm256_setzero_si256();\n    __m256i odd_mask2 = _mm256_setzero_si256();\n\n    for (int i = 0; i < size; i += 8) {\n        __m256i vec1 = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&lst1[i]));\n        __m256i vec2 = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&lst2[i]));\n\n        // Check for odd numbers using bitwise AND\n        __m256i ones = _mm256_set1_epi32(1);\n        __m256i odd_check1 = _mm256_and_si256(vec1, ones);\n        __m256i odd_check2 = _mm256_and_si256(vec2, ones);\n\n        // Compare with 1 to identify odd numbers\n        __m256i is_odd1 = _mm256_cmpeq_epi32(odd_check1, ones);\n        __m256i is_odd2 = _mm256_cmpeq_epi32(odd_check2, ones);\n\n        // Accumulate odd counts\n        odd_mask1 = _mm256_add_epi32(odd_mask1, _mm256_srli_epi32(is_odd1, 31));\n        odd_mask2 = _mm256_add_epi32(odd_mask2, _mm256_srli_epi32(is_odd2, 31));\n    }\n\n    // Horizontal sum of odd counts\n    __m128i sum1 = _mm_add_epi32(_mm256_extracti128_si256(odd_mask1, 0), \n                                  _mm256_extracti128_si256(odd_mask1, 1));\n    __m128i sum2 = _mm_add_epi32(_mm256_extracti128_si256(odd_mask2, 0), \n                                  _mm256_extracti128_si256(odd_mask2, 1));\n\n    sum1 = _mm_hadd_epi32(sum1, sum1);\n    sum2 = _mm_hadd_epi32(sum2, sum2);\n\n    odd_count1 = _mm_cvtsi128_si32(sum1);\n    odd_count2 = _mm_cvtsi128_si32(sum2);\n\n    // Handle remaining elements if size is not multiple of 8\n    for (int i = size - (size % 8); i < size; ++i) {\n        if (lst1[i] % 2 == 1) odd_count1++;\n        if (lst2[i] % 2 == 1) odd_count2++;\n    }\n\n    // If odd numbers in lst1 can be replaced by even numbers from lst2\n    return (odd_count1 <= odd_count2) ? \"YES\" : \"NO\";\n}\n```"}
{"task_id": "SimdBench_116_AVX", "completion": "```cpp\nstd::string myexchange_simd(const std::vector<int>& lst1, const std::vector<int>& lst2) {\n    int odd_count1 = 0, odd_count2 = 0;\n    int even_count2 = 0;\n    \n    // Use AVX2 to count odd/even numbers in parallel\n    int n = lst1.size();\n    int vec_size = 8; // AVX2 processes 8 integers at a time\n    \n    for (int i = 0; i + vec_size <= n; i += vec_size) {\n        __m256i vec1 = _mm256_loadu_si256((__m256i*)&lst1[i]);\n        __m256i vec2 = _mm256_loadu_si256((__m256i*)&lst2[i]);\n        \n        // Check odd numbers in lst1\n        __m256i odd_mask1 = _mm256_and_si256(vec1, _mm256_set1_epi32(1));\n        odd_count1 += _mm_popcnt_u32(_mm256_movemask_epi8(odd_mask1));\n        \n        // Check odd numbers in lst2\n        __m256i odd_mask2 = _mm256_and_si256(vec2, _mm256_set1_epi32(1));\n        odd_count2 += _mm_popcnt_u32(_mm256_movemask_epi8(odd_mask2));\n        \n        // Count even numbers in lst2\n        __m256i even_mask2 = _mm256_xor_si256(odd_mask2, _mm256_set1_epi32(1));\n        even_count2 += _mm_popcnt_u32(_mm256_movemask_epi8(even_mask2));\n    }\n    \n    // Handle remaining elements\n    for (int i = n - (n % vec_size); i < n; ++i) {\n        if (lst1[i] % 2 == 1) odd_count1++;\n        if (lst2[i] % 2 == 1) odd_count2++;\n        if (lst2[i] % 2 == 0) even_count2++;\n    }\n    \n    // Check if we can exchange to make lst1 all even\n    return (odd_count1 <= even_count2) ? \"YES\" : \"NO\";\n}\n```"}
{"task_id": "SimdBench_117_AVX", "completion": "```cpp\nstd::vector<std::string> odd_count_simd(const std::vector<std::string> & lst) {\n    std::vector<std::string> result;\n    result.reserve(lst.size());\n\n    for (const auto& str : lst) {\n        int odd_count = 0;\n        size_t len = str.length();\n\n        // Process 16 characters at a time using AVX2\n        size_t i = 0;\n        for (; i + 16 <= len; i += 16) {\n            __m256i chars = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(str.data() + i));\n            \n            // Subtract '0' to convert chars to numeric values\n            __m256i zero = _mm256_set1_epi8('0');\n            __m256i numeric_vals = _mm256_sub_epi8(chars, zero);\n            \n            // Check which digits are odd\n            __m256i ones = _mm256_set1_epi8(1);\n            __m256i odd_mask = _mm256_and_si256(numeric_vals, ones);\n            \n            // Count odd digits\n            __m256i sad = _mm256_sad_epu8(odd_mask, _mm256_setzero_si256());\n            odd_count += _mm256_extract_epi16(sad, 0) + \n                         _mm256_extract_epi16(sad, 4) + \n                         _mm256_extract_epi16(sad, 8) + \n                         _mm256_extract_epi16(sad, 12);\n        }\n\n        // Process remaining characters\n        for (; i < len; ++i) {\n            if ((str[i] - '0') % 2 == 1) {\n                odd_count++;\n            }\n        }\n\n        // Create result string\n        result.push_back(\"the number of odd elements \" + std::to_string(odd_count) + \n                         \"n the str\" + std::to_string(odd_count) + \n                         \"ng \" + std::to_string(odd_count) + \" of the \" + \n                         std::to_string(odd_count) + \"nput.\");\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_117_AVX", "completion": "```cpp\nstd::vector<std::string> odd_count_simd(const std::vector<std::string> & lst) {\n    std::vector<std::string> result;\n    result.reserve(lst.size());\n\n    for (const auto& str : lst) {\n        int odd_count = 0;\n        const char* data = str.data();\n        size_t len = str.length();\n\n        // Process 16 characters at a time using AVX2\n        size_t i = 0;\n        for (; i + 16 <= len; i += 16) {\n            __m256i chars = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(data + i));\n            \n            // Subtract '0' to convert chars to numeric values\n            __m256i zero = _mm256_set1_epi8('0');\n            __m256i numeric_vals = _mm256_sub_epi8(chars, zero);\n            \n            // Check which digits are odd\n            __m256i ones = _mm256_set1_epi8(1);\n            __m256i odd_mask = _mm256_and_si256(numeric_vals, ones);\n            \n            // Count odd digits\n            odd_count += _mm_popcnt_u32(_mm256_movemask_epi8(odd_mask));\n        }\n\n        // Process remaining characters\n        for (; i < len; ++i) {\n            if ((data[i] - '0') % 2 == 1) {\n                odd_count++;\n            }\n        }\n\n        // Create result string\n        result.push_back(\"the number of odd elements \" + std::to_string(odd_count) + \n                         \"n the str\" + std::to_string(odd_count) + \n                         \"ng \" + std::to_string(odd_count) + \" of the \" + \n                         std::to_string(odd_count) + \"nput.\");\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_117_AVX", "completion": "```cpp\nstd::vector<std::string> odd_count_simd(const std::vector<std::string> & lst) {\n    std::vector<std::string> result;\n    result.reserve(lst.size());\n\n    for (const auto& str : lst) {\n        int odd_count = 0;\n        size_t len = str.length();\n        \n        // Process 16 characters at a time using AVX2\n        size_t i = 0;\n        for (; i + 16 <= len; i += 16) {\n            __m256i chars = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(str.data() + i));\n            \n            // Subtract '0' to convert chars to numeric values\n            __m256i zero = _mm256_set1_epi8('0');\n            __m256i numeric_vals = _mm256_sub_epi8(chars, zero);\n            \n            // Check which digits are odd\n            __m256i ones = _mm256_set1_epi8(1);\n            __m256i odd_mask = _mm256_and_si256(numeric_vals, ones);\n            \n            // Count odd digits\n            odd_count += _mm_popcnt_u32(_mm256_movemask_epi8(odd_mask));\n        }\n        \n        // Process remaining characters\n        for (; i < len; ++i) {\n            if ((str[i] - '0') % 2 == 1) {\n                odd_count++;\n            }\n        }\n        \n        // Create result string\n        result.push_back(\"the number of odd elements \" + std::to_string(odd_count) + \n                         \"n the str\" + std::to_string(odd_count) + \n                         \"ng \" + std::to_string(odd_count) + \" of the \" + \n                         std::to_string(odd_count) + \"nput.\");\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_117_AVX", "completion": "```cpp\nstd::vector<std::string> odd_count_simd(const std::vector<std::string> & lst) {\n    std::vector<std::string> result;\n    result.reserve(lst.size());\n\n    for (const auto& str : lst) {\n        int odd_count = 0;\n        size_t len = str.length();\n        \n        // Process 16 characters at a time using AVX2\n        size_t i = 0;\n        for (; i + 16 <= len; i += 16) {\n            __m256i chars = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(str.data() + i));\n            \n            // Subtract '0' to convert chars to numeric values\n            __m256i zero = _mm256_set1_epi8('0');\n            __m256i numeric_vals = _mm256_sub_epi8(chars, zero);\n            \n            // Check which digits are odd using bitwise AND\n            __m256i ones = _mm256_set1_epi8(1);\n            __m256i odd_mask = _mm256_and_si256(numeric_vals, ones);\n            \n            // Count odd digits\n            __m256i cmp_mask = _mm256_cmpeq_epi8(odd_mask, ones);\n            odd_count += _mm_popcnt_u32(_mm256_movemask_epi8(cmp_mask));\n        }\n        \n        // Process remaining characters\n        for (; i < len; ++i) {\n            if ((str[i] - '0') % 2 == 1) {\n                ++odd_count;\n            }\n        }\n        \n        // Create result string\n        result.push_back(\"the number of odd elements \" + std::to_string(odd_count) + \n                         \"n the str\" + std::to_string(odd_count) + \n                         \"ng \" + std::to_string(odd_count) + \" of the \" + \n                         std::to_string(odd_count) + \"nput.\");\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_117_AVX", "completion": "```cpp\nstd::vector<std::string> odd_count_simd(const std::vector<std::string> & lst) {\n    std::vector<std::string> result;\n    result.reserve(lst.size());\n\n    for (const auto& str : lst) {\n        int odd_count = 0;\n        size_t len = str.length();\n        \n        // Process 16 characters at a time using AVX2\n        size_t i = 0;\n        for (; i + 16 <= len; i += 16) {\n            __m256i chars = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(str.data() + i));\n            \n            // Subtract '0' to convert chars to numeric values\n            __m256i zero = _mm256_set1_epi8('0');\n            __m256i numeric_vals = _mm256_sub_epi8(chars, zero);\n            \n            // Check which digits are odd\n            __m256i ones = _mm256_set1_epi8(1);\n            __m256i odd_mask = _mm256_and_si256(numeric_vals, ones);\n            \n            // Count odd digits\n            __m256i sad = _mm256_sad_epu8(odd_mask, _mm256_setzero_si256());\n            odd_count += _mm256_extract_epi16(sad, 0) + \n                         _mm256_extract_epi16(sad, 4) + \n                         _mm256_extract_epi16(sad, 8) + \n                         _mm256_extract_epi16(sad, 12);\n        }\n        \n        // Process remaining characters\n        for (; i < len; ++i) {\n            if ((str[i] - '0') % 2 == 1) {\n                odd_count++;\n            }\n        }\n        \n        // Create result string\n        result.push_back(\"the number of odd elements \" + std::to_string(odd_count) + \n                         \"n the str\" + std::to_string(odd_count) + \n                         \"ng \" + std::to_string(odd_count) + \" of the \" + \n                         std::to_string(odd_count) + \"nput.\");\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_118_AVX", "completion": "```cpp\nint64_t minSubArraySum_simd(const std::vector<int64_t>& nums) {\n    int n = nums.size();\n    if (n == 0) return 0;\n\n    __m256i min_sum_vec = _mm256_set1_epi64x(INT64_MAX);\n    __m256i current_sum_vec = _mm256_setzero_si256();\n    \n    for (int i = 0; i < n; i += 4) {\n        __m256i chunk = _mm256_loadu_si256((__m256i*)&nums[i]);\n        \n        current_sum_vec = _mm256_add_epi64(current_sum_vec, chunk);\n        min_sum_vec = _mm256_min_epi64(min_sum_vec, current_sum_vec);\n        \n        __m256i zero_vec = _mm256_setzero_si256();\n        current_sum_vec = _mm256_max_epi64(current_sum_vec, zero_vec);\n    }\n    \n    int64_t min_sums[4];\n    _mm256_storeu_si256((__m256i*)min_sums, min_sum_vec);\n    \n    int64_t global_min = min_sums[0];\n    for (int j = 1; j < 4; j++) {\n        global_min = std::min(global_min, min_sums[j]);\n    }\n    \n    return global_min;\n}\n```"}
{"task_id": "SimdBench_118_AVX", "completion": "```cpp\nint64_t minSubArraySum_simd(const std::vector<int64_t>& nums) {\n    int n = nums.size();\n    if (n == 0) return 0;\n    \n    // Initialize min sum with first element\n    int64_t min_sum = nums[0];\n    int64_t current_sum = 0;\n    \n    // Process 4 elements at a time using AVX2\n    __m256i min_sum_vec = _mm256_set1_epi64x(INT64_MAX);\n    __m256i current_sum_vec = _mm256_setzero_si256();\n    \n    int i;\n    for (i = 0; i + 4 <= n; i += 4) {\n        // Load 4 elements\n        __m256i vec = _mm256_loadu_si256((__m256i*)&nums[i]);\n        \n        // Update current sum vector\n        current_sum_vec = _mm256_add_epi64(current_sum_vec, vec);\n        \n        // Update min sum vector\n        min_sum_vec = _mm256_min_epi64(min_sum_vec, current_sum_vec);\n        \n        // Reset current sum if it becomes positive\n        __m256i zero_vec = _mm256_setzero_si256();\n        current_sum_vec = _mm256_min_epi64(current_sum_vec, zero_vec);\n    }\n    \n    // Horizontal min for SIMD vector\n    __m128i low128 = _mm256_extracti128_si256(min_sum_vec, 0);\n    __m128i high128 = _mm256_extracti128_si256(min_sum_vec, 1);\n    __m128i min_vec = _mm_min_epi64(low128, high128);\n    \n    // Scalar fallback for remaining elements\n    for (; i < n; i++) {\n        current_sum += nums[i];\n        min_sum = std::min(min_sum, current_sum);\n        if (current_sum > 0) current_sum = 0;\n    }\n    \n    // Combine SIMD and scalar results\n    int64_t simd_min = _mm_cvtsi128_si64(min_vec);\n    return std::min(min_sum, simd_min);\n}\n```"}
{"task_id": "SimdBench_118_AVX", "completion": "```cpp\nint64_t minSubArraySum_simd(const std::vector<int64_t>& nums) {\n    int n = nums.size();\n    if (n == 0) return 0;\n    \n    __m256i min_sum_vec = _mm256_set1_epi64x(INT64_MAX);\n    __m256i current_sum_vec = _mm256_setzero_si256();\n    \n    for (int i = 0; i <= n - 4; i += 4) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&nums[i]);\n        \n        current_sum_vec = _mm256_add_epi64(current_sum_vec, vec);\n        min_sum_vec = _mm256_min_epi64(min_sum_vec, current_sum_vec);\n        \n        __m256i zero_vec = _mm256_setzero_si256();\n        current_sum_vec = _mm256_max_epi64(current_sum_vec, zero_vec);\n    }\n    \n    int64_t min_sums[4];\n    _mm256_storeu_si256((__m256i*)min_sums, min_sum_vec);\n    \n    int64_t min_sum = min_sums[0];\n    for (int i = 1; i < 4; i++) {\n        min_sum = std::min(min_sum, min_sums[i]);\n    }\n    \n    for (int i = n - (n % 4); i < n; i++) {\n        min_sum = std::min(min_sum, nums[i]);\n    }\n    \n    return min_sum;\n}\n```"}
{"task_id": "SimdBench_118_AVX", "completion": "```cpp\nint64_t minSubArraySum_simd(const std::vector<int64_t>& nums) {\n    int n = nums.size();\n    if (n == 0) return 0;\n\n    __m256i min_sum_vec = _mm256_set1_epi64x(INT64_MAX);\n    __m256i current_sum_vec = _mm256_setzero_si256();\n    \n    for (int i = 0; i < n; i += 4) {\n        __m256i chunk;\n        if (i + 4 <= n) {\n            chunk = _mm256_loadu_si256((__m256i*)&nums[i]);\n        } else {\n            // Handle remaining elements\n            chunk = _mm256_set1_epi64x(0);\n            for (int j = i; j < n; j++) {\n                chunk = _mm256_insert_epi64(chunk, nums[j], j - i);\n            }\n        }\n\n        current_sum_vec = _mm256_add_epi64(current_sum_vec, chunk);\n        min_sum_vec = _mm256_min_epi64(min_sum_vec, current_sum_vec);\n        \n        __m256i zero_vec = _mm256_setzero_si256();\n        current_sum_vec = _mm256_max_epi64(current_sum_vec, zero_vec);\n    }\n\n    int64_t min_sum_array[4];\n    _mm256_storeu_si256((__m256i*)min_sum_array, min_sum_vec);\n    \n    int64_t min_sum = min_sum_array[0];\n    for (int i = 1; i < 4; i++) {\n        min_sum = std::min(min_sum, min_sum_array[i]);\n    }\n\n    return min_sum;\n}\n```"}
{"task_id": "SimdBench_118_AVX", "completion": "```cpp\nint64_t minSubArraySum_simd(const std::vector<int64_t>& nums) {\n    int n = nums.size();\n    if (n == 0) return 0;\n\n    // Initialize min sum with first element\n    int64_t min_sum = nums[0];\n    int64_t current_sum = 0;\n\n    // Process 4 elements at a time using AVX2\n    int i = 0;\n    __m256i min_sum_vec = _mm256_set1_epi64x(INT64_MAX);\n    __m256i current_sum_vec = _mm256_setzero_si256();\n\n    // Process 4 elements in parallel\n    for (; i + 4 <= n; i += 4) {\n        __m256i nums_vec = _mm256_loadu_si256((__m256i*)&nums[i]);\n        \n        // Compute cumulative sums\n        current_sum_vec = _mm256_add_epi64(current_sum_vec, nums_vec);\n        \n        // Update min sum\n        min_sum_vec = _mm256_min_epi64(min_sum_vec, current_sum_vec);\n        \n        // Reset current sum if it becomes positive\n        __m256i zero_vec = _mm256_setzero_si256();\n        current_sum_vec = _mm256_min_epi64(current_sum_vec, zero_vec);\n    }\n\n    // Horizontal min reduction\n    int64_t min_sums[4];\n    _mm256_storeu_si256((__m256i*)min_sums, min_sum_vec);\n    \n    for (int j = 0; j < 4; j++) {\n        min_sum = std::min(min_sum, min_sums[j]);\n    }\n\n    // Process remaining elements sequentially\n    current_sum = 0;\n    for (; i < n; i++) {\n        current_sum += nums[i];\n        min_sum = std::min(min_sum, current_sum);\n        current_sum = std::min(current_sum, 0LL);\n    }\n\n    return min_sum;\n}\n```"}
{"task_id": "SimdBench_119_AVX", "completion": "```cpp\nint max_fill_simd(const std::vector<std::vector<int> > & grid, int capacity) {\n    int rows = grid.size();\n    int cols = grid[0].size();\n    int total_water = 0;\n    \n    // Use AVX2 to count water in parallel\n    for (int i = 0; i < rows; i += 8) {\n        __m256i water_sum = _mm256_setzero_si256();\n        \n        for (int j = 0; j < cols; j++) {\n            __m256i row_water = _mm256_setzero_si256();\n            \n            // Load 8 rows of water at a time\n            for (int k = 0; k < 8 && i + k < rows; k++) {\n                int water_val = (j < grid[i + k].size()) ? grid[i + k][j] : 0;\n                row_water = _mm256_insert_epi32(row_water, water_val, k);\n            }\n            \n            water_sum = _mm256_add_epi32(water_sum, row_water);\n        }\n        \n        // Horizontal sum of water\n        __m256i sum_lo = _mm256_castsi256_si128(water_sum);\n        __m256i sum_hi = _mm256_extracti128_si256(water_sum, 1);\n        sum_lo = _mm_add_epi32(sum_lo, sum_hi);\n        sum_lo = _mm_hadd_epi32(sum_lo, sum_lo);\n        sum_lo = _mm_hadd_epi32(sum_lo, sum_lo);\n        \n        total_water += _mm_cvtsi128_si32(sum_lo);\n    }\n    \n    // Calculate number of bucket lowerings\n    return (total_water + capacity - 1) / capacity;\n}\n```"}
{"task_id": "SimdBench_119_AVX", "completion": "```cpp\nint max_fill_simd(const std::vector<std::vector<int> > & grid, int capacity) {\n    int rows = grid.size();\n    int cols = grid[0].size();\n    int total_water = 0;\n    \n    // Use AVX2 to count water in parallel\n    for (int i = 0; i < rows; i += 8) {\n        __m256i water_sum = _mm256_setzero_si256();\n        \n        for (int j = 0; j < cols; j++) {\n            __m256i row_data = _mm256_setzero_si256();\n            \n            // Load 8 rows of data or handle remaining rows\n            for (int k = 0; k < 8 && (i + k) < rows; k++) {\n                int water_in_row = std::count(grid[i + k].begin(), grid[i + k].end(), 1);\n                row_data = _mm256_insert_epi32(row_data, water_in_row, k);\n            }\n            \n            water_sum = _mm256_add_epi32(water_sum, row_data);\n        }\n        \n        // Horizontal sum of water\n        __m256i sum_shuffle = _mm256_hadd_epi32(water_sum, water_sum);\n        sum_shuffle = _mm256_hadd_epi32(sum_shuffle, sum_shuffle);\n        int water_block = _mm256_extract_epi32(sum_shuffle, 0) + _mm256_extract_epi32(sum_shuffle, 4);\n        \n        total_water += water_block;\n    }\n    \n    // Calculate number of bucket lowerings\n    return (total_water + capacity - 1) / capacity;\n}\n```"}
{"task_id": "SimdBench_119_AVX", "completion": "```cpp\nint max_fill_simd(const std::vector<std::vector<int> > & grid, int capacity) {\n    int rows = grid.size();\n    int cols = grid[0].size();\n    int total_water = 0;\n    \n    // Use AVX2 to count water in parallel\n    for (int i = 0; i < rows; i += 8) {\n        __m256i water_sum = _mm256_setzero_si256();\n        \n        for (int j = 0; j < cols; j++) {\n            __m256i row_water = _mm256_setzero_si256();\n            \n            // Load 8 rows at a time (or fewer if near end)\n            for (int k = 0; k < 8 && (i + k) < rows; k++) {\n                int water_val = (j < grid[i + k].size()) ? grid[i + k][j] : 0;\n                row_water = _mm256_insert_epi32(row_water, water_val, k);\n            }\n            \n            water_sum = _mm256_add_epi32(water_sum, row_water);\n        }\n        \n        // Horizontal sum of water\n        int water_array[8];\n        _mm256_storeu_si256((__m256i*)water_array, water_sum);\n        \n        for (int k = 0; k < 8 && (i + k) < rows; k++) {\n            total_water += water_array[k];\n        }\n    }\n    \n    // Calculate number of bucket lowerings\n    return (total_water + capacity - 1) / capacity;\n}\n```"}
{"task_id": "SimdBench_119_AVX", "completion": "```cpp\nint max_fill_simd(const std::vector<std::vector<int> > & grid, int capacity) {\n    int rows = grid.size();\n    int cols = grid[0].size();\n    int total_water = 0;\n    \n    // Use AVX2 to count water in parallel\n    for (int i = 0; i < rows; i += 8) {\n        __m256i water_sum = _mm256_setzero_si256();\n        \n        for (int j = 0; j < cols; j++) {\n            __m256i row_water = _mm256_setzero_si256();\n            \n            // Load 8 rows at a time (or fewer for last iteration)\n            for (int k = 0; k < 8 && (i + k) < rows; k++) {\n                int water_val = (j < grid[i + k].size()) ? grid[i + k][j] : 0;\n                row_water = _mm256_insert_epi32(row_water, water_val, k);\n            }\n            \n            water_sum = _mm256_add_epi32(water_sum, row_water);\n        }\n        \n        // Horizontal sum of water\n        __m256i sum_shuffle = _mm256_hadd_epi32(water_sum, water_sum);\n        sum_shuffle = _mm256_hadd_epi32(sum_shuffle, sum_shuffle);\n        \n        int water_block[8];\n        _mm256_storeu_si256((__m256i*)water_block, sum_shuffle);\n        total_water += water_block[0] + water_block[4];\n    }\n    \n    // Calculate number of bucket lowerings\n    return (total_water + capacity - 1) / capacity;\n}\n```"}
{"task_id": "SimdBench_119_AVX", "completion": "```cpp\nint max_fill_simd(const std::vector<std::vector<int> > & grid, int capacity) {\n    int rows = grid.size();\n    int cols = grid[0].size();\n    int total_water = 0;\n    \n    // Use AVX2 to parallelize water counting\n    for (int i = 0; i < rows; i += 8) {\n        __m256i water_sum = _mm256_setzero_si256();\n        \n        for (int j = 0; j < cols; j++) {\n            __m256i row_water = _mm256_setzero_si256();\n            \n            // Load 8 rows at a time if possible\n            for (int k = 0; k < 8 && (i + k) < rows; k++) {\n                int water_in_row = std::count(grid[i + k].begin(), grid[i + k].end(), 1);\n                row_water = _mm256_insert_epi32(row_water, water_in_row, k);\n            }\n            \n            water_sum = _mm256_add_epi32(water_sum, row_water);\n        }\n        \n        // Horizontal sum of water\n        __m128i sum_lo = _mm256_extracti128_si256(water_sum, 0);\n        __m128i sum_hi = _mm256_extracti128_si256(water_sum, 1);\n        __m128i sum = _mm_add_epi32(sum_lo, sum_hi);\n        sum = _mm_hadd_epi32(sum, sum);\n        sum = _mm_hadd_epi32(sum, sum);\n        \n        total_water += _mm_cvtsi128_si32(sum);\n    }\n    \n    // Calculate number of bucket lowerings\n    return (total_water + capacity - 1) / capacity;\n}\n```"}
{"task_id": "SimdBench_120_AVX", "completion": "```cpp\nint64_t solution_simd(const std::vector<int16_t>& lst) {\n    int64_t result = 0;\n    size_t n = lst.size();\n    size_t vectorSize = n - (n % 16);\n\n    __m256i sum = _mm256_setzero_si256();\n\n    for (size_t i = 0; i < vectorSize; i += 16) {\n        __m256i vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&lst[i]));\n        \n        // Create mask for even positions\n        __m256i evenPosMask = _mm256_set_epi16(\n            0, -1, 0, -1, 0, -1, 0, -1, \n            0, -1, 0, -1, 0, -1, 0, -1\n        );\n        \n        // Mask out elements in even positions\n        __m256i evenPosElements = _mm256_and_si256(vec, evenPosMask);\n        \n        // Create mask for odd elements\n        __m256i oddElementMask = _mm256_set1_epi16(1);\n        __m256i isOdd = _mm256_and_si256(vec, oddElementMask);\n        __m256i oddMask = _mm256_cmpeq_epi16(isOdd, oddElementMask);\n        \n        // Combine masks\n        __m256i finalMask = _mm256_and_si256(evenPosElements, oddMask);\n        \n        // Sum odd elements in even positions\n        __m256i sumVec = _mm256_and_si256(vec, finalMask);\n        sum = _mm256_add_epi16(sum, sumVec);\n    }\n\n    // Horizontal sum\n    __m128i sumLow = _mm256_extracti128_si256(sum, 0);\n    __m128i sumHigh = _mm256_extracti128_si256(sum, 1);\n    __m128i sumCombined = _mm_add_epi16(sumLow, sumHigh);\n    \n    int16_t sumArray[8];\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(sumArray), sumCombined);\n    \n    for (int i = 0; i < 8; i++) {\n        result += sumArray[i];\n    }\n\n    // Handle remaining elements\n    for (size_t i = vectorSize; i < n; i++) {\n        if (i % 2 == 0 && lst[i] % 2 == 1) {\n            result += lst[i];\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_120_AVX", "completion": "```cpp\nint64_t solution_simd(const std::vector<int16_t>& lst) {\n    int64_t result = 0;\n    size_t n = lst.size();\n    \n    // Process 16 elements at a time using AVX2\n    size_t vectorized_length = n - (n % 16);\n    \n    __m256i sum_vector = _mm256_setzero_si256();\n    \n    for (size_t i = 0; i < vectorized_length; i += 16) {\n        // Load 16 elements\n        __m256i data = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&lst[i]));\n        \n        // Create mask for even positions (0, 2, 4, 6, 8, 10, 12, 14)\n        __m256i even_mask = _mm256_set_epi16(\n            0, 1, 0, 3, 0, 5, 0, 7, \n            0, 9, 0, 11, 0, 13, 0, 15\n        );\n        \n        // Blend data with zeros to keep only even position elements\n        __m256i even_pos_data = _mm256_blendv_epi8(_mm256_setzero_si256(), data, even_mask);\n        \n        // Create mask for odd elements\n        __m256i odd_mask = _mm256_set1_epi16(1);\n        __m256i is_odd = _mm256_and_si256(_mm256_abs_epi16(even_pos_data), odd_mask);\n        is_odd = _mm256_cmpeq_epi16(is_odd, odd_mask);\n        \n        // Mask out non-odd elements\n        __m256i odd_elements = _mm256_and_si256(even_pos_data, is_odd);\n        \n        // Sum odd elements\n        sum_vector = _mm256_add_epi16(sum_vector, odd_elements);\n    }\n    \n    // Horizontal sum\n    __m128i sum_low = _mm256_extracti128_si256(sum_vector, 0);\n    __m128i sum_high = _mm256_extracti128_si256(sum_vector, 1);\n    \n    sum_low = _mm_add_epi16(sum_low, sum_high);\n    sum_low = _mm_hadd_epi16(sum_low, sum_low);\n    sum_low = _mm_hadd_epi16(sum_low, sum_low);\n    sum_low = _mm_hadd_epi16(sum_low, sum_low);\n    \n    result += _mm_extract_epi16(sum_low, 0);\n    \n    // Handle remaining elements\n    for (size_t i = vectorized_length; i < n; ++i) {\n        if (i % 2 == 0 && lst[i] % 2 == 1) {\n            result += lst[i];\n        }\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_120_AVX", "completion": "```cpp\nint64_t solution_simd(const std::vector<int16_t>& lst) {\n    int64_t result = 0;\n    size_t n = lst.size();\n    size_t vectorSize = n - (n % 16);\n\n    __m256i sum = _mm256_setzero_si256();\n\n    for (size_t i = 0; i < vectorSize; i += 16) {\n        __m256i vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&lst[i]));\n        \n        // Create mask for even positions (0, 2, 4, 6, 8, 10, 12, 14)\n        __m256i evenPosMask = _mm256_set_epi16(\n            0, 0xFFFF, 0, 0xFFFF, 0, 0xFFFF, 0, 0xFFFF,\n            0, 0xFFFF, 0, 0xFFFF, 0, 0xFFFF, 0, 0xFFFF\n        );\n        \n        // Mask to keep only elements at even positions\n        __m256i evenPosVec = _mm256_and_si256(vec, evenPosMask);\n        \n        // Create mask for odd elements\n        __m256i oddElementMask = _mm256_set1_epi16(0x0001);\n        __m256i oddElements = _mm256_and_si256(evenPosVec, oddElementMask);\n        \n        // Sum odd elements at even positions\n        sum = _mm256_add_epi16(sum, oddElements);\n    }\n\n    // Horizontal sum\n    __m128i low = _mm256_extracti128_si256(sum, 0);\n    __m128i high = _mm256_extracti128_si256(sum, 1);\n    __m128i total = _mm_add_epi16(low, high);\n    \n    int16_t scalar_sum[8];\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(scalar_sum), total);\n    \n    for (int i = 0; i < 8; i++) {\n        result += scalar_sum[i];\n    }\n\n    // Handle remaining elements\n    for (size_t i = vectorSize; i < n; i += 2) {\n        if (lst[i] % 2 == 1) {\n            result += lst[i];\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_120_AVX", "completion": "```cpp\nint64_t solution_simd(const std::vector<int16_t>& lst) {\n    int64_t result = 0;\n    size_t n = lst.size();\n    size_t vectorSize = n - (n % 16);\n\n    __m256i sumVector = _mm256_setzero_si256();\n\n    for (size_t i = 0; i < vectorSize; i += 16) {\n        __m256i loadedVector = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&lst[i]));\n        \n        // Create mask for even positions\n        __m256i evenPosMask = _mm256_set_epi16(\n            0, -1, 0, -1, 0, -1, 0, -1, \n            0, -1, 0, -1, 0, -1, 0, -1\n        );\n        \n        // Mask out odd elements in even positions\n        __m256i maskedVector = _mm256_and_si256(loadedVector, evenPosMask);\n        \n        // Keep only odd elements\n        __m256i oddMask = _mm256_set1_epi16(1);\n        __m256i oddElements = _mm256_and_si256(maskedVector, oddMask);\n        \n        // Sum odd elements\n        sumVector = _mm256_add_epi16(sumVector, oddElements);\n    }\n\n    // Horizontal sum\n    __m128i sum128 = _mm_add_epi16(_mm256_extracti128_si256(sumVector, 0), \n                                   _mm256_extracti128_si256(sumVector, 1));\n    sum128 = _mm_add_epi16(sum128, _mm_srli_si128(sum128, 8));\n    sum128 = _mm_add_epi16(sum128, _mm_srli_si128(sum128, 4));\n    sum128 = _mm_add_epi16(sum128, _mm_srli_si128(sum128, 2));\n    \n    result = _mm_cvtsi128_si32(sum128) & 0xFFFF;\n\n    // Handle remaining elements\n    for (size_t i = vectorSize; i < n; i += 2) {\n        if (lst[i] % 2 == 1) {\n            result += lst[i];\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_120_AVX", "completion": "```cpp\nint64_t solution_simd(const std::vector<int16_t>& lst) {\n    int64_t result = 0;\n    size_t n = lst.size();\n    size_t vectorSize = n - (n % 16);\n\n    __m256i sumVector = _mm256_setzero_si256();\n\n    for (size_t i = 0; i < vectorSize; i += 16) {\n        __m256i loadedVector = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&lst[i]));\n        \n        // Create mask for even positions\n        __m256i evenPosMask = _mm256_set_epi16(\n            0, -1, 0, -1, 0, -1, 0, -1, \n            0, -1, 0, -1, 0, -1, 0, -1\n        );\n        \n        // Mask out odd elements in even positions\n        __m256i maskedVector = _mm256_and_si256(loadedVector, evenPosMask);\n        \n        // Keep only odd elements\n        __m256i oddMask = _mm256_set1_epi16(0x0001);\n        __m256i oddElements = _mm256_and_si256(maskedVector, oddMask);\n        \n        // Sum odd elements\n        sumVector = _mm256_add_epi16(sumVector, oddElements);\n    }\n\n    // Horizontal sum\n    __m128i low = _mm256_extracti128_si256(sumVector, 0);\n    __m128i high = _mm256_extracti128_si256(sumVector, 1);\n    __m128i sum = _mm_add_epi16(low, high);\n    sum = _mm_hadd_epi16(sum, sum);\n    sum = _mm_hadd_epi16(sum, sum);\n    sum = _mm_hadd_epi16(sum, sum);\n\n    // Handle remaining elements\n    for (size_t i = vectorSize; i < n; i += 2) {\n        if (lst[i] % 2 == 1) {\n            result += lst[i];\n        }\n    }\n\n    return result + _mm_cvtsi128_si32(sum);\n}\n```"}
{"task_id": "SimdBench_121_AVX", "completion": "```cpp\nint add_elements_simd(std::vector<int> arr, int k) {\n    int sum = 0;\n    int i = 0;\n    \n    // Process 8 elements at a time using AVX2\n    __m256i sum_vec = _mm256_setzero_si256();\n    \n    for (; i + 8 <= k; i += 8) {\n        __m256i elements = _mm256_loadu_si256((__m256i*)&arr[i]);\n        \n        // Create mask for two-digit numbers (10 <= x <= 99)\n        __m256i lower_bound = _mm256_set1_epi32(10);\n        __m256i upper_bound = _mm256_set1_epi32(99);\n        \n        __m256i mask_lower = _mm256_cmpgt_epi32(elements, _mm256_sub_epi32(lower_bound, _mm256_set1_epi32(1)));\n        __m256i mask_upper = _mm256_cmpgt_epi32(upper_bound, _mm256_sub_epi32(elements, _mm256_set1_epi32(1)));\n        \n        __m256i two_digit_mask = _mm256_and_si256(mask_lower, mask_upper);\n        \n        // Mask elements and add to sum vector\n        __m256i masked_elements = _mm256_and_si256(elements, two_digit_mask);\n        sum_vec = _mm256_add_epi32(sum_vec, masked_elements);\n    }\n    \n    // Horizontal sum of vector\n    __m128i sum_low = _mm256_extracti128_si256(sum_vec, 0);\n    __m128i sum_high = _mm256_extracti128_si256(sum_vec, 1);\n    \n    sum_low = _mm_add_epi32(sum_low, sum_high);\n    sum_low = _mm_hadd_epi32(sum_low, sum_low);\n    sum_low = _mm_hadd_epi32(sum_low, sum_low);\n    \n    sum += _mm_cvtsi128_si32(sum_low);\n    \n    // Process remaining elements\n    for (; i < k; i++) {\n        if (arr[i] >= 10 && arr[i] <= 99) {\n            sum += arr[i];\n        }\n    }\n    \n    return sum;\n}\n```"}
{"task_id": "SimdBench_121_AVX", "completion": "```cpp\nint add_elements_simd(std::vector<int> arr, int k) {\n    int sum = 0;\n    int i = 0;\n    \n    // Process 8 elements at a time using AVX2\n    for (; i + 8 <= k; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&arr[i]);\n        \n        // Create mask for two-digit numbers (10 <= x <= 99)\n        __m256i lower_bound = _mm256_set1_epi32(10);\n        __m256i upper_bound = _mm256_set1_epi32(99);\n        \n        __m256i mask_lower = _mm256_cmpgt_epi32(vec, _mm256_sub_epi32(lower_bound, _mm256_set1_epi32(1)));\n        __m256i mask_upper = _mm256_cmpgt_epi32(upper_bound, _mm256_sub_epi32(vec, _mm256_set1_epi32(1)));\n        \n        __m256i two_digit_mask = _mm256_and_si256(mask_lower, mask_upper);\n        \n        // Mask the original vector to keep only two-digit numbers\n        __m256i two_digit_nums = _mm256_and_si256(vec, two_digit_mask);\n        \n        // Horizontal sum of two-digit numbers\n        __m128i sum_lo = _mm256_extracti128_si256(two_digit_nums, 0);\n        __m128i sum_hi = _mm256_extracti128_si256(two_digit_nums, 1);\n        \n        sum_lo = _mm_add_epi32(sum_lo, _mm_srli_si128(sum_lo, 8));\n        sum_lo = _mm_add_epi32(sum_lo, _mm_srli_si128(sum_lo, 4));\n        \n        sum_hi = _mm_add_epi32(sum_hi, _mm_srli_si128(sum_hi, 8));\n        sum_hi = _mm_add_epi32(sum_hi, _mm_srli_si128(sum_hi, 4));\n        \n        sum += _mm_cvtsi128_si32(sum_lo) + _mm_cvtsi128_si32(sum_hi);\n    }\n    \n    // Process remaining elements\n    for (; i < k; i++) {\n        if (arr[i] >= 10 && arr[i] <= 99) {\n            sum += arr[i];\n        }\n    }\n    \n    return sum;\n}\n```"}
{"task_id": "SimdBench_121_AVX", "completion": "```cpp\nint add_elements_simd(std::vector<int> arr, int k) {\n    int sum = 0;\n    int i = 0;\n    \n    // Process 8 elements at a time using AVX2\n    __m256i sum_vec = _mm256_setzero_si256();\n    \n    for (; i + 8 <= k; i += 8) {\n        __m256i elements = _mm256_loadu_si256((__m256i*)&arr[i]);\n        \n        // Create mask for elements with at most 2 digits\n        __m256i abs_mask = _mm256_set1_epi32(99);\n        __m256i abs_elements = _mm256_abs_epi32(elements);\n        __m256i mask = _mm256_cmpgt_epi32(abs_mask, abs_elements);\n        \n        // Blend elements that satisfy the condition\n        __m256i filtered_elements = _mm256_and_si256(elements, mask);\n        \n        // Add filtered elements to sum vector\n        sum_vec = _mm256_add_epi32(sum_vec, filtered_elements);\n    }\n    \n    // Horizontal sum of vector\n    __m128i sum_128 = _mm_add_epi32(_mm256_extracti128_si256(sum_vec, 0), \n                                     _mm256_extracti128_si256(sum_vec, 1));\n    sum_128 = _mm_hadd_epi32(sum_128, sum_128);\n    sum_128 = _mm_hadd_epi32(sum_128, sum_128);\n    sum = _mm_cvtsi128_si32(sum_128);\n    \n    // Process remaining elements\n    for (; i < k; i++) {\n        if (abs(arr[i]) <= 99) {\n            sum += arr[i];\n        }\n    }\n    \n    return sum;\n}\n```"}
{"task_id": "SimdBench_121_AVX", "completion": "```cpp\nint add_elements_simd(std::vector<int> arr, int k) {\n    int sum = 0;\n    int i = 0;\n    \n    // Process 8 elements at a time using AVX2\n    __m256i sum_vec = _mm256_setzero_si256();\n    \n    for (; i + 8 <= k; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&arr[i]);\n        \n        // Create mask for numbers with at most 2 digits\n        __m256i abs_vec = _mm256_abs_epi32(vec);\n        __m256i mask = _mm256_cmpgt_epi32(_mm256_set1_epi32(100), abs_vec);\n        \n        // Mask and add valid elements\n        __m256i masked_vec = _mm256_and_si256(vec, mask);\n        sum_vec = _mm256_add_epi32(sum_vec, masked_vec);\n    }\n    \n    // Horizontal sum of vector\n    __m128i sum_128 = _mm_add_epi32(_mm256_extracti128_si256(sum_vec, 0), \n                                     _mm256_extracti128_si256(sum_vec, 1));\n    sum_128 = _mm_hadd_epi32(sum_128, sum_128);\n    sum_128 = _mm_hadd_epi32(sum_128, sum_128);\n    sum += _mm_cvtsi128_si32(sum_128);\n    \n    // Handle remaining elements\n    for (; i < k; i++) {\n        if (abs(arr[i]) < 100) {\n            sum += arr[i];\n        }\n    }\n    \n    return sum;\n}\n```"}
{"task_id": "SimdBench_121_AVX", "completion": "```cpp\nint add_elements_simd(std::vector<int> arr, int k) {\n    int sum = 0;\n    int i = 0;\n    \n    // Process 8 elements at a time using AVX2\n    __m256i sum_vec = _mm256_setzero_si256();\n    \n    for (; i + 8 <= k; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&arr[i]);\n        \n        // Create mask for two-digit numbers (10 <= x <= 99)\n        __m256i lower_bound = _mm256_set1_epi32(10);\n        __m256i upper_bound = _mm256_set1_epi32(99);\n        \n        __m256i mask_lower = _mm256_cmpgt_epi32(vec, _mm256_sub_epi32(lower_bound, _mm256_set1_epi32(1)));\n        __m256i mask_upper = _mm256_cmpgt_epi32(upper_bound, _mm256_sub_epi32(vec, _mm256_set1_epi32(1)));\n        \n        __m256i mask = _mm256_and_si256(mask_lower, mask_upper);\n        \n        // Mask and add two-digit numbers\n        __m256i masked_vec = _mm256_and_si256(vec, mask);\n        sum_vec = _mm256_add_epi32(sum_vec, masked_vec);\n    }\n    \n    // Horizontal sum of vector\n    __m128i sum_128 = _mm_add_epi32(_mm256_extracti128_si256(sum_vec, 0), \n                                     _mm256_extracti128_si256(sum_vec, 1));\n    sum_128 = _mm_hadd_epi32(sum_128, sum_128);\n    sum_128 = _mm_hadd_epi32(sum_128, sum_128);\n    \n    sum += _mm_cvtsi128_si32(sum_128);\n    \n    // Handle remaining elements\n    for (; i < k; i++) {\n        if (arr[i] >= 10 && arr[i] <= 99) {\n            sum += arr[i];\n        }\n    }\n    \n    return sum;\n}\n```"}
{"task_id": "SimdBench_122_AVX", "completion": "```cpp\nbool is_sorted_simd(const std::vector<int> & lst) {\n    int n = lst.size();\n    if (n <= 1) return true;\n\n    // Process 8 integers at a time using AVX2\n    int vectorized_length = n - (n % 8);\n    \n    __m256i prev_vec = _mm256_loadu_si256((__m256i*)&lst[0]);\n    __m256i sorted_check = _mm256_set1_epi32(1);\n    __m256i duplicate_check = _mm256_set1_epi32(0);\n\n    // Check sorting and duplicates for first 8 elements\n    for (int i = 8; i < vectorized_length; i += 8) {\n        __m256i curr_vec = _mm256_loadu_si256((__m256i*)&lst[i]);\n        \n        // Check if current vector is greater than previous\n        __m256i compare = _mm256_cmpgt_epi32(curr_vec, prev_vec);\n        sorted_check = _mm256_and_si256(sorted_check, compare);\n\n        // Check for duplicates\n        __m256i equal_check = _mm256_cmpeq_epi32(curr_vec, prev_vec);\n        duplicate_check = _mm256_or_si256(duplicate_check, equal_check);\n\n        prev_vec = curr_vec;\n    }\n\n    // Horizontal reduction to check sorting and duplicates\n    int sorted_mask = _mm256_movemask_ps((__m256)sorted_check);\n    int duplicate_mask = _mm256_movemask_ps((__m256)duplicate_check);\n\n    // Check remaining elements\n    for (int i = vectorized_length; i < n - 1; ++i) {\n        if (lst[i] > lst[i+1]) return false;\n        if (lst[i] == lst[i+1]) {\n            if (duplicate_mask) return false;\n            duplicate_mask = 1;\n        }\n    }\n\n    return (sorted_mask == 0xFF) && (duplicate_mask == 0);\n}\n```"}
{"task_id": "SimdBench_122_AVX", "completion": "```cpp\nbool is_sorted_simd(const std::vector<int> & lst) {\n    if (lst.size() <= 1) return true;\n\n    int n = lst.size();\n    int vector_size = 8; // AVX can process 8 integers at a time\n    \n    // Check sorting and uniqueness in chunks of 8\n    for (int i = 0; i < n - vector_size; i += vector_size) {\n        __m256i current = _mm256_loadu_si256((__m256i*)&lst[i]);\n        __m256i next = _mm256_loadu_si256((__m256i*)&lst[i + 1]);\n        \n        // Check if sorted\n        __m256i cmp = _mm256_cmpgt_epi32(current, next);\n        if (_mm256_movemask_epi8(cmp) != 0) return false;\n        \n        // Check for more than one duplicate\n        __m256i unique_check = _mm256_cmpeq_epi32(current, next);\n        int mask = _mm256_movemask_epi8(unique_check);\n        int count = __builtin_popcount(mask);\n        if (count > 16) return false; // More than one duplicate\n    }\n    \n    // Check remaining elements\n    for (int i = vector_size * (n / vector_size); i < n - 1; ++i) {\n        if (lst[i] > lst[i + 1]) return false;\n        if (lst[i] == lst[i + 1]) {\n            int dup_count = 1;\n            for (int j = i + 2; j < n; ++j) {\n                if (lst[j] == lst[i]) dup_count++;\n                else break;\n            }\n            if (dup_count > 1) return false;\n        }\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_122_AVX", "completion": "```cpp\nbool is_sorted_simd(const std::vector<int> & lst) {\n    if (lst.size() <= 1) return true;\n\n    int n = lst.size();\n    int vec_size = 8; // AVX can process 8 integers at a time\n    \n    // Check sorting and uniqueness for full vector chunks\n    for (int i = 0; i < n - vec_size; i += vec_size) {\n        __m256i current = _mm256_loadu_si256((__m256i*)&lst[i]);\n        __m256i next = _mm256_loadu_si256((__m256i*)&lst[i+1]);\n        \n        // Check if sorted in ascending order\n        __m256i cmp_gt = _mm256_cmpgt_epi32(current, next);\n        if (_mm256_movemask_epi8(cmp_gt) != 0) return false;\n        \n        // Check for more than one duplicate\n        __m256i unique_mask = _mm256_cmpeq_epi32(current, next);\n        int duplicate_count = _mm256_movemask_epi8(unique_mask);\n        if (__builtin_popcount(duplicate_count) > 4) return false;\n    }\n    \n    // Check remaining elements\n    for (int i = vec_size * (n / vec_size); i < n - 1; ++i) {\n        if (lst[i] > lst[i+1]) return false;\n        if (lst[i] == lst[i+1] && lst[i] == lst[i+2]) return false;\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_122_AVX", "completion": "```cpp\nbool is_sorted_simd(const std::vector<int> & lst) {\n    if (lst.size() <= 1) return true;\n\n    int n = lst.size();\n    int vector_size = 8; // AVX can process 8 integers at a time\n    \n    // Check sorting and duplicates in 8-element chunks\n    for (int i = 0; i < n - vector_size; i += vector_size) {\n        __m256i current = _mm256_loadu_si256((__m256i*)&lst[i]);\n        __m256i next = _mm256_loadu_si256((__m256i*)&lst[i + 1]);\n        \n        // Check if elements are in ascending order\n        __m256i cmp_gt = _mm256_cmpgt_epi32(current, next);\n        if (_mm256_movemask_epi8(cmp_gt) != 0) return false;\n        \n        // Check for more than one duplicate\n        __m256i duplicates = _mm256_cmpeq_epi32(current, next);\n        int duplicate_mask = _mm256_movemask_epi8(duplicates);\n        int duplicate_count = __builtin_popcount(duplicate_mask);\n        if (duplicate_count > 16) return false; // More than 1 duplicate\n    }\n    \n    // Check remaining elements\n    for (int i = vector_size * (n / vector_size); i < n - 1; ++i) {\n        if (lst[i] > lst[i + 1]) return false;\n        if (lst[i] == lst[i + 1] && lst[i] == lst[i + 2]) return false;\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_122_AVX", "completion": "```cpp\nbool is_sorted_simd(const std::vector<int> & lst) {\n    if (lst.size() <= 1) return true;\n\n    int n = lst.size();\n    int vector_size = 8; // AVX can process 8 32-bit integers at once\n    \n    // Check sorting and duplicates in 8-element chunks\n    for (int i = 0; i < n - vector_size; i += vector_size) {\n        __m256i current = _mm256_loadu_si256((__m256i*)&lst[i]);\n        __m256i next = _mm256_loadu_si256((__m256i*)&lst[i + 1]);\n        \n        // Check if elements are in ascending order\n        __m256i cmp_gt = _mm256_cmpgt_epi32(current, next);\n        if (_mm256_movemask_epi8(cmp_gt) != 0) return false;\n        \n        // Check for more than one duplicate\n        __m256i duplicates = _mm256_cmpeq_epi32(current, next);\n        int duplicate_mask = _mm256_movemask_epi8(duplicates);\n        int duplicate_count = __builtin_popcount(duplicate_mask);\n        if (duplicate_count > 16) return false; // More than 1 duplicate\n    }\n    \n    // Handle remaining elements\n    for (int i = vector_size * (n / vector_size); i < n - 1; ++i) {\n        if (lst[i] > lst[i + 1]) return false;\n        if (lst[i] == lst[i + 1] && lst[i] == lst[i + 2]) return false;\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_123_AVX", "completion": "```cpp\nint prod_signs_simd(const std::vector<int> & arr) {\n    if (arr.empty()) return -32768;\n    \n    int n = arr.size();\n    int sign_product = 1;\n    int magnitude_sum = 0;\n    \n    // Process 8 integers at a time using AVX2\n    int i;\n    for (i = 0; i <= n - 8; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&arr[i]);\n        \n        // Extract signs\n        __m256i signs = _mm256_srai_epi32(vec, 31);\n        signs = _mm256_or_si256(signs, _mm256_cmpgt_epi32(vec, _mm256_setzero_si256()));\n        \n        // Compute sign product\n        __m256i sign_mask = _mm256_cmpeq_epi32(signs, _mm256_set1_epi32(-1));\n        sign_product *= _mm256_movemask_ps((__m256)sign_mask) == 0xFF ? 1 : -1;\n        \n        // Compute absolute values and sum\n        __m256i abs_vec = _mm256_abs_epi32(vec);\n        __m256i sum_vec = _mm256_hadd_epi32(abs_vec, abs_vec);\n        sum_vec = _mm256_hadd_epi32(sum_vec, sum_vec);\n        magnitude_sum += _mm256_extract_epi32(sum_vec, 0) + _mm256_extract_epi32(sum_vec, 4);\n    }\n    \n    // Process remaining elements\n    for (; i < n; ++i) {\n        if (arr[i] == 0) return 0;\n        sign_product *= arr[i] > 0 ? 1 : -1;\n        magnitude_sum += std::abs(arr[i]);\n    }\n    \n    return sign_product * magnitude_sum;\n}\n```"}
{"task_id": "SimdBench_123_AVX", "completion": "```cpp\nint prod_signs_simd(const std::vector<int> & arr) {\n    if (arr.empty()) return -32768;\n\n    int n = arr.size();\n    int sign_product = 1;\n    int magnitude_sum = 0;\n\n    // Process 8 integers at a time using AVX\n    int i = 0;\n    __m256i sign_vec = _mm256_setzero_si256();\n    __m256i magnitude_vec = _mm256_setzero_si256();\n\n    for (; i + 8 <= n; i += 8) {\n        // Load 8 integers\n        __m256i vec = _mm256_loadu_si256((__m256i*)&arr[i]);\n\n        // Extract signs using sign bit\n        __m256i sign_mask = _mm256_srai_epi32(vec, 31);\n        __m256i sign_bits = _mm256_xor_si256(sign_mask, _mm256_set1_epi32(1));\n        sign_vec = _mm256_add_epi32(sign_vec, sign_bits);\n\n        // Compute absolute values for magnitude\n        __m256i abs_vec = _mm256_abs_epi32(vec);\n        magnitude_vec = _mm256_add_epi32(magnitude_vec, abs_vec);\n    }\n\n    // Horizontal sum for signs and magnitudes\n    __m256i sign_sum = _mm256_hadd_epi32(sign_vec, sign_vec);\n    sign_sum = _mm256_hadd_epi32(sign_sum, sign_sum);\n    int total_sign_sum = _mm256_extract_epi32(sign_sum, 0) + _mm256_extract_epi32(sign_sum, 4);\n\n    __m256i magnitude_sum_vec = _mm256_hadd_epi32(magnitude_vec, magnitude_vec);\n    magnitude_sum_vec = _mm256_hadd_epi32(magnitude_sum_vec, magnitude_sum_vec);\n    int total_magnitude_sum = _mm256_extract_epi32(magnitude_sum_vec, 0) + _mm256_extract_epi32(magnitude_sum_vec, 4);\n\n    // Process remaining elements\n    for (; i < n; ++i) {\n        if (arr[i] == 0) return 0;\n        sign_product *= (arr[i] > 0) ? 1 : -1;\n        total_magnitude_sum += std::abs(arr[i]);\n    }\n\n    // Compute final result\n    if (total_sign_sum != n) return 0;\n    return sign_product * total_magnitude_sum;\n}\n```"}
{"task_id": "SimdBench_123_AVX", "completion": "```cpp\nint prod_signs_simd(const std::vector<int> & arr) {\n    if (arr.empty()) return -32768;\n    \n    int n = arr.size();\n    int sign_product = 1;\n    int magnitude_sum = 0;\n    \n    // Process 8 integers at a time using AVX2\n    int i;\n    for (i = 0; i <= n - 8; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&arr[i]);\n        \n        // Extract signs\n        __m256i signs = _mm256_srai_epi32(vec, 31);\n        signs = _mm256_or_si256(signs, _mm256_cmpgt_epi32(vec, _mm256_setzero_si256()));\n        \n        // Compute sign product\n        __m256i sign_mask = _mm256_cmpeq_epi32(signs, _mm256_set1_epi32(-1));\n        sign_product *= _mm256_movemask_ps((__m256)sign_mask) == 0xFF ? 1 : -1;\n        \n        // Compute absolute values for magnitude sum\n        __m256i abs_vec = _mm256_abs_epi32(vec);\n        __m256i sum_vec = _mm256_hadd_epi32(abs_vec, abs_vec);\n        sum_vec = _mm256_hadd_epi32(sum_vec, sum_vec);\n        magnitude_sum += _mm256_extract_epi32(sum_vec, 0) + _mm256_extract_epi32(sum_vec, 4);\n    }\n    \n    // Process remaining elements\n    for (; i < n; ++i) {\n        if (arr[i] == 0) return 0;\n        sign_product *= arr[i] > 0 ? 1 : -1;\n        magnitude_sum += std::abs(arr[i]);\n    }\n    \n    return sign_product * magnitude_sum;\n}\n```"}
{"task_id": "SimdBench_123_AVX", "completion": "```cpp\nint prod_signs_simd(const std::vector<int> & arr) {\n    if (arr.empty()) return -32768;\n    \n    int n = arr.size();\n    int sign_product = 1;\n    int magnitude_sum = 0;\n    \n    // Process 8 integers at a time using AVX2\n    int i = 0;\n    __m256i sign_vec = _mm256_setzero_si256();\n    __m256i magnitude_vec = _mm256_setzero_si256();\n    \n    for (; i + 8 <= n; i += 8) {\n        // Load 8 integers\n        __m256i vec = _mm256_loadu_si256((__m256i*)&arr[i]);\n        \n        // Extract signs\n        __m256i signs = _mm256_srai_epi32(vec, 31);\n        signs = _mm256_or_si256(signs, _mm256_cmpneq_epi32(vec, _mm256_setzero_si256()));\n        \n        // Update sign vector\n        sign_vec = _mm256_xor_si256(sign_vec, signs);\n        \n        // Compute absolute magnitudes\n        __m256i abs_vec = _mm256_abs_epi32(vec);\n        magnitude_vec = _mm256_add_epi32(magnitude_vec, abs_vec);\n    }\n    \n    // Horizontal sum of sign_vec\n    __m256i sign_shuffle = _mm256_shuffle_epi32(sign_vec, _MM_SHUFFLE(1, 0, 3, 2));\n    sign_vec = _mm256_xor_si256(sign_vec, sign_shuffle);\n    sign_shuffle = _mm256_shuffle_epi32(sign_vec, _MM_SHUFFLE(0, 1, 2, 3));\n    sign_vec = _mm256_xor_si256(sign_vec, sign_shuffle);\n    int sign_result = _mm256_extract_epi32(sign_vec, 0);\n    sign_product = (sign_result < 0) ? -1 : 1;\n    \n    // Horizontal sum of magnitude_vec\n    __m256i magnitude_shuffle = _mm256_hadd_epi32(magnitude_vec, magnitude_vec);\n    magnitude_shuffle = _mm256_hadd_epi32(magnitude_shuffle, magnitude_shuffle);\n    magnitude_sum = _mm256_extract_epi32(magnitude_shuffle, 0) + \n                    _mm256_extract_epi32(magnitude_shuffle, 4);\n    \n    // Process remaining elements\n    for (; i < n; i++) {\n        if (arr[i] == 0) {\n            sign_product = 0;\n            break;\n        }\n        sign_product *= (arr[i] < 0) ? -1 : 1;\n        magnitude_sum += std::abs(arr[i]);\n    }\n    \n    return sign_product * magnitude_sum;\n}\n```"}
{"task_id": "SimdBench_123_AVX", "completion": "```cpp\nint prod_signs_simd(const std::vector<int> & arr) {\n    if (arr.empty()) return -32768;\n    \n    int n = arr.size();\n    int sign_product = 1;\n    int magnitude_sum = 0;\n    \n    // Process 8 integers at a time using AVX2\n    int i = 0;\n    __m256i sign_vec = _mm256_setzero_si256();\n    __m256i magnitude_vec = _mm256_setzero_si256();\n    \n    for (; i + 8 <= n; i += 8) {\n        // Load 8 integers\n        __m256i vec = _mm256_loadu_si256((__m256i*)&arr[i]);\n        \n        // Extract signs\n        __m256i sign_mask = _mm256_srai_epi32(vec, 31);\n        __m256i sign_bits = _mm256_xor_si256(sign_mask, _mm256_set1_epi32(1));\n        sign_vec = _mm256_add_epi32(sign_vec, sign_bits);\n        \n        // Compute absolute values (magnitudes)\n        __m256i abs_vec = _mm256_abs_epi32(vec);\n        magnitude_vec = _mm256_add_epi32(magnitude_vec, abs_vec);\n    }\n    \n    // Horizontal sum of sign and magnitude vectors\n    __m128i sign_low = _mm256_extracti128_si256(sign_vec, 0);\n    __m128i sign_high = _mm256_extracti128_si256(sign_vec, 1);\n    __m128i sign_sum = _mm_add_epi32(sign_low, sign_high);\n    sign_sum = _mm_hadd_epi32(sign_sum, sign_sum);\n    sign_sum = _mm_hadd_epi32(sign_sum, sign_sum);\n    int sign_count = _mm_cvtsi128_si32(sign_sum);\n    \n    __m128i magnitude_low = _mm256_extracti128_si256(magnitude_vec, 0);\n    __m128i magnitude_high = _mm256_extracti128_si256(magnitude_vec, 1);\n    __m128i magnitude_sum_vec = _mm_add_epi32(magnitude_low, magnitude_high);\n    magnitude_sum_vec = _mm_hadd_epi32(magnitude_sum_vec, magnitude_sum_vec);\n    magnitude_sum_vec = _mm_hadd_epi32(magnitude_sum_vec, magnitude_sum_vec);\n    magnitude_sum = _mm_cvtsi128_si32(magnitude_sum_vec);\n    \n    // Process remaining elements\n    for (; i < n; i++) {\n        if (arr[i] == 0) return 0;\n        sign_product *= (arr[i] > 0) ? 1 : -1;\n        magnitude_sum += std::abs(arr[i]);\n    }\n    \n    // Adjust sign product based on sign count\n    if (sign_count != n) return 0;\n    \n    return sign_product * magnitude_sum;\n}\n```"}
{"task_id": "SimdBench_124_AVX", "completion": "```cpp\nstd::vector<int> minPath_simd(const std::vector<std::vector<int> > & grid, int k) {\n    int N = grid.size();\n    std::vector<int> result(k);\n    __m256i min_path_vec = _mm256_set1_epi32(INT_MAX);\n    \n    // Parallel search for minimum path\n    #pragma omp parallel for\n    for (int start_row = 0; start_row < N; start_row++) {\n        for (int start_col = 0; start_col < N; start_col++) {\n            std::vector<int> current_path(k);\n            current_path[0] = grid[start_row][start_col];\n            \n            // AVX2 vector to track current path\n            __m256i current_path_vec = _mm256_loadu_si256((__m256i*)current_path.data());\n            \n            // Recursive DFS with AVX2 path tracking\n            std::function<void(int, int, int)> dfs = [&](int row, int col, int depth) {\n                if (depth == k - 1) {\n                    // Compare paths using AVX2 comparison\n                    __m256i compare_vec = _mm256_cmpgt_epi32(min_path_vec, current_path_vec);\n                    if (_mm256_movemask_epi8(compare_vec) & 0x1) {\n                        #pragma omp critical\n                        {\n                            min_path_vec = current_path_vec;\n                            result = current_path;\n                        }\n                    }\n                    return;\n                }\n                \n                // Possible move directions\n                int dx[] = {0, 0, 1, -1};\n                int dy[] = {1, -1, 0, 0};\n                \n                // Parallel exploration of neighbors\n                #pragma omp parallel for\n                for (int d = 0; d < 4; d++) {\n                    int new_row = row + dx[d];\n                    int new_col = col + dy[d];\n                    \n                    if (new_row >= 0 && new_row < N && new_col >= 0 && new_col < N) {\n                        current_path[depth + 1] = grid[new_row][new_col];\n                        current_path_vec = _mm256_loadu_si256((__m256i*)current_path.data());\n                        dfs(new_row, new_col, depth + 1);\n                    }\n                }\n            };\n            \n            dfs(start_row, start_col, 0);\n        }\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_124_AVX", "completion": "```cpp\nstd::vector<int> minPath_simd(const std::vector<std::vector<int> > & grid, int k) {\n    int N = grid.size();\n    std::vector<int> result(k);\n    \n    // Directions: up, right, down, left\n    const int dx[4] = {-1, 0, 1, 0};\n    const int dy[4] = {0, 1, 0, -1};\n    \n    // Parallel path exploration using AVX2\n    __m256i min_path_vec = _mm256_set1_epi32(INT_MAX);\n    __m256i current_path_vec;\n    \n    // Parallel starting point exploration\n    for (int start_x = 0; start_x < N; start_x++) {\n        for (int start_y = 0; start_y < N; start_y++) {\n            std::vector<int> current_path(k);\n            current_path[0] = grid[start_x][start_y];\n            \n            // Parallel DFS with AVX2 pruning\n            std::function<void(int, int, int)> dfs = [&](int x, int y, int depth) {\n                if (depth == k - 1) {\n                    // Compare paths using AVX2 vector comparison\n                    current_path_vec = _mm256_loadu_si256((__m256i*)current_path.data());\n                    __m256i min_path_compare = _mm256_cmpgt_epi32(min_path_vec, current_path_vec);\n                    \n                    if (_mm256_movemask_epi8(min_path_compare) & 0x1) {\n                        min_path_vec = current_path_vec;\n                        result = current_path;\n                    }\n                    return;\n                }\n                \n                // Parallel neighbor exploration using AVX2 vector processing\n                __m256i x_vec = _mm256_set1_epi32(x);\n                __m256i y_vec = _mm256_set1_epi32(y);\n                \n                for (int d = 0; d < 4; d++) {\n                    __m256i new_x = _mm256_add_epi32(x_vec, _mm256_set1_epi32(dx[d]));\n                    __m256i new_y = _mm256_add_epi32(y_vec, _mm256_set1_epi32(dy[d]));\n                    \n                    int nx = _mm256_extract_epi32(new_x, 0);\n                    int ny = _mm256_extract_epi32(new_y, 0);\n                    \n                    if (nx >= 0 && nx < N && ny >= 0 && ny < N) {\n                        current_path[depth + 1] = grid[nx][ny];\n                        dfs(nx, ny, depth + 1);\n                    }\n                }\n            };\n            \n            dfs(start_x, start_y, 0);\n        }\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_124_AVX", "completion": "```cpp\nstd::vector<int> minPath_simd(const std::vector<std::vector<int> > & grid, int k) {\n    int N = grid.size();\n    std::vector<int> result(k);\n    __m256i min_path_vec = _mm256_set1_epi32(INT_MAX);\n    \n    // Parallel search for minimum path\n    #pragma omp parallel for\n    for (int start_row = 0; start_row < N; start_row++) {\n        for (int start_col = 0; start_col < N; start_col++) {\n            std::vector<int> current_path(k);\n            current_path[0] = grid[start_row][start_col];\n            \n            // Recursive DFS with AVX-based pruning\n            __m256i current_path_vec = _mm256_loadu_si256((__m256i*)current_path.data());\n            \n            // Directional moves: up, down, left, right\n            int dx[4] = {-1, 1, 0, 0};\n            int dy[4] = {0, 0, -1, 1};\n            \n            // Parallel path exploration\n            for (int step = 1; step < k; step++) {\n                __m256i candidates = _mm256_set1_epi32(0);\n                \n                for (int dir = 0; dir < 4; dir++) {\n                    int new_row = start_row + dx[dir];\n                    int new_col = start_col + dy[dir];\n                    \n                    if (new_row >= 0 && new_row < N && new_col >= 0 && new_col < N) {\n                        __m256i candidate = _mm256_set1_epi32(grid[new_row][new_col]);\n                        candidates = _mm256_min_epi32(candidates, candidate);\n                    }\n                }\n                \n                current_path_vec = _mm256_insert_epi32(current_path_vec, _mm256_extract_epi32(candidates, 0), step);\n            }\n            \n            // Compare paths using AVX comparison\n            __m256i comparison = _mm256_cmpgt_epi32(min_path_vec, current_path_vec);\n            if (_mm256_movemask_epi8(comparison) & 0x1) {\n                min_path_vec = current_path_vec;\n                _mm256_storeu_si256((__m256i*)result.data(), min_path_vec);\n            }\n        }\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_124_AVX", "completion": "```cpp\nstd::vector<int> minPath_simd(const std::vector<std::vector<int> > & grid, int k) {\n    int N = grid.size();\n    std::vector<int> result(k);\n    \n    // Directions: right, down, left, up\n    const int dx[4] = {0, 1, 0, -1};\n    const int dy[4] = {1, 0, -1, 0};\n    \n    // Parallel search using AVX2 intrinsics\n    __m256i min_path_vec = _mm256_set1_epi32(INT_MAX);\n    __m256i current_path_vec;\n    \n    // Parallel path exploration\n    for (int start_x = 0; start_x < N; start_x++) {\n        for (int start_y = 0; start_y < N; start_y++) {\n            std::vector<int> current_path(k);\n            current_path[0] = grid[start_x][start_y];\n            \n            // DFS with backtracking\n            std::function<void(int, int, int)> dfs = [&](int x, int y, int depth) {\n                if (depth == k - 1) {\n                    // Compare paths using AVX2 vector comparison\n                    current_path_vec = _mm256_loadu_si256((__m256i*)current_path.data());\n                    __m256i min_path_compare = _mm256_cmpgt_epi32(min_path_vec, current_path_vec);\n                    \n                    if (_mm256_movemask_epi8(min_path_compare) != 0) {\n                        min_path_vec = current_path_vec;\n                        result = current_path;\n                    }\n                    return;\n                }\n                \n                // Parallel exploration of 4 directions\n                for (int dir = 0; dir < 4; dir++) {\n                    int nx = x + dx[dir];\n                    int ny = y + dy[dir];\n                    \n                    if (nx >= 0 && nx < N && ny >= 0 && ny < N) {\n                        current_path[depth + 1] = grid[nx][ny];\n                        dfs(nx, ny, depth + 1);\n                    }\n                }\n            };\n            \n            dfs(start_x, start_y, 0);\n        }\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_124_AVX", "completion": "```cpp\nstd::vector<int> minPath_simd(const std::vector<std::vector<int> > & grid, int k) {\n    int N = grid.size();\n    std::vector<int> result(k);\n    \n    // Directions: right, down, left, up\n    const int dx[4] = {0, 1, 0, -1};\n    const int dy[4] = {1, 0, -1, 0};\n    \n    // Parallel path finding using AVX2\n    __m256i best_path_vec = _mm256_set1_epi32(INT_MAX);\n    std::vector<int> best_path(k, INT_MAX);\n    \n    // Parallel exploration of starting points\n    for (int start_x = 0; start_x < N; start_x++) {\n        for (int start_y = 0; start_y < N; start_y++) {\n            std::vector<int> current_path(k);\n            current_path[0] = grid[start_x][start_y];\n            \n            // Parallel DFS with AVX2 pruning\n            std::function<void(int, int, int)> dfs = [&](int x, int y, int depth) {\n                if (depth == k - 1) {\n                    // Compare paths using AVX2 vector comparison\n                    __m256i current_path_vec = _mm256_loadu_si256((__m256i*)current_path.data());\n                    __m256i best_path_compare = _mm256_cmpgt_epi32(best_path_vec, current_path_vec);\n                    \n                    if (_mm256_movemask_epi8(best_path_compare) != 0) {\n                        best_path = current_path;\n                        best_path_vec = current_path_vec;\n                    }\n                    return;\n                }\n                \n                // Parallel exploration of 4 directions using AVX2 vector operations\n                for (int dir = 0; dir < 4; dir++) {\n                    int nx = x + dx[dir];\n                    int ny = y + dy[dir];\n                    \n                    if (nx >= 0 && nx < N && ny >= 0 && ny < N) {\n                        current_path[depth + 1] = grid[nx][ny];\n                        dfs(nx, ny, depth + 1);\n                    }\n                }\n            };\n            \n            dfs(start_x, start_y, 0);\n        }\n    }\n    \n    return best_path;\n}\n```"}
{"task_id": "SimdBench_125_AVX", "completion": "```cpp\nuint64_t digits_simd(uint64_t n) {\n    if (n == 0) return 0;\n\n    // Convert number to string\n    char digits[20];\n    int len = sprintf(digits, \"%lu\", n);\n\n    // Align to 32-byte boundary for AVX\n    __attribute__((aligned(32))) int int_digits[20];\n    for (int i = 0; i < len; i++) {\n        int_digits[i] = digits[i] - '0';\n    }\n\n    // Process digits in parallel using AVX2\n    __m256i odd_mask = _mm256_set1_epi32(1);\n    __m256i result_vec = _mm256_set1_epi32(1);\n    __m256i zero_vec = _mm256_setzero_si256();\n\n    for (int i = 0; i < len; i += 8) {\n        __m256i digit_vec = _mm256_load_si256((__m256i*)&int_digits[i]);\n        __m256i is_odd = _mm256_and_si256(_mm256_and_si256(digit_vec, odd_mask), \n                                          _mm256_cmpgt_epi32(digit_vec, zero_vec));\n        __m256i odd_digits = _mm256_and_si256(digit_vec, is_odd);\n        result_vec = _mm256_mullo_epi32(result_vec, _mm256_max_epi32(odd_digits, _mm256_set1_epi32(1)));\n    }\n\n    // Horizontal multiply to get final result\n    __m128i result_low = _mm256_extracti128_si256(result_vec, 0);\n    __m128i result_high = _mm256_extracti128_si256(result_vec, 1);\n    result_low = _mm_mullo_epi32(result_low, result_high);\n    result_low = _mm_mullo_epi32(result_low, _mm_srli_si128(result_low, 8));\n    result_low = _mm_mullo_epi32(result_low, _mm_srli_si128(result_low, 4));\n\n    int final_result = _mm_cvtsi128_si32(result_low);\n    return final_result == 1 ? 0 : final_result;\n}\n```"}
{"task_id": "SimdBench_125_AVX", "completion": "```cpp\nuint64_t digits_simd(uint64_t n) {\n    // Convert number to string\n    char digits[20];\n    int len = sprintf(digits, \"%lu\", n);\n    \n    // Pad to multiple of 32 bytes\n    int padded_len = ((len + 31) / 32) * 32;\n    \n    // Align buffer\n    alignas(32) char padded_digits[padded_len];\n    memset(padded_digits, '0', padded_len);\n    memcpy(padded_digits, digits, len);\n    \n    // Initialize product vector\n    __m256i product_vec = _mm256_set1_epi32(1);\n    \n    // Process 32 digits at a time\n    for (int i = 0; i < padded_len; i += 32) {\n        // Load 32 digits\n        __m256i digit_vec = _mm256_loadu_si256((__m256i*)(padded_digits + i));\n        \n        // Subtract '0' to convert to numeric values\n        __m256i zero_vec = _mm256_set1_epi8('0');\n        digit_vec = _mm256_sub_epi8(digit_vec, zero_vec);\n        \n        // Create mask for odd digits\n        __m256i one_vec = _mm256_set1_epi8(1);\n        __m256i mod_vec = _mm256_and_si256(digit_vec, one_vec);\n        __m256i odd_mask = _mm256_cmpeq_epi8(mod_vec, one_vec);\n        \n        // Multiply odd digits\n        __m256i masked_digits = _mm256_and_si256(digit_vec, odd_mask);\n        __m256i non_zero_mask = _mm256_cmpgt_epi8(masked_digits, _mm256_setzero_si256());\n        masked_digits = _mm256_and_si256(masked_digits, non_zero_mask);\n        \n        product_vec = _mm256_mullo_epi32(product_vec, masked_digits);\n    }\n    \n    // Horizontal multiply to get final product\n    __m128i low_product = _mm256_extracti128_si256(product_vec, 0);\n    __m128i high_product = _mm256_extracti128_si256(product_vec, 1);\n    \n    low_product = _mm_mul_epu32(low_product, _mm_srli_si128(low_product, 4));\n    high_product = _mm_mul_epu32(high_product, _mm_srli_si128(high_product, 4));\n    \n    __m128i final_product = _mm_mul_epu32(low_product, high_product);\n    \n    return _mm_cvtsi128_si64(final_product);\n}\n```"}
{"task_id": "SimdBench_125_AVX", "completion": "```cpp\nuint64_t digits_simd(uint64_t n) {\n    // Convert number to string for digit extraction\n    char digits[20];\n    int len = sprintf(digits, \"%lu\", n);\n    \n    // Pad to multiple of 8 for AVX processing\n    int padded_len = ((len + 7) / 8) * 8;\n    \n    // Initialize result vector\n    __m256i result_vec = _mm256_set1_epi32(1);\n    \n    // Process 8 digits at a time\n    for (int i = 0; i < padded_len; i += 8) {\n        // Load 8 digits\n        __m256i digit_vec = _mm256_set_epi8(\n            i+7 < len ? digits[i+7] - '0' : 0,\n            i+6 < len ? digits[i+6] - '0' : 0,\n            i+5 < len ? digits[i+5] - '0' : 0,\n            i+4 < len ? digits[i+4] - '0' : 0,\n            i+3 < len ? digits[i+3] - '0' : 0,\n            i+2 < len ? digits[i+2] - '0' : 0,\n            i+1 < len ? digits[i+1] - '0' : 0,\n            i+0 < len ? digits[i+0] - '0' : 0,\n            0, 0, 0, 0, 0, 0, 0, 0,\n            0, 0, 0, 0, 0, 0, 0, 0,\n            0, 0, 0, 0, 0, 0, 0, 0\n        );\n        \n        // Check for odd digits\n        __m256i odd_mask = _mm256_and_si256(digit_vec, _mm256_set1_epi8(1));\n        __m256i odd_digits = _mm256_cmpeq_epi8(odd_mask, _mm256_set1_epi8(1));\n        \n        // Multiply odd digits\n        __m256i masked_digits = _mm256_and_si256(digit_vec, odd_digits);\n        __m256i non_zero_mask = _mm256_cmpgt_epi8(masked_digits, _mm256_setzero_si256());\n        masked_digits = _mm256_and_si256(masked_digits, non_zero_mask);\n        \n        // Horizontal multiply\n        __m128i low = _mm256_extracti128_si256(masked_digits, 0);\n        __m128i high = _mm256_extracti128_si256(masked_digits, 1);\n        \n        low = _mm_mullo_epi32(low, _mm_srli_si128(low, 4));\n        high = _mm_mullo_epi32(high, _mm_srli_si128(high, 4));\n        \n        __m256i product_vec = _mm256_set_m128i(high, low);\n        result_vec = _mm256_mullo_epi32(result_vec, product_vec);\n    }\n    \n    // Horizontal multiply to get final result\n    __m128i result_low = _mm256_extracti128_si256(result_vec, 0);\n    __m128i result_high = _mm256_extracti128_si256(result_vec, 1);\n    \n    result_low = _mm_mullo_epi32(result_low, result_high);\n    int result = _mm_cvtsi128_si32(result_low);\n    \n    return result > 1 ? result : 0;\n}\n```"}
{"task_id": "SimdBench_125_AVX", "completion": "```cpp\nuint64_t digits_simd(uint64_t n) {\n    // Convert number to string\n    char digits[20];\n    int len = sprintf(digits, \"%lu\", n);\n    \n    // Pad to multiple of 32 bytes\n    int padded_len = ((len + 31) / 32) * 32;\n    \n    // Align buffer\n    alignas(32) char padded_digits[padded_len];\n    memset(padded_digits, '0', padded_len);\n    memcpy(padded_digits, digits, len);\n    \n    // Initialize product vector\n    __m256i product_vec = _mm256_set1_epi32(1);\n    \n    // Process 32 bytes at a time\n    for (int i = 0; i < padded_len; i += 32) {\n        // Load 32 bytes\n        __m256i digit_vec = _mm256_loadu_si256((__m256i*)(padded_digits + i));\n        \n        // Subtract '0' to convert to numeric values\n        __m256i zero_vec = _mm256_set1_epi8('0');\n        digit_vec = _mm256_sub_epi8(digit_vec, zero_vec);\n        \n        // Create mask for odd digits\n        __m256i one_vec = _mm256_set1_epi8(1);\n        __m256i mod2_vec = _mm256_and_si256(digit_vec, one_vec);\n        __m256i odd_mask = _mm256_cmpeq_epi8(mod2_vec, one_vec);\n        \n        // Multiply odd digits\n        __m256i masked_digits = _mm256_and_si256(digit_vec, odd_mask);\n        __m256i nonzero_mask = _mm256_cmpgt_epi8(masked_digits, _mm256_setzero_si256());\n        masked_digits = _mm256_and_si256(masked_digits, nonzero_mask);\n        \n        // Horizontal multiply\n        __m256i product_low = _mm256_mullo_epi32(_mm256_cvtepu8_epi32(_mm256_castsi256_si128(masked_digits)),\n                                                 _mm256_set1_epi32(1));\n        \n        product_vec = _mm256_mullo_epi32(product_vec, product_low);\n    }\n    \n    // Horizontal sum of product vector\n    __m128i product_low_128 = _mm256_extracti128_si256(product_vec, 0);\n    __m128i product_high_128 = _mm256_extracti128_si256(product_vec, 1);\n    \n    product_low_128 = _mm_mullo_epi32(product_low_128, product_high_128);\n    product_low_128 = _mm_mullo_epi32(product_low_128, _mm_shuffle_epi32(product_low_128, _MM_SHUFFLE(1, 0, 3, 2)));\n    product_low_128 = _mm_mullo_epi32(product_low_128, _mm_shuffle_epi32(product_low_128, _MM_SHUFFLE(0, 1, 0, 1)));\n    \n    uint64_t result = _mm_cvtsi128_si32(product_low_128);\n    \n    return result == 1 ? 0 : result;\n}\n```"}
{"task_id": "SimdBench_125_AVX", "completion": "```cpp\nuint64_t digits_simd(uint64_t n) {\n    // Convert number to string for digit extraction\n    char digits[20];\n    int len = sprintf(digits, \"%lu\", n);\n    \n    // Align to 32-byte boundary for AVX\n    alignas(32) uint32_t odd_digits[8] = {0};\n    uint32_t product = 1;\n    \n    // Process 8 digits at a time using AVX2\n    for (int i = 0; i < len; i += 8) {\n        __m256i zero = _mm256_setzero_si256();\n        __m256i digit_vec = _mm256_loadu_si256((__m256i*)(digits + i));\n        \n        // Convert ASCII digits to integer values\n        digit_vec = _mm256_sub_epi8(digit_vec, _mm256_set1_epi8('0'));\n        \n        // Create mask for odd digits\n        __m256i one = _mm256_set1_epi8(1);\n        __m256i mod_check = _mm256_and_si256(digit_vec, one);\n        __m256i odd_mask = _mm256_cmpeq_epi8(mod_check, one);\n        \n        // Store odd digits\n        _mm256_maskstore_epi32((int*)odd_digits, odd_mask, digit_vec);\n    }\n    \n    // Compute product of odd digits\n    for (int i = 0; i < 8; i++) {\n        if (odd_digits[i] > 0) {\n            product *= odd_digits[i];\n        }\n    }\n    \n    return product == 1 ? 0 : product;\n}\n```"}
{"task_id": "SimdBench_126_AVX", "completion": "```cpp\nuint64_t sum_squares_simd(const std::vector<float> & lst) {\n    uint64_t result = 0;\n    size_t n = lst.size();\n    size_t vec_size = n - (n % 8);\n\n    __m256 sum_vec = _mm256_setzero_ps();\n\n    for (size_t i = 0; i < vec_size; i += 8) {\n        // Load 8 floats\n        __m256 input_vec = _mm256_loadu_ps(&lst[i]);\n        \n        // Round up to ceiling using _mm256_ceil_ps\n        __m256 ceil_vec = _mm256_ceil_ps(input_vec);\n        \n        // Square the rounded values\n        __m256 squared_vec = _mm256_mul_ps(ceil_vec, ceil_vec);\n        \n        // Accumulate squared values\n        sum_vec = _mm256_add_ps(sum_vec, squared_vec);\n    }\n\n    // Horizontal sum of vector\n    __m128 sum_low = _mm256_extractf128_ps(sum_vec, 0);\n    __m128 sum_high = _mm256_extractf128_ps(sum_vec, 1);\n    sum_low = _mm_add_ps(sum_low, sum_high);\n    sum_low = _mm_hadd_ps(sum_low, sum_low);\n    sum_low = _mm_hadd_ps(sum_low, sum_low);\n    result = _mm_cvtss_si32(sum_low);\n\n    // Handle remaining elements\n    for (size_t i = vec_size; i < n; ++i) {\n        result += std::ceil(lst[i]) * std::ceil(lst[i]);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_126_AVX", "completion": "```cpp\nuint64_t sum_squares_simd(const std::vector<float> & lst) {\n    uint64_t result = 0;\n    size_t vec_size = lst.size();\n    size_t simd_size = vec_size - (vec_size % 8);\n\n    __m256 sum_vec = _mm256_setzero_ps();\n\n    for (size_t i = 0; i < simd_size; i += 8) {\n        // Load 8 floats\n        __m256 vec = _mm256_loadu_ps(&lst[i]);\n        \n        // Ceiling operation using ceil intrinsic\n        __m256 ceil_vec = _mm256_ceil_ps(vec);\n        \n        // Square the values\n        __m256 squared_vec = _mm256_mul_ps(ceil_vec, ceil_vec);\n        \n        // Accumulate sum\n        sum_vec = _mm256_add_ps(sum_vec, squared_vec);\n    }\n\n    // Horizontal sum of vector\n    __m128 sum_low = _mm256_extractf128_ps(sum_vec, 0);\n    __m128 sum_high = _mm256_extractf128_ps(sum_vec, 1);\n    sum_low = _mm_add_ps(sum_low, sum_high);\n    sum_low = _mm_hadd_ps(sum_low, sum_low);\n    sum_low = _mm_hadd_ps(sum_low, sum_low);\n    result += _mm_cvtss_f32(sum_low);\n\n    // Handle remaining elements\n    for (size_t i = simd_size; i < vec_size; ++i) {\n        int ceil_val = std::ceil(lst[i]);\n        result += ceil_val * ceil_val;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_126_AVX", "completion": "```cpp\nuint64_t sum_squares_simd(const std::vector<float> & lst) {\n    uint64_t result = 0;\n    size_t vec_size = lst.size();\n    size_t simd_size = vec_size - (vec_size % 8);\n\n    __m256 sum_vec = _mm256_setzero_ps();\n\n    for (size_t i = 0; i < simd_size; i += 8) {\n        __m256 input_vec = _mm256_loadu_ps(&lst[i]);\n        __m256 ceil_vec = _mm256_ceil_ps(input_vec);\n        __m256 squared_vec = _mm256_mul_ps(ceil_vec, ceil_vec);\n        sum_vec = _mm256_add_ps(sum_vec, squared_vec);\n    }\n\n    float sum_array[8];\n    _mm256_storeu_ps(sum_array, sum_vec);\n\n    for (int j = 0; j < 8; j++) {\n        result += static_cast<uint64_t>(sum_array[j]);\n    }\n\n    for (size_t i = simd_size; i < vec_size; i++) {\n        result += static_cast<uint64_t>(std::ceil(lst[i]) * std::ceil(lst[i]));\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_126_AVX", "completion": "```cpp\nuint64_t sum_squares_simd(const std::vector<float> & lst) {\n    uint64_t result = 0;\n    size_t n = lst.size();\n    size_t vec_size = n - (n % 8);\n\n    __m256 sum_vec = _mm256_setzero_ps();\n\n    for (size_t i = 0; i < vec_size; i += 8) {\n        // Load 8 floats\n        __m256 vec = _mm256_loadu_ps(&lst[i]);\n        \n        // Ceiling operation using roundps\n        __m256 ceil_vec = _mm256_ceil_ps(vec);\n        \n        // Square the values\n        __m256 squared_vec = _mm256_mul_ps(ceil_vec, ceil_vec);\n        \n        // Accumulate squared values\n        sum_vec = _mm256_add_ps(sum_vec, squared_vec);\n    }\n\n    // Horizontal sum of vector\n    __m128 sum_128 = _mm_add_ps(_mm256_extractf128_ps(sum_vec, 0), \n                                 _mm256_extractf128_ps(sum_vec, 1));\n    sum_128 = _mm_add_ps(sum_128, _mm_movehl_ps(sum_128, sum_128));\n    sum_128 = _mm_add_ss(sum_128, _mm_shuffle_ps(sum_128, sum_128, 1));\n    result = _mm_cvtss_si32(sum_128);\n\n    // Handle remaining elements\n    for (size_t i = vec_size; i < n; ++i) {\n        result += std::ceil(lst[i]) * std::ceil(lst[i]);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_126_AVX", "completion": "```cpp\nuint64_t sum_squares_simd(const std::vector<float> & lst) {\n    uint64_t result = 0;\n    size_t vec_size = lst.size();\n    size_t simd_size = vec_size - (vec_size % 8);\n\n    __m256 sum_vec = _mm256_setzero_ps();\n\n    for (size_t i = 0; i < simd_size; i += 8) {\n        // Load 8 floats\n        __m256 vec = _mm256_loadu_ps(&lst[i]);\n        \n        // Ceiling operation using roundps\n        __m256 ceil_vec = _mm256_ceil_ps(vec);\n        \n        // Square the values\n        __m256 squared_vec = _mm256_mul_ps(ceil_vec, ceil_vec);\n        \n        // Accumulate squared values\n        sum_vec = _mm256_add_ps(sum_vec, squared_vec);\n    }\n\n    // Horizontal sum of vector\n    __m128 sum_low = _mm256_extractf128_ps(sum_vec, 0);\n    __m128 sum_high = _mm256_extractf128_ps(sum_vec, 1);\n    sum_low = _mm_add_ps(sum_low, sum_high);\n    sum_low = _mm_hadd_ps(sum_low, sum_low);\n    sum_low = _mm_hadd_ps(sum_low, sum_low);\n    result += _mm_cvtss_f32(sum_low);\n\n    // Handle remaining elements\n    for (size_t i = simd_size; i < vec_size; ++i) {\n        result += std::ceil(lst[i]) * std::ceil(lst[i]);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_127_AVX", "completion": "```cpp\nint can_arrange_simd(const std::vector<int> & arr) {\n    int n = arr.size();\n    if (n <= 1) return -1;\n\n    // Process 8 elements at a time using AVX2\n    int i = 0;\n    for (; i + 8 <= n; i += 8) {\n        __m256i current = _mm256_loadu_si256((__m256i*)&arr[i]);\n        __m256i next = _mm256_loadu_si256((__m256i*)&arr[i+1]);\n        \n        // Compare if current elements are less than next elements\n        __m256i compare = _mm256_cmpgt_epi32(next, current);\n        \n        // Create a mask of comparison results\n        int mask = _mm256_movemask_ps((__m256)compare);\n        \n        // Check if any element violates the condition\n        if (mask != 0xFF) {\n            // Find the first element that violates the condition\n            for (int j = 0; j < 8; j++) {\n                if (arr[i+j] >= arr[i+j+1]) {\n                    return i + j;\n                }\n            }\n        }\n    }\n\n    // Handle remaining elements\n    for (; i < n - 1; i++) {\n        if (arr[i] >= arr[i+1]) {\n            return i;\n        }\n    }\n\n    return -1;\n}\n```"}
{"task_id": "SimdBench_127_AVX", "completion": "```cpp\nint can_arrange_simd(const std::vector<int> & arr) {\n    int n = arr.size();\n    if (n <= 1) return -1;\n\n    // Process 8 elements at a time using AVX2\n    int i = 0;\n    for (; i + 8 <= n; i += 8) {\n        __m256i current = _mm256_loadu_si256((__m256i*)&arr[i]);\n        __m256i next = _mm256_loadu_si256((__m256i*)&arr[i+1]);\n        \n        // Compare if current elements are less than next elements\n        __m256i compare = _mm256_cmpgt_epi32(next, current);\n        \n        // Create mask of comparisons\n        int mask = _mm256_movemask_ps((__m256)compare);\n        \n        // Check if any comparison fails\n        if (mask != 0xFF) {\n            // Find the first index where condition fails\n            for (int j = 0; j < 7; ++j) {\n                if (!(mask & (1 << j))) {\n                    return i + j;\n                }\n            }\n        }\n    }\n\n    // Handle remaining elements\n    for (; i < n - 1; ++i) {\n        if (arr[i] >= arr[i+1]) {\n            return i;\n        }\n    }\n\n    return -1;\n}\n```"}
{"task_id": "SimdBench_127_AVX", "completion": "```cpp\nint can_arrange_simd(const std::vector<int> & arr) {\n    int n = arr.size();\n    if (n <= 1) return -1;\n\n    // Process 8 elements at a time using AVX2\n    int i = 0;\n    for (; i + 8 <= n; i += 8) {\n        __m256i current = _mm256_loadu_si256((__m256i*)&arr[i]);\n        __m256i next = _mm256_loadu_si256((__m256i*)&arr[i+1]);\n        \n        // Compare if current elements are not less than next elements\n        __m256i compare = _mm256_cmpgt_epi32(current, next);\n        int mask = _mm256_movemask_ps((__m256)compare);\n        \n        // Check if any element violates the condition\n        if (mask) {\n            // Find the first index where condition is violated\n            for (int j = 0; j < 7; j++) {\n                if (mask & (1 << j)) {\n                    return i + j;\n                }\n            }\n        }\n    }\n\n    // Handle remaining elements\n    for (; i < n - 1; i++) {\n        if (arr[i] >= arr[i+1]) {\n            return i;\n        }\n    }\n\n    return -1;\n}\n```"}
{"task_id": "SimdBench_127_AVX", "completion": "```cpp\nint can_arrange_simd(const std::vector<int> & arr) {\n    int n = arr.size();\n    if (n <= 1) return -1;\n\n    // Process 8 elements at a time using AVX2\n    int i = 0;\n    for (; i + 8 <= n; i += 8) {\n        __m256i current = _mm256_loadu_si256((__m256i*)&arr[i]);\n        __m256i next = _mm256_loadu_si256((__m256i*)&arr[i+1]);\n\n        // Compare if current elements are greater than or equal to next elements\n        __m256i comparison = _mm256_cmpgt_epi32(current, next);\n        int mask = _mm256_movemask_ps((__m256)comparison);\n\n        // Check if any element violates the condition\n        if (mask) {\n            // Find the first index where condition is violated\n            for (int j = 0; j < 7; j++) {\n                if (mask & (1 << j)) {\n                    return i + j;\n                }\n            }\n        }\n    }\n\n    // Handle remaining elements\n    for (; i < n - 1; i++) {\n        if (arr[i] >= arr[i+1]) {\n            return i;\n        }\n    }\n\n    return -1;\n}\n```"}
{"task_id": "SimdBench_127_AVX", "completion": "```cpp\nint can_arrange_simd(const std::vector<int> & arr) {\n    int n = arr.size();\n    if (n <= 1) return -1;\n\n    // Process 8 elements at a time using AVX2\n    int i = 0;\n    for (; i + 8 <= n; i += 8) {\n        __m256i current = _mm256_loadu_si256((__m256i*)&arr[i]);\n        __m256i next = _mm256_loadu_si256((__m256i*)&arr[i+1]);\n        \n        // Compare if current elements are less than next elements\n        __m256i cmp = _mm256_cmpgt_epi32(next, current);\n        \n        // Create a mask of comparison results\n        int mask = _mm256_movemask_ps((__m256)cmp);\n        \n        // Check if any element violates the condition\n        if (mask != 0xFF) {\n            // Find the first element that violates the condition\n            for (int j = 0; j < 8; j++) {\n                if (arr[i+j] >= arr[i+j+1]) {\n                    return i + j;\n                }\n            }\n        }\n    }\n\n    // Handle remaining elements\n    for (; i < n - 1; i++) {\n        if (arr[i] >= arr[i+1]) {\n            return i;\n        }\n    }\n\n    return -1;\n}\n```"}
{"task_id": "SimdBench_128_AVX", "completion": "```cpp\nstd::vector<int> largest_smallest_integers_simd(const std::vector<int>& lst) {\n    if (lst.empty()) return {0, 0};\n\n    int n = lst.size();\n    int max_neg = INT_MIN;\n    int min_pos = INT_MAX;\n\n    // Process 8 integers at a time using AVX2\n    int i;\n    for (i = 0; i + 8 <= n; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&lst[i]);\n        \n        // Negative mask\n        __m256i neg_mask = _mm256_cmpgt_epi32(_mm256_setzero_si256(), vec);\n        __m256i neg_vec = _mm256_and_si256(vec, neg_mask);\n        \n        // Positive mask\n        __m256i pos_mask = _mm256_cmpgt_epi32(vec, _mm256_setzero_si256());\n        __m256i pos_vec = _mm256_and_si256(vec, pos_mask);\n        \n        // Horizontal max for negatives\n        int neg_arr[8];\n        _mm256_storeu_si256((__m256i*)neg_arr, neg_vec);\n        for (int j = 0; j < 8; j++) {\n            max_neg = std::max(max_neg, neg_arr[j]);\n        }\n        \n        // Horizontal min for positives\n        int pos_arr[8];\n        _mm256_storeu_si256((__m256i*)pos_arr, pos_vec);\n        for (int j = 0; j < 8; j++) {\n            if (pos_arr[j] > 0) {\n                min_pos = std::min(min_pos, pos_arr[j]);\n            }\n        }\n    }\n    \n    // Process remaining elements\n    for (; i < n; i++) {\n        if (lst[i] < 0) {\n            max_neg = std::max(max_neg, lst[i]);\n        } else if (lst[i] > 0) {\n            min_pos = std::min(min_pos, lst[i]);\n        }\n    }\n    \n    // If no negatives or positives found\n    if (max_neg == INT_MIN) max_neg = 0;\n    if (min_pos == INT_MAX) min_pos = 0;\n    \n    return {max_neg, min_pos};\n}\n```"}
{"task_id": "SimdBench_128_AVX", "completion": "```cpp\nstd::vector<int> largest_smallest_integers_simd(const std::vector<int>& lst) {\n    if (lst.empty()) return {0, 0};\n\n    int n = lst.size();\n    int max_neg = INT_MIN;\n    int min_pos = INT_MAX;\n\n    // Process 8 integers at a time using AVX2\n    int i;\n    for (i = 0; i + 8 <= n; i += 8) {\n        __m256i vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&lst[i]));\n        \n        // Create masks for negative and positive integers\n        __m256i zero = _mm256_setzero_si256();\n        __m256i neg_mask = _mm256_cmpgt_epi32(zero, vec);\n        __m256i pos_mask = _mm256_cmpgt_epi32(vec, zero);\n\n        // Negative integers processing\n        __m256i neg_ints = _mm256_and_si256(vec, neg_mask);\n        int neg_max = _mm256_reduce_max_epi32(neg_ints);\n        max_neg = std::max(max_neg, neg_max);\n\n        // Positive integers processing\n        __m256i pos_ints = _mm256_and_si256(vec, pos_mask);\n        int pos_min = _mm256_reduce_min_epi32(pos_ints);\n        min_pos = std::min(min_pos, pos_min);\n    }\n\n    // Process remaining elements\n    for (; i < n; ++i) {\n        if (lst[i] < 0) max_neg = std::max(max_neg, lst[i]);\n        if (lst[i] > 0) min_pos = std::min(min_pos, lst[i]);\n    }\n\n    // If no negative or positive integers found\n    if (max_neg == INT_MIN) max_neg = 0;\n    if (min_pos == INT_MAX) min_pos = 0;\n\n    return {max_neg, min_pos};\n}\n```"}
{"task_id": "SimdBench_128_AVX", "completion": "```cpp\nstd::vector<int> largest_smallest_integers_simd(const std::vector<int>& lst) {\n    if (lst.empty()) return {0, 0};\n\n    int n = lst.size();\n    int max_neg = INT_MIN;\n    int min_pos = INT_MAX;\n\n    // Process 8 integers at a time using AVX2\n    int i;\n    for (i = 0; i + 8 <= n; i += 8) {\n        __m256i vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&lst[i]));\n        \n        // Negative mask\n        __m256i neg_mask = _mm256_cmpgt_epi32(_mm256_setzero_si256(), vec);\n        __m256i neg_values = _mm256_and_si256(vec, neg_mask);\n        \n        // Positive mask\n        __m256i pos_mask = _mm256_cmpgt_epi32(vec, _mm256_setzero_si256());\n        __m256i pos_values = _mm256_and_si256(vec, pos_mask);\n        \n        // Horizontal max for negatives\n        __m128i neg_high = _mm256_extracti128_si256(neg_values, 1);\n        __m128i neg_low = _mm256_castsi256_si128(neg_values);\n        __m128i max_neg_vec = _mm_max_epi32(neg_high, neg_low);\n        max_neg_vec = _mm_max_epi32(max_neg_vec, _mm_shuffle_epi32(max_neg_vec, _MM_SHUFFLE(1, 0, 3, 2)));\n        max_neg_vec = _mm_max_epi32(max_neg_vec, _mm_shuffle_epi32(max_neg_vec, _MM_SHUFFLE(0, 1, 2, 3)));\n        max_neg = _mm_cvtsi128_si32(max_neg_vec);\n        \n        // Horizontal min for positives\n        __m128i pos_high = _mm256_extracti128_si256(pos_values, 1);\n        __m128i pos_low = _mm256_castsi256_si128(pos_values);\n        __m128i min_pos_vec = _mm_min_epi32(pos_high, pos_low);\n        min_pos_vec = _mm_min_epi32(min_pos_vec, _mm_shuffle_epi32(min_pos_vec, _MM_SHUFFLE(1, 0, 3, 2)));\n        min_pos_vec = _mm_min_epi32(min_pos_vec, _mm_shuffle_epi32(min_pos_vec, _MM_SHUFFLE(0, 1, 2, 3)));\n        min_pos = _mm_cvtsi128_si32(min_pos_vec);\n    }\n\n    // Process remaining elements\n    for (; i < n; ++i) {\n        if (lst[i] < 0 && lst[i] > max_neg) {\n            max_neg = lst[i];\n        }\n        if (lst[i] > 0 && lst[i] < min_pos) {\n            min_pos = lst[i];\n        }\n    }\n\n    // If no negative or positive integers found\n    if (max_neg == INT_MIN) max_neg = 0;\n    if (min_pos == INT_MAX) min_pos = 0;\n\n    return {max_neg, min_pos};\n}\n```"}
{"task_id": "SimdBench_128_AVX", "completion": "```cpp\nstd::vector<int> largest_smallest_integers_simd(const std::vector<int>& lst) {\n    if (lst.empty()) return {0, 0};\n\n    int n = lst.size();\n    int max_neg = INT_MIN;\n    int min_pos = INT_MAX;\n\n    // Process 8 integers at a time using AVX2\n    int i;\n    for (i = 0; i + 8 <= n; i += 8) {\n        __m256i vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&lst[i]));\n        \n        // Create masks for negative and positive integers\n        __m256i zero = _mm256_setzero_si256();\n        __m256i neg_mask = _mm256_cmpgt_epi32(zero, vec);\n        __m256i pos_mask = _mm256_cmpgt_epi32(vec, zero);\n\n        // Negative integers processing\n        __m256i neg_values = _mm256_and_si256(vec, neg_mask);\n        int neg_max = _mm256_reduce_max_epi32(neg_values);\n        max_neg = std::max(max_neg, neg_max);\n\n        // Positive integers processing\n        __m256i pos_values = _mm256_and_si256(vec, pos_mask);\n        int pos_min = _mm256_reduce_min_epi32(pos_values);\n        min_pos = std::min(min_pos, pos_min);\n    }\n\n    // Process remaining elements\n    for (; i < n; ++i) {\n        if (lst[i] < 0) max_neg = std::max(max_neg, lst[i]);\n        if (lst[i] > 0) min_pos = std::min(min_pos, lst[i]);\n    }\n\n    // If no negative or positive integers found\n    if (max_neg == INT_MIN) max_neg = 0;\n    if (min_pos == INT_MAX) min_pos = 0;\n\n    return {max_neg, min_pos};\n}\n```"}
{"task_id": "SimdBench_128_AVX", "completion": "```cpp\nstd::vector<int> largest_smallest_integers_simd(const std::vector<int>& lst) {\n    if (lst.empty()) return {0, 0};\n\n    int n = lst.size();\n    int max_neg = INT_MIN;\n    int min_pos = INT_MAX;\n\n    // Process 8 integers at a time using AVX2\n    int i;\n    for (i = 0; i + 8 <= n; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&lst[i]);\n        \n        // Negative mask\n        __m256i neg_mask = _mm256_cmpgt_epi32(_mm256_setzero_si256(), vec);\n        __m256i neg_values = _mm256_and_si256(vec, neg_mask);\n        \n        // Positive mask\n        __m256i pos_mask = _mm256_cmpgt_epi32(vec, _mm256_setzero_si256());\n        __m256i pos_values = _mm256_and_si256(vec, pos_mask);\n        \n        // Horizontal max for negative values\n        int neg_arr[8];\n        _mm256_storeu_si256((__m256i*)neg_arr, neg_values);\n        for (int j = 0; j < 8; j++) {\n            max_neg = std::max(max_neg, neg_arr[j]);\n        }\n        \n        // Horizontal min for positive values\n        int pos_arr[8];\n        _mm256_storeu_si256((__m256i*)pos_arr, pos_values);\n        for (int j = 0; j < 8; j++) {\n            if (pos_arr[j] > 0) {\n                min_pos = std::min(min_pos, pos_arr[j]);\n            }\n        }\n    }\n    \n    // Process remaining elements\n    for (; i < n; i++) {\n        if (lst[i] < 0) {\n            max_neg = std::max(max_neg, lst[i]);\n        } else if (lst[i] > 0) {\n            min_pos = std::min(min_pos, lst[i]);\n        }\n    }\n    \n    // If no negative or positive integers found\n    if (max_neg == INT_MIN) max_neg = 0;\n    if (min_pos == INT_MAX) min_pos = 0;\n    \n    return {max_neg, min_pos};\n}\n```"}
{"task_id": "SimdBench_129_AVX", "completion": "```cpp\nuint64_t special_factorial_simd(uint64_t n) {\n    if (n == 0) return 1;\n    \n    // Compute factorials for each number from 1 to n\n    __m256i factorial_vector = _mm256_set1_epi64x(1);\n    __m256i current_value = _mm256_set1_epi64x(1);\n    \n    for (uint64_t i = 1; i <= n; ++i) {\n        current_value = _mm256_set1_epi64x(i);\n        __m256i temp = _mm256_set1_epi64x(1);\n        \n        for (uint64_t j = 1; j <= i; ++j) {\n            temp = _mm256_mul_epu32(temp, current_value);\n        }\n        \n        factorial_vector = _mm256_mul_epu32(factorial_vector, temp);\n    }\n    \n    // Extract and multiply the results\n    uint64_t result = 1;\n    alignas(32) uint64_t factorial_array[4];\n    _mm256_store_si256((__m256i*)factorial_array, factorial_vector);\n    \n    for (int k = 0; k < 4; ++k) {\n        result *= factorial_array[k];\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_129_AVX", "completion": "```cpp\nuint64_t special_factorial_simd(uint64_t n) {\n    if (n == 0) return 1;\n\n    uint64_t result = 1;\n    uint64_t factorial[8] = {1, 1, 1, 1, 1, 1, 1, 1};\n    \n    // Compute factorials in parallel\n    for (uint64_t i = 1; i <= n; ++i) {\n        __m256i vec_factorial = _mm256_loadu_si256((__m256i*)factorial);\n        __m256i vec_current = _mm256_set1_epi64x(i);\n        __m256i vec_result = _mm256_mullo_epi64(vec_factorial, vec_current);\n        \n        _mm256_storeu_si256((__m256i*)factorial, vec_result);\n    }\n    \n    // Multiply all factorials\n    for (int j = 0; j < 8; ++j) {\n        result *= factorial[j];\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_129_AVX", "completion": "```cpp\nuint64_t special_factorial_simd(uint64_t n) {\n    if (n == 0) return 1;\n\n    // Precompute factorials up to n\n    uint64_t factorials[16] = {1};\n    for (int i = 1; i <= n; i++) {\n        factorials[i] = factorials[i-1] * i;\n    }\n\n    // Use AVX2 to parallelize multiplication\n    __m256i result_vec = _mm256_set1_epi64x(1);\n    \n    for (int i = 0; i <= n; i += 4) {\n        __m256i fact_vec = _mm256_loadu_si256((__m256i*)&factorials[i]);\n        result_vec = _mm256_mul_epu32(result_vec, fact_vec);\n    }\n\n    // Horizontal multiplication of vector elements\n    uint64_t result = 1;\n    alignas(32) uint64_t temp[4];\n    _mm256_store_si256((__m256i*)temp, result_vec);\n    \n    for (int i = 0; i < 4; i++) {\n        result *= temp[i];\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_129_AVX", "completion": "```cpp\nuint64_t special_factorial_simd(uint64_t n) {\n    if (n == 0) return 1;\n\n    // Precompute factorials up to n\n    uint64_t factorials[16] = {1};\n    for (int i = 1; i <= n; i++) {\n        factorials[i] = factorials[i-1] * i;\n    }\n\n    // Use AVX2 to parallelize multiplication\n    __m256i result_vec = _mm256_set1_epi64x(1);\n    \n    for (int i = 0; i <= n; i += 4) {\n        __m256i fact_vec = _mm256_loadu_si256((__m256i*)&factorials[i]);\n        result_vec = _mm256_mul_epu32(result_vec, fact_vec);\n    }\n\n    // Horizontal multiplication of vector elements\n    __m128i low = _mm256_extracti128_si256(result_vec, 0);\n    __m128i high = _mm256_extracti128_si256(result_vec, 1);\n    \n    low = _mm_mul_epu32(low, high);\n    low = _mm_mul_epu32(low, _mm_srli_si128(low, 8));\n\n    return _mm_cvtsi128_si64(low);\n}\n```"}
{"task_id": "SimdBench_129_AVX", "completion": "```cpp\nuint64_t special_factorial_simd(uint64_t n) {\n    if (n == 0) return 1;\n\n    // Precompute factorials up to n\n    uint64_t factorials[16] = {1};\n    for (int i = 1; i <= n; i++) {\n        factorials[i] = factorials[i-1] * i;\n    }\n\n    // Use AVX2 to parallelize multiplication\n    __m256i result_vec = _mm256_set1_epi64x(1);\n    \n    for (int i = 0; i <= n; i += 4) {\n        __m256i fact_vec = _mm256_loadu_si256((__m256i*)&factorials[i]);\n        result_vec = _mm256_mul_epu32(result_vec, fact_vec);\n    }\n\n    // Horizontal multiplication of vector elements\n    uint64_t result = 1;\n    alignas(32) uint64_t temp[4];\n    _mm256_store_si256((__m256i*)temp, result_vec);\n    \n    for (int i = 0; i < 4; i++) {\n        result *= temp[i];\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_130_AVX", "completion": "```cpp\nint sum_squares_simd(const std::vector<int> & lst) {\n    int size = lst.size();\n    if (size == 0) return 0;\n\n    // Process 8 integers at a time with AVX2\n    int sum = 0;\n    int i = 0;\n    \n    // Process 8 integers in parallel\n    for (; i + 8 <= size; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&lst[i]);\n        __m256i modified_vec = _mm256_setzero_si256();\n\n        for (int j = 0; j < 8; j++) {\n            int index = i + j;\n            if (index % 3 == 0) {\n                // Square if index is multiple of 3\n                int val = lst[index];\n                int squared = val * val;\n                modified_vec = _mm256_insert_epi32(modified_vec, squared, j);\n            } else if (index % 4 == 0) {\n                // Cube if index is multiple of 4 but not 3\n                int val = lst[index];\n                int cubed = val * val * val;\n                modified_vec = _mm256_insert_epi32(modified_vec, cubed, j);\n            } else {\n                // Keep original value\n                modified_vec = _mm256_insert_epi32(modified_vec, lst[index], j);\n            }\n        }\n\n        // Horizontal sum of modified vector\n        __m128i sum_lo = _mm256_extracti128_si256(modified_vec, 0);\n        __m128i sum_hi = _mm256_extracti128_si256(modified_vec, 1);\n        __m128i sum_128 = _mm_add_epi32(sum_lo, sum_hi);\n        sum_128 = _mm_hadd_epi32(sum_128, sum_128);\n        sum_128 = _mm_hadd_epi32(sum_128, sum_128);\n        sum += _mm_cvtsi128_si32(sum_128);\n    }\n\n    // Handle remaining elements\n    for (; i < size; i++) {\n        if (i % 3 == 0) {\n            sum += lst[i] * lst[i];\n        } else if (i % 4 == 0) {\n            sum += lst[i] * lst[i] * lst[i];\n        } else {\n            sum += lst[i];\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_130_AVX", "completion": "```cpp\nint sum_squares_simd(const std::vector<int> & lst) {\n    int size = lst.size();\n    if (size == 0) return 0;\n\n    // Process 8 integers at a time with AVX2\n    int sum = 0;\n    int i = 0;\n    \n    // Process 8 elements at a time using AVX2\n    for (; i + 8 <= size; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&lst[i]);\n        __m256i modified_vec = _mm256_set_epi32(0, 0, 0, 0, 0, 0, 0, 0);\n\n        for (int j = 0; j < 8; j++) {\n            if ((i + j) % 3 == 0) {\n                // Square if index is multiple of 3\n                int val = lst[i + j];\n                modified_vec = _mm256_insert_epi32(modified_vec, val * val, j);\n            } else if ((i + j) % 4 == 0) {\n                // Cube if index is multiple of 4 and not 3\n                int val = lst[i + j];\n                modified_vec = _mm256_insert_epi32(modified_vec, val * val * val, j);\n            } else {\n                // Keep original value\n                modified_vec = _mm256_insert_epi32(modified_vec, lst[i + j], j);\n            }\n        }\n\n        // Horizontal sum of modified vector\n        __m256i sum_vec = _mm256_hadd_epi32(modified_vec, modified_vec);\n        sum_vec = _mm256_hadd_epi32(sum_vec, sum_vec);\n        __m128i sum_128 = _mm_add_epi32(_mm256_extracti128_si256(sum_vec, 0), \n                                         _mm256_extracti128_si256(sum_vec, 1));\n        sum += _mm_cvtsi128_si32(sum_128);\n    }\n\n    // Handle remaining elements\n    for (; i < size; i++) {\n        if (i % 3 == 0) {\n            sum += lst[i] * lst[i];\n        } else if (i % 4 == 0) {\n            sum += lst[i] * lst[i] * lst[i];\n        } else {\n            sum += lst[i];\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_130_AVX", "completion": "```cpp\nint sum_squares_simd(const std::vector<int> & lst) {\n    int size = lst.size();\n    if (size == 0) return 0;\n\n    // Process 8 integers at a time with AVX2\n    int sum = 0;\n    int i = 0;\n    \n    // Process 8 integers in parallel\n    for (; i + 8 <= size; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&lst[i]);\n        __m256i modified_vec = _mm256_set_epi32(0, 0, 0, 0, 0, 0, 0, 0);\n\n        for (int j = 0; j < 8; j++) {\n            int index = i + j;\n            int val = lst[index];\n            \n            if (index % 3 == 0) {\n                val *= val; // square\n            } else if (index % 4 == 0) {\n                val *= val * val; // cube\n            }\n            \n            modified_vec = _mm256_insert_epi32(modified_vec, val, j);\n        }\n\n        // Horizontal sum of modified vector\n        __m256i sum_vec = _mm256_hadd_epi32(modified_vec, modified_vec);\n        sum_vec = _mm256_hadd_epi32(sum_vec, sum_vec);\n        sum += _mm256_extract_epi32(sum_vec, 0) + _mm256_extract_epi32(sum_vec, 4);\n    }\n\n    // Handle remaining elements\n    for (; i < size; i++) {\n        int val = lst[i];\n        \n        if (i % 3 == 0) {\n            val *= val; // square\n        } else if (i % 4 == 0) {\n            val *= val * val; // cube\n        }\n        \n        sum += val;\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_130_AVX", "completion": "```cpp\nint sum_squares_simd(const std::vector<int> & lst) {\n    int size = lst.size();\n    if (size == 0) return 0;\n\n    // Process 8 integers at a time with AVX2\n    int sum = 0;\n    int i = 0;\n    \n    // Process 8 elements at a time using AVX2\n    for (; i + 7 < size; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&lst[i]);\n        __m256i modified_vec = _mm256_set_epi32(\n            (i+7) % 3 == 0 ? lst[i+7] * lst[i+7] : (i+7) % 4 == 0 ? lst[i+7] * lst[i+7] * lst[i+7] : lst[i+7],\n            (i+6) % 3 == 0 ? lst[i+6] * lst[i+6] : (i+6) % 4 == 0 ? lst[i+6] * lst[i+6] * lst[i+6] : lst[i+6],\n            (i+5) % 3 == 0 ? lst[i+5] * lst[i+5] : (i+5) % 4 == 0 ? lst[i+5] * lst[i+5] * lst[i+5] : lst[i+5],\n            (i+4) % 3 == 0 ? lst[i+4] * lst[i+4] : (i+4) % 4 == 0 ? lst[i+4] * lst[i+4] * lst[i+4] : lst[i+4],\n            (i+3) % 3 == 0 ? lst[i+3] * lst[i+3] : (i+3) % 4 == 0 ? lst[i+3] * lst[i+3] * lst[i+3] : lst[i+3],\n            (i+2) % 3 == 0 ? lst[i+2] * lst[i+2] : (i+2) % 4 == 0 ? lst[i+2] * lst[i+2] * lst[i+2] : lst[i+2],\n            (i+1) % 3 == 0 ? lst[i+1] * lst[i+1] : (i+1) % 4 == 0 ? lst[i+1] * lst[i+1] * lst[i+1] : lst[i+1],\n            i % 3 == 0 ? lst[i] * lst[i] : i % 4 == 0 ? lst[i] * lst[i] * lst[i] : lst[i]\n        );\n        \n        __m256i sum_vec = _mm256_hadd_epi32(modified_vec, modified_vec);\n        sum_vec = _mm256_hadd_epi32(sum_vec, sum_vec);\n        \n        __m128i sum_low = _mm256_extracti128_si256(sum_vec, 0);\n        __m128i sum_high = _mm256_extracti128_si256(sum_vec, 1);\n        __m128i total = _mm_add_epi32(sum_low, sum_high);\n        sum += _mm_cvtsi128_si32(total);\n    }\n    \n    // Handle remaining elements\n    for (; i < size; i++) {\n        if (i % 3 == 0) {\n            sum += lst[i] * lst[i];\n        } else if (i % 4 == 0) {\n            sum += lst[i] * lst[i] * lst[i];\n        } else {\n            sum += lst[i];\n        }\n    }\n    \n    return sum;\n}\n```"}
{"task_id": "SimdBench_130_AVX", "completion": "```cpp\nint sum_squares_simd(const std::vector<int> & lst) {\n    int size = lst.size();\n    if (size == 0) return 0;\n\n    // Process 8 integers at a time with AVX2\n    int sum = 0;\n    int i = 0;\n    \n    // Process 8 elements at a time using AVX2\n    for (; i + 8 <= size; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&lst[i]);\n        __m256i modified_vec = _mm256_setzero_si256();\n\n        for (int j = 0; j < 8; j++) {\n            int index = i + j;\n            int val = lst[index];\n            \n            if (index % 3 == 0) {\n                // Square if index is multiple of 3\n                val *= val;\n            } else if (index % 4 == 0) {\n                // Cube if index is multiple of 4 but not 3\n                val *= val * val;\n            }\n            \n            modified_vec = _mm256_insert_epi32(modified_vec, val, j);\n        }\n\n        // Horizontal sum of modified vector\n        __m128i sum_lo = _mm256_extracti128_si256(modified_vec, 0);\n        __m128i sum_hi = _mm256_extracti128_si256(modified_vec, 1);\n        sum_lo = _mm_add_epi32(sum_lo, sum_hi);\n        sum_lo = _mm_hadd_epi32(sum_lo, sum_lo);\n        sum_lo = _mm_hadd_epi32(sum_lo, sum_lo);\n        sum += _mm_cvtsi128_si32(sum_lo);\n    }\n\n    // Process remaining elements\n    for (; i < size; i++) {\n        int val = lst[i];\n        \n        if (i % 3 == 0) {\n            val *= val;\n        } else if (i % 4 == 0) {\n            val *= val * val;\n        }\n        \n        sum += val;\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_131_AVX", "completion": "```cpp\nint specialFilter_simd(const std::vector<int> & nums) {\n    int count = 0;\n    int size = nums.size();\n    \n    // Process 8 integers at a time using AVX2\n    int vector_size = size - (size % 8);\n    \n    __m256i threshold_vec = _mm256_set1_epi32(10);\n    __m256i zero_vec = _mm256_setzero_si256();\n    \n    for (int i = 0; i < vector_size; i += 8) {\n        // Load 8 integers\n        __m256i current_vec = _mm256_loadu_si256((__m256i*)&nums[i]);\n        \n        // Check numbers > 10\n        __m256i greater_mask = _mm256_cmpgt_epi32(current_vec, threshold_vec);\n        \n        // Take absolute value to handle negative numbers\n        __m256i abs_vec = _mm256_abs_epi32(current_vec);\n        \n        // Extract first and last digits\n        __m256i first_digit_vec = _mm256_div_epi32(abs_vec, _mm256_set1_epi32(pow(10, floor(log10(INT_MAX)))));\n        __m256i last_digit_vec = _mm256_mod_epi32(abs_vec, _mm256_set1_epi32(10));\n        \n        // Check if first and last digits are odd\n        __m256i first_odd_mask = _mm256_cmpeq_epi32(_mm256_mod_epi32(first_digit_vec, _mm256_set1_epi32(2)), _mm256_set1_epi32(1));\n        __m256i last_odd_mask = _mm256_cmpeq_epi32(_mm256_mod_epi32(last_digit_vec, _mm256_set1_epi32(2)), _mm256_set1_epi32(1));\n        \n        // Combine masks\n        __m256i combined_mask = _mm256_and_si256(greater_mask, first_odd_mask);\n        combined_mask = _mm256_and_si256(combined_mask, last_odd_mask);\n        \n        // Count matching elements\n        count += _mm_popcnt_u32(_mm256_movemask_epi8(combined_mask));\n    }\n    \n    // Handle remaining elements\n    for (int i = vector_size; i < size; ++i) {\n        int abs_num = std::abs(nums[i]);\n        int first_digit = abs_num / pow(10, floor(log10(abs_num)));\n        int last_digit = abs_num % 10;\n        \n        if (nums[i] > 10 && first_digit % 2 == 1 && last_digit % 2 == 1) {\n            ++count;\n        }\n    }\n    \n    return count;\n}\n```"}
{"task_id": "SimdBench_131_AVX", "completion": "```cpp\nint specialFilter_simd(const std::vector<int> & nums) {\n    int count = 0;\n    int n = nums.size();\n    \n    // Process 8 integers at a time using AVX2\n    for (int i = 0; i < n; i += 8) {\n        // Load 8 integers into AVX register\n        __m256i vec = _mm256_loadu_si256((__m256i*)&nums[i]);\n        \n        // Create mask for numbers > 10\n        __m256i ten = _mm256_set1_epi32(10);\n        __m256i mask_gt_ten = _mm256_cmpgt_epi32(vec, ten);\n        \n        // Extract first and last digit\n        __m256i abs_vec = _mm256_abs_epi32(vec);\n        __m256i first_digit = _mm256_div_epi32(abs_vec, _mm256_set1_epi32(pow(10, floor(log10(INT_MAX)))));\n        __m256i last_digit = _mm256_mod_epi32(abs_vec, _mm256_set1_epi32(10));\n        \n        // Check if first and last digits are odd\n        __m256i odd_first = _mm256_and_si256(_mm256_cmpeq_epi32(_mm256_mod_epi32(first_digit, _mm256_set1_epi32(2)), _mm256_set1_epi32(1)), \n                                             _mm256_cmpeq_epi32(_mm256_mod_epi32(last_digit, _mm256_set1_epi32(2)), _mm256_set1_epi32(1)));\n        \n        // Combine masks\n        __m256i final_mask = _mm256_and_si256(mask_gt_ten, odd_first);\n        \n        // Count matching elements\n        count += _mm_popcnt_u32(_mm256_movemask_ps(_mm256_castsi256_ps(final_mask)));\n    }\n    \n    // Handle remaining elements\n    for (int i = n - (n % 8); i < n; ++i) {\n        if (nums[i] > 10) {\n            int abs_num = abs(nums[i]);\n            int first_digit = abs_num / pow(10, floor(log10(abs_num)));\n            int last_digit = abs_num % 10;\n            \n            if (first_digit % 2 == 1 && last_digit % 2 == 1) {\n                count++;\n            }\n        }\n    }\n    \n    return count;\n}\n```"}
{"task_id": "SimdBench_131_AVX", "completion": "```cpp\nint specialFilter_simd(const std::vector<int> & nums) {\n    int count = 0;\n    int size = nums.size();\n    \n    // Process 8 integers at a time using AVX2\n    int vector_size = size - (size % 8);\n    \n    __m256i threshold_mask = _mm256_set1_epi32(10);\n    __m256i zero_mask = _mm256_setzero_si256();\n    \n    for (int i = 0; i < vector_size; i += 8) {\n        // Load 8 integers\n        __m256i vec = _mm256_loadu_si256((__m256i*)&nums[i]);\n        \n        // Check numbers > 10\n        __m256i greater_mask = _mm256_cmpgt_epi32(vec, threshold_mask);\n        \n        // Absolute value to handle negative numbers\n        __m256i abs_vec = _mm256_abs_epi32(vec);\n        \n        // Extract first digit\n        __m256i first_digit = _mm256_div_epi32(abs_vec, _mm256_set1_epi32(pow(10, floor(log10(INT_MAX)))));\n        \n        // Extract last digit\n        __m256i last_digit = _mm256_mod_epi32(abs_vec, _mm256_set1_epi32(10));\n        \n        // Check if first and last digits are odd (1, 3, 5, 7, 9)\n        __m256i first_odd_mask = _mm256_cmpeq_epi32(_mm256_mod_epi32(first_digit, _mm256_set1_epi32(2)), _mm256_set1_epi32(1));\n        __m256i last_odd_mask = _mm256_cmpeq_epi32(_mm256_mod_epi32(last_digit, _mm256_set1_epi32(2)), _mm256_set1_epi32(1));\n        \n        // Combine all conditions\n        __m256i result_mask = _mm256_and_si256(greater_mask, first_odd_mask);\n        result_mask = _mm256_and_si256(result_mask, last_odd_mask);\n        \n        // Count matching elements\n        count += _mm_popcnt_u32(_mm256_movemask_ps(_mm256_castsi256_ps(result_mask)));\n    }\n    \n    // Handle remaining elements\n    for (int i = vector_size; i < size; ++i) {\n        if (nums[i] > 10) {\n            int abs_num = std::abs(nums[i]);\n            int first_digit = abs_num / static_cast<int>(pow(10, floor(log10(abs_num))));\n            int last_digit = abs_num % 10;\n            \n            if (first_digit % 2 == 1 && last_digit % 2 == 1) {\n                ++count;\n            }\n        }\n    }\n    \n    return count;\n}\n```"}
{"task_id": "SimdBench_131_AVX", "completion": "```cpp\nint specialFilter_simd(const std::vector<int> & nums) {\n    int count = 0;\n    int n = nums.size();\n    \n    // Process 8 integers at a time using AVX2\n    for (int i = 0; i < n; i += 8) {\n        // Load 8 integers into AVX register\n        __m256i vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&nums[i]));\n        \n        // Create mask for numbers > 10\n        __m256i ten_vec = _mm256_set1_epi32(10);\n        __m256i mask_gt_ten = _mm256_cmpgt_epi32(vec, ten_vec);\n        \n        // Extract first and last digit\n        __m256i abs_vec = _mm256_abs_epi32(vec);\n        __m256i first_digit = _mm256_div_epi32(abs_vec, _mm256_set1_epi32(pow(10, floor(log10(INT_MAX)))));\n        __m256i last_digit = _mm256_rem_epi32(abs_vec, _mm256_set1_epi32(10));\n        \n        // Check if first and last digits are odd\n        __m256i first_odd_mask = _mm256_and_si256(_mm256_and_si256(first_digit, _mm256_set1_epi32(1)), _mm256_set1_epi32(1));\n        __m256i last_odd_mask = _mm256_and_si256(_mm256_and_si256(last_digit, _mm256_set1_epi32(1)), _mm256_set1_epi32(1));\n        \n        // Combine masks\n        __m256i combined_mask = _mm256_and_si256(mask_gt_ten, _mm256_and_si256(first_odd_mask, last_odd_mask));\n        \n        // Count matching elements\n        int mask = _mm256_movemask_ps(_mm256_castsi256_ps(combined_mask));\n        count += _mm_popcnt_u32(mask);\n    }\n    \n    // Handle remaining elements\n    for (int i = n - (n % 8); i < n; ++i) {\n        if (nums[i] > 10) {\n            int abs_num = abs(nums[i]);\n            int first_digit = abs_num / pow(10, floor(log10(abs_num)));\n            int last_digit = abs_num % 10;\n            \n            if (first_digit % 2 == 1 && last_digit % 2 == 1) {\n                ++count;\n            }\n        }\n    }\n    \n    return count;\n}\n```"}
{"task_id": "SimdBench_131_AVX", "completion": "```cpp\nint specialFilter_simd(const std::vector<int> & nums) {\n    int count = 0;\n    int size = nums.size();\n    \n    // Process 8 integers at a time using AVX2\n    int vector_size = size - (size % 8);\n    \n    __m256i threshold_vec = _mm256_set1_epi32(10);\n    __m256i zero_vec = _mm256_setzero_si256();\n    \n    for (int i = 0; i < vector_size; i += 8) {\n        // Load 8 integers\n        __m256i current_vec = _mm256_loadu_si256((__m256i*)&nums[i]);\n        \n        // Check values > 10\n        __m256i greater_mask = _mm256_cmpgt_epi32(current_vec, threshold_vec);\n        \n        // Take absolute value to handle negative numbers\n        __m256i abs_vec = _mm256_abs_epi32(current_vec);\n        \n        // Extract first and last digits\n        __m256i first_digit_vec = _mm256_div_epi32(abs_vec, _mm256_set1_epi32(pow(10, floor(log10(INT_MAX)))));\n        __m256i last_digit_vec = _mm256_mod_epi32(abs_vec, _mm256_set1_epi32(10));\n        \n        // Check if first and last digits are odd\n        __m256i first_odd_mask = _mm256_cmpeq_epi32(_mm256_mod_epi32(first_digit_vec, _mm256_set1_epi32(2)), _mm256_set1_epi32(1));\n        __m256i last_odd_mask = _mm256_cmpeq_epi32(_mm256_mod_epi32(last_digit_vec, _mm256_set1_epi32(2)), _mm256_set1_epi32(1));\n        \n        // Combine all conditions\n        __m256i combined_mask = _mm256_and_si256(greater_mask, first_odd_mask);\n        combined_mask = _mm256_and_si256(combined_mask, last_odd_mask);\n        \n        // Count matching elements\n        int mask = _mm256_movemask_ps((__m256)combined_mask);\n        count += _mm_popcnt_u32(mask);\n    }\n    \n    // Handle remaining elements\n    for (int i = vector_size; i < size; ++i) {\n        int abs_num = std::abs(nums[i]);\n        int first_digit = abs_num / static_cast<int>(pow(10, floor(log10(abs_num))));\n        int last_digit = abs_num % 10;\n        \n        if (nums[i] > 10 && first_digit % 2 == 1 && last_digit % 2 == 1) {\n            ++count;\n        }\n    }\n    \n    return count;\n}\n```"}
{"task_id": "SimdBench_132_AVX", "completion": "```cpp\nuint64_t get_max_triples_simd(uint64_t n) {\n    uint64_t triples_count = 0;\n    \n    // Precompute array using SIMD\n    __m256i* a = (__m256i*)_mm_malloc(n * sizeof(uint64_t), 32);\n    \n    // Process 4 elements at a time using AVX\n    for (uint64_t i = 0; i < n; i += 4) {\n        __m256i indices = _mm256_set_epi64x(i+3, i+2, i+1, i);\n        __m256i squared = _mm256_mul_epi64(indices, indices);\n        __m256i result = _mm256_sub_epi64(_mm256_add_epi64(squared, _mm256_set1_epi64x(1)), indices);\n        _mm256_storeu_si256(a + i/4, result);\n    }\n    \n    // Brute force triple counting with early exit\n    for (uint64_t i = 0; i < n - 2; i++) {\n        for (uint64_t j = i + 1; j < n - 1; j++) {\n            for (uint64_t k = j + 1; k < n; k++) {\n                if ((a[i] + a[j] + a[k]) % 3 == 0) {\n                    triples_count++;\n                }\n            }\n        }\n    }\n    \n    _mm_free(a);\n    return triples_count;\n}\n```"}
{"task_id": "SimdBench_132_AVX", "completion": "```cpp\nuint64_t get_max_triples_simd(uint64_t n) {\n    // Allocate aligned memory for vector a\n    uint64_t* a = (uint64_t*)_mm_malloc(n * sizeof(uint64_t), 32);\n    \n    // Compute vector a using AVX2 vectorization\n    for (uint64_t i = 0; i < n; i += 4) {\n        __m256i indices = _mm256_set_epi64x(i+3, i+2, i+1, i);\n        __m256i squared = _mm256_mul_epu32(indices, indices);\n        __m256i result = _mm256_sub_epi64(_mm256_add_epi64(squared, _mm256_set1_epi64x(1)), indices);\n        _mm256_storeu_si256((__m256i*)(a + i), result);\n    }\n    \n    // Handle remaining elements if n is not divisible by 4\n    for (uint64_t i = (n / 4) * 4; i < n; i++) {\n        a[i] = i * i - i + 1;\n    }\n    \n    uint64_t triples_count = 0;\n    \n    // Compute triples using nested loops\n    for (uint64_t i = 0; i < n - 2; i++) {\n        for (uint64_t j = i + 1; j < n - 1; j++) {\n            for (uint64_t k = j + 1; k < n; k++) {\n                if ((a[i] + a[j] + a[k]) % 3 == 0) {\n                    triples_count++;\n                }\n            }\n        }\n    }\n    \n    // Free aligned memory\n    _mm_free(a);\n    \n    return triples_count;\n}\n```"}
{"task_id": "SimdBench_132_AVX", "completion": "```cpp\nuint64_t get_max_triples_simd(uint64_t n) {\n    uint64_t count = 0;\n    \n    // Precompute array a using SIMD\n    __m256i* a = (__m256i*)_mm_malloc(n * sizeof(uint64_t), 32);\n    \n    // Process 4 elements at a time using AVX\n    for (uint64_t i = 0; i < n; i += 4) {\n        __m256i indices = _mm256_set_epi64x(i+3, i+2, i+1, i);\n        __m256i squared = _mm256_mul_epu32(indices, indices);\n        __m256i result = _mm256_sub_epi64(_mm256_add_epi64(squared, _mm256_set1_epi64x(1)), indices);\n        _mm256_storeu_si256(a + i/4, result);\n    }\n    \n    // Brute force triple counting with SIMD optimization\n    for (uint64_t i = 0; i < n - 2; i++) {\n        for (uint64_t j = i + 1; j < n - 1; j++) {\n            for (uint64_t k = j + 1; k < n; k++) {\n                if ((a[i] + a[j] + a[k]) % 3 == 0) {\n                    count++;\n                }\n            }\n        }\n    }\n    \n    _mm_free(a);\n    return count;\n}\n```"}
{"task_id": "SimdBench_132_AVX", "completion": "```cpp\nuint64_t get_max_triples_simd(uint64_t n) {\n    // Precompute array using SIMD\n    std::vector<uint64_t> a(n);\n    const int VECTOR_WIDTH = 4; // AVX can process 4 64-bit integers simultaneously\n\n    // Vectorized computation of array elements\n    for (int i = 0; i < n; i += VECTOR_WIDTH) {\n        __m256i indices = _mm256_set_epi64x(i+3, i+2, i+1, i);\n        __m256i squared = _mm256_mul_epu32(indices, indices);\n        __m256i result = _mm256_sub_epi64(_mm256_add_epi64(squared, _mm256_set1_epi64x(1)), indices);\n        \n        _mm256_storeu_si256((__m256i*)&a[i], result);\n    }\n\n    uint64_t triples_count = 0;\n\n    // Vectorized triple checking\n    for (uint64_t i = 0; i < n - 2; ++i) {\n        for (uint64_t j = i + 1; j < n - 1; ++j) {\n            // Vectorize inner loop\n            for (uint64_t k = j + 1; k < n; k += VECTOR_WIDTH) {\n                __m256i k_vec = _mm256_set_epi64x(k+3, k+2, k+1, k);\n                __m256i a_k_vec = _mm256_set_epi64x(\n                    k+3 < n ? a[k+3] : 0, \n                    k+2 < n ? a[k+2] : 0, \n                    k+1 < n ? a[k+1] : 0, \n                    k < n ? a[k] : 0\n                );\n\n                __m256i sum_vec = _mm256_set1_epi64x(a[i] + a[j]);\n                sum_vec = _mm256_add_epi64(sum_vec, a_k_vec);\n\n                // Check divisibility by 3\n                for (int l = 0; l < VECTOR_WIDTH; ++l) {\n                    uint64_t sum = _mm256_extract_epi64(sum_vec, l);\n                    if (sum % 3 == 0 && k+l < n) {\n                        triples_count++;\n                    }\n                }\n            }\n        }\n    }\n\n    return triples_count;\n}\n```"}
{"task_id": "SimdBench_132_AVX", "completion": "```cpp\nuint64_t get_max_triples_simd(uint64_t n) {\n    // Precompute array using SIMD\n    std::vector<uint64_t> a(n);\n    const int VECTOR_WIDTH = 4; // AVX can process 4 64-bit integers per instruction\n\n    // Use SIMD to compute array values\n    for (int i = 0; i < n; i += VECTOR_WIDTH) {\n        __m256i indices = _mm256_set_epi64x(i+3, i+2, i+1, i);\n        __m256i squared = _mm256_mul_epu32(indices, indices);\n        __m256i result = _mm256_sub_epi64(_mm256_add_epi64(squared, _mm256_set1_epi64x(1)), indices);\n        \n        _mm256_storeu_si256((__m256i*)&a[i], result);\n    }\n\n    // Count triples\n    uint64_t count = 0;\n    for (uint64_t i = 0; i < n - 2; ++i) {\n        for (uint64_t j = i + 1; j < n - 1; ++j) {\n            for (uint64_t k = j + 1; k < n; ++k) {\n                if ((a[i] + a[j] + a[k]) % 3 == 0) {\n                    ++count;\n                }\n            }\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_133_AVX", "completion": "```cpp\nint x_or_y_simd(int n, int x, int y) {\n    // Check primality using SIMD operations\n    __m256i divisors = _mm256_set_epi32(2, 3, 4, 5, 6, 7, 8, 9);\n    __m256i target = _mm256_set1_epi32(n);\n    __m256i ones = _mm256_set1_epi32(1);\n    __m256i is_prime = _mm256_set1_epi32(1);\n\n    for (int i = 0; i < 8; i++) {\n        __m256i div = _mm256_set1_epi32(_mm256_extract_epi32(divisors, i));\n        __m256i mod = _mm256_rem_epi32(target, div);\n        __m256i is_divisible = _mm256_cmpeq_epi32(mod, _mm256_setzero_si256());\n        is_prime = _mm256_and_si256(is_prime, _mm256_cmpgt_epi32(div, target));\n    }\n\n    int prime_result = _mm256_movemask_epi8(is_prime) & 0xFF;\n    return prime_result ? x : y;\n}\n```"}
{"task_id": "SimdBench_133_AVX", "completion": "```cpp\nint x_or_y_simd(int n, int x, int y) {\n    // Check primality using AVX2 vector operations\n    if (n <= 1) return y;\n    if (n == 2) return x;\n    if (n % 2 == 0) return y;\n\n    // Use AVX2 to check divisibility efficiently\n    __m256i divisors = _mm256_setr_epi32(3, 5, 7, 11, 13, 17, 19, 23);\n    __m256i target = _mm256_set1_epi32(n);\n    \n    for (int i = 0; i < 8; i++) {\n        __m256i div = _mm256_set1_epi32(_mm256_extract_epi32(divisors, i));\n        if (div >= target) break;\n        \n        __m256i remainder = _mm256_rem_epi32(target, div);\n        if (_mm256_movemask_epi8(_mm256_cmpeq_epi32(remainder, _mm256_setzero_si256())) != 0) {\n            return y;\n        }\n    }\n    \n    return x;\n}\n```"}
{"task_id": "SimdBench_133_AVX", "completion": "```cpp\nint x_or_y_simd(int n, int x, int y) {\n    // Check primality using SIMD operations\n    if (n <= 1) return y;\n    if (n == 2) return x;\n    if (n % 2 == 0) return y;\n\n    // Use AVX2 to check divisibility efficiently\n    __m256i divisors = _mm256_setr_epi32(3, 5, 7, 11, 13, 17, 19, 23);\n    __m256i target = _mm256_set1_epi32(n);\n    \n    for (int i = 0; i < 8; i++) {\n        __m256i div_check = _mm256_div_epi32(target, _mm256_set1_epi32(_mm256_extract_epi32(divisors, i)));\n        __m256i remainder = _mm256_sub_epi32(target, _mm256_mullo_epi32(div_check, _mm256_set1_epi32(_mm256_extract_epi32(divisors, i))));\n        \n        if (_mm256_extract_epi32(remainder, 0) == 0 && _mm256_extract_epi32(divisors, i) != n) {\n            return y;\n        }\n    }\n\n    // Additional primality check for larger divisors\n    for (int i = 29; i * i <= n; i += 2) {\n        if (n % i == 0) return y;\n    }\n\n    return x;\n}\n```"}
{"task_id": "SimdBench_133_AVX", "completion": "```cpp\nint x_or_y_simd(int n, int x, int y) {\n    // Check primality using SIMD-based approach\n    if (n <= 1) return y;\n    if (n == 2) return x;\n    if (n % 2 == 0) return y;\n\n    // Use AVX2 for efficient primality check\n    __m256i divisors = _mm256_setr_epi32(3, 5, 7, 11, 13, 17, 19, 23);\n    __m256i target = _mm256_set1_epi32(n);\n    __m256i result = _mm256_set1_epi32(1);\n\n    for (int i = 0; i < 8; i++) {\n        __m256i div = _mm256_set1_epi32(_mm256_extract_epi32(divisors, i));\n        __m256i mod = _mm256_set1_epi32(n % _mm256_extract_epi32(divisors, i));\n        result = _mm256_and_si256(result, _mm256_cmpgt_epi32(div, mod));\n    }\n\n    int is_prime = _mm256_movemask_epi8(result) == 0;\n    return is_prime ? x : y;\n}\n```"}
{"task_id": "SimdBench_133_AVX", "completion": "```cpp\nint x_or_y_simd(int n, int x, int y) {\n    // Check primality using SIMD operations\n    __m256i divisors = _mm256_setr_epi32(2, 3, 5, 7, 11, 13, 17, 19);\n    __m256i target = _mm256_set1_epi32(n);\n    __m256i ones = _mm256_set1_epi32(1);\n    \n    // Check divisibility\n    __m256i mod_results = _mm256_setzero_si256();\n    for (int i = 0; i < 8; i++) {\n        __m256i div_check = _mm256_div_epi32(target, _mm256_set1_epi32(_mm256_extract_epi32(divisors, i)));\n        __m256i remainder = _mm256_sub_epi32(target, _mm256_mullo_epi32(div_check, _mm256_set1_epi32(_mm256_extract_epi32(divisors, i))));\n        mod_results = _mm256_or_si256(mod_results, _mm256_cmpeq_epi32(remainder, _mm256_setzero_si256()));\n    }\n    \n    // Check if n is prime\n    int is_prime = (_mm256_movemask_epi8(mod_results) == 0) && (n > 1);\n    \n    return is_prime ? x : y;\n}\n```"}
{"task_id": "SimdBench_134_AVX", "completion": "```cpp\nuint64_t double_the_difference_simd(const std::vector<float> & lst) {\n    if (lst.empty()) return 0;\n\n    size_t n = lst.size();\n    size_t vec_size = n - (n % 8);\n    uint64_t result = 0;\n\n    __m256 zero = _mm256_setzero_ps();\n    __m256 ones = _mm256_set1_ps(1.0f);\n    __m256 sum_squares = _mm256_setzero_ps();\n\n    for (size_t i = 0; i < vec_size; i += 8) {\n        __m256 vec = _mm256_loadu_ps(&lst[i]);\n        \n        // Check for odd integers\n        __m256 is_odd = _mm256_and_ps(\n            _mm256_cmp_ps(_mm256_mod_ps(vec, _mm256_set1_ps(2.0f)), zero, _CMP_EQ_OQ),\n            _mm256_cmp_ps(vec, zero, _CMP_GE_OQ)\n        );\n        \n        // Square the odd numbers\n        __m256 squared = _mm256_mul_ps(vec, vec);\n        squared = _mm256_and_ps(squared, is_odd);\n        \n        sum_squares = _mm256_add_ps(sum_squares, squared);\n    }\n\n    // Horizontal sum\n    __m128 sum_low = _mm256_extractf128_ps(sum_squares, 0);\n    __m128 sum_high = _mm256_extractf128_ps(sum_squares, 1);\n    sum_low = _mm_add_ps(sum_low, sum_high);\n    sum_low = _mm_hadd_ps(sum_low, sum_low);\n    sum_low = _mm_hadd_ps(sum_low, sum_low);\n    result += _mm_cvtss_f32(sum_low);\n\n    // Handle remaining elements\n    for (size_t i = vec_size; i < n; ++i) {\n        float val = lst[i];\n        if (val > 0 && static_cast<int>(val) == val && static_cast<int>(val) % 2 == 1) {\n            result += val * val;\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_134_AVX", "completion": "```cpp\nuint64_t double_the_difference_simd(const std::vector<float> & lst) {\n    if (lst.empty()) return 0;\n\n    size_t vec_size = lst.size();\n    size_t simd_size = vec_size - (vec_size % 8);\n\n    __m256 zero = _mm256_setzero_ps();\n    __m256 sum_squares = _mm256_setzero_ps();\n\n    for (size_t i = 0; i < simd_size; i += 8) {\n        __m256 vec_data = _mm256_loadu_ps(&lst[i]);\n        \n        // Check for odd integers\n        __m256 is_odd = _mm256_and_ps(\n            _mm256_cmp_ps(vec_data, zero, _CMP_NEQ_OQ),  // Not zero\n            _mm256_and_ps(\n                _mm256_cmp_ps(_mm256_floor_ps(vec_data), vec_data, _CMP_EQ_OQ),  // Integer check\n                _mm256_cmp_ps(_mm256_mod_ps(vec_data, _mm256_set1_ps(2.0f)), _mm256_set1_ps(1.0f), _CMP_EQ_OQ)  // Odd check\n            )\n        );\n\n        __m256 squared_data = _mm256_mul_ps(vec_data, vec_data);\n        __m256 masked_squares = _mm256_and_ps(squared_data, is_odd);\n        \n        sum_squares = _mm256_add_ps(sum_squares, masked_squares);\n    }\n\n    // Horizontal sum\n    __m128 sum_low = _mm256_extractf128_ps(sum_squares, 0);\n    __m128 sum_high = _mm256_extractf128_ps(sum_squares, 1);\n    sum_low = _mm_add_ps(sum_low, sum_high);\n    sum_low = _mm_hadd_ps(sum_low, sum_low);\n    sum_low = _mm_hadd_ps(sum_low, sum_low);\n    \n    float final_sum = _mm_cvtss_f32(sum_low);\n\n    // Handle remaining elements\n    for (size_t i = simd_size; i < vec_size; ++i) {\n        float val = lst[i];\n        if (val > 0 && std::floor(val) == val && static_cast<int>(val) % 2 == 1) {\n            final_sum += val * val;\n        }\n    }\n\n    return static_cast<uint64_t>(final_sum);\n}\n```"}
{"task_id": "SimdBench_134_AVX", "completion": "```cpp\nuint64_t double_the_difference_simd(const std::vector<float> & lst) {\n    if (lst.empty()) return 0;\n\n    size_t n = lst.size();\n    size_t vec_size = n - (n % 8);\n    uint64_t result = 0;\n\n    __m256 zero = _mm256_setzero_ps();\n    __m256 ones = _mm256_set1_ps(1.0f);\n\n    for (size_t i = 0; i < vec_size; i += 8) {\n        __m256 vec = _mm256_loadu_ps(&lst[i]);\n        \n        // Check for odd integers\n        __m256 is_int = _mm256_cmp_ps(vec, _mm256_floor_ps(vec), _CMP_EQ_OQ);\n        __m256 is_odd = _mm256_and_ps(is_int, _mm256_cmp_ps(_mm256_mod_ps(vec, _mm256_set1_ps(2.0f)), zero, _CMP_NEQ_OQ));\n        \n        // Check for positive\n        __m256 is_positive = _mm256_cmp_ps(vec, zero, _CMP_GT_OQ);\n        \n        // Combine conditions\n        __m256 mask = _mm256_and_ps(is_odd, is_positive);\n        \n        // Square the values\n        __m256 squared = _mm256_mul_ps(vec, vec);\n        squared = _mm256_and_ps(squared, mask);\n        \n        // Horizontal sum\n        __m128 sum_lo = _mm256_extractf128_ps(squared, 0);\n        __m128 sum_hi = _mm256_extractf128_ps(squared, 1);\n        sum_lo = _mm_add_ps(sum_lo, sum_hi);\n        sum_lo = _mm_hadd_ps(sum_lo, sum_lo);\n        sum_lo = _mm_hadd_ps(sum_lo, sum_lo);\n        \n        result += _mm_cvtss_f32(sum_lo);\n    }\n\n    // Handle remaining elements\n    for (size_t i = vec_size; i < n; ++i) {\n        float val = lst[i];\n        if (val > 0 && std::floor(val) == val && static_cast<int>(val) % 2 == 1) {\n            result += val * val;\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_134_AVX", "completion": "```cpp\nuint64_t double_the_difference_simd(const std::vector<float> & lst) {\n    if (lst.empty()) return 0;\n\n    size_t vec_size = lst.size();\n    size_t simd_size = vec_size - (vec_size % 8);\n\n    __m256 zero_vec = _mm256_setzero_ps();\n    __m256 result_vec = _mm256_setzero_ps();\n\n    for (size_t i = 0; i < simd_size; i += 8) {\n        __m256 current_vec = _mm256_loadu_ps(&lst[i]);\n        \n        // Check for odd integers\n        __m256 is_odd_mask = _mm256_and_ps(\n            _mm256_cmp_ps(current_vec, zero_vec, _CMP_GT_OQ),  // positive\n            _mm256_cmp_ps(_mm256_floor_ps(current_vec), current_vec, _CMP_EQ_OQ)  // integer\n        );\n        \n        __m256 odd_mask = _mm256_and_ps(\n            is_odd_mask,\n            _mm256_cmp_ps(_mm256_mod_ps(current_vec, _mm256_set1_ps(2.0f)), _mm256_setzero_ps(), _CMP_NEQ_OQ)\n        );\n        \n        // Square the odd numbers\n        __m256 squared_vec = _mm256_mul_ps(current_vec, current_vec);\n        squared_vec = _mm256_and_ps(squared_vec, odd_mask);\n        \n        result_vec = _mm256_add_ps(result_vec, squared_vec);\n    }\n\n    // Horizontal sum\n    __m128 sum_low = _mm256_extractf128_ps(result_vec, 0);\n    __m128 sum_high = _mm256_extractf128_ps(result_vec, 1);\n    sum_low = _mm_add_ps(sum_low, sum_high);\n    sum_low = _mm_hadd_ps(sum_low, sum_low);\n    sum_low = _mm_hadd_ps(sum_low, sum_low);\n    float total_sum = _mm_cvtss_f32(sum_low);\n\n    // Handle remaining elements\n    for (size_t i = simd_size; i < vec_size; ++i) {\n        float val = lst[i];\n        if (val > 0 && std::floor(val) == val && static_cast<int>(val) % 2 == 1) {\n            total_sum += val * val;\n        }\n    }\n\n    return static_cast<uint64_t>(total_sum);\n}\n```"}
{"task_id": "SimdBench_134_AVX", "completion": "```cpp\nuint64_t double_the_difference_simd(const std::vector<float> & lst) {\n    if (lst.empty()) return 0;\n\n    size_t n = lst.size();\n    size_t vec_size = n - (n % 8);\n    uint64_t result = 0;\n\n    __m256 zero = _mm256_setzero_ps();\n    __m256 ones = _mm256_set1_ps(1.0f);\n    __m256 two = _mm256_set1_ps(2.0f);\n\n    for (size_t i = 0; i < vec_size; i += 8) {\n        __m256 vec = _mm256_loadu_ps(&lst[i]);\n        \n        // Check for positive integers\n        __m256 is_positive = _mm256_cmp_ps(vec, zero, _CMP_GT_OQ);\n        __m256 is_integer = _mm256_cmpeq_ps(vec, _mm256_floor_ps(vec));\n        \n        // Check for odd numbers\n        __m256 mod_two = _mm256_sub_ps(vec, _mm256_mul_ps(_mm256_floor_ps(_mm256_div_ps(vec, two)), two));\n        __m256 is_odd = _mm256_cmpeq_ps(mod_two, ones);\n        \n        // Combine conditions\n        __m256 mask = _mm256_and_ps(is_positive, _mm256_and_ps(is_integer, is_odd));\n        \n        // Square the odd numbers\n        __m256 squared = _mm256_mul_ps(vec, vec);\n        squared = _mm256_and_ps(squared, mask);\n        \n        // Horizontal sum\n        __m128 low = _mm256_extractf128_ps(squared, 0);\n        __m128 high = _mm256_extractf128_ps(squared, 1);\n        low = _mm_add_ps(low, high);\n        low = _mm_hadd_ps(low, low);\n        low = _mm_hadd_ps(low, low);\n        \n        result += _mm_cvtss_f32(low);\n    }\n\n    // Handle remaining elements\n    for (size_t i = vec_size; i < n; ++i) {\n        float val = lst[i];\n        if (val > 0 && std::floor(val) == val && static_cast<int>(val) % 2 == 1) {\n            result += val * val;\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_135_AVX", "completion": "```cpp\nstd::vector<int> compare_simd(const std::vector<int>& game, const std::vector<int>& guess) {\n    int n = game.size();\n    std::vector<int> result(n);\n    \n    // Process 8 integers at a time using AVX2\n    for (int i = 0; i < n; i += 8) {\n        // Load 8 game and guess values\n        __m256i game_vec = _mm256_loadu_si256((__m256i*)&game[i]);\n        __m256i guess_vec = _mm256_loadu_si256((__m256i*)&guess[i]);\n        \n        // Compute absolute difference\n        __m256i diff = _mm256_abs_epi32(_mm256_sub_epi32(game_vec, guess_vec));\n        \n        // Store results\n        _mm256_storeu_si256((__m256i*)&result[i], diff);\n    }\n    \n    // Handle remaining elements\n    for (int i = n - (n % 8); i < n; i++) {\n        result[i] = std::abs(game[i] - guess[i]);\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_135_AVX", "completion": "```cpp\nstd::vector<int> compare_simd(const std::vector<int>& game, const std::vector<int>& guess) {\n    int n = game.size();\n    std::vector<int> result(n);\n    \n    // Process 8 integers at a time using AVX2\n    for (int i = 0; i < n; i += 8) {\n        // Load 8 game scores and guesses\n        __m256i game_vec = _mm256_loadu_si256((__m256i*)&game[i]);\n        __m256i guess_vec = _mm256_loadu_si256((__m256i*)&guess[i]);\n        \n        // Compute absolute difference\n        __m256i diff = _mm256_abs_epi32(_mm256_sub_epi32(game_vec, guess_vec));\n        \n        // Store results\n        _mm256_storeu_si256((__m256i*)&result[i], diff);\n    }\n    \n    // Handle remaining elements\n    for (int i = (n/8)*8; i < n; i++) {\n        result[i] = std::abs(game[i] - guess[i]);\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_135_AVX", "completion": "```cpp\nstd::vector<int> compare_simd(const std::vector<int>& game, const std::vector<int>& guess) {\n    int n = game.size();\n    std::vector<int> result(n);\n    \n    // Process 8 integers at a time using AVX2\n    for (int i = 0; i < n; i += 8) {\n        // Load 8 game scores and guesses\n        __m256i game_vec = _mm256_loadu_si256((__m256i*)&game[i]);\n        __m256i guess_vec = _mm256_loadu_si256((__m256i*)&guess[i]);\n        \n        // Compute absolute difference\n        __m256i diff = _mm256_abs_epi32(_mm256_sub_epi32(game_vec, guess_vec));\n        \n        // Store results\n        _mm256_storeu_si256((__m256i*)&result[i], diff);\n    }\n    \n    // Handle remaining elements\n    for (int i = n - (n % 8); i < n; i++) {\n        result[i] = std::abs(game[i] - guess[i]);\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_135_AVX", "completion": "```cpp\nstd::vector<int> compare_simd(const std::vector<int>& game, const std::vector<int>& guess) {\n    int n = game.size();\n    std::vector<int> result(n);\n    \n    // Process 8 integers at a time using AVX2\n    for (int i = 0; i < n; i += 8) {\n        // Load 8 game scores and guesses into AVX registers\n        __m256i game_vec = _mm256_loadu_si256((__m256i*)&game[i]);\n        __m256i guess_vec = _mm256_loadu_si256((__m256i*)&guess[i]);\n        \n        // Compute absolute difference using subtraction and abs intrinsics\n        __m256i diff_vec = _mm256_abs_epi32(_mm256_sub_epi32(game_vec, guess_vec));\n        \n        // Store results back to result vector\n        _mm256_storeu_si256((__m256i*)&result[i], diff_vec);\n    }\n    \n    // Handle any remaining elements\n    for (int i = n - (n % 8); i < n; i++) {\n        result[i] = std::abs(game[i] - guess[i]);\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_135_AVX", "completion": "```cpp\nstd::vector<int> compare_simd(const std::vector<int>& game, const std::vector<int>& guess) {\n    int n = game.size();\n    std::vector<int> result(n);\n    \n    // Process 8 integers at a time using AVX2\n    for (int i = 0; i < n; i += 8) {\n        // Load 8 game and guess values\n        __m256i game_vec = _mm256_loadu_si256((__m256i*)&game[i]);\n        __m256i guess_vec = _mm256_loadu_si256((__m256i*)&guess[i]);\n        \n        // Compute absolute difference\n        __m256i diff = _mm256_abs_epi32(_mm256_sub_epi32(game_vec, guess_vec));\n        \n        // Store result\n        _mm256_storeu_si256((__m256i*)&result[i], diff);\n    }\n    \n    // Handle remaining elements\n    for (int i = n - (n % 8); i < n; i++) {\n        result[i] = std::abs(game[i] - guess[i]);\n    }\n    \n    return result;\n}\n```"}

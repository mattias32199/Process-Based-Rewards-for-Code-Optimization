{"task_id": "SimdBench_0_AVX", "completion": "```cpp\nvoid conditional_move_simd(const int64_t *src, int64_t *dst, const bool *mask, size_t length) {\n    size_t i;\n    for (i = 0; i + 4 <= length; i += 4) {\n        __m256i src_vec = _mm256_loadu_si256((const __m256i*)(src + i));\n        __m256i dst_vec = _mm256_loadu_si256((const __m256i*)(dst + i));\n        \n        __m256i mask_vec = _mm256_set_epi64x(mask[i+3], mask[i+2], mask[i+1], mask[i]);\n        \n        __m256i blend = _mm256_blendv_epi8(dst_vec, src_vec, mask_vec);\n        \n        _mm256_storeu_si256((__m256i*)(dst + i), blend);\n    }\n\n    for (; i < length; i++) {\n        if (mask[i]) {\n            dst[i] = src[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_0_AVX", "completion": "```cpp\nvoid conditional_move_simd(const int64_t *src, int64_t *dst, const bool *mask, size_t length) {\n    size_t i;\n    for (i = 0; i + 4 <= length; i += 4) {\n        __m256i src_vec = _mm256_loadu_si256((__m256i*)(src + i));\n        __m256i dst_vec = _mm256_loadu_si256((__m256i*)(dst + i));\n        \n        __m256i mask_vec = _mm256_set_epi64x(\n            mask[i+3] ? -1LL : 0,\n            mask[i+2] ? -1LL : 0,\n            mask[i+1] ? -1LL : 0,\n            mask[i] ? -1LL : 0\n        );\n        \n        __m256i blend = _mm256_blendv_epi8(dst_vec, src_vec, mask_vec);\n        _mm256_storeu_si256((__m256i*)(dst + i), blend);\n    }\n\n    for (; i < length; i++) {\n        if (mask[i]) {\n            dst[i] = src[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_0_AVX", "completion": "```cpp\nvoid conditional_move_simd(const int64_t *src, int64_t *dst, const bool *mask, size_t length) {\n    size_t i;\n    for (i = 0; i + 4 <= length; i += 4) {\n        __m256i src_vec = _mm256_loadu_si256((const __m256i*)(src + i));\n        __m256i dst_vec = _mm256_loadu_si256((const __m256i*)(dst + i));\n        \n        __m256i mask_vec = _mm256_set_epi64x(\n            mask[i+3] ? -1LL : 0,\n            mask[i+2] ? -1LL : 0,\n            mask[i+1] ? -1LL : 0,\n            mask[i] ? -1LL : 0\n        );\n        \n        __m256i blend = _mm256_blendv_epi8(dst_vec, src_vec, mask_vec);\n        _mm256_storeu_si256((__m256i*)(dst + i), blend);\n    }\n\n    for (; i < length; i++) {\n        if (mask[i]) {\n            dst[i] = src[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_0_AVX", "completion": "```cpp\nvoid conditional_move_simd(const int64_t *src, int64_t *dst, const bool *mask, size_t length) {\n    size_t i;\n    for (i = 0; i + 4 <= length; i += 4) {\n        __m256i src_vec = _mm256_loadu_si256((const __m256i*)(src + i));\n        __m256i dst_vec = _mm256_loadu_si256((const __m256i*)(dst + i));\n        \n        __m256i mask_vec = _mm256_set_epi64x(mask[i+3], mask[i+2], mask[i+1], mask[i]);\n        \n        __m256i blended = _mm256_blendv_epi8(dst_vec, src_vec, mask_vec);\n        \n        _mm256_storeu_si256((__m256i*)(dst + i), blended);\n    }\n\n    for (; i < length; i++) {\n        if (mask[i]) {\n            dst[i] = src[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_0_AVX", "completion": "```cpp\nvoid conditional_move_simd(const int64_t *src, int64_t *dst, const bool *mask, size_t length) {\n    size_t i;\n    for (i = 0; i + 4 <= length; i += 4) {\n        __m256i src_vec = _mm256_loadu_si256((__m256i*)(src + i));\n        __m256i dst_vec = _mm256_loadu_si256((__m256i*)(dst + i));\n        \n        __m256i mask_vec = _mm256_set_epi64x(\n            mask[i+3] ? -1LL : 0,\n            mask[i+2] ? -1LL : 0,\n            mask[i+1] ? -1LL : 0,\n            mask[i] ? -1LL : 0\n        );\n        \n        __m256i blend = _mm256_blendv_epi8(dst_vec, src_vec, mask_vec);\n        _mm256_storeu_si256((__m256i*)(dst + i), blend);\n    }\n\n    for (; i < length; i++) {\n        if (mask[i]) {\n            dst[i] = src[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_1_AVX", "completion": "```cpp\nvoid load_modify_store_simd(const int *src, int *dst, int scale, size_t length) {\n    __m256i scale_vec = _mm256_set1_epi32(scale);\n    size_t i;\n    \n    for (i = 0; i + 8 <= length; i += 8) {\n        __m256i src_vec = _mm256_loadu_si256((const __m256i*)(src + i));\n        \n        // element * scale\n        __m256i scaled = _mm256_mullo_epi32(src_vec, scale_vec);\n        \n        // tmp1 = (element * scale) >> 3\n        __m256i tmp1 = _mm256_srai_epi32(scaled, 3);\n        \n        // tmp2 = (element * scale) << 3\n        __m256i tmp2 = _mm256_slli_epi32(scaled, 3);\n        \n        // tmp1 * tmp2\n        __m256i prod = _mm256_mullo_epi32(tmp1, tmp2);\n        \n        // element * scale + tmp1 * tmp2\n        __m256i sum = _mm256_add_epi32(scaled, prod);\n        \n        // divide by 7 using multiplication by magic number\n        __m256i magic = _mm256_set1_epi32(0x24924925);\n        __m256i tmp = _mm256_srli_epi32(_mm256_mulhi_epi32(sum, magic), 2);\n        __m256i result = _mm256_sub_epi32(tmp, _mm256_srli_epi32(sum, 31));\n        \n        _mm256_storeu_si256((__m256i*)(dst + i), result);\n    }\n    \n    // Handle remaining elements\n    for (; i < length; i++) {\n        int scaled = src[i] * scale;\n        int tmp1 = scaled >> 3;\n        int tmp2 = scaled << 3;\n        dst[i] = (scaled + tmp1 * tmp2) / 7;\n    }\n}\n```"}
{"task_id": "SimdBench_1_AVX", "completion": "```cpp\nvoid load_modify_store_simd(const int *src, int *dst, int scale, size_t length) {\n    __m256i scale_vec = _mm256_set1_epi32(scale);\n    size_t i;\n    \n    for (i = 0; i + 8 <= length; i += 8) {\n        __m256i src_vec = _mm256_loadu_si256((__m256i*)(src + i));\n        \n        // element * scale\n        __m256i scaled = _mm256_mullo_epi32(src_vec, scale_vec);\n        \n        // tmp1 = (element * scale) >> 3\n        __m256i tmp1 = _mm256_srai_epi32(scaled, 3);\n        \n        // tmp2 = (element * scale) << 3\n        __m256i tmp2 = _mm256_slli_epi32(scaled, 3);\n        \n        // tmp1 * tmp2\n        __m256i prod = _mm256_mullo_epi32(tmp1, tmp2);\n        \n        // element * scale + tmp1 * tmp2\n        __m256i sum = _mm256_add_epi32(scaled, prod);\n        \n        // divide by 7 using multiplication by magic number\n        __m256i magic = _mm256_set1_epi32(0x24924925);\n        __m256i temp = _mm256_srli_epi32(_mm256_mulhi_epi32(sum, magic), 2);\n        __m256i result = _mm256_add_epi32(temp, _mm256_srli_epi32(sum, 31));\n        \n        _mm256_storeu_si256((__m256i*)(dst + i), result);\n    }\n    \n    // Handle remaining elements\n    for (; i < length; i++) {\n        int scaled = src[i] * scale;\n        int tmp1 = scaled >> 3;\n        int tmp2 = scaled << 3;\n        dst[i] = (scaled + tmp1 * tmp2) / 7;\n    }\n}\n```"}
{"task_id": "SimdBench_1_AVX", "completion": "```cpp\nvoid load_modify_store_simd(const int *src, int *dst, int scale, size_t length) {\n    __m256i scale_vec = _mm256_set1_epi32(scale);\n    size_t i;\n    \n    for (i = 0; i + 8 <= length; i += 8) {\n        __m256i src_vec = _mm256_loadu_si256((__m256i*)(src + i));\n        \n        // element * scale\n        __m256i scaled = _mm256_mullo_epi32(src_vec, scale_vec);\n        \n        // tmp1 = (element * scale) >> 3\n        __m256i tmp1 = _mm256_srai_epi32(scaled, 3);\n        \n        // tmp2 = (element * scale) << 3\n        __m256i tmp2 = _mm256_slli_epi32(scaled, 3);\n        \n        // tmp1 * tmp2\n        __m256i prod = _mm256_mullo_epi32(tmp1, tmp2);\n        \n        // element * scale + tmp1 * tmp2\n        __m256i sum = _mm256_add_epi32(scaled, prod);\n        \n        // divide by 7\n        __m256i div7 = _mm256_set1_epi32(0x24924925);\n        __m256i t1 = _mm256_srli_epi32(_mm256_mulhi_epi32(sum, div7), 2);\n        __m256i t2 = _mm256_srai_epi32(sum, 31);\n        __m256i result = _mm256_sub_epi32(t1, t2);\n        \n        _mm256_storeu_si256((__m256i*)(dst + i), result);\n    }\n    \n    // Handle remaining elements\n    for (; i < length; i++) {\n        int scaled = src[i] * scale;\n        int tmp1 = scaled >> 3;\n        int tmp2 = scaled << 3;\n        dst[i] = (scaled + tmp1 * tmp2) / 7;\n    }\n}\n```"}
{"task_id": "SimdBench_1_AVX", "completion": "```cpp\nvoid load_modify_store_simd(const int *src, int *dst, int scale, size_t length) {\n    __m256i scale_vec = _mm256_set1_epi32(scale);\n    size_t i;\n    \n    for (i = 0; i + 8 <= length; i += 8) {\n        __m256i src_vec = _mm256_loadu_si256((const __m256i*)(src + i));\n        \n        // element * scale\n        __m256i scaled = _mm256_mullo_epi32(src_vec, scale_vec);\n        \n        // tmp1 = (element * scale) >> 3\n        __m256i tmp1 = _mm256_srai_epi32(scaled, 3);\n        \n        // tmp2 = (element * scale) << 3\n        __m256i tmp2 = _mm256_slli_epi32(scaled, 3);\n        \n        // tmp1 * tmp2\n        __m256i prod = _mm256_mullo_epi32(tmp1, tmp2);\n        \n        // element * scale + tmp1 * tmp2\n        __m256i sum = _mm256_add_epi32(scaled, prod);\n        \n        // divide by 7\n        __m256i div7 = _mm256_set1_epi32(0x24924925);\n        __m256i t1 = _mm256_srli_epi32(_mm256_mulhi_epi32(sum, div7), 2);\n        __m256i t2 = _mm256_srai_epi32(sum, 31);\n        __m256i result = _mm256_sub_epi32(t1, t2);\n        \n        _mm256_storeu_si256((__m256i*)(dst + i), result);\n    }\n    \n    // Handle remaining elements\n    for (; i < length; i++) {\n        int scaled = src[i] * scale;\n        int tmp1 = scaled >> 3;\n        int tmp2 = scaled << 3;\n        dst[i] = (scaled + tmp1 * tmp2) / 7;\n    }\n}\n```"}
{"task_id": "SimdBench_1_AVX", "completion": "```cpp\nvoid load_modify_store_simd(const int *src, int *dst, int scale, size_t length) {\n    __m256i scale_vec = _mm256_set1_epi32(scale);\n    size_t i;\n    \n    for (i = 0; i + 8 <= length; i += 8) {\n        __m256i src_vec = _mm256_loadu_si256((__m256i*)(src + i));\n        \n        // element * scale\n        __m256i scaled = _mm256_mullo_epi32(src_vec, scale_vec);\n        \n        // tmp1 = (element * scale) >> 3\n        __m256i tmp1 = _mm256_srai_epi32(scaled, 3);\n        \n        // tmp2 = (element * scale) << 3\n        __m256i tmp2 = _mm256_slli_epi32(scaled, 3);\n        \n        // tmp1 * tmp2\n        __m256i prod = _mm256_mullo_epi32(tmp1, tmp2);\n        \n        // element * scale + tmp1 * tmp2\n        __m256i sum = _mm256_add_epi32(scaled, prod);\n        \n        // divide by 7 using multiplication by magic number\n        __m256i magic = _mm256_set1_epi32(0x24924925);\n        __m256i temp = _mm256_srli_epi32(_mm256_mulhi_epi32(sum, magic), 2);\n        __m256i result = _mm256_sub_epi32(temp, _mm256_srli_epi32(sum, 31));\n        \n        _mm256_storeu_si256((__m256i*)(dst + i), result);\n    }\n    \n    // Handle remaining elements\n    for (; i < length; i++) {\n        int scaled = src[i] * scale;\n        int tmp1 = scaled >> 3;\n        int tmp2 = scaled << 3;\n        dst[i] = (scaled + tmp1 * tmp2) / 7;\n    }\n}\n```"}
{"task_id": "SimdBench_2_AVX", "completion": "```cpp\nvoid strided_load_store_simd(const double *src, double *dst, size_t rows, size_t cols, size_t stride) {\n    const size_t vec_size = 4;\n    size_t vec_rows = rows / vec_size;\n    size_t rem_rows = rows % vec_size;\n\n    for (size_t i = 0; i < vec_rows; i++) {\n        __m256d vec = _mm256_set_pd(\n            src[(i*vec_size + 3)*cols + stride],\n            src[(i*vec_size + 2)*cols + stride], \n            src[(i*vec_size + 1)*cols + stride],\n            src[(i*vec_size + 0)*cols + stride]\n        );\n        _mm256_storeu_pd(&dst[i*vec_size], vec);\n    }\n\n    size_t offset = vec_rows * vec_size;\n    for (size_t i = 0; i < rem_rows; i++) {\n        dst[offset + i] = src[(offset + i)*cols + stride];\n    }\n}\n```"}
{"task_id": "SimdBench_2_AVX", "completion": "```cpp\nvoid strided_load_store_simd(const double *src, double *dst, size_t rows, size_t cols, size_t stride) {\n    const size_t vec_size = 4;\n    size_t vec_rows = rows / vec_size;\n    size_t rem_rows = rows % vec_size;\n\n    for (size_t i = 0; i < vec_rows; i++) {\n        __m256d vec = _mm256_set_pd(\n            src[(i*vec_size + 3)*cols + stride],\n            src[(i*vec_size + 2)*cols + stride], \n            src[(i*vec_size + 1)*cols + stride],\n            src[(i*vec_size + 0)*cols + stride]\n        );\n        _mm256_storeu_pd(&dst[i*vec_size], vec);\n    }\n\n    size_t base = vec_rows * vec_size;\n    for (size_t i = 0; i < rem_rows; i++) {\n        dst[base + i] = src[(base + i)*cols + stride];\n    }\n}\n```"}
{"task_id": "SimdBench_2_AVX", "completion": "```cpp\nvoid strided_load_store_simd(const double *src, double *dst, size_t rows, size_t cols, size_t stride) {\n    const size_t vec_size = 4;\n    size_t vec_rows = rows / vec_size;\n    size_t rem_rows = rows % vec_size;\n\n    for (size_t i = 0; i < vec_rows; i++) {\n        __m256d vec = _mm256_set_pd(\n            src[(i*vec_size + 3)*cols + stride],\n            src[(i*vec_size + 2)*cols + stride], \n            src[(i*vec_size + 1)*cols + stride],\n            src[(i*vec_size + 0)*cols + stride]\n        );\n        _mm256_storeu_pd(&dst[i*vec_size], vec);\n    }\n\n    size_t offset = vec_rows * vec_size;\n    for (size_t i = 0; i < rem_rows; i++) {\n        dst[offset + i] = src[(offset + i)*cols + stride];\n    }\n}\n```"}
{"task_id": "SimdBench_2_AVX", "completion": "```cpp\nvoid strided_load_store_simd(const double *src, double *dst, size_t rows, size_t cols, size_t stride) {\n    const size_t vec_size = 4;\n    size_t vec_rows = rows / vec_size;\n    size_t rem_rows = rows % vec_size;\n\n    for (size_t i = 0; i < vec_rows; i++) {\n        __m256d vec = _mm256_set_pd(\n            src[(i*vec_size + 3)*cols + stride],\n            src[(i*vec_size + 2)*cols + stride], \n            src[(i*vec_size + 1)*cols + stride],\n            src[(i*vec_size + 0)*cols + stride]\n        );\n        _mm256_storeu_pd(&dst[i*vec_size], vec);\n    }\n\n    size_t base = vec_rows * vec_size;\n    for (size_t i = 0; i < rem_rows; i++) {\n        dst[base + i] = src[(base + i)*cols + stride];\n    }\n}\n```"}
{"task_id": "SimdBench_2_AVX", "completion": "```cpp\nvoid strided_load_store_simd(const double *src, double *dst, size_t rows, size_t cols, size_t stride) {\n    const size_t vec_size = 4;\n    size_t vec_rows = rows / vec_size;\n    size_t rem_rows = rows % vec_size;\n\n    for (size_t i = 0; i < vec_rows; i++) {\n        __m256d vec = _mm256_set_pd(\n            src[(i * vec_size + 3) * cols + stride],\n            src[(i * vec_size + 2) * cols + stride], \n            src[(i * vec_size + 1) * cols + stride],\n            src[(i * vec_size + 0) * cols + stride]\n        );\n        _mm256_storeu_pd(&dst[i * vec_size], vec);\n    }\n\n    size_t offset = vec_rows * vec_size;\n    for (size_t i = 0; i < rem_rows; i++) {\n        dst[offset + i] = src[(offset + i) * cols + stride];\n    }\n}\n```"}
{"task_id": "SimdBench_3_AVX", "completion": "```cpp\nvoid indexed_access_simd(const float *src, const int *indices, float *dst, size_t length) {\n    size_t i;\n    const size_t vec_size = 8;\n    size_t vec_length = length - (length % vec_size);\n\n    // Gather operation\n    for (i = 0; i < vec_length; i += vec_size) {\n        __m256i idx = _mm256_loadu_si256((__m256i*)(indices + i));\n        __m256 gathered = _mm256_i32gather_ps(src, idx, 4);\n        _mm256_storeu_ps(dst + i, gathered);\n    }\n    \n    // Handle remaining elements for gather\n    for (; i < length; i++) {\n        dst[i] = src[indices[i]];\n    }\n\n    // Scatter operation\n    for (i = 0; i < length; i++) {\n        dst[indices[i]] = src[i];\n    }\n}\n```"}
{"task_id": "SimdBench_3_AVX", "completion": "```cpp\nvoid indexed_access_simd(const float *src, const int *indices, float *dst, size_t length) {\n    size_t i;\n    const size_t simd_width = 8;\n    const size_t simd_length = length & ~(simd_width - 1);\n\n    // Gather operation\n    for (i = 0; i < simd_length; i += simd_width) {\n        __m256i idx = _mm256_loadu_si256((__m256i*)(indices + i));\n        __m256 gathered = _mm256_i32gather_ps(src, idx, 4);\n        _mm256_storeu_ps(dst + i, gathered);\n    }\n    \n    // Handle remaining elements for gather\n    for (; i < length; i++) {\n        dst[i] = src[indices[i]];\n    }\n\n    // Scatter operation (AVX2 doesn't have native scatter, so we process scalar)\n    for (i = 0; i < length; i++) {\n        dst[indices[i]] = src[i];\n    }\n}\n```"}
{"task_id": "SimdBench_3_AVX", "completion": "```cpp\nvoid indexed_access_simd(const float *src, const int *indices, float *dst, size_t length) {\n    size_t i;\n    const size_t simd_width = 8;\n    const size_t simd_length = length - (length % simd_width);\n\n    // Gather operation\n    for (i = 0; i < simd_length; i += simd_width) {\n        __m256i idx = _mm256_loadu_si256((__m256i*)(indices + i));\n        __m256 gathered = _mm256_i32gather_ps(src, idx, 4);\n        _mm256_storeu_ps(dst + i, gathered);\n    }\n    \n    // Handle remaining elements for gather\n    for (; i < length; i++) {\n        dst[i] = src[indices[i]];\n    }\n\n    // Scatter operation (AVX2 doesn't have native scatter, so use scalar)\n    for (i = 0; i < length; i++) {\n        dst[indices[i]] = src[i];\n    }\n}\n```"}
{"task_id": "SimdBench_3_AVX", "completion": "```cpp\nvoid indexed_access_simd(const float *src, const int *indices, float *dst, size_t length) {\n    size_t i;\n    \n    // Process 8 elements at a time\n    for (i = 0; i + 8 <= length; i += 8) {\n        // Load 8 indices\n        __m256i idx = _mm256_loadu_si256((__m256i*)(indices + i));\n        \n        // Gather values from src using indices\n        __m256 gathered = _mm256_i32gather_ps(src, idx, 4);\n        \n        // Store gathered values to dst\n        _mm256_storeu_ps(dst + i, gathered);\n    }\n    \n    // Handle remaining elements for gather\n    for (; i < length; i++) {\n        dst[i] = src[indices[i]];\n    }\n    \n    // Reset counter for scatter operation\n    for (i = 0; i + 8 <= length; i += 8) {\n        // Load 8 values from src\n        __m256 values = _mm256_loadu_ps(src + i);\n        \n        // Load 8 indices\n        __m256i idx = _mm256_loadu_si256((__m256i*)(indices + i));\n        \n        // Scatter values one by one since AVX2 doesn't have scatter\n        float temp[8];\n        _mm256_storeu_ps(temp, values);\n        \n        for (int j = 0; j < 8; j++) {\n            dst[indices[i + j]] = temp[j];\n        }\n    }\n    \n    // Handle remaining elements for scatter\n    for (; i < length; i++) {\n        dst[indices[i]] = src[i];\n    }\n}\n```"}
{"task_id": "SimdBench_3_AVX", "completion": "```cpp\nvoid indexed_access_simd(const float *src, const int *indices, float *dst, size_t length) {\n    size_t i;\n    const size_t simd_width = 8;\n    const size_t simd_length = length - (length % simd_width);\n\n    // Gather operation\n    for (i = 0; i < simd_length; i += simd_width) {\n        __m256i idx = _mm256_loadu_si256((__m256i*)(indices + i));\n        __m256 gathered = _mm256_i32gather_ps(src, idx, 4);\n        _mm256_storeu_ps(dst + i, gathered);\n    }\n    \n    // Handle remaining elements for gather\n    for (; i < length; i++) {\n        dst[i] = src[indices[i]];\n    }\n\n    // Scatter operation (AVX2 doesn't have scatter, so do scalar)\n    for (i = 0; i < length; i++) {\n        dst[indices[i]] = src[i];\n    }\n}\n```"}
{"task_id": "SimdBench_4_AVX", "completion": "```cpp\nvoid range_reverse_simd(int16_t *arr, uint64_t start, uint64_t end) {\n    uint64_t length = end - start + 1;\n    uint64_t i;\n    \n    // Process 16 elements at a time using AVX2\n    for (i = 0; i < length/16; i++) {\n        __m256i v1 = _mm256_loadu_si256((__m256i*)(arr + start + i*16));\n        __m256i v2 = _mm256_loadu_si256((__m256i*)(arr + end - (i+1)*16 + 1));\n        \n        // Reverse elements within each vector\n        v1 = _mm256_shufflehi_epi16(v1, _MM_SHUFFLE(0,1,2,3));\n        v1 = _mm256_shufflelo_epi16(v1, _MM_SHUFFLE(0,1,2,3));\n        v1 = _mm256_permute4x64_epi64(v1, _MM_SHUFFLE(1,0,3,2));\n        \n        v2 = _mm256_shufflehi_epi16(v2, _MM_SHUFFLE(0,1,2,3));\n        v2 = _mm256_shufflelo_epi16(v2, _MM_SHUFFLE(0,1,2,3));\n        v2 = _mm256_permute4x64_epi64(v2, _MM_SHUFFLE(1,0,3,2));\n        \n        _mm256_storeu_si256((__m256i*)(arr + start + i*16), v2);\n        _mm256_storeu_si256((__m256i*)(arr + end - (i+1)*16 + 1), v1);\n    }\n    \n    // Handle remaining elements\n    uint64_t remaining_start = start + i*16;\n    uint64_t remaining_end = end - i*16;\n    \n    while (remaining_start < remaining_end) {\n        int16_t temp = arr[remaining_start];\n        arr[remaining_start] = arr[remaining_end];\n        arr[remaining_end] = temp;\n        remaining_start++;\n        remaining_end--;\n    }\n}\n```"}
{"task_id": "SimdBench_4_AVX", "completion": "```cpp\nvoid range_reverse_simd(int16_t *arr, uint64_t start, uint64_t end) {\n    uint64_t len = end - start + 1;\n    uint64_t i, j;\n    \n    // Process 16 elements at a time using AVX2\n    for (i = start, j = end; i < start + (len/2); i += 16, j -= 16) {\n        if (j - i >= 15) {\n            __m256i v1 = _mm256_loadu_si256((__m256i*)(arr + i));\n            __m256i v2 = _mm256_loadu_si256((__m256i*)(arr + j - 15));\n            \n            // Reverse elements within each vector\n            v1 = _mm256_shufflehi_epi16(v1, _MM_SHUFFLE(0,1,2,3));\n            v1 = _mm256_shufflelo_epi16(v1, _MM_SHUFFLE(0,1,2,3));\n            v1 = _mm256_permute4x64_epi64(v1, _MM_SHUFFLE(0,1,2,3));\n            \n            v2 = _mm256_shufflehi_epi16(v2, _MM_SHUFFLE(0,1,2,3));\n            v2 = _mm256_shufflelo_epi16(v2, _MM_SHUFFLE(0,1,2,3));\n            v2 = _mm256_permute4x64_epi64(v2, _MM_SHUFFLE(0,1,2,3));\n            \n            // Store reversed vectors\n            _mm256_storeu_si256((__m256i*)(arr + i), v2);\n            _mm256_storeu_si256((__m256i*)(arr + j - 15), v1);\n        }\n    }\n    \n    // Handle remaining elements\n    for (; i < start + (len/2); i++, j--) {\n        int16_t temp = arr[i];\n        arr[i] = arr[j];\n        arr[j] = temp;\n    }\n}\n```"}
{"task_id": "SimdBench_4_AVX", "completion": "```cpp\nvoid range_reverse_simd(int16_t *arr, uint64_t start, uint64_t end) {\n    uint64_t len = end - start + 1;\n    uint64_t i, j;\n    \n    // Process 16 elements at a time using AVX2\n    for (i = start, j = end; i < start + (len/2); i += 16, j -= 16) {\n        if (j - i >= 15) {\n            __m256i v1 = _mm256_loadu_si256((__m256i*)(arr + i));\n            __m256i v2 = _mm256_loadu_si256((__m256i*)(arr + j - 15));\n            \n            // Reverse elements within each vector\n            v1 = _mm256_shufflehi_epi16(v1, _MM_SHUFFLE(0,1,2,3));\n            v1 = _mm256_shufflelo_epi16(v1, _MM_SHUFFLE(0,1,2,3));\n            v2 = _mm256_shufflehi_epi16(v2, _MM_SHUFFLE(0,1,2,3)); \n            v2 = _mm256_shufflelo_epi16(v2, _MM_SHUFFLE(0,1,2,3));\n            \n            // Permute 128-bit lanes\n            v1 = _mm256_permute2x128_si256(v1, v1, 1);\n            v2 = _mm256_permute2x128_si256(v2, v2, 1);\n            \n            // Store reversed vectors\n            _mm256_storeu_si256((__m256i*)(arr + i), v2);\n            _mm256_storeu_si256((__m256i*)(arr + j - 15), v1);\n        }\n    }\n    \n    // Handle remaining elements\n    for (; i < start + (len/2); i++, j--) {\n        int16_t temp = arr[i];\n        arr[i] = arr[j];\n        arr[j] = temp;\n    }\n}\n```"}
{"task_id": "SimdBench_4_AVX", "completion": "```cpp\nvoid range_reverse_simd(int16_t *arr, uint64_t start, uint64_t end) {\n    uint64_t length = end - start + 1;\n    uint64_t i;\n    \n    // Process 16 elements at a time using AVX2\n    for (i = 0; i < length/16; i++) {\n        __m256i v1 = _mm256_loadu_si256((__m256i*)(arr + start + i*16));\n        __m256i v2 = _mm256_loadu_si256((__m256i*)(arr + end - (i+1)*16 + 1));\n        \n        // Reverse elements within each 128-bit lane\n        v1 = _mm256_shufflehi_epi16(v1, _MM_SHUFFLE(0,1,2,3));\n        v1 = _mm256_shufflelo_epi16(v1, _MM_SHUFFLE(0,1,2,3));\n        v2 = _mm256_shufflehi_epi16(v2, _MM_SHUFFLE(0,1,2,3)); \n        v2 = _mm256_shufflelo_epi16(v2, _MM_SHUFFLE(0,1,2,3));\n        \n        // Swap 128-bit lanes\n        v1 = _mm256_permute2x128_si256(v1, v1, 1);\n        v2 = _mm256_permute2x128_si256(v2, v2, 1);\n        \n        _mm256_storeu_si256((__m256i*)(arr + start + i*16), v2);\n        _mm256_storeu_si256((__m256i*)(arr + end - (i+1)*16 + 1), v1);\n    }\n    \n    // Handle remaining elements\n    uint64_t remaining_start = start + i*16;\n    uint64_t remaining_end = end - i*16;\n    \n    while (remaining_start < remaining_end) {\n        int16_t temp = arr[remaining_start];\n        arr[remaining_start] = arr[remaining_end];\n        arr[remaining_end] = temp;\n        remaining_start++;\n        remaining_end--;\n    }\n}\n```"}
{"task_id": "SimdBench_4_AVX", "completion": "```cpp\nvoid range_reverse_simd(int16_t *arr, uint64_t start, uint64_t end) {\n    uint64_t length = end - start + 1;\n    uint64_t i;\n    \n    // Process 16 elements at a time using AVX2\n    for (i = 0; i < length/16; i++) {\n        __m256i v1 = _mm256_loadu_si256((__m256i*)(arr + start + i*16));\n        __m256i v2 = _mm256_loadu_si256((__m256i*)(arr + end - (i+1)*16 + 1));\n        \n        // Reverse elements within each vector\n        v1 = _mm256_shufflehi_epi16(v1, _MM_SHUFFLE(0,1,2,3));\n        v1 = _mm256_shufflelo_epi16(v1, _MM_SHUFFLE(0,1,2,3));\n        v1 = _mm256_permute4x64_epi64(v1, _MM_SHUFFLE(1,0,3,2));\n        \n        v2 = _mm256_shufflehi_epi16(v2, _MM_SHUFFLE(0,1,2,3));\n        v2 = _mm256_shufflelo_epi16(v2, _MM_SHUFFLE(0,1,2,3));\n        v2 = _mm256_permute4x64_epi64(v2, _MM_SHUFFLE(1,0,3,2));\n        \n        // Store reversed vectors\n        _mm256_storeu_si256((__m256i*)(arr + start + i*16), v2);\n        _mm256_storeu_si256((__m256i*)(arr + end - (i+1)*16 + 1), v1);\n    }\n    \n    // Handle remaining elements\n    uint64_t remaining_start = start + i*16;\n    uint64_t remaining_end = end - i*16;\n    \n    while (remaining_start < remaining_end) {\n        int16_t temp = arr[remaining_start];\n        arr[remaining_start] = arr[remaining_end];\n        arr[remaining_end] = temp;\n        remaining_start++;\n        remaining_end--;\n    }\n}\n```"}
{"task_id": "SimdBench_5_AVX", "completion": "```cpp\nvoid extract_tensor_slice_simd(const uint8_t *tensor, uint8_t *slice, size_t dim1, size_t dim2, size_t dim3, size_t slice_idx) {\n    const size_t slice_size = dim1 * dim2;\n    const size_t tensor_slice_offset = slice_idx * slice_size;\n    const size_t tensor_plane_size = dim2 * dim3;\n    \n    size_t i = 0;\n    for (; i + 32 <= slice_size; i += 32) {\n        size_t tensor_idx = 0;\n        size_t row = i / dim2;\n        size_t col = i % dim2;\n        tensor_idx = row * tensor_plane_size + col * dim3 + slice_idx;\n        \n        __m256i v = _mm256_setr_epi8(\n            tensor[tensor_idx],\n            tensor[tensor_idx + dim3],\n            tensor[tensor_idx + 2*dim3],\n            tensor[tensor_idx + 3*dim3],\n            tensor[tensor_idx + 4*dim3],\n            tensor[tensor_idx + 5*dim3],\n            tensor[tensor_idx + 6*dim3],\n            tensor[tensor_idx + 7*dim3],\n            tensor[tensor_idx + 8*dim3],\n            tensor[tensor_idx + 9*dim3],\n            tensor[tensor_idx + 10*dim3],\n            tensor[tensor_idx + 11*dim3],\n            tensor[tensor_idx + 12*dim3],\n            tensor[tensor_idx + 13*dim3],\n            tensor[tensor_idx + 14*dim3],\n            tensor[tensor_idx + 15*dim3],\n            tensor[tensor_idx + 16*dim3],\n            tensor[tensor_idx + 17*dim3],\n            tensor[tensor_idx + 18*dim3],\n            tensor[tensor_idx + 19*dim3],\n            tensor[tensor_idx + 20*dim3],\n            tensor[tensor_idx + 21*dim3],\n            tensor[tensor_idx + 22*dim3],\n            tensor[tensor_idx + 23*dim3],\n            tensor[tensor_idx + 24*dim3],\n            tensor[tensor_idx + 25*dim3],\n            tensor[tensor_idx + 26*dim3],\n            tensor[tensor_idx + 27*dim3],\n            tensor[tensor_idx + 28*dim3],\n            tensor[tensor_idx + 29*dim3],\n            tensor[tensor_idx + 30*dim3],\n            tensor[tensor_idx + 31*dim3]\n        );\n        \n        _mm256_storeu_si256((__m256i*)(slice + i), v);\n    }\n\n    // Handle remaining elements\n    for (; i < slice_size; i++) {\n        size_t row = i / dim2;\n        size_t col = i % dim2;\n        size_t tensor_idx = row * tensor_plane_size + col * dim3 + slice_idx;\n        slice[i] = tensor[tensor_idx];\n    }\n}\n```"}
{"task_id": "SimdBench_5_AVX", "completion": "```cpp\nvoid extract_tensor_slice_simd(const uint8_t *tensor, uint8_t *slice, size_t dim1, size_t dim2, size_t dim3, size_t slice_idx) {\n    const size_t slice_size = dim1 * dim2;\n    const size_t tensor_slice_offset = slice_idx * slice_size;\n    const size_t tensor_plane_size = dim2 * dim3;\n    \n    size_t i = 0;\n    for (; i + 32 <= slice_size; i += 32) {\n        size_t tensor_idx = 0;\n        size_t row = (i + tensor_slice_offset) / tensor_plane_size;\n        size_t offset = (i + tensor_slice_offset) % tensor_plane_size;\n        tensor_idx = row * tensor_plane_size + offset;\n        \n        __m256i v = _mm256_loadu_si256((__m256i*)(tensor + tensor_idx));\n        _mm256_storeu_si256((__m256i*)(slice + i), v);\n    }\n\n    // Handle remaining elements\n    for (; i < slice_size; i++) {\n        size_t tensor_idx = 0;\n        size_t row = (i + tensor_slice_offset) / tensor_plane_size;\n        size_t offset = (i + tensor_slice_offset) % tensor_plane_size;\n        tensor_idx = row * tensor_plane_size + offset;\n        slice[i] = tensor[tensor_idx];\n    }\n}\n```"}
{"task_id": "SimdBench_5_AVX", "completion": "```cpp\nvoid extract_tensor_slice_simd(const uint8_t *tensor, uint8_t *slice, size_t dim1, size_t dim2, size_t dim3, size_t slice_idx) {\n    const size_t slice_size = dim1 * dim2;\n    const size_t tensor_slice_offset = slice_idx * slice_size;\n    const size_t tensor_plane_size = dim2 * dim3;\n    \n    size_t i = 0;\n    for (; i + 32 <= slice_size; i += 32) {\n        size_t tensor_idx = 0;\n        __m256i slice_vec = _mm256_setzero_si256();\n        \n        // Calculate source index in tensor\n        size_t row = i / dim2;\n        size_t col = i % dim2;\n        tensor_idx = row * tensor_plane_size + col * dim3 + slice_idx;\n        \n        // Load and store 32 bytes at a time\n        slice_vec = _mm256_i32gather_epi32((const int*)&tensor[tensor_idx], \n                                          _mm256_set_epi32(7*dim3, 6*dim3, 5*dim3, 4*dim3,\n                                                         3*dim3, 2*dim3, dim3, 0),\n                                          1);\n        \n        _mm256_storeu_si256((__m256i*)&slice[i], slice_vec);\n    }\n    \n    // Handle remaining elements\n    for (; i < slice_size; i++) {\n        size_t row = i / dim2;\n        size_t col = i % dim2;\n        size_t tensor_idx = row * tensor_plane_size + col * dim3 + slice_idx;\n        slice[i] = tensor[tensor_idx];\n    }\n}\n```"}
{"task_id": "SimdBench_5_AVX", "completion": "```cpp\nvoid extract_tensor_slice_simd(const uint8_t *tensor, uint8_t *slice, size_t dim1, size_t dim2, size_t dim3, size_t slice_idx) {\n    const size_t slice_size = dim1 * dim2;\n    const size_t tensor_slice_stride = dim1 * dim2 * dim3;\n    const uint8_t *src = tensor + (slice_idx * dim1 * dim2);\n    \n    size_t i = 0;\n    // Process 32 elements at a time using AVX2\n    for (; i + 32 <= slice_size; i += 32) {\n        __m256i data = _mm256_loadu_si256((__m256i*)(src + i));\n        _mm256_storeu_si256((__m256i*)(slice + i), data);\n    }\n    \n    // Process 16 elements at a time\n    for (; i + 16 <= slice_size; i += 16) {\n        __m128i data = _mm_loadu_si128((__m128i*)(src + i));\n        _mm_storeu_si128((__m128i*)(slice + i), data);\n    }\n    \n    // Handle remaining elements\n    for (; i < slice_size; i++) {\n        slice[i] = src[i];\n    }\n}\n```"}
{"task_id": "SimdBench_5_AVX", "completion": "```cpp\nvoid extract_tensor_slice_simd(const uint8_t *tensor, uint8_t *slice, size_t dim1, size_t dim2, size_t dim3, size_t slice_idx) {\n    const size_t slice_size = dim1 * dim2;\n    const size_t tensor_slice_offset = slice_idx * slice_size;\n    const size_t tensor_plane_size = dim2 * dim3;\n    \n    size_t i = 0;\n    for (; i + 32 <= slice_size; i += 32) {\n        size_t tensor_idx = 0;\n        size_t row = (i + tensor_slice_offset) / tensor_plane_size;\n        size_t col = (i + tensor_slice_offset) % tensor_plane_size;\n        tensor_idx = row * tensor_plane_size + col;\n        \n        __m256i v = _mm256_loadu_si256((__m256i*)(tensor + tensor_idx));\n        _mm256_storeu_si256((__m256i*)(slice + i), v);\n    }\n\n    // Handle remaining elements\n    for (; i < slice_size; i++) {\n        size_t tensor_idx = 0;\n        size_t row = (i + tensor_slice_offset) / tensor_plane_size;\n        size_t col = (i + tensor_slice_offset) % tensor_plane_size;\n        tensor_idx = row * tensor_plane_size + col;\n        slice[i] = tensor[tensor_idx];\n    }\n}\n```"}
{"task_id": "SimdBench_6_AVX", "completion": "```cpp\nvoid blocked_matrix_transpose_simd(const int16_t *src, int16_t *dst, size_t rows, size_t cols, size_t block_size) {\n    for (size_t i = 0; i < rows; i += block_size) {\n        for (size_t j = 0; j < cols; j += block_size) {\n            size_t max_i = (i + block_size < rows) ? i + block_size : rows;\n            size_t max_j = (j + block_size < cols) ? j + block_size : cols;\n\n            for (size_t bi = i; bi < max_i; bi += 8) {\n                for (size_t bj = j; bj < max_j; bj += 8) {\n                    if (bi + 8 <= max_i && bj + 8 <= max_j) {\n                        __m128i r0 = _mm_loadu_si128((__m128i*)(src + bi * cols + bj));\n                        __m128i r1 = _mm_loadu_si128((__m128i*)(src + (bi + 1) * cols + bj));\n                        __m128i r2 = _mm_loadu_si128((__m128i*)(src + (bi + 2) * cols + bj));\n                        __m128i r3 = _mm_loadu_si128((__m128i*)(src + (bi + 3) * cols + bj));\n                        __m128i r4 = _mm_loadu_si128((__m128i*)(src + (bi + 4) * cols + bj));\n                        __m128i r5 = _mm_loadu_si128((__m128i*)(src + (bi + 5) * cols + bj));\n                        __m128i r6 = _mm_loadu_si128((__m128i*)(src + (bi + 6) * cols + bj));\n                        __m128i r7 = _mm_loadu_si128((__m128i*)(src + (bi + 7) * cols + bj));\n\n                        __m128i t0 = _mm_unpacklo_epi16(r0, r1);\n                        __m128i t1 = _mm_unpackhi_epi16(r0, r1);\n                        __m128i t2 = _mm_unpacklo_epi16(r2, r3);\n                        __m128i t3 = _mm_unpackhi_epi16(r2, r3);\n                        __m128i t4 = _mm_unpacklo_epi16(r4, r5);\n                        __m128i t5 = _mm_unpackhi_epi16(r4, r5);\n                        __m128i t6 = _mm_unpacklo_epi16(r6, r7);\n                        __m128i t7 = _mm_unpackhi_epi16(r6, r7);\n\n                        __m128i tt0 = _mm_unpacklo_epi32(t0, t2);\n                        __m128i tt1 = _mm_unpackhi_epi32(t0, t2);\n                        __m128i tt2 = _mm_unpacklo_epi32(t1, t3);\n                        __m128i tt3 = _mm_unpackhi_epi32(t1, t3);\n                        __m128i tt4 = _mm_unpacklo_epi32(t4, t6);\n                        __m128i tt5 = _mm_unpackhi_epi32(t4, t6);\n                        __m128i tt6 = _mm_unpacklo_epi32(t5, t7);\n                        __m128i tt7 = _mm_unpackhi_epi32(t5, t7);\n\n                        r0 = _mm_unpacklo_epi64(tt0, tt4);\n                        r1 = _mm_unpackhi_epi64(tt0, tt4);\n                        r2 = _mm_unpacklo_epi64(tt1, tt5);\n                        r3 = _mm_unpackhi_epi64(tt1, tt5);\n                        r4 = _mm_unpacklo_epi64(tt2, tt6);\n                        r5 = _mm_unpackhi_epi64(tt2, tt6);\n                        r6 = _mm_unpacklo_epi64(tt3, tt7);\n                        r7 = _mm_unpackhi_epi64(tt3, tt7);\n\n                        _mm_storeu_si128((__m128i*)(dst + bj * rows + bi), r0);\n                        _mm_storeu_si128((__m128i*)(dst + (bj + 1) * rows + bi), r1);\n                        _mm_storeu_si128((__m128i*)(dst + (bj + 2) * rows + bi), r2);\n                        _mm_storeu_si128((__m128i*)(dst + (bj + 3) * rows + bi), r3);\n                        _mm_storeu_si128((__m128i*)(dst + (bj + 4) * rows + bi), r4);\n                        _mm_storeu_si128((__m128i*)(dst + (bj + 5) * rows + bi), r5);\n                        _mm_storeu_si128((__m128i*)(dst + (bj + 6) * rows + bi), r6);\n                        _mm_storeu_si128((__m128i*)(dst + (bj + 7) * rows + bi), r7);\n                    } else {\n                        for (size_t ii = bi; ii < max_i; ii++) {\n                            for (size_t jj = bj; jj < max_j; jj++) {\n                                dst[jj * rows + ii] = src[ii * cols + jj];\n                            }\n                        }\n                    }\n                }\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_6_AVX", "completion": "```cpp\nvoid blocked_matrix_transpose_simd(const int16_t *src, int16_t *dst, size_t rows, size_t cols, size_t block_size) {\n    for (size_t i = 0; i < rows; i += block_size) {\n        for (size_t j = 0; j < cols; j += block_size) {\n            size_t max_i = (i + block_size < rows) ? i + block_size : rows;\n            size_t max_j = (j + block_size < cols) ? j + block_size : cols;\n\n            for (size_t bi = i; bi < max_i; bi += 8) {\n                for (size_t bj = j; bj < max_j; bj += 8) {\n                    if (bi + 8 <= max_i && bj + 8 <= max_j) {\n                        __m128i r0 = _mm_loadu_si128((__m128i*)&src[bi * cols + bj]);\n                        __m128i r1 = _mm_loadu_si128((__m128i*)&src[(bi + 1) * cols + bj]);\n                        __m128i r2 = _mm_loadu_si128((__m128i*)&src[(bi + 2) * cols + bj]);\n                        __m128i r3 = _mm_loadu_si128((__m128i*)&src[(bi + 3) * cols + bj]);\n                        __m128i r4 = _mm_loadu_si128((__m128i*)&src[(bi + 4) * cols + bj]);\n                        __m128i r5 = _mm_loadu_si128((__m128i*)&src[(bi + 5) * cols + bj]);\n                        __m128i r6 = _mm_loadu_si128((__m128i*)&src[(bi + 6) * cols + bj]);\n                        __m128i r7 = _mm_loadu_si128((__m128i*)&src[(bi + 7) * cols + bj]);\n\n                        __m128i t0 = _mm_unpacklo_epi16(r0, r1);\n                        __m128i t1 = _mm_unpackhi_epi16(r0, r1);\n                        __m128i t2 = _mm_unpacklo_epi16(r2, r3);\n                        __m128i t3 = _mm_unpackhi_epi16(r2, r3);\n                        __m128i t4 = _mm_unpacklo_epi16(r4, r5);\n                        __m128i t5 = _mm_unpackhi_epi16(r4, r5);\n                        __m128i t6 = _mm_unpacklo_epi16(r6, r7);\n                        __m128i t7 = _mm_unpackhi_epi16(r6, r7);\n\n                        __m128i tt0 = _mm_unpacklo_epi32(t0, t2);\n                        __m128i tt1 = _mm_unpackhi_epi32(t0, t2);\n                        __m128i tt2 = _mm_unpacklo_epi32(t1, t3);\n                        __m128i tt3 = _mm_unpackhi_epi32(t1, t3);\n                        __m128i tt4 = _mm_unpacklo_epi32(t4, t6);\n                        __m128i tt5 = _mm_unpackhi_epi32(t4, t6);\n                        __m128i tt6 = _mm_unpacklo_epi32(t5, t7);\n                        __m128i tt7 = _mm_unpackhi_epi32(t5, t7);\n\n                        r0 = _mm_unpacklo_epi64(tt0, tt4);\n                        r1 = _mm_unpackhi_epi64(tt0, tt4);\n                        r2 = _mm_unpacklo_epi64(tt1, tt5);\n                        r3 = _mm_unpackhi_epi64(tt1, tt5);\n                        r4 = _mm_unpacklo_epi64(tt2, tt6);\n                        r5 = _mm_unpackhi_epi64(tt2, tt6);\n                        r6 = _mm_unpacklo_epi64(tt3, tt7);\n                        r7 = _mm_unpackhi_epi64(tt3, tt7);\n\n                        _mm_storeu_si128((__m128i*)&dst[bj * rows + bi], r0);\n                        _mm_storeu_si128((__m128i*)&dst[(bj + 1) * rows + bi], r1);\n                        _mm_storeu_si128((__m128i*)&dst[(bj + 2) * rows + bi], r2);\n                        _mm_storeu_si128((__m128i*)&dst[(bj + 3) * rows + bi], r3);\n                        _mm_storeu_si128((__m128i*)&dst[(bj + 4) * rows + bi], r4);\n                        _mm_storeu_si128((__m128i*)&dst[(bj + 5) * rows + bi], r5);\n                        _mm_storeu_si128((__m128i*)&dst[(bj + 6) * rows + bi], r6);\n                        _mm_storeu_si128((__m128i*)&dst[(bj + 7) * rows + bi], r7);\n                    } else {\n                        for (size_t ii = bi; ii < max_i; ii++) {\n                            for (size_t jj = bj; jj < max_j; jj++) {\n                                dst[jj * rows + ii] = src[ii * cols + jj];\n                            }\n                        }\n                    }\n                }\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_6_AVX", "completion": "```cpp\nvoid blocked_matrix_transpose_simd(const int16_t *src, int16_t *dst, size_t rows, size_t cols, size_t block_size) {\n    for (size_t i = 0; i < rows; i += block_size) {\n        for (size_t j = 0; j < cols; j += block_size) {\n            size_t max_i = (i + block_size < rows) ? i + block_size : rows;\n            size_t max_j = (j + block_size < cols) ? j + block_size : cols;\n\n            for (size_t bi = i; bi < max_i; bi += 8) {\n                for (size_t bj = j; bj < max_j; bj += 8) {\n                    if (bi + 8 <= max_i && bj + 8 <= max_j) {\n                        __m128i r0 = _mm_loadu_si128((__m128i*)&src[bi * cols + bj]);\n                        __m128i r1 = _mm_loadu_si128((__m128i*)&src[(bi + 1) * cols + bj]);\n                        __m128i r2 = _mm_loadu_si128((__m128i*)&src[(bi + 2) * cols + bj]);\n                        __m128i r3 = _mm_loadu_si128((__m128i*)&src[(bi + 3) * cols + bj]);\n                        __m128i r4 = _mm_loadu_si128((__m128i*)&src[(bi + 4) * cols + bj]);\n                        __m128i r5 = _mm_loadu_si128((__m128i*)&src[(bi + 5) * cols + bj]);\n                        __m128i r6 = _mm_loadu_si128((__m128i*)&src[(bi + 6) * cols + bj]);\n                        __m128i r7 = _mm_loadu_si128((__m128i*)&src[(bi + 7) * cols + bj]);\n\n                        __m128i t0 = _mm_unpacklo_epi16(r0, r1);\n                        __m128i t1 = _mm_unpackhi_epi16(r0, r1);\n                        __m128i t2 = _mm_unpacklo_epi16(r2, r3);\n                        __m128i t3 = _mm_unpackhi_epi16(r2, r3);\n                        __m128i t4 = _mm_unpacklo_epi16(r4, r5);\n                        __m128i t5 = _mm_unpackhi_epi16(r4, r5);\n                        __m128i t6 = _mm_unpacklo_epi16(r6, r7);\n                        __m128i t7 = _mm_unpackhi_epi16(r6, r7);\n\n                        __m128i tt0 = _mm_unpacklo_epi32(t0, t2);\n                        __m128i tt1 = _mm_unpackhi_epi32(t0, t2);\n                        __m128i tt2 = _mm_unpacklo_epi32(t1, t3);\n                        __m128i tt3 = _mm_unpackhi_epi32(t1, t3);\n                        __m128i tt4 = _mm_unpacklo_epi32(t4, t6);\n                        __m128i tt5 = _mm_unpackhi_epi32(t4, t6);\n                        __m128i tt6 = _mm_unpacklo_epi32(t5, t7);\n                        __m128i tt7 = _mm_unpackhi_epi32(t5, t7);\n\n                        r0 = _mm_unpacklo_epi64(tt0, tt4);\n                        r1 = _mm_unpackhi_epi64(tt0, tt4);\n                        r2 = _mm_unpacklo_epi64(tt1, tt5);\n                        r3 = _mm_unpackhi_epi64(tt1, tt5);\n                        r4 = _mm_unpacklo_epi64(tt2, tt6);\n                        r5 = _mm_unpackhi_epi64(tt2, tt6);\n                        r6 = _mm_unpacklo_epi64(tt3, tt7);\n                        r7 = _mm_unpackhi_epi64(tt3, tt7);\n\n                        _mm_storeu_si128((__m128i*)&dst[bj * rows + bi], r0);\n                        _mm_storeu_si128((__m128i*)&dst[(bj + 1) * rows + bi], r1);\n                        _mm_storeu_si128((__m128i*)&dst[(bj + 2) * rows + bi], r2);\n                        _mm_storeu_si128((__m128i*)&dst[(bj + 3) * rows + bi], r3);\n                        _mm_storeu_si128((__m128i*)&dst[(bj + 4) * rows + bi], r4);\n                        _mm_storeu_si128((__m128i*)&dst[(bj + 5) * rows + bi], r5);\n                        _mm_storeu_si128((__m128i*)&dst[(bj + 6) * rows + bi], r6);\n                        _mm_storeu_si128((__m128i*)&dst[(bj + 7) * rows + bi], r7);\n                    } else {\n                        for (size_t ii = bi; ii < max_i; ii++) {\n                            for (size_t jj = bj; jj < max_j; jj++) {\n                                dst[jj * rows + ii] = src[ii * cols + jj];\n                            }\n                        }\n                    }\n                }\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_6_AVX", "completion": "```cpp\nvoid blocked_matrix_transpose_simd(const int16_t *src, int16_t *dst, size_t rows, size_t cols, size_t block_size) {\n    for (size_t i = 0; i < rows; i += block_size) {\n        for (size_t j = 0; j < cols; j += block_size) {\n            size_t max_i = (i + block_size < rows) ? i + block_size : rows;\n            size_t max_j = (j + block_size < cols) ? j + block_size : cols;\n\n            for (size_t bi = i; bi < max_i; bi += 8) {\n                for (size_t bj = j; bj < max_j; bj += 8) {\n                    if (bi + 8 <= max_i && bj + 8 <= max_j) {\n                        __m128i r0 = _mm_loadu_si128((__m128i*)&src[bi * cols + bj]);\n                        __m128i r1 = _mm_loadu_si128((__m128i*)&src[(bi + 1) * cols + bj]);\n                        __m128i r2 = _mm_loadu_si128((__m128i*)&src[(bi + 2) * cols + bj]);\n                        __m128i r3 = _mm_loadu_si128((__m128i*)&src[(bi + 3) * cols + bj]);\n                        __m128i r4 = _mm_loadu_si128((__m128i*)&src[(bi + 4) * cols + bj]);\n                        __m128i r5 = _mm_loadu_si128((__m128i*)&src[(bi + 5) * cols + bj]);\n                        __m128i r6 = _mm_loadu_si128((__m128i*)&src[(bi + 6) * cols + bj]);\n                        __m128i r7 = _mm_loadu_si128((__m128i*)&src[(bi + 7) * cols + bj]);\n\n                        __m128i t0 = _mm_unpacklo_epi16(r0, r1);\n                        __m128i t1 = _mm_unpackhi_epi16(r0, r1);\n                        __m128i t2 = _mm_unpacklo_epi16(r2, r3);\n                        __m128i t3 = _mm_unpackhi_epi16(r2, r3);\n                        __m128i t4 = _mm_unpacklo_epi16(r4, r5);\n                        __m128i t5 = _mm_unpackhi_epi16(r4, r5);\n                        __m128i t6 = _mm_unpacklo_epi16(r6, r7);\n                        __m128i t7 = _mm_unpackhi_epi16(r6, r7);\n\n                        __m128i tt0 = _mm_unpacklo_epi32(t0, t2);\n                        __m128i tt1 = _mm_unpackhi_epi32(t0, t2);\n                        __m128i tt2 = _mm_unpacklo_epi32(t1, t3);\n                        __m128i tt3 = _mm_unpackhi_epi32(t1, t3);\n                        __m128i tt4 = _mm_unpacklo_epi32(t4, t6);\n                        __m128i tt5 = _mm_unpackhi_epi32(t4, t6);\n                        __m128i tt6 = _mm_unpacklo_epi32(t5, t7);\n                        __m128i tt7 = _mm_unpackhi_epi32(t5, t7);\n\n                        r0 = _mm_unpacklo_epi64(tt0, tt4);\n                        r1 = _mm_unpackhi_epi64(tt0, tt4);\n                        r2 = _mm_unpacklo_epi64(tt1, tt5);\n                        r3 = _mm_unpackhi_epi64(tt1, tt5);\n                        r4 = _mm_unpacklo_epi64(tt2, tt6);\n                        r5 = _mm_unpackhi_epi64(tt2, tt6);\n                        r6 = _mm_unpacklo_epi64(tt3, tt7);\n                        r7 = _mm_unpackhi_epi64(tt3, tt7);\n\n                        _mm_storeu_si128((__m128i*)&dst[bj * rows + bi], r0);\n                        _mm_storeu_si128((__m128i*)&dst[(bj + 1) * rows + bi], r1);\n                        _mm_storeu_si128((__m128i*)&dst[(bj + 2) * rows + bi], r2);\n                        _mm_storeu_si128((__m128i*)&dst[(bj + 3) * rows + bi], r3);\n                        _mm_storeu_si128((__m128i*)&dst[(bj + 4) * rows + bi], r4);\n                        _mm_storeu_si128((__m128i*)&dst[(bj + 5) * rows + bi], r5);\n                        _mm_storeu_si128((__m128i*)&dst[(bj + 6) * rows + bi], r6);\n                        _mm_storeu_si128((__m128i*)&dst[(bj + 7) * rows + bi], r7);\n                    } else {\n                        for (size_t ii = bi; ii < max_i; ii++) {\n                            for (size_t jj = bj; jj < max_j; jj++) {\n                                dst[jj * rows + ii] = src[ii * cols + jj];\n                            }\n                        }\n                    }\n                }\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_6_AVX", "completion": "```cpp\nvoid blocked_matrix_transpose_simd(const int16_t *src, int16_t *dst, size_t rows, size_t cols, size_t block_size) {\n    for (size_t i = 0; i < rows; i += block_size) {\n        for (size_t j = 0; j < cols; j += block_size) {\n            size_t max_i = (i + block_size < rows) ? i + block_size : rows;\n            size_t max_j = (j + block_size < cols) ? j + block_size : cols;\n\n            for (size_t bi = i; bi < max_i; bi += 8) {\n                for (size_t bj = j; bj < max_j; bj += 8) {\n                    if (bi + 8 <= max_i && bj + 8 <= max_j) {\n                        __m128i r0 = _mm_loadu_si128((__m128i*)&src[bi * cols + bj]);\n                        __m128i r1 = _mm_loadu_si128((__m128i*)&src[(bi + 1) * cols + bj]);\n                        __m128i r2 = _mm_loadu_si128((__m128i*)&src[(bi + 2) * cols + bj]);\n                        __m128i r3 = _mm_loadu_si128((__m128i*)&src[(bi + 3) * cols + bj]);\n                        __m128i r4 = _mm_loadu_si128((__m128i*)&src[(bi + 4) * cols + bj]);\n                        __m128i r5 = _mm_loadu_si128((__m128i*)&src[(bi + 5) * cols + bj]);\n                        __m128i r6 = _mm_loadu_si128((__m128i*)&src[(bi + 6) * cols + bj]);\n                        __m128i r7 = _mm_loadu_si128((__m128i*)&src[(bi + 7) * cols + bj]);\n\n                        __m128i t0 = _mm_unpacklo_epi16(r0, r1);\n                        __m128i t1 = _mm_unpackhi_epi16(r0, r1);\n                        __m128i t2 = _mm_unpacklo_epi16(r2, r3);\n                        __m128i t3 = _mm_unpackhi_epi16(r2, r3);\n                        __m128i t4 = _mm_unpacklo_epi16(r4, r5);\n                        __m128i t5 = _mm_unpackhi_epi16(r4, r5);\n                        __m128i t6 = _mm_unpacklo_epi16(r6, r7);\n                        __m128i t7 = _mm_unpackhi_epi16(r6, r7);\n\n                        __m128i tt0 = _mm_unpacklo_epi32(t0, t2);\n                        __m128i tt1 = _mm_unpackhi_epi32(t0, t2);\n                        __m128i tt2 = _mm_unpacklo_epi32(t1, t3);\n                        __m128i tt3 = _mm_unpackhi_epi32(t1, t3);\n                        __m128i tt4 = _mm_unpacklo_epi32(t4, t6);\n                        __m128i tt5 = _mm_unpackhi_epi32(t4, t6);\n                        __m128i tt6 = _mm_unpacklo_epi32(t5, t7);\n                        __m128i tt7 = _mm_unpackhi_epi32(t5, t7);\n\n                        r0 = _mm_unpacklo_epi64(tt0, tt4);\n                        r1 = _mm_unpackhi_epi64(tt0, tt4);\n                        r2 = _mm_unpacklo_epi64(tt1, tt5);\n                        r3 = _mm_unpackhi_epi64(tt1, tt5);\n                        r4 = _mm_unpacklo_epi64(tt2, tt6);\n                        r5 = _mm_unpackhi_epi64(tt2, tt6);\n                        r6 = _mm_unpacklo_epi64(tt3, tt7);\n                        r7 = _mm_unpackhi_epi64(tt3, tt7);\n\n                        _mm_storeu_si128((__m128i*)&dst[bj * rows + bi], r0);\n                        _mm_storeu_si128((__m128i*)&dst[(bj + 1) * rows + bi], r1);\n                        _mm_storeu_si128((__m128i*)&dst[(bj + 2) * rows + bi], r2);\n                        _mm_storeu_si128((__m128i*)&dst[(bj + 3) * rows + bi], r3);\n                        _mm_storeu_si128((__m128i*)&dst[(bj + 4) * rows + bi], r4);\n                        _mm_storeu_si128((__m128i*)&dst[(bj + 5) * rows + bi], r5);\n                        _mm_storeu_si128((__m128i*)&dst[(bj + 6) * rows + bi], r6);\n                        _mm_storeu_si128((__m128i*)&dst[(bj + 7) * rows + bi], r7);\n                    } else {\n                        for (size_t ii = bi; ii < max_i; ii++) {\n                            for (size_t jj = bj; jj < max_j; jj++) {\n                                dst[jj * rows + ii] = src[ii * cols + jj];\n                            }\n                        }\n                    }\n                }\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_7_AVX", "completion": "```cpp\nfloat diagonal_sum_3d_simd(const float *array, size_t dim) {\n    float sum = 0.0f;\n    __m256 sum_vec = _mm256_setzero_ps();\n    \n    size_t i = 0;\n    size_t diag_stride = dim * dim + dim + 1;\n    size_t vec_size = 8;\n    size_t vec_iters = dim / vec_size;\n    size_t remainder = dim % vec_size;\n\n    for (; i < vec_iters * vec_size; i += vec_size) {\n        size_t idx = i * diag_stride;\n        __m256 elements = _mm256_setr_ps(\n            array[idx],\n            array[idx + diag_stride],\n            array[idx + 2 * diag_stride],\n            array[idx + 3 * diag_stride],\n            array[idx + 4 * diag_stride],\n            array[idx + 5 * diag_stride],\n            array[idx + 6 * diag_stride],\n            array[idx + 7 * diag_stride]\n        );\n        sum_vec = _mm256_add_ps(sum_vec, elements);\n    }\n\n    float temp[8] __attribute__((aligned(32)));\n    _mm256_store_ps(temp, sum_vec);\n    \n    for (size_t j = 0; j < 8; j++) {\n        sum += temp[j];\n    }\n\n    for (; i < dim; i++) {\n        sum += array[i * diag_stride];\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_7_AVX", "completion": "```cpp\nfloat diagonal_sum_3d_simd(const float *array, size_t dim) {\n    float sum = 0.0f;\n    size_t dim_sq = dim * dim;\n    size_t elements = dim;\n    size_t i = 0;\n\n    __m256 sum_vec = _mm256_setzero_ps();\n    \n    for (; i + 8 <= elements; i += 8) {\n        size_t idx0 = i * dim_sq + i * dim + i;\n        size_t idx1 = (i+1) * dim_sq + (i+1) * dim + (i+1);\n        size_t idx2 = (i+2) * dim_sq + (i+2) * dim + (i+2);\n        size_t idx3 = (i+3) * dim_sq + (i+3) * dim + (i+3);\n        size_t idx4 = (i+4) * dim_sq + (i+4) * dim + (i+4);\n        size_t idx5 = (i+5) * dim_sq + (i+5) * dim + (i+5);\n        size_t idx6 = (i+6) * dim_sq + (i+6) * dim + (i+6);\n        size_t idx7 = (i+7) * dim_sq + (i+7) * dim + (i+7);\n        \n        __m256 values = _mm256_set_ps(array[idx7], array[idx6], array[idx5], array[idx4],\n                                     array[idx3], array[idx2], array[idx1], array[idx0]);\n        sum_vec = _mm256_add_ps(sum_vec, values);\n    }\n\n    float temp[8] __attribute__((aligned(32)));\n    _mm256_store_ps(temp, sum_vec);\n    sum = temp[0] + temp[1] + temp[2] + temp[3] + temp[4] + temp[5] + temp[6] + temp[7];\n\n    for (; i < elements; i++) {\n        size_t idx = i * dim_sq + i * dim + i;\n        sum += array[idx];\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_7_AVX", "completion": "```cpp\nfloat diagonal_sum_3d_simd(const float *array, size_t dim) {\n    float sum = 0.0f;\n    __m256 sum_vec = _mm256_setzero_ps();\n    \n    size_t i = 0;\n    size_t diag_stride = dim * dim + dim + 1;\n    size_t vec_size = 8;\n    size_t vec_iters = dim / vec_size;\n    size_t remainder = dim % vec_size;\n\n    // Process 8 diagonal elements at a time\n    for (; i < vec_iters * vec_size; i += vec_size) {\n        __m256 diag = _mm256_set_ps(\n            array[(i+7)*diag_stride],\n            array[(i+6)*diag_stride],\n            array[(i+5)*diag_stride], \n            array[(i+4)*diag_stride],\n            array[(i+3)*diag_stride],\n            array[(i+2)*diag_stride],\n            array[(i+1)*diag_stride],\n            array[i*diag_stride]\n        );\n        sum_vec = _mm256_add_ps(sum_vec, diag);\n    }\n\n    // Horizontal sum of vector\n    float temp[8] __attribute__((aligned(32)));\n    _mm256_store_ps(temp, sum_vec);\n    sum = temp[0] + temp[1] + temp[2] + temp[3] + \n          temp[4] + temp[5] + temp[6] + temp[7];\n\n    // Handle remaining elements\n    for (; i < dim; i++) {\n        sum += array[i * diag_stride];\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_7_AVX", "completion": "```cpp\nfloat diagonal_sum_3d_simd(const float *array, size_t dim) {\n    __m256 sum = _mm256_setzero_ps();\n    size_t dim_sq = dim * dim;\n    size_t i = 0;\n    \n    // Process 8 diagonal elements at a time\n    for (; i + 7 < dim && i + 7 < dim_sq; i += 8) {\n        size_t idx0 = i + i * dim + i * dim_sq;\n        size_t idx1 = (i+1) + (i+1) * dim + (i+1) * dim_sq;\n        size_t idx2 = (i+2) + (i+2) * dim + (i+2) * dim_sq;\n        size_t idx3 = (i+3) + (i+3) * dim + (i+3) * dim_sq;\n        size_t idx4 = (i+4) + (i+4) * dim + (i+4) * dim_sq;\n        size_t idx5 = (i+5) + (i+5) * dim + (i+5) * dim_sq;\n        size_t idx6 = (i+6) + (i+6) * dim + (i+6) * dim_sq;\n        size_t idx7 = (i+7) + (i+7) * dim + (i+7) * dim_sq;\n        \n        __m256 diag = _mm256_set_ps(array[idx7], array[idx6], array[idx5], array[idx4],\n                                   array[idx3], array[idx2], array[idx1], array[idx0]);\n        sum = _mm256_add_ps(sum, diag);\n    }\n    \n    // Sum the elements in the vector\n    float result = 0.0f;\n    float temp[8];\n    _mm256_storeu_ps(temp, sum);\n    for(int j = 0; j < 8; j++) {\n        result += temp[j];\n    }\n    \n    // Handle remaining elements\n    for(; i < dim; i++) {\n        size_t idx = i + i * dim + i * dim_sq;\n        result += array[idx];\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_7_AVX", "completion": "```cpp\nfloat diagonal_sum_3d_simd(const float *array, size_t dim) {\n    float sum = 0.0f;\n    __m256 sum_vec = _mm256_setzero_ps();\n    \n    size_t dim_sq = dim * dim;\n    size_t i = 0;\n    \n    // Process 8 diagonal elements at a time\n    for (; i + 7 < dim; i += 8) {\n        size_t idx0 = i * dim_sq + i * dim + i;\n        size_t idx1 = (i+1) * dim_sq + (i+1) * dim + (i+1);\n        size_t idx2 = (i+2) * dim_sq + (i+2) * dim + (i+2);\n        size_t idx3 = (i+3) * dim_sq + (i+3) * dim + (i+3);\n        size_t idx4 = (i+4) * dim_sq + (i+4) * dim + (i+4);\n        size_t idx5 = (i+5) * dim_sq + (i+5) * dim + (i+5);\n        size_t idx6 = (i+6) * dim_sq + (i+6) * dim + (i+6);\n        size_t idx7 = (i+7) * dim_sq + (i+7) * dim + (i+7);\n        \n        __m256 diag = _mm256_set_ps(array[idx7], array[idx6], array[idx5], array[idx4],\n                                   array[idx3], array[idx2], array[idx1], array[idx0]);\n        sum_vec = _mm256_add_ps(sum_vec, diag);\n    }\n    \n    // Reduce vector sum to scalar\n    float temp[8] __attribute__((aligned(32)));\n    _mm256_store_ps(temp, sum_vec);\n    sum = temp[0] + temp[1] + temp[2] + temp[3] + \n          temp[4] + temp[5] + temp[6] + temp[7];\n    \n    // Handle remaining elements\n    for (; i < dim; i++) {\n        size_t idx = i * dim_sq + i * dim + i;\n        sum += array[idx];\n    }\n    \n    return sum;\n}\n```"}
{"task_id": "SimdBench_8_AVX", "completion": "```cpp\nvoid conditional_scale_simd(const double *src, double *dst, size_t rows, size_t cols, double threshold, double scale) {\n    const size_t total = rows * cols;\n    const size_t simd_width = 4;\n    const size_t simd_limit = total - (total % simd_width);\n    \n    __m256d threshold_vec = _mm256_set1_pd(threshold);\n    __m256d scale_vec = _mm256_set1_pd(scale);\n    \n    size_t i;\n    for (i = 0; i < simd_limit; i += simd_width) {\n        __m256d src_vec = _mm256_loadu_pd(&src[i]);\n        __m256d mask = _mm256_cmp_pd(src_vec, threshold_vec, _CMP_GT_OQ);\n        __m256d scaled = _mm256_mul_pd(src_vec, scale_vec);\n        __m256d result = _mm256_blendv_pd(src_vec, scaled, mask);\n        _mm256_storeu_pd(&dst[i], result);\n    }\n\n    for (; i < total; i++) {\n        dst[i] = src[i] > threshold ? src[i] * scale : src[i];\n    }\n}\n```"}
{"task_id": "SimdBench_8_AVX", "completion": "```cpp\nvoid conditional_scale_simd(const double *src, double *dst, size_t rows, size_t cols, double threshold, double scale) {\n    const size_t total = rows * cols;\n    const size_t simd_width = 4;\n    const size_t simd_limit = total - (total % simd_width);\n    \n    __m256d threshold_vec = _mm256_set1_pd(threshold);\n    __m256d scale_vec = _mm256_set1_pd(scale);\n    \n    size_t i;\n    for (i = 0; i < simd_limit; i += simd_width) {\n        __m256d src_vec = _mm256_loadu_pd(&src[i]);\n        __m256d mask = _mm256_cmp_pd(src_vec, threshold_vec, _CMP_GT_OQ);\n        __m256d scaled = _mm256_mul_pd(src_vec, scale_vec);\n        __m256d result = _mm256_blendv_pd(src_vec, scaled, mask);\n        _mm256_storeu_pd(&dst[i], result);\n    }\n\n    for (; i < total; i++) {\n        dst[i] = src[i] > threshold ? src[i] * scale : src[i];\n    }\n}\n```"}
{"task_id": "SimdBench_8_AVX", "completion": "```cpp\nvoid conditional_scale_simd(const double *src, double *dst, size_t rows, size_t cols, double threshold, double scale) {\n    const size_t total = rows * cols;\n    const size_t simd_width = 4;\n    const size_t simd_limit = total - (total % simd_width);\n    \n    __m256d threshold_vec = _mm256_set1_pd(threshold);\n    __m256d scale_vec = _mm256_set1_pd(scale);\n    \n    size_t i;\n    for (i = 0; i < simd_limit; i += simd_width) {\n        __m256d src_vec = _mm256_loadu_pd(&src[i]);\n        __m256d mask = _mm256_cmp_pd(src_vec, threshold_vec, _CMP_GT_OQ);\n        __m256d scaled = _mm256_mul_pd(src_vec, scale_vec);\n        __m256d result = _mm256_blendv_pd(src_vec, scaled, mask);\n        _mm256_storeu_pd(&dst[i], result);\n    }\n\n    for (; i < total; i++) {\n        dst[i] = src[i] > threshold ? src[i] * scale : src[i];\n    }\n}\n```"}
{"task_id": "SimdBench_8_AVX", "completion": "```cpp\nvoid conditional_scale_simd(const double *src, double *dst, size_t rows, size_t cols, double threshold, double scale) {\n    size_t total = rows * cols;\n    size_t aligned_size = total - (total % 4);\n    \n    __m256d threshold_vec = _mm256_set1_pd(threshold);\n    __m256d scale_vec = _mm256_set1_pd(scale);\n    \n    for (size_t i = 0; i < aligned_size; i += 4) {\n        __m256d src_vec = _mm256_loadu_pd(&src[i]);\n        __m256d mask = _mm256_cmp_pd(src_vec, threshold_vec, _CMP_GT_OQ);\n        __m256d scaled = _mm256_mul_pd(src_vec, scale_vec);\n        __m256d result = _mm256_blendv_pd(src_vec, scaled, mask);\n        _mm256_storeu_pd(&dst[i], result);\n    }\n\n    for (size_t i = aligned_size; i < total; i++) {\n        dst[i] = src[i] > threshold ? src[i] * scale : src[i];\n    }\n}\n```"}
{"task_id": "SimdBench_8_AVX", "completion": "```cpp\nvoid conditional_scale_simd(const double *src, double *dst, size_t rows, size_t cols, double threshold, double scale) {\n    const size_t total = rows * cols;\n    const size_t simd_width = 4;\n    const size_t simd_limit = total - (total % simd_width);\n    \n    __m256d threshold_vec = _mm256_set1_pd(threshold);\n    __m256d scale_vec = _mm256_set1_pd(scale);\n    \n    size_t i;\n    for (i = 0; i < simd_limit; i += simd_width) {\n        __m256d src_vec = _mm256_loadu_pd(&src[i]);\n        __m256d mask = _mm256_cmp_pd(src_vec, threshold_vec, _CMP_GT_OQ);\n        __m256d scaled = _mm256_mul_pd(src_vec, scale_vec);\n        __m256d result = _mm256_blendv_pd(src_vec, scaled, mask);\n        _mm256_storeu_pd(&dst[i], result);\n    }\n\n    for (; i < total; i++) {\n        dst[i] = src[i] > threshold ? src[i] * scale : src[i];\n    }\n}\n```"}
{"task_id": "SimdBench_9_AVX", "completion": "```cpp\nvoid reorder_matrix_rows_simd(const double *src, double *dst, size_t rows, size_t cols, const size_t *indices) {\n    const size_t vec_size = 4;\n    const size_t vec_cols = cols / vec_size;\n    const size_t remainder = cols % vec_size;\n\n    for (size_t i = 0; i < rows; i++) {\n        const size_t src_row = indices[i];\n        const double* src_ptr = src + src_row * cols;\n        double* dst_ptr = dst + i * cols;\n\n        // Process 4 elements at a time using AVX\n        for (size_t j = 0; j < vec_cols; j++) {\n            __m256d v = _mm256_loadu_pd(src_ptr + j * vec_size);\n            _mm256_storeu_pd(dst_ptr + j * vec_size, v);\n        }\n\n        // Handle remaining elements\n        for (size_t j = vec_cols * vec_size; j < cols; j++) {\n            dst_ptr[j] = src_ptr[j];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_9_AVX", "completion": "```cpp\nvoid reorder_matrix_rows_simd(const double *src, double *dst, size_t rows, size_t cols, const size_t *indices) {\n    const size_t vec_size = 4;\n    const size_t vec_cols = cols / vec_size;\n    const size_t rem_cols = cols % vec_size;\n\n    for (size_t i = 0; i < rows; i++) {\n        const size_t src_row = indices[i];\n        const double* src_ptr = src + src_row * cols;\n        double* dst_ptr = dst + i * cols;\n\n        // Process 4 elements at a time using AVX\n        for (size_t j = 0; j < vec_cols; j++) {\n            __m256d vec = _mm256_loadu_pd(src_ptr + j * vec_size);\n            _mm256_storeu_pd(dst_ptr + j * vec_size, vec);\n        }\n\n        // Handle remaining elements\n        for (size_t j = vec_cols * vec_size; j < cols; j++) {\n            dst_ptr[j] = src_ptr[j];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_9_AVX", "completion": "```cpp\nvoid reorder_matrix_rows_simd(const double *src, double *dst, size_t rows, size_t cols, const size_t *indices) {\n    const size_t vec_size = 4;\n    const size_t vec_cols = cols / vec_size;\n    const size_t rem_cols = cols % vec_size;\n\n    for (size_t i = 0; i < rows; i++) {\n        const size_t src_row = indices[i];\n        const double* src_ptr = src + src_row * cols;\n        double* dst_ptr = dst + i * cols;\n\n        // Process 4 elements at a time using AVX\n        for (size_t j = 0; j < vec_cols; j++) {\n            __m256d vec = _mm256_loadu_pd(src_ptr + j * vec_size);\n            _mm256_storeu_pd(dst_ptr + j * vec_size, vec);\n        }\n\n        // Handle remaining elements\n        for (size_t j = vec_cols * vec_size; j < cols; j++) {\n            dst_ptr[j] = src_ptr[j];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_9_AVX", "completion": "```cpp\nvoid reorder_matrix_rows_simd(const double *src, double *dst, size_t rows, size_t cols, const size_t *indices) {\n    const size_t vec_size = 4;\n    const size_t vec_cols = cols / vec_size;\n    const size_t rem_cols = cols % vec_size;\n\n    for (size_t i = 0; i < rows; i++) {\n        const size_t src_row = indices[i];\n        const double* src_ptr = src + src_row * cols;\n        double* dst_ptr = dst + i * cols;\n\n        // Process 4 elements at a time using AVX\n        for (size_t j = 0; j < vec_cols; j++) {\n            __m256d v = _mm256_loadu_pd(src_ptr + j * vec_size);\n            _mm256_storeu_pd(dst_ptr + j * vec_size, v);\n        }\n\n        // Handle remaining elements\n        for (size_t j = vec_cols * vec_size; j < cols; j++) {\n            dst_ptr[j] = src_ptr[j];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_9_AVX", "completion": "```cpp\nvoid reorder_matrix_rows_simd(const double *src, double *dst, size_t rows, size_t cols, const size_t *indices) {\n    const size_t vec_size = 4; // AVX 256-bit = 4 doubles\n    const size_t vec_cols = cols / vec_size;\n    const size_t rem_cols = cols % vec_size;\n\n    for (size_t i = 0; i < rows; i++) {\n        const size_t src_row = indices[i];\n        const double* src_ptr = src + src_row * cols;\n        double* dst_ptr = dst + i * cols;\n\n        // Process vectors of 4 doubles using AVX\n        for (size_t j = 0; j < vec_cols; j++) {\n            __m256d vec = _mm256_loadu_pd(src_ptr + j * vec_size);\n            _mm256_storeu_pd(dst_ptr + j * vec_size, vec);\n        }\n\n        // Handle remaining columns\n        for (size_t j = vec_cols * vec_size; j < cols; j++) {\n            dst_ptr[j] = src_ptr[j];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_10_AVX", "completion": "```cpp\nvoid vector_vector_add_simd(const int64_t *src1, const int64_t *src2, int64_t *dst, int64_t scalar, size_t length) {\n    size_t i;\n    __m256i scalar_vec = _mm256_set1_epi64x(scalar);\n    \n    for (i = 0; i + 4 <= length; i += 4) {\n        __m256i v1 = _mm256_loadu_si256((__m256i*)(src1 + i));\n        __m256i v2 = _mm256_loadu_si256((__m256i*)(src2 + i));\n        \n        __m256i sum = _mm256_add_epi64(v1, v2);\n        sum = _mm256_add_epi64(sum, scalar_vec);\n        \n        // Divide by 2 using right shift\n        sum = _mm256_srai_epi64(sum, 1);\n        \n        _mm256_storeu_si256((__m256i*)(dst + i), sum);\n    }\n    \n    // Handle remaining elements\n    for (; i < length; i++) {\n        dst[i] = (src1[i] + src2[i] + scalar) / 2;\n    }\n}\n```"}
{"task_id": "SimdBench_10_AVX", "completion": "```cpp\nvoid vector_vector_add_simd(const int64_t *src1, const int64_t *src2, int64_t *dst, int64_t scalar, size_t length) {\n    size_t i;\n    __m256i scalar_vec = _mm256_set1_epi64x(scalar);\n    \n    for (i = 0; i + 4 <= length; i += 4) {\n        __m256i v1 = _mm256_loadu_si256((__m256i*)(src1 + i));\n        __m256i v2 = _mm256_loadu_si256((__m256i*)(src2 + i));\n        \n        __m256i sum = _mm256_add_epi64(v1, v2);\n        sum = _mm256_add_epi64(sum, scalar_vec);\n        \n        // Divide by 2 (shift right by 1)\n        __m256i result = _mm256_srai_epi64(sum, 1);\n        \n        _mm256_storeu_si256((__m256i*)(dst + i), result);\n    }\n    \n    // Handle remaining elements\n    for (; i < length; i++) {\n        dst[i] = (src1[i] + src2[i] + scalar) / 2;\n    }\n}\n```"}
{"task_id": "SimdBench_10_AVX", "completion": "```cpp\nvoid vector_vector_add_simd(const int64_t *src1, const int64_t *src2, int64_t *dst, int64_t scalar, size_t length) {\n    size_t i;\n    __m256i scalar_vec = _mm256_set1_epi64x(scalar);\n    \n    for (i = 0; i + 4 <= length; i += 4) {\n        __m256i v1 = _mm256_loadu_si256((__m256i*)(src1 + i));\n        __m256i v2 = _mm256_loadu_si256((__m256i*)(src2 + i));\n        \n        __m256i sum = _mm256_add_epi64(v1, v2);\n        sum = _mm256_add_epi64(sum, scalar_vec);\n        \n        // Divide by 2 (shift right by 1)\n        __m256i result = _mm256_srai_epi64(sum, 1);\n        \n        _mm256_storeu_si256((__m256i*)(dst + i), result);\n    }\n    \n    // Handle remaining elements\n    for (; i < length; i++) {\n        dst[i] = (src1[i] + src2[i] + scalar) / 2;\n    }\n}\n```"}
{"task_id": "SimdBench_10_AVX", "completion": "```cpp\nvoid vector_vector_add_simd(const int64_t *src1, const int64_t *src2, int64_t *dst, int64_t scalar, size_t length) {\n    size_t i;\n    __m256i scalar_vec = _mm256_set1_epi64x(scalar);\n    \n    for (i = 0; i + 4 <= length; i += 4) {\n        __m256i v1 = _mm256_loadu_si256((__m256i*)(src1 + i));\n        __m256i v2 = _mm256_loadu_si256((__m256i*)(src2 + i));\n        \n        __m256i sum = _mm256_add_epi64(v1, v2);\n        sum = _mm256_add_epi64(sum, scalar_vec);\n        \n        // Divide by 2 using right shift\n        sum = _mm256_srai_epi64(sum, 1);\n        \n        _mm256_storeu_si256((__m256i*)(dst + i), sum);\n    }\n    \n    // Handle remaining elements\n    for (; i < length; i++) {\n        dst[i] = (src1[i] + src2[i] + scalar) / 2;\n    }\n}\n```"}
{"task_id": "SimdBench_10_AVX", "completion": "```cpp\nvoid vector_vector_add_simd(const int64_t *src1, const int64_t *src2, int64_t *dst, int64_t scalar, size_t length) {\n    size_t i;\n    __m256i scalar_vec = _mm256_set1_epi64x(scalar);\n    \n    for (i = 0; i + 4 <= length; i += 4) {\n        __m256i v1 = _mm256_loadu_si256((__m256i*)(src1 + i));\n        __m256i v2 = _mm256_loadu_si256((__m256i*)(src2 + i));\n        \n        __m256i sum = _mm256_add_epi64(v1, v2);\n        sum = _mm256_add_epi64(sum, scalar_vec);\n        \n        // Divide by 2 (shift right by 1)\n        __m256i result = _mm256_srai_epi64(sum, 1);\n        \n        _mm256_storeu_si256((__m256i*)(dst + i), result);\n    }\n    \n    // Handle remaining elements\n    for (; i < length; i++) {\n        dst[i] = (src1[i] + src2[i] + scalar) / 2;\n    }\n}\n```"}
{"task_id": "SimdBench_11_AVX", "completion": "```cpp\nint vector_even_min_simd(const int *src, size_t length) {\n    if (length == 0) return -1;\n    \n    __m256i min_vec = _mm256_set1_epi32(INT_MAX);\n    size_t i = 0;\n    \n    for (; i + 8 <= length; i += 8) {\n        __m256i curr = _mm256_loadu_si256((__m256i*)(src + i));\n        __m256i mask = _mm256_set_epi32(0, -1, 0, -1, 0, -1, 0, -1);\n        curr = _mm256_blendv_epi8(min_vec, curr, mask);\n        min_vec = _mm256_min_epi32(min_vec, curr);\n    }\n    \n    int min_val = INT_MAX;\n    int temp[8];\n    _mm256_storeu_si256((__m256i*)temp, min_vec);\n    \n    for (int j = 0; j < 8; j += 2) {\n        min_val = std::min(min_val, temp[j]);\n    }\n    \n    for (; i < length; i += 2) {\n        min_val = std::min(min_val, src[i]);\n    }\n    \n    return min_val;\n}\n```"}
{"task_id": "SimdBench_11_AVX", "completion": "```cpp\nint vector_even_min_simd(const int *src, size_t length) {\n    if (length == 0) return -1;\n    \n    __m256i min_vec = _mm256_set1_epi32(INT_MAX);\n    size_t i;\n    \n    for (i = 0; i + 8 <= length; i += 8) {\n        __m256i curr = _mm256_loadu_si256((__m256i*)(src + i));\n        __m256i mask = _mm256_set_epi32(0, -1, 0, -1, 0, -1, 0, -1);\n        curr = _mm256_and_si256(curr, mask);\n        curr = _mm256_or_si256(curr, _mm256_andnot_si256(mask, min_vec));\n        min_vec = _mm256_min_epi32(min_vec, curr);\n    }\n\n    int min_val = INT_MAX;\n    int temp[8];\n    _mm256_storeu_si256((__m256i*)temp, min_vec);\n    \n    for (int j = 0; j < 8; j += 2) {\n        min_val = std::min(min_val, temp[j]);\n    }\n    \n    for (; i < length; i += 2) {\n        min_val = std::min(min_val, src[i]);\n    }\n    \n    return min_val;\n}\n```"}
{"task_id": "SimdBench_11_AVX", "completion": "```cpp\nint vector_even_min_simd(const int *src, size_t length) {\n    if (length == 0) return -1;\n    \n    __m256i min_vec = _mm256_set1_epi32(INT_MAX);\n    size_t i = 0;\n    \n    for (; i + 8 <= length; i += 8) {\n        __m256i curr = _mm256_loadu_si256((__m256i*)(src + i));\n        __m256i mask = _mm256_set_epi32(0, -1, 0, -1, 0, -1, 0, -1);\n        curr = _mm256_blendv_epi8(min_vec, curr, mask);\n        min_vec = _mm256_min_epi32(min_vec, curr);\n    }\n    \n    int min_arr[8];\n    _mm256_storeu_si256((__m256i*)min_arr, min_vec);\n    \n    int min_val = INT_MAX;\n    for (int j = 0; j < 8; j += 2) {\n        min_val = std::min(min_val, min_arr[j]);\n    }\n    \n    for (; i < length; i += 2) {\n        min_val = std::min(min_val, src[i]);\n    }\n    \n    return min_val;\n}\n```"}
{"task_id": "SimdBench_11_AVX", "completion": "```cpp\nint vector_even_min_simd(const int *src, size_t length) {\n    if (length == 0) return -1;\n    \n    __m256i min_vec = _mm256_set1_epi32(INT_MAX);\n    size_t i;\n    \n    for (i = 0; i + 8 <= length; i += 8) {\n        __m256i curr = _mm256_loadu_si256((__m256i*)(src + i));\n        __m256i mask = _mm256_set_epi32(0, -1, 0, -1, 0, -1, 0, -1);\n        curr = _mm256_and_si256(curr, mask);\n        curr = _mm256_or_si256(curr, _mm256_andnot_si256(mask, min_vec));\n        min_vec = _mm256_min_epi32(min_vec, curr);\n    }\n\n    int min_arr[8];\n    _mm256_storeu_si256((__m256i*)min_arr, min_vec);\n    \n    int min_val = min_arr[0];\n    for (int j = 2; j < 8; j += 2) {\n        min_val = std::min(min_val, min_arr[j]);\n    }\n    \n    for (; i < length; i += 2) {\n        if (i + 1 < length) {\n            min_val = std::min(min_val, src[i]);\n        }\n    }\n    \n    return min_val;\n}\n```"}
{"task_id": "SimdBench_11_AVX", "completion": "```cpp\nint vector_even_min_simd(const int *src, size_t length) {\n    if (length == 0) return -1;\n    \n    __m256i min_vec = _mm256_set1_epi32(INT_MAX);\n    size_t i;\n    \n    for (i = 0; i + 8 <= length; i += 8) {\n        __m256i curr = _mm256_loadu_si256((__m256i*)(src + i));\n        __m256i mask = _mm256_set_epi32(0, -1, 0, -1, 0, -1, 0, -1);\n        curr = _mm256_blendv_epi8(min_vec, curr, mask);\n        min_vec = _mm256_min_epi32(min_vec, curr);\n    }\n\n    int min_val = INT_MAX;\n    int temp[8];\n    _mm256_storeu_si256((__m256i*)temp, min_vec);\n    \n    for (int j = 0; j < 8; j += 2) {\n        min_val = std::min(min_val, temp[j]);\n    }\n    \n    for (; i < length; i += 2) {\n        min_val = std::min(min_val, src[i]);\n    }\n    \n    return min_val;\n}\n```"}
{"task_id": "SimdBench_12_AVX", "completion": "```cpp\nvoid mixed_right_shift_simd(const int *src, int *dst, uint8_t shift, size_t length) {\n    size_t i;\n    const size_t simd_width = 8;\n    size_t simd_length = length - (length % simd_width);\n\n    for (i = 0; i < simd_length; i += simd_width) {\n        __m256i input = _mm256_loadu_si256((__m256i*)(src + i));\n        \n        // Arithmetic right shift\n        __m256i arith_shift = _mm256_srai_epi32(input, shift);\n        \n        // Logical right shift\n        __m256i logic_shift = _mm256_srli_epi32(input, shift);\n        \n        // Add results\n        __m256i result = _mm256_add_epi32(arith_shift, logic_shift);\n        \n        // Store result\n        _mm256_storeu_si256((__m256i*)(dst + i), result);\n    }\n\n    // Handle remaining elements\n    for (; i < length; i++) {\n        int arith_shift = src[i] >> shift;\n        int logic_shift = (unsigned int)src[i] >> shift;\n        dst[i] = arith_shift + logic_shift;\n    }\n}\n```"}
{"task_id": "SimdBench_12_AVX", "completion": "```cpp\nvoid mixed_right_shift_simd(const int *src, int *dst, uint8_t shift, size_t length) {\n    size_t i;\n    __m256i shift_vec = _mm256_set1_epi32(shift);\n    \n    for (i = 0; i + 8 <= length; i += 8) {\n        __m256i input = _mm256_loadu_si256((__m256i*)(src + i));\n        \n        // Arithmetic right shift\n        __m256i arith_shift = _mm256_srav_epi32(input, shift_vec);\n        \n        // Logical right shift\n        __m256i logical_shift = _mm256_srli_epi32(input, shift);\n        \n        // Add results together\n        __m256i result = _mm256_add_epi32(arith_shift, logical_shift);\n        \n        // Store result\n        _mm256_storeu_si256((__m256i*)(dst + i), result);\n    }\n    \n    // Handle remaining elements\n    for (; i < length; i++) {\n        int arith_shift = src[i] >> shift;\n        int logical_shift = (unsigned int)src[i] >> shift;\n        dst[i] = arith_shift + logical_shift;\n    }\n}\n```"}
{"task_id": "SimdBench_12_AVX", "completion": "```cpp\nvoid mixed_right_shift_simd(const int *src, int *dst, uint8_t shift, size_t length) {\n    size_t i;\n    __m256i vec_shift = _mm256_set1_epi32(shift);\n    \n    for (i = 0; i + 8 <= length; i += 8) {\n        __m256i input = _mm256_loadu_si256((__m256i*)(src + i));\n        \n        // Arithmetic right shift\n        __m256i arith_shift = _mm256_srav_epi32(input, vec_shift);\n        \n        // Logical right shift \n        __m256i logic_shift = _mm256_srli_epi32(input, shift);\n        \n        // Add results\n        __m256i result = _mm256_add_epi32(arith_shift, logic_shift);\n        \n        // Store result\n        _mm256_storeu_si256((__m256i*)(dst + i), result);\n    }\n    \n    // Handle remaining elements\n    for (; i < length; i++) {\n        int arith_result = src[i] >> shift;\n        int logic_result = (unsigned int)src[i] >> shift;\n        dst[i] = arith_result + logic_result;\n    }\n}\n```"}
{"task_id": "SimdBench_12_AVX", "completion": "```cpp\nvoid mixed_right_shift_simd(const int *src, int *dst, uint8_t shift, size_t length) {\n    size_t i;\n    const size_t simd_width = 8;\n    size_t simd_length = length - (length % simd_width);\n\n    for (i = 0; i < simd_length; i += simd_width) {\n        __m256i input = _mm256_loadu_si256((__m256i*)(src + i));\n        \n        // Arithmetic right shift\n        __m256i arith_shift = _mm256_srai_epi32(input, shift);\n        \n        // Logical right shift\n        __m256i logic_shift = _mm256_srli_epi32(input, shift);\n        \n        // Add results\n        __m256i result = _mm256_add_epi32(arith_shift, logic_shift);\n        \n        // Store result\n        _mm256_storeu_si256((__m256i*)(dst + i), result);\n    }\n\n    // Handle remaining elements\n    for (; i < length; i++) {\n        int arith_shift = src[i] >> shift;\n        int logic_shift = (unsigned int)src[i] >> shift;\n        dst[i] = arith_shift + logic_shift;\n    }\n}\n```"}
{"task_id": "SimdBench_12_AVX", "completion": "```cpp\nvoid mixed_right_shift_simd(const int *src, int *dst, uint8_t shift, size_t length) {\n    size_t i;\n    size_t aligned_length = length & ~7;\n    \n    __m256i shift_vec = _mm256_set1_epi32(shift);\n    \n    for (i = 0; i < aligned_length; i += 8) {\n        __m256i input = _mm256_loadu_si256((__m256i*)(src + i));\n        \n        // Arithmetic right shift\n        __m256i arith_shift = _mm256_srav_epi32(input, shift_vec);\n        \n        // Logical right shift\n        __m256i logical_shift = _mm256_srli_epi32(input, shift);\n        \n        // Add results\n        __m256i result = _mm256_add_epi32(arith_shift, logical_shift);\n        \n        // Store result\n        _mm256_storeu_si256((__m256i*)(dst + i), result);\n    }\n    \n    // Handle remaining elements\n    for (; i < length; i++) {\n        int arith_shift = src[i] >> shift;\n        int logical_shift = (unsigned int)src[i] >> shift;\n        dst[i] = arith_shift + logical_shift;\n    }\n}\n```"}
{"task_id": "SimdBench_13_AVX", "completion": "```cpp\nint64_t matrix_sum_simd(const int *matrix, size_t rows, size_t cols) {\n    size_t total_elements = rows * cols;\n    size_t vec_size = total_elements / 8;\n    size_t remainder = total_elements % 8;\n    \n    __m256i sum_vec = _mm256_setzero_si256();\n    \n    for (size_t i = 0; i < vec_size; i++) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)(matrix + i * 8));\n        sum_vec = _mm256_add_epi32(sum_vec, vec);\n    }\n    \n    int temp[8];\n    _mm256_storeu_si256((__m256i*)temp, sum_vec);\n    \n    int64_t total_sum = 0;\n    for (int i = 0; i < 8; i++) {\n        total_sum += temp[i];\n    }\n    \n    for (size_t i = vec_size * 8; i < total_elements; i++) {\n        total_sum += matrix[i];\n    }\n    \n    return total_sum;\n}\n```"}
{"task_id": "SimdBench_13_AVX", "completion": "```cpp\nint64_t matrix_sum_simd(const int *matrix, size_t rows, size_t cols) {\n    size_t total_elements = rows * cols;\n    size_t aligned_size = total_elements & ~7;\n    \n    __m256i sum_vec = _mm256_setzero_si256();\n    \n    for (size_t i = 0; i < aligned_size; i += 8) {\n        __m256i elements = _mm256_loadu_si256((__m256i*)(matrix + i));\n        sum_vec = _mm256_add_epi32(sum_vec, elements);\n    }\n    \n    int sum_array[8];\n    _mm256_storeu_si256((__m256i*)sum_array, sum_vec);\n    \n    int64_t total_sum = 0;\n    for (int i = 0; i < 8; i++) {\n        total_sum += sum_array[i];\n    }\n    \n    for (size_t i = aligned_size; i < total_elements; i++) {\n        total_sum += matrix[i];\n    }\n    \n    return total_sum;\n}\n```"}
{"task_id": "SimdBench_13_AVX", "completion": "```cpp\nint64_t matrix_sum_simd(const int *matrix, size_t rows, size_t cols) {\n    size_t total = rows * cols;\n    size_t i = 0;\n    \n    __m256i sum_vec = _mm256_setzero_si256();\n    \n    // Process 8 elements at a time\n    for (; i + 7 < total; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)(matrix + i));\n        sum_vec = _mm256_add_epi32(sum_vec, vec);\n    }\n    \n    // Extract results and sum remaining elements\n    int sum_array[8];\n    _mm256_storeu_si256((__m256i*)sum_array, sum_vec);\n    \n    int64_t final_sum = 0;\n    for (int j = 0; j < 8; j++) {\n        final_sum += sum_array[j];\n    }\n    \n    // Handle remaining elements\n    for (; i < total; i++) {\n        final_sum += matrix[i];\n    }\n    \n    return final_sum;\n}\n```"}
{"task_id": "SimdBench_13_AVX", "completion": "```cpp\nint64_t matrix_sum_simd(const int *matrix, size_t rows, size_t cols) {\n    size_t total = rows * cols;\n    size_t i = 0;\n    \n    __m256i sum = _mm256_setzero_si256();\n    \n    for (; i + 8 <= total; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)(matrix + i));\n        sum = _mm256_add_epi32(sum, vec);\n    }\n    \n    int temp[8];\n    _mm256_storeu_si256((__m256i*)temp, sum);\n    \n    int64_t final_sum = 0;\n    for (int j = 0; j < 8; j++) {\n        final_sum += temp[j];\n    }\n    \n    for (; i < total; i++) {\n        final_sum += matrix[i];\n    }\n    \n    return final_sum;\n}\n```"}
{"task_id": "SimdBench_13_AVX", "completion": "```cpp\nint64_t matrix_sum_simd(const int *matrix, size_t rows, size_t cols) {\n    size_t total = rows * cols;\n    size_t i = 0;\n    \n    __m256i sum_vec = _mm256_setzero_si256();\n    \n    // Process 8 elements at a time\n    for (; i + 7 < total; i += 8) {\n        __m256i vec = _mm256_loadu_si256((const __m256i*)(matrix + i));\n        sum_vec = _mm256_add_epi32(sum_vec, vec);\n    }\n    \n    // Extract results and sum them\n    int temp[8];\n    _mm256_storeu_si256((__m256i*)temp, sum_vec);\n    int64_t sum = 0;\n    for (int j = 0; j < 8; j++) {\n        sum += temp[j];\n    }\n    \n    // Handle remaining elements\n    for (; i < total; i++) {\n        sum += matrix[i];\n    }\n    \n    return sum;\n}\n```"}
{"task_id": "SimdBench_14_AVX", "completion": "```cpp\nsize_t argmax_simd(const int8_t *src, size_t length) {\n    if (length == 0) return 0;\n\n    size_t max_idx = 0;\n    int8_t max_val = src[0];\n    \n    const size_t vec_size = 32;\n    size_t vec_length = length / vec_size;\n    \n    if (vec_length > 0) {\n        __m256i max_vec = _mm256_set1_epi8(max_val);\n        __m256i idx_vec = _mm256_setr_epi8(0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,\n                                          16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31);\n        __m256i inc = _mm256_set1_epi8(32);\n        __m256i curr_idx = idx_vec;\n        \n        for (size_t i = 0; i < vec_length; i++) {\n            __m256i curr_vec = _mm256_loadu_si256((__m256i*)(src + i * vec_size));\n            __m256i mask = _mm256_cmpgt_epi8(curr_vec, max_vec);\n            \n            if (!_mm256_testz_si256(mask, mask)) {\n                max_vec = _mm256_blendv_epi8(max_vec, curr_vec, mask);\n                curr_idx = _mm256_blendv_epi8(curr_idx, idx_vec, mask);\n            }\n            \n            idx_vec = _mm256_add_epi8(idx_vec, inc);\n        }\n        \n        int8_t max_arr[32];\n        int8_t idx_arr[32];\n        _mm256_storeu_si256((__m256i*)max_arr, max_vec);\n        _mm256_storeu_si256((__m256i*)idx_arr, curr_idx);\n        \n        for (size_t i = 0; i < vec_size; i++) {\n            if (max_arr[i] > max_val) {\n                max_val = max_arr[i];\n                max_idx = idx_arr[i];\n            }\n        }\n    }\n    \n    for (size_t i = vec_length * vec_size; i < length; i++) {\n        if (src[i] > max_val) {\n            max_val = src[i];\n            max_idx = i;\n        }\n    }\n    \n    return max_idx;\n}\n```"}
{"task_id": "SimdBench_14_AVX", "completion": "```cpp\nsize_t argmax_simd(const int8_t *src, size_t length) {\n    if (length == 0) return 0;\n\n    __m256i max_val = _mm256_set1_epi8(-128);\n    __m256i max_idx = _mm256_setzero_si256();\n    __m256i idx = _mm256_setr_epi8(0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,\n                                  16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31);\n    __m256i inc = _mm256_set1_epi8(32);\n    \n    size_t i;\n    size_t max_index = 0;\n    int8_t max = src[0];\n    \n    for (i = 0; i + 32 <= length; i += 32) {\n        __m256i curr = _mm256_loadu_si256((__m256i*)(src + i));\n        __m256i mask = _mm256_cmpgt_epi8(curr, max_val);\n        \n        max_val = _mm256_blendv_epi8(max_val, curr, mask);\n        max_idx = _mm256_blendv_epi8(max_idx, idx, mask);\n        \n        idx = _mm256_add_epi8(idx, inc);\n    }\n    \n    alignas(32) int8_t max_array[32];\n    alignas(32) int8_t idx_array[32];\n    \n    _mm256_store_si256((__m256i*)max_array, max_val);\n    _mm256_store_si256((__m256i*)idx_array, max_idx);\n    \n    for (int j = 0; j < 32; j++) {\n        if (max_array[j] > max) {\n            max = max_array[j];\n            max_index = idx_array[j];\n        }\n    }\n    \n    for (; i < length; i++) {\n        if (src[i] > max) {\n            max = src[i];\n            max_index = i;\n        }\n    }\n    \n    return max_index;\n}\n```"}
{"task_id": "SimdBench_14_AVX", "completion": "```cpp\nsize_t argmax_simd(const int8_t *src, size_t length) {\n    if (length == 0) return 0;\n\n    __m256i max_val = _mm256_set1_epi8(INT8_MIN);\n    __m256i max_idx = _mm256_setzero_si256();\n    __m256i idx = _mm256_setr_epi8(0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,\n                                  16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31);\n    __m256i inc = _mm256_set1_epi8(32);\n    \n    size_t i;\n    size_t max_index = 0;\n    int8_t global_max = INT8_MIN;\n\n    for (i = 0; i + 32 <= length; i += 32) {\n        __m256i curr = _mm256_loadu_si256((__m256i*)(src + i));\n        __m256i mask = _mm256_cmpgt_epi8(curr, max_val);\n        \n        max_val = _mm256_blendv_epi8(max_val, curr, mask);\n        max_idx = _mm256_blendv_epi8(max_idx, idx, mask);\n        \n        idx = _mm256_add_epi8(idx, inc);\n    }\n\n    alignas(32) int8_t max_array[32];\n    alignas(32) int8_t idx_array[32];\n    \n    _mm256_store_si256((__m256i*)max_array, max_val);\n    _mm256_store_si256((__m256i*)idx_array, max_idx);\n\n    for (int j = 0; j < 32; j++) {\n        if (max_array[j] > global_max) {\n            global_max = max_array[j];\n            max_index = idx_array[j];\n        }\n    }\n\n    for (; i < length; i++) {\n        if (src[i] > global_max) {\n            global_max = src[i];\n            max_index = i;\n        }\n    }\n\n    return max_index;\n}\n```"}
{"task_id": "SimdBench_14_AVX", "completion": "```cpp\nsize_t argmax_simd(const int8_t *src, size_t length) {\n    if (length == 0) return 0;\n\n    __m256i max_val = _mm256_set1_epi8(-128);\n    __m256i max_idx = _mm256_setzero_si256();\n    __m256i idx = _mm256_setr_epi8(0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,\n                                  16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31);\n    __m256i inc = _mm256_set1_epi8(32);\n    \n    size_t i;\n    size_t max_index = 0;\n    int8_t max = src[0];\n    \n    for (i = 0; i + 32 <= length; i += 32) {\n        __m256i curr = _mm256_loadu_si256((__m256i*)(src + i));\n        __m256i mask = _mm256_cmpgt_epi8(curr, max_val);\n        \n        max_val = _mm256_blendv_epi8(max_val, curr, mask);\n        max_idx = _mm256_blendv_epi8(max_idx, idx, mask);\n        \n        idx = _mm256_add_epi8(idx, inc);\n    }\n    \n    alignas(32) int8_t max_array[32];\n    alignas(32) int8_t idx_array[32];\n    \n    _mm256_store_si256((__m256i*)max_array, max_val);\n    _mm256_store_si256((__m256i*)idx_array, max_idx);\n    \n    for (int j = 0; j < 32; j++) {\n        if (max_array[j] > max) {\n            max = max_array[j];\n            max_index = idx_array[j];\n        }\n    }\n    \n    for (; i < length; i++) {\n        if (src[i] > max) {\n            max = src[i];\n            max_index = i;\n        }\n    }\n    \n    return max_index;\n}\n```"}
{"task_id": "SimdBench_14_AVX", "completion": "```cpp\nsize_t argmax_simd(const int8_t *src, size_t length) {\n    if (length == 0) return 0;\n\n    __m256i max_val = _mm256_set1_epi8(-128);\n    __m256i max_idx = _mm256_setzero_si256();\n    __m256i idx = _mm256_setr_epi8(0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,\n                                   16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31);\n    __m256i inc = _mm256_set1_epi8(32);\n    \n    size_t i;\n    size_t max_index = 0;\n    int8_t max = src[0];\n    \n    for (i = 0; i + 32 <= length; i += 32) {\n        __m256i curr = _mm256_loadu_si256((__m256i*)(src + i));\n        __m256i mask = _mm256_cmpgt_epi8(curr, max_val);\n        \n        max_val = _mm256_blendv_epi8(max_val, curr, mask);\n        max_idx = _mm256_blendv_epi8(max_idx, idx, mask);\n        \n        idx = _mm256_add_epi8(idx, inc);\n    }\n    \n    alignas(32) int8_t max_array[32];\n    alignas(32) int8_t idx_array[32];\n    \n    _mm256_store_si256((__m256i*)max_array, max_val);\n    _mm256_store_si256((__m256i*)idx_array, max_idx);\n    \n    for (int j = 0; j < 32; j++) {\n        if (max_array[j] > max) {\n            max = max_array[j];\n            max_index = idx_array[j];\n        }\n    }\n    \n    for (; i < length; i++) {\n        if (src[i] > max) {\n            max = src[i];\n            max_index = i;\n        }\n    }\n    \n    return max_index;\n}\n```"}
{"task_id": "SimdBench_15_AVX", "completion": "```cpp\nvoid vector_blend_simd(const uint16_t* src1, const uint16_t* src2, uint32_t mask, uint16_t* dst, size_t length) {\n    size_t i;\n    size_t simd_length = length - (length % 16);\n    \n    __m256i vmask = _mm256_set_epi32(7, 6, 5, 4, 3, 2, 1, 0);\n    __m256i vmask_inc = _mm256_set1_epi32(8);\n    __m256i mask_val = _mm256_set1_epi32(mask);\n    \n    for (i = 0; i < simd_length; i += 16) {\n        __m256i indices1 = vmask;\n        __m256i indices2 = _mm256_add_epi32(vmask, vmask_inc);\n        \n        __m256i src1_vec1 = _mm256_loadu_si256((__m256i*)(src1 + i));\n        __m256i src1_vec2 = _mm256_loadu_si256((__m256i*)(src1 + i + 8));\n        __m256i src2_vec1 = _mm256_loadu_si256((__m256i*)(src2 + i));\n        __m256i src2_vec2 = _mm256_loadu_si256((__m256i*)(src2 + i + 8));\n        \n        __m256i mask1 = _mm256_and_si256(indices1, mask_val);\n        __m256i mask2 = _mm256_and_si256(indices2, mask_val);\n        \n        mask1 = _mm256_cmpeq_epi32(mask1, _mm256_setzero_si256());\n        mask2 = _mm256_cmpeq_epi32(mask2, _mm256_setzero_si256());\n        \n        __m256i blend1 = _mm256_blendv_epi8(src1_vec1, src2_vec1, mask1);\n        __m256i blend2 = _mm256_blendv_epi8(src1_vec2, src2_vec2, mask2);\n        \n        _mm256_storeu_si256((__m256i*)(dst + i), blend1);\n        _mm256_storeu_si256((__m256i*)(dst + i + 8), blend2);\n        \n        vmask = _mm256_add_epi32(vmask, _mm256_set1_epi32(16));\n    }\n    \n    for (; i < length; i++) {\n        dst[i] = (i & mask) ? src1[i] : src2[i];\n    }\n}\n```"}
{"task_id": "SimdBench_15_AVX", "completion": "```cpp\nvoid vector_blend_simd(const uint16_t* src1, const uint16_t* src2, uint32_t mask, uint16_t* dst, size_t length) {\n    size_t i;\n    const size_t simd_width = 16; // Process 16 elements per iteration (256-bit)\n    \n    for (i = 0; i + simd_width <= length; i += simd_width) {\n        __m256i indices = _mm256_set_epi16(i+15, i+14, i+13, i+12, i+11, i+10, i+9, i+8,\n                                          i+7, i+6, i+5, i+4, i+3, i+2, i+1, i);\n        __m256i mask_vec = _mm256_set1_epi32(mask);\n        __m256i masked = _mm256_and_si256(indices, mask_vec);\n        __m256i zero = _mm256_setzero_si256();\n        __m256i mask_cmp = _mm256_cmpeq_epi16(masked, zero);\n        \n        __m256i src1_vec = _mm256_loadu_si256((__m256i*)(src1 + i));\n        __m256i src2_vec = _mm256_loadu_si256((__m256i*)(src2 + i));\n        \n        __m256i result = _mm256_blendv_epi8(src1_vec, src2_vec, mask_cmp);\n        _mm256_storeu_si256((__m256i*)(dst + i), result);\n    }\n\n    // Handle remaining elements\n    for (; i < length; i++) {\n        dst[i] = (i & mask) ? src1[i] : src2[i];\n    }\n}\n```"}
{"task_id": "SimdBench_15_AVX", "completion": "```cpp\nvoid vector_blend_simd(const uint16_t* src1, const uint16_t* src2, uint32_t mask, uint16_t* dst, size_t length) {\n    size_t i;\n    const size_t vectorSize = 16; // 256 bits / 16 bits = 16 elements per vector\n    size_t vectorLength = length / vectorSize;\n\n    for (i = 0; i < vectorLength * vectorSize; i += vectorSize) {\n        __m256i indices = _mm256_set_epi16(i+15, i+14, i+13, i+12, i+11, i+10, i+9, i+8,\n                                         i+7, i+6, i+5, i+4, i+3, i+2, i+1, i);\n        __m256i maskVec = _mm256_and_si256(indices, _mm256_set1_epi16(mask));\n        __m256i zero = _mm256_setzero_si256();\n        __m256i blendMask = _mm256_cmpgt_epi16(maskVec, zero);\n        \n        __m256i v1 = _mm256_loadu_si256((__m256i*)(src1 + i));\n        __m256i v2 = _mm256_loadu_si256((__m256i*)(src2 + i));\n        __m256i result = _mm256_blendv_epi8(v2, v1, blendMask);\n        \n        _mm256_storeu_si256((__m256i*)(dst + i), result);\n    }\n\n    // Handle remaining elements\n    for (; i < length; i++) {\n        dst[i] = ((i & mask) != 0) ? src1[i] : src2[i];\n    }\n}\n```"}
{"task_id": "SimdBench_15_AVX", "completion": "```cpp\nvoid vector_blend_simd(const uint16_t* src1, const uint16_t* src2, uint32_t mask, uint16_t* dst, size_t length) {\n    size_t i;\n    const size_t vector_size = 16; // 256 bits / 16 bits = 16 elements\n\n    // Process 16 elements at a time using AVX2\n    for (i = 0; i + vector_size <= length; i += vector_size) {\n        __m256i idx = _mm256_set_epi16(i+15, i+14, i+13, i+12, i+11, i+10, i+9, i+8,\n                                      i+7, i+6, i+5, i+4, i+3, i+2, i+1, i);\n        __m256i mask_vec = _mm256_set1_epi32(mask);\n        __m256i and_result = _mm256_and_si256(idx, mask_vec);\n        __m256i zero = _mm256_setzero_si256();\n        __m256i mask_cmp = _mm256_cmpeq_epi16(and_result, zero);\n        \n        __m256i src1_vec = _mm256_loadu_si256((__m256i*)(src1 + i));\n        __m256i src2_vec = _mm256_loadu_si256((__m256i*)(src2 + i));\n        \n        __m256i result = _mm256_blendv_epi8(src1_vec, src2_vec, mask_cmp);\n        \n        _mm256_storeu_si256((__m256i*)(dst + i), result);\n    }\n\n    // Handle remaining elements\n    for (; i < length; i++) {\n        dst[i] = (i & mask) ? src1[i] : src2[i];\n    }\n}\n```"}
{"task_id": "SimdBench_15_AVX", "completion": "```cpp\nvoid vector_blend_simd(const uint16_t* src1, const uint16_t* src2, uint32_t mask, uint16_t* dst, size_t length) {\n    size_t i = 0;\n    const size_t vectorSize = 16; // 256 bits = 16 x uint16_t elements\n    \n    for (; i + vectorSize <= length; i += vectorSize) {\n        __m256i indices = _mm256_set_epi16(i+15, i+14, i+13, i+12, i+11, i+10, i+9, i+8,\n                                          i+7, i+6, i+5, i+4, i+3, i+2, i+1, i);\n        __m256i maskVec = _mm256_set1_epi32(mask);\n        __m256i andResult = _mm256_and_si256(indices, maskVec);\n        __m256i zero = _mm256_setzero_si256();\n        __m256i cmp = _mm256_cmpeq_epi16(andResult, zero);\n        \n        __m256i v1 = _mm256_loadu_si256((__m256i*)(src1 + i));\n        __m256i v2 = _mm256_loadu_si256((__m256i*)(src2 + i));\n        \n        __m256i result = _mm256_blendv_epi8(v1, v2, cmp);\n        _mm256_storeu_si256((__m256i*)(dst + i), result);\n    }\n    \n    // Handle remaining elements\n    for (; i < length; i++) {\n        dst[i] = ((i & mask) ? src1[i] : src2[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_16_AVX", "completion": "```cpp\nvoid population_count_simd(const uint32_t* src, uint32_t* dst, size_t length) {\n    size_t i;\n    const size_t vector_size = 8;\n    size_t vector_length = length - (length % vector_size);\n\n    __m256i lookup = _mm256_setr_epi8(\n        0, 1, 1, 2, 1, 2, 2, 3, 1, 2, 2, 3, 2, 3, 3, 4,\n        0, 1, 1, 2, 1, 2, 2, 3, 1, 2, 2, 3, 2, 3, 3, 4\n    );\n\n    for (i = 0; i < vector_length; i += vector_size) {\n        __m256i input = _mm256_loadu_si256((__m256i*)(src + i));\n        \n        __m256i mask1 = _mm256_set1_epi8(0x0f);\n        __m256i low_nibble = _mm256_and_si256(input, mask1);\n        __m256i high_nibble = _mm256_and_si256(_mm256_srli_epi8(input, 4), mask1);\n        \n        __m256i count_low = _mm256_shuffle_epi8(lookup, low_nibble);\n        __m256i count_high = _mm256_shuffle_epi8(lookup, high_nibble);\n        __m256i count_byte = _mm256_add_epi8(count_low, count_high);\n        \n        __m256i count_word = _mm256_sad_epu8(count_byte, _mm256_setzero_si256());\n        \n        _mm256_storeu_si256((__m256i*)(dst + i), count_word);\n    }\n\n    for (; i < length; i++) {\n        uint32_t n = src[i];\n        n = n - ((n >> 1) & 0x55555555);\n        n = (n & 0x33333333) + ((n >> 2) & 0x33333333);\n        n = (n + (n >> 4)) & 0x0F0F0F0F;\n        dst[i] = (n * 0x01010101) >> 24;\n    }\n}\n```"}
{"task_id": "SimdBench_16_AVX", "completion": "```cpp\nvoid population_count_simd(const uint32_t* src, uint32_t* dst, size_t length) {\n    size_t i;\n    const size_t vector_size = 8;\n    size_t vector_length = length / vector_size;\n    size_t remainder = length % vector_size;\n\n    for (i = 0; i < vector_length; i++) {\n        __m256i input = _mm256_loadu_si256((__m256i*)(src + i * vector_size));\n        \n        // Split into bytes\n        __m256i mask1 = _mm256_set1_epi8(0x55);\n        __m256i mask2 = _mm256_set1_epi8(0x33);\n        __m256i mask3 = _mm256_set1_epi8(0x0F);\n        \n        __m256i x = input;\n        x = _mm256_sub_epi8(x, (_mm256_srli_epi8(x, 1) & mask1));\n        x = (_mm256_srli_epi8(x, 2) & mask2) + (x & mask2);\n        x = (x + _mm256_srli_epi8(x, 4)) & mask3;\n        \n        // Sum up bytes\n        __m256i lookup = _mm256_set1_epi8(0x01);\n        x = _mm256_sad_epu8(x, _mm256_setzero_si256());\n        \n        // Store results\n        __m128i lo = _mm256_extracti128_si256(x, 0);\n        __m128i hi = _mm256_extracti128_si256(x, 1);\n        \n        uint32_t* result = dst + i * vector_size;\n        result[0] = _mm_cvtsi128_si32(lo);\n        result[1] = _mm_extract_epi32(lo, 2);\n        result[2] = _mm_cvtsi128_si32(hi);\n        result[3] = _mm_extract_epi32(hi, 2);\n    }\n\n    // Handle remaining elements\n    for (i = vector_length * vector_size; i < length; i++) {\n        uint32_t n = src[i];\n        n = n - ((n >> 1) & 0x55555555);\n        n = (n & 0x33333333) + ((n >> 2) & 0x33333333);\n        n = (n + (n >> 4)) & 0x0F0F0F0F;\n        n = n + (n >> 8);\n        n = n + (n >> 16);\n        dst[i] = n & 0x3F;\n    }\n}\n```"}
{"task_id": "SimdBench_16_AVX", "completion": "```cpp\nvoid population_count_simd(const uint32_t* src, uint32_t* dst, size_t length) {\n    size_t i;\n    const size_t vector_size = 8;\n    size_t vector_length = length - (length % vector_size);\n\n    for (i = 0; i < vector_length; i += vector_size) {\n        __m256i input = _mm256_loadu_si256((__m256i*)(src + i));\n        \n        // Mask for bits in position 1\n        __m256i mask1 = _mm256_set1_epi32(0x55555555);\n        __m256i count1 = _mm256_srli_epi32(input, 1);\n        count1 = _mm256_and_si256(mask1, count1);\n        input = _mm256_and_si256(mask1, input);\n        input = _mm256_add_epi32(input, count1);\n        \n        // Mask for bits in position 2\n        __m256i mask2 = _mm256_set1_epi32(0x33333333);\n        count1 = _mm256_srli_epi32(input, 2);\n        count1 = _mm256_and_si256(mask2, count1);\n        input = _mm256_and_si256(mask2, input);\n        input = _mm256_add_epi32(input, count1);\n        \n        // Mask for bits in position 4\n        __m256i mask3 = _mm256_set1_epi32(0x0f0f0f0f);\n        count1 = _mm256_srli_epi32(input, 4);\n        count1 = _mm256_and_si256(mask3, count1);\n        input = _mm256_and_si256(mask3, input);\n        input = _mm256_add_epi32(input, count1);\n        \n        // Final sum\n        input = _mm256_srli_epi32(_mm256_mullo_epi32(input, _mm256_set1_epi32(0x01010101)), 24);\n        \n        _mm256_storeu_si256((__m256i*)(dst + i), input);\n    }\n\n    // Handle remaining elements\n    for (; i < length; i++) {\n        uint32_t x = src[i];\n        x = x - ((x >> 1) & 0x55555555);\n        x = (x & 0x33333333) + ((x >> 2) & 0x33333333);\n        x = (x + (x >> 4)) & 0x0f0f0f0f;\n        dst[i] = (x * 0x01010101) >> 24;\n    }\n}\n```"}
{"task_id": "SimdBench_16_AVX", "completion": "```cpp\nvoid population_count_simd(const uint32_t* src, uint32_t* dst, size_t length) {\n    size_t i;\n    const size_t vector_size = 8;\n    size_t vector_length = length - (length % vector_size);\n\n    __m256i lookup = _mm256_setr_epi8(\n        0, 1, 1, 2, 1, 2, 2, 3, 1, 2, 2, 3, 2, 3, 3, 4,\n        0, 1, 1, 2, 1, 2, 2, 3, 1, 2, 2, 3, 2, 3, 3, 4\n    );\n\n    for (i = 0; i < vector_length; i += vector_size) {\n        __m256i input = _mm256_loadu_si256((__m256i*)(src + i));\n        \n        __m256i mask1 = _mm256_set1_epi8(0x0f);\n        __m256i low_nibble = _mm256_and_si256(input, mask1);\n        __m256i high_nibble = _mm256_and_si256(_mm256_srli_epi8(input, 4), mask1);\n        \n        __m256i count_low = _mm256_shuffle_epi8(lookup, low_nibble);\n        __m256i count_high = _mm256_shuffle_epi8(lookup, high_nibble);\n        __m256i count_byte = _mm256_add_epi8(count_low, count_high);\n        \n        __m256i sum1 = _mm256_sad_epu8(count_byte, _mm256_setzero_si256());\n        __m256i result = _mm256_packus_epi32(sum1, sum1);\n        \n        _mm256_storeu_si256((__m256i*)(dst + i), result);\n    }\n\n    for (; i < length; i++) {\n        uint32_t n = src[i];\n        n = n - ((n >> 1) & 0x55555555);\n        n = (n & 0x33333333) + ((n >> 2) & 0x33333333);\n        n = (n + (n >> 4)) & 0x0F0F0F0F;\n        dst[i] = (n * 0x01010101) >> 24;\n    }\n}\n```"}
{"task_id": "SimdBench_16_AVX", "completion": "```cpp\nvoid population_count_simd(const uint32_t* src, uint32_t* dst, size_t length) {\n    size_t i;\n    const size_t vector_size = 8;\n    size_t vector_length = length - (length % vector_size);\n\n    for (i = 0; i < vector_length; i += vector_size) {\n        __m256i input = _mm256_loadu_si256((__m256i*)(src + i));\n        \n        // Lookup table method using PSHUFB\n        __m256i lookup = _mm256_setr_epi8(\n            0, 1, 1, 2, 1, 2, 2, 3, 1, 2, 2, 3, 2, 3, 3, 4,\n            0, 1, 1, 2, 1, 2, 2, 3, 1, 2, 2, 3, 2, 3, 3, 4\n        );\n        \n        __m256i low_mask = _mm256_set1_epi8(0x0f);\n        __m256i lo = _mm256_and_si256(input, low_mask);\n        __m256i hi = _mm256_and_si256(_mm256_srli_epi32(input, 4), low_mask);\n        \n        __m256i popcnt_lo = _mm256_shuffle_epi8(lookup, lo);\n        __m256i popcnt_hi = _mm256_shuffle_epi8(lookup, hi);\n        __m256i sum = _mm256_add_epi8(popcnt_lo, popcnt_hi);\n        \n        // Add adjacent bytes\n        sum = _mm256_sad_epu8(sum, _mm256_setzero_si256());\n        \n        // Store results\n        _mm256_storeu_si256((__m256i*)(dst + i), sum);\n    }\n\n    // Handle remaining elements\n    for (; i < length; i++) {\n        dst[i] = __builtin_popcount(src[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_17_AVX", "completion": "```cpp\nvoid saturating_add_simd(const uint16_t* src1, const uint16_t* src2, uint16_t* dst, size_t length) {\n    size_t i;\n    size_t simd_width = 16; // Process 16 elements per iteration (256-bit AVX2)\n    size_t aligned_length = length & ~(simd_width - 1);\n\n    for (i = 0; i < aligned_length; i += simd_width) {\n        __m256i v1 = _mm256_loadu_si256((__m256i*)(src1 + i));\n        __m256i v2 = _mm256_loadu_si256((__m256i*)(src2 + i));\n        __m256i result = _mm256_adds_epu16(v1, v2);\n        _mm256_storeu_si256((__m256i*)(dst + i), result);\n    }\n\n    // Handle remaining elements\n    for (; i < length; i++) {\n        uint32_t sum = (uint32_t)src1[i] + (uint32_t)src2[i];\n        dst[i] = (sum > UINT16_MAX) ? UINT16_MAX : (uint16_t)sum;\n    }\n}\n```"}
{"task_id": "SimdBench_17_AVX", "completion": "```cpp\nvoid saturating_add_simd(const uint16_t* src1, const uint16_t* src2, uint16_t* dst, size_t length) {\n    size_t i;\n    size_t simd_length = length - (length % 16);\n    \n    for (i = 0; i < simd_length; i += 16) {\n        __m256i v1 = _mm256_loadu_si256((__m256i*)(src1 + i));\n        __m256i v2 = _mm256_loadu_si256((__m256i*)(src2 + i));\n        __m256i result = _mm256_adds_epu16(v1, v2);\n        _mm256_storeu_si256((__m256i*)(dst + i), result);\n    }\n\n    // Handle remaining elements\n    for (; i < length; i++) {\n        uint32_t sum = (uint32_t)src1[i] + (uint32_t)src2[i];\n        dst[i] = (sum > UINT16_MAX) ? UINT16_MAX : (uint16_t)sum;\n    }\n}\n```"}
{"task_id": "SimdBench_17_AVX", "completion": "```cpp\nvoid saturating_add_simd(const uint16_t* src1, const uint16_t* src2, uint16_t* dst, size_t length) {\n    size_t i;\n    size_t simd_width = 16; // 256 bits = 16 x uint16_t elements\n    size_t aligned_length = length & ~(simd_width - 1);\n\n    for (i = 0; i < aligned_length; i += simd_width) {\n        __m256i v1 = _mm256_loadu_si256((__m256i*)(src1 + i));\n        __m256i v2 = _mm256_loadu_si256((__m256i*)(src2 + i));\n        __m256i result = _mm256_adds_epu16(v1, v2);\n        _mm256_storeu_si256((__m256i*)(dst + i), result);\n    }\n\n    // Handle remaining elements\n    for (; i < length; i++) {\n        uint32_t sum = (uint32_t)src1[i] + (uint32_t)src2[i];\n        dst[i] = (sum > UINT16_MAX) ? UINT16_MAX : (uint16_t)sum;\n    }\n}\n```"}
{"task_id": "SimdBench_17_AVX", "completion": "```cpp\nvoid saturating_add_simd(const uint16_t* src1, const uint16_t* src2, uint16_t* dst, size_t length) {\n    size_t i;\n    size_t simd_length = length - (length % 16);\n    \n    for (i = 0; i < simd_length; i += 16) {\n        __m256i v1 = _mm256_loadu_si256((__m256i*)(src1 + i));\n        __m256i v2 = _mm256_loadu_si256((__m256i*)(src2 + i));\n        __m256i result = _mm256_adds_epu16(v1, v2);\n        _mm256_storeu_si256((__m256i*)(dst + i), result);\n    }\n\n    // Handle remaining elements\n    for (; i < length; i++) {\n        uint32_t sum = (uint32_t)src1[i] + (uint32_t)src2[i];\n        dst[i] = (sum > UINT16_MAX) ? UINT16_MAX : (uint16_t)sum;\n    }\n}\n```"}
{"task_id": "SimdBench_17_AVX", "completion": "```cpp\nvoid saturating_add_simd(const uint16_t* src1, const uint16_t* src2, uint16_t* dst, size_t length) {\n    size_t i;\n    size_t simd_length = length - (length % 16);\n    \n    for (i = 0; i < simd_length; i += 16) {\n        __m256i v1 = _mm256_loadu_si256((__m256i*)(src1 + i));\n        __m256i v2 = _mm256_loadu_si256((__m256i*)(src2 + i));\n        __m256i result = _mm256_adds_epu16(v1, v2);\n        _mm256_storeu_si256((__m256i*)(dst + i), result);\n    }\n\n    // Handle remaining elements\n    for (; i < length; i++) {\n        uint32_t sum = (uint32_t)src1[i] + (uint32_t)src2[i];\n        dst[i] = (sum > UINT16_MAX) ? UINT16_MAX : (uint16_t)sum;\n    }\n}\n```"}
{"task_id": "SimdBench_18_AVX", "completion": "```cpp\nvoid range_matrix_mul_simd(const double* A, const double* B, double* C, size_t m, size_t n, size_t p) {\n    __m256d min_val = _mm256_set1_pd(-100.0);\n    __m256d max_val = _mm256_set1_pd(100.0);\n    __m256d zero = _mm256_setzero_pd();\n\n    for (size_t i = 0; i < m; i++) {\n        for (size_t j = 0; j < p; j++) {\n            __m256d sum = _mm256_setzero_pd();\n            \n            for (size_t k = 0; k < n; k += 4) {\n                size_t remaining = n - k;\n                if (remaining >= 4) {\n                    __m256d a = _mm256_loadu_pd(&A[i * n + k]);\n                    __m256d b = _mm256_loadu_pd(&B[k * p + j]);\n                    \n                    __m256d a_mask = _mm256_and_pd(\n                        _mm256_cmp_pd(a, min_val, _CMP_GE_OQ),\n                        _mm256_cmp_pd(a, max_val, _CMP_LE_OQ)\n                    );\n                    \n                    __m256d b_mask = _mm256_and_pd(\n                        _mm256_cmp_pd(b, min_val, _CMP_GE_OQ),\n                        _mm256_cmp_pd(b, max_val, _CMP_LE_OQ)\n                    );\n                    \n                    __m256d mask = _mm256_and_pd(a_mask, b_mask);\n                    \n                    a = _mm256_blendv_pd(zero, a, mask);\n                    b = _mm256_blendv_pd(zero, b, mask);\n                    \n                    sum = _mm256_fmadd_pd(a, b, sum);\n                } else {\n                    double partial_sum = 0.0;\n                    for (size_t r = 0; r < remaining; r++) {\n                        double a_val = A[i * n + k + r];\n                        double b_val = B[(k + r) * p + j];\n                        \n                        if (a_val >= -100.0 && a_val <= 100.0 && \n                            b_val >= -100.0 && b_val <= 100.0) {\n                            partial_sum += a_val * b_val;\n                        }\n                    }\n                    sum = _mm256_add_pd(sum, _mm256_set1_pd(partial_sum));\n                }\n            }\n            \n            double final_sum = 0.0;\n            double temp[4];\n            _mm256_storeu_pd(temp, sum);\n            for (int k = 0; k < 4; k++) {\n                final_sum += temp[k];\n            }\n            \n            C[i * p + j] = final_sum;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_18_AVX", "completion": "```cpp\nvoid range_matrix_mul_simd(const double* A, const double* B, double* C, size_t m, size_t n, size_t p) {\n    __m256d min_val = _mm256_set1_pd(-100.0);\n    __m256d max_val = _mm256_set1_pd(100.0);\n    __m256d zero = _mm256_setzero_pd();\n\n    for (size_t i = 0; i < m; i++) {\n        for (size_t j = 0; j < p; j++) {\n            __m256d sum = _mm256_setzero_pd();\n            \n            for (size_t k = 0; k < n - 3; k += 4) {\n                __m256d a = _mm256_loadu_pd(&A[i * n + k]);\n                __m256d b = _mm256_set_pd(B[(k+3)*p + j], \n                                        B[(k+2)*p + j],\n                                        B[(k+1)*p + j], \n                                        B[k*p + j]);\n\n                __m256d a_mask = _mm256_and_pd(\n                    _mm256_cmp_pd(a, min_val, _CMP_GE_OQ),\n                    _mm256_cmp_pd(a, max_val, _CMP_LE_OQ)\n                );\n\n                __m256d b_mask = _mm256_and_pd(\n                    _mm256_cmp_pd(b, min_val, _CMP_GE_OQ),\n                    _mm256_cmp_pd(b, max_val, _CMP_LE_OQ)\n                );\n\n                __m256d mask = _mm256_and_pd(a_mask, b_mask);\n                \n                a = _mm256_blendv_pd(zero, a, mask);\n                b = _mm256_blendv_pd(zero, b, mask);\n\n                sum = _mm256_fmadd_pd(a, b, sum);\n            }\n\n            double temp[4];\n            _mm256_storeu_pd(temp, sum);\n            C[i*p + j] = temp[0] + temp[1] + temp[2] + temp[3];\n\n            // Handle remaining elements\n            for (size_t k = (n/4)*4; k < n; k++) {\n                double a = A[i*n + k];\n                double b = B[k*p + j];\n                \n                if (a >= -100.0 && a <= 100.0 && b >= -100.0 && b <= 100.0) {\n                    C[i*p + j] += a * b;\n                }\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_18_AVX", "completion": "```cpp\nvoid range_matrix_mul_simd(const double* A, const double* B, double* C, size_t m, size_t n, size_t p) {\n    __m256d vmin = _mm256_set1_pd(-100.0);\n    __m256d vmax = _mm256_set1_pd(100.0);\n    \n    for (size_t i = 0; i < m; i++) {\n        for (size_t j = 0; j < p; j++) {\n            __m256d sum = _mm256_setzero_pd();\n            \n            for (size_t k = 0; k < n - 3; k += 4) {\n                __m256d va = _mm256_loadu_pd(&A[i * n + k]);\n                __m256d vb = _mm256_set_pd(B[(k+3)*p + j], \n                                         B[(k+2)*p + j],\n                                         B[(k+1)*p + j],\n                                         B[k*p + j]);\n                \n                __m256d mask_a = _mm256_and_pd(_mm256_cmp_pd(va, vmin, _CMP_GE_OQ),\n                                              _mm256_cmp_pd(va, vmax, _CMP_LE_OQ));\n                __m256d mask_b = _mm256_and_pd(_mm256_cmp_pd(vb, vmin, _CMP_GE_OQ),\n                                              _mm256_cmp_pd(vb, vmax, _CMP_LE_OQ));\n                __m256d mask = _mm256_and_pd(mask_a, mask_b);\n                \n                __m256d prod = _mm256_mul_pd(va, vb);\n                prod = _mm256_and_pd(prod, mask);\n                sum = _mm256_add_pd(sum, prod);\n            }\n            \n            double temp[4];\n            _mm256_storeu_pd(temp, sum);\n            double final_sum = temp[0] + temp[1] + temp[2] + temp[3];\n            \n            // Handle remaining elements\n            for (size_t k = n - (n % 4); k < n; k++) {\n                double a = A[i * n + k];\n                double b = B[k * p + j];\n                if (a >= -100.0 && a <= 100.0 && b >= -100.0 && b <= 100.0) {\n                    final_sum += a * b;\n                }\n            }\n            \n            C[i * p + j] = final_sum;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_18_AVX", "completion": "```cpp\nvoid range_matrix_mul_simd(const double* A, const double* B, double* C, size_t m, size_t n, size_t p) {\n    const __m256d upper = _mm256_set1_pd(100.0);\n    const __m256d lower = _mm256_set1_pd(-100.0);\n    \n    for (size_t i = 0; i < m; i++) {\n        for (size_t j = 0; j < p; j++) {\n            __m256d sum = _mm256_setzero_pd();\n            \n            for (size_t k = 0; k < n - 3; k += 4) {\n                __m256d a = _mm256_loadu_pd(&A[i * n + k]);\n                __m256d b = _mm256_loadu_pd(&B[k * p + j]);\n                \n                __m256d mask_a_upper = _mm256_cmp_pd(a, upper, _CMP_LE_OQ);\n                __m256d mask_a_lower = _mm256_cmp_pd(a, lower, _CMP_GE_OQ);\n                __m256d mask_a = _mm256_and_pd(mask_a_upper, mask_a_lower);\n                \n                __m256d mask_b_upper = _mm256_cmp_pd(b, upper, _CMP_LE_OQ);\n                __m256d mask_b_lower = _mm256_cmp_pd(b, lower, _CMP_GE_OQ);\n                __m256d mask_b = _mm256_and_pd(mask_b_upper, mask_b_lower);\n                \n                __m256d mask = _mm256_and_pd(mask_a, mask_b);\n                \n                __m256d prod = _mm256_mul_pd(a, b);\n                prod = _mm256_and_pd(prod, mask);\n                sum = _mm256_add_pd(sum, prod);\n            }\n            \n            double temp[4];\n            _mm256_storeu_pd(temp, sum);\n            double final_sum = temp[0] + temp[1] + temp[2] + temp[3];\n            \n            // Handle remaining elements\n            for (size_t k = (n/4)*4; k < n; k++) {\n                double a_val = A[i * n + k];\n                double b_val = B[k * p + j];\n                if (a_val >= -100.0 && a_val <= 100.0 && \n                    b_val >= -100.0 && b_val <= 100.0) {\n                    final_sum += a_val * b_val;\n                }\n            }\n            \n            C[i * p + j] = final_sum;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_18_AVX", "completion": "```cpp\nvoid range_matrix_mul_simd(const double* A, const double* B, double* C, size_t m, size_t n, size_t p) {\n    __m256d min_val = _mm256_set1_pd(-100.0);\n    __m256d max_val = _mm256_set1_pd(100.0);\n    __m256d zero = _mm256_setzero_pd();\n\n    for (size_t i = 0; i < m; i++) {\n        for (size_t j = 0; j < p; j++) {\n            __m256d sum = _mm256_setzero_pd();\n            \n            for (size_t k = 0; k < n - 3; k += 4) {\n                __m256d a = _mm256_loadu_pd(&A[i * n + k]);\n                __m256d b = _mm256_set_pd(B[(k+3)*p + j], B[(k+2)*p + j], \n                                        B[(k+1)*p + j], B[k*p + j]);\n                \n                __m256d a_mask = _mm256_and_pd(\n                    _mm256_cmp_pd(a, min_val, _CMP_GE_OQ),\n                    _mm256_cmp_pd(a, max_val, _CMP_LE_OQ)\n                );\n                \n                __m256d b_mask = _mm256_and_pd(\n                    _mm256_cmp_pd(b, min_val, _CMP_GE_OQ),\n                    _mm256_cmp_pd(b, max_val, _CMP_LE_OQ)\n                );\n                \n                __m256d mask = _mm256_and_pd(a_mask, b_mask);\n                \n                __m256d prod = _mm256_mul_pd(a, b);\n                prod = _mm256_blendv_pd(zero, prod, mask);\n                \n                sum = _mm256_add_pd(sum, prod);\n            }\n            \n            double final_sum = 0.0;\n            double temp[4];\n            _mm256_storeu_pd(temp, sum);\n            \n            for (int k = 0; k < 4; k++) {\n                final_sum += temp[k];\n            }\n            \n            // Handle remaining elements\n            for (size_t k = (n/4)*4; k < n; k++) {\n                double a_val = A[i * n + k];\n                double b_val = B[k * p + j];\n                if (a_val >= -100.0 && a_val <= 100.0 && \n                    b_val >= -100.0 && b_val <= 100.0) {\n                    final_sum += a_val * b_val;\n                }\n            }\n            \n            C[i * p + j] = final_sum;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_19_AVX", "completion": "```cpp\nvoid tensor_add_3d_simd(const int64_t* A, const int64_t* B, int64_t* C, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t vec_size = 4; // AVX2 can process 4 int64_t elements at once\n    size_t vec_count = total_elements / vec_size;\n    size_t remaining = total_elements % vec_size;\n\n    // Process 4 elements at a time using AVX2\n    for (size_t i = 0; i < vec_count; i++) {\n        __m256i a = _mm256_loadu_si256((__m256i*)&A[i * vec_size]);\n        __m256i b = _mm256_loadu_si256((__m256i*)&B[i * vec_size]);\n        __m256i c = _mm256_add_epi64(a, b);\n        _mm256_storeu_si256((__m256i*)&C[i * vec_size], c);\n    }\n\n    // Handle remaining elements\n    size_t offset = vec_count * vec_size;\n    for (size_t i = 0; i < remaining; i++) {\n        C[offset + i] = A[offset + i] + B[offset + i];\n    }\n}\n```"}
{"task_id": "SimdBench_19_AVX", "completion": "```cpp\nvoid tensor_add_3d_simd(const int64_t* A, const int64_t* B, int64_t* C, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t simd_width = 4; // AVX2 processes 4 int64 elements at a time\n    size_t simd_limit = total_elements - (total_elements % simd_width);\n    \n    size_t i;\n    for (i = 0; i < simd_limit; i += simd_width) {\n        __m256i a = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i b = _mm256_loadu_si256((__m256i*)&B[i]);\n        __m256i c = _mm256_add_epi64(a, b);\n        _mm256_storeu_si256((__m256i*)&C[i], c);\n    }\n\n    // Handle remaining elements\n    for (; i < total_elements; i++) {\n        C[i] = A[i] + B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_19_AVX", "completion": "```cpp\nvoid tensor_add_3d_simd(const int64_t* A, const int64_t* B, int64_t* C, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_size = dim1 * dim2 * dim3;\n    size_t aligned_size = total_size & ~3ULL; // Round down to multiple of 4\n    \n    // Process 4 elements at a time using AVX2\n    for (size_t i = 0; i < aligned_size; i += 4) {\n        __m256i a = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i b = _mm256_loadu_si256((__m256i*)&B[i]);\n        __m256i c = _mm256_add_epi64(a, b);\n        _mm256_storeu_si256((__m256i*)&C[i], c);\n    }\n    \n    // Handle remaining elements\n    for (size_t i = aligned_size; i < total_size; i++) {\n        C[i] = A[i] + B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_19_AVX", "completion": "```cpp\nvoid tensor_add_3d_simd(const int64_t* A, const int64_t* B, int64_t* C, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t vec_size = 4; // AVX2 can process 4 64-bit integers at once\n    size_t vec_count = total_elements / vec_size;\n    size_t remaining = total_elements % vec_size;\n\n    // Process 4 elements at a time using AVX2\n    for (size_t i = 0; i < vec_count; i++) {\n        __m256i a = _mm256_loadu_si256((__m256i*)&A[i * vec_size]);\n        __m256i b = _mm256_loadu_si256((__m256i*)&B[i * vec_size]);\n        __m256i c = _mm256_add_epi64(a, b);\n        _mm256_storeu_si256((__m256i*)&C[i * vec_size], c);\n    }\n\n    // Handle remaining elements\n    size_t offset = vec_count * vec_size;\n    for (size_t i = 0; i < remaining; i++) {\n        C[offset + i] = A[offset + i] + B[offset + i];\n    }\n}\n```"}
{"task_id": "SimdBench_19_AVX", "completion": "```cpp\nvoid tensor_add_3d_simd(const int64_t* A, const int64_t* B, int64_t* C, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_size = dim1 * dim2 * dim3;\n    size_t vec_size = total_size / 4;\n    size_t remainder = total_size % 4;\n    \n    __m256i* vec_A = (__m256i*)A;\n    __m256i* vec_B = (__m256i*)B; \n    __m256i* vec_C = (__m256i*)C;\n\n    // Process 4 elements at a time using AVX\n    for (size_t i = 0; i < vec_size; i++) {\n        __m256i a = _mm256_loadu_si256(&vec_A[i]);\n        __m256i b = _mm256_loadu_si256(&vec_B[i]);\n        __m256i c = _mm256_add_epi64(a, b);\n        _mm256_storeu_si256(&vec_C[i], c);\n    }\n\n    // Handle remaining elements\n    size_t offset = vec_size * 4;\n    for (size_t i = 0; i < remainder; i++) {\n        C[offset + i] = A[offset + i] + B[offset + i];\n    }\n}\n```"}
{"task_id": "SimdBench_20_AVX", "completion": "```cpp\nvoid vector_add_round_nearest_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    size_t i;\n    size_t simdLen = length - (length % 8);\n\n    for (i = 0; i < simdLen; i += 8) {\n        __m256 v1 = _mm256_loadu_ps(src1 + i);\n        __m256 v2 = _mm256_loadu_ps(src2 + i);\n        __m256 sum = _mm256_add_ps(v1, v2);\n        __m256 rounded = _mm256_round_ps(sum, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n        _mm256_storeu_ps(dst + i, rounded);\n    }\n\n    for (; i < length; i++) {\n        dst[i] = roundf(src1[i] + src2[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_20_AVX", "completion": "```cpp\nvoid vector_add_round_nearest_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    size_t i;\n    size_t simdLen = length - (length % 8);\n    \n    for (i = 0; i < simdLen; i += 8) {\n        __m256 v1 = _mm256_loadu_ps(src1 + i);\n        __m256 v2 = _mm256_loadu_ps(src2 + i);\n        __m256 sum = _mm256_add_ps(v1, v2);\n        __m256 rounded = _mm256_round_ps(sum, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n        _mm256_storeu_ps(dst + i, rounded);\n    }\n\n    // Handle remaining elements\n    for (; i < length; i++) {\n        dst[i] = roundf(src1[i] + src2[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_20_AVX", "completion": "```cpp\nvoid vector_add_round_nearest_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    size_t i;\n    size_t simdLen = length - (length % 8);\n    \n    for (i = 0; i < simdLen; i += 8) {\n        __m256 v1 = _mm256_loadu_ps(src1 + i);\n        __m256 v2 = _mm256_loadu_ps(src2 + i);\n        __m256 sum = _mm256_add_ps(v1, v2);\n        __m256 rounded = _mm256_round_ps(sum, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n        _mm256_storeu_ps(dst + i, rounded);\n    }\n\n    // Handle remaining elements\n    for (; i < length; i++) {\n        dst[i] = roundf(src1[i] + src2[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_20_AVX", "completion": "```cpp\nvoid vector_add_round_nearest_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    size_t i;\n    size_t simdLen = length - (length % 8);\n    \n    for (i = 0; i < simdLen; i += 8) {\n        __m256 v1 = _mm256_loadu_ps(src1 + i);\n        __m256 v2 = _mm256_loadu_ps(src2 + i);\n        __m256 sum = _mm256_add_ps(v1, v2);\n        __m256 rounded = _mm256_round_ps(sum, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n        _mm256_storeu_ps(dst + i, rounded);\n    }\n\n    // Handle remaining elements\n    for (; i < length; i++) {\n        dst[i] = roundf(src1[i] + src2[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_20_AVX", "completion": "```cpp\nvoid vector_add_round_nearest_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    size_t i;\n    size_t simd_length = length - (length % 8);\n    \n    for (i = 0; i < simd_length; i += 8) {\n        __m256 v1 = _mm256_loadu_ps(src1 + i);\n        __m256 v2 = _mm256_loadu_ps(src2 + i);\n        __m256 sum = _mm256_add_ps(v1, v2);\n        __m256 rounded = _mm256_round_ps(sum, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n        _mm256_storeu_ps(dst + i, rounded);\n    }\n\n    // Handle remaining elements\n    for (; i < length; i++) {\n        dst[i] = roundf(src1[i] + src2[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_21_AVX", "completion": "```cpp\nvoid vector_mul_round_up_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    const size_t simd_width = 8;\n    const size_t aligned_length = length & ~(simd_width - 1);\n    \n    __m256 v_minus_one = _mm256_set1_ps(-1.0f);\n    __m256 v_fifty = _mm256_set1_ps(50.0f);\n    __m256i v_two = _mm256_set1_epi32(2);\n    __m256i v_index = _mm256_set_epi32(7,6,5,4,3,2,1,0);\n    \n    for (size_t i = 0; i < aligned_length; i += simd_width) {\n        __m256 v_src1 = _mm256_loadu_ps(src1 + i);\n        __m256 v_src2 = _mm256_loadu_ps(src2 + i);\n        \n        // Calculate absolute difference\n        __m256 v_diff = _mm256_sub_ps(v_src1, v_src2);\n        __m256 v_abs_diff = _mm256_and_ps(v_diff, _mm256_castsi256_ps(_mm256_set1_epi32(0x7FFFFFFF)));\n        \n        // Check if difference is within 50\n        __m256 v_diff_mask = _mm256_cmp_ps(v_abs_diff, v_fifty, _CMP_LE_OQ);\n        \n        // Check if index is multiple of 2\n        __m256i v_curr_index = _mm256_add_epi32(v_index, _mm256_set1_epi32(i));\n        __m256i v_rem = _mm256_and_si256(v_curr_index, v_two);\n        __m256 v_index_mask = _mm256_castsi256_ps(_mm256_cmpeq_epi32(v_rem, _mm256_setzero_si256()));\n        \n        // Combine masks\n        __m256 v_mask = _mm256_and_ps(v_diff_mask, v_index_mask);\n        \n        // Multiply src1 and src2\n        __m256 v_mul = _mm256_mul_ps(v_src1, v_src2);\n        \n        // Round up toward positive infinity\n        v_mul = _mm256_ceil_ps(v_mul);\n        \n        // Select between multiplication result and -1 based on mask\n        __m256 v_result = _mm256_blendv_ps(v_minus_one, v_mul, v_mask);\n        \n        // Store result\n        _mm256_storeu_ps(dst + i, v_result);\n    }\n    \n    // Handle remaining elements\n    for (size_t i = aligned_length; i < length; i++) {\n        if (i % 2 == 0 && fabs(src1[i] - src2[i]) <= 50.0f) {\n            dst[i] = ceilf(src1[i] * src2[i]);\n        } else {\n            dst[i] = -1.0f;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_21_AVX", "completion": "```cpp\nvoid vector_mul_round_up_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    const size_t simd_width = 8;\n    const size_t aligned_length = length & ~(simd_width - 1);\n    \n    __m256 v_minus_one = _mm256_set1_ps(-1.0f);\n    __m256 v_fifty = _mm256_set1_ps(50.0f);\n    __m256i v_two = _mm256_set1_epi32(2);\n    __m256i v_index = _mm256_set_epi32(7,6,5,4,3,2,1,0);\n    \n    for (size_t i = 0; i < aligned_length; i += simd_width) {\n        __m256 v_src1 = _mm256_loadu_ps(src1 + i);\n        __m256 v_src2 = _mm256_loadu_ps(src2 + i);\n        \n        // Calculate absolute difference\n        __m256 v_diff = _mm256_sub_ps(v_src1, v_src2);\n        __m256 v_abs_diff = _mm256_and_ps(v_diff, _mm256_castsi256_ps(_mm256_set1_epi32(0x7FFFFFFF)));\n        \n        // Check if difference is within 50\n        __m256 v_diff_mask = _mm256_cmp_ps(v_abs_diff, v_fifty, _CMP_LE_OS);\n        \n        // Check if index is multiple of 2\n        __m256i v_curr_index = _mm256_add_epi32(v_index, _mm256_set1_epi32(i));\n        __m256i v_rem = _mm256_and_si256(v_curr_index, v_two);\n        __m256 v_index_mask = _mm256_castsi256_ps(_mm256_cmpeq_epi32(v_rem, _mm256_setzero_si256()));\n        \n        // Combine conditions\n        __m256 v_mask = _mm256_and_ps(v_diff_mask, v_index_mask);\n        \n        // Multiply and round up\n        __m256 v_mul = _mm256_mul_ps(v_src1, v_src2);\n        __m256 v_round = _mm256_ceil_ps(v_mul);\n        \n        // Select between rounded result and -1 based on mask\n        __m256 v_result = _mm256_blendv_ps(v_minus_one, v_round, v_mask);\n        \n        _mm256_storeu_ps(dst + i, v_result);\n    }\n    \n    // Handle remaining elements\n    for (size_t i = aligned_length; i < length; i++) {\n        if ((i % 2 == 0) && (fabs(src1[i] - src2[i]) <= 50.0f)) {\n            dst[i] = ceil(src1[i] * src2[i]);\n        } else {\n            dst[i] = -1.0f;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_21_AVX", "completion": "```cpp\nvoid vector_mul_round_up_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    const size_t simd_width = 8;\n    const size_t simd_length = length / simd_width * simd_width;\n    \n    __m256 v_minus_one = _mm256_set1_ps(-1.0f);\n    __m256 v_fifty = _mm256_set1_ps(50.0f);\n    __m256i v_two = _mm256_set1_epi32(2);\n    __m256i v_index = _mm256_setr_epi32(0, 1, 2, 3, 4, 5, 6, 7);\n    \n    for (size_t i = 0; i < simd_length; i += simd_width) {\n        __m256 v_src1 = _mm256_loadu_ps(src1 + i);\n        __m256 v_src2 = _mm256_loadu_ps(src2 + i);\n        \n        // Calculate absolute difference\n        __m256 v_diff = _mm256_sub_ps(v_src1, v_src2);\n        __m256 v_abs_diff = _mm256_and_ps(v_diff, _mm256_castsi256_ps(_mm256_set1_epi32(0x7FFFFFFF)));\n        \n        // Check if difference is within 50\n        __m256 v_diff_mask = _mm256_cmp_ps(v_abs_diff, v_fifty, _CMP_LE_OQ);\n        \n        // Check if index is multiple of 2\n        __m256i v_curr_index = _mm256_add_epi32(v_index, _mm256_set1_epi32(i));\n        __m256i v_rem = _mm256_and_si256(v_curr_index, v_two);\n        __m256 v_index_mask = _mm256_castsi256_ps(_mm256_cmpeq_epi32(v_rem, _mm256_setzero_si256()));\n        \n        // Combine masks\n        __m256 v_mask = _mm256_and_ps(v_diff_mask, v_index_mask);\n        \n        // Multiply src1 and src2\n        __m256 v_mul = _mm256_mul_ps(v_src1, v_src2);\n        \n        // Round up toward positive infinity\n        v_mul = _mm256_ceil_ps(v_mul);\n        \n        // Select between multiplication result and -1 based on mask\n        __m256 v_result = _mm256_blendv_ps(v_minus_one, v_mul, v_mask);\n        \n        // Store result\n        _mm256_storeu_ps(dst + i, v_result);\n    }\n    \n    // Handle remaining elements\n    for (size_t i = simd_length; i < length; i++) {\n        float diff = fabsf(src1[i] - src2[i]);\n        if (diff <= 50.0f && (i % 2 == 0)) {\n            dst[i] = ceilf(src1[i] * src2[i]);\n        } else {\n            dst[i] = -1.0f;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_21_AVX", "completion": "```cpp\nvoid vector_mul_round_up_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    const size_t simd_width = 8;\n    const size_t aligned_length = length & ~(simd_width - 1);\n    \n    __m256 v_minus_one = _mm256_set1_ps(-1.0f);\n    __m256 v_fifty = _mm256_set1_ps(50.0f);\n    __m256i v_two = _mm256_set1_epi32(2);\n    __m256i v_index = _mm256_set_epi32(7,6,5,4,3,2,1,0);\n    \n    for (size_t i = 0; i < aligned_length; i += simd_width) {\n        __m256 v_src1 = _mm256_loadu_ps(src1 + i);\n        __m256 v_src2 = _mm256_loadu_ps(src2 + i);\n        \n        // Calculate absolute difference\n        __m256 v_diff = _mm256_sub_ps(v_src1, v_src2);\n        __m256 v_abs_diff = _mm256_and_ps(v_diff, _mm256_castsi256_ps(_mm256_set1_epi32(0x7FFFFFFF)));\n        \n        // Check if difference is within 50\n        __m256 v_diff_mask = _mm256_cmp_ps(v_abs_diff, v_fifty, _CMP_LE_OS);\n        \n        // Check if index is multiple of 2\n        __m256i v_curr_index = _mm256_add_epi32(v_index, _mm256_set1_epi32(i));\n        __m256i v_rem = _mm256_and_si256(v_curr_index, v_two);\n        __m256 v_index_mask = _mm256_castsi256_ps(_mm256_cmpeq_epi32(v_rem, _mm256_setzero_si256()));\n        \n        // Combine conditions\n        __m256 v_mask = _mm256_and_ps(v_diff_mask, v_index_mask);\n        \n        // Multiply and round up\n        __m256 v_mul = _mm256_mul_ps(v_src1, v_src2);\n        v_mul = _mm256_ceil_ps(v_mul);\n        \n        // Select between multiplication result and -1 based on mask\n        __m256 v_result = _mm256_blendv_ps(v_minus_one, v_mul, v_mask);\n        \n        _mm256_storeu_ps(dst + i, v_result);\n    }\n    \n    // Handle remaining elements\n    for (size_t i = aligned_length; i < length; i++) {\n        float diff = fabsf(src1[i] - src2[i]);\n        if (diff <= 50.0f && (i % 2 == 0)) {\n            dst[i] = ceilf(src1[i] * src2[i]);\n        } else {\n            dst[i] = -1.0f;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_21_AVX", "completion": "```cpp\nvoid vector_mul_round_up_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    const __m256 minus_one = _mm256_set1_ps(-1.0f);\n    const __m256 fifty = _mm256_set1_ps(50.0f);\n    const __m256i two = _mm256_set1_epi32(2);\n    const __m256i zero = _mm256_setzero_si256();\n    \n    size_t i;\n    for (i = 0; i + 8 <= length; i += 8) {\n        __m256 v1 = _mm256_loadu_ps(&src1[i]);\n        __m256 v2 = _mm256_loadu_ps(&src2[i]);\n        \n        // Calculate absolute difference\n        __m256 diff = _mm256_sub_ps(v1, v2);\n        __m256 abs_diff = _mm256_and_ps(diff, _mm256_castsi256_ps(_mm256_set1_epi32(0x7FFFFFFF)));\n        \n        // Check if difference is within 50\n        __m256 diff_mask = _mm256_cmp_ps(abs_diff, fifty, _CMP_LE_OQ);\n        \n        // Check if index is multiple of 2\n        __m256i indices = _mm256_set_epi32(i+7, i+6, i+5, i+4, i+3, i+2, i+1, i);\n        __m256i rem = _mm256_and_si256(indices, two);\n        __m256i idx_mask = _mm256_cmpeq_epi32(rem, zero);\n        __m256 idx_maskf = _mm256_castsi256_ps(idx_mask);\n        \n        // Combine conditions\n        __m256 mask = _mm256_and_ps(diff_mask, idx_maskf);\n        \n        // Multiply values where conditions are met\n        __m256 mul = _mm256_mul_ps(v1, v2);\n        \n        // Round up toward positive infinity\n        __m256 rounded = _mm256_ceil_ps(mul);\n        \n        // Select between rounded result and -1 based on mask\n        __m256 result = _mm256_blendv_ps(minus_one, rounded, mask);\n        \n        _mm256_storeu_ps(&dst[i], result);\n    }\n    \n    // Handle remaining elements\n    for (; i < length; i++) {\n        float diff = fabsf(src1[i] - src2[i]);\n        if (diff <= 50.0f && (i % 2 == 0)) {\n            dst[i] = ceilf(src1[i] * src2[i]);\n        } else {\n            dst[i] = -1.0f;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_22_AVX", "completion": "```cpp\nvoid matrix_scalar_mul_simd(const double* mat, double scalar, double* dst, size_t m, size_t n) {\n    size_t total = m * n;\n    size_t i = 0;\n    \n    __m256d scalar_vec = _mm256_set1_pd(scalar);\n    \n    for (; i + 4 <= total; i += 4) {\n        __m256d mat_vec = _mm256_loadu_pd(&mat[i]);\n        __m256d result = _mm256_mul_pd(mat_vec, scalar_vec);\n        _mm256_storeu_pd(&dst[i], result);\n    }\n    \n    for (; i < total; i++) {\n        dst[i] = mat[i] * scalar;\n    }\n}\n```"}
{"task_id": "SimdBench_22_AVX", "completion": "```cpp\nvoid matrix_scalar_mul_simd(const double* mat, double scalar, double* dst, size_t m, size_t n) {\n    size_t total = m * n;\n    size_t i = 0;\n    \n    __m256d scalar_vec = _mm256_set1_pd(scalar);\n    \n    // Process 4 elements at a time using AVX\n    for (; i + 4 <= total; i += 4) {\n        __m256d mat_vec = _mm256_loadu_pd(&mat[i]);\n        __m256d result = _mm256_mul_pd(mat_vec, scalar_vec);\n        _mm256_storeu_pd(&dst[i], result);\n    }\n    \n    // Handle remaining elements\n    for (; i < total; i++) {\n        dst[i] = mat[i] * scalar;\n    }\n}\n```"}
{"task_id": "SimdBench_22_AVX", "completion": "```cpp\nvoid matrix_scalar_mul_simd(const double* mat, double scalar, double* dst, size_t m, size_t n) {\n    size_t total = m * n;\n    size_t i = 0;\n    \n    __m256d scalar_vec = _mm256_set1_pd(scalar);\n    \n    for (; i + 4 <= total; i += 4) {\n        __m256d mat_vec = _mm256_loadu_pd(&mat[i]);\n        __m256d result = _mm256_mul_pd(mat_vec, scalar_vec);\n        _mm256_storeu_pd(&dst[i], result);\n    }\n    \n    for (; i < total; i++) {\n        dst[i] = mat[i] * scalar;\n    }\n}\n```"}
{"task_id": "SimdBench_22_AVX", "completion": "```cpp\nvoid matrix_scalar_mul_simd(const double* mat, double scalar, double* dst, size_t m, size_t n) {\n    size_t total = m * n;\n    size_t i = 0;\n    \n    __m256d scalar_vec = _mm256_set1_pd(scalar);\n    \n    for (; i + 4 <= total; i += 4) {\n        __m256d mat_vec = _mm256_loadu_pd(&mat[i]);\n        __m256d result = _mm256_mul_pd(mat_vec, scalar_vec);\n        _mm256_storeu_pd(&dst[i], result);\n    }\n    \n    for (; i < total; i++) {\n        dst[i] = mat[i] * scalar;\n    }\n}\n```"}
{"task_id": "SimdBench_22_AVX", "completion": "```cpp\nvoid matrix_scalar_mul_simd(const double* mat, double scalar, double* dst, size_t m, size_t n) {\n    size_t total = m * n;\n    size_t i = 0;\n    \n    __m256d scalar_vec = _mm256_set1_pd(scalar);\n    \n    for (; i + 4 <= total; i += 4) {\n        __m256d mat_vec = _mm256_loadu_pd(&mat[i]);\n        __m256d result = _mm256_mul_pd(mat_vec, scalar_vec);\n        _mm256_storeu_pd(&dst[i], result);\n    }\n    \n    for (; i < total; i++) {\n        dst[i] = mat[i] * scalar;\n    }\n}\n```"}
{"task_id": "SimdBench_23_AVX", "completion": "```cpp\nvoid matrix_normalize_rows_simd(float* mat, size_t m, size_t n) {\n    const size_t SIMD_WIDTH = 8;\n    \n    for (size_t i = 0; i < m; i++) {\n        float* row = mat + i * n;\n        __m256 sum = _mm256_setzero_ps();\n        \n        size_t j = 0;\n        for (; j + SIMD_WIDTH <= n; j += SIMD_WIDTH) {\n            __m256 v = _mm256_loadu_ps(row + j);\n            sum = _mm256_add_ps(sum, _mm256_mul_ps(v, v));\n        }\n        \n        float row_sum = 0.0f;\n        float temp[8] __attribute__((aligned(32)));\n        _mm256_store_ps(temp, sum);\n        for (int k = 0; k < 8; k++) {\n            row_sum += temp[k];\n        }\n        \n        for (; j < n; j++) {\n            row_sum += row[j] * row[j];\n        }\n        \n        float norm = 1.0f / sqrtf(row_sum);\n        __m256 norm_vec = _mm256_set1_ps(norm);\n        \n        j = 0;\n        for (; j + SIMD_WIDTH <= n; j += SIMD_WIDTH) {\n            __m256 v = _mm256_loadu_ps(row + j);\n            _mm256_storeu_ps(row + j, _mm256_mul_ps(v, norm_vec));\n        }\n        \n        for (; j < n; j++) {\n            row[j] *= norm;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_23_AVX", "completion": "```cpp\nvoid matrix_normalize_rows_simd(float* mat, size_t m, size_t n) {\n    const size_t SIMD_WIDTH = 8;\n    \n    for (size_t i = 0; i < m; i++) {\n        float* row = mat + i * n;\n        \n        __m256 sum = _mm256_setzero_ps();\n        \n        // Calculate sum of squares using SIMD\n        size_t j = 0;\n        for (; j + SIMD_WIDTH <= n; j += SIMD_WIDTH) {\n            __m256 v = _mm256_loadu_ps(row + j);\n            sum = _mm256_add_ps(sum, _mm256_mul_ps(v, v));\n        }\n        \n        // Reduce sum vector to single value\n        float row_sum = 0.0f;\n        float temp[8];\n        _mm256_storeu_ps(temp, sum);\n        for (size_t k = 0; k < 8; k++) {\n            row_sum += temp[k];\n        }\n        \n        // Handle remaining elements\n        for (; j < n; j++) {\n            row_sum += row[j] * row[j];\n        }\n        \n        // Calculate reciprocal of square root\n        float norm = 1.0f / sqrtf(row_sum);\n        __m256 norm_vec = _mm256_set1_ps(norm);\n        \n        // Normalize row elements using SIMD\n        j = 0;\n        for (; j + SIMD_WIDTH <= n; j += SIMD_WIDTH) {\n            __m256 v = _mm256_loadu_ps(row + j);\n            __m256 result = _mm256_mul_ps(v, norm_vec);\n            _mm256_storeu_ps(row + j, result);\n        }\n        \n        // Handle remaining elements\n        for (; j < n; j++) {\n            row[j] *= norm;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_23_AVX", "completion": "```cpp\nvoid matrix_normalize_rows_simd(float* mat, size_t m, size_t n) {\n    const size_t simd_width = 8;\n    const size_t aligned_n = (n / simd_width) * simd_width;\n    \n    for (size_t i = 0; i < m; i++) {\n        float* row = mat + i * n;\n        __m256 sum = _mm256_setzero_ps();\n        \n        // Calculate sum of squares\n        for (size_t j = 0; j < aligned_n; j += simd_width) {\n            __m256 vec = _mm256_loadu_ps(row + j);\n            sum = _mm256_add_ps(sum, _mm256_mul_ps(vec, vec));\n        }\n        \n        // Handle remaining elements\n        float row_sum = 0.0f;\n        float temp[8];\n        _mm256_storeu_ps(temp, sum);\n        for (size_t k = 0; k < 8; k++) {\n            row_sum += temp[k];\n        }\n        for (size_t j = aligned_n; j < n; j++) {\n            row_sum += row[j] * row[j];\n        }\n        \n        // Calculate L2 norm\n        float norm = 1.0f / sqrtf(row_sum);\n        __m256 norm_vec = _mm256_set1_ps(norm);\n        \n        // Normalize row elements\n        for (size_t j = 0; j < aligned_n; j += simd_width) {\n            __m256 vec = _mm256_loadu_ps(row + j);\n            _mm256_storeu_ps(row + j, _mm256_mul_ps(vec, norm_vec));\n        }\n        \n        // Handle remaining elements\n        for (size_t j = aligned_n; j < n; j++) {\n            row[j] *= norm;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_23_AVX", "completion": "```cpp\nvoid matrix_normalize_rows_simd(float* mat, size_t m, size_t n) {\n    const int simd_width = 8;\n    \n    for (size_t i = 0; i < m; i++) {\n        float* row = mat + i * n;\n        \n        __m256 sum_squares = _mm256_setzero_ps();\n        \n        // Calculate sum of squares using SIMD\n        size_t j = 0;\n        for (; j + simd_width <= n; j += simd_width) {\n            __m256 v = _mm256_loadu_ps(row + j);\n            sum_squares = _mm256_add_ps(sum_squares, _mm256_mul_ps(v, v));\n        }\n        \n        // Reduce sum_squares vector to single value\n        float norm = 0.0f;\n        float temp[8];\n        _mm256_storeu_ps(temp, sum_squares);\n        for (int k = 0; k < 8; k++) {\n            norm += temp[k];\n        }\n        \n        // Handle remaining elements\n        for (; j < n; j++) {\n            norm += row[j] * row[j];\n        }\n        \n        norm = 1.0f / sqrtf(norm);\n        __m256 norm_vec = _mm256_set1_ps(norm);\n        \n        // Normalize using SIMD\n        j = 0;\n        for (; j + simd_width <= n; j += simd_width) {\n            __m256 v = _mm256_loadu_ps(row + j);\n            _mm256_storeu_ps(row + j, _mm256_mul_ps(v, norm_vec));\n        }\n        \n        // Handle remaining elements\n        for (; j < n; j++) {\n            row[j] *= norm;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_23_AVX", "completion": "```cpp\nvoid matrix_normalize_rows_simd(float* mat, size_t m, size_t n) {\n    const size_t simd_width = 8;\n    const size_t aligned_n = (n / simd_width) * simd_width;\n    \n    for (size_t i = 0; i < m; i++) {\n        float* row = mat + i * n;\n        __m256 sum_squares = _mm256_setzero_ps();\n        \n        // Calculate sum of squares using SIMD\n        for (size_t j = 0; j < aligned_n; j += simd_width) {\n            __m256 vec = _mm256_loadu_ps(row + j);\n            sum_squares = _mm256_add_ps(sum_squares, _mm256_mul_ps(vec, vec));\n        }\n        \n        // Handle remaining elements\n        float row_norm = 0.0f;\n        float temp[8] __attribute__((aligned(32)));\n        _mm256_store_ps(temp, sum_squares);\n        for (size_t k = 0; k < 8; k++) {\n            row_norm += temp[k];\n        }\n        for (size_t j = aligned_n; j < n; j++) {\n            row_norm += row[j] * row[j];\n        }\n        \n        // Calculate row norm\n        row_norm = 1.0f / sqrtf(row_norm);\n        __m256 norm_vec = _mm256_set1_ps(row_norm);\n        \n        // Normalize row using SIMD\n        for (size_t j = 0; j < aligned_n; j += simd_width) {\n            __m256 vec = _mm256_loadu_ps(row + j);\n            _mm256_storeu_ps(row + j, _mm256_mul_ps(vec, norm_vec));\n        }\n        \n        // Handle remaining elements\n        for (size_t j = aligned_n; j < n; j++) {\n            row[j] *= row_norm;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_24_AVX", "completion": "```cpp\nvoid matrix_mul_round_int_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n, size_t p) {\n    for (size_t i = 0; i < m; i++) {\n        for (size_t j = 0; j < p; j++) {\n            __m256d sum = _mm256_setzero_pd();\n            \n            for (size_t k = 0; k < n; k += 4) {\n                size_t remaining = n - k;\n                if (remaining >= 4) {\n                    __m256d a = _mm256_loadu_pd(&mat1[i * n + k]);\n                    __m256d b = _mm256_set_pd(mat2[(k+3)*p + j],\n                                            mat2[(k+2)*p + j],\n                                            mat2[(k+1)*p + j],\n                                            mat2[k*p + j]);\n                    sum = _mm256_fmadd_pd(a, b, sum);\n                } else {\n                    double scalar_sum = 0.0;\n                    for (size_t r = 0; r < remaining; r++) {\n                        scalar_sum += mat1[i * n + k + r] * mat2[(k + r) * p + j];\n                    }\n                    sum = _mm256_add_pd(sum, _mm256_set1_pd(scalar_sum));\n                }\n            }\n\n            double temp[4];\n            _mm256_storeu_pd(temp, sum);\n            double final_sum = temp[0] + temp[1] + temp[2] + temp[3];\n            \n            dst[i * p + j] = round(final_sum);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_24_AVX", "completion": "```cpp\nvoid matrix_mul_round_int_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n, size_t p) {\n    for (size_t i = 0; i < m; i++) {\n        for (size_t j = 0; j < p; j++) {\n            __m256d sum = _mm256_setzero_pd();\n            size_t k;\n            \n            for (k = 0; k + 4 <= n; k += 4) {\n                __m256d a = _mm256_loadu_pd(&mat1[i * n + k]);\n                __m256d b = _mm256_set_pd(mat2[(k+3) * p + j],\n                                        mat2[(k+2) * p + j],\n                                        mat2[(k+1) * p + j],\n                                        mat2[k * p + j]);\n                sum = _mm256_add_pd(sum, _mm256_mul_pd(a, b));\n            }\n            \n            double temp[4];\n            _mm256_storeu_pd(temp, sum);\n            double result = temp[0] + temp[1] + temp[2] + temp[3];\n            \n            for (; k < n; k++) {\n                result += mat1[i * n + k] * mat2[k * p + j];\n            }\n            \n            dst[i * p + j] = round(result);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_24_AVX", "completion": "```cpp\nvoid matrix_mul_round_int_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n, size_t p) {\n    for (size_t i = 0; i < m; i++) {\n        for (size_t j = 0; j < p; j++) {\n            __m256d sum = _mm256_setzero_pd();\n            \n            for (size_t k = 0; k < n; k += 4) {\n                size_t remaining = n - k;\n                if (remaining >= 4) {\n                    __m256d a = _mm256_loadu_pd(&mat1[i * n + k]);\n                    __m256d b0 = _mm256_set_pd(mat2[(k+3)*p + j],\n                                              mat2[(k+2)*p + j],\n                                              mat2[(k+1)*p + j],\n                                              mat2[k*p + j]);\n                    sum = _mm256_fmadd_pd(a, b0, sum);\n                } else {\n                    for (size_t r = 0; r < remaining; r++) {\n                        sum = _mm256_add_pd(sum, \n                            _mm256_mul_pd(_mm256_set1_pd(mat1[i * n + k + r]),\n                                        _mm256_set1_pd(mat2[(k + r) * p + j])));\n                    }\n                }\n            }\n\n            __m256d temp = _mm256_hadd_pd(sum, sum);\n            double final_sum = ((double*)&temp)[0] + ((double*)&temp)[2];\n            \n            dst[i * p + j] = round(final_sum);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_24_AVX", "completion": "```cpp\nvoid matrix_mul_round_int_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n, size_t p) {\n    for (size_t i = 0; i < m; i++) {\n        for (size_t j = 0; j < p; j++) {\n            __m256d sum = _mm256_setzero_pd();\n            \n            for (size_t k = 0; k < n; k += 4) {\n                size_t remaining = n - k;\n                if (remaining >= 4) {\n                    __m256d a = _mm256_loadu_pd(&mat1[i * n + k]);\n                    __m256d b = _mm256_set_pd(\n                        mat2[(k + 3) * p + j],\n                        mat2[(k + 2) * p + j],\n                        mat2[(k + 1) * p + j],\n                        mat2[k * p + j]\n                    );\n                    sum = _mm256_fmadd_pd(a, b, sum);\n                } else {\n                    for (size_t r = 0; r < remaining; r++) {\n                        sum = _mm256_add_pd(sum, \n                            _mm256_mul_pd(\n                                _mm256_set1_pd(mat1[i * n + k + r]),\n                                _mm256_set1_pd(mat2[(k + r) * p + j])\n                            )\n                        );\n                    }\n                }\n            }\n            \n            __m256d temp = _mm256_hadd_pd(sum, sum);\n            double result = ((double*)&temp)[0] + ((double*)&temp)[2];\n            \n            dst[i * p + j] = round(result);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_24_AVX", "completion": "```cpp\nvoid matrix_mul_round_int_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n, size_t p) {\n    for (size_t i = 0; i < m; i++) {\n        for (size_t j = 0; j < p; j++) {\n            __m256d sum = _mm256_setzero_pd();\n            \n            for (size_t k = 0; k < n; k += 4) {\n                size_t remaining = n - k;\n                if (remaining >= 4) {\n                    __m256d a = _mm256_loadu_pd(&mat1[i * n + k]);\n                    __m256d b = _mm256_set_pd(mat2[(k+3)*p + j],\n                                            mat2[(k+2)*p + j],\n                                            mat2[(k+1)*p + j],\n                                            mat2[k*p + j]);\n                    sum = _mm256_fmadd_pd(a, b, sum);\n                } else {\n                    double scalar_sum = 0.0;\n                    for (size_t r = 0; r < remaining; r++) {\n                        scalar_sum += mat1[i * n + k + r] * mat2[(k + r) * p + j];\n                    }\n                    sum = _mm256_add_pd(sum, _mm256_set1_pd(scalar_sum));\n                }\n            }\n\n            __m256d temp = _mm256_hadd_pd(sum, sum);\n            double final_sum = ((double*)&temp)[0] + ((double*)&temp)[2];\n            \n            dst[i * p + j] = round(final_sum);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_25_AVX", "completion": "```cpp\nvoid matrix_transpose_round_quarter_simd(const float* src, float* dst, size_t rows, size_t cols) {\n    const __m256 quarter = _mm256_set1_ps(0.25f);\n    const __m256 four = _mm256_set1_ps(4.0f);\n    \n    for (size_t i = 0; i < rows; i += 8) {\n        for (size_t j = 0; j < cols; j += 8) {\n            __m256 row0 = _mm256_loadu_ps(&src[(i + 0) * cols + j]);\n            __m256 row1 = _mm256_loadu_ps(&src[(i + 1) * cols + j]);\n            __m256 row2 = _mm256_loadu_ps(&src[(i + 2) * cols + j]);\n            __m256 row3 = _mm256_loadu_ps(&src[(i + 3) * cols + j]);\n            __m256 row4 = _mm256_loadu_ps(&src[(i + 4) * cols + j]);\n            __m256 row5 = _mm256_loadu_ps(&src[(i + 5) * cols + j]);\n            __m256 row6 = _mm256_loadu_ps(&src[(i + 6) * cols + j]);\n            __m256 row7 = _mm256_loadu_ps(&src[(i + 7) * cols + j]);\n\n            // Round to nearest quarter by multiplying by 4, rounding, then dividing by 4\n            row0 = _mm256_mul_ps(row0, four);\n            row1 = _mm256_mul_ps(row1, four);\n            row2 = _mm256_mul_ps(row2, four);\n            row3 = _mm256_mul_ps(row3, four);\n            row4 = _mm256_mul_ps(row4, four);\n            row5 = _mm256_mul_ps(row5, four);\n            row6 = _mm256_mul_ps(row6, four);\n            row7 = _mm256_mul_ps(row7, four);\n\n            row0 = _mm256_round_ps(row0, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n            row1 = _mm256_round_ps(row1, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n            row2 = _mm256_round_ps(row2, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n            row3 = _mm256_round_ps(row3, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n            row4 = _mm256_round_ps(row4, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n            row5 = _mm256_round_ps(row5, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n            row6 = _mm256_round_ps(row6, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n            row7 = _mm256_round_ps(row7, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n\n            row0 = _mm256_mul_ps(row0, quarter);\n            row1 = _mm256_mul_ps(row1, quarter);\n            row2 = _mm256_mul_ps(row2, quarter);\n            row3 = _mm256_mul_ps(row3, quarter);\n            row4 = _mm256_mul_ps(row4, quarter);\n            row5 = _mm256_mul_ps(row5, quarter);\n            row6 = _mm256_mul_ps(row6, quarter);\n            row7 = _mm256_mul_ps(row7, quarter);\n\n            // Transpose 8x8 block\n            __m256 __t0, __t1, __t2, __t3, __t4, __t5, __t6, __t7;\n            __m256 __tt0, __tt1, __tt2, __tt3, __tt4, __tt5, __tt6, __tt7;\n            \n            __t0 = _mm256_unpacklo_ps(row0, row1);\n            __t1 = _mm256_unpackhi_ps(row0, row1);\n            __t2 = _mm256_unpacklo_ps(row2, row3);\n            __t3 = _mm256_unpackhi_ps(row2, row3);\n            __t4 = _mm256_unpacklo_ps(row4, row5);\n            __t5 = _mm256_unpackhi_ps(row4, row5);\n            __t6 = _mm256_unpacklo_ps(row6, row7);\n            __t7 = _mm256_unpackhi_ps(row6, row7);\n\n            __tt0 = _mm256_shuffle_ps(__t0, __t2, _MM_SHUFFLE(1, 0, 1, 0));\n            __tt1 = _mm256_shuffle_ps(__t0, __t2, _MM_SHUFFLE(3, 2, 3, 2));\n            __tt2 = _mm256_shuffle_ps(__t1, __t3, _MM_SHUFFLE(1, 0, 1, 0));\n            __tt3 = _mm256_shuffle_ps(__t1, __t3, _MM_SHUFFLE(3, 2, 3, 2));\n            __tt4 = _mm256_shuffle_ps(__t4, __t6, _MM_SHUFFLE(1, 0, 1, 0));\n            __tt5 = _mm256_shuffle_ps(__t4, __t6, _MM_SHUFFLE(3, 2, 3, 2));\n            __tt6 = _mm256_shuffle_ps(__t5, __t7, _MM_SHUFFLE(1, 0, 1, 0));\n            __tt7 = _mm256_shuffle_ps(__t5, __t7, _MM_SHUFFLE(3, 2, 3, 2));\n\n            row0 = _mm256_permute2f128_ps(__tt0, __tt4, 0x20);\n            row1 = _mm256_permute2f128_ps(__tt1, __tt5, 0x20);\n            row2 = _mm256_permute2f128_ps(__tt2, __tt6, 0x20);\n            row3 = _mm256_permute2f128_ps(__tt3, __tt7, 0x20);\n            row4 = _mm256_permute2f128_ps(__tt0, __tt4, 0x31);\n            row5 = _mm256_permute2f128_ps(__tt1, __tt5, 0x31);\n            row6 = _mm256_permute2f128_ps(__tt2, __tt6, 0x31);\n            row7 = _mm256_permute2f128_ps(__tt3, __tt7, 0x31);\n\n            _mm256_storeu_ps(&dst[j * rows + i], row0);\n            _mm256_storeu_ps(&dst[(j + 1) * rows + i], row1);\n            _mm256_storeu_ps(&dst[(j + 2) * rows + i], row2);\n            _mm256_storeu_ps(&dst[(j + 3) * rows + i], row3);\n            _mm256_storeu_ps(&dst[(j + 4) * rows + i], row4);\n            _mm256_storeu_ps(&dst[(j + 5) * rows + i], row5);\n            _mm256_storeu_ps(&dst[(j + 6) * rows + i], row6);\n            _mm256_storeu_ps(&dst[(j + 7) * rows + i], row7);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_25_AVX", "completion": "```cpp\nvoid matrix_transpose_round_quarter_simd(const float* src, float* dst, size_t rows, size_t cols) {\n    const __m256 quarter = _mm256_set1_ps(0.25f);\n    const __m256 four = _mm256_set1_ps(4.0f);\n    \n    for (size_t i = 0; i < rows; i += 8) {\n        for (size_t j = 0; j < cols; j += 8) {\n            __m256 row0 = _mm256_loadu_ps(&src[(i + 0) * cols + j]);\n            __m256 row1 = _mm256_loadu_ps(&src[(i + 1) * cols + j]);\n            __m256 row2 = _mm256_loadu_ps(&src[(i + 2) * cols + j]);\n            __m256 row3 = _mm256_loadu_ps(&src[(i + 3) * cols + j]);\n            __m256 row4 = _mm256_loadu_ps(&src[(i + 4) * cols + j]);\n            __m256 row5 = _mm256_loadu_ps(&src[(i + 5) * cols + j]);\n            __m256 row6 = _mm256_loadu_ps(&src[(i + 6) * cols + j]);\n            __m256 row7 = _mm256_loadu_ps(&src[(i + 7) * cols + j]);\n\n            // Round to nearest quarter by multiplying by 4, rounding, then dividing by 4\n            row0 = _mm256_mul_ps(row0, four);\n            row1 = _mm256_mul_ps(row1, four);\n            row2 = _mm256_mul_ps(row2, four);\n            row3 = _mm256_mul_ps(row3, four);\n            row4 = _mm256_mul_ps(row4, four);\n            row5 = _mm256_mul_ps(row5, four);\n            row6 = _mm256_mul_ps(row6, four);\n            row7 = _mm256_mul_ps(row7, four);\n\n            row0 = _mm256_round_ps(row0, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n            row1 = _mm256_round_ps(row1, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n            row2 = _mm256_round_ps(row2, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n            row3 = _mm256_round_ps(row3, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n            row4 = _mm256_round_ps(row4, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n            row5 = _mm256_round_ps(row5, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n            row6 = _mm256_round_ps(row6, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n            row7 = _mm256_round_ps(row7, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n\n            row0 = _mm256_mul_ps(row0, quarter);\n            row1 = _mm256_mul_ps(row1, quarter);\n            row2 = _mm256_mul_ps(row2, quarter);\n            row3 = _mm256_mul_ps(row3, quarter);\n            row4 = _mm256_mul_ps(row4, quarter);\n            row5 = _mm256_mul_ps(row5, quarter);\n            row6 = _mm256_mul_ps(row6, quarter);\n            row7 = _mm256_mul_ps(row7, quarter);\n\n            // Transpose 8x8 block\n            __m256 __t0, __t1, __t2, __t3, __t4, __t5, __t6, __t7;\n            __m256 __tt0, __tt1, __tt2, __tt3, __tt4, __tt5, __tt6, __tt7;\n            \n            __t0 = _mm256_unpacklo_ps(row0, row1);\n            __t1 = _mm256_unpackhi_ps(row0, row1);\n            __t2 = _mm256_unpacklo_ps(row2, row3);\n            __t3 = _mm256_unpackhi_ps(row2, row3);\n            __t4 = _mm256_unpacklo_ps(row4, row5);\n            __t5 = _mm256_unpackhi_ps(row4, row5);\n            __t6 = _mm256_unpacklo_ps(row6, row7);\n            __t7 = _mm256_unpackhi_ps(row6, row7);\n\n            __tt0 = _mm256_shuffle_ps(__t0, __t2, _MM_SHUFFLE(1, 0, 1, 0));\n            __tt1 = _mm256_shuffle_ps(__t0, __t2, _MM_SHUFFLE(3, 2, 3, 2));\n            __tt2 = _mm256_shuffle_ps(__t1, __t3, _MM_SHUFFLE(1, 0, 1, 0));\n            __tt3 = _mm256_shuffle_ps(__t1, __t3, _MM_SHUFFLE(3, 2, 3, 2));\n            __tt4 = _mm256_shuffle_ps(__t4, __t6, _MM_SHUFFLE(1, 0, 1, 0));\n            __tt5 = _mm256_shuffle_ps(__t4, __t6, _MM_SHUFFLE(3, 2, 3, 2));\n            __tt6 = _mm256_shuffle_ps(__t5, __t7, _MM_SHUFFLE(1, 0, 1, 0));\n            __tt7 = _mm256_shuffle_ps(__t5, __t7, _MM_SHUFFLE(3, 2, 3, 2));\n\n            row0 = _mm256_permute2f128_ps(__tt0, __tt4, 0x20);\n            row1 = _mm256_permute2f128_ps(__tt1, __tt5, 0x20);\n            row2 = _mm256_permute2f128_ps(__tt2, __tt6, 0x20);\n            row3 = _mm256_permute2f128_ps(__tt3, __tt7, 0x20);\n            row4 = _mm256_permute2f128_ps(__tt0, __tt4, 0x31);\n            row5 = _mm256_permute2f128_ps(__tt1, __tt5, 0x31);\n            row6 = _mm256_permute2f128_ps(__tt2, __tt6, 0x31);\n            row7 = _mm256_permute2f128_ps(__tt3, __tt7, 0x31);\n\n            _mm256_storeu_ps(&dst[j * rows + i], row0);\n            _mm256_storeu_ps(&dst[j * rows + i + rows], row1);\n            _mm256_storeu_ps(&dst[j * rows + i + rows * 2], row2);\n            _mm256_storeu_ps(&dst[j * rows + i + rows * 3], row3);\n            _mm256_storeu_ps(&dst[j * rows + i + rows * 4], row4);\n            _mm256_storeu_ps(&dst[j * rows + i + rows * 5], row5);\n            _mm256_storeu_ps(&dst[j * rows + i + rows * 6], row6);\n            _mm256_storeu_ps(&dst[j * rows + i + rows * 7], row7);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_25_AVX", "completion": "```cpp\nvoid matrix_transpose_round_quarter_simd(const float* src, float* dst, size_t rows, size_t cols) {\n    const __m256 quarter = _mm256_set1_ps(0.25f);\n    const __m256 four = _mm256_set1_ps(4.0f);\n    \n    for (size_t i = 0; i < rows; i += 8) {\n        for (size_t j = 0; j < cols; j += 8) {\n            __m256 row0 = _mm256_loadu_ps(&src[(i + 0) * cols + j]);\n            __m256 row1 = _mm256_loadu_ps(&src[(i + 1) * cols + j]);\n            __m256 row2 = _mm256_loadu_ps(&src[(i + 2) * cols + j]);\n            __m256 row3 = _mm256_loadu_ps(&src[(i + 3) * cols + j]);\n            __m256 row4 = _mm256_loadu_ps(&src[(i + 4) * cols + j]);\n            __m256 row5 = _mm256_loadu_ps(&src[(i + 5) * cols + j]);\n            __m256 row6 = _mm256_loadu_ps(&src[(i + 6) * cols + j]);\n            __m256 row7 = _mm256_loadu_ps(&src[(i + 7) * cols + j]);\n\n            // Round to nearest quarter by multiplying by 4, rounding, then dividing by 4\n            row0 = _mm256_mul_ps(row0, four);\n            row1 = _mm256_mul_ps(row1, four);\n            row2 = _mm256_mul_ps(row2, four);\n            row3 = _mm256_mul_ps(row3, four);\n            row4 = _mm256_mul_ps(row4, four);\n            row5 = _mm256_mul_ps(row5, four);\n            row6 = _mm256_mul_ps(row6, four);\n            row7 = _mm256_mul_ps(row7, four);\n\n            row0 = _mm256_round_ps(row0, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n            row1 = _mm256_round_ps(row1, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n            row2 = _mm256_round_ps(row2, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n            row3 = _mm256_round_ps(row3, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n            row4 = _mm256_round_ps(row4, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n            row5 = _mm256_round_ps(row5, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n            row6 = _mm256_round_ps(row6, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n            row7 = _mm256_round_ps(row7, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n\n            row0 = _mm256_mul_ps(row0, quarter);\n            row1 = _mm256_mul_ps(row1, quarter);\n            row2 = _mm256_mul_ps(row2, quarter);\n            row3 = _mm256_mul_ps(row3, quarter);\n            row4 = _mm256_mul_ps(row4, quarter);\n            row5 = _mm256_mul_ps(row5, quarter);\n            row6 = _mm256_mul_ps(row6, quarter);\n            row7 = _mm256_mul_ps(row7, quarter);\n\n            // Transpose 8x8 block\n            __m256 __t0, __t1, __t2, __t3, __t4, __t5, __t6, __t7;\n            __m256 __tt0, __tt1, __tt2, __tt3, __tt4, __tt5, __tt6, __tt7;\n            \n            __t0 = _mm256_unpacklo_ps(row0, row1);\n            __t1 = _mm256_unpackhi_ps(row0, row1);\n            __t2 = _mm256_unpacklo_ps(row2, row3);\n            __t3 = _mm256_unpackhi_ps(row2, row3);\n            __t4 = _mm256_unpacklo_ps(row4, row5);\n            __t5 = _mm256_unpackhi_ps(row4, row5);\n            __t6 = _mm256_unpacklo_ps(row6, row7);\n            __t7 = _mm256_unpackhi_ps(row6, row7);\n\n            __tt0 = _mm256_shuffle_ps(__t0, __t2, _MM_SHUFFLE(1, 0, 1, 0));\n            __tt1 = _mm256_shuffle_ps(__t0, __t2, _MM_SHUFFLE(3, 2, 3, 2));\n            __tt2 = _mm256_shuffle_ps(__t1, __t3, _MM_SHUFFLE(1, 0, 1, 0));\n            __tt3 = _mm256_shuffle_ps(__t1, __t3, _MM_SHUFFLE(3, 2, 3, 2));\n            __tt4 = _mm256_shuffle_ps(__t4, __t6, _MM_SHUFFLE(1, 0, 1, 0));\n            __tt5 = _mm256_shuffle_ps(__t4, __t6, _MM_SHUFFLE(3, 2, 3, 2));\n            __tt6 = _mm256_shuffle_ps(__t5, __t7, _MM_SHUFFLE(1, 0, 1, 0));\n            __tt7 = _mm256_shuffle_ps(__t5, __t7, _MM_SHUFFLE(3, 2, 3, 2));\n\n            row0 = _mm256_permute2f128_ps(__tt0, __tt4, 0x20);\n            row1 = _mm256_permute2f128_ps(__tt1, __tt5, 0x20);\n            row2 = _mm256_permute2f128_ps(__tt2, __tt6, 0x20);\n            row3 = _mm256_permute2f128_ps(__tt3, __tt7, 0x20);\n            row4 = _mm256_permute2f128_ps(__tt0, __tt4, 0x31);\n            row5 = _mm256_permute2f128_ps(__tt1, __tt5, 0x31);\n            row6 = _mm256_permute2f128_ps(__tt2, __tt6, 0x31);\n            row7 = _mm256_permute2f128_ps(__tt3, __tt7, 0x31);\n\n            _mm256_storeu_ps(&dst[j * rows + i], row0);\n            _mm256_storeu_ps(&dst[(j + 1) * rows + i], row1);\n            _mm256_storeu_ps(&dst[(j + 2) * rows + i], row2);\n            _mm256_storeu_ps(&dst[(j + 3) * rows + i], row3);\n            _mm256_storeu_ps(&dst[(j + 4) * rows + i], row4);\n            _mm256_storeu_ps(&dst[(j + 5) * rows + i], row5);\n            _mm256_storeu_ps(&dst[(j + 6) * rows + i], row6);\n            _mm256_storeu_ps(&dst[(j + 7) * rows + i], row7);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_25_AVX", "completion": "```cpp\nvoid matrix_transpose_round_quarter_simd(const float* src, float* dst, size_t rows, size_t cols) {\n    const __m256 quarter = _mm256_set1_ps(0.25f);\n    const __m256 four = _mm256_set1_ps(4.0f);\n    \n    for (size_t i = 0; i < rows; i += 8) {\n        for (size_t j = 0; j < cols; j += 8) {\n            __m256 row0 = _mm256_loadu_ps(&src[(i + 0) * cols + j]);\n            __m256 row1 = _mm256_loadu_ps(&src[(i + 1) * cols + j]);\n            __m256 row2 = _mm256_loadu_ps(&src[(i + 2) * cols + j]);\n            __m256 row3 = _mm256_loadu_ps(&src[(i + 3) * cols + j]);\n            __m256 row4 = _mm256_loadu_ps(&src[(i + 4) * cols + j]);\n            __m256 row5 = _mm256_loadu_ps(&src[(i + 5) * cols + j]);\n            __m256 row6 = _mm256_loadu_ps(&src[(i + 6) * cols + j]);\n            __m256 row7 = _mm256_loadu_ps(&src[(i + 7) * cols + j]);\n\n            // Round to nearest quarter by multiplying by 4, rounding, then dividing by 4\n            row0 = _mm256_mul_ps(row0, four);\n            row1 = _mm256_mul_ps(row1, four);\n            row2 = _mm256_mul_ps(row2, four);\n            row3 = _mm256_mul_ps(row3, four);\n            row4 = _mm256_mul_ps(row4, four);\n            row5 = _mm256_mul_ps(row5, four);\n            row6 = _mm256_mul_ps(row6, four);\n            row7 = _mm256_mul_ps(row7, four);\n\n            row0 = _mm256_round_ps(row0, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n            row1 = _mm256_round_ps(row1, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n            row2 = _mm256_round_ps(row2, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n            row3 = _mm256_round_ps(row3, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n            row4 = _mm256_round_ps(row4, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n            row5 = _mm256_round_ps(row5, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n            row6 = _mm256_round_ps(row6, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n            row7 = _mm256_round_ps(row7, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n\n            row0 = _mm256_mul_ps(row0, quarter);\n            row1 = _mm256_mul_ps(row1, quarter);\n            row2 = _mm256_mul_ps(row2, quarter);\n            row3 = _mm256_mul_ps(row3, quarter);\n            row4 = _mm256_mul_ps(row4, quarter);\n            row5 = _mm256_mul_ps(row5, quarter);\n            row6 = _mm256_mul_ps(row6, quarter);\n            row7 = _mm256_mul_ps(row7, quarter);\n\n            // Transpose 8x8 block\n            __m256 __t0, __t1, __t2, __t3, __t4, __t5, __t6, __t7;\n            __m256 __tt0, __tt1, __tt2, __tt3, __tt4, __tt5, __tt6, __tt7;\n            \n            __t0 = _mm256_unpacklo_ps(row0, row1);\n            __t1 = _mm256_unpackhi_ps(row0, row1);\n            __t2 = _mm256_unpacklo_ps(row2, row3);\n            __t3 = _mm256_unpackhi_ps(row2, row3);\n            __t4 = _mm256_unpacklo_ps(row4, row5);\n            __t5 = _mm256_unpackhi_ps(row4, row5);\n            __t6 = _mm256_unpacklo_ps(row6, row7);\n            __t7 = _mm256_unpackhi_ps(row6, row7);\n\n            __tt0 = _mm256_shuffle_ps(__t0, __t2, _MM_SHUFFLE(1, 0, 1, 0));\n            __tt1 = _mm256_shuffle_ps(__t0, __t2, _MM_SHUFFLE(3, 2, 3, 2));\n            __tt2 = _mm256_shuffle_ps(__t1, __t3, _MM_SHUFFLE(1, 0, 1, 0));\n            __tt3 = _mm256_shuffle_ps(__t1, __t3, _MM_SHUFFLE(3, 2, 3, 2));\n            __tt4 = _mm256_shuffle_ps(__t4, __t6, _MM_SHUFFLE(1, 0, 1, 0));\n            __tt5 = _mm256_shuffle_ps(__t4, __t6, _MM_SHUFFLE(3, 2, 3, 2));\n            __tt6 = _mm256_shuffle_ps(__t5, __t7, _MM_SHUFFLE(1, 0, 1, 0));\n            __tt7 = _mm256_shuffle_ps(__t5, __t7, _MM_SHUFFLE(3, 2, 3, 2));\n\n            row0 = _mm256_permute2f128_ps(__tt0, __tt4, 0x20);\n            row1 = _mm256_permute2f128_ps(__tt1, __tt5, 0x20);\n            row2 = _mm256_permute2f128_ps(__tt2, __tt6, 0x20);\n            row3 = _mm256_permute2f128_ps(__tt3, __tt7, 0x20);\n            row4 = _mm256_permute2f128_ps(__tt0, __tt4, 0x31);\n            row5 = _mm256_permute2f128_ps(__tt1, __tt5, 0x31);\n            row6 = _mm256_permute2f128_ps(__tt2, __tt6, 0x31);\n            row7 = _mm256_permute2f128_ps(__tt3, __tt7, 0x31);\n\n            _mm256_storeu_ps(&dst[j * rows + i], row0);\n            _mm256_storeu_ps(&dst[(j + 1) * rows + i], row1);\n            _mm256_storeu_ps(&dst[(j + 2) * rows + i], row2);\n            _mm256_storeu_ps(&dst[(j + 3) * rows + i], row3);\n            _mm256_storeu_ps(&dst[(j + 4) * rows + i], row4);\n            _mm256_storeu_ps(&dst[(j + 5) * rows + i], row5);\n            _mm256_storeu_ps(&dst[(j + 6) * rows + i], row6);\n            _mm256_storeu_ps(&dst[(j + 7) * rows + i], row7);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_25_AVX", "completion": "```cpp\nvoid matrix_transpose_round_quarter_simd(const float* src, float* dst, size_t rows, size_t cols) {\n    const __m256 quarter = _mm256_set1_ps(0.25f);\n    const __m256 recip_quarter = _mm256_set1_ps(4.0f);\n    \n    for (size_t i = 0; i < rows; i += 8) {\n        for (size_t j = 0; j < cols; j += 8) {\n            __m256 row0 = (j + 7 < cols) ? _mm256_loadu_ps(&src[(i + 0) * cols + j]) : _mm256_setzero_ps();\n            __m256 row1 = (i + 1 < rows && j + 7 < cols) ? _mm256_loadu_ps(&src[(i + 1) * cols + j]) : _mm256_setzero_ps();\n            __m256 row2 = (i + 2 < rows && j + 7 < cols) ? _mm256_loadu_ps(&src[(i + 2) * cols + j]) : _mm256_setzero_ps();\n            __m256 row3 = (i + 3 < rows && j + 7 < cols) ? _mm256_loadu_ps(&src[(i + 3) * cols + j]) : _mm256_setzero_ps();\n            __m256 row4 = (i + 4 < rows && j + 7 < cols) ? _mm256_loadu_ps(&src[(i + 4) * cols + j]) : _mm256_setzero_ps();\n            __m256 row5 = (i + 5 < rows && j + 7 < cols) ? _mm256_loadu_ps(&src[(i + 5) * cols + j]) : _mm256_setzero_ps();\n            __m256 row6 = (i + 6 < rows && j + 7 < cols) ? _mm256_loadu_ps(&src[(i + 6) * cols + j]) : _mm256_setzero_ps();\n            __m256 row7 = (i + 7 < rows && j + 7 < cols) ? _mm256_loadu_ps(&src[(i + 7) * cols + j]) : _mm256_setzero_ps();\n\n            // Round to nearest quarter by multiplying by 4, rounding, then dividing by 4\n            row0 = _mm256_mul_ps(_mm256_round_ps(_mm256_mul_ps(row0, recip_quarter), _MM_FROUND_TO_NEAREST_INT), quarter);\n            row1 = _mm256_mul_ps(_mm256_round_ps(_mm256_mul_ps(row1, recip_quarter), _MM_FROUND_TO_NEAREST_INT), quarter);\n            row2 = _mm256_mul_ps(_mm256_round_ps(_mm256_mul_ps(row2, recip_quarter), _MM_FROUND_TO_NEAREST_INT), quarter);\n            row3 = _mm256_mul_ps(_mm256_round_ps(_mm256_mul_ps(row3, recip_quarter), _MM_FROUND_TO_NEAREST_INT), quarter);\n            row4 = _mm256_mul_ps(_mm256_round_ps(_mm256_mul_ps(row4, recip_quarter), _MM_FROUND_TO_NEAREST_INT), quarter);\n            row5 = _mm256_mul_ps(_mm256_round_ps(_mm256_mul_ps(row5, recip_quarter), _MM_FROUND_TO_NEAREST_INT), quarter);\n            row6 = _mm256_mul_ps(_mm256_round_ps(_mm256_mul_ps(row6, recip_quarter), _MM_FROUND_TO_NEAREST_INT), quarter);\n            row7 = _mm256_mul_ps(_mm256_round_ps(_mm256_mul_ps(row7, recip_quarter), _MM_FROUND_TO_NEAREST_INT), quarter);\n\n            // Transpose 8x8 block\n            __m256 __t0, __t1, __t2, __t3, __t4, __t5, __t6, __t7;\n            __m256 __tt0, __tt1, __tt2, __tt3, __tt4, __tt5, __tt6, __tt7;\n            \n            __t0 = _mm256_unpacklo_ps(row0, row1);\n            __t1 = _mm256_unpackhi_ps(row0, row1);\n            __t2 = _mm256_unpacklo_ps(row2, row3);\n            __t3 = _mm256_unpackhi_ps(row2, row3);\n            __t4 = _mm256_unpacklo_ps(row4, row5);\n            __t5 = _mm256_unpackhi_ps(row4, row5);\n            __t6 = _mm256_unpacklo_ps(row6, row7);\n            __t7 = _mm256_unpackhi_ps(row6, row7);\n\n            __tt0 = _mm256_shuffle_ps(__t0, __t2, _MM_SHUFFLE(1, 0, 1, 0));\n            __tt1 = _mm256_shuffle_ps(__t0, __t2, _MM_SHUFFLE(3, 2, 3, 2));\n            __tt2 = _mm256_shuffle_ps(__t1, __t3, _MM_SHUFFLE(1, 0, 1, 0));\n            __tt3 = _mm256_shuffle_ps(__t1, __t3, _MM_SHUFFLE(3, 2, 3, 2));\n            __tt4 = _mm256_shuffle_ps(__t4, __t6, _MM_SHUFFLE(1, 0, 1, 0));\n            __tt5 = _mm256_shuffle_ps(__t4, __t6, _MM_SHUFFLE(3, 2, 3, 2));\n            __tt6 = _mm256_shuffle_ps(__t5, __t7, _MM_SHUFFLE(1, 0, 1, 0));\n            __tt7 = _mm256_shuffle_ps(__t5, __t7, _MM_SHUFFLE(3, 2, 3, 2));\n\n            row0 = _mm256_permute2f128_ps(__tt0, __tt4, 0x20);\n            row1 = _mm256_permute2f128_ps(__tt1, __tt5, 0x20);\n            row2 = _mm256_permute2f128_ps(__tt2, __tt6, 0x20);\n            row3 = _mm256_permute2f128_ps(__tt3, __tt7, 0x20);\n            row4 = _mm256_permute2f128_ps(__tt0, __tt4, 0x31);\n            row5 = _mm256_permute2f128_ps(__tt1, __tt5, 0x31);\n            row6 = _mm256_permute2f128_ps(__tt2, __tt6, 0x31);\n            row7 = _mm256_permute2f128_ps(__tt3, __tt7, 0x31);\n\n            if (j + 7 < cols && i + 7 < rows) {\n                _mm256_storeu_ps(&dst[j * rows + i], row0);\n                _mm256_storeu_ps(&dst[(j + 1) * rows + i], row1);\n                _mm256_storeu_ps(&dst[(j + 2) * rows + i], row2);\n                _mm256_storeu_ps(&dst[(j + 3) * rows + i], row3);\n                _mm256_storeu_ps(&dst[(j + 4) * rows + i], row4);\n                _mm256_storeu_ps(&dst[(j + 5) * rows + i], row5);\n                _mm256_storeu_ps(&dst[(j + 6) * rows + i], row6);\n                _mm256_storeu_ps(&dst[(j + 7) * rows + i], row7);\n            } else {\n                // Handle edge cases\n                for (size_t k = 0; k < 8; k++) {\n                    if (j + k >= cols) break;\n                    for (size_t l = 0; l < 8; l++) {\n                        if (i + l >= rows) break;\n                        dst[(j + k) * rows + (i + l)] = ((float*)&row0)[k * 8 + l];\n                    }\n                }\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_26_AVX", "completion": "```cpp\nvoid tensor3d_sub_round_zero_simd(const float* tensor1, const float* tensor2, float* dst, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_size = dim1 * dim2 * dim3;\n    size_t vec_size = total_size / 8;\n    size_t remainder = total_size % 8;\n\n    __m256 t1, t2, result;\n    \n    for (size_t i = 0; i < vec_size; i++) {\n        t1 = _mm256_loadu_ps(tensor1 + i * 8);\n        t2 = _mm256_loadu_ps(tensor2 + i * 8);\n        result = _mm256_sub_ps(t1, t2);\n        result = _mm256_round_ps(result, _MM_FROUND_TO_ZERO |_MM_FROUND_NO_EXC);\n        _mm256_storeu_ps(dst + i * 8, result);\n    }\n\n    // Handle remaining elements\n    for (size_t i = vec_size * 8; i < total_size; i++) {\n        dst[i] = truncf(tensor1[i] - tensor2[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_26_AVX", "completion": "```cpp\nvoid tensor3d_sub_round_zero_simd(const float* tensor1, const float* tensor2, float* dst, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_size = dim1 * dim2 * dim3;\n    size_t vec_size = total_size / 8;\n    size_t remainder = total_size % 8;\n\n    for (size_t i = 0; i < vec_size; i++) {\n        __m256 v1 = _mm256_loadu_ps(tensor1 + i * 8);\n        __m256 v2 = _mm256_loadu_ps(tensor2 + i * 8);\n        __m256 diff = _mm256_sub_ps(v1, v2);\n        __m256 rounded = _mm256_round_ps(diff, _MM_FROUND_TO_ZERO | _MM_FROUND_NO_EXC);\n        _mm256_storeu_ps(dst + i * 8, rounded);\n    }\n\n    size_t offset = vec_size * 8;\n    for (size_t i = 0; i < remainder; i++) {\n        dst[offset + i] = truncf(tensor1[offset + i] - tensor2[offset + i]);\n    }\n}\n```"}
{"task_id": "SimdBench_26_AVX", "completion": "```cpp\nvoid tensor3d_sub_round_zero_simd(const float* tensor1, const float* tensor2, float* dst, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_size = dim1 * dim2 * dim3;\n    size_t vec_size = total_size / 8;\n    size_t remainder = total_size % 8;\n\n    __m256 t1, t2, result;\n    \n    for (size_t i = 0; i < vec_size; i++) {\n        t1 = _mm256_loadu_ps(tensor1 + i * 8);\n        t2 = _mm256_loadu_ps(tensor2 + i * 8);\n        result = _mm256_sub_ps(t1, t2);\n        result = _mm256_round_ps(result, _MM_FROUND_TO_ZERO | _MM_FROUND_NO_EXC);\n        _mm256_storeu_ps(dst + i * 8, result);\n    }\n\n    // Handle remaining elements\n    for (size_t i = vec_size * 8; i < total_size; i++) {\n        dst[i] = truncf(tensor1[i] - tensor2[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_26_AVX", "completion": "```cpp\nvoid tensor3d_sub_round_zero_simd(const float* tensor1, const float* tensor2, float* dst, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_size = dim1 * dim2 * dim3;\n    size_t vec_size = total_size / 8;\n    size_t remainder = total_size % 8;\n\n    for (size_t i = 0; i < vec_size; i++) {\n        __m256 v1 = _mm256_loadu_ps(tensor1 + i * 8);\n        __m256 v2 = _mm256_loadu_ps(tensor2 + i * 8);\n        __m256 diff = _mm256_sub_ps(v1, v2);\n        __m256 rounded = _mm256_round_ps(diff, _MM_FROUND_TO_ZERO | _MM_FROUND_NO_EXC);\n        _mm256_storeu_ps(dst + i * 8, rounded);\n    }\n\n    size_t offset = vec_size * 8;\n    for (size_t i = 0; i < remainder; i++) {\n        dst[offset + i] = truncf(tensor1[offset + i] - tensor2[offset + i]);\n    }\n}\n```"}
{"task_id": "SimdBench_26_AVX", "completion": "```cpp\nvoid tensor3d_sub_round_zero_simd(const float* tensor1, const float* tensor2, float* dst, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_size = dim1 * dim2 * dim3;\n    size_t vec_size = total_size / 8;\n    size_t remainder = total_size % 8;\n\n    for (size_t i = 0; i < vec_size; i++) {\n        __m256 v1 = _mm256_loadu_ps(tensor1 + i * 8);\n        __m256 v2 = _mm256_loadu_ps(tensor2 + i * 8);\n        __m256 sub = _mm256_sub_ps(v1, v2);\n        __m256 rounded = _mm256_round_ps(sub, _MM_FROUND_TO_ZERO | _MM_FROUND_NO_EXC);\n        _mm256_storeu_ps(dst + i * 8, rounded);\n    }\n\n    size_t offset = vec_size * 8;\n    for (size_t i = 0; i < remainder; i++) {\n        dst[offset + i] = truncf(tensor1[offset + i] - tensor2[offset + i]);\n    }\n}\n```"}
{"task_id": "SimdBench_27_AVX", "completion": "```cpp\nvoid matrix_hadamard_product_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n) {\n    size_t total = m * n;\n    size_t i = 0;\n    \n    // Process 4 elements at a time using AVX\n    for (; i + 3 < total; i += 4) {\n        __m256d v1 = _mm256_loadu_pd(mat1 + i);\n        __m256d v2 = _mm256_loadu_pd(mat2 + i);\n        __m256d result = _mm256_mul_pd(v1, v2);\n        _mm256_storeu_pd(dst + i, result);\n    }\n    \n    // Handle remaining elements\n    for (; i < total; i++) {\n        dst[i] = mat1[i] * mat2[i];\n    }\n}\n```"}
{"task_id": "SimdBench_27_AVX", "completion": "```cpp\nvoid matrix_hadamard_product_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n) {\n    size_t total = m * n;\n    size_t i;\n    \n    // Process 4 elements at a time using AVX\n    size_t simd_width = total / 4;\n    for (i = 0; i < simd_width * 4; i += 4) {\n        __m256d v1 = _mm256_loadu_pd(&mat1[i]);\n        __m256d v2 = _mm256_loadu_pd(&mat2[i]);\n        __m256d result = _mm256_mul_pd(v1, v2);\n        _mm256_storeu_pd(&dst[i], result);\n    }\n    \n    // Handle remaining elements\n    for (; i < total; i++) {\n        dst[i] = mat1[i] * mat2[i];\n    }\n}\n```"}
{"task_id": "SimdBench_27_AVX", "completion": "```cpp\nvoid matrix_hadamard_product_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n) {\n    size_t total = m * n;\n    size_t i = 0;\n    \n    // Process 4 elements at a time using AVX\n    for (; i + 3 < total; i += 4) {\n        __m256d v1 = _mm256_loadu_pd(&mat1[i]);\n        __m256d v2 = _mm256_loadu_pd(&mat2[i]);\n        __m256d result = _mm256_mul_pd(v1, v2);\n        _mm256_storeu_pd(&dst[i], result);\n    }\n    \n    // Handle remaining elements\n    for (; i < total; i++) {\n        dst[i] = mat1[i] * mat2[i];\n    }\n}\n```"}
{"task_id": "SimdBench_27_AVX", "completion": "```cpp\nvoid matrix_hadamard_product_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n) {\n    size_t total = m * n;\n    size_t i = 0;\n    \n    // Process 4 elements at a time using AVX\n    for (; i + 4 <= total; i += 4) {\n        __m256d v1 = _mm256_loadu_pd(&mat1[i]);\n        __m256d v2 = _mm256_loadu_pd(&mat2[i]);\n        __m256d result = _mm256_mul_pd(v1, v2);\n        _mm256_storeu_pd(&dst[i], result);\n    }\n    \n    // Handle remaining elements\n    for (; i < total; i++) {\n        dst[i] = mat1[i] * mat2[i];\n    }\n}\n```"}
{"task_id": "SimdBench_27_AVX", "completion": "```cpp\nvoid matrix_hadamard_product_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n) {\n    size_t total = m * n;\n    size_t i = 0;\n    \n    // Process 4 elements at a time using AVX\n    for (; i + 3 < total; i += 4) {\n        __m256d v1 = _mm256_loadu_pd(&mat1[i]);\n        __m256d v2 = _mm256_loadu_pd(&mat2[i]);\n        __m256d result = _mm256_mul_pd(v1, v2);\n        _mm256_storeu_pd(&dst[i], result);\n    }\n    \n    // Handle remaining elements\n    for (; i < total; i++) {\n        dst[i] = mat1[i] * mat2[i];\n    }\n}\n```"}
{"task_id": "SimdBench_28_AVX", "completion": "```cpp\nvoid matrix_vector_mul_simd(const float* mat, const float* vec, float* dst, size_t m, size_t n) {\n    const size_t SIMD_WIDTH = 8;\n    const size_t n_aligned = n & ~(SIMD_WIDTH-1);\n    \n    for (size_t i = 0; i < m; i++) {\n        __m256 sum = _mm256_setzero_ps();\n        const float* row = mat + i * n;\n        \n        for (size_t j = 0; j < n_aligned; j += SIMD_WIDTH) {\n            __m256 a = _mm256_loadu_ps(row + j);\n            __m256 b = _mm256_loadu_ps(vec + j);\n            sum = _mm256_add_ps(sum, _mm256_mul_ps(a, b));\n        }\n        \n        float temp[SIMD_WIDTH];\n        _mm256_storeu_ps(temp, sum);\n        float result = 0.0f;\n        for (size_t k = 0; k < SIMD_WIDTH; k++) {\n            result += temp[k];\n        }\n        \n        for (size_t j = n_aligned; j < n; j++) {\n            result += row[j] * vec[j];\n        }\n        \n        dst[i] = result;\n    }\n}\n```"}
{"task_id": "SimdBench_28_AVX", "completion": "```cpp\nvoid matrix_vector_mul_simd(const float* mat, const float* vec, float* dst, size_t m, size_t n) {\n    const size_t SIMD_WIDTH = 8;\n    const size_t n_aligned = n & ~(SIMD_WIDTH-1);\n    \n    for (size_t i = 0; i < m; i++) {\n        __m256 sum = _mm256_setzero_ps();\n        const float* row = mat + i * n;\n        \n        for (size_t j = 0; j < n_aligned; j += SIMD_WIDTH) {\n            __m256 a = _mm256_loadu_ps(row + j);\n            __m256 b = _mm256_loadu_ps(vec + j);\n            sum = _mm256_add_ps(sum, _mm256_mul_ps(a, b));\n        }\n        \n        float temp[SIMD_WIDTH];\n        _mm256_storeu_ps(temp, sum);\n        float result = 0.0f;\n        for (size_t k = 0; k < SIMD_WIDTH; k++) {\n            result += temp[k];\n        }\n        \n        for (size_t j = n_aligned; j < n; j++) {\n            result += row[j] * vec[j];\n        }\n        \n        dst[i] = result;\n    }\n}\n```"}
{"task_id": "SimdBench_28_AVX", "completion": "```cpp\nvoid matrix_vector_mul_simd(const float* mat, const float* vec, float* dst, size_t m, size_t n) {\n    const size_t SIMD_WIDTH = 8;\n    const size_t n_aligned = n & ~(SIMD_WIDTH-1);\n    \n    for (size_t i = 0; i < m; i++) {\n        __m256 sum = _mm256_setzero_ps();\n        const float* row = mat + i * n;\n        \n        for (size_t j = 0; j < n_aligned; j += SIMD_WIDTH) {\n            __m256 a = _mm256_loadu_ps(row + j);\n            __m256 b = _mm256_loadu_ps(vec + j);\n            sum = _mm256_add_ps(sum, _mm256_mul_ps(a, b));\n        }\n        \n        float temp[SIMD_WIDTH];\n        _mm256_storeu_ps(temp, sum);\n        float result = 0.0f;\n        for (size_t k = 0; k < SIMD_WIDTH; k++) {\n            result += temp[k];\n        }\n        \n        for (size_t j = n_aligned; j < n; j++) {\n            result += row[j] * vec[j];\n        }\n        \n        dst[i] = result;\n    }\n}\n```"}
{"task_id": "SimdBench_28_AVX", "completion": "```cpp\nvoid matrix_vector_mul_simd(const float* mat, const float* vec, float* dst, size_t m, size_t n) {\n    const size_t SIMD_WIDTH = 8;\n    const size_t n_aligned = n & ~(SIMD_WIDTH-1);\n    \n    for (size_t i = 0; i < m; i++) {\n        __m256 sum = _mm256_setzero_ps();\n        const float* row = mat + i * n;\n        \n        for (size_t j = 0; j < n_aligned; j += SIMD_WIDTH) {\n            __m256 a = _mm256_loadu_ps(row + j);\n            __m256 b = _mm256_loadu_ps(vec + j);\n            sum = _mm256_add_ps(sum, _mm256_mul_ps(a, b));\n        }\n        \n        float temp[SIMD_WIDTH];\n        _mm256_storeu_ps(temp, sum);\n        float result = 0.0f;\n        for (size_t k = 0; k < SIMD_WIDTH; k++) {\n            result += temp[k];\n        }\n        \n        for (size_t j = n_aligned; j < n; j++) {\n            result += row[j] * vec[j];\n        }\n        \n        dst[i] = result;\n    }\n}\n```"}
{"task_id": "SimdBench_28_AVX", "completion": "```cpp\nvoid matrix_vector_mul_simd(const float* mat, const float* vec, float* dst, size_t m, size_t n) {\n    const size_t SIMD_WIDTH = 8;\n    const size_t n_aligned = n & ~(SIMD_WIDTH-1);\n    \n    for (size_t i = 0; i < m; i++) {\n        __m256 sum = _mm256_setzero_ps();\n        const float* row = mat + i * n;\n        \n        for (size_t j = 0; j < n_aligned; j += SIMD_WIDTH) {\n            __m256 a = _mm256_loadu_ps(row + j);\n            __m256 b = _mm256_loadu_ps(vec + j);\n            sum = _mm256_add_ps(sum, _mm256_mul_ps(a, b));\n        }\n        \n        float temp[SIMD_WIDTH];\n        _mm256_storeu_ps(temp, sum);\n        float result = 0.0f;\n        for (size_t k = 0; k < SIMD_WIDTH; k++) {\n            result += temp[k];\n        }\n        \n        for (size_t j = n_aligned; j < n; j++) {\n            result += row[j] * vec[j];\n        }\n        \n        dst[i] = result;\n    }\n}\n```"}
{"task_id": "SimdBench_29_AVX", "completion": "```cpp\ndouble matrix_average_simd(const double* mat, size_t m, size_t n) {\n    __m256d sum = _mm256_setzero_pd();\n    size_t total = m * n;\n    size_t i = 0;\n    \n    // Process 4 elements at a time\n    for (; i + 3 < total; i += 4) {\n        __m256d v = _mm256_loadu_pd(&mat[i]);\n        sum = _mm256_add_pd(sum, v);\n    }\n    \n    // Horizontal sum of vector\n    __m256d temp = _mm256_hadd_pd(sum, sum);\n    __m128d high = _mm256_extractf128_pd(temp, 1);\n    __m128d low = _mm256_castpd256_pd128(temp);\n    __m128d result = _mm_add_pd(high, low);\n    double final_sum = _mm_cvtsd_f64(result);\n    \n    // Handle remaining elements\n    for (; i < total; i++) {\n        final_sum += mat[i];\n    }\n    \n    return final_sum / total;\n}\n```"}
{"task_id": "SimdBench_29_AVX", "completion": "```cpp\ndouble matrix_average_simd(const double* mat, size_t m, size_t n) {\n    __m256d sum_vec = _mm256_setzero_pd();\n    size_t total = m * n;\n    size_t i = 0;\n    \n    // Process 4 elements at a time\n    for (; i + 3 < total; i += 4) {\n        __m256d vec = _mm256_loadu_pd(&mat[i]);\n        sum_vec = _mm256_add_pd(sum_vec, vec);\n    }\n    \n    // Reduce vector sum to scalar\n    double sum = 0.0;\n    double temp[4];\n    _mm256_storeu_pd(temp, sum_vec);\n    sum = temp[0] + temp[1] + temp[2] + temp[3];\n    \n    // Handle remaining elements\n    for (; i < total; i++) {\n        sum += mat[i];\n    }\n    \n    return sum / total;\n}\n```"}
{"task_id": "SimdBench_29_AVX", "completion": "```cpp\ndouble matrix_average_simd(const double* mat, size_t m, size_t n) {\n    size_t total = m * n;\n    size_t vec_size = total / 4;\n    size_t remainder = total % 4;\n    \n    __m256d sum_vec = _mm256_setzero_pd();\n    \n    for(size_t i = 0; i < vec_size; i++) {\n        __m256d vec = _mm256_loadu_pd(&mat[i * 4]);\n        sum_vec = _mm256_add_pd(sum_vec, vec);\n    }\n    \n    double sum = 0.0;\n    double temp[4];\n    _mm256_storeu_pd(temp, sum_vec);\n    sum = temp[0] + temp[1] + temp[2] + temp[3];\n    \n    for(size_t i = vec_size * 4; i < total; i++) {\n        sum += mat[i];\n    }\n    \n    return sum / total;\n}\n```"}
{"task_id": "SimdBench_29_AVX", "completion": "```cpp\ndouble matrix_average_simd(const double* mat, size_t m, size_t n) {\n    size_t total = m * n;\n    size_t vec_size = total / 4;\n    size_t remainder = total % 4;\n    \n    __m256d sum_vec = _mm256_setzero_pd();\n    \n    for(size_t i = 0; i < vec_size; i++) {\n        __m256d vec = _mm256_loadu_pd(&mat[i * 4]);\n        sum_vec = _mm256_add_pd(sum_vec, vec);\n    }\n    \n    double sum = 0.0;\n    double temp[4];\n    _mm256_storeu_pd(temp, sum_vec);\n    sum = temp[0] + temp[1] + temp[2] + temp[3];\n    \n    for(size_t i = vec_size * 4; i < total; i++) {\n        sum += mat[i];\n    }\n    \n    return sum / total;\n}\n```"}
{"task_id": "SimdBench_29_AVX", "completion": "```cpp\ndouble matrix_average_simd(const double* mat, size_t m, size_t n) {\n    __m256d sum_vec = _mm256_setzero_pd();\n    size_t total = m * n;\n    size_t i = 0;\n    \n    // Process 4 elements at a time\n    for (; i + 3 < total; i += 4) {\n        __m256d vec = _mm256_loadu_pd(&mat[i]);\n        sum_vec = _mm256_add_pd(sum_vec, vec);\n    }\n    \n    // Horizontal sum of vector\n    __m256d temp = _mm256_hadd_pd(sum_vec, sum_vec);\n    __m128d sum_high = _mm256_extractf128_pd(temp, 1);\n    __m128d sum_low = _mm256_castpd256_pd128(temp);\n    __m128d result = _mm_add_pd(sum_high, sum_low);\n    double sum = _mm_cvtsd_f64(result);\n    \n    // Handle remaining elements\n    for (; i < total; i++) {\n        sum += mat[i];\n    }\n    \n    return sum / total;\n}\n```"}
{"task_id": "SimdBench_30_AVX", "completion": "```cpp\nbool matrix_rows_sorted_verify_simd(const int* matrix, const bool* directions, size_t rows, size_t cols) {\n    const size_t simd_width = 8;\n    const size_t simd_cols = cols - (cols % simd_width);\n    \n    for (size_t row = 0; row < rows; row++) {\n        const int* row_ptr = matrix + row * cols;\n        const bool ascending = directions[row];\n        \n        // Process 8 elements at a time using AVX2\n        for (size_t col = 0; col < simd_cols; col += simd_width) {\n            __m256i curr = _mm256_loadu_si256((__m256i*)(row_ptr + col));\n            __m256i next = _mm256_loadu_si256((__m256i*)(row_ptr + col + 1));\n            \n            __m256i cmp;\n            if (ascending) {\n                cmp = _mm256_cmpgt_epi32(curr, next);\n            } else {\n                cmp = _mm256_cmpgt_epi32(next, curr);\n            }\n            \n            int mask = _mm256_movemask_ps(_mm256_castsi256_ps(cmp));\n            if (mask != 0) {\n                return false;\n            }\n        }\n        \n        // Handle remaining elements\n        for (size_t col = simd_cols; col < cols - 1; col++) {\n            if (ascending) {\n                if (row_ptr[col] > row_ptr[col + 1]) {\n                    return false;\n                }\n            } else {\n                if (row_ptr[col] < row_ptr[col + 1]) {\n                    return false;\n                }\n            }\n        }\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_30_AVX", "completion": "```cpp\nbool matrix_rows_sorted_verify_simd(const int* matrix, const bool* directions, size_t rows, size_t cols) {\n    const size_t simd_width = 8;\n    const size_t simd_cols = cols - (cols % simd_width);\n    \n    for (size_t row = 0; row < rows; row++) {\n        const int* row_ptr = matrix + row * cols;\n        bool ascending = directions[row];\n        bool row_sorted = true;\n        \n        for (size_t col = 0; col < simd_cols; col += simd_width) {\n            __m256i curr = _mm256_loadu_si256((__m256i*)(row_ptr + col));\n            __m256i next = _mm256_loadu_si256((__m256i*)(row_ptr + col + 1));\n            \n            __m256i cmp;\n            if (ascending) {\n                cmp = _mm256_cmpgt_epi32(curr, next);\n            } else {\n                cmp = _mm256_cmpgt_epi32(next, curr);\n            }\n            \n            int mask = _mm256_movemask_ps(_mm256_castsi256_ps(cmp));\n            if (mask != 0) {\n                row_sorted = false;\n                break;\n            }\n        }\n        \n        if (row_sorted) {\n            for (size_t col = simd_cols; col < cols - 1; col++) {\n                if (ascending) {\n                    if (row_ptr[col] > row_ptr[col + 1]) {\n                        row_sorted = false;\n                        break;\n                    }\n                } else {\n                    if (row_ptr[col] < row_ptr[col + 1]) {\n                        row_sorted = false;\n                        break;\n                    }\n                }\n            }\n        }\n        \n        if (!row_sorted) {\n            return false;\n        }\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_30_AVX", "completion": "```cpp\nbool matrix_rows_sorted_verify_simd(const int* matrix, const bool* directions, size_t rows, size_t cols) {\n    const size_t simd_width = 8;\n    const size_t simd_cols = cols - (cols % simd_width);\n    \n    for (size_t row = 0; row < rows; row++) {\n        const int* row_ptr = matrix + row * cols;\n        bool ascending = directions[row];\n        bool row_sorted = true;\n        \n        // Process 8 elements at a time using AVX2\n        for (size_t col = 0; col < simd_cols; col += simd_width) {\n            __m256i curr = _mm256_loadu_si256((__m256i*)(row_ptr + col));\n            __m256i next = _mm256_loadu_si256((__m256i*)(row_ptr + col + 1));\n            \n            __m256i cmp;\n            if (ascending) {\n                cmp = _mm256_cmpgt_epi32(curr, next);\n            } else {\n                cmp = _mm256_cmpgt_epi32(next, curr);\n            }\n            \n            int mask = _mm256_movemask_ps(_mm256_castsi256_ps(cmp));\n            if (mask != 0) {\n                row_sorted = false;\n                break;\n            }\n        }\n        \n        // Handle remaining elements\n        if (row_sorted) {\n            for (size_t col = simd_cols; col < cols - 1; col++) {\n                if (ascending) {\n                    if (row_ptr[col] > row_ptr[col + 1]) {\n                        row_sorted = false;\n                        break;\n                    }\n                } else {\n                    if (row_ptr[col] < row_ptr[col + 1]) {\n                        row_sorted = false;\n                        break;\n                    }\n                }\n            }\n        }\n        \n        if (!row_sorted) {\n            return false;\n        }\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_30_AVX", "completion": "```cpp\nbool matrix_rows_sorted_verify_simd(const int* matrix, const bool* directions, size_t rows, size_t cols) {\n    const size_t simd_width = 8;\n    const size_t simd_cols = cols - (cols % simd_width);\n    \n    for (size_t row = 0; row < rows; row++) {\n        const int* row_ptr = matrix + row * cols;\n        bool ascending = directions[row];\n        \n        for (size_t col = 0; col < simd_cols; col += simd_width) {\n            __m256i curr = _mm256_loadu_si256((__m256i*)(row_ptr + col));\n            __m256i next = _mm256_loadu_si256((__m256i*)(row_ptr + col + 1));\n            \n            __m256i cmp;\n            if (ascending) {\n                cmp = _mm256_cmpgt_epi32(curr, next);\n            } else {\n                cmp = _mm256_cmpgt_epi32(next, curr);\n            }\n            \n            int mask = _mm256_movemask_ps(_mm256_castsi256_ps(cmp));\n            if (mask != 0) {\n                return false;\n            }\n        }\n        \n        // Handle remaining elements\n        for (size_t col = simd_cols; col < cols - 1; col++) {\n            if (ascending) {\n                if (row_ptr[col] > row_ptr[col + 1]) return false;\n            } else {\n                if (row_ptr[col] < row_ptr[col + 1]) return false;\n            }\n        }\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_30_AVX", "completion": "```cpp\nbool matrix_rows_sorted_verify_simd(const int* matrix, const bool* directions, size_t rows, size_t cols) {\n    const size_t vectors_per_row = cols / 8;\n    const size_t remainder = cols % 8;\n    \n    for (size_t i = 0; i < rows; i++) {\n        const int* row = matrix + i * cols;\n        const bool ascending = directions[i];\n        \n        // Process 8 elements at a time using AVX\n        for (size_t j = 0; j < vectors_per_row; j++) {\n            __m256i curr = _mm256_loadu_si256((__m256i*)(row + j * 8));\n            __m256i next = _mm256_loadu_si256((__m256i*)(row + j * 8 + 1));\n            \n            __m256i cmp;\n            if (ascending) {\n                cmp = _mm256_cmpgt_epi32(curr, next);\n            } else {\n                cmp = _mm256_cmpgt_epi32(next, curr);\n            }\n            \n            int mask = _mm256_movemask_ps(_mm256_castsi256_ps(cmp));\n            if (mask != 0) {\n                return false;\n            }\n        }\n        \n        // Handle remaining elements\n        for (size_t j = cols - remainder; j < cols - 1; j++) {\n            if (ascending) {\n                if (row[j] > row[j + 1]) return false;\n            } else {\n                if (row[j] < row[j + 1]) return false;\n            }\n        }\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_31_AVX", "completion": "```cpp\nvoid nearest_multiple_simd(const int16_t* src, int16_t* dst, uint8_t base, size_t length) {\n    __m256i vbase = _mm256_set1_epi16(base);\n    size_t i;\n    \n    for (i = 0; i + 15 < length; i += 16) {\n        __m256i vsrc = _mm256_loadu_si256((__m256i*)(src + i));\n        __m256i vdiv = _mm256_div_epi16(vsrc, vbase); // Divide by base\n        __m256i vmul = _mm256_mullo_epi16(vdiv, vbase); // Multiply back\n        _mm256_storeu_si256((__m256i*)(dst + i), vmul);\n    }\n\n    // Handle remaining elements\n    for (; i < length; i++) {\n        dst[i] = (src[i] / base) * base;\n    }\n}\n```"}
{"task_id": "SimdBench_31_AVX", "completion": "```cpp\nvoid nearest_multiple_simd(const int16_t* src, int16_t* dst, uint8_t base, size_t length) {\n    __m256i vbase = _mm256_set1_epi16(base);\n    size_t i;\n    \n    for (i = 0; i + 15 < length; i += 16) {\n        __m256i vsrc = _mm256_loadu_si256((__m256i*)(src + i));\n        __m256i vdiv = _mm256_div_epi16(vsrc, vbase);\n        __m256i vmul = _mm256_mullo_epi16(vdiv, vbase);\n        _mm256_storeu_si256((__m256i*)(dst + i), vmul);\n    }\n\n    // Handle remaining elements\n    for (; i < length; i++) {\n        dst[i] = (src[i] / base) * base;\n    }\n}\n```"}
{"task_id": "SimdBench_31_AVX", "completion": "```cpp\nvoid nearest_multiple_simd(const int16_t* src, int16_t* dst, uint8_t base, size_t length) {\n    __m256i vbase = _mm256_set1_epi16(base);\n    size_t i;\n    \n    for (i = 0; i + 15 < length; i += 16) {\n        __m256i vsrc = _mm256_loadu_si256((const __m256i*)(src + i));\n        \n        // Divide by base (truncating division)\n        __m256i vdiv = _mm256_div_epi16(vsrc, vbase);\n        \n        // Multiply back by base to get nearest multiple no larger than src\n        __m256i vresult = _mm256_mullo_epi16(vdiv, vbase);\n        \n        _mm256_storeu_si256((__m256i*)(dst + i), vresult);\n    }\n\n    // Handle remaining elements\n    for (; i < length; i++) {\n        dst[i] = (src[i] / base) * base;\n    }\n}\n```"}
{"task_id": "SimdBench_31_AVX", "completion": "```cpp\nvoid nearest_multiple_simd(const int16_t* src, int16_t* dst, uint8_t base, size_t length) {\n    __m256i vbase = _mm256_set1_epi16(base);\n    size_t i;\n    \n    for (i = 0; i + 15 < length; i += 16) {\n        __m256i vsrc = _mm256_loadu_si256((__m256i*)(src + i));\n        \n        // Divide by base\n        __m256i vdiv = _mm256_div_epi16(vsrc, vbase);\n        \n        // Multiply back by base to get nearest multiple\n        __m256i vmult = _mm256_mullo_epi16(vdiv, vbase);\n        \n        // Store result\n        _mm256_storeu_si256((__m256i*)(dst + i), vmult);\n    }\n\n    // Handle remaining elements\n    for (; i < length; i++) {\n        dst[i] = (src[i] / base) * base;\n    }\n}\n```"}
{"task_id": "SimdBench_31_AVX", "completion": "```cpp\nvoid nearest_multiple_simd(const int16_t* src, int16_t* dst, uint8_t base, size_t length) {\n    __m256i vbase = _mm256_set1_epi16(base);\n    size_t i;\n    \n    for (i = 0; i + 15 < length; i += 16) {\n        __m256i vsrc = _mm256_loadu_si256((__m256i*)(src + i));\n        __m256i vdiv = _mm256_div_epi16(vsrc, vbase);\n        __m256i vmul = _mm256_mullo_epi16(vdiv, vbase);\n        _mm256_storeu_si256((__m256i*)(dst + i), vmul);\n    }\n\n    // Handle remaining elements\n    for (; i < length; i++) {\n        dst[i] = (src[i] / base) * base;\n    }\n}\n```"}
{"task_id": "SimdBench_32_AVX", "completion": "```cpp\nbool matrix_has_row_simd(const double* matrix, const double* vector, size_t rows, size_t cols) {\n    const size_t step = 4; // AVX registers hold 4 doubles\n    const size_t aligned_cols = cols - (cols % step);\n    \n    for (size_t i = 0; i < rows; i++) {\n        const double* row = matrix + i * cols;\n        bool row_match = true;\n        \n        size_t j;\n        for (j = 0; j < aligned_cols; j += step) {\n            __m256d row_vec = _mm256_loadu_pd(row + j);\n            __m256d vec = _mm256_loadu_pd(vector + j);\n            __m256d cmp = _mm256_cmp_pd(row_vec, vec, _CMP_EQ_OQ);\n            if (_mm256_movemask_pd(cmp) != 0xF) {\n                row_match = false;\n                break;\n            }\n        }\n        \n        if (!row_match) continue;\n        \n        // Handle remaining elements\n        for (; j < cols; j++) {\n            if (row[j] != vector[j]) {\n                row_match = false;\n                break;\n            }\n        }\n        \n        if (row_match) return true;\n    }\n    \n    return false;\n}\n```"}
{"task_id": "SimdBench_32_AVX", "completion": "```cpp\nbool matrix_has_row_simd(const double* matrix, const double* vector, size_t rows, size_t cols) {\n    const size_t step = 4; // AVX 256-bit = 4 doubles\n    const size_t aligned_cols = cols - (cols % step);\n    \n    for (size_t i = 0; i < rows; i++) {\n        bool row_match = true;\n        size_t j;\n        \n        for (j = 0; j < aligned_cols; j += step) {\n            __m256d row_vec = _mm256_loadu_pd(matrix + i*cols + j);\n            __m256d cmp_vec = _mm256_loadu_pd(vector + j);\n            __m256d cmp_res = _mm256_cmp_pd(row_vec, cmp_vec, _CMP_EQ_OQ);\n            \n            if (_mm256_movemask_pd(cmp_res) != 0xF) {\n                row_match = false;\n                break;\n            }\n        }\n        \n        if (!row_match) continue;\n        \n        // Handle remaining elements\n        for (; j < cols; j++) {\n            if (matrix[i*cols + j] != vector[j]) {\n                row_match = false;\n                break;\n            }\n        }\n        \n        if (row_match) return true;\n    }\n    \n    return false;\n}\n```"}
{"task_id": "SimdBench_32_AVX", "completion": "```cpp\nbool matrix_has_row_simd(const double* matrix, const double* vector, size_t rows, size_t cols) {\n    const size_t simd_width = 4;\n    const size_t simd_cols = cols / simd_width;\n    const size_t remainder = cols % simd_width;\n\n    for (size_t i = 0; i < rows; i++) {\n        const double* row = matrix + i * cols;\n        bool row_match = true;\n        \n        for (size_t j = 0; j < simd_cols; j++) {\n            __m256d row_vec = _mm256_loadu_pd(row + j * simd_width);\n            __m256d vec = _mm256_loadu_pd(vector + j * simd_width);\n            __m256d cmp = _mm256_cmp_pd(row_vec, vec, _CMP_EQ_OQ);\n            \n            if (_mm256_movemask_pd(cmp) != 0xF) {\n                row_match = false;\n                break;\n            }\n        }\n\n        if (!row_match) continue;\n\n        for (size_t j = simd_cols * simd_width; j < cols; j++) {\n            if (row[j] != vector[j]) {\n                row_match = false;\n                break;\n            }\n        }\n\n        if (row_match) return true;\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_32_AVX", "completion": "```cpp\nbool matrix_has_row_simd(const double* matrix, const double* vector, size_t rows, size_t cols) {\n    const size_t simd_width = 4;\n    const size_t simd_cols = cols / simd_width;\n    const size_t remainder = cols % simd_width;\n\n    for (size_t i = 0; i < rows; i++) {\n        const double* row = matrix + i * cols;\n        bool row_match = true;\n        \n        for (size_t j = 0; j < simd_cols; j++) {\n            __m256d row_vec = _mm256_loadu_pd(row + j * simd_width);\n            __m256d vec = _mm256_loadu_pd(vector + j * simd_width);\n            __m256d cmp = _mm256_cmp_pd(row_vec, vec, _CMP_EQ_OQ);\n            \n            if (_mm256_movemask_pd(cmp) != 0xF) {\n                row_match = false;\n                break;\n            }\n        }\n\n        if (!row_match) continue;\n\n        for (size_t j = simd_cols * simd_width; j < cols; j++) {\n            if (row[j] != vector[j]) {\n                row_match = false;\n                break;\n            }\n        }\n\n        if (row_match) return true;\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_32_AVX", "completion": "```cpp\nbool matrix_has_row_simd(const double* matrix, const double* vector, size_t rows, size_t cols) {\n    const size_t step = 4; // Process 4 doubles at a time with AVX2\n    const size_t aligned_cols = cols - (cols % step);\n    \n    for (size_t i = 0; i < rows; i++) {\n        const double* row = matrix + i * cols;\n        bool row_match = true;\n        \n        size_t j;\n        for (j = 0; j < aligned_cols; j += step) {\n            __m256d row_vec = _mm256_loadu_pd(row + j);\n            __m256d vec = _mm256_loadu_pd(vector + j);\n            __m256d cmp = _mm256_cmp_pd(row_vec, vec, _CMP_EQ_OQ);\n            \n            if (_mm256_movemask_pd(cmp) != 0xF) {\n                row_match = false;\n                break;\n            }\n        }\n        \n        if (!row_match) continue;\n        \n        // Handle remaining elements\n        for (; j < cols; j++) {\n            if (row[j] != vector[j]) {\n                row_match = false;\n                break;\n            }\n        }\n        \n        if (row_match) return true;\n    }\n    \n    return false;\n}\n```"}
{"task_id": "SimdBench_33_AVX", "completion": "```cpp\nsize_t tensor_4d_equal_count_simd(const uint8_t* A, const uint8_t* B, const size_t dims[4]) {\n    size_t total_size = dims[0] * dims[1] * dims[2] * dims[3];\n    size_t count = 0;\n    size_t i = 0;\n\n    // Process 32 elements at a time using AVX2\n    for (; i + 31 < total_size; i += 32) {\n        __m256i a = _mm256_loadu_si256((__m256i*)(A + i));\n        __m256i b = _mm256_loadu_si256((__m256i*)(B + i));\n        \n        // Compare for equality\n        __m256i cmp = _mm256_cmpeq_epi8(a, b);\n        \n        // Get mask of comparisons\n        uint32_t mask = _mm256_movemask_epi8(cmp);\n        \n        // Count set bits\n        count += _mm_popcnt_u32(mask);\n    }\n\n    // Handle remaining elements\n    for (; i < total_size; i++) {\n        if (A[i] == B[i]) {\n            count++;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_33_AVX", "completion": "```cpp\nsize_t tensor_4d_equal_count_simd(const uint8_t* A, const uint8_t* B, const size_t dims[4]) {\n    size_t total_size = dims[0] * dims[1] * dims[2] * dims[3];\n    size_t count = 0;\n    size_t i = 0;\n\n    // Process 32 elements at a time using AVX2\n    for (; i + 31 < total_size; i += 32) {\n        __m256i a = _mm256_loadu_si256((__m256i*)(A + i));\n        __m256i b = _mm256_loadu_si256((__m256i*)(B + i));\n        \n        // Compare for equality\n        __m256i cmp = _mm256_cmpeq_epi8(a, b);\n        \n        // Get mask of comparisons\n        int mask = _mm256_movemask_epi8(cmp);\n        \n        // Count set bits in mask\n        count += _mm_popcnt_u32(mask);\n    }\n\n    // Handle remaining elements\n    for (; i < total_size; i++) {\n        if (A[i] == B[i]) {\n            count++;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_33_AVX", "completion": "```cpp\nsize_t tensor_4d_equal_count_simd(const uint8_t* A, const uint8_t* B, const size_t dims[4]) {\n    size_t total_size = dims[0] * dims[1] * dims[2] * dims[3];\n    size_t count = 0;\n    size_t i = 0;\n\n    // Process 32 elements at a time using AVX2\n    for (; i + 31 < total_size; i += 32) {\n        __m256i a = _mm256_loadu_si256((__m256i*)(A + i));\n        __m256i b = _mm256_loadu_si256((__m256i*)(B + i));\n        \n        // Compare for equality\n        __m256i cmp = _mm256_cmpeq_epi8(a, b);\n        \n        // Get mask of comparisons\n        uint32_t mask = _mm256_movemask_epi8(cmp);\n        \n        // Count set bits in mask\n        count += _mm_popcnt_u32(mask);\n    }\n\n    // Handle remaining elements\n    for (; i < total_size; i++) {\n        if (A[i] == B[i]) {\n            count++;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_33_AVX", "completion": "```cpp\nsize_t tensor_4d_equal_count_simd(const uint8_t* A, const uint8_t* B, const size_t dims[4]) {\n    size_t total_size = dims[0] * dims[1] * dims[2] * dims[3];\n    size_t count = 0;\n    size_t i = 0;\n\n    // Process 32 elements at a time using AVX2\n    for (; i + 31 < total_size; i += 32) {\n        __m256i a = _mm256_loadu_si256((__m256i*)(A + i));\n        __m256i b = _mm256_loadu_si256((__m256i*)(B + i));\n        \n        // Compare for equality\n        __m256i cmp = _mm256_cmpeq_epi8(a, b);\n        \n        // Get mask of comparisons\n        int mask = _mm256_movemask_epi8(cmp);\n        \n        // Count number of 1s in mask\n        count += _mm_popcnt_u32(mask);\n    }\n\n    // Handle remaining elements\n    for (; i < total_size; i++) {\n        if (A[i] == B[i]) {\n            count++;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_33_AVX", "completion": "```cpp\nsize_t tensor_4d_equal_count_simd(const uint8_t* A, const uint8_t* B, const size_t dims[4]) {\n    size_t total_size = dims[0] * dims[1] * dims[2] * dims[3];\n    size_t count = 0;\n    size_t i = 0;\n\n    // Process 32 elements at a time using AVX2\n    for (; i + 31 < total_size; i += 32) {\n        __m256i a = _mm256_loadu_si256((__m256i*)(A + i));\n        __m256i b = _mm256_loadu_si256((__m256i*)(B + i));\n        \n        // Compare for equality\n        __m256i cmp = _mm256_cmpeq_epi8(a, b);\n        \n        // Get mask of comparisons\n        uint32_t mask = _mm256_movemask_epi8(cmp);\n        \n        // Count set bits in mask\n        count += _mm_popcnt_u32(mask);\n    }\n\n    // Handle remaining elements\n    for (; i < total_size; i++) {\n        if (A[i] == B[i]) {\n            count++;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_34_AVX", "completion": "```cpp\nvoid axm_abs_simd(size_t length, const int64_t a, const int64_t *x, int64_t *y) {\n    __m256i va = _mm256_set1_epi64x(a);\n    size_t i;\n    \n    for (i = 0; i + 4 <= length; i += 4) {\n        __m256i vx = _mm256_loadu_si256((__m256i*)(x + i));\n        __m256i vy = _mm256_loadu_si256((__m256i*)(y + i));\n        \n        __m256i mul = _mm256_mul_epi32(va, vx);\n        __m256i abs_y = _mm256_abs_epi64(vy);\n        __m256i result = _mm256_sub_epi64(mul, abs_y);\n        \n        _mm256_storeu_si256((__m256i*)(y + i), result);\n    }\n\n    // Handle remaining elements\n    for (; i < length; i++) {\n        y[i] = a * x[i] - (y[i] >= 0 ? y[i] : -y[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_34_AVX", "completion": "```cpp\nvoid axm_abs_simd(size_t length, const int64_t a, const int64_t *x, int64_t *y) {\n    __m256i va = _mm256_set1_epi64x(a);\n    size_t i;\n    \n    for (i = 0; i + 4 <= length; i += 4) {\n        __m256i vx = _mm256_loadu_si256((__m256i*)(x + i));\n        __m256i vy = _mm256_loadu_si256((__m256i*)(y + i));\n        \n        __m256i prod = _mm256_mul_epi32(va, vx);\n        __m256i abs_y = _mm256_abs_epi64(vy);\n        __m256i result = _mm256_sub_epi64(prod, abs_y);\n        \n        _mm256_storeu_si256((__m256i*)(y + i), result);\n    }\n\n    // Handle remaining elements\n    for (; i < length; i++) {\n        y[i] = a * x[i] - (y[i] >= 0 ? y[i] : -y[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_34_AVX", "completion": "```cpp\nvoid axm_abs_simd(size_t length, const int64_t a, const int64_t *x, int64_t *y) {\n    __m256i a_vec = _mm256_set1_epi64x(a);\n    size_t i;\n    \n    for (i = 0; i + 4 <= length; i += 4) {\n        __m256i x_vec = _mm256_loadu_si256((__m256i*)(x + i));\n        __m256i y_vec = _mm256_loadu_si256((__m256i*)(y + i));\n        \n        __m256i ax = _mm256_mul_epi32(a_vec, x_vec);\n        __m256i abs_y = _mm256_abs_epi64(y_vec);\n        __m256i result = _mm256_sub_epi64(ax, abs_y);\n        \n        _mm256_storeu_si256((__m256i*)(y + i), result);\n    }\n\n    // Handle remaining elements\n    for (; i < length; i++) {\n        y[i] = a * x[i] - (y[i] >= 0 ? y[i] : -y[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_34_AVX", "completion": "```cpp\nvoid axm_abs_simd(size_t length, const int64_t a, const int64_t *x, int64_t *y) {\n    __m256i va = _mm256_set1_epi64x(a);\n    size_t i;\n    \n    for (i = 0; i + 4 <= length; i += 4) {\n        __m256i vx = _mm256_loadu_si256((__m256i*)(x + i));\n        __m256i vy = _mm256_loadu_si256((__m256i*)(y + i));\n        \n        __m256i mul = _mm256_mul_epi32(va, vx);\n        __m256i abs_y = _mm256_abs_epi64(vy);\n        __m256i result = _mm256_sub_epi64(mul, abs_y);\n        \n        _mm256_storeu_si256((__m256i*)(y + i), result);\n    }\n\n    // Handle remaining elements\n    for (; i < length; i++) {\n        y[i] = a * x[i] - llabs(y[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_34_AVX", "completion": "```cpp\nvoid axm_abs_simd(size_t length, const int64_t a, const int64_t *x, int64_t *y) {\n    __m256i va = _mm256_set1_epi64x(a);\n    size_t i;\n    \n    for (i = 0; i + 4 <= length; i += 4) {\n        __m256i vx = _mm256_loadu_si256((__m256i*)(x + i));\n        __m256i vy = _mm256_loadu_si256((__m256i*)(y + i));\n        \n        __m256i mul = _mm256_mul_epi32(va, vx);\n        __m256i abs_y = _mm256_abs_epi64(vy);\n        __m256i result = _mm256_sub_epi64(mul, abs_y);\n        \n        _mm256_storeu_si256((__m256i*)(y + i), result);\n    }\n\n    // Handle remaining elements\n    for (; i < length; i++) {\n        y[i] = a * x[i] - llabs(y[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_35_AVX", "completion": "```cpp\nMinMaxPair min_max_pair_simd(const int16_t* vec, size_t length) {\n    __m256i current_min = _mm256_set1_epi16(32767);\n    __m256i current_max = _mm256_set1_epi16(-32768);\n    \n    size_t i;\n    for(i = 0; i + 15 < length; i += 16) {\n        __m256i v = _mm256_loadu_si256((__m256i*)(vec + i));\n        current_min = _mm256_min_epi16(current_min, v);\n        current_max = _mm256_max_epi16(current_max, v);\n    }\n\n    int16_t min_vals[16], max_vals[16];\n    _mm256_storeu_si256((__m256i*)min_vals, current_min);\n    _mm256_storeu_si256((__m256i*)max_vals, current_max);\n\n    int16_t min_num = min_vals[0];\n    int16_t max_num = max_vals[0];\n\n    for(int j = 1; j < 16; j++) {\n        if(min_vals[j] < min_num) min_num = min_vals[j];\n        if(max_vals[j] > max_num) max_num = max_vals[j];\n    }\n\n    for(; i < length; i++) {\n        if(vec[i] < min_num) min_num = vec[i];\n        if(vec[i] > max_num) max_num = vec[i];\n    }\n\n    return (MinMaxPair){min_num, max_num};\n}\n```"}
{"task_id": "SimdBench_35_AVX", "completion": "```cpp\nMinMaxPair min_max_pair_simd(const int16_t* vec, size_t length) {\n    __m256i curr_max = _mm256_set1_epi16(INT16_MIN);\n    __m256i curr_min = _mm256_set1_epi16(INT16_MAX);\n    \n    size_t i;\n    for(i = 0; i + 15 < length; i += 16) {\n        __m256i v = _mm256_loadu_si256((__m256i*)(vec + i));\n        curr_max = _mm256_max_epi16(curr_max, v);\n        curr_min = _mm256_min_epi16(curr_min, v);\n    }\n\n    int16_t max_arr[16], min_arr[16];\n    _mm256_storeu_si256((__m256i*)max_arr, curr_max);\n    _mm256_storeu_si256((__m256i*)min_arr, curr_min);\n    \n    int16_t max_val = INT16_MIN;\n    int16_t min_val = INT16_MAX;\n    \n    for(int j = 0; j < 16; j++) {\n        max_val = max_val < max_arr[j] ? max_arr[j] : max_val;\n        min_val = min_val > min_arr[j] ? min_arr[j] : min_val;\n    }\n    \n    for(; i < length; i++) {\n        max_val = max_val < vec[i] ? vec[i] : max_val;\n        min_val = min_val > vec[i] ? vec[i] : min_val;\n    }\n    \n    return (MinMaxPair){min_val, max_val};\n}\n```"}
{"task_id": "SimdBench_35_AVX", "completion": "```cpp\nMinMaxPair min_max_pair_simd(const int16_t* vec, size_t length) {\n    __m256i current_min = _mm256_set1_epi16(32767);\n    __m256i current_max = _mm256_set1_epi16(-32768);\n    \n    size_t i;\n    for(i = 0; i + 16 <= length; i += 16) {\n        __m256i v = _mm256_loadu_si256((__m256i*)(vec + i));\n        current_min = _mm256_min_epi16(current_min, v);\n        current_max = _mm256_max_epi16(current_max, v);\n    }\n\n    int16_t min_vals[16], max_vals[16];\n    _mm256_storeu_si256((__m256i*)min_vals, current_min);\n    _mm256_storeu_si256((__m256i*)max_vals, current_max);\n\n    int16_t min_num = min_vals[0];\n    int16_t max_num = max_vals[0];\n\n    for(int j = 1; j < 16; j++) {\n        if(min_vals[j] < min_num) min_num = min_vals[j];\n        if(max_vals[j] > max_num) max_num = max_vals[j];\n    }\n\n    for(; i < length; i++) {\n        if(vec[i] < min_num) min_num = vec[i];\n        if(vec[i] > max_num) max_num = vec[i];\n    }\n\n    MinMaxPair result = {min_num, max_num};\n    return result;\n}\n```"}
{"task_id": "SimdBench_35_AVX", "completion": "```cpp\nMinMaxPair min_max_pair_simd(const int16_t* vec, size_t length) {\n    __m256i current_max = _mm256_set1_epi16(INT16_MIN);\n    __m256i current_min = _mm256_set1_epi16(INT16_MAX);\n    \n    size_t i;\n    for(i = 0; i + 15 < length; i += 16) {\n        __m256i v = _mm256_loadu_si256((__m256i*)(vec + i));\n        current_max = _mm256_max_epi16(current_max, v);\n        current_min = _mm256_min_epi16(current_min, v);\n    }\n\n    int16_t max_values[16];\n    int16_t min_values[16];\n    _mm256_storeu_si256((__m256i*)max_values, current_max);\n    _mm256_storeu_si256((__m256i*)min_values, current_min);\n\n    int16_t max_num = INT16_MIN;\n    int16_t min_num = INT16_MAX;\n\n    for(int j = 0; j < 16; j++) {\n        if(max_values[j] > max_num) max_num = max_values[j];\n        if(min_values[j] < min_num) min_num = min_values[j];\n    }\n\n    for(; i < length; i++) {\n        if(vec[i] > max_num) max_num = vec[i];\n        if(vec[i] < min_num) min_num = vec[i];\n    }\n\n    MinMaxPair result = {min_num, max_num};\n    return result;\n}\n```"}
{"task_id": "SimdBench_35_AVX", "completion": "```cpp\nMinMaxPair min_max_pair_simd(const int16_t* vec, size_t length) {\n    __m256i curr_min = _mm256_set1_epi16(32767);\n    __m256i curr_max = _mm256_set1_epi16(-32768);\n    \n    size_t i;\n    for(i = 0; i + 15 < length; i += 16) {\n        __m256i v = _mm256_loadu_si256((__m256i*)(vec + i));\n        curr_min = _mm256_min_epi16(curr_min, v);\n        curr_max = _mm256_max_epi16(curr_max, v);\n    }\n\n    int16_t min_vals[16], max_vals[16];\n    _mm256_storeu_si256((__m256i*)min_vals, curr_min);\n    _mm256_storeu_si256((__m256i*)max_vals, curr_max);\n\n    int16_t min_num = min_vals[0];\n    int16_t max_num = max_vals[0];\n\n    for(int j = 1; j < 16; j++) {\n        if(min_vals[j] < min_num) min_num = min_vals[j];\n        if(max_vals[j] > max_num) max_num = max_vals[j];\n    }\n\n    for(; i < length; i++) {\n        if(vec[i] < min_num) min_num = vec[i];\n        if(vec[i] > max_num) max_num = vec[i];\n    }\n\n    MinMaxPair result = {min_num, max_num};\n    return result;\n}\n```"}
{"task_id": "SimdBench_36_AVX", "completion": "```cpp\nbool matrix_rows_strictly_increasing_simd(const int* matrix, size_t rows, size_t cols) {\n    if (rows == 0 || cols <= 1) return false;\n\n    const int simd_width = 8;\n    __m256i ones = _mm256_set1_epi32(1);\n    \n    for (size_t i = 0; i < rows; i++) {\n        const int* row = matrix + i * cols;\n        \n        for (size_t j = 0; j < cols-simd_width; j += simd_width) {\n            __m256i curr = _mm256_loadu_si256((__m256i*)(row + j));\n            __m256i next = _mm256_loadu_si256((__m256i*)(row + j + 1));\n            \n            __m256i cmp = _mm256_cmpgt_epi32(next, curr);\n            if (_mm256_movemask_ps(_mm256_castsi256_ps(cmp)) != 0xFF) {\n                return false;\n            }\n        }\n        \n        // Handle remaining elements\n        for (size_t j = cols - (cols % simd_width); j < cols-1; j++) {\n            if (row[j] >= row[j+1]) {\n                return false;\n            }\n        }\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_36_AVX", "completion": "```cpp\nbool matrix_rows_strictly_increasing_simd(const int* matrix, size_t rows, size_t cols) {\n    if (rows == 0 || cols <= 1) return false;\n\n    const int simd_width = 8;\n    __m256i ones = _mm256_set1_epi32(1);\n    \n    for (size_t i = 0; i < rows; i++) {\n        const int* row = matrix + i * cols;\n        size_t j;\n        \n        for (j = 0; j + simd_width + 1 <= cols; j += simd_width) {\n            __m256i curr = _mm256_loadu_si256((__m256i*)(row + j));\n            __m256i next = _mm256_loadu_si256((__m256i*)(row + j + 1));\n            \n            __m256i cmp = _mm256_cmpgt_epi32(next, curr);\n            int mask = _mm256_movemask_ps(_mm256_castsi256_ps(cmp));\n            \n            if (mask != 0xFF) {\n                return false;\n            }\n        }\n        \n        for (; j < cols - 1; j++) {\n            if (row[j] >= row[j + 1]) {\n                return false;\n            }\n        }\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_36_AVX", "completion": "```cpp\nbool matrix_rows_strictly_increasing_simd(const int* matrix, size_t rows, size_t cols) {\n    if (rows == 0 || cols <= 1) return false;\n\n    const int simd_width = 8;\n    __m256i ones = _mm256_set1_epi32(1);\n    \n    for (size_t i = 0; i < rows; i++) {\n        const int* row = matrix + i * cols;\n        size_t j;\n        \n        for (j = 0; j + simd_width + 1 <= cols; j += simd_width) {\n            __m256i curr = _mm256_loadu_si256((__m256i*)(row + j));\n            __m256i next = _mm256_loadu_si256((__m256i*)(row + j + 1));\n            \n            __m256i cmp = _mm256_cmpgt_epi32(next, curr);\n            int mask = _mm256_movemask_ps(_mm256_castsi256_ps(cmp));\n            \n            if (mask != 0xFF) {\n                return false;\n            }\n        }\n        \n        for (; j < cols - 1; j++) {\n            if (row[j] >= row[j + 1]) {\n                return false;\n            }\n        }\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_36_AVX", "completion": "```cpp\nbool matrix_rows_strictly_increasing_simd(const int* matrix, size_t rows, size_t cols) {\n    if (rows == 0 || cols <= 1) return false;\n\n    const int simd_width = 8;\n    __m256i ones = _mm256_set1_epi32(1);\n\n    for (size_t i = 0; i < rows; i++) {\n        const int* row = matrix + i * cols;\n        \n        for (size_t j = 0; j < cols - simd_width; j += simd_width) {\n            __m256i curr = _mm256_loadu_si256((__m256i*)(row + j));\n            __m256i next = _mm256_loadu_si256((__m256i*)(row + j + 1));\n            \n            __m256i cmp = _mm256_cmpgt_epi32(next, curr);\n            if (_mm256_movemask_ps(_mm256_castsi256_ps(cmp)) != 0xFF) {\n                return false;\n            }\n        }\n\n        // Handle remaining elements\n        for (size_t j = cols - (cols % simd_width); j < cols - 1; j++) {\n            if (row[j] >= row[j + 1]) {\n                return false;\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_36_AVX", "completion": "```cpp\nbool matrix_rows_strictly_increasing_simd(const int* matrix, size_t rows, size_t cols) {\n    if (rows == 0 || cols <= 1) return false;\n\n    const int simd_width = 8; // AVX2 processes 8 32-bit integers at once\n    \n    for (size_t row = 0; row < rows; row++) {\n        const int* row_ptr = matrix + row * cols;\n        \n        // Process 8 elements at a time\n        for (size_t col = 0; col < cols - 1; col += simd_width) {\n            size_t remaining = cols - 1 - col;\n            size_t elements = (remaining < simd_width) ? remaining : simd_width;\n            \n            __m256i curr = _mm256_loadu_si256((__m256i*)(row_ptr + col));\n            __m256i next = _mm256_loadu_si256((__m256i*)(row_ptr + col + 1));\n            \n            __m256i cmp = _mm256_cmpgt_epi32(next, curr);\n            int mask = _mm256_movemask_ps(_mm256_castsi256_ps(cmp));\n            \n            // Check if all bits in the valid range are 1\n            int required_mask = (1 << elements) - 1;\n            if ((mask & required_mask) != required_mask) {\n                return false;\n            }\n        }\n        \n        // Handle remaining elements\n        for (size_t col = ((cols - 1) / simd_width) * simd_width; col < cols - 1; col++) {\n            if (row_ptr[col] >= row_ptr[col + 1]) {\n                return false;\n            }\n        }\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_37_AVX", "completion": "```cpp\nbool matrix_blocks_equal_simd(const int* matrix, size_t block_size, size_t rows, size_t cols) {\n    if (block_size == 0 || rows % block_size != 0 || cols % block_size != 0) {\n        return false;\n    }\n\n    const size_t blocks_per_row = cols / block_size;\n    const size_t blocks_per_col = rows / block_size;\n    const size_t elements_per_block = block_size * block_size;\n\n    // Process 8 integers at a time using AVX2\n    const size_t simd_width = 8;\n    const size_t simd_blocks = elements_per_block / simd_width;\n    const size_t remainder = elements_per_block % simd_width;\n\n    for (size_t block_row = 0; block_row < blocks_per_col; block_row++) {\n        for (size_t block_col = 0; block_col < blocks_per_row; block_col++) {\n            if (block_row == 0 && block_col == 0) continue;\n\n            const int* first_block = matrix;\n            const int* current_block = matrix + (block_row * block_size * cols + block_col * block_size);\n\n            // Compare blocks using AVX2\n            for (size_t i = 0; i < block_size; i++) {\n                const int* first_row = first_block + i * cols;\n                const int* current_row = current_block + i * cols;\n\n                size_t j = 0;\n                // Process 8 elements at a time\n                for (; j < block_size - (block_size % simd_width); j += simd_width) {\n                    __m256i v1 = _mm256_loadu_si256((__m256i*)(first_row + j));\n                    __m256i v2 = _mm256_loadu_si256((__m256i*)(current_row + j));\n                    __m256i cmp = _mm256_cmpeq_epi32(v1, v2);\n                    int mask = _mm256_movemask_ps(_mm256_castsi256_ps(cmp));\n                    if (mask != 0xFF) {\n                        return false;\n                    }\n                }\n\n                // Handle remaining elements\n                for (; j < block_size; j++) {\n                    if (first_row[j] != current_row[j]) {\n                        return false;\n                    }\n                }\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_37_AVX", "completion": "```cpp\nbool matrix_blocks_equal_simd(const int* matrix, size_t block_size, size_t rows, size_t cols) {\n    if (block_size == 0 || rows % block_size != 0 || cols % block_size != 0) {\n        return false;\n    }\n\n    const size_t blocks_per_row = cols / block_size;\n    const size_t blocks_per_col = rows / block_size;\n    const size_t elements_per_block = block_size * block_size;\n\n    // Process 8 integers at a time using AVX2\n    const size_t simd_width = 8;\n    const size_t simd_blocks = elements_per_block / simd_width;\n    const size_t remainder = elements_per_block % simd_width;\n\n    for (size_t block_row = 0; block_row < blocks_per_col; block_row++) {\n        for (size_t block_col = 0; block_col < blocks_per_row; block_col++) {\n            if (block_row == 0 && block_col == 0) continue;\n\n            const int* first_block = matrix;\n            const int* current_block = matrix + (block_row * block_size * cols + block_col * block_size);\n\n            // Compare blocks using AVX2\n            for (size_t i = 0; i < block_size; i++) {\n                const int* first_row = first_block + i * cols;\n                const int* current_row = current_block + i * cols;\n\n                size_t j = 0;\n                // Process 8 elements at a time\n                for (; j < block_size - (block_size % simd_width); j += simd_width) {\n                    __m256i v1 = _mm256_loadu_si256((__m256i*)(first_row + j));\n                    __m256i v2 = _mm256_loadu_si256((__m256i*)(current_row + j));\n                    __m256i cmp = _mm256_cmpeq_epi32(v1, v2);\n                    int mask = _mm256_movemask_ps(_mm256_castsi256_ps(cmp));\n                    if (mask != 0xFF) {\n                        return false;\n                    }\n                }\n\n                // Handle remaining elements\n                for (; j < block_size; j++) {\n                    if (first_row[j] != current_row[j]) {\n                        return false;\n                    }\n                }\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_37_AVX", "completion": "```cpp\nbool matrix_blocks_equal_simd(const int* matrix, size_t block_size, size_t rows, size_t cols) {\n    if (block_size == 0 || rows % block_size != 0 || cols % block_size != 0) {\n        return false;\n    }\n\n    size_t blocks_per_row = cols / block_size;\n    size_t blocks_per_col = rows / block_size;\n    \n    // Process 8 integers at a time using AVX2\n    const size_t simd_width = 8;\n    \n    for (size_t block_row = 0; block_row < blocks_per_col; block_row++) {\n        for (size_t block_col = 0; block_col < blocks_per_row; block_col++) {\n            if (block_row == 0 && block_col == 0) continue; // Skip first block\n            \n            for (size_t i = 0; i < block_size; i++) {\n                size_t ref_row = i;\n                size_t cur_row = block_row * block_size + i;\n                \n                for (size_t j = 0; j < block_size; j += simd_width) {\n                    size_t ref_col = j;\n                    size_t cur_col = block_col * block_size + j;\n                    \n                    size_t ref_idx = ref_row * cols + ref_col;\n                    size_t cur_idx = cur_row * cols + cur_col;\n                    \n                    if (j + simd_width <= block_size) {\n                        __m256i ref_vec = _mm256_loadu_si256((__m256i*)&matrix[ref_idx]);\n                        __m256i cur_vec = _mm256_loadu_si256((__m256i*)&matrix[cur_idx]);\n                        __m256i cmp = _mm256_cmpeq_epi32(ref_vec, cur_vec);\n                        int mask = _mm256_movemask_ps(_mm256_castsi256_ps(cmp));\n                        if (mask != 0xFF) {\n                            return false;\n                        }\n                    } else {\n                        // Handle remaining elements\n                        for (size_t k = j; k < block_size; k++) {\n                            if (matrix[ref_row * cols + k] != \n                                matrix[cur_row * cols + block_col * block_size + k]) {\n                                return false;\n                            }\n                        }\n                    }\n                }\n            }\n        }\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_37_AVX", "completion": "```cpp\nbool matrix_blocks_equal_simd(const int* matrix, size_t block_size, size_t rows, size_t cols) {\n    if (block_size == 0 || rows % block_size != 0 || cols % block_size != 0) {\n        return false;\n    }\n\n    const size_t blocks_per_row = cols / block_size;\n    const size_t blocks_per_col = rows / block_size;\n    const size_t elements_per_block = block_size * block_size;\n\n    // Process 8 integers at a time using AVX2\n    const size_t simd_width = 8;\n    const size_t simd_iterations = elements_per_block / simd_width;\n    const size_t remaining = elements_per_block % simd_width;\n\n    for (size_t block_row = 0; block_row < blocks_per_col; block_row++) {\n        for (size_t block_col = 0; block_col < blocks_per_row; block_col++) {\n            if (block_row == 0 && block_col == 0) continue;\n\n            const int* first_block = matrix;\n            const int* current_block = matrix + (block_row * cols * block_size) + (block_col * block_size);\n\n            // Compare blocks using AVX2\n            for (size_t i = 0; i < block_size; i++) {\n                const int* first_row = first_block + i * cols;\n                const int* current_row = current_block + i * cols;\n\n                for (size_t j = 0; j < simd_iterations; j++) {\n                    __m256i first = _mm256_loadu_si256((__m256i*)(first_row + j * simd_width));\n                    __m256i current = _mm256_loadu_si256((__m256i*)(current_row + j * simd_width));\n                    __m256i cmp = _mm256_cmpeq_epi32(first, current);\n                    \n                    if (_mm256_movemask_ps(_mm256_castsi256_ps(cmp)) != 0xFF) {\n                        return false;\n                    }\n                }\n\n                // Handle remaining elements\n                for (size_t j = simd_iterations * simd_width; j < block_size; j++) {\n                    if (first_row[j] != current_row[j]) {\n                        return false;\n                    }\n                }\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_37_AVX", "completion": "```cpp\nbool matrix_blocks_equal_simd(const int* matrix, size_t block_size, size_t rows, size_t cols) {\n    if (block_size == 0 || rows % block_size != 0 || cols % block_size != 0) {\n        return false;\n    }\n\n    const size_t blocks_per_row = cols / block_size;\n    const size_t blocks_per_col = rows / block_size;\n    const size_t elements_per_block = block_size * block_size;\n\n    // Process 8 integers at a time using AVX2\n    const size_t simd_width = 8;\n    const size_t simd_blocks = elements_per_block / simd_width;\n    const size_t remaining = elements_per_block % simd_width;\n\n    for (size_t block_row = 0; block_row < blocks_per_col; block_row++) {\n        for (size_t block_col = 0; block_col < blocks_per_row; block_col++) {\n            if (block_row == 0 && block_col == 0) continue;\n\n            const int* first_block = matrix;\n            const int* current_block = matrix + (block_row * cols * block_size) + (block_col * block_size);\n\n            // Compare SIMD blocks\n            for (size_t i = 0; i < block_size; i++) {\n                const int* first_row = first_block + i * cols;\n                const int* current_row = current_block + i * cols;\n\n                for (size_t j = 0; j < simd_blocks; j++) {\n                    __m256i first = _mm256_loadu_si256((__m256i*)(first_row + j * simd_width));\n                    __m256i current = _mm256_loadu_si256((__m256i*)(current_row + j * simd_width));\n                    __m256i cmp = _mm256_cmpeq_epi32(first, current);\n                    \n                    if (_mm256_movemask_ps(_mm256_castsi256_ps(cmp)) != 0xFF) {\n                        return false;\n                    }\n                }\n\n                // Handle remaining elements\n                for (size_t j = simd_blocks * simd_width; j < block_size; j++) {\n                    if (first_row[j] != current_row[j]) {\n                        return false;\n                    }\n                }\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_38_AVX", "completion": "```cpp\nbool vector_block_equal_simd(const double* vec, double tolerance, size_t length, size_t block_size) {\n    if (!vec || tolerance < 0 || length < block_size || block_size == 0) {\n        return false;\n    }\n\n    size_t num_blocks = length / block_size;\n    if (num_blocks <= 1) {\n        return false;\n    }\n\n    // Number of AVX elements per iteration (4 doubles per 256-bit register)\n    const size_t simd_width = 4;\n    size_t simd_iters = block_size / simd_width;\n    size_t remainder = block_size % simd_width;\n\n    // Process each block\n    for (size_t block = 1; block < num_blocks; block++) {\n        const double* base_ptr = vec;\n        const double* curr_ptr = vec + block * block_size;\n\n        // Process 4 elements at a time using AVX\n        for (size_t i = 0; i < simd_iters; i++) {\n            __m256d base_vec = _mm256_loadu_pd(base_ptr + i * simd_width);\n            __m256d curr_vec = _mm256_loadu_pd(curr_ptr + i * simd_width);\n\n            // Calculate absolute difference\n            __m256d diff = _mm256_sub_pd(base_vec, curr_vec);\n            __m256d abs_diff = _mm256_andnot_pd(_mm256_set1_pd(-0.0), diff);\n            \n            // Compare with tolerance\n            __m256d cmp = _mm256_cmp_pd(abs_diff, _mm256_set1_pd(tolerance), _CMP_GT_OQ);\n            \n            // If any element exceeds tolerance, return false\n            if (_mm256_movemask_pd(cmp) != 0) {\n                return false;\n            }\n        }\n\n        // Handle remaining elements\n        size_t offset = simd_iters * simd_width;\n        for (size_t i = 0; i < remainder; i++) {\n            if (fabs(base_ptr[offset + i] - curr_ptr[offset + i]) > tolerance) {\n                return false;\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_38_AVX", "completion": "```cpp\nbool vector_block_equal_simd(const double* vec, double tolerance, size_t length, size_t block_size) {\n    if (!vec || tolerance < 0 || length < block_size || block_size == 0) {\n        return false;\n    }\n\n    size_t num_blocks = length / block_size;\n    if (num_blocks <= 1) {\n        return false;\n    }\n\n    // Number of AVX elements per iteration (4 doubles per 256-bit register)\n    const size_t simd_width = 4;\n    size_t simd_iters = block_size / simd_width;\n    size_t remainder = block_size % simd_width;\n\n    // Process blocks\n    for (size_t block = 1; block < num_blocks; block++) {\n        const double* base_ptr = vec;\n        const double* curr_ptr = vec + (block * block_size);\n\n        // Process 4 elements at a time using AVX\n        for (size_t i = 0; i < simd_iters; i++) {\n            __m256d base_vec = _mm256_loadu_pd(base_ptr + i * simd_width);\n            __m256d curr_vec = _mm256_loadu_pd(curr_ptr + i * simd_width);\n\n            __m256d diff = _mm256_sub_pd(base_vec, curr_vec);\n            __m256d abs_diff = _mm256_abs_pd(diff);\n            __m256d tol_vec = _mm256_set1_pd(tolerance);\n            __m256d cmp = _mm256_cmp_pd(abs_diff, tol_vec, _CMP_GT_OQ);\n\n            int mask = _mm256_movemask_pd(cmp);\n            if (mask != 0) {\n                return false;\n            }\n        }\n\n        // Handle remaining elements\n        size_t start_idx = simd_iters * simd_width;\n        for (size_t i = 0; i < remainder; i++) {\n            if (fabs(base_ptr[start_idx + i] - curr_ptr[start_idx + i]) > tolerance) {\n                return false;\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_38_AVX", "completion": "```cpp\nbool vector_block_equal_simd(const double* vec, double tolerance, size_t length, size_t block_size) {\n    if (!vec || tolerance < 0 || length < block_size || block_size == 0) {\n        return false;\n    }\n\n    size_t num_blocks = length / block_size;\n    if (num_blocks <= 1) {\n        return false;\n    }\n\n    size_t avx_width = 4; // AVX 256-bit = 4 doubles\n    size_t avx_iters = block_size / avx_width;\n    size_t remainder = block_size % avx_width;\n\n    if (avx_iters == 0) {\n        return false;\n    }\n\n    __m256d tolerance_vec = _mm256_set1_pd(tolerance);\n\n    for (size_t block = 1; block < num_blocks; block++) {\n        const double* base_ptr = vec;\n        const double* curr_ptr = vec + (block * block_size);\n\n        for (size_t i = 0; i < avx_iters; i++) {\n            __m256d base_vec = _mm256_loadu_pd(base_ptr + i * avx_width);\n            __m256d curr_vec = _mm256_loadu_pd(curr_ptr + i * avx_width);\n\n            __m256d diff = _mm256_sub_pd(base_vec, curr_vec);\n            __m256d abs_diff = _mm256_andnot_pd(_mm256_set1_pd(-0.0), diff);\n            __m256d cmp = _mm256_cmp_pd(abs_diff, tolerance_vec, _CMP_GT_OQ);\n\n            int mask = _mm256_movemask_pd(cmp);\n            if (mask != 0) {\n                return false;\n            }\n        }\n\n        // Handle remaining elements\n        for (size_t i = avx_iters * avx_width; i < block_size; i++) {\n            if (fabs(base_ptr[i] - curr_ptr[i]) > tolerance) {\n                return false;\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_38_AVX", "completion": "```cpp\nbool vector_block_equal_simd(const double* vec, double tolerance, size_t length, size_t block_size) {\n    if (!vec || tolerance < 0 || length < block_size || block_size == 0) {\n        return false;\n    }\n\n    size_t num_blocks = length / block_size;\n    if (num_blocks <= 1) {\n        return false;\n    }\n\n    size_t simd_width = 4; // AVX 256-bit = 4 doubles\n    size_t simd_blocks = block_size / simd_width;\n    size_t remainder = block_size % simd_width;\n\n    __m256d tolerance_vec = _mm256_set1_pd(tolerance);\n\n    for (size_t block = 1; block < num_blocks; block++) {\n        const double* base_ptr = vec;\n        const double* curr_ptr = vec + block * block_size;\n\n        for (size_t i = 0; i < simd_blocks; i++) {\n            __m256d base_vec = _mm256_loadu_pd(base_ptr + i * simd_width);\n            __m256d curr_vec = _mm256_loadu_pd(curr_ptr + i * simd_width);\n\n            __m256d diff = _mm256_sub_pd(base_vec, curr_vec);\n            __m256d abs_diff = _mm256_andnot_pd(_mm256_set1_pd(-0.0), diff);\n            __m256d cmp = _mm256_cmp_pd(abs_diff, tolerance_vec, _CMP_GT_OQ);\n\n            int mask = _mm256_movemask_pd(cmp);\n            if (mask != 0) {\n                return false;\n            }\n        }\n\n        // Handle remaining elements\n        for (size_t i = simd_blocks * simd_width; i < block_size; i++) {\n            if (fabs(base_ptr[i] - curr_ptr[i]) > tolerance) {\n                return false;\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_38_AVX", "completion": "```cpp\nbool vector_block_equal_simd(const double* vec, double tolerance, size_t length, size_t block_size) {\n    if (!vec || tolerance < 0 || length < block_size || block_size == 0) {\n        return false;\n    }\n\n    size_t num_blocks = length / block_size;\n    if (num_blocks <= 1) {\n        return false;\n    }\n\n    size_t avx_width = 4; // AVX 256-bit = 4 doubles\n    size_t avx_iters = block_size / avx_width;\n    size_t remainder = block_size % avx_width;\n\n    if (avx_iters == 0) {\n        return false;\n    }\n\n    __m256d tolerance_vec = _mm256_set1_pd(tolerance);\n\n    for (size_t block = 1; block < num_blocks; block++) {\n        const double* base_ptr = vec;\n        const double* curr_ptr = vec + (block * block_size);\n\n        for (size_t i = 0; i < avx_iters; i++) {\n            __m256d base_vec = _mm256_loadu_pd(base_ptr + i * avx_width);\n            __m256d curr_vec = _mm256_loadu_pd(curr_ptr + i * avx_width);\n\n            __m256d diff = _mm256_sub_pd(base_vec, curr_vec);\n            __m256d abs_diff = _mm256_andnot_pd(_mm256_set1_pd(-0.0), diff);\n            __m256d cmp = _mm256_cmp_pd(abs_diff, tolerance_vec, _CMP_GT_OQ);\n\n            int mask = _mm256_movemask_pd(cmp);\n            if (mask != 0) {\n                return false;\n            }\n        }\n\n        // Handle remainder elements\n        for (size_t i = block_size - remainder; i < block_size; i++) {\n            if (fabs(vec[i] - vec[block * block_size + i]) > tolerance) {\n                return false;\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_39_AVX", "completion": "```cpp\nvoid matrix_row_norm_compare_simd(const double* matrix, const double* thresholds, size_t rows, size_t cols, bool* result) {\n    const size_t simd_width = 4;\n    const size_t cols_aligned = (cols / simd_width) * simd_width;\n    \n    for (size_t i = 0; i < rows; i++) {\n        __m256d sum = _mm256_setzero_pd();\n        const double* row = matrix + i * cols;\n        \n        // Process 4 elements at a time\n        for (size_t j = 0; j < cols_aligned; j += simd_width) {\n            __m256d vec = _mm256_loadu_pd(row + j);\n            sum = _mm256_fmadd_pd(vec, vec, sum);\n        }\n        \n        // Handle remaining elements\n        double row_sum = 0.0;\n        double remaining_sum = 0.0;\n        \n        // Horizontal sum of vector\n        double temp[4];\n        _mm256_storeu_pd(temp, sum);\n        row_sum = temp[0] + temp[1] + temp[2] + temp[3];\n        \n        // Process remaining elements\n        for (size_t j = cols_aligned; j < cols; j++) {\n            remaining_sum += row[j] * row[j];\n        }\n        \n        // Compare with threshold\n        result[i] = (sqrt(row_sum + remaining_sum) > thresholds[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_39_AVX", "completion": "```cpp\nvoid matrix_row_norm_compare_simd(const double* matrix, const double* thresholds, size_t rows, size_t cols, bool* result) {\n    const size_t simd_width = 4;\n    const size_t cols_aligned = (cols / simd_width) * simd_width;\n    \n    for (size_t i = 0; i < rows; i++) {\n        __m256d sum = _mm256_setzero_pd();\n        const double* row = matrix + i * cols;\n        \n        // Process 4 elements at a time\n        for (size_t j = 0; j < cols_aligned; j += simd_width) {\n            __m256d vec = _mm256_loadu_pd(row + j);\n            sum = _mm256_add_pd(sum, _mm256_mul_pd(vec, vec));\n        }\n        \n        // Horizontal sum of 4 doubles\n        __m256d temp = _mm256_hadd_pd(sum, sum);\n        double row_sum = ((double*)&temp)[0] + ((double*)&temp)[2];\n        \n        // Handle remaining elements\n        for (size_t j = cols_aligned; j < cols; j++) {\n            row_sum += row[j] * row[j];\n        }\n        \n        result[i] = (row_sum > thresholds[i] * thresholds[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_39_AVX", "completion": "```cpp\nvoid matrix_row_norm_compare_simd(const double* matrix, const double* thresholds, size_t rows, size_t cols, bool* result) {\n    const size_t simd_width = 4;\n    const size_t cols_aligned = (cols / simd_width) * simd_width;\n    \n    for (size_t i = 0; i < rows; i++) {\n        __m256d sum = _mm256_setzero_pd();\n        const double* row = matrix + i * cols;\n        \n        // Process 4 elements at a time\n        for (size_t j = 0; j < cols_aligned; j += simd_width) {\n            __m256d vec = _mm256_loadu_pd(row + j);\n            sum = _mm256_add_pd(sum, _mm256_mul_pd(vec, vec));\n        }\n        \n        // Reduce sum vector\n        __m256d temp = _mm256_hadd_pd(sum, sum);\n        double row_sum = ((double*)&temp)[0] + ((double*)&temp)[2];\n        \n        // Handle remaining elements\n        for (size_t j = cols_aligned; j < cols; j++) {\n            row_sum += row[j] * row[j];\n        }\n        \n        result[i] = (row_sum > thresholds[i] * thresholds[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_39_AVX", "completion": "```cpp\nvoid matrix_row_norm_compare_simd(const double* matrix, const double* thresholds, size_t rows, size_t cols, bool* result) {\n    const size_t simd_width = 4;\n    const size_t cols_aligned = (cols / simd_width) * simd_width;\n    \n    for (size_t i = 0; i < rows; i++) {\n        __m256d sum = _mm256_setzero_pd();\n        const double* row = matrix + i * cols;\n        \n        // Process 4 elements at a time\n        for (size_t j = 0; j < cols_aligned; j += simd_width) {\n            __m256d vec = _mm256_loadu_pd(row + j);\n            sum = _mm256_fmadd_pd(vec, vec, sum);\n        }\n        \n        // Handle remaining elements\n        double row_sum = 0.0;\n        double remaining_sum = 0.0;\n        \n        // Horizontal sum of vector elements\n        double temp[4];\n        _mm256_storeu_pd(temp, sum);\n        row_sum = temp[0] + temp[1] + temp[2] + temp[3];\n        \n        // Process remaining elements\n        for (size_t j = cols_aligned; j < cols; j++) {\n            double val = row[j];\n            remaining_sum += val * val;\n        }\n        \n        // Compare with threshold\n        result[i] = (sqrt(row_sum + remaining_sum) > thresholds[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_39_AVX", "completion": "```cpp\nvoid matrix_row_norm_compare_simd(const double* matrix, const double* thresholds, size_t rows, size_t cols, bool* result) {\n    const size_t simd_width = 4;\n    const size_t cols_aligned = (cols / simd_width) * simd_width;\n    \n    for (size_t i = 0; i < rows; i++) {\n        __m256d sum = _mm256_setzero_pd();\n        const double* row = matrix + i * cols;\n        \n        // Process 4 elements at a time\n        for (size_t j = 0; j < cols_aligned; j += simd_width) {\n            __m256d vec = _mm256_loadu_pd(row + j);\n            sum = _mm256_add_pd(sum, _mm256_mul_pd(vec, vec));\n        }\n        \n        // Horizontal sum of 4 doubles\n        __m256d temp = _mm256_hadd_pd(sum, sum);\n        double row_sum = ((double*)&temp)[0] + ((double*)&temp)[2];\n        \n        // Handle remaining elements\n        for (size_t j = cols_aligned; j < cols; j++) {\n            row_sum += row[j] * row[j];\n        }\n        \n        result[i] = (row_sum > thresholds[i] * thresholds[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_40_AVX", "completion": "```cpp\nvoid tensor_bitwise_or_simd(const uint32_t* A, const uint32_t* B, uint32_t* C, size_t length) {\n    size_t i;\n    size_t simd_length = length - (length % 8);\n    \n    for (i = 0; i < simd_length; i += 8) {\n        __m256i a = _mm256_loadu_si256((__m256i*)(A + i));\n        __m256i b = _mm256_loadu_si256((__m256i*)(B + i));\n        __m256i c = _mm256_or_si256(a, b);\n        _mm256_storeu_si256((__m256i*)(C + i), c);\n    }\n\n    for (; i < length; i++) {\n        C[i] = A[i] | B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_40_AVX", "completion": "```cpp\nvoid tensor_bitwise_or_simd(const uint32_t* A, const uint32_t* B, uint32_t* C, size_t length) {\n    size_t i;\n    size_t simd_length = length - (length % 8);\n    \n    for (i = 0; i < simd_length; i += 8) {\n        __m256i a = _mm256_loadu_si256((__m256i*)(A + i));\n        __m256i b = _mm256_loadu_si256((__m256i*)(B + i));\n        __m256i c = _mm256_or_si256(a, b);\n        _mm256_storeu_si256((__m256i*)(C + i), c);\n    }\n\n    for (; i < length; i++) {\n        C[i] = A[i] | B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_40_AVX", "completion": "```cpp\nvoid tensor_bitwise_or_simd(const uint32_t* A, const uint32_t* B, uint32_t* C, size_t length) {\n    size_t i;\n    size_t simd_length = length - (length % 8);\n    \n    for (i = 0; i < simd_length; i += 8) {\n        __m256i a = _mm256_loadu_si256((__m256i*)(A + i));\n        __m256i b = _mm256_loadu_si256((__m256i*)(B + i));\n        __m256i c = _mm256_or_si256(a, b);\n        _mm256_storeu_si256((__m256i*)(C + i), c);\n    }\n\n    for (; i < length; i++) {\n        C[i] = A[i] | B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_40_AVX", "completion": "```cpp\nvoid tensor_bitwise_or_simd(const uint32_t* A, const uint32_t* B, uint32_t* C, size_t length) {\n    size_t i;\n    size_t simd_length = length - (length % 8);\n    \n    for (i = 0; i < simd_length; i += 8) {\n        __m256i a = _mm256_loadu_si256((__m256i*)(A + i));\n        __m256i b = _mm256_loadu_si256((__m256i*)(B + i));\n        __m256i c = _mm256_or_si256(a, b);\n        _mm256_storeu_si256((__m256i*)(C + i), c);\n    }\n\n    for (; i < length; i++) {\n        C[i] = A[i] | B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_40_AVX", "completion": "```cpp\nvoid tensor_bitwise_or_simd(const uint32_t* A, const uint32_t* B, uint32_t* C, size_t length) {\n    size_t i;\n    size_t simd_length = length - (length % 8);\n    \n    for (i = 0; i < simd_length; i += 8) {\n        __m256i a = _mm256_loadu_si256((__m256i*)(A + i));\n        __m256i b = _mm256_loadu_si256((__m256i*)(B + i));\n        __m256i c = _mm256_or_si256(a, b);\n        _mm256_storeu_si256((__m256i*)(C + i), c);\n    }\n\n    for (; i < length; i++) {\n        C[i] = A[i] | B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_41_AVX", "completion": "```cpp\nint64_t squarediff_simd(const int8_t * A, const int8_t * B, size_t length) {\n    int64_t sum_squares = 0;\n    int64_t sum_products = 0;\n    \n    size_t i = 0;\n    size_t vec_size = length - (length % 32);\n    \n    __m256i sum_sq = _mm256_setzero_si256();\n    __m256i sum_prod = _mm256_setzero_si256();\n    \n    for(; i < vec_size; i += 32) {\n        __m256i a = _mm256_loadu_si256((__m256i*)(A + i));\n        __m256i b = _mm256_loadu_si256((__m256i*)(B + i));\n        \n        // Convert 8-bit to 16-bit\n        __m256i a_low = _mm256_cvtepi8_epi16(_mm256_extracti128_si256(a, 0));\n        __m256i a_high = _mm256_cvtepi8_epi16(_mm256_extracti128_si256(a, 1));\n        __m256i b_low = _mm256_cvtepi8_epi16(_mm256_extracti128_si256(b, 0));\n        __m256i b_high = _mm256_cvtepi8_epi16(_mm256_extracti128_si256(b, 1));\n        \n        // Calculate squares\n        __m256i sq_a_low = _mm256_mullo_epi16(a_low, a_low);\n        __m256i sq_a_high = _mm256_mullo_epi16(a_high, a_high);\n        __m256i sq_b_low = _mm256_mullo_epi16(b_low, b_low);\n        __m256i sq_b_high = _mm256_mullo_epi16(b_high, b_high);\n        \n        // Calculate products\n        __m256i prod_low = _mm256_mullo_epi16(a_low, b_low);\n        __m256i prod_high = _mm256_mullo_epi16(a_high, b_high);\n        \n        // Accumulate squares and products\n        sum_sq = _mm256_add_epi32(sum_sq, _mm256_add_epi32(\n            _mm256_add_epi32(_mm256_cvtepi16_epi32(_mm256_extracti128_si256(sq_a_low, 0)),\n                            _mm256_cvtepi16_epi32(_mm256_extracti128_si256(sq_a_low, 1))),\n            _mm256_add_epi32(_mm256_cvtepi16_epi32(_mm256_extracti128_si256(sq_b_low, 0)),\n                            _mm256_cvtepi16_epi32(_mm256_extracti128_si256(sq_b_low, 1)))));\n                            \n        sum_sq = _mm256_add_epi32(sum_sq, _mm256_add_epi32(\n            _mm256_add_epi32(_mm256_cvtepi16_epi32(_mm256_extracti128_si256(sq_a_high, 0)),\n                            _mm256_cvtepi16_epi32(_mm256_extracti128_si256(sq_a_high, 1))),\n            _mm256_add_epi32(_mm256_cvtepi16_epi32(_mm256_extracti128_si256(sq_b_high, 0)),\n                            _mm256_cvtepi16_epi32(_mm256_extracti128_si256(sq_b_high, 1)))));\n                            \n        sum_prod = _mm256_add_epi32(sum_prod, _mm256_add_epi32(\n            _mm256_cvtepi16_epi32(_mm256_extracti128_si256(prod_low, 0)),\n            _mm256_cvtepi16_epi32(_mm256_extracti128_si256(prod_low, 1))));\n            \n        sum_prod = _mm256_add_epi32(sum_prod, _mm256_add_epi32(\n            _mm256_cvtepi16_epi32(_mm256_extracti128_si256(prod_high, 0)),\n            _mm256_cvtepi16_epi32(_mm256_extracti128_si256(prod_high, 1))));\n    }\n    \n    // Horizontal sum\n    int32_t temp[8];\n    _mm256_storeu_si256((__m256i*)temp, sum_sq);\n    for(int j = 0; j < 8; j++) {\n        sum_squares += temp[j];\n    }\n    \n    _mm256_storeu_si256((__m256i*)temp, sum_prod);\n    for(int j = 0; j < 8; j++) {\n        sum_products += temp[j];\n    }\n    \n    // Handle remaining elements\n    for(; i < length; i++) {\n        sum_squares += A[i] * A[i] + B[i] * B[i];\n        sum_products += A[i] * B[i];\n    }\n    \n    return sum_squares - (2 * sum_products);\n}\n```"}
{"task_id": "SimdBench_41_AVX", "completion": "```cpp\nint64_t squarediff_simd(const int8_t * A, const int8_t * B, size_t length) {\n    int64_t sum_squares = 0;\n    int64_t sum_products = 0;\n    \n    size_t i = 0;\n    size_t simd_length = length - (length % 32);\n    \n    __m256i sum_sq_acc = _mm256_setzero_si256();\n    __m256i sum_prod_acc = _mm256_setzero_si256();\n    \n    for (; i < simd_length; i += 32) {\n        __m256i a = _mm256_loadu_si256((__m256i*)(A + i));\n        __m256i b = _mm256_loadu_si256((__m256i*)(B + i));\n        \n        // Convert int8 to int16\n        __m256i a_low = _mm256_cvtepi8_epi16(_mm256_extracti128_si256(a, 0));\n        __m256i a_high = _mm256_cvtepi8_epi16(_mm256_extracti128_si256(a, 1));\n        __m256i b_low = _mm256_cvtepi8_epi16(_mm256_extracti128_si256(b, 0));\n        __m256i b_high = _mm256_cvtepi8_epi16(_mm256_extracti128_si256(b, 1));\n        \n        // Calculate squares\n        __m256i sq_a_low = _mm256_mullo_epi16(a_low, a_low);\n        __m256i sq_a_high = _mm256_mullo_epi16(a_high, a_high);\n        __m256i sq_b_low = _mm256_mullo_epi16(b_low, b_low);\n        __m256i sq_b_high = _mm256_mullo_epi16(b_high, b_high);\n        \n        // Calculate products\n        __m256i prod_low = _mm256_mullo_epi16(a_low, b_low);\n        __m256i prod_high = _mm256_mullo_epi16(a_high, b_high);\n        \n        // Accumulate squares\n        sum_sq_acc = _mm256_add_epi32(sum_sq_acc, _mm256_add_epi32(\n            _mm256_cvtepi16_epi32(_mm256_extracti128_si256(sq_a_low, 0)),\n            _mm256_cvtepi16_epi32(_mm256_extracti128_si256(sq_a_low, 1))));\n        sum_sq_acc = _mm256_add_epi32(sum_sq_acc, _mm256_add_epi32(\n            _mm256_cvtepi16_epi32(_mm256_extracti128_si256(sq_a_high, 0)),\n            _mm256_cvtepi16_epi32(_mm256_extracti128_si256(sq_a_high, 1))));\n        sum_sq_acc = _mm256_add_epi32(sum_sq_acc, _mm256_add_epi32(\n            _mm256_cvtepi16_epi32(_mm256_extracti128_si256(sq_b_low, 0)),\n            _mm256_cvtepi16_epi32(_mm256_extracti128_si256(sq_b_low, 1))));\n        sum_sq_acc = _mm256_add_epi32(sum_sq_acc, _mm256_add_epi32(\n            _mm256_cvtepi16_epi32(_mm256_extracti128_si256(sq_b_high, 0)),\n            _mm256_cvtepi16_epi32(_mm256_extracti128_si256(sq_b_high, 1))));\n            \n        // Accumulate products\n        sum_prod_acc = _mm256_add_epi32(sum_prod_acc, _mm256_add_epi32(\n            _mm256_cvtepi16_epi32(_mm256_extracti128_si256(prod_low, 0)),\n            _mm256_cvtepi16_epi32(_mm256_extracti128_si256(prod_low, 1))));\n        sum_prod_acc = _mm256_add_epi32(sum_prod_acc, _mm256_add_epi32(\n            _mm256_cvtepi16_epi32(_mm256_extracti128_si256(prod_high, 0)),\n            _mm256_cvtepi16_epi32(_mm256_extracti128_si256(prod_high, 1))));\n    }\n    \n    // Horizontal sum\n    int32_t sum_sq_arr[8], sum_prod_arr[8];\n    _mm256_storeu_si256((__m256i*)sum_sq_arr, sum_sq_acc);\n    _mm256_storeu_si256((__m256i*)sum_prod_arr, sum_prod_acc);\n    \n    for(int j = 0; j < 8; j++) {\n        sum_squares += sum_sq_arr[j];\n        sum_products += sum_prod_arr[j];\n    }\n    \n    // Handle remaining elements\n    for(; i < length; i++) {\n        sum_squares += A[i] * A[i] + B[i] * B[i];\n        sum_products += A[i] * B[i];\n    }\n    \n    return sum_squares - 2 * sum_products;\n}\n```"}
{"task_id": "SimdBench_41_AVX", "completion": "```cpp\nint64_t squarediff_simd(const int8_t * A, const int8_t * B, size_t length) {\n    int64_t sum_squares = 0;\n    int64_t sum_products = 0;\n    \n    size_t i = 0;\n    size_t simd_width = 32;\n    \n    for (; i + simd_width <= length; i += simd_width) {\n        __m256i a = _mm256_loadu_si256((__m256i*)(A + i));\n        __m256i b = _mm256_loadu_si256((__m256i*)(B + i));\n        \n        // Convert 8-bit to 16-bit\n        __m256i a_low = _mm256_cvtepi8_epi16(_mm256_extracti128_si256(a, 0));\n        __m256i a_high = _mm256_cvtepi8_epi16(_mm256_extracti128_si256(a, 1));\n        __m256i b_low = _mm256_cvtepi8_epi16(_mm256_extracti128_si256(b, 0));\n        __m256i b_high = _mm256_cvtepi8_epi16(_mm256_extracti128_si256(b, 1));\n        \n        // Compute squares\n        __m256i squares_low = _mm256_mullo_epi16(a_low, a_low);\n        __m256i squares_high = _mm256_mullo_epi16(a_high, a_high);\n        squares_low = _mm256_add_epi16(squares_low, _mm256_mullo_epi16(b_low, b_low));\n        squares_high = _mm256_add_epi16(squares_high, _mm256_mullo_epi16(b_high, b_high));\n        \n        // Compute products\n        __m256i products_low = _mm256_mullo_epi16(a_low, b_low);\n        __m256i products_high = _mm256_mullo_epi16(a_high, b_high);\n        \n        // Convert 16-bit to 32-bit\n        __m256i squares_1 = _mm256_cvtepi16_epi32(_mm256_extracti128_si256(squares_low, 0));\n        __m256i squares_2 = _mm256_cvtepi16_epi32(_mm256_extracti128_si256(squares_low, 1));\n        __m256i squares_3 = _mm256_cvtepi16_epi32(_mm256_extracti128_si256(squares_high, 0));\n        __m256i squares_4 = _mm256_cvtepi16_epi32(_mm256_extracti128_si256(squares_high, 1));\n        \n        __m256i products_1 = _mm256_cvtepi16_epi32(_mm256_extracti128_si256(products_low, 0));\n        __m256i products_2 = _mm256_cvtepi16_epi32(_mm256_extracti128_si256(products_low, 1));\n        __m256i products_3 = _mm256_cvtepi16_epi32(_mm256_extracti128_si256(products_high, 0));\n        __m256i products_4 = _mm256_cvtepi16_epi32(_mm256_extracti128_si256(products_high, 1));\n        \n        // Horizontal sum\n        __m256i sum_squares_vec = _mm256_add_epi32(_mm256_add_epi32(squares_1, squares_2),\n                                                  _mm256_add_epi32(squares_3, squares_4));\n        __m256i sum_products_vec = _mm256_add_epi32(_mm256_add_epi32(products_1, products_2),\n                                                   _mm256_add_epi32(products_3, products_4));\n        \n        int32_t squares_arr[8], products_arr[8];\n        _mm256_storeu_si256((__m256i*)squares_arr, sum_squares_vec);\n        _mm256_storeu_si256((__m256i*)products_arr, sum_products_vec);\n        \n        for(int j = 0; j < 8; j++) {\n            sum_squares += squares_arr[j];\n            sum_products += products_arr[j];\n        }\n    }\n    \n    // Handle remaining elements\n    for(; i < length; i++) {\n        sum_squares += A[i] * A[i] + B[i] * B[i];\n        sum_products += A[i] * B[i];\n    }\n    \n    return sum_squares - (2 * sum_products);\n}\n```"}
{"task_id": "SimdBench_41_AVX", "completion": "```cpp\nint64_t squarediff_simd(const int8_t * A, const int8_t * B, size_t length) {\n    int64_t sum_squares = 0;\n    int64_t sum_products = 0;\n    \n    size_t i = 0;\n    size_t vec_size = length - (length % 32);\n    \n    __m256i sum_sq = _mm256_setzero_si256();\n    __m256i sum_prod = _mm256_setzero_si256();\n    \n    for(; i < vec_size; i += 32) {\n        __m256i a = _mm256_loadu_si256((__m256i*)(A + i));\n        __m256i b = _mm256_loadu_si256((__m256i*)(B + i));\n        \n        // Convert int8 to int16\n        __m256i a_low = _mm256_cvtepi8_epi16(_mm256_extracti128_si256(a, 0));\n        __m256i a_high = _mm256_cvtepi8_epi16(_mm256_extracti128_si256(a, 1));\n        __m256i b_low = _mm256_cvtepi8_epi16(_mm256_extracti128_si256(b, 0));\n        __m256i b_high = _mm256_cvtepi8_epi16(_mm256_extracti128_si256(b, 1));\n        \n        // Calculate squares\n        __m256i sq_a_low = _mm256_mullo_epi16(a_low, a_low);\n        __m256i sq_a_high = _mm256_mullo_epi16(a_high, a_high);\n        __m256i sq_b_low = _mm256_mullo_epi16(b_low, b_low);\n        __m256i sq_b_high = _mm256_mullo_epi16(b_high, b_high);\n        \n        // Calculate products\n        __m256i prod_low = _mm256_mullo_epi16(a_low, b_low);\n        __m256i prod_high = _mm256_mullo_epi16(a_high, b_high);\n        \n        // Add squares\n        sum_sq = _mm256_add_epi32(sum_sq, _mm256_add_epi32(\n            _mm256_add_epi32(\n                _mm256_cvtepi16_epi32(_mm256_extracti128_si256(sq_a_low, 0)),\n                _mm256_cvtepi16_epi32(_mm256_extracti128_si256(sq_a_low, 1))\n            ),\n            _mm256_add_epi32(\n                _mm256_cvtepi16_epi32(_mm256_extracti128_si256(sq_b_low, 0)),\n                _mm256_cvtepi16_epi32(_mm256_extracti128_si256(sq_b_low, 1))\n            )\n        ));\n        \n        sum_sq = _mm256_add_epi32(sum_sq, _mm256_add_epi32(\n            _mm256_cvtepi16_epi32(_mm256_extracti128_si256(sq_a_high, 0)),\n            _mm256_cvtepi16_epi32(_mm256_extracti128_si256(sq_a_high, 1))\n        ));\n        \n        sum_sq = _mm256_add_epi32(sum_sq, _mm256_add_epi32(\n            _mm256_cvtepi16_epi32(_mm256_extracti128_si256(sq_b_high, 0)),\n            _mm256_cvtepi16_epi32(_mm256_extracti128_si256(sq_b_high, 1))\n        ));\n        \n        // Add products\n        sum_prod = _mm256_add_epi32(sum_prod, _mm256_add_epi32(\n            _mm256_add_epi32(\n                _mm256_cvtepi16_epi32(_mm256_extracti128_si256(prod_low, 0)),\n                _mm256_cvtepi16_epi32(_mm256_extracti128_si256(prod_low, 1))\n            ),\n            _mm256_add_epi32(\n                _mm256_cvtepi16_epi32(_mm256_extracti128_si256(prod_high, 0)),\n                _mm256_cvtepi16_epi32(_mm256_extracti128_si256(prod_high, 1))\n            )\n        ));\n    }\n    \n    int32_t temp_sq[8];\n    int32_t temp_prod[8];\n    _mm256_storeu_si256((__m256i*)temp_sq, sum_sq);\n    _mm256_storeu_si256((__m256i*)temp_prod, sum_prod);\n    \n    for(int j = 0; j < 8; j++) {\n        sum_squares += temp_sq[j];\n        sum_products += temp_prod[j];\n    }\n    \n    // Handle remaining elements\n    for(; i < length; i++) {\n        sum_squares += A[i] * A[i] + B[i] * B[i];\n        sum_products += A[i] * B[i];\n    }\n    \n    return sum_squares - (2 * sum_products);\n}\n```"}
{"task_id": "SimdBench_41_AVX", "completion": "```cpp\nint64_t squarediff_simd(const int8_t * A, const int8_t * B, size_t length) {\n    __m256i sum_squares = _mm256_setzero_si256();\n    __m256i sum_products = _mm256_setzero_si256();\n    \n    size_t i;\n    for(i = 0; i + 32 <= length; i += 32) {\n        __m256i a = _mm256_loadu_si256((__m256i*)(A + i));\n        __m256i b = _mm256_loadu_si256((__m256i*)(B + i));\n        \n        // Convert 8-bit to 16-bit\n        __m256i a_low = _mm256_cvtepi8_epi16(_mm256_extracti128_si256(a, 0));\n        __m256i a_high = _mm256_cvtepi8_epi16(_mm256_extracti128_si256(a, 1));\n        __m256i b_low = _mm256_cvtepi8_epi16(_mm256_extracti128_si256(b, 0));\n        __m256i b_high = _mm256_cvtepi8_epi16(_mm256_extracti128_si256(b, 1));\n        \n        // Calculate squares and products\n        __m256i squares_low = _mm256_add_epi32(_mm256_madd_epi16(a_low, a_low), \n                                              _mm256_madd_epi16(b_low, b_low));\n        __m256i squares_high = _mm256_add_epi32(_mm256_madd_epi16(a_high, a_high), \n                                               _mm256_madd_epi16(b_high, b_high));\n        __m256i products_low = _mm256_slli_epi32(_mm256_madd_epi16(a_low, b_low), 1);\n        __m256i products_high = _mm256_slli_epi32(_mm256_madd_epi16(a_high, b_high), 1);\n        \n        sum_squares = _mm256_add_epi64(sum_squares, _mm256_add_epi64(\n            _mm256_cvtepi32_epi64(_mm256_extracti128_si256(squares_low, 0)),\n            _mm256_cvtepi32_epi64(_mm256_extracti128_si256(squares_low, 1))));\n        sum_squares = _mm256_add_epi64(sum_squares, _mm256_add_epi64(\n            _mm256_cvtepi32_epi64(_mm256_extracti128_si256(squares_high, 0)),\n            _mm256_cvtepi32_epi64(_mm256_extracti128_si256(squares_high, 1))));\n            \n        sum_products = _mm256_add_epi64(sum_products, _mm256_add_epi64(\n            _mm256_cvtepi32_epi64(_mm256_extracti128_si256(products_low, 0)),\n            _mm256_cvtepi32_epi64(_mm256_extracti128_si256(products_low, 1))));\n        sum_products = _mm256_add_epi64(sum_products, _mm256_add_epi64(\n            _mm256_cvtepi32_epi64(_mm256_extracti128_si256(products_high, 0)),\n            _mm256_cvtepi32_epi64(_mm256_extracti128_si256(products_high, 1))));\n    }\n    \n    int64_t result = 0;\n    int64_t squares = 0;\n    int64_t products = 0;\n    \n    alignas(32) int64_t squares_arr[4];\n    alignas(32) int64_t products_arr[4];\n    _mm256_store_si256((__m256i*)squares_arr, sum_squares);\n    _mm256_store_si256((__m256i*)products_arr, sum_products);\n    \n    for(int j = 0; j < 4; j++) {\n        squares += squares_arr[j];\n        products += products_arr[j];\n    }\n    \n    // Handle remaining elements\n    for(; i < length; i++) {\n        squares += A[i] * A[i] + B[i] * B[i];\n        products += 2 * A[i] * B[i];\n    }\n    \n    return squares - products;\n}\n```"}
{"task_id": "SimdBench_42_AVX", "completion": "```cpp\nvoid tensor_bit_clear_simd(const uint64_t* A, const uint64_t* B, uint64_t* C, size_t length) {\n    size_t i;\n    size_t simd_length = length - (length % 4);\n    \n    __m256i ones = _mm256_set1_epi64x(-1);\n    \n    for (i = 0; i < simd_length; i += 4) {\n        __m256i a = _mm256_loadu_si256((__m256i*)(A + i));\n        __m256i b = _mm256_loadu_si256((__m256i*)(B + i));\n        __m256i notb = _mm256_xor_si256(b, ones);\n        __m256i result = _mm256_and_si256(a, notb);\n        _mm256_storeu_si256((__m256i*)(C + i), result);\n    }\n\n    for (; i < length; i++) {\n        C[i] = A[i] & (~B[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_42_AVX", "completion": "```cpp\nvoid tensor_bit_clear_simd(const uint64_t* A, const uint64_t* B, uint64_t* C, size_t length) {\n    size_t i;\n    const size_t simd_width = 4; // AVX2 processes 4 uint64_t elements at a time\n    size_t simd_length = length - (length % simd_width);\n\n    // Process 4 elements at a time using AVX2\n    for (i = 0; i < simd_length; i += simd_width) {\n        __m256i a = _mm256_loadu_si256((const __m256i*)(A + i));\n        __m256i b = _mm256_loadu_si256((const __m256i*)(B + i));\n        \n        // Bitwise NOT of B\n        __m256i not_b = _mm256_xor_si256(b, _mm256_set1_epi64x(-1));\n        \n        // Bitwise AND between A and NOT B\n        __m256i result = _mm256_and_si256(a, not_b);\n        \n        _mm256_storeu_si256((__m256i*)(C + i), result);\n    }\n\n    // Handle remaining elements\n    for (; i < length; i++) {\n        C[i] = A[i] & (~B[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_42_AVX", "completion": "```cpp\nvoid tensor_bit_clear_simd(const uint64_t* A, const uint64_t* B, uint64_t* C, size_t length) {\n    size_t i;\n    size_t simd_length = length - (length % 4);\n    \n    __m256i ones = _mm256_set1_epi64x(-1);\n    \n    for (i = 0; i < simd_length; i += 4) {\n        __m256i a = _mm256_loadu_si256((__m256i*)(A + i));\n        __m256i b = _mm256_loadu_si256((__m256i*)(B + i));\n        __m256i notb = _mm256_xor_si256(b, ones);\n        __m256i result = _mm256_and_si256(a, notb);\n        _mm256_storeu_si256((__m256i*)(C + i), result);\n    }\n\n    for (; i < length; i++) {\n        C[i] = A[i] & (~B[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_42_AVX", "completion": "```cpp\nvoid tensor_bit_clear_simd(const uint64_t* A, const uint64_t* B, uint64_t* C, size_t length) {\n    size_t i;\n    size_t simd_length = length - (length % 4);\n    \n    __m256i ones = _mm256_set1_epi64x(-1);\n    \n    for (i = 0; i < simd_length; i += 4) {\n        __m256i a = _mm256_loadu_si256((__m256i*)(A + i));\n        __m256i b = _mm256_loadu_si256((__m256i*)(B + i));\n        __m256i notb = _mm256_xor_si256(b, ones);\n        __m256i result = _mm256_and_si256(a, notb);\n        _mm256_storeu_si256((__m256i*)(C + i), result);\n    }\n\n    for (; i < length; i++) {\n        C[i] = A[i] & (~B[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_42_AVX", "completion": "```cpp\nvoid tensor_bit_clear_simd(const uint64_t* A, const uint64_t* B, uint64_t* C, size_t length) {\n    size_t i;\n    size_t simd_length = length - (length % 4);\n    \n    __m256i ones = _mm256_set1_epi64x(-1);\n    \n    for (i = 0; i < simd_length; i += 4) {\n        __m256i a = _mm256_loadu_si256((__m256i*)(A + i));\n        __m256i b = _mm256_loadu_si256((__m256i*)(B + i));\n        __m256i notb = _mm256_xor_si256(b, ones);\n        __m256i result = _mm256_and_si256(a, notb);\n        _mm256_storeu_si256((__m256i*)(C + i), result);\n    }\n\n    for (; i < length; i++) {\n        C[i] = A[i] & (~B[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_43_AVX", "completion": "```cpp\nvoid tensor_three_valued_logic_simd(const int8_t* A, const int8_t* B, int8_t* C, size_t length) {\n    size_t i;\n    const size_t vector_size = 32;\n    size_t aligned_length = length & ~(vector_size - 1);\n\n    __m256i ones = _mm256_set1_epi8(1);\n    __m256i neg_ones = _mm256_set1_epi8(-1);\n    __m256i zeros = _mm256_setzero_si256();\n\n    for (i = 0; i < aligned_length; i += vector_size) {\n        __m256i a = _mm256_loadu_si256((__m256i*)(A + i));\n        __m256i b = _mm256_loadu_si256((__m256i*)(B + i));\n\n        __m256i a_pos = _mm256_cmpgt_epi8(a, zeros);\n        __m256i b_pos = _mm256_cmpgt_epi8(b, zeros);\n        __m256i a_neg = _mm256_cmpgt_epi8(zeros, a);\n        __m256i b_neg = _mm256_cmpgt_epi8(zeros, b);\n\n        __m256i both_pos = _mm256_and_si256(a_pos, b_pos);\n        __m256i both_neg = _mm256_and_si256(a_neg, b_neg);\n\n        __m256i result = _mm256_and_si256(both_pos, ones);\n        __m256i neg_result = _mm256_and_si256(both_neg, neg_ones);\n        result = _mm256_or_si256(result, neg_result);\n\n        _mm256_storeu_si256((__m256i*)(C + i), result);\n    }\n\n    for (; i < length; i++) {\n        if (A[i] > 0 && B[i] > 0) {\n            C[i] = 1;\n        } else if (A[i] < 0 && B[i] < 0) {\n            C[i] = -1;\n        } else {\n            C[i] = 0;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_43_AVX", "completion": "```cpp\nvoid tensor_three_valued_logic_simd(const int8_t* A, const int8_t* B, int8_t* C, size_t length) {\n    size_t i;\n    const size_t simd_width = 32;\n    size_t aligned_length = length & ~(simd_width - 1);\n    \n    __m256i ones = _mm256_set1_epi8(1);\n    __m256i neg_ones = _mm256_set1_epi8(-1);\n    __m256i zeros = _mm256_setzero_si256();\n\n    for (i = 0; i < aligned_length; i += simd_width) {\n        __m256i a = _mm256_loadu_si256((__m256i*)(A + i));\n        __m256i b = _mm256_loadu_si256((__m256i*)(B + i));\n\n        __m256i both_pos = _mm256_and_si256(\n            _mm256_cmpgt_epi8(a, zeros),\n            _mm256_cmpgt_epi8(b, zeros)\n        );\n\n        __m256i both_neg = _mm256_and_si256(\n            _mm256_cmpgt_epi8(zeros, a),\n            _mm256_cmpgt_epi8(zeros, b)\n        );\n\n        __m256i result = _mm256_or_si256(\n            _mm256_and_si256(both_pos, ones),\n            _mm256_and_si256(both_neg, neg_ones)\n        );\n\n        _mm256_storeu_si256((__m256i*)(C + i), result);\n    }\n\n    // Handle remaining elements\n    for (; i < length; i++) {\n        if (A[i] > 0 && B[i] > 0) {\n            C[i] = 1;\n        } else if (A[i] < 0 && B[i] < 0) {\n            C[i] = -1;\n        } else {\n            C[i] = 0;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_43_AVX", "completion": "```cpp\nvoid tensor_three_valued_logic_simd(const int8_t* A, const int8_t* B, int8_t* C, size_t length) {\n    const size_t simd_width = 32;\n    size_t i = 0;\n    \n    __m256i ones = _mm256_set1_epi8(1);\n    __m256i neg_ones = _mm256_set1_epi8(-1);\n    __m256i zeros = _mm256_setzero_si256();\n\n    for (; i + simd_width <= length; i += simd_width) {\n        __m256i a = _mm256_loadu_si256((__m256i*)(A + i));\n        __m256i b = _mm256_loadu_si256((__m256i*)(B + i));\n\n        __m256i a_pos = _mm256_cmpgt_epi8(a, zeros);\n        __m256i b_pos = _mm256_cmpgt_epi8(b, zeros);\n        __m256i a_neg = _mm256_cmpgt_epi8(zeros, a);\n        __m256i b_neg = _mm256_cmpgt_epi8(zeros, b);\n\n        __m256i both_pos = _mm256_and_si256(a_pos, b_pos);\n        __m256i both_neg = _mm256_and_si256(a_neg, b_neg);\n\n        __m256i result = _mm256_and_si256(both_pos, ones);\n        __m256i neg_result = _mm256_and_si256(both_neg, neg_ones);\n        result = _mm256_or_si256(result, neg_result);\n\n        _mm256_storeu_si256((__m256i*)(C + i), result);\n    }\n\n    // Handle remaining elements\n    for (; i < length; i++) {\n        if (A[i] > 0 && B[i] > 0) {\n            C[i] = 1;\n        } else if (A[i] < 0 && B[i] < 0) {\n            C[i] = -1;\n        } else {\n            C[i] = 0;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_43_AVX", "completion": "```cpp\nvoid tensor_three_valued_logic_simd(const int8_t* A, const int8_t* B, int8_t* C, size_t length) {\n    size_t i;\n    size_t simd_length = length - (length % 32);\n    \n    __m256i ones = _mm256_set1_epi8(1);\n    __m256i neg_ones = _mm256_set1_epi8(-1);\n    __m256i zeros = _mm256_setzero_si256();\n\n    for (i = 0; i < simd_length; i += 32) {\n        __m256i a = _mm256_loadu_si256((__m256i*)(A + i));\n        __m256i b = _mm256_loadu_si256((__m256i*)(B + i));\n\n        __m256i a_pos = _mm256_cmpgt_epi8(a, zeros);\n        __m256i b_pos = _mm256_cmpgt_epi8(b, zeros);\n        __m256i a_neg = _mm256_cmpgt_epi8(zeros, a);\n        __m256i b_neg = _mm256_cmpgt_epi8(zeros, b);\n\n        __m256i both_pos = _mm256_and_si256(a_pos, b_pos);\n        __m256i both_neg = _mm256_and_si256(a_neg, b_neg);\n\n        __m256i result = _mm256_and_si256(both_pos, ones);\n        __m256i neg_result = _mm256_and_si256(both_neg, neg_ones);\n        result = _mm256_or_si256(result, neg_result);\n\n        _mm256_storeu_si256((__m256i*)(C + i), result);\n    }\n\n    for (; i < length; i++) {\n        if (A[i] > 0 && B[i] > 0) {\n            C[i] = 1;\n        } else if (A[i] < 0 && B[i] < 0) {\n            C[i] = -1;\n        } else {\n            C[i] = 0;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_43_AVX", "completion": "```cpp\nvoid tensor_three_valued_logic_simd(const int8_t* A, const int8_t* B, int8_t* C, size_t length) {\n    const size_t vector_size = 32;\n    size_t i;\n    \n    __m256i ones = _mm256_set1_epi8(1);\n    __m256i neg_ones = _mm256_set1_epi8(-1);\n    __m256i zeros = _mm256_setzero_si256();\n\n    for (i = 0; i + vector_size <= length; i += vector_size) {\n        __m256i a = _mm256_loadu_si256((__m256i*)(A + i));\n        __m256i b = _mm256_loadu_si256((__m256i*)(B + i));\n\n        __m256i a_pos = _mm256_cmpgt_epi8(a, zeros);\n        __m256i b_pos = _mm256_cmpgt_epi8(b, zeros);\n        __m256i a_neg = _mm256_cmpgt_epi8(zeros, a);\n        __m256i b_neg = _mm256_cmpgt_epi8(zeros, b);\n\n        __m256i both_pos = _mm256_and_si256(a_pos, b_pos);\n        __m256i both_neg = _mm256_and_si256(a_neg, b_neg);\n\n        __m256i result = _mm256_and_si256(both_pos, ones);\n        __m256i neg_result = _mm256_and_si256(both_neg, neg_ones);\n        result = _mm256_or_si256(result, neg_result);\n\n        _mm256_storeu_si256((__m256i*)(C + i), result);\n    }\n\n    // Handle remaining elements\n    for (; i < length; i++) {\n        if (A[i] > 0 && B[i] > 0) {\n            C[i] = 1;\n        } else if (A[i] < 0 && B[i] < 0) {\n            C[i] = -1;\n        } else {\n            C[i] = 0;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_44_AVX", "completion": "```cpp\nvoid tensor_bit_op_simd(const uint16_t* A, const uint16_t* B, uint16_t* C, size_t length) {\n    size_t midpoint = length / 2;\n    size_t i = 0;\n    \n    // Process 16 elements at a time using AVX2\n    for (; i + 15 < midpoint; i += 16) {\n        __m256i a = _mm256_loadu_si256((__m256i*)(A + i));\n        __m256i b = _mm256_loadu_si256((__m256i*)(B + i));\n        __m256i result = _mm256_xor_si256(a, b);\n        _mm256_storeu_si256((__m256i*)(C + i), result);\n    }\n\n    // Handle remaining elements before midpoint\n    for (; i < midpoint; i++) {\n        C[i] = A[i] ^ B[i];\n    }\n\n    // Handle midpoint\n    C[midpoint] = A[midpoint];\n\n    i = midpoint + 1;\n    // Process elements after midpoint 16 at a time\n    for (; i + 15 < length; i += 16) {\n        __m256i a = _mm256_loadu_si256((__m256i*)(A + i));\n        __m256i b = _mm256_loadu_si256((__m256i*)(B + i));\n        __m256i result = _mm256_and_si256(a, b);\n        _mm256_storeu_si256((__m256i*)(C + i), result);\n    }\n\n    // Handle remaining elements after midpoint\n    for (; i < length; i++) {\n        C[i] = A[i] & B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_44_AVX", "completion": "```cpp\nvoid tensor_bit_op_simd(const uint16_t* A, const uint16_t* B, uint16_t* C, size_t length) {\n    size_t midpoint = length / 2;\n    size_t i = 0;\n    \n    // Process 16 elements at a time using AVX2\n    __m256i mask_xor, mask_and;\n    for (; i + 15 < length; i += 16) {\n        __m256i a = _mm256_loadu_si256((__m256i*)(A + i));\n        __m256i b = _mm256_loadu_si256((__m256i*)(B + i));\n        \n        __m256i xor_result = _mm256_xor_si256(a, b);\n        __m256i and_result = _mm256_and_si256(a, b);\n        \n        // Create masks for before/after midpoint\n        uint16_t mask_arr[16];\n        for (int j = 0; j < 16; j++) {\n            mask_arr[j] = (i + j < midpoint) ? 0xFFFF : 0;\n        }\n        mask_xor = _mm256_loadu_si256((__m256i*)mask_arr);\n        \n        for (int j = 0; j < 16; j++) {\n            mask_arr[j] = (i + j > midpoint) ? 0xFFFF : 0;\n        }\n        mask_and = _mm256_loadu_si256((__m256i*)mask_arr);\n        \n        // Blend results based on position\n        __m256i result = _mm256_or_si256(\n            _mm256_and_si256(xor_result, mask_xor),\n            _mm256_and_si256(and_result, mask_and)\n        );\n        \n        // Keep original A value at midpoint\n        if (i <= midpoint && midpoint < i + 16) {\n            uint16_t temp[16];\n            _mm256_storeu_si256((__m256i*)temp, result);\n            temp[midpoint - i] = A[midpoint];\n            result = _mm256_loadu_si256((__m256i*)temp);\n        }\n        \n        _mm256_storeu_si256((__m256i*)(C + i), result);\n    }\n    \n    // Handle remaining elements\n    for (; i < length; i++) {\n        if (i < midpoint) {\n            C[i] = A[i] ^ B[i];\n        } else if (i > midpoint) {\n            C[i] = A[i] & B[i];\n        } else {\n            C[i] = A[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_44_AVX", "completion": "```cpp\nvoid tensor_bit_op_simd(const uint16_t* A, const uint16_t* B, uint16_t* C, size_t length) {\n    size_t midpoint = length / 2;\n    size_t i = 0;\n    \n    // Process 16 elements at a time using AVX2\n    for (; i + 15 < midpoint; i += 16) {\n        __m256i a = _mm256_loadu_si256((__m256i*)(A + i));\n        __m256i b = _mm256_loadu_si256((__m256i*)(B + i));\n        __m256i result = _mm256_xor_si256(a, b);\n        _mm256_storeu_si256((__m256i*)(C + i), result);\n    }\n\n    // Handle remaining elements before midpoint\n    for (; i < midpoint; i++) {\n        C[i] = A[i] ^ B[i];\n    }\n\n    // Handle midpoint\n    C[midpoint] = A[midpoint];\n\n    i = midpoint + 1;\n    // Process elements after midpoint 16 at a time\n    for (; i + 15 < length; i += 16) {\n        __m256i a = _mm256_loadu_si256((__m256i*)(A + i));\n        __m256i b = _mm256_loadu_si256((__m256i*)(B + i));\n        __m256i result = _mm256_and_si256(a, b);\n        _mm256_storeu_si256((__m256i*)(C + i), result);\n    }\n\n    // Handle remaining elements after midpoint\n    for (; i < length; i++) {\n        C[i] = A[i] & B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_44_AVX", "completion": "```cpp\nvoid tensor_bit_op_simd(const uint16_t* A, const uint16_t* B, uint16_t* C, size_t length) {\n    size_t midpoint = length / 2;\n    size_t i = 0;\n    \n    // Process 16 elements at a time using AVX2\n    __m256i mask_xor, mask_and;\n    for (; i + 15 < length; i += 16) {\n        __m256i a = _mm256_loadu_si256((__m256i*)(A + i));\n        __m256i b = _mm256_loadu_si256((__m256i*)(B + i));\n        \n        __m256i xor_result = _mm256_xor_si256(a, b);\n        __m256i and_result = _mm256_and_si256(a, b);\n        \n        // Create masks for before/after midpoint\n        uint16_t mask_arr[16];\n        for (int j = 0; j < 16; j++) {\n            mask_arr[j] = (i + j < midpoint) ? 0xFFFF : 0;\n        }\n        mask_xor = _mm256_loadu_si256((__m256i*)mask_arr);\n        \n        for (int j = 0; j < 16; j++) {\n            mask_arr[j] = (i + j > midpoint) ? 0xFFFF : 0;\n        }\n        mask_and = _mm256_loadu_si256((__m256i*)mask_arr);\n        \n        // Blend results based on position\n        __m256i result = _mm256_or_si256(\n            _mm256_and_si256(xor_result, mask_xor),\n            _mm256_and_si256(and_result, mask_and)\n        );\n        \n        // Handle midpoint\n        if (i <= midpoint && midpoint < i + 16) {\n            uint16_t temp_result[16];\n            _mm256_storeu_si256((__m256i*)temp_result, result);\n            temp_result[midpoint - i] = A[midpoint];\n            result = _mm256_loadu_si256((__m256i*)temp_result);\n        }\n        \n        _mm256_storeu_si256((__m256i*)(C + i), result);\n    }\n    \n    // Handle remaining elements\n    for (; i < length; i++) {\n        if (i < midpoint) {\n            C[i] = A[i] ^ B[i];\n        } else if (i > midpoint) {\n            C[i] = A[i] & B[i];\n        } else {\n            C[i] = A[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_44_AVX", "completion": "```cpp\nvoid tensor_bit_op_simd(const uint16_t* A, const uint16_t* B, uint16_t* C, size_t length) {\n    size_t midpoint = length / 2;\n    size_t i = 0;\n    \n    // Process 16 elements at a time using AVX2\n    for (; i + 15 < midpoint; i += 16) {\n        __m256i a = _mm256_loadu_si256((__m256i*)(A + i));\n        __m256i b = _mm256_loadu_si256((__m256i*)(B + i));\n        __m256i result = _mm256_xor_si256(a, b);\n        _mm256_storeu_si256((__m256i*)(C + i), result);\n    }\n\n    // Handle remaining elements before midpoint\n    for (; i < midpoint; i++) {\n        C[i] = A[i] ^ B[i];\n    }\n\n    // Handle midpoint\n    C[midpoint] = A[midpoint];\n\n    i = midpoint + 1;\n    // Process elements after midpoint 16 at a time\n    for (; i + 15 < length; i += 16) {\n        __m256i a = _mm256_loadu_si256((__m256i*)(A + i));\n        __m256i b = _mm256_loadu_si256((__m256i*)(B + i));\n        __m256i result = _mm256_and_si256(a, b);\n        _mm256_storeu_si256((__m256i*)(C + i), result);\n    }\n\n    // Handle remaining elements after midpoint\n    for (; i < length; i++) {\n        C[i] = A[i] & B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_45_AVX", "completion": "```cpp\nvoid tensor_multi_select_simd(const float* A, const float* B, const float* C, const float* D, const bool* cond1, const bool* cond2, float* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_size = dim1 * dim2 * dim3;\n    size_t vec_size = total_size - (total_size % 8);\n    \n    for (size_t i = 0; i < vec_size; i += 8) {\n        __m256 a = _mm256_loadu_ps(&A[i]);\n        __m256 b = _mm256_loadu_ps(&B[i]);\n        __m256 c = _mm256_loadu_ps(&C[i]);\n        __m256 d = _mm256_loadu_ps(&D[i]);\n        \n        __m256 mask1 = _mm256_castsi256_ps(_mm256_set1_epi32(0xFFFFFFFF));\n        __m256 mask2 = _mm256_castsi256_ps(_mm256_set1_epi32(0xFFFFFFFF));\n        \n        for (int j = 0; j < 8; j++) {\n            int mask_val1 = cond1[i + j] ? 0xFFFFFFFF : 0;\n            int mask_val2 = cond2[i + j] ? 0xFFFFFFFF : 0;\n            ((int*)&mask1)[j] = mask_val1;\n            ((int*)&mask2)[j] = mask_val2;\n        }\n        \n        __m256 temp1 = _mm256_blendv_ps(c, a, mask1);\n        __m256 temp2 = _mm256_blendv_ps(d, b, mask1);\n        __m256 result = _mm256_blendv_ps(temp2, temp1, mask2);\n        \n        _mm256_storeu_ps(&out[i], result);\n    }\n    \n    for (size_t i = vec_size; i < total_size; i++) {\n        if (cond1[i]) {\n            out[i] = cond2[i] ? A[i] : B[i];\n        } else {\n            out[i] = cond2[i] ? C[i] : D[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_45_AVX", "completion": "```cpp\nvoid tensor_multi_select_simd(const float* A, const float* B, const float* C, const float* D, const bool* cond1, const bool* cond2, float* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_size = dim1 * dim2 * dim3;\n    size_t vec_size = total_size - (total_size % 8);\n    \n    for (size_t i = 0; i < vec_size; i += 8) {\n        __m256 a = _mm256_loadu_ps(&A[i]);\n        __m256 b = _mm256_loadu_ps(&B[i]);\n        __m256 c = _mm256_loadu_ps(&C[i]);\n        __m256 d = _mm256_loadu_ps(&D[i]);\n        \n        __m256 mask1 = _mm256_castsi256_ps(_mm256_set1_epi32(0xFFFFFFFF));\n        __m256 mask2 = _mm256_castsi256_ps(_mm256_set1_epi32(0xFFFFFFFF));\n        \n        for (int j = 0; j < 8; j++) {\n            int mask_val1 = cond1[i + j] ? 0xFFFFFFFF : 0;\n            int mask_val2 = cond2[i + j] ? 0xFFFFFFFF : 0;\n            mask1 = _mm256_blend_ps(mask1, _mm256_castsi256_ps(_mm256_set1_epi32(mask_val1)), 1 << j);\n            mask2 = _mm256_blend_ps(mask2, _mm256_castsi256_ps(_mm256_set1_epi32(mask_val2)), 1 << j);\n        }\n\n        __m256 temp1 = _mm256_blendv_ps(c, a, mask1);\n        __m256 temp2 = _mm256_blendv_ps(d, b, mask1);\n        __m256 result = _mm256_blendv_ps(temp2, temp1, mask2);\n        \n        _mm256_storeu_ps(&out[i], result);\n    }\n\n    for (size_t i = vec_size; i < total_size; i++) {\n        if (cond1[i]) {\n            out[i] = cond2[i] ? A[i] : B[i];\n        } else {\n            out[i] = cond2[i] ? C[i] : D[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_45_AVX", "completion": "```cpp\nvoid tensor_multi_select_simd(const float* A, const float* B, const float* C, const float* D, const bool* cond1, const bool* cond2, float* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_size = dim1 * dim2 * dim3;\n    size_t vec_size = total_size - (total_size % 8);\n    \n    for (size_t i = 0; i < vec_size; i += 8) {\n        __m256 a = _mm256_loadu_ps(&A[i]);\n        __m256 b = _mm256_loadu_ps(&B[i]);\n        __m256 c = _mm256_loadu_ps(&C[i]);\n        __m256 d = _mm256_loadu_ps(&D[i]);\n        \n        __m256 mask1 = _mm256_castsi256_ps(_mm256_set_epi32(\n            cond1[i+7] ? -1 : 0,\n            cond1[i+6] ? -1 : 0,\n            cond1[i+5] ? -1 : 0,\n            cond1[i+4] ? -1 : 0,\n            cond1[i+3] ? -1 : 0,\n            cond1[i+2] ? -1 : 0,\n            cond1[i+1] ? -1 : 0,\n            cond1[i] ? -1 : 0\n        ));\n        \n        __m256 mask2 = _mm256_castsi256_ps(_mm256_set_epi32(\n            cond2[i+7] ? -1 : 0,\n            cond2[i+6] ? -1 : 0,\n            cond2[i+5] ? -1 : 0,\n            cond2[i+4] ? -1 : 0,\n            cond2[i+3] ? -1 : 0,\n            cond2[i+2] ? -1 : 0,\n            cond2[i+1] ? -1 : 0,\n            cond2[i] ? -1 : 0\n        ));\n\n        __m256 ab = _mm256_blendv_ps(b, a, mask2);\n        __m256 cd = _mm256_blendv_ps(d, c, mask2);\n        __m256 result = _mm256_blendv_ps(cd, ab, mask1);\n        \n        _mm256_storeu_ps(&out[i], result);\n    }\n\n    for (size_t i = vec_size; i < total_size; i++) {\n        if (cond1[i]) {\n            out[i] = cond2[i] ? A[i] : B[i];\n        } else {\n            out[i] = cond2[i] ? C[i] : D[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_45_AVX", "completion": "```cpp\nvoid tensor_multi_select_simd(const float* A, const float* B, const float* C, const float* D, const bool* cond1, const bool* cond2, float* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_size = dim1 * dim2 * dim3;\n    size_t vec_size = total_size - (total_size % 8);\n    \n    for (size_t i = 0; i < vec_size; i += 8) {\n        __m256 a = _mm256_loadu_ps(&A[i]);\n        __m256 b = _mm256_loadu_ps(&B[i]);\n        __m256 c = _mm256_loadu_ps(&C[i]);\n        __m256 d = _mm256_loadu_ps(&D[i]);\n        \n        __m256 mask1 = _mm256_castsi256_ps(_mm256_set1_epi32(0xFFFFFFFF));\n        __m256 mask2 = _mm256_castsi256_ps(_mm256_set1_epi32(0xFFFFFFFF));\n        \n        for (int j = 0; j < 8; j++) {\n            int mask_val1 = cond1[i + j] ? 0xFFFFFFFF : 0;\n            int mask_val2 = cond2[i + j] ? 0xFFFFFFFF : 0;\n            reinterpret_cast<int*>(&mask1)[j] = mask_val1;\n            reinterpret_cast<int*>(&mask2)[j] = mask_val2;\n        }\n\n        __m256 temp1 = _mm256_blendv_ps(c, a, mask1);\n        __m256 temp2 = _mm256_blendv_ps(d, b, mask1);\n        __m256 result = _mm256_blendv_ps(temp2, temp1, mask2);\n        \n        _mm256_storeu_ps(&out[i], result);\n    }\n\n    for (size_t i = vec_size; i < total_size; i++) {\n        if (cond1[i]) {\n            out[i] = cond2[i] ? A[i] : B[i];\n        } else {\n            out[i] = cond2[i] ? C[i] : D[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_45_AVX", "completion": "```cpp\nvoid tensor_multi_select_simd(const float* A, const float* B, const float* C, const float* D, const bool* cond1, const bool* cond2, float* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_size = dim1 * dim2 * dim3;\n    size_t vec_size = total_size - (total_size % 8);\n    \n    for (size_t i = 0; i < vec_size; i += 8) {\n        __m256 a = _mm256_loadu_ps(&A[i]);\n        __m256 b = _mm256_loadu_ps(&B[i]);\n        __m256 c = _mm256_loadu_ps(&C[i]);\n        __m256 d = _mm256_loadu_ps(&D[i]);\n        \n        __m256 mask1 = _mm256_castsi256_ps(_mm256_set_epi32(\n            cond1[i+7] ? -1 : 0,\n            cond1[i+6] ? -1 : 0,\n            cond1[i+5] ? -1 : 0,\n            cond1[i+4] ? -1 : 0,\n            cond1[i+3] ? -1 : 0,\n            cond1[i+2] ? -1 : 0,\n            cond1[i+1] ? -1 : 0,\n            cond1[i] ? -1 : 0\n        ));\n        \n        __m256 mask2 = _mm256_castsi256_ps(_mm256_set_epi32(\n            cond2[i+7] ? -1 : 0,\n            cond2[i+6] ? -1 : 0,\n            cond2[i+5] ? -1 : 0,\n            cond2[i+4] ? -1 : 0,\n            cond2[i+3] ? -1 : 0,\n            cond2[i+2] ? -1 : 0,\n            cond2[i+1] ? -1 : 0,\n            cond2[i] ? -1 : 0\n        ));\n\n        __m256 ab = _mm256_blendv_ps(b, a, mask2);\n        __m256 cd = _mm256_blendv_ps(d, c, mask2);\n        __m256 result = _mm256_blendv_ps(cd, ab, mask1);\n        \n        _mm256_storeu_ps(&out[i], result);\n    }\n\n    for (size_t i = vec_size; i < total_size; i++) {\n        if (cond1[i]) {\n            out[i] = cond2[i] ? A[i] : B[i];\n        } else {\n            out[i] = cond2[i] ? C[i] : D[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_46_AVX", "completion": "```cpp\nvoid tensor_bit_count_simd(const uint32_t* A, uint8_t* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_size = dim1 * dim2 * dim3;\n    size_t vec_size = total_size - (total_size % 8);\n    \n    for (size_t i = 0; i < vec_size; i += 8) {\n        __m256i input = _mm256_loadu_si256((__m256i*)(A + i));\n        \n        // Parallel bit count using AVX2 popcnt emulation\n        __m256i mask1 = _mm256_set1_epi32(0x55555555);\n        __m256i mask2 = _mm256_set1_epi32(0x33333333);\n        __m256i mask3 = _mm256_set1_epi32(0x0F0F0F0F);\n        \n        __m256i x = input;\n        x = _mm256_sub_epi32(x, _mm256_and_si256(_mm256_srli_epi32(x, 1), mask1));\n        x = _mm256_add_epi32(_mm256_and_si256(x, mask2), _mm256_and_si256(_mm256_srli_epi32(x, 2), mask2));\n        x = _mm256_and_si256(_mm256_add_epi32(x, _mm256_srli_epi32(x, 4)), mask3);\n        x = _mm256_add_epi32(x, _mm256_srli_epi32(x, 8));\n        x = _mm256_add_epi32(x, _mm256_srli_epi32(x, 16));\n        x = _mm256_and_si256(x, _mm256_set1_epi32(0x3F));\n        \n        // Pack 32-bit results into 8-bit values\n        __m256i packed1 = _mm256_packus_epi32(x, x);\n        __m256i packed2 = _mm256_packus_epi16(packed1, packed1);\n        \n        // Store lower 8 bytes\n        _mm_storel_epi64((__m128i*)(out + i), _mm256_extracti128_si256(packed2, 0));\n    }\n    \n    // Handle remaining elements\n    for (size_t i = vec_size; i < total_size; i++) {\n        uint32_t val = A[i];\n        val = val - ((val >> 1) & 0x55555555);\n        val = (val & 0x33333333) + ((val >> 2) & 0x33333333);\n        val = (val + (val >> 4)) & 0x0F0F0F0F;\n        val = val + (val >> 8);\n        val = val + (val >> 16);\n        out[i] = (uint8_t)(val & 0x3F);\n    }\n}\n```"}
{"task_id": "SimdBench_46_AVX", "completion": "```cpp\nvoid tensor_bit_count_simd(const uint32_t* A, uint8_t* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_size = dim1 * dim2 * dim3;\n    size_t vec_size = total_size - (total_size % 8);\n    \n    for (size_t i = 0; i < vec_size; i += 8) {\n        __m256i input = _mm256_loadu_si256((__m256i*)(A + i));\n        \n        // Parallel bit count using POPCNT\n        __m256i mask1 = _mm256_set1_epi32(0x55555555);\n        __m256i mask2 = _mm256_set1_epi32(0x33333333);\n        __m256i mask3 = _mm256_set1_epi32(0x0F0F0F0F);\n        \n        __m256i x = input;\n        x = _mm256_sub_epi32(x, _mm256_and_si256(_mm256_srli_epi32(x, 1), mask1));\n        x = _mm256_add_epi32(_mm256_and_si256(x, mask2), _mm256_and_si256(_mm256_srli_epi32(x, 2), mask2));\n        x = _mm256_and_si256(_mm256_add_epi32(x, _mm256_srli_epi32(x, 4)), mask3);\n        x = _mm256_add_epi32(x, _mm256_srli_epi32(x, 8));\n        x = _mm256_add_epi32(x, _mm256_srli_epi32(x, 16));\n        x = _mm256_and_si256(x, _mm256_set1_epi32(0x3F));\n        \n        // Pack 32-bit results into 8-bit\n        __m256i packed = _mm256_packus_epi32(x, x);\n        packed = _mm256_packus_epi16(packed, packed);\n        \n        // Store lower 8 bytes\n        _mm_storel_epi64((__m128i*)(out + i), _mm256_extracti128_si256(packed, 0));\n    }\n    \n    // Handle remaining elements\n    for (size_t i = vec_size; i < total_size; i++) {\n        uint32_t val = A[i];\n        val = val - ((val >> 1) & 0x55555555);\n        val = (val & 0x33333333) + ((val >> 2) & 0x33333333);\n        val = (val + (val >> 4)) & 0x0F0F0F0F;\n        val = val + (val >> 8);\n        val = val + (val >> 16);\n        out[i] = (uint8_t)(val & 0x3F);\n    }\n}\n```"}
{"task_id": "SimdBench_46_AVX", "completion": "```cpp\nvoid tensor_bit_count_simd(const uint32_t* A, uint8_t* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_size = dim1 * dim2 * dim3;\n    size_t vec_size = total_size / 8;\n    size_t remainder = total_size % 8;\n\n    for (size_t i = 0; i < vec_size; i++) {\n        __m256i input = _mm256_loadu_si256((__m256i*)(A + i * 8));\n        \n        // Compute popcount for each 32-bit integer using parallel bit counting\n        __m256i mask1 = _mm256_set1_epi32(0x55555555);\n        __m256i mask2 = _mm256_set1_epi32(0x33333333);\n        __m256i mask3 = _mm256_set1_epi32(0x0F0F0F0F);\n        \n        __m256i x = input;\n        x = _mm256_sub_epi32(x, _mm256_and_si256(_mm256_srli_epi32(x, 1), mask1));\n        x = _mm256_add_epi32(_mm256_and_si256(x, mask2), _mm256_and_si256(_mm256_srli_epi32(x, 2), mask2));\n        x = _mm256_and_si256(_mm256_add_epi32(x, _mm256_srli_epi32(x, 4)), mask3);\n        x = _mm256_add_epi32(x, _mm256_srli_epi32(x, 8));\n        x = _mm256_add_epi32(x, _mm256_srli_epi32(x, 16));\n        x = _mm256_and_si256(x, _mm256_set1_epi32(0x3F));\n\n        // Pack 32-bit results into 8-bit values\n        __m256i packed = _mm256_packs_epi32(x, x);\n        packed = _mm256_packs_epi16(packed, packed);\n        \n        // Store lower 8 bytes\n        _mm_storel_epi64((__m128i*)(out + i * 8), _mm256_extracti128_si256(packed, 0));\n    }\n\n    // Handle remaining elements\n    for (size_t i = vec_size * 8; i < total_size; i++) {\n        uint32_t val = A[i];\n        val = val - ((val >> 1) & 0x55555555);\n        val = (val & 0x33333333) + ((val >> 2) & 0x33333333);\n        val = (val + (val >> 4)) & 0x0F0F0F0F;\n        val = val + (val >> 8);\n        val = val + (val >> 16);\n        out[i] = val & 0x3F;\n    }\n}\n```"}
{"task_id": "SimdBench_46_AVX", "completion": "```cpp\nvoid tensor_bit_count_simd(const uint32_t* A, uint8_t* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_size = dim1 * dim2 * dim3;\n    size_t i = 0;\n    \n    // Process 8 elements at a time using AVX2\n    for (; i + 7 < total_size; i += 8) {\n        __m256i input = _mm256_loadu_si256((__m256i*)(A + i));\n        \n        // Parallel bit counting using POPCNT\n        __m256i mask1 = _mm256_set1_epi32(0x55555555);\n        __m256i mask2 = _mm256_set1_epi32(0x33333333);\n        __m256i mask3 = _mm256_set1_epi32(0x0F0F0F0F);\n        \n        __m256i x = input;\n        x = _mm256_sub_epi32(x, _mm256_and_si256(_mm256_srli_epi32(x, 1), mask1));\n        x = _mm256_add_epi32(_mm256_and_si256(x, mask2), _mm256_and_si256(_mm256_srli_epi32(x, 2), mask2));\n        x = _mm256_and_si256(_mm256_add_epi32(x, _mm256_srli_epi32(x, 4)), mask3);\n        x = _mm256_add_epi32(x, _mm256_srli_epi32(x, 8));\n        x = _mm256_add_epi32(x, _mm256_srli_epi32(x, 16));\n        x = _mm256_and_si256(x, _mm256_set1_epi32(0x3F));\n        \n        // Pack 32-bit results into 8-bit\n        __m256i packed = _mm256_packs_epi32(x, x);\n        packed = _mm256_packs_epi16(packed, packed);\n        \n        // Store lower 8 bytes\n        _mm_storel_epi64((__m128i*)(out + i), _mm256_extracti128_si256(packed, 0));\n    }\n    \n    // Handle remaining elements\n    for (; i < total_size; i++) {\n        uint32_t val = A[i];\n        val = val - ((val >> 1) & 0x55555555);\n        val = (val & 0x33333333) + ((val >> 2) & 0x33333333);\n        val = (val + (val >> 4)) & 0x0F0F0F0F;\n        val = val + (val >> 8);\n        val = val + (val >> 16);\n        out[i] = (uint8_t)(val & 0x3F);\n    }\n}\n```"}
{"task_id": "SimdBench_46_AVX", "completion": "```cpp\nvoid tensor_bit_count_simd(const uint32_t* A, uint8_t* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_size = dim1 * dim2 * dim3;\n    size_t vec_size = total_size / 8;\n    size_t remainder = total_size % 8;\n\n    for (size_t i = 0; i < vec_size; i++) {\n        __m256i input = _mm256_loadu_si256((__m256i*)(A + i * 8));\n        \n        // Compute popcount using parallel bit counting\n        __m256i mask1 = _mm256_set1_epi32(0x55555555);\n        __m256i mask2 = _mm256_set1_epi32(0x33333333);\n        __m256i mask3 = _mm256_set1_epi32(0x0F0F0F0F);\n        \n        __m256i x = input;\n        x = _mm256_sub_epi32(x, _mm256_and_si256(_mm256_srli_epi32(x, 1), mask1));\n        x = _mm256_add_epi32(_mm256_and_si256(x, mask2), _mm256_and_si256(_mm256_srli_epi32(x, 2), mask2));\n        x = _mm256_and_si256(_mm256_add_epi32(x, _mm256_srli_epi32(x, 4)), mask3);\n        x = _mm256_add_epi32(x, _mm256_srli_epi32(x, 8));\n        x = _mm256_add_epi32(x, _mm256_srli_epi32(x, 16));\n        x = _mm256_and_si256(x, _mm256_set1_epi32(0x3F));\n\n        // Pack 32-bit results into 8-bit values\n        __m256i packed = _mm256_packus_epi32(x, x);\n        packed = _mm256_packus_epi16(packed, packed);\n        \n        // Store lower 8 bytes\n        _mm_storel_epi64((__m128i*)(out + i * 8), _mm256_extracti128_si256(packed, 0));\n    }\n\n    // Handle remaining elements\n    for (size_t i = vec_size * 8; i < total_size; i++) {\n        uint32_t val = A[i];\n        val = val - ((val >> 1) & 0x55555555);\n        val = (val & 0x33333333) + ((val >> 2) & 0x33333333);\n        val = (val + (val >> 4)) & 0x0F0F0F0F;\n        val = val + (val >> 8);\n        val = val + (val >> 16);\n        out[i] = (uint8_t)(val & 0x3F);\n    }\n}\n```"}
{"task_id": "SimdBench_47_AVX", "completion": "```cpp\nvoid matrix_conditional_abs_simd(const int* A, int* B, size_t rows, size_t cols) {\n    const size_t total = rows * cols;\n    const size_t simd_width = 8; // AVX2 processes 8 32-bit integers at once\n    const size_t simd_limit = total - (total % simd_width);\n    \n    __m256i three = _mm256_set1_epi32(3);\n    __m256i zero = _mm256_setzero_si256();\n    \n    for (size_t i = 0; i < simd_limit; i += simd_width) {\n        __m256i a = _mm256_loadu_si256((__m256i*)(A + i));\n        \n        // Calculate remainder when divided by 3\n        __m256i quotient = _mm256_div_epi32(a, three);\n        __m256i product = _mm256_mullo_epi32(quotient, three);\n        __m256i remainder = _mm256_sub_epi32(a, product);\n        \n        // Create mask for elements divisible by 3\n        __m256i mask = _mm256_cmpeq_epi32(remainder, zero);\n        \n        // Calculate absolute values\n        __m256i neg = _mm256_sub_epi32(zero, a);\n        __m256i abs = _mm256_max_epi32(a, neg);\n        \n        // Select between original and absolute values based on mask\n        __m256i result = _mm256_blendv_epi8(a, abs, mask);\n        \n        _mm256_storeu_si256((__m256i*)(B + i), result);\n    }\n    \n    // Handle remaining elements\n    for (size_t i = simd_limit; i < total; i++) {\n        B[i] = (A[i] % 3 == 0) ? abs(A[i]) : A[i];\n    }\n}\n```"}
{"task_id": "SimdBench_47_AVX", "completion": "```cpp\nvoid matrix_conditional_abs_simd(const int* A, int* B, size_t rows, size_t cols) {\n    const size_t total = rows * cols;\n    const size_t simd_width = 8; // AVX processes 8 32-bit integers at a time\n    const size_t aligned_size = total & ~(simd_width - 1);\n\n    __m256i three = _mm256_set1_epi32(3);\n    __m256i zero = _mm256_setzero_si256();\n\n    for (size_t i = 0; i < aligned_size; i += simd_width) {\n        __m256i a = _mm256_loadu_si256((__m256i*)(A + i));\n        \n        // Calculate absolute values\n        __m256i abs_a = _mm256_abs_epi32(a);\n        \n        // Check divisibility by 3\n        __m256i quotient = _mm256_div_epi32(a, three);\n        __m256i product = _mm256_mullo_epi32(quotient, three);\n        __m256i remainder = _mm256_sub_epi32(a, product);\n        __m256i mask = _mm256_cmpeq_epi32(remainder, zero);\n        \n        // Select abs value or original based on mask\n        __m256i result = _mm256_blendv_epi8(a, abs_a, mask);\n        \n        _mm256_storeu_si256((__m256i*)(B + i), result);\n    }\n\n    // Handle remaining elements\n    for (size_t i = aligned_size; i < total; i++) {\n        B[i] = (A[i] % 3 == 0) ? abs(A[i]) : A[i];\n    }\n}\n```"}
{"task_id": "SimdBench_47_AVX", "completion": "```cpp\nvoid matrix_conditional_abs_simd(const int* A, int* B, size_t rows, size_t cols) {\n    const size_t total = rows * cols;\n    const size_t simd_width = 8; // AVX processes 8 32-bit integers at a time\n    const size_t simd_limit = total - (total % simd_width);\n    \n    __m256i three = _mm256_set1_epi32(3);\n    __m256i zero = _mm256_setzero_si256();\n    \n    for (size_t i = 0; i < simd_limit; i += simd_width) {\n        __m256i a = _mm256_loadu_si256((__m256i*)(A + i));\n        \n        // Calculate remainder when divided by 3\n        __m256i quotient = _mm256_div_epi32(a, three);\n        __m256i product = _mm256_mullo_epi32(quotient, three);\n        __m256i remainder = _mm256_sub_epi32(a, product);\n        \n        // Create mask for elements divisible by 3\n        __m256i mask = _mm256_cmpeq_epi32(remainder, zero);\n        \n        // Calculate absolute values\n        __m256i neg = _mm256_sub_epi32(zero, a);\n        __m256i abs = _mm256_max_epi32(a, neg);\n        \n        // Select between original and absolute based on mask\n        __m256i result = _mm256_blendv_epi8(a, abs, mask);\n        \n        _mm256_storeu_si256((__m256i*)(B + i), result);\n    }\n    \n    // Handle remaining elements\n    for (size_t i = simd_limit; i < total; i++) {\n        B[i] = (A[i] % 3 == 0) ? abs(A[i]) : A[i];\n    }\n}\n```"}
{"task_id": "SimdBench_47_AVX", "completion": "```cpp\nvoid matrix_conditional_abs_simd(const int* A, int* B, size_t rows, size_t cols) {\n    const size_t total = rows * cols;\n    const size_t simd_width = 8; // AVX processes 8 integers at a time\n    const size_t simd_limit = total - (total % simd_width);\n    \n    __m256i three = _mm256_set1_epi32(3);\n    __m256i zero = _mm256_setzero_si256();\n    \n    for (size_t i = 0; i < simd_limit; i += simd_width) {\n        __m256i a = _mm256_loadu_si256((__m256i*)(A + i));\n        \n        // Calculate remainder when divided by 3\n        __m256i remainder = _mm256_rem_epi32(a, three);\n        \n        // Create mask for elements divisible by 3 (remainder == 0)\n        __m256i mask = _mm256_cmpeq_epi32(remainder, zero);\n        \n        // Get absolute values\n        __m256i abs_a = _mm256_abs_epi32(a);\n        \n        // Blend based on mask\n        __m256i result = _mm256_blendv_epi8(a, abs_a, mask);\n        \n        _mm256_storeu_si256((__m256i*)(B + i), result);\n    }\n    \n    // Handle remaining elements\n    for (size_t i = simd_limit; i < total; i++) {\n        B[i] = (A[i] % 3 == 0) ? abs(A[i]) : A[i];\n    }\n}\n```"}
{"task_id": "SimdBench_47_AVX", "completion": "```cpp\nvoid matrix_conditional_abs_simd(const int* A, int* B, size_t rows, size_t cols) {\n    const size_t total = rows * cols;\n    const size_t simd_width = 8; // AVX processes 8 32-bit integers at a time\n    const size_t aligned_size = total & ~(simd_width - 1);\n\n    __m256i three = _mm256_set1_epi32(3);\n    __m256i zero = _mm256_setzero_si256();\n\n    for (size_t i = 0; i < aligned_size; i += simd_width) {\n        __m256i a = _mm256_loadu_si256((__m256i*)(A + i));\n        \n        // Calculate absolute values\n        __m256i abs_a = _mm256_abs_epi32(a);\n        \n        // Check divisibility by 3\n        __m256i quotient = _mm256_div_epi32(a, three);\n        __m256i product = _mm256_mullo_epi32(quotient, three);\n        __m256i mask = _mm256_cmpeq_epi32(product, a);\n        \n        // Select between original and absolute values based on mask\n        __m256i result = _mm256_blendv_epi8(a, abs_a, mask);\n        \n        _mm256_storeu_si256((__m256i*)(B + i), result);\n    }\n\n    // Handle remaining elements\n    for (size_t i = aligned_size; i < total; i++) {\n        B[i] = (A[i] % 3 == 0) ? abs(A[i]) : A[i];\n    }\n}\n```"}
{"task_id": "SimdBench_48_AVX", "completion": "```cpp\nvoid matrix_conditional_bit_rotate_simd(const uint32_t* src, uint32_t* dst, uint8_t rotate_bits, size_t length) {\n    const size_t simd_width = 8;\n    size_t i = 0;\n    \n    __m256i mask_0xf = _mm256_set1_epi32(0xf);\n    __m256i mask_0xf_compare = _mm256_set1_epi32(0xf);\n    \n    for (; i + simd_width <= length; i += simd_width) {\n        __m256i src_vec = _mm256_loadu_si256((__m256i*)(src + i));\n        \n        // Check if low 4 bits are all 1\n        __m256i low_bits = _mm256_and_si256(src_vec, mask_0xf);\n        __m256i condition = _mm256_cmpeq_epi32(low_bits, mask_0xf_compare);\n        \n        // Perform rotation for true condition\n        __m256i rotated = _mm256_or_si256(\n            _mm256_srlv_epi32(src_vec, _mm256_set1_epi32(rotate_bits)),\n            _mm256_sllv_epi32(src_vec, _mm256_set1_epi32(32 - rotate_bits))\n        );\n        \n        // Perform negation for false condition\n        __m256i negated = _mm256_xor_si256(src_vec, _mm256_set1_epi32(0xffffffff));\n        \n        // Select between rotated and negated based on condition\n        __m256i result = _mm256_blendv_epi8(negated, rotated, condition);\n        \n        _mm256_storeu_si256((__m256i*)(dst + i), result);\n    }\n    \n    // Handle remaining elements\n    for (; i < length; i++) {\n        if ((src[i] & 0xf) == 0xf) {\n            dst[i] = (src[i] >> rotate_bits) | (src[i] << (32 - rotate_bits));\n        } else {\n            dst[i] = ~src[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_48_AVX", "completion": "```cpp\nvoid matrix_conditional_bit_rotate_simd(const uint32_t* src, uint32_t* dst, uint8_t rotate_bits, size_t length) {\n    const size_t simd_width = 8;\n    size_t i = 0;\n    \n    __m256i mask_0xf = _mm256_set1_epi32(0xf);\n    __m256i mask_0xf_compare = _mm256_set1_epi32(0xf);\n    \n    for (; i + simd_width <= length; i += simd_width) {\n        __m256i src_vec = _mm256_loadu_si256((__m256i*)(src + i));\n        \n        // Check if low 4 bits are all 1\n        __m256i low_bits = _mm256_and_si256(src_vec, mask_0xf);\n        __m256i condition = _mm256_cmpeq_epi32(low_bits, mask_0xf_compare);\n        \n        // Perform rotation for true condition\n        __m256i rotated = _mm256_or_si256(\n            _mm256_srlv_epi32(src_vec, _mm256_set1_epi32(rotate_bits)),\n            _mm256_sllv_epi32(src_vec, _mm256_set1_epi32(32 - rotate_bits))\n        );\n        \n        // Perform negation for false condition\n        __m256i negated = _mm256_xor_si256(src_vec, _mm256_set1_epi32(0xffffffff));\n        \n        // Select between rotated and negated based on condition\n        __m256i result = _mm256_blendv_epi8(negated, rotated, condition);\n        \n        _mm256_storeu_si256((__m256i*)(dst + i), result);\n    }\n    \n    // Handle remaining elements\n    for (; i < length; i++) {\n        if ((src[i] & 0xf) == 0xf) {\n            dst[i] = (src[i] >> rotate_bits) | (src[i] << (32 - rotate_bits));\n        } else {\n            dst[i] = ~src[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_48_AVX", "completion": "```cpp\nvoid matrix_conditional_bit_rotate_simd(const uint32_t* src, uint32_t* dst, uint8_t rotate_bits, size_t length) {\n    size_t i;\n    __m256i mask = _mm256_set1_epi32(0xF);\n    __m256i all_ones = _mm256_set1_epi32(0xF);\n    \n    for (i = 0; i + 8 <= length; i += 8) {\n        __m256i src_vec = _mm256_loadu_si256((__m256i*)(src + i));\n        \n        // Check if low 4 bits are all 1s\n        __m256i low_bits = _mm256_and_si256(src_vec, mask);\n        __m256i cmp = _mm256_cmpeq_epi32(low_bits, all_ones);\n        \n        // Perform rotation for matching elements\n        __m256i rotated = _mm256_or_si256(\n            _mm256_srlv_epi32(src_vec, _mm256_set1_epi32(rotate_bits)),\n            _mm256_sllv_epi32(src_vec, _mm256_set1_epi32(32 - rotate_bits))\n        );\n        \n        // Perform NOT operation\n        __m256i negated = _mm256_xor_si256(src_vec, _mm256_set1_epi32(0xFFFFFFFF));\n        \n        // Select between rotated and negated based on condition\n        __m256i result = _mm256_blendv_epi8(negated, rotated, cmp);\n        \n        _mm256_storeu_si256((__m256i*)(dst + i), result);\n    }\n    \n    // Handle remaining elements\n    for (; i < length; i++) {\n        if ((src[i] & 0xF) == 0xF) {\n            dst[i] = (src[i] >> rotate_bits) | (src[i] << (32 - rotate_bits));\n        } else {\n            dst[i] = ~src[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_48_AVX", "completion": "```cpp\nvoid matrix_conditional_bit_rotate_simd(const uint32_t* src, uint32_t* dst, uint8_t rotate_bits, size_t length) {\n    const size_t simd_width = 8;\n    size_t i = 0;\n    \n    __m256i mask_0xf = _mm256_set1_epi32(0xf);\n    __m256i mask_0xf_compare = _mm256_set1_epi32(0xf);\n    \n    for (; i + simd_width <= length; i += simd_width) {\n        __m256i src_vec = _mm256_loadu_si256((__m256i*)(src + i));\n        \n        // Check if low 4 bits are all 1\n        __m256i low_bits = _mm256_and_si256(src_vec, mask_0xf);\n        __m256i condition = _mm256_cmpeq_epi32(low_bits, mask_0xf_compare);\n        \n        // Perform rotation for true condition\n        __m256i rotated = _mm256_or_si256(\n            _mm256_srlv_epi32(src_vec, _mm256_set1_epi32(rotate_bits)),\n            _mm256_sllv_epi32(src_vec, _mm256_set1_epi32(32 - rotate_bits))\n        );\n        \n        // Perform negation for false condition\n        __m256i negated = _mm256_xor_si256(src_vec, _mm256_set1_epi32(0xFFFFFFFF));\n        \n        // Select between rotated and negated based on condition\n        __m256i result = _mm256_blendv_epi8(negated, rotated, condition);\n        \n        _mm256_storeu_si256((__m256i*)(dst + i), result);\n    }\n    \n    // Handle remaining elements\n    for (; i < length; i++) {\n        if ((src[i] & 0xf) == 0xf) {\n            dst[i] = (src[i] >> rotate_bits) | (src[i] << (32 - rotate_bits));\n        } else {\n            dst[i] = ~src[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_48_AVX", "completion": "```cpp\nvoid matrix_conditional_bit_rotate_simd(const uint32_t* src, uint32_t* dst, uint8_t rotate_bits, size_t length) {\n    const size_t simd_width = 8;\n    size_t i = 0;\n    \n    __m256i mask_0xf = _mm256_set1_epi32(0xf);\n    __m256i mask_0xf_compare = _mm256_set1_epi32(0xf);\n    \n    for (; i + simd_width <= length; i += simd_width) {\n        __m256i src_vec = _mm256_loadu_si256((__m256i*)(src + i));\n        \n        // Check if low 4 bits are all 1\n        __m256i low_bits = _mm256_and_si256(src_vec, mask_0xf);\n        __m256i condition = _mm256_cmpeq_epi32(low_bits, mask_0xf_compare);\n        \n        // Perform rotation for true condition\n        __m256i rotated = _mm256_or_si256(\n            _mm256_srlv_epi32(src_vec, _mm256_set1_epi32(rotate_bits)),\n            _mm256_sllv_epi32(src_vec, _mm256_set1_epi32(32 - rotate_bits))\n        );\n        \n        // Perform negation for false condition\n        __m256i negated = _mm256_xor_si256(src_vec, _mm256_set1_epi32(0xFFFFFFFF));\n        \n        // Select between rotated and negated based on condition\n        __m256i result = _mm256_blendv_epi8(negated, rotated, condition);\n        \n        _mm256_storeu_si256((__m256i*)(dst + i), result);\n    }\n    \n    // Handle remaining elements\n    for (; i < length; i++) {\n        if ((src[i] & 0xf) == 0xf) {\n            dst[i] = (src[i] >> rotate_bits) | (src[i] << (32 - rotate_bits));\n        } else {\n            dst[i] = ~src[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_49_AVX", "completion": "```cpp\nvoid tensor_ternary_compare_simd(const float* A, const float* B, int8_t* out, float epsilon, size_t length) {\n    const size_t simd_width = 8;\n    const size_t simd_length = length / simd_width;\n    const size_t remainder = length % simd_width;\n    \n    __m256 eps_vec = _mm256_set1_ps(epsilon);\n    __m256 neg_eps_vec = _mm256_set1_ps(-epsilon);\n    __m256 ones = _mm256_set1_ps(1.0f);\n    __m256 neg_ones = _mm256_set1_ps(-1.0f);\n    __m256 zeros = _mm256_setzero_ps();\n\n    for (size_t i = 0; i < simd_length; i++) {\n        __m256 a = _mm256_loadu_ps(A + i * simd_width);\n        __m256 b = _mm256_loadu_ps(B + i * simd_width);\n        __m256 diff = _mm256_sub_ps(a, b);\n        \n        __m256 gt_mask = _mm256_cmp_ps(diff, eps_vec, _CMP_GT_OS);\n        __m256 lt_mask = _mm256_cmp_ps(diff, neg_eps_vec, _CMP_LT_OS);\n        \n        __m256 result = _mm256_blendv_ps(zeros, ones, gt_mask);\n        result = _mm256_blendv_ps(result, neg_ones, lt_mask);\n        \n        __m256i result_i = _mm256_cvtps_epi32(result);\n        __m128i result_narrow = _mm_packs_epi32(_mm256_extractf128_si256(result_i, 0),\n                                               _mm256_extractf128_si256(result_i, 1));\n        __m128i result_byte = _mm_packs_epi16(result_narrow, result_narrow);\n        \n        _mm_storel_epi64((__m128i*)(out + i * simd_width), result_byte);\n    }\n    \n    // Handle remaining elements\n    for (size_t i = simd_length * simd_width; i < length; i++) {\n        float diff = A[i] - B[i];\n        if (diff > epsilon) {\n            out[i] = 1;\n        } else if (diff < -epsilon) {\n            out[i] = -1;\n        } else {\n            out[i] = 0;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_49_AVX", "completion": "```cpp\nvoid tensor_ternary_compare_simd(const float* A, const float* B, int8_t* out, float epsilon, size_t length) {\n    const size_t simd_width = 8;\n    const size_t simd_length = length / simd_width;\n    const size_t remainder = length % simd_width;\n    \n    __m256 eps_vec = _mm256_set1_ps(epsilon);\n    __m256 neg_eps_vec = _mm256_set1_ps(-epsilon);\n    __m256 ones = _mm256_set1_ps(1.0f);\n    __m256 neg_ones = _mm256_set1_ps(-1.0f);\n    __m256 zeros = _mm256_setzero_ps();\n\n    for (size_t i = 0; i < simd_length; i++) {\n        __m256 a = _mm256_loadu_ps(A + i * simd_width);\n        __m256 b = _mm256_loadu_ps(B + i * simd_width);\n        __m256 diff = _mm256_sub_ps(a, b);\n        \n        __m256 gt_mask = _mm256_cmp_ps(diff, eps_vec, _CMP_GT_OQ);\n        __m256 lt_mask = _mm256_cmp_ps(diff, neg_eps_vec, _CMP_LT_OQ);\n        \n        __m256 result = _mm256_blendv_ps(zeros, ones, gt_mask);\n        result = _mm256_blendv_ps(result, neg_ones, lt_mask);\n        \n        __m256i result_int = _mm256_cvtps_epi32(result);\n        __m128i result_narrow = _mm_packs_epi32(_mm256_extractf128_si256(result_int, 0),\n                                               _mm256_extractf128_si256(result_int, 1));\n        __m128i result_packed = _mm_packs_epi16(result_narrow, result_narrow);\n        \n        _mm_storel_epi64((__m128i*)(out + i * simd_width), result_packed);\n    }\n\n    // Handle remaining elements\n    for (size_t i = simd_length * simd_width; i < length; i++) {\n        float diff = A[i] - B[i];\n        if (diff > epsilon) {\n            out[i] = 1;\n        } else if (diff < -epsilon) {\n            out[i] = -1;\n        } else {\n            out[i] = 0;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_49_AVX", "completion": "```cpp\nvoid tensor_ternary_compare_simd(const float* A, const float* B, int8_t* out, float epsilon, size_t length) {\n    const size_t simd_width = 8;\n    size_t i = 0;\n    \n    __m256 eps_vec = _mm256_set1_ps(epsilon);\n    __m256 neg_eps_vec = _mm256_set1_ps(-epsilon);\n    __m256 ones = _mm256_set1_ps(1.0f);\n    __m256 neg_ones = _mm256_set1_ps(-1.0f);\n    __m256 zeros = _mm256_setzero_ps();\n\n    for (; i + simd_width <= length; i += simd_width) {\n        __m256 a = _mm256_loadu_ps(A + i);\n        __m256 b = _mm256_loadu_ps(B + i);\n        __m256 diff = _mm256_sub_ps(a, b);\n        \n        __m256 gt_mask = _mm256_cmp_ps(diff, eps_vec, _CMP_GT_OQ);\n        __m256 lt_mask = _mm256_cmp_ps(diff, neg_eps_vec, _CMP_LT_OQ);\n        \n        __m256 result = _mm256_blendv_ps(zeros, ones, gt_mask);\n        result = _mm256_blendv_ps(result, neg_ones, lt_mask);\n        \n        __m256i int_result = _mm256_cvtps_epi32(result);\n        __m128i low = _mm256_extractf128_si256(int_result, 0);\n        __m128i high = _mm256_extractf128_si256(int_result, 1);\n        \n        int32_t temp[8];\n        _mm_storeu_si128((__m128i*)temp, low);\n        _mm_storeu_si128((__m128i*)(temp + 4), high);\n        \n        for(int j = 0; j < 8; j++) {\n            out[i + j] = (int8_t)temp[j];\n        }\n    }\n\n    // Handle remaining elements\n    for (; i < length; i++) {\n        float diff = A[i] - B[i];\n        if (diff > epsilon) out[i] = 1;\n        else if (diff < -epsilon) out[i] = -1;\n        else out[i] = 0;\n    }\n}\n```"}
{"task_id": "SimdBench_49_AVX", "completion": "```cpp\nvoid tensor_ternary_compare_simd(const float* A, const float* B, int8_t* out, float epsilon, size_t length) {\n    const size_t simd_width = 8;\n    size_t i = 0;\n    \n    __m256 eps_vec = _mm256_set1_ps(epsilon);\n    __m256 neg_eps_vec = _mm256_set1_ps(-epsilon);\n    __m256 ones = _mm256_set1_ps(1.0f);\n    __m256 neg_ones = _mm256_set1_ps(-1.0f);\n    __m256 zeros = _mm256_setzero_ps();\n\n    for (; i + simd_width <= length; i += simd_width) {\n        __m256 a = _mm256_loadu_ps(A + i);\n        __m256 b = _mm256_loadu_ps(B + i);\n        __m256 diff = _mm256_sub_ps(a, b);\n        \n        __m256 gt_mask = _mm256_cmp_ps(diff, eps_vec, _CMP_GT_OQ);\n        __m256 lt_mask = _mm256_cmp_ps(diff, neg_eps_vec, _CMP_LT_OQ);\n        \n        __m256 result = _mm256_blendv_ps(zeros, ones, gt_mask);\n        result = _mm256_blendv_ps(result, neg_ones, lt_mask);\n        \n        __m256i result_i = _mm256_cvtps_epi32(result);\n        __m128i result_narrow = _mm_packs_epi32(_mm256_extractf128_si256(result_i, 0),\n                                               _mm256_extractf128_si256(result_i, 1));\n        __m128i result_byte = _mm_packs_epi16(result_narrow, result_narrow);\n        \n        _mm_storel_epi64((__m128i*)(out + i), result_byte);\n    }\n\n    for (; i < length; i++) {\n        float diff = A[i] - B[i];\n        if (diff > epsilon) out[i] = 1;\n        else if (diff < -epsilon) out[i] = -1;\n        else out[i] = 0;\n    }\n}\n```"}
{"task_id": "SimdBench_49_AVX", "completion": "```cpp\nvoid tensor_ternary_compare_simd(const float* A, const float* B, int8_t* out, float epsilon, size_t length) {\n    const size_t simd_width = 8;\n    const size_t simd_length = length - (length % simd_width);\n    \n    __m256 eps_vec = _mm256_set1_ps(epsilon);\n    __m256 neg_eps_vec = _mm256_set1_ps(-epsilon);\n    __m256 ones = _mm256_set1_ps(1.0f);\n    __m256 neg_ones = _mm256_set1_ps(-1.0f);\n    __m256 zeros = _mm256_setzero_ps();\n\n    for (size_t i = 0; i < simd_length; i += simd_width) {\n        __m256 a = _mm256_loadu_ps(A + i);\n        __m256 b = _mm256_loadu_ps(B + i);\n        __m256 diff = _mm256_sub_ps(a, b);\n        \n        __m256 gt_mask = _mm256_cmp_ps(diff, eps_vec, _CMP_GT_OQ);\n        __m256 lt_mask = _mm256_cmp_ps(diff, neg_eps_vec, _CMP_LT_OQ);\n        \n        __m256 result = _mm256_blendv_ps(zeros, ones, gt_mask);\n        result = _mm256_blendv_ps(result, neg_ones, lt_mask);\n        \n        __m256i result_i = _mm256_cvtps_epi32(result);\n        __m128i result_low = _mm256_extractf128_si256(result_i, 0);\n        __m128i result_high = _mm256_extractf128_si256(result_i, 1);\n        \n        for (size_t j = 0; j < 4; j++) {\n            out[i + j] = _mm_extract_epi32(result_low, j);\n            out[i + j + 4] = _mm_extract_epi32(result_high, j);\n        }\n    }\n\n    for (size_t i = simd_length; i < length; i++) {\n        float diff = A[i] - B[i];\n        if (diff > epsilon) {\n            out[i] = 1;\n        } else if (diff < -epsilon) {\n            out[i] = -1;\n        } else {\n            out[i] = 0;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_50_AVX", "completion": "```cpp\nvoid float_to_int_saturate_simd(const float* A, int32_t* B, size_t size) {\n    size_t i = 0;\n    size_t simd_size = size - (size % 8);\n    \n    __m256 max_float = _mm256_set1_ps((float)INT32_MAX);\n    __m256 min_float = _mm256_set1_ps((float)INT32_MIN);\n    \n    for (; i < simd_size; i += 8) {\n        __m256 input = _mm256_loadu_ps(A + i);\n        \n        input = _mm256_min_ps(input, max_float);\n        input = _mm256_max_ps(input, min_float);\n        \n        __m256i converted = _mm256_cvtps_epi32(input);\n        _mm256_storeu_si256((__m256i*)(B + i), converted);\n    }\n    \n    for (; i < size; i++) {\n        float val = A[i];\n        if (val > INT32_MAX) {\n            B[i] = INT32_MAX;\n        } else if (val < INT32_MIN) {\n            B[i] = INT32_MIN;\n        } else {\n            B[i] = (int32_t)val;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_50_AVX", "completion": "```cpp\nvoid float_to_int_saturate_simd(const float* A, int32_t* B, size_t size) {\n    size_t i = 0;\n    size_t simd_size = size - (size % 8);\n    \n    __m256 max_float = _mm256_set1_ps((float)INT32_MAX);\n    __m256 min_float = _mm256_set1_ps((float)INT32_MIN);\n    \n    for (; i < simd_size; i += 8) {\n        __m256 input = _mm256_loadu_ps(A + i);\n        \n        input = _mm256_min_ps(input, max_float);\n        input = _mm256_max_ps(input, min_float);\n        \n        __m256i result = _mm256_cvtps_epi32(input);\n        _mm256_storeu_si256((__m256i*)(B + i), result);\n    }\n    \n    for (; i < size; i++) {\n        float val = A[i];\n        if (val > INT32_MAX) {\n            B[i] = INT32_MAX;\n        } else if (val < INT32_MIN) {\n            B[i] = INT32_MIN;\n        } else {\n            B[i] = (int32_t)val;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_50_AVX", "completion": "```cpp\nvoid float_to_int_saturate_simd(const float* A, int32_t* B, size_t size) {\n    size_t i = 0;\n    const size_t simd_size = size - (size % 8);\n    \n    __m256 max_float = _mm256_set1_ps((float)INT32_MAX);\n    __m256 min_float = _mm256_set1_ps((float)INT32_MIN);\n    \n    for (; i < simd_size; i += 8) {\n        __m256 input = _mm256_loadu_ps(&A[i]);\n        \n        input = _mm256_min_ps(input, max_float);\n        input = _mm256_max_ps(input, min_float);\n        \n        __m256i result = _mm256_cvtps_epi32(input);\n        _mm256_storeu_si256((__m256i*)&B[i], result);\n    }\n    \n    for (; i < size; i++) {\n        float val = A[i];\n        if (val > INT32_MAX) {\n            B[i] = INT32_MAX;\n        } else if (val < INT32_MIN) {\n            B[i] = INT32_MIN;\n        } else {\n            B[i] = (int32_t)val;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_50_AVX", "completion": "```cpp\nvoid float_to_int_saturate_simd(const float* A, int32_t* B, size_t size) {\n    size_t i;\n    size_t simd_size = size - (size % 8);\n    \n    __m256 max_float = _mm256_set1_ps((float)INT32_MAX);\n    __m256 min_float = _mm256_set1_ps((float)INT32_MIN);\n    \n    for (i = 0; i < simd_size; i += 8) {\n        __m256 input = _mm256_loadu_ps(A + i);\n        \n        input = _mm256_min_ps(input, max_float);\n        input = _mm256_max_ps(input, min_float);\n        \n        __m256i result = _mm256_cvtps_epi32(input);\n        _mm256_storeu_si256((__m256i*)(B + i), result);\n    }\n    \n    for (; i < size; i++) {\n        float val = A[i];\n        if (val > INT32_MAX) {\n            B[i] = INT32_MAX;\n        } else if (val < INT32_MIN) {\n            B[i] = INT32_MIN;\n        } else {\n            B[i] = (int32_t)val;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_50_AVX", "completion": "```cpp\nvoid float_to_int_saturate_simd(const float* A, int32_t* B, size_t size) {\n    size_t i;\n    size_t simd_size = size - (size % 8);\n    \n    __m256 max_float = _mm256_set1_ps((float)INT32_MAX);\n    __m256 min_float = _mm256_set1_ps((float)INT32_MIN);\n    \n    for (i = 0; i < simd_size; i += 8) {\n        __m256 input = _mm256_loadu_ps(A + i);\n        \n        input = _mm256_min_ps(input, max_float);\n        input = _mm256_max_ps(input, min_float);\n        \n        __m256i result = _mm256_cvtps_epi32(input);\n        _mm256_storeu_si256((__m256i*)(B + i), result);\n    }\n    \n    for (; i < size; i++) {\n        float val = A[i];\n        if (val > INT32_MAX) {\n            B[i] = INT32_MAX;\n        } else if (val < INT32_MIN) {\n            B[i] = INT32_MIN;\n        } else {\n            B[i] = (int32_t)val;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_51_AVX", "completion": "```cpp\nvoid int_to_float_scaled_simd(const int32_t* A, int8_t scale, float* B, size_t size) {\n    size_t i;\n    __m256 scale_vec = _mm256_set1_ps((float)scale);\n    \n    for (i = 0; i + 7 < size; i += 8) {\n        __m256i int_vec = _mm256_loadu_si256((__m256i*)(A + i));\n        __m256 float_vec = _mm256_cvtepi32_ps(int_vec);\n        __m256 scaled = _mm256_mul_ps(float_vec, scale_vec);\n        _mm256_storeu_ps(B + i, scaled);\n    }\n\n    // Handle remaining elements\n    for (; i < size; i++) {\n        B[i] = (float)A[i] * scale;\n    }\n}\n```"}
{"task_id": "SimdBench_51_AVX", "completion": "```cpp\nvoid int_to_float_scaled_simd(const int32_t* A, int8_t scale, float* B, size_t size) {\n    size_t i;\n    __m256 scale_vec = _mm256_set1_ps((float)scale);\n    \n    for (i = 0; i + 7 < size; i += 8) {\n        __m256i int_vec = _mm256_loadu_si256((const __m256i*)(A + i));\n        __m256 float_vec = _mm256_cvtepi32_ps(int_vec);\n        __m256 scaled = _mm256_mul_ps(float_vec, scale_vec);\n        _mm256_storeu_ps(B + i, scaled);\n    }\n\n    // Handle remaining elements\n    for (; i < size; i++) {\n        B[i] = (float)A[i] * scale;\n    }\n}\n```"}
{"task_id": "SimdBench_51_AVX", "completion": "```cpp\nvoid int_to_float_scaled_simd(const int32_t* A, int8_t scale, float* B, size_t size) {\n    size_t i;\n    __m256 scale_vec = _mm256_set1_ps((float)scale);\n    \n    for (i = 0; i + 7 < size; i += 8) {\n        __m256i int_vec = _mm256_loadu_si256((__m256i*)(A + i));\n        __m256 float_vec = _mm256_cvtepi32_ps(int_vec);\n        __m256 result = _mm256_mul_ps(float_vec, scale_vec);\n        _mm256_storeu_ps(B + i, result);\n    }\n\n    // Handle remaining elements\n    for (; i < size; i++) {\n        B[i] = (float)A[i] * scale;\n    }\n}\n```"}
{"task_id": "SimdBench_51_AVX", "completion": "```cpp\nvoid int_to_float_scaled_simd(const int32_t* A, int8_t scale, float* B, size_t size) {\n    size_t i;\n    __m256 scale_vec = _mm256_set1_ps((float)scale);\n    \n    for (i = 0; i + 8 <= size; i += 8) {\n        __m256i int_vec = _mm256_loadu_si256((__m256i*)(A + i));\n        __m256 float_vec = _mm256_cvtepi32_ps(int_vec);\n        __m256 scaled = _mm256_mul_ps(float_vec, scale_vec);\n        _mm256_storeu_ps(B + i, scaled);\n    }\n\n    // Handle remaining elements\n    for (; i < size; i++) {\n        B[i] = (float)A[i] * scale;\n    }\n}\n```"}
{"task_id": "SimdBench_51_AVX", "completion": "```cpp\nvoid int_to_float_scaled_simd(const int32_t* A, int8_t scale, float* B, size_t size) {\n    size_t i;\n    __m256 scale_vec = _mm256_set1_ps((float)scale);\n    \n    for (i = 0; i + 7 < size; i += 8) {\n        __m256i int_vec = _mm256_loadu_si256((__m256i*)(A + i));\n        __m256 float_vec = _mm256_cvtepi32_ps(int_vec);\n        __m256 scaled = _mm256_mul_ps(float_vec, scale_vec);\n        _mm256_storeu_ps(B + i, scaled);\n    }\n\n    // Handle remaining elements\n    for (; i < size; i++) {\n        B[i] = (float)A[i] * scale;\n    }\n}\n```"}
{"task_id": "SimdBench_52_AVX", "completion": "```cpp\nvoid float_div_round_simd(const float* A, const float* B, int32_t* C, size_t size) {\n    size_t i;\n    size_t simd_size = size - (size % 8);\n    \n    for (i = 0; i < simd_size; i += 8) {\n        __m256 a = _mm256_loadu_ps(A + i);\n        __m256 b = _mm256_loadu_ps(B + i);\n        __m256 div = _mm256_div_ps(a, b);\n        __m256i result = _mm256_cvtps_epi32(div);\n        _mm256_storeu_si256((__m256i*)(C + i), result);\n    }\n\n    // Handle remaining elements\n    for (; i < size; i++) {\n        C[i] = (int32_t)roundf(A[i] / B[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_52_AVX", "completion": "```cpp\nvoid float_div_round_simd(const float* A, const float* B, int32_t* C, size_t size) {\n    size_t i;\n    size_t simd_size = size - (size % 8);\n    \n    for (i = 0; i < simd_size; i += 8) {\n        __m256 a = _mm256_loadu_ps(A + i);\n        __m256 b = _mm256_loadu_ps(B + i);\n        __m256 div = _mm256_div_ps(a, b);\n        __m256i result = _mm256_cvtps_epi32(div);\n        _mm256_storeu_si256((__m256i*)(C + i), result);\n    }\n\n    // Handle remaining elements\n    for (; i < size; i++) {\n        C[i] = (int32_t)roundf(A[i] / B[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_52_AVX", "completion": "```cpp\nvoid float_div_round_simd(const float* A, const float* B, int32_t* C, size_t size) {\n    size_t i;\n    size_t simd_size = size - (size % 8);\n    \n    for (i = 0; i < simd_size; i += 8) {\n        __m256 a = _mm256_loadu_ps(A + i);\n        __m256 b = _mm256_loadu_ps(B + i);\n        __m256 div = _mm256_div_ps(a, b);\n        __m256i rounded = _mm256_cvtps_epi32(div);\n        _mm256_storeu_si256((__m256i*)(C + i), rounded);\n    }\n\n    // Handle remaining elements\n    for (; i < size; i++) {\n        C[i] = (int32_t)roundf(A[i] / B[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_52_AVX", "completion": "```cpp\nvoid float_div_round_simd(const float* A, const float* B, int32_t* C, size_t size) {\n    size_t i = 0;\n    size_t simd_size = size - (size % 8);\n    \n    for (; i < simd_size; i += 8) {\n        __m256 a = _mm256_loadu_ps(A + i);\n        __m256 b = _mm256_loadu_ps(B + i);\n        __m256 div = _mm256_div_ps(a, b);\n        __m256i result = _mm256_cvtps_epi32(div);\n        _mm256_storeu_si256((__m256i*)(C + i), result);\n    }\n\n    // Handle remaining elements\n    for (; i < size; i++) {\n        C[i] = (int32_t)roundf(A[i] / B[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_52_AVX", "completion": "```cpp\nvoid float_div_round_simd(const float* A, const float* B, int32_t* C, size_t size) {\n    size_t i;\n    size_t simd_size = size - (size % 8);\n    \n    for (i = 0; i < simd_size; i += 8) {\n        __m256 a = _mm256_loadu_ps(&A[i]);\n        __m256 b = _mm256_loadu_ps(&B[i]);\n        __m256 div = _mm256_div_ps(a, b);\n        __m256i rounded = _mm256_cvtps_epi32(div);\n        _mm256_storeu_si256((__m256i*)&C[i], rounded);\n    }\n\n    // Handle remaining elements\n    for (; i < size; i++) {\n        C[i] = (int32_t)roundf(A[i] / B[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_53_AVX", "completion": "```cpp\nvoid double_to_float_saturate_simd(const double* A, float* B, size_t size) {\n    size_t i;\n    const __m256d flt_max_d = _mm256_set1_pd(FLT_MAX);\n    const __m256d flt_min_d = _mm256_set1_pd(-FLT_MAX);\n    \n    for (i = 0; i + 3 < size; i += 4) {\n        __m256d input = _mm256_loadu_pd(A + i);\n        \n        // Clamp values between -FLT_MAX and FLT_MAX\n        input = _mm256_min_pd(input, flt_max_d);\n        input = _mm256_max_pd(input, flt_min_d);\n        \n        // Convert double to float with saturation\n        __m128 result = _mm256_cvtpd_ps(input);\n        \n        _mm_storeu_ps(B + i, result);\n    }\n    \n    // Handle remaining elements\n    for (; i < size; i++) {\n        double val = A[i];\n        if (val > FLT_MAX) {\n            B[i] = FLT_MAX;\n        } else if (val < -FLT_MAX) {\n            B[i] = -FLT_MAX;\n        } else {\n            B[i] = (float)val;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_53_AVX", "completion": "```cpp\nvoid double_to_float_saturate_simd(const double* A, float* B, size_t size) {\n    size_t i;\n    const __m256d flt_max_d = _mm256_set1_pd(FLT_MAX);\n    const __m256d flt_min_d = _mm256_set1_pd(-FLT_MAX);\n    \n    for (i = 0; i + 3 < size; i += 4) {\n        __m256d input = _mm256_loadu_pd(A + i);\n        \n        // Clamp values between -FLT_MAX and FLT_MAX\n        input = _mm256_min_pd(input, flt_max_d);\n        input = _mm256_max_pd(input, flt_min_d);\n        \n        // Convert double to float with saturation\n        __m128 result = _mm256_cvtpd_ps(input);\n        \n        _mm_storeu_ps(B + i, result);\n    }\n    \n    // Handle remaining elements\n    for (; i < size; i++) {\n        double val = A[i];\n        if (val > FLT_MAX) val = FLT_MAX;\n        if (val < -FLT_MAX) val = -FLT_MAX;\n        B[i] = (float)val;\n    }\n}\n```"}
{"task_id": "SimdBench_53_AVX", "completion": "```cpp\nvoid double_to_float_saturate_simd(const double* A, float* B, size_t size) {\n    size_t i;\n    const __m256d flt_max_d = _mm256_set1_pd(FLT_MAX);\n    const __m256d flt_min_d = _mm256_set1_pd(-FLT_MAX);\n    \n    for (i = 0; i + 3 < size; i += 4) {\n        __m256d input = _mm256_loadu_pd(A + i);\n        \n        // Clamp values between -FLT_MAX and FLT_MAX\n        input = _mm256_min_pd(input, flt_max_d);\n        input = _mm256_max_pd(input, flt_min_d);\n        \n        // Convert double to float with saturation\n        __m128 result = _mm256_cvtpd_ps(input);\n        \n        _mm_storeu_ps(B + i, result);\n    }\n    \n    // Handle remaining elements\n    for (; i < size; i++) {\n        double val = A[i];\n        if (val > FLT_MAX) val = FLT_MAX;\n        else if (val < -FLT_MAX) val = -FLT_MAX;\n        B[i] = (float)val;\n    }\n}\n```"}
{"task_id": "SimdBench_53_AVX", "completion": "```cpp\nvoid double_to_float_saturate_simd(const double* A, float* B, size_t size) {\n    size_t i;\n    const __m256d flt_max_d = _mm256_set1_pd(FLT_MAX);\n    const __m256d flt_min_d = _mm256_set1_pd(-FLT_MAX);\n    \n    for (i = 0; i + 3 < size; i += 4) {\n        __m256d input = _mm256_loadu_pd(A + i);\n        \n        // Clamp values between -FLT_MAX and FLT_MAX\n        input = _mm256_min_pd(input, flt_max_d);\n        input = _mm256_max_pd(input, flt_min_d);\n        \n        // Convert double to float with saturation\n        __m128 result = _mm256_cvtpd_ps(input);\n        \n        _mm_storeu_ps(B + i, result);\n    }\n    \n    // Handle remaining elements\n    for (; i < size; i++) {\n        double val = A[i];\n        if (val > FLT_MAX) val = FLT_MAX;\n        if (val < -FLT_MAX) val = -FLT_MAX;\n        B[i] = (float)val;\n    }\n}\n```"}
{"task_id": "SimdBench_53_AVX", "completion": "```cpp\nvoid double_to_float_saturate_simd(const double* A, float* B, size_t size) {\n    size_t i;\n    const size_t simd_size = size - (size % 4);\n    const __m256 max_float = _mm256_set1_ps(FLT_MAX);\n    const __m256 min_float = _mm256_set1_ps(-FLT_MAX);\n\n    for (i = 0; i < simd_size; i += 4) {\n        __m256d v_double = _mm256_loadu_pd(&A[i]);\n        __m128 v_float = _mm256_cvtpd_ps(v_double);\n        __m256 v_float_extended = _mm256_insertf128_ps(_mm256_castps128_ps256(v_float), v_float, 1);\n        \n        v_float_extended = _mm256_min_ps(_mm256_max_ps(v_float_extended, min_float), max_float);\n        _mm_storeu_ps(&B[i], _mm256_castps256_ps128(v_float_extended));\n    }\n\n    for (; i < size; i++) {\n        if (A[i] > FLT_MAX) {\n            B[i] = FLT_MAX;\n        } else if (A[i] < -FLT_MAX) {\n            B[i] = -FLT_MAX;\n        } else {\n            B[i] = (float)A[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_54_AVX", "completion": "```cpp\nvoid int16_to_int32_simd(const int16_t* A, int32_t* B, size_t size) {\n    size_t i = 0;\n    \n    // Process 8 elements at a time using AVX2\n    for (; i + 7 < size; i += 8) {\n        __m128i a = _mm_loadu_si128((__m128i*)(A + i));\n        __m256i b = _mm256_cvtepi16_epi32(a);\n        _mm256_storeu_si256((__m256i*)(B + i), b);\n    }\n    \n    // Handle remaining elements\n    for (; i < size; i++) {\n        B[i] = (int32_t)A[i];\n    }\n}\n```"}
{"task_id": "SimdBench_54_AVX", "completion": "```cpp\nvoid int16_to_int32_simd(const int16_t* A, int32_t* B, size_t size) {\n    size_t i = 0;\n    \n    // Process 8 elements at a time using AVX2\n    for (; i + 7 < size; i += 8) {\n        __m128i input = _mm_loadu_si128((__m128i*)(A + i));\n        __m256i output = _mm256_cvtepi16_epi32(input);\n        _mm256_storeu_si256((__m256i*)(B + i), output);\n    }\n    \n    // Handle remaining elements\n    for (; i < size; i++) {\n        B[i] = (int32_t)A[i];\n    }\n}\n```"}
{"task_id": "SimdBench_54_AVX", "completion": "```cpp\nvoid int16_to_int32_simd(const int16_t* A, int32_t* B, size_t size) {\n    size_t i = 0;\n    \n    // Process 8 elements at a time using AVX2\n    for (; i + 7 < size; i += 8) {\n        __m128i input = _mm_loadu_si128((__m128i*)(A + i));\n        __m256i output = _mm256_cvtepi16_epi32(input);\n        _mm256_storeu_si256((__m256i*)(B + i), output);\n    }\n    \n    // Handle remaining elements\n    for (; i < size; i++) {\n        B[i] = (int32_t)A[i];\n    }\n}\n```"}
{"task_id": "SimdBench_54_AVX", "completion": "```cpp\nvoid int16_to_int32_simd(const int16_t* A, int32_t* B, size_t size) {\n    size_t i = 0;\n    \n    // Process 8 elements at a time using AVX2\n    for (; i + 7 < size; i += 8) {\n        __m128i input = _mm_loadu_si128((__m128i*)(A + i));\n        __m256i output = _mm256_cvtepi16_epi32(input);\n        _mm256_storeu_si256((__m256i*)(B + i), output);\n    }\n    \n    // Handle remaining elements\n    for (; i < size; i++) {\n        B[i] = (int32_t)A[i];\n    }\n}\n```"}
{"task_id": "SimdBench_54_AVX", "completion": "```cpp\nvoid int16_to_int32_simd(const int16_t* A, int32_t* B, size_t size) {\n    size_t i = 0;\n    \n    // Process 8 elements at a time using AVX2\n    for (; i + 7 < size; i += 8) {\n        __m128i a = _mm_loadu_si128((__m128i*)(A + i));\n        __m256i b = _mm256_cvtepi16_epi32(a);\n        _mm256_storeu_si256((__m256i*)(B + i), b);\n    }\n    \n    // Handle remaining elements\n    for (; i < size; i++) {\n        B[i] = (int32_t)A[i];\n    }\n}\n```"}
{"task_id": "SimdBench_55_AVX", "completion": "```cpp\nvoid conditional_normalize_simd(const float* A, const int32_t* control, float* B, size_t size, float min_val, float max_val) {\n    const size_t simd_size = size - (size % 8);\n    const float range = max_val - min_val;\n    \n    __m256 v_min = _mm256_set1_ps(min_val);\n    __m256 v_range = _mm256_set1_ps(range);\n    __m256 v_zero = _mm256_setzero_ps();\n    __m256 v_one = _mm256_set1_ps(1.0f);\n\n    for (size_t i = 0; i < simd_size; i += 8) {\n        __m256 v_a = _mm256_loadu_ps(&A[i]);\n        __m256i v_control = _mm256_loadu_si256((__m256i*)&control[i]);\n        \n        // Create mask for positive control values\n        __m256 v_mask = _mm256_castsi256_ps(_mm256_cmpgt_epi32(v_control, _mm256_setzero_si256()));\n        \n        // Normalize values\n        __m256 v_normalized = _mm256_sub_ps(v_a, v_min);\n        v_normalized = _mm256_div_ps(v_normalized, v_range);\n        \n        // Clamp between 0 and 1\n        v_normalized = _mm256_max_ps(v_normalized, v_zero);\n        v_normalized = _mm256_min_ps(v_normalized, v_one);\n        \n        // Select between normalized and original based on mask\n        __m256 v_result = _mm256_blendv_ps(v_a, v_normalized, v_mask);\n        \n        _mm256_storeu_ps(&B[i], v_result);\n    }\n\n    // Handle remaining elements\n    for (size_t i = simd_size; i < size; i++) {\n        if (control[i] > 0) {\n            float normalized = (A[i] - min_val) / range;\n            B[i] = normalized < 0.0f ? 0.0f : (normalized > 1.0f ? 1.0f : normalized);\n        } else {\n            B[i] = A[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_55_AVX", "completion": "```cpp\nvoid conditional_normalize_simd(const float* A, const int32_t* control, float* B, size_t size, float min_val, float max_val) {\n    const size_t simd_size = size - (size % 8);\n    const float range = max_val - min_val;\n    \n    __m256 v_min = _mm256_set1_ps(min_val);\n    __m256 v_range = _mm256_set1_ps(range);\n    __m256 v_zero = _mm256_setzero_ps();\n    __m256 v_one = _mm256_set1_ps(1.0f);\n    \n    for (size_t i = 0; i < simd_size; i += 8) {\n        __m256 v_a = _mm256_loadu_ps(&A[i]);\n        __m256i v_control = _mm256_loadu_si256((__m256i*)&control[i]);\n        \n        // Create mask for positive control values\n        __m256 v_mask = _mm256_castsi256_ps(_mm256_cmpgt_epi32(v_control, _mm256_setzero_si256()));\n        \n        // Normalize values\n        __m256 v_normalized = _mm256_sub_ps(v_a, v_min);\n        v_normalized = _mm256_div_ps(v_normalized, v_range);\n        \n        // Clamp between 0 and 1\n        v_normalized = _mm256_max_ps(v_normalized, v_zero);\n        v_normalized = _mm256_min_ps(v_normalized, v_one);\n        \n        // Select between normalized and original based on mask\n        __m256 v_result = _mm256_blendv_ps(v_a, v_normalized, v_mask);\n        \n        _mm256_storeu_ps(&B[i], v_result);\n    }\n    \n    // Handle remaining elements\n    for (size_t i = simd_size; i < size; i++) {\n        if (control[i] > 0) {\n            float normalized = (A[i] - min_val) / range;\n            B[i] = normalized < 0.0f ? 0.0f : (normalized > 1.0f ? 1.0f : normalized);\n        } else {\n            B[i] = A[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_55_AVX", "completion": "```cpp\nvoid conditional_normalize_simd(const float* A, const int32_t* control, float* B, size_t size, float min_val, float max_val) {\n    const size_t simd_size = size - (size % 8);\n    const float range = max_val - min_val;\n    \n    __m256 v_min = _mm256_set1_ps(min_val);\n    __m256 v_range = _mm256_set1_ps(range);\n    __m256 v_zero = _mm256_setzero_ps();\n    __m256 v_one = _mm256_set1_ps(1.0f);\n\n    for (size_t i = 0; i < simd_size; i += 8) {\n        __m256 v_a = _mm256_loadu_ps(&A[i]);\n        __m256i v_control = _mm256_loadu_si256((__m256i*)&control[i]);\n        \n        // Create mask for positive control values\n        __m256 v_mask = _mm256_cmp_ps(_mm256_cvtepi32_ps(v_control), v_zero, _CMP_GT_OS);\n        \n        // Normalize values\n        __m256 v_normalized = _mm256_sub_ps(v_a, v_min);\n        v_normalized = _mm256_div_ps(v_normalized, v_range);\n        \n        // Clamp between 0 and 1\n        v_normalized = _mm256_min_ps(_mm256_max_ps(v_normalized, v_zero), v_one);\n        \n        // Select between normalized and original based on mask\n        __m256 v_result = _mm256_blendv_ps(v_a, v_normalized, v_mask);\n        \n        _mm256_storeu_ps(&B[i], v_result);\n    }\n\n    // Handle remaining elements\n    for (size_t i = simd_size; i < size; i++) {\n        if (control[i] > 0) {\n            float normalized = (A[i] - min_val) / range;\n            B[i] = normalized < 0.0f ? 0.0f : (normalized > 1.0f ? 1.0f : normalized);\n        } else {\n            B[i] = A[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_55_AVX", "completion": "```cpp\nvoid conditional_normalize_simd(const float* A, const int32_t* control, float* B, size_t size, float min_val, float max_val) {\n    const size_t simd_size = size - (size % 8);\n    const float range = max_val - min_val;\n    \n    __m256 v_min = _mm256_set1_ps(min_val);\n    __m256 v_range = _mm256_set1_ps(range);\n    __m256 v_zero = _mm256_setzero_ps();\n    __m256 v_one = _mm256_set1_ps(1.0f);\n    \n    for (size_t i = 0; i < simd_size; i += 8) {\n        __m256 v_a = _mm256_loadu_ps(&A[i]);\n        __m256i v_control = _mm256_loadu_si256((__m256i*)&control[i]);\n        \n        // Create mask for positive control values\n        __m256 v_mask = _mm256_cmp_ps(_mm256_cvtepi32_ps(v_control), v_zero, _CMP_GT_OS);\n        \n        // Normalize values\n        __m256 v_normalized = _mm256_sub_ps(v_a, v_min);\n        v_normalized = _mm256_div_ps(v_normalized, v_range);\n        \n        // Clamp between 0 and 1\n        v_normalized = _mm256_min_ps(_mm256_max_ps(v_normalized, v_zero), v_one);\n        \n        // Select between normalized and original based on mask\n        __m256 v_result = _mm256_blendv_ps(v_a, v_normalized, v_mask);\n        \n        _mm256_storeu_ps(&B[i], v_result);\n    }\n    \n    // Handle remaining elements\n    for (size_t i = simd_size; i < size; i++) {\n        if (control[i] > 0) {\n            float normalized = (A[i] - min_val) / range;\n            B[i] = normalized < 0.0f ? 0.0f : (normalized > 1.0f ? 1.0f : normalized);\n        } else {\n            B[i] = A[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_55_AVX", "completion": "```cpp\nvoid conditional_normalize_simd(const float* A, const int32_t* control, float* B, size_t size, float min_val, float max_val) {\n    const size_t simd_size = size - (size % 8);\n    const float range = max_val - min_val;\n    \n    __m256 v_min = _mm256_set1_ps(min_val);\n    __m256 v_range = _mm256_set1_ps(range);\n    __m256 v_zero = _mm256_setzero_ps();\n    __m256 v_one = _mm256_set1_ps(1.0f);\n\n    for (size_t i = 0; i < simd_size; i += 8) {\n        __m256 v_a = _mm256_loadu_ps(&A[i]);\n        __m256i v_control = _mm256_loadu_si256((__m256i*)&control[i]);\n        \n        // Create mask for positive control values\n        __m256 v_mask = _mm256_castsi256_ps(_mm256_cmpgt_epi32(v_control, _mm256_setzero_si256()));\n        \n        // Normalize values\n        __m256 v_normalized = _mm256_sub_ps(v_a, v_min);\n        v_normalized = _mm256_div_ps(v_normalized, v_range);\n        \n        // Clamp between 0 and 1\n        v_normalized = _mm256_max_ps(v_normalized, v_zero);\n        v_normalized = _mm256_min_ps(v_normalized, v_one);\n        \n        // Select between normalized and original based on mask\n        __m256 v_result = _mm256_blendv_ps(v_a, v_normalized, v_mask);\n        \n        _mm256_storeu_ps(&B[i], v_result);\n    }\n\n    // Handle remaining elements\n    for (size_t i = simd_size; i < size; i++) {\n        if (control[i] > 0) {\n            float normalized = (A[i] - min_val) / range;\n            B[i] = normalized < 0.0f ? 0.0f : (normalized > 1.0f ? 1.0f : normalized);\n        } else {\n            B[i] = A[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_56_AVX", "completion": "```cpp\nvoid int_to_float_sqrt_simd(const uint32_t* A, float* B, size_t size) {\n    size_t i;\n    const size_t simd_size = size - (size % 8);\n    \n    for (i = 0; i < simd_size; i += 8) {\n        __m256i input = _mm256_loadu_si256((__m256i*)(A + i));\n        __m256i shifted = _mm256_srli_epi32(input, 16);\n        __m256 converted = _mm256_cvtepi32_ps(shifted);\n        __m256 result = _mm256_sqrt_ps(converted);\n        _mm256_storeu_ps(B + i, result);\n    }\n\n    // Handle remaining elements\n    for (; i < size; i++) {\n        uint32_t val = A[i] >> 16;\n        B[i] = sqrtf((float)val);\n    }\n}\n```"}
{"task_id": "SimdBench_56_AVX", "completion": "```cpp\nvoid int_to_float_sqrt_simd(const uint32_t* A, float* B, size_t size) {\n    size_t i;\n    const size_t simd_size = size - (size % 8);\n    \n    for (i = 0; i < simd_size; i += 8) {\n        __m256i input = _mm256_loadu_si256((__m256i*)(A + i));\n        __m256i shifted = _mm256_srli_epi32(input, 16);\n        __m256 converted = _mm256_cvtepi32_ps(shifted);\n        __m256 result = _mm256_sqrt_ps(converted);\n        _mm256_storeu_ps(B + i, result);\n    }\n\n    // Handle remaining elements\n    for (; i < size; i++) {\n        uint32_t val = A[i] >> 16;\n        B[i] = sqrtf((float)val);\n    }\n}\n```"}
{"task_id": "SimdBench_56_AVX", "completion": "```cpp\nvoid int_to_float_sqrt_simd(const uint32_t* A, float* B, size_t size) {\n    size_t i;\n    const size_t simd_size = size - (size % 8);\n    \n    for (i = 0; i < simd_size; i += 8) {\n        __m256i input = _mm256_loadu_si256((__m256i*)(A + i));\n        __m256i shifted = _mm256_srli_epi32(input, 16);\n        __m256 converted = _mm256_cvtepi32_ps(shifted);\n        __m256 result = _mm256_sqrt_ps(converted);\n        _mm256_storeu_ps(B + i, result);\n    }\n\n    // Handle remaining elements\n    for (; i < size; i++) {\n        uint32_t val = A[i] >> 16;\n        B[i] = sqrtf((float)val);\n    }\n}\n```"}
{"task_id": "SimdBench_56_AVX", "completion": "```cpp\nvoid int_to_float_sqrt_simd(const uint32_t* A, float* B, size_t size) {\n    size_t i;\n    const size_t simd_size = size - (size % 8);\n    \n    for (i = 0; i < simd_size; i += 8) {\n        __m256i input = _mm256_loadu_si256((__m256i*)(A + i));\n        __m256i shifted = _mm256_srli_epi32(input, 16);\n        __m256 converted = _mm256_cvtepi32_ps(shifted);\n        __m256 result = _mm256_sqrt_ps(converted);\n        _mm256_storeu_ps(B + i, result);\n    }\n\n    // Handle remaining elements\n    for (; i < size; i++) {\n        uint32_t val = A[i] >> 16;\n        B[i] = sqrtf((float)val);\n    }\n}\n```"}
{"task_id": "SimdBench_56_AVX", "completion": "```cpp\nvoid int_to_float_sqrt_simd(const uint32_t* A, float* B, size_t size) {\n    size_t i;\n    const size_t simd_size = size - (size % 8);\n    \n    for (i = 0; i < simd_size; i += 8) {\n        __m256i input = _mm256_loadu_si256((__m256i*)(A + i));\n        __m256i shifted = _mm256_srli_epi32(input, 16);\n        __m256 converted = _mm256_cvtepi32_ps(shifted);\n        __m256 result = _mm256_sqrt_ps(converted);\n        _mm256_storeu_ps(B + i, result);\n    }\n\n    // Handle remaining elements\n    for (; i < size; i++) {\n        uint32_t val = A[i] >> 16;\n        B[i] = sqrtf((float)val);\n    }\n}\n```"}
{"task_id": "SimdBench_57_AVX", "completion": "```cpp\nvoid int_bits_to_float_simd(const uint32_t* A, float* B, size_t size) {\n    size_t i;\n    size_t simd_width = 8;\n    size_t simd_size = size - (size % simd_width);\n\n    for (i = 0; i < simd_size; i += simd_width) {\n        __m256i int_vec = _mm256_loadu_si256((__m256i*)(A + i));\n        __m256 float_vec = _mm256_castsi256_ps(int_vec);\n        _mm256_storeu_ps(B + i, float_vec);\n    }\n\n    for (; i < size; i++) {\n        union {\n            uint32_t i;\n            float f;\n        } u;\n        u.i = A[i];\n        B[i] = u.f;\n    }\n}\n```"}
{"task_id": "SimdBench_57_AVX", "completion": "```cpp\nvoid int_bits_to_float_simd(const uint32_t* A, float* B, size_t size) {\n    size_t i = 0;\n    size_t simd_size = size - (size % 8);\n    \n    for (; i < simd_size; i += 8) {\n        __m256i int_vec = _mm256_loadu_si256((__m256i*)(A + i));\n        __m256 float_vec = _mm256_castsi256_ps(int_vec);\n        _mm256_storeu_ps(B + i, float_vec);\n    }\n\n    for (; i < size; i++) {\n        union {\n            uint32_t i;\n            float f;\n        } u;\n        u.i = A[i];\n        B[i] = u.f;\n    }\n}\n```"}
{"task_id": "SimdBench_57_AVX", "completion": "```cpp\nvoid int_bits_to_float_simd(const uint32_t* A, float* B, size_t size) {\n    size_t i = 0;\n    size_t simd_size = size - (size % 8);\n    \n    for (; i < simd_size; i += 8) {\n        __m256i int_vec = _mm256_loadu_si256((__m256i*)(A + i));\n        __m256 float_vec = _mm256_castsi256_ps(int_vec);\n        _mm256_storeu_ps(B + i, float_vec);\n    }\n\n    for (; i < size; i++) {\n        union {\n            uint32_t i;\n            float f;\n        } u;\n        u.i = A[i];\n        B[i] = u.f;\n    }\n}\n```"}
{"task_id": "SimdBench_57_AVX", "completion": "```cpp\nvoid int_bits_to_float_simd(const uint32_t* A, float* B, size_t size) {\n    size_t i = 0;\n    size_t simd_size = size - (size % 8);\n    \n    for (; i < simd_size; i += 8) {\n        __m256i int_vec = _mm256_loadu_si256((__m256i*)(A + i));\n        _mm256_storeu_ps(B + i, _mm256_castsi256_ps(int_vec));\n    }\n    \n    for (; i < size; i++) {\n        B[i] = *(float*)(A + i);\n    }\n}\n```"}
{"task_id": "SimdBench_57_AVX", "completion": "```cpp\nvoid int_bits_to_float_simd(const uint32_t* A, float* B, size_t size) {\n    size_t i = 0;\n    size_t simd_size = size - (size % 8);\n    \n    for (; i < simd_size; i += 8) {\n        __m256i int_vec = _mm256_loadu_si256((__m256i*)(A + i));\n        __m256 float_vec = _mm256_castsi256_ps(int_vec);\n        _mm256_storeu_ps(B + i, float_vec);\n    }\n\n    for (; i < size; i++) {\n        union {\n            uint32_t i;\n            float f;\n        } u;\n        u.i = A[i];\n        B[i] = u.f;\n    }\n}\n```"}
{"task_id": "SimdBench_58_AVX", "completion": "```cpp\nvoid conditional_diff_simd(const int32_t* A, const bool* cond, float* diff, size_t size) {\n    diff[0] = 0.0f;\n    \n    if (size <= 1) return;\n    \n    const size_t vec_size = 8;\n    size_t i = 1;\n    \n    for (; i + vec_size <= size; i += vec_size) {\n        __m256i curr = _mm256_loadu_si256((__m256i*)(A + i));\n        __m256i prev = _mm256_loadu_si256((__m256i*)(A + i - 1));\n        __m256i diff_i = _mm256_sub_epi32(curr, prev);\n        \n        __m256 diff_f = _mm256_cvtepi32_ps(diff_i);\n        \n        __m256i cond_mask = _mm256_loadu_si256((__m256i*)(cond + i));\n        cond_mask = _mm256_and_si256(cond_mask, _mm256_set1_epi32(0x1));\n        __m256 mask_f = _mm256_castsi256_ps(_mm256_cmpeq_epi32(cond_mask, _mm256_set1_epi32(1)));\n        \n        __m256 result = _mm256_and_ps(diff_f, mask_f);\n        \n        _mm256_storeu_ps(diff + i, result);\n    }\n    \n    for (; i < size; i++) {\n        diff[i] = cond[i] ? (float)(A[i] - A[i-1]) : 0.0f;\n    }\n}\n```"}
{"task_id": "SimdBench_58_AVX", "completion": "```cpp\nvoid conditional_diff_simd(const int32_t* A, const bool* cond, float* diff, size_t size) {\n    diff[0] = 0.0f;\n    \n    if (size <= 1) return;\n    \n    const size_t vec_size = 8;\n    size_t i = 1;\n    \n    for (; i + vec_size <= size; i += vec_size) {\n        __m256i curr = _mm256_loadu_si256((__m256i*)(A + i));\n        __m256i prev = _mm256_loadu_si256((__m256i*)(A + i - 1));\n        __m256i mask = _mm256_loadu_si256((__m256i*)(cond + i));\n        \n        // Calculate difference\n        __m256i diff_i = _mm256_sub_epi32(curr, prev);\n        \n        // Convert to float\n        __m256 diff_f = _mm256_cvtepi32_ps(diff_i);\n        \n        // Create mask from boolean array\n        mask = _mm256_and_si256(mask, _mm256_set1_epi32(0xFFFFFFFF));\n        __m256 mask_f = _mm256_castsi256_ps(mask);\n        \n        // Apply mask\n        __m256 result = _mm256_and_ps(diff_f, mask_f);\n        \n        // Store result\n        _mm256_storeu_ps(diff + i, result);\n    }\n    \n    // Handle remaining elements\n    for (; i < size; i++) {\n        diff[i] = cond[i] ? (float)(A[i] - A[i-1]) : 0.0f;\n    }\n}\n```"}
{"task_id": "SimdBench_58_AVX", "completion": "```cpp\nvoid conditional_diff_simd(const int32_t* A, const bool* cond, float* diff, size_t size) {\n    if (size == 0) return;\n    \n    diff[0] = 0.0f;\n    \n    const size_t vec_size = 8;\n    size_t i = 1;\n    \n    for (; i + vec_size <= size; i += vec_size) {\n        __m256i curr = _mm256_loadu_si256((__m256i*)(A + i));\n        __m256i prev = _mm256_loadu_si256((__m256i*)(A + i - 1));\n        __m256i diff_i = _mm256_sub_epi32(curr, prev);\n        \n        __m256 diff_f = _mm256_cvtepi32_ps(diff_i);\n        \n        __m256i cond_mask = _mm256_loadu_si256((__m256i*)(cond + i));\n        cond_mask = _mm256_and_si256(cond_mask, _mm256_set1_epi32(0x1));\n        __m256 mask_f = _mm256_castsi256_ps(_mm256_and_si256(\n            _mm256_set1_epi32(0xFFFFFFFF),\n            _mm256_cvtepi8_epi32(_mm256_castsi256_si128(cond_mask))\n        ));\n        \n        __m256 result = _mm256_and_ps(diff_f, mask_f);\n        _mm256_storeu_ps(diff + i, result);\n    }\n    \n    for (; i < size; i++) {\n        diff[i] = cond[i] ? (float)(A[i] - A[i-1]) : 0.0f;\n    }\n}\n```"}
{"task_id": "SimdBench_58_AVX", "completion": "```cpp\nvoid conditional_diff_simd(const int32_t* A, const bool* cond, float* diff, size_t size) {\n    if (size == 0) return;\n    \n    diff[0] = 0.0f;\n    \n    const size_t simd_width = 8;\n    const size_t simd_size = size - (size % simd_width);\n    \n    for (size_t i = 1; i < simd_size; i += simd_width) {\n        __m256i curr = _mm256_loadu_si256((__m256i*)(A + i));\n        __m256i prev = _mm256_loadu_si256((__m256i*)(A + i - 1));\n        \n        __m256i diff_i32 = _mm256_sub_epi32(curr, prev);\n        __m256 diff_f32 = _mm256_cvtepi32_ps(diff_i32);\n        \n        __m256i cond_mask = _mm256_loadu_si256((__m256i*)(cond + i));\n        cond_mask = _mm256_and_si256(cond_mask, _mm256_set1_epi32(0x1));\n        __m256 mask = _mm256_castsi256_ps(_mm256_cmpeq_epi32(cond_mask, _mm256_set1_epi32(1)));\n        \n        __m256 result = _mm256_and_ps(diff_f32, mask);\n        _mm256_storeu_ps(diff + i, result);\n    }\n    \n    for (size_t i = simd_size; i < size; i++) {\n        diff[i] = cond[i] ? (float)(A[i] - A[i-1]) : 0.0f;\n    }\n}\n```"}
{"task_id": "SimdBench_58_AVX", "completion": "```cpp\nvoid conditional_diff_simd(const int32_t* A, const bool* cond, float* diff, size_t size) {\n    if (size == 0) return;\n    \n    diff[0] = 0.0f;\n    \n    const size_t vec_size = 8;\n    size_t i = 1;\n    \n    if (size > vec_size) {\n        __m256i prev = _mm256_set1_epi32(A[0]);\n        \n        for (; i + vec_size <= size; i += vec_size) {\n            __m256i curr = _mm256_loadu_si256((__m256i*)(A + i));\n            __m256i shifted = _mm256_alignr_epi8(curr, prev, 12);\n            \n            __m256i diff_i = _mm256_sub_epi32(curr, shifted);\n            __m256 diff_f = _mm256_cvtepi32_ps(diff_i);\n            \n            __m256i mask = _mm256_loadu_si256((__m256i*)(cond + i));\n            mask = _mm256_and_si256(mask, _mm256_set1_epi32(0xFFFFFFFF));\n            __m256 mask_f = _mm256_castsi256_ps(mask);\n            \n            __m256 result = _mm256_and_ps(diff_f, mask_f);\n            _mm256_storeu_ps(diff + i, result);\n            \n            prev = curr;\n        }\n    }\n    \n    for (; i < size; i++) {\n        diff[i] = cond[i] ? (float)(A[i] - A[i-1]) : 0.0f;\n    }\n}\n```"}
{"task_id": "SimdBench_59_AVX", "completion": "```cpp\nvoid widening_uint_simd(const uint32_t* src, uint64_t* dst, size_t length) {\n    size_t i = 0;\n    const __m256i ones = _mm256_set1_epi32(-1);\n\n    for (; i + 4 <= length; i += 4) {\n        __m128i x = _mm_loadu_si128((__m128i*)(src + i));\n        __m256i extended = _mm256_cvtepu32_epi64(x);\n        __m256i result = _mm256_slli_epi64(ones, 32);\n        result = _mm256_or_si256(result, extended);\n        _mm256_storeu_si256((__m256i*)(dst + i), result);\n    }\n\n    // Handle remaining elements\n    for (; i < length; i++) {\n        dst[i] = (0xFFFFFFFFULL << 32) | src[i];\n    }\n}\n```"}
{"task_id": "SimdBench_59_AVX", "completion": "```cpp\nvoid widening_uint_simd(const uint32_t* src, uint64_t* dst, size_t length) {\n    size_t i;\n    const __m256i ones = _mm256_set1_epi32(-1);\n    \n    for (i = 0; i + 4 <= length; i += 4) {\n        __m128i x = _mm_loadu_si128((__m128i*)(src + i));\n        __m256i extended = _mm256_cvtepu32_epi64(x);\n        __m256i result = _mm256_slli_epi64(ones, 32);\n        result = _mm256_or_si256(result, extended);\n        _mm256_storeu_si256((__m256i*)(dst + i), result);\n    }\n\n    // Handle remaining elements\n    for (; i < length; i++) {\n        dst[i] = (uint64_t)src[i] | (0xFFFFFFFFULL << 32);\n    }\n}\n```"}
{"task_id": "SimdBench_59_AVX", "completion": "```cpp\nvoid widening_uint_simd(const uint32_t* src, uint64_t* dst, size_t length) {\n    size_t i = 0;\n    \n    // Process 4 elements at a time using AVX2\n    for (; i + 4 <= length; i += 4) {\n        __m128i src_vec = _mm_loadu_si128((__m128i*)(src + i));\n        __m256i wide = _mm256_cvtepu32_epi64(src_vec);\n        __m256i mask = _mm256_set1_epi64x(0xFFFFFFFF00000000);\n        __m256i result = _mm256_or_si256(wide, mask);\n        _mm256_storeu_si256((__m256i*)(dst + i), result);\n    }\n    \n    // Handle remaining elements\n    for (; i < length; i++) {\n        dst[i] = (uint64_t)src[i] | 0xFFFFFFFF00000000ULL;\n    }\n}\n```"}
{"task_id": "SimdBench_59_AVX", "completion": "```cpp\nvoid widening_uint_simd(const uint32_t* src, uint64_t* dst, size_t length) {\n    size_t i = 0;\n    const __m256i ones = _mm256_set1_epi32(-1);\n\n    for (; i + 4 <= length; i += 4) {\n        __m128i x = _mm_loadu_si128((__m128i*)(src + i));\n        __m256i extended = _mm256_cvtepu32_epi64(x);\n        __m256i high_bits = _mm256_slli_epi64(ones, 32);\n        __m256i result = _mm256_or_si256(extended, high_bits);\n        _mm256_storeu_si256((__m256i*)(dst + i), result);\n    }\n\n    for (; i < length; i++) {\n        dst[i] = (uint64_t)src[i] | (0xFFFFFFFFULL << 32);\n    }\n}\n```"}
{"task_id": "SimdBench_59_AVX", "completion": "```cpp\nvoid widening_uint_simd(const uint32_t* src, uint64_t* dst, size_t length) {\n    size_t i = 0;\n    const __m256i ones = _mm256_set1_epi32(-1);\n    \n    for (; i + 4 <= length; i += 4) {\n        __m128i x = _mm_loadu_si128((__m128i*)(src + i));\n        __m256i extended = _mm256_cvtepu32_epi64(x);\n        __m256i result = _mm256_slli_epi64(ones, 32);\n        result = _mm256_or_si256(result, extended);\n        _mm256_storeu_si256((__m256i*)(dst + i), result);\n    }\n\n    // Handle remaining elements\n    for (; i < length; i++) {\n        dst[i] = (uint64_t)src[i] | (0xFFFFFFFFULL << 32);\n    }\n}\n```"}
{"task_id": "SimdBench_60_AVX", "completion": "```cpp\ndouble indexed_sum_simd(const double* vec, const int16_t* index, size_t length) {\n    __m256d sum = _mm256_setzero_pd();\n    size_t i;\n    \n    for (i = 0; i + 3 < length; i += 4) {\n        __m128i idx = _mm_loadu_si128((__m128i*)(index + i));\n        __m128i idx_32 = _mm_cvtepi16_epi32(idx);\n        \n        __m256d v = _mm256_set_pd(\n            vec[_mm_extract_epi32(idx_32, 3)],\n            vec[_mm_extract_epi32(idx_32, 2)], \n            vec[_mm_extract_epi32(idx_32, 1)],\n            vec[_mm_extract_epi32(idx_32, 0)]\n        );\n        \n        sum = _mm256_add_pd(sum, v);\n    }\n    \n    double result = _mm256_cvtsd_f64(sum) + \n                   _mm256_cvtsd_f64(_mm256_permute4x64_pd(sum, 1)) +\n                   _mm256_cvtsd_f64(_mm256_permute4x64_pd(sum, 2)) +\n                   _mm256_cvtsd_f64(_mm256_permute4x64_pd(sum, 3));\n                   \n    for (; i < length; i++) {\n        result += vec[index[i]];\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_60_AVX", "completion": "```cpp\ndouble indexed_sum_simd(const double* vec, const int16_t* index, size_t length) {\n    __m256d sum = _mm256_setzero_pd();\n    size_t i;\n    \n    for (i = 0; i + 3 < length; i += 4) {\n        __m128i idx = _mm_loadu_si128((__m128i*)(index + i));\n        __m128i idx_32 = _mm_cvtepi16_epi32(idx);\n        \n        __m256d v = _mm256_set_pd(\n            vec[_mm_extract_epi32(idx_32, 3)],\n            vec[_mm_extract_epi32(idx_32, 2)], \n            vec[_mm_extract_epi32(idx_32, 1)],\n            vec[_mm_extract_epi32(idx_32, 0)]\n        );\n        \n        sum = _mm256_add_pd(sum, v);\n    }\n    \n    double result = _mm256_cvtsd_f64(sum) + \n                   _mm256_cvtsd_f64(_mm256_permute4x64_pd(sum, 1)) +\n                   _mm256_cvtsd_f64(_mm256_permute4x64_pd(sum, 2)) +\n                   _mm256_cvtsd_f64(_mm256_permute4x64_pd(sum, 3));\n                   \n    for (; i < length; i++) {\n        result += vec[index[i]];\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_60_AVX", "completion": "```cpp\ndouble indexed_sum_simd(const double* vec, const int16_t* index, size_t length) {\n    __m256d sum = _mm256_setzero_pd();\n    size_t i;\n    \n    for (i = 0; i + 3 < length; i += 4) {\n        __m128i idx = _mm_loadu_si128((__m128i*)(index + i));\n        __m128i idx_32 = _mm_cvtepi16_epi32(idx);\n        \n        __m256d v = _mm256_set_pd(\n            vec[_mm_extract_epi32(idx_32, 3)],\n            vec[_mm_extract_epi32(idx_32, 2)], \n            vec[_mm_extract_epi32(idx_32, 1)],\n            vec[_mm_extract_epi32(idx_32, 0)]\n        );\n        \n        sum = _mm256_add_pd(sum, v);\n    }\n    \n    double result = _mm256_cvtsd_f64(sum) + \n                    _mm256_cvtsd_f64(_mm256_permute4x64_pd(sum, 1)) +\n                    _mm256_cvtsd_f64(_mm256_permute4x64_pd(sum, 2)) +\n                    _mm256_cvtsd_f64(_mm256_permute4x64_pd(sum, 3));\n                    \n    for (; i < length; i++) {\n        result += vec[index[i]];\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_60_AVX", "completion": "```cpp\ndouble indexed_sum_simd(const double* vec, const int16_t* index, size_t length) {\n    __m256d sum = _mm256_setzero_pd();\n    size_t i;\n    \n    for (i = 0; i + 3 < length; i += 4) {\n        __m128i idx = _mm_loadu_si128((__m128i*)(index + i));\n        __m128i idx_32 = _mm_cvtepi16_epi32(idx);\n        \n        __m256d vec_elements = _mm256_set_pd(\n            vec[_mm_extract_epi32(idx_32, 3)],\n            vec[_mm_extract_epi32(idx_32, 2)], \n            vec[_mm_extract_epi32(idx_32, 1)],\n            vec[_mm_extract_epi32(idx_32, 0)]\n        );\n        \n        sum = _mm256_add_pd(sum, vec_elements);\n    }\n    \n    double result = _mm256_reduce_add_pd(sum);\n    \n    for (; i < length; i++) {\n        result += vec[index[i]];\n    }\n    \n    return result;\n}\n\nstatic inline double _mm256_reduce_add_pd(__m256d v) {\n    __m128d sum_high = _mm256_extractf128_pd(v, 1);\n    __m128d sum_low = _mm256_castpd256_pd128(v);\n    __m128d sum = _mm_add_pd(sum_high, sum_low);\n    __m128d high64 = _mm_unpackhi_pd(sum, sum);\n    return _mm_cvtsd_f64(_mm_add_sd(sum, high64));\n}\n```"}
{"task_id": "SimdBench_60_AVX", "completion": "```cpp\ndouble indexed_sum_simd(const double* vec, const int16_t* index, size_t length) {\n    __m256d sum = _mm256_setzero_pd();\n    size_t i;\n    \n    for (i = 0; i + 3 < length; i += 4) {\n        __m128i idx = _mm_loadu_si128((__m128i*)(index + i));\n        __m128i idx_32 = _mm_cvtepi16_epi32(idx);\n        \n        __m256d v = _mm256_set_pd(\n            vec[_mm_extract_epi32(idx_32, 3)],\n            vec[_mm_extract_epi32(idx_32, 2)], \n            vec[_mm_extract_epi32(idx_32, 1)],\n            vec[_mm_extract_epi32(idx_32, 0)]\n        );\n        \n        sum = _mm256_add_pd(sum, v);\n    }\n    \n    double result = _mm256_cvtsd_f64(sum) + \n                   _mm256_cvtsd_f64(_mm256_permute4x64_pd(sum, 1)) +\n                   _mm256_cvtsd_f64(_mm256_permute4x64_pd(sum, 2)) +\n                   _mm256_cvtsd_f64(_mm256_permute4x64_pd(sum, 3));\n                   \n    for (; i < length; i++) {\n        result += vec[index[i]];\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_61_AVX", "completion": "```cpp\nvoid simple_conv2d_simd(const double* input, const double* kernel, double* output, size_t input_size, size_t kernel_size) {\n    size_t output_size = input_size - kernel_size + 1;\n    __m256d zero = _mm256_setzero_pd();\n\n    for (size_t i = 0; i < output_size; i++) {\n        for (size_t j = 0; j < output_size; j++) {\n            __m256d sum = _mm256_setzero_pd();\n            \n            for (size_t ki = 0; ki < kernel_size; ki++) {\n                size_t input_row = i + ki;\n                \n                for (size_t kj = 0; kj < kernel_size; kj += 4) {\n                    size_t input_col = j + kj;\n                    size_t kernel_idx = ki * kernel_size + kj;\n                    size_t input_idx = input_row * input_size + input_col;\n                    \n                    if (kj + 4 <= kernel_size) {\n                        __m256d input_vec = _mm256_loadu_pd(&input[input_idx]);\n                        __m256d kernel_vec = _mm256_loadu_pd(&kernel[kernel_idx]);\n                        __m256d mul = _mm256_mul_pd(input_vec, kernel_vec);\n                        sum = _mm256_add_pd(sum, mul);\n                    } else {\n                        for (size_t k = kj; k < kernel_size; k++) {\n                            double val = input[input_row * input_size + j + k] * \n                                       kernel[ki * kernel_size + k];\n                            sum = _mm256_add_pd(sum, _mm256_set1_pd(val));\n                        }\n                    }\n                }\n            }\n            \n            double final_sum = 0.0;\n            double temp[4];\n            _mm256_storeu_pd(temp, sum);\n            \n            for (int k = 0; k < 4; k++) {\n                final_sum += temp[k];\n            }\n            \n            // ReLU activation\n            __m256d result = _mm256_max_pd(_mm256_set1_pd(final_sum), zero);\n            output[i * output_size + j] = ((double*)&result)[0];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_61_AVX", "completion": "```cpp\nvoid simple_conv2d_simd(const double* input, const double* kernel, double* output, size_t input_size, size_t kernel_size) {\n    size_t output_size = input_size - kernel_size + 1;\n    __m256d zero = _mm256_setzero_pd();\n\n    for (size_t i = 0; i < output_size; i++) {\n        for (size_t j = 0; j < output_size; j += 4) {\n            __m256d sum = _mm256_setzero_pd();\n            \n            for (size_t ki = 0; ki < kernel_size; ki++) {\n                for (size_t kj = 0; kj < kernel_size; kj++) {\n                    size_t input_idx = (i + ki) * input_size + j + kj;\n                    __m256d input_vec = _mm256_loadu_pd(&input[input_idx]);\n                    __m256d kernel_val = _mm256_set1_pd(kernel[ki * kernel_size + kj]);\n                    sum = _mm256_add_pd(sum, _mm256_mul_pd(input_vec, kernel_val));\n                }\n            }\n            \n            // ReLU activation\n            sum = _mm256_max_pd(sum, zero);\n            \n            if (j + 4 <= output_size) {\n                _mm256_storeu_pd(&output[i * output_size + j], sum);\n            } else {\n                // Handle edge case when output_size is not multiple of 4\n                double temp[4];\n                _mm256_storeu_pd(temp, sum);\n                for (size_t k = 0; k < output_size - j; k++) {\n                    output[i * output_size + j + k] = temp[k];\n                }\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_61_AVX", "completion": "```cpp\nvoid simple_conv2d_simd(const double* input, const double* kernel, double* output, size_t input_size, size_t kernel_size) {\n    size_t output_size = input_size - kernel_size + 1;\n    \n    for(size_t i = 0; i < output_size; i++) {\n        for(size_t j = 0; j < output_size; j += 4) {\n            __m256d sum = _mm256_setzero_pd();\n            \n            for(size_t ki = 0; ki < kernel_size; ki++) {\n                for(size_t kj = 0; kj < kernel_size; kj++) {\n                    size_t input_idx = (i + ki) * input_size + j + kj;\n                    __m256d input_vec = _mm256_loadu_pd(&input[input_idx]);\n                    __m256d kernel_val = _mm256_set1_pd(kernel[ki * kernel_size + kj]);\n                    sum = _mm256_add_pd(sum, _mm256_mul_pd(input_vec, kernel_val));\n                }\n            }\n            \n            // ReLU activation\n            __m256d zeros = _mm256_setzero_pd();\n            sum = _mm256_max_pd(sum, zeros);\n            \n            // Store result\n            if(j + 4 <= output_size) {\n                _mm256_storeu_pd(&output[i * output_size + j], sum);\n            }\n            else {\n                // Handle edge case\n                double temp[4];\n                _mm256_storeu_pd(temp, sum);\n                for(size_t k = 0; k < output_size - j; k++) {\n                    output[i * output_size + j + k] = temp[k];\n                }\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_61_AVX", "completion": "```cpp\nvoid simple_conv2d_simd(const double* input, const double* kernel, double* output, size_t input_size, size_t kernel_size) {\n    size_t output_size = input_size - kernel_size + 1;\n    __m256d zero = _mm256_setzero_pd();\n\n    for (size_t i = 0; i < output_size; i++) {\n        for (size_t j = 0; j < output_size; j += 4) {\n            __m256d sum = _mm256_setzero_pd();\n            \n            for (size_t ki = 0; ki < kernel_size; ki++) {\n                for (size_t kj = 0; kj < kernel_size; kj++) {\n                    size_t input_idx = (i + ki) * input_size + j + kj;\n                    __m256d input_vec = _mm256_loadu_pd(&input[input_idx]);\n                    __m256d kernel_val = _mm256_set1_pd(kernel[ki * kernel_size + kj]);\n                    sum = _mm256_add_pd(sum, _mm256_mul_pd(input_vec, kernel_val));\n                }\n            }\n            \n            // ReLU activation\n            sum = _mm256_max_pd(sum, zero);\n            \n            // Store result\n            if (j + 4 <= output_size) {\n                _mm256_storeu_pd(&output[i * output_size + j], sum);\n            }\n            else {\n                // Handle edge case\n                double temp[4];\n                _mm256_storeu_pd(temp, sum);\n                for (size_t k = 0; k < output_size - j; k++) {\n                    output[i * output_size + j + k] = temp[k];\n                }\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_61_AVX", "completion": "```cpp\nvoid simple_conv2d_simd(const double* input, const double* kernel, double* output, size_t input_size, size_t kernel_size) {\n    size_t output_size = input_size - kernel_size + 1;\n    __m256d zero = _mm256_setzero_pd();\n\n    for (size_t i = 0; i < output_size; i++) {\n        for (size_t j = 0; j < output_size; j += 4) {\n            __m256d sum = _mm256_setzero_pd();\n            \n            for (size_t ki = 0; ki < kernel_size; ki++) {\n                for (size_t kj = 0; kj < kernel_size; kj++) {\n                    size_t input_idx = (i + ki) * input_size + j + kj;\n                    __m256d input_vec = _mm256_loadu_pd(&input[input_idx]);\n                    __m256d kernel_val = _mm256_set1_pd(kernel[ki * kernel_size + kj]);\n                    sum = _mm256_add_pd(sum, _mm256_mul_pd(input_vec, kernel_val));\n                }\n            }\n            \n            // ReLU activation\n            sum = _mm256_max_pd(sum, zero);\n            \n            // Store result\n            if (j + 4 <= output_size) {\n                _mm256_storeu_pd(&output[i * output_size + j], sum);\n            }\n            else {\n                // Handle edge case\n                double result[4];\n                _mm256_storeu_pd(result, sum);\n                for (size_t k = 0; k < output_size - j; k++) {\n                    output[i * output_size + j + k] = result[k];\n                }\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_62_AVX", "completion": "```cpp\nbool has_close_elements_simd(const std::vector<double>& numbers, double threshold) {\n    if (numbers.size() < 2) return false;\n\n    const int n = numbers.size();\n    const __m256d thresh = _mm256_set1_pd(threshold);\n\n    for (int i = 0; i < n - 1; i++) {\n        const __m256d v1 = _mm256_set1_pd(numbers[i]);\n        \n        for (int j = i + 1; j < n; j += 4) {\n            int remaining = n - j;\n            if (remaining < 4) {\n                // Handle remaining elements sequentially\n                for (int k = j; k < n; k++) {\n                    if (std::abs(numbers[i] - numbers[k]) < threshold) {\n                        return true;\n                    }\n                }\n                break;\n            }\n\n            __m256d v2 = _mm256_loadu_pd(&numbers[j]);\n            __m256d diff = _mm256_sub_pd(v1, v2);\n            __m256d abs_diff = _mm256_and_pd(diff, _mm256_set1_pd(-0.0));\n            __m256d cmp = _mm256_cmp_pd(abs_diff, thresh, _CMP_LT_OQ);\n            \n            int mask = _mm256_movemask_pd(cmp);\n            if (mask != 0) {\n                return true;\n            }\n        }\n    }\n    \n    return false;\n}\n```"}
{"task_id": "SimdBench_62_AVX", "completion": "```cpp\nbool has_close_elements_simd(const std::vector<double>& numbers, double threshold) {\n    if (numbers.size() < 2) return false;\n\n    const int vectorSize = 4;\n    const size_t n = numbers.size();\n    const size_t alignedSize = n & ~(vectorSize - 1);\n\n    __m256d thresholdVec = _mm256_set1_pd(threshold);\n\n    for (size_t i = 0; i < n - 1; i++) {\n        __m256d v1 = _mm256_set1_pd(numbers[i]);\n        \n        size_t j;\n        for (j = i + 1; j + vectorSize <= n; j += vectorSize) {\n            __m256d v2 = _mm256_loadu_pd(&numbers[j]);\n            __m256d diff = _mm256_sub_pd(v1, v2);\n            __m256d absDiff = _mm256_andnot_pd(_mm256_set1_pd(-0.0), diff);\n            __m256d cmp = _mm256_cmp_pd(absDiff, thresholdVec, _CMP_LT_OQ);\n            \n            int mask = _mm256_movemask_pd(cmp);\n            if (mask != 0) {\n                return true;\n            }\n        }\n\n        // Handle remaining elements\n        for (; j < n; j++) {\n            if (std::abs(numbers[i] - numbers[j]) < threshold) {\n                return true;\n            }\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_62_AVX", "completion": "```cpp\nbool has_close_elements_simd(const std::vector<double>& numbers, double threshold) {\n    if (numbers.size() < 2) return false;\n    \n    const size_t n = numbers.size();\n    const size_t simd_width = 4;\n    \n    __m256d threshold_v = _mm256_set1_pd(threshold);\n    \n    for (size_t i = 0; i < n-1; i++) {\n        __m256d v1 = _mm256_set1_pd(numbers[i]);\n        \n        for (size_t j = i+1; j < n; j += simd_width) {\n            size_t remaining = n - j;\n            if (remaining >= simd_width) {\n                __m256d v2 = _mm256_loadu_pd(&numbers[j]);\n                __m256d diff = _mm256_sub_pd(v1, v2);\n                __m256d abs_diff = _mm256_andnot_pd(_mm256_set1_pd(-0.0), diff);\n                __m256d cmp = _mm256_cmp_pd(abs_diff, threshold_v, _CMP_LT_OQ);\n                int mask = _mm256_movemask_pd(cmp);\n                if (mask != 0) return true;\n            }\n            else {\n                for (size_t k = j; k < n; k++) {\n                    if (std::abs(numbers[i] - numbers[k]) < threshold) {\n                        return true;\n                    }\n                }\n            }\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_62_AVX", "completion": "```cpp\nbool has_close_elements_simd(const std::vector<double>& numbers, double threshold) {\n    if (numbers.size() < 2) return false;\n    \n    const size_t n = numbers.size();\n    const size_t simd_width = 4;\n    const __m256d thresh_vec = _mm256_set1_pd(threshold);\n\n    for (size_t i = 0; i < n-1; i++) {\n        const __m256d v1 = _mm256_set1_pd(numbers[i]);\n        \n        for (size_t j = i+1; j < n; j += simd_width) {\n            size_t remaining = n - j;\n            if (remaining >= simd_width) {\n                __m256d v2 = _mm256_loadu_pd(&numbers[j]);\n                __m256d diff = _mm256_sub_pd(v1, v2);\n                __m256d abs_diff = _mm256_andnot_pd(_mm256_set1_pd(-0.0), diff);\n                __m256d cmp = _mm256_cmp_pd(abs_diff, thresh_vec, _CMP_LT_OQ);\n                \n                int mask = _mm256_movemask_pd(cmp);\n                if (mask != 0) {\n                    return true;\n                }\n            } else {\n                for (size_t k = j; k < n; k++) {\n                    if (std::abs(numbers[i] - numbers[k]) < threshold) {\n                        return true;\n                    }\n                }\n            }\n        }\n    }\n    \n    return false;\n}\n```"}
{"task_id": "SimdBench_62_AVX", "completion": "```cpp\nbool has_close_elements_simd(const std::vector<double>& numbers, double threshold) {\n    if (numbers.size() < 2) return false;\n\n    const int simd_width = 4;\n    const size_t n = numbers.size();\n    const size_t aligned_size = n & ~(simd_width-1);\n\n    __m256d threshold_vec = _mm256_set1_pd(threshold);\n\n    for (size_t i = 0; i < n-1; i++) {\n        __m256d v1 = _mm256_set1_pd(numbers[i]);\n        \n        size_t j;\n        for (j = i+1; j + simd_width <= n; j += simd_width) {\n            __m256d v2 = _mm256_loadu_pd(&numbers[j]);\n            __m256d diff = _mm256_sub_pd(v1, v2);\n            __m256d abs_diff = _mm256_andnot_pd(_mm256_set1_pd(-0.0), diff);\n            __m256d cmp = _mm256_cmp_pd(abs_diff, threshold_vec, _CMP_LT_OQ);\n            \n            int mask = _mm256_movemask_pd(cmp);\n            if (mask != 0) {\n                return true;\n            }\n        }\n\n        // Handle remaining elements\n        for (; j < n; j++) {\n            if (std::abs(numbers[i] - numbers[j]) < threshold) {\n                return true;\n            }\n        }\n    }\n    \n    return false;\n}\n```"}
{"task_id": "SimdBench_63_AVX", "completion": "```cpp\nbool below_zero_simd(std::vector<int> operations) {\n    int n = operations.size();\n    if (n == 0) return false;\n\n    // Pad vector size to multiple of 8 for AVX\n    int padded_size = ((n + 7) / 8) * 8;\n    operations.resize(padded_size, 0);\n\n    __m256i sum = _mm256_setzero_si256();\n    __m256i zero = _mm256_setzero_si256();\n\n    for (int i = 0; i < padded_size; i += 8) {\n        // Load 8 integers\n        __m256i ops = _mm256_loadu_si256((__m256i*)&operations[i]);\n        \n        // Running sum\n        sum = _mm256_add_epi32(sum, ops);\n        \n        // Compare with zero\n        __m256i mask = _mm256_cmpgt_epi32(zero, sum);\n        \n        // Check if any element is negative\n        int negative = _mm256_movemask_ps(_mm256_castsi256_ps(mask));\n        if (negative) return true;\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_63_AVX", "completion": "```cpp\nbool below_zero_simd(std::vector<int> operations) {\n    int n = operations.size();\n    if (n == 0) return false;\n\n    // Pad vector size to multiple of 8 for AVX\n    int padded_size = ((n + 7) / 8) * 8;\n    operations.resize(padded_size, 0);\n\n    __m256i sum = _mm256_setzero_si256();\n    __m256i running_min = _mm256_setzero_si256();\n\n    for (int i = 0; i < padded_size; i += 8) {\n        // Load 8 integers\n        __m256i ops = _mm256_loadu_si256((__m256i*)&operations[i]);\n        \n        // Add to running sum\n        sum = _mm256_add_epi32(sum, ops);\n        \n        // Update running minimum\n        running_min = _mm256_min_epi32(running_min, sum);\n    }\n\n    // Extract minimum values\n    int min_vals[8];\n    _mm256_storeu_si256((__m256i*)min_vals, running_min);\n\n    // Find global minimum\n    int global_min = min_vals[0];\n    for (int i = 1; i < 8; i++) {\n        global_min = std::min(global_min, min_vals[i]);\n    }\n\n    return global_min < 0;\n}\n```"}
{"task_id": "SimdBench_63_AVX", "completion": "```cpp\nbool below_zero_simd(std::vector<int> operations) {\n    int n = operations.size();\n    if (n == 0) return false;\n\n    // Pad vector size to multiple of 8 for AVX\n    int padded_size = ((n + 7) / 8) * 8;\n    operations.resize(padded_size, 0);\n\n    __m256i sum = _mm256_setzero_si256();\n    __m256i zero = _mm256_setzero_si256();\n\n    for (int i = 0; i < padded_size; i += 8) {\n        // Load 8 integers\n        __m256i ops = _mm256_loadu_si256((__m256i*)&operations[i]);\n        \n        // Add to running sum\n        sum = _mm256_add_epi32(sum, ops);\n        \n        // Compare if any element is less than 0\n        __m256i mask = _mm256_cmpgt_epi32(zero, sum);\n        \n        // Check if any comparison was true\n        int negative = _mm256_movemask_ps(_mm256_castsi256_ps(mask));\n        if (negative) {\n            return true;\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_63_AVX", "completion": "```cpp\nbool below_zero_simd(std::vector<int> operations) {\n    if (operations.empty()) {\n        return false;\n    }\n\n    const int vectorSize = 8;\n    const size_t n = operations.size();\n    const size_t alignedSize = n & ~(vectorSize - 1);\n\n    __m256i sum = _mm256_setzero_si256();\n    __m256i running = _mm256_setzero_si256();\n\n    for (size_t i = 0; i < alignedSize; i += vectorSize) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)(operations.data() + i));\n        running = _mm256_add_epi32(running, vec);\n        sum = _mm256_min_epi32(sum, running);\n    }\n\n    int minVal = INT_MAX;\n    int temp[8];\n    _mm256_storeu_si256((__m256i*)temp, sum);\n    \n    for (int i = 0; i < 8; i++) {\n        minVal = std::min(minVal, temp[i]);\n    }\n\n    int runningSum = 0;\n    for (size_t i = alignedSize; i < n; i++) {\n        runningSum += operations[i];\n        minVal = std::min(minVal, runningSum);\n    }\n\n    return minVal < 0;\n}\n```"}
{"task_id": "SimdBench_63_AVX", "completion": "```cpp\nbool below_zero_simd(std::vector<int> operations) {\n    int n = operations.size();\n    if (n == 0) return false;\n\n    // Pad vector size to multiple of 8 for AVX\n    int padded_size = ((n + 7) / 8) * 8;\n    operations.resize(padded_size, 0);\n\n    __m256i sum = _mm256_setzero_si256();\n    __m256i zero = _mm256_setzero_si256();\n\n    for (int i = 0; i < padded_size; i += 8) {\n        // Load 8 integers\n        __m256i ops = _mm256_loadu_si256((__m256i*)&operations[i]);\n        \n        // Add to running sum\n        sum = _mm256_add_epi32(sum, ops);\n        \n        // Compare if any element is less than zero\n        __m256i cmp = _mm256_cmpgt_epi32(zero, sum);\n        \n        // Check if any comparison was true\n        int mask = _mm256_movemask_ps(_mm256_castsi256_ps(cmp));\n        if (mask != 0) {\n            return true;\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_64_AVX", "completion": "```cpp\ndouble mean_absolute_deviation_simd(std::vector<double> numbers) {\n    if (numbers.empty()) return 0.0;\n    \n    size_t n = numbers.size();\n    size_t simd_size = n - (n % 4);\n    \n    // Calculate mean first\n    __m256d sum_vec = _mm256_setzero_pd();\n    size_t i;\n    \n    for (i = 0; i < simd_size; i += 4) {\n        __m256d vec = _mm256_loadu_pd(&numbers[i]);\n        sum_vec = _mm256_add_pd(sum_vec, vec);\n    }\n    \n    double sum_arr[4];\n    _mm256_storeu_pd(sum_arr, sum_vec);\n    double sum = sum_arr[0] + sum_arr[1] + sum_arr[2] + sum_arr[3];\n    \n    // Add remaining elements\n    for (; i < n; i++) {\n        sum += numbers[i];\n    }\n    \n    double mean = sum / n;\n    \n    // Calculate absolute deviations\n    __m256d mean_vec = _mm256_set1_pd(mean);\n    __m256d abs_sum = _mm256_setzero_pd();\n    \n    for (i = 0; i < simd_size; i += 4) {\n        __m256d vec = _mm256_loadu_pd(&numbers[i]);\n        __m256d diff = _mm256_sub_pd(vec, mean_vec);\n        __m256d abs_diff = _mm256_andnot_pd(_mm256_set1_pd(-0.0), diff);\n        abs_sum = _mm256_add_pd(abs_sum, abs_diff);\n    }\n    \n    _mm256_storeu_pd(sum_arr, abs_sum);\n    double abs_total = sum_arr[0] + sum_arr[1] + sum_arr[2] + sum_arr[3];\n    \n    // Add remaining elements\n    for (; i < n; i++) {\n        abs_total += std::fabs(numbers[i] - mean);\n    }\n    \n    return abs_total / n;\n}\n```"}
{"task_id": "SimdBench_64_AVX", "completion": "```cpp\ndouble mean_absolute_deviation_simd(std::vector<double> numbers) {\n    if (numbers.empty()) return 0.0;\n    \n    size_t size = numbers.size();\n    size_t simd_size = size - (size % 4);\n    \n    // Calculate mean first\n    __m256d sum_vec = _mm256_setzero_pd();\n    size_t i;\n    \n    for (i = 0; i < simd_size; i += 4) {\n        __m256d vec = _mm256_loadu_pd(&numbers[i]);\n        sum_vec = _mm256_add_pd(sum_vec, vec);\n    }\n    \n    double sum_arr[4];\n    _mm256_storeu_pd(sum_arr, sum_vec);\n    double sum = sum_arr[0] + sum_arr[1] + sum_arr[2] + sum_arr[3];\n    \n    // Add remaining elements\n    for (; i < size; i++) {\n        sum += numbers[i];\n    }\n    \n    double mean = sum / size;\n    \n    // Calculate absolute deviations\n    __m256d mean_vec = _mm256_set1_pd(mean);\n    __m256d abs_sum = _mm256_setzero_pd();\n    \n    for (i = 0; i < simd_size; i += 4) {\n        __m256d vec = _mm256_loadu_pd(&numbers[i]);\n        __m256d diff = _mm256_sub_pd(vec, mean_vec);\n        __m256d abs_diff = _mm256_andnot_pd(_mm256_set1_pd(-0.0), diff);\n        abs_sum = _mm256_add_pd(abs_sum, abs_diff);\n    }\n    \n    _mm256_storeu_pd(sum_arr, abs_sum);\n    double abs_total = sum_arr[0] + sum_arr[1] + sum_arr[2] + sum_arr[3];\n    \n    // Add remaining elements\n    for (; i < size; i++) {\n        abs_total += std::abs(numbers[i] - mean);\n    }\n    \n    return abs_total / size;\n}\n```"}
{"task_id": "SimdBench_64_AVX", "completion": "```cpp\ndouble mean_absolute_deviation_simd(std::vector<double> numbers) {\n    if (numbers.empty()) return 0.0;\n    \n    size_t size = numbers.size();\n    size_t simd_size = size - (size % 4);\n    \n    // Calculate mean first\n    __m256d sum = _mm256_setzero_pd();\n    size_t i;\n    \n    for (i = 0; i < simd_size; i += 4) {\n        __m256d vec = _mm256_loadu_pd(&numbers[i]);\n        sum = _mm256_add_pd(sum, vec);\n    }\n    \n    double total = _mm256_cvtsd_f64(sum);\n    total += _mm256_cvtsd_f64(_mm256_permute4x64_pd(sum, 1));\n    total += _mm256_cvtsd_f64(_mm256_permute4x64_pd(sum, 2)); \n    total += _mm256_cvtsd_f64(_mm256_permute4x64_pd(sum, 3));\n    \n    // Add remaining elements\n    for (; i < size; i++) {\n        total += numbers[i];\n    }\n    \n    double mean = total / size;\n    \n    // Calculate absolute deviations\n    __m256d mean_vec = _mm256_set1_pd(mean);\n    __m256d abs_sum = _mm256_setzero_pd();\n    \n    for (i = 0; i < simd_size; i += 4) {\n        __m256d vec = _mm256_loadu_pd(&numbers[i]);\n        __m256d diff = _mm256_sub_pd(vec, mean_vec);\n        __m256d abs_diff = _mm256_andnot_pd(_mm256_set1_pd(-0.0), diff);\n        abs_sum = _mm256_add_pd(abs_sum, abs_diff);\n    }\n    \n    double abs_total = _mm256_cvtsd_f64(abs_sum);\n    abs_total += _mm256_cvtsd_f64(_mm256_permute4x64_pd(abs_sum, 1));\n    abs_total += _mm256_cvtsd_f64(_mm256_permute4x64_pd(abs_sum, 2));\n    abs_total += _mm256_cvtsd_f64(_mm256_permute4x64_pd(abs_sum, 3));\n    \n    // Add remaining elements\n    for (; i < size; i++) {\n        abs_total += std::fabs(numbers[i] - mean);\n    }\n    \n    return abs_total / size;\n}\n```"}
{"task_id": "SimdBench_64_AVX", "completion": "```cpp\ndouble mean_absolute_deviation_simd(std::vector<double> numbers) {\n    if (numbers.empty()) return 0.0;\n    \n    size_t size = numbers.size();\n    size_t simd_size = size - (size % 4);\n    \n    // Calculate mean using SIMD\n    __m256d sum_vec = _mm256_setzero_pd();\n    size_t i;\n    \n    for (i = 0; i < simd_size; i += 4) {\n        __m256d vec = _mm256_loadu_pd(&numbers[i]);\n        sum_vec = _mm256_add_pd(sum_vec, vec);\n    }\n    \n    double sum_arr[4];\n    _mm256_storeu_pd(sum_arr, sum_vec);\n    double sum = sum_arr[0] + sum_arr[1] + sum_arr[2] + sum_arr[3];\n    \n    // Add remaining elements\n    for (; i < size; i++) {\n        sum += numbers[i];\n    }\n    \n    double mean = sum / size;\n    \n    // Calculate absolute deviations using SIMD\n    __m256d mean_vec = _mm256_set1_pd(mean);\n    __m256d abs_sum_vec = _mm256_setzero_pd();\n    \n    for (i = 0; i < simd_size; i += 4) {\n        __m256d vec = _mm256_loadu_pd(&numbers[i]);\n        __m256d diff = _mm256_sub_pd(vec, mean_vec);\n        __m256d abs_diff = _mm256_andnot_pd(_mm256_set1_pd(-0.0), diff);\n        abs_sum_vec = _mm256_add_pd(abs_sum_vec, abs_diff);\n    }\n    \n    _mm256_storeu_pd(sum_arr, abs_sum_vec);\n    double abs_sum = sum_arr[0] + sum_arr[1] + sum_arr[2] + sum_arr[3];\n    \n    // Add remaining elements\n    for (; i < size; i++) {\n        abs_sum += std::abs(numbers[i] - mean);\n    }\n    \n    return abs_sum / size;\n}\n```"}
{"task_id": "SimdBench_64_AVX", "completion": "```cpp\ndouble mean_absolute_deviation_simd(std::vector<double> numbers) {\n    size_t n = numbers.size();\n    if (n == 0) return 0.0;\n    \n    // Calculate mean first\n    __m256d sum = _mm256_setzero_pd();\n    size_t i;\n    \n    for (i = 0; i + 4 <= n; i += 4) {\n        __m256d vec = _mm256_loadu_pd(&numbers[i]);\n        sum = _mm256_add_pd(sum, vec);\n    }\n    \n    double temp[4];\n    _mm256_storeu_pd(temp, sum);\n    double total = temp[0] + temp[1] + temp[2] + temp[3];\n    \n    // Add remaining elements\n    for (; i < n; i++) {\n        total += numbers[i];\n    }\n    \n    double mean = total / n;\n    \n    // Calculate absolute deviations\n    __m256d mean_vec = _mm256_set1_pd(mean);\n    __m256d abs_sum = _mm256_setzero_pd();\n    \n    for (i = 0; i + 4 <= n; i += 4) {\n        __m256d vec = _mm256_loadu_pd(&numbers[i]);\n        __m256d diff = _mm256_sub_pd(vec, mean_vec);\n        // Absolute value using bitwise AND with all bits except sign bit\n        __m256d abs_diff = _mm256_and_pd(diff, _mm256_castsi256_pd(_mm256_set1_epi64x(0x7FFFFFFFFFFFFFFF)));\n        abs_sum = _mm256_add_pd(abs_sum, abs_diff);\n    }\n    \n    _mm256_storeu_pd(temp, abs_sum);\n    double abs_total = temp[0] + temp[1] + temp[2] + temp[3];\n    \n    // Add remaining elements\n    for (; i < n; i++) {\n        abs_total += std::fabs(numbers[i] - mean);\n    }\n    \n    return abs_total / n;\n}\n```"}
{"task_id": "SimdBench_65_AVX", "completion": "```cpp\nstd::vector<int> intersperse_simd(std::vector<int> numbers, int delimeter) {\n    if (numbers.empty()) {\n        return numbers;\n    }\n\n    std::vector<int> result((numbers.size() * 2) - 1);\n    \n    const int vectorSize = 8;\n    const int inputStep = 4;\n    const int outputStep = 8;\n    \n    __m256i delimiter_vec = _mm256_set1_epi32(delimeter);\n    \n    size_t i = 0;\n    size_t j = 0;\n    \n    for (; i + inputStep <= numbers.size(); i += inputStep, j += outputStep) {\n        __m128i input = _mm_loadu_si128((__m128i*)&numbers[i]);\n        __m256i expanded = _mm256_cvtepi32_epi64(input);\n        \n        __m256i shuffled = _mm256_permutevar8x32_epi32(\n            _mm256_permute2x128_si256(expanded, delimiter_vec, 0x20),\n            _mm256_setr_epi32(0, 4, 1, 5, 2, 6, 3, 7)\n        );\n        \n        _mm256_storeu_si256((__m256i*)&result[j], shuffled);\n    }\n    \n    // Handle remaining elements\n    for (; i < numbers.size(); i++) {\n        result[j++] = numbers[i];\n        if (i < numbers.size() - 1) {\n            result[j++] = delimeter;\n        }\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_65_AVX", "completion": "```cpp\nstd::vector<int> intersperse_simd(std::vector<int> numbers, int delimeter) {\n    if (numbers.empty()) return {};\n    \n    size_t input_size = numbers.size();\n    size_t output_size = input_size * 2 - 1;\n    std::vector<int> result(output_size);\n\n    // Handle first element\n    result[0] = numbers[0];\n\n    // Process 8 elements at a time using AVX2\n    __m256i delim_vec = _mm256_set1_epi32(delimeter);\n    size_t i;\n    \n    for (i = 1; i + 7 < input_size; i += 8) {\n        __m256i nums = _mm256_loadu_si256((__m256i*)&numbers[i]);\n        \n        // Store delimiters\n        _mm256_storeu_si256((__m256i*)&result[i*2-1], delim_vec);\n        \n        // Store numbers\n        size_t dest_idx = i * 2;\n        _mm256_storeu_si256((__m256i*)&result[dest_idx], nums);\n        \n        // Store delimiter after last number in this chunk\n        result[dest_idx + 8] = delimeter;\n    }\n\n    // Handle remaining elements\n    for (; i < input_size; i++) {\n        result[i*2] = numbers[i];\n        if (i*2 + 1 < output_size) {\n            result[i*2 + 1] = delimeter;\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_65_AVX", "completion": "```cpp\nstd::vector<int> intersperse_simd(std::vector<int> numbers, int delimeter) {\n    if (numbers.empty()) {\n        return numbers;\n    }\n\n    std::vector<int> result;\n    result.reserve(2 * numbers.size() - 1);\n\n    const int vectorSize = 8;\n    const int inputElements = 4;\n    int i = 0;\n\n    __m256i delim = _mm256_set1_epi32(delimeter);\n\n    for (; i + inputElements <= numbers.size(); i += inputElements) {\n        // Load 4 elements from input\n        __m128i input = _mm_loadu_si128((__m128i*)&numbers[i]);\n        \n        // Expand to 8 elements with delimeter between them\n        __m256i expanded = _mm256_set_m128i(\n            _mm_unpackhi_epi32(input, _mm_set1_epi32(delimeter)),\n            _mm_unpacklo_epi32(input, _mm_set1_epi32(delimeter))\n        );\n\n        // Store 8 elements (4 original + 4 delimeters)\n        _mm256_storeu_si256((__m256i*)&result[2*i], expanded);\n    }\n\n    // Handle remaining elements\n    for (; i < numbers.size(); i++) {\n        result.push_back(numbers[i]);\n        if (i < numbers.size() - 1) {\n            result.push_back(delimeter);\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_65_AVX", "completion": "```cpp\nstd::vector<int> intersperse_simd(std::vector<int> numbers, int delimeter) {\n    if (numbers.empty()) {\n        return numbers;\n    }\n\n    std::vector<int> result((numbers.size() * 2) - 1);\n    \n    const int vectorSize = 8;\n    __m256i delimVec = _mm256_set1_epi32(delimeter);\n    \n    size_t i = 0;\n    size_t j = 0;\n    \n    for (; i + vectorSize <= numbers.size(); i += vectorSize) {\n        __m256i numVec = _mm256_loadu_si256((__m256i*)&numbers[i]);\n        \n        // Store original numbers\n        _mm256_storeu_si256((__m256i*)&result[j], numVec);\n        \n        // Insert delimiters between numbers\n        if (i + vectorSize < numbers.size()) {\n            for (int k = 0; k < vectorSize; k++) {\n                result[j + 2*k + 1] = delimeter;\n            }\n        }\n        \n        j += vectorSize * 2;\n    }\n    \n    // Handle remaining elements\n    for (; i < numbers.size(); i++) {\n        result[j] = numbers[i];\n        if (i < numbers.size() - 1) {\n            result[j + 1] = delimeter;\n        }\n        j += 2;\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_65_AVX", "completion": "```cpp\nstd::vector<int> intersperse_simd(std::vector<int> numbers, int delimeter) {\n    if (numbers.empty()) {\n        return numbers;\n    }\n\n    std::vector<int> result;\n    result.reserve(2 * numbers.size() - 1);\n\n    const int vectorSize = 8;\n    const int inputElements = 4;\n    __m256i delimVec = _mm256_set1_epi32(delimeter);\n\n    size_t i = 0;\n    for (; i + inputElements <= numbers.size(); i += inputElements) {\n        // Load 4 input elements\n        __m128i input = _mm_loadu_si128((__m128i*)&numbers[i]);\n        \n        // Expand to 8 elements with delimiters in between\n        __m256i expanded = _mm256_set_m128i(\n            _mm_unpackhi_epi32(input, _mm_set1_epi32(delimeter)),\n            _mm_unpacklo_epi32(input, _mm_set1_epi32(delimeter))\n        );\n\n        // Store 8 elements (4 original + 4 delimiters)\n        _mm256_storeu_si256((__m256i*)&result[2*i], expanded);\n    }\n\n    // Handle remaining elements\n    for (; i < numbers.size(); i++) {\n        result.push_back(numbers[i]);\n        if (i < numbers.size() - 1) {\n            result.push_back(delimeter);\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_66_AVX", "completion": "```cpp\nstd::vector<int64_t> sum_product_simd(std::vector<int16_t> numbers) {\n    if (numbers.empty()) {\n        return {0, 1};\n    }\n\n    __m256i sum_vec = _mm256_setzero_si256();\n    __m256i prod_vec = _mm256_set1_epi16(1);\n    \n    size_t i;\n    for (i = 0; i + 15 < numbers.size(); i += 16) {\n        __m256i nums = _mm256_loadu_si256((__m256i*)(numbers.data() + i));\n        \n        // Sum\n        sum_vec = _mm256_add_epi16(sum_vec, nums);\n        \n        // Product \n        __m256i prod_low = _mm256_mullo_epi16(prod_vec, nums);\n        __m256i prod_high = _mm256_mulhi_epi16(prod_vec, nums);\n        \n        // Combine low and high parts\n        prod_vec = _mm256_unpacklo_epi16(prod_low, prod_high);\n    }\n\n    // Horizontal sum and product\n    int64_t total_sum = 0;\n    int64_t total_product = 1;\n    \n    alignas(32) int16_t sum_arr[16];\n    _mm256_store_si256((__m256i*)sum_arr, sum_vec);\n    \n    alignas(32) int32_t prod_arr[8];\n    _mm256_store_si256((__m256i*)prod_arr, prod_vec);\n\n    // Reduce sum\n    for (int j = 0; j < 16; j++) {\n        total_sum += sum_arr[j];\n    }\n    \n    // Reduce product\n    for (int j = 0; j < 8; j++) {\n        total_product *= prod_arr[j];\n    }\n\n    // Handle remaining elements\n    for (; i < numbers.size(); i++) {\n        total_sum += numbers[i];\n        total_product *= numbers[i];\n    }\n\n    return {total_sum, total_product};\n}\n```"}
{"task_id": "SimdBench_66_AVX", "completion": "```cpp\nstd::vector<int64_t> sum_product_simd(std::vector<int16_t> numbers) {\n    if (numbers.empty()) {\n        return {0, 1};\n    }\n\n    __m256i sum_vec = _mm256_setzero_si256();\n    __m256i prod_vec = _mm256_set1_epi16(1);\n    \n    size_t i;\n    for (i = 0; i + 16 <= numbers.size(); i += 16) {\n        __m256i nums = _mm256_loadu_si256((__m256i*)(numbers.data() + i));\n        \n        // Sum\n        sum_vec = _mm256_add_epi16(sum_vec, nums);\n        \n        // Product \n        __m256i prod_low = _mm256_mullo_epi16(prod_vec, nums);\n        __m256i prod_high = _mm256_mulhi_epi16(prod_vec, nums);\n        \n        // Combine low and high products\n        prod_vec = _mm256_unpacklo_epi16(prod_low, prod_high);\n    }\n\n    // Horizontal sum and product\n    int64_t total_sum = 0;\n    int64_t total_product = 1;\n    \n    alignas(32) int16_t sum_arr[16];\n    _mm256_store_si256((__m256i*)sum_arr, sum_vec);\n    \n    alignas(32) int32_t prod_arr[8];\n    _mm256_store_si256((__m256i*)prod_arr, prod_vec);\n    \n    for (int j = 0; j < 16; j++) {\n        total_sum += sum_arr[j];\n    }\n    \n    for (int j = 0; j < 8; j++) {\n        total_product *= prod_arr[j];\n    }\n    \n    // Handle remaining elements\n    for (; i < numbers.size(); i++) {\n        total_sum += numbers[i];\n        total_product *= numbers[i];\n    }\n    \n    return {total_sum, total_product};\n}\n```"}
{"task_id": "SimdBench_66_AVX", "completion": "```cpp\nstd::vector<int64_t> sum_product_simd(std::vector<int16_t> numbers) {\n    if (numbers.empty()) {\n        return {0, 1};\n    }\n\n    __m256i sum_vec = _mm256_setzero_si256();\n    __m256i prod_vec = _mm256_set1_epi16(1);\n    \n    size_t i;\n    for (i = 0; i + 15 < numbers.size(); i += 16) {\n        __m256i nums = _mm256_loadu_si256((__m256i*)(numbers.data() + i));\n        \n        // Sum\n        sum_vec = _mm256_add_epi16(sum_vec, nums);\n        \n        // Product \n        __m256i prod_low = _mm256_mullo_epi16(prod_vec, nums);\n        __m256i prod_high = _mm256_mulhi_epi16(prod_vec, nums);\n        \n        // Combine low and high parts\n        prod_vec = _mm256_unpacklo_epi16(prod_low, prod_high);\n    }\n\n    // Horizontal sum and product\n    int64_t total_sum = 0;\n    int64_t total_product = 1;\n    \n    alignas(32) int16_t sum_arr[16];\n    _mm256_store_si256((__m256i*)sum_arr, sum_vec);\n    \n    for (int j = 0; j < 16; j++) {\n        total_sum += sum_arr[j];\n    }\n    \n    alignas(32) int32_t prod_arr[8];\n    _mm256_store_si256((__m256i*)prod_arr, prod_vec);\n    \n    for (int j = 0; j < 8; j++) {\n        total_product *= prod_arr[j];\n    }\n\n    // Handle remaining elements\n    for (; i < numbers.size(); i++) {\n        total_sum += numbers[i];\n        total_product *= numbers[i];\n    }\n\n    return {total_sum, total_product};\n}\n```"}
{"task_id": "SimdBench_66_AVX", "completion": "```cpp\nstd::vector<int64_t> sum_product_simd(std::vector<int16_t> numbers) {\n    if (numbers.empty()) {\n        return {0, 1};\n    }\n\n    __m256i sum_vec = _mm256_setzero_si256();\n    __m256i prod_vec = _mm256_set1_epi16(1);\n    \n    size_t i;\n    for (i = 0; i + 16 <= numbers.size(); i += 16) {\n        __m256i nums = _mm256_loadu_si256((__m256i*)(numbers.data() + i));\n        \n        // Sum\n        sum_vec = _mm256_add_epi16(sum_vec, nums);\n        \n        // Product \n        __m256i prod_low = _mm256_mullo_epi16(prod_vec, nums);\n        __m256i prod_high = _mm256_mulhi_epi16(prod_vec, nums);\n        \n        // Combine low and high parts\n        prod_vec = _mm256_unpacklo_epi16(prod_low, prod_high);\n    }\n\n    // Horizontal sum and product\n    int16_t sum = 0;\n    int64_t product = 1;\n    \n    alignas(32) int16_t sum_arr[16];\n    _mm256_store_si256((__m256i*)sum_arr, sum_vec);\n    \n    alignas(32) int32_t prod_arr[8];\n    _mm256_store_si256((__m256i*)prod_arr, prod_vec);\n\n    for (int j = 0; j < 16; j++) {\n        sum += sum_arr[j];\n    }\n    \n    for (int j = 0; j < 8; j++) {\n        product *= prod_arr[j];\n    }\n\n    // Handle remaining elements\n    for (; i < numbers.size(); i++) {\n        sum += numbers[i];\n        product *= numbers[i];\n    }\n\n    return {static_cast<int64_t>(sum), product};\n}\n```"}
{"task_id": "SimdBench_66_AVX", "completion": "```cpp\nstd::vector<int64_t> sum_product_simd(std::vector<int16_t> numbers) {\n    if (numbers.empty()) {\n        return {0, 1};\n    }\n\n    __m256i sum_vec = _mm256_setzero_si256();\n    __m256i prod_vec = _mm256_set1_epi16(1);\n    \n    size_t i;\n    for (i = 0; i + 15 < numbers.size(); i += 16) {\n        __m256i nums = _mm256_loadu_si256((__m256i*)(numbers.data() + i));\n        \n        // Sum\n        sum_vec = _mm256_add_epi16(sum_vec, nums);\n        \n        // Product \n        __m256i prod_low = _mm256_mullo_epi16(prod_vec, nums);\n        __m256i prod_high = _mm256_mulhi_epi16(prod_vec, nums);\n        \n        // Combine low and high 32-bits\n        __m256i prod_even = _mm256_unpacklo_epi16(prod_low, prod_high);\n        __m256i prod_odd = _mm256_unpackhi_epi16(prod_low, prod_high);\n        prod_vec = _mm256_mullo_epi32(prod_even, prod_odd);\n    }\n\n    // Horizontal sum and product\n    int64_t sum = 0;\n    int64_t product = 1;\n    \n    alignas(32) int16_t sum_array[16];\n    _mm256_store_si256((__m256i*)sum_array, sum_vec);\n    \n    alignas(32) int32_t prod_array[8];\n    _mm256_store_si256((__m256i*)prod_array, prod_vec);\n\n    for (int j = 0; j < 16; j++) {\n        sum += sum_array[j];\n    }\n    \n    for (int j = 0; j < 8; j++) {\n        product *= prod_array[j];\n    }\n\n    // Handle remaining elements\n    for (; i < numbers.size(); i++) {\n        sum += numbers[i];\n        product *= numbers[i];\n    }\n\n    return {sum, product};\n}\n```"}
{"task_id": "SimdBench_67_AVX", "completion": "```cpp\nstd::vector<int> rolling_max_simd(std::vector<int> numbers) {\n    if (numbers.empty()) return numbers;\n    \n    const size_t n = numbers.size();\n    std::vector<int> result(n);\n    result[0] = numbers[0];\n    \n    // Process 8 elements at a time using AVX2\n    const size_t simd_width = 8;\n    size_t i = 1;\n    \n    if (n >= simd_width) {\n        __m256i current_max = _mm256_set1_epi32(numbers[0]);\n        \n        for (; i + simd_width <= n; i += simd_width) {\n            __m256i vec = _mm256_loadu_si256((__m256i*)&numbers[i]);\n            current_max = _mm256_max_epi32(current_max, vec);\n            _mm256_storeu_si256((__m256i*)&result[i], current_max);\n        }\n    }\n    \n    // Handle remaining elements\n    int current_max = result[i-1];\n    for (; i < n; i++) {\n        current_max = std::max(current_max, numbers[i]);\n        result[i] = current_max;\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_67_AVX", "completion": "```cpp\nstd::vector<int> rolling_max_simd(std::vector<int> numbers) {\n    if (numbers.empty()) return numbers;\n    \n    const int n = numbers.size();\n    std::vector<int> result(n);\n    result[0] = numbers[0];\n    \n    // Process 8 elements at a time using AVX2\n    const int simd_width = 8;\n    int i = 1;\n    \n    for (; i + simd_width <= n; i += simd_width) {\n        __m256i curr = _mm256_loadu_si256((__m256i*)&numbers[i]);\n        __m256i prev = _mm256_loadu_si256((__m256i*)&result[i-1]);\n        \n        // Shift right to align with previous max\n        __m256i shifted = _mm256_alignr_epi8(\n            _mm256_permute2x128_si256(curr, curr, 0x81),\n            _mm256_permute2x128_si256(prev, prev, 0x02),\n            12\n        );\n        \n        // Compare and get max between current and previous max\n        __m256i max_val = _mm256_max_epi32(curr, shifted);\n        \n        // Store result\n        _mm256_storeu_si256((__m256i*)&result[i], max_val);\n    }\n    \n    // Handle remaining elements\n    int curr_max = result[i-1];\n    for (; i < n; i++) {\n        curr_max = std::max(curr_max, numbers[i]);\n        result[i] = curr_max;\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_67_AVX", "completion": "```cpp\nstd::vector<int> rolling_max_simd(std::vector<int> numbers) {\n    if (numbers.empty()) return numbers;\n    \n    const size_t n = numbers.size();\n    std::vector<int> result(n);\n    result[0] = numbers[0];\n    \n    // Process 8 elements at a time using AVX2\n    const size_t simd_width = 8;\n    size_t i = 1;\n    \n    if (n >= simd_width) {\n        __m256i current_max = _mm256_set1_epi32(numbers[0]);\n        \n        for (; i + simd_width <= n; i += simd_width) {\n            __m256i nums = _mm256_loadu_si256((__m256i*)(numbers.data() + i));\n            current_max = _mm256_max_epi32(current_max, nums);\n            _mm256_storeu_si256((__m256i*)(result.data() + i), current_max);\n        }\n    }\n    \n    // Handle remaining elements\n    int running_max = result[i-1];\n    for (; i < n; i++) {\n        running_max = std::max(running_max, numbers[i]);\n        result[i] = running_max;\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_67_AVX", "completion": "```cpp\nstd::vector<int> rolling_max_simd(std::vector<int> numbers) {\n    if (numbers.empty()) return numbers;\n    \n    const size_t n = numbers.size();\n    std::vector<int> result(n);\n    result[0] = numbers[0];\n\n    // Process 8 elements at a time using AVX2\n    const size_t simd_size = 8;\n    size_t i = 1;\n    \n    if (n >= simd_size) {\n        __m256i current_max = _mm256_set1_epi32(numbers[0]);\n        \n        for (; i + simd_size <= n; i += simd_size) {\n            __m256i nums = _mm256_loadu_si256((__m256i*)&numbers[i]);\n            current_max = _mm256_max_epi32(current_max, nums);\n            _mm256_storeu_si256((__m256i*)&result[i], current_max);\n        }\n    }\n\n    // Handle remaining elements\n    int current_max = result[i-1];\n    for (; i < n; i++) {\n        current_max = std::max(current_max, numbers[i]);\n        result[i] = current_max;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_67_AVX", "completion": "```cpp\nstd::vector<int> rolling_max_simd(std::vector<int> numbers) {\n    if (numbers.empty()) return numbers;\n    \n    const size_t n = numbers.size();\n    std::vector<int> result(n);\n    result[0] = numbers[0];\n    \n    // Process 8 elements at a time using AVX2\n    const size_t simd_size = 8;\n    size_t i = 1;\n    \n    if (n >= simd_size) {\n        __m256i current_max = _mm256_set1_epi32(numbers[0]);\n        \n        for (; i + simd_size <= n; i += simd_size) {\n            __m256i nums = _mm256_loadu_si256((__m256i*)(numbers.data() + i));\n            current_max = _mm256_max_epi32(current_max, nums);\n            _mm256_storeu_si256((__m256i*)(result.data() + i), current_max);\n        }\n    }\n    \n    // Handle remaining elements\n    int current_max = result[i-1];\n    for (; i < n; i++) {\n        current_max = std::max(current_max, numbers[i]);\n        result[i] = current_max;\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_68_AVX", "completion": "```cpp\nstd::string string_xor_simd(std::string a, std::string b) {\n    size_t len = a.length();\n    std::string result(len, '0');\n    \n    size_t vec_size = 32; // AVX2 processes 256 bits = 32 bytes at a time\n    size_t vec_iterations = len / vec_size;\n    \n    for(size_t i = 0; i < vec_iterations; i++) {\n        __m256i vec_a = _mm256_loadu_si256((__m256i*)&a[i * vec_size]);\n        __m256i vec_b = _mm256_loadu_si256((__m256i*)&b[i * vec_size]);\n        __m256i vec_xor = _mm256_xor_si256(vec_a, vec_b);\n        _mm256_storeu_si256((__m256i*)&result[i * vec_size], vec_xor);\n    }\n    \n    // Handle remaining characters\n    for(size_t i = vec_iterations * vec_size; i < len; i++) {\n        result[i] = (a[i] == b[i]) ? '0' : '1';\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_68_AVX", "completion": "```cpp\nstd::string string_xor_simd(std::string a, std::string b) {\n    size_t len = a.length();\n    std::string result(len, '0');\n    \n    size_t i = 0;\n    \n    // Process 32 characters at a time using AVX2\n    for (; i + 32 <= len; i += 32) {\n        __m256i vec_a = _mm256_loadu_si256((__m256i*)(a.data() + i));\n        __m256i vec_b = _mm256_loadu_si256((__m256i*)(b.data() + i));\n        \n        // XOR the vectors\n        __m256i vec_result = _mm256_xor_si256(vec_a, vec_b);\n        \n        // Store result back\n        _mm256_storeu_si256((__m256i*)(result.data() + i), vec_result);\n    }\n    \n    // Handle remaining characters\n    for (; i < len; i++) {\n        result[i] = (a[i] == b[i]) ? '0' : '1';\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_68_AVX", "completion": "```cpp\nstd::string string_xor_simd(std::string a, std::string b) {\n    size_t len = a.length();\n    std::string result(len, '0');\n    \n    size_t i = 0;\n    \n    // Process 32 characters at a time using AVX2\n    for (; i + 32 <= len; i += 32) {\n        __m256i va = _mm256_loadu_si256((__m256i*)(a.data() + i));\n        __m256i vb = _mm256_loadu_si256((__m256i*)(b.data() + i));\n        \n        // XOR the vectors\n        __m256i vxor = _mm256_xor_si256(va, vb);\n        \n        // Store result\n        _mm256_storeu_si256((__m256i*)(result.data() + i), vxor);\n    }\n    \n    // Handle remaining characters\n    for (; i < len; i++) {\n        result[i] = (a[i] == b[i]) ? '0' : '1';\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_68_AVX", "completion": "```cpp\nstd::string string_xor_simd(std::string a, std::string b) {\n    size_t len = a.length();\n    std::string result(len, '0');\n    \n    size_t vec_size = 32; // 256 bits\n    size_t vec_count = len / vec_size;\n    \n    for(size_t i = 0; i < vec_count * vec_size; i += vec_size) {\n        __m256i va = _mm256_loadu_si256((__m256i*)&a[i]);\n        __m256i vb = _mm256_loadu_si256((__m256i*)&b[i]);\n        __m256i vxor = _mm256_xor_si256(va, vb);\n        _mm256_storeu_si256((__m256i*)&result[i], vxor);\n    }\n    \n    // Handle remaining elements\n    for(size_t i = vec_count * vec_size; i < len; i++) {\n        result[i] = (a[i] == b[i]) ? '0' : '1';\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_68_AVX", "completion": "```cpp\nstd::string string_xor_simd(std::string a, std::string b) {\n    size_t len = a.length();\n    std::string result(len, '0');\n    \n    size_t i = 0;\n    \n    // Process 32 characters at a time using AVX2\n    for (; i + 32 <= len; i += 32) {\n        __m256i va = _mm256_loadu_si256((__m256i*)(a.data() + i));\n        __m256i vb = _mm256_loadu_si256((__m256i*)(b.data() + i));\n        \n        // XOR the vectors\n        __m256i vxor = _mm256_xor_si256(va, vb);\n        \n        // Store result\n        _mm256_storeu_si256((__m256i*)(result.data() + i), vxor);\n    }\n    \n    // Handle remaining characters\n    for (; i < len; i++) {\n        result[i] = (a[i] == b[i]) ? '0' : '1';\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_69_AVX", "completion": "```cpp\nstd::string longest_simd(const std::vector<std::string>& strings) {\n    if (strings.empty()) {\n        return std::string();\n    }\n\n    size_t max_len = 0;\n    size_t max_idx = 0;\n    \n    const size_t n = strings.size();\n    const size_t simd_width = 8; // Process 8 lengths at a time with AVX2\n    \n    alignas(32) int32_t lengths[8] = {0};\n    __m256i max_vec = _mm256_setzero_si256();\n    \n    for (size_t i = 0; i < n; i += simd_width) {\n        size_t remaining = std::min(simd_width, n - i);\n        \n        // Load string lengths into vector\n        for (size_t j = 0; j < remaining; j++) {\n            lengths[j] = static_cast<int32_t>(strings[i + j].length());\n        }\n        for (size_t j = remaining; j < simd_width; j++) {\n            lengths[j] = 0;\n        }\n        \n        __m256i len_vec = _mm256_load_si256(reinterpret_cast<const __m256i*>(lengths));\n        \n        // Compare lengths with current max\n        __m256i mask = _mm256_cmpgt_epi32(len_vec, max_vec);\n        \n        // Update max values where mask is true\n        max_vec = _mm256_blendv_epi8(max_vec, len_vec, mask);\n        \n        // Find index of max length in this chunk\n        for (size_t j = 0; j < remaining; j++) {\n            if (strings[i + j].length() > max_len) {\n                max_len = strings[i + j].length();\n                max_idx = i + j;\n            }\n        }\n    }\n    \n    return strings[max_idx];\n}\n```"}
{"task_id": "SimdBench_69_AVX", "completion": "```cpp\nstd::string longest_simd(const std::vector<std::string>& strings) {\n    if (strings.empty()) {\n        return std::string();\n    }\n\n    size_t max_len = 0;\n    size_t max_idx = 0;\n    \n    const size_t vec_size = 8;\n    const size_t n = strings.size();\n    const size_t vec_iterations = n / vec_size;\n    const size_t remainder = n % vec_size;\n\n    __m256i max_lengths = _mm256_setzero_si256();\n    __m256i indices = _mm256_setzero_si256();\n    __m256i increment = _mm256_set1_epi32(1);\n    __m256i curr_indices = _mm256_setr_epi32(0,1,2,3,4,5,6,7);\n\n    for (size_t i = 0; i < vec_iterations; i++) {\n        __m256i lengths = _mm256_setzero_si256();\n        for (int j = 0; j < 8; j++) {\n            size_t str_len = strings[i * vec_size + j].length();\n            lengths = _mm256_insert_epi32(lengths, str_len, j);\n        }\n\n        __m256i mask = _mm256_cmpgt_epi32(lengths, max_lengths);\n        max_lengths = _mm256_blendv_epi8(max_lengths, lengths, mask);\n        indices = _mm256_blendv_epi8(indices, curr_indices, mask);\n        curr_indices = _mm256_add_epi32(curr_indices, _mm256_set1_epi32(8));\n    }\n\n    alignas(32) int len_array[8];\n    alignas(32) int idx_array[8];\n    _mm256_store_si256((__m256i*)len_array, max_lengths);\n    _mm256_store_si256((__m256i*)idx_array, indices);\n\n    for (int i = 0; i < 8; i++) {\n        if (len_array[i] > max_len) {\n            max_len = len_array[i];\n            max_idx = idx_array[i];\n        }\n    }\n\n    for (size_t i = vec_iterations * vec_size; i < n; i++) {\n        if (strings[i].length() > max_len) {\n            max_len = strings[i].length();\n            max_idx = i;\n        }\n    }\n\n    return strings[max_idx];\n}\n```"}
{"task_id": "SimdBench_69_AVX", "completion": "```cpp\nstd::string longest_simd(const std::vector<std::string>& strings) {\n    if (strings.empty()) {\n        return std::string();\n    }\n\n    size_t max_len = 0;\n    size_t max_idx = 0;\n    \n    const size_t vec_size = 8;\n    size_t i = 0;\n    \n    for (; i + vec_size <= strings.size(); i += vec_size) {\n        __m256i lengths = _mm256_setr_epi32(\n            strings[i].length(),\n            strings[i+1].length(), \n            strings[i+2].length(),\n            strings[i+3].length(),\n            strings[i+4].length(),\n            strings[i+5].length(),\n            strings[i+6].length(),\n            strings[i+7].length()\n        );\n        \n        __m256i max_mask = _mm256_cmpeq_epi32(\n            lengths,\n            _mm256_max_epu32(lengths, _mm256_permute2x128_si256(lengths, lengths, 1))\n        );\n        \n        uint32_t mask = _mm256_movemask_ps(_mm256_castsi256_ps(max_mask));\n        \n        if (mask) {\n            int first_max = _tzcnt_u32(mask);\n            size_t curr_len = strings[i + first_max].length();\n            if (curr_len > max_len) {\n                max_len = curr_len;\n                max_idx = i + first_max;\n            }\n        }\n    }\n    \n    // Handle remaining elements\n    for (; i < strings.size(); i++) {\n        if (strings[i].length() > max_len) {\n            max_len = strings[i].length();\n            max_idx = i;\n        }\n    }\n    \n    return strings[max_idx];\n}\n```"}
{"task_id": "SimdBench_69_AVX", "completion": "```cpp\nstd::string longest_simd(const std::vector<std::string>& strings) {\n    if (strings.empty()) {\n        return std::string();\n    }\n\n    size_t max_len = 0;\n    size_t max_idx = 0;\n    \n    // Process 8 lengths at a time using AVX2\n    const size_t vec_size = strings.size();\n    const size_t vec_step = 8;\n    size_t i;\n    \n    for (i = 0; i + vec_step <= vec_size; i += vec_step) {\n        __m256i lengths = _mm256_setr_epi32(\n            strings[i].length(),\n            strings[i+1].length(), \n            strings[i+2].length(),\n            strings[i+3].length(),\n            strings[i+4].length(),\n            strings[i+5].length(),\n            strings[i+6].length(),\n            strings[i+7].length()\n        );\n        \n        // Find max of 8 lengths\n        __m256i max_vec = lengths;\n        __m256i shuffle = _mm256_shuffle_epi32(max_vec, _MM_SHUFFLE(2,3,0,1));\n        max_vec = _mm256_max_epi32(max_vec, shuffle);\n        shuffle = _mm256_shuffle_epi32(max_vec, _MM_SHUFFLE(1,0,3,2)); \n        max_vec = _mm256_max_epi32(max_vec, shuffle);\n        \n        // Extract max value\n        int max_val = _mm256_extract_epi32(max_vec, 0);\n        \n        if (max_val > max_len) {\n            // Find index of max length\n            for (size_t j = 0; j < vec_step; j++) {\n                if (strings[i+j].length() == max_val) {\n                    max_len = max_val;\n                    max_idx = i+j;\n                    break;\n                }\n            }\n        }\n    }\n    \n    // Handle remaining elements\n    for (; i < vec_size; i++) {\n        if (strings[i].length() > max_len) {\n            max_len = strings[i].length();\n            max_idx = i;\n        }\n    }\n    \n    return strings[max_idx];\n}\n```"}
{"task_id": "SimdBench_69_AVX", "completion": "```cpp\nstd::string longest_simd(const std::vector<std::string>& strings) {\n    if (strings.empty()) {\n        return std::string();\n    }\n\n    size_t max_len = 0;\n    size_t max_idx = 0;\n    \n    size_t n = strings.size();\n    size_t vec_size = 8; // Process 8 lengths at a time with AVX2\n    size_t aligned_size = n - (n % vec_size);\n\n    __m256i max_vec = _mm256_setzero_si256();\n\n    // Process 8 strings at a time\n    for (size_t i = 0; i < aligned_size; i += vec_size) {\n        __m256i len_vec = _mm256_setr_epi32(\n            strings[i].length(),\n            strings[i+1].length(), \n            strings[i+2].length(),\n            strings[i+3].length(),\n            strings[i+4].length(),\n            strings[i+5].length(),\n            strings[i+6].length(),\n            strings[i+7].length()\n        );\n\n        // Find max lengths\n        max_vec = _mm256_max_epi32(max_vec, len_vec);\n        \n        // Extract max length and index\n        alignas(32) int lengths[8];\n        _mm256_store_si256((__m256i*)lengths, max_vec);\n        \n        for (size_t j = 0; j < 8; j++) {\n            if (lengths[j] > max_len) {\n                max_len = lengths[j];\n                max_idx = i + j;\n            }\n        }\n    }\n\n    // Handle remaining elements\n    for (size_t i = aligned_size; i < n; i++) {\n        if (strings[i].length() > max_len) {\n            max_len = strings[i].length();\n            max_idx = i;\n        }\n    }\n\n    return strings[max_idx];\n}\n```"}
{"task_id": "SimdBench_70_AVX", "completion": "```cpp\nuint64_t greatest_common_divisor_simd(uint64_t a, uint64_t b) {\n    __m256i va = _mm256_set1_epi64x(a);\n    __m256i vb = _mm256_set1_epi64x(b);\n    __m256i zero = _mm256_setzero_si256();\n    \n    while (1) {\n        __m256i mask = _mm256_cmpeq_epi64(vb, zero);\n        if (_mm256_movemask_epi8(mask) == -1) {\n            return _mm256_extract_epi64(va, 0);\n        }\n        \n        __m256i temp = va;\n        va = vb;\n        vb = _mm256_rem_epi64(temp, vb);\n    }\n}\n```"}
{"task_id": "SimdBench_70_AVX", "completion": "```cpp\nuint64_t greatest_common_divisor_simd(uint64_t a, uint64_t b) {\n    __m256i va = _mm256_set1_epi64x(a);\n    __m256i vb = _mm256_set1_epi64x(b);\n    __m256i zero = _mm256_setzero_si256();\n    \n    while (1) {\n        __m256i mask = _mm256_cmpgt_epi64(vb, zero);\n        if (_mm256_testz_si256(mask, mask)) {\n            return _mm256_extract_epi64(va, 0);\n        }\n        \n        __m256i temp = va;\n        va = vb;\n        vb = _mm256_rem_epi64(temp, vb);\n    }\n}\n```"}
{"task_id": "SimdBench_70_AVX", "completion": "```cpp\nuint64_t greatest_common_divisor_simd(uint64_t a, uint64_t b) {\n    __m256i va = _mm256_set1_epi64x(a);\n    __m256i vb = _mm256_set1_epi64x(b);\n    \n    while (1) {\n        __m256i zero = _mm256_setzero_si256();\n        __m256i mask = _mm256_cmpeq_epi64(vb, zero);\n        \n        if (_mm256_movemask_epi8(mask) == -1) {\n            return _mm256_extract_epi64(va, 0);\n        }\n        \n        __m256i temp = vb;\n        vb = _mm256_rem_epi64(va, vb);\n        va = temp;\n    }\n    \n    return _mm256_extract_epi64(va, 0);\n}\n```"}
{"task_id": "SimdBench_70_AVX", "completion": "```cpp\nuint64_t greatest_common_divisor_simd(uint64_t a, uint64_t b) {\n    __m256i va = _mm256_set1_epi64x(a);\n    __m256i vb = _mm256_set1_epi64x(b);\n    __m256i zero = _mm256_setzero_si256();\n    \n    while (1) {\n        __m256i mask = _mm256_cmpeq_epi64(vb, zero);\n        if (_mm256_movemask_epi8(mask) == -1) {\n            return _mm256_extract_epi64(va, 0);\n        }\n        \n        __m256i temp = va;\n        va = vb;\n        vb = _mm256_rem_epi64(temp, vb);\n    }\n}\n```"}
{"task_id": "SimdBench_70_AVX", "completion": "```cpp\nuint64_t greatest_common_divisor_simd(uint64_t a, uint64_t b) {\n    __m256i va = _mm256_set1_epi64x(a);\n    __m256i vb = _mm256_set1_epi64x(b);\n    __m256i zero = _mm256_setzero_si256();\n    \n    while (1) {\n        __m256i mask = _mm256_cmpgt_epi64(vb, zero);\n        if (_mm256_testz_si256(mask, mask)) {\n            return _mm256_extract_epi64(va, 0);\n        }\n        \n        __m256i temp = va;\n        va = vb;\n        vb = _mm256_sub_epi64(temp, _mm256_mul_epi32(_mm256_div_epi64(temp, vb), vb));\n    }\n}\n```"}
{"task_id": "SimdBench_71_AVX", "completion": "```cpp\nstd::vector<float> find_closest_elements_simd(std::vector<float> numbers) {\n    size_t n = numbers.size();\n    float min_diff = std::numeric_limits<float>::max();\n    float num1 = 0.0f, num2 = 0.0f;\n\n    // Process 8 elements at a time using AVX\n    for (size_t i = 0; i < n - 8; i += 8) {\n        __m256 vec1 = _mm256_loadu_ps(&numbers[i]);\n        \n        // Compare with next elements\n        for (size_t j = i + 1; j < n; j++) {\n            __m256 vec2 = _mm256_set1_ps(numbers[j]);\n            __m256 diff = _mm256_sub_ps(vec1, vec2);\n            __m256 abs_diff = _mm256_andnot_ps(_mm256_set1_ps(-0.0f), diff);\n            \n            float diffs[8];\n            _mm256_storeu_ps(diffs, abs_diff);\n            \n            for (int k = 0; k < 8; k++) {\n                if (i + k != j && diffs[k] < min_diff) {\n                    min_diff = diffs[k];\n                    num1 = std::min(numbers[i + k], numbers[j]);\n                    num2 = std::max(numbers[i + k], numbers[j]);\n                }\n            }\n        }\n    }\n    \n    // Handle remaining elements\n    for (size_t i = n - (n % 8); i < n; i++) {\n        for (size_t j = i + 1; j < n; j++) {\n            float diff = std::abs(numbers[i] - numbers[j]);\n            if (diff < min_diff) {\n                min_diff = diff;\n                num1 = std::min(numbers[i], numbers[j]);\n                num2 = std::max(numbers[i], numbers[j]);\n            }\n        }\n    }\n\n    return {num1, num2};\n}\n```"}
{"task_id": "SimdBench_71_AVX", "completion": "```cpp\nstd::vector<float> find_closest_elements_simd(std::vector<float> numbers) {\n    size_t n = numbers.size();\n    float min_diff = std::numeric_limits<float>::max();\n    float num1 = 0.0f, num2 = 0.0f;\n\n    for (size_t i = 0; i < n; i += 8) {\n        __m256 v1 = _mm256_loadu_ps(&numbers[i]);\n        \n        for (size_t j = i + 1; j < n; j++) {\n            __m256 v2 = _mm256_set1_ps(numbers[j]);\n            __m256 diff = _mm256_sub_ps(v1, v2);\n            __m256 abs_diff = _mm256_abs_ps(diff);\n            \n            float diffs[8];\n            _mm256_storeu_ps(diffs, abs_diff);\n            \n            size_t limit = std::min(size_t(8), n - i);\n            for (size_t k = 0; k < limit; k++) {\n                if (i + k != j && diffs[k] < min_diff) {\n                    min_diff = diffs[k];\n                    if (numbers[i + k] <= numbers[j]) {\n                        num1 = numbers[i + k];\n                        num2 = numbers[j];\n                    } else {\n                        num1 = numbers[j];\n                        num2 = numbers[i + k];\n                    }\n                }\n            }\n        }\n    }\n    \n    return {num1, num2};\n}\n```"}
{"task_id": "SimdBench_71_AVX", "completion": "```cpp\nstd::vector<float> find_closest_elements_simd(std::vector<float> numbers) {\n    size_t n = numbers.size();\n    float min_diff = std::numeric_limits<float>::max();\n    float num1 = 0.0f, num2 = 0.0f;\n\n    for (size_t i = 0; i < n; i += 8) {\n        __m256 v1 = _mm256_loadu_ps(&numbers[i]);\n        \n        for (size_t j = i + 1; j < n; j++) {\n            __m256 v2 = _mm256_set1_ps(numbers[j]);\n            __m256 diff = _mm256_sub_ps(v1, v2);\n            __m256 abs_diff = _mm256_abs_ps(diff);\n            \n            float diffs[8];\n            _mm256_storeu_ps(diffs, abs_diff);\n            \n            int limit = std::min(8, static_cast<int>(n - i));\n            for (int k = 0; k < limit; k++) {\n                if (i + k != j && diffs[k] < min_diff) {\n                    min_diff = diffs[k];\n                    if (numbers[i + k] <= numbers[j]) {\n                        num1 = numbers[i + k];\n                        num2 = numbers[j];\n                    } else {\n                        num1 = numbers[j];\n                        num2 = numbers[i + k];\n                    }\n                }\n            }\n        }\n    }\n\n    return {num1, num2};\n}\n```"}
{"task_id": "SimdBench_71_AVX", "completion": "```cpp\nstd::vector<float> find_closest_elements_simd(std::vector<float> numbers) {\n    int n = numbers.size();\n    float min_diff = std::numeric_limits<float>::max();\n    float num1 = 0.0f, num2 = 0.0f;\n\n    for (int i = 0; i < n; i += 8) {\n        __m256 v1 = _mm256_loadu_ps(&numbers[i]);\n        \n        for (int j = i; j < n; j += 8) {\n            __m256 v2 = _mm256_loadu_ps(&numbers[j]);\n            \n            for (int k = 0; k < 8; k++) {\n                float val1 = numbers[i + k];\n                if (i + k >= n) break;\n                \n                __m256 broadcast = _mm256_set1_ps(val1);\n                __m256 diff = _mm256_sub_ps(broadcast, v2);\n                __m256 abs_diff = _mm256_andnot_ps(_mm256_set1_ps(-0.0f), diff);\n                \n                float diffs[8];\n                _mm256_storeu_ps(diffs, abs_diff);\n                \n                for (int l = 0; l < 8; l++) {\n                    if (j + l >= n) break;\n                    if (i + k != j + l && diffs[l] < min_diff) {\n                        min_diff = diffs[l];\n                        if (val1 <= numbers[j + l]) {\n                            num1 = val1;\n                            num2 = numbers[j + l];\n                        } else {\n                            num1 = numbers[j + l];\n                            num2 = val1;\n                        }\n                    }\n                }\n            }\n        }\n    }\n    \n    return {num1, num2};\n}\n```"}
{"task_id": "SimdBench_71_AVX", "completion": "```cpp\nstd::vector<float> find_closest_elements_simd(std::vector<float> numbers) {\n    size_t n = numbers.size();\n    float min_diff = std::numeric_limits<float>::max();\n    float num1 = 0.0f, num2 = 0.0f;\n\n    for (size_t i = 0; i < n; i += 8) {\n        __m256 v1 = _mm256_loadu_ps(&numbers[i]);\n        \n        for (size_t j = i + 1; j < n; j++) {\n            __m256 v2 = _mm256_set1_ps(numbers[j]);\n            __m256 diff = _mm256_sub_ps(v1, v2);\n            __m256 abs_diff = _mm256_andnot_ps(_mm256_set1_ps(-0.0f), diff);\n            \n            float diffs[8];\n            _mm256_storeu_ps(diffs, abs_diff);\n            \n            size_t limit = std::min(size_t(8), n - i);\n            for (size_t k = 0; k < limit; k++) {\n                if (i + k != j && diffs[k] < min_diff) {\n                    min_diff = diffs[k];\n                    if (numbers[i + k] <= numbers[j]) {\n                        num1 = numbers[i + k];\n                        num2 = numbers[j];\n                    } else {\n                        num1 = numbers[j];\n                        num2 = numbers[i + k];\n                    }\n                }\n            }\n        }\n    }\n\n    return {num1, num2};\n}\n```"}
{"task_id": "SimdBench_72_AVX", "completion": "```cpp\nstd::vector<float> rescale_to_unit_simd(std::vector<float> numbers) {\n    size_t n = numbers.size();\n    if (n < 2) return numbers;\n\n    // Find min and max using SIMD\n    __m256 vmin = _mm256_set1_ps(numbers[0]);\n    __m256 vmax = _mm256_set1_ps(numbers[0]);\n    \n    size_t i;\n    for (i = 0; i + 8 <= n; i += 8) {\n        __m256 curr = _mm256_loadu_ps(&numbers[i]);\n        vmin = _mm256_min_ps(vmin, curr);\n        vmax = _mm256_max_ps(vmax, curr);\n    }\n\n    // Horizontal min/max\n    float min_vals[8], max_vals[8];\n    _mm256_storeu_ps(min_vals, vmin);\n    _mm256_storeu_ps(max_vals, vmax);\n    \n    float min_val = min_vals[0];\n    float max_val = max_vals[0];\n    \n    for (size_t j = 1; j < 8; j++) {\n        min_val = std::min(min_val, min_vals[j]);\n        max_val = std::max(max_val, max_vals[j]);\n    }\n\n    // Handle remaining elements\n    for (; i < n; i++) {\n        min_val = std::min(min_val, numbers[i]);\n        max_val = std::max(max_val, numbers[i]);\n    }\n\n    float range = max_val - min_val;\n    if (range == 0) return numbers;\n\n    // Scale the values using SIMD\n    __m256 vrange = _mm256_set1_ps(range);\n    __m256 vmin_val = _mm256_set1_ps(min_val);\n\n    for (i = 0; i + 8 <= n; i += 8) {\n        __m256 curr = _mm256_loadu_ps(&numbers[i]);\n        curr = _mm256_sub_ps(curr, vmin_val);\n        curr = _mm256_div_ps(curr, vrange);\n        _mm256_storeu_ps(&numbers[i], curr);\n    }\n\n    // Handle remaining elements\n    for (; i < n; i++) {\n        numbers[i] = (numbers[i] - min_val) / range;\n    }\n\n    return numbers;\n}\n```"}
{"task_id": "SimdBench_72_AVX", "completion": "```cpp\nstd::vector<float> rescale_to_unit_simd(std::vector<float> numbers) {\n    size_t size = numbers.size();\n    if (size < 2) return numbers;\n\n    // Find min and max using SIMD\n    __m256 vmin = _mm256_set1_ps(numbers[0]);\n    __m256 vmax = _mm256_set1_ps(numbers[0]);\n    \n    size_t i;\n    for (i = 0; i + 8 <= size; i += 8) {\n        __m256 curr = _mm256_loadu_ps(&numbers[i]);\n        vmin = _mm256_min_ps(vmin, curr);\n        vmax = _mm256_max_ps(vmax, curr);\n    }\n\n    // Horizontal min/max\n    float min_vals[8], max_vals[8];\n    _mm256_storeu_ps(min_vals, vmin);\n    _mm256_storeu_ps(max_vals, vmax);\n    \n    float min_val = min_vals[0];\n    float max_val = max_vals[0];\n    \n    for (size_t j = 1; j < 8; j++) {\n        min_val = std::min(min_val, min_vals[j]);\n        max_val = std::max(max_val, max_vals[j]);\n    }\n\n    // Handle remaining elements\n    for (; i < size; i++) {\n        min_val = std::min(min_val, numbers[i]);\n        max_val = std::max(max_val, numbers[i]);\n    }\n\n    float range = max_val - min_val;\n    if (range == 0) return std::vector<float>(size, 0);\n\n    // Scale the values using SIMD\n    __m256 vrange = _mm256_set1_ps(range);\n    __m256 vmin_val = _mm256_set1_ps(min_val);\n\n    for (i = 0; i + 8 <= size; i += 8) {\n        __m256 curr = _mm256_loadu_ps(&numbers[i]);\n        curr = _mm256_sub_ps(curr, vmin_val);\n        curr = _mm256_div_ps(curr, vrange);\n        _mm256_storeu_ps(&numbers[i], curr);\n    }\n\n    // Handle remaining elements\n    for (; i < size; i++) {\n        numbers[i] = (numbers[i] - min_val) / range;\n    }\n\n    return numbers;\n}\n```"}
{"task_id": "SimdBench_72_AVX", "completion": "```cpp\nstd::vector<float> rescale_to_unit_simd(std::vector<float> numbers) {\n    size_t n = numbers.size();\n    if (n < 2) return numbers;\n\n    // Find min and max using SIMD\n    __m256 vmin = _mm256_set1_ps(numbers[0]);\n    __m256 vmax = _mm256_set1_ps(numbers[0]);\n    \n    size_t i;\n    for (i = 0; i + 8 <= n; i += 8) {\n        __m256 v = _mm256_loadu_ps(&numbers[i]);\n        vmin = _mm256_min_ps(vmin, v);\n        vmax = _mm256_max_ps(vmax, v);\n    }\n\n    // Horizontal min/max\n    float min_vals[8], max_vals[8];\n    _mm256_storeu_ps(min_vals, vmin);\n    _mm256_storeu_ps(max_vals, vmax);\n    \n    float min_val = min_vals[0];\n    float max_val = max_vals[0];\n    \n    for (size_t j = 1; j < 8; j++) {\n        min_val = std::min(min_val, min_vals[j]);\n        max_val = std::max(max_val, max_vals[j]);\n    }\n\n    // Handle remaining elements\n    for (; i < n; i++) {\n        min_val = std::min(min_val, numbers[i]);\n        max_val = std::max(max_val, numbers[i]);\n    }\n\n    float range = max_val - min_val;\n    if (range == 0) return std::vector<float>(n, 0.0f);\n\n    // Scale the values using SIMD\n    __m256 vrange = _mm256_set1_ps(range);\n    __m256 vmin_val = _mm256_set1_ps(min_val);\n    \n    for (i = 0; i + 8 <= n; i += 8) {\n        __m256 v = _mm256_loadu_ps(&numbers[i]);\n        v = _mm256_sub_ps(v, vmin_val);\n        v = _mm256_div_ps(v, vrange);\n        _mm256_storeu_ps(&numbers[i], v);\n    }\n\n    // Handle remaining elements\n    for (; i < n; i++) {\n        numbers[i] = (numbers[i] - min_val) / range;\n    }\n\n    return numbers;\n}\n```"}
{"task_id": "SimdBench_72_AVX", "completion": "```cpp\nstd::vector<float> rescale_to_unit_simd(std::vector<float> numbers) {\n    size_t n = numbers.size();\n    if (n < 2) return numbers;\n\n    // Find min and max using SIMD\n    __m256 vmin = _mm256_set1_ps(numbers[0]);\n    __m256 vmax = _mm256_set1_ps(numbers[0]);\n    \n    size_t i;\n    for (i = 0; i + 8 <= n; i += 8) {\n        __m256 curr = _mm256_loadu_ps(&numbers[i]);\n        vmin = _mm256_min_ps(vmin, curr);\n        vmax = _mm256_max_ps(vmax, curr);\n    }\n\n    // Horizontal min/max\n    float min_arr[8], max_arr[8];\n    _mm256_storeu_ps(min_arr, vmin);\n    _mm256_storeu_ps(max_arr, vmax);\n    \n    float min_val = min_arr[0];\n    float max_val = max_arr[0];\n    \n    for (size_t j = 1; j < 8; j++) {\n        min_val = std::min(min_val, min_arr[j]);\n        max_val = std::max(max_val, max_arr[j]);\n    }\n\n    // Handle remaining elements\n    for (; i < n; i++) {\n        min_val = std::min(min_val, numbers[i]);\n        max_val = std::max(max_val, numbers[i]);\n    }\n\n    float range = max_val - min_val;\n    if (range == 0) return std::vector<float>(n, 0);\n\n    // Scale the values using SIMD\n    __m256 vrange = _mm256_set1_ps(range);\n    __m256 vmin_val = _mm256_set1_ps(min_val);\n\n    for (i = 0; i + 8 <= n; i += 8) {\n        __m256 curr = _mm256_loadu_ps(&numbers[i]);\n        curr = _mm256_sub_ps(curr, vmin_val);\n        curr = _mm256_div_ps(curr, vrange);\n        _mm256_storeu_ps(&numbers[i], curr);\n    }\n\n    // Handle remaining elements\n    for (; i < n; i++) {\n        numbers[i] = (numbers[i] - min_val) / range;\n    }\n\n    return numbers;\n}\n```"}
{"task_id": "SimdBench_72_AVX", "completion": "```cpp\nstd::vector<float> rescale_to_unit_simd(std::vector<float> numbers) {\n    size_t n = numbers.size();\n    if (n < 2) return numbers;\n\n    // Find min and max using SIMD\n    __m256 vmin = _mm256_set1_ps(numbers[0]);\n    __m256 vmax = _mm256_set1_ps(numbers[0]);\n    \n    size_t i;\n    for (i = 0; i + 8 <= n; i += 8) {\n        __m256 curr = _mm256_loadu_ps(&numbers[i]);\n        vmin = _mm256_min_ps(vmin, curr);\n        vmax = _mm256_max_ps(vmax, curr);\n    }\n\n    // Horizontal min/max\n    float min_vals[8], max_vals[8];\n    _mm256_storeu_ps(min_vals, vmin);\n    _mm256_storeu_ps(max_vals, vmax);\n    \n    float min_val = min_vals[0];\n    float max_val = max_vals[0];\n    \n    for (size_t j = 1; j < 8; j++) {\n        min_val = std::min(min_val, min_vals[j]);\n        max_val = std::max(max_val, max_vals[j]);\n    }\n\n    // Handle remaining elements\n    for (; i < n; i++) {\n        min_val = std::min(min_val, numbers[i]);\n        max_val = std::max(max_val, numbers[i]);\n    }\n\n    float range = max_val - min_val;\n    if (range == 0) return std::vector<float>(n, 0);\n\n    // Scale the values using SIMD\n    __m256 vrange = _mm256_set1_ps(range);\n    __m256 vmin_val = _mm256_set1_ps(min_val);\n\n    for (i = 0; i + 8 <= n; i += 8) {\n        __m256 curr = _mm256_loadu_ps(&numbers[i]);\n        curr = _mm256_sub_ps(curr, vmin_val);\n        curr = _mm256_div_ps(curr, vrange);\n        _mm256_storeu_ps(&numbers[i], curr);\n    }\n\n    // Handle remaining elements\n    for (; i < n; i++) {\n        numbers[i] = (numbers[i] - min_val) / range;\n    }\n\n    return numbers;\n}\n```"}
{"task_id": "SimdBench_73_AVX", "completion": "```cpp\nuint64_t largest_divisor_simd(uint64_t n) {\n    __m256i divisors = _mm256_setr_epi64x(n/2, n/2-1, n/2-2, n/2-3);\n    __m256i ones = _mm256_set1_epi64x(1);\n    __m256i n_vec = _mm256_set1_epi64x(n);\n    \n    for(uint64_t i = n/2; i > 0; i -= 4) {\n        __m256i rem = _mm256_rem_epi64(n_vec, divisors);\n        __m256i mask = _mm256_cmpeq_epi64(rem, _mm256_setzero_si256());\n        \n        if(_mm256_movemask_epi8(mask)) {\n            uint64_t result[4];\n            _mm256_store_si256((__m256i*)result, divisors);\n            \n            for(int j = 0; j < 4; j++) {\n                if(n % result[j] == 0) {\n                    return result[j];\n                }\n            }\n        }\n        \n        divisors = _mm256_sub_epi64(divisors, _mm256_set1_epi64x(4));\n    }\n    \n    return 1;\n}\n```"}
{"task_id": "SimdBench_73_AVX", "completion": "```cpp\nuint64_t largest_divisor_simd(uint64_t n) {\n    if (n <= 1) return 1;\n    \n    __m256i divisors = _mm256_setr_epi64x(n/2, n/2-1, n/2-2, n/2-3);\n    __m256i n_vec = _mm256_set1_epi64x(n);\n    __m256i zero = _mm256_setzero_si256();\n    \n    for (int64_t i = n/2; i > 0; i -= 4) {\n        __m256i remainder = _mm256_rem_epi64(n_vec, divisors);\n        __m256i mask = _mm256_cmpeq_epi64(remainder, zero);\n        \n        if (_mm256_movemask_epi8(mask)) {\n            uint64_t result[4];\n            _mm256_store_si256((__m256i*)result, divisors);\n            \n            for (int j = 0; j < 4; j++) {\n                if (n % result[j] == 0) {\n                    return result[j];\n                }\n            }\n        }\n        \n        divisors = _mm256_sub_epi64(divisors, _mm256_set1_epi64x(4));\n    }\n    \n    return 1;\n}\n```"}
{"task_id": "SimdBench_73_AVX", "completion": "```cpp\nuint64_t largest_divisor_simd(uint64_t n) {\n    if (n <= 1) return 1;\n    \n    __m256i divisors = _mm256_setr_epi64x(n/2, n/2-1, n/2-2, n/2-3);\n    __m256i n_vec = _mm256_set1_epi64x(n);\n    __m256i zero = _mm256_setzero_si256();\n    \n    for (int64_t i = n/2; i > 0; i -= 4) {\n        __m256i remainder = _mm256_rem_epi64(n_vec, divisors);\n        __m256i mask = _mm256_cmpeq_epi64(remainder, zero);\n        \n        if (_mm256_movemask_epi8(mask)) {\n            uint64_t result[4];\n            _mm256_store_si256((__m256i*)result, divisors);\n            \n            for (int j = 0; j < 4; j++) {\n                if (n % result[j] == 0) {\n                    return result[j];\n                }\n            }\n        }\n        \n        divisors = _mm256_sub_epi64(divisors, _mm256_set1_epi64x(4));\n    }\n    \n    return 1;\n}\n```"}
{"task_id": "SimdBench_73_AVX", "completion": "```cpp\nuint64_t largest_divisor_simd(uint64_t n) {\n    __m256i divisors = _mm256_setr_epi64x(n/2, n/2-1, n/2-2, n/2-3);\n    __m256i ones = _mm256_set1_epi64x(1);\n    __m256i n_vec = _mm256_set1_epi64x(n);\n    \n    while (1) {\n        __m256i remainders = _mm256_rem_epi64(n_vec, divisors);\n        __m256i mask = _mm256_cmpeq_epi64(remainders, _mm256_setzero_si256());\n        \n        if (_mm256_movemask_epi8(mask)) {\n            uint64_t result[4];\n            _mm256_store_si256((__m256i*)result, divisors);\n            \n            for (int i = 0; i < 4; i++) {\n                if (n % result[i] == 0) {\n                    return result[i];\n                }\n            }\n        }\n        \n        divisors = _mm256_sub_epi64(divisors, _mm256_set1_epi64x(4));\n        \n        uint64_t min_divisor[4];\n        _mm256_store_si256((__m256i*)min_divisor, divisors);\n        if (min_divisor[0] <= 1) {\n            return 1;\n        }\n    }\n    \n    return 1;\n}\n```"}
{"task_id": "SimdBench_73_AVX", "completion": "```cpp\nuint64_t largest_divisor_simd(uint64_t n) {\n    if (n <= 1) return 1;\n    \n    __m256i divisors = _mm256_setr_epi64x(n/2, n/2-1, n/2-2, n/2-3);\n    __m256i decrement = _mm256_set1_epi64x(4);\n    __m256i zeros = _mm256_setzero_si256();\n    __m256i n_vec = _mm256_set1_epi64x(n);\n    \n    while (1) {\n        __m256i remainder = _mm256_rem_epi64(n_vec, divisors);\n        __m256i mask = _mm256_cmpeq_epi64(remainder, zeros);\n        \n        if (_mm256_movemask_epi8(mask)) {\n            uint64_t result[4];\n            _mm256_store_si256((__m256i*)result, divisors);\n            \n            for (int i = 0; i < 4; i++) {\n                if (n % result[i] == 0) {\n                    return result[i];\n                }\n            }\n        }\n        \n        divisors = _mm256_sub_epi64(divisors, decrement);\n        \n        uint64_t min_divisor[4];\n        _mm256_store_si256((__m256i*)min_divisor, divisors);\n        if (min_divisor[3] <= 1) {\n            for (uint64_t i = min_divisor[0]; i > 1; i--) {\n                if (n % i == 0) {\n                    return i;\n                }\n            }\n            return 1;\n        }\n    }\n    \n    return 1;\n}\n```"}
{"task_id": "SimdBench_74_AVX", "completion": "```cpp\nstd::vector<int> factorize_simd(int n) {\n    std::vector<int> factors;\n    if (n <= 1) return factors;\n\n    // Load number into all elements of vector\n    __m256i num = _mm256_set1_epi32(n);\n    __m256i divisor = _mm256_setr_epi32(2,3,4,5,6,7,8,9);\n    __m256i increment = _mm256_set1_epi32(8);\n    __m256i one = _mm256_set1_epi32(1);\n    \n    while (n > 1) {\n        // Check divisibility for 8 numbers at once\n        __m256i quotient = _mm256_div_epi32(num, divisor);\n        __m256i product = _mm256_mullo_epi32(quotient, divisor);\n        __m256i mask = _mm256_cmpeq_epi32(product, num);\n        \n        // Get mask of which numbers divide evenly\n        int movemask = _mm256_movemask_ps(_mm256_castsi256_ps(mask));\n        \n        if (movemask) {\n            // Found a factor\n            int index = _tzcnt_u32(movemask);\n            int factor = ((int*)&divisor)[index];\n            \n            factors.push_back(factor);\n            n /= factor;\n            num = _mm256_set1_epi32(n);\n        } else {\n            // Try next batch of potential factors\n            divisor = _mm256_add_epi32(divisor, increment);\n        }\n        \n        // Early exit for prime numbers\n        if (((int*)&divisor)[0] * ((int*)&divisor)[0] > n) {\n            if (n > 1) factors.push_back(n);\n            break;\n        }\n    }\n    \n    return factors;\n}\n```"}
{"task_id": "SimdBench_74_AVX", "completion": "```cpp\nstd::vector<int> factorize_simd(int n) {\n    std::vector<int> factors;\n    if (n <= 1) return factors;\n\n    // Load number into all elements of vector\n    __m256i num = _mm256_set1_epi32(n);\n    __m256i divisor = _mm256_setr_epi32(2,3,4,5,6,7,8,9);\n    __m256i increment = _mm256_set1_epi32(8);\n    __m256i one = _mm256_set1_epi32(1);\n\n    while (n > 1) {\n        // Try dividing by 8 numbers at once\n        __m256i quotient = _mm256_div_epi32(num, divisor);\n        __m256i remainder = _mm256_sub_epi32(num, _mm256_mullo_epi32(quotient, divisor));\n        __m256i mask = _mm256_cmpeq_epi32(remainder, _mm256_setzero_si256());\n        \n        // Check if any division was successful\n        int divMask = _mm256_movemask_ps(_mm256_castsi256_ps(mask));\n        \n        if (divMask) {\n            // Find first successful division\n            int idx = __builtin_ctz(divMask);\n            int d = ((int*)&divisor)[idx];\n            \n            // Add factor and update n\n            factors.push_back(d);\n            n /= d;\n            \n            // Update vector for next iteration\n            num = _mm256_set1_epi32(n);\n        } else {\n            // Try next 8 numbers\n            divisor = _mm256_add_epi32(divisor, increment);\n        }\n        \n        // Early exit for prime numbers\n        if (((int*)&divisor)[0] * ((int*)&divisor)[0] > n) {\n            if (n > 1) factors.push_back(n);\n            break;\n        }\n    }\n\n    return factors;\n}\n```"}
{"task_id": "SimdBench_74_AVX", "completion": "```cpp\nstd::vector<int> factorize_simd(int n) {\n    std::vector<int> factors;\n    if (n <= 1) return factors;\n\n    // Load number into all elements of vector\n    __m256i num = _mm256_set1_epi32(n);\n    __m256i divisor = _mm256_setr_epi32(2, 3, 5, 7, 11, 13, 17, 19);\n    __m256i increment = _mm256_set1_epi32(1);\n    __m256i zero = _mm256_setzero_si256();\n\n    while (n > 1) {\n        // Check divisibility for 8 numbers at once\n        __m256i quotient = _mm256_div_epi32(num, divisor);\n        __m256i product = _mm256_mullo_epi32(quotient, divisor);\n        __m256i mask = _mm256_cmpeq_epi32(product, num);\n        \n        // Extract mask to check which divisors worked\n        int movemask = _mm256_movemask_ps(_mm256_castsi256_ps(mask));\n        \n        if (movemask) {\n            // At least one divisor found\n            int index = _tzcnt_u32(movemask);\n            int factor = ((int*)&divisor)[index];\n            \n            factors.push_back(factor);\n            n /= factor;\n            num = _mm256_set1_epi32(n);\n        } else {\n            // No divisors found, increment all potential divisors\n            divisor = _mm256_add_epi32(divisor, _mm256_set1_epi32(8));\n        }\n    }\n\n    return factors;\n}\n```"}
{"task_id": "SimdBench_74_AVX", "completion": "```cpp\nstd::vector<int> factorize_simd(int n) {\n    std::vector<int> factors;\n    if (n <= 1) return factors;\n\n    __m256i num = _mm256_set1_epi32(n);\n    __m256i divisor = _mm256_set_epi32(8, 7, 6, 5, 4, 3, 2, 1);\n    __m256i one = _mm256_set1_epi32(1);\n    __m256i increment = _mm256_set1_epi32(8);\n\n    while (n > 1) {\n        __m256i quotient = _mm256_div_epi32(num, divisor);\n        __m256i remainder = _mm256_sub_epi32(num, _mm256_mul_epi32(quotient, divisor));\n        __m256i mask = _mm256_cmpeq_epi32(remainder, _mm256_setzero_si256());\n        \n        int m = _mm256_movemask_ps(_mm256_castsi256_ps(mask));\n        \n        if (m) {\n            int idx = __builtin_ffs(m) - 1;\n            int d = ((int*)&divisor)[idx];\n            \n            factors.push_back(d);\n            n /= d;\n            num = _mm256_set1_epi32(n);\n        } else {\n            divisor = _mm256_add_epi32(divisor, increment);\n        }\n        \n        if (((int*)&divisor)[0] * ((int*)&divisor)[0] > n) {\n            if (n > 1) factors.push_back(n);\n            break;\n        }\n    }\n\n    return factors;\n}\n```"}
{"task_id": "SimdBench_74_AVX", "completion": "```cpp\nstd::vector<int> factorize_simd(int n) {\n    std::vector<int> factors;\n    \n    // Handle 2 as a special case\n    while (n % 2 == 0) {\n        factors.push_back(2);\n        n = n / 2;\n    }\n\n    // Create vector of 8 consecutive odd numbers starting from 3\n    __m256i increment = _mm256_set1_epi32(16);\n    __m256i current = _mm256_setr_epi32(3, 5, 7, 9, 11, 13, 15, 17);\n    __m256i num = _mm256_set1_epi32(n);\n    \n    int sqrt_n = static_cast<int>(sqrt(n));\n    \n    while (n > 1) {\n        // Check divisibility for 8 numbers in parallel\n        __m256i quotient = _mm256_div_epi32(num, current);\n        __m256i product = _mm256_mullo_epi32(quotient, current);\n        __m256i is_divisible = _mm256_cmpeq_epi32(num, product);\n        \n        int mask = _mm256_movemask_ps(_mm256_castsi256_ps(is_divisible));\n        \n        if (mask) {\n            // Find first divisible number\n            int divisor = current.m256i_i32[_tzcnt_u32(mask)];\n            \n            if (divisor > sqrt_n) {\n                factors.push_back(n);\n                break;\n            }\n            \n            factors.push_back(divisor);\n            n /= divisor;\n            num = _mm256_set1_epi32(n);\n            sqrt_n = static_cast<int>(sqrt(n));\n        } else {\n            // Move to next batch of 8 numbers\n            current = _mm256_add_epi32(current, increment);\n        }\n    }\n    \n    return factors;\n}\n```"}
{"task_id": "SimdBench_75_AVX", "completion": "```cpp\nstd::vector<float> get_positive_simd(const std::vector<float>& l) {\n    std::vector<float> result;\n    const int simd_width = 8;\n    int size = l.size();\n    int i = 0;\n\n    __m256 zero = _mm256_setzero_ps();\n\n    // Process 8 elements at a time\n    for (; i <= size - simd_width; i += simd_width) {\n        __m256 v = _mm256_loadu_ps(&l[i]);\n        __m256 mask = _mm256_cmp_ps(v, zero, _CMP_GT_OS);\n        \n        // Store positive numbers\n        float temp[8];\n        _mm256_storeu_ps(temp, _mm256_and_ps(v, mask));\n        \n        for (int j = 0; j < 8; j++) {\n            if (temp[j] > 0) {\n                result.push_back(temp[j]);\n            }\n        }\n    }\n\n    // Handle remaining elements\n    for (; i < size; i++) {\n        if (l[i] > 0) {\n            result.push_back(l[i]);\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_75_AVX", "completion": "```cpp\nstd::vector<float> get_positive_simd(const std::vector<float>& l) {\n    std::vector<float> result;\n    const int simd_width = 8;\n    int size = l.size();\n    int i = 0;\n\n    __m256 zero = _mm256_setzero_ps();\n\n    // Process 8 elements at a time\n    for (; i <= size - simd_width; i += simd_width) {\n        __m256 v = _mm256_loadu_ps(&l[i]);\n        __m256 mask = _mm256_cmp_ps(v, zero, _CMP_GT_OS);\n        \n        // Store positive numbers\n        float temp[8];\n        _mm256_storeu_ps(temp, _mm256_and_ps(v, mask));\n        \n        for (int j = 0; j < simd_width; j++) {\n            if (temp[j] > 0) {\n                result.push_back(temp[j]);\n            }\n        }\n    }\n\n    // Handle remaining elements\n    for (; i < size; i++) {\n        if (l[i] > 0) {\n            result.push_back(l[i]);\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_75_AVX", "completion": "```cpp\nstd::vector<float> get_positive_simd(const std::vector<float>& l) {\n    std::vector<float> result;\n    const int simd_width = 8;\n    int size = l.size();\n    int i = 0;\n\n    __m256 zero = _mm256_setzero_ps();\n\n    // Process 8 elements at a time\n    for (; i <= size - simd_width; i += simd_width) {\n        __m256 v = _mm256_loadu_ps(&l[i]);\n        __m256 mask = _mm256_cmp_ps(v, zero, _CMP_GT_OS);\n        \n        // Store positive numbers\n        float temp[8];\n        _mm256_storeu_ps(temp, _mm256_and_ps(v, mask));\n        \n        for (int j = 0; j < simd_width; j++) {\n            if (temp[j] > 0) {\n                result.push_back(temp[j]);\n            }\n        }\n    }\n\n    // Handle remaining elements\n    for (; i < size; i++) {\n        if (l[i] > 0) {\n            result.push_back(l[i]);\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_75_AVX", "completion": "```cpp\nstd::vector<float> get_positive_simd(const std::vector<float>& l) {\n    std::vector<float> result;\n    if (l.empty()) return result;\n\n    const int simd_width = 8;\n    int size = l.size();\n    int aligned_size = size - (size % simd_width);\n\n    __m256 zero = _mm256_setzero_ps();\n    float temp[8];\n\n    for (int i = 0; i < aligned_size; i += simd_width) {\n        __m256 vec = _mm256_loadu_ps(&l[i]);\n        __m256 mask = _mm256_cmp_ps(vec, zero, _CMP_GT_OS);\n        __m256 positive = _mm256_and_ps(vec, mask);\n        _mm256_storeu_ps(temp, positive);\n\n        for (int j = 0; j < simd_width; j++) {\n            if (temp[j] > 0) {\n                result.push_back(temp[j]);\n            }\n        }\n    }\n\n    for (int i = aligned_size; i < size; i++) {\n        if (l[i] > 0) {\n            result.push_back(l[i]);\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_75_AVX", "completion": "```cpp\nstd::vector<float> get_positive_simd(const std::vector<float>& l) {\n    std::vector<float> result;\n    const int simd_width = 8;\n    const int n = l.size();\n    int i = 0;\n\n    __m256 zero = _mm256_setzero_ps();\n\n    // Process 8 elements at a time\n    for (; i <= n - simd_width; i += simd_width) {\n        __m256 v = _mm256_loadu_ps(&l[i]);\n        __m256 mask = _mm256_cmp_ps(v, zero, _CMP_GT_OS);\n        \n        // Store positive numbers\n        float temp[8];\n        _mm256_storeu_ps(temp, _mm256_and_ps(v, mask));\n        \n        for (int j = 0; j < simd_width; j++) {\n            if (temp[j] > 0) {\n                result.push_back(temp[j]);\n            }\n        }\n    }\n\n    // Handle remaining elements\n    for (; i < n; i++) {\n        if (l[i] > 0) {\n            result.push_back(l[i]);\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_76_AVX", "completion": "```cpp\nbool is_prime_simd(int64_t n) {\n    if (n <= 1) return false;\n    if (n <= 3) return true;\n    if (n % 2 == 0 || n % 3 == 0) return false;\n\n    int64_t sqrt_n = sqrt(n);\n    \n    __m256i increment = _mm256_set1_epi64x(30);\n    __m256i divisors = _mm256_set_epi64x(29, 23, 19, 17);\n    __m256i current = _mm256_set1_epi64x(n);\n    \n    for (int64_t i = 5; i <= sqrt_n; i += 30) {\n        __m256i values = _mm256_add_epi64(_mm256_set1_epi64x(i), divisors);\n        __m256i remainders = _mm256_rem_epi64(current, values);\n        __m256i zero = _mm256_setzero_si256();\n        __m256i cmp = _mm256_cmpeq_epi64(remainders, zero);\n        \n        if (_mm256_movemask_epi8(cmp) != 0) {\n            return false;\n        }\n        \n        values = _mm256_add_epi64(values, _mm256_set_epi64x(2, 4, 2, 4));\n        remainders = _mm256_rem_epi64(current, values);\n        cmp = _mm256_cmpeq_epi64(remainders, zero);\n        \n        if (_mm256_movemask_epi8(cmp) != 0) {\n            return false;\n        }\n        \n        values = _mm256_add_epi64(values, _mm256_set_epi64x(4, 2, 4, 2));\n        remainders = _mm256_rem_epi64(current, values);\n        cmp = _mm256_cmpeq_epi64(remainders, zero);\n        \n        if (_mm256_movemask_epi8(cmp) != 0) {\n            return false;\n        }\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_76_AVX", "completion": "```cpp\nbool is_prime_simd(int64_t n) {\n    if (n <= 1) return false;\n    if (n <= 3) return true;\n    if (n % 2 == 0 || n % 3 == 0) return false;\n\n    int64_t sqrt_n = sqrt(n);\n    \n    __m256i increment = _mm256_set1_epi64x(30);\n    __m256i divisors = _mm256_set_epi64x(29, 23, 19, 17);\n    __m256i current = _mm256_set_epi64x(29, 23, 19, 17);\n    \n    while (_mm256_extract_epi64(current, 0) <= sqrt_n) {\n        __m256i remainders = _mm256_set1_epi64x(n);\n        \n        for (int i = 0; i < 4; i++) {\n            int64_t div = _mm256_extract_epi64(current, i);\n            if (div <= sqrt_n && n % div == 0) {\n                return false;\n            }\n        }\n        \n        current = _mm256_add_epi64(current, increment);\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_76_AVX", "completion": "```cpp\nbool is_prime_simd(int64_t n) {\n    if (n <= 1) return false;\n    if (n <= 3) return true;\n    if (n % 2 == 0 || n % 3 == 0) return false;\n\n    int64_t sqrt_n = sqrt(n);\n    \n    __m256i increment = _mm256_set1_epi64x(30);\n    __m256i divisors1 = _mm256_set_epi64x(29, 23, 19, 17);\n    __m256i divisors2 = _mm256_set_epi64x(31, 13, 11, 7);\n    __m256i current = _mm256_set1_epi64x(5);\n\n    while (_mm256_extract_epi64(current, 0) <= sqrt_n) {\n        __m256i quotients1 = _mm256_set1_epi64x(n);\n        __m256i quotients2 = _mm256_set1_epi64x(n);\n        \n        quotients1 = _mm256_div_epi64(quotients1, _mm256_add_epi64(current, divisors1));\n        quotients2 = _mm256_div_epi64(quotients2, _mm256_add_epi64(current, divisors2));\n        \n        __m256i remainders1 = _mm256_sub_epi64(_mm256_set1_epi64x(n), \n            _mm256_mul_epi32(quotients1, _mm256_add_epi64(current, divisors1)));\n            \n        __m256i remainders2 = _mm256_sub_epi64(_mm256_set1_epi64x(n),\n            _mm256_mul_epi32(quotients2, _mm256_add_epi64(current, divisors2)));\n\n        __m256i zero = _mm256_setzero_si256();\n        __m256i mask1 = _mm256_cmpeq_epi64(remainders1, zero);\n        __m256i mask2 = _mm256_cmpeq_epi64(remainders2, zero);\n\n        if (_mm256_movemask_epi8(mask1) || _mm256_movemask_epi8(mask2)) {\n            return false;\n        }\n\n        current = _mm256_add_epi64(current, increment);\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_76_AVX", "completion": "```cpp\nbool is_prime_simd(int64_t n) {\n    if (n <= 1) return false;\n    if (n <= 3) return true;\n    if (n % 2 == 0 || n % 3 == 0) return false;\n\n    int64_t sqrt_n = sqrt(n);\n    \n    __m256i increment = _mm256_set1_epi64x(30);\n    __m256i divisors = _mm256_set_epi64x(29, 23, 19, 17);\n    __m256i current = _mm256_set1_epi64x(n);\n    \n    for (int64_t i = 5; i <= sqrt_n; i += 30) {\n        __m256i test = _mm256_set1_epi64x(i);\n        test = _mm256_add_epi64(test, divisors);\n        \n        __m256i quotient = _mm256_div_epi64(current, test);\n        __m256i product = _mm256_mul_epi32(quotient, test);\n        __m256i remainder = _mm256_sub_epi64(current, product);\n        \n        __m256i zero = _mm256_setzero_si256();\n        __m256i cmp = _mm256_cmpeq_epi64(remainder, zero);\n        \n        int mask = _mm256_movemask_epi8(cmp);\n        if (mask) return false;\n        \n        test = _mm256_add_epi64(test, increment);\n        quotient = _mm256_div_epi64(current, test); \n        product = _mm256_mul_epi32(quotient, test);\n        remainder = _mm256_sub_epi64(current, product);\n        \n        cmp = _mm256_cmpeq_epi64(remainder, zero);\n        mask = _mm256_movemask_epi8(cmp);\n        if (mask) return false;\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_76_AVX", "completion": "```cpp\nbool is_prime_simd(int64_t n) {\n    if (n <= 1) return false;\n    if (n <= 3) return true;\n    if ((n % 2) == 0 || (n % 3) == 0) return false;\n\n    int64_t sqrt_n = (int64_t)sqrt(n);\n    \n    __m256i increment = _mm256_set1_epi64x(30);\n    __m256i divisors1 = _mm256_set_epi64x(29, 23, 19, 17);\n    __m256i divisors2 = _mm256_set_epi64x(31, 13, 11, 7);\n    __m256i num = _mm256_set1_epi64x(n);\n    __m256i i = _mm256_set1_epi64x(5);\n\n    while (_mm256_extract_epi64(i, 0) <= sqrt_n) {\n        __m256i quotient1 = _mm256_div_epi64(num, _mm256_add_epi64(i, divisors1));\n        __m256i quotient2 = _mm256_div_epi64(num, _mm256_add_epi64(i, divisors2));\n        \n        __m256i remainder1 = _mm256_sub_epi64(num, _mm256_mul_epi32(quotient1, _mm256_add_epi64(i, divisors1)));\n        __m256i remainder2 = _mm256_sub_epi64(num, _mm256_mul_epi32(quotient2, _mm256_add_epi64(i, divisors2)));\n\n        __m256i mask1 = _mm256_cmpeq_epi64(remainder1, _mm256_setzero_si256());\n        __m256i mask2 = _mm256_cmpeq_epi64(remainder2, _mm256_setzero_si256());\n\n        if (_mm256_movemask_pd(_mm256_castsi256_pd(mask1)) || \n            _mm256_movemask_pd(_mm256_castsi256_pd(mask2))) {\n            return false;\n        }\n\n        i = _mm256_add_epi64(i, increment);\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_77_AVX", "completion": "```cpp\nstd::string solve_simd(const std::string& s) {\n    std::string result = s;\n    int len = s.length();\n    bool has_letters = false;\n\n    // Process 32 characters at a time using AVX2\n    for (int i = 0; i + 32 <= len; i += 32) {\n        __m256i chars = _mm256_loadu_si256((__m256i*)(result.data() + i));\n        \n        // Check if character is a letter\n        __m256i is_upper = _mm256_and_si256(_mm256_cmpgt_epi8(chars, _mm256_set1_epi8('A' - 1)), \n                                           _mm256_cmpgt_epi8(_mm256_set1_epi8('Z' + 1), chars));\n        __m256i is_lower = _mm256_and_si256(_mm256_cmpgt_epi8(chars, _mm256_set1_epi8('a' - 1)),\n                                           _mm256_cmpgt_epi8(_mm256_set1_epi8('z' + 1), chars));\n        \n        // Convert case if it's a letter\n        __m256i to_upper = _mm256_and_si256(is_lower, _mm256_set1_epi8(0xDF));\n        __m256i to_lower = _mm256_and_si256(is_upper, _mm256_set1_epi8(0x20));\n        chars = _mm256_xor_si256(chars, _mm256_or_si256(to_upper, to_lower));\n        \n        // Store result\n        _mm256_storeu_si256((__m256i*)(result.data() + i), chars);\n        \n        // Check if any letters found\n        if (!has_letters) {\n            __m256i any_letter = _mm256_or_si256(is_upper, is_lower);\n            has_letters |= !_mm256_testz_si256(any_letter, any_letter);\n        }\n    }\n\n    // Handle remaining characters\n    for (int i = (len / 32) * 32; i < len; i++) {\n        if (isalpha(result[i])) {\n            has_letters = true;\n            result[i] ^= 32;\n        }\n    }\n\n    // If no letters found, reverse the entire string\n    if (!has_letters) {\n        int left = 0, right = len - 1;\n        while (left < right) {\n            std::swap(result[left++], result[right--]);\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_77_AVX", "completion": "```cpp\nstd::string solve_simd(const std::string& s) {\n    std::string result = s;\n    size_t len = s.length();\n    \n    bool has_letters = false;\n    \n    if (len >= 32) {\n        __m256i vec_str;\n        __m256i upper_mask = _mm256_set1_epi8(0x40);\n        __m256i lower_mask = _mm256_set1_epi8(0x60);\n        __m256i case_bit = _mm256_set1_epi8(0x20);\n        \n        for (size_t i = 0; i <= len-32; i += 32) {\n            vec_str = _mm256_loadu_si256((__m256i*)(result.data() + i));\n            \n            __m256i is_upper = _mm256_and_si256(_mm256_cmpgt_epi8(vec_str, upper_mask),\n                                               _mm256_cmpgt_epi8(lower_mask, vec_str));\n                                               \n            __m256i is_lower = _mm256_and_si256(_mm256_cmpgt_epi8(vec_str, lower_mask),\n                                               _mm256_cmpgt_epi8(_mm256_set1_epi8(0x7B), vec_str));\n                                               \n            if (_mm256_movemask_epi8(_mm256_or_si256(is_upper, is_lower))) {\n                has_letters = true;\n                vec_str = _mm256_xor_si256(vec_str, \n                         _mm256_and_si256(_mm256_or_si256(is_upper, is_lower), case_bit));\n            }\n            \n            _mm256_storeu_si256((__m256i*)(result.data() + i), vec_str);\n        }\n    }\n    \n    // Process remaining characters\n    for (size_t i = (len/32)*32; i < len; i++) {\n        if (isalpha(result[i])) {\n            has_letters = true;\n            result[i] ^= 0x20;\n        }\n    }\n    \n    // If no letters found, reverse the string\n    if (!has_letters) {\n        size_t i = 0, j = len - 1;\n        while (i < j) {\n            std::swap(result[i], result[j]);\n            i++;\n            j--;\n        }\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_77_AVX", "completion": "```cpp\nstd::string solve_simd(const std::string& s) {\n    std::string result = s;\n    size_t len = s.length();\n    bool has_letters = false;\n\n    if (len >= 32) {\n        const __m256i upper_mask = _mm256_set1_epi8(0x20);\n        const __m256i lower_bound = _mm256_set1_epi8('a');\n        const __m256i upper_bound = _mm256_set1_epi8('z');\n        const __m256i upper_bound_caps = _mm256_set1_epi8('Z');\n        const __m256i lower_bound_caps = _mm256_set1_epi8('A');\n\n        for (size_t i = 0; i <= len - 32; i += 32) {\n            __m256i chars = _mm256_loadu_si256((__m256i*)(result.data() + i));\n            \n            __m256i is_lower = _mm256_and_si256(\n                _mm256_cmpgt_epi8(chars, _mm256_sub_epi8(lower_bound, _mm256_set1_epi8(1))),\n                _mm256_cmpgt_epi8(_mm256_add_epi8(upper_bound, _mm256_set1_epi8(1)), chars)\n            );\n            \n            __m256i is_upper = _mm256_and_si256(\n                _mm256_cmpgt_epi8(chars, _mm256_sub_epi8(lower_bound_caps, _mm256_set1_epi8(1))),\n                _mm256_cmpgt_epi8(_mm256_add_epi8(upper_bound_caps, _mm256_set1_epi8(1)), chars)\n            );\n\n            __m256i is_letter = _mm256_or_si256(is_lower, is_upper);\n            \n            if (_mm256_movemask_epi8(is_letter)) {\n                has_letters = true;\n                chars = _mm256_xor_si256(chars, _mm256_and_si256(is_letter, upper_mask));\n            }\n            \n            _mm256_storeu_si256((__m256i*)(result.data() + i), chars);\n        }\n    }\n\n    // Handle remaining characters\n    for (size_t i = (len / 32) * 32; i < len; i++) {\n        if ((result[i] >= 'a' && result[i] <= 'z') || \n            (result[i] >= 'A' && result[i] <= 'Z')) {\n            has_letters = true;\n            result[i] ^= 0x20;\n        }\n    }\n\n    if (!has_letters) {\n        std::reverse(result.begin(), result.end());\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_77_AVX", "completion": "```cpp\nstd::string solve_simd(const std::string& s) {\n    std::string result = s;\n    size_t len = s.length();\n    bool has_letters = false;\n\n    if (len >= 32) {\n        size_t vec_size = len - (len % 32);\n        __m256i* vec_ptr = (__m256i*)result.data();\n        \n        for (size_t i = 0; i < vec_size; i += 32) {\n            __m256i data = _mm256_loadu_si256(vec_ptr);\n            \n            __m256i is_upper = _mm256_and_si256(_mm256_cmpgt_epi8(data, _mm256_set1_epi8('A' - 1)),\n                                               _mm256_cmpgt_epi8(_mm256_set1_epi8('Z' + 1), data));\n                                               \n            __m256i is_lower = _mm256_and_si256(_mm256_cmpgt_epi8(data, _mm256_set1_epi8('a' - 1)),\n                                               _mm256_cmpgt_epi8(_mm256_set1_epi8('z' + 1), data));\n            \n            __m256i is_letter = _mm256_or_si256(is_upper, is_lower);\n            \n            if (_mm256_movemask_epi8(is_letter)) {\n                has_letters = true;\n                \n                __m256i upper_to_lower = _mm256_and_si256(is_upper, _mm256_set1_epi8(32));\n                __m256i lower_to_upper = _mm256_and_si256(is_lower, _mm256_set1_epi8(-32));\n                \n                __m256i case_change = _mm256_or_si256(upper_to_lower, lower_to_upper);\n                data = _mm256_xor_si256(data, case_change);\n                \n                _mm256_storeu_si256(vec_ptr, data);\n            }\n            vec_ptr++;\n        }\n    }\n\n    // Handle remaining characters\n    for (size_t i = len - (len % 32); i < len; i++) {\n        if (isalpha(result[i])) {\n            has_letters = true;\n            result[i] ^= 32;\n        }\n    }\n\n    if (!has_letters) {\n        size_t i = 0, j = len - 1;\n        while (i < j) {\n            std::swap(result[i], result[j]);\n            i++;\n            j--;\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_77_AVX", "completion": "```cpp\nstd::string solve_simd(const std::string& s) {\n    std::string result = s;\n    size_t len = s.length();\n    \n    bool has_letters = false;\n    \n    if (len >= 32) {\n        const __m256i upper_mask = _mm256_set1_epi8(0x20);\n        const __m256i letter_mask_a = _mm256_set1_epi8('a' - 1);\n        const __m256i letter_mask_z = _mm256_set1_epi8('z');\n        const __m256i letter_mask_A = _mm256_set1_epi8('A' - 1);\n        const __m256i letter_mask_Z = _mm256_set1_epi8('Z');\n        \n        for (size_t i = 0; i <= len - 32; i += 32) {\n            __m256i str = _mm256_loadu_si256((__m256i*)(result.data() + i));\n            \n            __m256i is_lower = _mm256_and_si256(\n                _mm256_cmpgt_epi8(str, letter_mask_a),\n                _mm256_cmpgt_epi8(letter_mask_z, str)\n            );\n            \n            __m256i is_upper = _mm256_and_si256(\n                _mm256_cmpgt_epi8(str, letter_mask_A),\n                _mm256_cmpgt_epi8(letter_mask_Z, str)\n            );\n            \n            __m256i is_letter = _mm256_or_si256(is_lower, is_upper);\n            \n            if (_mm256_movemask_epi8(is_letter)) {\n                has_letters = true;\n                str = _mm256_xor_si256(str, _mm256_and_si256(is_letter, upper_mask));\n                _mm256_storeu_si256((__m256i*)(result.data() + i), str);\n            }\n        }\n    }\n    \n    // Process remaining characters\n    for (size_t i = (len / 32) * 32; i < len; i++) {\n        char c = result[i];\n        if (isalpha(c)) {\n            has_letters = true;\n            result[i] = (islower(c) ? toupper(c) : tolower(c));\n        }\n    }\n    \n    // If no letters found, reverse the whole string\n    if (!has_letters) {\n        size_t i = 0, j = len - 1;\n        while (i < j) {\n            std::swap(result[i], result[j]);\n            i++;\n            j--;\n        }\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_78_AVX", "completion": "```cpp\nstd::vector<int> sort_third_simd(std::vector<int> l) {\n    if (l.size() < 3) return l;\n    \n    // Create vector to store values at indices divisible by 3\n    std::vector<int> thirds;\n    for (size_t i = 0; i < l.size(); i += 3) {\n        thirds.push_back(l[i]);\n    }\n\n    // Sort the thirds vector using AVX2\n    size_t thirds_size = thirds.size();\n    size_t vec_size = (thirds_size + 7) / 8 * 8; // Round up to multiple of 8\n    thirds.resize(vec_size, INT_MAX);\n\n    for (size_t i = 0; i < thirds_size - 1; i++) {\n        for (size_t j = 0; j < thirds_size - i - 1; j += 8) {\n            __m256i v1 = _mm256_loadu_si256((__m256i*)&thirds[j]);\n            __m256i v2 = _mm256_loadu_si256((__m256i*)&thirds[j+1]);\n            \n            __m256i mask = _mm256_cmpgt_epi32(v1, v2);\n            __m256i min = _mm256_blendv_epi8(v1, v2, mask);\n            __m256i max = _mm256_blendv_epi8(v2, v1, mask);\n            \n            _mm256_storeu_si256((__m256i*)&thirds[j], min);\n            _mm256_storeu_si256((__m256i*)&thirds[j+1], max);\n        }\n    }\n\n    thirds.resize(thirds_size);\n\n    // Put sorted values back in original array at indices divisible by 3\n    size_t thirds_idx = 0;\n    for (size_t i = 0; i < l.size(); i += 3) {\n        l[i] = thirds[thirds_idx++];\n    }\n\n    return l;\n}\n```"}
{"task_id": "SimdBench_78_AVX", "completion": "```cpp\nstd::vector<int> sort_third_simd(std::vector<int> l) {\n    if (l.size() < 3) return l;\n    \n    std::vector<int> thirds;\n    for (size_t i = 0; i < l.size(); i += 3) {\n        thirds.push_back(l[i]);\n    }\n    \n    // Sort the thirds using AVX2\n    size_t thirds_size = thirds.size();\n    size_t vec_size = (thirds_size + 7) / 8 * 8; // Round up to multiple of 8\n    thirds.resize(vec_size, INT_MAX);\n    \n    for (size_t i = 0; i < thirds_size-1; i++) {\n        for (size_t j = 0; j < thirds_size-1-i; j += 8) {\n            __m256i v1 = _mm256_loadu_si256((__m256i*)&thirds[j]);\n            __m256i v2 = _mm256_loadu_si256((__m256i*)&thirds[j+1]);\n            \n            __m256i mask = _mm256_cmpgt_epi32(v1, v2);\n            __m256i min = _mm256_blendv_epi8(v1, v2, mask);\n            __m256i max = _mm256_blendv_epi8(v2, v1, mask);\n            \n            _mm256_storeu_si256((__m256i*)&thirds[j], min);\n            _mm256_storeu_si256((__m256i*)&thirds[j+1], max);\n        }\n    }\n    \n    thirds.resize(thirds_size);\n    \n    // Put sorted values back in original array\n    size_t thirds_idx = 0;\n    for (size_t i = 0; i < l.size(); i += 3) {\n        l[i] = thirds[thirds_idx++];\n    }\n    \n    return l;\n}\n```"}
{"task_id": "SimdBench_78_AVX", "completion": "```cpp\nstd::vector<int> sort_third_simd(std::vector<int> l) {\n    if (l.size() < 3) return l;\n    \n    std::vector<int> thirds;\n    for (size_t i = 0; i < l.size(); i += 3) {\n        thirds.push_back(l[i]);\n    }\n    \n    // Sort the thirds using AVX2\n    size_t n = thirds.size();\n    size_t simd_size = 8; // AVX2 processes 8 integers at a time\n    size_t aligned_size = (n + simd_size - 1) & ~(simd_size - 1);\n    \n    thirds.resize(aligned_size, INT_MAX);\n    \n    for (size_t i = 0; i < aligned_size; i += simd_size) {\n        for (size_t j = i + simd_size; j < aligned_size; j += simd_size) {\n            __m256i v1 = _mm256_loadu_si256((__m256i*)&thirds[i]);\n            __m256i v2 = _mm256_loadu_si256((__m256i*)&thirds[j]);\n            \n            __m256i min = _mm256_min_epi32(v1, v2);\n            __m256i max = _mm256_max_epi32(v1, v2);\n            \n            _mm256_storeu_si256((__m256i*)&thirds[i], min);\n            _mm256_storeu_si256((__m256i*)&thirds[j], max);\n        }\n    }\n    \n    thirds.resize(n);\n    \n    // Put sorted values back in original array\n    size_t third_idx = 0;\n    for (size_t i = 0; i < l.size(); i++) {\n        if (i % 3 == 0) {\n            l[i] = thirds[third_idx++];\n        }\n    }\n    \n    return l;\n}\n```"}
{"task_id": "SimdBench_78_AVX", "completion": "```cpp\nstd::vector<int> sort_third_simd(std::vector<int> l) {\n    if (l.size() < 3) return l;\n    \n    std::vector<int> thirds;\n    for (size_t i = 0; i < l.size(); i += 3) {\n        thirds.push_back(l[i]);\n    }\n    \n    // Sort the thirds using AVX2\n    size_t n = thirds.size();\n    size_t simd_size = (n / 8) * 8;\n    \n    for (size_t i = 0; i < n-1; i++) {\n        for (size_t j = 0; j < simd_size; j += 8) {\n            __m256i v1 = _mm256_loadu_si256((__m256i*)&thirds[j]);\n            __m256i v2 = _mm256_loadu_si256((__m256i*)&thirds[j+1]);\n            \n            __m256i min = _mm256_min_epi32(v1, v2);\n            __m256i max = _mm256_max_epi32(v1, v2);\n            \n            _mm256_storeu_si256((__m256i*)&thirds[j], min);\n            _mm256_storeu_si256((__m256i*)&thirds[j+1], max);\n        }\n        \n        // Handle remaining elements\n        for (size_t j = simd_size; j < n-1; j++) {\n            if (thirds[j] > thirds[j+1]) {\n                std::swap(thirds[j], thirds[j+1]);\n            }\n        }\n    }\n    \n    // Put sorted values back in original array\n    size_t thirds_idx = 0;\n    for (size_t i = 0; i < l.size(); i += 3) {\n        l[i] = thirds[thirds_idx++];\n    }\n    \n    return l;\n}\n```"}
{"task_id": "SimdBench_78_AVX", "completion": "```cpp\nstd::vector<int> sort_third_simd(std::vector<int> l) {\n    if (l.size() < 3) return l;\n    \n    std::vector<int> thirds;\n    for (size_t i = 0; i < l.size(); i += 3) {\n        thirds.push_back(l[i]);\n    }\n    \n    // Sort the thirds using AVX2\n    size_t n = thirds.size();\n    size_t simd_size = (n / 8) * 8;\n    \n    for (size_t i = 0; i < n-1; i++) {\n        for (size_t j = 0; j < simd_size; j += 8) {\n            __m256i v1 = _mm256_loadu_si256((__m256i*)&thirds[j]);\n            __m256i v2 = _mm256_loadu_si256((__m256i*)&thirds[j+1]);\n            \n            __m256i min = _mm256_min_epi32(v1, v2);\n            __m256i max = _mm256_max_epi32(v1, v2);\n            \n            _mm256_storeu_si256((__m256i*)&thirds[j], min);\n            _mm256_storeu_si256((__m256i*)&thirds[j+1], max);\n        }\n        \n        // Handle remaining elements\n        for (size_t j = simd_size; j < n-1; j++) {\n            if (thirds[j] > thirds[j+1]) {\n                std::swap(thirds[j], thirds[j+1]);\n            }\n        }\n    }\n    \n    // Put sorted values back in original array\n    size_t thirds_idx = 0;\n    for (size_t i = 0; i < l.size(); i += 3) {\n        l[i] = thirds[thirds_idx++];\n    }\n    \n    return l;\n}\n```"}
{"task_id": "SimdBench_79_AVX", "completion": "```cpp\nfloat max_element_simd(std::vector<float> l) {\n    size_t n = l.size();\n    size_t aligned_size = n - (n % 8);\n    \n    __m256 max_vec = _mm256_set1_ps(-INFINITY);\n    \n    for(size_t i = 0; i < aligned_size; i += 8) {\n        __m256 curr = _mm256_loadu_ps(&l[i]);\n        max_vec = _mm256_max_ps(max_vec, curr);\n    }\n    \n    float max_val = -INFINITY;\n    float temp[8];\n    _mm256_storeu_ps(temp, max_vec);\n    \n    for(int i = 0; i < 8; i++) {\n        max_val = std::max(max_val, temp[i]);\n    }\n    \n    for(size_t i = aligned_size; i < n; i++) {\n        max_val = std::max(max_val, l[i]);\n    }\n    \n    return max_val;\n}\n```"}
{"task_id": "SimdBench_79_AVX", "completion": "```cpp\nfloat max_element_simd(std::vector<float> l) {\n    size_t n = l.size();\n    size_t aligned_size = n - (n % 8);\n    \n    __m256 max_vec = _mm256_set1_ps(-INFINITY);\n    \n    for(size_t i = 0; i < aligned_size; i += 8) {\n        __m256 curr = _mm256_loadu_ps(&l[i]);\n        max_vec = _mm256_max_ps(max_vec, curr);\n    }\n    \n    float max_val = -INFINITY;\n    float temp[8];\n    _mm256_storeu_ps(temp, max_vec);\n    \n    for(int i = 0; i < 8; i++) {\n        max_val = std::max(max_val, temp[i]);\n    }\n    \n    for(size_t i = aligned_size; i < n; i++) {\n        max_val = std::max(max_val, l[i]);\n    }\n    \n    return max_val;\n}\n```"}
{"task_id": "SimdBench_79_AVX", "completion": "```cpp\nfloat max_element_simd(std::vector<float> l) {\n    size_t size = l.size();\n    size_t simd_size = size - (size % 8);\n    \n    __m256 max_vec = _mm256_set1_ps(-INFINITY);\n    \n    for(size_t i = 0; i < simd_size; i += 8) {\n        __m256 curr = _mm256_loadu_ps(&l[i]);\n        max_vec = _mm256_max_ps(max_vec, curr);\n    }\n    \n    float max_val = -INFINITY;\n    float temp[8];\n    _mm256_storeu_ps(temp, max_vec);\n    \n    for(int i = 0; i < 8; i++) {\n        max_val = std::max(max_val, temp[i]);\n    }\n    \n    for(size_t i = simd_size; i < size; i++) {\n        max_val = std::max(max_val, l[i]);\n    }\n    \n    return max_val;\n}\n```"}
{"task_id": "SimdBench_79_AVX", "completion": "```cpp\nfloat max_element_simd(std::vector<float> l) {\n    size_t n = l.size();\n    size_t aligned_size = n - (n % 8);\n    \n    __m256 max_vec = _mm256_set1_ps(-INFINITY);\n    \n    for(size_t i = 0; i < aligned_size; i += 8) {\n        __m256 curr = _mm256_loadu_ps(&l[i]);\n        max_vec = _mm256_max_ps(max_vec, curr);\n    }\n    \n    float max_val = -INFINITY;\n    float temp[8];\n    _mm256_storeu_ps(temp, max_vec);\n    \n    for(int i = 0; i < 8; i++) {\n        max_val = std::max(max_val, temp[i]);\n    }\n    \n    for(size_t i = aligned_size; i < n; i++) {\n        max_val = std::max(max_val, l[i]);\n    }\n    \n    return max_val;\n}\n```"}
{"task_id": "SimdBench_79_AVX", "completion": "```cpp\nfloat max_element_simd(std::vector<float> l) {\n    size_t size = l.size();\n    size_t aligned_size = size - (size % 8);\n    \n    __m256 max_vec = _mm256_set1_ps(-INFINITY);\n    \n    for(size_t i = 0; i < aligned_size; i += 8) {\n        __m256 curr = _mm256_loadu_ps(&l[i]);\n        max_vec = _mm256_max_ps(max_vec, curr);\n    }\n    \n    float max_val = -INFINITY;\n    float temp[8];\n    _mm256_storeu_ps(temp, max_vec);\n    \n    for(int i = 0; i < 8; i++) {\n        max_val = std::max(max_val, temp[i]);\n    }\n    \n    for(size_t i = aligned_size; i < size; i++) {\n        max_val = std::max(max_val, l[i]);\n    }\n    \n    return max_val;\n}\n```"}
{"task_id": "SimdBench_80_AVX", "completion": "```cpp\nint fizz_buzz_simd(int n) {\n    int count = 0;\n    __m256i sevens = _mm256_set1_epi32(7);\n    __m256i tens = _mm256_set1_epi32(10);\n    __m256i zeros = _mm256_setzero_si256();\n    \n    for(int i = 0; i < n; i += 8) {\n        __m256i nums = _mm256_setr_epi32(i, i+1, i+2, i+3, i+4, i+5, i+6, i+7);\n        __m256i div11 = _mm256_set1_epi32(11);\n        __m256i div13 = _mm256_set1_epi32(13);\n        \n        __m256i mod11 = _mm256_rem_epi32(nums, div11);\n        __m256i mod13 = _mm256_rem_epi32(nums, div13);\n        \n        __m256i is_div = _mm256_or_si256(\n            _mm256_cmpeq_epi32(mod11, zeros),\n            _mm256_cmpeq_epi32(mod13, zeros)\n        );\n        \n        int mask = _mm256_movemask_ps(_mm256_castsi256_ps(is_div));\n        \n        for(int j = 0; j < 8; j++) {\n            if((mask & (1 << j)) && (i + j) < n) {\n                int num = i + j;\n                while(num > 0) {\n                    if(num % 10 == 7) count++;\n                    num /= 10;\n                }\n            }\n        }\n    }\n    \n    return count;\n}\n```"}
{"task_id": "SimdBench_80_AVX", "completion": "```cpp\nint fizz_buzz_simd(int n) {\n    int count = 0;\n    __m256i sevens = _mm256_set1_epi32(7);\n    __m256i tens = _mm256_set1_epi32(10);\n    __m256i zeros = _mm256_setzero_si256();\n    \n    for(int i = 0; i < n; i += 8) {\n        __m256i nums = _mm256_setr_epi32(i, i+1, i+2, i+3, i+4, i+5, i+6, i+7);\n        __m256i div11 = _mm256_set1_epi32(11);\n        __m256i div13 = _mm256_set1_epi32(13);\n        \n        __m256i mod11 = _mm256_rem_epi32(nums, div11);\n        __m256i mod13 = _mm256_rem_epi32(nums, div13);\n        \n        __m256i is_div = _mm256_or_si256(\n            _mm256_cmpeq_epi32(mod11, zeros),\n            _mm256_cmpeq_epi32(mod13, zeros)\n        );\n        \n        int mask = _mm256_movemask_ps(_mm256_castsi256_ps(is_div));\n        \n        for(int j = 0; j < 8; j++) {\n            if((mask & (1 << j)) && (i + j) < n) {\n                int num = i + j;\n                while(num > 0) {\n                    if(num % 10 == 7) count++;\n                    num /= 10;\n                }\n            }\n        }\n    }\n    \n    return count;\n}\n```"}
{"task_id": "SimdBench_80_AVX", "completion": "```cpp\nint fizz_buzz_simd(int n) {\n    int count = 0;\n    __m256i sevens = _mm256_set1_epi32(7);\n    __m256i tens = _mm256_set1_epi32(10);\n    __m256i zeros = _mm256_setzero_si256();\n    \n    for(int i = 0; i < n; i += 8) {\n        __m256i nums = _mm256_setr_epi32(i, i+1, i+2, i+3, i+4, i+5, i+6, i+7);\n        __m256i div11 = _mm256_set1_epi32(11);\n        __m256i div13 = _mm256_set1_epi32(13);\n        \n        __m256i mod11 = _mm256_rem_epi32(nums, div11);\n        __m256i mod13 = _mm256_rem_epi32(nums, div13);\n        \n        __m256i is_div = _mm256_or_si256(\n            _mm256_cmpeq_epi32(mod11, zeros),\n            _mm256_cmpeq_epi32(mod13, zeros)\n        );\n        \n        int mask = _mm256_movemask_ps(_mm256_castsi256_ps(is_div));\n        \n        for(int j = 0; j < 8; j++) {\n            if((mask & (1 << j)) && (i + j) < n) {\n                int num = i + j;\n                while(num > 0) {\n                    if(num % 10 == 7) count++;\n                    num /= 10;\n                }\n            }\n        }\n    }\n    \n    return count;\n}\n```"}
{"task_id": "SimdBench_80_AVX", "completion": "```cpp\nint fizz_buzz_simd(int n) {\n    int count = 0;\n    __m256i vec_11 = _mm256_set1_epi32(11);\n    __m256i vec_13 = _mm256_set1_epi32(13);\n    __m256i vec_10 = _mm256_set1_epi32(10);\n    __m256i vec_7 = _mm256_set1_epi32(7);\n    \n    for(int i = 0; i < n; i += 8) {\n        __m256i nums = _mm256_setr_epi32(i, i+1, i+2, i+3, i+4, i+5, i+6, i+7);\n        \n        __m256i mod11 = _mm256_rem_epi32(nums, vec_11);\n        __m256i mod13 = _mm256_rem_epi32(nums, vec_13);\n        \n        __m256i div_mask = _mm256_or_si256(\n            _mm256_cmpeq_epi32(mod11, _mm256_setzero_si256()),\n            _mm256_cmpeq_epi32(mod13, _mm256_setzero_si256())\n        );\n        \n        int div_bits = _mm256_movemask_ps(_mm256_castsi256_ps(div_mask));\n        \n        for(int j = 0; j < 8; j++) {\n            if((div_bits & (1 << j)) && (i+j) < n) {\n                int num = i + j;\n                while(num > 0) {\n                    if(num % 10 == 7) count++;\n                    num /= 10;\n                }\n            }\n        }\n    }\n    \n    return count;\n}\n```"}
{"task_id": "SimdBench_80_AVX", "completion": "```cpp\nint fizz_buzz_simd(int n) {\n    int count = 0;\n    __m256i vec_11 = _mm256_set1_epi32(11);\n    __m256i vec_13 = _mm256_set1_epi32(13);\n    __m256i vec_10 = _mm256_set1_epi32(10);\n    __m256i vec_7 = _mm256_set1_epi32(7);\n    \n    for(int i = 0; i < n; i += 8) {\n        __m256i nums = _mm256_setr_epi32(i, i+1, i+2, i+3, i+4, i+5, i+6, i+7);\n        __m256i mod11 = _mm256_rem_epi32(nums, vec_11);\n        __m256i mod13 = _mm256_rem_epi32(nums, vec_13);\n        __m256i mask = _mm256_or_si256(\n            _mm256_cmpeq_epi32(mod11, _mm256_setzero_si256()),\n            _mm256_cmpeq_epi32(mod13, _mm256_setzero_si256())\n        );\n        \n        int valid_nums = _mm256_movemask_ps(_mm256_castsi256_ps(mask));\n        \n        for(int j = 0; j < 8; j++) {\n            if(i + j >= n) break;\n            if(valid_nums & (1 << j)) {\n                int num = i + j;\n                while(num > 0) {\n                    if(num % 10 == 7) count++;\n                    num /= 10;\n                }\n            }\n        }\n    }\n    \n    return count;\n}\n```"}
{"task_id": "SimdBench_81_AVX", "completion": "```cpp\nstd::vector<float> sort_even_simd(std::vector<float> l) {\n    if (l.size() <= 1) return l;\n    \n    size_t n = l.size();\n    size_t even_count = (n + 1) / 2;\n    std::vector<float> even_values;\n    even_values.reserve(even_count);\n    \n    // Extract even-indexed elements\n    for (size_t i = 0; i < n; i += 2) {\n        even_values.push_back(l[i]);\n    }\n    \n    // Sort even values using AVX\n    size_t simd_size = 8;\n    size_t simd_count = (even_count + simd_size - 1) / simd_size;\n    \n    for (size_t i = 0; i < even_count; i++) {\n        for (size_t j = 0; j < even_count - 1; j += simd_size) {\n            size_t remaining = std::min(simd_size, even_count - j);\n            \n            if (remaining >= 8) {\n                __m256 v1 = _mm256_loadu_ps(&even_values[j]);\n                __m256 v2 = _mm256_permute_ps(v1, 0b10110001);\n                __m256 min = _mm256_min_ps(v1, v2);\n                __m256 max = _mm256_max_ps(v1, v2);\n                v1 = _mm256_blend_ps(min, max, 0b10101010);\n                v2 = _mm256_permute_ps(v1, 0b01001110);\n                min = _mm256_min_ps(v1, v2);\n                max = _mm256_max_ps(v1, v2);\n                v1 = _mm256_blend_ps(min, max, 0b11001100);\n                v2 = _mm256_permute2f128_ps(v1, v1, 0x01);\n                min = _mm256_min_ps(v1, v2);\n                max = _mm256_max_ps(v1, v2);\n                v1 = _mm256_blend_ps(min, max, 0b11110000);\n                _mm256_storeu_ps(&even_values[j], v1);\n            } else {\n                // Handle remaining elements\n                for (size_t k = j; k < j + remaining - 1; k++) {\n                    if (even_values[k] > even_values[k + 1]) {\n                        std::swap(even_values[k], even_values[k + 1]);\n                    }\n                }\n            }\n        }\n    }\n    \n    // Put sorted even values back\n    size_t even_idx = 0;\n    for (size_t i = 0; i < n; i += 2) {\n        l[i] = even_values[even_idx++];\n    }\n    \n    return l;\n}\n```"}
{"task_id": "SimdBench_81_AVX", "completion": "```cpp\nstd::vector<float> sort_even_simd(std::vector<float> l) {\n    if (l.size() <= 1) return l;\n    \n    size_t n = l.size();\n    size_t even_count = (n + 1) / 2;\n    std::vector<float> even_values;\n    even_values.reserve(even_count);\n    \n    // Extract even indices\n    for (size_t i = 0; i < n; i += 2) {\n        even_values.push_back(l[i]);\n    }\n\n    // Sort even values using AVX\n    size_t vec_size = (even_count + 7) / 8 * 8;\n    even_values.resize(vec_size, std::numeric_limits<float>::infinity());\n    \n    for (size_t i = 0; i < vec_size; i += 8) {\n        for (size_t j = 0; j < vec_size - 8; j += 8) {\n            __m256 v1 = _mm256_loadu_ps(&even_values[j]);\n            __m256 v2 = _mm256_loadu_ps(&even_values[j + 8]);\n            \n            __m256 min = _mm256_min_ps(v1, v2);\n            __m256 max = _mm256_max_ps(v1, v2);\n            \n            _mm256_storeu_ps(&even_values[j], min);\n            _mm256_storeu_ps(&even_values[j + 8], max);\n        }\n    }\n\n    // Put sorted even values back\n    size_t even_idx = 0;\n    for (size_t i = 0; i < n; i += 2) {\n        l[i] = even_values[even_idx++];\n    }\n    \n    return l;\n}\n```"}
{"task_id": "SimdBench_81_AVX", "completion": "```cpp\nstd::vector<float> sort_even_simd(std::vector<float> l) {\n    if (l.size() <= 1) return l;\n    \n    size_t n = l.size();\n    size_t even_count = (n + 1) / 2;\n    std::vector<float> even_values;\n    even_values.reserve(even_count);\n    \n    // Extract even indices\n    for (size_t i = 0; i < n; i += 2) {\n        even_values.push_back(l[i]);\n    }\n\n    // Sort even values using AVX\n    size_t vec_size = (even_count + 7) / 8 * 8;\n    even_values.resize(vec_size, std::numeric_limits<float>::max());\n    \n    for (size_t i = 0; i < vec_size; i += 8) {\n        __m256 v = _mm256_loadu_ps(&even_values[i]);\n        \n        // Bitonic sort within vector\n        __m256 t0 = _mm256_permute_ps(v, 0xB1);\n        __m256 m0 = _mm256_cmp_ps(v, t0, _CMP_LT_OS);\n        v = _mm256_blendv_ps(t0, v, m0);\n        \n        t0 = _mm256_permute_ps(v, 0x4E);\n        m0 = _mm256_cmp_ps(v, t0, _CMP_LT_OS);\n        v = _mm256_blendv_ps(t0, v, m0);\n        \n        t0 = _mm256_permute_ps(v, 0xB1);\n        m0 = _mm256_cmp_ps(v, t0, _CMP_LT_OS);\n        v = _mm256_blendv_ps(t0, v, m0);\n        \n        t0 = _mm256_permute2f128_ps(v, v, 0x01);\n        m0 = _mm256_cmp_ps(v, t0, _CMP_LT_OS);\n        v = _mm256_blendv_ps(t0, v, m0);\n        \n        t0 = _mm256_permute_ps(v, 0x4E);\n        m0 = _mm256_cmp_ps(v, t0, _CMP_LT_OS);\n        v = _mm256_blendv_ps(t0, v, m0);\n        \n        t0 = _mm256_permute_ps(v, 0xB1);\n        m0 = _mm256_cmp_ps(v, t0, _CMP_LT_OS);\n        v = _mm256_blendv_ps(t0, v, m0);\n        \n        _mm256_storeu_ps(&even_values[i], v);\n    }\n\n    even_values.resize(even_count);\n    \n    // Put sorted even values back\n    size_t even_idx = 0;\n    for (size_t i = 0; i < n; i += 2) {\n        l[i] = even_values[even_idx++];\n    }\n    \n    return l;\n}\n```"}
{"task_id": "SimdBench_81_AVX", "completion": "```cpp\nstd::vector<float> sort_even_simd(std::vector<float> l) {\n    if (l.size() <= 1) return l;\n    \n    size_t n = l.size();\n    size_t even_count = (n + 1) / 2;\n    std::vector<float> even_values;\n    even_values.reserve(even_count);\n    \n    // Extract even indices\n    for (size_t i = 0; i < n; i += 2) {\n        even_values.push_back(l[i]);\n    }\n\n    // Sort even values using AVX\n    size_t vec_size = (even_count + 7) / 8 * 8;\n    even_values.resize(vec_size, std::numeric_limits<float>::max());\n    \n    for (size_t i = 0; i < vec_size; i += 8) {\n        __m256 v = _mm256_loadu_ps(&even_values[i]);\n        \n        // Bitonic sort within 256-bit vector\n        __m256 t0 = _mm256_permute_ps(v, 0xB1);\n        __m256 m0 = _mm256_cmp_ps(v, t0, _CMP_LT_OS);\n        v = _mm256_blendv_ps(t0, v, m0);\n        \n        t0 = _mm256_permute_ps(v, 0x4E);\n        m0 = _mm256_cmp_ps(v, t0, _CMP_LT_OS);\n        v = _mm256_blendv_ps(t0, v, m0);\n        \n        t0 = _mm256_permute_ps(v, 0xB1);\n        m0 = _mm256_cmp_ps(v, t0, _CMP_LT_OS);\n        v = _mm256_blendv_ps(t0, v, m0);\n        \n        t0 = _mm256_permute2f128_ps(v, v, 0x01);\n        m0 = _mm256_cmp_ps(v, t0, _CMP_LT_OS);\n        v = _mm256_blendv_ps(t0, v, m0);\n        \n        t0 = _mm256_permute_ps(v, 0x4E);\n        m0 = _mm256_cmp_ps(v, t0, _CMP_LT_OS);\n        v = _mm256_blendv_ps(t0, v, m0);\n        \n        t0 = _mm256_permute_ps(v, 0xB1);\n        m0 = _mm256_cmp_ps(v, t0, _CMP_LT_OS);\n        v = _mm256_blendv_ps(t0, v, m0);\n        \n        _mm256_storeu_ps(&even_values[i], v);\n    }\n    \n    even_values.resize(even_count);\n    std::sort(even_values.begin(), even_values.end());\n    \n    // Put sorted even values back\n    size_t even_idx = 0;\n    for (size_t i = 0; i < n; i += 2) {\n        l[i] = even_values[even_idx++];\n    }\n    \n    return l;\n}\n```"}
{"task_id": "SimdBench_81_AVX", "completion": "```cpp\nstd::vector<float> sort_even_simd(std::vector<float> l) {\n    if (l.size() <= 1) return l;\n    \n    size_t n = l.size();\n    size_t even_count = (n + 1) / 2;\n    std::vector<float> even_values;\n    even_values.reserve(even_count);\n    \n    // Extract even indexed values\n    for (size_t i = 0; i < n; i += 2) {\n        even_values.push_back(l[i]);\n    }\n\n    // Sort even values using AVX\n    size_t vec_size = (even_count + 7) / 8 * 8;\n    even_values.resize(vec_size, std::numeric_limits<float>::max());\n    \n    for (size_t i = 0; i < vec_size; i += 8) {\n        __m256 v = _mm256_loadu_ps(&even_values[i]);\n        \n        // Bitonic sort within vector\n        __m256 t0 = _mm256_permute_ps(v, 0b10110001);\n        __m256 m0 = _mm256_min_ps(v, t0);\n        __m256 M0 = _mm256_max_ps(v, t0);\n        v = _mm256_blend_ps(m0, M0, 0b10101010);\n        \n        t0 = _mm256_permute_ps(v, 0b01001110);\n        m0 = _mm256_min_ps(v, t0);\n        M0 = _mm256_max_ps(v, t0);\n        v = _mm256_blend_ps(m0, M0, 0b11001100);\n        \n        t0 = _mm256_permute2f128_ps(v, v, 1);\n        m0 = _mm256_min_ps(v, t0);\n        M0 = _mm256_max_ps(v, t0);\n        v = _mm256_blend_ps(m0, M0, 0b11110000);\n        \n        _mm256_storeu_ps(&even_values[i], v);\n    }\n    \n    even_values.resize(even_count);\n    std::sort(even_values.begin(), even_values.end());\n    \n    // Put sorted even values back\n    size_t even_idx = 0;\n    for (size_t i = 0; i < n; i += 2) {\n        l[i] = even_values[even_idx++];\n    }\n    \n    return l;\n}\n```"}
{"task_id": "SimdBench_82_AVX", "completion": "```cpp\nbool triples_sum_to_zero_simd(std::vector<int> l) {\n    if (l.size() < 3) return false;\n    \n    int n = l.size();\n    int aligned_size = (n + 7) & ~7;\n    std::vector<int> aligned_data(aligned_size, 0);\n    std::copy(l.begin(), l.end(), aligned_data.begin());\n\n    for (int i = 0; i < n-2; i++) {\n        for (int j = i+1; j < n-1; j++) {\n            int sum2 = l[i] + l[j];\n            \n            __m256i v_sum2 = _mm256_set1_epi32(-sum2);\n            __m256i v_i = _mm256_set1_epi32(i);\n            __m256i v_j = _mm256_set1_epi32(j);\n            \n            for (int k = j+1; k < n; k += 8) {\n                __m256i v_indices = _mm256_set_epi32(k+7, k+6, k+5, k+4, k+3, k+2, k+1, k);\n                __m256i v_data = _mm256_loadu_si256((__m256i*)&aligned_data[k]);\n                \n                __m256i v_cmp = _mm256_cmpeq_epi32(v_data, v_sum2);\n                __m256i v_valid_k = _mm256_cmpgt_epi32(v_indices, v_j);\n                \n                int mask = _mm256_movemask_ps(_mm256_castsi256_ps(_mm256_and_si256(v_cmp, v_valid_k)));\n                \n                if (mask != 0) {\n                    return true;\n                }\n            }\n        }\n    }\n    \n    return false;\n}\n```"}
{"task_id": "SimdBench_82_AVX", "completion": "```cpp\nbool triples_sum_to_zero_simd(std::vector<int> l) {\n    if (l.size() < 3) return false;\n    \n    int n = l.size();\n    int aligned_size = (n + 7) & ~7;\n    std::vector<int> aligned_arr(aligned_size, 0);\n    std::copy(l.begin(), l.end(), aligned_arr.begin());\n\n    for (int i = 0; i < n-2; i++) {\n        for (int j = i+1; j < n-1; j++) {\n            int sum2 = l[i] + l[j];\n            \n            __m256i v_sum2 = _mm256_set1_epi32(-sum2);\n            __m256i v_i = _mm256_set1_epi32(i);\n            __m256i v_j = _mm256_set1_epi32(j);\n            \n            for (int k = j+1; k < aligned_size; k += 8) {\n                __m256i v_nums = _mm256_load_si256((__m256i*)&aligned_arr[k]);\n                __m256i v_k = _mm256_set_epi32(k+7, k+6, k+5, k+4, k+3, k+2, k+1, k);\n                \n                __m256i cmp = _mm256_cmpeq_epi32(v_nums, v_sum2);\n                __m256i valid_k = _mm256_cmpgt_epi32(v_k, v_j);\n                __m256i result = _mm256_and_si256(cmp, valid_k);\n                \n                if (_mm256_movemask_ps(_mm256_castsi256_ps(result)) != 0) {\n                    return true;\n                }\n            }\n        }\n    }\n    \n    return false;\n}\n```"}
{"task_id": "SimdBench_82_AVX", "completion": "```cpp\nbool triples_sum_to_zero_simd(std::vector<int> l) {\n    if (l.size() < 3) return false;\n    \n    int n = l.size();\n    int aligned_size = (n + 7) & ~7;\n    std::vector<int> aligned_vec(aligned_size, 0);\n    std::copy(l.begin(), l.end(), aligned_vec.begin());\n\n    for (int i = 0; i < n-2; i++) {\n        for (int j = i+1; j < n-1; j++) {\n            int sum2 = l[i] + l[j];\n            \n            __m256i v_sum2 = _mm256_set1_epi32(-sum2);\n            __m256i v_i = _mm256_set1_epi32(i);\n            __m256i v_j = _mm256_set1_epi32(j);\n            \n            for (int k = 0; k < aligned_size; k += 8) {\n                __m256i v_indices = _mm256_set_epi32(k+7, k+6, k+5, k+4, k+3, k+2, k+1, k);\n                __m256i v_nums = _mm256_load_si256((__m256i*)&aligned_vec[k]);\n                \n                __m256i v_eq = _mm256_cmpeq_epi32(v_nums, v_sum2);\n                __m256i v_gt_i = _mm256_cmpgt_epi32(v_indices, v_i);\n                __m256i v_gt_j = _mm256_cmpgt_epi32(v_indices, v_j);\n                \n                __m256i v_valid = _mm256_and_si256(v_eq, v_gt_i);\n                v_valid = _mm256_and_si256(v_valid, v_gt_j);\n                \n                int mask = _mm256_movemask_ps(_mm256_castsi256_ps(v_valid));\n                if (mask != 0) return true;\n            }\n        }\n    }\n    \n    return false;\n}\n```"}
{"task_id": "SimdBench_82_AVX", "completion": "```cpp\nbool triples_sum_to_zero_simd(std::vector<int> l) {\n    if (l.size() < 3) return false;\n    \n    int n = l.size();\n    int aligned_size = ((n + 7) / 8) * 8;\n    std::vector<int> aligned_arr(aligned_size, 0);\n    std::copy(l.begin(), l.end(), aligned_arr.begin());\n\n    for (int i = 0; i < n-2; i++) {\n        for (int j = i+1; j < n-1; j++) {\n            int sum2 = l[i] + l[j];\n            \n            int remaining = n - (j+1);\n            int vectors = remaining / 8;\n            \n            __m256i v_sum2 = _mm256_set1_epi32(-sum2);\n            \n            for (int k = 0; k < vectors; k++) {\n                __m256i v_arr = _mm256_load_si256((__m256i*)&aligned_arr[j+1 + k*8]);\n                __m256i v_cmp = _mm256_cmpeq_epi32(v_arr, v_sum2);\n                int mask = _mm256_movemask_ps(_mm256_castsi256_ps(v_cmp));\n                \n                if (mask != 0) {\n                    return true;\n                }\n            }\n            \n            // Handle remaining elements\n            for (int k = j+1 + vectors*8; k < n; k++) {\n                if (l[k] + sum2 == 0) {\n                    return true;\n                }\n            }\n        }\n    }\n    \n    return false;\n}\n```"}
{"task_id": "SimdBench_82_AVX", "completion": "```cpp\nbool triples_sum_to_zero_simd(std::vector<int> l) {\n    if (l.size() < 3) return false;\n    \n    int n = l.size();\n    int aligned_size = (n + 7) & ~7;\n    std::vector<int> aligned_arr(aligned_size, 0);\n    std::copy(l.begin(), l.end(), aligned_arr.begin());\n\n    for (int i = 0; i < n-2; i++) {\n        for (int j = i+1; j < n-1; j++) {\n            int sum2 = l[i] + l[j];\n            \n            __m256i v_sum2 = _mm256_set1_epi32(-sum2);\n            __m256i v_i = _mm256_set1_epi32(i);\n            __m256i v_j = _mm256_set1_epi32(j);\n            \n            for (int k = 0; k < aligned_size; k += 8) {\n                __m256i v_nums = _mm256_load_si256((__m256i*)&aligned_arr[k]);\n                __m256i v_indices = _mm256_set_epi32(k+7, k+6, k+5, k+4, k+3, k+2, k+1, k);\n                \n                __m256i v_eq = _mm256_cmpeq_epi32(v_nums, v_sum2);\n                __m256i v_gt_i = _mm256_cmpgt_epi32(v_indices, v_i);\n                __m256i v_gt_j = _mm256_cmpgt_epi32(v_indices, v_j);\n                \n                __m256i v_valid = _mm256_and_si256(v_eq, _mm256_and_si256(v_gt_i, v_gt_j));\n                \n                if (_mm256_movemask_ps(_mm256_castsi256_ps(v_valid)) != 0) {\n                    return true;\n                }\n            }\n        }\n    }\n    \n    return false;\n}\n```"}
{"task_id": "SimdBench_83_AVX", "completion": "```cpp\nstd::vector<int> incr_list_simd(std::vector<int> l) {\n    size_t size = l.size();\n    size_t simd_size = size - (size % 8);\n    \n    // Process 8 elements at a time using AVX2\n    for (size_t i = 0; i < simd_size; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&l[i]);\n        __m256i ones = _mm256_set1_epi32(1);\n        __m256i result = _mm256_add_epi32(vec, ones);\n        _mm256_storeu_si256((__m256i*)&l[i], result);\n    }\n    \n    // Handle remaining elements\n    for (size_t i = simd_size; i < size; i++) {\n        l[i]++;\n    }\n    \n    return l;\n}\n```"}
{"task_id": "SimdBench_83_AVX", "completion": "```cpp\nstd::vector<int> incr_list_simd(std::vector<int> l) {\n    size_t size = l.size();\n    size_t simd_size = size - (size % 8);\n    \n    // Process 8 elements at a time using AVX\n    for (size_t i = 0; i < simd_size; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&l[i]);\n        __m256i ones = _mm256_set1_epi32(1);\n        __m256i result = _mm256_add_epi32(vec, ones);\n        _mm256_storeu_si256((__m256i*)&l[i], result);\n    }\n    \n    // Handle remaining elements\n    for (size_t i = simd_size; i < size; i++) {\n        l[i]++;\n    }\n    \n    return l;\n}\n```"}
{"task_id": "SimdBench_83_AVX", "completion": "```cpp\nstd::vector<int> incr_list_simd(std::vector<int> l) {\n    size_t size = l.size();\n    size_t simd_size = size - (size % 8);\n    \n    for(size_t i = 0; i < simd_size; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&l[i]);\n        __m256i ones = _mm256_set1_epi32(1);\n        __m256i result = _mm256_add_epi32(vec, ones);\n        _mm256_storeu_si256((__m256i*)&l[i], result);\n    }\n\n    for(size_t i = simd_size; i < size; i++) {\n        l[i]++;\n    }\n    \n    return l;\n}\n```"}
{"task_id": "SimdBench_83_AVX", "completion": "```cpp\nstd::vector<int> incr_list_simd(std::vector<int> l) {\n    size_t size = l.size();\n    size_t simd_size = size - (size % 8);\n    \n    // Process 8 elements at a time using AVX2\n    for (size_t i = 0; i < simd_size; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&l[i]);\n        __m256i ones = _mm256_set1_epi32(1);\n        __m256i result = _mm256_add_epi32(vec, ones);\n        _mm256_storeu_si256((__m256i*)&l[i], result);\n    }\n    \n    // Handle remaining elements\n    for (size_t i = simd_size; i < size; i++) {\n        l[i]++;\n    }\n    \n    return l;\n}\n```"}
{"task_id": "SimdBench_83_AVX", "completion": "```cpp\nstd::vector<int> incr_list_simd(std::vector<int> l) {\n    size_t size = l.size();\n    size_t simd_size = size - (size % 8);\n    \n    // Process 8 elements at a time using AVX2\n    for (size_t i = 0; i < simd_size; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&l[i]);\n        __m256i ones = _mm256_set1_epi32(1);\n        __m256i result = _mm256_add_epi32(vec, ones);\n        _mm256_storeu_si256((__m256i*)&l[i], result);\n    }\n    \n    // Handle remaining elements\n    for (size_t i = simd_size; i < size; i++) {\n        l[i]++;\n    }\n    \n    return l;\n}\n```"}
{"task_id": "SimdBench_84_AVX", "completion": "```cpp\nbool pairs_sum_to_zero_simd(std::vector<int> l) {\n    if (l.size() < 2) return false;\n    \n    int n = l.size();\n    int vectorSize = 8; // AVX2 processes 8 integers at a time\n    int paddedSize = ((n + vectorSize - 1) / vectorSize) * vectorSize;\n    \n    // Pad the vector with zeros to make its size a multiple of 8\n    l.resize(paddedSize, 0);\n    \n    for (int i = 0; i < n; i++) {\n        __m256i v1 = _mm256_set1_epi32(-l[i]); // Broadcast -l[i]\n        \n        for (int j = 0; j < paddedSize; j += vectorSize) {\n            if (i >= j && i < j + vectorSize) continue; // Skip comparing with self\n            \n            __m256i v2 = _mm256_loadu_si256((__m256i*)&l[j]);\n            __m256i cmp = _mm256_cmpeq_epi32(v1, v2);\n            int mask = _mm256_movemask_ps(_mm256_castsi256_ps(cmp));\n            \n            if (mask != 0) {\n                // Check if the match is not with the same element\n                int matchIndex = j + __builtin_ctz(mask);\n                if (matchIndex != i && matchIndex < n) {\n                    return true;\n                }\n            }\n        }\n    }\n    \n    return false;\n}\n```"}
{"task_id": "SimdBench_84_AVX", "completion": "```cpp\nbool pairs_sum_to_zero_simd(std::vector<int> l) {\n    if (l.size() < 2) return false;\n    \n    int n = l.size();\n    int vectorSize = 8; // AVX2 can process 8 integers at once\n    int remainder = n % vectorSize;\n    int paddedSize = n + (vectorSize - remainder) % vectorSize;\n    \n    // Pad the vector to multiple of 8\n    l.resize(paddedSize, 0);\n    \n    for (int i = 0; i < n; i++) {\n        __m256i current = _mm256_set1_epi32(-l[i]); // Broadcast -current value\n        \n        for (int j = 0; j < paddedSize; j += vectorSize) {\n            if (i >= j && i < j + vectorSize) continue; // Skip comparing with self\n            \n            __m256i chunk = _mm256_loadu_si256((__m256i*)&l[j]);\n            __m256i cmp = _mm256_cmpeq_epi32(current, chunk);\n            int mask = _mm256_movemask_ps(_mm256_castsi256_ps(cmp));\n            \n            if (mask != 0) {\n                // Verify the match isn't with the same index\n                for (int k = 0; k < vectorSize; k++) {\n                    if ((mask & (1 << k)) && (j + k != i) && (j + k < n)) {\n                        return true;\n                    }\n                }\n            }\n        }\n    }\n    \n    return false;\n}\n```"}
{"task_id": "SimdBench_84_AVX", "completion": "```cpp\nbool pairs_sum_to_zero_simd(std::vector<int> l) {\n    if (l.size() < 2) return false;\n    \n    const int n = l.size();\n    const int simd_width = 8; // AVX2 processes 8 integers at a time\n    \n    for (int i = 0; i < n; i++) {\n        __m256i v1 = _mm256_set1_epi32(l[i]);\n        \n        for (int j = 0; j < n; j += simd_width) {\n            if (j + simd_width <= n) {\n                __m256i v2 = _mm256_loadu_si256((__m256i*)&l[j]);\n                __m256i sum = _mm256_add_epi32(v1, v2);\n                __m256i mask = _mm256_cmpeq_epi32(sum, _mm256_setzero_si256());\n                int movemask = _mm256_movemask_ps(_mm256_castsi256_ps(mask));\n                \n                if (movemask != 0) {\n                    // Check if we found a valid pair (not the same element)\n                    for (int k = 0; k < simd_width; k++) {\n                        if ((movemask & (1 << k)) && (i != j + k)) {\n                            return true;\n                        }\n                    }\n                }\n            } else {\n                // Handle remaining elements\n                for (; j < n; j++) {\n                    if (i != j && l[i] + l[j] == 0) {\n                        return true;\n                    }\n                }\n            }\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_84_AVX", "completion": "```cpp\nbool pairs_sum_to_zero_simd(std::vector<int> l) {\n    if (l.size() < 2) return false;\n    \n    size_t n = l.size();\n    size_t vec_size = 8; // AVX2 processes 8 integers at a time\n    size_t aligned_size = (n + vec_size - 1) & ~(vec_size - 1);\n    \n    // Pad vector to multiple of 8\n    l.resize(aligned_size, 0);\n    \n    for (size_t i = 0; i < n; i++) {\n        __m256i v1 = _mm256_set1_epi32(l[i]);\n        \n        for (size_t j = 0; j < aligned_size; j += vec_size) {\n            if (i >= j && i < j + vec_size) continue; // Skip comparing with self\n            \n            __m256i v2 = _mm256_loadu_si256((__m256i*)&l[j]);\n            __m256i sum = _mm256_add_epi32(v1, v2);\n            __m256i cmp = _mm256_cmpeq_epi32(sum, _mm256_setzero_si256());\n            int mask = _mm256_movemask_ps(_mm256_castsi256_ps(cmp));\n            \n            if (mask != 0) {\n                // Check if the match is not with self\n                for (int k = 0; k < 8; k++) {\n                    if ((mask & (1 << k)) && (j + k < n) && (j + k != i)) {\n                        return true;\n                    }\n                }\n            }\n        }\n    }\n    \n    return false;\n}\n```"}
{"task_id": "SimdBench_84_AVX", "completion": "```cpp\nbool pairs_sum_to_zero_simd(std::vector<int> l) {\n    if (l.size() < 2) return false;\n\n    const int n = l.size();\n    const int simd_width = 8; // AVX2 processes 8 integers at a time\n    \n    // Pad input vector to multiple of SIMD width\n    const int padded_size = ((n + simd_width - 1) / simd_width) * simd_width;\n    l.resize(padded_size, 0);\n\n    for (int i = 0; i < n-1; i++) {\n        __m256i v1 = _mm256_set1_epi32(l[i]);\n        \n        for (int j = 0; j < n; j += simd_width) {\n            __m256i v2 = _mm256_loadu_si256((__m256i*)&l[j]);\n            \n            // Compare if sum is zero\n            __m256i sum = _mm256_add_epi32(v1, v2);\n            __m256i zero = _mm256_setzero_si256();\n            __m256i cmp = _mm256_cmpeq_epi32(sum, zero);\n            \n            int mask = _mm256_movemask_ps(_mm256_castsi256_ps(cmp));\n            \n            // Check if any element is zero sum, excluding self-pair\n            if (mask != 0) {\n                for (int k = 0; k < simd_width; k++) {\n                    if ((mask & (1 << k)) && (i != j + k)) {\n                        return true;\n                    }\n                }\n            }\n        }\n    }\n    \n    return false;\n}\n```"}
{"task_id": "SimdBench_85_AVX", "completion": "```cpp\nstd::string change_base_simd(int64_t x, int8_t base) {\n    if (x == 0) return \"0\";\n    \n    char result[65];\n    int pos = 64;\n    result[pos] = '\\0';\n    \n    __m256i vec_x = _mm256_set1_epi64x(x);\n    __m256i vec_base = _mm256_set1_epi64x(base);\n    __m256i vec_zero = _mm256_setzero_si256();\n    \n    while (_mm256_movemask_pd(_mm256_castsi256_pd(_mm256_cmpgt_epi64(vec_x, vec_zero))) {\n        __m256i remainder = _mm256_rem_epi64(vec_x, vec_base);\n        __m256i quotient = _mm256_div_epi64(vec_x, vec_base);\n        \n        int64_t rem = _mm256_extract_epi64(remainder, 0);\n        result[--pos] = '0' + rem;\n        \n        vec_x = quotient;\n    }\n    \n    return std::string(result + pos);\n}\n```"}
{"task_id": "SimdBench_85_AVX", "completion": "```cpp\nstd::string change_base_simd(int64_t x, int8_t base) {\n    if (x == 0) return \"0\";\n    \n    char digits[64];\n    int pos = 0;\n    \n    __m256i vec_x = _mm256_set1_epi64x(x);\n    __m256i vec_base = _mm256_set1_epi64x(base);\n    __m256i vec_zero = _mm256_setzero_si256();\n    \n    while (_mm256_movemask_pd(_mm256_castsi256_pd(_mm256_cmpgt_epi64(vec_x, vec_zero))) {\n        __m256i remainder = _mm256_rem_epi64(vec_x, vec_base);\n        __m256i quotient = _mm256_div_epi64(vec_x, vec_base);\n        \n        int64_t rem = _mm256_extract_epi64(remainder, 0);\n        digits[pos++] = '0' + rem;\n        \n        vec_x = quotient;\n    }\n    \n    std::string result;\n    for (int i = pos - 1; i >= 0; i--) {\n        result += digits[i];\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_85_AVX", "completion": "```cpp\nstd::string change_base_simd(int64_t x, int8_t base) {\n    if (x == 0) return \"0\";\n    \n    char digits[64];\n    int pos = 0;\n    \n    __m256i vec_x = _mm256_set1_epi64x(x);\n    __m256i vec_base = _mm256_set1_epi64x(base);\n    __m256i vec_zero = _mm256_setzero_si256();\n    \n    while (_mm256_movemask_pd(_mm256_castsi256_pd(_mm256_cmpgt_epi64(vec_x, vec_zero))) {\n        __m256i quotient = _mm256_div_epi64(vec_x, vec_base);\n        __m256i remainder = _mm256_sub_epi64(vec_x, _mm256_mul_epi32(quotient, vec_base));\n        \n        int64_t rem[4];\n        _mm256_store_si256((__m256i*)rem, remainder);\n        \n        digits[pos++] = '0' + (char)rem[0];\n        vec_x = quotient;\n    }\n    \n    std::string result;\n    for(int i = pos-1; i >= 0; i--) {\n        result += digits[i];\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_85_AVX", "completion": "```cpp\nstd::string change_base_simd(int64_t x, int8_t base) {\n    if (x == 0) return \"0\";\n    \n    char digits[64];\n    int pos = 0;\n    \n    __m256i vec_x = _mm256_set1_epi64x(x);\n    __m256i vec_base = _mm256_set1_epi64x(base);\n    __m256i vec_zero = _mm256_setzero_si256();\n    \n    while (_mm256_movemask_pd(_mm256_castsi256_pd(_mm256_cmpgt_epi64(vec_x, vec_zero))) {\n        __m256i quotient = _mm256_div_epi64(vec_x, vec_base);\n        __m256i remainder = _mm256_sub_epi64(vec_x, _mm256_mul_epi32(quotient, vec_base));\n        \n        int64_t rem[4];\n        _mm256_store_si256((__m256i*)rem, remainder);\n        \n        digits[pos++] = '0' + (char)rem[0];\n        vec_x = quotient;\n    }\n    \n    std::string result;\n    for(int i = pos-1; i >= 0; i--) {\n        result += digits[i];\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_85_AVX", "completion": "```cpp\nstd::string change_base_simd(int64_t x, int8_t base) {\n    if (x == 0) return \"0\";\n    \n    char digits[64];\n    int pos = 0;\n    \n    __m256i vec_x = _mm256_set1_epi64x(x);\n    __m256i vec_base = _mm256_set1_epi64x(base);\n    __m256i vec_zero = _mm256_setzero_si256();\n    \n    while (_mm256_movemask_pd(_mm256_castsi256_pd(_mm256_cmpgt_epi64(vec_x, vec_zero))) {\n        __m256i quotient = _mm256_div_epi64(vec_x, vec_base);\n        __m256i remainder = _mm256_sub_epi64(vec_x, _mm256_mul_epi32(quotient, vec_base));\n        \n        int64_t rem[4];\n        _mm256_store_si256((__m256i*)rem, remainder);\n        \n        digits[pos++] = '0' + (char)rem[0];\n        vec_x = quotient;\n    }\n    \n    std::string result;\n    for(int i = pos-1; i >= 0; i--) {\n        result += digits[i];\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_86_AVX", "completion": "```cpp\nbool is_palindrome_simd(std::string text) {\n    const size_t len = text.length();\n    if (len <= 1) return true;\n\n    const char* str = text.c_str();\n    size_t i = 0;\n    size_t j = len - 1;\n\n    while (i < j) {\n        size_t remaining = j - i + 1;\n        if (remaining >= 32) {\n            __m256i forward = _mm256_loadu_si256((__m256i*)(str + i));\n            __m256i reverse = _mm256_loadu_si256((__m256i*)(str + j - 31));\n            reverse = _mm256_permute4x64_epi64(reverse, 0x1B);\n            reverse = _mm256_shuffle_epi8(reverse, _mm256_setr_epi8(\n                15,14,13,12,11,10,9,8,7,6,5,4,3,2,1,0,\n                31,30,29,28,27,26,25,24,23,22,21,20,19,18,17,16\n            ));\n            \n            __m256i cmp = _mm256_cmpeq_epi8(forward, reverse);\n            int mask = _mm256_movemask_epi8(cmp);\n            \n            if (mask != -1) return false;\n            \n            i += 32;\n            j -= 32;\n        } else if (remaining >= 16) {\n            __m128i forward = _mm_loadu_si128((__m128i*)(str + i));\n            __m128i reverse = _mm_loadu_si128((__m128i*)(str + j - 15));\n            reverse = _mm_shuffle_epi8(reverse, _mm_setr_epi8(\n                15,14,13,12,11,10,9,8,7,6,5,4,3,2,1,0\n            ));\n            \n            __m128i cmp = _mm_cmpeq_epi8(forward, reverse);\n            int mask = _mm_movemask_epi8(cmp);\n            \n            if (mask != 0xFFFF) return false;\n            \n            i += 16;\n            j -= 16;\n        } else {\n            if (str[i] != str[j]) return false;\n            i++;\n            j--;\n        }\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_86_AVX", "completion": "```cpp\nbool is_palindrome_simd(std::string text) {\n    const size_t len = text.length();\n    if (len <= 1) return true;\n\n    const char* str = text.c_str();\n    size_t i = 0;\n    size_t j = len - 1;\n\n    while (i < j) {\n        size_t remaining = j - i + 1;\n        if (remaining >= 32) {\n            __m256i forward = _mm256_loadu_si256((__m256i*)(str + i));\n            __m256i reverse = _mm256_loadu_si256((__m256i*)(str + j - 31));\n            reverse = _mm256_permute4x64_epi64(reverse, 0x1B);\n            reverse = _mm256_shuffle_epi8(reverse, _mm256_setr_epi8(\n                15,14,13,12,11,10,9,8,7,6,5,4,3,2,1,0,\n                31,30,29,28,27,26,25,24,23,22,21,20,19,18,17,16\n            ));\n            \n            __m256i cmp = _mm256_cmpeq_epi8(forward, reverse);\n            int mask = _mm256_movemask_epi8(cmp);\n            \n            if (mask != -1) return false;\n            \n            i += 32;\n            j -= 32;\n        } else {\n            if (str[i] != str[j]) return false;\n            i++;\n            j--;\n        }\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_86_AVX", "completion": "```cpp\nbool is_palindrome_simd(std::string text) {\n    const size_t len = text.length();\n    if (len <= 1) return true;\n\n    const char* str = text.c_str();\n    size_t i = 0;\n    size_t j = len - 1;\n\n    while (i < j) {\n        size_t remaining = j - i + 1;\n        if (remaining >= 32) {\n            __m256i forward = _mm256_loadu_si256((__m256i*)(str + i));\n            __m256i reverse = _mm256_loadu_si256((__m256i*)(str + j - 31));\n            reverse = _mm256_permute2x128_si256(reverse, reverse, 1);\n            reverse = _mm256_shuffle_epi8(reverse, _mm256_setr_epi8(\n                15,14,13,12,11,10,9,8,7,6,5,4,3,2,1,0,\n                31,30,29,28,27,26,25,24,23,22,21,20,19,18,17,16\n            ));\n            \n            __m256i cmp = _mm256_cmpeq_epi8(forward, reverse);\n            int mask = _mm256_movemask_epi8(cmp);\n            \n            if (mask != -1) return false;\n            \n            i += 32;\n            j -= 32;\n        } else {\n            if (str[i] != str[j]) return false;\n            i++;\n            j--;\n        }\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_86_AVX", "completion": "```cpp\nbool is_palindrome_simd(std::string text) {\n    const size_t len = text.length();\n    if (len <= 1) return true;\n\n    const char* str = text.c_str();\n    size_t i = 0;\n    size_t j = len - 1;\n\n    while (i < j) {\n        size_t remaining = j - i + 1;\n        if (remaining >= 32) {\n            __m256i forward = _mm256_loadu_si256((__m256i*)(str + i));\n            __m256i reverse = _mm256_loadu_si256((__m256i*)(str + j - 31));\n            reverse = _mm256_permute2x128_si256(reverse, reverse, 1);\n            reverse = _mm256_shuffle_epi8(reverse, _mm256_setr_epi8(\n                15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 0,\n                31, 30, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16\n            ));\n            \n            __m256i cmp = _mm256_cmpeq_epi8(forward, reverse);\n            int mask = _mm256_movemask_epi8(cmp);\n            if (mask != -1) return false;\n            \n            i += 32;\n            j -= 32;\n        } else {\n            if (str[i] != str[j]) return false;\n            i++;\n            j--;\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_86_AVX", "completion": "```cpp\nbool is_palindrome_simd(std::string text) {\n    const size_t len = text.length();\n    if (len <= 1) return true;\n\n    const char* str = text.c_str();\n    size_t i = 0;\n    size_t j = len - 1;\n\n    while (i < j) {\n        size_t remaining = j - i + 1;\n        if (remaining >= 32) {\n            __m256i forward = _mm256_loadu_si256((__m256i*)(str + i));\n            __m256i reverse = _mm256_loadu_si256((__m256i*)(str + j - 31));\n            reverse = _mm256_permute4x64_epi64(reverse, 0x1B);\n            reverse = _mm256_shuffle_epi8(reverse, _mm256_setr_epi8(\n                15,14,13,12,11,10,9,8,7,6,5,4,3,2,1,0,\n                31,30,29,28,27,26,25,24,23,22,21,20,19,18,17,16\n            ));\n            \n            __m256i cmp = _mm256_cmpeq_epi8(forward, reverse);\n            int mask = _mm256_movemask_epi8(cmp);\n            \n            if (mask != -1) return false;\n            \n            i += 32;\n            j -= 32;\n        } else if (remaining >= 16) {\n            __m128i forward = _mm_loadu_si128((__m128i*)(str + i));\n            __m128i reverse = _mm_loadu_si128((__m128i*)(str + j - 15));\n            reverse = _mm_shuffle_epi8(reverse, _mm_setr_epi8(\n                15,14,13,12,11,10,9,8,7,6,5,4,3,2,1,0\n            ));\n            \n            __m128i cmp = _mm_cmpeq_epi8(forward, reverse);\n            int mask = _mm_movemask_epi8(cmp);\n            \n            if (mask != 0xFFFF) return false;\n            \n            i += 16;\n            j -= 16;\n        } else {\n            if (str[i] != str[j]) return false;\n            i++;\n            j--;\n        }\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_87_AVX", "completion": "```cpp\nstd::string decode_shift_simd(std::string s) {\n    std::string out(s.length(), 0);\n    int i;\n    \n    __m256i shift = _mm256_set1_epi8(-5);\n    __m256i a = _mm256_set1_epi8('a');\n    __m256i z = _mm256_set1_epi8('z');\n    __m256i range = _mm256_set1_epi8(26);\n\n    for (i = 0; i + 32 <= s.length(); i += 32) {\n        __m256i input = _mm256_loadu_si256((__m256i*)(s.data() + i));\n        \n        // Shift characters back by 5\n        __m256i shifted = _mm256_add_epi8(input, shift);\n        \n        // Handle wraparound\n        __m256i mask = _mm256_cmpgt_epi8(a, shifted);\n        __m256i wrapped = _mm256_add_epi8(shifted, range);\n        __m256i result = _mm256_blendv_epi8(shifted, wrapped, mask);\n        \n        _mm256_storeu_si256((__m256i*)(out.data() + i), result);\n    }\n\n    // Handle remaining characters\n    for (; i < s.length(); i++) {\n        int w = ((int)s[i] - 5 - (int)'a' + 26) % 26 + (int)'a';\n        out[i] = (char)w;\n    }\n\n    return out;\n}\n```"}
{"task_id": "SimdBench_87_AVX", "completion": "```cpp\nstd::string decode_shift_simd(std::string s) {\n    std::string out(s.length(), 0);\n    int i;\n    \n    __m256i shift = _mm256_set1_epi8(5);\n    __m256i a_val = _mm256_set1_epi8('a');\n    __m256i mod26 = _mm256_set1_epi8(26);\n    \n    for(i = 0; i + 32 <= s.length(); i += 32) {\n        __m256i input = _mm256_loadu_si256((__m256i*)(s.data() + i));\n        \n        // Subtract 'a' to get 0-25 range\n        __m256i normalized = _mm256_sub_epi8(input, a_val);\n        \n        // Subtract shift (equivalent to adding 21 since we'll mod by 26)\n        __m256i shifted = _mm256_sub_epi8(normalized, shift);\n        \n        // Add 26 to handle negative values\n        shifted = _mm256_add_epi8(shifted, mod26);\n        \n        // Modulo 26 \n        __m256i modded = _mm256_and_si256(shifted, _mm256_set1_epi8(0x1F));\n        __m256i mask = _mm256_cmpgt_epi8(modded, _mm256_set1_epi8(25));\n        modded = _mm256_sub_epi8(modded, _mm256_and_si256(mask, mod26));\n        \n        // Add 'a' back\n        __m256i result = _mm256_add_epi8(modded, a_val);\n        \n        _mm256_storeu_si256((__m256i*)(out.data() + i), result);\n    }\n    \n    // Handle remaining characters\n    for(; i < s.length(); i++) {\n        int w = ((int)s[i] - 5 - (int)'a' + 26) % 26 + (int)'a';\n        out[i] = (char)w;\n    }\n    \n    return out;\n}\n```"}
{"task_id": "SimdBench_87_AVX", "completion": "```cpp\nstd::string decode_shift_simd(std::string s) {\n    std::string out(s.length(), 0);\n    int i = 0;\n    \n    // Process 32 characters at a time using AVX2\n    for (; i + 32 <= s.length(); i += 32) {\n        __m256i chars = _mm256_loadu_si256((__m256i*)(s.data() + i));\n        \n        // Subtract 5 from each character\n        __m256i shifted = _mm256_sub_epi8(chars, _mm256_set1_epi8(5));\n        \n        // Handle wraparound for characters that go below 'a'\n        __m256i below_a = _mm256_cmpgt_epi8(_mm256_set1_epi8('a'), shifted);\n        __m256i add_26 = _mm256_and_si256(below_a, _mm256_set1_epi8(26));\n        shifted = _mm256_add_epi8(shifted, add_26);\n        \n        _mm256_storeu_si256((__m256i*)(out.data() + i), shifted);\n    }\n    \n    // Handle remaining characters\n    for (; i < s.length(); i++) {\n        int w = ((int)s[i] - 5 - (int)'a');\n        if (w < 0) w += 26;\n        w = w % 26 + (int)'a';\n        out[i] = (char)w;\n    }\n    \n    return out;\n}\n```"}
{"task_id": "SimdBench_87_AVX", "completion": "```cpp\nstd::string decode_shift_simd(std::string s) {\n    std::string out(s.length(), 0);\n    int i = 0;\n    \n    __m256i shift = _mm256_set1_epi8(5);\n    __m256i a = _mm256_set1_epi8('a');\n    __m256i mod26 = _mm256_set1_epi8(26);\n    \n    for (; i + 32 <= s.length(); i += 32) {\n        __m256i input = _mm256_loadu_si256((__m256i*)(s.data() + i));\n        \n        // Subtract 'a' to get 0-25 range\n        __m256i normalized = _mm256_sub_epi8(input, a);\n        \n        // Subtract shift (equivalent to adding 21 since we'll mod by 26)\n        __m256i shifted = _mm256_sub_epi8(normalized, shift);\n        \n        // Add 26 to handle negative values\n        shifted = _mm256_add_epi8(shifted, mod26);\n        \n        // Modulo 26\n        __m256i modded = _mm256_and_si256(shifted, _mm256_set1_epi8(0x1F));\n        __m256i mask = _mm256_cmpgt_epi8(modded, _mm256_sub_epi8(mod26, _mm256_set1_epi8(1)));\n        __m256i result = _mm256_sub_epi8(modded, _mm256_and_si256(mask, mod26));\n        \n        // Add 'a' back\n        result = _mm256_add_epi8(result, a);\n        \n        _mm256_storeu_si256((__m256i*)(out.data() + i), result);\n    }\n    \n    // Handle remaining characters\n    for (; i < s.length(); i++) {\n        int w = ((int)s[i] - 5 - (int)'a' + 26) % 26 + (int)'a';\n        out[i] = (char)w;\n    }\n    \n    return out;\n}\n```"}
{"task_id": "SimdBench_87_AVX", "completion": "```cpp\nstd::string decode_shift_simd(std::string s) {\n    std::string out(s.length(), 0);\n    int i = 0;\n    \n    // Process 32 characters at a time using AVX2\n    for (; i + 32 <= s.length(); i += 32) {\n        __m256i chars = _mm256_loadu_si256((__m256i*)(s.data() + i));\n        \n        // Subtract 5 from each character\n        __m256i decoded = _mm256_sub_epi8(chars, _mm256_set1_epi8(5));\n        \n        // Handle wrap-around for characters that go below 'a'\n        __m256i below_a = _mm256_cmpgt_epi8(_mm256_set1_epi8('a'), decoded);\n        __m256i add_26 = _mm256_and_si256(below_a, _mm256_set1_epi8(26));\n        decoded = _mm256_add_epi8(decoded, add_26);\n        \n        _mm256_storeu_si256((__m256i*)(out.data() + i), decoded);\n    }\n    \n    // Handle remaining characters\n    for (; i < s.length(); i++) {\n        int w = ((int)s[i] - 5 - (int)'a');\n        if (w < 0) w += 26;\n        w = w % 26 + (int)'a';\n        out[i] = (char)w;\n    }\n    \n    return out;\n}\n```"}
{"task_id": "SimdBench_88_AVX", "completion": "```cpp\nbool below_threshold_simd(std::vector<int> l, int t) {\n    size_t n = l.size();\n    size_t simd_size = n - (n % 8);\n    \n    __m256i threshold = _mm256_set1_epi32(t);\n    \n    for (size_t i = 0; i < simd_size; i += 8) {\n        __m256i values = _mm256_loadu_si256((__m256i*)&l[i]);\n        __m256i cmp = _mm256_cmpgt_epi32(values, threshold);\n        int mask = _mm256_movemask_ps(_mm256_castsi256_ps(cmp));\n        if (mask != 0) {\n            return false;\n        }\n    }\n\n    for (size_t i = simd_size; i < n; i++) {\n        if (l[i] >= t) {\n            return false;\n        }\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_88_AVX", "completion": "```cpp\nbool below_threshold_simd(std::vector<int> l, int t) {\n    const int size = l.size();\n    const int simd_width = 8; // AVX2 processes 8 integers at a time\n    \n    // Create vector with threshold value replicated 8 times\n    __m256i threshold = _mm256_set1_epi32(t);\n    \n    // Process 8 elements at a time\n    for (int i = 0; i <= size - simd_width; i += simd_width) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&l[i]);\n        __m256i cmp = _mm256_cmpgt_epi32(vec, threshold);\n        \n        // If any element is greater than threshold, return false\n        if (_mm256_movemask_ps(_mm256_castsi256_ps(cmp)) != 0) {\n            return false;\n        }\n    }\n    \n    // Handle remaining elements\n    for (int i = size - (size % simd_width); i < size; i++) {\n        if (l[i] >= t) {\n            return false;\n        }\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_88_AVX", "completion": "```cpp\nbool below_threshold_simd(std::vector<int> l, int t) {\n    const int size = l.size();\n    const int simd_size = 8; // AVX2 processes 8 integers at a time\n    \n    // Handle empty vector case\n    if (size == 0) return true;\n    \n    // Broadcast threshold to all elements of vector register\n    __m256i threshold = _mm256_set1_epi32(t);\n    \n    // Process 8 elements at a time\n    int i = 0;\n    for (; i + simd_size <= size; i += simd_size) {\n        // Load 8 integers\n        __m256i values = _mm256_loadu_si256((__m256i*)&l[i]);\n        \n        // Compare values < threshold\n        __m256i cmp = _mm256_cmpgt_epi32(values, threshold);\n        \n        // If any value > threshold, movemask will be non-zero\n        if (_mm256_movemask_ps(_mm256_castsi256_ps(cmp))) {\n            return false;\n        }\n    }\n    \n    // Handle remaining elements\n    for (; i < size; i++) {\n        if (l[i] >= t) {\n            return false;\n        }\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_88_AVX", "completion": "```cpp\nbool below_threshold_simd(std::vector<int> l, int t) {\n    const int size = l.size();\n    const int simd_size = 8; // AVX2 processes 8 integers at a time\n    \n    // Create vector of thresholds\n    __m256i threshold = _mm256_set1_epi32(t);\n    \n    // Process 8 elements at a time\n    for (int i = 0; i <= size - simd_size; i += simd_size) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&l[i]);\n        __m256i cmp = _mm256_cmpgt_epi32(vec, threshold);\n        \n        // If any element is greater than threshold, return false\n        if (_mm256_movemask_ps(_mm256_castsi256_ps(cmp)) != 0) {\n            return false;\n        }\n    }\n    \n    // Handle remaining elements\n    for (int i = size - (size % simd_size); i < size; i++) {\n        if (l[i] > t) {\n            return false;\n        }\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_88_AVX", "completion": "```cpp\nbool below_threshold_simd(std::vector<int> l, int t) {\n    const int size = l.size();\n    const int simd_size = 8; // AVX2 processes 8 integers at once\n    \n    // Create vector with threshold value replicated 8 times\n    __m256i threshold = _mm256_set1_epi32(t);\n    \n    // Process 8 elements at a time\n    for (int i = 0; i <= size - simd_size; i += simd_size) {\n        __m256i values = _mm256_loadu_si256((__m256i*)&l[i]);\n        __m256i compare = _mm256_cmpgt_epi32(values, threshold);\n        \n        // If any value is greater than threshold, return false\n        if (_mm256_movemask_ps(_mm256_castsi256_ps(compare)) != 0) {\n            return false;\n        }\n    }\n    \n    // Handle remaining elements\n    for (int i = size - (size % simd_size); i < size; i++) {\n        if (l[i] >= t) {\n            return false;\n        }\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_89_AVX", "completion": "```cpp\nbool correct_bracketing_simd(std::string brackets) {\n    int len = brackets.length();\n    if (len == 0) return true;\n    if (len % 2) return false;\n\n    int count = 0;\n    int i = 0;\n\n    // Process 32 characters at a time using AVX2\n    if (len >= 32) {\n        __m256i ones = _mm256_set1_epi8(1);\n        __m256i zeros = _mm256_setzero_si256();\n        __m256i sum = _mm256_setzero_si256();\n\n        for (; i <= len - 32; i += 32) {\n            __m256i data = _mm256_loadu_si256((__m256i*)(brackets.data() + i));\n            __m256i lt = _mm256_cmpeq_epi8(data, _mm256_set1_epi8('<'));\n            __m256i gt = _mm256_cmpeq_epi8(data, _mm256_set1_epi8('>'));\n            \n            __m256i inc = _mm256_and_si256(lt, ones);\n            __m256i dec = _mm256_and_si256(gt, ones);\n            \n            __m256i diff = _mm256_sub_epi8(inc, dec);\n            sum = _mm256_add_epi8(sum, diff);\n            \n            // Check if count goes negative\n            __m256i running = _mm256_add_epi8(_mm256_set1_epi8(count), sum);\n            __m256i neg = _mm256_cmpgt_epi8(zeros, running);\n            if (_mm256_movemask_epi8(neg)) {\n                return false;\n            }\n        }\n        \n        // Sum up the counts\n        alignas(32) char counts[32];\n        _mm256_store_si256((__m256i*)counts, sum);\n        for (int j = 0; j < 32; j++) {\n            count += counts[j];\n        }\n    }\n\n    // Process remaining characters\n    for (; i < len; i++) {\n        if (brackets[i] == '<') count++;\n        else count--;\n        if (count < 0) return false;\n    }\n\n    return count == 0;\n}\n```"}
{"task_id": "SimdBench_89_AVX", "completion": "```cpp\nbool correct_bracketing_simd(std::string brackets) {\n    int len = brackets.length();\n    if (len == 0) return true;\n    if (len % 2) return false;\n\n    int count = 0;\n    int i = 0;\n\n    // Process 32 characters at a time using AVX2\n    if (len >= 32) {\n        __m256i zeros = _mm256_setzero_si256();\n        __m256i ones = _mm256_set1_epi8(1);\n        __m256i neg_ones = _mm256_set1_epi8(-1);\n        __m256i sum = _mm256_setzero_si256();\n\n        for (; i <= len - 32; i += 32) {\n            __m256i data = _mm256_loadu_si256((__m256i*)(brackets.data() + i));\n            __m256i open_mask = _mm256_cmpeq_epi8(data, _mm256_set1_epi8('<'));\n            __m256i close_mask = _mm256_cmpeq_epi8(data, _mm256_set1_epi8('>'));\n            \n            __m256i adds = _mm256_and_si256(open_mask, ones);\n            __m256i subs = _mm256_and_si256(close_mask, neg_ones);\n            \n            sum = _mm256_add_epi8(sum, adds);\n            sum = _mm256_add_epi8(sum, subs);\n            \n            // Check if count goes negative\n            __m256i neg_check = _mm256_cmpgt_epi8(zeros, sum);\n            if (_mm256_movemask_epi8(neg_check)) {\n                return false;\n            }\n        }\n        \n        // Sum up the counts\n        alignas(32) int8_t temp[32];\n        _mm256_store_si256((__m256i*)temp, sum);\n        for (int j = 0; j < 32; j++) {\n            count += temp[j];\n        }\n    }\n\n    // Process remaining characters\n    for (; i < len; i++) {\n        if (brackets[i] == '<') count++;\n        else count--;\n        if (count < 0) return false;\n    }\n\n    return count == 0;\n}\n```"}
{"task_id": "SimdBench_89_AVX", "completion": "```cpp\nbool correct_bracketing_simd(std::string brackets) {\n    int len = brackets.length();\n    if (len == 0) return true;\n    if (len % 2) return false;\n\n    int count = 0;\n    int i = 0;\n\n    // Process 32 characters at a time using AVX2\n    if (len >= 32) {\n        __m256i zeros = _mm256_setzero_si256();\n        __m256i ones = _mm256_set1_epi8(1);\n        __m256i neg_ones = _mm256_set1_epi8(-1);\n        \n        for (; i <= len-32; i += 32) {\n            __m256i data = _mm256_loadu_si256((__m256i*)(brackets.data() + i));\n            \n            // Create mask for '<' characters\n            __m256i lt_mask = _mm256_cmpeq_epi8(data, _mm256_set1_epi8('<'));\n            \n            // Create mask for '>' characters\n            __m256i gt_mask = _mm256_cmpeq_epi8(data, _mm256_set1_epi8('>'));\n            \n            // Add 1 for '<' and -1 for '>'\n            __m256i sum = _mm256_add_epi8(\n                _mm256_and_si256(lt_mask, ones),\n                _mm256_and_si256(gt_mask, neg_ones)\n            );\n            \n            // Horizontal sum\n            __m128i sum_128 = _mm_add_epi8(\n                _mm256_extracti128_si256(sum, 0),\n                _mm256_extracti128_si256(sum, 1)\n            );\n            \n            int8_t temp[16];\n            _mm_storeu_si128((__m128i*)temp, sum_128);\n            \n            for (int j = 0; j < 16; j++) {\n                count += temp[j];\n                if (count < 0) return false;\n            }\n        }\n    }\n\n    // Process remaining characters\n    for (; i < len; i++) {\n        count += (brackets[i] == '<') ? 1 : -1;\n        if (count < 0) return false;\n    }\n\n    return count == 0;\n}\n```"}
{"task_id": "SimdBench_89_AVX", "completion": "```cpp\nbool correct_bracketing_simd(std::string brackets) {\n    int len = brackets.length();\n    if (len == 0) return true;\n    if (len % 2) return false;\n\n    int count = 0;\n    const int simd_width = 32;\n    __m256i ones = _mm256_set1_epi8(1);\n    __m256i zeros = _mm256_setzero_si256();\n\n    for (int i = 0; i < len; i += simd_width) {\n        int chunk_size = std::min(simd_width, len - i);\n        \n        if (chunk_size == simd_width) {\n            __m256i data = _mm256_loadu_si8(brackets.c_str() + i);\n            __m256i cmp = _mm256_cmpeq_epi8(data, _mm256_set1_epi8('<'));\n            __m256i mask = _mm256_blendv_epi8(ones, zeros, cmp);\n            \n            int sum = 0;\n            uint8_t* vals = (uint8_t*)&mask;\n            for (int j = 0; j < simd_width; j++) {\n                if (vals[j]) count--;\n                else count++;\n                \n                if (count < 0) return false;\n            }\n        } else {\n            for (int j = i; j < len; j++) {\n                if (brackets[j] == '<') count++;\n                else count--;\n                \n                if (count < 0) return false;\n            }\n        }\n    }\n\n    return count == 0;\n}\n```"}
{"task_id": "SimdBench_89_AVX", "completion": "```cpp\nbool correct_bracketing_simd(std::string brackets) {\n    int len = brackets.length();\n    if (len == 0) return true;\n    if (len % 2) return false;\n\n    int count = 0;\n    int i = 0;\n\n    // Process 32 characters at a time using AVX2\n    if (len >= 32) {\n        __m256i zero = _mm256_setzero_si256();\n        __m256i ones = _mm256_set1_epi8(1);\n        __m256i neg_ones = _mm256_set1_epi8(-1);\n        \n        for (; i <= len - 32; i += 32) {\n            __m256i data = _mm256_loadu_si256((__m256i*)(brackets.data() + i));\n            \n            // Create masks for '<' and '>'\n            __m256i open_mask = _mm256_cmpeq_epi8(data, _mm256_set1_epi8('<'));\n            __m256i close_mask = _mm256_cmpeq_epi8(data, _mm256_set1_epi8('>'));\n            \n            // Convert masks to +1 for '<' and -1 for '>'\n            __m256i open_count = _mm256_and_si256(open_mask, ones);\n            __m256i close_count = _mm256_and_si256(close_mask, neg_ones);\n            \n            // Combine counts\n            __m256i sum = _mm256_add_epi8(open_count, close_count);\n            \n            // Sum all bytes\n            int total = 0;\n            char* bytes = (char*)&sum;\n            for (int j = 0; j < 32; j++) {\n                total += bytes[j];\n                count += bytes[j];\n                if (count < 0) return false;\n            }\n        }\n    }\n\n    // Process remaining characters\n    for (; i < len; i++) {\n        count += (brackets[i] == '<') ? 1 : -1;\n        if (count < 0) return false;\n    }\n\n    return count == 0;\n}\n```"}
{"task_id": "SimdBench_90_AVX", "completion": "```cpp\nbool correct_bracketing_simd(std::string brackets) {\n    int len = brackets.length();\n    if (len == 0) return true;\n    if (len % 2) return false;\n\n    int count = 0;\n    const int simd_width = 32;\n    __m256i zeros = _mm256_setzero_si256();\n    \n    for (int i = 0; i < len; i += simd_width) {\n        int chunk_size = std::min(simd_width, len - i);\n        __m256i chunk;\n        \n        if (chunk_size == simd_width) {\n            chunk = _mm256_loadu_si256((__m256i*)(brackets.data() + i));\n        } else {\n            char temp[simd_width] = {0};\n            memcpy(temp, brackets.data() + i, chunk_size);\n            chunk = _mm256_loadu_si256((__m256i*)temp);\n        }\n\n        __m256i open_mask = _mm256_cmpeq_epi8(chunk, _mm256_set1_epi8('('));\n        __m256i close_mask = _mm256_cmpeq_epi8(chunk, _mm256_set1_epi8(')'));\n        \n        int open_count = _mm256_movemask_epi8(open_mask);\n        int close_count = _mm256_movemask_epi8(close_mask);\n\n        if (chunk_size < simd_width) {\n            open_count &= (1 << chunk_size) - 1;\n            close_count &= (1 << chunk_size) - 1;\n        }\n\n        count += _mm_popcnt_u32(open_count);\n        count -= _mm_popcnt_u32(close_count);\n        \n        if (count < 0) return false;\n    }\n\n    return count == 0;\n}\n```"}
{"task_id": "SimdBench_90_AVX", "completion": "```cpp\nbool correct_bracketing_simd(std::string brackets) {\n    int len = brackets.length();\n    if (len == 0) return true;\n    if (len % 2) return false;\n\n    int count = 0;\n    const char* data = brackets.c_str();\n    \n    __m256i ones = _mm256_set1_epi8(1);\n    __m256i neg_ones = _mm256_set1_epi8(-1);\n    __m256i zeros = _mm256_setzero_si256();\n    \n    for (int i = 0; i < len; i += 32) {\n        int remaining = std::min(32, len - i);\n        __m256i chunk;\n        \n        if (remaining == 32) {\n            chunk = _mm256_loadu_si256((__m256i*)(data + i));\n        } else {\n            char temp[32] = {0};\n            memcpy(temp, data + i, remaining);\n            chunk = _mm256_loadu_si256((__m256i*)temp);\n        }\n\n        __m256i open_mask = _mm256_cmpeq_epi8(chunk, _mm256_set1_epi8('('));\n        __m256i close_mask = _mm256_cmpeq_epi8(chunk, _mm256_set1_epi8(')'));\n        \n        __m256i adds = _mm256_and_si256(open_mask, ones);\n        __m256i subs = _mm256_and_si256(close_mask, neg_ones);\n        __m256i changes = _mm256_add_epi8(adds, subs);\n        \n        char temp[32];\n        _mm256_storeu_si256((__m256i*)temp, changes);\n        \n        for (int j = 0; j < remaining; j++) {\n            count += temp[j];\n            if (count < 0) return false;\n        }\n    }\n    \n    return count == 0;\n}\n```"}
{"task_id": "SimdBench_90_AVX", "completion": "```cpp\nbool correct_bracketing_simd(std::string brackets) {\n    int len = brackets.length();\n    if (len == 0) return true;\n    if (len % 2) return false;\n\n    int count = 0;\n    const int simd_width = 32;\n    __m256i ones = _mm256_set1_epi8(1);\n    __m256i neg_ones = _mm256_set1_epi8(-1);\n    \n    for (int i = 0; i < len; i += simd_width) {\n        int remaining = std::min(simd_width, len - i);\n        __m256i data;\n        \n        if (remaining == simd_width) {\n            data = _mm256_loadu_si256((__m256i*)(brackets.data() + i));\n        } else {\n            char temp[simd_width] = {0};\n            memcpy(temp, brackets.data() + i, remaining);\n            data = _mm256_loadu_si256((__m256i*)temp);\n        }\n\n        __m256i open_mask = _mm256_cmpeq_epi8(data, _mm256_set1_epi8('('));\n        __m256i close_mask = _mm256_cmpeq_epi8(data, _mm256_set1_epi8(')'));\n        \n        __m256i counts = _mm256_or_si256(\n            _mm256_and_si256(open_mask, ones),\n            _mm256_and_si256(close_mask, neg_ones)\n        );\n        \n        __m128i sum_128 = _mm_add_epi8(\n            _mm256_extracti128_si256(counts, 0),\n            _mm256_extracti128_si256(counts, 1)\n        );\n        \n        for (int j = 0; j < 16; j++) {\n            count += ((char*)&sum_128)[j];\n            if (count < 0) return false;\n        }\n    }\n    \n    return count == 0;\n}\n```"}
{"task_id": "SimdBench_90_AVX", "completion": "```cpp\nbool correct_bracketing_simd(std::string brackets) {\n    int len = brackets.length();\n    if (len == 0) return true;\n    if (len % 2) return false;\n\n    int count = 0;\n    int i;\n    \n    __m256i ones = _mm256_set1_epi8(1);\n    __m256i neg_ones = _mm256_set1_epi8(-1);\n    __m256i zeros = _mm256_setzero_si256();\n    \n    for (i = 0; i + 32 <= len; i += 32) {\n        __m256i chars = _mm256_loadu_si256((__m256i*)(brackets.data() + i));\n        __m256i open_mask = _mm256_cmpeq_epi8(chars, _mm256_set1_epi8('('));\n        __m256i close_mask = _mm256_cmpeq_epi8(chars, _mm256_set1_epi8(')'));\n        \n        __m256i adds = _mm256_blendv_epi8(zeros, ones, open_mask);\n        __m256i subs = _mm256_blendv_epi8(zeros, ones, close_mask);\n        \n        __m256i diff = _mm256_sub_epi8(adds, subs);\n        \n        uint32_t sum = 0;\n        char* bytes = (char*)&diff;\n        for(int j = 0; j < 32; j++) {\n            count += bytes[j];\n            if(count < 0) return false;\n        }\n    }\n    \n    for(; i < len; i++) {\n        if(brackets[i] == '(') count++;\n        else count--;\n        if(count < 0) return false;\n    }\n    \n    return count == 0;\n}\n```"}
{"task_id": "SimdBench_90_AVX", "completion": "```cpp\nbool correct_bracketing_simd(std::string brackets) {\n    if (brackets.empty()) return true;\n    if (brackets.length() % 2) return false;\n\n    const int len = brackets.length();\n    int count = 0;\n    \n    __m256i ones = _mm256_set1_epi8(1);\n    __m256i neg_ones = _mm256_set1_epi8(-1);\n    __m256i zeros = _mm256_setzero_si256();\n    \n    for (int i = 0; i < len; i += 32) {\n        int remaining = std::min(32, len - i);\n        __m256i data;\n        \n        if (remaining == 32) {\n            data = _mm256_loadu_si256((__m256i*)(brackets.data() + i));\n        } else {\n            char temp[32] = {0};\n            memcpy(temp, brackets.data() + i, remaining);\n            data = _mm256_loadu_si256((__m256i*)temp);\n        }\n\n        __m256i open_mask = _mm256_cmpeq_epi8(data, _mm256_set1_epi8('('));\n        __m256i close_mask = _mm256_cmpeq_epi8(data, _mm256_set1_epi8(')'));\n        \n        __m256i adds = _mm256_blendv_epi8(zeros, ones, open_mask);\n        __m256i subs = _mm256_blendv_epi8(zeros, neg_ones, close_mask);\n        \n        __m256i changes = _mm256_add_epi8(adds, subs);\n        \n        uint8_t temp[32];\n        _mm256_storeu_si256((__m256i*)temp, changes);\n        \n        for (int j = 0; j < remaining; j++) {\n            count += temp[j];\n            if (count < 0) return false;\n        }\n    }\n    \n    return count == 0;\n}\n```"}
{"task_id": "SimdBench_91_AVX", "completion": "```cpp\nstd::vector<float> derivative_simd(std::vector<float> xs) {\n    if (xs.size() <= 1) {\n        return std::vector<float>();\n    }\n\n    size_t n = xs.size() - 1;\n    std::vector<float> result(n);\n    \n    // Process 8 elements at a time using AVX\n    size_t i = 0;\n    for (; i + 7 < n; i += 8) {\n        __m256 indices = _mm256_set_ps(i+8, i+7, i+6, i+5, i+4, i+3, i+2, i+1);\n        __m256 coeffs = _mm256_loadu_ps(&xs[i+1]);\n        __m256 derivatives = _mm256_mul_ps(indices, coeffs);\n        _mm256_storeu_ps(&result[i], derivatives);\n    }\n\n    // Handle remaining elements\n    for (; i < n; i++) {\n        result[i] = xs[i+1] * (i+1);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_91_AVX", "completion": "```cpp\nstd::vector<float> derivative_simd(std::vector<float> xs) {\n    if (xs.size() <= 1) {\n        return std::vector<float>();\n    }\n\n    size_t n = xs.size() - 1;\n    std::vector<float> result(n);\n    \n    // Process 8 elements at a time using AVX\n    size_t i = 0;\n    for (; i + 7 < n; i += 8) {\n        __m256 indices = _mm256_set_ps(i + 8, i + 7, i + 6, i + 5, i + 4, i + 3, i + 2, i + 1);\n        __m256 coeffs = _mm256_loadu_ps(&xs[i + 1]);\n        __m256 derivatives = _mm256_mul_ps(indices, coeffs);\n        _mm256_storeu_ps(&result[i], derivatives);\n    }\n\n    // Handle remaining elements\n    for (; i < n; i++) {\n        result[i] = xs[i + 1] * (i + 1);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_91_AVX", "completion": "```cpp\nstd::vector<float> derivative_simd(std::vector<float> xs) {\n    if (xs.size() <= 1) {\n        return std::vector<float>();\n    }\n\n    size_t n = xs.size() - 1;\n    std::vector<float> result(n);\n    \n    size_t i = 0;\n    for (; i + 7 < n; i += 8) {\n        __m256 coeffs = _mm256_loadu_ps(&xs[i + 1]);\n        __m256 indices = _mm256_set_ps(i + 8, i + 7, i + 6, i + 5, i + 4, i + 3, i + 2, i + 1);\n        __m256 derivatives = _mm256_mul_ps(coeffs, indices);\n        _mm256_storeu_ps(&result[i], derivatives);\n    }\n\n    // Handle remaining elements\n    for (; i < n; i++) {\n        result[i] = xs[i + 1] * (i + 1);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_91_AVX", "completion": "```cpp\nstd::vector<float> derivative_simd(std::vector<float> xs) {\n    if (xs.size() <= 1) {\n        return std::vector<float>();\n    }\n\n    std::vector<float> result(xs.size() - 1);\n    \n    int i = 0;\n    int simd_size = 8; // AVX processes 8 floats at a time\n    \n    // Process 8 elements at a time using AVX\n    for (; i + simd_size <= xs.size() - 1; i += simd_size) {\n        __m256 coeffs = _mm256_loadu_ps(&xs[i + 1]);\n        __m256 indices = _mm256_set_ps(i + 8, i + 7, i + 6, i + 5, i + 4, i + 3, i + 2, i + 1);\n        __m256 products = _mm256_mul_ps(coeffs, indices);\n        _mm256_storeu_ps(&result[i], products);\n    }\n    \n    // Handle remaining elements\n    for (; i < xs.size() - 1; i++) {\n        result[i] = xs[i + 1] * (i + 1);\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_91_AVX", "completion": "```cpp\nstd::vector<float> derivative_simd(std::vector<float> xs) {\n    if (xs.size() <= 1) {\n        return std::vector<float>();\n    }\n\n    size_t n = xs.size() - 1;\n    std::vector<float> result(n);\n    \n    // Process 8 elements at a time using AVX\n    size_t i = 0;\n    for (; i + 7 < n; i += 8) {\n        __m256 coeffs = _mm256_loadu_ps(&xs[i + 1]);\n        __m256 indices = _mm256_set_ps(i + 8, i + 7, i + 6, i + 5, i + 4, i + 3, i + 2, i + 1);\n        __m256 derivatives = _mm256_mul_ps(coeffs, indices);\n        _mm256_storeu_ps(&result[i], derivatives);\n    }\n    \n    // Handle remaining elements\n    for (; i < n; i++) {\n        result[i] = xs[i + 1] * (i + 1);\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_92_AVX", "completion": "```cpp\nint vowels_count_simd(std::string s) {\n    int len = s.length();\n    int count = 0;\n    \n    // Convert string to lowercase for case-insensitive comparison\n    for(int i = 0; i < len; i++) {\n        s[i] = tolower(s[i]);\n    }\n    \n    if(len >= 32) {\n        __m256i vowels = _mm256_set1_epi8('a');\n        __m256i vowels_e = _mm256_set1_epi8('e');\n        __m256i vowels_i = _mm256_set1_epi8('i'); \n        __m256i vowels_o = _mm256_set1_epi8('o');\n        __m256i vowels_u = _mm256_set1_epi8('u');\n        \n        int aligned_len = len & ~31;\n        \n        for(int i = 0; i < aligned_len; i += 32) {\n            __m256i str = _mm256_loadu_si256((__m256i*)(s.c_str() + i));\n            \n            __m256i cmp_a = _mm256_cmpeq_epi8(str, vowels);\n            __m256i cmp_e = _mm256_cmpeq_epi8(str, vowels_e);\n            __m256i cmp_i = _mm256_cmpeq_epi8(str, vowels_i);\n            __m256i cmp_o = _mm256_cmpeq_epi8(str, vowels_o);\n            __m256i cmp_u = _mm256_cmpeq_epi8(str, vowels_u);\n            \n            __m256i result = _mm256_or_si256(cmp_a, cmp_e);\n            result = _mm256_or_si256(result, cmp_i);\n            result = _mm256_or_si256(result, cmp_o);\n            result = _mm256_or_si256(result, cmp_u);\n            \n            count += _mm_popcnt_u32(_mm256_movemask_epi8(result));\n        }\n        \n        // Handle remaining characters\n        for(int i = aligned_len; i < len; i++) {\n            if(s[i] == 'a' || s[i] == 'e' || s[i] == 'i' || \n               s[i] == 'o' || s[i] == 'u') {\n                count++;\n            }\n        }\n    } else {\n        // For short strings, use scalar code\n        for(int i = 0; i < len; i++) {\n            if(s[i] == 'a' || s[i] == 'e' || s[i] == 'i' || \n               s[i] == 'o' || s[i] == 'u') {\n                count++;\n            }\n        }\n    }\n    \n    // Handle 'y' at the end\n    if(len > 0 && s[len-1] == 'y') {\n        count++;\n    }\n    \n    return count;\n}\n```"}
{"task_id": "SimdBench_92_AVX", "completion": "```cpp\nint vowels_count_simd(std::string s) {\n    int len = s.length();\n    int count = 0;\n    \n    // Convert string to lowercase\n    for(int i = 0; i < len; i++) {\n        s[i] = tolower(s[i]);\n    }\n    \n    if(len >= 32) {\n        __m256i vowels = _mm256_set1_epi8('a');\n        __m256i vowels_e = _mm256_set1_epi8('e');\n        __m256i vowels_i = _mm256_set1_epi8('i');\n        __m256i vowels_o = _mm256_set1_epi8('o');\n        __m256i vowels_u = _mm256_set1_epi8('u');\n        \n        int aligned_len = len & ~31;\n        \n        for(int i = 0; i < aligned_len; i += 32) {\n            __m256i str = _mm256_loadu_si256((__m256i*)(s.c_str() + i));\n            \n            __m256i match_a = _mm256_cmpeq_epi8(str, vowels);\n            __m256i match_e = _mm256_cmpeq_epi8(str, vowels_e); \n            __m256i match_i = _mm256_cmpeq_epi8(str, vowels_i);\n            __m256i match_o = _mm256_cmpeq_epi8(str, vowels_o);\n            __m256i match_u = _mm256_cmpeq_epi8(str, vowels_u);\n            \n            __m256i result = _mm256_or_si256(match_a, match_e);\n            result = _mm256_or_si256(result, match_i);\n            result = _mm256_or_si256(result, match_o);\n            result = _mm256_or_si256(result, match_u);\n            \n            count += _mm_popcnt_u32(_mm256_movemask_epi8(result));\n        }\n        \n        // Handle remaining characters\n        for(int i = aligned_len; i < len; i++) {\n            if(s[i] == 'a' || s[i] == 'e' || s[i] == 'i' || s[i] == 'o' || s[i] == 'u') {\n                count++;\n            }\n        }\n    } else {\n        for(int i = 0; i < len; i++) {\n            if(s[i] == 'a' || s[i] == 'e' || s[i] == 'i' || s[i] == 'o' || s[i] == 'u') {\n                count++;\n            }\n        }\n    }\n    \n    // Handle 'y' at the end\n    if(len > 0 && s[len-1] == 'y') {\n        count++;\n    }\n    \n    return count;\n}\n```"}
{"task_id": "SimdBench_92_AVX", "completion": "```cpp\nint vowels_count_simd(std::string s) {\n    int count = 0;\n    int len = s.length();\n    \n    // Convert string to lowercase for case-insensitive comparison\n    for(int i = 0; i < len; i++) {\n        s[i] = tolower(s[i]);\n    }\n    \n    // Process 32 characters at a time using AVX2\n    const __m256i vowels_a = _mm256_set1_epi8('a');\n    const __m256i vowels_e = _mm256_set1_epi8('e');\n    const __m256i vowels_i = _mm256_set1_epi8('i');\n    const __m256i vowels_o = _mm256_set1_epi8('o');\n    const __m256i vowels_u = _mm256_set1_epi8('u');\n    \n    int i;\n    for(i = 0; i + 32 <= len; i += 32) {\n        __m256i str = _mm256_loadu_si256((__m256i*)(s.data() + i));\n        \n        __m256i match_a = _mm256_cmpeq_epi8(str, vowels_a);\n        __m256i match_e = _mm256_cmpeq_epi8(str, vowels_e);\n        __m256i match_i = _mm256_cmpeq_epi8(str, vowels_i);\n        __m256i match_o = _mm256_cmpeq_epi8(str, vowels_o);\n        __m256i match_u = _mm256_cmpeq_epi8(str, vowels_u);\n        \n        __m256i result = _mm256_or_si256(match_a, match_e);\n        result = _mm256_or_si256(result, match_i);\n        result = _mm256_or_si256(result, match_o);\n        result = _mm256_or_si256(result, match_u);\n        \n        count += _mm_popcnt_u32(_mm256_movemask_epi8(result));\n    }\n    \n    // Process remaining characters\n    for(; i < len; i++) {\n        char c = s[i];\n        if(c == 'a' || c == 'e' || c == 'i' || c == 'o' || c == 'u') {\n            count++;\n        }\n    }\n    \n    // Check if last character is 'y'\n    if(len > 0 && s[len-1] == 'y') {\n        count++;\n    }\n    \n    return count;\n}\n```"}
{"task_id": "SimdBench_92_AVX", "completion": "```cpp\nint vowels_count_simd(std::string s) {\n    int len = s.length();\n    int count = 0;\n    \n    // Convert string to lowercase\n    for(int i = 0; i < len; i++) {\n        s[i] = tolower(s[i]);\n    }\n    \n    // Process 32 characters at a time using AVX\n    __m256i vowels_a = _mm256_set1_epi8('a');\n    __m256i vowels_e = _mm256_set1_epi8('e'); \n    __m256i vowels_i = _mm256_set1_epi8('i');\n    __m256i vowels_o = _mm256_set1_epi8('o');\n    __m256i vowels_u = _mm256_set1_epi8('u');\n    \n    int i;\n    for(i = 0; i + 32 <= len; i += 32) {\n        __m256i str = _mm256_loadu_si256((__m256i*)(s.c_str() + i));\n        \n        __m256i match_a = _mm256_cmpeq_epi8(str, vowels_a);\n        __m256i match_e = _mm256_cmpeq_epi8(str, vowels_e);\n        __m256i match_i = _mm256_cmpeq_epi8(str, vowels_i);\n        __m256i match_o = _mm256_cmpeq_epi8(str, vowels_o);\n        __m256i match_u = _mm256_cmpeq_epi8(str, vowels_u);\n        \n        __m256i result = _mm256_or_si256(match_a, match_e);\n        result = _mm256_or_si256(result, match_i);\n        result = _mm256_or_si256(result, match_o);\n        result = _mm256_or_si256(result, match_u);\n        \n        unsigned mask = _mm256_movemask_epi8(result);\n        count += _mm_popcnt_u32(mask);\n    }\n    \n    // Process remaining characters\n    for(; i < len; i++) {\n        char c = s[i];\n        if(c == 'a' || c == 'e' || c == 'i' || c == 'o' || c == 'u') {\n            count++;\n        }\n    }\n    \n    // Check for 'y' at the end\n    if(len > 0 && s[len-1] == 'y') {\n        count++;\n    }\n    \n    return count;\n}\n```"}
{"task_id": "SimdBench_92_AVX", "completion": "```cpp\nint vowels_count_simd(std::string s) {\n    int count = 0;\n    int len = s.length();\n    \n    // Convert string to lowercase\n    for(int i = 0; i < len; i++) {\n        s[i] = tolower(s[i]);\n    }\n    \n    // Process 32 characters at a time using AVX2\n    const int SIMD_WIDTH = 32;\n    int vectorized_len = len - (len % SIMD_WIDTH);\n    \n    __m256i vowel_a = _mm256_set1_epi8('a');\n    __m256i vowel_e = _mm256_set1_epi8('e'); \n    __m256i vowel_i = _mm256_set1_epi8('i');\n    __m256i vowel_o = _mm256_set1_epi8('o');\n    __m256i vowel_u = _mm256_set1_epi8('u');\n    \n    for(int i = 0; i < vectorized_len; i += SIMD_WIDTH) {\n        __m256i chars = _mm256_loadu_si256((__m256i*)(s.data() + i));\n        \n        __m256i match_a = _mm256_cmpeq_epi8(chars, vowel_a);\n        __m256i match_e = _mm256_cmpeq_epi8(chars, vowel_e);\n        __m256i match_i = _mm256_cmpeq_epi8(chars, vowel_i);\n        __m256i match_o = _mm256_cmpeq_epi8(chars, vowel_o);\n        __m256i match_u = _mm256_cmpeq_epi8(chars, vowel_u);\n        \n        __m256i matches = _mm256_or_si256(match_a,\n                         _mm256_or_si256(match_e,\n                         _mm256_or_si256(match_i,\n                         _mm256_or_si256(match_o, match_u))));\n                         \n        uint32_t mask = _mm256_movemask_epi8(matches);\n        count += _mm_popcnt_u32(mask);\n    }\n    \n    // Handle remaining characters and 'y' at end\n    for(int i = vectorized_len; i < len; i++) {\n        if(s[i] == 'a' || s[i] == 'e' || s[i] == 'i' || \n           s[i] == 'o' || s[i] == 'u') {\n            count++;\n        }\n    }\n    \n    // Check for 'y' at end\n    if(len > 0 && s[len-1] == 'y') {\n        count++;\n    }\n    \n    return count;\n}\n```"}
{"task_id": "SimdBench_93_AVX", "completion": "```cpp\nint digitSum_simd(std::string s) {\n    int sum = 0;\n    size_t len = s.length();\n    size_t vectorSize = 32;\n    \n    if (len == 0) return 0;\n\n    // Process 32 characters at a time using AVX2\n    size_t vectorizedLen = len - (len % vectorSize);\n    const char* ptr = s.c_str();\n    \n    __m256i sumVec = _mm256_setzero_si256();\n    __m256i upperMask = _mm256_set1_epi8(0x40);\n    __m256i lowerMask = _mm256_set1_epi8(0x5B);\n    \n    for (size_t i = 0; i < vectorizedLen; i += vectorSize) {\n        __m256i data = _mm256_loadu_si256((__m256i*)(ptr + i));\n        \n        // Check if characters are uppercase (between 0x41 and 0x5A)\n        __m256i isGreater = _mm256_cmpgt_epi8(data, upperMask);\n        __m256i isLower = _mm256_cmpgt_epi8(lowerMask, data);\n        __m256i isUpper = _mm256_and_si256(isGreater, isLower);\n        \n        // Zero out non-uppercase characters\n        __m256i maskedData = _mm256_and_si256(data, isUpper);\n        \n        // Add to running sum\n        sumVec = _mm256_add_epi8(sumVec, maskedData);\n    }\n    \n    // Horizontal sum of vector\n    __m128i sum128 = _mm_add_epi8(_mm256_extracti128_si256(sumVec, 0),\n                                 _mm256_extracti128_si256(sumVec, 1));\n    \n    // Convert to 16-bit to avoid overflow during sum\n    __m128i sum_16_1 = _mm_cvtepi8_epi16(sum128);\n    __m128i sum_16_2 = _mm_cvtepi8_epi16(_mm_srli_si128(sum128, 8));\n    __m128i sum_16 = _mm_add_epi16(sum_16_1, sum_16_2);\n    \n    // Horizontal sum of 16-bit integers\n    sum_16 = _mm_add_epi16(sum_16, _mm_srli_si128(sum_16, 8));\n    sum_16 = _mm_add_epi16(sum_16, _mm_srli_si128(sum_16, 4));\n    sum_16 = _mm_add_epi16(sum_16, _mm_srli_si128(sum_16, 2));\n    \n    sum = _mm_extract_epi16(sum_16, 0);\n    \n    // Process remaining characters\n    for (size_t i = vectorizedLen; i < len; i++) {\n        if (s[i] >= 'A' && s[i] <= 'Z') {\n            sum += s[i];\n        }\n    }\n    \n    return sum;\n}\n```"}
{"task_id": "SimdBench_93_AVX", "completion": "```cpp\nint digitSum_simd(std::string s) {\n    if (s.empty()) return 0;\n    \n    int sum = 0;\n    size_t len = s.length();\n    size_t vectorLen = len - (len % 32);\n    \n    __m256i sum_vec = _mm256_setzero_si256();\n    __m256i upper_mask = _mm256_set1_epi8(0x40);\n    __m256i lower_mask = _mm256_set1_epi8(0x5B);\n    \n    for (size_t i = 0; i < vectorLen; i += 32) {\n        __m256i chars = _mm256_loadu_si256((__m256i*)(s.data() + i));\n        \n        __m256i is_upper = _mm256_and_si256(\n            _mm256_cmpgt_epi8(chars, upper_mask),\n            _mm256_cmpgt_epi8(lower_mask, chars)\n        );\n        \n        __m256i masked_chars = _mm256_and_si256(chars, is_upper);\n        sum_vec = _mm256_add_epi8(sum_vec, masked_chars);\n    }\n    \n    alignas(32) char sum_array[32];\n    _mm256_store_si256((__m256i*)sum_array, sum_vec);\n    \n    for (int i = 0; i < 32; i++) {\n        sum += (unsigned char)sum_array[i];\n    }\n    \n    for (size_t i = vectorLen; i < len; i++) {\n        if (s[i] >= 'A' && s[i] <= 'Z') {\n            sum += s[i];\n        }\n    }\n    \n    return sum;\n}\n```"}
{"task_id": "SimdBench_93_AVX", "completion": "```cpp\nint digitSum_simd(std::string s) {\n    int sum = 0;\n    size_t len = s.length();\n    size_t vec_size = 32;\n    \n    if (len == 0) return 0;\n\n    // Process 32 characters at a time using AVX2\n    size_t vec_len = len - (len % vec_size);\n    __m256i sum_vec = _mm256_setzero_si256();\n    __m256i upper_mask = _mm256_set1_epi8(0x40);\n    __m256i lower_mask = _mm256_set1_epi8(0x5B);\n    \n    for (size_t i = 0; i < vec_len; i += vec_size) {\n        __m256i chars = _mm256_loadu_si256((__m256i*)(s.data() + i));\n        \n        // Check if characters are uppercase (between 0x41 and 0x5A)\n        __m256i gt_mask = _mm256_cmpgt_epi8(chars, upper_mask);\n        __m256i lt_mask = _mm256_cmpgt_epi8(lower_mask, chars);\n        __m256i is_upper = _mm256_and_si256(gt_mask, lt_mask);\n        \n        // Zero out non-uppercase characters\n        chars = _mm256_and_si256(chars, is_upper);\n        \n        // Add to running sum\n        sum_vec = _mm256_add_epi8(sum_vec, chars);\n    }\n    \n    // Horizontal sum of vector\n    __m128i sum_128 = _mm_add_epi8(_mm256_extracti128_si256(sum_vec, 0),\n                                   _mm256_extracti128_si256(sum_vec, 1));\n    __m128i sum_64 = _mm_add_epi8(sum_128, _mm_srli_si128(sum_128, 8));\n    __m128i sum_32 = _mm_add_epi8(sum_64, _mm_srli_si128(sum_64, 4));\n    __m128i sum_16 = _mm_add_epi8(sum_32, _mm_srli_si128(sum_32, 2));\n    __m128i sum_8 = _mm_add_epi8(sum_16, _mm_srli_si128(sum_16, 1));\n    sum += _mm_extract_epi8(sum_8, 0);\n    \n    // Process remaining characters\n    for (size_t i = vec_len; i < len; i++) {\n        if (s[i] >= 'A' && s[i] <= 'Z') {\n            sum += s[i];\n        }\n    }\n    \n    return sum;\n}\n```"}
{"task_id": "SimdBench_93_AVX", "completion": "```cpp\nint digitSum_simd(std::string s) {\n    int sum = 0;\n    size_t len = s.length();\n    size_t vec_size = 32;\n    \n    if (len == 0) return 0;\n\n    // Process 32 characters at a time using AVX2\n    size_t vec_len = len - (len % vec_size);\n    __m256i sum_vec = _mm256_setzero_si256();\n    __m256i upper_mask = _mm256_set1_epi8(0x40);\n    __m256i lower_mask = _mm256_set1_epi8(0x5B);\n    \n    for (size_t i = 0; i < vec_len; i += vec_size) {\n        __m256i chars = _mm256_loadu_si256((__m256i*)(s.data() + i));\n        \n        // Check if characters are uppercase (between 0x41 and 0x5A)\n        __m256i is_greater = _mm256_cmpgt_epi8(chars, upper_mask);\n        __m256i is_less = _mm256_cmpgt_epi8(lower_mask, chars);\n        __m256i is_upper = _mm256_and_si256(is_greater, is_less);\n        \n        // Zero out non-uppercase characters\n        chars = _mm256_and_si256(chars, is_upper);\n        \n        // Add to running sum\n        sum_vec = _mm256_add_epi8(sum_vec, chars);\n    }\n    \n    // Horizontal sum of vector\n    __m128i sum128 = _mm_add_epi8(_mm256_extracti128_si256(sum_vec, 0),\n                                  _mm256_extracti128_si256(sum_vec, 1));\n    __m128i sum64 = _mm_add_epi8(sum128, _mm_srli_si128(sum128, 8));\n    __m128i sum32 = _mm_add_epi8(sum64, _mm_srli_si128(sum64, 4));\n    __m128i sum16 = _mm_add_epi8(sum32, _mm_srli_si128(sum32, 2));\n    __m128i sum8 = _mm_add_epi8(sum16, _mm_srli_si128(sum16, 1));\n    sum += _mm_extract_epi8(sum8, 0);\n    \n    // Process remaining characters\n    for (size_t i = vec_len; i < len; i++) {\n        if (s[i] >= 'A' && s[i] <= 'Z') {\n            sum += s[i];\n        }\n    }\n    \n    return sum;\n}\n```"}
{"task_id": "SimdBench_93_AVX", "completion": "```cpp\nint digitSum_simd(std::string s) {\n    int sum = 0;\n    int len = s.length();\n    const char* str = s.c_str();\n    \n    // Process 32 characters at a time using AVX2\n    while (len >= 32) {\n        __m256i chars = _mm256_loadu_si256((__m256i*)str);\n        \n        // Create mask for uppercase letters (0x41-0x5A)\n        __m256i upper_mask = _mm256_and_si256(\n            _mm256_cmpgt_epi8(chars, _mm256_set1_epi8(0x40)),\n            _mm256_cmpgt_epi8(_mm256_set1_epi8(0x5B), chars)\n        );\n        \n        // Zero out non-uppercase characters\n        chars = _mm256_and_si256(chars, upper_mask);\n        \n        // Horizontal sum of bytes\n        __m256i sum_vec = _mm256_sad_epu8(chars, _mm256_setzero_si256());\n        \n        // Extract sums from high and low 128-bit lanes\n        __m128i sum_128 = _mm_add_epi32(\n            _mm256_castsi256_si128(sum_vec),\n            _mm256_extracti128_si256(sum_vec, 1)\n        );\n        \n        sum += _mm_cvtsi128_si32(sum_128) + \n               _mm_cvtsi128_si32(_mm_srli_si128(sum_128, 8));\n               \n        str += 32;\n        len -= 32;\n    }\n    \n    // Handle remaining characters\n    while (len > 0) {\n        if (*str >= 'A' && *str <= 'Z') {\n            sum += *str;\n        }\n        str++;\n        len--;\n    }\n    \n    return sum;\n}\n```"}
{"task_id": "SimdBench_94_AVX", "completion": "```cpp\nstd::vector<int> pluck_simd(std::vector<int> arr) {\n    if (arr.empty()) return {};\n    \n    const int n = arr.size();\n    const int simd_width = 8;\n    const int aligned_size = (n + simd_width - 1) & ~(simd_width - 1);\n    \n    std::vector<int> padded(aligned_size, INT_MAX);\n    std::copy(arr.begin(), arr.end(), padded.begin());\n\n    __m256i min_even = _mm256_set1_epi32(INT_MAX);\n    __m256i min_idx = _mm256_set1_epi32(INT_MAX);\n    __m256i curr_idx = _mm256_setr_epi32(0,1,2,3,4,5,6,7);\n    const __m256i idx_inc = _mm256_set1_epi32(simd_width);\n    const __m256i two = _mm256_set1_epi32(2);\n\n    for (int i = 0; i < aligned_size; i += simd_width) {\n        __m256i curr = _mm256_loadu_si256((__m256i*)&padded[i]);\n        __m256i is_even = _mm256_cmpeq_epi32(_mm256_and_si256(curr, two), _mm256_setzero_si256());\n        \n        __m256i masked_vals = _mm256_blendv_epi8(_mm256_set1_epi32(INT_MAX), curr, is_even);\n        __m256i masked_idx = _mm256_blendv_epi8(_mm256_set1_epi32(INT_MAX), curr_idx, is_even);\n        \n        __m256i lt_mask = _mm256_cmpgt_epi32(min_even, masked_vals);\n        min_even = _mm256_blendv_epi8(min_even, masked_vals, lt_mask);\n        min_idx = _mm256_blendv_epi8(min_idx, masked_idx, lt_mask);\n        \n        curr_idx = _mm256_add_epi32(curr_idx, idx_inc);\n    }\n\n    alignas(32) int min_vals[8];\n    alignas(32) int idx_vals[8];\n    _mm256_store_si256((__m256i*)min_vals, min_even);\n    _mm256_store_si256((__m256i*)idx_vals, min_idx);\n\n    int min_val = INT_MAX;\n    int min_index = INT_MAX;\n    \n    for (int i = 0; i < 8; i++) {\n        if (min_vals[i] < min_val) {\n            min_val = min_vals[i];\n            min_index = idx_vals[i];\n        }\n    }\n\n    if (min_val == INT_MAX) return {};\n    return {min_val, min_index};\n}\n```"}
{"task_id": "SimdBench_94_AVX", "completion": "```cpp\nstd::vector<int> pluck_simd(std::vector<int> arr) {\n    if (arr.empty()) return {};\n    \n    const int n = arr.size();\n    const int simd_width = 8;\n    const int aligned_size = (n + simd_width - 1) & ~(simd_width - 1);\n    \n    std::vector<int> padded(aligned_size, INT_MAX);\n    std::copy(arr.begin(), arr.end(), padded.begin());\n\n    __m256i min_even = _mm256_set1_epi32(INT_MAX);\n    __m256i min_idx = _mm256_set1_epi32(INT_MAX);\n    __m256i idx = _mm256_setr_epi32(0,1,2,3,4,5,6,7);\n    __m256i increment = _mm256_set1_epi32(simd_width);\n    \n    for (int i = 0; i < aligned_size; i += simd_width) {\n        __m256i curr = _mm256_loadu_si256((__m256i*)&padded[i]);\n        __m256i is_even = _mm256_cmpeq_epi32(_mm256_and_si256(curr, _mm256_set1_epi32(1)), _mm256_setzero_si256());\n        \n        __m256i masked_vals = _mm256_blendv_epi8(_mm256_set1_epi32(INT_MAX), curr, is_even);\n        __m256i curr_idx = _mm256_blendv_epi8(_mm256_set1_epi32(INT_MAX), idx, is_even);\n        \n        __m256i lt_mask = _mm256_cmpgt_epi32(min_even, masked_vals);\n        min_even = _mm256_blendv_epi8(min_even, masked_vals, lt_mask);\n        min_idx = _mm256_blendv_epi8(min_idx, curr_idx, lt_mask);\n        \n        idx = _mm256_add_epi32(idx, increment);\n    }\n    \n    alignas(32) int min_vals[8];\n    alignas(32) int indices[8];\n    _mm256_store_si256((__m256i*)min_vals, min_even);\n    _mm256_store_si256((__m256i*)indices, min_idx);\n    \n    int min_val = INT_MAX;\n    int min_index = INT_MAX;\n    \n    for(int i = 0; i < 8; i++) {\n        if(min_vals[i] < min_val) {\n            min_val = min_vals[i];\n            min_index = indices[i];\n        }\n    }\n    \n    if(min_val == INT_MAX) return {};\n    return {min_val, min_index};\n}\n```"}
{"task_id": "SimdBench_94_AVX", "completion": "```cpp\nstd::vector<int> pluck_simd(std::vector<int> arr) {\n    if (arr.empty()) return {};\n    \n    const int n = arr.size();\n    const int simd_width = 8;\n    const int num_iters = n / simd_width;\n    const int remainder = n % simd_width;\n    \n    __m256i min_even = _mm256_set1_epi32(INT_MAX);\n    __m256i min_idx = _mm256_set1_epi32(INT_MAX);\n    __m256i idx = _mm256_setr_epi32(0,1,2,3,4,5,6,7);\n    __m256i increment = _mm256_set1_epi32(simd_width);\n    \n    for (int i = 0; i < num_iters; i++) {\n        __m256i vals = _mm256_loadu_si256((__m256i*)&arr[i * simd_width]);\n        __m256i is_even = _mm256_and_si256(vals, _mm256_set1_epi32(1));\n        is_even = _mm256_cmpeq_epi32(is_even, _mm256_setzero_si256());\n        \n        __m256i masked_vals = _mm256_blendv_epi8(\n            _mm256_set1_epi32(INT_MAX),\n            vals,\n            is_even\n        );\n        \n        __m256i lt_mask = _mm256_cmpgt_epi32(min_even, masked_vals);\n        min_even = _mm256_blendv_epi8(min_even, masked_vals, lt_mask);\n        min_idx = _mm256_blendv_epi8(min_idx, idx, lt_mask);\n        \n        idx = _mm256_add_epi32(idx, increment);\n    }\n    \n    alignas(32) int min_vals[8];\n    alignas(32) int indices[8];\n    _mm256_store_si256((__m256i*)min_vals, min_even);\n    _mm256_store_si256((__m256i*)indices, min_idx);\n    \n    int min_val = INT_MAX;\n    int min_index = INT_MAX;\n    \n    for (int i = 0; i < 8; i++) {\n        if (min_vals[i] < min_val) {\n            min_val = min_vals[i];\n            min_index = indices[i];\n        }\n    }\n    \n    for (int i = num_iters * simd_width; i < n; i++) {\n        if ((arr[i] % 2 == 0) && arr[i] < min_val) {\n            min_val = arr[i];\n            min_index = i;\n        }\n    }\n    \n    if (min_val == INT_MAX) return {};\n    return {min_val, min_index};\n}\n```"}
{"task_id": "SimdBench_94_AVX", "completion": "```cpp\nstd::vector<int> pluck_simd(std::vector<int> arr) {\n    if (arr.empty()) return {};\n    \n    const int n = arr.size();\n    const int simd_width = 8;\n    const int aligned_size = (n + simd_width - 1) & ~(simd_width - 1);\n    \n    std::vector<int> padded(aligned_size, INT_MAX);\n    std::copy(arr.begin(), arr.end(), padded.begin());\n    \n    __m256i min_even = _mm256_set1_epi32(INT_MAX);\n    __m256i min_idx = _mm256_set1_epi32(INT_MAX);\n    __m256i idx = _mm256_setr_epi32(0,1,2,3,4,5,6,7);\n    __m256i increment = _mm256_set1_epi32(simd_width);\n    \n    for (int i = 0; i < aligned_size; i += simd_width) {\n        __m256i curr = _mm256_loadu_si256((__m256i*)&padded[i]);\n        __m256i is_even = _mm256_and_si256(curr, _mm256_set1_epi32(1));\n        is_even = _mm256_cmpeq_epi32(is_even, _mm256_setzero_si256());\n        \n        __m256i masked_vals = _mm256_blendv_epi8(\n            _mm256_set1_epi32(INT_MAX),\n            curr,\n            is_even\n        );\n        \n        __m256i lt_mask = _mm256_cmpgt_epi32(min_even, masked_vals);\n        min_even = _mm256_blendv_epi8(min_even, masked_vals, lt_mask);\n        min_idx = _mm256_blendv_epi8(min_idx, idx, lt_mask);\n        \n        idx = _mm256_add_epi32(idx, increment);\n    }\n    \n    alignas(32) int min_vals[8];\n    alignas(32) int indices[8];\n    \n    _mm256_store_si256((__m256i*)min_vals, min_even);\n    _mm256_store_si256((__m256i*)indices, min_idx);\n    \n    int min_val = INT_MAX;\n    int min_index = INT_MAX;\n    \n    for (int i = 0; i < 8; i++) {\n        if (min_vals[i] < min_val) {\n            min_val = min_vals[i];\n            min_index = indices[i];\n        }\n    }\n    \n    if (min_val == INT_MAX) return {};\n    return {min_val, min_index};\n}\n```"}
{"task_id": "SimdBench_94_AVX", "completion": "```cpp\nstd::vector<int> pluck_simd(std::vector<int> arr) {\n    if (arr.empty()) return {};\n    \n    const int n = arr.size();\n    const int simd_width = 8;\n    const int aligned_size = (n + simd_width - 1) & ~(simd_width - 1);\n    \n    std::vector<int> padded(aligned_size, INT_MAX);\n    std::copy(arr.begin(), arr.end(), padded.begin());\n    \n    __m256i min_even = _mm256_set1_epi32(INT_MAX);\n    __m256i min_idx = _mm256_set1_epi32(INT_MAX);\n    __m256i idx = _mm256_setr_epi32(0,1,2,3,4,5,6,7);\n    __m256i inc = _mm256_set1_epi32(simd_width);\n    \n    for (int i = 0; i < aligned_size; i += simd_width) {\n        __m256i curr = _mm256_loadu_si256((__m256i*)&padded[i]);\n        __m256i is_even = _mm256_cmpeq_epi32(_mm256_and_si256(curr, _mm256_set1_epi32(1)), _mm256_setzero_si256());\n        \n        __m256i masked_vals = _mm256_blendv_epi8(_mm256_set1_epi32(INT_MAX), curr, is_even);\n        __m256i curr_idx = _mm256_blendv_epi8(_mm256_set1_epi32(INT_MAX), idx, is_even);\n        \n        __m256i cmp = _mm256_cmpgt_epi32(min_even, masked_vals);\n        min_even = _mm256_blendv_epi8(min_even, masked_vals, cmp);\n        min_idx = _mm256_blendv_epi8(min_idx, curr_idx, cmp);\n        \n        idx = _mm256_add_epi32(idx, inc);\n    }\n    \n    alignas(32) int min_vals[8];\n    alignas(32) int indices[8];\n    \n    _mm256_store_si256((__m256i*)min_vals, min_even);\n    _mm256_store_si256((__m256i*)indices, min_idx);\n    \n    int min_val = INT_MAX;\n    int min_index = INT_MAX;\n    \n    for(int i = 0; i < 8; i++) {\n        if(min_vals[i] < min_val) {\n            min_val = min_vals[i];\n            min_index = indices[i];\n        }\n    }\n    \n    if(min_val == INT_MAX) return {};\n    return {min_val, min_index};\n}\n```"}
{"task_id": "SimdBench_95_AVX", "completion": "```cpp\nint search_simd(std::vector<int> lst) {\n    if (lst.empty()) return -1;\n    \n    // Create frequency array\n    int max_val = *std::max_element(lst.begin(), lst.end());\n    std::vector<int> freq(max_val + 1, 0);\n    \n    // Count frequencies\n    for (int num : lst) {\n        freq[num]++;\n    }\n\n    // Process 8 elements at a time using AVX2\n    __m256i result = _mm256_set1_epi32(-1);\n    int max_result = -1;\n    \n    for (int i = 0; i <= max_val; i += 8) {\n        // Load 8 indices and frequencies\n        __m256i indices = _mm256_setr_epi32(i, i+1, i+2, i+3, i+4, i+5, i+6, i+7);\n        __m256i freqs;\n        if (i + 7 <= max_val) {\n            freqs = _mm256_loadu_si256((__m256i*)&freq[i]);\n        } else {\n            // Handle boundary case\n            int temp[8] = {0};\n            for(int j = 0; j < max_val-i+1; j++) {\n                temp[j] = freq[i+j];\n            }\n            freqs = _mm256_loadu_si256((__m256i*)temp);\n        }\n        \n        // Compare if frequency >= index and index > 0\n        __m256i freq_ge_idx = _mm256_cmpgt_epi32(freqs, _mm256_sub_epi32(indices, _mm256_set1_epi32(1)));\n        __m256i idx_gt_zero = _mm256_cmpgt_epi32(indices, _mm256_setzero_si256());\n        __m256i valid = _mm256_and_si256(freq_ge_idx, idx_gt_zero);\n        \n        // Update result where conditions are met\n        result = _mm256_blendv_epi8(result, indices, valid);\n    }\n    \n    // Extract maximum valid result\n    int results[8];\n    _mm256_storeu_si256((__m256i*)results, result);\n    for(int i = 0; i < 8; i++) {\n        if(results[i] > max_result) {\n            max_result = results[i];\n        }\n    }\n    \n    return max_result;\n}\n```"}
{"task_id": "SimdBench_95_AVX", "completion": "```cpp\nint search_simd(std::vector<int> lst) {\n    if (lst.empty()) return -1;\n    \n    // Find max element to determine frequency array size\n    int max_element = *std::max_element(lst.begin(), lst.end());\n    std::vector<int> freq(max_element + 1, 0);\n    \n    // Count frequencies\n    for (int num : lst) {\n        freq[num]++;\n    }\n\n    // Process 8 elements at a time using AVX2\n    __m256i result = _mm256_set1_epi32(-1);\n    int result_arr[8];\n    \n    for (int i = 0; i < freq.size(); i += 8) {\n        // Load 8 frequency counts\n        __m256i freq_vec;\n        if (i + 8 <= freq.size()) {\n            freq_vec = _mm256_loadu_si256((__m256i*)&freq[i]);\n        } else {\n            // Handle remaining elements\n            int temp[8] = {0};\n            for (int j = 0; j < freq.size() - i; j++) {\n                temp[j] = freq[i + j];\n            }\n            freq_vec = _mm256_loadu_si256((__m256i*)temp);\n        }\n\n        // Load indices\n        __m256i idx = _mm256_set_epi32(i+7, i+6, i+5, i+4, i+3, i+2, i+1, i);\n        \n        // Compare if frequency >= index\n        __m256i cmp = _mm256_cmpgt_epi32(freq_vec, _mm256_sub_epi32(idx, _mm256_set1_epi32(1)));\n        \n        // Update result where comparison is true and index is greater\n        __m256i mask = _mm256_and_si256(cmp, idx);\n        result = _mm256_max_epi32(result, mask);\n    }\n    \n    // Extract maximum valid result\n    _mm256_storeu_si256((__m256i*)result_arr, result);\n    \n    int max_result = -1;\n    for (int i = 0; i < 8; i++) {\n        if (result_arr[i] > max_result && result_arr[i] < freq.size() && \n            freq[result_arr[i]] >= result_arr[i]) {\n            max_result = result_arr[i];\n        }\n    }\n    \n    return max_result;\n}\n```"}
{"task_id": "SimdBench_95_AVX", "completion": "```cpp\nint search_simd(std::vector<int> lst) {\n    if (lst.empty()) return -1;\n    \n    // Create frequency array\n    int max_val = *std::max_element(lst.begin(), lst.end());\n    std::vector<int> freq(max_val + 1, 0);\n    \n    // Count frequencies\n    for (int x : lst) {\n        freq[x]++;\n    }\n\n    // Process 8 elements at a time using AVX2\n    __m256i result = _mm256_set1_epi32(-1);\n    int max_result = -1;\n    \n    for (int i = 0; i <= max_val; i += 8) {\n        // Load 8 indices and frequencies\n        __m256i indices = _mm256_setr_epi32(i, i+1, i+2, i+3, i+4, i+5, i+6, i+7);\n        __m256i freqs;\n        \n        if (i + 7 <= max_val) {\n            freqs = _mm256_loadu_si256((__m256i*)&freq[i]);\n        } else {\n            // Handle remaining elements\n            int temp[8] = {0};\n            for(int j = 0; j < max_val - i + 1; j++) {\n                temp[j] = freq[i + j];\n            }\n            freqs = _mm256_loadu_si256((__m256i*)temp);\n        }\n\n        // Compare if frequency >= index and index > 0\n        __m256i freq_ge_idx = _mm256_cmpgt_epi32(freqs, _mm256_sub_epi32(indices, _mm256_set1_epi32(1)));\n        __m256i idx_gt_zero = _mm256_cmpgt_epi32(indices, _mm256_setzero_si256());\n        __m256i valid = _mm256_and_si256(freq_ge_idx, idx_gt_zero);\n        \n        // Update result where conditions are met\n        result = _mm256_blendv_epi8(result, indices, valid);\n    }\n\n    // Extract maximum valid result\n    int results[8];\n    _mm256_storeu_si256((__m256i*)results, result);\n    \n    for(int i = 0; i < 8; i++) {\n        if(results[i] > max_result) {\n            max_result = results[i];\n        }\n    }\n\n    return max_result;\n}\n```"}
{"task_id": "SimdBench_95_AVX", "completion": "```cpp\nint search_simd(std::vector<int> lst) {\n    if (lst.empty()) return -1;\n    \n    // Get max element to determine frequency array size\n    int max_element = *std::max_element(lst.begin(), lst.end());\n    std::vector<int> freq(max_element + 1, 0);\n    \n    // Count frequencies\n    for (int num : lst) {\n        freq[num]++;\n    }\n\n    // Process 8 elements at a time using AVX2\n    __m256i result = _mm256_set1_epi32(-1);\n    int n = freq.size();\n    int i;\n    \n    for (i = 0; i + 8 <= n; i += 8) {\n        // Load 8 frequency counts\n        __m256i freq_vec = _mm256_loadu_si256((__m256i*)&freq[i]);\n        \n        // Load indices (i, i+1, i+2, ..., i+7)\n        __m256i idx = _mm256_set_epi32(i+7, i+6, i+5, i+4, i+3, i+2, i+1, i);\n        \n        // Compare if frequency >= index\n        __m256i cmp = _mm256_cmpgt_epi32(freq_vec, idx);\n        __m256i valid = _mm256_and_si256(cmp, idx);\n        \n        // Update result with max valid values\n        result = _mm256_max_epi32(result, valid);\n    }\n    \n    // Extract maximum from result vector\n    int max_val = -1;\n    int* res = (int*)&result;\n    for (int j = 0; j < 8; j++) {\n        if (res[j] > max_val) max_val = res[j];\n    }\n    \n    // Process remaining elements\n    for (; i < n; i++) {\n        if (freq[i] >= i && i > max_val) {\n            max_val = i;\n        }\n    }\n    \n    return max_val;\n}\n```"}
{"task_id": "SimdBench_95_AVX", "completion": "```cpp\nint search_simd(std::vector<int> lst) {\n    if (lst.empty()) return -1;\n    \n    const int n = lst.size();\n    int freq[10001] = {0};\n    \n    // Count frequencies using SIMD\n    int i = 0;\n    for (; i + 8 <= n; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&lst[i]);\n        for (int j = 0; j < 8; j++) {\n            freq[_mm256_extract_epi32(vec, j)]++;\n        }\n    }\n    \n    // Handle remaining elements\n    for (; i < n; i++) {\n        freq[lst[i]]++;\n    }\n    \n    // Find max value that appears at least as many times as its value\n    int result = -1;\n    __m256i zeros = _mm256_setzero_si256();\n    \n    for (i = 0; i + 8 <= 10001; i += 8) {\n        __m256i freqs = _mm256_loadu_si256((__m256i*)&freq[i]);\n        __m256i indices = _mm256_set_epi32(i+7, i+6, i+5, i+4, i+3, i+2, i+1, i);\n        \n        // Compare if frequency >= index\n        __m256i cmp = _mm256_cmpgt_epi32(freqs, zeros);\n        __m256i valid = _mm256_and_si256(cmp, \n            _mm256_cmpge_epi32(freqs, indices));\n            \n        if (_mm256_movemask_ps(_mm256_castsi256_ps(valid))) {\n            for (int j = 0; j < 8; j++) {\n                int idx = i + j;\n                if (freq[idx] >= idx && idx > result) {\n                    result = idx;\n                }\n            }\n        }\n    }\n    \n    // Check remaining elements\n    for (; i < 10001; i++) {\n        if (freq[i] >= i && i > result) {\n            result = i;\n        }\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_96_AVX", "completion": "```cpp\nbool will_it_fly_simd(std::vector<int> q, int w) {\n    int size = q.size();\n    \n    // Check sum <= w using SIMD\n    __m256i sum_vec = _mm256_setzero_si256();\n    for (int i = 0; i < size - 7; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&q[i]);\n        sum_vec = _mm256_add_epi32(sum_vec, vec);\n    }\n    \n    int sum = 0;\n    int* temp = (int*)&sum_vec;\n    for (int i = 0; i < 8; i++) {\n        sum += temp[i];\n    }\n    \n    // Add remaining elements\n    for (int i = size - (size % 8); i < size; i++) {\n        sum += q[i];\n    }\n    \n    if (sum > w) return false;\n    \n    // Check palindrome using SIMD\n    int half = size / 2;\n    for (int i = 0; i < half - 7; i += 8) {\n        __m256i front = _mm256_loadu_si256((__m256i*)&q[i]);\n        __m256i back = _mm256_loadu_si256((__m256i*)&q[size-8-i]);\n        back = _mm256_shuffle_epi32(back, 0x1b); // Reverse order\n        __m256i cmp = _mm256_cmpeq_epi32(front, back);\n        int mask = _mm256_movemask_ps(_mm256_castsi256_ps(cmp));\n        if (mask != 0xFF) return false;\n    }\n    \n    // Check remaining elements\n    for (int i = half - (half % 8); i < half; i++) {\n        if (q[i] != q[size-1-i]) return false;\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_96_AVX", "completion": "```cpp\nbool will_it_fly_simd(std::vector<int> q, int w) {\n    int size = q.size();\n    \n    // Check sum <= w using SIMD\n    __m256i sum_vec = _mm256_setzero_si256();\n    for(int i = 0; i < size; i += 8) {\n        __m256i vec;\n        if(i + 8 <= size) {\n            vec = _mm256_loadu_si256((__m256i*)&q[i]);\n        } else {\n            alignas(32) int temp[8] = {0};\n            for(int j = 0; j < size-i; j++) {\n                temp[j] = q[i+j];\n            }\n            vec = _mm256_load_si256((__m256i*)temp);\n        }\n        sum_vec = _mm256_add_epi32(sum_vec, vec);\n    }\n    \n    alignas(32) int sum_arr[8];\n    _mm256_store_si256((__m256i*)sum_arr, sum_vec);\n    int total = 0;\n    for(int i = 0; i < 8; i++) {\n        total += sum_arr[i];\n    }\n    \n    if(total > w) return false;\n    \n    // Check palindrome using SIMD\n    int half = size/2;\n    for(int i = 0; i < half; i += 8) {\n        __m256i vec1, vec2;\n        if(i + 8 <= half) {\n            vec1 = _mm256_loadu_si256((__m256i*)&q[i]);\n            alignas(32) int rev[8];\n            for(int j = 0; j < 8; j++) {\n                rev[j] = q[size-1-(i+j)];\n            }\n            vec2 = _mm256_load_si256((__m256i*)rev);\n        } else {\n            alignas(32) int temp1[8] = {0};\n            alignas(32) int temp2[8] = {0};\n            for(int j = 0; j < half-i; j++) {\n                temp1[j] = q[i+j];\n                temp2[j] = q[size-1-(i+j)];\n            }\n            vec1 = _mm256_load_si256((__m256i*)temp1);\n            vec2 = _mm256_load_si256((__m256i*)temp2);\n        }\n        \n        __m256i cmp = _mm256_cmpeq_epi32(vec1, vec2);\n        int mask = _mm256_movemask_ps(_mm256_castsi256_ps(cmp));\n        if((mask & ((1 << (std::min(8, half-i)))-1)) != ((1 << (std::min(8, half-i)))-1)) {\n            return false;\n        }\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_96_AVX", "completion": "```cpp\nbool will_it_fly_simd(std::vector<int> q, int w) {\n    int size = q.size();\n    \n    // Check sum <= w using SIMD\n    __m256i sum_vec = _mm256_setzero_si256();\n    for(int i = 0; i < size; i += 8) {\n        __m256i vec;\n        if(i + 8 <= size) {\n            vec = _mm256_loadu_si256((__m256i*)&q[i]);\n        } else {\n            int remaining = size - i;\n            alignas(32) int temp[8] = {0};\n            for(int j = 0; j < remaining; j++) {\n                temp[j] = q[i+j];\n            }\n            vec = _mm256_load_si256((__m256i*)temp);\n        }\n        sum_vec = _mm256_add_epi32(sum_vec, vec);\n    }\n    \n    alignas(32) int sum_arr[8];\n    _mm256_store_si256((__m256i*)sum_arr, sum_vec);\n    int total = 0;\n    for(int i = 0; i < 8; i++) {\n        total += sum_arr[i];\n    }\n    \n    if(total > w) return false;\n    \n    // Check palindrome using SIMD\n    int half = size/2;\n    for(int i = 0; i < half; i += 8) {\n        __m256i front, back;\n        if(i + 8 <= half) {\n            front = _mm256_loadu_si256((__m256i*)&q[i]);\n            alignas(32) int rev[8];\n            for(int j = 0; j < 8; j++) {\n                rev[j] = q[size-1-(i+j)];\n            }\n            back = _mm256_load_si256((__m256i*)rev);\n        } else {\n            int remaining = half - i;\n            alignas(32) int temp1[8] = {0};\n            alignas(32) int temp2[8] = {0};\n            for(int j = 0; j < remaining; j++) {\n                temp1[j] = q[i+j];\n                temp2[j] = q[size-1-(i+j)];\n            }\n            front = _mm256_load_si256((__m256i*)temp1);\n            back = _mm256_load_si256((__m256i*)temp2);\n        }\n        \n        __m256i cmp = _mm256_cmpeq_epi32(front, back);\n        int mask = _mm256_movemask_ps(_mm256_castsi256_ps(cmp));\n        if((mask & ((1 << remaining) - 1)) != ((1 << remaining) - 1)) {\n            return false;\n        }\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_96_AVX", "completion": "```cpp\nbool will_it_fly_simd(std::vector<int> q, int w) {\n    int size = q.size();\n    if (size == 0) return false;\n    \n    // Check sum <= w using SIMD\n    __m256i sum_vec = _mm256_setzero_si256();\n    for (int i = 0; i < size; i += 8) {\n        __m256i vec;\n        if (i + 8 <= size) {\n            vec = _mm256_loadu_si256((__m256i*)&q[i]);\n        } else {\n            alignas(32) int temp[8] = {0};\n            for (int j = 0; j < size - i; j++) {\n                temp[j] = q[i + j];\n            }\n            vec = _mm256_load_si256((__m256i*)temp);\n        }\n        sum_vec = _mm256_add_epi32(sum_vec, vec);\n    }\n    \n    alignas(32) int sum_arr[8];\n    _mm256_store_si256((__m256i*)sum_arr, sum_vec);\n    int total = 0;\n    for (int i = 0; i < 8; i++) {\n        total += sum_arr[i];\n    }\n    if (total > w) return false;\n    \n    // Check palindrome using SIMD\n    int half = size / 2;\n    for (int i = 0; i < half; i += 8) {\n        __m256i front, back;\n        if (i + 8 <= half) {\n            front = _mm256_loadu_si256((__m256i*)&q[i]);\n            alignas(32) int temp[8];\n            for (int j = 0; j < 8; j++) {\n                temp[j] = q[size - 1 - (i + j)];\n            }\n            back = _mm256_load_si256((__m256i*)temp);\n        } else {\n            alignas(32) int temp1[8] = {0};\n            alignas(32) int temp2[8] = {0};\n            for (int j = 0; j < half - i; j++) {\n                temp1[j] = q[i + j];\n                temp2[j] = q[size - 1 - (i + j)];\n            }\n            front = _mm256_load_si256((__m256i*)temp1);\n            back = _mm256_load_si256((__m256i*)temp2);\n        }\n        \n        __m256i cmp = _mm256_cmpeq_epi32(front, back);\n        int mask = _mm256_movemask_ps(_mm256_castsi256_ps(cmp));\n        if ((mask & ((1 << (std::min(8, half - i))) - 1)) != ((1 << (std::min(8, half - i))) - 1)) {\n            return false;\n        }\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_96_AVX", "completion": "```cpp\nbool will_it_fly_simd(std::vector<int> q, int w) {\n    int size = q.size();\n    \n    // Check sum <= w using SIMD\n    __m256i sum_vec = _mm256_setzero_si256();\n    for(int i = 0; i < size; i += 8) {\n        __m256i vec;\n        if(i + 8 <= size) {\n            vec = _mm256_loadu_si256((__m256i*)&q[i]);\n        } else {\n            alignas(32) int temp[8] = {0};\n            for(int j = 0; j < size-i; j++) {\n                temp[j] = q[i+j];\n            }\n            vec = _mm256_load_si256((__m256i*)temp);\n        }\n        sum_vec = _mm256_add_epi32(sum_vec, vec);\n    }\n    \n    alignas(32) int sum_arr[8];\n    _mm256_store_si256((__m256i*)sum_arr, sum_vec);\n    int total = 0;\n    for(int i = 0; i < 8; i++) {\n        total += sum_arr[i];\n    }\n    \n    if(total > w) return false;\n    \n    // Check palindrome using SIMD\n    int half = size/2;\n    for(int i = 0; i < half; i += 8) {\n        __m256i front, back;\n        if(i + 8 <= half) {\n            front = _mm256_loadu_si256((__m256i*)&q[i]);\n            alignas(32) int temp[8];\n            for(int j = 0; j < 8; j++) {\n                temp[j] = q[size-1-i-j];\n            }\n            back = _mm256_load_si256((__m256i*)temp);\n        } else {\n            alignas(32) int temp_front[8] = {0};\n            alignas(32) int temp_back[8] = {0};\n            for(int j = 0; j < half-i; j++) {\n                temp_front[j] = q[i+j];\n                temp_back[j] = q[size-1-i-j];\n            }\n            front = _mm256_load_si256((__m256i*)temp_front);\n            back = _mm256_load_si256((__m256i*)temp_back);\n        }\n        \n        __m256i cmp = _mm256_cmpeq_epi32(front, back);\n        int mask = _mm256_movemask_ps(_mm256_castsi256_ps(cmp));\n        int required = (1 << min(8, half-i)) - 1;\n        if((mask & required) != required) return false;\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_97_AVX", "completion": "```cpp\nint smallest_change_simd(std::vector<int> arr) {\n    int n = arr.size();\n    int changes = 0;\n    \n    // Handle sizes less than 8 without SIMD\n    if (n < 8) {\n        for (int i = 0; i < n/2; i++) {\n            if (arr[i] != arr[n-1-i]) {\n                changes++;\n            }\n        }\n        return changes;\n    }\n\n    // Number of full AVX iterations (8 integers per iteration)\n    int simd_iters = n / 16;\n    \n    __m256i count = _mm256_setzero_si256();\n    \n    for (int i = 0; i < simd_iters; i++) {\n        // Load 8 elements from front and back\n        __m256i front = _mm256_loadu_si256((__m256i*)&arr[i*8]);\n        __m256i back = _mm256_loadu_si256((__m256i*)&arr[n-8-(i*8)]);\n        \n        // Reverse elements in back vector\n        back = _mm256_shuffle_epi32(back, _MM_SHUFFLE(0,1,2,3));\n        back = _mm256_permute2x128_si256(back, back, 1);\n        \n        // Compare front and reversed back\n        __m256i cmp = _mm256_cmpeq_epi32(front, back);\n        \n        // Count non-equal elements\n        __m256i ones = _mm256_set1_epi32(1);\n        __m256i masked = _mm256_andnot_si256(cmp, ones);\n        count = _mm256_add_epi32(count, masked);\n    }\n    \n    // Horizontal sum of count vector\n    int sum[8];\n    _mm256_storeu_si256((__m256i*)sum, count);\n    changes = sum[0] + sum[1] + sum[2] + sum[3] + \n             sum[4] + sum[5] + sum[6] + sum[7];\n    \n    // Handle remaining elements\n    int rem_start = simd_iters * 8;\n    for (int i = rem_start; i < n/2; i++) {\n        if (arr[i] != arr[n-1-i]) {\n            changes++;\n        }\n    }\n    \n    return changes;\n}\n```"}
{"task_id": "SimdBench_97_AVX", "completion": "```cpp\nint smallest_change_simd(std::vector<int> arr) {\n    int n = arr.size();\n    int changes = 0;\n    \n    // Handle sizes less than 8 without SIMD\n    if (n < 8) {\n        for (int i = 0; i < n/2; i++) {\n            if (arr[i] != arr[n-1-i]) {\n                changes++;\n            }\n        }\n        return changes;\n    }\n\n    int simd_iters = n/8;\n    int remainder = n % 8;\n    \n    for (int i = 0; i < simd_iters; i++) {\n        // Load 8 elements from front and back\n        __m256i front = _mm256_loadu_si256((__m256i*)&arr[i*8]);\n        __m256i back = _mm256_loadu_si256((__m256i*)&arr[n-8-(i*8)]);\n        \n        // Reverse elements in back vector\n        back = _mm256_permutevar8x32_epi32(back, _mm256_set_epi32(0,1,2,3,4,5,6,7));\n        \n        // Compare vectors\n        __m256i cmp = _mm256_cmpeq_epi32(front, back);\n        \n        // Get mask of comparisons\n        int mask = _mm256_movemask_ps(_mm256_castsi256_ps(cmp));\n        \n        // Count number of mismatches\n        changes += 8 - _mm_popcnt_u32(mask);\n    }\n    \n    // Handle remaining elements\n    int start = simd_iters * 8;\n    int end = n - start;\n    for (int i = 0; i < end/2; i++) {\n        if (arr[start + i] != arr[n-1-i]) {\n            changes++;\n        }\n    }\n    \n    return changes/2;\n}\n```"}
{"task_id": "SimdBench_97_AVX", "completion": "```cpp\nint smallest_change_simd(std::vector<int> arr) {\n    int n = arr.size();\n    int changes = 0;\n    \n    // Handle sizes less than 8 without SIMD\n    if (n < 8) {\n        for (int i = 0; i < n/2; i++) {\n            if (arr[i] != arr[n-1-i]) {\n                changes++;\n            }\n        }\n        return changes;\n    }\n\n    int simd_iters = n/16; // Process 16 elements at a time (8 pairs)\n    int remainder = n % 16;\n    \n    for (int i = 0; i < simd_iters; i++) {\n        // Load 8 elements from front and back\n        __m256i front = _mm256_loadu_si256((__m256i*)&arr[i*8]);\n        __m256i back = _mm256_loadu_si256((__m256i*)&arr[n-8-(i*8)]);\n        \n        // Reverse elements in back vector\n        back = _mm256_permutevar8x32_epi32(back, _mm256_set_epi32(0,1,2,3,4,5,6,7));\n        \n        // Compare elements\n        __m256i cmp = _mm256_cmpeq_epi32(front, back);\n        \n        // Get mask of comparisons\n        int mask = _mm256_movemask_ps(_mm256_castsi256_ps(cmp));\n        \n        // Count number of mismatches\n        changes += 8 - _mm_popcnt_u32(mask);\n    }\n    \n    // Handle remaining elements\n    int start = simd_iters * 8;\n    int end = n - start - remainder/2;\n    for (int i = start; i < end; i++) {\n        if (arr[i] != arr[n-1-i]) {\n            changes++;\n        }\n    }\n    \n    return changes;\n}\n```"}
{"task_id": "SimdBench_97_AVX", "completion": "```cpp\nint smallest_change_simd(std::vector<int> arr) {\n    int n = arr.size();\n    int changes = 0;\n    \n    // Handle sizes less than 8 without SIMD\n    if (n < 8) {\n        for (int i = 0; i < n/2; i++) {\n            if (arr[i] != arr[n-1-i]) {\n                changes++;\n            }\n        }\n        return changes;\n    }\n\n    // Number of full AVX iterations (8 integers per iteration)\n    int simd_iters = n / 16;\n    \n    __m256i* left = (__m256i*)arr.data();\n    \n    for (int i = 0; i < simd_iters; i++) {\n        // Load 8 integers from left side\n        __m256i left_vec = _mm256_loadu_si256(left + i);\n        \n        // Load 8 integers from right side in reverse order\n        int right_idx = n - 8 - (i * 8);\n        __m256i right_vec = _mm256_loadu_si256((__m256i*)&arr[right_idx]);\n        right_vec = _mm256_shuffle_epi32(right_vec, _MM_SHUFFLE(0,1,2,3));\n        right_vec = _mm256_permute2x128_si256(right_vec, right_vec, 1);\n        \n        // Compare vectors\n        __m256i cmp = _mm256_cmpeq_epi32(left_vec, right_vec);\n        \n        // Count non-matching elements\n        int mask = _mm256_movemask_ps(_mm256_castsi256_ps(cmp));\n        changes += 8 - _mm_popcnt_u32(mask);\n    }\n    \n    // Handle remaining elements\n    int rem_start = simd_iters * 8;\n    for (int i = rem_start; i < n/2; i++) {\n        if (arr[i] != arr[n-1-i]) {\n            changes++;\n        }\n    }\n    \n    return changes;\n}\n```"}
{"task_id": "SimdBench_97_AVX", "completion": "```cpp\nint smallest_change_simd(std::vector<int> arr) {\n    int n = arr.size();\n    int changes = 0;\n    \n    // Handle sizes less than 8 without SIMD\n    if (n < 8) {\n        for (int i = 0; i < n/2; i++) {\n            if (arr[i] != arr[n-1-i]) {\n                changes++;\n            }\n        }\n        return changes;\n    }\n\n    // Number of full AVX iterations (8 integers per iteration)\n    int simd_iters = n / 16;\n    \n    __m256i* left = (__m256i*)arr.data();\n    __m256i* right = (__m256i*)(arr.data() + n - 8);\n    \n    for (int i = 0; i < simd_iters; i++) {\n        // Load 8 integers from left and right sides\n        __m256i left_vec = _mm256_loadu_si256(left);\n        __m256i right_vec = _mm256_loadu_si256(right);\n        \n        // Reverse the right vector\n        right_vec = _mm256_shuffle_epi32(right_vec, _MM_SHUFFLE(0,1,2,3));\n        right_vec = _mm256_permute2x128_si256(right_vec, right_vec, 1);\n        \n        // Compare for equality\n        __m256i cmp = _mm256_cmpeq_epi32(left_vec, right_vec);\n        \n        // Count non-matching elements\n        int mask = _mm256_movemask_ps(_mm256_castsi256_ps(cmp));\n        changes += 8 - _mm_popcnt_u32(mask);\n        \n        left++;\n        right = (__m256i*)((int*)right - 8);\n    }\n    \n    // Handle remaining elements\n    int remaining = (n - simd_iters * 16) / 2;\n    for (int i = simd_iters * 8; i < simd_iters * 8 + remaining; i++) {\n        if (arr[i] != arr[n-1-i]) {\n            changes++;\n        }\n    }\n    \n    return changes;\n}\n```"}
{"task_id": "SimdBench_98_AVX", "completion": "```cpp\nstd::vector<std::string> total_match_simd(const std::vector<std::string>& lst1, const std::vector<std::string>& lst2) {\n    if (lst1.empty() && lst2.empty()) {\n        return {};\n    }\n\n    size_t total1 = 0;\n    size_t total2 = 0;\n    \n    // Process 8 characters at a time using AVX2\n    const int simd_width = 8;\n    \n    for (const auto& str : lst1) {\n        size_t len = str.length();\n        const char* ptr = str.c_str();\n        \n        size_t simd_iters = len / simd_width;\n        size_t remainder = len % simd_width;\n        \n        __m256i sum = _mm256_setzero_si256();\n        \n        for (size_t i = 0; i < simd_iters; i++) {\n            __m256i chars = _mm256_loadu_si256((__m256i*)(ptr + i * simd_width));\n            sum = _mm256_add_epi32(sum, _mm256_set1_epi32(1));\n        }\n        \n        // Sum up the SIMD counts\n        int temp[8];\n        _mm256_storeu_si256((__m256i*)temp, sum);\n        total1 += simd_iters * simd_width + remainder;\n    }\n\n    for (const auto& str : lst2) {\n        size_t len = str.length();\n        const char* ptr = str.c_str();\n        \n        size_t simd_iters = len / simd_width; \n        size_t remainder = len % simd_width;\n        \n        __m256i sum = _mm256_setzero_si256();\n        \n        for (size_t i = 0; i < simd_iters; i++) {\n            __m256i chars = _mm256_loadu_si256((__m256i*)(ptr + i * simd_width));\n            sum = _mm256_add_epi32(sum, _mm256_set1_epi32(1));\n        }\n        \n        int temp[8];\n        _mm256_storeu_si256((__m256i*)temp, sum);\n        total2 += simd_iters * simd_width + remainder;\n    }\n\n    return (total2 < total1) ? lst2 : lst1;\n}\n```"}
{"task_id": "SimdBench_98_AVX", "completion": "```cpp\nstd::vector<std::string> total_match_simd(const std::vector<std::string>& lst1, const std::vector<std::string>& lst2) {\n    if (lst1.empty() && lst2.empty()) {\n        return {};\n    }\n\n    size_t total1 = 0;\n    size_t total2 = 0;\n    \n    // Process 8 characters at a time using AVX2\n    const int simd_width = 8;\n    \n    for (const auto& str : lst1) {\n        size_t len = str.length();\n        const char* ptr = str.c_str();\n        \n        size_t simd_iters = len / simd_width;\n        size_t remainder = len % simd_width;\n        \n        __m256i sum = _mm256_setzero_si256();\n        \n        for (size_t i = 0; i < simd_iters; i++) {\n            __m256i chars = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(ptr + i * simd_width));\n            sum = _mm256_add_epi8(sum, chars);\n        }\n        \n        // Horizontal sum of vector\n        __m128i sum128 = _mm_add_epi8(_mm256_extracti128_si256(sum, 0),\n                                     _mm256_extracti128_si256(sum, 1));\n        __m128i sum64 = _mm_add_epi8(sum128, _mm_srli_si128(sum128, 8));\n        __m128i sum32 = _mm_add_epi8(sum64, _mm_srli_si128(sum64, 4));\n        __m128i sum16 = _mm_add_epi8(sum32, _mm_srli_si128(sum32, 2));\n        __m128i sum8 = _mm_add_epi8(sum16, _mm_srli_si128(sum16, 1));\n        total1 += _mm_extract_epi8(sum8, 0);\n        \n        // Add remaining characters\n        for (size_t i = simd_iters * simd_width; i < len; i++) {\n            total1 += 1;\n        }\n    }\n\n    for (const auto& str : lst2) {\n        size_t len = str.length();\n        const char* ptr = str.c_str();\n        \n        size_t simd_iters = len / simd_width;\n        size_t remainder = len % simd_width;\n        \n        __m256i sum = _mm256_setzero_si256();\n        \n        for (size_t i = 0; i < simd_iters; i++) {\n            __m256i chars = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(ptr + i * simd_width));\n            sum = _mm256_add_epi8(sum, chars);\n        }\n        \n        __m128i sum128 = _mm_add_epi8(_mm256_extracti128_si256(sum, 0),\n                                     _mm256_extracti128_si256(sum, 1));\n        __m128i sum64 = _mm_add_epi8(sum128, _mm_srli_si128(sum128, 8));\n        __m128i sum32 = _mm_add_epi8(sum64, _mm_srli_si128(sum64, 4));\n        __m128i sum16 = _mm_add_epi8(sum32, _mm_srli_si128(sum32, 2));\n        __m128i sum8 = _mm_add_epi8(sum16, _mm_srli_si128(sum16, 1));\n        total2 += _mm_extract_epi8(sum8, 0);\n        \n        for (size_t i = simd_iters * simd_width; i < len; i++) {\n            total2 += 1;\n        }\n    }\n\n    return total1 <= total2 ? lst1 : lst2;\n}\n```"}
{"task_id": "SimdBench_98_AVX", "completion": "```cpp\nstd::vector<std::string> total_match_simd(const std::vector<std::string>& lst1, const std::vector<std::string>& lst2) {\n    if (lst1.empty() && lst2.empty()) {\n        return {};\n    }\n\n    size_t total1 = 0;\n    size_t total2 = 0;\n    \n    // Process 8 characters at a time using AVX2\n    const size_t vec_size = 8;\n    \n    for (const auto& str : lst1) {\n        size_t len = str.length();\n        const char* ptr = str.c_str();\n        \n        size_t vec_count = len / vec_size;\n        __m256i sum = _mm256_setzero_si256();\n        \n        for (size_t i = 0; i < vec_count; i++) {\n            __m256i chars = _mm256_loadu_si256((__m256i*)(ptr + i * vec_size));\n            sum = _mm256_add_epi8(sum, chars);\n        }\n        \n        // Handle remaining characters\n        for (size_t i = vec_count * vec_size; i < len; i++) {\n            total1 += ptr[i];\n        }\n        \n        // Horizontal sum of vector\n        __m128i sum128 = _mm_add_epi8(_mm256_extracti128_si256(sum, 0),\n                                     _mm256_extracti128_si256(sum, 1));\n        __m128i sum64 = _mm_add_epi8(sum128, _mm_srli_si128(sum128, 8));\n        __m128i sum32 = _mm_add_epi8(sum64, _mm_srli_si128(sum64, 4));\n        __m128i sum16 = _mm_add_epi8(sum32, _mm_srli_si128(sum32, 2));\n        __m128i sum8 = _mm_add_epi8(sum16, _mm_srli_si128(sum16, 1));\n        total1 += _mm_extract_epi8(sum8, 0);\n    }\n\n    for (const auto& str : lst2) {\n        size_t len = str.length();\n        const char* ptr = str.c_str();\n        \n        size_t vec_count = len / vec_size;\n        __m256i sum = _mm256_setzero_si256();\n        \n        for (size_t i = 0; i < vec_count; i++) {\n            __m256i chars = _mm256_loadu_si256((__m256i*)(ptr + i * vec_size));\n            sum = _mm256_add_epi8(sum, chars);\n        }\n        \n        // Handle remaining characters\n        for (size_t i = vec_count * vec_size; i < len; i++) {\n            total2 += ptr[i];\n        }\n        \n        // Horizontal sum of vector\n        __m128i sum128 = _mm_add_epi8(_mm256_extracti128_si256(sum, 0),\n                                     _mm256_extracti128_si256(sum, 1));\n        __m128i sum64 = _mm_add_epi8(sum128, _mm_srli_si128(sum128, 8));\n        __m128i sum32 = _mm_add_epi8(sum64, _mm_srli_si128(sum64, 4));\n        __m128i sum16 = _mm_add_epi8(sum32, _mm_srli_si128(sum32, 2));\n        __m128i sum8 = _mm_add_epi8(sum16, _mm_srli_si128(sum16, 1));\n        total2 += _mm_extract_epi8(sum8, 0);\n    }\n\n    return total1 <= total2 ? lst1 : lst2;\n}\n```"}
{"task_id": "SimdBench_98_AVX", "completion": "```cpp\nstd::vector<std::string> total_match_simd(const std::vector<std::string>& lst1, const std::vector<std::string>& lst2) {\n    if (lst1.empty() && lst2.empty()) {\n        return {};\n    }\n\n    size_t total1 = 0;\n    size_t total2 = 0;\n    \n    // Process 8 characters at a time using AVX2\n    const size_t vec_size = 8;\n    \n    for (const auto& str : lst1) {\n        size_t len = str.length();\n        const char* ptr = str.c_str();\n        \n        size_t vec_count = len / vec_size;\n        __m256i sum = _mm256_setzero_si256();\n        \n        // Process 8 chars at a time\n        for (size_t i = 0; i < vec_count; i++) {\n            __m256i chars = _mm256_loadu_si256((__m256i*)(ptr + i * vec_size));\n            sum = _mm256_add_epi8(sum, chars);\n        }\n        \n        // Process remaining chars\n        for (size_t i = vec_count * vec_size; i < len; i++) {\n            total1 += ptr[i];\n        }\n        \n        // Horizontal sum of vector\n        __m128i sum128 = _mm_add_epi8(_mm256_extracti128_si256(sum, 0),\n                                     _mm256_extracti128_si256(sum, 1));\n        __m128i sum64 = _mm_add_epi8(sum128, _mm_srli_si128(sum128, 8));\n        __m128i sum32 = _mm_add_epi8(sum64, _mm_srli_si128(sum64, 4));\n        __m128i sum16 = _mm_add_epi8(sum32, _mm_srli_si128(sum32, 2));\n        __m128i sum8 = _mm_add_epi8(sum16, _mm_srli_si128(sum16, 1));\n        total1 += _mm_extract_epi8(sum8, 0);\n    }\n\n    for (const auto& str : lst2) {\n        size_t len = str.length();\n        const char* ptr = str.c_str();\n        \n        size_t vec_count = len / vec_size;\n        __m256i sum = _mm256_setzero_si256();\n        \n        for (size_t i = 0; i < vec_count; i++) {\n            __m256i chars = _mm256_loadu_si256((__m256i*)(ptr + i * vec_size));\n            sum = _mm256_add_epi8(sum, chars);\n        }\n        \n        for (size_t i = vec_count * vec_size; i < len; i++) {\n            total2 += ptr[i];\n        }\n        \n        __m128i sum128 = _mm_add_epi8(_mm256_extracti128_si256(sum, 0),\n                                     _mm256_extracti128_si256(sum, 1));\n        __m128i sum64 = _mm_add_epi8(sum128, _mm_srli_si128(sum128, 8));\n        __m128i sum32 = _mm_add_epi8(sum64, _mm_srli_si128(sum64, 4));\n        __m128i sum16 = _mm_add_epi8(sum32, _mm_srli_si128(sum32, 2));\n        __m128i sum8 = _mm_add_epi8(sum16, _mm_srli_si128(sum16, 1));\n        total2 += _mm_extract_epi8(sum8, 0);\n    }\n\n    return (total2 < total1) ? lst2 : lst1;\n}\n```"}
{"task_id": "SimdBench_98_AVX", "completion": "```cpp\nstd::vector<std::string> total_match_simd(const std::vector<std::string>& lst1, const std::vector<std::string>& lst2) {\n    if (lst1.empty() && lst2.empty()) {\n        return {};\n    }\n\n    size_t total1 = 0;\n    size_t total2 = 0;\n    \n    // Process 8 characters at a time using AVX2\n    const size_t vec_size = 8;\n    \n    for (const auto& str : lst1) {\n        size_t len = str.length();\n        const char* ptr = str.c_str();\n        \n        size_t vec_count = len / vec_size;\n        __m256i sum = _mm256_setzero_si256();\n        \n        for (size_t i = 0; i < vec_count; i++) {\n            __m256i chars = _mm256_loadu_si256((__m256i*)(ptr + i * vec_size));\n            sum = _mm256_add_epi8(sum, chars);\n        }\n        \n        // Handle remaining characters\n        for (size_t i = vec_count * vec_size; i < len; i++) {\n            total1 += ptr[i];\n        }\n        \n        // Horizontal sum of vector\n        __m128i sum128 = _mm_add_epi8(_mm256_extracti128_si256(sum, 0),\n                                     _mm256_extracti128_si256(sum, 1));\n        __m128i sum64 = _mm_add_epi8(sum128, _mm_srli_si128(sum128, 8));\n        __m128i sum32 = _mm_add_epi8(sum64, _mm_srli_si128(sum64, 4));\n        __m128i sum16 = _mm_add_epi8(sum32, _mm_srli_si128(sum32, 2));\n        __m128i sum8 = _mm_add_epi8(sum16, _mm_srli_si128(sum16, 1));\n        total1 += _mm_extract_epi8(sum8, 0);\n    }\n\n    for (const auto& str : lst2) {\n        size_t len = str.length();\n        const char* ptr = str.c_str();\n        \n        size_t vec_count = len / vec_size;\n        __m256i sum = _mm256_setzero_si256();\n        \n        for (size_t i = 0; i < vec_count; i++) {\n            __m256i chars = _mm256_loadu_si256((__m256i*)(ptr + i * vec_size));\n            sum = _mm256_add_epi8(sum, chars);\n        }\n        \n        // Handle remaining characters\n        for (size_t i = vec_count * vec_size; i < len; i++) {\n            total2 += ptr[i];\n        }\n        \n        // Horizontal sum of vector\n        __m128i sum128 = _mm_add_epi8(_mm256_extracti128_si256(sum, 0),\n                                     _mm256_extracti128_si256(sum, 1));\n        __m128i sum64 = _mm_add_epi8(sum128, _mm_srli_si128(sum128, 8));\n        __m128i sum32 = _mm_add_epi8(sum64, _mm_srli_si128(sum64, 4));\n        __m128i sum16 = _mm_add_epi8(sum32, _mm_srli_si128(sum32, 2));\n        __m128i sum8 = _mm_add_epi8(sum16, _mm_srli_si128(sum16, 1));\n        total2 += _mm_extract_epi8(sum8, 0);\n    }\n\n    return total2 < total1 ? lst2 : lst1;\n}\n```"}
{"task_id": "SimdBench_99_AVX", "completion": "```cpp\nbool is_simple_power_simd(uint64_t x, uint64_t n) {\n    if (x == 0) return false;\n    if (x == 1) return true;\n    if (n <= 1) return false;\n\n    __m256i vec_x = _mm256_set1_epi64x(x);\n    __m256i vec_n = _mm256_set1_epi64x(n);\n    __m256i result = _mm256_set1_epi64x(1);\n    __m256i one = _mm256_set1_epi64x(1);\n    \n    while (x > 1) {\n        if (x % n != 0) return false;\n        x /= n;\n    }\n    \n    return x == 1;\n}\n```"}
{"task_id": "SimdBench_99_AVX", "completion": "```cpp\nbool is_simple_power_simd(uint64_t x, uint64_t n) {\n    if (x == 0) return false;\n    if (x == 1) return true;\n    if (n <= 1) return false;\n    \n    __m256d vec_x = _mm256_set1_pd(x);\n    __m256d vec_n = _mm256_set1_pd(n);\n    __m256d result = _mm256_set1_pd(1.0);\n    \n    while (result[0] < x) {\n        result = _mm256_mul_pd(result, vec_n);\n        if (result[0] == x) return true;\n    }\n    \n    return false;\n}\n```"}
{"task_id": "SimdBench_99_AVX", "completion": "```cpp\nbool is_simple_power_simd(uint64_t x, uint64_t n) {\n    if (x == 0) return false;\n    if (x == 1) return true;\n    if (n <= 1) return false;\n\n    __m256i vec_x = _mm256_set1_epi64x(x);\n    __m256i vec_n = _mm256_set1_epi64x(n);\n    __m256i result = _mm256_set1_epi64x(1);\n    __m256i one = _mm256_set1_epi64x(1);\n    \n    while (true) {\n        __m256i cmp = _mm256_cmpeq_epi64(result, vec_x);\n        int mask = _mm256_movemask_epi8(cmp);\n        if (mask) return true;\n\n        __m256i next = _mm256_mul_epi32(result, vec_n);\n        \n        // Check if we've exceeded x\n        __m256i gt = _mm256_cmpgt_epi64(next, vec_x);\n        mask = _mm256_movemask_epi8(gt);\n        if (mask) return false;\n        \n        // Check if multiplication overflowed\n        __m256i div = _mm256_div_epi64(next, vec_n);\n        __m256i overflow = _mm256_cmpeq_epi64(div, result);\n        mask = _mm256_movemask_epi8(overflow);\n        if (!mask) return false;\n\n        result = next;\n    }\n    \n    return false;\n}\n```"}
{"task_id": "SimdBench_99_AVX", "completion": "```cpp\nbool is_simple_power_simd(uint64_t x, uint64_t n) {\n    if (x == 0) return false;\n    if (x == 1) return true;\n    if (n <= 1) return false;\n\n    __m256i vec_x = _mm256_set1_epi64x(x);\n    __m256i vec_n = _mm256_set1_epi64x(n);\n    __m256i result = _mm256_set1_epi64x(1);\n    __m256i one = _mm256_set1_epi64x(1);\n    \n    while (true) {\n        __m256i cmp = _mm256_cmpeq_epi64(result, vec_x);\n        int mask = _mm256_movemask_epi8(cmp);\n        if (mask != 0) return true;\n\n        if (_mm256_extract_epi64(result, 0) > x) return false;\n\n        result = _mm256_mul_epi32(result, vec_n);\n    }\n    \n    return false;\n}\n```"}
{"task_id": "SimdBench_99_AVX", "completion": "```cpp\nbool is_simple_power_simd(uint64_t x, uint64_t n) {\n    if (x == 0 || n == 0 || n == 1) return false;\n    if (x == 1) return true;\n\n    __m256i vec_x = _mm256_set1_epi64x(x);\n    __m256i vec_n = _mm256_set1_epi64x(n);\n    __m256i result = _mm256_set1_epi64x(1);\n    __m256i one = _mm256_set1_epi64x(1);\n    \n    while (true) {\n        __m256i cmp = _mm256_cmpeq_epi64(result, vec_x);\n        int mask = _mm256_movemask_epi8(cmp);\n        if (mask) return true;\n\n        __m256i next = _mm256_mul_epu32(result, vec_n);\n        \n        // Check if we've exceeded x\n        __m256i gt = _mm256_cmpgt_epi64(next, vec_x);\n        mask = _mm256_movemask_epi8(gt);\n        if (mask) return false;\n        \n        // Check if multiplication overflowed\n        __m256i div = _mm256_div_epu32(next, vec_n);\n        __m256i overflow = _mm256_cmpeq_epi64(div, result);\n        mask = _mm256_movemask_epi8(overflow);\n        if (!mask) return false;\n\n        result = next;\n    }\n    \n    return false;\n}\n```"}
{"task_id": "SimdBench_100_AVX", "completion": "```cpp\nint hex_key_simd(const std::string & num) {\n    if(num.empty()) return 0;\n    \n    const int len = num.length();\n    int count = 0;\n    \n    // Create constant vectors for comparison\n    __m256i prime_vec = _mm256_set1_epi8(0);\n    uint8_t prime_mask[32] = {0};\n    \n    // Set 1s for prime hex digits (2,3,5,7,B,D)\n    prime_mask[2] = 1;  // 2\n    prime_mask[3] = 1;  // 3 \n    prime_mask[5] = 1;  // 5\n    prime_mask[7] = 1;  // 7\n    prime_mask[11] = 1; // B\n    prime_mask[13] = 1; // D\n    \n    prime_vec = _mm256_loadu_si256((__m256i*)prime_mask);\n\n    for(int i = 0; i < len; i += 32) {\n        __m256i char_vec;\n        uint8_t temp[32] = {0};\n        \n        // Load next 32 characters or remaining\n        int remaining = std::min(32, len - i);\n        for(int j = 0; j < remaining; j++) {\n            char c = num[i + j];\n            if(c >= '0' && c <= '9')\n                temp[j] = c - '0';\n            else\n                temp[j] = c - 'A' + 10;\n        }\n        \n        char_vec = _mm256_loadu_si256((__m256i*)temp);\n        \n        // Compare with prime mask\n        __m256i cmp = _mm256_cmpeq_epi8(\n            _mm256_and_si256(prime_vec, \n                _mm256_set1_epi8(1)),\n            _mm256_and_si256(\n                _mm256_shuffle_epi8(prime_vec, char_vec),\n                _mm256_set1_epi8(1))\n        );\n        \n        // Count matches\n        uint32_t mask = _mm256_movemask_epi8(cmp);\n        while(remaining > 0) {\n            count += mask & 1;\n            mask >>= 1;\n            remaining--;\n        }\n    }\n    \n    return count;\n}\n```"}
{"task_id": "SimdBench_100_AVX", "completion": "```cpp\nint hex_key_simd(const std::string & num) {\n    if (num.empty()) return 0;\n    \n    int len = num.length();\n    int count = 0;\n    \n    // Load prime hex digits into vector\n    __m256i primes = _mm256_setr_epi8('2', '3', '5', '7', 'B', 'D', 0, 0,\n                                     '2', '3', '5', '7', 'B', 'D', 0, 0,\n                                     '2', '3', '5', '7', 'B', 'D', 0, 0,\n                                     '2', '3', '5', '7', 'B', 'D', 0, 0);\n                                     \n    // Process 32 characters at a time\n    for (int i = 0; i < len; i += 32) {\n        __m256i input;\n        if (i + 32 <= len) {\n            input = _mm256_loadu_si256((__m256i*)(num.c_str() + i));\n        } else {\n            // Handle remaining characters\n            char temp[32] = {0};\n            memcpy(temp, num.c_str() + i, len - i);\n            input = _mm256_loadu_si256((__m256i*)temp);\n        }\n        \n        // Compare input with each prime digit\n        __m256i cmp2 = _mm256_cmpeq_epi8(input, primes);\n        \n        // Get mask of matches\n        int mask = _mm256_movemask_epi8(cmp2);\n        \n        // Count set bits in mask\n        count += _mm_popcnt_u32(mask);\n    }\n    \n    return count;\n}\n```"}
{"task_id": "SimdBench_100_AVX", "completion": "```cpp\nint hex_key_simd(const std::string & num) {\n    if (num.empty()) return 0;\n    \n    const int len = num.length();\n    int count = 0;\n    \n    __m256i primes = _mm256_setr_epi8('2', '3', '5', '7', 'B', 'D', 0, 0,\n                                     '2', '3', '5', '7', 'B', 'D', 0, 0,\n                                     '2', '3', '5', '7', 'B', 'D', 0, 0,\n                                     '2', '3', '5', '7', 'B', 'D', 0, 0);\n                                     \n    for (int i = 0; i < len; i += 16) {\n        __m256i input;\n        if (len - i >= 16) {\n            input = _mm256_loadu_si256((__m256i*)(num.c_str() + i));\n        } else {\n            char padded[32] = {0};\n            memcpy(padded, num.c_str() + i, len - i);\n            input = _mm256_loadu_si256((__m256i*)padded);\n        }\n        \n        __m256i cmp1 = _mm256_cmpeq_epi8(input, primes);\n        __m256i cmp2 = _mm256_permute2x128_si256(input, input, 0x00);\n        __m256i cmp3 = _mm256_cmpeq_epi8(cmp2, primes);\n        \n        __m256i result = _mm256_or_si256(cmp1, cmp3);\n        \n        uint32_t mask = _mm256_movemask_epi8(result);\n        \n        while (mask) {\n            count += mask & 1;\n            mask >>= 1;\n        }\n    }\n    \n    return count;\n}\n```"}
{"task_id": "SimdBench_100_AVX", "completion": "```cpp\nint hex_key_simd(const std::string & num) {\n    if (num.empty()) return 0;\n    \n    const int len = num.length();\n    int count = 0;\n    \n    __m256i primes = _mm256_setr_epi8('2', '3', '5', '7', 'B', 'D', 0, 0,\n                                     '2', '3', '5', '7', 'B', 'D', 0, 0,\n                                     '2', '3', '5', '7', 'B', 'D', 0, 0,\n                                     '2', '3', '5', '7', 'B', 'D', 0, 0);\n                                     \n    for (int i = 0; i < len; i += 16) {\n        __m256i input;\n        if (len - i >= 16) {\n            input = _mm256_loadu_si256((__m256i*)(num.c_str() + i));\n        } else {\n            char padded[32] = {0};\n            memcpy(padded, num.c_str() + i, len - i);\n            input = _mm256_loadu_si256((__m256i*)padded);\n        }\n        \n        __m256i cmp0 = _mm256_cmpeq_epi8(input, primes);\n        __m256i cmp1 = _mm256_permute4x64_epi64(input, 0x4E);\n        cmp1 = _mm256_cmpeq_epi8(cmp1, primes);\n        \n        __m256i result = _mm256_or_si256(cmp0, cmp1);\n        \n        int mask = _mm256_movemask_epi8(result);\n        \n        while (mask) {\n            count += mask & 1;\n            mask >>= 1;\n        }\n    }\n    \n    return count;\n}\n```"}
{"task_id": "SimdBench_100_AVX", "completion": "```cpp\nint hex_key_simd(const std::string & num) {\n    if(num.empty()) return 0;\n    \n    const int len = num.length();\n    const char* str = num.c_str();\n    \n    __m256i primes = _mm256_setr_epi8('2', '3', '5', '7', 'B', 'D', 0, 0,\n                                     '2', '3', '5', '7', 'B', 'D', 0, 0,\n                                     '2', '3', '5', '7', 'B', 'D', 0, 0,\n                                     '2', '3', '5', '7', 'B', 'D', 0, 0);\n                                     \n    int count = 0;\n    int i = 0;\n    \n    for(; i + 32 <= len; i += 32) {\n        __m256i input = _mm256_loadu_si256((__m256i*)(str + i));\n        \n        __m256i cmp1 = _mm256_cmpeq_epi8(input, primes);\n        uint32_t mask = _mm256_movemask_epi8(cmp1);\n        count += _mm_popcnt_u32(mask);\n    }\n    \n    for(; i < len; i++) {\n        char c = str[i];\n        if(c == '2' || c == '3' || c == '5' || c == '7' || c == 'B' || c == 'D') {\n            count++;\n        }\n    }\n    \n    return count;\n}\n```"}
{"task_id": "SimdBench_101_AVX", "completion": "```cpp\nbool is_happy_simd(const std::string & s) {\n    if (s.length() < 3) {\n        return false;\n    }\n\n    const int len = s.length();\n    const int simd_width = 32;\n    const int vec_size = len - 2;\n    \n    __m256i ones = _mm256_set1_epi8(1);\n    __m256i zeros = _mm256_setzero_si256();\n    \n    for (int i = 0; i < vec_size; i += simd_width) {\n        int chunk_size = std::min(simd_width, vec_size - i);\n        \n        if (chunk_size < 3) break;\n        \n        for (int j = 0; j < chunk_size - 2; j++) {\n            char a = s[i + j];\n            char b = s[i + j + 1]; \n            char c = s[i + j + 2];\n            \n            if (a == b || b == c || a == c) {\n                return false;\n            }\n        }\n    }\n    \n    // Handle remaining elements\n    for (int i = (vec_size/simd_width)*simd_width; i <= len-3; i++) {\n        if (s[i] == s[i+1] || s[i+1] == s[i+2] || s[i] == s[i+2]) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_101_AVX", "completion": "```cpp\nbool is_happy_simd(const std::string & s) {\n    if (s.length() < 3) {\n        return false;\n    }\n\n    const int len = s.length();\n    const int simd_width = 32;\n    const int vec_size = len - 2;\n    \n    // Pad input to multiple of 32 bytes\n    std::string padded = s;\n    padded.resize((vec_size + simd_width - 1) & ~(simd_width - 1), 0);\n    \n    __m256i result = _mm256_setzero_si256();\n    \n    for (int i = 0; i < vec_size; i += 32) {\n        // Load 32 bytes\n        __m256i curr = _mm256_loadu_si256((__m256i*)(padded.data() + i));\n        __m256i next1 = _mm256_loadu_si256((__m256i*)(padded.data() + i + 1));\n        __m256i next2 = _mm256_loadu_si256((__m256i*)(padded.data() + i + 2));\n\n        // Compare consecutive characters\n        __m256i eq1 = _mm256_cmpeq_epi8(curr, next1);\n        __m256i eq2 = _mm256_cmpeq_epi8(curr, next2);\n        __m256i eq3 = _mm256_cmpeq_epi8(next1, next2);\n        \n        // Combine results\n        __m256i any_equal = _mm256_or_si256(eq1, _mm256_or_si256(eq2, eq3));\n        \n        result = _mm256_or_si256(result, any_equal);\n    }\n\n    // Check remaining elements\n    int mask = _mm256_movemask_epi8(result);\n    for (int i = 0; i < vec_size; i++) {\n        if (mask & (1 << i)) {\n            return false;\n        }\n    }\n\n    // Check remaining elements serially\n    for (int i = (vec_size/32)*32; i < vec_size; i++) {\n        if (s[i] == s[i+1] || s[i] == s[i+2] || s[i+1] == s[i+2]) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_101_AVX", "completion": "```cpp\nbool is_happy_simd(const std::string & s) {\n    if (s.length() < 3) {\n        return false;\n    }\n\n    const int len = s.length();\n    const int simd_width = 32;\n    const int vec_size = len - 2;\n    \n    __m256i ones = _mm256_set1_epi8(1);\n    __m256i zeros = _mm256_setzero_si256();\n    \n    for (int i = 0; i < vec_size; i += simd_width) {\n        int chunk_size = std::min(simd_width, vec_size - i);\n        \n        if (chunk_size < 3) break;\n        \n        for (int j = i; j < i + chunk_size - 2; j++) {\n            char a = s[j];\n            char b = s[j+1]; \n            char c = s[j+2];\n            \n            if (a == b || b == c || a == c) {\n                return false;\n            }\n        }\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_101_AVX", "completion": "```cpp\nbool is_happy_simd(const std::string & s) {\n    if (s.length() < 3) {\n        return false;\n    }\n\n    const int len = s.length();\n    const int simd_width = 8;\n    const int vec_size = len - 2;\n    \n    __m256i ones = _mm256_set1_epi32(1);\n    \n    for (int i = 0; i <= vec_size - simd_width; i += simd_width) {\n        __m256i v1 = _mm256_loadu_si256((__m256i*)(s.data() + i));\n        __m256i v2 = _mm256_loadu_si256((__m256i*)(s.data() + i + 1)); \n        __m256i v3 = _mm256_loadu_si256((__m256i*)(s.data() + i + 2));\n\n        __m256i eq12 = _mm256_cmpeq_epi8(v1, v2);\n        __m256i eq23 = _mm256_cmpeq_epi8(v2, v3);\n        __m256i eq13 = _mm256_cmpeq_epi8(v1, v3);\n        \n        __m256i any_equal = _mm256_or_si256(_mm256_or_si256(eq12, eq23), eq13);\n        \n        if (_mm256_movemask_epi8(any_equal)) {\n            return false;\n        }\n    }\n\n    // Handle remaining elements\n    for (int i = (vec_size/simd_width)*simd_width; i < vec_size; i++) {\n        if (s[i] == s[i+1] || s[i+1] == s[i+2] || s[i] == s[i+2]) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_101_AVX", "completion": "```cpp\nbool is_happy_simd(const std::string & s) {\n    if (s.length() < 3) {\n        return false;\n    }\n\n    const int len = s.length();\n    const int simd_width = 32;\n    const int vec_size = len - 2;\n    \n    __m256i result = _mm256_setzero_si256();\n    \n    for (int i = 0; i < vec_size; i += simd_width) {\n        int chunk_size = std::min(simd_width, vec_size - i);\n        \n        if (chunk_size < simd_width) {\n            // Process remaining elements sequentially\n            for (int j = i; j < vec_size; j++) {\n                if (s[j] == s[j+1] || s[j] == s[j+2] || s[j+1] == s[j+2]) {\n                    return false;\n                }\n            }\n            break;\n        }\n\n        __m256i curr = _mm256_loadu_si256((__m256i*)(s.data() + i));\n        __m256i next = _mm256_loadu_si256((__m256i*)(s.data() + i + 1)); \n        __m256i next2 = _mm256_loadu_si256((__m256i*)(s.data() + i + 2));\n\n        __m256i eq1 = _mm256_cmpeq_epi8(curr, next);\n        __m256i eq2 = _mm256_cmpeq_epi8(curr, next2);\n        __m256i eq3 = _mm256_cmpeq_epi8(next, next2);\n\n        __m256i any_equal = _mm256_or_si256(eq1, _mm256_or_si256(eq2, eq3));\n        \n        if (_mm256_movemask_epi8(any_equal)) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_102_AVX", "completion": "```cpp\nbool prime_length_simd(const std::string& str) {\n    int len = str.length();\n    if (len <= 1) return false;\n    if (len == 2) return true;\n    if (len % 2 == 0) return false;\n\n    int sqrt_len = sqrt(len);\n    int nums_to_check = (sqrt_len - 1) / 8 + 1;\n    \n    __m256i divisors = _mm256_setr_epi32(3, 5, 7, 9, 11, 13, 15, 17);\n    __m256i len_vec = _mm256_set1_epi32(len);\n    \n    for (int i = 0; i < nums_to_check; i++) {\n        __m256i remainder = _mm256_rem_epi32(len_vec, divisors);\n        __m256i zero = _mm256_setzero_si256();\n        __m256i cmp = _mm256_cmpeq_epi32(remainder, zero);\n        int mask = _mm256_movemask_ps(_mm256_castsi256_ps(cmp));\n        \n        if (mask != 0) {\n            return false;\n        }\n        \n        divisors = _mm256_add_epi32(divisors, _mm256_set1_epi32(16));\n        \n        if (_mm256_extract_epi32(divisors, 0) > sqrt_len) {\n            break;\n        }\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_102_AVX", "completion": "```cpp\nbool prime_length_simd(const std::string& str) {\n    int len = str.length();\n    if (len <= 1) return false;\n    if (len == 2) return true;\n    if ((len & 1) == 0) return false;\n\n    int sqrt_len = sqrt(len);\n    int vec_size = (sqrt_len + 7) / 8 * 8;\n    \n    alignas(32) int numbers[8] = {0};\n    for (int i = 0; i < 8; i++) {\n        numbers[i] = i + 3;\n    }\n\n    __m256i vec_divisors = _mm256_load_si256((__m256i*)numbers);\n    __m256i vec_len = _mm256_set1_epi32(len);\n    __m256i vec_zero = _mm256_setzero_si256();\n    \n    for (int i = 3; i <= sqrt_len; i += 8) {\n        __m256i vec_rem = _mm256_rem_epi32(vec_len, vec_divisors);\n        __m256i vec_cmp = _mm256_cmpeq_epi32(vec_rem, vec_zero);\n        int mask = _mm256_movemask_ps(_mm256_castsi256_ps(vec_cmp));\n        \n        if (mask != 0) {\n            return false;\n        }\n        \n        for (int j = 0; j < 8; j++) {\n            numbers[j] += 8;\n        }\n        vec_divisors = _mm256_load_si256((__m256i*)numbers);\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_102_AVX", "completion": "```cpp\nbool prime_length_simd(const std::string & str) {\n    size_t len = str.length();\n    if (len <= 1) return false;\n    if (len == 2) return true;\n    if ((len & 1) == 0) return false;\n\n    __m256i nums = _mm256_setr_epi32(3, 5, 7, 9, 11, 13, 15, 17);\n    __m256i lens = _mm256_set1_epi32(len);\n    __m256i zeros = _mm256_setzero_si256();\n    \n    size_t sqrt_len = static_cast<size_t>(sqrt(len));\n    \n    for (int i = 3; i <= sqrt_len; i += 8) {\n        __m256i rem = _mm256_rem_epi32(lens, nums);\n        __m256i cmp = _mm256_cmpeq_epi32(rem, zeros);\n        int mask = _mm256_movemask_ps(_mm256_castsi256_ps(cmp));\n        \n        if (mask != 0) return false;\n        \n        nums = _mm256_add_epi32(nums, _mm256_set1_epi32(8));\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_102_AVX", "completion": "```cpp\nbool prime_length_simd(const std::string& str) {\n    size_t len = str.length();\n    if (len <= 1) return false;\n    if (len == 2) return true;\n    if (len % 2 == 0) return false;\n\n    size_t sqrt_len = static_cast<size_t>(sqrt(len));\n    size_t vec_size = (sqrt_len + 7) / 8 * 8;\n    \n    alignas(32) int numbers[8] = {0};\n    for(size_t i = 0; i < 8; i++) {\n        numbers[i] = i < vec_size ? 3 + i * 2 : 1;\n    }\n\n    __m256i increment = _mm256_set1_epi32(16);\n    __m256i divisors = _mm256_load_si256((__m256i*)numbers);\n    __m256i len_vec = _mm256_set1_epi32(len);\n    \n    for(; numbers[0] <= sqrt_len; ) {\n        __m256i remainder = _mm256_rem_epi32(len_vec, divisors);\n        __m256i zero = _mm256_setzero_si256();\n        __m256i cmp = _mm256_cmpeq_epi32(remainder, zero);\n        \n        int mask = _mm256_movemask_ps(_mm256_castsi256_ps(cmp));\n        if(mask != 0) return false;\n        \n        divisors = _mm256_add_epi32(divisors, increment);\n        _mm256_store_si256((__m256i*)numbers, divisors);\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_102_AVX", "completion": "```cpp\nbool prime_length_simd(const std::string& str) {\n    size_t len = str.length();\n    \n    if (len <= 1) return false;\n    if (len == 2) return true;\n    if (len % 2 == 0) return false;\n\n    size_t sqrt_len = static_cast<size_t>(sqrt(len));\n    size_t vec_size = (sqrt_len + 7) / 8 * 8;\n    \n    alignas(32) int numbers[8] = {0};\n    for(size_t i = 0; i < 8; i++) {\n        numbers[i] = i < vec_size ? 3 + i * 2 : 1;\n    }\n\n    __m256i vec_divisors = _mm256_load_si256((__m256i*)numbers);\n    __m256i vec_len = _mm256_set1_epi32(len);\n    __m256i vec_zero = _mm256_setzero_si256();\n    \n    for(size_t i = 0; i < vec_size; i += 8) {\n        __m256i vec_rem = _mm256_rem_epi32(vec_len, vec_divisors);\n        __m256i vec_cmp = _mm256_cmpeq_epi32(vec_rem, vec_zero);\n        \n        int mask = _mm256_movemask_ps(_mm256_castsi256_ps(vec_cmp));\n        if(mask != 0) return false;\n        \n        vec_divisors = _mm256_add_epi32(vec_divisors, _mm256_set1_epi32(16));\n        \n        if(_mm256_extract_epi32(vec_divisors, 0) > sqrt_len) {\n            break;\n        }\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_103_AVX", "completion": "```cpp\nstd::string solve_simd(uint64_t N) {\n    __m256i sum = _mm256_setzero_si256();\n    \n    while (N > 0) {\n        // Convert N to string\n        std::string num = std::to_string(N);\n        int len = num.length();\n        \n        // Process 32 digits at a time\n        while (len >= 32) {\n            char digits[32];\n            for (int i = 0; i < 32; i++) {\n                digits[i] = num[i] - '0';\n            }\n            \n            __m256i vec = _mm256_loadu_si256((__m256i*)digits);\n            sum = _mm256_add_epi8(sum, vec);\n            \n            num = num.substr(32);\n            len -= 32;\n        }\n        \n        // Process remaining digits\n        int remaining_sum = 0;\n        for (char c : num) {\n            remaining_sum += (c - '0');\n        }\n        \n        // Add remaining sum\n        __m256i remaining = _mm256_set1_epi8(remaining_sum);\n        sum = _mm256_add_epi8(sum, remaining);\n        \n        // Extract total sum\n        uint8_t total = 0;\n        uint8_t* sums = (uint8_t*)&sum;\n        for (int i = 0; i < 32; i++) {\n            total += sums[i];\n        }\n        \n        N = total;\n    }\n    \n    // Convert final sum to binary string\n    if (N == 0) return \"0\";\n    \n    std::string result;\n    while (N > 0) {\n        result = ((N & 1) ? \"1\" : \"0\") + result;\n        N >>= 1;\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_103_AVX", "completion": "```cpp\nstd::string solve_simd(uint64_t N) {\n    __m256i sum = _mm256_setzero_si256();\n    __m256i ten = _mm256_set1_epi32(10);\n    __m256i digits = _mm256_setzero_si256();\n    \n    while (N > 0) {\n        // Extract 8 digits at a time\n        for (int i = 0; i < 8 && N > 0; i++) {\n            int digit = N % 10;\n            N /= 10;\n            digits = _mm256_insert_epi32(digits, digit, i);\n        }\n        \n        // Add digits to running sum\n        sum = _mm256_add_epi32(sum, digits);\n        digits = _mm256_setzero_si256();\n    }\n    \n    // Horizontal sum of all elements\n    __m128i sum128 = _mm_add_epi32(_mm256_extracti128_si256(sum, 0),\n                                   _mm256_extracti128_si256(sum, 1));\n    sum128 = _mm_add_epi32(sum128, _mm_srli_si128(sum128, 8));\n    sum128 = _mm_add_epi32(sum128, _mm_srli_si128(sum128, 4));\n    int final_sum = _mm_cvtsi128_si32(sum128);\n    \n    if (final_sum == 0) return \"0\";\n    \n    std::string result;\n    while (final_sum > 0) {\n        result = (char)('0' + (final_sum & 1)) + result;\n        final_sum >>= 1;\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_103_AVX", "completion": "```cpp\nstd::string solve_simd(uint64_t N) {\n    __m256i sum = _mm256_setzero_si256();\n    \n    while (N > 0) {\n        // Convert N to string to process digits in parallel\n        char digits[32] = {0};\n        int len = snprintf(digits, sizeof(digits), \"%lu\", N);\n        \n        // Process 32 digits at a time using AVX\n        __m256i vec = _mm256_loadu_si256((__m256i*)digits);\n        \n        // Subtract '0' from each digit to get actual values\n        __m256i ascii_zero = _mm256_set1_epi8('0');\n        __m256i digit_vals = _mm256_sub_epi8(vec, ascii_zero);\n        \n        // Add to running sum\n        sum = _mm256_add_epi8(sum, digit_vals);\n        \n        N = N / 10;\n    }\n    \n    // Horizontal sum of all bytes\n    __m128i sum128 = _mm_add_epi8(_mm256_extracti128_si256(sum, 0),\n                                 _mm256_extracti128_si256(sum, 1));\n    __m128i sum64 = _mm_add_epi8(sum128, _mm_srli_si128(sum128, 8));\n    __m128i sum32 = _mm_add_epi8(sum64, _mm_srli_si128(sum64, 4));\n    __m128i sum16 = _mm_add_epi8(sum32, _mm_srli_si128(sum32, 2));\n    __m128i sum8 = _mm_add_epi8(sum16, _mm_srli_si128(sum16, 1));\n    \n    int final_sum = _mm_extract_epi8(sum8, 0);\n    \n    // Convert to binary string\n    std::string result;\n    while (final_sum > 0) {\n        result = (final_sum % 2 ? \"1\" : \"0\") + result;\n        final_sum /= 2;\n    }\n    \n    return result.empty() ? \"0\" : result;\n}\n```"}
{"task_id": "SimdBench_103_AVX", "completion": "```cpp\nstd::string solve_simd(uint64_t N) {\n    __m256i sum = _mm256_setzero_si256();\n    \n    while (N > 0) {\n        // Convert N to string\n        char digits[20];\n        int len = sprintf(digits, \"%llu\", N);\n        \n        // Process 8 digits at a time using AVX2\n        int i = 0;\n        for (; i + 8 <= len; i += 8) {\n            __m256i vec = _mm256_loadu_si256((__m256i*)(digits + i));\n            __m256i sub = _mm256_set1_epi8('0');\n            vec = _mm256_sub_epi8(vec, sub);\n            sum = _mm256_add_epi8(sum, vec);\n        }\n        \n        // Handle remaining digits\n        int remaining_sum = 0;\n        for (; i < len; i++) {\n            remaining_sum += (digits[i] - '0');\n        }\n        \n        // Horizontal sum of vector\n        __m128i sum128 = _mm_add_epi8(_mm256_extracti128_si256(sum, 0),\n                                     _mm256_extracti128_si256(sum, 1));\n        uint8_t* vals = (uint8_t*)&sum128;\n        int total = remaining_sum;\n        for (int i = 0; i < 16; i++) {\n            total += vals[i];\n        }\n        \n        // Update N for next iteration\n        N = total;\n        sum = _mm256_setzero_si256();\n    }\n    \n    // Convert final sum to binary string\n    std::string result;\n    do {\n        result = ((N & 1) ? \"1\" : \"0\") + result;\n        N >>= 1;\n    } while (N);\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_103_AVX", "completion": "```cpp\nstd::string solve_simd(uint64_t N) {\n    __m256i sum = _mm256_setzero_si256();\n    \n    while (N > 0) {\n        // Convert N to string to process digits in parallel\n        std::string num = std::to_string(N);\n        int len = num.length();\n        \n        // Process 8 digits at a time using AVX2\n        for (int i = 0; i < len; i += 8) {\n            __m256i digits;\n            char temp[32] = {0};\n            memcpy(temp, num.c_str() + i, std::min(8, len - i));\n            \n            // Load digits into vector\n            digits = _mm256_loadu_si256((__m256i*)temp);\n            \n            // Convert ASCII to integer by subtracting '0'\n            digits = _mm256_sub_epi32(digits, _mm256_set1_epi32('0'));\n            \n            // Add to running sum\n            sum = _mm256_add_epi32(sum, digits);\n        }\n        \n        // Extract sum from vector\n        int total = 0;\n        int* vals = (int*)&sum;\n        for (int i = 0; i < 8; i++) {\n            if (vals[i] >= 0 && vals[i] <= 9) {\n                total += vals[i];\n            }\n        }\n        \n        N = total;\n        sum = _mm256_setzero_si256();\n    }\n    \n    // Convert final sum to binary string\n    if (N == 0) return \"0\";\n    \n    std::string result;\n    while (N > 0) {\n        result = (char)('0' + (N & 1)) + result;\n        N >>= 1;\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_104_AVX", "completion": "```cpp\nint add_simd(std::vector<int> lst) {\n    int size = lst.size();\n    int sum = 0;\n    \n    __m256i indices = _mm256_setr_epi32(1, 3, 5, 7, 9, 11, 13, 15);\n    __m256i two = _mm256_set1_epi32(2);\n    \n    for(int i = 0; i < size; i += 8) {\n        __m256i curr;\n        if(i + 8 <= size) {\n            curr = _mm256_loadu_si256((__m256i*)(lst.data() + i));\n        } else {\n            int remaining = size - i;\n            alignas(32) int temp[8] = {0};\n            memcpy(temp, lst.data() + i, remaining * sizeof(int));\n            curr = _mm256_load_si256((__m256i*)temp);\n        }\n        \n        __m256i idx = _mm256_set1_epi32(i);\n        idx = _mm256_add_epi32(idx, indices);\n        \n        __m256i mask_idx = _mm256_cmpgt_epi32(idx, _mm256_set1_epi32(size-1));\n        __m256i mask_even = _mm256_and_si256(curr, _mm256_set1_epi32(1));\n        mask_even = _mm256_cmpeq_epi32(mask_even, _mm256_setzero_si256());\n        \n        __m256i combined_mask = _mm256_or_si256(mask_idx, mask_even);\n        curr = _mm256_andnot_si256(combined_mask, curr);\n        \n        __m256i sum_vec = _mm256_hadd_epi32(curr, curr);\n        sum_vec = _mm256_hadd_epi32(sum_vec, sum_vec);\n        \n        sum += _mm256_extract_epi32(sum_vec, 0) + _mm256_extract_epi32(sum_vec, 4);\n    }\n    \n    return sum;\n}\n```"}
{"task_id": "SimdBench_104_AVX", "completion": "```cpp\nint add_simd(std::vector<int> lst) {\n    int size = lst.size();\n    int result = 0;\n    \n    // Pad size to multiple of 8 for AVX\n    int padded_size = (size + 7) & ~7;\n    std::vector<int> padded(padded_size, 0);\n    std::copy(lst.begin(), lst.end(), padded.begin());\n\n    __m256i sum = _mm256_setzero_si256();\n    __m256i mask = _mm256_set1_epi32(1);\n    __m256i two = _mm256_set1_epi32(2);\n\n    for (int i = 0; i < padded_size; i += 8) {\n        __m256i vals = _mm256_loadu_si256((__m256i*)&padded[i]);\n        __m256i indices = _mm256_set_epi32(i+7, i+6, i+5, i+4, i+3, i+2, i+1, i);\n        \n        // Check for odd indices\n        __m256i odd_mask = _mm256_and_si256(indices, mask);\n        odd_mask = _mm256_cmpeq_epi32(odd_mask, mask);\n        \n        // Check for even values\n        __m256i even_mask = _mm256_and_si256(vals, two);\n        even_mask = _mm256_cmpeq_epi32(even_mask, _mm256_setzero_si256());\n        \n        // Combine masks\n        __m256i final_mask = _mm256_and_si256(odd_mask, even_mask);\n        \n        // Zero out non-matching elements\n        vals = _mm256_and_si256(vals, final_mask);\n        \n        sum = _mm256_add_epi32(sum, vals);\n    }\n\n    int temp[8];\n    _mm256_storeu_si256((__m256i*)temp, sum);\n    \n    for(int i = 0; i < 8; i++) {\n        result += temp[i];\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_104_AVX", "completion": "```cpp\nint add_simd(std::vector<int> lst) {\n    int size = lst.size();\n    int sum = 0;\n    \n    __m256i indices = _mm256_set_epi32(7, 6, 5, 4, 3, 2, 1, 0);\n    __m256i ones = _mm256_set1_epi32(1);\n    __m256i twos = _mm256_set1_epi32(2);\n    \n    for (int i = 0; i < size; i += 8) {\n        __m256i chunk;\n        if (i + 8 <= size) {\n            chunk = _mm256_loadu_si256((__m256i*)(lst.data() + i));\n        } else {\n            alignas(32) int temp[8] = {0};\n            for(int j = 0; j < size-i; j++) {\n                temp[j] = lst[i+j];\n            }\n            chunk = _mm256_load_si256((__m256i*)temp);\n        }\n\n        __m256i curr_indices = _mm256_add_epi32(indices, _mm256_set1_epi32(i));\n        \n        // Check for odd indices\n        __m256i odd_mask = _mm256_and_si256(curr_indices, ones);\n        odd_mask = _mm256_cmpeq_epi32(odd_mask, ones);\n        \n        // Check for even numbers\n        __m256i even_mask = _mm256_and_si256(chunk, twos);\n        even_mask = _mm256_cmpeq_epi32(even_mask, _mm256_setzero_si256());\n        \n        // Combine masks\n        __m256i final_mask = _mm256_and_si256(odd_mask, even_mask);\n        \n        // Zero out unwanted elements\n        chunk = _mm256_and_si256(chunk, final_mask);\n        \n        // Horizontal sum\n        __m128i sum128 = _mm_add_epi32(\n            _mm256_extracti128_si256(chunk, 0),\n            _mm256_extracti128_si256(chunk, 1)\n        );\n        sum128 = _mm_add_epi32(sum128, _mm_srli_si128(sum128, 8));\n        sum128 = _mm_add_epi32(sum128, _mm_srli_si128(sum128, 4));\n        sum += _mm_cvtsi128_si32(sum128);\n    }\n    \n    return sum;\n}\n```"}
{"task_id": "SimdBench_104_AVX", "completion": "```cpp\nint add_simd(std::vector<int> lst) {\n    int n = lst.size();\n    int sum = 0;\n    \n    // Pad size to multiple of 8\n    int padded_size = ((n + 7) / 8) * 8;\n    std::vector<int> padded(padded_size, 0);\n    std::copy(lst.begin(), lst.end(), padded.begin());\n\n    __m256i indices = _mm256_set_epi32(7, 6, 5, 4, 3, 2, 1, 0);\n    __m256i ones = _mm256_set1_epi32(1);\n    __m256i twos = _mm256_set1_epi32(2);\n    __m256i sum_vec = _mm256_setzero_si256();\n\n    for (int i = 0; i < padded_size; i += 8) {\n        // Load 8 integers\n        __m256i data = _mm256_loadu_si256((__m256i*)&padded[i]);\n        \n        // Create mask for odd indices\n        __m256i idx = _mm256_add_epi32(indices, _mm256_set1_epi32(i));\n        __m256i odd_mask = _mm256_and_si256(_mm256_cmpgt_epi32(idx, _mm256_setzero_si256()),\n                                           _mm256_cmpeq_epi32(_mm256_and_si256(idx, ones), ones));\n        \n        // Create mask for even values\n        __m256i even_mask = _mm256_cmpeq_epi32(_mm256_and_si256(data, twos), _mm256_setzero_si256());\n        \n        // Combine masks and add matching elements\n        __m256i mask = _mm256_and_si256(odd_mask, even_mask);\n        __m256i masked_data = _mm256_and_si256(data, mask);\n        sum_vec = _mm256_add_epi32(sum_vec, masked_data);\n    }\n\n    // Horizontal sum\n    __m128i sum128 = _mm_add_epi32(_mm256_extracti128_si256(sum_vec, 0),\n                                  _mm256_extracti128_si256(sum_vec, 1));\n    sum128 = _mm_add_epi32(sum128, _mm_srli_si128(sum128, 8));\n    sum128 = _mm_add_epi32(sum128, _mm_srli_si128(sum128, 4));\n    sum = _mm_cvtsi128_si32(sum128);\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_104_AVX", "completion": "```cpp\nint add_simd(std::vector<int> lst) {\n    int size = lst.size();\n    int sum = 0;\n    \n    // Pad vector size to multiple of 8 for AVX\n    int padded_size = (size + 7) & ~7;\n    lst.resize(padded_size, 0);\n    \n    __m256i sum_vec = _mm256_setzero_si256();\n    __m256i mask = _mm256_set1_epi32(1);\n    __m256i two = _mm256_set1_epi32(2);\n    \n    for(int i = 0; i < padded_size; i += 8) {\n        // Load 8 integers\n        __m256i vec = _mm256_loadu_si256((__m256i*)&lst[i]);\n        \n        // Create index mask\n        __m256i idx = _mm256_set_epi32(i+7, i+6, i+5, i+4, i+3, i+2, i+1, i);\n        __m256i odd_mask = _mm256_and_si256(idx, mask);\n        odd_mask = _mm256_cmpeq_epi32(odd_mask, mask);\n        \n        // Check for even numbers\n        __m256i even_mask = _mm256_and_si256(vec, two);\n        even_mask = _mm256_cmpeq_epi32(even_mask, _mm256_setzero_si256());\n        \n        // Combine masks\n        __m256i final_mask = _mm256_and_si256(odd_mask, even_mask);\n        \n        // Zero out non-matching elements\n        vec = _mm256_and_si256(vec, final_mask);\n        \n        // Add to running sum\n        sum_vec = _mm256_add_epi32(sum_vec, vec);\n    }\n    \n    // Horizontal sum\n    __m128i sum128 = _mm_add_epi32(\n        _mm256_extracti128_si256(sum_vec, 0),\n        _mm256_extracti128_si256(sum_vec, 1)\n    );\n    sum128 = _mm_add_epi32(sum128, _mm_srli_si128(sum128, 8));\n    sum128 = _mm_add_epi32(sum128, _mm_srli_si128(sum128, 4));\n    \n    sum = _mm_cvtsi128_si32(sum128);\n    \n    return sum;\n}\n```"}
{"task_id": "SimdBench_105_AVX", "completion": "```cpp\nstd::string encrypt_simd(const std::string& s) {\n    std::string result(s);\n    size_t len = s.length();\n    size_t simd_width = 32;\n    size_t vec_size = len - (len % simd_width);\n\n    for (size_t i = 0; i < vec_size; i += simd_width) {\n        __m256i chars = _mm256_loadu_si256((__m256i*)(s.data() + i));\n        \n        // Multiply by 2 and shift by 2\n        __m256i shift = _mm256_set1_epi8(4);\n        __m256i encrypted = _mm256_add_epi8(chars, shift);\n        \n        // Handle wrapping around alphabet\n        __m256i upper_bound = _mm256_set1_epi8('z');\n        __m256i lower_bound = _mm256_set1_epi8('a');\n        __m256i wrap_mask = _mm256_cmpgt_epi8(encrypted, upper_bound);\n        __m256i wrap_amount = _mm256_set1_epi8(26);\n        __m256i wrapped = _mm256_sub_epi8(encrypted, wrap_amount);\n        encrypted = _mm256_blendv_epi8(encrypted, wrapped, wrap_mask);\n        \n        _mm256_storeu_si256((__m256i*)(result.data() + i), encrypted);\n    }\n\n    // Handle remaining characters\n    for (size_t i = vec_size; i < len; i++) {\n        char c = s[i];\n        c = c + 4;\n        if (c > 'z') {\n            c = c - 26;\n        }\n        result[i] = c;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_105_AVX", "completion": "```cpp\nstd::string encrypt_simd(const std::string& s) {\n    if (s.empty()) return \"\";\n\n    size_t len = s.length();\n    std::string result(s);\n    \n    // Process 32 characters at a time using AVX2\n    size_t vectorSize = 32;\n    size_t vectorizedLength = len - (len % vectorSize);\n    \n    for (size_t i = 0; i < vectorizedLength; i += vectorSize) {\n        __m256i chars = _mm256_loadu_si256((__m256i*)(s.data() + i));\n        \n        // Multiply by 2 and shift by 2\n        __m256i shifted = _mm256_add_epi8(chars, _mm256_set1_epi8(4));\n        \n        // Store result\n        _mm256_storeu_si256((__m256i*)(result.data() + i), shifted);\n    }\n    \n    // Handle remaining characters\n    for (size_t i = vectorizedLength; i < len; i++) {\n        result[i] = s[i] + 4;\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_105_AVX", "completion": "```cpp\nstd::string encrypt_simd(const std::string& s) {\n    size_t len = s.length();\n    std::string result(len, 0);\n    \n    // Process 32 characters at a time using AVX2\n    size_t i = 0;\n    for (; i + 32 <= len; i += 32) {\n        __m256i input = _mm256_loadu_si256((__m256i*)(s.data() + i));\n        \n        // Multiply by 2 and shift by 2\n        __m256i shift = _mm256_set1_epi8(4);\n        __m256i encrypted = _mm256_add_epi8(input, shift);\n        \n        _mm256_storeu_si256((__m256i*)(result.data() + i), encrypted);\n    }\n    \n    // Handle remaining characters\n    for (; i < len; i++) {\n        result[i] = s[i] + 4;\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_105_AVX", "completion": "```cpp\nstd::string encrypt_simd(const std::string& s) {\n    if (s.empty()) return \"\";\n\n    size_t len = s.length();\n    std::string result(s);\n    \n    // Process 32 characters at a time using AVX2\n    size_t vectorSize = 32;\n    size_t vectorizedLen = len - (len % vectorSize);\n    \n    for (size_t i = 0; i < vectorizedLen; i += vectorSize) {\n        __m256i chars = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&s[i]));\n        \n        // Multiply by 2 and shift by 2\n        __m256i shift = _mm256_set1_epi8(4);\n        chars = _mm256_add_epi8(chars, shift);\n        \n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(&result[i]), chars);\n    }\n    \n    // Handle remaining characters\n    for (size_t i = vectorizedLen; i < len; i++) {\n        result[i] = s[i] + 4;\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_105_AVX", "completion": "```cpp\nstd::string encrypt_simd(const std::string& s) {\n    size_t len = s.length();\n    std::string result(len, 0);\n    \n    size_t i = 0;\n    \n    // Process 32 characters at a time using AVX2\n    for (; i + 32 <= len; i += 32) {\n        __m256i chars = _mm256_loadu_si256((__m256i*)(s.data() + i));\n        \n        // Multiply by 2 and shift by 2\n        __m256i shift = _mm256_set1_epi8(4);\n        __m256i encrypted = _mm256_add_epi8(chars, shift);\n        \n        _mm256_storeu_si256((__m256i*)(result.data() + i), encrypted);\n    }\n    \n    // Process remaining characters\n    for (; i < len; i++) {\n        result[i] = s[i] + 4;\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_106_AVX", "completion": "```cpp\nstd::string encode_simd(const std::string& message) {\n    std::string result = message;\n    size_t len = message.length();\n    size_t simd_size = 32;\n    size_t vec_size = len - (len % simd_size);\n\n    __m256i vowels = _mm256_setr_epi8(\n        'a', 'e', 'i', 'o', 'u', 'A', 'E', 'I', 'O', 'U',\n        'a', 'e', 'i', 'o', 'u', 'A', 'E', 'I', 'O', 'U',\n        'a', 'e', 'i', 'o', 'u', 'A', 'E', 'I', 'O', 'U',\n        'a', 'e');\n\n    __m256i vowel_replace = _mm256_setr_epi8(\n        'c', 'g', 'k', 'q', 'w', 'C', 'G', 'K', 'Q', 'W',\n        'c', 'g', 'k', 'q', 'w', 'C', 'G', 'K', 'Q', 'W',\n        'c', 'g', 'k', 'q', 'w', 'C', 'G', 'K', 'Q', 'W',\n        'c', 'g');\n\n    __m256i upper_mask = _mm256_set1_epi8(0x20);\n    __m256i upper_bound = _mm256_set1_epi8('z');\n    __m256i lower_bound = _mm256_set1_epi8('a');\n    __m256i upper_bound_cap = _mm256_set1_epi8('Z');\n    __m256i lower_bound_cap = _mm256_set1_epi8('A');\n\n    for (size_t i = 0; i < vec_size; i += simd_size) {\n        __m256i curr = _mm256_loadu_si256((__m256i*)(message.data() + i));\n        \n        // Check for vowels\n        __m256i is_vowel = _mm256_cmpeq_epi8(curr, vowels);\n        __m256i vowel_result = _mm256_blendv_epi8(curr, vowel_replace, is_vowel);\n        \n        // Change case\n        __m256i is_lower = _mm256_and_si256(\n            _mm256_cmpgt_epi8(curr, _mm256_set1_epi8('a'-1)),\n            _mm256_cmpgt_epi8(_mm256_set1_epi8('z'+1), curr)\n        );\n        \n        __m256i is_upper = _mm256_and_si256(\n            _mm256_cmpgt_epi8(curr, _mm256_set1_epi8('A'-1)),\n            _mm256_cmpgt_epi8(_mm256_set1_epi8('Z'+1), curr)\n        );\n\n        __m256i case_changed = _mm256_xor_si256(curr, \n            _mm256_and_si256(_mm256_or_si256(is_lower, is_upper), upper_mask));\n\n        // Combine vowel replacement and case change\n        __m256i final = _mm256_blendv_epi8(case_changed, vowel_result, is_vowel);\n        \n        _mm256_storeu_si256((__m256i*)(result.data() + i), final);\n    }\n\n    // Handle remaining characters\n    for (size_t i = vec_size; i < len; i++) {\n        char c = message[i];\n        if (c >= 'a' && c <= 'z') {\n            if (c == 'a' || c == 'e' || c == 'i' || c == 'o' || c == 'u') {\n                result[i] = c + 2;\n            } else {\n                result[i] = c - 32;\n            }\n        } else if (c >= 'A' && c <= 'Z') {\n            if (c == 'A' || c == 'E' || c == 'I' || c == 'O' || c == 'U') {\n                result[i] = c + 2 + 32;\n            } else {\n                result[i] = c + 32;\n            }\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_106_AVX", "completion": "```cpp\nstd::string encode_simd(const std::string& message) {\n    std::string result = message;\n    size_t len = message.length();\n    size_t simd_width = 32;\n    size_t vec_size = len - (len % simd_width);\n\n    __m256i vowels = _mm256_setr_epi8(\n        'a', 'e', 'i', 'o', 'u', 'A', 'E', 'I', 'O', 'U',\n        'a', 'e', 'i', 'o', 'u', 'A', 'E', 'I', 'O', 'U',\n        'a', 'e', 'i', 'o', 'u', 'A', 'E', 'I', 'O', 'U',\n        'a', 'e');\n\n    __m256i vowel_replacements = _mm256_setr_epi8(\n        'c', 'g', 'k', 'q', 'w', 'C', 'G', 'K', 'Q', 'W',\n        'c', 'g', 'k', 'q', 'w', 'C', 'G', 'K', 'Q', 'W',\n        'c', 'g', 'k', 'q', 'w', 'C', 'G', 'K', 'Q', 'W',\n        'c', 'g');\n\n    __m256i upper_mask = _mm256_set1_epi8(0x20);\n    __m256i lower_bound = _mm256_set1_epi8('a');\n    __m256i upper_bound = _mm256_set1_epi8('z');\n    __m256i upper_lower_bound = _mm256_set1_epi8('A');\n    __m256i upper_upper_bound = _mm256_set1_epi8('Z');\n\n    for (size_t i = 0; i < vec_size; i += simd_width) {\n        __m256i chars = _mm256_loadu_si256((__m256i*)(result.data() + i));\n        \n        // Check for vowels and replace\n        __m256i is_vowel = _mm256_cmpeq_epi8(chars, vowels);\n        chars = _mm256_blendv_epi8(chars, vowel_replacements, is_vowel);\n\n        // Swap case for letters\n        __m256i is_lower = _mm256_and_si256(\n            _mm256_cmpgt_epi8(chars, _mm256_sub_epi8(lower_bound, _mm256_set1_epi8(1))),\n            _mm256_cmpgt_epi8(_mm256_add_epi8(upper_bound, _mm256_set1_epi8(1)), chars)\n        );\n        \n        __m256i is_upper = _mm256_and_si256(\n            _mm256_cmpgt_epi8(chars, _mm256_sub_epi8(upper_lower_bound, _mm256_set1_epi8(1))),\n            _mm256_cmpgt_epi8(_mm256_add_epi8(upper_upper_bound, _mm256_set1_epi8(1)), chars)\n        );\n\n        chars = _mm256_xor_si256(chars, _mm256_and_si256(upper_mask, _mm256_or_si256(is_lower, is_upper)));\n        \n        _mm256_storeu_si256((__m256i*)(result.data() + i), chars);\n    }\n\n    // Handle remaining characters\n    for (size_t i = vec_size; i < len; i++) {\n        char c = result[i];\n        if (c >= 'a' && c <= 'z') {\n            c = toupper(c);\n        } else if (c >= 'A' && c <= 'Z') {\n            c = tolower(c);\n        }\n        \n        switch(tolower(c)) {\n            case 'a': c = (isupper(result[i]) ? 'C' : 'c'); break;\n            case 'e': c = (isupper(result[i]) ? 'G' : 'g'); break;\n            case 'i': c = (isupper(result[i]) ? 'K' : 'k'); break;\n            case 'o': c = (isupper(result[i]) ? 'Q' : 'q'); break;\n            case 'u': c = (isupper(result[i]) ? 'W' : 'w'); break;\n        }\n        result[i] = c;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_106_AVX", "completion": "```cpp\nstd::string encode_simd(const std::string& message) {\n    std::string result = message;\n    int len = message.length();\n    \n    // Process 32 characters at a time using AVX2\n    for (int i = 0; i + 32 <= len; i += 32) {\n        __m256i chars = _mm256_loadu_si256((__m256i*)(result.data() + i));\n        \n        // Check for lowercase letters\n        __m256i is_lower = _mm256_and_si256(\n            _mm256_cmpgt_epi8(chars, _mm256_set1_epi8('a' - 1)),\n            _mm256_cmpgt_epi8(_mm256_set1_epi8('z' + 1), chars)\n        );\n        \n        // Check for uppercase letters\n        __m256i is_upper = _mm256_and_si256(\n            _mm256_cmpgt_epi8(chars, _mm256_set1_epi8('A' - 1)),\n            _mm256_cmpgt_epi8(_mm256_set1_epi8('Z' + 1), chars)\n        );\n        \n        // Convert case\n        __m256i case_mask = _mm256_set1_epi8(0x20);\n        chars = _mm256_xor_si256(chars, _mm256_and_si256(_mm256_or_si256(is_lower, is_upper), case_mask));\n        \n        // Check for vowels (both lowercase and uppercase)\n        __m256i is_a = _mm256_or_si256(\n            _mm256_cmpeq_epi8(chars, _mm256_set1_epi8('a')),\n            _mm256_cmpeq_epi8(chars, _mm256_set1_epi8('A'))\n        );\n        __m256i is_e = _mm256_or_si256(\n            _mm256_cmpeq_epi8(chars, _mm256_set1_epi8('e')),\n            _mm256_cmpeq_epi8(chars, _mm256_set1_epi8('E'))\n        );\n        __m256i is_i = _mm256_or_si256(\n            _mm256_cmpeq_epi8(chars, _mm256_set1_epi8('i')),\n            _mm256_cmpeq_epi8(chars, _mm256_set1_epi8('I'))\n        );\n        __m256i is_o = _mm256_or_si256(\n            _mm256_cmpeq_epi8(chars, _mm256_set1_epi8('o')),\n            _mm256_cmpeq_epi8(chars, _mm256_set1_epi8('O'))\n        );\n        __m256i is_u = _mm256_or_si256(\n            _mm256_cmpeq_epi8(chars, _mm256_set1_epi8('u')),\n            _mm256_cmpeq_epi8(chars, _mm256_set1_epi8('U'))\n        );\n        \n        // Replace vowels with letters 2 positions ahead\n        chars = _mm256_or_si256(chars,\n            _mm256_and_si256(is_a, _mm256_set1_epi8('C' - 'a'))\n        );\n        chars = _mm256_or_si256(chars,\n            _mm256_and_si256(is_e, _mm256_set1_epi8('G' - 'e'))\n        );\n        chars = _mm256_or_si256(chars,\n            _mm256_and_si256(is_i, _mm256_set1_epi8('K' - 'i'))\n        );\n        chars = _mm256_or_si256(chars,\n            _mm256_and_si256(is_o, _mm256_set1_epi8('Q' - 'o'))\n        );\n        chars = _mm256_or_si256(chars,\n            _mm256_and_si256(is_u, _mm256_set1_epi8('W' - 'u'))\n        );\n        \n        _mm256_storeu_si256((__m256i*)(result.data() + i), chars);\n    }\n    \n    // Handle remaining characters\n    for (int i = (len / 32) * 32; i < len; i++) {\n        char c = result[i];\n        if (isalpha(c)) {\n            // Swap case\n            c ^= 0x20;\n            // Replace vowels\n            switch(tolower(c)) {\n                case 'a': c = (c & 0x20) ? 'c' : 'C'; break;\n                case 'e': c = (c & 0x20) ? 'g' : 'G'; break;\n                case 'i': c = (c & 0x20) ? 'k' : 'K'; break;\n                case 'o': c = (c & 0x20) ? 'q' : 'Q'; break;\n                case 'u': c = (c & 0x20) ? 'w' : 'W'; break;\n            }\n        }\n        result[i] = c;\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_106_AVX", "completion": "```cpp\nstd::string encode_simd(const std::string& message) {\n    std::string result = message;\n    size_t len = message.length();\n    size_t simd_size = 32;\n    size_t vec_size = len - (len % simd_size);\n\n    __m256i vowels = _mm256_set1_epi8(0);\n    __m256i vowels_mask = _mm256_setr_epi8(\n        'a', 'e', 'i', 'o', 'u', 'A', 'E', 'I', 'O', 'U',\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n    );\n\n    __m256i vowel_shifts = _mm256_setr_epi8(\n        'c', 'g', 'k', 'q', 'w', 'C', 'G', 'K', 'Q', 'W',\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n    );\n\n    __m256i upper = _mm256_set1_epi8('A');\n    __m256i lower = _mm256_set1_epi8('a');\n    __m256i diff = _mm256_set1_epi8(32);\n\n    for (size_t i = 0; i < vec_size; i += simd_size) {\n        __m256i data = _mm256_loadu_si256((__m256i*)(message.data() + i));\n        \n        // Check for vowels\n        __m256i is_vowel = _mm256_cmpeq_epi8(data, vowels_mask);\n        __m256i vowel_result = _mm256_blendv_epi8(data, vowel_shifts, is_vowel);\n        \n        // Case conversion\n        __m256i is_upper = _mm256_cmpgt_epi8(_mm256_sub_epi8(data, upper), _mm256_set1_epi8(-1));\n        __m256i is_lower = _mm256_cmpgt_epi8(_mm256_sub_epi8(data, lower), _mm256_set1_epi8(-1));\n        \n        __m256i case_converted = _mm256_xor_si256(data, _mm256_and_si256(diff, \n            _mm256_or_si256(is_upper, is_lower)));\n\n        // Combine vowel replacement and case conversion\n        __m256i final = _mm256_blendv_epi8(case_converted, vowel_result, is_vowel);\n        \n        _mm256_storeu_si256((__m256i*)(result.data() + i), final);\n    }\n\n    // Handle remaining characters\n    for (size_t i = vec_size; i < len; i++) {\n        char c = message[i];\n        if (c >= 'A' && c <= 'Z') {\n            c = c - 'A' + 'a';\n        } else if (c >= 'a' && c <= 'z') {\n            c = c - 'a' + 'A';\n        }\n        \n        switch(c) {\n            case 'a': c = 'c'; break;\n            case 'e': c = 'g'; break;\n            case 'i': c = 'k'; break;\n            case 'o': c = 'q'; break;\n            case 'u': c = 'w'; break;\n            case 'A': c = 'C'; break;\n            case 'E': c = 'G'; break;\n            case 'I': c = 'K'; break;\n            case 'O': c = 'Q'; break;\n            case 'U': c = 'W'; break;\n        }\n        result[i] = c;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_106_AVX", "completion": "```cpp\nstd::string encode_simd(const std::string& message) {\n    std::string result(message);\n    size_t len = message.length();\n    size_t simd_width = 32;\n    size_t vec_size = len - (len % simd_width);\n\n    __m256i vowels = _mm256_setr_epi8(\n        'a', 'e', 'i', 'o', 'u', 'A', 'E', 'I', 'O', 'U',\n        'a', 'e', 'i', 'o', 'u', 'A', 'E', 'I', 'O', 'U',\n        'a', 'e', 'i', 'o', 'u', 'A', 'E', 'I', 'O', 'U',\n        'a', 'e');\n\n    __m256i vowel_replacements = _mm256_setr_epi8(\n        'c', 'g', 'k', 'q', 'w', 'C', 'G', 'K', 'Q', 'W',\n        'c', 'g', 'k', 'q', 'w', 'C', 'G', 'K', 'Q', 'W',\n        'c', 'g', 'k', 'q', 'w', 'C', 'G', 'K', 'Q', 'W',\n        'c', 'g');\n\n    __m256i upper_mask = _mm256_set1_epi8(0x20);\n    __m256i upper_bound = _mm256_set1_epi8('z');\n    __m256i lower_bound = _mm256_set1_epi8('a');\n    __m256i upper_bound_upper = _mm256_set1_epi8('Z');\n    __m256i lower_bound_upper = _mm256_set1_epi8('A');\n\n    for (size_t i = 0; i < vec_size; i += simd_width) {\n        __m256i chars = _mm256_loadu_si256((__m256i*)(message.data() + i));\n        \n        // Check for vowels\n        __m256i is_vowel = _mm256_cmpeq_epi8(chars, vowels);\n        for (int shift = 1; shift < 10; shift++) {\n            __m256i shifted = _mm256_alignr_epi8(\n                _mm256_permute2x128_si256(vowels, vowels, 0x01),\n                vowels,\n                shift);\n            is_vowel = _mm256_or_si256(is_vowel, _mm256_cmpeq_epi8(chars, shifted));\n        }\n\n        // Replace vowels\n        __m256i vowel_result = _mm256_blendv_epi8(chars, vowel_replacements, is_vowel);\n\n        // Swap case for letters\n        __m256i is_lower = _mm256_and_si256(\n            _mm256_cmpgt_epi8(chars, lower_bound - 1),\n            _mm256_cmpgt_epi8(upper_bound + 1, chars)\n        );\n        \n        __m256i is_upper = _mm256_and_si256(\n            _mm256_cmpgt_epi8(chars, lower_bound_upper - 1),\n            _mm256_cmpgt_epi8(upper_bound_upper + 1, chars)\n        );\n\n        __m256i case_swapped = _mm256_xor_si256(\n            vowel_result,\n            _mm256_and_si256(_mm256_or_si256(is_lower, is_upper), upper_mask)\n        );\n\n        _mm256_storeu_si256((__m256i*)(result.data() + i), case_swapped);\n    }\n\n    // Handle remaining characters\n    for (size_t i = vec_size; i < len; i++) {\n        char c = message[i];\n        bool is_vowel = (c == 'a' || c == 'e' || c == 'i' || c == 'o' || c == 'u' ||\n                        c == 'A' || c == 'E' || c == 'I' || c == 'O' || c == 'U');\n        \n        if (is_vowel) {\n            c = (c >= 'a' && c <= 'z') ? \n                (char)(((c - 'a' + 2) % 26) + 'A') :\n                (char)(((c - 'A' + 2) % 26) + 'a');\n        } else if ((c >= 'a' && c <= 'z') || (c >= 'A' && c <= 'Z')) {\n            c ^= 0x20;\n        }\n        result[i] = c;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_107_AVX", "completion": "```cpp\nbool check_dict_case_simd(std::map<std::string, std::string> dict) {\n    if (dict.empty()) {\n        return false;\n    }\n\n    // Get first key to determine case\n    std::string first_key = dict.begin()->first;\n    bool is_upper = std::isupper(first_key[0]);\n    bool is_lower = std::islower(first_key[0]);\n    \n    if (!is_upper && !is_lower) {\n        return false;\n    }\n\n    // Process 32 characters at a time using AVX2\n    __m256i upper_mask = _mm256_set1_epi8('A' - 1);\n    __m256i lower_mask = _mm256_set1_epi8('z' + 1);\n    __m256i az_range = _mm256_set1_epi8('z' - 'a');\n\n    for (const auto& pair : dict) {\n        const std::string& key = pair.first;\n        size_t len = key.length();\n        size_t i = 0;\n\n        while (i + 32 <= len) {\n            __m256i chars = _mm256_loadu_si256((__m256i*)(key.data() + i));\n            \n            __m256i gt_upper = _mm256_cmpgt_epi8(chars, upper_mask);\n            __m256i lt_lower = _mm256_cmpgt_epi8(lower_mask, chars);\n            __m256i in_range = _mm256_and_si256(gt_upper, lt_lower);\n            \n            int mask = _mm256_movemask_epi8(in_range);\n            \n            if (is_upper) {\n                __m256i upper_chars = _mm256_sub_epi8(chars, az_range);\n                __m256i is_lower = _mm256_cmpeq_epi8(chars, upper_chars);\n                if (_mm256_movemask_epi8(is_lower) != 0) {\n                    return false;\n                }\n            } else {\n                __m256i lower_chars = _mm256_add_epi8(chars, az_range); \n                __m256i is_upper = _mm256_cmpeq_epi8(chars, lower_chars);\n                if (_mm256_movemask_epi8(is_upper) != 0) {\n                    return false;\n                }\n            }\n            \n            i += 32;\n        }\n\n        // Handle remaining characters\n        for (; i < len; i++) {\n            if (is_upper && std::islower(key[i])) {\n                return false;\n            }\n            if (is_lower && std::isupper(key[i])) {\n                return false;\n            }\n            if (!std::isalpha(key[i])) {\n                return false;\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_107_AVX", "completion": "```cpp\nbool check_dict_case_simd(std::map<std::string, std::string> dict) {\n    if (dict.empty()) {\n        return false;\n    }\n\n    // Get first key to determine case\n    std::string first_key = dict.begin()->first;\n    bool is_upper = std::isupper(first_key[0]);\n    bool is_lower = std::islower(first_key[0]);\n    \n    if (!is_upper && !is_lower) {\n        return false;\n    }\n\n    // Process 32 characters at a time using AVX2\n    __m256i upper_mask = _mm256_set1_epi8('A' - 1);\n    __m256i lower_mask = _mm256_set1_epi8('z' + 1);\n    __m256i az_range = _mm256_set1_epi8(26);\n\n    for (const auto& pair : dict) {\n        const std::string& key = pair.first;\n        size_t len = key.length();\n        size_t i = 0;\n\n        // Process chunks of 32 bytes\n        for (; i + 32 <= len; i += 32) {\n            __m256i chars = _mm256_loadu_si256((__m256i*)(key.data() + i));\n            \n            // Check if characters are letters\n            __m256i gt_upper = _mm256_cmpgt_epi8(chars, upper_mask);\n            __m256i lt_lower = _mm256_cmpgt_epi8(lower_mask, chars);\n            __m256i is_letter = _mm256_and_si256(gt_upper, lt_lower);\n\n            // Get mask of non-letter characters\n            int letter_mask = _mm256_movemask_epi8(is_letter);\n            if (letter_mask != -1) {\n                return false;\n            }\n\n            if (is_upper) {\n                // Check if all characters are uppercase\n                __m256i upper_range = _mm256_sub_epi8(chars, _mm256_set1_epi8('A'));\n                __m256i is_upper_vec = _mm256_cmpgt_epi8(az_range, upper_range);\n                int upper_mask = _mm256_movemask_epi8(is_upper_vec);\n                if (upper_mask != -1) {\n                    return false;\n                }\n            } else {\n                // Check if all characters are lowercase\n                __m256i lower_range = _mm256_sub_epi8(chars, _mm256_set1_epi8('a'));\n                __m256i is_lower_vec = _mm256_cmpgt_epi8(az_range, lower_range);\n                int lower_mask = _mm256_movemask_epi8(is_lower_vec);\n                if (lower_mask != -1) {\n                    return false;\n                }\n            }\n        }\n\n        // Handle remaining characters\n        for (; i < len; i++) {\n            char c = key[i];\n            if (!std::isalpha(c)) {\n                return false;\n            }\n            if ((is_upper && !std::isupper(c)) || (is_lower && !std::islower(c))) {\n                return false;\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_107_AVX", "completion": "```cpp\nbool check_dict_case_simd(std::map<std::string, std::string> dict) {\n    if (dict.empty()) {\n        return false;\n    }\n\n    // Get all keys\n    std::vector<std::string> keys;\n    for (const auto& pair : dict) {\n        keys.push_back(pair.first);\n    }\n\n    // Check if first key is all uppercase or lowercase to determine expected case\n    bool expect_upper = std::isupper(keys[0][0]);\n    \n    // Process 32 characters at a time using AVX2\n    for (const auto& key : keys) {\n        const size_t len = key.length();\n        const char* str = key.c_str();\n        size_t i = 0;\n\n        while (i + 32 <= len) {\n            __m256i chars = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(str + i));\n            \n            if (expect_upper) {\n                // Check if any character is lowercase (0x61-0x7A)\n                __m256i lower_bound = _mm256_set1_epi8(0x61);\n                __m256i upper_bound = _mm256_set1_epi8(0x7A);\n                __m256i is_lower = _mm256_and_si256(\n                    _mm256_cmpgt_epi8(chars, _mm256_sub_epi8(lower_bound, _mm256_set1_epi8(1))),\n                    _mm256_cmpgt_epi8(_mm256_add_epi8(upper_bound, _mm256_set1_epi8(1)), chars)\n                );\n                if (_mm256_movemask_epi8(is_lower)) {\n                    return false;\n                }\n            } else {\n                // Check if any character is uppercase (0x41-0x5A)\n                __m256i lower_bound = _mm256_set1_epi8(0x41);\n                __m256i upper_bound = _mm256_set1_epi8(0x5A);\n                __m256i is_upper = _mm256_and_si256(\n                    _mm256_cmpgt_epi8(chars, _mm256_sub_epi8(lower_bound, _mm256_set1_epi8(1))),\n                    _mm256_cmpgt_epi8(_mm256_add_epi8(upper_bound, _mm256_set1_epi8(1)), chars)\n                );\n                if (_mm256_movemask_epi8(is_upper)) {\n                    return false;\n                }\n            }\n            i += 32;\n        }\n\n        // Handle remaining characters\n        while (i < len) {\n            char c = str[i];\n            if (expect_upper) {\n                if (std::islower(c)) return false;\n            } else {\n                if (std::isupper(c)) return false;\n            }\n            i++;\n        }\n\n        // Check if any non-alphabetic characters\n        for (char c : key) {\n            if (!std::isalpha(c)) return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_107_AVX", "completion": "```cpp\nbool check_dict_case_simd(std::map<std::string, std::string> dict) {\n    if (dict.empty()) {\n        return false;\n    }\n\n    // Get first key to determine case\n    std::string first_key = dict.begin()->first;\n    bool is_upper = std::isupper(first_key[0]);\n    bool is_lower = std::islower(first_key[0]);\n\n    if (!is_upper && !is_lower) {\n        return false;\n    }\n\n    // Process 32 characters at a time using AVX2\n    __m256i upper_mask = _mm256_set1_epi8('A' - 1);\n    __m256i lower_mask = _mm256_set1_epi8('z' + 1);\n    __m256i alpha_min = _mm256_set1_epi8('A');\n    __m256i alpha_max = _mm256_set1_epi8('z');\n\n    for (const auto& pair : dict) {\n        const std::string& key = pair.first;\n        size_t len = key.length();\n        size_t i = 0;\n\n        while (i + 32 <= len) {\n            __m256i chars = _mm256_loadu_si256((__m256i*)(key.data() + i));\n            \n            __m256i is_alpha = _mm256_and_si256(\n                _mm256_cmpgt_epi8(chars, alpha_min),\n                _mm256_cmpgt_epi8(alpha_max, chars)\n            );\n\n            if (is_upper) {\n                __m256i is_upper_vec = _mm256_cmpgt_epi8(chars, upper_mask);\n                if (!_mm256_testc_si256(is_upper_vec, is_alpha)) {\n                    return false;\n                }\n            } else {\n                __m256i is_lower_vec = _mm256_cmpgt_epi8(lower_mask, chars);\n                if (!_mm256_testc_si256(is_lower_vec, is_alpha)) {\n                    return false;\n                }\n            }\n            i += 32;\n        }\n\n        // Handle remaining characters\n        for (; i < len; i++) {\n            char c = key[i];\n            if (!std::isalpha(c)) {\n                return false;\n            }\n            if (is_upper && !std::isupper(c)) {\n                return false;\n            }\n            if (is_lower && !std::islower(c)) {\n                return false;\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_107_AVX", "completion": "```cpp\nbool check_dict_case_simd(std::map<std::string, std::string> dict) {\n    if (dict.empty()) {\n        return false;\n    }\n\n    // Get first key to determine case\n    std::string first_key = dict.begin()->first;\n    bool is_upper = std::isupper(first_key[0]);\n    bool is_lower = std::islower(first_key[0]);\n\n    if (!is_upper && !is_lower) {\n        return false;\n    }\n\n    // Process 32 characters at a time using AVX2\n    for (const auto& pair : dict) {\n        const std::string& key = pair.first;\n        size_t len = key.length();\n        size_t i = 0;\n\n        while (i + 32 <= len) {\n            __m256i chars = _mm256_loadu_si256((__m256i*)(key.data() + i));\n\n            if (is_upper) {\n                // Check if any character is not uppercase\n                __m256i upper_mask = _mm256_set1_epi8('A' - 1);\n                __m256i lower_mask = _mm256_set1_epi8('Z' + 1);\n                __m256i gt_upper = _mm256_cmpgt_epi8(chars, upper_mask);\n                __m256i lt_lower = _mm256_cmpgt_epi8(lower_mask, chars);\n                __m256i in_range = _mm256_and_si256(gt_upper, lt_lower);\n                \n                if (_mm256_movemask_epi8(in_range) != -1) {\n                    return false;\n                }\n            } else {\n                // Check if any character is not lowercase\n                __m256i upper_mask = _mm256_set1_epi8('a' - 1);\n                __m256i lower_mask = _mm256_set1_epi8('z' + 1);\n                __m256i gt_upper = _mm256_cmpgt_epi8(chars, upper_mask);\n                __m256i lt_lower = _mm256_cmpgt_epi8(lower_mask, chars);\n                __m256i in_range = _mm256_and_si256(gt_upper, lt_lower);\n                \n                if (_mm256_movemask_epi8(in_range) != -1) {\n                    return false;\n                }\n            }\n            i += 32;\n        }\n\n        // Process remaining characters\n        for (; i < len; i++) {\n            char c = key[i];\n            if (is_upper && !std::isupper(c)) {\n                return false;\n            }\n            if (is_lower && !std::islower(c)) {\n                return false;\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_108_AVX", "completion": "```cpp\nstd::vector<int> count_up_to_simd(int n) {\n    if (n <= 2) return {};\n    \n    std::vector<int> primes;\n    primes.push_back(2);\n    \n    std::vector<bool> is_prime(n, true);\n    is_prime[0] = is_prime[1] = false;\n\n    const int simd_width = 8;\n    __m256i ones = _mm256_set1_epi32(1);\n    __m256i zeros = _mm256_setzero_si256();\n\n    for (int i = 2; i * i < n; i++) {\n        if (is_prime[i]) {\n            int start = i * i;\n            int aligned_start = (start + simd_width - 1) & ~(simd_width - 1);\n            \n            // Handle unaligned part\n            for (int j = start; j < aligned_start && j < n; j += i) {\n                is_prime[j] = false;\n            }\n            \n            // SIMD part\n            for (int j = aligned_start; j + simd_width <= n; j += simd_width) {\n                __m256i indices = _mm256_set_epi32(j+7, j+6, j+5, j+4, j+3, j+2, j+1, j);\n                __m256i divisible = _mm256_set1_epi32(i);\n                __m256i remainders = _mm256_rem_epi32(indices, divisible);\n                __m256i mask = _mm256_cmpeq_epi32(remainders, zeros);\n                \n                int bit_mask = _mm256_movemask_ps(_mm256_castsi256_ps(mask));\n                \n                while (bit_mask) {\n                    int pos = j + __builtin_ctz(bit_mask);\n                    if (pos < n) is_prime[pos] = false;\n                    bit_mask &= (bit_mask - 1);\n                }\n            }\n            \n            // Handle remaining elements\n            for (int j = (n/simd_width)*simd_width; j < n; j += i) {\n                if (j >= i * i) is_prime[j] = false;\n            }\n        }\n    }\n\n    for (int i = 2; i < n; i++) {\n        if (is_prime[i]) {\n            primes.push_back(i);\n        }\n    }\n    \n    return primes;\n}\n```"}
{"task_id": "SimdBench_108_AVX", "completion": "```cpp\nstd::vector<int> count_up_to_simd(int n) {\n    if (n <= 2) return {};\n    \n    std::vector<int> primes;\n    primes.push_back(2);\n    \n    std::vector<bool> is_prime(n, true);\n    is_prime[0] = is_prime[1] = false;\n\n    const int simd_width = 8;\n    __m256i ones = _mm256_set1_epi32(1);\n    __m256i zeros = _mm256_setzero_si256();\n\n    for (int i = 2; i * i < n; i++) {\n        if (is_prime[i]) {\n            int start = i * i;\n            int aligned_start = (start + simd_width - 1) & ~(simd_width - 1);\n            \n            // Handle unaligned part\n            for (int j = start; j < aligned_start && j < n; j += i) {\n                is_prime[j] = false;\n            }\n            \n            // SIMD part\n            for (int j = aligned_start; j + simd_width <= n; j += simd_width) {\n                __m256i indices = _mm256_set_epi32(j+7, j+6, j+5, j+4, j+3, j+2, j+1, j);\n                __m256i divisible = _mm256_set1_epi32(i);\n                __m256i remainders = _mm256_rem_epi32(indices, divisible);\n                __m256i mask = _mm256_cmpeq_epi32(remainders, zeros);\n                \n                int write_mask = _mm256_movemask_ps(_mm256_castsi256_ps(mask));\n                \n                for (int k = 0; k < simd_width; k++) {\n                    if (write_mask & (1 << k)) {\n                        is_prime[j + k] = false;\n                    }\n                }\n            }\n            \n            // Handle remaining elements\n            for (int j = (n/simd_width)*simd_width; j < n; j += i) {\n                if (j >= i * i) {\n                    is_prime[j] = false;\n                }\n            }\n        }\n    }\n\n    for (int i = 3; i < n; i++) {\n        if (is_prime[i]) {\n            primes.push_back(i);\n        }\n    }\n    \n    return primes;\n}\n```"}
{"task_id": "SimdBench_108_AVX", "completion": "```cpp\nstd::vector<int> count_up_to_simd(int n) {\n    if (n <= 2) return {};\n    \n    std::vector<int> primes;\n    primes.push_back(2);\n    \n    __m256i ones = _mm256_set1_epi32(1);\n    __m256i zeros = _mm256_setzero_si256();\n    \n    for (int num = 3; num < n; num += 2) {\n        int sqrtNum = sqrt(num);\n        int vectorSize = (sqrtNum + 7) / 8 * 8;\n        \n        __m256i numVec = _mm256_set1_epi32(num);\n        bool isPrime = true;\n        \n        for (int i = 0; i < primes.size() && primes[i] <= sqrtNum; i += 8) {\n            __m256i primeVec;\n            if (i + 8 <= primes.size()) {\n                primeVec = _mm256_loadu_si256((__m256i*)&primes[i]);\n            } else {\n                int temp[8] = {0};\n                for(int j = 0; j < primes.size() - i; j++) {\n                    temp[j] = primes[i + j];\n                }\n                primeVec = _mm256_loadu_si256((__m256i*)temp);\n            }\n            \n            __m256i divResult = _mm256_div_epi32(numVec, primeVec);\n            __m256i mulResult = _mm256_mullo_epi32(divResult, primeVec);\n            __m256i cmpResult = _mm256_cmpeq_epi32(mulResult, numVec);\n            \n            int mask = _mm256_movemask_ps(_mm256_castsi256_ps(cmpResult));\n            \n            if (mask != 0) {\n                isPrime = false;\n                break;\n            }\n        }\n        \n        if (isPrime) {\n            primes.push_back(num);\n        }\n    }\n    \n    return primes;\n}\n```"}
{"task_id": "SimdBench_108_AVX", "completion": "```cpp\nstd::vector<int> count_up_to_simd(int n) {\n    if (n <= 2) return {};\n    \n    std::vector<int> primes;\n    primes.push_back(2);\n    \n    std::vector<bool> is_prime(n, true);\n    is_prime[0] = is_prime[1] = false;\n\n    const int simd_width = 8;\n    __m256i ones = _mm256_set1_epi32(1);\n    __m256i zeros = _mm256_setzero_si256();\n\n    for (int i = 2; i * i < n; i++) {\n        if (is_prime[i]) {\n            int start = i * i;\n            int aligned_start = (start + simd_width - 1) & ~(simd_width - 1);\n            \n            // Handle unaligned part\n            for (int j = start; j < aligned_start && j < n; j += i) {\n                is_prime[j] = false;\n            }\n            \n            // SIMD part\n            for (int j = aligned_start; j + simd_width <= n; j += simd_width) {\n                __m256i indices = _mm256_setr_epi32(j, j+1, j+2, j+3, j+4, j+5, j+6, j+7);\n                __m256i divisible = _mm256_set1_epi32(i);\n                __m256i remainders = _mm256_rem_epi32(indices, divisible);\n                __m256i mask = _mm256_cmpeq_epi32(remainders, zeros);\n                \n                int bit_mask = _mm256_movemask_ps(_mm256_castsi256_ps(mask));\n                \n                while (bit_mask) {\n                    int pos = j + _tzcnt_u32(bit_mask);\n                    if (pos < n) is_prime[pos] = false;\n                    bit_mask &= (bit_mask - 1);\n                }\n            }\n        }\n    }\n\n    for (int i = 3; i < n; i++) {\n        if (is_prime[i]) {\n            primes.push_back(i);\n        }\n    }\n\n    return primes;\n}\n```"}
{"task_id": "SimdBench_108_AVX", "completion": "```cpp\nstd::vector<int> count_up_to_simd(int n) {\n    if (n <= 2) return {};\n    \n    std::vector<int> primes;\n    primes.push_back(2);\n    \n    std::vector<bool> is_prime(n, true);\n    is_prime[0] = is_prime[1] = false;\n\n    const int simd_width = 8;\n    __m256i ones = _mm256_set1_epi32(1);\n    __m256i zeros = _mm256_setzero_si256();\n\n    for (int i = 2; i * i < n; i++) {\n        if (!is_prime[i]) continue;\n        \n        int start = i * i;\n        int aligned_start = (start + simd_width - 1) & ~(simd_width - 1);\n        \n        // Handle unaligned portion\n        for (int j = start; j < aligned_start && j < n; j += i) {\n            is_prime[j] = false;\n        }\n        \n        // SIMD portion\n        for (int j = aligned_start; j + simd_width <= n; j += simd_width) {\n            __m256i indices = _mm256_set_epi32(j+7, j+6, j+5, j+4, j+3, j+2, j+1, j);\n            __m256i divisible = _mm256_set1_epi32(i);\n            __m256i remainders = _mm256_rem_epi32(indices, divisible);\n            __m256i mask = _mm256_cmpeq_epi32(remainders, zeros);\n            \n            int bit_mask = _mm256_movemask_ps(_mm256_castsi256_ps(mask));\n            \n            while (bit_mask) {\n                int pos = _tzcnt_u32(bit_mask);\n                if (j + pos < n) {\n                    is_prime[j + pos] = false;\n                }\n                bit_mask &= (bit_mask - 1);\n            }\n        }\n    }\n\n    for (int i = 2; i < n; i++) {\n        if (is_prime[i]) {\n            primes.push_back(i);\n        }\n    }\n\n    return primes;\n}\n```"}
{"task_id": "SimdBench_109_AVX", "completion": "```cpp\nint count_upper_simd(const std::string & s) {\n    int count = 0;\n    int len = s.length();\n    \n    if (len < 32) {\n        for (int i = 0; i < len; i += 2) {\n            char c = s[i];\n            if (c == 'A' || c == 'E' || c == 'I' || c == 'O' || c == 'U')\n                count++;\n        }\n        return count;\n    }\n\n    __m256i vowels_a = _mm256_set1_epi8('A');\n    __m256i vowels_e = _mm256_set1_epi8('E');\n    __m256i vowels_i = _mm256_set1_epi8('I');\n    __m256i vowels_o = _mm256_set1_epi8('O');\n    __m256i vowels_u = _mm256_set1_epi8('U');\n    \n    int i;\n    for (i = 0; i + 31 < len; i += 32) {\n        __m256i str = _mm256_loadu_si256((__m256i*)(s.c_str() + i));\n        \n        __m256i mask_a = _mm256_cmpeq_epi8(str, vowels_a);\n        __m256i mask_e = _mm256_cmpeq_epi8(str, vowels_e);\n        __m256i mask_i = _mm256_cmpeq_epi8(str, vowels_i);\n        __m256i mask_o = _mm256_cmpeq_epi8(str, vowels_o);\n        __m256i mask_u = _mm256_cmpeq_epi8(str, vowels_u);\n        \n        __m256i mask = _mm256_or_si256(mask_a, mask_e);\n        mask = _mm256_or_si256(mask, mask_i);\n        mask = _mm256_or_si256(mask, mask_o);\n        mask = _mm256_or_si256(mask, mask_u);\n\n        uint32_t even_mask = 0x55555555;\n        __m256i even_indices = _mm256_set1_epi32(even_mask);\n        mask = _mm256_and_si256(mask, even_indices);\n        \n        uint32_t bits = _mm256_movemask_epi8(mask);\n        count += _mm_popcnt_u32(bits);\n    }\n\n    for (; i < len; i += 2) {\n        char c = s[i];\n        if (c == 'A' || c == 'E' || c == 'I' || c == 'O' || c == 'U')\n            count++;\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_109_AVX", "completion": "```cpp\nint count_upper_simd(const std::string& s) {\n    int count = 0;\n    int len = s.length();\n    \n    if (len < 32) {\n        for (int i = 0; i < len; i += 2) {\n            char c = s[i];\n            if (c == 'A' || c == 'E' || c == 'I' || c == 'O' || c == 'U')\n                count++;\n        }\n        return count;\n    }\n\n    __m256i vowels_a = _mm256_set1_epi8('A');\n    __m256i vowels_e = _mm256_set1_epi8('E');\n    __m256i vowels_i = _mm256_set1_epi8('I');\n    __m256i vowels_o = _mm256_set1_epi8('O');\n    __m256i vowels_u = _mm256_set1_epi8('U');\n    \n    int i;\n    for (i = 0; i + 31 < len; i += 32) {\n        __m256i str = _mm256_loadu_si256((__m256i*)(s.data() + i));\n        \n        __m256i mask_a = _mm256_cmpeq_epi8(str, vowels_a);\n        __m256i mask_e = _mm256_cmpeq_epi8(str, vowels_e);\n        __m256i mask_i = _mm256_cmpeq_epi8(str, vowels_i);\n        __m256i mask_o = _mm256_cmpeq_epi8(str, vowels_o);\n        __m256i mask_u = _mm256_cmpeq_epi8(str, vowels_u);\n        \n        __m256i mask_vowels = _mm256_or_si256(\n            _mm256_or_si256(\n                _mm256_or_si256(mask_a, mask_e),\n                _mm256_or_si256(mask_i, mask_o)\n            ),\n            mask_u\n        );\n        \n        uint32_t mask = _mm256_movemask_epi8(mask_vowels);\n        \n        // Count only even indices\n        mask &= 0x55555555;\n        count += _mm_popcnt_u32(mask);\n    }\n    \n    // Handle remaining characters\n    for (; i < len; i += 2) {\n        char c = s[i];\n        if (c == 'A' || c == 'E' || c == 'I' || c == 'O' || c == 'U')\n            count++;\n    }\n    \n    return count;\n}\n```"}
{"task_id": "SimdBench_109_AVX", "completion": "```cpp\nint count_upper_simd(const std::string& s) {\n    int count = 0;\n    int len = s.length();\n    \n    if (len < 32) {\n        for (int i = 0; i < len; i += 2) {\n            char c = s[i];\n            if (c == 'A' || c == 'E' || c == 'I' || c == 'O' || c == 'U') {\n                count++;\n            }\n        }\n        return count;\n    }\n\n    __m256i vowels_a = _mm256_set1_epi8('A');\n    __m256i vowels_e = _mm256_set1_epi8('E');\n    __m256i vowels_i = _mm256_set1_epi8('I');\n    __m256i vowels_o = _mm256_set1_epi8('O');\n    __m256i vowels_u = _mm256_set1_epi8('U');\n    \n    int i;\n    for (i = 0; i + 31 < len; i += 32) {\n        __m256i str = _mm256_loadu_si256((__m256i*)(s.data() + i));\n        \n        __m256i mask_a = _mm256_cmpeq_epi8(str, vowels_a);\n        __m256i mask_e = _mm256_cmpeq_epi8(str, vowels_e);\n        __m256i mask_i = _mm256_cmpeq_epi8(str, vowels_i);\n        __m256i mask_o = _mm256_cmpeq_epi8(str, vowels_o);\n        __m256i mask_u = _mm256_cmpeq_epi8(str, vowels_u);\n        \n        __m256i mask = _mm256_or_si256(mask_a, mask_e);\n        mask = _mm256_or_si256(mask, mask_i);\n        mask = _mm256_or_si256(mask, mask_o);\n        mask = _mm256_or_si256(mask, mask_u);\n        \n        uint32_t even_mask = 0x55555555;\n        __m256i even_indices = _mm256_set1_epi32(even_mask);\n        mask = _mm256_and_si256(mask, even_indices);\n        \n        uint32_t bits = _mm256_movemask_epi8(mask);\n        count += _mm_popcnt_u32(bits);\n    }\n    \n    for (; i < len; i += 2) {\n        char c = s[i];\n        if (c == 'A' || c == 'E' || c == 'I' || c == 'O' || c == 'U') {\n            count++;\n        }\n    }\n    \n    return count;\n}\n```"}
{"task_id": "SimdBench_109_AVX", "completion": "```cpp\nint count_upper_simd(const std::string & s) {\n    int count = 0;\n    int len = s.length();\n    \n    if (len < 32) {\n        for (int i = 0; i < len; i += 2) {\n            char c = s[i];\n            if (c == 'A' || c == 'E' || c == 'I' || c == 'O' || c == 'U') {\n                count++;\n            }\n        }\n        return count;\n    }\n\n    __m256i vowels_a = _mm256_set1_epi8('A');\n    __m256i vowels_e = _mm256_set1_epi8('E');\n    __m256i vowels_i = _mm256_set1_epi8('I');\n    __m256i vowels_o = _mm256_set1_epi8('O');\n    __m256i vowels_u = _mm256_set1_epi8('U');\n    \n    int i;\n    for (i = 0; i + 31 < len; i += 32) {\n        __m256i str = _mm256_loadu_si256((__m256i*)(s.data() + i));\n        \n        __m256i mask_a = _mm256_cmpeq_epi8(str, vowels_a);\n        __m256i mask_e = _mm256_cmpeq_epi8(str, vowels_e);\n        __m256i mask_i = _mm256_cmpeq_epi8(str, vowels_i);\n        __m256i mask_o = _mm256_cmpeq_epi8(str, vowels_o);\n        __m256i mask_u = _mm256_cmpeq_epi8(str, vowels_u);\n        \n        __m256i mask = _mm256_or_si256(mask_a, mask_e);\n        mask = _mm256_or_si256(mask, mask_i);\n        mask = _mm256_or_si256(mask, mask_o);\n        mask = _mm256_or_si256(mask, mask_u);\n        \n        uint32_t even_mask = 0x55555555;\n        __m256i even_indices = _mm256_set1_epi32(even_mask);\n        mask = _mm256_and_si256(mask, even_indices);\n        \n        uint32_t bits = _mm256_movemask_epi8(mask);\n        count += _mm_popcnt_u32(bits);\n    }\n    \n    for (; i < len; i += 2) {\n        char c = s[i];\n        if (c == 'A' || c == 'E' || c == 'I' || c == 'O' || c == 'U') {\n            count++;\n        }\n    }\n    \n    return count;\n}\n```"}
{"task_id": "SimdBench_109_AVX", "completion": "```cpp\nint count_upper_simd(const std::string& s) {\n    int count = 0;\n    int len = s.length();\n    \n    if (len < 32) {\n        for (int i = 0; i < len; i += 2) {\n            char c = s[i];\n            if (c == 'A' || c == 'E' || c == 'I' || c == 'O' || c == 'U')\n                count++;\n        }\n        return count;\n    }\n\n    __m256i vowels_a = _mm256_set1_epi8('A');\n    __m256i vowels_e = _mm256_set1_epi8('E');\n    __m256i vowels_i = _mm256_set1_epi8('I');\n    __m256i vowels_o = _mm256_set1_epi8('O');\n    __m256i vowels_u = _mm256_set1_epi8('U');\n    \n    int i;\n    for (i = 0; i + 31 < len; i += 32) {\n        __m256i str = _mm256_loadu_si256((__m256i*)(s.data() + i));\n        \n        __m256i mask_a = _mm256_cmpeq_epi8(str, vowels_a);\n        __m256i mask_e = _mm256_cmpeq_epi8(str, vowels_e);\n        __m256i mask_i = _mm256_cmpeq_epi8(str, vowels_i);\n        __m256i mask_o = _mm256_cmpeq_epi8(str, vowels_o);\n        __m256i mask_u = _mm256_cmpeq_epi8(str, vowels_u);\n        \n        __m256i mask_vowels = _mm256_or_si256(\n            _mm256_or_si256(\n                _mm256_or_si256(mask_a, mask_e),\n                _mm256_or_si256(mask_i, mask_o)\n            ),\n            mask_u\n        );\n        \n        uint32_t mask = _mm256_movemask_epi8(mask_vowels);\n        \n        // Count set bits at even positions only\n        mask &= 0x55555555;\n        count += _mm_popcnt_u32(mask);\n    }\n    \n    // Handle remaining characters\n    for (; i < len; i += 2) {\n        char c = s[i];\n        if (c == 'A' || c == 'E' || c == 'I' || c == 'O' || c == 'U')\n            count++;\n    }\n    \n    return count;\n}\n```"}
{"task_id": "SimdBench_110_AVX", "completion": "```cpp\nstd::vector<int> make_a_pile_simd(int n) {\n    std::vector<int> result(n);\n    \n    // Handle first element\n    result[0] = n;\n    \n    // Determine if n is odd or even\n    bool isOdd = n & 1;\n    \n    // Set increment value based on odd/even\n    int increment = isOdd ? 2 : 2;\n    \n    // Process 8 elements at a time using AVX2\n    __m256i vec_increment = _mm256_set1_epi32(increment * 4);\n    __m256i vec_curr = _mm256_set_epi32(\n        n + increment * 7,\n        n + increment * 6, \n        n + increment * 5,\n        n + increment * 4,\n        n + increment * 3,\n        n + increment * 2,\n        n + increment,\n        n\n    );\n    \n    for(int i = 0; i < n/8; i++) {\n        _mm256_storeu_si256((__m256i*)&result[i*8], vec_curr);\n        vec_curr = _mm256_add_epi32(vec_curr, vec_increment);\n    }\n    \n    // Handle remaining elements\n    int remaining = n % 8;\n    if(remaining > 0) {\n        int last = result[n-remaining-1];\n        for(int i = n-remaining; i < n; i++) {\n            last += increment;\n            result[i] = last;\n        }\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_110_AVX", "completion": "```cpp\nstd::vector<int> make_a_pile_simd(int n) {\n    std::vector<int> result(n);\n    \n    // Handle first element\n    result[0] = n;\n    \n    // Initialize vector with indices 0,1,2,3,4,5,6,7\n    __m256i indices = _mm256_setr_epi32(0,1,2,3,4,5,6,7);\n    \n    // Process 8 elements at a time\n    for(int i = 0; i < n-1; i += 8) {\n        int remaining = std::min(8, n-1-i);\n        \n        if(remaining < 8) {\n            // Handle remaining elements sequentially\n            for(int j = 0; j < remaining; j++) {\n                result[i+1+j] = result[i+j] + ((n % 2 == 0) ? 2 : 2); \n            }\n        }\n        else {\n            // Load previous 8 values\n            __m256i prev = _mm256_loadu_si256((__m256i*)&result[i]);\n            \n            // Add 2 to each element\n            __m256i increment = _mm256_set1_epi32(2);\n            __m256i next = _mm256_add_epi32(prev, increment);\n            \n            // Store result\n            _mm256_storeu_si256((__m256i*)&result[i+1], next);\n        }\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_110_AVX", "completion": "```cpp\nstd::vector<int> make_a_pile_simd(int n) {\n    std::vector<int> result(n);\n    \n    // Handle first element\n    result[0] = n;\n    \n    if (n <= 1) return result;\n    \n    // Determine if n is odd or even\n    bool is_odd = n & 1;\n    \n    // Calculate increment (2 for both odd and even)\n    __m256i increment = _mm256_set1_epi32(2);\n    \n    // Set initial value based on n\n    __m256i current = _mm256_set1_epi32(n);\n    \n    // Process 8 elements at a time\n    int i;\n    for (i = 1; i + 8 <= n; i += 8) {\n        // Add increment 1,2,3,4,5,6,7,8 times respectively\n        __m256i multiplier = _mm256_set_epi32(8,7,6,5,4,3,2,1);\n        __m256i inc = _mm256_mullo_epi32(increment, multiplier);\n        __m256i values = _mm256_add_epi32(current, inc);\n        _mm256_storeu_si256((__m256i*)&result[i], values);\n        current = _mm256_add_epi32(current, _mm256_set1_epi32(16));\n    }\n    \n    // Handle remaining elements\n    for (; i < n; i++) {\n        result[i] = result[i-1] + 2;\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_110_AVX", "completion": "```cpp\nstd::vector<int> make_a_pile_simd(int n) {\n    std::vector<int> result(n);\n    \n    // Handle first element\n    result[0] = n;\n    \n    // Initialize vector with indices 0,1,2,3,4,5,6,7\n    __m256i indices = _mm256_setr_epi32(0,1,2,3,4,5,6,7);\n    \n    // Process 8 elements at a time\n    for(int i = 0; i < n-1; i += 8) {\n        int remaining = std::min(8, n-1-i);\n        \n        // Load previous values\n        __m256i prev;\n        if(i == 0) {\n            prev = _mm256_set1_epi32(n);\n        } else {\n            prev = _mm256_loadu_si256((__m256i*)&result[i]);\n        }\n        \n        // Add 2 to each element\n        __m256i next = _mm256_add_epi32(prev, _mm256_set1_epi32(2));\n        \n        // Store results\n        if(remaining == 8) {\n            _mm256_storeu_si256((__m256i*)&result[i+1], next);\n        } else {\n            // Handle remaining elements\n            int* next_arr = (int*)&next;\n            for(int j = 0; j < remaining; j++) {\n                result[i+1+j] = next_arr[j];\n            }\n        }\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_110_AVX", "completion": "```cpp\nstd::vector<int> make_a_pile_simd(int n) {\n    std::vector<int> result(n);\n    \n    // Handle first element\n    result[0] = n;\n    \n    // Initialize vector with indices 0,1,2,3,4,5,6,7\n    __m256i indices = _mm256_setr_epi32(0,1,2,3,4,5,6,7);\n    \n    // Process 8 elements at a time\n    for(int i = 0; i < n-1; i += 8) {\n        int remaining = std::min(8, n-1-i);\n        \n        if(n % 2 == 0) {\n            // For even n, add 2 to each index\n            __m256i increment = _mm256_set1_epi32(2);\n            __m256i values = _mm256_mullo_epi32(indices, increment);\n            values = _mm256_add_epi32(values, _mm256_set1_epi32(n+2));\n            \n            // Store results\n            if(remaining == 8) {\n                _mm256_storeu_si256((__m256i*)&result[i+1], values);\n            }\n            else {\n                // Store remaining elements\n                int* val = (int*)&values;\n                for(int j = 0; j < remaining; j++) {\n                    result[i+1+j] = val[j];\n                }\n            }\n        }\n        else {\n            // For odd n, add 2 to each index\n            __m256i increment = _mm256_set1_epi32(2); \n            __m256i values = _mm256_mullo_epi32(indices, increment);\n            values = _mm256_add_epi32(values, _mm256_set1_epi32(n+2));\n            \n            // Store results\n            if(remaining == 8) {\n                _mm256_storeu_si256((__m256i*)&result[i+1], values);\n            }\n            else {\n                // Store remaining elements\n                int* val = (int*)&values;\n                for(int j = 0; j < remaining; j++) {\n                    result[i+1+j] = val[j];\n                }\n            }\n        }\n        \n        // Increment indices by 8\n        indices = _mm256_add_epi32(indices, _mm256_set1_epi32(8));\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_111_AVX", "completion": "```cpp\nstd::string rounded_avg_simd(int64_t n, int64_t m) {\n    if (n > m) return \"-1\";\n    \n    int64_t count = m - n + 1;\n    \n    // Use AVX2 to sum up numbers in parallel\n    __m256i sum = _mm256_setzero_si256();\n    __m256i increment = _mm256_set1_epi64x(8);\n    __m256i current = _mm256_set_epi64x(n+3, n+2, n+1, n);\n    \n    int64_t i;\n    for (i = n; i <= m-7; i += 8) {\n        sum = _mm256_add_epi64(sum, current);\n        current = _mm256_add_epi64(current, increment);\n    }\n    \n    // Extract partial sums\n    int64_t total = 0;\n    int64_t* partial = (int64_t*)&sum;\n    total += partial[0] + partial[1] + partial[2] + partial[3];\n    \n    // Add remaining elements\n    for (; i <= m; i++) {\n        total += i;\n    }\n    \n    // Calculate average and round down\n    int64_t avg = total / count;\n    \n    if (avg == 0) return \"0\";\n    \n    // Convert to binary\n    std::string result;\n    while (avg > 0) {\n        result = (avg % 2 ? '1' : '0') + result;\n        avg /= 2;\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_111_AVX", "completion": "```cpp\nstd::string rounded_avg_simd(int64_t n, int64_t m) {\n    if (n > m) return \"-1\";\n    \n    __m256i sum = _mm256_setzero_si256();\n    int64_t count = m - n + 1;\n    \n    // Process 4 numbers at a time using AVX2\n    int64_t i;\n    for (i = n; i <= m-3; i += 4) {\n        __m256i nums = _mm256_set_epi64x(i+3, i+2, i+1, i);\n        sum = _mm256_add_epi64(sum, nums);\n    }\n    \n    // Sum remaining numbers\n    int64_t total = 0;\n    int64_t* sums = (int64_t*)&sum;\n    total = sums[0] + sums[1] + sums[2] + sums[3];\n    \n    // Add any remaining numbers\n    for (; i <= m; i++) {\n        total += i;\n    }\n    \n    // Calculate average and round down\n    int64_t avg = total / count;\n    \n    if (avg == 0) return \"0\";\n    \n    // Convert to binary string\n    std::string binary;\n    while (avg > 0) {\n        binary = (avg % 2 ? \"1\" : \"0\") + binary;\n        avg /= 2;\n    }\n    \n    return binary;\n}\n```"}
{"task_id": "SimdBench_111_AVX", "completion": "```cpp\nstd::string rounded_avg_simd(int64_t n, int64_t m) {\n    if (n > m) return \"-1\";\n    \n    __m256i sum = _mm256_setzero_si256();\n    int64_t count = m - n + 1;\n    \n    // Process 4 numbers at a time\n    int64_t i;\n    for (i = n; i <= m-3; i += 4) {\n        __m256i nums = _mm256_set_epi64x(i+3, i+2, i+1, i);\n        sum = _mm256_add_epi64(sum, nums);\n    }\n    \n    // Handle remaining elements\n    int64_t remaining_sum = 0;\n    for (; i <= m; i++) {\n        remaining_sum += i;\n    }\n    \n    // Extract sum from vector\n    int64_t vector_sum = 0;\n    int64_t* sum_array = (int64_t*)&sum;\n    for (int j = 0; j < 4; j++) {\n        vector_sum += sum_array[j];\n    }\n    \n    // Calculate final sum and average\n    int64_t total_sum = vector_sum + remaining_sum;\n    int64_t avg = total_sum / count;\n    \n    if (avg == 0) return \"0\";\n    \n    // Convert to binary\n    std::string binary;\n    while (avg > 0) {\n        binary = (avg % 2 ? \"1\" : \"0\") + binary;\n        avg /= 2;\n    }\n    \n    return binary;\n}\n```"}
{"task_id": "SimdBench_111_AVX", "completion": "```cpp\nstd::string rounded_avg_simd(int64_t n, int64_t m) {\n    if (n > m) return \"-1\";\n    \n    int64_t count = m - n + 1;\n    \n    __m256i vec_n = _mm256_set1_epi64x(n);\n    __m256i increment = _mm256_set_epi64x(3, 2, 1, 0);\n    \n    int64_t sum = 0;\n    int64_t i;\n    \n    for (i = n; i <= m-4; i += 4) {\n        __m256i curr = _mm256_add_epi64(vec_n, increment);\n        __m256i mask = _mm256_cmpgt_epi64(_mm256_set1_epi64x(m+1), curr);\n        curr = _mm256_and_si256(curr, mask);\n        \n        int64_t arr[4];\n        _mm256_storeu_si256((__m256i*)arr, curr);\n        \n        sum += arr[0] + arr[1] + arr[2] + arr[3];\n        vec_n = _mm256_add_epi64(vec_n, _mm256_set1_epi64x(4));\n    }\n    \n    for (; i <= m; i++) {\n        sum += i;\n    }\n    \n    int64_t avg = sum / count;\n    \n    if (avg == 0) return \"0\";\n    \n    std::string binary;\n    while (avg > 0) {\n        binary = (avg % 2 ? \"1\" : \"0\") + binary;\n        avg /= 2;\n    }\n    \n    return binary;\n}\n```"}
{"task_id": "SimdBench_111_AVX", "completion": "```cpp\nstd::string rounded_avg_simd(int64_t n, int64_t m) {\n    if (n > m) return \"-1\";\n    \n    __m256i sum = _mm256_setzero_si256();\n    int64_t count = m - n + 1;\n    \n    // Process 4 numbers at a time\n    int64_t i;\n    for (i = n; i <= m-3; i += 4) {\n        __m256i nums = _mm256_set_epi64x(i+3, i+2, i+1, i);\n        sum = _mm256_add_epi64(sum, nums);\n    }\n    \n    // Handle remaining elements\n    int64_t remaining_sum = 0;\n    for (; i <= m; i++) {\n        remaining_sum += i;\n    }\n    \n    // Extract sum from vector\n    int64_t vector_sum = 0;\n    int64_t* sum_array = (int64_t*)&sum;\n    for (int j = 0; j < 4; j++) {\n        vector_sum += sum_array[j];\n    }\n    \n    // Calculate final sum and average\n    int64_t total_sum = vector_sum + remaining_sum;\n    int64_t avg = total_sum / count;\n    \n    if (avg == 0) return \"0\";\n    \n    // Convert to binary\n    std::string binary;\n    while (avg > 0) {\n        binary = (avg % 2 ? \"1\" : \"0\") + binary;\n        avg /= 2;\n    }\n    \n    return binary;\n}\n```"}
{"task_id": "SimdBench_112_AVX", "completion": "```cpp\nstd::vector<int> func_simd(int n) {\n    std::vector<int> result(n);\n    \n    // Process 8 elements at a time using AVX2\n    const int simd_width = 8;\n    int i = 0;\n    \n    for (; i + simd_width <= n; i += simd_width) {\n        __m256i indices = _mm256_set_epi32(i+8, i+7, i+6, i+5, i+4, i+3, i+2, i+1);\n        __m256i ones = _mm256_set1_epi32(1);\n        __m256i twos = _mm256_set1_epi32(2);\n        __m256i mod = _mm256_set1_epi32(10000);\n        \n        // Calculate factorial for even indices\n        __m256i fact = ones;\n        __m256i counter = ones;\n        __m256i max_val = indices;\n        \n        while (_mm256_movemask_ps(_mm256_castsi256_ps(_mm256_cmpgt_epi32(max_val, counter))) != 0) {\n            counter = _mm256_add_epi32(counter, ones);\n            fact = _mm256_mullo_epi32(fact, counter);\n            fact = _mm256_rem_epi32(fact, mod);\n        }\n        \n        // Calculate sum for odd indices\n        __m256i sum = _mm256_setzero_si256();\n        counter = ones;\n        \n        while (_mm256_movemask_ps(_mm256_castsi256_ps(_mm256_cmpgt_epi32(indices, counter))) != 0) {\n            sum = _mm256_add_epi32(sum, counter);\n            counter = _mm256_add_epi32(counter, ones);\n        }\n        \n        // Create mask for even/odd indices\n        __m256i even_mask = _mm256_cmpeq_epi32(_mm256_and_si256(indices, ones), _mm256_setzero_si256());\n        \n        // Blend factorial and sum based on even/odd\n        __m256i final = _mm256_blendv_epi8(sum, fact, even_mask);\n        \n        // Store results\n        _mm256_storeu_si256((__m256i*)&result[i], final);\n    }\n    \n    // Handle remaining elements\n    for (; i < n; i++) {\n        if ((i + 1) % 2 == 0) {\n            int fact = 1;\n            for (int j = 1; j <= i + 1; j++) {\n                fact = (fact * j) % 10000;\n            }\n            result[i] = fact;\n        } else {\n            int sum = 0;\n            for (int j = 1; j <= i + 1; j++) {\n                sum += j;\n            }\n            result[i] = sum;\n        }\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_112_AVX", "completion": "```cpp\nstd::vector<int> func_simd(int n) {\n    std::vector<int> result(n);\n    \n    // Handle first element separately since i starts from 1\n    if (n > 0) result[0] = 1;\n    \n    // Process 8 elements at a time using AVX2\n    const int simd_width = 8;\n    int i = 1;\n    \n    for (; i + simd_width <= n; i += simd_width) {\n        __m256i indices = _mm256_set_epi32(i+7, i+6, i+5, i+4, i+3, i+2, i+1, i);\n        __m256i ones = _mm256_set1_epi32(1);\n        __m256i twos = _mm256_set1_epi32(2);\n        __m256i mod = _mm256_set1_epi32(10000);\n        \n        // Check if indices are even\n        __m256i is_even = _mm256_and_si256(indices, ones);\n        is_even = _mm256_cmpeq_epi32(is_even, _mm256_setzero_si256());\n        \n        // Calculate factorial for even indices\n        __m256i fact = _mm256_set1_epi32(1);\n        for (int j = 1; j <= n; j++) {\n            __m256i j_vec = _mm256_set1_epi32(j);\n            __m256i tmp = _mm256_mullo_epi32(fact, j_vec);\n            tmp = _mm256_rem_epi32(tmp, mod);\n            __m256i mask = _mm256_cmpgt_epi32(indices, j_vec);\n            fact = _mm256_blendv_epi8(fact, tmp, mask);\n        }\n        \n        // Calculate sum for odd indices\n        __m256i sum = _mm256_set1_epi32(0);\n        for (int j = 1; j <= n; j++) {\n            __m256i j_vec = _mm256_set1_epi32(j);\n            __m256i tmp = _mm256_add_epi32(sum, j_vec);\n            __m256i mask = _mm256_cmpgt_epi32(indices, j_vec);\n            sum = _mm256_blendv_epi8(sum, tmp, mask);\n        }\n        \n        // Select factorial or sum based on even/odd\n        __m256i final = _mm256_blendv_epi8(sum, fact, is_even);\n        \n        // Store results\n        _mm256_storeu_si256((__m256i*)&result[i], final);\n    }\n    \n    // Handle remaining elements\n    for (; i < n; i++) {\n        if ((i + 1) % 2 == 0) {\n            int fact = 1;\n            for (int j = 1; j <= i + 1; j++) {\n                fact = (fact * j) % 10000;\n            }\n            result[i] = fact;\n        } else {\n            int sum = 0;\n            for (int j = 1; j <= i + 1; j++) {\n                sum += j;\n            }\n            result[i] = sum;\n        }\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_112_AVX", "completion": "```cpp\nstd::vector<int> func_simd(int n) {\n    std::vector<int> result(n);\n    \n    // Process 8 elements at a time using AVX2\n    const int simd_width = 8;\n    int i = 0;\n    \n    for (; i + simd_width <= n; i += simd_width) {\n        __m256i indices = _mm256_set_epi32(i+8, i+7, i+6, i+5, i+4, i+3, i+2, i+1);\n        __m256i ones = _mm256_set1_epi32(1);\n        __m256i twos = _mm256_set1_epi32(2);\n        __m256i mod = _mm256_set1_epi32(10000);\n        \n        // Calculate factorial for even indices\n        __m256i fact = ones;\n        __m256i counter = ones;\n        __m256i max_val = indices;\n        \n        while (_mm256_movemask_ps(_mm256_castsi256_ps(_mm256_cmpgt_epi32(max_val, counter))) != 0) {\n            fact = _mm256_mullo_epi32(fact, counter);\n            fact = _mm256_rem_epi32(fact, mod);\n            counter = _mm256_add_epi32(counter, ones);\n        }\n        \n        // Calculate sum for odd indices\n        __m256i sum = _mm256_setzero_si256();\n        counter = ones;\n        \n        while (_mm256_movemask_ps(_mm256_castsi256_ps(_mm256_cmpgt_epi32(indices, counter))) != 0) {\n            sum = _mm256_add_epi32(sum, counter);\n            counter = _mm256_add_epi32(counter, ones);\n        }\n        sum = _mm256_add_epi32(sum, indices);\n        \n        // Select factorial or sum based on even/odd index\n        __m256i mask = _mm256_and_si256(indices, ones);\n        mask = _mm256_cmpeq_epi32(mask, _mm256_setzero_si256());\n        __m256i final = _mm256_blendv_epi8(sum, fact, mask);\n        \n        _mm256_storeu_si256((__m256i*)&result[i], final);\n    }\n    \n    // Handle remaining elements\n    for (; i < n; i++) {\n        if ((i + 1) % 2 == 0) {\n            int fact = 1;\n            for (int j = 1; j <= i + 1; j++) {\n                fact = (fact * j) % 10000;\n            }\n            result[i] = fact;\n        } else {\n            int sum = 0;\n            for (int j = 1; j <= i + 1; j++) {\n                sum += j;\n            }\n            result[i] = sum;\n        }\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_112_AVX", "completion": "```cpp\nstd::vector<int> func_simd(int n) {\n    std::vector<int> result(n);\n    \n    // Handle first element separately since i starts from 1\n    if (n > 0) result[0] = 1;\n    \n    // Process 8 elements at a time using AVX2\n    const int simd_width = 8;\n    int i = 1;\n    \n    for (; i + simd_width <= n; i += simd_width) {\n        __m256i indices = _mm256_set_epi32(i+7, i+6, i+5, i+4, i+3, i+2, i+1, i);\n        __m256i ones = _mm256_set1_epi32(1);\n        __m256i sums = _mm256_setzero_si256();\n        __m256i facts = _mm256_set1_epi32(1);\n        __m256i mod = _mm256_set1_epi32(10000);\n        \n        // Calculate both factorial and sum for all indices\n        for (int j = 1; j <= i + simd_width; j++) {\n            __m256i j_vec = _mm256_set1_epi32(j);\n            __m256i mask = _mm256_cmpgt_epi32(indices, j_vec);\n            __m256i add = _mm256_and_si256(ones, mask);\n            sums = _mm256_add_epi32(sums, add);\n            \n            facts = _mm256_mullo_epi32(facts, j_vec);\n            facts = _mm256_rem_epi32(facts, mod);\n        }\n        \n        // Select factorial for even indices, sum for odd indices\n        __m256i even_mask = _mm256_set1_epi32(1);\n        even_mask = _mm256_and_si256(indices, even_mask);\n        even_mask = _mm256_cmpeq_epi32(even_mask, _mm256_setzero_si256());\n        \n        __m256i result_vec = _mm256_blendv_epi8(sums, facts, even_mask);\n        \n        // Store results\n        int temp[8];\n        _mm256_storeu_si256((__m256i*)temp, result_vec);\n        for (int j = 0; j < simd_width && i+j < n; j++) {\n            result[i+j] = temp[j];\n        }\n    }\n    \n    // Handle remaining elements\n    for (; i < n; i++) {\n        if (i % 2 == 0) {\n            int fact = 1;\n            for (int j = 1; j <= i+1; j++) {\n                fact = (fact * j) % 10000;\n            }\n            result[i] = fact;\n        } else {\n            int sum = 0;\n            for (int j = 1; j <= i+1; j++) {\n                sum += 1;\n            }\n            result[i] = sum;\n        }\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_112_AVX", "completion": "```cpp\nstd::vector<int> func_simd(int n) {\n    std::vector<int> result(n);\n    \n    // Process 8 elements at a time using AVX2\n    const int simd_width = 8;\n    int i = 0;\n    \n    for (; i + simd_width <= n; i += simd_width) {\n        __m256i indices = _mm256_set_epi32(i+8, i+7, i+6, i+5, i+4, i+3, i+2, i+1);\n        __m256i ones = _mm256_set1_epi32(1);\n        __m256i twos = _mm256_set1_epi32(2);\n        __m256i mod = _mm256_set1_epi32(10000);\n        \n        // Calculate factorial for even indices\n        __m256i fact = ones;\n        __m256i j = ones;\n        __m256i temp_indices = indices;\n        \n        while (_mm256_movemask_ps(_mm256_castsi256_ps(_mm256_cmpgt_epi32(temp_indices, _mm256_setzero_si256()))) != 0) {\n            fact = _mm256_mullo_epi32(fact, j);\n            fact = _mm256_rem_epi32(fact, mod);\n            j = _mm256_add_epi32(j, ones);\n            temp_indices = _mm256_sub_epi32(temp_indices, ones);\n        }\n        \n        // Calculate sum for odd indices\n        __m256i sum = _mm256_setzero_si256();\n        j = ones;\n        temp_indices = indices;\n        \n        while (_mm256_movemask_ps(_mm256_castsi256_ps(_mm256_cmpgt_epi32(temp_indices, _mm256_setzero_si256()))) != 0) {\n            sum = _mm256_add_epi32(sum, j);\n            j = _mm256_add_epi32(j, ones);\n            temp_indices = _mm256_sub_epi32(temp_indices, ones);\n        }\n        \n        // Select factorial or sum based on even/odd index\n        __m256i mask = _mm256_and_si256(indices, ones);\n        mask = _mm256_cmpeq_epi32(mask, _mm256_setzero_si256());\n        __m256i final = _mm256_blendv_epi8(sum, fact, mask);\n        \n        _mm256_storeu_si256((__m256i*)&result[i], final);\n    }\n    \n    // Handle remaining elements\n    for (; i < n; i++) {\n        if ((i + 1) % 2 == 0) {\n            int fact = 1;\n            for (int j = 1; j <= i + 1; j++) {\n                fact = (fact * j) % 10000;\n            }\n            result[i] = fact;\n        } else {\n            int sum = 0;\n            for (int j = 1; j <= i + 1; j++) {\n                sum += j;\n            }\n            result[i] = sum;\n        }\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_113_AVX", "completion": "```cpp\nstd::vector<int> even_odd_palindrome_simd(int n) {\n    __m256i counts = _mm256_setzero_si256();\n    __m256i ones = _mm256_set1_epi32(1);\n    \n    // Process 8 numbers at a time\n    for(int i = 1; i <= n; i += 8) {\n        __m256i nums = _mm256_setr_epi32(i, i+1, i+2, i+3, i+4, i+5, i+6, i+7);\n        __m256i mask = _mm256_cmpgt_epi32(_mm256_set1_epi32(n+1), nums);\n        \n        // Check palindrome for each number\n        __m256i palindrome_mask = _mm256_setzero_si256();\n        __m256i even_mask = _mm256_setzero_si256();\n        \n        for(int j = 0; j < 8; j++) {\n            int num = ((int*)&nums)[j];\n            if(num > n) break;\n            \n            // Check if palindrome\n            int rev = 0;\n            int temp = num;\n            while(temp > 0) {\n                rev = rev * 10 + temp % 10;\n                temp /= 10;\n            }\n            \n            if(rev == num) {\n                ((int*)&palindrome_mask)[j] = -1;\n                if(num % 2 == 0) {\n                    ((int*)&even_mask)[j] = -1;\n                }\n            }\n        }\n        \n        // Mask with valid range\n        palindrome_mask = _mm256_and_si256(palindrome_mask, mask);\n        even_mask = _mm256_and_si256(even_mask, palindrome_mask);\n        \n        // Count even and odd palindromes\n        __m256i even_count = _mm256_and_si256(palindrome_mask, even_mask);\n        __m256i odd_count = _mm256_andnot_si256(even_mask, palindrome_mask);\n        \n        counts = _mm256_add_epi32(counts, \n                 _mm256_add_epi32(_mm256_and_si256(even_count, ones),\n                                 _mm256_and_si256(odd_count, ones)));\n    }\n    \n    // Horizontal sum\n    int even_sum = 0;\n    int odd_sum = 0;\n    for(int i = 0; i < 8; i++) {\n        if(((int*)&counts)[i] & 1) {\n            odd_sum++;\n        } else if(((int*)&counts)[i] > 0) {\n            even_sum++;\n        }\n    }\n    \n    return {even_sum, odd_sum};\n}\n```"}
{"task_id": "SimdBench_113_AVX", "completion": "```cpp\nstd::vector<int> even_odd_palindrome_simd(int n) {\n    std::vector<int> result(2, 0);\n    \n    __m256i counts = _mm256_setzero_si256();\n    __m256i ones = _mm256_set1_epi32(1);\n    \n    // Process 8 numbers at a time\n    for(int i = 1; i <= n; i += 8) {\n        __m256i nums = _mm256_setr_epi32(i, i+1, i+2, i+3, i+4, i+5, i+6, i+7);\n        __m256i mask = _mm256_cmpgt_epi32(_mm256_set1_epi32(n+1), nums);\n        \n        // Check palindrome for each number\n        __m256i palindrome_mask = _mm256_setzero_si256();\n        for(int j = 0; j < 8; j++) {\n            int num = i + j;\n            if(num > n) break;\n            \n            // Convert to string to check palindrome\n            char str[16];\n            sprintf(str, \"%d\", num);\n            int len = strlen(str);\n            bool is_palindrome = true;\n            \n            for(int k = 0; k < len/2; k++) {\n                if(str[k] != str[len-1-k]) {\n                    is_palindrome = false;\n                    break;\n                }\n            }\n            \n            if(is_palindrome) {\n                palindrome_mask = _mm256_insert_epi32(palindrome_mask, 1, j);\n            }\n        }\n        \n        // Count even/odd palindromes\n        __m256i even_mask = _mm256_and_si256(palindrome_mask, \n            _mm256_cmpeq_epi32(_mm256_and_si256(nums, ones), _mm256_setzero_si256()));\n            \n        __m256i odd_mask = _mm256_and_si256(palindrome_mask,\n            _mm256_cmpeq_epi32(_mm256_and_si256(nums, ones), ones));\n            \n        even_mask = _mm256_and_si256(even_mask, mask);\n        odd_mask = _mm256_and_si256(odd_mask, mask);\n        \n        counts = _mm256_add_epi32(counts, \n            _mm256_add_epi32(_mm256_and_si256(even_mask, ones), \n                            _mm256_and_si256(odd_mask, ones)));\n    }\n    \n    // Horizontal sum\n    int* temp = (int*)&counts;\n    int even_count = 0;\n    int odd_count = 0;\n    \n    for(int i = 0; i < 8; i++) {\n        if(i % 2 == 0) {\n            even_count += temp[i];\n        } else {\n            odd_count += temp[i];\n        }\n    }\n    \n    result[0] = even_count;\n    result[1] = odd_count;\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_113_AVX", "completion": "```cpp\nstd::vector<int> even_odd_palindrome_simd(int n) {\n    __m256i counts = _mm256_setzero_si256();\n    __m256i ones = _mm256_set1_epi32(1);\n    \n    // Process 8 numbers at a time\n    for(int i = 1; i <= n; i += 8) {\n        __m256i nums = _mm256_setr_epi32(i, i+1, i+2, i+3, i+4, i+5, i+6, i+7);\n        __m256i mask = _mm256_cmpgt_epi32(_mm256_set1_epi32(n+1), nums);\n        \n        // Check palindrome for each number\n        __m256i palindrome_mask = _mm256_setzero_si256();\n        __m256i even_mask = _mm256_setzero_si256();\n        \n        for(int j = 0; j < 8; j++) {\n            int num = ((int*)&nums)[j];\n            if(num > n) continue;\n            \n            // Check if palindrome\n            int rev = 0;\n            int temp = num;\n            while(temp > 0) {\n                rev = rev * 10 + temp % 10;\n                temp /= 10;\n            }\n            \n            if(rev == num) {\n                ((int*)&palindrome_mask)[j] = -1;\n                if(num % 2 == 0) {\n                    ((int*)&even_mask)[j] = -1;\n                }\n            }\n        }\n        \n        // Update counts based on masks\n        palindrome_mask = _mm256_and_si256(palindrome_mask, mask);\n        even_mask = _mm256_and_si256(even_mask, palindrome_mask);\n        \n        __m256i even_count = _mm256_and_si256(even_mask, ones);\n        __m256i odd_count = _mm256_and_si256(_mm256_xor_si256(even_mask, palindrome_mask), ones);\n        \n        counts = _mm256_add_epi32(counts, _mm256_add_epi32(\n            _mm256_slli_si256(even_count, 4),\n            odd_count\n        ));\n    }\n    \n    // Horizontal sum\n    int even_sum = 0;\n    int odd_sum = 0;\n    for(int i = 0; i < 8; i++) {\n        even_sum += ((int*)&counts)[i*2];\n        odd_sum += ((int*)&counts)[i*2+1];\n    }\n    \n    return {even_sum, odd_sum};\n}\n```"}
{"task_id": "SimdBench_113_AVX", "completion": "```cpp\nstd::vector<int> even_odd_palindrome_simd(int n) {\n    std::vector<int> result(2, 0);\n    \n    __m256i counts = _mm256_setzero_si256();\n    __m256i ones = _mm256_set1_epi32(1);\n    \n    // Process 8 numbers at a time\n    for(int i = 1; i <= n; i += 8) {\n        __m256i nums = _mm256_setr_epi32(i, i+1, i+2, i+3, i+4, i+5, i+6, i+7);\n        __m256i mask = _mm256_cmpgt_epi32(_mm256_set1_epi32(n+1), nums);\n        \n        // Check palindrome for each number\n        __m256i palindrome_mask = _mm256_setzero_si256();\n        __m256i even_mask = _mm256_setzero_si256();\n        \n        for(int j = 0; j < 8; j++) {\n            int num = ((int*)&nums)[j];\n            if(num > n) break;\n            \n            // Check if palindrome\n            int rev = 0;\n            int temp = num;\n            while(temp > 0) {\n                rev = rev * 10 + temp % 10;\n                temp /= 10;\n            }\n            \n            if(rev == num) {\n                ((int*)&palindrome_mask)[j] = -1;\n                if(num % 2 == 0) {\n                    ((int*)&even_mask)[j] = -1;\n                }\n            }\n        }\n        \n        // Combine masks\n        palindrome_mask = _mm256_and_si256(palindrome_mask, mask);\n        even_mask = _mm256_and_si256(even_mask, palindrome_mask);\n        \n        // Count palindromes\n        __m256i even_count = _mm256_and_si256(even_mask, ones);\n        __m256i odd_count = _mm256_and_si256(_mm256_xor_si256(palindrome_mask, even_mask), ones);\n        \n        counts = _mm256_add_epi32(counts, _mm256_add_epi32(\n            _mm256_and_si256(even_count, mask),\n            _mm256_slli_epi32(_mm256_and_si256(odd_count, mask), 16)\n        ));\n    }\n    \n    // Horizontal sum\n    int* count_array = (int*)&counts;\n    int even_sum = 0;\n    int odd_sum = 0;\n    for(int i = 0; i < 8; i++) {\n        even_sum += count_array[i] & 0xFFFF;\n        odd_sum += (count_array[i] >> 16) & 0xFFFF;\n    }\n    \n    result[0] = even_sum;\n    result[1] = odd_sum;\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_113_AVX", "completion": "```cpp\nstd::vector<int> even_odd_palindrome_simd(int n) {\n    __m256i counts = _mm256_setzero_si256();\n    __m256i ones = _mm256_set1_epi32(1);\n    \n    // Process 8 numbers at a time\n    for(int i = 1; i <= n; i += 8) {\n        __m256i nums = _mm256_setr_epi32(i, i+1, i+2, i+3, i+4, i+5, i+6, i+7);\n        __m256i masks = _mm256_cmpgt_epi32(_mm256_set1_epi32(n+1), nums);\n        \n        // Check palindrome for each number\n        __m256i palindrome_masks = _mm256_setzero_si256();\n        for(int j = 0; j < 8; j++) {\n            int num = ((int*)&nums)[j];\n            if(((int*)&masks)[j]) {\n                // Convert to string to check palindrome\n                char str[16];\n                int len = sprintf(str, \"%d\", num);\n                bool is_palindrome = true;\n                for(int k = 0; k < len/2; k++) {\n                    if(str[k] != str[len-1-k]) {\n                        is_palindrome = false;\n                        break;\n                    }\n                }\n                if(is_palindrome) {\n                    ((int*)&palindrome_masks)[j] = 1;\n                }\n            }\n        }\n        \n        // Check even/odd\n        __m256i even_nums = _mm256_and_si256(nums, _mm256_set1_epi32(1));\n        __m256i is_even = _mm256_cmpeq_epi32(even_nums, _mm256_setzero_si256());\n        \n        // Count even palindromes\n        __m256i even_palindromes = _mm256_and_si256(is_even, palindrome_masks);\n        even_palindromes = _mm256_and_si256(even_palindromes, masks);\n        counts = _mm256_add_epi32(counts, _mm256_and_si256(even_palindromes, ones));\n        \n        // Count odd palindromes  \n        __m256i odd_palindromes = _mm256_andnot_si256(is_even, palindrome_masks);\n        odd_palindromes = _mm256_and_si256(odd_palindromes, masks);\n        counts = _mm256_add_epi32(counts, _mm256_slli_epi32(_mm256_and_si256(odd_palindromes, ones), 1));\n    }\n    \n    // Horizontal sum\n    int* count_array = (int*)&counts;\n    int even_count = 0;\n    int odd_count = 0;\n    for(int i = 0; i < 8; i++) {\n        even_count += count_array[i] & 1;\n        odd_count += (count_array[i] >> 1) & 1;\n    }\n    \n    return {even_count, odd_count};\n}\n```"}
{"task_id": "SimdBench_114_AVX", "completion": "```cpp\nint count_nums_simd(std::vector<int> n) {\n    if (n.empty()) return 0;\n    \n    int count = 0;\n    int size = n.size();\n    int i = 0;\n\n    // Process 8 integers at a time using AVX2\n    for (; i + 8 <= size; i += 8) {\n        __m256i nums = _mm256_loadu_si256((__m256i*)&n[i]);\n        __m256i zeros = _mm256_setzero_si256();\n        __m256i result = zeros;\n\n        // Process each number's digits\n        while (1) {\n            __m256i quotient = _mm256_div_epi32(nums, _mm256_set1_epi32(10));\n            __m256i remainder = _mm256_sub_epi32(nums, _mm256_mullo_epi32(quotient, _mm256_set1_epi32(10)));\n            result = _mm256_add_epi32(result, remainder);\n            nums = quotient;\n            \n            // Check if all numbers are zero\n            __m256i cmp = _mm256_cmpeq_epi32(nums, zeros);\n            if (_mm256_movemask_ps(_mm256_castsi256_ps(cmp)) == 0xFF) break;\n        }\n\n        // Compare sum of digits with zero\n        __m256i cmp = _mm256_cmpgt_epi32(result, zeros);\n        int mask = _mm256_movemask_ps(_mm256_castsi256_ps(cmp));\n        count += _mm_popcnt_u32(mask);\n    }\n\n    // Process remaining elements\n    for (; i < size; i++) {\n        int num = n[i];\n        int sum = 0;\n        while (num != 0) {\n            sum += num % 10;\n            num /= 10;\n        }\n        if (sum > 0) count++;\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_114_AVX", "completion": "```cpp\nint count_nums_simd(std::vector<int> n) {\n    if (n.empty()) return 0;\n    \n    int count = 0;\n    int size = n.size();\n    int i = 0;\n\n    // Process 8 integers at a time using AVX2\n    for (; i + 8 <= size; i += 8) {\n        __m256i nums = _mm256_loadu_si256((__m256i*)&n[i]);\n        __m256i zeros = _mm256_setzero_si256();\n        __m256i result = zeros;\n        \n        // Process each digit until all numbers become 0\n        while (_mm256_movemask_epi8(_mm256_cmpeq_epi32(nums, zeros)) != -1) {\n            // Get remainder when divided by 10\n            __m256i div10 = _mm256_set1_epi32(10);\n            __m256i rem = _mm256_rem_epi32(nums, div10);\n            \n            // Add remainder to result\n            result = _mm256_add_epi32(result, rem);\n            \n            // Divide numbers by 10\n            nums = _mm256_div_epi32(nums, div10);\n        }\n        \n        // Store results\n        int temp[8];\n        _mm256_storeu_si256((__m256i*)temp, result);\n        \n        // Count numbers with non-zero sum\n        for (int j = 0; j < 8; j++) {\n            if (temp[j] != 0) count++;\n        }\n    }\n\n    // Process remaining elements\n    for (; i < size; i++) {\n        int num = n[i];\n        int sum = 0;\n        while (num != 0) {\n            sum += num % 10;\n            num /= 10;\n        }\n        if (sum != 0) count++;\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_114_AVX", "completion": "```cpp\nint count_nums_simd(std::vector<int> n) {\n    if (n.empty()) return 0;\n    \n    int count = 0;\n    int size = n.size();\n    int i = 0;\n\n    // Process 8 integers at a time using AVX2\n    for (; i + 8 <= size; i += 8) {\n        __m256i nums = _mm256_loadu_si256((__m256i*)&n[i]);\n        __m256i zeros = _mm256_setzero_si256();\n        __m256i result = zeros;\n        \n        // Process each digit until all numbers become 0\n        while (_mm256_movemask_ps(_mm256_castsi256_ps(_mm256_cmpeq_epi32(nums, zeros))) != 0xFF) {\n            __m256i abs_nums = _mm256_abs_epi32(nums);\n            __m256i remainders = _mm256_rem_epi32(abs_nums, _mm256_set1_epi32(10));\n            \n            // For negative numbers, make the first digit negative\n            __m256i signs = _mm256_srai_epi32(nums, 31);\n            remainders = _mm256_xor_si256(remainders, signs);\n            remainders = _mm256_sub_epi32(remainders, signs);\n            \n            // Add digit to result\n            result = _mm256_add_epi32(result, remainders);\n            nums = _mm256_div_epi32(nums, _mm256_set1_epi32(10));\n        }\n        \n        // Count numbers with non-zero digit sum\n        __m256i mask = _mm256_cmpgt_epi32(result, zeros);\n        mask = _mm256_or_si256(mask, _mm256_cmplt_epi32(result, zeros));\n        count += _mm_popcnt_u32(_mm256_movemask_ps(_mm256_castsi256_ps(mask)));\n    }\n\n    // Process remaining elements\n    for (; i < size; i++) {\n        int num = n[i];\n        int sum = 0;\n        bool first = true;\n        \n        while (num != 0) {\n            int digit = abs(num % 10);\n            if (first && num < 0) {\n                digit = -digit;\n                first = false;\n            }\n            sum += digit;\n            num /= 10;\n        }\n        \n        if (sum != 0) count++;\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_114_AVX", "completion": "```cpp\nint count_nums_simd(std::vector<int> n) {\n    if (n.empty()) return 0;\n    \n    int count = 0;\n    int size = n.size();\n    int i = 0;\n\n    // Process 8 integers at a time using AVX2\n    for (; i + 8 <= size; i += 8) {\n        __m256i nums = _mm256_loadu_si256((__m256i*)&n[i]);\n        __m256i zeros = _mm256_setzero_si256();\n        __m256i result = zeros;\n        \n        // Process each digit until all numbers are zero\n        while (_mm256_movemask_epi8(_mm256_cmpeq_epi32(nums, zeros)) != -1) {\n            // Get remainder when divided by 10\n            __m256i div10 = _mm256_set1_epi32(10);\n            __m256i rem = _mm256_rem_epi32(nums, div10);\n            \n            // Add remainder to result\n            result = _mm256_add_epi32(result, rem);\n            \n            // Divide by 10 for next iteration\n            nums = _mm256_div_epi32(nums, div10);\n        }\n        \n        // Compare if sum > 0 and add to count\n        __m256i mask = _mm256_cmpgt_epi32(result, zeros);\n        int bits = _mm256_movemask_ps(_mm256_castsi256_ps(mask));\n        count += _mm_popcnt_u32(bits);\n    }\n\n    // Process remaining elements\n    for (; i < size; i++) {\n        int num = n[i];\n        int sum = 0;\n        while (num != 0) {\n            sum += num % 10;\n            num /= 10;\n        }\n        if (sum > 0) count++;\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_114_AVX", "completion": "```cpp\nint count_nums_simd(std::vector<int> n) {\n    if (n.empty()) return 0;\n    \n    int count = 0;\n    int size = n.size();\n    int i = 0;\n\n    // Process 8 integers at a time using AVX2\n    for (; i + 8 <= size; i += 8) {\n        __m256i nums = _mm256_loadu_si256((__m256i*)&n[i]);\n        __m256i zeros = _mm256_setzero_si256();\n        __m256i signs = _mm256_cmpgt_epi32(zeros, nums);\n        __m256i abs_nums = _mm256_abs_epi32(nums);\n        \n        int sums[8] = {0};\n        __m256i vec = abs_nums;\n        \n        while (_mm256_movemask_epi8(_mm256_cmpeq_epi32(vec, zeros)) != -1) {\n            __m256i remainder = _mm256_rem_epi32(vec, _mm256_set1_epi32(10));\n            __m256i curr_sums = _mm256_loadu_si256((__m256i*)sums);\n            curr_sums = _mm256_add_epi32(curr_sums, remainder);\n            _mm256_storeu_si256((__m256i*)sums, curr_sums);\n            vec = _mm256_div_epi32(vec, _mm256_set1_epi32(10));\n        }\n\n        // Apply sign to first digit\n        __m256i final_sums = _mm256_loadu_si256((__m256i*)sums);\n        __m256i neg_sums = _mm256_sub_epi32(zeros, final_sums);\n        final_sums = _mm256_blendv_epi8(final_sums, neg_sums, signs);\n        \n        // Compare sums with zero\n        __m256i mask = _mm256_cmpgt_epi32(final_sums, zeros);\n        int nonzero = _mm256_movemask_ps(_mm256_castsi256_ps(mask));\n        count += _mm_popcnt_u32(nonzero);\n    }\n\n    // Handle remaining elements\n    for (; i < size; i++) {\n        int num = n[i];\n        int sum = 0;\n        bool isNeg = num < 0;\n        num = abs(num);\n        \n        bool first = true;\n        while (num) {\n            int digit = num % 10;\n            if (first && isNeg) {\n                sum -= digit;\n            } else {\n                sum += digit;\n            }\n            first = false;\n            num /= 10;\n        }\n        \n        if (sum > 0) count++;\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_115_AVX", "completion": "```cpp\nbool move_one_ball_simd(std::vector<int> arr) {\n    if (arr.size() <= 1) return true;\n    \n    int n = arr.size();\n    \n    // Find position of minimum element\n    __m256i vmin = _mm256_set1_epi32(INT_MAX);\n    int min_pos = 0;\n    \n    for (int i = 0; i < n; i += 8) {\n        int remaining = std::min(8, n - i);\n        \n        if (remaining < 8) {\n            // Handle remaining elements serially\n            for (int j = i; j < n; j++) {\n                if (arr[j] < _mm256_extract_epi32(vmin, 0)) {\n                    vmin = _mm256_set1_epi32(arr[j]);\n                    min_pos = j;\n                }\n            }\n            continue;\n        }\n        \n        __m256i vcurr = _mm256_loadu_si256((__m256i*)&arr[i]);\n        __m256i vcmp = _mm256_cmpgt_epi32(vmin, vcurr);\n        \n        int mask = _mm256_movemask_ps(_mm256_castsi256_ps(vcmp));\n        \n        if (mask) {\n            for (int j = 0; j < 8; j++) {\n                if (mask & (1 << j)) {\n                    if (arr[i + j] < _mm256_extract_epi32(vmin, 0)) {\n                        vmin = _mm256_set1_epi32(arr[i + j]);\n                        min_pos = i + j;\n                    }\n                }\n            }\n        }\n    }\n    \n    // Check if array is sorted after rotation\n    int prev = arr[min_pos];\n    for (int i = 1; i < n; i++) {\n        int curr_pos = (min_pos + i) % n;\n        if (arr[curr_pos] < prev) return false;\n        prev = arr[curr_pos];\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_115_AVX", "completion": "```cpp\nbool move_one_ball_simd(std::vector<int> arr) {\n    if (arr.empty()) return true;\n    \n    int n = arr.size();\n    if (n == 1) return true;\n\n    // Find minimum element and its index\n    __m256i vmin = _mm256_set1_epi32(INT_MAX);\n    int min_val = INT_MAX;\n    int min_idx = 0;\n    \n    for (int i = 0; i < n; i += 8) {\n        int remaining = std::min(8, n - i);\n        \n        if (remaining == 8) {\n            __m256i curr = _mm256_loadu_si256((__m256i*)&arr[i]);\n            vmin = _mm256_min_epi32(vmin, curr);\n        } else {\n            for (int j = i; j < n; j++) {\n                if (arr[j] < min_val) {\n                    min_val = arr[j];\n                    min_idx = j;\n                }\n            }\n        }\n    }\n    \n    // Find minimum from vector\n    alignas(32) int min_arr[8];\n    _mm256_store_si256((__m256i*)min_arr, vmin);\n    for (int i = 0; i < 8; i++) {\n        if (min_arr[i] < min_val) {\n            min_val = min_arr[i];\n        }\n    }\n    \n    // Find index of minimum\n    for (int i = 0; i < n; i++) {\n        if (arr[i] == min_val) {\n            min_idx = i;\n            break;\n        }\n    }\n\n    // Check if array is sorted after rotation\n    __m256i prev = _mm256_set1_epi32(min_val);\n    bool sorted = true;\n    \n    for (int i = 1; i < n; i++) {\n        int curr_idx = (min_idx + i) % n;\n        int prev_idx = (min_idx + i - 1) % n;\n        \n        if (arr[curr_idx] < arr[prev_idx]) {\n            sorted = false;\n            break;\n        }\n    }\n\n    return sorted;\n}\n```"}
{"task_id": "SimdBench_115_AVX", "completion": "```cpp\nbool move_one_ball_simd(std::vector<int> arr) {\n    if (arr.empty()) return true;\n    \n    int n = arr.size();\n    if (n == 1) return true;\n\n    // Find minimum element and its index\n    __m256i vmin = _mm256_set1_epi32(INT_MAX);\n    int min_val = INT_MAX;\n    int min_idx = 0;\n    \n    for (int i = 0; i < n; i += 8) {\n        int remaining = std::min(8, n - i);\n        if (remaining < 8) {\n            for (int j = i; j < n; j++) {\n                if (arr[j] < min_val) {\n                    min_val = arr[j];\n                    min_idx = j;\n                }\n            }\n            break;\n        }\n        \n        __m256i curr = _mm256_loadu_si256((__m256i*)&arr[i]);\n        vmin = _mm256_min_epi32(vmin, curr);\n        \n        alignas(32) int min_arr[8];\n        _mm256_store_si256((__m256i*)min_arr, vmin);\n        \n        for (int j = 0; j < 8; j++) {\n            if (min_arr[j] < min_val) {\n                min_val = min_arr[j];\n                for (int k = i; k < i + 8; k++) {\n                    if (arr[k] == min_val) {\n                        min_idx = k;\n                        break;\n                    }\n                }\n            }\n        }\n    }\n\n    // Check if array can be sorted by rotation\n    bool increasing = true;\n    __m256i prev = _mm256_set1_epi32(min_val);\n    \n    for (int i = 1; i < n; i++) {\n        int curr_idx = (min_idx + i) % n;\n        int prev_idx = (min_idx + i - 1) % n;\n        \n        if (arr[curr_idx] < arr[prev_idx]) {\n            increasing = false;\n            break;\n        }\n    }\n\n    return increasing;\n}\n```"}
{"task_id": "SimdBench_115_AVX", "completion": "```cpp\nbool move_one_ball_simd(std::vector<int> arr) {\n    if (arr.size() <= 1) return true;\n    \n    size_t n = arr.size();\n    size_t vec_size = (n + 7) / 8 * 8; // Round up to multiple of 8\n    \n    std::vector<int> padded(vec_size, INT_MAX);\n    std::copy(arr.begin(), arr.end(), padded.begin());\n    \n    // Find minimum element and its position\n    __m256i min_vec = _mm256_set1_epi32(INT_MAX);\n    for (size_t i = 0; i < vec_size; i += 8) {\n        __m256i curr = _mm256_loadu_si256((__m256i*)&padded[i]);\n        min_vec = _mm256_min_epi32(min_vec, curr);\n    }\n    \n    int min_arr[8];\n    _mm256_storeu_si256((__m256i*)min_arr, min_vec);\n    int min_val = INT_MAX;\n    for (int i = 0; i < 8; i++) {\n        min_val = std::min(min_val, min_arr[i]);\n    }\n    \n    int min_pos = 0;\n    for (size_t i = 0; i < n; i++) {\n        if (arr[i] == min_val) {\n            min_pos = i;\n            break;\n        }\n    }\n    \n    // Check if elements after min_pos are sorted\n    __m256i prev_vec = _mm256_set1_epi32(min_val);\n    bool sorted = true;\n    \n    for (size_t i = 0; i < n - min_pos - 1; i += 8) {\n        size_t remaining = std::min(size_t(8), n - min_pos - i);\n        __m256i curr;\n        \n        if (remaining < 8) {\n            int temp[8] = {INT_MAX, INT_MAX, INT_MAX, INT_MAX, INT_MAX, INT_MAX, INT_MAX, INT_MAX};\n            for (size_t j = 0; j < remaining; j++) {\n                temp[j] = arr[(min_pos + i + j + 1) % n];\n            }\n            curr = _mm256_loadu_si256((__m256i*)temp);\n        } else {\n            curr = _mm256_loadu_si256((__m256i*)&arr[(min_pos + i + 1) % n]);\n        }\n        \n        __m256i cmp = _mm256_cmpgt_epi32(prev_vec, curr);\n        int mask = _mm256_movemask_ps(_mm256_castsi256_ps(cmp));\n        \n        if (mask != 0) {\n            sorted = false;\n            break;\n        }\n        \n        prev_vec = curr;\n    }\n    \n    if (!sorted) return false;\n    \n    // Check if elements before min_pos are sorted\n    prev_vec = _mm256_set1_epi32(arr[n-1]);\n    \n    for (size_t i = 0; i < min_pos; i += 8) {\n        size_t remaining = std::min(size_t(8), min_pos - i);\n        __m256i curr;\n        \n        if (remaining < 8) {\n            int temp[8] = {INT_MAX, INT_MAX, INT_MAX, INT_MAX, INT_MAX, INT_MAX, INT_MAX, INT_MAX};\n            for (size_t j = 0; j < remaining; j++) {\n                temp[j] = arr[i + j];\n            }\n            curr = _mm256_loadu_si256((__m256i*)temp);\n        } else {\n            curr = _mm256_loadu_si256((__m256i*)&arr[i]);\n        }\n        \n        __m256i cmp = _mm256_cmpgt_epi32(prev_vec, curr);\n        int mask = _mm256_movemask_ps(_mm256_castsi256_ps(cmp));\n        \n        if (mask != 0) return false;\n        \n        prev_vec = curr;\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_115_AVX", "completion": "```cpp\nbool move_one_ball_simd(std::vector<int> arr) {\n    if (arr.empty()) return true;\n    \n    int n = arr.size();\n    if (n == 1) return true;\n\n    // Find minimum element and its index\n    __m256i vmin = _mm256_set1_epi32(INT_MAX);\n    int min_val = INT_MAX;\n    int min_idx = 0;\n    \n    for (int i = 0; i < n; i += 8) {\n        __m256i curr;\n        if (i + 8 <= n) {\n            curr = _mm256_loadu_si256((__m256i*)&arr[i]);\n        } else {\n            // Handle remaining elements\n            alignas(32) int temp[8] = {INT_MAX, INT_MAX, INT_MAX, INT_MAX, \n                                     INT_MAX, INT_MAX, INT_MAX, INT_MAX};\n            for(int j = i; j < n; j++) {\n                temp[j-i] = arr[j];\n            }\n            curr = _mm256_load_si256((__m256i*)temp);\n        }\n        \n        vmin = _mm256_min_epi32(vmin, curr);\n        \n        alignas(32) int min_arr[8];\n        _mm256_store_si256((__m256i*)min_arr, curr);\n        \n        for(int j = 0; j < 8 && i+j < n; j++) {\n            if(min_arr[j] < min_val) {\n                min_val = min_arr[j];\n                min_idx = i + j;\n            }\n        }\n    }\n\n    // Check if array after rotation at min_idx is sorted\n    int prev = arr[min_idx];\n    for(int i = 1; i < n; i++) {\n        int curr = arr[(min_idx + i) % n];\n        if(curr < prev) return false;\n        prev = curr;\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_116_AVX", "completion": "```cpp\nstd::string myexchange_simd(const std::vector<int>& lst1, const std::vector<int>& lst2) {\n    int n = lst1.size();\n    int odd_count1 = 0;\n    int even_count2 = 0;\n    \n    // Process 8 elements at a time using AVX2\n    const int simd_width = 8;\n    int aligned_size = n - (n % simd_width);\n    \n    __m256i ones = _mm256_set1_epi32(1);\n    \n    for(int i = 0; i < aligned_size; i += simd_width) {\n        // Load 8 integers from lst1\n        __m256i v1 = _mm256_loadu_si256((__m256i*)&lst1[i]);\n        \n        // Check odd/even by AND with 1\n        __m256i mask1 = _mm256_and_si256(v1, ones);\n        \n        // Count odd numbers in lst1\n        int odd_mask1 = _mm256_movemask_ps(_mm256_castsi256_ps(mask1));\n        odd_count1 += _mm_popcnt_u32(odd_mask1);\n        \n        // Load 8 integers from lst2\n        __m256i v2 = _mm256_loadu_si256((__m256i*)&lst2[i]);\n        \n        // Check odd/even\n        __m256i mask2 = _mm256_and_si256(v2, ones);\n        \n        // Count even numbers in lst2\n        int even_mask2 = _mm256_movemask_ps(_mm256_castsi256_ps(mask2));\n        even_count2 += _mm_popcnt_u32(~even_mask2 & 0xFF);\n    }\n    \n    // Handle remaining elements\n    for(int i = aligned_size; i < n; i++) {\n        if(lst1[i] & 1) odd_count1++;\n        if(!(lst2[i] & 1)) even_count2++;\n    }\n    \n    return (even_count2 >= odd_count1) ? \"YES\" : \"NO\";\n}\n```"}
{"task_id": "SimdBench_116_AVX", "completion": "```cpp\nstd::string myexchange_simd(const std::vector<int>& lst1, const std::vector<int>& lst2) {\n    int n = lst1.size();\n    int odd_count1 = 0;\n    int even_count2 = 0;\n    \n    // Process 8 elements at a time using AVX2\n    const int simd_width = 8;\n    int aligned_size = n - (n % simd_width);\n    \n    __m256i ones = _mm256_set1_epi32(1);\n    \n    for (int i = 0; i < aligned_size; i += simd_width) {\n        // Load 8 integers from lst1\n        __m256i v1 = _mm256_loadu_si256((__m256i*)&lst1[i]);\n        \n        // Check odd numbers in lst1\n        __m256i and_result1 = _mm256_and_si256(v1, ones);\n        __m256i cmp_result1 = _mm256_cmpeq_epi32(and_result1, ones);\n        int mask1 = _mm256_movemask_ps(_mm256_castsi256_ps(cmp_result1));\n        odd_count1 += _mm_popcnt_u32(mask1);\n        \n        // Load 8 integers from lst2\n        __m256i v2 = _mm256_loadu_si256((__m256i*)&lst2[i]);\n        \n        // Check even numbers in lst2\n        __m256i and_result2 = _mm256_and_si256(v2, ones);\n        __m256i cmp_result2 = _mm256_cmpeq_epi32(and_result2, _mm256_setzero_si256());\n        int mask2 = _mm256_movemask_ps(_mm256_castsi256_ps(cmp_result2));\n        even_count2 += _mm_popcnt_u32(mask2);\n    }\n    \n    // Handle remaining elements\n    for (int i = aligned_size; i < n; i++) {\n        if (lst1[i] & 1) odd_count1++;\n        if (!(lst2[i] & 1)) even_count2++;\n    }\n    \n    return (even_count2 >= odd_count1) ? \"YES\" : \"NO\";\n}\n```"}
{"task_id": "SimdBench_116_AVX", "completion": "```cpp\nstd::string myexchange_simd(const std::vector<int>& lst1, const std::vector<int>& lst2) {\n    int n = lst1.size();\n    int odd_count1 = 0;\n    int even_count2 = 0;\n    \n    // Process 8 elements at a time using AVX2\n    const int simd_width = 8;\n    int aligned_size = n - (n % simd_width);\n    \n    __m256i ones = _mm256_set1_epi32(1);\n    \n    for (int i = 0; i < aligned_size; i += simd_width) {\n        // Load 8 integers from lst1\n        __m256i v1 = _mm256_loadu_si256((__m256i*)&lst1[i]);\n        \n        // Check which numbers are odd in lst1\n        __m256i mask1 = _mm256_and_si256(v1, ones);\n        int odd_mask1 = _mm256_movemask_ps(_mm256_castsi256_ps(mask1));\n        odd_count1 += _mm_popcnt_u32(odd_mask1);\n        \n        // Load 8 integers from lst2\n        __m256i v2 = _mm256_loadu_si256((__m256i*)&lst2[i]);\n        \n        // Check which numbers are even in lst2\n        __m256i mask2 = _mm256_and_si256(v2, ones);\n        int odd_mask2 = _mm256_movemask_ps(_mm256_castsi256_ps(mask2));\n        even_count2 += 8 - _mm_popcnt_u32(odd_mask2);\n    }\n    \n    // Handle remaining elements\n    for (int i = aligned_size; i < n; i++) {\n        if (lst1[i] & 1) odd_count1++;\n        if (!(lst2[i] & 1)) even_count2++;\n    }\n    \n    return (even_count2 >= odd_count1) ? \"YES\" : \"NO\";\n}\n```"}
{"task_id": "SimdBench_116_AVX", "completion": "```cpp\nstd::string myexchange_simd(const std::vector<int>& lst1, const std::vector<int>& lst2) {\n    int n = lst1.size();\n    int odd_count1 = 0;\n    int even_count2 = 0;\n    \n    // Process 8 elements at a time using AVX2\n    const int simd_width = 8;\n    int aligned_size = n - (n % simd_width);\n    \n    __m256i ones = _mm256_set1_epi32(1);\n    \n    for (int i = 0; i < aligned_size; i += simd_width) {\n        // Load 8 integers from lst1\n        __m256i v1 = _mm256_loadu_si256((__m256i*)&lst1[i]);\n        \n        // Check odd/even by AND with 1\n        __m256i mask1 = _mm256_and_si256(v1, ones);\n        \n        // Count odd numbers in lst1\n        int odd_mask1 = _mm256_movemask_ps(_mm256_castsi256_ps(mask1));\n        odd_count1 += _mm_popcnt_u32(odd_mask1);\n        \n        // Load 8 integers from lst2\n        __m256i v2 = _mm256_loadu_si256((__m256i*)&lst2[i]);\n        \n        // Check odd/even\n        __m256i mask2 = _mm256_and_si256(v2, ones);\n        \n        // Count even numbers in lst2\n        int even_mask2 = _mm256_movemask_ps(_mm256_castsi256_ps(mask2));\n        even_count2 += _mm_popcnt_u32(~even_mask2 & 0xFF);\n    }\n    \n    // Handle remaining elements\n    for (int i = aligned_size; i < n; i++) {\n        if (lst1[i] & 1) odd_count1++;\n        if (!(lst2[i] & 1)) even_count2++;\n    }\n    \n    return (even_count2 >= odd_count1) ? \"YES\" : \"NO\";\n}\n```"}
{"task_id": "SimdBench_116_AVX", "completion": "```cpp\nstd::string myexchange_simd(const std::vector<int>& lst1, const std::vector<int>& lst2) {\n    int n = lst1.size();\n    \n    // Count odd numbers in lst1 and even numbers in lst2\n    int odd_count1 = 0;\n    int even_count2 = 0;\n    \n    // Process 8 elements at a time using AVX2\n    const int simd_size = 8;\n    int aligned_size = n - (n % simd_size);\n    \n    __m256i ones = _mm256_set1_epi32(1);\n    \n    for(int i = 0; i < aligned_size; i += simd_size) {\n        // Load 8 integers from lst1 and lst2\n        __m256i v1 = _mm256_loadu_si256((__m256i*)&lst1[i]);\n        __m256i v2 = _mm256_loadu_si256((__m256i*)&lst2[i]);\n        \n        // Check odd/even by AND with 1\n        __m256i odd1 = _mm256_and_si256(v1, ones);\n        __m256i odd2 = _mm256_and_si256(v2, ones);\n        \n        // Convert comparison results to masks\n        int mask1 = _mm256_movemask_ps(_mm256_castsi256_ps(odd1));\n        int mask2 = _mm256_movemask_ps(_mm256_castsi256_ps(odd2));\n        \n        // Count set bits\n        odd_count1 += _mm_popcnt_u32(mask1);\n        even_count2 += 8 - _mm_popcnt_u32(mask2);\n    }\n    \n    // Handle remaining elements\n    for(int i = aligned_size; i < n; i++) {\n        if(lst1[i] & 1) odd_count1++;\n        if(!(lst2[i] & 1)) even_count2++;\n    }\n    \n    // If number of odd elements in lst1 is less than or equal to \n    // number of even elements in lst2, exchange is possible\n    return (odd_count1 <= even_count2) ? \"YES\" : \"NO\";\n}\n```"}
{"task_id": "SimdBench_117_AVX", "completion": "```cpp\nstd::vector<std::string> odd_count_simd(const std::vector<std::string>& lst) {\n    std::vector<std::string> result;\n    const char* template_str = \"the number of odd elements %n the str%ng % of the %nput.\";\n    \n    for (const auto& str : lst) {\n        int odd_count = 0;\n        size_t len = str.length();\n        \n        // Process 32 characters at a time using AVX2\n        const size_t vec_size = 32;\n        size_t vec_len = len - (len % vec_size);\n        \n        for (size_t i = 0; i < vec_len; i += vec_size) {\n            __m256i chars = _mm256_loadu_si256((__m256i*)(str.c_str() + i));\n            \n            // Convert ASCII digits to actual numbers by subtracting '0'\n            __m256i nums = _mm256_sub_epi8(chars, _mm256_set1_epi8('0'));\n            \n            // Create mask for odd numbers\n            __m256i odd_mask = _mm256_and_si256(nums, _mm256_set1_epi8(1));\n            \n            // Count odd numbers using popcount\n            uint32_t mask = _mm256_movemask_epi8(_mm256_cmpeq_epi8(odd_mask, _mm256_set1_epi8(1)));\n            odd_count += _mm_popcnt_u32(mask);\n        }\n        \n        // Handle remaining characters\n        for (size_t i = vec_len; i < len; i++) {\n            int digit = str[i] - '0';\n            odd_count += digit & 1;\n        }\n        \n        // Create result string\n        char buffer[256];\n        snprintf(buffer, sizeof(buffer), template_str, \n                odd_count, odd_count, odd_count, odd_count);\n        result.push_back(std::string(buffer));\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_117_AVX", "completion": "```cpp\nstd::vector<std::string> odd_count_simd(const std::vector<std::string>& lst) {\n    std::vector<std::string> result;\n    result.reserve(lst.size());\n    \n    const char* template_str = \"the number of odd elements %n the str%ng % of the %nput.\";\n    \n    for (const auto& str : lst) {\n        // Load string into vector registers\n        int len = str.length();\n        int vec_size = (len + 31) / 32 * 32; // Round up to nearest 32\n        \n        __m256i odd_mask = _mm256_set1_epi8(1);\n        __m256i zeros = _mm256_setzero_si256();\n        int odd_count = 0;\n        \n        for (int i = 0; i < len; i += 32) {\n            // Load 32 bytes (chars) into vector register\n            __m256i chars;\n            if (i + 32 <= len) {\n                chars = _mm256_loadu_si256((__m256i*)(str.c_str() + i));\n            } else {\n                // Handle remaining bytes\n                char temp[32] = {0};\n                memcpy(temp, str.c_str() + i, len - i);\n                chars = _mm256_loadu_si256((__m256i*)temp);\n            }\n            \n            // Convert chars to integers\n            __m256i nums = _mm256_sub_epi8(chars, _mm256_set1_epi8('0'));\n            \n            // Check for odd numbers using AND with 1\n            __m256i odds = _mm256_and_si256(nums, odd_mask);\n            \n            // Compare with zeros to get mask of odd numbers\n            __m256i cmp = _mm256_cmpeq_epi8(odds, odd_mask);\n            \n            // Count number of 1s in mask\n            unsigned mask = _mm256_movemask_epi8(cmp);\n            odd_count += _mm_popcnt_u32(mask);\n        }\n        \n        // Create result string\n        char result_str[256];\n        snprintf(result_str, sizeof(result_str), template_str, \n                odd_count, odd_count, odd_count, odd_count);\n        result.emplace_back(result_str);\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_117_AVX", "completion": "```cpp\nstd::vector<std::string> odd_count_simd(const std::vector<std::string>& lst) {\n    std::vector<std::string> result;\n    result.reserve(lst.size());\n    \n    const char* template_str = \"the number of odd elements %n the str%ng % of the %nput.\";\n    \n    for (const auto& s : lst) {\n        __m256i nums = _mm256_setzero_si256();\n        const int len = s.length();\n        int i = 0;\n        \n        // Process 32 characters at a time\n        for (; i + 31 < len; i += 32) {\n            __m256i chars = _mm256_loadu_si256((__m256i*)(s.data() + i));\n            \n            // Convert chars to integers by subtracting '0'\n            chars = _mm256_sub_epi8(chars, _mm256_set1_epi8('0'));\n            \n            // Create mask for odd numbers\n            __m256i odd_mask = _mm256_and_si256(chars, _mm256_set1_epi8(1));\n            odd_mask = _mm256_cmpeq_epi8(odd_mask, _mm256_set1_epi8(1));\n            \n            // Count odd numbers\n            nums = _mm256_add_epi8(nums, _mm256_and_si256(odd_mask, _mm256_set1_epi8(1)));\n        }\n        \n        // Sum up the counts\n        int odd_count = 0;\n        uint8_t counts[32];\n        _mm256_storeu_si256((__m256i*)counts, nums);\n        \n        for (int j = 0; j < 32; j++) {\n            odd_count += counts[j];\n        }\n        \n        // Handle remaining characters\n        for (; i < len; i++) {\n            if ((s[i] - '0') & 1) {\n                odd_count++;\n            }\n        }\n        \n        // Create result string\n        std::string res;\n        res.reserve(strlen(template_str));\n        \n        const char* ptr = template_str;\n        while (*ptr) {\n            if (*ptr == '%') {\n                res += std::to_string(odd_count);\n            } else {\n                res += *ptr;\n            }\n            ptr++;\n        }\n        \n        result.push_back(res);\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_117_AVX", "completion": "```cpp\nstd::vector<std::string> odd_count_simd(const std::vector<std::string>& lst) {\n    std::vector<std::string> result;\n    result.reserve(lst.size());\n    \n    const char* template_str = \"the number of odd elements %dn the str%dng %d of the %dnput.\";\n    \n    for (const auto& str : lst) {\n        int odd_count = 0;\n        size_t len = str.length();\n        \n        // Process 32 characters at a time using AVX2\n        size_t vec_size = len - (len % 32);\n        const char* ptr = str.c_str();\n        \n        for (size_t i = 0; i < vec_size; i += 32) {\n            __m256i chars = _mm256_loadu_si256((__m256i*)(ptr + i));\n            \n            // Convert ASCII digits to actual numbers by subtracting '0'\n            __m256i nums = _mm256_sub_epi8(chars, _mm256_set1_epi8('0'));\n            \n            // Create mask for odd numbers\n            __m256i odd_mask = _mm256_and_si256(nums, _mm256_set1_epi8(1));\n            \n            // Count odd numbers using popcount\n            uint32_t mask = _mm256_movemask_epi8(_mm256_cmpeq_epi8(odd_mask, _mm256_set1_epi8(1)));\n            odd_count += _mm_popcnt_u32(mask);\n        }\n        \n        // Handle remaining characters\n        for (size_t i = vec_size; i < len; i++) {\n            int digit = str[i] - '0';\n            odd_count += digit & 1;\n        }\n        \n        char buffer[256];\n        snprintf(buffer, sizeof(buffer), template_str, odd_count, odd_count, odd_count, odd_count);\n        result.emplace_back(buffer);\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_117_AVX", "completion": "```cpp\nstd::vector<std::string> odd_count_simd(const std::vector<std::string>& lst) {\n    std::vector<std::string> result;\n    result.reserve(lst.size());\n    \n    const char* template_str = \"the number of odd elements %n the str%ng % of the %nput.\";\n    \n    for (const auto& s : lst) {\n        // Load string into vector registers\n        size_t len = s.length();\n        size_t vec_size = (len + 31) / 32 * 32; // Round up to multiple of 32\n        \n        alignas(32) char padded[32];\n        std::memset(padded, '0', sizeof(padded));\n        std::memcpy(padded, s.data(), std::min(len, size_t(32)));\n        \n        __m256i chars = _mm256_load_si256(reinterpret_cast<const __m256i*>(padded));\n        \n        // Create mask for odd digits\n        __m256i zero = _mm256_set1_epi8('0');\n        __m256i nine = _mm256_set1_epi8('9');\n        __m256i one = _mm256_set1_epi8(0x1);\n        \n        // Check if characters are digits\n        __m256i ge_zero = _mm256_cmpgt_epi8(chars, _mm256_sub_epi8(zero, one));\n        __m256i le_nine = _mm256_cmpgt_epi8(_mm256_add_epi8(nine, one), chars);\n        __m256i is_digit = _mm256_and_si256(ge_zero, le_nine);\n        \n        // Convert to actual numbers\n        __m256i nums = _mm256_sub_epi8(chars, zero);\n        \n        // Check for odd digits\n        __m256i odd_mask = _mm256_and_si256(nums, one);\n        odd_mask = _mm256_and_si256(odd_mask, is_digit);\n        \n        // Count odd digits\n        int mask = _mm256_movemask_epi8(odd_mask);\n        int odd_count = __builtin_popcount(mask);\n        \n        if (len > 32) {\n            size_t remaining = len - 32;\n            std::memset(padded, '0', sizeof(padded));\n            std::memcpy(padded, s.data() + 32, std::min(remaining, size_t(32)));\n            \n            chars = _mm256_load_si256(reinterpret_cast<const __m256i*>(padded));\n            \n            ge_zero = _mm256_cmpgt_epi8(chars, _mm256_sub_epi8(zero, one));\n            le_nine = _mm256_cmpgt_epi8(_mm256_add_epi8(nine, one), chars);\n            is_digit = _mm256_and_si256(ge_zero, le_nine);\n            \n            nums = _mm256_sub_epi8(chars, zero);\n            odd_mask = _mm256_and_si256(nums, one);\n            odd_mask = _mm256_and_si256(odd_mask, is_digit);\n            \n            mask = _mm256_movemask_epi8(odd_mask);\n            odd_count += __builtin_popcount(mask);\n        }\n        \n        std::string output(template_str);\n        std::string count_str = std::to_string(odd_count);\n        \n        size_t pos = 0;\n        while ((pos = output.find('%', pos)) != std::string::npos) {\n            output.replace(pos, 1, count_str);\n            pos += count_str.length();\n        }\n        \n        result.push_back(output);\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_118_AVX", "completion": "```cpp\nint64_t minSubArraySum_simd(const std::vector<int64_t>& nums) {\n    if (nums.empty()) return 0;\n    \n    const size_t n = nums.size();\n    const size_t simd_width = 4;\n    const size_t aligned_size = (n + simd_width - 1) / simd_width * simd_width;\n    \n    std::vector<int64_t> padded_nums(aligned_size, 0);\n    std::copy(nums.begin(), nums.end(), padded_nums.begin());\n    \n    __m256i curr_sum = _mm256_setzero_si256();\n    __m256i min_sum = _mm256_set1_epi64x(INT64_MAX);\n    __m256i zero = _mm256_setzero_si256();\n    \n    for (size_t i = 0; i < aligned_size; i += simd_width) {\n        __m256i nums_vec = _mm256_loadu_si256((__m256i*)&padded_nums[i]);\n        curr_sum = _mm256_add_epi64(curr_sum, nums_vec);\n        min_sum = _mm256_min_epi64(min_sum, curr_sum);\n        \n        __m256i cmp = _mm256_cmpgt_epi64(zero, curr_sum);\n        curr_sum = _mm256_blendv_epi8(curr_sum, zero, cmp);\n    }\n    \n    alignas(32) int64_t min_vals[4];\n    _mm256_store_si256((__m256i*)min_vals, min_sum);\n    \n    int64_t global_min = min_vals[0];\n    for (int i = 1; i < 4; i++) {\n        global_min = std::min(global_min, min_vals[i]);\n    }\n    \n    return global_min;\n}\n```"}
{"task_id": "SimdBench_118_AVX", "completion": "```cpp\nint64_t minSubArraySum_simd(const std::vector<int64_t>& nums) {\n    if (nums.empty()) return 0;\n    \n    const size_t n = nums.size();\n    const size_t simd_width = 4;\n    const size_t aligned_size = (n / simd_width) * simd_width;\n    \n    __m256i curr_sum = _mm256_setzero_si256();\n    __m256i min_sum = _mm256_set1_epi64x(INT64_MAX);\n    \n    int64_t global_min = INT64_MAX;\n    int64_t curr = 0;\n    \n    for (size_t i = 0; i < aligned_size; i += simd_width) {\n        __m256i nums_vec = _mm256_loadu_si256((__m256i*)&nums[i]);\n        curr_sum = _mm256_add_epi64(curr_sum, nums_vec);\n        min_sum = _mm256_min_epi64(min_sum, curr_sum);\n        \n        int64_t sums[4];\n        _mm256_storeu_si256((__m256i*)sums, curr_sum);\n        \n        for (int j = 0; j < 4; j++) {\n            curr = sums[j];\n            global_min = std::min(global_min, curr);\n            if (curr > 0) {\n                curr = 0;\n                curr_sum = _mm256_setzero_si256();\n            }\n        }\n    }\n    \n    for (size_t i = aligned_size; i < n; i++) {\n        curr += nums[i];\n        global_min = std::min(global_min, curr);\n        if (curr > 0) {\n            curr = 0;\n        }\n    }\n    \n    int64_t min_vals[4];\n    _mm256_storeu_si256((__m256i*)min_vals, min_sum);\n    for (int i = 0; i < 4; i++) {\n        global_min = std::min(global_min, min_vals[i]);\n    }\n    \n    return global_min;\n}\n```"}
{"task_id": "SimdBench_118_AVX", "completion": "```cpp\nint64_t minSubArraySum_simd(const std::vector<int64_t>& nums) {\n    if (nums.empty()) return 0;\n    \n    const size_t n = nums.size();\n    const size_t simd_width = 4;\n    const size_t aligned_size = (n + simd_width - 1) / simd_width * simd_width;\n    \n    std::vector<int64_t> padded(aligned_size, 0);\n    std::copy(nums.begin(), nums.end(), padded.begin());\n\n    __m256i curr_sum = _mm256_setzero_si256();\n    __m256i min_sum = _mm256_set1_epi64x(INT64_MAX);\n    __m256i zero = _mm256_setzero_si256();\n\n    for (size_t i = 0; i < aligned_size; i += simd_width) {\n        __m256i nums_vec = _mm256_loadu_si256((__m256i*)&padded[i]);\n        curr_sum = _mm256_add_epi64(curr_sum, nums_vec);\n        min_sum = _mm256_min_epi64(min_sum, curr_sum);\n        \n        __m256i cmp = _mm256_cmpgt_epi64(zero, curr_sum);\n        curr_sum = _mm256_blendv_epi8(curr_sum, zero, cmp);\n    }\n\n    alignas(32) int64_t min_vals[4];\n    _mm256_store_si256((__m256i*)min_vals, min_sum);\n\n    int64_t global_min = INT64_MAX;\n    for (int i = 0; i < 4; i++) {\n        global_min = std::min(global_min, min_vals[i]);\n    }\n\n    int64_t curr = 0;\n    int64_t min_so_far = nums[0];\n    \n    for (size_t i = 0; i < n; i++) {\n        curr += nums[i];\n        min_so_far = std::min(min_so_far, curr);\n        if (curr > 0) {\n            curr = 0;\n        }\n    }\n\n    return min_so_far;\n}\n```"}
{"task_id": "SimdBench_118_AVX", "completion": "```cpp\nint64_t minSubArraySum_simd(const std::vector<int64_t>& nums) {\n    if (nums.empty()) return 0;\n    \n    const size_t n = nums.size();\n    const size_t simd_width = 4;\n    const size_t aligned_size = (n / simd_width) * simd_width;\n    \n    __m256i curr_sum = _mm256_setzero_si256();\n    __m256i min_sum = _mm256_set1_epi64x(INT64_MAX);\n    __m256i zero = _mm256_setzero_si256();\n    \n    int64_t global_min = INT64_MAX;\n    int64_t curr = 0;\n    \n    for (size_t i = 0; i < aligned_size; i += simd_width) {\n        __m256i nums_vec = _mm256_loadu_si256((__m256i*)&nums[i]);\n        curr_sum = _mm256_add_epi64(curr_sum, nums_vec);\n        \n        min_sum = _mm256_min_epi64(min_sum, curr_sum);\n        \n        __m256i mask = _mm256_cmpgt_epi64(zero, curr_sum);\n        curr_sum = _mm256_blendv_epi8(curr_sum, zero, mask);\n    }\n    \n    alignas(32) int64_t min_arr[4];\n    _mm256_store_si256((__m256i*)min_arr, min_sum);\n    \n    for (int i = 0; i < 4; i++) {\n        global_min = std::min(global_min, min_arr[i]);\n    }\n    \n    for (size_t i = aligned_size; i < n; i++) {\n        curr += nums[i];\n        global_min = std::min(global_min, curr);\n        if (curr < 0) curr = 0;\n    }\n    \n    return global_min;\n}\n```"}
{"task_id": "SimdBench_118_AVX", "completion": "```cpp\nint64_t minSubArraySum_simd(const std::vector<int64_t>& nums) {\n    if (nums.empty()) return 0;\n    if (nums.size() == 1) return nums[0];\n\n    const size_t n = nums.size();\n    const size_t simd_width = 4;\n    const size_t aligned_size = (n + simd_width - 1) & ~(simd_width - 1);\n    \n    std::vector<int64_t> curr_sum(aligned_size, 0);\n    std::copy(nums.begin(), nums.end(), curr_sum.begin());\n\n    __m256i min_sum = _mm256_set1_epi64x(INT64_MAX);\n    __m256i curr = _mm256_setzero_si256();\n    \n    for (size_t i = 0; i < aligned_size; i += simd_width) {\n        __m256i nums_vec = _mm256_load_si256((__m256i*)&curr_sum[i]);\n        curr = _mm256_add_epi64(curr, nums_vec);\n        min_sum = _mm256_min_epi64(min_sum, curr);\n        \n        __m256i zero = _mm256_setzero_si256();\n        curr = _mm256_max_epi64(curr, zero);\n    }\n\n    int64_t min_val = INT64_MAX;\n    int64_t results[4];\n    _mm256_store_si256((__m256i*)results, min_sum);\n    \n    for (int i = 0; i < 4; i++) {\n        min_val = std::min(min_val, results[i]);\n    }\n\n    return min_val;\n}\n```"}
{"task_id": "SimdBench_119_AVX", "completion": "```cpp\nint max_fill_simd(const std::vector<std::vector<int>>& grid, int capacity) {\n    if (grid.empty() || grid[0].empty()) return 0;\n    \n    const int rows = grid.size();\n    const int cols = grid[0].size();\n    \n    int result = 0;\n    std::vector<int> row_sums(rows, 0);\n    \n    // Process 8 elements at a time using AVX2\n    const int simd_width = 8;\n    const int simd_iters = cols / simd_width;\n    const int remainder = cols % simd_width;\n    \n    __m256i sum_vec = _mm256_setzero_si256();\n    __m256i ones = _mm256_set1_epi32(1);\n    \n    for (int i = 0; i < rows; i++) {\n        sum_vec = _mm256_setzero_si256();\n        \n        // Process chunks of 8 elements\n        for (int j = 0; j < simd_iters; j++) {\n            __m256i data = _mm256_loadu_si256((__m256i*)&grid[i][j * simd_width]);\n            __m256i mask = _mm256_cmpeq_epi32(data, ones);\n            sum_vec = _mm256_add_epi32(sum_vec, _mm256_and_si256(ones, mask));\n        }\n        \n        // Horizontal sum of vector\n        int sum_arr[8];\n        _mm256_storeu_si256((__m256i*)sum_arr, sum_vec);\n        row_sums[i] = sum_arr[0] + sum_arr[1] + sum_arr[2] + sum_arr[3] + \n                      sum_arr[4] + sum_arr[5] + sum_arr[6] + sum_arr[7];\n        \n        // Handle remaining elements\n        for (int j = simd_iters * simd_width; j < cols; j++) {\n            row_sums[i] += grid[i][j];\n        }\n        \n        result += (row_sums[i] + capacity - 1) / capacity;\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_119_AVX", "completion": "```cpp\nint max_fill_simd(const std::vector<std::vector<int>>& grid, int capacity) {\n    if (grid.empty() || grid[0].empty()) return 0;\n    \n    const int rows = grid.size();\n    const int cols = grid[0].size();\n    \n    // Calculate number of full vector operations\n    const int vec_size = 8; // AVX2 processes 8 integers at a time\n    const int vec_iters = cols / vec_size;\n    const int remainder = cols % vec_size;\n    \n    int total_trips = 0;\n    \n    // Process each row\n    for (int i = 0; i < rows; i++) {\n        int water_units = 0;\n        const int* row = grid[i].data();\n        \n        // Process 8 elements at a time using AVX2\n        for (int j = 0; j < vec_iters; j++) {\n            __m256i vec = _mm256_loadu_si256((__m256i*)(row + j * vec_size));\n            water_units += _mm256_movemask_ps(_mm256_castsi256_ps(vec));\n        }\n        \n        // Handle remaining elements\n        for (int j = vec_iters * vec_size; j < cols; j++) {\n            water_units += row[j];\n        }\n        \n        // Calculate trips needed for this row\n        total_trips += (water_units + capacity - 1) / capacity;\n    }\n    \n    return total_trips;\n}\n```"}
{"task_id": "SimdBench_119_AVX", "completion": "```cpp\nint max_fill_simd(const std::vector<std::vector<int>>& grid, int capacity) {\n    if (grid.empty() || grid[0].empty()) return 0;\n    \n    const int rows = grid.size();\n    const int cols = grid[0].size();\n    \n    // Calculate number of complete AVX2 vectors needed\n    const int vec_size = 8; // 8 integers per 256-bit vector\n    const int vec_count = cols / vec_size;\n    const int remainder = cols % vec_size;\n    \n    int total_trips = 0;\n    \n    // Process each row\n    for (int i = 0; i < rows; i++) {\n        int water_units = 0;\n        \n        // Process complete vectors\n        for (int j = 0; j < vec_count; j++) {\n            __m256i vec = _mm256_loadu_si256((__m256i*)&grid[i][j * vec_size]);\n            __m256i ones = _mm256_set1_epi32(1);\n            __m256i mask = _mm256_cmpeq_epi32(vec, ones);\n            int sum = _mm256_movemask_ps(_mm256_castsi256_ps(mask));\n            water_units += _mm_popcnt_u32(sum);\n        }\n        \n        // Process remaining elements\n        for (int j = vec_count * vec_size; j < cols; j++) {\n            water_units += grid[i][j];\n        }\n        \n        // Calculate trips needed for this row\n        total_trips += (water_units + capacity - 1) / capacity;\n    }\n    \n    return total_trips;\n}\n```"}
{"task_id": "SimdBench_119_AVX", "completion": "```cpp\nint max_fill_simd(const std::vector<std::vector<int>>& grid, int capacity) {\n    if (grid.empty() || grid[0].empty()) return 0;\n    \n    const int rows = grid.size();\n    const int cols = grid[0].size();\n    \n    int total_trips = 0;\n    \n    // Process 8 elements at a time using AVX2\n    const int simd_width = 8;\n    const int simd_iters = cols / simd_width;\n    const int remainder = cols % simd_width;\n    \n    std::vector<int> water_levels(rows, 0);\n    bool has_water = true;\n    \n    while (has_water) {\n        has_water = false;\n        \n        for (int i = 0; i < rows; i++) {\n            int current_capacity = 0;\n            \n            // Process 8 elements at a time\n            for (int j = 0; j < simd_iters; j++) {\n                __m256i water = _mm256_loadu_si256((__m256i*)&grid[i][j * simd_width]);\n                __m256i levels = _mm256_loadu_si256((__m256i*)&water_levels[j * simd_width]);\n                \n                // Compare water levels\n                __m256i mask = _mm256_cmpgt_epi32(water, levels);\n                \n                // If any element needs processing\n                if (_mm256_movemask_ps(_mm256_castsi256_ps(mask))) {\n                    has_water = true;\n                    \n                    // Count remaining capacity\n                    int remaining = capacity - current_capacity;\n                    if (remaining > 0) {\n                        __m256i increment = _mm256_and_si256(mask, _mm256_set1_epi32(1));\n                        levels = _mm256_add_epi32(levels, increment);\n                        \n                        // Update current capacity\n                        int extracted = _mm256_movemask_ps(_mm256_castsi256_ps(increment));\n                        current_capacity += _mm_popcnt_u32(extracted);\n                        \n                        _mm256_storeu_si256((__m256i*)&water_levels[j * simd_width], levels);\n                    }\n                }\n            }\n            \n            // Handle remaining elements\n            for (int j = simd_iters * simd_width; j < cols; j++) {\n                if (grid[i][j] > water_levels[j] && current_capacity < capacity) {\n                    water_levels[j]++;\n                    current_capacity++;\n                    has_water = true;\n                }\n            }\n        }\n        \n        if (has_water) total_trips++;\n    }\n    \n    return total_trips;\n}\n```"}
{"task_id": "SimdBench_119_AVX", "completion": "```cpp\nint max_fill_simd(const std::vector<std::vector<int>>& grid, int capacity) {\n    if (grid.empty() || grid[0].empty()) return 0;\n    \n    const int rows = grid.size();\n    const int cols = grid[0].size();\n    \n    // Calculate number of full vector iterations\n    const int vec_size = 8; // __m256i processes 8 integers at once\n    const int vec_iters = cols / vec_size;\n    const int remainder = cols % vec_size;\n    \n    int total_trips = 0;\n    \n    // Process each row\n    for (int i = 0; i < rows; i++) {\n        int water_units = 0;\n        \n        // Vector processing\n        for (int j = 0; j < vec_iters; j++) {\n            __m256i vec = _mm256_loadu_si256((__m256i*)&grid[i][j * vec_size]);\n            __m256i sum = _mm256_sad_epu8(vec, _mm256_setzero_si256());\n            water_units += _mm256_extract_epi32(sum, 0) + _mm256_extract_epi32(sum, 4);\n        }\n        \n        // Handle remaining elements\n        for (int j = vec_iters * vec_size; j < cols; j++) {\n            water_units += grid[i][j];\n        }\n        \n        // Calculate trips needed for this row\n        total_trips += (water_units + capacity - 1) / capacity;\n    }\n    \n    return total_trips;\n}\n```"}
{"task_id": "SimdBench_120_AVX", "completion": "```cpp\nint64_t solution_simd(const std::vector<int16_t>& lst) {\n    int64_t sum = 0;\n    size_t size = lst.size();\n    size_t vec_size = size - (size % 16);\n    \n    if (size < 2) return 0;\n\n    __m256i ones = _mm256_set1_epi16(1);\n    __m256i zeros = _mm256_setzero_si256();\n    __m256i mask = _mm256_set_epi16(0,-1,0,-1,0,-1,0,-1,0,-1,0,-1,0,-1,0,-1);\n    \n    for (size_t i = 0; i < vec_size; i += 16) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)(lst.data() + i));\n        \n        // Check for odd numbers by AND with 1\n        __m256i odd_check = _mm256_and_si256(vec, ones);\n        __m256i is_odd = _mm256_cmpeq_epi16(odd_check, ones);\n        \n        // Mask even positions\n        __m256i masked = _mm256_and_si256(is_odd, mask);\n        \n        // Multiply original values with mask\n        __m256i result = _mm256_and_si256(vec, masked);\n        \n        // Horizontal sum\n        __m256i sum_vec = _mm256_sad_epu8(result, zeros);\n        sum += _mm256_extract_epi64(sum_vec, 0);\n        sum += _mm256_extract_epi64(sum_vec, 2);\n    }\n    \n    // Handle remaining elements\n    for (size_t i = vec_size; i < size; i += 2) {\n        if (i < size && (lst[i] & 1)) {\n            sum += lst[i];\n        }\n    }\n    \n    return sum;\n}\n```"}
{"task_id": "SimdBench_120_AVX", "completion": "```cpp\nint64_t solution_simd(const std::vector<int16_t>& lst) {\n    int64_t sum = 0;\n    size_t size = lst.size();\n    size_t vec_size = size - (size % 16);\n    \n    if (size < 2) return 0;\n\n    __m256i ones = _mm256_set1_epi16(1);\n    __m256i zeros = _mm256_setzero_si256();\n    __m256i mask = _mm256_set_epi16(0,-1,0,-1,0,-1,0,-1,0,-1,0,-1,0,-1,0,-1);\n    \n    for (size_t i = 0; i < vec_size; i += 16) {\n        __m256i data = _mm256_loadu_si256((__m256i*)(lst.data() + i));\n        \n        // Check for odd numbers (AND with 1)\n        __m256i odd_check = _mm256_and_si256(data, ones);\n        __m256i is_odd = _mm256_cmpeq_epi16(odd_check, ones);\n        \n        // Mask even positions\n        __m256i masked = _mm256_and_si256(is_odd, mask);\n        \n        // Zero out non-odd numbers\n        __m256i values = _mm256_and_si256(data, masked);\n        \n        // Horizontal sum\n        __m256i sum_vec = _mm256_sad_epu8(values, zeros);\n        sum += _mm256_extract_epi64(sum_vec, 0);\n        sum += _mm256_extract_epi64(sum_vec, 2);\n    }\n    \n    // Handle remaining elements\n    for (size_t i = vec_size; i < size; i += 2) {\n        if (i < size && (lst[i] & 1)) {\n            sum += lst[i];\n        }\n    }\n    \n    return sum;\n}\n```"}
{"task_id": "SimdBench_120_AVX", "completion": "```cpp\nint64_t solution_simd(const std::vector<int16_t>& lst) {\n    int64_t sum = 0;\n    size_t size = lst.size();\n    size_t vec_size = size - (size % 16);\n    \n    if (size < 2) return 0;\n\n    __m256i ones = _mm256_set1_epi16(1);\n    __m256i zeros = _mm256_setzero_si256();\n    __m256i mask = _mm256_set_epi16(0,-1,0,-1,0,-1,0,-1,0,-1,0,-1,0,-1,0,-1);\n    \n    for (size_t i = 0; i < vec_size; i += 16) {\n        __m256i data = _mm256_loadu_si256((__m256i*)(lst.data() + i));\n        \n        // Check for odd numbers (AND with 1)\n        __m256i odd_check = _mm256_and_si256(data, ones);\n        __m256i is_odd = _mm256_cmpeq_epi16(odd_check, ones);\n        \n        // Mask even positions\n        __m256i masked = _mm256_and_si256(is_odd, mask);\n        \n        // Keep only odd numbers in even positions\n        __m256i valid_nums = _mm256_and_si256(data, masked);\n        \n        // Horizontal sum\n        __m256i sum_vec = _mm256_sad_epu8(valid_nums, zeros);\n        sum += _mm256_extract_epi64(sum_vec, 0);\n        sum += _mm256_extract_epi64(sum_vec, 2);\n    }\n    \n    // Handle remaining elements\n    for (size_t i = vec_size; i < size; i += 2) {\n        if (i < size && (lst[i] & 1)) {\n            sum += lst[i];\n        }\n    }\n    \n    return sum;\n}\n```"}
{"task_id": "SimdBench_120_AVX", "completion": "```cpp\nint64_t solution_simd(const std::vector<int16_t>& lst) {\n    int64_t sum = 0;\n    size_t size = lst.size();\n    size_t vectorSize = size - (size % 16);\n    \n    if (size < 2) return 0;\n\n    __m256i ones = _mm256_set1_epi16(1);\n    __m256i zeros = _mm256_setzero_si256();\n    __m256i evenMask = _mm256_set_epi16(0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1);\n    __m256i sumVec = _mm256_setzero_si256();\n    \n    for (size_t i = 0; i < vectorSize; i += 16) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)(lst.data() + i));\n        \n        // Check for odd numbers\n        __m256i isOdd = _mm256_and_si256(vec, ones);\n        isOdd = _mm256_cmpeq_epi16(isOdd, ones);\n        \n        // Mask for even positions\n        vec = _mm256_and_si256(vec, evenMask);\n        vec = _mm256_and_si256(vec, isOdd);\n        \n        sumVec = _mm256_add_epi16(sumVec, vec);\n    }\n    \n    // Horizontal sum\n    __m128i sum128 = _mm_add_epi16(_mm256_extracti128_si256(sumVec, 0),\n                                   _mm256_extracti128_si256(sumVec, 1));\n    sum128 = _mm_add_epi16(sum128, _mm_srli_si128(sum128, 8));\n    sum128 = _mm_add_epi16(sum128, _mm_srli_si128(sum128, 4));\n    sum128 = _mm_add_epi16(sum128, _mm_srli_si128(sum128, 2));\n    \n    sum = _mm_extract_epi16(sum128, 0);\n    \n    // Process remaining elements\n    for (size_t i = vectorSize; i < size; i += 2) {\n        if (i < size && (lst[i] & 1)) {\n            sum += lst[i];\n        }\n    }\n    \n    return sum;\n}\n```"}
{"task_id": "SimdBench_120_AVX", "completion": "```cpp\nint64_t solution_simd(const std::vector<int16_t>& lst) {\n    int64_t sum = 0;\n    size_t size = lst.size();\n    size_t vec_size = size - (size % 16);\n    \n    if (size < 2) return 0;\n\n    __m256i ones = _mm256_set1_epi16(1);\n    __m256i zeros = _mm256_setzero_si256();\n    __m256i mask = _mm256_set_epi16(0,-1,0,-1,0,-1,0,-1,0,-1,0,-1,0,-1,0,-1);\n    \n    for (size_t i = 0; i < vec_size; i += 16) {\n        __m256i data = _mm256_loadu_si256((__m256i*)(lst.data() + i));\n        \n        // Check for odd numbers (AND with 1)\n        __m256i odd_check = _mm256_and_si256(data, ones);\n        __m256i is_odd = _mm256_cmpeq_epi16(odd_check, ones);\n        \n        // Mask even positions\n        __m256i masked = _mm256_and_si256(is_odd, mask);\n        \n        // Multiply original numbers with mask\n        __m256i result = _mm256_and_si256(data, masked);\n        \n        // Horizontal sum\n        __m256i sum_vec = _mm256_add_epi16(result, _mm256_srli_si256(_mm256_permute2x128_si256(result, result, 1), 8));\n        sum_vec = _mm256_add_epi16(sum_vec, _mm256_srli_si256(sum_vec, 8));\n        sum_vec = _mm256_add_epi16(sum_vec, _mm256_srli_si256(sum_vec, 4));\n        sum_vec = _mm256_add_epi16(sum_vec, _mm256_srli_si256(sum_vec, 2));\n        \n        sum += _mm256_extract_epi16(sum_vec, 0);\n    }\n\n    // Handle remaining elements\n    for (size_t i = vec_size; i < size; i += 2) {\n        if (lst[i] & 1) {\n            sum += lst[i];\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_121_AVX", "completion": "```cpp\nint add_elements_simd(std::vector<int> arr, int k) {\n    int result = 0;\n    int simd_width = 8; // AVX2 processes 8 integers at a time\n    int i = 0;\n\n    __m256i sum_vec = _mm256_setzero_si256();\n    __m256i hundred = _mm256_set1_epi32(100);\n    __m256i minus_hundred = _mm256_set1_epi32(-100);\n\n    // Process 8 elements at a time\n    for (; i + simd_width <= k; i += simd_width) {\n        __m256i data = _mm256_loadu_si256((__m256i*)&arr[i]);\n        \n        // Check if absolute value is less than 100\n        __m256i gt_hundred = _mm256_cmpgt_epi32(data, hundred);\n        __m256i lt_minus_hundred = _mm256_cmpgt_epi32(minus_hundred, data);\n        __m256i mask = _mm256_or_si256(gt_hundred, lt_minus_hundred);\n        \n        // Zero out elements > 99 or < -99\n        __m256i masked_data = _mm256_andnot_si256(mask, data);\n        \n        // Add to running sum\n        sum_vec = _mm256_add_epi32(sum_vec, masked_data);\n    }\n\n    // Extract sum from vector\n    alignas(32) int temp[8];\n    _mm256_store_si256((__m256i*)temp, sum_vec);\n    for (int j = 0; j < 8; j++) {\n        result += temp[j];\n    }\n\n    // Handle remaining elements\n    for (; i < k; i++) {\n        if (arr[i] > -100 && arr[i] < 100) {\n            result += arr[i];\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_121_AVX", "completion": "```cpp\nint add_elements_simd(std::vector<int> arr, int k) {\n    int result = 0;\n    int processed = 0;\n    \n    // Process 8 elements at a time using AVX2\n    while (processed + 8 <= k) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&arr[processed]);\n        \n        // Create masks for numbers < 100 and numbers < -99\n        __m256i mask1 = _mm256_cmpgt_epi32(_mm256_set1_epi32(100), vec);\n        __m256i mask2 = _mm256_cmpgt_epi32(vec, _mm256_set1_epi32(-100));\n        __m256i mask = _mm256_and_si256(mask1, mask2);\n        \n        // Zero out numbers that don't meet criteria\n        vec = _mm256_and_si256(vec, mask);\n        \n        // Horizontal sum\n        __m128i sum128 = _mm_add_epi32(\n            _mm256_extracti128_si256(vec, 0),\n            _mm256_extracti128_si256(vec, 1)\n        );\n        sum128 = _mm_add_epi32(sum128, _mm_srli_si128(sum128, 8));\n        sum128 = _mm_add_epi32(sum128, _mm_srli_si128(sum128, 4));\n        \n        result += _mm_cvtsi128_si32(sum128);\n        processed += 8;\n    }\n    \n    // Handle remaining elements\n    for (int i = processed; i < k; i++) {\n        if (arr[i] > -100 && arr[i] < 100) {\n            result += arr[i];\n        }\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_121_AVX", "completion": "```cpp\nint add_elements_simd(std::vector<int> arr, int k) {\n    int result = 0;\n    int i = 0;\n    \n    // Process 8 elements at a time using AVX2\n    for (; i + 8 <= k; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&arr[i]);\n        \n        // Create masks for numbers >= 100 and >= 10000\n        __m256i mask_100 = _mm256_set1_epi32(100);\n        __m256i mask_10000 = _mm256_set1_epi32(10000);\n        \n        // Compare numbers with masks\n        __m256i cmp_100 = _mm256_cmpgt_epi32(vec, mask_100);\n        __m256i cmp_10000 = _mm256_cmpgt_epi32(vec, mask_10000);\n        \n        // Combine masks to get numbers with 1 or 2 digits\n        __m256i valid_nums = _mm256_xor_si256(cmp_100, _mm256_and_si256(cmp_100, cmp_10000));\n        \n        // Zero out numbers with more than 2 digits\n        vec = _mm256_andnot_si256(valid_nums, vec);\n        \n        // Horizontal sum of valid numbers\n        int sum_array[8];\n        _mm256_storeu_si256((__m256i*)sum_array, vec);\n        \n        for (int j = 0; j < 8; j++) {\n            result += sum_array[j];\n        }\n    }\n    \n    // Process remaining elements\n    for (; i < k; i++) {\n        if (arr[i] >= 0 && arr[i] < 100) {\n            result += arr[i];\n        }\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_121_AVX", "completion": "```cpp\nint add_elements_simd(std::vector<int> arr, int k) {\n    int result = 0;\n    int elements_to_process = std::min(k, (int)arr.size());\n    int simd_width = 8; // AVX2 processes 8 integers at a time\n    int simd_iters = elements_to_process / simd_width;\n    int remaining = elements_to_process % simd_width;\n\n    __m256i sum_vec = _mm256_setzero_si256();\n    __m256i hundred = _mm256_set1_epi32(100);\n    __m256i neg_hundred = _mm256_set1_epi32(-100);\n\n    for (int i = 0; i < simd_iters; i++) {\n        __m256i data = _mm256_loadu_si256((__m256i*)&arr[i * simd_width]);\n        \n        // Check if numbers are between -99 and 99\n        __m256i gt_neg = _mm256_cmpgt_epi32(data, neg_hundred);\n        __m256i lt_pos = _mm256_cmpgt_epi32(hundred, data);\n        __m256i mask = _mm256_and_si256(gt_neg, lt_pos);\n        \n        // Zero out numbers that don't meet criteria\n        __m256i masked_data = _mm256_and_si256(data, mask);\n        sum_vec = _mm256_add_epi32(sum_vec, masked_data);\n    }\n\n    // Horizontal sum of vector\n    int temp[8];\n    _mm256_storeu_si256((__m256i*)temp, sum_vec);\n    for(int i = 0; i < 8; i++) {\n        result += temp[i];\n    }\n\n    // Process remaining elements\n    for(int i = simd_iters * simd_width; i < elements_to_process; i++) {\n        if(arr[i] > -100 && arr[i] < 100) {\n            result += arr[i];\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_121_AVX", "completion": "```cpp\nint add_elements_simd(std::vector<int> arr, int k) {\n    int result = 0;\n    int elements = std::min(k, (int)arr.size());\n    int simd_size = elements - (elements % 8);\n    \n    __m256i sum = _mm256_setzero_si256();\n    __m256i hundred = _mm256_set1_epi32(100);\n    __m256i neg_hundred = _mm256_set1_epi32(-100);\n    \n    for(int i = 0; i < simd_size; i += 8) {\n        __m256i vals = _mm256_loadu_si256((__m256i*)&arr[i]);\n        \n        // Check if absolute value is less than 100\n        __m256i gt_hundred = _mm256_cmpgt_epi32(vals, hundred);\n        __m256i lt_neg_hundred = _mm256_cmpgt_epi32(neg_hundred, vals);\n        __m256i mask = _mm256_or_si256(gt_hundred, lt_neg_hundred);\n        \n        // Zero out numbers >= 100 or <= -100\n        vals = _mm256_andnot_si256(mask, vals);\n        \n        // Add to running sum\n        sum = _mm256_add_epi32(sum, vals);\n    }\n    \n    // Horizontal sum of vector\n    __m128i sum_hi = _mm256_extracti128_si256(sum, 1);\n    __m128i sum_lo = _mm256_castsi256_si128(sum);\n    __m128i sum_1 = _mm_add_epi32(sum_hi, sum_lo);\n    __m128i sum_2 = _mm_hadd_epi32(sum_1, sum_1);\n    __m128i sum_3 = _mm_hadd_epi32(sum_2, sum_2);\n    result = _mm_cvtsi128_si32(sum_3);\n    \n    // Process remaining elements\n    for(int i = simd_size; i < elements; i++) {\n        if(arr[i] > -100 && arr[i] < 100) {\n            result += arr[i];\n        }\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_122_AVX", "completion": "```cpp\nbool is_sorted_simd(const std::vector<int>& lst) {\n    if (lst.size() <= 1) return true;\n    \n    size_t n = lst.size();\n    size_t simd_size = n - (n % 8);\n    \n    // Check if sorted in ascending order using AVX\n    for (size_t i = 0; i < simd_size; i += 8) {\n        __m256i curr = _mm256_loadu_si256((__m256i*)(lst.data() + i));\n        __m256i next = _mm256_loadu_si256((__m256i*)(lst.data() + i + 1));\n        \n        __m256i cmp = _mm256_cmpgt_epi32(curr, next);\n        int mask = _mm256_movemask_ps(_mm256_castsi256_ps(cmp));\n        \n        if (mask != 0) return false;\n    }\n    \n    // Check remaining elements\n    for (size_t i = simd_size; i < n-1; i++) {\n        if (lst[i] >= lst[i+1]) return false;\n    }\n    \n    // Check for more than 1 duplicate\n    for (size_t i = 0; i < n-2; i++) {\n        __m256i curr = _mm256_set1_epi32(lst[i]);\n        \n        for (size_t j = i+1; j < n; j += 8) {\n            size_t elements = std::min(size_t(8), n-j);\n            __m256i mask = _mm256_setr_epi32(\n                (j+0 < n) ? -1 : 0, (j+1 < n) ? -1 : 0,\n                (j+2 < n) ? -1 : 0, (j+3 < n) ? -1 : 0,\n                (j+4 < n) ? -1 : 0, (j+5 < n) ? -1 : 0,\n                (j+6 < n) ? -1 : 0, (j+7 < n) ? -1 : 0\n            );\n            \n            __m256i next = _mm256_maskload_epi32(lst.data() + j, mask);\n            __m256i eq = _mm256_cmpeq_epi32(curr, next);\n            int eq_mask = _mm256_movemask_ps(_mm256_castsi256_ps(eq));\n            \n            if (_mm_popcnt_u32(eq_mask) > 1) return false;\n        }\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_122_AVX", "completion": "```cpp\nbool is_sorted_simd(const std::vector<int>& lst) {\n    if (lst.size() <= 1) return true;\n    \n    size_t n = lst.size();\n    size_t simd_size = n - (n % 8);\n    \n    // Check if sorted in ascending order using SIMD\n    for (size_t i = 0; i < simd_size; i += 8) {\n        __m256i curr = _mm256_loadu_si256((__m256i*)&lst[i]);\n        __m256i next = _mm256_loadu_si256((__m256i*)&lst[i+1]);\n        \n        __m256i cmp = _mm256_cmpgt_epi32(curr, next);\n        int mask = _mm256_movemask_ps(_mm256_castsi256_ps(cmp));\n        if (mask != 0) return false;\n        \n        // Check for more than 1 duplicate\n        __m256i shifted = _mm256_loadu_si256((__m256i*)&lst[i+2]);\n        __m256i eq1 = _mm256_cmpeq_epi32(curr, next);\n        __m256i eq2 = _mm256_cmpeq_epi32(curr, shifted);\n        mask = _mm256_movemask_ps(_mm256_castsi256_ps(_mm256_and_si256(eq1, eq2)));\n        if (mask != 0) return false;\n    }\n    \n    // Check remaining elements\n    for (size_t i = simd_size; i < n-1; i++) {\n        if (lst[i] >= lst[i+1]) return false;\n        if (i < n-2 && lst[i] == lst[i+1] && lst[i] == lst[i+2]) return false;\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_122_AVX", "completion": "```cpp\nbool is_sorted_simd(const std::vector<int>& lst) {\n    if (lst.size() <= 1) return true;\n    \n    size_t n = lst.size();\n    size_t simd_size = n - (n % 8);\n    \n    // Check if sorted using AVX\n    for (size_t i = 0; i < simd_size; i += 8) {\n        __m256i curr = _mm256_loadu_si256((__m256i*)(lst.data() + i));\n        __m256i next = _mm256_loadu_si256((__m256i*)(lst.data() + i + 1));\n        \n        __m256i cmp = _mm256_cmpgt_epi32(curr, next);\n        int mask = _mm256_movemask_ps(_mm256_castsi256_ps(cmp));\n        \n        if (mask != 0) return false;\n        \n        // Check for more than 1 duplicate\n        __m256i dup = _mm256_cmpeq_epi32(curr, next);\n        int dup_mask = _mm256_movemask_ps(_mm256_castsi256_ps(dup));\n        int dup_count = _mm_popcnt_u32(dup_mask);\n        if (dup_count > 1) return false;\n    }\n    \n    // Check remaining elements\n    for (size_t i = simd_size; i < n - 1; i++) {\n        if (lst[i] >= lst[i + 1]) return false;\n        \n        // Check duplicates in remaining elements\n        if (i < n-2 && lst[i] == lst[i+1] && lst[i+1] == lst[i+2]) {\n            return false;\n        }\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_122_AVX", "completion": "```cpp\nbool is_sorted_simd(const std::vector<int>& lst) {\n    if (lst.size() <= 1) return true;\n    \n    size_t n = lst.size();\n    size_t simd_size = n - (n % 8);\n    \n    // Check if sorted using AVX\n    for (size_t i = 0; i < simd_size; i += 8) {\n        __m256i curr = _mm256_loadu_si256((__m256i*)&lst[i]);\n        __m256i next = _mm256_loadu_si256((__m256i*)&lst[i+1]);\n        \n        __m256i cmp = _mm256_cmpgt_epi32(curr, next);\n        int mask = _mm256_movemask_ps(_mm256_castsi256_ps(cmp));\n        if (mask != 0) return false;\n        \n        // Check for more than 1 duplicate\n        __m256i dup = _mm256_cmpeq_epi32(curr, next);\n        mask = _mm256_movemask_ps(_mm256_castsi256_ps(dup));\n        int count = _mm_popcnt_u32(mask);\n        if (count > 1) return false;\n    }\n    \n    // Check remaining elements\n    for (size_t i = simd_size; i < n-1; i++) {\n        if (lst[i] >= lst[i+1]) return false;\n    }\n    \n    // Final check for duplicates\n    for (size_t i = 0; i < n-2; i++) {\n        int count = 0;\n        for (size_t j = i+1; j < n; j++) {\n            if (lst[i] == lst[j]) count++;\n            if (count > 1) return false;\n        }\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_122_AVX", "completion": "```cpp\nbool is_sorted_simd(const std::vector<int>& lst) {\n    if (lst.size() <= 1) return true;\n    \n    size_t n = lst.size();\n    size_t simd_size = n - (n % 8);\n    \n    // Check if sorted using AVX\n    for (size_t i = 0; i < simd_size; i += 8) {\n        __m256i curr = _mm256_loadu_si256((__m256i*)&lst[i]);\n        __m256i next = _mm256_loadu_si256((__m256i*)&lst[i+1]);\n        \n        // Compare current elements with shifted elements\n        __m256i cmp = _mm256_cmpgt_epi32(curr, next);\n        \n        // If any comparison is true (greater than), array is not sorted\n        if (_mm256_movemask_ps(_mm256_castsi256_ps(cmp)) != 0) {\n            return false;\n        }\n        \n        // Check for more than 1 duplicate\n        for (size_t j = i; j < i + 7; j++) {\n            if (lst[j] == lst[j+1] && lst[j] == lst[j+2]) {\n                return false;\n            }\n        }\n    }\n    \n    // Check remaining elements\n    for (size_t i = simd_size; i < n-1; i++) {\n        if (lst[i] > lst[i+1]) {\n            return false;\n        }\n        if (i < n-2 && lst[i] == lst[i+1] && lst[i] == lst[i+2]) {\n            return false; \n        }\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_123_AVX", "completion": "```cpp\nint prod_signs_simd(const std::vector<int> & arr) {\n    if (arr.empty()) return -32768;\n    \n    const int n = arr.size();\n    const int simd_width = 8;\n    const int num_iters = n / simd_width;\n    const int remainder = n % simd_width;\n    \n    __m256i sum_vec = _mm256_setzero_si256();\n    __m256i sign_prod = _mm256_set1_epi32(1);\n    \n    for (int i = 0; i < num_iters; i++) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&arr[i * simd_width]);\n        \n        // Get absolute values\n        __m256i abs_vec = _mm256_abs_epi32(vec);\n        sum_vec = _mm256_add_epi32(sum_vec, abs_vec);\n        \n        // Get signs\n        __m256i zero = _mm256_setzero_si256();\n        __m256i pos_mask = _mm256_cmpgt_epi32(vec, zero);\n        __m256i neg_mask = _mm256_cmpgt_epi32(zero, vec);\n        \n        __m256i signs = _mm256_or_si256(\n            _mm256_and_si256(pos_mask, _mm256_set1_epi32(1)),\n            _mm256_and_si256(neg_mask, _mm256_set1_epi32(-1))\n        );\n        \n        sign_prod = _mm256_mullo_epi32(sign_prod, signs);\n    }\n    \n    // Horizontal sum\n    int sum = 0;\n    int sign = 1;\n    int* sum_arr = (int*)&sum_vec;\n    int* sign_arr = (int*)&sign_prod;\n    \n    for (int i = 0; i < simd_width; i++) {\n        sum += sum_arr[i];\n        sign *= sign_arr[i];\n    }\n    \n    // Handle remaining elements\n    for (int i = num_iters * simd_width; i < n; i++) {\n        sum += std::abs(arr[i]);\n        sign *= (arr[i] > 0) ? 1 : (arr[i] < 0) ? -1 : 0;\n    }\n    \n    return sum * sign;\n}\n```"}
{"task_id": "SimdBench_123_AVX", "completion": "```cpp\nint prod_signs_simd(const std::vector<int> & arr) {\n    if (arr.empty()) return -32768;\n    \n    const int n = arr.size();\n    const int simd_width = 8;\n    const int num_iters = n / simd_width;\n    const int remainder = n % simd_width;\n    \n    __m256i sum_vec = _mm256_setzero_si256();\n    __m256i sign_prod = _mm256_set1_epi32(1);\n    \n    for (int i = 0; i < num_iters; i++) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&arr[i * simd_width]);\n        \n        // Get absolute values\n        __m256i abs_vec = _mm256_abs_epi32(vec);\n        sum_vec = _mm256_add_epi32(sum_vec, abs_vec);\n        \n        // Get signs\n        __m256i zero = _mm256_setzero_si256();\n        __m256i gt_mask = _mm256_cmpgt_epi32(vec, zero);\n        __m256i lt_mask = _mm256_cmpgt_epi32(zero, vec);\n        \n        __m256i pos_ones = _mm256_and_si256(gt_mask, _mm256_set1_epi32(1));\n        __m256i neg_ones = _mm256_and_si256(lt_mask, _mm256_set1_epi32(-1));\n        __m256i signs = _mm256_or_si256(pos_ones, neg_ones);\n        \n        sign_prod = _mm256_mullo_epi32(sign_prod, signs);\n    }\n    \n    // Horizontal sum of magnitudes\n    int sum_arr[8];\n    _mm256_storeu_si256((__m256i*)sum_arr, sum_vec);\n    int magnitude_sum = 0;\n    for (int i = 0; i < 8; i++) {\n        magnitude_sum += sum_arr[i];\n    }\n    \n    // Process remaining elements\n    for (int i = num_iters * simd_width; i < n; i++) {\n        magnitude_sum += abs(arr[i]);\n    }\n    \n    // Horizontal product of signs\n    int sign_arr[8];\n    _mm256_storeu_si256((__m256i*)sign_arr, sign_prod);\n    int sign_result = 1;\n    for (int i = 0; i < 8; i++) {\n        if (sign_arr[i] == 0) return 0;\n        sign_result *= sign_arr[i];\n    }\n    \n    // Process remaining signs\n    for (int i = num_iters * simd_width; i < n; i++) {\n        if (arr[i] == 0) return 0;\n        sign_result *= (arr[i] > 0) ? 1 : -1;\n    }\n    \n    return magnitude_sum * sign_result;\n}\n```"}
{"task_id": "SimdBench_123_AVX", "completion": "```cpp\nint prod_signs_simd(const std::vector<int> & arr) {\n    if (arr.empty()) return -32768;\n    \n    const int n = arr.size();\n    const int simd_width = 8;\n    const int num_iters = n / simd_width;\n    const int remainder = n % simd_width;\n    \n    __m256i sum_vec = _mm256_setzero_si256();\n    __m256i sign_prod = _mm256_set1_epi32(1);\n    \n    for (int i = 0; i < num_iters; i++) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&arr[i * simd_width]);\n        \n        // Get absolute values\n        __m256i abs_vec = _mm256_abs_epi32(vec);\n        sum_vec = _mm256_add_epi32(sum_vec, abs_vec);\n        \n        // Get signs\n        __m256i zero = _mm256_setzero_si256();\n        __m256i pos_mask = _mm256_cmpgt_epi32(vec, zero);\n        __m256i neg_mask = _mm256_cmpgt_epi32(zero, vec);\n        \n        __m256i signs = _mm256_or_si256(\n            _mm256_and_si256(pos_mask, _mm256_set1_epi32(1)),\n            _mm256_and_si256(neg_mask, _mm256_set1_epi32(-1))\n        );\n        \n        sign_prod = _mm256_mullo_epi32(sign_prod, signs);\n    }\n    \n    // Horizontal sum\n    int sum = 0;\n    int sign = 1;\n    int* sum_arr = (int*)&sum_vec;\n    int* sign_arr = (int*)&sign_prod;\n    \n    for (int i = 0; i < 8; i++) {\n        sum += sum_arr[i];\n        if (sign_arr[i] == 0) sign = 0;\n        else sign *= sign_arr[i];\n    }\n    \n    // Process remaining elements\n    for (int i = num_iters * simd_width; i < n; i++) {\n        sum += std::abs(arr[i]);\n        if (arr[i] == 0) sign = 0;\n        else sign *= (arr[i] > 0) ? 1 : -1;\n    }\n    \n    return sum * sign;\n}\n```"}
{"task_id": "SimdBench_123_AVX", "completion": "```cpp\nint prod_signs_simd(const std::vector<int> & arr) {\n    if (arr.empty()) return -32768;\n    \n    const int n = arr.size();\n    const int simd_width = 8;\n    const int num_iters = n / simd_width;\n    const int remainder = n % simd_width;\n    \n    __m256i sum_vec = _mm256_setzero_si256();\n    __m256i sign_prod = _mm256_set1_epi32(1);\n    \n    for (int i = 0; i < num_iters; i++) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&arr[i * simd_width]);\n        \n        // Get absolute values\n        __m256i abs_vec = _mm256_abs_epi32(vec);\n        sum_vec = _mm256_add_epi32(sum_vec, abs_vec);\n        \n        // Get signs\n        __m256i zero = _mm256_setzero_si256();\n        __m256i pos_mask = _mm256_cmpgt_epi32(vec, zero);\n        __m256i neg_mask = _mm256_cmpgt_epi32(zero, vec);\n        \n        __m256i signs = _mm256_or_si256(\n            _mm256_and_si256(pos_mask, _mm256_set1_epi32(1)),\n            _mm256_and_si256(neg_mask, _mm256_set1_epi32(-1))\n        );\n        \n        sign_prod = _mm256_mullo_epi32(sign_prod, signs);\n    }\n    \n    // Process remaining elements\n    int sum = 0;\n    int sign = 1;\n    for (int i = 0; i < 8; i++) {\n        sum += _mm256_extract_epi32(sum_vec, i);\n        sign *= _mm256_extract_epi32(sign_prod, i);\n    }\n    \n    for (int i = num_iters * simd_width; i < n; i++) {\n        sum += std::abs(arr[i]);\n        sign *= (arr[i] > 0) ? 1 : (arr[i] < 0) ? -1 : 0;\n    }\n    \n    return sum * sign;\n}\n```"}
{"task_id": "SimdBench_123_AVX", "completion": "```cpp\nint prod_signs_simd(const std::vector<int> & arr) {\n    if (arr.empty()) return -32768;\n    \n    const int n = arr.size();\n    const int simd_width = 8;\n    const int num_iters = n / simd_width;\n    const int remainder = n % simd_width;\n    \n    __m256i sum_vec = _mm256_setzero_si256();\n    __m256i sign_prod = _mm256_set1_epi32(1);\n    \n    for (int i = 0; i < num_iters; i++) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&arr[i * simd_width]);\n        \n        // Get absolute values\n        __m256i abs_vec = _mm256_abs_epi32(vec);\n        sum_vec = _mm256_add_epi32(sum_vec, abs_vec);\n        \n        // Get signs\n        __m256i zero = _mm256_setzero_si256();\n        __m256i pos_mask = _mm256_cmpgt_epi32(vec, zero);\n        __m256i neg_mask = _mm256_cmpgt_epi32(zero, vec);\n        \n        __m256i signs = _mm256_or_si256(\n            _mm256_and_si256(pos_mask, _mm256_set1_epi32(1)),\n            _mm256_and_si256(neg_mask, _mm256_set1_epi32(-1))\n        );\n        \n        sign_prod = _mm256_mullo_epi32(sign_prod, signs);\n    }\n    \n    // Horizontal sum\n    int sum = 0;\n    int sign = 1;\n    int* sum_arr = (int*)&sum_vec;\n    int* sign_arr = (int*)&sign_prod;\n    \n    for (int i = 0; i < simd_width; i++) {\n        sum += sum_arr[i];\n        if (sign_arr[i] == 0) {\n            sign = 0;\n        } else {\n            sign *= sign_arr[i];\n        }\n    }\n    \n    // Process remaining elements\n    for (int i = num_iters * simd_width; i < n; i++) {\n        sum += std::abs(arr[i]);\n        if (arr[i] == 0) {\n            sign = 0;\n        } else {\n            sign *= (arr[i] > 0) ? 1 : -1;\n        }\n    }\n    \n    return sum * sign;\n}\n```"}
{"task_id": "SimdBench_124_AVX", "completion": "```cpp\nstd::vector<int> minPath_simd(const std::vector<std::vector<int>>& grid, int k) {\n    const int n = grid.size();\n    std::vector<int> result(k);\n    \n    if (k == 1) {\n        int minVal = INT_MAX;\n        __m256i minVec = _mm256_set1_epi32(INT_MAX);\n        \n        for (int i = 0; i < n; i++) {\n            for (int j = 0; j < n; j += 8) {\n                int remaining = std::min(8, n - j);\n                int temp[8] = {INT_MAX, INT_MAX, INT_MAX, INT_MAX, INT_MAX, INT_MAX, INT_MAX, INT_MAX};\n                for (int k = 0; k < remaining; k++) {\n                    temp[k] = grid[i][j + k];\n                }\n                \n                __m256i currVec = _mm256_loadu_si256((__m256i*)temp);\n                minVec = _mm256_min_epi32(minVec, currVec);\n            }\n        }\n        \n        int minArray[8];\n        _mm256_storeu_si256((__m256i*)minArray, minVec);\n        \n        for (int i = 0; i < 8; i++) {\n            minVal = std::min(minVal, minArray[i]);\n        }\n        \n        result[0] = minVal;\n        return result;\n    }\n    \n    std::vector<std::vector<int>> dp(n, std::vector<int>(n, INT_MAX));\n    std::vector<std::vector<int>> prev_i(n, std::vector<int>(n));\n    std::vector<std::vector<int>> prev_j(n, std::vector<int>(n));\n    \n    int min_i = 0, min_j = 0;\n    int min_val = INT_MAX;\n    \n    for (int len = 1; len <= k; len++) {\n        std::vector<std::vector<int>> new_dp(n, std::vector<int>(n, INT_MAX));\n        \n        for (int i = 0; i < n; i++) {\n            for (int j = 0; j < n; j++) {\n                if (len == 1) {\n                    new_dp[i][j] = grid[i][j];\n                    if (k == 1 && grid[i][j] < min_val) {\n                        min_val = grid[i][j];\n                        min_i = i;\n                        min_j = j;\n                    }\n                    continue;\n                }\n                \n                const int dx[] = {-1, 1, 0, 0};\n                const int dy[] = {0, 0, -1, 1};\n                \n                __m256i currMin = _mm256_set1_epi32(INT_MAX);\n                \n                for (int d = 0; d < 4; d++) {\n                    int ni = i + dx[d];\n                    int nj = j + dy[d];\n                    \n                    if (ni >= 0 && ni < n && nj >= 0 && nj < n) {\n                        if (dp[ni][nj] != INT_MAX) {\n                            int val = grid[i][j];\n                            if (val < new_dp[i][j]) {\n                                new_dp[i][j] = val;\n                                prev_i[i][j] = ni;\n                                prev_j[i][j] = nj;\n                            }\n                        }\n                    }\n                }\n                \n                if (len == k && new_dp[i][j] < min_val) {\n                    min_val = new_dp[i][j];\n                    min_i = i;\n                    min_j = j;\n                }\n            }\n        }\n        \n        dp = new_dp;\n    }\n    \n    int curr_i = min_i;\n    int curr_j = min_j;\n    \n    for (int i = k - 1; i >= 0; i--) {\n        result[i] = grid[curr_i][curr_j];\n        if (i > 0) {\n            int ni = prev_i[curr_i][curr_j];\n            int nj = prev_j[curr_i][curr_j];\n            curr_i = ni;\n            curr_j = nj;\n        }\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_124_AVX", "completion": "```cpp\nstd::vector<int> minPath_simd(const std::vector<std::vector<int>>& grid, int k) {\n    const int n = grid.size();\n    std::vector<int> result(k);\n    \n    if (k == 1) {\n        int minVal = INT_MAX;\n        __m256i minVec = _mm256_set1_epi32(INT_MAX);\n        \n        for (int i = 0; i < n; i++) {\n            for (int j = 0; j < n; j += 8) {\n                int remaining = std::min(8, n - j);\n                if (remaining < 8) {\n                    for (int x = 0; x < remaining; x++) {\n                        minVal = std::min(minVal, grid[i][j + x]);\n                    }\n                    continue;\n                }\n                \n                __m256i row = _mm256_setr_epi32(\n                    grid[i][j], grid[i][j+1], grid[i][j+2], grid[i][j+3],\n                    grid[i][j+4], grid[i][j+5], grid[i][j+6], grid[i][j+7]\n                );\n                minVec = _mm256_min_epi32(minVec, row);\n            }\n        }\n        \n        int minArray[8];\n        _mm256_storeu_si256((__m256i*)minArray, minVec);\n        for (int i = 0; i < 8; i++) {\n            minVal = std::min(minVal, minArray[i]);\n        }\n        result[0] = minVal;\n        return result;\n    }\n    \n    std::vector<std::vector<int>> dp(n, std::vector<int>(n, INT_MAX));\n    std::vector<int> dx = {-1, 1, 0, 0};\n    std::vector<int> dy = {0, 0, -1, 1};\n    \n    int minFirst = INT_MAX;\n    int startX = 0, startY = 0;\n    \n    for (int i = 0; i < n; i++) {\n        for (int j = 0; j < n; j++) {\n            if (grid[i][j] < minFirst) {\n                minFirst = grid[i][j];\n                startX = i;\n                startY = j;\n            }\n        }\n    }\n    \n    result[0] = minFirst;\n    int curX = startX;\n    int curY = startY;\n    \n    for (int step = 1; step < k; step++) {\n        int nextVal = INT_MAX;\n        int nextX = -1, nextY = -1;\n        \n        __m256i minVec = _mm256_set1_epi32(INT_MAX);\n        \n        for (int d = 0; d < 4; d++) {\n            int newX = curX + dx[d];\n            int newY = curY + dy[d];\n            \n            if (newX >= 0 && newX < n && newY >= 0 && newY < n) {\n                if (grid[newX][newY] < nextVal) {\n                    nextVal = grid[newX][newY];\n                    nextX = newX;\n                    nextY = newY;\n                }\n            }\n        }\n        \n        result[step] = nextVal;\n        curX = nextX;\n        curY = nextY;\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_124_AVX", "completion": "```cpp\nstd::vector<int> minPath_simd(const std::vector<std::vector<int>>& grid, int k) {\n    int n = grid.size();\n    std::vector<int> result(k);\n    \n    if (k == 1) {\n        int minVal = INT_MAX;\n        __m256i minVec = _mm256_set1_epi32(INT_MAX);\n        \n        for (int i = 0; i < n; i++) {\n            for (int j = 0; j < n; j += 8) {\n                int remaining = std::min(8, n - j);\n                __m256i mask = _mm256_setr_epi32(\n                    j < n ? -1 : 0, j+1 < n ? -1 : 0,\n                    j+2 < n ? -1 : 0, j+3 < n ? -1 : 0,\n                    j+4 < n ? -1 : 0, j+5 < n ? -1 : 0,\n                    j+6 < n ? -1 : 0, j+7 < n ? -1 : 0\n                );\n                \n                __m256i row = _mm256_maskload_epi32(&grid[i][j], mask);\n                minVec = _mm256_min_epi32(minVec, row);\n            }\n        }\n        \n        int minArray[8];\n        _mm256_storeu_si256((__m256i*)minArray, minVec);\n        \n        for(int i = 0; i < 8; i++) {\n            minVal = std::min(minVal, minArray[i]);\n        }\n        \n        result[0] = minVal;\n        return result;\n    }\n    \n    std::vector<std::vector<int>> dirs = {{-1,0}, {1,0}, {0,-1}, {0,1}};\n    std::vector<int> bestPath(k, INT_MAX);\n    \n    auto isValid = [&](int x, int y) {\n        return x >= 0 && x < n && y >= 0 && y < n;\n    };\n    \n    std::function<void(int,int,int,std::vector<int>&)> dfs = \n    [&](int x, int y, int len, std::vector<int>& path) {\n        path[len] = grid[x][y];\n        \n        if (len == k-1) {\n            if (path < bestPath) {\n                bestPath = path;\n            }\n            return;\n        }\n        \n        for (const auto& dir : dirs) {\n            int nx = x + dir[0];\n            int ny = y + dir[1];\n            if (isValid(nx, ny)) {\n                dfs(nx, ny, len+1, path);\n            }\n        }\n    };\n    \n    std::vector<int> path(k);\n    for (int i = 0; i < n; i++) {\n        for (int j = 0; j < n; j++) {\n            dfs(i, j, 0, path);\n        }\n    }\n    \n    return bestPath;\n}\n```"}
{"task_id": "SimdBench_124_AVX", "completion": "```cpp\nstd::vector<int> minPath_simd(const std::vector<std::vector<int>>& grid, int k) {\n    const int n = grid.size();\n    std::vector<int> result(k);\n    \n    if (k == 1) {\n        int minVal = INT_MAX;\n        __m256i minVec = _mm256_set1_epi32(INT_MAX);\n        \n        for (int i = 0; i < n; i++) {\n            for (int j = 0; j < n; j += 8) {\n                int remaining = std::min(8, n - j);\n                __m256i row;\n                if (remaining == 8) {\n                    row = _mm256_set_epi32(grid[i][j+7], grid[i][j+6], grid[i][j+5], grid[i][j+4],\n                                         grid[i][j+3], grid[i][j+2], grid[i][j+1], grid[i][j]);\n                } else {\n                    int temp[8] = {INT_MAX, INT_MAX, INT_MAX, INT_MAX, INT_MAX, INT_MAX, INT_MAX, INT_MAX};\n                    for(int r = 0; r < remaining; r++) {\n                        temp[r] = grid[i][j+r];\n                    }\n                    row = _mm256_loadu_si256((__m256i*)temp);\n                }\n                minVec = _mm256_min_epi32(minVec, row);\n            }\n        }\n        \n        int minArray[8];\n        _mm256_storeu_si256((__m256i*)minArray, minVec);\n        \n        for(int i = 0; i < 8; i++) {\n            minVal = std::min(minVal, minArray[i]);\n        }\n        \n        result[0] = minVal;\n        return result;\n    }\n    \n    const int dx[] = {-1, 0, 1, 0};\n    const int dy[] = {0, 1, 0, -1};\n    \n    std::vector<int> bestPath(k, INT_MAX);\n    std::function<void(int,int,int,std::vector<int>&)> dfs;\n    \n    dfs = [&](int x, int y, int len, std::vector<int>& path) {\n        path[len] = grid[x][y];\n        \n        if (len + 1 == k) {\n            if (path < bestPath) {\n                bestPath = path;\n            }\n            return;\n        }\n        \n        for (int d = 0; d < 4; d++) {\n            int nx = x + dx[d];\n            int ny = y + dy[d];\n            \n            if (nx >= 0 && nx < n && ny >= 0 && ny < n) {\n                dfs(nx, ny, len + 1, path);\n            }\n        }\n    };\n    \n    std::vector<int> path(k);\n    for (int i = 0; i < n; i++) {\n        for (int j = 0; j < n; j++) {\n            dfs(i, j, 0, path);\n        }\n    }\n    \n    return bestPath;\n}\n```"}
{"task_id": "SimdBench_124_AVX", "completion": "```cpp\nstd::vector<int> minPath_simd(const std::vector<std::vector<int>>& grid, int k) {\n    const int n = grid.size();\n    std::vector<int> result(k);\n    \n    if (k == 1) {\n        int minVal = INT_MAX;\n        __m256i vmin = _mm256_set1_epi32(INT_MAX);\n        \n        for (int i = 0; i < n; i++) {\n            for (int j = 0; j < n; j += 8) {\n                int remaining = std::min(8, n - j);\n                __m256i row;\n                if (remaining == 8) {\n                    row = _mm256_loadu_si256((__m256i*)&grid[i][j]);\n                } else {\n                    int temp[8] = {INT_MAX, INT_MAX, INT_MAX, INT_MAX, INT_MAX, INT_MAX, INT_MAX, INT_MAX};\n                    for(int t = 0; t < remaining; t++) {\n                        temp[t] = grid[i][j + t];\n                    }\n                    row = _mm256_loadu_si256((__m256i*)temp);\n                }\n                vmin = _mm256_min_epi32(vmin, row);\n            }\n        }\n        \n        int temp[8];\n        _mm256_storeu_si256((__m256i*)temp, vmin);\n        for(int i = 0; i < 8; i++) {\n            minVal = std::min(minVal, temp[i]);\n        }\n        result[0] = minVal;\n        return result;\n    }\n    \n    const int dx[4] = {-1, 0, 1, 0};\n    const int dy[4] = {0, 1, 0, -1};\n    \n    std::vector<int> bestPath(k, INT_MAX);\n    \n    std::function<void(int,int,int,std::vector<int>&)> dfs = \n    [&](int x, int y, int len, std::vector<int>& path) {\n        path[len-1] = grid[x][y];\n        \n        if (len == k) {\n            if (path < bestPath) {\n                bestPath = path;\n            }\n            return;\n        }\n        \n        for (int d = 0; d < 4; d++) {\n            int nx = x + dx[d];\n            int ny = y + dy[d];\n            if (nx >= 0 && nx < n && ny >= 0 && ny < n) {\n                dfs(nx, ny, len + 1, path);\n            }\n        }\n    };\n    \n    std::vector<int> path(k);\n    for (int i = 0; i < n; i++) {\n        for (int j = 0; j < n; j++) {\n            dfs(i, j, 1, path);\n        }\n    }\n    \n    return bestPath;\n}\n```"}
{"task_id": "SimdBench_125_AVX", "completion": "```cpp\nuint64_t digits_simd(uint64_t n) {\n    if (n == 0) return 0;\n    \n    // Convert number to string of digits\n    char digits[20];\n    int len = snprintf(digits, sizeof(digits), \"%lu\", n);\n    \n    // Pad with zeros to multiple of 8\n    int padded_len = ((len + 7) / 8) * 8;\n    for(int i = len; i < padded_len; i++) {\n        digits[i] = '0';\n    }\n\n    __m256i vec_digits = _mm256_loadu_si256((__m256i*)digits);\n    __m256i ascii_zero = _mm256_set1_epi8('0');\n    \n    // Convert ASCII to actual digits\n    vec_digits = _mm256_sub_epi8(vec_digits, ascii_zero);\n    \n    // Create mask for odd digits\n    __m256i one = _mm256_set1_epi8(1);\n    __m256i mask = _mm256_and_si256(vec_digits, one);\n    \n    // Zero out even digits\n    vec_digits = _mm256_and_si256(vec_digits, \n                _mm256_cmpeq_epi8(mask, one));\n    \n    // Initialize product as 1\n    uint64_t product = 1;\n    uint8_t* vals = (uint8_t*)&vec_digits;\n    \n    // Multiply non-zero digits\n    bool has_odd = false;\n    for(int i = 0; i < len; i++) {\n        if(vals[i] > 0) {\n            product *= vals[i];\n            has_odd = true;\n        }\n    }\n    \n    return has_odd ? product : 0;\n}\n```"}
{"task_id": "SimdBench_125_AVX", "completion": "```cpp\nuint64_t digits_simd(uint64_t n) {\n    if (n == 0) return 0;\n    \n    // Convert number to string of digits\n    char digits[20];\n    int len = snprintf(digits, sizeof(digits), \"%lu\", n);\n    \n    // Pad with zeros to multiple of 8\n    int padded_len = (len + 7) & ~7;\n    char padded[32] = {0};\n    memcpy(padded + padded_len - len, digits, len);\n    \n    // Load digits into vector\n    __m256i vec = _mm256_loadu_si256((__m256i*)padded);\n    \n    // Convert ascii to actual digits\n    vec = _mm256_sub_epi8(vec, _mm256_set1_epi8('0'));\n    \n    // Create mask for odd digits\n    __m256i odd_mask = _mm256_and_si256(vec, _mm256_set1_epi8(1));\n    odd_mask = _mm256_cmpeq_epi8(odd_mask, _mm256_set1_epi8(1));\n    \n    // Zero out even digits\n    vec = _mm256_and_si256(vec, odd_mask);\n    \n    // Initialize product as 1\n    uint64_t product = 1;\n    uint8_t* v = (uint8_t*)&vec;\n    \n    // Multiply odd digits\n    bool has_odd = false;\n    for(int i = padded_len-len; i < padded_len; i++) {\n        if(v[i] > 0) {\n            product *= v[i];\n            has_odd = true;\n        }\n    }\n    \n    return has_odd ? product : 0;\n}\n```"}
{"task_id": "SimdBench_125_AVX", "completion": "```cpp\nuint64_t digits_simd(uint64_t n) {\n    if (n == 0) return 0;\n    \n    // Convert number to string of digits\n    char digits[20];\n    int len = snprintf(digits, sizeof(digits), \"%lu\", n);\n    \n    // Pad with zeros to multiple of 8\n    int padded_len = ((len + 7) / 8) * 8;\n    for(int i = len; i < padded_len; i++) {\n        digits[i] = '0';\n    }\n\n    __m256i vec_digits = _mm256_loadu_si256((__m256i*)digits);\n    __m256i ascii_zero = _mm256_set1_epi8('0');\n    \n    // Convert ASCII to actual digits\n    vec_digits = _mm256_sub_epi8(vec_digits, ascii_zero);\n    \n    // Create mask for odd digits\n    __m256i one = _mm256_set1_epi8(1);\n    __m256i mask = _mm256_and_si256(vec_digits, one);\n    \n    // Zero out even digits\n    vec_digits = _mm256_and_si256(vec_digits, \n                 _mm256_cmpeq_epi8(mask, one));\n    \n    uint64_t product = 1;\n    uint8_t* vals = (uint8_t*)&vec_digits;\n    \n    bool has_odd = false;\n    for(int i = 0; i < len; i++) {\n        if(vals[i] > 0) {\n            product *= vals[i];\n            has_odd = true;\n        }\n    }\n    \n    return has_odd ? product : 0;\n}\n```"}
{"task_id": "SimdBench_125_AVX", "completion": "```cpp\nuint64_t digits_simd(uint64_t n) {\n    if (n == 0) return 0;\n    \n    // Convert number to string of digits\n    char digits[20];\n    int len = snprintf(digits, sizeof(digits), \"%lu\", n);\n    \n    // Pad with zeros to multiple of 8\n    int padded_len = ((len + 7) / 8) * 8;\n    for (int i = len; i < padded_len; i++) {\n        digits[i] = '0';\n    }\n\n    __m256i vec_digits = _mm256_loadu_si256((__m256i*)digits);\n    __m256i ascii_zero = _mm256_set1_epi8('0');\n    \n    // Convert ASCII to actual digits\n    vec_digits = _mm256_sub_epi8(vec_digits, ascii_zero);\n    \n    // Create mask for odd digits\n    __m256i one = _mm256_set1_epi8(1);\n    __m256i mask = _mm256_and_si256(vec_digits, one);\n    \n    // Zero out even digits\n    vec_digits = _mm256_and_si256(vec_digits, \n                 _mm256_cmpeq_epi8(mask, one));\n    \n    // Initialize product as 1\n    uint64_t product = 1;\n    uint8_t* vals = (uint8_t*)&vec_digits;\n    \n    // Multiply non-zero digits\n    bool has_odd = false;\n    for (int i = 0; i < len; i++) {\n        if (vals[i] > 0) {\n            product *= vals[i];\n            has_odd = true;\n        }\n    }\n    \n    return has_odd ? product : 0;\n}\n```"}
{"task_id": "SimdBench_125_AVX", "completion": "```cpp\nuint64_t digits_simd(uint64_t n) {\n    if (n == 0) return 0;\n    \n    // Convert number to string of digits\n    char digits[20];\n    int len = snprintf(digits, sizeof(digits), \"%lu\", n);\n    \n    // Pad with zeros to multiple of 8\n    int padded_len = ((len + 7) / 8) * 8;\n    for (int i = len; i < padded_len; i++) {\n        digits[i] = '0';\n    }\n\n    __m256i vec_digits = _mm256_loadu_si256((__m256i*)digits);\n    __m256i ascii_zero = _mm256_set1_epi8('0');\n    \n    // Convert ASCII to actual digits\n    vec_digits = _mm256_sub_epi8(vec_digits, ascii_zero);\n    \n    // Create mask for odd digits\n    __m256i one = _mm256_set1_epi8(1);\n    __m256i mask = _mm256_and_si256(vec_digits, one);\n    \n    // Zero out even digits\n    vec_digits = _mm256_and_si256(vec_digits, \n                 _mm256_cmpeq_epi8(mask, one));\n    \n    // Initialize product\n    uint64_t product = 1;\n    uint8_t* vals = (uint8_t*)&vec_digits;\n    \n    bool has_odd = false;\n    // Multiply non-zero values\n    for (int i = 0; i < len; i++) {\n        if (vals[i] != 0) {\n            product *= vals[i];\n            has_odd = true;\n        }\n    }\n    \n    return has_odd ? product : 0;\n}\n```"}
{"task_id": "SimdBench_126_AVX", "completion": "```cpp\nuint64_t sum_squares_simd(const std::vector<float> & lst) {\n    size_t size = lst.size();\n    size_t aligned_size = size - (size % 8);\n    \n    __m256 sum = _mm256_setzero_ps();\n    \n    for (size_t i = 0; i < aligned_size; i += 8) {\n        __m256 vec = _mm256_loadu_ps(&lst[i]);\n        __m256 ceil_vec = _mm256_ceil_ps(vec);\n        __m256 square = _mm256_mul_ps(ceil_vec, ceil_vec);\n        sum = _mm256_add_ps(sum, square);\n    }\n    \n    float temp[8];\n    _mm256_storeu_ps(temp, sum);\n    uint64_t result = 0;\n    \n    for (int i = 0; i < 8; i++) {\n        result += (uint64_t)temp[i];\n    }\n    \n    for (size_t i = aligned_size; i < size; i++) {\n        float ceil_val = ceil(lst[i]);\n        result += (uint64_t)(ceil_val * ceil_val);\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_126_AVX", "completion": "```cpp\nuint64_t sum_squares_simd(const std::vector<float> & lst) {\n    size_t size = lst.size();\n    size_t aligned_size = size - (size % 8);\n    \n    __m256 sum = _mm256_setzero_ps();\n    \n    for (size_t i = 0; i < aligned_size; i += 8) {\n        __m256 vec = _mm256_loadu_ps(&lst[i]);\n        __m256 ceil_vec = _mm256_ceil_ps(vec);\n        __m256 square = _mm256_mul_ps(ceil_vec, ceil_vec);\n        sum = _mm256_add_ps(sum, square);\n    }\n    \n    float temp[8];\n    _mm256_storeu_ps(temp, sum);\n    uint64_t result = 0;\n    \n    for (int i = 0; i < 8; i++) {\n        result += (uint64_t)temp[i];\n    }\n    \n    for (size_t i = aligned_size; i < size; i++) {\n        float ceil_val = ceilf(lst[i]);\n        result += (uint64_t)(ceil_val * ceil_val);\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_126_AVX", "completion": "```cpp\nuint64_t sum_squares_simd(const std::vector<float> & lst) {\n    size_t size = lst.size();\n    size_t aligned_size = size - (size % 8);\n    uint64_t sum = 0;\n\n    __m256 sum_vec = _mm256_setzero_ps();\n    \n    for (size_t i = 0; i < aligned_size; i += 8) {\n        __m256 vec = _mm256_loadu_ps(&lst[i]);\n        __m256 ceil_vec = _mm256_ceil_ps(vec);\n        __m256 square = _mm256_mul_ps(ceil_vec, ceil_vec);\n        sum_vec = _mm256_add_ps(sum_vec, square);\n    }\n\n    float temp[8];\n    _mm256_storeu_ps(temp, sum_vec);\n    \n    for (int i = 0; i < 8; i++) {\n        sum += (uint64_t)temp[i];\n    }\n\n    for (size_t i = aligned_size; i < size; i++) {\n        float ceil_val = ceil(lst[i]);\n        sum += (uint64_t)(ceil_val * ceil_val);\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_126_AVX", "completion": "```cpp\nuint64_t sum_squares_simd(const std::vector<float> & lst) {\n    size_t size = lst.size();\n    size_t simd_size = size - (size % 8);\n    \n    __m256 sum = _mm256_setzero_ps();\n    \n    for(size_t i = 0; i < simd_size; i += 8) {\n        __m256 vec = _mm256_loadu_ps(&lst[i]);\n        __m256 ceil = _mm256_ceil_ps(vec);\n        __m256 square = _mm256_mul_ps(ceil, ceil);\n        sum = _mm256_add_ps(sum, square);\n    }\n    \n    float temp[8];\n    _mm256_storeu_ps(temp, sum);\n    uint64_t result = 0;\n    \n    for(int i = 0; i < 8; i++) {\n        result += (uint64_t)temp[i];\n    }\n    \n    for(size_t i = simd_size; i < size; i++) {\n        float ceil_val = std::ceil(lst[i]);\n        result += (uint64_t)(ceil_val * ceil_val);\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_126_AVX", "completion": "```cpp\nuint64_t sum_squares_simd(const std::vector<float> & lst) {\n    size_t size = lst.size();\n    size_t aligned_size = size - (size % 8);\n    \n    __m256 sum = _mm256_setzero_ps();\n    \n    for (size_t i = 0; i < aligned_size; i += 8) {\n        __m256 vec = _mm256_loadu_ps(&lst[i]);\n        __m256 ceil_vec = _mm256_ceil_ps(vec);\n        __m256 square = _mm256_mul_ps(ceil_vec, ceil_vec);\n        sum = _mm256_add_ps(sum, square);\n    }\n    \n    float temp[8];\n    _mm256_storeu_ps(temp, sum);\n    uint64_t result = 0;\n    \n    for (int i = 0; i < 8; i++) {\n        result += (uint64_t)temp[i];\n    }\n    \n    for (size_t i = aligned_size; i < size; i++) {\n        float ceil_val = ceilf(lst[i]);\n        result += (uint64_t)(ceil_val * ceil_val);\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_127_AVX", "completion": "```cpp\nint can_arrange_simd(const std::vector<int>& arr) {\n    if (arr.size() < 2) return -1;\n    \n    int n = arr.size();\n    int i = 0;\n    \n    for (; i + 8 <= n - 1; i += 8) {\n        __m256i curr = _mm256_loadu_si256((__m256i*)(arr.data() + i));\n        __m256i next = _mm256_loadu_si256((__m256i*)(arr.data() + i + 1));\n        \n        __m256i cmp = _mm256_cmpgt_epi32(curr, next);\n        int mask = _mm256_movemask_ps(_mm256_castsi256_ps(cmp));\n        \n        if (mask) {\n            return i + _tzcnt_u32(mask);\n        }\n    }\n    \n    for (; i < n - 1; i++) {\n        if (arr[i] > arr[i + 1]) {\n            return i + 1;\n        }\n    }\n    \n    return -1;\n}\n```"}
{"task_id": "SimdBench_127_AVX", "completion": "```cpp\nint can_arrange_simd(const std::vector<int>& arr) {\n    if (arr.size() < 2) return -1;\n    \n    int n = arr.size();\n    int result = -1;\n    \n    // Process 8 elements at a time using AVX2\n    const int simd_width = 8;\n    int aligned_size = n - (n % simd_width);\n    \n    for (int i = 0; i < aligned_size; i += simd_width) {\n        __m256i curr = _mm256_loadu_si256((__m256i*)(arr.data() + i));\n        __m256i next = _mm256_loadu_si256((__m256i*)(arr.data() + i + 1));\n        \n        __m256i cmp = _mm256_cmpgt_epi32(curr, next);\n        int mask = _mm256_movemask_ps(_mm256_castsi256_ps(cmp));\n        \n        if (mask) {\n            result = i + _tzcnt_u32(mask);\n            break;\n        }\n    }\n    \n    // Handle remaining elements\n    if (result == -1) {\n        for (int i = aligned_size; i < n - 1; i++) {\n            if (arr[i] > arr[i + 1]) {\n                result = i + 1;\n                break;\n            }\n        }\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_127_AVX", "completion": "```cpp\nint can_arrange_simd(const std::vector<int>& arr) {\n    if (arr.size() < 2) return -1;\n\n    int n = arr.size();\n    int aligned_size = (n / 8) * 8;\n    \n    __m256i result = _mm256_set1_epi32(-1);\n    \n    for (int i = 0; i < aligned_size; i += 8) {\n        __m256i curr = _mm256_loadu_si256((__m256i*)(arr.data() + i));\n        __m256i shifted = _mm256_loadu_si256((__m256i*)(arr.data() + i - 1));\n        \n        if (i == 0) {\n            shifted = _mm256_set1_epi32(INT_MIN);\n            shifted = _mm256_insert_epi32(shifted, arr[0], 1);\n            shifted = _mm256_insert_epi32(shifted, arr[1], 2);\n            shifted = _mm256_insert_epi32(shifted, arr[2], 3);\n            shifted = _mm256_insert_epi32(shifted, arr[3], 4);\n            shifted = _mm256_insert_epi32(shifted, arr[4], 5);\n            shifted = _mm256_insert_epi32(shifted, arr[5], 6);\n            shifted = _mm256_insert_epi32(shifted, arr[6], 7);\n        }\n        \n        __m256i cmp = _mm256_cmpgt_epi32(curr, shifted);\n        int mask = _mm256_movemask_ps(_mm256_castsi256_ps(cmp));\n        \n        if (mask != 255) {\n            for (int j = 0; j < 8; j++) {\n                if (!(mask & (1 << j)) && i + j > 0) {\n                    return i + j;\n                }\n            }\n        }\n    }\n    \n    for (int i = aligned_size + 1; i < n; i++) {\n        if (arr[i] <= arr[i-1]) {\n            return i;\n        }\n    }\n    \n    return -1;\n}\n```"}
{"task_id": "SimdBench_127_AVX", "completion": "```cpp\nint can_arrange_simd(const std::vector<int>& arr) {\n    if (arr.size() < 2) return -1;\n    \n    int n = arr.size();\n    int result = -1;\n    \n    // Process 8 elements at a time using AVX2\n    for (int i = 0; i <= n-8; i += 8) {\n        __m256i curr = _mm256_loadu_si256((__m256i*)(arr.data() + i));\n        __m256i next = _mm256_loadu_si256((__m256i*)(arr.data() + i + 1));\n        \n        // Compare if next < curr\n        __m256i mask = _mm256_cmpgt_epi32(curr, next);\n        \n        // Get mask bits\n        int bits = _mm256_movemask_ps(_mm256_castsi256_ps(mask));\n        \n        if (bits) {\n            // Find first set bit\n            result = i + _tzcnt_u32(bits);\n        }\n    }\n    \n    // Handle remaining elements\n    for (int i = (n/8)*8; i < n-1; i++) {\n        if (arr[i+1] < arr[i]) {\n            result = i+1;\n        }\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_127_AVX", "completion": "```cpp\nint can_arrange_simd(const std::vector<int>& arr) {\n    if (arr.size() < 2) return -1;\n    \n    int n = arr.size();\n    int result = -1;\n    \n    // Process 8 elements at a time using AVX2\n    for (int i = 0; i <= n-8; i += 8) {\n        __m256i curr = _mm256_loadu_si256((__m256i*)(arr.data() + i));\n        __m256i next = _mm256_loadu_si256((__m256i*)(arr.data() + i + 1));\n        \n        __m256i cmp = _mm256_cmpgt_epi32(curr, next);\n        int mask = _mm256_movemask_ps(_mm256_castsi256_ps(cmp));\n        \n        if (mask) {\n            result = i + _tzcnt_u32(mask);\n            return result + 1;\n        }\n    }\n    \n    // Handle remaining elements\n    for (int i = n-8; i < n-1; i++) {\n        if (arr[i] > arr[i+1]) {\n            return i+1;\n        }\n    }\n    \n    return -1;\n}\n```"}
{"task_id": "SimdBench_128_AVX", "completion": "```cpp\nstd::vector<int> largest_smallest_integers_simd(const std::vector<int>& lst) {\n    if (lst.empty()) {\n        return {0, 0};\n    }\n\n    __m256i max_neg = _mm256_set1_epi32(0);\n    __m256i min_pos = _mm256_set1_epi32(INT_MAX);\n    \n    for (size_t i = 0; i < lst.size(); i += 8) {\n        __m256i curr;\n        if (i + 8 <= lst.size()) {\n            curr = _mm256_loadu_si256((__m256i*)(lst.data() + i));\n        } else {\n            alignas(32) int temp[8] = {0};\n            for (size_t j = i; j < lst.size(); j++) {\n                temp[j-i] = lst[j];\n            }\n            curr = _mm256_load_si256((__m256i*)temp);\n        }\n\n        __m256i is_neg = _mm256_cmpgt_epi32(_mm256_setzero_si256(), curr);\n        __m256i is_pos = _mm256_cmpgt_epi32(curr, _mm256_setzero_si256());\n        \n        __m256i neg_vals = _mm256_and_si256(curr, is_neg);\n        __m256i pos_vals = _mm256_and_si256(curr, is_pos);\n        \n        max_neg = _mm256_max_epi32(max_neg, neg_vals);\n        min_pos = _mm256_min_epi32(min_pos, \n                    _mm256_or_si256(pos_vals, \n                        _mm256_andnot_si256(is_pos, _mm256_set1_epi32(INT_MAX))));\n    }\n\n    alignas(32) int neg_arr[8];\n    alignas(32) int pos_arr[8];\n    _mm256_store_si256((__m256i*)neg_arr, max_neg);\n    _mm256_store_si256((__m256i*)pos_arr, min_pos);\n\n    int max_negative = 0;\n    int min_positive = INT_MAX;\n\n    for (int i = 0; i < 8; i++) {\n        if (neg_arr[i] < 0) {\n            max_negative = std::max(max_negative, neg_arr[i]);\n        }\n        if (pos_arr[i] > 0) {\n            min_positive = std::min(min_positive, pos_arr[i]);\n        }\n    }\n\n    return {max_negative, min_positive == INT_MAX ? 0 : min_positive};\n}\n```"}
{"task_id": "SimdBench_128_AVX", "completion": "```cpp\nstd::vector<int> largest_smallest_integers_simd(const std::vector<int>& lst) {\n    if (lst.empty()) {\n        return {0, 0};\n    }\n\n    __m256i max_neg = _mm256_set1_epi32(0x80000000);  // Minimum possible value\n    __m256i min_pos = _mm256_set1_epi32(0x7FFFFFFF);  // Maximum possible value\n    __m256i zeros = _mm256_setzero_si256();\n    \n    for (size_t i = 0; i < lst.size(); i += 8) {\n        __m256i curr;\n        if (i + 8 <= lst.size()) {\n            curr = _mm256_loadu_si256((__m256i*)(lst.data() + i));\n        } else {\n            // Handle remaining elements\n            alignas(32) int temp[8] = {0};\n            for (size_t j = i; j < lst.size(); j++) {\n                temp[j - i] = lst[j];\n            }\n            curr = _mm256_load_si256((__m256i*)temp);\n        }\n\n        __m256i is_neg = _mm256_cmpgt_epi32(zeros, curr);\n        __m256i is_pos = _mm256_cmpgt_epi32(curr, zeros);\n        \n        // Update max negative\n        __m256i neg_vals = _mm256_and_si256(curr, is_neg);\n        max_neg = _mm256_blendv_epi8(max_neg, \n                                    _mm256_max_epi32(max_neg, neg_vals),\n                                    is_neg);\n        \n        // Update min positive\n        __m256i pos_vals = _mm256_and_si256(curr, is_pos);\n        min_pos = _mm256_blendv_epi8(min_pos,\n                                    _mm256_min_epi32(min_pos, pos_vals),\n                                    is_pos);\n    }\n\n    alignas(32) int max_neg_arr[8];\n    alignas(32) int min_pos_arr[8];\n    _mm256_store_si256((__m256i*)max_neg_arr, max_neg);\n    _mm256_store_si256((__m256i*)min_pos_arr, min_pos);\n\n    int max_negative = 0;\n    int min_positive = 0;\n\n    // Find max negative across lanes\n    for (int i = 0; i < 8; i++) {\n        if (max_neg_arr[i] < 0) {\n            max_negative = std::max(max_negative, max_neg_arr[i]);\n        }\n    }\n\n    // Find min positive across lanes\n    min_positive = 0x7FFFFFFF;\n    for (int i = 0; i < 8; i++) {\n        if (min_pos_arr[i] > 0) {\n            min_positive = std::min(min_positive, min_pos_arr[i]);\n        }\n    }\n\n    if (min_positive == 0x7FFFFFFF) min_positive = 0;\n    if (max_negative == 0x80000000) max_negative = 0;\n\n    return {max_negative, min_positive};\n}\n```"}
{"task_id": "SimdBench_128_AVX", "completion": "```cpp\nstd::vector<int> largest_smallest_integers_simd(const std::vector<int>& lst) {\n    if (lst.empty()) {\n        return {0, 0};\n    }\n\n    __m256i max_neg = _mm256_set1_epi32(0x80000000);  // Minimum possible int\n    __m256i min_pos = _mm256_set1_epi32(0x7FFFFFFF);  // Maximum possible int\n    __m256i zeros = _mm256_setzero_si256();\n\n    for (size_t i = 0; i < lst.size(); i += 8) {\n        __m256i curr;\n        if (i + 8 <= lst.size()) {\n            curr = _mm256_loadu_si256((__m256i*)(lst.data() + i));\n        } else {\n            // Handle remaining elements\n            alignas(32) int temp[8] = {0};\n            for (size_t j = i; j < lst.size(); j++) {\n                temp[j - i] = lst[j];\n            }\n            curr = _mm256_load_si256((__m256i*)temp);\n        }\n\n        __m256i is_neg = _mm256_cmpgt_epi32(zeros, curr);\n        __m256i is_pos = _mm256_cmpgt_epi32(curr, zeros);\n\n        __m256i neg_vals = _mm256_and_si256(curr, is_neg);\n        __m256i pos_vals = _mm256_and_si256(curr, is_pos);\n\n        max_neg = _mm256_max_epi32(max_neg, neg_vals);\n        min_pos = _mm256_min_epi32(min_pos, _mm256_or_si256(pos_vals, \n                 _mm256_andnot_si256(is_pos, _mm256_set1_epi32(0x7FFFFFFF))));\n    }\n\n    alignas(32) int neg_arr[8], pos_arr[8];\n    _mm256_store_si256((__m256i*)neg_arr, max_neg);\n    _mm256_store_si256((__m256i*)pos_arr, min_pos);\n\n    int max_negative = 0;\n    int min_positive = 0;\n\n    for (int i = 0; i < 8; i++) {\n        if (neg_arr[i] < 0) {\n            max_negative = std::max(max_negative, neg_arr[i]);\n        }\n        if (pos_arr[i] > 0) {\n            if (min_positive == 0) {\n                min_positive = pos_arr[i];\n            } else {\n                min_positive = std::min(min_positive, pos_arr[i]);\n            }\n        }\n    }\n\n    return {max_negative, min_positive};\n}\n```"}
{"task_id": "SimdBench_128_AVX", "completion": "```cpp\nstd::vector<int> largest_smallest_integers_simd(const std::vector<int>& lst) {\n    if (lst.empty()) {\n        return {0, 0};\n    }\n\n    __m256i max_neg = _mm256_set1_epi32(0x80000000);  // Minimum possible int\n    __m256i min_pos = _mm256_set1_epi32(0x7FFFFFFF);  // Maximum possible int\n    __m256i zeros = _mm256_setzero_si256();\n\n    for (size_t i = 0; i < lst.size(); i += 8) {\n        __m256i curr;\n        if (i + 8 <= lst.size()) {\n            curr = _mm256_loadu_si256((__m256i*)(lst.data() + i));\n        } else {\n            // Handle remaining elements\n            alignas(32) int temp[8] = {0};\n            for (size_t j = i; j < lst.size(); j++) {\n                temp[j - i] = lst[j];\n            }\n            curr = _mm256_load_si256((__m256i*)temp);\n        }\n\n        __m256i is_neg = _mm256_cmpgt_epi32(zeros, curr);\n        __m256i is_pos = _mm256_cmpgt_epi32(curr, zeros);\n\n        // Update max negative\n        __m256i neg_vals = _mm256_and_si256(curr, is_neg);\n        max_neg = _mm256_blendv_epi8(max_neg, \n                    _mm256_max_epi32(max_neg, neg_vals),\n                    is_neg);\n\n        // Update min positive  \n        __m256i pos_vals = _mm256_and_si256(curr, is_pos);\n        min_pos = _mm256_blendv_epi8(min_pos,\n                    _mm256_min_epi32(min_pos, pos_vals),\n                    is_pos);\n    }\n\n    // Extract results\n    alignas(32) int max_neg_arr[8];\n    alignas(32) int min_pos_arr[8];\n    _mm256_store_si256((__m256i*)max_neg_arr, max_neg);\n    _mm256_store_si256((__m256i*)min_pos_arr, min_pos);\n\n    int max_neg_val = 0;\n    int min_pos_val = 0;\n\n    // Find max negative across lanes\n    for (int i = 0; i < 8; i++) {\n        if (max_neg_arr[i] < 0) {\n            max_neg_val = std::max(max_neg_val, max_neg_arr[i]);\n        }\n    }\n\n    // Find min positive across lanes\n    min_pos_val = 0x7FFFFFFF;\n    for (int i = 0; i < 8; i++) {\n        if (min_pos_arr[i] > 0) {\n            min_pos_val = std::min(min_pos_val, min_pos_arr[i]);\n        }\n    }\n\n    if (min_pos_val == 0x7FFFFFFF) min_pos_val = 0;\n    if (max_neg_val == 0x80000000) max_neg_val = 0;\n\n    return {max_neg_val, min_pos_val};\n}\n```"}
{"task_id": "SimdBench_128_AVX", "completion": "```cpp\nstd::vector<int> largest_smallest_integers_simd(const std::vector<int>& lst) {\n    if (lst.empty()) {\n        return {0, 0};\n    }\n\n    __m256i max_neg = _mm256_set1_epi32(0x80000000);  // Minimum possible int\n    __m256i min_pos = _mm256_set1_epi32(0x7FFFFFFF);  // Maximum possible int\n    __m256i zero = _mm256_setzero_si256();\n\n    for (size_t i = 0; i < lst.size(); i += 8) {\n        __m256i curr;\n        if (i + 8 <= lst.size()) {\n            curr = _mm256_loadu_si256((__m256i*)(lst.data() + i));\n        } else {\n            // Handle remaining elements\n            alignas(32) int temp[8] = {0};\n            for (size_t j = i; j < lst.size(); j++) {\n                temp[j - i] = lst[j];\n            }\n            curr = _mm256_load_si256((__m256i*)temp);\n        }\n\n        __m256i is_neg = _mm256_cmpgt_epi32(zero, curr);\n        __m256i is_pos = _mm256_cmpgt_epi32(curr, zero);\n\n        // Update max negative\n        __m256i neg_vals = _mm256_and_si256(curr, is_neg);\n        max_neg = _mm256_blendv_epi8(max_neg, \n                                    _mm256_max_epi32(max_neg, neg_vals),\n                                    is_neg);\n\n        // Update min positive\n        __m256i pos_vals = _mm256_and_si256(curr, is_pos);\n        min_pos = _mm256_blendv_epi8(min_pos,\n                                    _mm256_min_epi32(min_pos, pos_vals),\n                                    is_pos);\n    }\n\n    alignas(32) int max_neg_arr[8];\n    alignas(32) int min_pos_arr[8];\n    _mm256_store_si256((__m256i*)max_neg_arr, max_neg);\n    _mm256_store_si256((__m256i*)min_pos_arr, min_pos);\n\n    int max_negative = 0;\n    int min_positive = 0;\n\n    // Find max negative across lanes\n    for (int i = 0; i < 8; i++) {\n        if (max_neg_arr[i] < 0) {\n            max_negative = std::max(max_negative, max_neg_arr[i]);\n        }\n    }\n\n    // Find min positive across lanes\n    min_positive = 0x7FFFFFFF;\n    for (int i = 0; i < 8; i++) {\n        if (min_pos_arr[i] > 0) {\n            min_positive = std::min(min_positive, min_pos_arr[i]);\n        }\n    }\n\n    if (min_positive == 0x7FFFFFFF) min_positive = 0;\n\n    return {max_negative, min_positive};\n}\n```"}
{"task_id": "SimdBench_129_AVX", "completion": "```cpp\nuint64_t special_factorial_simd(uint64_t n) {\n    if (n <= 1) return 1;\n    \n    uint64_t result = 1;\n    __m256i vec_result = _mm256_set1_epi64x(1);\n    \n    for (uint64_t i = 1; i <= n; i++) {\n        uint64_t factorial = 1;\n        __m256i vec_factorial = _mm256_set1_epi64x(1);\n        \n        for (uint64_t j = 2; j <= i; j += 4) {\n            __m256i multipliers = _mm256_set_epi64x(\n                (j + 3 <= i) ? j + 3 : 1,\n                (j + 2 <= i) ? j + 2 : 1,\n                (j + 1 <= i) ? j + 1 : 1,\n                j\n            );\n            vec_factorial = _mm256_mul_epi32(vec_factorial, multipliers);\n        }\n        \n        uint64_t temp[4];\n        _mm256_store_si256((__m256i*)temp, vec_factorial);\n        factorial = temp[0] * temp[1] * temp[2] * temp[3];\n        \n        result *= factorial;\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_129_AVX", "completion": "```cpp\nuint64_t special_factorial_simd(uint64_t n) {\n    if (n <= 1) return 1;\n    \n    uint64_t result = 1;\n    __m256i vec_result = _mm256_set1_epi64x(1);\n    \n    for (uint64_t i = 1; i <= n; i++) {\n        uint64_t factorial = 1;\n        __m256i vec_factorial = _mm256_set1_epi64x(1);\n        \n        for (uint64_t j = 1; j <= i; j += 4) {\n            __m256i multipliers = _mm256_set_epi64x(\n                (j+3 <= i) ? j+3 : 1,\n                (j+2 <= i) ? j+2 : 1,\n                (j+1 <= i) ? j+1 : 1,\n                j\n            );\n            vec_factorial = _mm256_mul_epi32(vec_factorial, multipliers);\n        }\n        \n        uint64_t temp[4];\n        _mm256_store_si256((__m256i*)temp, vec_factorial);\n        factorial = temp[0] * temp[1] * temp[2] * temp[3];\n        \n        result *= factorial;\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_129_AVX", "completion": "```cpp\nuint64_t special_factorial_simd(uint64_t n) {\n    if (n <= 1) return 1;\n    \n    uint64_t result = 1;\n    __m256i vec_result = _mm256_set1_epi64x(1);\n    \n    for (uint64_t i = 1; i <= n; i++) {\n        uint64_t factorial = 1;\n        __m256i vec_factorial = _mm256_set1_epi64x(1);\n        \n        for (uint64_t j = 2; j <= i; j += 4) {\n            __m256i multipliers = _mm256_set_epi64x(\n                (j + 3 <= i) ? j + 3 : 1,\n                (j + 2 <= i) ? j + 2 : 1,\n                (j + 1 <= i) ? j + 1 : 1,\n                j\n            );\n            vec_factorial = _mm256_mul_epi32(vec_factorial, multipliers);\n        }\n        \n        uint64_t temp[4];\n        _mm256_store_si256((__m256i*)temp, vec_factorial);\n        \n        factorial = temp[0] * temp[1] * temp[2] * temp[3];\n        result *= factorial;\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_129_AVX", "completion": "```cpp\nuint64_t special_factorial_simd(uint64_t n) {\n    if (n == 0 || n == 1) return 1;\n    \n    __m256i vec_result = _mm256_set1_epi64x(1);\n    uint64_t result = 1;\n    \n    for (uint64_t i = 1; i <= n; i++) {\n        uint64_t factorial = 1;\n        __m256i vec_factorial = _mm256_set1_epi64x(1);\n        \n        for (uint64_t j = 1; j <= i; j += 4) {\n            __m256i vec_nums = _mm256_set_epi64x(\n                (j+3 <= i) ? j+3 : 1,\n                (j+2 <= i) ? j+2 : 1,\n                (j+1 <= i) ? j+1 : 1,\n                j\n            );\n            vec_factorial = _mm256_mul_epi32(vec_factorial, vec_nums);\n        }\n        \n        uint64_t temp[4];\n        _mm256_store_si256((__m256i*)temp, vec_factorial);\n        \n        factorial = temp[0] * temp[1] * temp[2] * temp[3];\n        result *= factorial;\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_129_AVX", "completion": "```cpp\nuint64_t special_factorial_simd(uint64_t n) {\n    if (n <= 1) return 1;\n    \n    uint64_t result = 1;\n    __m256i vec_result = _mm256_set1_epi64x(1);\n    \n    for (uint64_t i = 1; i <= n; i++) {\n        uint64_t factorial = 1;\n        __m256i vec_factorial = _mm256_set1_epi64x(1);\n        \n        for (uint64_t j = 2; j <= i; j += 4) {\n            __m256i multipliers = _mm256_set_epi64x(\n                (j + 3 <= i) ? j + 3 : 1,\n                (j + 2 <= i) ? j + 2 : 1,\n                (j + 1 <= i) ? j + 1 : 1,\n                j\n            );\n            vec_factorial = _mm256_mul_epi32(vec_factorial, multipliers);\n        }\n        \n        uint64_t temp[4];\n        _mm256_store_si256((__m256i*)temp, vec_factorial);\n        factorial = temp[0] * temp[1] * temp[2] * temp[3];\n        \n        result *= factorial;\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_130_AVX", "completion": "```cpp\nint sum_squares_simd(const std::vector<int> & lst) {\n    if (lst.empty()) return 0;\n    \n    int size = lst.size();\n    int remainder = size % 8;\n    int simd_size = size - remainder;\n    \n    __m256i sum = _mm256_setzero_si256();\n    \n    for (int i = 0; i < simd_size; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)(lst.data() + i));\n        __m256i idx = _mm256_set_epi32(i+7, i+6, i+5, i+4, i+3, i+2, i+1, i);\n        \n        __m256i mod3 = _mm256_set1_epi32(3);\n        __m256i mod4 = _mm256_set1_epi32(4);\n        \n        __m256i is_mult3 = _mm256_cmpeq_epi32(_mm256_rem_epi32(idx, mod3), _mm256_setzero_si256());\n        __m256i is_mult4 = _mm256_cmpeq_epi32(_mm256_rem_epi32(idx, mod4), _mm256_setzero_si256());\n        \n        __m256i square = _mm256_mullo_epi32(vec, vec);\n        __m256i cube = _mm256_mullo_epi32(square, vec);\n        \n        __m256i result = vec;\n        result = _mm256_blendv_epi8(result, square, is_mult3);\n        result = _mm256_blendv_epi8(result, cube, _mm256_andnot_si256(is_mult3, is_mult4));\n        \n        sum = _mm256_add_epi32(sum, result);\n    }\n    \n    int final_sum = 0;\n    int* sum_arr = (int*)&sum;\n    for (int i = 0; i < 8; i++) {\n        final_sum += sum_arr[i];\n    }\n    \n    for (int i = simd_size; i < size; i++) {\n        if (i % 3 == 0) {\n            final_sum += lst[i] * lst[i];\n        }\n        else if (i % 4 == 0) {\n            final_sum += lst[i] * lst[i] * lst[i];\n        }\n        else {\n            final_sum += lst[i];\n        }\n    }\n    \n    return final_sum;\n}\n```"}
{"task_id": "SimdBench_130_AVX", "completion": "```cpp\nint sum_squares_simd(const std::vector<int> & lst) {\n    if (lst.empty()) return 0;\n    \n    int size = lst.size();\n    int sum = 0;\n    \n    // Pad input to multiple of 8\n    int padded_size = ((size + 7) / 8) * 8;\n    std::vector<int> padded(padded_size, 0);\n    std::copy(lst.begin(), lst.end(), padded.begin());\n    \n    __m256i sum_vec = _mm256_setzero_si256();\n    \n    for (int i = 0; i < padded_size; i += 8) {\n        // Load 8 integers\n        __m256i nums = _mm256_loadu_si256((__m256i*)&padded[i]);\n        \n        // Create index mask for multiples of 3\n        __m256i idx = _mm256_set_epi32(i+7, i+6, i+5, i+4, i+3, i+2, i+1, i);\n        __m256i mod3 = _mm256_set1_epi32(3);\n        __m256i mod4 = _mm256_set1_epi32(4);\n        __m256i is_mult3 = _mm256_cmpeq_epi32(_mm256_rem_epi32(idx, mod3), _mm256_setzero_si256());\n        __m256i is_mult4 = _mm256_cmpeq_epi32(_mm256_rem_epi32(idx, mod4), _mm256_setzero_si256());\n        \n        // Square numbers at indices divisible by 3\n        __m256i squared = _mm256_mullo_epi32(nums, nums);\n        __m256i cubed = _mm256_mullo_epi32(squared, nums);\n        \n        // Select between original, squared and cubed based on index\n        __m256i result = _mm256_blendv_epi8(nums, squared, is_mult3);\n        __m256i not_mult3 = _mm256_xor_si256(is_mult3, _mm256_set1_epi32(-1));\n        result = _mm256_blendv_epi8(result, cubed, _mm256_and_si256(is_mult4, not_mult3));\n        \n        // Add to running sum\n        sum_vec = _mm256_add_epi32(sum_vec, result);\n    }\n    \n    // Horizontal sum\n    int temp[8];\n    _mm256_storeu_si256((__m256i*)temp, sum_vec);\n    \n    for (int i = 0; i < 8; i++) {\n        if (i < size) sum += temp[i];\n    }\n    \n    return sum;\n}\n```"}
{"task_id": "SimdBench_130_AVX", "completion": "```cpp\nint sum_squares_simd(const std::vector<int> & lst) {\n    if (lst.empty()) return 0;\n    \n    int size = lst.size();\n    int remainder = size % 8;\n    int vectorized_size = size - remainder;\n    \n    __m256i sum = _mm256_setzero_si256();\n    \n    for (int i = 0; i < vectorized_size; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)(lst.data() + i));\n        __m256i idx = _mm256_set_epi32(i+7, i+6, i+5, i+4, i+3, i+2, i+1, i);\n        \n        __m256i div3 = _mm256_set1_epi32(3);\n        __m256i div4 = _mm256_set1_epi32(4);\n        \n        __m256i mod3 = _mm256_rem_epi32(idx, div3);\n        __m256i mod4 = _mm256_rem_epi32(idx, div4);\n        \n        __m256i is_mult3 = _mm256_cmpeq_epi32(mod3, _mm256_setzero_si256());\n        __m256i is_mult4 = _mm256_cmpeq_epi32(mod4, _mm256_setzero_si256());\n        __m256i is_mult4_not3 = _mm256_andnot_si256(is_mult3, is_mult4);\n        \n        __m256i square = _mm256_mullo_epi32(vec, vec);\n        __m256i cube = _mm256_mullo_epi32(square, vec);\n        \n        __m256i result = vec;\n        result = _mm256_blendv_epi8(result, square, is_mult3);\n        result = _mm256_blendv_epi8(result, cube, is_mult4_not3);\n        \n        sum = _mm256_add_epi32(sum, result);\n    }\n    \n    int final_sum = 0;\n    int* sum_arr = (int*)&sum;\n    for (int i = 0; i < 8; i++) {\n        final_sum += sum_arr[i];\n    }\n    \n    for (int i = vectorized_size; i < size; i++) {\n        if (i % 3 == 0) {\n            final_sum += lst[i] * lst[i];\n        }\n        else if (i % 4 == 0) {\n            final_sum += lst[i] * lst[i] * lst[i];\n        }\n        else {\n            final_sum += lst[i];\n        }\n    }\n    \n    return final_sum;\n}\n```"}
{"task_id": "SimdBench_130_AVX", "completion": "```cpp\nint sum_squares_simd(const std::vector<int> & lst) {\n    if (lst.empty()) return 0;\n    \n    const int n = lst.size();\n    const int simd_width = 8;\n    const int aligned_size = n - (n % simd_width);\n    \n    __m256i sum = _mm256_setzero_si256();\n    __m256i three = _mm256_set1_epi32(3);\n    __m256i four = _mm256_set1_epi32(4);\n    \n    for (int i = 0; i < aligned_size; i += simd_width) {\n        __m256i data = _mm256_loadu_si256((__m256i*)(lst.data() + i));\n        __m256i indices = _mm256_set_epi32(i+7, i+6, i+5, i+4, i+3, i+2, i+1, i);\n        \n        __m256i mod3 = _mm256_srli_epi32(_mm256_mullo_epi32(indices, _mm256_set1_epi32(0x55555556)), 31);\n        __m256i mod4 = _mm256_cmpeq_epi32(_mm256_and_si256(indices, _mm256_set1_epi32(3)), _mm256_setzero_si256());\n        \n        __m256i square_mask = mod3;\n        __m256i cube_mask = _mm256_andnot_si256(mod3, mod4);\n        \n        __m256i squared = _mm256_mullo_epi32(data, data);\n        __m256i cubed = _mm256_mullo_epi32(squared, data);\n        \n        __m256i result = data;\n        result = _mm256_blendv_epi8(result, squared, square_mask);\n        result = _mm256_blendv_epi8(result, cubed, cube_mask);\n        \n        sum = _mm256_add_epi32(sum, result);\n    }\n    \n    int final_sum = 0;\n    int temp[8];\n    _mm256_storeu_si256((__m256i*)temp, sum);\n    \n    for (int i = 0; i < 8; i++) {\n        final_sum += temp[i];\n    }\n    \n    for (int i = aligned_size; i < n; i++) {\n        if (i % 3 == 0) {\n            final_sum += lst[i] * lst[i];\n        } else if (i % 4 == 0) {\n            final_sum += lst[i] * lst[i] * lst[i];\n        } else {\n            final_sum += lst[i];\n        }\n    }\n    \n    return final_sum;\n}\n```"}
{"task_id": "SimdBench_130_AVX", "completion": "```cpp\nint sum_squares_simd(const std::vector<int> & lst) {\n    if (lst.empty()) return 0;\n    \n    const int n = lst.size();\n    alignas(32) int result[8] = {0};\n    __m256i sum = _mm256_setzero_si256();\n    \n    int i = 0;\n    for (; i + 7 < n; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)(lst.data() + i));\n        __m256i idx = _mm256_set_epi32(i+7, i+6, i+5, i+4, i+3, i+2, i+1, i);\n        \n        __m256i mod3 = _mm256_set1_epi32(3);\n        __m256i mod4 = _mm256_set1_epi32(4);\n        \n        __m256i is_mult3 = _mm256_cmpeq_epi32(_mm256_rem_epi32(idx, mod3), _mm256_setzero_si256());\n        __m256i is_mult4 = _mm256_cmpeq_epi32(_mm256_rem_epi32(idx, mod4), _mm256_setzero_si256());\n        \n        __m256i square = _mm256_mullo_epi32(vec, vec);\n        __m256i cube = _mm256_mullo_epi32(_mm256_mullo_epi32(vec, vec), vec);\n        \n        __m256i result = _mm256_blendv_epi8(vec, square, is_mult3);\n        result = _mm256_blendv_epi8(result, cube, _mm256_andnot_si256(is_mult3, is_mult4));\n        \n        sum = _mm256_add_epi32(sum, result);\n    }\n    \n    _mm256_store_si256((__m256i*)result, sum);\n    int final_sum = 0;\n    for (int j = 0; j < 8; j++) {\n        final_sum += result[j];\n    }\n    \n    for (; i < n; i++) {\n        if (i % 3 == 0) {\n            final_sum += lst[i] * lst[i];\n        }\n        else if (i % 4 == 0) {\n            final_sum += lst[i] * lst[i] * lst[i];\n        }\n        else {\n            final_sum += lst[i];\n        }\n    }\n    \n    return final_sum;\n}\n```"}
{"task_id": "SimdBench_131_AVX", "completion": "```cpp\nint specialFilter_simd(const std::vector<int> & nums) {\n    int count = 0;\n    int size = nums.size();\n    int remainder = size % 8;\n    int simd_size = size - remainder;\n\n    __m256i ten = _mm256_set1_epi32(10);\n    __m256i zero = _mm256_setzero_si256();\n    \n    for (int i = 0; i < simd_size; i += 8) {\n        __m256i nums_vec = _mm256_loadu_si256((__m256i*)(nums.data() + i));\n        \n        // Check if greater than 10\n        __m256i gt_mask = _mm256_cmpgt_epi32(nums_vec, ten);\n        \n        // Get absolute values for digit checks\n        __m256i abs_nums = _mm256_abs_epi32(nums_vec);\n        \n        // Get last digits\n        __m256i last_digits = _mm256_and_si256(abs_nums, _mm256_set1_epi32(0xF));\n        \n        // Get first digits by division\n        __m256i temp = abs_nums;\n        for(int j = 0; j < 9; j++) {\n            __m256i div_mask = _mm256_cmpgt_epi32(temp, _mm256_set1_epi32(9));\n            temp = _mm256_srli_epi32(_mm256_and_si256(div_mask, temp), 1);\n        }\n        __m256i first_digits = temp;\n        \n        // Check if digits are odd\n        __m256i last_odd = _mm256_and_si256(last_digits, _mm256_set1_epi32(1));\n        __m256i first_odd = _mm256_and_si256(first_digits, _mm256_set1_epi32(1));\n        \n        // Combine all conditions\n        __m256i odd_mask = _mm256_and_si256(last_odd, first_odd);\n        __m256i final_mask = _mm256_and_si256(gt_mask, odd_mask);\n        \n        // Count matching elements\n        int mask = _mm256_movemask_ps(_mm256_castsi256_ps(final_mask));\n        count += _mm_popcnt_u32(mask);\n    }\n    \n    // Handle remaining elements\n    for (int i = simd_size; i < size; i++) {\n        int num = std::abs(nums[i]);\n        if (nums[i] > 10) {\n            int last_digit = num % 10;\n            while (num >= 10) {\n                num /= 10;\n            }\n            int first_digit = num;\n            if ((first_digit % 2 == 1) && (last_digit % 2 == 1)) {\n                count++;\n            }\n        }\n    }\n    \n    return count;\n}\n```"}
{"task_id": "SimdBench_131_AVX", "completion": "```cpp\nint specialFilter_simd(const std::vector<int> & nums) {\n    int count = 0;\n    int size = nums.size();\n    int aligned_size = size - (size % 8);\n    \n    __m256i ten = _mm256_set1_epi32(10);\n    __m256i zero = _mm256_setzero_si256();\n    \n    for(int i = 0; i < aligned_size; i += 8) {\n        __m256i nums_vec = _mm256_loadu_si256((__m256i*)&nums[i]);\n        \n        // Check if greater than 10\n        __m256i mask_gt = _mm256_cmpgt_epi32(nums_vec, ten);\n        \n        // Get absolute values for digit extraction\n        __m256i abs_nums = _mm256_abs_epi32(nums_vec);\n        \n        // Get last digits\n        __m256i last_digits = _mm256_and_si256(abs_nums, _mm256_set1_epi32(0xF));\n        \n        // Get first digits by division\n        __m256i temp = abs_nums;\n        while(_mm256_movemask_ps(_mm256_castsi256_ps(_mm256_cmpgt_epi32(temp, _mm256_set1_epi32(9)))) != 0) {\n            temp = _mm256_srli_epi32(temp, 4);\n        }\n        __m256i first_digits = temp;\n        \n        // Check if first and last digits are odd\n        __m256i last_odd = _mm256_and_si256(last_digits, _mm256_set1_epi32(1));\n        __m256i first_odd = _mm256_and_si256(first_digits, _mm256_set1_epi32(1));\n        __m256i both_odd = _mm256_and_si256(last_odd, first_odd);\n        \n        // Combine conditions\n        __m256i final_mask = _mm256_and_si256(mask_gt, both_odd);\n        \n        // Count matches\n        int mask = _mm256_movemask_ps(_mm256_castsi256_ps(final_mask));\n        count += _mm_popcnt_u32(mask);\n    }\n    \n    // Handle remaining elements\n    for(int i = aligned_size; i < size; i++) {\n        int num = abs(nums[i]);\n        if(nums[i] > 10) {\n            int first = num;\n            while(first > 9) first /= 10;\n            int last = num % 10;\n            if(first % 2 == 1 && last % 2 == 1) {\n                count++;\n            }\n        }\n    }\n    \n    return count;\n}\n```"}
{"task_id": "SimdBench_131_AVX", "completion": "```cpp\nint specialFilter_simd(const std::vector<int> & nums) {\n    int count = 0;\n    int size = nums.size();\n    int rem = size % 8;\n    int simd_size = size - rem;\n\n    __m256i ten = _mm256_set1_epi32(10);\n    __m256i zero = _mm256_setzero_si256();\n    __m256i ten_div = _mm256_set1_epi32(10);\n    __m256i odd_mask = _mm256_set1_epi32(1);\n\n    for (int i = 0; i < simd_size; i += 8) {\n        __m256i nums_vec = _mm256_loadu_si256((__m256i*)(nums.data() + i));\n        \n        // Check if greater than 10\n        __m256i gt_mask = _mm256_cmpgt_epi32(nums_vec, ten);\n        \n        // Get absolute values for digit extraction\n        __m256i abs_nums = _mm256_abs_epi32(nums_vec);\n        \n        // Get last digits\n        __m256i last_digits = _mm256_and_si256(abs_nums, odd_mask);\n        __m256i last_odd = _mm256_and_si256(last_digits, odd_mask);\n        \n        // Get first digits\n        __m256i temp = abs_nums;\n        for(int j = 0; j < 10; j++) {\n            __m256i div_result = _mm256_div_epi32(temp, ten_div);\n            __m256i is_zero = _mm256_cmpeq_epi32(div_result, zero);\n            temp = _mm256_andnot_si256(is_zero, div_result);\n        }\n        __m256i first_digits = _mm256_and_si256(temp, odd_mask);\n        \n        // Combine conditions\n        __m256i odd_digits = _mm256_and_si256(first_digits, last_odd);\n        __m256i final_mask = _mm256_and_si256(gt_mask, odd_digits);\n        \n        // Count results\n        int mask = _mm256_movemask_ps(_mm256_castsi256_ps(final_mask));\n        count += _mm_popcnt_u32(mask);\n    }\n\n    // Handle remaining elements\n    for (int i = simd_size; i < size; i++) {\n        int num = std::abs(nums[i]);\n        if (nums[i] > 10) {\n            int last_digit = num % 10;\n            int first_digit = num;\n            while (first_digit >= 10) {\n                first_digit /= 10;\n            }\n            if ((last_digit % 2 == 1) && (first_digit % 2 == 1)) {\n                count++;\n            }\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_131_AVX", "completion": "```cpp\nint specialFilter_simd(const std::vector<int> & nums) {\n    int count = 0;\n    int size = nums.size();\n    int rem = size % 8;\n    int simd_size = size - rem;\n    \n    __m256i ten = _mm256_set1_epi32(10);\n    __m256i zero = _mm256_setzero_si256();\n    \n    for(int i = 0; i < simd_size; i += 8) {\n        __m256i nums_vec = _mm256_loadu_si256((__m256i*)&nums[i]);\n        \n        // Check if greater than 10\n        __m256i mask_gt = _mm256_cmpgt_epi32(nums_vec, ten);\n        \n        // Get absolute values for digit checks\n        __m256i abs_nums = _mm256_abs_epi32(nums_vec);\n        \n        // Get last digits\n        __m256i last_digits = _mm256_and_si256(abs_nums, _mm256_set1_epi32(0xF));\n        \n        // Get first digits by division\n        __m256i temp = abs_nums;\n        while(_mm256_movemask_ps(_mm256_castsi256_ps(_mm256_cmpgt_epi32(temp, _mm256_set1_epi32(9)))) != 0) {\n            temp = _mm256_srli_epi32(temp, 2);\n            temp = _mm256_mulhi_epi16(temp, _mm256_set1_epi32(0x199A));\n        }\n        __m256i first_digits = temp;\n        \n        // Check if digits are odd\n        __m256i last_odd = _mm256_and_si256(last_digits, _mm256_set1_epi32(1));\n        __m256i first_odd = _mm256_and_si256(first_digits, _mm256_set1_epi32(1));\n        \n        // Combine all conditions\n        __m256i odd_mask = _mm256_and_si256(last_odd, first_odd);\n        __m256i final_mask = _mm256_and_si256(mask_gt, odd_mask);\n        \n        // Count matching elements\n        int mask = _mm256_movemask_ps(_mm256_castsi256_ps(final_mask));\n        count += _mm_popcnt_u32(mask);\n    }\n    \n    // Handle remaining elements\n    for(int i = simd_size; i < size; i++) {\n        int num = std::abs(nums[i]);\n        if(nums[i] > 10) {\n            int last_digit = num % 10;\n            int first_digit = num;\n            while(first_digit > 9) {\n                first_digit /= 10;\n            }\n            if((last_digit % 2 == 1) && (first_digit % 2 == 1)) {\n                count++;\n            }\n        }\n    }\n    \n    return count;\n}\n```"}
{"task_id": "SimdBench_131_AVX", "completion": "```cpp\nint specialFilter_simd(const std::vector<int> & nums) {\n    int count = 0;\n    int size = nums.size();\n    int aligned_size = size - (size % 8);\n    \n    __m256i ten = _mm256_set1_epi32(10);\n    __m256i zero = _mm256_setzero_si256();\n    \n    for(int i = 0; i < aligned_size; i += 8) {\n        __m256i nums_vec = _mm256_loadu_si256((__m256i*)&nums[i]);\n        \n        // Check if greater than 10\n        __m256i mask_gt = _mm256_cmpgt_epi32(nums_vec, ten);\n        \n        // Get absolute values for digit extraction\n        __m256i abs_nums = _mm256_abs_epi32(nums_vec);\n        \n        // Get last digits\n        __m256i last_digits = _mm256_and_si256(abs_nums, _mm256_set1_epi32(0xF));\n        \n        // Get first digits by division\n        __m256i temp = abs_nums;\n        while(_mm256_movemask_epi8(_mm256_cmpgt_epi32(temp, _mm256_set1_epi32(9)))) {\n            temp = _mm256_srli_epi32(temp, 4);\n        }\n        __m256i first_digits = temp;\n        \n        // Check if digits are odd\n        __m256i last_odd = _mm256_and_si256(last_digits, _mm256_set1_epi32(1));\n        __m256i first_odd = _mm256_and_si256(first_digits, _mm256_set1_epi32(1));\n        \n        // Combine all conditions\n        __m256i odd_mask = _mm256_and_si256(first_odd, last_odd);\n        __m256i final_mask = _mm256_and_si256(mask_gt, odd_mask);\n        \n        int mask = _mm256_movemask_ps(_mm256_castsi256_ps(final_mask));\n        count += _mm_popcnt_u32(mask);\n    }\n    \n    // Handle remaining elements\n    for(int i = aligned_size; i < size; i++) {\n        int num = abs(nums[i]);\n        if(nums[i] > 10) {\n            int last_digit = num % 10;\n            while(num >= 10) {\n                num /= 10;\n            }\n            int first_digit = num;\n            if((first_digit % 2 == 1) && (last_digit % 2 == 1)) {\n                count++;\n            }\n        }\n    }\n    \n    return count;\n}\n```"}
{"task_id": "SimdBench_132_AVX", "completion": "```cpp\nuint64_t get_max_triples_simd(uint64_t n) {\n    if (n < 3) return 0;\n    \n    uint64_t count = 0;\n    uint64_t* a = (uint64_t*)aligned_alloc(32, ((n+4)/4)*32);\n    \n    // Generate array values using SIMD\n    __m256i increment = _mm256_set_epi64x(4,3,2,1);\n    __m256i four = _mm256_set1_epi64x(4);\n    \n    for(uint64_t i = 0; i < n; i += 4) {\n        __m256i idx = _mm256_add_epi64(_mm256_set1_epi64x(i), increment);\n        __m256i squared = _mm256_mul_epi32(idx, idx);\n        __m256i result = _mm256_sub_epi64(squared, idx);\n        result = _mm256_add_epi64(result, _mm256_set1_epi64x(1));\n        _mm256_store_si256((__m256i*)(a+i), result);\n    }\n\n    // Check all possible triples\n    for(uint64_t i = 0; i < n-2; i++) {\n        for(uint64_t j = i+1; j < n-1; j++) {\n            __m256i vi = _mm256_set1_epi64x(a[i]);\n            __m256i vj = _mm256_set1_epi64x(a[j]);\n            \n            for(uint64_t k = j+1; k < n; k += 4) {\n                if(k + 3 >= n) break;\n                \n                __m256i vk = _mm256_load_si256((__m256i*)(a+k));\n                __m256i sum = _mm256_add_epi64(vi, vj);\n                sum = _mm256_add_epi64(sum, vk);\n                \n                __m256i div3 = _mm256_set1_epi64x(3);\n                __m256i remainder = _mm256_rem_epi64(sum, div3);\n                __m256i mask = _mm256_cmpeq_epi64(remainder, _mm256_setzero_si256());\n                \n                uint32_t bits = _mm256_movemask_pd((__m256d)mask);\n                count += _mm_popcnt_u32(bits);\n            }\n            \n            // Handle remaining elements\n            for(uint64_t k = ((n-1)/4)*4; k < n; k++) {\n                if(k <= j) continue;\n                if((a[i] + a[j] + a[k]) % 3 == 0) {\n                    count++;\n                }\n            }\n        }\n    }\n    \n    free(a);\n    return count;\n}\n```"}
{"task_id": "SimdBench_132_AVX", "completion": "```cpp\nuint64_t get_max_triples_simd(uint64_t n) {\n    if (n < 3) return 0;\n    \n    uint64_t count = 0;\n    uint64_t* a = (uint64_t*)aligned_alloc(32, ((n + 3) & ~3) * sizeof(uint64_t));\n    \n    // Generate array using SIMD\n    __m256i increment = _mm256_set_epi64x(4, 3, 2, 1);\n    __m256i ones = _mm256_set1_epi64x(1);\n    \n    for (uint64_t i = 0; i < n; i += 4) {\n        __m256i idx = _mm256_add_epi64(_mm256_set1_epi64x(i), increment);\n        __m256i squared = _mm256_mul_epi32(idx, idx);\n        __m256i minus = _mm256_sub_epi64(squared, idx);\n        __m256i result = _mm256_add_epi64(minus, ones);\n        _mm256_store_si256((__m256i*)(a + i), result);\n    }\n\n    // Check all possible triples\n    for (uint64_t i = 0; i < n-2; i++) {\n        for (uint64_t j = i+1; j < n-1; j++) {\n            __m256i vi = _mm256_set1_epi64x(a[i]);\n            __m256i vj = _mm256_set1_epi64x(a[j]);\n            \n            for (uint64_t k = j+1; k < n; k += 4) {\n                __m256i vk = _mm256_load_si256((__m256i*)(a + k));\n                __m256i sum = _mm256_add_epi64(vi, vj);\n                sum = _mm256_add_epi64(sum, vk);\n                \n                // Check divisibility by 3\n                __m256i div3 = _mm256_set1_epi64x(3);\n                __m256i remainder = _mm256_rem_epi64(sum, div3);\n                __m256i mask = _mm256_cmpeq_epi64(remainder, _mm256_setzero_si256());\n                \n                uint32_t bits = _mm256_movemask_pd(_mm256_castsi256_pd(mask));\n                \n                while (bits && k < n) {\n                    if (bits & 1) count++;\n                    bits >>= 1;\n                    k++;\n                }\n                k -= 4;\n            }\n        }\n    }\n    \n    free(a);\n    return count;\n}\n```"}
{"task_id": "SimdBench_132_AVX", "completion": "```cpp\nuint64_t get_max_triples_simd(uint64_t n) {\n    if (n < 3) return 0;\n    \n    uint64_t count = 0;\n    uint64_t* a = (uint64_t*)aligned_alloc(32, ((n+4)&~3) * sizeof(uint64_t));\n    \n    // Generate array values using SIMD\n    __m256i increment = _mm256_set_epi64x(4,3,2,1);\n    __m256i four = _mm256_set1_epi64x(4);\n    \n    for(uint64_t i = 0; i < n; i += 4) {\n        __m256i idx = _mm256_add_epi64(_mm256_set1_epi64x(i), increment);\n        __m256i square = _mm256_mul_epi32(idx, idx);\n        __m256i result = _mm256_sub_epi64(square, idx);\n        result = _mm256_add_epi64(result, _mm256_set1_epi64x(1));\n        _mm256_store_si256((__m256i*)(a+i), result);\n        increment = _mm256_add_epi64(increment, four);\n    }\n\n    // Check triples\n    for(uint64_t i = 0; i < n-2; i++) {\n        for(uint64_t j = i+1; j < n-1; j++) {\n            __m256i sum_ij = _mm256_set1_epi64x(a[i] + a[j]);\n            \n            for(uint64_t k = j+1; k < n; k += 4) {\n                __m256i ak = _mm256_load_si256((__m256i*)(a+k));\n                __m256i sum = _mm256_add_epi64(sum_ij, ak);\n                __m256i rem = _mm256_set1_epi64x(0);\n                \n                for(int l = 0; l < 4 && k+l < n; l++) {\n                    uint64_t total = _mm256_extract_epi64(sum, l);\n                    if(total % 3 == 0) count++;\n                }\n            }\n        }\n    }\n    \n    free(a);\n    return count;\n}\n```"}
{"task_id": "SimdBench_132_AVX", "completion": "```cpp\nuint64_t get_max_triples_simd(uint64_t n) {\n    if (n < 3) return 0;\n    \n    uint64_t count = 0;\n    uint64_t* a = (uint64_t*)aligned_alloc(32, ((n+4)/4)*32);\n    \n    // Fill array using SIMD\n    __m256i idx = _mm256_setr_epi64x(1, 2, 3, 4);\n    __m256i inc = _mm256_set1_epi64x(4);\n    \n    for(uint64_t i = 0; i < n; i += 4) {\n        __m256i squares = _mm256_mul_epi64(idx, idx);\n        __m256i term = _mm256_sub_epi64(squares, idx);\n        __m256i result = _mm256_add_epi64(term, _mm256_set1_epi64x(1));\n        _mm256_store_si256((__m256i*)&a[i], result);\n        idx = _mm256_add_epi64(idx, inc);\n    }\n\n    // Check all possible triples\n    for(uint64_t i = 0; i < n-2; i++) {\n        for(uint64_t j = i+1; j < n-1; j++) {\n            __m256i vi = _mm256_set1_epi64x(a[i]);\n            __m256i vj = _mm256_set1_epi64x(a[j]);\n            \n            for(uint64_t k = j+1; k < n; k += 4) {\n                __m256i vk = _mm256_load_si256((__m256i*)&a[k]);\n                \n                __m256i sum = _mm256_add_epi64(vi, vj);\n                sum = _mm256_add_epi64(sum, vk);\n                \n                __m256i div3 = _mm256_set1_epi64x(3);\n                __m256i rem = _mm256_rem_epi64(sum, div3);\n                \n                uint64_t mask = _mm256_movemask_pd(_mm256_castsi256_pd(_mm256_cmpeq_epi64(rem, _mm256_setzero_si256())));\n                \n                while(mask) {\n                    int pos = __builtin_ctz(mask);\n                    if(k + pos < n) count++;\n                    mask &= (mask - 1);\n                }\n            }\n        }\n    }\n    \n    free(a);\n    return count;\n}\n```"}
{"task_id": "SimdBench_132_AVX", "completion": "```cpp\nuint64_t get_max_triples_simd(uint64_t n) {\n    if (n < 3) return 0;\n    \n    uint64_t count = 0;\n    uint64_t* a = (uint64_t*)aligned_alloc(32, ((n+4)/4)*32);\n    \n    // Fill array using SIMD\n    __m256i increment = _mm256_set_epi64x(3,2,1,0);\n    for(uint64_t i = 0; i < n; i += 4) {\n        __m256i idx = _mm256_add_epi64(_mm256_set1_epi64x(i), increment);\n        __m256i squared = _mm256_mul_epi32(idx, idx);\n        __m256i result = _mm256_sub_epi64(squared, idx);\n        result = _mm256_add_epi64(result, _mm256_set1_epi64x(1));\n        _mm256_store_si256((__m256i*)(a+i), result);\n    }\n\n    // Check all possible triples\n    for(uint64_t i = 0; i < n-2; i++) {\n        for(uint64_t j = i+1; j < n-1; j++) {\n            __m256i vi = _mm256_set1_epi64x(a[i]);\n            __m256i vj = _mm256_set1_epi64x(a[j]);\n            \n            for(uint64_t k = j+1; k < n; k += 4) {\n                __m256i vk = _mm256_load_si256((__m256i*)(a+k));\n                \n                // Calculate sum\n                __m256i sum = _mm256_add_epi64(vi, vj);\n                sum = _mm256_add_epi64(sum, vk);\n                \n                // Check divisibility by 3\n                uint64_t sums[4];\n                _mm256_store_si256((__m256i*)sums, sum);\n                \n                for(int x = 0; x < 4 && k+x < n; x++) {\n                    if(sums[x] % 3 == 0) {\n                        count++;\n                    }\n                }\n            }\n        }\n    }\n    \n    free(a);\n    return count;\n}\n```"}
{"task_id": "SimdBench_133_AVX", "completion": "```cpp\nint x_or_y_simd(int n, int x, int y) {\n    if (n <= 1) return y;\n    if (n <= 3) return x;\n    \n    __m256i vn = _mm256_set1_epi32(n);\n    __m256i divisors = _mm256_setr_epi32(2, 3, 4, 5, 6, 7, 8, 9);\n    __m256i increment = _mm256_set1_epi32(8);\n    __m256i zeros = _mm256_setzero_si256();\n    \n    int sqrt_n = (int)sqrt(n);\n    \n    while (1) {\n        __m256i remainders = _mm256_rem_epi32(vn, divisors);\n        __m256i mask = _mm256_cmpeq_epi32(remainders, zeros);\n        int result = _mm256_movemask_ps(_mm256_castsi256_ps(mask));\n        \n        if (result) {\n            if (n % 2 == 0 || n % 3 == 0) return y;\n            for (int i = 5; i * i <= n; i += 6) {\n                if (n % i == 0 || n % (i + 2) == 0) return y;\n            }\n            return x;\n        }\n        \n        if (_mm256_extract_epi32(divisors, 7) > sqrt_n) {\n            return x;\n        }\n        \n        divisors = _mm256_add_epi32(divisors, increment);\n    }\n}\n```"}
{"task_id": "SimdBench_133_AVX", "completion": "```cpp\nint x_or_y_simd(int n, int x, int y) {\n    if (n <= 1) return y;\n    if (n <= 3) return x;\n    \n    __m256i nums = _mm256_setr_epi32(2, 3, 4, 5, 6, 7, 8, 9);\n    __m256i vn = _mm256_set1_epi32(n);\n    __m256i zeros = _mm256_setzero_si256();\n    \n    int limit = (int)sqrt(n);\n    int is_prime = 1;\n    \n    for(int i = 2; i <= limit; i += 8) {\n        __m256i divs = _mm256_add_epi32(nums, _mm256_set1_epi32(i-2));\n        __m256i rem = _mm256_rem_epi32(vn, divs);\n        __m256i cmp = _mm256_cmpeq_epi32(rem, zeros);\n        int mask = _mm256_movemask_ps(_mm256_castsi256_ps(cmp));\n        \n        if(mask != 0) {\n            is_prime = 0;\n            break;\n        }\n        \n        if(i + 7 > limit) break;\n    }\n    \n    return is_prime ? x : y;\n}\n```"}
{"task_id": "SimdBench_133_AVX", "completion": "```cpp\nint x_or_y_simd(int n, int x, int y) {\n    if (n <= 1) return y;\n    if (n <= 3) return x;\n    \n    __m256i divisors = _mm256_setr_epi32(2, 3, 4, 5, 6, 7, 8, 9);\n    __m256i num = _mm256_set1_epi32(n);\n    __m256i zeros = _mm256_setzero_si256();\n    \n    int limit = (int)sqrt(n);\n    int i;\n    \n    for (i = 0; i <= limit-8; i += 8) {\n        __m256i quotients = _mm256_div_epi32(num, divisors);\n        __m256i products = _mm256_mullo_epi32(quotients, divisors);\n        __m256i remainders = _mm256_sub_epi32(num, products);\n        __m256i mask = _mm256_cmpeq_epi32(remainders, zeros);\n        \n        if (_mm256_movemask_epi8(mask) != 0) {\n            return y;\n        }\n        \n        divisors = _mm256_add_epi32(divisors, _mm256_set1_epi32(8));\n    }\n    \n    for (; i <= limit; i++) {\n        if (n % i == 0) {\n            return y;\n        }\n    }\n    \n    return x;\n}\n```"}
{"task_id": "SimdBench_133_AVX", "completion": "```cpp\nint x_or_y_simd(int n, int x, int y) {\n    if (n <= 1) return y;\n    if (n <= 3) return x;\n    \n    __m256i divisors = _mm256_setr_epi32(2, 3, 4, 5, 6, 7, 8, 9);\n    __m256i num = _mm256_set1_epi32(n);\n    __m256i zeros = _mm256_setzero_si256();\n    \n    for (int i = 0; i <= (n/2 - 8); i += 8) {\n        __m256i rem = _mm256_rem_epi32(num, divisors);\n        __m256i cmp = _mm256_cmpeq_epi32(rem, zeros);\n        int mask = _mm256_movemask_ps(_mm256_castsi256_ps(cmp));\n        if (mask) return y;\n        divisors = _mm256_add_epi32(divisors, _mm256_set1_epi32(8));\n    }\n    \n    int remaining = (n/2) % 8;\n    int start = n/2 - remaining;\n    \n    for (int i = start + 1; i <= n/2; i++) {\n        if (n % i == 0) return y;\n    }\n    \n    return x;\n}\n```"}
{"task_id": "SimdBench_133_AVX", "completion": "```cpp\nint x_or_y_simd(int n, int x, int y) {\n    if (n <= 1) return y;\n    if (n <= 3) return x;\n    if (n % 2 == 0 || n % 3 == 0) return y;\n\n    __m256i i_vec = _mm256_set1_epi32(5);\n    __m256i inc_vec = _mm256_set1_epi32(8);\n    __m256i n_vec = _mm256_set1_epi32(n);\n    __m256i sqrt_n = _mm256_set1_epi32((int)sqrt(n));\n    \n    while (_mm256_extract_epi32(i_vec, 0) <= sqrt(n)) {\n        __m256i mod1 = _mm256_rem_epi32(n_vec, i_vec);\n        __m256i mod2 = _mm256_rem_epi32(n_vec, _mm256_add_epi32(i_vec, _mm256_set1_epi32(2)));\n        \n        __m256i zero = _mm256_setzero_si256();\n        __m256i cmp1 = _mm256_cmpeq_epi32(mod1, zero);\n        __m256i cmp2 = _mm256_cmpeq_epi32(mod2, zero);\n        \n        if (_mm256_movemask_epi8(_mm256_or_si256(cmp1, cmp2))) {\n            return y;\n        }\n        \n        i_vec = _mm256_add_epi32(i_vec, inc_vec);\n    }\n    \n    return x;\n}\n```"}
{"task_id": "SimdBench_134_AVX", "completion": "```cpp\nuint64_t double_the_difference_simd(const std::vector<float>& lst) {\n    if (lst.empty()) return 0;\n    \n    const int vec_size = 8;\n    int n = lst.size();\n    int vec_count = n / vec_size;\n    \n    __m256 sum = _mm256_setzero_ps();\n    __m256 zeros = _mm256_setzero_ps();\n    __m256 ones = _mm256_set1_ps(1.0f);\n    __m256 twos = _mm256_set1_ps(2.0f);\n    \n    for (int i = 0; i < vec_count * vec_size; i += vec_size) {\n        __m256 vec = _mm256_loadu_ps(&lst[i]);\n        \n        // Check if numbers are positive\n        __m256 pos_mask = _mm256_cmp_ps(vec, zeros, _CMP_GT_OS);\n        \n        // Check if numbers are integers\n        __m256 rounded = _mm256_round_ps(vec, _MM_FROUND_TO_NEAREST_INT);\n        __m256 int_mask = _mm256_cmp_ps(vec, rounded, _CMP_EQ_OS);\n        \n        // Check if numbers are odd\n        __m256 div_two = _mm256_div_ps(rounded, twos);\n        __m256 mult_two = _mm256_mul_ps(div_two, twos);\n        __m256 odd_mask = _mm256_cmp_ps(rounded, mult_two, _CMP_NEQ_OS);\n        \n        // Combine masks\n        __m256 final_mask = _mm256_and_ps(_mm256_and_ps(pos_mask, int_mask), odd_mask);\n        \n        // Zero out invalid numbers\n        vec = _mm256_and_ps(vec, final_mask);\n        \n        // Square the numbers\n        __m256 squares = _mm256_mul_ps(vec, vec);\n        \n        // Add to sum\n        sum = _mm256_add_ps(sum, squares);\n    }\n    \n    // Process remaining elements\n    float result = 0;\n    float temp[8];\n    _mm256_storeu_ps(temp, sum);\n    for (int i = 0; i < 8; i++) {\n        result += temp[i];\n    }\n    \n    // Handle remaining elements not processed by SIMD\n    for (int i = vec_count * vec_size; i < n; i++) {\n        float val = lst[i];\n        if (val > 0 && val == std::floor(val) && (static_cast<int>(val) % 2 == 1)) {\n            result += val * val;\n        }\n    }\n    \n    return static_cast<uint64_t>(result);\n}\n```"}
{"task_id": "SimdBench_134_AVX", "completion": "```cpp\nuint64_t double_the_difference_simd(const std::vector<float>& lst) {\n    if (lst.empty()) return 0;\n    \n    const int vec_size = 8;\n    int n = lst.size();\n    uint64_t sum = 0;\n    \n    __m256 zeros = _mm256_setzero_ps();\n    __m256 ones = _mm256_set1_ps(1.0f);\n    __m256 twos = _mm256_set1_ps(2.0f);\n    \n    for (int i = 0; i < n - (n % vec_size); i += vec_size) {\n        __m256 vec = _mm256_loadu_ps(&lst[i]);\n        \n        // Check if numbers are non-negative\n        __m256 mask_pos = _mm256_cmp_ps(vec, zeros, _CMP_GE_OQ);\n        \n        // Check if numbers are integers\n        __m256 rounded = _mm256_round_ps(vec, _MM_FROUND_TO_NEAREST_INT);\n        __m256 mask_int = _mm256_cmp_ps(vec, rounded, _CMP_EQ_OQ);\n        \n        // Check if numbers are odd\n        __m256 div_two = _mm256_div_ps(rounded, twos);\n        __m256 round_div = _mm256_round_ps(div_two, _MM_FROUND_TO_NEAREST_INT);\n        __m256 mult_two = _mm256_mul_ps(round_div, twos);\n        __m256 mask_odd = _mm256_cmp_ps(rounded, mult_two, _CMP_NEQ_OQ);\n        \n        // Combine masks\n        __m256 final_mask = _mm256_and_ps(_mm256_and_ps(mask_pos, mask_int), mask_odd);\n        \n        // Zero out non-qualifying numbers\n        __m256 masked_vec = _mm256_and_ps(vec, final_mask);\n        \n        // Square the numbers\n        __m256 squared = _mm256_mul_ps(masked_vec, masked_vec);\n        \n        // Store to array and sum\n        float temp[8];\n        _mm256_storeu_ps(temp, squared);\n        for(int j = 0; j < 8; j++) {\n            sum += (uint64_t)temp[j];\n        }\n    }\n    \n    // Handle remaining elements\n    for (int i = n - (n % vec_size); i < n; i++) {\n        float val = lst[i];\n        if (val >= 0 && val == (int)val && (int)val % 2 == 1) {\n            sum += (uint64_t)(val * val);\n        }\n    }\n    \n    return sum;\n}\n```"}
{"task_id": "SimdBench_134_AVX", "completion": "```cpp\nuint64_t double_the_difference_simd(const std::vector<float>& lst) {\n    if (lst.empty()) return 0;\n\n    const int vec_size = 8;\n    int size = lst.size();\n    uint64_t sum = 0;\n\n    __m256 vec_zero = _mm256_setzero_ps();\n    __m256 vec_one = _mm256_set1_ps(1.0f);\n    __m256 vec_two = _mm256_set1_ps(2.0f);\n\n    for (int i = 0; i < size - (size % vec_size); i += vec_size) {\n        __m256 vec = _mm256_loadu_ps(&lst[i]);\n        \n        // Check if numbers are negative\n        __m256 mask_neg = _mm256_cmp_ps(vec, vec_zero, _CMP_GT_OQ);\n        \n        // Check if numbers are integers\n        __m256 rounded = _mm256_round_ps(vec, _MM_FROUND_TO_NEAREST_INT);\n        __m256 mask_int = _mm256_cmp_ps(vec, rounded, _CMP_EQ_OQ);\n        \n        // Check if numbers are odd\n        __m256 div_two = _mm256_div_ps(vec, vec_two);\n        __m256 round_div = _mm256_round_ps(div_two, _MM_FROUND_TO_NEAREST_INT);\n        __m256 mult_two = _mm256_mul_ps(round_div, vec_two);\n        __m256 mask_odd = _mm256_cmp_ps(vec, mult_two, _CMP_NEQ_OQ);\n        \n        // Combine masks\n        __m256 mask_combined = _mm256_and_ps(_mm256_and_ps(mask_neg, mask_int), mask_odd);\n        \n        // Zero out non-qualifying numbers\n        __m256 qualified = _mm256_and_ps(vec, mask_combined);\n        \n        // Square the numbers\n        __m256 squared = _mm256_mul_ps(qualified, qualified);\n        \n        // Store results\n        float temp[8];\n        _mm256_storeu_ps(temp, squared);\n        \n        // Add up results\n        for (int j = 0; j < vec_size; j++) {\n            sum += (uint64_t)temp[j];\n        }\n    }\n\n    // Handle remaining elements\n    for (int i = size - (size % vec_size); i < size; i++) {\n        float val = lst[i];\n        if (val > 0 && val == (int)val && (int)val % 2 == 1) {\n            sum += (uint64_t)(val * val);\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_134_AVX", "completion": "```cpp\nuint64_t double_the_difference_simd(const std::vector<float>& lst) {\n    if (lst.empty()) return 0;\n\n    const int vec_size = 8;\n    int n = lst.size();\n    int aligned_size = (n + vec_size - 1) & ~(vec_size - 1);\n    \n    std::vector<float> padded(aligned_size, 0.0f);\n    std::copy(lst.begin(), lst.end(), padded.begin());\n\n    __m256 sum = _mm256_setzero_ps();\n    __m256 zeros = _mm256_setzero_ps();\n    __m256 ones = _mm256_set1_ps(1.0f);\n    __m256 twos = _mm256_set1_ps(2.0f);\n\n    for (int i = 0; i < aligned_size; i += vec_size) {\n        __m256 nums = _mm256_load_ps(&padded[i]);\n        \n        // Check if numbers are negative\n        __m256 pos_mask = _mm256_cmp_ps(nums, zeros, _CMP_GT_OS);\n        \n        // Check if numbers are integers\n        __m256 rounded = _mm256_round_ps(nums, _MM_FROUND_TO_NEAREST_INT);\n        __m256 int_mask = _mm256_cmp_ps(nums, rounded, _CMP_EQ_OS);\n        \n        // Check if numbers are odd\n        __m256 divided = _mm256_div_ps(rounded, twos);\n        __m256 mult = _mm256_mul_ps(divided, twos);\n        __m256 odd_mask = _mm256_cmp_ps(rounded, mult, _CMP_NEQ_OS);\n        \n        // Combine masks\n        __m256 final_mask = _mm256_and_ps(_mm256_and_ps(pos_mask, int_mask), odd_mask);\n        \n        // Square the numbers\n        __m256 squares = _mm256_mul_ps(nums, nums);\n        \n        // Apply mask and add to sum\n        squares = _mm256_and_ps(squares, final_mask);\n        sum = _mm256_add_ps(sum, squares);\n    }\n\n    float temp[vec_size];\n    _mm256_store_ps(temp, sum);\n    \n    uint64_t result = 0;\n    for (int i = 0; i < vec_size; i++) {\n        result += (uint64_t)temp[i];\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_134_AVX", "completion": "```cpp\nuint64_t double_the_difference_simd(const std::vector<float>& lst) {\n    if (lst.empty()) return 0;\n\n    const int vec_size = 8;\n    int size = lst.size();\n    uint64_t sum = 0;\n\n    __m256 vec_nums, vec_floor, vec_is_int;\n    __m256 vec_zeros = _mm256_setzero_ps();\n    __m256 vec_ones = _mm256_set1_ps(1.0f);\n    __m256 vec_twos = _mm256_set1_ps(2.0f);\n\n    for (int i = 0; i <= size - vec_size; i += vec_size) {\n        // Load 8 floats\n        vec_nums = _mm256_loadu_ps(&lst[i]);\n        \n        // Check if numbers are non-negative\n        __m256 vec_positive = _mm256_cmp_ps(vec_nums, vec_zeros, _CMP_GE_OQ);\n        \n        // Check if numbers are integers\n        vec_floor = _mm256_floor_ps(vec_nums);\n        vec_is_int = _mm256_cmp_ps(vec_nums, vec_floor, _CMP_EQ_OQ);\n        \n        // Get remainder when divided by 2 to check odd numbers\n        __m256 vec_div2 = _mm256_div_ps(vec_nums, vec_twos);\n        __m256 vec_floor_div2 = _mm256_floor_ps(vec_div2);\n        __m256 vec_rem = _mm256_sub_ps(vec_div2, vec_floor_div2);\n        __m256 vec_is_odd = _mm256_cmp_ps(vec_rem, vec_zeros, _CMP_NEQ_OQ);\n        \n        // Combine all conditions\n        __m256 vec_valid = _mm256_and_ps(vec_positive, vec_is_int);\n        vec_valid = _mm256_and_ps(vec_valid, vec_is_odd);\n        \n        // Square the valid numbers\n        __m256 vec_squared = _mm256_mul_ps(vec_nums, vec_nums);\n        vec_squared = _mm256_and_ps(vec_squared, vec_valid);\n        \n        // Extract results\n        float results[8];\n        _mm256_storeu_ps(results, vec_squared);\n        \n        for (int j = 0; j < 8; j++) {\n            sum += (uint64_t)results[j];\n        }\n    }\n\n    // Handle remaining elements\n    for (int i = size - (size % vec_size); i < size; i++) {\n        float num = lst[i];\n        if (num >= 0 && num == floor(num) && (int)num % 2 == 1) {\n            sum += (uint64_t)(num * num);\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_135_AVX", "completion": "```cpp\nstd::vector<int> compare_simd(const std::vector<int>& game, const std::vector<int>& guess) {\n    std::vector<int> result(game.size());\n    const int n = game.size();\n    \n    for (int i = 0; i < n; i += 8) {\n        __m256i game_vec = _mm256_loadu_si256((__m256i*)(game.data() + i));\n        __m256i guess_vec = _mm256_loadu_si256((__m256i*)(guess.data() + i));\n        \n        __m256i diff = _mm256_sub_epi32(game_vec, guess_vec);\n        __m256i abs_diff = _mm256_abs_epi32(diff);\n        \n        _mm256_storeu_si256((__m256i*)(result.data() + i), abs_diff);\n    }\n    \n    // Handle remaining elements\n    for (int i = n - (n % 8); i < n; i++) {\n        result[i] = std::abs(game[i] - guess[i]);\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_135_AVX", "completion": "```cpp\nstd::vector<int> compare_simd(const std::vector<int>& game, const std::vector<int>& guess) {\n    std::vector<int> result(game.size());\n    const int n = game.size();\n    \n    for (int i = 0; i < n; i += 8) {\n        __m256i v1 = _mm256_loadu_si256((__m256i*)&game[i]);\n        __m256i v2 = _mm256_loadu_si256((__m256i*)&guess[i]);\n        \n        // Calculate differences\n        __m256i diff = _mm256_sub_epi32(v1, v2);\n        \n        // Get absolute values\n        __m256i neg = _mm256_sub_epi32(_mm256_setzero_si256(), diff);\n        __m256i abs_diff = _mm256_max_epi32(diff, neg);\n        \n        // Store result\n        _mm256_storeu_si256((__m256i*)&result[i], abs_diff);\n    }\n    \n    // Handle remaining elements\n    for (int i = n - (n % 8); i < n; i++) {\n        result[i] = std::abs(game[i] - guess[i]);\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_135_AVX", "completion": "```cpp\nstd::vector<int> compare_simd(const std::vector<int>& game, const std::vector<int>& guess) {\n    std::vector<int> result(game.size());\n    const int n = game.size();\n    \n    for (int i = 0; i < n; i += 8) {\n        __m256i v1 = _mm256_loadu_si256((__m256i*)&game[i]);\n        __m256i v2 = _mm256_loadu_si256((__m256i*)&guess[i]);\n        \n        // Calculate differences\n        __m256i diff = _mm256_sub_epi32(v1, v2);\n        \n        // Get absolute values\n        __m256i neg = _mm256_sub_epi32(_mm256_setzero_si256(), diff);\n        __m256i abs_diff = _mm256_max_epi32(diff, neg);\n        \n        // Store result\n        _mm256_storeu_si256((__m256i*)&result[i], abs_diff);\n    }\n    \n    // Handle remaining elements\n    for (int i = n - (n % 8); i < n; i++) {\n        result[i] = std::abs(game[i] - guess[i]);\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_135_AVX", "completion": "```cpp\nstd::vector<int> compare_simd(const std::vector<int>& game, const std::vector<int>& guess) {\n    std::vector<int> result(game.size());\n    const int n = game.size();\n    \n    for (int i = 0; i < n; i += 8) {\n        __m256i v1 = _mm256_loadu_si256((__m256i*)&game[i]);\n        __m256i v2 = _mm256_loadu_si256((__m256i*)&guess[i]);\n        \n        // Calculate differences\n        __m256i diff = _mm256_sub_epi32(v1, v2);\n        \n        // Get absolute values\n        __m256i neg = _mm256_sub_epi32(_mm256_setzero_si256(), diff);\n        __m256i abs_diff = _mm256_max_epi32(diff, neg);\n        \n        // Store result\n        _mm256_storeu_si256((__m256i*)&result[i], abs_diff);\n    }\n    \n    // Handle remaining elements\n    for (int i = n - (n % 8); i < n; i++) {\n        result[i] = std::abs(game[i] - guess[i]);\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_135_AVX", "completion": "```cpp\nstd::vector<int> compare_simd(const std::vector<int>& game, const std::vector<int>& guess) {\n    std::vector<int> result(game.size());\n    const int n = game.size();\n    \n    for (int i = 0; i < n; i += 8) {\n        __m256i v1 = _mm256_loadu_si256((__m256i*)(game.data() + i));\n        __m256i v2 = _mm256_loadu_si256((__m256i*)(guess.data() + i));\n        \n        __m256i diff = _mm256_sub_epi32(v1, v2);\n        __m256i neg_diff = _mm256_sub_epi32(_mm256_setzero_si256(), diff);\n        __m256i abs_diff = _mm256_max_epi32(diff, neg_diff);\n        \n        _mm256_storeu_si256((__m256i*)(result.data() + i), abs_diff);\n    }\n    \n    // Handle remaining elements\n    for (int i = n - (n % 8); i < n; i++) {\n        result[i] = std::abs(game[i] - guess[i]);\n    }\n    \n    return result;\n}\n```"}

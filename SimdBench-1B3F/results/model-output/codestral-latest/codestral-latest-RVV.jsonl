{"task_id": "SimdBench_0_RVV", "completion": "```c\nvoid conditional_move_simd(const int64_t *src, int64_t *dst, const bool *mask, size_t length) {\n    size_t vl = __riscv_vsetvl_e64m1(length);\n    for (size_t i = 0; i < length; i += vl) {\n        vl = __riscv_vsetvl_e64m1(length - i);\n        vint64m1_t v_src = __riscv_vle64_v_i64m1(&src[i], vl);\n        vint64m1_t v_dst = __riscv_vle64_v_i64m1(&dst[i], vl);\n        vuint8mf8_t v_mask = __riscv_vle8_v_u8mf8((const uint8_t *)&mask[i], vl);\n        v_mask = __riscv_vmsif_m_b(v_mask, 0, vl);\n        v_dst = __riscv_vmerge_vxm_i64m1(v_dst, v_src, v_mask, v_dst, vl);\n        __riscv_vse64_v_i64m1(&dst[i], v_dst, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_0_RVV", "completion": "```cpp\nvoid conditional_move_simd(const int64_t *src, int64_t *dst, const bool *mask, size_t length) {\n    size_t vl = __riscv_vsetvl_e64m1(length);\n    for (size_t i = 0; i < length; i += vl) {\n        vl = __riscv_vsetvl_e64m1(length - i);\n        vint64m1_t v_src = __riscv_vle64_v_i64m1(src + i, vl);\n        vint64m1_t v_dst = __riscv_vle64_v_i64m1(dst + i, vl);\n        vuint8mf8_t v_mask = __riscv_vle8_v_u8mf8((const uint8_t *)(mask + i), vl);\n        v_mask = __riscv_vmsif_m_b8(v_mask, vl);\n        v_dst = __riscv_vmerge_vxm_i64m1(v_dst, v_src, v_mask, 0, vl);\n        __riscv_vse64_v_i64m1(dst + i, v_dst, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_0_RVV", "completion": "```c\nvoid conditional_move_simd(const int64_t *src, int64_t *dst, const bool *mask, size_t length) {\n    size_t vl = __riscv_vsetvl_e64m1(length);\n    for (size_t i = 0; i < length; i += vl) {\n        vl = __riscv_vsetvl_e64m1(length - i);\n        vint64m1_t v_src = __riscv_vle64_v_i64m1(&src[i], vl);\n        vint64m1_t v_dst = __riscv_vle64_v_i64m1(&dst[i], vl);\n        vuint8mf8_t v_mask = __riscv_vle8_v_u8mf8((const uint8_t *)&mask[i], vl);\n        v_mask = __riscv_vmsif_m_b(v_mask, 0, vl);\n        v_dst = __riscv_vmerge_vxm_i64m1(v_dst, v_src, v_mask, v_dst, vl);\n        __riscv_vse64_v_i64m1(&dst[i], v_dst, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_0_RVV", "completion": "```cpp\nvoid conditional_move_simd(const int64_t *src, int64_t *dst, const bool *mask, size_t length) {\n    size_t vl = __riscv_vsetvl_e64m1(length);\n    for (size_t i = 0; i < length; i += vl) {\n        vl = __riscv_vsetvl_e64m1(length - i);\n        vint64m1_t v_src = __riscv_vle64_v_i64m1(&src[i], vl);\n        vint64m1_t v_dst = __riscv_vle64_v_i64m1(&dst[i], vl);\n        vuint8mf8_t v_mask = __riscv_vlm_v_u8mf8((const uint8_t *)&mask[i], vl);\n        v_mask = __riscv_vreinterpret_v_u8mf8_u8m1(v_mask);\n        v_dst = __riscv_vmerge_vxm_i64m1(v_dst, v_src, v_mask, 0, vl);\n        __riscv_vse64_v_i64m1(&dst[i], v_dst, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_0_RVV", "completion": "```cpp\nvoid conditional_move_simd(const int64_t *src, int64_t *dst, const bool *mask, size_t length) {\n    size_t vl = __riscv_vsetvl_e64m1(length);\n    for (size_t i = 0; i < length; i += vl) {\n        vl = __riscv_vsetvl_e64m1(length - i);\n        vint64m1_t v_src = __riscv_vle64_v_i64m1(&src[i], vl);\n        vint64m1_t v_dst = __riscv_vle64_v_i64m1(&dst[i], vl);\n        vuint8mf8_t v_mask = __riscv_vlm_v_u8mf8((const uint8_t *)&mask[i], vl);\n        v_mask = __riscv_vreinterpret_v_u8mf8_u64m1(v_mask);\n        v_dst = __riscv_vmerge_vxm_i64m1(v_dst, v_src, v_mask, 0, vl);\n        __riscv_vse64_v_i64m1(&dst[i], v_dst, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_1_RVV", "completion": "```c\nvoid load_modify_store_simd(const int *src, int *dst, int scale, size_t length) {\n    size_t vl = vsetvl_e32m1(length);\n    vint32m1_t v_src = vle32_v_i32m1(src, vl);\n    vint32m1_t v_scale = vmv_v_x_i32m1(scale, vl);\n\n    vint32m1_t v_tmp1 = vsra_vv_i32m1(vmul_vv_i32m1(v_src, v_scale, vl), 3, vl);\n    vint32m1_t v_tmp2 = vsll_vv_i32m1(vmul_vv_i32m1(v_src, v_scale, vl), 3, vl);\n\n    vint32m1_t v_result = vdiv_vv_i32m1(vadd_vv_i32m1(vmul_vv_i32m1(v_src, v_scale, vl), vmul_vv_i32m1(v_tmp1, v_tmp2, vl), vl), 7, vl);\n\n    vse32_v_i32m1(dst, v_result, vl);\n}\n```"}
{"task_id": "SimdBench_1_RVV", "completion": "```c\nvoid load_modify_store_simd(const int *src, int *dst, int scale, size_t length) {\n    size_t vl = vsetvl_e32m1(length);\n    vint32m1_t v_src = vle32_v_i32m1(src, vl);\n    vint32m1_t v_scale = vmv_v_x_i32m1(scale, vl);\n\n    vint32m1_t v_tmp1 = vsra_vv_i32m1(vmul_vv_i32m1(v_src, v_scale, vl), 3, vl);\n    vint32m1_t v_tmp2 = vsll_vv_i32m1(vmul_vv_i32m1(v_src, v_scale, vl), 3, vl);\n\n    vint32m1_t v_result = vdiv_vv_i32m1(vadd_vv_i32m1(vmul_vv_i32m1(v_src, v_scale, vl), vmul_vv_i32m1(v_tmp1, v_tmp2, vl), vl), 7, vl);\n\n    vse32_v_i32m1(dst, v_result, vl);\n}\n```"}
{"task_id": "SimdBench_1_RVV", "completion": "```c\nvoid load_modify_store_simd(const int *src, int *dst, int scale, size_t length) {\n    size_t vl = vsetvl_e32m1(length);\n    vint32m1_t v_src = vle32_v_i32m1(src, vl);\n    vint32m1_t v_scale = vmv_v_x_i32m1(scale, vl);\n\n    vint32m1_t v_tmp1 = vsra_vv_i32m1(vmul_vv_i32m1(v_src, v_scale, vl), 3, vl);\n    vint32m1_t v_tmp2 = vsll_vv_i32m1(vmul_vv_i32m1(v_src, v_scale, vl), 3, vl);\n\n    vint32m1_t v_result = vdiv_vv_i32m1(vadd_vv_i32m1(vmul_vv_i32m1(v_src, v_scale, vl), vmul_vv_i32m1(v_tmp1, v_tmp2, vl), vl), 7, vl);\n\n    vse32_v_i32m1(dst, v_result, vl);\n}\n```"}
{"task_id": "SimdBench_1_RVV", "completion": "```c\nvoid load_modify_store_simd(const int *src, int *dst, int scale, size_t length) {\n    size_t vl = vsetvl_e32m1(length);\n    vint32m1_t v_src = vle32_v_i32m1(src, vl);\n    vint32m1_t v_scale = vmv_v_x_i32m1(scale, vl);\n\n    vint32m1_t v_tmp1 = vsra_vv_i32m1(vmul_vv_i32m1(v_src, v_scale, vl), 3, vl);\n    vint32m1_t v_tmp2 = vsll_vv_i32m1(vmul_vv_i32m1(v_src, v_scale, vl), 3, vl);\n\n    vint32m1_t v_result = vdiv_vv_i32m1(vadd_vv_i32m1(vmul_vv_i32m1(v_src, v_scale, vl), vmul_vv_i32m1(v_tmp1, v_tmp2, vl), vl), 7, vl);\n\n    vse32_v_i32m1(dst, v_result, vl);\n}\n```"}
{"task_id": "SimdBench_1_RVV", "completion": "```c\nvoid load_modify_store_simd(const int *src, int *dst, int scale, size_t length) {\n    size_t vl = vsetvl_e32m1(length);\n    vint32m1_t v_src = vle32_v_i32m1(src, vl);\n    vint32m1_t v_scale = vmv_v_x_i32m1(scale, vl);\n\n    vint32m1_t v_tmp1 = vsra_vv_i32m1(vmul_vv_i32m1(v_src, v_scale, vl), 3, vl);\n    vint32m1_t v_tmp2 = vsll_vv_i32m1(vmul_vv_i32m1(v_src, v_scale, vl), 3, vl);\n\n    vint32m1_t v_result = vdiv_vv_i32m1(vadd_vv_i32m1(vmul_vv_i32m1(v_src, v_scale, vl), vmul_vv_i32m1(v_tmp1, v_tmp2, vl), vl), 7, vl);\n\n    vse32_v_i32m1(dst, v_result, vl);\n}\n```"}
{"task_id": "SimdBench_2_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid strided_load_store_simd(const double *src, double *dst, size_t rows, size_t cols, size_t stride) {\n    size_t vl = __riscv_vsetvl_e64m1(rows);\n    for (size_t r = 0; r < rows; r += vl) {\n        vl = __riscv_vsetvl_e64m1(rows - r);\n        vuint64m1_t indices = __riscv_vid_v_u64m1(vl);\n        indices = __riscv_vmul_vx_u64m1(indices, cols, vl);\n        indices = __riscv_vadd_vx_u64m1(indices, stride, vl);\n        vfloat64m1_t src_vals = __riscv_vlse64_v_f64m1(src, indices, vl);\n        __riscv_vsse64_v_f64m1(dst, __riscv_vid_v_u64m1(vl), src_vals, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_2_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid strided_load_store_simd(const double *src, double *dst, size_t rows, size_t cols, size_t stride) {\n    size_t vl = __riscv_vsetvl_e64m1(rows);\n    for (size_t r = 0; r < rows; r += vl) {\n        vl = __riscv_vsetvl_e64m1(rows - r);\n        vuint64m1_t indices = __riscv_vid_v_u64m1(vl);\n        indices = __riscv_vmul_vx_u64m1(indices, cols, vl);\n        indices = __riscv_vadd_vx_u64m1(indices, stride, vl);\n        vfloat64m1_t src_vec = __riscv_vlse64_v_f64m1(src, indices, vl);\n        __riscv_vse64_v_f64m1(dst + r, src_vec, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_2_RVV", "completion": "```c\nvoid strided_load_store_simd(const double *src, double *dst, size_t rows, size_t cols, size_t stride) {\n    size_t vl = __riscv_vsetvl_e64m1(1);\n    for (size_t r = 0; r < rows; r++) {\n        size_t index = r * cols + stride;\n        vfloat64m1_t v_src = __riscv_vle64_v_f64m1(&src[index], vl);\n        __riscv_vse64_v_f64m1(&dst[r], v_src, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_2_RVV", "completion": "```c\nvoid strided_load_store_simd(const double *src, double *dst, size_t rows, size_t cols, size_t stride) {\n    size_t vl = __riscv_vsetvl_e64m1(rows);\n    for (size_t r = 0; r < rows; r += vl) {\n        vl = __riscv_vsetvl_e64m1(rows - r);\n        vuint64m1_t indices = __riscv_vid_v_u64m1(vl);\n        indices = __riscv_vmul_vx_u64m1(indices, cols, vl);\n        indices = __riscv_vadd_vx_u64m1(indices, stride, vl);\n        vfloat64m1_t src_vals = __riscv_vlrx_v_f64m1(src, indices, vl);\n        __riscv_vsx_v_f64m1(dst, src_vals, r, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_2_RVV", "completion": "```c\nvoid strided_load_store_simd(const double *src, double *dst, size_t rows, size_t cols, size_t stride) {\n    size_t vl = __riscv_vsetvl_e64m1(1);\n    for (size_t r = 0; r < rows; ++r) {\n        size_t index = r * cols + stride;\n        vfloat64m1_t v = __riscv_vle64_v_f64m1(&src[index], vl);\n        __riscv_vse64_v_f64m1(&dst[r], v, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_3_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid indexed_access_simd(const float *src, const int *indices, float *dst, size_t length) {\n    size_t vl = vsetvl_e32m1(length);\n    vfloat32m1_t vsrc = vle32_v_f32m1(src, vl);\n    vint32m1_t vindices = vle32_v_i32m1(indices, vl);\n\n    vfloat32m1_t vdst = vle32_v_f32m1(dst, vl);\n\n    vdst = vrgatherei32_v_f32m1(vdst, vindices, vsrc, vl);\n    vse32_v_f32m1(dst, vdst, vl);\n\n    vdst = vscatterei32_v_f32m1(vdst, vindices, vsrc, vl);\n    vse32_v_f32m1(dst, vdst, vl);\n}\n```"}
{"task_id": "SimdBench_3_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n\nvoid indexed_access_simd(const float *src, const int *indices, float *dst, size_t length) {\n    size_t vl = vsetvl_e32m8(length);\n    vfloat32m8_t vsrc = vle32_v_f32m8(src, vl);\n    vint32m8_t vindices = vle32_v_i32m8(indices, vl);\n\n    vfloat32m8_t vdst_gather = vrgatherei32_v_f32m8(vindices, vsrc, vl);\n    vse32_v_f32m8(dst, vdst_gather, vl);\n\n    vfloat32m8_t vdst_scatter = vle32_v_f32m8(src, vl);\n    vscatter_v_f32m8(vdst_scatter, vindices, vl);\n}\n```"}
{"task_id": "SimdBench_3_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid indexed_access_simd(const float *src, const int *indices, float *dst, size_t length) {\n    size_t vl = vsetvl_e32m1(length);\n    vfloat32m1_t v_src = vle32_v_f32m1(src, vl);\n    vint32m1_t v_indices = vle32_v_i32m1(indices, vl);\n\n    vfloat32m1_t v_dst_gather = vloxei32_v_f32m1(v_src, v_indices, vl);\n    vse32_v_f32m1(dst, v_dst_gather, vl);\n\n    vsoxei32_v_f32m1(v_dst_gather, dst, v_indices, vl);\n}\n```"}
{"task_id": "SimdBench_3_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid indexed_access_simd(const float *src, const int *indices, float *dst, size_t length) {\n    size_t vl = vsetvl_e32m1(length);\n    vfloat32m1_t v_src = vle32_v_f32m1(src, vl);\n    vint32m1_t v_indices = vle32_v_i32m1(indices, vl);\n\n    vfloat32m1_t v_dst_gather = vloxei32_v_f32m1(v_src, v_indices, vl);\n    vse32_v_f32m1(dst, v_dst_gather, vl);\n\n    vsoxei32_v_f32m1(v_dst_gather, dst, v_indices, vl);\n}\n```"}
{"task_id": "SimdBench_3_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid indexed_access_simd(const float *src, const int *indices, float *dst, size_t length) {\n    size_t vl = vsetvl_e32m8(length);\n    vfloat32m8_t vsrc = vle32_v_f32m8(src, vl);\n    vint32m8_t vindices = vle32_v_i32m8(indices, vl);\n\n    vfloat32m8_t vdst = vrgatherei32_v_f32m8(vindices, vsrc, vl);\n    vse32_v_f32m8(dst, vdst, vl);\n\n    vfloat32m8_t vdst2 = vle32_v_f32m8(src, vl);\n    vscatterei32_v_f32m8(vdst2, vindices, dst, vl);\n}\n```"}
{"task_id": "SimdBench_4_RVV", "completion": "```c\nvoid range_reverse_simd(int16_t *arr, uint64_t start, uint64_t end) {\n    size_t vl = __riscv_vsetvl_e16m1(1);\n    uint64_t mid = (start + end) / 2;\n\n    for (uint64_t i = start; i <= mid; ++i) {\n        uint64_t j = start + end - i;\n        vint16m1_t va = __riscv_vle16_v_i16m1(&arr[i], vl);\n        vint16m1_t vb = __riscv_vle16_v_i16m1(&arr[j], vl);\n        __riscv_vse16_v_i16m1(&arr[i], vb, vl);\n        __riscv_vse16_v_i16m1(&arr[j], va, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_4_RVV", "completion": "```c\nvoid range_reverse_simd(int16_t *arr, uint64_t start, uint64_t end) {\n    size_t vl = __riscv_vsetvl_e16m1(1);\n    uint64_t i = start;\n    uint64_t j = end;\n\n    while (i < j) {\n        vl = __riscv_vsetvl_e16m1(j - i + 1);\n\n        vint16m1_t v_a = __riscv_vle16_v_i16m1(&arr[i], vl);\n        vint16m1_t v_b = __riscv_vle16_v_i16m1(&arr[j], vl);\n\n        __riscv_vse16_v_i16m1(&arr[i], v_b, vl);\n        __riscv_vse16_v_i16m1(&arr[j], v_a, vl);\n\n        i += vl;\n        j -= vl;\n    }\n}\n```"}
{"task_id": "SimdBench_4_RVV", "completion": "```c\nvoid range_reverse_simd(int16_t *arr, uint64_t start, uint64_t end) {\n    size_t vl = vsetvlmax_e16m1();\n    size_t n = end - start + 1;\n    int16_t *left = arr + start;\n    int16_t *right = arr + end;\n\n    while (left < right) {\n        size_t vl = vsetvl_e16m1(n);\n        vint16m1_t v_left = vle16_v_i16m1(left, vl);\n        vint16m1_t v_right = vle16_v_i16m1(right, vl);\n\n        vse16_v_i16m1(left, v_right, vl);\n        vse16_v_i16m1(right, v_left, vl);\n\n        left += vl;\n        right -= vl;\n        n -= 2 * vl;\n    }\n}\n```"}
{"task_id": "SimdBench_4_RVV", "completion": "```c\nvoid range_reverse_simd(int16_t *arr, uint64_t start, uint64_t end) {\n    size_t vl = vsetvlmax_e16m1();\n    int16_t *left = arr + start;\n    int16_t *right = arr + end;\n\n    while (left < right) {\n        size_t vl = vsetvl_e16m1(right - left);\n        vint16m1_t v_left = vle16_v_i16m1(left, vl);\n        vint16m1_t v_right = vle16_v_i16m1(right - vl + 1, vl);\n\n        vse16_v_i16m1(left, v_right, vl);\n        vse16_v_i16m1(right - vl + 1, v_left, vl);\n\n        left += vl;\n        right -= vl;\n    }\n}\n```"}
{"task_id": "SimdBench_4_RVV", "completion": "```c\nvoid range_reverse_simd(int16_t *arr, uint64_t start, uint64_t end) {\n    size_t vl = vsetvlmax_e16m1();\n    size_t n = end - start + 1;\n    int16_t *left = arr + start;\n    int16_t *right = arr + end;\n\n    while (left < right) {\n        size_t vl = vsetvl_e16m1(n);\n        vint16m1_t v_left = vle16_v_i16m1(left, vl);\n        vint16m1_t v_right = vle16_v_i16m1(right, vl);\n\n        vse16_v_i16m1(left, v_right, vl);\n        vse16_v_i16m1(right, v_left, vl);\n\n        left += vl;\n        right -= vl;\n        n -= 2 * vl;\n    }\n}\n```"}
{"task_id": "SimdBench_5_RVV", "completion": "```c\nvoid extract_tensor_slice_simd(const uint8_t *tensor, uint8_t *slice, size_t dim1, size_t dim2, size_t dim3, size_t slice_idx) {\n    size_t slice_size = dim1 * dim2;\n    size_t offset = slice_idx * slice_size;\n    const uint8_t *src = tensor + offset;\n    uint8_t *dst = slice;\n\n    size_t vl = __riscv_vsetvl_e8m1(slice_size);\n    for (size_t i = 0; i < slice_size; i += vl) {\n        vuint8m1_t v = __riscv_vle8_v_u8m1(src + i, vl);\n        __riscv_vse8_v_u8m1(dst + i, v, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_5_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid extract_tensor_slice_simd(const uint8_t *tensor, uint8_t *slice, size_t dim1, size_t dim2, size_t dim3, size_t slice_idx) {\n    size_t slice_size = dim1 * dim2;\n    size_t offset = slice_idx * slice_size;\n    const uint8_t *src = tensor + offset;\n    uint8_t *dst = slice;\n\n    size_t vl = __riscv_vsetvl_e8m1(slice_size);\n    for (size_t i = 0; i < slice_size; i += vl) {\n        vuint8m1_t v = __riscv_vle8_v_u8m1(src + i, vl);\n        __riscv_vse8_v_u8m1(dst + i, v, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_5_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid extract_tensor_slice_simd(const uint8_t *tensor, uint8_t *slice, size_t dim1, size_t dim2, size_t dim3, size_t slice_idx) {\n    size_t slice_size = dim1 * dim2;\n    size_t offset = slice_idx * slice_size;\n    const uint8_t *src = tensor + offset;\n    uint8_t *dst = slice;\n\n    size_t vl = __riscv_vsetvl_e8m1(slice_size);\n    for (size_t i = 0; i < slice_size; i += vl) {\n        vl = __riscv_vsetvl_e8m1(slice_size - i);\n        vuint8m1_t v = __riscv_vle8_v_u8m1(src + i, vl);\n        __riscv_vse8_v_u8m1(dst + i, v, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_5_RVV", "completion": "```c\nvoid extract_tensor_slice_simd(const uint8_t *tensor, uint8_t *slice, size_t dim1, size_t dim2, size_t dim3, size_t slice_idx) {\n    size_t slice_size = dim1 * dim2;\n    const uint8_t *src = tensor + slice_idx * slice_size;\n    size_t vlmax = __riscv_vsetvlmax_e8m1();\n    size_t vl = vlmax;\n\n    for (size_t i = 0; i < slice_size; i += vl) {\n        vl = __riscv_vsetvl_e8m1(slice_size - i);\n        vuint8m1_t v_src = __riscv_vle8_v_u8m1(src + i, vl);\n        __riscv_vse8_v_u8m1(slice + i, v_src, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_5_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid extract_tensor_slice_simd(const uint8_t *tensor, uint8_t *slice, size_t dim1, size_t dim2, size_t dim3, size_t slice_idx) {\n    size_t slice_size = dim1 * dim2;\n    size_t offset = slice_idx * slice_size;\n    const uint8_t *src = tensor + offset;\n\n    for (size_t i = 0; i < slice_size; i += vsetvl_e8m1(slice_size - i)) {\n        vuint8m1_t v = vle8_v_u8m1(src + i, vsetvl_e8m1(slice_size - i));\n        vse8_v_u8m1(slice + i, v, vsetvl_e8m1(slice_size - i));\n    }\n}\n```"}
{"task_id": "SimdBench_6_RVV", "completion": "```c\nvoid blocked_matrix_transpose_simd(const int16_t *src, int16_t *dst, size_t rows, size_t cols, size_t block_size) {\n    size_t i, j, k, l;\n    size_t vlmax = __riscv_vsetvlmax_e16m1();\n\n    for (i = 0; i < rows; i += block_size) {\n        for (j = 0; j < cols; j += block_size) {\n            for (k = i; k < i + block_size && k < rows; ++k) {\n                size_t vl = __riscv_vsetvl_e16m1(block_size);\n                vint16m1_t v_src = __riscv_vle16_v_i16m1(&src[k * cols + j], vl);\n                for (l = 0; l < block_size && j + l < cols; ++l) {\n                    vint16m1_t v_dst = __riscv_vle16_v_i16m1(&dst[(j + l) * rows + i], vl);\n                    v_dst = __riscv_vslideup_vx_i16m1(v_dst, v_src, l, vl);\n                    __riscv_vse16_v_i16m1(&dst[(j + l) * rows + i], v_dst, vl);\n                }\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_6_RVV", "completion": "```c\nvoid blocked_matrix_transpose_simd(const int16_t *src, int16_t *dst, size_t rows, size_t cols, size_t block_size) {\n    size_t i, j, k, l;\n    size_t vl = __riscv_vsetvl_e16m1(block_size);\n\n    for (i = 0; i < rows; i += block_size) {\n        for (j = 0; j < cols; j += block_size) {\n            for (k = i; k < i + block_size && k < rows; ++k) {\n                for (l = j; l < j + block_size && l < cols; ++l) {\n                    size_t src_index = k * cols + l;\n                    size_t dst_index = l * rows + k;\n                    vint16m1_t v_src = __riscv_vle16_v_i16m1(&src[src_index], vl);\n                    __riscv_vse16_v_i16m1(&dst[dst_index], v_src, vl);\n                }\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_6_RVV", "completion": "```c\nvoid blocked_matrix_transpose_simd(const int16_t *src, int16_t *dst, size_t rows, size_t cols, size_t block_size) {\n    size_t i, j, k, l;\n    size_t vlmax = __riscv_vsetvlmax_e16m1();\n    vint16m1_t v_src, v_dst;\n\n    for (i = 0; i < rows; i += block_size) {\n        for (j = 0; j < cols; j += block_size) {\n            for (k = i; k < i + block_size && k < rows; ++k) {\n                for (l = j; l < j + block_size && l < cols; ++l) {\n                    size_t vl = __riscv_vsetvl_e16m1(block_size);\n                    v_src = __riscv_vle16_v_i16m1(&src[k * cols + l], vl);\n                    __riscv_vse16_v_i16m1(&dst[l * rows + k], v_src, vl);\n                }\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_6_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid blocked_matrix_transpose_simd(const int16_t *src, int16_t *dst, size_t rows, size_t cols, size_t block_size) {\n    size_t i, j, ii, jj;\n    vint16m1_t v_src, v_dst;\n    size_t vl = __riscv_vsetvl_e16m1(block_size);\n\n    for (i = 0; i < rows; i += block_size) {\n        for (j = 0; j < cols; j += block_size) {\n            for (ii = i; ii < i + block_size && ii < rows; ++ii) {\n                for (jj = j; jj < j + block_size && jj < cols; ++jj) {\n                    v_src = __riscv_vle16_v_i16m1(&src[ii * cols + jj], vl);\n                    v_dst = __riscv_vle16_v_i16m1(&dst[jj * rows + ii], vl);\n                    __riscv_vse16_v_i16m1(&dst[jj * rows + ii], v_src, vl);\n                    __riscv_vse16_v_i16m1(&dst[ii * rows + jj], v_dst, vl);\n                }\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_6_RVV", "completion": "```c\nvoid blocked_matrix_transpose_simd(const int16_t *src, int16_t *dst, size_t rows, size_t cols, size_t block_size) {\n    size_t i, j, k, l;\n    size_t vlmax = __riscv_vsetvlmax_e16m1();\n\n    for (i = 0; i < rows; i += block_size) {\n        for (j = 0; j < cols; j += block_size) {\n            for (k = i; k < i + block_size && k < rows; ++k) {\n                for (l = j; l < j + block_size && l < cols; ++l) {\n                    size_t vl = __riscv_vsetvl_e16m1(block_size);\n                    vint16m1_t v_src = __riscv_vle16_v_i16m1(&src[k * cols + l], vl);\n                    __riscv_vse16_v_i16m1(&dst[l * rows + k], v_src, vl);\n                }\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_7_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nfloat diagonal_sum_3d_simd(const float *array, size_t dim) {\n    size_t stride = dim * dim;\n    size_t vlen = __riscv_vsetvl_e32m1(dim);\n    vfloat32m1_t vsum = __riscv_vfmv_v_f_f32m1(0.0f, vlen);\n    vfloat32m1_t vdiag;\n\n    for (size_t i = 0; i < dim; ++i) {\n        vdiag = __riscv_vle32_v_f32m1(&array[i * stride + i * dim + i], vlen);\n        vsum = __riscv_vfadd_vv_f32m1(vsum, vdiag, vlen);\n    }\n\n    float sum = 0.0f;\n    for (size_t i = 0; i < vlen; ++i) {\n        sum += __riscv_vfmv_f_s_f32m1_f32(vsum, i);\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_7_RVV", "completion": "```c\nfloat diagonal_sum_3d_simd(const float *array, size_t dim) {\n    size_t stride = dim * dim;\n    float sum = 0.0f;\n\n    for (size_t i = 0; i < dim; ++i) {\n        size_t index = i * (stride + dim + 1);\n        sum += array[index];\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_7_RVV", "completion": "```c\nfloat diagonal_sum_3d_simd(const float *array, size_t dim) {\n    size_t stride = dim * dim;\n    size_t num_elements = dim;\n    float sum = 0.0f;\n\n    for (size_t i = 0; i < num_elements; i += vsetvl_e32m1(num_elements - i)) {\n        size_t vl = vsetvl_e32m1(num_elements - i);\n        vfloat32m1_t v_diag = vle32_v_f32m1(&array[i * (stride + dim + 1)], vl);\n        sum += vreduce_sum_vs_f32m1_f32m1(v_diag, sum, vl);\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_7_RVV", "completion": "```cpp\nfloat diagonal_sum_3d_simd(const float *array, size_t dim) {\n    size_t stride = dim * dim;\n    size_t vlen = __riscv_vsetvl_e32m1(dim);\n    vfloat32m1_t vsum = __riscv_vfmv_v_f_f32m1(0.0f, vlen);\n    for (size_t i = 0; i < dim; ++i) {\n        vfloat32m1_t vdiag = __riscv_vle32_v_f32m1(&array[i * stride + i * dim + i], vlen);\n        vsum = __riscv_vfadd_vv_f32m1(vsum, vdiag, vlen);\n    }\n    float sum = 0.0f;\n    for (size_t i = 0; i < vlen; ++i) {\n        sum += __riscv_vfmv_f_s_f32m1_f32(vsum, i);\n    }\n    return sum;\n}\n```"}
{"task_id": "SimdBench_7_RVV", "completion": "```c\nfloat diagonal_sum_3d_simd(const float *array, size_t dim) {\n    size_t stride = dim * dim;\n    size_t num_elements = dim;\n    float sum = 0.0f;\n\n    for (size_t i = 0; i < num_elements; i += vsetvl_e32m1(num_elements - i)) {\n        size_t vl = vsetvl_e32m1(num_elements - i);\n        vfloat32m1_t v_diag = vle32_v_f32m1(&array[i * (stride + dim + 1)], vl);\n        sum += vreduce_sum_vs_f32m1_f32m1(v_diag, sum, vl);\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_8_RVV", "completion": "```c\nvoid conditional_scale_simd(const double *src, double *dst, size_t rows, size_t cols, double threshold, double scale) {\n    size_t vl = vsetvl_e64m1(cols);\n    for (size_t i = 0; i < rows; ++i) {\n        const double *src_row = src + i * cols;\n        double *dst_row = dst + i * cols;\n        for (size_t j = 0; j < cols; j += vl) {\n            vl = vsetvl_e64m1(cols - j);\n            vfloat64m1_t v_src = vle64_v_f64m1(src_row + j, vl);\n            vbool64_t mask = vmfgt_vf_f64m1_b64(v_src, threshold, vl);\n            vfloat64m1_t v_scaled = vfmul_vf_f64m1(v_src, scale, vl);\n            vfloat64m1_t v_result = vmerge_vvm_f64m1(v_src, v_scaled, mask, vl);\n            vse64_v_f64m1(dst_row + j, v_result, vl);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_8_RVV", "completion": "```c\nvoid conditional_scale_simd(const double *src, double *dst, size_t rows, size_t cols, double threshold, double scale) {\n    size_t total_elements = rows * cols;\n    size_t i = 0;\n\n    vfloat64m1_t v_threshold = vfmv_v_f_f64m1(threshold, 1);\n    vfloat64m1_t v_scale = vfmv_v_f_f64m1(scale, 1);\n\n    for (; i <= total_elements - 8; i += 8) {\n        vfloat64m1_t v_src = vle64_v_f64m1(&src[i], 8);\n        vuint64m1_t v_mask = vmflt_vv_f64m1_b64(v_src, v_threshold, 8);\n        vfloat64m1_t v_scaled = vfmul_vv_f64m1(v_src, v_scale, 8);\n        vfloat64m1_t v_dst = vmerge_vvm_f64m1(v_src, v_scaled, v_mask, 8);\n        vse64_v_f64m1(&dst[i], v_dst, 8);\n    }\n\n    for (; i < total_elements; ++i) {\n        dst[i] = (src[i] > threshold) ? src[i] * scale : src[i];\n    }\n}\n```"}
{"task_id": "SimdBench_8_RVV", "completion": "```c\nvoid conditional_scale_simd(const double *src, double *dst, size_t rows, size_t cols, double threshold, double scale) {\n    size_t total_elements = rows * cols;\n    size_t i = 0;\n\n    vfloat64m1_t v_threshold = __riscv_vfmv_v_f_f64m1(threshold, total_elements);\n    vfloat64m1_t v_scale = __riscv_vfmv_v_f_f64m1(scale, total_elements);\n\n    for (; i <= total_elements - 8; i += 8) {\n        vfloat64m1_t v_src = __riscv_vle64_v_f64m1(src + i, 8);\n        vuint64m1_t v_mask = __riscv_vmfgt_vv_f64m1_b64(v_src, v_threshold, 8);\n        vfloat64m1_t v_scaled = __riscv_vfmul_vv_f64m1(v_src, v_scale, 8);\n        vfloat64m1_t v_dst = __riscv_vmerge_vvm_f64m1(v_src, v_scaled, v_mask, 8);\n        __riscv_vse64_v_f64m1(dst + i, v_dst, 8);\n    }\n\n    for (; i < total_elements; ++i) {\n        dst[i] = (src[i] > threshold) ? src[i] * scale : src[i];\n    }\n}\n```"}
{"task_id": "SimdBench_8_RVV", "completion": "```c\nvoid conditional_scale_simd(const double *src, double *dst, size_t rows, size_t cols, double threshold, double scale) {\n    size_t vlmax = __riscv_vsetvlmax_e64m1();\n    for (size_t i = 0; i < rows; ++i) {\n        for (size_t j = 0; j < cols; j += vlmax) {\n            size_t vl = __riscv_vsetvl_e64m1(cols - j);\n            vfloat64m1_t v_src = __riscv_vle64_v_f64m1(&src[i * cols + j], vl);\n            vfloat64m1_t v_threshold = __riscv_vfmv_v_f_f64m1(threshold, vl);\n            vfloat64m1_t v_scale = __riscv_vfmv_v_f_f64m1(scale, vl);\n            vbool64_t mask = __riscv_vmfgt_vv_f64m1_b64(v_src, v_threshold, vl);\n            vfloat64m1_t v_dst = __riscv_vmerge_vvm_f64m1(v_src, __riscv_vfmul_vv_f64m1(v_src, v_scale, vl), mask, vl);\n            __riscv_vse64_v_f64m1(&dst[i * cols + j], v_dst, vl);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_8_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid conditional_scale_simd(const double *src, double *dst, size_t rows, size_t cols, double threshold, double scale) {\n    size_t total_elements = rows * cols;\n    size_t vlmax = __riscv_vsetvlmax_e64m1();\n    size_t vl;\n\n    for (size_t i = 0; i < total_elements; i += vl) {\n        vl = __riscv_vsetvl_e64m1(total_elements - i);\n        vfloat64m1_t v_src = __riscv_vle64_v_f64m1(&src[i], vl);\n        vfloat64m1_t v_threshold = __riscv_vfmv_v_f_f64m1(threshold, vl);\n        vfloat64m1_t v_scale = __riscv_vfmv_v_f_f64m1(scale, vl);\n\n        vbool64_t mask = __riscv_vmfgt_vv_f64m1_b64(v_src, v_threshold, vl);\n        vfloat64m1_t v_dst = __riscv_vmerge_vvm_f64m1(v_src, __riscv_vfmul_vv_f64m1(v_src, v_scale, vl), mask, vl);\n\n        __riscv_vse64_v_f64m1(&dst[i], v_dst, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_9_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n\nvoid reorder_matrix_rows_simd(const double *src, double *dst, size_t rows, size_t cols, const size_t *indices) {\n    size_t vl = vsetvl_e64m8(cols);\n    for (size_t i = 0; i < rows; ++i) {\n        size_t idx = indices[i];\n        vfloat64m8_t v_src = vle64_v_f64m8(&src[idx * cols], vl);\n        vse64_v_f64m8(&dst[i * cols], v_src, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_9_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid reorder_matrix_rows_simd(const double *src, double *dst, size_t rows, size_t cols, const size_t *indices) {\n    size_t vl = vsetvl_e64m8(cols);\n    for (size_t i = 0; i < rows; ++i) {\n        size_t idx = indices[i];\n        vfloat64m8_t v_src = vle64_v_f64m8(&src[idx * cols], vl);\n        vse64_v_f64m8(&dst[i * cols], v_src, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_9_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n\nvoid reorder_matrix_rows_simd(const double *src, double *dst, size_t rows, size_t cols, const size_t *indices) {\n    size_t vl = vsetvl_e64m8(cols);\n    for (size_t i = 0; i < rows; ++i) {\n        size_t idx = indices[i];\n        vfloat64m8_t src_vec = vle64_v_f64m8(&src[idx * cols], vl);\n        vse64_v_f64m8(&dst[i * cols], src_vec, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_9_RVV", "completion": "```c\nvoid reorder_matrix_rows_simd(const double *src, double *dst, size_t rows, size_t cols, const size_t *indices) {\n    size_t vl = __riscv_vsetvl_e64m1(cols);\n    for (size_t i = 0; i < rows; ++i) {\n        size_t idx = indices[i];\n        vfloat64m1_t src_vec = __riscv_vle64_v_f64m1(&src[idx * cols], vl);\n        __riscv_vse64_v_f64m1(&dst[i * cols], src_vec, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_9_RVV", "completion": "```c\nvoid reorder_matrix_rows_simd(const double *src, double *dst, size_t rows, size_t cols, const size_t *indices) {\n    size_t vl = __riscv_vsetvl_e64m1(cols);\n    for (size_t i = 0; i < rows; ++i) {\n        size_t idx = indices[i];\n        vfloat64m1_t src_vec = __riscv_vle64_v_f64m1(&src[idx * cols], vl);\n        __riscv_vse64_v_f64m1(&dst[i * cols], src_vec, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_10_RVV", "completion": "```c\nvoid vector_vector_add_simd(const int64_t *src1, const int64_t *src2, int64_t *dst, int64_t scalar, size_t length) {\n    size_t vl = __riscv_vsetvl_e64m1(length);\n    vint64m1_t v_src1 = __riscv_vle64_v_i64m1(src1, vl);\n    vint64m1_t v_src2 = __riscv_vle64_v_i64m1(src2, vl);\n    vint64m1_t v_scalar = __riscv_vmv_v_x_i64m1(scalar, vl);\n    vint64m1_t v_result = __riscv_vadd_vv_i64m1(v_src1, v_src2, vl);\n    v_result = __riscv_vadd_vv_i64m1(v_result, v_scalar, vl);\n    v_result = __riscv_vsra_vx_i64m1(v_result, 1, vl);\n    __riscv_vse64_v_i64m1(dst, v_result, vl);\n}\n```"}
{"task_id": "SimdBench_10_RVV", "completion": "```c\nvoid vector_vector_add_simd(const int64_t *src1, const int64_t *src2, int64_t *dst, int64_t scalar, size_t length) {\n    size_t vl = vsetvl_e64m8(length);\n    vint64m8_t v_src1, v_src2, v_dst, v_scalar, v_result;\n\n    for (size_t i = 0; i < length; i += vl) {\n        vl = vsetvl_e64m8(length - i);\n        v_src1 = vle64_v_i64m8(&src1[i], vl);\n        v_src2 = vle64_v_i64m8(&src2[i], vl);\n        v_scalar = vmv_v_x_i64m8(scalar, vl);\n\n        v_result = vadd_vv_i64m8(v_src1, v_src2, vl);\n        v_result = vadd_vv_i64m8(v_result, v_scalar, vl);\n        v_result = vsra_vx_i64m8(v_result, 1, vl);\n\n        vse64_v_i64m8(&dst[i], v_result, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_10_RVV", "completion": "```c\nvoid vector_vector_add_simd(const int64_t *src1, const int64_t *src2, int64_t *dst, int64_t scalar, size_t length) {\n    size_t vl = __riscv_vsetvl_e64m1(length);\n    vint64m1_t v_src1 = __riscv_vle64_v_i64m1(src1, vl);\n    vint64m1_t v_src2 = __riscv_vle64_v_i64m1(src2, vl);\n    vint64m1_t v_scalar = __riscv_vmv_v_x_i64m1(scalar, vl);\n    vint64m1_t v_result = __riscv_vadd_vv_i64m1(v_src1, v_src2, vl);\n    v_result = __riscv_vadd_vv_i64m1(v_result, v_scalar, vl);\n    v_result = __riscv_vsra_vx_i64m1(v_result, 1, vl);\n    __riscv_vse64_v_i64m1(dst, v_result, vl);\n}\n```"}
{"task_id": "SimdBench_10_RVV", "completion": "```cpp\nvoid vector_vector_add_simd(const int64_t *src1, const int64_t *src2, int64_t *dst, int64_t scalar, size_t length) {\n    size_t vl = vsetvl_e64m1(length);\n    for (size_t i = 0; i < length; i += vl) {\n        vl = vsetvl_e64m1(length - i);\n        vint64m1_t v_src1 = vle64_v_i64m1(&src1[i], vl);\n        vint64m1_t v_src2 = vle64_v_i64m1(&src2[i], vl);\n        vint64m1_t v_sum = vadd_vv_i64m1(v_src1, v_src2, vl);\n        vint64m1_t v_scalar = vmv_v_x_i64m1(scalar, vl);\n        vint64m1_t v_result = vadd_vv_i64m1(v_sum, v_scalar, vl);\n        vint64m1_t v_final = vsra_vx_i64m1(v_result, 1, vl);\n        vse64_v_i64m1(&dst[i], v_final, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_10_RVV", "completion": "```c\nvoid vector_vector_add_simd(const int64_t *src1, const int64_t *src2, int64_t *dst, int64_t scalar, size_t length) {\n    size_t vl = __riscv_vsetvl_e64m1(length);\n    vint64m1_t v_src1 = __riscv_vle64_v_i64m1(src1, vl);\n    vint64m1_t v_src2 = __riscv_vle64_v_i64m1(src2, vl);\n    vint64m1_t v_scalar = __riscv_vmv_v_x_i64m1(scalar, vl);\n    vint64m1_t v_result = __riscv_vadd_vv_i64m1(v_src1, v_src2, vl);\n    v_result = __riscv_vadd_vv_i64m1(v_result, v_scalar, vl);\n    v_result = __riscv_vsra_vx_i64m1(v_result, 1, vl);\n    __riscv_vse64_v_i64m1(dst, v_result, vl);\n}\n```"}
{"task_id": "SimdBench_11_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nint vector_even_min_simd(const int *src, size_t length) {\n    if (length == 0) {\n        return -1;\n    }\n\n    size_t vl = vsetvl_e32m1(length);\n    vint32m1_t v_src = vle32_v_i32m1(src, vl);\n\n    vint32m1_t v_even_mask = vmseq_vx_i32m1_b32(v_src, 0, vl);\n    vint32m1_t v_even = vmerge_vx_i32m1(v_src, v_even_mask, INT32_MAX, vl);\n\n    int min_val = INT32_MAX;\n    for (size_t i = 0; i < length; i += vl) {\n        vl = vsetvl_e32m1(length - i);\n        v_src = vle32_v_i32m1(src + i, vl);\n        v_even_mask = vmseq_vx_i32m1_b32(v_src, 0, vl);\n        v_even = vmerge_vx_i32m1(v_src, v_even_mask, INT32_MAX, vl);\n\n        vint32m1_t v_min = vreduce_min_vs_i32m1_i32m1(v_even, v_even, vl);\n        int local_min = vmv_x_s_i32m1_i32(v_min);\n        if (local_min < min_val) {\n            min_val = local_min;\n        }\n    }\n\n    return min_val;\n}\n```"}
{"task_id": "SimdBench_11_RVV", "completion": "```c\nint vector_even_min_simd(const int *src, size_t length) {\n    if (length == 0) {\n        return -1;\n    }\n\n    size_t vl = __riscv_vsetvl_e32m1(length);\n    vint32m1_t v_src = __riscv_vle32_v_i32m1(src, vl);\n\n    vint32m1_t v_even_mask = __riscv_vmsge_vx_i32m1_b32(v_src, 0, vl);\n    vint32m1_t v_even_indices = __riscv_vid_v_i32m1(vl);\n    vint32m1_t v_even_masked_indices = __riscv_vand_vv_i32m1(v_even_mask, v_even_indices, vl);\n\n    vint32m1_t v_even_values = __riscv_vrgather_vv_i32m1(v_src, v_even_masked_indices, vl);\n\n    vint32m1_t v_min = __riscv_vmv_v_x_i32m1(INT_MAX, vl);\n    vint32m1_t v_min_reduced = __riscv_vredmin_vs_i32m1_i32m1(v_min, v_even_values, vl);\n\n    int min_value = __riscv_vmv_x_s_i32m1_i32(v_min_reduced);\n\n    return min_value;\n}\n```"}
{"task_id": "SimdBench_11_RVV", "completion": "```c\nint vector_even_min_simd(const int *src, size_t length) {\n    if (length == 0) {\n        return -1;\n    }\n\n    size_t vl = __riscv_vsetvl_e32m1(length);\n    vint32m1_t v_src = __riscv_vle32_v_i32m1(src, vl);\n\n    vint32m1_t v_even_mask = __riscv_vmslt_vx_i32m1_b32(v_src, 0, vl);\n    vint32m1_t v_even = __riscv_vand_vx_i32m1(v_src, 1, vl);\n\n    vint32m1_t v_min = __riscv_vmv_v_x_i32m1(INT32_MAX, vl);\n    for (size_t i = 0; i < length; i += vl) {\n        vl = __riscv_vsetvl_e32m1(length - i);\n        v_src = __riscv_vle32_v_i32m1(src + i, vl);\n        v_even_mask = __riscv_vmslt_vx_i32m1_b32(v_src, 0, vl);\n        v_even = __riscv_vand_vx_i32m1(v_src, 1, vl);\n\n        v_min = __riscv_vmin_vv_i32m1(v_min, v_even, vl);\n    }\n\n    int min_val = __riscv_vmv_x_s_i32m1_i32(v_min);\n    return min_val;\n}\n```"}
{"task_id": "SimdBench_11_RVV", "completion": "```c\nint vector_even_min_simd(const int *src, size_t length) {\n    if (length == 0) {\n        return -1;\n    }\n\n    size_t vl = __riscv_vsetvl_e32m1(length);\n    vint32m1_t v_src = __riscv_vle32_v_i32m1(src, vl);\n\n    vint32m1_t v_even_mask = __riscv_vmslt_vx_i32m1_b32(v_src, 0, vl);\n    vint32m1_t v_even = __riscv_vmerge_vx_i32m1(v_src, v_src, 0, vl);\n\n    vint32m1_t v_min = __riscv_vmv_v_x_i32m1(INT_MAX, vl);\n    for (size_t i = 0; i < length; i += vl) {\n        vl = __riscv_vsetvl_e32m1(length - i);\n        v_src = __riscv_vle32_v_i32m1(src + i, vl);\n        v_even_mask = __riscv_vmslt_vx_i32m1_b32(v_src, 0, vl);\n        v_even = __riscv_vmerge_vx_i32m1(v_src, v_src, 0, vl);\n        v_min = __riscv_vmin_vv_i32m1(v_min, v_even, vl);\n    }\n\n    int min_val = __riscv_vmv_x_s_i32m1_i32(v_min);\n    return min_val;\n}\n```"}
{"task_id": "SimdBench_11_RVV", "completion": "```c\nint vector_even_min_simd(const int *src, size_t length) {\n    if (length == 0) {\n        return -1;\n    }\n\n    size_t vl = __riscv_vsetvl_e32m1(length);\n    vint32m1_t v_src = __riscv_vle32_v_i32m1(src, vl);\n\n    vint32m1_t v_even_mask = __riscv_vid_v_i32m1(vl);\n    v_even_mask = __riscv_vand_vx_i32m1(v_even_mask, 1, vl);\n\n    vint32m1_t v_even_elements = __riscv_vmerge_vvm_i32m1(v_src, v_src, v_even_mask, vl);\n\n    vint32m1_t v_min = __riscv_vmv_v_x_i32m1(INT_MAX, vl);\n    v_min = __riscv_vredmin_vs_i32m1_i32m1(v_min, v_even_elements, vl);\n\n    int min_value = __riscv_vmv_x_s_i32m1_i32(v_min);\n\n    return min_value;\n}\n```"}
{"task_id": "SimdBench_12_RVV", "completion": "```c\nvoid mixed_right_shift_simd(const int *src, int *dst, uint8_t shift, size_t length) {\n    size_t vl = vsetvl_e32m1(length);\n    vint32m1_t v_src = vle32_v_i32m1(src, vl);\n    vint32m1_t v_arith_shift = vsra_vx_i32m1(v_src, shift, vl);\n    vuint32m1_t v_src_uint = vreinterpret_v_i32m1_u32m1(v_src);\n    vuint32m1_t v_logical_shift = vsrl_vx_u32m1(v_src_uint, shift, vl);\n    vint32m1_t v_logical_shift_int = vreinterpret_v_u32m1_i32m1(v_logical_shift);\n    vint32m1_t v_result = vadd_vv_i32m1(v_arith_shift, v_logical_shift_int, vl);\n    vse32_v_i32m1(dst, v_result, vl);\n}\n```"}
{"task_id": "SimdBench_12_RVV", "completion": "```c\nvoid mixed_right_shift_simd(const int *src, int *dst, uint8_t shift, size_t length) {\n    size_t vl = vsetvl_e32m1(length);\n    vint32m1_t v_src = vle32_v_i32m1(src, vl);\n    vint32m1_t v_arith_shift = vsra_vv_i32m1(v_src, vmv_v_x_i32m1(shift, vl), vl);\n    vuint32m1_t v_src_uint = vreinterpret_v_i32m1_u32m1(v_src);\n    vuint32m1_t v_logical_shift = vsrl_vv_u32m1(v_src_uint, vmv_v_x_u32m1(shift, vl), vl);\n    vint32m1_t v_logical_shift_int = vreinterpret_v_u32m1_i32m1(v_logical_shift);\n    vint32m1_t v_result = vadd_vv_i32m1(v_arith_shift, v_logical_shift_int, vl);\n    vse32_v_i32m1(dst, v_result, vl);\n}\n```"}
{"task_id": "SimdBench_12_RVV", "completion": "```c\nvoid mixed_right_shift_simd(const int *src, int *dst, uint8_t shift, size_t length) {\n    size_t vl = vsetvl_e32m1(length);\n    vint32m1_t v_src = vle32_v_i32m1(src, vl);\n    vint32m1_t v_arith_shift = vsra_vx_i32m1(v_src, shift, vl);\n    vuint32m1_t v_src_uint = vreinterpret_v_i32m1_u32m1(v_src);\n    vuint32m1_t v_logical_shift = vsrl_vx_u32m1(v_src_uint, shift, vl);\n    vint32m1_t v_logical_shift_int = vreinterpret_v_u32m1_i32m1(v_logical_shift);\n    vint32m1_t v_result = vadd_vv_i32m1(v_arith_shift, v_logical_shift_int, vl);\n    vse32_v_i32m1(dst, v_result, vl);\n}\n```"}
{"task_id": "SimdBench_12_RVV", "completion": "```c\nvoid mixed_right_shift_simd(const int *src, int *dst, uint8_t shift, size_t length) {\n    size_t vl = vsetvl_e32m1(length);\n    vint32m1_t v_src = vle32_v_i32m1(src, vl);\n    vint32m1_t v_arith_shift = vsra_vv_i32m1(v_src, vmv_v_x_i32m1(shift, vl), vl);\n    vint32m1_t v_logical_shift = vsrl_vv_u32m1(vreinterpret_v_i32m1_u32m1(v_src), vmv_v_x_u32m1(shift, vl), vl);\n    vint32m1_t v_result = vadd_vv_i32m1(v_arith_shift, vreinterpret_v_u32m1_i32m1(v_logical_shift), vl);\n    vse32_v_i32m1(dst, v_result, vl);\n}\n```"}
{"task_id": "SimdBench_12_RVV", "completion": "```c\nvoid mixed_right_shift_simd(const int *src, int *dst, uint8_t shift, size_t length) {\n    size_t vl = vsetvl_e32m1(length);\n    vint32m1_t v_src = vle32_v_i32m1(src, vl);\n    vint32m1_t v_arith_shift = vsra_vx_i32m1(v_src, shift, vl);\n    vuint32m1_t v_src_uint = vreinterpret_v_i32m1_u32m1(v_src);\n    vuint32m1_t v_logical_shift = vsrl_vx_u32m1(v_src_uint, shift, vl);\n    vint32m1_t v_logical_shift_int = vreinterpret_v_u32m1_i32m1(v_logical_shift);\n    vint32m1_t v_result = vadd_vv_i32m1(v_arith_shift, v_logical_shift_int, vl);\n    vse32_v_i32m1(dst, v_result, vl);\n}\n```"}
{"task_id": "SimdBench_13_RVV", "completion": "```cpp\nint64_t matrix_sum_simd(const int *matrix, size_t rows, size_t cols) {\n    size_t size = rows * cols;\n    int64_t sum = 0;\n\n    size_t vl = __riscv_vsetvl_e32m1(size);\n    vint32m1_t v_matrix = __riscv_vle32_v_i32m1(matrix, vl);\n\n    vint64m1_t v_sum = __riscv_vredsum_vs_i32m1_i64m1(v_matrix, v_sum, vl);\n\n    sum = __riscv_vmv_x_s_i64m1_i64(v_sum);\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_13_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nint64_t matrix_sum_simd(const int *matrix, size_t rows, size_t cols) {\n    size_t size = rows * cols;\n    size_t vl = __riscv_vsetvl_e32m1(size);\n    vint32m1_t v_matrix = __riscv_vle32_v_i32m1(matrix, vl);\n    vint64m1_t v_sum = __riscv_vredsum_vs_i32m1_i64m1(v_matrix, __riscv_vmv_v_x_i64m1(0, vl), vl);\n    return __riscv_vmv_x_s_i64m1_i64(v_sum);\n}\n```"}
{"task_id": "SimdBench_13_RVV", "completion": "```c\nint64_t matrix_sum_simd(const int *matrix, size_t rows, size_t cols) {\n    size_t size = rows * cols;\n    int64_t sum = 0;\n\n    size_t vl = __riscv_vsetvl_e32m1(size);\n    vint32m1_t v_matrix = __riscv_vle32_v_i32m1(matrix, vl);\n    vint64m1_t v_sum = __riscv_vwredsum_vs_i32m1_i64m1(v_matrix, v_sum, vl);\n\n    sum = __riscv_vmv_x_s_i64m1_i64(v_sum);\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_13_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nint64_t matrix_sum_simd(const int *matrix, size_t rows, size_t cols) {\n    size_t n = rows * cols;\n    int64_t sum = 0;\n    size_t vl;\n\n    vint64m1_t v_sum = __riscv_vmv_v_x_i64m1(0, 1);\n    vint32m1_t v_matrix;\n\n    for (size_t i = 0; i < n; i += vl) {\n        vl = __riscv_vsetvl_e32m1(n - i);\n        v_matrix = __riscv_vle32_v_i32m1(&matrix[i], vl);\n        vint64m1_t v_matrix_ext = __riscv_vwcvtu_x_x_v_i64m1(v_matrix, vl);\n        v_sum = __riscv_vredsum_vs_i64m1_i64m1(v_sum, v_matrix_ext, v_sum, vl);\n    }\n\n    sum = __riscv_vmv_x_s_i64m1_i64(v_sum);\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_13_RVV", "completion": "```cpp\nint64_t matrix_sum_simd(const int *matrix, size_t rows, size_t cols) {\n    size_t size = rows * cols;\n    int64_t sum = 0;\n\n    size_t vl = __riscv_vsetvl_e32m8(size);\n    vint32m8_t v_matrix = __riscv_vle32_v_i32m8(matrix, vl);\n    vint64m1_t v_sum = __riscv_vmv_v_x_i64m1(0, vl);\n\n    for (size_t i = 0; i < size; i += vl) {\n        vl = __riscv_vsetvl_e32m8(size - i);\n        v_matrix = __riscv_vle32_v_i32m8(matrix + i, vl);\n        vint64m1_t v_temp = __riscv_vwadd_vv_i64m1(v_sum, __riscv_vmv_v_x_i64m1(0, vl), v_matrix, vl);\n        v_sum = __riscv_vredsum_vs_i64m1_i64m1(v_sum, v_temp, v_sum, vl);\n    }\n\n    sum = __riscv_vmv_x_s_i64m1_i64(v_sum);\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_14_RVV", "completion": "```c\nsize_t argmax_simd(const int8_t *src, size_t length) {\n    if (length == 0) {\n        return 0;\n    }\n\n    size_t max_index = 0;\n    vint8m1_t v_src;\n    vint8m1_t v_max;\n    vint8m1_t v_indices;\n    size_t vl;\n\n    v_max = __riscv_vmv_v_x_i8m1(INT8_MIN, vl);\n    v_indices = __riscv_vid_v_i8m1(vl);\n\n    for (size_t i = 0; i < length; i += vl) {\n        vl = __riscv_vsetvl_e8m1(length - i);\n        v_src = __riscv_vle8_v_i8m1(src + i, vl);\n\n        vint8m1_t v_gt = __riscv_vmgt_vv_i8m1_b8(v_src, v_max, vl);\n        v_max = __riscv_vmerge_vvm_i8m1(v_max, v_src, v_gt, vl);\n        v_indices = __riscv_vmerge_vvm_i8m1(v_indices, __riscv_vid_v_i8m1(vl), v_gt, vl);\n    }\n\n    vint8m1_t v_max_indices = __riscv_vcompress_vm_i8m1(v_indices, v_gt, vl);\n    vint8m1_t v_max_values = __riscv_vcompress_vm_i8m1(v_src, v_gt, vl);\n\n    for (size_t i = 0; i < vl; ++i) {\n        if (v_max_values[i] == v_max[0]) {\n            max_index = v_max_indices[i];\n            break;\n        }\n    }\n\n    return max_index;\n}\n```"}
{"task_id": "SimdBench_14_RVV", "completion": "```c\nsize_t argmax_simd(const int8_t *src, size_t length) {\n    if (length == 0) {\n        return 0;\n    }\n\n    size_t max_index = 0;\n    vint8m1_t v_src;\n    vint8m1_t v_max;\n    vint8m1_t v_indices;\n    size_t vl;\n\n    v_max = __riscv_vmv_v_x_i8m1(INT8_MIN, vl);\n    v_indices = __riscv_vid_v_i8m1(vl);\n\n    for (size_t i = 0; i < length; i += vl) {\n        vl = __riscv_vsetvl_e8m1(length - i);\n        v_src = __riscv_vle8_v_i8m1(&src[i], vl);\n\n        vint8m1_t v_cmp = __riscv_vmseq_vv_i8m1_b8(v_src, v_max, vl);\n        vint8m1_t v_new_max = __riscv_vmax_vv_i8m1(v_src, v_max, vl);\n\n        v_max = __riscv_vmerge_vvm_i8m1(v_max, v_new_max, v_cmp, vl);\n        vint8m1_t v_new_indices = __riscv_vmerge_vvm_i8m1(v_indices, __riscv_vadd_vx_i8m1(v_indices, i, vl), v_cmp, vl);\n        v_indices = v_new_indices;\n    }\n\n    vint8m1_t v_max_val = __riscv_vmv_x_s_i8m1_f8m1(v_max, vl);\n    vint8m1_t v_max_idx = __riscv_vmv_x_s_i8m1_f8m1(v_indices, vl);\n\n    for (size_t i = 0; i < vl; ++i) {\n        if (v_max_val[i] == v_max) {\n            max_index = v_max_idx[i];\n            break;\n        }\n    }\n\n    return max_index;\n}\n```"}
{"task_id": "SimdBench_14_RVV", "completion": "```c\nsize_t argmax_simd(const int8_t *src, size_t length) {\n    if (length == 0) {\n        return 0;\n    }\n\n    size_t max_index = 0;\n    int8_t max_value = src[0];\n\n    size_t vl = __riscv_vsetvl_e8m1(length);\n    vint8m1_t v_src = __riscv_vle8_v_i8m1(src, vl);\n    vint8m1_t v_max = __riscv_vmv_v_x_i8m1(max_value, vl);\n    vuint8m1_t v_indices = __riscv_vid_v_u8m1(vl);\n\n    for (size_t i = vl; i < length; i += vl) {\n        vl = __riscv_vsetvl_e8m1(length - i);\n        v_src = __riscv_vle8_v_i8m1(src + i, vl);\n        v_indices = __riscv_vid_v_u8m1(vl);\n\n        vuint8m1_t v_mask = __riscv_vmsgt_vx_i8m1_b8(v_src, v_max, vl);\n        v_max = __riscv_vmax_vv_i8m1(v_max, v_src, vl);\n        vuint8m1_t v_new_indices = __riscv_vadd_vx_u8m1(v_indices, i, vl);\n        vuint8m1_t v_selected_indices = __riscv_vmerge_vvm_u8m1(v_new_indices, v_indices, v_mask, vl);\n        v_indices = __riscv_vmerge_vvm_u8m1(v_selected_indices, v_indices, v_mask, vl);\n    }\n\n    size_t index = __riscv_vfirst_m_u8m1(v_mask, vl);\n    if (index < vl) {\n        max_index = __riscv_vmv_x_s_u8m1_u8(v_indices, index);\n    }\n\n    return max_index;\n}\n```"}
{"task_id": "SimdBench_14_RVV", "completion": "```c\nsize_t argmax_simd(const int8_t *src, size_t length) {\n    if (length == 0) {\n        return 0;\n    }\n\n    size_t max_index = 0;\n    vint8m1_t v_src;\n    vint8m1_t v_max;\n    vint8m1_t v_indices;\n    size_t vl;\n\n    v_src = __riscv_vle8_v_i8m1(src, length, &vl);\n    v_max = __riscv_vmv_v_x_i8m1(INT8_MIN, vl);\n    v_indices = __riscv_vid_v_i8m1(vl);\n\n    for (size_t i = 0; i < length; i += vl) {\n        vint8m1_t v_temp = __riscv_vle8_v_i8m1(src + i, length - i, &vl);\n        vint8m1_t v_temp_indices = __riscv_vid_v_i8m1(vl);\n        vint8m1_t v_mask = __riscv_vmseq_vv_i8m1_b8(v_temp, v_max, vl);\n\n        v_max = __riscv_vmax_vv_i8m1(v_max, v_temp, vl);\n        v_indices = __riscv_vmerge_vvm_i8m1(v_indices, v_temp_indices, v_mask, vl);\n    }\n\n    int8_t max_value = __riscv_vmv_x_s_i8m1_i8(v_max);\n    max_index = __riscv_vmv_x_s_i8m1_i8(v_indices);\n\n    for (size_t i = 0; i < length; ++i) {\n        if (src[i] == max_value) {\n            max_index = i;\n            break;\n        }\n    }\n\n    return max_index;\n}\n```"}
{"task_id": "SimdBench_14_RVV", "completion": "```c\nsize_t argmax_simd(const int8_t *src, size_t length) {\n    if (length == 0) {\n        return 0;\n    }\n\n    size_t max_index = 0;\n    vint8m1_t v_src;\n    vint8m1_t v_max;\n    vint8m1_t v_indices;\n    size_t vl;\n\n    v_src = __riscv_vle8_v_i8m1(src, length, &vl);\n    v_max = __riscv_vmv_v_x_i8m1(INT8_MIN, vl);\n    v_indices = __riscv_vid_v_i8m1(vl);\n\n    for (size_t i = 0; i < length; i += vl) {\n        vint8m1_t v_temp = __riscv_vle8_v_i8m1(src + i, length - i, &vl);\n        vint8m1_t v_temp_indices = __riscv_vid_v_i8m1(vl);\n        vint8m1_t v_mask = __riscv_vmseq_vv_i8m1_b8(v_temp, v_max, vl);\n\n        v_max = __riscv_vmax_vv_i8m1(v_max, v_temp, vl);\n        v_indices = __riscv_vmerge_vvm_i8m1(v_indices, v_temp_indices, v_mask, vl);\n    }\n\n    vint8m1_t v_max_indices = __riscv_vcompress_vm_i8m1(v_indices, __riscv_vmsne_vx_i8m1_b8(v_max, INT8_MIN, vl), vl);\n    max_index = __riscv_vfirst_m_b8(__riscv_vmsne_vx_i8m1_b8(v_max, INT8_MIN, vl), vl);\n\n    return max_index;\n}\n```"}
{"task_id": "SimdBench_15_RVV", "completion": "```c\nvoid vector_blend_simd(const uint16_t* src1, const uint16_t* src2, uint32_t mask, uint16_t* dst, size_t length) {\n    size_t vl = vsetvl_e16m1(length);\n    for (size_t i = 0; i < length; i += vl) {\n        vl = vsetvl_e16m1(length - i);\n        vuint16m1_t v_src1 = vle16_v_u16m1(&src1[i], vl);\n        vuint16m1_t v_src2 = vle16_v_u16m1(&src2[i], vl);\n        vuint16m1_t v_mask = vmseq_vx_u16m1_b16(vuint16m1_t, 0, vl);\n        for (uint32_t j = 0; j < vl; ++j) {\n            v_mask = vmseq_vx_u16m1_b16(v_mask, (i + j) & mask, vl);\n        }\n        vuint16m1_t v_dst = vmerge_vvm_u16m1(v_src2, v_src1, v_mask, vl);\n        vse16_v_u16m1(&dst[i], v_dst, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_15_RVV", "completion": "```c\nvoid vector_blend_simd(const uint16_t* src1, const uint16_t* src2, uint32_t mask, uint16_t* dst, size_t length) {\n    size_t vl = vsetvl_e16m1(length);\n    for (size_t i = 0; i < length; i += vl) {\n        vl = vsetvl_e16m1(length - i);\n        vuint16m1_t v_src1 = vle16_v_u16m1(&src1[i], vl);\n        vuint16m1_t v_src2 = vle16_v_u16m1(&src2[i], vl);\n        vuint16m1_t v_mask = vmseq_vx_u16m1_b16(vu16m1_t, mask, 0, vl);\n        vuint16m1_t v_dst = vmerge_vvm_u16m1(v_src2, v_src1, v_mask, vl);\n        vse16_v_u16m1(&dst[i], v_dst, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_15_RVV", "completion": "```c\nvoid vector_blend_simd(const uint16_t* src1, const uint16_t* src2, uint32_t mask, uint16_t* dst, size_t length) {\n    size_t vl = vsetvl_e16m1(length);\n    vuint16m1_t v_src1, v_src2, v_dst;\n    vuint32m2_t v_mask;\n    vuint16m1_t v_zero = vmv_v_x_u16m1(0, vl);\n\n    for (size_t i = 0; i < length; i += vl) {\n        vl = vsetvl_e16m1(length - i);\n        v_src1 = vle16_v_u16m1(&src1[i], vl);\n        v_src2 = vle16_v_u16m1(&src2[i], vl);\n\n        v_mask = vmseq_vx_u32m2((i / 2) & mask, 0, vl);\n        v_dst = vmerge_vvm_u16m1(v_src1, v_src2, v_mask, vl);\n\n        vse16_v_u16m1(&dst[i], v_dst, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_15_RVV", "completion": "```c\nvoid vector_blend_simd(const uint16_t* src1, const uint16_t* src2, uint32_t mask, uint16_t* dst, size_t length) {\n    size_t vl = vsetvl_e16m1(length);\n    for (size_t i = 0; i < length; i += vl) {\n        vl = vsetvl_e16m1(length - i);\n        vuint16m1_t v_src1 = vle16_v_u16m1(&src1[i], vl);\n        vuint16m1_t v_src2 = vle16_v_u16m1(&src2[i], vl);\n        vuint16m1_t v_mask = vmseq_vx_u16m1_b16(vu16m1_t, mask, 0, vl);\n        vuint16m1_t v_dst = vmerge_vvm_u16m1(v_src2, v_src1, v_mask, vl);\n        vse16_v_u16m1(&dst[i], v_dst, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_15_RVV", "completion": "```c\nvoid vector_blend_simd(const uint16_t* src1, const uint16_t* src2, uint32_t mask, uint16_t* dst, size_t length) {\n    size_t vl = vsetvl_e16m1(length);\n    for (size_t i = 0; i < length; i += vl) {\n        vl = vsetvl_e16m1(length - i);\n        vuint16m1_t v_src1 = vle16_v_u16m1(&src1[i], vl);\n        vuint16m1_t v_src2 = vle16_v_u16m1(&src2[i], vl);\n        vuint16m1_t v_mask = vmseq_vx_u16m1_b16(vu16m1_t, mask, 0, vl);\n        vuint16m1_t v_dst = vmerge_vvm_u16m1(v_src2, v_src1, v_mask, vl);\n        vse16_v_u16m1(&dst[i], v_dst, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_16_RVV", "completion": "```cpp\nvoid population_count_simd(const uint32_t* src, uint32_t* dst, size_t length) {\n    size_t vl = __riscv_vsetvl_e32m1(length);\n    vuint32m1_t v_src = __riscv_vle32_v_u32m1(src, vl);\n    vuint32m1_t v_popcount = __riscv_vpopc_v_u32m1(v_src, vl);\n    __riscv_vse32_v_u32m1(dst, v_popcount, vl);\n}\n```"}
{"task_id": "SimdBench_16_RVV", "completion": "```c\nvoid population_count_simd(const uint32_t* src, uint32_t* dst, size_t length) {\n    size_t vl = vsetvl_e32m1(length);\n    for (size_t i = 0; i < length; i += vl) {\n        vl = vsetvl_e32m1(length - i);\n        vuint32m1_t v_src = vle32_v_u32m1(&src[i], vl);\n        vuint32m1_t v_popcnt = vpopc_v_u32m1(v_src, vl);\n        vse32_v_u32m1(&dst[i], v_popcnt, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_16_RVV", "completion": "```c\nvoid population_count_simd(const uint32_t* src, uint32_t* dst, size_t length) {\n    size_t vl = __riscv_vsetvl_e32m1(length);\n    for (size_t i = 0; i < length; i += vl) {\n        vl = __riscv_vsetvl_e32m1(length - i);\n        vuint32m1_t v_src = __riscv_vle32_v_u32m1(&src[i], vl);\n        vuint32m1_t v_popcnt = __riscv_vpopc_v_u32m1(v_src, vl);\n        __riscv_vse32_v_u32m1(&dst[i], v_popcnt, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_16_RVV", "completion": "```c\nvoid population_count_simd(const uint32_t* src, uint32_t* dst, size_t length) {\n    size_t vl = vsetvl_e32m1(length);\n    for (size_t i = 0; i < length; i += vl) {\n        vl = vsetvl_e32m1(length - i);\n        vuint32m1_t v_src = vle32_v_u32m1(&src[i], vl);\n        vuint32m1_t v_popcnt = vpopc_v_u32m1(v_src, vl);\n        vse32_v_u32m1(&dst[i], v_popcnt, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_16_RVV", "completion": "```c\nvoid population_count_simd(const uint32_t* src, uint32_t* dst, size_t length) {\n    size_t vl = __riscv_vsetvl_e32m1(length);\n    for (size_t i = 0; i < length; i += vl) {\n        vl = __riscv_vsetvl_e32m1(length - i);\n        vuint32m1_t v_src = __riscv_vle32_v_u32m1(&src[i], vl);\n        vuint32m1_t v_popcnt = __riscv_vpopc_v_u32m1(v_src, vl);\n        __riscv_vse32_v_u32m1(&dst[i], v_popcnt, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_17_RVV", "completion": "```c\nvoid saturating_add_simd(const uint16_t* src1, const uint16_t* src2, uint16_t* dst, size_t length) {\n    size_t vl = vsetvl_e16m1(length);\n    for (size_t i = 0; i < length; i += vl) {\n        vl = vsetvl_e16m1(length - i);\n        vuint16m1_t v_src1 = vle16_v_u16m1(&src1[i], vl);\n        vuint16m1_t v_src2 = vle16_v_u16m1(&src2[i], vl);\n        vuint16m1_t v_sum = vadd_vv_u16m1(v_src1, v_src2, vl);\n        vuint16m1_t v_max = vmv_v_x_u16m1(UINT16_MAX, vl);\n        vuint16m1_t v_saturated = vminu_vv_u16m1(v_sum, v_max, vl);\n        vse16_v_u16m1(&dst[i], v_saturated, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_17_RVV", "completion": "```c\nvoid saturating_add_simd(const uint16_t* src1, const uint16_t* src2, uint16_t* dst, size_t length) {\n    size_t vl = vsetvl_e16m1(length);\n    for (size_t i = 0; i < length; i += vl) {\n        vl = vsetvl_e16m1(length - i);\n        vuint16m1_t v_src1 = vle16_v_u16m1(&src1[i], vl);\n        vuint16m1_t v_src2 = vle16_v_u16m1(&src2[i], vl);\n        vuint16m1_t v_sum = vadd_vv_u16m1(v_src1, v_src2, vl);\n        vuint16m1_t v_max = vmv_v_x_u16m1(UINT16_MAX, vl);\n        vuint16m1_t v_saturated = vminu_vv_u16m1(v_sum, v_max, vl);\n        vse16_v_u16m1(&dst[i], v_saturated, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_17_RVV", "completion": "```c\nvoid saturating_add_simd(const uint16_t* src1, const uint16_t* src2, uint16_t* dst, size_t length) {\n    size_t vl = vsetvl_e16m1(length);\n    for (size_t i = 0; i < length; i += vl) {\n        vl = vsetvl_e16m1(length - i);\n        vuint16m1_t v_src1 = vle16_v_u16m1(&src1[i], vl);\n        vuint16m1_t v_src2 = vle16_v_u16m1(&src2[i], vl);\n        vuint16m1_t v_sum = vadd_vv_u16m1(v_src1, v_src2, vl);\n        vuint16m1_t v_max = vmv_v_x_u16m1(UINT16_MAX, vl);\n        vuint16m1_t v_result = vminu_vv_u16m1(v_sum, v_max, vl);\n        vse16_v_u16m1(&dst[i], v_result, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_17_RVV", "completion": "```c\nvoid saturating_add_simd(const uint16_t* src1, const uint16_t* src2, uint16_t* dst, size_t length) {\n    size_t vl = __riscv_vsetvl_e16m1(length);\n    for (size_t i = 0; i < length; i += vl) {\n        vl = __riscv_vsetvl_e16m1(length - i);\n        vuint16m1_t v_src1 = __riscv_vle16_v_u16m1(&src1[i], vl);\n        vuint16m1_t v_src2 = __riscv_vle16_v_u16m1(&src2[i], vl);\n        vuint16m1_t v_dst = __riscv_vadd_vv_u16m1(v_src1, v_src2, vl);\n        v_dst = __riscv_vminu_vx_u16m1(v_dst, UINT16_MAX, vl);\n        __riscv_vse16_v_u16m1(&dst[i], v_dst, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_17_RVV", "completion": "```c\nvoid saturating_add_simd(const uint16_t* src1, const uint16_t* src2, uint16_t* dst, size_t length) {\n    size_t vl = vsetvl_e16m1(length);\n    for (size_t i = 0; i < length; i += vl) {\n        vl = vsetvl_e16m1(length - i);\n        vuint16m1_t v_src1 = vle16_v_u16m1(&src1[i], vl);\n        vuint16m1_t v_src2 = vle16_v_u16m1(&src2[i], vl);\n        vuint16m1_t v_sum = vadd_vv_u16m1(v_src1, v_src2, vl);\n        vuint16m1_t v_max = vmv_v_x_u16m1(UINT16_MAX, vl);\n        vuint16m1_t v_saturated = vminu_vv_u16m1(v_sum, v_max, vl);\n        vse16_v_u16m1(&dst[i], v_saturated, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_18_RVV", "completion": "```c\nvoid range_matrix_mul_simd(const double* A, const double* B, double* C, size_t m, size_t n, size_t p) {\n    size_t vl = __riscv_vsetvl_e64m1(n);\n    for (size_t i = 0; i < m; ++i) {\n        for (size_t j = 0; j < p; ++j) {\n            double sum = 0.0;\n            for (size_t k = 0; k < n; k += vl) {\n                size_t remaining = n - k;\n                vl = __riscv_vsetvl_e64m1(remaining);\n                vfloat64m1_t va = __riscv_vle64_v_f64m1(&A[i * n + k], vl);\n                vfloat64m1_t vb = __riscv_vle64_v_f64m1(&B[k * p + j], vl);\n                vbool64_t mask_a = __riscv_vmseq_vx_f64m1_b64(va, 100.0, vl);\n                vbool64_t mask_b = __riscv_vmseq_vx_f64m1_b64(vb, 100.0, vl);\n                vbool64_t mask = __riscv_vmand_mm_b64(mask_a, mask_b, vl);\n                vfloat64m1_t vprod = __riscv_vfmacc_vv_f64m1(va, vb, vfloat64m1_t{0.0}, vl, mask);\n                sum += __riscv_vfmv_f_s_f64m1_f64(vprod);\n            }\n            C[i * p + j] = sum;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_18_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid range_matrix_mul_simd(const double* A, const double* B, double* C, size_t m, size_t n, size_t p) {\n    size_t vl = vsetvl_e64m1(n);\n    for (size_t i = 0; i < m; ++i) {\n        for (size_t j = 0; j < p; ++j) {\n            vfloat64m1_t vsum = vfmv_v_f_f64m1(0.0, vl);\n            for (size_t k = 0; k < n; k += vl) {\n                vl = vsetvl_e64m1(n - k);\n                vfloat64m1_t va = vle64_v_f64m1(&A[i * n + k], vl);\n                vfloat64m1_t vb = vle64_v_f64m1(&B[k * p + j], vl);\n                vbool64_t mask_a = vmflt_v_f_f64m1_b10(va, -100.0, vl);\n                vbool64_t mask_b = vmflt_v_f_f64m1_b10(vb, -100.0, vl);\n                vbool64_t mask = vmseq_vv_b10(mask_a, mask_b, vl);\n                va = vmerge_vx_f64m1(va, 0.0, mask, vl);\n                vb = vmerge_vx_f64m1(vb, 0.0, mask, vl);\n                vsum = vfmacc_vv_f64m1(vsum, va, vb, vl);\n            }\n            vs1r_v_f64m1(&C[i * p + j], vsum, vl);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_18_RVV", "completion": "```c\nvoid range_matrix_mul_simd(const double* A, const double* B, double* C, size_t m, size_t n, size_t p) {\n    size_t vl = __riscv_vsetvl_e64m1(p);\n    for (size_t i = 0; i < m; ++i) {\n        for (size_t j = 0; j < p; ++j) {\n            vfloat64m1_t vsum = __riscv_vfmv_v_f_f64m1(0.0, vl);\n            for (size_t k = 0; k < n; ++k) {\n                vfloat64m1_t va = __riscv_vle64_v_f64m1(&A[i * n + k], vl);\n                vfloat64m1_t vb = __riscv_vle64_v_f64m1(&B[k * p + j], vl);\n                vbool64_t mask_a = __riscv_vmflt_vf_f64m1_b64(va, -100.0, vl);\n                vbool64_t mask_b = __riscv_vmflt_vf_f64m1_b64(vb, -100.0, vl);\n                vbool64_t mask = __riscv_vmand_mm_b64(mask_a, mask_b, vl);\n                va = __riscv_vmerge_vvm_f64m1(va, va, mask, vl);\n                vb = __riscv_vmerge_vvm_f64m1(vb, vb, mask, vl);\n                vfloat64m1_t vprod = __riscv_vfmul_vv_f64m1(va, vb, vl);\n                vsum = __riscv_vfredusum_vs_f64m1_f64m1(vsum, vprod, vsum, vl);\n            }\n            __riscv_vse64_v_f64m1(&C[i * p + j], vsum, vl);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_18_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid range_matrix_mul_simd(const double* A, const double* B, double* C, size_t m, size_t n, size_t p) {\n    size_t vl = vsetvlmax_e64m1();\n    for (size_t i = 0; i < m; ++i) {\n        for (size_t j = 0; j < p; ++j) {\n            vfloat64m1_t sum = vfmv_v_f_f64m1(0.0, vl);\n            for (size_t k = 0; k < n; ++k) {\n                vfloat64m1_t a = vle64_v_f64m1(&A[i * n + k], vl);\n                vfloat64m1_t b = vle64_v_f64m1(&B[k * p + j], vl);\n                vbool64_t mask_a = vmflt_vv_f64m1_b11(a, vfmv_v_f_f64m1(100.0, vl), vl);\n                vbool64_t mask_b = vmflt_vv_f64m1_b11(b, vfmv_v_f_f64m1(100.0, vl), vl);\n                vbool64_t mask = vmseq_vv_b11(mask_a, mask_b, vl);\n                vfloat64m1_t prod = vfmul_vv_f64m1_m(mask, a, b, sum, vl);\n                sum = vfredusum_vs_f64m1_f64m1(sum, prod, sum, vl);\n            }\n            vse64_v_f64m1(&C[i * p + j], sum, vl);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_18_RVV", "completion": "```c\nvoid range_matrix_mul_simd(const double* A, const double* B, double* C, size_t m, size_t n, size_t p) {\n    size_t vl = __riscv_vsetvl_e64m1(p);\n    for (size_t i = 0; i < m; ++i) {\n        for (size_t j = 0; j < p; ++j) {\n            vfloat64m1_t vsum = __riscv_vfmv_v_f_f64m1(0.0, vl);\n            for (size_t k = 0; k < n; ++k) {\n                vfloat64m1_t va = __riscv_vle64_v_f64m1(&A[i * n + k], vl);\n                vfloat64m1_t vb = __riscv_vle64_v_f64m1(&B[k * p + j], vl);\n                vbool64_t mask_a = __riscv_vmfge_vf_f64m1_b64(va, -100.0, vl);\n                vbool64_t mask_b = __riscv_vmfge_vf_f64m1_b64(vb, -100.0, vl);\n                vbool64_t mask = __riscv_vmand_mm_b64(mask_a, mask_b, vl);\n                va = __riscv_vmerge_vxm_f64m1(0.0, va, mask, vl);\n                vb = __riscv_vmerge_vxm_f64m1(0.0, vb, mask, vl);\n                vfloat64m1_t vprod = __riscv_vfmul_vv_f64m1(va, vb, vl);\n                vsum = __riscv_vfredusum_vs_f64m1_f64m1(vsum, vprod, vsum, vl);\n            }\n            __riscv_vse64_v_f64m1(&C[i * p + j], vsum, vl);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_19_RVV", "completion": "```c\nvoid tensor_add_3d_simd(const int64_t* A, const int64_t* B, int64_t* C, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t vl = __riscv_vsetvl_e64m1(total_elements);\n\n    for (size_t i = 0; i < total_elements; i += vl) {\n        vl = __riscv_vsetvl_e64m1(total_elements - i);\n        vuint64m1_t va = __riscv_vle64_v_u64m1(&A[i], vl);\n        vuint64m1_t vb = __riscv_vle64_v_u64m1(&B[i], vl);\n        vuint64m1_t vc = __riscv_vadd_vv_u64m1(va, vb, vl);\n        __riscv_vse64_v_u64m1(&C[i], vc, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_19_RVV", "completion": "```cpp\nvoid tensor_add_3d_simd(const int64_t* A, const int64_t* B, int64_t* C, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t vlmax = __riscv_vsetvlmax_e64m1();\n\n    for (size_t i = 0; i < total_elements; i += vlmax) {\n        size_t vl = __riscv_vsetvl_e64m1(total_elements - i);\n        vuint64m1_t va = __riscv_vle64_v_u64m1(&A[i], vl);\n        vuint64m1_t vb = __riscv_vle64_v_u64m1(&B[i], vl);\n        vuint64m1_t vc = __riscv_vadd_vv_u64m1(va, vb, vl);\n        __riscv_vse64_v_u64m1(&C[i], vc, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_19_RVV", "completion": "```c\nvoid tensor_add_3d_simd(const int64_t* A, const int64_t* B, int64_t* C, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t vl = __riscv_vsetvl_e64m1(total_elements);\n\n    for (size_t i = 0; i < total_elements; i += vl) {\n        vl = __riscv_vsetvl_e64m1(total_elements - i);\n        vuint64m1_t va = __riscv_vle64_v_u64m1(&A[i], vl);\n        vuint64m1_t vb = __riscv_vle64_v_u64m1(&B[i], vl);\n        vuint64m1_t vc = __riscv_vadd_vv_u64m1(va, vb, vl);\n        __riscv_vse64_v_u64m1(&C[i], vc, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_19_RVV", "completion": "```c\nvoid tensor_add_3d_simd(const int64_t* A, const int64_t* B, int64_t* C, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t vl = __riscv_vsetvl_e64m1(total_elements);\n\n    for (size_t i = 0; i < total_elements; i += vl) {\n        vl = __riscv_vsetvl_e64m1(total_elements - i);\n\n        vint64m1_t va = __riscv_vle64_v_i64m1(&A[i], vl);\n        vint64m1_t vb = __riscv_vle64_v_i64m1(&B[i], vl);\n        vint64m1_t vc = __riscv_vadd_vv_i64m1(va, vb, vl);\n\n        __riscv_vse64_v_i64m1(&C[i], vc, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_19_RVV", "completion": "```c\nvoid tensor_add_3d_simd(const int64_t* A, const int64_t* B, int64_t* C, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t vlmax = __riscv_vsetvlmax_e64m1();\n    for (size_t i = 0; i < total_elements; i += vlmax) {\n        size_t vl = __riscv_vsetvl_e64m1(total_elements - i);\n        vuint64m1_t va = __riscv_vle64_v_u64m1(&A[i], vl);\n        vuint64m1_t vb = __riscv_vle64_v_u64m1(&B[i], vl);\n        vuint64m1_t vc = __riscv_vadd_vv_u64m1(va, vb, vl);\n        __riscv_vse64_v_u64m1(&C[i], vc, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_20_RVV", "completion": "```c\nvoid vector_add_round_nearest_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    size_t vl = __riscv_vsetvl_e32m1(length);\n    for (size_t i = 0; i < length; i += vl) {\n        vl = __riscv_vsetvl_e32m1(length - i);\n        vfloat32m1_t v_src1 = __riscv_vle32_v_f32m1(&src1[i], vl);\n        vfloat32m1_t v_src2 = __riscv_vle32_v_f32m1(&src2[i], vl);\n        vfloat32m1_t v_sum = __riscv_vfadd_vv_f32m1(v_src1, v_src2, vl);\n        vint32m1_t v_rounded = __riscv_vfncvt_xu_f_w_i32m1(v_sum, vl);\n        vfloat32m1_t v_result = __riscv_vfcvt_f_xu_v_i32m1(v_rounded, vl);\n        __riscv_vse32_v_f32m1(&dst[i], v_result, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_20_RVV", "completion": "```c\nvoid vector_add_round_nearest_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    size_t vl = __riscv_vsetvl_e32m1(length);\n    for (size_t i = 0; i < length; i += vl) {\n        vl = __riscv_vsetvl_e32m1(length - i);\n        vfloat32m1_t v_src1 = __riscv_vle32_v_f32m1(&src1[i], vl);\n        vfloat32m1_t v_src2 = __riscv_vle32_v_f32m1(&src2[i], vl);\n        vfloat32m1_t v_sum = __riscv_vfadd_vv_f32m1(v_src1, v_src2, vl);\n        vint32m1_t v_rounded = __riscv_vfncvt_x_f_w_i32m1(v_sum, vl);\n        vfloat32m1_t v_result = __riscv_vfcvt_f_x_v_f32m1(v_rounded, vl);\n        __riscv_vse32_v_f32m1(&dst[i], v_result, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_20_RVV", "completion": "```c\nvoid vector_add_round_nearest_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    size_t vl = vsetvl_e32m1(length);\n    for (size_t i = 0; i < length; i += vl) {\n        vl = vsetvl_e32m1(length - i);\n        vfloat32m1_t v_src1 = vle32_v_f32m1(&src1[i], vl);\n        vfloat32m1_t v_src2 = vle32_v_f32m1(&src2[i], vl);\n        vfloat32m1_t v_sum = vfadd_vv_f32m1(v_src1, v_src2, vl);\n        vint32m1_t v_rounded = vfncvt_x_f_w_i32m1(v_sum, vl);\n        vfloat32m1_t v_result = vfcvt_f_x_v_i32m1(v_rounded, vl);\n        vse32_v_f32m1(&dst[i], v_result, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_20_RVV", "completion": "```c\nvoid vector_add_round_nearest_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    size_t vl = vsetvl_e32m8(length);\n    for (size_t i = 0; i < length; i += vl) {\n        vl = vsetvl_e32m8(length - i);\n        vfloat32m8_t v_src1 = vle32_v_f32m8(&src1[i], vl);\n        vfloat32m8_t v_src2 = vle32_v_f32m8(&src2[i], vl);\n        vfloat32m8_t v_sum = vfadd_vv_f32m8(v_src1, v_src2, vl);\n        vint32m8_t v_rounded = vfncvt_rtz_x_f_w_i32m8(v_sum, vl);\n        vse32_v_i32m8(&dst[i], v_rounded, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_20_RVV", "completion": "```c\nvoid vector_add_round_nearest_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    size_t vl = vsetvl_e32m1(length);\n    for (size_t i = 0; i < length; i += vl) {\n        vl = vsetvl_e32m1(length - i);\n        vfloat32m1_t v_src1 = vle32_v_f32m1(&src1[i], vl);\n        vfloat32m1_t v_src2 = vle32_v_f32m1(&src2[i], vl);\n        vfloat32m1_t v_sum = vfadd_vv_f32m1(v_src1, v_src2, vl);\n        vint32m1_t v_rounded = vfncvt_x_f_w_i32m1(v_sum, vl);\n        vfloat32m1_t v_result = vfcvt_f_x_v_i32m1(v_rounded, vl);\n        vse32_v_f32m1(&dst[i], v_result, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_21_RVV", "completion": "```c\nvoid vector_mul_round_up_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    size_t vl = __riscv_vsetvl_e32m1(length);\n    for (size_t i = 0; i < length; i += vl) {\n        vl = __riscv_vsetvl_e32m1(length - i);\n        vfloat32m1_t v_src1 = __riscv_vle32_v_f32m1(&src1[i], vl);\n        vfloat32m1_t v_src2 = __riscv_vle32_v_f32m1(&src2[i], vl);\n        vint32m1_t v_indices = __riscv_vid_v_i32m1(vl);\n        vbool32_t v_mask = __riscv_vmseq_vx_i32m1_b32(v_indices, 0, vl);\n        v_mask = __riscv_vmand_mm_b32(v_mask, __riscv_vmsle_vx_f32m1_b32(__riscv_vfsub_vv_f32m1(v_src1, v_src2, vl), 50.0f, vl), vl);\n        v_mask = __riscv_vmand_mm_b32(v_mask, __riscv_vmsge_vx_f32m1_b32(__riscv_vfsub_vv_f32m1(v_src1, v_src2, vl), -50.0f, vl), vl);\n        v_mask = __riscv_vmand_mm_b32(v_mask, __riscv_vmseq_vx_i32m1_b32(__riscv_vrem_vx_i32m1(v_indices, 2, vl), 0, vl), vl);\n        vfloat32m1_t v_result = __riscv_vfmul_vv_f32m1(v_src1, v_src2, vl);\n        v_result = __riscv_vfadd_vf_f32m1(v_result, 0.5f, vl);\n        v_result = __riscv_vfmax_vf_f32m1(v_result, -1.0f, vl);\n        v_result = __riscv_vmerge_vx_f32m1(v_result, -1.0f, v_mask, vl);\n        __riscv_vse32_v_f32m1(&dst[i], v_result, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_21_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid vector_mul_round_up_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    size_t vl = __riscv_vsetvl_e32m1(length);\n\n    for (size_t i = 0; i < length; i += vl) {\n        vl = __riscv_vsetvl_e32m1(length - i);\n\n        vfloat32m1_t v_src1 = __riscv_vle32_v_f32m1(&src1[i], vl);\n        vfloat32m1_t v_src2 = __riscv_vle32_v_f32m1(&src2[i], vl);\n\n        vfloat32m1_t v_diff = __riscv_vfsub_vv_f32m1(v_src1, v_src2, vl);\n        vfloat32m1_t v_abs_diff = __riscv_vfabs_v_f32m1(v_diff, vl);\n\n        vuint32m1_t v_mask = __riscv_vmflt_vf_f32m1_b32(v_abs_diff, 50.0f, vl);\n        vuint32m1_t v_index_mask = __riscv_vmseq_vx_u32m1_b32(__riscv_vid_v_u32m1(vl), 0, vl);\n        v_index_mask = __riscv_vmand_mm_b32(v_index_mask, __riscv_vmseq_vx_u32m1_b32(__riscv_vid_v_u32m1(vl), 1, vl), vl);\n\n        vuint32m1_t v_final_mask = __riscv_vmand_mm_b32(v_mask, v_index_mask, vl);\n\n        vfloat32m1_t v_mul = __riscv_vfmul_vv_f32m1(v_src1, v_src2, vl);\n        vfloat32m1_t v_round_up = __riscv_vfadd_vf_f32m1(v_mul, 0.999999f, vl);\n        vfloat32m1_t v_result = __riscv_vfmerge_vvm_f32m1(__riscv_vfmv_v_f_f32m1(-1.0f, vl), v_round_up, v_final_mask, vl);\n\n        __riscv_vse32_v_f32m1(&dst[i], v_result, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_21_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid vector_mul_round_up_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    size_t vl = __riscv_vsetvl_e32m1(length);\n    vfloat32m1_t v_src1 = __riscv_vle32_v_f32m1(src1, vl);\n    vfloat32m1_t v_src2 = __riscv_vle32_v_f32m1(src2, vl);\n\n    vfloat32m1_t v_diff = __riscv_vfsub_vv_f32m1(v_src1, v_src2, vl);\n    vfloat32m1_t v_abs_diff = __riscv_vfabs_v_f32m1(v_diff, vl);\n\n    vbool32_t v_mask = __riscv_vmflt_vf_f32m1_b32(v_abs_diff, 50.0f, vl);\n\n    vuint32m1_t v_indices = __riscv_vid_v_u32m1(vl);\n    vbool32_t v_even_mask = __riscv_vmand_mm_b32(__riscv_vmseq_vx_u32m1_b32(v_indices, 0, vl), __riscv_vmseq_vx_u32m1_b32(v_indices, 1, vl), vl);\n\n    vbool32_t v_final_mask = __riscv_vmand_mm_b32(v_mask, v_even_mask, vl);\n\n    vfloat32m1_t v_mul = __riscv_vfmul_vv_f32m1(v_src1, v_src2, vl);\n    vfloat32m1_t v_round_up = __riscv_vfadd_vf_f32m1(v_mul, 0.5f, vl);\n    vfloat32m1_t v_result = __riscv_vfmax_vf_f32m1(v_round_up, -1.0f, vl);\n\n    vfloat32m1_t v_final_result = __riscv_vmerge_vxm_f32m1(v_result, -1.0f, v_final_mask, vl);\n\n    __riscv_vse32_v_f32m1(dst, v_final_result, vl);\n}\n```"}
{"task_id": "SimdBench_21_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid vector_mul_round_up_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    size_t vl = vsetvl_e32m1(length);\n\n    for (size_t i = 0; i < length; i += vl) {\n        vl = vsetvl_e32m1(length - i);\n\n        vfloat32m1_t v_src1 = vle32_v_f32m1(&src1[i], vl);\n        vfloat32m1_t v_src2 = vle32_v_f32m1(&src2[i], vl);\n\n        vfloat32m1_t v_diff = vfsub_vv_f32m1(v_src1, v_src2, vl);\n        vfloat32m1_t v_abs_diff = vfabs_v_f32m1(v_diff, vl);\n\n        vuint32m1_t v_index = vid_v_u32m1(vl);\n        vuint32m1_t v_mod2 = vremu_vx_u32m1(v_index, 2, vl);\n\n        vbool32_t v_mask = vmseq_vx_u32m1_b32(v_mod2, 0, vl);\n        v_mask = vmseq_vx_f32m1_b32(v_abs_diff, 50.0f, vl) & v_mask;\n\n        vfloat32m1_t v_mul = vfmul_vv_f32m1(v_src1, v_src2, vl);\n        vfloat32m1_t v_round_up = vfceil_v_f32m1(v_mul, vl);\n\n        vfloat32m1_t v_result = vmerge_vx_f32m1(v_round_up, -1.0f, v_mask, vl);\n\n        vse32_v_f32m1(&dst[i], v_result, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_21_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid vector_mul_round_up_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    size_t vl = __riscv_vsetvl_e32m1(length);\n\n    for (size_t i = 0; i < length; i += vl) {\n        vl = __riscv_vsetvl_e32m1(length - i);\n\n        vfloat32m1_t v_src1 = __riscv_vle32_v_f32m1(&src1[i], vl);\n        vfloat32m1_t v_src2 = __riscv_vle32_v_f32m1(&src2[i], vl);\n\n        vfloat32m1_t v_diff = __riscv_vfsub_vv_f32m1(v_src1, v_src2, vl);\n        vfloat32m1_t v_abs_diff = __riscv_vfabs_v_f32m1(v_diff, vl);\n\n        vuint32m1_t v_mask = __riscv_vmflt_vf_f32m1_b32(v_abs_diff, 50.0f, vl);\n        vuint32m1_t v_index_mask = __riscv_vid_v_u32m1(vl);\n        v_index_mask = __riscv_vand_vx_u32m1(v_index_mask, 1, vl);\n        v_mask = __riscv_vand_vv_b32(v_mask, v_index_mask, vl);\n\n        vfloat32m1_t v_mul = __riscv_vfmul_vv_f32m1(v_src1, v_src2, vl);\n        vfloat32m1_t v_round_up = __riscv_vfadd_vf_f32m1(v_mul, 0.5f, vl);\n        vfloat32m1_t v_result = __riscv_vfmax_vf_f32m1(v_round_up, -1.0f, vl);\n\n        v_mask = __riscv_vmseq_vx_u32m1_b32(v_mask, 0, vl);\n        v_result = __riscv_vmerge_vvm_f32m1(v_result, v_result, v_mask, vl);\n\n        __riscv_vse32_v_f32m1(&dst[i], v_result, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_22_RVV", "completion": "```c\nvoid matrix_scalar_mul_simd(const double* mat, double scalar, double* dst, size_t m, size_t n) {\n    size_t vlmax = __riscv_vsetvlmax_e64m1();\n    size_t elements = m * n;\n\n    for (size_t i = 0; i < elements; i += vlmax) {\n        size_t vl = __riscv_vsetvl_e64m1(elements - i);\n        vfloat64m1_t v_mat = __riscv_vle64_v_f64m1(&mat[i], vl);\n        vfloat64m1_t v_scalar = __riscv_vfmv_v_f_f64m1(scalar, vl);\n        vfloat64m1_t v_result = __riscv_vfmul_vv_f64m1(v_mat, v_scalar, vl);\n        __riscv_vse64_v_f64m1(&dst[i], v_result, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_22_RVV", "completion": "```c\nvoid matrix_scalar_mul_simd(const double* mat, double scalar, double* dst, size_t m, size_t n) {\n    size_t size = m * n;\n    size_t vl = __riscv_vsetvl_e64m1(size);\n\n    for (size_t i = 0; i < size; i += vl) {\n        vl = __riscv_vsetvl_e64m1(size - i);\n        vfloat64m1_t v_mat = __riscv_vle64_v_f64m1(&mat[i], vl);\n        vfloat64m1_t v_scalar = __riscv_vfmv_v_f_f64m1(scalar, vl);\n        vfloat64m1_t v_result = __riscv_vfmul_vv_f64m1(v_mat, v_scalar, vl);\n        __riscv_vse64_v_f64m1(&dst[i], v_result, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_22_RVV", "completion": "```c\nvoid matrix_scalar_mul_simd(const double* mat, double scalar, double* dst, size_t m, size_t n) {\n    size_t vl = __riscv_vsetvl_e64m1(n);\n    for (size_t i = 0; i < m; ++i) {\n        vfloat64m1_t v_mat = __riscv_vle64_v_f64m1(&mat[i * n], vl);\n        vfloat64m1_t v_scalar = __riscv_vfmv_v_f_f64m1(scalar, vl);\n        vfloat64m1_t v_result = __riscv_vfmul_vv_f64m1(v_mat, v_scalar, vl);\n        __riscv_vse64_v_f64m1(&dst[i * n], v_result, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_22_RVV", "completion": "```c\nvoid matrix_scalar_mul_simd(const double* mat, double scalar, double* dst, size_t m, size_t n) {\n    size_t size = m * n;\n    size_t vl = __riscv_vsetvl_e64m1(size);\n\n    for (size_t i = 0; i < size; i += vl) {\n        vl = __riscv_vsetvl_e64m1(size - i);\n        vfloat64m1_t v_mat = __riscv_vle64_v_f64m1(&mat[i], vl);\n        vfloat64m1_t v_scalar = __riscv_vfmv_v_f_f64m1(scalar, vl);\n        vfloat64m1_t v_result = __riscv_vfmul_vv_f64m1(v_mat, v_scalar, vl);\n        __riscv_vse64_v_f64m1(&dst[i], v_result, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_22_RVV", "completion": "```c\nvoid matrix_scalar_mul_simd(const double* mat, double scalar, double* dst, size_t m, size_t n) {\n    size_t vl = __riscv_vsetvl_e64m8(n);\n    for (size_t i = 0; i < m; ++i) {\n        size_t offset = i * n;\n        for (size_t j = 0; j < n; j += vl) {\n            vl = __riscv_vsetvl_e64m8(n - j);\n            vfloat64m8_t v_mat = __riscv_vle64_v_f64m8(&mat[offset + j], vl);\n            vfloat64m8_t v_scalar = __riscv_vfmv_v_f_f64m8(scalar, vl);\n            vfloat64m8_t v_result = __riscv_vfmul_vv_f64m8(v_mat, v_scalar, vl);\n            __riscv_vse64_v_f64m8(&dst[offset + j], v_result, vl);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_23_RVV", "completion": "```c\nvoid matrix_normalize_rows_simd(float* mat, size_t m, size_t n) {\n    size_t vl = __riscv_vsetvl_e32m1(n);\n    for (size_t i = 0; i < m; ++i) {\n        float* row = mat + i * n;\n        vfloat32m1_t v_row = __riscv_vle32_v_f32m1(row, vl);\n        vfloat32m1_t v_squares = __riscv_vfmul_vv_f32m1(v_row, v_row, vl);\n        float sum_squares = __riscv_vfmv_f_s_f32m1_f32(__riscv_vfredsum_vs_f32m1_f32(__riscv_vfmv_v_f_f32m1(0.0f, vl), v_squares, vl));\n        float norm = sqrtf(sum_squares);\n        vfloat32m1_t v_norm = __riscv_vfmv_v_f_f32m1(norm, vl);\n        vfloat32m1_t v_normalized_row = __riscv_vfdiv_vv_f32m1(v_row, v_norm, vl);\n        __riscv_vse32_v_f32m1(row, v_normalized_row, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_23_RVV", "completion": "```c\nvoid matrix_normalize_rows_simd(float* mat, size_t m, size_t n) {\n    for (size_t i = 0; i < m; ++i) {\n        float* row = mat + i * n;\n        size_t vl = __riscv_vsetvl_e32m1(n);\n\n        vfloat32m1_t v_row = __riscv_vle32_v_f32m1(row, vl);\n        vfloat32m1_t v_squares = __riscv_vfmul_vv_f32m1(v_row, v_row, vl);\n        float sum_squares = __riscv_vfmv_f_s_f32m1_f32(__riscv_vfredusum_vs_f32m1_f32m1(v_squares, 0.0f, vl));\n        float norm = __riscv_vfsqrt_s_f32m1_f32(sum_squares, vl);\n\n        vfloat32m1_t v_norm = __riscv_vfmv_v_f_f32m1(norm, vl);\n        vfloat32m1_t v_normalized = __riscv_vfdiv_vv_f32m1(v_row, v_norm, vl);\n\n        __riscv_vse32_v_f32m1(row, v_normalized, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_23_RVV", "completion": "```c\nvoid matrix_normalize_rows_simd(float* mat, size_t m, size_t n) {\n    for (size_t i = 0; i < m; ++i) {\n        float* row = mat + i * n;\n        size_t vl = __riscv_vsetvl_e32m1(n);\n\n        vfloat32m1_t v_row = __riscv_vle32_v_f32m1(row, vl);\n        vfloat32m1_t v_squares = __riscv_vfmul_vv_f32m1(v_row, v_row, vl);\n        float sum_squares = __riscv_vfredusum_vs_f32m1_f32m1(0.0f, v_squares, vl);\n        float norm = __riscv_vfsqrt_f_f32m1(sum_squares, vl);\n\n        vfloat32m1_t v_norm = __riscv_vfmv_v_f_f32m1(norm, vl);\n        vfloat32m1_t v_normalized_row = __riscv_vfdiv_vv_f32m1(v_row, v_norm, vl);\n\n        __riscv_vse32_v_f32m1(row, v_normalized_row, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_23_RVV", "completion": "```c\nvoid matrix_normalize_rows_simd(float* mat, size_t m, size_t n) {\n    size_t vl = vsetvlmax_e32m1();\n    for (size_t i = 0; i < m; ++i) {\n        float* row = &mat[i * n];\n        vfloat32m1_t v_row = vle32_v_f32m1(row, vl);\n        vfloat32m1_t v_squares = vfmul_vv_f32m1(v_row, v_row, vl);\n        float sum_squares = vfredusum_vs_f32m1_f32m1(v_squares, v_squares, 0.0f, vl);\n        float norm = sqrtf(sum_squares);\n        vfloat32m1_t v_norm = vfmv_v_f_f32m1(norm, vl);\n        vfloat32m1_t v_normalized = vfdiv_vv_f32m1(v_row, v_norm, vl);\n        vse32_v_f32m1(row, v_normalized, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_23_RVV", "completion": "```c\nvoid matrix_normalize_rows_simd(float* mat, size_t m, size_t n) {\n    for (size_t i = 0; i < m; ++i) {\n        float* row = &mat[i * n];\n        size_t vl = __riscv_vsetvl_e32m1(n);\n\n        vfloat32m1_t v_row = __riscv_vle32_v_f32m1(row, vl);\n        vfloat32m1_t v_squares = __riscv_vfmul_vv_f32m1(v_row, v_row, vl);\n        float sum_squares = __riscv_vfmv_f_s_f32m1_f32(__riscv_vfredusum_vs_f32m1_f32m1(v_squares, 0.0f, vl));\n        float norm = sqrtf(sum_squares);\n\n        vfloat32m1_t v_norm = __riscv_vfmv_v_f_f32m1(norm, vl);\n        vfloat32m1_t v_normalized_row = __riscv_vfdiv_vv_f32m1(v_row, v_norm, vl);\n\n        __riscv_vse32_v_f32m1(row, v_normalized_row, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_24_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid matrix_mul_round_int_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n, size_t p) {\n    size_t vl = vsetvl_e64m1(p);\n    for (size_t i = 0; i < m; ++i) {\n        for (size_t j = 0; j < p; ++j) {\n            vfloat64m1_t acc = vfmv_v_f_f64m1(0.0, vl);\n            for (size_t k = 0; k < n; ++k) {\n                vfloat64m1_t a = vle64_v_f64m1(&mat1[i * n + k], vl);\n                vfloat64m1_t b = vle64_v_f64m1(&mat2[k * p + j], vl);\n                acc = vfmacc_vv_f64m1(acc, a, b, vl);\n            }\n            vfloat64m1_t rounded = vfncvt_xu_f_w_i64m1(vfncvt_rtz_xu_f_v_i64m1(acc, vl), vl);\n            vse64_v_f64m1(&dst[i * p + j], rounded, vl);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_24_RVV", "completion": "```cpp\nvoid matrix_mul_round_int_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n, size_t p) {\n    size_t vl = __riscv_vsetvl_e64m8(p);\n    for (size_t i = 0; i < m; ++i) {\n        for (size_t j = 0; j < p; ++j) {\n            vfloat64m8_t acc = __riscv_vfmv_v_f_f64m8(0.0, vl);\n            for (size_t k = 0; k < n; ++k) {\n                vfloat64m8_t a = __riscv_vfmv_v_f_f64m8(mat1[i * n + k], vl);\n                vfloat64m8_t b = __riscv_vfmv_v_f_f64m8(mat2[k * p + j], vl);\n                acc = __riscv_vfmacc_vv_f64m8(acc, a, b, vl);\n            }\n            vfloat64m8_t rounded = __riscv_vfncvt_x_f_w_i64m8(__riscv_vfncvt_rtz_x_f_w_i64m8(acc, vl), vl);\n            __riscv_vse64_v_f64m8(&dst[i * p + j], rounded, vl);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_24_RVV", "completion": "```cpp\nvoid matrix_mul_round_int_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n, size_t p) {\n    size_t vl = __riscv_vsetvl_e64m1(p);\n    for (size_t i = 0; i < m; ++i) {\n        for (size_t j = 0; j < p; ++j) {\n            vfloat64m1_t vsum = __riscv_vfmv_v_f_f64m1(0.0, vl);\n            for (size_t k = 0; k < n; ++k) {\n                vfloat64m1_t va = __riscv_vfmv_v_f_f64m1(mat1[i * n + k], vl);\n                vfloat64m1_t vb = __riscv_vfmv_v_f_f64m1(mat2[k * p + j], vl);\n                vsum = __riscv_vfadd_vv_f64m1(vsum, __riscv_vfmul_vv_f64m1(va, vb, vl), vl);\n            }\n            vfloat64m1_t vrounded = __riscv_vfncvt_x_f_w_i64m1(__riscv_vfncvt_f_x_w_i64m1(vsum, vl), vl);\n            __riscv_vse64_v_f64m1(&dst[i * p + j], vrounded, vl);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_24_RVV", "completion": "```cpp\nvoid matrix_mul_round_int_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n, size_t p) {\n    size_t vl = __riscv_vsetvl_e64m8(p);\n    for (size_t i = 0; i < m; ++i) {\n        for (size_t j = 0; j < p; ++j) {\n            vfloat64m8_t vsum = __riscv_vfmv_v_f_f64m8(0.0, vl);\n            for (size_t k = 0; k < n; ++k) {\n                vfloat64m8_t va = __riscv_vfmv_v_f_f64m8(mat1[i * n + k], vl);\n                vfloat64m8_t vb = __riscv_vfmv_v_f_f64m8(mat2[k * p + j], vl);\n                vfloat64m8_t vprod = __riscv_vfmul_vv_f64m8(va, vb, vl);\n                vsum = __riscv_vfadd_vv_f64m8(vsum, vprod, vl);\n            }\n            vfloat64m8_t vrounded = __riscv_vfncvt_x_f_v_i64m8(vsum, vl);\n            __riscv_vse64_v_f64m8(&dst[i * p + j], vrounded, vl);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_24_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid matrix_mul_round_int_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n, size_t p) {\n    size_t vl = vsetvl_e64m8(p);\n    for (size_t i = 0; i < m; ++i) {\n        for (size_t j = 0; j < p; ++j) {\n            vfloat64m8_t acc = vfmv_v_f_f64m8(0.0, vl);\n            for (size_t k = 0; k < n; ++k) {\n                vfloat64m8_t a = vle64_v_f64m8(&mat1[i * n + k], vl);\n                vfloat64m8_t b = vle64_v_f64m8(&mat2[k * p + j], vl);\n                acc = vfmacc_vv_f64m8(acc, a, b, vl);\n            }\n            vfloat64m8_t rounded = vfncvt_xu_f_w_i64m8(acc, vl);\n            vse64_v_f64m8(&dst[i * p + j], rounded, vl);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_25_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid matrix_transpose_round_quarter_simd(const float* src, float* dst, size_t rows, size_t cols) {\n    size_t vl = vsetvl_e32m1(cols);\n    for (size_t i = 0; i < rows; ++i) {\n        vfloat32m1_t vrow = vle32_v_f32m1(&src[i * cols], vl);\n        for (size_t j = 0; j < cols; ++j) {\n            float val = vfmv_f_s_f32m1_f32(vrow, j);\n            val = round(val * 4.0f) / 4.0f;\n            dst[j * rows + i] = val;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_25_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid matrix_transpose_round_quarter_simd(const float* src, float* dst, size_t rows, size_t cols) {\n    size_t vl = vsetvl_e32m1(cols);\n    for (size_t i = 0; i < rows; ++i) {\n        vfloat32m1_t vrow = vle32_v_f32m1(&src[i * cols], vl);\n        for (size_t j = 0; j < cols; ++j) {\n            float val = vfmv_f_s_f32m1_f32(vrow, j);\n            val = roundf(val * 4.0f) / 4.0f;\n            vse32_v_f32m1(&dst[j * rows + i], vfmv_v_f_f32m1(val, vl), vl);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_25_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid matrix_transpose_round_quarter_simd(const float* src, float* dst, size_t rows, size_t cols) {\n    size_t vl = vsetvl_e32m1(cols);\n    for (size_t i = 0; i < rows; ++i) {\n        vfloat32m1_t vrow = vle32_v_f32m1(&src[i * cols], vl);\n        for (size_t j = 0; j < cols; ++j) {\n            float val = vfmv_f_s_f32m1_f32(vrow, j);\n            val = roundf(val * 4.0f) / 4.0f;\n            vse32_v_f32m1(&dst[j * rows + i], vfmv_v_f_f32m1(val, vl), vl);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_25_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid matrix_transpose_round_quarter_simd(const float* src, float* dst, size_t rows, size_t cols) {\n    size_t vl = vsetvl_e32m8(cols);\n    for (size_t i = 0; i < rows; ++i) {\n        vfloat32m8_t vrow = vle32_v_f32m8(src + i * cols, vl);\n        for (size_t j = 0; j < cols; ++j) {\n            float val = vfmv_f_s_f32m8_f32(vrow, j);\n            val = roundf(val * 4.0f) / 4.0f;\n            vse32_v_f32m8(dst + j * rows + i, &val, vl);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_25_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid matrix_transpose_round_quarter_simd(const float* src, float* dst, size_t rows, size_t cols) {\n    size_t vl = vsetvl_e32m1(cols);\n    for (size_t i = 0; i < rows; ++i) {\n        vfloat32m1_t vrow = vle32_v_f32m1(&src[i * cols], vl);\n        for (size_t j = 0; j < cols; ++j) {\n            float val = vfmv_f_s_f32m1_f32(vrow, j);\n            val = roundf(val * 4.0f) / 4.0f;\n            vse32_v_f32m1(&dst[j * rows + i], vfmv_v_f_f32m1(val, vl), vl);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_26_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid tensor3d_sub_round_zero_simd(const float* tensor1, const float* tensor2, float* dst, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t vlmax = __riscv_vsetvlmax_e32m1();\n\n    for (size_t i = 0; i < total_elements; i += vlmax) {\n        size_t vl = __riscv_vsetvl_e32m1(total_elements - i);\n\n        vfloat32m1_t v_tensor1 = __riscv_vle32_v_f32m1(&tensor1[i], vl);\n        vfloat32m1_t v_tensor2 = __riscv_vle32_v_f32m1(&tensor2[i], vl);\n\n        vfloat32m1_t v_result = __riscv_vfsub_vv_f32m1(v_tensor1, v_tensor2, vl);\n        v_result = __riscv_vfround_v_f32m1(v_result, vl, RVV_RD_ZERO);\n\n        __riscv_vse32_v_f32m1(&dst[i], v_result, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_26_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid tensor3d_sub_round_zero_simd(const float* tensor1, const float* tensor2, float* dst, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t vlmax = __riscv_vsetvlmax_e32m1();\n\n    for (size_t i = 0; i < total_elements; i += vlmax) {\n        size_t vl = __riscv_vsetvl_e32m1(total_elements - i);\n\n        vfloat32m1_t v_t1 = __riscv_vle32_v_f32m1(&tensor1[i], vl);\n        vfloat32m1_t v_t2 = __riscv_vle32_v_f32m1(&tensor2[i], vl);\n\n        vfloat32m1_t v_diff = __riscv_vfsub_vv_f32m1(v_t1, v_t2, vl);\n        vfloat32m1_t v_rounded = __riscv_vfncvt_xu_f_w_i32m1(v_diff, vl);\n\n        __riscv_vse32_v_f32m1(&dst[i], v_rounded, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_26_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid tensor3d_sub_round_zero_simd(const float* tensor1, const float* tensor2, float* dst, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t vlmax = __riscv_vsetvlmax_e32m1();\n\n    for (size_t i = 0; i < total_elements; i += vlmax) {\n        size_t vl = __riscv_vsetvl_e32m1(total_elements - i);\n\n        vfloat32m1_t v1 = __riscv_vle32_v_f32m1(&tensor1[i], vl);\n        vfloat32m1_t v2 = __riscv_vle32_v_f32m1(&tensor2[i], vl);\n\n        vfloat32m1_t v_sub = __riscv_vfsub_vv_f32m1(v1, v2, vl);\n        vfloat32m1_t v_round = __riscv_vfround_v_f32m1(v_sub, vl, RVV_RD_ZERO);\n\n        __riscv_vse32_v_f32m1(&dst[i], v_round, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_26_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid tensor3d_sub_round_zero_simd(const float* tensor1, const float* tensor2, float* dst, size_t dim1, size_t dim2, size_t dim3) {\n    size_t size = dim1 * dim2 * dim3;\n    size_t vl = vsetvl_e32m1(size);\n\n    for (size_t i = 0; i < size; i += vl) {\n        vl = vsetvl_e32m1(size - i);\n\n        vfloat32m1_t v1 = vle32_v_f32m1(&tensor1[i], vl);\n        vfloat32m1_t v2 = vle32_v_f32m1(&tensor2[i], vl);\n\n        vfloat32m1_t vsub = vfsub_vv_f32m1(v1, v2, vl);\n        vint32m1_t vround = vfcvt_x_f_v_i32m1(vsub, vl);\n\n        vse32_v_i32m1(&dst[i], vround, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_26_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid tensor3d_sub_round_zero_simd(const float* tensor1, const float* tensor2, float* dst, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t vl = __riscv_vsetvl_e32m1(total_elements);\n\n    for (size_t i = 0; i < total_elements; i += vl) {\n        vl = __riscv_vsetvl_e32m1(total_elements - i);\n\n        vfloat32m1_t v_tensor1 = __riscv_vle32_v_f32m1(&tensor1[i], vl);\n        vfloat32m1_t v_tensor2 = __riscv_vle32_v_f32m1(&tensor2[i], vl);\n\n        vfloat32m1_t v_result = __riscv_vfsub_vv_f32m1(v_tensor1, v_tensor2, vl);\n        v_result = __riscv_vfround_v_f32m1(v_result, vl, RVV_RD_ZERO);\n\n        __riscv_vse32_v_f32m1(&dst[i], v_result, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_27_RVV", "completion": "```c\nvoid matrix_hadamard_product_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n) {\n    size_t i;\n    size_t vl = __riscv_vsetvl_e64m8(n);\n    for (i = 0; i < m; i++) {\n        vfloat64m8_t v_mat1 = __riscv_vle64_v_f64m8(mat1 + i * n, vl);\n        vfloat64m8_t v_mat2 = __riscv_vle64_v_f64m8(mat2 + i * n, vl);\n        vfloat64m8_t v_dst = __riscv_vfmul_vv_f64m8(v_mat1, v_mat2, vl);\n        __riscv_vse64_v_f64m8(dst + i * n, v_dst, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_27_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n\nvoid matrix_hadamard_product_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n) {\n    size_t i;\n    size_t vl;\n    for (i = 0; i < m * n; i += vl) {\n        vl = vsetvl_e64m8(m * n - i);\n        vfloat64m8_t v_mat1 = vle64_v_f64m8(&mat1[i], vl);\n        vfloat64m8_t v_mat2 = vle64_v_f64m8(&mat2[i], vl);\n        vfloat64m8_t v_dst = vfmul_vv_f64m8(v_mat1, v_mat2, vl);\n        vse64_v_f64m8(&dst[i], v_dst, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_27_RVV", "completion": "```cpp\nvoid matrix_hadamard_product_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n) {\n    size_t elements = m * n;\n    size_t vl = __riscv_vsetvl_e64m1(elements);\n\n    for (size_t i = 0; i < elements; i += vl) {\n        vl = __riscv_vsetvl_e64m1(elements - i);\n\n        vfloat64m1_t v_mat1 = __riscv_vle64_v_f64m1(&mat1[i], vl);\n        vfloat64m1_t v_mat2 = __riscv_vle64_v_f64m1(&mat2[i], vl);\n        vfloat64m1_t v_dst = __riscv_vfmul_vv_f64m1(v_mat1, v_mat2, vl);\n\n        __riscv_vse64_v_f64m1(&dst[i], v_dst, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_27_RVV", "completion": "```c\nvoid matrix_hadamard_product_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n) {\n    size_t i;\n    size_t vl = __riscv_vsetvl_e64m1(n);\n    for (i = 0; i < m; i++) {\n        size_t offset = i * n;\n        vfloat64m1_t v_mat1 = __riscv_vle64_v_f64m1(&mat1[offset], vl);\n        vfloat64m1_t v_mat2 = __riscv_vle64_v_f64m1(&mat2[offset], vl);\n        vfloat64m1_t v_dst = __riscv_vfmul_vv_f64m1(v_mat1, v_mat2, vl);\n        __riscv_vse64_v_f64m1(&dst[offset], v_dst, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_27_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n\nvoid matrix_hadamard_product_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n) {\n    size_t i;\n    size_t vlmax = __riscv_vsetvlmax_e64m1();\n    for (i = 0; i < m * n; i += vlmax) {\n        size_t vl = __riscv_vsetvl_e64m1(m * n - i);\n        vfloat64m1_t v_mat1 = __riscv_vle64_v_f64m1(&mat1[i], vl);\n        vfloat64m1_t v_mat2 = __riscv_vle64_v_f64m1(&mat2[i], vl);\n        vfloat64m1_t v_dst = __riscv_vfmul_vv_f64m1(v_mat1, v_mat2, vl);\n        __riscv_vse64_v_f64m1(&dst[i], v_dst, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_28_RVV", "completion": "```c\nvoid matrix_vector_mul_simd(const float* mat, const float* vec, float* dst, size_t m, size_t n) {\n    size_t vl = __riscv_vsetvl_e32m1(n);\n    for (size_t i = 0; i < m; ++i) {\n        size_t offset = i * n;\n        vfloat32m1_t v_mat = __riscv_vle32_v_f32m1(&mat[offset], vl);\n        vfloat32m1_t v_vec = __riscv_vle32_v_f32m1(vec, vl);\n        vfloat32m1_t v_prod = __riscv_vfmv_v_f_f32m1(0.0f, vl);\n        v_prod = __riscv_vfwmacc_vv_f32m1(v_prod, v_mat, v_vec, vl);\n        float sum = __riscv_vfmv_fs_f32m1_f32(v_prod);\n        dst[i] = sum;\n    }\n}\n```"}
{"task_id": "SimdBench_28_RVV", "completion": "```c\nvoid matrix_vector_mul_simd(const float* mat, const float* vec, float* dst, size_t m, size_t n) {\n    size_t vl = __riscv_vsetvl_e32m1(n);\n    for (size_t i = 0; i < m; ++i) {\n        size_t offset = i * n;\n        vfloat32m1_t v_mat = __riscv_vle32_v_f32m1(&mat[offset], vl);\n        vfloat32m1_t v_vec = __riscv_vle32_v_f32m1(vec, vl);\n        vfloat32m1_t v_prod = __riscv_vfmv_v_f_f32m1(0.0f, vl);\n        for (size_t j = 0; j < n; j += vl) {\n            vl = __riscv_vsetvl_e32m1(n - j);\n            v_mat = __riscv_vle32_v_f32m1(&mat[offset + j], vl);\n            v_vec = __riscv_vle32_v_f32m1(&vec[j], vl);\n            v_prod = __riscv_vfmacc_vv_f32m1(v_prod, v_mat, v_vec, vl);\n        }\n        float sum = __riscv_vfmv_fs_f32m1_f32(v_prod);\n        dst[i] = sum;\n    }\n}\n```"}
{"task_id": "SimdBench_28_RVV", "completion": "```c\nvoid matrix_vector_mul_simd(const float* mat, const float* vec, float* dst, size_t m, size_t n) {\n    size_t vl = __riscv_vsetvl_e32m1(n);\n    for (size_t i = 0; i < m; ++i) {\n        size_t offset = i * n;\n        vfloat32m1_t v_mat = __riscv_vle32_v_f32m1(&mat[offset], vl);\n        vfloat32m1_t v_vec = __riscv_vle32_v_f32m1(vec, vl);\n        vfloat32m1_t v_prod = __riscv_vfmv_v_f_f32m1(0.0f, vl);\n        v_prod = __riscv_vfwmacc_vv_f32m1(v_prod, v_mat, v_vec, vl);\n        float sum = __riscv_vfmv_f_s_f32m1_f32(v_prod);\n        dst[i] = sum;\n    }\n}\n```"}
{"task_id": "SimdBench_28_RVV", "completion": "```c\nvoid matrix_vector_mul_simd(const float* mat, const float* vec, float* dst, size_t m, size_t n) {\n    size_t vl = __riscv_vsetvl_e32m1(n);\n    for (size_t i = 0; i < m; ++i) {\n        size_t offset = i * n;\n        vfloat32m1_t v_mat = __riscv_vle32_v_f32m1(&mat[offset], vl);\n        vfloat32m1_t v_vec = __riscv_vle32_v_f32m1(vec, vl);\n        vfloat32m1_t v_prod = __riscv_vfmv_v_f_f32m1(0.0f, vl);\n        v_prod = __riscv_vfwmacc_vv_f32m1(v_prod, v_mat, v_vec, vl);\n        float sum = __riscv_vfmv_f_s_f32m1_f32(v_prod);\n        dst[i] = sum;\n    }\n}\n```"}
{"task_id": "SimdBench_28_RVV", "completion": "```c\nvoid matrix_vector_mul_simd(const float* mat, const float* vec, float* dst, size_t m, size_t n) {\n    size_t vlmax = __riscv_vsetvlmax_e32m1();\n    for (size_t i = 0; i < m; ++i) {\n        size_t vl = __riscv_vsetvl_e32m1(n);\n        vfloat32m1_t vmat = __riscv_vle32_v_f32m1(&mat[i * n], vl);\n        vfloat32m1_t vvec = __riscv_vle32_v_f32m1(vec, vl);\n        vfloat32m1_t vprod = __riscv_vfmv_v_f_f32m1(0.0f, vl);\n        for (size_t j = 0; j < n; j += vl) {\n            vl = __riscv_vsetvl_e32m1(n - j);\n            vmat = __riscv_vle32_v_f32m1(&mat[i * n + j], vl);\n            vvec = __riscv_vle32_v_f32m1(&vec[j], vl);\n            vprod = __riscv_vfmacc_vv_f32m1(vprod, vmat, vvec, vl);\n        }\n        vfloat32m1_t vsum = __riscv_vfredusum_vs_f32m1_f32m1(vprod, vprod, vl);\n        __riscv_vse32_v_f32m1(&dst[i], vsum, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_29_RVV", "completion": "```cpp\ndouble matrix_average_simd(const double* mat, size_t m, size_t n) {\n    size_t num_elements = m * n;\n    double sum = 0.0;\n\n    size_t vl = __riscv_vsetvl_e64m1(num_elements);\n    vfloat64m1_t v_sum = __riscv_vfmv_v_f_f64m1(0.0, vl);\n\n    for (size_t i = 0; i < num_elements; i += vl) {\n        vl = __riscv_vsetvl_e64m1(num_elements - i);\n        vfloat64m1_t v_mat = __riscv_vle64_v_f64m1(&mat[i], vl);\n        v_sum = __riscv_vfredusum_vs_f64m1_f64m1(v_sum, v_mat, v_sum, vl);\n    }\n\n    sum = __riscv_vfmv_f_s_f64m1_f64(v_sum);\n\n    return sum / num_elements;\n}\n```"}
{"task_id": "SimdBench_29_RVV", "completion": "```cpp\ndouble matrix_average_simd(const double* mat, size_t m, size_t n) {\n    size_t num_elements = m * n;\n    double sum = 0.0;\n\n    size_t vl = __riscv_vsetvl_e64m1(num_elements);\n    vfloat64m1_t v_sum = __riscv_vfmv_v_f_f64m1(0.0, vl);\n\n    for (size_t i = 0; i < num_elements; i += vl) {\n        vl = __riscv_vsetvl_e64m1(num_elements - i);\n        vfloat64m1_t v_mat = __riscv_vle64_v_f64m1(&mat[i], vl);\n        v_sum = __riscv_vfredusum_vs_f64m1_f64m1(v_sum, v_mat, v_sum, vl);\n    }\n\n    sum = __riscv_vfmv_f_s_f64m1_f64(v_sum);\n\n    return sum / num_elements;\n}\n```"}
{"task_id": "SimdBench_29_RVV", "completion": "```cpp\ndouble matrix_average_simd(const double* mat, size_t m, size_t n) {\n    size_t num_elements = m * n;\n    double sum = 0.0;\n\n    size_t vl = __riscv_vsetvl_e64m1(num_elements);\n    vfloat64m1_t v_sum = __riscv_vfmv_v_f_f64m1(0.0, vl);\n\n    for (size_t i = 0; i < num_elements; i += vl) {\n        vl = __riscv_vsetvl_e64m1(num_elements - i);\n        vfloat64m1_t v_mat = __riscv_vle64_v_f64m1(&mat[i], vl);\n        v_sum = __riscv_vfredusum_vs_f64m1_f64m1(v_sum, v_mat, v_sum, vl);\n    }\n\n    sum = __riscv_vfmv_f_s_f64m1_f64(v_sum);\n\n    return sum / num_elements;\n}\n```"}
{"task_id": "SimdBench_29_RVV", "completion": "```c\ndouble matrix_average_simd(const double* mat, size_t m, size_t n) {\n    size_t num_elements = m * n;\n    double sum = 0.0;\n\n    size_t vl = __riscv_vsetvl_e64m1(num_elements);\n    vfloat64m1_t v_sum = __riscv_vfmv_v_f_f64m1(0.0, vl);\n\n    for (size_t i = 0; i < num_elements; i += vl) {\n        vl = __riscv_vsetvl_e64m1(num_elements - i);\n        vfloat64m1_t v_mat = __riscv_vle64_v_f64m1(&mat[i], vl);\n        v_sum = __riscv_vfredusum_vs_f64m1_f64m1(v_sum, v_mat, v_sum, vl);\n    }\n\n    sum = __riscv_vfmv_f_s_f64m1_f64(v_sum);\n\n    return sum / num_elements;\n}\n```"}
{"task_id": "SimdBench_29_RVV", "completion": "```cpp\ndouble matrix_average_simd(const double* mat, size_t m, size_t n) {\n    size_t num_elements = m * n;\n    double sum = 0.0;\n\n    size_t vl = __riscv_vsetvl_e64m1(num_elements);\n    vfloat64m1_t v_sum = __riscv_vfmv_v_f_f64m1(0.0, vl);\n\n    for (size_t i = 0; i < num_elements; i += vl) {\n        vl = __riscv_vsetvl_e64m1(num_elements - i);\n        vfloat64m1_t v_mat = __riscv_vle64_v_f64m1(&mat[i], vl);\n        v_sum = __riscv_vfredusum_vs_f64m1_f64m1(v_sum, v_mat, v_sum, vl);\n    }\n\n    sum = __riscv_vfmv_f_s_f64m1_f64(v_sum);\n\n    return sum / num_elements;\n}\n```"}
{"task_id": "SimdBench_30_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n\nbool matrix_rows_sorted_verify_simd(const int* matrix, const bool* directions, size_t rows, size_t cols) {\n    bool all_sorted = true;\n\n    for (size_t i = 0; i < rows; ++i) {\n        const int* row = matrix + i * cols;\n        bool direction = directions[i];\n\n        size_t vl = __riscv_vsetvl_e32m1(cols);\n        vint32m1_t vrow = __riscv_vle32_v_i32m1(row, vl);\n\n        vint32m1_t vrow_shifted = __riscv_vslideup_vx_i32m1(vrow, vrow, 1, vl);\n        vint32m1_t vdiff = __riscv_vsub_vv_i32m1(vrow, vrow_shifted, vl);\n\n        if (direction) {\n            // Check for ascending order\n            vint32m1_t vcheck = __riscv_vsgt_vx_i32m1(vdiff, 0, vl);\n            bool row_sorted = __riscv_vmv_x_s_b32(__riscv_vmand_mm_b32(vcheck, vcheck, vl));\n            all_sorted &= row_sorted;\n        } else {\n            // Check for descending order\n            vint32m1_t vcheck = __riscv_vslt_vx_i32m1(vdiff, 0, vl);\n            bool row_sorted = __riscv_vmv_x_s_b32(__riscv_vmand_mm_b32(vcheck, vcheck, vl));\n            all_sorted &= row_sorted;\n        }\n    }\n\n    return all_sorted;\n}\n```"}
{"task_id": "SimdBench_30_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n\nbool matrix_rows_sorted_verify_simd(const int* matrix, const bool* directions, size_t rows, size_t cols) {\n    for (size_t i = 0; i < rows; ++i) {\n        const int* row = matrix + i * cols;\n        bool ascending = directions[i];\n\n        if (cols == 1) {\n            continue;\n        }\n\n        size_t vl = __riscv_vsetvl_e32m1(cols - 1);\n        vint32m1_t v_a = __riscv_vle32_v_i32m1(row, vl);\n        vint32m1_t v_b = __riscv_vle32_v_i32m1(row + 1, vl);\n\n        vint32m1_t v_diff = __riscv_vsub_vv_i32m1(v_b, v_a, vl);\n        vint32m1_t v_cond = ascending ? __riscv_vslt_vx_i32m1_b32(v_diff, 0, vl) : __riscv_vsgt_vx_i32m1_b32(v_diff, 0, vl);\n\n        if (__riscv_vfirst_m_b32(v_cond, vl) != -1) {\n            return false;\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_30_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n\nbool matrix_rows_sorted_verify_simd(const int* matrix, const bool* directions, size_t rows, size_t cols) {\n    for (size_t i = 0; i < rows; ++i) {\n        const int* row = matrix + i * cols;\n        bool ascending = directions[i];\n\n        size_t j = 0;\n        for (; j <= cols - 4; j += 4) {\n            vint32m1_t v0 = __riscv_vle32_v_i32m1(row + j, 4);\n            vint32m1_t v1 = __riscv_vle32_v_i32m1(row + j + 1, 4);\n\n            vbool32_t cmp = ascending ? __riscv_vmsle_vv_i32m1_b32(v0, v1, 4) : __riscv_vmsge_vv_i32m1_b32(v0, v1, 4);\n            if (!__riscv_vreduc_and_b32(cmp, 4)) {\n                return false;\n            }\n        }\n\n        for (; j < cols - 1; ++j) {\n            if ((ascending && row[j] > row[j + 1]) || (!ascending && row[j] < row[j + 1])) {\n                return false;\n            }\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_30_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n\nbool matrix_rows_sorted_verify_simd(const int* matrix, const bool* directions, size_t rows, size_t cols) {\n    bool all_sorted = true;\n    size_t vl;\n\n    for (size_t i = 0; i < rows; ++i) {\n        const int* row = matrix + i * cols;\n        bool ascending = directions[i];\n        bool row_sorted = true;\n\n        if (cols > 1) {\n            vint32m1_t v_prev = __riscv_vle32_v_i32m1(row, cols, &vl);\n            vint32m1_t v_curr = __riscv_vle32_v_i32m1(row + 1, cols - 1, &vl);\n\n            if (ascending) {\n                vbool32_t v_cond = __riscv_vmslt_vv_i32m1_b32(v_prev, v_curr, vl);\n                row_sorted = __riscv_vreduc_and_b32(v_cond, vl);\n            } else {\n                vbool32_t v_cond = __riscv_vmsgt_vv_i32m1_b32(v_prev, v_curr, vl);\n                row_sorted = __riscv_vreduc_and_b32(v_cond, vl);\n            }\n        }\n\n        all_sorted &= row_sorted;\n    }\n\n    return all_sorted;\n}\n```"}
{"task_id": "SimdBench_30_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nbool matrix_rows_sorted_verify_simd(const int* matrix, const bool* directions, size_t rows, size_t cols) {\n    for (size_t i = 0; i < rows; ++i) {\n        const int* row = matrix + i * cols;\n        bool ascending = directions[i];\n\n        size_t vl = __riscv_vsetvl_e32m1(cols);\n        vint32m1_t v_row = __riscv_vle32_v_i32m1(row, vl);\n\n        vint32m1_t v_row_shifted = __riscv_vslide1down_vx_i32m1(v_row, 0, vl);\n\n        vint32m1_t v_diff = __riscv_vsub_vv_i32m1(v_row, v_row_shifted, vl);\n\n        if (ascending) {\n            vint32m1_t v_lt_zero = __riscv_vmslt_vx_i32m1(v_diff, 0, vl);\n            if (__riscv_vfirst_m(v_lt_zero, vl) != -1) {\n                return false;\n            }\n        } else {\n            vint32m1_t v_gt_zero = __riscv_vmsgt_vx_i32m1(v_diff, 0, vl);\n            if (__riscv_vfirst_m(v_gt_zero, vl) != -1) {\n                return false;\n            }\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_31_RVV", "completion": "```c\nvoid nearest_multiple_simd(const int16_t* src, int16_t* dst, uint8_t base, size_t length) {\n    size_t vl = vsetvl_e16m1(length);\n    vint16m1_t v_src = vle16_v_i16m1(src, vl);\n    vint16m1_t v_base = vmv_v_x_i16m1(base, vl);\n    vint16m1_t v_quotient = vdiv_vv_i16m1(v_src, v_base, vl);\n    vint16m1_t v_result = vmul_vv_i16m1(v_quotient, v_base, vl);\n    vse16_v_i16m1(dst, v_result, vl);\n}\n```"}
{"task_id": "SimdBench_31_RVV", "completion": "```c\nvoid nearest_multiple_simd(const int16_t* src, int16_t* dst, uint8_t base, size_t length) {\n    size_t vl = vsetvl_e16m1(length);\n    vint16m1_t v_src = vle16_v_i16m1(src, vl);\n    vint16m1_t v_base = vmv_v_x_i16m1(base, vl);\n    vint16m1_t v_quotient = vdiv_vv_i16m1(v_src, v_base, vl);\n    vint16m1_t v_result = vmul_vv_i16m1(v_quotient, v_base, vl);\n    vse16_v_i16m1(dst, v_result, vl);\n}\n```"}
{"task_id": "SimdBench_31_RVV", "completion": "```c\nvoid nearest_multiple_simd(const int16_t* src, int16_t* dst, uint8_t base, size_t length) {\n    size_t vl = vsetvl_e16m1(length);\n    vint16m1_t v_src = vle16_v_i16m1(src, vl);\n    vint16m1_t v_base = vmv_v_x_i16m1(base, vl);\n    vint16m1_t v_quotient = vdiv_vv_i16m1(v_src, v_base, vl);\n    vint16m1_t v_result = vmul_vv_i16m1(v_quotient, v_base, vl);\n    vse16_v_i16m1(dst, v_result, vl);\n}\n```"}
{"task_id": "SimdBench_31_RVV", "completion": "```c\nvoid nearest_multiple_simd(const int16_t* src, int16_t* dst, uint8_t base, size_t length) {\n    size_t vl = vsetvl_e16m1(length);\n    vint16m1_t v_src = vle16_v_i16m1(src, vl);\n    vint16m1_t v_base = vmv_v_x_i16m1(base, vl);\n    vint16m1_t v_div = vdiv_vv_i16m1(v_src, v_base, vl);\n    vint16m1_t v_mul = vmul_vv_i16m1(v_div, v_base, vl);\n    vse16_v_i16m1(dst, v_mul, vl);\n}\n```"}
{"task_id": "SimdBench_31_RVV", "completion": "```c\nvoid nearest_multiple_simd(const int16_t* src, int16_t* dst, uint8_t base, size_t length) {\n    size_t vl = vsetvl_e16m1(length);\n    vint16m1_t v_src = vle16_v_i16m1(src, vl);\n    vint16m1_t v_base = vmv_v_x_i16m1(base, vl);\n    vint16m1_t v_quotient = vdiv_vv_i16m1(v_src, v_base, vl);\n    vint16m1_t v_result = vmul_vv_i16m1(v_quotient, v_base, vl);\n    vse16_v_i16m1(dst, v_result, vl);\n}\n```"}
{"task_id": "SimdBench_32_RVV", "completion": "```cpp\nbool matrix_has_row_simd(const double* matrix, const double* vector, size_t rows, size_t cols) {\n    size_t vl = __riscv_vsetvl_e64m8(cols);\n    vfloat64m8_t v_vector = __riscv_vle64_v_f64m8(vector, vl);\n\n    for (size_t i = 0; i < rows; ++i) {\n        vfloat64m8_t v_row = __riscv_vle64_v_f64m8(matrix + i * cols, vl);\n        vint64m8_t v_cmp = __riscv_vmseq_vv_f64m8_b64(v_row, v_vector, vl);\n        bool all_equal = __riscv_vmv_x_s_b64(__riscv_vmand_mm_b64(v_cmp, v_cmp, vl));\n        if (all_equal) {\n            return true;\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_32_RVV", "completion": "```c\nbool matrix_has_row_simd(const double* matrix, const double* vector, size_t rows, size_t cols) {\n    size_t vl = __riscv_vsetvl_e64m1(cols);\n    vfloat64m1_t v_vector = __riscv_vle64_v_f64m1(vector, vl);\n\n    for (size_t i = 0; i < rows; ++i) {\n        vfloat64m1_t v_row = __riscv_vle64_v_f64m1(matrix + i * cols, vl);\n        vint64m1_t v_eq = __riscv_vmseq_vv_f64m1_b64(v_row, v_vector, vl);\n        vint64m1_t v_all_eq = __riscv_vmand_mm_b64(v_eq, v_eq, vl);\n        if (__riscv_vmv_x_s_b64(v_all_eq)) {\n            return true;\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_32_RVV", "completion": "```c\nbool matrix_has_row_simd(const double* matrix, const double* vector, size_t rows, size_t cols) {\n    size_t vl = __riscv_vsetvl_e64m1(cols);\n    vfloat64m1_t v_vector = __riscv_vle64_v_f64m1(vector, vl);\n\n    for (size_t i = 0; i < rows; ++i) {\n        vfloat64m1_t v_row = __riscv_vle64_v_f64m1(matrix + i * cols, vl);\n        vbool64_t mask = __riscv_vmseq_vv_f64m1_b64(v_row, v_vector, vl);\n        if (__riscv_vcpop_m_b64(mask, vl) == vl) {\n            return true;\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_32_RVV", "completion": "```c\nbool matrix_has_row_simd(const double* matrix, const double* vector, size_t rows, size_t cols) {\n    size_t vl = __riscv_vsetvl_e64m1(cols);\n    vfloat64m1_t v_vector = __riscv_vle64_v_f64m1(vector, vl);\n\n    for (size_t i = 0; i < rows; ++i) {\n        vfloat64m1_t v_row = __riscv_vle64_v_f64m1(matrix + i * cols, vl);\n        vuint64m1_t v_match = __riscv_vmseq_vv_f64m1_b64(v_row, v_vector, vl);\n        uint64_t match = __riscv_vmv_x_s_u64m1_b64(v_match);\n\n        if (match == ((uint64_t)1 << vl) - 1) {\n            return true;\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_32_RVV", "completion": "```cpp\nbool matrix_has_row_simd(const double* matrix, const double* vector, size_t rows, size_t cols) {\n    size_t vl = vsetvl_e64m8(cols);\n    vfloat64m8_t v_vector = vle64_v_f64m8(vector, vl);\n\n    for (size_t i = 0; i < rows; ++i) {\n        vfloat64m8_t v_row = vle64_v_f64m8(matrix + i * cols, vl);\n        vuint64m8_t v_mask = vmseq_vv_f64m8_b64(v_row, v_vector, vl);\n        if (vmand_mm_b64(v_mask, vl)) {\n            return true;\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_33_RVV", "completion": "```cpp\nsize_t tensor_4d_equal_count_simd(const uint8_t* A, const uint8_t* B, const size_t dims[4]) {\n    size_t total_elements = dims[0] * dims[1] * dims[2] * dims[3];\n    size_t count = 0;\n    size_t vl;\n\n    for (size_t i = 0; i < total_elements; i += vl) {\n        vl = vsetvl_e8m1(total_elements - i);\n        vuint8m1_t va = vle8_v_u8m1(&A[i], vl);\n        vuint8m1_t vb = vle8_v_u8m1(&B[i], vl);\n        vuint1m1_t mask = vmseq_vv_u8m1_b8(va, vb, vl);\n        count += vpopc_m_b8(mask, vl);\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_33_RVV", "completion": "```c\nsize_t tensor_4d_equal_count_simd(const uint8_t* A, const uint8_t* B, const size_t dims[4]) {\n    size_t total_elements = dims[0] * dims[1] * dims[2] * dims[3];\n    size_t count = 0;\n    size_t vl;\n\n    for (size_t i = 0; i < total_elements; i += vl) {\n        vl = vsetvl_e8m1(total_elements - i);\n        vuint8m1_t va = vle8_v_u8m1(&A[i], vl);\n        vuint8m1_t vb = vle8_v_u8m1(&B[i], vl);\n        vuint1m1_t veq = vmseq_vv_u8m1_b8(va, vb, vl);\n        count += vpopc_m_b8(veq, vl);\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_33_RVV", "completion": "```cpp\nsize_t tensor_4d_equal_count_simd(const uint8_t* A, const uint8_t* B, const size_t dims[4]) {\n    size_t total_elements = dims[0] * dims[1] * dims[2] * dims[3];\n    size_t count = 0;\n    size_t vl;\n\n    for (size_t i = 0; i < total_elements; i += vl) {\n        vl = vsetvl_e8m8(total_elements - i);\n        vuint8m8_t va = vle8_v_u8m8(&A[i], vl);\n        vuint8m8_t vb = vle8_v_u8m8(&B[i], vl);\n        vuint1m8_t mask = vmseq_vv_u8m8_b8(va, vb, vl);\n        count += vpopc_m_b8(mask, vl);\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_33_RVV", "completion": "```c\nsize_t tensor_4d_equal_count_simd(const uint8_t* A, const uint8_t* B, const size_t dims[4]) {\n    size_t total_elements = dims[0] * dims[1] * dims[2] * dims[3];\n    size_t count = 0;\n    size_t vl;\n\n    for (size_t i = 0; i < total_elements; i += vl) {\n        vl = vsetvl_e8m1(total_elements - i);\n        vuint8m1_t va = vle8_v_u8m1(&A[i], vl);\n        vuint8m1_t vb = vle8_v_u8m1(&B[i], vl);\n        vuint1m1_t veq = vmseq_vv_u8m1_b8(va, vb, vl);\n        count += vpopc_m_b8(veq, vl);\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_33_RVV", "completion": "```c\nsize_t tensor_4d_equal_count_simd(const uint8_t* A, const uint8_t* B, const size_t dims[4]) {\n    size_t total_elements = dims[0] * dims[1] * dims[2] * dims[3];\n    size_t count = 0;\n    size_t vl;\n\n    for (size_t i = 0; i < total_elements; i += vl) {\n        vl = vsetvl_e8m1(total_elements - i);\n        vuint8m1_t va = vle8_v_u8m1(&A[i], vl);\n        vuint8m1_t vb = vle8_v_u8m1(&B[i], vl);\n        vuint8m1_t veq = vmseq_vv_u8m1_b8(va, vb, vl);\n        count += vpopc_m_b8(veq, vl);\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_34_RVV", "completion": "```c\nvoid axm_abs_simd(size_t length, const int64_t a, const int64_t *x, int64_t *y) {\n    size_t vl = __riscv_vsetvl_e64m1(length);\n    vint64m1_t va = __riscv_vmv_v_x_i64m1(a, vl);\n    vint64m1_t vx = __riscv_vle64_v_i64m1(x, vl);\n    vint64m1_t vy = __riscv_vabs_v_i64m1(vx, vl);\n    vy = __riscv_vmul_vv_i64m1(va, vy, vl);\n    __riscv_vse64_v_i64m1(y, vy, vl);\n}\n```"}
{"task_id": "SimdBench_34_RVV", "completion": "```c\nvoid axm_abs_simd(size_t length, const int64_t a, const int64_t *x, int64_t *y) {\n    size_t vl = vsetvl_e64m1(length);\n    vint64m1_t va = vbroadcast_e64(a, vl);\n    vint64m1_t vx = vle64_v_i64m1(x, vl);\n    vint64m1_t vy = vabs_v_i64m1(vx, vl);\n    vy = vsub_vv_i64m1(va, vy, vl);\n    vse64_v_i64m1(y, vy, vl);\n}\n```"}
{"task_id": "SimdBench_34_RVV", "completion": "```c\nvoid axm_abs_simd(size_t length, const int64_t a, const int64_t *x, int64_t *y) {\n    size_t vl = vsetvl_e64m1(length);\n    vint64m1_t va = vbroadcast_e64(a, vl);\n    vint64m1_t vx = vle64_v_i64m1(x, vl);\n    vint64m1_t vy = vabs_vx_i64m1(vx, vl);\n    vy = vsub_vv_i64m1(va, vy, vl);\n    vse64_v_i64m1(y, vy, vl);\n}\n```"}
{"task_id": "SimdBench_34_RVV", "completion": "```c\nvoid axm_abs_simd(size_t length, const int64_t a, const int64_t *x, int64_t *y) {\n    size_t vl = vsetvl_e64m1(length);\n    vint64m1_t va = vbroadcast_e64(a, vl);\n    vint64m1_t vx = vle64_v_i64m1(x, vl);\n    vint64m1_t vy = vabs_vx_i64m1(vx, vl);\n    vy = vsub_vv_i64m1(va, vy, vl);\n    vse64_v_i64m1(y, vy, vl);\n}\n```"}
{"task_id": "SimdBench_34_RVV", "completion": "```c\nvoid axm_abs_simd(size_t length, const int64_t a, const int64_t *x, int64_t *y) {\n    size_t vl = __riscv_vsetvl_e64m1(length);\n    vint64m1_t va = __riscv_vmv_v_x_i64m1(a, vl);\n    vint64m1_t vx = __riscv_vle64_v_i64m1(x, vl);\n    vint64m1_t vy = __riscv_vabs_v_i64m1(vx, vl);\n    vy = __riscv_vmul_vv_i64m1(va, vy, vl);\n    __riscv_vse64_v_i64m1(y, vy, vl);\n}\n```"}
{"task_id": "SimdBench_35_RVV", "completion": "```c\nMinMaxPair min_max_pair_simd(const int16_t* vec, size_t length) {\n    MinMaxPair result;\n    size_t vl = __riscv_vsetvl_e16m1(length);\n\n    vint16m1_t v_min = __riscv_vmv_v_x_i16m1(INT16_MAX, vl);\n    vint16m1_t v_max = __riscv_vmv_v_x_i16m1(INT16_MIN, vl);\n\n    for (size_t i = 0; i < length; i += vl) {\n        vl = __riscv_vsetvl_e16m1(length - i);\n        vint16m1_t v_vec = __riscv_vle16_v_i16m1(&vec[i], vl);\n\n        v_min = __riscv_vmin_vv_i16m1(v_min, v_vec, vl);\n        v_max = __riscv_vmax_vv_i16m1(v_max, v_vec, vl);\n    }\n\n    result.min_num = __riscv_vmv_x_s_i16m1_i16(__riscv_vredmin_vs_i16m1_i16(v_min, v_min, vl));\n    result.max_num = __riscv_vmv_x_s_i16m1_i16(__riscv_vredmax_vs_i16m1_i16(v_max, v_max, vl));\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_35_RVV", "completion": "```c\nMinMaxPair min_max_pair_simd(const int16_t* vec, size_t length) {\n    MinMaxPair result;\n    size_t vl = __riscv_vsetvl_e16m1(length);\n\n    vint16m1_t v_vec = __riscv_vle16_v_i16m1(vec, vl);\n    vint16m1_t v_min = __riscv_vredmin_vs_i16m1(v_vec, v_vec, vl);\n    vint16m1_t v_max = __riscv_vredmax_vs_i16m1(v_vec, v_vec, vl);\n\n    result.min_num = __riscv_vmv_x_s_i16m1_i16(v_min);\n    result.max_num = __riscv_vmv_x_s_i16m1_i16(v_max);\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_35_RVV", "completion": "```c\nMinMaxPair min_max_pair_simd(const int16_t* vec, size_t length) {\n    MinMaxPair result;\n    size_t vl = __riscv_vsetvl_e16m1(length);\n\n    vint16m1_t v_vec = __riscv_vle16_v_i16m1(vec, vl);\n    vint16m1_t v_min = __riscv_vredmin_vs_i16m1(v_vec, v_vec, vl);\n    vint16m1_t v_max = __riscv_vredmax_vs_i16m1(v_vec, v_vec, vl);\n\n    result.min_num = __riscv_vmv_x_s_i16m1_i16(v_min);\n    result.max_num = __riscv_vmv_x_s_i16m1_i16(v_max);\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_35_RVV", "completion": "```c\nMinMaxPair min_max_pair_simd(const int16_t* vec, size_t length) {\n    MinMaxPair result;\n    size_t vl = __riscv_vsetvl_e16m1(length);\n\n    vint16m1_t v_vec = __riscv_vle16_v_i16m1(vec, vl);\n    vint16m1_t v_min = __riscv_vmv_v_x_i16m1(INT16_MAX, vl);\n    vint16m1_t v_max = __riscv_vmv_v_x_i16m1(INT16_MIN, vl);\n\n    for (size_t i = 0; i < length; i += vl) {\n        vl = __riscv_vsetvl_e16m1(length - i);\n        v_vec = __riscv_vle16_v_i16m1(vec + i, vl);\n        v_min = __riscv_vmin_vv_i16m1(v_min, v_vec, vl);\n        v_max = __riscv_vmax_vv_i16m1(v_max, v_vec, vl);\n    }\n\n    result.min_num = __riscv_vmv_x_s_i16m1_i16(__riscv_vreducemin_vs_i16m1_i16m1(v_min, v_min, vl));\n    result.max_num = __riscv_vmv_x_s_i16m1_i16(__riscv_vreducemax_vs_i16m1_i16m1(v_max, v_max, vl));\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_35_RVV", "completion": "```c\nMinMaxPair min_max_pair_simd(const int16_t* vec, size_t length) {\n    MinMaxPair result;\n    size_t vl = __riscv_vsetvl_e16m1(length);\n\n    vint16m1_t v_min = __riscv_vmv_v_x_i16m1(INT16_MAX, vl);\n    vint16m1_t v_max = __riscv_vmv_v_x_i16m1(INT16_MIN, vl);\n\n    for (size_t i = 0; i < length; i += vl) {\n        vl = __riscv_vsetvl_e16m1(length - i);\n        vint16m1_t v_vec = __riscv_vle16_v_i16m1(&vec[i], vl);\n\n        v_min = __riscv_vmin_vv_i16m1(v_min, v_vec, vl);\n        v_max = __riscv_vmax_vv_i16m1(v_max, v_vec, vl);\n    }\n\n    result.min_num = __riscv_vmv_x_s_i16m1_i16(__riscv_vreducemin_vs_i16m1_i16(v_min, v_min, vl));\n    result.max_num = __riscv_vmv_x_s_i16m1_i16(__riscv_vreducemax_vs_i16m1_i16(v_max, v_max, vl));\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_36_RVV", "completion": "```cpp\nbool matrix_rows_strictly_increasing_simd(const int* matrix, size_t rows, size_t cols) {\n    if (rows == 0 || cols == 0) {\n        return false;\n    }\n\n    for (size_t i = 0; i < rows; ++i) {\n        const int* row = matrix + i * cols;\n        size_t j = 0;\n\n        while (j + 4 <= cols) {\n            vint32m1_t v0 = __riscv_vle32_v_i32m1(row + j, 4);\n            vint32m1_t v1 = __riscv_vle32_v_i32m1(row + j + 1, 4);\n            vint32m1_t vcmp = __riscv_vmslt_vv_i32m1(v0, v1, 4);\n\n            if (__riscv_vmv_x_s_i32m1_i32(vcmp) != 0) {\n                return false;\n            }\n\n            j += 4;\n        }\n\n        for (; j < cols - 1; ++j) {\n            if (row[j] >= row[j + 1]) {\n                return false;\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_36_RVV", "completion": "```c\nbool matrix_rows_strictly_increasing_simd(const int* matrix, size_t rows, size_t cols) {\n    if (rows == 0 || cols == 0) {\n        return false;\n    }\n\n    for (size_t i = 0; i < rows; ++i) {\n        const int* row = matrix + i * cols;\n        size_t j = 0;\n\n        while (j + 4 <= cols) {\n            vint32m1_t v0 = __riscv_vle32_v_i32m1(row + j, 4);\n            vint32m1_t v1 = __riscv_vle32_v_i32m1(row + j + 1, 4);\n            vint32m1_t vcmp = __riscv_vmslt_vv_i32m1(v0, v1, 4);\n\n            if (__riscv_vfirst_m(vcmp, 4) != -1) {\n                return false;\n            }\n\n            j += 4;\n        }\n\n        for (; j < cols - 1; ++j) {\n            if (row[j] >= row[j + 1]) {\n                return false;\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_36_RVV", "completion": "```cpp\nbool matrix_rows_strictly_increasing_simd(const int* matrix, size_t rows, size_t cols) {\n    if (rows == 0 || cols == 0) {\n        return false;\n    }\n\n    for (size_t i = 0; i < rows; ++i) {\n        const int* row = matrix + i * cols;\n        size_t j = 0;\n\n        while (j + 1 < cols) {\n            size_t vl = __riscv_vsetvl_e32m1(cols - j);\n            vint32m1_t v_a = __riscv_vle32_v_i32m1(row + j, vl);\n            vint32m1_t v_b = __riscv_vle32_v_i32m1(row + j + 1, vl);\n\n            vbool32_t mask = __riscv_vmslt_vv_i32m1_b32(v_a, v_b, vl);\n            if (__riscv_vfirst_m_b32(mask, vl) < vl) {\n                return false;\n            }\n\n            j += vl;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_36_RVV", "completion": "```cpp\nbool matrix_rows_strictly_increasing_simd(const int* matrix, size_t rows, size_t cols) {\n    if (rows == 0 || cols == 0) {\n        return false;\n    }\n\n    for (size_t i = 0; i < rows; ++i) {\n        const int* row = matrix + i * cols;\n        size_t j = 0;\n\n        while (j + 4 <= cols) {\n            vint32m1_t v0 = __riscv_vle32_v_i32m1(row + j, 4);\n            vint32m1_t v1 = __riscv_vle32_v_i32m1(row + j + 1, 4);\n            vint32m1_t vcmp = __riscv_vmslt_vv_i32m1(v0, v1, 4);\n\n            if (__riscv_vmv_x_s_i32m1_i32(vcmp) != 0) {\n                return false;\n            }\n\n            j += 4;\n        }\n\n        for (; j + 1 < cols; ++j) {\n            if (row[j] >= row[j + 1]) {\n                return false;\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_36_RVV", "completion": "```c\nbool matrix_rows_strictly_increasing_simd(const int* matrix, size_t rows, size_t cols) {\n    if (rows == 0 || cols == 0) {\n        return false;\n    }\n\n    for (size_t i = 0; i < rows; ++i) {\n        const int* row = matrix + i * cols;\n        size_t j = 0;\n\n        while (j + 4 <= cols) {\n            vint32m1_t v0 = __riscv_vle32_v_i32m1(row + j, 4);\n            vint32m1_t v1 = __riscv_vle32_v_i32m1(row + j + 1, 4);\n            vuint1m1_t mask = __riscv_vmslt_vv_i32m1(v0, v1, 4);\n\n            if (__riscv_vcpop_m(mask, 4) != 4) {\n                return false;\n            }\n\n            j += 4;\n        }\n\n        for (; j + 1 < cols; ++j) {\n            if (row[j] >= row[j + 1]) {\n                return false;\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_37_RVV", "completion": "```c\nbool matrix_blocks_equal_simd(const int* matrix, size_t block_size, size_t rows, size_t cols) {\n    if (block_size == 0 || block_size > rows || block_size > cols || rows % block_size != 0 || cols % block_size != 0) {\n        return false;\n    }\n\n    size_t num_blocks_row = rows / block_size;\n    size_t num_blocks_col = cols / block_size;\n\n    for (size_t block_row = 0; block_row < num_blocks_row; ++block_row) {\n        for (size_t block_col = 0; block_col < num_blocks_col; ++block_col) {\n            const int* block = matrix + block_row * block_size * cols + block_col * block_size;\n            for (size_t i = 0; i < block_size; ++i) {\n                for (size_t j = 0; j < block_size; ++j) {\n                    size_t vlen = __riscv_vsetvl_e32m1(block_size - j);\n                    vuint32m1_t v_block = __riscv_vle32_v_u32m1(block + i * cols + j, vlen);\n                    vuint32m1_t v_first_block = __riscv_vle32_v_u32m1(matrix + i * cols + j, vlen);\n                    vuint32m1_t v_cmp = __riscv_vmseq_vv_u32m1_b32(v_block, v_first_block, vlen);\n                    bool all_equal = __riscv_vmv_x_s_b32(__riscv_vmand_mm_b32(v_cmp, v_cmp, vlen));\n                    if (!all_equal) {\n                        return false;\n                    }\n                }\n            }\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_37_RVV", "completion": "```c\nbool matrix_blocks_equal_simd(const int* matrix, size_t block_size, size_t rows, size_t cols) {\n    if (block_size == 0 || rows % block_size != 0 || cols % block_size != 0) {\n        return false;\n    }\n\n    size_t num_blocks_row = rows / block_size;\n    size_t num_blocks_col = cols / block_size;\n\n    for (size_t block_row = 0; block_row < num_blocks_row; ++block_row) {\n        for (size_t block_col = 0; block_col < num_blocks_col; ++block_col) {\n            const int* block = matrix + block_row * block_size * cols + block_col * block_size;\n            const int* first_block = matrix;\n\n            for (size_t i = 0; i < block_size; ++i) {\n                size_t vl = vsetvl_e32m1(block_size);\n                vuint32m1_t v_block = vle32_v_u32m1(block + i * cols, vl);\n                vuint32m1_t v_first_block = vle32_v_u32m1(first_block + i * cols, vl);\n\n                vuint1m1_t v_cmp = vmseq_vv_u32m1_b32(v_block, v_first_block, vl);\n                bool all_equal = vmfirst_m_b32(v_cmp, vl) == 0;\n\n                if (!all_equal) {\n                    return false;\n                }\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_37_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nbool matrix_blocks_equal_simd(const int* matrix, size_t block_size, size_t rows, size_t cols) {\n    if (block_size == 0 || block_size > rows || block_size > cols || rows % block_size != 0 || cols % block_size != 0) {\n        return false;\n    }\n\n    size_t num_blocks_row = rows / block_size;\n    size_t num_blocks_col = cols / block_size;\n    size_t block_elements = block_size * block_size;\n\n    vint32m1_t first_block = __riscv_vle32_v_i32m1(matrix, block_elements, block_elements);\n\n    for (size_t i = 0; i < num_blocks_row; ++i) {\n        for (size_t j = 0; j < num_blocks_col; ++j) {\n            if (i == 0 && j == 0) continue;\n\n            size_t block_start = (i * block_size * cols + j * block_size);\n            vint32m1_t current_block = __riscv_vle32_v_i32m1(matrix + block_start, block_elements, block_elements);\n\n            vuint1m1_t mask = __riscv_vmseq_vv_i32m1_b32(first_block, current_block, block_elements);\n            bool all_equal = __riscv_vcpop_m_b32(mask, block_elements) == block_elements;\n\n            if (!all_equal) {\n                return false;\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_37_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n\nbool matrix_blocks_equal_simd(const int* matrix, size_t block_size, size_t rows, size_t cols) {\n    if (block_size == 0 || rows % block_size != 0 || cols % block_size != 0) {\n        return false;\n    }\n\n    size_t num_blocks_row = rows / block_size;\n    size_t num_blocks_col = cols / block_size;\n\n    for (size_t block_row = 0; block_row < num_blocks_row; ++block_row) {\n        for (size_t block_col = 0; block_col < num_blocks_col; ++block_col) {\n            const int* block = matrix + block_row * block_size * cols + block_col * block_size;\n\n            for (size_t i = 0; i < block_size; ++i) {\n                for (size_t j = 0; j < block_size; ++j) {\n                    size_t vlen = __riscv_vsetvl_e32m1(block_size - j);\n                    vint32m1_t vblock = __riscv_vle32_v_i32m1(block + i * cols + j, vlen);\n                    vint32m1_t vfirst_block = __riscv_vle32_v_i32m1(matrix + i * cols + j, vlen);\n\n                    if (!__riscv_vreduce_and_vm_i32m1(__riscv_vmseq_vv_i32m1_b32(vblock, vfirst_block, vlen), vlen)) {\n                        return false;\n                    }\n                }\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_37_RVV", "completion": "```cpp\nbool matrix_blocks_equal_simd(const int* matrix, size_t block_size, size_t rows, size_t cols) {\n    if (block_size == 0 || rows % block_size != 0 || cols % block_size != 0) {\n        return false;\n    }\n\n    size_t num_blocks_row = rows / block_size;\n    size_t num_blocks_col = cols / block_size;\n\n    for (size_t i = 0; i < num_blocks_row; ++i) {\n        for (size_t j = 0; j < num_blocks_col; ++j) {\n            const int* block = matrix + (i * block_size * cols + j * block_size);\n            for (size_t bi = 0; bi < block_size; ++bi) {\n                for (size_t bj = 0; bj < block_size; ++bj) {\n                    size_t vlen = __riscv_vsetvl_e32m1(block_size);\n                    vint32m1_t v_first_block = __riscv_vle32_v_i32m1(matrix, vlen);\n                    vint32m1_t v_current_block = __riscv_vle32_v_i32m1(block + bi * cols + bj, vlen);\n                    vint32m1_t v_equal = __riscv_vmseq_vv_i32m1_b32(v_first_block, v_current_block, vlen);\n                    if (!__riscv_vmv_x_s_b32m1(v_equal)) {\n                        return false;\n                    }\n                }\n            }\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_38_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n\nbool vector_block_equal_simd(const double* vec, double tolerance, size_t length, size_t block_size) {\n    if (block_size == 0 || length < block_size) {\n        return false;\n    }\n\n    size_t num_blocks = length / block_size;\n    if (num_blocks == 0) {\n        return false;\n    }\n\n    size_t vlmax = __riscv_vsetvlmax_e64m1();\n    vfloat64m1_t v_tolerance = __riscv_vfmv_v_f_f64m1(tolerance, vlmax);\n\n    for (size_t i = 0; i < num_blocks; ++i) {\n        size_t vl = __riscv_vsetvl_e64m1(block_size);\n        vfloat64m1_t v_block1 = __riscv_vle64_v_f64m1(vec, vl);\n        vfloat64m1_t v_block2 = __riscv_vle64_v_f64m1(vec + i * block_size, vl);\n\n        vbool64_t v_mask = __riscv_vmfne_vv_f64m1_b64(v_block1, v_block2, vl);\n        vfloat64m1_t v_diff = __riscv_vfsub_vv_f64m1(v_block1, v_block2, vl);\n        vfloat64m1_t v_abs_diff = __riscv_vfabs_v_f64m1(v_diff, vl);\n        vbool64_t v_tol_mask = __riscv_vmfgt_vv_f64m1_b64(v_abs_diff, v_tolerance, vl);\n\n        vbool64_t v_final_mask = __riscv_vmand_mm_b64(v_mask, v_tol_mask, vl);\n        if (__riscv_vfirst_m_b64(v_final_mask, vl) >= 0) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_38_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n\nbool vector_block_equal_simd(const double* vec, double tolerance, size_t length, size_t block_size) {\n    if (block_size == 0 || length < block_size) {\n        return false;\n    }\n\n    size_t num_blocks = length / block_size;\n    if (num_blocks < 2) {\n        return false;\n    }\n\n    size_t vl = __riscv_vsetvl_e64m1(block_size);\n    vfloat64m1_t v_first_block = __riscv_vle64_v_f64m1(vec, vl);\n    vfloat64m1_t v_tolerance = __riscv_vfmv_v_f_f64m1(tolerance, vl);\n\n    for (size_t i = 1; i < num_blocks; ++i) {\n        vfloat64m1_t v_current_block = __riscv_vle64_v_f64m1(vec + i * block_size, vl);\n        vbool64_t v_diff = __riscv_vmfgt_vv_f64m1_b64(v_first_block, v_current_block, vl);\n        vbool64_t v_diff2 = __riscv_vmfgt_vv_f64m1_b64(v_current_block, v_first_block, vl);\n        vbool64_t v_diff3 = __riscv_vmand_mm_b64(v_diff, v_diff2, vl);\n        vbool64_t v_diff4 = __riscv_vmfgt_vv_f64m1_b64(v_first_block, __riscv_vfsub_vv_f64m1(v_current_block, v_tolerance, vl), vl);\n        vbool64_t v_diff5 = __riscv_vmfgt_vv_f64m1_b64(__riscv_vfadd_vv_f64m1(v_first_block, v_tolerance, vl), v_current_block, vl);\n        vbool64_t v_diff6 = __riscv_vmand_mm_b64(v_diff4, v_diff5, vl);\n        vbool64_t v_diff7 = __riscv_vmand_mm_b64(v_diff3, v_diff6, vl);\n\n        if (__riscv_vcpop_m_b64(v_diff7, vl) > 0) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_38_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n\nbool vector_block_equal_simd(const double* vec, double tolerance, size_t length, size_t block_size) {\n    if (block_size == 0 || length < block_size) {\n        return false;\n    }\n\n    size_t num_blocks = length / block_size;\n    if (num_blocks == 0) {\n        return false;\n    }\n\n    size_t vlmax = __riscv_vsetvlmax_e64m1();\n    vfloat64m1_t v_tolerance = __riscv_vfmv_v_f_f64m1(tolerance, vlmax);\n\n    for (size_t i = 0; i < num_blocks; ++i) {\n        size_t vl = __riscv_vsetvl_e64m1(block_size);\n        vfloat64m1_t v_block1 = __riscv_vle64_v_f64m1(vec, vl);\n        vfloat64m1_t v_block2 = __riscv_vle64_v_f64m1(vec + i * block_size, vl);\n\n        vbool64_t v_mask = __riscv_vmfne_vf_f64m1_b64(v_block1, v_block2, vl);\n        vfloat64m1_t v_diff = __riscv_vfsub_vv_f64m1(v_block1, v_block2, vl);\n        vbool64_t v_diff_mask = __riscv_vmfgt_vf_f64m1_b64(v_diff, v_tolerance, vl);\n\n        vbool64_t v_result = __riscv_vmand_mm_b64(v_mask, v_diff_mask, vl);\n        if (__riscv_vcpop_m_b64(v_result, vl) > 0) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_38_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nbool vector_block_equal_simd(const double* vec, double tolerance, size_t length, size_t block_size) {\n    if (block_size == 0 || length < block_size) {\n        return false;\n    }\n\n    size_t num_blocks = length / block_size;\n    if (num_blocks == 0) {\n        return false;\n    }\n\n    size_t vlmax = __riscv_vsetvlmax_e64m1();\n    vfloat64m1_t v_tolerance = __riscv_vfmv_v_f_f64m1(tolerance, vlmax);\n    vfloat64m1_t v_first_block = __riscv_vle64_v_f64m1(vec, block_size, vlmax);\n\n    for (size_t i = 1; i < num_blocks; ++i) {\n        vfloat64m1_t v_current_block = __riscv_vle64_v_f64m1(vec + i * block_size, block_size, vlmax);\n        vbool64_t v_diff = __riscv_vmfgt_vv_f64m1_b64(v_current_block, v_first_block, vlmax);\n        v_diff = __riscv_vmor_mm_b64(v_diff, __riscv_vmflt_vv_f64m1_b64(v_current_block, v_first_block, vlmax), vlmax);\n        v_diff = __riscv_vmor_mm_b64(v_diff, __riscv_vmfgt_vv_f64m1_b64(v_current_block, __riscv_vfadd_vv_f64m1(v_first_block, v_tolerance, vlmax), vlmax), vlmax);\n        v_diff = __riscv_vmor_mm_b64(v_diff, __riscv_vmflt_vv_f64m1_b64(v_current_block, __riscv_vfsub_vv_f64m1(v_first_block, v_tolerance, vlmax), vlmax), vlmax);\n\n        if (__riscv_vcpop_m_b64(v_diff, vlmax) > 0) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_38_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nbool vector_block_equal_simd(const double* vec, double tolerance, size_t length, size_t block_size) {\n    if (block_size == 0 || block_size > length) {\n        return false;\n    }\n\n    size_t num_blocks = length / block_size;\n    if (num_blocks < 2) {\n        return false;\n    }\n\n    size_t vlmax = __riscv_vsetvlmax_e64m1();\n    vfloat64m1_t v_tolerance = __riscv_vfmv_v_f_f64m1(tolerance, vlmax);\n\n    for (size_t i = 0; i < num_blocks; ++i) {\n        size_t vl = __riscv_vsetvl_e64m1(block_size);\n        vfloat64m1_t v_block = __riscv_vle64_v_f64m1(vec + i * block_size, vl);\n\n        for (size_t j = i + 1; j < num_blocks; ++j) {\n            vfloat64m1_t v_other_block = __riscv_vle64_v_f64m1(vec + j * block_size, vl);\n            vbool64_t v_mask = __riscv_vmfne_vv_f64m1_b64(v_block, v_other_block, vl);\n            vfloat64m1_t v_diff = __riscv_vfsub_vv_f64m1(v_block, v_other_block, vl);\n            vfloat64m1_t v_abs_diff = __riscv_vfabs_v_f64m1(v_diff, vl);\n            vbool64_t v_tol_mask = __riscv_vmfgt_vv_f64m1_b64(v_abs_diff, v_tolerance, vl);\n            vbool64_t v_final_mask = __riscv_vmand_mm_b64(v_mask, v_tol_mask, vl);\n\n            if (__riscv_vmv_x_s_b64(v_final_mask, vl)) {\n                return false;\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_39_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid matrix_row_norm_compare_simd(const double* matrix, const double* thresholds, size_t rows, size_t cols, bool* result) {\n    size_t vl = vsetvl_e64m1(cols);\n    for (size_t i = 0; i < rows; ++i) {\n        vfloat64m1_t v_row = vle64_v_f64m1(&matrix[i * cols], vl);\n        vfloat64m1_t v_squared = vfmul_vv_f64m1(v_row, v_row, vl);\n        vfloat64m1_t v_sum = vfredusum_vs_f64m1_f64m1(v_sum, v_squared, v_sum, vl);\n        double sum = vfmv_f_s_f64m1_f64(v_sum);\n        double norm = sqrt(sum);\n        result[i] = (norm > thresholds[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_39_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n\nvoid matrix_row_norm_compare_simd(const double* matrix, const double* thresholds, size_t rows, size_t cols, bool* result) {\n    size_t vl;\n    for (size_t i = 0; i < rows; ++i) {\n        vfloat64m1_t v_row = vle64_v_f64m1(&matrix[i * cols], cols, &vl);\n        vfloat64m1_t v_squared = vfmul_vv_f64m1(v_row, v_row, vl);\n        vfloat64m1_t v_sum = vfredusum_vs_f64m1_f64m1(v_sum, v_squared, v_sum, vl);\n        double sum = vfmv_f_s_f64m1_f64(v_sum);\n        double norm = sqrt(sum);\n        result[i] = (norm > thresholds[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_39_RVV", "completion": "```c\nvoid matrix_row_norm_compare_simd(const double* matrix, const double* thresholds, size_t rows, size_t cols, bool* result) {\n    size_t vl = __riscv_vsetvl_e64m1(cols);\n    for (size_t i = 0; i < rows; ++i) {\n        vfloat64m1_t row = __riscv_vle64_v_f64m1(&matrix[i * cols], vl);\n        vfloat64m1_t squared_row = __riscv_vfmul_vv_f64m1(row, row, vl);\n        vfloat64m1_t sum = __riscv_vfredusum_vs_f64m1_f64m1(squared_row, __riscv_vfmv_v_f_f64m1(0.0, vl), vl);\n        double norm = __riscv_vfmv_f_s_f64m1_f64(sum);\n        result[i] = (norm > thresholds[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_39_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid matrix_row_norm_compare_simd(const double* matrix, const double* thresholds, size_t rows, size_t cols, bool* result) {\n    size_t vl = vsetvl_e64m1(cols);\n    for (size_t i = 0; i < rows; ++i) {\n        vfloat64m1_t v_row = vle64_v_f64m1(&matrix[i * cols], vl);\n        vfloat64m1_t v_squared = vfmul_vv_f64m1(v_row, v_row, vl);\n        vfloat64m1_t v_sum = vfredusum_vs_f64m1_f64m1(v_sum, v_squared, v_sum, vl);\n        double sum = vfmv_f_s_f64m1_f64(v_sum);\n        double norm = sqrt(sum);\n        result[i] = (norm > thresholds[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_39_RVV", "completion": "```c\nvoid matrix_row_norm_compare_simd(const double* matrix, const double* thresholds, size_t rows, size_t cols, bool* result) {\n    size_t vl = __riscv_vsetvl_e64m1(cols);\n    for (size_t i = 0; i < rows; ++i) {\n        vfloat64m1_t row = __riscv_vle64_v_f64m1(&matrix[i * cols], vl);\n        vfloat64m1_t squared_row = __riscv_vfmul_vv_f64m1(row, row, vl);\n        vfloat64m1_t sum = __riscv_vfredusum_vs_f64m1_f64m1(squared_row, __riscv_vfmv_v_f_f64m1(0.0, vl), vl);\n        double norm = __riscv_vfmv_f_s_f64m1_f64(sum);\n        result[i] = (norm > thresholds[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_40_RVV", "completion": "```c\nvoid tensor_bitwise_or_simd(const uint32_t* A, const uint32_t* B, uint32_t* C, size_t length) {\n    size_t vl = __riscv_vsetvl_e32m1(length);\n    for (size_t i = 0; i < length; i += vl) {\n        vuint32m1_t va = __riscv_vle32_v_u32m1(&A[i], vl);\n        vuint32m1_t vb = __riscv_vle32_v_u32m1(&B[i], vl);\n        vuint32m1_t vc = __riscv_vor_vv_u32m1(va, vb, vl);\n        __riscv_vse32_v_u32m1(&C[i], vc, vl);\n        vl = __riscv_vsetvl_e32m1(length - i - vl);\n    }\n}\n```"}
{"task_id": "SimdBench_40_RVV", "completion": "```c\nvoid tensor_bitwise_or_simd(const uint32_t* A, const uint32_t* B, uint32_t* C, size_t length) {\n    size_t vl = __riscv_vsetvl_e32m1(length);\n    for (size_t i = 0; i < length; i += vl) {\n        vl = __riscv_vsetvl_e32m1(length - i);\n        vuint32m1_t va = __riscv_vle32_v_u32m1(&A[i], vl);\n        vuint32m1_t vb = __riscv_vle32_v_u32m1(&B[i], vl);\n        vuint32m1_t vc = __riscv_vor_vv_u32m1(va, vb, vl);\n        __riscv_vse32_v_u32m1(&C[i], vc, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_40_RVV", "completion": "```c\nvoid tensor_bitwise_or_simd(const uint32_t* A, const uint32_t* B, uint32_t* C, size_t length) {\n    size_t vl = __riscv_vsetvl_e32m1(length);\n    for (size_t i = 0; i < length; i += vl) {\n        vuint32m1_t va = __riscv_vle32_v_u32m1(&A[i], vl);\n        vuint32m1_t vb = __riscv_vle32_v_u32m1(&B[i], vl);\n        vuint32m1_t vc = __riscv_vor_vv_u32m1(va, vb, vl);\n        __riscv_vse32_v_u32m1(&C[i], vc, vl);\n        vl = __riscv_vsetvl_e32m1(length - i - vl);\n    }\n}\n```"}
{"task_id": "SimdBench_40_RVV", "completion": "```c\nvoid tensor_bitwise_or_simd(const uint32_t* A, const uint32_t* B, uint32_t* C, size_t length) {\n    size_t vl = __riscv_vsetvl_e32m1(length);\n    for (size_t i = 0; i < length; i += vl) {\n        vuint32m1_t va = __riscv_vle32_v_u32m1(&A[i], vl);\n        vuint32m1_t vb = __riscv_vle32_v_u32m1(&B[i], vl);\n        vuint32m1_t vc = __riscv_vor_vv_u32m1(va, vb, vl);\n        __riscv_vse32_v_u32m1(&C[i], vc, vl);\n        vl = __riscv_vsetvl_e32m1(length - i - vl);\n    }\n}\n```"}
{"task_id": "SimdBench_40_RVV", "completion": "```cpp\nvoid tensor_bitwise_or_simd(const uint32_t* A, const uint32_t* B, uint32_t* C, size_t length) {\n    size_t vl = __riscv_vsetvl_e32m1(length);\n    for (size_t i = 0; i < length; i += vl) {\n        vl = __riscv_vsetvl_e32m1(length - i);\n        vuint32m1_t va = __riscv_vle32_v_u32m1(&A[i], vl);\n        vuint32m1_t vb = __riscv_vle32_v_u32m1(&B[i], vl);\n        vuint32m1_t vc = __riscv_vor_vv_u32m1(va, vb, vl);\n        __riscv_vse32_v_u32m1(&C[i], vc, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_41_RVV", "completion": "```c\nint64_t squarediff_simd(const int8_t * A, const int8_t * B, size_t length) {\n    size_t vl = vsetvl_e8m1(length);\n    vint8m1_t va = vle8_v_i8m1(A, vl);\n    vint8m1_t vb = vle8_v_i8m1(B, vl);\n\n    vint16m2_t va_squared = vwmul_vv_i16m2(va, va, vl);\n    vint16m2_t vb_squared = vwmul_vv_i16m2(vb, vb, vl);\n    vint16m2_t vprod = vwmul_vv_i16m2(va, vb, vl);\n\n    vint32m4_t va_squared_w = vwadd_vv_i32m4(va_squared, va_squared, vl);\n    vint32m4_t vb_squared_w = vwadd_vv_i32m4(vb_squared, vb_squared, vl);\n    vint32m4_t vprod_w = vwadd_vv_i32m4(vprod, vprod, vl);\n\n    vint64m8_t va_squared_d = vwadd_vv_i64m8(va_squared_w, va_squared_w, vl);\n    vint64m8_t vb_squared_d = vwadd_vv_i64m8(vb_squared_w, vb_squared_w, vl);\n    vint64m8_t vprod_d = vwadd_vv_i64m8(vprod_w, vprod_w, vl);\n\n    int64_t sum_squares = vsum_vs_i64m8_i64(va_squared_d, vb_squared_d, vl);\n    int64_t sum_products = vsum_vs_i64m8_i64(vprod_d, vprod_d, vl);\n\n    return sum_squares - sum_products;\n}\n```"}
{"task_id": "SimdBench_41_RVV", "completion": "```c\nint64_t squarediff_simd(const int8_t * A, const int8_t * B, size_t length) {\n    size_t vl = vsetvl_e8m1(length);\n    vint8m1_t va = vle8_v_i8m1(A, vl);\n    vint8m1_t vb = vle8_v_i8m1(B, vl);\n\n    vint16m2_t va_squared = vwmul_vv_i16m2(va, va, vl);\n    vint16m2_t vb_squared = vwmul_vv_i16m2(vb, vb, vl);\n    vint16m2_t vprod = vwmul_vv_i16m2(va, vb, vl);\n\n    vint32m4_t va_squared_w = vwadd_vv_i32m4(va_squared, va_squared, vl);\n    vint32m4_t vb_squared_w = vwadd_vv_i32m4(vb_squared, vb_squared, vl);\n    vint32m4_t vprod_w = vwadd_vv_i32m4(vprod, vprod, vl);\n\n    vint64m8_t va_squared_d = vwadd_vv_i64m8(va_squared_w, va_squared_w, vl);\n    vint64m8_t vb_squared_d = vwadd_vv_i64m8(vb_squared_w, vb_squared_w, vl);\n    vint64m8_t vprod_d = vwadd_vv_i64m8(vprod_w, vprod_w, vl);\n\n    int64_t sum_squares = vsum_vv_i64m8_i64m1(va_squared_d, vb_squared_d, vl);\n    int64_t sum_products = vsum_vv_i64m8_i64m1(vprod_d, vprod_d, vl);\n\n    return sum_squares - sum_products;\n}\n```"}
{"task_id": "SimdBench_41_RVV", "completion": "```c\nint64_t squarediff_simd(const int8_t * A, const int8_t * B, size_t length) {\n    size_t vl = vsetvl_e8m1(length);\n    vint8m1_t va = vle8_v_i8m1(A, vl);\n    vint8m1_t vb = vle8_v_i8m1(B, vl);\n\n    vint16m2_t va_squared = vwmul_vv_i16m2(va, va, vl);\n    vint16m2_t vb_squared = vwmul_vv_i16m2(vb, vb, vl);\n    vint16m2_t vprod = vwmul_vv_i16m2(va, vb, vl);\n\n    vint32m4_t va_squared_w = vwadd_vv_i32m4(va_squared, va_squared, vl);\n    vint32m4_t vb_squared_w = vwadd_vv_i32m4(vb_squared, vb_squared, vl);\n    vint32m4_t vprod_w = vwadd_vv_i32m4(vprod, vprod, vl);\n\n    vint64m8_t va_squared_d = vwadd_vv_i64m8(va_squared_w, va_squared_w, vl);\n    vint64m8_t vb_squared_d = vwadd_vv_i64m8(vb_squared_w, vb_squared_w, vl);\n    vint64m8_t vprod_d = vwadd_vv_i64m8(vprod_w, vprod_w, vl);\n\n    int64_t sum_squares = vsum_vv_i64m8_i64(va_squared_d, vb_squared_d, vl);\n    int64_t sum_prod = vsum_vv_i64m8_i64(vprod_d, vprod_d, vl);\n\n    return sum_squares - sum_prod;\n}\n```"}
{"task_id": "SimdBench_41_RVV", "completion": "```c\nint64_t squarediff_simd(const int8_t * A, const int8_t * B, size_t length) {\n    size_t vl = vsetvl_e8m1(length);\n    vint8m1_t va = vle8_v_i8m1(A, vl);\n    vint8m1_t vb = vle8_v_i8m1(B, vl);\n\n    vint16m2_t va_squared = vwmul_vv_i16m2(va, va, vl);\n    vint16m2_t vb_squared = vwmul_vv_i16m2(vb, vb, vl);\n    vint16m2_t vprod = vmul_vv_i16m2(va, vb, vl);\n\n    vint32m4_t va_squared_w = vwadd_vv_i32m4(va_squared, va_squared, vl);\n    vint32m4_t vb_squared_w = vwadd_vv_i32m4(vb_squared, vb_squared, vl);\n    vint32m4_t vprod_w = vwadd_vv_i32m4(vprod, vprod, vl);\n\n    vint64m8_t va_squared_d = vwadd_vv_i64m8(va_squared_w, va_squared_w, vl);\n    vint64m8_t vb_squared_d = vwadd_vv_i64m8(vb_squared_w, vb_squared_w, vl);\n    vint64m8_t vprod_d = vwadd_vv_i64m8(vprod_w, vprod_w, vl);\n\n    int64_t sum_squares = vredsum_vs_i64m8_i64m1(va_squared_d, vb_squared_d, vl);\n    int64_t sum_products = vredsum_vs_i64m8_i64m1(vprod_d, vprod_d, vl);\n\n    return sum_squares - sum_products;\n}\n```"}
{"task_id": "SimdBench_41_RVV", "completion": "```c\nint64_t squarediff_simd(const int8_t * A, const int8_t * B, size_t length) {\n    size_t vl = vsetvl_e8m1(length);\n    vint8m1_t va = vle8_v_i8m1(A, vl);\n    vint8m1_t vb = vle8_v_i8m1(B, vl);\n\n    vint16m2_t va_squared = vwmul_vv_i16m2(va, va, vl);\n    vint16m2_t vb_squared = vwmul_vv_i16m2(vb, vb, vl);\n    vint16m2_t va_vb = vwmul_vv_i16m2(va, vb, vl);\n\n    vint32m4_t va_squared_sum = vredsum_vs_i32m4(vcvt_x_i32m4(va_squared), vint32m4_t(0), vl);\n    vint32m4_t vb_squared_sum = vredsum_vs_i32m4(vcvt_x_i32m4(vb_squared), vint32m4_t(0), vl);\n    vint32m4_t va_vb_sum = vredsum_vs_i32m4(vcvt_x_i32m4(va_vb), vint32m4_t(0), vl);\n\n    int32_t sum_squares = vadd_vv_i32m4(va_squared_sum, vb_squared_sum, vl);\n    int32_t sum_products = va_vb_sum;\n\n    return sum_squares - sum_products;\n}\n```"}
{"task_id": "SimdBench_42_RVV", "completion": "```c\nvoid tensor_bit_clear_simd(const uint64_t* A, const uint64_t* B, uint64_t* C, size_t length) {\n    size_t vl = __riscv_vsetvl_e64m8(length);\n    for (size_t i = 0; i < length; i += vl) {\n        vl = __riscv_vsetvl_e64m8(length - i);\n        vuint64m8_t va = __riscv_vle64_v_u64m8(&A[i], vl);\n        vuint64m8_t vb = __riscv_vle64_v_u64m8(&B[i], vl);\n        vuint64m8_t vb_not = __riscv_vnot_v_u64m8(vb, vl);\n        vuint64m8_t vc = __riscv_vand_vv_u64m8(va, vb_not, vl);\n        __riscv_vse64_v_u64m8(&C[i], vc, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_42_RVV", "completion": "```c\nvoid tensor_bit_clear_simd(const uint64_t* A, const uint64_t* B, uint64_t* C, size_t length) {\n    size_t vl = __riscv_vsetvl_e64m8(length);\n    for (size_t i = 0; i < length; i += vl) {\n        vl = __riscv_vsetvl_e64m8(length - i);\n        vuint64m8_t va = __riscv_vle64_v_u64m8(&A[i], vl);\n        vuint64m8_t vb = __riscv_vle64_v_u64m8(&B[i], vl);\n        vuint64m8_t vb_not = __riscv_vnot_v_u64m8(vb, vl);\n        vuint64m8_t vc = __riscv_vand_vv_u64m8(va, vb_not, vl);\n        __riscv_vse64_v_u64m8(&C[i], vc, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_42_RVV", "completion": "```c\nvoid tensor_bit_clear_simd(const uint64_t* A, const uint64_t* B, uint64_t* C, size_t length) {\n    size_t vl = __riscv_vsetvl_e64m8(length);\n    for (size_t i = 0; i < length; i += vl) {\n        vl = __riscv_vsetvl_e64m8(length - i);\n        vuint64m8_t va = __riscv_vle64_v_u64m8(&A[i], vl);\n        vuint64m8_t vb = __riscv_vle64_v_u64m8(&B[i], vl);\n        vuint64m8_t vnot_b = __riscv_vnot_v_u64m8(vb, vl);\n        vuint64m8_t vc = __riscv_vand_vv_u64m8(va, vnot_b, vl);\n        __riscv_vse64_v_u64m8(&C[i], vc, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_42_RVV", "completion": "```c\nvoid tensor_bit_clear_simd(const uint64_t* A, const uint64_t* B, uint64_t* C, size_t length) {\n    size_t vl = __riscv_vsetvl_e64m8(length);\n    for (size_t i = 0; i < length; i += vl) {\n        vl = __riscv_vsetvl_e64m8(length - i);\n        vuint64m8_t va = __riscv_vle64_v_u64m8(&A[i], vl);\n        vuint64m8_t vb = __riscv_vle64_v_u64m8(&B[i], vl);\n        vuint64m8_t vnot_b = __riscv_vnot_v_u64m8(vb, vl);\n        vuint64m8_t vc = __riscv_vand_vv_u64m8(va, vnot_b, vl);\n        __riscv_vse64_v_u64m8(&C[i], vc, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_42_RVV", "completion": "```c\nvoid tensor_bit_clear_simd(const uint64_t* A, const uint64_t* B, uint64_t* C, size_t length) {\n    size_t vlmax = __riscv_vsetvlmax_e64m8();\n    for (size_t i = 0; i < length; i += vlmax) {\n        size_t vl = __riscv_vsetvl_e64m8(length - i);\n        vuint64m8_t va = __riscv_vle64_v_u64m8(&A[i], vl);\n        vuint64m8_t vb = __riscv_vle64_v_u64m8(&B[i], vl);\n        vuint64m8_t vnot_b = __riscv_vnot_v_u64m8(vb, vl);\n        vuint64m8_t vc = __riscv_vand_vv_u64m8(va, vnot_b, vl);\n        __riscv_vse64_v_u64m8(&C[i], vc, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_43_RVV", "completion": "```c\nvoid tensor_three_valued_logic_simd(const int8_t* A, const int8_t* B, int8_t* C, size_t length) {\n    size_t vl = __riscv_vsetvl_e8m1(length);\n    for (size_t i = 0; i < length; i += vl) {\n        vl = __riscv_vsetvl_e8m1(length - i);\n        vuint8m1_t va = __riscv_vle8_v_u8m1(&A[i], vl);\n        vuint8m1_t vb = __riscv_vle8_v_u8m1(&B[i], vl);\n        vuint8m1_t vpos = __riscv_vand_vv_u8m1(va, vb, vl);\n        vuint8m1_t vneg = __riscv_vand_vv_u8m1(__riscv_vnot_v_u8m1(va, vl), __riscv_vnot_v_u8m1(vb, vl), vl);\n        vuint8m1_t vres = __riscv_vmerge_vvm_u8m1(vneg, vpos, vpos, vl);\n        __riscv_vse8_v_u8m1(&C[i], vres, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_43_RVV", "completion": "```c\nvoid tensor_three_valued_logic_simd(const int8_t* A, const int8_t* B, int8_t* C, size_t length) {\n    size_t vl = __riscv_vsetvl_e8m1(length);\n    for (size_t i = 0; i < length; i += vl) {\n        vl = __riscv_vsetvl_e8m1(length - i);\n        vuint8m1_t va = __riscv_vle8_v_i8m1(&A[i], vl);\n        vuint8m1_t vb = __riscv_vle8_v_i8m1(&B[i], vl);\n        vuint8m1_t vc = __riscv_vmerge_vvm_i8m1(va, vb, va, vl);\n        vuint8m1_t v1 = __riscv_vmv_v_x_i8m1(1, vl);\n        vuint8m1_t vm1 = __riscv_vmv_v_x_i8m1(-1, vl);\n        vuint8m1_t v0 = __riscv_vmv_v_x_i8m1(0, vl);\n        vuint8m1_t vcmp1 = __riscv_vmsgt_vx_i8m1_bm(va, 0, vl);\n        vuint8m1_t vcmp2 = __riscv_vmsgt_vx_i8m1_bm(vb, 0, vl);\n        vuint8m1_t vcmp3 = __riscv_vmslt_vx_i8m1_bm(va, 0, vl);\n        vuint8m1_t vcmp4 = __riscv_vmslt_vx_i8m1_bm(vb, 0, vl);\n        vuint8m1_t vcmp5 = __riscv_vmand_mm_bm(vcmp1, vcmp2, vl);\n        vuint8m1_t vcmp6 = __riscv_vmand_mm_bm(vcmp3, vcmp4, vl);\n        vuint8m1_t vcmp7 = __riscv_vmandnot_mm_bm(vcmp5, vcmp6, vl);\n        vuint8m1_t vcmp8 = __riscv_vmandnot_mm_bm(vcmp6, vcmp5, vl);\n        vuint8m1_t vcmp9 = __riscv_vmandnot_mm_bm(vcmp7, vcmp8, vl);\n        vuint8m1_t vresult = __riscv_vmerge_vvm_i8m1(v1, vm1, vcmp5, vl);\n        vresult = __riscv_vmerge_vvm_i8m1(vresult, v0, vcmp9, vl);\n        __riscv_vse8_v_i8m1(&C[i], vresult, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_43_RVV", "completion": "```c\nvoid tensor_three_valued_logic_simd(const int8_t* A, const int8_t* B, int8_t* C, size_t length) {\n    size_t vl = __riscv_vsetvl_e8m1(length);\n    for (size_t i = 0; i < length; i += vl) {\n        vl = __riscv_vsetvl_e8m1(length - i);\n        vuint8m1_t va = __riscv_vle8_v_i8m1(&A[i], vl);\n        vuint8m1_t vb = __riscv_vle8_v_i8m1(&B[i], vl);\n        vuint8m1_t vc = __riscv_vmerge_vxm_i8m1(0, __riscv_vmseq_vx_i8m1_b8(va, vb, 0), 1, vl);\n        vc = __riscv_vmerge_vxm_i8m1(vc, __riscv_vmsne_vx_i8m1_b8(va, vb, 0), -1, vl);\n        __riscv_vse8_v_i8m1(&C[i], vc, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_43_RVV", "completion": "```cpp\nvoid tensor_three_valued_logic_simd(const int8_t* A, const int8_t* B, int8_t* C, size_t length) {\n    size_t vl = __riscv_vsetvl_e8m1(length);\n    for (size_t i = 0; i < length; i += vl) {\n        vl = __riscv_vsetvl_e8m1(length - i);\n        vuint8m1_t va = __riscv_vle8_v_i8m1(&A[i], vl);\n        vuint8m1_t vb = __riscv_vle8_v_i8m1(&B[i], vl);\n        vuint8m1_t vc = __riscv_vmerge_vxm1(__riscv_vmseq_vx_i8m1_b1(va, vb, 0), __riscv_vmsne_vx_i8m1_b1(va, vb, 0), 1, vl);\n        __riscv_vse8_v_i8m1(&C[i], vc, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_43_RVV", "completion": "```c\nvoid tensor_three_valued_logic_simd(const int8_t* A, const int8_t* B, int8_t* C, size_t length) {\n    size_t vl = __riscv_vsetvl_e8m1(length);\n    for (size_t i = 0; i < length; i += vl) {\n        vl = __riscv_vsetvl_e8m1(length - i);\n        vuint8m1_t va = __riscv_vle8_v_i8m1(&A[i], vl);\n        vuint8m1_t vb = __riscv_vle8_v_i8m1(&B[i], vl);\n        vuint8m1_t vc = __riscv_vmerge_vvm_i8m1(\n            __riscv_vmerge_vvm_i8m1(\n                __riscv_vmv_v_x_i8m1(0, vl),\n                __riscv_vmv_v_x_i8m1(1, vl),\n                __riscv_vmsgt_vx_i8m1_bm(va, 0, vl)\n            ),\n            __riscv_vmv_v_x_i8m1(-1, vl),\n            __riscv_vmslt_vx_i8m1_bm(vb, 0, vl)\n        );\n        __riscv_vse8_v_i8m1(&C[i], vc, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_44_RVV", "completion": "```c\nvoid tensor_bit_op_simd(const uint16_t* A, const uint16_t* B, uint16_t* C, size_t length) {\n    size_t midpoint = length / 2;\n\n    size_t vl = __riscv_vsetvl_e16m1(length);\n    vuint16m1_t va = __riscv_vle16_v_u16m1(A, vl);\n    vuint16m1_t vb = __riscv_vle16_v_u16m1(B, vl);\n\n    vuint16m1_t vxor = __riscv_vxor_vv_u16m1(va, vb, vl);\n    vuint16m1_t vand = __riscv_vand_vv_u16m1(va, vb, vl);\n\n    for (size_t i = 0; i < midpoint; i++) {\n        C[i] = vxor[i];\n    }\n\n    for (size_t i = midpoint; i < length; i++) {\n        C[i] = va[i];\n    }\n\n    for (size_t i = midpoint; i < length; i++) {\n        C[i] = vand[i];\n    }\n}\n```"}
{"task_id": "SimdBench_44_RVV", "completion": "```c\nvoid tensor_bit_op_simd(const uint16_t* A, const uint16_t* B, uint16_t* C, size_t length) {\n    size_t vl = __riscv_vsetvl_e16m1(length);\n    size_t midpoint = length / 2;\n\n    for (size_t i = 0; i < length; i += vl) {\n        size_t current_vl = __riscv_vsetvl_e16m1(length - i);\n\n        vuint16m1_t va = __riscv_vle16_v_u16m1(&A[i], current_vl);\n        vuint16m1_t vb = __riscv_vle16_v_u16m1(&B[i], current_vl);\n\n        vuint16m1_t vxor = __riscv_vxor_vv_u16m1(va, vb, current_vl);\n        vuint16m1_t vand = __riscv_vand_vv_u16m1(va, vb, current_vl);\n\n        vuint16m1_t vresult = __riscv_vmerge_vvm_u16m1(vxor, va, (i + current_vl <= midpoint), current_vl);\n        vresult = __riscv_vmerge_vvm_u16m1(vresult, vand, (i < midpoint), current_vl);\n\n        __riscv_vse16_v_u16m1(&C[i], vresult, current_vl);\n    }\n}\n```"}
{"task_id": "SimdBench_44_RVV", "completion": "```c\nvoid tensor_bit_op_simd(const uint16_t* A, const uint16_t* B, uint16_t* C, size_t length) {\n    size_t vl = __riscv_vsetvl_e16m1(length);\n    size_t midpoint = length / 2;\n\n    for (size_t i = 0; i < length; i += vl) {\n        size_t vl = __riscv_vsetvl_e16m1(length - i);\n\n        vuint16m1_t va = __riscv_vle16_v_u16m1(&A[i], vl);\n        vuint16m1_t vb = __riscv_vle16_v_u16m1(&B[i], vl);\n\n        vuint16m1_t vxor = __riscv_vxor_vv_u16m1(va, vb, vl);\n        vuint16m1_t vand = __riscv_vand_vv_u16m1(va, vb, vl);\n\n        vuint16m1_t vresult = __riscv_vmerge_vvm_u16m1(vand, vxor, (i < midpoint), vl);\n\n        if (i + vl > midpoint) {\n            size_t offset = midpoint - i;\n            vuint16m1_t vmid = __riscv_vslideup_vx_u16m1(va, 0, offset);\n            vresult = __riscv_vmerge_vvm_u16m1(vresult, vmid, (i < midpoint), vl);\n        }\n\n        __riscv_vse16_v_u16m1(&C[i], vresult, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_44_RVV", "completion": "```c\nvoid tensor_bit_op_simd(const uint16_t* A, const uint16_t* B, uint16_t* C, size_t length) {\n    size_t i = 0;\n    size_t midpoint = length / 2;\n\n    for (; i <= midpoint - vsetvl_e16m1(length - i); i += vsetvl_e16m1(length - i)) {\n        vuint16m1_t va = vle16_v_u16m1(&A[i], vsetvl_e16m1(length - i));\n        vuint16m1_t vb = vle16_v_u16m1(&B[i], vsetvl_e16m1(length - i));\n\n        vuint16m1_t vresult;\n        if (i < midpoint) {\n            vresult = vxor_vv_u16m1(va, vb, vsetvl_e16m1(length - i));\n        } else {\n            vresult = vand_vv_u16m1(va, vb, vsetvl_e16m1(length - i));\n        }\n\n        vse16_v_u16m1(&C[i], vresult, vsetvl_e16m1(length - i));\n    }\n\n    if (i < length) {\n        size_t remaining = length - i;\n        vuint16m1_t va = vle16_v_u16m1(&A[i], vsetvl_e16m1(remaining));\n        vuint16m1_t vb = vle16_v_u16m1(&B[i], vsetvl_e16m1(remaining));\n\n        vuint16m1_t vresult;\n        if (i < midpoint) {\n            vresult = vxor_vv_u16m1(va, vb, vsetvl_e16m1(remaining));\n        } else {\n            vresult = vand_vv_u16m1(va, vb, vsetvl_e16m1(remaining));\n        }\n\n        vse16_v_u16m1(&C[i], vresult, vsetvl_e16m1(remaining));\n    }\n\n    if (length % 2 != 0) {\n        C[midpoint] = A[midpoint];\n    }\n}\n```"}
{"task_id": "SimdBench_44_RVV", "completion": "```cpp\nvoid tensor_bit_op_simd(const uint16_t* A, const uint16_t* B, uint16_t* C, size_t length) {\n    size_t midpoint = length / 2;\n\n    size_t vl = __riscv_vsetvl_e16m1(length);\n\n    vuint16m1_t va = __riscv_vle16_v_u16m1(A, vl);\n    vuint16m1_t vb = __riscv_vle16_v_u16m1(B, vl);\n\n    vuint16m1_t vxor = __riscv_vxor_vv_u16m1(va, vb, vl);\n    vuint16m1_t vand = __riscv_vand_vv_u16m1(va, vb, vl);\n\n    for (size_t i = 0; i < midpoint; ++i) {\n        C[i] = vxor[i];\n    }\n\n    for (size_t i = midpoint; i < length; ++i) {\n        C[i] = va[i];\n    }\n\n    for (size_t i = midpoint; i < length; ++i) {\n        C[i] = vand[i];\n    }\n}\n```"}
{"task_id": "SimdBench_45_RVV", "completion": "```c\nvoid tensor_multi_select_simd(const float* A, const float* B, const float* C, const float* D, const bool* cond1, const bool* cond2, float* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t vl = __riscv_vsetvl_e32m1(total_elements);\n\n    for (size_t i = 0; i < total_elements; i += vl) {\n        vl = __riscv_vsetvl_e32m1(total_elements - i);\n\n        vbool32_t vcond1 = __riscv_vle_v_b32mf2(cond1 + i, vl);\n        vbool32_t vcond2 = __riscv_vle_v_b32mf2(cond2 + i, vl);\n\n        vfloat32m1_t va = __riscv_vle_v_f32m1(A + i, vl);\n        vfloat32m1_t vb = __riscv_vle_v_f32m1(B + i, vl);\n        vfloat32m1_t vc = __riscv_vle_v_f32m1(C + i, vl);\n        vfloat32m1_t vd = __riscv_vle_v_f32m1(D + i, vl);\n\n        vfloat32m1_t vout = __riscv_vmerge_vvm(vb, va, vcond2, vl);\n        vout = __riscv_vmerge_vvm(vc, vout, vcond1, vl);\n        vout = __riscv_vmerge_vvm(vd, vout, __riscv_vmandn_mm_b32(vcond1, vcond2, vl), vl);\n\n        __riscv_vse_v_f32m1(out + i, vout, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_45_RVV", "completion": "```cpp\nvoid tensor_multi_select_simd(const float* A, const float* B, const float* C, const float* D, const bool* cond1, const bool* cond2, float* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t vl = __riscv_vsetvl_e32m1(total_elements);\n\n    for (size_t i = 0; i < total_elements; i += vl) {\n        vl = __riscv_vsetvl_e32m1(total_elements - i);\n\n        vbool32_t mask1 = __riscv_vlm_v_b32(cond1 + i, vl);\n        vbool32_t mask2 = __riscv_vlm_v_b32(cond2 + i, vl);\n\n        vfloat32m1_t vec_A = __riscv_vlm_v_f32m1(A + i, vl);\n        vfloat32m1_t vec_B = __riscv_vlm_v_f32m1(B + i, vl);\n        vfloat32m1_t vec_C = __riscv_vlm_v_f32m1(C + i, vl);\n        vfloat32m1_t vec_D = __riscv_vlm_v_f32m1(D + i, vl);\n\n        vfloat32m1_t result = __riscv_vmerge_vvm_f32m1(vec_D, vec_C, mask2, vl);\n        result = __riscv_vmerge_vvm_f32m1(result, vec_B, mask1, vl);\n        result = __riscv_vmerge_vvm_f32m1(result, vec_A, __riscv_vmand_mm_b32(mask1, mask2, vl), vl);\n\n        __riscv_vsm_v_f32m1(out + i, result, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_45_RVV", "completion": "```c\nvoid tensor_multi_select_simd(const float* A, const float* B, const float* C, const float* D, const bool* cond1, const bool* cond2, float* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t vl = __riscv_vsetvl_e32m1(total_elements);\n\n    for (size_t i = 0; i < total_elements; i += vl) {\n        vl = __riscv_vsetvl_e32m1(total_elements - i);\n\n        vbool32_t vcond1 = __riscv_vlm_v_b32(cond1 + i, vl);\n        vbool32_t vcond2 = __riscv_vlm_v_b32(cond2 + i, vl);\n\n        vfloat32m1_t va = __riscv_vlm_v_f32m1(A + i, vl);\n        vfloat32m1_t vb = __riscv_vlm_v_f32m1(B + i, vl);\n        vfloat32m1_t vc = __riscv_vlm_v_f32m1(C + i, vl);\n        vfloat32m1_t vd = __riscv_vlm_v_f32m1(D + i, vl);\n\n        vfloat32m1_t vout = __riscv_vmerge_vvm_f32m1(vb, va, vcond2, vl);\n        vout = __riscv_vmerge_vvm_f32m1(vc, vout, vcond1, vl);\n        vout = __riscv_vmerge_vvm_f32m1(vd, vout, __riscv_vmand_mm_b32(vcond1, vcond2, vl), vl);\n\n        __riscv_vsm_v_f32m1(out + i, vout, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_45_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid tensor_multi_select_simd(const float* A, const float* B, const float* C, const float* D, const bool* cond1, const bool* cond2, float* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t vl = vsetvl_e32m1(total_elements);\n\n    for (size_t i = 0; i < total_elements; i += vl) {\n        vl = vsetvl_e32m1(total_elements - i);\n\n        vfloat32m1_t va = vle32_v_f32m1(&A[i], vl);\n        vfloat32m1_t vb = vle32_v_f32m1(&B[i], vl);\n        vfloat32m1_t vc = vle32_v_f32m1(&C[i], vl);\n        vfloat32m1_t vd = vle32_v_f32m1(&D[i], vl);\n\n        vuint8mf8_t vcond1 = vle8_v_u8mf8(&cond1[i], vl);\n        vuint8mf8_t vcond2 = vle8_v_u8mf8(&cond2[i], vl);\n\n        vuint8mf8_t vcond1_true = vmseq_vx_u8mf8(vcond1, 1, vl);\n        vuint8mf8_t vcond2_true = vmseq_vx_u8mf8(vcond2, 1, vl);\n\n        vuint8mf8_t vcond1_false = vmseq_vx_u8mf8(vcond1, 0, vl);\n        vuint8mf8_t vcond2_false = vmseq_vx_u8mf8(vcond2, 0, vl);\n\n        vuint8mf8_t vcond1_true_and_cond2_true = vand_vv_u8mf8(vcond1_true, vcond2_true, vl);\n        vuint8mf8_t vcond1_true_and_cond2_false = vand_vv_u8mf8(vcond1_true, vcond2_false, vl);\n        vuint8mf8_t vcond1_false_and_cond2_true = vand_vv_u8mf8(vcond1_false, vcond2_true, vl);\n        vuint8mf8_t vcond1_false_and_cond2_false = vand_vv_u8mf8(vcond1_false, vcond2_false, vl);\n\n        vfloat32m1_t vout = vmerge_vv_f32m1(vd, vc, vcond1_false_and_cond2_true, vl);\n        vout = vmerge_vv_f32m1(vout, vb, vcond1_true_and_cond2_false, vl);\n        vout = vmerge_vv_f32m1(vout, va, vcond1_true_and_cond2_true, vl);\n\n        vse32_v_f32m1(&out[i], vout, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_45_RVV", "completion": "```c\nvoid tensor_multi_select_simd(const float* A, const float* B, const float* C, const float* D, const bool* cond1, const bool* cond2, float* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t vl = __riscv_vsetvl_e32m1(total_elements);\n\n    for (size_t i = 0; i < total_elements; i += vl) {\n        vl = __riscv_vsetvl_e32m1(total_elements - i);\n\n        vbool32_t vcond1 = __riscv_vlm_v_b32(cond1 + i, vl);\n        vbool32_t vcond2 = __riscv_vlm_v_b32(cond2 + i, vl);\n\n        vfloat32m1_t va = __riscv_vlm_v_f32m1(A + i, vl);\n        vfloat32m1_t vb = __riscv_vlm_v_f32m1(B + i, vl);\n        vfloat32m1_t vc = __riscv_vlm_v_f32m1(C + i, vl);\n        vfloat32m1_t vd = __riscv_vlm_v_f32m1(D + i, vl);\n\n        vfloat32m1_t vout = __riscv_vmerge_vvm_f32m1(vb, va, vcond2, vl);\n        vout = __riscv_vmerge_vvm_f32m1(vc, vout, vcond1, vl);\n        vout = __riscv_vmerge_vvm_f32m1(vd, vout, __riscv_vmand_mm_b32(vcond1, vcond2, vl), vl);\n\n        __riscv_vsm_v_f32m1(out + i, vout, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_46_RVV", "completion": "```c\nvoid tensor_bit_count_simd(const uint32_t* A, uint8_t* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t i = 0;\n\n    for (; i <= total_elements - 8; i += 8) {\n        vuint32m1_t v_a = __riscv_vle32_v_u32m1(&A[i], 8);\n        vuint8m1_t v_count = __riscv_vcpop_v_u8m1(v_a, 8);\n        __riscv_vse8_v_u8m1(&out[i], v_count, 8);\n    }\n\n    for (; i < total_elements; ++i) {\n        out[i] = __riscv_vcpop_m_u32m1(A[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_46_RVV", "completion": "```c\nvoid tensor_bit_count_simd(const uint32_t* A, uint8_t* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t i = 0;\n\n    for (; i <= total_elements - 8; i += 8) {\n        vuint32m1_t v_a = __riscv_vle32_v_u32m1(&A[i], 8);\n        vuint8mf8_t v_count = __riscv_vcpop_v_u32m1(v_a, 8);\n        __riscv_vse8_v_u8mf8(&out[i], v_count, 8);\n    }\n\n    for (; i < total_elements; ++i) {\n        out[i] = __builtin_popcount(A[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_46_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid tensor_bit_count_simd(const uint32_t* A, uint8_t* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t vl = __riscv_vsetvl_e32m1(total_elements);\n\n    for (size_t i = 0; i < total_elements; i += vl) {\n        vl = __riscv_vsetvl_e32m1(total_elements - i);\n        vuint32m1_t v_a = __riscv_vle32_v_u32m1(&A[i], vl);\n        vuint8mf8_t v_count = __riscv_vcpop_v_u8mf8(v_a, vl);\n        __riscv_vse8_v_u8mf8(&out[i], v_count, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_46_RVV", "completion": "```c\nvoid tensor_bit_count_simd(const uint32_t* A, uint8_t* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t i = 0;\n\n    for (; i <= total_elements - 16; i += 16) {\n        vuint32m1_t v_a = __riscv_vle32_v_u32m1(&A[i], 16);\n        vuint8mf4_t v_count = __riscv_vcpop_v_u8mf4(v_a, 16);\n        __riscv_vse8_v_u8mf4(&out[i], v_count, 16);\n    }\n\n    for (; i < total_elements; ++i) {\n        out[i] = __riscv_vcpop_m_u32m1(A[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_46_RVV", "completion": "```c\nvoid tensor_bit_count_simd(const uint32_t* A, uint8_t* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t vl = __riscv_vsetvl_e32m1(total_elements);\n\n    for (size_t i = 0; i < total_elements; i += vl) {\n        vl = __riscv_vsetvl_e32m1(total_elements - i);\n\n        vuint32m1_t v_a = __riscv_vle32_v_u32m1(&A[i], vl);\n        vuint8mf8_t v_count = __riscv_vcpop_v_u8mf8(v_a, vl);\n\n        __riscv_vse8_v_u8mf8(&out[i], v_count, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_47_RVV", "completion": "```c\nvoid matrix_conditional_abs_simd(const int* A, int* B, size_t rows, size_t cols) {\n    size_t size = rows * cols;\n    size_t vl = vsetvl_e32m1(size);\n\n    for (size_t i = 0; i < size; i += vl) {\n        vl = vsetvl_e32m1(size - i);\n\n        vint32m1_t vec_A = vle32_v_i32m1(&A[i], vl);\n        vint32m1_t vec_abs_A = vabs_v_i32m1(vec_A, vl);\n        vuint32m1_t vec_mod_3 = vremu_vu_i32m1(vec_A, 3, vl);\n        vuint32m1_t vec_zero = vmv_v_x_u32m1(0, vl);\n        vuint32m1_t vec_mask = vmseq_vu_u32m1(vec_mod_3, vec_zero, vl);\n\n        vint32m1_t vec_B = vmerge_vvm_i32m1(vec_A, vec_abs_A, vec_mask, vl);\n        vse32_v_i32m1(&B[i], vec_B, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_47_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid matrix_conditional_abs_simd(const int* A, int* B, size_t rows, size_t cols) {\n    size_t size = rows * cols;\n    size_t vl = vsetvl_e32m1(size);\n\n    for (size_t i = 0; i < size; i += vl) {\n        vl = vsetvl_e32m1(size - i);\n\n        vbool32_t mask = vmseq_vx_i32m1_b32(vl, A + i, 0);\n        vint32m1_t vec_A = vle32_v_i32m1(A + i, vl);\n        vint32m1_t abs_A = vabs_v_i32m1(vec_A, vl);\n        vint32m1_t vec_B = vmerge_vvm_i32m1(mask, abs_A, vec_A, vl);\n\n        vse32_v_i32m1(B + i, vec_B, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_47_RVV", "completion": "```c\nvoid matrix_conditional_abs_simd(const int* A, int* B, size_t rows, size_t cols) {\n    size_t size = rows * cols;\n    size_t vl = vsetvl_e32m1(size);\n\n    for (size_t i = 0; i < size; i += vl) {\n        vl = vsetvl_e32m1(size - i);\n\n        vint32m1_t v_a = vle32_v_i32m1(&A[i], vl);\n        vint32m1_t v_cond = vmseq_vx_i32m1_b32(v_a, 0, vl);\n        vint32m1_t v_abs = vabs_v_i32m1(v_a, vl);\n        vint32m1_t v_result = vmerge_vvm_i32m1(v_a, v_abs, v_cond, vl);\n\n        vse32_v_i32m1(&B[i], v_result, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_47_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid matrix_conditional_abs_simd(const int* A, int* B, size_t rows, size_t cols) {\n    size_t size = rows * cols;\n    size_t vl = vsetvl_e32m1(size);\n\n    for (size_t i = 0; i < size; i += vl) {\n        vl = vsetvl_e32m1(size - i);\n\n        vint32m1_t va = vle32_v_i32m1(&A[i], vl);\n        vint32m1_t vmod = vrem_vv_i32m1(va, vmv_v_x_i32m1(3, vl), vl);\n        vuint1_t vmask = vmseq_vx_i32m1_b32(vmod, 0, vl);\n\n        vint32m1_t vabs = vabs_v_i32m1(va, vl);\n        vint32m1_t vresult = vmerge_vvm_i32m1(va, vabs, vmask, vl);\n\n        vse32_v_i32m1(&B[i], vresult, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_47_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid matrix_conditional_abs_simd(const int* A, int* B, size_t rows, size_t cols) {\n    size_t size = rows * cols;\n    size_t vl = vsetvl_e32m1(size);\n\n    for (size_t i = 0; i < size; i += vl) {\n        vl = vsetvl_e32m1(size - i);\n\n        vint32m1_t va = vle32_v_i32m1(&A[i], vl);\n        vint32m1_t vcond = vmseq_vx_i32m1_b32(va, 0, vl);\n        vint32m1_t vabs = vabs_v_i32m1(va, vl);\n        vint32m1_t vresult = vmerge_vvm_i32m1(vabs, va, vcond, vl);\n\n        vse32_v_i32m1(&B[i], vresult, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_48_RVV", "completion": "```c\nvoid matrix_conditional_bit_rotate_simd(const uint32_t* src, uint32_t* dst, uint8_t rotate_bits, size_t length) {\n    size_t vl = __riscv_vsetvl_e32m1(length);\n    vuint32m1_t v_src = __riscv_vle32_v_u32m1(src, vl);\n    vuint32m1_t v_dst;\n\n    vuint32m1_t v_ones = __riscv_vmv_v_x_u32m1(0xF, vl);\n    vuint32m1_t v_low_bits = __riscv_vand_vv_u32m1(v_src, v_ones, vl);\n    vuint32m1_t v_all_ones = __riscv_vmv_v_x_u32m1(0xF, vl);\n\n    vbool32_t mask = __riscv_vmseq_vv_u32m1_b32(v_low_bits, v_all_ones, vl);\n\n    vuint32m1_t v_rotated = __riscv_vrol_vx_u32m1(v_src, rotate_bits, vl);\n    vuint32m1_t v_negated = __riscv_vnot_v_u32m1(v_src, vl);\n\n    v_dst = __riscv_vmerge_vvm_u32m1(v_rotated, v_negated, mask, vl);\n\n    __riscv_vse32_v_u32m1(dst, v_dst, vl);\n}\n```"}
{"task_id": "SimdBench_48_RVV", "completion": "```c\nvoid matrix_conditional_bit_rotate_simd(const uint32_t* src, uint32_t* dst, uint8_t rotate_bits, size_t length) {\n    size_t vl = __riscv_vsetvl_e32m1(length);\n    vuint32m1_t v_src = __riscv_vle32_v_u32m1(src, vl);\n    vuint32m1_t v_dst;\n\n    vuint32m1_t v_ones = __riscv_vmv_v_x_u32m1(0xF, vl);\n    vuint32m1_t v_low_bits = __riscv_vand_vv_u32m1(v_src, v_ones, vl);\n    vuint32m1_t v_all_ones = __riscv_vmv_v_x_u32m1(0xF, vl);\n\n    vbool32_t mask = __riscv_vmseq_vv_u32m1_b32(v_low_bits, v_all_ones, vl);\n\n    vuint32m1_t v_rotated = __riscv_vrol_vx_u32m1(v_src, rotate_bits, vl);\n    vuint32m1_t v_negated = __riscv_vnot_v_u32m1(v_src, vl);\n\n    v_dst = __riscv_vmerge_vvm_u32m1(v_rotated, v_negated, mask, vl);\n\n    __riscv_vse32_v_u32m1(dst, v_dst, vl);\n}\n```"}
{"task_id": "SimdBench_48_RVV", "completion": "```c\nvoid matrix_conditional_bit_rotate_simd(const uint32_t* src, uint32_t* dst, uint8_t rotate_bits, size_t length) {\n    size_t vl = __riscv_vsetvl_e32m1(length);\n    vuint32m1_t v_src = __riscv_vle32_v_u32m1(src, vl);\n    vuint32m1_t v_dst;\n    vuint32m1_t v_ones = __riscv_vmv_v_x_u32m1(0xF, vl);\n    vuint32m1_t v_neg = __riscv_vnot_v_u32m1(v_src, vl);\n    vuint32m1_t v_cond = __riscv_vand_vv_u32m1(v_src, v_ones, vl);\n    vuint32m1_t v_rotate = __riscv_vrol_vx_u32m1(v_src, rotate_bits, vl);\n    vbool32_t mask = __riscv_vmseq_vx_u32m1_b32(v_cond, 0xF, vl);\n    v_dst = __riscv_vmerge_vvm_u32m1(v_rotate, v_neg, mask, vl);\n    __riscv_vse32_v_u32m1(dst, v_dst, vl);\n}\n```"}
{"task_id": "SimdBench_48_RVV", "completion": "```c\nvoid matrix_conditional_bit_rotate_simd(const uint32_t* src, uint32_t* dst, uint8_t rotate_bits, size_t length) {\n    size_t vl = __riscv_vsetvl_e32m1(length);\n    vuint32m1_t v_src = __riscv_vle32_v_u32m1(src, vl);\n    vuint32m1_t v_dst;\n    vuint32m1_t v_ones = __riscv_vmv_v_x_u32m1(0xF, vl);\n    vuint32m1_t v_rotated = __riscv_vrol_vx_u32m1(v_src, rotate_bits, vl);\n    vuint32m1_t v_negated = __riscv_vnot_v_u32m1(v_src, vl);\n    vuint32m1_t v_low_bits = __riscv_vand_vv_u32m1(v_src, v_ones, vl);\n    vbool32_t v_mask = __riscv_vmseq_vx_u32m1_b32(v_low_bits, 0xF, vl);\n    v_dst = __riscv_vmerge_vvm_u32m1(v_negated, v_rotated, v_mask, vl);\n    __riscv_vse32_v_u32m1(dst, v_dst, vl);\n}\n```"}
{"task_id": "SimdBench_48_RVV", "completion": "```cpp\nvoid matrix_conditional_bit_rotate_simd(const uint32_t* src, uint32_t* dst, uint8_t rotate_bits, size_t length) {\n    size_t vl = __riscv_vsetvl_e32m1(length);\n    vuint32m1_t v_src = __riscv_vle32_v_u32m1(src, vl);\n    vuint32m1_t v_dst;\n    vuint32m1_t v_ones = __riscv_vmv_v_x_u32m1(0xF, vl);\n    vuint32m1_t v_rotate_bits = __riscv_vmv_v_x_u32m1(rotate_bits, vl);\n\n    vuint32m1_t v_low_4_bits = __riscv_vand_vv_u32m1(v_src, v_ones, vl);\n    vuint32m1_t v_all_ones = __riscv_vmv_v_x_u32m1(0xF, vl);\n    vbool32_t v_mask = __riscv_vmseq_vv_u32m1_b32(v_low_4_bits, v_all_ones, vl);\n\n    vuint32m1_t v_rotated = __riscv_vrol_vv_u32m1(v_src, v_rotate_bits, vl);\n    vuint32m1_t v_negated = __riscv_vnot_v_u32m1(v_src, vl);\n\n    v_dst = __riscv_vmerge_vvm_u32m1(v_rotated, v_negated, v_mask, vl);\n\n    __riscv_vse32_v_u32m1(dst, v_dst, vl);\n}\n```"}
{"task_id": "SimdBench_49_RVV", "completion": "```c\nvoid tensor_ternary_compare_simd(const float* A, const float* B, int8_t* out, float epsilon, size_t length) {\n    size_t vl = __riscv_vsetvl_e32m1(length);\n    for (size_t i = 0; i < length; i += vl) {\n        vl = __riscv_vsetvl_e32m1(length - i);\n        vfloat32m1_t va = __riscv_vle32_v_f32m1(&A[i], vl);\n        vfloat32m1_t vb = __riscv_vle32_v_f32m1(&B[i], vl);\n        vfloat32m1_t vdiff = __riscv_vfsub_vv_f32m1(va, vb, vl);\n        vfloat32m1_t vabs_diff = __riscv_vfabs_v_f32m1(vdiff, vl);\n        vfloat32m1_t veps = __riscv_vfmv_v_f_f32m1(epsilon, vl);\n        vint8m1_t vout = __riscv_vmerge_vx_i8m1(__riscv_vmv_v_x_i8m1(0, vl), 1, __riscv_vfgt_vv_f32m1_b(vdiff, veps, vl), vl);\n        vout = __riscv_vmerge_vx_i8m1(vout, -1, __riscv_vflt_vv_f32m1_b(vdiff, __riscv_vfneg_v_f32m1(veps, vl), vl), vl);\n        __riscv_vse8_v_i8m1(&out[i], vout, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_49_RVV", "completion": "```c\nvoid tensor_ternary_compare_simd(const float* A, const float* B, int8_t* out, float epsilon, size_t length) {\n    size_t vl = __riscv_vsetvl_e32m1(length);\n    vfloat32m1_t va = __riscv_vle32_v_f32m1(A, vl);\n    vfloat32m1_t vb = __riscv_vle32_v_f32m1(B, vl);\n    vfloat32m1_t veps = __riscv_vfmv_v_f_f32m1(epsilon, vl);\n\n    vfloat32m1_t vdiff = __riscv_vfsub_vv_f32m1(va, vb, vl);\n    vfloat32m1_t vabs_diff = __riscv_vfabs_v_f32m1(vdiff, vl);\n\n    vint8m1_t vout = __riscv_vmerge_vx_i8m1(__riscv_vmv_v_x_i8m1(0, vl), 1, __riscv_vfgt_vf_f32m1_b(vdiff, epsilon, vl), vl);\n    vout = __riscv_vmerge_vx_i8m1(vout, -1, __riscv_vflt_vf_f32m1_b(vdiff, -epsilon, vl), vl);\n    vout = __riscv_vmerge_vx_i8m1(vout, 0, __riscv_vfle_vf_f32m1_b(vabs_diff, epsilon, vl), vl);\n\n    __riscv_vse8_v_i8m1(out, vout, vl);\n}\n```"}
{"task_id": "SimdBench_49_RVV", "completion": "```c\nvoid tensor_ternary_compare_simd(const float* A, const float* B, int8_t* out, float epsilon, size_t length) {\n    size_t vl = __riscv_vsetvl_e32m1(length);\n    for (size_t i = 0; i < length; i += vl) {\n        vl = __riscv_vsetvl_e32m1(length - i);\n        vfloat32m1_t va = __riscv_vle32_v_f32m1(&A[i], vl);\n        vfloat32m1_t vb = __riscv_vle32_v_f32m1(&B[i], vl);\n        vfloat32m1_t diff = __riscv_vfsub_vv_f32m1(va, vb, vl);\n        vfloat32m1_t abs_diff = __riscv_vfabs_v_f32m1(diff, vl);\n        vfloat32m1_t abs_epsilon = __riscv_vfmv_v_f_f32m1(fabsf(epsilon), vl);\n        vint8m1_t result = __riscv_vmerge_vxm_i8m1(__riscv_vmseq_vx_i8m1_b8(__riscv_vcvt_x_f_v_i8m1(abs_diff, vl), 0, vl),\n                                                   __riscv_vcvt_x_f_v_i8m1(diff, vl),\n                                                   __riscv_vcvt_x_f_v_i8m1(abs_epsilon, vl), vl);\n        __riscv_vse8_v_i8m1(&out[i], result, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_49_RVV", "completion": "```c\nvoid tensor_ternary_compare_simd(const float* A, const float* B, int8_t* out, float epsilon, size_t length) {\n    size_t vl = __riscv_vsetvl_e32m1(length);\n    vfloat32m1_t va = __riscv_vle32_v_f32m1(A, vl);\n    vfloat32m1_t vb = __riscv_vle32_v_f32m1(B, vl);\n    vfloat32m1_t veps = __riscv_vfmv_v_f_f32m1(epsilon, vl);\n    vfloat32m1_t vdiff = __riscv_vfsub_vv_f32m1(va, vb, vl);\n    vfloat32m1_t vabs_diff = __riscv_vfabs_v_f32m1(vdiff, vl);\n    vbool32_t vcmp_gt = __riscv_vfgt_vv_b32(vdiff, veps, vl);\n    vbool32_t vcmp_lt = __riscv_vflt_vv_b32(vdiff, __riscv_vfneg_v_f32m1(veps, vl), vl);\n    vint8m1_t vout = __riscv_vmerge_vx_i8m1(__riscv_vmerge_vx_i8m1(__riscv_vmv_v_x_i8m1(0, vl), 1, vcmp_gt, vl), -1, vcmp_lt, vl);\n    __riscv_vse8_v_i8m1(out, vout, vl);\n}\n```"}
{"task_id": "SimdBench_49_RVV", "completion": "```c\nvoid tensor_ternary_compare_simd(const float* A, const float* B, int8_t* out, float epsilon, size_t length) {\n    size_t vl = __riscv_vsetvl_e32m1(length);\n    vfloat32m1_t va = __riscv_vle32_v_f32m1(A, vl);\n    vfloat32m1_t vb = __riscv_vle32_v_f32m1(B, vl);\n    vfloat32m1_t veps = __riscv_vfmv_v_f_f32m1(epsilon, vl);\n    vfloat32m1_t vdiff = __riscv_vfsub_vv_f32m1(va, vb, vl);\n    vfloat32m1_t vabs_diff = __riscv_vfabs_v_f32m1(vdiff, vl);\n    vint8m1_t vout = __riscv_vmv_v_x_i8m1(0, vl);\n    vint8m1_t vone = __riscv_vmv_v_x_i8m1(1, vl);\n    vint8m1_t vnegone = __riscv_vmv_v_x_i8m1(-1, vl);\n\n    vbool32_t mask_gt = __riscv_vmfgt_vv_f32m1_b32(vdiff, veps, vl);\n    vbool32_t mask_lt = __riscv_vmflt_vv_f32m1_b32(vdiff, __riscv_vfneg_v_f32m1(veps, vl), vl);\n    vbool32_t mask_eq = __riscv_vmfle_vv_f32m1_b32(vabs_diff, veps, vl);\n\n    vout = __riscv_vmerge_vxm_i8m1(vout, vone, mask_gt, vl);\n    vout = __riscv_vmerge_vxm_i8m1(vout, vnegone, mask_lt, vl);\n    vout = __riscv_vmerge_vxm_i8m1(vout, __riscv_vmv_v_x_i8m1(0, vl), mask_eq, vl);\n\n    __riscv_vse8_v_i8m1(out, vout, vl);\n}\n```"}
{"task_id": "SimdBench_50_RVV", "completion": "```c\nvoid float_to_int_saturate_simd(const float* A, int32_t* B, size_t size) {\n    size_t vl = __riscv_vsetvl_e32m1(size);\n    for (size_t i = 0; i < size; i += vl) {\n        vl = __riscv_vsetvl_e32m1(size - i);\n        vfloat32m1_t va = __riscv_vle32_v_f32m1(&A[i], vl);\n        vint32m1_t vb = __riscv_vfcvt_x_f_v_i32m1(va, vl);\n        vint32m1_t vmax = __riscv_vmv_v_x_i32m1(INT32_MAX, vl);\n        vint32m1_t vmin = __riscv_vmv_v_x_i32m1(INT32_MIN, vl);\n        vint32m1_t vclamped = __riscv_vmin_vv_i32m1(__riscv_vmax_vv_i32m1(vb, vmin, vl), vmax, vl);\n        __riscv_vse32_v_i32m1(&B[i], vclamped, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_50_RVV", "completion": "```c\nvoid float_to_int_saturate_simd(const float* A, int32_t* B, size_t size) {\n    size_t vl = vsetvl_e32m1(size);\n    for (size_t i = 0; i < size; i += vl) {\n        vl = vsetvl_e32m1(size - i);\n        vfloat32m1_t vA = vle32_v_f32m1(&A[i], vl);\n        vint32m1_t vB = vfcvt_x_f_v_i32m1(vA, vl);\n        vint32m1_t vMax = vmv_v_x_i32m1(INT32_MAX, vl);\n        vint32m1_t vMin = vmv_v_x_i32m1(INT32_MIN, vl);\n        vint32m1_t vB_clamped = vmin_vv_i32m1(vmax_vv_i32m1(vB, vMin), vMax, vl);\n        vse32_v_i32m1(&B[i], vB_clamped, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_50_RVV", "completion": "```c\nvoid float_to_int_saturate_simd(const float* A, int32_t* B, size_t size) {\n    size_t vl = vsetvl_e32m1(size);\n    for (size_t i = 0; i < size; i += vl) {\n        vl = vsetvl_e32m1(size - i);\n        vfloat32m1_t vA = vle32_v_f32m1(&A[i], vl);\n        vint32m1_t vB = vfcvt_x_f_v_i32m1(vA, vl);\n        vint32m1_t vMax = vmv_v_x_i32m1(INT32_MAX, vl);\n        vint32m1_t vMin = vmv_v_x_i32m1(INT32_MIN, vl);\n        vint32m1_t vCmpMax = vmax_vv_i32m1(vB, vMin, vl);\n        vint32m1_t vCmpMin = vmin_vv_i32m1(vCmpMax, vMax, vl);\n        vse32_v_i32m1(&B[i], vCmpMin, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_50_RVV", "completion": "```c\nvoid float_to_int_saturate_simd(const float* A, int32_t* B, size_t size) {\n    size_t vl = vsetvl_e32m1(size);\n    for (size_t i = 0; i < size; i += vl) {\n        vl = vsetvl_e32m1(size - i);\n        vfloat32m1_t va = vle32_v_f32m1(&A[i], vl);\n        vint32m1_t vb = vfcvt_x_f_v_i32m1(va, vl);\n        vint32m1_t vmax = vmv_v_x_i32m1(INT32_MAX, vl);\n        vint32m1_t vmin = vmv_v_x_i32m1(INT32_MIN, vl);\n        vint32m1_t vclamped = vmin_vv_i32m1(vmax, vb, vl);\n        vclamped = vmax_vv_i32m1(vmin, vclamped, vl);\n        vse32_v_i32m1(&B[i], vclamped, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_50_RVV", "completion": "```c\nvoid float_to_int_saturate_simd(const float* A, int32_t* B, size_t size) {\n    size_t vl = vsetvl_e32m1(size);\n    for (size_t i = 0; i < size; i += vl) {\n        vl = vsetvl_e32m1(size - i);\n        vfloat32m1_t va = vle32_v_f32m1(&A[i], vl);\n        vint32m1_t vb = vfcvt_x_f_v_i32m1(va, vl);\n        vint32m1_t vmax = vmv_v_x_i32m1(INT32_MAX, vl);\n        vint32m1_t vmin = vmv_v_x_i32m1(INT32_MIN, vl);\n        vint32m1_t vclamped = vmin_vv_i32m1(vmax, vb, vl);\n        vclamped = vmax_vv_i32m1(vmin, vclamped, vl);\n        vse32_v_i32m1(&B[i], vclamped, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_51_RVV", "completion": "```c\nvoid int_to_float_scaled_simd(const int32_t* A, int8_t scale, float* B, size_t size) {\n    size_t vl = vsetvl_e32m1(size);\n    vint32m1_t v_a = vle32_v_i32m1(A, vl);\n    vfloat32m1_t v_b = vfcvt_f_x_v_f32m1(v_a, vl);\n    vfloat32m1_t v_scale = vfmv_v_f_f32m1((float)scale, vl);\n    v_b = vfmul_vv_f32m1(v_b, v_scale, vl);\n    vse32_v_f32m1(B, v_b, vl);\n}\n```"}
{"task_id": "SimdBench_51_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid int_to_float_scaled_simd(const int32_t* A, int8_t scale, float* B, size_t size) {\n    size_t vl = vsetvl_e32m1(size);\n    vint32m1_t vA = vle32_v_i32m1(A, vl);\n    vfloat32m1_t vB = vfcvt_f_x_v_f32m1(vA, vl);\n    vfloat32m1_t vScale = vfmv_v_f_f32m1((float)scale, vl);\n    vB = vfmul_vv_f32m1(vB, vScale, vl);\n    vse32_v_f32m1(B, vB, vl);\n}\n```"}
{"task_id": "SimdBench_51_RVV", "completion": "```c\nvoid int_to_float_scaled_simd(const int32_t* A, int8_t scale, float* B, size_t size) {\n    size_t vl = vsetvl_e32m1(size);\n    vint32m1_t v_a = vle32_v_i32m1(A, vl);\n    vfloat32m1_t v_b = vfcvt_f_x_v_f32m1(v_a, vl);\n    vfloat32m1_t v_scale = vfmv_v_f_f32m1((float)scale, vl);\n    v_b = vfmul_vv_f32m1(v_b, v_scale, vl);\n    vse32_v_f32m1(B, v_b, vl);\n}\n```"}
{"task_id": "SimdBench_51_RVV", "completion": "```c\nvoid int_to_float_scaled_simd(const int32_t* A, int8_t scale, float* B, size_t size) {\n    size_t vl = vsetvl_e32m1(size);\n    vint32m1_t v_a = vle32_v_i32m1(A, vl);\n    vfloat32m1_t v_b = vfcvt_f_x_v_f32m1(v_a, vl);\n    vfloat32m1_t v_scale = vfmv_v_f_f32m1((float)scale, vl);\n    v_b = vfmul_vv_f32m1(v_b, v_scale, vl);\n    vse32_v_f32m1(B, v_b, vl);\n}\n```"}
{"task_id": "SimdBench_51_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid int_to_float_scaled_simd(const int32_t* A, int8_t scale, float* B, size_t size) {\n    size_t vl = vsetvl_e32m1(size);\n    vint32m1_t vA = vle32_v_i32m1(A, vl);\n    vfloat32m1_t vB = vfcvt_f_x_v_f32m1(vA, vl);\n    vfloat32m1_t vScale = vfmv_v_f_f32m1((float)scale, vl);\n    vB = vfmul_vv_f32m1(vB, vScale, vl);\n    vse32_v_f32m1(B, vB, vl);\n}\n```"}
{"task_id": "SimdBench_52_RVV", "completion": "```c\nvoid float_div_round_simd(const float* A, const float* B, int32_t* C, size_t size) {\n    size_t vl = __riscv_vsetvl_e32m1(size);\n    for (size_t i = 0; i < size; i += vl) {\n        vl = __riscv_vsetvl_e32m1(size - i);\n        vfloat32m1_t va = __riscv_vle32_v_f32m1(&A[i], vl);\n        vfloat32m1_t vb = __riscv_vle32_v_f32m1(&B[i], vl);\n        vfloat32m1_t vq = __riscv_vfdiv_vv_f32m1(va, vb, vl);\n        vint32m1_t vc = __riscv_vfncvt_x_f_w_i32m1(vq, vl);\n        __riscv_vse32_v_i32m1(&C[i], vc, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_52_RVV", "completion": "```c\nvoid float_div_round_simd(const float* A, const float* B, int32_t* C, size_t size) {\n    size_t vlmax = __riscv_vsetvlmax_e32m1();\n    for (size_t i = 0; i < size; i += vlmax) {\n        size_t vl = __riscv_vsetvl_e32m1(size - i);\n        vfloat32m1_t va = __riscv_vle32_v_f32m1(&A[i], vl);\n        vfloat32m1_t vb = __riscv_vle32_v_f32m1(&B[i], vl);\n        vfloat32m1_t vq = __riscv_vfdiv_vv_f32m1(va, vb, vl);\n        vint32m1_t vc = __riscv_vfncvt_x_f_w_i32m1(vq, vl);\n        __riscv_vse32_v_i32m1(&C[i], vc, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_52_RVV", "completion": "```cpp\nvoid float_div_round_simd(const float* A, const float* B, int32_t* C, size_t size) {\n    size_t vl = vsetvl_e32m1(size);\n    for (size_t i = 0; i < size; i += vl) {\n        vl = vsetvl_e32m1(size - i);\n        vfloat32m1_t va = vle32_v_f32m1(&A[i], vl);\n        vfloat32m1_t vb = vle32_v_f32m1(&B[i], vl);\n        vfloat32m1_t vq = vfdiv_vv_f32m1(va, vb, vl);\n        vint32m1_t vc = vnarrow_vx_i32m1(vq, 0, vl);\n        vse32_v_i32m1(&C[i], vc, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_52_RVV", "completion": "```cpp\nvoid float_div_round_simd(const float* A, const float* B, int32_t* C, size_t size) {\n    size_t vl = vsetvl_e32m1(size);\n    for (size_t i = 0; i < size; i += vl) {\n        vl = vsetvl_e32m1(size - i);\n        vfloat32m1_t va = vle32_v_f32m1(&A[i], vl);\n        vfloat32m1_t vb = vle32_v_f32m1(&B[i], vl);\n        vfloat32m1_t vq = vfdiv_vv_f32m1(va, vb, vl);\n        vint32m1_t vc = vnarrow_vx_i32m1(vq, 0, vl);\n        vse32_v_i32m1(&C[i], vc, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_52_RVV", "completion": "```c\nvoid float_div_round_simd(const float* A, const float* B, int32_t* C, size_t size) {\n    size_t vl = vsetvl_e32m1(size);\n    for (size_t i = 0; i < size; i += vl) {\n        vl = vsetvl_e32m1(size - i);\n        vfloat32m1_t va = vle32_v_f32m1(&A[i], vl);\n        vfloat32m1_t vb = vle32_v_f32m1(&B[i], vl);\n        vfloat32m1_t vq = vfdiv_vv_f32m1(va, vb, vl);\n        vint32m1_t vc = vfncvt_x_f_w_i32m1(vq, vl);\n        vse32_v_i32m1(&C[i], vc, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_53_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <float.h>\n\nvoid double_to_float_saturate_simd(const double* A, float* B, size_t size) {\n    size_t vl = vsetvl_e64m1(size);\n    vfloat64m1_t vA;\n    vfloat32m1_t vB;\n\n    for (size_t i = 0; i < size; i += vl) {\n        vl = vsetvl_e64m1(size - i);\n        vA = vle64_v_f64m1(&A[i], vl);\n\n        vfloat64m1_t vMax = vfmv_v_f_f64m1(FLT_MAX, vl);\n        vfloat64m1_t vMin = vfmv_v_f_f64m1(-FLT_MAX, vl);\n\n        vfloat64m1_t vClamped = vfmin_vv_f64m1(vfmax_vv_f64m1(vA, vMin, vl), vMax, vl);\n\n        vB = vfncvt_f_f_w_f32m1(vClamped, vl);\n\n        vse32_v_f32m1(&B[i], vB, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_53_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <float.h>\n\nvoid double_to_float_saturate_simd(const double* A, float* B, size_t size) {\n    size_t vl = vsetvl_e64m1(size);\n    vfloat64m1_t vA;\n    vfloat32m1_t vB;\n\n    for (size_t i = 0; i < size; i += vl) {\n        vl = vsetvl_e64m1(size - i);\n        vA = vle64_v_f64m1(&A[i], vl);\n\n        vB = vfcvt_f_f_v_f32m1(vA, vl);\n\n        vfloat32m1_t vMax = vfmv_v_f_f32m1(FLT_MAX, vl);\n        vfloat32m1_t vMin = vfmv_v_f_f32m1(-FLT_MAX, vl);\n\n        vB = vfmin_vv_f32m1(vB, vMax, vl);\n        vB = vfmax_vv_f32m1(vB, vMin, vl);\n\n        vse32_v_f32m1(&B[i], vB, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_53_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <float.h>\n\nvoid double_to_float_saturate_simd(const double* A, float* B, size_t size) {\n    size_t vl = vsetvl_e64m1(size);\n    vfloat64m1_t vA;\n    vfloat32m1_t vB;\n\n    for (size_t i = 0; i < size; i += vl) {\n        vl = vsetvl_e64m1(size - i);\n        vA = vle64_v_f64m1(&A[i], vl);\n\n        vfloat64m1_t vMax = vfmv_v_f_f64m1(FLT_MAX, vl);\n        vfloat64m1_t vMin = vfmv_v_f_f64m1(-FLT_MAX, vl);\n\n        vfloat64m1_t vClamped = vfmin_vv_f64m1(vfmax_vv_f64m1(vA, vMin), vMax, vl);\n        vB = vfncvt_f_f_w_f32m1(vClamped, vl);\n\n        vse32_v_f32m1(&B[i], vB, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_53_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <float.h>\n\nvoid double_to_float_saturate_simd(const double* A, float* B, size_t size) {\n    size_t vl = vsetvl_e64m1(size);\n    vfloat64m1_t vA;\n    vfloat32m1_t vB;\n\n    for (size_t i = 0; i < size; i += vl) {\n        vl = vsetvl_e64m1(size - i);\n        vA = vle64_v_f64m1(&A[i], vl);\n\n        vB = vfcvt_f_f_v_f32m1(vA, vl);\n\n        vfloat32m1_t vMax = vfmv_v_f_f32m1(FLT_MAX, vl);\n        vfloat32m1_t vMin = vfmv_v_f_f32m1(-FLT_MAX, vl);\n\n        vB = vfmin_vv_f32m1(vB, vMax, vl);\n        vB = vfmax_vv_f32m1(vB, vMin, vl);\n\n        vse32_v_f32m1(&B[i], vB, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_53_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <float.h>\n\nvoid double_to_float_saturate_simd(const double* A, float* B, size_t size) {\n    size_t vl = vsetvl_e64m1(size);\n    vfloat64m1_t vA = vle64_v_f64m1(A, vl);\n    vfloat32m1_t vB = vfcvt_f_xu_f_v_f_wu(vfcvt_rtz_xu_f_v_f_wu(vA, vl), vl);\n\n    vfloat64m1_t vFLT_MAX = vfmv_v_f_f64m1(FLT_MAX, vl);\n    vfloat64m1_t vNEG_FLT_MAX = vfmv_v_f_f64m1(-FLT_MAX, vl);\n\n    vbool64_t mask_gt_FLT_MAX = vmfgt_vv_f64m1_b64(vA, vFLT_MAX, vl);\n    vbool64_t mask_lt_NEG_FLT_MAX = vmflt_vv_f64m1_b64(vA, vNEG_FLT_MAX, vl);\n\n    vfloat32m1_t vFLT_MAX_f32 = vfcvt_f_xu_f_v_f_wu(vfcvt_rtz_xu_f_v_f_wu(vFLT_MAX, vl), vl);\n    vfloat32m1_t vNEG_FLT_MAX_f32 = vfcvt_f_xu_f_v_f_wu(vfcvt_rtz_xu_f_v_f_wu(vNEG_FLT_MAX, vl), vl);\n\n    vB = vmerge_vv_f32m1(vB, vFLT_MAX_f32, mask_gt_FLT_MAX, vl);\n    vB = vmerge_vv_f32m1(vB, vNEG_FLT_MAX_f32, mask_lt_NEG_FLT_MAX, vl);\n\n    vse32_v_f32m1(B, vB, vl);\n}\n```"}
{"task_id": "SimdBench_54_RVV", "completion": "```c\nvoid int16_to_int32_simd(const int16_t* A, int32_t* B, size_t size) {\n    size_t vl = vsetvl_e16m1(size);\n    for (size_t i = 0; i < size; i += vl) {\n        vl = vsetvl_e16m1(size - i);\n        vint16m1_t va = vle16_v_i16m1(&A[i], vl);\n        vint32m2_t vb = vwcvtu_x_w_i32m2(va, vl);\n        vse32_v_i32m2(&B[i], vb, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_54_RVV", "completion": "```c\nvoid int16_to_int32_simd(const int16_t* A, int32_t* B, size_t size) {\n    size_t vl = vsetvl_e16m1(size);\n    for (size_t i = 0; i < size; i += vl) {\n        vl = vsetvl_e16m1(size - i);\n        vint16m1_t va = vle16_v_i16m1(&A[i], vl);\n        vint32m2_t vb = vwcvtu_x_i32m2(va, vl);\n        vse32_v_i32m2(&B[i], vb, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_54_RVV", "completion": "```c\nvoid int16_to_int32_simd(const int16_t* A, int32_t* B, size_t size) {\n    size_t vl = vsetvl_e16m1(size);\n    for (size_t i = 0; i < size; i += vl) {\n        vl = vsetvl_e16m1(size - i);\n        vint16m1_t va = vle16_v_i16m1(&A[i], vl);\n        vint32m2_t vb = vwcvtu_x_i32m2(va, vl);\n        vse32_v_i32m2(&B[i], vb, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_54_RVV", "completion": "```c\nvoid int16_to_int32_simd(const int16_t* A, int32_t* B, size_t size) {\n    size_t vl = vsetvl_e16m1(size);\n    for (size_t i = 0; i < size; i += vl) {\n        vl = vsetvl_e16m1(size - i);\n        vint16m1_t va = vle16_v_i16m1(&A[i], vl);\n        vint32m2_t vb = vwcvtu_x_i32m2(va, vl);\n        vse32_v_i32m2(&B[i], vb, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_54_RVV", "completion": "```c\nvoid int16_to_int32_simd(const int16_t* A, int32_t* B, size_t size) {\n    size_t vl = vsetvl_e16m1(size);\n    for (size_t i = 0; i < size; i += vl) {\n        vl = vsetvl_e16m1(size - i);\n        vint16m1_t va = vle16_v_i16m1(&A[i], vl);\n        vint32m2_t vb = vwcvtu_x_i32m2(va, vl);\n        vse32_v_i32m2(&B[i], vb, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_55_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n\nvoid conditional_normalize_simd(const float* A, const int32_t* control, float* B, size_t size, float min_val, float max_val) {\n    size_t vl = vsetvl_e32m1(size);\n    size_t i = 0;\n\n    vfloat32m1_t v_min_val = vfmv_v_f_f32m1(min_val, vl);\n    vfloat32m1_t v_max_val = vfmv_v_f_f32m1(max_val, vl);\n    vfloat32m1_t v_zero = vfmv_v_f_f32m1(0.0f, vl);\n    vfloat32m1_t v_one = vfmv_v_f_f32m1(1.0f, vl);\n\n    for (; (i + vl) <= size; i += vl) {\n        vfloat32m1_t v_A = vle32_v_f32m1(&A[i], vl);\n        vint32m1_t v_control = vle32_v_i32m1(&control[i], vl);\n\n        vbool32_t mask = vmv_v_x_i32m1_b32(1, vl);\n        mask = vmseq_vx_i32m1_b32(mask, v_control, 0, vl);\n\n        vfloat32m1_t v_normalized = vfsub_vf_f32m1(v_A, v_min_val, vl);\n        v_normalized = vfdiv_vf_f32m1(v_normalized, vfsub_vf_f32m1(v_max_val, min_val, vl), vl);\n        v_normalized = vfmax_vf_f32m1(v_normalized, v_zero, vl);\n        v_normalized = vfmin_vf_f32m1(v_normalized, v_one, vl);\n\n        vfloat32m1_t v_B = vmerge_vvm_f32m1(mask, v_normalized, v_A, vl);\n        vse32_v_f32m1(&B[i], v_B, vl);\n    }\n\n    for (; i < size; ++i) {\n        if (control[i] > 0) {\n            float val = (A[i] - min_val) / (max_val - min_val);\n            B[i] = (val < 0.0f) ? 0.0f : (val > 1.0f) ? 1.0f : val;\n        } else {\n            B[i] = A[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_55_RVV", "completion": "```c\nvoid conditional_normalize_simd(const float* A, const int32_t* control, float* B, size_t size, float min_val, float max_val) {\n    size_t vl = vsetvl_e32m1(size);\n    size_t i;\n\n    for (i = 0; i < size; i += vl) {\n        vl = vsetvl_e32m1(size - i);\n\n        vfloat32m1_t va = vle32_v_f32m1(&A[i], vl);\n        vint32m1_t vctrl = vle32_v_i32m1(&control[i], vl);\n\n        vbool32_t mask = vmv_v_x_i32m1_b32(vl, 0);\n        mask = vmseq_vx_i32m1_b32(mask, vctrl, 0, vl);\n\n        vfloat32m1_t vmin = vfmv_v_f_f32m1(min_val, vl);\n        vfloat32m1_t vmax = vfmv_v_f_f32m1(max_val, vl);\n\n        vfloat32m1_t vnorm = vfsub_vv_f32m1(va, vmin, vl);\n        vnorm = vfdiv_vv_f32m1(vnorm, vfsub_vv_f32m1(vmax, vmin, vl), vl);\n\n        vnorm = vfmin_vf_f32m1(vnorm, 1.0f, vl);\n        vnorm = vfmax_vf_f32m1(vnorm, 0.0f, vl);\n\n        vfloat32m1_t vb = vmerge_vvm_f32m1(mask, vnorm, va, vl);\n\n        vse32_v_f32m1(&B[i], vb, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_55_RVV", "completion": "```c\nvoid conditional_normalize_simd(const float* A, const int32_t* control, float* B, size_t size, float min_val, float max_val) {\n    size_t vl = vsetvl_e32m1(size);\n    size_t i;\n\n    for (i = 0; i < size; i += vl) {\n        vl = vsetvl_e32m1(size - i);\n\n        vfloat32m1_t va = vle32_v_f32m1(&A[i], vl);\n        vint32m1_t vctrl = vle32_v_i32m1(&control[i], vl);\n\n        vbool32_t mask = vmv_v_x_i32m1_b32(vl, 0);\n        mask = vmseq_vx_i32m1_b32(mask, vctrl, 0, vl);\n\n        vfloat32m1_t vmin = vfmv_v_f_f32m1(min_val, vl);\n        vfloat32m1_t vmax = vfmv_v_f_f32m1(max_val, vl);\n\n        vfloat32m1_t vnorm = vfsub_vv_f32m1(va, vmin, vl);\n        vnorm = vfdiv_vv_f32m1(vnorm, vfsub_vv_f32m1(vmax, vmin, vl), vl);\n\n        vnorm = vfmin_vf_f32m1(vnorm, 1.0f, vl);\n        vnorm = vfmax_vf_f32m1(vnorm, 0.0f, vl);\n\n        vfloat32m1_t vb = vmerge_vvm_f32m1(mask, vnorm, va, vl);\n\n        vse32_v_f32m1(&B[i], vb, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_55_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n\nvoid conditional_normalize_simd(const float* A, const int32_t* control, float* B, size_t size, float min_val, float max_val) {\n    size_t vl = vsetvl_e32m1(size);\n    size_t i = 0;\n\n    for (; i <= size - vl; i += vl) {\n        vl = vsetvl_e32m1(size - i);\n\n        vfloat32m1_t va = vle32_v_f32m1(&A[i], vl);\n        vint32m1_t vctrl = vle32_v_i32m1(&control[i], vl);\n\n        vbool32_t mask = vmseq_vx_i32m1_b32(vctrl, 0, vl);\n        vfloat32m1_t vmin = vfmv_v_f_f32m1(min_val, vl);\n        vfloat32m1_t vmax = vfmv_v_f_f32m1(max_val, vl);\n\n        vfloat32m1_t vnorm = vfsub_vv_f32m1(va, vmin, vl);\n        vnorm = vfdiv_vv_f32m1(vnorm, vfsub_vv_f32m1(vmax, vmin, vl), vl);\n\n        vnorm = vfmax_vf_f32m1(vnorm, 0.0f, vl);\n        vnorm = vfmin_vf_f32m1(vnorm, 1.0f, vl);\n\n        vfloat32m1_t vb = vmerge_vvm_f32m1(va, vnorm, mask, vl);\n        vse32_v_f32m1(&B[i], vb, vl);\n    }\n\n    for (; i < size; ++i) {\n        if (control[i] > 0) {\n            float val = (A[i] - min_val) / (max_val - min_val);\n            B[i] = (val < 0.0f) ? 0.0f : (val > 1.0f) ? 1.0f : val;\n        } else {\n            B[i] = A[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_55_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n\nvoid conditional_normalize_simd(const float* A, const int32_t* control, float* B, size_t size, float min_val, float max_val) {\n    size_t vl;\n    vfloat32m1_t vA, vB, vmin_val, vmax_val, vrange, vnorm;\n    vint32m1_t vcontrol;\n    vbool32_t vmask;\n\n    vmin_val = vfmv_v_f_f32m1(min_val, vl);\n    vmax_val = vfmv_v_f_f32m1(max_val, vl);\n    vrange = vfsub_vv_f32m1(vmax_val, vmin_val, vl);\n\n    for (size_t i = 0; i < size; i += vl) {\n        vl = vsetvl_e32m1(size - i);\n\n        vA = vle32_v_f32m1(&A[i], vl);\n        vcontrol = vle32_v_i32m1(&control[i], vl);\n\n        vmask = vmv_v_x_i32m1_b32(1, vl);\n        vmask = vmsgt_vx_i32m1_b32(vmask, vcontrol, 0, vl);\n\n        vnorm = vfsub_vv_f32m1(vA, vmin_val, vl);\n        vnorm = vfdiv_vv_f32m1(vnorm, vrange, vl);\n        vnorm = vfmin_vf_f32m1(vnorm, 1.0f, vl);\n        vnorm = vfmax_vf_f32m1(vnorm, 0.0f, vl);\n\n        vB = vmerge_vvm_f32m1(vnorm, vA, vmask, vl);\n\n        vse32_v_f32m1(&B[i], vB, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_56_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid int_to_float_sqrt_simd(const uint32_t* A, float* B, size_t size) {\n    size_t vl = vsetvl_e32m1(size);\n    for (size_t i = 0; i < size; i += vl) {\n        vl = vsetvl_e32m1(size - i);\n        vuint32m1_t v_a = vle32_v_u32m1(&A[i], vl);\n        vuint32m1_t v_a_high = vsrl_vx_u32m1(v_a, 16, vl);\n        vfloat32m1_t v_a_float = vfcvt_f_xu_v_f32m1(v_a_high, vl);\n        vfloat32m1_t v_a_sqrt = vfsqrt_v_f32m1(v_a_float, vl);\n        vse32_v_f32m1(&B[i], v_a_sqrt, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_56_RVV", "completion": "```c\nvoid int_to_float_sqrt_simd(const uint32_t* A, float* B, size_t size) {\n    size_t vl = __riscv_vsetvl_e32m1(size);\n    for (size_t i = 0; i < size; i += vl) {\n        vl = __riscv_vsetvl_e32m1(size - i);\n        vuint32m1_t va = __riscv_vle32_v_u32m1(&A[i], vl);\n        vuint32m1_t vhigh = __riscv_vsrl_vx_u32m1(va, 16, vl);\n        vfloat32m1_t vf = __riscv_vfcvt_f_xu_v_f32m1(vhigh, vl);\n        vfloat32m1_t vsqrt = __riscv_vfsqrt_v_f32m1(vf, vl);\n        __riscv_vse32_v_f32m1(&B[i], vsqrt, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_56_RVV", "completion": "```c\nvoid int_to_float_sqrt_simd(const uint32_t* A, float* B, size_t size) {\n    size_t vl = __riscv_vsetvl_e32m1(size);\n    for (size_t i = 0; i < size; i += vl) {\n        vl = __riscv_vsetvl_e32m1(size - i);\n        vuint32m1_t v_a = __riscv_vle32_v_u32m1(&A[i], vl);\n        vuint32m1_t v_high_bits = __riscv_vsrl_vx_u32m1(v_a, 16, vl);\n        vfloat32m1_t v_float = __riscv_vfcvt_f_x_v_f32m1(v_high_bits, vl);\n        v_float = __riscv_vfsqrt_v_f32m1(v_float, vl);\n        __riscv_vse32_v_f32m1(&B[i], v_float, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_56_RVV", "completion": "```c\nvoid int_to_float_sqrt_simd(const uint32_t* A, float* B, size_t size) {\n    size_t vl = vsetvl_e32m1(size);\n    for (size_t i = 0; i < size; i += vl) {\n        vl = vsetvl_e32m1(size - i);\n        vuint32m1_t va = vle32_v_u32m1(&A[i], vl);\n        vuint32m1_t vhigh = vsrl_vx_u32m1(va, 16, vl);\n        vfloat32m1_t vf = vfcvt_f_xu_v_f32m1(vhigh, vl);\n        vf = vfsqrt_v_f32m1(vf, vl);\n        vse32_v_f32m1(&B[i], vf, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_56_RVV", "completion": "```c\nvoid int_to_float_sqrt_simd(const uint32_t* A, float* B, size_t size) {\n    size_t vl = vsetvl_e32m1(size);\n    for (size_t i = 0; i < size; i += vl) {\n        vl = vsetvl_e32m1(size - i);\n        vuint32m1_t v_a = vle32_v_u32m1(&A[i], vl);\n        vuint32m1_t v_a_high = vsrl_vx_u32m1(v_a, 16, vl);\n        vfloat32m1_t v_a_float = vfcvt_f_xu_v_f32m1(v_a_high, vl);\n        vfloat32m1_t v_result = vfsqrt_v_f32m1(v_a_float, vl);\n        vse32_v_f32m1(&B[i], v_result, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_57_RVV", "completion": "```c\nvoid int_bits_to_float_simd(const uint32_t* A, float* B, size_t size) {\n    size_t vl = vsetvl_e32m8(size);\n    for (size_t i = 0; i < size; i += vl) {\n        vl = vsetvl_e32m8(size - i);\n        vuint32m8_t va = vle32_v_u32m8(&A[i], vl);\n        vfloat32m8_t vb = vreinterpret_v_u32m8_f32m8(va);\n        vse32_v_f32m8(&B[i], vb, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_57_RVV", "completion": "```c\nvoid int_bits_to_float_simd(const uint32_t* A, float* B, size_t size) {\n    size_t vl = __riscv_vsetvl_e32m8(size);\n    for (size_t i = 0; i < size; i += vl) {\n        vl = __riscv_vsetvl_e32m8(size - i);\n        vuint32m8_t va = __riscv_vle32_v_u32m8(&A[i], vl);\n        vfloat32m8_t vb = __riscv_vreinterpret_v_u32m8_f32m8(va);\n        __riscv_vse32_v_f32m8(&B[i], vb, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_57_RVV", "completion": "```c\nvoid int_bits_to_float_simd(const uint32_t* A, float* B, size_t size) {\n    size_t i;\n    for (i = 0; i < size; i += 4) {\n        vuint32m1_t va = vle32_v_u32m1(&A[i], 4);\n        vfloat32m1_t vb = vreinterpret_v_f32m1_u32m1(va);\n        vse32_v_f32m1(&B[i], vb, 4);\n    }\n}\n```"}
{"task_id": "SimdBench_57_RVV", "completion": "```c\nvoid int_bits_to_float_simd(const uint32_t* A, float* B, size_t size) {\n    size_t vl = __riscv_vsetvl_e32m1(size);\n    for (size_t i = 0; i < size; i += vl) {\n        vl = __riscv_vsetvl_e32m1(size - i);\n        vuint32m1_t va = __riscv_vle32_v_u32m1(&A[i], vl);\n        vfloat32m1_t vb = __riscv_vreinterpret_v_u32m1_f32m1(va);\n        __riscv_vse32_v_f32m1(&B[i], vb, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_57_RVV", "completion": "```c\nvoid int_bits_to_float_simd(const uint32_t* A, float* B, size_t size) {\n    size_t vl = vsetvl_e32m1(size);\n    for (size_t i = 0; i < size; i += vl) {\n        vl = vsetvl_e32m1(size - i);\n        vuint32m1_t va = vle32_v_u32m1(&A[i], vl);\n        vfloat32m1_t vb = vreinterpret_v_u32m1_f32m1(va);\n        vse32_v_f32m1(&B[i], vb, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_58_RVV", "completion": "```c\nvoid conditional_diff_simd(const int32_t* A, const bool* cond, float* diff, size_t size) {\n    size_t vl = __riscv_vsetvl_e32m1(size);\n    vint32m1_t vA = __riscv_vle32_v_i32m1(A, vl);\n    vint32m1_t vA_prev = __riscv_vslideup_vx_i32m1(vA, 0, vl);\n    vint32m1_t vdiff_int = __riscv_vsub_vv_i32m1(vA, vA_prev, vl);\n    vbool32_t vcond = __riscv_vle32_v_u32m1((const uint32_t*)cond, vl);\n    vfloat32m1_t vdiff_float = __riscv_vfcvt_f_x_v_f32m1(vdiff_int, vl);\n    vfloat32m1_t vdiff = __riscv_vmerge_vxm_f32m1(__riscv_vfmv_v_f_f32m1(0.0f, vl), vdiff_float, vcond, vl);\n    vdiff = __riscv_vslideup_vx_f32m1(vdiff, 0, vl);\n    __riscv_vse32_v_f32m1(diff, vdiff, vl);\n}\n```"}
{"task_id": "SimdBench_58_RVV", "completion": "```cpp\nvoid conditional_diff_simd(const int32_t* A, const bool* cond, float* diff, size_t size) {\n    size_t vl = vsetvl_e32m1(size);\n    vint32m1_t vA = vle32_v_i32m1(A, vl);\n    vint32m1_t vA_prev = vslide1down_vx_i32m1(vA, 0, vl);\n    vbool32_t vcond = vle_v_b32(cond, vl);\n    vint32m1_t vdiff_int = vsub_vv_i32m1(vA, vA_prev, vl);\n    vfloat32m1_t vdiff_float = vfcvt_f_x_v_f32m1(vdiff_int, vl);\n    vfloat32m1_t vdiff_zero = vfmv_v_f_f32m1(0.0f, vl);\n    vfloat32m1_t vdiff = vmerge_vvm_f32m1(vdiff_zero, vdiff_float, vcond, vl);\n    vdiff = vslide1up_vx_f32m1(vdiff, 0.0f, vl);\n    vse32_v_f32m1(diff, vdiff, vl);\n}\n```"}
{"task_id": "SimdBench_58_RVV", "completion": "```c\nvoid conditional_diff_simd(const int32_t* A, const bool* cond, float* diff, size_t size) {\n    size_t vl = vsetvl_e32m1(size);\n    vint32m1_t vA = vle32_v_i32m1(A, vl);\n    vint32m1_t vA_prev = vslide1down_vx_i32m1(vA, 0, vl);\n    vint32m1_t vdiff_int = vsub_vv_i32m1(vA, vA_prev, vl);\n    vuint8mf8_t vcond = vle8_v_u8mf8((const uint8_t*)cond, vl);\n    vuint8mf8_t vcond_broadcast = vzext_vf8_u8mf8(vcond, vl);\n    vuint8mf8_t vcond_mask = vmseq_vx_u8mf8(vcond_broadcast, 1, vl);\n    vfloat32m1_t vdiff_float = vfcvt_f_x_v_f32m1(vdiff_int, vl);\n    vfloat32m1_t vdiff_zero = vfmv_v_f_f32m1(0.0f, vl);\n    vfloat32m1_t vdiff = vmerge_vvm_f32m1(vdiff_float, vdiff_zero, vcond_mask, vl);\n    vdiff = vslide1down_vx_f32m1(vdiff, 0.0f, vl);\n    vse32_v_f32m1(diff, vdiff, vl);\n}\n```"}
{"task_id": "SimdBench_58_RVV", "completion": "```c\nvoid conditional_diff_simd(const int32_t* A, const bool* cond, float* diff, size_t size) {\n    size_t vl = __riscv_vsetvl_e32m1(size);\n    vint32m1_t vA = __riscv_vle32_v_i32m1(A, vl);\n    vint32m1_t vA_prev = __riscv_vslideup_vx_i32m1(vA, 0, vl);\n    vint32m1_t vdiff_int = __riscv_vsub_vv_i32m1(vA, vA_prev, vl);\n\n    vuint8mf8_t vcond = __riscv_vle8_v_u8mf8((const uint8_t*)cond, vl);\n    vuint8mf8_t vcond_mask = __riscv_vmsif_m_b8(vcond, vl);\n\n    vfloat32m1_t vdiff_float = __riscv_vfcvt_f_x_v_f32m1(vdiff_int, vl);\n    vfloat32m1_t vdiff_zero = __riscv_vfmv_v_f_f32m1(0.0f, vl);\n    vfloat32m1_t vdiff = __riscv_vmerge_vvm_f32m1(vdiff_float, vdiff_zero, vcond_mask, vl);\n\n    vdiff = __riscv_vslideup_vx_f32m1(vdiff, 0, vl);\n    vdiff = __riscv_vfmv_s_f_f32m1_f32(0.0f, vdiff, vl);\n\n    __riscv_vse32_v_f32m1(diff, vdiff, vl);\n}\n```"}
{"task_id": "SimdBench_58_RVV", "completion": "```c\nvoid conditional_diff_simd(const int32_t* A, const bool* cond, float* diff, size_t size) {\n    size_t vl = vsetvl_e32m1(size);\n    vint32m1_t vA = vle32_v_i32m1(A, vl);\n    vint32m1_t vA_prev = vslide1down_vx_i32m1(vA, 0, vl);\n    vint32m1_t vdiff_int = vsub_vv_i32m1(vA, vA_prev, vl);\n\n    vuint8mf4_t vcond = vle8_v_u8mf4((const uint8_t*)cond, vl);\n    vuint8mf4_t vcond_mask = vmseq_vx_u8mf4(vcond, 0, vl);\n\n    vfloat32m1_t vdiff_float = vfcvt_f_x_v_f32m1(vdiff_int, vl);\n    vfloat32m1_t vdiff_zero = vfmv_v_f_f32m1(0.0f, vl);\n    vfloat32m1_t vdiff = vmerge_vvm_f32m1(vdiff_float, vdiff_zero, vcond_mask, vl);\n\n    vdiff = vslide1down_vx_f32m1(vdiff, 0, vl);\n    vse32_v_f32m1(diff, vdiff, vl);\n}\n```"}
{"task_id": "SimdBench_59_RVV", "completion": "```c\nvoid widening_uint_simd(const uint32_t* src, uint64_t* dst, size_t length) {\n    size_t vl = vsetvl_e32m1(length);\n    vuint32m1_t v_src = vle32_v_u32m1(src, vl);\n    vuint64m1_t v_dst = vwidenu_vx_u64m1(0xFFFFFFFF, v_src, vl);\n    vse64_v_u64m1(dst, v_dst, vl);\n}\n```"}
{"task_id": "SimdBench_59_RVV", "completion": "```c\nvoid widening_uint_simd(const uint32_t* src, uint64_t* dst, size_t length) {\n    size_t vl = vsetvl_e32m1(length);\n    vuint32m1_t v_src = vle32_v_u32m1(src, vl);\n    vuint64m1_t v_dst = vwidenu_vx_u64m1(1, v_src, vl);\n    vse64_v_u64m1(dst, v_dst, vl);\n}\n```"}
{"task_id": "SimdBench_59_RVV", "completion": "```c\nvoid widening_uint_simd(const uint32_t* src, uint64_t* dst, size_t length) {\n    size_t vl = vsetvl_e32m1(length);\n    vuint32m1_t v_src = vle32_v_u32m1(src, vl);\n    vuint64m1_t v_dst = vwidenu_vx_u64m1(v_src, 1, vl);\n    vse64_v_u64m1(dst, v_dst, vl);\n}\n```"}
{"task_id": "SimdBench_59_RVV", "completion": "```c\nvoid widening_uint_simd(const uint32_t* src, uint64_t* dst, size_t length) {\n    size_t vl = __riscv_vsetvl_e32m1(length);\n    vuint32m1_t v_src = __riscv_vle32_v_u32m1(src, vl);\n    vuint64m1_t v_dst = __riscv_vzext_vf2_u64m1(v_src, vl);\n    v_dst = __riscv_vsll_vx_u64m1(v_dst, 32, vl);\n    v_dst = __riscv_vadd_vx_u64m1(v_dst, 0xFFFFFFFF, vl);\n    __riscv_vse64_v_u64m1(dst, v_dst, vl);\n}\n```"}
{"task_id": "SimdBench_59_RVV", "completion": "```c\nvoid widening_uint_simd(const uint32_t* src, uint64_t* dst, size_t length) {\n    size_t vl = __riscv_vsetvl_e32m1(length);\n    vuint32m1_t v_src = __riscv_vle32_v_u32m1(src, vl);\n    vuint64m2_t v_dst = __riscv_vzext_vf2_u64m2(v_src, vl);\n    v_dst = __riscv_vsll_vx_u64m2(v_dst, 32, vl);\n    v_dst = __riscv_vadd_vx_u64m2(v_dst, 0xFFFFFFFF, vl);\n    __riscv_vse64_v_u64m2(dst, v_dst, vl);\n}\n```"}
{"task_id": "SimdBench_60_RVV", "completion": "```c\ndouble indexed_sum_simd(const double* vec, const int16_t* index, size_t length) {\n    double sum = 0.0;\n    size_t vl = __riscv_vsetvl_e64m1(length);\n    vfloat64m1_t vsum = __riscv_vfmv_v_f_f64m1(0.0, vl);\n    vint16m1_t vind = __riscv_vle16_v_i16m1(index, vl);\n    vint64m1_t vind64 = __riscv_vwcvtu_x_x_v_i64m1(vind, vl);\n    vfloat64m1_t vvec = __riscv_vlgatherei64_v_f64m1(vec, vind64, vl);\n    vsum = __riscv_vfredusum_vs_f64m1_f64m1(vsum, vvec, vsum, vl);\n    sum = __riscv_vfmv_f_s_f64m1_f64(vsum);\n    return sum;\n}\n```"}
{"task_id": "SimdBench_60_RVV", "completion": "```c\ndouble indexed_sum_simd(const double* vec, const int16_t* index, size_t length) {\n    double sum = 0.0;\n    size_t vl = __riscv_vsetvl_e64m1(length);\n    vfloat64m1_t vsum = __riscv_vfmv_v_f_f64m1(0.0, vl);\n    vint16m1_t vind = __riscv_vle16_v_i16m1(index, vl);\n    vbool64_t mask = __riscv_vmslt_vx_i16m1_b16(vind, length, vl);\n\n    for (size_t i = 0; i < length; i += vl) {\n        vl = __riscv_vsetvl_e64m1(length - i);\n        vind = __riscv_vle16_v_i16m1(index + i, vl);\n        mask = __riscv_vmslt_vx_i16m1_b16(vind, length, vl);\n        vfloat64m1_t vvec = __riscv_vlgatherei64_v_f64m1(vec, vind, vl);\n        vsum = __riscv_vfredusum_vs_f64m1_f64m1(vsum, vvec, mask, vsum);\n    }\n\n    sum = __riscv_vfmv_f_s_f64m1_f64(vsum);\n    return sum;\n}\n```"}
{"task_id": "SimdBench_60_RVV", "completion": "```c\ndouble indexed_sum_simd(const double* vec, const int16_t* index, size_t length) {\n    size_t vl = __riscv_vsetvl_e64m1(length);\n    vfloat64m1_t vsum = __riscv_vfmv_v_f_f64m1(0.0, vl);\n    size_t i = 0;\n\n    for (; i <= length - vl; i += vl) {\n        vint16m1_t vindices = __riscv_vle16_v_i16m1(index + i, vl);\n        vfloat64m1_t vvec = __riscv_vlgathere16_v_f64m1(vec, vindices, vl);\n        vsum = __riscv_vfredusum_vs_f64m1_f64m1(vsum, vvec, vsum, vl);\n    }\n\n    if (i < length) {\n        vl = __riscv_vsetvl_e64m1(length - i);\n        vint16m1_t vindices = __riscv_vle16_v_i16m1(index + i, vl);\n        vfloat64m1_t vvec = __riscv_vlgathere16_v_f64m1(vec, vindices, vl);\n        vsum = __riscv_vfredusum_vs_f64m1_f64m1(vsum, vvec, vsum, vl);\n    }\n\n    return __riscv_vfmv_f_s_f64m1_f64(vsum);\n}\n```"}
{"task_id": "SimdBench_60_RVV", "completion": "```c\ndouble indexed_sum_simd(const double* vec, const int16_t* index, size_t length) {\n    double sum = 0.0;\n    size_t vl = __riscv_vsetvl_e64m1(length);\n    vfloat64m1_t vsum = __riscv_vfmv_v_f_f64m1(0.0, vl);\n    vint16m1_t vind = __riscv_vle16_v_i16m1(index, vl);\n    vbool64_t mask = __riscv_vmslt_vx_i16m1_b16(vind, length, vl);\n\n    for (size_t i = 0; i < length; i += vl) {\n        vl = __riscv_vsetvl_e64m1(length - i);\n        vind = __riscv_vle16_v_i16m1(index + i, vl);\n        mask = __riscv_vmslt_vx_i16m1_b16(vind, length, vl);\n        vfloat64m1_t vvec = __riscv_vlgatherei64_v_f64m1(vec, vind, vl);\n        vsum = __riscv_vfmacc_vv_f64m1_m(mask, vsum, vvec, vsum, vl);\n    }\n\n    sum = __riscv_vfmv_f_s_f64m1_f64(vsum);\n    return sum;\n}\n```"}
{"task_id": "SimdBench_60_RVV", "completion": "```c\ndouble indexed_sum_simd(const double* vec, const int16_t* index, size_t length) {\n    size_t vl = __riscv_vsetvl_e64m1(length);\n    vfloat64m1_t vsum = __riscv_vfmv_v_f_f64m1(0.0, vl);\n    size_t i = 0;\n\n    for (; i <= length - vl; i += vl) {\n        vint16m1_t vindices = __riscv_vle16_v_i16m1(index + i, vl);\n        vfloat64m1_t vvec = __riscv_vlgather_vv_f64m1(vec, vindices, vl);\n        vsum = __riscv_vfredusum_vs_f64m1_f64m1(vsum, vvec, vsum, vl);\n    }\n\n    double sum = __riscv_vfmv_f_s_f64m1_f64(vsum);\n\n    for (; i < length; ++i) {\n        sum += vec[index[i]];\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_61_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid simple_conv2d_simd(const double* input, const double* kernel, double * output, size_t input_size, size_t kernel_size) {\n    size_t output_size = input_size - kernel_size + 1;\n    size_t output_length = output_size * output_size;\n\n    for (size_t i = 0; i < output_length; ++i) {\n        size_t row = i / output_size;\n        size_t col = i % output_size;\n\n        double sum = 0.0;\n        for (size_t ki = 0; ki < kernel_size; ++ki) {\n            for (size_t kj = 0; kj < kernel_size; ++kj) {\n                size_t input_index = (row + ki) * input_size + (col + kj);\n                size_t kernel_index = ki * kernel_size + kj;\n                sum += input[input_index] * kernel[kernel_index];\n            }\n        }\n\n        output[i] = (sum > 0.0) ? sum : 0.0;\n    }\n}\n```"}
{"task_id": "SimdBench_61_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid simple_conv2d_simd(const double* input, const double* kernel, double * output, size_t input_size, size_t kernel_size) {\n    size_t output_size = input_size - kernel_size + 1;\n    size_t output_len = output_size * output_size;\n\n    for (size_t i = 0; i < output_len; ++i) {\n        size_t row = i / output_size;\n        size_t col = i % output_size;\n\n        vfloat64m1_t vsum = __riscv_vfmv_v_f_f64m1(0.0, output_len);\n        for (size_t ki = 0; ki < kernel_size; ++ki) {\n            for (size_t kj = 0; kj < kernel_size; ++kj) {\n                size_t input_index = (row + ki) * input_size + (col + kj);\n                size_t kernel_index = ki * kernel_size + kj;\n\n                vfloat64m1_t vinput = __riscv_vfmv_v_f_f64m1(input[input_index], output_len);\n                vfloat64m1_t vkernel = __riscv_vfmv_v_f_f64m1(kernel[kernel_index], output_len);\n\n                vsum = __riscv_vfadd_vv_f64m1(vsum, __riscv_vfmul_vv_f64m1(vinput, vkernel), output_len);\n            }\n        }\n\n        double sum = __riscv_vfmv_f_s_f64m1_f64(vsum);\n        output[i] = (sum > 0) ? sum : 0.0;\n    }\n}\n```"}
{"task_id": "SimdBench_61_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid simple_conv2d_simd(const double* input, const double* kernel, double * output, size_t input_size, size_t kernel_size) {\n    size_t output_size = input_size - kernel_size + 1;\n    size_t output_length = output_size * output_size;\n\n    for (size_t i = 0; i < output_length; ++i) {\n        size_t row = i / output_size;\n        size_t col = i % output_size;\n\n        vfloat64m1_t vsum = __riscv_vfmv_v_f_f64m1(0.0, output_length);\n        for (size_t ki = 0; ki < kernel_size; ++ki) {\n            for (size_t kj = 0; kj < kernel_size; ++kj) {\n                size_t input_index = (row + ki) * input_size + (col + kj);\n                size_t kernel_index = ki * kernel_size + kj;\n\n                vfloat64m1_t vinput = __riscv_vfmv_v_f_f64m1(input[input_index], output_length);\n                vfloat64m1_t vkernel = __riscv_vfmv_v_f_f64m1(kernel[kernel_index], output_length);\n\n                vsum = __riscv_vfadd_vv_f64m1(vsum, __riscv_vfmul_vv_f64m1(vinput, vkernel), output_length);\n            }\n        }\n\n        double sum = __riscv_vfmv_f_s_f64m1_f64(vsum);\n        output[i] = (sum > 0) ? sum : 0.0;\n    }\n}\n```"}
{"task_id": "SimdBench_61_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid simple_conv2d_simd(const double* input, const double* kernel, double * output, size_t input_size, size_t kernel_size) {\n    size_t output_size = input_size - kernel_size + 1;\n    size_t output_len = output_size * output_size;\n\n    for (size_t i = 0; i < output_len; ++i) {\n        size_t row = i / output_size;\n        size_t col = i % output_size;\n\n        double sum = 0.0;\n        for (size_t ki = 0; ki < kernel_size; ++ki) {\n            for (size_t kj = 0; kj < kernel_size; ++kj) {\n                size_t input_index = (row + ki) * input_size + (col + kj);\n                size_t kernel_index = ki * kernel_size + kj;\n                sum += input[input_index] * kernel[kernel_index];\n            }\n        }\n\n        output[i] = (sum > 0.0) ? sum : 0.0;\n    }\n}\n```"}
{"task_id": "SimdBench_61_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid simple_conv2d_simd(const double* input, const double* kernel, double * output, size_t input_size, size_t kernel_size) {\n    size_t output_size = input_size - kernel_size + 1;\n    size_t vl = vsetvl_e64m1(output_size);\n\n    for (size_t i = 0; i < output_size; ++i) {\n        for (size_t j = 0; j < output_size; ++j) {\n            vfloat64m1_t vsum = vfmv_v_f_f64m1(0.0, vl);\n            for (size_t ki = 0; ki < kernel_size; ++ki) {\n                for (size_t kj = 0; kj < kernel_size; ++kj) {\n                    size_t input_index = (i + ki) * input_size + (j + kj);\n                    size_t kernel_index = ki * kernel_size + kj;\n                    vfloat64m1_t vinput = vfmv_v_f_f64m1(input[input_index], vl);\n                    vfloat64m1_t vkernel = vfmv_v_f_f64m1(kernel[kernel_index], vl);\n                    vfloat64m1_t vprod = vfmul_vv_f64m1(vinput, vkernel, vl);\n                    vsum = vfadd_vv_f64m1(vsum, vprod, vl);\n                }\n            }\n            vfloat64m1_t vrelu = vfmax_vf_f64m1(vsum, 0.0, vl);\n            vssegeseg_e64(vrelu, output, vl);\n            output += vl;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_62_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nbool has_close_elements_simd(const std::vector<double> & numbers, double threshold) {\n    size_t n = numbers.size();\n    if (n < 2) return false;\n\n    size_t vlmax = __riscv_vsetvlmax_e64m1();\n    for (size_t i = 0; i < n; i += vlmax) {\n        size_t vl = __riscv_vsetvl_e64m1(n - i);\n        vfloat64m1_t v_a = __riscv_vle64_v_f64m1(&numbers[i], vl);\n\n        for (size_t j = i + 1; j < n; j += vlmax) {\n            size_t vl2 = __riscv_vsetvl_e64m1(n - j);\n            vfloat64m1_t v_b = __riscv_vle64_v_f64m1(&numbers[j], vl2);\n\n            vfloat64m1_t v_diff = __riscv_vfsub_vv_f64m1(v_a, v_b, vl);\n            vfloat64m1_t v_abs_diff = __riscv_vfabs_v_f64m1(v_diff, vl);\n            vbool64_t v_close = __riscv_vmflt_vf_f64m1_b64(v_abs_diff, threshold, vl);\n\n            if (__riscv_vfirst_m_b64(v_close, vl) != -1) {\n                return true;\n            }\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_62_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nbool has_close_elements_simd(const std::vector<double> & numbers, double threshold) {\n    size_t n = numbers.size();\n    if (n < 2) return false;\n\n    size_t vl = __riscv_vsetvl_e64m1(n);\n    vfloat64m1_t v_numbers = __riscv_vle64_v_f64m1(numbers.data(), vl);\n\n    for (size_t i = 0; i < n; ++i) {\n        vfloat64m1_t v_diff = __riscv_vfsub_vv_f64m1(v_numbers, __riscv_vfmv_s_f_f64m1(numbers[i], vl), vl);\n        vbool64_t v_mask = __riscv_vfclass_v_f64m1_b64(v_diff, vl, VFCLASS_LE, threshold);\n        if (__riscv_vfirst_m_b64(v_mask, vl) != -1) {\n            return true;\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_62_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nbool has_close_elements_simd(const std::vector<double> & numbers, double threshold) {\n    size_t n = numbers.size();\n    if (n < 2) return false;\n\n    size_t vlmax = __riscv_vsetvlmax_e64m1();\n    for (size_t i = 0; i < n; i += vlmax) {\n        size_t vl = __riscv_vsetvl_e64m1(n - i);\n        vfloat64m1_t v_a = __riscv_vle64_v_f64m1(&numbers[i], vl);\n\n        for (size_t j = i + 1; j < n; j += vlmax) {\n            size_t vl2 = __riscv_vsetvl_e64m1(n - j);\n            vfloat64m1_t v_b = __riscv_vle64_v_f64m1(&numbers[j], vl2);\n\n            vfloat64m1_t v_diff = __riscv_vfsub_vv_f64m1(v_a, v_b, vl);\n            vbool64_t v_mask = __riscv_vmfle_vf_f64m1_b64(v_diff, threshold, vl);\n\n            if (__riscv_vfirst_m_b64(v_mask, vl)) {\n                return true;\n            }\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_62_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nbool has_close_elements_simd(const std::vector<double> & numbers, double threshold) {\n    size_t n = numbers.size();\n    if (n < 2) return false;\n\n    size_t vlmax = __riscv_vsetvlmax_e64m1();\n    size_t vl = vlmax;\n\n    for (size_t i = 0; i < n; i += vl) {\n        vl = __riscv_vsetvl_e64m1(n - i);\n        vfloat64m1_t v_a = __riscv_vle64_v_f64m1(&numbers[i], vl);\n\n        for (size_t j = i + 1; j < n; j += vl) {\n            vl = __riscv_vsetvl_e64m1(n - j);\n            vfloat64m1_t v_b = __riscv_vle64_v_f64m1(&numbers[j], vl);\n\n            vfloat64m1_t diff = __riscv_vfsub_vv_f64m1(v_a, v_b, vl);\n            vbool64_t mask = __riscv_vmfge_vf_f64m1_b64(diff, -threshold, vl);\n            mask = __riscv_vmand_mm_b64(mask, __riscv_vmfle_vf_f64m1_b64(diff, threshold, vl), vl);\n\n            if (__riscv_vfirst_m_b64(mask, vl) != -1) {\n                return true;\n            }\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_62_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nbool has_close_elements_simd(const std::vector<double> & numbers, double threshold) {\n    size_t n = numbers.size();\n    if (n < 2) return false;\n\n    size_t vl = __riscv_vsetvl_e64m1(n);\n    vfloat64m1_t v_numbers = __riscv_vle64_v_f64m1(numbers.data(), vl);\n\n    for (size_t i = 0; i < n; ++i) {\n        vfloat64m1_t v_diff = __riscv_vfsub_vv_f64m1(v_numbers, __riscv_vfmv_s_f_f64m1(numbers[i], vl), vl);\n        vbool64_t v_close = __riscv_vmflt_vf_f64m1_b64(v_diff, threshold, vl);\n        if (__riscv_vfirst_m_b64(v_close, vl) != -1) return true;\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_63_RVV", "completion": "```cpp\nbool below_zero_simd(std::vector<int> operations) {\n    size_t n = operations.size();\n    vint32m1_t v_balance = __riscv_vmv_v_x_i32m1(0, 0);\n    vint32m1_t v_operations = __riscv_vle32_v_i32m1(operations.data(), n);\n\n    for (size_t i = 0; i < n; i += __riscv_vsetvl_e32m1(n - i)) {\n        v_balance = __riscv_vadd_vv_i32m1(v_balance, v_operations, __riscv_vsetvl_e32m1(n - i));\n        vint32m1_t v_ltz = __riscv_vmslt_vx_i32m1_b32(v_balance, 0, __riscv_vsetvl_e32m1(n - i));\n        if (__riscv_vfirst_m_b32(v_ltz, __riscv_vsetvl_e32m1(n - i)) != -1) {\n            return true;\n        }\n        v_operations = __riscv_vle32_v_i32m1(operations.data() + i + __riscv_vsetvl_e32m1(n - i), n - i);\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_63_RVV", "completion": "```c++\nbool below_zero_simd(std::vector<int> operations) {\n    size_t n = operations.size();\n    vint32m1_t v_balance = __riscv_vmv_v_x_i32m1(0, 0);\n    vint32m1_t v_operations = __riscv_vle32_v_i32m1(operations.data(), n);\n\n    for (size_t i = 0; i < n; i += __riscv_vsetvl_e32m1(n - i)) {\n        v_balance = __riscv_vadd_vv_i32m1(v_balance, v_operations, __riscv_vsetvl_e32m1(n - i));\n        vint32m1_t v_ltz = __riscv_vmslt_vx_i32m1_b32(v_balance, 0, __riscv_vsetvl_e32m1(n - i));\n        if (__riscv_vfirst_m_b32(v_ltz, __riscv_vsetvl_e32m1(n - i)) != -1) {\n            return true;\n        }\n        v_operations = __riscv_vle32_v_i32m1(operations.data() + i + __riscv_vsetvl_e32m1(n - i), n - i - __riscv_vsetvl_e32m1(n - i));\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_63_RVV", "completion": "```c++\nbool below_zero_simd(std::vector<int> operations) {\n    size_t n = operations.size();\n    vint32m1_t v_balance = __riscv_vmv_v_x_i32m1(0, 32);\n    vint32m1_t v_operations = __riscv_vle32_v_i32m1(operations.data(), n);\n\n    for (size_t i = 0; i < n; i += 32) {\n        size_t vl = __riscv_vsetvl_e32m1(n - i);\n        v_balance = __riscv_vadd_vv_i32m1(v_balance, v_operations, vl);\n        vint32m1_t v_ltz = __riscv_vmslt_vx_i32m1_b32(v_balance, 0, vl);\n        if (__riscv_vmv_x_s_b32(v_ltz)) {\n            return true;\n        }\n        v_operations = __riscv_vle32_v_i32m1(operations.data() + i + 32, n - i - 32);\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_63_RVV", "completion": "```cpp\nbool below_zero_simd(std::vector<int> operations) {\n    size_t n = operations.size();\n    vint32m1_t v_balance = __riscv_vmv_v_x_i32m1(0, 0);\n    vint32m1_t v_operations = __riscv_vle32_v_i32m1(operations.data(), n);\n\n    for (size_t i = 0; i < n; i += __riscv_vsetvl_e32m1(n - i)) {\n        v_balance = __riscv_vadd_vv_i32m1(v_balance, v_operations, __riscv_vsetvl_e32m1(n - i));\n        vint32m1_t v_ltz = __riscv_vmslt_vx_i32m1_b32(v_balance, 0, __riscv_vsetvl_e32m1(n - i));\n        if (__riscv_vfirst_m_b32(v_ltz, __riscv_vsetvl_e32m1(n - i)) >= 0) {\n            return true;\n        }\n        v_operations = __riscv_vle32_v_i32m1(operations.data() + i + __riscv_vsetvl_e32m1(n - i), n - i);\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_63_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nbool below_zero_simd(std::vector<int> operations) {\n    size_t n = operations.size();\n    vint32m1_t v_balance = __riscv_vmv_v_x_i32m1(0, 32);\n    vint32m1_t v_operations = __riscv_vle32_v_i32m1(operations.data(), n);\n\n    for (size_t i = 0; i < n; i += 32) {\n        size_t vl = __riscv_vsetvl_e32m1(n - i);\n        v_balance = __riscv_vadd_vv_i32m1(v_balance, v_operations, vl);\n        v_operations = __riscv_vle32_v_i32m1(operations.data() + i, vl);\n\n        vint32m1_t v_ltz = __riscv_vmslt_vx_i32m1(v_balance, 0, vl);\n        if (__riscv_vmv_x_s_i32m1_i32(v_ltz) != 0) {\n            return true;\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_64_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <cmath>\n\ndouble mean_absolute_deviation_simd(std::vector<double> numbers) {\n    size_t n = numbers.size();\n    vfloat64m1_t v_numbers = __riscv_vle64_v_f64m1(numbers.data(), n, 1);\n\n    vfloat64m1_t v_sum = __riscv_vfmv_s_f_f64m1(0.0, vfloat64m1);\n    v_sum = __riscv_vfredusum_vs_f64m1_f64m1(v_sum, v_numbers, v_sum, n);\n\n    double sum = __riscv_vfmv_f_s_f64m1_f64(v_sum);\n    double mean = sum / n;\n\n    vfloat64m1_t v_mean = __riscv_vfmv_v_f_f64m1(mean, vfloat64m1);\n    vfloat64m1_t v_diff = __riscv_vfsub_vv_f64m1(v_numbers, v_mean, n);\n    vfloat64m1_t v_abs_diff = __riscv_vfabs_v_f64m1(v_diff, n);\n\n    vfloat64m1_t v_mad_sum = __riscv_vfmv_s_f_f64m1(0.0, vfloat64m1);\n    v_mad_sum = __riscv_vfredusum_vs_f64m1_f64m1(v_mad_sum, v_abs_diff, v_mad_sum, n);\n\n    double mad_sum = __riscv_vfmv_f_s_f64m1_f64(v_mad_sum);\n    double mad = mad_sum / n;\n\n    return mad;\n}\n```"}
{"task_id": "SimdBench_64_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <cmath>\n\ndouble mean_absolute_deviation_simd(std::vector<double> numbers) {\n    size_t n = numbers.size();\n    if (n == 0) return 0.0;\n\n    double sum = 0.0;\n    for (size_t i = 0; i < n; ++i) {\n        sum += numbers[i];\n    }\n    double mean = sum / n;\n\n    double mad_sum = 0.0;\n    size_t vl = __riscv_vsetvl_e64m1(n);\n    vfloat64m1_t v_mean = __riscv_vfmv_v_f_f64m1(mean, vl);\n    vfloat64m1_t v_mad_sum = __riscv_vfmv_v_f_f64m1(0.0, vl);\n\n    for (size_t i = 0; i < n; i += vl) {\n        vl = __riscv_vsetvl_e64m1(n - i);\n        vfloat64m1_t v_numbers = __riscv_vle64_v_f64m1(&numbers[i], vl);\n        vfloat64m1_t v_diff = __riscv_vfsub_vv_f64m1(v_numbers, v_mean, vl);\n        vfloat64m1_t v_abs_diff = __riscv_vfabs_v_f64m1(v_diff, vl);\n        v_mad_sum = __riscv_vfredusum_vs_f64m1_f64m1(v_mad_sum, v_abs_diff, v_mad_sum, vl);\n    }\n\n    mad_sum = __riscv_vfmv_f_s_f64m1_f64(v_mad_sum);\n    return mad_sum / n;\n}\n```"}
{"task_id": "SimdBench_64_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <cmath>\n\ndouble mean_absolute_deviation_simd(std::vector<double> numbers) {\n    size_t n = numbers.size();\n    if (n == 0) return 0.0;\n\n    double sum = 0.0;\n    for (size_t i = 0; i < n; ++i) {\n        sum += numbers[i];\n    }\n    double mean = sum / n;\n\n    double mad_sum = 0.0;\n    size_t vl = __riscv_vsetvl_e64m1(n);\n    vfloat64m1_t v_mean = __riscv_vfmv_v_f_f64m1(mean, vl);\n    vfloat64m1_t v_mad_sum = __riscv_vfmv_v_f_f64m1(0.0, vl);\n\n    for (size_t i = 0; i < n; i += vl) {\n        vl = __riscv_vsetvl_e64m1(n - i);\n        vfloat64m1_t v_numbers = __riscv_vle64_v_f64m1(&numbers[i], vl);\n        vfloat64m1_t v_diff = __riscv_vfsub_vv_f64m1(v_numbers, v_mean, vl);\n        vfloat64m1_t v_abs_diff = __riscv_vfabs_v_f64m1(v_diff, vl);\n        v_mad_sum = __riscv_vfredusum_vs_f64m1_f64m1(v_mad_sum, v_abs_diff, v_mad_sum, vl);\n    }\n\n    mad_sum = __riscv_vfmv_f_s_f64m1_f64(v_mad_sum);\n    return mad_sum / n;\n}\n```"}
{"task_id": "SimdBench_64_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <cmath>\n\ndouble mean_absolute_deviation_simd(std::vector<double> numbers) {\n    size_t n = numbers.size();\n    if (n == 0) return 0.0;\n\n    double sum = 0.0;\n    for (size_t i = 0; i < n; ++i) {\n        sum += numbers[i];\n    }\n    double mean = sum / n;\n\n    double mad_sum = 0.0;\n    size_t vl;\n    vfloat64m1_t v_mean = __riscv_vfmv_v_f_f64m1(mean, vlmax);\n    vfloat64m1_t v_mad_sum = __riscv_vfmv_v_f_f64m1(0.0, vlmax);\n\n    for (size_t i = 0; i < n; i += vl) {\n        vl = __riscv_vsetvl_e64m1(n - i);\n        vfloat64m1_t v_numbers = __riscv_vle64_v_f64m1(&numbers[i], vl);\n        vfloat64m1_t v_diff = __riscv_vfsub_vv_f64m1(v_numbers, v_mean, vl);\n        vfloat64m1_t v_abs_diff = __riscv_vfabs_v_f64m1(v_diff, vl);\n        v_mad_sum = __riscv_vfredusum_vs_f64m1_f64m1(v_mad_sum, v_abs_diff, v_mad_sum, vl);\n    }\n\n    mad_sum = __riscv_vfmv_f_s_f64m1_f64(v_mad_sum);\n    return mad_sum / n;\n}\n```"}
{"task_id": "SimdBench_64_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <cmath>\n\ndouble mean_absolute_deviation_simd(std::vector<double> numbers) {\n    size_t n = numbers.size();\n    if (n == 0) return 0.0;\n\n    double sum = 0.0;\n    for (size_t i = 0; i < n; ++i) {\n        sum += numbers[i];\n    }\n    double mean = sum / n;\n\n    double mad_sum = 0.0;\n    size_t vl = __riscv_vsetvl_e64m1(n);\n    vfloat64m1_t v_mean = __riscv_vfmv_v_f_f64m1(mean, vl);\n    vfloat64m1_t v_numbers, v_diff, v_abs_diff;\n\n    for (size_t i = 0; i < n; i += vl) {\n        vl = __riscv_vsetvl_e64m1(n - i);\n        v_numbers = __riscv_vle64_v_f64m1(&numbers[i], vl);\n        v_diff = __riscv_vfsub_vv_f64m1(v_numbers, v_mean, vl);\n        v_abs_diff = __riscv_vfabs_v_f64m1(v_diff, vl);\n        mad_sum += __riscv_vfmv_f_s_f64m1_f64(__riscv_vfredusum_vs_f64m1_f64m1(v_abs_diff, __riscv_vfmv_v_f_f64m1(0.0, vl), vl));\n    }\n\n    return mad_sum / n;\n}\n```"}
{"task_id": "SimdBench_65_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> intersperse_simd(std::vector<int> numbers, int delimeter) {\n    size_t n = numbers.size();\n    if (n == 0) return {};\n\n    std::vector<int> result(2 * n - 1);\n    size_t vl;\n\n    vint32m1_t v_numbers = __riscv_vle32_v_i32m1(numbers.data(), n, &vl);\n    vint32m1_t v_delim = __riscv_vmv_v_x_i32m1(delimeter, vl);\n\n    for (size_t i = 0; i < n - 1; ++i) {\n        vint32m1_t v_result = __riscv_vslideup_vx_i32m1(v_numbers, v_delim, 1, vl);\n        __riscv_vse32_v_i32m1(result.data() + 2 * i, v_result, vl);\n        v_numbers = __riscv_vslideup_vx_i32m1(v_numbers, v_numbers, 1, vl);\n    }\n\n    result[2 * n - 2] = numbers[n - 1];\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_65_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> intersperse_simd(std::vector<int> numbers, int delimeter) {\n    size_t n = numbers.size();\n    if (n == 0) return {};\n\n    std::vector<int> result(2 * n - 1);\n    size_t vl = __riscv_vsetvl_e32m1(n);\n\n    vint32m1_t v_numbers = __riscv_vle32_v_i32m1(numbers.data(), vl);\n    vint32m1_t v_delim = __riscv_vmv_v_x_i32m1(delimeter, vl);\n\n    for (size_t i = 0; i < n - 1; ++i) {\n        vint32m1_t v_result = __riscv_vslideup_vx_i32m1(v_numbers, v_delim, 1, vl);\n        __riscv_vse32_v_i32m1(result.data() + 2 * i, v_result, vl);\n        v_numbers = __riscv_vslideup_vx_i32m1(v_numbers, v_numbers, 1, vl);\n    }\n\n    result[2 * n - 2] = numbers[n - 1];\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_65_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> intersperse_simd(std::vector<int> numbers, int delimeter) {\n    size_t n = numbers.size();\n    if (n == 0) return {};\n\n    std::vector<int> result(2 * n - 1);\n    size_t vl = __riscv_vsetvlmax_e32m1();\n\n    for (size_t i = 0; i < n; i += vl) {\n        size_t current_vl = __riscv_vsetvl_e32m1(n - i);\n        vuint32m1_t v_numbers = __riscv_vle32_v_u32m1(&numbers[i], current_vl);\n\n        if (i + current_vl < n) {\n            vuint32m1_t v_delim = __riscv_vmv_v_x_u32m1(delimeter, current_vl);\n            vuint32m1_t v_interleaved = __riscv_vslideup_vx_u32m1(v_numbers, v_delim, 1, current_vl);\n            __riscv_vse32_v_u32m1(&result[2 * i], v_interleaved, current_vl);\n            __riscv_vse32_v_u32m1(&result[2 * i + current_vl], v_delim, 1);\n        } else {\n            __riscv_vse32_v_u32m1(&result[2 * i], v_numbers, current_vl);\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_65_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> intersperse_simd(std::vector<int> numbers, int delimeter) {\n    size_t n = numbers.size();\n    if (n == 0) return {};\n\n    std::vector<int> result(2 * n - 1);\n    size_t vl = __riscv_vsetvlmax_e32m1();\n\n    for (size_t i = 0; i < n; i += vl) {\n        size_t current_vl = __riscv_vsetvl_e32m1(n - i);\n        vuint32m1_t v_numbers = __riscv_vle32_v_u32m1(&numbers[i], current_vl);\n\n        if (i + current_vl < n) {\n            vuint32m1_t v_delim = __riscv_vmv_v_x_u32m1(delimeter, current_vl);\n            vuint32m1_t v_interspersed = __riscv_vslideup_vx_u32m1(v_numbers, v_delim, 1, current_vl);\n            __riscv_vse32_v_u32m1(&result[2 * i], v_interspersed, current_vl);\n            __riscv_vse32_v_u32m1(&result[2 * i + 1], v_delim, current_vl - 1);\n        } else {\n            __riscv_vse32_v_u32m1(&result[2 * i], v_numbers, current_vl);\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_65_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> intersperse_simd(std::vector<int> numbers, int delimeter) {\n    size_t n = numbers.size();\n    if (n == 0) return {};\n\n    std::vector<int> result(2 * n - 1);\n    size_t vl = __riscv_vsetvlmax_e32m1();\n\n    for (size_t i = 0; i < n; i += vl) {\n        size_t current_vl = __riscv_vsetvl_e32m1(n - i);\n        vuint32m1_t v_numbers = __riscv_vle32_v_u32m1(&numbers[i], current_vl);\n\n        if (i + current_vl < n) {\n            vuint32m1_t v_delim = __riscv_vmv_v_x_u32m1(delimeter, current_vl);\n            vuint32m1_t v_interleaved = __riscv_vslideup_vx_u32m1(v_numbers, v_delim, 1, current_vl);\n            __riscv_vse32_v_u32m1(&result[2 * i], v_interleaved, current_vl);\n            __riscv_vse32_v_u32m1(&result[2 * i + 1], v_delim, current_vl - 1);\n        } else {\n            __riscv_vse32_v_u32m1(&result[2 * i], v_numbers, current_vl);\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_66_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int64_t> sum_product_simd(std::vector<int16_t> numbers) {\n    size_t n = numbers.size();\n    int64_t sum = 0;\n    int64_t product = 1;\n\n    if (n == 0) {\n        return {0, 1};\n    }\n\n    size_t vl = __riscv_vsetvl_e16m1(n);\n    vint16m1_t v_numbers = __riscv_vle16_v_i16m1(numbers.data(), vl);\n\n    vint64m1_t v_sum = __riscv_vmv_v_x_i64m1(0, vl);\n    vint64m1_t v_product = __riscv_vmv_v_x_i64m1(1, vl);\n\n    while (vl > 0) {\n        vint64m1_t v_temp_sum = __riscv_vwredsum_vs_i64m1_i64m1(v_sum, v_numbers, vl);\n        vint64m1_t v_temp_product = __riscv_vredprod_vs_i64m1_i64m1(v_product, v_numbers, vl);\n\n        v_sum = __riscv_vmv_v_v_i64m1(v_temp_sum, vl);\n        v_product = __riscv_vmv_v_v_i64m1(v_temp_product, vl);\n\n        n -= vl;\n        vl = __riscv_vsetvl_e16m1(n);\n        v_numbers = __riscv_vle16_v_i16m1(numbers.data() + (numbers.size() - n), vl);\n    }\n\n    sum = __riscv_vmv_x_s_i64m1_i64(v_sum);\n    product = __riscv_vmv_x_s_i64m1_i64(v_product);\n\n    return {sum, product};\n}\n```"}
{"task_id": "SimdBench_66_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int64_t> sum_product_simd(std::vector<int16_t> numbers) {\n    size_t n = numbers.size();\n    if (n == 0) {\n        return {0, 1};\n    }\n\n    int64_t sum = 0;\n    int64_t product = 1;\n\n    size_t vl;\n    vint16m1_t v_numbers;\n    vint32m2_t v_sum;\n    vint64m1_t v_product;\n\n    for (size_t i = 0; i < n; i += vl) {\n        vl = vsetvl_e16m1(n - i);\n        v_numbers = vle16_v_i16m1(&numbers[i], vl);\n\n        vint32m2_t v_sum_temp = vredsum_vs_i32m2(vcvt_x_i32m2(v_numbers, vl), v_sum, vl);\n        vint64m1_t v_product_temp = vredprod_vs_i64m1(vcvt_x_i64m1(v_numbers, vl), v_product, vl);\n\n        sum += vsum_vs_i32m2(v_sum_temp, vl);\n        product *= vsum_vs_i64m1(v_product_temp, vl);\n    }\n\n    return {sum, product};\n}\n```"}
{"task_id": "SimdBench_66_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int64_t> sum_product_simd(std::vector<int16_t> numbers) {\n    size_t n = numbers.size();\n    int64_t sum = 0;\n    int64_t product = 1;\n\n    if (n == 0) {\n        return {0, 1};\n    }\n\n    size_t vl = __riscv_vsetvl_e16m1(n);\n    vint16m1_t v_numbers = __riscv_vle16_v_i16m1(numbers.data(), vl);\n\n    vint64m1_t v_sum = __riscv_vmv_v_x_i64m1(0, vl);\n    vint64m1_t v_product = __riscv_vmv_v_x_i64m1(1, vl);\n\n    for (size_t i = 0; i < n; i += vl) {\n        vl = __riscv_vsetvl_e16m1(n - i);\n        v_numbers = __riscv_vle16_v_i16m1(numbers.data() + i, vl);\n\n        vint64m1_t v_numbers_ext = __riscv_vwcvx_i64m1(v_numbers, vl);\n        v_sum = __riscv_vredsum_vs_i64m1_i64m1(v_sum, v_numbers_ext, vl);\n        v_product = __riscv_vredprod_vs_i64m1_i64m1(v_product, v_numbers_ext, vl);\n    }\n\n    sum = __riscv_vmv_x_s_i64m1_i64(v_sum);\n    product = __riscv_vmv_x_s_i64m1_i64(v_product);\n\n    return {sum, product};\n}\n```"}
{"task_id": "SimdBench_66_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int64_t> sum_product_simd(std::vector<int16_t> numbers) {\n    size_t n = numbers.size();\n    int64_t sum = 0;\n    int64_t product = 1;\n\n    if (n == 0) {\n        return {0, 1};\n    }\n\n    size_t vl = __riscv_vsetvl_e16m1(n);\n    vint16m1_t v_numbers = __riscv_vle16_v_i16m1(numbers.data(), vl);\n\n    vint64m1_t v_sum = __riscv_vmv_v_x_i64m1(0, vl);\n    vint64m1_t v_product = __riscv_vmv_v_x_i64m1(1, vl);\n\n    for (size_t i = 0; i < n; i += vl) {\n        vl = __riscv_vsetvl_e16m1(n - i);\n        v_numbers = __riscv_vle16_v_i16m1(numbers.data() + i, vl);\n\n        vint64m1_t v_numbers_ext = __riscv_vwcvx_x_i64m1(v_numbers, vl);\n        v_sum = __riscv_vredsum_vs_i64m1_i64m1(v_sum, v_numbers_ext, vl);\n        v_product = __riscv_vredprod_vs_i64m1_i64m1(v_product, v_numbers_ext, vl);\n    }\n\n    sum = __riscv_vmv_x_s_i64m1_i64(v_sum);\n    product = __riscv_vmv_x_s_i64m1_i64(v_product);\n\n    return {sum, product};\n}\n```"}
{"task_id": "SimdBench_66_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int64_t> sum_product_simd(std::vector<int16_t> numbers) {\n    size_t n = numbers.size();\n    int64_t sum = 0;\n    int64_t product = 1;\n\n    if (n == 0) {\n        return {0, 1};\n    }\n\n    size_t vl = __riscv_vsetvl_e16m1(n);\n    vint16m1_t v_numbers = __riscv_vle16_v_i16m1(numbers.data(), vl);\n\n    vint64m1_t v_sum = __riscv_vmv_v_x_i64m1(0, vl);\n    vint64m1_t v_product = __riscv_vmv_v_x_i64m1(1, vl);\n\n    for (size_t i = 0; i < n; i += vl) {\n        vl = __riscv_vsetvl_e16m1(n - i);\n        v_numbers = __riscv_vle16_v_i16m1(numbers.data() + i, vl);\n\n        vint64m1_t v_numbers_ext = __riscv_vwcvx_x_i64m1(v_numbers, vl);\n        v_sum = __riscv_vredsum_vs_i64m1_i64m1(v_sum, v_numbers_ext, v_sum, vl);\n        v_product = __riscv_vredprod_vs_i64m1_i64m1(v_product, v_numbers_ext, v_product, vl);\n    }\n\n    sum = __riscv_vmv_x_s_i64m1_i64(v_sum);\n    product = __riscv_vmv_x_s_i64m1_i64(v_product);\n\n    return {sum, product};\n}\n```"}
{"task_id": "SimdBench_67_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> rolling_max_simd(std::vector<int> numbers) {\n    size_t n = numbers.size();\n    std::vector<int> result(n);\n    if (n == 0) return result;\n\n    size_t vlmax = __riscv_vsetvlmax_e32m1();\n    vint32m1_t v_numbers, v_max, v_result;\n    int max_val = numbers[0];\n    result[0] = max_val;\n\n    for (size_t i = 1; i < n; i += vlmax) {\n        size_t vl = __riscv_vsetvl_e32m1(n - i);\n        v_numbers = __riscv_vle32_v_i32m1(&numbers[i], vl);\n        v_max = __riscv_vmv_v_x_i32m1(max_val, vl);\n        v_result = __riscv_vmax_vv_i32m1(v_max, v_numbers, vl);\n        __riscv_vse32_v_i32m1(&result[i], v_result, vl);\n\n        max_val = __riscv_vredmax_vs_i32m1_i32m1(max_val, v_result, vl);\n    }\n\n    for (size_t i = 1; i < n; ++i) {\n        result[i] = std::max(result[i], result[i - 1]);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_67_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> rolling_max_simd(std::vector<int> numbers) {\n    size_t n = numbers.size();\n    std::vector<int> result(n);\n    if (n == 0) return result;\n\n    size_t vlmax = __riscv_vsetvlmax_e32m1();\n    vint32m1_t v_numbers, v_result, v_max;\n    v_numbers = __riscv_vle32_v_i32m1(numbers.data(), vlmax);\n    v_result = __riscv_vmv_v_v_i32m1(v_numbers, vlmax);\n    v_max = __riscv_vmv_v_v_i32m1(v_numbers, vlmax);\n\n    for (size_t i = 1; i < n; i += vlmax) {\n        size_t vl = __riscv_vsetvl_e32m1(n - i);\n        v_numbers = __riscv_vle32_v_i32m1(numbers.data() + i, vl);\n        v_max = __riscv_vmax_vv_i32m1(v_max, v_numbers, vl);\n        v_result = __riscv_vmv_v_v_i32m1(v_max, vl);\n        __riscv_vse32_v_i32m1(result.data() + i, v_result, vl);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_67_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> rolling_max_simd(std::vector<int> numbers) {\n    size_t n = numbers.size();\n    std::vector<int> result(n);\n    if (n == 0) return result;\n\n    size_t vlmax = __riscv_vsetvlmax_e32m1();\n    vint32m1_t v_numbers = __riscv_vundefined_e32m1();\n    vint32m1_t v_result = __riscv_vundefined_e32m1();\n    vint32m1_t v_max = __riscv_vundefined_e32m1();\n\n    v_max = __riscv_vmv_v_x_i32m1(numbers[0], vlmax);\n\n    for (size_t i = 0; i < n; i += vlmax) {\n        size_t vl = __riscv_vsetvl_e32m1(n - i);\n        v_numbers = __riscv_vle32_v_i32m1(&numbers[i], vl);\n        v_max = __riscv_vmax_vv_i32m1(v_max, v_numbers, vl);\n        v_result = v_max;\n        __riscv_vse32_v_i32m1(&result[i], v_result, vl);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_67_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> rolling_max_simd(std::vector<int> numbers) {\n    size_t n = numbers.size();\n    std::vector<int> result(n);\n    if (n == 0) return result;\n\n    size_t vlmax = __riscv_vsetvlmax_e32m1();\n    vint32m1_t v_numbers = __riscv_vundefined_e32m1();\n    vint32m1_t v_result = __riscv_vundefined_e32m1();\n    vint32m1_t v_max = __riscv_vundefined_e32m1();\n\n    v_max = __riscv_vle32_v_i32m1(&numbers[0], vlmax);\n    result[0] = numbers[0];\n\n    for (size_t i = 1; i < n; ++i) {\n        size_t vl = __riscv_vsetvl_e32m1(n - i);\n        v_numbers = __riscv_vle32_v_i32m1(&numbers[i], vl);\n        v_max = __riscv_vmax_vv_i32m1(v_max, v_numbers, vl);\n        __riscv_vse32_v_i32m1(&result[i], v_max, vl);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_67_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> rolling_max_simd(std::vector<int> numbers) {\n    size_t n = numbers.size();\n    std::vector<int> result(n);\n    if (n == 0) return result;\n\n    size_t vlmax = __riscv_vsetvlmax_e32m1();\n    vint32m1_t v_numbers = __riscv_vle32_v_i32m1(numbers.data(), n, vlmax);\n    vint32m1_t v_result = __riscv_vundefined_i32m1();\n    vint32m1_t v_max = __riscv_vundefined_i32m1();\n\n    v_max = __riscv_vmv_v_x_i32m1(v_max, numbers[0], vlmax);\n    v_result = __riscv_vmv_v_v_i32m1(v_result, v_max, vlmax);\n\n    for (size_t i = 1; i < n; i += vlmax) {\n        size_t vl = __riscv_vsetvl_e32m1(n - i);\n        v_numbers = __riscv_vle32_v_i32m1(numbers.data() + i, vl);\n        v_max = __riscv_vmax_vv_i32m1(v_max, v_numbers, vl);\n        v_result = __riscv_vmv_v_v_i32m1(v_result, v_max, vl);\n        __riscv_vse32_v_i32m1(result.data() + i, v_result, vl);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_68_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nstd::string string_xor_simd(std::string a, std::string b) {\n    size_t len = a.size();\n    std::string result(len, '0');\n\n    for (size_t i = 0; i < len; i += sizeof(vuint8m1_t) / sizeof(uint8_t)) {\n        vuint8m1_t va = vle8_v_u8m1((uint8_t*)&a[i], sizeof(vuint8m1_t));\n        vuint8m1_t vb = vle8_v_u8m1((uint8_t*)&b[i], sizeof(vuint8m1_t));\n        vuint8m1_t vres = vxor_vv_u8m1(va, vb, sizeof(vuint8m1_t));\n        vse8_v_u8m1((uint8_t*)&result[i], vres, sizeof(vuint8m1_t));\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_68_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nstd::string string_xor_simd(std::string a, std::string b) {\n    size_t len = a.size();\n    std::string result(len, '0');\n\n    for (size_t i = 0; i < len; i += sizeof(vuint8m1_t) / sizeof(uint8_t)) {\n        vuint8m1_t va = vle8_v_u8m1(&a[i], sizeof(vuint8m1_t) / sizeof(uint8_t));\n        vuint8m1_t vb = vle8_v_u8m1(&b[i], sizeof(vuint8m1_t) / sizeof(uint8_t));\n        vuint8m1_t vres = vxor_vv_u8m1(va, vb, sizeof(vuint8m1_t) / sizeof(uint8_t));\n        vse8_v_u8m1(&result[i], vres, sizeof(vuint8m1_t) / sizeof(uint8_t));\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_68_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nstd::string string_xor_simd(std::string a, std::string b) {\n    size_t len = a.size();\n    std::string result(len, '0');\n\n    size_t vl = __riscv_vsetvl_e8m8(len);\n\n    vuint8m8_t va = __riscv_vle8_v_u8m8((const uint8_t*)a.data(), vl);\n    vuint8m8_t vb = __riscv_vle8_v_u8m8((const uint8_t*)b.data(), vl);\n    vuint8m8_t vres = __riscv_vxor_vv_u8m8(va, vb, vl);\n\n    __riscv_vse8_v_u8m8((uint8_t*)result.data(), vres, vl);\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_68_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nstd::string string_xor_simd(std::string a, std::string b) {\n    size_t len = a.size();\n    std::string result(len, '0');\n\n    size_t vl = __riscv_vsetvl_e8m8(len);\n\n    vuint8m8_t va = __riscv_vle8_v_u8m8((const uint8_t*)a.data(), vl);\n    vuint8m8_t vb = __riscv_vle8_v_u8m8((const uint8_t*)b.data(), vl);\n    vuint8m8_t vresult = __riscv_vxor_vv_u8m8(va, vb, vl);\n\n    __riscv_vse8_v_u8m8((uint8_t*)result.data(), vresult, vl);\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_68_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nstd::string string_xor_simd(std::string a, std::string b) {\n    size_t len = a.size();\n    std::string result(len, '0');\n\n    size_t vl = __riscv_vsetvl_e8m8(len);\n\n    vuint8m8_t va = __riscv_vle8_v_u8m8((const uint8_t*)a.data(), vl);\n    vuint8m8_t vb = __riscv_vle8_v_u8m8((const uint8_t*)b.data(), vl);\n    vuint8m8_t vresult = __riscv_vxor_vv_u8m8(va, vb, vl);\n\n    __riscv_vse8_v_u8m8((uint8_t*)result.data(), vresult, vl);\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_69_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <string>\n#include <optional>\n\nstd::optional<std::string> longest_simd(const std::vector<std::string>& strings) {\n    if (strings.empty()) {\n        return std::nullopt;\n    }\n\n    size_t max_length = 0;\n    std::string longest_string;\n\n    size_t n = strings.size();\n    size_t vl = __riscv_vsetvl_e8m1(n);\n\n    for (size_t i = 0; i < n; i += vl) {\n        vl = __riscv_vsetvl_e8m1(n - i);\n\n        vuint8m1_t lengths = __riscv_vundefined_u8m1();\n        for (size_t j = 0; j < vl; ++j) {\n            lengths = __riscv_vslideup_u8m1(lengths, lengths, 1);\n            lengths = __riscv_vslideup_u8m1(lengths, __riscv_vmv_v_x_u8m1(strings[i + j].size()), 1);\n        }\n\n        vuint8m1_t max_lengths = __riscv_vundefined_u8m1();\n        max_lengths = __riscv_vmv_v_x_u8m1(max_length);\n\n        vuint8m1_t mask = __riscv_vmsgtu_u8m1_b8(lengths, max_lengths);\n        size_t idx = __riscv_vfirst_m_b8(mask, vl);\n\n        if (idx < vl) {\n            max_length = strings[i + idx].size();\n            longest_string = strings[i + idx];\n        }\n    }\n\n    return longest_string;\n}\n```"}
{"task_id": "SimdBench_69_RVV", "completion": "```c++\n#include <riscv_vector.h>\n#include <vector>\n#include <string>\n\nstd::string longest_simd(const std::vector<std::string> &strings) {\n    if (strings.empty()) {\n        return \"\";\n    }\n\n    size_t max_length = 0;\n    std::string longest_string = strings[0];\n\n    size_t n = strings.size();\n    size_t vl = __riscv_vsetvl_e32m1(n);\n\n    for (size_t i = 0; i < n; i += vl) {\n        vl = __riscv_vsetvl_e32m1(n - i);\n\n        vuint32m1_t lengths = __riscv_vundefined_u32m1();\n        for (size_t j = 0; j < vl; ++j) {\n            lengths = __riscv_vslideup_vx_u32m1(lengths, strings[i + j].size(), 1);\n        }\n\n        vuint32m1_t max_lengths = __riscv_vundefined_u32m1();\n        max_lengths = __riscv_vredmaxu_vs_u32m1_u32m1(max_lengths, lengths, max_lengths, vl);\n\n        uint32_t current_max_length = __riscv_vmv_x_s_u32m1_u32(max_lengths);\n        if (current_max_length > max_length) {\n            max_length = current_max_length;\n            for (size_t j = 0; j < vl; ++j) {\n                if (strings[i + j].size() == max_length) {\n                    longest_string = strings[i + j];\n                    break;\n                }\n            }\n        }\n    }\n\n    return longest_string;\n}\n```"}
{"task_id": "SimdBench_69_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <string>\n#include <optional>\n\nstd::optional<std::string> longest_simd(const std::vector<std::string> & strings) {\n    if (strings.empty()) {\n        return std::nullopt;\n    }\n\n    size_t max_length = 0;\n    std::string longest_string;\n\n    size_t n = strings.size();\n    size_t vl = __riscv_vsetvl_e32m1(n);\n\n    for (size_t i = 0; i < n; i += vl) {\n        vl = __riscv_vsetvl_e32m1(n - i);\n\n        vuint32m1_t lengths = __riscv_vundefined_u32m1();\n        for (size_t j = 0; j < vl; ++j) {\n            lengths = __riscv_vslideup_vx_u32m1(lengths, strings[i + j].size(), 1);\n        }\n\n        vuint32m1_t max_lengths = __riscv_vundefined_u32m1();\n        max_lengths = __riscv_vredmaxu_vs_u32m1_u32m1(max_lengths, lengths, max_lengths, vl);\n\n        size_t local_max_length = __riscv_vmv_x_s_u32m1_u32(max_lengths);\n        if (local_max_length > max_length) {\n            max_length = local_max_length;\n            longest_string = strings[i + __riscv_vfirst_m_u32m1(__riscv_vmsne_vx_u32m1_b32(lengths, max_length), vl)];\n        }\n    }\n\n    return longest_string;\n}\n```"}
{"task_id": "SimdBench_69_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <string>\n#include <optional>\n\nstd::optional<std::string> longest_simd(const std::vector<std::string>& strings) {\n    if (strings.empty()) {\n        return std::nullopt;\n    }\n\n    size_t max_length = 0;\n    std::string longest_string;\n\n    size_t n = strings.size();\n    size_t vl = __riscv_vsetvl_e32m1(n);\n\n    for (size_t i = 0; i < n; i += vl) {\n        vl = __riscv_vsetvl_e32m1(n - i);\n\n        vuint32m1_t lengths = __riscv_vundefined_u32m1();\n        for (size_t j = 0; j < vl; ++j) {\n            lengths = __riscv_vslideup_vx_u32m1(lengths, strings[i + j].size(), 1);\n        }\n\n        size_t max_index = __riscv_vfirst_m_u32m1_b32(__riscv_vmsne_vx_u32m1_b32(lengths, max_length, vl));\n        if (max_index < vl) {\n            max_length = strings[i + max_index].size();\n            longest_string = strings[i + max_index];\n        }\n    }\n\n    return longest_string;\n}\n```"}
{"task_id": "SimdBench_69_RVV", "completion": "```c++\n#include <riscv_vector.h>\n#include <vector>\n#include <string>\n\nstd::string longest_simd(const std::vector<std::string> & strings) {\n    if (strings.empty()) {\n        return \"\";\n    }\n\n    size_t max_length = 0;\n    std::string longest_string = strings[0];\n\n    size_t n = strings.size();\n    size_t vl = __riscv_vsetvl_e32m1(n);\n\n    vuint32m1_t lengths = __riscv_vundefined_u32m1();\n    vuint32m1_t indices = __riscv_vundefined_u32m1();\n\n    for (size_t i = 0; i < n; i += vl) {\n        vl = __riscv_vsetvl_e32m1(n - i);\n\n        for (size_t j = 0; j < vl; ++j) {\n            lengths = __riscv_vslideup_vx_u32m1(lengths, strings[i + j].length(), 1);\n            indices = __riscv_vslideup_vx_u32m1(indices, i + j, 1);\n        }\n\n        vuint32m1_t max_lengths = __riscv_vundefined_u32m1();\n        vuint32m1_t max_indices = __riscv_vundefined_u32m1();\n\n        __riscv_vredmaxu_vs_u32m1_u32m1(max_lengths, lengths, max_lengths, vl);\n        __riscv_vredmaxu_vs_u32m1_u32m1(max_indices, indices, max_indices, vl);\n\n        uint32_t current_max_length = __riscv_vmv_x_s_u32m1_u32(max_lengths);\n        uint32_t current_max_index = __riscv_vmv_x_s_u32m1_u32(max_indices);\n\n        if (current_max_length > max_length) {\n            max_length = current_max_length;\n            longest_string = strings[current_max_index];\n        }\n    }\n\n    return longest_string;\n}\n```"}
{"task_id": "SimdBench_70_RVV", "completion": "```c\nuint64_t greatest_common_divisor_simd(uint64_t a, uint64_t b) {\n    vint64m1_t va = __riscv_vle64_v_i64m1(&a, 1, 1);\n    vint64m1_t vb = __riscv_vle64_v_i64m1(&b, 1, 1);\n\n    while (__riscv_vany_true_vm_i64m1(__riscv_vne_vv_i64m1(va, vb, 1))) {\n        vint64m1_t temp = __riscv_vsub_vv_i64m1(va, vb, 1);\n        vint64m1_t mask = __riscv_vmslt_vv_i64m1(va, vb, 1);\n        va = __riscv_vmerge_vvm_i64m1(va, temp, mask, 1);\n        vb = __riscv_vmerge_vvm_i64m1(vb, temp, __riscv_vmnot_vm_i64m1(mask, 1), 1);\n    }\n\n    return __riscv_vmv_x_s_i64m1_i64(va);\n}\n```"}
{"task_id": "SimdBench_70_RVV", "completion": "```c\nuint64_t greatest_common_divisor_simd(uint64_t a, uint64_t b) {\n    vint64m1_t va = __riscv_vmv_v_x_i64m1(a, 1);\n    vint64m1_t vb = __riscv_vmv_v_x_i64m1(b, 1);\n\n    while (__riscv_vfirst_m(vmsne_vv_i64m1_b16(va, vb, 1), 1)) {\n        vint64m1_t temp = __riscv_vmv_v_v_i64m1(va, 1);\n        va = __riscv_vmv_v_v_i64m1(vb, 1);\n        vb = __riscv_vsub_vv_i64m1(temp, vb, 1);\n    }\n\n    return __riscv_vmv_x_s_i64m1_i64(va);\n}\n```"}
{"task_id": "SimdBench_70_RVV", "completion": "```c\nuint64_t greatest_common_divisor_simd(uint64_t a, uint64_t b) {\n    vint64m1_t va = __riscv_vmv_v_x_i64m1(a, 1);\n    vint64m1_t vb = __riscv_vmv_v_x_i64m1(b, 1);\n\n    while (__riscv_vreinterpret_u64m1_i64m1(__riscv_vne_i64m1(va, vb, 1))) {\n        vint64m1_t temp = __riscv_vmv_v_v_i64m1(va, 1);\n        va = __riscv_vmv_v_v_i64m1(vb, 1);\n        vb = __riscv_vsub_vv_i64m1(temp, vb, 1);\n    }\n\n    return __riscv_vmv_x_s_i64m1_i64(va);\n}\n```"}
{"task_id": "SimdBench_70_RVV", "completion": "```c\nuint64_t greatest_common_divisor_simd(uint64_t a, uint64_t b) {\n    vint64m1_t va = __riscv_vmv_v_x_i64m1(a, 1);\n    vint64m1_t vb = __riscv_vmv_v_x_i64m1(b, 1);\n\n    while (__riscv_vreinterpret_v_u64m1_u64m1(__riscv_vmseq_vv_u64m1_b64(va, vb, 1)) != 0) {\n        vint64m1_t temp = va;\n        va = vb;\n        vb = __riscv_vsub_vv_u64m1(temp, vb, 1);\n    }\n\n    return __riscv_vmv_x_s_u64m1_u64(va);\n}\n```"}
{"task_id": "SimdBench_70_RVV", "completion": "```c\nuint64_t greatest_common_divisor_simd(uint64_t a, uint64_t b) {\n    vint64m1_t va = __riscv_vmv_v_x_i64m1(a, 1);\n    vint64m1_t vb = __riscv_vmv_v_x_i64m1(b, 1);\n\n    while (__riscv_vreinterpret_v_u64m1_u64m1(__riscv_vmseq_vv_u64m1_b64(va, vb, 1)) != 0) {\n        vint64m1_t temp = va;\n        va = vb;\n        vb = __riscv_vrem_vv_u64m1(temp, vb, 1);\n    }\n\n    return __riscv_vmv_x_s_u64m1_u64(va);\n}\n```"}
{"task_id": "SimdBench_71_RVV", "completion": "```c++\n#include <riscv_vector.h>\n#include <vector>\n#include <cmath>\n#include <limits>\n\nstd::vector<float> find_closest_elements_simd(std::vector<float> numbers) {\n    size_t n = numbers.size();\n    float min_diff = std::numeric_limits<float>::max();\n    float closest_a = 0.0f, closest_b = 0.0f;\n\n    size_t vl = __riscv_vsetvlmax_e32m1();\n    vfloat32m1_t v_numbers = __riscv_vle32_v_f32m1(numbers.data(), n, vl);\n\n    for (size_t i = 0; i < n; ++i) {\n        vfloat32m1_t v_diff = __riscv_vfsub_vv_f32m1(v_numbers, __riscv_vfmv_v_f_f32m1(numbers[i], vl), vl);\n        vfloat32m1_t v_abs_diff = __riscv_vfabs_v_f32m1(v_diff, vl);\n\n        float local_min_diff = __riscv_vfmv_f_s_f32m1_f32(__riscv_vfredmin_vs_f32m1_f32m1(v_abs_diff, __riscv_vfmv_v_f_f32m1(min_diff, vl), vl));\n\n        if (local_min_diff < min_diff) {\n            min_diff = local_min_diff;\n            size_t idx = __riscv_vfirst_m_b32(__riscv_vmsne_vv_f32m1_b32(v_abs_diff, __riscv_vfmv_v_f_f32m1(min_diff, vl), vl));\n            closest_a = numbers[i];\n            closest_b = numbers[idx];\n            if (closest_a > closest_b) std::swap(closest_a, closest_b);\n        }\n    }\n\n    return {closest_a, closest_b};\n}\n```"}
{"task_id": "SimdBench_71_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <cmath>\n#include <limits>\n\nstd::vector<float> find_closest_elements_simd(std::vector<float> numbers) {\n    size_t n = numbers.size();\n    float min_diff = std::numeric_limits<float>::max();\n    float closest_a = 0.0f, closest_b = 0.0f;\n\n    size_t vl = __riscv_vsetvl_e32m1(n);\n    vfloat32m1_t v_numbers = __riscv_vle32_v_f32m1(numbers.data(), vl);\n\n    for (size_t i = 0; i < n; ++i) {\n        vfloat32m1_t v_diff = __riscv_vfsub_vv_f32m1(v_numbers, __riscv_vfmv_v_f_f32m1(numbers[i], vl), vl);\n        vfloat32m1_t v_abs_diff = __riscv_vfabs_v_f32m1(v_diff, vl);\n\n        float local_min_diff = __riscv_vfmv_f_s_f32m1_f32(__riscv_vfredmin_vs_f32m1_f32m1(v_abs_diff, __riscv_vfmv_v_f_f32m1(0.0f, vl), vl));\n        if (local_min_diff < min_diff) {\n            min_diff = local_min_diff;\n            closest_a = numbers[i];\n            closest_b = numbers[__riscv_vfmv_f_s_f32m1_f32(__riscv_vfirst_m_u32m1(__riscv_vmsne_vv_f32m1_b32(v_abs_diff, __riscv_vfmv_v_f_f32m1(min_diff, vl), vl), vl))];\n        }\n    }\n\n    return {std::min(closest_a, closest_b), std::max(closest_a, closest_b)};\n}\n```"}
{"task_id": "SimdBench_71_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <cmath>\n#include <limits>\n\nstd::vector<float> find_closest_elements_simd(std::vector<float> numbers) {\n    size_t n = numbers.size();\n    float min_diff = std::numeric_limits<float>::max();\n    std::vector<float> closest_pair(2);\n\n    for (size_t i = 0; i < n; i += 8) {\n        size_t vl = __riscv_vsetvl_e32m1(n - i);\n        vfloat32m1_t v_a = __riscv_vle32_v_f32m1(&numbers[i], vl);\n\n        for (size_t j = i + 1; j < n; j += 8) {\n            size_t vl2 = __riscv_vsetvl_e32m1(n - j);\n            vfloat32m1_t v_b = __riscv_vle32_v_f32m1(&numbers[j], vl2);\n\n            vfloat32m1_t v_diff = __riscv_vfsub_vv_f32m1(v_a, v_b, vl);\n            vfloat32m1_t v_abs_diff = __riscv_vfabs_v_f32m1(v_diff, vl);\n\n            float local_min_diff = __riscv_vfmv_s_f_f32m1_f32(__riscv_vfredmin_vs_f32m1_f32m1(v_abs_diff, 0.0f, vl));\n            if (local_min_diff < min_diff) {\n                min_diff = local_min_diff;\n                for (size_t k = 0; k < vl; ++k) {\n                    for (size_t l = 0; l < vl2; ++l) {\n                        if (std::abs(numbers[i + k] - numbers[j + l]) == local_min_diff) {\n                            closest_pair[0] = std::min(numbers[i + k], numbers[j + l]);\n                            closest_pair[1] = std::max(numbers[i + k], numbers[j + l]);\n                        }\n                    }\n                }\n            }\n        }\n    }\n\n    return closest_pair;\n}\n```"}
{"task_id": "SimdBench_71_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <cmath>\n#include <limits>\n\nstd::vector<float> find_closest_elements_simd(std::vector<float> numbers) {\n    size_t n = numbers.size();\n    float min_diff = std::numeric_limits<float>::max();\n    std::vector<float> result(2);\n\n    for (size_t i = 0; i < n; ++i) {\n        size_t vl = vsetvl_e32m1(n - i);\n        vfloat32m1_t v_a = vle32_v_f32m1(&numbers[i], vl);\n        vfloat32m1_t v_b = vle32_v_f32m1(&numbers[i + 1], vl - 1);\n\n        vfloat32m1_t v_diff = vfsub_vv_f32m1(v_b, v_a, vl - 1);\n        vfloat32m1_t v_abs_diff = vfabs_v_f32m1(v_diff, vl - 1);\n\n        size_t idx;\n        float local_min_diff = vfredmin_vs_f32m1_f32(v_abs_diff, min_diff, &idx, vl - 1);\n\n        if (local_min_diff < min_diff) {\n            min_diff = local_min_diff;\n            result[0] = numbers[i + idx];\n            result[1] = numbers[i + idx + 1];\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_71_RVV", "completion": "```c++\nstd::vector<float> find_closest_elements_simd(std::vector<float> numbers) {\n    size_t n = numbers.size();\n    float min_diff = std::numeric_limits<float>::max();\n    std::vector<float> closest_pair(2);\n\n    for (size_t i = 0; i < n; ++i) {\n        size_t vl = __riscv_vsetvl_e32m1(n - i);\n        vfloat32m1_t v_a = __riscv_vle32_v_f32m1(&numbers[i], vl);\n        vfloat32m1_t v_b = __riscv_vle32_v_f32m1(&numbers[i + 1], vl - 1);\n\n        vfloat32m1_t v_diff = __riscv_vfsub_vv_f32m1(v_b, v_a, vl - 1);\n        vfloat32m1_t v_abs_diff = __riscv_vfabs_v_f32m1(v_diff, vl - 1);\n\n        size_t idx = __riscv_vfirst_m(vbool32_t(__riscv_vmseq_vf_f32m1_b32(v_abs_diff, min_diff, vl - 1)), vl - 1);\n        if (idx < vl - 1) {\n            min_diff = __riscv_vfmv_s_f_f32m1_f32(v_abs_diff, idx);\n            closest_pair[0] = numbers[i + idx];\n            closest_pair[1] = numbers[i + idx + 1];\n        }\n    }\n\n    return closest_pair;\n}\n```"}
{"task_id": "SimdBench_72_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<float> rescale_to_unit_simd(std::vector<float> numbers) {\n    size_t n = numbers.size();\n    std::vector<float> result(n);\n\n    float* input = numbers.data();\n    float* output = result.data();\n\n    size_t vl = __riscv_vsetvl_e32m1(n);\n\n    vfloat32m1_t v_min = __riscv_vfmv_v_f_f32m1(FLT_MAX, vl);\n    vfloat32m1_t v_max = __riscv_vfmv_v_f_f32m1(-FLT_MAX, vl);\n\n    for (size_t i = 0; i < n; i += vl) {\n        vl = __riscv_vsetvl_e32m1(n - i);\n        vfloat32m1_t v_input = __riscv_vle32_v_f32m1(input + i, vl);\n        v_min = __riscv_vfmin_vv_f32m1(v_min, v_input, vl);\n        v_max = __riscv_vfmax_vv_f32m1(v_max, v_input, vl);\n    }\n\n    float min_val = __riscv_vfmv_f_s_f32m1_f32(v_min);\n    float max_val = __riscv_vfmv_f_s_f32m1_f32(v_max);\n\n    float scale = 1.0f / (max_val - min_val);\n\n    for (size_t i = 0; i < n; i += vl) {\n        vl = __riscv_vsetvl_e32m1(n - i);\n        vfloat32m1_t v_input = __riscv_vle32_v_f32m1(input + i, vl);\n        vfloat32m1_t v_output = __riscv_vfsub_vf_f32m1(v_input, min_val, vl);\n        v_output = __riscv_vfmul_vf_f32m1(v_output, scale, vl);\n        __riscv_vse32_v_f32m1(output + i, v_output, vl);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_72_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<float> rescale_to_unit_simd(std::vector<float> numbers) {\n    size_t n = numbers.size();\n    std::vector<float> result(n);\n\n    float* input = numbers.data();\n    float* output = result.data();\n\n    size_t vl = __riscv_vsetvl_e32m1(n);\n\n    vfloat32m1_t v_min = __riscv_vfmv_v_f_f32m1(FLT_MAX, vl);\n    vfloat32m1_t v_max = __riscv_vfmv_v_f_f32m1(-FLT_MAX, vl);\n\n    for (size_t i = 0; i < n; i += vl) {\n        vl = __riscv_vsetvl_e32m1(n - i);\n        vfloat32m1_t v_input = __riscv_vle32_v_f32m1(input + i, vl);\n        v_min = __riscv_vfmin_vv_f32m1(v_min, v_input, vl);\n        v_max = __riscv_vfmax_vv_f32m1(v_max, v_input, vl);\n    }\n\n    float min_val = __riscv_vfmv_f_s_f32m1_f32(v_min);\n    float max_val = __riscv_vfmv_f_s_f32m1_f32(v_max);\n\n    float scale = 1.0f / (max_val - min_val);\n\n    vl = __riscv_vsetvl_e32m1(n);\n    vfloat32m1_t v_scale = __riscv_vfmv_v_f_f32m1(scale, vl);\n    vfloat32m1_t v_min_val = __riscv_vfmv_v_f_f32m1(min_val, vl);\n\n    for (size_t i = 0; i < n; i += vl) {\n        vl = __riscv_vsetvl_e32m1(n - i);\n        vfloat32m1_t v_input = __riscv_vle32_v_f32m1(input + i, vl);\n        vfloat32m1_t v_output = __riscv_vfsub_vv_f32m1(v_input, v_min_val, vl);\n        v_output = __riscv_vfmul_vv_f32m1(v_output, v_scale, vl);\n        __riscv_vse32_v_f32m1(output + i, v_output, vl);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_72_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<float> rescale_to_unit_simd(std::vector<float> numbers) {\n    size_t n = numbers.size();\n    float* data = numbers.data();\n\n    // Load the vector data into RVV registers\n    vfloat32m1_t v_data = vle32_v_f32m1(data, n);\n\n    // Find the minimum value in the vector\n    vfloat32m1_t v_min = vfmv_s_f_f32m1(v_data, 0);\n    v_min = vfredmin_vs_f32m1_f32m1(v_min, v_data, v_min);\n\n    // Find the maximum value in the vector\n    vfloat32m1_t v_max = vfmv_s_f_f32m1(v_data, 0);\n    v_max = vfredmax_vs_f32m1_f32m1(v_max, v_data, v_max);\n\n    // Broadcast the min and max values to all elements in the vector\n    vfloat32m1_t v_min_broadcast = vfmv_v_f_f32m1(v_min, n);\n    vfloat32m1_t v_max_broadcast = vfmv_v_f_f32m1(v_max, n);\n\n    // Subtract the min value from all elements\n    vfloat32m1_t v_diff = vfsub_vv_f32m1(v_data, v_min_broadcast, n);\n\n    // Subtract the min value from the max value\n    vfloat32m1_t v_range = vfsub_vv_f32m1(v_max_broadcast, v_min_broadcast, n);\n\n    // Divide the difference by the range to rescale to [0, 1]\n    vfloat32m1_t v_rescaled = vfdiv_vv_f32m1(v_diff, v_range, n);\n\n    // Store the rescaled values back into the original vector\n    vse32_v_f32m1(data, v_rescaled, n);\n\n    return numbers;\n}\n```"}
{"task_id": "SimdBench_72_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<float> rescale_to_unit_simd(std::vector<float> numbers) {\n    size_t n = numbers.size();\n    float* data = numbers.data();\n\n    vfloat32m1_t v_data = vle32_v_f32m1(data, n);\n    vfloat32m1_t v_min = vfmv_v_f_f32m1(v_data, 0, n);\n    vfloat32m1_t v_max = vfmv_v_f_f32m1(v_data, 0, n);\n\n    v_min = vfredmin_vs_f32m1_f32m1(v_min, v_data, v_min, n);\n    v_max = vfredmax_vs_f32m1_f32m1(v_max, v_data, v_max, n);\n\n    float min_val = vfmv_f_s_f32m1_f32(v_min);\n    float max_val = vfmv_f_s_f32m1_f32(v_max);\n\n    float scale = 1.0f / (max_val - min_val);\n    vfloat32m1_t v_scale = vfmv_v_f_f32m1(v_data, scale, n);\n    vfloat32m1_t v_min_val = vfmv_v_f_f32m1(v_data, min_val, n);\n\n    v_data = vfsub_vv_f32m1(v_data, v_min_val, n);\n    v_data = vfmul_vv_f32m1(v_data, v_scale, n);\n\n    vse32_v_f32m1(data, v_data, n);\n\n    return numbers;\n}\n```"}
{"task_id": "SimdBench_72_RVV", "completion": "```c++\nstd::vector<float> rescale_to_unit_simd(std::vector<float> numbers) {\n    size_t n = numbers.size();\n    float* data = numbers.data();\n\n    vfloat32m1_t v_data = vle32_v_f32m1(data, n);\n    vfloat32m1_t v_min = vfmv_s_f_f32m1(v_data, 0);\n    vfloat32m1_t v_max = vfmv_s_f_f32m1(v_data, 0);\n\n    for (size_t i = 0; i < n; i += 8) {\n        vfloat32m1_t v_chunk = vle32_v_f32m1(data + i, n - i);\n        v_min = vfmin_vv_f32m1(v_min, v_chunk, v_min);\n        v_max = vfmax_vv_f32m1(v_max, v_chunk, v_max);\n    }\n\n    float min_val = vfmv_f_s_f32m1_f32(v_min);\n    float max_val = vfmv_f_s_f32m1_f32(v_max);\n    float scale = 1.0f / (max_val - min_val);\n\n    for (size_t i = 0; i < n; i += 8) {\n        vfloat32m1_t v_chunk = vle32_v_f32m1(data + i, n - i);\n        v_chunk = vfsub_vf_f32m1(v_chunk, min_val, v_chunk);\n        v_chunk = vfmul_vf_f32m1(v_chunk, scale, v_chunk);\n        vse32_v_f32m1(data + i, v_chunk, n - i);\n    }\n\n    return numbers;\n}\n```"}
{"task_id": "SimdBench_73_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nuint64_t largest_divisor_simd(uint64_t n) {\n    size_t vl = vsetvl_e64m1(n);\n    vuint64m1_t vx = vid_v_u64m1(vl);\n    vuint64m1_t vrem = vremu_vv_u64m1(vx, vcreate_u64(n, vl), vl);\n    vuint64m1_t veqz = vmseq_vx_u64m1_b1(vrem, 0, vl);\n    uint64_t mask = vmv_x_s_u64m1_b1(veqz);\n    uint64_t largest_divisor = __builtin_ctzl(mask);\n    return largest_divisor;\n}\n```"}
{"task_id": "SimdBench_73_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nuint64_t largest_divisor_simd(uint64_t n) {\n    size_t vl = vsetvl_e64m1(n);\n    vuint64m1_t vx = vid_v_u64m1(1, vl);\n    vuint64m1_t vy = vremu_vv_u64m1(vx, vadd_vx_u64m1(vx, 1, vl), vl);\n    vuint64m1_t vmask = vmseq_vx_u64m1_b32(vy, 0, vl);\n    vuint64m1_t vresult = vcompress_vm(vx, vmask, vl);\n    uint64_t result = vmaxu_v_u64m1(vresult, vl);\n    return result;\n}\n```"}
{"task_id": "SimdBench_73_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nuint64_t largest_divisor_simd(uint64_t n) {\n    size_t vl = vsetvl_e64m1(n);\n    vuint64m1_t vx = vid_v_u64m1(vl);\n    vuint64m1_t vrem = vremu_vv_u64m1(vx, vcreate_u64(n, vl), vl);\n    vuint64m1_t vdiv = vdivu_vv_u64m1(vx, vcreate_u64(n, vl), vl);\n    vuint64m1_t vcond = vmseq_vv_u64m1_b16(vrem, vcreate_u64(0, vl), vl);\n    vuint64m1_t vresult = vcompress_vm_u64m1(vdiv, vcond, vl);\n    size_t result_size = vsetvl_e64m1(vcpop_m_b16(vcond));\n    vuint64m1_t vmax = vmaxu_vv_u64m1(vresult, vresult, result_size);\n    return vfirst_m_u64m1_b16(vmax, vcond);\n}\n```"}
{"task_id": "SimdBench_73_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nuint64_t largest_divisor_simd(uint64_t n) {\n    size_t vl = vsetvl_e64m1(n);\n    vuint64m1_t vx = vid_v_u64m1(vl);\n    vuint64m1_t vy = vremu_vv_u64m1(vx, vcreate_u64m1(n), vl);\n    vuint64m1_t vz = vmsne_vx_u64m1_b64(vy, 0, vl);\n    uint64_t mask = vmv_x_s_u64m1_b64(vz);\n    uint64_t largest_divisor = __builtin_ctzll(mask) - 1;\n    return largest_divisor;\n}\n```"}
{"task_id": "SimdBench_73_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nuint64_t largest_divisor_simd(uint64_t n) {\n    size_t vl = vsetvl_e64m1(n);\n    vuint64m1_t vx = vid_v_u64m1(vl);\n    vuint64m1_t vrem = vremu_vv_u64m1(vx, vcreate_u64(n), vl);\n    vuint64m1_t vdiv = vdivu_vv_u64m1(vx, vcreate_u64(n), vl);\n    vuint64m1_t vcmp = vmseq_vv_u64m1_b16(vrem, vcreate_u64(0), vl);\n    vuint64m1_t vdiv_masked = vmerge_vv_u64m1(vdiv, vcreate_u64(0), vcmp, vl);\n    uint64_t max_divisor = vredmaxu_vs_u64m1_u64(vdiv_masked, vcreate_u64(0), vl);\n    return max_divisor;\n}\n```"}
{"task_id": "SimdBench_74_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> factorize_simd(int n) {\n    std::vector<int> factors;\n    int factor = 2;\n\n    while (n > 1) {\n        if (n % factor == 0) {\n            factors.push_back(factor);\n            n /= factor;\n        } else {\n            factor++;\n        }\n    }\n\n    return factors;\n}\n```"}
{"task_id": "SimdBench_74_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> factorize_simd(int n) {\n    std::vector<int> factors;\n    int factor = 2;\n\n    while (n > 1) {\n        if (n % factor == 0) {\n            factors.push_back(factor);\n            n /= factor;\n        } else {\n            factor++;\n        }\n    }\n\n    return factors;\n}\n```"}
{"task_id": "SimdBench_74_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> factorize_simd(int n) {\n    std::vector<int> factors;\n    int factor = 2;\n\n    while (n > 1) {\n        if (n % factor == 0) {\n            factors.push_back(factor);\n            n /= factor;\n        } else {\n            factor++;\n        }\n    }\n\n    return factors;\n}\n```"}
{"task_id": "SimdBench_74_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> factorize_simd(int n) {\n    std::vector<int> factors;\n    vint32m1_t v_factors = __riscv_vundefined_vint32m1();\n    size_t vl = __riscv_vsetvl_e32m1(1);\n\n    for (int i = 2; i * i <= n; ++i) {\n        while (n % i == 0) {\n            v_factors = __riscv_vslideup_vx_i32m1(v_factors, i, vl);\n            n /= i;\n        }\n    }\n\n    if (n > 1) {\n        v_factors = __riscv_vslideup_vx_i32m1(v_factors, n, vl);\n    }\n\n    for (size_t i = 0; i < vl; ++i) {\n        int factor = __riscv_vmv_x_s_i32m1_i32(v_factors, i);\n        if (factor != 0) {\n            factors.push_back(factor);\n        }\n    }\n\n    return factors;\n}\n```"}
{"task_id": "SimdBench_74_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> factorize_simd(int n) {\n    std::vector<int> factors;\n    int d = 2;\n    while (n > 1) {\n        if (n % d == 0) {\n            factors.push_back(d);\n            n /= d;\n        } else {\n            d++;\n        }\n    }\n    return factors;\n}\n```"}
{"task_id": "SimdBench_75_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<float> get_positive_simd(const std::vector<float> & l) {\n    size_t n = l.size();\n    std::vector<float> result;\n    result.reserve(n);\n\n    size_t vlmax = __riscv_vsetvlmax_e32m1();\n    for (size_t i = 0; i < n; i += vlmax) {\n        size_t vl = __riscv_vsetvl_e32m1(n - i);\n        vfloat32m1_t v_input = __riscv_vle32_v_f32m1(&l[i], vl);\n        vbool32_t v_mask = __riscv_vmfgt_vf_f32m1_b32(v_input, 0.0f, vl);\n        size_t count = __riscv_vcpop_m_b32(v_mask, vl);\n        if (count > 0) {\n            vfloat32m1_t v_output = __riscv_vcompress_vm_f32m1(v_input, v_mask, vl);\n            for (size_t j = 0; j < count; ++j) {\n                result.push_back(__riscv_vmv_x_s_f32m1_f32(v_output, j));\n            }\n        }\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_75_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<float> get_positive_simd(const std::vector<float>& l) {\n    size_t n = l.size();\n    std::vector<float> result;\n    result.reserve(n);\n\n    size_t vlmax = __riscv_vsetvlmax_e32m1();\n    size_t vl = vlmax;\n\n    for (size_t i = 0; i < n; i += vl) {\n        vl = __riscv_vsetvl_e32m1(n - i);\n\n        vfloat32m1_t v_input = __riscv_vle32_v_f32m1(&l[i], vl);\n        vbool32_t v_mask = __riscv_vmfgt_vf_f32m1_b32(v_input, 0.0f, vl);\n\n        size_t count = __riscv_vcpop_m_b32(v_mask, vl);\n        if (count > 0) {\n            vfloat32m1_t v_output = __riscv_vcompress_vm_f32m1(v_input, v_mask, vl);\n            for (size_t j = 0; j < count; ++j) {\n                result.push_back(__riscv_vmv_x_s_f32m1_f32(v_output, j));\n            }\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_75_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<float> get_positive_simd(const std::vector<float>& l) {\n    size_t n = l.size();\n    std::vector<float> result;\n    result.reserve(n);\n\n    size_t vlmax = __riscv_vsetvlmax_e32m1();\n    size_t vl = vlmax;\n\n    for (size_t i = 0; i < n; i += vl) {\n        vl = __riscv_vsetvl_e32m1(n - i);\n\n        vfloat32m1_t v_input = __riscv_vle32_v_f32m1(&l[i], vl);\n        vbool32_t v_mask = __riscv_vmfgt_vf_f32m1_b32(v_input, 0.0f, vl);\n\n        size_t count = __riscv_vcpop_m_b32(v_mask, vl);\n        if (count > 0) {\n            vfloat32m1_t v_output = __riscv_vcompress_vm_f32m1(v_input, v_mask, vl);\n            float* temp = (float*)malloc(count * sizeof(float));\n            __riscv_vse32_v_f32m1(temp, v_output, count);\n            result.insert(result.end(), temp, temp + count);\n            free(temp);\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_75_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<float> get_positive_simd(const std::vector<float>& l) {\n    size_t n = l.size();\n    std::vector<float> result;\n    result.reserve(n);\n\n    size_t vlmax = __riscv_vsetvlmax_e32m1();\n    for (size_t i = 0; i < n; i += vlmax) {\n        size_t vl = __riscv_vsetvl_e32m1(n - i);\n        vfloat32m1_t v_input = __riscv_vle32_v_f32m1(&l[i], vl);\n        vbool32_t v_mask = __riscv_vmflt_vf_f32m1_b32(v_input, 0.0f, vl);\n        size_t count = __riscv_vcpop_m_b32(v_mask, vl);\n        if (count > 0) {\n            vfloat32m1_t v_output = __riscv_vcompress_vm_f32m1(v_input, v_mask, vl);\n            float temp[vlmax];\n            __riscv_vse32_v_f32m1(temp, v_output, count);\n            result.insert(result.end(), temp, temp + count);\n        }\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_75_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<float> get_positive_simd(const std::vector<float> & l) {\n    size_t n = l.size();\n    std::vector<float> result;\n    result.reserve(n);\n\n    size_t vlmax = __riscv_vsetvlmax_e32m1();\n    for (size_t i = 0; i < n; i += vlmax) {\n        size_t vl = __riscv_vsetvl_e32m1(n - i);\n        vfloat32m1_t v_input = __riscv_vle32_v_f32m1(&l[i], vl);\n        vbool32_t v_mask = __riscv_vmflt_vf_f32m1_b32(v_input, 0.0f, vl);\n        size_t count = __riscv_vcpop_m_b32(v_mask, vl);\n        if (count > 0) {\n            vfloat32m1_t v_output = __riscv_vcompress_vm_f32m1(v_input, v_mask, vl);\n            for (size_t j = 0; j < count; ++j) {\n                result.push_back(__riscv_vmv_x_s_f32m1_f32(v_output, j));\n            }\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_76_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nbool is_prime_simd(int64_t n) {\n    if (n <= 1) return false;\n    if (n <= 3) return true;\n    if (n % 2 == 0 || n % 3 == 0) return false;\n\n    int64_t i = 5;\n    int64_t limit = sqrt(n);\n    size_t vl = vsetvl_e64m1(1);\n\n    vint64m1_t v_i = vadd_vx_i64m1(vmv_v_x_i64m1(5, vl), vmv_v_x_i64m1(0, vl), vl);\n    vint64m1_t v_limit = vmv_v_x_i64m1(limit, vl);\n    vint64m1_t v_n = vmv_v_x_i64m1(n, vl);\n\n    while (i <= limit) {\n        vint64m1_t v_mod = vrem_vv_i64m1(v_n, v_i, vl);\n        vint64m1_t v_zero = vmv_v_x_i64m1(0, vl);\n        vuint1m1_t v_eq_zero = vmseq_vv_i64m1_b16(v_mod, v_zero, vl);\n\n        if (vfirst_m_b16(v_eq_zero, vl)) {\n            return false;\n        }\n\n        i += 6;\n        v_i = vadd_vx_i64m1(v_i, vmv_v_x_i64m1(6, vl), vl);\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_76_RVV", "completion": "```cpp\nbool is_prime_simd(int64_t n) {\n    if (n <= 1) return false;\n    if (n <= 3) return true;\n    if (n % 2 == 0 || n % 3 == 0) return false;\n\n    int64_t i = 5;\n    int64_t inc = 2;\n    int64_t limit = sqrt(n);\n\n    while (i <= limit) {\n        size_t vl = __riscv_vsetvl_e64m1(1);\n        vint64m1_t v_i = __riscv_vle64_v_i64m1(&i, vl);\n        vint64m1_t v_n = __riscv_vbroadcast_i64m1(n, vl);\n        vint64m1_t v_rem = __riscv_vrem_vv_i64m1(v_n, v_i, vl);\n        vbool64_t v_mask = __riscv_vmseq_vx_i64m1_b64(v_rem, 0, vl);\n\n        if (__riscv_vfirst_m_b64(v_mask, vl) != -1) {\n            return false;\n        }\n\n        i += inc;\n        inc = 6 - inc;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_76_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nbool is_prime_simd(int64_t n) {\n    if (n <= 1) return false;\n    if (n <= 3) return true;\n    if (n % 2 == 0 || n % 3 == 0) return false;\n\n    int64_t i = 5;\n    size_t vl = __riscv_vsetvl_e64m1(1);\n    vint64m1_t v_i = __riscv_vle64_v_i64m1(&i, vl);\n    vint64m1_t v_n = __riscv_vle64_v_i64m1(&n, vl);\n    vint64m1_t v_sqrt_n = __riscv_vsqrt_v_i64m1(v_n, vl);\n\n    while (__riscv_vmv_x_s_i64m1_i64(v_i) <= __riscv_vmv_x_s_i64m1_i64(v_sqrt_n)) {\n        vint64m1_t v_mod = __riscv_vrem_vv_i64m1(v_n, v_i, vl);\n        if (__riscv_vmv_x_s_i64m1_i64(v_mod) == 0) return false;\n        v_i = __riscv_vadd_vx_i64m1(v_i, 6, vl);\n        v_mod = __riscv_vrem_vv_i64m1(v_n, v_i, vl);\n        if (__riscv_vmv_x_s_i64m1_i64(v_mod) == 0) return false;\n        v_i = __riscv_vadd_vx_i64m1(v_i, 4, vl);\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_76_RVV", "completion": "```c\nbool is_prime_simd(int64_t n) {\n    if (n <= 1) return false;\n    if (n <= 3) return true;\n    if (n % 2 == 0 || n % 3 == 0) return false;\n\n    int64_t i = 5;\n    int64_t limit = sqrt(n);\n    size_t vl = __riscv_vsetvl_e64m1(1);\n\n    vint64m1_t v_i = __riscv_vid_v_i64m1(5, vl);\n    vint64m1_t v_limit = __riscv_vmv_v_x_i64m1(limit, vl);\n    vint64m1_t v_n = __riscv_vmv_v_x_i64m1(n, vl);\n\n    while (i <= limit) {\n        vint64m1_t v_mod = __riscv_vremm_vv_i64m1(v_n, v_i, vl);\n        vint64m1_t v_zero = __riscv_vmv_v_x_i64m1(0, vl);\n        vbool64_t v_mask = __riscv_vmseq_vv_i64m1_b64(v_mod, v_zero, vl);\n\n        if (__riscv_vfirst_m_b64(v_mask, vl) >= 0) {\n            return false;\n        }\n\n        i += 6;\n        v_i = __riscv_vadd_vx_i64m1(v_i, 6, vl);\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_76_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nbool is_prime_simd(int64_t n) {\n    if (n <= 1) return false;\n    if (n <= 3) return true;\n    if (n % 2 == 0 || n % 3 == 0) return false;\n\n    int64_t i = 5;\n    int64_t limit = sqrt(n);\n    size_t vl = vsetvl_e64m1(1);\n\n    vint64m1_t v_i = vmv_v_x_i64m1(i, vl);\n    vint64m1_t v_limit = vmv_v_x_i64m1(limit, vl);\n    vint64m1_t v_n = vmv_v_x_i64m1(n, vl);\n\n    while (vle64_v_i64m1_b2(v_i, vl)) {\n        vint64m1_t v_mod = vrem_vv_i64m1(v_n, v_i, vl);\n        vint64m1_t v_mod2 = vrem_vv_i64m1(v_n, vadd_vx_i64m1(v_i, 2, vl), vl);\n\n        if (vfirst_m_b2(vseq_vx_i64m1_b2(v_mod, 0, vl)) ||\n            vfirst_m_b2(vseq_vx_i64m1_b2(v_mod2, 0, vl))) {\n            return false;\n        }\n\n        v_i = vadd_vx_i64m1(v_i, 6, vl);\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_77_RVV", "completion": "```c++\n#include <riscv_vector.h>\n#include <string>\n\nstd::string solve_simd(const std::string &s) {\n    size_t len = s.length();\n    if (len == 0) return s;\n\n    bool has_letters = false;\n    vbool8_t mask = vmseq_vx_u8(vundefined_u8(), 0, 0);\n    vuint8m1_t vec = vle8_v_u8((const uint8_t*)s.data(), len, mask);\n\n    for (size_t i = 0; i < len; ++i) {\n        if (isalpha(s[i])) {\n            has_letters = true;\n            break;\n        }\n    }\n\n    if (has_letters) {\n        vuint8m1_t lower = vle8_v_u8((const uint8_t*)\"abcdefghijklmnopqrstuvwxyz\", 26, mask);\n        vuint8m1_t upper = vle8_v_u8((const uint8_t*)\"ABCDEFGHIJKLMNOPQRSTUVWXYZ\", 26, mask);\n\n        vuint8m1_t lower_mask = vmsif_vx_u8(mask, vec, 'a');\n        vuint8m1_t upper_mask = vmsif_vx_u8(mask, vec, 'A');\n\n        vuint8m1_t lower_to_upper = vsub_vx_u8(vec, 'a' - 'A', lower_mask);\n        vuint8m1_t upper_to_lower = vadd_vx_u8(vec, 'a' - 'A', upper_mask);\n\n        vec = vor_vv_u8(vec, lower_to_upper, mask);\n        vec = vor_vv_u8(vec, upper_to_lower, mask);\n    } else {\n        vuint8m1_t reversed = vreverse_v_u8(vec, mask);\n        vec = reversed;\n    }\n\n    std::string result(len, '\\0');\n    vse8_v_u8((uint8_t*)result.data(), vec, len, mask);\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_77_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nstd::string solve_simd(const std::string &s) {\n    size_t len = s.length();\n    if (len == 0) return s;\n\n    bool has_letters = false;\n    std::string result = s;\n\n    // Check if the string contains any letters\n    for (size_t i = 0; i < len; ++i) {\n        if (isalpha(s[i])) {\n            has_letters = true;\n            break;\n        }\n    }\n\n    if (has_letters) {\n        // Reverse case for letters using RVV intrinsics\n        size_t vl = vsetvl_e8m8(len);\n        vuint8m8_t v_s = vle8_v_u8m8((const uint8_t*)s.data(), vl);\n        vuint8m8_t v_lower = vle8_v_u8m8((const uint8_t*)\"abcdefghijklmnopqrstuvwxyz\", vl);\n        vuint8m8_t v_upper = vle8_v_u8m8((const uint8_t*)\"ABCDEFGHIJKLMNOPQRSTUVWXYZ\", vl);\n\n        vuint8m8_t v_is_lower = vmseq_vx_u8m8_b8(v_s, v_lower, vl);\n        vuint8m8_t v_is_upper = vmseq_vx_u8m8_b8(v_s, v_upper, vl);\n\n        vuint8m8_t v_result = vmerge_vxm_u8m8(v_s, v_upper, v_is_lower, vl);\n        v_result = vmerge_vxm_u8m8(v_result, v_lower, v_is_upper, vl);\n\n        vse8_v_u8m8((uint8_t*)result.data(), v_result, vl);\n    } else {\n        // Reverse the string\n        std::reverse(result.begin(), result.end());\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_77_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nstd::string solve_simd(const std::string &s) {\n    size_t len = s.length();\n    if (len == 0) return s;\n\n    bool has_letters = false;\n    std::string result = s;\n\n    // Check if there are any letters in the string\n    for (size_t i = 0; i < len; ++i) {\n        if (isalpha(s[i])) {\n            has_letters = true;\n            break;\n        }\n    }\n\n    if (has_letters) {\n        // Reverse case of letters using RVV intrinsics\n        size_t vl = __riscv_vsetvl_e8m8(len);\n        vuint8m8_t v_s = __riscv_vle8_v_u8m8((const uint8_t*)s.data(), vl);\n        vuint8m8_t v_result = __riscv_vle8_v_u8m8((uint8_t*)result.data(), vl);\n\n        vuint8m8_t v_lower = __riscv_vmv_v_x_u8m8('a', vl);\n        vuint8m8_t v_upper = __riscv_vmv_v_x_u8m8('A', vl);\n        vuint8m8_t v_z = __riscv_vmv_v_x_u8m8('z', vl);\n        vuint8m8_t v_Z = __riscv_vmv_v_x_u8m8('Z', vl);\n\n        vuint8m8_t v_is_lower = __riscv_vmseq_vv_u8m8_b32(v_s, v_lower, vl);\n        vuint8m8_t v_is_upper = __riscv_vmseq_vv_u8m8_b32(v_s, v_upper, vl);\n\n        vuint8m8_t v_diff = __riscv_vsub_vv_u8m8(v_z, v_lower, vl);\n        vuint8m8_t v_diff_upper = __riscv_vsub_vv_u8m8(v_Z, v_upper, vl);\n\n        vuint8m8_t v_new_lower = __riscv_vsub_vv_u8m8(v_s, v_diff, vl);\n        vuint8m8_t v_new_upper = __riscv_vadd_vv_u8m8(v_s, v_diff_upper, vl);\n\n        v_result = __riscv_vmerge_vvm_u8m8(v_result, v_new_lower, v_is_lower, vl);\n        v_result = __riscv_vmerge_vvm_u8m8(v_result, v_new_upper, v_is_upper, vl);\n\n        __riscv_vse8_v_u8m8((uint8_t*)result.data(), v_result, vl);\n    } else {\n        // Reverse the string\n        std::reverse(result.begin(), result.end());\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_77_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n#include <cctype>\n\nstd::string solve_simd(const std::string & s) {\n    size_t len = s.length();\n    if (len == 0) return s;\n\n    bool has_letters = false;\n    std::string result = s;\n\n    // Check if there are any letters in the string\n    for (size_t i = 0; i < len; ++i) {\n        if (std::isalpha(s[i])) {\n            has_letters = true;\n            break;\n        }\n    }\n\n    if (has_letters) {\n        // Reverse case for letters using RVV intrinsics\n        size_t vl = __riscv_vsetvl_e8m1(len);\n        vuint8m1_t v_s = __riscv_vle8_v_u8m1((const uint8_t*)s.data(), vl);\n        vuint8m1_t v_result = __riscv_vle8_v_u8m1((uint8_t*)result.data(), vl);\n\n        vuint8m1_t v_lower = __riscv_vand_vx_u8m1(v_s, 0x20, vl);\n        vuint8m1_t v_upper = __riscv_vand_vx_u8m1(v_s, 0xDF, vl);\n        vuint8m1_t v_mask = __riscv_vand_vx_u8m1(v_s, 0x40, vl);\n\n        vuint8m1_t v_toggle = __riscv_vxor_vv_u8m1(v_lower, v_mask, vl);\n        vuint8m1_t v_final = __riscv_vmerge_vvm_u8m1(v_upper, v_toggle, v_mask, vl);\n\n        __riscv_vse8_v_u8m1((uint8_t*)result.data(), v_final, vl);\n    } else {\n        // Reverse the string\n        std::reverse(result.begin(), result.end());\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_77_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nstd::string solve_simd(const std::string &s) {\n    size_t len = s.length();\n    if (len == 0) return s;\n\n    bool has_letters = false;\n    std::string result = s;\n\n    // Check if there are any letters in the string\n    for (size_t i = 0; i < len; ++i) {\n        if (isalpha(s[i])) {\n            has_letters = true;\n            break;\n        }\n    }\n\n    if (has_letters) {\n        // Reverse case for letters using RVV intrinsics\n        size_t vl = __riscv_vsetvl_e8m1(len);\n        vuint8m1_t v_s = __riscv_vle8_v_u8m1((const uint8_t*)s.data(), vl);\n        vuint8m1_t v_lower = __riscv_vand_vx_u8m1(v_s, 0xDF, vl);\n        vuint8m1_t v_upper = __riscv_vor_vx_u8m1(v_s, 0x20, vl);\n        vuint8m1_t v_mask = __riscv_vand_vx_u8m1(v_s, 0x20, vl);\n        vuint8m1_t v_result = __riscv_vmerge_vvm_u8m1(v_lower, v_upper, v_mask, vl);\n        __riscv_vse8_v_u8m1((uint8_t*)result.data(), v_result, vl);\n    } else {\n        // Reverse the string using RVV intrinsics\n        size_t vl = __riscv_vsetvl_e8m1(len);\n        vuint8m1_t v_s = __riscv_vle8_v_u8m1((const uint8_t*)s.data(), vl);\n        vuint8m1_t v_rev = __riscv_vrgather_vv_u8m1(v_s, __riscv_vid_v_u8m1(vl), vl);\n        __riscv_vse8_v_u8m1((uint8_t*)result.data(), v_rev, vl);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_78_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<int> sort_third_simd(std::vector<int> l) {\n    size_t n = l.size();\n    std::vector<int> result(n);\n    std::vector<int> to_sort;\n\n    // Collect elements at indices divisible by 3\n    for (size_t i = 0; i < n; i += 3) {\n        to_sort.push_back(l[i]);\n    }\n\n    // Sort the collected elements\n    std::sort(to_sort.begin(), to_sort.end());\n\n    // Place sorted elements back into the result vector\n    size_t sort_index = 0;\n    for (size_t i = 0; i < n; ++i) {\n        if (i % 3 == 0) {\n            result[i] = to_sort[sort_index++];\n        } else {\n            result[i] = l[i];\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_78_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<int> sort_third_simd(std::vector<int> l) {\n    size_t n = l.size();\n    std::vector<int> result(n);\n    std::vector<int> to_sort;\n\n    // Collect elements at indices divisible by 3\n    for (size_t i = 0; i < n; i += 3) {\n        to_sort.push_back(l[i]);\n    }\n\n    // Sort the collected elements\n    std::sort(to_sort.begin(), to_sort.end());\n\n    // Reconstruct the result vector\n    size_t sort_index = 0;\n    for (size_t i = 0; i < n; ++i) {\n        if (i % 3 == 0) {\n            result[i] = to_sort[sort_index++];\n        } else {\n            result[i] = l[i];\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_78_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<int> sort_third_simd(std::vector<int> l) {\n    size_t n = l.size();\n    std::vector<int> result(n);\n\n    // Create a mask for elements at indices divisible by 3\n    size_t vl = __riscv_vsetvl_e32m1(n);\n    vuint32m1_t mask = __riscv_vid_v_u32m1(vl);\n    mask = __riscv_vremu_vx_u32m1(mask, 3, vl);\n    mask = __riscv_vmsne_vx_u32m1_b32(mask, 0, vl);\n\n    // Extract elements at indices divisible by 3\n    vint32m1_t vec = __riscv_vle32_v_i32m1(l.data(), vl);\n    vint32m1_t sorted_vec = __riscv_vcompress_vm(vec, mask, vl);\n\n    // Sort the extracted elements\n    size_t sorted_size = __riscv_vcpop_m(mask, vl);\n    std::vector<int> sorted(sorted_size);\n    __riscv_vse32_v_i32m1(sorted.data(), sorted_vec, sorted_size);\n    std::sort(sorted.begin(), sorted.end());\n\n    // Reconstruct the result vector\n    vint32m1_t sorted_vec_expanded = __riscv_vle32_v_i32m1(sorted.data(), sorted_size);\n    vint32m1_t result_vec = __riscv_vmerge_vvm(vec, sorted_vec_expanded, mask, vl);\n    __riscv_vse32_v_i32m1(result.data(), result_vec, vl);\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_78_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<int> sort_third_simd(std::vector<int> l) {\n    size_t n = l.size();\n    std::vector<int> result(n);\n    std::vector<int> to_sort;\n\n    // Collect elements at indices divisible by 3\n    for (size_t i = 0; i < n; i += 3) {\n        to_sort.push_back(l[i]);\n    }\n\n    // Sort the collected elements\n    std::sort(to_sort.begin(), to_sort.end());\n\n    // Create masks for vector operations\n    size_t vl = __riscv_vsetvl_e32m1(n);\n    vint32m1_t v_indices = __riscv_vid_v_i32m1(vl, 0);\n    vint32m1_t v_mask = __riscv_vremu_vx_i32m1_b32(v_indices, 3, vl);\n\n    // Load the original vector into a vector register\n    vint32m1_t v_l = __riscv_vle32_v_i32m1(l.data(), vl);\n\n    // Create a vector with sorted elements at indices divisible by 3\n    vint32m1_t v_sorted = __riscv_vle32_v_i32m1(to_sort.data(), vl);\n\n    // Merge the sorted elements back into the original vector\n    vint32m1_t v_result = __riscv_vmerge_vvm_i32m1(v_l, v_sorted, v_mask, vl);\n\n    // Store the result back into the result vector\n    __riscv_vse32_v_i32m1(result.data(), v_result, vl);\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_78_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<int> sort_third_simd(std::vector<int> l) {\n    size_t n = l.size();\n    std::vector<int> result(n);\n    std::vector<int> to_sort;\n\n    // Collect elements at indices divisible by 3\n    for (size_t i = 0; i < n; i += 3) {\n        to_sort.push_back(l[i]);\n    }\n\n    // Sort the collected elements\n    std::sort(to_sort.begin(), to_sort.end());\n\n    // Create masks for vector operations\n    size_t vl = __riscv_vsetvl_e32m1(n);\n    vint32m1_t v_indices = __riscv_vid_v_i32m1(vl, 0);\n    vint32m1_t v_mask = __riscv_vremu_vx_i32m1_b32(v_indices, 3, vl);\n\n    // Load the original vector into a vector register\n    vint32m1_t v_l = __riscv_vle32_v_i32m1(l.data(), vl);\n\n    // Create a vector with sorted elements at indices divisible by 3\n    vint32m1_t v_sorted = __riscv_vle32_v_i32m1(to_sort.data(), vl);\n\n    // Merge the sorted elements back into the original vector\n    vint32m1_t v_result = __riscv_vmerge_vvm_i32m1(v_l, v_sorted, v_mask, vl);\n\n    // Store the result back into the result vector\n    __riscv_vse32_v_i32m1(result.data(), v_result, vl);\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_79_RVV", "completion": "```cpp\nfloat max_element_simd(std::vector<float> l) {\n    size_t n = l.size();\n    size_t vl = vsetvl_e32m1(n);\n    vfloat32m1_t v = vle32_v_f32m1(l.data(), vl);\n    vfloat32m1_t max_val = v;\n\n    for (size_t i = vl; i < n; i += vl) {\n        vl = vsetvl_e32m1(n - i);\n        vfloat32m1_t v_next = vle32_v_f32m1(l.data() + i, vl);\n        max_val = vfmax_vv_f32m1(max_val, v_next, vl);\n    }\n\n    float max_scalar = vfmv_f_s_f32m1_f32(max_val);\n    return max_scalar;\n}\n```"}
{"task_id": "SimdBench_79_RVV", "completion": "```c++\nfloat max_element_simd(std::vector<float> l) {\n    size_t n = l.size();\n    size_t vl = vsetvl_e32m1(n);\n    vfloat32m1_t v = vle32_v_f32m1(l.data(), vl);\n\n    while (vl < n) {\n        size_t remaining = n - vl;\n        size_t new_vl = vsetvl_e32m1(remaining);\n        vfloat32m1_t v_new = vle32_v_f32m1(l.data() + vl, new_vl);\n        v = vfmax_vv_f32m1(v, v_new, vl);\n        vl += new_vl;\n    }\n\n    float max_val = vfmv_s_f_f32m1_f32(vredmax_vs_f32m1_f32(v, vfmv_s_f_f32m1_f32(v, vl), vl));\n    return max_val;\n}\n```"}
{"task_id": "SimdBench_79_RVV", "completion": "```c++\nfloat max_element_simd(std::vector<float> l) {\n    size_t n = l.size();\n    size_t vl = __riscv_vsetvl_e32m1(n);\n    vfloat32m1_t v = __riscv_vle32_v_f32m1(l.data(), vl);\n\n    vfloat32m1_t max_val = __riscv_vfmv_s_f_f32m1(v[0], vl);\n    for (size_t i = 1; i < n; i += vl) {\n        vl = __riscv_vsetvl_e32m1(n - i);\n        vfloat32m1_t v = __riscv_vle32_v_f32m1(l.data() + i, vl);\n        max_val = __riscv_vfmax_vv_f32m1(max_val, v, vl);\n    }\n\n    float result;\n    __riscv_vse32_v_f32m1(&result, max_val, 1);\n    return result;\n}\n```"}
{"task_id": "SimdBench_79_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nfloat max_element_simd(std::vector<float> l) {\n    size_t n = l.size();\n    vfloat32m1_t v = vle32_v_f32m1(l.data(), n);\n    vfloat32m1_t max_val = vfmv_s_f_f32m1(0.0f, vfloat32m1);\n    for (size_t i = 0; i < n; i += 8) {\n        vfloat32m1_t chunk = vle32_v_f32m1(l.data() + i, n - i);\n        max_val = vfmax_vv_f32m1(max_val, chunk, vfloat32m1);\n    }\n    return vfmv_f_s_f32m1_f32(max_val);\n}\n```"}
{"task_id": "SimdBench_79_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nfloat max_element_simd(std::vector<float> l) {\n    size_t n = l.size();\n    vfloat32m1_t v = vle32_v_f32m1(l.data(), n);\n    vfloat32m1_t max_val = vfmv_s_f_f32m1(vfmv_s_f_f32m1(v, 0), v, 0);\n    for (size_t i = 1; i < n; i++) {\n        max_val = vfmax_vv_f32m1(max_val, v, max_val);\n    }\n    return vfmv_f_s_f32m1_f32(max_val);\n}\n```"}
{"task_id": "SimdBench_80_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nint fizz_buzz_simd(int n) {\n    int count = 0;\n    int vl = __riscv_vsetvl_e32m1(n);\n\n    vint32m1_t v_indices = __riscv_vid_v_i32m1(vl, 0);\n    vint32m1_t v_mod11 = __riscv_vremu_vx_i32m1(v_indices, 11, vl);\n    vint32m1_t v_mod13 = __riscv_vremu_vx_i32m1(v_indices, 13, vl);\n    vint32m1_t v_mask = __riscv_vmseq_vx_i32m1_b32(v_mod11, 0, vl);\n    v_mask = __riscv_vmor_mm_b32(v_mask, __riscv_vmseq_vx_i32m1_b32(v_mod13, 0, vl), vl);\n\n    vint32m1_t v_divisible = __riscv_vcompress_vm_i32m1(v_indices, v_mask, vl);\n\n    for (int i = 0; i < vl; ++i) {\n        int num = v_divisible[i];\n        while (num > 0) {\n            if (num % 10 == 7) {\n                count++;\n            }\n            num /= 10;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_80_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nint fizz_buzz_simd(int n) {\n    int count = 0;\n    int vl = vsetvl_e32m1(n);\n    vint32m1_t v_indices = vid_v_i32m1(0, 1, vl);\n    vint32m1_t v_mod11 = vrem_vv_i32m1(v_indices, vcreate_i32m1(11), vl);\n    vint32m1_t v_mod13 = vrem_vv_i32m1(v_indices, vcreate_i32m1(13), vl);\n    vint32m1_t v_mask = vor_vv_i32m1_b32(vmseq_vx_i32m1_b32(v_mod11, 0, vl), vmseq_vx_i32m1_b32(v_mod13, 0, vl), vl);\n\n    for (int i = 0; i < n; i += vl) {\n        vl = vsetvl_e32m1(n - i);\n        v_indices = vid_v_i32m1(i, 1, vl);\n        v_mod11 = vrem_vv_i32m1(v_indices, vcreate_i32m1(11), vl);\n        v_mod13 = vrem_vv_i32m1(v_indices, vcreate_i32m1(13), vl);\n        v_mask = vor_vv_i32m1_b32(vmseq_vx_i32m1_b32(v_mod11, 0, vl), vmseq_vx_i32m1_b32(v_mod13, 0, vl), vl);\n\n        vint32m1_t v_num = vle32_v_i32m1(&v_indices, vl);\n        vint32m1_t v_digit = vrem_vv_i32m1(v_num, vcreate_i32m1(10), vl);\n        vint32m1_t v_mask_digit = vmseq_vx_i32m1_b32(v_digit, 7, vl);\n        vint32m1_t v_mask_final = vand_vv_i32m1_b32(v_mask, v_mask_digit, vl);\n\n        count += vpopc_m_b32(v_mask_final, vl);\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_80_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nint fizz_buzz_simd(int n) {\n    int count = 0;\n    vint8m1_t v_ones = __riscv_vmv_v_x_i8m1(1, 1);\n    vint8m1_t v_sevens = __riscv_vmv_v_x_i8m1(7, 1);\n    vint8m1_t v_zeros = __riscv_vmv_v_x_i8m1(0, 1);\n\n    for (int i = 0; i < n; i += 8) {\n        vint8m1_t v_indices = __riscv_vid_v_i8m1(8, i);\n        vint8m1_t v_mod11 = __riscv_vrem_vx_i8m1(v_indices, 11, 8);\n        vint8m1_t v_mod13 = __riscv_vrem_vx_i8m1(v_indices, 13, 8);\n        vint8m1_t v_mask = __riscv_vmseq_vx_i8m1(v_mod11, 0, 8) | __riscv_vmseq_vx_i8m1(v_mod13, 0, 8);\n\n        vint8m1_t v_digits = __riscv_vmv_v_v_i8m1(v_indices, 8);\n        vint8m1_t v_count_sevens = __riscv_vmv_v_v_i8m1(v_zeros, 8);\n\n        for (int j = 0; j < 8; ++j) {\n            vint8m1_t v_digit = __riscv_vmv_v_v_i8m1(v_digits, 8);\n            vint8m1_t v_digit_mod10 = __riscv_vrem_vx_i8m1(v_digit, 10, 8);\n            vint8m1_t v_is_seven = __riscv_vmseq_vx_i8m1(v_digit_mod10, 7, 8);\n            v_count_sevens = __riscv_vadd_vv_i8m1(v_count_sevens, v_is_seven, 8);\n            v_digits = __riscv_vdiv_vx_i8m1(v_digits, 10, 8);\n        }\n\n        vint8m1_t v_final_count = __riscv_vand_vv_i8m1(v_mask, v_count_sevens, 8);\n        count += __riscv_vredsum_vs_i8m1_i32m1(v_final_count, v_zeros, 8);\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_80_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nint fizz_buzz_simd(int n) {\n    int count = 0;\n    int vl = vsetvl_e32m1(n);\n\n    vint32m1_t v_indices = vid_v_i32m1(0, 1, vl);\n    vint32m1_t v_mod11 = vremu_vx_i32m1(v_indices, 11, vl);\n    vint32m1_t v_mod13 = vremu_vx_i32m1(v_indices, 13, vl);\n    vint32m1_t v_mask = vor_vv_i32m1_b1(v_mask, v_mask, vl);\n\n    for (int i = 0; i < n; i += vl) {\n        vl = vsetvl_e32m1(n - i);\n        v_indices = vid_v_i32m1(i, 1, vl);\n        v_mod11 = vremu_vx_i32m1(v_indices, 11, vl);\n        v_mod13 = vremu_vx_i32m1(v_indices, 13, vl);\n        v_mask = vor_vv_i32m1_b1(v_mask, v_mask, vl);\n\n        vint32m1_t v_divisible = vor_vv_i32m1_b1(vseq_vx_i32m1_b1(v_mod11, 0, vl), vseq_vx_i32m1_b1(v_mod13, 0, vl), vl);\n        vint32m1_t v_digits = vcompress_vm_i32m1(v_divisible, v_indices, vl);\n\n        for (int j = 0; j < vl; ++j) {\n            int num = v_digits[j];\n            while (num > 0) {\n                if (num % 10 == 7) {\n                    count++;\n                }\n                num /= 10;\n            }\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_80_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nint fizz_buzz_simd(int n) {\n    int count = 0;\n    int vl = vsetvl_e32m1(n);\n    vint32m1_t vx = vid_v_i32m1(0, 1, vl);\n    vint32m1_t vmod11 = vrem_vv_i32m1(vx, vmv_v_x_i32m1(11, vl), vl);\n    vint32m1_t vmod13 = vrem_vv_i32m1(vx, vmv_v_x_i32m1(13, vl), vl);\n    vint32m1_t vdivisible = vor_vv_i32m1_b128(vmseq_vx_i32m1_b128(vmod11, 0, vl), vmseq_vx_i32m1_b128(vmod13, 0, vl), vl);\n    vint32m1_t vcount = vmv_v_x_i32m1(0, vl);\n\n    for (int i = 0; i < n; i += vl) {\n        vl = vsetvl_e32m1(n - i);\n        vx = vid_v_i32m1(i, 1, vl);\n        vmod11 = vrem_vv_i32m1(vx, vmv_v_x_i32m1(11, vl), vl);\n        vmod13 = vrem_vv_i32m1(vx, vmv_v_x_i32m1(13, vl), vl);\n        vdivisible = vor_vv_i32m1_b128(vmseq_vx_i32m1_b128(vmod11, 0, vl), vmseq_vx_i32m1_b128(vmod13, 0, vl), vl);\n\n        vint32m1_t vdigits = vdiv_vv_i32m1(vx, vmv_v_x_i32m1(10, vl), vl);\n        vint32m1_t vremainder = vrem_vv_i32m1(vx, vmv_v_x_i32m1(10, vl), vl);\n        vint32m1_t vcount7 = vmv_v_x_i32m1(0, vl);\n\n        while (vany_v_i32m1_b128(vdivisible, vl)) {\n            vint32m1_t vdigit7 = vmseq_vx_i32m1_b128(vremainder, 7, vl);\n            vcount7 = vadd_vv_i32m1(vcount7, vdigit7, vl);\n            vdivisible = vand_vv_i32m1_b128(vdivisible, vmsne_vx_i32m1_b128(vdigits, 0, vl), vl);\n            vdigits = vdiv_vv_i32m1(vdigits, vmv_v_x_i32m1(10, vl), vl);\n            vremainder = vrem_vv_i32m1(vdigits, vmv_v_x_i32m1(10, vl), vl);\n        }\n\n        vcount = vadd_vv_i32m1(vcount, vcount7, vl);\n    }\n\n    count = vredsum_vs_i32m1_i32m1(vcount, count, vl);\n    return count;\n}\n```"}
{"task_id": "SimdBench_81_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<float> sort_even_simd(std::vector<float> l) {\n    size_t n = l.size();\n    if (n == 0) return l;\n\n    std::vector<float> even_indices;\n    std::vector<size_t> even_positions;\n\n    for (size_t i = 0; i < n; i += 2) {\n        even_indices.push_back(l[i]);\n        even_positions.push_back(i);\n    }\n\n    std::sort(even_indices.begin(), even_indices.end());\n\n    for (size_t i = 0; i < even_indices.size(); ++i) {\n        l[even_positions[i]] = even_indices[i];\n    }\n\n    return l;\n}\n```"}
{"task_id": "SimdBench_81_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<float> sort_even_simd(std::vector<float> l) {\n    size_t n = l.size();\n    if (n == 0) return l;\n\n    std::vector<float> even_indices;\n    std::vector<size_t> even_positions;\n\n    for (size_t i = 0; i < n; i += 2) {\n        even_indices.push_back(l[i]);\n        even_positions.push_back(i);\n    }\n\n    std::sort(even_indices.begin(), even_indices.end());\n\n    for (size_t i = 0; i < even_indices.size(); ++i) {\n        l[even_positions[i]] = even_indices[i];\n    }\n\n    return l;\n}\n```"}
{"task_id": "SimdBench_81_RVV", "completion": "```c++\n#include <riscv_vector.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<float> sort_even_simd(std::vector<float> l) {\n    size_t n = l.size();\n    std::vector<float> result(n);\n\n    // Create a vector of even-indexed elements\n    std::vector<float> even_elements;\n    for (size_t i = 0; i < n; i += 2) {\n        even_elements.push_back(l[i]);\n    }\n\n    // Sort the even-indexed elements\n    std::sort(even_elements.begin(), even_elements.end());\n\n    // Reconstruct the result vector\n    size_t even_index = 0;\n    for (size_t i = 0; i < n; ++i) {\n        if (i % 2 == 0) {\n            result[i] = even_elements[even_index++];\n        } else {\n            result[i] = l[i];\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_81_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<float> sort_even_simd(std::vector<float> l) {\n    size_t n = l.size();\n    if (n == 0) return l;\n\n    std::vector<float> even_elements;\n    std::vector<size_t> even_indices;\n\n    for (size_t i = 0; i < n; i += 2) {\n        even_elements.push_back(l[i]);\n        even_indices.push_back(i);\n    }\n\n    std::sort(even_elements.begin(), even_elements.end());\n\n    for (size_t i = 0; i < even_elements.size(); ++i) {\n        l[even_indices[i]] = even_elements[i];\n    }\n\n    return l;\n}\n```"}
{"task_id": "SimdBench_81_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<float> sort_even_simd(std::vector<float> l) {\n    size_t n = l.size();\n    if (n == 0) return l;\n\n    // Create a vector to hold the even-indexed elements\n    std::vector<float> even_elements;\n    for (size_t i = 0; i < n; i += 2) {\n        even_elements.push_back(l[i]);\n    }\n\n    // Sort the even-indexed elements\n    std::sort(even_elements.begin(), even_elements.end());\n\n    // Place the sorted even-indexed elements back into the original vector\n    for (size_t i = 0, j = 0; i < n; i += 2, ++j) {\n        l[i] = even_elements[j];\n    }\n\n    return l;\n}\n```"}
{"task_id": "SimdBench_82_RVV", "completion": "```c++\nbool triples_sum_to_zero_simd(std::vector<int> l) {\n    size_t n = l.size();\n    if (n < 3) return false;\n\n    size_t vl = __riscv_vsetvl_e32m1(n);\n    vint32m1_t v_a = __riscv_vle32_v_i32m1(l.data(), vl);\n\n    for (size_t i = 0; i < n - 2; ++i) {\n        vint32m1_t v_b = __riscv_vle32_v_i32m1(l.data() + i + 1, vl);\n        vint32m1_t v_c = __riscv_vle32_v_i32m1(l.data() + i + 2, vl);\n\n        vint32m1_t v_sum = __riscv_vadd_vv_i32m1(v_a, v_b, vl);\n        v_sum = __riscv_vadd_vv_i32m1(v_sum, v_c, vl);\n\n        vint8m1_t v_zero = __riscv_vmseq_vx_i32m1_b8(v_sum, 0, vl);\n        if (__riscv_vfirst_m_b8(v_zero, vl) != -1) {\n            return true;\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_82_RVV", "completion": "```c++\nbool triples_sum_to_zero_simd(std::vector<int> l) {\n    size_t n = l.size();\n    if (n < 3) return false;\n\n    size_t vl = __riscv_vsetvl_e32m1(n);\n    vint32m1_t v_a = __riscv_vle32_v_i32m1(l.data(), vl);\n\n    for (size_t i = 0; i < n - 2; ++i) {\n        vint32m1_t v_b = __riscv_vle32_v_i32m1(l.data() + i + 1, vl);\n        vint32m1_t v_c = __riscv_vle32_v_i32m1(l.data() + i + 2, vl);\n\n        vint32m1_t v_sum = __riscv_vadd_vv_i32m1(v_a, v_b, vl);\n        v_sum = __riscv_vadd_vv_i32m1(v_sum, v_c, vl);\n\n        vint8mf8_t v_zero = __riscv_vmseq_vx_i32mf8(v_sum, 0, vl);\n        if (__riscv_vfirst_m(v_zero, vl) != -1) {\n            return true;\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_82_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nbool triples_sum_to_zero_simd(std::vector<int> l) {\n    size_t n = l.size();\n    if (n < 3) return false;\n\n    for (size_t i = 0; i < n - 2; ++i) {\n        int a = l[i];\n        size_t vl = __riscv_vsetvl_e32m1(n - i - 1);\n        vint32m1_t v_b = __riscv_vle32_v_i32m1(&l[i + 1], vl);\n        vint32m1_t v_c = __riscv_vle32_v_i32m1(&l[i + 2], vl);\n\n        vint32m1_t v_sum = __riscv_vadd_vv_i32m1(v_b, v_c, vl);\n        vint32m1_t v_neg_a = __riscv_vmv_v_x_i32m1(-a, vl);\n        vint32m1_t v_result = __riscv_vmseq_vv_i32m1(v_sum, v_neg_a, vl);\n\n        if (__riscv_vmv_x_s_i32m1_i32(v_result) != 0) {\n            return true;\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_82_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nbool triples_sum_to_zero_simd(std::vector<int> l) {\n    size_t n = l.size();\n    if (n < 3) return false;\n\n    size_t vl = __riscv_vsetvl_e32m1(n);\n    vint32m1_t v_a = __riscv_vle32_v_i32m1(l.data(), vl);\n\n    for (size_t i = 0; i < n - 2; ++i) {\n        vint32m1_t v_b = __riscv_vle32_v_i32m1(l.data() + i + 1, vl);\n        for (size_t j = i + 1; j < n - 1; ++j) {\n            vint32m1_t v_c = __riscv_vle32_v_i32m1(l.data() + j + 1, vl);\n            vint32m1_t v_sum = __riscv_vadd_vv_i32m1(v_a, v_b, vl);\n            v_sum = __riscv_vadd_vv_i32m1(v_sum, v_c, vl);\n            vint8mf8_t v_zero = __riscv_vmseq_vx_i32mf8(v_sum, 0, vl);\n            if (__riscv_vfirst_m(v_zero, vl) != -1) {\n                return true;\n            }\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_82_RVV", "completion": "```c++\nbool triples_sum_to_zero_simd(std::vector<int> l) {\n    size_t n = l.size();\n    if (n < 3) return false;\n\n    size_t vl = __riscv_vsetvl_e32m1(n);\n    vint32m1_t v_a = __riscv_vle32_v_i32m1(l.data(), vl);\n\n    for (size_t i = 0; i < n - 2; ++i) {\n        vint32m1_t v_b = __riscv_vle32_v_i32m1(l.data() + i + 1, vl);\n        vint32m1_t v_c = __riscv_vle32_v_i32m1(l.data() + i + 2, vl);\n\n        vint32m1_t v_sum = __riscv_vadd_vv_i32m1(v_a, v_b, vl);\n        v_sum = __riscv_vadd_vv_i32m1(v_sum, v_c, vl);\n\n        vint32m1_t v_zero = __riscv_vmv_v_x_i32m1(0, vl);\n        vint32m1_t v_mask = __riscv_vmseq_vv_i32m1_b32(v_sum, v_zero, vl);\n\n        if (__riscv_vfirst_m_b32(v_mask, vl) != -1) {\n            return true;\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_83_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> incr_list_simd(std::vector<int> l) {\n    size_t n = l.size();\n    std::vector<int> result(n);\n\n    vint32m1_t v_input = __riscv_vle32_v_i32m1(l.data(), n);\n    vint32m1_t v_one = __riscv_vmv_v_x_i32m1(1, n);\n    vint32m1_t v_output = __riscv_vadd_vv_i32m1(v_input, v_one, n);\n\n    __riscv_vse32_v_i32m1(result.data(), v_output, n);\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_83_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> incr_list_simd(std::vector<int> l) {\n    size_t n = l.size();\n    std::vector<int> result(n);\n\n    vint32m1_t v_in = __riscv_vle32_v_i32m1(l.data(), n);\n    vint32m1_t v_one = __riscv_vmv_v_x_i32m1(1, n);\n    vint32m1_t v_out = __riscv_vadd_vv_i32m1(v_in, v_one, n);\n\n    __riscv_vse32_v_i32m1(result.data(), v_out, n);\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_83_RVV", "completion": "```c++\nstd::vector<int> incr_list_simd(std::vector<int> l) {\n    size_t n = l.size();\n    std::vector<int> result(n);\n\n    vint32m1_t v_input = __riscv_vle32_v_i32m1(l.data(), n);\n    vint32m1_t v_one = __riscv_vmv_v_x_i32m1(1, n);\n    vint32m1_t v_output = __riscv_vadd_vv_i32m1(v_input, v_one, n);\n\n    __riscv_vse32_v_i32m1(result.data(), v_output, n);\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_83_RVV", "completion": "```c++\nstd::vector<int> incr_list_simd(std::vector<int> l) {\n    size_t n = l.size();\n    std::vector<int> result(n);\n\n    vint32m1_t v_input = __riscv_vle32_v_i32m1(l.data(), n);\n    vint32m1_t v_one = __riscv_vmv_v_x_i32m1(1, n);\n    vint32m1_t v_result = __riscv_vadd_vv_i32m1(v_input, v_one, n);\n\n    __riscv_vse32_v_i32m1(result.data(), v_result, n);\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_83_RVV", "completion": "```c++\nstd::vector<int> incr_list_simd(std::vector<int> l) {\n    size_t n = l.size();\n    std::vector<int> result(n);\n\n    vint32m1_t v_input = __riscv_vle32_v_i32m1(l.data(), n);\n    vint32m1_t v_one = __riscv_vmv_v_x_i32m1(1, n);\n    vint32m1_t v_result = __riscv_vadd_vv_i32m1(v_input, v_one, n);\n\n    __riscv_vse32_v_i32m1(result.data(), v_result, n);\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_84_RVV", "completion": "```c++\nbool pairs_sum_to_zero_simd(std::vector<int> l) {\n    size_t n = l.size();\n    if (n < 2) return false;\n\n    size_t vl = __riscv_vsetvl_e32m1(n);\n    vint32m1_t v = __riscv_vle32_v_i32m1(l.data(), vl);\n\n    for (size_t i = 0; i < n; ++i) {\n        vint32m1_t vi = __riscv_vle32_v_i32m1(l.data() + i, vl);\n        vint32m1_t neg_vi = __riscv_vneg_v_i32m1(vi, vl);\n        vint32m1_t mask = __riscv_vmsne_vv_i32m1_b32(v, neg_vi, vl);\n        vint32m1_t result = __riscv_vand_vv_i32m1_m(mask, v, v, vl);\n\n        if (__riscv_vfirst_m_b32(mask, vl) != -1) {\n            return true;\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_84_RVV", "completion": "```c++\nbool pairs_sum_to_zero_simd(std::vector<int> l) {\n    size_t n = l.size();\n    if (n < 2) return false;\n\n    size_t vl = __riscv_vsetvl_e32m1(n);\n    vint32m1_t v = __riscv_vle32_v_i32m1(l.data(), vl);\n\n    for (size_t i = 0; i < n; ++i) {\n        vint32m1_t vi = __riscv_vle32_v_i32m1(l.data() + i, vl);\n        vint32m1_t neg_vi = __riscv_vneg_v_i32m1(vi, vl);\n        vint32m1_t sum = __riscv_vadd_vv_i32m1(v, neg_vi, vl);\n        vbool32_t mask = __riscv_vmseq_vx_i32m1_b32(sum, 0, vl);\n        if (__riscv_vfirst_m_b32(mask, vl) != -1) {\n            return true;\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_84_RVV", "completion": "```c++\nbool pairs_sum_to_zero_simd(std::vector<int> l) {\n    size_t n = l.size();\n    if (n < 2) return false;\n\n    size_t vl = __riscv_vsetvl_e32m1(n);\n    vint32m1_t v = __riscv_vle32_v_i32m1(l.data(), vl);\n\n    for (size_t i = 0; i < n; ++i) {\n        vint32m1_t vi = __riscv_vle32_v_i32m1(l.data() + i, vl);\n        vint32m1_t neg_vi = __riscv_vneg_v_i32m1(vi, vl);\n        vint32m1_t sum = __riscv_vadd_vv_i32m1(v, neg_vi, vl);\n        vbool32_t mask = __riscv_vmseq_vx_i32m1_b32(sum, 0, vl);\n        if (__riscv_vfirst_m_b32(mask, vl) != -1) {\n            return true;\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_84_RVV", "completion": "```c++\nbool pairs_sum_to_zero_simd(std::vector<int> l) {\n    size_t n = l.size();\n    if (n < 2) return false;\n\n    size_t vl = __riscv_vsetvl_e32m1(n);\n    vint32m1_t v = __riscv_vle32_v_i32m1(l.data(), vl);\n\n    for (size_t i = 0; i < n; ++i) {\n        vint32m1_t vi = __riscv_vle32_v_i32m1(l.data() + i, vl);\n        vint32m1_t neg_vi = __riscv_vneg_v_i32m1(vi, vl);\n        vint32m1_t result = __riscv_vand_mm_b32(__riscv_vmsne_vv_i32m1_b32(v, neg_vi, vl), __riscv_vmsne_vv_i32m1_b32(v, vi, vl), vl);\n\n        if (__riscv_vfirst_m_b32(result, vl) != -1) {\n            return true;\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_84_RVV", "completion": "```c++\nbool pairs_sum_to_zero_simd(std::vector<int> l) {\n    size_t n = l.size();\n    if (n < 2) return false;\n\n    size_t vl = __riscv_vsetvl_e32m1(n);\n    vint32m1_t v = __riscv_vle32_v_i32m1(l.data(), vl);\n\n    for (size_t i = 0; i < n; ++i) {\n        vint32m1_t vi = __riscv_vle32_v_i32m1(l.data() + i, vl);\n        vint32m1_t neg_vi = __riscv_vneg_v_i32m1(vi, vl);\n        vint32m1_t sum = __riscv_vadd_vv_i32m1(v, neg_vi, vl);\n        vbool32_t mask = __riscv_vmseq_vx_i32m1_b32(sum, 0, vl);\n        if (__riscv_vfirst_m_b32(mask, vl) != -1) {\n            return true;\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_85_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nstd::string change_base_simd(int64_t x, int8_t base) {\n    std::string result;\n    vint8m1_t vbase = __riscv_vmv_v_x_i8m1(base, 1);\n    vint64m1_t vx = __riscv_vmv_v_x_i64m1(x, 1);\n\n    while (__riscv_vmv_x_s_i64m1_i64(vx) != 0) {\n        vint64m1_t vrem = __riscv_vrem_vv_i64m1(vx, vbase, 1);\n        vint64m1_t vquot = __riscv_vdiv_vv_i64m1(vx, vbase, 1);\n        char digit = '0' + __riscv_vmv_x_s_i64m1_i64(vrem);\n        result = digit + result;\n        vx = vquot;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_85_RVV", "completion": "```c++\n#include <riscv_vector.h>\n#include <string>\n\nstd::string change_base_simd(int64_t x, int8_t base) {\n    std::string result;\n    vint64m1_t vx = __riscv_vmv_v_x_i64m1(1, x);\n    vint8m1_t vbase = __riscv_vmv_v_x_i8m1(1, base);\n    vint64m1_t vrem = __riscv_vmv_v_x_i64m1(1, 0);\n    vint64m1_t vquot = __riscv_vmv_v_x_i64m1(1, 0);\n\n    while (__riscv_vreduc_max_u64m1_i64m1(vx, 1) > 0) {\n        vrem = __riscv_vrem_vv_i64m1(vx, vbase, 1);\n        vquot = __riscv_vdiv_vv_i64m1(vx, vbase, 1);\n        result = std::to_string(__riscv_vmv_x_s_i64m1_i64(vrem)) + result;\n        vx = vquot;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_85_RVV", "completion": "```c++\n#include <riscv_vector.h>\n#include <string>\n\nstd::string change_base_simd(int64_t x, int8_t base) {\n    std::string result;\n    vint64m1_t vx = __riscv_vmv_v_x_i64m1(0, x, 1);\n    vint64m1_t vbase = __riscv_vmv_v_x_i64m1(0, base, 1);\n    vint64m1_t vremainder;\n    vint64m1_t vquotient;\n\n    while (__riscv_vmv_x_s_i64m1_i64(vx, 0) != 0) {\n        vremainder = __riscv_vrem_vv_i64m1(vx, vbase, 1);\n        vquotient = __riscv_vdiv_vv_i64m1(vx, vbase, 1);\n        result.insert(result.begin(), '0' + __riscv_vmv_x_s_i64m1_i64(vremainder, 0));\n        vx = vquotient;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_85_RVV", "completion": "```c++\n#include <riscv_vector.h>\n#include <string>\n\nstd::string change_base_simd(int64_t x, int8_t base) {\n    std::string result;\n    vint64m1_t vx = __riscv_vmv_v_x_i64m1(1, x);\n    vint64m1_t vbase = __riscv_vmv_v_x_i64m1(1, base);\n    vint64m1_t vrem = __riscv_vmv_v_x_i64m1(1, 0);\n    vint64m1_t vquot = __riscv_vmv_v_x_i64m1(1, 0);\n\n    while (__riscv_vreduc_sum_vs_i64m1_i64m1(vx, 0, vbase) != 0) {\n        vrem = __riscv_vrem_vv_i64m1(vx, vbase, 1);\n        vquot = __riscv_vdiv_vv_i64m1(vx, vbase, 1);\n        result = std::to_string(__riscv_vmv_x_s_i64m1_i64(vrem)) + result;\n        vx = vquot;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_85_RVV", "completion": "```c++\n#include <riscv_vector.h>\n#include <string>\n\nstd::string change_base_simd(int64_t x, int8_t base) {\n    std::string result;\n    vint64m1_t vx = __riscv_vmv_v_x_i64m1(1, x);\n    vint8m1_t vbase = __riscv_vmv_v_x_i8m1(1, base);\n    vint64m1_t vrem = __riscv_vmv_v_x_i64m1(1, 0);\n    vint64m1_t vquot = __riscv_vmv_v_x_i64m1(1, 0);\n\n    while (__riscv_vreduc_max_u64m1_i64m1(vx, 1) > 0) {\n        vrem = __riscv_vrem_vv_i64m1(vx, vbase, 1);\n        vquot = __riscv_vdiv_vv_i64m1(vx, vbase, 1);\n        result = std::to_string(__riscv_vmv_x_s_i64m1_i64(vrem)) + result;\n        vx = vquot;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_86_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nbool is_palindrome_simd(std::string text) {\n    size_t len = text.length();\n    if (len == 0) return true;\n\n    size_t vl = __riscv_vsetvl_e8m8(len / 2);\n    vuint8m8_t v1 = __riscv_vle8_v_u8m8((const uint8_t*)text.c_str(), vl);\n    vuint8m8_t v2 = __riscv_vle8_v_u8m8((const uint8_t*)(text.c_str() + len - 1), vl);\n\n    vuint8m8_t v3 = __riscv_vrevg_v_u8m8(v2, vl);\n    vuint8m8_t v4 = __riscv_vmsne_vv_u8m8_b8(v1, v3, vl);\n\n    bool result = __riscv_vmv_x_s_b8(__riscv_vfirst_m_b8(v4, vl));\n    return !result;\n}\n```"}
{"task_id": "SimdBench_86_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nbool is_palindrome_simd(std::string text) {\n    size_t len = text.size();\n    if (len == 0) return true;\n\n    size_t vl = __riscv_vsetvl_e8m1(len);\n    vuint8m1_t vec1 = __riscv_vle8_v_u8m1((const uint8_t*)text.c_str(), vl);\n    vuint8m1_t vec2 = __riscv_vle8_v_u8m1((const uint8_t*)(text.c_str() + len - 1), vl);\n\n    vuint8m1_t mask = __riscv_vmsne_vx_u8m1_b8(vec1, vec2, vl);\n    bool result = __riscv_vcpop_m(mask, vl) == 0;\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_86_RVV", "completion": "```c++\nbool is_palindrome_simd(std::string text) {\n    size_t len = text.length();\n    if (len == 0) return true;\n\n    size_t vl = __riscv_vsetvl_e8m1(len);\n    vuint8m1_t v_text = __riscv_vle8_v_u8m1((const uint8_t*)text.c_str(), vl);\n    vuint8m1_t v_rev_text = __riscv_vrevg_v_u8m1(v_text, vl);\n\n    vuint8m1_t v_cmp = __riscv_vmsne_vv_u8m1_b8(v_text, v_rev_text, vl);\n    bool result = __riscv_vfirst_m_b8(v_cmp, vl) < 0;\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_86_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nbool is_palindrome_simd(std::string text) {\n    size_t len = text.length();\n    if (len == 0) return true;\n\n    size_t vl = __riscv_vsetvl_e8m1(len);\n    vuint8m1_t vec1 = __riscv_vle8_v_u8m1((const uint8_t*)text.c_str(), vl);\n    vuint8m1_t vec2 = __riscv_vle8_v_u8m1((const uint8_t*)(text.c_str() + len - 1), vl);\n\n    vuint8m1_t mask = __riscv_vmsne_vx_u8m1_b8(vec1, vec2, vl);\n    bool result = __riscv_vfirst_m_b8(mask, vl) < 0;\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_86_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nbool is_palindrome_simd(std::string text) {\n    size_t len = text.length();\n    if (len == 0) return true;\n\n    size_t vl = __riscv_vsetvl_e8m1(len);\n    vuint8m1_t vec1 = __riscv_vle8_v_u8m1((uint8_t*)text.c_str(), vl);\n    vuint8m1_t vec2 = __riscv_vle8_v_u8m1((uint8_t*)(text.c_str() + len - 1), vl);\n\n    vuint8m1_t eq = __riscv_vmseq_vv_u8m1_b8(vec1, vec2, vl);\n    bool all_equal = __riscv_vmv_x_s_b8(__riscv_vmand_mm_b8(eq, eq, vl));\n\n    return all_equal;\n}\n```"}
{"task_id": "SimdBench_87_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nstd::string decode_shift_simd(std::string s) {\n    size_t len = s.length();\n    size_t vl = vsetvl_e8m8(len);\n\n    vuint8m8_t v_input = vle8_v_u8m8((const uint8_t*)s.data(), vl);\n    vuint8m8_t v_shift = vadd_vx_u8m8(v_input, -5, vl);\n    vuint8m8_t v_base = vadd_vx_u8m8(v_shift, (int)'a', vl);\n    vuint8m8_t v_mod = vrem_vx_u8m8(v_base, 26, vl);\n    vuint8m8_t v_result = vadd_vx_u8m8(v_mod, (int)'a', vl);\n\n    std::string out(len, '\\0');\n    vse8_v_u8m8((uint8_t*)out.data(), v_result, vl);\n\n    return out;\n}\n```"}
{"task_id": "SimdBench_87_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nstd::string decode_shift_simd(std::string s) {\n    size_t len = s.length();\n    size_t vl = vsetvl_e8m8(len);\n\n    vint8m8_t v_input = vle8_v_i8m8((int8_t*)s.data(), vl);\n    vint8m8_t v_shift = vadd_vx_i8m8(v_input, -5, vl);\n    vint8m8_t v_base = vadd_vx_i8m8(v_input, -'a', vl);\n    vint8m8_t v_mod = vrem_vx_i8m8(v_base, 26, vl);\n    vint8m8_t v_result = vadd_vx_i8m8(v_mod, 'a', vl);\n\n    std::string out(len, '\\0');\n    vse8_v_i8m8((int8_t*)out.data(), v_result, vl);\n\n    return out;\n}\n```"}
{"task_id": "SimdBench_87_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nstd::string decode_shift_simd(std::string s) {\n    size_t len = s.length();\n    size_t vl = vsetvl_e8m8(len);\n\n    vuint8m8_t v_input = vle8_v_u8m8((const uint8_t*)s.data(), vl);\n    vuint8m8_t v_shift = vadd_vx_u8m8(v_input, -5, vl);\n    vuint8m8_t v_base = vadd_vx_u8m8(v_shift, (int)'a', vl);\n    vuint8m8_t v_mod = vrem_vx_u8m8(v_base, 26, vl);\n    vuint8m8_t v_result = vadd_vx_u8m8(v_mod, (int)'a', vl);\n\n    std::string out(len, '\\0');\n    vse8_v_u8m8((uint8_t*)out.data(), v_result, vl);\n\n    return out;\n}\n```"}
{"task_id": "SimdBench_87_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nstd::string decode_shift_simd(std::string s) {\n    size_t len = s.length();\n    std::string out(len, ' ');\n\n    size_t vl = __riscv_vsetvl_e8m8(len);\n    vuint8m8_t v_a = __riscv_vle8_v_u8m8((const int8_t*)s.c_str(), vl);\n    vuint8m8_t v_shift = __riscv_vmv_v_x_u8m8(5, vl);\n    vuint8m8_t v_base = __riscv_vmv_v_x_u8m8('a', vl);\n    vuint8m8_t v_mod = __riscv_vmv_v_x_u8m8(26, vl);\n\n    vuint8m8_t v_decoded = __riscv_vsub_vv_u8m8(v_a, v_shift, vl);\n    v_decoded = __riscv_vsub_vv_u8m8(v_decoded, v_base, vl);\n    v_decoded = __riscv_vrem_vv_u8m8(v_decoded, v_mod, vl);\n    v_decoded = __riscv_vadd_vv_u8m8(v_decoded, v_base, vl);\n\n    __riscv_vse8_v_u8m8((int8_t*)out.data(), v_decoded, vl);\n\n    return out;\n}\n```"}
{"task_id": "SimdBench_87_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nstd::string decode_shift_simd(std::string s) {\n    size_t len = s.length();\n    std::string out(len, ' ');\n\n    size_t vl = __riscv_vsetvl_e8m1(len);\n    vuint8m1_t v_s = __riscv_vle8_v_u8m1((const uint8_t*)s.data(), vl);\n    vuint8m1_t v_a = __riscv_vmv_v_x_u8m1('a', vl);\n    vuint8m1_t v_26 = __riscv_vmv_v_x_u8m1(26, vl);\n    vuint8m1_t v_5 = __riscv_vmv_v_x_u8m1(5, vl);\n\n    vuint8m1_t v_w = __riscv_vsub_vv_u8m1(v_s, v_5, vl);\n    v_w = __riscv_vsub_vv_u8m1(v_w, v_a, vl);\n    v_w = __riscv_vrem_vv_u8m1(v_w, v_26, vl);\n    v_w = __riscv_vadd_vv_u8m1(v_w, v_a, vl);\n\n    __riscv_vse8_v_u8m1((uint8_t*)out.data(), v_w, vl);\n\n    return out;\n}\n```"}
{"task_id": "SimdBench_88_RVV", "completion": "```cpp\nbool below_threshold_simd(std::vector<int> l, int t) {\n    size_t n = l.size();\n    vint32m1_t v = __riscv_vle32_v_i32m1(l.data(), n);\n    vint32m1_t threshold = __riscv_vmv_v_x_i32m1(t, n);\n    vuint1m1_t mask = __riscv_vmslt_vv_i32m1_b32(v, threshold, n);\n    return __riscv_vcpop_m(mask, n) == n;\n}\n```"}
{"task_id": "SimdBench_88_RVV", "completion": "```cpp\nbool below_threshold_simd(std::vector<int> l, int t) {\n    size_t n = l.size();\n    vint32m1_t v_threshold = __riscv_vmv_v_x_i32m1(t, n);\n    vint32m1_t v_data = __riscv_vle32_v_i32m1(l.data(), n);\n    vuint1_t v_result = __riscv_vmslt_vv_i32m1_b1(v_data, v_threshold, n);\n    return __riscv_vmv_x_s_u1(__riscv_vmand_mm_b1(v_result, n));\n}\n```"}
{"task_id": "SimdBench_88_RVV", "completion": "```c++\nbool below_threshold_simd(std::vector<int> l, int t) {\n    size_t n = l.size();\n    vint32m1_t v_threshold = __riscv_vmv_v_x_i32m1(t, n);\n    vint32m1_t v_data = __riscv_vle32_v_i32m1(l.data(), n);\n    vuint1_t v_mask = __riscv_vmslt_vv_u32m1_b32(v_data, v_threshold, n);\n    bool result = __riscv_vmv_x_s_u32m1_u32(v_mask);\n    return result;\n}\n```"}
{"task_id": "SimdBench_88_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n\nbool below_threshold_simd(std::vector<int> l, int t) {\n    size_t n = l.size();\n    vint32m1_t v_threshold = __riscv_vmv_v_x_i32m1(t, n);\n    vint32m1_t v_data = __riscv_vle32_v_i32m1(l.data(), n);\n    vuint1_t v_mask = __riscv_vmslt_vv_i32m1_b32(v_data, v_threshold, n);\n    return __riscv_vcpop_m_b32(v_mask, n) == n;\n}\n```"}
{"task_id": "SimdBench_88_RVV", "completion": "```cpp\nbool below_threshold_simd(std::vector<int> l, int t) {\n    size_t n = l.size();\n    vint32m1_t v_threshold = __riscv_vmv_v_x_i32m1(t, n);\n    vint32m1_t v_data = __riscv_vle32_v_i32m1(l.data(), n);\n    vuint1_t v_result = __riscv_vmslt_vv_i32m1_b1(v_data, v_threshold, n);\n    return __riscv_vmv_x_s_u1(__riscv_vmand_mm_b1(v_result, n));\n}\n```"}
{"task_id": "SimdBench_89_RVV", "completion": "```c++\nbool correct_bracketing_simd(std::string brackets) {\n    size_t len = brackets.size();\n    if (len % 2 != 0) return false;\n\n    size_t vl = vsetvl_e8m1(len);\n    vint8m1_t v_brackets = vle8_v_i8m1((int8_t*)brackets.data(), vl);\n\n    vint8m1_t v_open = vmv_v_x_i8m1('<', vl);\n    vint8m1_t v_close = vmv_v_x_i8m1('>', vl);\n\n    vint8m1_t v_open_mask = vmseq_vv_i8m1_b8(v_brackets, v_open, vl);\n    vint8m1_t v_close_mask = vmseq_vv_i8m1_b8(v_brackets, v_close, vl);\n\n    int open_count = vpopc_m_b8(v_open_mask, vl);\n    int close_count = vpopc_m_b8(v_close_mask, vl);\n\n    if (open_count != close_count) return false;\n\n    int balance = 0;\n    for (size_t i = 0; i < len; ++i) {\n        if (brackets[i] == '<') {\n            balance++;\n        } else {\n            balance--;\n        }\n        if (balance < 0) return false;\n    }\n\n    return balance == 0;\n}\n```"}
{"task_id": "SimdBench_89_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nbool correct_bracketing_simd(std::string brackets) {\n    size_t len = brackets.size();\n    if (len % 8 != 0) {\n        return false;\n    }\n\n    vint8m1_t v_open = __riscv_vmv_v_x_i8m1(0, '<');\n    vint8m1_t v_close = __riscv_vmv_v_x_i8m1(0, '>');\n    vint8m1_t v_brackets = __riscv_vle8_v_i8m1((int8_t*)brackets.data(), len);\n\n    vint8m1_t v_open_count = __riscv_vmv_v_x_i8m1(0, 0);\n    vint8m1_t v_close_count = __riscv_vmv_v_x_i8m1(0, 0);\n\n    for (size_t i = 0; i < len; i += 8) {\n        vint8m1_t v_chunk = __riscv_vle8_v_i8m1((int8_t*)brackets.data() + i, 8);\n        vint8m1_t v_open_mask = __riscv_vmseq_vv_i8m1_b8(v_chunk, v_open, 8);\n        vint8m1_t v_close_mask = __riscv_vmseq_vv_i8m1_b8(v_chunk, v_close, 8);\n\n        v_open_count = __riscv_vadd_vv_i8m1(v_open_count, __riscv_vmv_v_v_i8m1(v_open_mask, 8), 8);\n        v_close_count = __riscv_vadd_vv_i8m1(v_close_count, __riscv_vmv_v_v_i8m1(v_close_mask, 8), 8);\n    }\n\n    int open_count = __riscv_vmv_x_s_i8m1_i8(__riscv_vredsum_vs_i8m1_i8(v_open_count, 0, 8));\n    int close_count = __riscv_vmv_x_s_i8m1_i8(__riscv_vredsum_vs_i8m1_i8(v_close_count, 0, 8));\n\n    return open_count == close_count;\n}\n```"}
{"task_id": "SimdBench_89_RVV", "completion": "```c++\nbool correct_bracketing_simd(std::string brackets) {\n    size_t len = brackets.size();\n    if (len % 2 != 0) return false;\n\n    size_t vl = vsetvl_e8m1(len);\n    vint8m1_t v_brackets = vle8_v_i8m1((int8_t*)brackets.data(), vl);\n\n    vint8m1_t v_open = vmv_v_x_i8m1('<', vl);\n    vint8m1_t v_close = vmv_v_x_i8m1('>', vl);\n\n    vint8m1_t v_open_mask = vmseq_vv_i8m1_b8(v_brackets, v_open, vl);\n    vint8m1_t v_close_mask = vmseq_vv_i8m1_b8(v_brackets, v_close, vl);\n\n    int open_count = vpopc_m_b8(v_open_mask, vl);\n    int close_count = vpopc_m_b8(v_close_mask, vl);\n\n    if (open_count != close_count) return false;\n\n    int balance = 0;\n    for (size_t i = 0; i < len; ++i) {\n        if (brackets[i] == '<') ++balance;\n        else --balance;\n        if (balance < 0) return false;\n    }\n\n    return balance == 0;\n}\n```"}
{"task_id": "SimdBench_89_RVV", "completion": "```c++\nbool correct_bracketing_simd(std::string brackets) {\n    size_t len = brackets.size();\n    if (len % 2 != 0) return false;\n\n    size_t vl = vsetvl_e8m1(len);\n    vint8m1_t v_brackets = vle8_v_i8m1((int8_t*)brackets.data(), vl);\n\n    vint8m1_t v_open = vmv_v_x_i8m1('<', vl);\n    vint8m1_t v_close = vmv_v_x_i8m1('>', vl);\n\n    vint8m1_t v_open_mask = vmseq_vv_i8m1_b8(v_brackets, v_open, vl);\n    vint8m1_t v_close_mask = vmseq_vv_i8m1_b8(v_brackets, v_close, vl);\n\n    int open_count = vpopc_m_b8(v_open_mask, vl);\n    int close_count = vpopc_m_b8(v_close_mask, vl);\n\n    if (open_count != close_count) return false;\n\n    int balance = 0;\n    for (size_t i = 0; i < len; ++i) {\n        if (brackets[i] == '<') {\n            balance++;\n        } else {\n            balance--;\n        }\n        if (balance < 0) return false;\n    }\n\n    return balance == 0;\n}\n```"}
{"task_id": "SimdBench_89_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nbool correct_bracketing_simd(std::string brackets) {\n    size_t len = brackets.size();\n    if (len % 8 != 0) {\n        return false;\n    }\n\n    vint8m1_t v_open = __riscv_vmv_v_x_i8m1(1, '<');\n    vint8m1_t v_close = __riscv_vmv_v_x_i8m1(1, '>');\n    vint8m1_t v_brackets = __riscv_vle8_v_i8m1(brackets.data(), len);\n\n    vint8m1_t v_open_count = __riscv_vmv_v_x_i8m1(0, 0);\n    vint8m1_t v_close_count = __riscv_vmv_v_x_i8m1(0, 0);\n\n    for (size_t i = 0; i < len; i += 8) {\n        vint8m1_t v_chunk = __riscv_vle8_v_i8m1(brackets.data() + i, 8);\n        vint8m1_t v_open_mask = __riscv_vmseq_vv_i8m1_b8(v_chunk, v_open, 8);\n        vint8m1_t v_close_mask = __riscv_vmseq_vv_i8m1_b8(v_chunk, v_close, 8);\n\n        v_open_count = __riscv_vadd_vv_i8m1(v_open_count, __riscv_vcpop_m_b8(v_open_mask, 8), 8);\n        v_close_count = __riscv_vadd_vv_i8m1(v_close_count, __riscv_vcpop_m_b8(v_close_mask, 8), 8);\n    }\n\n    int open_count = __riscv_vredsum_vs_i8m1_i32m1(v_open_count, 0, 8);\n    int close_count = __riscv_vredsum_vs_i8m1_i32m1(v_close_count, 0, 8);\n\n    return open_count == close_count;\n}\n```"}
{"task_id": "SimdBench_90_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nbool correct_bracketing_simd(std::string brackets) {\n    size_t len = brackets.size();\n    if (len % 2 != 0) return false;\n\n    size_t vl = __riscv_vsetvl_e8m1(len);\n    vint8m1_t v_brackets = __riscv_vle8_v_i8m1((int8_t*)brackets.data(), vl);\n\n    vint8m1_t v_open = __riscv_vmv_v_x_i8m1('(', vl);\n    vint8m1_t v_close = __riscv_vmv_v_x_i8m1(')', vl);\n\n    vint8m1_t v_open_mask = __riscv_vmseq_vv_i8m1_b8(v_brackets, v_open, vl);\n    vint8m1_t v_close_mask = __riscv_vmseq_vv_i8m1_b8(v_brackets, v_close, vl);\n\n    int open_count = __riscv_vcpop_m_b8(v_open_mask, vl);\n    int close_count = __riscv_vcpop_m_b8(v_close_mask, vl);\n\n    if (open_count != close_count) return false;\n\n    int balance = 0;\n    for (size_t i = 0; i < len; ++i) {\n        if (brackets[i] == '(') {\n            balance++;\n        } else {\n            balance--;\n        }\n        if (balance < 0) return false;\n    }\n\n    return balance == 0;\n}\n```"}
{"task_id": "SimdBench_90_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nbool correct_bracketing_simd(std::string brackets) {\n    size_t len = brackets.size();\n    if (len % 2 != 0) return false;\n\n    size_t vl = __riscv_vsetvl_e8m1(len);\n    vint8m1_t v_brackets = __riscv_vle8_v_i8m1((int8_t*)brackets.data(), vl);\n\n    vint8m1_t v_open = __riscv_vmv_v_x_i8m1('(', vl);\n    vint8m1_t v_close = __riscv_vmv_v_x_i8m1(')', vl);\n\n    vint8m1_t v_open_mask = __riscv_vmseq_vv_i8m1_b8(v_brackets, v_open, vl);\n    vint8m1_t v_close_mask = __riscv_vmseq_vv_i8m1_b8(v_brackets, v_close, vl);\n\n    int open_count = __riscv_vcpop_m_b8(v_open_mask, vl);\n    int close_count = __riscv_vcpop_m_b8(v_close_mask, vl);\n\n    if (open_count != close_count) return false;\n\n    int balance = 0;\n    for (size_t i = 0; i < len; ++i) {\n        if (brackets[i] == '(') {\n            balance++;\n        } else {\n            balance--;\n        }\n        if (balance < 0) return false;\n    }\n\n    return balance == 0;\n}\n```"}
{"task_id": "SimdBench_90_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nbool correct_bracketing_simd(std::string brackets) {\n    size_t len = brackets.size();\n    if (len == 0) return true;\n\n    int32_t *data = new int32_t[len];\n    for (size_t i = 0; i < len; ++i) {\n        data[i] = (brackets[i] == '(') ? 1 : -1;\n    }\n\n    size_t vl = __riscv_vsetvl_e32m1(len);\n    vint32m1_t v_data = __riscv_vle32_v_i32m1(data, vl);\n\n    vint32m1_t v_sum = __riscv_vmv_v_x_i32m1(0, vl);\n    vint32m1_t v_accum = __riscv_vmv_v_x_i32m1(0, vl);\n\n    for (size_t i = 0; i < len; i += vl) {\n        vl = __riscv_vsetvl_e32m1(len - i);\n        v_data = __riscv_vle32_v_i32m1(data + i, vl);\n        v_accum = __riscv_vredsum_vs_i32m1_i32m1(v_accum, v_data, v_sum, vl);\n    }\n\n    int32_t sum = __riscv_vmv_x_s_i32m1_i32(v_accum);\n\n    delete[] data;\n    return sum == 0;\n}\n```"}
{"task_id": "SimdBench_90_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nbool correct_bracketing_simd(std::string brackets) {\n    size_t len = brackets.size();\n    if (len % 2 != 0) return false;\n\n    size_t vl = __riscv_vsetvl_e8m1(len);\n    vint8m1_t v_brackets = __riscv_vle8_v_i8m1((int8_t*)brackets.data(), vl);\n\n    vint8m1_t v_open = __riscv_vmv_v_x_i8m1('(', vl);\n    vint8m1_t v_close = __riscv_vmv_v_x_i8m1(')', vl);\n\n    vint8m1_t v_open_mask = __riscv_vmseq_vv_i8m1_b8(v_brackets, v_open, vl);\n    vint8m1_t v_close_mask = __riscv_vmseq_vv_i8m1_b8(v_brackets, v_close, vl);\n\n    int open_count = __riscv_vcpop_m_b8(v_open_mask, vl);\n    int close_count = __riscv_vcpop_m_b8(v_close_mask, vl);\n\n    if (open_count != close_count) return false;\n\n    int balance = 0;\n    for (size_t i = 0; i < len; ++i) {\n        if (brackets[i] == '(') {\n            balance++;\n        } else {\n            balance--;\n        }\n        if (balance < 0) return false;\n    }\n\n    return balance == 0;\n}\n```"}
{"task_id": "SimdBench_90_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nbool correct_bracketing_simd(std::string brackets) {\n    size_t len = brackets.length();\n    if (len % 2 != 0) return false;\n\n    size_t vl = __riscv_vsetvl_e8m1(len);\n    vint8m1_t v_brackets = __riscv_vle8_v_i8m1((int8_t*)brackets.data(), vl);\n\n    vint8m1_t v_open = __riscv_vmv_v_x_i8m1('(', vl);\n    vint8m1_t v_close = __riscv_vmv_v_x_i8m1(')', vl);\n\n    vint8m1_t v_open_mask = __riscv_vmseq_vv_i8m1_b8(v_brackets, v_open, vl);\n    vint8m1_t v_close_mask = __riscv_vmseq_vv_i8m1_b8(v_brackets, v_close, vl);\n\n    int open_count = __riscv_vcpop_m_b8(v_open_mask, vl);\n    int close_count = __riscv_vcpop_m_b8(v_close_mask, vl);\n\n    if (open_count != close_count) return false;\n\n    int balance = 0;\n    for (size_t i = 0; i < len; ++i) {\n        if (brackets[i] == '(') {\n            balance++;\n        } else {\n            balance--;\n        }\n        if (balance < 0) return false;\n    }\n\n    return balance == 0;\n}\n```"}
{"task_id": "SimdBench_91_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<float> derivative_simd(std::vector<float> xs) {\n    size_t n = xs.size();\n    if (n <= 1) return {};\n\n    std::vector<float> result(n - 1);\n    size_t vl = __riscv_vsetvl_e32m1(n - 1);\n\n    vint32m1_t vindex = __riscv_vid_v_i32m1(vl, 1);\n    vfloat32m1_t vcoeffs = __riscv_vle32_v_f32m1(&xs[1], vl);\n    vfloat32m1_t vresult = __riscv_vmul_vv_f32m1(vcoeffs, __riscv_vfcvt_f_x_v_f32m1(vindex, vl), vl);\n\n    __riscv_vse32_v_f32m1(&result[0], vresult, vl);\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_91_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<float> derivative_simd(std::vector<float> xs) {\n    size_t n = xs.size();\n    if (n <= 1) return {};\n\n    std::vector<float> result(n - 1);\n    size_t vl = vsetvl_e32m1(n - 1);\n\n    vfloat32m1_t v_xs = vle32_v_f32m1(xs.data(), vl);\n    vfloat32m1_t v_indices = vid_v_f32m1(vl);\n\n    vfloat32m1_t v_deriv = vmul_vv_f32m1(v_xs, v_indices, vl);\n\n    vse32_v_f32m1(result.data(), v_deriv, vl);\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_91_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<float> derivative_simd(std::vector<float> xs) {\n    size_t n = xs.size();\n    if (n <= 1) return {};\n\n    std::vector<float> result(n - 1);\n    size_t vl = vsetvl_e32m1(n - 1);\n\n    vfloat32m1_t v_xs = vle32_v_f32m1(&xs[1], vl);\n    vint32m1_t v_indices = vid_v_i32m1(1, vl);\n    vfloat32m1_t v_mult = vwmul_vv_f32m1(v_xs, v_indices, vl);\n\n    vse32_v_f32m1(&result[0], v_mult, vl);\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_91_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<float> derivative_simd(std::vector<float> xs) {\n    size_t n = xs.size();\n    if (n <= 1) return {};\n\n    std::vector<float> result(n - 1);\n    size_t vl = __riscv_vsetvl_e32m1(n - 1);\n\n    vint32m1_t vindex = __riscv_vid_v_i32m1(vl, 1);\n    vfloat32m1_t vcoeffs = __riscv_vle32_v_f32m1(&xs[1], vl);\n    vfloat32m1_t vresult = __riscv_vmul_vv_f32m1(vcoeffs, __riscv_vfcvt_f_x_v_f32m1(vindex, vl), vl);\n\n    __riscv_vse32_v_f32m1(&result[0], vresult, vl);\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_91_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<float> derivative_simd(std::vector<float> xs) {\n    size_t n = xs.size();\n    if (n <= 1) return {};\n\n    std::vector<float> result(n - 1);\n    size_t vl = __riscv_vsetvl_e32m1(n - 1);\n\n    vint32m1_t indices = __riscv_vid_v_i32m1(vl, 1);\n    vfloat32m1_t coeffs = __riscv_vle32_v_f32m1(xs.data() + 1, vl);\n    vfloat32m1_t scaled_coeffs = __riscv_vfmv_v_f_f32m1(indices, vl);\n    vfloat32m1_t derivative = __riscv_vfmul_vv_f32m1(coeffs, scaled_coeffs, vl);\n\n    __riscv_vse32_v_f32m1(result.data(), derivative, vl);\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_92_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nint vowels_count_simd(std::string s) {\n    size_t len = s.length();\n    if (len == 0) return 0;\n\n    size_t vl = vsetvl_e8m8(len);\n    vuint8m8_t v_vowels = vle8_v_u8m8((const uint8_t*)\"aeiouy\", vl);\n    vuint8m8_t v_word = vle8_v_u8m8((const uint8_t*)s.c_str(), vl);\n\n    vuint8m8_t v_mask = vmseq_vv_u8m8_b8(v_word, v_vowels, vl);\n    int count = vpopc_m_b8(v_mask, vl);\n\n    if (s.back() == 'y') {\n        count++;\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_92_RVV", "completion": "```c++\nint vowels_count_simd(std::string s) {\n    size_t len = s.length();\n    int count = 0;\n\n    // Define the vector of vowels\n    const char vowels[] = {'a', 'e', 'i', 'o', 'u', 'y'};\n    size_t vlen = sizeof(vowels) / sizeof(vowels[0]);\n\n    // Create a vector mask for vowels\n    vuint8m1_t v_vowels = __riscv_vle8_v_u8m1(vowels, vlen, vlen);\n\n    // Process the string in chunks\n    for (size_t i = 0; i < len; i += vlen) {\n        size_t chunk_size = std::min(vlen, len - i);\n        vuint8m1_t v_chunk = __riscv_vle8_v_u8m1(s.data() + i, chunk_size, vlen);\n\n        // Convert to lowercase for case-insensitive comparison\n        v_chunk = __riscv_vadd_vx_u8m1(v_chunk, 32, vlen);\n\n        // Compare each character in the chunk with the vowels\n        for (size_t j = 0; j < vlen; ++j) {\n            vuint8m1_t v_mask = __riscv_vmseq_vx_u8m1_b8(v_chunk, vowels[j], vlen);\n            count += __riscv_vcpop_m_b8(v_mask, vlen);\n        }\n    }\n\n    // Check if 'y' is at the end of the string\n    if (len > 0 && (s[len - 1] == 'y' || s[len - 1] == 'Y')) {\n        count++;\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_92_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nint vowels_count_simd(std::string s) {\n    size_t len = s.length();\n    if (len == 0) return 0;\n\n    // Define the vowels\n    const char vowels[] = {'a', 'e', 'i', 'o', 'u', 'y'};\n    size_t num_vowels = sizeof(vowels) / sizeof(vowels[0]);\n\n    // Initialize the vector registers\n    vuint8mf8_t v_vowels = __riscv_vle8_v_u8mf8(vowels, num_vowels, 8);\n    vuint8mf8_t v_word = __riscv_vle8_v_u8mf8((const uint8_t*)s.c_str(), len, 8);\n\n    // Convert to lowercase\n    v_word = __riscv_vadd_vx_u8mf8(v_word, 32, 8);\n\n    // Initialize count\n    int count = 0;\n\n    // Check for vowels\n    for (size_t i = 0; i < num_vowels; ++i) {\n        vuint8mf8_t v_match = __riscv_vmsne_vx_u8mf8(v_word, vowels[i], 8);\n        count += __riscv_vcpop_m_u8mf8(v_match, 8);\n    }\n\n    // Check if 'y' is at the end\n    if (s[len - 1] == 'y' || s[len - 1] == 'Y') {\n        count++;\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_92_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nint vowels_count_simd(std::string s) {\n    size_t len = s.length();\n    if (len == 0) return 0;\n\n    // Define the vector of vowels\n    const char vowels[] = {'a', 'e', 'i', 'o', 'u', 'y'};\n    size_t num_vowels = sizeof(vowels) / sizeof(vowels[0]);\n\n    // Initialize the vector registers\n    vuint8mf8_t v_vowels = __riscv_vle8_v_u8mf8(vowels, num_vowels, 8);\n    vuint8mf8_t v_word = __riscv_vle8_v_u8mf8((const uint8_t*)s.c_str(), len, 8);\n\n    // Convert to lowercase for case-insensitive comparison\n    v_word = __riscv_vadd_vx_u8mf8(v_word, 32, 8);\n\n    // Initialize the count\n    int count = 0;\n\n    // Check for vowels in the word\n    for (size_t i = 0; i < len; ++i) {\n        vuint8mf8_t v_match = __riscv_vmsne_vx_u8mf8(v_vowels, v_word[i], 8);\n        if (__riscv_vcpop_m_u8mf8(v_match, 8) > 0) {\n            count++;\n        }\n    }\n\n    // Check if 'y' is at the end of the word\n    if (s[len - 1] == 'y' || s[len - 1] == 'Y') {\n        count++;\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_92_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nint vowels_count_simd(std::string s) {\n    size_t len = s.length();\n    if (len == 0) return 0;\n\n    // Define the vector of vowels\n    const char vowels[] = {'a', 'e', 'i', 'o', 'u', 'y'};\n    size_t num_vowels = sizeof(vowels) / sizeof(vowels[0]);\n\n    // Initialize the count\n    int count = 0;\n\n    // Process the string in chunks\n    size_t vl = __riscv_vsetvl_e8m1(len);\n    for (size_t i = 0; i < len; i += vl) {\n        vl = __riscv_vsetvl_e8m1(len - i);\n\n        // Load the current chunk of the string\n        vuint8m1_t str_chunk = __riscv_vle8_v_u8m1((const uint8_t*)&s[i], vl);\n\n        // Initialize a mask for vowels\n        vuint8m1_t mask = __riscv_vmv_v_x_u8m1(0, vl);\n\n        // Check for each vowel\n        for (size_t j = 0; j < num_vowels; ++j) {\n            vuint8m1_t vowel_vec = __riscv_vmv_v_x_u8m1(vowels[j], vl);\n            vuint8m1_t eq = __riscv_vmseq_vv_u8m1_b8(str_chunk, vowel_vec, vl);\n            mask = __riscv_vmor_mm_b8(mask, eq, vl);\n        }\n\n        // Count the number of vowels in the current chunk\n        count += __riscv_vcpop_m_b8(mask, vl);\n    }\n\n    // Check if 'y' is at the end of the string\n    if (len > 0 && s[len - 1] == 'y') {\n        count++;\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_93_RVV", "completion": "```c++\nint digitSum_simd(std::string s) {\n    size_t len = s.length();\n    int sum = 0;\n\n    if (len == 0) {\n        return 0;\n    }\n\n    size_t vl = __riscv_vsetvl_e8m1(len);\n    vuint8m1_t v_str = __riscv_vle8_v_u8m1((const uint8_t*)s.c_str(), vl);\n    vuint8m1_t v_upper = __riscv_vand_vx_u8m1(v_str, 0xDF, vl);\n    vuint8m1_t v_mask = __riscv_vmslt_vx_u8m1(v_upper, 'A', vl);\n    vuint8m1_t v_mask2 = __riscv_vmsgt_vx_u8m1(v_upper, 'Z', vl);\n    vuint8m1_t v_mask3 = __riscv_vor_vv_u8m1(v_mask, v_mask2, vl);\n    vuint8m1_t v_filtered = __riscv_vmerge_vx_u8m1(v_upper, 0, v_mask3, vl);\n    vint8m1_t v_ascii = __riscv_vreinterpret_v_u8m1_i8m1(v_filtered);\n    vint8m1_t v_sum = __riscv_vredsum_vs_i8m1_i32m1(v_ascii, __riscv_vmv_v_x_i32m1(0, vl), vl);\n\n    sum = __riscv_vmv_x_s_i32m1_i32(v_sum);\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_93_RVV", "completion": "```c++\nint digitSum_simd(std::string s) {\n    size_t len = s.length();\n    int sum = 0;\n\n    if (len == 0) {\n        return 0;\n    }\n\n    size_t vl = __riscv_vsetvl_e8m1(len);\n    vuint8m1_t v_str = __riscv_vle8_v_u8m1((const uint8_t*)s.c_str(), vl);\n\n    vuint8m1_t v_upper = __riscv_vand_vx_u8m1(v_str, 0xDF, vl);\n    vuint8m1_t v_mask = __riscv_vmslt_vx_u8m1(v_upper, 'A', vl);\n    vuint8m1_t v_mask2 = __riscv_vmsgt_vx_u8m1(v_upper, 'Z', vl);\n    vuint8m1_t v_mask3 = __riscv_vor_vv_u8m1(v_mask, v_mask2, vl);\n    vuint8m1_t v_mask4 = __riscv_vnot_v_u8m1(v_mask3, vl);\n\n    vuint8m1_t v_filtered = __riscv_vand_vv_u8m1(v_str, v_mask4, vl);\n    vuint8m1_t v_zero = __riscv_vmv_v_x_u8m1(0, vl);\n    vuint8m1_t v_result = __riscv_vsub_vv_u8m1(v_filtered, v_zero, vl);\n\n    sum = __riscv_vredsum_vs_u8m1_u32m1(v_result, sum, vl);\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_93_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nint digitSum_simd(std::string s) {\n    size_t len = s.length();\n    int sum = 0;\n\n    if (len == 0) {\n        return 0;\n    }\n\n    size_t vl = __riscv_vsetvl_e8m1(len);\n    vuint8m1_t v_input = __riscv_vle8_v_u8m1((const uint8_t*)s.c_str(), vl);\n\n    vuint8m1_t v_upper = __riscv_vand_vx_u8m1(v_input, 0xDF, vl);\n    vuint8m1_t v_mask = __riscv_vmslt_vx_u8m1(v_input, v_upper, vl);\n    vuint8m1_t v_sum = __riscv_vand_vv_u8m1(v_input, v_mask, vl);\n\n    sum = __riscv_vredsum_vs_u8m1_u32m1(v_sum, 0, vl);\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_93_RVV", "completion": "```c++\nint digitSum_simd(std::string s) {\n    size_t len = s.length();\n    int sum = 0;\n\n    if (len == 0) return 0;\n\n    size_t vl = __riscv_vsetvl_e8m1(len);\n    vuint8m1_t v_str = __riscv_vle8_v_u8m1((const uint8_t*)s.c_str(), vl);\n\n    vuint8m1_t v_upper = __riscv_vand_vx_u8m1(v_str, 0xDF, vl);\n    vuint8m1_t v_mask = __riscv_vmsne_vx_u8m1(v_upper, v_str, vl);\n\n    vuint8m1_t v_ascii = __riscv_vand_vx_u8m1(v_str, v_mask, vl);\n    vuint8m1_t v_sum = __riscv_vredsum_vs_u8m1_u32m1(v_ascii, 0, vl);\n\n    sum = __riscv_vmv_x_s_u32m1_u32(v_sum);\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_93_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nint digitSum_simd(std::string s) {\n    size_t len = s.length();\n    int sum = 0;\n\n    if (len == 0) {\n        return 0;\n    }\n\n    size_t vl = __riscv_vsetvl_e8m1(len);\n    vuint8m1_t v_str = __riscv_vle8_v_u8m1((const uint8_t*)s.data(), vl);\n\n    vuint8m1_t v_upper = __riscv_vand_vx_u8m1(v_str, 0xDF, vl);\n    vuint8m1_t v_mask = __riscv_vmslt_vx_u8m1(v_upper, 'A', vl);\n    vuint8m1_t v_mask2 = __riscv_vmsgt_vx_u8m1(v_upper, 'Z', vl);\n    vuint8m1_t v_mask3 = __riscv_vor_vv_u8m1(v_mask, v_mask2, vl);\n    vuint8m1_t v_mask4 = __riscv_vnot_v_u8m1(v_mask3, vl);\n\n    vuint8m1_t v_filtered = __riscv_vand_vv_u8m1(v_str, v_mask4, vl);\n    vuint8m1_t v_zero = __riscv_vmv_v_x_u8m1(0, vl);\n    vuint8m1_t v_sum = __riscv_vredsum_vs_u8m1_u32m1(v_filtered, v_zero, vl);\n\n    sum = __riscv_vmv_x_s_u32m1_i32(v_sum);\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_94_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <limits.h>\n\nstd::vector<int> pluck_simd(std::vector<int> arr) {\n    if (arr.empty()) {\n        return {};\n    }\n\n    size_t n = arr.size();\n    size_t vl = __riscv_vsetvl_e32m1(n);\n\n    vint32m1_t v_arr = __riscv_vle32_v_i32m1(arr.data(), vl);\n    vint32m1_t v_indices = __riscv_vid_v_i32m1(vl);\n\n    vint32m1_t v_even_mask = __riscv_vmseq_vx_i32m1_b32(v_arr, 0, vl);\n    vint32m1_t v_even_indices = __riscv_vcompress_vm(v_indices, v_even_mask, vl);\n\n    vint32m1_t v_even_values = __riscv_vcompress_vm(v_arr, v_even_mask, vl);\n\n    vint32m1_t v_even = __riscv_vmand_mm_b32(v_even_values, v_even_mask, vl);\n    vint32m1_t v_min_value = __riscv_vredmin_vs_i32m1_i32m1(v_even, INT_MAX, vl);\n\n    vint32m1_t v_min_index_mask = __riscv_vmseq_vv_i32m1_b32(v_even_values, v_min_value, vl);\n    vint32m1_t v_min_index = __riscv_vcompress_vm(v_even_indices, v_min_index_mask, vl);\n\n    int min_value = __riscv_vmv_x_s_i32m1_i32(v_min_value);\n    int min_index = __riscv_vmv_x_s_i32m1_i32(v_min_index);\n\n    if (min_value == INT_MAX) {\n        return {};\n    }\n\n    return {min_value, min_index};\n}\n```"}
{"task_id": "SimdBench_94_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <limits.h>\n\nstd::vector<int> pluck_simd(std::vector<int> arr) {\n    size_t n = arr.size();\n    if (n == 0) return {};\n\n    int min_even = INT_MAX;\n    int min_index = -1;\n\n    size_t vl = __riscv_vsetvl_e32m1(n);\n    vint32m1_t v_arr = __riscv_vle32_v_i32m1(arr.data(), vl);\n    vint32m1_t v_indices = __riscv_vid_v_i32m1(vl);\n    vuint32m1_t v_even_mask = __riscv_vmsne_vx_u32m1_b32(v_arr, 0, vl);\n    vuint32m1_t v_even = __riscv_vand_vv_u32m1(v_even_mask, v_arr, vl);\n    vuint32m1_t v_even_indices = __riscv_vand_vv_u32m1(v_even_mask, v_indices, vl);\n\n    while (vl > 0) {\n        vint32m1_t v_min_even = __riscv_vredmin_vs_i32m1_i32m1(v_even, min_even, vl);\n        vint32m1_t v_min_index = __riscv_vredminu_vs_u32m1_u32m1(v_even_indices, min_index, vl);\n\n        min_even = __riscv_vmv_x_s_i32m1_i32(v_min_even);\n        min_index = __riscv_vmv_x_s_i32m1_i32(v_min_index);\n\n        vl = __riscv_vsetvl_e32m1(n);\n        v_arr = __riscv_vle32_v_i32m1(arr.data(), vl);\n        v_indices = __riscv_vid_v_i32m1(vl);\n        v_even_mask = __riscv_vmsne_vx_u32m1_b32(v_arr, 0, vl);\n        v_even = __riscv_vand_vv_u32m1(v_even_mask, v_arr, vl);\n        v_even_indices = __riscv_vand_vv_u32m1(v_even_mask, v_indices, vl);\n    }\n\n    if (min_index == -1) return {};\n    return {min_even, min_index};\n}\n```"}
{"task_id": "SimdBench_94_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <limits.h>\n\nstd::vector<int> pluck_simd(std::vector<int> arr) {\n    size_t n = arr.size();\n    if (n == 0) return {};\n\n    int min_even = INT_MAX;\n    int min_index = -1;\n\n    size_t vl = __riscv_vsetvl_e32m1(n);\n    vint32m1_t v_arr = __riscv_vle32_v_i32m1(arr.data(), vl);\n    vint32m1_t v_indices = __riscv_vid_v_i32m1(vl);\n    vuint32m1_t v_even_mask = __riscv_vmsne_vx_u32m1_b32(v_arr, 0, vl);\n    v_even_mask = __riscv_vmand_mm_b32(v_even_mask, __riscv_vmsne_vx_u32m1_b32(__riscv_vrem_vx_u32m1_u32(v_arr, 2, vl), 0, vl), vl);\n\n    vint32m1_t v_even_values = __riscv_vcompress_vm_i32m1(v_arr, v_even_mask, vl);\n    vint32m1_t v_even_indices = __riscv_vcompress_vm_i32m1(v_indices, v_even_mask, vl);\n\n    size_t even_count = __riscv_vcpop_m_b32(v_even_mask, vl);\n    if (even_count == 0) return {};\n\n    vint32m1_t v_min_even = __riscv_vmv_v_x_i32m1(INT_MAX, vl);\n    vint32m1_t v_min_index = __riscv_vmv_v_x_i32m1(-1, vl);\n\n    for (size_t i = 0; i < even_count; i += vl) {\n        vl = __riscv_vsetvl_e32m1(even_count - i);\n        vint32m1_t v_curr_values = __riscv_vle32_v_i32m1(&v_even_values[i], vl);\n        vint32m1_t v_curr_indices = __riscv_vle32_v_i32m1(&v_even_indices[i], vl);\n\n        vuint32m1_t v_update_mask = __riscv_vmslt_vv_u32m1_b32(v_curr_values, v_min_even, vl);\n        v_min_even = __riscv_vmerge_vvm_i32m1(v_min_even, v_curr_values, v_update_mask, vl);\n        v_min_index = __riscv_vmerge_vvm_i32m1(v_min_index, v_curr_indices, v_update_mask, vl);\n    }\n\n    min_even = __riscv_vmv_x_s_i32m1_i32(v_min_even);\n    min_index = __riscv_vmv_x_s_i32m1_i32(v_min_index);\n\n    return {min_even, min_index};\n}\n```"}
{"task_id": "SimdBench_94_RVV", "completion": "```c++\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> pluck_simd(std::vector<int> arr) {\n    if (arr.empty()) {\n        return {};\n    }\n\n    size_t n = arr.size();\n    size_t vl = __riscv_vsetvl_e32m1(n);\n\n    vint32m1_t v_arr = __riscv_vle32_v_i32m1(arr.data(), vl);\n    vint32m1_t v_indices = __riscv_vid_v_i32m1(vl);\n\n    vint32m1_t v_even_mask = __riscv_vmseq_vx_i32m1_b32(v_arr, 0, vl);\n    vint32m1_t v_even_values = __riscv_vmerge_vx_i32m1(v_arr, INT32_MAX, v_even_mask, vl);\n\n    vint32m1_t v_min_value = __riscv_vredmin_vs_i32m1_i32m1(v_even_values, INT32_MAX, vl);\n    vint32m1_t v_min_index = __riscv_vredminu_vs_i32m1_i32m1(v_indices, INT32_MAX, vl);\n\n    int min_value = __riscv_vmv_x_s_i32m1_i32(v_min_value);\n    int min_index = __riscv_vmv_x_s_i32m1_i32(v_min_index);\n\n    if (min_value == INT32_MAX) {\n        return {};\n    }\n\n    return {min_value, min_index};\n}\n```"}
{"task_id": "SimdBench_94_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <limits.h>\n\nstd::vector<int> pluck_simd(std::vector<int> arr) {\n    if (arr.empty()) {\n        return {};\n    }\n\n    size_t n = arr.size();\n    size_t vl = __riscv_vsetvl_e32m1(n);\n\n    vint32m1_t v_arr = __riscv_vle32_v_i32m1(arr.data(), vl);\n    vint32m1_t v_indices = __riscv_vid_v_i32m1(vl);\n\n    vint32m1_t v_even_mask = __riscv_vmseq_vx_i32m1_b32(v_arr, 0, vl);\n    vint32m1_t v_even_indices = __riscv_vcompress_vm(v_indices, v_even_mask, vl);\n\n    vint32m1_t v_even_values = __riscv_vcompress_vm(v_arr, v_even_mask, vl);\n\n    vint32m1_t v_even = __riscv_vmand_mm_b32(v_even_values, v_even_mask, vl);\n    vint32m1_t v_min_value = __riscv_vredmin_vs_i32m1_i32m1(v_even, INT_MAX, vl);\n\n    vint32m1_t v_min_index_mask = __riscv_vmseq_vv_i32m1_b32(v_even_values, v_min_value, vl);\n    vint32m1_t v_min_index = __riscv_vcompress_vm(v_even_indices, v_min_index_mask, vl);\n\n    int min_value = __riscv_vmv_x_s_i32m1_i32(v_min_value);\n    int min_index = __riscv_vmv_x_s_i32m1_i32(v_min_index);\n\n    if (min_value == INT_MAX) {\n        return {};\n    }\n\n    return {min_value, min_index};\n}\n```"}
{"task_id": "SimdBench_95_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <algorithm>\n\nint search_simd(std::vector<int> lst) {\n    size_t n = lst.size();\n    int max_val = *std::max_element(lst.begin(), lst.end());\n    std::vector<int> count(max_val + 1, 0);\n\n    for (size_t i = 0; i < n; i += vsetvl_e32m1(n - i)) {\n        size_t vl = vsetvl_e32m1(n - i);\n        vuint32m1_t v_indices = vid_v_u32m1(vl);\n        vbool32_t mask = vmseq_vv_u32m1_b32(v_indices, vle32_v_u32m1(&lst[i], vl), vl);\n        vbool32_t mask2 = vmseq_vv_u32m1_b32(vle32_v_u32m1(&lst[i], vl), v_indices, vl);\n        mask = vmand_mm_b32(mask, mask2, vl);\n        vsadd_vv_u32m1(&count[0], vle32_v_u32m1(&lst[i], vl), mask, vl);\n    }\n\n    for (int i = max_val; i > 0; --i) {\n        if (count[i] >= i) {\n            return i;\n        }\n    }\n    return -1;\n}\n```"}
{"task_id": "SimdBench_95_RVV", "completion": "```c++\nint search_simd(std::vector<int> lst) {\n    size_t n = lst.size();\n    int max_val = -1;\n\n    for (size_t i = 0; i < n; i += 8) {\n        size_t vl = __riscv_vsetvl_e32m1(n - i);\n        vuint32m1_t v = __riscv_vle32_v_u32m1(&lst[i], vl);\n\n        for (int j = 1; j <= 8; ++j) {\n            vuint32m1_t mask = __riscv_vmseq_vx_u32m1_b32(v, j, vl);\n            int count = __riscv_vcpop_m(mask, vl);\n\n            if (count >= j && j > max_val) {\n                max_val = j;\n            }\n        }\n    }\n\n    return max_val;\n}\n```"}
{"task_id": "SimdBench_95_RVV", "completion": "```c++\nint search_simd(std::vector<int> lst) {\n    size_t n = lst.size();\n    int max_val = -1;\n\n    for (size_t i = 0; i < n; i += __riscv_vsetvl_e32m1(n - i)) {\n        size_t vl = __riscv_vsetvl_e32m1(n - i);\n\n        vint32m1_t v_lst = __riscv_vle32_v_i32m1(&lst[i], vl);\n        vint32m1_t v_ones = __riscv_vmv_v_x_i32m1(1, vl);\n        vint32m1_t v_freq = __riscv_vmv_v_x_i32m1(0, vl);\n\n        for (size_t j = 0; j < n; j += vl) {\n            vint32m1_t v_cmp = __riscv_vmseq_vv_i32m1_b32(v_lst, __riscv_vle32_v_i32m1(&lst[j], vl), vl);\n            v_freq = __riscv_vadd_vv_i32m1(v_freq, __riscv_vmv_v_v_i32m1(v_ones, v_cmp, vl), vl);\n        }\n\n        vint32m1_t v_cmp_freq = __riscv_vmsge_vv_i32m1_b32(v_freq, v_lst, vl);\n        vint32m1_t v_cmp_val = __riscv_vmsgt_vx_i32m1_b32(v_lst, 0, vl);\n        vint32m1_t v_valid = __riscv_vmand_mm_b32(v_cmp_freq, v_cmp_val, vl);\n\n        vint32m1_t v_max_candidates = __riscv_vmv_v_v_i32m1(v_lst, v_valid, vl);\n        vint32m1_t v_max = __riscv_vredmax_vs_i32m1_i32m1(v_max_candidates, __riscv_vmv_v_x_i32m1(0, vl), vl);\n\n        if (v_max[0] > max_val) {\n            max_val = v_max[0];\n        }\n    }\n\n    return max_val;\n}\n```"}
{"task_id": "SimdBench_95_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <algorithm>\n\nint search_simd(std::vector<int> lst) {\n    size_t n = lst.size();\n    int max_val = *std::max_element(lst.begin(), lst.end());\n    std::vector<int> count(max_val + 1, 0);\n\n    for (size_t i = 0; i < n; i += sizeof(vint32m1_t) / sizeof(int)) {\n        vint32m1_t v = __riscv_vle32_v_i32m1(&lst[i], n - i);\n        vint32m1_t mask = __riscv_vmsge_vx_i32m1_b32(v, 0, n - i);\n        vint32m1_t indices = __riscv_vcompress_vm_i32m1(mask, v, n - i);\n        size_t m = __riscv_vcpop_m(mask);\n\n        for (size_t j = 0; j < m; ++j) {\n            count[indices[j]]++;\n        }\n    }\n\n    for (int i = max_val; i > 0; --i) {\n        if (count[i] >= i) {\n            return i;\n        }\n    }\n\n    return -1;\n}\n```"}
{"task_id": "SimdBench_95_RVV", "completion": "```c++\nint search_simd(std::vector<int> lst) {\n    size_t n = lst.size();\n    int max_val = -1;\n\n    for (size_t i = 0; i < n; i += __riscv_vsetvl_e32m1(n - i)) {\n        size_t vl = __riscv_vsetvl_e32m1(n - i);\n\n        vint32m1_t v_lst = __riscv_vle32_v_i32m1(&lst[i], vl);\n        vint32m1_t v_ones = __riscv_vmv_v_x_i32m1(1, vl);\n        vint32m1_t v_freq = __riscv_vmv_v_x_i32m1(0, vl);\n\n        for (size_t j = 0; j < n; j += vl) {\n            vint32m1_t v_cmp = __riscv_vmseq_vv_i32m1_b32(v_lst, __riscv_vle32_v_i32m1(&lst[j], vl), vl);\n            v_freq = __riscv_vadd_vv_i32m1(v_freq, __riscv_vand_mm_b32(v_cmp, v_ones, vl), vl);\n        }\n\n        vint32m1_t v_cmp = __riscv_vmsgt_vx_i32m1_b32(v_freq, 0, vl);\n        vint32m1_t v_cmp2 = __riscv_vmsge_vv_i32m1_b32(v_freq, v_lst, vl);\n        vint32m1_t v_cmp3 = __riscv_vmand_mm_b32(v_cmp, v_cmp2, vl);\n\n        vint32m1_t v_max = __riscv_vmv_v_x_i32m1(max_val, vl);\n        v_max = __riscv_vmax_vv_i32m1(v_max, __riscv_vand_mm_b32(v_cmp3, v_lst, vl), vl);\n\n        max_val = __riscv_vredmax_vs_i32m1_i32m1(v_max, max_val, vl);\n    }\n\n    return max_val;\n}\n```"}
{"task_id": "SimdBench_96_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nbool will_it_fly_simd(std::vector<int> q, int w) {\n    size_t n = q.size();\n    size_t vl = __riscv_vsetvl_e32m1(n);\n\n    vint32m1_t vq = __riscv_vle32_v_i32m1(q.data(), vl);\n    vint32m1_t vreversed = __riscv_vrgather_vx_i32m1(vq, n - 1, vl);\n\n    bool is_palindrome = __riscv_vreduc_and_mm_b32(__riscv_vmseq_vv_b32m1(vq, vreversed, vl), vl);\n\n    vint32m1_t vsum = __riscv_vredsum_vs_i32m1_i32m1(vq, __riscv_vmv_v_x_i32m1(0, vl), vl);\n    int sum = __riscv_vmv_x_s_i32m1_i32(vsum);\n\n    return is_palindrome && sum <= w;\n}\n```"}
{"task_id": "SimdBench_96_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nbool will_it_fly_simd(std::vector<int> q, int w) {\n    size_t n = q.size();\n    size_t vl = __riscv_vsetvl_e32m1(n);\n\n    vint32m1_t vq = __riscv_vle32_v_i32m1(q.data(), vl);\n    vint32m1_t vreversed = __riscv_vrgather_vv_i32m1(vq, __riscv_vid_v_i32m1(vl), vl);\n\n    bool is_palindrome = __riscv_vreduc_vs_i32m1_i32m1(vq, vreversed, 0, vl) == 0;\n\n    vint32m1_t vsum = __riscv_vredsum_vs_i32m1_i32m1(vq, 0, vl);\n    int sum = __riscv_vmv_x_s_i32m1_i32(vsum);\n\n    return is_palindrome && sum <= w;\n}\n```"}
{"task_id": "SimdBench_96_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nbool will_it_fly_simd(std::vector<int> q, int w) {\n    size_t n = q.size();\n    vint32m1_t vq = __riscv_vle32_v_i32m1(q.data(), n);\n    vint32m1_t vq_rev = __riscv_vrgather_vx_i32m1(vq, n - 1, __riscv_vid_v_i32m1(n));\n    vint32m1_t vq_diff = __riscv_vsub_vv_i32m1(vq, vq_rev, n);\n    vint32m1_t vq_sum = __riscv_vredsum_vs_i32m1_i32m1(vq, __riscv_vmv_v_x_i32m1(0, n), n);\n    vint32m1_t vq_diff_sum = __riscv_vredsum_vs_i32m1_i32m1(vq_diff, __riscv_vmv_v_x_i32m1(0, n), n);\n    int sum = __riscv_vmv_x_s_i32m1_i32(vq_sum);\n    int diff_sum = __riscv_vmv_x_s_i32m1_i32(vq_diff_sum);\n    return (diff_sum == 0) && (sum <= w);\n}\n```"}
{"task_id": "SimdBench_96_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nbool will_it_fly_simd(std::vector<int> q, int w) {\n    size_t n = q.size();\n    vint32m1_t vq = __riscv_vle32_v_i32m1(q.data(), n);\n    vint32m1_t vq_rev = __riscv_vrgather_vv_i32m1(vq, __riscv_vid_v_i32m1(n), n);\n\n    bool is_palindrome = __riscv_vreduc_and_vm_i32m1_bm(__riscv_vmseq_vv_i32m1_bm(vq, vq_rev, n), n);\n\n    vint32m1_t sum = __riscv_vredsum_vs_i32m1_i32m1(vq, __riscv_vmv_v_x_i32m1(0, n), n);\n    int total_sum = __riscv_vmv_x_s_i32m1_i32(sum);\n\n    return is_palindrome && total_sum <= w;\n}\n```"}
{"task_id": "SimdBench_96_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nbool will_it_fly_simd(std::vector<int> q, int w) {\n    size_t n = q.size();\n    size_t vl = __riscv_vsetvl_e32m1(n);\n\n    vint32m1_t vq = __riscv_vle32_v_i32m1(q.data(), vl);\n    vint32m1_t vreversed = __riscv_vrgather_vv_i32m1(vq, __riscv_vid_v_i32m1(vl), vl);\n\n    bool is_palindromic = __riscv_vreduc_and_vm_i32m1_bm(__riscv_vmseq_vv_i32m1_bm(vq, vreversed, vl), vl);\n\n    vint32m1_t vsum = __riscv_vredsum_vs_i32m1_i32m1(vq, __riscv_vmv_v_x_i32m1(0, vl), vl);\n    int sum = __riscv_vmv_x_s_i32m1_i32(vsum);\n\n    return is_palindromic && sum <= w;\n}\n```"}
{"task_id": "SimdBench_97_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nint smallest_change_simd(std::vector<int> arr) {\n    size_t n = arr.size();\n    size_t half = n / 2;\n    int changes = 0;\n\n    for (size_t i = 0; i < half; i += sizeof(int) * 8) {\n        size_t vl = __riscv_vsetvl_e32m1(n - i);\n        vint32m1_t v_left = __riscv_vle32_v_i32m1(&arr[i], vl);\n        vint32m1_t v_right = __riscv_vle32_v_i32m1(&arr[n - i - vl], vl);\n\n        vint32m1_t v_diff = __riscv_vmsne_vv_i32m1_b32(v_left, v_right, vl);\n        changes += __riscv_vcpop_m_b32(v_diff, vl);\n    }\n\n    if (n % 2 == 1) {\n        size_t mid = n / 2;\n        if (arr[mid] != arr[mid]) {\n            changes++;\n        }\n    }\n\n    return changes;\n}\n```"}
{"task_id": "SimdBench_97_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nint smallest_change_simd(std::vector<int> arr) {\n    size_t n = arr.size();\n    size_t half = n / 2;\n    int changes = 0;\n\n    for (size_t i = 0; i < half; i += sizeof(vint32m1_t) / sizeof(int)) {\n        vint32m1_t v1 = __riscv_vle32_v_i32m1(&arr[i], sizeof(vint32m1_t) / sizeof(int));\n        vint32m1_t v2 = __riscv_vle32_v_i32m1(&arr[n - i - sizeof(vint32m1_t) / sizeof(int)], sizeof(vint32m1_t) / sizeof(int));\n\n        vbool32_t mask = __riscv_vmsne_vv_i32m1_b32(v1, v2, sizeof(vint32m1_t) / sizeof(int));\n        changes += __riscv_vcpop_m(mask, sizeof(vint32m1_t) / sizeof(int));\n    }\n\n    if (n % 2 == 0) {\n        return changes;\n    } else {\n        return changes + (arr[half] != arr[half + 1]);\n    }\n}\n```"}
{"task_id": "SimdBench_97_RVV", "completion": "```c++\n#include <riscv_vector.h>\n#include <vector>\n\nint smallest_change_simd(std::vector<int> arr) {\n    size_t n = arr.size();\n    size_t half_n = n / 2;\n    int changes = 0;\n\n    for (size_t i = 0; i < half_n; i += sizeof(int) * 8) {\n        size_t vl = __riscv_vsetvl_e32m1(n - i);\n        vint32m1_t v_left = __riscv_vle32_v_i32m1(&arr[i], vl);\n        vint32m1_t v_right = __riscv_vle32_v_i32m1(&arr[n - i - vl], vl);\n\n        vint32m1_t v_diff = __riscv_vmsne_vv_i32m1(v_left, v_right, vl);\n        changes += __riscv_vcpop_m(v_diff, vl);\n    }\n\n    if (n % 2 == 1) {\n        changes += (arr[half_n] != arr[half_n + 1]);\n    }\n\n    return changes;\n}\n```"}
{"task_id": "SimdBench_97_RVV", "completion": "```c++\n#include <riscv_vector.h>\n#include <vector>\n\nint smallest_change_simd(std::vector<int> arr) {\n    size_t n = arr.size();\n    size_t half = n / 2;\n    int changes = 0;\n\n    for (size_t i = 0; i < half; i += sizeof(vint32m1_t) / sizeof(int)) {\n        vint32m1_t v1 = vle32_v_i32m1(&arr[i], sizeof(vint32m1_t) / sizeof(int));\n        vint32m1_t v2 = vle32_v_i32m1(&arr[n - i - sizeof(vint32m1_t) / sizeof(int)], sizeof(vint32m1_t) / sizeof(int));\n\n        vint32m1_t vdiff = vsub_vv_i32m1(v1, v2, sizeof(vint32m1_t) / sizeof(int));\n        vint32m1_t vabs = vabs_v_i32m1(vdiff, sizeof(vint32m1_t) / sizeof(int));\n        vint32m1_t vcmp = vmseq_vx_i32m1_b16(vabs, 0, sizeof(vint32m1_t) / sizeof(int));\n\n        changes += vpopc_m_b16(vcmp, sizeof(vint32m1_t) / sizeof(int));\n    }\n\n    if (n % 2 == 1) {\n        changes += (arr[half] != arr[half + 1]);\n    }\n\n    return changes;\n}\n```"}
{"task_id": "SimdBench_97_RVV", "completion": "```c++\n#include <riscv_vector.h>\n#include <vector>\n\nint smallest_change_simd(std::vector<int> arr) {\n    size_t n = arr.size();\n    size_t half = n / 2;\n    int changes = 0;\n\n    for (size_t i = 0; i < half; i += sizeof(vint32m1_t) / sizeof(int)) {\n        vint32m1_t v1 = vle32_v_i32m1(&arr[i], sizeof(vint32m1_t) / sizeof(int));\n        vint32m1_t v2 = vle32_v_i32m1(&arr[n - i - sizeof(vint32m1_t) / sizeof(int)], sizeof(vint32m1_t) / sizeof(int));\n\n        vint32m1_t mask = vmne_vv_i32m1(v1, v2, sizeof(vint32m1_t) / sizeof(int));\n        changes += vpopc_m_i32m1(mask, sizeof(vint32m1_t) / sizeof(int));\n    }\n\n    if (n % 2 == 0) {\n        return changes;\n    } else {\n        return changes + (arr[half] != arr[half + 1]);\n    }\n}\n```"}
{"task_id": "SimdBench_98_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <string>\n\nstd::vector<std::string> total_match_simd(const std::vector<std::string> & lst1, const std::vector<std::string> & lst2) {\n    size_t total_chars1 = 0;\n    size_t total_chars2 = 0;\n\n    size_t vlmax = __riscv_vsetvlmax_e8m1();\n\n    for (size_t i = 0; i < lst1.size(); i += vlmax) {\n        size_t vl = __riscv_vsetvl_e8m1(std::min(vlmax, lst1.size() - i));\n        vuint8m1_t v_chars = __riscv_vundefined_u8m1();\n        for (size_t j = 0; j < lst1[i].size(); j += vl) {\n            size_t vvl = __riscv_vsetvl_e8m1(std::min(vl, lst1[i].size() - j));\n            v_chars = __riscv_vload_u8m1(&lst1[i][j], vvl);\n            total_chars1 += __riscv_vreduc_sum_u8m1_u64m1(v_chars, vvl);\n        }\n    }\n\n    for (size_t i = 0; i < lst2.size(); i += vlmax) {\n        size_t vl = __riscv_vsetvl_e8m1(std::min(vlmax, lst2.size() - i));\n        vuint8m1_t v_chars = __riscv_vundefined_u8m1();\n        for (size_t j = 0; j < lst2[i].size(); j += vl) {\n            size_t vvl = __riscv_vsetvl_e8m1(std::min(vl, lst2[i].size() - j));\n            v_chars = __riscv_vload_u8m1(&lst2[i][j], vvl);\n            total_chars2 += __riscv_vreduc_sum_u8m1_u64m1(v_chars, vvl);\n        }\n    }\n\n    return total_chars1 < total_chars2 ? lst1 : lst2;\n}\n```"}
{"task_id": "SimdBench_98_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <string>\n\nstd::vector<std::string> total_match_simd(const std::vector<std::string> & lst1, const std::vector<std::string> & lst2) {\n    size_t total_chars1 = 0;\n    size_t total_chars2 = 0;\n\n    size_t vlmax = __riscv_vsetvlmax_e8m1();\n    size_t vl = vlmax;\n\n    for (const auto& str : lst1) {\n        size_t len = str.size();\n        total_chars1 += len;\n    }\n\n    for (const auto& str : lst2) {\n        size_t len = str.size();\n        total_chars2 += len;\n    }\n\n    if (total_chars1 < total_chars2) {\n        return lst1;\n    } else {\n        return lst2;\n    }\n}\n```"}
{"task_id": "SimdBench_98_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <string>\n\nstd::vector<std::string> total_match_simd(const std::vector<std::string> & lst1, const std::vector<std::string> & lst2) {\n    size_t total_chars1 = 0;\n    size_t total_chars2 = 0;\n\n    size_t vl = __riscv_vsetvl_e8m8(1);\n    for (size_t i = 0; i < lst1.size(); i += vl) {\n        vl = __riscv_vsetvl_e8m8(lst1.size() - i);\n        vuint8m8_t v_str = __riscv_vle8_v_u8m8((const uint8_t*)lst1[i].c_str(), vl);\n        vuint8m8_t v_len = __riscv_vreinterpret_v_u8m8_u8m1(__riscv_vset_v_u8m1(1, vl));\n        vuint8m8_t v_sum = __riscv_vredsum_vs_u8m8_u8m1(v_len, v_str, 0);\n        total_chars1 += __riscv_vmv_x_s_u8m1_u8(v_sum);\n    }\n\n    vl = __riscv_vsetvl_e8m8(1);\n    for (size_t i = 0; i < lst2.size(); i += vl) {\n        vl = __riscv_vsetvl_e8m8(lst2.size() - i);\n        vuint8m8_t v_str = __riscv_vle8_v_u8m8((const uint8_t*)lst2[i].c_str(), vl);\n        vuint8m8_t v_len = __riscv_vreinterpret_v_u8m8_u8m1(__riscv_vset_v_u8m1(1, vl));\n        vuint8m8_t v_sum = __riscv_vredsum_vs_u8m8_u8m1(v_len, v_str, 0);\n        total_chars2 += __riscv_vmv_x_s_u8m1_u8(v_sum);\n    }\n\n    return total_chars1 < total_chars2 ? lst1 : lst2;\n}\n```"}
{"task_id": "SimdBench_98_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <string>\n\nstd::vector<std::string> total_match_simd(const std::vector<std::string> & lst1, const std::vector<std::string> & lst2) {\n    size_t total_chars1 = 0;\n    size_t total_chars2 = 0;\n\n    size_t vl = __riscv_vsetvl_e8m8(lst1.size());\n    for (size_t i = 0; i < lst1.size(); i += vl) {\n        vl = __riscv_vsetvl_e8m8(lst1.size() - i);\n        for (size_t j = 0; j < vl; ++j) {\n            total_chars1 += lst1[i + j].size();\n        }\n    }\n\n    vl = __riscv_vsetvl_e8m8(lst2.size());\n    for (size_t i = 0; i < lst2.size(); i += vl) {\n        vl = __riscv_vsetvl_e8m8(lst2.size() - i);\n        for (size_t j = 0; j < vl; ++j) {\n            total_chars2 += lst2[i + j].size();\n        }\n    }\n\n    return (total_chars1 <= total_chars2) ? lst1 : lst2;\n}\n```"}
{"task_id": "SimdBench_98_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <string>\n\nstd::vector<std::string> total_match_simd(const std::vector<std::string> &lst1, const std::vector<std::string> &lst2) {\n    size_t total_chars1 = 0;\n    size_t total_chars2 = 0;\n\n    // Calculate total number of characters in lst1\n    for (const auto &str : lst1) {\n        total_chars1 += str.size();\n    }\n\n    // Calculate total number of characters in lst2\n    for (const auto &str : lst2) {\n        total_chars2 += str.size();\n    }\n\n    // Compare the total number of characters and return the appropriate vector\n    if (total_chars1 < total_chars2) {\n        return lst1;\n    } else {\n        return lst2;\n    }\n}\n```"}
{"task_id": "SimdBench_99_RVV", "completion": "```c\nbool is_simple_power_simd(uint64_t x, uint64_t n) {\n    if (x == 1) return true;\n    if (n == 1) return x == 1;\n    if (n == 0) return x == 1;\n\n    uint64_t current = n;\n    while (current <= x) {\n        if (current == x) return true;\n        if (x / current < n) break;\n        current *= n;\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_99_RVV", "completion": "```c\nbool is_simple_power_simd(uint64_t x, uint64_t n) {\n    if (x == 1) return true;\n    if (n == 1) return x == 1;\n    if (n == 0) return x == 1;\n\n    uint64_t current = n;\n    while (current <= x) {\n        if (current == x) return true;\n        if (current > UINT64_MAX / n) break;\n        current *= n;\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_99_RVV", "completion": "```c\nbool is_simple_power_simd(uint64_t x, uint64_t n) {\n    if (n == 1) {\n        return x == 1;\n    }\n\n    uint64_t power = n;\n    while (power <= x) {\n        if (power == x) {\n            return true;\n        }\n        if (power > UINT64_MAX / n) {\n            break;\n        }\n        power *= n;\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_99_RVV", "completion": "```c\nbool is_simple_power_simd(uint64_t x, uint64_t n) {\n    if (x == 1) return true;\n    if (n == 1) return x == 1;\n    if (n == 0) return x == 1;\n\n    uint64_t current = n;\n    while (current <= x) {\n        if (current == x) return true;\n        if (current > UINT64_MAX / n) break;\n        current *= n;\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_99_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nbool is_simple_power_simd(uint64_t x, uint64_t n) {\n    if (n == 1) {\n        return x == 1;\n    }\n    if (x == 1) {\n        return n == 1;\n    }\n    if (n == 0) {\n        return x == 1;\n    }\n\n    uint64_t power = n;\n    while (power <= x) {\n        if (power == x) {\n            return true;\n        }\n        if (power > UINT64_MAX / n) {\n            return false;\n        }\n        power *= n;\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_100_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nint hex_key_simd(const std::string & num) {\n    size_t len = num.size();\n    if (len == 0) return 0;\n\n    // Define the prime hexadecimal digits\n    const char prime_digits[] = {'2', '3', '5', '7', 'B', 'D'};\n    size_t prime_count = sizeof(prime_digits) / sizeof(prime_digits[0]);\n\n    // Initialize the vector registers\n    vuint8mf8_t v_prime_digits = __riscv_vle8_v_u8mf8(prime_digits, prime_count, 1);\n    vuint8mf8_t v_input = __riscv_vle8_v_u8mf8((const uint8_t*)num.c_str(), len, 1);\n\n    // Initialize the mask and count\n    vuint8mf8_t v_mask = __riscv_vmv_v_x_u8mf8(0, 1);\n    size_t count = 0;\n\n    // Compare each input character with the prime digits\n    for (size_t i = 0; i < prime_count; ++i) {\n        vuint8mf8_t v_compare = __riscv_vmseq_vv_u8mf8(v_input, v_prime_digits, 1);\n        v_mask = __riscv_vmand_mm_u8mf8(v_mask, v_compare, 1);\n    }\n\n    // Count the number of 1s in the mask\n    count = __riscv_vcpop_m_u8mf8(v_mask, 1);\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_100_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nint hex_key_simd(const std::string & num) {\n    size_t len = num.size();\n    if (len == 0) return 0;\n\n    // Define the prime hexadecimal digits\n    const char prime_digits[] = {'2', '3', '5', '7', 'B', 'D'};\n    size_t prime_count = sizeof(prime_digits) / sizeof(prime_digits[0]);\n\n    // Initialize the count\n    int count = 0;\n\n    // Process the string in chunks of 8 characters\n    for (size_t i = 0; i < len; i += 8) {\n        size_t chunk_size = std::min(len - i, size_t(8));\n\n        // Load the chunk into a vector\n        vuint8m1_t v_chunk = vle8_v_u8m1(&num[i], chunk_size);\n\n        // Broadcast the prime digits to a vector\n        vuint8m1_t v_prime_digits = vle8_v_u8m1(prime_digits, prime_count);\n\n        // Compare each character in the chunk with each prime digit\n        for (size_t j = 0; j < prime_count; ++j) {\n            vuint8m1_t v_prime = vbroadcast_u8m1(v_prime_digits, j);\n            vuint8m1_t v_cmp = vmseq_u8m1(v_chunk, v_prime, chunk_size);\n\n            // Count the number of matches\n            count += vpopc_m_u8m1(v_cmp, chunk_size);\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_100_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nint hex_key_simd(const std::string & num) {\n    size_t len = num.size();\n    if (len == 0) return 0;\n\n    // Define the prime hexadecimal digits\n    const char prime_digits[] = {'2', '3', '5', '7', 'B', 'D'};\n    size_t prime_count = sizeof(prime_digits) / sizeof(prime_digits[0]);\n\n    // Initialize the vector registers\n    vuint8m1_t v_prime_digits = __riscv_vle8_v_u8m1(prime_digits, prime_count, 1);\n    vuint8m1_t v_input = __riscv_vle8_v_u8m1((const uint8_t*)num.c_str(), len, 1);\n\n    // Initialize the mask and count\n    vuint8m1_t v_mask = __riscv_vmv_v_x_u8m1(0, 1);\n    size_t count = 0;\n\n    // Compare each character in the input string with the prime digits\n    for (size_t i = 0; i < len; ++i) {\n        vuint8m1_t v_char = __riscv_vmv_v_x_u8m1(num[i], 1);\n        vuint8m1_t v_cmp = __riscv_vmseq_vv_u8m1_b8(v_char, v_prime_digits, prime_count);\n        v_mask = __riscv_vmand_mm_b8(v_mask, v_cmp, prime_count);\n        count += __riscv_vcpop_m_b8(v_mask, prime_count);\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_100_RVV", "completion": "```c++\n#include <riscv_vector.h>\n#include <string>\n\nint hex_key_simd(const std::string & num) {\n    size_t len = num.size();\n    if (len == 0) return 0;\n\n    // Define the prime hexadecimal digits\n    const char prime_digits[] = {'2', '3', '5', '7', 'B', 'D'};\n    size_t prime_count = sizeof(prime_digits) / sizeof(prime_digits[0]);\n\n    // Initialize the vector registers\n    vuint8m1_t v_prime_digits = __riscv_vle8_v_u8m1(prime_digits, prime_count, 1);\n    vuint8m1_t v_input = __riscv_vle8_v_u8m1((const uint8_t*)num.c_str(), len, 1);\n\n    // Initialize the count register\n    vuint8m1_t v_count = __riscv_vmv_v_x_u8m1(0, 1);\n\n    // Compare each input character with the prime digits\n    for (size_t i = 0; i < len; ++i) {\n        vuint8m1_t v_match = __riscv_vmseq_vv_u8m1_b8(v_input, v_prime_digits, prime_count);\n        v_count = __riscv_vadd_vv_u8m1(v_count, v_match, 1);\n    }\n\n    // Reduce the count vector to a scalar\n    uint8_t count = __riscv_vredsum_vs_u8m1_u8(v_count, 0, 1);\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_100_RVV", "completion": "```c++\n#include <riscv_vector.h>\n#include <string>\n\nint hex_key_simd(const std::string & num) {\n    size_t len = num.size();\n    if (len == 0) return 0;\n\n    // Define the prime hexadecimal digits\n    const char prime_digits[] = {'2', '3', '5', '7', 'B', 'D'};\n    size_t prime_count = sizeof(prime_digits) / sizeof(prime_digits[0]);\n\n    // Initialize the count of prime digits\n    int count = 0;\n\n    // Vectorize the input string\n    size_t vl = vsetvl_e8m1(len);\n    vuint8m1_t v_input = vle8_v_u8m1((const uint8_t*)num.data(), vl);\n\n    // Vectorize the prime digits\n    vuint8m1_t v_primes = vle8_v_u8m1((const uint8_t*)prime_digits, prime_count);\n\n    // Compare each character in the input string with the prime digits\n    for (size_t i = 0; i < prime_count; ++i) {\n        vuint8m1_t v_compare = vmseq_vv_u8m1_b8(v_input, v_primes, vl);\n        count += vpopc_m_b8(v_compare, vl);\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_101_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nbool is_happy_simd(const std::string & s) {\n    size_t len = s.length();\n    if (len < 3) return false;\n\n    size_t vl = vsetvl_e8m8(len);\n    vuint8m8_t v_s = vle8_v_u8m8((const uint8_t*)s.data(), vl);\n\n    for (size_t i = 0; i < len - 2; ++i) {\n        vuint8m8_t v_a = vslide1down_vx_u8m8(v_s, s[i], vl);\n        vuint8m8_t v_b = vslide1down_vx_u8m8(v_a, s[i + 1], vl);\n        vuint8m8_t v_c = vslide1down_vx_u8m8(v_b, s[i + 2], vl);\n\n        vuint8m8_t v_eq_ab = vmseq_vv_u8m8_b8(v_a, v_b, vl);\n        vuint8m8_t v_eq_ac = vmseq_vv_u8m8_b8(v_a, v_c, vl);\n        vuint8m8_t v_eq_bc = vmseq_vv_u8m8_b8(v_b, v_c, vl);\n\n        vuint8m8_t v_all_eq = vmor_mm_b8(vmor_mm_b8(v_eq_ab, v_eq_ac), v_eq_bc);\n        if (vfirst_m_b8(v_all_eq, vl) != -1) return false;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_101_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nbool is_happy_simd(const std::string & s) {\n    size_t len = s.length();\n    if (len < 3) return false;\n\n    size_t vl = vsetvl_e8m8(len);\n    vuint8m8_t v_s = vle8_v_u8m8((const uint8_t*)s.data(), vl);\n\n    for (size_t i = 0; i < len - 2; ++i) {\n        vuint8m8_t v_a = vslide1down_vx_u8m8(v_s, s[i], vl);\n        vuint8m8_t v_b = vslide1down_vx_u8m8(v_a, s[i + 1], vl);\n        vuint8m8_t v_c = vslide1down_vx_u8m8(v_b, s[i + 2], vl);\n\n        vuint8m8_t v_eq_ab = vmseq_vv_u8m8_b8(v_a, v_b, vl);\n        vuint8m8_t v_eq_ac = vmseq_vv_u8m8_b8(v_a, v_c, vl);\n        vuint8m8_t v_eq_bc = vmseq_vv_u8m8_b8(v_b, v_c, vl);\n\n        vuint8m8_t v_all_eq = vmor_mm_b8(vmor_mm_b8(v_eq_ab, v_eq_ac), v_eq_bc);\n        if (vfirst_m_b8(v_all_eq, vl) != -1) return false;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_101_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nbool is_happy_simd(const std::string & s) {\n    size_t len = s.length();\n    if (len < 3) {\n        return false;\n    }\n\n    size_t vl = vsetvl_e8m8(len - 2);\n    vuint8m8_t v_a = vle8_v_u8m8(&s[0], vl);\n    vuint8m8_t v_b = vle8_v_u8m8(&s[1], vl);\n    vuint8m8_t v_c = vle8_v_u8m8(&s[2], vl);\n\n    vuint8m8_t cmp_ab = vmseq_vv_u8m8_b8(v_a, v_b, vl);\n    vuint8m8_t cmp_ac = vmseq_vv_u8m8_b8(v_a, v_c, vl);\n    vuint8m8_t cmp_bc = vmseq_vv_u8m8_b8(v_b, v_c, vl);\n\n    vuint8m8_t result = vmor_mm_b8(vmor_mm_b8(cmp_ab, cmp_ac), cmp_bc);\n\n    return vfirst_m_b8(result, vl) < 0;\n}\n```"}
{"task_id": "SimdBench_101_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nbool is_happy_simd(const std::string &s) {\n    size_t len = s.length();\n    if (len < 3) return false;\n\n    size_t vl = vsetvl_e8m8(len);\n    vuint8m8_t v_s = vle8_v_u8m8((const uint8_t*)s.data(), vl);\n\n    for (size_t i = 0; i < len - 2; ++i) {\n        vuint8m8_t v_a = vslide1up_vx_u8m8(v_s, s[i], vl);\n        vuint8m8_t v_b = vslide1up_vx_u8m8(v_a, s[i + 1], vl);\n        vuint8m8_t v_c = vslide1up_vx_u8m8(v_b, s[i + 2], vl);\n\n        vuint8m8_t v_eq_ab = vmseq_vv_u8m8_b8(v_a, v_b, vl);\n        vuint8m8_t v_eq_bc = vmseq_vv_u8m8_b8(v_b, v_c, vl);\n        vuint8m8_t v_eq_ac = vmseq_vv_u8m8_b8(v_a, v_c, vl);\n\n        vuint8m8_t v_all_eq = vmor_mm_b8(vmor_mm_b8(v_eq_ab, v_eq_bc), v_eq_ac);\n        if (vfirst_m_b8(v_all_eq, vl) != -1) return false;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_101_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nbool is_happy_simd(const std::string & s) {\n    size_t len = s.length();\n    if (len < 3) return false;\n\n    size_t vl = vsetvl_e8m1(len);\n    vuint8m1_t v_s = vle8_v_u8m1((const uint8_t*)s.data(), vl);\n\n    for (size_t i = 0; i < len - 2; ++i) {\n        vuint8m1_t v_a = vslide1down_vx_u8m1(v_s, s[i], vl);\n        vuint8m1_t v_b = vslide1down_vx_u8m1(v_a, s[i + 1], vl);\n        vuint8m1_t v_c = vslide1down_vx_u8m1(v_b, s[i + 2], vl);\n\n        vuint8m1_t v_eq_ab = vmseq_vv_u8m1_b8(v_a, v_b, vl);\n        vuint8m1_t v_eq_bc = vmseq_vv_u8m1_b8(v_b, v_c, vl);\n        vuint8m1_t v_eq_ac = vmseq_vv_u8m1_b8(v_a, v_c, vl);\n\n        vuint8m1_t v_all_diff = vmnor_mm_b8(vmnor_mm_b8(v_eq_ab, v_eq_bc, vl), v_eq_ac, vl);\n\n        if (vfirst_m_b8(v_all_diff, vl) == -1) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_102_RVV", "completion": "```c++\n#include <riscv_vector.h>\n#include <cmath>\n#include <string>\n\nbool prime_length_simd(const std::string & str) {\n    int length = str.length();\n    if (length <= 1) return false;\n    if (length == 2) return true;\n    if (length % 2 == 0) return false;\n\n    int limit = std::sqrt(length);\n    for (int i = 3; i <= limit; i += 2) {\n        if (length % i == 0) return false;\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_102_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nbool prime_length_simd(const std::string & str) {\n    size_t len = str.length();\n    if (len < 2) return false;\n\n    size_t sqrt_len = static_cast<size_t>(std::sqrt(len));\n    size_t vl = __riscv_vsetvl_e32m1(sqrt_len);\n\n    vint32m1_t v_i = __riscv_vid_v_i32m1(sqrt_len, 1);\n    vint32m1_t v_len = __riscv_vmv_v_x_i32m1(len, vl);\n\n    vint32m1_t v_div = __riscv_vdiv_vv_i32m1(v_len, v_i, vl);\n    vint32m1_t v_mul = __riscv_vmul_vv_i32m1(v_div, v_i, vl);\n    vint32m1_t v_cmp = __riscv_vmseq_vv_i32m1(v_mul, v_len, vl);\n\n    vint8mf8_t v_cmp_mask = __riscv_vmv_x_s_b8mf8(__riscv_vfirst_m_b8(v_cmp, vl), vl);\n    bool is_prime = __riscv_vcpop_m_b8(v_cmp_mask, vl) == 1;\n\n    return is_prime && len > 1;\n}\n```"}
{"task_id": "SimdBench_102_RVV", "completion": "```c++\n#include <riscv_vector.h>\n#include <string>\n\nbool prime_length_simd(const std::string & str) {\n    size_t len = str.length();\n    if (len < 2) return false;\n\n    size_t limit = static_cast<size_t>(std::sqrt(len));\n    size_t vl = vsetvl_e32m1(limit);\n\n    vint32m1_t v_i = vid_v_i32m1(2, vl);\n    vint32m1_t v_len = vbroadcast_vx_i32m1(len, vl);\n    vint32m1_t v_remainder = vrem_vv_i32m1(v_len, v_i, vl);\n\n    vint32m1_t v_zero = vmseq_vx_i32m1(v_remainder, 0, vl);\n    vint32m1_t v_one = vmseq_vx_i32m1(v_i, 1, vl);\n\n    vint32m1_t v_mask = vmandn_mm(v_zero, v_one, vl);\n    vint32m1_t v_result = vredand_vs_i32m1_b32(v_mask, true, vl);\n\n    return vresult_mask_i32m1(v_result);\n}\n```"}
{"task_id": "SimdBench_102_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nbool prime_length_simd(const std::string & str) {\n    size_t len = str.length();\n    if (len < 2) return false;\n\n    vint8m1_t v = __riscv_vsetivli(1, RVV_E8, RVV_M1);\n    vint8m1_t v_len = __riscv_vmv_v_x_i8m1(v, len, v);\n\n    vint8m1_t v_i = __riscv_vsetivli(len, RVV_E8, RVV_M1);\n    vint8m1_t v_range = __riscv_vid_v_u8m1(v_i, v);\n\n    vint8m1_t v_mod = __riscv_vrem_vv_u8m1(v_len, v_range, v);\n    vint8m1_t v_zero = __riscv_vmv_v_x_i8m1(v, 0, v);\n\n    vint8m1_t v_cmp = __riscv_vmseq_vx_u8m1_b8(v_mod, 0, v);\n    vint8m1_t v_cmp_mask = __riscv_vmv_v_x_i8m1(v, 1, v);\n\n    vint8m1_t v_and = __riscv_vand_vv_u8m1(v_cmp, v_cmp_mask, v);\n    vint8m1_t v_sum = __riscv_vredsum_vs_u8m1_u8m1(v_and, v_zero, v);\n\n    uint8_t sum = __riscv_vmv_x_s_u8m1_u8(v_sum);\n    return sum == 2;\n}\n```"}
{"task_id": "SimdBench_102_RVV", "completion": "```c++\nbool prime_length_simd(const std::string & str) {\n    size_t len = str.length();\n    if (len < 2) return false;\n\n    size_t sqrt_len = static_cast<size_t>(std::sqrt(len));\n    size_t vl = vsetvl_e32m1(len);\n\n    vint32m1_t v_indices = vid_v_i32m1(2, vl);\n    vint32m1_t v_len = vmv_v_x_i32m1(len, vl);\n\n    vint32m1_t v_remainder = vrem_vv_i32m1(v_len, v_indices, vl);\n    vint32m1_t v_zero = vmv_v_x_i32m1(0, vl);\n\n    vint32m1_t v_mask = vmseq_vv_i32m1(v_remainder, v_zero, vl);\n    vint32m1_t v_ones = vmv_v_x_i32m1(1, vl);\n\n    vint32m1_t v_sum = vredsum_vs_i32m1_i32m1(v_mask, v_ones, vl);\n\n    int sum = vmv_x_s_i32m1_i32(v_sum);\n    return sum == 2;\n}\n```"}
{"task_id": "SimdBench_103_RVV", "completion": "```c++\n#include <riscv_vector.h>\n#include <string>\n\nstd::string solve_simd(uint64_t N) {\n    // Convert the number to a string of binary digits\n    std::string binary_str;\n    while (N > 0) {\n        binary_str += (N % 2) ? '1' : '0';\n        N /= 2;\n    }\n\n    // Reverse the binary string to get the correct order\n    std::reverse(binary_str.begin(), binary_str.end());\n\n    // Convert the binary string to a vector of integers\n    size_t len = binary_str.size();\n    int32_t* binary_vec = new int32_t[len];\n    for (size_t i = 0; i < len; ++i) {\n        binary_vec[i] = binary_str[i] - '0';\n    }\n\n    // Use RVV intrinsics to sum the digits in parallel\n    size_t vl = __riscv_vsetvl_e32m1(len);\n    vint32m1_t v_binary = __riscv_vle32_v_i32m1(binary_vec, vl);\n    vint32m1_t v_sum = __riscv_vredsum_vs_i32m1_i32m1(v_binary, __riscv_vmv_v_x_i32m1(0, vl), vl);\n\n    // Extract the sum from the vector\n    int32_t sum = __riscv_vmv_x_s_i32m1_i32(v_sum);\n\n    // Convert the sum back to a binary string\n    std::string result;\n    while (sum > 0) {\n        result += (sum % 2) ? '1' : '0';\n        sum /= 2;\n    }\n\n    // Reverse the result string to get the correct order\n    std::reverse(result.begin(), result.end());\n\n    // Clean up\n    delete[] binary_vec;\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_103_RVV", "completion": "```c++\n#include <riscv_vector.h>\n#include <string>\n\nstd::string solve_simd(uint64_t N) {\n    // Convert the number to a string to process each digit\n    std::string num_str = std::to_string(N);\n    size_t len = num_str.length();\n\n    // Initialize the sum\n    uint64_t sum = 0;\n\n    // Process the digits in parallel using RVV intrinsics\n    for (size_t i = 0; i < len; i += sizeof(vuint64m1_t) / sizeof(char)) {\n        vuint64m1_t v_digits = vle8_v_u64m1(&num_str[i], sizeof(vuint64m1_t));\n        vuint64m1_t v_sum = vredsum_vs_u64m1(v_digits, v_sum, 0);\n        sum += vsum_v_u64m1_u64(v_sum);\n    }\n\n    // Convert the sum to binary string\n    std::string binary_str;\n    while (sum > 0) {\n        binary_str = (sum % 2 == 0 ? \"0\" : \"1\") + binary_str;\n        sum /= 2;\n    }\n\n    return binary_str.empty() ? \"0\" : binary_str;\n}\n```"}
{"task_id": "SimdBench_103_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nstd::string solve_simd(uint64_t N) {\n    // Initialize the sum to 0\n    uint64_t sum = 0;\n\n    // Process the number in chunks of 64 bits\n    while (N > 0) {\n        // Extract the lower 64 bits of N\n        uint64_t chunk = N & 0xFFFFFFFFFFFFFFFF;\n\n        // Create a vector of 64-bit elements\n        vuint64m1_t v_chunk = __riscv_vset_v_u64m1(chunk, 1);\n\n        // Create a vector of 1s\n        vuint64m1_t v_ones = __riscv_vset_v_u64m1(1, 1);\n\n        // Count the number of 1s in the chunk\n        vuint64m1_t v_count = __riscv_vcpop_m_u64m1(v_chunk, v_ones, 1);\n\n        // Reduce the count vector to a scalar\n        sum += __riscv_vredsum_vs_u64m1_u64m1(v_count, 0, 1);\n\n        // Shift N right by 64 bits\n        N >>= 64;\n    }\n\n    // Convert the sum to a binary string\n    std::string binary_str;\n    while (sum > 0) {\n        binary_str = (sum % 2 == 0 ? \"0\" : \"1\") + binary_str;\n        sum /= 2;\n    }\n\n    return binary_str.empty() ? \"0\" : binary_str;\n}\n```"}
{"task_id": "SimdBench_103_RVV", "completion": "```c++\n#include <riscv_vector.h>\n#include <string>\n\nstd::string solve_simd(uint64_t N) {\n    // Convert the number to a string to process each digit\n    std::string num_str = std::to_string(N);\n    size_t len = num_str.length();\n\n    // Initialize the sum\n    int sum = 0;\n\n    // Process the digits in parallel using RVV intrinsics\n    for (size_t i = 0; i < len; i += 8) {\n        size_t chunk_size = std::min(len - i, static_cast<size_t>(8));\n        uint8_t digits[8] = {0};\n\n        // Load digits into the vector\n        for (size_t j = 0; j < chunk_size; ++j) {\n            digits[j] = num_str[i + j] - '0';\n        }\n\n        // Create a vector from the digits\n        vuint8m1_t v_digits = __riscv_vle8_v_u8m1(digits, chunk_size);\n\n        // Sum the digits in the vector\n        vuint8m1_t v_sum = __riscv_vredsum_vs_u8m1_u8m1(v_digits, 0, chunk_size);\n\n        // Extract the sum from the vector\n        sum += __riscv_vmv_x_s_u8m1_u8(v_sum);\n    }\n\n    // Convert the sum to a binary string\n    std::string binary_str;\n    while (sum > 0) {\n        binary_str = (sum % 2 == 0 ? \"0\" : \"1\") + binary_str;\n        sum /= 2;\n    }\n\n    return binary_str.empty() ? \"0\" : binary_str;\n}\n```"}
{"task_id": "SimdBench_103_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nstd::string solve_simd(uint64_t N) {\n    // Initialize the sum to 0\n    uint64_t sum = 0;\n\n    // Process the number in chunks of 64 bits\n    while (N > 0) {\n        // Extract the lower 64 bits of N\n        uint64_t chunk = N & 0xFFFFFFFFFFFFFFFF;\n\n        // Create a vector of 64-bit elements\n        vuint64m1_t v_chunk = __riscv_vmv_v_x_u64m1(1, chunk);\n\n        // Create a vector of 1s\n        vuint64m1_t v_ones = __riscv_vmv_v_x_u64m1(1, 1);\n\n        // Count the number of 1s in the chunk\n        vuint64m1_t v_popcount = __riscv_vpopc_u64m1(v_chunk, v_ones);\n\n        // Reduce the vector to a scalar sum\n        sum += __riscv_vredsum_u64m1_u64m1(v_popcount);\n\n        // Shift N right by 64 bits\n        N >>= 64;\n    }\n\n    // Convert the sum to a binary string\n    std::string binary_str;\n    while (sum > 0) {\n        binary_str = (sum % 2 == 0 ? \"0\" : \"1\") + binary_str;\n        sum /= 2;\n    }\n\n    // Return the binary string\n    return binary_str.empty() ? \"0\" : binary_str;\n}\n```"}
{"task_id": "SimdBench_104_RVV", "completion": "```c++\nint add_simd(std::vector<int> lst) {\n    size_t n = lst.size();\n    int sum = 0;\n\n    if (n == 0) return sum;\n\n    size_t vl = __riscv_vsetvl_e32m1(n);\n    vint32m1_t v_indices = __riscv_vid_v_i32m1(vl, 0);\n    vint32m1_t v_even_mask = __riscv_vmsne_vx_i32m1_b32(v_indices, 0, vl);\n    vint32m1_t v_odd_indices_mask = __riscv_vmsne_vx_i32m1_b32(v_indices, 1, vl);\n\n    vint32m1_t v_lst = __riscv_vle32_v_i32m1(&lst[0], vl);\n    vint32m1_t v_even_odd_mask = __riscv_vmand_mm_b32(v_even_mask, v_odd_indices_mask, vl);\n    vint32m1_t v_even_odd_elements = __riscv_vmmerge_vx_i32m1(v_lst, 0, v_even_odd_mask, vl);\n\n    vint32m1_t v_sum = __riscv_vredsum_vs_i32m1_i32m1(v_even_odd_elements, v_sum, vl);\n\n    sum = __riscv_vmv_x_s_i32m1_i32(v_sum);\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_104_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nint add_simd(std::vector<int> lst) {\n    size_t n = lst.size();\n    int sum = 0;\n\n    if (n == 0) return sum;\n\n    size_t vl = __riscv_vsetvl_e32m1(n);\n    vint32m1_t v_lst = __riscv_vle32_v_i32m1(lst.data(), vl);\n\n    vint32m1_t v_indices = __riscv_vid_v_i32m1(vl);\n    vint32m1_t v_even_mask = __riscv_vmsne_vx_i32m1_b32(v_lst, 0, vl);\n    vint32m1_t v_odd_indices_mask = __riscv_vmsne_vx_i32m1_b32(v_indices, 0, vl);\n\n    vint32m1_t v_result_mask = __riscv_vmand_mm_b32(v_even_mask, v_odd_indices_mask, vl);\n    vint32m1_t v_result = __riscv_vmseq_vx_i32m1_b32(v_result_mask, 1, vl);\n\n    vint32m1_t v_sum = __riscv_vredsum_vs_i32m1_i32m1(v_lst, v_result, vl);\n\n    sum = __riscv_vmv_x_s_i32m1_i32(v_sum);\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_104_RVV", "completion": "```c++\nint add_simd(std::vector<int> lst) {\n    size_t n = lst.size();\n    int sum = 0;\n\n    if (n == 0) return sum;\n\n    size_t vl = __riscv_vsetvl_e32m1(n);\n    vint32m1_t v_lst = __riscv_vle32_v_i32m1(lst.data(), vl);\n\n    vint32m1_t v_indices = __riscv_vid_v_i32m1(vl);\n    vint32m1_t v_even_mask = __riscv_vmsne_vx_i32m1_b32(v_lst, 0, vl);\n    vint32m1_t v_odd_indices_mask = __riscv_vmsne_vx_i32m1_b32(v_indices, 0, vl);\n\n    vint32m1_t v_result_mask = __riscv_vmand_mm_b32(v_even_mask, v_odd_indices_mask, vl);\n    vint32m1_t v_result = __riscv_vmmerge_vx_i32m1(v_lst, 0, v_result_mask, vl);\n\n    sum = __riscv_vredsum_vs_i32m1_i32(v_result, sum, vl);\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_104_RVV", "completion": "```c++\nint add_simd(std::vector<int> lst) {\n    size_t n = lst.size();\n    int sum = 0;\n\n    if (n == 0) return sum;\n\n    size_t vl = __riscv_vsetvl_e32m1(n);\n    vint32m1_t v_indices = __riscv_vid_v_i32m1(vl, 0);\n    vint32m1_t v_even_mask = __riscv_vmsne_vx_i32m1_b32(v_indices, 0, vl);\n    vint32m1_t v_odd_indices_mask = __riscv_vmsne_vx_i32m1_b32(v_indices, 1, vl);\n\n    vint32m1_t v_lst = __riscv_vle32_v_i32m1(lst.data(), vl);\n    vint32m1_t v_even_odd_mask = __riscv_vmand_mm_b32(v_even_mask, v_odd_indices_mask, vl);\n    vint32m1_t v_even_odd_elements = __riscv_vmseq_vx_i32m1_b32(v_lst, 0, vl);\n\n    vint32m1_t v_sum = __riscv_vredsum_vs_i32m1_i32m1(v_even_odd_elements, v_sum, vl);\n\n    sum = __riscv_vmv_x_s_i32m1_i32(v_sum);\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_104_RVV", "completion": "```c++\nint add_simd(std::vector<int> lst) {\n    size_t n = lst.size();\n    int sum = 0;\n\n    if (n == 0) return sum;\n\n    size_t vl = __riscv_vsetvl_e32m1(n);\n    vint32m1_t v_lst = __riscv_vle32_v_i32m1(lst.data(), vl);\n\n    vint32m1_t v_indices = __riscv_vid_v_i32m1(vl);\n    vint32m1_t v_even_mask = __riscv_vmsne_vx_i32m1_b32(v_lst, 0, vl);\n    vint32m1_t v_odd_indices_mask = __riscv_vmsne_vx_i32m1_b32(v_indices, 0, vl);\n\n    vint32m1_t v_result_mask = __riscv_vmand_mm_b32(v_even_mask, v_odd_indices_mask, vl);\n    vint32m1_t v_result = __riscv_vmmerge_vx_i32m1(v_lst, 0, v_result_mask, vl);\n\n    sum = __riscv_vredsum_vs_i32m1_i32(v_result, sum, vl);\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_105_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nstd::string encrypt_simd(const std::string & s) {\n    size_t len = s.length();\n    std::string result(len, ' ');\n\n    // Define the vector size\n    size_t vl = __riscv_vsetvl_e8m1(len);\n\n    // Load the input string into a vector\n    vuint8m1_t v_input = __riscv_vle8_v_u8m1((const uint8_t*)s.data(), vl);\n\n    // Create a vector with the shift value (4)\n    vuint8m1_t v_shift = __riscv_vmv_v_x_u8m1(4, vl);\n\n    // Perform the shift operation\n    vuint8m1_t v_output = __riscv_vadd_vv_u8m1(v_input, v_shift, vl);\n\n    // Store the result back into the result string\n    __riscv_vse8_v_u8m1((uint8_t*)result.data(), v_output, vl);\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_105_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nstd::string encrypt_simd(const std::string & s) {\n    size_t len = s.length();\n    std::string result(len, ' ');\n\n    // Define the vector size\n    size_t vl = vsetvl_e8m8(len);\n\n    // Load the input string into a vector\n    vuint8m8_t input_vec = vle8_v_u8m8((const uint8_t*)s.data(), vl);\n\n    // Create a vector for the shift amount (4 in this case)\n    vuint8m8_t shift_vec = vmv_v_x_u8m8(4, vl);\n\n    // Perform the shift operation\n    vuint8m8_t result_vec = vadd_vv_u8m8(input_vec, shift_vec, vl);\n\n    // Store the result back into the result string\n    vse8_v_u8m8((uint8_t*)result.data(), result_vec, vl);\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_105_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nstd::string encrypt_simd(const std::string & s) {\n    size_t len = s.length();\n    std::string result(len, ' ');\n\n    size_t vl = __riscv_vsetvl_e8m1(len);\n\n    vuint8m1_t v_input = __riscv_vle8_v_u8m1((const uint8_t *)s.data(), vl);\n    vuint8m1_t v_shift = __riscv_vmv_v_x_u8m1(2 * 2, vl);\n    vuint8m1_t v_result = __riscv_vadd_vv_u8m1(v_input, v_shift, vl);\n\n    __riscv_vse8_v_u8m1((uint8_t *)result.data(), v_result, vl);\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_105_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nstd::string encrypt_simd(const std::string & s) {\n    size_t len = s.length();\n    std::string result(len, ' ');\n\n    size_t vl = __riscv_vsetvl_e8m1(len);\n\n    vuint8m1_t v_input = __riscv_vle8_v_u8m1((const uint8_t*)s.data(), vl);\n    vuint8m1_t v_shift = __riscv_vmv_v_x_u8m1(4, vl);\n    vuint8m1_t v_result = __riscv_vadd_vv_u8m1(v_input, v_shift, vl);\n\n    __riscv_vse8_v_u8m1((uint8_t*)result.data(), v_result, vl);\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_105_RVV", "completion": "```c++\n#include <riscv_vector.h>\n#include <string>\n\nstd::string encrypt_simd(const std::string & s) {\n    size_t len = s.length();\n    std::string result(len, ' ');\n\n    size_t vl = __riscv_vsetvl_e8m1(len);\n\n    vuint8m1_t v_input = __riscv_vle8_v_u8m1((const uint8_t*)s.data(), vl);\n    vuint8m1_t v_shift = __riscv_vmv_v_x_u8m1(2 * 2, vl);\n    vuint8m1_t v_result = __riscv_vadd_vv_u8m1(v_input, v_shift, vl);\n\n    __riscv_vse8_v_u8m1((uint8_t*)result.data(), v_result, vl);\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_106_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nstd::string encode_simd(const std::string &message) {\n    size_t len = message.size();\n    std::string result(len, ' ');\n\n    // Define masks and vectors for parallel processing\n    const vint8m1_t lower_mask = __riscv_vmv_v_x_i8m1(0x20, len);\n    const vint8m1_t upper_mask = __riscv_vmv_v_x_i8m1(0xDF, len);\n    const vint8m1_t vowel_mask = __riscv_vmv_v_x_i8m1(0x00, len);\n    const vint8m1_t vowel_replacement = __riscv_vmv_v_x_i8m1(0x00, len);\n\n    // Load the message into a vector\n    vint8m1_t msg_vec = __riscv_vle8_v_i8m1((const int8_t*)message.c_str(), len);\n\n    // Swap case\n    vint8m1_t case_swapped = __riscv_vxor_vv_i8m1(msg_vec, lower_mask, len);\n\n    // Identify vowels and replace them\n    vint8m1_t is_vowel = __riscv_vmseq_vx_i8m1_b8(vowel_mask, msg_vec, len);\n    vint8m1_t replaced_vowels = __riscv_vadd_vv_i8m1(case_swapped, vowel_replacement, len);\n    vint8m1_t final_vec = __riscv_vmerge_vvm_i8m1(case_swapped, replaced_vowels, is_vowel, len);\n\n    // Store the result back into the result string\n    __riscv_vse8_v_i8m1((int8_t*)result.data(), final_vec, len);\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_106_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nstd::string encode_simd(const std::string & message) {\n    size_t len = message.length();\n    std::string result(len, ' ');\n\n    // Define the vowel replacement map\n    const char vowels[] = \"aeiouAEIOU\";\n    const char replacements[] = \"cgikqCGIKQ\";\n\n    // Create vectors for the message and result\n    vuint8m1_t v_message = __riscv_vle8_v_u8m1((const uint8_t*)message.data(), len, 1);\n    vuint8m1_t v_result = __riscv_vle8_v_u8m1((const uint8_t*)result.data(), len, 1);\n\n    // Swap case\n    vuint8m1_t v_lower = __riscv_vand_vx_u8m1(v_message, 0x20, 1);\n    vuint8m1_t v_upper = __riscv_vand_vx_u8m1(v_message, ~0x20, 1);\n    vuint8m1_t v_swapped = __riscv_vmerge_vvm_u8m1(v_lower, v_upper, __riscv_vmsbf_m_u8m1(1), 1);\n\n    // Replace vowels\n    vuint8m1_t v_vowels = __riscv_vle8_v_u8m1((const uint8_t*)vowels, sizeof(vowels) - 1, 1);\n    vuint8m1_t v_replacements = __riscv_vle8_v_u8m1((const uint8_t*)replacements, sizeof(replacements) - 1, 1);\n\n    vuint8m1_t v_mask = __riscv_vmsne_vx_u8m1(v_swapped, 0, 1);\n    vuint8m1_t v_replaced = __riscv_vrgather_vv_u8m1(v_replacements, v_swapped, v_mask, 1);\n\n    // Store the result\n    __riscv_vse8_v_u8m1((uint8_t*)result.data(), v_replaced, len, 1);\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_106_RVV", "completion": "```c++\n#include <riscv_vector.h>\n#include <string>\n\nstd::string encode_simd(const std::string & message) {\n    size_t len = message.length();\n    std::string result(len, ' ');\n\n    // Define the vowel replacement map\n    const char vowels[] = \"aeiouAEIOU\";\n    const char replacements[] = \"cgikqCGIKQ\";\n\n    // Create vectors for vowels and replacements\n    vuint8m1_t v_vowels = __riscv_vle8_v_u8m1(vowels, 10, 10);\n    vuint8m1_t v_replacements = __riscv_vle8_v_u8m1(replacements, 10, 10);\n\n    // Process the message in chunks\n    for (size_t i = 0; i < len; i += 32) {\n        size_t chunk_size = std::min(len - i, (size_t)32);\n        vuint8m1_t v_message = __riscv_vle8_v_u8m1(&message[i], chunk_size, chunk_size);\n\n        // Swap case\n        vuint8m1_t v_lower = __riscv_vand_vx_u8m1(v_message, 0xDF, chunk_size);\n        vuint8m1_t v_upper = __riscv_vor_vx_u8m1(v_message, 0x20, chunk_size);\n        vuint8m1_t v_swapped = __riscv_vmerge_vvm_u8m1(__riscv_vmslt_vx_u8m1(v_message, 'a', chunk_size),\n                                                        v_upper, v_lower, chunk_size);\n\n        // Replace vowels\n        vuint8m1_t v_mask = __riscv_vmseq_vv_u8m1(v_swapped, v_vowels, chunk_size);\n        vuint8m1_t v_replaced = __riscv_vmerge_vvm_u8m1(v_mask, v_replacements, v_swapped, chunk_size);\n\n        // Store the result\n        __riscv_vse8_v_u8m1(&result[i], v_replaced, chunk_size);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_106_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nstd::string encode_simd(const std::string & message) {\n    size_t len = message.length();\n    std::string result(len, ' ');\n\n    // Define the vowel replacement map\n    const char vowels[] = \"aeiouAEIOU\";\n    const char replacements[] = \"cgikqCGIKQ\";\n\n    // Create vectors for the message and result\n    vuint8m1_t v_message = __riscv_vle8_v_u8m1((const uint8_t*)message.data(), len, 1);\n    vuint8m1_t v_result = __riscv_vle8_v_u8m1((const uint8_t*)result.data(), len, 1);\n\n    // Swap case\n    vuint8m1_t v_lower = __riscv_vand_vx_u8m1(v_message, 0x20, 1);\n    vuint8m1_t v_upper = __riscv_vand_vx_u8m1(v_message, ~0x20, 1);\n    vuint8m1_t v_swapped = __riscv_vmerge_vvm_u8m1(v_lower, v_upper, v_message, 1);\n\n    // Replace vowels\n    vuint8m1_t v_vowels = __riscv_vle8_v_u8m1((const uint8_t*)vowels, sizeof(vowels) - 1, 1);\n    vuint8m1_t v_replacements = __riscv_vle8_v_u8m1((const uint8_t*)replacements, sizeof(replacements) - 1, 1);\n\n    vuint8m1_t v_mask = __riscv_vmseq_vx_u8m1_b8(v_swapped, 'a', 1);\n    for (size_t i = 1; i < sizeof(vowels) - 1; ++i) {\n        v_mask = __riscv_vmor_vx_u8m1_b8(v_mask, __riscv_vmseq_vx_u8m1_b8(v_swapped, vowels[i], 1), 1);\n    }\n\n    v_result = __riscv_vmerge_vvm_u8m1(v_swapped, v_replacements, v_mask, 1);\n\n    // Store the result back to the string\n    __riscv_vse8_v_u8m1((uint8_t*)result.data(), v_result, len, 1);\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_106_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nstd::string encode_simd(const std::string & message) {\n    size_t len = message.size();\n    std::string result(len, ' ');\n\n    // Define the vowel replacement map\n    const char vowels[] = \"aeiouAEIOU\";\n    const char replacements[] = \"cgikqCGIKQ\";\n\n    // Create vectors for input and output\n    vuint8m1_t v_message = __riscv_vle8_v_u8m1((const uint8_t*)message.data(), len, 1);\n    vuint8m1_t v_result = __riscv_vle8_v_u8m1((const uint8_t*)result.data(), len, 1);\n\n    // Swap case\n    vuint8m1_t v_lower = __riscv_vand_vx_u8m1(v_message, 0x20, 1);\n    vuint8m1_t v_upper = __riscv_vand_vx_u8m1(v_message, ~0x20, 1);\n    vuint8m1_t v_swapped = __riscv_vmerge_vvm_u8m1(v_lower, v_upper, __riscv_vmsbf_m_b1(1), 1);\n\n    // Replace vowels\n    vuint8m1_t v_vowels = __riscv_vle8_v_u8m1((const uint8_t*)vowels, 12, 1);\n    vuint8m1_t v_replacements = __riscv_vle8_v_u8m1((const uint8_t*)replacements, 12, 1);\n\n    for (size_t i = 0; i < 12; ++i) {\n        vuint8m1_t v_match = __riscv_vmseq_vx_u8m1_b1(v_swapped, vowels[i], 1);\n        v_swapped = __riscv_vmerge_vvm_u8m1(v_swapped, v_replacements, v_match, 1);\n    }\n\n    // Store the result\n    __riscv_vse8_v_u8m1((uint8_t*)result.data(), v_swapped, len, 1);\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_107_RVV", "completion": "```c++\nbool check_dict_case_simd(std::map<std::string, std::string> dict) {\n    if (dict.empty()) return false;\n\n    size_t n = dict.size();\n    std::vector<char> keys;\n    keys.reserve(n);\n\n    for (const auto& pair : dict) {\n        keys.push_back(pair.first[0]);\n    }\n\n    size_t vl = __riscv_vsetvl_e8m1(n);\n    vuint8m1_t v_keys = __riscv_vle8_v_u8m1(keys.data(), vl);\n\n    vuint8m1_t v_lower = __riscv_vmv_v_x_u8m1('a', vl);\n    vuint8m1_t v_upper = __riscv_vmv_v_x_u8m1('A', vl);\n\n    vuint8m1_t v_lower_mask = __riscv_vmsltu_vx_u8m1_b8(v_keys, v_lower, vl);\n    vuint8m1_t v_upper_mask = __riscv_vmsltu_vx_u8m1_b8(v_keys, v_upper, vl);\n\n    bool all_lower = __riscv_vcpop_m_b8(v_lower_mask, vl) == n;\n    bool all_upper = __riscv_vcpop_m_b8(v_upper_mask, vl) == n;\n\n    return all_lower || all_upper;\n}\n```"}
{"task_id": "SimdBench_107_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <map>\n#include <string>\n\nbool check_dict_case_simd(std::map<std::string, std::string> dict) {\n    if (dict.empty()) {\n        return false;\n    }\n\n    size_t n = dict.size();\n    std::string keys[n];\n    size_t i = 0;\n    for (const auto& pair : dict) {\n        keys[i++] = pair.first;\n    }\n\n    size_t vl = vsetvl_e8m8(n);\n    vuint8m8_t lower_mask = vmv_v_x_u8m8(0, vl);\n    vuint8m8_t upper_mask = vmv_v_x_u8m8(0, vl);\n\n    for (i = 0; i < n; i += vl) {\n        vl = vsetvl_e8m8(n - i);\n        vuint8m8_t v_keys = vle8_v_u8m8(&keys[i][0], vl);\n        vuint8m8_t is_lower = vand_mm_u8m8(v_keys, vmv_v_x_u8m8(0x20, vl), vl);\n        vuint8m8_t is_upper = vand_mm_u8m8(v_keys, vmv_v_x_u8m8(0x40, vl), vl);\n\n        lower_mask = vor_mm_u8m8(lower_mask, is_lower, vl);\n        upper_mask = vor_mm_u8m8(upper_mask, is_upper, vl);\n    }\n\n    bool all_lower = vmsbf_m_u8m8_b8(lower_mask);\n    bool all_upper = vmsbf_m_u8m8_b8(upper_mask);\n\n    return all_lower || all_upper;\n}\n```"}
{"task_id": "SimdBench_107_RVV", "completion": "```c++\nbool check_dict_case_simd(std::map<std::string, std::string> dict) {\n    if (dict.empty()) {\n        return false;\n    }\n\n    size_t n = dict.size();\n    std::vector<char> keys;\n    keys.reserve(n);\n\n    for (const auto& pair : dict) {\n        keys.push_back(pair.first[0]);\n    }\n\n    size_t vl = __riscv_vsetvl_e8m1(n);\n    vuint8m1_t v_keys = __riscv_vle8_v_u8m1(keys.data(), vl);\n\n    vuint8m1_t v_lower = __riscv_vand_vx_u8m1(v_keys, 0x20, vl);\n    vuint8m1_t v_upper = __riscv_vand_vx_u8m1(v_keys, 0x40, vl);\n\n    vuint8m1_t v_all_lower = __riscv_vredand_vs_u8m1_u8m1(v_lower, 0x20, vl);\n    vuint8m1_t v_all_upper = __riscv_vredand_vs_u8m1_u8m1(v_upper, 0x40, vl);\n\n    bool all_lower = __riscv_vmv_x_s_u8m1_u8(v_all_lower);\n    bool all_upper = __riscv_vmv_x_s_u8m1_u8(v_all_upper);\n\n    return all_lower || all_upper;\n}\n```"}
{"task_id": "SimdBench_107_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <map>\n#include <string>\n\nbool check_dict_case_simd(std::map<std::string, std::string> dict) {\n    if (dict.empty()) return false;\n\n    size_t n = dict.size();\n    std::string keys[n];\n    size_t i = 0;\n    for (const auto& pair : dict) {\n        keys[i++] = pair.first;\n    }\n\n    size_t vl = __riscv_vsetvl_e8m8(n);\n    vuint8m8_t lower = __riscv_vmv_v_x_u8m8(0, vl);\n    vuint8m8_t upper = __riscv_vmv_v_x_u8m8(0, vl);\n\n    for (i = 0; i < n; i += vl) {\n        vl = __riscv_vsetvl_e8m8(n - i);\n        vuint8m8_t vkeys = __riscv_vle8_v_u8m8((const uint8_t*)keys[i].c_str(), vl);\n        vuint8m8_t is_lower = __riscv_vmseq_vx_u8m8_b8(vkeys, 'a', vl);\n        vuint8m8_t is_upper = __riscv_vmseq_vx_u8m8_b8(vkeys, 'A', vl);\n        lower = __riscv_vmand_mm_b8(lower, is_lower, vl);\n        upper = __riscv_vmand_mm_b8(upper, is_upper, vl);\n    }\n\n    bool all_lower = __riscv_vmv_x_s_b8(__riscv_vmand_mm_b8(lower, lower, vl));\n    bool all_upper = __riscv_vmv_x_s_b8(__riscv_vmand_mm_b8(upper, upper, vl));\n\n    return all_lower || all_upper;\n}\n```"}
{"task_id": "SimdBench_107_RVV", "completion": "```c++\nbool check_dict_case_simd(std::map<std::string, std::string> dict) {\n    if (dict.empty()) return false;\n\n    size_t n = dict.size();\n    std::vector<char> keys;\n    keys.reserve(n);\n\n    for (const auto& pair : dict) {\n        keys.push_back(pair.first[0]);\n    }\n\n    size_t vl = __riscv_vsetvl_e8m1(n);\n    vuint8m1_t v_keys = __riscv_vle8_v_u8m1(keys.data(), vl);\n\n    vuint8m1_t v_lower = __riscv_vmv_v_x_u8m1('a', vl);\n    vuint8m1_t v_upper = __riscv_vmv_v_x_u8m1('A', vl);\n\n    vuint8m1_t v_lower_mask = __riscv_vmsltu_vx_u8m1_b8(v_keys, 'a', vl);\n    vuint8m1_t v_upper_mask = __riscv_vmsltu_vx_u8m1_b8(v_keys, 'A', vl);\n\n    vuint8m1_t v_all_lower = __riscv_vmand_mm_b8(v_lower_mask, v_lower_mask, vl);\n    vuint8m1_t v_all_upper = __riscv_vmand_mm_b8(v_upper_mask, v_upper_mask, vl);\n\n    bool all_lower = __riscv_vmv_x_s_u8m1_b8(v_all_lower);\n    bool all_upper = __riscv_vmv_x_s_u8m1_b8(v_all_upper);\n\n    return all_lower || all_upper;\n}\n```"}
{"task_id": "SimdBench_108_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> count_up_to_simd(int n) {\n    std::vector<int> primes;\n    if (n <= 2) return primes;\n\n    size_t vl = __riscv_vsetvl_e32m1(n);\n    vint32m1_t v_indices = __riscv_vid_v_i32m1(vl);\n    vint32m1_t v_ones = __riscv_vmv_v_x_i32m1(1, vl);\n    vint32m1_t v_primes = __riscv_vmv_v_x_i32m1(1, vl);\n\n    for (int i = 2; i < n; ++i) {\n        vint32m1_t v_i = __riscv_vmv_v_x_i32m1(i, vl);\n        vint32m1_t v_mod = __riscv_vrem_vv_i32m1(v_indices, v_i, vl);\n        vint32m1_t v_is_prime = __riscv_vmseq_vx_i32m1_b32(v_mod, 0, vl);\n        v_primes = __riscv_vand_vv_i32m1(v_primes, v_is_prime, vl, vl);\n    }\n\n    for (int i = 2; i < n; ++i) {\n        if (__riscv_vmv_x_s_i32m1_i32(v_primes) == 1) {\n            primes.push_back(i);\n        }\n        v_primes = __riscv_vslideup_vx_i32m1(v_primes, v_primes, 1, vl);\n    }\n\n    return primes;\n}\n```"}
{"task_id": "SimdBench_108_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> count_up_to_simd(int n) {\n    std::vector<int> primes;\n    if (n <= 2) return primes;\n\n    int size = (n + 7) / 8;\n    int8_t* is_prime = new int8_t[size];\n    for (int i = 0; i < size; ++i) {\n        is_prime[i] = -1; // All bits set to 1\n    }\n\n    is_prime[0] &= ~1; // 0 is not prime\n    is_prime[0] &= ~2; // 1 is not prime\n\n    for (int i = 2; i * i < n; ++i) {\n        if (is_prime[i / 8] & (1 << (i % 8))) {\n            for (int j = i * i; j < n; j += i) {\n                is_prime[j / 8] &= ~(1 << (j % 8));\n            }\n        }\n    }\n\n    for (int i = 2; i < n; ++i) {\n        if (is_prime[i / 8] & (1 << (i % 8))) {\n            primes.push_back(i);\n        }\n    }\n\n    delete[] is_prime;\n    return primes;\n}\n```"}
{"task_id": "SimdBench_108_RVV", "completion": "```c++\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> count_up_to_simd(int n) {\n    std::vector<int> primes;\n    if (n <= 2) return primes;\n\n    size_t vl = __riscv_vsetvl_e32m1(n);\n    vint32m1_t v_indices = __riscv_vid_v_i32m1(vl, 0);\n    vint32m1_t v_n = __riscv_vmv_v_x_i32m1(n, vl);\n    vint32m1_t v_ones = __riscv_vmv_v_x_i32m1(1, vl);\n    vint32m1_t v_zeros = __riscv_vmv_v_x_i32m1(0, vl);\n\n    vint32m1_t v_is_prime = __riscv_vmv_v_x_i32m1(1, vl);\n    v_is_prime = __riscv_vslideup_vx_i32m1(v_is_prime, 0, vl);\n    v_is_prime = __riscv_vslideup_vx_i32m1(v_is_prime, 0, vl);\n\n    for (int i = 2; i * i < n; ++i) {\n        vint32m1_t v_i = __riscv_vmv_v_x_i32m1(i, vl);\n        vint32m1_t v_multiple = __riscv_vmul_vv_i32m1(v_i, v_indices, vl);\n        vint32m1_t v_mask = __riscv_vmslt_vv_i32m1(v_multiple, v_n, vl);\n        vint32m1_t v_update = __riscv_vand_vv_i32m1(v_mask, v_zeros, vl);\n        v_is_prime = __riscv_vand_vv_i32m1(v_is_prime, v_update, vl);\n    }\n\n    vint32m1_t v_prime_indices = __riscv_vcompress_vm_i32m1(v_is_prime, v_indices, vl);\n    size_t prime_count = __riscv_vcpop_m_i32m1(v_is_prime, vl);\n\n    primes.resize(prime_count);\n    __riscv_vse32_v_i32m1(primes.data(), v_prime_indices, prime_count);\n\n    return primes;\n}\n```"}
{"task_id": "SimdBench_108_RVV", "completion": "```c++\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> count_up_to_simd(int n) {\n    std::vector<int> primes;\n    if (n <= 2) return primes;\n\n    size_t vl = __riscv_vsetvl_e32m1(n);\n    vint32m1_t v_indices = __riscv_vid_v_i32m1(vl, 0);\n    vint32m1_t v_n = __riscv_vmv_v_x_i32m1(n, vl);\n    vint32m1_t v_is_prime = __riscv_vmv_v_x_i32m1(1, vl);\n\n    for (int i = 2; i * i < n; ++i) {\n        vint32m1_t v_i = __riscv_vmv_v_x_i32m1(i, vl);\n        vint32m1_t v_mod = __riscv_vrem_vv_i32m1(v_indices, v_i, vl);\n        vint32m1_t v_eq_zero = __riscv_vmseq_vx_i32m1_b32(v_mod, 0, vl);\n        vint32m1_t v_gt_i = __riscv_vmsgt_vx_i32m1_b32(v_indices, i, vl);\n        vint32m1_t v_mask = __riscv_vmand_mm_b32(v_eq_zero, v_gt_i, vl);\n        v_is_prime = __riscv_vmandn_mm_b32(v_is_prime, v_mask, vl);\n    }\n\n    for (int i = 2; i < n; ++i) {\n        if (__riscv_vmv_x_s_i32m1_b32(v_is_prime, i)) {\n            primes.push_back(i);\n        }\n    }\n\n    return primes;\n}\n```"}
{"task_id": "SimdBench_108_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> count_up_to_simd(int n) {\n    std::vector<int> primes;\n    if (n <= 2) return primes;\n\n    size_t vl = vsetvlmax_e32m1();\n    vint32m1_t v_indices = vid_v_i32m1(2, vl);\n    vint32m1_t v_n = vmv_v_x_i32m1(n, vl);\n    vint32m1_t v_ones = vmv_v_x_i32m1(1, vl);\n    vint32m1_t v_zeros = vmv_v_x_i32m1(0, vl);\n\n    while (vle32_v_i32m1_tu(v_indices, &v_indices, vl) != 0) {\n        vint32m1_t v_is_prime = vmv_v_x_i32m1(1, vl);\n        vint32m1_t v_i = v_indices;\n\n        for (int i = 2; i * i <= n; ++i) {\n            vint32m1_t v_i_mod = vrem_vv_i32m1(v_i, vmv_v_x_i32m1(i, vl), vl);\n            v_is_prime = vand_vv_i32m1(v_is_prime, vmsne_vv_i32m1(v_i_mod, v_zeros, vl), vl);\n        }\n\n        vint32m1_t v_prime_indices = vmv_v_v_i32m1(v_i, vl);\n        v_prime_indices = vand_vv_i32m1(v_prime_indices, v_is_prime, vl);\n\n        for (int i = 0; i < vl; ++i) {\n            if (v_prime_indices[i] != 0 && v_prime_indices[i] < n) {\n                primes.push_back(v_prime_indices[i]);\n            }\n        }\n\n        v_indices = vadd_vv_i32m1(v_indices, vmv_v_x_i32m1(vl, vl), vl);\n    }\n\n    return primes;\n}\n```"}
{"task_id": "SimdBench_109_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nint count_upper_simd(const std::string & s) {\n    size_t len = s.length();\n    int count = 0;\n\n    if (len == 0) return 0;\n\n    size_t vl = __riscv_vsetvl_e8m1(len);\n    vuint8m1_t v_uppercase = __riscv_vmv_v_x_u8m1('A', vl);\n    vuint8m1_t v_lowercase = __riscv_vmv_v_x_u8m1('Z', vl);\n    vuint8m1_t v_vowels = __riscv_vmv_v_x_u8m1('A', vl);\n    vuint8m1_t v_even_indices = __riscv_vmv_v_x_u8m1(0, vl);\n\n    for (size_t i = 0; i < len; i += vl) {\n        vl = __riscv_vsetvl_e8m1(len - i);\n        vuint8m1_t v_str = __riscv_vle8_v_u8m1((const uint8_t*)&s[i], vl);\n        vuint8m1_t v_mask = __riscv_vmseq_vv_u8m1_b8(v_str, v_vowels, vl);\n        v_mask = __riscv_vmand_mm_b8(v_mask, __riscv_vmseq_vv_u8m1_b8(v_str, v_uppercase, vl), vl);\n        v_mask = __riscv_vmand_mm_b8(v_mask, __riscv_vmseq_vv_u8m1_b8(v_str, v_lowercase, vl), vl);\n        v_mask = __riscv_vmand_mm_b8(v_mask, __riscv_vmseq_vv_u8m1_b8(v_even_indices, __riscv_vmv_v_x_u8m1(i % 2, vl), vl), vl);\n        count += __riscv_vcpop_m_b8(v_mask, vl);\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_109_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nint count_upper_simd(const std::string & s) {\n    const char* str = s.c_str();\n    size_t len = s.length();\n\n    vint8m1_t v_uppercase = __riscv_vset_v_i8m1(0x41, 0x45, 0x49, 0x4F, 0x55, 0, 0, 0);\n    vint8m1_t v_even_mask = __riscv_vset_v_i8m1(0xFF, 0, 0xFF, 0, 0xFF, 0, 0xFF, 0);\n\n    vint8m1_t v_str = __riscv_vle8_v_i8m1((int8_t*)str, len, 1);\n    vint8m1_t v_masked_str = __riscv_vand_vv_i8m1(v_str, v_even_mask, len);\n\n    vint8m1_t v_is_upper = __riscv_vmseq_vv_i8m1_b8(v_masked_str, v_uppercase, len);\n    vint8m1_t v_is_vowel = __riscv_vmseq_vv_i8m1_b8(v_masked_str, v_uppercase, len);\n\n    vint8m1_t v_result = __riscv_vand_vv_i8m1(v_is_upper, v_is_vowel, len);\n    int count = __riscv_vcpop_m_b8(v_result, len);\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_109_RVV", "completion": "```c++\nint count_upper_simd(const std::string & s) {\n    size_t len = s.length();\n    size_t vl = vsetvl_e8m1(len);\n\n    vuint8m1_t vec_str = vle8_v_u8m1((const uint8_t*)s.c_str(), vl);\n    vuint8m1_t vec_indices = vid_v_u8m1(0, 1, vl);\n    vuint8m1_t vec_even_indices = vand_vv_u8m1(vec_indices, 1, vl);\n\n    vuint8m1_t vec_upper_vowels = vand_vv_u8m1(vec_str, vec_even_indices, vl);\n    vuint8m1_t vec_mask = vmseq_vx_u8m1_b8(vec_upper_vowels, 'A', vl);\n    vec_mask = vmseq_vx_u8m1_b8(vec_upper_vowels, 'E', vl);\n    vec_mask = vmseq_vx_u8m1_b8(vec_upper_vowels, 'I', vl);\n    vec_mask = vmseq_vx_u8m1_b8(vec_upper_vowels, 'O', vl);\n    vec_mask = vmseq_vx_u8m1_b8(vec_upper_vowels, 'U', vl);\n\n    vint8m1_t vec_count = vpopc_m_b8(vec_mask, vl);\n\n    int count = 0;\n    for (size_t i = 0; i < vl; ++i) {\n        count += vec_count[i];\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_109_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nint count_upper_simd(const std::string & s) {\n    size_t len = s.length();\n    int count = 0;\n\n    if (len == 0) return 0;\n\n    size_t vl = __riscv_vsetvl_e8m1(len);\n    vuint8m1_t v_uppercase = __riscv_vmv_v_x_u8m1('A', vl);\n    vuint8m1_t v_lowercase = __riscv_vmv_v_x_u8m1('Z', vl);\n    vuint8m1_t v_even_indices = __riscv_vmv_v_x_u8m1(0, vl);\n\n    for (size_t i = 0; i < len; i += vl) {\n        vl = __riscv_vsetvl_e8m1(len - i);\n        vuint8m1_t v_str = __riscv_vle8_v_u8m1(&s[i], vl);\n\n        vuint8m1_t v_is_upper = __riscv_vmseq_vv_u8m1_b8(v_str, v_uppercase, vl);\n        vuint8m1_t v_is_lower = __riscv_vmsle_vv_u8m1_b8(v_str, v_lowercase, vl);\n        vuint8m1_t v_is_vowel = __riscv_vmand_mm_b8(v_is_upper, v_is_lower, vl);\n\n        vuint8m1_t v_is_even = __riscv_vmand_mm_b8(v_even_indices, v_is_vowel, vl);\n        count += __riscv_vcpop_m_b8(v_is_even, vl);\n\n        v_even_indices = __riscv_vmv_v_x_u8m1((i + vl) % 2, vl);\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_109_RVV", "completion": "```c++\nint count_upper_simd(const std::string & s) {\n    size_t len = s.length();\n    int count = 0;\n\n    // Define the vector length\n    size_t vl = __riscv_vsetvl_e8m1(len);\n\n    // Load the string into a vector\n    vuint8m1_t vec = __riscv_vle8_v_u8m1((const uint8_t*)s.c_str(), vl);\n\n    // Create a mask for even indices\n    vuint8m1_t mask = __riscv_vid_v_u8m1(vl);\n    mask = __riscv_vand_vx_u8m1(mask, 1, vl);\n\n    // Create a vector of uppercase vowels\n    vuint8m1_t vowels = __riscv_vmv_v_x_u8m1('A', vl);\n    vowels = __riscv_vslideup_vx_u8m1(vowels, 'E', vl);\n    vowels = __riscv_vslideup_vx_u8m1(vowels, 'I', vl);\n    vowels = __riscv_vslideup_vx_u8m1(vowels, 'O', vl);\n    vowels = __riscv_vslideup_vx_u8m1(vowels, 'U', vl);\n\n    // Compare the string with the vowels vector\n    vuint8m1_t cmp = __riscv_vmseq_vv_u8m1(vec, vowels, vl);\n\n    // Apply the mask to only consider even indices\n    cmp = __riscv_vand_vv_u8m1(cmp, mask, vl);\n\n    // Count the number of true values in the comparison result\n    count = __riscv_vcpop_m_u8m1(cmp, vl);\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_110_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> make_a_pile_simd(int n) {\n    std::vector<int> result(n);\n    size_t vl = vsetvl_e32m1(n);\n\n    vint32m1_t vindex = vid_v_i32m1(0, 1, vl);\n    vint32m1_t vbase = vadd_vx_i32m1(vindex, n, vl);\n    vint32m1_t vstep = vmv_v_x_i32m1(2, vl);\n\n    vint32m1_t vodd = vand_vx_i32m1(vbase, 1, vl);\n    vint32m1_t veven = vsub_vx_i32m1(vbase, 1, vl);\n\n    vint32m1_t vresult = vmerge_vvm_i32m1(vodd, veven, vodd, vl);\n\n    vstore_v_i32m1(result.data(), vresult, vl);\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_110_RVV", "completion": "```c++\nstd::vector<int> make_a_pile_simd(int n) {\n    std::vector<int> result(n);\n    size_t vl = __riscv_vsetvl_e32m1(n);\n\n    vint32m1_t vindex = __riscv_vid_v_i32m1(vl);\n    vint32m1_t vstart = __riscv_vmv_v_x_i32m1(n, vl);\n    vint32m1_t vone = __riscv_vmv_v_x_i32m1(1, vl);\n    vint32m1_t vtwo = __riscv_vmv_v_x_i32m1(2, vl);\n\n    vint32m1_t vlevels = __riscv_vadd_vv_i32m1(vstart, __riscv_vmul_vv_i32m1(vindex, vone), vl);\n    vint32m1_t vodd = __riscv_vand_vv_i32m1(vlevels, vone, vl);\n    vint32m1_t veven = __riscv_vsub_vv_i32m1(vtwo, vodd, vl);\n\n    vint32m1_t vnext = __riscv_vadd_vv_i32m1(vlevels, __riscv_vadd_vv_i32m1(vodd, veven, vl), vl);\n\n    __riscv_vse32_v_i32m1(result.data(), vnext, vl);\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_110_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> make_a_pile_simd(int n) {\n    std::vector<int> result(n);\n    size_t vl = vsetvl_e32m1(n);\n\n    vint32m1_t vindex = vid_v_i32m1(0, 1, vl);\n    vint32m1_t vstart = vadd_vx_i32m1(vindex, n - 1, vl);\n    vint32m1_t vstep = vmv_v_x_i32m1((n % 2 == 0) ? 2 : 1, vl);\n    vint32m1_t vresult = vmul_vv_i32m1(vstart, vstep, vl);\n\n    vsetvl_e32m1(n);\n    vse32_v_i32m1(result.data(), vresult, vl);\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_110_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> make_a_pile_simd(int n) {\n    std::vector<int> result(n);\n    size_t vl = vsetvl_e32m1(n);\n\n    vint32m1_t vindex = vid_v_i32m1(0, 1, vl);\n    vint32m1_t vstart = vadd_vx_i32m1(vindex, n, vl);\n\n    vint32m1_t vstep;\n    if (n % 2 == 0) {\n        vstep = vid_v_i32m1(2, 2, vl);\n    } else {\n        vstep = vid_v_i32m1(1, 2, vl);\n    }\n\n    vint32m1_t vresult = vadd_vv_i32m1(vstart, vstep, vl);\n\n    vint32m1_t vresult_masked = vmseq_vx_i32m1_b32(vindex, n, vl);\n    vresult = vmerge_vvm_i32m1(vresult, vresult, vresult_masked, vl);\n\n    vse32_v_i32m1(result.data(), vresult, vl);\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_110_RVV", "completion": "```c++\nstd::vector<int> make_a_pile_simd(int n) {\n    std::vector<int> result(n);\n    size_t vl = __riscv_vsetvl_e32m1(n);\n\n    vint32m1_t vindex = __riscv_vid_v_i32m1(vl);\n    vint32m1_t vstart = __riscv_vmv_v_x_i32m1(n, vl);\n    vint32m1_t vone = __riscv_vmv_v_x_i32m1(1, vl);\n    vint32m1_t vtwo = __riscv_vmv_v_x_i32m1(2, vl);\n\n    vint32m1_t vstep = __riscv_vadd_vv_i32m1(vone, __riscv_vand_mm_b32(__riscv_vmsne_vx_i32m1_b32(vstart, 0), vone, vl), vl);\n    vint32m1_t vlevels = __riscv_vadd_vv_i32m1(vstart, __riscv_vmul_vv_i32m1(vindex, vstep, vl), vl);\n\n    __riscv_vse32_v_i32m1(result.data(), vlevels, vl);\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_111_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nstd::string rounded_avg_simd(int64_t n, int64_t m) {\n    if (n > m) {\n        return \"-1\";\n    }\n\n    int64_t sum = 0;\n    int64_t count = m - n + 1;\n\n    vint64m1_t v_n = __riscv_vmv_v_x_i64m1(n, count);\n    vint64m1_t v_m = __riscv_vmv_v_x_i64m1(m, count);\n    vint64m1_t v_seq = __riscv_vid_v_i64m1(count);\n    vint64m1_t v_sum = __riscv_vadd_vv_i64m1(v_n, v_seq, count);\n\n    sum = __riscv_vredsum_vs_i64m1_i64(sum, v_sum, count);\n\n    int64_t avg = sum / count;\n    std::string binary = \"\";\n\n    while (avg > 0) {\n        binary = (avg % 2 == 0 ? \"0\" : \"1\") + binary;\n        avg /= 2;\n    }\n\n    return binary.empty() ? \"0\" : binary;\n}\n```"}
{"task_id": "SimdBench_111_RVV", "completion": "```c++\n#include <riscv_vector.h>\n#include <string>\n\nstd::string rounded_avg_simd(int64_t n, int64_t m) {\n    if (n > m) {\n        return \"-1\";\n    }\n\n    int64_t count = m - n + 1;\n    int64_t sum = 0;\n\n    size_t vl = __riscv_vsetvl_e64m1(count);\n    vint64m1_t v_n = __riscv_vmv_v_x_i64m1(n, vl);\n    vint64m1_t v_m = __riscv_vmv_v_x_i64m1(m, vl);\n    vint64m1_t v_count = __riscv_vmv_v_x_i64m1(count, vl);\n\n    vint64m1_t v_range = __riscv_vslideup_vx_i64m1(v_n, 1, vl);\n    vint64m1_t v_sum = __riscv_vredsum_vs_i64m1_i64m1(v_range, v_sum, vl);\n\n    sum = __riscv_vmv_x_s_i64m1_i64(v_sum);\n\n    int64_t avg = (sum + count / 2) / count;\n\n    std::string binary = \"\";\n    while (avg > 0) {\n        binary = std::to_string(avg % 2) + binary;\n        avg /= 2;\n    }\n\n    return binary.empty() ? \"0\" : binary;\n}\n```"}
{"task_id": "SimdBench_111_RVV", "completion": "```c++\n#include <riscv_vector.h>\n#include <string>\n\nstd::string rounded_avg_simd(int64_t n, int64_t m) {\n    if (n > m) {\n        return \"-1\";\n    }\n\n    int64_t count = m - n + 1;\n    int64_t sum = 0;\n\n    size_t vl = __riscv_vsetvl_e64m1(count);\n    vint64m1_t v_n = __riscv_vmv_v_x_i64m1(n, vl);\n    vint64m1_t v_m = __riscv_vmv_v_x_i64m1(m, vl);\n    vint64m1_t v_count = __riscv_vmv_v_x_i64m1(count, vl);\n\n    vint64m1_t v_range = __riscv_vslideup_vx_i64m1(v_n, 1, vl);\n    vint64m1_t v_sum = __riscv_vredsum_vs_i64m1_i64m1(v_range, v_sum, vl);\n\n    sum = __riscv_vmv_x_s_i64m1_i64(v_sum);\n\n    int64_t avg = sum / count;\n    int64_t rounded_avg = (sum + count / 2) / count;\n\n    std::string binary = \"\";\n    while (rounded_avg > 0) {\n        binary = (rounded_avg % 2 == 0 ? \"0\" : \"1\") + binary;\n        rounded_avg /= 2;\n    }\n\n    return binary.empty() ? \"0\" : binary;\n}\n```"}
{"task_id": "SimdBench_111_RVV", "completion": "```c++\n#include <riscv_vector.h>\n#include <string>\n\nstd::string rounded_avg_simd(int64_t n, int64_t m) {\n    if (n > m) {\n        return \"-1\";\n    }\n\n    int64_t count = m - n + 1;\n    int64_t sum = 0;\n\n    size_t vl = __riscv_vsetvl_e64m1(count);\n    vint64m1_t v_n = __riscv_vmv_v_x_i64m1(n, vl);\n    vint64m1_t v_m = __riscv_vmv_v_x_i64m1(m, vl);\n    vint64m1_t v_count = __riscv_vmv_v_x_i64m1(count, vl);\n\n    vint64m1_t v_range = __riscv_vslideup_vx_i64m1(v_n, 1, vl);\n    vint64m1_t v_sum = __riscv_vredsum_vs_i64m1_i64m1(v_range, v_sum, vl);\n\n    sum = __riscv_vmv_x_s_i64m1_i64(v_sum);\n\n    int64_t avg = (sum + count / 2) / count;\n\n    std::string binary = \"\";\n    while (avg > 0) {\n        binary = (avg % 2 == 0 ? \"0\" : \"1\") + binary;\n        avg /= 2;\n    }\n\n    return binary.empty() ? \"0\" : binary;\n}\n```"}
{"task_id": "SimdBench_111_RVV", "completion": "```c++\n#include <riscv_vector.h>\n#include <string>\n\nstd::string rounded_avg_simd(int64_t n, int64_t m) {\n    if (n > m) {\n        return \"-1\";\n    }\n\n    int64_t count = m - n + 1;\n    int64_t sum = 0;\n\n    size_t vl = __riscv_vsetvl_e64m1(count);\n    vint64m1_t v_n = __riscv_vmv_v_x_i64m1(n, vl);\n    vint64m1_t v_m = __riscv_vmv_v_x_i64m1(m, vl);\n    vint64m1_t v_count = __riscv_vmv_v_x_i64m1(count, vl);\n\n    vint64m1_t v_range = __riscv_vslideup_vx_i64m1(v_n, 1, vl);\n    vint64m1_t v_sum = __riscv_vredsum_vs_i64m1_i64m1(v_range, v_sum, vl);\n\n    sum = __riscv_vmv_x_s_i64m1_i64(v_sum);\n\n    int64_t avg = (sum + count / 2) / count;\n\n    std::string binary = \"\";\n    while (avg > 0) {\n        binary = (avg % 2 == 0 ? \"0\" : \"1\") + binary;\n        avg /= 2;\n    }\n\n    return binary.empty() ? \"0\" : binary;\n}\n```"}
{"task_id": "SimdBench_112_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> func_simd(int n) {\n    std::vector<int> result(n);\n    size_t vl = __riscv_vsetvl_e32m1(n);\n\n    vint32m1_t vindex = __riscv_vid_v_i32m1(vl, 1);\n    vint32m1_t veven_mask = __riscv_vmsne_vx_i32m1_b32(vindex, 0, vl);\n    vint32m1_t vfactorial = __riscv_vmv_v_x_i32m1(1, vl);\n    vint32m1_t vsum = __riscv_vmv_v_x_i32m1(0, vl);\n\n    for (int i = 1; i <= n; ++i) {\n        vint32m1_t vtemp = __riscv_vmv_v_x_i32m1(i, vl);\n        vfactorial = __riscv_vmul_vv_i32m1(vfactorial, vtemp, vl);\n        vsum = __riscv_vadd_vv_i32m1(vsum, vtemp, vl);\n\n        vint32m1_t vresult = __riscv_vmerge_vvm_i32m1(vfactorial, vsum, veven_mask, vl);\n        vresult = __riscv_vrem_vx_i32m1(vresult, 10000, vl);\n\n        __riscv_vse32_v_i32m1(&result[i - 1], vresult, vl);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_112_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> func_simd(int n) {\n    std::vector<int> result(n);\n    size_t vl = vsetvl_e32m1(n);\n\n    vint32m1_t vindex = vid_v_i32m1(1, 1, vl);\n    vint32m1_t vone = vid_v_i32m1(1, 1, vl);\n    vint32m1_t vmod = vid_v_i32m1(10000, 1, vl);\n    vint32m1_t vsum = vmv_v_x_i32m1(0, vl);\n    vint32m1_t vfact = vmv_v_x_i32m1(1, vl);\n\n    for (int i = 0; i < n; i += vl) {\n        vl = vsetvl_e32m1(n - i);\n\n        vint32m1_t veven = vmseq_vv_i32m1_b32(vand_vv_i32m1(vindex, vone, vl), vone, vl);\n        vint32m1_t vfactorial = vmv_v_v_i32m1(vfact, vl);\n        vint32m1_t vsummation = vmv_v_v_i32m1(vsum, vl);\n\n        for (int j = 2; j <= n; ++j) {\n            vint32m1_t vj = vmv_v_x_i32m1(j, vl);\n            vfactorial = vmul_vv_i32m1(vfactorial, vj, vl);\n            vsummation = vadd_vv_i32m1(vsummation, vj, vl);\n        }\n\n        vint32m1_t vresult = vmerge_vvm_i32m1(vfactorial, vsummation, veven, vl);\n        vresult = vrem_vv_i32m1(vresult, vmod, vl);\n\n        vse32_v_i32m1(&result[i], vresult, vl);\n        vindex = vadd_vv_i32m1(vindex, vone, vl);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_112_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> func_simd(int n) {\n    std::vector<int> result(n);\n    size_t vl = __riscv_vsetvl_e32m1(n);\n\n    vint32m1_t vindex = __riscv_vid_v_i32m1(vl, 1);\n    vint32m1_t veven_mask = __riscv_vmsne_vx_i32m1_b32(vindex, 0, vl);\n    vint32m1_t vfactorial = __riscv_vmv_v_x_i32m1(1, vl);\n    vint32m1_t vsum = __riscv_vmv_v_x_i32m1(0, vl);\n\n    for (int i = 1; i <= n; ++i) {\n        vsum = __riscv_vadd_vv_i32m1(vsum, vindex, vl);\n        vfactorial = __riscv_vmul_vv_i32m1(vfactorial, vindex, vl);\n        vindex = __riscv_vadd_vx_i32m1(vindex, 1, vl);\n    }\n\n    vint32m1_t vresult = __riscv_vmerge_vvm_i32m1(vfactorial, vsum, veven_mask, vl);\n    vresult = __riscv_vrem_vx_i32m1(vresult, 10000, vl);\n\n    __riscv_vse32_v_i32m1(result.data(), vresult, vl);\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_112_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> func_simd(int n) {\n    std::vector<int> result(n);\n    size_t vl = __riscv_vsetvl_e32m1(n);\n\n    vint32m1_t vindex = __riscv_vid_v_i32m1(vl, 1);\n    vint32m1_t veven_mask = __riscv_vmsne_vx_i32m1_b32(vindex, 0, vl);\n    vint32m1_t vfactorial = __riscv_vmv_v_x_i32m1(1, vl);\n    vint32m1_t vsum = __riscv_vmv_v_x_i32m1(0, vl);\n\n    for (int i = 1; i <= n; ++i) {\n        vsum = __riscv_vadd_vv_i32m1(vsum, vindex, vl);\n        vfactorial = __riscv_vmul_vv_i32m1(vfactorial, vindex, vl);\n        vindex = __riscv_vadd_vx_i32m1(vindex, 1, vl);\n    }\n\n    vint32m1_t vresult = __riscv_vmerge_vvm_i32m1(vfactorial, vsum, veven_mask, vl);\n    vresult = __riscv_vrem_vx_i32m1(vresult, 10000, vl);\n\n    __riscv_vse32_v_i32m1(result.data(), vresult, vl);\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_112_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> func_simd(int n) {\n    std::vector<int> result(n);\n    size_t vl = __riscv_vsetvl_e32m1(n);\n\n    vint32m1_t vindex = __riscv_vid_v_i32m1(vl, 1);\n    vint32m1_t veven_mask = __riscv_vmsne_vx_i32m1_b32(vindex, 0, vl);\n    vint32m1_t vfactorial = __riscv_vmv_v_x_i32m1(1, vl);\n    vint32m1_t vsum = __riscv_vmv_v_x_i32m1(0, vl);\n\n    for (int i = 1; i <= n; ++i) {\n        vsum = __riscv_vadd_vv_i32m1(vsum, vindex, vl);\n        vfactorial = __riscv_vmul_vv_i32m1(vfactorial, vindex, vl);\n        vindex = __riscv_vadd_vx_i32m1(vindex, 1, vl);\n    }\n\n    vint32m1_t vresult = __riscv_vmerge_vvm_i32m1(vfactorial, vsum, veven_mask, vl);\n    vresult = __riscv_vrem_vx_i32m1(vresult, 10000, vl);\n\n    __riscv_vse32_v_i32m1(result.data(), vresult, vl);\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_113_RVV", "completion": "```c++\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> even_odd_palindrome_simd(int n) {\n    int even_count = 0;\n    int odd_count = 0;\n\n    // Create a vector of integers from 1 to n\n    size_t vl = vsetvl_e32m1(n);\n    vint32m1_t v = vid_v_i32m1(1, vl);\n\n    // Check if each number is a palindrome\n    for (int i = 1; i <= n; ++i) {\n        int num = i;\n        int reversed = 0;\n        int temp = num;\n\n        while (temp != 0) {\n            reversed = reversed * 10 + temp % 10;\n            temp /= 10;\n        }\n\n        if (num == reversed) {\n            if (num % 2 == 0) {\n                even_count++;\n            } else {\n                odd_count++;\n            }\n        }\n    }\n\n    return {even_count, odd_count};\n}\n```"}
{"task_id": "SimdBench_113_RVV", "completion": "```c++\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> even_odd_palindrome_simd(int n) {\n    size_t vl = vsetvl_e32m1(n);\n    vint32m1_t v_indices = vid_v_i32m1(0, 1, vl);\n    vint32m1_t v_palindromes = vadd_vv_i32m1(v_indices, v_indices, vl);\n\n    vint32m1_t v_even_mask = vmseq_vx_i32m1_b32(v_palindromes, 0, vl);\n    vint32m1_t v_odd_mask = vmseq_vx_i32m1_b32(v_palindromes, 1, vl);\n\n    vint32m1_t v_even_count = vredsum_vs_i32m1_i32m1(v_even_mask, v_even_mask, vl);\n    vint32m1_t v_odd_count = vredsum_vs_i32m1_i32m1(v_odd_mask, v_odd_mask, vl);\n\n    int even_count = vfirst_m(v_even_count, vl);\n    int odd_count = vfirst_m(v_odd_count, vl);\n\n    return {even_count, odd_count};\n}\n```"}
{"task_id": "SimdBench_113_RVV", "completion": "```c++\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> even_odd_palindrome_simd(int n) {\n    int even_count = 0;\n    int odd_count = 0;\n\n    // Create a vector of integers from 1 to n\n    size_t vl = vsetvl_e32m1(n);\n    vint32m1_t v_indices = vid_v_i32m1(1, vl);\n    vint32m1_t v_n = vid_v_i32m1(n, vl);\n\n    // Check if each number is a palindrome\n    for (int i = 1; i <= n; ++i) {\n        int num = i;\n        int reversed = 0;\n        int temp = num;\n\n        while (temp != 0) {\n            reversed = reversed * 10 + temp % 10;\n            temp /= 10;\n        }\n\n        if (num == reversed) {\n            if (num % 2 == 0) {\n                even_count++;\n            } else {\n                odd_count++;\n            }\n        }\n    }\n\n    return {even_count, odd_count};\n}\n```"}
{"task_id": "SimdBench_113_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> even_odd_palindrome_simd(int n) {\n    size_t vl = vsetvl_e32m1(n);\n    vint32m1_t v_indices = vid_v_i32m1(1, 1, vl);\n    vint32m1_t v_n = vmv_v_x_i32m1(n, vl);\n\n    vint32m1_t v_even_count = vmv_v_x_i32m1(0, vl);\n    vint32m1_t v_odd_count = vmv_v_x_i32m1(0, vl);\n\n    for (int i = 1; i <= n; ++i) {\n        vint32m1_t v_i = vmv_v_x_i32m1(i, vl);\n        vint32m1_t v_reversed = vreverse_v_i32m1(v_i, vl);\n        vint32m1_t v_is_palindrome = vmsne_vv_i32m1_b32(v_i, v_reversed, vl);\n\n        vint32m1_t v_is_even = vmseq_vx_i32m1_b32(v_i, 0, vl);\n        vint32m1_t v_is_odd = vmsne_vx_i32m1_b32(v_i, 0, vl);\n\n        v_even_count = vadd_vv_i32m1(v_even_count, vand_vv_i32m1(v_is_palindrome, v_is_even, vl), vl);\n        v_odd_count = vadd_vv_i32m1(v_odd_count, vand_vv_i32m1(v_is_palindrome, v_is_odd, vl), vl);\n    }\n\n    int even_count = vredsum_vs_i32m1_i32(v_even_count, 0, vl);\n    int odd_count = vredsum_vs_i32m1_i32(v_odd_count, 0, vl);\n\n    return {even_count, odd_count};\n}\n```"}
{"task_id": "SimdBench_113_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> even_odd_palindrome_simd(int n) {\n    int even_count = 0;\n    int odd_count = 0;\n\n    // Create a vector of integers from 1 to n\n    size_t vl = vsetvl_e32m1(n);\n    vuint32m1_t v_indices = vid_v_u32m1(vl);\n    vuint32m1_t v_n = vadd_vx_u32m1(v_indices, 1, vl);\n\n    // Check if each number is a palindrome\n    vuint32m1_t v_palindromes = vmseq_vv_u32m1(v_n, vrev_v_u32m1(v_n, vl), vl);\n\n    // Check if each palindrome is even or odd\n    vuint32m1_t v_even = vmseq_vx_u32m1(v_n, 0, vl);\n    vuint32m1_t v_odd = vmseq_vx_u32m1(v_n, 1, vl);\n\n    // Count the number of even and odd palindromes\n    vuint32m1_t v_even_palindromes = vand_vv_u32m1(v_palindromes, v_even, vl);\n    vuint32m1_t v_odd_palindromes = vand_vv_u32m1(v_palindromes, v_odd, vl);\n\n    even_count = vsum_vs_u32m1_u32m1(v_even_palindromes, 0, vl);\n    odd_count = vsum_vs_u32m1_u32m1(v_odd_palindromes, 0, vl);\n\n    return {even_count, odd_count};\n}\n```"}
{"task_id": "SimdBench_114_RVV", "completion": "```c++\nint count_nums_simd(std::vector<int> n) {\n    size_t vl = __riscv_vsetvl_e32m1(n.size());\n    vint32m1_t v_nums = __riscv_vle32_v_i32m1(n.data(), vl);\n    vint32m1_t v_zeros = __riscv_vmv_v_x_i32m1(0, vl);\n    vint32m1_t v_ones = __riscv_vmv_v_x_i32m1(1, vl);\n    vint32m1_t v_mask = __riscv_vmseq_vv_i32m1_b32(v_nums, v_zeros, vl);\n    vint32m1_t v_result = __riscv_vmv_v_v_i32m1(v_ones, vl);\n    v_result = __riscv_vmerge_vvm_i32m1(v_zeros, v_result, v_mask, vl);\n    vint32m1_t v_sum = __riscv_vredsum_vs_i32m1_i32m1(v_result, v_zeros, vl);\n    return __riscv_vmv_x_s_i32m1_i32(v_sum);\n}\n```"}
{"task_id": "SimdBench_114_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nint count_nums_simd(std::vector<int> n) {\n    size_t len = n.size();\n    if (len == 0) return 0;\n\n    vint32m1_t v_nums = __riscv_vle32_v_i32m1(n.data(), len);\n    vint32m1_t v_ones = __riscv_vmv_v_x_i32m1(1, len);\n    vint32m1_t v_zeros = __riscv_vmv_v_x_i32m1(0, len);\n    vint32m1_t v_ten = __riscv_vmv_v_x_i32m1(10, len);\n    vint32m1_t v_sum = v_zeros;\n\n    for (int i = 0; i < 10; ++i) {\n        vint32m1_t v_digit = __riscv_vrem_vv_i32m1(v_nums, v_ten, len);\n        v_sum = __riscv_vadd_vv_i32m1(v_sum, v_digit, len);\n        v_nums = __riscv_vdiv_vv_i32m1(v_nums, v_ten, len);\n    }\n\n    vint32m1_t v_abs_sum = __riscv_vabs_v_i32m1(v_sum, len);\n    vint32m1_t v_mask = __riscv_vmsgt_vx_i32m1_b32(v_abs_sum, 0, len);\n    int count = __riscv_vcpop_m_b32(v_mask, len);\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_114_RVV", "completion": "```c++\nint count_nums_simd(std::vector<int> n) {\n    size_t vl = __riscv_vsetvl_e32m1(n.size());\n    vint32m1_t v_nums = __riscv_vle32_v_i32m1(n.data(), vl);\n\n    vint32m1_t v_abs_nums = __riscv_vabs_v_i32m1(v_nums, vl);\n    vint32m1_t v_digits_sum = __riscv_vmv_v_x_i32m1(0, vl);\n\n    for (int i = 0; i < 10; ++i) {\n        vint32m1_t v_digits = __riscv_vremu_vv_i32m1(v_abs_nums, __riscv_vmv_v_x_i32m1(10, vl), vl);\n        v_digits_sum = __riscv_vadd_vv_i32m1(v_digits_sum, v_digits, vl);\n        v_abs_nums = __riscv_vdivu_vv_i32m1(v_abs_nums, __riscv_vmv_v_x_i32m1(10, vl), vl);\n    }\n\n    vint32m1_t v_neg_mask = __riscv_vslt_vx_i32m1_b32(v_nums, 0, vl);\n    vint32m1_t v_neg_digits = __riscv_vsub_vv_i32m1(__riscv_vmv_v_x_i32m1(0, vl), __riscv_vand_vv_i32m1(v_nums, v_neg_mask, vl), vl);\n    v_digits_sum = __riscv_vadd_vv_i32m1(v_digits_sum, v_neg_digits, vl);\n\n    vint32m1_t v_gt_zero_mask = __riscv_vsgt_vx_i32m1_b32(v_digits_sum, 0, vl);\n    int count = __riscv_vcpop_m(v_gt_zero_mask, vl);\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_114_RVV", "completion": "```c++\nint count_nums_simd(std::vector<int> n) {\n    size_t vl = __riscv_vsetvl_e32m1(n.size());\n    vint32m1_t v_nums = __riscv_vle32_v_i32m1(n.data(), vl);\n    vint32m1_t v_ones = __riscv_vmv_v_x_i32m1(1, vl);\n    vint32m1_t v_zeros = __riscv_vmv_v_x_i32m1(0, vl);\n    vint32m1_t v_neg_ones = __riscv_vmv_v_x_i32m1(-1, vl);\n    vint32m1_t v_abs_nums = __riscv_vmerge_vvm_i32m1(v_nums, v_neg_ones, __riscv_vmslt_vv_i32m1_b32(v_nums, v_zeros), vl);\n    vint32m1_t v_sum_digits = v_zeros;\n    vint32m1_t v_temp = v_abs_nums;\n\n    while (__riscv_vfirst_m_b32(__riscv_vmsne_vv_i32m1_b32(v_temp, v_zeros, vl))) {\n        vint32m1_t v_digit = __riscv_vremu_vv_i32m1(v_temp, v_ones, vl);\n        v_sum_digits = __riscv_vadd_vv_i32m1(v_sum_digits, v_digit, vl);\n        v_temp = __riscv_vdivu_vv_i32m1(v_temp, v_ones, vl);\n    }\n\n    vint32m1_t v_mask = __riscv_vmsgt_vv_i32m1_b32(v_sum_digits, v_zeros, vl);\n    return __riscv_vcpop_m_b32(v_mask, vl);\n}\n```"}
{"task_id": "SimdBench_114_RVV", "completion": "```c++\nint count_nums_simd(std::vector<int> n) {\n    size_t vl = vsetvlmax_e32m1();\n    vint32m1_t v_nums = vle32_v_i32m1(n.data(), vl);\n    vint32m1_t v_ones = vmv_v_x_i32m1(1, vl);\n    vint32m1_t v_zeros = vmv_v_x_i32m1(0, vl);\n    vint32m1_t v_sum = vmv_v_x_i32m1(0, vl);\n    vint32m1_t v_count = vmv_v_x_i32m1(0, vl);\n\n    for (size_t i = 0; i < n.size(); i += vl) {\n        vl = vsetvl_e32m1(n.size() - i);\n        v_nums = vle32_v_i32m1(n.data() + i, vl);\n        vint32m1_t v_abs_nums = vabs_v_i32m1(v_nums, vl);\n        vint32m1_t v_digits = vremu_vv_i32m1(v_abs_nums, v_ones, vl);\n        vint32m1_t v_sum_digits = vadd_vv_i32m1(v_sum, v_digits, vl);\n        vint32m1_t v_cond = vmsgt_vx_i32m1_b32(v_sum_digits, 0, vl);\n        v_count = vadd_vv_i32m1(v_count, v_cond, vl);\n    }\n\n    vint32m1_t v_result = vredsum_vs_i32m1_i32m1(v_zeros, v_count, vl);\n    return vmv_x_s_i32m1_i32(v_result);\n}\n```"}
{"task_id": "SimdBench_115_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nbool move_one_ball_simd(std::vector<int> arr) {\n    size_t N = arr.size();\n    if (N == 0) return true;\n\n    vint32m1_t v_arr = __riscv_vle32_v_i32m1(arr.data(), N, N);\n    vint32m1_t v_sorted = __riscv_vsort_v_i32m1(v_arr, N, N);\n\n    for (size_t i = 0; i < N; ++i) {\n        vint32m1_t v_shifted = __riscv_vslideup_vx_i32m1(v_arr, 1, N);\n        if (__riscv_vreinterpret_vm1_i32(__riscv_vmsne_vv_i32m1_b32(v_shifted, v_sorted, N))) {\n            return false;\n        }\n        v_arr = v_shifted;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_115_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <algorithm>\n\nbool move_one_ball_simd(std::vector<int> arr) {\n    size_t n = arr.size();\n    if (n == 0) return true;\n\n    vint32m1_t v_arr = __riscv_vle32_v_i32m1(arr.data(), n, n);\n    vint32m1_t v_sorted = __riscv_vle32_v_i32m1(arr.data(), n, n);\n    __riscv_vsort_v_i32m1(v_sorted, v_sorted, n, 0);\n\n    for (size_t i = 0; i < n; ++i) {\n        vint32m1_t v_shifted = __riscv_vslideup_vx_i32m1(v_arr, v_arr, 1, n);\n        if (__riscv_vreduc_and_i32m1(__riscv_vmsne_vv_i32m1_b32(v_shifted, v_sorted, n), n)) {\n            return false;\n        }\n        v_arr = v_shifted;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_115_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nbool move_one_ball_simd(std::vector<int> arr) {\n    size_t N = arr.size();\n    if (N == 0) return true;\n\n    int* data = arr.data();\n    size_t vl = __riscv_vsetvl_e32m1(N);\n\n    vint32m1_t vdata = __riscv_vle32_v_i32m1(data, vl);\n    vint32m1_t vsorted = __riscv_vslideup_vx_i32m1(vdata, vdata, 1, vl);\n\n    for (size_t i = 0; i < N; ++i) {\n        if (__riscv_vmv_x_s_i32m1_i32(vsorted) > __riscv_vmv_x_s_i32m1_i32(vdata)) {\n            return false;\n        }\n        vsorted = __riscv_vslideup_vx_i32m1(vsorted, vsorted, 1, vl);\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_115_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nbool move_one_ball_simd(std::vector<int> arr) {\n    size_t N = arr.size();\n    if (N == 0) return true;\n\n    vint32m1_t v_arr = __riscv_vle32_v_i32m1(arr.data(), N, N);\n    vint32m1_t v_sorted = __riscv_vsort_v_i32m1(v_arr, N, N);\n\n    for (size_t i = 0; i < N; ++i) {\n        vint32m1_t v_shifted = __riscv_vslideup_vx_i32m1(v_arr, 1, N);\n        v_arr = v_shifted;\n\n        if (__riscv_vreduc_vm_i32m1_b(__riscv_vmsne_vv_i32m1_b(v_arr, v_sorted, N), N)) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_115_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nbool move_one_ball_simd(std::vector<int> arr) {\n    size_t N = arr.size();\n    if (N == 0) return true;\n\n    vint32m1_t v_arr = __riscv_vle32_v_i32m1(arr.data(), N, N);\n    vint32m1_t v_sorted = __riscv_vsort_v_i32m1(v_arr, N, 1);\n\n    for (size_t i = 0; i < N; ++i) {\n        vint32m1_t v_shifted = __riscv_vslideup_vx_i32m1(v_arr, v_arr, 1, N);\n        if (__riscv_vreduc_and_i32m1(__riscv_vmsne_vv_i32m1_b32(v_shifted, v_sorted, N), N)) {\n            return false;\n        }\n        v_arr = v_shifted;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_116_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <string>\n\nstd::string myexchange_simd(const std::vector<int>& lst1, const std::vector<int>& lst2) {\n    size_t n = lst1.size();\n    vint32m1_t v_lst1 = __riscv_vle32_v_i32m1(lst1.data(), n);\n    vint32m1_t v_lst2 = __riscv_vle32_v_i32m1(lst2.data(), n);\n\n    vint32m1_t v_even_mask = __riscv_vmseq_vx_i32m1_b32(v_lst1, 0, n);\n    vint32m1_t v_odd_mask = __riscv_vmsne_vx_i32m1_b32(v_lst1, 0, n);\n\n    vint32m1_t v_even_lst2 = __riscv_vcompress_vm(v_lst2, v_even_mask, n);\n    vint32m1_t v_odd_lst2 = __riscv_vcompress_vm(v_lst2, v_odd_mask, n);\n\n    size_t even_count_lst2 = __riscv_vcpop_m(v_even_mask, n);\n    size_t odd_count_lst2 = __riscv_vcpop_m(v_odd_mask, n);\n\n    vint32m1_t v_odd_lst1 = __riscv_vcompress_vm(v_lst1, v_odd_mask, n);\n\n    size_t odd_count_lst1 = __riscv_vcpop_m(v_odd_mask, n);\n\n    if (odd_count_lst1 <= even_count_lst2) {\n        return \"YES\";\n    } else {\n        return \"NO\";\n    }\n}\n```"}
{"task_id": "SimdBench_116_RVV", "completion": "```c++\n#include <riscv_vector.h>\n#include <vector>\n#include <string>\n\nstd::string myexchange_simd(const std::vector<int>& lst1, const std::vector<int>& lst2) {\n    size_t n = lst1.size();\n    vint32m1_t v_lst1 = __riscv_vle32_v_i32m1(lst1.data(), n);\n    vint32m1_t v_lst2 = __riscv_vle32_v_i32m1(lst2.data(), n);\n\n    vint32m1_t v_even_mask = __riscv_vand_vx_i32m1_bm(v_lst1, 1, __riscv_vmv_v_x_i32m1_bm(0));\n    vint32m1_t v_odd_mask = __riscv_vsub_vv_i32m1(v_lst1, v_even_mask, __riscv_vmv_v_x_i32m1_bm(1));\n\n    vint32m1_t v_lst2_even_mask = __riscv_vand_vx_i32m1_bm(v_lst2, 1, __riscv_vmv_v_x_i32m1_bm(0));\n    vint32m1_t v_lst2_odd_mask = __riscv_vsub_vv_i32m1(v_lst2, v_lst2_even_mask, __riscv_vmv_v_x_i32m1_bm(1));\n\n    vint32m1_t v_odd_in_lst1 = __riscv_vand_vv_i32m1_bm(v_lst1, v_odd_mask, __riscv_vmv_v_x_i32m1_bm(1));\n    vint32m1_t v_even_in_lst2 = __riscv_vand_vv_i32m1_bm(v_lst2, v_lst2_even_mask, __riscv_vmv_v_x_i32m1_bm(1));\n\n    vint32m1_t v_can_exchange = __riscv_vand_vv_i32m1_bm(v_odd_in_lst1, v_even_in_lst2, __riscv_vmv_v_x_i32m1_bm(1));\n\n    bool can_exchange = __riscv_vmv_x_s_i32m1_bm(__riscv_vfirst_m_bm(v_can_exchange, __riscv_vmv_v_x_i32m1_bm(1)));\n\n    return can_exchange ? \"YES\" : \"NO\";\n}\n```"}
{"task_id": "SimdBench_116_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <string>\n\nstd::string myexchange_simd(const std::vector<int>& lst1, const std::vector<int>& lst2) {\n    size_t n = lst1.size();\n    size_t vl = vsetvl_e32m1(n);\n\n    vint32m1_t v_lst1 = vle32_v_i32m1(&lst1[0], vl);\n    vint32m1_t v_lst2 = vle32_v_i32m1(&lst2[0], vl);\n\n    vint32m1_t v_even_mask = vmseq_vx_i32m1_b32(v_lst1, 0, vl);\n    vint32m1_t v_odd_mask = vmsne_vx_i32m1_b32(v_lst1, 0, vl);\n\n    vint32m1_t v_even_lst1 = vcompress_vm(v_lst1, v_even_mask, vl);\n    vint32m1_t v_odd_lst1 = vcompress_vm(v_lst1, v_odd_mask, vl);\n\n    vint32m1_t v_even_lst2 = vcompress_vm(v_lst2, v_even_mask, vl);\n    vint32m1_t v_odd_lst2 = vcompress_vm(v_lst2, v_odd_mask, vl);\n\n    size_t even_count_lst1 = vpopc_m_b32(v_even_mask, vl);\n    size_t odd_count_lst1 = vpopc_m_b32(v_odd_mask, vl);\n\n    size_t even_count_lst2 = vpopc_m_b32(v_even_mask, vl);\n    size_t odd_count_lst2 = vpopc_m_b32(v_odd_mask, vl);\n\n    if (even_count_lst1 + odd_count_lst2 >= n) {\n        return \"YES\";\n    } else {\n        return \"NO\";\n    }\n}\n```"}
{"task_id": "SimdBench_116_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <string>\n\nstd::string myexchange_simd(const std::vector<int>& lst1, const std::vector<int>& lst2) {\n    size_t n = lst1.size();\n    vint32m1_t v_lst1 = __riscv_vle32_v_i32m1(lst1.data(), n);\n    vint32m1_t v_lst2 = __riscv_vle32_v_i32m1(lst2.data(), n);\n\n    vint32m1_t v_even_mask = __riscv_vmsif_m_b32(v_lst1, 2, 0);\n    vint32m1_t v_odd_mask = __riscv_vmnot_m_b32(v_even_mask, n);\n\n    vint32m1_t v_even_lst1 = __riscv_vcompress_m(v_lst1, v_even_mask, n);\n    vint32m1_t v_odd_lst1 = __riscv_vcompress_m(v_lst1, v_odd_mask, n);\n\n    vint32m1_t v_even_lst2 = __riscv_vcompress_m(v_lst2, v_even_mask, n);\n    vint32m1_t v_odd_lst2 = __riscv_vcompress_m(v_lst2, v_odd_mask, n);\n\n    size_t even_count_lst1 = __riscv_vcpop_m(v_even_mask, n);\n    size_t odd_count_lst1 = __riscv_vcpop_m(v_odd_mask, n);\n\n    size_t even_count_lst2 = __riscv_vcpop_m(v_even_lst2, n);\n    size_t odd_count_lst2 = __riscv_vcpop_m(v_odd_lst2, n);\n\n    if (odd_count_lst1 <= even_count_lst2) {\n        return \"YES\";\n    } else {\n        return \"NO\";\n    }\n}\n```"}
{"task_id": "SimdBench_116_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <string>\n\nstd::string myexchange_simd(const std::vector<int>& lst1, const std::vector<int>& lst2) {\n    size_t n = lst1.size();\n    vint32m1_t v_lst1 = __riscv_vle32_v_i32m1(lst1.data(), n);\n    vint32m1_t v_lst2 = __riscv_vle32_v_i32m1(lst2.data(), n);\n\n    vint32m1_t v_even_mask = __riscv_vand_vx_i32m1_b32(v_lst1, 1, __riscv_vmv_v_x_i32m1_b32(0, n));\n    vint32m1_t v_odd_mask = __riscv_vsub_vv_i32m1(v_lst1, v_even_mask, __riscv_vmv_v_x_i32m1_b32(0, n));\n\n    vint32m1_t v_even_count = __riscv_vcpop_m(v_even_mask, n);\n    vint32m1_t v_odd_count = __riscv_vcpop_m(v_odd_mask, n);\n\n    vint32m1_t v_lst2_even_mask = __riscv_vand_vx_i32m1_b32(v_lst2, 1, __riscv_vmv_v_x_i32m1_b32(0, n));\n    vint32m1_t v_lst2_odd_mask = __riscv_vsub_vv_i32m1(v_lst2, v_lst2_even_mask, __riscv_vmv_v_x_i32m1_b32(0, n));\n\n    vint32m1_t v_lst2_even_count = __riscv_vcpop_m(v_lst2_even_mask, n);\n    vint32m1_t v_lst2_odd_count = __riscv_vcpop_m(v_lst2_odd_mask, n);\n\n    int even_count = __riscv_vmv_x_s_i32m1_b32(v_even_count);\n    int odd_count = __riscv_vmv_x_s_i32m1_b32(v_odd_count);\n    int lst2_even_count = __riscv_vmv_x_s_i32m1_b32(v_lst2_even_count);\n    int lst2_odd_count = __riscv_vmv_x_s_i32m1_b32(v_lst2_odd_count);\n\n    if (even_count + lst2_even_count >= n && odd_count <= lst2_odd_count) {\n        return \"YES\";\n    } else {\n        return \"NO\";\n    }\n}\n```"}
{"task_id": "SimdBench_117_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <string>\n\nstd::vector<std::string> odd_count_simd(const std::vector<std::string> & lst) {\n    std::vector<std::string> result;\n    result.reserve(lst.size());\n\n    for (const auto& str : lst) {\n        size_t len = str.size();\n        size_t odd_count = 0;\n\n        // Process in chunks of 8 characters\n        size_t i = 0;\n        for (; i + 8 <= len; i += 8) {\n            vuint8m1_t v_digits = __riscv_vle8_v_u8m1((const uint8_t*)&str[i], 8);\n            vuint8m1_t v_odd_mask = __riscv_vmsne_vx_u8m1_b8(v_digits, 0, 1);\n            vuint8m1_t v_odd_counts = __riscv_vand_vx_u8m1(v_odd_mask, 1, 8);\n            odd_count += __riscv_vreduc_sum_vs_u8m1_u8m1(v_odd_counts, 0);\n        }\n\n        // Process remaining characters\n        for (; i < len; ++i) {\n            if ((str[i] - '0') % 2 != 0) {\n                ++odd_count;\n            }\n        }\n\n        result.push_back(\"the number of odd elements \" + std::to_string(odd_count) +\n                         \"n the str\" + std::to_string(odd_count) +\n                         \"ng \" + std::to_string(odd_count) +\n                         \" of the \" + std::to_string(odd_count) + \"nput.\");\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_117_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <string>\n\nstd::vector<std::string> odd_count_simd(const std::vector<std::string> & lst) {\n    std::vector<std::string> result;\n    result.reserve(lst.size());\n\n    for (const auto& str : lst) {\n        size_t len = str.size();\n        size_t odd_count = 0;\n\n        // Process the string in chunks of 8 characters\n        for (size_t i = 0; i < len; i += 8) {\n            size_t chunk_size = std::min(len - i, static_cast<size_t>(8));\n            vuint8m1_t v_digits = __riscv_vle8_v_u8m1(str.data() + i, chunk_size);\n\n            // Create a mask for odd digits (1, 3, 5, 7, 9)\n            vuint8m1_t v_odd_mask = __riscv_vmsne_vx_u8m1_b8(v_digits, 0, 1);\n            v_odd_mask = __riscv_vmand_mm_b8(v_odd_mask, __riscv_vmsne_vx_u8m1_b8(v_digits, 0, 3));\n            v_odd_mask = __riscv_vmand_mm_b8(v_odd_mask, __riscv_vmsne_vx_u8m1_b8(v_digits, 0, 5));\n            v_odd_mask = __riscv_vmand_mm_b8(v_odd_mask, __riscv_vmsne_vx_u8m1_b8(v_digits, 0, 7));\n            v_odd_mask = __riscv_vmand_mm_b8(v_odd_mask, __riscv_vmsne_vx_u8m1_b8(v_digits, 0, 9));\n\n            // Count the number of odd digits in the chunk\n            odd_count += __riscv_vcpop_m_b8(v_odd_mask, chunk_size);\n        }\n\n        // Construct the result string\n        std::string result_str = \"the number of odd elements \" + std::to_string(odd_count) +\n                                 \"n the str\" + std::to_string(odd_count) +\n                                 \"ng \" + std::to_string(odd_count) +\n                                 \" of the \" + std::to_string(odd_count) + \"nput.\";\n        result.push_back(result_str);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_117_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <string>\n\nstd::vector<std::string> odd_count_simd(const std::vector<std::string> & lst) {\n    std::vector<std::string> result;\n    result.reserve(lst.size());\n\n    for (const auto& str : lst) {\n        size_t len = str.size();\n        size_t odd_count = 0;\n\n        for (size_t i = 0; i < len; i += sizeof(vuint8m1_t) / sizeof(uint8_t)) {\n            vuint8m1_t v = vle8_v_u8m1(&str[i], sizeof(vuint8m1_t) / sizeof(uint8_t));\n            vuint8m1_t odd_mask = vrem_vx_u8m1(v, 2, sizeof(vuint8m1_t) / sizeof(uint8_t));\n            odd_mask = vmseq_vx_u8m1(odd_mask, 1, sizeof(vuint8m1_t) / sizeof(uint8_t));\n            odd_count += vpopc_m(sizeof(vuint8m1_t) / sizeof(uint8_t), odd_mask);\n        }\n\n        std::string output = \"the number of odd elements \" + std::to_string(odd_count) +\n                            \"n the str\" + std::to_string(odd_count) +\n                            \"ng \" + std::to_string(odd_count) +\n                            \" of the \" + std::to_string(odd_count) + \"nput.\";\n        result.push_back(output);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_117_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <string>\n\nstd::vector<std::string> odd_count_simd(const std::vector<std::string> & lst) {\n    std::vector<std::string> result;\n    result.reserve(lst.size());\n\n    for (const auto& str : lst) {\n        size_t len = str.size();\n        size_t odd_count = 0;\n\n        // Process in chunks of 8 characters\n        size_t i = 0;\n        for (; i + 8 <= len; i += 8) {\n            vuint8m1_t v_digits = __riscv_vle8_v_u8m1((const uint8_t*)&str[i], 8);\n            vuint8m1_t v_odd_mask = __riscv_vand_vx_u8m1_b8(v_digits, 1, 8);\n            vuint8m1_t v_odd_count = __riscv_vcpop_m_u8m1(v_odd_mask, 8);\n            odd_count += __riscv_vmv_x_s_u8m1_u8(v_odd_count);\n        }\n\n        // Process remaining characters\n        for (; i < len; ++i) {\n            if ((str[i] - '0') % 2 != 0) {\n                ++odd_count;\n            }\n        }\n\n        result.push_back(\"the number of odd elements \" + std::to_string(odd_count) +\n                         \"n the str\" + std::to_string(odd_count) +\n                         \"ng \" + std::to_string(odd_count) +\n                         \" of the \" + std::to_string(odd_count) + \"nput.\");\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_117_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <string>\n\nstd::vector<std::string> odd_count_simd(const std::vector<std::string> & lst) {\n    std::vector<std::string> result;\n    result.reserve(lst.size());\n\n    for (const auto& str : lst) {\n        size_t len = str.size();\n        size_t odd_count = 0;\n\n        // Process in chunks of 8 characters\n        size_t i = 0;\n        for (; i + 8 <= len; i += 8) {\n            vuint8m1_t v_digits = __riscv_vle8_v_u8m1((const uint8_t*)&str[i], 8);\n            vuint8m1_t v_odd_mask = __riscv_vand_vx_u8m1_b8(v_digits, 1, 8);\n            vuint8m1_t v_odd_count = __riscv_vcpop_m_u8m1(v_odd_mask, 8);\n            odd_count += __riscv_vmv_x_s_u8m1_u8(v_odd_count);\n        }\n\n        // Process remaining characters\n        for (; i < len; ++i) {\n            if ((str[i] - '0') % 2 != 0) {\n                ++odd_count;\n            }\n        }\n\n        result.push_back(\"the number of odd elements \" + std::to_string(odd_count) +\n                         \"n the str\" + std::to_string(odd_count) +\n                         \"ng \" + std::to_string(odd_count) +\n                         \" of the \" + std::to_string(odd_count) + \"nput.\");\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_118_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <cstdint>\n#include <limits>\n\nint64_t minSubArraySum_simd(const std::vector<int64_t>& nums) {\n    size_t n = nums.size();\n    if (n == 0) return 0;\n\n    int64_t min_sum = std::numeric_limits<int64_t>::max();\n    int64_t current_sum = 0;\n\n    size_t vl = __riscv_vsetvl_e64m1(n);\n    vint64m1_t v_nums = __riscv_vle64_v_i64m1(nums.data(), vl);\n\n    for (size_t i = 0; i < n; i += vl) {\n        vl = __riscv_vsetvl_e64m1(n - i);\n        vint64m1_t v_current = __riscv_vle64_v_i64m1(nums.data() + i, vl);\n\n        current_sum += __riscv_vredsum_vs_i64m1_i64m1(v_current, current_sum, vl);\n        min_sum = std::min(min_sum, current_sum);\n    }\n\n    return min_sum;\n}\n```"}
{"task_id": "SimdBench_118_RVV", "completion": "```cpp\nint64_t minSubArraySum_simd(const std::vector<int64_t>& nums) {\n    size_t n = nums.size();\n    int64_t min_sum = INT64_MAX;\n    int64_t current_sum = 0;\n\n    size_t vl = __riscv_vsetvl_e64m1(n);\n    vint64m1_t v_nums = __riscv_vle64_v_i64m1(nums.data(), vl);\n\n    for (size_t i = 0; i < n; i += vl) {\n        vl = __riscv_vsetvl_e64m1(n - i);\n        vint64m1_t v_subarray = __riscv_vle64_v_i64m1(nums.data() + i, vl);\n\n        current_sum += __riscv_vreduce_sum_vs_i64m1_i64m1(v_subarray, current_sum, vl);\n        min_sum = std::min(min_sum, current_sum);\n    }\n\n    return min_sum;\n}\n```"}
{"task_id": "SimdBench_118_RVV", "completion": "```cpp\nint64_t minSubArraySum_simd(const std::vector<int64_t>& nums) {\n    size_t n = nums.size();\n    int64_t min_sum = INT64_MAX;\n    int64_t current_sum = 0;\n\n    size_t vl = __riscv_vsetvl_e64m1(n);\n    vint64m1_t v_nums = __riscv_vle64_v_i64m1(nums.data(), vl);\n\n    for (size_t i = 0; i < n; i += vl) {\n        vl = __riscv_vsetvl_e64m1(n - i);\n        vint64m1_t v_segment = __riscv_vle64_v_i64m1(nums.data() + i, vl);\n\n        current_sum += __riscv_vredsum_vs_i64m1_i64m1(v_segment, current_sum, vl);\n        min_sum = std::min(min_sum, current_sum);\n    }\n\n    return min_sum;\n}\n```"}
{"task_id": "SimdBench_118_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <cstdint>\n#include <limits>\n\nint64_t minSubArraySum_simd(const std::vector<int64_t>& nums) {\n    size_t n = nums.size();\n    if (n == 0) return 0;\n\n    int64_t min_sum = std::numeric_limits<int64_t>::max();\n    size_t vl = vsetvl_e64m1(n);\n\n    vint64m1_t v_min_sum = vmv_v_x_i64m1(min_sum, vl);\n    vint64m1_t v_nums = vle64_v_i64m1(nums.data(), vl);\n\n    for (size_t i = 0; i < n; i += vl) {\n        vl = vsetvl_e64m1(n - i);\n        v_nums = vle64_v_i64m1(nums.data() + i, vl);\n        v_min_sum = vmin_vv_i64m1(v_min_sum, v_nums, vl);\n    }\n\n    vint64m1_t v_reduced_min = vredmin_vs_i64m1_i64m1(v_min_sum, v_min_sum, vl);\n    min_sum = vmv_x_s_i64m1_i64(v_reduced_min);\n\n    return min_sum;\n}\n```"}
{"task_id": "SimdBench_118_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <cstdint>\n#include <limits>\n\nint64_t minSubArraySum_simd(const std::vector<int64_t>& nums) {\n    size_t n = nums.size();\n    if (n == 0) return 0;\n\n    int64_t min_sum = std::numeric_limits<int64_t>::max();\n    int64_t current_sum = 0;\n\n    size_t vl = __riscv_vsetvl_e64m1(n);\n    vint64m1_t v_nums = __riscv_vle64_v_i64m1(nums.data(), vl);\n\n    for (size_t i = 0; i < n; i += vl) {\n        vl = __riscv_vsetvl_e64m1(n - i);\n        vint64m1_t v_subarray = __riscv_vle64_v_i64m1(nums.data() + i, vl);\n\n        vint64m1_t v_current_sum = __riscv_vadd_vv_i64m1(v_current_sum, v_subarray, vl);\n        vint64m1_t v_min_sum = __riscv_vmin_vv_i64m1(v_min_sum, v_current_sum, vl);\n\n        current_sum = __riscv_vmv_x_s_i64m1_i64(v_current_sum);\n        min_sum = __riscv_vmv_x_s_i64m1_i64(v_min_sum);\n    }\n\n    return min_sum;\n}\n```"}
{"task_id": "SimdBench_119_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nint max_fill_simd(const std::vector<std::vector<int>>& grid, int capacity) {\n    int total_water = 0;\n    size_t num_rows = grid.size();\n    size_t num_cols = grid[0].size();\n\n    for (size_t i = 0; i < num_rows; ++i) {\n        const int* row = grid[i].data();\n        size_t j = 0;\n\n        while (j < num_cols) {\n            size_t vl = vsetvl_e32m1(num_cols - j);\n            vint32m1_t v_water = vle32_v_i32m1(&row[j], vl);\n            vint32m1_t v_sum = vredsum_vs_i32m1_i32m1(v_water, vint32m1_t(0), vl);\n            int sum = vmv_x_s_i32m1_i32(v_sum);\n            total_water += sum;\n            j += vl;\n        }\n    }\n\n    return (total_water + capacity - 1) / capacity;\n}\n```"}
{"task_id": "SimdBench_119_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nint max_fill_simd(const std::vector<std::vector<int>>& grid, int capacity) {\n    int total_water = 0;\n    size_t num_rows = grid.size();\n    size_t num_cols = grid[0].size();\n\n    for (size_t i = 0; i < num_rows; ++i) {\n        size_t j = 0;\n        while (j < num_cols) {\n            size_t vl = __riscv_vsetvl_e32m1(num_cols - j);\n            vint32m1_t v_water = __riscv_vle32_v_i32m1(&grid[i][j], vl);\n            vint32m1_t v_sum = __riscv_vredsum_vs_i32m1_i32m1(v_water, 0, vl);\n            total_water += __riscv_vmv_x_s_i32m1_i32(v_sum);\n            j += vl;\n        }\n    }\n\n    return (total_water + capacity - 1) / capacity;\n}\n```"}
{"task_id": "SimdBench_119_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nint max_fill_simd(const std::vector<std::vector<int>>& grid, int capacity) {\n    int total_water = 0;\n    size_t num_rows = grid.size();\n    size_t num_cols = grid[0].size();\n\n    for (size_t i = 0; i < num_rows; ++i) {\n        const int* row = grid[i].data();\n        size_t j = 0;\n\n        while (j < num_cols) {\n            size_t vl = __riscv_vsetvl_e32m1(num_cols - j);\n            vint32m1_t v_water = __riscv_vle32_v_i32m1(row + j, vl);\n            vint32m1_t v_sum = __riscv_vredsum_vs_i32m1_i32m1(v_water, __riscv_vmv_v_x_i32m1(0, vl), vl);\n            total_water += __riscv_vmv_x_s_i32m1_i32(v_sum);\n            j += vl;\n        }\n    }\n\n    return (total_water + capacity - 1) / capacity;\n}\n```"}
{"task_id": "SimdBench_119_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nint max_fill_simd(const std::vector<std::vector<int>> &grid, int capacity) {\n    int total_water = 0;\n    size_t num_rows = grid.size();\n    size_t num_cols = grid[0].size();\n\n    for (size_t i = 0; i < num_rows; ++i) {\n        size_t j = 0;\n        while (j < num_cols) {\n            size_t vl = vsetvl_e32m1(num_cols - j);\n            vint32m1_t v_water = vle32_v_i32m1(&grid[i][j], vl);\n            vint32m1_t v_sum = vredsum_vs_i32m1_i32m1(v_water, vint32m1_t(0), vl);\n            total_water += vsum_v_i32m1_i32(v_sum, vl);\n            j += vl;\n        }\n    }\n\n    return (total_water + capacity - 1) / capacity;\n}\n```"}
{"task_id": "SimdBench_119_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nint max_fill_simd(const std::vector<std::vector<int>>& grid, int capacity) {\n    int total_water = 0;\n    size_t num_rows = grid.size();\n    size_t num_cols = grid[0].size();\n\n    for (size_t i = 0; i < num_rows; ++i) {\n        size_t j = 0;\n        while (j < num_cols) {\n            size_t vl = vsetvl_e32m1(num_cols - j);\n            vuint32m1_t v_water = vle32_v_u32m1(&grid[i][j], vl);\n            vuint32m1_t v_sum = vredsum_vs_u32m1_u32m1(v_water, v_sum, vl);\n            total_water += vsum_v_u32m1_u32(v_sum, vl);\n            j += vl;\n        }\n    }\n\n    return (total_water + capacity - 1) / capacity;\n}\n```"}
{"task_id": "SimdBench_120_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nint64_t solution_simd(const std::vector<int16_t>& lst) {\n    size_t n = lst.size();\n    int16_t* data = lst.data();\n\n    // Initialize vector registers\n    vint16m1_t v_data = __riscv_vle16_v_i16m1(data, n, n);\n    vint16m1_t v_indices = __riscv_vid_v_i16m1(n);\n\n    // Create masks for even positions and odd values\n    vuint16m1_t v_even_mask = __riscv_vmsne_vx_u16m1(v_indices, 0, 0);\n    vuint16m1_t v_odd_mask = __riscv_vmsne_vx_u16m1(__riscv_vand_vx_i16m1(v_data, 1, n), 0, n);\n\n    // Combine masks\n    vuint16m1_t v_combined_mask = __riscv_vand_vv_u16m1(v_even_mask, v_odd_mask, n);\n\n    // Apply mask to data\n    vint16m1_t v_filtered_data = __riscv_vmerge_vx_i16m1(v_data, 0, v_combined_mask, n);\n\n    // Sum the filtered data\n    vint64m1_t v_sum = __riscv_vredsum_vs_i64m1_i64m1(v_filtered_data, 0, n);\n\n    // Extract the result\n    int64_t sum = __riscv_vmv_x_s_i64m1_i64(v_sum);\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_120_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nint64_t solution_simd(const std::vector<int16_t>& lst) {\n    size_t n = lst.size();\n    int16_t* data = lst.data();\n\n    // Initialize vector registers\n    vint16m1_t v_data = __riscv_vle16_v_i16m1(data, n, n);\n    vint16m1_t v_indices = __riscv_vid_v_i16m1(n);\n\n    // Create masks for even indices and odd values\n    vuint16m1_t v_even_mask = __riscv_vmsne_vx_i16m1_b16(v_indices, 0, 0);\n    vuint16m1_t v_odd_mask = __riscv_vmsne_vx_i16m1_b16(__riscv_vand_vx_i16m1(v_data, 1, n), 0, n);\n\n    // Combine masks\n    vuint16m1_t v_combined_mask = __riscv_vand_vv_u16m1(v_even_mask, v_odd_mask, n);\n\n    // Apply mask to data\n    vint16m1_t v_filtered_data = __riscv_vmerge_vx_i16m1(v_data, 0, v_combined_mask, n);\n\n    // Sum the filtered data\n    vint64m1_t v_sum = __riscv_vredsum_vs_i16m1_i64m1(v_filtered_data, 0, n);\n\n    // Extract the result\n    int64_t sum = __riscv_vmv_x_s_i64m1_i64(v_sum);\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_120_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nint64_t solution_simd(const std::vector<int16_t>& lst) {\n    size_t n = lst.size();\n    int16_t* data = lst.data();\n\n    // Initialize vector registers\n    vint16m1_t v_data = __riscv_vle16_v_i16m1(data, n, n);\n    vint16m1_t v_indices = __riscv_vid_v_i16m1(n, n);\n\n    // Mask for even positions\n    vuint16m1_t v_mask_even = __riscv_vmsif_m_b16(v_indices, 2, n);\n\n    // Mask for odd values\n    vuint16m1_t v_mask_odd = __riscv_vmsif_m_b16(v_data, 2, n);\n\n    // Combine masks for even positions and odd values\n    vuint16m1_t v_mask = __riscv_vmand_mm_b16(v_mask_even, v_mask_odd, n);\n\n    // Apply mask to data\n    vint16m1_t v_filtered = __riscv_vmmerge_vx_i16m1(v_mask, v_data, 0, n);\n\n    // Sum the filtered values\n    vint64m1_t v_sum = __riscv_vredsum_vs_i64m1_i64m1(v_filtered, __riscv_vmv_v_x_i64m1(0, n), n);\n\n    // Extract the sum from the vector register\n    int64_t sum = __riscv_vmv_x_s_i64m1_i64(v_sum);\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_120_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nint64_t solution_simd(const std::vector<int16_t>& lst) {\n    size_t n = lst.size();\n    int16_t* data = lst.data();\n\n    // Initialize vector registers\n    vint16m1_t v_even_positions = __riscv_vsetivli(1, RVV_E16, RVV_M1);\n    vint16m1_t v_odd_elements = __riscv_vsetivli(1, RVV_E16, RVV_M1);\n    vint16m1_t v_sum = __riscv_vsetivli(1, RVV_E16, RVV_M1);\n\n    // Initialize sum to zero\n    v_sum = __riscv_vmv_v_x_i16m1(v_sum, 0, 1);\n\n    for (size_t i = 0; i < n; i += 2) {\n        // Load elements at even positions\n        v_even_positions = __riscv_vle16_v_i16m1(&data[i], 1);\n\n        // Check if elements are odd\n        v_odd_elements = __riscv_vand_vv_i16m1(v_even_positions, __riscv_vmv_v_x_i16m1(v_odd_elements, 1, 1), RVV_M1);\n\n        // Sum the odd elements\n        v_sum = __riscv_vadd_vv_i16m1(v_sum, v_odd_elements, RVV_M1);\n    }\n\n    // Reduce the sum vector to a scalar\n    int64_t sum = __riscv_vredsum_vs_i16m1_i64m1(v_sum, 0, RVV_M1);\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_120_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nint64_t solution_simd(const std::vector<int16_t>& lst) {\n    size_t n = lst.size();\n    int16_t* data = lst.data();\n\n    size_t vl = __riscv_vsetvl_e16m1(n);\n    vint16m1_t v_data = __riscv_vle16_v_i16m1(data, vl);\n\n    vint16m1_t v_indices = __riscv_vid_v_i16m1(vl);\n    vint16m1_t v_even_indices = __riscv_vand_vx_i16m1(v_indices, 1, vl);\n\n    vint16m1_t v_odd_elements = __riscv_vand_vx_i16m1(v_data, 1, vl);\n    vint16m1_t v_even_odd_elements = __riscv_vand_vv_i16m1(v_even_indices, v_odd_elements, vl);\n\n    vint16m1_t v_sum = __riscv_vredsum_vs_i16m1_i64m1(v_even_odd_elements, __riscv_vmv_v_x_i64m1(0, vl), vl);\n\n    return __riscv_vmv_x_s_i64m1_i64(v_sum);\n}\n```"}
{"task_id": "SimdBench_121_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nint add_elements_simd(std::vector<int> arr, int k) {\n    int sum = 0;\n    size_t vl = vsetvl_e32m1(k);\n    vint32m1_t v_arr = vle32_v_i32m1(arr.data(), vl);\n    vint32m1_t v_mask = vmseq_vx_i32m1_b32(v_arr, 100, vl);\n    vint32m1_t v_filtered = vmerge_vx_i32m1(v_arr, 0, v_mask, vl);\n    vint32m1_t v_sum = vredsum_vs_i32m1_i32m1(v_sum, v_filtered, vl);\n    sum = vsum_vs_i32m1_i32(v_sum, vl);\n    return sum;\n}\n```"}
{"task_id": "SimdBench_121_RVV", "completion": "```c++\n#include <riscv_vector.h>\n#include <vector>\n\nint add_elements_simd(std::vector<int> arr, int k) {\n    size_t vl = vsetvl_e32m1(k);\n    vint32m1_t v_arr = vle32_v_i32m1(arr.data(), vl);\n    vint32m1_t v_mask = vmseq_vx_i32m1_b32(v_arr, 10, vl);\n    vint32m1_t v_filtered = vmerge_vx_i32m1(v_arr, 0, v_mask, vl);\n    vint32m1_t v_sum = vredsum_vs_i32m1_i32m1(v_filtered, v_sum, vl);\n    return v_sum;\n}\n```"}
{"task_id": "SimdBench_121_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nint add_elements_simd(std::vector<int> arr, int k) {\n    size_t vl = vsetvl_e32m1(k);\n    vint32m1_t v_arr = vle32_v_i32m1(arr.data(), vl);\n\n    vint32m1_t v_mask = vmseq_vx_i32m1_b11(v_arr, 9, vl);\n    vint32m1_t v_mask2 = vmseq_vx_i32m1_b11(v_arr, 10, vl);\n    vint32m1_t v_mask3 = vmseq_vx_i32m1_b11(v_arr, 11, vl);\n    vint32m1_t v_mask4 = vmseq_vx_i32m1_b11(v_arr, 12, vl);\n    vint32m1_t v_mask5 = vmseq_vx_i32m1_b11(v_arr, 13, vl);\n    vint32m1_t v_mask6 = vmseq_vx_i32m1_b11(v_arr, 14, vl);\n    vint32m1_t v_mask7 = vmseq_vx_i32m1_b11(v_arr, 15, vl);\n    vint32m1_t v_mask8 = vmseq_vx_i32m1_b11(v_arr, 16, vl);\n    vint32m1_t v_mask9 = vmseq_vx_i32m1_b11(v_arr, 17, vl);\n    vint32m1_t v_mask10 = vmseq_vx_i32m1_b11(v_arr, 18, vl);\n    vint32m1_t v_mask11 = vmseq_vx_i32m1_b11(v_arr, 19, vl);\n    vint32m1_t v_mask12 = vmseq_vx_i32m1_b11(v_arr, 20, vl);\n    vint32m1_t v_mask13 = vmseq_vx_i32m1_b11(v_arr, 21, vl);\n    vint32m1_t v_mask14 = vmseq_vx_i32m1_b11(v_arr, 22, vl);\n    vint32m1_t v_mask15 = vmseq_vx_i32m1_b11(v_arr, 23, vl);\n    vint32m1_t v_mask16 = vmseq_vx_i32m1_b11(v_arr, 24, vl);\n    vint32m1_t v_mask17 = vmseq_vx_i32m1_b11(v_arr, 25, vl);\n    vint32m1_t v_mask18 = vmseq_vx_i32m1_b11(v_arr, 26, vl);\n    vint32m1_t v_mask19 = vmseq_vx_i32m1_b11(v_arr, 27, vl);\n    vint32m1_t v_mask20 = vmseq_vx_i32m1_b11(v_arr, 28, vl);\n    vint32m1_t v_mask21 = vmseq_vx_i32m1_b11(v_arr, 29, vl);\n    vint32m1_t v_mask22 = vmseq_vx_i32m1_b11(v_arr, 30, vl);\n    vint32m1_t v_mask23 = vmseq_vx_i32m1_b11(v_arr, 31, vl);\n    vint32m1_t v_mask24 = vmseq_vx_i32m1_b11(v_arr, 32, vl);\n    vint32m1_t v_mask25 = vmseq_vx_i32m1_b11(v_arr, 33, vl);\n    vint32m1_t v_mask26 = vmseq_vx_i32m1_b11(v_arr, 34, vl);\n    vint32m1_t v_mask27 = vmseq_vx_i32m1_b11(v_arr, 35, vl);\n    vint32m1_t v_mask28 = vmseq_vx_i32m1_b11(v_arr, 36, vl);\n    vint32m1_t v_mask29 = vmseq_vx_i32m1_b11(v_arr, 37, vl);\n    vint32m1_t v_mask30 = vmseq_vx_i32m1_b11(v_arr, 38, vl);\n    vint32m1_t v_mask31 = vmseq_vx_i32m1_b11(v_arr, 39, vl);\n    vint32m1_t v_mask32 = vmseq_vx_i32m1_b11(v_arr, 40, vl);\n    vint32m1_t v_mask33 = vmseq_vx_i32m1_b11(v_arr, 41, vl);\n    vint32m1_t v_mask34 = vmseq_vx_i32m1_b11(v_arr, 42, vl);\n    vint32m1_t v_mask35 = vmseq_vx_i32m1_b11(v_arr, 43, vl);\n    vint32m1_t v_mask36 = vmseq_vx_i32m1_b11(v_arr, 44, vl);\n    vint32m1_t v_mask37 = vmseq_vx_i32m1_b11(v_arr, 45, vl);\n    vint32m1_t v_mask38 = vmseq_vx_i32m1_b11(v_arr, 46, vl);\n    vint32m1_t v_mask39 = vmseq_vx_i32m1_b11(v_arr, 47, vl);\n    vint32m1_t v_mask40 = vmseq_vx_i32m1_b11(v_arr, 48, vl);\n    vint32m1_t v_mask41 = vmseq_vx_i32m1_b11(v_arr, 49, vl);\n    vint32m1_t v_mask42 = vmseq_vx_i32m1_b11(v_arr, 50, vl);\n    vint32m1_t v_mask43 = vmseq_vx_i32m1_b11(v_arr, 51, vl);\n    vint32m1_t v_mask44 = vmseq_vx_i32m1_b11(v_arr, 52, vl);\n    vint32m1_t v_mask45 = vmseq_vx_i32m1_b11(v_arr, 53, vl);\n    vint32m1_t v_mask46 = vmseq_vx_i32m1_b11(v_arr, 54, vl);\n    vint32m1_t v_mask47 = vmseq_vx_i32m1_b11(v_arr, 55, vl);\n    vint32m1_t v_mask48 = vmseq_vx_i32m1_b11(v_arr, 56, vl);\n    vint32m1_t v_mask49 = vmseq_vx_i32m1_b11(v_arr, 57, vl);\n    vint32m1_t v_mask50 = vmseq_vx_i32m1_b11(v_arr, 58, vl);\n    vint32m1_t v_mask51 = vmseq_vx_i32m1_b11(v_arr, 59, vl);\n    vint32m1_t v_mask52 = vmseq_vx_i32m1_b11(v_arr, 60, vl);\n    vint32m1_t v_mask53 = vmseq_vx_i32m1_b11(v_arr, 61, vl);\n    vint32m1_t v_mask54 = vmseq_vx_i32m1_b11(v_arr, 62, vl);\n    vint32m1_t v_mask55 = vmseq_vx_i32m1_b11(v_arr, 63, vl);\n    vint32m1_t v_mask56 = vmseq_vx_i32m1_b11(v_arr, 64, vl);\n    vint32m1_t v_mask57 = vmseq_vx_i32m1_b11(v_arr, 65, vl);\n    vint32m1_t v_mask58 = vmseq_vx_i32m1_b11(v_arr, 66, vl);\n    vint32m1_t v_mask59 = vmseq_vx_i32m1_b11(v_arr, 67, vl);\n    vint32m1_t v_mask60 = vmseq_vx_i32m1_b11(v_arr, 68, vl);\n    vint32m1_t v_mask61 = vmseq_vx_i32m1_b11(v_arr, 69, vl);\n    vint32m1_t v_mask62 = vmseq_vx_i32m1_b11(v_arr, 70, vl);\n    vint32m1_t v_mask63 = vmseq_vx_i32m1_b11(v_arr, 71, vl);\n    vint32m1_t v_mask64 = vmseq_vx_i32m1_b11(v_arr, 72, vl);\n    vint32m1_t v_mask65 = vmseq_vx_i32m1_b11(v_arr, 73, vl);\n    vint32m1_t v_mask66 = vmseq_vx_i32m1_b11(v_arr, 74, vl);\n    vint32m1_t v_mask67 = vmseq_vx_i32m1_b11(v_arr, 75, vl);\n    vint32m1_t v_mask68 = vmseq_vx_i32m1_b11(v_arr, 76, vl);\n    vint32m1_t v_mask69 = vmseq_vx_i32m1_b11(v_arr, 77, vl);\n    vint32m1_t v_mask70 = vmseq_vx_i32m1_b11(v_arr, 78, vl);\n    vint32m1_t v_mask71 = vmseq_vx_i32m1_b11(v_arr, 79, vl);\n    vint32m1_t v_mask72 = vmseq_vx_i32m1_b11(v_arr, 80, vl);\n    vint32m1_t v_mask73 = vmseq_vx_i32m1_b11(v_arr, 81, vl);\n    vint32m1_t v_mask74 = vmseq_vx_i32m1_b11(v_arr, 82, vl);\n    vint32m1_t v_mask75 = vmseq_vx_i32m1_b11(v_arr, 83, vl);\n    vint32m1_t v_mask76 = vmseq_vx_i32m1_b11(v_arr, 84, vl);\n    vint32m1_t v_mask77 = vmseq_vx_i32m1_b11(v_arr, 85, vl);\n    vint32m1_t v_mask78 = vmseq_vx_i32m1_b11(v_arr, 86, vl);\n    vint32m1_t v_mask79 = vmseq_vx_i32m1_b11(v_arr, 87, vl);\n    vint32m1_t v_mask80 = vmseq_vx_i32m1_b11(v_arr, 88, vl);\n    vint32m1_t v_mask81 = vmseq_vx_i32m1_b11(v_arr, 89, vl);\n    vint32m1_t v_mask82 = vmseq_vx_i32m1_b11(v_arr, 90, vl);\n    vint32m1_t v_mask83 = vmseq_vx_i32m1_b11(v_arr, 91, vl);\n    vint32m1_t v_mask84 = vmseq_vx_i32m1_b11(v_arr, 92, vl);\n    vint32m1_t v_mask85 = vmseq_vx_i32m1_b11(v_arr, 93, vl);\n    vint32m1_t v_mask86 = vmseq_vx_i32m1_b11(v_arr, 94, vl);\n    vint32m1_t v_mask87 = vmseq_vx_i32m1_b11(v_arr, 95, vl);\n    vint32m1_t v_mask88 = vmseq_vx_i32m1_b11(v_arr, 96, vl);\n    vint32m1_t v_mask89 = vmseq_vx_i32m1_b11(v_arr, 97, vl);\n    vint32m1_t v_mask90 = vmseq_vx_i32m1_b11(v_arr, 98, vl);\n    vint32m1_t v_mask91 = vmseq_vx_i32m1_b11(v_arr, 99, vl);\n\n    vint32m1_t v_mask_final = vmor_mm_b11(v_mask, v_mask2, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask3, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask4, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask5, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask6, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask7, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask8, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask9, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask10, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask11, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask12, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask13, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask14, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask15, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask16, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask17, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask18, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask19, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask20, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask21, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask22, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask23, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask24, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask25, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask26, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask27, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask28, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask29, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask30, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask31, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask32, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask33, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask34, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask35, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask36, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask37, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask38, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask39, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask40, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask41, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask42, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask43, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask44, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask45, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask46, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask47, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask48, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask49, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask50, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask51, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask52, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask53, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask54, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask55, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask56, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask57, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask58, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask59, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask60, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask61, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask62, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask63, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask64, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask65, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask66, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask67, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask68, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask69, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask70, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask71, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask72, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask73, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask74, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask75, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask76, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask77, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask78, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask79, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask80, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask81, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask82, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask83, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask84, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask85, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask86, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask87, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask88, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask89, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask90, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask91, vl);\n\n    vint32m1_t v_result = vmv_v_v_i32m1(v_arr, v_mask_final, vl);\n    int sum = vredsum_vs_i32m1_i32(v_result, 0, vl);\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_121_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n\nint add_elements_simd(std::vector<int> arr, int k) {\n    int sum = 0;\n    size_t vl = vsetvl_e32m1(k);\n    vint32m1_t v_arr = vle32_v_i32m1(arr.data(), vl);\n    vint32m1_t v_mask = vmseq_vx_i32m1_b32(v_arr, 10, vl);\n    vint32m1_t v_mask2 = vmseq_vx_i32m1_b32(v_arr, 99, vl);\n    vint32m1_t v_mask3 = vor_vv_i32m1_b32(v_mask, v_mask2, vl);\n    vint32m1_t v_filtered = vcompress_vm_i32m1(v_arr, v_mask3, vl);\n    size_t vl2 = vsetvl_e32m1(vl);\n    vint32m1_t v_sum = vredsum_vs_i32m1_i32m1(v_filtered, v_sum, vl2);\n    sum = vsum_vs_i32m1_i32(v_sum, vl2);\n    return sum;\n}\n```"}
{"task_id": "SimdBench_121_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n\nint add_elements_simd(std::vector<int> arr, int k) {\n    size_t vl = vsetvl_e32m1(k);\n    vint32m1_t v_arr = vle32_v_i32m1(arr.data(), vl);\n\n    vint32m1_t v_mask = vmseq_vx_i32m1_b11(v_arr, 9, vl);\n    vint32m1_t v_mask2 = vmseq_vx_i32m1_b11(v_arr, 10, vl);\n    vint32m1_t v_mask3 = vmseq_vx_i32m1_b11(v_arr, 11, vl);\n    vint32m1_t v_mask4 = vmseq_vx_i32m1_b11(v_arr, 12, vl);\n    vint32m1_t v_mask5 = vmseq_vx_i32m1_b11(v_arr, 13, vl);\n    vint32m1_t v_mask6 = vmseq_vx_i32m1_b11(v_arr, 14, vl);\n    vint32m1_t v_mask7 = vmseq_vx_i32m1_b11(v_arr, 15, vl);\n    vint32m1_t v_mask8 = vmseq_vx_i32m1_b11(v_arr, 16, vl);\n    vint32m1_t v_mask9 = vmseq_vx_i32m1_b11(v_arr, 17, vl);\n    vint32m1_t v_mask10 = vmseq_vx_i32m1_b11(v_arr, 18, vl);\n    vint32m1_t v_mask11 = vmseq_vx_i32m1_b11(v_arr, 19, vl);\n    vint32m1_t v_mask12 = vmseq_vx_i32m1_b11(v_arr, 20, vl);\n    vint32m1_t v_mask13 = vmseq_vx_i32m1_b11(v_arr, 21, vl);\n    vint32m1_t v_mask14 = vmseq_vx_i32m1_b11(v_arr, 22, vl);\n    vint32m1_t v_mask15 = vmseq_vx_i32m1_b11(v_arr, 23, vl);\n    vint32m1_t v_mask16 = vmseq_vx_i32m1_b11(v_arr, 24, vl);\n    vint32m1_t v_mask17 = vmseq_vx_i32m1_b11(v_arr, 25, vl);\n    vint32m1_t v_mask18 = vmseq_vx_i32m1_b11(v_arr, 26, vl);\n    vint32m1_t v_mask19 = vmseq_vx_i32m1_b11(v_arr, 27, vl);\n    vint32m1_t v_mask20 = vmseq_vx_i32m1_b11(v_arr, 28, vl);\n    vint32m1_t v_mask21 = vmseq_vx_i32m1_b11(v_arr, 29, vl);\n    vint32m1_t v_mask22 = vmseq_vx_i32m1_b11(v_arr, 30, vl);\n    vint32m1_t v_mask23 = vmseq_vx_i32m1_b11(v_arr, 31, vl);\n    vint32m1_t v_mask24 = vmseq_vx_i32m1_b11(v_arr, 32, vl);\n    vint32m1_t v_mask25 = vmseq_vx_i32m1_b11(v_arr, 33, vl);\n    vint32m1_t v_mask26 = vmseq_vx_i32m1_b11(v_arr, 34, vl);\n    vint32m1_t v_mask27 = vmseq_vx_i32m1_b11(v_arr, 35, vl);\n    vint32m1_t v_mask28 = vmseq_vx_i32m1_b11(v_arr, 36, vl);\n    vint32m1_t v_mask29 = vmseq_vx_i32m1_b11(v_arr, 37, vl);\n    vint32m1_t v_mask30 = vmseq_vx_i32m1_b11(v_arr, 38, vl);\n    vint32m1_t v_mask31 = vmseq_vx_i32m1_b11(v_arr, 39, vl);\n    vint32m1_t v_mask32 = vmseq_vx_i32m1_b11(v_arr, 40, vl);\n    vint32m1_t v_mask33 = vmseq_vx_i32m1_b11(v_arr, 41, vl);\n    vint32m1_t v_mask34 = vmseq_vx_i32m1_b11(v_arr, 42, vl);\n    vint32m1_t v_mask35 = vmseq_vx_i32m1_b11(v_arr, 43, vl);\n    vint32m1_t v_mask36 = vmseq_vx_i32m1_b11(v_arr, 44, vl);\n    vint32m1_t v_mask37 = vmseq_vx_i32m1_b11(v_arr, 45, vl);\n    vint32m1_t v_mask38 = vmseq_vx_i32m1_b11(v_arr, 46, vl);\n    vint32m1_t v_mask39 = vmseq_vx_i32m1_b11(v_arr, 47, vl);\n    vint32m1_t v_mask40 = vmseq_vx_i32m1_b11(v_arr, 48, vl);\n    vint32m1_t v_mask41 = vmseq_vx_i32m1_b11(v_arr, 49, vl);\n    vint32m1_t v_mask42 = vmseq_vx_i32m1_b11(v_arr, 50, vl);\n    vint32m1_t v_mask43 = vmseq_vx_i32m1_b11(v_arr, 51, vl);\n    vint32m1_t v_mask44 = vmseq_vx_i32m1_b11(v_arr, 52, vl);\n    vint32m1_t v_mask45 = vmseq_vx_i32m1_b11(v_arr, 53, vl);\n    vint32m1_t v_mask46 = vmseq_vx_i32m1_b11(v_arr, 54, vl);\n    vint32m1_t v_mask47 = vmseq_vx_i32m1_b11(v_arr, 55, vl);\n    vint32m1_t v_mask48 = vmseq_vx_i32m1_b11(v_arr, 56, vl);\n    vint32m1_t v_mask49 = vmseq_vx_i32m1_b11(v_arr, 57, vl);\n    vint32m1_t v_mask50 = vmseq_vx_i32m1_b11(v_arr, 58, vl);\n    vint32m1_t v_mask51 = vmseq_vx_i32m1_b11(v_arr, 59, vl);\n    vint32m1_t v_mask52 = vmseq_vx_i32m1_b11(v_arr, 60, vl);\n    vint32m1_t v_mask53 = vmseq_vx_i32m1_b11(v_arr, 61, vl);\n    vint32m1_t v_mask54 = vmseq_vx_i32m1_b11(v_arr, 62, vl);\n    vint32m1_t v_mask55 = vmseq_vx_i32m1_b11(v_arr, 63, vl);\n    vint32m1_t v_mask56 = vmseq_vx_i32m1_b11(v_arr, 64, vl);\n    vint32m1_t v_mask57 = vmseq_vx_i32m1_b11(v_arr, 65, vl);\n    vint32m1_t v_mask58 = vmseq_vx_i32m1_b11(v_arr, 66, vl);\n    vint32m1_t v_mask59 = vmseq_vx_i32m1_b11(v_arr, 67, vl);\n    vint32m1_t v_mask60 = vmseq_vx_i32m1_b11(v_arr, 68, vl);\n    vint32m1_t v_mask61 = vmseq_vx_i32m1_b11(v_arr, 69, vl);\n    vint32m1_t v_mask62 = vmseq_vx_i32m1_b11(v_arr, 70, vl);\n    vint32m1_t v_mask63 = vmseq_vx_i32m1_b11(v_arr, 71, vl);\n    vint32m1_t v_mask64 = vmseq_vx_i32m1_b11(v_arr, 72, vl);\n    vint32m1_t v_mask65 = vmseq_vx_i32m1_b11(v_arr, 73, vl);\n    vint32m1_t v_mask66 = vmseq_vx_i32m1_b11(v_arr, 74, vl);\n    vint32m1_t v_mask67 = vmseq_vx_i32m1_b11(v_arr, 75, vl);\n    vint32m1_t v_mask68 = vmseq_vx_i32m1_b11(v_arr, 76, vl);\n    vint32m1_t v_mask69 = vmseq_vx_i32m1_b11(v_arr, 77, vl);\n    vint32m1_t v_mask70 = vmseq_vx_i32m1_b11(v_arr, 78, vl);\n    vint32m1_t v_mask71 = vmseq_vx_i32m1_b11(v_arr, 79, vl);\n    vint32m1_t v_mask72 = vmseq_vx_i32m1_b11(v_arr, 80, vl);\n    vint32m1_t v_mask73 = vmseq_vx_i32m1_b11(v_arr, 81, vl);\n    vint32m1_t v_mask74 = vmseq_vx_i32m1_b11(v_arr, 82, vl);\n    vint32m1_t v_mask75 = vmseq_vx_i32m1_b11(v_arr, 83, vl);\n    vint32m1_t v_mask76 = vmseq_vx_i32m1_b11(v_arr, 84, vl);\n    vint32m1_t v_mask77 = vmseq_vx_i32m1_b11(v_arr, 85, vl);\n    vint32m1_t v_mask78 = vmseq_vx_i32m1_b11(v_arr, 86, vl);\n    vint32m1_t v_mask79 = vmseq_vx_i32m1_b11(v_arr, 87, vl);\n    vint32m1_t v_mask80 = vmseq_vx_i32m1_b11(v_arr, 88, vl);\n    vint32m1_t v_mask81 = vmseq_vx_i32m1_b11(v_arr, 89, vl);\n    vint32m1_t v_mask82 = vmseq_vx_i32m1_b11(v_arr, 90, vl);\n    vint32m1_t v_mask83 = vmseq_vx_i32m1_b11(v_arr, 91, vl);\n    vint32m1_t v_mask84 = vmseq_vx_i32m1_b11(v_arr, 92, vl);\n    vint32m1_t v_mask85 = vmseq_vx_i32m1_b11(v_arr, 93, vl);\n    vint32m1_t v_mask86 = vmseq_vx_i32m1_b11(v_arr, 94, vl);\n    vint32m1_t v_mask87 = vmseq_vx_i32m1_b11(v_arr, 95, vl);\n    vint32m1_t v_mask88 = vmseq_vx_i32m1_b11(v_arr, 96, vl);\n    vint32m1_t v_mask89 = vmseq_vx_i32m1_b11(v_arr, 97, vl);\n    vint32m1_t v_mask90 = vmseq_vx_i32m1_b11(v_arr, 98, vl);\n    vint32m1_t v_mask91 = vmseq_vx_i32m1_b11(v_arr, 99, vl);\n\n    vint32m1_t v_mask_final = vmor_mm_b11(v_mask, v_mask2, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask3, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask4, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask5, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask6, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask7, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask8, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask9, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask10, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask11, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask12, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask13, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask14, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask15, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask16, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask17, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask18, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask19, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask20, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask21, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask22, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask23, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask24, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask25, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask26, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask27, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask28, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask29, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask30, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask31, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask32, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask33, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask34, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask35, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask36, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask37, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask38, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask39, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask40, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask41, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask42, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask43, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask44, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask45, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask46, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask47, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask48, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask49, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask50, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask51, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask52, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask53, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask54, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask55, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask56, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask57, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask58, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask59, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask60, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask61, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask62, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask63, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask64, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask65, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask66, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask67, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask68, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask69, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask70, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask71, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask72, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask73, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask74, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask75, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask76, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask77, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask78, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask79, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask80, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask81, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask82, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask83, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask84, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask85, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask86, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask87, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask88, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask89, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask90, vl);\n    v_mask_final = vmor_mm_b11(v_mask_final, v_mask91, vl);\n\n    vint32m1_t v_filtered = vmv_v_v_i32m1(v_arr, v_mask_final, vl);\n    vint32m1_t v_sum = vredsum_vs_i32m1_i32m1(v_filtered, v_sum, vl);\n\n    int sum = vsum_vs_i32m1_i32(v_sum, 0, vl);\n    return sum;\n}\n```"}
{"task_id": "SimdBench_122_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nbool is_sorted_simd(const std::vector<int> &lst) {\n    size_t n = lst.size();\n    if (n <= 1) return true;\n\n    size_t vl = __riscv_vsetvl_e32m1(n);\n    vint32m1_t v = __riscv_vle32_v_i32m1(lst.data(), vl);\n\n    vint32m1_t v_shifted = __riscv_vslide1down_vx_i32m1(v, 0, vl);\n    vint32m1_t v_diff = __riscv_vsub_vv_i32m1(v_shifted, v, vl);\n\n    vint32m1_t v_zeros = __riscv_vmv_v_x_i32m1(0, vl);\n    vint32m1_t v_ones = __riscv_vmv_v_x_i32m1(1, vl);\n\n    vint32m1_t v_lt = __riscv_vmslt_vv_i32m1(v_diff, v_zeros, vl);\n    vint32m1_t v_eq = __riscv_vmseq_vv_i32m1(v_diff, v_zeros, vl);\n\n    vint32m1_t v_or = __riscv_vmor_mm_b32(v_lt, v_eq, vl);\n    vint32m1_t v_and = __riscv_vmand_mm_b32(v_or, v_ones, vl);\n\n    bool all_sorted = __riscv_vmv_x_s_b32(__riscv_vreduc_and_vm_b32(v_and, v_ones, vl));\n\n    if (!all_sorted) return false;\n\n    vint32m1_t v_eq_mask = __riscv_vmseq_vv_i32m1(v_diff, v_zeros, vl);\n    vint32m1_t v_eq_count = __riscv_vmv_v_x_i32m1(0, vl);\n    vint32m1_t v_eq_count_inc = __riscv_vadd_vv_i32m1(v_eq_count, v_eq_mask, vl);\n\n    vint32m1_t v_max_eq_count = __riscv_vreduc_max_vs_i32m1_i32m1(v_eq_count_inc, v_eq_count, vl);\n\n    bool no_duplicates = __riscv_vmv_x_s_i32m1(v_max_eq_count) <= 1;\n\n    return no_duplicates;\n}\n```"}
{"task_id": "SimdBench_122_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nbool is_sorted_simd(const std::vector<int> &lst) {\n    size_t n = lst.size();\n    if (n <= 1) return true;\n\n    size_t vl = __riscv_vsetvl_e32m1(n);\n    vint32m1_t v = __riscv_vle32_v_i32m1(&lst[0], vl);\n\n    vint32m1_t v_shifted = __riscv_vslide1down_vx_i32m1(v, 0, vl);\n    vint32m1_t v_diff = __riscv_vsub_vv_i32m1(v, v_shifted, vl);\n\n    vint32m1_t v_lt_zero = __riscv_vmslt_vx_i32m1(v_diff, 0, vl);\n    bool any_lt_zero = __riscv_vmv_x_s_b32(__riscv_vfirst_m_b32(v_lt_zero, vl));\n\n    if (any_lt_zero) return false;\n\n    vint32m1_t v_eq_zero = __riscv_vmseq_vx_i32m1(v_diff, 0, vl);\n    vint32m1_t v_eq_zero_shifted = __riscv_vslide1down_vx_i32m1(v_eq_zero, 0, vl);\n    vint32m1_t v_and = __riscv_vand_vv_b32(v_eq_zero, v_eq_zero_shifted, vl);\n    bool any_duplicate = __riscv_vmv_x_s_b32(__riscv_vfirst_m_b32(v_and, vl));\n\n    return !any_duplicate;\n}\n```"}
{"task_id": "SimdBench_122_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nbool is_sorted_simd(const std::vector<int> &lst) {\n    size_t n = lst.size();\n    if (n <= 1) return true;\n\n    vint32m1_t v_a = __riscv_vle32_v_i32m1(lst.data(), n, n);\n    vint32m1_t v_b = __riscv_vslideup_vx_i32m1(v_a, 1, n);\n\n    vbool32_t mask = __riscv_vmslt_vv_b32(v_a, v_b, n);\n    bool all_sorted = __riscv_vcpop_m_b32(mask, n) == n - 1;\n\n    if (!all_sorted) return false;\n\n    vint32m1_t v_c = __riscv_vslideup_vx_i32m1(v_a, 2, n);\n    vbool32_t mask_dup = __riscv_vmseq_vv_b32(v_a, v_c, n);\n    bool no_duplicates = __riscv_vcpop_m_b32(mask_dup, n) == 0;\n\n    return no_duplicates;\n}\n```"}
{"task_id": "SimdBench_122_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nbool is_sorted_simd(const std::vector<int> &lst) {\n    size_t n = lst.size();\n    if (n <= 1) return true;\n\n    size_t vl = __riscv_vsetvl_e32m1(n);\n    vuint32m1_t v_a = __riscv_vle32_v_u32m1(&lst[0], vl);\n\n    for (size_t i = 1; i < n; i += vl) {\n        vuint32m1_t v_b = __riscv_vle32_v_u32m1(&lst[i], vl);\n        vuint32m1_t v_cmp = __riscv_vmsltu_vv_u32m1_b32(v_a, v_b, vl);\n        vuint32m1_t v_eq = __riscv_vmseq_vv_u32m1_b32(v_a, v_b, vl);\n\n        bool all_sorted = __riscv_vmv_x_s_b32(__riscv_vmand_mm_b32(v_cmp, v_eq, vl));\n        if (!all_sorted) return false;\n\n        v_a = v_b;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_122_RVV", "completion": "```cpp\nbool is_sorted_simd(const std::vector<int> & lst) {\n    size_t n = lst.size();\n    if (n == 0) return true;\n\n    size_t vl = __riscv_vsetvl_e32m1(n);\n    vuint32m1_t v = __riscv_vle32_v_u32m1(&lst[0], vl);\n\n    vuint32m1_t v_shifted = __riscv_vslide1down_vx_u32m1(v, 0, vl);\n    vuint32m1_t v_diff = __riscv_vsub_vv_u32m1(v, v_shifted, vl);\n\n    vuint32m1_t v_ones = __riscv_vmv_v_x_u32m1(1, vl);\n    vuint32m1_t v_zeros = __riscv_vmv_v_x_u32m1(0, vl);\n\n    vuint32m1_t v_lt = __riscv_vmslt_vv_u32m1(v_diff, v_ones, vl);\n    vuint32m1_t v_eq = __riscv_vmseq_vv_u32m1(v_diff, v_zeros, vl);\n\n    vuint32m1_t v_and = __riscv_vmand_mm_u32m1(v_lt, v_eq, vl);\n    vuint32m1_t v_or = __riscv_vmor_mm_u32m1(v_and, v_eq, vl);\n\n    bool all_true = __riscv_vmv_x_s_u32m1_f(v_or, vl) == -1;\n\n    if (!all_true) return false;\n\n    vuint32m1_t v_duplicates = __riscv_vmsne_vv_u32m1(v, v_shifted, vl);\n    vuint32m1_t v_duplicates_and = __riscv_vmand_mm_u32m1(v_duplicates, v_eq, vl);\n\n    bool no_duplicates = __riscv_vmv_x_s_u32m1_f(v_duplicates_and, vl) == 0;\n\n    return no_duplicates;\n}\n```"}
{"task_id": "SimdBench_123_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nint prod_signs_simd(const std::vector<int> &arr) {\n    if (arr.empty()) {\n        return -32768;\n    }\n\n    size_t n = arr.size();\n    vint32m1_t v_arr = __riscv_vle32_v_i32m1(arr.data(), n);\n\n    vint32m1_t v_signs = __riscv_vsign_v_i32m1(v_arr, v_arr, v_arr);\n    vint32m1_t v_abs = __riscv_vabs_v_i32m1(v_arr);\n\n    vint32m1_t v_prod_signs = __riscv_vredprod_vs_i32m1_i32m1(v_signs, 1, v_signs, 0);\n    vint32m1_t v_sum_abs = __riscv_vredsum_vs_i32m1_i32m1(v_abs, 0, v_abs, 0);\n\n    int prod_signs = __riscv_vmv_x_s_i32m1_i32(v_prod_signs);\n    int sum_abs = __riscv_vmv_x_s_i32m1_i32(v_sum_abs);\n\n    return prod_signs * sum_abs;\n}\n```"}
{"task_id": "SimdBench_123_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nint prod_signs_simd(const std::vector<int>& arr) {\n    if (arr.empty()) {\n        return -32768;\n    }\n\n    size_t n = arr.size();\n    int32_t* data = const_cast<int32_t*>(arr.data());\n\n    vint32m1_t v_arr = __riscv_vle32_v_i32m1(data, n, n);\n    vint32m1_t v_signs = __riscv_vsign_v_i32m1(v_arr, v_arr, 0);\n\n    vint32m1_t v_abs = __riscv_vabs_v_i32m1(v_arr, v_arr);\n    vint32m1_t v_sum = __riscv_vredsum_vs_i32m1_i32m1(v_abs, __riscv_vmv_v_x_i32m1(0, n), 0);\n    vint32m1_t v_prod = __riscv_vredprod_vs_i32m1_i32m1(v_signs, __riscv_vmv_v_x_i32m1(1, n), 0);\n\n    int sum = __riscv_vmv_x_s_i32m1_i32(v_sum);\n    int prod = __riscv_vmv_x_s_i32m1_i32(v_prod);\n\n    return sum * prod;\n}\n```"}
{"task_id": "SimdBench_123_RVV", "completion": "```c++\nint prod_signs_simd(const std::vector<int> & arr) {\n    if (arr.empty()) {\n        return -32768;\n    }\n\n    size_t n = arr.size();\n    int sum_magnitudes = 0;\n    int prod_signs = 1;\n\n    size_t vl = __riscv_vsetvl_e32m1(n);\n    vint32m1_t v_arr = __riscv_vle32_v_i32m1(arr.data(), vl);\n\n    vint32m1_t v_signs = __riscv_vsgn_v_i32m1(v_arr, vl);\n    vint32m1_t v_abs = __riscv_vabs_v_i32m1(v_arr, vl);\n\n    sum_magnitudes = __riscv_vredsum_vs_i32m1_i32m1(0, v_abs, vl);\n    prod_signs = __riscv_vredprod_vs_i32m1_i32m1(1, v_signs, vl);\n\n    return sum_magnitudes * prod_signs;\n}\n```"}
{"task_id": "SimdBench_123_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nint prod_signs_simd(const std::vector<int> &arr) {\n    if (arr.empty()) {\n        return -32768;\n    }\n\n    size_t n = arr.size();\n    vint32m1_t v_arr = __riscv_vle32_v_i32m1(arr.data(), n);\n\n    vint32m1_t v_signs = __riscv_vsign_v_i32m1(v_arr, v_arr, 0);\n    vint32m1_t v_magnitudes = __riscv_vabs_v_i32m1(v_arr);\n\n    vint32m1_t v_prod_signs = __riscv_vredsum_vs_i32m1_i32m1(v_signs, 0, v_signs, 0);\n    vint32m1_t v_sum_magnitudes = __riscv_vredsum_vs_i32m1_i32m1(v_magnitudes, 0, v_magnitudes, 0);\n\n    int prod_signs = __riscv_vmv_x_s_i32m1_i32(v_prod_signs);\n    int sum_magnitudes = __riscv_vmv_x_s_i32m1_i32(v_sum_magnitudes);\n\n    return sum_magnitudes * prod_signs;\n}\n```"}
{"task_id": "SimdBench_123_RVV", "completion": "```c++\nint prod_signs_simd(const std::vector<int> & arr) {\n    if (arr.empty()) {\n        return -32768;\n    }\n\n    size_t n = arr.size();\n    int sum = 0;\n    int prod_signs = 1;\n\n    size_t vl = __riscv_vsetvl_e32m1(n);\n    vint32m1_t v_arr = __riscv_vle32_v_i32m1(arr.data(), vl);\n\n    vint32m1_t v_abs = __riscv_vabs_v_i32m1(v_arr, vl);\n    vint32m1_t v_signs = __riscv_vsign_v_i32m1(v_arr, vl);\n\n    vint32m1_t v_prod_signs = __riscv_vredsum_vs_i32m1_i32m1(v_signs, v_prod_signs, vl);\n    vint32m1_t v_sum = __riscv_vredsum_vs_i32m1_i32m1(v_abs, v_sum, vl);\n\n    sum = __riscv_vmv_x_s_i32m1_i32(v_sum);\n    prod_signs = __riscv_vmv_x_s_i32m1_i32(v_prod_signs);\n\n    return sum * prod_signs;\n}\n```"}
{"task_id": "SimdBench_124_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<int> minPath_simd(const std::vector<std::vector<int>>& grid, int k) {\n    int N = grid.size();\n    std::vector<int> min_path(k);\n    std::vector<int> current_path(k);\n    std::vector<int> best_path(k, INT_MAX);\n\n    auto is_valid = [&](int x, int y) {\n        return x >= 0 && x < N && y >= 0 && y < N;\n    };\n\n    auto dfs = [&](auto&& self, int x, int y, int step) -> void {\n        if (step == k) {\n            if (current_path < best_path) {\n                best_path = current_path;\n            }\n            return;\n        }\n\n        int dx[] = {-1, 1, 0, 0};\n        int dy[] = {0, 0, -1, 1};\n\n        for (int i = 0; i < 4; ++i) {\n            int nx = x + dx[i];\n            int ny = y + dy[i];\n            if (is_valid(nx, ny)) {\n                current_path[step] = grid[nx][ny];\n                self(self, nx, ny, step + 1);\n            }\n        }\n    };\n\n    for (int i = 0; i < N; ++i) {\n        for (int j = 0; j < N; ++j) {\n            current_path[0] = grid[i][j];\n            dfs(dfs, i, j, 1);\n        }\n    }\n\n    return best_path;\n}\n```"}
{"task_id": "SimdBench_124_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <algorithm>\n#include <limits>\n\nstd::vector<int> minPath_simd(const std::vector<std::vector<int>>& grid, int k) {\n    int N = grid.size();\n    std::vector<int> min_path(k, std::numeric_limits<int>::max());\n    std::vector<int> current_path(k);\n\n    // Directions for moving to neighbor cells (right, down, left, up)\n    const int directions[4][2] = {{0, 1}, {1, 0}, {0, -1}, {-1, 0}};\n\n    // Helper function to check if a position is within the grid\n    auto is_valid = [&](int x, int y) {\n        return x >= 0 && x < N && y >= 0 && y < N;\n    };\n\n    // Recursive function to find the minimum path\n    auto find_min_path = [&](auto&& self, int x, int y, int step) -> void {\n        if (step == k) {\n            if (current_path < min_path) {\n                min_path = current_path;\n            }\n            return;\n        }\n\n        for (const auto& dir : directions) {\n            int nx = x + dir[0];\n            int ny = y + dir[1];\n            if (is_valid(nx, ny)) {\n                current_path[step] = grid[nx][ny];\n                self(self, nx, ny, step + 1);\n            }\n        }\n    };\n\n    // Start the search from each cell in the grid\n    for (int i = 0; i < N; ++i) {\n        for (int j = 0; j < N; ++j) {\n            current_path[0] = grid[i][j];\n            find_min_path(find_min_path, i, j, 1);\n        }\n    }\n\n    return min_path;\n}\n```"}
{"task_id": "SimdBench_124_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <algorithm>\n#include <limits>\n\nstd::vector<int> minPath_simd(const std::vector<std::vector<int>>& grid, int k) {\n    int N = grid.size();\n    std::vector<int> min_path(k, std::numeric_limits<int>::max());\n    std::vector<int> current_path(k);\n\n    for (int start_row = 0; start_row < N; ++start_row) {\n        for (int start_col = 0; start_col < N; ++start_col) {\n            current_path[0] = grid[start_row][start_col];\n            std::vector<std::pair<int, int>> stack = {{start_row, start_col}};\n\n            while (!stack.empty()) {\n                auto [row, col] = stack.back();\n                stack.pop_back();\n\n                for (int step = 1; step < k; ++step) {\n                    std::vector<std::pair<int, int>> neighbors;\n                    if (row > 0) neighbors.emplace_back(row - 1, col);\n                    if (row < N - 1) neighbors.emplace_back(row + 1, col);\n                    if (col > 0) neighbors.emplace_back(row, col - 1);\n                    if (col < N - 1) neighbors.emplace_back(row, col + 1);\n\n                    for (const auto& [nr, nc] : neighbors) {\n                        current_path[step] = grid[nr][nc];\n                        stack.emplace_back(nr, nc);\n                    }\n                }\n\n                if (current_path < min_path) {\n                    min_path = current_path;\n                }\n            }\n        }\n    }\n\n    return min_path;\n}\n```"}
{"task_id": "SimdBench_124_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <algorithm>\n#include <limits>\n\nstd::vector<int> minPath_simd(const std::vector<std::vector<int>>& grid, int k) {\n    int N = grid.size();\n    std::vector<int> min_path(k, std::numeric_limits<int>::max());\n    std::vector<int> current_path(k);\n\n    // Directions for moving to neighbor cells (right, down, left, up)\n    const int directions[4][2] = {{0, 1}, {1, 0}, {0, -1}, {-1, 0}};\n\n    // Helper function to check if a position is within the grid\n    auto is_valid = [&](int x, int y) {\n        return x >= 0 && x < N && y >= 0 && y < N;\n    };\n\n    // Recursive function to find the minimum path\n    std::function<void(int, int, int)> dfs = [&](int x, int y, int step) {\n        if (step == k) {\n            if (current_path < min_path) {\n                min_path = current_path;\n            }\n            return;\n        }\n\n        current_path[step] = grid[x][y];\n\n        for (const auto& dir : directions) {\n            int nx = x + dir[0];\n            int ny = y + dir[1];\n            if (is_valid(nx, ny)) {\n                dfs(nx, ny, step + 1);\n            }\n        }\n    };\n\n    // Start DFS from each cell\n    for (int i = 0; i < N; ++i) {\n        for (int j = 0; j < N; ++j) {\n            dfs(i, j, 0);\n        }\n    }\n\n    return min_path;\n}\n```"}
{"task_id": "SimdBench_124_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<int> minPath_simd(const std::vector<std::vector<int>>& grid, int k) {\n    int N = grid.size();\n    std::vector<int> min_path(k);\n    std::vector<int> current_path(k);\n    std::vector<int> best_path(k, INT_MAX);\n\n    auto is_valid = [&](int x, int y) {\n        return x >= 0 && x < N && y >= 0 && y < N;\n    };\n\n    auto dfs = [&](auto&& self, int x, int y, int depth) -> void {\n        if (depth == k) {\n            if (std::lexicographical_compare(current_path.begin(), current_path.end(), best_path.begin(), best_path.end())) {\n                best_path = current_path;\n            }\n            return;\n        }\n\n        int dx[] = {-1, 1, 0, 0};\n        int dy[] = {0, 0, -1, 1};\n\n        for (int i = 0; i < 4; ++i) {\n            int nx = x + dx[i];\n            int ny = y + dy[i];\n            if (is_valid(nx, ny)) {\n                current_path[depth] = grid[nx][ny];\n                self(self, nx, ny, depth + 1);\n            }\n        }\n    };\n\n    for (int i = 0; i < N; ++i) {\n        for (int j = 0; j < N; ++j) {\n            current_path[0] = grid[i][j];\n            dfs(dfs, i, j, 1);\n        }\n    }\n\n    return best_path;\n}\n```"}
{"task_id": "SimdBench_125_RVV", "completion": "```c\nuint64_t digits_simd(uint64_t n) {\n    uint64_t product = 1;\n    size_t vl = __riscv_vsetvl_e64m1(1);\n\n    vint64m1_t v_digits = __riscv_vundefined_v64m1();\n    vint64m1_t v_odd_mask = __riscv_vundefined_v64m1();\n    vint64m1_t v_product = __riscv_vundefined_v64m1();\n\n    while (n > 0) {\n        uint64_t digit = n % 10;\n        v_digits = __riscv_vslideup_vx_v64m1(v_digits, digit, vl);\n        n /= 10;\n\n        v_odd_mask = __riscv_vmsne_vx_i64m1_b32(v_digits, 0, vl);\n        v_odd_mask = __riscv_vmand_mm_b32(v_odd_mask, __riscv_vmsne_vx_i64m1_b32(v_digits, 2, vl), vl);\n        v_odd_mask = __riscv_vmand_mm_b32(v_odd_mask, __riscv_vmsne_vx_i64m1_b32(v_digits, 4, vl), vl);\n        v_odd_mask = __riscv_vmand_mm_b32(v_odd_mask, __riscv_vmsne_vx_i64m1_b32(v_digits, 6, vl), vl);\n        v_odd_mask = __riscv_vmand_mm_b32(v_odd_mask, __riscv_vmsne_vx_i64m1_b32(v_digits, 8, vl), vl);\n\n        v_product = __riscv_vmseq_vx_i64m1_b32(v_digits, 1, vl);\n        v_product = __riscv_vmand_mm_b32(v_product, v_odd_mask, vl);\n        v_product = __riscv_vmul_vv_i64m1(v_product, v_digits, vl);\n\n        product *= __riscv_vmv_x_s_i64m1_i64(v_product);\n    }\n\n    return product == 1 ? 0 : product;\n}\n```"}
{"task_id": "SimdBench_125_RVV", "completion": "```c\nuint64_t digits_simd(uint64_t n) {\n    uint64_t product = 1;\n    uint64_t mask = 0;\n    size_t vl = __riscv_vsetvl_e64m1(1);\n\n    vint64m1_t v_digits = __riscv_vmv_v_x_i64m1(0, vl);\n    vint64m1_t v_odd_mask = __riscv_vmv_v_x_i64m1(0, vl);\n    vint64m1_t v_product = __riscv_vmv_v_x_i64m1(1, vl);\n\n    while (n > 0) {\n        uint64_t digit = n % 10;\n        n /= 10;\n\n        v_digits = __riscv_vmv_v_x_i64m1(digit, vl);\n        v_odd_mask = __riscv_vand_vx_i64m1(v_digits, 1, vl);\n\n        vint64m1_t v_is_odd = __riscv_vmseq_vx_i64m1_b1(v_odd_mask, 1, vl);\n        vint64m1_t v_odd_digits = __riscv_vmerge_vvm_i64m1(v_digits, v_digits, v_is_odd, vl);\n\n        v_product = __riscv_vmul_vv_i64m1(v_product, v_odd_digits, vl);\n        mask |= __riscv_vmv_x_s_i64m1_b1(v_is_odd);\n    }\n\n    if (mask == 0) {\n        return 0;\n    }\n\n    product = __riscv_vmv_x_s_i64m1(v_product);\n    return product;\n}\n```"}
{"task_id": "SimdBench_125_RVV", "completion": "```c\nuint64_t digits_simd(uint64_t n) {\n    uint64_t product = 1;\n    size_t vl = __riscv_vsetvl_e64m1(1);\n    vuint64m1_t v_n = __riscv_vle64_v_u64m1(&n, vl);\n    vuint64m1_t v_digits = __riscv_vid_v_u64m1(vl);\n    vuint64m1_t v_odd_mask = __riscv_vmsne_vx_u64m1_b32(v_digits, 0, 1);\n    vuint64m1_t v_odd_digits = __riscv_vand_vv_u64m1(v_digits, v_odd_mask, vl);\n    vuint64m1_t v_product = __riscv_vmv_v_x_u64m1(1, vl);\n\n    while (n > 0) {\n        vuint64m1_t v_digit = __riscv_vmv_v_x_u64m1(n % 10, vl);\n        vuint64m1_t v_is_odd = __riscv_vmsne_vx_u64m1_b32(v_digit, 0, 1);\n        vuint64m1_t v_odd_digit = __riscv_vand_vv_u64m1(v_digit, v_is_odd, vl);\n        v_product = __riscv_vmul_vv_u64m1(v_product, v_odd_digit, vl);\n        n /= 10;\n    }\n\n    product = __riscv_vmv_x_s_u64m1_i64(v_product, 0);\n    return product;\n}\n```"}
{"task_id": "SimdBench_125_RVV", "completion": "```c\nuint64_t digits_simd(uint64_t n) {\n    uint64_t product = 1;\n    bool has_odd = false;\n\n    while (n > 0) {\n        uint64_t digit = n % 10;\n        n /= 10;\n\n        if (digit % 2 != 0) {\n            product *= digit;\n            has_odd = true;\n        }\n    }\n\n    return has_odd ? product : 0;\n}\n```"}
{"task_id": "SimdBench_125_RVV", "completion": "```c\nuint64_t digits_simd(uint64_t n) {\n    size_t vl = __riscv_vsetvl_e64m1(1);\n    vuint64m1_t v_n = __riscv_vle64_v_u64m1(&n, vl);\n\n    vuint64m1_t v_digits = __riscv_vid_v_u64m1(vl);\n    vuint64m1_t v_ones = __riscv_vmv_v_x_u64m1(1, vl);\n    vuint64m1_t v_tens = __riscv_vmv_v_x_u64m1(10, vl);\n\n    vuint64m1_t v_mod = __riscv_vremu_vv_u64m1(v_n, v_tens, vl);\n    vuint64m1_t v_div = __riscv_vdivu_vv_u64m1(v_n, v_tens, vl);\n\n    vuint64m1_t v_is_odd = __riscv_vand_vv_u64m1(v_mod, v_ones, vl);\n    vuint64m1_t v_odd_digits = __riscv_vmul_vv_u64m1(v_mod, v_is_odd, vl);\n\n    uint64_t product = 1;\n    for (size_t i = 0; i < vl; ++i) {\n        if (v_odd_digits[i] != 0) {\n            product *= v_odd_digits[i];\n        }\n    }\n\n    return product == 1 ? 0 : product;\n}\n```"}
{"task_id": "SimdBench_126_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <cmath>\n\nuint64_t sum_squares_simd(const std::vector<float> & lst) {\n    size_t n = lst.size();\n    size_t vl = vsetvl_e32m1(n);\n\n    vfloat32m1_t v_input = vle32_v_f32m1(lst.data(), vl);\n    vfloat32m1_t v_ceil = vfceil_v_f32m1(v_input, vl);\n    vfloat32m1_t v_squared = vfmul_vv_f32m1(v_ceil, v_ceil, vl);\n\n    float sum = 0.0f;\n    for (size_t i = 0; i < n; i += vl) {\n        vl = vsetvl_e32m1(n - i);\n        vfloat32m1_t v_segment = vle32_v_f32m1(lst.data() + i, vl);\n        vfloat32m1_t v_ceil_segment = vfceil_v_f32m1(v_segment, vl);\n        vfloat32m1_t v_squared_segment = vfmul_vv_f32m1(v_ceil_segment, v_ceil_segment, vl);\n        sum += vfredusum_vs_f32m1_f32m1(v_squared_segment, v_squared_segment, sum, vl);\n    }\n\n    return static_cast<uint64_t>(sum);\n}\n```"}
{"task_id": "SimdBench_126_RVV", "completion": "```c++\nuint64_t sum_squares_simd(const std::vector<float> & lst) {\n    size_t n = lst.size();\n    size_t vl = vsetvl_e32m1(n);\n\n    vfloat32m1_t v_lst = vle32_v_f32m1(&lst[0], vl);\n    vfloat32m1_t v_ceil = vfceil_v_f32m1(v_lst, vl);\n    vfloat32m1_t v_squared = vfmul_vv_f32m1(v_ceil, v_ceil, vl);\n\n    float sum = 0.0f;\n    for (size_t i = 0; i < n; i += vl) {\n        vl = vsetvl_e32m1(n - i);\n        vfloat32m1_t v_sum = vfredusum_vs_f32m1_f32m1(v_squared, v_squared, vl);\n        sum += vfmv_f_s_f32m1_f32(v_sum);\n        v_lst = vle32_v_f32m1(&lst[i + vl], vl);\n        v_ceil = vfceil_v_f32m1(v_lst, vl);\n        v_squared = vfmul_vv_f32m1(v_ceil, v_ceil, vl);\n    }\n\n    return static_cast<uint64_t>(sum);\n}\n```"}
{"task_id": "SimdBench_126_RVV", "completion": "```c++\nuint64_t sum_squares_simd(const std::vector<float> & lst) {\n    size_t n = lst.size();\n    size_t vl = vsetvl_e32m1(n);\n\n    vfloat32m1_t v_input = vle32_v_f32m1(&lst[0], vl);\n    vfloat32m1_t v_ceil = vfceil_v_f32m1(v_input, vl);\n    vfloat32m1_t v_squared = vfmul_vv_f32m1(v_ceil, v_ceil, vl);\n\n    float sum = 0.0f;\n    for (size_t i = 0; i < n; i += vl) {\n        vl = vsetvl_e32m1(n - i);\n        vfloat32m1_t v_partial_sum = vfredusum_vs_f32m1_f32m1(v_squared, v_f32m1(0.0f), vl);\n        sum += vfmv_f_s_f32m1_f32(v_partial_sum);\n    }\n\n    return static_cast<uint64_t>(sum);\n}\n```"}
{"task_id": "SimdBench_126_RVV", "completion": "```c++\nuint64_t sum_squares_simd(const std::vector<float> & lst) {\n    size_t n = lst.size();\n    float *data = lst.data();\n\n    size_t vl = __riscv_vsetvl_e32m1(n);\n    vfloat32m1_t v_data = __riscv_vle32_v_f32m1(data, vl);\n\n    vfloat32m1_t v_ceil = __riscv_vrceil_v_f32m1(v_data, vl);\n    vfloat32m1_t v_squared = __riscv_vfmul_vv_f32m1(v_ceil, v_ceil, vl);\n\n    float sum = __riscv_vfmv_f_s_f32m1_f32(__riscv_vfredusum_vs_f32m1_f32m1(v_squared, __riscv_vfmv_v_f_f32m1(0.0f, vl), vl));\n\n    return static_cast<uint64_t>(sum);\n}\n```"}
{"task_id": "SimdBench_126_RVV", "completion": "```c++\nuint64_t sum_squares_simd(const std::vector<float> & lst) {\n    size_t n = lst.size();\n    size_t vl = vsetvl_e32m1(n);\n\n    vfloat32m1_t v_input = vle32_v_f32m1(&lst[0], vl);\n    vfloat32m1_t v_ceil = vfceil_v_f32m1(v_input, vl);\n    vfloat32m1_t v_squared = vfmul_vv_f32m1(v_ceil, v_ceil, vl);\n\n    vfloat32m1_t v_sum = vfredusum_vs_f32m1_f32m1(v_squared, v_sum, vl);\n    float sum = vfmv_f_s_f32m1_f32(v_sum);\n\n    return static_cast<uint64_t>(sum);\n}\n```"}
{"task_id": "SimdBench_127_RVV", "completion": "```c++\nint can_arrange_simd(const std::vector<int> & arr) {\n    size_t n = arr.size();\n    if (n < 2) return -1;\n\n    int result = -1;\n    size_t vl = __riscv_vsetvl_e32m1(n);\n\n    vint32m1_t v_arr = __riscv_vle32_v_i32m1(arr.data(), vl);\n    vint32m1_t v_arr_shifted = __riscv_vslide1down_vx_i32m1(v_arr, 0, vl);\n\n    vuint32m1_t v_mask = __riscv_vmsge_vv_i32m1_b32(v_arr, v_arr_shifted, vl);\n    vuint32m1_t v_indices = __riscv_vid_v_u32m1(vl);\n\n    vuint32m1_t v_filtered_indices = __riscv_vcompress_vm_u32m1(v_indices, v_mask, vl);\n\n    size_t filtered_vl = __riscv_vsetvl_e32m1(__riscv_vcpop_m_b32(v_mask, vl));\n    if (filtered_vl > 0) {\n        vuint32m1_t v_max_index = __riscv_vredmaxu_vs_u32m1_u32m1(v_filtered_indices, 0, filtered_vl);\n        result = __riscv_vmv_x_s_u32m1_u32(v_max_index);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_127_RVV", "completion": "```c++\nint can_arrange_simd(const std::vector<int> & arr) {\n    size_t n = arr.size();\n    if (n < 2) return -1;\n\n    int max_index = -1;\n    size_t vl = vsetvl_e32m1(n);\n\n    vint32m1_t v_arr = vle32_v_i32m1(&arr[0], vl);\n    vint32m1_t v_arr_shifted = vle32_v_i32m1(&arr[1], vl - 1);\n\n    vuint32m1_t v_mask = vmseq_vv_i32m1_b32(v_arr, v_arr_shifted, vl - 1);\n    size_t index = vfirst_m_b32(v_mask, vl - 1);\n\n    if (index < vl - 1) {\n        max_index = index + 1;\n    }\n\n    return max_index;\n}\n```"}
{"task_id": "SimdBench_127_RVV", "completion": "```c++\nint can_arrange_simd(const std::vector<int> & arr) {\n    size_t n = arr.size();\n    if (n < 2) return -1;\n\n    int max_index = -1;\n    size_t vl = vsetvl_e32m1(n);\n\n    vint32m1_t v_arr = vle32_v_i32m1(&arr[0], vl);\n    vint32m1_t v_arr_shifted = vle32_v_i32m1(&arr[1], vl - 1);\n\n    vuint32m1_t v_mask = vmseq_vv_i32m1_b32(v_arr, v_arr_shifted, vl - 1);\n    size_t index = vfirst_m_b32(v_mask, vl - 1);\n\n    if (index < vl - 1) {\n        max_index = index;\n    }\n\n    return max_index;\n}\n```"}
{"task_id": "SimdBench_127_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nint can_arrange_simd(const std::vector<int>& arr) {\n    size_t n = arr.size();\n    if (n < 2) return -1;\n\n    size_t vlmax = __riscv_vsetvlmax_e32m1();\n    int largest_index = -1;\n\n    for (size_t i = 0; i < n; i += vlmax) {\n        size_t vl = __riscv_vsetvl_e32m1(n - i);\n        vuint32m1_t v_arr = __riscv_vle32_v_u32m1(&arr[i], vl);\n        vuint32m1_t v_arr_shifted = __riscv_vslide1down_vx_u32m1(v_arr, 0, vl);\n\n        vbool32_t mask = __riscv_vmsge_vv_u32m1_b32(v_arr, v_arr_shifted, vl);\n\n        if (__riscv_vfirst_m_b32(mask, vl) != -1) {\n            largest_index = i + __riscv_vfirst_m_b32(mask, vl);\n        }\n    }\n\n    return largest_index;\n}\n```"}
{"task_id": "SimdBench_127_RVV", "completion": "```c++\nint can_arrange_simd(const std::vector<int> & arr) {\n    size_t n = arr.size();\n    if (n < 2) return -1;\n\n    int max_index = -1;\n    size_t vl = vsetvl_e32m1(n);\n\n    vint32m1_t v_arr = vle32_v_i32m1(&arr[0], vl);\n    vint32m1_t v_arr_shifted = vle32_v_i32m1(&arr[1], vl - 1);\n\n    vuint32m1_t v_mask = vmseq_vv_i32m1_b32(v_arr, v_arr_shifted, vl - 1);\n\n    for (size_t i = 0; i < n - 1; i += vl) {\n        vl = vsetvl_e32m1(n - i);\n\n        v_arr = vle32_v_i32m1(&arr[i], vl);\n        v_arr_shifted = vle32_v_i32m1(&arr[i + 1], vl - 1);\n\n        v_mask = vmseq_vv_i32m1_b32(v_arr, v_arr_shifted, vl - 1);\n\n        size_t index = vfirst_m_b32(v_mask, vl - 1);\n        if (index != vl - 1) {\n            max_index = i + index;\n        }\n    }\n\n    return max_index;\n}\n```"}
{"task_id": "SimdBench_128_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> largest_smallest_integers_simd(const std::vector<int>& lst) {\n    size_t n = lst.size();\n    if (n == 0) return {0, 0};\n\n    vint32m1_t v_neg = __riscv_vmv_v_x_i32m1(0, 32);\n    vint32m1_t v_pos = __riscv_vmv_v_x_i32m1(INT32_MAX, 32);\n\n    for (size_t i = 0; i < n; i += 32) {\n        size_t vl = __riscv_vsetvl_e32m1(n - i);\n        vint32m1_t v_data = __riscv_vle32_v_i32m1(&lst[i], vl);\n\n        vint32m1_t v_neg_mask = __riscv_vmslt_vx_i32m1_b32(v_data, 0, vl);\n        vint32m1_t v_pos_mask = __riscv_vmsgt_vx_i32m1_b32(v_data, 0, vl);\n\n        v_neg = __riscv_vmax_vv_i32m1(v_neg, v_data, vl, v_neg_mask);\n        v_pos = __riscv_vmin_vv_i32m1(v_pos, v_data, vl, v_pos_mask);\n    }\n\n    int largest_neg = __riscv_vmv_x_s_i32m1_i32(v_neg);\n    int smallest_pos = __riscv_vmv_x_s_i32m1_i32(v_pos);\n\n    if (largest_neg == 0) largest_neg = 0;\n    if (smallest_pos == INT32_MAX) smallest_pos = 0;\n\n    return {largest_neg, smallest_pos};\n}\n```"}
{"task_id": "SimdBench_128_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> largest_smallest_integers_simd(const std::vector<int>& lst) {\n    size_t n = lst.size();\n    if (n == 0) return {0, 0};\n\n    vint32m1_t v = __riscv_vle32_v_i32m1(lst.data(), n, n);\n    vint32m1_t neg_mask = __riscv_vmslt_vx_i32m1_b32(v, 0, n);\n    vint32m1_t pos_mask = __riscv_vmsgt_vx_i32m1_b32(v, 0, n);\n\n    vint32m1_t neg_values = __riscv_vmerge_vvm_i32m1(v, __riscv_vmv_v_x_i32m1(0, n), neg_mask, n);\n    vint32m1_t pos_values = __riscv_vmerge_vvm_i32m1(v, __riscv_vmv_v_x_i32m1(0, n), pos_mask, n);\n\n    int largest_neg = __riscv_vreduce_max_vs_i32m1_i32(neg_values, 0, n);\n    int smallest_pos = __riscv_vreduce_min_vs_i32m1_i32(pos_values, 0, n);\n\n    return {largest_neg, smallest_pos};\n}\n```"}
{"task_id": "SimdBench_128_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <limits>\n\nstd::vector<int> largest_smallest_integers_simd(const std::vector<int>& lst) {\n    size_t n = lst.size();\n    if (n == 0) return {0, 0};\n\n    int32_t* data = const_cast<int32_t*>(lst.data());\n    vint32m1_t v_data = __riscv_vle32_v_i32m1(data, n);\n\n    vint32m1_t v_neg_mask = __riscv_vmslt_vx_i32m1_b32(v_data, 0, n);\n    vint32m1_t v_pos_mask = __riscv_vmsgt_vx_i32m1_b32(v_data, 0, n);\n\n    vint32m1_t v_neg = __riscv_vmerge_vvm_i32m1(v_data, __riscv_vmv_v_x_i32m1(std::numeric_limits<int32_t>::min(), n), v_neg_mask, n);\n    vint32m1_t v_pos = __riscv_vmerge_vvm_i32m1(v_data, __riscv_vmv_v_x_i32m1(std::numeric_limits<int32_t>::max(), n), v_pos_mask, n);\n\n    int32_t largest_neg = __riscv_vredmax_vs_i32m1_i32(v_neg, std::numeric_limits<int32_t>::min(), n);\n    int32_t smallest_pos = __riscv_vredmin_vs_i32m1_i32(v_pos, std::numeric_limits<int32_t>::max(), n);\n\n    return {largest_neg < 0 ? largest_neg : 0, smallest_pos > 0 ? smallest_pos : 0};\n}\n```"}
{"task_id": "SimdBench_128_RVV", "completion": "```c++\nstd::vector<int> largest_smallest_integers_simd(const std::vector<int>& lst) {\n    size_t n = lst.size();\n    if (n == 0) return {0, 0};\n\n    int32_t* data = const_cast<int32_t*>(lst.data());\n    vint32m1_t v_data = __riscv_vle32_v_i32m1(data, n);\n\n    vint32m1_t v_neg = __riscv_vmseq_vx_i32m1_b32(v_data, 0, n);\n    vint32m1_t v_pos = __riscv_vmsgt_vx_i32m1_b32(v_data, 0, n);\n\n    vint32m1_t v_neg_data = __riscv_vmerge_vvm_i32m1(v_data, __riscv_vmv_v_x_i32m1(0, n), v_neg, n);\n    vint32m1_t v_pos_data = __riscv_vmerge_vvm_i32m1(v_data, __riscv_vmv_v_x_i32m1(0, n), v_pos, n);\n\n    int32_t max_neg = __riscv_vredmax_vs_i32m1_i32m1(v_neg_data, __riscv_vmv_v_x_i32m1(INT32_MIN, n), n);\n    int32_t min_pos = __riscv_vredmin_vs_i32m1_i32m1(v_pos_data, __riscv_vmv_v_x_i32m1(INT32_MAX, n), n);\n\n    return {max_neg == INT32_MIN ? 0 : max_neg, min_pos == INT32_MAX ? 0 : min_pos};\n}\n```"}
{"task_id": "SimdBench_128_RVV", "completion": "```c++\nstd::vector<int> largest_smallest_integers_simd(const std::vector<int>& lst) {\n    size_t n = lst.size();\n    if (n == 0) return {0, 0};\n\n    int32_t* data = const_cast<int32_t*>(lst.data());\n    vint32m1_t v = __riscv_vle32_v_i32m1(data, n);\n\n    vint32m1_t v_neg = __riscv_vmseq_vx_i32m1_b32(v, 0, n);\n    vint32m1_t v_pos = __riscv_vmsgt_vx_i32m1_b32(v, 0, n);\n\n    vint32m1_t v_neg_vals = __riscv_vmerge_vvm_i32m1(v, __riscv_vmv_v_x_i32m1(0, n), v_neg, n);\n    vint32m1_t v_pos_vals = __riscv_vmerge_vvm_i32m1(v, __riscv_vmv_v_x_i32m1(0, n), v_pos, n);\n\n    int32_t max_neg = __riscv_vredmax_vs_i32m1_i32m1(v_neg_vals, __riscv_vmv_v_x_i32m1(INT32_MIN, n), n);\n    int32_t min_pos = __riscv_vredmin_vs_i32m1_i32m1(v_pos_vals, __riscv_vmv_v_x_i32m1(INT32_MAX, n), n);\n\n    return {max_neg == INT32_MIN ? 0 : max_neg, min_pos == INT32_MAX ? 0 : min_pos};\n}\n```"}
{"task_id": "SimdBench_129_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nuint64_t special_factorial_simd(uint64_t n) {\n    uint64_t result = 1;\n    size_t vl = vsetvl_e64m1(n);\n\n    vint64m1_t v_factorials = vid_v_i64m1(1, vl);\n    vint64m1_t v_indices = vid_v_i64m1(1, vl);\n\n    for (uint64_t i = 1; i <= n; ++i) {\n        v_factorials = vmul_vv_i64m1(v_factorials, v_indices, vl);\n        v_indices = vadd_vx_i64m1(v_indices, 1, vl);\n    }\n\n    result = vreduce_vm_i64m1_i64m1(v_factorials, result, vl);\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_129_RVV", "completion": "```c\nuint64_t special_factorial_simd(uint64_t n) {\n    uint64_t result = 1;\n    uint64_t factorial = 1;\n\n    for (uint64_t i = 1; i <= n; ++i) {\n        factorial *= i;\n        result *= factorial;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_129_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nuint64_t special_factorial_simd(uint64_t n) {\n    uint64_t result = 1;\n    uint64_t i = 1;\n\n    while (i <= n) {\n        uint64_t factorial = 1;\n        uint64_t j = 1;\n\n        while (j <= i) {\n            factorial *= j;\n            j++;\n        }\n\n        result *= factorial;\n        i++;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_129_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nuint64_t special_factorial_simd(uint64_t n) {\n    uint64_t result = 1;\n    size_t vl = __riscv_vsetvl_e64m1(n);\n\n    vuint64m1_t v_factorials = __riscv_vid_v_u64m1(vl);\n    vuint64m1_t v_ones = __riscv_vmv_v_x_u64m1(1, vl);\n\n    for (uint64_t i = 2; i <= n; ++i) {\n        vuint64m1_t v_i = __riscv_vmv_v_x_u64m1(i, vl);\n        v_factorials = __riscv_vmul_vv_u64m1(v_factorials, v_i, vl);\n    }\n\n    vuint64m1_t v_result = __riscv_vredsum_vs_u64m1_u64m1(v_factorials, v_ones, vl);\n    result = __riscv_vmv_x_s_u64m1_u64(v_result);\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_129_RVV", "completion": "```c\nuint64_t special_factorial_simd(uint64_t n) {\n    uint64_t result = 1;\n    uint64_t factorial = 1;\n\n    for (uint64_t i = 1; i <= n; ++i) {\n        factorial *= i;\n        result *= factorial;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_130_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nint sum_squares_simd(const std::vector<int>& lst) {\n    size_t n = lst.size();\n    if (n == 0) return 0;\n\n    vint32m1_t v = __riscv_vle32_v_i32m1(lst.data(), n);\n    vint32m1_t indices = __riscv_vid_v_i32m1(n);\n\n    vint32m1_t mask_multiple_of_3 = __riscv_vmseq_vx_i32m1_b32(indices, 0, 3);\n    vint32m1_t mask_multiple_of_4 = __riscv_vmseq_vx_i32m1_b32(indices, 0, 4);\n    vint32m1_t mask_not_multiple_of_3 = __riscv_vmsne_vx_i32m1_b32(indices, 0, 3);\n\n    vint32m1_t mask_square = __riscv_vmand_mm_b32(mask_multiple_of_3, mask_multiple_of_4, n);\n    vint32m1_t mask_cube = __riscv_vmand_mm_b32(mask_multiple_of_4, mask_not_multiple_of_3, n);\n\n    vint32m1_t v_squared = __riscv_vmul_vv_i32m1(v, v, n);\n    vint32m1_t v_cubed = __riscv_vmul_vv_i32m1(v_squared, v, n);\n\n    vint32m1_t result = __riscv_vmerge_vvm_i32m1(v, v_squared, mask_square, n);\n    result = __riscv_vmerge_vvm_i32m1(result, v_cubed, mask_cube, n);\n\n    vint32m1_t sum = __riscv_vredsum_vs_i32m1_i32m1(result, __riscv_vmv_v_x_i32m1(0, n), n);\n\n    return __riscv_vmv_x_s_i32m1_i32(sum);\n}\n```"}
{"task_id": "SimdBench_130_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nint sum_squares_simd(const std::vector<int>& lst) {\n    size_t n = lst.size();\n    if (n == 0) return 0;\n\n    const int* data = lst.data();\n    vint32m1_t v_data = __riscv_vle32_v_i32m1(data, n, 1);\n    vint32m1_t v_indices = __riscv_vid_v_i32m1(n, 1);\n\n    vint32m1_t v_mult3 = __riscv_vremu_vx_i32m1(v_indices, 3, n);\n    vint32m1_t v_mult4 = __riscv_vremu_vx_i32m1(v_indices, 4, n);\n\n    vint32m1_t v_square_mask = __riscv_vmseq_vx_i32m1_b32(v_mult3, 0, n);\n    vint32m1_t v_cube_mask = __riscv_vmandn_mm_b32(__riscv_vmseq_vx_i32m1_b32(v_mult4, 0, n), v_square_mask, n);\n\n    vint32m1_t v_squared = __riscv_vmul_vv_i32m1(v_data, v_data, n);\n    vint32m1_t v_cubed = __riscv_vmul_vv_i32m1(v_squared, v_data, n);\n\n    vint32m1_t v_result = __riscv_vmerge_vvm_i32m1(v_data, v_squared, v_square_mask, n);\n    v_result = __riscv_vmerge_vvm_i32m1(v_result, v_cubed, v_cube_mask, n);\n\n    vint32m1_t v_sum = __riscv_vredsum_vs_i32m1_i32m1(v_result, __riscv_vmv_v_x_i32m1(0, n), n);\n\n    return __riscv_vmv_x_s_i32m1_i32(v_sum);\n}\n```"}
{"task_id": "SimdBench_130_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nint sum_squares_simd(const std::vector<int>& lst) {\n    size_t n = lst.size();\n    if (n == 0) return 0;\n\n    const int* data = lst.data();\n    vint32m1_t vdata = __riscv_vle32_v_i32m1(data, n, n);\n    vint32m1_t vindex = __riscv_vid_v_i32m1(n);\n    vint32m1_t vmask3 = __riscv_vmseq_vx_i32m1_b32(vindex, 0, 3);\n    vint32m1_t vmask4 = __riscv_vmseq_vx_i32m1_b32(vindex, 0, 4);\n    vint32m1_t vmask3_not4 = __riscv_vmandn_mm_b32(vmask3, vmask4);\n\n    vint32m1_t vsquared = __riscv_vmul_vv_i32m1(vdata, vdata, vmask3);\n    vint32m1_t vcubed = __riscv_vmul_vv_i32m1(vdata, __riscv_vmul_vv_i32m1(vdata, vdata, vmask3_not4), vmask3_not4);\n\n    vint32m1_t vresult = __riscv_vmerge_vvm_i32m1(vdata, vsquared, vcubed, vmask3_not4);\n    vint32m1_t vsum = __riscv_vredsum_vs_i32m1_i32m1(vresult, __riscv_vmv_v_x_i32m1(0, 1), n);\n\n    return __riscv_vmv_x_s_i32m1_i32(vsum);\n}\n```"}
{"task_id": "SimdBench_130_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nint sum_squares_simd(const std::vector<int>& lst) {\n    size_t n = lst.size();\n    if (n == 0) return 0;\n\n    const int* data = lst.data();\n    vint32m1_t v_data = __riscv_vle32_v_i32m1(data, n, 1);\n    vint32m1_t v_indices = __riscv_vid_v_i32m1(n, 1);\n\n    vint32m1_t v_multiple_of_3 = __riscv_vrem_vx_i32m1(v_indices, 3, 1);\n    vint32m1_t v_multiple_of_4 = __riscv_vrem_vx_i32m1(v_indices, 4, 1);\n\n    vint32m1_t v_squared = __riscv_vmul_vv_i32m1(v_data, v_data, 1);\n    vint32m1_t v_cubed = __riscv_vmul_vv_i32m1(v_squared, v_data, 1);\n\n    vint32m1_t v_result = __riscv_vmerge_vvm_i32m1(v_data, v_squared, v_multiple_of_3 == 0, 1);\n    v_result = __riscv_vmerge_vvm_i32m1(v_result, v_cubed, (v_multiple_of_4 == 0) & (v_multiple_of_3 != 0), 1);\n\n    int sum = __riscv_vredsum_vs_i32m1_i32(v_result, 0, 1);\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_130_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nint sum_squares_simd(const std::vector<int>& lst) {\n    size_t n = lst.size();\n    if (n == 0) return 0;\n\n    int* data = lst.data();\n    int sum = 0;\n\n    size_t vl = __riscv_vsetvl_e32m1(n);\n    vint32m1_t vdata = __riscv_vle32_v_i32m1(data, vl);\n\n    vint32m1_t vindex = __riscv_vid_v_i32m1(vl);\n    vint32m1_t vmod3 = __riscv_vremu_vx_i32m1(vindex, 3, vl);\n    vint32m1_t vmod4 = __riscv_vremu_vx_i32m1(vindex, 4, vl);\n\n    vint32m1_t vsquare_mask = __riscv_vmseq_vx_i32m1_b32(vmod3, 0, vl);\n    vint32m1_t vcube_mask = __riscv_vmandn_mm_b32(__riscv_vmseq_vx_i32m1_b32(vmod4, 0, vl), vsquare_mask, vl);\n\n    vint32m1_t vsquared = __riscv_vmul_vv_i32m1(vdata, vdata, vl);\n    vint32m1_t vcubed = __riscv_vmul_vv_i32m1(vdata, __riscv_vmul_vv_i32m1(vdata, vdata, vl), vl);\n\n    vint32m1_t vresult = __riscv_vmerge_vvm_i32m1(vdata, vsquared, vsquare_mask, vl);\n    vresult = __riscv_vmerge_vvm_i32m1(vresult, vcubed, vcube_mask, vl);\n\n    vint32m1_t vsum = __riscv_vredsum_vs_i32m1_i32m1(vresult, __riscv_vmv_v_x_i32m1(0, vl), vl);\n    sum = __riscv_vmv_x_s_i32m1_i32(vsum);\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_131_RVV", "completion": "```c++\nint specialFilter_simd(const std::vector<int> & nums) {\n    size_t n = nums.size();\n    int count = 0;\n\n    if (n == 0) return 0;\n\n    size_t vl = __riscv_vsetvl_e32m1(n);\n    vint32m1_t v_nums = __riscv_vle32_v_i32m1(nums.data(), vl);\n\n    vint32m1_t v_abs_nums = __riscv_vabs_v_i32m1(v_nums, vl);\n    vint32m1_t v_ones = __riscv_vmv_v_x_i32m1(1, vl);\n    vint32m1_t v_tens = __riscv_vmv_v_x_i32m1(10, vl);\n\n    vint32m1_t v_first_digit = __riscv_vdiv_vv_i32m1(v_abs_nums, v_tens, vl);\n    vint32m1_t v_last_digit = __riscv_vrem_vv_i32m1(v_abs_nums, v_tens, vl);\n\n    vint32m1_t v_odd_digits = __riscv_vmv_v_x_i32m1(1, vl);\n    v_odd_digits = __riscv_vslideup_vx_i32m1(v_odd_digits, 1, vl);\n    v_odd_digits = __riscv_vslideup_vx_i32m1(v_odd_digits, 1, vl);\n    v_odd_digits = __riscv_vslideup_vx_i32m1(v_odd_digits, 1, vl);\n    v_odd_digits = __riscv_vslideup_vx_i32m1(v_odd_digits, 1, vl);\n\n    vint32m1_t v_first_odd = __riscv_vand_vv_i32m1(v_first_digit, v_odd_digits, vl);\n    vint32m1_t v_last_odd = __riscv_vand_vv_i32m1(v_last_digit, v_odd_digits, vl);\n\n    vint32m1_t v_both_odd = __riscv_vand_vv_i32m1(v_first_odd, v_last_odd, vl);\n    vint32m1_t v_greater_than_10 = __riscv_vmseq_vx_i32m1_b32(v_nums, 10, vl);\n\n    vint32m1_t v_result = __riscv_vand_vv_i32m1(v_both_odd, v_greater_than_10, vl);\n\n    count = __riscv_vcpop_m_i32m1(v_result, vl);\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_131_RVV", "completion": "```c++\nint specialFilter_simd(const std::vector<int> & nums) {\n    size_t n = nums.size();\n    int count = 0;\n\n    if (n == 0) return 0;\n\n    size_t vl = __riscv_vsetvl_e32m1(n);\n    vint32m1_t v_nums = __riscv_vle32_v_i32m1(nums.data(), vl);\n\n    vint32m1_t v_abs_nums = __riscv_vabs_v_i32m1(v_nums, vl);\n    vint32m1_t v_ones = __riscv_vmv_v_x_i32m1(1, vl);\n    vint32m1_t v_tens = __riscv_vmv_v_x_i32m1(10, vl);\n\n    vint32m1_t v_first_digits = __riscv_vdiv_vv_i32m1(v_abs_nums, v_tens, vl);\n    vint32m1_t v_last_digits = __riscv_vrem_vv_i32m1(v_abs_nums, v_tens, vl);\n\n    vint32m1_t v_odd_digits = __riscv_vmv_v_x_i32m1(1, vl);\n    v_odd_digits = __riscv_vslideup_vx_i32m1(v_odd_digits, 1, vl);\n    v_odd_digits = __riscv_vslideup_vx_i32m1(v_odd_digits, 3, vl);\n    v_odd_digits = __riscv_vslideup_vx_i32m1(v_odd_digits, 5, vl);\n    v_odd_digits = __riscv_vslideup_vx_i32m1(v_odd_digits, 7, vl);\n    v_odd_digits = __riscv_vslideup_vx_i32m1(v_odd_digits, 9, vl);\n\n    vint32m1_t v_first_odd = __riscv_vreinterpret_v_u32m1(__riscv_vand_vv_u32m1(__riscv_vreinterpret_v_u32m1(v_first_digits), __riscv_vreinterpret_v_u32m1(v_odd_digits), vl));\n    vint32m1_t v_last_odd = __riscv_vreinterpret_v_u32m1(__riscv_vand_vv_u32m1(__riscv_vreinterpret_v_u32m1(v_last_digits), __riscv_vreinterpret_v_u32m1(v_odd_digits), vl));\n\n    vint32m1_t v_mask = __riscv_vand_vv_i32m1(__riscv_vmsgt_vx_i32m1(v_nums, 10, vl), __riscv_vand_vv_i32m1(v_first_odd, v_last_odd, vl), vl);\n\n    count = __riscv_vcpop_m_i32m1(v_mask, vl);\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_131_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nint specialFilter_simd(const std::vector<int> & nums) {\n    size_t n = nums.size();\n    vint32m1_t v_nums = __riscv_vle32_v_i32m1(nums.data(), n, n);\n    vint32m1_t v_abs_nums = __riscv_vabs_v_i32m1(v_nums, n);\n    vint32m1_t v_first_digits = __riscv_vdivu_vx_i32m1(v_abs_nums, 10, n);\n    vint32m1_t v_last_digits = __riscv_vremu_vx_i32m1(v_abs_nums, 10, n);\n    vint32m1_t v_first_odd = __riscv_vremu_vx_i32m1(v_first_digits, 2, n);\n    vint32m1_t v_last_odd = __riscv_vremu_vx_i32m1(v_last_digits, 2, n);\n    vint32m1_t v_both_odd = __riscv_vand_vv_i32m1(v_first_odd, v_last_odd, n);\n    vint32m1_t v_gt_10 = __riscv_vmsgt_vx_i32m1(v_nums, 10, n);\n    vint32m1_t v_result = __riscv_vand_vv_i32m1(v_both_odd, v_gt_10, n);\n    vint32m1_t v_count = __riscv_vcpop_m_i32m1(v_result, n);\n    return __riscv_vmv_x_s_i32m1_i32(v_count);\n}\n```"}
{"task_id": "SimdBench_131_RVV", "completion": "```c++\nint specialFilter_simd(const std::vector<int> & nums) {\n    size_t n = nums.size();\n    int count = 0;\n\n    if (n == 0) return 0;\n\n    size_t vl = __riscv_vsetvl_e32m1(n);\n    vint32m1_t v_nums = __riscv_vle32_v_i32m1(nums.data(), vl);\n\n    vint32m1_t v_abs_nums = __riscv_vabs_v_i32m1(v_nums, vl);\n    vint32m1_t v_first_digit = __riscv_vdiv_vx_i32m1(v_abs_nums, 10, vl);\n    vint32m1_t v_last_digit = __riscv_vrem_vx_i32m1(v_abs_nums, 10, vl);\n\n    vint32m1_t v_first_digit_odd = __riscv_vrem_vx_i32m1(v_first_digit, 2, vl);\n    vint32m1_t v_last_digit_odd = __riscv_vrem_vx_i32m1(v_last_digit, 2, vl);\n\n    vbool32_t v_first_digit_odd_mask = __riscv_vmseq_vx_i32m1_b32(v_first_digit_odd, 1, vl);\n    vbool32_t v_last_digit_odd_mask = __riscv_vmseq_vx_i32m1_b32(v_last_digit_odd, 1, vl);\n    vbool32_t v_greater_than_10_mask = __riscv_vmsgt_vx_i32m1_b32(v_nums, 10, vl);\n\n    vbool32_t v_mask = __riscv_vmand_mm_b32(v_first_digit_odd_mask, v_last_digit_odd_mask, vl);\n    v_mask = __riscv_vmand_mm_b32(v_mask, v_greater_than_10_mask, vl);\n\n    count = __riscv_vcpop_m_b32(v_mask, vl);\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_131_RVV", "completion": "```c++\nint specialFilter_simd(const std::vector<int> & nums) {\n    size_t n = nums.size();\n    int count = 0;\n\n    if (n == 0) return 0;\n\n    size_t vl = __riscv_vsetvl_e32m1(n);\n    vint32m1_t v_nums = __riscv_vle32_v_i32m1(nums.data(), vl);\n\n    vint32m1_t v_abs_nums = __riscv_vabs_v_i32m1(v_nums, vl);\n    vint32m1_t v_ones = __riscv_vmv_v_x_i32m1(1, vl);\n    vint32m1_t v_tens = __riscv_vmv_v_x_i32m1(10, vl);\n\n    vint32m1_t v_first_digit = __riscv_vdiv_vv_i32m1(v_abs_nums, v_tens, vl);\n    vint32m1_t v_last_digit = __riscv_vrem_vv_i32m1(v_abs_nums, v_tens, vl);\n\n    vint32m1_t v_odd_digits = __riscv_vmv_v_x_i32m1(1, vl);\n    v_odd_digits = __riscv_vslideup_vx_i32m1(v_odd_digits, 1, vl);\n    v_odd_digits = __riscv_vslideup_vx_i32m1(v_odd_digits, 3, vl);\n    v_odd_digits = __riscv_vslideup_vx_i32m1(v_odd_digits, 5, vl);\n    v_odd_digits = __riscv_vslideup_vx_i32m1(v_odd_digits, 7, vl);\n    v_odd_digits = __riscv_vslideup_vx_i32m1(v_odd_digits, 9, vl);\n\n    vint32m1_t v_first_odd = __riscv_vreinterpret_v_u32m1(__riscv_vmand_mm(__riscv_vmseq_vv_i32m1_b32(v_first_digit, v_odd_digits, vl), vl));\n    vint32m1_t v_last_odd = __riscv_vreinterpret_v_u32m1(__riscv_vmand_mm(__riscv_vmseq_vv_i32m1_b32(v_last_digit, v_odd_digits, vl), vl));\n\n    vint32m1_t v_mask = __riscv_vmand_mm(__riscv_vmseq_vx_i32m1_b32(v_nums, 10, vl), __riscv_vmand_mm(v_first_odd, v_last_odd, vl), vl);\n\n    count = __riscv_vcpop_m_b32(v_mask, vl);\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_132_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nuint64_t get_max_triples_simd(uint64_t n) {\n    size_t vl = vsetvl_e64m1(n);\n    vint64m1_t indices = vid_v_i64m1(1, vl);\n    vint64m1_t a = vrem_vv_i64m1(vmul_vv_i64m1(indices, indices, vl), indices, vl);\n    a = vadd_vv_i64m1(a, vind_v_i64m1(1, vl), vl);\n\n    uint64_t count = 0;\n    for (uint64_t i = 0; i < n; ++i) {\n        for (uint64_t j = i + 1; j < n; ++j) {\n            for (uint64_t k = j + 1; k < n; ++k) {\n                vint64m1_t sum = vadd_vv_i64m1(vadd_vv_i64m1(vmv_s_x_i64m1(a[i], vl), vmv_s_x_i64m1(a[j], vl), vl), vmv_s_x_i64m1(a[k], vl), vl);\n                vint64m1_t mask = vrem_vv_i64m1(sum, vind_v_i64m1(3, vl), vl);\n                if (vfirst_m(mask, vl) == 0) {\n                    count++;\n                }\n            }\n        }\n    }\n    return count;\n}\n```"}
{"task_id": "SimdBench_132_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nuint64_t get_max_triples_simd(uint64_t n) {\n    size_t vl = vsetvl_e64m1(n);\n    vint64m1_t v_i = vid_v_i64m1(vl);\n    vint64m1_t v_a = vadd_vv_i64m1(vmul_vv_i64m1(v_i, v_i, vl), vsub_vv_i64m1(v_i, v_i, vl), vl);\n    v_a = vadd_vv_i64m1(v_a, v_i, vl);\n\n    uint64_t count = 0;\n    for (uint64_t i = 0; i < n; ++i) {\n        for (uint64_t j = i + 1; j < n; ++j) {\n            for (uint64_t k = j + 1; k < n; ++k) {\n                vint64m1_t v_sum = vadd_vv_i64m1(v_a, v_a, vl);\n                v_sum = vadd_vv_i64m1(v_sum, v_a, vl);\n                vint64m1_t v_mod = vrem_vx_i64m1(v_sum, 3, vl);\n                vint64m1_t v_zero = vmseq_vx_i64m1_b16(v_mod, 0, vl);\n                count += vpopc_m_b16(v_zero, vl);\n            }\n        }\n    }\n    return count;\n}\n```"}
{"task_id": "SimdBench_132_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nuint64_t get_max_triples_simd(uint64_t n) {\n    size_t vl = vsetvl_e64m1(n);\n    vuint64m1_t indices = vid_v_u64m1(1, vl);\n    vuint64m1_t a = vremu_vv_u64m1(vmul_vv_u64m1(indices, indices, vl), indices, vl);\n    a = vadd_vv_u64m1(a, vid_v_u64m1(1, vl), vl);\n\n    uint64_t count = 0;\n    for (uint64_t i = 0; i < n; ++i) {\n        for (uint64_t j = i + 1; j < n; ++j) {\n            for (uint64_t k = j + 1; k < n; ++k) {\n                vuint64m1_t sum = vadd_vv_u64m1(vadd_vv_u64m1(vslide1down_vx_u64m1(a, a[i], vl), vslide1down_vx_u64m1(a, a[j], vl), vl), vslide1down_vx_u64m1(a, a[k], vl), vl);\n                if (vfirst_m_u64m1(vremu_vx_u64m1(sum, 3, vl), vl) == 0) {\n                    ++count;\n                }\n            }\n        }\n    }\n    return count;\n}\n```"}
{"task_id": "SimdBench_132_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nuint64_t get_max_triples_simd(uint64_t n) {\n    size_t vl = vsetvl_e64m1(n);\n    vint64m1_t v_i = vid_v_i64m1(vl);\n    vint64m1_t v_a = vadd_vv_i64m1(vmul_vv_i64m1(v_i, v_i, vl), vsub_vv_i64m1(v_i, v_i, vl), vl);\n    v_a = vadd_vv_i64m1(v_a, vbroadcast_i64m1(1, vl), vl);\n\n    uint64_t count = 0;\n    for (uint64_t i = 0; i < n; ++i) {\n        for (uint64_t j = i + 1; j < n; ++j) {\n            for (uint64_t k = j + 1; k < n; ++k) {\n                vint64m1_t v_sum = vadd_vv_i64m1(v_a, v_a, vl);\n                v_sum = vadd_vv_i64m1(v_sum, v_a, vl);\n                if (vsum_vv_i64m1(v_sum, vl) % 3 == 0) {\n                    count++;\n                }\n            }\n        }\n    }\n    return count;\n}\n```"}
{"task_id": "SimdBench_132_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nuint64_t get_max_triples_simd(uint64_t n) {\n    size_t vl = vsetvl_e64m1(n);\n    vint64m1_t indices = vid_v_i64m1(1, 1, vl);\n    vint64m1_t a = vrem_vv_i64m1(vmul_vv_i64m1(indices, indices, vl), indices, vl);\n    a = vadd_vv_i64m1(a, vind_v_i64m1(1, vl), vl);\n\n    uint64_t count = 0;\n    for (uint64_t i = 0; i < n; ++i) {\n        for (uint64_t j = i + 1; j < n; ++j) {\n            for (uint64_t k = j + 1; k < n; ++k) {\n                vint64m1_t sum = vadd_vv_i64m1(vadd_vv_i64m1(vmv_s_x_i64m1(a[i], vl), vmv_s_x_i64m1(a[j], vl), vl), vmv_s_x_i64m1(a[k], vl), vl);\n                if (vrem_vx_i64m1_b32(sum, 3, vl)) {\n                    count++;\n                }\n            }\n        }\n    }\n    return count;\n}\n```"}
{"task_id": "SimdBench_133_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nint x_or_y_simd(int n, int x, int y) {\n    vint32m1_t v_n = __riscv_vmv_v_x_i32m1(1, n);\n    vint32m1_t v_x = __riscv_vmv_v_x_i32m1(1, x);\n    vint32m1_t v_y = __riscv_vmv_v_x_i32m1(1, y);\n\n    vint32m1_t v_prime = __riscv_vmv_v_x_i32m1(1, 1);\n    vint32m1_t v_one = __riscv_vmv_v_x_i32m1(1, 1);\n    vint32m1_t v_two = __riscv_vmv_v_x_i32m1(1, 2);\n\n    vint32m1_t v_i = __riscv_vmv_v_x_i32m1(1, 2);\n    vint32m1_t v_n_minus_one = __riscv_vsub_vv_i32m1(v_n, v_one, 1);\n\n    for (int i = 2; i * i <= n; ++i) {\n        vint32m1_t v_i_squared = __riscv_vmul_vv_i32m1(v_i, v_i, 1);\n        vint32m1_t v_cond = __riscv_vmle_vv_i32m1_b32(v_i_squared, v_n, 1);\n        vint32m1_t v_mod = __riscv_vrem_vv_i32m1(v_n, v_i, 1);\n        vint32m1_t v_zero = __riscv_vmv_v_x_i32m1(1, 0);\n        vint32m1_t v_mod_zero = __riscv_vmseq_vv_i32m1_b32(v_mod, v_zero, 1);\n\n        v_prime = __riscv_vand_vv_b32(v_prime, __riscv_vor_vv_b32(v_cond, v_mod_zero, 1), 1);\n        v_i = __riscv_vadd_vv_i32m1(v_i, v_one, 1);\n    }\n\n    vint32m1_t v_result = __riscv_vmerge_vvm_i32m1(v_x, v_y, v_prime, 1);\n    return __riscv_vmv_x_s_i32m1_i32(v_result);\n}\n```"}
{"task_id": "SimdBench_133_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nint x_or_y_simd(int n, int x, int y) {\n    vint32m1_t v_n = __riscv_vmv_v_x_i32m1(1, n);\n    vint32m1_t v_2 = __riscv_vmv_v_x_i32m1(1, 2);\n    vint32m1_t v_3 = __riscv_vmv_v_x_i32m1(1, 3);\n    vint32m1_t v_5 = __riscv_vmv_v_x_i32m1(1, 5);\n    vint32m1_t v_7 = __riscv_vmv_v_x_i32m1(1, 7);\n\n    vint32m1_t v_rem2 = __riscv_vrem_vv_i32m1(v_n, v_2, 1);\n    vint32m1_t v_rem3 = __riscv_vrem_vv_i32m1(v_n, v_3, 1);\n    vint32m1_t v_rem5 = __riscv_vrem_vv_i32m1(v_n, v_5, 1);\n    vint32m1_t v_rem7 = __riscv_vrem_vv_i32m1(v_n, v_7, 1);\n\n    vint32m1_t v_is_prime = __riscv_vand_vv_i32m1(__riscv_vand_vv_i32m1(__riscv_vand_vv_i32m1(__riscv_vand_vv_i32m1(v_rem2, v_rem3, 1), v_rem5, 1), v_rem7, 1), __riscv_vmv_v_x_i32m1(1, 1), 1);\n\n    vint32m1_t v_result = __riscv_vmerge_vxm_i32m1(v_is_prime, y, x, 1);\n\n    return __riscv_vmv_x_s_i32m1_i32(v_result);\n}\n```"}
{"task_id": "SimdBench_133_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nint x_or_y_simd(int n, int x, int y) {\n    vint32m1_t v_n = __riscv_vmv_v_x_i32m1(1, n);\n    vint32m1_t v_x = __riscv_vmv_v_x_i32m1(1, x);\n    vint32m1_t v_y = __riscv_vmv_v_x_i32m1(1, y);\n\n    vint32m1_t v_ones = __riscv_vmv_v_x_i32m1(1, 1);\n    vint32m1_t v_zeros = __riscv_vmv_v_x_i32m1(1, 0);\n\n    vint32m1_t v_prime = __riscv_vmv_v_x_i32m1(1, 1);\n\n    for (int i = 2; i * i <= n; ++i) {\n        vint32m1_t v_i = __riscv_vmv_v_x_i32m1(1, i);\n        vint32m1_t v_mod = __riscv_vrem_vv_i32m1(v_n, v_i, 1);\n        vint32m1_t v_is_divisible = __riscv_vmseq_vx_i32m1_b32(v_mod, 0, 1);\n        v_prime = __riscv_vand_vv_i32m1(v_prime, __riscv_vmv_v_x_i32m1(1, !__riscv_vmv_x_s_i32m1_b32(v_is_divisible)), 1);\n    }\n\n    vint32m1_t v_result = __riscv_vmerge_vvm_i32m1(v_x, v_y, v_prime, 1);\n    return __riscv_vmv_x_s_i32m1_i32(v_result);\n}\n```"}
{"task_id": "SimdBench_133_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nint x_or_y_simd(int n, int x, int y) {\n    vint32m1_t v_n = __riscv_vmv_v_x_i32m1(1, n);\n    vint32m1_t v_x = __riscv_vmv_v_x_i32m1(1, x);\n    vint32m1_t v_y = __riscv_vmv_v_x_i32m1(1, y);\n\n    vint32m1_t v_prime = __riscv_vmv_v_x_i32m1(1, 1);\n    vint32m1_t v_two = __riscv_vmv_v_x_i32m1(1, 2);\n\n    vint32m1_t v_i = __riscv_vmv_v_x_i32m1(1, 2);\n    vint32m1_t v_n_minus_one = __riscv_vsub_vv_i32m1(v_n, v_two, 1);\n\n    for (int i = 2; i * i <= n; ++i) {\n        vint32m1_t v_i_squared = __riscv_vmul_vv_i32m1(v_i, v_i, 1);\n        vint32m1_t v_cond = __riscv_vmle_vv_i32m1_b(v_i_squared, v_n_minus_one, 1);\n        vint32m1_t v_mod = __riscv_vrem_vv_i32m1(v_n, v_i, 1);\n        vint32m1_t v_zero = __riscv_vmv_v_x_i32m1(1, 0);\n        vint32m1_t v_is_divisible = __riscv_vmseq_vv_i32m1_b(v_mod, v_zero, 1);\n\n        v_prime = __riscv_vand_vv_i32m1_b(v_prime, __riscv_vnot_v_i32m1_b(v_is_divisible, 1), 1);\n        v_i = __riscv_vadd_vv_i32m1(v_i, v_two, 1);\n    }\n\n    vint32m1_t v_result = __riscv_vmerge_vvm_i32m1(v_x, v_y, v_prime, 1);\n    return __riscv_vmv_x_s_i32m1_i32(v_result);\n}\n```"}
{"task_id": "SimdBench_133_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nint x_or_y_simd(int n, int x, int y) {\n    vint32m1_t v_n = __riscv_vmv_v_x_i32m1(1, n, 32);\n    vint32m1_t v_x = __riscv_vmv_v_x_i32m1(1, x, 32);\n    vint32m1_t v_y = __riscv_vmv_v_x_i32m1(1, y, 32);\n\n    vint32m1_t v_one = __riscv_vmv_v_x_i32m1(1, 1, 32);\n    vint32m1_t v_two = __riscv_vmv_v_x_i32m1(1, 2, 32);\n    vint32m1_t v_three = __riscv_vmv_v_x_i32m1(1, 3, 32);\n\n    vint32m1_t v_i = __riscv_vmv_v_x_i32m1(1, 2, 32);\n    vint32m1_t v_limit = __riscv_vmv_v_x_i32m1(1, n / 2, 32);\n\n    vint32m1_t v_prime = __riscv_vmv_v_x_i32m1(1, 1, 32);\n\n    while (__riscv_vreduc_max_u32m1(v_i, v_limit, 32) <= n / 2) {\n        vint32m1_t v_mod = __riscv_vrem_vv_i32m1(v_n, v_i, 32);\n        v_prime = __riscv_vand_vv_i32m1(v_prime, __riscv_vmsne_vx_i32m1(v_mod, 0, 32), 32);\n        v_i = __riscv_vadd_vx_i32m1(v_i, 1, 32);\n    }\n\n    vint32m1_t v_result = __riscv_vmerge_vvm_i32m1(v_x, v_y, v_prime, 32);\n    return __riscv_vmv_x_s_i32m1(v_result, 0);\n}\n```"}
{"task_id": "SimdBench_134_RVV", "completion": "```c++\nuint64_t double_the_difference_simd(const std::vector<float> & lst) {\n    size_t n = lst.size();\n    if (n == 0) return 0;\n\n    size_t vl = __riscv_vsetvl_e32m1(n);\n    vfloat32m1_t v_lst = __riscv_vle32_v_f32m1(lst.data(), vl);\n\n    vbool32_t mask_odd = __riscv_vmsne_vx_i32m1_b32(v_lst, 0, vl);\n    vbool32_t mask_positive = __riscv_vmsgt_vx_f32m1_b32(v_lst, 0, vl);\n    vbool32_t mask_odd_positive = __riscv_vmand_mm_b32(mask_odd, mask_positive, vl);\n\n    vfloat32m1_t v_squares = __riscv_vfmv_v_f_f32m1(0.0f, vl);\n    v_squares = __riscv_vfmul_vv_f32m1(v_lst, v_lst, vl, mask_odd_positive);\n\n    float sum = __riscv_vfmv_f_s_f32m1_f32(__riscv_vfredusum_vs_f32m1_f32(v_squares, v_squares, 0.0f, vl));\n\n    return static_cast<uint64_t>(sum);\n}\n```"}
{"task_id": "SimdBench_134_RVV", "completion": "```c++\nuint64_t double_the_difference_simd(const std::vector<float> & lst) {\n    size_t n = lst.size();\n    if (n == 0) return 0;\n\n    uint64_t sum = 0;\n    size_t vl = __riscv_vsetvl_e64m1(n);\n\n    vfloat32m1_t v_lst = __riscv_vle32_v_f32m1(lst.data(), vl);\n    vint32m1_t v_ints = __riscv_vfncvt_xu_f_w(v_lst, vl);\n    vfloat32m1_t v_floats = __riscv_vfcvt_f_xu_w(v_ints, vl);\n    vint32m1_t v_odd_mask = __riscv_vmsne_vx_i32m1_b(v_ints, 0, vl);\n    vint32m1_t v_odd_ints = __riscv_vand_vx_i32m1(v_ints, 1, vl);\n    vint32m1_t v_odd_mask2 = __riscv_vmsne_vx_i32m1_b(v_odd_ints, 0, vl);\n    vint32m1_t v_mask = __riscv_vand_vv_i32m1_b(v_odd_mask, v_odd_mask2, vl);\n    vint32m1_t v_squares = __riscv_vmul_vv_i32m1(v_ints, v_ints, vl);\n    vint32m1_t v_filtered_squares = __riscv_vand_vv_i32m1(v_squares, v_mask, vl);\n    vint64m1_t v_sum = __riscv_vwredsum_vs_i32m1_i64m1(v_filtered_squares, v_sum, vl);\n\n    sum = __riscv_vmv_x_s_i64m1_i64(v_sum);\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_134_RVV", "completion": "```c++\nuint64_t double_the_difference_simd(const std::vector<float> & lst) {\n    size_t n = lst.size();\n    if (n == 0) return 0;\n\n    size_t vl = __riscv_vsetvl_e32m1(n);\n    vfloat32m1_t v_lst = __riscv_vle32_v_f32m1(lst.data(), vl);\n\n    vbool32_t mask_odd = __riscv_vmsne_vx_i32m1_b32(v_lst, 0, vl);\n    vbool32_t mask_positive = __riscv_vmsgt_vx_f32m1_b32(v_lst, 0.0f, vl);\n    vbool32_t mask_odd_positive = __riscv_vmand_mm_b32(mask_odd, mask_positive, vl);\n\n    vint32m1_t v_squares = __riscv_vmul_vv_i32m1(v_lst, v_lst, vl);\n    vint32m1_t v_filtered_squares = __riscv_vcompress_vm_i32m1(v_squares, mask_odd_positive, vl);\n\n    uint64_t sum = 0;\n    for (size_t i = 0; i < vl; ++i) {\n        sum += v_filtered_squares[i];\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_134_RVV", "completion": "```c++\nuint64_t double_the_difference_simd(const std::vector<float> & lst) {\n    size_t n = lst.size();\n    if (n == 0) return 0;\n\n    size_t vl = __riscv_vsetvl_e32m1(n);\n    vfloat32m1_t v_lst = __riscv_vle32_v_f32m1(lst.data(), vl);\n\n    vint32m1_t v_ones = __riscv_vmv_v_x_i32m1(1, vl);\n    vint32m1_t v_zeros = __riscv_vmv_v_x_i32m1(0, vl);\n\n    vint32m1_t v_mask = __riscv_vmseq_vx_i32m1_b32(v_lst, 0, vl);\n    vint32m1_t v_mask_odd = __riscv_vmand_mm_b32(v_mask, __riscv_vmsne_vx_i32m1_b32(v_lst, 0, vl), vl);\n    vint32m1_t v_mask_odd_int = __riscv_vmand_mm_b32(v_mask_odd, __riscv_vmsne_vx_i32m1_b32(v_lst, 0, vl), vl);\n\n    vfloat32m1_t v_squares = __riscv_vfmul_vv_f32m1(v_lst, v_lst, vl);\n    vfloat32m1_t v_result = __riscv_vfmv_v_f_f32m1(0.0f, vl);\n    v_result = __riscv_vfmerge_vvm_f32m1(v_result, v_squares, v_mask_odd_int, vl);\n\n    float sum = __riscv_vfmv_f_s_f32m1_f32(__riscv_vfredusum_vs_f32m1_f32m1(v_result, v_zeros, vl));\n\n    return static_cast<uint64_t>(sum);\n}\n```"}
{"task_id": "SimdBench_134_RVV", "completion": "```c++\nuint64_t double_the_difference_simd(const std::vector<float> & lst) {\n    size_t n = lst.size();\n    if (n == 0) return 0;\n\n    size_t vl = __riscv_vsetvl_e32m1(n);\n    vfloat32m1_t v_lst = __riscv_vle32_v_f32m1(lst.data(), vl);\n\n    vbool32_t mask_odd = __riscv_vmsne_vx_i32m1_b32(v_lst, 0, vl);\n    vbool32_t mask_positive = __riscv_vmsgt_vx_f32m1_b32(v_lst, 0.0f, vl);\n    vbool32_t mask_odd_positive = __riscv_vmand_mm_b32(mask_odd, mask_positive, vl);\n\n    vint32m1_t v_squares = __riscv_vmul_vv_i32m1(v_lst, v_lst, vl);\n    vint32m1_t v_squares_filtered = __riscv_vcompress_vm_i32m1(v_squares, mask_odd_positive, vl);\n\n    uint64_t sum = 0;\n    for (size_t i = 0; i < vl; ++i) {\n        sum += v_squares_filtered[i];\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_135_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> compare_simd(const std::vector<int>& game, const std::vector<int>& guess) {\n    size_t n = game.size();\n    std::vector<int> result(n);\n\n    size_t vl = __riscv_vsetvl_e32m1(n);\n    vint32m1_t v_game = __riscv_vle32_v_i32m1(game.data(), vl);\n    vint32m1_t v_guess = __riscv_vle32_v_i32m1(guess.data(), vl);\n\n    vint32m1_t v_diff = __riscv_vsub_vv_i32m1(v_game, v_guess, vl);\n    vint32m1_t v_abs_diff = __riscv_vabs_v_i32m1(v_diff, vl);\n\n    vint32m1_t v_zero = __riscv_vmv_v_x_i32m1(0, vl);\n    vint32m1_t v_result = __riscv_vmerge_vvm_i32m1(v_zero, v_abs_diff, __riscv_vmseq_vv_i32m1_b32(v_game, v_guess, vl), vl);\n\n    __riscv_vse32_v_i32m1(result.data(), v_result, vl);\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_135_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> compare_simd(const std::vector<int>& game, const std::vector<int>& guess) {\n    size_t n = game.size();\n    std::vector<int> result(n);\n\n    size_t vl = __riscv_vsetvl_e32m1(n);\n    vint32m1_t v_game = __riscv_vle32_v_i32m1(game.data(), vl);\n    vint32m1_t v_guess = __riscv_vle32_v_i32m1(guess.data(), vl);\n\n    vint32m1_t v_diff = __riscv_vsub_vv_i32m1(v_game, v_guess, vl);\n    vint32m1_t v_abs_diff = __riscv_vabs_v_i32m1(v_diff, vl);\n    vint32m1_t v_zero = __riscv_vmv_v_x_i32m1(0, vl);\n    vint32m1_t v_result = __riscv_vmerge_vvm_i32m1(v_zero, v_abs_diff, v_game, vl);\n\n    __riscv_vse32_v_i32m1(result.data(), v_result, vl);\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_135_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> compare_simd(const std::vector<int>& game, const std::vector<int>& guess) {\n    size_t n = game.size();\n    std::vector<int> result(n);\n\n    size_t vl = __riscv_vsetvl_e32m1(n);\n    vint32m1_t v_game = __riscv_vle32_v_i32m1(game.data(), vl);\n    vint32m1_t v_guess = __riscv_vle32_v_i32m1(guess.data(), vl);\n\n    vint32m1_t v_diff = __riscv_vsub_vv_i32m1(v_game, v_guess, vl);\n    vint32m1_t v_abs_diff = __riscv_vabs_v_i32m1(v_diff, vl);\n\n    vint32m1_t v_zero = __riscv_vmv_v_x_i32m1(0, vl);\n    vint32m1_t v_result = __riscv_vmerge_vvm_i32m1(v_zero, v_abs_diff, __riscv_vmseq_vv_i32m1_b32(v_game, v_guess, vl), vl);\n\n    __riscv_vse32_v_i32m1(result.data(), v_result, vl);\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_135_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> compare_simd(const std::vector<int>& game, const std::vector<int>& guess) {\n    size_t n = game.size();\n    std::vector<int> result(n);\n\n    size_t vl = __riscv_vsetvl_e32m1(n);\n    vint32m1_t v_game = __riscv_vle32_v_i32m1(game.data(), vl);\n    vint32m1_t v_guess = __riscv_vle32_v_i32m1(guess.data(), vl);\n\n    vint32m1_t v_diff = __riscv_vsub_vv_i32m1(v_game, v_guess, vl);\n    vint32m1_t v_abs_diff = __riscv_vabs_v_i32m1(v_diff, vl);\n\n    vint32m1_t v_zero = __riscv_vmv_v_x_i32m1(0, vl);\n    vint32m1_t v_result = __riscv_vmerge_vvm_i32m1(v_zero, v_abs_diff, __riscv_vmseq_vv_i32m1_b32(v_game, v_guess, vl), vl);\n\n    __riscv_vse32_v_i32m1(result.data(), v_result, vl);\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_135_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> compare_simd(const std::vector<int>& game, const std::vector<int>& guess) {\n    size_t n = game.size();\n    std::vector<int> result(n);\n\n    size_t vl = __riscv_vsetvl_e32m1(n);\n    vint32m1_t v_game = __riscv_vle32_v_i32m1(game.data(), vl);\n    vint32m1_t v_guess = __riscv_vle32_v_i32m1(guess.data(), vl);\n\n    vint32m1_t v_diff = __riscv_vsub_vv_i32m1(v_game, v_guess, vl);\n    vint32m1_t v_abs_diff = __riscv_vabs_v_i32m1(v_diff, vl);\n\n    vint32m1_t v_zero = __riscv_vmv_v_x_i32m1(0, vl);\n    vint32m1_t v_result = __riscv_vmerge_vvm_i32m1(v_zero, v_abs_diff, __riscv_vmseq_vv_i32m1_b32(v_game, v_guess, vl), vl);\n\n    __riscv_vse32_v_i32m1(result.data(), v_result, vl);\n\n    return result;\n}\n```"}

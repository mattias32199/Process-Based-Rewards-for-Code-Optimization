{"task_id": "SimdBench_0_SSE", "completion": "```cpp\nvoid conditional_move_simd(const int64_t *src, int64_t *dst, const bool *mask, size_t length) {\n    size_t i = 0;\n    for (; i + 2 <= length; i += 2) {\n        __m128i src_vec = _mm_loadu_si128((__m128i*)&src[i]);\n        __m128i dst_vec = _mm_loadu_si128((__m128i*)&dst[i]);\n        __m128i mask_vec = _mm_set_epi64x(mask[i + 1], mask[i]);\n\n        __m128i result = _mm_blendv_epi8(dst_vec, src_vec, mask_vec);\n\n        _mm_storeu_si128((__m128i*)&dst[i], result);\n    }\n\n    for (; i < length; ++i) {\n        if (mask[i]) {\n            dst[i] = src[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_0_SSE", "completion": "```cpp\nvoid conditional_move_simd(const int64_t *src, int64_t *dst, const bool *mask, size_t length) {\n    size_t i = 0;\n    for (; i + 2 <= length; i += 2) {\n        __m128i src_vec = _mm_loadu_si128((__m128i *)&src[i]);\n        __m128i dst_vec = _mm_loadu_si128((__m128i *)&dst[i]);\n        __m128i mask_vec = _mm_set_epi64x(mask[i + 1], mask[i]);\n\n        __m128i result = _mm_blendv_epi8(dst_vec, src_vec, mask_vec);\n\n        _mm_storeu_si128((__m128i *)&dst[i], result);\n    }\n\n    for (; i < length; ++i) {\n        if (mask[i]) {\n            dst[i] = src[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_0_SSE", "completion": "```cpp\nvoid conditional_move_simd(const int64_t *src, int64_t *dst, const bool *mask, size_t length) {\n    size_t i = 0;\n    for (; i + 2 <= length; i += 2) {\n        __m128i src_vec = _mm_loadu_si128((__m128i *)&src[i]);\n        __m128i dst_vec = _mm_loadu_si128((__m128i *)&dst[i]);\n        __m128i mask_vec = _mm_set_epi64x(mask[i + 1], mask[i]);\n\n        __m128i result = _mm_blendv_epi8(dst_vec, src_vec, mask_vec);\n\n        _mm_storeu_si128((__m128i *)&dst[i], result);\n    }\n\n    for (; i < length; ++i) {\n        if (mask[i]) {\n            dst[i] = src[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_0_SSE", "completion": "```cpp\nvoid conditional_move_simd(const int64_t *src, int64_t *dst, const bool *mask, size_t length) {\n    size_t i = 0;\n    for (; i + 2 <= length; i += 2) {\n        __m128i src_vec = _mm_loadu_si128((__m128i *)&src[i]);\n        __m128i dst_vec = _mm_loadu_si128((__m128i *)&dst[i]);\n        __m128i mask_vec = _mm_set_epi64x(mask[i + 1], mask[i]);\n\n        __m128i result_vec = _mm_blendv_epi8(dst_vec, src_vec, mask_vec);\n\n        _mm_storeu_si128((__m128i *)&dst[i], result_vec);\n    }\n\n    for (; i < length; ++i) {\n        if (mask[i]) {\n            dst[i] = src[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_0_SSE", "completion": "```cpp\nvoid conditional_move_simd(const int64_t *src, int64_t *dst, const bool *mask, size_t length) {\n    size_t i = 0;\n    for (; i + 2 <= length; i += 2) {\n        __m128i src_vec = _mm_loadu_si128((__m128i *)&src[i]);\n        __m128i dst_vec = _mm_loadu_si128((__m128i *)&dst[i]);\n        __m128i mask_vec = _mm_set_epi64x(mask[i + 1], mask[i]);\n\n        __m128i result_vec = _mm_blendv_epi8(dst_vec, src_vec, mask_vec);\n        _mm_storeu_si128((__m128i *)&dst[i], result_vec);\n    }\n\n    for (; i < length; ++i) {\n        if (mask[i]) {\n            dst[i] = src[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_1_SSE", "completion": "```c\nvoid load_modify_store_simd(const int *src, int *dst, int scale, size_t length) {\n    __m128i scale_vec = _mm_set1_epi32(scale);\n    __m128i shift_mask = _mm_set1_epi32(7);\n\n    for (size_t i = 0; i < length; i += 4) {\n        __m128i src_vec = _mm_loadu_si128((__m128i*)&src[i]);\n\n        __m128i tmp1 = _mm_srai_epi32(_mm_mullo_epi32(src_vec, scale_vec), 3);\n        __m128i tmp2 = _mm_slli_epi32(_mm_mullo_epi32(src_vec, scale_vec), 3);\n\n        __m128i tmp1_tmp2 = _mm_mullo_epi32(tmp1, tmp2);\n        __m128i src_scaled = _mm_mullo_epi32(src_vec, scale_vec);\n\n        __m128i result = _mm_add_epi32(src_scaled, tmp1_tmp2);\n        result = _mm_div_epi32(result, shift_mask);\n\n        _mm_storeu_si128((__m128i*)&dst[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_1_SSE", "completion": "```c\nvoid load_modify_store_simd(const int *src, int *dst, int scale, size_t length) {\n    __m128i scale_vec = _mm_set1_epi32(scale);\n    __m128i shift_mask = _mm_set1_epi32(7);\n\n    for (size_t i = 0; i < length; i += 4) {\n        __m128i src_vec = _mm_loadu_si128((__m128i *)&src[i]);\n\n        __m128i tmp1 = _mm_srai_epi32(_mm_mullo_epi32(src_vec, scale_vec), 3);\n        __m128i tmp2 = _mm_slli_epi32(_mm_mullo_epi32(src_vec, scale_vec), 3);\n\n        __m128i tmp1_tmp2 = _mm_mullo_epi32(tmp1, tmp2);\n        __m128i scaled_src = _mm_mullo_epi32(src_vec, scale_vec);\n        __m128i sum = _mm_add_epi32(scaled_src, tmp1_tmp2);\n\n        __m128i result = _mm_div_epi32(sum, shift_mask);\n\n        _mm_storeu_si128((__m128i *)&dst[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_1_SSE", "completion": "```c\nvoid load_modify_store_simd(const int *src, int *dst, int scale, size_t length) {\n    __m128i scale_vec = _mm_set1_epi32(scale);\n    __m128i shift_mask = _mm_set1_epi32(7);\n\n    for (size_t i = 0; i < length; i += 4) {\n        __m128i src_vec = _mm_loadu_si128((__m128i *)&src[i]);\n\n        __m128i tmp1 = _mm_srai_epi32(_mm_mullo_epi32(src_vec, scale_vec), 3);\n        __m128i tmp2 = _mm_slli_epi32(_mm_mullo_epi32(src_vec, scale_vec), 3);\n\n        __m128i tmp1_tmp2 = _mm_mullo_epi32(tmp1, tmp2);\n        __m128i scaled_src = _mm_mullo_epi32(src_vec, scale_vec);\n        __m128i result = _mm_add_epi32(scaled_src, tmp1_tmp2);\n        result = _mm_div_epi32(result, shift_mask);\n\n        _mm_storeu_si128((__m128i *)&dst[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_1_SSE", "completion": "```cpp\nvoid load_modify_store_simd(const int *src, int *dst, int scale, size_t length) {\n    __m128i vscale = _mm_set1_epi32(scale);\n    __m128i vshift = _mm_set1_epi32(3);\n    __m128i vdiv = _mm_set1_epi32(7);\n\n    for (size_t i = 0; i < length; i += 4) {\n        __m128i vsrc = _mm_loadu_si128((__m128i*)&src[i]);\n        __m128i vtmp1 = _mm_srai_epi32(_mm_mullo_epi32(vsrc, vscale), 3);\n        __m128i vtmp2 = _mm_slli_epi32(_mm_mullo_epi32(vsrc, vscale), 3);\n        __m128i vresult = _mm_div_epi32(_mm_add_epi32(_mm_mullo_epi32(vsrc, vscale), _mm_mullo_epi32(vtmp1, vtmp2)), vdiv);\n        _mm_storeu_si128((__m128i*)&dst[i], vresult);\n    }\n}\n```"}
{"task_id": "SimdBench_1_SSE", "completion": "```cpp\nvoid load_modify_store_simd(const int *src, int *dst, int scale, size_t length) {\n    __m128i scale_vec = _mm_set1_epi32(scale);\n    __m128i shift_right_mask = _mm_set1_epi32(7);\n    __m128i shift_left_mask = _mm_set1_epi32(7);\n\n    for (size_t i = 0; i < length; i += 4) {\n        __m128i src_vec = _mm_loadu_si128((__m128i*)&src[i]);\n\n        __m128i tmp1 = _mm_srai_epi32(_mm_mullo_epi32(src_vec, scale_vec), 3);\n        __m128i tmp2 = _mm_slli_epi32(_mm_mullo_epi32(src_vec, scale_vec), 3);\n\n        __m128i result = _mm_div_epi32(_mm_add_epi32(_mm_mullo_epi32(src_vec, scale_vec), _mm_mullo_epi32(tmp1, tmp2)), shift_right_mask);\n\n        _mm_storeu_si128((__m128i*)&dst[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_2_SSE", "completion": "```c\nvoid strided_load_store_simd(const double *src, double *dst, size_t rows, size_t cols, size_t stride) {\n    for (size_t r = 0; r < rows; ++r) {\n        __m128d src_val = _mm_load_sd(&src[r * cols + stride]);\n        _mm_store_sd(&dst[r], src_val);\n    }\n}\n```"}
{"task_id": "SimdBench_2_SSE", "completion": "```cpp\nvoid strided_load_store_simd(const double *src, double *dst, size_t rows, size_t cols, size_t stride) {\n    for (size_t r = 0; r < rows; ++r) {\n        __m128d src_val = _mm_load_sd(&src[r * cols + stride]);\n        _mm_store_sd(&dst[r], src_val);\n    }\n}\n```"}
{"task_id": "SimdBench_2_SSE", "completion": "```c\nvoid strided_load_store_simd(const double *src, double *dst, size_t rows, size_t cols, size_t stride) {\n    for (size_t r = 0; r < rows; ++r) {\n        __m128d src_val = _mm_load_sd(&src[r * cols + stride]);\n        _mm_store_sd(&dst[r], src_val);\n    }\n}\n```"}
{"task_id": "SimdBench_2_SSE", "completion": "```c\nvoid strided_load_store_simd(const double *src, double *dst, size_t rows, size_t cols, size_t stride) {\n    for (size_t r = 0; r < rows; ++r) {\n        __m128d src_val = _mm_load_sd(&src[r * cols + stride]);\n        _mm_store_sd(&dst[r], src_val);\n    }\n}\n```"}
{"task_id": "SimdBench_2_SSE", "completion": "```c\nvoid strided_load_store_simd(const double *src, double *dst, size_t rows, size_t cols, size_t stride) {\n    for (size_t r = 0; r < rows; ++r) {\n        __m128d src_val = _mm_load_sd(&src[r * cols + stride]);\n        _mm_store_sd(&dst[r], src_val);\n    }\n}\n```"}
{"task_id": "SimdBench_3_SSE", "completion": "```c\nvoid indexed_access_simd(const float *src, const int *indices, float *dst, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 4; i += 4) {\n        __m128i idx = _mm_loadu_si128((__m128i*)&indices[i]);\n        __m128 src_vals = _mm_setr_ps(src[indices[i]], src[indices[i+1]], src[indices[i+2]], src[indices[i+3]]);\n        _mm_storeu_ps(&dst[i], src_vals);\n        _mm_storeu_ps((float*)&dst[indices[i]], src_vals);\n    }\n    for (; i < length; ++i) {\n        dst[i] = src[indices[i]];\n        dst[indices[i]] = src[i];\n    }\n}\n```"}
{"task_id": "SimdBench_3_SSE", "completion": "```c\nvoid indexed_access_simd(const float *src, const int *indices, float *dst, size_t length) {\n    size_t i;\n    for (i = 0; i < length; i += 4) {\n        __m128i idx = _mm_loadu_si128((__m128i*)&indices[i]);\n        __m128 src_vals = _mm_set_ps(src[indices[i+3]], src[indices[i+2]], src[indices[i+1]], src[indices[i]]);\n        _mm_storeu_ps(&dst[i], src_vals);\n    }\n\n    for (i = 0; i < length; i += 4) {\n        __m128i idx = _mm_loadu_si128((__m128i*)&indices[i]);\n        __m128 src_vals = _mm_loadu_ps(&src[i]);\n        _mm_storeu_ps((float*)&dst[indices[i]], src_vals);\n    }\n}\n```"}
{"task_id": "SimdBench_3_SSE", "completion": "```c\nvoid indexed_access_simd(const float *src, const int *indices, float *dst, size_t length) {\n    size_t i = 0;\n    for (; i + 4 <= length; i += 4) {\n        __m128i idx = _mm_loadu_si128((__m128i*)&indices[i]);\n        __m128 src_vals = _mm_set_ps(src[indices[i+3]], src[indices[i+2]], src[indices[i+1]], src[indices[i]]);\n        _mm_storeu_ps(&dst[i], src_vals);\n        _mm_storeu_ps((float*)&dst[indices[i]], src_vals);\n    }\n    for (; i < length; ++i) {\n        dst[i] = src[indices[i]];\n        dst[indices[i]] = src[i];\n    }\n}\n```"}
{"task_id": "SimdBench_3_SSE", "completion": "```c\nvoid indexed_access_simd(const float *src, const int *indices, float *dst, size_t length) {\n    size_t i;\n    for (i = 0; i < length; i += 4) {\n        __m128i idx = _mm_loadu_si128((__m128i*)&indices[i]);\n        __m128 src_vals = _mm_set_ps(src[indices[i+3]], src[indices[i+2]], src[indices[i+1]], src[indices[i]]);\n        _mm_storeu_ps(&dst[i], src_vals);\n    }\n\n    for (i = 0; i < length; i += 4) {\n        __m128i idx = _mm_loadu_si128((__m128i*)&indices[i]);\n        __m128 src_vals = _mm_loadu_ps(&src[i]);\n        _mm_storeu_ps((float*)&dst[indices[i]], src_vals);\n    }\n}\n```"}
{"task_id": "SimdBench_3_SSE", "completion": "```c\nvoid indexed_access_simd(const float *src, const int *indices, float *dst, size_t length) {\n    size_t i;\n    for (i = 0; i < length; i += 4) {\n        __m128i idx = _mm_loadu_si128((__m128i*)&indices[i]);\n        __m128 src_vals = _mm_set_ps(src[indices[i+3]], src[indices[i+2]], src[indices[i+1]], src[indices[i]]);\n        _mm_storeu_ps(&dst[i], src_vals);\n\n        __m128 dst_vals = _mm_set_ps(src[i+3], src[i+2], src[i+1], src[i]);\n        _mm_storeu_ps((float*)&dst[indices[i]], dst_vals);\n    }\n}\n```"}
{"task_id": "SimdBench_4_SSE", "completion": "```cpp\nvoid range_reverse_simd(int16_t *arr, uint64_t start, uint64_t end) {\n    while (start < end) {\n        __m128i a = _mm_loadu_si128((__m128i*)&arr[start]);\n        __m128i b = _mm_loadu_si128((__m128i*)&arr[end - 7]);\n\n        __m128i t = _mm_shuffle_epi32(a, _MM_SHUFFLE(0, 1, 2, 3));\n        a = _mm_shuffle_epi32(b, _MM_SHUFFLE(0, 1, 2, 3));\n        b = t;\n\n        _mm_storeu_si128((__m128i*)&arr[start], a);\n        _mm_storeu_si128((__m128i*)&arr[end - 7], b);\n\n        start += 8;\n        end -= 8;\n    }\n}\n```"}
{"task_id": "SimdBench_4_SSE", "completion": "```c\nvoid range_reverse_simd(int16_t *arr, uint64_t start, uint64_t end) {\n    uint64_t i = start;\n    uint64_t j = end;\n\n    while (i < j) {\n        __m128i a = _mm_loadu_si128((__m128i*)&arr[i]);\n        __m128i b = _mm_loadu_si128((__m128i*)&arr[j]);\n\n        __m128i temp = a;\n        a = _mm_shuffle_epi8(b, _mm_set_epi8(14, 15, 12, 13, 10, 11, 8, 9, 6, 7, 4, 5, 2, 3, 0, 1));\n        b = _mm_shuffle_epi8(temp, _mm_set_epi8(14, 15, 12, 13, 10, 11, 8, 9, 6, 7, 4, 5, 2, 3, 0, 1));\n\n        _mm_storeu_si128((__m128i*)&arr[i], a);\n        _mm_storeu_si128((__m128i*)&arr[j], b);\n\n        i += 8;\n        j -= 8;\n    }\n}\n```"}
{"task_id": "SimdBench_4_SSE", "completion": "```c\nvoid range_reverse_simd(int16_t *arr, uint64_t start, uint64_t end) {\n    uint64_t i = start;\n    uint64_t j = end;\n\n    while (i < j) {\n        __m128i a = _mm_loadu_si128((__m128i*)&arr[i]);\n        __m128i b = _mm_loadu_si128((__m128i*)&arr[j]);\n\n        __m128i temp = a;\n        a = _mm_shuffle_epi8(b, _mm_set_epi8(14, 15, 12, 13, 10, 11, 8, 9, 6, 7, 4, 5, 2, 3, 0, 1));\n        b = _mm_shuffle_epi8(temp, _mm_set_epi8(14, 15, 12, 13, 10, 11, 8, 9, 6, 7, 4, 5, 2, 3, 0, 1));\n\n        _mm_storeu_si128((__m128i*)&arr[i], a);\n        _mm_storeu_si128((__m128i*)&arr[j], b);\n\n        i += 8;\n        j -= 8;\n    }\n}\n```"}
{"task_id": "SimdBench_4_SSE", "completion": "```c\nvoid range_reverse_simd(int16_t *arr, uint64_t start, uint64_t end) {\n    uint64_t i = start;\n    uint64_t j = end;\n\n    while (i < j) {\n        __m128i a = _mm_loadu_si128((__m128i*)&arr[i]);\n        __m128i b = _mm_loadu_si128((__m128i*)&arr[j]);\n\n        __m128i temp = a;\n        a = _mm_shuffle_epi8(b, _mm_set_epi8(14, 15, 12, 13, 10, 11, 8, 9, 6, 7, 4, 5, 2, 3, 0, 1));\n        b = _mm_shuffle_epi8(temp, _mm_set_epi8(14, 15, 12, 13, 10, 11, 8, 9, 6, 7, 4, 5, 2, 3, 0, 1));\n\n        _mm_storeu_si128((__m128i*)&arr[i], a);\n        _mm_storeu_si128((__m128i*)&arr[j], b);\n\n        i += 8;\n        j -= 8;\n    }\n}\n```"}
{"task_id": "SimdBench_4_SSE", "completion": "```c\nvoid range_reverse_simd(int16_t *arr, uint64_t start, uint64_t end) {\n    uint64_t i = start;\n    uint64_t j = end;\n\n    while (i < j) {\n        __m128i a = _mm_loadu_si128((__m128i*)&arr[i]);\n        __m128i b = _mm_loadu_si128((__m128i*)&arr[j]);\n\n        __m128i temp = a;\n        a = _mm_shuffle_epi8(b, _mm_set_epi8(14, 15, 12, 13, 10, 11, 8, 9, 6, 7, 4, 5, 2, 3, 0, 1));\n        b = _mm_shuffle_epi8(temp, _mm_set_epi8(14, 15, 12, 13, 10, 11, 8, 9, 6, 7, 4, 5, 2, 3, 0, 1));\n\n        _mm_storeu_si128((__m128i*)&arr[i], a);\n        _mm_storeu_si128((__m128i*)&arr[j], b);\n\n        i += 8;\n        j -= 8;\n    }\n}\n```"}
{"task_id": "SimdBench_5_SSE", "completion": "```c\nvoid extract_tensor_slice_simd(const uint8_t *tensor, uint8_t *slice, size_t dim1, size_t dim2, size_t dim3, size_t slice_idx) {\n    size_t slice_size = dim1 * dim2;\n    const uint8_t *src = tensor + slice_idx * slice_size;\n    uint8_t *dst = slice;\n\n    for (size_t i = 0; i < slice_size; i += 16) {\n        __m128i data = _mm_loadu_si128((__m128i *)(src + i));\n        _mm_storeu_si128((__m128i *)(dst + i), data);\n    }\n}\n```"}
{"task_id": "SimdBench_5_SSE", "completion": "```c\nvoid extract_tensor_slice_simd(const uint8_t *tensor, uint8_t *slice, size_t dim1, size_t dim2, size_t dim3, size_t slice_idx) {\n    size_t slice_size = dim1 * dim2;\n    const uint8_t *src = tensor + slice_idx * slice_size;\n    uint8_t *dst = slice;\n\n    for (size_t i = 0; i < slice_size; i += 16) {\n        __m128i data = _mm_loadu_si128((__m128i *)(src + i));\n        _mm_storeu_si128((__m128i *)(dst + i), data);\n    }\n}\n```"}
{"task_id": "SimdBench_5_SSE", "completion": "```c\nvoid extract_tensor_slice_simd(const uint8_t *tensor, uint8_t *slice, size_t dim1, size_t dim2, size_t dim3, size_t slice_idx) {\n    size_t slice_size = dim1 * dim2;\n    const uint8_t *src = tensor + slice_idx * slice_size;\n    uint8_t *dst = slice;\n\n    for (size_t i = 0; i < slice_size; i += 16) {\n        __m128i data = _mm_loadu_si128((__m128i *)(src + i));\n        _mm_storeu_si128((__m128i *)(dst + i), data);\n    }\n}\n```"}
{"task_id": "SimdBench_5_SSE", "completion": "```c\nvoid extract_tensor_slice_simd(const uint8_t *tensor, uint8_t *slice, size_t dim1, size_t dim2, size_t dim3, size_t slice_idx) {\n    size_t slice_size = dim1 * dim2;\n    const uint8_t *src = tensor + slice_idx * slice_size;\n    uint8_t *dst = slice;\n\n    for (size_t i = 0; i < slice_size; i += 16) {\n        __m128i data = _mm_loadu_si128((__m128i *)(src + i));\n        _mm_storeu_si128((__m128i *)(dst + i), data);\n    }\n}\n```"}
{"task_id": "SimdBench_5_SSE", "completion": "```c\nvoid extract_tensor_slice_simd(const uint8_t *tensor, uint8_t *slice, size_t dim1, size_t dim2, size_t dim3, size_t slice_idx) {\n    size_t slice_size = dim1 * dim2;\n    const uint8_t *src = tensor + slice_idx * slice_size;\n    uint8_t *dst = slice;\n\n    for (size_t i = 0; i < slice_size; i += 16) {\n        __m128i data = _mm_loadu_si128((__m128i *)(src + i));\n        _mm_storeu_si128((__m128i *)(dst + i), data);\n    }\n}\n```"}
{"task_id": "SimdBench_6_SSE", "completion": "```cpp\nvoid blocked_matrix_transpose_simd(const int16_t *src, int16_t *dst, size_t rows, size_t cols, size_t block_size) {\n    for (size_t i = 0; i < rows; i += block_size) {\n        for (size_t j = 0; j < cols; j += block_size) {\n            for (size_t ii = i; ii < i + block_size && ii < rows; ++ii) {\n                for (size_t jj = j; jj < j + block_size && jj < cols; ++jj) {\n                    __m128i src_vec = _mm_loadu_si128((__m128i*)&src[ii * cols + jj]);\n                    __m128i dst_vec = _mm_setzero_si128();\n                    for (size_t k = 0; k < 8; ++k) {\n                        __m128i temp = _mm_shuffle_epi8(src_vec, _mm_set_epi8(14, 12, 10, 8, 6, 4, 2, 0, 15, 13, 11, 9, 7, 5, 3, 1));\n                        dst_vec = _mm_insert_epi16(dst_vec, _mm_extract_epi16(temp, k), k);\n                    }\n                    _mm_storeu_si128((__m128i*)&dst[jj * rows + ii], dst_vec);\n                }\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_6_SSE", "completion": "```cpp\nvoid blocked_matrix_transpose_simd(const int16_t *src, int16_t *dst, size_t rows, size_t cols, size_t block_size) {\n    for (size_t i = 0; i < rows; i += block_size) {\n        for (size_t j = 0; j < cols; j += block_size) {\n            for (size_t ii = i; ii < i + block_size && ii < rows; ++ii) {\n                for (size_t jj = j; jj < j + block_size && jj < cols; ++jj) {\n                    __m128i src_vec = _mm_loadu_si128((__m128i*)&src[ii * cols + jj]);\n                    __m128i dst_vec = _mm_setzero_si128();\n                    for (size_t k = 0; k < 8; ++k) {\n                        dst_vec = _mm_insert_epi16(dst_vec, _mm_extract_epi16(src_vec, k), k);\n                    }\n                    _mm_storeu_si128((__m128i*)&dst[jj * rows + ii], dst_vec);\n                }\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_6_SSE", "completion": "```cpp\nvoid blocked_matrix_transpose_simd(const int16_t *src, int16_t *dst, size_t rows, size_t cols, size_t block_size) {\n    for (size_t i = 0; i < rows; i += block_size) {\n        for (size_t j = 0; j < cols; j += block_size) {\n            for (size_t ii = i; ii < i + block_size && ii < rows; ++ii) {\n                for (size_t jj = j; jj < j + block_size && jj < cols; ++jj) {\n                    __m128i src_vec = _mm_loadu_si128((__m128i*)&src[ii * cols + jj]);\n                    __m128i dst_vec = _mm_setzero_si128();\n                    for (size_t k = 0; k < 8; ++k) {\n                        dst_vec = _mm_insert_epi16(dst_vec, _mm_extract_epi16(src_vec, k), k);\n                    }\n                    _mm_storeu_si128((__m128i*)&dst[jj * rows + ii], dst_vec);\n                }\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_6_SSE", "completion": "```cpp\nvoid blocked_matrix_transpose_simd(const int16_t *src, int16_t *dst, size_t rows, size_t cols, size_t block_size) {\n    for (size_t i = 0; i < rows; i += block_size) {\n        for (size_t j = 0; j < cols; j += block_size) {\n            for (size_t ii = i; ii < i + block_size && ii < rows; ++ii) {\n                for (size_t jj = j; jj < j + block_size && jj < cols; ++jj) {\n                    __m128i src_vec = _mm_loadu_si128((__m128i*)&src[ii * cols + jj]);\n                    __m128i dst_vec = _mm_setzero_si128();\n                    for (size_t k = 0; k < 8; ++k) {\n                        __m128i temp = _mm_shuffle_epi8(src_vec, _mm_set_epi8(14, 12, 10, 8, 6, 4, 2, 0, 15, 13, 11, 9, 7, 5, 3, 1));\n                        dst_vec = _mm_insert_epi16(dst_vec, _mm_extract_epi16(temp, k), k);\n                    }\n                    _mm_storeu_si128((__m128i*)&dst[jj * rows + ii], dst_vec);\n                }\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_6_SSE", "completion": "```cpp\nvoid blocked_matrix_transpose_simd(const int16_t *src, int16_t *dst, size_t rows, size_t cols, size_t block_size) {\n    for (size_t i = 0; i < rows; i += block_size) {\n        for (size_t j = 0; j < cols; j += block_size) {\n            for (size_t ii = i; ii < i + block_size && ii < rows; ++ii) {\n                for (size_t jj = j; jj < j + block_size && jj < cols; jj += 8) {\n                    __m128i row = _mm_loadu_si128((__m128i*)&src[ii * cols + jj]);\n                    _MM_TRANSPOSE4_EPI16(row, row, row, row);\n                    _mm_storeu_si128((__m128i*)&dst[jj * rows + ii], row);\n                }\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_7_SSE", "completion": "```c\nfloat diagonal_sum_3d_simd(const float *array, size_t dim) {\n    float sum = 0.0f;\n    __m128 sum_vec = _mm_setzero_ps();\n\n    for (size_t i = 0; i < dim; ++i) {\n        size_t index = i * (dim * dim + dim + 1);\n        size_t end = index + dim;\n\n        for (size_t j = index; j < end; j += 4) {\n            __m128 vec = _mm_loadu_ps(&array[j]);\n            sum_vec = _mm_add_ps(sum_vec, vec);\n        }\n    }\n\n    sum_vec = _mm_hadd_ps(sum_vec, sum_vec);\n    sum_vec = _mm_hadd_ps(sum_vec, sum_vec);\n    sum += _mm_cvtss_f32(sum_vec);\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_7_SSE", "completion": "```c\nfloat diagonal_sum_3d_simd(const float *array, size_t dim) {\n    float sum = 0.0f;\n    __m128 sum_vec = _mm_setzero_ps();\n\n    for (size_t i = 0; i < dim; ++i) {\n        size_t index = i * (dim * dim + dim + 1);\n        __m128 vec = _mm_loadu_ps(&array[index]);\n        sum_vec = _mm_add_ps(sum_vec, vec);\n    }\n\n    sum_vec = _mm_hadd_ps(sum_vec, sum_vec);\n    sum_vec = _mm_hadd_ps(sum_vec, sum_vec);\n    sum += _mm_cvtss_f32(sum_vec);\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_7_SSE", "completion": "```cpp\nfloat diagonal_sum_3d_simd(const float *array, size_t dim) {\n    float sum = 0.0f;\n    __m128 sum_vec = _mm_setzero_ps();\n\n    for (size_t i = 0; i < dim; ++i) {\n        size_t index = i * (dim * dim + dim + 1);\n        size_t end = index + dim;\n\n        for (size_t j = index; j < end; j += 4) {\n            __m128 vec = _mm_loadu_ps(&array[j]);\n            sum_vec = _mm_add_ps(sum_vec, vec);\n        }\n    }\n\n    sum_vec = _mm_hadd_ps(sum_vec, sum_vec);\n    sum_vec = _mm_hadd_ps(sum_vec, sum_vec);\n    sum += _mm_cvtss_f32(sum_vec);\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_7_SSE", "completion": "```c\nfloat diagonal_sum_3d_simd(const float *array, size_t dim) {\n    float sum = 0.0f;\n    size_t stride = dim * dim;\n    size_t i;\n\n    __m128 sum_vec = _mm_setzero_ps();\n\n    for (i = 0; i < dim; i += 4) {\n        __m128 diag_vec = _mm_loadu_ps(&array[i * stride + i * dim + i]);\n        sum_vec = _mm_add_ps(sum_vec, diag_vec);\n    }\n\n    sum_vec = _mm_hadd_ps(sum_vec, sum_vec);\n    sum_vec = _mm_hadd_ps(sum_vec, sum_vec);\n\n    sum = _mm_cvtss_f32(sum_vec);\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_7_SSE", "completion": "```c\nfloat diagonal_sum_3d_simd(const float *array, size_t dim) {\n    float sum = 0.0f;\n    __m128 sum_vec = _mm_setzero_ps();\n\n    for (size_t i = 0; i < dim; ++i) {\n        size_t index = i * (dim * dim + dim + 1);\n        size_t end = index + dim;\n\n        for (size_t j = index; j < end; j += 4) {\n            __m128 vec = _mm_loadu_ps(&array[j]);\n            sum_vec = _mm_add_ps(sum_vec, vec);\n        }\n    }\n\n    sum_vec = _mm_hadd_ps(sum_vec, sum_vec);\n    sum_vec = _mm_hadd_ps(sum_vec, sum_vec);\n    sum += _mm_cvtss_f32(sum_vec);\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_8_SSE", "completion": "```c\nvoid conditional_scale_simd(const double *src, double *dst, size_t rows, size_t cols, double threshold, double scale) {\n    size_t size = rows * cols;\n    __m128d v_threshold = _mm_set1_pd(threshold);\n    __m128d v_scale = _mm_set1_pd(scale);\n\n    for (size_t i = 0; i < size; i += 2) {\n        __m128d v_src = _mm_loadu_pd(&src[i]);\n        __m128d v_mask = _mm_cmpgt_pd(v_src, v_threshold);\n        __m128d v_scaled = _mm_mul_pd(v_src, v_scale);\n        __m128d v_result = _mm_blendv_pd(v_src, v_scaled, v_mask);\n        _mm_storeu_pd(&dst[i], v_result);\n    }\n}\n```"}
{"task_id": "SimdBench_8_SSE", "completion": "```cpp\nvoid conditional_scale_simd(const double *src, double *dst, size_t rows, size_t cols, double threshold, double scale) {\n    size_t size = rows * cols;\n    __m128d v_threshold = _mm_set1_pd(threshold);\n    __m128d v_scale = _mm_set1_pd(scale);\n\n    for (size_t i = 0; i < size; i += 2) {\n        __m128d v_src = _mm_loadu_pd(&src[i]);\n        __m128d v_mask = _mm_cmpgt_pd(v_src, v_threshold);\n        __m128d v_scaled = _mm_mul_pd(v_src, v_scale);\n        __m128d v_dst = _mm_blendv_pd(v_src, v_scaled, v_mask);\n        _mm_storeu_pd(&dst[i], v_dst);\n    }\n}\n```"}
{"task_id": "SimdBench_8_SSE", "completion": "```cpp\nvoid conditional_scale_simd(const double *src, double *dst, size_t rows, size_t cols, double threshold, double scale) {\n    size_t size = rows * cols;\n    __m128d v_threshold = _mm_set1_pd(threshold);\n    __m128d v_scale = _mm_set1_pd(scale);\n\n    for (size_t i = 0; i < size; i += 2) {\n        __m128d v_src = _mm_loadu_pd(&src[i]);\n        __m128d v_mask = _mm_cmpgt_pd(v_src, v_threshold);\n        __m128d v_scaled = _mm_mul_pd(v_src, v_scale);\n        __m128d v_result = _mm_blendv_pd(v_src, v_scaled, v_mask);\n        _mm_storeu_pd(&dst[i], v_result);\n    }\n}\n```"}
{"task_id": "SimdBench_8_SSE", "completion": "```cpp\nvoid conditional_scale_simd(const double *src, double *dst, size_t rows, size_t cols, double threshold, double scale) {\n    size_t size = rows * cols;\n    __m128d v_threshold = _mm_set1_pd(threshold);\n    __m128d v_scale = _mm_set1_pd(scale);\n\n    for (size_t i = 0; i < size; i += 2) {\n        __m128d v_src = _mm_loadu_pd(&src[i]);\n        __m128d v_mask = _mm_cmpgt_pd(v_src, v_threshold);\n        __m128d v_scaled = _mm_mul_pd(v_src, v_scale);\n        __m128d v_dst = _mm_blendv_pd(v_src, v_scaled, v_mask);\n        _mm_storeu_pd(&dst[i], v_dst);\n    }\n}\n```"}
{"task_id": "SimdBench_8_SSE", "completion": "```cpp\nvoid conditional_scale_simd(const double *src, double *dst, size_t rows, size_t cols, double threshold, double scale) {\n    size_t size = rows * cols;\n    __m128d v_threshold = _mm_set1_pd(threshold);\n    __m128d v_scale = _mm_set1_pd(scale);\n\n    for (size_t i = 0; i < size; i += 2) {\n        __m128d v_src = _mm_loadu_pd(&src[i]);\n        __m128d v_mask = _mm_cmpgt_pd(v_src, v_threshold);\n        __m128d v_scaled = _mm_mul_pd(v_src, v_scale);\n        __m128d v_result = _mm_blendv_pd(v_src, v_scaled, v_mask);\n        _mm_storeu_pd(&dst[i], v_result);\n    }\n}\n```"}
{"task_id": "SimdBench_9_SSE", "completion": "```cpp\nvoid reorder_matrix_rows_simd(const double *src, double *dst, size_t rows, size_t cols, const size_t *indices) {\n    for (size_t i = 0; i < rows; ++i) {\n        size_t src_row = indices[i];\n        const double *src_row_ptr = src + src_row * cols;\n        double *dst_row_ptr = dst + i * cols;\n\n        size_t j = 0;\n        for (; j <= cols - 2; j += 2) {\n            __m128d src_data = _mm_loadu_pd(src_row_ptr + j);\n            _mm_storeu_pd(dst_row_ptr + j, src_data);\n        }\n\n        for (; j < cols; ++j) {\n            dst_row_ptr[j] = src_row_ptr[j];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_9_SSE", "completion": "```cpp\nvoid reorder_matrix_rows_simd(const double *src, double *dst, size_t rows, size_t cols, const size_t *indices) {\n    for (size_t i = 0; i < rows; ++i) {\n        const double *src_row = src + indices[i] * cols;\n        double *dst_row = dst + i * cols;\n        size_t j = 0;\n        for (; j + 1 < cols; j += 2) {\n            __m128d src_data = _mm_loadu_pd(src_row + j);\n            _mm_storeu_pd(dst_row + j, src_data);\n        }\n        if (j < cols) {\n            dst_row[j] = src_row[j];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_9_SSE", "completion": "```cpp\nvoid reorder_matrix_rows_simd(const double *src, double *dst, size_t rows, size_t cols, const size_t *indices) {\n    for (size_t i = 0; i < rows; ++i) {\n        size_t src_row = indices[i] * cols;\n        size_t dst_row = i * cols;\n        for (size_t j = 0; j < cols; j += 2) {\n            __m128d src_data = _mm_loadu_pd(&src[src_row + j]);\n            _mm_storeu_pd(&dst[dst_row + j], src_data);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_9_SSE", "completion": "```cpp\nvoid reorder_matrix_rows_simd(const double *src, double *dst, size_t rows, size_t cols, const size_t *indices) {\n    for (size_t i = 0; i < rows; ++i) {\n        size_t src_row = indices[i];\n        const double *src_row_ptr = src + src_row * cols;\n        double *dst_row_ptr = dst + i * cols;\n\n        for (size_t j = 0; j < cols; j += 2) {\n            __m128d src_data = _mm_loadu_pd(src_row_ptr + j);\n            _mm_storeu_pd(dst_row_ptr + j, src_data);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_9_SSE", "completion": "```cpp\nvoid reorder_matrix_rows_simd(const double *src, double *dst, size_t rows, size_t cols, const size_t *indices) {\n    for (size_t i = 0; i < rows; ++i) {\n        size_t src_row = indices[i];\n        const double *src_row_ptr = src + src_row * cols;\n        double *dst_row_ptr = dst + i * cols;\n\n        size_t j = 0;\n        for (; j <= cols - 2; j += 2) {\n            __m128d src_data = _mm_loadu_pd(src_row_ptr + j);\n            _mm_storeu_pd(dst_row_ptr + j, src_data);\n        }\n\n        for (; j < cols; ++j) {\n            dst_row_ptr[j] = src_row_ptr[j];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_10_SSE", "completion": "```c\nvoid vector_vector_add_simd(const int64_t *src1, const int64_t *src2, int64_t *dst, int64_t scalar, size_t length) {\n    __m128i scalar_vec = _mm_set1_epi64x(scalar);\n    __m128i div2_vec = _mm_set1_epi64x(2);\n\n    for (size_t i = 0; i < length; i += 2) {\n        __m128i vec1 = _mm_loadu_si128((__m128i *)&src1[i]);\n        __m128i vec2 = _mm_loadu_si128((__m128i *)&src2[i]);\n\n        __m128i sum = _mm_add_epi64(vec1, vec2);\n        sum = _mm_add_epi64(sum, scalar_vec);\n        sum = _mm_srli_epi64(sum, 1);\n\n        _mm_storeu_si128((__m128i *)&dst[i], sum);\n    }\n}\n```"}
{"task_id": "SimdBench_10_SSE", "completion": "```cpp\nvoid vector_vector_add_simd(const int64_t *src1, const int64_t *src2, int64_t *dst, int64_t scalar, size_t length) {\n    __m128i scalar_vec = _mm_set1_epi64x(scalar);\n    __m128i div2_vec = _mm_set1_epi64x(2);\n\n    for (size_t i = 0; i < length; i += 2) {\n        __m128i vec1 = _mm_loadu_si128((__m128i *)&src1[i]);\n        __m128i vec2 = _mm_loadu_si128((__m128i *)&src2[i]);\n\n        __m128i sum = _mm_add_epi64(vec1, vec2);\n        sum = _mm_add_epi64(sum, scalar_vec);\n        sum = _mm_srli_epi64(sum, 1);\n\n        _mm_storeu_si128((__m128i *)&dst[i], sum);\n    }\n}\n```"}
{"task_id": "SimdBench_10_SSE", "completion": "```c\nvoid vector_vector_add_simd(const int64_t *src1, const int64_t *src2, int64_t *dst, int64_t scalar, size_t length) {\n    __m128i scalar_vec = _mm_set1_epi64x(scalar);\n    __m128i div2_vec = _mm_set1_epi64x(2);\n\n    for (size_t i = 0; i < length; i += 2) {\n        __m128i vec1 = _mm_loadu_si128((__m128i *)&src1[i]);\n        __m128i vec2 = _mm_loadu_si128((__m128i *)&src2[i]);\n\n        __m128i sum = _mm_add_epi64(vec1, vec2);\n        sum = _mm_add_epi64(sum, scalar_vec);\n        sum = _mm_srai_epi64(sum, 1);\n\n        _mm_storeu_si128((__m128i *)&dst[i], sum);\n    }\n}\n```"}
{"task_id": "SimdBench_10_SSE", "completion": "```c\nvoid vector_vector_add_simd(const int64_t *src1, const int64_t *src2, int64_t *dst, int64_t scalar, size_t length) {\n    __m128i scalar_vec = _mm_set1_epi64x(scalar);\n    __m128i two_vec = _mm_set1_epi64x(2);\n\n    for (size_t i = 0; i < length; i += 2) {\n        __m128i src1_vec = _mm_loadu_si128((__m128i *)&src1[i]);\n        __m128i src2_vec = _mm_loadu_si128((__m128i *)&src2[i]);\n\n        __m128i sum_vec = _mm_add_epi64(src1_vec, src2_vec);\n        sum_vec = _mm_add_epi64(sum_vec, scalar_vec);\n        sum_vec = _mm_srai_epi64(sum_vec, 1);\n\n        _mm_storeu_si128((__m128i *)&dst[i], sum_vec);\n    }\n}\n```"}
{"task_id": "SimdBench_10_SSE", "completion": "```c\nvoid vector_vector_add_simd(const int64_t *src1, const int64_t *src2, int64_t *dst, int64_t scalar, size_t length) {\n    __m128i scalar_vec = _mm_set1_epi64x(scalar);\n    __m128i two_vec = _mm_set1_epi64x(2);\n\n    for (size_t i = 0; i < length; i += 2) {\n        __m128i src1_vec = _mm_loadu_si128((__m128i *)&src1[i]);\n        __m128i src2_vec = _mm_loadu_si128((__m128i *)&src2[i]);\n\n        __m128i sum_vec = _mm_add_epi64(src1_vec, src2_vec);\n        sum_vec = _mm_add_epi64(sum_vec, scalar_vec);\n        sum_vec = _mm_srai_epi64(sum_vec, 1);\n\n        _mm_storeu_si128((__m128i *)&dst[i], sum_vec);\n    }\n}\n```"}
{"task_id": "SimdBench_11_SSE", "completion": "```cpp\nint vector_even_min_simd(const int *src, size_t length) {\n    if (length == 0) {\n        return -1;\n    }\n\n    __m128i min_val = _mm_set1_epi32(INT_MAX);\n    size_t i = 0;\n\n    for (; i + 3 < length; i += 4) {\n        __m128i v = _mm_loadu_si128((__m128i*)&src[i]);\n        __m128i even_mask = _mm_setr_epi32(0, -1, 0, -1);\n        __m128i even_vals = _mm_and_si128(v, even_mask);\n        min_val = _mm_min_epi32(min_val, even_vals);\n    }\n\n    int min_arr[4];\n    _mm_storeu_si128((__m128i*)min_arr, min_val);\n    int min_even = INT_MAX;\n\n    for (int j = 0; j < 4; ++j) {\n        if (min_arr[j] < min_even) {\n            min_even = min_arr[j];\n        }\n    }\n\n    for (; i < length; i += 2) {\n        if (src[i] < min_even) {\n            min_even = src[i];\n        }\n    }\n\n    return min_even;\n}\n```"}
{"task_id": "SimdBench_11_SSE", "completion": "```c\nint vector_even_min_simd(const int *src, size_t length) {\n    if (length == 0) {\n        return -1;\n    }\n\n    __m128i min_val = _mm_set1_epi32(INT_MAX);\n    size_t i = 0;\n\n    for (; i + 4 <= length; i += 4) {\n        __m128i vec = _mm_loadu_si128((__m128i*)&src[i]);\n        __m128i even_mask = _mm_set_epi32(0, INT_MAX, 0, INT_MAX);\n        vec = _mm_and_si128(vec, even_mask);\n        min_val = _mm_min_epi32(min_val, vec);\n    }\n\n    int min_array[4];\n    _mm_storeu_si128((__m128i*)min_array, min_val);\n    int min = INT_MAX;\n    for (int j = 0; j < 4; ++j) {\n        if (min_array[j] != 0 && min_array[j] < min) {\n            min = min_array[j];\n        }\n    }\n\n    for (; i < length; i += 2) {\n        if (src[i] < min) {\n            min = src[i];\n        }\n    }\n\n    return min;\n}\n```"}
{"task_id": "SimdBench_11_SSE", "completion": "```c\nint vector_even_min_simd(const int *src, size_t length) {\n    if (length == 0) {\n        return -1;\n    }\n\n    __m128i min_val = _mm_set1_epi32(INT_MAX);\n    size_t i = 0;\n\n    for (; i + 4 <= length; i += 4) {\n        __m128i vec = _mm_loadu_si128((__m128i *)&src[i]);\n        __m128i mask = _mm_setr_epi32(0, 1, 0, 1);\n        __m128i even_elements = _mm_and_si128(vec, mask);\n        min_val = _mm_min_epi32(min_val, even_elements);\n    }\n\n    int min[4];\n    _mm_storeu_si128((__m128i *)min, min_val);\n    int result = INT_MAX;\n    for (int j = 0; j < 4; ++j) {\n        if (min[j] < result) {\n            result = min[j];\n        }\n    }\n\n    for (; i < length; i += 2) {\n        if (src[i] < result) {\n            result = src[i];\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_11_SSE", "completion": "```c\nint vector_even_min_simd(const int *src, size_t length) {\n    if (length == 0) {\n        return -1;\n    }\n\n    __m128i min_val = _mm_set1_epi32(INT_MAX);\n    size_t i = 0;\n\n    for (; i + 3 < length; i += 4) {\n        __m128i v = _mm_loadu_si128((__m128i*)&src[i]);\n        __m128i even_mask = _mm_set_epi32(0, INT_MAX, 0, INT_MAX);\n        __m128i even_vals = _mm_and_si128(v, even_mask);\n        min_val = _mm_min_epi32(min_val, even_vals);\n    }\n\n    int min[4];\n    _mm_storeu_si128((__m128i*)min, min_val);\n    int result = INT_MAX;\n\n    for (int j = 0; j < 4; ++j) {\n        if (min[j] != INT_MAX && min[j] < result) {\n            result = min[j];\n        }\n    }\n\n    for (; i < length; i += 2) {\n        if (src[i] < result) {\n            result = src[i];\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_11_SSE", "completion": "```cpp\nint vector_even_min_simd(const int *src, size_t length) {\n    if (length == 0) {\n        return -1;\n    }\n\n    __m128i min_val = _mm_set1_epi32(INT_MAX);\n    size_t i = 0;\n\n    for (; i + 3 < length; i += 4) {\n        __m128i v = _mm_loadu_si128((__m128i*)&src[i]);\n        __m128i even_mask = _mm_set_epi32(0, INT_MAX, 0, INT_MAX);\n        __m128i even_vals = _mm_and_si128(v, even_mask);\n        min_val = _mm_min_epi32(min_val, even_vals);\n    }\n\n    int min_arr[4];\n    _mm_storeu_si128((__m128i*)min_arr, min_val);\n    int min_even = INT_MAX;\n    for (int j = 0; j < 4; ++j) {\n        if (min_arr[j] != INT_MAX && min_arr[j] < min_even) {\n            min_even = min_arr[j];\n        }\n    }\n\n    for (; i < length; i += 2) {\n        if (src[i] < min_even) {\n            min_even = src[i];\n        }\n    }\n\n    return min_even;\n}\n```"}
{"task_id": "SimdBench_12_SSE", "completion": "```c\nvoid mixed_right_shift_simd(const int *src, int *dst, uint8_t shift, size_t length) {\n    size_t i;\n    __m128i shift_vec = _mm_set1_epi32(shift);\n    __m128i zero_vec = _mm_setzero_si128();\n\n    for (i = 0; i < length; i += 4) {\n        __m128i src_vec = _mm_loadu_si128((__m128i *)&src[i]);\n\n        __m128i arith_shift = _mm_sra_epi32(src_vec, shift_vec);\n\n        __m128i logical_shift = _mm_srl_epi32(_mm_castsi128_si32(src_vec), shift_vec);\n\n        __m128i result = _mm_add_epi32(arith_shift, logical_shift);\n\n        _mm_storeu_si128((__m128i *)&dst[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_12_SSE", "completion": "```c\nvoid mixed_right_shift_simd(const int *src, int *dst, uint8_t shift, size_t length) {\n    __m128i shift_vec = _mm_set1_epi32(shift);\n    __m128i zero_vec = _mm_setzero_si128();\n\n    for (size_t i = 0; i < length; i += 4) {\n        __m128i src_vec = _mm_loadu_si128((__m128i *)&src[i]);\n\n        __m128i arith_shift = _mm_sra_epi32(src_vec, shift_vec);\n        __m128i logical_shift = _mm_srl_epi32(_mm_castsi128_si32(src_vec), shift_vec);\n\n        __m128i result = _mm_add_epi32(arith_shift, logical_shift);\n\n        _mm_storeu_si128((__m128i *)&dst[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_12_SSE", "completion": "```c\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid mixed_right_shift_simd(const int *src, int *dst, uint8_t shift, size_t length) {\n    __m128i shift_vec = _mm_set1_epi32(shift);\n    __m128i zero_vec = _mm_setzero_si128();\n\n    for (size_t i = 0; i < length; i += 4) {\n        __m128i src_vec = _mm_loadu_si128((__m128i*)&src[i]);\n\n        __m128i arith_shift = _mm_sra_epi32(src_vec, shift_vec);\n        __m128i logical_shift = _mm_srl_epi32(_mm_castsi128_si32(src_vec), shift_vec);\n\n        __m128i result = _mm_add_epi32(arith_shift, logical_shift);\n\n        _mm_storeu_si128((__m128i*)&dst[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_12_SSE", "completion": "```c\nvoid mixed_right_shift_simd(const int *src, int *dst, uint8_t shift, size_t length) {\n    __m128i shift_vec = _mm_set1_epi32(shift);\n    __m128i zero_vec = _mm_setzero_si128();\n\n    for (size_t i = 0; i < length; i += 4) {\n        __m128i src_vec = _mm_loadu_si128((__m128i*)&src[i]);\n\n        __m128i arith_shift = _mm_sra_epi32(src_vec, shift_vec);\n\n        __m128i logical_shift = _mm_srl_epi32(_mm_castsi128_si32(src_vec), shift_vec);\n\n        __m128i result = _mm_add_epi32(arith_shift, logical_shift);\n\n        _mm_storeu_si128((__m128i*)&dst[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_12_SSE", "completion": "```cpp\nvoid mixed_right_shift_simd(const int *src, int *dst, uint8_t shift, size_t length) {\n    __m128i shift_vec = _mm_set1_epi32(shift);\n    __m128i zero_vec = _mm_setzero_si128();\n\n    for (size_t i = 0; i < length; i += 4) {\n        __m128i src_vec = _mm_loadu_si128((__m128i*)&src[i]);\n\n        __m128i arith_shift_vec = _mm_sra_epi32(src_vec, shift_vec);\n\n        __m128i logical_shift_vec = _mm_srl_epi32(_mm_castsi128_si32(src_vec), shift_vec);\n\n        __m128i result_vec = _mm_add_epi32(arith_shift_vec, logical_shift_vec);\n\n        _mm_storeu_si128((__m128i*)&dst[i], result_vec);\n    }\n}\n```"}
{"task_id": "SimdBench_13_SSE", "completion": "```c\nint64_t matrix_sum_simd(const int *matrix, size_t rows, size_t cols) {\n    size_t size = rows * cols;\n    __m128i sum = _mm_setzero_si128();\n    size_t i;\n\n    for (i = 0; i <= size - 4; i += 4) {\n        __m128i data = _mm_loadu_si128((__m128i*)&matrix[i]);\n        sum = _mm_add_epi32(sum, data);\n    }\n\n    int32_t temp[4];\n    _mm_storeu_si128((__m128i*)temp, sum);\n    int64_t result = temp[0] + temp[1] + temp[2] + temp[3];\n\n    for (; i < size; ++i) {\n        result += matrix[i];\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_13_SSE", "completion": "```cpp\nint64_t matrix_sum_simd(const int *matrix, size_t rows, size_t cols) {\n    size_t size = rows * cols;\n    __m128i sum_vec = _mm_setzero_si128();\n    size_t i = 0;\n\n    for (; i <= size - 4; i += 4) {\n        __m128i vec = _mm_loadu_si128((__m128i*)&matrix[i]);\n        sum_vec = _mm_add_epi32(sum_vec, vec);\n    }\n\n    int32_t sum_array[4];\n    _mm_storeu_si128((__m128i*)sum_array, sum_vec);\n    int64_t sum = sum_array[0] + sum_array[1] + sum_array[2] + sum_array[3];\n\n    for (; i < size; ++i) {\n        sum += matrix[i];\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_13_SSE", "completion": "```c\nint64_t matrix_sum_simd(const int *matrix, size_t rows, size_t cols) {\n    size_t size = rows * cols;\n    __m128i sum = _mm_setzero_si128();\n    size_t i;\n\n    for (i = 0; i <= size - 4; i += 4) {\n        __m128i data = _mm_loadu_si128((__m128i*)&matrix[i]);\n        sum = _mm_add_epi32(sum, data);\n    }\n\n    int32_t temp[4];\n    _mm_storeu_si128((__m128i*)temp, sum);\n    int64_t result = temp[0] + temp[1] + temp[2] + temp[3];\n\n    for (; i < size; ++i) {\n        result += matrix[i];\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_13_SSE", "completion": "```c\nint64_t matrix_sum_simd(const int *matrix, size_t rows, size_t cols) {\n    size_t size = rows * cols;\n    __m128i sum = _mm_setzero_si128();\n    size_t i;\n\n    for (i = 0; i <= size - 4; i += 4) {\n        __m128i data = _mm_loadu_si128((__m128i*)&matrix[i]);\n        sum = _mm_add_epi32(sum, data);\n    }\n\n    int32_t temp[4];\n    _mm_storeu_si128((__m128i*)temp, sum);\n    int64_t result = temp[0] + temp[1] + temp[2] + temp[3];\n\n    for (; i < size; ++i) {\n        result += matrix[i];\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_13_SSE", "completion": "```c\nint64_t matrix_sum_simd(const int *matrix, size_t rows, size_t cols) {\n    size_t size = rows * cols;\n    __m128i sum_vec = _mm_setzero_si128();\n    size_t i;\n\n    for (i = 0; i <= size - 4; i += 4) {\n        __m128i vec = _mm_loadu_si128((__m128i*)&matrix[i]);\n        sum_vec = _mm_add_epi32(sum_vec, vec);\n    }\n\n    int32_t sum_array[4];\n    _mm_storeu_si128((__m128i*)sum_array, sum_vec);\n    int64_t sum = sum_array[0] + sum_array[1] + sum_array[2] + sum_array[3];\n\n    for (; i < size; ++i) {\n        sum += matrix[i];\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_14_SSE", "completion": "```cpp\nsize_t argmax_simd(const int8_t *src, size_t length) {\n    if (length == 0) return 0;\n\n    __m128i max_val = _mm_set1_epi8(src[0]);\n    __m128i indices = _mm_set_epi8(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15);\n    size_t max_index = 0;\n\n    for (size_t i = 0; i < length; i += 16) {\n        __m128i current = _mm_loadu_si128((__m128i*)&src[i]);\n        __m128i cmp = _mm_cmpgt_epi8(current, max_val);\n        __m128i new_max_val = _mm_max_epi8(current, max_val);\n        __m128i new_indices = _mm_blendv_epi8(indices, _mm_add_epi8(indices, _mm_set1_epi8(16)), cmp);\n\n        max_val = new_max_val;\n        indices = new_indices;\n        max_index = i + _mm_extract_epi16(_mm_shuffle_epi8(indices, _mm_set1_epi8(0)), 0);\n    }\n\n    return max_index;\n}\n```"}
{"task_id": "SimdBench_14_SSE", "completion": "```cpp\nsize_t argmax_simd(const int8_t *src, size_t length) {\n    if (length == 0) return 0;\n\n    __m128i max_val = _mm_set1_epi8(src[0]);\n    size_t max_index = 0;\n\n    for (size_t i = 0; i < length; i += 16) {\n        __m128i current = _mm_loadu_si128((__m128i*)&src[i]);\n        __m128i cmp = _mm_cmpgt_epi8(current, max_val);\n\n        if (!_mm_testz_si128(cmp, cmp)) {\n            int mask = _mm_movemask_epi8(cmp);\n            int bit_pos = _tzcnt_u32(mask);\n            max_val = _mm_set1_epi8(src[i + bit_pos]);\n            max_index = i + bit_pos;\n        }\n    }\n\n    return max_index;\n}\n```"}
{"task_id": "SimdBench_14_SSE", "completion": "```cpp\nsize_t argmax_simd(const int8_t *src, size_t length) {\n    if (length == 0) return 0;\n\n    __m128i max_val = _mm_set1_epi8(src[0]);\n    __m128i indices = _mm_set_epi8(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15);\n    size_t max_index = 0;\n\n    for (size_t i = 0; i < length; i += 16) {\n        __m128i current_vals = _mm_loadu_si128((__m128i*)&src[i]);\n        __m128i cmp = _mm_cmpgt_epi8(current_vals, max_val);\n\n        __m128i new_max_val = _mm_max_epi8(current_vals, max_val);\n        __m128i new_indices = _mm_blendv_epi8(indices, _mm_add_epi8(indices, _mm_set1_epi8(16)), cmp);\n\n        max_val = new_max_val;\n        indices = new_indices;\n\n        if (i + 16 < length) {\n            indices = _mm_add_epi8(indices, _mm_set1_epi8(16));\n        }\n    }\n\n    int8_t max_val_arr[16];\n    _mm_storeu_si128((__m128i*)max_val_arr, max_val);\n\n    int8_t max_index_arr[16];\n    _mm_storeu_si128((__m128i*)max_index_arr, indices);\n\n    int8_t max_value = max_val_arr[0];\n    size_t max_index = max_index_arr[0];\n\n    for (int i = 1; i < 16; ++i) {\n        if (max_val_arr[i] > max_value) {\n            max_value = max_val_arr[i];\n            max_index = max_index_arr[i];\n        }\n    }\n\n    return max_index;\n}\n```"}
{"task_id": "SimdBench_14_SSE", "completion": "```cpp\nsize_t argmax_simd(const int8_t *src, size_t length) {\n    if (length == 0) return 0;\n\n    __m128i max_val = _mm_set1_epi8(src[0]);\n    __m128i indices = _mm_set_epi8(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15);\n    size_t max_index = 0;\n\n    for (size_t i = 0; i < length; i += 16) {\n        __m128i current_vals = _mm_loadu_si128((__m128i*)&src[i]);\n        __m128i cmp = _mm_cmpgt_epi8(current_vals, max_val);\n        __m128i new_max_val = _mm_max_epi8(current_vals, max_val);\n        __m128i new_indices = _mm_or_si128(_mm_and_si128(cmp, indices), _mm_andnot_si128(cmp, _mm_set1_epi8(-1)));\n\n        max_val = new_max_val;\n        indices = new_indices;\n\n        if (i + 16 < length) {\n            indices = _mm_add_epi8(indices, _mm_set1_epi8(16));\n        }\n    }\n\n    int8_t max_vals[16];\n    int8_t idx_vals[16];\n    _mm_storeu_si128((__m128i*)max_vals, max_val);\n    _mm_storeu_si128((__m128i*)idx_vals, indices);\n\n    int8_t global_max = max_vals[0];\n    size_t global_index = idx_vals[0];\n\n    for (int i = 1; i < 16; ++i) {\n        if (max_vals[i] > global_max) {\n            global_max = max_vals[i];\n            global_index = idx_vals[i];\n        }\n    }\n\n    return global_index;\n}\n```"}
{"task_id": "SimdBench_14_SSE", "completion": "```cpp\nsize_t argmax_simd(const int8_t *src, size_t length) {\n    if (length == 0) return 0;\n\n    __m128i max_val = _mm_set1_epi8(src[0]);\n    size_t max_index = 0;\n\n    for (size_t i = 0; i < length; i += 16) {\n        __m128i current = _mm_loadu_si128((__m128i*)&src[i]);\n        __m128i cmp = _mm_cmpgt_epi8(current, max_val);\n\n        if (!_mm_testz_si128(cmp, cmp)) {\n            int mask = _mm_movemask_epi8(cmp);\n            int bit_pos = _tzcnt_u32(mask);\n            max_val = _mm_set1_epi8(src[i + bit_pos]);\n            max_index = i + bit_pos;\n        }\n    }\n\n    return max_index;\n}\n```"}
{"task_id": "SimdBench_15_SSE", "completion": "```c\nvoid vector_blend_simd(const uint16_t* src1, const uint16_t* src2, uint32_t mask, uint16_t* dst, size_t length) {\n    size_t i = 0;\n    __m128i mask_vec = _mm_set1_epi32(mask);\n    __m128i index_vec = _mm_set_epi32(3, 2, 1, 0);\n\n    for (; i <= length - 8; i += 8) {\n        __m128i src1_vec = _mm_loadu_si128((__m128i*)&src1[i]);\n        __m128i src2_vec = _mm_loadu_si128((__m128i*)&src2[i]);\n\n        __m128i index_base = _mm_add_epi32(index_vec, _mm_set1_epi32(i));\n        __m128i and_result = _mm_and_si128(index_base, mask_vec);\n        __m128i blend_mask = _mm_cmpgt_epi32(and_result, _mm_setzero_si128());\n\n        __m128i result_vec = _mm_blendv_epi8(src2_vec, src1_vec, blend_mask);\n\n        _mm_storeu_si128((__m128i*)&dst[i], result_vec);\n    }\n\n    for (; i < length; ++i) {\n        if ((i & mask) != 0) {\n            dst[i] = src1[i];\n        } else {\n            dst[i] = src2[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_15_SSE", "completion": "```c\nvoid vector_blend_simd(const uint16_t* src1, const uint16_t* src2, uint32_t mask, uint16_t* dst, size_t length) {\n    size_t i = 0;\n    __m128i mask_vec = _mm_set1_epi32(mask);\n    __m128i index_vec = _mm_setr_epi32(0, 1, 2, 3);\n\n    for (; i + 8 <= length; i += 8) {\n        __m128i src1_vec = _mm_loadu_si128((__m128i*)&src1[i]);\n        __m128i src2_vec = _mm_loadu_si128((__m128i*)&src2[i]);\n\n        __m128i index_vec_0 = _mm_add_epi32(index_vec, _mm_set1_epi32(i));\n        __m128i index_vec_1 = _mm_add_epi32(index_vec, _mm_set1_epi32(i + 4));\n\n        __m128i mask_vec_0 = _mm_and_si128(index_vec_0, mask_vec);\n        __m128i mask_vec_1 = _mm_and_si128(index_vec_1, mask_vec);\n\n        __m128i blend_mask_0 = _mm_cmpgt_epi32(mask_vec_0, _mm_setzero_si128());\n        __m128i blend_mask_1 = _mm_cmpgt_epi32(mask_vec_1, _mm_setzero_si128());\n\n        __m128i result_0 = _mm_blendv_epi8(src2_vec, src1_vec, blend_mask_0);\n        __m128i result_1 = _mm_blendv_epi8(src2_vec, src1_vec, blend_mask_1);\n\n        _mm_storeu_si128((__m128i*)&dst[i], result_0);\n        _mm_storeu_si128((__m128i*)&dst[i + 4], result_1);\n    }\n\n    for (; i < length; ++i) {\n        dst[i] = (i & mask) ? src1[i] : src2[i];\n    }\n}\n```"}
{"task_id": "SimdBench_15_SSE", "completion": "```c\nvoid vector_blend_simd(const uint16_t* src1, const uint16_t* src2, uint32_t mask, uint16_t* dst, size_t length) {\n    size_t i = 0;\n    __m128i mask_vec = _mm_set1_epi32(mask);\n    __m128i index_vec = _mm_set_epi32(3, 2, 1, 0);\n\n    for (; i + 8 <= length; i += 8) {\n        __m128i src1_vec = _mm_loadu_si128((__m128i*)&src1[i]);\n        __m128i src2_vec = _mm_loadu_si128((__m128i*)&src2[i]);\n\n        __m128i index_base = _mm_add_epi32(index_vec, _mm_set1_epi32(i));\n        __m128i and_result = _mm_and_si128(index_base, mask_vec);\n\n        __m128i blend_mask = _mm_cmpgt_epi32(and_result, _mm_setzero_si128());\n        __m128i result = _mm_blendv_epi8(src2_vec, src1_vec, blend_mask);\n\n        _mm_storeu_si128((__m128i*)&dst[i], result);\n    }\n\n    for (; i < length; ++i) {\n        if ((i & mask) != 0) {\n            dst[i] = src1[i];\n        } else {\n            dst[i] = src2[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_15_SSE", "completion": "```cpp\nvoid vector_blend_simd(const uint16_t* src1, const uint16_t* src2, uint32_t mask, uint16_t* dst, size_t length) {\n    size_t i = 0;\n    __m128i mask_vec = _mm_set1_epi32(mask);\n\n    for (; i + 8 <= length; i += 8) {\n        __m128i idx_vec = _mm_set_epi32(i + 7, i + 6, i + 5, i + 4);\n        __m128i idx_vec2 = _mm_set_epi32(i + 3, i + 2, i + 1, i);\n\n        __m128i and_result = _mm_and_si128(idx_vec, mask_vec);\n        __m128i and_result2 = _mm_and_si128(idx_vec2, mask_vec);\n\n        __m128i src1_vec = _mm_loadu_si128((__m128i*)&src1[i]);\n        __m128i src2_vec = _mm_loadu_si128((__m128i*)&src2[i]);\n\n        __m128i blend_mask = _mm_or_si128(_mm_cmpgt_epi32(and_result, _mm_setzero_si128()), _mm_cmpgt_epi32(and_result2, _mm_setzero_si128()));\n        __m128i result = _mm_blendv_epi8(src2_vec, src1_vec, blend_mask);\n\n        _mm_storeu_si128((__m128i*)&dst[i], result);\n    }\n\n    for (; i < length; ++i) {\n        dst[i] = (i & mask) ? src1[i] : src2[i];\n    }\n}\n```"}
{"task_id": "SimdBench_15_SSE", "completion": "```c\nvoid vector_blend_simd(const uint16_t* src1, const uint16_t* src2, uint32_t mask, uint16_t* dst, size_t length) {\n    size_t i;\n    for (i = 0; i < length; i += 8) {\n        __m128i v_src1 = _mm_loadu_si128((__m128i*)&src1[i]);\n        __m128i v_src2 = _mm_loadu_si128((__m128i*)&src2[i]);\n\n        __m128i v_mask = _mm_set1_epi32(mask);\n        __m128i v_index = _mm_setr_epi32(i, i + 1, i + 2, i + 3);\n        __m128i v_and = _mm_and_si128(v_index, v_mask);\n\n        __m128i v_blend = _mm_blendv_epi8(v_src2, v_src1, v_and);\n\n        _mm_storeu_si128((__m128i*)&dst[i], v_blend);\n    }\n}\n```"}
{"task_id": "SimdBench_16_SSE", "completion": "```c\nvoid population_count_simd(const uint32_t* src, uint32_t* dst, size_t length) {\n    size_t i;\n    for (i = 0; i + 4 <= length; i += 4) {\n        __m128i v = _mm_loadu_si128((__m128i*)&src[i]);\n        __m128i v1 = _mm_srli_epi32(v, 1);\n        __m128i v2 = _mm_and_si128(v1, _mm_set1_epi32(0x55555555));\n        __m128i v3 = _mm_sub_epi32(v, v2);\n        __m128i v4 = _mm_srli_epi32(v3, 2);\n        __m128i v5 = _mm_and_si128(v4, _mm_set1_epi32(0x33333333));\n        __m128i v6 = _mm_add_epi32(v5, _mm_and_si128(v3, _mm_set1_epi32(0x33333333)));\n        __m128i v7 = _mm_srli_epi32(v6, 4);\n        __m128i v8 = _mm_add_epi32(v7, v6);\n        __m128i v9 = _mm_and_si128(v8, _mm_set1_epi32(0x0f0f0f0f));\n        __m128i v10 = _mm_srli_epi32(v9, 8);\n        __m128i v11 = _mm_add_epi32(v10, v9);\n        __m128i v12 = _mm_srli_epi32(v11, 16);\n        __m128i v13 = _mm_add_epi32(v12, v11);\n        _mm_storeu_si128((__m128i*)&dst[i], v13);\n    }\n    for (; i < length; ++i) {\n        dst[i] = _mm_popcnt_u32(src[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_16_SSE", "completion": "```c\nvoid population_count_simd(const uint32_t* src, uint32_t* dst, size_t length) {\n    size_t i;\n    for (i = 0; i + 4 <= length; i += 4) {\n        __m128i v = _mm_loadu_si128((__m128i*)&src[i]);\n        __m128i popcnt = _mm_sad_epu8(v, _mm_setzero_si128());\n        popcnt = _mm_add_epi32(popcnt, _mm_srli_si128(popcnt, 8));\n        popcnt = _mm_add_epi32(popcnt, _mm_srli_si128(popcnt, 4));\n        _mm_storeu_si128((__m128i*)&dst[i], popcnt);\n    }\n    for (; i < length; ++i) {\n        dst[i] = _mm_popcnt_u32(src[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_16_SSE", "completion": "```c\nvoid population_count_simd(const uint32_t* src, uint32_t* dst, size_t length) {\n    size_t i;\n    for (i = 0; i + 4 <= length; i += 4) {\n        __m128i v = _mm_loadu_si128((__m128i*)&src[i]);\n        __m128i v1 = _mm_srli_epi32(v, 1);\n        __m128i v2 = _mm_srli_epi32(v, 2);\n        __m128i v3 = _mm_srli_epi32(v, 3);\n        __m128i v4 = _mm_and_si128(v, _mm_set1_epi32(0x55555555));\n        __m128i v5 = _mm_and_si128(v1, _mm_set1_epi32(0x55555555));\n        __m128i v6 = _mm_and_si128(v2, _mm_set1_epi32(0x55555555));\n        __m128i v7 = _mm_and_si128(v3, _mm_set1_epi32(0x55555555));\n        __m128i v8 = _mm_add_epi32(v4, v5);\n        __m128i v9 = _mm_add_epi32(v6, v7);\n        __m128i v10 = _mm_add_epi32(v8, v9);\n        __m128i v11 = _mm_srli_epi32(v10, 4);\n        __m128i v12 = _mm_add_epi32(v10, v11);\n        __m128i v13 = _mm_and_si128(v12, _mm_set1_epi32(0x0f0f0f0f));\n        __m128i v14 = _mm_srli_epi32(v13, 8);\n        __m128i v15 = _mm_add_epi32(v13, v14);\n        __m128i v16 = _mm_srli_epi32(v15, 16);\n        __m128i v17 = _mm_add_epi32(v15, v16);\n        __m128i v18 = _mm_and_si128(v17, _mm_set1_epi32(0x0000003f));\n        _mm_storeu_si128((__m128i*)&dst[i], v18);\n    }\n    for (; i < length; ++i) {\n        dst[i] = _mm_popcnt_u32(src[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_16_SSE", "completion": "```c\nvoid population_count_simd(const uint32_t* src, uint32_t* dst, size_t length) {\n    size_t i = 0;\n    for (; i + 4 <= length; i += 4) {\n        __m128i v = _mm_loadu_si128((__m128i*)&src[i]);\n        __m128i count = _mm_setzero_si128();\n        count = _mm_sub_epi32(count, _mm_and_si128(_mm_srli_epi32(v, 1), _mm_set1_epi32(0x55555555)));\n        count = _mm_sub_epi32(count, _mm_and_si128(_mm_srli_epi32(count, 1), _mm_set1_epi32(0x33333333)));\n        count = _mm_sub_epi32(count, _mm_and_si128(_mm_srli_epi32(count, 2), _mm_set1_epi32(0x0f0f0f0f)));\n        count = _mm_srli_epi32(count, 24);\n        _mm_storeu_si128((__m128i*)&dst[i], count);\n    }\n    for (; i < length; ++i) {\n        dst[i] = _mm_popcnt_u32(src[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_16_SSE", "completion": "```c\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid population_count_simd(const uint32_t* src, uint32_t* dst, size_t length) {\n    size_t i;\n    for (i = 0; i <= length - 4; i += 4) {\n        __m128i v = _mm_loadu_si128((__m128i*)&src[i]);\n        __m128i count = _mm_sad_epu8(v, _mm_setzero_si128());\n        count = _mm_add_epi32(count, _mm_srli_si128(count, 8));\n        count = _mm_add_epi32(count, _mm_srli_si128(count, 4));\n        _mm_storeu_si128((__m128i*)&dst[i], count);\n    }\n    for (; i < length; ++i) {\n        dst[i] = _mm_popcnt_u32(src[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_17_SSE", "completion": "```cpp\nvoid saturating_add_simd(const uint16_t* src1, const uint16_t* src2, uint16_t* dst, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 8; i += 8) {\n        __m128i a = _mm_loadu_si128((__m128i*)&src1[i]);\n        __m128i b = _mm_loadu_si128((__m128i*)&src2[i]);\n        __m128i sum = _mm_adds_epu16(a, b);\n        _mm_storeu_si128((__m128i*)&dst[i], sum);\n    }\n    for (; i < length; ++i) {\n        uint32_t sum = (uint32_t)src1[i] + (uint32_t)src2[i];\n        dst[i] = (sum > UINT16_MAX) ? UINT16_MAX : (uint16_t)sum;\n    }\n}\n```"}
{"task_id": "SimdBench_17_SSE", "completion": "```cpp\nvoid saturating_add_simd(const uint16_t* src1, const uint16_t* src2, uint16_t* dst, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 8; i += 8) {\n        __m128i a = _mm_loadu_si128((__m128i*)&src1[i]);\n        __m128i b = _mm_loadu_si128((__m128i*)&src2[i]);\n        __m128i sum = _mm_adds_epu16(a, b);\n        _mm_storeu_si128((__m128i*)&dst[i], sum);\n    }\n    for (; i < length; ++i) {\n        uint32_t sum = (uint32_t)src1[i] + (uint32_t)src2[i];\n        dst[i] = (sum > UINT16_MAX) ? UINT16_MAX : (uint16_t)sum;\n    }\n}\n```"}
{"task_id": "SimdBench_17_SSE", "completion": "```cpp\nvoid saturating_add_simd(const uint16_t* src1, const uint16_t* src2, uint16_t* dst, size_t length) {\n    size_t i;\n    for (i = 0; i <= length - 8; i += 8) {\n        __m128i a = _mm_loadu_si128((__m128i*)&src1[i]);\n        __m128i b = _mm_loadu_si128((__m128i*)&src2[i]);\n        __m128i sum = _mm_adds_epu16(a, b);\n        _mm_storeu_si128((__m128i*)&dst[i], sum);\n    }\n    for (; i < length; ++i) {\n        uint32_t sum = (uint32_t)src1[i] + (uint32_t)src2[i];\n        dst[i] = (sum > UINT16_MAX) ? UINT16_MAX : (uint16_t)sum;\n    }\n}\n```"}
{"task_id": "SimdBench_17_SSE", "completion": "```c\nvoid saturating_add_simd(const uint16_t* src1, const uint16_t* src2, uint16_t* dst, size_t length) {\n    size_t i;\n    for (i = 0; i <= length - 8; i += 8) {\n        __m128i a = _mm_loadu_si128((__m128i*)&src1[i]);\n        __m128i b = _mm_loadu_si128((__m128i*)&src2[i]);\n        __m128i sum = _mm_adds_epu16(a, b);\n        _mm_storeu_si128((__m128i*)&dst[i], sum);\n    }\n    for (; i < length; ++i) {\n        uint32_t sum = (uint32_t)src1[i] + (uint32_t)src2[i];\n        dst[i] = (sum > UINT16_MAX) ? UINT16_MAX : (uint16_t)sum;\n    }\n}\n```"}
{"task_id": "SimdBench_17_SSE", "completion": "```cpp\nvoid saturating_add_simd(const uint16_t* src1, const uint16_t* src2, uint16_t* dst, size_t length) {\n    size_t i;\n    for (i = 0; i <= length - 8; i += 8) {\n        __m128i a = _mm_loadu_si128((__m128i*)&src1[i]);\n        __m128i b = _mm_loadu_si128((__m128i*)&src2[i]);\n        __m128i sum = _mm_adds_epu16(a, b);\n        _mm_storeu_si128((__m128i*)&dst[i], sum);\n    }\n    for (; i < length; ++i) {\n        uint32_t sum = (uint32_t)src1[i] + (uint32_t)src2[i];\n        dst[i] = (sum > UINT16_MAX) ? UINT16_MAX : (uint16_t)sum;\n    }\n}\n```"}
{"task_id": "SimdBench_18_SSE", "completion": "```cpp\nvoid range_matrix_mul_simd(const double* A, const double* B, double* C, size_t m, size_t n, size_t p) {\n    const double lower_bound = -100.0;\n    const double upper_bound = 100.0;\n    const __m128d lower_bound_vec = _mm_set1_pd(lower_bound);\n    const __m128d upper_bound_vec = _mm_set1_pd(upper_bound);\n\n    for (size_t i = 0; i < m; ++i) {\n        for (size_t j = 0; j < p; ++j) {\n            __m128d sum_vec = _mm_setzero_pd();\n            for (size_t k = 0; k < n; k += 2) {\n                __m128d a_vec = _mm_loadu_pd(&A[i * n + k]);\n                __m128d b_vec = _mm_loadu_pd(&B[k * p + j]);\n\n                __m128d mask_a = _mm_and_pd(_mm_cmpge_pd(a_vec, lower_bound_vec), _mm_cmple_pd(a_vec, upper_bound_vec));\n                __m128d mask_b = _mm_and_pd(_mm_cmpge_pd(b_vec, lower_bound_vec), _mm_cmple_pd(b_vec, upper_bound_vec));\n\n                __m128d masked_a = _mm_and_pd(a_vec, mask_a);\n                __m128d masked_b = _mm_and_pd(b_vec, mask_b);\n\n                sum_vec = _mm_add_pd(sum_vec, _mm_mul_pd(masked_a, masked_b));\n            }\n            double sum[2];\n            _mm_storeu_pd(sum, sum_vec);\n            C[i * p + j] = sum[0] + sum[1];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_18_SSE", "completion": "```cpp\nvoid range_matrix_mul_simd(const double* A, const double* B, double* C, size_t m, size_t n, size_t p) {\n    __m128d range_min = _mm_set1_pd(-100.0);\n    __m128d range_max = _mm_set1_pd(100.0);\n\n    for (size_t i = 0; i < m; ++i) {\n        for (size_t j = 0; j < p; ++j) {\n            __m128d c = _mm_setzero_pd();\n            for (size_t k = 0; k < n; k += 2) {\n                __m128d a = _mm_loadu_pd(&A[i * n + k]);\n                __m128d b = _mm_loadu_pd(&B[k * p + j]);\n\n                __m128d mask_a = _mm_and_pd(_mm_cmpge_pd(a, range_min), _mm_cmple_pd(a, range_max));\n                __m128d mask_b = _mm_and_pd(_mm_cmpge_pd(b, range_min), _mm_cmple_pd(b, range_max));\n\n                __m128d masked_a = _mm_and_pd(a, mask_a);\n                __m128d masked_b = _mm_and_pd(b, mask_b);\n\n                c = _mm_add_pd(c, _mm_mul_pd(masked_a, masked_b));\n            }\n            _mm_storeu_pd(&C[i * p + j], c);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_18_SSE", "completion": "```cpp\nvoid range_matrix_mul_simd(const double* A, const double* B, double* C, size_t m, size_t n, size_t p) {\n    __m128d range_min = _mm_set1_pd(-100.0);\n    __m128d range_max = _mm_set1_pd(100.0);\n\n    for (size_t i = 0; i < m; ++i) {\n        for (size_t j = 0; j < p; ++j) {\n            __m128d sum = _mm_setzero_pd();\n            for (size_t k = 0; k < n; k += 2) {\n                __m128d a = _mm_loadu_pd(&A[i * n + k]);\n                __m128d b = _mm_loadu_pd(&B[k * p + j]);\n\n                __m128d mask_a = _mm_and_pd(_mm_cmpge_pd(a, range_min), _mm_cmple_pd(a, range_max));\n                __m128d mask_b = _mm_and_pd(_mm_cmpge_pd(b, range_min), _mm_cmple_pd(b, range_max));\n\n                __m128d masked_a = _mm_and_pd(a, mask_a);\n                __m128d masked_b = _mm_and_pd(b, mask_b);\n\n                sum = _mm_add_pd(sum, _mm_mul_pd(masked_a, masked_b));\n            }\n            double temp[2];\n            _mm_storeu_pd(temp, sum);\n            C[i * p + j] = temp[0] + temp[1];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_18_SSE", "completion": "```cpp\nvoid range_matrix_mul_simd(const double* A, const double* B, double* C, size_t m, size_t n, size_t p) {\n    const double lower_bound = -100.0;\n    const double upper_bound = 100.0;\n    const __m128d lower_bound_vec = _mm_set1_pd(lower_bound);\n    const __m128d upper_bound_vec = _mm_set1_pd(upper_bound);\n\n    for (size_t i = 0; i < m; ++i) {\n        for (size_t j = 0; j < p; ++j) {\n            __m128d sum_vec = _mm_setzero_pd();\n            for (size_t k = 0; k < n; k += 2) {\n                __m128d a_vec = _mm_loadu_pd(&A[i * n + k]);\n                __m128d b_vec = _mm_loadu_pd(&B[k * p + j]);\n\n                __m128d mask_a = _mm_and_pd(\n                    _mm_cmpge_pd(a_vec, lower_bound_vec),\n                    _mm_cmple_pd(a_vec, upper_bound_vec)\n                );\n                __m128d mask_b = _mm_and_pd(\n                    _mm_cmpge_pd(b_vec, lower_bound_vec),\n                    _mm_cmple_pd(b_vec, upper_bound_vec)\n                );\n                __m128d mask = _mm_and_pd(mask_a, mask_b);\n\n                __m128d prod_vec = _mm_mul_pd(a_vec, b_vec);\n                prod_vec = _mm_and_pd(prod_vec, mask);\n\n                sum_vec = _mm_add_pd(sum_vec, prod_vec);\n            }\n            double sum[2];\n            _mm_storeu_pd(sum, sum_vec);\n            C[i * p + j] = sum[0] + sum[1];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_18_SSE", "completion": "```c\nvoid range_matrix_mul_simd(const double* A, const double* B, double* C, size_t m, size_t n, size_t p) {\n    __m128d lower_bound = _mm_set1_pd(-100.0);\n    __m128d upper_bound = _mm_set1_pd(100.0);\n\n    for (size_t i = 0; i < m; ++i) {\n        for (size_t j = 0; j < p; ++j) {\n            __m128d sum = _mm_setzero_pd();\n            for (size_t k = 0; k < n; k += 2) {\n                __m128d a = _mm_loadu_pd(&A[i * n + k]);\n                __m128d b = _mm_loadu_pd(&B[k * p + j]);\n\n                __m128d mask_a = _mm_and_pd(_mm_cmpge_pd(a, lower_bound), _mm_cmple_pd(a, upper_bound));\n                __m128d mask_b = _mm_and_pd(_mm_cmpge_pd(b, lower_bound), _mm_cmple_pd(b, upper_bound));\n\n                __m128d masked_a = _mm_and_pd(a, mask_a);\n                __m128d masked_b = _mm_and_pd(b, mask_b);\n\n                sum = _mm_add_pd(sum, _mm_mul_pd(masked_a, masked_b));\n            }\n            double temp[2];\n            _mm_storeu_pd(temp, sum);\n            C[i * p + j] = temp[0] + temp[1];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_19_SSE", "completion": "```cpp\nvoid tensor_add_3d_simd(const int64_t* A, const int64_t* B, int64_t* C, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t i;\n\n    for (i = 0; i <= total_elements - 2; i += 2) {\n        __m128i a = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i b = _mm_loadu_si128((__m128i*)&B[i]);\n        __m128i c = _mm_add_epi64(a, b);\n        _mm_storeu_si128((__m128i*)&C[i], c);\n    }\n\n    for (; i < total_elements; ++i) {\n        C[i] = A[i] + B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_19_SSE", "completion": "```c\nvoid tensor_add_3d_simd(const int64_t* A, const int64_t* B, int64_t* C, size_t dim1, size_t dim2, size_t dim3) {\n    size_t size = dim1 * dim2 * dim3;\n    size_t i;\n\n    for (i = 0; i <= size - 2; i += 2) {\n        __m128i a = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i b = _mm_loadu_si128((__m128i*)&B[i]);\n        __m128i c = _mm_add_epi64(a, b);\n        _mm_storeu_si128((__m128i*)&C[i], c);\n    }\n\n    if (i < size) {\n        C[i] = A[i] + B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_19_SSE", "completion": "```cpp\nvoid tensor_add_3d_simd(const int64_t* A, const int64_t* B, int64_t* C, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t i;\n\n    for (i = 0; i <= total_elements - 2; i += 2) {\n        __m128i a = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i b = _mm_loadu_si128((__m128i*)&B[i]);\n        __m128i c = _mm_add_epi64(a, b);\n        _mm_storeu_si128((__m128i*)&C[i], c);\n    }\n\n    for (; i < total_elements; ++i) {\n        C[i] = A[i] + B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_19_SSE", "completion": "```cpp\nvoid tensor_add_3d_simd(const int64_t* A, const int64_t* B, int64_t* C, size_t dim1, size_t dim2, size_t dim3) {\n    size_t size = dim1 * dim2 * dim3;\n    size_t i;\n\n    for (i = 0; i <= size - 2; i += 2) {\n        __m128i a = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i b = _mm_loadu_si128((__m128i*)&B[i]);\n        __m128i c = _mm_add_epi64(a, b);\n        _mm_storeu_si128((__m128i*)&C[i], c);\n    }\n\n    for (; i < size; ++i) {\n        C[i] = A[i] + B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_19_SSE", "completion": "```cpp\nvoid tensor_add_3d_simd(const int64_t* A, const int64_t* B, int64_t* C, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t i;\n\n    for (i = 0; i <= total_elements - 2; i += 2) {\n        __m128i a = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i b = _mm_loadu_si128((__m128i*)&B[i]);\n        __m128i c = _mm_add_epi64(a, b);\n        _mm_storeu_si128((__m128i*)&C[i], c);\n    }\n\n    for (; i < total_elements; ++i) {\n        C[i] = A[i] + B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_20_SSE", "completion": "```c\nvoid vector_add_round_nearest_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    size_t i;\n    for (i = 0; i <= length - 4; i += 4) {\n        __m128 a = _mm_loadu_ps(&src1[i]);\n        __m128 b = _mm_loadu_ps(&src2[i]);\n        __m128 sum = _mm_add_ps(a, b);\n        __m128 rounded = _mm_round_ps(sum, _MM_FROUND_TO_NEAREST_INT);\n        _mm_storeu_ps(&dst[i], rounded);\n    }\n    for (; i < length; ++i) {\n        dst[i] = roundf(src1[i] + src2[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_20_SSE", "completion": "```c\nvoid vector_add_round_nearest_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    size_t i;\n    for (i = 0; i <= length - 4; i += 4) {\n        __m128 a = _mm_loadu_ps(&src1[i]);\n        __m128 b = _mm_loadu_ps(&src2[i]);\n        __m128 sum = _mm_add_ps(a, b);\n        __m128 rounded = _mm_round_ps(sum, _MM_FROUND_TO_NEAREST_INT);\n        _mm_storeu_ps(&dst[i], rounded);\n    }\n    for (; i < length; ++i) {\n        dst[i] = roundf(src1[i] + src2[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_20_SSE", "completion": "```c\nvoid vector_add_round_nearest_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    size_t i;\n    for (i = 0; i <= length - 4; i += 4) {\n        __m128 a = _mm_loadu_ps(&src1[i]);\n        __m128 b = _mm_loadu_ps(&src2[i]);\n        __m128 sum = _mm_add_ps(a, b);\n        __m128 rounded = _mm_round_ps(sum, _MM_FROUND_TO_NEAREST_INT);\n        _mm_storeu_ps(&dst[i], rounded);\n    }\n    for (; i < length; ++i) {\n        dst[i] = roundf(src1[i] + src2[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_20_SSE", "completion": "```c\nvoid vector_add_round_nearest_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    size_t i;\n    for (i = 0; i <= length - 4; i += 4) {\n        __m128 a = _mm_loadu_ps(&src1[i]);\n        __m128 b = _mm_loadu_ps(&src2[i]);\n        __m128 sum = _mm_add_ps(a, b);\n        __m128 rounded = _mm_round_ps(sum, _MM_FROUND_TO_NEAREST_INT);\n        _mm_storeu_ps(&dst[i], rounded);\n    }\n    for (; i < length; ++i) {\n        dst[i] = roundf(src1[i] + src2[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_20_SSE", "completion": "```cpp\nvoid vector_add_round_nearest_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    size_t i;\n    for (i = 0; i <= length - 4; i += 4) {\n        __m128 a = _mm_loadu_ps(&src1[i]);\n        __m128 b = _mm_loadu_ps(&src2[i]);\n        __m128 sum = _mm_add_ps(a, b);\n        __m128 rounded = _mm_round_ps(sum, _MM_FROUND_TO_NEAREST_INT);\n        _mm_storeu_ps(&dst[i], rounded);\n    }\n    for (; i < length; ++i) {\n        dst[i] = roundf(src1[i] + src2[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_21_SSE", "completion": "```c\nvoid vector_mul_round_up_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    __m128 threshold = _mm_set1_ps(50.0f);\n    __m128 neg_one = _mm_set1_ps(-1.0f);\n    __m128i mask = _mm_set_epi32(0, -1, 0, -1);\n\n    for (size_t i = 0; i < length; i += 4) {\n        __m128 v1 = _mm_loadu_ps(&src1[i]);\n        __m128 v2 = _mm_loadu_ps(&src2[i]);\n\n        __m128 diff = _mm_sub_ps(v1, v2);\n        __m128 abs_diff = _mm_andnot_ps(_mm_set1_ps(-0.0f), diff);\n        __m128 cmp = _mm_cmple_ps(abs_diff, threshold);\n\n        __m128 mul = _mm_mul_ps(v1, v2);\n        __m128 rounded = _mm_ceil_ps(mul);\n\n        __m128i cmp_i = _mm_castps_si128(cmp);\n        cmp_i = _mm_and_si128(cmp_i, mask);\n        __m128 cmp_f = _mm_castsi128_ps(cmp_i);\n\n        __m128 result = _mm_blendv_ps(neg_one, rounded, cmp_f);\n\n        _mm_storeu_ps(&dst[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_21_SSE", "completion": "```c\nvoid vector_mul_round_up_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    __m128 threshold = _mm_set1_ps(50.0f);\n    __m128 neg_one = _mm_set1_ps(-1.0f);\n    __m128i index_mask = _mm_set_epi32(0, -1, 0, -1);\n\n    for (size_t i = 0; i < length; i += 4) {\n        __m128 v1 = _mm_loadu_ps(&src1[i]);\n        __m128 v2 = _mm_loadu_ps(&src2[i]);\n\n        __m128 diff = _mm_sub_ps(v1, v2);\n        __m128 abs_diff = _mm_andnot_ps(_mm_set1_ps(-0.0f), diff);\n        __m128 mask = _mm_cmple_ps(abs_diff, threshold);\n\n        __m128i index = _mm_set_epi32(i + 3, i + 2, i + 1, i);\n        __m128i index_masked = _mm_and_si128(index, index_mask);\n        __m128i zero = _mm_setzero_si128();\n        __m128i index_valid = _mm_cmpeq_epi32(index_masked, zero);\n\n        __m128 mask_final = _mm_and_ps(mask, _mm_castsi128_ps(index_valid));\n\n        __m128 result = _mm_mul_ps(v1, v2);\n        result = _mm_ceil_ps(result);\n        result = _mm_blendv_ps(neg_one, result, mask_final);\n\n        _mm_storeu_ps(&dst[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_21_SSE", "completion": "```c\nvoid vector_mul_round_up_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    __m128 threshold = _mm_set1_ps(50.0f);\n    __m128 neg_one = _mm_set1_ps(-1.0f);\n    __m128i index_mask = _mm_set_epi32(0, -1, 0, -1);\n\n    for (size_t i = 0; i < length; i += 4) {\n        __m128 v1 = _mm_loadu_ps(&src1[i]);\n        __m128 v2 = _mm_loadu_ps(&src2[i]);\n\n        __m128 diff = _mm_sub_ps(v1, v2);\n        __m128 abs_diff = _mm_andnot_ps(_mm_set1_ps(-0.0f), diff);\n        __m128 mask = _mm_cmple_ps(abs_diff, threshold);\n\n        __m128i index = _mm_set_epi32(i + 3, i + 2, i + 1, i);\n        __m128i index_masked = _mm_and_si128(index, index_mask);\n        __m128i zero = _mm_setzero_si128();\n        __m128i index_valid = _mm_cmpeq_epi32(index_masked, zero);\n\n        __m128 mask_final = _mm_and_ps(mask, _mm_castsi128_ps(index_valid));\n\n        __m128 result = _mm_mul_ps(v1, v2);\n        result = _mm_round_ps(result, _MM_FROUND_TO_POS_INF);\n\n        __m128 final_result = _mm_blendv_ps(neg_one, result, mask_final);\n\n        _mm_storeu_ps(&dst[i], final_result);\n    }\n}\n```"}
{"task_id": "SimdBench_21_SSE", "completion": "```c\nvoid vector_mul_round_up_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    __m128 threshold = _mm_set1_ps(50.0f);\n    __m128 neg_one = _mm_set1_ps(-1.0f);\n    __m128i mask = _mm_set_epi32(0, -1, 0, -1);\n\n    for (size_t i = 0; i < length; i += 4) {\n        __m128 a = _mm_loadu_ps(&src1[i]);\n        __m128 b = _mm_loadu_ps(&src2[i]);\n\n        __m128 diff = _mm_sub_ps(a, b);\n        diff = _mm_and_ps(diff, mask);\n        __m128 abs_diff = _mm_andnot_ps(_mm_set1_ps(-0.0f), diff);\n        __m128 cmp = _mm_cmple_ps(abs_diff, threshold);\n\n        __m128 mul = _mm_mul_ps(a, b);\n        __m128 rounded = _mm_ceil_ps(mul);\n\n        __m128 result = _mm_blendv_ps(neg_one, rounded, cmp);\n\n        _mm_storeu_ps(&dst[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_21_SSE", "completion": "```c\nvoid vector_mul_round_up_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    __m128 threshold = _mm_set1_ps(50.0f);\n    __m128 neg_one = _mm_set1_ps(-1.0f);\n    __m128i index_mask = _mm_set_epi32(0, -1, 0, -1);\n\n    for (size_t i = 0; i < length; i += 4) {\n        __m128 v1 = _mm_loadu_ps(&src1[i]);\n        __m128 v2 = _mm_loadu_ps(&src2[i]);\n\n        __m128 diff = _mm_sub_ps(v1, v2);\n        __m128 abs_diff = _mm_andnot_ps(_mm_set1_ps(-0.0f), diff);\n        __m128 mask = _mm_cmplt_ps(abs_diff, threshold);\n\n        __m128i index = _mm_set1_epi32(i);\n        __m128i index_masked = _mm_and_si128(index, index_mask);\n        __m128i zero = _mm_setzero_si128();\n        __m128i even_mask = _mm_cmpeq_epi32(index_masked, zero);\n\n        __m128 even_mask_f = _mm_castsi128_ps(even_mask);\n        mask = _mm_and_ps(mask, even_mask_f);\n\n        __m128 result = _mm_mul_ps(v1, v2);\n        result = _mm_ceil_ps(result);\n        result = _mm_blendv_ps(neg_one, result, mask);\n\n        _mm_storeu_ps(&dst[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_22_SSE", "completion": "```cpp\nvoid matrix_scalar_mul_simd(const double* mat, double scalar, double* dst, size_t m, size_t n) {\n    size_t size = m * n;\n    __m128d scalar_vec = _mm_set1_pd(scalar);\n\n    for (size_t i = 0; i < size; i += 2) {\n        __m128d mat_vec = _mm_loadu_pd(&mat[i]);\n        __m128d result_vec = _mm_mul_pd(mat_vec, scalar_vec);\n        _mm_storeu_pd(&dst[i], result_vec);\n    }\n}\n```"}
{"task_id": "SimdBench_22_SSE", "completion": "```c\nvoid matrix_scalar_mul_simd(const double* mat, double scalar, double* dst, size_t m, size_t n) {\n    size_t size = m * n;\n    __m128d scalar_vec = _mm_set1_pd(scalar);\n\n    for (size_t i = 0; i < size; i += 2) {\n        __m128d mat_vec = _mm_loadu_pd(&mat[i]);\n        __m128d result_vec = _mm_mul_pd(mat_vec, scalar_vec);\n        _mm_storeu_pd(&dst[i], result_vec);\n    }\n}\n```"}
{"task_id": "SimdBench_22_SSE", "completion": "```cpp\nvoid matrix_scalar_mul_simd(const double* mat, double scalar, double* dst, size_t m, size_t n) {\n    size_t size = m * n;\n    __m128d scalar_vec = _mm_set1_pd(scalar);\n\n    for (size_t i = 0; i < size; i += 2) {\n        __m128d mat_vec = _mm_loadu_pd(&mat[i]);\n        __m128d result_vec = _mm_mul_pd(mat_vec, scalar_vec);\n        _mm_storeu_pd(&dst[i], result_vec);\n    }\n}\n```"}
{"task_id": "SimdBench_22_SSE", "completion": "```cpp\nvoid matrix_scalar_mul_simd(const double* mat, double scalar, double* dst, size_t m, size_t n) {\n    size_t size = m * n;\n    __m128d scalar_vec = _mm_set1_pd(scalar);\n\n    for (size_t i = 0; i < size; i += 2) {\n        __m128d mat_vec = _mm_loadu_pd(&mat[i]);\n        __m128d result_vec = _mm_mul_pd(mat_vec, scalar_vec);\n        _mm_storeu_pd(&dst[i], result_vec);\n    }\n}\n```"}
{"task_id": "SimdBench_22_SSE", "completion": "```cpp\nvoid matrix_scalar_mul_simd(const double* mat, double scalar, double* dst, size_t m, size_t n) {\n    size_t size = m * n;\n    __m128d scalar_vec = _mm_set1_pd(scalar);\n\n    for (size_t i = 0; i < size; i += 2) {\n        __m128d mat_vec = _mm_loadu_pd(&mat[i]);\n        __m128d result_vec = _mm_mul_pd(mat_vec, scalar_vec);\n        _mm_storeu_pd(&dst[i], result_vec);\n    }\n}\n```"}
{"task_id": "SimdBench_23_SSE", "completion": "```c\nvoid matrix_normalize_rows_simd(float* mat, size_t m, size_t n) {\n    for (size_t i = 0; i < m; ++i) {\n        float* row = mat + i * n;\n        __m128 sum_squares = _mm_setzero_ps();\n        for (size_t j = 0; j < n; j += 4) {\n            __m128 vec = _mm_loadu_ps(row + j);\n            sum_squares = _mm_add_ps(sum_squares, _mm_mul_ps(vec, vec));\n        }\n        float row_sum[4];\n        _mm_storeu_ps(row_sum, sum_squares);\n        float norm = sqrt(row_sum[0] + row_sum[1] + row_sum[2] + row_sum[3]);\n        __m128 inv_norm = _mm_set1_ps(1.0f / norm);\n        for (size_t j = 0; j < n; j += 4) {\n            __m128 vec = _mm_loadu_ps(row + j);\n            vec = _mm_mul_ps(vec, inv_norm);\n            _mm_storeu_ps(row + j, vec);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_23_SSE", "completion": "```c\nvoid matrix_normalize_rows_simd(float* mat, size_t m, size_t n) {\n    for (size_t i = 0; i < m; ++i) {\n        float* row = mat + i * n;\n        __m128 sum_squares = _mm_setzero_ps();\n\n        for (size_t j = 0; j < n; j += 4) {\n            __m128 vec = _mm_loadu_ps(row + j);\n            sum_squares = _mm_add_ps(sum_squares, _mm_mul_ps(vec, vec));\n        }\n\n        float temp[4];\n        _mm_storeu_ps(temp, sum_squares);\n        float norm = sqrt(temp[0] + temp[1] + temp[2] + temp[3]);\n\n        __m128 norm_vec = _mm_set1_ps(norm);\n        for (size_t j = 0; j < n; j += 4) {\n            __m128 vec = _mm_loadu_ps(row + j);\n            vec = _mm_div_ps(vec, norm_vec);\n            _mm_storeu_ps(row + j, vec);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_23_SSE", "completion": "```cpp\nvoid matrix_normalize_rows_simd(float* mat, size_t m, size_t n) {\n    for (size_t i = 0; i < m; ++i) {\n        __m128 sum = _mm_setzero_ps();\n        for (size_t j = 0; j < n; j += 4) {\n            __m128 row = _mm_loadu_ps(&mat[i * n + j]);\n            sum = _mm_add_ps(sum, _mm_mul_ps(row, row));\n        }\n        float temp[4];\n        _mm_storeu_ps(temp, sum);\n        float norm = temp[0] + temp[1] + temp[2] + temp[3];\n        for (size_t k = 4; k < n; k++) {\n            norm += mat[i * n + k] * mat[i * n + k];\n        }\n        norm = sqrt(norm);\n        __m128 inv_norm = _mm_set1_ps(1.0f / norm);\n        for (size_t j = 0; j < n; j += 4) {\n            __m128 row = _mm_loadu_ps(&mat[i * n + j]);\n            row = _mm_mul_ps(row, inv_norm);\n            _mm_storeu_ps(&mat[i * n + j], row);\n        }\n        for (size_t k = n / 4 * 4; k < n; k++) {\n            mat[i * n + k] /= norm;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_23_SSE", "completion": "```c\nvoid matrix_normalize_rows_simd(float* mat, size_t m, size_t n) {\n    for (size_t i = 0; i < m; ++i) {\n        float* row = mat + i * n;\n        __m128 sum_squares = _mm_setzero_ps();\n        for (size_t j = 0; j < n; j += 4) {\n            __m128 vec = _mm_loadu_ps(row + j);\n            sum_squares = _mm_add_ps(sum_squares, _mm_mul_ps(vec, vec));\n        }\n        float temp[4];\n        _mm_storeu_ps(temp, sum_squares);\n        float norm = sqrt(temp[0] + temp[1] + temp[2] + temp[3]);\n        __m128 norm_vec = _mm_set1_ps(norm);\n        for (size_t j = 0; j < n; j += 4) {\n            __m128 vec = _mm_loadu_ps(row + j);\n            vec = _mm_div_ps(vec, norm_vec);\n            _mm_storeu_ps(row + j, vec);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_23_SSE", "completion": "```c\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <math.h>\n\nvoid matrix_normalize_rows_simd(float* mat, size_t m, size_t n) {\n    for (size_t i = 0; i < m; ++i) {\n        float* row = mat + i * n;\n        __m128 sum_squares = _mm_setzero_ps();\n\n        for (size_t j = 0; j < n; j += 4) {\n            __m128 vec = _mm_loadu_ps(row + j);\n            sum_squares = _mm_add_ps(sum_squares, _mm_mul_ps(vec, vec));\n        }\n\n        float temp[4];\n        _mm_storeu_ps(temp, sum_squares);\n        float l2_norm = sqrt(temp[0] + temp[1] + temp[2] + temp[3]);\n\n        __m128 norm_vec = _mm_set1_ps(l2_norm);\n\n        for (size_t j = 0; j < n; j += 4) {\n            __m128 vec = _mm_loadu_ps(row + j);\n            vec = _mm_div_ps(vec, norm_vec);\n            _mm_storeu_ps(row + j, vec);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_24_SSE", "completion": "```c\nvoid matrix_mul_round_int_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n, size_t p) {\n    for (size_t i = 0; i < m; ++i) {\n        for (size_t j = 0; j < p; ++j) {\n            __m128d sum = _mm_setzero_pd();\n            for (size_t k = 0; k < n; k += 2) {\n                __m128d a = _mm_loadu_pd(&mat1[i * n + k]);\n                __m128d b = _mm_loadu_pd(&mat2[k * p + j]);\n                sum = _mm_add_pd(sum, _mm_mul_pd(a, b));\n            }\n            sum = _mm_hadd_pd(sum, sum);\n            _mm_store_sd(&dst[i * p + j], sum);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_24_SSE", "completion": "```c\nvoid matrix_mul_round_int_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n, size_t p) {\n    for (size_t i = 0; i < m; ++i) {\n        for (size_t j = 0; j < p; ++j) {\n            __m128d sum = _mm_setzero_pd();\n            for (size_t k = 0; k < n; k += 2) {\n                __m128d a = _mm_loadu_pd(&mat1[i * n + k]);\n                __m128d b = _mm_loadu_pd(&mat2[k * p + j]);\n                sum = _mm_add_pd(sum, _mm_mul_pd(a, b));\n            }\n            sum = _mm_hadd_pd(sum, sum);\n            _mm_store_sd(&dst[i * p + j], _mm_round_sd(_mm_setzero_pd(), sum, _MM_FROUND_TO_NEAREST_INT));\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_24_SSE", "completion": "```cpp\nvoid matrix_mul_round_int_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n, size_t p) {\n    for (size_t i = 0; i < m; ++i) {\n        for (size_t j = 0; j < p; ++j) {\n            __m128d sum = _mm_setzero_pd();\n            for (size_t k = 0; k < n; k += 2) {\n                __m128d a = _mm_loadu_pd(&mat1[i * n + k]);\n                __m128d b = _mm_loadu_pd(&mat2[k * p + j]);\n                sum = _mm_add_pd(sum, _mm_mul_pd(a, b));\n            }\n            sum = _mm_hadd_pd(sum, sum);\n            sum = _mm_cvtpd_epi32(sum);\n            sum = _mm_cvtepi32_pd(sum);\n            _mm_storeu_pd(&dst[i * p + j], sum);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_24_SSE", "completion": "```c\nvoid matrix_mul_round_int_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n, size_t p) {\n    for (size_t i = 0; i < m; ++i) {\n        for (size_t j = 0; j < p; ++j) {\n            __m128d sum = _mm_setzero_pd();\n            for (size_t k = 0; k < n; k += 2) {\n                __m128d a = _mm_loadu_pd(&mat1[i * n + k]);\n                __m128d b = _mm_loadu_pd(&mat2[k * p + j]);\n                sum = _mm_add_pd(sum, _mm_mul_pd(a, b));\n            }\n            sum = _mm_hadd_pd(sum, sum);\n            sum = _mm_round_pd(sum, _MM_FROUND_TO_NEAREST_INT);\n            _mm_store_sd(&dst[i * p + j], sum);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_24_SSE", "completion": "```c\nvoid matrix_mul_round_int_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n, size_t p) {\n    for (size_t i = 0; i < m; ++i) {\n        for (size_t j = 0; j < p; ++j) {\n            __m128d sum = _mm_setzero_pd();\n            for (size_t k = 0; k < n; k += 2) {\n                __m128d a = _mm_loadu_pd(&mat1[i * n + k]);\n                __m128d b = _mm_loadu_pd(&mat2[k * p + j]);\n                sum = _mm_add_pd(sum, _mm_mul_pd(a, b));\n            }\n            sum = _mm_hadd_pd(sum, sum);\n            sum = _mm_round_pd(sum, _MM_FROUND_TO_NEAREST_INT);\n            _mm_store_sd(&dst[i * p + j], sum);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_25_SSE", "completion": "```c\nvoid matrix_transpose_round_quarter_simd(const float* src, float* dst, size_t rows, size_t cols) {\n    __m128 quarter = _mm_set1_ps(0.25f);\n    __m128 rounder = _mm_set1_ps(0.5f);\n\n    for (size_t i = 0; i < rows; i += 4) {\n        for (size_t j = 0; j < cols; j += 4) {\n            __m128 row0 = _mm_loadu_ps(&src[i * cols + j]);\n            __m128 row1 = _mm_loadu_ps(&src[(i + 1) * cols + j]);\n            __m128 row2 = _mm_loadu_ps(&src[(i + 2) * cols + j]);\n            __m128 row3 = _mm_loadu_ps(&src[(i + 3) * cols + j]);\n\n            __m128 t0 = _mm_unpacklo_ps(row0, row1);\n            __m128 t1 = _mm_unpackhi_ps(row0, row1);\n            __m128 t2 = _mm_unpacklo_ps(row2, row3);\n            __m128 t3 = _mm_unpackhi_ps(row2, row3);\n\n            row0 = _mm_movelh_ps(t0, t2);\n            row1 = _mm_movehl_ps(t2, t0);\n            row2 = _mm_movelh_ps(t1, t3);\n            row3 = _mm_movehl_ps(t3, t1);\n\n            row0 = _mm_add_ps(row0, rounder);\n            row1 = _mm_add_ps(row1, rounder);\n            row2 = _mm_add_ps(row2, rounder);\n            row3 = _mm_add_ps(row3, rounder);\n\n            row0 = _mm_mul_ps(row0, quarter);\n            row1 = _mm_mul_ps(row1, quarter);\n            row2 = _mm_mul_ps(row2, quarter);\n            row3 = _mm_mul_ps(row3, quarter);\n\n            row0 = _mm_floor_ps(row0);\n            row1 = _mm_floor_ps(row1);\n            row2 = _mm_floor_ps(row2);\n            row3 = _mm_floor_ps(row3);\n\n            row0 = _mm_mul_ps(row0, quarter);\n            row1 = _mm_mul_ps(row1, quarter);\n            row2 = _mm_mul_ps(row2, quarter);\n            row3 = _mm_mul_ps(row3, quarter);\n\n            _mm_storeu_ps(&dst[j * rows + i], row0);\n            _mm_storeu_ps(&dst[(j + 1) * rows + i], row1);\n            _mm_storeu_ps(&dst[(j + 2) * rows + i], row2);\n            _mm_storeu_ps(&dst[(j + 3) * rows + i], row3);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_25_SSE", "completion": "```cpp\nvoid matrix_transpose_round_quarter_simd(const float* src, float* dst, size_t rows, size_t cols) {\n    const __m128 quarter = _mm_set1_ps(0.25f);\n    const __m128 rounder = _mm_set1_ps(0.5f);\n\n    for (size_t i = 0; i < rows; i += 4) {\n        for (size_t j = 0; j < cols; j += 4) {\n            __m128 row0 = _mm_loadu_ps(&src[i * cols + j]);\n            __m128 row1 = _mm_loadu_ps(&src[(i + 1) * cols + j]);\n            __m128 row2 = _mm_loadu_ps(&src[(i + 2) * cols + j]);\n            __m128 row3 = _mm_loadu_ps(&src[(i + 3) * cols + j]);\n\n            __m128 t0 = _mm_unpacklo_ps(row0, row1);\n            __m128 t1 = _mm_unpackhi_ps(row0, row1);\n            __m128 t2 = _mm_unpacklo_ps(row2, row3);\n            __m128 t3 = _mm_unpackhi_ps(row2, row3);\n\n            row0 = _mm_shuffle_ps(t0, t2, _MM_SHUFFLE(1, 0, 1, 0));\n            row1 = _mm_shuffle_ps(t0, t2, _MM_SHUFFLE(3, 2, 3, 2));\n            row2 = _mm_shuffle_ps(t1, t3, _MM_SHUFFLE(1, 0, 1, 0));\n            row3 = _mm_shuffle_ps(t1, t3, _MM_SHUFFLE(3, 2, 3, 2));\n\n            row0 = _mm_add_ps(row0, rounder);\n            row1 = _mm_add_ps(row1, rounder);\n            row2 = _mm_add_ps(row2, rounder);\n            row3 = _mm_add_ps(row3, rounder);\n\n            row0 = _mm_mul_ps(row0, quarter);\n            row1 = _mm_mul_ps(row1, quarter);\n            row2 = _mm_mul_ps(row2, quarter);\n            row3 = _mm_mul_ps(row3, quarter);\n\n            row0 = _mm_floor_ps(row0);\n            row1 = _mm_floor_ps(row1);\n            row2 = _mm_floor_ps(row2);\n            row3 = _mm_floor_ps(row3);\n\n            row0 = _mm_mul_ps(row0, quarter);\n            row1 = _mm_mul_ps(row1, quarter);\n            row2 = _mm_mul_ps(row2, quarter);\n            row3 = _mm_mul_ps(row3, quarter);\n\n            _mm_storeu_ps(&dst[j * rows + i], row0);\n            _mm_storeu_ps(&dst[(j + 1) * rows + i], row1);\n            _mm_storeu_ps(&dst[(j + 2) * rows + i], row2);\n            _mm_storeu_ps(&dst[(j + 3) * rows + i], row3);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_25_SSE", "completion": "```c\nvoid matrix_transpose_round_quarter_simd(const float* src, float* dst, size_t rows, size_t cols) {\n    __m128 quarter = _mm_set1_ps(0.25f);\n    __m128 rounder = _mm_set1_ps(0.5f);\n\n    for (size_t i = 0; i < rows; i += 4) {\n        for (size_t j = 0; j < cols; j += 4) {\n            __m128 row0 = _mm_loadu_ps(&src[i * cols + j]);\n            __m128 row1 = _mm_loadu_ps(&src[(i + 1) * cols + j]);\n            __m128 row2 = _mm_loadu_ps(&src[(i + 2) * cols + j]);\n            __m128 row3 = _mm_loadu_ps(&src[(i + 3) * cols + j]);\n\n            __m128 t0 = _mm_unpacklo_ps(row0, row1);\n            __m128 t1 = _mm_unpackhi_ps(row0, row1);\n            __m128 t2 = _mm_unpacklo_ps(row2, row3);\n            __m128 t3 = _mm_unpackhi_ps(row2, row3);\n\n            row0 = _mm_shuffle_ps(t0, t2, _MM_SHUFFLE(1, 0, 1, 0));\n            row1 = _mm_shuffle_ps(t0, t2, _MM_SHUFFLE(3, 2, 3, 2));\n            row2 = _mm_shuffle_ps(t1, t3, _MM_SHUFFLE(1, 0, 1, 0));\n            row3 = _mm_shuffle_ps(t1, t3, _MM_SHUFFLE(3, 2, 3, 2));\n\n            row0 = _mm_add_ps(row0, rounder);\n            row1 = _mm_add_ps(row1, rounder);\n            row2 = _mm_add_ps(row2, rounder);\n            row3 = _mm_add_ps(row3, rounder);\n\n            row0 = _mm_mul_ps(row0, quarter);\n            row1 = _mm_mul_ps(row1, quarter);\n            row2 = _mm_mul_ps(row2, quarter);\n            row3 = _mm_mul_ps(row3, quarter);\n\n            row0 = _mm_floor_ps(row0);\n            row1 = _mm_floor_ps(row1);\n            row2 = _mm_floor_ps(row2);\n            row3 = _mm_floor_ps(row3);\n\n            row0 = _mm_mul_ps(row0, quarter);\n            row1 = _mm_mul_ps(row1, quarter);\n            row2 = _mm_mul_ps(row2, quarter);\n            row3 = _mm_mul_ps(row3, quarter);\n\n            _mm_storeu_ps(&dst[j * rows + i], row0);\n            _mm_storeu_ps(&dst[(j + 1) * rows + i], row1);\n            _mm_storeu_ps(&dst[(j + 2) * rows + i], row2);\n            _mm_storeu_ps(&dst[(j + 3) * rows + i], row3);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_25_SSE", "completion": "```c\nvoid matrix_transpose_round_quarter_simd(const float* src, float* dst, size_t rows, size_t cols) {\n    __m128 quarter = _mm_set1_ps(0.25f);\n    __m128 rounder = _mm_set1_ps(0.5f);\n\n    for (size_t i = 0; i < rows; i += 4) {\n        for (size_t j = 0; j < cols; j += 4) {\n            __m128 row0 = _mm_loadu_ps(&src[i * cols + j]);\n            __m128 row1 = _mm_loadu_ps(&src[(i + 1) * cols + j]);\n            __m128 row2 = _mm_loadu_ps(&src[(i + 2) * cols + j]);\n            __m128 row3 = _mm_loadu_ps(&src[(i + 3) * cols + j]);\n\n            __m128 t0 = _mm_unpacklo_ps(row0, row1);\n            __m128 t1 = _mm_unpackhi_ps(row0, row1);\n            __m128 t2 = _mm_unpacklo_ps(row2, row3);\n            __m128 t3 = _mm_unpackhi_ps(row2, row3);\n\n            row0 = _mm_movelh_ps(t0, t2);\n            row1 = _mm_movehl_ps(t2, t0);\n            row2 = _mm_movelh_ps(t1, t3);\n            row3 = _mm_movehl_ps(t3, t1);\n\n            row0 = _mm_add_ps(row0, rounder);\n            row1 = _mm_add_ps(row1, rounder);\n            row2 = _mm_add_ps(row2, rounder);\n            row3 = _mm_add_ps(row3, rounder);\n\n            row0 = _mm_mul_ps(row0, quarter);\n            row1 = _mm_mul_ps(row1, quarter);\n            row2 = _mm_mul_ps(row2, quarter);\n            row3 = _mm_mul_ps(row3, quarter);\n\n            row0 = _mm_floor_ps(row0);\n            row1 = _mm_floor_ps(row1);\n            row2 = _mm_floor_ps(row2);\n            row3 = _mm_floor_ps(row3);\n\n            row0 = _mm_mul_ps(row0, quarter);\n            row1 = _mm_mul_ps(row1, quarter);\n            row2 = _mm_mul_ps(row2, quarter);\n            row3 = _mm_mul_ps(row3, quarter);\n\n            _mm_storeu_ps(&dst[j * rows + i], row0);\n            _mm_storeu_ps(&dst[(j + 1) * rows + i], row1);\n            _mm_storeu_ps(&dst[(j + 2) * rows + i], row2);\n            _mm_storeu_ps(&dst[(j + 3) * rows + i], row3);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_25_SSE", "completion": "```c\nvoid matrix_transpose_round_quarter_simd(const float* src, float* dst, size_t rows, size_t cols) {\n    __m128 quarter = _mm_set1_ps(0.25f);\n    __m128 rounder = _mm_set1_ps(0.5f);\n\n    for (size_t i = 0; i < rows; i += 4) {\n        for (size_t j = 0; j < cols; j += 4) {\n            __m128 row0 = _mm_loadu_ps(&src[i * cols + j]);\n            __m128 row1 = _mm_loadu_ps(&src[(i + 1) * cols + j]);\n            __m128 row2 = _mm_loadu_ps(&src[(i + 2) * cols + j]);\n            __m128 row3 = _mm_loadu_ps(&src[(i + 3) * cols + j]);\n\n            __m128 t0 = _mm_unpacklo_ps(row0, row1);\n            __m128 t1 = _mm_unpackhi_ps(row0, row1);\n            __m128 t2 = _mm_unpacklo_ps(row2, row3);\n            __m128 t3 = _mm_unpackhi_ps(row2, row3);\n\n            row0 = _mm_shuffle_ps(t0, t2, _MM_SHUFFLE(1, 0, 1, 0));\n            row1 = _mm_shuffle_ps(t0, t2, _MM_SHUFFLE(3, 2, 3, 2));\n            row2 = _mm_shuffle_ps(t1, t3, _MM_SHUFFLE(1, 0, 1, 0));\n            row3 = _mm_shuffle_ps(t1, t3, _MM_SHUFFLE(3, 2, 3, 2));\n\n            row0 = _mm_add_ps(row0, rounder);\n            row1 = _mm_add_ps(row1, rounder);\n            row2 = _mm_add_ps(row2, rounder);\n            row3 = _mm_add_ps(row3, rounder);\n\n            row0 = _mm_mul_ps(row0, quarter);\n            row1 = _mm_mul_ps(row1, quarter);\n            row2 = _mm_mul_ps(row2, quarter);\n            row3 = _mm_mul_ps(row3, quarter);\n\n            row0 = _mm_floor_ps(row0);\n            row1 = _mm_floor_ps(row1);\n            row2 = _mm_floor_ps(row2);\n            row3 = _mm_floor_ps(row3);\n\n            row0 = _mm_mul_ps(row0, quarter);\n            row1 = _mm_mul_ps(row1, quarter);\n            row2 = _mm_mul_ps(row2, quarter);\n            row3 = _mm_mul_ps(row3, quarter);\n\n            _mm_storeu_ps(&dst[j * rows + i], row0);\n            _mm_storeu_ps(&dst[(j + 1) * rows + i], row1);\n            _mm_storeu_ps(&dst[(j + 2) * rows + i], row2);\n            _mm_storeu_ps(&dst[(j + 3) * rows + i], row3);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_26_SSE", "completion": "```cpp\nvoid tensor3d_sub_round_zero_simd(const float* tensor1, const float* tensor2, float* dst, size_t dim1, size_t dim2, size_t dim3) {\n    size_t size = dim1 * dim2 * dim3;\n    size_t i = 0;\n\n    __m128 sign_mask = _mm_set1_ps(-0.0f);\n\n    for (; i <= size - 4; i += 4) {\n        __m128 v1 = _mm_loadu_ps(&tensor1[i]);\n        __m128 v2 = _mm_loadu_ps(&tensor2[i]);\n        __m128 diff = _mm_sub_ps(v1, v2);\n        __m128 rounded = _mm_andnot_ps(sign_mask, diff);\n        _mm_storeu_ps(&dst[i], rounded);\n    }\n\n    for (; i < size; ++i) {\n        dst[i] = roundf(tensor1[i] - tensor2[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_26_SSE", "completion": "```c\nvoid tensor3d_sub_round_zero_simd(const float* tensor1, const float* tensor2, float* dst, size_t dim1, size_t dim2, size_t dim3) {\n    size_t size = dim1 * dim2 * dim3;\n    size_t i;\n\n    __m128 a, b, c;\n\n    for (i = 0; i <= size - 4; i += 4) {\n        a = _mm_loadu_ps(&tensor1[i]);\n        b = _mm_loadu_ps(&tensor2[i]);\n        c = _mm_sub_ps(a, b);\n        c = _mm_round_ps(c, _MM_FROUND_TO_ZERO);\n        _mm_storeu_ps(&dst[i], c);\n    }\n\n    for (; i < size; ++i) {\n        dst[i] = roundf(tensor1[i] - tensor2[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_26_SSE", "completion": "```c\nvoid tensor3d_sub_round_zero_simd(const float* tensor1, const float* tensor2, float* dst, size_t dim1, size_t dim2, size_t dim3) {\n    size_t size = dim1 * dim2 * dim3;\n    size_t i;\n\n    for (i = 0; i <= size - 4; i += 4) {\n        __m128 a = _mm_loadu_ps(&tensor1[i]);\n        __m128 b = _mm_loadu_ps(&tensor2[i]);\n        __m128 result = _mm_sub_ps(a, b);\n        result = _mm_round_ps(result, _MM_FROUND_TO_ZERO);\n        _mm_storeu_ps(&dst[i], result);\n    }\n\n    for (; i < size; ++i) {\n        dst[i] = roundf(tensor1[i] - tensor2[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_26_SSE", "completion": "```cpp\nvoid tensor3d_sub_round_zero_simd(const float* tensor1, const float* tensor2, float* dst, size_t dim1, size_t dim2, size_t dim3) {\n    size_t size = dim1 * dim2 * dim3;\n    size_t i = 0;\n\n    __m128 sign_mask = _mm_set1_ps(-0.0f);\n\n    for (; i <= size - 4; i += 4) {\n        __m128 v1 = _mm_loadu_ps(&tensor1[i]);\n        __m128 v2 = _mm_loadu_ps(&tensor2[i]);\n        __m128 diff = _mm_sub_ps(v1, v2);\n        __m128 rounded = _mm_andnot_ps(sign_mask, diff);\n        _mm_storeu_ps(&dst[i], rounded);\n    }\n\n    for (; i < size; ++i) {\n        dst[i] = tensor1[i] - tensor2[i];\n        if (dst[i] < 0.0f) {\n            dst[i] = -dst[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_26_SSE", "completion": "```cpp\nvoid tensor3d_sub_round_zero_simd(const float* tensor1, const float* tensor2, float* dst, size_t dim1, size_t dim2, size_t dim3) {\n    size_t size = dim1 * dim2 * dim3;\n    size_t i = 0;\n\n    __m128 sign_mask = _mm_set1_ps(-0.0f);\n\n    for (; i <= size - 4; i += 4) {\n        __m128 v1 = _mm_loadu_ps(&tensor1[i]);\n        __m128 v2 = _mm_loadu_ps(&tensor2[i]);\n        __m128 diff = _mm_sub_ps(v1, v2);\n        __m128 rounded = _mm_andnot_ps(sign_mask, diff);\n        _mm_storeu_ps(&dst[i], rounded);\n    }\n\n    for (; i < size; ++i) {\n        dst[i] = roundf(tensor1[i] - tensor2[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_27_SSE", "completion": "```cpp\nvoid matrix_hadamard_product_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n) {\n    size_t size = m * n;\n    size_t i = 0;\n\n    for (; i <= size - 2; i += 2) {\n        __m128d a = _mm_loadu_pd(&mat1[i]);\n        __m128d b = _mm_loadu_pd(&mat2[i]);\n        __m128d result = _mm_mul_pd(a, b);\n        _mm_storeu_pd(&dst[i], result);\n    }\n\n    if (i < size) {\n        dst[i] = mat1[i] * mat2[i];\n    }\n}\n```"}
{"task_id": "SimdBench_27_SSE", "completion": "```cpp\nvoid matrix_hadamard_product_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n) {\n    size_t size = m * n;\n    size_t i = 0;\n\n    for (; i <= size - 2; i += 2) {\n        __m128d a = _mm_loadu_pd(&mat1[i]);\n        __m128d b = _mm_loadu_pd(&mat2[i]);\n        __m128d result = _mm_mul_pd(a, b);\n        _mm_storeu_pd(&dst[i], result);\n    }\n\n    if (i < size) {\n        dst[i] = mat1[i] * mat2[i];\n    }\n}\n```"}
{"task_id": "SimdBench_27_SSE", "completion": "```cpp\nvoid matrix_hadamard_product_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n) {\n    size_t size = m * n;\n    size_t i;\n\n    for (i = 0; i <= size - 2; i += 2) {\n        __m128d a = _mm_loadu_pd(&mat1[i]);\n        __m128d b = _mm_loadu_pd(&mat2[i]);\n        __m128d result = _mm_mul_pd(a, b);\n        _mm_storeu_pd(&dst[i], result);\n    }\n\n    for (; i < size; ++i) {\n        dst[i] = mat1[i] * mat2[i];\n    }\n}\n```"}
{"task_id": "SimdBench_27_SSE", "completion": "```cpp\nvoid matrix_hadamard_product_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n) {\n    size_t size = m * n;\n    size_t i = 0;\n\n    for (; i <= size - 2; i += 2) {\n        __m128d a = _mm_loadu_pd(&mat1[i]);\n        __m128d b = _mm_loadu_pd(&mat2[i]);\n        __m128d result = _mm_mul_pd(a, b);\n        _mm_storeu_pd(&dst[i], result);\n    }\n\n    if (i < size) {\n        dst[i] = mat1[i] * mat2[i];\n    }\n}\n```"}
{"task_id": "SimdBench_27_SSE", "completion": "```cpp\nvoid matrix_hadamard_product_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n) {\n    size_t size = m * n;\n    size_t i = 0;\n\n    for (; i <= size - 2; i += 2) {\n        __m128d a = _mm_loadu_pd(&mat1[i]);\n        __m128d b = _mm_loadu_pd(&mat2[i]);\n        __m128d result = _mm_mul_pd(a, b);\n        _mm_storeu_pd(&dst[i], result);\n    }\n\n    if (i < size) {\n        dst[i] = mat1[i] * mat2[i];\n    }\n}\n```"}
{"task_id": "SimdBench_28_SSE", "completion": "```c\nvoid matrix_vector_mul_simd(const float* mat, const float* vec, float* dst, size_t m, size_t n) {\n    for (size_t i = 0; i < m; ++i) {\n        __m128 sum = _mm_setzero_ps();\n        for (size_t j = 0; j < n; j += 4) {\n            __m128 a = _mm_loadu_ps(&mat[i * n + j]);\n            __m128 b = _mm_loadu_ps(&vec[j]);\n            sum = _mm_add_ps(sum, _mm_mul_ps(a, b));\n        }\n        sum = _mm_hadd_ps(sum, sum);\n        sum = _mm_hadd_ps(sum, sum);\n        _mm_store_ss(&dst[i], sum);\n    }\n}\n```"}
{"task_id": "SimdBench_28_SSE", "completion": "```cpp\nvoid matrix_vector_mul_simd(const float* mat, const float* vec, float* dst, size_t m, size_t n) {\n    for (size_t i = 0; i < m; ++i) {\n        __m128 sum = _mm_setzero_ps();\n        for (size_t j = 0; j < n; j += 4) {\n            __m128 a = _mm_loadu_ps(&mat[i * n + j]);\n            __m128 b = _mm_loadu_ps(&vec[j]);\n            sum = _mm_add_ps(sum, _mm_mul_ps(a, b));\n        }\n        sum = _mm_hadd_ps(sum, sum);\n        sum = _mm_hadd_ps(sum, sum);\n        _mm_store_ss(&dst[i], sum);\n    }\n}\n```"}
{"task_id": "SimdBench_28_SSE", "completion": "```c\nvoid matrix_vector_mul_simd(const float* mat, const float* vec, float* dst, size_t m, size_t n) {\n    for (size_t i = 0; i < m; ++i) {\n        __m128 sum = _mm_setzero_ps();\n        for (size_t j = 0; j < n; j += 4) {\n            __m128 a = _mm_loadu_ps(&mat[i * n + j]);\n            __m128 b = _mm_loadu_ps(&vec[j]);\n            sum = _mm_add_ps(sum, _mm_mul_ps(a, b));\n        }\n        sum = _mm_hadd_ps(sum, sum);\n        sum = _mm_hadd_ps(sum, sum);\n        _mm_store_ss(&dst[i], sum);\n    }\n}\n```"}
{"task_id": "SimdBench_28_SSE", "completion": "```cpp\nvoid matrix_vector_mul_simd(const float* mat, const float* vec, float* dst, size_t m, size_t n) {\n    for (size_t i = 0; i < m; ++i) {\n        __m128 sum = _mm_setzero_ps();\n        for (size_t j = 0; j < n; j += 4) {\n            __m128 a = _mm_loadu_ps(&mat[i * n + j]);\n            __m128 b = _mm_loadu_ps(&vec[j]);\n            sum = _mm_add_ps(sum, _mm_mul_ps(a, b));\n        }\n        sum = _mm_hadd_ps(sum, sum);\n        sum = _mm_hadd_ps(sum, sum);\n        _mm_store_ss(&dst[i], sum);\n    }\n}\n```"}
{"task_id": "SimdBench_28_SSE", "completion": "```c\nvoid matrix_vector_mul_simd(const float* mat, const float* vec, float* dst, size_t m, size_t n) {\n    for (size_t i = 0; i < m; ++i) {\n        __m128 sum = _mm_setzero_ps();\n        for (size_t j = 0; j < n; j += 4) {\n            __m128 a = _mm_loadu_ps(&mat[i * n + j]);\n            __m128 b = _mm_loadu_ps(&vec[j]);\n            sum = _mm_add_ps(sum, _mm_mul_ps(a, b));\n        }\n        sum = _mm_hadd_ps(sum, sum);\n        sum = _mm_hadd_ps(sum, sum);\n        _mm_store_ss(&dst[i], sum);\n    }\n}\n```"}
{"task_id": "SimdBench_29_SSE", "completion": "```cpp\ndouble matrix_average_simd(const double* mat, size_t m, size_t n) {\n    __m128d sum = _mm_setzero_pd();\n    size_t total_elements = m * n;\n    size_t i = 0;\n\n    for (; i <= total_elements - 2; i += 2) {\n        __m128d val = _mm_loadu_pd(&mat[i]);\n        sum = _mm_add_pd(sum, val);\n    }\n\n    double temp[2];\n    _mm_storeu_pd(temp, sum);\n    double total_sum = temp[0] + temp[1];\n\n    for (; i < total_elements; ++i) {\n        total_sum += mat[i];\n    }\n\n    return total_sum / total_elements;\n}\n```"}
{"task_id": "SimdBench_29_SSE", "completion": "```cpp\ndouble matrix_average_simd(const double* mat, size_t m, size_t n) {\n    __m128d sum = _mm_setzero_pd();\n    size_t size = m * n;\n    size_t i = 0;\n\n    for (; i <= size - 2; i += 2) {\n        __m128d val = _mm_loadu_pd(&mat[i]);\n        sum = _mm_add_pd(sum, val);\n    }\n\n    double temp[2];\n    _mm_storeu_pd(temp, sum);\n    double total_sum = temp[0] + temp[1];\n\n    for (; i < size; ++i) {\n        total_sum += mat[i];\n    }\n\n    return total_sum / size;\n}\n```"}
{"task_id": "SimdBench_29_SSE", "completion": "```cpp\ndouble matrix_average_simd(const double* mat, size_t m, size_t n) {\n    __m128d sum = _mm_setzero_pd();\n    size_t total_elements = m * n;\n    size_t i;\n\n    for (i = 0; i <= total_elements - 2; i += 2) {\n        __m128d val = _mm_loadu_pd(&mat[i]);\n        sum = _mm_add_pd(sum, val);\n    }\n\n    double temp[2];\n    _mm_storeu_pd(temp, sum);\n    double total_sum = temp[0] + temp[1];\n\n    for (; i < total_elements; ++i) {\n        total_sum += mat[i];\n    }\n\n    return total_sum / total_elements;\n}\n```"}
{"task_id": "SimdBench_29_SSE", "completion": "```c\ndouble matrix_average_simd(const double* mat, size_t m, size_t n) {\n    __m128d sum = _mm_setzero_pd();\n    size_t num_elements = m * n;\n    size_t i;\n\n    for (i = 0; i <= num_elements - 2; i += 2) {\n        __m128d val = _mm_loadu_pd(&mat[i]);\n        sum = _mm_add_pd(sum, val);\n    }\n\n    double temp[2];\n    _mm_storeu_pd(temp, sum);\n    double total_sum = temp[0] + temp[1];\n\n    for (; i < num_elements; ++i) {\n        total_sum += mat[i];\n    }\n\n    return total_sum / num_elements;\n}\n```"}
{"task_id": "SimdBench_29_SSE", "completion": "```cpp\ndouble matrix_average_simd(const double* mat, size_t m, size_t n) {\n    __m128d sum = _mm_setzero_pd();\n    size_t total_elements = m * n;\n    size_t i;\n\n    for (i = 0; i <= total_elements - 2; i += 2) {\n        __m128d val = _mm_loadu_pd(&mat[i]);\n        sum = _mm_add_pd(sum, val);\n    }\n\n    double temp[2];\n    _mm_storeu_pd(temp, sum);\n    double total_sum = temp[0] + temp[1];\n\n    for (; i < total_elements; ++i) {\n        total_sum += mat[i];\n    }\n\n    return total_sum / total_elements;\n}\n```"}
{"task_id": "SimdBench_30_SSE", "completion": "```cpp\nbool matrix_rows_sorted_verify_simd(const int* matrix, const bool* directions, size_t rows, size_t cols) {\n    for (size_t i = 0; i < rows; ++i) {\n        const int* row = matrix + i * cols;\n        bool ascending = directions[i];\n        bool sorted = true;\n\n        if (cols > 1) {\n            __m128i prev = _mm_loadu_si128((__m128i*)row);\n            for (size_t j = 4; j < cols; j += 4) {\n                __m128i curr = _mm_loadu_si128((__m128i*)(row + j));\n                __m128i cmp = ascending ? _mm_cmpgt_epi32(prev, curr) : _mm_cmplt_epi32(prev, curr);\n                if (_mm_movemask_epi8(cmp) != 0) {\n                    sorted = false;\n                    break;\n                }\n                prev = curr;\n            }\n\n            if (sorted) {\n                for (size_t j = cols / 4 * 4; j < cols - 1; ++j) {\n                    if ((ascending && row[j] > row[j + 1]) || (!ascending && row[j] < row[j + 1])) {\n                        sorted = false;\n                        break;\n                    }\n                }\n            }\n        }\n\n        if (!sorted) {\n            return false;\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_30_SSE", "completion": "```cpp\nbool matrix_rows_sorted_verify_simd(const int* matrix, const bool* directions, size_t rows, size_t cols) {\n    for (size_t i = 0; i < rows; ++i) {\n        const int* row = matrix + i * cols;\n        bool ascending = directions[i];\n\n        for (size_t j = 0; j < cols - 4; j += 4) {\n            __m128i current = _mm_loadu_si128((__m128i*)&row[j]);\n            __m128i next = _mm_loadu_si128((__m128i*)&row[j + 1]);\n\n            __m128i cmp = ascending ? _mm_cmplt_epi32(current, next) : _mm_cmpgt_epi32(current, next);\n            int mask = _mm_movemask_epi8(cmp);\n\n            if (mask != 0xFFFF) {\n                return false;\n            }\n        }\n\n        for (size_t j = cols - (cols % 4); j < cols - 1; ++j) {\n            if ((ascending && row[j] > row[j + 1]) || (!ascending && row[j] < row[j + 1])) {\n                return false;\n            }\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_30_SSE", "completion": "```cpp\nbool matrix_rows_sorted_verify_simd(const int* matrix, const bool* directions, size_t rows, size_t cols) {\n    for (size_t i = 0; i < rows; ++i) {\n        const int* row = matrix + i * cols;\n        bool ascending = directions[i];\n        __m128i prev = _mm_loadu_si128((__m128i*)row);\n        for (size_t j = 4; j < cols; j += 4) {\n            __m128i curr = _mm_loadu_si128((__m128i*)(row + j));\n            __m128i cmp = ascending ? _mm_cmpgt_epi32(prev, curr) : _mm_cmplt_epi32(prev, curr);\n            if (_mm_movemask_epi8(cmp) != 0) {\n                return false;\n            }\n            prev = curr;\n        }\n        for (size_t j = cols - (cols % 4); j < cols - 1; ++j) {\n            if ((ascending && row[j] > row[j + 1]) || (!ascending && row[j] < row[j + 1])) {\n                return false;\n            }\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_30_SSE", "completion": "```cpp\nbool matrix_rows_sorted_verify_simd(const int* matrix, const bool* directions, size_t rows, size_t cols) {\n    for (size_t i = 0; i < rows; ++i) {\n        const int* row = matrix + i * cols;\n        bool ascending = directions[i];\n\n        if (cols >= 4) {\n            __m128i prev = _mm_loadu_si128((__m128i*)row);\n            for (size_t j = 4; j < cols; j += 4) {\n                __m128i curr = _mm_loadu_si128((__m128i*)(row + j));\n                __m128i cmp = ascending ? _mm_cmpgt_epi32(prev, curr) : _mm_cmplt_epi32(prev, curr);\n                if (_mm_movemask_epi8(cmp) != 0) {\n                    return false;\n                }\n                prev = curr;\n            }\n            row += cols - (cols % 4);\n        }\n\n        for (size_t j = 1; j < cols; ++j) {\n            if ((ascending && row[j - 1] > row[j]) || (!ascending && row[j - 1] < row[j])) {\n                return false;\n            }\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_30_SSE", "completion": "```cpp\nbool matrix_rows_sorted_verify_simd(const int* matrix, const bool* directions, size_t rows, size_t cols) {\n    for (size_t i = 0; i < rows; ++i) {\n        const int* row = matrix + i * cols;\n        bool ascending = directions[i];\n\n        if (cols < 4) {\n            for (size_t j = 1; j < cols; ++j) {\n                if ((ascending && row[j-1] > row[j]) || (!ascending && row[j-1] < row[j])) {\n                    return false;\n                }\n            }\n        } else {\n            size_t j = 0;\n            for (; j <= cols - 4; j += 4) {\n                __m128i v1 = _mm_loadu_si128((__m128i*)&row[j]);\n                __m128i v2 = _mm_loadu_si128((__m128i*)&row[j+1]);\n\n                __m128i cmp = ascending ? _mm_cmpgt_epi32(v1, v2) : _mm_cmplt_epi32(v1, v2);\n                int mask = _mm_movemask_epi8(cmp);\n\n                if (mask != 0) {\n                    return false;\n                }\n            }\n\n            for (; j < cols - 1; ++j) {\n                if ((ascending && row[j] > row[j+1]) || (!ascending && row[j] < row[j+1])) {\n                    return false;\n                }\n            }\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_31_SSE", "completion": "```cpp\nvoid nearest_multiple_simd(const int16_t* src, int16_t* dst, uint8_t base, size_t length) {\n    __m128i base_vec = _mm_set1_epi16(base);\n    __m128i half_base_vec = _mm_set1_epi16(base / 2);\n\n    for (size_t i = 0; i < length; i += 8) {\n        __m128i src_vec = _mm_loadu_si128((__m128i*)&src[i]);\n        __m128i quotient = _mm_div_epi16(src_vec, base_vec);\n        __m128i product = _mm_mullo_epi16(quotient, base_vec);\n        __m128i remainder = _mm_sub_epi16(src_vec, product);\n        __m128i mask = _mm_cmpgt_epi16(remainder, half_base_vec);\n        __m128i adjusted_quotient = _mm_add_epi16(quotient, mask);\n        __m128i result = _mm_mullo_epi16(adjusted_quotient, base_vec);\n        _mm_storeu_si128((__m128i*)&dst[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_31_SSE", "completion": "```c\nvoid nearest_multiple_simd(const int16_t* src, int16_t* dst, uint8_t base, size_t length) {\n    __m128i vbase = _mm_set1_epi16(base);\n    __m128i vone = _mm_set1_epi16(1);\n    __m128i vhalf_base = _mm_srli_epi16(_mm_add_epi16(vbase, vone), 1);\n\n    for (size_t i = 0; i < length; i += 8) {\n        __m128i vsrc = _mm_loadu_si128((__m128i*)&src[i]);\n        __m128i vquotient = _mm_div_epi16(vsrc, vbase);\n        __m128i vproduct = _mm_mullo_epi16(vquotient, vbase);\n        __m128i vadjust = _mm_and_si128(_mm_cmpgt_epi16(_mm_sub_epi16(vsrc, vproduct), vhalf_base), vone);\n        __m128i vresult = _mm_sub_epi16(vproduct, _mm_mullo_epi16(vadjust, vbase));\n        _mm_storeu_si128((__m128i*)&dst[i], vresult);\n    }\n}\n```"}
{"task_id": "SimdBench_31_SSE", "completion": "```cpp\nvoid nearest_multiple_simd(const int16_t* src, int16_t* dst, uint8_t base, size_t length) {\n    __m128i base_vec = _mm_set1_epi16(base);\n    __m128i half_base_vec = _mm_set1_epi16(base / 2);\n\n    for (size_t i = 0; i < length; i += 8) {\n        __m128i src_vec = _mm_loadu_si128((__m128i*)&src[i]);\n        __m128i quotient = _mm_div_epi16(_mm_add_epi16(src_vec, half_base_vec), base_vec);\n        __m128i result = _mm_mullo_epi16(quotient, base_vec);\n        _mm_storeu_si128((__m128i*)&dst[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_31_SSE", "completion": "```c\nvoid nearest_multiple_simd(const int16_t* src, int16_t* dst, uint8_t base, size_t length) {\n    __m128i base_vec = _mm_set1_epi16(base);\n    __m128i half_base_vec = _mm_set1_epi16(base / 2);\n\n    for (size_t i = 0; i < length; i += 8) {\n        __m128i src_vec = _mm_loadu_si128((__m128i*)&src[i]);\n        __m128i quotient = _mm_div_epi16(src_vec, base_vec);\n        __m128i product = _mm_mullo_epi16(quotient, base_vec);\n        __m128i remainder = _mm_sub_epi16(src_vec, product);\n        __m128i mask = _mm_cmpgt_epi16(remainder, half_base_vec);\n        __m128i increment = _mm_and_si128(mask, base_vec);\n        __m128i result = _mm_add_epi16(product, increment);\n        _mm_storeu_si128((__m128i*)&dst[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_31_SSE", "completion": "```c\nvoid nearest_multiple_simd(const int16_t* src, int16_t* dst, uint8_t base, size_t length) {\n    __m128i base_vec = _mm_set1_epi16(base);\n    __m128i half_base_vec = _mm_set1_epi16(base / 2);\n\n    for (size_t i = 0; i < length; i += 8) {\n        __m128i src_vec = _mm_loadu_si128((__m128i*)&src[i]);\n        __m128i quotient = _mm_div_epi16(src_vec, base_vec);\n        __m128i product = _mm_mullo_epi16(quotient, base_vec);\n        __m128i remainder = _mm_sub_epi16(src_vec, product);\n        __m128i mask = _mm_cmpgt_epi16(remainder, half_base_vec);\n        __m128i adjusted_quotient = _mm_add_epi16(quotient, mask);\n        __m128i result = _mm_mullo_epi16(adjusted_quotient, base_vec);\n        _mm_storeu_si128((__m128i*)&dst[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_32_SSE", "completion": "```cpp\nbool matrix_has_row_simd(const double* matrix, const double* vector, size_t rows, size_t cols) {\n    __m128d vec = _mm_loadu_pd(vector);\n    for (size_t i = 0; i < rows; ++i) {\n        const double* row = matrix + i * cols;\n        for (size_t j = 0; j < cols; j += 2) {\n            __m128d mat = _mm_loadu_pd(row + j);\n            __m128d cmp = _mm_cmpeq_pd(mat, vec);\n            int mask = _mm_movemask_pd(cmp);\n            if (mask == 3) {\n                return true;\n            }\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_32_SSE", "completion": "```cpp\nbool matrix_has_row_simd(const double* matrix, const double* vector, size_t rows, size_t cols) {\n    __m128d vec = _mm_loadu_pd(vector);\n    for (size_t i = 0; i < rows; ++i) {\n        const double* row = matrix + i * cols;\n        for (size_t j = 0; j < cols; j += 2) {\n            __m128d mat = _mm_loadu_pd(row + j);\n            __m128d cmp = _mm_cmpeq_pd(mat, vec);\n            int mask = _mm_movemask_pd(cmp);\n            if (mask == 3) {\n                return true;\n            }\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_32_SSE", "completion": "```cpp\nbool matrix_has_row_simd(const double* matrix, const double* vector, size_t rows, size_t cols) {\n    __m128d vec = _mm_loadu_pd(vector);\n    for (size_t i = 0; i < rows; ++i) {\n        const double* row = matrix + i * cols;\n        for (size_t j = 0; j < cols; j += 2) {\n            __m128d mat = _mm_loadu_pd(row + j);\n            __m128d cmp = _mm_cmpeq_pd(mat, vec);\n            int mask = _mm_movemask_pd(cmp);\n            if (mask == 3) {\n                return true;\n            }\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_32_SSE", "completion": "```cpp\nbool matrix_has_row_simd(const double* matrix, const double* vector, size_t rows, size_t cols) {\n    __m128d vec = _mm_loadu_pd(vector);\n    for (size_t i = 0; i < rows; ++i) {\n        const double* row = matrix + i * cols;\n        for (size_t j = 0; j < cols; j += 2) {\n            __m128d mat = _mm_loadu_pd(row + j);\n            __m128d cmp = _mm_cmpeq_pd(mat, vec);\n            int mask = _mm_movemask_pd(cmp);\n            if (mask == 3) {\n                return true;\n            }\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_32_SSE", "completion": "```cpp\nbool matrix_has_row_simd(const double* matrix, const double* vector, size_t rows, size_t cols) {\n    __m128d vec = _mm_loadu_pd(vector);\n    for (size_t i = 0; i < rows; ++i) {\n        const double* row = matrix + i * cols;\n        for (size_t j = 0; j < cols; j += 2) {\n            __m128d mat = _mm_loadu_pd(row + j);\n            __m128d cmp = _mm_cmpeq_pd(mat, vec);\n            int mask = _mm_movemask_pd(cmp);\n            if (mask == 3) {\n                return true;\n            }\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_33_SSE", "completion": "```cpp\nsize_t tensor_4d_equal_count_simd(const uint8_t* A, const uint8_t* B, const size_t dims[4]) {\n    size_t total_elements = dims[0] * dims[1] * dims[2] * dims[3];\n    size_t count = 0;\n\n    for (size_t i = 0; i < total_elements; i += 16) {\n        __m128i a = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i b = _mm_loadu_si128((__m128i*)&B[i]);\n        __m128i eq = _mm_cmpeq_epi8(a, b);\n        int mask = _mm_movemask_epi8(eq);\n        count += _mm_popcnt_u32(mask);\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_33_SSE", "completion": "```c\nsize_t tensor_4d_equal_count_simd(const uint8_t* A, const uint8_t* B, const size_t dims[4]) {\n    size_t total_elements = dims[0] * dims[1] * dims[2] * dims[3];\n    size_t equal_count = 0;\n\n    for (size_t i = 0; i < total_elements; i += 16) {\n        __m128i a = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i b = _mm_loadu_si128((__m128i*)&B[i]);\n        __m128i cmp = _mm_cmpeq_epi8(a, b);\n        int mask = _mm_movemask_epi8(cmp);\n        equal_count += __builtin_popcount(mask);\n    }\n\n    return equal_count;\n}\n```"}
{"task_id": "SimdBench_33_SSE", "completion": "```c\nsize_t tensor_4d_equal_count_simd(const uint8_t* A, const uint8_t* B, const size_t dims[4]) {\n    size_t total_elements = dims[0] * dims[1] * dims[2] * dims[3];\n    size_t count = 0;\n    size_t i = 0;\n\n    for (; i <= total_elements - 16; i += 16) {\n        __m128i a = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i b = _mm_loadu_si128((__m128i*)&B[i]);\n        __m128i eq = _mm_cmpeq_epi8(a, b);\n        int mask = _mm_movemask_epi8(eq);\n        count += _mm_popcnt_u32(mask);\n    }\n\n    for (; i < total_elements; ++i) {\n        if (A[i] == B[i]) {\n            ++count;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_33_SSE", "completion": "```c\nsize_t tensor_4d_equal_count_simd(const uint8_t* A, const uint8_t* B, const size_t dims[4]) {\n    size_t total_elements = dims[0] * dims[1] * dims[2] * dims[3];\n    size_t equal_count = 0;\n\n    for (size_t i = 0; i < total_elements; i += 16) {\n        __m128i a = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i b = _mm_loadu_si128((__m128i*)&B[i]);\n        __m128i cmp = _mm_cmpeq_epi8(a, b);\n        int mask = _mm_movemask_epi8(cmp);\n        equal_count += _mm_popcnt_u32(mask);\n    }\n\n    return equal_count;\n}\n```"}
{"task_id": "SimdBench_33_SSE", "completion": "```cpp\nsize_t tensor_4d_equal_count_simd(const uint8_t* A, const uint8_t* B, const size_t dims[4]) {\n    size_t total_elements = dims[0] * dims[1] * dims[2] * dims[3];\n    size_t count = 0;\n\n    for (size_t i = 0; i < total_elements; i += 16) {\n        __m128i a = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i b = _mm_loadu_si128((__m128i*)&B[i]);\n        __m128i eq = _mm_cmpeq_epi8(a, b);\n        int mask = _mm_movemask_epi8(eq);\n        count += _mm_popcnt_u32(mask);\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_34_SSE", "completion": "```cpp\nvoid axm_abs_simd(size_t length, const int64_t a, const int64_t *x, int64_t *y) {\n    __m128i va = _mm_set1_epi64x(a);\n    for (size_t i = 0; i < length; i += 2) {\n        __m128i vx = _mm_loadu_si128((__m128i*)&x[i]);\n        __m128i vy = _mm_loadu_si128((__m128i*)&y[i]);\n\n        __m128i vmul = _mm_mullo_epi64(vx, va);\n        __m128i vabs = _mm_abs_epi64(vy);\n        __m128i vsub = _mm_sub_epi64(vabs, vmul);\n\n        _mm_storeu_si128((__m128i*)&y[i], vsub);\n    }\n}\n```"}
{"task_id": "SimdBench_34_SSE", "completion": "```c\nvoid axm_abs_simd(size_t length, const int64_t a, const int64_t *x, int64_t *y) {\n    __m128i va = _mm_set1_epi64x(a);\n    for (size_t i = 0; i < length; i += 2) {\n        __m128i vx = _mm_loadu_si128((__m128i *)&x[i]);\n        __m128i vy = _mm_loadu_si128((__m128i *)&y[i]);\n\n        __m128i vax = _mm_mullo_epi64(vx, va);\n        __m128i vabs = _mm_abs_epi64(vy);\n        __m128i result = _mm_sub_epi64(vax, vabs);\n\n        _mm_storeu_si128((__m128i *)&y[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_34_SSE", "completion": "```c\nvoid axm_abs_simd(size_t length, const int64_t a, const int64_t *x, int64_t *y) {\n    size_t i;\n    __m128i va = _mm_set1_epi64x(a);\n    for (i = 0; i < length; i += 2) {\n        __m128i vx = _mm_loadu_si128((__m128i *)&x[i]);\n        __m128i vy = _mm_loadu_si128((__m128i *)&y[i]);\n\n        __m128i vax = _mm_mullo_epi64(vx, va);\n        __m128i vabs = _mm_abs_epi64(vy);\n        __m128i vresult = _mm_sub_epi64(vax, vabs);\n\n        _mm_storeu_si128((__m128i *)&y[i], vresult);\n    }\n}\n```"}
{"task_id": "SimdBench_34_SSE", "completion": "```cpp\nvoid axm_abs_simd(size_t length, const int64_t a, const int64_t *x, int64_t *y) {\n    __m128i va = _mm_set1_epi64x(a);\n    for (size_t i = 0; i < length; i += 2) {\n        __m128i vx = _mm_loadu_si128((__m128i*)&x[i]);\n        __m128i vy = _mm_loadu_si128((__m128i*)&y[i]);\n        __m128i vax = _mm_mullo_epi64(vx, va);\n        __m128i vabs = _mm_abs_epi64(vy);\n        __m128i vresult = _mm_sub_epi64(vabs, vax);\n        _mm_storeu_si128((__m128i*)&y[i], vresult);\n    }\n}\n```"}
{"task_id": "SimdBench_34_SSE", "completion": "```c\nvoid axm_abs_simd(size_t length, const int64_t a, const int64_t *x, int64_t *y) {\n    size_t i;\n    __m128i va = _mm_set1_epi64x(a);\n    for (i = 0; i < length; i += 2) {\n        __m128i vx = _mm_loadu_si128((__m128i *)&x[i]);\n        __m128i vy = _mm_loadu_si128((__m128i *)&y[i]);\n\n        __m128i vax = _mm_mullo_epi64(vx, va);\n        __m128i vabs = _mm_abs_epi64(vy);\n        __m128i vresult = _mm_sub_epi64(vax, vabs);\n\n        _mm_storeu_si128((__m128i *)&y[i], vresult);\n    }\n}\n```"}
{"task_id": "SimdBench_35_SSE", "completion": "```c\nMinMaxPair min_max_pair_simd(const int16_t* vec, size_t length) {\n    __m128i min_vec = _mm_set1_epi16(INT16_MAX);\n    __m128i max_vec = _mm_set1_epi16(INT16_MIN);\n\n    for (size_t i = 0; i < length; i += 8) {\n        __m128i current_vec = _mm_loadu_si128((__m128i*)&vec[i]);\n        min_vec = _mm_min_epi16(min_vec, current_vec);\n        max_vec = _mm_max_epi16(max_vec, current_vec);\n    }\n\n    int16_t min_vals[8];\n    int16_t max_vals[8];\n    _mm_storeu_si128((__m128i*)min_vals, min_vec);\n    _mm_storeu_si128((__m128i*)max_vals, max_vec);\n\n    int16_t min_num = min_vals[0];\n    int16_t max_num = max_vals[0];\n\n    for (int i = 1; i < 8; ++i) {\n        if (min_vals[i] < min_num) min_num = min_vals[i];\n        if (max_vals[i] > max_num) max_num = max_vals[i];\n    }\n\n    MinMaxPair result;\n    result.min_num = min_num;\n    result.max_num = max_num;\n    return result;\n}\n```"}
{"task_id": "SimdBench_35_SSE", "completion": "```c\nMinMaxPair min_max_pair_simd(const int16_t* vec, size_t length) {\n    __m128i min_vec = _mm_set1_epi16(INT16_MAX);\n    __m128i max_vec = _mm_set1_epi16(INT16_MIN);\n\n    for (size_t i = 0; i < length; i += 8) {\n        __m128i current_vec = _mm_loadu_si128((__m128i*)&vec[i]);\n        min_vec = _mm_min_epi16(min_vec, current_vec);\n        max_vec = _mm_max_epi16(max_vec, current_vec);\n    }\n\n    int16_t min_vals[8];\n    int16_t max_vals[8];\n    _mm_storeu_si128((__m128i*)min_vals, min_vec);\n    _mm_storeu_si128((__m128i*)max_vals, max_vec);\n\n    int16_t min_num = min_vals[0];\n    int16_t max_num = max_vals[0];\n\n    for (int i = 1; i < 8; ++i) {\n        if (min_vals[i] < min_num) min_num = min_vals[i];\n        if (max_vals[i] > max_num) max_num = max_vals[i];\n    }\n\n    MinMaxPair result;\n    result.min_num = min_num;\n    result.max_num = max_num;\n    return result;\n}\n```"}
{"task_id": "SimdBench_35_SSE", "completion": "```c\nMinMaxPair min_max_pair_simd(const int16_t* vec, size_t length) {\n    __m128i min_vec = _mm_set1_epi16(INT16_MAX);\n    __m128i max_vec = _mm_set1_epi16(INT16_MIN);\n\n    for (size_t i = 0; i < length; i += 8) {\n        __m128i current_vec = _mm_loadu_si128((__m128i*)&vec[i]);\n        min_vec = _mm_min_epi16(min_vec, current_vec);\n        max_vec = _mm_max_epi16(max_vec, current_vec);\n    }\n\n    int16_t min_vals[8];\n    int16_t max_vals[8];\n    _mm_storeu_si128((__m128i*)min_vals, min_vec);\n    _mm_storeu_si128((__m128i*)max_vals, max_vec);\n\n    int16_t min_num = min_vals[0];\n    int16_t max_num = max_vals[0];\n\n    for (int i = 1; i < 8; ++i) {\n        if (min_vals[i] < min_num) min_num = min_vals[i];\n        if (max_vals[i] > max_num) max_num = max_vals[i];\n    }\n\n    MinMaxPair result;\n    result.min_num = min_num;\n    result.max_num = max_num;\n    return result;\n}\n```"}
{"task_id": "SimdBench_35_SSE", "completion": "```c\nMinMaxPair min_max_pair_simd(const int16_t* vec, size_t length) {\n    __m128i min_vec = _mm_set1_epi16(INT16_MAX);\n    __m128i max_vec = _mm_set1_epi16(INT16_MIN);\n\n    for (size_t i = 0; i < length; i += 8) {\n        __m128i current_vec = _mm_loadu_si128((__m128i*)&vec[i]);\n        min_vec = _mm_min_epi16(min_vec, current_vec);\n        max_vec = _mm_max_epi16(max_vec, current_vec);\n    }\n\n    int16_t min_vals[8];\n    int16_t max_vals[8];\n    _mm_storeu_si128((__m128i*)min_vals, min_vec);\n    _mm_storeu_si128((__m128i*)max_vals, max_vec);\n\n    int16_t min_num = min_vals[0];\n    int16_t max_num = max_vals[0];\n\n    for (int i = 1; i < 8; ++i) {\n        if (min_vals[i] < min_num) min_num = min_vals[i];\n        if (max_vals[i] > max_num) max_num = max_vals[i];\n    }\n\n    MinMaxPair result;\n    result.min_num = min_num;\n    result.max_num = max_num;\n    return result;\n}\n```"}
{"task_id": "SimdBench_35_SSE", "completion": "```c\nMinMaxPair min_max_pair_simd(const int16_t* vec, size_t length) {\n    __m128i min_vec = _mm_set1_epi16(INT16_MAX);\n    __m128i max_vec = _mm_set1_epi16(INT16_MIN);\n\n    for (size_t i = 0; i < length; i += 8) {\n        __m128i current_vec = _mm_loadu_si128((__m128i*)&vec[i]);\n        min_vec = _mm_min_epi16(min_vec, current_vec);\n        max_vec = _mm_max_epi16(max_vec, current_vec);\n    }\n\n    int16_t min_vals[8];\n    int16_t max_vals[8];\n    _mm_storeu_si128((__m128i*)min_vals, min_vec);\n    _mm_storeu_si128((__m128i*)max_vals, max_vec);\n\n    int16_t min_num = min_vals[0];\n    int16_t max_num = max_vals[0];\n\n    for (int i = 1; i < 8; ++i) {\n        if (min_vals[i] < min_num) min_num = min_vals[i];\n        if (max_vals[i] > max_num) max_num = max_vals[i];\n    }\n\n    MinMaxPair result;\n    result.min_num = min_num;\n    result.max_num = max_num;\n    return result;\n}\n```"}
{"task_id": "SimdBench_36_SSE", "completion": "```cpp\nbool matrix_rows_strictly_increasing_simd(const int* matrix, size_t rows, size_t cols) {\n    if (rows == 0 || cols == 0) {\n        return false;\n    }\n\n    for (size_t i = 0; i < rows; ++i) {\n        const int* row = matrix + i * cols;\n        size_t j = 0;\n\n        for (; j <= cols - 4; j += 4) {\n            __m128i v1 = _mm_loadu_si128((__m128i*)&row[j]);\n            __m128i v2 = _mm_loadu_si128((__m128i*)&row[j + 1]);\n\n            __m128i cmp = _mm_cmplt_epi32(v1, v2);\n            int mask = _mm_movemask_epi8(cmp);\n\n            if (mask != 0xFFFF) {\n                return false;\n            }\n        }\n\n        for (; j < cols - 1; ++j) {\n            if (row[j] >= row[j + 1]) {\n                return false;\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_36_SSE", "completion": "```c++\nbool matrix_rows_strictly_increasing_simd(const int* matrix, size_t rows, size_t cols) {\n    if (rows == 0 || cols == 0) {\n        return false;\n    }\n\n    for (size_t i = 0; i < rows; ++i) {\n        const int* row = matrix + i * cols;\n        size_t j = 0;\n\n        for (; j + 4 < cols; j += 4) {\n            __m128i current = _mm_loadu_si128((__m128i*)&row[j]);\n            __m128i next = _mm_loadu_si128((__m128i*)&row[j + 1]);\n\n            __m128i cmp = _mm_cmplt_epi32(current, next);\n            int mask = _mm_movemask_epi8(cmp);\n\n            if (mask != 0xFFFF) {\n                return false;\n            }\n        }\n\n        for (; j < cols - 1; ++j) {\n            if (row[j] >= row[j + 1]) {\n                return false;\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_36_SSE", "completion": "```cpp\nbool matrix_rows_strictly_increasing_simd(const int* matrix, size_t rows, size_t cols) {\n    if (rows == 0 || cols == 0) return false;\n\n    for (size_t i = 0; i < rows; ++i) {\n        const int* row = matrix + i * cols;\n        size_t j = 0;\n\n        for (; j + 4 <= cols; j += 4) {\n            __m128i v1 = _mm_loadu_si128((__m128i*)&row[j]);\n            __m128i v2 = _mm_loadu_si128((__m128i*)&row[j + 1]);\n            __m128i cmp = _mm_cmplt_epi32(v1, v2);\n\n            if (_mm_movemask_epi8(cmp) != 0xFFFF) return false;\n        }\n\n        for (; j + 1 < cols; ++j) {\n            if (row[j] >= row[j + 1]) return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_36_SSE", "completion": "```cpp\nbool matrix_rows_strictly_increasing_simd(const int* matrix, size_t rows, size_t cols) {\n    if (rows == 0 || cols == 0) {\n        return false;\n    }\n\n    for (size_t i = 0; i < rows; ++i) {\n        const int* row = matrix + i * cols;\n        size_t j = 0;\n\n        for (; j <= cols - 4; j += 4) {\n            __m128i current = _mm_loadu_si128((__m128i*)&row[j]);\n            __m128i next = _mm_loadu_si128((__m128i*)&row[j + 1]);\n\n            __m128i cmp = _mm_cmplt_epi32(current, next);\n            int mask = _mm_movemask_epi8(cmp);\n\n            if (mask != 0xFFFF) {\n                return false;\n            }\n        }\n\n        for (; j < cols - 1; ++j) {\n            if (row[j] >= row[j + 1]) {\n                return false;\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_36_SSE", "completion": "```cpp\nbool matrix_rows_strictly_increasing_simd(const int* matrix, size_t rows, size_t cols) {\n    if (rows == 0 || cols == 0) return false;\n\n    for (size_t i = 0; i < rows; ++i) {\n        const int* row = matrix + i * cols;\n        size_t j = 0;\n\n        for (; j + 4 < cols; j += 4) {\n            __m128i v1 = _mm_loadu_si128((__m128i*)&row[j]);\n            __m128i v2 = _mm_loadu_si128((__m128i*)&row[j + 1]);\n            __m128i cmp = _mm_cmpgt_epi32(v2, v1);\n\n            if (_mm_movemask_epi8(cmp) != 0xFFFF) return false;\n        }\n\n        for (; j + 1 < cols; ++j) {\n            if (row[j] >= row[j + 1]) return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_37_SSE", "completion": "```cpp\nbool matrix_blocks_equal_simd(const int* matrix, size_t block_size, size_t rows, size_t cols) {\n    if (block_size == 0 || block_size > rows || block_size > cols || rows % block_size != 0 || cols % block_size != 0) {\n        return false;\n    }\n\n    const int* first_block = matrix;\n    size_t num_blocks_row = cols / block_size;\n    size_t num_blocks_col = rows / block_size;\n\n    for (size_t block_row = 0; block_row < num_blocks_col; ++block_row) {\n        for (size_t block_col = 0; block_col < num_blocks_row; ++block_col) {\n            const int* current_block = matrix + block_row * block_size * cols + block_col * block_size;\n\n            for (size_t i = 0; i < block_size; ++i) {\n                for (size_t j = 0; j < block_size; j += 4) {\n                    __m128i first_block_vec = _mm_loadu_si128((__m128i*)(first_block + i * block_size + j));\n                    __m128i current_block_vec = _mm_loadu_si128((__m128i*)(current_block + i * block_size + j));\n                    __m128i cmp_result = _mm_cmpeq_epi32(first_block_vec, current_block_vec);\n\n                    if (_mm_movemask_epi8(cmp_result) != 0xFFFF) {\n                        return false;\n                    }\n                }\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_37_SSE", "completion": "```cpp\nbool matrix_blocks_equal_simd(const int* matrix, size_t block_size, size_t rows, size_t cols) {\n    if (block_size == 0 || block_size > rows || block_size > cols || rows % block_size != 0 || cols % block_size != 0) {\n        return false;\n    }\n\n    const int* first_block = matrix;\n    size_t block_elements = block_size * block_size;\n\n    for (size_t i = 0; i < rows; i += block_size) {\n        for (size_t j = 0; j < cols; j += block_size) {\n            const int* current_block = matrix + i * cols + j;\n\n            for (size_t k = 0; k < block_elements; k += 4) {\n                __m128i first_block_vec = _mm_loadu_si128((__m128i*)(first_block + k));\n                __m128i current_block_vec = _mm_loadu_si128((__m128i*)(current_block + k));\n                __m128i cmp_result = _mm_cmpeq_epi32(first_block_vec, current_block_vec);\n\n                if (_mm_movemask_epi8(cmp_result) != 0xFFFF) {\n                    return false;\n                }\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_37_SSE", "completion": "```cpp\nbool matrix_blocks_equal_simd(const int* matrix, size_t block_size, size_t rows, size_t cols) {\n    if (block_size == 0 || block_size > rows || block_size > cols || rows % block_size != 0 || cols % block_size != 0) {\n        return false;\n    }\n\n    const size_t num_blocks_row = rows / block_size;\n    const size_t num_blocks_col = cols / block_size;\n\n    for (size_t block_row = 0; block_row < num_blocks_row; ++block_row) {\n        for (size_t block_col = 0; block_col < num_blocks_col; ++block_col) {\n            const int* block = matrix + block_row * block_size * cols + block_col * block_size;\n            for (size_t i = 0; i < block_size; ++i) {\n                for (size_t j = 0; j < block_size; j += 4) {\n                    __m128i block_data = _mm_loadu_si128((__m128i*)(block + i * cols + j));\n                    for (size_t k = 1; k < num_blocks_row; ++k) {\n                        for (size_t l = 0; l < num_blocks_col; ++l) {\n                            const int* compare_block = matrix + k * block_size * cols + l * block_size;\n                            __m128i compare_data = _mm_loadu_si128((__m128i*)(compare_block + i * cols + j));\n                            if (!_mm_movemask_epi8(_mm_cmpeq_epi32(block_data, compare_data))) {\n                                return false;\n                            }\n                        }\n                    }\n                }\n            }\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_37_SSE", "completion": "```cpp\nbool matrix_blocks_equal_simd(const int* matrix, size_t block_size, size_t rows, size_t cols) {\n    if (block_size == 0 || block_size > rows || block_size > cols || rows % block_size != 0 || cols % block_size != 0) {\n        return false;\n    }\n\n    const int* first_block = matrix;\n    size_t num_blocks_row = cols / block_size;\n    size_t num_blocks_col = rows / block_size;\n\n    for (size_t block_row = 0; block_row < num_blocks_col; ++block_row) {\n        for (size_t block_col = 0; block_col < num_blocks_row; ++block_col) {\n            const int* current_block = matrix + block_row * block_size * cols + block_col * block_size;\n\n            for (size_t i = 0; i < block_size; ++i) {\n                for (size_t j = 0; j < block_size; j += 4) {\n                    __m128i first_block_vec = _mm_loadu_si128((__m128i*)(first_block + i * block_size + j));\n                    __m128i current_block_vec = _mm_loadu_si128((__m128i*)(current_block + i * block_size + j));\n                    __m128i cmp_result = _mm_cmpeq_epi32(first_block_vec, current_block_vec);\n\n                    if (_mm_movemask_epi8(cmp_result) != 0xFFFF) {\n                        return false;\n                    }\n                }\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_37_SSE", "completion": "```cpp\nbool matrix_blocks_equal_simd(const int* matrix, size_t block_size, size_t rows, size_t cols) {\n    if (block_size == 0 || block_size > rows || block_size > cols || rows % block_size != 0 || cols % block_size != 0) {\n        return false;\n    }\n\n    const size_t num_blocks_row = rows / block_size;\n    const size_t num_blocks_col = cols / block_size;\n    const size_t block_elements = block_size * block_size;\n\n    __m128i first_block[block_elements / 4];\n\n    for (size_t i = 0; i < block_elements / 4; ++i) {\n        first_block[i] = _mm_load_si128((__m128i*)&matrix[i * 4]);\n    }\n\n    for (size_t block_row = 0; block_row < num_blocks_row; ++block_row) {\n        for (size_t block_col = 0; block_col < num_blocks_col; ++block_col) {\n            if (block_row == 0 && block_col == 0) continue;\n\n            const int* current_block = &matrix[(block_row * block_size * cols + block_col * block_size)];\n\n            for (size_t i = 0; i < block_elements / 4; ++i) {\n                __m128i current = _mm_load_si128((__m128i*)&current_block[i * 4]);\n                __m128i diff = _mm_xor_si128(first_block[i], current);\n                if (!_mm_testz_si128(diff, diff)) {\n                    return false;\n                }\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_38_SSE", "completion": "```cpp\nbool vector_block_equal_simd(const double* vec, double tolerance, size_t length, size_t block_size) {\n    if (block_size == 0 || block_size > length || length % block_size != 0) {\n        return false;\n    }\n\n    size_t num_blocks = length / block_size;\n    if (num_blocks < 2) {\n        return false;\n    }\n\n    __m128d tol_vec = _mm_set1_pd(tolerance);\n    __m128d first_block[block_size / 2];\n\n    for (size_t i = 0; i < block_size / 2; ++i) {\n        first_block[i] = _mm_loadu_pd(&vec[i * 2]);\n    }\n\n    for (size_t block = 1; block < num_blocks; ++block) {\n        for (size_t i = 0; i < block_size / 2; ++i) {\n            __m128d current_block = _mm_loadu_pd(&vec[block * block_size + i * 2]);\n            __m128d diff = _mm_sub_pd(current_block, first_block[i]);\n            __m128d abs_diff = _mm_andnot_pd(_mm_set1_pd(-0.0), diff);\n            __m128d cmp = _mm_cmplt_pd(abs_diff, tol_vec);\n            int mask = _mm_movemask_pd(cmp);\n            if (mask != 3) {\n                return false;\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_38_SSE", "completion": "```cpp\nbool vector_block_equal_simd(const double* vec, double tolerance, size_t length, size_t block_size) {\n    if (block_size < 2 || block_size > length || length % block_size != 0) {\n        return false;\n    }\n\n    __m128d tol_vec = _mm_set1_pd(tolerance);\n    __m128d first_block[block_size / 2];\n\n    for (size_t i = 0; i < block_size / 2; ++i) {\n        first_block[i] = _mm_loadu_pd(&vec[i * 2]);\n    }\n\n    for (size_t block = 1; block < length / block_size; ++block) {\n        for (size_t i = 0; i < block_size / 2; ++i) {\n            __m128d current_block = _mm_loadu_pd(&vec[block * block_size + i * 2]);\n            __m128d diff = _mm_sub_pd(current_block, first_block[i]);\n            __m128d abs_diff = _mm_andnot_pd(_mm_set1_pd(-0.0), diff);\n            __m128d mask = _mm_cmplt_pd(abs_diff, tol_vec);\n            if (!_mm_movemask_pd(mask)) {\n                return false;\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_38_SSE", "completion": "```cpp\nbool vector_block_equal_simd(const double* vec, double tolerance, size_t length, size_t block_size) {\n    if (block_size == 0 || block_size > length || length % block_size != 0) {\n        return false;\n    }\n\n    size_t num_blocks = length / block_size;\n    if (num_blocks < 2) {\n        return false;\n    }\n\n    __m128d tol_vec = _mm_set1_pd(tolerance);\n    __m128d first_block[block_size / 2];\n\n    for (size_t i = 0; i < block_size / 2; ++i) {\n        first_block[i] = _mm_loadu_pd(&vec[i * 2]);\n    }\n\n    for (size_t block = 1; block < num_blocks; ++block) {\n        for (size_t i = 0; i < block_size / 2; ++i) {\n            __m128d current_block = _mm_loadu_pd(&vec[block * block_size + i * 2]);\n            __m128d diff = _mm_sub_pd(current_block, first_block[i]);\n            __m128d abs_diff = _mm_andnot_pd(_mm_set1_pd(-0.0), diff);\n            __m128d cmp = _mm_cmple_pd(abs_diff, tol_vec);\n            int mask = _mm_movemask_pd(cmp);\n            if (mask != 3) {\n                return false;\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_38_SSE", "completion": "```cpp\nbool vector_block_equal_simd(const double* vec, double tolerance, size_t length, size_t block_size) {\n    if (block_size == 0 || block_size > length || length % block_size != 0) {\n        return false;\n    }\n\n    size_t num_blocks = length / block_size;\n    if (num_blocks < 2) {\n        return false;\n    }\n\n    __m128d tol_vec = _mm_set1_pd(tolerance);\n    __m128d first_block[block_size / 2];\n\n    for (size_t i = 0; i < block_size / 2; ++i) {\n        first_block[i] = _mm_loadu_pd(&vec[i * 2]);\n    }\n\n    for (size_t block = 1; block < num_blocks; ++block) {\n        for (size_t i = 0; i < block_size / 2; ++i) {\n            __m128d current_block = _mm_loadu_pd(&vec[block * block_size + i * 2]);\n            __m128d diff = _mm_sub_pd(current_block, first_block[i]);\n            __m128d abs_diff = _mm_andnot_pd(_mm_set1_pd(-0.0), diff);\n            __m128d mask = _mm_cmplt_pd(abs_diff, tol_vec);\n            if (!_mm_movemask_pd(mask)) {\n                return false;\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_38_SSE", "completion": "```c++\nbool vector_block_equal_simd(const double* vec, double tolerance, size_t length, size_t block_size) {\n    if (block_size == 0 || block_size > length || length % block_size != 0) {\n        return false;\n    }\n\n    size_t num_blocks = length / block_size;\n    if (num_blocks < 2) {\n        return false;\n    }\n\n    __m128d tol_vec = _mm_set1_pd(tolerance);\n    __m128d first_block[block_size / 2];\n\n    for (size_t i = 0; i < block_size / 2; ++i) {\n        first_block[i] = _mm_loadu_pd(&vec[i * 2]);\n    }\n\n    for (size_t block = 1; block < num_blocks; ++block) {\n        for (size_t i = 0; i < block_size / 2; ++i) {\n            __m128d current = _mm_loadu_pd(&vec[block * block_size + i * 2]);\n            __m128d diff = _mm_sub_pd(current, first_block[i]);\n            __m128d abs_diff = _mm_andnot_pd(_mm_set1_pd(-0.0), diff);\n            __m128d mask = _mm_cmplt_pd(abs_diff, tol_vec);\n            if (!_mm_movemask_pd(mask)) {\n                return false;\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_39_SSE", "completion": "```c\nvoid matrix_row_norm_compare_simd(const double* matrix, const double* thresholds, size_t rows, size_t cols, bool* result) {\n    for (size_t i = 0; i < rows; ++i) {\n        __m128d sum = _mm_setzero_pd();\n        for (size_t j = 0; j < cols; j += 2) {\n            __m128d val = _mm_loadu_pd(&matrix[i * cols + j]);\n            sum = _mm_add_pd(sum, _mm_mul_pd(val, val));\n        }\n        double temp[2];\n        _mm_storeu_pd(temp, sum);\n        double norm = temp[0] + temp[1];\n        result[i] = norm > thresholds[i];\n    }\n}\n```"}
{"task_id": "SimdBench_39_SSE", "completion": "```cpp\nvoid matrix_row_norm_compare_simd(const double* matrix, const double* thresholds, size_t rows, size_t cols, bool* result) {\n    for (size_t i = 0; i < rows; ++i) {\n        __m128d sum = _mm_setzero_pd();\n        for (size_t j = 0; j < cols; j += 2) {\n            __m128d val = _mm_loadu_pd(&matrix[i * cols + j]);\n            sum = _mm_add_pd(sum, _mm_mul_pd(val, val));\n        }\n        double norm_squared = _mm_cvtsd_f64(_mm_hadd_pd(sum, sum));\n        result[i] = norm_squared > thresholds[i];\n    }\n}\n```"}
{"task_id": "SimdBench_39_SSE", "completion": "```cpp\nvoid matrix_row_norm_compare_simd(const double* matrix, const double* thresholds, size_t rows, size_t cols, bool* result) {\n    for (size_t i = 0; i < rows; ++i) {\n        __m128d sum = _mm_setzero_pd();\n        for (size_t j = 0; j < cols; j += 2) {\n            __m128d val = _mm_loadu_pd(&matrix[i * cols + j]);\n            val = _mm_mul_pd(val, val);\n            sum = _mm_add_pd(sum, val);\n        }\n        double norm_squared = _mm_cvtsd_f64(_mm_hadd_pd(sum, sum));\n        result[i] = norm_squared > thresholds[i];\n    }\n}\n```"}
{"task_id": "SimdBench_39_SSE", "completion": "```cpp\nvoid matrix_row_norm_compare_simd(const double* matrix, const double* thresholds, size_t rows, size_t cols, bool* result) {\n    for (size_t i = 0; i < rows; ++i) {\n        __m128d sum = _mm_setzero_pd();\n        for (size_t j = 0; j < cols; j += 2) {\n            __m128d val = _mm_loadu_pd(&matrix[i * cols + j]);\n            val = _mm_mul_pd(val, val);\n            sum = _mm_add_pd(sum, val);\n        }\n        double norm_squared = _mm_cvtsd_f64(_mm_hadd_pd(sum, sum));\n        result[i] = norm_squared > thresholds[i];\n    }\n}\n```"}
{"task_id": "SimdBench_39_SSE", "completion": "```c\nvoid matrix_row_norm_compare_simd(const double* matrix, const double* thresholds, size_t rows, size_t cols, bool* result) {\n    for (size_t i = 0; i < rows; ++i) {\n        __m128d sum = _mm_setzero_pd();\n        for (size_t j = 0; j < cols; j += 2) {\n            __m128d val = _mm_loadu_pd(&matrix[i * cols + j]);\n            val = _mm_mul_pd(val, val);\n            sum = _mm_add_pd(sum, val);\n        }\n        double norm_squared = _mm_cvtsd_f64(_mm_hadd_pd(sum, sum));\n        result[i] = (norm_squared > thresholds[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_40_SSE", "completion": "```cpp\nvoid tensor_bitwise_or_simd(const uint32_t* A, const uint32_t* B, uint32_t* C, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 4; i += 4) {\n        __m128i a = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i b = _mm_loadu_si128((__m128i*)&B[i]);\n        __m128i result = _mm_or_si128(a, b);\n        _mm_storeu_si128((__m128i*)&C[i], result);\n    }\n    for (; i < length; ++i) {\n        C[i] = A[i] | B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_40_SSE", "completion": "```cpp\nvoid tensor_bitwise_or_simd(const uint32_t* A, const uint32_t* B, uint32_t* C, size_t length) {\n    size_t i;\n    for (i = 0; i <= length - 4; i += 4) {\n        __m128i a = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i b = _mm_loadu_si128((__m128i*)&B[i]);\n        __m128i result = _mm_or_si128(a, b);\n        _mm_storeu_si128((__m128i*)&C[i], result);\n    }\n    for (; i < length; ++i) {\n        C[i] = A[i] | B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_40_SSE", "completion": "```c\nvoid tensor_bitwise_or_simd(const uint32_t* A, const uint32_t* B, uint32_t* C, size_t length) {\n    size_t i;\n    for (i = 0; i <= length - 4; i += 4) {\n        __m128i a = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i b = _mm_loadu_si128((__m128i*)&B[i]);\n        __m128i result = _mm_or_si128(a, b);\n        _mm_storeu_si128((__m128i*)&C[i], result);\n    }\n    for (; i < length; ++i) {\n        C[i] = A[i] | B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_40_SSE", "completion": "```cpp\nvoid tensor_bitwise_or_simd(const uint32_t* A, const uint32_t* B, uint32_t* C, size_t length) {\n    size_t i;\n    for (i = 0; i <= length - 4; i += 4) {\n        __m128i a = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i b = _mm_loadu_si128((__m128i*)&B[i]);\n        __m128i result = _mm_or_si128(a, b);\n        _mm_storeu_si128((__m128i*)&C[i], result);\n    }\n    for (; i < length; ++i) {\n        C[i] = A[i] | B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_40_SSE", "completion": "```cpp\nvoid tensor_bitwise_or_simd(const uint32_t* A, const uint32_t* B, uint32_t* C, size_t length) {\n    size_t i;\n    for (i = 0; i <= length - 4; i += 4) {\n        __m128i a = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i b = _mm_loadu_si128((__m128i*)&B[i]);\n        __m128i result = _mm_or_si128(a, b);\n        _mm_storeu_si128((__m128i*)&C[i], result);\n    }\n    for (; i < length; ++i) {\n        C[i] = A[i] | B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_41_SSE", "completion": "```c\nint64_t squarediff_simd(const int8_t * A, const int8_t * B, size_t length) {\n    __m128i sum_squares = _mm_setzero_si128();\n    __m128i sum_products = _mm_setzero_si128();\n\n    for (size_t i = 0; i < length; i += 16) {\n        __m128i a = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i b = _mm_loadu_si128((__m128i*)&B[i]);\n\n        __m128i a_squared = _mm_mullo_epi16(a, a);\n        __m128i b_squared = _mm_mullo_epi16(b, b);\n        __m128i ab_product = _mm_mullo_epi16(a, b);\n\n        sum_squares = _mm_add_epi32(sum_squares, _mm_unpacklo_epi16(a_squared, b_squared));\n        sum_squares = _mm_add_epi32(sum_squares, _mm_unpackhi_epi16(a_squared, b_squared));\n        sum_products = _mm_add_epi32(sum_products, _mm_unpacklo_epi16(ab_product, ab_product));\n        sum_products = _mm_add_epi32(sum_products, _mm_unpackhi_epi16(ab_product, ab_product));\n    }\n\n    int32_t sum_squares_array[4];\n    int32_t sum_products_array[4];\n    _mm_storeu_si128((__m128i*)sum_squares_array, sum_squares);\n    _mm_storeu_si128((__m128i*)sum_products_array, sum_products);\n\n    int64_t sum_squares_total = 0;\n    int64_t sum_products_total = 0;\n    for (int i = 0; i < 4; ++i) {\n        sum_squares_total += sum_squares_array[i];\n        sum_products_total += sum_products_array[i];\n    }\n\n    return sum_squares_total - sum_products_total;\n}\n```"}
{"task_id": "SimdBench_41_SSE", "completion": "```c\nint64_t squarediff_simd(const int8_t * A, const int8_t * B, size_t length) {\n    __m128i sum_squares = _mm_setzero_si128();\n    __m128i sum_products = _mm_setzero_si128();\n\n    for (size_t i = 0; i < length; i += 16) {\n        __m128i a = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i b = _mm_loadu_si128((__m128i*)&B[i]);\n\n        __m128i a_squared = _mm_mullo_epi16(a, a);\n        __m128i b_squared = _mm_mullo_epi16(b, b);\n        __m128i ab_product = _mm_mullo_epi16(a, b);\n\n        sum_squares = _mm_add_epi32(sum_squares, _mm_unpacklo_epi16(a_squared, b_squared));\n        sum_squares = _mm_add_epi32(sum_squares, _mm_unpackhi_epi16(a_squared, b_squared));\n        sum_products = _mm_add_epi32(sum_products, _mm_unpacklo_epi16(ab_product, _mm_setzero_si128()));\n        sum_products = _mm_add_epi32(sum_products, _mm_unpackhi_epi16(ab_product, _mm_setzero_si128()));\n    }\n\n    int32_t sum_squares_arr[4];\n    int32_t sum_products_arr[4];\n    _mm_storeu_si128((__m128i*)sum_squares_arr, sum_squares);\n    _mm_storeu_si128((__m128i*)sum_products_arr, sum_products);\n\n    int64_t sum_squares_total = sum_squares_arr[0] + sum_squares_arr[1] + sum_squares_arr[2] + sum_squares_arr[3];\n    int64_t sum_products_total = sum_products_arr[0] + sum_products_arr[1] + sum_products_arr[2] + sum_products_arr[3];\n\n    return sum_squares_total - sum_products_total;\n}\n```"}
{"task_id": "SimdBench_41_SSE", "completion": "```c\nint64_t squarediff_simd(const int8_t * A, const int8_t * B, size_t length) {\n    __m128i sum_squares = _mm_setzero_si128();\n    __m128i sum_products = _mm_setzero_si128();\n    __m128i zero = _mm_setzero_si128();\n\n    for (size_t i = 0; i < length; i += 16) {\n        __m128i a = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i b = _mm_loadu_si128((__m128i*)&B[i]);\n\n        __m128i a_squared = _mm_mullo_epi16(a, a);\n        __m128i b_squared = _mm_mullo_epi16(b, b);\n        __m128i ab_product = _mm_mullo_epi16(a, b);\n\n        __m128i a_squared_lo = _mm_unpacklo_epi8(a_squared, zero);\n        __m128i a_squared_hi = _mm_unpackhi_epi8(a_squared, zero);\n        __m128i b_squared_lo = _mm_unpacklo_epi8(b_squared, zero);\n        __m128i b_squared_hi = _mm_unpackhi_epi8(b_squared, zero);\n        __m128i ab_product_lo = _mm_unpacklo_epi8(ab_product, zero);\n        __m128i ab_product_hi = _mm_unpackhi_epi8(ab_product, zero);\n\n        sum_squares = _mm_add_epi32(sum_squares, _mm_add_epi32(a_squared_lo, b_squared_lo));\n        sum_squares = _mm_add_epi32(sum_squares, _mm_add_epi32(a_squared_hi, b_squared_hi));\n        sum_products = _mm_add_epi32(sum_products, _mm_add_epi32(ab_product_lo, ab_product_hi));\n    }\n\n    int32_t sum_squares_arr[4];\n    int32_t sum_products_arr[4];\n    _mm_storeu_si128((__m128i*)sum_squares_arr, sum_squares);\n    _mm_storeu_si128((__m128i*)sum_products_arr, sum_products);\n\n    int64_t sum_squares_total = 0;\n    int64_t sum_products_total = 0;\n    for (int i = 0; i < 4; ++i) {\n        sum_squares_total += sum_squares_arr[i];\n        sum_products_total += sum_products_arr[i];\n    }\n\n    return sum_squares_total - sum_products_total;\n}\n```"}
{"task_id": "SimdBench_41_SSE", "completion": "```c\nint64_t squarediff_simd(const int8_t * A, const int8_t * B, size_t length) {\n    __m128i sum_squares = _mm_setzero_si128();\n    __m128i sum_products = _mm_setzero_si128();\n    __m128i zero = _mm_setzero_si128();\n\n    for (size_t i = 0; i < length; i += 16) {\n        __m128i a = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i b = _mm_loadu_si128((__m128i*)&B[i]);\n\n        __m128i a_squared = _mm_mullo_epi16(a, a);\n        __m128i b_squared = _mm_mullo_epi16(b, b);\n        __m128i ab_product = _mm_mullo_epi16(a, b);\n\n        __m128i a_squared_lo = _mm_unpacklo_epi8(a_squared, zero);\n        __m128i a_squared_hi = _mm_unpackhi_epi8(a_squared, zero);\n        __m128i b_squared_lo = _mm_unpacklo_epi8(b_squared, zero);\n        __m128i b_squared_hi = _mm_unpackhi_epi8(b_squared, zero);\n        __m128i ab_product_lo = _mm_unpacklo_epi8(ab_product, zero);\n        __m128i ab_product_hi = _mm_unpackhi_epi8(ab_product, zero);\n\n        sum_squares = _mm_add_epi32(sum_squares, _mm_add_epi32(a_squared_lo, a_squared_hi));\n        sum_squares = _mm_add_epi32(sum_squares, _mm_add_epi32(b_squared_lo, b_squared_hi));\n        sum_products = _mm_add_epi32(sum_products, _mm_add_epi32(ab_product_lo, ab_product_hi));\n    }\n\n    int32_t sum_squares_arr[4];\n    int32_t sum_products_arr[4];\n    _mm_storeu_si128((__m128i*)sum_squares_arr, sum_squares);\n    _mm_storeu_si128((__m128i*)sum_products_arr, sum_products);\n\n    int64_t sum_squares_total = 0;\n    int64_t sum_products_total = 0;\n    for (int i = 0; i < 4; ++i) {\n        sum_squares_total += sum_squares_arr[i];\n        sum_products_total += sum_products_arr[i];\n    }\n\n    return sum_squares_total - sum_products_total;\n}\n```"}
{"task_id": "SimdBench_41_SSE", "completion": "```c\nint64_t squarediff_simd(const int8_t * A, const int8_t * B, size_t length) {\n    __m128i sum_squares = _mm_setzero_si128();\n    __m128i sum_products = _mm_setzero_si128();\n\n    for (size_t i = 0; i < length; i += 16) {\n        __m128i a = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i b = _mm_loadu_si128((__m128i*)&B[i]);\n\n        __m128i a_squared = _mm_mullo_epi16(a, a);\n        __m128i b_squared = _mm_mullo_epi16(b, b);\n        __m128i ab_product = _mm_mullo_epi16(a, b);\n\n        sum_squares = _mm_add_epi32(sum_squares, _mm_unpacklo_epi16(a_squared, b_squared));\n        sum_squares = _mm_add_epi32(sum_squares, _mm_unpackhi_epi16(a_squared, b_squared));\n        sum_products = _mm_add_epi32(sum_products, _mm_unpacklo_epi16(ab_product, _mm_setzero_si128()));\n        sum_products = _mm_add_epi32(sum_products, _mm_unpackhi_epi16(ab_product, _mm_setzero_si128()));\n    }\n\n    int32_t sum_squares_array[4];\n    int32_t sum_products_array[4];\n    _mm_storeu_si128((__m128i*)sum_squares_array, sum_squares);\n    _mm_storeu_si128((__m128i*)sum_products_array, sum_products);\n\n    int64_t sum_squares_total = 0;\n    int64_t sum_products_total = 0;\n    for (int i = 0; i < 4; ++i) {\n        sum_squares_total += sum_squares_array[i];\n        sum_products_total += sum_products_array[i];\n    }\n\n    return sum_squares_total - sum_products_total;\n}\n```"}
{"task_id": "SimdBench_42_SSE", "completion": "```cpp\nvoid tensor_bit_clear_simd(const uint64_t* A, const uint64_t* B, uint64_t* C, size_t length) {\n    size_t i = 0;\n    for (; i + 1 < length; i += 2) {\n        __m128i a = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i b = _mm_loadu_si128((__m128i*)&B[i]);\n        __m128i not_b = _mm_andnot_si128(b, _mm_set1_epi64x(-1));\n        __m128i result = _mm_and_si128(a, not_b);\n        _mm_storeu_si128((__m128i*)&C[i], result);\n    }\n    for (; i < length; ++i) {\n        C[i] = A[i] & ~B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_42_SSE", "completion": "```cpp\nvoid tensor_bit_clear_simd(const uint64_t* A, const uint64_t* B, uint64_t* C, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 2; i += 2) {\n        __m128i a = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i b = _mm_loadu_si128((__m128i*)&B[i]);\n        __m128i not_b = _mm_andnot_si128(b, _mm_set1_epi64x(-1));\n        __m128i result = _mm_and_si128(a, not_b);\n        _mm_storeu_si128((__m128i*)&C[i], result);\n    }\n    for (; i < length; ++i) {\n        C[i] = A[i] & ~B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_42_SSE", "completion": "```c\nvoid tensor_bit_clear_simd(const uint64_t* A, const uint64_t* B, uint64_t* C, size_t length) {\n    size_t i;\n    for (i = 0; i < length; i += 2) {\n        __m128i a = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i b = _mm_loadu_si128((__m128i*)&B[i]);\n        __m128i not_b = _mm_andnot_si128(b, _mm_set1_epi64x(-1));\n        __m128i result = _mm_and_si128(a, not_b);\n        _mm_storeu_si128((__m128i*)&C[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_42_SSE", "completion": "```c\nvoid tensor_bit_clear_simd(const uint64_t* A, const uint64_t* B, uint64_t* C, size_t length) {\n    size_t i;\n    for (i = 0; i < length; i += 2) {\n        __m128i a = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i b = _mm_loadu_si128((__m128i*)&B[i]);\n        __m128i not_b = _mm_andnot_si128(b, _mm_set1_epi64x(-1));\n        __m128i result = _mm_and_si128(a, not_b);\n        _mm_storeu_si128((__m128i*)&C[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_42_SSE", "completion": "```c\nvoid tensor_bit_clear_simd(const uint64_t* A, const uint64_t* B, uint64_t* C, size_t length) {\n    size_t i = 0;\n    for (; i + 1 < length; i += 2) {\n        __m128i a = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i b = _mm_loadu_si128((__m128i*)&B[i]);\n        __m128i not_b = _mm_andnot_si128(b, _mm_set1_epi64x(-1));\n        __m128i result = _mm_and_si128(a, not_b);\n        _mm_storeu_si128((__m128i*)&C[i], result);\n    }\n    for (; i < length; ++i) {\n        C[i] = A[i] & ~B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_43_SSE", "completion": "```cpp\nvoid tensor_three_valued_logic_simd(const int8_t* A, const int8_t* B, int8_t* C, size_t length) {\n    size_t i = 0;\n    __m128i mask_pos = _mm_set1_epi8(0x80);\n    __m128i mask_neg = _mm_set1_epi8(0x7F);\n    __m128i zero = _mm_setzero_si128();\n    __m128i one = _mm_set1_epi8(1);\n    __m128i neg_one = _mm_set1_epi8(-1);\n\n    for (; i <= length - 16; i += 16) {\n        __m128i a = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i b = _mm_loadu_si128((__m128i*)&B[i]);\n\n        __m128i a_pos = _mm_andnot_si128(mask_pos, a);\n        __m128i b_pos = _mm_andnot_si128(mask_pos, b);\n        __m128i both_pos = _mm_and_si128(a_pos, b_pos);\n        __m128i both_pos_mask = _mm_cmpeq_epi8(both_pos, zero);\n        __m128i result_pos = _mm_andnot_si128(both_pos_mask, one);\n\n        __m128i a_neg = _mm_and_si128(mask_neg, a);\n        __m128i b_neg = _mm_and_si128(mask_neg, b);\n        __m128i both_neg = _mm_and_si128(a_neg, b_neg);\n        __m128i both_neg_mask = _mm_cmpeq_epi8(both_neg, zero);\n        __m128i result_neg = _mm_andnot_si128(both_neg_mask, neg_one);\n\n        __m128i result = _mm_or_si128(result_pos, result_neg);\n        _mm_storeu_si128((__m128i*)&C[i], result);\n    }\n\n    for (; i < length; ++i) {\n        if (A[i] > 0 && B[i] > 0) {\n            C[i] = 1;\n        } else if (A[i] < 0 && B[i] < 0) {\n            C[i] = -1;\n        } else {\n            C[i] = 0;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_43_SSE", "completion": "```cpp\nvoid tensor_three_valued_logic_simd(const int8_t* A, const int8_t* B, int8_t* C, size_t length) {\n    size_t i = 0;\n    __m128i mask_positive = _mm_set1_epi8(0x80);\n    __m128i mask_negative = _mm_set1_epi8(0x7F);\n    __m128i zero = _mm_setzero_si128();\n    __m128i one = _mm_set1_epi8(1);\n    __m128i minus_one = _mm_set1_epi8(-1);\n\n    for (; i <= length - 16; i += 16) {\n        __m128i a = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i b = _mm_loadu_si128((__m128i*)&B[i]);\n\n        __m128i a_positive = _mm_andnot_si128(mask_positive, a);\n        __m128i b_positive = _mm_andnot_si128(mask_positive, b);\n        __m128i a_negative = _mm_and_si128(mask_negative, a);\n        __m128i b_negative = _mm_and_si128(mask_negative, b);\n\n        __m128i both_positive = _mm_and_si128(a_positive, b_positive);\n        __m128i both_negative = _mm_and_si128(a_negative, b_negative);\n\n        __m128i result = _mm_or_si128(\n            _mm_and_si128(_mm_cmpeq_epi8(both_positive, zero), one),\n            _mm_and_si128(_mm_cmpeq_epi8(both_negative, zero), minus_one)\n        );\n\n        _mm_storeu_si128((__m128i*)&C[i], result);\n    }\n\n    for (; i < length; ++i) {\n        if (A[i] > 0 && B[i] > 0) {\n            C[i] = 1;\n        } else if (A[i] < 0 && B[i] < 0) {\n            C[i] = -1;\n        } else {\n            C[i] = 0;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_43_SSE", "completion": "```cpp\nvoid tensor_three_valued_logic_simd(const int8_t* A, const int8_t* B, int8_t* C, size_t length) {\n    size_t i = 0;\n    __m128i mask_positive = _mm_set1_epi8(0x80);\n    __m128i mask_negative = _mm_set1_epi8(0x7F);\n    __m128i zero = _mm_setzero_si128();\n    __m128i one = _mm_set1_epi8(1);\n    __m128i neg_one = _mm_set1_epi8(-1);\n\n    for (; i <= length - 16; i += 16) {\n        __m128i a = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i b = _mm_loadu_si128((__m128i*)&B[i]);\n\n        __m128i a_pos = _mm_andnot_si128(mask_positive, a);\n        __m128i b_pos = _mm_andnot_si128(mask_positive, b);\n        __m128i a_neg = _mm_and_si128(mask_negative, a);\n        __m128i b_neg = _mm_and_si128(mask_negative, b);\n\n        __m128i both_pos = _mm_and_si128(a_pos, b_pos);\n        __m128i both_neg = _mm_and_si128(a_neg, b_neg);\n\n        __m128i result = _mm_or_si128(\n            _mm_and_si128(_mm_cmpeq_epi8(both_pos, zero), one),\n            _mm_and_si128(_mm_cmpeq_epi8(both_neg, zero), neg_one)\n        );\n\n        _mm_storeu_si128((__m128i*)&C[i], result);\n    }\n\n    for (; i < length; ++i) {\n        if (A[i] > 0 && B[i] > 0) {\n            C[i] = 1;\n        } else if (A[i] < 0 && B[i] < 0) {\n            C[i] = -1;\n        } else {\n            C[i] = 0;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_43_SSE", "completion": "```c\nvoid tensor_three_valued_logic_simd(const int8_t* A, const int8_t* B, int8_t* C, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 16; i += 16) {\n        __m128i a = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i b = _mm_loadu_si128((__m128i*)&B[i]);\n\n        __m128i pos_mask = _mm_cmpgt_epi8(a, _mm_setzero_si128());\n        pos_mask = _mm_and_si128(pos_mask, _mm_cmpgt_epi8(b, _mm_setzero_si128()));\n        pos_mask = _mm_and_si128(pos_mask, _mm_set1_epi8(1));\n\n        __m128i neg_mask = _mm_cmplt_epi8(a, _mm_setzero_si128());\n        neg_mask = _mm_and_si128(neg_mask, _mm_cmplt_epi8(b, _mm_setzero_si128()));\n        neg_mask = _mm_and_si128(neg_mask, _mm_set1_epi8(-1));\n\n        __m128i result = _mm_or_si128(pos_mask, neg_mask);\n\n        _mm_storeu_si128((__m128i*)&C[i], result);\n    }\n\n    for (; i < length; ++i) {\n        if (A[i] > 0 && B[i] > 0) {\n            C[i] = 1;\n        } else if (A[i] < 0 && B[i] < 0) {\n            C[i] = -1;\n        } else {\n            C[i] = 0;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_43_SSE", "completion": "```c\nvoid tensor_three_valued_logic_simd(const int8_t* A, const int8_t* B, int8_t* C, size_t length) {\n    size_t i;\n    for (i = 0; i < length; i += 16) {\n        __m128i a = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i b = _mm_loadu_si128((__m128i*)&B[i]);\n\n        __m128i pos_mask = _mm_cmpgt_epi8(a, _mm_setzero_si128());\n        __m128i neg_mask = _mm_cmpgt_epi8(_mm_setzero_si128(), a);\n\n        __m128i b_pos_mask = _mm_cmpgt_epi8(b, _mm_setzero_si128());\n        __m128i b_neg_mask = _mm_cmpgt_epi8(_mm_setzero_si128(), b);\n\n        __m128i both_pos = _mm_and_si128(pos_mask, b_pos_mask);\n        __m128i both_neg = _mm_and_si128(neg_mask, b_neg_mask);\n\n        __m128i result = _mm_or_si128(\n            _mm_and_si128(both_pos, _mm_set1_epi8(1)),\n            _mm_and_si128(both_neg, _mm_set1_epi8(-1))\n        );\n\n        _mm_storeu_si128((__m128i*)&C[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_44_SSE", "completion": "```c\nvoid tensor_bit_op_simd(const uint16_t* A, const uint16_t* B, uint16_t* C, size_t length) {\n    size_t midpoint = length / 2;\n    size_t i;\n\n    for (i = 0; i < midpoint; i += 4) {\n        __m128i a = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i b = _mm_loadu_si128((__m128i*)&B[i]);\n\n        __m128i xor_result = _mm_xor_si128(a, b);\n        __m128i and_result = _mm_and_si128(a, b);\n\n        _mm_storeu_si128((__m128i*)&C[i], xor_result);\n        _mm_storeu_si128((__m128i*)&C[i + 4], and_result);\n    }\n\n    for (; i < length; ++i) {\n        C[i] = A[i];\n    }\n}\n```"}
{"task_id": "SimdBench_44_SSE", "completion": "```c\nvoid tensor_bit_op_simd(const uint16_t* A, const uint16_t* B, uint16_t* C, size_t length) {\n    size_t midpoint = length / 2;\n    size_t i;\n\n    for (i = 0; i < midpoint; i += 8) {\n        __m128i a = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i b = _mm_loadu_si128((__m128i*)&B[i]);\n\n        __m128i xor_result = _mm_xor_si128(a, b);\n        __m128i and_result = _mm_and_si128(a, b);\n\n        _mm_storeu_si128((__m128i*)&C[i], xor_result);\n        _mm_storeu_si128((__m128i*)&C[i + 8], and_result);\n    }\n\n    for (; i < length; ++i) {\n        C[i] = A[i];\n    }\n}\n```"}
{"task_id": "SimdBench_44_SSE", "completion": "```cpp\nvoid tensor_bit_op_simd(const uint16_t* A, const uint16_t* B, uint16_t* C, size_t length) {\n    size_t midpoint = length / 2;\n    size_t i;\n\n    for (i = 0; i < midpoint; i += 8) {\n        __m128i a = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i b = _mm_loadu_si128((__m128i*)&B[i]);\n        __m128i xor_result = _mm_xor_si128(a, b);\n        __m128i and_result = _mm_and_si128(a, b);\n        _mm_storeu_si128((__m128i*)&C[i], xor_result);\n        _mm_storeu_si128((__m128i*)&C[i + 8], and_result);\n    }\n\n    for (; i < length; ++i) {\n        C[i] = A[i];\n    }\n}\n```"}
{"task_id": "SimdBench_44_SSE", "completion": "```c\nvoid tensor_bit_op_simd(const uint16_t* A, const uint16_t* B, uint16_t* C, size_t length) {\n    size_t midpoint = length / 2;\n    size_t i;\n\n    for (i = 0; i < midpoint; i += 4) {\n        __m128i a = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i b = _mm_loadu_si128((__m128i*)&B[i]);\n        __m128i xor_result = _mm_xor_si128(a, b);\n        __m128i and_result = _mm_and_si128(a, b);\n        _mm_storeu_si128((__m128i*)&C[i], xor_result);\n        _mm_storeu_si128((__m128i*)&C[midpoint + i], and_result);\n    }\n\n    for (i = midpoint; i < length; i++) {\n        C[i] = A[i];\n    }\n}\n```"}
{"task_id": "SimdBench_44_SSE", "completion": "```cpp\nvoid tensor_bit_op_simd(const uint16_t* A, const uint16_t* B, uint16_t* C, size_t length) {\n    size_t midpoint = length / 2;\n    size_t i;\n\n    for (i = 0; i < midpoint; i += 8) {\n        __m128i a = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i b = _mm_loadu_si128((__m128i*)&B[i]);\n        __m128i xor_result = _mm_xor_si128(a, b);\n        __m128i and_result = _mm_and_si128(a, b);\n        _mm_storeu_si128((__m128i*)&C[i], xor_result);\n        _mm_storeu_si128((__m128i*)&C[i + 8], and_result);\n    }\n\n    for (; i < length; ++i) {\n        C[i] = A[i];\n    }\n}\n```"}
{"task_id": "SimdBench_45_SSE", "completion": "```cpp\nvoid tensor_multi_select_simd(const float* A, const float* B, const float* C, const float* D, const bool* cond1, const bool* cond2, float* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t i;\n\n    for (i = 0; i <= total_elements - 4; i += 4) {\n        __m128 a = _mm_loadu_ps(&A[i]);\n        __m128 b = _mm_loadu_ps(&B[i]);\n        __m128 c = _mm_loadu_ps(&C[i]);\n        __m128 d = _mm_loadu_ps(&D[i]);\n\n        __m128i cond1_vec = _mm_loadu_si128((__m128i*)&cond1[i]);\n        __m128i cond2_vec = _mm_loadu_si128((__m128i*)&cond2[i]);\n\n        __m128i mask1 = _mm_cmpeq_epi32(cond1_vec, _mm_set1_epi32(-1));\n        __m128i mask2 = _mm_cmpeq_epi32(cond2_vec, _mm_set1_epi32(-1));\n\n        __m128i mask1_and_mask2 = _mm_and_si128(mask1, mask2);\n        __m128i mask1_and_not_mask2 = _mm_andnot_si128(mask2, mask1);\n        __m128i not_mask1_and_mask2 = _mm_andnot_si128(mask1, mask2);\n        __m128i not_mask1_and_not_mask2 = _mm_andnot_si128(mask1, _mm_andnot_si128(mask2, _mm_set1_epi32(-1)));\n\n        __m128 result = _mm_or_ps(\n            _mm_or_ps(\n                _mm_and_ps(_mm_castsi128_ps(mask1_and_mask2), a),\n                _mm_and_ps(_mm_castsi128_ps(mask1_and_not_mask2), b)\n            ),\n            _mm_or_ps(\n                _mm_and_ps(_mm_castsi128_ps(not_mask1_and_mask2), c),\n                _mm_and_ps(_mm_castsi128_ps(not_mask1_and_not_mask2), d)\n            )\n        );\n\n        _mm_storeu_ps(&out[i], result);\n    }\n\n    for (; i < total_elements; ++i) {\n        if (cond1[i] && cond2[i]) {\n            out[i] = A[i];\n        } else if (cond1[i] && !cond2[i]) {\n            out[i] = B[i];\n        } else if (!cond1[i] && cond2[i]) {\n            out[i] = C[i];\n        } else {\n            out[i] = D[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_45_SSE", "completion": "```c\nvoid tensor_multi_select_simd(const float* A, const float* B, const float* C, const float* D, const bool* cond1, const bool* cond2, float* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t i;\n\n    for (i = 0; i < total_elements; i += 4) {\n        __m128 a = _mm_loadu_ps(&A[i]);\n        __m128 b = _mm_loadu_ps(&B[i]);\n        __m128 c = _mm_loadu_ps(&C[i]);\n        __m128 d = _mm_loadu_ps(&D[i]);\n\n        __m128i c1 = _mm_loadu_si128((__m128i*)&cond1[i]);\n        __m128i c2 = _mm_loadu_si128((__m128i*)&cond2[i]);\n\n        __m128i mask1 = _mm_and_si128(c1, c2);\n        __m128i mask2 = _mm_andnot_si128(c2, c1);\n        __m128i mask3 = _mm_andnot_si128(c1, c2);\n        __m128i mask4 = _mm_andnot_si128(c1, _mm_andnot_si128(c2, _mm_set1_epi32(-1)));\n\n        __m128 result = _mm_or_ps(\n            _mm_or_ps(\n                _mm_and_ps(_mm_castsi128_ps(mask1), a),\n                _mm_and_ps(_mm_castsi128_ps(mask2), b)\n            ),\n            _mm_or_ps(\n                _mm_and_ps(_mm_castsi128_ps(mask3), c),\n                _mm_and_ps(_mm_castsi128_ps(mask4), d)\n            )\n        );\n\n        _mm_storeu_ps(&out[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_45_SSE", "completion": "```cpp\nvoid tensor_multi_select_simd(const float* A, const float* B, const float* C, const float* D, const bool* cond1, const bool* cond2, float* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t i;\n\n    for (i = 0; i <= total_elements - 4; i += 4) {\n        __m128 a = _mm_loadu_ps(&A[i]);\n        __m128 b = _mm_loadu_ps(&B[i]);\n        __m128 c = _mm_loadu_ps(&C[i]);\n        __m128 d = _mm_loadu_ps(&D[i]);\n\n        __m128i cond1_vec = _mm_loadu_si128((__m128i*)&cond1[i]);\n        __m128i cond2_vec = _mm_loadu_si128((__m128i*)&cond2[i]);\n\n        __m128i mask1 = _mm_and_si128(cond1_vec, cond2_vec);\n        __m128i mask2 = _mm_andnot_si128(cond2_vec, cond1_vec);\n        __m128i mask3 = _mm_andnot_si128(cond1_vec, cond2_vec);\n        __m128i mask4 = _mm_andnot_si128(cond1_vec, _mm_andnot_si128(cond2_vec, _mm_set1_epi32(-1)));\n\n        __m128 result = _mm_or_ps(\n            _mm_or_ps(\n                _mm_and_ps(_mm_castsi128_ps(mask1), a),\n                _mm_and_ps(_mm_castsi128_ps(mask2), b)\n            ),\n            _mm_or_ps(\n                _mm_and_ps(_mm_castsi128_ps(mask3), c),\n                _mm_and_ps(_mm_castsi128_ps(mask4), d)\n            )\n        );\n\n        _mm_storeu_ps(&out[i], result);\n    }\n\n    for (; i < total_elements; ++i) {\n        if (cond1[i] && cond2[i]) {\n            out[i] = A[i];\n        } else if (cond1[i] && !cond2[i]) {\n            out[i] = B[i];\n        } else if (!cond1[i] && cond2[i]) {\n            out[i] = C[i];\n        } else {\n            out[i] = D[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_45_SSE", "completion": "```c\nvoid tensor_multi_select_simd(const float* A, const float* B, const float* C, const float* D, const bool* cond1, const bool* cond2, float* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t i;\n\n    for (i = 0; i < total_elements; i += 4) {\n        __m128 a = _mm_loadu_ps(&A[i]);\n        __m128 b = _mm_loadu_ps(&B[i]);\n        __m128 c = _mm_loadu_ps(&C[i]);\n        __m128 d = _mm_loadu_ps(&D[i]);\n\n        __m128i cond1_vec = _mm_loadu_si128((__m128i*)&cond1[i]);\n        __m128i cond2_vec = _mm_loadu_si128((__m128i*)&cond2[i]);\n\n        __m128i mask1 = _mm_cmpeq_epi32(cond1_vec, _mm_set1_epi32(1));\n        __m128i mask2 = _mm_cmpeq_epi32(cond2_vec, _mm_set1_epi32(1));\n\n        __m128i mask1_and_mask2 = _mm_and_si128(mask1, mask2);\n        __m128i mask1_and_not_mask2 = _mm_andnot_si128(mask2, mask1);\n        __m128i not_mask1_and_mask2 = _mm_andnot_si128(mask1, mask2);\n        __m128i not_mask1_and_not_mask2 = _mm_andnot_si128(mask1, _mm_andnot_si128(mask2, _mm_set1_epi32(-1)));\n\n        __m128 result = _mm_or_ps(\n            _mm_or_ps(\n                _mm_and_ps(_mm_castsi128_ps(mask1_and_mask2), a),\n                _mm_and_ps(_mm_castsi128_ps(mask1_and_not_mask2), b)\n            ),\n            _mm_or_ps(\n                _mm_and_ps(_mm_castsi128_ps(not_mask1_and_mask2), c),\n                _mm_and_ps(_mm_castsi128_ps(not_mask1_and_not_mask2), d)\n            )\n        );\n\n        _mm_storeu_ps(&out[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_45_SSE", "completion": "```c\nvoid tensor_multi_select_simd(const float* A, const float* B, const float* C, const float* D, const bool* cond1, const bool* cond2, float* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t i;\n\n    for (i = 0; i < total_elements; i += 4) {\n        __m128 a = _mm_loadu_ps(&A[i]);\n        __m128 b = _mm_loadu_ps(&B[i]);\n        __m128 c = _mm_loadu_ps(&C[i]);\n        __m128 d = _mm_loadu_ps(&D[i]);\n\n        __m128i c1 = _mm_loadu_si128((__m128i*)&cond1[i]);\n        __m128i c2 = _mm_loadu_si128((__m128i*)&cond2[i]);\n\n        __m128i mask1 = _mm_set1_epi32(0xFFFFFFFF);\n        __m128i mask2 = _mm_set1_epi32(0xFFFFFFFF);\n\n        __m128i cond1_true = _mm_and_si128(c1, mask1);\n        __m128i cond2_true = _mm_and_si128(c2, mask2);\n\n        __m128i cond1_false = _mm_andnot_si128(cond1_true, mask1);\n        __m128i cond2_false = _mm_andnot_si128(cond2_true, mask2);\n\n        __m128i cond1_true_and_cond2_true = _mm_and_si128(cond1_true, cond2_true);\n        __m128i cond1_true_and_cond2_false = _mm_and_si128(cond1_true, cond2_false);\n        __m128i cond1_false_and_cond2_true = _mm_and_si128(cond1_false, cond2_true);\n        __m128i cond1_false_and_cond2_false = _mm_and_si128(cond1_false, cond2_false);\n\n        __m128 result = _mm_or_ps(\n            _mm_and_ps(_mm_castsi128_ps(cond1_true_and_cond2_true), a),\n            _mm_or_ps(\n                _mm_and_ps(_mm_castsi128_ps(cond1_true_and_cond2_false), b),\n                _mm_or_ps(\n                    _mm_and_ps(_mm_castsi128_ps(cond1_false_and_cond2_true), c),\n                    _mm_and_ps(_mm_castsi128_ps(cond1_false_and_cond2_false), d)\n                )\n            )\n        );\n\n        _mm_storeu_ps(&out[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_46_SSE", "completion": "```cpp\nvoid tensor_bit_count_simd(const uint32_t* A, uint8_t* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t i = 0;\n\n    for (; i <= total_elements - 4; i += 4) {\n        __m128i a = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i count = _mm_setzero_si128();\n\n        count = _mm_add_epi8(count, _mm_and_si128(a, _mm_set1_epi32(0x01010101)));\n        a = _mm_srli_epi32(a, 1);\n        count = _mm_add_epi8(count, _mm_and_si128(a, _mm_set1_epi32(0x01010101)));\n        a = _mm_srli_epi32(a, 1);\n        count = _mm_add_epi8(count, _mm_and_si128(a, _mm_set1_epi32(0x01010101)));\n        a = _mm_srli_epi32(a, 1);\n        count = _mm_add_epi8(count, _mm_and_si128(a, _mm_set1_epi32(0x01010101)));\n        a = _mm_srli_epi32(a, 1);\n        count = _mm_add_epi8(count, _mm_and_si128(a, _mm_set1_epi32(0x01010101)));\n        a = _mm_srli_epi32(a, 1);\n        count = _mm_add_epi8(count, _mm_and_si128(a, _mm_set1_epi32(0x01010101)));\n        a = _mm_srli_epi32(a, 1);\n        count = _mm_add_epi8(count, _mm_and_si128(a, _mm_set1_epi32(0x01010101)));\n        a = _mm_srli_epi32(a, 1);\n        count = _mm_add_epi8(count, _mm_and_si128(a, _mm_set1_epi32(0x01010101)));\n\n        count = _mm_sad_epu8(count, _mm_setzero_si128());\n        _mm_storeu_si128((__m128i*)&out[i], count);\n    }\n\n    for (; i < total_elements; ++i) {\n        uint32_t val = A[i];\n        uint8_t count = 0;\n        while (val) {\n            count += val & 1;\n            val >>= 1;\n        }\n        out[i] = count;\n    }\n}\n```"}
{"task_id": "SimdBench_46_SSE", "completion": "```cpp\nvoid tensor_bit_count_simd(const uint32_t* A, uint8_t* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    __m128i mask = _mm_set1_epi8(0x01);\n    __m128i zero = _mm_setzero_si128();\n\n    for (size_t i = 0; i < total_elements; i += 4) {\n        __m128i a = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i count = _mm_setzero_si128();\n\n        for (int j = 0; j < 32; ++j) {\n            __m128i bit = _mm_and_si128(a, mask);\n            count = _mm_add_epi8(count, _mm_cmpeq_epi8(bit, mask));\n            a = _mm_srli_epi32(a, 1);\n        }\n\n        _mm_storeu_si128((__m128i*)&out[i], count);\n    }\n}\n```"}
{"task_id": "SimdBench_46_SSE", "completion": "```c\nvoid tensor_bit_count_simd(const uint32_t* A, uint8_t* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t i;\n\n    for (i = 0; i < total_elements; i += 4) {\n        __m128i a = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i count = _mm_setzero_si128();\n\n        count = _mm_add_epi8(count, _mm_and_si128(_mm_srli_epi32(a, 0), _mm_set1_epi32(1)));\n        count = _mm_add_epi8(count, _mm_and_si128(_mm_srli_epi32(a, 1), _mm_set1_epi32(1)));\n        count = _mm_add_epi8(count, _mm_and_si128(_mm_srli_epi32(a, 2), _mm_set1_epi32(1)));\n        count = _mm_add_epi8(count, _mm_and_si128(_mm_srli_epi32(a, 3), _mm_set1_epi32(1)));\n        count = _mm_add_epi8(count, _mm_and_si128(_mm_srli_epi32(a, 4), _mm_set1_epi32(1)));\n        count = _mm_add_epi8(count, _mm_and_si128(_mm_srli_epi32(a, 5), _mm_set1_epi32(1)));\n        count = _mm_add_epi8(count, _mm_and_si128(_mm_srli_epi32(a, 6), _mm_set1_epi32(1)));\n        count = _mm_add_epi8(count, _mm_and_si128(_mm_srli_epi32(a, 7), _mm_set1_epi32(1)));\n        count = _mm_add_epi8(count, _mm_and_si128(_mm_srli_epi32(a, 8), _mm_set1_epi32(1)));\n        count = _mm_add_epi8(count, _mm_and_si128(_mm_srli_epi32(a, 9), _mm_set1_epi32(1)));\n        count = _mm_add_epi8(count, _mm_and_si128(_mm_srli_epi32(a, 10), _mm_set1_epi32(1)));\n        count = _mm_add_epi8(count, _mm_and_si128(_mm_srli_epi32(a, 11), _mm_set1_epi32(1)));\n        count = _mm_add_epi8(count, _mm_and_si128(_mm_srli_epi32(a, 12), _mm_set1_epi32(1)));\n        count = _mm_add_epi8(count, _mm_and_si128(_mm_srli_epi32(a, 13), _mm_set1_epi32(1)));\n        count = _mm_add_epi8(count, _mm_and_si128(_mm_srli_epi32(a, 14), _mm_set1_epi32(1)));\n        count = _mm_add_epi8(count, _mm_and_si128(_mm_srli_epi32(a, 15), _mm_set1_epi32(1)));\n        count = _mm_add_epi8(count, _mm_and_si128(_mm_srli_epi32(a, 16), _mm_set1_epi32(1)));\n        count = _mm_add_epi8(count, _mm_and_si128(_mm_srli_epi32(a, 17), _mm_set1_epi32(1)));\n        count = _mm_add_epi8(count, _mm_and_si128(_mm_srli_epi32(a, 18), _mm_set1_epi32(1)));\n        count = _mm_add_epi8(count, _mm_and_si128(_mm_srli_epi32(a, 19), _mm_set1_epi32(1)));\n        count = _mm_add_epi8(count, _mm_and_si128(_mm_srli_epi32(a, 20), _mm_set1_epi32(1)));\n        count = _mm_add_epi8(count, _mm_and_si128(_mm_srli_epi32(a, 21), _mm_set1_epi32(1)));\n        count = _mm_add_epi8(count, _mm_and_si128(_mm_srli_epi32(a, 22), _mm_set1_epi32(1)));\n        count = _mm_add_epi8(count, _mm_and_si128(_mm_srli_epi32(a, 23), _mm_set1_epi32(1)));\n        count = _mm_add_epi8(count, _mm_and_si128(_mm_srli_epi32(a, 24), _mm_set1_epi32(1)));\n        count = _mm_add_epi8(count, _mm_and_si128(_mm_srli_epi32(a, 25), _mm_set1_epi32(1)));\n        count = _mm_add_epi8(count, _mm_and_si128(_mm_srli_epi32(a, 26), _mm_set1_epi32(1)));\n        count = _mm_add_epi8(count, _mm_and_si128(_mm_srli_epi32(a, 27), _mm_set1_epi32(1)));\n        count = _mm_add_epi8(count, _mm_and_si128(_mm_srli_epi32(a, 28), _mm_set1_epi32(1)));\n        count = _mm_add_epi8(count, _mm_and_si128(_mm_srli_epi32(a, 29), _mm_set1_epi32(1)));\n        count = _mm_add_epi8(count, _mm_and_si128(_mm_srli_epi32(a, 30), _mm_set1_epi32(1)));\n        count = _mm_add_epi8(count, _mm_and_si128(_mm_srli_epi32(a, 31), _mm_set1_epi32(1)));\n\n        count = _mm_sad_epu8(count, _mm_setzero_si128());\n        count = _mm_add_epi16(count, _mm_srli_si128(count, 8));\n\n        _mm_storel_epi64((__m128i*)&out[i], count);\n    }\n}\n```"}
{"task_id": "SimdBench_46_SSE", "completion": "```cpp\nvoid tensor_bit_count_simd(const uint32_t* A, uint8_t* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    __m128i mask = _mm_set1_epi8(0x01);\n\n    for (size_t i = 0; i < total_elements; i += 4) {\n        __m128i a = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i count = _mm_setzero_si128();\n\n        for (int j = 0; j < 4; ++j) {\n            __m128i bits = _mm_and_si128(a, mask);\n            count = _mm_add_epi8(count, bits);\n            a = _mm_srli_epi32(a, 1);\n        }\n\n        uint8_t counts[16];\n        _mm_storeu_si128((__m128i*)counts, count);\n\n        for (int j = 0; j < 4; ++j) {\n            out[i + j] = counts[j * 4] + counts[j * 4 + 1] + counts[j * 4 + 2] + counts[j * 4 + 3];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_46_SSE", "completion": "```cpp\nvoid tensor_bit_count_simd(const uint32_t* A, uint8_t* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    __m128i mask = _mm_set1_epi8(0x01);\n\n    for (size_t i = 0; i < total_elements; i += 4) {\n        __m128i a = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i count = _mm_setzero_si128();\n\n        for (int j = 0; j < 4; ++j) {\n            __m128i bits = _mm_and_si128(a, mask);\n            count = _mm_add_epi8(count, bits);\n            a = _mm_srli_epi32(a, 1);\n        }\n\n        count = _mm_sad_epu8(count, _mm_setzero_si128());\n        _mm_storeu_si32((int*)&out[i], _mm_cvtsi128_si32(count));\n    }\n}\n```"}
{"task_id": "SimdBench_47_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid matrix_conditional_abs_simd(const int* A, int* B, size_t rows, size_t cols) {\n    size_t size = rows * cols;\n    __m128i three = _mm_set1_epi32(3);\n    __m128i zero = _mm_setzero_si128();\n\n    for (size_t i = 0; i < size; i += 4) {\n        __m128i a = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i rem = _mm_rem_epi32(a, three);\n        __m128i mask = _mm_cmpeq_epi32(rem, zero);\n        __m128i abs_a = _mm_abs_epi32(a);\n        __m128i result = _mm_blendv_epi8(a, abs_a, mask);\n        _mm_storeu_si128((__m128i*)&B[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_47_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid matrix_conditional_abs_simd(const int* A, int* B, size_t rows, size_t cols) {\n    size_t size = rows * cols;\n    __m128i three = _mm_set1_epi32(3);\n    __m128i zero = _mm_setzero_si128();\n\n    for (size_t i = 0; i < size; i += 4) {\n        __m128i a = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i rem = _mm_rem_epi32(a, three);\n        __m128i mask = _mm_cmpeq_epi32(rem, zero);\n        __m128i abs_a = _mm_abs_epi32(a);\n        __m128i result = _mm_blendv_epi8(a, abs_a, mask);\n        _mm_storeu_si128((__m128i*)&B[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_47_SSE", "completion": "```cpp\nvoid matrix_conditional_abs_simd(const int* A, int* B, size_t rows, size_t cols) {\n    size_t size = rows * cols;\n    __m128i three = _mm_set1_epi32(3);\n    __m128i zero = _mm_setzero_si128();\n\n    for (size_t i = 0; i < size; i += 4) {\n        __m128i a = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i rem = _mm_rem_epi32(a, three);\n        __m128i mask = _mm_cmpeq_epi32(rem, zero);\n        __m128i abs_a = _mm_abs_epi32(a);\n        __m128i result = _mm_blendv_epi8(a, abs_a, mask);\n        _mm_storeu_si128((__m128i*)&B[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_47_SSE", "completion": "```c\nvoid matrix_conditional_abs_simd(const int* A, int* B, size_t rows, size_t cols) {\n    size_t size = rows * cols;\n    __m128i three = _mm_set1_epi32(3);\n    __m128i zero = _mm_setzero_si128();\n\n    for (size_t i = 0; i < size; i += 4) {\n        __m128i a = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i rem = _mm_rem_epi32(a, three);\n        __m128i mask = _mm_cmpeq_epi32(rem, zero);\n        __m128i abs_a = _mm_abs_epi32(a);\n        __m128i result = _mm_blendv_epi8(a, abs_a, mask);\n        _mm_storeu_si128((__m128i*)&B[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_47_SSE", "completion": "```cpp\nvoid matrix_conditional_abs_simd(const int* A, int* B, size_t rows, size_t cols) {\n    size_t size = rows * cols;\n    __m128i three = _mm_set1_epi32(3);\n    __m128i zero = _mm_setzero_si128();\n\n    for (size_t i = 0; i < size; i += 4) {\n        __m128i a = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i rem = _mm_rem_epi32(a, three);\n        __m128i mask = _mm_cmpeq_epi32(rem, zero);\n        __m128i abs_a = _mm_abs_epi32(a);\n        __m128i result = _mm_blendv_epi8(a, abs_a, mask);\n        _mm_storeu_si128((__m128i*)&B[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_48_SSE", "completion": "```c\nvoid matrix_conditional_bit_rotate_simd(const uint32_t* src, uint32_t* dst, uint8_t rotate_bits, size_t length) {\n    size_t i;\n    __m128i mask = _mm_set1_epi32(0xF);\n    __m128i rotate_mask = _mm_set1_epi32((1 << rotate_bits) - 1);\n    __m128i all_ones = _mm_set1_epi32(0xFFFFFFFF);\n\n    for (i = 0; i < length; i += 4) {\n        __m128i src_vec = _mm_loadu_si128((__m128i*)&src[i]);\n        __m128i low_bits = _mm_and_si128(src_vec, mask);\n        __m128i all_ones_mask = _mm_cmpeq_epi32(low_bits, mask);\n        __m128i rotated = _mm_or_si128(_mm_slli_epi32(src_vec, rotate_bits), _mm_srli_epi32(src_vec, 32 - rotate_bits));\n        __m128i negated = _mm_xor_si128(src_vec, all_ones);\n        __m128i result = _mm_blendv_epi8(negated, rotated, all_ones_mask);\n\n        _mm_storeu_si128((__m128i*)&dst[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_48_SSE", "completion": "```c\nvoid matrix_conditional_bit_rotate_simd(const uint32_t* src, uint32_t* dst, uint8_t rotate_bits, size_t length) {\n    size_t i;\n    __m128i mask = _mm_set1_epi32(0xF);\n    __m128i rotate_mask = _mm_set1_epi32((1 << rotate_bits) - 1);\n    __m128i all_ones = _mm_set1_epi32(0xFFFFFFFF);\n\n    for (i = 0; i < length; i += 4) {\n        __m128i src_vec = _mm_loadu_si128((__m128i*)&src[i]);\n        __m128i low_bits = _mm_and_si128(src_vec, mask);\n        __m128i condition = _mm_cmpeq_epi32(low_bits, mask);\n\n        __m128i rotated = _mm_or_si128(\n            _mm_slli_epi32(src_vec, rotate_bits),\n            _mm_srli_epi32(src_vec, 32 - rotate_bits)\n        );\n        rotated = _mm_and_si128(rotated, rotate_mask);\n\n        __m128i negated = _mm_xor_si128(src_vec, all_ones);\n\n        __m128i result = _mm_blendv_epi8(negated, rotated, condition);\n\n        _mm_storeu_si128((__m128i*)&dst[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_48_SSE", "completion": "```c\nvoid matrix_conditional_bit_rotate_simd(const uint32_t* src, uint32_t* dst, uint8_t rotate_bits, size_t length) {\n    __m128i mask = _mm_set1_epi32(0xF);\n    __m128i rotate_mask = _mm_set1_epi32((1 << rotate_bits) - 1);\n    __m128i all_ones = _mm_set1_epi32(0xFFFFFFFF);\n\n    for (size_t i = 0; i < length; i += 4) {\n        __m128i src_vec = _mm_loadu_si128((__m128i*)&src[i]);\n        __m128i low_bits = _mm_and_si128(src_vec, mask);\n        __m128i condition = _mm_cmpeq_epi32(low_bits, mask);\n\n        __m128i rotated = _mm_or_si128(\n            _mm_slli_epi32(src_vec, rotate_bits),\n            _mm_srli_epi32(src_vec, 32 - rotate_bits)\n        );\n        __m128i negated = _mm_xor_si128(src_vec, all_ones);\n\n        __m128i result = _mm_blendv_epi8(negated, rotated, condition);\n\n        _mm_storeu_si128((__m128i*)&dst[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_48_SSE", "completion": "```c\nvoid matrix_conditional_bit_rotate_simd(const uint32_t* src, uint32_t* dst, uint8_t rotate_bits, size_t length) {\n    __m128i mask = _mm_set1_epi32(0xF);\n    __m128i rotate_mask = _mm_set1_epi32((1 << rotate_bits) - 1);\n    __m128i all_ones = _mm_set1_epi32(0xFFFFFFFF);\n\n    for (size_t i = 0; i < length; i += 4) {\n        __m128i src_vec = _mm_loadu_si128((__m128i*)&src[i]);\n        __m128i low_bits = _mm_and_si128(src_vec, mask);\n        __m128i all_ones_mask = _mm_cmpeq_epi32(low_bits, mask);\n\n        __m128i rotated = _mm_or_si128(\n            _mm_slli_epi32(src_vec, rotate_bits),\n            _mm_srli_epi32(src_vec, 32 - rotate_bits)\n        );\n\n        __m128i negated = _mm_xor_si128(src_vec, all_ones);\n\n        __m128i result = _mm_blendv_epi8(negated, rotated, all_ones_mask);\n\n        _mm_storeu_si128((__m128i*)&dst[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_48_SSE", "completion": "```c\nvoid matrix_conditional_bit_rotate_simd(const uint32_t* src, uint32_t* dst, uint8_t rotate_bits, size_t length) {\n    __m128i mask = _mm_set1_epi32(0xF);\n    __m128i rotate_mask = _mm_set1_epi32((1 << rotate_bits) - 1);\n    __m128i all_ones = _mm_set1_epi32(0xFFFFFFFF);\n\n    for (size_t i = 0; i < length; i += 4) {\n        __m128i src_vec = _mm_loadu_si128((__m128i*)&src[i]);\n        __m128i low_bits = _mm_and_si128(src_vec, mask);\n        __m128i all_ones_mask = _mm_cmpeq_epi32(low_bits, mask);\n\n        __m128i rotated = _mm_or_si128(\n            _mm_slli_epi32(src_vec, rotate_bits),\n            _mm_srli_epi32(src_vec, 32 - rotate_bits)\n        );\n\n        __m128i negated = _mm_xor_si128(src_vec, all_ones);\n\n        __m128i result = _mm_blendv_epi8(negated, rotated, all_ones_mask);\n\n        _mm_storeu_si128((__m128i*)&dst[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_49_SSE", "completion": "```c\nvoid tensor_ternary_compare_simd(const float* A, const float* B, int8_t* out, float epsilon, size_t length) {\n    size_t i;\n    __m128 eps = _mm_set1_ps(fabsf(epsilon));\n    __m128 neg_eps = _mm_set1_ps(-fabsf(epsilon));\n    __m128 zero = _mm_setzero_ps();\n\n    for (i = 0; i <= length - 4; i += 4) {\n        __m128 a = _mm_loadu_ps(&A[i]);\n        __m128 b = _mm_loadu_ps(&B[i]);\n        __m128 diff = _mm_sub_ps(a, b);\n\n        __m128 cmp_gt = _mm_cmpgt_ps(diff, eps);\n        __m128 cmp_lt = _mm_cmplt_ps(diff, neg_eps);\n\n        __m128 result = _mm_and_ps(cmp_gt, _mm_set1_ps(1.0f));\n        result = _mm_or_ps(result, _mm_and_ps(cmp_lt, _mm_set1_ps(-1.0f)));\n\n        _mm_storeu_si128((__m128i*)&out[i], _mm_cvtps_epi32(result));\n    }\n\n    for (; i < length; ++i) {\n        float diff = A[i] - B[i];\n        if (diff > fabsf(epsilon)) {\n            out[i] = 1;\n        } else if (diff < -fabsf(epsilon)) {\n            out[i] = -1;\n        } else {\n            out[i] = 0;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_49_SSE", "completion": "```c\nvoid tensor_ternary_compare_simd(const float* A, const float* B, int8_t* out, float epsilon, size_t length) {\n    __m128 eps = _mm_set1_ps(fabsf(epsilon));\n    __m128 neg_eps = _mm_set1_ps(-fabsf(epsilon));\n    __m128 zero = _mm_setzero_ps();\n\n    for (size_t i = 0; i < length; i += 4) {\n        __m128 a = _mm_loadu_ps(&A[i]);\n        __m128 b = _mm_loadu_ps(&B[i]);\n        __m128 diff = _mm_sub_ps(a, b);\n\n        __m128 cmp_gt = _mm_cmpgt_ps(diff, eps);\n        __m128 cmp_lt = _mm_cmplt_ps(diff, neg_eps);\n        __m128 cmp_eq = _mm_andnot_ps(_mm_or_ps(cmp_gt, cmp_lt), _mm_set1_ps(1.0f));\n\n        __m128 result = _mm_or_ps(_mm_or_ps(_mm_and_ps(cmp_gt, _mm_set1_ps(1.0f)), _mm_and_ps(cmp_lt, _mm_set1_ps(-1.0f))), _mm_and_ps(cmp_eq, zero));\n\n        _mm_storeu_si128((__m128i*)&out[i], _mm_cvtps_epi32(result));\n    }\n}\n```"}
{"task_id": "SimdBench_49_SSE", "completion": "```c\nvoid tensor_ternary_compare_simd(const float* A, const float* B, int8_t* out, float epsilon, size_t length) {\n    __m128 eps = _mm_set1_ps(fabsf(epsilon));\n    __m128 neg_eps = _mm_set1_ps(-fabsf(epsilon));\n    __m128 zero = _mm_set1_ps(0.0f);\n    __m128 one = _mm_set1_ps(1.0f);\n    __m128 neg_one = _mm_set1_ps(-1.0f);\n\n    for (size_t i = 0; i < length; i += 4) {\n        __m128 a = _mm_loadu_ps(&A[i]);\n        __m128 b = _mm_loadu_ps(&B[i]);\n        __m128 diff = _mm_sub_ps(a, b);\n\n        __m128 cmp_gt = _mm_cmpgt_ps(diff, eps);\n        __m128 cmp_lt = _mm_cmplt_ps(diff, neg_eps);\n        __m128 cmp_eq = _mm_andnot_ps(_mm_or_ps(cmp_gt, cmp_lt), _mm_cmpeq_ps(diff, zero));\n\n        __m128 result = _mm_or_ps(\n            _mm_and_ps(cmp_gt, one),\n            _mm_or_ps(\n                _mm_and_ps(cmp_lt, neg_one),\n                _mm_and_ps(cmp_eq, zero)\n            )\n        );\n\n        _mm_storeu_si128((__m128i*)&out[i], _mm_cvtps_epi32(result));\n    }\n}\n```"}
{"task_id": "SimdBench_49_SSE", "completion": "```c\nvoid tensor_ternary_compare_simd(const float* A, const float* B, int8_t* out, float epsilon, size_t length) {\n    __m128 eps = _mm_set1_ps(fabsf(epsilon));\n    __m128 neg_eps = _mm_set1_ps(-fabsf(epsilon));\n    __m128 zero = _mm_set1_ps(0.0f);\n    __m128 one = _mm_set1_ps(1.0f);\n    __m128 neg_one = _mm_set1_ps(-1.0f);\n\n    for (size_t i = 0; i < length; i += 4) {\n        __m128 a = _mm_loadu_ps(&A[i]);\n        __m128 b = _mm_loadu_ps(&B[i]);\n        __m128 diff = _mm_sub_ps(a, b);\n\n        __m128 cmp_gt = _mm_cmpgt_ps(diff, eps);\n        __m128 cmp_lt = _mm_cmplt_ps(diff, neg_eps);\n        __m128 cmp_eq = _mm_andnot_ps(_mm_or_ps(cmp_gt, cmp_lt), _mm_cmpeq_ps(diff, zero));\n\n        __m128 result = _mm_or_ps(\n            _mm_and_ps(cmp_gt, one),\n            _mm_or_ps(\n                _mm_and_ps(cmp_lt, neg_one),\n                _mm_and_ps(cmp_eq, zero)\n            )\n        );\n\n        _mm_storeu_si128((__m128i*)&out[i], _mm_cvtps_epi32(result));\n    }\n}\n```"}
{"task_id": "SimdBench_49_SSE", "completion": "```c\nvoid tensor_ternary_compare_simd(const float* A, const float* B, int8_t* out, float epsilon, size_t length) {\n    __m128 eps = _mm_set1_ps(fabsf(epsilon));\n    __m128 neg_eps = _mm_set1_ps(-fabsf(epsilon));\n    __m128i zero = _mm_setzero_si128();\n    __m128i one = _mm_set1_epi32(1);\n    __m128i neg_one = _mm_set1_epi32(-1);\n\n    for (size_t i = 0; i < length; i += 4) {\n        __m128 a = _mm_loadu_ps(&A[i]);\n        __m128 b = _mm_loadu_ps(&B[i]);\n        __m128 diff = _mm_sub_ps(a, b);\n\n        __m128i mask_gt = _mm_castps_si128(_mm_cmpgt_ps(diff, eps));\n        __m128i mask_lt = _mm_castps_si128(_mm_cmplt_ps(diff, neg_eps));\n        __m128i mask_eq = _mm_andnot_si128(_mm_or_si128(mask_gt, mask_lt), _mm_set1_epi32(-1));\n\n        __m128i result = _mm_or_si128(_mm_and_si128(mask_gt, one), _mm_and_si128(mask_lt, neg_one));\n        result = _mm_or_si128(result, _mm_and_si128(mask_eq, zero));\n\n        _mm_storeu_si128((__m128i*)&out[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_50_SSE", "completion": "```c\nvoid float_to_int_saturate_simd(const float* A, int32_t* B, size_t size) {\n    size_t i = 0;\n    __m128 max_val = _mm_set1_ps(INT32_MAX);\n    __m128 min_val = _mm_set1_ps(INT32_MIN);\n\n    for (; i + 4 <= size; i += 4) {\n        __m128 a = _mm_loadu_ps(&A[i]);\n        __m128 clamped = _mm_min_ps(_mm_max_ps(a, min_val), max_val);\n        __m128i b = _mm_cvtps_epi32(clamped);\n        _mm_storeu_si128((__m128i*)&B[i], b);\n    }\n\n    for (; i < size; ++i) {\n        float val = A[i];\n        if (val > INT32_MAX) {\n            B[i] = INT32_MAX;\n        } else if (val < INT32_MIN) {\n            B[i] = INT32_MIN;\n        } else {\n            B[i] = (int32_t)val;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_50_SSE", "completion": "```c\nvoid float_to_int_saturate_simd(const float* A, int32_t* B, size_t size) {\n    const __m128 max_val = _mm_set1_ps(INT32_MAX);\n    const __m128 min_val = _mm_set1_ps(INT32_MIN);\n\n    for (size_t i = 0; i < size; i += 4) {\n        __m128 vec = _mm_loadu_ps(&A[i]);\n\n        __m128 clamped_vec = _mm_min_ps(_mm_max_ps(vec, min_val), max_val);\n\n        __m128i int_vec = _mm_cvtps_epi32(clamped_vec);\n\n        _mm_storeu_si128((__m128i*)&B[i], int_vec);\n    }\n}\n```"}
{"task_id": "SimdBench_50_SSE", "completion": "```c\nvoid float_to_int_saturate_simd(const float* A, int32_t* B, size_t size) {\n    __m128 max_val = _mm_set1_ps(INT32_MAX);\n    __m128 min_val = _mm_set1_ps(INT32_MIN);\n\n    for (size_t i = 0; i < size; i += 4) {\n        __m128 a = _mm_loadu_ps(&A[i]);\n\n        __m128 clamped = _mm_min_ps(_mm_max_ps(a, min_val), max_val);\n\n        __m128i b = _mm_cvtps_epi32(clamped);\n\n        _mm_storeu_si128((__m128i*)&B[i], b);\n    }\n}\n```"}
{"task_id": "SimdBench_50_SSE", "completion": "```c\nvoid float_to_int_saturate_simd(const float* A, int32_t* B, size_t size) {\n    const __m128 max_val = _mm_set1_ps(INT32_MAX);\n    const __m128 min_val = _mm_set1_ps(INT32_MIN);\n\n    for (size_t i = 0; i < size; i += 4) {\n        __m128 a = _mm_loadu_ps(&A[i]);\n\n        __m128 clamped = _mm_min_ps(_mm_max_ps(a, min_val), max_val);\n\n        __m128i b = _mm_cvtps_epi32(clamped);\n\n        _mm_storeu_si128((__m128i*)&B[i], b);\n    }\n}\n```"}
{"task_id": "SimdBench_50_SSE", "completion": "```c\nvoid float_to_int_saturate_simd(const float* A, int32_t* B, size_t size) {\n    size_t i;\n    __m128 max_val = _mm_set1_ps(INT32_MAX);\n    __m128 min_val = _mm_set1_ps(INT32_MIN);\n\n    for (i = 0; i <= size - 4; i += 4) {\n        __m128 v = _mm_loadu_ps(&A[i]);\n        __m128 clamped = _mm_min_ps(_mm_max_ps(v, min_val), max_val);\n        __m128i vi = _mm_cvtps_epi32(clamped);\n        _mm_storeu_si128((__m128i*)&B[i], vi);\n    }\n\n    for (; i < size; ++i) {\n        float val = A[i];\n        if (val > INT32_MAX) {\n            B[i] = INT32_MAX;\n        } else if (val < INT32_MIN) {\n            B[i] = INT32_MIN;\n        } else {\n            B[i] = (int32_t)val;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_51_SSE", "completion": "```c\nvoid int_to_float_scaled_simd(const int32_t* A, int8_t scale, float* B, size_t size) {\n    __m128i scale_vec = _mm_set1_epi32(scale);\n    __m128 scale_float_vec = _mm_cvtepi32_ps(scale_vec);\n\n    for (size_t i = 0; i < size; i += 4) {\n        __m128i a_vec = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128 a_float_vec = _mm_cvtepi32_ps(a_vec);\n        __m128 result_vec = _mm_mul_ps(a_float_vec, scale_float_vec);\n        _mm_storeu_ps(&B[i], result_vec);\n    }\n}\n```"}
{"task_id": "SimdBench_51_SSE", "completion": "```c\nvoid int_to_float_scaled_simd(const int32_t* A, int8_t scale, float* B, size_t size) {\n    __m128i scale_vector = _mm_set1_epi32(scale);\n    __m128 scale_float = _mm_cvtepi32_ps(scale_vector);\n\n    for (size_t i = 0; i < size; i += 4) {\n        __m128i a = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128 a_float = _mm_cvtepi32_ps(a);\n        __m128 result = _mm_mul_ps(a_float, scale_float);\n        _mm_storeu_ps(&B[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_51_SSE", "completion": "```c\nvoid int_to_float_scaled_simd(const int32_t* A, int8_t scale, float* B, size_t size) {\n    __m128i scale_vec = _mm_set1_epi32(scale);\n    __m128 scale_float_vec = _mm_cvtepi32_ps(scale_vec);\n\n    for (size_t i = 0; i < size; i += 4) {\n        __m128i a_vec = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128 a_float_vec = _mm_cvtepi32_ps(a_vec);\n        __m128 result_vec = _mm_mul_ps(a_float_vec, scale_float_vec);\n        _mm_storeu_ps(&B[i], result_vec);\n    }\n}\n```"}
{"task_id": "SimdBench_51_SSE", "completion": "```c\nvoid int_to_float_scaled_simd(const int32_t* A, int8_t scale, float* B, size_t size) {\n    __m128i scale_vec = _mm_set1_epi32(scale);\n    __m128 scale_float_vec = _mm_cvtepi32_ps(scale_vec);\n\n    for (size_t i = 0; i < size; i += 4) {\n        __m128i a_vec = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128 a_float_vec = _mm_cvtepi32_ps(a_vec);\n        __m128 result_vec = _mm_mul_ps(a_float_vec, scale_float_vec);\n        _mm_storeu_ps(&B[i], result_vec);\n    }\n}\n```"}
{"task_id": "SimdBench_51_SSE", "completion": "```c\nvoid int_to_float_scaled_simd(const int32_t* A, int8_t scale, float* B, size_t size) {\n    __m128i scale_vec = _mm_set1_epi32(scale);\n    __m128 scale_float_vec = _mm_cvtepi32_ps(scale_vec);\n\n    for (size_t i = 0; i < size; i += 4) {\n        __m128i a_vec = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128 a_float_vec = _mm_cvtepi32_ps(a_vec);\n        __m128 result_vec = _mm_mul_ps(a_float_vec, scale_float_vec);\n        _mm_storeu_ps(&B[i], result_vec);\n    }\n}\n```"}
{"task_id": "SimdBench_52_SSE", "completion": "```c\nvoid float_div_round_simd(const float* A, const float* B, int32_t* C, size_t size) {\n    size_t i;\n    for (i = 0; i <= size - 4; i += 4) {\n        __m128 a = _mm_loadu_ps(&A[i]);\n        __m128 b = _mm_loadu_ps(&B[i]);\n        __m128 div = _mm_div_ps(a, b);\n        __m128i rounded = _mm_cvtps_epi32(div);\n        _mm_storeu_si128((__m128i*)&C[i], rounded);\n    }\n    for (; i < size; ++i) {\n        C[i] = (int32_t)(A[i] / B[i] + 0.5f);\n    }\n}\n```"}
{"task_id": "SimdBench_52_SSE", "completion": "```c\nvoid float_div_round_simd(const float* A, const float* B, int32_t* C, size_t size) {\n    size_t i;\n    for (i = 0; i <= size - 4; i += 4) {\n        __m128 a = _mm_loadu_ps(&A[i]);\n        __m128 b = _mm_loadu_ps(&B[i]);\n        __m128 div = _mm_div_ps(a, b);\n        __m128i rounded = _mm_cvtps_epi32(div);\n        _mm_storeu_si128((__m128i*)&C[i], rounded);\n    }\n    for (; i < size; ++i) {\n        C[i] = (int32_t)(A[i] / B[i] + 0.5f);\n    }\n}\n```"}
{"task_id": "SimdBench_52_SSE", "completion": "```c\nvoid float_div_round_simd(const float* A, const float* B, int32_t* C, size_t size) {\n    size_t i;\n    for (i = 0; i <= size - 4; i += 4) {\n        __m128 a = _mm_loadu_ps(&A[i]);\n        __m128 b = _mm_loadu_ps(&B[i]);\n        __m128 div = _mm_div_ps(a, b);\n        __m128i rounded = _mm_cvtps_epi32(div);\n        _mm_storeu_si128((__m128i*)&C[i], rounded);\n    }\n    for (; i < size; ++i) {\n        C[i] = (int32_t)(A[i] / B[i] + 0.5f);\n    }\n}\n```"}
{"task_id": "SimdBench_52_SSE", "completion": "```c\nvoid float_div_round_simd(const float* A, const float* B, int32_t* C, size_t size) {\n    size_t i;\n    for (i = 0; i <= size - 4; i += 4) {\n        __m128 a = _mm_loadu_ps(&A[i]);\n        __m128 b = _mm_loadu_ps(&B[i]);\n        __m128 div = _mm_div_ps(a, b);\n        __m128i rounded = _mm_cvtps_epi32(div);\n        _mm_storeu_si128((__m128i*)&C[i], rounded);\n    }\n    for (; i < size; ++i) {\n        C[i] = (int32_t)(A[i] / B[i] + 0.5f);\n    }\n}\n```"}
{"task_id": "SimdBench_52_SSE", "completion": "```c\nvoid float_div_round_simd(const float* A, const float* B, int32_t* C, size_t size) {\n    size_t i;\n    for (i = 0; i <= size - 4; i += 4) {\n        __m128 a = _mm_loadu_ps(&A[i]);\n        __m128 b = _mm_loadu_ps(&B[i]);\n        __m128 div = _mm_div_ps(a, b);\n        __m128i rounded = _mm_cvtps_epi32(div);\n        _mm_storeu_si128((__m128i*)&C[i], rounded);\n    }\n    for (; i < size; ++i) {\n        C[i] = (int32_t)(A[i] / B[i] + 0.5f);\n    }\n}\n```"}
{"task_id": "SimdBench_53_SSE", "completion": "```c\nvoid double_to_float_saturate_simd(const double* A, float* B, size_t size) {\n    __m128d max_val = _mm_set1_pd(FLT_MAX);\n    __m128d min_val = _mm_set1_pd(-FLT_MAX);\n\n    for (size_t i = 0; i < size; i += 2) {\n        __m128d a = _mm_loadu_pd(&A[i]);\n        __m128d clamped = _mm_min_pd(_mm_max_pd(a, min_val), max_val);\n        __m128 b = _mm_cvtpd_ps(clamped);\n        _mm_storeu_ps(&B[i], b);\n    }\n}\n```"}
{"task_id": "SimdBench_53_SSE", "completion": "```c\nvoid double_to_float_saturate_simd(const double* A, float* B, size_t size) {\n    __m128d max_val = _mm_set1_pd(FLT_MAX);\n    __m128d min_val = _mm_set1_pd(-FLT_MAX);\n\n    for (size_t i = 0; i < size; i += 2) {\n        __m128d a = _mm_loadu_pd(&A[i]);\n\n        __m128d clamped = _mm_max_pd(_mm_min_pd(a, max_val), min_val);\n\n        __m128 b = _mm_cvtpd_ps(clamped);\n\n        _mm_storeu_ps(&B[i], b);\n    }\n}\n```"}
{"task_id": "SimdBench_53_SSE", "completion": "```c\nvoid double_to_float_saturate_simd(const double* A, float* B, size_t size) {\n    __m128d max_val = _mm_set1_pd(FLT_MAX);\n    __m128d min_val = _mm_set1_pd(-FLT_MAX);\n\n    for (size_t i = 0; i < size; i += 2) {\n        __m128d a = _mm_loadu_pd(&A[i]);\n        __m128d clamped = _mm_min_pd(_mm_max_pd(a, min_val), max_val);\n        __m128 b = _mm_cvtpd_ps(clamped);\n        _mm_storeu_ps(&B[i], b);\n    }\n}\n```"}
{"task_id": "SimdBench_53_SSE", "completion": "```c\nvoid double_to_float_saturate_simd(const double* A, float* B, size_t size) {\n    __m128d max_val = _mm_set1_pd(FLT_MAX);\n    __m128d min_val = _mm_set1_pd(-FLT_MAX);\n\n    for (size_t i = 0; i < size; i += 2) {\n        __m128d a = _mm_loadu_pd(&A[i]);\n        __m128d clamped = _mm_min_pd(_mm_max_pd(a, min_val), max_val);\n        __m128 b = _mm_cvtpd_ps(clamped);\n        _mm_storeu_ps(&B[i], b);\n    }\n}\n```"}
{"task_id": "SimdBench_53_SSE", "completion": "```c\nvoid double_to_float_saturate_simd(const double* A, float* B, size_t size) {\n    __m128d max_val = _mm_set1_pd(FLT_MAX);\n    __m128d min_val = _mm_set1_pd(-FLT_MAX);\n\n    for (size_t i = 0; i < size; i += 2) {\n        __m128d a = _mm_loadu_pd(&A[i]);\n        __m128d clamped = _mm_min_pd(_mm_max_pd(a, min_val), max_val);\n        __m128 b = _mm_cvtpd_ps(clamped);\n        _mm_storeu_ps(&B[i], b);\n    }\n}\n```"}
{"task_id": "SimdBench_54_SSE", "completion": "```cpp\nvoid int16_to_int32_simd(const int16_t* A, int32_t* B, size_t size) {\n    size_t i;\n    for (i = 0; i <= size - 8; i += 8) {\n        __m128i a = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i b_low = _mm_cvtepi16_epi32(a);\n        __m128i b_high = _mm_cvtepi16_epi32(_mm_srli_si128(a, 8));\n        _mm_storeu_si128((__m128i*)&B[i], b_low);\n        _mm_storeu_si128((__m128i*)&B[i + 4], b_high);\n    }\n    for (; i < size; ++i) {\n        B[i] = (int32_t)A[i];\n    }\n}\n```"}
{"task_id": "SimdBench_54_SSE", "completion": "```c\nvoid int16_to_int32_simd(const int16_t* A, int32_t* B, size_t size) {\n    size_t i;\n    for (i = 0; i <= size - 8; i += 8) {\n        __m128i a = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i b_low = _mm_cvtepi16_epi32(a);\n        __m128i b_high = _mm_cvtepi16_epi32(_mm_srli_si128(a, 8));\n        _mm_storeu_si128((__m128i*)&B[i], b_low);\n        _mm_storeu_si128((__m128i*)&B[i + 4], b_high);\n    }\n    for (; i < size; ++i) {\n        B[i] = (int32_t)A[i];\n    }\n}\n```"}
{"task_id": "SimdBench_54_SSE", "completion": "```c\nvoid int16_to_int32_simd(const int16_t* A, int32_t* B, size_t size) {\n    size_t i;\n    for (i = 0; i <= size - 8; i += 8) {\n        __m128i a = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i b_low = _mm_cvtepi16_epi32(a);\n        __m128i b_high = _mm_cvtepi16_epi32(_mm_srli_si128(a, 8));\n        _mm_storeu_si128((__m128i*)&B[i], b_low);\n        _mm_storeu_si128((__m128i*)&B[i + 4], b_high);\n    }\n    for (; i < size; ++i) {\n        B[i] = (int32_t)A[i];\n    }\n}\n```"}
{"task_id": "SimdBench_54_SSE", "completion": "```cpp\nvoid int16_to_int32_simd(const int16_t* A, int32_t* B, size_t size) {\n    size_t i;\n    for (i = 0; i <= size - 8; i += 8) {\n        __m128i a = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i b_low = _mm_cvtepi16_epi32(a);\n        __m128i b_high = _mm_cvtepi16_epi32(_mm_srli_si128(a, 8));\n        _mm_storeu_si128((__m128i*)&B[i], b_low);\n        _mm_storeu_si128((__m128i*)&B[i + 4], b_high);\n    }\n    for (; i < size; ++i) {\n        B[i] = A[i];\n    }\n}\n```"}
{"task_id": "SimdBench_54_SSE", "completion": "```c\nvoid int16_to_int32_simd(const int16_t* A, int32_t* B, size_t size) {\n    size_t i;\n    for (i = 0; i <= size - 8; i += 8) {\n        __m128i a = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i b_low = _mm_cvtepi16_epi32(a);\n        __m128i b_high = _mm_cvtepi16_epi32(_mm_srli_si128(a, 8));\n        _mm_storeu_si128((__m128i*)&B[i], b_low);\n        _mm_storeu_si128((__m128i*)&B[i + 4], b_high);\n    }\n    for (; i < size; ++i) {\n        B[i] = (int32_t)A[i];\n    }\n}\n```"}
{"task_id": "SimdBench_55_SSE", "completion": "```cpp\nvoid conditional_normalize_simd(const float* A, const int32_t* control, float* B, size_t size, float min_val, float max_val) {\n    __m128 vmin_val = _mm_set1_ps(min_val);\n    __m128 vmax_val = _mm_set1_ps(max_val);\n    __m128 vrange = _mm_sub_ps(vmax_val, vmin_val);\n    __m128 vzero = _mm_set1_ps(0.0f);\n    __m128 vone = _mm_set1_ps(1.0f);\n\n    for (size_t i = 0; i < size; i += 4) {\n        __m128 va = _mm_loadu_ps(&A[i]);\n        __m128 vcontrol = _mm_loadu_ps((float*)&control[i]);\n        __m128 vnorm = _mm_div_ps(_mm_sub_ps(va, vmin_val), vrange);\n        vnorm = _mm_max_ps(vnorm, vzero);\n        vnorm = _mm_min_ps(vnorm, vone);\n\n        __m128 mask = _mm_cmpgt_ps(vcontrol, vzero);\n        __m128 vresult = _mm_blendv_ps(va, vnorm, mask);\n\n        _mm_storeu_ps(&B[i], vresult);\n    }\n}\n```"}
{"task_id": "SimdBench_55_SSE", "completion": "```cpp\nvoid conditional_normalize_simd(const float* A, const int32_t* control, float* B, size_t size, float min_val, float max_val) {\n    __m128 vmin_val = _mm_set1_ps(min_val);\n    __m128 vmax_val = _mm_set1_ps(max_val);\n    __m128 vrange = _mm_sub_ps(vmax_val, vmin_val);\n    __m128 vzero = _mm_set1_ps(0.0f);\n    __m128 vone = _mm_set1_ps(1.0f);\n\n    for (size_t i = 0; i < size; i += 4) {\n        __m128 va = _mm_loadu_ps(&A[i]);\n        __m128 vcontrol = _mm_loadu_ps((float*)&control[i]);\n        __m128 vnorm = _mm_div_ps(_mm_sub_ps(va, vmin_val), vrange);\n        vnorm = _mm_max_ps(_mm_min_ps(vnorm, vone), vzero);\n\n        __m128 mask = _mm_cmpgt_ps(vcontrol, vzero);\n        __m128 vresult = _mm_blendv_ps(va, vnorm, mask);\n\n        _mm_storeu_ps(&B[i], vresult);\n    }\n}\n```"}
{"task_id": "SimdBench_55_SSE", "completion": "```c\nvoid conditional_normalize_simd(const float* A, const int32_t* control, float* B, size_t size, float min_val, float max_val) {\n    __m128 vmin_val = _mm_set1_ps(min_val);\n    __m128 vmax_val = _mm_set1_ps(max_val);\n    __m128 vrange = _mm_sub_ps(vmax_val, vmin_val);\n    __m128 vzero = _mm_set1_ps(0.0f);\n    __m128 vone = _mm_set1_ps(1.0f);\n\n    for (size_t i = 0; i < size; i += 4) {\n        __m128 vA = _mm_loadu_ps(&A[i]);\n        __m128i vcontrol = _mm_loadu_si128((__m128i*)&control[i]);\n\n        __m128 vnorm = _mm_div_ps(_mm_sub_ps(vA, vmin_val), vrange);\n        vnorm = _mm_max_ps(vnorm, vzero);\n        vnorm = _mm_min_ps(vnorm, vone);\n\n        __m128i vcontrol_mask = _mm_cmpgt_epi32(vcontrol, _mm_setzero_si128());\n        __m128 vresult = _mm_blendv_ps(vA, vnorm, (__m128)vcontrol_mask);\n\n        _mm_storeu_ps(&B[i], vresult);\n    }\n}\n```"}
{"task_id": "SimdBench_55_SSE", "completion": "```cpp\nvoid conditional_normalize_simd(const float* A, const int32_t* control, float* B, size_t size, float min_val, float max_val) {\n    __m128 vmin_val = _mm_set1_ps(min_val);\n    __m128 vmax_val = _mm_set1_ps(max_val);\n    __m128 vrange = _mm_sub_ps(vmax_val, vmin_val);\n    __m128 vzero = _mm_set1_ps(0.0f);\n    __m128 vone = _mm_set1_ps(1.0f);\n\n    for (size_t i = 0; i < size; i += 4) {\n        __m128 va = _mm_loadu_ps(&A[i]);\n        __m128i vcontrol = _mm_loadu_si128((__m128i*)&control[i]);\n\n        __m128 vnorm = _mm_div_ps(_mm_sub_ps(va, vmin_val), vrange);\n        vnorm = _mm_max_ps(vnorm, vzero);\n        vnorm = _mm_min_ps(vnorm, vone);\n\n        __m128i vcontrol_mask = _mm_cmpgt_epi32(vcontrol, _mm_setzero_si128());\n        __m128 vresult = _mm_blendv_ps(va, vnorm, (__m128)vcontrol_mask);\n\n        _mm_storeu_ps(&B[i], vresult);\n    }\n}\n```"}
{"task_id": "SimdBench_55_SSE", "completion": "```cpp\nvoid conditional_normalize_simd(const float* A, const int32_t* control, float* B, size_t size, float min_val, float max_val) {\n    __m128 vmin_val = _mm_set1_ps(min_val);\n    __m128 vmax_val = _mm_set1_ps(max_val);\n    __m128 vrange = _mm_sub_ps(vmax_val, vmin_val);\n    __m128 vzero = _mm_set1_ps(0.0f);\n    __m128 vone = _mm_set1_ps(1.0f);\n\n    for (size_t i = 0; i < size; i += 4) {\n        __m128 va = _mm_loadu_ps(&A[i]);\n        __m128 vcontrol = _mm_loadu_ps((float*)&control[i]);\n\n        __m128 vnorm = _mm_div_ps(_mm_sub_ps(va, vmin_val), vrange);\n        vnorm = _mm_max_ps(vnorm, vzero);\n        vnorm = _mm_min_ps(vnorm, vone);\n\n        __m128 vcopy = va;\n\n        __m128i vcontrol_mask = _mm_cmpgt_epi32(_mm_castps_si128(vcontrol), _mm_setzero_si128());\n        __m128 vcontrol_mask_ps = _mm_castsi128_ps(vcontrol_mask);\n\n        __m128 vresult = _mm_blendv_ps(vcopy, vnorm, vcontrol_mask_ps);\n\n        _mm_storeu_ps(&B[i], vresult);\n    }\n}\n```"}
{"task_id": "SimdBench_56_SSE", "completion": "```c\nvoid int_to_float_sqrt_simd(const uint32_t* A, float* B, size_t size) {\n    for (size_t i = 0; i < size; i += 4) {\n        __m128i a = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i high_bits = _mm_srli_epi32(a, 16);\n        __m128 floats = _mm_cvtepi32_ps(high_bits);\n        __m128 sqrt_floats = _mm_sqrt_ps(floats);\n        _mm_storeu_ps(&B[i], sqrt_floats);\n    }\n}\n```"}
{"task_id": "SimdBench_56_SSE", "completion": "```c\nvoid int_to_float_sqrt_simd(const uint32_t* A, float* B, size_t size) {\n    for (size_t i = 0; i < size; i += 4) {\n        __m128i a = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i high_bits = _mm_srli_epi32(a, 16);\n        __m128 floats = _mm_cvtepi32_ps(high_bits);\n        __m128 sqrt_floats = _mm_sqrt_ps(floats);\n        _mm_storeu_ps(&B[i], sqrt_floats);\n    }\n}\n```"}
{"task_id": "SimdBench_56_SSE", "completion": "```c\nvoid int_to_float_sqrt_simd(const uint32_t* A, float* B, size_t size) {\n    size_t i;\n    for (i = 0; i < size; i += 4) {\n        __m128i a = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i high_bits = _mm_srli_epi32(a, 16);\n        __m128 floats = _mm_cvtepi32_ps(high_bits);\n        __m128 sqrt_floats = _mm_sqrt_ps(floats);\n        _mm_storeu_ps(&B[i], sqrt_floats);\n    }\n}\n```"}
{"task_id": "SimdBench_56_SSE", "completion": "```c\nvoid int_to_float_sqrt_simd(const uint32_t* A, float* B, size_t size) {\n    for (size_t i = 0; i < size; i += 4) {\n        __m128i a = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i high_bits = _mm_srli_epi32(a, 16);\n        __m128 floats = _mm_cvtepi32_ps(high_bits);\n        __m128 sqrt_floats = _mm_sqrt_ps(floats);\n        _mm_storeu_ps(&B[i], sqrt_floats);\n    }\n}\n```"}
{"task_id": "SimdBench_56_SSE", "completion": "```c\nvoid int_to_float_sqrt_simd(const uint32_t* A, float* B, size_t size) {\n    size_t i;\n    for (i = 0; i < size; i += 4) {\n        __m128i a = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i high_bits = _mm_srli_epi32(a, 16);\n        __m128 b = _mm_cvtepi32_ps(high_bits);\n        __m128 sqrt_b = _mm_sqrt_ps(b);\n        _mm_storeu_ps(&B[i], sqrt_b);\n    }\n}\n```"}
{"task_id": "SimdBench_57_SSE", "completion": "```cpp\nvoid int_bits_to_float_simd(const uint32_t* A, float* B, size_t size) {\n    size_t i;\n    for (i = 0; i <= size - 4; i += 4) {\n        __m128i int_vec = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128 float_vec = _mm_castsi128_ps(int_vec);\n        _mm_storeu_ps(&B[i], float_vec);\n    }\n    for (; i < size; ++i) {\n        B[i] = *(float*)&A[i];\n    }\n}\n```"}
{"task_id": "SimdBench_57_SSE", "completion": "```c\nvoid int_bits_to_float_simd(const uint32_t* A, float* B, size_t size) {\n    size_t i;\n    for (i = 0; i <= size - 4; i += 4) {\n        __m128i int_vec = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128 float_vec = _mm_castsi128_ps(int_vec);\n        _mm_storeu_ps(&B[i], float_vec);\n    }\n    for (; i < size; ++i) {\n        B[i] = *(float*)&A[i];\n    }\n}\n```"}
{"task_id": "SimdBench_57_SSE", "completion": "```cpp\nvoid int_bits_to_float_simd(const uint32_t* A, float* B, size_t size) {\n    size_t i;\n    for (i = 0; i <= size - 4; i += 4) {\n        __m128i int_vec = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128 float_vec = _mm_castsi128_ps(int_vec);\n        _mm_storeu_ps(&B[i], float_vec);\n    }\n    for (; i < size; ++i) {\n        B[i] = *(float*)&A[i];\n    }\n}\n```"}
{"task_id": "SimdBench_57_SSE", "completion": "```cpp\nvoid int_bits_to_float_simd(const uint32_t* A, float* B, size_t size) {\n    size_t i;\n    for (i = 0; i <= size - 4; i += 4) {\n        __m128i int_vec = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128 float_vec = _mm_castsi128_ps(int_vec);\n        _mm_storeu_ps(&B[i], float_vec);\n    }\n    for (; i < size; ++i) {\n        B[i] = *(float*)&A[i];\n    }\n}\n```"}
{"task_id": "SimdBench_57_SSE", "completion": "```c\nvoid int_bits_to_float_simd(const uint32_t* A, float* B, size_t size) {\n    size_t i;\n    for (i = 0; i <= size - 4; i += 4) {\n        __m128i int_vec = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128 float_vec = _mm_castsi128_ps(int_vec);\n        _mm_storeu_ps(&B[i], float_vec);\n    }\n    for (; i < size; ++i) {\n        B[i] = *(float*)&A[i];\n    }\n}\n```"}
{"task_id": "SimdBench_58_SSE", "completion": "```cpp\nvoid conditional_diff_simd(const int32_t* A, const bool* cond, float* diff, size_t size) {\n    if (size == 0) return;\n\n    diff[0] = 0.0f;\n\n    for (size_t i = 1; i < size; i += 4) {\n        __m128i a = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i a_prev = _mm_loadu_si128((__m128i*)&A[i - 1]);\n\n        __m128i diff_int = _mm_sub_epi32(a, a_prev);\n\n        __m128 diff_float = _mm_cvtepi32_ps(diff_int);\n\n        __m128i cond_vec = _mm_loadu_si128((__m128i*)&cond[i]);\n\n        __m128i mask = _mm_cmpeq_epi32(cond_vec, _mm_set1_epi32(1));\n\n        __m128 result = _mm_and_ps(diff_float, _mm_castsi128_ps(mask));\n\n        _mm_storeu_ps(&diff[i], result);\n    }\n\n    for (size_t i = size - (size % 4); i < size; ++i) {\n        if (cond[i]) {\n            diff[i] = static_cast<float>(A[i] - A[i - 1]);\n        } else {\n            diff[i] = 0.0f;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_58_SSE", "completion": "```cpp\nvoid conditional_diff_simd(const int32_t* A, const bool* cond, float* diff, size_t size) {\n    __m128i zero_vec = _mm_setzero_si128();\n    __m128 zero_float_vec = _mm_setzero_ps();\n    __m128i mask = _mm_set1_epi32(0xFFFFFFFF);\n\n    diff[0] = 0.0f;\n    for (size_t i = 1; i < size; i += 4) {\n        __m128i a_vec = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i a_prev_vec = _mm_loadu_si128((__m128i*)&A[i - 1]);\n\n        __m128i cond_vec = _mm_loadu_si128((__m128i*)&cond[i]);\n        cond_vec = _mm_and_si128(cond_vec, mask);\n\n        __m128i diff_int_vec = _mm_sub_epi32(a_vec, a_prev_vec);\n        __m128 diff_float_vec = _mm_cvtepi32_ps(diff_int_vec);\n\n        __m128i cond_float_vec = _mm_cvtepi32_ps(cond_vec);\n        __m128 result_vec = _mm_and_ps(diff_float_vec, cond_float_vec);\n\n        _mm_storeu_ps(&diff[i], result_vec);\n    }\n\n    for (size_t i = size - (size % 4); i < size; ++i) {\n        diff[i] = cond[i] ? static_cast<float>(A[i] - A[i - 1]) : 0.0f;\n    }\n}\n```"}
{"task_id": "SimdBench_58_SSE", "completion": "```c\nvoid conditional_diff_simd(const int32_t* A, const bool* cond, float* diff, size_t size) {\n    __m128i zero_vec = _mm_setzero_si128();\n    __m128 zero_float_vec = _mm_setzero_ps();\n    __m128i mask = _mm_set1_epi32(0xFFFFFFFF);\n\n    diff[0] = 0.0f;\n    for (size_t i = 1; i < size; i += 4) {\n        __m128i a_vec = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i a_prev_vec = _mm_loadu_si128((__m128i*)&A[i - 1]);\n\n        __m128i cond_vec = _mm_loadu_si128((__m128i*)&cond[i]);\n        __m128i cond_mask = _mm_and_si128(cond_vec, mask);\n\n        __m128i diff_int_vec = _mm_sub_epi32(a_vec, a_prev_vec);\n        __m128 diff_float_vec = _mm_cvtepi32_ps(diff_int_vec);\n\n        __m128i cond_mask_neg = _mm_xor_si128(cond_mask, mask);\n        __m128 cond_float_vec = _mm_castsi128_ps(cond_mask_neg);\n        __m128 result_vec = _mm_andnot_ps(cond_float_vec, diff_float_vec);\n\n        _mm_storeu_ps(&diff[i], result_vec);\n    }\n}\n```"}
{"task_id": "SimdBench_58_SSE", "completion": "```cpp\nvoid conditional_diff_simd(const int32_t* A, const bool* cond, float* diff, size_t size) {\n    if (size == 0) return;\n\n    diff[0] = 0.0f;\n\n    for (size_t i = 1; i < size; i += 4) {\n        __m128i a = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i a_prev = _mm_loadu_si128((__m128i*)&A[i - 1]);\n\n        __m128i diff_int = _mm_sub_epi32(a, a_prev);\n\n        __m128 diff_float = _mm_cvtepi32_ps(diff_int);\n\n        __m128i cond_mask = _mm_loadu_si128((__m128i*)&cond[i]);\n        cond_mask = _mm_cmpeq_epi32(cond_mask, _mm_set1_epi32(1));\n\n        __m128 zero = _mm_setzero_ps();\n        __m128 result = _mm_blendv_ps(zero, diff_float, _mm_castsi128_ps(cond_mask));\n\n        _mm_storeu_ps(&diff[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_58_SSE", "completion": "```cpp\nvoid conditional_diff_simd(const int32_t* A, const bool* cond, float* diff, size_t size) {\n    if (size == 0) return;\n\n    diff[0] = 0.0f;\n\n    for (size_t i = 1; i < size; i += 4) {\n        __m128i a = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i a_prev = _mm_loadu_si128((__m128i*)&A[i - 1]);\n\n        __m128i diff_int = _mm_sub_epi32(a, a_prev);\n\n        __m128 diff_float = _mm_cvtepi32_ps(diff_int);\n\n        __m128i cond_mask = _mm_loadu_si128((__m128i*)&cond[i]);\n        cond_mask = _mm_cmpeq_epi32(cond_mask, _mm_set1_epi32(1));\n\n        __m128 zero = _mm_set1_ps(0.0f);\n        __m128 result = _mm_blendv_ps(zero, diff_float, (__m128)cond_mask);\n\n        _mm_storeu_ps(&diff[i], result);\n    }\n\n    for (size_t i = size - (size % 4); i < size; ++i) {\n        if (cond[i]) {\n            diff[i] = static_cast<float>(A[i] - A[i - 1]);\n        } else {\n            diff[i] = 0.0f;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_59_SSE", "completion": "```c\nvoid widening_uint_simd(const uint32_t* src, uint64_t* dst, size_t length) {\n    __m128i ones = _mm_set1_epi32(0xFFFFFFFF);\n    for (size_t i = 0; i < length; i += 4) {\n        __m128i src_vec = _mm_loadu_si128((__m128i*)&src[i]);\n        __m128i high_bits = _mm_slli_epi64(src_vec, 32);\n        __m128i result = _mm_or_si128(high_bits, ones);\n        _mm_storeu_si128((__m128i*)&dst[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_59_SSE", "completion": "```c\nvoid widening_uint_simd(const uint32_t* src, uint64_t* dst, size_t length) {\n    __m128i ones = _mm_set1_epi32(0xFFFFFFFF);\n    for (size_t i = 0; i < length; i += 4) {\n        __m128i src_vec = _mm_loadu_si128((__m128i*)&src[i]);\n        __m128i high_bits = _mm_slli_epi64(src_vec, 32);\n        __m128i result = _mm_or_si128(high_bits, ones);\n        _mm_storeu_si128((__m128i*)&dst[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_59_SSE", "completion": "```c\nvoid widening_uint_simd(const uint32_t* src, uint64_t* dst, size_t length) {\n    size_t i = 0;\n    __m128i ones = _mm_set1_epi32(0xFFFFFFFF);\n\n    for (; i + 4 <= length; i += 4) {\n        __m128i src_vec = _mm_loadu_si128((__m128i*)&src[i]);\n        __m128i high_bits = _mm_slli_epi64(src_vec, 32);\n        __m128i result = _mm_or_si128(high_bits, ones);\n        _mm_storeu_si128((__m128i*)&dst[i], result);\n    }\n\n    for (; i < length; ++i) {\n        dst[i] = ((uint64_t)src[i] << 32) | 0xFFFFFFFF;\n    }\n}\n```"}
{"task_id": "SimdBench_59_SSE", "completion": "```c\nvoid widening_uint_simd(const uint32_t* src, uint64_t* dst, size_t length) {\n    __m128i mask = _mm_set1_epi32(0xFFFFFFFF);\n    __m128i high_bits = _mm_set1_epi32(0xFFFFFFFF);\n\n    for (size_t i = 0; i < length; i += 4) {\n        __m128i src_vec = _mm_loadu_si128((__m128i*)&src[i]);\n        __m128i low_bits = _mm_and_si128(src_vec, mask);\n        __m128i high_bits_vec = _mm_slli_epi64(high_bits, 32);\n        __m128i result = _mm_or_si128(low_bits, high_bits_vec);\n\n        _mm_storeu_si128((__m128i*)&dst[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_59_SSE", "completion": "```c\nvoid widening_uint_simd(const uint32_t* src, uint64_t* dst, size_t length) {\n    __m128i mask = _mm_set1_epi32(0xFFFFFFFF);\n    __m128i high_bits = _mm_set1_epi32(0xFFFFFFFF);\n\n    for (size_t i = 0; i < length; i += 4) {\n        __m128i src_vec = _mm_loadu_si128((__m128i*)&src[i]);\n        __m128i low_bits = _mm_and_si128(src_vec, mask);\n        __m128i high_bits_vec = _mm_slli_epi64(high_bits, 32);\n        __m128i result = _mm_or_si128(low_bits, high_bits_vec);\n\n        _mm_storeu_si128((__m128i*)&dst[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_60_SSE", "completion": "```cpp\ndouble indexed_sum_simd(const double* vec, const int16_t* index, size_t length) {\n    __m128d sum = _mm_setzero_pd();\n    size_t i = 0;\n\n    for (; i <= length - 2; i += 2) {\n        __m128i indices = _mm_loadu_si128((__m128i*)&index[i]);\n        __m128d values = _mm_set_pd(vec[indices.m128i_i64[1]], vec[indices.m128i_i64[0]]);\n        sum = _mm_add_pd(sum, values);\n    }\n\n    double result[2];\n    _mm_storeu_pd(result, sum);\n\n    for (; i < length; ++i) {\n        result[0] += vec[index[i]];\n    }\n\n    return result[0] + result[1];\n}\n```"}
{"task_id": "SimdBench_60_SSE", "completion": "```c\ndouble indexed_sum_simd(const double* vec, const int16_t* index, size_t length) {\n    __m128d sum = _mm_setzero_pd();\n    size_t i = 0;\n\n    for (; i <= length - 2; i += 2) {\n        __m128i indices = _mm_loadu_si128((__m128i*)&index[i]);\n        __m128d values = _mm_set_pd(vec[indices.m128i_i64[1]], vec[indices.m128i_i64[0]]);\n        sum = _mm_add_pd(sum, values);\n    }\n\n    double result[2];\n    _mm_storeu_pd(result, sum);\n\n    for (; i < length; ++i) {\n        result[0] += vec[index[i]];\n    }\n\n    return result[0] + result[1];\n}\n```"}
{"task_id": "SimdBench_60_SSE", "completion": "```cpp\ndouble indexed_sum_simd(const double* vec, const int16_t* index, size_t length) {\n    __m128d sum = _mm_setzero_pd();\n    size_t i = 0;\n\n    for (; i + 1 < length; i += 2) {\n        __m128i indices = _mm_loadu_si128((__m128i*)&index[i]);\n        __m128d values = _mm_set_pd(vec[indices.m128i_i64[1]], vec[indices.m128i_i64[0]]);\n        sum = _mm_add_pd(sum, values);\n    }\n\n    double result[2];\n    _mm_storeu_pd(result, sum);\n\n    double total_sum = result[0] + result[1];\n\n    for (; i < length; ++i) {\n        total_sum += vec[index[i]];\n    }\n\n    return total_sum;\n}\n```"}
{"task_id": "SimdBench_60_SSE", "completion": "```c\ndouble indexed_sum_simd(const double* vec, const int16_t* index, size_t length) {\n    __m128d sum = _mm_setzero_pd();\n    size_t i = 0;\n\n    for (; i <= length - 2; i += 2) {\n        __m128i indices = _mm_loadu_si128((__m128i*)&index[i]);\n        __m128d values = _mm_set_pd(vec[indices.m128i_i64[1]], vec[indices.m128i_i64[0]]);\n        sum = _mm_add_pd(sum, values);\n    }\n\n    double result[2];\n    _mm_storeu_pd(result, sum);\n\n    for (; i < length; ++i) {\n        result[0] += vec[index[i]];\n    }\n\n    return result[0] + result[1];\n}\n```"}
{"task_id": "SimdBench_60_SSE", "completion": "```cpp\ndouble indexed_sum_simd(const double* vec, const int16_t* index, size_t length) {\n    __m128d sum = _mm_setzero_pd();\n    size_t i = 0;\n\n    for (; i <= length - 2; i += 2) {\n        __m128i indices = _mm_loadu_si128((__m128i*)&index[i]);\n        __m128d values = _mm_set_pd(vec[indices.m128i_i64[1]], vec[indices.m128i_i64[0]]);\n        sum = _mm_add_pd(sum, values);\n    }\n\n    double result[2];\n    _mm_storeu_pd(result, sum);\n\n    for (; i < length; ++i) {\n        result[0] += vec[index[i]];\n    }\n\n    return result[0] + result[1];\n}\n```"}
{"task_id": "SimdBench_61_SSE", "completion": "```c\nvoid simple_conv2d_simd(const double* input, const double* kernel, double * output, size_t input_size, size_t kernel_size) {\n    size_t output_size = input_size - kernel_size + 1;\n    size_t output_length = output_size * output_size;\n\n    for (size_t i = 0; i < output_length; ++i) {\n        size_t row = i / output_size;\n        size_t col = i % output_size;\n\n        __m128d sum = _mm_setzero_pd();\n\n        for (size_t ki = 0; ki < kernel_size; ++ki) {\n            for (size_t kj = 0; kj < kernel_size; ++kj) {\n                size_t input_index = (row + ki) * input_size + (col + kj);\n                size_t kernel_index = ki * kernel_size + kj;\n\n                __m128d input_val = _mm_loadu_pd(&input[input_index]);\n                __m128d kernel_val = _mm_loadu_pd(&kernel[kernel_index]);\n\n                sum = _mm_add_pd(sum, _mm_mul_pd(input_val, kernel_val));\n            }\n        }\n\n        double result[2];\n        _mm_storeu_pd(result, sum);\n\n        output[i] = result[0] + result[1];\n        output[i] = output[i] > 0 ? output[i] : 0;\n    }\n}\n```"}
{"task_id": "SimdBench_61_SSE", "completion": "```c\nvoid simple_conv2d_simd(const double* input, const double* kernel, double * output, size_t input_size, size_t kernel_size) {\n    size_t output_size = input_size - kernel_size + 1;\n    size_t output_length = output_size * output_size;\n\n    for (size_t i = 0; i < output_length; ++i) {\n        size_t row = i / output_size;\n        size_t col = i % output_size;\n\n        __m128d sum = _mm_setzero_pd();\n\n        for (size_t k_row = 0; k_row < kernel_size; ++k_row) {\n            for (size_t k_col = 0; k_col < kernel_size; ++k_col) {\n                size_t input_index = (row + k_row) * input_size + (col + k_col);\n                size_t kernel_index = k_row * kernel_size + k_col;\n\n                __m128d input_val = _mm_loadu_pd(&input[input_index]);\n                __m128d kernel_val = _mm_loadu_pd(&kernel[kernel_index]);\n\n                sum = _mm_add_pd(sum, _mm_mul_pd(input_val, kernel_val));\n            }\n        }\n\n        double result[2];\n        _mm_storeu_pd(result, sum);\n\n        output[i] = result[0] + result[1];\n        output[i] = output[i] > 0 ? output[i] : 0;\n    }\n}\n```"}
{"task_id": "SimdBench_61_SSE", "completion": "```cpp\nvoid simple_conv2d_simd(const double* input, const double* kernel, double * output, size_t input_size, size_t kernel_size) {\n    size_t output_size = input_size - kernel_size + 1;\n    size_t output_index = 0;\n\n    for (size_t i = 0; i < output_size; ++i) {\n        for (size_t j = 0; j < output_size; ++j) {\n            __m128d sum = _mm_setzero_pd();\n\n            for (size_t ki = 0; ki < kernel_size; ++ki) {\n                for (size_t kj = 0; kj < kernel_size; ++kj) {\n                    size_t input_index = (i + ki) * input_size + (j + kj);\n                    size_t kernel_index = ki * kernel_size + kj;\n\n                    __m128d input_val = _mm_load1_pd(&input[input_index]);\n                    __m128d kernel_val = _mm_load1_pd(&kernel[kernel_index]);\n\n                    sum = _mm_add_pd(sum, _mm_mul_pd(input_val, kernel_val));\n                }\n            }\n\n            double result[2];\n            _mm_storeu_pd(result, sum);\n            output[output_index++] = result[0] + result[1] > 0 ? result[0] + result[1] : 0;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_61_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid simple_conv2d_simd(const double* input, const double* kernel, double * output, size_t input_size, size_t kernel_size) {\n    size_t output_size = input_size - kernel_size + 1;\n    size_t output_stride = output_size * output_size;\n\n    for (size_t i = 0; i < output_size; ++i) {\n        for (size_t j = 0; j < output_size; ++j) {\n            __m128d sum = _mm_setzero_pd();\n\n            for (size_t ki = 0; ki < kernel_size; ++ki) {\n                for (size_t kj = 0; kj < kernel_size; ++kj) {\n                    size_t input_index = (i + ki) * input_size + (j + kj);\n                    size_t kernel_index = ki * kernel_size + kj;\n\n                    __m128d in_val = _mm_loadu_pd(&input[input_index]);\n                    __m128d ker_val = _mm_loadu_pd(&kernel[kernel_index]);\n\n                    sum = _mm_add_pd(sum, _mm_mul_pd(in_val, ker_val));\n                }\n            }\n\n            double result[2];\n            _mm_storeu_pd(result, sum);\n            double relu_result = result[0] + result[1];\n            output[i * output_size + j] = relu_result > 0 ? relu_result : 0;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_61_SSE", "completion": "```c\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid simple_conv2d_simd(const double* input, const double* kernel, double * output, size_t input_size, size_t kernel_size) {\n    size_t output_size = input_size - kernel_size + 1;\n    size_t output_index = 0;\n\n    for (size_t i = 0; i < output_size; ++i) {\n        for (size_t j = 0; j < output_size; ++j) {\n            __m128d sum = _mm_setzero_pd();\n\n            for (size_t ki = 0; ki < kernel_size; ++ki) {\n                for (size_t kj = 0; kj < kernel_size; ++kj) {\n                    size_t input_index = (i + ki) * input_size + (j + kj);\n                    size_t kernel_index = ki * kernel_size + kj;\n\n                    __m128d input_val = _mm_loadu_pd(&input[input_index]);\n                    __m128d kernel_val = _mm_loadu_pd(&kernel[kernel_index]);\n\n                    sum = _mm_add_pd(sum, _mm_mul_pd(input_val, kernel_val));\n                }\n            }\n\n            double result[2];\n            _mm_storeu_pd(result, sum);\n            output[output_index++] = result[0] + result[1] > 0 ? result[0] + result[1] : 0;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_62_SSE", "completion": "```cpp\nbool has_close_elements_simd(const std::vector<double> & numbers, double threshold) {\n    const int size = numbers.size();\n    if (size < 2) return false;\n\n    __m128d threshold_vec = _mm_set1_pd(threshold);\n\n    for (int i = 0; i < size; ++i) {\n        __m128d a = _mm_set1_pd(numbers[i]);\n        for (int j = i + 1; j < size; j += 2) {\n            __m128d b = _mm_loadu_pd(&numbers[j]);\n            __m128d diff = _mm_sub_pd(a, b);\n            __m128d abs_diff = _mm_andnot_pd(_mm_set1_pd(-0.0), diff);\n            __m128d cmp = _mm_cmplt_pd(abs_diff, threshold_vec);\n            int mask = _mm_movemask_pd(cmp);\n            if (mask != 0) return true;\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_62_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nbool has_close_elements_simd(const std::vector<double> & numbers, double threshold) {\n    const size_t size = numbers.size();\n    const size_t step = 2; // SSE2 operates on 128-bit registers, which can hold 2 doubles\n\n    __m128d thresh = _mm_set1_pd(threshold);\n\n    for (size_t i = 0; i < size; ++i) {\n        __m128d a = _mm_set1_pd(numbers[i]);\n\n        for (size_t j = i + 1; j < size; j += step) {\n            __m128d b = _mm_loadu_pd(&numbers[j]);\n            __m128d diff = _mm_sub_pd(a, b);\n            __m128d abs_diff = _mm_andnot_pd(_mm_set1_pd(-0.0), diff);\n            __m128d cmp = _mm_cmplt_pd(abs_diff, thresh);\n\n            if (_mm_movemask_pd(cmp) != 0) {\n                return true;\n            }\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_62_SSE", "completion": "```cpp\nbool has_close_elements_simd(const std::vector<double> & numbers, double threshold) {\n    const int size = numbers.size();\n    const __m128d thresh = _mm_set1_pd(threshold);\n\n    for (int i = 0; i < size; ++i) {\n        __m128d a = _mm_set1_pd(numbers[i]);\n        for (int j = i + 1; j < size; j += 2) {\n            __m128d b = _mm_loadu_pd(&numbers[j]);\n            __m128d diff = _mm_sub_pd(a, b);\n            __m128d abs_diff = _mm_andnot_pd(_mm_set1_pd(-0.0), diff);\n            __m128d cmp = _mm_cmplt_pd(abs_diff, thresh);\n            int mask = _mm_movemask_pd(cmp);\n            if (mask != 0) {\n                return true;\n            }\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_62_SSE", "completion": "```cpp\nbool has_close_elements_simd(const std::vector<double> & numbers, double threshold) {\n    const int size = numbers.size();\n    const int simdWidth = 2; // SSE operates on 2 doubles at a time\n    const int alignedSize = size & ~(simdWidth - 1);\n\n    __m128d thresholdVec = _mm_set1_pd(threshold);\n\n    for (int i = 0; i < alignedSize; i += simdWidth) {\n        __m128d a = _mm_loadu_pd(&numbers[i]);\n        for (int j = i + simdWidth; j < size; j += simdWidth) {\n            __m128d b = _mm_loadu_pd(&numbers[j]);\n            __m128d diff = _mm_sub_pd(a, b);\n            __m128d absDiff = _mm_andnot_pd(_mm_set1_pd(-0.0), diff);\n            __m128d mask = _mm_cmplt_pd(absDiff, thresholdVec);\n            if (_mm_movemask_pd(mask)) {\n                return true;\n            }\n        }\n    }\n\n    for (int i = alignedSize; i < size; ++i) {\n        for (int j = i + 1; j < size; ++j) {\n            if (std::abs(numbers[i] - numbers[j]) < threshold) {\n                return true;\n            }\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_62_SSE", "completion": "```cpp\nbool has_close_elements_simd(const std::vector<double> & numbers, double threshold) {\n    const int size = numbers.size();\n    if (size < 2) return false;\n\n    __m128d thresh = _mm_set1_pd(threshold);\n\n    for (int i = 0; i < size; ++i) {\n        __m128d a = _mm_set1_pd(numbers[i]);\n        for (int j = i + 1; j < size; j += 2) {\n            __m128d b = _mm_loadu_pd(&numbers[j]);\n            __m128d diff = _mm_sub_pd(a, b);\n            __m128d abs_diff = _mm_andnot_pd(_mm_set1_pd(-0.0), diff);\n            __m128d cmp = _mm_cmplt_pd(abs_diff, thresh);\n            int mask = _mm_movemask_pd(cmp);\n            if (mask != 0) return true;\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_63_SSE", "completion": "```c++\nbool below_zero_simd(std::vector<int> operations) {\n    __m128i balance = _mm_setzero_si128();\n    __m128i zero = _mm_setzero_si128();\n\n    for (size_t i = 0; i < operations.size(); i += 4) {\n        __m128i ops = _mm_loadu_si128((__m128i*)&operations[i]);\n        balance = _mm_add_epi32(balance, ops);\n        __m128i mask = _mm_cmplt_epi32(balance, zero);\n        if (_mm_movemask_epi8(mask)) {\n            return true;\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_63_SSE", "completion": "```cpp\nbool below_zero_simd(std::vector<int> operations) {\n    __m128i balance = _mm_setzero_si128();\n    __m128i zero = _mm_setzero_si128();\n\n    for (size_t i = 0; i < operations.size(); i += 4) {\n        __m128i ops = _mm_loadu_si128((__m128i*)&operations[i]);\n        balance = _mm_add_epi32(balance, ops);\n        __m128i mask = _mm_cmplt_epi32(balance, zero);\n        if (_mm_movemask_epi8(mask)) {\n            return true;\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_63_SSE", "completion": "```cpp\nbool below_zero_simd(std::vector<int> operations) {\n    __m128i balance = _mm_setzero_si128();\n    __m128i zero = _mm_setzero_si128();\n\n    for (size_t i = 0; i < operations.size(); i += 4) {\n        __m128i ops = _mm_loadu_si128((__m128i*)&operations[i]);\n        balance = _mm_add_epi32(balance, ops);\n        __m128i mask = _mm_cmplt_epi32(balance, zero);\n        if (_mm_movemask_epi8(mask)) {\n            return true;\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_63_SSE", "completion": "```c++\nbool below_zero_simd(std::vector<int> operations) {\n    __m128i balance = _mm_setzero_si128();\n    __m128i zero = _mm_setzero_si128();\n\n    for (size_t i = 0; i < operations.size(); i += 4) {\n        __m128i ops = _mm_loadu_si128((__m128i*)&operations[i]);\n        balance = _mm_add_epi32(balance, ops);\n        __m128i mask = _mm_cmplt_epi32(balance, zero);\n        if (_mm_movemask_epi8(mask) != 0) {\n            return true;\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_63_SSE", "completion": "```c++\nbool below_zero_simd(std::vector<int> operations) {\n    __m128i balance = _mm_setzero_si128();\n    __m128i zero = _mm_setzero_si128();\n\n    for (size_t i = 0; i < operations.size(); i += 4) {\n        __m128i ops = _mm_loadu_si128((__m128i*)&operations[i]);\n        balance = _mm_add_epi32(balance, ops);\n        __m128i mask = _mm_cmplt_epi32(balance, zero);\n        if (_mm_movemask_epi8(mask)) {\n            return true;\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_64_SSE", "completion": "```c++\ndouble mean_absolute_deviation_simd(std::vector<double> numbers) {\n    size_t n = numbers.size();\n    __m128d sum = _mm_setzero_pd();\n    __m128d mean = _mm_setzero_pd();\n\n    for (size_t i = 0; i < n; i += 2) {\n        __m128d x = _mm_loadu_pd(&numbers[i]);\n        sum = _mm_add_pd(sum, x);\n    }\n\n    double total_sum[2];\n    _mm_storeu_pd(total_sum, sum);\n    double mean_value = (total_sum[0] + total_sum[1]) / n;\n\n    mean = _mm_set1_pd(mean_value);\n    __m128d mad_sum = _mm_setzero_pd();\n\n    for (size_t i = 0; i < n; i += 2) {\n        __m128d x = _mm_loadu_pd(&numbers[i]);\n        __m128d diff = _mm_sub_pd(x, mean);\n        __m128d abs_diff = _mm_andnot_pd(_mm_set1_pd(-0.0), diff);\n        mad_sum = _mm_add_pd(mad_sum, abs_diff);\n    }\n\n    double mad_total[2];\n    _mm_storeu_pd(mad_total, mad_sum);\n    double mad = (mad_total[0] + mad_total[1]) / n;\n\n    return mad;\n}\n```"}
{"task_id": "SimdBench_64_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <cmath>\n\ndouble mean_absolute_deviation_simd(std::vector<double> numbers) {\n    size_t n = numbers.size();\n    if (n == 0) return 0.0;\n\n    __m128d sum = _mm_setzero_pd();\n    for (size_t i = 0; i < n; i += 2) {\n        __m128d val = _mm_loadu_pd(&numbers[i]);\n        sum = _mm_add_pd(sum, val);\n    }\n\n    double total_sum[2];\n    _mm_storeu_pd(total_sum, sum);\n    double mean = (total_sum[0] + total_sum[1]) / n;\n\n    __m128d mean_vec = _mm_set1_pd(mean);\n    __m128d mad_sum = _mm_setzero_pd();\n    for (size_t i = 0; i < n; i += 2) {\n        __m128d val = _mm_loadu_pd(&numbers[i]);\n        __m128d diff = _mm_sub_pd(val, mean_vec);\n        __m128d abs_diff = _mm_andnot_pd(_mm_set1_pd(-0.0), diff);\n        mad_sum = _mm_add_pd(mad_sum, abs_diff);\n    }\n\n    double mad_total[2];\n    _mm_storeu_pd(mad_total, mad_sum);\n    double mad = (mad_total[0] + mad_total[1]) / n;\n\n    return mad;\n}\n```"}
{"task_id": "SimdBench_64_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <cmath>\n\ndouble mean_absolute_deviation_simd(std::vector<double> numbers) {\n    size_t n = numbers.size();\n    if (n == 0) return 0.0;\n\n    __m128d sum = _mm_setzero_pd();\n    for (size_t i = 0; i < n; i += 2) {\n        __m128d val = _mm_loadu_pd(&numbers[i]);\n        sum = _mm_add_pd(sum, val);\n    }\n\n    double total_sum = _mm_cvtsd_f64(sum) + _mm_cvtsd_f64(_mm_unpackhi_pd(sum, sum));\n    double mean = total_sum / n;\n\n    __m128d mean_vec = _mm_set1_pd(mean);\n    __m128d abs_diff_sum = _mm_setzero_pd();\n    for (size_t i = 0; i < n; i += 2) {\n        __m128d val = _mm_loadu_pd(&numbers[i]);\n        __m128d diff = _mm_sub_pd(val, mean_vec);\n        __m128d abs_diff = _mm_andnot_pd(_mm_set1_pd(-0.0), diff);\n        abs_diff_sum = _mm_add_pd(abs_diff_sum, abs_diff);\n    }\n\n    double abs_diff_total = _mm_cvtsd_f64(abs_diff_sum) + _mm_cvtsd_f64(_mm_unpackhi_pd(abs_diff_sum, abs_diff_sum));\n    return abs_diff_total / n;\n}\n```"}
{"task_id": "SimdBench_64_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <cmath>\n\ndouble mean_absolute_deviation_simd(std::vector<double> numbers) {\n    size_t n = numbers.size();\n    if (n == 0) return 0.0;\n\n    __m128d sum = _mm_setzero_pd();\n    for (size_t i = 0; i < n; i += 2) {\n        __m128d val = _mm_loadu_pd(&numbers[i]);\n        sum = _mm_add_pd(sum, val);\n    }\n\n    double total_sum = _mm_cvtsd_f64(sum) + _mm_cvtsd_f64(_mm_unpackhi_pd(sum, sum));\n    double mean = total_sum / n;\n\n    __m128d mean_vec = _mm_set1_pd(mean);\n    __m128d mad_sum = _mm_setzero_pd();\n    for (size_t i = 0; i < n; i += 2) {\n        __m128d val = _mm_loadu_pd(&numbers[i]);\n        __m128d diff = _mm_sub_pd(val, mean_vec);\n        __m128d abs_diff = _mm_andnot_pd(_mm_set1_pd(-0.0), diff);\n        mad_sum = _mm_add_pd(mad_sum, abs_diff);\n    }\n\n    double mad_total = _mm_cvtsd_f64(mad_sum) + _mm_cvtsd_f64(_mm_unpackhi_pd(mad_sum, mad_sum));\n    return mad_total / n;\n}\n```"}
{"task_id": "SimdBench_64_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <cmath>\n\ndouble mean_absolute_deviation_simd(std::vector<double> numbers) {\n    size_t n = numbers.size();\n    if (n == 0) return 0.0;\n\n    __m128d sum = _mm_setzero_pd();\n    for (size_t i = 0; i < n; i += 2) {\n        __m128d val = _mm_loadu_pd(&numbers[i]);\n        sum = _mm_add_pd(sum, val);\n    }\n\n    double total_sum[2];\n    _mm_storeu_pd(total_sum, sum);\n    double mean = (total_sum[0] + total_sum[1]) / n;\n\n    __m128d mean_vec = _mm_set1_pd(mean);\n    __m128d abs_diff_sum = _mm_setzero_pd();\n    for (size_t i = 0; i < n; i += 2) {\n        __m128d val = _mm_loadu_pd(&numbers[i]);\n        __m128d diff = _mm_sub_pd(val, mean_vec);\n        __m128d abs_diff = _mm_andnot_pd(_mm_set1_pd(-0.0), diff);\n        abs_diff_sum = _mm_add_pd(abs_diff_sum, abs_diff);\n    }\n\n    double abs_diff_total[2];\n    _mm_storeu_pd(abs_diff_total, abs_diff_sum);\n    double mad = (abs_diff_total[0] + abs_diff_total[1]) / n;\n\n    return mad;\n}\n```"}
{"task_id": "SimdBench_65_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> intersperse_simd(std::vector<int> numbers, int delimeter) {\n    if (numbers.empty()) return {};\n\n    std::vector<int> result;\n    result.reserve(numbers.size() * 2 - 1);\n\n    __m128i delim = _mm_set1_epi32(delimeter);\n\n    for (size_t i = 0; i < numbers.size(); ++i) {\n        result.push_back(numbers[i]);\n        if (i < numbers.size() - 1) {\n            result.push_back(delimeter);\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_65_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> intersperse_simd(std::vector<int> numbers, int delimeter) {\n    if (numbers.empty()) return numbers;\n\n    std::vector<int> result;\n    result.reserve(numbers.size() * 2 - 1);\n\n    __m128i delim = _mm_set1_epi32(delimeter);\n\n    for (size_t i = 0; i < numbers.size(); ++i) {\n        result.push_back(numbers[i]);\n        if (i < numbers.size() - 1) {\n            result.push_back(delimeter);\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_65_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> intersperse_simd(std::vector<int> numbers, int delimeter) {\n    if (numbers.empty()) return {};\n\n    std::vector<int> result;\n    result.reserve(numbers.size() * 2 - 1);\n\n    __m128i delim = _mm_set1_epi32(delimeter);\n\n    for (size_t i = 0; i < numbers.size(); ++i) {\n        result.push_back(numbers[i]);\n        if (i < numbers.size() - 1) {\n            result.push_back(delimeter);\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_65_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> intersperse_simd(std::vector<int> numbers, int delimeter) {\n    if (numbers.empty()) return numbers;\n\n    std::vector<int> result;\n    result.reserve(numbers.size() * 2 - 1);\n\n    __m128i delim = _mm_set1_epi32(delimeter);\n\n    for (size_t i = 0; i < numbers.size(); ++i) {\n        result.push_back(numbers[i]);\n        if (i < numbers.size() - 1) {\n            result.push_back(delimeter);\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_65_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> intersperse_simd(std::vector<int> numbers, int delimeter) {\n    if (numbers.empty()) return numbers;\n\n    std::vector<int> result;\n    result.reserve(numbers.size() * 2 - 1);\n\n    __m128i delim = _mm_set1_epi32(delimeter);\n\n    for (size_t i = 0; i < numbers.size(); ++i) {\n        result.push_back(numbers[i]);\n        if (i < numbers.size() - 1) {\n            result.push_back(delimeter);\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_66_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int64_t> sum_product_simd(std::vector<int16_t> numbers) {\n    int64_t sum = 0;\n    int64_t product = 1;\n\n    if (numbers.empty()) {\n        return {0, 1};\n    }\n\n    size_t size = numbers.size();\n    size_t i = 0;\n\n    __m128i sum_vec = _mm_setzero_si128();\n    __m128i prod_vec = _mm_set1_epi32(1);\n\n    for (; i + 8 <= size; i += 8) {\n        __m128i a = _mm_loadu_si128((__m128i*)&numbers[i]);\n        __m128i b = _mm_loadu_si128((__m128i*)&numbers[i + 4]);\n\n        sum_vec = _mm_add_epi16(sum_vec, a);\n        sum_vec = _mm_add_epi16(sum_vec, b);\n\n        prod_vec = _mm_mullo_epi16(prod_vec, a);\n        prod_vec = _mm_mullo_epi16(prod_vec, b);\n    }\n\n    alignas(16) int16_t sum_array[8];\n    alignas(16) int16_t prod_array[8];\n\n    _mm_store_si128((__m128i*)sum_array, sum_vec);\n    _mm_store_si128((__m128i*)prod_array, prod_vec);\n\n    for (int j = 0; j < 8; ++j) {\n        sum += sum_array[j];\n        product *= prod_array[j];\n    }\n\n    for (; i < size; ++i) {\n        sum += numbers[i];\n        product *= numbers[i];\n    }\n\n    return {sum, product};\n}\n```"}
{"task_id": "SimdBench_66_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int64_t> sum_product_simd(std::vector<int16_t> numbers) {\n    int64_t sum = 0;\n    int64_t product = 1;\n    size_t size = numbers.size();\n\n    if (size == 0) {\n        return {0, 1};\n    }\n\n    __m128i sum_vec = _mm_setzero_si128();\n    __m128i product_vec = _mm_set1_epi32(1);\n\n    for (size_t i = 0; i < size; i += 8) {\n        __m128i a = _mm_loadu_si128((__m128i*)&numbers[i]);\n        __m128i b = _mm_loadu_si128((__m128i*)&numbers[i + 4]);\n\n        sum_vec = _mm_add_epi16(sum_vec, a);\n        sum_vec = _mm_add_epi16(sum_vec, b);\n\n        product_vec = _mm_mullo_epi16(product_vec, a);\n        product_vec = _mm_mullo_epi16(product_vec, b);\n    }\n\n    int16_t sum_arr[8];\n    _mm_storeu_si128((__m128i*)sum_arr, sum_vec);\n\n    for (int i = 0; i < 8; ++i) {\n        sum += sum_arr[i];\n    }\n\n    int32_t product_arr[4];\n    _mm_storeu_si128((__m128i*)product_arr, product_vec);\n\n    for (int i = 0; i < 4; ++i) {\n        product *= product_arr[i];\n    }\n\n    return {sum, product};\n}\n```"}
{"task_id": "SimdBench_66_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int64_t> sum_product_simd(std::vector<int16_t> numbers) {\n    int64_t sum = 0;\n    int64_t product = 1;\n    size_t size = numbers.size();\n\n    if (size == 0) {\n        return {0, 1};\n    }\n\n    __m128i sum_vec = _mm_setzero_si128();\n    __m128i product_vec = _mm_set1_epi32(1);\n\n    for (size_t i = 0; i < size; i += 8) {\n        __m128i a = _mm_loadu_si128((__m128i*)&numbers[i]);\n        __m128i b = _mm_loadu_si128((__m128i*)&numbers[i + 4]);\n\n        sum_vec = _mm_add_epi16(sum_vec, a);\n        sum_vec = _mm_add_epi16(sum_vec, b);\n\n        product_vec = _mm_mullo_epi16(product_vec, a);\n        product_vec = _mm_mullo_epi16(product_vec, b);\n    }\n\n    alignas(16) int16_t sum_array[8];\n    alignas(16) int16_t product_array[8];\n\n    _mm_store_si128((__m128i*)sum_array, sum_vec);\n    _mm_store_si128((__m128i*)product_array, product_vec);\n\n    for (int i = 0; i < 8; ++i) {\n        sum += sum_array[i];\n        product *= product_array[i];\n    }\n\n    return {sum, product};\n}\n```"}
{"task_id": "SimdBench_66_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int64_t> sum_product_simd(std::vector<int16_t> numbers) {\n    int64_t sum = 0;\n    int64_t product = 1;\n    size_t size = numbers.size();\n\n    if (size == 0) {\n        return {0, 1};\n    }\n\n    __m128i sum_vec = _mm_setzero_si128();\n    __m128i product_vec = _mm_set1_epi32(1);\n\n    for (size_t i = 0; i < size; i += 8) {\n        __m128i a = _mm_loadu_si128((__m128i*)&numbers[i]);\n        __m128i b = _mm_loadu_si128((__m128i*)&numbers[i + 4]);\n\n        sum_vec = _mm_add_epi16(sum_vec, a);\n        sum_vec = _mm_add_epi16(sum_vec, b);\n\n        product_vec = _mm_mullo_epi16(product_vec, a);\n        product_vec = _mm_mullo_epi16(product_vec, b);\n    }\n\n    alignas(16) int16_t sum_array[8];\n    alignas(16) int16_t product_array[8];\n\n    _mm_store_si128((__m128i*)sum_array, sum_vec);\n    _mm_store_si128((__m128i*)product_array, product_vec);\n\n    for (int i = 0; i < 8; ++i) {\n        sum += sum_array[i];\n        product *= product_array[i];\n    }\n\n    return {sum, product};\n}\n```"}
{"task_id": "SimdBench_66_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int64_t> sum_product_simd(std::vector<int16_t> numbers) {\n    int64_t sum = 0;\n    int64_t product = 1;\n    size_t size = numbers.size();\n\n    if (size == 0) {\n        return {0, 1};\n    }\n\n    __m128i sum_vec = _mm_setzero_si128();\n    __m128i product_vec = _mm_set1_epi32(1);\n\n    for (size_t i = 0; i < size; i += 8) {\n        __m128i num_vec = _mm_loadu_si128((__m128i*)&numbers[i]);\n\n        sum_vec = _mm_add_epi16(sum_vec, num_vec);\n\n        __m128i lo = _mm_mullo_epi16(num_vec, product_vec);\n        __m128i hi = _mm_mulhi_epi16(num_vec, product_vec);\n        product_vec = _mm_unpacklo_epi16(lo, hi);\n    }\n\n    int16_t sum_arr[8];\n    _mm_storeu_si128((__m128i*)sum_arr, sum_vec);\n    for (int i = 0; i < 8; ++i) {\n        sum += sum_arr[i];\n    }\n\n    int32_t product_arr[4];\n    _mm_storeu_si128((__m128i*)product_arr, product_vec);\n    for (int i = 0; i < 4; ++i) {\n        product *= product_arr[i];\n    }\n\n    return {sum, product};\n}\n```"}
{"task_id": "SimdBench_67_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> rolling_max_simd(std::vector<int> numbers) {\n    std::vector<int> result(numbers.size());\n    if (numbers.empty()) return result;\n\n    __m128i max_val = _mm_set1_epi32(numbers[0]);\n    result[0] = numbers[0];\n\n    for (size_t i = 1; i < numbers.size(); i += 4) {\n        __m128i current = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&numbers[i]));\n        max_val = _mm_max_epi32(max_val, current);\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i]), max_val);\n    }\n\n    for (size_t i = 0; i < numbers.size(); ++i) {\n        result[i] = std::max(result[i], result[i - 1]);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_67_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> rolling_max_simd(std::vector<int> numbers) {\n    std::vector<int> result(numbers.size());\n    if (numbers.empty()) return result;\n\n    __m128i max_val = _mm_set1_epi32(numbers[0]);\n    result[0] = numbers[0];\n\n    for (size_t i = 1; i < numbers.size(); i += 4) {\n        __m128i current_vals = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&numbers[i]));\n        max_val = _mm_max_epi32(max_val, current_vals);\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i]), max_val);\n    }\n\n    for (size_t i = 0; i < numbers.size(); ++i) {\n        result[i] = _mm_cvtsi128_si32(_mm_shuffle_epi32(max_val, _MM_SHUFFLE(i % 4, i % 4, i % 4, i % 4)));\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_67_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> rolling_max_simd(std::vector<int> numbers) {\n    std::vector<int> result(numbers.size());\n    if (numbers.empty()) return result;\n\n    __m128i max_val = _mm_set1_epi32(numbers[0]);\n    result[0] = numbers[0];\n\n    for (size_t i = 1; i < numbers.size(); i += 4) {\n        __m128i current_vals = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&numbers[i]));\n        max_val = _mm_max_epi32(max_val, current_vals);\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i]), max_val);\n    }\n\n    for (size_t i = 0; i < numbers.size(); ++i) {\n        result[i] = _mm_cvtsi128_si32(_mm_shuffle_epi32(max_val, _MM_SHUFFLE(i % 4, i % 4, i % 4, i % 4)));\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_67_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> rolling_max_simd(std::vector<int> numbers) {\n    int n = numbers.size();\n    std::vector<int> result(n);\n    if (n == 0) return result;\n\n    __m128i max_val = _mm_set1_epi32(numbers[0]);\n    result[0] = numbers[0];\n\n    for (int i = 1; i < n; i += 4) {\n        __m128i current = _mm_loadu_si128((__m128i*)&numbers[i]);\n        max_val = _mm_max_epi32(max_val, current);\n        _mm_storeu_si128((__m128i*)&result[i], max_val);\n    }\n\n    for (int i = 1; i < n; ++i) {\n        result[i] = std::max(result[i], result[i - 1]);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_67_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> rolling_max_simd(std::vector<int> numbers) {\n    std::vector<int> result(numbers.size());\n    if (numbers.empty()) return result;\n\n    __m128i max_val = _mm_set1_epi32(numbers[0]);\n    result[0] = numbers[0];\n\n    for (size_t i = 1; i < numbers.size(); i += 4) {\n        __m128i current = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&numbers[i]));\n        max_val = _mm_max_epi32(max_val, current);\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i]), max_val);\n    }\n\n    for (size_t i = numbers.size() - (numbers.size() % 4); i < numbers.size(); ++i) {\n        result[i] = std::max(result[i - 1], numbers[i]);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_68_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string string_xor_simd(std::string a, std::string b) {\n    size_t len = a.size();\n    std::string result(len, '0');\n\n    for (size_t i = 0; i < len; i += 16) {\n        __m128i vec_a = _mm_loadu_si128(reinterpret_cast<const __m128i*>(a.data() + i));\n        __m128i vec_b = _mm_loadu_si128(reinterpret_cast<const __m128i*>(b.data() + i));\n        __m128i vec_result = _mm_xor_si128(vec_a, vec_b);\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i]), vec_result);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_68_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string string_xor_simd(std::string a, std::string b) {\n    size_t len = a.size();\n    std::string result(len, '0');\n\n    for (size_t i = 0; i < len; i += 16) {\n        __m128i vec_a = _mm_loadu_si128(reinterpret_cast<const __m128i*>(a.data() + i));\n        __m128i vec_b = _mm_loadu_si128(reinterpret_cast<const __m128i*>(b.data() + i));\n        __m128i vec_result = _mm_xor_si128(vec_a, vec_b);\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i]), vec_result);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_68_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string string_xor_simd(std::string a, std::string b) {\n    size_t len = a.size();\n    std::string result(len, '0');\n\n    for (size_t i = 0; i < len; i += 16) {\n        __m128i vec_a = _mm_loadu_si128(reinterpret_cast<const __m128i*>(a.data() + i));\n        __m128i vec_b = _mm_loadu_si128(reinterpret_cast<const __m128i*>(b.data() + i));\n        __m128i vec_result = _mm_xor_si128(vec_a, vec_b);\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i]), vec_result);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_68_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string string_xor_simd(std::string a, std::string b) {\n    size_t len = a.size();\n    std::string result(len, '0');\n\n    for (size_t i = 0; i < len; i += 16) {\n        __m128i vec_a = _mm_loadu_si128(reinterpret_cast<const __m128i*>(a.data() + i));\n        __m128i vec_b = _mm_loadu_si128(reinterpret_cast<const __m128i*>(b.data() + i));\n        __m128i vec_result = _mm_xor_si128(vec_a, vec_b);\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i]), vec_result);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_68_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string string_xor_simd(std::string a, std::string b) {\n    size_t len = a.size();\n    std::string result(len, '0');\n\n    for (size_t i = 0; i < len; i += 16) {\n        __m128i vec_a = _mm_loadu_si128(reinterpret_cast<const __m128i*>(a.data() + i));\n        __m128i vec_b = _mm_loadu_si128(reinterpret_cast<const __m128i*>(b.data() + i));\n        __m128i vec_result = _mm_xor_si128(vec_a, vec_b);\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i]), vec_result);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_69_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n\nstd::string longest_simd(const std::vector<std::string> & strings) {\n    if (strings.empty()) {\n        return \"\";\n    }\n\n    size_t max_length = 0;\n    size_t max_index = 0;\n\n    for (size_t i = 0; i < strings.size(); ++i) {\n        size_t length = strings[i].size();\n        if (length > max_length) {\n            max_length = length;\n            max_index = i;\n        }\n    }\n\n    return strings[max_index];\n}\n```"}
{"task_id": "SimdBench_69_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n\nstd::string longest_simd(const std::vector<std::string> & strings) {\n    if (strings.empty()) {\n        return \"\";\n    }\n\n    size_t max_length = 0;\n    size_t max_index = 0;\n\n    for (size_t i = 0; i < strings.size(); ++i) {\n        size_t length = strings[i].size();\n        if (length > max_length) {\n            max_length = length;\n            max_index = i;\n        }\n    }\n\n    return strings[max_index];\n}\n```"}
{"task_id": "SimdBench_69_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n\nstd::string longest_simd(const std::vector<std::string> & strings) {\n    if (strings.empty()) {\n        return \"\";\n    }\n\n    size_t max_length = 0;\n    size_t max_index = 0;\n\n    for (size_t i = 0; i < strings.size(); ++i) {\n        size_t length = strings[i].size();\n        if (length > max_length) {\n            max_length = length;\n            max_index = i;\n        }\n    }\n\n    return strings[max_index];\n}\n```"}
{"task_id": "SimdBench_69_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n\nstd::string longest_simd(const std::vector<std::string> & strings) {\n    if (strings.empty()) {\n        return \"\";\n    }\n\n    size_t max_length = 0;\n    std::string longest_string = strings[0];\n\n    for (const auto& str : strings) {\n        size_t length = str.size();\n        if (length > max_length) {\n            max_length = length;\n            longest_string = str;\n        }\n    }\n\n    return longest_string;\n}\n```"}
{"task_id": "SimdBench_69_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n\nstd::string longest_simd(const std::vector<std::string> & strings) {\n    if (strings.empty()) {\n        return \"\";\n    }\n\n    size_t max_length = 0;\n    std::string longest_string = strings[0];\n\n    for (const auto& str : strings) {\n        size_t length = str.size();\n        if (length > max_length) {\n            max_length = length;\n            longest_string = str;\n        }\n    }\n\n    return longest_string;\n}\n```"}
{"task_id": "SimdBench_70_SSE", "completion": "```c\nuint64_t greatest_common_divisor_simd(uint64_t a, uint64_t b) {\n    __m128i va = _mm_set1_epi64x(a);\n    __m128i vb = _mm_set1_epi64x(b);\n\n    while (!_mm_testz_si128(vb, vb)) {\n        __m128i temp = vb;\n        vb = _mm_sub_epi64(va, _mm_and_si128(vb, _mm_sub_epi64(_mm_set1_epi64x(1), _mm_cmpeq_epi64(vb, _mm_setzero_si128()))));\n        va = temp;\n    }\n\n    return _mm_cvtsi128_si64(va);\n}\n```"}
{"task_id": "SimdBench_70_SSE", "completion": "```c\nuint64_t greatest_common_divisor_simd(uint64_t a, uint64_t b) {\n    __m128i vec_a = _mm_set1_epi64x(a);\n    __m128i vec_b = _mm_set1_epi64x(b);\n\n    while (!_mm_testz_si128(vec_b, vec_b)) {\n        __m128i temp = vec_b;\n        vec_b = _mm_sub_epi64(vec_a, _mm_and_si128(vec_b, _mm_sub_epi64(_mm_set1_epi64x(1), _mm_cmpeq_epi64(vec_a, vec_b))));\n        vec_a = temp;\n    }\n\n    return _mm_cvtsi128_si64(vec_a);\n}\n```"}
{"task_id": "SimdBench_70_SSE", "completion": "```c\nuint64_t greatest_common_divisor_simd(uint64_t a, uint64_t b) {\n    __m128i va = _mm_set1_epi64x(a);\n    __m128i vb = _mm_set1_epi64x(b);\n    __m128i zero = _mm_setzero_si128();\n\n    while (!_mm_testz_si128(vb, vb)) {\n        __m128i temp = vb;\n        vb = _mm_sub_epi64(va, _mm_and_si128(vb, _mm_cmpeq_epi64(_mm_and_si128(va, _mm_set1_epi64x(1)), zero)));\n        va = temp;\n    }\n\n    return _mm_cvtsi128_si64(va);\n}\n```"}
{"task_id": "SimdBench_70_SSE", "completion": "```c\nuint64_t greatest_common_divisor_simd(uint64_t a, uint64_t b) {\n    __m128i va = _mm_set1_epi64x(a);\n    __m128i vb = _mm_set1_epi64x(b);\n\n    while (!_mm_testz_si128(vb, vb)) {\n        __m128i temp = vb;\n        vb = _mm_sub_epi64(va, _mm_and_si128(vb, _mm_sub_epi64(va, vb)));\n        va = temp;\n    }\n\n    return _mm_cvtsi128_si64(va);\n}\n```"}
{"task_id": "SimdBench_70_SSE", "completion": "```c\nuint64_t greatest_common_divisor_simd(uint64_t a, uint64_t b) {\n    __m128i va = _mm_set1_epi64x(a);\n    __m128i vb = _mm_set1_epi64x(b);\n\n    while (!_mm_testz_si128(vb, vb)) {\n        __m128i temp = vb;\n        vb = _mm_sub_epi64(va, _mm_and_si128(vb, _mm_sub_epi64(va, vb)));\n        va = temp;\n    }\n\n    return _mm_cvtsi128_si64(va);\n}\n```"}
{"task_id": "SimdBench_71_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <cmath>\n#include <limits>\n\nstd::vector<float> find_closest_elements_simd(std::vector<float> numbers) {\n    size_t n = numbers.size();\n    float min_diff = std::numeric_limits<float>::max();\n    std::vector<float> result(2);\n\n    for (size_t i = 0; i < n; i += 4) {\n        __m128 a = _mm_loadu_ps(&numbers[i]);\n        for (size_t j = i + 4; j < n; j += 4) {\n            __m128 b = _mm_loadu_ps(&numbers[j]);\n            __m128 diff = _mm_sub_ps(a, b);\n            __m128 abs_diff = _mm_andnot_ps(_mm_set1_ps(-0.0f), diff);\n            float diff_arr[4];\n            _mm_storeu_ps(diff_arr, abs_diff);\n\n            for (int k = 0; k < 4; ++k) {\n                if (diff_arr[k] < min_diff) {\n                    min_diff = diff_arr[k];\n                    result[0] = std::min(numbers[i + k], numbers[j]);\n                    result[1] = std::max(numbers[i + k], numbers[j]);\n                }\n            }\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_71_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <cmath>\n#include <limits>\n\nstd::vector<float> find_closest_elements_simd(std::vector<float> numbers) {\n    size_t n = numbers.size();\n    float min_diff = std::numeric_limits<float>::max();\n    std::vector<float> result(2);\n\n    for (size_t i = 0; i < n; i += 4) {\n        __m128 a = _mm_loadu_ps(&numbers[i]);\n        for (size_t j = i + 4; j < n; j += 4) {\n            __m128 b = _mm_loadu_ps(&numbers[j]);\n            __m128 diff = _mm_sub_ps(a, b);\n            __m128 abs_diff = _mm_andnot_ps(_mm_set1_ps(-0.0f), diff);\n            float diff_array[4];\n            _mm_storeu_ps(diff_array, abs_diff);\n\n            for (int k = 0; k < 4; ++k) {\n                if (diff_array[k] < min_diff) {\n                    min_diff = diff_array[k];\n                    result[0] = std::min(numbers[i + k], numbers[j]);\n                    result[1] = std::max(numbers[i + k], numbers[j]);\n                }\n            }\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_71_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <cmath>\n#include <limits>\n\nstd::vector<float> find_closest_elements_simd(std::vector<float> numbers) {\n    size_t n = numbers.size();\n    float min_diff = std::numeric_limits<float>::max();\n    std::vector<float> closest_pair(2);\n\n    for (size_t i = 0; i < n; i += 4) {\n        __m128 a = _mm_loadu_ps(&numbers[i]);\n        for (size_t j = i + 4; j < n; j += 4) {\n            __m128 b = _mm_loadu_ps(&numbers[j]);\n\n            __m128 diff = _mm_sub_ps(a, b);\n            diff = _mm_mul_ps(diff, diff);\n\n            float diff_array[4];\n            _mm_storeu_ps(diff_array, diff);\n\n            for (int k = 0; k < 4; ++k) {\n                if (diff_array[k] < min_diff) {\n                    min_diff = diff_array[k];\n                    closest_pair[0] = std::min(numbers[i + k], numbers[j]);\n                    closest_pair[1] = std::max(numbers[i + k], numbers[j]);\n                }\n            }\n        }\n    }\n\n    return closest_pair;\n}\n```"}
{"task_id": "SimdBench_71_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <cmath>\n#include <limits>\n\nstd::vector<float> find_closest_elements_simd(std::vector<float> numbers) {\n    size_t n = numbers.size();\n    float min_diff = std::numeric_limits<float>::max();\n    std::vector<float> result(2);\n\n    for (size_t i = 0; i < n; i += 4) {\n        __m128 a = _mm_loadu_ps(&numbers[i]);\n        for (size_t j = i + 4; j < n; j += 4) {\n            __m128 b = _mm_loadu_ps(&numbers[j]);\n\n            __m128 diff = _mm_sub_ps(a, b);\n            diff = _mm_mul_ps(diff, diff);\n\n            float diff_array[4];\n            _mm_storeu_ps(diff_array, diff);\n\n            for (int k = 0; k < 4; ++k) {\n                if (diff_array[k] < min_diff) {\n                    min_diff = diff_array[k];\n                    result[0] = std::min(numbers[i + k], numbers[j]);\n                    result[1] = std::max(numbers[i + k], numbers[j]);\n                }\n            }\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_71_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <cmath>\n#include <limits>\n\nstd::vector<float> find_closest_elements_simd(std::vector<float> numbers) {\n    size_t n = numbers.size();\n    float min_diff = std::numeric_limits<float>::max();\n    std::vector<float> closest_pair(2);\n\n    for (size_t i = 0; i < n; ++i) {\n        __m128 current = _mm_set1_ps(numbers[i]);\n        for (size_t j = i + 1; j < n; j += 4) {\n            __m128 next = _mm_loadu_ps(&numbers[j]);\n            __m128 diff = _mm_sub_ps(next, current);\n            __m128 abs_diff = _mm_andnot_ps(_mm_set1_ps(-0.0f), diff);\n            float diffs[4];\n            _mm_storeu_ps(diffs, abs_diff);\n\n            for (int k = 0; k < 4 && j + k < n; ++k) {\n                if (diffs[k] < min_diff) {\n                    min_diff = diffs[k];\n                    closest_pair[0] = std::min(numbers[i], numbers[j + k]);\n                    closest_pair[1] = std::max(numbers[i], numbers[j + k]);\n                }\n            }\n        }\n    }\n\n    return closest_pair;\n}\n```"}
{"task_id": "SimdBench_72_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<float> rescale_to_unit_simd(std::vector<float> numbers) {\n    size_t n = numbers.size();\n    std::vector<float> result(n);\n\n    __m128 min_val = _mm_set1_ps(numbers[0]);\n    __m128 max_val = _mm_set1_ps(numbers[0]);\n\n    for (size_t i = 0; i < n; i += 4) {\n        __m128 vec = _mm_loadu_ps(&numbers[i]);\n        min_val = _mm_min_ps(min_val, vec);\n        max_val = _mm_max_ps(max_val, vec);\n    }\n\n    float min_arr[4];\n    float max_arr[4];\n    _mm_storeu_ps(min_arr, min_val);\n    _mm_storeu_ps(max_arr, max_val);\n\n    float min = min_arr[0];\n    float max = max_arr[0];\n    for (int i = 1; i < 4; ++i) {\n        min = std::min(min, min_arr[i]);\n        max = std::max(max, max_arr[i]);\n    }\n\n    __m128 scale = _mm_set1_ps(1.0f / (max - min));\n    __m128 offset = _mm_set1_ps(-min);\n\n    for (size_t i = 0; i < n; i += 4) {\n        __m128 vec = _mm_loadu_ps(&numbers[i]);\n        vec = _mm_add_ps(_mm_mul_ps(_mm_sub_ps(vec, offset), scale), offset);\n        _mm_storeu_ps(&result[i], vec);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_72_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<float> rescale_to_unit_simd(std::vector<float> numbers) {\n    size_t n = numbers.size();\n    std::vector<float> result(n);\n\n    __m128 min_val = _mm_set1_ps(numbers[0]);\n    __m128 max_val = _mm_set1_ps(numbers[0]);\n\n    for (size_t i = 0; i < n; i += 4) {\n        __m128 current = _mm_loadu_ps(&numbers[i]);\n        min_val = _mm_min_ps(min_val, current);\n        max_val = _mm_max_ps(max_val, current);\n    }\n\n    float min_arr[4];\n    float max_arr[4];\n    _mm_storeu_ps(min_arr, min_val);\n    _mm_storeu_ps(max_arr, max_val);\n\n    float min = min_arr[0];\n    float max = max_arr[0];\n    for (int i = 1; i < 4; ++i) {\n        if (min_arr[i] < min) min = min_arr[i];\n        if (max_arr[i] > max) max = max_arr[i];\n    }\n\n    __m128 scale = _mm_set1_ps(1.0f / (max - min));\n    __m128 offset = _mm_set1_ps(-min);\n\n    for (size_t i = 0; i < n; i += 4) {\n        __m128 current = _mm_loadu_ps(&numbers[i]);\n        current = _mm_add_ps(_mm_mul_ps(current, scale), offset);\n        _mm_storeu_ps(&result[i], current);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_72_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<float> rescale_to_unit_simd(std::vector<float> numbers) {\n    size_t n = numbers.size();\n    std::vector<float> result(n);\n\n    __m128 min_val = _mm_set1_ps(numbers[0]);\n    __m128 max_val = _mm_set1_ps(numbers[0]);\n\n    for (size_t i = 0; i < n; i += 4) {\n        __m128 vec = _mm_loadu_ps(&numbers[i]);\n        min_val = _mm_min_ps(min_val, vec);\n        max_val = _mm_max_ps(max_val, vec);\n    }\n\n    float min_arr[4];\n    float max_arr[4];\n    _mm_storeu_ps(min_arr, min_val);\n    _mm_storeu_ps(max_arr, max_val);\n\n    float min = min_arr[0];\n    float max = max_arr[0];\n    for (int i = 1; i < 4; ++i) {\n        if (min_arr[i] < min) min = min_arr[i];\n        if (max_arr[i] > max) max = max_arr[i];\n    }\n\n    __m128 scale = _mm_set1_ps(1.0f / (max - min));\n    __m128 offset = _mm_set1_ps(-min);\n\n    for (size_t i = 0; i < n; i += 4) {\n        __m128 vec = _mm_loadu_ps(&numbers[i]);\n        vec = _mm_add_ps(_mm_mul_ps(_mm_sub_ps(vec, offset), scale), offset);\n        _mm_storeu_ps(&result[i], vec);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_72_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<float> rescale_to_unit_simd(std::vector<float> numbers) {\n    size_t n = numbers.size();\n    std::vector<float> result(n);\n\n    __m128 min_val = _mm_set1_ps(numbers[0]);\n    __m128 max_val = _mm_set1_ps(numbers[0]);\n\n    for (size_t i = 0; i < n; i += 4) {\n        __m128 current = _mm_loadu_ps(&numbers[i]);\n        min_val = _mm_min_ps(min_val, current);\n        max_val = _mm_max_ps(max_val, current);\n    }\n\n    float min_arr[4];\n    float max_arr[4];\n    _mm_storeu_ps(min_arr, min_val);\n    _mm_storeu_ps(max_arr, max_val);\n\n    float min = min_arr[0];\n    float max = max_arr[0];\n    for (int i = 1; i < 4; ++i) {\n        if (min_arr[i] < min) min = min_arr[i];\n        if (max_arr[i] > max) max = max_arr[i];\n    }\n\n    __m128 scale = _mm_set1_ps(1.0f / (max - min));\n    __m128 offset = _mm_set1_ps(-min);\n\n    for (size_t i = 0; i < n; i += 4) {\n        __m128 current = _mm_loadu_ps(&numbers[i]);\n        current = _mm_add_ps(_mm_mul_ps(current, scale), offset);\n        _mm_storeu_ps(&result[i], current);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_72_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<float> rescale_to_unit_simd(std::vector<float> numbers) {\n    size_t size = numbers.size();\n    std::vector<float> result(size);\n\n    if (size < 2) {\n        return result;\n    }\n\n    __m128 min_val = _mm_set1_ps(numbers[0]);\n    __m128 max_val = _mm_set1_ps(numbers[0]);\n\n    for (size_t i = 0; i < size; i += 4) {\n        __m128 current = _mm_loadu_ps(&numbers[i]);\n        min_val = _mm_min_ps(min_val, current);\n        max_val = _mm_max_ps(max_val, current);\n    }\n\n    float min_arr[4];\n    float max_arr[4];\n    _mm_storeu_ps(min_arr, min_val);\n    _mm_storeu_ps(max_arr, max_val);\n\n    float min = min_arr[0];\n    float max = max_arr[0];\n    for (int i = 1; i < 4; ++i) {\n        min = std::min(min, min_arr[i]);\n        max = std::max(max, max_arr[i]);\n    }\n\n    __m128 scale = _mm_set1_ps(1.0f / (max - min));\n    __m128 offset = _mm_set1_ps(-min);\n\n    for (size_t i = 0; i < size; i += 4) {\n        __m128 current = _mm_loadu_ps(&numbers[i]);\n        current = _mm_add_ps(_mm_mul_ps(_mm_sub_ps(current, _mm_set1_ps(min)), scale), _mm_set1_ps(0.0f));\n        _mm_storeu_ps(&result[i], current);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_73_SSE", "completion": "```c\nuint64_t largest_divisor_simd(uint64_t n) {\n    uint64_t result = 1;\n    __m128i n_vec = _mm_set1_epi64x(n);\n    __m128i div_vec = _mm_set_epi64x(n / 2, n / 2 - 1);\n    __m128i one_vec = _mm_set1_epi64x(1);\n\n    for (uint64_t i = n / 2; i > 1; i -= 2) {\n        __m128i i_vec = _mm_set_epi64x(i, i - 1);\n        __m128i rem_vec = _mm_sub_epi64(n_vec, _mm_mullo_epi64(i_vec, _mm_div_epu64(n_vec, i_vec)));\n        __m128i mask = _mm_cmpeq_epi64(rem_vec, _mm_setzero_si128());\n\n        if (_mm_movemask_epi8(mask)) {\n            result = _mm_extract_epi64(mask, 0) ? i : i - 1;\n            break;\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_73_SSE", "completion": "```c\nuint64_t largest_divisor_simd(uint64_t n) {\n    __m128i vec_n = _mm_set1_epi64x(n);\n    __m128i vec_i = _mm_set_epi64x(n - 1, n - 2);\n    __m128i vec_step = _mm_set1_epi64x(2);\n    __m128i vec_zero = _mm_setzero_si128();\n    __m128i vec_one = _mm_set1_epi64x(1);\n\n    while (_mm_movemask_epi8(_mm_cmpeq_epi64(vec_i, vec_zero)) == 0) {\n        __m128i vec_rem = _mm_sub_epi64(vec_n, _mm_mullo_epi64(vec_i, _mm_div_epu64(vec_n, vec_i)));\n        __m128i vec_divisible = _mm_cmpeq_epi64(vec_rem, vec_zero);\n        if (_mm_movemask_epi8(vec_divisible) != 0) {\n            return _mm_cvtsi128_si64(vec_i);\n        }\n        vec_i = _mm_sub_epi64(vec_i, vec_one);\n    }\n    return 1;\n}\n```"}
{"task_id": "SimdBench_73_SSE", "completion": "```c\nuint64_t largest_divisor_simd(uint64_t n) {\n    __m128i vec_n = _mm_set1_epi64x(n);\n    __m128i vec_i = _mm_set_epi64x(n - 1, n - 2);\n    __m128i vec_step = _mm_set1_epi64x(2);\n    __m128i vec_one = _mm_set1_epi64x(1);\n\n    while (_mm_movemask_epi8(_mm_cmpeq_epi64(_mm_setzero_si128(), _mm_sub_epi64(vec_n, _mm_mul_epu32(vec_i, _mm_div_epu64(vec_n, vec_i))))) != 0xFFFF) {\n        vec_i = _mm_sub_epi64(vec_i, vec_step);\n    }\n\n    return _mm_cvtsi128_si64(vec_i);\n}\n```"}
{"task_id": "SimdBench_73_SSE", "completion": "```c\nuint64_t largest_divisor_simd(uint64_t n) {\n    uint64_t result = 1;\n    __m128i n_vec = _mm_set1_epi64x(n);\n    __m128i div_vec = _mm_set_epi64x(n - 1, n - 2);\n    __m128i one_vec = _mm_set1_epi64x(1);\n\n    for (uint64_t i = n / 2; i > 1; i -= 2) {\n        __m128i i_vec = _mm_set_epi64x(i, i - 1);\n        __m128i rem_vec = _mm_sub_epi64(n_vec, _mm_mullo_epi32(i_vec, one_vec));\n        __m128i mask = _mm_cmpeq_epi64(rem_vec, _mm_setzero_si128());\n\n        if (_mm_movemask_epi8(mask)) {\n            result = _mm_extract_epi64(i_vec, _mm_movemask_epi8(mask) ? 0 : 1);\n            break;\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_73_SSE", "completion": "```cpp\nuint64_t largest_divisor_simd(uint64_t n) {\n    __m128i vec_n = _mm_set1_epi64x(n);\n    __m128i vec_i = _mm_set_epi64x(n - 1, n - 2);\n    __m128i vec_step = _mm_set1_epi64x(-2);\n    __m128i vec_zero = _mm_setzero_si128();\n\n    while (_mm_movemask_epi8(_mm_cmpeq_epi64(_mm_and_si128(_mm_cvtepi64_epi32(_mm_div_epi64(vec_n, vec_i)), _mm_cvtepi64_epi32(_mm_mul_epi64(vec_i, _mm_cvtepi64_epi32(_mm_div_epi64(vec_n, vec_i))))), vec_zero)) != 0xFFFF) {\n        vec_i = _mm_add_epi64(vec_i, vec_step);\n    }\n\n    return _mm_cvtsi128_si64(vec_i);\n}\n```"}
{"task_id": "SimdBench_74_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> factorize_simd(int n) {\n    std::vector<int> factors;\n    __m128i two = _mm_set1_epi32(2);\n    __m128i four = _mm_set1_epi32(4);\n    __m128i n_vec = _mm_set1_epi32(n);\n\n    while (_mm_movemask_epi8(_mm_cmpeq_epi32(n_vec, _mm_setzero_si128())) == 0) {\n        __m128i div_result = _mm_div_epi32(n_vec, two);\n        __m128i mod_result = _mm_sub_epi32(n_vec, _mm_mullo_epi32(div_result, two));\n\n        if (_mm_movemask_epi8(_mm_cmpeq_epi32(mod_result, _mm_setzero_si128())) != 0) {\n            factors.push_back(2);\n            n_vec = div_result;\n        } else {\n            __m128i i = _mm_add_epi32(two, four);\n            while (_mm_movemask_epi8(_mm_cmpeq_epi32(n_vec, _mm_setzero_si128())) == 0) {\n                __m128i div_result = _mm_div_epi32(n_vec, i);\n                __m128i mod_result = _mm_sub_epi32(n_vec, _mm_mullo_epi32(div_result, i));\n\n                if (_mm_movemask_epi8(_mm_cmpeq_epi32(mod_result, _mm_setzero_si128())) != 0) {\n                    factors.push_back(_mm_cvtsi128_si32(i));\n                    n_vec = div_result;\n                } else {\n                    i = _mm_add_epi32(i, four);\n                }\n            }\n        }\n    }\n\n    return factors;\n}\n```"}
{"task_id": "SimdBench_74_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> factorize_simd(int n) {\n    std::vector<int> factors;\n    __m128i two = _mm_set1_epi32(2);\n    __m128i four = _mm_set1_epi32(4);\n    __m128i n_vec = _mm_set1_epi32(n);\n\n    while (_mm_movemask_epi8(_mm_cmpeq_epi32(n_vec, _mm_setzero_si128())) == 0) {\n        __m128i div_result = _mm_div_epi32(n_vec, two);\n        __m128i rem_result = _mm_sub_epi32(n_vec, _mm_mullo_epi32(div_result, two));\n\n        if (_mm_movemask_epi8(_mm_cmpeq_epi32(rem_result, _mm_setzero_si128())) != 0) {\n            factors.push_back(2);\n            n_vec = div_result;\n        } else {\n            break;\n        }\n    }\n\n    __m128i i = _mm_set1_epi32(3);\n    __m128i limit = _mm_sqrt_epi32(n_vec);\n\n    while (_mm_movemask_epi8(_mm_cmplt_epi32(i, limit)) != 0) {\n        __m128i div_result = _mm_div_epi32(n_vec, i);\n        __m128i rem_result = _mm_sub_epi32(n_vec, _mm_mullo_epi32(div_result, i));\n\n        if (_mm_movemask_epi8(_mm_cmpeq_epi32(rem_result, _mm_setzero_si128())) != 0) {\n            factors.push_back(_mm_cvtsi128_si32(i));\n            n_vec = div_result;\n            limit = _mm_sqrt_epi32(n_vec);\n        } else {\n            i = _mm_add_epi32(i, four);\n        }\n    }\n\n    if (_mm_movemask_epi8(_mm_cmpgt_epi32(n_vec, _mm_set1_epi32(1))) != 0) {\n        factors.push_back(_mm_cvtsi128_si32(n_vec));\n    }\n\n    return factors;\n}\n```"}
{"task_id": "SimdBench_74_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> factorize_simd(int n) {\n    std::vector<int> factors;\n    __m128i two = _mm_set1_epi32(2);\n    __m128i four = _mm_set1_epi32(4);\n    __m128i n_vec = _mm_set1_epi32(n);\n\n    while (_mm_movemask_epi8(_mm_cmpeq_epi32(n_vec, _mm_setzero_si128())) == 0) {\n        __m128i rem = _mm_and_si128(n_vec, _mm_set1_epi32(1));\n        __m128i is_even = _mm_cmpeq_epi32(rem, _mm_setzero_si128());\n        if (_mm_movemask_epi8(is_even) != 0) {\n            factors.push_back(2);\n            n_vec = _mm_div_epi32(n_vec, two);\n        } else {\n            break;\n        }\n    }\n\n    int n_int = _mm_cvtsi128_si32(n_vec);\n    for (int i = 3; i * i <= n_int; i += 2) {\n        while (n_int % i == 0) {\n            factors.push_back(i);\n            n_int /= i;\n        }\n    }\n\n    if (n_int > 2) {\n        factors.push_back(n_int);\n    }\n\n    return factors;\n}\n```"}
{"task_id": "SimdBench_74_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> factorize_simd(int n) {\n    std::vector<int> factors;\n    __m128i two = _mm_set1_epi32(2);\n    __m128i n_vec = _mm_set1_epi32(n);\n\n    while (_mm_movemask_epi8(_mm_cmpeq_epi32(n_vec, _mm_setzero_si128())) == 0) {\n        __m128i div_result = _mm_div_epi32(n_vec, two);\n        __m128i rem_result = _mm_sub_epi32(n_vec, _mm_mullo_epi32(div_result, two));\n\n        if (_mm_movemask_epi8(_mm_cmpeq_epi32(rem_result, _mm_setzero_si128())) != 0) {\n            factors.push_back(2);\n            n_vec = div_result;\n        } else {\n            __m128i i = _mm_set1_epi32(3);\n            __m128i limit = _mm_sqrt_epi32(n_vec);\n\n            while (_mm_movemask_epi8(_mm_cmplt_epi32(i, limit)) != 0) {\n                __m128i div_result = _mm_div_epi32(n_vec, i);\n                __m128i rem_result = _mm_sub_epi32(n_vec, _mm_mullo_epi32(div_result, i));\n\n                if (_mm_movemask_epi8(_mm_cmpeq_epi32(rem_result, _mm_setzero_si128())) != 0) {\n                    factors.push_back(_mm_cvtsi128_si32(i));\n                    n_vec = div_result;\n                    limit = _mm_sqrt_epi32(n_vec);\n                } else {\n                    i = _mm_add_epi32(i, two);\n                }\n            }\n            if (_mm_movemask_epi8(_mm_cmpgt_epi32(n_vec, _mm_set1_epi32(1))) != 0) {\n                factors.push_back(_mm_cvtsi128_si32(n_vec));\n            }\n            break;\n        }\n    }\n    return factors;\n}\n```"}
{"task_id": "SimdBench_74_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> factorize_simd(int n) {\n    std::vector<int> factors;\n    __m128i two = _mm_set1_epi32(2);\n    __m128i four = _mm_set1_epi32(4);\n    __m128i n_vec = _mm_set1_epi32(n);\n\n    while (_mm_movemask_epi8(_mm_cmpeq_epi32(n_vec, _mm_setzero_si128())) == 0) {\n        __m128i div_result = _mm_div_epi32(n_vec, two);\n        __m128i rem_result = _mm_sub_epi32(n_vec, _mm_mullo_epi32(div_result, two));\n\n        if (_mm_movemask_epi8(_mm_cmpeq_epi32(rem_result, _mm_setzero_si128())) != 0) {\n            factors.push_back(2);\n            n_vec = div_result;\n        } else {\n            __m128i i = _mm_add_epi32(two, two);\n            __m128i limit = _mm_sqrt_epi32(n_vec);\n\n            while (_mm_movemask_epi8(_mm_cmpgt_epi32(i, limit)) == 0) {\n                div_result = _mm_div_epi32(n_vec, i);\n                rem_result = _mm_sub_epi32(n_vec, _mm_mullo_epi32(div_result, i));\n\n                if (_mm_movemask_epi8(_mm_cmpeq_epi32(rem_result, _mm_setzero_si128())) != 0) {\n                    factors.push_back(_mm_cvtsi128_si32(i));\n                    n_vec = div_result;\n                    limit = _mm_sqrt_epi32(n_vec);\n                } else {\n                    i = _mm_add_epi32(i, two);\n                }\n            }\n        }\n    }\n\n    if (_mm_cvtsi128_si32(n_vec) > 1) {\n        factors.push_back(_mm_cvtsi128_si32(n_vec));\n    }\n\n    return factors;\n}\n```"}
{"task_id": "SimdBench_75_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<float> get_positive_simd(const std::vector<float>& l) {\n    std::vector<float> result;\n    __m128 zero = _mm_set1_ps(0.0f);\n\n    for (size_t i = 0; i < l.size(); i += 4) {\n        __m128 vec = _mm_loadu_ps(&l[i]);\n        __m128 mask = _mm_cmpgt_ps(vec, zero);\n        float temp[4];\n        _mm_storeu_ps(temp, vec);\n\n        for (int j = 0; j < 4; ++j) {\n            if (mask.m128_f32[j] != 0) {\n                result.push_back(temp[j]);\n            }\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_75_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<float> get_positive_simd(const std::vector<float>& l) {\n    std::vector<float> result;\n    __m128 zero = _mm_set1_ps(0.0f);\n\n    for (size_t i = 0; i < l.size(); i += 4) {\n        __m128 vec = _mm_loadu_ps(&l[i]);\n        __m128 mask = _mm_cmpgt_ps(vec, zero);\n        float temp[4];\n        _mm_storeu_ps(temp, vec);\n\n        for (int j = 0; j < 4 && i + j < l.size(); ++j) {\n            if (mask.m128_f32[j] != 0) {\n                result.push_back(temp[j]);\n            }\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_75_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<float> get_positive_simd(const std::vector<float>& l) {\n    std::vector<float> result;\n    __m128 zero = _mm_set1_ps(0.0f);\n\n    for (size_t i = 0; i < l.size(); i += 4) {\n        __m128 vec = _mm_loadu_ps(&l[i]);\n        __m128 mask = _mm_cmpgt_ps(vec, zero);\n        float temp[4];\n        _mm_storeu_ps(temp, vec);\n\n        for (int j = 0; j < 4 && i + j < l.size(); ++j) {\n            if (mask.m128_f32[j] != 0) {\n                result.push_back(temp[j]);\n            }\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_75_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<float> get_positive_simd(const std::vector<float>& l) {\n    std::vector<float> result;\n    __m128 zero = _mm_set1_ps(0.0f);\n\n    for (size_t i = 0; i < l.size(); i += 4) {\n        __m128 vec = _mm_loadu_ps(&l[i]);\n        __m128 mask = _mm_cmpgt_ps(vec, zero);\n        float temp[4];\n        _mm_storeu_ps(temp, vec);\n\n        for (int j = 0; j < 4 && i + j < l.size(); ++j) {\n            if (mask.m128_f32[j] != 0) {\n                result.push_back(temp[j]);\n            }\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_75_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<float> get_positive_simd(const std::vector<float>& l) {\n    std::vector<float> result;\n    __m128 zero = _mm_set1_ps(0.0f);\n\n    for (size_t i = 0; i < l.size(); i += 4) {\n        __m128 vec = _mm_loadu_ps(&l[i]);\n        __m128 mask = _mm_cmpgt_ps(vec, zero);\n        float temp[4];\n        _mm_storeu_ps(temp, vec);\n\n        for (int j = 0; j < 4 && i + j < l.size(); ++j) {\n            if (mask.m128_f32[j] != 0) {\n                result.push_back(temp[j]);\n            }\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_76_SSE", "completion": "```c\nbool is_prime_simd(int64_t n) {\n    if (n <= 1) return false;\n    if (n <= 3) return true;\n    if (n % 2 == 0 || n % 3 == 0) return false;\n\n    int64_t i = 5;\n    __m128i inc = _mm_set1_epi64x(2);\n    __m128i six = _mm_set1_epi64x(6);\n    __m128i n_vec = _mm_set1_epi64x(n);\n\n    while (i * i <= n) {\n        __m128i i_vec = _mm_set1_epi64x(i);\n        __m128i i_plus_2_vec = _mm_add_epi64(i_vec, inc);\n        __m128i i_plus_4_vec = _mm_add_epi64(i_vec, six);\n\n        __m128i rem1 = _mm_cvtepi64_epi32(_mm_cvtsi64_si128(n % i));\n        __m128i rem2 = _mm_cvtepi64_epi32(_mm_cvtsi64_si128(n % (i + 2)));\n        __m128i rem3 = _mm_cvtepi64_epi32(_mm_cvtsi64_si128(n % (i + 4)));\n        __m128i rem4 = _mm_cvtepi64_epi32(_mm_cvtsi64_si128(n % (i + 6)));\n\n        if (_mm_testz_si128(rem1, rem1) || _mm_testz_si128(rem2, rem2) || _mm_testz_si128(rem3, rem3) || _mm_testz_si128(rem4, rem4)) {\n            return false;\n        }\n\n        i += 6;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_76_SSE", "completion": "```c\nbool is_prime_simd(int64_t n) {\n    if (n <= 1) return false;\n    if (n <= 3) return true;\n    if (n % 2 == 0 || n % 3 == 0) return false;\n\n    int64_t i = 5;\n    __m128i step = _mm_set1_epi64x(6);\n    __m128i n_vec = _mm_set1_epi64x(n);\n\n    while (i * i <= n) {\n        __m128i i_vec = _mm_set1_epi64x(i);\n        __m128i i_plus_2_vec = _mm_add_epi64(i_vec, _mm_set1_epi64x(2));\n\n        __m128i div_result = _mm_div_epi64(n_vec, i_vec);\n        __m128i div_result2 = _mm_div_epi64(n_vec, i_plus_2_vec);\n\n        __m128i rem_result = _mm_sub_epi64(n_vec, _mm_mullo_epi64(div_result, i_vec));\n        __m128i rem_result2 = _mm_sub_epi64(n_vec, _mm_mullo_epi64(div_result2, i_plus_2_vec));\n\n        if (_mm_movemask_epi8(_mm_cmpeq_epi64(rem_result, _mm_setzero_si128())) ||\n            _mm_movemask_epi8(_mm_cmpeq_epi64(rem_result2, _mm_setzero_si128()))) {\n            return false;\n        }\n\n        i += 6;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_76_SSE", "completion": "```c\nbool is_prime_simd(int64_t n) {\n    if (n <= 1) return false;\n    if (n <= 3) return true;\n    if (n % 2 == 0 || n % 3 == 0) return false;\n\n    int64_t i = 5;\n    __m128i step = _mm_set1_epi64x(6);\n    __m128i n_vec = _mm_set1_epi64x(n);\n\n    while (i * i <= n) {\n        __m128i i_vec = _mm_set1_epi64x(i);\n        __m128i i_plus_2_vec = _mm_add_epi64(i_vec, _mm_set1_epi64x(2));\n\n        __m128i div_result = _mm_div_epi64(n_vec, i_vec);\n        __m128i div_result_2 = _mm_div_epi64(n_vec, i_plus_2_vec);\n\n        if (_mm_movemask_epi8(_mm_cmpeq_epi64(div_result, _mm_setzero_si128())) != 0xFFFF ||\n            _mm_movemask_epi8(_mm_cmpeq_epi64(div_result_2, _mm_setzero_si128())) != 0xFFFF) {\n            return false;\n        }\n\n        i += 6;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_76_SSE", "completion": "```c\nbool is_prime_simd(int64_t n) {\n    if (n <= 1) return false;\n    if (n <= 3) return true;\n    if (n % 2 == 0 || n % 3 == 0) return false;\n\n    int64_t i = 5;\n    __m128i inc = _mm_set1_epi64x(8);\n    __m128i limit = _mm_set1_epi64x((int64_t)sqrt(n));\n\n    while (_mm_movemask_epi8(_mm_cmpgt_epi64(limit, _mm_set1_epi64x(i)))) {\n        if (n % i == 0 || n % (i + 2) == 0) return false;\n        i = _mm_cvtsi128_si64(_mm_add_epi64(_mm_set1_epi64x(i), inc));\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_76_SSE", "completion": "```c\nbool is_prime_simd(int64_t n) {\n    if (n <= 1) return false;\n    if (n <= 3) return true;\n    if (n % 2 == 0 || n % 3 == 0) return false;\n\n    int64_t i = 5;\n    __m128i step = _mm_set1_epi64x(6);\n    __m128i n_vec = _mm_set1_epi64x(n);\n\n    while (i * i <= n) {\n        __m128i i_vec = _mm_set1_epi64x(i);\n        __m128i i_plus_2_vec = _mm_add_epi64(i_vec, _mm_set1_epi64x(2));\n\n        __m128i div_result = _mm_div_epi64(n_vec, i_vec);\n        __m128i div_result2 = _mm_div_epi64(n_vec, i_plus_2_vec);\n\n        int64_t div_result_scalar = _mm_cvtsi128_si64(div_result);\n        int64_t div_result2_scalar = _mm_cvtsi128_si64(div_result2);\n\n        if (n % i == 0 || n % (i + 2) == 0) return false;\n\n        i += 6;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_77_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string solve_simd(const std::string & s) {\n    std::string result = s;\n    bool has_letters = false;\n\n    __m128i lower_bound = _mm_set1_epi8('a');\n    __m128i upper_bound = _mm_set1_epi8('z');\n    __m128i case_diff = _mm_set1_epi8('a' - 'A');\n\n    for (size_t i = 0; i < s.size(); i += 16) {\n        __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(s.data() + i));\n        __m128i is_lower = _mm_and_si128(_mm_cmpgt_epi8(chunk, _mm_sub_epi8(lower_bound, _mm_set1_epi8(1))),\n                                          _mm_cmplt_epi8(chunk, _mm_add_epi8(upper_bound, _mm_set1_epi8(1))));\n        __m128i is_upper = _mm_and_si128(_mm_cmpgt_epi8(chunk, _mm_sub_epi8(_mm_set1_epi8('A'), _mm_set1_epi8(1))),\n                                          _mm_cmplt_epi8(chunk, _mm_add_epi8(_mm_set1_epi8('Z'), _mm_set1_epi8(1))));\n\n        __m128i to_upper = _mm_andnot_si128(is_lower, is_upper);\n        __m128i to_lower = _mm_andnot_si128(is_upper, is_lower);\n\n        __m128i upper_chunk = _mm_sub_epi8(chunk, case_diff);\n        __m128i lower_chunk = _mm_add_epi8(chunk, case_diff);\n\n        __m128i final_chunk = _mm_or_si128(_mm_and_si128(to_upper, upper_chunk),\n                                            _mm_or_si128(_mm_and_si128(to_lower, lower_chunk),\n                                                         _mm_andnot_si128(_mm_or_si128(to_upper, to_lower), chunk)));\n\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(result.data() + i), final_chunk);\n\n        has_letters |= _mm_movemask_epi8(_mm_or_si128(is_lower, is_upper)) != 0;\n    }\n\n    if (!has_letters) {\n        std::reverse(result.begin(), result.end());\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_77_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string solve_simd(const std::string & s) {\n    std::string result = s;\n    bool has_letters = false;\n\n    __m128i lower_bound = _mm_set1_epi8('a');\n    __m128i upper_bound = _mm_set1_epi8('z');\n    __m128i case_diff = _mm_set1_epi8('a' - 'A');\n\n    for (size_t i = 0; i < s.size(); i += 16) {\n        __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&s[i]));\n        __m128i is_lower = _mm_and_si128(_mm_cmpgt_epi8(chunk, _mm_sub_epi8(lower_bound, _mm_set1_epi8(1))),\n                                         _mm_cmplt_epi8(chunk, _mm_add_epi8(upper_bound, _mm_set1_epi8(1))));\n        __m128i is_upper = _mm_and_si128(_mm_cmpgt_epi8(chunk, _mm_sub_epi8(_mm_set1_epi8('A'), _mm_set1_epi8(1))),\n                                         _mm_cmplt_epi8(chunk, _mm_add_epi8(_mm_set1_epi8('Z'), _mm_set1_epi8(1))));\n\n        __m128i to_upper = _mm_and_si128(is_lower, _mm_sub_epi8(chunk, case_diff));\n        __m128i to_lower = _mm_and_si128(is_upper, _mm_add_epi8(chunk, case_diff));\n        __m128i no_change = _mm_andnot_si128(_mm_or_si128(is_lower, is_upper), chunk);\n\n        __m128i processed_chunk = _mm_or_si128(_mm_or_si128(to_upper, to_lower), no_change);\n\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i]), processed_chunk);\n\n        has_letters |= _mm_movemask_epi8(is_lower) | _mm_movemask_epi8(is_upper);\n    }\n\n    if (!has_letters) {\n        std::reverse(result.begin(), result.end());\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_77_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string solve_simd(const std::string & s) {\n    std::string result = s;\n    bool has_letters = false;\n\n    __m128i lower_bound = _mm_set1_epi8('a');\n    __m128i upper_bound = _mm_set1_epi8('z');\n    __m128i case_diff = _mm_set1_epi8('a' - 'A');\n\n    for (size_t i = 0; i < s.size(); i += 16) {\n        __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(s.data() + i));\n        __m128i is_lower = _mm_and_si128(_mm_cmpgt_epi8(chunk, _mm_sub_epi8(lower_bound, _mm_set1_epi8(1))), _mm_cmplt_epi8(chunk, _mm_add_epi8(upper_bound, _mm_set1_epi8(1))));\n        __m128i is_upper = _mm_and_si128(_mm_cmpgt_epi8(chunk, _mm_sub_epi8(_mm_add_epi8(lower_bound, case_diff), _mm_set1_epi8(1))), _mm_cmplt_epi8(chunk, _mm_add_epi8(_mm_add_epi8(lower_bound, case_diff), _mm_set1_epi8(1))));\n\n        has_letters |= _mm_movemask_epi8(is_lower) | _mm_movemask_epi8(is_upper);\n\n        __m128i lower_to_upper = _mm_sub_epi8(chunk, case_diff);\n        __m128i upper_to_lower = _mm_add_epi8(chunk, case_diff);\n\n        __m128i reversed_chunk = _mm_or_si128(_mm_and_si128(is_lower, lower_to_upper), _mm_andnot_si128(is_lower, _mm_or_si128(_mm_and_si128(is_upper, upper_to_lower), _mm_andnot_si128(is_upper, chunk))));\n\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(result.data() + i), reversed_chunk);\n    }\n\n    if (!has_letters) {\n        std::reverse(result.begin(), result.end());\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_77_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string solve_simd(const std::string & s) {\n    std::string result = s;\n    bool has_letters = false;\n\n    __m128i lower_bound = _mm_set1_epi8('a');\n    __m128i upper_bound = _mm_set1_epi8('z');\n    __m128i case_diff = _mm_set1_epi8('a' - 'A');\n\n    for (size_t i = 0; i < s.size(); i += 16) {\n        __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&s[i]));\n        __m128i is_lower = _mm_and_si128(_mm_cmpgt_epi8(chunk, _mm_sub_epi8(lower_bound, _mm_set1_epi8(1))),\n                                         _mm_cmplt_epi8(chunk, _mm_add_epi8(upper_bound, _mm_set1_epi8(1))));\n        __m128i is_upper = _mm_and_si128(_mm_cmpgt_epi8(chunk, _mm_sub_epi8(_mm_set1_epi8('A'), _mm_set1_epi8(1))),\n                                         _mm_cmplt_epi8(chunk, _mm_add_epi8(_mm_set1_epi8('Z'), _mm_set1_epi8(1))));\n\n        __m128i is_letter = _mm_or_si128(is_lower, is_upper);\n        has_letters = has_letters || _mm_movemask_epi8(is_letter) != 0;\n\n        __m128i lower_to_upper = _mm_sub_epi8(chunk, case_diff);\n        __m128i upper_to_lower = _mm_add_epi8(chunk, case_diff);\n\n        __m128i reversed_chunk = _mm_or_si128(_mm_and_si128(is_lower, lower_to_upper),\n                                              _mm_and_si128(is_upper, upper_to_lower));\n        reversed_chunk = _mm_or_si128(_mm_andnot_si128(is_letter, chunk), reversed_chunk);\n\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i]), reversed_chunk);\n    }\n\n    if (!has_letters) {\n        std::reverse(result.begin(), result.end());\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_77_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string solve_simd(const std::string & s) {\n    std::string result = s;\n    bool has_letters = false;\n\n    __m128i lower_bound = _mm_set1_epi8('a');\n    __m128i upper_bound = _mm_set1_epi8('z');\n    __m128i case_diff = _mm_set1_epi8('a' - 'A');\n\n    for (size_t i = 0; i < s.size(); i += 16) {\n        __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(s.data() + i));\n        __m128i is_lower = _mm_and_si128(_mm_cmpgt_epi8(chunk, _mm_sub_epi8(lower_bound, _mm_set1_epi8(1))),\n                                          _mm_cmplt_epi8(chunk, _mm_add_epi8(upper_bound, _mm_set1_epi8(1))));\n        __m128i is_upper = _mm_and_si128(_mm_cmpgt_epi8(chunk, _mm_sub_epi8(_mm_set1_epi8('A'), _mm_set1_epi8(1))),\n                                          _mm_cmplt_epi8(chunk, _mm_add_epi8(_mm_set1_epi8('Z'), _mm_set1_epi8(1))));\n\n        __m128i is_letter = _mm_or_si128(is_lower, is_upper);\n        has_letters = has_letters || _mm_movemask_epi8(is_letter) != 0;\n\n        __m128i lower_to_upper = _mm_sub_epi8(chunk, case_diff);\n        __m128i upper_to_lower = _mm_add_epi8(chunk, case_diff);\n\n        __m128i reversed_chunk = _mm_or_si128(_mm_and_si128(is_lower, lower_to_upper),\n                                               _mm_andnot_si128(is_lower, _mm_or_si128(_mm_and_si128(is_upper, upper_to_lower), chunk)));\n\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(result.data() + i), reversed_chunk);\n    }\n\n    if (!has_letters) {\n        std::reverse(result.begin(), result.end());\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_78_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<int> sort_third_simd(std::vector<int> l) {\n    int n = l.size();\n    std::vector<int> sorted_thirds;\n\n    // Collect elements at indices divisible by 3\n    for (int i = 0; i < n; i += 3) {\n        sorted_thirds.push_back(l[i]);\n    }\n\n    // Sort the collected elements\n    std::sort(sorted_thirds.begin(), sorted_thirds.end());\n\n    // Place sorted elements back into the original vector\n    for (int i = 0, j = 0; i < n; i += 3, j++) {\n        l[i] = sorted_thirds[j];\n    }\n\n    return l;\n}\n```"}
{"task_id": "SimdBench_78_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<int> sort_third_simd(std::vector<int> l) {\n    int n = l.size();\n    std::vector<int> sorted_thirds;\n\n    for (int i = 0; i < n; i += 3) {\n        sorted_thirds.push_back(l[i]);\n    }\n\n    std::sort(sorted_thirds.begin(), sorted_thirds.end());\n\n    int sorted_index = 0;\n    for (int i = 0; i < n; i += 3) {\n        l[i] = sorted_thirds[sorted_index++];\n    }\n\n    return l;\n}\n```"}
{"task_id": "SimdBench_78_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<int> sort_third_simd(std::vector<int> l) {\n    int n = l.size();\n    std::vector<int> sorted_thirds;\n\n    for (int i = 0; i < n; i += 3) {\n        sorted_thirds.push_back(l[i]);\n    }\n\n    std::sort(sorted_thirds.begin(), sorted_thirds.end());\n\n    int sorted_index = 0;\n    for (int i = 0; i < n; i += 3) {\n        l[i] = sorted_thirds[sorted_index++];\n    }\n\n    return l;\n}\n```"}
{"task_id": "SimdBench_78_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<int> sort_third_simd(std::vector<int> l) {\n    int n = l.size();\n    std::vector<int> sorted_thirds;\n\n    // Collect elements at indices divisible by 3\n    for (int i = 0; i < n; i += 3) {\n        sorted_thirds.push_back(l[i]);\n    }\n\n    // Sort the collected elements\n    std::sort(sorted_thirds.begin(), sorted_thirds.end());\n\n    // Place sorted elements back into the original vector\n    for (int i = 0, j = 0; i < n; i += 3, j++) {\n        l[i] = sorted_thirds[j];\n    }\n\n    return l;\n}\n```"}
{"task_id": "SimdBench_78_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<int> sort_third_simd(std::vector<int> l) {\n    int n = l.size();\n    std::vector<int> third_elements;\n\n    for (int i = 0; i < n; i += 3) {\n        third_elements.push_back(l[i]);\n    }\n\n    std::sort(third_elements.begin(), third_elements.end());\n\n    int k = 0;\n    for (int i = 0; i < n; i += 3) {\n        l[i] = third_elements[k++];\n    }\n\n    return l;\n}\n```"}
{"task_id": "SimdBench_79_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n\nfloat max_element_simd(std::vector<float> l) {\n    const int size = l.size();\n    const int aligned_size = size & ~3;\n    __m128 max_vec = _mm_set1_ps(-std::numeric_limits<float>::infinity());\n\n    for (int i = 0; i < aligned_size; i += 4) {\n        __m128 vec = _mm_loadu_ps(&l[i]);\n        max_vec = _mm_max_ps(max_vec, vec);\n    }\n\n    float max_vals[4];\n    _mm_storeu_ps(max_vals, max_vec);\n    float max_val = *std::max_element(max_vals, max_vals + 4);\n\n    for (int i = aligned_size; i < size; ++i) {\n        max_val = std::max(max_val, l[i]);\n    }\n\n    return max_val;\n}\n```"}
{"task_id": "SimdBench_79_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n\nfloat max_element_simd(std::vector<float> l) {\n    size_t size = l.size();\n    size_t i = 0;\n    __m128 max_vec = _mm_set1_ps(l[0]);\n\n    for (; i + 3 < size; i += 4) {\n        __m128 data = _mm_loadu_ps(&l[i]);\n        max_vec = _mm_max_ps(max_vec, data);\n    }\n\n    float max_vals[4];\n    _mm_storeu_ps(max_vals, max_vec);\n    float max_val = *std::max_element(max_vals, max_vals + 4);\n\n    for (; i < size; ++i) {\n        max_val = std::max(max_val, l[i]);\n    }\n\n    return max_val;\n}\n```"}
{"task_id": "SimdBench_79_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n\nfloat max_element_simd(std::vector<float> l) {\n    size_t size = l.size();\n    size_t i = 0;\n\n    __m128 max_vec = _mm_set1_ps(l[0]);\n\n    for (; i <= size - 4; i += 4) {\n        __m128 vec = _mm_loadu_ps(&l[i]);\n        max_vec = _mm_max_ps(max_vec, vec);\n    }\n\n    float max_vals[4];\n    _mm_storeu_ps(max_vals, max_vec);\n    float max_val = *std::max_element(max_vals, max_vals + 4);\n\n    for (; i < size; ++i) {\n        max_val = std::max(max_val, l[i]);\n    }\n\n    return max_val;\n}\n```"}
{"task_id": "SimdBench_79_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n\nfloat max_element_simd(std::vector<float> l) {\n    __m128 max_vec = _mm_set1_ps(-std::numeric_limits<float>::infinity());\n    size_t size = l.size();\n    size_t i = 0;\n\n    for (; i + 3 < size; i += 4) {\n        __m128 vec = _mm_loadu_ps(&l[i]);\n        max_vec = _mm_max_ps(max_vec, vec);\n    }\n\n    float max_vals[4];\n    _mm_storeu_ps(max_vals, max_vec);\n    float max_val = *std::max_element(max_vals, max_vals + 4);\n\n    for (; i < size; ++i) {\n        max_val = std::max(max_val, l[i]);\n    }\n\n    return max_val;\n}\n```"}
{"task_id": "SimdBench_79_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n\nfloat max_element_simd(std::vector<float> l) {\n    size_t size = l.size();\n    size_t i = 0;\n\n    __m128 max_vec = _mm_set1_ps(l[0]);\n\n    for (; i <= size - 4; i += 4) {\n        __m128 vec = _mm_loadu_ps(&l[i]);\n        max_vec = _mm_max_ps(max_vec, vec);\n    }\n\n    float max_arr[4];\n    _mm_storeu_ps(max_arr, max_vec);\n    float max_val = *std::max_element(max_arr, max_arr + 4);\n\n    for (; i < size; ++i) {\n        max_val = std::max(max_val, l[i]);\n    }\n\n    return max_val;\n}\n```"}
{"task_id": "SimdBench_80_SSE", "completion": "```c\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint fizz_buzz_simd(int n) {\n    int count = 0;\n    __m128i mask = _mm_set1_epi32(0x0F0F0F0F); // Mask to isolate each digit\n    __m128i seven = _mm_set1_epi32(0x37373737); // ASCII '7' in each byte\n\n    for (int i = 0; i < n; i += 4) {\n        __m128i numbers = _mm_set_epi32(i + 3, i + 2, i + 1, i);\n        __m128i div11 = _mm_set1_epi32(11);\n        __m128i div13 = _mm_set1_epi32(13);\n\n        __m128i rem11 = _mm_sub_epi32(numbers, _mm_mul_epi32(_mm_div_epi32(numbers, div11), div11));\n        __m128i rem13 = _mm_sub_epi32(numbers, _mm_mul_epi32(_mm_div_epi32(numbers, div13), div13));\n\n        __m128i mask11 = _mm_cmpeq_epi32(rem11, _mm_setzero_si128());\n        __m128i mask13 = _mm_cmpeq_epi32(rem13, _mm_setzero_si128());\n\n        __m128i combined_mask = _mm_or_si128(mask11, mask13);\n\n        __m128i isolated_digits = _mm_and_si128(numbers, mask);\n        __m128i seven_mask = _mm_cmpeq_epi8(isolated_digits, seven);\n\n        __m128i count_mask = _mm_and_si128(combined_mask, seven_mask);\n        count += _mm_movemask_epi8(count_mask);\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_80_SSE", "completion": "```c\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint fizz_buzz_simd(int n) {\n    int count = 0;\n    __m128i ones = _mm_set1_epi32(1);\n    __m128i sevens = _mm_set1_epi32(7);\n    __m128i eleven = _mm_set1_epi32(11);\n    __m128i thirteen = _mm_set1_epi32(13);\n\n    for (int i = 0; i < n; i += 4) {\n        __m128i indices = _mm_add_epi32(_mm_set_epi32(i + 3, i + 2, i + 1, i), ones);\n        __m128i mod11 = _mm_mod_epi32(indices, eleven);\n        __m128i mod13 = _mm_mod_epi32(indices, thirteen);\n        __m128i mask11 = _mm_cmpeq_epi32(mod11, _mm_setzero_si128());\n        __m128i mask13 = _mm_cmpeq_epi32(mod13, _mm_setzero_si128());\n        __m128i mask = _mm_or_si128(mask11, mask13);\n\n        __m128i digits = _mm_and_si128(mask, indices);\n        __m128i count_sevens = _mm_cmpeq_epi32(digits, sevens);\n        count += _mm_movemask_epi8(count_sevens);\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_80_SSE", "completion": "```c\nint fizz_buzz_simd(int n) {\n    __m128i count = _mm_setzero_si128();\n    __m128i ones = _mm_set1_epi32(1);\n    __m128i sevens = _mm_set1_epi32(7);\n    __m128i eleven = _mm_set1_epi32(11);\n    __m128i thirteen = _mm_set1_epi32(13);\n\n    for (int i = 0; i < n; i += 4) {\n        __m128i indices = _mm_add_epi32(_mm_set_epi32(i + 3, i + 2, i + 1, i), ones);\n        __m128i mod_eleven = _mm_div_epi32(indices, eleven);\n        __m128i mod_thirteen = _mm_div_epi32(indices, thirteen);\n\n        __m128i mask_eleven = _mm_cmpeq_epi32(mod_eleven, _mm_setzero_si128());\n        __m128i mask_thirteen = _mm_cmpeq_epi32(mod_thirteen, _mm_setzero_si128());\n\n        __m128i mask = _mm_or_si128(mask_eleven, mask_thirteen);\n\n        __m128i digits = _mm_and_si128(indices, _mm_set1_epi32(0xF));\n        __m128i mask_sevens = _mm_cmpeq_epi32(digits, sevens);\n\n        __m128i count_sevens = _mm_and_si128(mask, mask_sevens);\n        count = _mm_add_epi32(count, _mm_sad_epu8(count_sevens, _mm_setzero_si128()));\n    }\n\n    int result = _mm_extract_epi32(count, 0) + _mm_extract_epi32(count, 1) +\n                 _mm_extract_epi32(count, 2) + _mm_extract_epi32(count, 3);\n    return result;\n}\n```"}
{"task_id": "SimdBench_80_SSE", "completion": "```c\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint fizz_buzz_simd(int n) {\n    int count = 0;\n    __m128i ones = _mm_set1_epi32(1);\n    __m128i sevens = _mm_set1_epi32(7);\n    __m128i eleven = _mm_set1_epi32(11);\n    __m128i thirteen = _mm_set1_epi32(13);\n    __m128i zero = _mm_setzero_si128();\n\n    for (int i = 0; i < n; i += 4) {\n        __m128i indices = _mm_add_epi32(_mm_set_epi32(i + 3, i + 2, i + 1, i), ones);\n        __m128i mod_eleven = _mm_and_si128(_mm_cmpeq_epi32(_mm_and_si128(_mm_sub_epi32(indices, _mm_set1_epi32(1)), eleven), zero), ones);\n        __m128i mod_thirteen = _mm_and_si128(_mm_cmpeq_epi32(_mm_and_si128(_mm_sub_epi32(indices, _mm_set1_epi32(1)), thirteen), zero), ones);\n        __m128i mask = _mm_or_si128(mod_eleven, mod_thirteen);\n\n        __m128i digits = _mm_setzero_si128();\n        for (int j = 0; j < 4; ++j) {\n            int val = _mm_extract_epi32(indices, j);\n            if (val < n && _mm_extract_epi32(mask, j)) {\n                while (val > 0) {\n                    if (val % 10 == 7) {\n                        digits = _mm_add_epi32(digits, ones);\n                    }\n                    val /= 10;\n                }\n            }\n        }\n        count += _mm_extract_epi32(digits, 0);\n    }\n    return count;\n}\n```"}
{"task_id": "SimdBench_80_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint fizz_buzz_simd(int n) {\n    int count = 0;\n    __m128i mask = _mm_set1_epi32(0x0F0F0F0F); // Mask to isolate each byte\n    __m128i seven = _mm_set1_epi32(0x37373737); // ASCII '7' in each byte\n\n    for (int i = 0; i < n; i += 4) {\n        __m128i numbers = _mm_set_epi32(i + 3, i + 2, i + 1, i);\n        __m128i div11 = _mm_set1_epi32(11);\n        __m128i div13 = _mm_set1_epi32(13);\n\n        __m128i rem11 = _mm_sub_epi32(numbers, _mm_mul_epi32(_mm_div_epi32(numbers, div11), div11));\n        __m128i rem13 = _mm_sub_epi32(numbers, _mm_mul_epi32(_mm_div_epi32(numbers, div13), div13));\n\n        __m128i isDiv11 = _mm_cmpeq_epi32(rem11, _mm_setzero_si128());\n        __m128i isDiv13 = _mm_cmpeq_epi32(rem13, _mm_setzero_si128());\n\n        __m128i isDiv = _mm_or_si128(isDiv11, isDiv13);\n\n        __m128i ascii = _mm_set1_epi32(0x30303030); // ASCII '0' in each byte\n        __m128i numAscii = _mm_add_epi32(numbers, ascii);\n\n        __m128i masked = _mm_and_si128(numAscii, mask);\n        __m128i isSeven = _mm_cmpeq_epi32(masked, seven);\n\n        __m128i valid = _mm_and_si128(isDiv, isSeven);\n\n        count += _mm_movemask_epi8(valid);\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_81_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<float> sort_even_simd(std::vector<float> l) {\n    int n = l.size();\n    if (n < 2) return l;\n\n    std::vector<float> even_values;\n    for (int i = 0; i < n; i += 2) {\n        even_values.push_back(l[i]);\n    }\n\n    std::sort(even_values.begin(), even_values.end());\n\n    for (int i = 0; i < n; i += 2) {\n        l[i] = even_values[i / 2];\n    }\n\n    return l;\n}\n```"}
{"task_id": "SimdBench_81_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<float> sort_even_simd(std::vector<float> l) {\n    int n = l.size();\n    if (n < 2) return l;\n\n    std::vector<float> even_values;\n    for (int i = 0; i < n; i += 2) {\n        even_values.push_back(l[i]);\n    }\n\n    std::sort(even_values.begin(), even_values.end());\n\n    for (int i = 0; i < even_values.size(); ++i) {\n        l[2 * i] = even_values[i];\n    }\n\n    return l;\n}\n```"}
{"task_id": "SimdBench_81_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<float> sort_even_simd(std::vector<float> l) {\n    int n = l.size();\n    if (n < 2) return l;\n\n    std::vector<float> even_values;\n    for (int i = 0; i < n; i += 2) {\n        even_values.push_back(l[i]);\n    }\n\n    std::sort(even_values.begin(), even_values.end());\n\n    for (int i = 0; i < n; i += 2) {\n        l[i] = even_values[i / 2];\n    }\n\n    return l;\n}\n```"}
{"task_id": "SimdBench_81_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<float> sort_even_simd(std::vector<float> l) {\n    int n = l.size();\n    std::vector<float> sorted_even;\n\n    for (int i = 0; i < n; i += 2) {\n        sorted_even.push_back(l[i]);\n    }\n\n    std::sort(sorted_even.begin(), sorted_even.end());\n\n    for (int i = 0, j = 0; i < n; i += 2, ++j) {\n        l[i] = sorted_even[j];\n    }\n\n    return l;\n}\n```"}
{"task_id": "SimdBench_81_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<float> sort_even_simd(std::vector<float> l) {\n    int n = l.size();\n    if (n < 2) return l;\n\n    std::vector<float> even_values;\n    for (int i = 0; i < n; i += 2) {\n        even_values.push_back(l[i]);\n    }\n\n    std::sort(even_values.begin(), even_values.end());\n\n    for (int i = 0; i < n; i += 2) {\n        l[i] = even_values[i / 2];\n    }\n\n    return l;\n}\n```"}
{"task_id": "SimdBench_82_SSE", "completion": "```cpp\nbool triples_sum_to_zero_simd(std::vector<int> l) {\n    int n = l.size();\n    if (n < 3) return false;\n\n    for (int i = 0; i < n - 2; ++i) {\n        __m128i a = _mm_set1_epi32(l[i]);\n        for (int j = i + 1; j < n - 1; ++j) {\n            __m128i b = _mm_set1_epi32(l[j]);\n            __m128i c = _mm_set1_epi32(-(l[i] + l[j]));\n            for (int k = j + 1; k < n; k += 4) {\n                __m128i d = _mm_loadu_si128((__m128i*)&l[k]);\n                __m128i cmp = _mm_cmpeq_epi32(d, c);\n                int mask = _mm_movemask_epi8(cmp);\n                if (mask != 0) return true;\n            }\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_82_SSE", "completion": "```c++\nbool triples_sum_to_zero_simd(std::vector<int> l) {\n    int n = l.size();\n    if (n < 3) return false;\n\n    for (int i = 0; i < n - 2; ++i) {\n        __m128i a = _mm_set1_epi32(l[i]);\n        for (int j = i + 1; j < n - 1; ++j) {\n            __m128i b = _mm_set1_epi32(l[j]);\n            __m128i c = _mm_set1_epi32(-(l[i] + l[j]));\n            for (int k = j + 1; k < n; k += 4) {\n                __m128i d = _mm_loadu_si128((__m128i*)&l[k]);\n                __m128i cmp = _mm_cmpeq_epi32(d, c);\n                int mask = _mm_movemask_epi8(cmp);\n                if (mask != 0) return true;\n            }\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_82_SSE", "completion": "```cpp\nbool triples_sum_to_zero_simd(std::vector<int> l) {\n    int n = l.size();\n    if (n < 3) return false;\n\n    for (int i = 0; i < n - 2; ++i) {\n        for (int j = i + 1; j < n - 1; ++j) {\n            __m128i a = _mm_set1_epi32(l[i] + l[j]);\n            for (int k = j + 1; k < n; k += 4) {\n                __m128i b = _mm_loadu_si128((__m128i*)&l[k]);\n                __m128i c = _mm_add_epi32(a, b);\n                __m128i d = _mm_setzero_si128();\n                __m128i e = _mm_cmpeq_epi32(c, d);\n                int mask = _mm_movemask_epi8(e);\n                if (mask != 0) return true;\n            }\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_82_SSE", "completion": "```c++\nbool triples_sum_to_zero_simd(std::vector<int> l) {\n    int n = l.size();\n    if (n < 3) return false;\n\n    for (int i = 0; i < n - 2; ++i) {\n        __m128i a = _mm_set1_epi32(l[i]);\n        for (int j = i + 1; j < n - 1; ++j) {\n            __m128i b = _mm_set1_epi32(l[j]);\n            __m128i c = _mm_set1_epi32(-(l[i] + l[j]));\n\n            for (int k = j + 1; k < n; k += 4) {\n                __m128i d = _mm_loadu_si128((__m128i*)&l[k]);\n                __m128i cmp = _mm_cmpeq_epi32(d, c);\n                int mask = _mm_movemask_epi8(cmp);\n                if (mask != 0) return true;\n            }\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_82_SSE", "completion": "```cpp\nbool triples_sum_to_zero_simd(std::vector<int> l) {\n    int n = l.size();\n    if (n < 3) return false;\n\n    for (int i = 0; i < n - 2; ++i) {\n        __m128i a = _mm_set1_epi32(l[i]);\n        for (int j = i + 1; j < n - 1; ++j) {\n            __m128i b = _mm_set1_epi32(l[j]);\n            __m128i sum_ab = _mm_add_epi32(a, b);\n\n            for (int k = j + 1; k < n; k += 4) {\n                __m128i c = _mm_loadu_si128((__m128i*)&l[k]);\n                __m128i sum_abc = _mm_add_epi32(sum_ab, c);\n                __m128i zero = _mm_setzero_si128();\n                __m128i cmp = _mm_cmpeq_epi32(sum_abc, zero);\n                int mask = _mm_movemask_epi8(cmp);\n                if (mask != 0) return true;\n            }\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_83_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> incr_list_simd(std::vector<int> l) {\n    int size = l.size();\n    int aligned_size = (size + 3) & ~3;\n    l.resize(aligned_size, 0);\n\n    __m128i increment = _mm_set1_epi32(1);\n\n    for (int i = 0; i < size; i += 4) {\n        __m128i vec = _mm_loadu_si128((__m128i*)&l[i]);\n        vec = _mm_add_epi32(vec, increment);\n        _mm_storeu_si128((__m128i*)&l[i], vec);\n    }\n\n    l.resize(size);\n    return l;\n}\n```"}
{"task_id": "SimdBench_83_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> incr_list_simd(std::vector<int> l) {\n    int size = l.size();\n    int remainder = size % 4;\n    int aligned_size = size - remainder;\n\n    __m128i increment = _mm_set1_epi32(1);\n\n    for (int i = 0; i < aligned_size; i += 4) {\n        __m128i vec = _mm_loadu_si128((__m128i*)&l[i]);\n        vec = _mm_add_epi32(vec, increment);\n        _mm_storeu_si128((__m128i*)&l[i], vec);\n    }\n\n    for (int i = aligned_size; i < size; ++i) {\n        l[i] += 1;\n    }\n\n    return l;\n}\n```"}
{"task_id": "SimdBench_83_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> incr_list_simd(std::vector<int> l) {\n    int size = l.size();\n    int aligned_size = (size + 3) & ~3;\n    l.resize(aligned_size, 0);\n\n    __m128i increment = _mm_set1_epi32(1);\n\n    for (int i = 0; i < size; i += 4) {\n        __m128i vec = _mm_loadu_si128((__m128i*)&l[i]);\n        vec = _mm_add_epi32(vec, increment);\n        _mm_storeu_si128((__m128i*)&l[i], vec);\n    }\n\n    l.resize(size);\n    return l;\n}\n```"}
{"task_id": "SimdBench_83_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> incr_list_simd(std::vector<int> l) {\n    int size = l.size();\n    int remainder = size % 4;\n    int aligned_size = size - remainder;\n\n    for (int i = 0; i < aligned_size; i += 4) {\n        __m128i vec = _mm_loadu_si128((__m128i*)&l[i]);\n        __m128i ones = _mm_set1_epi32(1);\n        __m128i result = _mm_add_epi32(vec, ones);\n        _mm_storeu_si128((__m128i*)&l[i], result);\n    }\n\n    for (int i = aligned_size; i < size; ++i) {\n        l[i] += 1;\n    }\n\n    return l;\n}\n```"}
{"task_id": "SimdBench_83_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> incr_list_simd(std::vector<int> l) {\n    int size = l.size();\n    int aligned_size = (size + 3) & ~3;\n    l.resize(aligned_size, 0);\n\n    __m128i one = _mm_set1_epi32(1);\n\n    for (int i = 0; i < size; i += 4) {\n        __m128i vec = _mm_loadu_si128((__m128i*)&l[i]);\n        vec = _mm_add_epi32(vec, one);\n        _mm_storeu_si128((__m128i*)&l[i], vec);\n    }\n\n    l.resize(size);\n    return l;\n}\n```"}
{"task_id": "SimdBench_84_SSE", "completion": "```cpp\nbool pairs_sum_to_zero_simd(std::vector<int> l) {\n    if (l.size() < 2) return false;\n\n    for (size_t i = 0; i < l.size(); ++i) {\n        __m128i vec = _mm_set1_epi32(l[i]);\n        for (size_t j = i + 1; j < l.size(); j += 4) {\n            __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&l[j]));\n            __m128i neg_chunk = _mm_sub_epi32(_mm_setzero_si128(), chunk);\n            __m128i cmp = _mm_cmpeq_epi32(vec, neg_chunk);\n            int mask = _mm_movemask_epi8(cmp);\n            if (mask != 0) return true;\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_84_SSE", "completion": "```cpp\nbool pairs_sum_to_zero_simd(std::vector<int> l) {\n    if (l.size() < 2) return false;\n\n    __m128i zero = _mm_setzero_si128();\n    int n = l.size();\n    int i = 0;\n\n    for (; i <= n - 4; i += 4) {\n        __m128i a = _mm_loadu_si128((__m128i*)&l[i]);\n        __m128i neg_a = _mm_sub_epi32(zero, a);\n\n        for (int j = 0; j < n; ++j) {\n            if (j >= i && j < i + 4) continue;\n            __m128i b = _mm_set1_epi32(l[j]);\n            __m128i cmp = _mm_cmpeq_epi32(neg_a, b);\n            int mask = _mm_movemask_epi8(cmp);\n            if (mask != 0) return true;\n        }\n    }\n\n    for (; i < n; ++i) {\n        for (int j = 0; j < n; ++j) {\n            if (i != j && l[i] + l[j] == 0) return true;\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_84_SSE", "completion": "```cpp\nbool pairs_sum_to_zero_simd(std::vector<int> l) {\n    if (l.size() < 2) return false;\n\n    int n = l.size();\n    int i = 0;\n\n    for (; i <= n - 4; i += 4) {\n        __m128i a = _mm_loadu_si128((__m128i*)&l[i]);\n        for (int j = i + 4; j <= n - 4; j += 4) {\n            __m128i b = _mm_loadu_si128((__m128i*)&l[j]);\n            __m128i sum = _mm_add_epi32(a, b);\n            int mask = _mm_movemask_epi8(_mm_cmpeq_epi32(sum, _mm_setzero_si128()));\n            if (mask != 0) return true;\n        }\n    }\n\n    for (; i < n; ++i) {\n        for (int j = i + 1; j < n; ++j) {\n            if (l[i] + l[j] == 0) return true;\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_84_SSE", "completion": "```cpp\nbool pairs_sum_to_zero_simd(std::vector<int> l) {\n    int n = l.size();\n    if (n < 2) return false;\n\n    for (int i = 0; i < n; i += 4) {\n        __m128i vec1 = _mm_loadu_si128((__m128i*)&l[i]);\n        for (int j = i + 4; j < n; j += 4) {\n            __m128i vec2 = _mm_loadu_si128((__m128i*)&l[j]);\n            __m128i sum = _mm_add_epi32(vec1, vec2);\n            __m128i zero = _mm_setzero_si128();\n            __m128i cmp = _mm_cmpeq_epi32(sum, zero);\n            int mask = _mm_movemask_epi8(cmp);\n            if (mask != 0) return true;\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_84_SSE", "completion": "```cpp\nbool pairs_sum_to_zero_simd(std::vector<int> l) {\n    if (l.size() < 2) return false;\n\n    int n = l.size();\n    int i = 0;\n\n    for (; i <= n - 4; i += 4) {\n        __m128i v1 = _mm_loadu_si128((__m128i*)&l[i]);\n        __m128i v2 = _mm_loadu_si128((__m128i*)&l[i + 1]);\n        __m128i v3 = _mm_loadu_si128((__m128i*)&l[i + 2]);\n        __m128i v4 = _mm_loadu_si128((__m128i*)&l[i + 3]);\n\n        __m128i sum1 = _mm_add_epi32(v1, v2);\n        __m128i sum2 = _mm_add_epi32(v3, v4);\n\n        __m128i zero = _mm_setzero_si128();\n\n        __m128i cmp1 = _mm_cmpeq_epi32(sum1, zero);\n        __m128i cmp2 = _mm_cmpeq_epi32(sum2, zero);\n\n        int mask1 = _mm_movemask_epi8(cmp1);\n        int mask2 = _mm_movemask_epi8(cmp2);\n\n        if (mask1 || mask2) return true;\n    }\n\n    for (; i < n; ++i) {\n        for (int j = i + 1; j < n; ++j) {\n            if (l[i] + l[j] == 0) return true;\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_85_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string change_base_simd(int64_t x, int8_t base) {\n    std::string result;\n    __m128i base_vec = _mm_set1_epi32(base);\n    __m128i zero_vec = _mm_setzero_si128();\n\n    while (x > 0) {\n        __m128i x_vec = _mm_set1_epi64x(x);\n        __m128i rem_vec = _mm_div_epi32(x_vec, base_vec);\n        __m128i rem = _mm_cvtsi128_si32(rem_vec);\n        result = std::to_string(rem) + result;\n        x /= base;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_85_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string change_base_simd(int64_t x, int8_t base) {\n    std::string result;\n    __m128i base_vec = _mm_set1_epi8(base);\n    __m128i zero_vec = _mm_setzero_si128();\n\n    while (x > 0) {\n        __m128i x_vec = _mm_set1_epi64x(x);\n        __m128i rem_vec = _mm_div_epi64(x_vec, base_vec);\n        __m128i rem = _mm_extract_epi64(rem_vec, 0);\n        result = std::to_string(rem) + result;\n        x = _mm_extract_epi64(rem_vec, 1);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_85_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string change_base_simd(int64_t x, int8_t base) {\n    std::string result;\n    __m128i base_vec = _mm_set1_epi32(base);\n    __m128i zero_vec = _mm_setzero_si128();\n\n    while (x > 0) {\n        __m128i x_vec = _mm_set1_epi64x(x);\n        __m128i div_result = _mm_div_epi64(x_vec, base_vec);\n        __m128i rem_result = _mm_sub_epi64(x_vec, _mm_mullo_epi64(div_result, base_vec));\n\n        int64_t remainder = _mm_cvtsi128_si64(rem_result);\n        result = std::to_string(remainder) + result;\n        x = _mm_cvtsi128_si64(div_result);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_85_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string change_base_simd(int64_t x, int8_t base) {\n    std::string result;\n    __m128i base_vec = _mm_set1_epi8(base);\n    __m128i zero_vec = _mm_setzero_si128();\n\n    while (x > 0) {\n        __m128i x_vec = _mm_set1_epi64x(x);\n        __m128i rem_vec = _mm_div_epi64(x_vec, base_vec);\n        __m128i rem = _mm_extract_epi64(rem_vec, 0);\n        result = std::to_string(rem) + result;\n        x = _mm_extract_epi64(rem_vec, 1);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_85_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string change_base_simd(int64_t x, int8_t base) {\n    std::string result;\n    __m128i base_vec = _mm_set1_epi32(base);\n    __m128i zero_vec = _mm_setzero_si128();\n\n    while (x > 0) {\n        __m128i x_vec = _mm_set1_epi64x(x);\n        __m128i div_result = _mm_div_epi64(x_vec, base_vec);\n        __m128i rem_result = _mm_sub_epi64(x_vec, _mm_mullo_epi64(div_result, base_vec));\n\n        int64_t remainder = _mm_cvtsi128_si64(rem_result);\n        result = std::to_string(remainder) + result;\n        x = _mm_cvtsi128_si64(div_result);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_86_SSE", "completion": "```cpp\nbool is_palindrome_simd(std::string text) {\n    size_t len = text.length();\n    if (len == 0) return true;\n\n    size_t i = 0;\n    for (; i <= len - 16; i += 16) {\n        __m128i left = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&text[i]));\n        __m128i right = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&text[len - i - 16]));\n\n        __m128i cmp = _mm_cmpeq_epi8(left, _mm_shuffle_epi8(right, _mm_setr_epi8(15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 0)));\n\n        if (_mm_movemask_epi8(cmp) != 0xFFFF) return false;\n    }\n\n    for (; i < len / 2; ++i) {\n        if (text[i] != text[len - i - 1]) return false;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_86_SSE", "completion": "```cpp\nbool is_palindrome_simd(std::string text) {\n    size_t len = text.length();\n    if (len == 0) return true;\n\n    size_t i = 0;\n    size_t j = len - 1;\n\n    while (i < j) {\n        __m128i chunk1 = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&text[i]));\n        __m128i chunk2 = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&text[j - 15]));\n\n        __m128i reversed_chunk2 = _mm_shuffle_epi8(chunk2, _mm_set_epi8(15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 0));\n\n        __m128i cmp = _mm_cmpeq_epi8(chunk1, reversed_chunk2);\n        int mask = _mm_movemask_epi8(cmp);\n\n        if (mask != 0xFFFF) return false;\n\n        i += 16;\n        j -= 16;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_86_SSE", "completion": "```cpp\nbool is_palindrome_simd(std::string text) {\n    size_t len = text.length();\n    if (len == 0) return true;\n\n    size_t i = 0;\n    size_t j = len - 1;\n\n    while (i < j) {\n        __m128i a = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&text[i]));\n        __m128i b = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&text[j - 15]));\n\n        __m128i cmp = _mm_cmpeq_epi8(a, _mm_shuffle_epi8(b, _mm_setr_epi8(15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 0)));\n\n        if (_mm_movemask_epi8(cmp) != 0xFFFF) return false;\n\n        i += 16;\n        j -= 16;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_86_SSE", "completion": "```cpp\nbool is_palindrome_simd(std::string text) {\n    size_t len = text.length();\n    if (len == 0) return true;\n\n    size_t i = 0;\n    size_t j = len - 1;\n\n    while (i < j) {\n        __m128i a = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&text[i]));\n        __m128i b = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&text[j - 15]));\n\n        __m128i cmp = _mm_cmpeq_epi8(a, _mm_shuffle_epi8(b, _mm_setr_epi8(15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 0)));\n\n        if (_mm_movemask_epi8(cmp) != 0xFFFF) return false;\n\n        i += 16;\n        j -= 16;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_86_SSE", "completion": "```c++\nbool is_palindrome_simd(std::string text) {\n    size_t len = text.length();\n    if (len == 0) return true;\n\n    size_t i = 0;\n    size_t j = len - 1;\n\n    while (i < j) {\n        __m128i a = _mm_loadu_si128((__m128i*)&text[i]);\n        __m128i b = _mm_loadu_si128((__m128i*)&text[j - 15]);\n\n        __m128i cmp = _mm_cmpeq_epi8(a, _mm_shuffle_epi8(b, _mm_setr_epi8(15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 0)));\n\n        int mask = _mm_movemask_epi8(cmp);\n        if (mask != 0xFFFF) return false;\n\n        i += 16;\n        j -= 16;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_87_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string decode_shift_simd(std::string s) {\n    std::string out(s.length(), ' ');\n    int i;\n    __m128i shift = _mm_set1_epi8(5);\n    __m128i a = _mm_set1_epi8('a');\n    __m128i z = _mm_set1_epi8('z');\n    __m128i mask = _mm_set1_epi8(25);\n\n    for (i = 0; i <= s.length() - 16; i += 16) {\n        __m128i input = _mm_loadu_si128((__m128i*)&s[i]);\n        __m128i decoded = _mm_subs_epu8(input, shift);\n        __m128i below_a = _mm_cmplt_epu8(decoded, a);\n        __m128i above_z = _mm_cmpgt_epu8(decoded, z);\n        __m128i wrap = _mm_and_si128(_mm_or_si128(below_a, above_z), mask);\n        decoded = _mm_adds_epu8(decoded, wrap);\n        _mm_storeu_si128((__m128i*)&out[i], decoded);\n    }\n\n    for (; i < s.length(); i++) {\n        int w = ((int)s[i] - 5 - (int)'a' + 26) % 26 + (int)'a';\n        out[i] = (char)w;\n    }\n\n    return out;\n}\n```"}
{"task_id": "SimdBench_87_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string decode_shift_simd(std::string s) {\n    std::string out(s.length(), '\\0');\n    __m128i shift = _mm_set1_epi8(5);\n    __m128i a = _mm_set1_epi8('a');\n    __m128i z = _mm_set1_epi8('z');\n\n    for (size_t i = 0; i < s.length(); i += 16) {\n        __m128i input = _mm_loadu_si128((__m128i*)&s[i]);\n        __m128i decoded = _mm_sub_epi8(input, shift);\n        __m128i mask = _mm_cmplt_epi8(decoded, a);\n        decoded = _mm_sub_epi8(decoded, _mm_and_si128(mask, _mm_set1_epi8(26)));\n        _mm_storeu_si128((__m128i*)&out[i], decoded);\n    }\n\n    return out;\n}\n```"}
{"task_id": "SimdBench_87_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string decode_shift_simd(std::string s) {\n    std::string out(s.length(), '\\0');\n    __m128i shift = _mm_set1_epi8(5);\n    __m128i a = _mm_set1_epi8('a');\n    __m128i z = _mm_set1_epi8('z');\n    __m128i mask = _mm_set1_epi8(25);\n\n    for (size_t i = 0; i < s.length(); i += 16) {\n        __m128i input = _mm_loadu_si128((__m128i*)&s[i]);\n        __m128i decoded = _mm_sub_epi8(input, shift);\n        __m128i below_a = _mm_cmplt_epi8(decoded, a);\n        __m128i above_z = _mm_cmpgt_epi8(decoded, z);\n        __m128i wrap = _mm_and_si128(_mm_or_si128(below_a, above_z), mask);\n        decoded = _mm_add_epi8(decoded, wrap);\n        _mm_storeu_si128((__m128i*)&out[i], decoded);\n    }\n\n    return out;\n}\n```"}
{"task_id": "SimdBench_87_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string decode_shift_simd(std::string s) {\n    std::string out(s.length(), ' ');\n    int len = s.length();\n    int i;\n\n    __m128i shift = _mm_set1_epi8(5);\n    __m128i a = _mm_set1_epi8('a');\n    __m128i mod = _mm_set1_epi8(26);\n\n    for (i = 0; i <= len - 16; i += 16) {\n        __m128i input = _mm_loadu_si128((__m128i*)&s[i]);\n        __m128i decoded = _mm_sub_epi8(input, shift);\n        decoded = _mm_sub_epi8(decoded, a);\n        decoded = _mm_add_epi8(decoded, mod);\n        decoded = _mm_and_si128(decoded, _mm_set1_epi8(0x1F));\n        decoded = _mm_add_epi8(decoded, a);\n        _mm_storeu_si128((__m128i*)&out[i], decoded);\n    }\n\n    for (; i < len; ++i) {\n        int w = ((int)s[i] - 5 - (int)'a' + 26) % 26 + (int)'a';\n        out[i] = (char)w;\n    }\n\n    return out;\n}\n```"}
{"task_id": "SimdBench_87_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string decode_shift_simd(std::string s) {\n    std::string out(s.length(), ' ');\n    int i;\n    __m128i shift = _mm_set1_epi8(5);\n    __m128i a = _mm_set1_epi8('a');\n    __m128i z = _mm_set1_epi8('z');\n    __m128i mask = _mm_set1_epi8(25);\n\n    for (i = 0; i <= s.length() - 16; i += 16) {\n        __m128i input = _mm_loadu_si128((__m128i*)&s[i]);\n        __m128i decoded = _mm_subs_epu8(input, shift);\n        __m128i below_a = _mm_cmplt_epi8(decoded, a);\n        __m128i above_z = _mm_cmpgt_epi8(decoded, z);\n        __m128i wrap_around = _mm_and_si128(_mm_or_si128(below_a, above_z), mask);\n        decoded = _mm_add_epi8(decoded, _mm_and_si128(wrap_around, shift));\n        _mm_storeu_si128((__m128i*)&out[i], decoded);\n    }\n\n    for (; i < s.length(); i++) {\n        int w = ((int)s[i] - 5 - (int)'a' + 26) % 26 + (int)'a';\n        out[i] = (char)w;\n    }\n\n    return out;\n}\n```"}
{"task_id": "SimdBench_88_SSE", "completion": "```cpp\nbool below_threshold_simd(std::vector<int> l, int t) {\n    __m128i threshold = _mm_set1_epi32(t);\n    __m128i all_below = _mm_set1_epi32(-1);\n\n    for (size_t i = 0; i < l.size(); i += 4) {\n        __m128i vec = _mm_loadu_si128((__m128i*)&l[i]);\n        __m128i cmp = _mm_cmplt_epi32(vec, threshold);\n        all_below = _mm_and_si128(all_below, cmp);\n    }\n\n    return _mm_movemask_epi8(all_below) == 0xFFFFFFFF;\n}\n```"}
{"task_id": "SimdBench_88_SSE", "completion": "```cpp\nbool below_threshold_simd(std::vector<int> l, int t) {\n    __m128i threshold = _mm_set1_epi32(t);\n    __m128i all_below = _mm_set1_epi32(-1);\n\n    for (size_t i = 0; i < l.size(); i += 4) {\n        __m128i vec = _mm_loadu_si128((__m128i*)&l[i]);\n        __m128i cmp = _mm_cmplt_epi32(vec, threshold);\n        all_below = _mm_and_si128(all_below, cmp);\n    }\n\n    return _mm_movemask_epi8(all_below) == 0xFFFFFFFF;\n}\n```"}
{"task_id": "SimdBench_88_SSE", "completion": "```cpp\nbool below_threshold_simd(std::vector<int> l, int t) {\n    const int size = l.size();\n    const int num_elements = size / 4;\n    const int remainder = size % 4;\n\n    __m128i threshold = _mm_set1_epi32(t);\n    __m128i mask = _mm_set1_epi32(0);\n\n    for (int i = 0; i < num_elements; ++i) {\n        __m128i vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&l[i * 4]));\n        __m128i cmp = _mm_cmplt_epi32(vec, threshold);\n        mask = _mm_or_si128(mask, cmp);\n    }\n\n    int mask_result = _mm_movemask_epi8(mask);\n    if (mask_result != 0) {\n        return false;\n    }\n\n    for (int i = num_elements * 4; i < size; ++i) {\n        if (l[i] >= t) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_88_SSE", "completion": "```cpp\nbool below_threshold_simd(std::vector<int> l, int t) {\n    __m128i threshold = _mm_set1_epi32(t);\n    __m128i result = _mm_set1_epi32(1);\n\n    for (size_t i = 0; i < l.size(); i += 4) {\n        __m128i vec = _mm_loadu_si128((__m128i*)&l[i]);\n        __m128i cmp = _mm_cmplt_epi32(vec, threshold);\n        result = _mm_and_si128(result, cmp);\n    }\n\n    int mask = _mm_movemask_epi8(result);\n    return mask == 0xFFFFFFFF;\n}\n```"}
{"task_id": "SimdBench_88_SSE", "completion": "```cpp\nbool below_threshold_simd(std::vector<int> l, int t) {\n    __m128i threshold = _mm_set1_epi32(t);\n    __m128i mask = _mm_setzero_si128();\n\n    for (size_t i = 0; i < l.size(); i += 4) {\n        __m128i values = _mm_loadu_si128((__m128i*)&l[i]);\n        __m128i cmp = _mm_cmplt_epi32(values, threshold);\n        mask = _mm_or_si128(mask, cmp);\n    }\n\n    return _mm_movemask_epi8(mask) == 0;\n}\n```"}
{"task_id": "SimdBench_89_SSE", "completion": "```cpp\nbool correct_bracketing_simd(std::string brackets) {\n    const size_t len = brackets.size();\n    if (len % 16 != 0) {\n        return false;\n    }\n\n    __m128i open_bracket = _mm_set1_epi8('<');\n    __m128i close_bracket = _mm_set1_epi8('>');\n    __m128i zero = _mm_setzero_si128();\n    __m128i count = zero;\n\n    for (size_t i = 0; i < len; i += 16) {\n        __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&brackets[i]));\n\n        __m128i open_mask = _mm_cmpeq_epi8(chunk, open_bracket);\n        __m128i close_mask = _mm_cmpeq_epi8(chunk, close_bracket);\n\n        __m128i open_count = _mm_and_si128(open_mask, _mm_set1_epi8(1));\n        __m128i close_count = _mm_and_si128(close_mask, _mm_set1_epi8(1));\n\n        open_count = _mm_sad_epu8(open_count, zero);\n        close_count = _mm_sad_epu8(close_count, zero);\n\n        count = _mm_add_epi32(count, _mm_unpacklo_epi64(open_count, close_count));\n    }\n\n    int32_t open_total = _mm_cvtsi128_si32(count);\n    int32_t close_total = _mm_cvtsi128_si32(_mm_srli_si128(count, 8));\n\n    return open_total == close_total;\n}\n```"}
{"task_id": "SimdBench_89_SSE", "completion": "```cpp\nbool correct_bracketing_simd(std::string brackets) {\n    int len = brackets.size();\n    int balance = 0;\n    __m128i zero = _mm_setzero_si128();\n    __m128i open = _mm_set1_epi8('<');\n    __m128i close = _mm_set1_epi8('>');\n\n    for (int i = 0; i < len; i += 16) {\n        __m128i chunk = _mm_loadu_si128((__m128i*)&brackets[i]);\n        __m128i open_mask = _mm_cmpeq_epi8(chunk, open);\n        __m128i close_mask = _mm_cmpeq_epi8(chunk, close);\n\n        int open_count = _mm_movemask_epi8(open_mask);\n        int close_count = _mm_movemask_epi8(close_mask);\n\n        balance += __builtin_popcount(open_count) - __builtin_popcount(close_count);\n\n        if (balance < 0) {\n            return false;\n        }\n    }\n\n    return balance == 0;\n}\n```"}
{"task_id": "SimdBench_89_SSE", "completion": "```cpp\nbool correct_bracketing_simd(std::string brackets) {\n    int len = brackets.size();\n    int balance = 0;\n    __m128i zero = _mm_setzero_si128();\n    __m128i open = _mm_set1_epi8('<');\n    __m128i close = _mm_set1_epi8('>');\n\n    for (int i = 0; i < len; i += 16) {\n        __m128i chunk = _mm_loadu_si128((__m128i*)&brackets[i]);\n        __m128i open_mask = _mm_cmpeq_epi8(chunk, open);\n        __m128i close_mask = _mm_cmpeq_epi8(chunk, close);\n\n        int open_count = _mm_movemask_epi8(open_mask);\n        int close_count = _mm_movemask_epi8(close_mask);\n\n        balance += __builtin_popcount(open_count) - __builtin_popcount(close_count);\n\n        if (balance < 0) {\n            return false;\n        }\n    }\n\n    return balance == 0;\n}\n```"}
{"task_id": "SimdBench_89_SSE", "completion": "```c++\nbool correct_bracketing_simd(std::string brackets) {\n    const size_t len = brackets.size();\n    const size_t simd_len = len & ~15; // Process in chunks of 16 bytes (128 bits)\n    int balance = 0;\n\n    __m128i open_bracket = _mm_set1_epi8('<');\n    __m128i close_bracket = _mm_set1_epi8('>');\n\n    for (size_t i = 0; i < simd_len; i += 16) {\n        __m128i chunk = _mm_loadu_si128((__m128i*)&brackets[i]);\n        __m128i open_mask = _mm_cmpeq_epi8(chunk, open_bracket);\n        __m128i close_mask = _mm_cmpeq_epi8(chunk, close_bracket);\n\n        int open_count = _mm_movemask_epi8(open_mask);\n        int close_count = _mm_movemask_epi8(close_mask);\n\n        balance += _mm_popcnt_u32(open_count) - _mm_popcnt_u32(close_count);\n        if (balance < 0) return false;\n    }\n\n    for (size_t i = simd_len; i < len; ++i) {\n        if (brackets[i] == '<') ++balance;\n        else if (brackets[i] == '>') --balance;\n        if (balance < 0) return false;\n    }\n\n    return balance == 0;\n}\n```"}
{"task_id": "SimdBench_89_SSE", "completion": "```c++\nbool correct_bracketing_simd(std::string brackets) {\n    const size_t len = brackets.size();\n    if (len % 16 != 0) {\n        return false;\n    }\n\n    __m128i open_bracket = _mm_set1_epi8('<');\n    __m128i close_bracket = _mm_set1_epi8('>');\n    __m128i zero = _mm_setzero_si128();\n    __m128i count = zero;\n\n    for (size_t i = 0; i < len; i += 16) {\n        __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&brackets[i]));\n\n        __m128i open_mask = _mm_cmpeq_epi8(chunk, open_bracket);\n        __m128i close_mask = _mm_cmpeq_epi8(chunk, close_bracket);\n\n        __m128i open_count = _mm_and_si128(open_mask, _mm_set1_epi8(1));\n        __m128i close_count = _mm_and_si128(close_mask, _mm_set1_epi8(1));\n\n        count = _mm_sub_epi8(count, close_count);\n        count = _mm_add_epi8(count, open_count);\n\n        __m128i negative_mask = _mm_cmplt_epi8(count, zero);\n        if (_mm_movemask_epi8(negative_mask) != 0) {\n            return false;\n        }\n    }\n\n    return _mm_testz_si128(count, count);\n}\n```"}
{"task_id": "SimdBench_90_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nbool correct_bracketing_simd(std::string brackets) {\n    const size_t len = brackets.size();\n    if (len % 16 != 0) {\n        return false; // For simplicity, assume length is a multiple of 16\n    }\n\n    __m128i open_bracket = _mm_set1_epi8('(');\n    __m128i close_bracket = _mm_set1_epi8(')');\n    __m128i zero = _mm_setzero_si128();\n    __m128i count = zero;\n\n    for (size_t i = 0; i < len; i += 16) {\n        __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&brackets[i]));\n\n        __m128i open_mask = _mm_cmpeq_epi8(chunk, open_bracket);\n        __m128i close_mask = _mm_cmpeq_epi8(chunk, close_bracket);\n\n        __m128i open_count = _mm_and_si128(open_mask, _mm_set1_epi8(1));\n        __m128i close_count = _mm_and_si128(close_mask, _mm_set1_epi8(1));\n\n        open_count = _mm_sad_epu8(open_count, zero);\n        close_count = _mm_sad_epu8(close_count, zero);\n\n        count = _mm_add_epi32(count, _mm_sub_epi32(open_count, close_count));\n    }\n\n    int32_t result[4];\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(result), count);\n\n    return result[0] == 0 && result[1] == 0 && result[2] == 0 && result[3] == 0;\n}\n```"}
{"task_id": "SimdBench_90_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nbool correct_bracketing_simd(std::string brackets) {\n    const size_t len = brackets.length();\n    if (len % 16 != 0) {\n        return false; // For simplicity, assume length is a multiple of 16\n    }\n\n    __m128i open_bracket = _mm_set1_epi8('(');\n    __m128i close_bracket = _mm_set1_epi8(')');\n    __m128i zero = _mm_setzero_si128();\n    __m128i count = zero;\n\n    for (size_t i = 0; i < len; i += 16) {\n        __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&brackets[i]));\n\n        __m128i open_mask = _mm_cmpeq_epi8(chunk, open_bracket);\n        __m128i close_mask = _mm_cmpeq_epi8(chunk, close_bracket);\n\n        __m128i open_count = _mm_and_si128(open_mask, _mm_set1_epi8(1));\n        __m128i close_count = _mm_and_si128(close_mask, _mm_set1_epi8(1));\n\n        open_count = _mm_sad_epu8(open_count, zero);\n        close_count = _mm_sad_epu8(close_count, zero);\n\n        __m128i diff = _mm_sub_epi32(open_count, close_count);\n        count = _mm_add_epi32(count, diff);\n    }\n\n    int32_t result[4];\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(result), count);\n\n    return result[0] == 0 && result[1] == 0 && result[2] == 0 && result[3] == 0;\n}\n```"}
{"task_id": "SimdBench_90_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nbool correct_bracketing_simd(std::string brackets) {\n    const size_t len = brackets.size();\n    if (len % 16 != 0) {\n        return false; // For simplicity, assume length is a multiple of 16\n    }\n\n    __m128i open_bracket = _mm_set1_epi8('(');\n    __m128i close_bracket = _mm_set1_epi8(')');\n    __m128i zero = _mm_setzero_si128();\n    __m128i count = _mm_setzero_si128();\n\n    for (size_t i = 0; i < len; i += 16) {\n        __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&brackets[i]));\n\n        __m128i open_mask = _mm_cmpeq_epi8(chunk, open_bracket);\n        __m128i close_mask = _mm_cmpeq_epi8(chunk, close_bracket);\n\n        __m128i open_count = _mm_and_si128(open_mask, _mm_set1_epi8(1));\n        __m128i close_count = _mm_and_si128(close_mask, _mm_set1_epi8(1));\n\n        count = _mm_sub_epi8(count, close_count);\n        count = _mm_add_epi8(count, open_count);\n\n        __m128i negative_mask = _mm_cmplt_epi8(count, zero);\n        if (_mm_movemask_epi8(negative_mask) != 0) {\n            return false;\n        }\n    }\n\n    return _mm_testz_si128(count, count) != 0;\n}\n```"}
{"task_id": "SimdBench_90_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nbool correct_bracketing_simd(std::string brackets) {\n    const size_t len = brackets.size();\n    if (len % 16 != 0) {\n        return false; // For simplicity, assume length is a multiple of 16\n    }\n\n    __m128i open_bracket = _mm_set1_epi8('(');\n    __m128i close_bracket = _mm_set1_epi8(')');\n    __m128i zero = _mm_setzero_si128();\n    __m128i count = zero;\n\n    for (size_t i = 0; i < len; i += 16) {\n        __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&brackets[i]));\n\n        __m128i open_mask = _mm_cmpeq_epi8(chunk, open_bracket);\n        __m128i close_mask = _mm_cmpeq_epi8(chunk, close_bracket);\n\n        __m128i open_count = _mm_and_si128(open_mask, _mm_set1_epi8(1));\n        __m128i close_count = _mm_and_si128(close_mask, _mm_set1_epi8(1));\n\n        open_count = _mm_sad_epu8(open_count, zero);\n        close_count = _mm_sad_epu8(close_count, zero);\n\n        __m128i diff = _mm_sub_epi32(open_count, close_count);\n        count = _mm_add_epi32(count, diff);\n    }\n\n    int32_t result[4];\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(result), count);\n\n    return result[0] == 0 && result[1] == 0 && result[2] == 0 && result[3] == 0;\n}\n```"}
{"task_id": "SimdBench_90_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nbool correct_bracketing_simd(std::string brackets) {\n    const size_t len = brackets.size();\n    if (len % 16 != 0) {\n        return false; // For simplicity, assume length is a multiple of 16\n    }\n\n    __m128i open_bracket = _mm_set1_epi8('(');\n    __m128i close_bracket = _mm_set1_epi8(')');\n    __m128i zero = _mm_setzero_si128();\n    __m128i count = zero;\n\n    for (size_t i = 0; i < len; i += 16) {\n        __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&brackets[i]));\n\n        __m128i open_mask = _mm_cmpeq_epi8(chunk, open_bracket);\n        __m128i close_mask = _mm_cmpeq_epi8(chunk, close_bracket);\n\n        __m128i open_count = _mm_and_si128(open_mask, _mm_set1_epi8(1));\n        __m128i close_count = _mm_and_si128(close_mask, _mm_set1_epi8(1));\n\n        count = _mm_sub_epi8(count, close_count);\n        count = _mm_add_epi8(count, open_count);\n\n        __m128i negative_mask = _mm_cmplt_epi8(count, zero);\n        if (_mm_movemask_epi8(negative_mask) != 0) {\n            return false;\n        }\n    }\n\n    return _mm_testz_si128(count, count) != 0;\n}\n```"}
{"task_id": "SimdBench_91_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<float> derivative_simd(std::vector<float> xs) {\n    int n = xs.size();\n    std::vector<float> result(n - 1);\n\n    for (int i = 1; i < n; ++i) {\n        result[i - 1] = xs[i] * i;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_91_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<float> derivative_simd(std::vector<float> xs) {\n    int n = xs.size();\n    std::vector<float> result(n - 1);\n\n    for (int i = 1; i < n; ++i) {\n        result[i - 1] = xs[i] * i;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_91_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<float> derivative_simd(std::vector<float> xs) {\n    int n = xs.size();\n    std::vector<float> result(n - 1);\n\n    if (n <= 1) {\n        return result;\n    }\n\n    __m128 index = _mm_set_ps(3.0f, 2.0f, 1.0f, 0.0f);\n\n    for (int i = 1; i < n; ++i) {\n        __m128 coeff = _mm_loadu_ps(&xs[i]);\n        __m128 mul = _mm_mul_ps(coeff, index);\n        _mm_storeu_ps(&result[i - 1], mul);\n\n        index = _mm_add_ps(index, _mm_set1_ps(4.0f));\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_91_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<float> derivative_simd(std::vector<float> xs) {\n    int n = xs.size();\n    std::vector<float> result(n - 1);\n\n    if (n <= 1) {\n        return result;\n    }\n\n    __m128i index = _mm_set_epi32(3, 2, 1, 0);\n    __m128i step = _mm_set1_epi32(4);\n\n    for (int i = 0; i < n - 1; i += 4) {\n        __m128 coeffs = _mm_loadu_ps(&xs[i + 1]);\n        __m128 multipliers = _mm_cvtepi32_ps(_mm_add_epi32(index, _mm_set1_epi32(i + 1)));\n        __m128 product = _mm_mul_ps(coeffs, multipliers);\n        _mm_storeu_ps(&result[i], product);\n        index = _mm_add_epi32(index, step);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_91_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<float> derivative_simd(std::vector<float> xs) {\n    int n = xs.size();\n    std::vector<float> result(n - 1);\n\n    for (int i = 1; i < n; ++i) {\n        result[i - 1] = i * xs[i];\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_92_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nint vowels_count_simd(std::string s) {\n    const __m128i vowels = _mm_set_epi8('u', 'o', 'i', 'e', 'a', 'y', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n    int count = 0;\n    size_t len = s.length();\n    size_t i = 0;\n\n    for (; i + 16 <= len; i += 16) {\n        __m128i chunk = _mm_loadu_si128((__m128i*)&s[i]);\n        chunk = _mm_or_si128(_mm_cmpeq_epi8(chunk, vowels), _mm_cmpeq_epi8(_mm_sub_epi8(chunk, _mm_set1_epi8(32)), vowels));\n        count += _mm_movemask_epi8(chunk);\n    }\n\n    for (; i < len; ++i) {\n        char c = s[i];\n        if (c == 'a' || c == 'e' || c == 'i' || c == 'o' || c == 'u' ||\n            c == 'A' || c == 'E' || c == 'I' || c == 'O' || c == 'U' ||\n            (c == 'y' && i == len - 1) || (c == 'Y' && i == len - 1)) {\n            count++;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_92_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nint vowels_count_simd(std::string s) {\n    const __m128i vowels = _mm_set_epi8('u', 'o', 'i', 'e', 'a', 'y', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n    int count = 0;\n    int len = s.length();\n\n    for (int i = 0; i < len; i += 16) {\n        __m128i chunk = _mm_loadu_si128((__m128i*)&s[i]);\n        chunk = _mm_and_si128(_mm_cmpeq_epi8(chunk, vowels), _mm_set1_epi8(1));\n        count += _mm_extract_epi16(_mm_sad_epu8(chunk, _mm_setzero_si128()), 0);\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_92_SSE", "completion": "```c++\nint vowels_count_simd(std::string s) {\n    const __m128i vowels = _mm_set_epi8('u', 'o', 'i', 'e', 'a', 'y', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n    int count = 0;\n    int len = s.length();\n    int i = 0;\n\n    for (; i <= len - 16; i += 16) {\n        __m128i chunk = _mm_loadu_si128((__m128i*)&s[i]);\n        __m128i lower = _mm_or_si128(chunk, _mm_set1_epi8(0x20));\n        __m128i cmp1 = _mm_cmpeq_epi8(_mm_shuffle_epi8(lower, _mm_set1_epi8(0)), vowels);\n        __m128i cmp2 = _mm_cmpeq_epi8(_mm_shuffle_epi8(lower, _mm_set1_epi8(1)), vowels);\n        __m128i cmp3 = _mm_cmpeq_epi8(_mm_shuffle_epi8(lower, _mm_set1_epi8(2)), vowels);\n        __m128i cmp4 = _mm_cmpeq_epi8(_mm_shuffle_epi8(lower, _mm_set1_epi8(3)), vowels);\n        __m128i cmp5 = _mm_cmpeq_epi8(_mm_shuffle_epi8(lower, _mm_set1_epi8(4)), vowels);\n        __m128i cmp6 = _mm_cmpeq_epi8(_mm_shuffle_epi8(lower, _mm_set1_epi8(5)), vowels);\n        __m128i cmp7 = _mm_cmpeq_epi8(_mm_shuffle_epi8(lower, _mm_set1_epi8(6)), vowels);\n        __m128i cmp8 = _mm_cmpeq_epi8(_mm_shuffle_epi8(lower, _mm_set1_epi8(7)), vowels);\n        __m128i cmp9 = _mm_cmpeq_epi8(_mm_shuffle_epi8(lower, _mm_set1_epi8(8)), vowels);\n        __m128i cmp10 = _mm_cmpeq_epi8(_mm_shuffle_epi8(lower, _mm_set1_epi8(9)), vowels);\n        __m128i cmp11 = _mm_cmpeq_epi8(_mm_shuffle_epi8(lower, _mm_set1_epi8(10)), vowels);\n        __m128i cmp12 = _mm_cmpeq_epi8(_mm_shuffle_epi8(lower, _mm_set1_epi8(11)), vowels);\n        __m128i cmp13 = _mm_cmpeq_epi8(_mm_shuffle_epi8(lower, _mm_set1_epi8(12)), vowels);\n        __m128i cmp14 = _mm_cmpeq_epi8(_mm_shuffle_epi8(lower, _mm_set1_epi8(13)), vowels);\n        __m128i cmp15 = _mm_cmpeq_epi8(_mm_shuffle_epi8(lower, _mm_set1_epi8(14)), vowels);\n        __m128i cmp16 = _mm_cmpeq_epi8(_mm_shuffle_epi8(lower, _mm_set1_epi8(15)), vowels);\n\n        __m128i result = _mm_or_si128(_mm_or_si128(cmp1, cmp2), _mm_or_si128(cmp3, cmp4));\n        result = _mm_or_si128(result, _mm_or_si128(cmp5, cmp6));\n        result = _mm_or_si128(result, _mm_or_si128(cmp7, cmp8));\n        result = _mm_or_si128(result, _mm_or_si128(cmp9, cmp10));\n        result = _mm_or_si128(result, _mm_or_si128(cmp11, cmp12));\n        result = _mm_or_si128(result, _mm_or_si128(cmp13, cmp14));\n        result = _mm_or_si128(result, _mm_or_si128(cmp15, cmp16));\n\n        count += _mm_movemask_epi8(result);\n    }\n\n    for (; i < len; ++i) {\n        char c = tolower(s[i]);\n        if (c == 'a' || c == 'e' || c == 'i' || c == 'o' || c == 'u' || (c == 'y' && i == len - 1)) {\n            ++count;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_92_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nint vowels_count_simd(std::string s) {\n    const __m128i vowels = _mm_set_epi8('u', 'o', 'i', 'e', 'a', 'y', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n    int count = 0;\n    size_t len = s.length();\n    size_t i = 0;\n\n    for (; i + 16 <= len; i += 16) {\n        __m128i chunk = _mm_loadu_si128((__m128i*)&s[i]);\n        __m128i lower = _mm_or_si128(chunk, _mm_set1_epi8(0x20));\n        __m128i cmp = _mm_cmpeq_epi8(_mm_shuffle_epi8(vowels, _mm_cmpeq_epi8(lower, vowels)), vowels);\n        count += _mm_movemask_epi8(cmp);\n    }\n\n    for (; i < len; ++i) {\n        char c = tolower(s[i]);\n        if (c == 'a' || c == 'e' || c == 'i' || c == 'o' || c == 'u' || (c == 'y' && i == len - 1)) {\n            ++count;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_92_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nint vowels_count_simd(std::string s) {\n    const __m128i vowels = _mm_set_epi8('u', 'o', 'i', 'e', 'a', 'y', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n    int count = 0;\n    size_t len = s.length();\n    size_t i = 0;\n\n    for (; i + 16 <= len; i += 16) {\n        __m128i chunk = _mm_loadu_si128((__m128i*)&s[i]);\n        chunk = _mm_or_si128(_mm_cmpeq_epi8(chunk, vowels), _mm_cmpeq_epi8(_mm_sub_epi8(chunk, _mm_set1_epi8(32)), vowels));\n        count += _mm_movemask_epi8(chunk);\n    }\n\n    for (; i < len; ++i) {\n        char c = s[i];\n        if (c == 'a' || c == 'e' || c == 'i' || c == 'o' || c == 'u' ||\n            c == 'A' || c == 'E' || c == 'I' || c == 'O' || c == 'U' ||\n            (c == 'y' && i == len - 1) || (c == 'Y' && i == len - 1)) {\n            count++;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_93_SSE", "completion": "```cpp\nint digitSum_simd(std::string s) {\n    __m128i sum = _mm_setzero_si128();\n    __m128i upper_mask = _mm_set1_epi8(0x20);\n    __m128i ascii_mask = _mm_set1_epi8(0x7F);\n\n    int len = s.length();\n    int i = 0;\n\n    for (; i <= len - 16; i += 16) {\n        __m128i chunk = _mm_loadu_si128((__m128i*)&s[i]);\n        __m128i upper_chunk = _mm_andnot_si128(upper_mask, chunk);\n        __m128i is_upper = _mm_cmpeq_epi8(upper_chunk, chunk);\n        __m128i ascii_chunk = _mm_and_si128(chunk, ascii_mask);\n        __m128i masked_chunk = _mm_and_si128(ascii_chunk, is_upper);\n        sum = _mm_add_epi8(sum, masked_chunk);\n    }\n\n    alignas(16) int temp[4];\n    _mm_store_si128((__m128i*)temp, sum);\n    int total_sum = temp[0] + temp[1] + temp[2] + temp[3];\n\n    for (; i < len; ++i) {\n        if (s[i] >= 'A' && s[i] <= 'Z') {\n            total_sum += s[i];\n        }\n    }\n\n    return total_sum;\n}\n```"}
{"task_id": "SimdBench_93_SSE", "completion": "```cpp\nint digitSum_simd(std::string s) {\n    int sum = 0;\n    int len = s.length();\n    int i = 0;\n\n    __m128i upper_bound = _mm_set1_epi8('Z');\n    __m128i lower_bound = _mm_set1_epi8('A');\n\n    for (; i <= len - 16; i += 16) {\n        __m128i chars = _mm_loadu_si128((__m128i*)&s[i]);\n        __m128i is_upper = _mm_and_si128(_mm_cmpgt_epi8(chars, lower_bound), _mm_cmplt_epi8(chars, upper_bound));\n        __m128i ascii_values = _mm_and_si128(chars, is_upper);\n        int temp[4];\n        _mm_storeu_si128((__m128i*)temp, ascii_values);\n        sum += temp[0] + temp[1] + temp[2] + temp[3];\n    }\n\n    for (; i < len; ++i) {\n        if (s[i] >= 'A' && s[i] <= 'Z') {\n            sum += s[i];\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_93_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nint digitSum_simd(std::string s) {\n    int sum = 0;\n    int length = s.length();\n    int i = 0;\n\n    // Process 16 characters at a time\n    for (; i <= length - 16; i += 16) {\n        __m128i chunk = _mm_loadu_si128((__m128i*)&s[i]);\n        __m128i upper_mask = _mm_set1_epi8('A' - 1);\n        __m128i lower_mask = _mm_set1_epi8('Z' + 1);\n        __m128i is_upper = _mm_and_si128(_mm_cmpgt_epi8(chunk, upper_mask), _mm_cmplt_epi8(chunk, lower_mask));\n        __m128i ascii_values = _mm_and_si128(chunk, is_upper);\n        int temp_sum = _mm_extract_epi16(ascii_values, 0) & 0xFF;\n        temp_sum += _mm_extract_epi16(ascii_values, 1) & 0xFF;\n        temp_sum += _mm_extract_epi16(ascii_values, 2) & 0xFF;\n        temp_sum += _mm_extract_epi16(ascii_values, 3) & 0xFF;\n        temp_sum += _mm_extract_epi16(ascii_values, 4) & 0xFF;\n        temp_sum += _mm_extract_epi16(ascii_values, 5) & 0xFF;\n        temp_sum += _mm_extract_epi16(ascii_values, 6) & 0xFF;\n        temp_sum += _mm_extract_epi16(ascii_values, 7) & 0xFF;\n        sum += temp_sum;\n    }\n\n    // Process remaining characters\n    for (; i < length; ++i) {\n        if (s[i] >= 'A' && s[i] <= 'Z') {\n            sum += s[i];\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_93_SSE", "completion": "```c++\nint digitSum_simd(std::string s) {\n    __m128i sum = _mm_setzero_si128();\n    __m128i upper_bound = _mm_set1_epi8('A' - 1);\n    __m128i lower_bound = _mm_set1_epi8('Z' + 1);\n\n    for (size_t i = 0; i < s.size(); i += 16) {\n        __m128i chunk = _mm_loadu_si128((__m128i*)&s[i]);\n        __m128i upper_mask = _mm_and_si128(_mm_cmpgt_epi8(chunk, upper_bound), _mm_cmplt_epi8(chunk, lower_bound));\n        __m128i filtered_chunk = _mm_and_si128(chunk, upper_mask);\n        sum = _mm_add_epi8(sum, filtered_chunk);\n    }\n\n    int result = 0;\n    for (int i = 0; i < 16; ++i) {\n        result += ((uint8_t*)&sum)[i];\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_93_SSE", "completion": "```cpp\nint digitSum_simd(std::string s) {\n    __m128i sum = _mm_setzero_si128();\n    __m128i upper_bound = _mm_set1_epi8('A' - 1);\n    __m128i lower_bound = _mm_set1_epi8('Z' + 1);\n\n    int len = s.length();\n    int i = 0;\n\n    for (; i <= len - 16; i += 16) {\n        __m128i chunk = _mm_loadu_si128((__m128i*)&s[i]);\n        __m128i mask = _mm_and_si128(\n            _mm_cmpgt_epi8(chunk, upper_bound),\n            _mm_cmplt_epi8(chunk, lower_bound)\n        );\n        __m128i masked_chunk = _mm_and_si128(chunk, mask);\n        sum = _mm_add_epi8(sum, masked_chunk);\n    }\n\n    alignas(16) int result[4];\n    _mm_store_si128((__m128i*)result, sum);\n    int total_sum = result[0] + result[1] + result[2] + result[3];\n\n    for (; i < len; ++i) {\n        if (s[i] >= 'A' && s[i] <= 'Z') {\n            total_sum += s[i];\n        }\n    }\n\n    return total_sum;\n}\n```"}
{"task_id": "SimdBench_94_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <limits.h>\n\nstd::vector<int> pluck_simd(std::vector<int> arr) {\n    if (arr.empty()) {\n        return {};\n    }\n\n    int min_even = INT_MAX;\n    int min_index = -1;\n\n    __m128i min_even_vec = _mm_set1_epi32(INT_MAX);\n    __m128i min_index_vec = _mm_set1_epi32(-1);\n    __m128i even_mask = _mm_set1_epi32(1);\n\n    int size = arr.size();\n    int i = 0;\n\n    for (; i <= size - 4; i += 4) {\n        __m128i values = _mm_loadu_si128((__m128i*)&arr[i]);\n        __m128i indices = _mm_set_epi32(i + 3, i + 2, i + 1, i);\n\n        __m128i is_even = _mm_and_si128(values, even_mask);\n        is_even = _mm_cmpeq_epi32(is_even, _mm_setzero_si128());\n\n        __m128i masked_values = _mm_and_si128(values, is_even);\n        __m128i masked_indices = _mm_and_si128(indices, is_even);\n\n        __m128i cmp = _mm_cmplt_epi32(masked_values, min_even_vec);\n        min_even_vec = _mm_min_epi32(min_even_vec, masked_values);\n        min_index_vec = _mm_blendv_epi8(min_index_vec, masked_indices, cmp);\n    }\n\n    _mm_storeu_si128((__m128i*)&min_even, min_even_vec);\n    _mm_storeu_si128((__m128i*)&min_index, min_index_vec);\n\n    for (int j = 0; j < 4; ++j) {\n        if (min_even[j] < INT_MAX && (min_index == -1 || min_even[j] < min_even || (min_even[j] == min_even && min_index[j] < min_index))) {\n            min_even = min_even[j];\n            min_index = min_index[j];\n        }\n    }\n\n    for (; i < size; ++i) {\n        if (arr[i] % 2 == 0 && (min_index == -1 || arr[i] < min_even || (arr[i] == min_even && i < min_index))) {\n            min_even = arr[i];\n            min_index = i;\n        }\n    }\n\n    if (min_index == -1) {\n        return {};\n    }\n\n    return {min_even, min_index};\n}\n```"}
{"task_id": "SimdBench_94_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <limits.h>\n\nstd::vector<int> pluck_simd(std::vector<int> arr) {\n    if (arr.empty()) return {};\n\n    int n = arr.size();\n    int min_even = INT_MAX;\n    int min_index = -1;\n\n    __m128i min_even_vec = _mm_set1_epi32(INT_MAX);\n    __m128i min_index_vec = _mm_set1_epi32(-1);\n    __m128i even_mask = _mm_set1_epi32(1);\n\n    for (int i = 0; i < n; i += 4) {\n        __m128i values = _mm_loadu_si128((__m128i*)&arr[i]);\n        __m128i indices = _mm_setr_epi32(i, i + 1, i + 2, i + 3);\n\n        __m128i is_even = _mm_and_si128(values, even_mask);\n        is_even = _mm_cmpeq_epi32(is_even, _mm_setzero_si128());\n\n        __m128i even_values = _mm_and_si128(values, is_even);\n        __m128i even_indices = _mm_and_si128(indices, is_even);\n\n        __m128i cmp = _mm_cmplt_epi32(even_values, min_even_vec);\n        min_even_vec = _mm_min_epi32(min_even_vec, _mm_and_si128(cmp, even_values));\n        min_index_vec = _mm_blendv_epi8(min_index_vec, even_indices, cmp);\n    }\n\n    int min_even_arr[4];\n    int min_index_arr[4];\n    _mm_storeu_si128((__m128i*)min_even_arr, min_even_vec);\n    _mm_storeu_si128((__m128i*)min_index_arr, min_index_vec);\n\n    for (int i = 0; i < 4; ++i) {\n        if (min_even_arr[i] < min_even) {\n            min_even = min_even_arr[i];\n            min_index = min_index_arr[i];\n        }\n    }\n\n    if (min_index == -1) return {};\n    return {min_even, min_index};\n}\n```"}
{"task_id": "SimdBench_94_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <limits.h>\n\nstd::vector<int> pluck_simd(std::vector<int> arr) {\n    if (arr.empty()) return {};\n\n    int n = arr.size();\n    int min_even = INT_MAX;\n    int min_index = -1;\n\n    __m128i min_even_vec = _mm_set1_epi32(INT_MAX);\n    __m128i min_index_vec = _mm_set1_epi32(-1);\n    __m128i even_mask = _mm_set1_epi32(1);\n\n    for (int i = 0; i < n; i += 4) {\n        __m128i values = _mm_loadu_si128((__m128i*)&arr[i]);\n        __m128i indices = _mm_setr_epi32(i, i + 1, i + 2, i + 3);\n\n        __m128i is_even = _mm_and_si128(values, even_mask);\n        is_even = _mm_cmpeq_epi32(is_even, _mm_setzero_si128());\n\n        __m128i even_values = _mm_and_si128(values, is_even);\n        __m128i even_indices = _mm_and_si128(indices, is_even);\n\n        __m128i cmp = _mm_cmplt_epi32(even_values, min_even_vec);\n        min_even_vec = _mm_min_epi32(min_even_vec, _mm_and_si128(cmp, even_values));\n        min_index_vec = _mm_blendv_epi8(min_index_vec, even_indices, cmp);\n    }\n\n    int min_even_arr[4];\n    int min_index_arr[4];\n    _mm_storeu_si128((__m128i*)min_even_arr, min_even_vec);\n    _mm_storeu_si128((__m128i*)min_index_arr, min_index_vec);\n\n    for (int i = 0; i < 4; ++i) {\n        if (min_even_arr[i] < min_even) {\n            min_even = min_even_arr[i];\n            min_index = min_index_arr[i];\n        }\n    }\n\n    if (min_index == -1) return {};\n    return {min_even, min_index};\n}\n```"}
{"task_id": "SimdBench_94_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <limits.h>\n\nstd::vector<int> pluck_simd(std::vector<int> arr) {\n    if (arr.empty()) return {};\n\n    int n = arr.size();\n    int min_even = INT_MAX;\n    int min_index = -1;\n\n    __m128i min_even_vec = _mm_set1_epi32(INT_MAX);\n    __m128i min_index_vec = _mm_set1_epi32(-1);\n    __m128i even_mask = _mm_set1_epi32(1);\n\n    for (int i = 0; i < n; i += 4) {\n        __m128i values = _mm_loadu_si128((__m128i*)&arr[i]);\n        __m128i indices = _mm_setr_epi32(i, i + 1, i + 2, i + 3);\n\n        __m128i is_even = _mm_and_si128(values, even_mask);\n        is_even = _mm_cmpeq_epi32(is_even, _mm_setzero_si128());\n\n        __m128i even_values = _mm_and_si128(values, is_even);\n        __m128i even_indices = _mm_and_si128(indices, is_even);\n\n        __m128i cmp = _mm_cmplt_epi32(even_values, min_even_vec);\n        min_even_vec = _mm_min_epi32(min_even_vec, _mm_and_si128(cmp, even_values));\n        min_index_vec = _mm_min_epi32(min_index_vec, _mm_and_si128(cmp, even_indices));\n    }\n\n    int min_even_arr[4];\n    int min_index_arr[4];\n    _mm_storeu_si128((__m128i*)min_even_arr, min_even_vec);\n    _mm_storeu_si128((__m128i*)min_index_arr, min_index_vec);\n\n    for (int i = 0; i < 4; ++i) {\n        if (min_even_arr[i] < min_even) {\n            min_even = min_even_arr[i];\n            min_index = min_index_arr[i];\n        }\n    }\n\n    if (min_index == -1) return {};\n    return {min_even, min_index};\n}\n```"}
{"task_id": "SimdBench_94_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <limits.h>\n\nstd::vector<int> pluck_simd(std::vector<int> arr) {\n    if (arr.empty()) return {};\n\n    int n = arr.size();\n    int min_even = INT_MAX;\n    int min_index = -1;\n\n    __m128i min_even_vec = _mm_set1_epi32(INT_MAX);\n    __m128i min_index_vec = _mm_set1_epi32(-1);\n    __m128i even_mask = _mm_set1_epi32(1);\n\n    for (int i = 0; i < n; i += 4) {\n        __m128i values = _mm_loadu_si128((__m128i*)&arr[i]);\n        __m128i indices = _mm_set_epi32(i + 3, i + 2, i + 1, i);\n\n        __m128i is_even = _mm_and_si128(values, even_mask);\n        is_even = _mm_cmpeq_epi32(is_even, _mm_setzero_si128());\n\n        __m128i even_values = _mm_and_si128(values, is_even);\n        __m128i even_indices = _mm_and_si128(indices, is_even);\n\n        __m128i cmp = _mm_cmplt_epi32(even_values, min_even_vec);\n        min_even_vec = _mm_min_epi32(min_even_vec, _mm_and_si128(cmp, even_values));\n        min_index_vec = _mm_min_epi32(min_index_vec, _mm_and_si128(cmp, even_indices));\n    }\n\n    int* min_even_ptr = (int*)&min_even_vec;\n    int* min_index_ptr = (int*)&min_index_vec;\n\n    for (int i = 0; i < 4; ++i) {\n        if (min_even_ptr[i] < min_even) {\n            min_even = min_even_ptr[i];\n            min_index = min_index_ptr[i];\n        }\n    }\n\n    if (min_index == -1) return {};\n    return {min_even, min_index};\n}\n```"}
{"task_id": "SimdBench_95_SSE", "completion": "```c++\nint search_simd(std::vector<int> lst) {\n    const int size = lst.size();\n    const int block_size = 4; // SSE operates on 4 integers at a time\n    int max_freq = -1;\n\n    // Create a frequency array\n    std::vector<int> freq(1000001, 0); // Assuming the maximum value in the list is 1000000\n\n    // Calculate frequencies using SSE\n    for (int i = 0; i < size; i += block_size) {\n        __m128i v = _mm_loadu_si128((__m128i*)&lst[i]);\n        __m128i mask = _mm_cmpgt_epi32(v, _mm_setzero_si128());\n        v = _mm_and_si128(v, mask);\n\n        for (int j = 0; j < block_size; ++j) {\n            int val = _mm_extract_epi32(v, j);\n            if (val > 0) {\n                freq[val]++;\n            }\n        }\n    }\n\n    // Find the greatest integer with frequency >= value\n    for (int i = size; i > 0; --i) {\n        if (freq[i] >= i) {\n            max_freq = i;\n            break;\n        }\n    }\n\n    return max_freq;\n}\n```"}
{"task_id": "SimdBench_95_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n\nint search_simd(std::vector<int> lst) {\n    if (lst.empty()) return -1;\n\n    std::sort(lst.begin(), lst.end());\n    int max_val = lst.back();\n    std::vector<int> freq(max_val + 1, 0);\n\n    for (size_t i = 0; i < lst.size(); ++i) {\n        ++freq[lst[i]];\n    }\n\n    __m128i max_freq = _mm_set1_epi32(0);\n    __m128i indices = _mm_set_epi32(3, 2, 1, 0);\n\n    for (int i = 1; i <= max_val; i += 4) {\n        __m128i freqs = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&freq[i]));\n        __m128i vals = _mm_add_epi32(indices, _mm_set1_epi32(i));\n        __m128i mask = _mm_cmpgt_epi32(freqs, vals);\n        max_freq = _mm_max_epi32(max_freq, _mm_and_si128(mask, vals));\n    }\n\n    int result = _mm_cvtsi128_si32(max_freq);\n    return result > 0 ? result : -1;\n}\n```"}
{"task_id": "SimdBench_95_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n\nint search_simd(std::vector<int> lst) {\n    if (lst.empty()) return -1;\n\n    std::sort(lst.begin(), lst.end());\n    int max_val = lst.back();\n    int n = lst.size();\n\n    __m128i freq = _mm_setzero_si128();\n    __m128i count = _mm_setzero_si128();\n    __m128i ones = _mm_set1_epi32(1);\n\n    for (int i = 0; i < n; i += 4) {\n        __m128i current = _mm_loadu_si128((__m128i*)&lst[i]);\n        __m128i mask = _mm_cmpeq_epi32(current, _mm_set1_epi32(lst[i]));\n        count = _mm_add_epi32(count, mask);\n    }\n\n    int max_freq = 0;\n    for (int i = 0; i < 4; ++i) {\n        max_freq = std::max(max_freq, ((int*)&count)[i]);\n    }\n\n    for (int val = max_val; val > 0; --val) {\n        int freq = 0;\n        for (int i = 0; i < n; i += 4) {\n            __m128i current = _mm_loadu_si128((__m128i*)&lst[i]);\n            __m128i mask = _mm_cmpeq_epi32(current, _mm_set1_epi32(val));\n            freq += _mm_movemask_epi8(_mm_packs_epi16(_mm_packs_epi32(mask, mask), _mm_setzero_si128()));\n        }\n        if (freq >= val) return val;\n    }\n\n    return -1;\n}\n```"}
{"task_id": "SimdBench_95_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n\nint search_simd(std::vector<int> lst) {\n    if (lst.empty()) return -1;\n\n    std::sort(lst.begin(), lst.end());\n    int max_val = lst.back();\n    std::vector<int> freq(max_val + 1, 0);\n\n    for (int i = 0; i < lst.size(); ++i) {\n        freq[lst[i]]++;\n    }\n\n    __m128i max_freq = _mm_setzero_si128();\n    __m128i indices = _mm_set_epi32(12, 8, 4, 0);\n\n    for (int i = 0; i <= max_val; i += 4) {\n        __m128i freqs = _mm_loadu_si128((__m128i*)&freq[i]);\n        __m128i vals = _mm_add_epi32(indices, _mm_set1_epi32(i));\n        __m128i mask = _mm_cmpgt_epi32(freqs, vals);\n        __m128i result = _mm_and_si128(mask, freqs);\n        max_freq = _mm_max_epi32(max_freq, result);\n    }\n\n    int max_freq_scalar[4];\n    _mm_storeu_si128((__m128i*)max_freq_scalar, max_freq);\n    int max_freq_val = *std::max_element(max_freq_scalar, max_freq_scalar + 4);\n\n    for (int i = max_freq_val; i > 0; --i) {\n        if (freq[i] >= i) {\n            return i;\n        }\n    }\n\n    return -1;\n}\n```"}
{"task_id": "SimdBench_95_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n\nint search_simd(std::vector<int> lst) {\n    if (lst.empty()) return -1;\n\n    std::sort(lst.begin(), lst.end());\n    int max_val = lst.back();\n    std::vector<int> freq(max_val + 1, 0);\n\n    for (size_t i = 0; i < lst.size(); ++i) {\n        ++freq[lst[i]];\n    }\n\n    __m128i max_freq = _mm_set1_epi32(0);\n    __m128i indices = _mm_set_epi32(3, 2, 1, 0);\n\n    for (int i = 1; i <= max_val; i += 4) {\n        __m128i freqs = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&freq[i]));\n        __m128i cmp = _mm_cmpgt_epi32(freqs, indices);\n        __m128i mask = _mm_and_si128(cmp, _mm_set1_epi32(1));\n        max_freq = _mm_max_epi32(max_freq, _mm_and_si128(mask, indices));\n        indices = _mm_add_epi32(indices, _mm_set1_epi32(4));\n    }\n\n    int result = _mm_cvtsi128_si32(max_freq);\n    return result > 0 && result <= max_val && freq[result] >= result ? result : -1;\n}\n```"}
{"task_id": "SimdBench_96_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nbool will_it_fly_simd(std::vector<int> q, int w) {\n    int n = q.size();\n    if (n == 0) return false;\n\n    bool is_palindrome = true;\n    for (int i = 0; i < n / 2; ++i) {\n        if (q[i] != q[n - i - 1]) {\n            is_palindrome = false;\n            break;\n        }\n    }\n\n    if (!is_palindrome) return false;\n\n    __m128i sum = _mm_setzero_si128();\n    int i = 0;\n    for (; i <= n - 4; i += 4) {\n        __m128i v = _mm_loadu_si128((__m128i*)&q[i]);\n        sum = _mm_add_epi32(sum, v);\n    }\n\n    int temp[4];\n    _mm_storeu_si128((__m128i*)temp, sum);\n    int total_sum = temp[0] + temp[1] + temp[2] + temp[3];\n\n    for (; i < n; ++i) {\n        total_sum += q[i];\n    }\n\n    return total_sum <= w;\n}\n```"}
{"task_id": "SimdBench_96_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nbool will_it_fly_simd(std::vector<int> q, int w) {\n    int n = q.size();\n    if (n == 0) return false;\n\n    bool is_palindrome = true;\n    for (int i = 0; i < n / 2; ++i) {\n        if (q[i] != q[n - i - 1]) {\n            is_palindrome = false;\n            break;\n        }\n    }\n\n    if (!is_palindrome) return false;\n\n    __m128i sum = _mm_setzero_si128();\n    int i = 0;\n    for (; i <= n - 4; i += 4) {\n        __m128i v = _mm_loadu_si128((__m128i*)&q[i]);\n        sum = _mm_add_epi32(sum, v);\n    }\n\n    int temp[4];\n    _mm_storeu_si128((__m128i*)temp, sum);\n    int total_sum = temp[0] + temp[1] + temp[2] + temp[3];\n\n    for (; i < n; ++i) {\n        total_sum += q[i];\n    }\n\n    return total_sum <= w;\n}\n```"}
{"task_id": "SimdBench_96_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nbool will_it_fly_simd(std::vector<int> q, int w) {\n    int n = q.size();\n    if (n == 0) return false;\n\n    bool is_palindrome = true;\n    for (int i = 0; i < n / 2; ++i) {\n        if (q[i] != q[n - i - 1]) {\n            is_palindrome = false;\n            break;\n        }\n    }\n\n    if (!is_palindrome) return false;\n\n    __m128i sum = _mm_setzero_si128();\n    int i = 0;\n    for (; i <= n - 4; i += 4) {\n        __m128i v = _mm_loadu_si128((__m128i*)&q[i]);\n        sum = _mm_add_epi32(sum, v);\n    }\n\n    int temp[4];\n    _mm_storeu_si128((__m128i*)temp, sum);\n    int total_sum = temp[0] + temp[1] + temp[2] + temp[3];\n\n    for (; i < n; ++i) {\n        total_sum += q[i];\n    }\n\n    return total_sum <= w;\n}\n```"}
{"task_id": "SimdBench_96_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nbool will_it_fly_simd(std::vector<int> q, int w) {\n    int n = q.size();\n    if (n == 0) return false;\n\n    bool is_palindrome = true;\n    for (int i = 0; i < n / 2; ++i) {\n        if (q[i] != q[n - i - 1]) {\n            is_palindrome = false;\n            break;\n        }\n    }\n\n    if (!is_palindrome) return false;\n\n    __m128i sum = _mm_setzero_si128();\n    int i = 0;\n    for (; i <= n - 4; i += 4) {\n        __m128i v = _mm_loadu_si128((__m128i*)&q[i]);\n        sum = _mm_add_epi32(sum, v);\n    }\n\n    int temp[4];\n    _mm_storeu_si128((__m128i*)temp, sum);\n    int total_sum = temp[0] + temp[1] + temp[2] + temp[3];\n\n    for (; i < n; ++i) {\n        total_sum += q[i];\n    }\n\n    return total_sum <= w;\n}\n```"}
{"task_id": "SimdBench_96_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nbool will_it_fly_simd(std::vector<int> q, int w) {\n    int n = q.size();\n    if (n == 0) return false;\n\n    // Check if the vector is a palindrome\n    bool is_palindrome = true;\n    for (int i = 0; i < n / 2; ++i) {\n        if (q[i] != q[n - i - 1]) {\n            is_palindrome = false;\n            break;\n        }\n    }\n    if (!is_palindrome) return false;\n\n    // Calculate the sum using SSE2 intrinsics\n    __m128i sum = _mm_setzero_si128();\n    int i = 0;\n    for (; i <= n - 4; i += 4) {\n        __m128i v = _mm_loadu_si128((__m128i*)&q[i]);\n        sum = _mm_add_epi32(sum, v);\n    }\n\n    // Horizontal sum of the vector\n    sum = _mm_add_epi32(sum, _mm_shuffle_epi32(sum, _MM_SHUFFLE(2, 3, 0, 1)));\n    sum = _mm_add_epi32(sum, _mm_shuffle_epi32(sum, _MM_SHUFFLE(0, 1, 2, 3)));\n\n    int total_sum = _mm_cvtsi128_si32(sum);\n\n    // Add remaining elements\n    for (; i < n; ++i) {\n        total_sum += q[i];\n    }\n\n    return total_sum <= w;\n}\n```"}
{"task_id": "SimdBench_97_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint smallest_change_simd(std::vector<int> arr) {\n    int n = arr.size();\n    int changes = 0;\n    int i = 0;\n\n    for (; i <= n - 1 - i; i++) {\n        if (arr[i] != arr[n - 1 - i]) {\n            changes++;\n        }\n    }\n\n    return changes;\n}\n```"}
{"task_id": "SimdBench_97_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint smallest_change_simd(std::vector<int> arr) {\n    int n = arr.size();\n    int changes = 0;\n    int i = 0;\n\n    for (; i <= n - 1 - i; i++) {\n        if (arr[i] != arr[n - 1 - i]) {\n            changes++;\n        }\n    }\n\n    return changes;\n}\n```"}
{"task_id": "SimdBench_97_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint smallest_change_simd(std::vector<int> arr) {\n    int n = arr.size();\n    int changes = 0;\n    int i = 0;\n\n    for (; i <= n - i - 4; i += 4) {\n        __m128i left = _mm_loadu_si128((__m128i*)&arr[i]);\n        __m128i right = _mm_loadu_si128((__m128i*)&arr[n - i - 4]);\n\n        __m128i cmp = _mm_cmpeq_epi32(left, right);\n        int mask = _mm_movemask_epi8(cmp);\n\n        changes += _mm_popcnt_u32(~mask & 0x11111111);\n    }\n\n    for (; i < n / 2; ++i) {\n        if (arr[i] != arr[n - i - 1]) {\n            ++changes;\n        }\n    }\n\n    return changes;\n}\n```"}
{"task_id": "SimdBench_97_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint smallest_change_simd(std::vector<int> arr) {\n    int n = arr.size();\n    int changes = 0;\n    int i = 0;\n\n    for (; i <= n - i - 4; i += 4) {\n        __m128i left = _mm_loadu_si128((__m128i*)&arr[i]);\n        __m128i right = _mm_loadu_si128((__m128i*)&arr[n - i - 4]);\n\n        __m128i cmp = _mm_cmpeq_epi32(left, right);\n        int mask = _mm_movemask_epi8(cmp);\n\n        changes += _mm_popcnt_u32(~mask & 0x11111111);\n    }\n\n    for (; i < n / 2; ++i) {\n        if (arr[i] != arr[n - i - 1]) {\n            ++changes;\n        }\n    }\n\n    return changes;\n}\n```"}
{"task_id": "SimdBench_97_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint smallest_change_simd(std::vector<int> arr) {\n    int n = arr.size();\n    int changes = 0;\n\n    for (int i = 0; i < n / 2; i++) {\n        __m128i a = _mm_loadu_si128((__m128i*)&arr[i]);\n        __m128i b = _mm_loadu_si128((__m128i*)&arr[n - i - 4]);\n\n        __m128i cmp = _mm_cmpeq_epi32(a, b);\n        int mask = _mm_movemask_epi8(cmp);\n\n        changes += __builtin_popcount(~mask & 0xFFFF);\n    }\n\n    if (n % 2 == 1) {\n        changes += (arr[n / 2] != arr[n / 2]);\n    }\n\n    return changes;\n}\n```"}
{"task_id": "SimdBench_98_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n\nstd::vector<std::string> total_match_simd(const std::vector<std::string> & lst1, const std::vector<std::string> & lst2) {\n    int total1 = 0, total2 = 0;\n\n    for (const auto& str : lst1) {\n        total1 += str.size();\n    }\n\n    for (const auto& str : lst2) {\n        total2 += str.size();\n    }\n\n    if (total1 < total2) {\n        return lst1;\n    } else {\n        return lst2;\n    }\n}\n```"}
{"task_id": "SimdBench_98_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n\nstd::vector<std::string> total_match_simd(const std::vector<std::string> & lst1, const std::vector<std::string> & lst2) {\n    int total1 = 0, total2 = 0;\n\n    for (const auto& str : lst1) {\n        total1 += str.size();\n    }\n\n    for (const auto& str : lst2) {\n        total2 += str.size();\n    }\n\n    if (total1 < total2) {\n        return lst1;\n    } else {\n        return lst2;\n    }\n}\n```"}
{"task_id": "SimdBench_98_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n\nstd::vector<std::string> total_match_simd(const std::vector<std::string> & lst1, const std::vector<std::string> & lst2) {\n    int total1 = 0, total2 = 0;\n\n    for (const auto& str : lst1) {\n        total1 += str.size();\n    }\n\n    for (const auto& str : lst2) {\n        total2 += str.size();\n    }\n\n    if (total1 < total2) {\n        return lst1;\n    } else {\n        return lst2;\n    }\n}\n```"}
{"task_id": "SimdBench_98_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n\nstd::vector<std::string> total_match_simd(const std::vector<std::string> & lst1, const std::vector<std::string> & lst2) {\n    int sum1 = 0, sum2 = 0;\n\n    for (const auto& str : lst1) {\n        sum1 += str.size();\n    }\n\n    for (const auto& str : lst2) {\n        sum2 += str.size();\n    }\n\n    return (sum1 <= sum2) ? lst1 : lst2;\n}\n```"}
{"task_id": "SimdBench_98_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n\nstd::vector<std::string> total_match_simd(const std::vector<std::string> & lst1, const std::vector<std::string> & lst2) {\n    int total1 = 0, total2 = 0;\n\n    for (const auto& str : lst1) {\n        total1 += str.size();\n    }\n\n    for (const auto& str : lst2) {\n        total2 += str.size();\n    }\n\n    if (total1 <= total2) {\n        return lst1;\n    } else {\n        return lst2;\n    }\n}\n```"}
{"task_id": "SimdBench_99_SSE", "completion": "```c\nbool is_simple_power_simd(uint64_t x, uint64_t n) {\n    if (n == 1) return x == 1;\n    if (n == 0) return x == 1;\n    if (x == 0) return false;\n\n    __m128i vx = _mm_set1_epi64x(x);\n    __m128i vn = _mm_set1_epi64x(n);\n    __m128i vpow = _mm_set1_epi64x(1);\n\n    while (_mm_movemask_epi8(_mm_cmpeq_epi64(vpow, vx)) == 0) {\n        vpow = _mm_mul_epu32(vpow, vn);\n        if (_mm_movemask_epi8(_mm_cmpgt_epi64(vpow, vx)) != 0) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_99_SSE", "completion": "```cpp\nbool is_simple_power_simd(uint64_t x, uint64_t n) {\n    if (n == 1) return x == 1;\n    if (n == 0) return x == 1;\n    if (x == 0) return n == 1;\n    if (x == 1) return true;\n\n    __m128i vx = _mm_set1_epi64x(x);\n    __m128i vn = _mm_set1_epi64x(n);\n    __m128i ones = _mm_set1_epi64x(1);\n    __m128i zero = _mm_setzero_si128();\n\n    while (_mm_movemask_epi8(_mm_cmpeq_epi64(vx, ones)) == 0) {\n        __m128i rem = _mm_and_si128(vx, _mm_set1_epi64x(1));\n        if (_mm_movemask_epi8(_mm_cmpeq_epi64(rem, zero)) != 0) return false;\n        vx = _mm_div_epu64(vx, vn);\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_99_SSE", "completion": "```c\nbool is_simple_power_simd(uint64_t x, uint64_t n) {\n    if (n == 1) return x == 1;\n    if (n == 0) return x == 1;\n    if (x == 0) return n == 1;\n    if (x == 1) return true;\n\n    __m128i vx = _mm_set1_epi64x(x);\n    __m128i vn = _mm_set1_epi64x(n);\n    __m128i vpow = _mm_set1_epi64x(1);\n\n    while (_mm_movemask_epi8(_mm_cmpeq_epi64(vpow, vx)) == 0) {\n        vpow = _mm_mul_epu32(vpow, vn);\n        if (_mm_movemask_epi8(_mm_cmpgt_epi64(vpow, vx)) != 0) return false;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_99_SSE", "completion": "```c\nbool is_simple_power_simd(uint64_t x, uint64_t n) {\n    if (n == 1) return x == 1;\n    if (n == 0) return x == 1;\n    if (x == 0) return false;\n    if (x == 1) return true;\n\n    __m128i vx = _mm_set1_epi64x(x);\n    __m128i vn = _mm_set1_epi64x(n);\n    __m128i vpow = _mm_set1_epi64x(1);\n\n    while (_mm_movemask_epi8(_mm_cmpeq_epi64(vpow, vx)) == 0) {\n        vpow = _mm_mul_epu32(vpow, vn);\n        if (_mm_movemask_epi8(_mm_cmpeq_epi64(vpow, vx)) != 0) return true;\n        if (_mm_movemask_epi8(_mm_cmpgt_epi64(vpow, vx)) != 0) return false;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_99_SSE", "completion": "```cpp\nbool is_simple_power_simd(uint64_t x, uint64_t n) {\n    if (n == 1) return x == 1;\n    if (n == 0) return x == 1;\n    if (x == 0) return n == 1;\n    if (x == 1) return true;\n\n    __m128i vx = _mm_set1_epi64x(x);\n    __m128i vn = _mm_set1_epi64x(n);\n    __m128i ones = _mm_set1_epi64x(1);\n    __m128i zero = _mm_setzero_si128();\n\n    while (_mm_movemask_epi8(_mm_cmpeq_epi64(vx, ones)) == 0) {\n        __m128i rem = _mm_and_si128(vx, _mm_set1_epi64x(1));\n        if (_mm_movemask_epi8(_mm_cmpeq_epi64(rem, zero)) != 0) return false;\n        vx = _mm_div_epu64(vx, vn);\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_100_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nint hex_key_simd(const std::string & num) {\n    const __m128i prime_mask = _mm_setr_epi8(0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0);\n    const __m128i hex_to_dec = _mm_setr_epi8(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 0, 0, 0, 0, 0);\n    const __m128i offset = _mm_set1_epi8('0');\n    const __m128i offset_A = _mm_set1_epi8('A' - 10);\n\n    int count = 0;\n    int len = num.size();\n    int i = 0;\n\n    for (; i <= len - 16; i += 16) {\n        __m128i input = _mm_loadu_si128(reinterpret_cast<const __m128i*>(num.data() + i));\n        __m128i dec_values = _mm_sub_epi8(input, offset);\n        __m128i is_letter = _mm_cmpgt_epi8(dec_values, _mm_set1_epi8(9));\n        __m128i letter_values = _mm_sub_epi8(input, offset_A);\n        __m128i values = _mm_blendv_epi8(dec_values, letter_values, is_letter);\n        __m128i is_prime = _mm_and_si128(_mm_cmplt_epi8(values, _mm_set1_epi8(16)), prime_mask);\n        count += _mm_popcnt_u32(_mm_movemask_epi8(is_prime));\n    }\n\n    for (; i < len; ++i) {\n        char c = num[i];\n        int value = (c >= 'A') ? (c - 'A' + 10) : (c - '0');\n        if (value < 16 && (prime_mask.m128i_u8[value] & 1)) {\n            ++count;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_100_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nint hex_key_simd(const std::string & num) {\n    const __m128i prime_mask = _mm_set_epi8(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n    const __m128i prime_digits = _mm_set_epi8('2', '3', '5', '7', 'B', 'D', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n\n    int count = 0;\n    int length = num.size();\n    int i = 0;\n\n    for (; i <= length - 16; i += 16) {\n        __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&num[i]));\n        __m128i cmp = _mm_cmpeq_epi8(chunk, prime_digits);\n        __m128i result = _mm_and_si128(cmp, prime_mask);\n        count += _mm_movemask_epi8(result);\n    }\n\n    for (; i < length; ++i) {\n        if (num[i] == '2' || num[i] == '3' || num[i] == '5' || num[i] == '7' || num[i] == 'B' || num[i] == 'D') {\n            ++count;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_100_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nint hex_key_simd(const std::string & num) {\n    const __m128i prime_mask = _mm_set_epi8(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n    const __m128i prime_digits = _mm_set_epi8('2', '3', '5', '7', 'B', 'D', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n\n    int count = 0;\n    int length = num.size();\n    int i = 0;\n\n    for (; i <= length - 16; i += 16) {\n        __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&num[i]));\n        __m128i cmp = _mm_cmpeq_epi8(chunk, prime_digits);\n        __m128i result = _mm_and_si128(cmp, prime_mask);\n        count += _mm_movemask_epi8(result);\n    }\n\n    for (; i < length; ++i) {\n        if (num[i] == '2' || num[i] == '3' || num[i] == '5' || num[i] == '7' || num[i] == 'B' || num[i] == 'D') {\n            ++count;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_100_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nint hex_key_simd(const std::string & num) {\n    const __m128i prime_mask = _mm_setr_epi8(\n        0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1\n    );\n\n    int count = 0;\n    int length = num.size();\n    int i = 0;\n\n    for (; i <= length - 16; i += 16) {\n        __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&num[i]));\n        __m128i ascii_mask = _mm_set1_epi8(0x0F);\n        __m128i hex_digits = _mm_and_si128(chunk, ascii_mask);\n        __m128i shifted_hex_digits = _mm_srli_epi64(hex_digits, 4);\n        __m128i combined_hex_digits = _mm_or_si128(hex_digits, shifted_hex_digits);\n        __m128i prime_check = _mm_shuffle_epi8(prime_mask, combined_hex_digits);\n        count += _mm_movemask_epi8(prime_check);\n    }\n\n    for (; i < length; ++i) {\n        char digit = num[i];\n        if (digit >= '0' && digit <= '9') {\n            digit -= '0';\n        } else {\n            digit -= 'A' - 10;\n        }\n        if (digit == 2 || digit == 3 || digit == 5 || digit == 7 ||\n            digit == 11 || digit == 13) {\n            count++;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_100_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nint hex_key_simd(const std::string & num) {\n    const __m128i prime_mask = _mm_set_epi8(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n    const __m128i prime_digits = _mm_set_epi8('2', '3', '5', '7', 'B', 'D', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n\n    int count = 0;\n    int length = num.length();\n    int i = 0;\n\n    for (; i <= length - 16; i += 16) {\n        __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&num[i]));\n        __m128i cmp = _mm_cmpeq_epi8(chunk, prime_digits);\n        __m128i result = _mm_and_si128(cmp, prime_mask);\n        count += _mm_movemask_epi8(result);\n    }\n\n    for (; i < length; ++i) {\n        if (num[i] == '2' || num[i] == '3' || num[i] == '5' || num[i] == '7' || num[i] == 'B' || num[i] == 'D') {\n            ++count;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_101_SSE", "completion": "```cpp\nbool is_happy_simd(const std::string & s) {\n    if (s.length() < 3) {\n        return false;\n    }\n\n    const size_t len = s.length();\n    const size_t aligned_len = len & ~3;\n\n    for (size_t i = 0; i < aligned_len; i += 4) {\n        __m128i v1 = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&s[i]));\n        __m128i v2 = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&s[i + 1]));\n        __m128i v3 = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&s[i + 2]));\n\n        __m128i cmp1 = _mm_cmpeq_epi8(v1, v2);\n        __m128i cmp2 = _mm_cmpeq_epi8(v1, v3);\n        __m128i cmp3 = _mm_cmpeq_epi8(v2, v3);\n\n        __m128i or1 = _mm_or_si128(cmp1, cmp2);\n        __m128i or2 = _mm_or_si128(or1, cmp3);\n\n        if (_mm_movemask_epi8(or2) != 0) {\n            return false;\n        }\n    }\n\n    for (size_t i = aligned_len; i < len - 2; ++i) {\n        if (s[i] == s[i + 1] || s[i] == s[i + 2] || s[i + 1] == s[i + 2]) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_101_SSE", "completion": "```cpp\nbool is_happy_simd(const std::string & s) {\n    if (s.length() < 3) {\n        return false;\n    }\n\n    const char* data = s.data();\n    size_t len = s.length();\n\n    for (size_t i = 0; i <= len - 3; i += 4) {\n        __m128i chunk = _mm_loadu_si128((__m128i*)&data[i]);\n\n        __m128i a = _mm_shuffle_epi8(chunk, _mm_set_epi8(15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 0));\n        __m128i b = _mm_shuffle_epi8(chunk, _mm_set_epi8(15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 0));\n        __m128i c = _mm_shuffle_epi8(chunk, _mm_set_epi8(15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 0));\n\n        a = _mm_slli_si128(a, 1);\n        b = _mm_slli_si128(b, 2);\n        c = _mm_slli_si128(c, 3);\n\n        __m128i mask = _mm_cmpeq_epi8(a, b);\n        mask = _mm_or_si128(mask, _mm_cmpeq_epi8(a, c));\n        mask = _mm_or_si128(mask, _mm_cmpeq_epi8(b, c));\n\n        if (_mm_movemask_epi8(mask) != 0) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_101_SSE", "completion": "```cpp\nbool is_happy_simd(const std::string & s) {\n    if (s.length() < 3) {\n        return false;\n    }\n\n    const size_t len = s.length();\n    const size_t vec_size = 16; // SSE registers are 128 bits (16 bytes)\n\n    for (size_t i = 0; i < len - 2; i += vec_size) {\n        __m128i vec1 = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&s[i]));\n        __m128i vec2 = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&s[i + 1]));\n        __m128i vec3 = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&s[i + 2]));\n\n        __m128i cmp1 = _mm_cmpeq_epi8(vec1, vec2);\n        __m128i cmp2 = _mm_cmpeq_epi8(vec1, vec3);\n        __m128i cmp3 = _mm_cmpeq_epi8(vec2, vec3);\n\n        __m128i or1 = _mm_or_si128(cmp1, cmp2);\n        __m128i or2 = _mm_or_si128(or1, cmp3);\n\n        int mask = _mm_movemask_epi8(or2);\n        if (mask != 0) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_101_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nbool is_happy_simd(const std::string & s) {\n    if (s.length() < 3) {\n        return false;\n    }\n\n    const char* data = s.c_str();\n    size_t len = s.length();\n    size_t i = 0;\n\n    while (i + 3 < len) {\n        __m128i v1 = _mm_loadu_si128((__m128i*)&data[i]);\n        __m128i v2 = _mm_loadu_si128((__m128i*)&data[i + 1]);\n        __m128i v3 = _mm_loadu_si128((__m128i*)&data[i + 2]);\n\n        __m128i cmp1 = _mm_cmpeq_epi8(v1, v2);\n        __m128i cmp2 = _mm_cmpeq_epi8(v1, v3);\n        __m128i cmp3 = _mm_cmpeq_epi8(v2, v3);\n\n        __m128i result = _mm_or_si128(_mm_or_si128(cmp1, cmp2), cmp3);\n        int mask = _mm_movemask_epi8(result);\n\n        if (mask != 0) {\n            return false;\n        }\n\n        i += 4;\n    }\n\n    for (; i + 2 < len; ++i) {\n        if (s[i] == s[i + 1] || s[i] == s[i + 2] || s[i + 1] == s[i + 2]) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_101_SSE", "completion": "```cpp\nbool is_happy_simd(const std::string & s) {\n    if (s.length() < 3) {\n        return false;\n    }\n\n    const size_t len = s.length();\n    const size_t simd_len = len - 2;\n\n    for (size_t i = 0; i < simd_len; i += 4) {\n        __m128i v1 = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&s[i]));\n        __m128i v2 = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&s[i + 1]));\n        __m128i v3 = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&s[i + 2]));\n\n        __m128i cmp1 = _mm_cmpeq_epi8(v1, v2);\n        __m128i cmp2 = _mm_cmpeq_epi8(v1, v3);\n        __m128i cmp3 = _mm_cmpeq_epi8(v2, v3);\n\n        __m128i or_result = _mm_or_si128(cmp1, cmp2);\n        or_result = _mm_or_si128(or_result, cmp3);\n\n        if (_mm_movemask_epi8(or_result) != 0) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_102_SSE", "completion": "```cpp\nbool prime_length_simd(const std::string & str) {\n    int length = str.length();\n    if (length < 2) return false;\n\n    __m128i length_vec = _mm_set1_epi32(length);\n    __m128i div_vec = _mm_set_epi32(1, 2, 3, 4);\n    __m128i mod_vec = _mm_set1_epi32(0);\n\n    for (int i = 2; i * i <= length; ++i) {\n        __m128i i_vec = _mm_set1_epi32(i);\n        __m128i div_result = _mm_div_epi32(length_vec, i_vec);\n        __m128i mod_result = _mm_sub_epi32(length_vec, _mm_mullo_epi32(div_result, i_vec));\n\n        mod_vec = _mm_or_si128(mod_vec, mod_result);\n    }\n\n    int mod_result = _mm_movemask_epi8(mod_vec);\n    return mod_result == 0;\n}\n```"}
{"task_id": "SimdBench_102_SSE", "completion": "```cpp\nbool prime_length_simd(const std::string & str) {\n    int len = str.length();\n    if (len < 2) return false;\n\n    __m128i len_vec = _mm_set1_epi32(len);\n    __m128i div_vec = _mm_set_epi32(1, 2, 3, 4);\n    __m128i mod_vec = _mm_set1_epi32(0);\n\n    for (int i = 2; i * i <= len; ++i) {\n        __m128i i_vec = _mm_set1_epi32(i);\n        __m128i quotient = _mm_div_epi32(len_vec, i_vec);\n        __m128i product = _mm_mullo_epi32(quotient, i_vec);\n        mod_vec = _mm_sub_epi32(len_vec, product);\n\n        int mod = _mm_cvtsi128_si32(mod_vec);\n        if (mod == 0) return false;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_102_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nbool prime_length_simd(const std::string & str) {\n    int length = str.length();\n    if (length < 2) return false;\n\n    __m128i length_vec = _mm_set1_epi32(length);\n    __m128i div_vec = _mm_set_epi32(7, 5, 3, 2);\n    __m128i mod_vec = _mm_setzero_si128();\n\n    mod_vec = _mm_cvtepi32_ps(_mm_div_epi32(length_vec, div_vec));\n    mod_vec = _mm_cvttps_epi32(mod_vec);\n\n    __m128i zero_vec = _mm_setzero_si128();\n    __m128i cmp_vec = _mm_cmpeq_epi32(mod_vec, zero_vec);\n\n    int mask = _mm_movemask_epi8(cmp_vec);\n    return mask == 0;\n}\n```"}
{"task_id": "SimdBench_102_SSE", "completion": "```cpp\nbool prime_length_simd(const std::string & str) {\n    int len = str.length();\n    if (len < 2) return false;\n\n    __m128i len_vec = _mm_set1_epi32(len);\n    __m128i div_vec = _mm_set_epi32(2, 3, 4, 5);\n    __m128i mod_vec = _mm_set1_epi32(1);\n\n    __m128i result = _mm_cmpeq_epi32(_mm_mod_epi32(len_vec, div_vec), mod_vec);\n\n    int mask = _mm_movemask_epi8(result);\n    return mask == 0;\n}\n```"}
{"task_id": "SimdBench_102_SSE", "completion": "```cpp\nbool prime_length_simd(const std::string & str) {\n    int length = str.length();\n    if (length < 2) return false;\n\n    __m128i length_vec = _mm_set1_epi32(length);\n    __m128i div_vec = _mm_set_epi32(1, 2, 3, 4);\n    __m128i mod_vec = _mm_set1_epi32(0);\n\n    for (int i = 2; i * i <= length; ++i) {\n        __m128i i_vec = _mm_set1_epi32(i);\n        __m128i div_result = _mm_div_epi32(length_vec, i_vec);\n        __m128i mul_result = _mm_mullo_epi32(div_result, i_vec);\n        mod_vec = _mm_sub_epi32(length_vec, mul_result);\n\n        if (_mm_movemask_epi8(_mm_cmpeq_epi32(mod_vec, _mm_setzero_si128())) != 0) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_103_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string solve_simd(uint64_t N) {\n    __m128i sum = _mm_setzero_si128();\n    __m128i mask = _mm_set1_epi8(0x0F);\n\n    while (N) {\n        __m128i digits = _mm_set1_epi64x(N);\n        digits = _mm_and_si128(digits, mask);\n        sum = _mm_add_epi8(sum, digits);\n        N /= 10;\n    }\n\n    uint8_t temp[16];\n    _mm_storeu_si128((__m128i*)temp, sum);\n\n    uint64_t total_sum = 0;\n    for (int i = 0; i < 16; ++i) {\n        total_sum += temp[i];\n    }\n\n    std::string binary;\n    while (total_sum) {\n        binary = (total_sum % 2 ? \"1\" : \"0\") + binary;\n        total_sum /= 2;\n    }\n\n    return binary.empty() ? \"0\" : binary;\n}\n```"}
{"task_id": "SimdBench_103_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string solve_simd(uint64_t N) {\n    __m128i sum = _mm_setzero_si128();\n    __m128i mask = _mm_set1_epi8(0x0F);\n\n    while (N) {\n        __m128i digits = _mm_set1_epi64x(N);\n        digits = _mm_and_si128(digits, mask);\n        sum = _mm_add_epi8(sum, digits);\n        N >>= 4;\n    }\n\n    uint64_t result = 0;\n    for (int i = 0; i < 16; ++i) {\n        result += ((uint8_t*)&sum)[i];\n    }\n\n    std::string binary;\n    while (result) {\n        binary = (result % 2 ? \"1\" : \"0\") + binary;\n        result /= 2;\n    }\n\n    return binary.empty() ? \"0\" : binary;\n}\n```"}
{"task_id": "SimdBench_103_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string solve_simd(uint64_t N) {\n    __m128i sum = _mm_setzero_si128();\n    __m128i mask = _mm_set1_epi8(0x0F);\n\n    while (N) {\n        __m128i digits = _mm_set1_epi64x(N);\n        __m128i low = _mm_and_si128(digits, mask);\n        __m128i high = _mm_and_si128(_mm_srli_epi64(digits, 4), mask);\n        sum = _mm_add_epi8(sum, low);\n        sum = _mm_add_epi8(sum, high);\n        N >>= 8;\n    }\n\n    uint8_t temp[16];\n    _mm_storeu_si128((__m128i*)temp, sum);\n    uint8_t total_sum = 0;\n    for (int i = 0; i < 16; ++i) {\n        total_sum += temp[i];\n    }\n\n    std::string result;\n    while (total_sum) {\n        result = (total_sum % 2 ? \"1\" : \"0\") + result;\n        total_sum /= 2;\n    }\n\n    return result.empty() ? \"0\" : result;\n}\n```"}
{"task_id": "SimdBench_103_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string solve_simd(uint64_t N) {\n    __m128i sum = _mm_setzero_si128();\n    __m128i mask = _mm_set1_epi8(0x0F);\n\n    while (N) {\n        __m128i digits = _mm_set1_epi64x(N);\n        digits = _mm_and_si128(digits, mask);\n        sum = _mm_add_epi8(sum, digits);\n        N /= 10;\n    }\n\n    uint8_t temp[16];\n    _mm_storeu_si128((__m128i*)temp, sum);\n\n    uint64_t total_sum = 0;\n    for (int i = 0; i < 16; ++i) {\n        total_sum += temp[i];\n    }\n\n    std::string binary_str;\n    while (total_sum) {\n        binary_str = (total_sum % 2 ? \"1\" : \"0\") + binary_str;\n        total_sum /= 2;\n    }\n\n    return binary_str.empty() ? \"0\" : binary_str;\n}\n```"}
{"task_id": "SimdBench_103_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string solve_simd(uint64_t N) {\n    __m128i sum = _mm_setzero_si128();\n    __m128i mask = _mm_set1_epi8(0x0F);\n\n    while (N) {\n        __m128i digits = _mm_set1_epi64x(N);\n        digits = _mm_and_si128(digits, mask);\n        sum = _mm_add_epi8(sum, digits);\n        N /= 10;\n    }\n\n    uint8_t temp[16];\n    _mm_storeu_si128((__m128i*)temp, sum);\n\n    uint64_t total_sum = 0;\n    for (int i = 0; i < 16; ++i) {\n        total_sum += temp[i];\n    }\n\n    std::string binary;\n    while (total_sum) {\n        binary = (total_sum % 2 ? \"1\" : \"0\") + binary;\n        total_sum /= 2;\n    }\n\n    return binary.empty() ? \"0\" : binary;\n}\n```"}
{"task_id": "SimdBench_104_SSE", "completion": "```c++\nint add_simd(std::vector<int> lst) {\n    int sum = 0;\n    __m128i sum_vec = _mm_setzero_si128();\n\n    for (size_t i = 1; i < lst.size(); i += 4) {\n        __m128i vec = _mm_loadu_si128((__m128i*)&lst[i]);\n\n        __m128i even_mask = _mm_set1_epi32(1);\n        __m128i even_elements = _mm_and_si128(vec, even_mask);\n\n        __m128i zero = _mm_setzero_si128();\n        __m128i is_even = _mm_cmpeq_epi32(even_elements, zero);\n\n        __m128i odd_indices = _mm_setr_epi32(0, 1, 0, 1);\n        __m128i odd_mask = _mm_shuffle_epi32(is_even, _MM_SHUFFLE(1, 1, 0, 0));\n        odd_mask = _mm_and_si128(odd_mask, odd_indices);\n\n        __m128i result = _mm_and_si128(vec, odd_mask);\n        sum_vec = _mm_add_epi32(sum_vec, result);\n    }\n\n    int temp[4];\n    _mm_storeu_si128((__m128i*)temp, sum_vec);\n    sum = temp[0] + temp[1] + temp[2] + temp[3];\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_104_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint add_simd(std::vector<int> lst) {\n    int sum = 0;\n    __m128i sum_vec = _mm_setzero_si128();\n\n    for (size_t i = 1; i < lst.size(); i += 4) {\n        __m128i vec = _mm_loadu_si128((__m128i*)&lst[i]);\n        __m128i mask = _mm_setr_epi32(0, 1, 0, 1);\n        __m128i even_mask = _mm_set1_epi32(1);\n        __m128i even_vec = _mm_and_si128(vec, even_mask);\n        __m128i result = _mm_and_si128(even_vec, mask);\n        sum_vec = _mm_add_epi32(sum_vec, result);\n    }\n\n    int temp[4];\n    _mm_storeu_si128((__m128i*)temp, sum_vec);\n    sum = temp[0] + temp[1] + temp[2] + temp[3];\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_104_SSE", "completion": "```c++\nint add_simd(std::vector<int> lst) {\n    int sum = 0;\n    __m128i sum_vec = _mm_setzero_si128();\n\n    for (size_t i = 1; i < lst.size(); i += 4) {\n        __m128i vec = _mm_loadu_si128((__m128i*)&lst[i]);\n        __m128i mask = _mm_set1_epi32(1);\n        __m128i even_mask = _mm_set_epi32(0, -1, 0, -1);\n        __m128i even_vec = _mm_and_si128(vec, even_mask);\n        __m128i odd_indices = _mm_and_si128(mask, _mm_set1_epi32(i % 2));\n        __m128i result = _mm_and_si128(even_vec, odd_indices);\n        sum_vec = _mm_add_epi32(sum_vec, result);\n    }\n\n    int temp[4];\n    _mm_storeu_si128((__m128i*)temp, sum_vec);\n    sum = temp[0] + temp[1] + temp[2] + temp[3];\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_104_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint add_simd(std::vector<int> lst) {\n    int sum = 0;\n    __m128i sum_vec = _mm_setzero_si128();\n\n    for (size_t i = 1; i < lst.size(); i += 4) {\n        __m128i vec = _mm_loadu_si128((__m128i*)&lst[i]);\n        __m128i mask = _mm_setr_epi32(0, 1, 0, 1);\n        __m128i even_mask = _mm_set1_epi32(1);\n        __m128i even_elements = _mm_and_si128(vec, even_mask);\n        __m128i odd_indices = _mm_and_si128(vec, mask);\n        __m128i result = _mm_and_si128(even_elements, odd_indices);\n        sum_vec = _mm_add_epi32(sum_vec, result);\n    }\n\n    alignas(16) int temp[4];\n    _mm_store_si128((__m128i*)temp, sum_vec);\n    sum = temp[0] + temp[1] + temp[2] + temp[3];\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_104_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint add_simd(std::vector<int> lst) {\n    int sum = 0;\n    __m128i sum_vec = _mm_setzero_si128();\n\n    for (size_t i = 1; i < lst.size(); i += 4) {\n        __m128i vec = _mm_loadu_si128((__m128i*)&lst[i]);\n        __m128i mask = _mm_setr_epi32(0, 1, 0, 1);\n        __m128i even_mask = _mm_set1_epi32(1);\n        __m128i odd_mask = _mm_setr_epi32(1, 0, 1, 0);\n\n        __m128i even_elements = _mm_and_si128(vec, even_mask);\n        __m128i odd_elements = _mm_and_si128(vec, odd_mask);\n\n        __m128i even_odd_mask = _mm_and_si128(even_elements, odd_mask);\n        __m128i result = _mm_and_si128(even_odd_mask, mask);\n\n        sum_vec = _mm_add_epi32(sum_vec, result);\n    }\n\n    alignas(16) int temp[4];\n    _mm_store_si128((__m128i*)temp, sum_vec);\n    sum = temp[0] + temp[1] + temp[2] + temp[3];\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_105_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string encrypt_simd(const std::string & s) {\n    std::string result = s;\n    size_t len = s.length();\n\n    for (size_t i = 0; i < len; i += 16) {\n        __m128i input = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&s[i]));\n        __m128i shift = _mm_set1_epi8(4);\n        __m128i encrypted = _mm_add_epi8(input, shift);\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i]), encrypted);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_105_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string encrypt_simd(const std::string & s) {\n    std::string result = s;\n    size_t len = s.length();\n    size_t padded_len = (len + 15) & ~15; // Pad to multiple of 16\n\n    __m128i shift = _mm_set1_epi8(4); // Shift by 4 positions (2 * 2)\n    __m128i mask = _mm_set1_epi8(0xDF); // Mask to convert to uppercase\n\n    for (size_t i = 0; i < padded_len; i += 16) {\n        __m128i input = _mm_loadu_si128(reinterpret_cast<const __m128i*>(s.data() + i));\n        __m128i encrypted = _mm_add_epi8(input, shift);\n        encrypted = _mm_and_si128(encrypted, mask); // Ensure uppercase\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(result.data() + i), encrypted);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_105_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string encrypt_simd(const std::string & s) {\n    std::string result = s;\n    size_t len = s.length();\n    size_t padded_len = (len + 15) & ~15; // Pad to multiple of 16\n\n    __m128i shift = _mm_set1_epi8(4); // Shift by 4 positions (2 * 2)\n    __m128i mask = _mm_set1_epi8(0xDF); // Mask to convert to uppercase\n\n    for (size_t i = 0; i < padded_len; i += 16) {\n        __m128i input = _mm_loadu_si128(reinterpret_cast<const __m128i*>(s.data() + i));\n        __m128i encrypted = _mm_add_epi8(input, shift);\n        encrypted = _mm_and_si128(encrypted, mask); // Ensure uppercase\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(result.data() + i), encrypted);\n    }\n\n    return result.substr(0, len); // Remove padding\n}\n```"}
{"task_id": "SimdBench_105_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string encrypt_simd(const std::string & s) {\n    std::string result = s;\n    size_t len = s.length();\n    size_t padded_len = (len + 15) & ~15; // Pad to multiple of 16\n\n    __m128i shift = _mm_set1_epi8(4); // Shift by 4 positions\n\n    for (size_t i = 0; i < padded_len; i += 16) {\n        __m128i input = _mm_loadu_si128(reinterpret_cast<const __m128i*>(s.data() + i));\n        __m128i encrypted = _mm_add_epi8(input, shift);\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(result.data() + i), encrypted);\n    }\n\n    return result.substr(0, len); // Remove padding\n}\n```"}
{"task_id": "SimdBench_105_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string encrypt_simd(const std::string & s) {\n    std::string result = s;\n    size_t len = s.length();\n    size_t padded_len = (len + 15) & ~15; // Pad to the next multiple of 16\n\n    __m128i shift = _mm_set1_epi8(4); // Shift by 4 positions (2 * 2)\n    __m128i mask = _mm_set1_epi8(0xDF); // Mask to convert to uppercase\n\n    for (size_t i = 0; i < padded_len; i += 16) {\n        __m128i input = _mm_loadu_si128(reinterpret_cast<const __m128i*>(s.data() + i));\n        __m128i shifted = _mm_add_epi8(input, shift);\n        __m128i masked = _mm_and_si128(shifted, mask);\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(result.data() + i), masked);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_106_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string encode_simd(const std::string & message) {\n    std::string result = message;\n    size_t len = message.size();\n    size_t i = 0;\n\n    // Process 16 characters at a time\n    for (; i + 16 <= len; i += 16) {\n        __m128i input = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&message[i]));\n        __m128i lower_mask = _mm_set1_epi8(0x20);\n        __m128i upper_mask = _mm_set1_epi8(0xDF);\n\n        // Swap case\n        __m128i swapped_case = _mm_xor_si128(input, lower_mask);\n\n        // Replace vowels\n        __m128i vowels = _mm_set1_epi8('a' | 'e' | 'i' | 'o' | 'u' | 'A' | 'E' | 'I' | 'O' | 'U');\n        __m128i replacements = _mm_set1_epi8(2);\n        __m128i is_vowel = _mm_cmpeq_epi8(_mm_and_si128(input, vowels), vowels);\n        __m128i replaced_vowels = _mm_add_epi8(input, _mm_and_si128(is_vowel, replacements));\n\n        // Combine swapped case and replaced vowels\n        __m128i output = _mm_or_si128(_mm_andnot_si128(is_vowel, swapped_case), replaced_vowels);\n\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i]), output);\n    }\n\n    // Process remaining characters\n    for (; i < len; ++i) {\n        char c = message[i];\n        if (c >= 'a' && c <= 'z') {\n            c = c - 'a' + 'A';\n        } else if (c >= 'A' && c <= 'Z') {\n            c = c - 'A' + 'a';\n        }\n\n        if (c == 'a' || c == 'e' || c == 'i' || c == 'o' || c == 'u') {\n            c += 2;\n        } else if (c == 'A' || c == 'E' || c == 'I' || c == 'O' || c == 'U') {\n            c += 2;\n        }\n\n        result[i] = c;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_106_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string encode_simd(const std::string & message) {\n    std::string result = message;\n    size_t len = message.size();\n    size_t i;\n\n    __m128i swap_case_mask = _mm_set1_epi8(0x20);\n    __m128i vowel_mask = _mm_set1_epi8(0x20 | 'a' | 'e' | 'i' | 'o' | 'u');\n    __m128i vowel_replace = _mm_setr_epi8('c', 'd', 'f', 'g', 'h', 'j', 'k', 'l', 'm', 'n', 'p', 'q', 'r', 's', 't', 'v');\n\n    for (i = 0; i <= len - 16; i += 16) {\n        __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(message.data() + i));\n        __m128i lower_chunk = _mm_andnot_si128(swap_case_mask, chunk);\n        __m128i upper_chunk = _mm_or_si128(swap_case_mask, chunk);\n\n        __m128i is_vowel = _mm_cmpeq_epi8(_mm_and_si128(lower_chunk, vowel_mask), vowel_mask);\n        __m128i replaced_vowels = _mm_or_si128(_mm_andnot_si128(is_vowel, lower_chunk), _mm_and_si128(is_vowel, vowel_replace));\n\n        __m128i encoded_chunk = _mm_or_si128(_mm_andnot_si128(swap_case_mask, replaced_vowels), _mm_and_si128(swap_case_mask, upper_chunk));\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(result.data() + i), encoded_chunk);\n    }\n\n    for (; i < len; ++i) {\n        char c = message[i];\n        if (c >= 'a' && c <= 'z') {\n            c ^= 0x20;\n            if (c == 'a' || c == 'e' || c == 'i' || c == 'o' || c == 'u') {\n                c += 2;\n            }\n        } else if (c >= 'A' && c <= 'Z') {\n            c ^= 0x20;\n            if (c == 'A' || c == 'E' || c == 'I' || c == 'O' || c == 'U') {\n                c += 2;\n            }\n            c ^= 0x20;\n        }\n        result[i] = c;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_106_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string encode_simd(const std::string & message) {\n    std::string result = message;\n    size_t len = message.size();\n    size_t i = 0;\n\n    __m128i lower_mask = _mm_set1_epi8(0x20);\n    __m128i vowel_mask = _mm_set1_epi8(0x20 | 0x04 | 0x08 | 0x10 | 0x20);\n    __m128i vowel_replace = _mm_setr_epi8(0, 2, 0, 0, 4, 0, 0, 0, 8, 0, 0, 0, 0, 0, 16, 0);\n\n    for (; i + 16 <= len; i += 16) {\n        __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&message[i]));\n        __m128i lower_chunk = _mm_and_si128(chunk, lower_mask);\n        __m128i upper_chunk = _mm_andnot_si128(lower_mask, chunk);\n\n        __m128i swapped_chunk = _mm_or_si128(_mm_andnot_si128(lower_mask, lower_chunk), _mm_and_si128(lower_mask, upper_chunk));\n\n        __m128i vowel_chunk = _mm_and_si128(swapped_chunk, vowel_mask);\n        __m128i replace_chunk = _mm_shuffle_epi8(vowel_replace, vowel_chunk);\n\n        __m128i encoded_chunk = _mm_or_si128(_mm_andnot_si128(vowel_mask, swapped_chunk), replace_chunk);\n\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i]), encoded_chunk);\n    }\n\n    for (; i < len; ++i) {\n        char c = message[i];\n        if (c >= 'a' && c <= 'z') {\n            c -= 0x20;\n        } else if (c >= 'A' && c <= 'Z') {\n            c += 0x20;\n        }\n\n        if (c == 'a' || c == 'e' || c == 'i' || c == 'o' || c == 'u') {\n            c += 2;\n        } else if (c == 'A' || c == 'E' || c == 'I' || c == 'O' || c == 'U') {\n            c += 2;\n        }\n\n        result[i] = c;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_106_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string encode_simd(const std::string & message) {\n    std::string result = message;\n    const size_t len = message.size();\n    const size_t aligned_len = len & ~15;\n\n    __m128i lower_mask = _mm_set1_epi8(0x20);\n    __m128i vowel_mask = _mm_set1_epi8(0x00);\n    __m128i vowel_replace = _mm_setr_epi8('e', 'i', 'o', 'u', 'a', 'E', 'I', 'O', 'U', 'A', 0, 0, 0, 0, 0, 0);\n\n    for (size_t i = 0; i < aligned_len; i += 16) {\n        __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&message[i]));\n        __m128i lower_chunk = _mm_or_si128(chunk, lower_mask);\n        __m128i upper_chunk = _mm_andnot_si128(lower_mask, chunk);\n\n        __m128i is_vowel = _mm_cmpeq_epi8(_mm_and_si128(lower_chunk, _mm_set1_epi8(0xDF)), _mm_set1_epi8('a'));\n        is_vowel = _mm_or_si128(is_vowel, _mm_cmpeq_epi8(_mm_and_si128(lower_chunk, _mm_set1_epi8(0xDF)), _mm_set1_epi8('e')));\n        is_vowel = _mm_or_si128(is_vowel, _mm_cmpeq_epi8(_mm_and_si128(lower_chunk, _mm_set1_epi8(0xDF)), _mm_set1_epi8('i')));\n        is_vowel = _mm_or_si128(is_vowel, _mm_cmpeq_epi8(_mm_and_si128(lower_chunk, _mm_set1_epi8(0xDF)), _mm_set1_epi8('o')));\n        is_vowel = _mm_or_si128(is_vowel, _mm_cmpeq_epi8(_mm_and_si128(lower_chunk, _mm_set1_epi8(0xDF)), _mm_set1_epi8('u')));\n\n        __m128i replaced_vowels = _mm_blendv_epi8(lower_chunk, vowel_replace, is_vowel);\n        __m128i final_chunk = _mm_or_si128(_mm_andnot_si128(lower_mask, replaced_vowels), upper_chunk);\n\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i]), final_chunk);\n    }\n\n    for (size_t i = aligned_len; i < len; ++i) {\n        char c = message[i];\n        if (c >= 'a' && c <= 'z') {\n            c -= 0x20;\n        } else if (c >= 'A' && c <= 'Z') {\n            c += 0x20;\n        }\n\n        if (c == 'a' || c == 'e' || c == 'i' || c == 'o' || c == 'u') {\n            c += 2;\n        } else if (c == 'A' || c == 'E' || c == 'I' || c == 'O' || c == 'U') {\n            c += 2;\n        }\n\n        result[i] = c;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_106_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string encode_simd(const std::string & message) {\n    std::string result = message;\n    size_t len = message.length();\n    size_t i = 0;\n\n    __m128i lower_mask = _mm_set1_epi8(0x20);\n    __m128i vowel_mask = _mm_set1_epi8(0x00);\n    __m128i vowel_replace = _mm_set_epi8('u', 'o', 'i', 'e', 'a', 'U', 'O', 'I', 'E', 'A', 0, 0, 0, 0, 0, 0);\n\n    for (; i + 16 <= len; i += 16) {\n        __m128i chunk = _mm_loadu_si128((__m128i*)&message[i]);\n        __m128i lower_chunk = _mm_or_si128(chunk, lower_mask);\n        __m128i upper_chunk = _mm_andnot_si128(lower_mask, chunk);\n\n        __m128i swapped_chunk = _mm_or_si128(lower_chunk, upper_chunk);\n\n        __m128i vowel_chunk = _mm_cmpeq_epi8(swapped_chunk, vowel_mask);\n        __m128i replaced_chunk = _mm_or_si128(_mm_andnot_si128(vowel_chunk, swapped_chunk), _mm_and_si128(vowel_chunk, vowel_replace));\n\n        _mm_storeu_si128((__m128i*)&result[i], replaced_chunk);\n    }\n\n    for (; i < len; ++i) {\n        char c = message[i];\n        if (c >= 'a' && c <= 'z') {\n            c = c - 0x20;\n        } else if (c >= 'A' && c <= 'Z') {\n            c = c + 0x20;\n        }\n\n        if (c == 'a' || c == 'e' || c == 'i' || c == 'o' || c == 'u') {\n            c += 2;\n        } else if (c == 'A' || c == 'E' || c == 'I' || c == 'O' || c == 'U') {\n            c += 2;\n        }\n\n        result[i] = c;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_107_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <map>\n#include <string>\n#include <cctype>\n\nbool check_dict_case_simd(std::map<std::string, std::string> dict) {\n    if (dict.empty()) return false;\n\n    bool all_lower = true;\n    bool all_upper = true;\n\n    for (const auto& pair : dict) {\n        const std::string& key = pair.first;\n        __m128i lower_mask = _mm_set1_epi8(0x20);\n        __m128i upper_mask = _mm_set1_epi8(0xDF);\n\n        size_t len = key.size();\n        size_t i = 0;\n\n        for (; i + 16 <= len; i += 16) {\n            __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(key.data() + i));\n            __m128i lower_chunk = _mm_or_si128(chunk, lower_mask);\n            __m128i upper_chunk = _mm_and_si128(chunk, upper_mask);\n\n            all_lower &= _mm_movemask_epi8(_mm_cmpeq_epi8(chunk, lower_chunk)) == 0xFFFF;\n            all_upper &= _mm_movemask_epi8(_mm_cmpeq_epi8(chunk, upper_chunk)) == 0xFFFF;\n        }\n\n        for (; i < len; ++i) {\n            all_lower &= std::islower(key[i]);\n            all_upper &= std::isupper(key[i]);\n        }\n\n        if (!all_lower && !all_upper) return false;\n    }\n\n    return all_lower || all_upper;\n}\n```"}
{"task_id": "SimdBench_107_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <map>\n#include <string>\n\nbool check_dict_case_simd(std::map<std::string, std::string> dict) {\n    if (dict.empty()) return false;\n\n    bool all_lower = true;\n    bool all_upper = true;\n\n    for (const auto& pair : dict) {\n        const std::string& key = pair.first;\n        __m128i lower_mask = _mm_set1_epi8(0x20);\n        __m128i upper_mask = _mm_set1_epi8(0xDF);\n\n        size_t len = key.size();\n        size_t i = 0;\n\n        for (; i + 16 <= len; i += 16) {\n            __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(key.data() + i));\n            __m128i lower_chunk = _mm_or_si128(chunk, lower_mask);\n            __m128i upper_chunk = _mm_and_si128(chunk, upper_mask);\n\n            all_lower &= _mm_movemask_epi8(_mm_cmpeq_epi8(chunk, lower_chunk)) == 0xFFFF;\n            all_upper &= _mm_movemask_epi8(_mm_cmpeq_epi8(chunk, upper_chunk)) == 0xFFFF;\n        }\n\n        for (; i < len; ++i) {\n            char c = key[i];\n            all_lower &= (c >= 'a' && c <= 'z');\n            all_upper &= (c >= 'A' && c <= 'Z');\n        }\n\n        if (!all_lower && !all_upper) return false;\n    }\n\n    return all_lower || all_upper;\n}\n```"}
{"task_id": "SimdBench_107_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <map>\n#include <string>\n\nbool check_dict_case_simd(std::map<std::string, std::string> dict) {\n    if (dict.empty()) return false;\n\n    bool all_lower = true;\n    bool all_upper = true;\n\n    for (const auto& pair : dict) {\n        const std::string& key = pair.first;\n        __m128i lower_mask = _mm_set1_epi8(0x20);\n        __m128i upper_mask = _mm_set1_epi8(0xDF);\n\n        size_t len = key.size();\n        size_t i = 0;\n\n        for (; i + 16 <= len; i += 16) {\n            __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(key.data() + i));\n            __m128i lower_chunk = _mm_or_si128(chunk, lower_mask);\n            __m128i upper_chunk = _mm_and_si128(chunk, upper_mask);\n\n            all_lower &= _mm_movemask_epi8(_mm_cmpeq_epi8(chunk, lower_chunk)) == 0xFFFF;\n            all_upper &= _mm_movemask_epi8(_mm_cmpeq_epi8(chunk, upper_chunk)) == 0xFFFF;\n        }\n\n        for (; i < len; ++i) {\n            all_lower &= islower(key[i]);\n            all_upper &= isupper(key[i]);\n        }\n\n        if (!all_lower && !all_upper) return false;\n    }\n\n    return all_lower || all_upper;\n}\n```"}
{"task_id": "SimdBench_107_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <map>\n#include <string>\n#include <cctype>\n\nbool check_dict_case_simd(std::map<std::string, std::string> dict) {\n    if (dict.empty()) return false;\n\n    bool all_lower = true;\n    bool all_upper = true;\n\n    for (const auto& pair : dict) {\n        const std::string& key = pair.first;\n        __m128i lower_mask = _mm_set1_epi8(0x20);\n        __m128i upper_mask = _mm_set1_epi8(0xDF);\n\n        size_t len = key.size();\n        size_t i = 0;\n\n        for (; i + 16 <= len; i += 16) {\n            __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(key.data() + i));\n            __m128i lower_chunk = _mm_or_si128(chunk, lower_mask);\n            __m128i upper_chunk = _mm_and_si128(chunk, upper_mask);\n\n            all_lower &= _mm_movemask_epi8(_mm_cmpeq_epi8(chunk, lower_chunk)) == 0xFFFF;\n            all_upper &= _mm_movemask_epi8(_mm_cmpeq_epi8(chunk, upper_chunk)) == 0xFFFF;\n        }\n\n        for (; i < len; ++i) {\n            all_lower &= std::islower(key[i]);\n            all_upper &= std::isupper(key[i]);\n        }\n\n        if (!all_lower && !all_upper) return false;\n    }\n\n    return all_lower || all_upper;\n}\n```"}
{"task_id": "SimdBench_107_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <map>\n#include <string>\n\nbool check_dict_case_simd(std::map<std::string, std::string> dict) {\n    if (dict.empty()) return false;\n\n    bool all_lower = true;\n    bool all_upper = true;\n\n    for (const auto& pair : dict) {\n        const std::string& key = pair.first;\n        __m128i lower_mask = _mm_set1_epi8(0x20);\n        __m128i upper_mask = _mm_set1_epi8(0xDF);\n\n        size_t len = key.size();\n        size_t i = 0;\n\n        for (; i + 16 <= len; i += 16) {\n            __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(key.data() + i));\n            __m128i lower_chunk = _mm_or_si128(chunk, lower_mask);\n            __m128i upper_chunk = _mm_and_si128(chunk, upper_mask);\n\n            all_lower &= _mm_movemask_epi8(_mm_cmpeq_epi8(chunk, lower_chunk)) == 0xFFFF;\n            all_upper &= _mm_movemask_epi8(_mm_cmpeq_epi8(chunk, upper_chunk)) == 0xFFFF;\n        }\n\n        for (; i < len; ++i) {\n            char c = key[i];\n            all_lower &= (c >= 'a' && c <= 'z');\n            all_upper &= (c >= 'A' && c <= 'Z');\n        }\n\n        if (!all_lower && !all_upper) return false;\n    }\n\n    return all_lower || all_upper;\n}\n```"}
{"task_id": "SimdBench_108_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> count_up_to_simd(int n) {\n    std::vector<int> primes;\n    if (n <= 2) return primes;\n\n    std::vector<bool> is_prime(n, true);\n    is_prime[0] = is_prime[1] = false;\n\n    for (int i = 2; i * i < n; ++i) {\n        if (is_prime[i]) {\n            for (int j = i * i; j < n; j += i) {\n                is_prime[j] = false;\n            }\n        }\n    }\n\n    for (int i = 2; i < n; ++i) {\n        if (is_prime[i]) {\n            primes.push_back(i);\n        }\n    }\n\n    return primes;\n}\n```"}
{"task_id": "SimdBench_108_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> count_up_to_simd(int n) {\n    std::vector<int> primes;\n    if (n <= 2) return primes;\n\n    std::vector<bool> is_prime(n, true);\n    is_prime[0] = is_prime[1] = false;\n\n    for (int i = 2; i * i < n; ++i) {\n        if (is_prime[i]) {\n            for (int j = i * i; j < n; j += i) {\n                is_prime[j] = false;\n            }\n        }\n    }\n\n    for (int i = 2; i < n; ++i) {\n        if (is_prime[i]) {\n            primes.push_back(i);\n        }\n    }\n\n    return primes;\n}\n```"}
{"task_id": "SimdBench_108_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <cmath>\n\nstd::vector<int> count_up_to_simd(int n) {\n    std::vector<int> primes;\n    if (n <= 2) return primes;\n\n    std::vector<bool> is_prime(n, true);\n    is_prime[0] = is_prime[1] = false;\n\n    for (int i = 2; i < n; ++i) {\n        if (is_prime[i]) {\n            primes.push_back(i);\n            if (i * 1LL * i < n) {\n                for (int j = i * i; j < n; j += i) {\n                    is_prime[j] = false;\n                }\n            }\n        }\n    }\n\n    return primes;\n}\n```"}
{"task_id": "SimdBench_108_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> count_up_to_simd(int n) {\n    std::vector<int> primes;\n    if (n <= 2) return primes;\n\n    std::vector<bool> is_prime(n, true);\n    is_prime[0] = is_prime[1] = false;\n\n    for (int i = 2; i * i < n; ++i) {\n        if (is_prime[i]) {\n            for (int j = i * i; j < n; j += i) {\n                is_prime[j] = false;\n            }\n        }\n    }\n\n    for (int i = 2; i < n; ++i) {\n        if (is_prime[i]) {\n            primes.push_back(i);\n        }\n    }\n\n    return primes;\n}\n```"}
{"task_id": "SimdBench_108_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> count_up_to_simd(int n) {\n    std::vector<int> primes;\n    if (n <= 2) return primes;\n\n    std::vector<bool> is_prime(n, true);\n    is_prime[0] = is_prime[1] = false;\n\n    for (int i = 2; i * i < n; ++i) {\n        if (is_prime[i]) {\n            for (int j = i * i; j < n; j += i) {\n                is_prime[j] = false;\n            }\n        }\n    }\n\n    for (int i = 2; i < n; ++i) {\n        if (is_prime[i]) {\n            primes.push_back(i);\n        }\n    }\n\n    return primes;\n}\n```"}
{"task_id": "SimdBench_109_SSE", "completion": "```cpp\nint count_upper_simd(const std::string & s){\n    const __m128i vowels = _mm_set1_epi8('A' | 'E' | 'I' | 'O' | 'U');\n    const __m128i mask = _mm_set1_epi8(0x55);\n    int count = 0;\n    int len = s.length();\n\n    for (int i = 0; i < len; i += 16) {\n        __m128i chunk = _mm_loadu_si128((__m128i*)&s[i]);\n        __m128i even_mask = _mm_and_si128(mask, _mm_cmpeq_epi8(chunk, vowels));\n        count += _mm_movemask_epi8(even_mask);\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_109_SSE", "completion": "```cpp\nint count_upper_simd(const std::string & s) {\n    const __m128i vowels = _mm_set1_epi8('A' | 'E' | 'I' | 'O' | 'U');\n    const __m128i mask = _mm_set1_epi8(0xDF); // Mask to convert to uppercase\n    int count = 0;\n    int len = s.length();\n\n    for (int i = 0; i < len; i += 16) {\n        __m128i chunk = _mm_loadu_si128((__m128i*)&s[i]);\n        __m128i upper_chunk = _mm_and_si128(chunk, mask);\n        __m128i is_vowel = _mm_cmpeq_epi8(_mm_and_si128(upper_chunk, vowels), vowels);\n\n        for (int j = 0; j < 16 && i + j < len; ++j) {\n            if (is_vowel.m128i_u8[j] && (i + j) % 2 == 0) {\n                count++;\n            }\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_109_SSE", "completion": "```cpp\nint count_upper_simd(const std::string & s) {\n    const char* str = s.c_str();\n    int len = s.length();\n    int count = 0;\n\n    __m128i mask = _mm_set1_epi8('A' | 'E' | 'I' | 'O' | 'U');\n    __m128i even_mask = _mm_set_epi8(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n\n    for (int i = 0; i < len; i += 16) {\n        __m128i chunk = _mm_loadu_si128((__m128i*)&str[i]);\n        __m128i upper = _mm_and_si128(chunk, mask);\n        __m128i even = _mm_and_si128(upper, even_mask);\n        count += _mm_popcnt_u32(_mm_movemask_epi8(even));\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_109_SSE", "completion": "```cpp\nint count_upper_simd(const std::string & s) {\n    const char* str = s.c_str();\n    int len = s.length();\n    int count = 0;\n\n    __m128i mask = _mm_set1_epi8('A' | 'E' | 'I' | 'O' | 'U');\n    __m128i even_mask = _mm_set_epi8(0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1);\n\n    for (int i = 0; i <= len - 16; i += 16) {\n        __m128i data = _mm_loadu_si128((__m128i*)&str[i]);\n        __m128i upper = _mm_and_si128(data, mask);\n        __m128i even = _mm_and_si128(upper, even_mask);\n        count += _mm_movemask_epi8(even) & 0x5555;\n    }\n\n    for (int i = (len / 16) * 16; i < len; i += 2) {\n        if (str[i] == 'A' || str[i] == 'E' || str[i] == 'I' || str[i] == 'O' || str[i] == 'U') {\n            count++;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_109_SSE", "completion": "```cpp\nint count_upper_simd(const std::string & s) {\n    const char* str = s.c_str();\n    size_t len = s.length();\n    int count = 0;\n\n    __m128i mask = _mm_set1_epi8('A' | 'E' | 'I' | 'O' | 'U');\n    __m128i even_mask = _mm_set_epi8(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n\n    for (size_t i = 0; i < len; i += 16) {\n        __m128i chunk = _mm_loadu_si128((__m128i*)&str[i]);\n        __m128i upper = _mm_and_si128(chunk, mask);\n        __m128i even = _mm_and_si128(upper, even_mask);\n        count += _mm_movemask_epi8(even);\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_110_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> make_a_pile_simd(int n) {\n    std::vector<int> result(n);\n    __m128i increment = _mm_set1_epi32(n % 2 == 0 ? 2 : 1);\n    __m128i current = _mm_set1_epi32(n);\n\n    for (int i = 0; i < n; i += 4) {\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i]), current);\n        current = _mm_add_epi32(current, increment);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_110_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> make_a_pile_simd(int n) {\n    std::vector<int> result(n);\n    __m128i increment = _mm_set1_epi32(2); // Set increment to 2 for even numbers\n    __m128i start = _mm_set_epi32(n, n, n, n); // Set initial values to n\n\n    if (n % 2 == 0) {\n        increment = _mm_set1_epi32(2); // Increment by 2 for even numbers\n    } else {\n        increment = _mm_set1_epi32(2); // Increment by 2 for odd numbers\n    }\n\n    for (int i = 0; i < n; i += 4) {\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i]), start);\n        start = _mm_add_epi32(start, increment);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_110_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> make_a_pile_simd(int n) {\n    std::vector<int> result(n);\n    __m128i increment = _mm_set1_epi32(2);\n    __m128i current = _mm_set1_epi32(n);\n\n    for (int i = 0; i < n; i += 4) {\n        _mm_storeu_si128((__m128i*)&result[i], current);\n        current = _mm_add_epi32(current, increment);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_110_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> make_a_pile_simd(int n) {\n    std::vector<int> result(n);\n    __m128i increment = _mm_set1_epi32(2);\n    __m128i current = _mm_set1_epi32(n);\n\n    for (int i = 0; i < n; i += 4) {\n        _mm_storeu_si128((__m128i*)&result[i], current);\n        current = _mm_add_epi32(current, increment);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_110_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> make_a_pile_simd(int n) {\n    std::vector<int> result(n);\n    __m128i increment = _mm_set1_epi32(n % 2 == 0 ? 2 : 1);\n    __m128i current = _mm_set1_epi32(n);\n\n    for (int i = 0; i < n; i += 4) {\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i]), current);\n        current = _mm_add_epi32(current, increment);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_111_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string rounded_avg_simd(int64_t n, int64_t m) {\n    if (n > m) {\n        return \"-1\";\n    }\n\n    __m128i sum = _mm_setzero_si128();\n    __m128i count = _mm_setzero_si128();\n\n    for (int64_t i = n; i <= m; ++i) {\n        __m128i value = _mm_set1_epi32(static_cast<int>(i));\n        sum = _mm_add_epi32(sum, value);\n        count = _mm_add_epi32(count, _mm_set1_epi32(1));\n    }\n\n    int32_t total_sum = _mm_extract_epi32(sum, 0) + _mm_extract_epi32(sum, 1) + _mm_extract_epi32(sum, 2) + _mm_extract_epi32(sum, 3);\n    int32_t total_count = _mm_extract_epi32(count, 0) + _mm_extract_epi32(count, 1) + _mm_extract_epi32(count, 2) + _mm_extract_epi32(count, 3);\n\n    int32_t avg = total_sum / total_count;\n\n    std::string binary = \"\";\n    while (avg > 0) {\n        binary = std::to_string(avg % 2) + binary;\n        avg /= 2;\n    }\n\n    return binary.empty() ? \"0\" : binary;\n}\n```"}
{"task_id": "SimdBench_111_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string rounded_avg_simd(int64_t n, int64_t m) {\n    if (n > m) {\n        return \"-1\";\n    }\n\n    __m128i sum = _mm_setzero_si128();\n    __m128i count = _mm_setzero_si128();\n\n    __m128i start = _mm_set1_epi64x(n);\n    __m128i end = _mm_set1_epi64x(m);\n    __m128i one = _mm_set1_epi64x(1);\n\n    while (_mm_movemask_epi8(_mm_cmpeq_epi64(start, end)) == 0) {\n        sum = _mm_add_epi64(sum, start);\n        count = _mm_add_epi64(count, one);\n        start = _mm_add_epi64(start, one);\n    }\n\n    sum = _mm_add_epi64(sum, start);\n    count = _mm_add_epi64(count, one);\n\n    int64_t total_sum = _mm_cvtsi128_si64(sum);\n    int64_t total_count = _mm_cvtsi128_si64(count);\n\n    int64_t avg = total_sum / total_count;\n\n    std::string binary = \"\";\n    while (avg > 0) {\n        binary = std::to_string(avg % 2) + binary;\n        avg /= 2;\n    }\n\n    return binary.empty() ? \"0\" : binary;\n}\n```"}
{"task_id": "SimdBench_111_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string rounded_avg_simd(int64_t n, int64_t m) {\n    if (n > m) {\n        return \"-1\";\n    }\n\n    __m128i sum = _mm_setzero_si128();\n    __m128i count = _mm_setzero_si128();\n\n    for (int64_t i = n; i <= m; ++i) {\n        __m128i value = _mm_set1_epi64x(i);\n        sum = _mm_add_epi64(sum, value);\n        count = _mm_add_epi64(count, _mm_set1_epi64x(1));\n    }\n\n    int64_t total_sum = _mm_cvtsi128_si64(sum);\n    int64_t total_count = _mm_cvtsi128_si64(count);\n\n    int64_t avg = total_sum / total_count;\n\n    std::string binary;\n    while (avg > 0) {\n        binary = (avg % 2 == 0 ? \"0\" : \"1\") + binary;\n        avg /= 2;\n    }\n\n    return binary.empty() ? \"0\" : binary;\n}\n```"}
{"task_id": "SimdBench_111_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string rounded_avg_simd(int64_t n, int64_t m) {\n    if (n > m) {\n        return \"-1\";\n    }\n\n    __m128i sum = _mm_setzero_si128();\n    __m128i count = _mm_setzero_si128();\n\n    for (int64_t i = n; i <= m; ++i) {\n        __m128i value = _mm_set1_epi64x(i);\n        sum = _mm_add_epi64(sum, value);\n        count = _mm_add_epi64(count, _mm_set1_epi64x(1));\n    }\n\n    int64_t total_sum = _mm_cvtsi128_si64(sum);\n    int64_t total_count = _mm_cvtsi128_si64(count);\n\n    int64_t avg = total_sum / total_count;\n\n    std::string binary;\n    while (avg > 0) {\n        binary = (avg % 2 == 0 ? \"0\" : \"1\") + binary;\n        avg /= 2;\n    }\n\n    return binary.empty() ? \"0\" : binary;\n}\n```"}
{"task_id": "SimdBench_111_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string rounded_avg_simd(int64_t n, int64_t m) {\n    if (n > m) {\n        return \"-1\";\n    }\n\n    __m128i sum = _mm_setzero_si128();\n    __m128i count = _mm_setzero_si128();\n\n    for (int64_t i = n; i <= m; ++i) {\n        __m128i value = _mm_set1_epi64x(i);\n        sum = _mm_add_epi64(sum, value);\n        count = _mm_add_epi64(count, _mm_set1_epi64x(1));\n    }\n\n    int64_t total_sum = _mm_cvtsi128_si64(sum) + _mm_cvtsi128_si64(_mm_srli_si128(sum, 8));\n    int64_t total_count = _mm_cvtsi128_si64(count) + _mm_cvtsi128_si64(_mm_srli_si128(count, 8));\n\n    int64_t avg = total_sum / total_count;\n\n    std::string binary = \"\";\n    while (avg > 0) {\n        binary = std::to_string(avg % 2) + binary;\n        avg /= 2;\n    }\n\n    return binary.empty() ? \"0\" : binary;\n}\n```"}
{"task_id": "SimdBench_112_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> func_simd(int n) {\n    std::vector<int> result(n);\n    __m128i ones = _mm_set1_epi32(1);\n    __m128i tens = _mm_set1_epi32(10000);\n    __m128i two = _mm_set1_epi32(2);\n    __m128i four = _mm_set1_epi32(4);\n\n    for (int i = 0; i < n; i += 4) {\n        __m128i indices = _mm_add_epi32(_mm_set_epi32(i + 4, i + 3, i + 2, i + 1), ones);\n        __m128i is_even = _mm_cmpeq_epi32(_mm_and_si128(indices, ones), _mm_setzero_si128());\n\n        __m128i factorials = _mm_set1_epi32(1);\n        __m128i sums = _mm_set1_epi32(0);\n\n        for (int j = 1; j <= 4; ++j) {\n            __m128i current = _mm_set1_epi32(j);\n            __m128i mask = _mm_cmpgt_epi32(indices, current);\n            factorials = _mm_mullo_epi32(factorials, _mm_and_si128(mask, current));\n            sums = _mm_add_epi32(sums, _mm_and_si128(mask, current));\n        }\n\n        factorials = _mm_and_si128(factorials, is_even);\n        sums = _mm_andnot_si128(is_even, sums);\n\n        __m128i res = _mm_or_si128(factorials, sums);\n        res = _mm_mod_epi32(res, tens);\n\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i]), res);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_112_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> func_simd(int n) {\n    std::vector<int> result(n);\n    __m128i zero = _mm_set1_epi32(0);\n    __m128i one = _mm_set1_epi32(1);\n    __m128i mod = _mm_set1_epi32(10000);\n    __m128i sum = _mm_set1_epi32(0);\n    __m128i fact = _mm_set1_epi32(1);\n    __m128i index = _mm_set_epi32(4, 3, 2, 1);\n\n    for (int i = 0; i < n; i += 4) {\n        __m128i current_index = _mm_add_epi32(index, _mm_set1_epi32(i));\n        __m128i mask = _mm_cmpeq_epi32(_mm_and_si128(current_index, one), zero);\n        __m128i even_mask = _mm_andnot_si128(mask, one);\n\n        __m128i even_fact = _mm_set1_epi32(1);\n        __m128i even_sum = _mm_set1_epi32(0);\n\n        for (int j = 0; j < 4; ++j) {\n            __m128i current = _mm_extract_epi32(current_index, j);\n            __m128i is_even = _mm_extract_epi32(even_mask, j);\n\n            if (_mm_cvtsi128_si32(is_even)) {\n                even_fact = _mm_mullo_epi32(even_fact, current);\n                even_fact = _mm_mod_epi32(even_fact, mod);\n            } else {\n                even_sum = _mm_add_epi32(even_sum, current);\n            }\n        }\n\n        _mm_storeu_si128((__m128i*)&result[i], _mm_blendv_epi8(even_sum, even_fact, even_mask));\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_112_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> func_simd(int n) {\n    std::vector<int> result(n);\n    __m128i ones = _mm_set1_epi32(1);\n    __m128i tens = _mm_set1_epi32(10000);\n    __m128i two = _mm_set1_epi32(2);\n    __m128i four = _mm_set1_epi32(4);\n\n    for (int i = 0; i < n; i += 4) {\n        __m128i indices = _mm_add_epi32(_mm_setr_epi32(i + 1, i + 2, i + 3, i + 4), ones);\n        __m128i is_even = _mm_cmpeq_epi32(_mm_and_si128(indices, ones), _mm_setzero_si128());\n\n        __m128i fact = _mm_set1_epi32(1);\n        __m128i sum = _mm_set1_epi32(0);\n\n        for (int j = 0; j < 4; ++j) {\n            __m128i current = _mm_set1_epi32(_mm_extract_epi32(indices, j));\n            __m128i mask = _mm_cmpeq_epi32(current, _mm_setzero_si128());\n            __m128i is_even_mask = _mm_and_si128(is_even, mask);\n\n            __m128i temp_fact = _mm_set1_epi32(1);\n            for (int k = 1; k <= _mm_extract_epi32(current, 0); ++k) {\n                temp_fact = _mm_mullo_epi32(temp_fact, _mm_set1_epi32(k));\n            }\n            temp_fact = _mm_mod_epi32(temp_fact, tens);\n\n            __m128i temp_sum = _mm_set1_epi32(0);\n            for (int k = 1; k <= _mm_extract_epi32(current, 0); ++k) {\n                temp_sum = _mm_add_epi32(temp_sum, _mm_set1_epi32(k));\n            }\n\n            fact = _mm_blendv_epi8(fact, temp_fact, is_even_mask);\n            sum = _mm_blendv_epi8(sum, temp_sum, _mm_xor_si128(is_even_mask, _mm_set1_epi32(-1)));\n        }\n\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i]), _mm_blendv_epi8(sum, fact, is_even));\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_112_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> func_simd(int n) {\n    std::vector<int> result(n);\n    __m128i ones = _mm_set1_epi32(1);\n    __m128i tens = _mm_set1_epi32(10000);\n    __m128i idx = _mm_set_epi32(4, 3, 2, 1);\n    __m128i sum = _mm_setzero_si128();\n    __m128i fact = _mm_set1_epi32(1);\n\n    for (int i = 0; i < n; i += 4) {\n        __m128i current_idx = _mm_add_epi32(idx, _mm_set1_epi32(i));\n        __m128i mask = _mm_cmpeq_epi32(_mm_and_si128(current_idx, _mm_set1_epi32(1)), _mm_setzero_si128());\n\n        __m128i fact_mask = _mm_and_si128(mask, _mm_set1_epi32(1));\n        fact = _mm_mullo_epi32(fact, _mm_add_epi32(fact_mask, ones));\n        fact = _mm_mod_epi32(fact, tens);\n\n        __m128i sum_mask = _mm_andnot_si128(mask, _mm_set1_epi32(1));\n        sum = _mm_add_epi32(sum, sum_mask);\n        sum = _mm_mullo_epi32(sum, _mm_add_epi32(sum_mask, ones));\n\n        __m128i res = _mm_or_si128(_mm_and_si128(fact, mask), _mm_and_si128(sum, sum_mask));\n        _mm_storeu_si128((__m128i*)&result[i], res);\n\n        idx = _mm_add_epi32(idx, _mm_set1_epi32(4));\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_112_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> func_simd(int n) {\n    std::vector<int> result(n);\n    __m128i zero = _mm_set1_epi32(0);\n    __m128i one = _mm_set1_epi32(1);\n    __m128i two = _mm_set1_epi32(2);\n    __m128i mod = _mm_set1_epi32(10000);\n    __m128i sum = _mm_set1_epi32(0);\n    __m128i fact = _mm_set1_epi32(1);\n\n    for (int i = 0; i < n; i += 4) {\n        __m128i indices = _mm_add_epi32(_mm_setr_epi32(i + 1, i + 2, i + 3, i + 4), one);\n        __m128i even_mask = _mm_cmpeq_epi32(_mm_and_si128(indices, one), zero);\n        __m128i odd_mask = _mm_xor_si128(even_mask, _mm_set1_epi32(-1));\n\n        __m128i even_indices = _mm_and_si128(indices, even_mask);\n        __m128i odd_indices = _mm_and_si128(indices, odd_mask);\n\n        __m128i even_fact = _mm_set1_epi32(1);\n        for (int j = 0; j < 4; ++j) {\n            int idx = _mm_extract_epi32(even_indices, j);\n            if (idx > 0) {\n                __m128i temp = _mm_set1_epi32(idx);\n                even_fact = _mm_mullo_epi32(even_fact, temp);\n                even_fact = _mm_mod_epi32(even_fact, mod);\n            }\n        }\n\n        __m128i odd_sum = _mm_set1_epi32(0);\n        for (int j = 0; j < 4; ++j) {\n            int idx = _mm_extract_epi32(odd_indices, j);\n            if (idx > 0) {\n                __m128i temp = _mm_set1_epi32(idx);\n                odd_sum = _mm_add_epi32(odd_sum, temp);\n            }\n        }\n\n        __m128i res = _mm_or_si128(_mm_and_si128(even_fact, even_mask), _mm_and_si128(odd_sum, odd_mask));\n        _mm_storeu_si128((__m128i*)&result[i], res);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_113_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> even_odd_palindrome_simd(int n) {\n    int even_count = 0;\n    int odd_count = 0;\n\n    __m128i even_mask = _mm_set1_epi32(1);\n    __m128i odd_mask = _mm_set1_epi32(0);\n\n    for (int i = 1; i <= n; i += 4) {\n        __m128i numbers = _mm_set_epi32(i + 3, i + 2, i + 1, i);\n        __m128i reversed = _mm_shuffle_epi32(numbers, _MM_SHUFFLE(0, 1, 2, 3));\n\n        __m128i is_palindrome = _mm_cmpeq_epi32(numbers, reversed);\n        __m128i even_palindromes = _mm_and_si128(is_palindrome, even_mask);\n        __m128i odd_palindromes = _mm_and_si128(is_palindrome, odd_mask);\n\n        even_count += _mm_movemask_epi8(even_palindromes) & 0x1111;\n        odd_count += _mm_movemask_epi8(odd_palindromes) & 0x1111;\n    }\n\n    return {even_count, odd_count};\n}\n```"}
{"task_id": "SimdBench_113_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> even_odd_palindrome_simd(int n) {\n    int even_count = 0;\n    int odd_count = 0;\n\n    __m128i even_mask = _mm_set1_epi32(1);\n    __m128i zero = _mm_setzero_si128();\n\n    for (int i = 1; i <= n; i += 4) {\n        __m128i numbers = _mm_set_epi32(i + 3, i + 2, i + 1, i);\n        __m128i reversed = _mm_shuffle_epi32(numbers, _MM_SHUFFLE(0, 1, 2, 3));\n\n        __m128i is_palindrome = _mm_cmpeq_epi32(numbers, reversed);\n        __m128i even_numbers = _mm_and_si128(numbers, even_mask);\n\n        __m128i even_palindromes = _mm_and_si128(is_palindrome, _mm_cmpeq_epi32(even_numbers, even_mask));\n        __m128i odd_palindromes = _mm_andnot_si128(even_palindromes, is_palindrome);\n\n        even_count += _mm_movemask_epi8(_mm_cmpeq_epi32(even_palindromes, zero)) & 0x0F;\n        odd_count += _mm_movemask_epi8(_mm_cmpeq_epi32(odd_palindromes, zero)) & 0x0F;\n    }\n\n    return {even_count, odd_count};\n}\n```"}
{"task_id": "SimdBench_113_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> even_odd_palindrome_simd(int n) {\n    int even_count = 0;\n    int odd_count = 0;\n\n    __m128i even_mask = _mm_set1_epi32(1);\n    __m128i zero = _mm_setzero_si128();\n\n    for (int i = 1; i <= n; i += 4) {\n        __m128i numbers = _mm_set_epi32(i + 3, i + 2, i + 1, i);\n        __m128i reversed = _mm_shuffle_epi32(numbers, _MM_SHUFFLE(0, 1, 2, 3));\n\n        __m128i is_palindrome = _mm_cmpeq_epi32(numbers, reversed);\n        __m128i even_numbers = _mm_and_si128(numbers, even_mask);\n        __m128i is_even = _mm_cmpeq_epi32(even_numbers, zero);\n\n        __m128i even_palindromes = _mm_and_si128(is_palindrome, is_even);\n        __m128i odd_palindromes = _mm_andnot_si128(is_even, is_palindrome);\n\n        even_count += _mm_movemask_epi8(_mm_cmpeq_epi32(even_palindromes, zero)) & 0x1111;\n        odd_count += _mm_movemask_epi8(_mm_cmpeq_epi32(odd_palindromes, zero)) & 0x1111;\n    }\n\n    return {even_count, odd_count};\n}\n```"}
{"task_id": "SimdBench_113_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> even_odd_palindrome_simd(int n) {\n    int even_count = 0;\n    int odd_count = 0;\n\n    __m128i even_mask = _mm_set1_epi32(1);\n    __m128i zero = _mm_setzero_si128();\n\n    for (int i = 1; i <= n; i += 4) {\n        __m128i numbers = _mm_set_epi32(i + 3, i + 2, i + 1, i);\n        __m128i reversed = _mm_shuffle_epi32(numbers, _MM_SHUFFLE(0, 1, 2, 3));\n\n        __m128i is_palindrome = _mm_cmpeq_epi32(numbers, reversed);\n        __m128i even_numbers = _mm_and_si128(numbers, even_mask);\n        __m128i is_even = _mm_cmpeq_epi32(even_numbers, zero);\n\n        __m128i even_palindromes = _mm_and_si128(is_palindrome, is_even);\n        __m128i odd_palindromes = _mm_andnot_si128(is_even, is_palindrome);\n\n        even_count += _mm_movemask_epi8(_mm_packs_epi32(even_palindromes, zero)) & 0x0F;\n        odd_count += _mm_movemask_epi8(_mm_packs_epi32(odd_palindromes, zero)) & 0x0F;\n    }\n\n    return {even_count, odd_count};\n}\n```"}
{"task_id": "SimdBench_113_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> even_odd_palindrome_simd(int n) {\n    int even_count = 0;\n    int odd_count = 0;\n\n    __m128i even_mask = _mm_set1_epi32(1);\n    __m128i zero = _mm_setzero_si128();\n\n    for (int i = 1; i <= n; i += 4) {\n        __m128i numbers = _mm_set_epi32(i + 3, i + 2, i + 1, i);\n        __m128i reversed = _mm_shuffle_epi32(numbers, _MM_SHUFFLE(0, 1, 2, 3));\n\n        __m128i is_palindrome = _mm_cmpeq_epi32(numbers, reversed);\n        __m128i even_numbers = _mm_and_si128(numbers, even_mask);\n        __m128i is_even = _mm_cmpeq_epi32(even_numbers, zero);\n\n        __m128i even_palindromes = _mm_and_si128(is_palindrome, is_even);\n        __m128i odd_palindromes = _mm_andnot_si128(is_even, is_palindrome);\n\n        even_count += _mm_movemask_epi8(_mm_cmpeq_epi32(even_palindromes, zero)) & 0x1111;\n        odd_count += _mm_movemask_epi8(_mm_cmpeq_epi32(odd_palindromes, zero)) & 0x1111;\n    }\n\n    return {even_count, odd_count};\n}\n```"}
{"task_id": "SimdBench_114_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint count_nums_simd(std::vector<int> n) {\n    int count = 0;\n    int size = n.size();\n    int i = 0;\n\n    for (; i <= size - 4; i += 4) {\n        __m128i vec = _mm_loadu_si128((__m128i*)&n[i]);\n        __m128i abs_vec = _mm_abs_epi32(vec);\n        __m128i sum = _mm_setzero_si128();\n\n        for (int j = 0; j < 4; ++j) {\n            int num = _mm_extract_epi32(abs_vec, j);\n            int digit_sum = 0;\n            while (num > 0) {\n                digit_sum += num % 10;\n                num /= 10;\n            }\n            sum = _mm_add_epi32(sum, _mm_set1_epi32(digit_sum));\n        }\n\n        count += _mm_movemask_epi8(_mm_cmpgt_epi32(sum, _mm_setzero_si128()));\n    }\n\n    for (; i < size; ++i) {\n        int num = abs(n[i]);\n        int digit_sum = 0;\n        while (num > 0) {\n            digit_sum += num % 10;\n            num /= 10;\n        }\n        if (digit_sum > 0) {\n            count++;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_114_SSE", "completion": "```c++\nint count_nums_simd(std::vector<int> n) {\n    int count = 0;\n    __m128i zero = _mm_setzero_si128();\n    __m128i sum = _mm_setzero_si128();\n\n    for (size_t i = 0; i < n.size(); i += 4) {\n        __m128i nums = _mm_loadu_si128((__m128i*)&n[i]);\n        __m128i mask = _mm_cmpgt_epi32(nums, zero);\n        __m128i abs_nums = _mm_andnot_si128(mask, nums);\n        abs_nums = _mm_sub_epi32(abs_nums, mask);\n\n        __m128i digits = _mm_set1_epi32(10);\n        __m128i sum_digits = _mm_setzero_si128();\n\n        for (int j = 0; j < 4; ++j) {\n            __m128i digit = _mm_div_epi32(abs_nums, digits);\n            sum_digits = _mm_add_epi32(sum_digits, digit);\n            abs_nums = _mm_sub_epi32(abs_nums, _mm_mullo_epi32(digit, digits));\n            digits = _mm_srli_epi32(digits, 1);\n        }\n\n        sum = _mm_add_epi32(sum, sum_digits);\n    }\n\n    int sums[4];\n    _mm_storeu_si128((__m128i*)sums, sum);\n\n    for (int i = 0; i < 4; ++i) {\n        if (sums[i] > 0) {\n            count++;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_114_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint count_nums_simd(std::vector<int> n) {\n    int count = 0;\n    int size = n.size();\n    int i = 0;\n\n    for (; i <= size - 4; i += 4) {\n        __m128i v = _mm_loadu_si128((__m128i*)&n[i]);\n        __m128i sum = _mm_setzero_si128();\n\n        for (int j = 0; j < 4; ++j) {\n            int num = _mm_extract_epi32(v, j);\n            int digit_sum = 0;\n            bool negative = num < 0;\n            if (negative) num = -num;\n\n            while (num > 0) {\n                digit_sum += num % 10;\n                num /= 10;\n            }\n\n            if (negative) digit_sum = -digit_sum;\n            if (digit_sum > 0) count++;\n        }\n    }\n\n    for (; i < size; ++i) {\n        int num = n[i];\n        int digit_sum = 0;\n        bool negative = num < 0;\n        if (negative) num = -num;\n\n        while (num > 0) {\n            digit_sum += num % 10;\n            num /= 10;\n        }\n\n        if (negative) digit_sum = -digit_sum;\n        if (digit_sum > 0) count++;\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_114_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint count_nums_simd(std::vector<int> n) {\n    int count = 0;\n    int size = n.size();\n    int i = 0;\n\n    for (; i <= size - 4; i += 4) {\n        __m128i vec = _mm_loadu_si128((__m128i*)&n[i]);\n        __m128i abs_vec = _mm_abs_epi32(vec);\n        __m128i sum = _mm_setzero_si128();\n\n        for (int j = 0; j < 4; ++j) {\n            int num = _mm_extract_epi32(abs_vec, j);\n            int digit_sum = 0;\n            while (num > 0) {\n                digit_sum += num % 10;\n                num /= 10;\n            }\n            sum = _mm_add_epi32(sum, _mm_set1_epi32(digit_sum));\n        }\n\n        int sums[4];\n        _mm_storeu_si128((__m128i*)sums, sum);\n        for (int j = 0; j < 4; ++j) {\n            if (sums[j] > 0) {\n                count++;\n            }\n        }\n    }\n\n    for (; i < size; ++i) {\n        int num = abs(n[i]);\n        int digit_sum = 0;\n        while (num > 0) {\n            digit_sum += num % 10;\n            num /= 10;\n        }\n        if (digit_sum > 0) {\n            count++;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_114_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint count_nums_simd(std::vector<int> n) {\n    int count = 0;\n    int size = n.size();\n    int i = 0;\n\n    for (; i <= size - 4; i += 4) {\n        __m128i vec = _mm_loadu_si128((__m128i*)&n[i]);\n        __m128i abs_vec = _mm_abs_epi32(vec);\n        __m128i sum = _mm_setzero_si128();\n\n        for (int j = 0; j < 4; ++j) {\n            int num = _mm_extract_epi32(abs_vec, j);\n            int digit_sum = 0;\n            while (num > 0) {\n                digit_sum += num % 10;\n                num /= 10;\n            }\n            sum = _mm_add_epi32(sum, _mm_set1_epi32(digit_sum));\n        }\n\n        int sums[4];\n        _mm_storeu_si128((__m128i*)sums, sum);\n        for (int j = 0; j < 4; ++j) {\n            if (sums[j] > 0) {\n                count++;\n            }\n        }\n    }\n\n    for (; i < size; ++i) {\n        int num = abs(n[i]);\n        int digit_sum = 0;\n        while (num > 0) {\n            digit_sum += num % 10;\n            num /= 10;\n        }\n        if (digit_sum > 0) {\n            count++;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_115_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n\nbool move_one_ball_simd(std::vector<int> arr) {\n    int n = arr.size();\n    if (n == 0) return true;\n\n    std::vector<int> sorted_arr = arr;\n    std::sort(sorted_arr.begin(), sorted_arr.end());\n\n    for (int shift = 0; shift < n; ++shift) {\n        bool is_sorted = true;\n        for (int i = 0; i < n; i += 4) {\n            __m128i vec1 = _mm_loadu_si128((__m128i*)&arr[(i + shift) % n]);\n            __m128i vec2 = _mm_loadu_si128((__m128i*)&sorted_arr[i]);\n            __m128i cmp = _mm_cmplt_epi32(vec1, vec2);\n            if (_mm_movemask_epi8(cmp) != 0) {\n                is_sorted = false;\n                break;\n            }\n        }\n        if (is_sorted) return true;\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_115_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n\nbool move_one_ball_simd(std::vector<int> arr) {\n    int N = arr.size();\n    if (N == 0) return true;\n\n    std::vector<int> sorted_arr = arr;\n    std::sort(sorted_arr.begin(), sorted_arr.end());\n\n    for (int shift = 0; shift < N; ++shift) {\n        bool is_sorted = true;\n        for (int i = 0; i < N; i += 4) {\n            __m128i vec1 = _mm_loadu_si128((__m128i*)&arr[(i + shift) % N]);\n            __m128i vec2 = _mm_loadu_si128((__m128i*)&sorted_arr[i]);\n\n            __m128i cmp = _mm_cmplt_epi32(vec1, vec2);\n            int mask = _mm_movemask_epi8(cmp);\n\n            if (mask != 0) {\n                is_sorted = false;\n                break;\n            }\n        }\n        if (is_sorted) return true;\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_115_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n\nbool move_one_ball_simd(std::vector<int> arr) {\n    int n = arr.size();\n    if (n == 0) return true;\n\n    std::vector<int> sorted_arr = arr;\n    std::sort(sorted_arr.begin(), sorted_arr.end());\n\n    for (int shift = 0; shift < n; ++shift) {\n        bool is_sorted = true;\n        for (int i = 0; i < n; i += 4) {\n            __m128i vec1 = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&arr[i]));\n            __m128i vec2 = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&sorted_arr[(i + shift) % n]));\n\n            __m128i cmp = _mm_cmplt_epi32(vec1, vec2);\n            int mask = _mm_movemask_epi8(cmp);\n\n            if (mask != 0xFFFF) {\n                is_sorted = false;\n                break;\n            }\n        }\n        if (is_sorted) return true;\n\n        std::rotate(arr.begin(), arr.end() - 1, arr.end());\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_115_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n\nbool move_one_ball_simd(std::vector<int> arr) {\n    int n = arr.size();\n    if (n == 0) return true;\n\n    std::vector<int> sorted_arr = arr;\n    std::sort(sorted_arr.begin(), sorted_arr.end());\n\n    for (int shift = 0; shift < n; ++shift) {\n        bool is_sorted = true;\n        for (int i = 0; i < n; i += 4) {\n            __m128i vec1 = _mm_loadu_si128((__m128i*)&arr[(i + shift) % n]);\n            __m128i vec2 = _mm_loadu_si128((__m128i*)&sorted_arr[i]);\n            __m128i cmp = _mm_cmplt_epi32(vec1, vec2);\n            int mask = _mm_movemask_epi8(cmp);\n            if (mask != 0) {\n                is_sorted = false;\n                break;\n            }\n        }\n        if (is_sorted) return true;\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_115_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n\nbool move_one_ball_simd(std::vector<int> arr) {\n    int n = arr.size();\n    if (n == 0) return true;\n\n    std::vector<int> sorted_arr = arr;\n    std::sort(sorted_arr.begin(), sorted_arr.end());\n\n    for (int shift = 0; shift < n; ++shift) {\n        bool is_sorted = true;\n        for (int i = 0; i < n; i += 4) {\n            __m128i a = _mm_loadu_si128((__m128i*)&arr[(i + shift) % n]);\n            __m128i b = _mm_loadu_si128((__m128i*)&sorted_arr[i]);\n            __m128i cmp = _mm_cmpeq_epi32(a, b);\n            int mask = _mm_movemask_epi8(cmp);\n            if (mask != 0xFFFF) {\n                is_sorted = false;\n                break;\n            }\n        }\n        if (is_sorted) return true;\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_116_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n\nstd::string exchange_simd(const std::vector<int>& lst1, const std::vector<int>& lst2) {\n    int size = lst1.size();\n    __m128i even_mask = _mm_set1_epi32(1);\n\n    for (int i = 0; i < size; i += 4) {\n        __m128i vec1 = _mm_loadu_si128((__m128i*)&lst1[i]);\n        __m128i vec2 = _mm_loadu_si128((__m128i*)&lst2[i]);\n\n        __m128i odd_mask1 = _mm_andnot_si128(even_mask, vec1);\n        __m128i odd_mask2 = _mm_andnot_si128(even_mask, vec2);\n\n        if (_mm_movemask_epi8(odd_mask1) != 0) {\n            if (_mm_movemask_epi8(odd_mask2) == 0) {\n                return \"NO\";\n            }\n        }\n    }\n\n    return \"YES\";\n}\n```"}
{"task_id": "SimdBench_116_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n\nstd::string exchange_simd(const std::vector<int>& lst1, const std::vector<int>& lst2) {\n    int size = lst1.size();\n    int even_count = 0;\n    int odd_count = 0;\n\n    for (int i = 0; i < size; i += 4) {\n        __m128i vec1 = _mm_loadu_si128((__m128i*)&lst1[i]);\n        __m128i vec2 = _mm_loadu_si128((__m128i*)&lst2[i]);\n\n        __m128i mask1 = _mm_set1_epi32(1);\n        __m128i mask2 = _mm_set1_epi32(1);\n\n        __m128i even_mask1 = _mm_andnot_si128(mask1, vec1);\n        __m128i even_mask2 = _mm_andnot_si128(mask2, vec2);\n\n        __m128i odd_mask1 = _mm_and_si128(mask1, vec1);\n        __m128i odd_mask2 = _mm_and_si128(mask2, vec2);\n\n        even_count += _mm_movemask_epi8(_mm_cmpeq_epi32(even_mask1, _mm_setzero_si128()));\n        odd_count += _mm_movemask_epi8(_mm_cmpeq_epi32(odd_mask1, _mm_setzero_si128()));\n\n        even_count += _mm_movemask_epi8(_mm_cmpeq_epi32(even_mask2, _mm_setzero_si128()));\n        odd_count += _mm_movemask_epi8(_mm_cmpeq_epi32(odd_mask2, _mm_setzero_si128()));\n    }\n\n    if (even_count >= odd_count) {\n        return \"YES\";\n    } else {\n        return \"NO\";\n    }\n}\n```"}
{"task_id": "SimdBench_116_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n\nstd::string exchange_simd(const std::vector<int>& lst1, const std::vector<int>& lst2) {\n    int size = lst1.size();\n    __m128i even_mask = _mm_set1_epi32(1);\n\n    for (int i = 0; i < size; i += 4) {\n        __m128i vec1 = _mm_loadu_si128((__m128i*)&lst1[i]);\n        __m128i vec2 = _mm_loadu_si128((__m128i*)&lst2[i]);\n\n        __m128i odd_mask1 = _mm_andnot_si128(even_mask, vec1);\n        __m128i odd_mask2 = _mm_andnot_si128(even_mask, vec2);\n\n        if (_mm_movemask_epi8(odd_mask1) != 0) {\n            if (_mm_movemask_epi8(odd_mask2) == 0) {\n                return \"NO\";\n            }\n        }\n    }\n\n    return \"YES\";\n}\n```"}
{"task_id": "SimdBench_116_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n\nstd::string myexchange_simd(const std::vector<int>& lst1, const std::vector<int>& lst2) {\n    int size = lst1.size();\n    __m128i even_mask = _mm_set1_epi32(1);\n    __m128i odd_mask = _mm_set1_epi32(0);\n\n    int even_count_lst1 = 0;\n    int odd_count_lst1 = 0;\n    int even_count_lst2 = 0;\n    int odd_count_lst2 = 0;\n\n    for (int i = 0; i < size; i += 4) {\n        __m128i vec1 = _mm_loadu_si128((__m128i*)&lst1[i]);\n        __m128i vec2 = _mm_loadu_si128((__m128i*)&lst2[i]);\n\n        __m128i even1 = _mm_and_si128(vec1, even_mask);\n        __m128i odd1 = _mm_and_si128(vec1, odd_mask);\n        __m128i even2 = _mm_and_si128(vec2, even_mask);\n        __m128i odd2 = _mm_and_si128(vec2, odd_mask);\n\n        even_count_lst1 += _mm_movemask_epi8(_mm_cmpeq_epi32(even1, even_mask));\n        odd_count_lst1 += _mm_movemask_epi8(_mm_cmpeq_epi32(odd1, odd_mask));\n        even_count_lst2 += _mm_movemask_epi8(_mm_cmpeq_epi32(even2, even_mask));\n        odd_count_lst2 += _mm_movemask_epi8(_mm_cmpeq_epi32(odd2, odd_mask));\n    }\n\n    if (even_count_lst1 + even_count_lst2 >= size) {\n        return \"YES\";\n    } else {\n        return \"NO\";\n    }\n}\n```"}
{"task_id": "SimdBench_116_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n\nstd::string exchange_simd(const std::vector<int>& lst1, const std::vector<int>& lst2) {\n    int size = lst1.size();\n    __m128i even_mask = _mm_set1_epi32(1);\n    __m128i odd_mask = _mm_set1_epi32(0);\n\n    int even_count_lst1 = 0;\n    int odd_count_lst1 = 0;\n    int even_count_lst2 = 0;\n    int odd_count_lst2 = 0;\n\n    for (int i = 0; i < size; i += 4) {\n        __m128i vec1 = _mm_loadu_si128((__m128i*)&lst1[i]);\n        __m128i vec2 = _mm_loadu_si128((__m128i*)&lst2[i]);\n\n        __m128i even1 = _mm_and_si128(vec1, even_mask);\n        __m128i odd1 = _mm_and_si128(vec1, odd_mask);\n        __m128i even2 = _mm_and_si128(vec2, even_mask);\n        __m128i odd2 = _mm_and_si128(vec2, odd_mask);\n\n        even_count_lst1 += _mm_movemask_epi8(_mm_cmpeq_epi32(even1, even_mask));\n        odd_count_lst1 += _mm_movemask_epi8(_mm_cmpeq_epi32(odd1, odd_mask));\n        even_count_lst2 += _mm_movemask_epi8(_mm_cmpeq_epi32(even2, even_mask));\n        odd_count_lst2 += _mm_movemask_epi8(_mm_cmpeq_epi32(odd2, odd_mask));\n    }\n\n    if (even_count_lst1 + even_count_lst2 >= size) {\n        return \"YES\";\n    } else {\n        return \"NO\";\n    }\n}\n```"}
{"task_id": "SimdBench_117_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n\nstd::vector<std::string> odd_count_simd(const std::vector<std::string> & lst) {\n    std::vector<std::string> result;\n    for (const auto& str : lst) {\n        int odd_count = 0;\n        int length = str.length();\n        int i = 0;\n\n        // Process 16 characters at a time\n        for (; i <= length - 16; i += 16) {\n            __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&str[i]));\n            __m128i odd_mask = _mm_set1_epi8(1);\n            __m128i and_result = _mm_and_si128(chunk, odd_mask);\n            __m128i cmp_result = _mm_cmpeq_epi8(and_result, odd_mask);\n            int mask = _mm_movemask_epi8(cmp_result);\n            odd_count += _mm_popcnt_u32(mask);\n        }\n\n        // Process remaining characters\n        for (; i < length; ++i) {\n            if ((str[i] - '0') % 2 != 0) {\n                ++odd_count;\n            }\n        }\n\n        std::string output = \"the number of odd elements \" + std::to_string(odd_count) + \"n the str\" + std::to_string(odd_count) + \"ng \" + std::to_string(odd_count) + \" of the \" + std::to_string(odd_count) + \"nput.\";\n        result.push_back(output);\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_117_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n\nstd::vector<std::string> odd_count_simd(const std::vector<std::string> & lst) {\n    std::vector<std::string> result;\n    for (const auto& str : lst) {\n        int odd_count = 0;\n        int length = str.length();\n        int i = 0;\n\n        // Process 16 characters at a time\n        for (; i <= length - 16; i += 16) {\n            __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&str[i]));\n            __m128i odd_mask = _mm_set1_epi8(1);\n            __m128i odd_digits = _mm_and_si128(chunk, odd_mask);\n            odd_count += _mm_movemask_epi8(_mm_cmpeq_epi8(odd_digits, odd_mask));\n        }\n\n        // Process remaining characters\n        for (; i < length; ++i) {\n            if ((str[i] - '0') % 2 != 0) {\n                ++odd_count;\n            }\n        }\n\n        std::string output = \"the number of odd elements \" + std::to_string(odd_count) +\n                             \"n the str\" + std::to_string(odd_count) +\n                             \"ng \" + std::to_string(odd_count) +\n                             \" of the \" + std::to_string(odd_count) + \"nput.\";\n        result.push_back(output);\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_117_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n\nstd::vector<std::string> odd_count_simd(const std::vector<std::string> & lst) {\n    std::vector<std::string> result;\n    for (const auto& str : lst) {\n        int odd_count = 0;\n        int length = str.length();\n        int i = 0;\n\n        // Process 16 characters at a time using SSE2\n        for (; i <= length - 16; i += 16) {\n            __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(str.data() + i));\n            __m128i odd_mask = _mm_set1_epi8(1);\n            __m128i odd_digits = _mm_and_si128(chunk, odd_mask);\n            odd_count += _mm_movemask_epi8(_mm_cmpeq_epi8(odd_digits, odd_mask));\n        }\n\n        // Process remaining characters\n        for (; i < length; ++i) {\n            if ((str[i] - '0') % 2 != 0) {\n                ++odd_count;\n            }\n        }\n\n        std::string output = \"the number of odd elements \" + std::to_string(odd_count) + \"n the str\" + std::to_string(odd_count) + \"ng \" + std::to_string(odd_count) + \" of the \" + std::to_string(odd_count) + \"nput.\";\n        result.push_back(output);\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_117_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n\nstd::vector<std::string> odd_count_simd(const std::vector<std::string> & lst) {\n    std::vector<std::string> result;\n    for (const auto& str : lst) {\n        int odd_count = 0;\n        size_t len = str.size();\n        size_t i = 0;\n\n        // Process 16 characters at a time using SSE2\n        for (; i + 16 <= len; i += 16) {\n            __m128i data = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&str[i]));\n            __m128i odd_mask = _mm_set1_epi8(1);\n            __m128i odd_digits = _mm_and_si128(data, odd_mask);\n            odd_digits = _mm_cmpeq_epi8(odd_digits, odd_mask);\n            odd_count += _mm_movemask_epi8(odd_digits);\n        }\n\n        // Process remaining characters\n        for (; i < len; ++i) {\n            if ((str[i] - '0') % 2 != 0) {\n                ++odd_count;\n            }\n        }\n\n        std::string output = \"the number of odd elements \" + std::to_string(odd_count) +\n                             \"n the str\" + std::to_string(odd_count) +\n                             \"ng \" + std::to_string(odd_count) +\n                             \" of the \" + std::to_string(odd_count) + \"nput.\";\n        result.push_back(output);\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_117_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n\nstd::vector<std::string> odd_count_simd(const std::vector<std::string> & lst) {\n    std::vector<std::string> result;\n    for (const auto& str : lst) {\n        int odd_count = 0;\n        int length = str.length();\n        int i = 0;\n\n        // Process 16 characters at a time\n        for (; i <= length - 16; i += 16) {\n            __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(str.data() + i));\n            __m128i odd_mask = _mm_set1_epi8(1);\n            __m128i odd_digits = _mm_and_si128(chunk, odd_mask);\n            odd_count += _mm_movemask_epi8(_mm_cmpeq_epi8(odd_digits, odd_mask));\n        }\n\n        // Process remaining characters\n        for (; i < length; ++i) {\n            if ((str[i] - '0') % 2 != 0) {\n                ++odd_count;\n            }\n        }\n\n        std::string output = \"the number of odd elements \" + std::to_string(odd_count) + \"n the str\" + std::to_string(odd_count) + \"ng \" + std::to_string(odd_count) + \" of the \" + std::to_string(odd_count) + \"nput.\";\n        result.push_back(output);\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_118_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <limits>\n\nint64_t minSubArraySum_simd(const std::vector<int64_t>& nums) {\n    int64_t min_sum = std::numeric_limits<int64_t>::max();\n    int64_t current_sum = 0;\n    size_t size = nums.size();\n    size_t i = 0;\n\n    // Process elements in chunks of 2\n    for (; i + 1 < size; i += 2) {\n        __m128i vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&nums[i]));\n        int64_t val1 = _mm_cvtsi128_si64(vec);\n        int64_t val2 = _mm_cvtsi128_si64(_mm_srli_si128(vec, 8));\n\n        current_sum += val1;\n        min_sum = std::min(min_sum, current_sum);\n        current_sum += val2;\n        min_sum = std::min(min_sum, current_sum);\n    }\n\n    // Process any remaining elements\n    for (; i < size; ++i) {\n        current_sum += nums[i];\n        min_sum = std::min(min_sum, current_sum);\n    }\n\n    return min_sum;\n}\n```"}
{"task_id": "SimdBench_118_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <limits>\n\nint64_t minSubArraySum_simd(const std::vector<int64_t>& nums) {\n    int64_t min_sum = std::numeric_limits<int64_t>::max();\n    int64_t current_sum = 0;\n    __m128i min_sum_vec = _mm_set1_epi64x(min_sum);\n    __m128i current_sum_vec = _mm_setzero_si128();\n\n    size_t size = nums.size();\n    size_t i = 0;\n\n    for (; i + 2 <= size; i += 2) {\n        __m128i nums_vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&nums[i]));\n        current_sum_vec = _mm_add_epi64(current_sum_vec, nums_vec);\n        min_sum_vec = _mm_min_epi64(min_sum_vec, current_sum_vec);\n    }\n\n    min_sum = _mm_cvtsi128_si64(min_sum_vec);\n\n    for (; i < size; ++i) {\n        current_sum += nums[i];\n        if (current_sum < min_sum) {\n            min_sum = current_sum;\n        }\n    }\n\n    return min_sum;\n}\n```"}
{"task_id": "SimdBench_118_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <limits>\n\nint64_t minSubArraySum_simd(const std::vector<int64_t>& nums) {\n    int64_t min_sum = std::numeric_limits<int64_t>::max();\n    int64_t current_sum = 0;\n    int64_t min_val = std::numeric_limits<int64_t>::max();\n\n    __m128i min_vec = _mm_set1_epi64x(min_val);\n    __m128i sum_vec = _mm_setzero_si128();\n\n    size_t size = nums.size();\n    size_t i = 0;\n\n    for (; i + 1 < size; i += 2) {\n        __m128i num_vec = _mm_set_epi64x(nums[i + 1], nums[i]);\n        min_vec = _mm_min_epi64(min_vec, num_vec);\n        sum_vec = _mm_add_epi64(sum_vec, num_vec);\n    }\n\n    if (i < size) {\n        __m128i num_vec = _mm_set_epi64x(nums[i], 0);\n        min_vec = _mm_min_epi64(min_vec, num_vec);\n        sum_vec = _mm_add_epi64(sum_vec, num_vec);\n    }\n\n    int64_t min_val_lo = _mm_cvtsi128_si64(min_vec);\n    int64_t min_val_hi = _mm_cvtsi128_si64(_mm_shuffle_epi32(min_vec, _MM_SHUFFLE(1, 0, 3, 2)));\n    min_val = std::min(min_val_lo, min_val_hi);\n\n    int64_t sum_val_lo = _mm_cvtsi128_si64(sum_vec);\n    int64_t sum_val_hi = _mm_cvtsi128_si64(_mm_shuffle_epi32(sum_vec, _MM_SHUFFLE(1, 0, 3, 2)));\n    current_sum = sum_val_lo + sum_val_hi;\n\n    min_sum = std::min(min_sum, current_sum);\n\n    for (size_t i = 0; i < size; ++i) {\n        current_sum = std::min(nums[i], current_sum + nums[i]);\n        min_sum = std::min(min_sum, current_sum);\n    }\n\n    return min_sum;\n}\n```"}
{"task_id": "SimdBench_118_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <limits>\n\nint64_t minSubArraySum_simd(const std::vector<int64_t>& nums) {\n    int64_t min_sum = std::numeric_limits<int64_t>::max();\n    int64_t current_sum = 0;\n\n    __m128i min_sum_vec = _mm_set1_epi64x(min_sum);\n    __m128i current_sum_vec = _mm_setzero_si128();\n\n    size_t size = nums.size();\n    size_t i = 0;\n\n    for (; i + 1 < size; i += 2) {\n        __m128i nums_vec = _mm_set_epi64x(nums[i + 1], nums[i]);\n        current_sum_vec = _mm_add_epi64(current_sum_vec, nums_vec);\n\n        __m128i temp_min_sum_vec = _mm_min_epi64(min_sum_vec, current_sum_vec);\n        min_sum_vec = _mm_min_epi64(temp_min_sum_vec, _mm_shuffle_epi32(current_sum_vec, _MM_SHUFFLE(1, 0, 3, 2)));\n    }\n\n    if (i < size) {\n        current_sum_vec = _mm_add_epi64(current_sum_vec, _mm_set_epi64x(0, nums[i]));\n        min_sum_vec = _mm_min_epi64(min_sum_vec, current_sum_vec);\n    }\n\n    min_sum = _mm_cvtsi128_si64(min_sum_vec);\n\n    return min_sum;\n}\n```"}
{"task_id": "SimdBench_118_SSE", "completion": "```cpp\nint64_t minSubArraySum_simd(const std::vector<int64_t>& nums) {\n    const int64_t* data = nums.data();\n    size_t size = nums.size();\n    size_t i = 0;\n\n    __m128i min_val = _mm_set1_epi64x(data[0]);\n\n    for (; i + 1 < size; i += 2) {\n        __m128i current = _mm_loadu_si128(reinterpret_cast<const __m128i*>(data + i));\n        min_val = _mm_min_epi64(min_val, current);\n    }\n\n    if (i < size) {\n        __m128i current = _mm_set1_epi64x(data[i]);\n        min_val = _mm_min_epi64(min_val, current);\n    }\n\n    int64_t min_values[2];\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(min_values), min_val);\n\n    return std::min(min_values[0], min_values[1]);\n}\n```"}
{"task_id": "SimdBench_119_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint max_fill_simd(const std::vector<std::vector<int>>& grid, int capacity) {\n    int total_water = 0;\n    int num_rows = grid.size();\n    int num_cols = grid[0].size();\n\n    for (int i = 0; i < num_rows; ++i) {\n        const std::vector<int>& row = grid[i];\n        int j = 0;\n\n        while (j + 4 <= num_cols) {\n            __m128i water = _mm_setzero_si128();\n            for (int k = 0; k < 4; ++k) {\n                water = _mm_add_epi32(water, _mm_set1_epi32(row[j + k]));\n            }\n            int sum = _mm_cvtsi128_si32(_mm_hadd_epi32(_mm_hadd_epi32(water, water), water));\n            total_water += sum;\n            j += 4;\n        }\n\n        while (j < num_cols) {\n            total_water += row[j];\n            ++j;\n        }\n    }\n\n    return (total_water + capacity - 1) / capacity;\n}\n```"}
{"task_id": "SimdBench_119_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint max_fill_simd(const std::vector<std::vector<int>>& grid, int capacity) {\n    int total_water = 0;\n    int num_rows = grid.size();\n    int num_cols = grid[0].size();\n\n    for (int i = 0; i < num_rows; ++i) {\n        const std::vector<int>& row = grid[i];\n        int j = 0;\n\n        while (j + 4 <= num_cols) {\n            __m128i water = _mm_setzero_si128();\n            for (int k = 0; k < 4; ++k) {\n                water = _mm_add_epi32(water, _mm_set1_epi32(row[j + k]));\n            }\n            int sum = _mm_cvtsi128_si32(_mm_hadd_epi32(water, water));\n            total_water += sum;\n            j += 4;\n        }\n\n        while (j < num_cols) {\n            total_water += row[j];\n            ++j;\n        }\n    }\n\n    return (total_water + capacity - 1) / capacity;\n}\n```"}
{"task_id": "SimdBench_119_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint max_fill_simd(const std::vector<std::vector<int>>& grid, int capacity) {\n    int total_water = 0;\n    int num_rows = grid.size();\n    int num_cols = grid[0].size();\n\n    for (int i = 0; i < num_rows; ++i) {\n        const int* row = grid[i].data();\n        int j = 0;\n\n        for (; j <= num_cols - 4; j += 4) {\n            __m128i water = _mm_loadu_si128(reinterpret_cast<const __m128i*>(row + j));\n            __m128i sum = _mm_sad_epu8(water, _mm_setzero_si128());\n            total_water += _mm_cvtsi128_si32(sum) + _mm_extract_epi16(sum, 4);\n        }\n\n        for (; j < num_cols; ++j) {\n            total_water += row[j];\n        }\n    }\n\n    return (total_water + capacity - 1) / capacity;\n}\n```"}
{"task_id": "SimdBench_119_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint max_fill_simd(const std::vector<std::vector<int>>& grid, int capacity) {\n    int total_water = 0;\n    int num_rows = grid.size();\n    int num_cols = grid[0].size();\n\n    for (int i = 0; i < num_rows; ++i) {\n        const int* row = grid[i].data();\n        int j = 0;\n\n        for (; j <= num_cols - 8; j += 8) {\n            __m128i water = _mm_loadu_si128(reinterpret_cast<const __m128i*>(row + j));\n            total_water += _mm_popcnt_u32(_mm_movemask_epi8(water));\n        }\n\n        for (; j < num_cols; ++j) {\n            total_water += row[j];\n        }\n    }\n\n    return (total_water + capacity - 1) / capacity;\n}\n```"}
{"task_id": "SimdBench_119_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint max_fill_simd(const std::vector<std::vector<int>>& grid, int capacity) {\n    int total_water = 0;\n    int num_rows = grid.size();\n    int num_cols = grid[0].size();\n\n    for (int i = 0; i < num_rows; ++i) {\n        const std::vector<int>& row = grid[i];\n        int j = 0;\n\n        while (j + 4 <= num_cols) {\n            __m128i water = _mm_setzero_si128();\n            for (int k = 0; k < 4; ++k) {\n                water = _mm_add_epi32(water, _mm_set1_epi32(row[j + k]));\n            }\n            int sum = _mm_extract_epi32(water, 0) + _mm_extract_epi32(water, 1) + _mm_extract_epi32(water, 2) + _mm_extract_epi32(water, 3);\n            total_water += sum;\n            j += 4;\n        }\n\n        while (j < num_cols) {\n            total_water += row[j];\n            ++j;\n        }\n    }\n\n    return (total_water + capacity - 1) / capacity;\n}\n```"}
{"task_id": "SimdBench_120_SSE", "completion": "```c++\nint64_t solution_simd(const std::vector<int16_t>& lst) {\n    int64_t sum = 0;\n    __m128i zero = _mm_setzero_si128();\n    __m128i mask = _mm_set_epi16(1, 0, 1, 0, 1, 0, 1, 0);\n\n    for (size_t i = 0; i < lst.size(); i += 8) {\n        __m128i data = _mm_loadu_si128((__m128i*)&lst[i]);\n        __m128i odd_mask = _mm_cmpgt_epi16(_mm_and_si128(data, mask), zero);\n        __m128i even_pos_mask = _mm_set_epi16(0, 1, 0, 1, 0, 1, 0, 1);\n        __m128i result = _mm_and_si128(odd_mask, even_pos_mask);\n        result = _mm_and_si128(result, data);\n\n        int16_t temp[8];\n        _mm_storeu_si128((__m128i*)temp, result);\n\n        for (int j = 0; j < 8; ++j) {\n            sum += temp[j];\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_120_SSE", "completion": "```cpp\nint64_t solution_simd(const std::vector<int16_t>& lst) {\n    int64_t sum = 0;\n    __m128i zero = _mm_setzero_si128();\n    __m128i odd_mask = _mm_set1_epi16(1);\n    __m128i even_pos_mask = _mm_set_epi16(0, 1, 0, 1, 0, 1, 0, 1);\n\n    for (size_t i = 0; i < lst.size(); i += 8) {\n        __m128i data = _mm_loadu_si128((__m128i*)&lst[i]);\n        __m128i odd_elements = _mm_and_si128(data, odd_mask);\n        __m128i even_pos_elements = _mm_and_si128(data, even_pos_mask);\n        __m128i result = _mm_and_si128(odd_elements, even_pos_elements);\n\n        int16_t temp[8];\n        _mm_storeu_si128((__m128i*)temp, result);\n\n        for (int j = 0; j < 8; ++j) {\n            sum += temp[j];\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_120_SSE", "completion": "```cpp\nint64_t solution_simd(const std::vector<int16_t>& lst) {\n    int64_t sum = 0;\n    __m128i zero = _mm_setzero_si128();\n    __m128i mask = _mm_set1_epi16(1);\n    __m128i sum_vec = _mm_setzero_si128();\n\n    for (size_t i = 0; i < lst.size(); i += 8) {\n        __m128i vec = _mm_loadu_si128((__m128i*)&lst[i]);\n        __m128i even_pos = _mm_and_si128(vec, mask);\n        __m128i odd_elements = _mm_andnot_si128(mask, vec);\n        __m128i result = _mm_and_si128(even_pos, odd_elements);\n        sum_vec = _mm_add_epi16(sum_vec, result);\n    }\n\n    alignas(16) int16_t temp[8];\n    _mm_store_si128((__m128i*)temp, sum_vec);\n\n    for (int i = 0; i < 8; ++i) {\n        sum += temp[i];\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_120_SSE", "completion": "```c++\nint64_t solution_simd(const std::vector<int16_t>& lst) {\n    int64_t sum = 0;\n    __m128i zero = _mm_setzero_si128();\n    __m128i odd_mask = _mm_set1_epi16(1);\n    __m128i even_pos_mask = _mm_setr_epi16(0, 1, 0, 1, 0, 1, 0, 1);\n\n    for (size_t i = 0; i < lst.size(); i += 8) {\n        __m128i data = _mm_loadu_si128((__m128i*)&lst[i]);\n        __m128i odd_elements = _mm_and_si128(data, odd_mask);\n        __m128i even_pos_elements = _mm_and_si128(data, even_pos_mask);\n        __m128i result = _mm_and_si128(odd_elements, even_pos_elements);\n\n        int16_t temp[8];\n        _mm_storeu_si128((__m128i*)temp, result);\n\n        for (int j = 0; j < 8; ++j) {\n            sum += temp[j];\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_120_SSE", "completion": "```c++\nint64_t solution_simd(const std::vector<int16_t>& lst) {\n    int64_t sum = 0;\n    __m128i zero = _mm_setzero_si128();\n    __m128i odd_mask = _mm_set1_epi16(1);\n    __m128i even_pos_mask = _mm_setr_epi16(1, 0, 1, 0, 1, 0, 1, 0);\n\n    for (size_t i = 0; i < lst.size(); i += 8) {\n        __m128i data = _mm_loadu_si128((__m128i*)&lst[i]);\n        __m128i odd_elements = _mm_and_si128(data, odd_mask);\n        __m128i even_pos_elements = _mm_and_si128(data, even_pos_mask);\n        __m128i result = _mm_and_si128(odd_elements, even_pos_elements);\n\n        int16_t temp[8];\n        _mm_storeu_si128((__m128i*)temp, result);\n\n        for (int j = 0; j < 8; ++j) {\n            sum += temp[j];\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_121_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint add_elements_simd(std::vector<int> arr, int k) {\n    int sum = 0;\n    int i = 0;\n\n    // Process 4 elements at a time using SSE2\n    for (; i <= k - 4; i += 4) {\n        __m128i vec = _mm_loadu_si128((__m128i*)&arr[i]);\n        __m128i mask = _mm_set1_epi32(99);\n        __m128i cmp = _mm_cmple_epi32(vec, mask);\n        __m128i result = _mm_and_si128(vec, cmp);\n\n        int temp[4];\n        _mm_storeu_si128((__m128i*)temp, result);\n\n        for (int j = 0; j < 4; ++j) {\n            sum += temp[j];\n        }\n    }\n\n    // Process remaining elements\n    for (; i < k; ++i) {\n        if (arr[i] <= 99) {\n            sum += arr[i];\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_121_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint add_elements_simd(std::vector<int> arr, int k) {\n    int sum = 0;\n    __m128i sum_vec = _mm_setzero_si128();\n\n    for (int i = 0; i < k; i += 4) {\n        __m128i vec = _mm_loadu_si128((__m128i*)&arr[i]);\n        __m128i mask = _mm_cmplt_epi32(vec, _mm_set1_epi32(100));\n        __m128i masked_vec = _mm_and_si128(vec, mask);\n        sum_vec = _mm_add_epi32(sum_vec, masked_vec);\n    }\n\n    int temp[4];\n    _mm_storeu_si128((__m128i*)temp, sum_vec);\n    sum = temp[0] + temp[1] + temp[2] + temp[3];\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_121_SSE", "completion": "```c++\nint add_elements_simd(std::vector<int> arr, int k) {\n    __m128i sum = _mm_setzero_si128();\n    __m128i mask = _mm_set1_epi32(99);\n    __m128i threshold = _mm_set1_epi32(10);\n\n    for (int i = 0; i < k; i += 4) {\n        __m128i vec = _mm_loadu_si128((__m128i*)&arr[i]);\n        __m128i cmp = _mm_cmpgt_epi32(mask, vec);\n        __m128i cmp2 = _mm_cmpgt_epi32(vec, threshold);\n        __m128i valid = _mm_and_si128(cmp, cmp2);\n        __m128i masked = _mm_and_si128(vec, valid);\n        sum = _mm_add_epi32(sum, masked);\n    }\n\n    int result[4];\n    _mm_storeu_si128((__m128i*)result, sum);\n    return result[0] + result[1] + result[2] + result[3];\n}\n```"}
{"task_id": "SimdBench_121_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint add_elements_simd(std::vector<int> arr, int k) {\n    int sum = 0;\n    __m128i sum_vec = _mm_setzero_si128();\n\n    for (int i = 0; i < k; i += 4) {\n        __m128i vec = _mm_loadu_si128((__m128i*)&arr[i]);\n        __m128i mask = _mm_cmpgt_epi32(vec, _mm_set1_epi32(9));\n        mask = _mm_andnot_si128(mask, _mm_cmpgt_epi32(_mm_set1_epi32(100), vec));\n        vec = _mm_and_si128(vec, mask);\n        sum_vec = _mm_add_epi32(sum_vec, vec);\n    }\n\n    alignas(16) int temp[4];\n    _mm_store_si128((__m128i*)temp, sum_vec);\n    sum = temp[0] + temp[1] + temp[2] + temp[3];\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_121_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint add_elements_simd(std::vector<int> arr, int k) {\n    int sum = 0;\n    __m128i sum_vec = _mm_setzero_si128();\n\n    for (int i = 0; i < k; i += 4) {\n        __m128i vec = _mm_loadu_si128((__m128i*)&arr[i]);\n        __m128i mask = _mm_cmpgt_epi32(vec, _mm_set1_epi32(9));\n        mask = _mm_andnot_si128(mask, _mm_cmpgt_epi32(_mm_set1_epi32(100), vec));\n        vec = _mm_and_si128(vec, mask);\n        sum_vec = _mm_add_epi32(sum_vec, vec);\n    }\n\n    alignas(16) int temp[4];\n    _mm_store_si128((__m128i*)temp, sum_vec);\n    sum = temp[0] + temp[1] + temp[2] + temp[3];\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_122_SSE", "completion": "```cpp\nbool is_sorted_simd(const std::vector<int> & lst) {\n    if (lst.size() < 2) return true;\n\n    __m128i prev = _mm_set1_epi32(lst[0]);\n    __m128i curr;\n    __m128i mask = _mm_set1_epi32(0xFFFFFFFF);\n\n    for (size_t i = 1; i < lst.size(); i += 4) {\n        curr = _mm_loadu_si128((__m128i*)&lst[i]);\n\n        __m128i cmp = _mm_cmplt_epi32(prev, curr);\n        if (_mm_movemask_epi8(cmp) != 0xFFFF) return false;\n\n        __m128i eq = _mm_cmpeq_epi32(prev, curr);\n        if (_mm_movemask_epi8(eq) != 0) {\n            __m128i shifted = _mm_slli_si128(eq, 4);\n            __m128i anded = _mm_and_si128(eq, shifted);\n            if (_mm_movemask_epi8(anded) != 0) return false;\n        }\n\n        prev = curr;\n    }\n\n    for (size_t i = lst.size() - (lst.size() % 4); i < lst.size(); ++i) {\n        if (lst[i] < lst[i - 1]) return false;\n        if (i > 1 && lst[i] == lst[i - 1] && lst[i] == lst[i - 2]) return false;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_122_SSE", "completion": "```cpp\nbool is_sorted_simd(const std::vector<int> & lst) {\n    const int size = lst.size();\n    if (size < 2) return true;\n\n    __m128i prev = _mm_set1_epi32(lst[0]);\n    __m128i curr;\n    __m128i mask;\n    __m128i dup_mask;\n\n    for (int i = 1; i < size; i += 4) {\n        if (i + 4 <= size) {\n            curr = _mm_loadu_si128((__m128i*)&lst[i]);\n        } else {\n            int temp[4] = {0};\n            for (int j = 0; j < size - i; ++j) {\n                temp[j] = lst[i + j];\n            }\n            curr = _mm_loadu_si128((__m128i*)temp);\n        }\n\n        mask = _mm_cmpgt_epi32(prev, curr);\n        if (_mm_movemask_epi8(mask) != 0) return false;\n\n        dup_mask = _mm_cmpeq_epi32(prev, curr);\n        if (_mm_movemask_epi8(dup_mask) != 0) {\n            for (int j = 0; j < 4; ++j) {\n                if (lst[i + j] == lst[i + j - 1]) return false;\n            }\n        }\n\n        prev = curr;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_122_SSE", "completion": "```cpp\nbool is_sorted_simd(const std::vector<int> & lst) {\n    if (lst.size() < 2) return true;\n\n    __m128i prev = _mm_set1_epi32(lst[0]);\n    __m128i curr;\n    __m128i mask = _mm_set1_epi32(0xFFFFFFFF);\n\n    for (size_t i = 1; i < lst.size(); i += 4) {\n        curr = _mm_loadu_si128((__m128i*)&lst[i]);\n\n        __m128i cmp = _mm_cmpgt_epi32(prev, curr);\n        if (_mm_movemask_epi8(cmp) != 0) return false;\n\n        __m128i eq = _mm_cmpeq_epi32(prev, curr);\n        if (_mm_movemask_epi8(eq) != 0) {\n            __m128i shifted = _mm_slli_si128(eq, 4);\n            __m128i anded = _mm_and_si128(eq, shifted);\n            if (_mm_movemask_epi8(anded) != 0) return false;\n        }\n\n        prev = curr;\n    }\n\n    for (size_t i = lst.size() - (lst.size() % 4); i < lst.size(); ++i) {\n        if (lst[i] < lst[i - 1]) return false;\n        if (i > 1 && lst[i] == lst[i - 1] && lst[i] == lst[i - 2]) return false;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_122_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nbool is_sorted_simd(const std::vector<int> & lst) {\n    if (lst.size() < 2) return true;\n\n    __m128i prev = _mm_set1_epi32(lst[0]);\n    __m128i curr;\n    __m128i mask = _mm_set1_epi32(0xFFFFFFFF);\n\n    for (size_t i = 1; i < lst.size(); i += 4) {\n        curr = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&lst[i]));\n\n        __m128i cmp = _mm_cmplt_epi32(prev, curr);\n        if (_mm_movemask_epi8(cmp) != 0xFFFF) return false;\n\n        __m128i eq = _mm_cmpeq_epi32(prev, curr);\n        if (_mm_movemask_epi8(eq) != 0) {\n            __m128i shifted = _mm_slli_si128(eq, 4);\n            __m128i anded = _mm_and_si128(eq, shifted);\n            if (_mm_movemask_epi8(anded) != 0) return false;\n        }\n\n        prev = curr;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_122_SSE", "completion": "```cpp\nbool is_sorted_simd(const std::vector<int> & lst) {\n    if (lst.size() < 2) return true;\n\n    __m128i prev = _mm_set1_epi32(lst[0]);\n    __m128i curr;\n    __m128i mask = _mm_set1_epi32(0xFFFFFFFF);\n\n    for (size_t i = 1; i < lst.size(); i += 4) {\n        curr = _mm_loadu_si128((__m128i*)&lst[i]);\n\n        __m128i cmp = _mm_cmpgt_epi32(prev, curr);\n        if (_mm_movemask_epi8(cmp) != 0) return false;\n\n        __m128i eq = _mm_cmpeq_epi32(prev, curr);\n        if (_mm_movemask_epi8(eq) != 0) {\n            __m128i shifted = _mm_slli_si128(eq, 4);\n            __m128i anded = _mm_and_si128(eq, shifted);\n            if (_mm_movemask_epi8(anded) != 0) return false;\n        }\n\n        prev = curr;\n    }\n\n    for (size_t i = lst.size() - (lst.size() % 4); i < lst.size(); ++i) {\n        if (lst[i] < lst[i - 1]) return false;\n        if (i > 1 && lst[i] == lst[i - 1] && lst[i] == lst[i - 2]) return false;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_123_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint prod_signs_simd(const std::vector<int> & arr) {\n    if (arr.empty()) {\n        return -32768;\n    }\n\n    __m128i sum = _mm_setzero_si128();\n    __m128i signs = _mm_set1_epi32(1);\n\n    int size = arr.size();\n    int i = 0;\n\n    for (; i <= size - 4; i += 4) {\n        __m128i v = _mm_loadu_si128((__m128i*)&arr[i]);\n        __m128i abs_v = _mm_abs_epi32(v);\n        sum = _mm_add_epi32(sum, abs_v);\n\n        __m128i sign_v = _mm_sign_epi32(_mm_set1_epi32(1), v);\n        signs = _mm_mullo_epi32(signs, sign_v);\n    }\n\n    int sum_arr[4];\n    _mm_storeu_si128((__m128i*)sum_arr, sum);\n    int total_sum = sum_arr[0] + sum_arr[1] + sum_arr[2] + sum_arr[3];\n\n    int sign_arr[4];\n    _mm_storeu_si128((__m128i*)sign_arr, signs);\n    int total_sign = sign_arr[0] * sign_arr[1] * sign_arr[2] * sign_arr[3];\n\n    for (; i < size; ++i) {\n        total_sum += abs(arr[i]);\n        total_sign *= (arr[i] > 0) - (arr[i] < 0);\n    }\n\n    return total_sum * total_sign;\n}\n```"}
{"task_id": "SimdBench_123_SSE", "completion": "```c++\nint prod_signs_simd(const std::vector<int> & arr) {\n    if (arr.empty()) {\n        return -32768;\n    }\n\n    __m128i sum = _mm_setzero_si128();\n    __m128i signs = _mm_set1_epi32(1);\n\n    int i = 0;\n    for (; i <= (int)arr.size() - 4; i += 4) {\n        __m128i v = _mm_loadu_si128((__m128i*)&arr[i]);\n        __m128i abs_v = _mm_abs_epi32(v);\n        sum = _mm_add_epi32(sum, abs_v);\n\n        __m128i sign_v = _mm_sign_epi32(_mm_set1_epi32(1), v);\n        signs = _mm_mullo_epi32(signs, sign_v);\n    }\n\n    int sum_arr[4];\n    _mm_storeu_si128((__m128i*)sum_arr, sum);\n    int total_sum = sum_arr[0] + sum_arr[1] + sum_arr[2] + sum_arr[3];\n\n    int sign_arr[4];\n    _mm_storeu_si128((__m128i*)sign_arr, signs);\n    int total_sign = sign_arr[0] * sign_arr[1] * sign_arr[2] * sign_arr[3];\n\n    for (; i < (int)arr.size(); ++i) {\n        total_sum += abs(arr[i]);\n        total_sign *= (arr[i] > 0) - (arr[i] < 0);\n    }\n\n    return total_sum * total_sign;\n}\n```"}
{"task_id": "SimdBench_123_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint prod_signs_simd(const std::vector<int>& arr) {\n    if (arr.empty()) {\n        return -32768;\n    }\n\n    __m128i sumVec = _mm_setzero_si128();\n    __m128i signVec = _mm_set1_epi32(1);\n    __m128i zeroVec = _mm_setzero_si128();\n    __m128i oneVec = _mm_set1_epi32(1);\n    __m128i negOneVec = _mm_set1_epi32(-1);\n\n    int size = arr.size();\n    int i = 0;\n\n    for (; i <= size - 4; i += 4) {\n        __m128i vec = _mm_loadu_si128((__m128i*)&arr[i]);\n\n        __m128i absVec = _mm_abs_epi32(vec);\n        sumVec = _mm_add_epi32(sumVec, absVec);\n\n        __m128i signMask = _mm_cmpgt_epi32(zeroVec, vec);\n        __m128i sign = _mm_blendv_epi8(oneVec, negOneVec, signMask);\n        signVec = _mm_mullo_epi32(signVec, sign);\n    }\n\n    int sum = _mm_cvtsi128_si32(_mm_hadd_epi32(_mm_hadd_epi32(sumVec, sumVec), sumVec));\n    int sign = _mm_cvtsi128_si32(signVec);\n\n    for (; i < size; ++i) {\n        sum += abs(arr[i]);\n        sign *= (arr[i] > 0) - (arr[i] < 0);\n    }\n\n    return sum * sign;\n}\n```"}
{"task_id": "SimdBench_123_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint prod_signs_simd(const std::vector<int> & arr) {\n    if (arr.empty()) {\n        return -32768;\n    }\n\n    __m128i sum = _mm_setzero_si128();\n    __m128i signs = _mm_set1_epi32(1);\n\n    int size = arr.size();\n    int i = 0;\n\n    for (; i <= size - 4; i += 4) {\n        __m128i v = _mm_loadu_si128((__m128i*)&arr[i]);\n        __m128i abs_v = _mm_abs_epi32(v);\n        sum = _mm_add_epi32(sum, abs_v);\n\n        __m128i sign_v = _mm_sign_epi32(_mm_set1_epi32(1), v);\n        signs = _mm_mullo_epi32(signs, sign_v);\n    }\n\n    int sum_arr[4];\n    _mm_storeu_si128((__m128i*)sum_arr, sum);\n    int total_sum = sum_arr[0] + sum_arr[1] + sum_arr[2] + sum_arr[3];\n\n    int sign_arr[4];\n    _mm_storeu_si128((__m128i*)sign_arr, signs);\n    int total_sign = sign_arr[0] * sign_arr[1] * sign_arr[2] * sign_arr[3];\n\n    for (; i < size; ++i) {\n        total_sum += abs(arr[i]);\n        total_sign *= (arr[i] > 0) - (arr[i] < 0);\n    }\n\n    return total_sum * total_sign;\n}\n```"}
{"task_id": "SimdBench_123_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint prod_signs_simd(const std::vector<int>& arr) {\n    if (arr.empty()) {\n        return -32768;\n    }\n\n    __m128i sumVec = _mm_setzero_si128();\n    __m128i signVec = _mm_set1_epi32(1);\n\n    int size = arr.size();\n    int i = 0;\n\n    for (; i <= size - 4; i += 4) {\n        __m128i vec = _mm_loadu_si128((__m128i*)&arr[i]);\n\n        __m128i absVec = _mm_abs_epi32(vec);\n        sumVec = _mm_add_epi32(sumVec, absVec);\n\n        __m128i signMask = _mm_cmpeq_epi32(vec, _mm_setzero_si128());\n        __m128i signVecTemp = _mm_andnot_si128(signMask, vec);\n        signVecTemp = _mm_srai_epi32(signVecTemp, 31);\n        signVecTemp = _mm_add_epi32(signVecTemp, _mm_set1_epi32(1));\n        signVec = _mm_mullo_epi32(signVec, signVecTemp);\n    }\n\n    int sum = _mm_cvtsi128_si32(sumVec) + _mm_cvtsi128_si32(_mm_srli_si128(sumVec, 4)) +\n              _mm_cvtsi128_si32(_mm_srli_si128(sumVec, 8)) + _mm_cvtsi128_si32(_mm_srli_si128(sumVec, 12));\n\n    int sign = _mm_cvtsi128_si32(signVec);\n\n    for (; i < size; ++i) {\n        sum += abs(arr[i]);\n        sign *= (arr[i] == 0) ? 0 : (arr[i] > 0) ? 1 : -1;\n    }\n\n    return sum * sign;\n}\n```"}
{"task_id": "SimdBench_124_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n#include <limits>\n\nstd::vector<int> minPath_simd(const std::vector<std::vector<int>>& grid, int k) {\n    int N = grid.size();\n    std::vector<int> minPath(k, std::numeric_limits<int>::max());\n    std::vector<int> currentPath(k);\n\n    auto isValid = [&](int x, int y) {\n        return x >= 0 && x < N && y >= 0 && y < N;\n    };\n\n    auto dfs = [&](auto&& dfs, int x, int y, int step) -> void {\n        if (step == k) {\n            if (currentPath < minPath) {\n                minPath = currentPath;\n            }\n            return;\n        }\n\n        currentPath[step] = grid[x][y];\n\n        int dx[] = {-1, 1, 0, 0};\n        int dy[] = {0, 0, -1, 1};\n\n        for (int i = 0; i < 4; ++i) {\n            int nx = x + dx[i];\n            int ny = y + dy[i];\n            if (isValid(nx, ny)) {\n                dfs(dfs, nx, ny, step + 1);\n            }\n        }\n    };\n\n    for (int i = 0; i < N; ++i) {\n        for (int j = 0; j < N; ++j) {\n            dfs(dfs, i, j, 0);\n        }\n    }\n\n    return minPath;\n}\n```"}
{"task_id": "SimdBench_124_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n#include <limits>\n\nstd::vector<int> minPath_simd(const std::vector<std::vector<int>>& grid, int k) {\n    int N = grid.size();\n    std::vector<int> minPath(k, std::numeric_limits<int>::max());\n    std::vector<int> currentPath(k);\n\n    for (int startRow = 0; startRow < N; ++startRow) {\n        for (int startCol = 0; startCol < N; ++startCol) {\n            currentPath[0] = grid[startRow][startCol];\n            std::vector<std::pair<int, int>> stack = {{startRow, startCol}};\n            std::vector<std::pair<int, int>> directions = {{-1, 0}, {1, 0}, {0, -1}, {0, 1}};\n\n            while (!stack.empty()) {\n                auto [row, col] = stack.back();\n                stack.pop_back();\n                int pathLength = stack.size() + 1;\n\n                if (pathLength == k) {\n                    if (currentPath < minPath) {\n                        minPath = currentPath;\n                    }\n                    continue;\n                }\n\n                for (auto [dr, dc] : directions) {\n                    int newRow = row + dr;\n                    int newCol = col + dc;\n                    if (newRow >= 0 && newRow < N && newCol >= 0 && newCol < N) {\n                        currentPath[pathLength] = grid[newRow][newCol];\n                        stack.push_back({newRow, newCol});\n                    }\n                }\n            }\n        }\n    }\n\n    return minPath;\n}\n```"}
{"task_id": "SimdBench_124_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n#include <limits>\n\nstd::vector<int> minPath_simd(const std::vector<std::vector<int>>& grid, int k) {\n    int N = grid.size();\n    std::vector<int> minPath(k, std::numeric_limits<int>::max());\n    std::vector<int> currentPath(k);\n\n    auto isValid = [&](int x, int y) {\n        return x >= 0 && x < N && y >= 0 && y < N;\n    };\n\n    auto dfs = [&](auto&& dfs, int x, int y, int step) -> void {\n        if (step == k) {\n            if (currentPath < minPath) {\n                minPath = currentPath;\n            }\n            return;\n        }\n\n        int dx[] = {-1, 1, 0, 0};\n        int dy[] = {0, 0, -1, 1};\n\n        for (int i = 0; i < 4; ++i) {\n            int nx = x + dx[i];\n            int ny = y + dy[i];\n            if (isValid(nx, ny)) {\n                currentPath[step] = grid[nx][ny];\n                dfs(dfs, nx, ny, step + 1);\n            }\n        }\n    };\n\n    for (int i = 0; i < N; ++i) {\n        for (int j = 0; j < N; ++j) {\n            currentPath[0] = grid[i][j];\n            dfs(dfs, i, j, 1);\n        }\n    }\n\n    return minPath;\n}\n```"}
{"task_id": "SimdBench_124_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n#include <limits>\n\nstd::vector<int> minPath_simd(const std::vector<std::vector<int>>& grid, int k) {\n    int N = grid.size();\n    std::vector<int> minPath(k, std::numeric_limits<int>::max());\n    std::vector<int> currentPath(k);\n\n    for (int startRow = 0; startRow < N; ++startRow) {\n        for (int startCol = 0; startCol < N; ++startCol) {\n            currentPath[0] = grid[startRow][startCol];\n            std::vector<std::pair<int, int>> stack = {{startRow, startCol}};\n\n            while (!stack.empty()) {\n                auto [row, col] = stack.back();\n                stack.pop_back();\n\n                if (stack.size() == k - 1) {\n                    for (int dr = -1; dr <= 1; ++dr) {\n                        for (int dc = -1; dc <= 1; ++dc) {\n                            if (dr == 0 && dc == 0) continue;\n                            int newRow = row + dr;\n                            int newCol = col + dc;\n                            if (newRow >= 0 && newRow < N && newCol >= 0 && newCol < N) {\n                                currentPath[k - 1] = grid[newRow][newCol];\n                                if (std::lexicographical_compare(currentPath.begin(), currentPath.end(), minPath.begin(), minPath.end())) {\n                                    minPath = currentPath;\n                                }\n                            }\n                        }\n                    }\n                } else {\n                    for (int dr = -1; dr <= 1; ++dr) {\n                        for (int dc = -1; dc <= 1; ++dc) {\n                            if (dr == 0 && dc == 0) continue;\n                            int newRow = row + dr;\n                            int newCol = col + dc;\n                            if (newRow >= 0 && newRow < N && newCol >= 0 && newCol < N) {\n                                currentPath[stack.size()] = grid[newRow][newCol];\n                                stack.emplace_back(newRow, newCol);\n                            }\n                        }\n                    }\n                }\n            }\n        }\n    }\n\n    return minPath;\n}\n```"}
{"task_id": "SimdBench_124_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n#include <limits>\n\nstd::vector<int> minPath_simd(const std::vector<std::vector<int>>& grid, int k) {\n    int N = grid.size();\n    std::vector<int> minPath(k, std::numeric_limits<int>::max());\n    std::vector<int> currentPath(k);\n\n    auto isValid = [&](int x, int y) {\n        return x >= 0 && x < N && y >= 0 && y < N;\n    };\n\n    auto dfs = [&](auto&& self, int x, int y, int step) -> void {\n        if (step == k) {\n            if (currentPath < minPath) {\n                minPath = currentPath;\n            }\n            return;\n        }\n\n        currentPath[step] = grid[x][y];\n\n        int dx[] = {-1, 1, 0, 0};\n        int dy[] = {0, 0, -1, 1};\n\n        for (int i = 0; i < 4; ++i) {\n            int nx = x + dx[i];\n            int ny = y + dy[i];\n            if (isValid(nx, ny)) {\n                self(self, nx, ny, step + 1);\n            }\n        }\n    };\n\n    for (int i = 0; i < N; ++i) {\n        for (int j = 0; j < N; ++j) {\n            dfs(dfs, i, j, 0);\n        }\n    }\n\n    return minPath;\n}\n```"}
{"task_id": "SimdBench_125_SSE", "completion": "```c\nuint64_t digits_simd(uint64_t n) {\n    __m128i mask = _mm_set1_epi8(0x0F);\n    __m128i odd_mask = _mm_set1_epi8(0x01);\n    __m128i product = _mm_set1_epi64x(1);\n    __m128i zero = _mm_setzero_si128();\n    __m128i all_even = _mm_set1_epi8(1);\n\n    while (n > 0) {\n        __m128i digits = _mm_set1_epi64x(n);\n        digits = _mm_and_si128(digits, mask);\n        __m128i odd_digits = _mm_and_si128(digits, odd_mask);\n        __m128i is_odd = _mm_cmpeq_epi8(odd_digits, odd_mask);\n        __m128i odd_product = _mm_and_si128(digits, is_odd);\n        product = _mm_mullo_epi16(product, odd_product);\n        all_even = _mm_andnot_si128(is_odd, all_even);\n        n /= 10;\n    }\n\n    uint64_t result = 1;\n    for (int i = 0; i < 2; ++i) {\n        result *= ((uint64_t*)(&product))[i];\n    }\n\n    if (_mm_movemask_epi8(all_even) == 0xFFFF) {\n        return 0;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_125_SSE", "completion": "```cpp\nuint64_t digits_simd(uint64_t n) {\n    __m128i mask = _mm_set1_epi8(0x0F);\n    __m128i odd_mask = _mm_set1_epi8(0x01);\n    __m128i product = _mm_set1_epi8(1);\n    __m128i zero = _mm_setzero_si128();\n\n    while (n > 0) {\n        __m128i digits = _mm_set1_epi64x(n);\n        digits = _mm_and_si128(digits, mask);\n        __m128i odd_digits = _mm_and_si128(digits, odd_mask);\n        odd_digits = _mm_cmpeq_epi8(odd_digits, odd_mask);\n        odd_digits = _mm_and_si128(odd_digits, digits);\n        product = _mm_mullo_epi16(product, odd_digits);\n        n /= 10;\n    }\n\n    uint64_t result = 1;\n    for (int i = 0; i < 8; ++i) {\n        result *= ((uint8_t*)&product)[i];\n    }\n\n    return result == 1 ? 0 : result;\n}\n```"}
{"task_id": "SimdBench_125_SSE", "completion": "```cpp\nuint64_t digits_simd(uint64_t n) {\n    __m128i mask = _mm_set1_epi8(0x0F);\n    __m128i odd_mask = _mm_set1_epi8(0x01);\n    __m128i product = _mm_set1_epi8(1);\n    __m128i zero = _mm_setzero_si128();\n\n    while (n > 0) {\n        __m128i digits = _mm_set1_epi64x(n);\n        digits = _mm_and_si128(digits, mask);\n        __m128i odd_digits = _mm_and_si128(digits, odd_mask);\n        odd_digits = _mm_cmpeq_epi8(odd_digits, odd_mask);\n        odd_digits = _mm_and_si128(odd_digits, digits);\n        product = _mm_mullo_epi16(product, odd_digits);\n        n /= 10;\n    }\n\n    uint64_t result = 1;\n    for (int i = 0; i < 8; ++i) {\n        result *= ((uint8_t*)&product)[i];\n    }\n\n    return result == 1 ? 0 : result;\n}\n```"}
{"task_id": "SimdBench_125_SSE", "completion": "```c\nuint64_t digits_simd(uint64_t n) {\n    __m128i zero = _mm_setzero_si128();\n    __m128i ones = _mm_set1_epi8(1);\n    __m128i twos = _mm_set1_epi8(2);\n    __m128i fives = _mm_set1_epi8(5);\n    __m128i sevens = _mm_set1_epi8(7);\n    __m128i nines = _mm_set1_epi8(9);\n\n    __m128i product = _mm_set1_epi8(1);\n\n    while (n > 0) {\n        uint8_t digit = n % 10;\n        n /= 10;\n\n        __m128i d = _mm_set1_epi8(digit);\n\n        __m128i is_odd = _mm_or_si128(\n            _mm_cmpeq_epi8(d, ones),\n            _mm_or_si128(\n                _mm_cmpeq_epi8(d, fives),\n                _mm_or_si128(\n                    _mm_cmpeq_epi8(d, sevens),\n                    _mm_cmpeq_epi8(d, nines)\n                )\n            )\n        );\n\n        __m128i odd_product = _mm_and_si128(is_odd, d);\n        product = _mm_mullo_epi16(product, odd_product);\n    }\n\n    uint64_t result = 1;\n    for (int i = 0; i < 16; ++i) {\n        result *= ((uint8_t*)&product)[i];\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_125_SSE", "completion": "```c\nuint64_t digits_simd(uint64_t n) {\n    __m128i mask = _mm_set1_epi8(0x0F);\n    __m128i odd_mask = _mm_set1_epi8(0x01);\n    __m128i zero = _mm_setzero_si128();\n    __m128i product = _mm_set1_epi32(1);\n\n    while (n > 0) {\n        __m128i digits = _mm_set1_epi64x(n);\n        digits = _mm_and_si128(digits, mask);\n        __m128i odd_digits = _mm_and_si128(digits, odd_mask);\n        odd_digits = _mm_cmpeq_epi8(odd_digits, odd_mask);\n        odd_digits = _mm_and_si128(odd_digits, digits);\n\n        __m128i odd_product = _mm_and_si128(odd_digits, _mm_set1_epi8(0xFF));\n        odd_product = _mm_mullo_epi16(odd_product, _mm_set1_epi16(1));\n        odd_product = _mm_madd_epi16(odd_product, _mm_set1_epi16(1));\n\n        product = _mm_mullo_epi32(product, odd_product);\n\n        n /= 10;\n    }\n\n    uint32_t result[4];\n    _mm_storeu_si128((__m128i*)result, product);\n    return result[0] * result[1] * result[2] * result[3];\n}\n```"}
{"task_id": "SimdBench_126_SSE", "completion": "```cpp\nuint64_t sum_squares_simd(const std::vector<float> & lst) {\n    uint64_t sum = 0;\n    __m128 sum_vec = _mm_setzero_ps();\n    __m128 ceil_vec = _mm_set1_ps(1.0f);\n    __m128i mask = _mm_set1_epi32(0x7FFFFFFF);\n\n    size_t i = 0;\n    for (; i <= lst.size() - 4; i += 4) {\n        __m128 vec = _mm_loadu_ps(&lst[i]);\n        vec = _mm_add_ps(vec, ceil_vec);\n        __m128i int_vec = _mm_cvtps_epi32(vec);\n        __m128i abs_vec = _mm_and_si128(int_vec, mask);\n        __m128 float_vec = _mm_cvtepi32_ps(abs_vec);\n        __m128 sq_vec = _mm_mul_ps(float_vec, float_vec);\n        sum_vec = _mm_add_ps(sum_vec, sq_vec);\n    }\n\n    float temp[4];\n    _mm_storeu_ps(temp, sum_vec);\n    sum = temp[0] + temp[1] + temp[2] + temp[3];\n\n    for (; i < lst.size(); ++i) {\n        float val = lst[i] + 1.0f;\n        int int_val = static_cast<int>(val);\n        sum += int_val * int_val;\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_126_SSE", "completion": "```cpp\nuint64_t sum_squares_simd(const std::vector<float> & lst) {\n    uint64_t sum = 0;\n    __m128 sum_vec = _mm_setzero_ps();\n    __m128 ceil_vec = _mm_set1_ps(0.999999f);\n    __m128i mask = _mm_set1_epi32(0x7fffffff);\n\n    size_t i = 0;\n    for (; i + 3 < lst.size(); i += 4) {\n        __m128 vec = _mm_loadu_ps(&lst[i]);\n        vec = _mm_add_ps(vec, ceil_vec);\n        __m128i int_vec = _mm_cvtps_epi32(vec);\n        int_vec = _mm_and_si128(int_vec, mask);\n        __m128 float_vec = _mm_cvtepi32_ps(int_vec);\n        __m128 sq_vec = _mm_mul_ps(float_vec, float_vec);\n        sum_vec = _mm_add_ps(sum_vec, sq_vec);\n    }\n\n    float temp[4];\n    _mm_storeu_ps(temp, sum_vec);\n    sum = temp[0] + temp[1] + temp[2] + temp[3];\n\n    for (; i < lst.size(); ++i) {\n        float val = lst[i] + 0.999999f;\n        int int_val = static_cast<int>(val);\n        sum += int_val * int_val;\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_126_SSE", "completion": "```cpp\nuint64_t sum_squares_simd(const std::vector<float> & lst) {\n    uint64_t sum = 0;\n    __m128 sum_vec = _mm_setzero_ps();\n    __m128 ceil_vec = _mm_set1_ps(1.0f);\n    __m128i mask = _mm_set1_epi32(0x7FFFFFFF);\n\n    size_t i = 0;\n    for (; i <= lst.size() - 4; i += 4) {\n        __m128 vec = _mm_loadu_ps(&lst[i]);\n        vec = _mm_add_ps(vec, ceil_vec);\n        __m128i int_vec = _mm_cvtps_epi32(vec);\n        int_vec = _mm_and_si128(int_vec, mask);\n        __m128 float_vec = _mm_cvtepi32_ps(int_vec);\n        __m128 sq_vec = _mm_mul_ps(float_vec, float_vec);\n        sum_vec = _mm_add_ps(sum_vec, sq_vec);\n    }\n\n    float temp[4];\n    _mm_storeu_ps(temp, sum_vec);\n    sum = temp[0] + temp[1] + temp[2] + temp[3];\n\n    for (; i < lst.size(); ++i) {\n        float val = lst[i] + 1.0f;\n        int int_val = static_cast<int>(val);\n        sum += int_val * int_val;\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_126_SSE", "completion": "```cpp\nuint64_t sum_squares_simd(const std::vector<float> & lst) {\n    uint64_t sum = 0;\n    __m128 sum_vec = _mm_setzero_ps();\n    __m128 ceil_vec = _mm_set1_ps(1.0f);\n    __m128i mask = _mm_set1_epi32(0x7FFFFFFF);\n\n    size_t i = 0;\n    for (; i + 3 < lst.size(); i += 4) {\n        __m128 vec = _mm_loadu_ps(&lst[i]);\n        vec = _mm_add_ps(vec, ceil_vec);\n        vec = _mm_and_ps(vec, _mm_castsi128_ps(mask));\n        vec = _mm_mul_ps(vec, vec);\n        sum_vec = _mm_add_ps(sum_vec, vec);\n    }\n\n    float temp[4];\n    _mm_storeu_ps(temp, sum_vec);\n    sum = temp[0] + temp[1] + temp[2] + temp[3];\n\n    for (; i < lst.size(); ++i) {\n        float val = lst[i] + 1.0f;\n        val = (val > 0) ? val : 0;\n        sum += val * val;\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_126_SSE", "completion": "```c++\nuint64_t sum_squares_simd(const std::vector<float> & lst) {\n    uint64_t sum = 0;\n    __m128 sum_vec = _mm_setzero_ps();\n    __m128 ceil_vec = _mm_set1_ps(1.0f);\n    __m128i mask = _mm_set1_epi32(0x7FFFFFFF);\n\n    size_t i = 0;\n    for (; i + 3 < lst.size(); i += 4) {\n        __m128 vec = _mm_loadu_ps(&lst[i]);\n        vec = _mm_add_ps(vec, ceil_vec);\n        __m128i int_vec = _mm_cvtps_epi32(vec);\n        int_vec = _mm_and_si128(int_vec, mask);\n        __m128 float_vec = _mm_cvtepi32_ps(int_vec);\n        __m128 sq_vec = _mm_mul_ps(float_vec, float_vec);\n        sum_vec = _mm_add_ps(sum_vec, sq_vec);\n    }\n\n    float temp[4];\n    _mm_storeu_ps(temp, sum_vec);\n    sum = temp[0] + temp[1] + temp[2] + temp[3];\n\n    for (; i < lst.size(); ++i) {\n        float val = ceilf(lst[i]);\n        sum += val * val;\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_127_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint can_arrange_simd(const std::vector<int>& arr) {\n    int n = arr.size();\n    if (n < 2) return -1;\n\n    __m128i prev = _mm_set1_epi32(arr[0]);\n    __m128i idx = _mm_set_epi32(3, 2, 1, 0);\n    __m128i inc = _mm_set1_epi32(4);\n\n    for (int i = 1; i < n; i += 4) {\n        __m128i curr = _mm_loadu_si128((__m128i*)&arr[i]);\n        __m128i mask = _mm_cmpgt_epi32(prev, curr);\n        int mask_bits = _mm_movemask_epi8(mask);\n\n        if (mask_bits) {\n            __m128i result = _mm_and_si128(mask, idx);\n            int result_bits = _mm_movemask_epi8(result);\n            int pos = __builtin_ctz(result_bits) / 4;\n            return i + pos;\n        }\n\n        prev = curr;\n        idx = _mm_add_epi32(idx, inc);\n    }\n\n    return -1;\n}\n```"}
{"task_id": "SimdBench_127_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint can_arrange_simd(const std::vector<int>& arr) {\n    int n = arr.size();\n    if (n < 2) return -1;\n\n    __m128i prev = _mm_set1_epi32(arr[0]);\n    int index = -1;\n\n    for (int i = 1; i < n; i += 4) {\n        __m128i current = _mm_loadu_si128((__m128i*)&arr[i]);\n        __m128i cmp = _mm_cmpgt_epi32(prev, current);\n\n        int mask = _mm_movemask_epi8(cmp);\n        if (mask != 0) {\n            for (int j = 0; j < 4; ++j) {\n                if (mask & (0x01010101 << (j * 4))) {\n                    index = i + j;\n                    break;\n                }\n            }\n        }\n\n        prev = current;\n    }\n\n    return index;\n}\n```"}
{"task_id": "SimdBench_127_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint can_arrange_simd(const std::vector<int>& arr) {\n    int n = arr.size();\n    if (n < 2) return -1;\n\n    __m128i prev = _mm_set1_epi32(arr[0]);\n    __m128i idx = _mm_set_epi32(3, 2, 1, 0);\n    __m128i inc = _mm_set1_epi32(4);\n\n    for (int i = 1; i < n; i += 4) {\n        __m128i curr = _mm_loadu_si128((__m128i*)&arr[i]);\n        __m128i cmp = _mm_cmpgt_epi32(prev, curr);\n        int mask = _mm_movemask_epi8(cmp);\n\n        if (mask != 0) {\n            __m128i result = _mm_add_epi32(idx, _mm_set1_epi32(i));\n            int idx0 = _mm_extract_epi32(result, 0);\n            int idx1 = _mm_extract_epi32(result, 1);\n            int idx2 = _mm_extract_epi32(result, 2);\n            int idx3 = _mm_extract_epi32(result, 3);\n\n            if (mask & 0xFF) return idx0;\n            if (mask & 0xFF00) return idx1;\n            if (mask & 0xFF0000) return idx2;\n            if (mask & 0xFF000000) return idx3;\n        }\n\n        prev = curr;\n        idx = _mm_add_epi32(idx, inc);\n    }\n\n    return -1;\n}\n```"}
{"task_id": "SimdBench_127_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint can_arrange_simd(const std::vector<int>& arr) {\n    int n = arr.size();\n    if (n < 2) return -1;\n\n    __m128i prev = _mm_set1_epi32(arr[0]);\n    __m128i idx = _mm_set_epi32(3, 2, 1, 0);\n    __m128i inc = _mm_set1_epi32(4);\n\n    for (int i = 1; i < n; i += 4) {\n        __m128i curr = _mm_loadu_si128((__m128i*)&arr[i]);\n        __m128i mask = _mm_cmpgt_epi32(prev, curr);\n        int mask_bits = _mm_movemask_epi8(mask);\n\n        if (mask_bits) {\n            __m128i result = _mm_add_epi32(idx, _mm_set1_epi32(i));\n            int indices[4];\n            _mm_storeu_si128((__m128i*)indices, result);\n\n            for (int j = 0; j < 4; ++j) {\n                if (mask_bits & (0xFF << (j * 8))) {\n                    return indices[j];\n                }\n            }\n        }\n\n        prev = curr;\n        idx = _mm_add_epi32(idx, inc);\n    }\n\n    return -1;\n}\n```"}
{"task_id": "SimdBench_127_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint can_arrange_simd(const std::vector<int>& arr) {\n    int n = arr.size();\n    if (n < 2) return -1;\n\n    __m128i prev = _mm_set1_epi32(arr[0]);\n    __m128i idx = _mm_set_epi32(3, 2, 1, 0);\n    __m128i inc = _mm_set1_epi32(4);\n\n    for (int i = 1; i < n; i += 4) {\n        __m128i curr = _mm_loadu_si128((__m128i*)&arr[i]);\n        __m128i cmp = _mm_cmpgt_epi32(prev, curr);\n        int mask = _mm_movemask_epi8(cmp);\n\n        if (mask != 0) {\n            __m128i result = _mm_and_si128(cmp, idx);\n            int res = _mm_extract_epi32(result, 0);\n            if (res != 0) return i + res - 1;\n            res = _mm_extract_epi32(result, 1);\n            if (res != 0) return i + res - 1;\n            res = _mm_extract_epi32(result, 2);\n            if (res != 0) return i + res - 1;\n            res = _mm_extract_epi32(result, 3);\n            if (res != 0) return i + res - 1;\n        }\n\n        prev = curr;\n        idx = _mm_add_epi32(idx, inc);\n    }\n\n    return -1;\n}\n```"}
{"task_id": "SimdBench_128_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <limits>\n\nstd::vector<int> largest_smallest_integers_simd(const std::vector<int>& lst) {\n    __m128i max_neg = _mm_set1_epi32(std::numeric_limits<int>::min());\n    __m128i min_pos = _mm_set1_epi32(std::numeric_limits<int>::max());\n\n    int size = lst.size();\n    int i = 0;\n\n    for (; i <= size - 4; i += 4) {\n        __m128i vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&lst[i]));\n\n        __m128i neg_mask = _mm_cmplt_epi32(vec, _mm_setzero_si128());\n        __m128i pos_mask = _mm_cmpgt_epi32(vec, _mm_setzero_si128());\n\n        __m128i max_neg_candidate = _mm_and_si128(vec, neg_mask);\n        __m128i min_pos_candidate = _mm_and_si128(vec, pos_mask);\n\n        max_neg = _mm_max_epi32(max_neg, max_neg_candidate);\n        min_pos = _mm_min_epi32(min_pos, min_pos_candidate);\n    }\n\n    int max_neg_result = _mm_cvtsi128_si32(max_neg);\n    int min_pos_result = _mm_cvtsi128_si32(min_pos);\n\n    for (; i < size; ++i) {\n        if (lst[i] < 0 && lst[i] > max_neg_result) {\n            max_neg_result = lst[i];\n        }\n        if (lst[i] > 0 && lst[i] < min_pos_result) {\n            min_pos_result = lst[i];\n        }\n    }\n\n    if (max_neg_result == std::numeric_limits<int>::min()) {\n        max_neg_result = 0;\n    }\n    if (min_pos_result == std::numeric_limits<int>::max()) {\n        min_pos_result = 0;\n    }\n\n    return {max_neg_result, min_pos_result};\n}\n```"}
{"task_id": "SimdBench_128_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <limits>\n\nstd::vector<int> largest_smallest_integers_simd(const std::vector<int>& lst) {\n    __m128i largest_neg = _mm_set1_epi32(std::numeric_limits<int>::min());\n    __m128i smallest_pos = _mm_set1_epi32(std::numeric_limits<int>::max());\n\n    size_t n = lst.size();\n    size_t i = 0;\n\n    for (; i + 4 <= n; i += 4) {\n        __m128i v = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&lst[i]));\n\n        __m128i neg_mask = _mm_cmplt_epi32(v, _mm_setzero_si128());\n        __m128i pos_mask = _mm_cmpgt_epi32(v, _mm_setzero_si128());\n\n        __m128i neg_values = _mm_and_si128(v, neg_mask);\n        __m128i pos_values = _mm_and_si128(v, pos_mask);\n\n        largest_neg = _mm_max_epi32(largest_neg, neg_values);\n        smallest_pos = _mm_min_epi32(smallest_pos, pos_values);\n    }\n\n    int largest_neg_scalar = std::numeric_limits<int>::min();\n    int smallest_pos_scalar = std::numeric_limits<int>::max();\n\n    for (int j = 0; j < 4; ++j) {\n        int neg_val = _mm_extract_epi32(largest_neg, j);\n        int pos_val = _mm_extract_epi32(smallest_pos, j);\n\n        if (neg_val > largest_neg_scalar) {\n            largest_neg_scalar = neg_val;\n        }\n        if (pos_val < smallest_pos_scalar) {\n            smallest_pos_scalar = pos_val;\n        }\n    }\n\n    for (; i < n; ++i) {\n        int val = lst[i];\n        if (val < 0 && val > largest_neg_scalar) {\n            largest_neg_scalar = val;\n        }\n        if (val > 0 && val < smallest_pos_scalar) {\n            smallest_pos_scalar = val;\n        }\n    }\n\n    if (largest_neg_scalar == std::numeric_limits<int>::min()) {\n        largest_neg_scalar = 0;\n    }\n    if (smallest_pos_scalar == std::numeric_limits<int>::max()) {\n        smallest_pos_scalar = 0;\n    }\n\n    return {largest_neg_scalar, smallest_pos_scalar};\n}\n```"}
{"task_id": "SimdBench_128_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> largest_smallest_integers_simd(const std::vector<int>& lst) {\n    __m128i max_neg = _mm_set1_epi32(INT_MIN);\n    __m128i min_pos = _mm_set1_epi32(INT_MAX);\n    int largest_neg = 0;\n    int smallest_pos = 0;\n\n    size_t size = lst.size();\n    size_t i = 0;\n\n    for (; i + 4 <= size; i += 4) {\n        __m128i vec = _mm_loadu_si128((__m128i*)&lst[i]);\n        __m128i neg_mask = _mm_cmplt_epi32(vec, _mm_setzero_si128());\n        __m128i pos_mask = _mm_cmpgt_epi32(vec, _mm_setzero_si128());\n\n        __m128i neg_values = _mm_and_si128(vec, neg_mask);\n        __m128i pos_values = _mm_and_si128(vec, pos_mask);\n\n        max_neg = _mm_max_epi32(max_neg, neg_values);\n        min_pos = _mm_min_epi32(min_pos, pos_values);\n    }\n\n    alignas(16) int neg_buffer[4];\n    alignas(16) int pos_buffer[4];\n    _mm_store_si128((__m128i*)neg_buffer, max_neg);\n    _mm_store_si128((__m128i*)pos_buffer, min_pos);\n\n    for (int j = 0; j < 4; ++j) {\n        if (neg_buffer[j] > largest_neg) largest_neg = neg_buffer[j];\n        if (pos_buffer[j] < smallest_pos && pos_buffer[j] != 0) smallest_pos = pos_buffer[j];\n    }\n\n    for (; i < size; ++i) {\n        if (lst[i] < 0 && lst[i] > largest_neg) largest_neg = lst[i];\n        if (lst[i] > 0 && (lst[i] < smallest_pos || smallest_pos == 0)) smallest_pos = lst[i];\n    }\n\n    return {largest_neg, smallest_pos};\n}\n```"}
{"task_id": "SimdBench_128_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <limits>\n\nstd::vector<int> largest_smallest_integers_simd(const std::vector<int>& lst) {\n    __m128i max_neg = _mm_set1_epi32(std::numeric_limits<int>::min());\n    __m128i min_pos = _mm_set1_epi32(std::numeric_limits<int>::max());\n\n    int size = lst.size();\n    int i = 0;\n\n    for (; i <= size - 4; i += 4) {\n        __m128i vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&lst[i]));\n\n        __m128i neg_mask = _mm_cmplt_epi32(vec, _mm_setzero_si128());\n        __m128i pos_mask = _mm_cmpgt_epi32(vec, _mm_setzero_si128());\n\n        __m128i neg_values = _mm_and_si128(vec, neg_mask);\n        __m128i pos_values = _mm_and_si128(vec, pos_mask);\n\n        max_neg = _mm_max_epi32(max_neg, neg_values);\n        min_pos = _mm_min_epi32(min_pos, pos_values);\n    }\n\n    int max_neg_val = std::numeric_limits<int>::min();\n    int min_pos_val = std::numeric_limits<int>::max();\n\n    for (int j = 0; j < 4; ++j) {\n        int val = _mm_extract_epi32(max_neg, j);\n        if (val > max_neg_val) {\n            max_neg_val = val;\n        }\n\n        val = _mm_extract_epi32(min_pos, j);\n        if (val < min_pos_val) {\n            min_pos_val = val;\n        }\n    }\n\n    for (; i < size; ++i) {\n        if (lst[i] < 0 && lst[i] > max_neg_val) {\n            max_neg_val = lst[i];\n        }\n        if (lst[i] > 0 && lst[i] < min_pos_val) {\n            min_pos_val = lst[i];\n        }\n    }\n\n    return {max_neg_val == std::numeric_limits<int>::min() ? 0 : max_neg_val,\n            min_pos_val == std::numeric_limits<int>::max() ? 0 : min_pos_val};\n}\n```"}
{"task_id": "SimdBench_128_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <limits>\n\nstd::vector<int> largest_smallest_integers_simd(const std::vector<int>& lst) {\n    __m128i max_neg = _mm_set1_epi32(std::numeric_limits<int>::min());\n    __m128i min_pos = _mm_set1_epi32(std::numeric_limits<int>::max());\n\n    int size = lst.size();\n    int i = 0;\n\n    for (; i <= size - 4; i += 4) {\n        __m128i v = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&lst[i]));\n\n        __m128i neg_mask = _mm_cmplt_epi32(v, _mm_setzero_si128());\n        __m128i pos_mask = _mm_cmpgt_epi32(v, _mm_setzero_si128());\n\n        __m128i neg_values = _mm_and_si128(v, neg_mask);\n        __m128i pos_values = _mm_and_si128(v, pos_mask);\n\n        max_neg = _mm_max_epi32(max_neg, neg_values);\n        min_pos = _mm_min_epi32(min_pos, pos_values);\n    }\n\n    int max_neg_val = _mm_cvtsi128_si32(max_neg);\n    int min_pos_val = _mm_cvtsi128_si32(min_pos);\n\n    for (; i < size; ++i) {\n        if (lst[i] < 0 && lst[i] > max_neg_val) {\n            max_neg_val = lst[i];\n        }\n        if (lst[i] > 0 && lst[i] < min_pos_val) {\n            min_pos_val = lst[i];\n        }\n    }\n\n    if (max_neg_val == std::numeric_limits<int>::min()) {\n        max_neg_val = 0;\n    }\n    if (min_pos_val == std::numeric_limits<int>::max()) {\n        min_pos_val = 0;\n    }\n\n    return {max_neg_val, min_pos_val};\n}\n```"}
{"task_id": "SimdBench_129_SSE", "completion": "```c\nuint64_t special_factorial_simd(uint64_t n) {\n    __m128i result = _mm_set1_epi64x(1);\n    __m128i one = _mm_set1_epi64x(1);\n    __m128i i = _mm_set1_epi64x(1);\n\n    while (_mm_cvtsi128_si64(i) <= n) {\n        __m128i factorial = _mm_set1_epi64x(1);\n        __m128i j = _mm_set1_epi64x(1);\n\n        while (_mm_cvtsi128_si64(j) <= _mm_cvtsi128_si64(i)) {\n            factorial = _mm_mullo_epi64(factorial, j);\n            j = _mm_add_epi64(j, one);\n        }\n\n        result = _mm_mullo_epi64(result, factorial);\n        i = _mm_add_epi64(i, one);\n    }\n\n    return _mm_cvtsi128_si64(result);\n}\n```"}
{"task_id": "SimdBench_129_SSE", "completion": "```c\nuint64_t special_factorial_simd(uint64_t n) {\n    __m128i result = _mm_set1_epi64x(1);\n    __m128i one = _mm_set1_epi64x(1);\n    __m128i i = _mm_set1_epi64x(1);\n\n    while (_mm_extract_epi64(i, 0) <= n) {\n        __m128i factorial = _mm_set1_epi64x(1);\n        __m128i j = _mm_set1_epi64x(1);\n\n        while (_mm_extract_epi64(j, 0) <= _mm_extract_epi64(i, 0)) {\n            factorial = _mm_mullo_epi64(factorial, j);\n            j = _mm_add_epi64(j, one);\n        }\n\n        result = _mm_mullo_epi64(result, factorial);\n        i = _mm_add_epi64(i, one);\n    }\n\n    return _mm_extract_epi64(result, 0);\n}\n```"}
{"task_id": "SimdBench_129_SSE", "completion": "```c\nuint64_t special_factorial_simd(uint64_t n) {\n    __m128i result = _mm_set1_epi64x(1);\n    __m128i one = _mm_set1_epi64x(1);\n    __m128i i = _mm_set1_epi64x(1);\n\n    while (_mm_extract_epi64(i, 0) <= n) {\n        __m128i factorial = _mm_set1_epi64x(1);\n        __m128i j = _mm_set1_epi64x(1);\n\n        while (_mm_extract_epi64(j, 0) <= _mm_extract_epi64(i, 0)) {\n            factorial = _mm_mullo_epi64(factorial, j);\n            j = _mm_add_epi64(j, one);\n        }\n\n        result = _mm_mullo_epi64(result, factorial);\n        i = _mm_add_epi64(i, one);\n    }\n\n    return _mm_extract_epi64(result, 0);\n}\n```"}
{"task_id": "SimdBench_129_SSE", "completion": "```c\nuint64_t special_factorial_simd(uint64_t n) {\n    __m128i result = _mm_set1_epi64x(1);\n    __m128i one = _mm_set1_epi64x(1);\n    __m128i i = _mm_set1_epi64x(1);\n\n    while (_mm_cvtsi128_si64(i) <= n) {\n        __m128i factorial = _mm_set1_epi64x(1);\n        __m128i j = _mm_set1_epi64x(1);\n\n        while (_mm_cvtsi128_si64(j) <= _mm_cvtsi128_si64(i)) {\n            factorial = _mm_mullo_epi64(factorial, j);\n            j = _mm_add_epi64(j, one);\n        }\n\n        result = _mm_mullo_epi64(result, factorial);\n        i = _mm_add_epi64(i, one);\n    }\n\n    return _mm_cvtsi128_si64(result);\n}\n```"}
{"task_id": "SimdBench_129_SSE", "completion": "```c\nuint64_t special_factorial_simd(uint64_t n) {\n    __m128i result = _mm_set1_epi64x(1);\n    __m128i one = _mm_set1_epi64x(1);\n    __m128i i = _mm_set1_epi64x(1);\n\n    while (_mm_extract_epi64(i, 0) <= n) {\n        __m128i factorial = _mm_set1_epi64x(1);\n        __m128i j = _mm_set1_epi64x(1);\n\n        while (_mm_extract_epi64(j, 0) <= _mm_extract_epi64(i, 0)) {\n            factorial = _mm_mullo_epi64(factorial, j);\n            j = _mm_add_epi64(j, one);\n        }\n\n        result = _mm_mullo_epi64(result, factorial);\n        i = _mm_add_epi64(i, one);\n    }\n\n    return _mm_extract_epi64(result, 0);\n}\n```"}
{"task_id": "SimdBench_130_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint sum_squares_simd(const std::vector<int>& lst) {\n    int sum = 0;\n    int size = lst.size();\n    int i = 0;\n\n    // Process 4 elements at a time\n    for (; i <= size - 4; i += 4) {\n        __m128i v = _mm_loadu_si128((__m128i*)&lst[i]);\n        __m128i v_squared = _mm_mullo_epi32(v, v);\n        __m128i v_cubed = _mm_mullo_epi32(v, _mm_mullo_epi32(v, v));\n\n        __m128i mask_multiple_of_3 = _mm_setr_epi32(i % 3 == 0, (i + 1) % 3 == 0, (i + 2) % 3 == 0, (i + 3) % 3 == 0);\n        __m128i mask_multiple_of_4 = _mm_setr_epi32(i % 4 == 0, (i + 1) % 4 == 0, (i + 2) % 4 == 0, (i + 3) % 4 == 0);\n        __m128i mask_multiple_of_4_not_3 = _mm_andnot_si128(mask_multiple_of_3, mask_multiple_of_4);\n\n        __m128i result = _mm_blendv_epi8(v, v_squared, mask_multiple_of_3);\n        result = _mm_blendv_epi8(result, v_cubed, mask_multiple_of_4_not_3);\n\n        sum += _mm_extract_epi32(result, 0);\n        sum += _mm_extract_epi32(result, 1);\n        sum += _mm_extract_epi32(result, 2);\n        sum += _mm_extract_epi32(result, 3);\n    }\n\n    // Process remaining elements\n    for (; i < size; ++i) {\n        if (i % 3 == 0) {\n            sum += lst[i] * lst[i];\n        } else if (i % 4 == 0) {\n            sum += lst[i] * lst[i] * lst[i];\n        } else {\n            sum += lst[i];\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_130_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint sum_squares_simd(const std::vector<int>& lst) {\n    int sum = 0;\n    int size = lst.size();\n    int i = 0;\n\n    // Process 4 elements at a time using SSE2\n    for (; i <= size - 4; i += 4) {\n        __m128i vec = _mm_loadu_si128((__m128i*)&lst[i]);\n        __m128i indices = _mm_set_epi32(i + 3, i + 2, i + 1, i);\n        __m128i mask3 = _mm_set1_epi32(3);\n        __m128i mask4 = _mm_set1_epi32(4);\n\n        __m128i mod3 = _mm_div_epi32(indices, mask3);\n        __m128i mod4 = _mm_div_epi32(indices, mask4);\n\n        __m128i is_multiple_of_3 = _mm_cmpeq_epi32(mod3, _mm_setzero_si128());\n        __m128i is_multiple_of_4 = _mm_cmpeq_epi32(mod4, _mm_setzero_si128());\n        __m128i is_multiple_of_4_not_3 = _mm_andnot_si128(is_multiple_of_3, is_multiple_of_4);\n\n        __m128i squared = _mm_mullo_epi32(vec, vec);\n        __m128i cubed = _mm_mullo_epi32(vec, _mm_mullo_epi32(vec, vec));\n\n        __m128i result = _mm_blendv_epi8(vec, squared, is_multiple_of_3);\n        result = _mm_blendv_epi8(result, cubed, is_multiple_of_4_not_3);\n\n        sum += _mm_extract_epi32(result, 0) + _mm_extract_epi32(result, 1) + _mm_extract_epi32(result, 2) + _mm_extract_epi32(result, 3);\n    }\n\n    // Process remaining elements\n    for (; i < size; ++i) {\n        if (i % 3 == 0) {\n            sum += lst[i] * lst[i];\n        } else if (i % 4 == 0) {\n            sum += lst[i] * lst[i] * lst[i];\n        } else {\n            sum += lst[i];\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_130_SSE", "completion": "```c++\nint sum_squares_simd(const std::vector<int> & lst) {\n    int sum = 0;\n    __m128i sum_vec = _mm_setzero_si128();\n    __m128i three = _mm_set1_epi32(3);\n    __m128i four = _mm_set1_epi32(4);\n    __m128i zero = _mm_setzero_si128();\n\n    for (size_t i = 0; i < lst.size(); i += 4) {\n        __m128i indices = _mm_set_epi32(i + 3, i + 2, i + 1, i);\n        __m128i values = _mm_loadu_si128((__m128i*)&lst[i]);\n\n        __m128i mod3 = _mm_and_si128(_mm_cmpeq_epi32(_mm_and_si128(indices, three), zero), _mm_set1_epi32(1));\n        __m128i mod4 = _mm_and_si128(_mm_cmpeq_epi32(_mm_and_si128(indices, four), zero), _mm_set1_epi32(1));\n\n        __m128i sq = _mm_mullo_epi32(values, values);\n        __m128i cube = _mm_mullo_epi32(_mm_mullo_epi32(values, values), values);\n\n        __m128i result = _mm_blendv_epi8(values, sq, mod3);\n        result = _mm_blendv_epi8(result, cube, _mm_andnot_si128(mod3, mod4));\n\n        sum_vec = _mm_add_epi32(sum_vec, result);\n    }\n\n    sum = _mm_extract_epi32(sum_vec, 0) + _mm_extract_epi32(sum_vec, 1) + _mm_extract_epi32(sum_vec, 2) + _mm_extract_epi32(sum_vec, 3);\n\n    for (size_t i = lst.size() / 4 * 4; i < lst.size(); ++i) {\n        if (i % 3 == 0) {\n            sum += lst[i] * lst[i];\n        } else if (i % 4 == 0) {\n            sum += lst[i] * lst[i] * lst[i];\n        } else {\n            sum += lst[i];\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_130_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint sum_squares_simd(const std::vector<int>& lst) {\n    int sum = 0;\n    __m128i sum_vec = _mm_setzero_si128();\n\n    for (size_t i = 0; i < lst.size(); i += 4) {\n        __m128i vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&lst[i]));\n        __m128i indices = _mm_set_epi32(i + 3, i + 2, i + 1, i);\n        __m128i mask3 = _mm_set1_epi32(3);\n        __m128i mask4 = _mm_set1_epi32(4);\n\n        __m128i mod3 = _mm_and_si128(_mm_cmpeq_epi32(_mm_mod_epi32(indices, mask3), _mm_setzero_si128()), vec);\n        __m128i mod4 = _mm_and_si128(_mm_cmpeq_epi32(_mm_mod_epi32(indices, mask4), _mm_setzero_si128()), vec);\n\n        __m128i squared = _mm_mullo_epi32(mod3, mod3);\n        __m128i cubed = _mm_mullo_epi32(_mm_mullo_epi32(mod4, mod4), mod4);\n\n        __m128i result = _mm_add_epi32(_mm_add_epi32(vec, squared), cubed);\n        sum_vec = _mm_add_epi32(sum_vec, result);\n    }\n\n    alignas(16) int temp[4];\n    _mm_store_si128(reinterpret_cast<__m128i*>(temp), sum_vec);\n    sum = temp[0] + temp[1] + temp[2] + temp[3];\n\n    for (size_t i = lst.size() / 4 * 4; i < lst.size(); ++i) {\n        if (i % 3 == 0) {\n            sum += lst[i] * lst[i];\n        } else if (i % 4 == 0) {\n            sum += lst[i] * lst[i] * lst[i];\n        } else {\n            sum += lst[i];\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_130_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint sum_squares_simd(const std::vector<int>& lst) {\n    int sum = 0;\n    int size = lst.size();\n    int i = 0;\n\n    // Process 4 elements at a time using SSE2\n    for (; i <= size - 4; i += 4) {\n        __m128i v = _mm_loadu_si128((__m128i*)&lst[i]);\n        __m128i v_squared = _mm_mullo_epi32(v, v);\n        __m128i v_cubed = _mm_mullo_epi32(v_squared, v);\n\n        __m128i mask_multiple_of_3 = _mm_set_epi32(i % 3 == 0, (i + 1) % 3 == 0, (i + 2) % 3 == 0, (i + 3) % 3 == 0);\n        __m128i mask_multiple_of_4 = _mm_set_epi32(i % 4 == 0, (i + 1) % 4 == 0, (i + 2) % 4 == 0, (i + 3) % 4 == 0);\n        __m128i mask_not_multiple_of_3 = _mm_andnot_si128(mask_multiple_of_3, mask_multiple_of_4);\n\n        __m128i result = _mm_blendv_epi8(v, v_squared, mask_multiple_of_3);\n        result = _mm_blendv_epi8(result, v_cubed, mask_not_multiple_of_3);\n\n        sum += _mm_extract_epi32(result, 0) + _mm_extract_epi32(result, 1) + _mm_extract_epi32(result, 2) + _mm_extract_epi32(result, 3);\n    }\n\n    // Process remaining elements\n    for (; i < size; ++i) {\n        if (i % 3 == 0) {\n            sum += lst[i] * lst[i];\n        } else if (i % 4 == 0) {\n            sum += lst[i] * lst[i] * lst[i];\n        } else {\n            sum += lst[i];\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_131_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint specialFilter_simd(const std::vector<int>& nums) {\n    int count = 0;\n    int size = nums.size();\n    int i = 0;\n\n    __m128i threshold = _mm_set1_epi32(10);\n    __m128i odd_mask = _mm_set1_epi32(0x55555555);\n\n    for (; i <= size - 4; i += 4) {\n        __m128i vec = _mm_loadu_si128((__m128i*)&nums[i]);\n        __m128i abs_vec = _mm_abs_epi32(vec);\n\n        __m128i first_digit = _mm_srli_epi32(abs_vec, 28);\n        __m128i last_digit = _mm_and_si128(abs_vec, _mm_set1_epi32(0xF));\n\n        __m128i first_odd = _mm_and_si128(first_digit, odd_mask);\n        __m128i last_odd = _mm_and_si128(last_digit, odd_mask);\n\n        __m128i both_odd = _mm_and_si128(first_odd, last_odd);\n        __m128i greater_than_10 = _mm_cmpgt_epi32(vec, threshold);\n\n        __m128i result = _mm_and_si128(both_odd, greater_than_10);\n\n        count += _mm_movemask_epi8(_mm_packs_epi32(result, _mm_setzero_si128())) & 0x0F;\n    }\n\n    for (; i < size; ++i) {\n        int num = nums[i];\n        int abs_num = abs(num);\n        int first_digit = abs_num / 1000000000 % 10;\n        int last_digit = abs_num % 10;\n\n        if (num > 10 && (first_digit & 1) && (last_digit & 1)) {\n            ++count;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_131_SSE", "completion": "```c++\nint specialFilter_simd(const std::vector<int>& nums) {\n    int count = 0;\n    int size = nums.size();\n    __m128i threshold = _mm_set1_epi32(10);\n    __m128i odd_mask = _mm_set1_epi32(0x55555555); // 01010101... in binary\n\n    for (int i = 0; i < size; i += 4) {\n        __m128i vec = _mm_loadu_si128((__m128i*)&nums[i]);\n        __m128i abs_vec = _mm_abs_epi32(vec);\n        __m128i first_digit = _mm_srli_epi32(abs_vec, 28);\n        __m128i last_digit = _mm_and_si128(abs_vec, _mm_set1_epi32(0xF));\n        __m128i first_odd = _mm_and_si128(first_digit, odd_mask);\n        __m128i last_odd = _mm_and_si128(last_digit, odd_mask);\n        __m128i both_odd = _mm_and_si128(first_odd, last_odd);\n        __m128i greater_than_10 = _mm_cmpgt_epi32(vec, threshold);\n        __m128i result = _mm_and_si128(both_odd, greater_than_10);\n\n        count += _mm_movemask_epi8(_mm_packs_epi32(result, _mm_setzero_si128())) & 0x1111;\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_131_SSE", "completion": "```c++\nint specialFilter_simd(const std::vector<int>& nums) {\n    int count = 0;\n    const int size = nums.size();\n    const int step = 4; // SSE operates on 4 floats at a time\n\n    __m128i threshold = _mm_set1_epi32(10);\n    __m128i odd_digits_mask = _mm_set1_epi32(0x55555555); // Binary: 01010101010101010101010101010101\n\n    for (int i = 0; i <= size - step; i += step) {\n        __m128i vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&nums[i]));\n        __m128i abs_vec = _mm_abs_epi32(vec);\n        __m128i first_digit = _mm_srli_epi32(abs_vec, 28); // Shift right to get the first digit\n        __m128i last_digit = _mm_and_si128(abs_vec, _mm_set1_epi32(0xF)); // Mask to get the last digit\n\n        __m128i first_digit_odd = _mm_and_si128(first_digit, odd_digits_mask);\n        __m128i last_digit_odd = _mm_and_si128(last_digit, odd_digits_mask);\n\n        __m128i both_odd = _mm_and_si128(first_digit_odd, last_digit_odd);\n        __m128i greater_than_10 = _mm_cmpgt_epi32(vec, threshold);\n\n        __m128i result = _mm_and_si128(both_odd, greater_than_10);\n        count += _mm_movemask_epi8(_mm_cmpeq_epi32(result, _mm_setzero_si128())) == 0 ? 4 : 0;\n    }\n\n    // Handle remaining elements\n    for (int i = (size / step) * step; i < size; ++i) {\n        int num = nums[i];\n        int abs_num = abs(num);\n        int first_digit = abs_num / 1000000000 % 10;\n        int last_digit = abs_num % 10;\n        if (num > 10 && (first_digit & 1) && (last_digit & 1)) {\n            count++;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_131_SSE", "completion": "```c++\nint specialFilter_simd(const std::vector<int>& nums) {\n    int count = 0;\n    int size = nums.size();\n    __m128i threshold = _mm_set1_epi32(10);\n    __m128i odd_mask = _mm_set1_epi32(0x55555555);\n\n    for (int i = 0; i < size; i += 4) {\n        __m128i vec = _mm_loadu_si128((__m128i*)&nums[i]);\n        __m128i abs_vec = _mm_abs_epi32(vec);\n        __m128i cmp = _mm_cmpgt_epi32(abs_vec, threshold);\n\n        __m128i first_digit = _mm_srli_epi32(abs_vec, 28);\n        __m128i last_digit = _mm_and_si128(abs_vec, _mm_set1_epi32(0xF));\n\n        __m128i first_odd = _mm_and_si128(first_digit, odd_mask);\n        __m128i last_odd = _mm_and_si128(last_digit, odd_mask);\n\n        __m128i both_odd = _mm_and_si128(first_odd, last_odd);\n        __m128i result = _mm_and_si128(cmp, both_odd);\n\n        count += _mm_movemask_epi8(_mm_packs_epi32(result, result)) & 0x1111;\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_131_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint specialFilter_simd(const std::vector<int>& nums) {\n    const int threshold = 10;\n    const __m128i threshold_vec = _mm_set1_epi32(threshold);\n    const __m128i odd_digits_mask = _mm_set1_epi32(0x55555555); // 01010101... in binary\n    const __m128i odd_digits = _mm_set1_epi32(0x11111111); // 00010001... in binary\n\n    int count = 0;\n    int size = nums.size();\n    int i = 0;\n\n    for (; i <= size - 4; i += 4) {\n        __m128i vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&nums[i]));\n        __m128i abs_vec = _mm_abs_epi32(vec);\n        __m128i cmp = _mm_cmpgt_epi32(abs_vec, threshold_vec);\n\n        __m128i first_digit = _mm_and_si128(abs_vec, odd_digits_mask);\n        __m128i last_digit = _mm_and_si128(_mm_srli_epi32(abs_vec, 28), odd_digits_mask);\n\n        __m128i first_odd = _mm_cmpeq_epi32(first_digit, odd_digits);\n        __m128i last_odd = _mm_cmpeq_epi32(last_digit, odd_digits);\n\n        __m128i result = _mm_and_si128(cmp, _mm_and_si128(first_odd, last_odd));\n        count += _mm_movemask_epi8(_mm_packs_epi16(_mm_packs_epi32(result, result), _mm_setzero_si128())) & 0x0F;\n    }\n\n    for (; i < size; ++i) {\n        int num = nums[i];\n        int abs_num = abs(num);\n        if (abs_num > threshold && ((abs_num % 10) & 1) && (((abs_num / 10) % 10) & 1)) {\n            ++count;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_132_SSE", "completion": "```c\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nuint64_t get_max_triples_simd(uint64_t n) {\n    uint64_t count = 0;\n    __m128i vindex = _mm_set_epi32(3, 2, 1, 0);\n    __m128i vone = _mm_set1_epi32(1);\n    __m128i vthree = _mm_set1_epi32(3);\n\n    for (uint64_t i = 0; i < n; i += 4) {\n        __m128i vi = _mm_add_epi32(vindex, _mm_set1_epi32(i));\n        __m128i vsq = _mm_mullo_epi32(vi, vi);\n        __m128i va = _mm_sub_epi32(vsq, vi);\n        va = _mm_add_epi32(va, vone);\n\n        for (uint64_t j = i + 4; j < n; j += 4) {\n            __m128i vj = _mm_add_epi32(vindex, _mm_set1_epi32(j));\n            __m128i vsq_j = _mm_mullo_epi32(vj, vj);\n            __m128i va_j = _mm_sub_epi32(vsq_j, vj);\n            va_j = _mm_add_epi32(va_j, vone);\n\n            for (uint64_t k = j + 4; k < n; k += 4) {\n                __m128i vk = _mm_add_epi32(vindex, _mm_set1_epi32(k));\n                __m128i vsq_k = _mm_mullo_epi32(vk, vk);\n                __m128i va_k = _mm_sub_epi32(vsq_k, vk);\n                va_k = _mm_add_epi32(va_k, vone);\n\n                __m128i sum = _mm_add_epi32(va, va_j);\n                sum = _mm_add_epi32(sum, va_k);\n                __m128i mask = _mm_cmpeq_epi32(_mm_and_si128(sum, vthree), _mm_setzero_si128());\n\n                count += _mm_movemask_epi8(mask) & 0x1111;\n            }\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_132_SSE", "completion": "```c\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nuint64_t get_max_triples_simd(uint64_t n) {\n    uint64_t count = 0;\n    uint64_t* a = (uint64_t*)_mm_malloc(n * sizeof(uint64_t), 16);\n\n    for (uint64_t i = 0; i < n; ++i) {\n        a[i] = i * i - i + 1;\n    }\n\n    __m128i three = _mm_set1_epi32(3);\n\n    for (uint64_t i = 0; i < n; ++i) {\n        for (uint64_t j = i + 1; j < n; ++j) {\n            for (uint64_t k = j + 1; k < n; ++k) {\n                __m128i sum = _mm_set_epi32(0, 0, a[k], a[j]);\n                sum = _mm_add_epi32(sum, _mm_set_epi32(0, 0, 0, a[i]));\n                __m128i mod = _mm_mod_epi32(sum, three);\n                if (_mm_testz_si128(mod, mod)) {\n                    ++count;\n                }\n            }\n        }\n    }\n\n    _mm_free(a);\n    return count;\n}\n```"}
{"task_id": "SimdBench_132_SSE", "completion": "```c\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nuint64_t get_max_triples_simd(uint64_t n) {\n    uint64_t count = 0;\n    __m128i idx = _mm_set_epi32(4, 3, 2, 1);\n    __m128i ones = _mm_set1_epi32(1);\n    __m128i threes = _mm_set1_epi32(3);\n\n    for (uint64_t i = 1; i <= n; ++i) {\n        __m128i ai = _mm_mullo_epi32(idx, idx);\n        ai = _mm_sub_epi32(ai, idx);\n        ai = _mm_add_epi32(ai, ones);\n\n        for (uint64_t j = i + 1; j <= n; ++j) {\n            __m128i aj = _mm_mullo_epi32(idx, idx);\n            aj = _mm_sub_epi32(aj, idx);\n            aj = _mm_add_epi32(aj, ones);\n\n            for (uint64_t k = j + 1; k <= n; ++k) {\n                __m128i ak = _mm_mullo_epi32(idx, idx);\n                ak = _mm_sub_epi32(ak, idx);\n                ak = _mm_add_epi32(ak, ones);\n\n                __m128i sum = _mm_add_epi32(ai, aj);\n                sum = _mm_add_epi32(sum, ak);\n\n                __m128i mod = _mm_div_epi32(sum, threes);\n                mod = _mm_mullo_epi32(mod, threes);\n                mod = _mm_sub_epi32(sum, mod);\n\n                if (_mm_movemask_epi8(_mm_cmpeq_epi32(mod, _mm_setzero_si128())) == 0xFFFF) {\n                    count++;\n                }\n            }\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_132_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nuint64_t get_max_triples_simd(uint64_t n) {\n    uint64_t count = 0;\n    __m128i ones = _mm_set1_epi32(1);\n    __m128i threes = _mm_set1_epi32(3);\n\n    for (uint64_t i = 1; i <= n; ++i) {\n        for (uint64_t j = i + 1; j <= n; ++j) {\n            for (uint64_t k = j + 1; k <= n; ++k) {\n                __m128i ai = _mm_set1_epi32(i * i - i + 1);\n                __m128i aj = _mm_set1_epi32(j * j - j + 1);\n                __m128i ak = _mm_set1_epi32(k * k - k + 1);\n\n                __m128i sum = _mm_add_epi32(ai, aj);\n                sum = _mm_add_epi32(sum, ak);\n\n                __m128i mod = _mm_div_epi32(sum, threes);\n                mod = _mm_mullo_epi32(mod, threes);\n                mod = _mm_sub_epi32(sum, mod);\n\n                __m128i is_zero = _mm_cmpeq_epi32(mod, _mm_setzero_si128());\n                int mask = _mm_movemask_epi8(is_zero);\n\n                if (mask == 0xFFFF) {\n                    count++;\n                }\n            }\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_132_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nuint64_t get_max_triples_simd(uint64_t n) {\n    uint64_t count = 0;\n    uint64_t* a = (uint64_t*)_mm_malloc(n * sizeof(uint64_t), 16);\n\n    // Initialize the array a with the formula a[i] = i * i - i + 1\n    for (uint64_t i = 0; i < n; ++i) {\n        a[i] = i * i - i + 1;\n    }\n\n    // Use SIMD to count the number of valid triples\n    __m128i three = _mm_set1_epi32(3);\n    for (uint64_t i = 0; i < n; ++i) {\n        for (uint64_t j = i + 1; j < n; ++j) {\n            for (uint64_t k = j + 1; k < n; ++k) {\n                __m128i sum = _mm_set_epi32(0, 0, 0, a[i] + a[j] + a[k]);\n                __m128i mod = _mm_div_epi32(sum, three);\n                mod = _mm_mul_epi32(mod, three);\n                __m128i diff = _mm_sub_epi32(sum, mod);\n                if (_mm_testz_si128(diff, diff)) {\n                    count++;\n                }\n            }\n        }\n    }\n\n    _mm_free(a);\n    return count;\n}\n```"}
{"task_id": "SimdBench_133_SSE", "completion": "```c\nint x_or_y_simd(int n, int x, int y) {\n    __m128i n_vec = _mm_set1_epi32(n);\n    __m128i primes = _mm_set_epi32(2, 3, 5, 7);\n    __m128i cmp = _mm_cmpeq_epi32(n_vec, primes);\n    int mask = _mm_movemask_epi8(cmp);\n    return (mask & 0xFFFF) ? x : y;\n}\n```"}
{"task_id": "SimdBench_133_SSE", "completion": "```cpp\nint x_or_y_simd(int n, int x, int y) {\n    __m128i n_vec = _mm_set1_epi32(n);\n    __m128i one_vec = _mm_set1_epi32(1);\n    __m128i two_vec = _mm_set1_epi32(2);\n    __m128i four_vec = _mm_set1_epi32(4);\n    __m128i six_vec = _mm_set1_epi32(6);\n    __m128i eight_vec = _mm_set1_epi32(8);\n    __m128i ten_vec = _mm_set1_epi32(10);\n    __m128i twelve_vec = _mm_set1_epi32(12);\n\n    __m128i mod_two = _mm_cmpeq_epi32(_mm_and_si128(n_vec, one_vec), _mm_setzero_si128());\n    __m128i mod_three = _mm_cmpeq_epi32(_mm_and_si128(n_vec, two_vec), _mm_setzero_si128());\n    __m128i mod_four = _mm_cmpeq_epi32(_mm_and_si128(n_vec, three_vec), _mm_setzero_si128());\n    __m128i mod_six = _mm_cmpeq_epi32(_mm_and_si128(n_vec, five_vec), _mm_setzero_si128());\n    __m128i mod_eight = _mm_cmpeq_epi32(_mm_and_si128(n_vec, seven_vec), _mm_setzero_si128());\n    __m128i mod_ten = _mm_cmpeq_epi32(_mm_and_si128(n_vec, nine_vec), _mm_setzero_si128());\n    __m128i mod_twelve = _mm_cmpeq_epi32(_mm_and_si128(n_vec, eleven_vec), _mm_setzero_si128());\n\n    __m128i is_prime = _mm_and_si128(_mm_and_si128(_mm_and_si128(_mm_and_si128(_mm_and_si128(_mm_and_si128(_mm_and_si128(mod_two, mod_three), mod_four), mod_six), mod_eight), mod_ten), mod_twelve);\n\n    int prime_mask = _mm_movemask_epi8(is_prime);\n    return (prime_mask == 0xFFFF) ? x : y;\n}\n```"}
{"task_id": "SimdBench_133_SSE", "completion": "```c\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint x_or_y_simd(int n, int x, int y) {\n    __m128i primes = _mm_set_epi32(11, 7, 5, 3);\n    __m128i n_vec = _mm_set1_epi32(n);\n    __m128i cmp = _mm_cmpeq_epi32(n_vec, primes);\n    int mask = _mm_movemask_epi8(cmp);\n    return (mask != 0) ? x : y;\n}\n```"}
{"task_id": "SimdBench_133_SSE", "completion": "```cpp\nint x_or_y_simd(int n, int x, int y) {\n    __m128i vec_n = _mm_set1_epi32(n);\n    __m128i vec_2 = _mm_set1_epi32(2);\n    __m128i vec_3 = _mm_set1_epi32(3);\n    __m128i vec_5 = _mm_set1_epi32(5);\n    __m128i vec_7 = _mm_set1_epi32(7);\n\n    __m128i div_2 = _mm_cvtepi32_epi64(_mm_div_epi32(vec_n, vec_2));\n    __m128i div_3 = _mm_cvtepi32_epi64(_mm_div_epi32(vec_n, vec_3));\n    __m128i div_5 = _mm_cvtepi32_epi64(_mm_div_epi32(vec_n, vec_5));\n    __m128i div_7 = _mm_cvtepi32_epi64(_mm_div_epi32(vec_n, vec_7));\n\n    __m128i mod_2 = _mm_cvtepi32_epi64(_mm_sub_epi32(vec_n, _mm_mullo_epi32(div_2, vec_2)));\n    __m128i mod_3 = _mm_cvtepi32_epi64(_mm_sub_epi32(vec_n, _mm_mullo_epi32(div_3, vec_3)));\n    __m128i mod_5 = _mm_cvtepi32_epi64(_mm_sub_epi32(vec_n, _mm_mullo_epi32(div_5, vec_5)));\n    __m128i mod_7 = _mm_cvtepi32_epi64(_mm_sub_epi32(vec_n, _mm_mullo_epi32(div_7, vec_7)));\n\n    __m128i is_prime = _mm_and_si128(\n        _mm_and_si128(_mm_cmpeq_epi32(mod_2, _mm_setzero_si128()), _mm_cmpeq_epi32(mod_3, _mm_setzero_si128())),\n        _mm_and_si128(_mm_cmpeq_epi32(mod_5, _mm_setzero_si128()), _mm_cmpeq_epi32(mod_7, _mm_setzero_si128()))\n    );\n\n    int prime_mask = _mm_movemask_epi8(is_prime);\n    return (prime_mask == 0) ? x : y;\n}\n```"}
{"task_id": "SimdBench_133_SSE", "completion": "```c\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint x_or_y_simd(int n, int x, int y) {\n    __m128i primes = _mm_set_epi32(11, 7, 5, 3);\n    __m128i n_vec = _mm_set1_epi32(n);\n    __m128i cmp = _mm_cmpeq_epi32(n_vec, primes);\n    int mask = _mm_movemask_epi8(cmp);\n    return (mask != 0) ? x : y;\n}\n```"}
{"task_id": "SimdBench_134_SSE", "completion": "```c++\nuint64_t double_the_difference_simd(const std::vector<float> & lst) {\n    if (lst.empty()) return 0;\n\n    __m128 sum = _mm_setzero_ps();\n    __m128i mask = _mm_set1_epi32(0x80000000);\n    __m128i one = _mm_set1_epi32(1);\n\n    for (size_t i = 0; i < lst.size(); i += 4) {\n        __m128 v = _mm_loadu_ps(&lst[i]);\n        __m128i vi = _mm_cvtps_epi32(v);\n        __m128i odd_mask = _mm_andnot_si128(mask, vi);\n        odd_mask = _mm_and_si128(odd_mask, one);\n        __m128 odd = _mm_cvtepi32_ps(odd_mask);\n        __m128 square = _mm_mul_ps(v, v);\n        __m128 result = _mm_mul_ps(square, odd);\n        sum = _mm_add_ps(sum, result);\n    }\n\n    float temp[4];\n    _mm_storeu_ps(temp, sum);\n    return temp[0] + temp[1] + temp[2] + temp[3];\n}\n```"}
{"task_id": "SimdBench_134_SSE", "completion": "```c++\nuint64_t double_the_difference_simd(const std::vector<float> & lst) {\n    if (lst.empty()) return 0;\n\n    __m128 sum = _mm_setzero_ps();\n    __m128i mask = _mm_set1_epi32(0x80000000);\n    __m128i one = _mm_set1_epi32(1);\n\n    for (size_t i = 0; i < lst.size(); i += 4) {\n        __m128 v = _mm_loadu_ps(&lst[i]);\n        __m128i vi = _mm_cvtps_epi32(v);\n        __m128i odd_mask = _mm_and_si128(_mm_cmpeq_epi32(_mm_and_si128(vi, one), one), _mm_cmpgt_epi32(vi, _mm_setzero_si128()));\n        __m128 odd = _mm_and_ps(v, _mm_castsi128_ps(odd_mask));\n        __m128 odd_squared = _mm_mul_ps(odd, odd);\n        sum = _mm_add_ps(sum, odd_squared);\n    }\n\n    float result[4];\n    _mm_storeu_ps(result, sum);\n    return result[0] + result[1] + result[2] + result[3];\n}\n```"}
{"task_id": "SimdBench_134_SSE", "completion": "```c++\nuint64_t double_the_difference_simd(const std::vector<float> & lst) {\n    uint64_t sum = 0;\n    __m128i zero = _mm_setzero_si128();\n    __m128i one = _mm_set1_epi32(1);\n    __m128i two = _mm_set1_epi32(2);\n    __m128i mask = _mm_set1_epi32(0x7FFFFFFF);\n\n    for (size_t i = 0; i < lst.size(); i += 4) {\n        __m128i v = _mm_loadu_si128((__m128i*)&lst[i]);\n        __m128i abs_v = _mm_and_si128(v, mask);\n        __m128i odd_mask = _mm_and_si128(_mm_cmpeq_epi32(_mm_and_si128(abs_v, one), zero), _mm_cmpgt_epi32(abs_v, zero));\n        __m128i squares = _mm_mullo_epi32(abs_v, abs_v);\n        __m128i result = _mm_and_si128(squares, odd_mask);\n\n        sum += _mm_extract_epi32(result, 0);\n        sum += _mm_extract_epi32(result, 1);\n        sum += _mm_extract_epi32(result, 2);\n        sum += _mm_extract_epi32(result, 3);\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_134_SSE", "completion": "```c++\nuint64_t double_the_difference_simd(const std::vector<float> & lst) {\n    if (lst.empty()) return 0;\n\n    __m128 sum = _mm_setzero_ps();\n    __m128i mask = _mm_set1_epi32(0x80000000);\n    __m128i one = _mm_set1_epi32(1);\n\n    for (size_t i = 0; i < lst.size(); i += 4) {\n        __m128 v = _mm_loadu_ps(&lst[i]);\n        __m128i vi = _mm_cvtps_epi32(v);\n        __m128i odd_mask = _mm_and_si128(_mm_cmpeq_epi32(_mm_and_si128(vi, one), one), _mm_cmpgt_epi32(vi, _mm_setzero_si128()));\n        __m128 odd = _mm_and_ps(v, _mm_castsi128_ps(odd_mask));\n        __m128 odd_squared = _mm_mul_ps(odd, odd);\n        sum = _mm_add_ps(sum, odd_squared);\n    }\n\n    float result[4];\n    _mm_storeu_ps(result, sum);\n    return result[0] + result[1] + result[2] + result[3];\n}\n```"}
{"task_id": "SimdBench_134_SSE", "completion": "```cpp\nuint64_t double_the_difference_simd(const std::vector<float> & lst) {\n    if (lst.empty()) return 0;\n\n    __m128 sum = _mm_setzero_ps();\n    __m128i mask = _mm_set1_epi32(0x80000000);\n\n    for (size_t i = 0; i < lst.size(); i += 4) {\n        __m128 v = _mm_loadu_ps(&lst[i]);\n        __m128i vi = _mm_cvtps_epi32(v);\n        __m128i odd_mask = _mm_andnot_si128(mask, vi);\n        odd_mask = _mm_and_si128(odd_mask, _mm_set1_epi32(1));\n        __m128 odd = _mm_cvtepi32_ps(odd_mask);\n        __m128 odd_squared = _mm_mul_ps(odd, odd);\n        sum = _mm_add_ps(sum, odd_squared);\n    }\n\n    float result[4];\n    _mm_storeu_ps(result, sum);\n    return result[0] + result[1] + result[2] + result[3];\n}\n```"}
{"task_id": "SimdBench_135_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> compare_simd(const std::vector<int>& game, const std::vector<int>& guess) {\n    size_t n = game.size();\n    std::vector<int> result(n);\n\n    for (size_t i = 0; i < n; i += 4) {\n        __m128i game_vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&game[i]));\n        __m128i guess_vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&guess[i]));\n\n        __m128i diff_vec = _mm_sub_epi32(game_vec, guess_vec);\n        __m128i abs_diff_vec = _mm_abs_epi32(diff_vec);\n\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i]), abs_diff_vec);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_135_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> compare_simd(const std::vector<int>& game, const std::vector<int>& guess) {\n    size_t n = game.size();\n    std::vector<int> result(n);\n\n    for (size_t i = 0; i < n; i += 4) {\n        __m128i game_vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&game[i]));\n        __m128i guess_vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&guess[i]));\n\n        __m128i diff_vec = _mm_sub_epi32(game_vec, guess_vec);\n        __m128i abs_diff_vec = _mm_abs_epi32(diff_vec);\n\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i]), abs_diff_vec);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_135_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> compare_simd(const std::vector<int>& game, const std::vector<int>& guess) {\n    size_t size = game.size();\n    std::vector<int> result(size);\n\n    for (size_t i = 0; i < size; i += 4) {\n        __m128i game_vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&game[i]));\n        __m128i guess_vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&guess[i]));\n\n        __m128i diff_vec = _mm_sub_epi32(game_vec, guess_vec);\n        __m128i abs_diff_vec = _mm_abs_epi32(diff_vec);\n\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i]), abs_diff_vec);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_135_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> compare_simd(const std::vector<int>& game, const std::vector<int>& guess) {\n    size_t n = game.size();\n    std::vector<int> result(n);\n\n    for (size_t i = 0; i < n; i += 4) {\n        __m128i game_vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&game[i]));\n        __m128i guess_vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&guess[i]));\n\n        __m128i diff_vec = _mm_sub_epi32(game_vec, guess_vec);\n        __m128i abs_diff_vec = _mm_abs_epi32(diff_vec);\n\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i]), abs_diff_vec);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_135_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> compare_simd(const std::vector<int>& game, const std::vector<int>& guess) {\n    std::vector<int> result(game.size());\n    int n = game.size();\n\n    for (int i = 0; i < n; i += 4) {\n        __m128i game_vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&game[i]));\n        __m128i guess_vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&guess[i]));\n\n        __m128i diff_vec = _mm_sub_epi32(game_vec, guess_vec);\n        __m128i abs_diff_vec = _mm_abs_epi32(diff_vec);\n\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i]), abs_diff_vec);\n    }\n\n    return result;\n}\n```"}

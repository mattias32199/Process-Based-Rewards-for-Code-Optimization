{"task_id": "SimdBench_0_AVX", "completion": "```\nvoid conditional_move_simd(const int64_t *src, int64_t *dst, const bool *mask, size_t length) {\n    for (size_t i = 0; i < length; i += 4) {\n        __m256i src_vec = _mm256_loadu_si256((__m256i*)(src + i));\n        __m256i dst_vec = _mm256_loadu_si256((__m256i*)(dst + i));\n        __m256i mask_vec = _mm256_loadu_si256((__m256i*)(mask + i));\n\n        __m256i result = _mm256_blendv_epi8(dst_vec, src_vec, mask_vec);\n\n        _mm256_storeu_si256((__m256i*)(dst + i), result);\n    }\n}\n```"}
{"task_id": "SimdBench_0_AVX", "completion": "```\nvoid conditional_move_simd(const int64_t *src, int64_t *dst, const bool *mask, size_t length) {\n    for (size_t i = 0; i < length; i += 4) {\n        __m256i src_vec = _mm256_loadu_si256((__m256i*)(src + i));\n        __m256i mask_vec = _mm256_loadu_si256((__m256i*)(mask + i));\n\n        __m256i result = _mm256_blendv_epi8(_mm256_loadu_si256((__m256i*)(dst + i)), src_vec, mask_vec);\n\n        _mm256_storeu_si256((__m256i*)(dst + i), result);\n    }\n}\n```  "}
{"task_id": "SimdBench_0_AVX", "completion": "```c\nvoid conditional_move_simd(const int64_t *src, int64_t *dst, const bool *mask, size_t length) {\n    const int step = 4;\n    for (size_t i = 0; i < length; i += step) {\n        __m256i src_vec = _mm256_loadu_si256((__m256i*)(src + i));\n        __m256i dst_vec = _mm256_loadu_si256((__m256i*)(dst + i));\n        __m256i mask_vec = _mm256_loadu_si256((__m256i*)(mask + i));\n\n        __m256i result = _mm256_blendv_epi8(dst_vec, src_vec, mask_vec);\n\n        _mm256_storeu_si256((__m256i*)(dst + i), result);\n    }\n}\n```"}
{"task_id": "SimdBench_0_AVX", "completion": "```\nvoid conditional_move_simd(const int64_t *src, int64_t *dst, const bool *mask, size_t length) {\n    for (size_t i = 0; i < length; i += 4) {\n        __m256i src_vec = _mm256_loadu_si256((__m256i*)(src + i));\n        __m256i dst_vec = _mm256_loadu_si256((__m256i*)(dst + i));\n        __m256i mask_vec = _mm256_loadu_si256((__m256i*)(mask + i));\n\n        __m256i result = _mm256_blendv_epi8(dst_vec, src_vec, mask_vec);\n\n        _mm256_storeu_si256((__m256i*)(dst + i), result);\n    }\n}\n```"}
{"task_id": "SimdBench_0_AVX", "completion": "```\nvoid conditional_move_simd(const int64_t *src, int64_t *dst, const bool *mask, size_t length) {\n    for (size_t i = 0; i < length; i += 4) {\n        __m256i src_vec = _mm256_loadu_si256((__m256i*)&src[i]);\n        __m256i mask_vec = _mm256_loadu_si256((__m256i*)&mask[i]);\n        \n        __m256i result = _mm256_blendv_epi8(_mm256_loadu_si256((__m256i*)&dst[i]), src_vec, mask_vec);\n        \n        _mm256_storeu_si256((__m256i*)&dst[i], result);\n    }\n}\n```  "}
{"task_id": "SimdBench_1_AVX", "completion": "```c\nvoid load_modify_store_simd(const int *src, int *dst, int scale, size_t length) {\n    __m256i scale_v = _mm256_set1_epi32(scale);\n    __m256i shift_right = _mm256_set1_epi32(3);\n    __m256i shift_left = _mm256_set1_epi32(-3);\n    __m256i div_by = _mm256_set1_epi32(7);\n\n    for (size_t i = 0; i < length; i += 8) {\n        __m256i src_v = _mm256_loadu_si256((__m256i*)(src + i));\n\n        __m256i tmp1 = _mm256_sra_epi32(_mm256_mullo_epi32(src_v, scale_v), shift_right);\n        __m256i tmp2 = _mm256_sll_epi32(_mm256_mullo_epi32(src_v, scale_v), shift_left);\n\n        __m256i result = _mm256_cvtps_epi32(_mm256_div_ps(_mm256_cvtepi32_ps(_mm256_add_epi32(_mm256_mullo_epi32(src_v, scale_v), _mm256_mullo_epi32(tmp1, tmp2))), _mm256_cvtepi32_ps(div_by)));\n\n        _mm256_storeu_si256((__m256i*)(dst + i), result);\n    }\n}\n```"}
{"task_id": "SimdBench_1_AVX", "completion": "```c\nvoid load_modify_store_simd(const int *src, int *dst, int scale, size_t length) {\n    __m256i scale_v = _mm256_set1_epi32(scale);\n    __m256i shift_right = _mm256_set1_epi32(3);\n    __m256i shift_left = _mm256_set1_epi32(-3);\n    __m256i div_by = _mm256_set1_epi32(7);\n\n    for (size_t i = 0; i < length; i += 8) {\n        __m256i src_v = _mm256_loadu_si256((__m256i*)(src + i));\n\n        __m256i tmp1 = _mm256_sra_epi32(_mm256_mullo_epi32(src_v, scale_v), shift_right);\n        __m256i tmp2 = _mm256_sll_epi32(_mm256_mullo_epi32(src_v, scale_v), shift_left);\n\n        __m256i result = _mm256_cvtps_epi32(_mm256_div_ps(_mm256_cvtepi32_ps(_mm256_add_epi32(_mm256_mullo_epi32(src_v, scale_v), _mm256_mullo_epi32(tmp1, tmp2))), _mm256_cvtepi32_ps(div_by)));\n\n        _mm256_storeu_si256((__m256i*)(dst + i), result);\n    }\n}\n```"}
{"task_id": "SimdBench_1_AVX", "completion": "```c\nvoid load_modify_store_simd(const int *src, int *dst, int scale, size_t length) {\n    __m256i scale_v = _mm256_set1_epi32(scale);\n    __m256i shift_right = _mm256_set1_epi32(3);\n    __m256i shift_left = _mm256_set1_epi32(-3);\n    __m256i div_by = _mm256_set1_epi32(7);\n\n    for (size_t i = 0; i < length; i += 8) {\n        __m256i src_v = _mm256_loadu_si256((__m256i*)(src + i));\n\n        __m256i tmp1 = _mm256_sra_epi32(_mm256_mullo_epi32(src_v, scale_v), shift_right);\n        __m256i tmp2 = _mm256_sll_epi32(_mm256_mullo_epi32(src_v, scale_v), shift_left);\n\n        __m256i result = _mm256_cvtps_epi32(_mm256_div_ps(_mm256_cvtepi32_ps(_mm256_add_epi32(_mm256_mullo_epi32(src_v, scale_v), _mm256_mullo_epi32(tmp1, tmp2))), _mm256_cvtepi32_ps(div_by)));\n\n        _mm256_storeu_si256((__m256i*)(dst + i), result);\n    }\n}\n```"}
{"task_id": "SimdBench_1_AVX", "completion": "```c\nvoid load_modify_store_simd(const int *src, int *dst, int scale, size_t length) {\n    __m256i scale_v = _mm256_set1_epi32(scale);\n    __m256i shift_right = _mm256_set1_epi32(3);\n    __m256i shift_left = _mm256_set1_epi32(-3);\n    __m256i div_by = _mm256_set1_epi32(7);\n\n    for (size_t i = 0; i < length; i += 8) {\n        __m256i src_v = _mm256_loadu_si256((__m256i*)(src + i));\n\n        __m256i tmp1 = _mm256_sra_epi32(_mm256_mullo_epi32(src_v, scale_v), shift_right);\n        __m256i tmp2 = _mm256_sll_epi32(_mm256_mullo_epi32(src_v, scale_v), shift_left);\n\n        __m256i result = _mm256_cvtps_epi32(_mm256_div_ps(_mm256_cvtepi32_ps(_mm256_add_epi32(_mm256_mullo_epi32(src_v, scale_v), _mm256_mullo_epi32(tmp1, tmp2))), _mm256_cvtepi32_ps(div_by)));\n\n        _mm256_storeu_si256((__m256i*)(dst + i), result);\n    }\n}\n```"}
{"task_id": "SimdBench_1_AVX", "completion": "```c\nvoid load_modify_store_simd(const int *src, int *dst, int scale, size_t length) {\n    __m256i scale_v = _mm256_set1_epi32(scale);\n    __m256i shift_right = _mm256_set1_epi32(3);\n    __m256i shift_left = _mm256_set1_epi32(-3);\n    __m256i div_by = _mm256_set1_epi32(7);\n\n    for (size_t i = 0; i < length; i += 8) {\n        __m256i src_v = _mm256_loadu_si256((__m256i*)(src + i));\n\n        __m256i tmp1 = _mm256_sra_epi32(_mm256_mullo_epi32(src_v, scale_v), shift_right);\n        __m256i tmp2 = _mm256_sll_epi32(_mm256_mullo_epi32(src_v, scale_v), shift_left);\n\n        __m256i result = _mm256_cvtps_epi32(_mm256_div_ps(_mm256_cvtepi32_ps(_mm256_add_epi32(_mm256_mullo_epi32(src_v, scale_v), _mm256_mullo_epi32(tmp1, tmp2))), _mm256_cvtepi32_ps(div_by)));\n\n        _mm256_storeu_si256((__m256i*)(dst + i), result);\n    }\n}\n```"}
{"task_id": "SimdBench_2_AVX", "completion": "```cpp\nvoid strided_load_store_simd(const double *src, double *dst, size_t rows, size_t cols, size_t stride) {\n    for (size_t r = 0; r < rows; ++r) {\n        __m256d src_vec = _mm256_loadu_pd(&src[r * cols + stride]);\n        _mm256_storeu_pd(&dst[r], src_vec);\n    }\n}\n```"}
{"task_id": "SimdBench_2_AVX", "completion": "```cpp\nvoid strided_load_store_simd(const double *src, double *dst, size_t rows, size_t cols, size_t stride) {\n    for (size_t r = 0; r < rows; ++r) {\n        __m256d src_vec = _mm256_loadu_pd(&src[r * cols + stride]);\n        _mm256_storeu_pd(&dst[r], src_vec);\n    }\n}\n```"}
{"task_id": "SimdBench_2_AVX", "completion": "```cpp\nvoid strided_load_store_simd(const double *src, double *dst, size_t rows, size_t cols, size_t stride) {\n    for (size_t r = 0; r < rows; ++r) {\n        __m256d src_vec = _mm256_loadu_pd(&src[r * cols + stride]);\n        _mm256_storeu_pd(&dst[r], src_vec);\n    }\n}\n```"}
{"task_id": "SimdBench_2_AVX", "completion": "```c\nvoid strided_load_store_simd(const double *src, double *dst, size_t rows, size_t cols, size_t stride) {\n    for (size_t r = 0; r < rows; ++r) {\n        __m256d src_vec = _mm256_loadu_pd(&src[r * cols + stride]);\n        _mm256_storeu_pd(&dst[r], src_vec);\n    }\n}\n```"}
{"task_id": "SimdBench_2_AVX", "completion": "```cpp\nvoid strided_load_store_simd(const double *src, double *dst, size_t rows, size_t cols, size_t stride) {\n    for (size_t r = 0; r < rows; ++r) {\n        __m256d src_vec = _mm256_loadu_pd(&src[r * cols + stride]);\n        _mm256_storeu_pd(&dst[r], src_vec);\n    }\n}\n```"}
{"task_id": "SimdBench_3_AVX", "completion": "```cpp\nvoid indexed_access_simd(const float *src, const int *indices, float *dst, size_t length) {\n    for (size_t i = 0; i < length; i += 8) {\n        __m256i index = _mm256_loadu_si256((__m256i*)&indices[i]);\n        __m256 src_values = _mm256_i32gather_ps(src, index, 4);\n        _mm256_storeu_ps(&dst[i], src_values);\n    }\n}\n```"}
{"task_id": "SimdBench_3_AVX", "completion": "```c\nvoid indexed_access_simd(const float *src, const int *indices, float *dst, size_t length) {\n    for (size_t i = 0; i < length; i += 8) {\n        __m256i index = _mm256_loadu_si256((__m256i*)&indices[i]);\n        __m256 src_values = _mm256_i32gather_ps(src, index, 4);\n        _mm256_storeu_ps(&dst[i], src_values);\n    }\n}\n```"}
{"task_id": "SimdBench_3_AVX", "completion": "```c\nvoid indexed_access_simd(const float *src, const int *indices, float *dst, size_t length) {\n    for (size_t i = 0; i < length; i += 8) {\n        __m256i index = _mm256_loadu_si256((__m256i*)&indices[i]);\n        __m256 src_values = _mm256_i32gather_ps(src, index, 4);\n        _mm256_storeu_ps(&dst[i], src_values);\n    }\n}\n```"}
{"task_id": "SimdBench_3_AVX", "completion": "```cpp\nvoid indexed_access_simd(const float *src, const int *indices, float *dst, size_t length) {\n    for (size_t i = 0; i < length; i += 8) {\n        __m256i index = _mm256_loadu_si256((__m256i*)&indices[i]);\n        __m256 values = _mm256_i32gather_ps(src, index, 4);\n        _mm256_storeu_ps(&dst[i], values);\n    }\n\n    for (size_t i = 0; i < length; i += 8) {\n        __m256i index = _mm256_loadu_si256((__m256i*)&indices[i]);\n        __m256 values = _mm256_loadu_ps(&src[i]);\n        _mm256_i32scatter_ps(dst, index, values, 4);\n    }\n}\n```"}
{"task_id": "SimdBench_3_AVX", "completion": "```cpp\nvoid indexed_access_simd(const float *src, const int *indices, float *dst, size_t length) {\n    for (size_t i = 0; i < length; i += 8) {\n        __m256i index = _mm256_loadu_si256((__m256i*)&indices[i]);\n        __m256 src_values = _mm256_i32gather_ps(src, index, 4);\n        _mm256_storeu_ps(&dst[i], src_values);\n    }\n}\n```"}
{"task_id": "SimdBench_4_AVX", "completion": "```c\nvoid range_reverse_simd(int16_t *arr, uint64_t start, uint64_t end) {\n    __m256i mask = _mm256_set_epi16(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1);\n    uint64_t length = end - start + 1;\n    uint64_t simd_length = length / 16;\n    \n    for (uint64_t i = 0; i < simd_length; i++) {\n        __m256i v1 = _mm256_maskload_epi16((__m128i*)&arr[start + i * 16], mask);\n        __m256i v2 = _mm256_permute4x64_epi64(v1, 0b01001110);\n        _mm256_maskstore_epi16((__m128i*)&arr[start + i * 16], mask, v2);\n    }\n    \n    for (uint64_t i = simd_length * 16; i < length; i++) {\n        int16_t temp = arr[start + i];\n        arr[start + i] = arr[end - i + start];\n        arr[end - i + start] = temp;\n    }\n}\n```"}
{"task_id": "SimdBench_4_AVX", "completion": "```c\nvoid range_reverse_simd(int16_t *arr, uint64_t start, uint64_t end) {\n    __m256i mask = _mm256_set_epi16(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1);\n    uint64_t length = end - start + 1;\n    uint64_t full_chunks = length / 16;\n    uint64_t remaining_elements = length % 16;\n    \n    for (uint64_t i = 0; i < full_chunks; i++) {\n        __m256i chunk = _mm256_maskload_epi16((__m256i*)(arr + start + i * 16), mask);\n        chunk = _mm256_shuffle_epi8(chunk, _mm256_set_epi8(14, 15, 12, 13, 10, 11, 8, 9, 6, 7, 4, 5, 2, 3, 0, 1, 14, 15, 12, 13, 10, 11, 8, 9, 6, 7, 4, 5, 2, 3, 0, 1));\n        _mm256_maskstore_epi16((__m256i*)(arr + start + i * 16), mask, chunk);\n    }\n    \n    for (uint64_t i = 0; i < remaining_elements / 2; i++) {\n        int16_t temp = arr[start + full_chunks * 16 + i];\n        arr[start + full_chunks * 16 + i] = arr[end - i];\n        arr[end - i] = temp;\n    }\n}\n```"}
{"task_id": "SimdBench_4_AVX", "completion": "```c\nvoid range_reverse_simd(int16_t *arr, uint64_t start, uint64_t end) {\n    __m256i mask = _mm256_set_epi64x(0, 0, 0, 0xFFFFFFFFFFFFFFFF);\n    uint64_t i = start;\n    \n    for (; i <= end - 15; i += 16) {\n        __m256i vec1 = _mm256_loadu_si256((__m256i*)&arr[i]);\n        __m256i vec2 = _mm256_loadu_si256((__m256i*)&arr[end - (i - start)]);\n        \n        __m256i temp = _mm256_permute4x64_epi64(vec2, 0b01001110);\n        __m256i result = _mm256_blendv_epi8(vec1, temp, mask);\n        \n        _mm256_storeu_si256((__m256i*)&arr[i], result);\n    }\n    \n    for (; i <= end; ++i) {\n        int16_t temp = arr[i];\n        arr[i] = arr[end - (i - start)];\n        arr[end - (i - start)] = temp;\n    }\n}\n```"}
{"task_id": "SimdBench_4_AVX", "completion": "```c\nvoid range_reverse_simd(int16_t *arr, uint64_t start, uint64_t end) {\n    __m256i mask = _mm256_set_epi16(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n    __m256i* ptr = (__m256i*)(arr + start);\n    int remaining = (end - start + 1) % 16;\n    \n    for (int i = 0; i < (end - start + 1) / 16; i++) {\n        __m256i tmp = _mm256_loadu_si256(ptr + i);\n        __m256i rev = _mm256_permutevar8x16_epi16(tmp, mask);\n        _mm256_storeu_si256(ptr + i, rev);\n    }\n    \n    if (remaining > 0) {\n        int16_t tmp_arr[16];\n        for (int i = 0; i < remaining; i++) {\n            tmp_arr[i] = arr[start + 16 * ((end - start + 1) / 16) + i];\n        }\n        for (int i = 0; i < remaining; i++) {\n            arr[start + 16 * ((end - start + 1) / 16) + i] = tmp_arr[remaining - 1 - i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_4_AVX", "completion": "```c\nvoid range_reverse_simd(int16_t *arr, uint64_t start, uint64_t end) {\n    __m256i mask = _mm256_set_epi16(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n    __m256i* ptr = (__m256i*)(arr + start);\n    int remaining = (end - start + 1) % 16;\n    \n    for (uint64_t i = start; i <= end - 15; i += 16) {\n        __m256i vec = _mm256_loadu_si256(ptr);\n        __m256i rev_vec = _mm256_permutevar8x16_epi8(vec, mask);\n        _mm256_storeu_si256(ptr, rev_vec);\n        ptr++;\n    }\n    \n    if (remaining > 0) {\n        __m256i vec = _mm256_loadu_si256(ptr);\n        __m256i rev_vec = _mm256_permutevar8x16_epi8(vec, mask);\n        _mm256_maskstore_epi16((arr + end - remaining + 1), 0xFFFF >> (16 - remaining), rev_vec);\n    }\n}\n```"}
{"task_id": "SimdBench_5_AVX", "completion": "```cpp\nvoid extract_tensor_slice_simd(const uint8_t *tensor, uint8_t *slice, size_t dim1, size_t dim2, size_t dim3, size_t slice_idx) {\n    size_t slice_size = dim1 * dim2;\n    size_t start_idx = slice_idx * slice_size;\n\n    for (size_t i = 0; i < dim1; ++i) {\n        for (size_t j = 0; j < dim2; j += 32) {\n            __m256i data = _mm256_loadu_si256((__m256i*)(tensor + start_idx + i * dim2 + j));\n            _mm256_storeu_si256((__m256i*)(slice + i * dim2 + j), data);\n        }\n    }\n}\n```  "}
{"task_id": "SimdBench_5_AVX", "completion": "```c\nvoid extract_tensor_slice_simd(const uint8_t *tensor, uint8_t *slice, size_t dim1, size_t dim2, size_t dim3, size_t slice_idx) {\n    size_t slice_size = dim1 * dim2;\n    size_t start_idx = slice_idx * slice_size;\n    \n    for (size_t i = 0; i < dim1; ++i) {\n        for (size_t j = 0; j < dim2; j += 32) {\n            __m256i data = _mm256_loadu_si256((__m256i*)(tensor + start_idx + i * dim2 + j));\n            _mm256_storeu_si256((__m256i*)(slice + i * dim2 + j), data);\n        }\n    }\n}\n```  "}
{"task_id": "SimdBench_5_AVX", "completion": "```cpp\nvoid extract_tensor_slice_simd(const uint8_t *tensor, uint8_t *slice, size_t dim1, size_t dim2, size_t dim3, size_t slice_idx) {\n    size_t slice_size = dim1 * dim2;\n    size_t start_idx = slice_idx * slice_size;\n    \n    for (size_t i = 0; i < dim1; ++i) {\n        for (size_t j = 0; j < dim2; j += 32) {\n            __m256i v_slice = _mm256_loadu_si256((__m256i*)&tensor[start_idx + i * dim2 + j]);\n            _mm256_storeu_si256((__m256i*)&slice[i * dim2 + j], v_slice);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_5_AVX", "completion": "```cpp\nvoid extract_tensor_slice_simd(const uint8_t *tensor, uint8_t *slice, size_t dim1, size_t dim2, size_t dim3, size_t slice_idx) {\n    size_t slice_size = dim1 * dim2;\n    size_t start_idx = slice_idx * slice_size;\n    \n    for (size_t i = 0; i < dim1; ++i) {\n        for (size_t j = 0; j < dim2; j += 32) {\n            __m256i data = _mm256_loadu_si256((__m256i*)(tensor + start_idx + i * dim2 + j));\n            _mm256_storeu_si256((__m256i*)(slice + i * dim2 + j), data);\n        }\n    }\n}\n```  "}
{"task_id": "SimdBench_5_AVX", "completion": "```cpp\nvoid extract_tensor_slice_simd(const uint8_t *tensor, uint8_t *slice, size_t dim1, size_t dim2, size_t dim3, size_t slice_idx) {\n    size_t slice_size = dim1 * dim2;\n    size_t start_idx = slice_idx * slice_size;\n\n    for (size_t i = 0; i < dim1; ++i) {\n        for (size_t j = 0; j < dim2; j += 32) {\n            __m256i slice_data = _mm256_loadu_si256((__m256i*)(tensor + start_idx + i * dim2 + j));\n            _mm256_storeu_si256((__m256i*)(slice + i * dim2 + j), slice_data);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_6_AVX", "completion": "```c\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid blocked_matrix_transpose_simd(const int16_t *src, int16_t *dst, size_t rows, size_t cols, size_t block_size) {\n    for (size_t i = 0; i < rows; i += block_size) {\n        for (size_t j = 0; j < cols; j += block_size) {\n            for (size_t ii = i; ii < i + block_size && ii < rows; ii += 8) {\n                for (size_t jj = j; jj < j + block_size && jj < cols; jj += 8) {\n                    for (size_t iii = ii; iii < ii + 8 && iii < rows; iii++) {\n                        for (size_t jjj = jj; jjj < jj + 8 && jjj < cols; jjj++) {\n                            __m256i vec = _mm256_loadu_si256((__m256i*)&src[iii * cols + jjj]);\n                            __m256i transposed = _mm256_permute4x64_epi64(vec, 0xd8);\n                            _mm256_storeu_si256((__m256i*)&dst[jjj * rows + iii], transposed);\n                        }\n                    }\n                }\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_6_AVX", "completion": "```c\nvoid blocked_matrix_transpose_simd(const int16_t *src, int16_t *dst, size_t rows, size_t cols, size_t block_size) {\n    for (size_t i = 0; i < rows; i += block_size) {\n        for (size_t j = 0; j < cols; j += block_size) {\n            for (size_t ii = i; ii < i + block_size && ii < rows; ii += 8) {\n                for (size_t jj = j; jj < j + block_size && jj < cols; jj += 8) {\n                    __m256i tmp[8];\n                    for (size_t x = 0; x < 8; x++) {\n                        tmp[x] = _mm256_loadu_si256((__m256i*)(src + (jj + x) * rows + ii));\n                    }\n                    for (size_t x = 0; x < 8; x++) {\n                        _mm256_storeu_si256((__m256i*)(dst + (ii + x) * cols + jj), tmp[x]);\n                    }\n                }\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_6_AVX", "completion": "```c\nvoid blocked_matrix_transpose_simd(const int16_t *src, int16_t *dst, size_t rows, size_t cols, size_t block_size) {\n    for (size_t i = 0; i < rows; i += block_size) {\n        for (size_t j = 0; j < cols; j += block_size) {\n            for (size_t ii = i; ii < i + block_size && ii < rows; ii += 8) {\n                for (size_t jj = j; jj < j + block_size && jj < cols; jj += 8) {\n                    for (size_t x = ii; x < ii + 8 && x < rows; x++) {\n                        for (size_t y = jj; y < jj + 8 && y < cols; y++) {\n                            __m256i v_src = _mm256_loadu_si256((__m256i*)&src[x * cols + y]);\n                            __m256i v_dst = _mm256_loadu_si256((__m256i*)&dst[y * rows + x]);\n                            _mm256_storeu_si256((__m256i*)&dst[y * rows + x], v_src);\n                            _mm256_storeu_si256((__m256i*)&src[x * cols + y], v_dst);\n                        }\n                    }\n                }\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_6_AVX", "completion": "```c\nvoid blocked_matrix_transpose_simd(const int16_t *src, int16_t *dst, size_t rows, size_t cols, size_t block_size) {\n    for (size_t i = 0; i < rows; i += block_size) {\n        for (size_t j = 0; j < cols; j += block_size) {\n            for (size_t ii = i; ii < i + block_size && ii < rows; ii += 8) {\n                for (size_t jj = j; jj < j + block_size && jj < cols; jj += 8) {\n                    for (size_t x = ii; x < ii + 8 && x < rows; x++) {\n                        for (size_t y = jj; y < jj + 8 && y < cols; y++) {\n                            __m256i vec1 = _mm256_loadu_si256((__m256i*)&src[x * cols + y]);\n                            __m256i vec2 = _mm256_loadu_si256((__m256i*)&dst[y * rows + x]);\n                            _mm256_storeu_si256((__m256i*)&dst[y * rows + x], vec1);\n                            _mm256_storeu_si256((__m256i*)&src[x * cols + y], vec2);\n                        }\n                    }\n                }\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_6_AVX", "completion": "```c\nvoid blocked_matrix_transpose_simd(const int16_t *src, int16_t *dst, size_t rows, size_t cols, size_t block_size) {\n    for (size_t i = 0; i < rows; i += block_size) {\n        for (size_t j = 0; j < cols; j += block_size) {\n            for (size_t ii = i; ii < i + block_size && ii < rows; ii += 8) {\n                for (size_t jj = j; jj < j + block_size && jj < cols; jj += 8) {\n                    for (size_t i_block = ii; i_block < ii + 8 && i_block < rows; i_block++) {\n                        for (size_t j_block = jj; j_block < jj + 8 && j_block < cols; j_block++) {\n                            __m256i data = _mm256_loadu_si256((__m256i*)&src[i_block * cols + j_block]);\n                            __m256i transposed = _mm256_permute4x64_epi64(data, 0xd8);\n                            _mm256_storeu_si256((__m256i*)&dst[j_block * rows + i_block], transposed);\n                        }\n                    }\n                }\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_7_AVX", "completion": "```c\nfloat diagonal_sum_3d_simd(const float *array, size_t dim) {\n    float sum = 0.0f;\n    size_t size = dim * dim * dim;\n    size_t i = 0;\n\n    __m256 sum_vec = _mm256_setzero_ps();\n\n    for (i = 0; i < size; i += 8) {\n        __m256 values = _mm256_loadu_ps(&array[i]);\n        sum_vec = _mm256_add_ps(sum_vec, values);\n    }\n\n    float sum_array[8];\n    _mm256_storeu_ps(sum_array, sum_vec);\n\n    for (i = 0; i < 8; i++) {\n        sum += sum_array[i];\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_7_AVX", "completion": "```c\nfloat diagonal_sum_3d_simd(const float *array, size_t dim) {\n    float sum = 0.0f;\n    size_t total_elements = dim * dim * dim;\n    size_t elements_per_iteration = 8; // AVX can process 8 floats at a time\n\n    for (size_t i = 0; i < total_elements; i += elements_per_iteration) {\n        __m256 sum_vec = _mm256_setzero_ps();\n\n        for (size_t j = 0; j < elements_per_iteration; j++) {\n            if ((i + j) % (dim*dim + 1) == 0) {\n                __m256 values = _mm256_loadu_ps(&array[i + j]);\n                sum_vec = _mm256_add_ps(sum_vec, values);\n            }\n        }\n\n        float temp_sum[8];\n        _mm256_storeu_ps(temp_sum, sum_vec);\n\n        sum += temp_sum[0] + temp_sum[1] + temp_sum[2] + temp_sum[3] + temp_sum[4] + temp_sum[5] + temp_sum[6] + temp_sum[7];\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_7_AVX", "completion": "```c\nfloat diagonal_sum_3d_simd(const float *array, size_t dim) {\n    size_t size = dim * dim * dim;\n    size_t simd_size = size / 8 * 8;\n    __m256 sum = _mm256_setzero_ps();\n\n    for (size_t i = 0; i < simd_size; i += 8) {\n        __m256 values = _mm256_loadu_ps(&array[i]);\n        sum = _mm256_add_ps(sum, values);\n    }\n\n    float result[8];\n    _mm256_storeu_ps(result, sum);\n\n    float final_sum = 0.0f;\n    for (int i = 0; i < 8; i++) {\n        final_sum += result[i];\n    }\n\n    for (size_t i = simd_size; i < size; i++) {\n        if (i % (dim * dim + 1) == 0) {\n            final_sum += array[i];\n        }\n    }\n\n    return final_sum;\n}\n```"}
{"task_id": "SimdBench_7_AVX", "completion": "```c\nfloat diagonal_sum_3d_simd(const float *array, size_t dim) {\n    size_t size = dim * dim * dim;\n    size_t simd_size = size / 8 * 8;\n    \n    __m256 sum = _mm256_setzero_ps();\n    \n    for (size_t i = 0; i < simd_size; i += 8) {\n        __m256 values = _mm256_loadu_ps(&array[i]);\n        sum = _mm256_add_ps(sum, values);\n    }\n    \n    float result[8];\n    _mm256_storeu_ps(result, sum);\n    \n    float final_sum = 0.0f;\n    for (int i = 0; i < 8; i++) {\n        final_sum += result[i];\n    }\n    \n    for (size_t i = simd_size; i < size; i++) {\n        if (i % (dim*dim + 1) == 0) {\n            final_sum += array[i];\n        }\n    }\n    \n    return final_sum;\n}\n```"}
{"task_id": "SimdBench_7_AVX", "completion": "```c\nfloat diagonal_sum_3d_simd(const float *array, size_t dim) {\n    float sum = 0.0f;\n    size_t size = dim * dim * dim;\n    size_t i = 0;\n\n    __m256 sum_vec = _mm256_setzero_ps();\n\n    for (i = 0; i < size; i += 8) {\n        __m256 values = _mm256_loadu_ps(&array[i]);\n        sum_vec = _mm256_add_ps(sum_vec, values);\n    }\n\n    float temp[8];\n    _mm256_storeu_ps(temp, sum_vec);\n    for (int j = 0; j < 8; j++) {\n        sum += temp[j];\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_8_AVX", "completion": "```c\nvoid conditional_scale_simd(const double *src, double *dst, size_t rows, size_t cols, double threshold, double scale) {\n    const __m256d threshold_v = _mm256_set1_pd(threshold);\n    const __m256d scale_v = _mm256_set1_pd(scale);\n\n    for (size_t i = 0; i < rows * cols; i += 4) {\n        __m256d src_v = _mm256_loadu_pd(&src[i]);\n        __m256d mask = _mm256_cmp_pd(src_v, threshold_v, _CMP_GT_OQ);\n        __m256d scaled_values = _mm256_mul_pd(src_v, scale_v);\n        __m256d result = _mm256_blendv_pd(src_v, scaled_values, mask);\n        _mm256_storeu_pd(&dst[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_8_AVX", "completion": "```cpp\nvoid conditional_scale_simd(const double *src, double *dst, size_t rows, size_t cols, double threshold, double scale) {\n    const __m256d threshold_v = _mm256_set1_pd(threshold);\n    const __m256d scale_v = _mm256_set1_pd(scale);\n\n    for (size_t i = 0; i < rows * cols; i += 4) {\n        __m256d src_v = _mm256_loadu_pd(&src[i]);\n        __m256d mask = _mm256_cmp_pd(src_v, threshold_v, _CMP_GT_OQ);\n        __m256d result = _mm256_blendv_pd(src_v, _mm256_mul_pd(src_v, scale_v), mask);\n        _mm256_storeu_pd(&dst[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_8_AVX", "completion": "```c\nvoid conditional_scale_simd(const double *src, double *dst, size_t rows, size_t cols, double threshold, double scale) {\n    const __m256d threshold_v = _mm256_set1_pd(threshold);\n    const __m256d scale_v = _mm256_set1_pd(scale);\n\n    for (size_t i = 0; i < rows * cols; i += 4) {\n        __m256d src_v = _mm256_loadu_pd(&src[i]);\n        __m256d mask = _mm256_cmp_pd(src_v, threshold_v, _CMP_GT_OS);\n        __m256d scaled_values = _mm256_mul_pd(src_v, scale_v);\n        __m256d result = _mm256_blendv_pd(src_v, scaled_values, mask);\n        _mm256_storeu_pd(&dst[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_8_AVX", "completion": "```c\nvoid conditional_scale_simd(const double *src, double *dst, size_t rows, size_t cols, double threshold, double scale) {\n    const __m256d threshold_v = _mm256_set1_pd(threshold);\n    const __m256d scale_v = _mm256_set1_pd(scale);\n    \n    for (size_t i = 0; i < rows * cols; i += 4) {\n        __m256d src_v = _mm256_loadu_pd(&src[i]);\n        __m256d mask = _mm256_cmp_pd(src_v, threshold_v, _CMP_GT_OQ);\n        __m256d result = _mm256_blendv_pd(src_v, _mm256_mul_pd(src_v, scale_v), mask);\n        _mm256_storeu_pd(&dst[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_8_AVX", "completion": "```c\nvoid conditional_scale_simd(const double *src, double *dst, size_t rows, size_t cols, double threshold, double scale) {\n    const __m256d threshold_v = _mm256_set1_pd(threshold);\n    const __m256d scale_v = _mm256_set1_pd(scale);\n\n    for (size_t i = 0; i < rows * cols; i += 4) {\n        __m256d src_v = _mm256_loadu_pd(&src[i]);\n        __m256d mask = _mm256_cmp_pd(src_v, threshold_v, _CMP_GT_OS);\n        __m256d result = _mm256_blendv_pd(src_v, _mm256_mul_pd(src_v, scale_v), mask);\n        _mm256_storeu_pd(&dst[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_9_AVX", "completion": "```c\nvoid reorder_matrix_rows_simd(const double *src, double *dst, size_t rows, size_t cols, const size_t *indices) {\n    for (size_t i = 0; i < rows; i += 4) {\n        __m256d row0 = _mm256_loadu_pd(&src[indices[i] * cols]);\n        __m256d row1 = _mm256_loadu_pd(&src[indices[i + 1] * cols]);\n        __m256d row2 = _mm256_loadu_pd(&src[indices[i + 2] * cols]);\n        __m256d row3 = _mm256_loadu_pd(&src[indices[i + 3] * cols]);\n\n        _mm256_storeu_pd(&dst[i * cols], row0);\n        _mm256_storeu_pd(&dst[(i + 1) * cols], row1);\n        _mm256_storeu_pd(&dst[(i + 2) * cols], row2);\n        _mm256_storeu_pd(&dst[(i + 3) * cols], row3);\n    }\n}\n```"}
{"task_id": "SimdBench_9_AVX", "completion": "```c\nvoid reorder_matrix_rows_simd(const double *src, double *dst, size_t rows, size_t cols, const size_t *indices) {\n    for (size_t i = 0; i < rows; i += 4) {\n        __m256d row1 = _mm256_loadu_pd(&src[indices[i] * cols]);\n        __m256d row2 = _mm256_loadu_pd(&src[indices[i + 1] * cols]);\n        __m256d row3 = _mm256_loadu_pd(&src[indices[i + 2] * cols]);\n        __m256d row4 = _mm256_loadu_pd(&src[indices[i + 3] * cols]);\n\n        _mm256_storeu_pd(&dst[i * cols], row1);\n        _mm256_storeu_pd(&dst[(i + 1) * cols], row2);\n        _mm256_storeu_pd(&dst[(i + 2) * cols], row3);\n        _mm256_storeu_pd(&dst[(i + 3) * cols], row4);\n    }\n}\n```"}
{"task_id": "SimdBench_9_AVX", "completion": "```cpp\nvoid reorder_matrix_rows_simd(const double *src, double *dst, size_t rows, size_t cols, const size_t *indices) {\n    for (size_t i = 0; i < rows; i += 4) {\n        __m256d vindex = _mm256_set_pd(indices[i+3], indices[i+2], indices[i+1], indices[i]);\n        for (size_t j = 0; j < cols; ++j) {\n            __m256d vsrc = _mm256_i64gather_pd(src + i*cols + j, vindex, 8);\n            _mm256_storeu_pd(dst + (i/4)*cols + j, vsrc);\n        }\n    }\n}\n```  "}
{"task_id": "SimdBench_9_AVX", "completion": "```cpp\nvoid reorder_matrix_rows_simd(const double *src, double *dst, size_t rows, size_t cols, const size_t *indices) {\n    for (size_t i = 0; i < rows; i += 4) {\n        __m256d row0 = _mm256_loadu_pd(&src[indices[i] * cols]);\n        __m256d row1 = _mm256_loadu_pd(&src[indices[i + 1] * cols]);\n        __m256d row2 = _mm256_loadu_pd(&src[indices[i + 2] * cols]);\n        __m256d row3 = _mm256_loadu_pd(&src[indices[i + 3] * cols]);\n\n        _mm256_storeu_pd(&dst[i * cols], row0);\n        _mm256_storeu_pd(&dst[(i + 1) * cols], row1);\n        _mm256_storeu_pd(&dst[(i + 2) * cols], row2);\n        _mm256_storeu_pd(&dst[(i + 3) * cols], row3);\n    }\n}\n```"}
{"task_id": "SimdBench_9_AVX", "completion": "```cpp\nvoid reorder_matrix_rows_simd(const double *src, double *dst, size_t rows, size_t cols, const size_t *indices) {\n    for (size_t i = 0; i < rows; i += 4) {\n        __m256d vindex = _mm256_set_pd(indices[i+3], indices[i+2], indices[i+1], indices[i]);\n        for (size_t j = 0; j < cols; ++j) {\n            __m256d vsrc = _mm256_i32gather_pd(src + i*cols + j, vindex, 8);\n            _mm256_storeu_pd(dst + (i/4)*cols + j, vsrc);\n        }\n    }\n}\n```  "}
{"task_id": "SimdBench_10_AVX", "completion": "```c\nvoid vector_vector_add_simd(const int64_t *src1, const int64_t *src2, int64_t *dst, int64_t scalar, size_t length) {\n    const __m256i scalar_v = _mm256_set1_epi64x(scalar);\n    const __m256i *src1_ptr = (__m256i*)src1;\n    const __m256i *src2_ptr = (__m256i*)src2;\n    __m256i *dst_ptr = (__m256i*)dst;\n    \n    for (size_t i = 0; i < length / 4; i++) {\n        __m256i src1_v = _mm256_loadu_si256(src1_ptr + i);\n        __m256i src2_v = _mm256_loadu_si256(src2_ptr + i);\n        \n        __m256i result = _mm256_add_epi64(src1_v, src2_v);\n        result = _mm256_add_epi64(result, scalar_v);\n        result = _mm256_srai_epi64(result, 1);\n        \n        _mm256_storeu_si256(dst_ptr + i, result);\n    }\n}\n```  "}
{"task_id": "SimdBench_10_AVX", "completion": "```c\nvoid vector_vector_add_simd(const int64_t *src1, const int64_t *src2, int64_t *dst, int64_t scalar, size_t length) {\n    const __m256i scalar_v = _mm256_set1_epi64x(scalar);\n    const __m256i mask = _mm256_set1_epi64x(1);\n    \n    for (size_t i = 0; i < length; i += 4) {\n        __m256i vec1 = _mm256_loadu_si256((__m256i*)(src1 + i));\n        __m256i vec2 = _mm256_loadu_si256((__m256i*)(src2 + i));\n        \n        __m256i result = _mm256_add_epi64(vec1, vec2);\n        result = _mm256_add_epi64(result, scalar_v);\n        result = _mm256_srai_epi64(result, 1);\n        \n        _mm256_storeu_si256((__m256i*)(dst + i), result);\n    }\n}\n```  "}
{"task_id": "SimdBench_10_AVX", "completion": "```cpp\nvoid vector_vector_add_simd(const int64_t *src1, const int64_t *src2, int64_t *dst, int64_t scalar, size_t length) {\n    const __m256i scalar_vec = _mm256_set1_epi64x(scalar);\n    const size_t simd_length = length / 4 * 4;\n\n    for (size_t i = 0; i < simd_length; i += 4) {\n        __m256i vec1 = _mm256_loadu_si256((__m256i*)&src1[i]);\n        __m256i vec2 = _mm256_loadu_si256((__m256i*)&src2[i]);\n\n        __m256i result = _mm256_add_epi64(vec1, vec2);\n        result = _mm256_add_epi64(result, scalar_vec);\n        result = _mm256_srai_epi64(result, 1);\n\n        _mm256_storeu_si256((__m256i*)&dst[i], result);\n    }\n\n    for (size_t i = simd_length; i < length; ++i) {\n        dst[i] = (src1[i] + src2[i] + scalar) / 2;\n    }\n}\n```  "}
{"task_id": "SimdBench_10_AVX", "completion": "```c\nvoid vector_vector_add_simd(const int64_t *src1, const int64_t *src2, int64_t *dst, int64_t scalar, size_t length) {\n    const __m256i scalar_vec = _mm256_set1_epi64x(scalar);\n    const __m256i *src1_ptr = (__m256i*)src1;\n    const __m256i *src2_ptr = (__m256i*)src2;\n    __m256i *dst_ptr = (__m256i*)dst;\n    \n    for (size_t i = 0; i < length / 4; i++) {\n        __m256i vec1 = _mm256_loadu_si256(src1_ptr + i);\n        __m256i vec2 = _mm256_loadu_si256(src2_ptr + i);\n        \n        __m256i result = _mm256_add_epi64(vec1, vec2);\n        result = _mm256_add_epi64(result, scalar_vec);\n        result = _mm256_srai_epi64(result, 1);\n        \n        _mm256_storeu_si256(dst_ptr + i, result);\n    }\n}\n```"}
{"task_id": "SimdBench_10_AVX", "completion": "```cpp\nvoid vector_vector_add_simd(const int64_t *src1, const int64_t *src2, int64_t *dst, int64_t scalar, size_t length) {\n    const __m256i scalar_vec = _mm256_set1_epi64x(scalar);\n    const size_t avx_length = length / 4 * 4;\n\n    for (size_t i = 0; i < avx_length; i += 4) {\n        __m256i vec1 = _mm256_loadu_si256((__m256i*)(src1 + i));\n        __m256i vec2 = _mm256_loadu_si256((__m256i*)(src2 + i));\n\n        __m256i result = _mm256_add_epi64(vec1, vec2);\n        result = _mm256_add_epi64(result, scalar_vec);\n        result = _mm256_srai_epi64(result, 1);\n\n        _mm256_storeu_si256((__m256i*)(dst + i), result);\n    }\n\n    for (size_t i = avx_length; i < length; ++i) {\n        dst[i] = (src1[i] + src2[i] + scalar) / 2;\n    }\n}\n```"}
{"task_id": "SimdBench_11_AVX", "completion": "```\nint vector_even_min_simd(const int *src, size_t length){\n    if (length == 0) {\n        return -1;\n    }\n\n    __m256i min_values = _mm256_set1_epi32(INT_MAX);\n\n    for (size_t i = 0; i < length; i += 8) {\n        __m256i values = _mm256_loadu_si256((__m256i*)&src[i]);\n        __m256i even_mask = _mm256_set1_epi32(0xaaaaaaaa); // Mask for even elements\n\n        __m256i even_values = _mm256_and_si256(values, even_mask);\n        min_values = _mm256_min_epi32(min_values, even_values);\n    }\n\n    __m128i min_values128 = _mm256_extractf128_si256(min_values, 1);\n    __m128i min_values128_permuted = _mm_shuffle_epi32(min_values128, _MM_SHUFFLE(1, 0, 3, 2));\n    __m128i final_min = _mm_min_epi32(min_values128, min_values128_permuted);\n\n    int result[4];\n    _mm_storeu_si128((__m128i*)result, final_min);\n\n    return std::min(std::min(result[0], result[1]), std::min(result[2], result[3]));\n}\n```"}
{"task_id": "SimdBench_11_AVX", "completion": "```\nint vector_even_min_simd(const int *src, size_t length){\n    if (length == 0) {\n        return -1;\n    }\n\n    __m256i min_values = _mm256_set1_epi32(INT_MAX);\n\n    for (size_t i = 0; i < length; i += 8) {\n        __m256i values = _mm256_loadu_si256((__m256i*)&src[i]);\n        __m256i even_mask = _mm256_set1_epi32(0xaaaaaaaa); // Mask to select even-numbered elements\n        __m256i even_values = _mm256_and_si256(values, even_mask);\n        min_values = _mm256_min_epi32(min_values, even_values);\n    }\n\n    __m128i min_values128 = _mm256_extractf128_si256(min_values, 1);\n    __m128i min_values128_permuted = _mm_shuffle_epi32(min_values128, _MM_SHUFFLE(1, 0, 3, 2));\n    __m128i min_values_final = _mm_min_epi32(min_values128, min_values128_permuted);\n    __m128i min_values_final_permuted = _mm_shuffle_epi32(min_values_final, _MM_SHUFFLE(0, 1, 2, 3));\n\n    return _mm_cvtsi128_si32(min_values_final_permuted);\n}\n```"}
{"task_id": "SimdBench_11_AVX", "completion": "```\nint vector_even_min_simd(const int *src, size_t length){\n    if (length == 0) {\n        return -1;\n    }\n\n    __m256i min_values = _mm256_set1_epi32(INT_MAX);\n\n    for (size_t i = 0; i < length; i += 8) {\n        __m256i current_values = _mm256_loadu_si256((__m256i*)(src + i));\n        __m256i even_mask = _mm256_set1_epi32(0xaaaaaaaa); // Mask to select even elements\n\n        __m256i even_values = _mm256_and_si256(current_values, even_mask);\n        min_values = _mm256_min_epi32(min_values, even_values);\n    }\n\n    __m128i min_values128 = _mm_min_epi32(_mm256_castsi256_si128(min_values), _mm256_extracti128_si256(min_values, 1));\n    __m128i min_values128_permuted = _mm_shuffle_epi32(min_values128, _MM_SHUFFLE(2, 3, 0, 1));\n    __m128i final_min = _mm_min_epi32(min_values128, min_values128_permuted);\n\n    return _mm_cvtsi128_si32(final_min);\n}\n```"}
{"task_id": "SimdBench_11_AVX", "completion": "```\nint vector_even_min_simd(const int *src, size_t length){\n    if (length == 0) {\n        return -1;\n    }\n\n    __m256i min_values = _mm256_set1_epi32(INT_MAX);\n\n    for (size_t i = 0; i < length; i += 8) {\n        __m256i values = _mm256_loadu_si256((__m256i*)&src[i]);\n        __m256i even_mask = _mm256_set1_epi32(0xaaaaaaaa); // Mask to select even-numbered elements\n        __m256i even_values = _mm256_and_si256(values, even_mask);\n        min_values = _mm256_min_epi32(min_values, even_values);\n    }\n\n    __m128i min_values128 = _mm256_castsi256_si128(min_values);\n    __m128i min_values_high = _mm256_extracti128_si256(min_values, 1);\n    __m128i min_values_final = _mm_min_epi32(min_values128, min_values_high);\n\n    int result[4];\n    _mm_storeu_si128((__m128i*)result, min_values_final);\n\n    return std::min({result[0], result[1], result[2], result[3]});\n}\n```"}
{"task_id": "SimdBench_11_AVX", "completion": "```\nint vector_even_min_simd(const int *src, size_t length){\n    if (length == 0) {\n        return -1;\n    }\n\n    __m256i min_values = _mm256_set1_epi32(INT_MAX);\n\n    for (size_t i = 0; i < length; i += 8) {\n        __m256i values = _mm256_loadu_si256((__m256i*)&src[i]);\n        __m256i even_mask = _mm256_set1_epi32(0xaaaaaaaa); // Mask to select even-numbered elements\n\n        __m256i even_values = _mm256_and_si256(values, even_mask);\n        min_values = _mm256_min_epi32(min_values, even_values);\n    }\n\n    __m128i min_values128 = _mm256_castsi256_si128(min_values);\n    __m128i min_values128_permuted = _mm_shuffle_epi32(min_values128, _MM_SHUFFLE(1, 0, 3, 2));\n    __m128i min_values128_final = _mm_min_epi32(min_values128, min_values128_permuted);\n\n    return _mm_cvtsi128_si32(min_values128_final);\n}\n```"}
{"task_id": "SimdBench_12_AVX", "completion": "```\nvoid mixed_right_shift_simd(const int *src, int *dst, uint8_t shift, size_t length) {\n    __m256i arith_shift, logic_shift, result;\n    __m256i mask = _mm256_set1_epi32(0xFFFFFFFF);\n\n    for (size_t i = 0; i < length; i += 8) {\n        arith_shift = _mm256_srai_epi32(_mm256_loadu_si256((__m256i*)(src + i)), shift);\n        logic_shift = _mm256_srli_epi32(_mm256_and_si256(_mm256_loadu_si256((__m256i*)(src + i)), mask), shift);\n        result = _mm256_add_epi32(arith_shift, logic_shift);\n        _mm256_storeu_si256((__m256i*)(dst + i), result);\n    }\n}\n```"}
{"task_id": "SimdBench_12_AVX", "completion": "```\nvoid mixed_right_shift_simd(const int *src, int *dst, uint8_t shift, size_t length) {\n    __m256i arith_shift, logical_shift, result;\n    __m256i mask = _mm256_set1_epi32(0x80000000);\n\n    for (size_t i = 0; i < length; i += 8) {\n        arith_shift = _mm256_srai_epi32(_mm256_loadu_si256((__m256i*)(src + i)), shift);\n        logical_shift = _mm256_srli_epi32(_mm256_castsi256_si256(_mm256_and_si256(_mm256_loadu_si256((__m256i*)(src + i)), _mm256_set1_epi32(0x7FFFFFFF))), shift);\n        result = _mm256_add_epi32(arith_shift, logical_shift);\n        _mm256_storeu_si256((__m256i*)(dst + i), result);\n    }\n}\n```"}
{"task_id": "SimdBench_12_AVX", "completion": "```\nvoid mixed_right_shift_simd(const int *src, int *dst, uint8_t shift, size_t length) {\n    __m256i arith_shift, logic_shift, result;\n    __m256i mask = _mm256_set1_epi32(0xFFFFFFFF);\n\n    for (size_t i = 0; i < length; i += 8) {\n        arith_shift = _mm256_srai_epi32(_mm256_loadu_si256((__m256i*)(src + i)), shift);\n        logic_shift = _mm256_srli_epi32(_mm256_and_si256(_mm256_loadu_si256((__m256i*)(src + i)), mask), shift);\n        result = _mm256_add_epi32(arith_shift, logic_shift);\n        _mm256_storeu_si256((__m256i*)(dst + i), result);\n    }\n}\n```"}
{"task_id": "SimdBench_12_AVX", "completion": "```c\nvoid mixed_right_shift_simd(const int *src, int *dst, uint8_t shift, size_t length) {\n    __m256i arith_shift, logical_shift, result;\n    __m256i mask = _mm256_set1_epi32(0x80000000);\n\n    for (size_t i = 0; i < length; i += 8) {\n        arith_shift = _mm256_srai_epi32(_mm256_loadu_si256((__m256i*)(src + i)), shift);\n        logical_shift = _mm256_srli_epi32(_mm256_and_si256(_mm256_loadu_si256((__m256i*)(src + i)), _mm256_set1_epi32(0x7FFFFFFF)), shift);\n        result = _mm256_add_epi32(arith_shift, logical_shift);\n        _mm256_storeu_si256((__m256i*)(dst + i), result);\n    }\n}\n```"}
{"task_id": "SimdBench_12_AVX", "completion": "```c\nvoid mixed_right_shift_simd(const int *src, int *dst, uint8_t shift, size_t length) {\n    __m256i arith_shift, logical_shift, result;\n    __m256i mask = _mm256_set1_epi32(0x80000000);\n\n    for (size_t i = 0; i < length; i += 8) {\n        arith_shift = _mm256_srai_epi32(_mm256_loadu_si256((__m256i*)(src + i)), shift);\n        __m256i src_uint = _mm256_and_si256(_mm256_loadu_si256((__m256i*)(src + i)), _mm256_set1_epi32(0xFFFFFFFF));\n        logical_shift = _mm256_srli_epi32(src_uint, shift);\n        result = _mm256_add_epi32(arith_shift, logical_shift);\n        _mm256_storeu_si256((__m256i*)(dst + i), result);\n    }\n}\n```"}
{"task_id": "SimdBench_13_AVX", "completion": "```c\nint64_t matrix_sum_simd(const int *matrix, size_t rows, size_t cols) {\n    int64_t sum = 0;\n    size_t total_elements = rows * cols;\n    size_t remaining_elements = total_elements % 8;\n    size_t simd_elements = total_elements - remaining_elements;\n\n    __m256i sum_vec = _mm256_setzero_si256();\n\n    for (size_t i = 0; i < simd_elements; i += 8) {\n        __m256i data = _mm256_loadu_si256((__m256i*)&matrix[i]);\n        sum_vec = _mm256_add_epi32(sum_vec, data);\n    }\n\n    int32_t temp_sum[8];\n    _mm256_storeu_si256((__m256i*)temp_sum, sum_vec);\n\n    for (size_t i = 0; i < 8; i++) {\n        sum += temp_sum[i];\n    }\n\n    for (size_t i = simd_elements; i < total_elements; i++) {\n        sum += matrix[i];\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_13_AVX", "completion": "```c\nint64_t matrix_sum_simd(const int *matrix, size_t rows, size_t cols) {\n    int64_t sum = 0;\n    size_t total_elements = rows * cols;\n    size_t remaining_elements = total_elements % 8;\n    size_t simd_elements = total_elements - remaining_elements;\n\n    __m256i sum_vec = _mm256_setzero_si256();\n\n    for (size_t i = 0; i < simd_elements; i += 8) {\n        __m256i data = _mm256_loadu_si256((__m256i*)&matrix[i]);\n        sum_vec = _mm256_add_epi32(sum_vec, data);\n    }\n\n    int32_t temp_sum[8];\n    _mm256_storeu_si256((__m256i*)temp_sum, sum_vec);\n\n    for (size_t i = 0; i < 8; i++) {\n        sum += temp_sum[i];\n    }\n\n    for (size_t i = simd_elements; i < total_elements; i++) {\n        sum += matrix[i];\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_13_AVX", "completion": "```cpp\nint64_t matrix_sum_simd(const int *matrix, size_t rows, size_t cols) {\n    int64_t sum = 0;\n    size_t total_elements = rows * cols;\n    size_t remaining_elements = total_elements % 8;\n    total_elements -= remaining_elements;\n\n    __m256i sum_vec = _mm256_setzero_si256();\n\n    for (size_t i = 0; i < total_elements; i += 8) {\n        __m256i data = _mm256_loadu_si256((__m256i*)&matrix[i]);\n        sum_vec = _mm256_add_epi32(sum_vec, data);\n    }\n\n    alignas(32) int32_t temp[8];\n    _mm256_store_si256((__m256i*)temp, sum_vec);\n    sum = temp[0] + temp[1] + temp[2] + temp[3] + temp[4] + temp[5] + temp[6] + temp[7];\n\n    for (size_t i = total_elements; i < total_elements + remaining_elements; ++i) {\n        sum += matrix[i];\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_13_AVX", "completion": "```cpp\nint64_t matrix_sum_simd(const int *matrix, size_t rows, size_t cols) {\n    int64_t sum = 0;\n    size_t elements = rows * cols;\n    size_t elements_simd = elements / 8 * 8;\n    \n    __m256i sum_vec = _mm256_setzero_si256();\n    \n    for (size_t i = 0; i < elements_simd; i += 8) {\n        __m256i data = _mm256_loadu_si256((__m256i*)(matrix + i));\n        sum_vec = _mm256_add_epi32(sum_vec, data);\n    }\n    \n    alignas(32) int32_t sum_arr[8];\n    _mm256_store_si256((__m256i*)sum_arr, sum_vec);\n    \n    for (int i = 0; i < 8; ++i) {\n        sum += sum_arr[i];\n    }\n    \n    for (size_t i = elements_simd; i < elements; ++i) {\n        sum += matrix[i];\n    }\n    \n    return sum;\n}\n```"}
{"task_id": "SimdBench_13_AVX", "completion": "```c\nint64_t matrix_sum_simd(const int *matrix, size_t rows, size_t cols) {\n    int64_t sum = 0;\n    size_t total_elements = rows * cols;\n    size_t total_elements_avx = total_elements / 8 * 8;\n    \n    __m256i sum_avx = _mm256_setzero_si256();\n    \n    for (size_t i = 0; i < total_elements_avx; i += 8) {\n        __m256i data = _mm256_loadu_si256((__m256i*)&matrix[i]);\n        sum_avx = _mm256_add_epi32(sum_avx, data);\n    }\n    \n    int32_t sum_array[8];\n    _mm256_storeu_si256((__m256i*)sum_array, sum_avx);\n    \n    for (int i = 0; i < 8; i++) {\n        sum += sum_array[i];\n    }\n    \n    for (size_t i = total_elements_avx; i < total_elements; i++) {\n        sum += matrix[i];\n    }\n    \n    return sum;\n}\n```"}
{"task_id": "SimdBench_14_AVX", "completion": "```\nsize_t argmax_simd(const int8_t *src, size_t length) {\n    if (length == 0) {\n        return 0;\n    }\n\n    const int8_t *ptr = src;\n    __m256i max_values = _mm256_set1_epi8(INT8_MIN);\n    __m256i max_indices = _mm256_setzero_si256();\n    __m256i current_values, current_indices;\n\n    for (size_t i = 0; i < length; i += 32) {\n        current_values = _mm256_loadu_si256((__m256i*)(ptr + i));\n        current_indices = _mm256_setr_epi32(0, 1, 2, 3, 4, 5, 6, 7);\n\n        __m256i cmp_mask = _mm256_cmpgt_epi8(current_values, max_values);\n        max_values = _mm256_max_epi8(max_values, current_values);\n        max_indices = _mm256_blendv_epi8(max_indices, current_indices, cmp_mask);\n    }\n\n    alignas(32) int8_t max_values_arr[32];\n    alignas(32) int8_t max_indices_arr[32];\n    _mm256_store_si256((__m256i*)max_values_arr, max_values);\n    _mm256_store_si256((__m256i*)max_indices_arr, max_indices);\n\n    int8_t max_value = INT8_MIN;\n    size_t max_index = 0;\n    for (size_t i = 0; i < 32; i++) {\n        if (max_values_arr[i] > max_value) {\n            max_value = max_values_arr[i];\n            max_index = i;\n        }\n    }\n\n    return max_index;\n}\n```"}
{"task_id": "SimdBench_14_AVX", "completion": "```\nsize_t argmax_simd(const int8_t *src, size_t length) {\n    if (length == 0) {\n        return 0;\n    }\n\n    const int8_t *ptr = src;\n    __m256i max_val = _mm256_set1_epi8(INT8_MIN);\n    __m256i max_idx = _mm256_setzero_si256();\n    __m256i cur_val, cur_idx;\n\n    for (size_t i = 0; i < length; i += 32) {\n        cur_val = _mm256_loadu_si256((__m256i*)(ptr + i));\n        cur_idx = _mm256_setr_epi8(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31);\n        cur_idx = _mm256_add_epi8(cur_idx, _mm256_set1_epi8(i));\n\n        __m256i mask = _mm256_cmpgt_epi8(cur_val, max_val);\n        max_val = _mm256_max_epi8(max_val, cur_val);\n        max_idx = _mm256_blendv_epi8(max_idx, cur_idx, mask);\n    }\n\n    __m128i max_val_lo = _mm256_extracti128_si256(max_val, 0);\n    __m128i max_val_hi = _mm256_extracti128_si256(max_val, 1);\n    __m128i max_idx_lo = _mm256_extracti128_si256(max_idx, 0);\n    __m128i max_idx_hi = _mm256_extracti128_si256(max_idx, 1);\n\n    __m128i final_val = _mm_max_epi8(max_val_lo, max_val_hi);\n    __m128i final_idx = _mm_blendv_epi8(max_idx_lo, max_idx_hi, _mm_cmpgt_epi8(max_val_lo, max_val_hi));\n\n    int8_t result[16];\n    _mm_storeu_si128((__m128i*)result, final_val);\n\n    int8_t max_value = INT8_MIN;\n    size_t max_index = 0;\n    for (int i = 0; i < 16; i++) {\n        if (result[i] > max_value) {\n            max_value = result[i];\n            max_index = final_idx[i];\n        }\n    }\n\n    return max_index;\n}\n```"}
{"task_id": "SimdBench_14_AVX", "completion": "```\nsize_t argmax_simd(const int8_t *src, size_t length) {\n    if (length == 0) {\n        return 0;\n    }\n\n    const int8_t *ptr = src;\n    __m256i max_val = _mm256_set1_epi8(INT8_MIN);\n    __m256i max_idx = _mm256_setzero_si256();\n    size_t i = 0;\n\n    for (; i <= length - 32; i += 32) {\n        __m256i v0 = _mm256_loadu_si256((__m256i*)(ptr + i));\n        __m256i v1 = _mm256_loadu_si256((__m256i*)(ptr + i + 16));\n\n        __m256i mask0 = _mm256_cmpgt_epi8(v0, max_val);\n        __m256i mask1 = _mm256_cmpgt_epi8(v1, max_val);\n\n        max_val = _mm256_max_epi8(max_val, v0);\n        max_val = _mm256_max_epi8(max_val, v1);\n\n        max_idx = _mm256_blendv_epi8(max_idx, _mm256_add_epi8(_mm256_set1_epi8(i), _mm256_setr_epi8(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15)), mask0);\n        max_idx = _mm256_blendv_epi8(max_idx, _mm256_add_epi8(_mm256_set1_epi8(i + 16), _mm256_setr_epi8(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15)), mask1);\n    }\n\n    __m128i max_val_lo = _mm256_castsi256_si128(max_val);\n    __m128i max_val_hi = _mm256_extracti128_si256(max_val, 1);\n    __m128i max_idx_lo = _mm256_castsi256_si128(max_idx);\n    __m128i max_idx_hi = _mm256_extracti128_si256(max_idx, 1);\n\n    __m128i max_val_final = _mm_max_epu8(max_val_lo, max_val_hi);\n    __m128i max_idx_final = _mm_blendv_epi8(max_idx_lo, max_idx_hi, _mm_cmpeq_epi8(max_val_final, max_val_hi));\n\n    int8_t max_val_array[16];\n    int8_t max_idx_array[16];\n    _mm_storeu_si128((__m128i*)max_val_array, max_val_final);\n    _mm_storeu_si128((__m128i*)max_idx_array, max_idx_final);\n\n    int8_t max_val_result = INT8_MIN;\n    size_t max_idx_result = 0;\n\n    for (int j = 0; j < 16; ++j) {\n        if (max_val_array[j] > max_val_result) {\n            max_val_result = max_val_array[j];\n            max_idx_result = i + max_idx_array[j];\n        }\n    }\n\n    return max_idx_result;\n}\n```"}
{"task_id": "SimdBench_14_AVX", "completion": "```\nsize_t argmax_simd(const int8_t *src, size_t length) {\n    if (length == 0) {\n        return 0;\n    }\n\n    const int8_t *ptr = src;\n    __m256i max_values = _mm256_set1_epi8(INT8_MIN);\n    __m256i max_indices = _mm256_setzero_si256();\n    __m256i current_values, current_indices;\n    __m256i cmp_mask, cmp_result;\n\n    for (size_t i = 0; i < length; i += 32) {\n        current_values = _mm256_loadu_si256((__m256i*)(ptr + i));\n        current_indices = _mm256_setr_epi8(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, \n                                           16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31);\n        \n        cmp_mask = _mm256_cmpgt_epi8(current_values, max_values);\n        cmp_result = _mm256_blendv_epi8(max_values, current_values, cmp_mask);\n        max_indices = _mm256_blendv_epi8(max_indices, current_indices, cmp_mask);\n        max_values = cmp_result;\n    }\n\n    __m128i max_values_lo = _mm256_extractf128_si256(max_values, 0);\n    __m128i max_values_hi = _mm256_extractf128_si256(max_values, 1);\n    __m128i max_values_combined = _mm_max_epi8(max_values_lo, max_values_hi);\n\n    __m128i max_indices_lo = _mm256_extractf128_si256(max_indices, 0);\n    __m128i max_indices_hi = _mm256_extractf128_si256(max_indices, 1);\n    __m128i max_indices_combined = _mm_blendv_epi8(max_indices_lo, max_indices_hi, _mm_cmpeq_epi8(max_values_combined, max_values_hi));\n\n    int8_t max_value = _mm_extract_epi8(max_values_combined, 0);\n    int8_t max_index = _mm_extract_epi8(max_indices_combined, 0);\n\n    return max_index;\n}\n```"}
{"task_id": "SimdBench_14_AVX", "completion": "```c\nsize_t argmax_simd(const int8_t *src, size_t length) {\n    if (length == 0) {\n        return 0;\n    }\n\n    const int8_t *ptr = src;\n    __m256i max_val = _mm256_set1_epi8(INT8_MIN);\n    __m256i max_idx = _mm256_setzero_si256();\n    size_t i = 0;\n\n    for (; i <= length - 32; i += 32) {\n        __m256i v0 = _mm256_loadu_si256((__m256i*)(ptr + i));\n        __m256i v1 = _mm256_loadu_si256((__m256i*)(ptr + i + 16));\n\n        __m256i cmp_mask0 = _mm256_cmpgt_epi8(v0, max_val);\n        __m256i cmp_mask1 = _mm256_cmpgt_epi8(v1, max_val);\n\n        max_val = _mm256_max_epi8(max_val, v0);\n        max_val = _mm256_max_epi8(max_val, v1);\n\n        max_idx = _mm256_blendv_epi8(max_idx, _mm256_set1_epi32(i), cmp_mask0);\n        max_idx = _mm256_blendv_epi8(max_idx, _mm256_set1_epi32(i + 16), cmp_mask1);\n    }\n\n    __m128i max_val_lo = _mm256_castsi256_si128(max_val);\n    __m128i max_val_hi = _mm256_extracti128_si256(max_val, 1);\n    __m128i max_idx_lo = _mm256_castsi256_si128(max_idx);\n    __m128i max_idx_hi = _mm256_extracti128_si256(max_idx, 1);\n\n    __m128i cmp_mask_lo = _mm_cmpgt_epi8(max_val_lo, _mm256_castsi256_si128(_mm256_permute2x128_si256(max_val, max_val, 0x81)));\n    __m128i cmp_mask_hi = _mm_cmpgt_epi8(max_val_hi, _mm256_extracti128_si256(_mm256_permute2x128_si256(max_val, max_val, 0x81), 1));\n\n    __m128i final_max_val = _mm_max_epi8(max_val_lo, _mm256_castsi256_si128(_mm256_permute2x128_si256(max_val, max_val, 0x81)));\n    __m128i final_max_idx = _mm_blendv_epi8(max_idx_lo, _mm_add_epi32(max_idx_lo, _mm_set1_epi32(16)), cmp_mask_lo);\n    final_max_idx = _mm_blendv_epi8(final_max_idx, _mm_add_epi32(max_idx_hi, _mm_set1_epi32(16)), cmp_mask_hi);\n\n    int8_t max_val_arr[16];\n    int32_t max_idx_arr[4];\n    _mm_storeu_si128((__m128i*)max_val_arr, final_max_val);\n    _mm_storeu_si128((__m128i*)max_idx_arr, final_max_idx);\n\n    int8_t max_val_result = INT8_MIN;\n    size_t max_idx_result = 0;\n\n    for (int j = 0; j < 16; j++) {\n        if (max_val_arr[j] > max_val_result) {\n            max_val_result = max_val_arr[j];\n            max_idx_result = max_idx_arr[j];\n        }\n    }\n\n    return max_idx_result;\n}\n```"}
{"task_id": "SimdBench_15_AVX", "completion": "```c\nvoid vector_blend_simd(const uint16_t* src1, const uint16_t* src2, uint32_t mask, uint16_t* dst, size_t length) {\n    const __m256i mask_v = _mm256_set1_epi16(mask);\n    const __m256i zero_v = _mm256_setzero_si256();\n\n    for (size_t i = 0; i < length; i += 16) {\n        __m256i index_v = _mm256_setr_epi16(i, i + 1, i + 2, i + 3, i + 4, i + 5, i + 6, i + 7,\n                                            i + 8, i + 9, i + 10, i + 11, i + 12, i + 13, i + 14, i + 15);\n        __m256i and_result = _mm256_and_si256(index_v, mask_v);\n        __m256i cmp_mask = _mm256_cmpgt_epi16(and_result, zero_v);\n\n        __m256i src1_v = _mm256_loadu_si256((__m256i*)(src1 + i));\n        __m256i src2_v = _mm256_loadu_si256((__m256i*)(src2 + i));\n\n        __m256i result = _mm256_blendv_epi8(src2_v, src1_v, cmp_mask);\n\n        _mm256_storeu_si256((__m256i*)(dst + i), result);\n    }\n}\n```"}
{"task_id": "SimdBench_15_AVX", "completion": "```c\nvoid vector_blend_simd(const uint16_t* src1, const uint16_t* src2, uint32_t mask, uint16_t* dst, size_t length) {\n    const __m256i mask_v = _mm256_set1_epi16(mask);\n    const __m256i zero_v = _mm256_setzero_si256();\n\n    for (size_t i = 0; i < length; i += 16) {\n        __m256i index_v = _mm256_setr_epi16(i, i + 1, i + 2, i + 3, i + 4, i + 5, i + 6, i + 7,\n                                            i + 8, i + 9, i + 10, i + 11, i + 12, i + 13, i + 14, i + 15);\n        __m256i and_result = _mm256_and_si256(index_v, mask_v);\n        __m256i cmp_result = _mm256_cmpgt_epi16(and_result, zero_v);\n\n        __m256i src1_v = _mm256_loadu_si256((__m256i*)(src1 + i));\n        __m256i src2_v = _mm256_loadu_si256((__m256i*)(src2 + i));\n\n        __m256i result = _mm256_blendv_epi8(src2_v, src1_v, cmp_result);\n\n        _mm256_storeu_si256((__m256i*)(dst + i), result);\n    }\n}\n```  "}
{"task_id": "SimdBench_15_AVX", "completion": "```cpp\nvoid vector_blend_simd(const uint16_t* src1, const uint16_t* src2, uint32_t mask, uint16_t* dst, size_t length) {\n    const __m256i mask_v = _mm256_set1_epi32(mask);\n    const __m256i zero_v = _mm256_setzero_si256();\n\n    for (size_t i = 0; i < length; i += 16) {\n        __m256i index_v = _mm256_setr_epi32(i, i + 1, i + 2, i + 3, i + 4, i + 5, i + 6, i + 7);\n        __m256i src1_v = _mm256_loadu_si256((__m256i*)(src1 + i));\n        __m256i src2_v = _mm256_loadu_si256((__m256i*)(src2 + i));\n\n        __m256i and_result = _mm256_and_si256(index_v, mask_v);\n        __m256i cmp_result = _mm256_cmpgt_epi32(and_result, zero_v);\n\n        __m256i blend_result = _mm256_blendv_epi8(src2_v, src1_v, cmp_result);\n\n        _mm256_storeu_si256((__m256i*)(dst + i), blend_result);\n    }\n}\n```"}
{"task_id": "SimdBench_15_AVX", "completion": "```cpp\nvoid vector_blend_simd(const uint16_t* src1, const uint16_t* src2, uint32_t mask, uint16_t* dst, size_t length) {\n    const __m256i mask_v = _mm256_set1_epi16(mask);\n    const __m256i zero_v = _mm256_setzero_si256();\n\n    for (size_t i = 0; i < length; i += 16) {\n        __m256i indices = _mm256_setr_epi16(i, i + 1, i + 2, i + 3, i + 4, i + 5, i + 6, i + 7,\n                                            i + 8, i + 9, i + 10, i + 11, i + 12, i + 13, i + 14, i + 15);\n        __m256i and_result = _mm256_and_si256(indices, mask_v);\n        __m256i cmp_result = _mm256_cmpgt_epi16(and_result, zero_v);\n\n        __m256i src1_values = _mm256_loadu_si256((__m256i*)(src1 + i));\n        __m256i src2_values = _mm256_loadu_si256((__m256i*)(src2 + i));\n\n        __m256i result = _mm256_blendv_epi8(src2_values, src1_values, cmp_result);\n\n        _mm256_storeu_si256((__m256i*)(dst + i), result);\n    }\n}\n```"}
{"task_id": "SimdBench_15_AVX", "completion": "```cpp\nvoid vector_blend_simd(const uint16_t* src1, const uint16_t* src2, uint32_t mask, uint16_t* dst, size_t length) {\n    const __m256i mask_v = _mm256_set1_epi16(mask);\n    for (size_t i = 0; i < length; i += 16) {\n        __m256i index = _mm256_setr_epi16(i, i + 1, i + 2, i + 3, i + 4, i + 5, i + 6, i + 7, i + 8, i + 9, i + 10, i + 11, i + 12, i + 13, i + 14, i + 15);\n        __m256i src1_v = _mm256_loadu_si256((__m256i*)(src1 + i));\n        __m256i src2_v = _mm256_loadu_si256((__m256i*)(src2 + i));\n        __m256i and_result = _mm256_and_si256(index, mask_v);\n        __m256i result = _mm256_blendv_epi8(src2_v, src1_v, and_result);\n        _mm256_storeu_si256((__m256i*)(dst + i), result);\n    }\n}\n```"}
{"task_id": "SimdBench_16_AVX", "completion": "```c\nvoid population_count_simd(const uint32_t* src, uint32_t* dst, size_t length) {\n    for (size_t i = 0; i < length; i += 8) {\n        __m256i vsrc = _mm256_loadu_si256((__m256i*)(src + i));\n        __m256i vones = _mm256_set1_epi32(1);\n        __m256i vpcount = _mm256_setzero_si256();\n\n        for (int j = 0; j < 32; ++j) {\n            __m256i vbit = _mm256_and_si256(vsrc, vones);\n            vpcount = _mm256_add_epi32(vpcount, vbit);\n            vsrc = _mm256_srli_epi32(vsrc, 1);\n        }\n\n        _mm256_storeu_si256((__m256i*)(dst + i), vpcount);\n    }\n}\n```  "}
{"task_id": "SimdBench_16_AVX", "completion": "```c\nvoid population_count_simd(const uint32_t* src, uint32_t* dst, size_t length) {\n    for (size_t i = 0; i < length; i += 8) {\n        __m256i vsrc = _mm256_loadu_si256((__m256i*)(src + i));\n        __m256i vones = _mm256_set1_epi32(1);\n        __m256i vpcount = _mm256_setzero_si256();\n\n        for (int j = 0; j < 32; ++j) {\n            __m256i vbit = _mm256_and_si256(vsrc, vones);\n            vpcount = _mm256_add_epi32(vpcount, vbit);\n            vsrc = _mm256_srli_epi32(vsrc, 1);\n        }\n\n        _mm256_storeu_si256((__m256i*)(dst + i), vpcount);\n    }\n}\n```"}
{"task_id": "SimdBench_16_AVX", "completion": "```c\nvoid population_count_simd(const uint32_t* src, uint32_t* dst, size_t length) {\n    for (size_t i = 0; i < length; i += 8) {\n        __m256i vsrc = _mm256_loadu_si256((__m256i*)(src + i));\n        __m256i vones = _mm256_set1_epi32(1);\n        __m256i vcount = _mm256_setzero_si256();\n\n        for (int j = 0; j < 32; ++j) {\n            __m256i vbit = _mm256_and_si256(vsrc, vones);\n            vcount = _mm256_add_epi32(vcount, vbit);\n            vsrc = _mm256_srli_epi32(vsrc, 1);\n        }\n\n        _mm256_storeu_si256((__m256i*)(dst + i), vcount);\n    }\n}\n```"}
{"task_id": "SimdBench_16_AVX", "completion": "```c\nvoid population_count_simd(const uint32_t* src, uint32_t* dst, size_t length) {\n    for (size_t i = 0; i < length; i += 8) {\n        __m256i vsrc = _mm256_loadu_si256((__m256i*)(src + i));\n        __m256i vcount = _mm256_popcnt_epi32(vsrc);\n        _mm256_storeu_si256((__m256i*)(dst + i), vcount);\n    }\n}\n```"}
{"task_id": "SimdBench_16_AVX", "completion": "```\nvoid population_count_simd(const uint32_t* src, uint32_t* dst, size_t length) {\n    for (size_t i = 0; i < length; i += 8) {\n        __m256i vsrc = _mm256_loadu_si256((__m256i*)(src + i));\n        __m256i vones = _mm256_set1_epi32(1);\n        __m256i vcount = _mm256_setzero_si256();\n\n        for (int j = 0; j < 32; ++j) {\n            __m256i vbit = _mm256_and_si256(vsrc, vones);\n            vcount = _mm256_add_epi32(vcount, vbit);\n            vsrc = _mm256_srli_epi32(vsrc, 1);\n        }\n\n        _mm256_storeu_si256((__m256i*)(dst + i), vcount);\n    }\n}\n```"}
{"task_id": "SimdBench_17_AVX", "completion": "```\nvoid saturating_add_simd(const uint16_t* src1, const uint16_t* src2, uint16_t* dst, size_t length) {\n    const int chunk_size = 16;\n    const __m256i max_val = _mm256_set1_epi16(UINT16_MAX);\n\n    for (size_t i = 0; i < length; i += chunk_size) {\n        __m256i vec1 = _mm256_loadu_si256((__m256i*)(src1 + i));\n        __m256i vec2 = _mm256_loadu_si256((__m256i*)(src2 + i));\n\n        __m256i sum = _mm256_adds_epu16(vec1, vec2);\n        sum = _mm256_min_epu16(sum, max_val);\n\n        _mm256_storeu_si256((__m256i*)(dst + i), sum);\n    }\n}\n```"}
{"task_id": "SimdBench_17_AVX", "completion": "```\nvoid saturating_add_simd(const uint16_t* src1, const uint16_t* src2, uint16_t* dst, size_t length) {\n    const int chunkSize = 16;\n    const __m256i maxVal = _mm256_set1_epi16(UINT16_MAX);\n\n    for (size_t i = 0; i < length; i += chunkSize) {\n        __m256i vec1 = _mm256_loadu_si256((__m256i*)(src1 + i));\n        __m256i vec2 = _mm256_loadu_si256((__m256i*)(src2 + i));\n\n        __m256i sum = _mm256_adds_epu16(vec1, vec2);\n        sum = _mm256_min_epu16(sum, maxVal);\n\n        _mm256_storeu_si256((__m256i*)(dst + i), sum);\n    }\n}\n```"}
{"task_id": "SimdBench_17_AVX", "completion": "```\nvoid saturating_add_simd(const uint16_t* src1, const uint16_t* src2, uint16_t* dst, size_t length) {\n    size_t i = 0;\n    const size_t simd_length = length / 8 * 8;\n    \n    __m256i max_val = _mm256_set1_epi16(UINT16_MAX);\n    \n    for (; i < simd_length; i += 8) {\n        __m128i src1_lo = _mm_loadu_si128((__m128i*)(src1 + i));\n        __m128i src1_hi = _mm_loadu_si128((__m128i*)(src1 + i + 8));\n        __m128i src2_lo = _mm_loadu_si128((__m128i*)(src2 + i));\n        __m128i src2_hi = _mm_loadu_si128((__m128i*)(src2 + i + 8));\n        \n        __m256i result_lo = _mm256_adds_epu16(_mm256_cvtepu16_epi32(src1_lo), _mm256_cvtepu16_epi32(src2_lo));\n        __m256i result_hi = _mm256_adds_epu16(_mm256_cvtepu16_epi32(src1_hi), _mm256_cvtepu16_epi32(src2_hi));\n        \n        result_lo = _mm256_min_epu16(result_lo, max_val);\n        result_hi = _mm256_min_epu16(result_hi, max_val);\n        \n        _mm_storeu_si128((__m128i*)(dst + i), _mm256_extractf128_si256(result_lo, 0));\n        _mm_storeu_si128((__m128i*)(dst + i + 8), _mm256_extractf128_si256(result_hi, 0));\n    }\n    \n    for (; i < length; ++i) {\n        uint16_t sum = src1[i] + src2[i];\n        dst[i] = sum > UINT16_MAX ? UINT16_MAX : sum;\n    }\n}\n```"}
{"task_id": "SimdBench_17_AVX", "completion": "```\nvoid saturating_add_simd(const uint16_t* src1, const uint16_t* src2, uint16_t* dst, size_t length) {\n    const int chunk_size = 16;\n    const __m256i max_val = _mm256_set1_epi16(UINT16_MAX);\n\n    for (size_t i = 0; i < length; i += chunk_size) {\n        __m256i vec1 = _mm256_loadu_si256((__m256i*)(src1 + i));\n        __m256i vec2 = _mm256_loadu_si256((__m256i*)(src2 + i));\n\n        __m256i result = _mm256_adds_epu16(vec1, vec2);\n        result = _mm256_min_epu16(result, max_val);\n\n        _mm256_storeu_si256((__m256i*)(dst + i), result);\n    }\n}\n```"}
{"task_id": "SimdBench_17_AVX", "completion": "```\nvoid saturating_add_simd(const uint16_t* src1, const uint16_t* src2, uint16_t* dst, size_t length) {\n    const int chunkSize = 16;\n    const __m256i maxVal = _mm256_set1_epi16(UINT16_MAX);\n\n    for (size_t i = 0; i < length; i += chunkSize) {\n        __m256i vec1 = _mm256_loadu_si256((__m256i*)(src1 + i));\n        __m256i vec2 = _mm256_loadu_si256((__m256i*)(src2 + i));\n\n        __m256i result = _mm256_adds_epu16(vec1, vec2);\n        result = _mm256_min_epu16(result, maxVal);\n\n        _mm256_storeu_si256((__m256i*)(dst + i), result);\n    }\n}\n```"}
{"task_id": "SimdBench_18_AVX", "completion": "```cpp\nvoid range_matrix_mul_simd(const double* A, const double* B, double* C, size_t m, size_t n, size_t p) {\n    for (size_t i = 0; i < m; ++i) {\n        for (size_t j = 0; j < p; ++j) {\n            __m256d sum = _mm256_setzero_pd();\n            for (size_t k = 0; k < n; k += 4) {\n                __m256d a = _mm256_loadu_pd(&A[i * n + k]);\n                __m256d b = _mm256_loadu_pd(&B[k * p + j]);\n                __m256d mask_a = _mm256_cmp_pd(a, _mm256_set1_pd(-100.0), _CMP_GE_OQ);\n                __m256d mask_b = _mm256_cmp_pd(b, _mm256_set1_pd(-100.0), _CMP_GE_OQ);\n                __m256d mask = _mm256_and_pd(mask_a, mask_b);\n                __m256d result = _mm256_mul_pd(a, b);\n                sum = _mm256_add_pd(sum, _mm256_and_pd(result, mask));\n            }\n            C[i * p + j] = _mm256_cvtsd_f64(_mm256_hadd_pd(_mm256_hadd_pd(sum, _mm256_setzero_pd()), _mm256_setzero_pd()));\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_18_AVX", "completion": "```c\nvoid range_matrix_mul_simd(const double* A, const double* B, double* C, size_t m, size_t n, size_t p) {\n    for (size_t i = 0; i < m; ++i) {\n        for (size_t j = 0; j < p; ++j) {\n            __m256d sum = _mm256_setzero_pd();\n            for (size_t k = 0; k < n; k += 4) {\n                __m256d a = _mm256_loadu_pd(&A[i * n + k]);\n                __m256d b = _mm256_loadu_pd(&B[k * p + j]);\n                __m256d mask_a = _mm256_cmp_pd(a, _mm256_set1_pd(-100.0), _CMP_GE_OQ);\n                __m256d mask_b = _mm256_cmp_pd(b, _mm256_set1_pd(-100.0), _CMP_GE_OQ);\n                __m256d mask = _mm256_and_pd(mask_a, mask_b);\n                __m256d prod = _mm256_mul_pd(a, b);\n                sum = _mm256_add_pd(sum, _mm256_and_pd(mask, prod));\n            }\n            C[i * p + j] = _mm256_reduce_add_pd(sum);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_18_AVX", "completion": "```cpp\nvoid range_matrix_mul_simd(const double* A, const double* B, double* C, size_t m, size_t n, size_t p) {\n    for (size_t i = 0; i < m; ++i) {\n        for (size_t j = 0; j < p; ++j) {\n            __m256d sum = _mm256_setzero_pd();\n            for (size_t k = 0; k < n; k += 4) {\n                __m256d a = _mm256_loadu_pd(&A[i * n + k]);\n                __m256d b = _mm256_loadu_pd(&B[k * p + j]);\n                __m256d mask_a = _mm256_cmp_pd(a, _mm256_set1_pd(-100.0), _CMP_GE_OQ);\n                __m256d mask_b = _mm256_cmp_pd(b, _mm256_set1_pd(-100.0), _CMP_GE_OQ);\n                __m256d mask = _mm256_and_pd(mask_a, mask_b);\n                __m256d prod = _mm256_mul_pd(a, b);\n                sum = _mm256_add_pd(sum, _mm256_and_pd(prod, mask));\n            }\n            C[i * p + j] = sum[0] + sum[1] + sum[2] + sum[3];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_18_AVX", "completion": "```c\nvoid range_matrix_mul_simd(const double* A, const double* B, double* C, size_t m, size_t n, size_t p) {\n    for (size_t i = 0; i < m; ++i) {\n        for (size_t j = 0; j < p; ++j) {\n            __m256d sum = _mm256_setzero_pd();\n            for (size_t k = 0; k < n; k += 4) {\n                __m256d a = _mm256_loadu_pd(&A[i * n + k]);\n                __m256d b = _mm256_loadu_pd(&B[k * p + j]);\n                __m256d mask_a = _mm256_cmp_pd(a, _mm256_set1_pd(-100.0), _CMP_GE_OQ);\n                __m256d mask_b = _mm256_cmp_pd(b, _mm256_set1_pd(-100.0), _CMP_GE_OQ);\n                __m256d mask = _mm256_and_pd(mask_a, mask_b);\n                if (!_mm256_testz_pd(mask, mask)) {\n                    __m256d prod = _mm256_mul_pd(a, b);\n                    sum = _mm256_add_pd(sum, _mm256_and_pd(prod, mask));\n                }\n            }\n            _mm256_storeu_pd(&C[i * p + j], sum);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_18_AVX", "completion": "```cpp\nvoid range_matrix_mul_simd(const double* A, const double* B, double* C, size_t m, size_t n, size_t p) {\n    for (size_t i = 0; i < m; ++i) {\n        for (size_t j = 0; j < p; ++j) {\n            __m256d sum = _mm256_setzero_pd();\n            for (size_t k = 0; k < n; k += 4) {\n                __m256d a = _mm256_loadu_pd(&A[i * n + k]);\n                __m256d b = _mm256_loadu_pd(&B[k * p + j]);\n                __m256d mask_a = _mm256_cmp_pd(a, _mm256_set1_pd(-100.0), _CMP_GE_OQ);\n                __m256d mask_b = _mm256_cmp_pd(b, _mm256_set1_pd(-100.0), _CMP_GE_OQ);\n                __m256d mask = _mm256_and_pd(mask_a, mask_b);\n                __m256d result = _mm256_mul_pd(a, b);\n                result = _mm256_and_pd(result, mask);\n                sum = _mm256_add_pd(sum, result);\n            }\n            C[i * p + j] = _mm256_reduce_add_pd(sum);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_19_AVX", "completion": "```cpp\nvoid tensor_add_3d_simd(const int64_t* A, const int64_t* B, int64_t* C, size_t dim1, size_t dim2, size_t dim3) {\n    for (size_t i = 0; i < dim1 * dim2 * dim3; i += 4) {\n        __m256i a = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i b = _mm256_loadu_si256((__m256i*)&B[i]);\n        __m256i result = _mm256_add_epi64(a, b);\n        _mm256_storeu_si256((__m256i*)&C[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_19_AVX", "completion": "```cpp\nvoid tensor_add_3d_simd(const int64_t* A, const int64_t* B, int64_t* C, size_t dim1, size_t dim2, size_t dim3) {\n    for (size_t i = 0; i < dim1 * dim2 * dim3; i += 4) {\n        __m256i a = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i b = _mm256_loadu_si256((__m256i*)&B[i]);\n        __m256i result = _mm256_add_epi64(a, b);\n        _mm256_storeu_si256((__m256i*)&C[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_19_AVX", "completion": "```cpp\nvoid tensor_add_3d_simd(const int64_t* A, const int64_t* B, int64_t* C, size_t dim1, size_t dim2, size_t dim3) {\n    for (size_t i = 0; i < dim1 * dim2 * dim3; i += 4) {\n        __m256i a = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i b = _mm256_loadu_si256((__m256i*)&B[i]);\n        __m256i result = _mm256_add_epi64(a, b);\n        _mm256_storeu_si256((__m256i*)&C[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_19_AVX", "completion": "```cpp\nvoid tensor_add_3d_simd(const int64_t* A, const int64_t* B, int64_t* C, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_size = dim1 * dim2 * dim3;\n    size_t simd_size = sizeof(__m256i) / sizeof(int64_t);\n    \n    for (size_t i = 0; i < total_size; i += simd_size) {\n        __m256i va = _mm256_loadu_si256((__m256i*)(A + i));\n        __m256i vb = _mm256_loadu_si256((__m256i*)(B + i));\n        __m256i vc = _mm256_add_epi64(va, vb);\n        _mm256_storeu_si256((__m256i*)(C + i), vc);\n    }\n}\n```"}
{"task_id": "SimdBench_19_AVX", "completion": "```cpp\nvoid tensor_add_3d_simd(const int64_t* A, const int64_t* B, int64_t* C, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_size = dim1 * dim2 * dim3;\n    size_t simd_size = 4; // AVX2 can process 4 int64_t elements in parallel\n\n    for (size_t i = 0; i < total_size; i += simd_size) {\n        __m256i vecA = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i vecB = _mm256_loadu_si256((__m256i*)&B[i]);\n        __m256i vecC = _mm256_add_epi64(vecA, vecB);\n        _mm256_storeu_si256((__m256i*)&C[i], vecC);\n    }\n}\n```"}
{"task_id": "SimdBench_20_AVX", "completion": "```\nvoid vector_add_round_nearest_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    const int step = 8;\n    const int remainder = length % step;\n    const int loop_length = length - remainder;\n\n    __m256i rounding_mask = _mm256_set1_epi32(0x7FFFFFFF);\n    __m256 rounding_offset = _mm256_set1_ps(0.5f);\n    __m256i rounding_offset_int = _mm256_set1_epi32(0x3F000000);\n\n    for (size_t i = 0; i < loop_length; i += step) {\n        __m256 vec1 = _mm256_loadu_ps(&src1[i]);\n        __m256 vec2 = _mm256_loadu_ps(&src2[i]);\n\n        __m256 sum = _mm256_add_ps(vec1, vec2);\n        __m256 rounded = _mm256_add_ps(sum, rounding_offset);\n        __m256i rounded_int = _mm256_cvtps_epi32(rounded);\n        __m256i result = _mm256_and_si256(rounded_int, rounding_mask);\n        _mm256_storeu_ps(&dst[i], _mm256_castsi256_ps(result));\n    }\n\n    for (size_t i = loop_length; i < length; ++i) {\n        dst[i] = (float)(int)(src1[i] + src2[i] + 0.5f);\n    }\n}\n```"}
{"task_id": "SimdBench_20_AVX", "completion": "```c\nvoid vector_add_round_nearest_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    const int step = 8;\n    const int remainder = length % step;\n    const int loop_length = length - remainder;\n\n    __m256i rounding_mask = _mm256_set1_epi32(0x7FFFFFFF);\n    __m256 rounding_offset = _mm256_set1_ps(0.5f);\n    __m256i rounding_offset_int = _mm256_set1_epi32(0x3F000000);\n\n    for (size_t i = 0; i < loop_length; i += step) {\n        __m256 vec1 = _mm256_loadu_ps(&src1[i]);\n        __m256 vec2 = _mm256_loadu_ps(&src2[i]);\n        __m256 result = _mm256_add_ps(vec1, vec2);\n        result = _mm256_add_ps(result, rounding_offset);\n        __m256i int_result = _mm256_cvtps_epi32(result);\n        int_result = _mm256_and_si256(int_result, rounding_mask);\n        int_result = _mm256_add_epi32(int_result, rounding_offset_int);\n        _mm256_storeu_ps(&dst[i], _mm256_cvtepi32_ps(int_result));\n    }\n\n    for (size_t i = loop_length; i < length; ++i) {\n        dst[i] = roundf(src1[i] + src2[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_20_AVX", "completion": "```c\nvoid vector_add_round_nearest_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    const int step = 8;\n    const int remainder = length % step;\n    const int loop_length = length - remainder;\n\n    __m256i rounding_offset = _mm256_set1_epi32(0x8000);\n    __m256 rounding_offset_f = _mm256_castsi256_ps(rounding_offset);\n\n    for (int i = 0; i < loop_length; i += step) {\n        __m256 vec1 = _mm256_loadu_ps(&src1[i]);\n        __m256 vec2 = _mm256_loadu_ps(&src2[i]);\n        __m256 sum = _mm256_add_ps(vec1, vec2);\n        __m256 rounded = _mm256_round_ps(sum, _MM_FROUND_TO_NEAREST_INT);\n        __m256i result = _mm256_cvtps_epi32(_mm256_add_ps(rounded, rounding_offset_f));\n        _mm256_storeu_ps(&dst[i], _mm256_cvtepi32_ps(result));\n    }\n\n    for (int i = loop_length; i < length; ++i) {\n        dst[i] = (float)lrintf(src1[i] + src2[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_20_AVX", "completion": "```c\nvoid vector_add_round_nearest_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    const int step = 8;\n    const int remainder = length % step;\n    const int loop_length = length - remainder;\n\n    __m256i rounding_mask = _mm256_set1_epi32(0x7FFFFFFF);\n    __m256 rounding_offset = _mm256_set1_ps(0.5f);\n    __m256i one = _mm256_set1_epi32(1);\n\n    for (int i = 0; i < loop_length; i += step) {\n        __m256 vec1 = _mm256_loadu_ps(&src1[i]);\n        __m256 vec2 = _mm256_loadu_ps(&src2[i]);\n        __m256 sum = _mm256_add_ps(vec1, vec2);\n        sum = _mm256_add_ps(sum, rounding_offset);\n        __m256i int_sum = _mm256_cvtps_epi32(sum);\n        int_sum = _mm256_and_si256(int_sum, rounding_mask);\n        _mm256_storeu_ps(&dst[i], _mm256_cvtepi32_ps(int_sum));\n    }\n\n    for (int i = loop_length; i < length; ++i) {\n        dst[i] = (float)(int)(src1[i] + src2[i] + 0.5f);\n    }\n}\n```"}
{"task_id": "SimdBench_20_AVX", "completion": "```c\nvoid vector_add_round_nearest_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    const int step = 8;\n    const int remainder = length % step;\n    const int loop_length = length - remainder;\n\n    __m256i rounding_mask = _mm256_set1_epi32(0x7FFFFFFF);\n    __m256 rounding_offset = _mm256_set1_ps(0.5f);\n    \n    for (int i = 0; i < loop_length; i += step) {\n        __m256 vec1 = _mm256_loadu_ps(&src1[i]);\n        __m256 vec2 = _mm256_loadu_ps(&src2[i]);\n        __m256 result = _mm256_round_ps(_mm256_add_ps(vec1, vec2), _MM_FROUND_TO_NEAREST_INT);\n        _mm256_storeu_ps(&dst[i], result);\n    }\n\n    for (int i = loop_length; i < length; ++i) {\n        dst[i] = roundf(src1[i] + src2[i]);\n    }\n}\n```  "}
{"task_id": "SimdBench_21_AVX", "completion": "```\nvoid vector_mul_round_up_simd(const float* src1, const float* src2, float* dst, size_t length){\n    __m256i mask = _mm256_set1_epi32(0x80000000);\n    __m256i fifty = _mm256_set1_epi32(50);\n    __m256i two = _mm256_set1_epi32(2);\n    __m256i one = _mm256_set1_epi32(1);\n    __m256i minus_one = _mm256_set1_epi32(-1);\n\n    for (size_t i = 0; i < length; i += 8) {\n        __m256 a = _mm256_loadu_ps(&src1[i]);\n        __m256 b = _mm256_loadu_ps(&src2[i]);\n\n        __m256 diff = _mm256_sub_ps(a, b);\n        __m256 abs_diff = _mm256_andnot_ps(mask, diff);\n        __m256i abs_diff_int = _mm256_cvtps_epi32(abs_diff);\n\n        __m256i mask1 = _mm256_cmpgt_epi32(abs_diff_int, fifty);\n        __m256i mask2 = _mm256_cmplt_epi32(abs_diff_int, fifty);\n        __m256i mask3 = _mm256_and_si256(mask1, mask2);\n\n        __m256i indices = _mm256_setr_epi32(0, 1, 2, 3, 4, 5, 6, 7);\n        __m256i is_multiple = _mm256_and_si256(indices, two);\n        __m256i mask4 = _mm256_cmpeq_epi32(is_multiple, _mm256_setzero_si256());\n\n        __m256i final_mask = _mm256_and_si256(mask3, mask4);\n\n        __m256 result = _mm256_blendv_ps(_mm256_round_ps(_mm256_mul_ps(a, b, _MM_FROUND_CEIL), _MM_FROUND_TO_ZERO), _mm256_set1_ps(-1), _mm256_castsi256_ps(final_mask));\n\n        _mm256_storeu_ps(&dst[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_21_AVX", "completion": "```\nvoid vector_mul_round_up_simd(const float* src1, const float* src2, float* dst, size_t length){\n    __m256i mask = _mm256_set1_epi32(0x80000000); // Mask for checking sign bit\n    __m256i fifty = _mm256_set1_epi32(50); // Vector of 50\n    __m256i two = _mm256_set1_epi32(2); // Vector of 2\n    __m256i one = _mm256_set1_epi32(1); // Vector of 1\n    __m256i minus_one = _mm256_set1_epi32(-1); // Vector of -1\n\n    for (size_t i = 0; i < length; i += 8) {\n        __m256 a = _mm256_loadu_ps(&src1[i]);\n        __m256 b = _mm256_loadu_ps(&src2[i]);\n\n        __m256 diff = _mm256_sub_ps(a, b);\n        __m256 abs_diff = _mm256_andnot_ps((__m256)mask, diff); // Absolute difference\n\n        __m256i abs_diff_int = _mm256_cvtps_epi32(abs_diff);\n        __m256i abs_diff_less_than_fifty = _mm256_cmpgt_epi32(fifty, abs_diff_int); // Check if abs_diff < 50\n        __m256i index_mod_two = _mm256_and_si256(_mm256_set1_epi32(1), _mm256_srai_epi32(_mm256_setr_epi32(i, i+1, i+2, i+3, i+4, i+5, i+6, i+7), 1)); // Check if index is multiple of 2\n\n        __m256i condition_met = _mm256_and_si256(abs_diff_less_than_fifty, index_mod_two);\n\n        __m256 result = _mm256_blendv_ps(_mm256_round_ps(_mm256_mul_ps(a, b, _MM_FROUND_CEIL), _MM_FROUND_TO_ZERO), _mm256_set1_ps(-1), _mm256_cvtepi32_ps(condition_met));\n\n        _mm256_storeu_ps(&dst[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_21_AVX", "completion": "```\nvoid vector_mul_round_up_simd(const float* src1, const float* src2, float* dst, size_t length){\n    __m256i mask = _mm256_set1_epi32(0x80000000);\n    __m256i mask50 = _mm256_set1_epi32(50);\n    __m256i mask2 = _mm256_setr_epi32(0, -1, 0, -1, 0, -1, 0, -1);\n    \n    for (size_t i = 0; i < length; i += 8) {\n        __m256 a = _mm256_loadu_ps(&src1[i]);\n        __m256 b = _mm256_loadu_ps(&src2[i]);\n        \n        __m256 diff = _mm256_sub_ps(a, b);\n        __m256 abs_diff = _mm256_andnot_ps(mask, diff);\n        __m256 abs_diff_cmp = _mm256_cmp_ps(abs_diff, _mm256_castsi256_ps(mask50), _CMP_LE_OQ);\n        __m256i index_mask = _mm256_and_si256(_mm256_set1_epi32(i), mask2);\n        __m256i final_mask = _mm256_and_si256(_mm256_castps_si256(abs_diff_cmp), index_mask);\n        \n        __m256 result = _mm256_blendv_ps(_mm256_set1_ps(-1), _mm256_round_ps(_mm256_mul_ps(a, b), _MM_FROUND_CEIL), _mm256_castsi256_ps(final_mask));\n        \n        _mm256_storeu_ps(&dst[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_21_AVX", "completion": "```cpp\nvoid vector_mul_round_up_simd(const float* src1, const float* src2, float* dst, size_t length){\n    const __m256i mask = _mm256_set1_epi32(0x80000000);\n    const __m256i threshold = _mm256_set1_epi32(50);\n    const __m256i two = _mm256_set1_epi32(2);\n    const __m256i neg_one = _mm256_set1_epi32(-1);\n\n    for (size_t i = 0; i < length; i += 8) {\n        __m256 a = _mm256_loadu_ps(&src1[i]);\n        __m256 b = _mm256_loadu_ps(&src2[i]);\n\n        __m256 diff = _mm256_sub_ps(a, b);\n        __m256 abs_diff = _mm256_andnot_ps(mask, diff);\n        __m256i abs_diff_int = _mm256_cvtps_epi32(abs_diff);\n\n        __m256i mask1 = _mm256_cmpgt_epi32(threshold, abs_diff_int);\n        __m256i mask2 = _mm256_and_si256(_mm256_cmpeq_epi32(_mm256_and_si256(_mm256_cvtps_epi32(a), two), _mm256_setzero_si256()), mask1);\n\n        __m256 result = _mm256_blendv_ps(_mm256_set1_ps(-1.0f), _mm256_ceil_ps(_mm256_mul_ps(a, b)), _mm256_castsi256_ps(mask2));\n\n        _mm256_storeu_ps(&dst[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_21_AVX", "completion": "```\nvoid vector_mul_round_up_simd(const float* src1, const float* src2, float* dst, size_t length){\n    const __m256i mask = _mm256_set1_epi32(0x80000000);\n    const __m256i threshold = _mm256_set1_epi32(50);\n    const __m256i two = _mm256_set1_epi32(2);\n    const __m256i minus_one = _mm256_set1_epi32(-1);\n\n    for (size_t i = 0; i < length; i += 8) {\n        __m256 a = _mm256_loadu_ps(&src1[i]);\n        __m256 b = _mm256_loadu_ps(&src2[i]);\n\n        __m256 diff = _mm256_sub_ps(a, b);\n        __m256 abs_diff = _mm256_andnot_ps(mask, diff);\n        __m256i abs_diff_int = _mm256_cvtps_epi32(abs_diff);\n\n        __m256i mask1 = _mm256_cmpgt_epi32(abs_diff_int, threshold);\n        __m256i mask2 = _mm256_cmpeq_epi32(_mm256_and_si256(_mm256_cvtps_epi32(a), two), _mm256_setzero_si256());\n        __m256i final_mask = _mm256_and_si256(mask1, mask2);\n\n        __m256 result = _mm256_blendv_ps(_mm256_round_ps(_mm256_mul_ps(a, b, _MM_FROUND_CEIL), _MM_FROUND_TO_ZERO), _mm256_set1_ps(-1), _mm256_castsi256_ps(final_mask));\n\n        _mm256_storeu_ps(&dst[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_22_AVX", "completion": "```cpp\nvoid matrix_scalar_mul_simd(const double* mat, double scalar, double* dst, size_t m, size_t n) {\n    __m256d scalar_vec = _mm256_set1_pd(scalar);\n    for (size_t i = 0; i < m*n; i += 4) {\n        __m256d mat_vec = _mm256_loadu_pd(&mat[i]);\n        __m256d result = _mm256_mul_pd(mat_vec, scalar_vec);\n        _mm256_storeu_pd(&dst[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_22_AVX", "completion": "```cpp\nvoid matrix_scalar_mul_simd(const double* mat, double scalar, double* dst, size_t m, size_t n) {\n    __m256d scalar_vec = _mm256_set1_pd(scalar);\n    for (size_t i = 0; i < m*n; i += 4) {\n        __m256d mat_vec = _mm256_loadu_pd(&mat[i]);\n        __m256d result = _mm256_mul_pd(mat_vec, scalar_vec);\n        _mm256_storeu_pd(&dst[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_22_AVX", "completion": "```cpp\nvoid matrix_scalar_mul_simd(const double* mat, double scalar, double* dst, size_t m, size_t n) {\n    __m256d scalar_vec = _mm256_set1_pd(scalar);\n    for (size_t i = 0; i < m * n; i += 4) {\n        __m256d mat_vec = _mm256_loadu_pd(&mat[i]);\n        __m256d result = _mm256_mul_pd(mat_vec, scalar_vec);\n        _mm256_storeu_pd(&dst[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_22_AVX", "completion": "```cpp\nvoid matrix_scalar_mul_simd(const double* mat, double scalar, double* dst, size_t m, size_t n) {\n    __m256d scalar_vec = _mm256_set1_pd(scalar);\n    size_t size = m * n;\n    size_t i = 0;\n    \n    for (; i + 4 <= size; i += 4) {\n        __m256d mat_vec = _mm256_loadu_pd(&mat[i]);\n        __m256d result = _mm256_mul_pd(mat_vec, scalar_vec);\n        _mm256_storeu_pd(&dst[i], result);\n    }\n    \n    for (; i < size; i++) {\n        dst[i] = mat[i] * scalar;\n    }\n}\n```  "}
{"task_id": "SimdBench_22_AVX", "completion": "```cpp\nvoid matrix_scalar_mul_simd(const double* mat, double scalar, double* dst, size_t m, size_t n) {\n    __m256d scalar_vec = _mm256_set1_pd(scalar);\n    for (size_t i = 0; i < m*n; i += 4) {\n        __m256d mat_vec = _mm256_loadu_pd(&mat[i]);\n        __m256d result = _mm256_mul_pd(mat_vec, scalar_vec);\n        _mm256_storeu_pd(&dst[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_23_AVX", "completion": "```cpp\nvoid matrix_normalize_rows_simd(float* mat, size_t m, size_t n) {\n    for (size_t i = 0; i < m; i++) {\n        float sum_squares = 0.0f;\n        __m256 sum_squares_avx = _mm256_setzero_ps();\n\n        // Calculate sum of squares using AVX\n        for (size_t j = 0; j < n; j += 8) {\n            __m256 values = _mm256_loadu_ps(&mat[i * n + j]);\n            sum_squares_avx = _mm256_fmadd_ps(values, values, sum_squares_avx);\n        }\n\n        // Horizontal sum of AVX register\n        __m128 sum_squares_high = _mm256_extractf128_ps(sum_squares_avx, 1);\n        __m128 sum_squares_low = _mm256_castps256_ps128(sum_squares_avx);\n        __m128 sum_squares_combined = _mm_add_ps(sum_squares_low, sum_squares_high);\n        sum_squares = _mm_cvtss_f32(_mm_hadd_ps(sum_squares_combined, sum_squares_combined));\n\n        // Calculate reciprocal of square root of sum of squares\n        float norm_factor = 1.0f / sqrtf(sum_squares);\n        __m256 norm_factor_avx = _mm256_set1_ps(norm_factor);\n\n        // Normalize row using AVX\n        for (size_t j = 0; j < n; j += 8) {\n            __m256 values = _mm256_loadu_ps(&mat[i * n + j]);\n            __m256 normalized_values = _mm256_mul_ps(values, norm_factor_avx);\n            _mm256_storeu_ps(&mat[i * n + j], normalized_values);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_23_AVX", "completion": "```cpp\nvoid matrix_normalize_rows_simd(float* mat, size_t m, size_t n) {\n    for (size_t i = 0; i < m; i++) {\n        float sum_squares = 0.0f;\n        __m256 sum_squares_vec = _mm256_setzero_ps();\n\n        // Calculate sum of squares using AVX\n        for (size_t j = 0; j < n; j += 8) {\n            __m256 values = _mm256_loadu_ps(&mat[i * n + j]);\n            sum_squares_vec = _mm256_fmadd_ps(values, values, sum_squares_vec);\n        }\n        sum_squares_vec = _mm256_hadd_ps(sum_squares_vec, sum_squares_vec);\n        sum_squares_vec = _mm256_hadd_ps(sum_squares_vec, sum_squares_vec);\n        sum_squares += _mm_cvtss_f32(_mm256_castps256_ps128(sum_squares_vec));\n        \n        sum_squares = sqrtf(sum_squares);\n\n        // Normalize row using AVX\n        for (size_t j = 0; j < n; j += 8) {\n            __m256 values = _mm256_loadu_ps(&mat[i * n + j]);\n            values = _mm256_div_ps(values, _mm256_set1_ps(sum_squares));\n            _mm256_storeu_ps(&mat[i * n + j], values);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_23_AVX", "completion": "```cpp\nvoid matrix_normalize_rows_simd(float* mat, size_t m, size_t n) {\n    for (size_t i = 0; i < m; ++i) {\n        float sum_squares = 0.0f;\n        __m256 sum_squares_vec = _mm256_setzero_ps();\n\n        // Calculate sum of squares using AVX\n        for (size_t j = 0; j < n; j += 8) {\n            __m256 values = _mm256_loadu_ps(&mat[i * n + j]);\n            sum_squares_vec = _mm256_fmadd_ps(values, values, sum_squares_vec);\n        }\n\n        // Horizontal sum of the 8 floats in the AVX register\n        __m128 sum_squares_low = _mm256_castps256_ps128(sum_squares_vec);\n        __m128 sum_squares_high = _mm256_extractf128_ps(sum_squares_vec, 1);\n        __m128 sum_squares = _mm_add_ps(sum_squares_low, sum_squares_high);\n        sum_squares = _mm_hadd_ps(sum_squares, sum_squares);\n        sum_squares = _mm_hadd_ps(sum_squares, sum_squares);\n\n        // Calculate reciprocal of the square root of sum of squares\n        __m256 norm_factor = _mm256_set1_ps(1.0f / sqrt(_mm_cvtss_f32(sum_squares)));\n\n        // Normalize row using AVX\n        for (size_t j = 0; j < n; j += 8) {\n            __m256 values = _mm256_loadu_ps(&mat[i * n + j]);\n            values = _mm256_mul_ps(values, norm_factor);\n            _mm256_storeu_ps(&mat[i * n + j], values);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_23_AVX", "completion": "```cpp\nvoid matrix_normalize_rows_simd(float* mat, size_t m, size_t n) {\n    for (size_t i = 0; i < m; ++i) {\n        float sum_squares = 0.0f;\n        __m256 sum_squares_avx = _mm256_setzero_ps();\n\n        // Calculate sum of squares using AVX\n        for (size_t j = 0; j < n; j += 8) {\n            __m256 values = _mm256_loadu_ps(&mat[i * n + j]);\n            sum_squares_avx = _mm256_fmadd_ps(values, values, sum_squares_avx);\n        }\n\n        // Horizontal sum of AVX register\n        __m128 sum_squares_low = _mm256_castps256_ps128(sum_squares_avx);\n        __m128 sum_squares_high = _mm256_extractf128_ps(sum_squares_avx, 1);\n        __m128 sum_squares_combined = _mm_add_ps(sum_squares_low, sum_squares_high);\n        sum_squares_combined = _mm_hadd_ps(sum_squares_combined, sum_squares_combined);\n        sum_squares_combined = _mm_hadd_ps(sum_squares_combined, sum_squares_combined);\n\n        _mm_store_ss(&sum_squares, sum_squares_combined);\n        sum_squares = sqrtf(sum_squares);\n\n        // Normalize row using AVX\n        for (size_t j = 0; j < n; j += 8) {\n            __m256 values = _mm256_loadu_ps(&mat[i * n + j]);\n            values = _mm256_div_ps(values, _mm256_set1_ps(sum_squares));\n            _mm256_storeu_ps(&mat[i * n + j], values);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_23_AVX", "completion": "```cpp\nvoid matrix_normalize_rows_simd(float* mat, size_t m, size_t n) {\n    for (size_t i = 0; i < m; ++i) {\n        __m256 sum_sq = _mm256_setzero_ps();\n        for (size_t j = 0; j < n; j += 8) {\n            __m256 values = _mm256_loadu_ps(&mat[i * n + j]);\n            sum_sq = _mm256_fmadd_ps(values, values, sum_sq);\n        }\n        __m256 norm = _mm256_sqrt_ps(sum_sq);\n        for (size_t j = 0; j < n; j += 8) {\n            __m256 values = _mm256_loadu_ps(&mat[i * n + j]);\n            _mm256_storeu_ps(&mat[i * n + j], _mm256_div_ps(values, norm));\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_24_AVX", "completion": "```cpp\nvoid matrix_mul_round_int_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n, size_t p) {\n    for (size_t i = 0; i < m; ++i) {\n        for (size_t j = 0; j < p; ++j) {\n            __m256d sum = _mm256_setzero_pd();\n            for (size_t k = 0; k < n; k += 4) {\n                __m256d a = _mm256_loadu_pd(&mat1[i * n + k]);\n                __m256d b = _mm256_loadu_pd(&mat2[k * p + j]);\n                sum = _mm256_fmadd_pd(a, b, sum);\n            }\n            __m256d rounded = _mm256_round_pd(sum, _MM_FROUND_TO_NEAREST_INT);\n            _mm256_storeu_pd(&dst[i * p + j], rounded);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_24_AVX", "completion": "```c\nvoid matrix_mul_round_int_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n, size_t p) {\n    for (size_t i = 0; i < m; i++) {\n        for (size_t j = 0; j < p; j++) {\n            __m256d sum = _mm256_setzero_pd();\n            for (size_t k = 0; k < n; k += 4) {\n                __m256d a = _mm256_loadu_pd(&mat1[i * n + k]);\n                __m256d b = _mm256_loadu_pd(&mat2[k * p + j]);\n                sum = _mm256_fmadd_pd(a, b, sum);\n            }\n            __m256d rounded = _mm256_round_pd(sum, _MM_FROUND_TO_NEAREST_INT);\n            _mm256_storeu_pd(&dst[i * p + j], rounded);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_24_AVX", "completion": "```cpp\nvoid matrix_mul_round_int_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n, size_t p) {\n    for (size_t i = 0; i < m; ++i) {\n        for (size_t j = 0; j < p; ++j) {\n            __m256d sum = _mm256_setzero_pd();\n            for (size_t k = 0; k < n; k += 4) {\n                __m256d a = _mm256_loadu_pd(&mat1[i * n + k]);\n                __m256d b = _mm256_loadu_pd(&mat2[k * p + j]);\n                sum = _mm256_fmadd_pd(a, b, sum);\n            }\n            __m256d rounded = _mm256_round_pd(sum, _MM_FROUND_TO_NEAREST_INT);\n            _mm256_storeu_pd(&dst[i * p + j], rounded);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_24_AVX", "completion": "```c\nvoid matrix_mul_round_int_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n, size_t p) {\n    for (size_t i = 0; i < m; i++) {\n        for (size_t j = 0; j < p; j++) {\n            __m256d sum = _mm256_setzero_pd();\n            for (size_t k = 0; k < n; k += 4) {\n                __m256d a = _mm256_loadu_pd(&mat1[i * n + k]);\n                __m256d b = _mm256_loadu_pd(&mat2[k * p + j]);\n                sum = _mm256_fmadd_pd(a, b, sum);\n            }\n            __m256d rounded = _mm256_round_pd(sum, _MM_FROUND_TO_NEAREST_INT);\n            _mm256_storeu_pd(&dst[i * p + j], rounded);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_24_AVX", "completion": "```cpp\nvoid matrix_mul_round_int_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n, size_t p) {\n    for (size_t i = 0; i < m; ++i) {\n        for (size_t j = 0; j < p; ++j) {\n            __m256d sum = _mm256_setzero_pd();\n            for (size_t k = 0; k < n; k += 4) {\n                __m256d a = _mm256_loadu_pd(&mat1[i * n + k]);\n                __m256d b = _mm256_loadu_pd(&mat2[k * p + j]);\n                sum = _mm256_fmadd_pd(a, b, sum);\n            }\n            __m256d rounded = _mm256_round_pd(sum, _MM_FROUND_TO_NEAREST_INT);\n            _mm256_storeu_pd(&dst[i * p + j], rounded);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_25_AVX", "completion": "```cpp\nvoid matrix_transpose_round_quarter_simd(const float* src, float* dst, size_t rows, size_t cols) {\n    for (size_t i = 0; i < rows; i += 8) {\n        for (size_t j = 0; j < cols; j += 8) {\n            __m256 src_row[8], transposed[8];\n\n            for (size_t k = 0; k < 8; ++k) {\n                src_row[k] = _mm256_loadu_ps(&src[(i + k) * cols + j]);\n            }\n\n            for (size_t k = 0; k < 8; ++k) {\n                __m256 tmp1 = _mm256_unpacklo_ps(src_row[k], src_row[k]);\n                __m256 tmp2 = _mm256_unpackhi_ps(src_row[k], src_row[k]);\n                transposed[k] = _mm256_shuffle_ps(tmp1, tmp2, 0b11000000);\n            }\n\n            for (size_t k = 0; k < 8; ++k) {\n                _mm256_storeu_ps(&dst[(j + k) * rows + i], transposed[k]);\n            }\n        }\n    }\n\n    for (size_t i = 0; i < rows; ++i) {\n        for (size_t j = 0; j < cols; ++j) {\n            dst[i * cols + j] = roundf(dst[i * cols + j] * 4.0f) / 4.0f;\n        }\n    }\n}\n```  "}
{"task_id": "SimdBench_25_AVX", "completion": "```cpp\nvoid matrix_transpose_round_quarter_simd(const float* src, float* dst, size_t rows, size_t cols) {\n    for (size_t i = 0; i < rows; i += 8) {\n        for (size_t j = 0; j < cols; j += 8) {\n            for (size_t ii = i; ii < i + 8 && ii < rows; ii++) {\n                for (size_t jj = j; jj < j + 8 && jj < cols; jj++) {\n                    __m256 src_vec = _mm256_loadu_ps(&src[ii * cols + jj]);\n                    __m256 rounded_vec = _mm256_round_ps(src_vec, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n                    _mm256_storeu_ps(&dst[jj * rows + ii], rounded_vec);\n                }\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_25_AVX", "completion": "```c\nvoid matrix_transpose_round_quarter_simd(const float* src, float* dst, size_t rows, size_t cols) {\n    for (size_t i = 0; i < rows; i += 8) {\n        for (size_t j = 0; j < cols; j += 8) {\n            for (size_t ii = i; ii < i + 8 && ii < rows; ii++) {\n                for (size_t jj = j; jj < j + 8 && jj < cols; jj++) {\n                    __m256 src_vec = _mm256_loadu_ps(&src[ii * cols + jj]);\n                    __m256 rounded_vec = _mm256_round_ps(src_vec, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n                    __m256 dst_vec = _mm256_permute_ps(rounded_vec, _MM_SHUFFLE(2, 3, 0, 1));\n                    _mm256_storeu_ps(&dst[jj * rows + ii], dst_vec);\n                }\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_25_AVX", "completion": "```cpp\nvoid matrix_transpose_round_quarter_simd(const float* src, float* dst, size_t rows, size_t cols) {\n    for (size_t i = 0; i < rows; i += 8) {\n        for (size_t j = 0; j < cols; j += 8) {\n            for (size_t ii = i; ii < i + 8 && ii < rows; ++ii) {\n                for (size_t jj = j; jj < j + 8 && jj < cols; ++jj) {\n                    __m256 src_vec = _mm256_loadu_ps(&src[ii * cols + jj]);\n                    __m256 rounded_vec = _mm256_round_ps(src_vec, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n                    _mm256_storeu_ps(&dst[jj * rows + ii], rounded_vec);\n                }\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_25_AVX", "completion": "```c\nvoid matrix_transpose_round_quarter_simd(const float* src, float* dst, size_t rows, size_t cols) {\n    for (size_t i = 0; i < rows; i += 8) {\n        for (size_t j = 0; j < cols; j += 8) {\n            for (size_t ii = i; ii < i + 8 && ii < rows; ii++) {\n                for (size_t jj = j; jj < j + 8 && jj < cols; jj++) {\n                    __m256 src_vec = _mm256_loadu_ps(&src[ii * cols + jj]);\n                    __m256 rounded_vec = _mm256_round_ps(src_vec, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n                    _mm256_storeu_ps(&dst[jj * rows + ii], rounded_vec);\n                }\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_26_AVX", "completion": "```c\nvoid tensor3d_sub_round_zero_simd(const float* tensor1, const float* tensor2, float* dst, size_t dim1, size_t dim2, size_t dim3) {\n    const size_t total_size = dim1 * dim2 * dim3;\n    const size_t avx_size = total_size / 8 * 8;\n\n    __m256i mask = _mm256_set1_epi32(0x7FFFFFFF);\n    for (size_t i = 0; i < avx_size; i += 8) {\n        __m256 vec1 = _mm256_loadu_ps(&tensor1[i]);\n        __m256 vec2 = _mm256_loadu_ps(&tensor2[i]);\n        __m256 result = _mm256_sub_ps(vec1, vec2);\n        __m256i int_result = _mm256_cvttps_epi32(result);\n        __m256i rounded_result = _mm256_and_si256(int_result, mask);\n        _mm256_storeu_ps(&dst[i], _mm256_cvtepi32_ps(rounded_result));\n    }\n\n    for (size_t i = avx_size; i < total_size; ++i) {\n        dst[i] = (float)((int)tensor1[i] - (int)tensor2[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_26_AVX", "completion": "```cpp\nvoid tensor3d_sub_round_zero_simd(const float* tensor1, const float* tensor2, float* dst, size_t dim1, size_t dim2, size_t dim3) {\n    for (size_t i = 0; i < dim1 * dim2 * dim3; i += 8) {\n        __m256 t1 = _mm256_loadu_ps(&tensor1[i]);\n        __m256 t2 = _mm256_loadu_ps(&tensor2[i]);\n        __m256 result = _mm256_sub_ps(t1, t2);\n        __m256 zero = _mm256_setzero_ps();\n        __m256 mask = _mm256_cmp_ps(result, zero, _CMP_LT_OS);\n        __m256 rounded_result = _mm256_round_ps(result, _MM_FROUND_TO_ZERO);\n        __m256 final_result = _mm256_blendv_ps(rounded_result, result, mask);\n        _mm256_storeu_ps(&dst[i], final_result);\n    }\n}\n```"}
{"task_id": "SimdBench_26_AVX", "completion": "```cpp\nvoid tensor3d_sub_round_zero_simd(const float* tensor1, const float* tensor2, float* dst, size_t dim1, size_t dim2, size_t dim3) {\n    const size_t elements = dim1 * dim2 * dim3;\n    const size_t avx_size = 8;\n    \n    for (size_t i = 0; i < elements; i += avx_size) {\n        __m256 vec1 = _mm256_loadu_ps(&tensor1[i]);\n        __m256 vec2 = _mm256_loadu_ps(&tensor2[i]);\n        \n        __m256 result = _mm256_sub_ps(vec1, vec2);\n        __m256 zero = _mm256_setzero_ps();\n        \n        __m256 mask = _mm256_cmp_ps(result, zero, _CMP_LT_OS);\n        __m256 rounded_result = _mm256_cvtepi32_ps(_mm256_cvttps_epi32(result));\n        __m256 final_result = _mm256_blendv_ps(rounded_result, zero, mask);\n        \n        _mm256_storeu_ps(&dst[i], final_result);\n    }\n}\n```"}
{"task_id": "SimdBench_26_AVX", "completion": "```cpp\nvoid tensor3d_sub_round_zero_simd(const float* tensor1, const float* tensor2, float* dst, size_t dim1, size_t dim2, size_t dim3) {\n    for (size_t i = 0; i < dim1 * dim2 * dim3; i += 8) {\n        __m256 t1 = _mm256_loadu_ps(&tensor1[i]);\n        __m256 t2 = _mm256_loadu_ps(&tensor2[i]);\n        __m256 result = _mm256_sub_ps(t1, t2);\n        __m256 zero = _mm256_setzero_ps();\n        __m256 mask = _mm256_cmp_ps(result, zero, _CMP_LT_OS);\n        __m256 rounded_result = _mm256_cvtepi32_ps(_mm256_cvttps_epi32(result));\n        __m256 final_result = _mm256_blendv_ps(_mm256_floor_ps(result), _mm256_ceil_ps(result), mask);\n        _mm256_storeu_ps(&dst[i], final_result);\n    }\n}\n```"}
{"task_id": "SimdBench_26_AVX", "completion": "```c\nvoid tensor3d_sub_round_zero_simd(const float* tensor1, const float* tensor2, float* dst, size_t dim1, size_t dim2, size_t dim3) {\n    for (size_t i = 0; i < dim1 * dim2 * dim3; i += 8) {\n        __m256 t1 = _mm256_loadu_ps(&tensor1[i]);\n        __m256 t2 = _mm256_loadu_ps(&tensor2[i]);\n        __m256 result = _mm256_sub_ps(t1, t2);\n        __m256 zero = _mm256_setzero_ps();\n        __m256 mask = _mm256_cmp_ps(result, zero, _CMP_LT_OS);\n        __m256 rounded_result = _mm256_cvtepi32_ps(_mm256_cvttps_epi32(result));\n        __m256 final_result = _mm256_blendv_ps(_mm256_floor_ps(result), rounded_result, mask);\n        _mm256_storeu_ps(&dst[i], final_result);\n    }\n}\n```"}
{"task_id": "SimdBench_27_AVX", "completion": "```cpp\nvoid matrix_hadamard_product_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n) {\n    for (size_t i = 0; i < m*n; i += 4) {\n        __m256d vec1 = _mm256_loadu_pd(&mat1[i]);\n        __m256d vec2 = _mm256_loadu_pd(&mat2[i]);\n        __m256d result = _mm256_mul_pd(vec1, vec2);\n        _mm256_storeu_pd(&dst[i], result);\n    }\n}\n```  "}
{"task_id": "SimdBench_27_AVX", "completion": "```cpp\nvoid matrix_hadamard_product_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n) {\n    for (size_t i = 0; i < m * n; i += 4) {\n        __m256d vec1 = _mm256_loadu_pd(&mat1[i]);\n        __m256d vec2 = _mm256_loadu_pd(&mat2[i]);\n        __m256d result = _mm256_mul_pd(vec1, vec2);\n        _mm256_storeu_pd(&dst[i], result);\n    }\n}\n```  "}
{"task_id": "SimdBench_27_AVX", "completion": "```c\nvoid matrix_hadamard_product_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n) {\n    for (size_t i = 0; i < m*n; i += 4) {\n        __m256d vec1 = _mm256_loadu_pd(&mat1[i]);\n        __m256d vec2 = _mm256_loadu_pd(&mat2[i]);\n        __m256d result = _mm256_mul_pd(vec1, vec2);\n        _mm256_storeu_pd(&dst[i], result);\n    }\n}\n```  "}
{"task_id": "SimdBench_27_AVX", "completion": "```cpp\nvoid matrix_hadamard_product_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n) {\n    for (size_t i = 0; i < m*n; i += 4) {\n        __m256d vec1 = _mm256_loadu_pd(&mat1[i]);\n        __m256d vec2 = _mm256_loadu_pd(&mat2[i]);\n        __m256d result = _mm256_mul_pd(vec1, vec2);\n        _mm256_storeu_pd(&dst[i], result);\n    }\n}\n```  "}
{"task_id": "SimdBench_27_AVX", "completion": "```cpp\nvoid matrix_hadamard_product_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n) {\n    for (size_t i = 0; i < m*n; i += 4) {\n        __m256d vec1 = _mm256_loadu_pd(&mat1[i]);\n        __m256d vec2 = _mm256_loadu_pd(&mat2[i]);\n        __m256d result = _mm256_mul_pd(vec1, vec2);\n        _mm256_storeu_pd(&dst[i], result);\n    }\n}\n```  "}
{"task_id": "SimdBench_28_AVX", "completion": "```cpp\nvoid matrix_vector_mul_simd(const float* mat, const float* vec, float* dst, size_t m, size_t n) {\n    for (size_t i = 0; i < m; ++i) {\n        __m256 sum = _mm256_setzero_ps();\n        for (size_t j = 0; j < n; j += 8) {\n            __m256 mat_row = _mm256_loadu_ps(&mat[i * n + j]);\n            __m256 vec_data = _mm256_loadu_ps(&vec[j]);\n            sum = _mm256_fmadd_ps(mat_row, vec_data, sum);\n        }\n        _mm256_storeu_ps(&dst[i], sum);\n    }\n}\n```"}
{"task_id": "SimdBench_28_AVX", "completion": "```cpp\nvoid matrix_vector_mul_simd(const float* mat, const float* vec, float* dst, size_t m, size_t n) {\n    for (size_t i = 0; i < m; ++i) {\n        __m256 sum = _mm256_setzero_ps();\n        for (size_t j = 0; j < n; j += 8) {\n            __m256 mat_chunk = _mm256_loadu_ps(&mat[i * n + j]);\n            __m256 vec_chunk = _mm256_loadu_ps(&vec[j]);\n            sum = _mm256_fmadd_ps(mat_chunk, vec_chunk, sum);\n        }\n        float temp[8];\n        _mm256_storeu_ps(temp, sum);\n        dst[i] = temp[0] + temp[1] + temp[2] + temp[3] + temp[4] + temp[5] + temp[6] + temp[7];\n    }\n}\n```"}
{"task_id": "SimdBench_28_AVX", "completion": "```cpp\nvoid matrix_vector_mul_simd(const float* mat, const float* vec, float* dst, size_t m, size_t n) {\n    for (size_t i = 0; i < m; ++i) {\n        __m256 sum = _mm256_setzero_ps();\n        for (size_t j = 0; j < n; j += 8) {\n            __m256 mat_chunk = _mm256_loadu_ps(&mat[i * n + j]);\n            __m256 vec_chunk = _mm256_loadu_ps(&vec[j]);\n            sum = _mm256_fmadd_ps(mat_chunk, vec_chunk, sum);\n        }\n        _mm256_storeu_ps(&dst[i], sum);\n    }\n}\n```"}
{"task_id": "SimdBench_28_AVX", "completion": "```cpp\nvoid matrix_vector_mul_simd(const float* mat, const float* vec, float* dst, size_t m, size_t n) {\n    for (size_t i = 0; i < m; ++i) {\n        __m256 sum = _mm256_setzero_ps();\n        for (size_t j = 0; j < n; j += 8) {\n            __m256 mat_row = _mm256_loadu_ps(&mat[i * n + j]);\n            __m256 vec_data = _mm256_loadu_ps(&vec[j]);\n            sum = _mm256_fmadd_ps(mat_row, vec_data, sum);\n        }\n        _mm256_storeu_ps(&dst[i], sum);\n    }\n}\n```"}
{"task_id": "SimdBench_28_AVX", "completion": "```cpp\nvoid matrix_vector_mul_simd(const float* mat, const float* vec, float* dst, size_t m, size_t n) {\n    for (size_t i = 0; i < m; ++i) {\n        __m256 sum = _mm256_setzero_ps();\n        for (size_t j = 0; j < n; j += 8) {\n            __m256 mat_chunk = _mm256_loadu_ps(&mat[i * n + j]);\n            __m256 vec_chunk = _mm256_loadu_ps(&vec[j]);\n            sum = _mm256_fmadd_ps(mat_chunk, vec_chunk, sum);\n        }\n        _mm256_storeu_ps(&dst[i], sum);\n    }\n}\n```"}
{"task_id": "SimdBench_29_AVX", "completion": "```c\ndouble matrix_average_simd(const double* mat, size_t m, size_t n) {\n    __m256d sum = _mm256_setzero_pd();\n    size_t total_elements = m * n;\n\n    for (size_t i = 0; i < total_elements; i += 4) {\n        __m256d vec = _mm256_loadu_pd(&mat[i]);\n        sum = _mm256_add_pd(sum, vec);\n    }\n\n    double result[4];\n    _mm256_storeu_pd(result, sum);\n\n    double avg = (result[0] + result[1] + result[2] + result[3]) / total_elements;\n    return avg;\n}\n```"}
{"task_id": "SimdBench_29_AVX", "completion": "```cpp\ndouble matrix_average_simd(const double* mat, size_t m, size_t n) {\n    __m256d sum = _mm256_setzero_pd();\n    size_t total_elements = m * n;\n\n    for (size_t i = 0; i < total_elements; i += 4) {\n        __m256d values = _mm256_loadu_pd(&mat[i]);\n        sum = _mm256_add_pd(sum, values);\n    }\n\n    double result[4];\n    _mm256_storeu_pd(result, sum);\n\n    double average = (result[0] + result[1] + result[2] + result[3]) / total_elements;\n    return average;\n}\n```  "}
{"task_id": "SimdBench_29_AVX", "completion": "```c\ndouble matrix_average_simd(const double* mat, size_t m, size_t n) {\n    __m256d sum = _mm256_setzero_pd();\n    size_t total_elements = m * n;\n\n    for (size_t i = 0; i < total_elements; i += 4) {\n        __m256d values = _mm256_loadu_pd(&mat[i]);\n        sum = _mm256_add_pd(sum, values);\n    }\n\n    double result[4] = {0.0, 0.0, 0.0, 0.0};\n    _mm256_storeu_pd(result, sum);\n\n    double average = (result[0] + result[1] + result[2] + result[3]) / total_elements;\n    return average;\n}\n```"}
{"task_id": "SimdBench_29_AVX", "completion": "```c\ndouble matrix_average_simd(const double* mat, size_t m, size_t n) {\n    __m256d sum = _mm256_setzero_pd();\n    size_t total_elements = m * n;\n    size_t remaining_elements = total_elements % 4;\n    total_elements -= remaining_elements;\n\n    for (size_t i = 0; i < total_elements; i += 4) {\n        __m256d row1 = _mm256_loadu_pd(&mat[i]);\n        __m256d row2 = _mm256_loadu_pd(&mat[i + 4]);\n        __m256d row3 = _mm256_loadu_pd(&mat[i + 8]);\n        __m256d row4 = _mm256_loadu_pd(&mat[i + 12]);\n\n        sum = _mm256_add_pd(sum, row1);\n        sum = _mm256_add_pd(sum, row2);\n        sum = _mm256_add_pd(sum, row3);\n        sum = _mm256_add_pd(sum, row4);\n    }\n\n    double result[4];\n    _mm256_storeu_pd(result, sum);\n    double avg = (result[0] + result[1] + result[2] + result[3]) / total_elements;\n\n    for (size_t i = total_elements; i < total_elements + remaining_elements; i++) {\n        avg += mat[i];\n    }\n\n    return avg;\n}\n```"}
{"task_id": "SimdBench_29_AVX", "completion": "```c\ndouble matrix_average_simd(const double* mat, size_t m, size_t n) {\n    __m256d sum = _mm256_setzero_pd();\n    size_t total_elements = m * n;\n\n    for (size_t i = 0; i < total_elements; i += 4) {\n        __m256d vec = _mm256_loadu_pd(&mat[i]);\n        sum = _mm256_add_pd(sum, vec);\n    }\n\n    double result[4];\n    _mm256_storeu_pd(result, sum);\n\n    double avg = (result[0] + result[1] + result[2] + result[3]) / total_elements;\n    return avg;\n}\n```"}
{"task_id": "SimdBench_30_AVX", "completion": "```cpp\nbool matrix_rows_sorted_verify_simd(const int* matrix, const bool* directions, size_t rows, size_t cols) {\n    for (size_t i = 0; i < rows; ++i) {\n        const int* row = matrix + i * cols;\n        __m256i vec = _mm256_loadu_si256((__m256i*)row);\n        __m256i sorted = _mm256_setzero_si256();\n        for (size_t j = 0; j < cols - 1; j += 8) {\n            __m256i next_vec = _mm256_loadu_si256((__m256i*)(row + j + 1));\n            __m256i cmp = _mm256_cmpgt_epi32(vec, next_vec);\n            __m256i direction = _mm256_set1_epi32(directions[i] ? 0xFFFFFFFF : 0);\n            sorted = _mm256_or_si256(sorted, _mm256_and_si256(cmp, direction));\n            vec = next_vec;\n        }\n        if (!_mm256_testz_si256(sorted, sorted)) {\n            return false;\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_30_AVX", "completion": "```cpp\nbool matrix_rows_sorted_verify_simd(const int* matrix, const bool* directions, size_t rows, size_t cols) {\n    for (size_t i = 0; i < rows; ++i) {\n        __m256i prev = _mm256_set1_epi32(matrix[i * cols]);\n        bool ascending = directions[i];\n        for (size_t j = 1; j < cols; j += 8) {\n            __m256i current = _mm256_loadu_si256((__m256i*)(matrix + i * cols + j));\n            if (ascending) {\n                __m256i mask = _mm256_cmpgt_epi32(prev, current);\n                if (_mm256_movemask_ps(_mm256_castsi256_ps(mask)) != 0) {\n                    return false;\n                }\n            } else {\n                __m256i mask = _mm256_cmpgt_epi32(current, prev);\n                if (_mm256_movemask_ps(_mm256_castsi256_ps(mask)) != 0) {\n                    return false;\n                }\n            }\n            prev = current;\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_30_AVX", "completion": "```cpp\nbool matrix_rows_sorted_verify_simd(const int* matrix, const bool* directions, size_t rows, size_t cols) {\n    for (size_t i = 0; i < rows; ++i) {\n        __m256i prev = _mm256_set1_epi32(matrix[i * cols]);\n        bool ascending = directions[i];\n        for (size_t j = 1; j < cols / 8; ++j) {\n            __m256i current = _mm256_loadu_si256((__m256i*)(matrix + i * cols + j * 8));\n            if (ascending) {\n                __m256i mask = _mm256_cmpgt_epi32(current, prev);\n                if (_mm256_movemask_ps(_mm256_castsi256_ps(mask)) != 0xFF) {\n                    return false;\n                }\n            } else {\n                __m256i mask = _mm256_cmpgt_epi32(prev, current);\n                if (_mm256_movemask_ps(_mm256_castsi256_ps(mask)) != 0xFF) {\n                    return false;\n                }\n            }\n            prev = current;\n        }\n        for (size_t j = (cols / 8) * 8; j < cols; ++j) {\n            int val = matrix[i * cols + j];\n            if ((ascending && val < _mm256_extract_epi32(prev, 7)) || (!ascending && val > _mm256_extract_epi32(prev, 7))) {\n                return false;\n            }\n            prev = _mm256_insert_epi32(prev, val, 7);\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_30_AVX", "completion": "```cpp\nbool matrix_rows_sorted_verify_simd(const int* matrix, const bool* directions, size_t rows, size_t cols) {\n    for (size_t i = 0; i < rows; ++i) {\n        __m256i prev = _mm256_set1_epi32(matrix[i * cols]);\n        bool ascending = directions[i];\n        for (size_t j = 1; j < cols / 8; ++j) {\n            __m256i current = _mm256_loadu_si256((__m256i*)&matrix[i * cols + j * 8]);\n            if (ascending) {\n                __m256i cmp = _mm256_cmpgt_epi32(prev, current);\n                if (_mm256_movemask_ps(_mm256_castsi256_ps(cmp)) != 0) {\n                    return false;\n                }\n            } else {\n                __m256i cmp = _mm256_cmpgt_epi32(current, prev);\n                if (_mm256_movemask_ps(_mm256_castsi256_ps(cmp)) != 0) {\n                    return false;\n                }\n            }\n            prev = current;\n        }\n        for (size_t j = cols - cols % 8; j < cols; ++j) {\n            int val = matrix[i * cols + j];\n            if ((ascending && val < _mm256_extract_epi32(prev, j % 8)) ||\n                (!ascending && val > _mm256_extract_epi32(prev, j % 8))) {\n                return false;\n            }\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_30_AVX", "completion": "```cpp\nbool matrix_rows_sorted_verify_simd(const int* matrix, const bool* directions, size_t rows, size_t cols) {\n    for (size_t i = 0; i < rows; ++i) {\n        __m256i prev = _mm256_loadu_si256((__m256i*)(matrix + i * cols));\n        bool ascending = directions[i];\n        for (size_t j = 1; j < cols; j += 8) {\n            __m256i current = _mm256_loadu_si256((__m256i*)(matrix + i * cols + j));\n            __m256i mask = _mm256_cmpgt_epi32(prev, current);\n            if (ascending) {\n                if (!_mm256_testz_si256(mask, mask)) {\n                    return false;\n                }\n            } else {\n                if (!_mm256_testz_si256(_mm256_xor_si256(mask, _mm256_set1_epi32(-1)), _mm256_set1_epi32(-1))) {\n                    return false;\n                }\n            }\n            prev = current;\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_31_AVX", "completion": "```c\nvoid nearest_multiple_simd(const int16_t* src, int16_t* dst, uint8_t base, size_t length) {\n    __m256i base_v = _mm256_set1_epi16(base);\n    __m256i zero_v = _mm256_setzero_si256();\n    __m256i one_v = _mm256_set1_epi16(1);\n\n    for (size_t i = 0; i < length; i += 16) {\n        __m256i src_v = _mm256_loadu_si256((__m256i*)(src + i));\n        __m256i div_v = _mm256_div_epi16(src_v, base_v);\n        __m256i floor_v = _mm256_mullo_epi16(div_v, base_v);\n        __m256i ceil_v = _mm256_mullo_epi16(_mm256_add_epi16(div_v, one_v), base_v);\n        __m256i diff_floor_v = _mm256_sub_epi16(src_v, floor_v);\n        __m256i diff_ceil_v = _mm256_sub_epi16(ceil_v, src_v);\n        __m256i mask_v = _mm256_cmpgt_epi16(diff_floor_v, diff_ceil_v);\n        __m256i result_v = _mm256_blendv_epi8(ceil_v, floor_v, mask_v);\n        _mm256_storeu_si256((__m256i*)(dst + i), result_v);\n    }\n}\n```"}
{"task_id": "SimdBench_31_AVX", "completion": "```c\nvoid nearest_multiple_simd(const int16_t* src, int16_t* dst, uint8_t base, size_t length) {\n    __m256i base_v = _mm256_set1_epi16(base);\n    __m256i zero = _mm256_setzero_si256();\n    __m256i one = _mm256_set1_epi16(1);\n    __m256i mask = _mm256_set1_epi16(0xFFFF);\n\n    for (size_t i = 0; i < length; i += 16) {\n        __m256i src_v = _mm256_loadu_si256((__m256i*)(src + i));\n\n        __m256i div = _mm256_div_epi16(src_v, base_v);\n        __m256i mul = _mm256_mullo_epi16(base_v, div);\n        __m256i diff1 = _mm256_sub_epi16(src_v, mul);\n\n        __m256i mul_plus_one = _mm256_mullo_epi16(base_v, _mm256_add_epi16(div, one));\n        __m256i diff2 = _mm256_sub_epi16(mul_plus_one, src_v);\n\n        __m256i cmp = _mm256_cmpgt_epi16(diff1, diff2);\n        __m256i result = _mm256_blendv_epi8(mul_plus_one, mul, cmp);\n\n        _mm256_storeu_si256((__m256i*)(dst + i), result);\n    }\n}\n```"}
{"task_id": "SimdBench_31_AVX", "completion": "```c\nvoid nearest_multiple_simd(const int16_t* src, int16_t* dst, uint8_t base, size_t length) {\n    __m256i base_v = _mm256_set1_epi16(base);\n    __m256i mask = _mm256_set1_epi16(base - 1);\n    __m256i zero = _mm256_setzero_si256();\n\n    for (size_t i = 0; i < length; i += 16) {\n        __m256i src_v = _mm256_loadu_si256((__m256i*)(src + i));\n        __m256i div = _mm256_div_epi16(src_v, base_v);\n        __m256i mul = _mm256_mullo_epi16(div, base_v);\n        __m256i diff = _mm256_sub_epi16(src_v, mul);\n        __m256i cmp = _mm256_cmpgt_epi16(mask, diff);\n        __m256i result = _mm256_blendv_epi8(mul, _mm256_sub_epi16(mul, base_v), cmp);\n        _mm256_storeu_si256((__m256i*)(dst + i), result);\n    }\n}\n```"}
{"task_id": "SimdBench_31_AVX", "completion": "```c\nvoid nearest_multiple_simd(const int16_t* src, int16_t* dst, uint8_t base, size_t length) {\n    __m256i base_v = _mm256_set1_epi16(base);\n    __m256i zero = _mm256_setzero_si256();\n    __m256i one = _mm256_set1_epi16(1);\n    __m256i mask = _mm256_set1_epi16(0xFFFF);\n\n    for (size_t i = 0; i < length; i += 16) {\n        __m256i src_v = _mm256_loadu_si256((__m256i*)(src + i));\n\n        __m256i div = _mm256_div_epi16(src_v, base_v);\n        __m256i mul = _mm256_mullo_epi16(div, base_v);\n\n        __m256i cmp = _mm256_cmpgt_epi16(src_v, mul);\n        __m256i sub = _mm256_sub_epi16(cmp, one);\n        __m256i result = _mm256_add_epi16(mul, _mm256_and_si256(sub, base_v));\n\n        _mm256_storeu_si256((__m256i*)(dst + i), result);\n    }\n}\n```"}
{"task_id": "SimdBench_31_AVX", "completion": "```c\nvoid nearest_multiple_simd(const int16_t* src, int16_t* dst, uint8_t base, size_t length) {\n    __m256i base_v = _mm256_set1_epi16(base);\n    __m256i mask = _mm256_set1_epi16(0x7FFF); // Mask to clear the sign bit\n\n    for (size_t i = 0; i < length; i += 16) {\n        __m256i src_v = _mm256_loadu_si256((__m256i*)(src + i));\n        __m256i src_abs = _mm256_and_si256(src_v, mask); // Clear the sign bit to get absolute value\n\n        __m256i div = _mm256_div_epi16(src_abs, base_v);\n        __m256i nearest_multiple = _mm256_mullo_epi16(div, base_v);\n\n        __m256i cmp = _mm256_cmpgt_epi16(src_v, nearest_multiple);\n        __m256i result = _mm256_blendv_epi8(nearest_multiple, _mm256_sub_epi16(nearest_multiple, base_v), cmp);\n\n        _mm256_storeu_si256((__m256i*)(dst + i), result);\n    }\n}\n```"}
{"task_id": "SimdBench_32_AVX", "completion": "```cpp\nbool matrix_has_row_simd(const double* matrix, const double* vector, size_t rows, size_t cols) {\n    for (size_t i = 0; i < rows; i++) {\n        const double* row = matrix + i * cols;\n        __m256d sum = _mm256_setzero_pd();\n        for (size_t j = 0; j < cols; j += 4) {\n            __m256d a = _mm256_loadu_pd(row + j);\n            __m256d b = _mm256_loadu_pd(vector + j);\n            __m256d cmp = _mm256_cmp_pd(a, b, _CMP_EQ_OQ);\n            sum = _mm256_or_pd(sum, cmp);\n        }\n        int mask = _mm256_movemask_pd(sum);\n        if (mask == 15) {\n            return true;\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_32_AVX", "completion": "```cpp\nbool matrix_has_row_simd(const double* matrix, const double* vector, size_t rows, size_t cols) {\n    for (size_t i = 0; i < rows; i++) {\n        const double* row = matrix + i * cols;\n        __m256d match = _mm256_set1_pd(vector[0]);\n        for (size_t j = 0; j < cols; j += 4) {\n            __m256d m = _mm256_loadu_pd(row + j);\n            __m256d v = _mm256_loadu_pd(vector);\n            __m256d cmp = _mm256_cmp_pd(m, v, _CMP_EQ_OQ);\n            int mask = _mm256_movemask_pd(cmp);\n            if (mask == 15) {\n                return true;\n            }\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_32_AVX", "completion": "```cpp\nbool matrix_has_row_simd(const double* matrix, const double* vector, size_t rows, size_t cols) {\n    for (size_t i = 0; i < rows; ++i) {\n        const double* row = matrix + i * cols;\n        __m256d match = _mm256_set1_pd(vector[0]);\n        bool found = true;\n        for (size_t j = 0; j < cols; j += 4) {\n            __m256d mrow = _mm256_loadu_pd(row + j);\n            __m256d mvec = _mm256_loadu_pd(vector);\n            __m256d cmp = _mm256_cmp_pd(mrow, mvec, _CMP_EQ_OQ);\n            int mask = _mm256_movemask_pd(cmp);\n            if (mask != 15) {\n                found = false;\n                break;\n            }\n        }\n        if (found) {\n            return true;\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_32_AVX", "completion": "```cpp\nbool matrix_has_row_simd(const double* matrix, const double* vector, size_t rows, size_t cols) {\n    for (size_t i = 0; i < rows; i++) {\n        const double* row = matrix + i * cols;\n        __m256d match = _mm256_set1_pd(vector[0]);\n        size_t j = 0;\n        for (; j + 4 <= cols; j += 4) {\n            __m256d a = _mm256_loadu_pd(row + j);\n            __m256d b = _mm256_loadu_pd(vector);\n            __m256d cmp = _mm256_cmp_pd(a, b, _CMP_EQ_OQ);\n            int mask = _mm256_movemask_pd(cmp);\n            if (mask != 15) break;\n        }\n        for (; j < cols; j++) {\n            if (row[j] != vector[j]) break;\n        }\n        if (j == cols) return true;\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_32_AVX", "completion": "```cpp\nbool matrix_has_row_simd(const double* matrix, const double* vector, size_t rows, size_t cols) {\n    for (size_t i = 0; i < rows; i++) {\n        const double* row = matrix + i * cols;\n        __m256d match = _mm256_set1_pd(vector[0]);\n        for (size_t j = 0; j < cols; j += 4) {\n            __m256d m = _mm256_loadu_pd(row + j);\n            __m256d v = _mm256_loadu_pd(vector);\n            __m256d cmp = _mm256_cmp_pd(m, v, _CMP_EQ_OQ);\n            int mask = _mm256_movemask_pd(cmp);\n            if (mask == 15) {\n                return true;\n            }\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_33_AVX", "completion": "```\nsize_t tensor_4d_equal_count_simd(const uint8_t* A, const uint8_t* B, const size_t dims[4]) {\n    const size_t total_elements = dims[0] * dims[1] * dims[2] * dims[3];\n    const size_t total_elements_padded = total_elements + (32 - total_elements % 32);\n    \n    size_t equal_count = 0;\n    \n    for (size_t i = 0; i < total_elements_padded; i += 32) {\n        __m256i va = _mm256_loadu_si256((__m256i*)(A + i));\n        __m256i vb = _mm256_loadu_si256((__m256i*)(B + i));\n        \n        __m256i equal_mask = _mm256_cmpeq_epi8(va, vb);\n        \n        uint32_t mask = _mm256_movemask_epi8(equal_mask);\n        equal_count += _mm_popcnt_u32(mask);\n    }\n    \n    return equal_count;\n}\n```"}
{"task_id": "SimdBench_33_AVX", "completion": "```\nsize_t tensor_4d_equal_count_simd(const uint8_t* A, const uint8_t* B, const size_t dims[4]) {\n    const size_t total_elements = dims[0] * dims[1] * dims[2] * dims[3];\n    const size_t total_elements_avx = total_elements / 32 * 32;\n    \n    __m256i count = _mm256_setzero_si256();\n    \n    for (size_t i = 0; i < total_elements_avx; i += 32) {\n        __m256i a = _mm256_loadu_si256((__m256i*)(A + i));\n        __m256i b = _mm256_loadu_si256((__m256i*)(B + i));\n        __m256i equal = _mm256_cmpeq_epi8(a, b);\n        count = _mm256_add_epi8(count, equal);\n    }\n    \n    uint8_t count_array[32];\n    _mm256_storeu_si256((__m256i*)count_array, count);\n    \n    size_t equal_count = 0;\n    for (int i = 0; i < 32; i++) {\n        equal_count += count_array[i];\n    }\n    \n    for (size_t i = total_elements_avx; i < total_elements; i++) {\n        if (A[i] == B[i]) {\n            equal_count++;\n        }\n    }\n    \n    return equal_count;\n}\n```"}
{"task_id": "SimdBench_33_AVX", "completion": "```\nsize_t tensor_4d_equal_count_simd(const uint8_t* A, const uint8_t* B, const size_t dims[4]) {\n    size_t equalCount = 0;\n    const size_t totalSize = dims[0] * dims[1] * dims[2] * dims[3];\n    const size_t simdSize = 32; // 32 elements in a 256-bit AVX2 register\n\n    for (size_t i = 0; i < totalSize; i += simdSize) {\n        __m256i vecA = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i vecB = _mm256_loadu_si256((__m256i*)&B[i]);\n        __m256i cmpResult = _mm256_cmpeq_epi8(vecA, vecB);\n\n        uint32_t mask = _mm256_movemask_epi8(cmpResult);\n        equalCount += _mm_popcnt_u32(mask);\n    }\n\n    return equalCount;\n}\n```"}
{"task_id": "SimdBench_33_AVX", "completion": "```\nsize_t tensor_4d_equal_count_simd(const uint8_t* A, const uint8_t* B, const size_t dims[4]) {\n    const size_t total_elements = dims[0] * dims[1] * dims[2] * dims[3];\n    const size_t total_elements_padded = total_elements + (32 - (total_elements % 32));\n    \n    __m256i count = _mm256_setzero_si256();\n    \n    for (size_t i = 0; i < total_elements_padded; i += 32) {\n        __m256i a = _mm256_loadu_si256((__m256i*)(A + i));\n        __m256i b = _mm256_loadu_si256((__m256i*)(B + i));\n        \n        __m256i equal = _mm256_cmpeq_epi8(a, b);\n        count = _mm256_add_epi8(count, equal);\n    }\n    \n    alignas(32) uint8_t result[32];\n    _mm256_store_si256((__m256i*)result, count);\n    \n    size_t equal_count = 0;\n    for (int i = 0; i < 32; i++) {\n        equal_count += result[i];\n    }\n    \n    return equal_count;\n}\n```"}
{"task_id": "SimdBench_33_AVX", "completion": "```\nsize_t tensor_4d_equal_count_simd(const uint8_t* A, const uint8_t* B, const size_t dims[4]) {\n    size_t count = 0;\n    size_t total_elements = dims[0] * dims[1] * dims[2] * dims[3];\n    size_t simd_size = 32; // 32 bytes = 256 bits = AVX2 register size\n\n    for (size_t i = 0; i < total_elements; i += simd_size) {\n        __m256i va = _mm256_loadu_si256((__m256i*)(A + i));\n        __m256i vb = _mm256_loadu_si256((__m256i*)(B + i));\n        __m256i equal_mask = _mm256_cmpeq_epi8(va, vb);\n        count += _mm256_popcnt_u32(_mm256_movemask_epi8(equal_mask));\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_34_AVX", "completion": "```\nvoid axm_abs_simd(size_t length, const int64_t a, const int64_t *x, int64_t *y) {\n    __m256i scalar_a = _mm256_set1_epi64x(a);\n    for (size_t i = 0; i < length; i += 4) {\n        __m256i vec_x = _mm256_loadu_si256((__m256i*)&x[i]);\n        __m256i vec_result = _mm256_sub_epi64(_mm256_abs_epi64(vec_x), _mm256_mul_epi32(scalar_a, vec_x));\n        _mm256_storeu_si256((__m256i*)&y[i], vec_result);\n    }\n}\n```  "}
{"task_id": "SimdBench_34_AVX", "completion": "```\nvoid axm_abs_simd(size_t length, const int64_t a, const int64_t *x, int64_t *y) {\n    __m256i va = _mm256_set1_epi64x(a);\n    for (size_t i = 0; i < length; i += 4) {\n        __m256i vx = _mm256_loadu_si256((__m256i*)&x[i]);\n        __m256i vmul = _mm256_mul_epi32(va, vx);\n        __m256i vabs = _mm256_abs_epi64(vmul);\n        _mm256_storeu_si256((__m256i*)&y[i], vabs);\n    }\n}\n```"}
{"task_id": "SimdBench_34_AVX", "completion": "```\nvoid axm_abs_simd(size_t length, const int64_t a, const int64_t *x, int64_t *y) {\n    __m256i va = _mm256_set1_epi64x(a);\n    for (size_t i = 0; i < length; i += 4) {\n        __m256i vx = _mm256_loadu_si256((__m256i*)(x + i));\n        __m256i vmul = _mm256_mul_epi32(va, vx);\n        __m256i vabs = _mm256_abs_epi64(vmul);\n        _mm256_storeu_si256((__m256i*)(y + i), vabs);\n    }\n}\n```"}
{"task_id": "SimdBench_34_AVX", "completion": "```\nvoid axm_abs_simd(size_t length, const int64_t a, const int64_t *x, int64_t *y) {\n    __m256i va = _mm256_set1_epi64x(a);\n    for (size_t i = 0; i < length; i += 4) {\n        __m256i vx = _mm256_loadu_si256((__m256i*)&x[i]);\n        __m256i vmul = _mm256_mul_epi32(va, vx);\n        __m256i vabs = _mm256_abs_epi64(vmul);\n        _mm256_storeu_si256((__m256i*)&y[i], vabs);\n    }\n}\n```"}
{"task_id": "SimdBench_34_AVX", "completion": "```\nvoid axm_abs_simd(size_t length, const int64_t a, const int64_t *x, int64_t *y) {\n    __m256i va = _mm256_set1_epi64x(a);\n    for (size_t i = 0; i < length; i += 4) {\n        __m256i vx = _mm256_loadu_si256((__m256i*)&x[i]);\n        __m256i vmul = _mm256_mul_epi32(va, vx);\n        __m256i vabs = _mm256_abs_epi64(vmul);\n        _mm256_storeu_si256((__m256i*)&y[i], vabs);\n    }\n}\n```  "}
{"task_id": "SimdBench_35_AVX", "completion": "```c\ntypedef struct {\n    int16_t min_num;\n    int16_t max_num;\n} MinMaxPair;\n\nMinMaxPair min_max_pair_simd(const int16_t* vec, size_t length) {\n    __m256i min_val = _mm256_set1_epi16(INT16_MAX);\n    __m256i max_val = _mm256_set1_epi16(INT16_MIN);\n\n    for (size_t i = 0; i < length; i += 16) {\n        __m256i vec_data = _mm256_loadu_si256((__m256i*)&vec[i]);\n        \n        min_val = _mm256_min_epi16(min_val, vec_data);\n        max_val = _mm256_max_epi16(max_val, vec_data);\n    }\n\n    __m128i min_val_lo = _mm256_extracti128_si256(min_val, 0);\n    __m128i min_val_hi = _mm256_extracti128_si256(min_val, 1);\n    __m128i max_val_lo = _mm256_extracti128_si256(max_val, 0);\n    __m128i max_val_hi = _mm256_extracti128_si256(max_val, 1);\n\n    __m128i min_val_final = _mm_min_epi16(min_val_lo, min_val_hi);\n    __m128i max_val_final = _mm_max_epi16(max_val_lo, max_val_hi);\n\n    int16_t min_result[8], max_result[8];\n    _mm_storeu_si128((__m128i*)min_result, min_val_final);\n    _mm_storeu_si128((__m128i*)max_result, max_val_final);\n\n    int16_t min_num = min_result[0];\n    int16_t max_num = max_result[0];\n    for (int i = 1; i < 8; ++i) {\n        if (min_result[i] < min_num) min_num = min_result[i];\n        if (max_result[i] > max_num) max_num = max_result[i];\n    }\n\n    return (MinMaxPair){min_num, max_num};\n}\n```"}
{"task_id": "SimdBench_35_AVX", "completion": "```c\n#include <immintrin.h>\n#include <x86intrin.h>\n\ntypedef struct {\n    int16_t min_num;\n    int16_t max_num;\n} MinMaxPair;\n\nMinMaxPair min_max_pair_simd(const int16_t* vec, size_t length) {\n    __m256i min_val = _mm256_set1_epi16(INT16_MAX);\n    __m256i max_val = _mm256_set1_epi16(INT16_MIN);\n\n    for (size_t i = 0; i < length; i += 16) {\n        __m256i vec_data = _mm256_loadu_si256((__m256i*)&vec[i]);\n        min_val = _mm256_min_epi16(min_val, vec_data);\n        max_val = _mm256_max_epi16(max_val, vec_data);\n    }\n\n    __m128i min_val_lo = _mm256_castsi256_si128(min_val);\n    __m128i min_val_hi = _mm256_extracti128_si256(min_val, 1);\n    __m128i min_val_final = _mm_min_epi16(min_val_lo, min_val_hi);\n\n    __m128i max_val_lo = _mm256_castsi256_si128(max_val);\n    __m128i max_val_hi = _mm256_extracti128_si256(max_val, 1);\n    __m128i max_val_final = _mm_max_epi16(max_val_lo, max_val_hi);\n\n    MinMaxPair result;\n    result.min_num = _mm_extract_epi16(min_val_final, 0);\n    result.max_num = _mm_extract_epi16(max_val_final, 0);\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_35_AVX", "completion": "```c\n#include <immintrin.h>\n#include <x86intrin.h>\n\ntypedef struct {\n    int16_t min_num;\n    int16_t max_num;\n} MinMaxPair;\n\nMinMaxPair min_max_pair_simd(const int16_t* vec, size_t length) {\n    __m256i min_val = _mm256_set1_epi16(INT16_MAX);\n    __m256i max_val = _mm256_set1_epi16(INT16_MIN);\n\n    for (size_t i = 0; i < length; i += 16) {\n        __m256i vec_data = _mm256_loadu_si256((__m256i*)&vec[i]);\n        min_val = _mm256_min_epi16(min_val, vec_data);\n        max_val = _mm256_max_epi16(max_val, vec_data);\n    }\n\n    __m128i min_val_lo = _mm256_extracti128_si256(min_val, 0);\n    __m128i min_val_hi = _mm256_extracti128_si256(min_val, 1);\n    __m128i max_val_lo = _mm256_extracti128_si256(max_val, 0);\n    __m128i max_val_hi = _mm256_extracti128_si256(max_val, 1);\n\n    __m128i min_val_final = _mm_min_epi16(min_val_lo, min_val_hi);\n    __m128i max_val_final = _mm_max_epi16(max_val_lo, max_val_hi);\n\n    int16_t min_result[8], max_result[8];\n    _mm_storeu_si128((__m128i*)min_result, min_val_final);\n    _mm_storeu_si128((__m128i*)max_result, max_val_final);\n\n    int16_t min_num = min_result[0];\n    int16_t max_num = max_result[0];\n\n    for (int i = 1; i < 8; i++) {\n        min_num = (min_result[i] < min_num) ? min_result[i] : min_num;\n        max_num = (max_result[i] > max_num) ? max_result[i] : max_num;\n    }\n\n    return (MinMaxPair){min_num, max_num};\n}\n```"}
{"task_id": "SimdBench_35_AVX", "completion": "```c\ntypedef struct {\n    int16_t min_num;\n    int16_t max_num;\n} MinMaxPair;\n\nMinMaxPair min_max_pair_simd(const int16_t* vec, size_t length) {\n    __m256i min_val = _mm256_set1_epi16(INT16_MAX);\n    __m256i max_val = _mm256_set1_epi16(INT16_MIN);\n\n    for (size_t i = 0; i < length; i += 16) {\n        __m256i vec_data = _mm256_loadu_si256((__m256i*)&vec[i]);\n        min_val = _mm256_min_epi16(min_val, vec_data);\n        max_val = _mm256_max_epi16(max_val, vec_data);\n    }\n\n    __m128i min_val_lo = _mm256_extracti128_si256(min_val, 0);\n    __m128i min_val_hi = _mm256_extracti128_si256(min_val, 1);\n    __m128i max_val_lo = _mm256_extracti128_si256(max_val, 0);\n    __m128i max_val_hi = _mm256_extracti128_si256(max_val, 1);\n\n    __m128i min_val_final = _mm_min_epi16(min_val_lo, min_val_hi);\n    __m128i max_val_final = _mm_max_epi16(max_val_lo, max_val_hi);\n\n    int16_t min_result[8], max_result[8];\n    _mm_storeu_si128((__m128i*)min_result, min_val_final);\n    _mm_storeu_si128((__m128i*)max_result, max_val_final);\n\n    int16_t min_num = min_result[0];\n    int16_t max_num = max_result[0];\n\n    for (int i = 1; i < 8; ++i) {\n        if (min_result[i] < min_num) min_num = min_result[i];\n        if (max_result[i] > max_num) max_num = max_result[i];\n    }\n\n    return (MinMaxPair){min_num, max_num};\n}\n```"}
{"task_id": "SimdBench_35_AVX", "completion": "```c\ntypedef struct {\n    int16_t min_num;\n    int16_t max_num;\n} MinMaxPair;\n\nMinMaxPair min_max_pair_simd(const int16_t* vec, size_t length) {\n    __m256i min_val = _mm256_set1_epi16(INT16_MAX);\n    __m256i max_val = _mm256_set1_epi16(INT16_MIN);\n\n    for (size_t i = 0; i < length; i += 16) {\n        __m256i vec_chunk = _mm256_loadu_si256((__m256i*)&vec[i]);\n        \n        min_val = _mm256_min_epi16(min_val, vec_chunk);\n        max_val = _mm256_max_epi16(max_val, vec_chunk);\n    }\n\n    __m128i min_val_lo = _mm256_extracti128_si256(min_val, 0);\n    __m128i min_val_hi = _mm256_extracti128_si256(min_val, 1);\n    __m128i max_val_lo = _mm256_extracti128_si256(max_val, 0);\n    __m128i max_val_hi = _mm256_extracti128_si256(max_val, 1);\n\n    __m128i min_val_final = _mm_min_epi16(min_val_lo, min_val_hi);\n    __m128i max_val_final = _mm_max_epi16(max_val_lo, max_val_hi);\n\n    int16_t min_result[8], max_result[8];\n    _mm_storeu_si128((__m128i*)min_result, min_val_final);\n    _mm_storeu_si128((__m128i*)max_result, max_val_final);\n\n    int16_t min_num = min_result[0];\n    int16_t max_num = max_result[0];\n\n    for (int i = 1; i < 8; ++i) {\n        if (min_result[i] < min_num) min_num = min_result[i];\n        if (max_result[i] > max_num) max_num = max_result[i];\n    }\n\n    return (MinMaxPair){min_num, max_num};\n}\n```"}
{"task_id": "SimdBench_36_AVX", "completion": "```cpp\nbool matrix_rows_strictly_increasing_simd(const int* matrix, size_t rows, size_t cols) {\n    if (rows == 0) {\n        return false;\n    }\n\n    for (size_t i = 0; i < rows; ++i) {\n        const int* row = matrix + i * cols;\n        __m256i prev_values = _mm256_loadu_si256((__m256i*)row);\n\n        for (size_t j = 1; j < cols / 8; ++j) {\n            __m256i current_values = _mm256_loadu_si256((__m256i*)(row + j * 8));\n            __m256i cmp_result = _mm256_cmpgt_epi32(current_values, prev_values);\n            int mask = _mm256_movemask_ps(_mm256_castsi256_ps(cmp_result));\n            if (mask != 255) {\n                return false;\n            }\n            prev_values = current_values;\n        }\n\n        for (size_t j = cols / 8 * 8; j < cols; ++j) {\n            if (row[j] <= row[j - 1]) {\n                return false;\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_36_AVX", "completion": "```\nbool matrix_rows_strictly_increasing_simd(const int* matrix, size_t rows, size_t cols) {\n    if (rows == 0) {\n        return false;\n    }\n\n    for (size_t i = 0; i < rows; ++i) {\n        const int* row = matrix + i * cols;\n        __m256i prev_values = _mm256_set1_epi32(row[0]);\n\n        for (size_t j = 1; j < cols; j += 8) {\n            __m256i current_values = _mm256_loadu_si256((__m256i*)(row + j));\n            __m256i cmp_result = _mm256_cmpgt_epi32(current_values, prev_values);\n            int mask = _mm256_movemask_ps(_mm256_castsi256_ps(cmp_result));\n            if (mask != 255) {\n                return false;\n            }\n            prev_values = current_values;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_36_AVX", "completion": "```\nbool matrix_rows_strictly_increasing_simd(const int* matrix, size_t rows, size_t cols) {\n    if (rows == 0) {\n        return false;\n    }\n\n    for (size_t i = 0; i < rows; ++i) {\n        const int* row = matrix + i * cols;\n        __m256i prev_values = _mm256_set1_epi32(row[0]);\n\n        for (size_t j = 1; j < cols; j += 8) {\n            __m256i current_values = _mm256_loadu_si256((__m256i*)(row + j));\n            __m256i cmp_result = _mm256_cmpgt_epi32(current_values, prev_values);\n            int mask = _mm256_movemask_ps(_mm256_castsi256_ps(cmp_result));\n            if (mask != 255) {\n                return false;\n            }\n            prev_values = current_values;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_36_AVX", "completion": "```\nbool matrix_rows_strictly_increasing_simd(const int* matrix, size_t rows, size_t cols) {\n    if (rows == 0) {\n        return false;\n    }\n\n    for (size_t i = 0; i < rows; ++i) {\n        const int* row = matrix + i * cols;\n        __m256i prev_values = _mm256_set1_epi32(row[0]);\n\n        for (size_t j = 1; j < cols; j += 8) {\n            __m256i current_values = _mm256_loadu_si256((__m256i*)(row + j));\n            __m256i cmp_result = _mm256_cmpgt_epi32(current_values, prev_values);\n            int mask = _mm256_movemask_ps(_mm256_castsi256_ps(cmp_result));\n            if (mask != 255) {\n                return false;\n            }\n            prev_values = current_values;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_36_AVX", "completion": "```cpp\nbool matrix_rows_strictly_increasing_simd(const int* matrix, size_t rows, size_t cols) {\n    if (rows == 0) {\n        return false;\n    }\n\n    for (size_t i = 0; i < rows; ++i) {\n        const int* row = matrix + i * cols;\n        __m256i prev_values = _mm256_set1_epi32(row[0]);\n\n        for (size_t j = 1; j < cols; j += 8) {\n            __m256i current_values = _mm256_loadu_si256((__m256i*)(row + j));\n            __m256i cmp_result = _mm256_cmpgt_epi32(current_values, prev_values);\n            int mask = _mm256_movemask_ps(_mm256_castsi256_ps(cmp_result));\n            if (mask != 255) {\n                return false;\n            }\n            prev_values = current_values;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_37_AVX", "completion": "```\nbool matrix_blocks_equal_simd(const int* matrix, size_t block_size, size_t rows, size_t cols) {\n    if (rows % block_size != 0 || cols % block_size != 0) {\n        return false;\n    }\n\n    const size_t block_elements = block_size * block_size;\n    const size_t num_blocks_row = cols / block_size;\n    const size_t num_blocks_col = rows / block_size;\n\n    for (size_t i = 1; i < num_blocks_col; ++i) {\n        for (size_t j = 1; j < num_blocks_row; ++j) {\n            const int* block_start = matrix + i * block_size * cols + j * block_size;\n            const int* first_block_start = matrix;\n\n            __m256i all_equal = _mm256_set1_epi32(1);\n\n            for (size_t k = 0; k < block_size; ++k) {\n                const int* block_row_start = block_start + k * cols;\n                const int* first_block_row_start = first_block_start + k * cols;\n\n                for (size_t l = 0; l < block_size; l += 8) {\n                    __m256i block_values = _mm256_loadu_si256((__m256i*)(block_row_start + l));\n                    __m256i first_block_values = _mm256_loadu_si256((__m256i*)(first_block_row_start + l));\n\n                    __m256i equal = _mm256_cmpeq_epi32(block_values, first_block_values);\n                    all_equal = _mm256_and_si256(all_equal, equal);\n                }\n            }\n\n            int equal_mask = _mm256_movemask_ps(_mm256_castsi256_ps(all_equal));\n            if (equal_mask != 255) {\n                return false;\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_37_AVX", "completion": "```cpp\nbool matrix_blocks_equal_simd(const int* matrix, size_t block_size, size_t rows, size_t cols) {\n    if (rows % block_size != 0 || cols % block_size != 0) {\n        return false;\n    }\n\n    size_t block_elements = block_size * block_size;\n    size_t num_blocks_row = cols / block_size;\n    size_t num_blocks_col = rows / block_size;\n\n    for (size_t i = 0; i < num_blocks_col; i++) {\n        for (size_t j = 0; j < num_blocks_row; j++) {\n            const int* block_start = matrix + i * block_size * cols + j * block_size;\n            __m256i first_block = _mm256_loadu_si256((__m256i*)block_start);\n\n            for (size_t k = 1; k < block_size; k++) {\n                const int* current_block_start = block_start + k * cols;\n                __m256i current_block = _mm256_loadu_si256((__m256i*)current_block_start);\n                if (!_mm256_testc_si256(first_block, current_block)) {\n                    return false;\n                }\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_37_AVX", "completion": "```cpp\nbool matrix_blocks_equal_simd(const int* matrix, size_t block_size, size_t rows, size_t cols) {\n    if (rows % block_size != 0 || cols % block_size != 0) {\n        return false;\n    }\n\n    size_t block_elements = block_size * block_size;\n    size_t num_blocks_row = cols / block_size;\n    size_t num_blocks_col = rows / block_size;\n\n    for (size_t i = 0; i < num_blocks_col; i++) {\n        for (size_t j = 0; j < num_blocks_row; j++) {\n            const int* block_start = matrix + i * block_size * cols + j * block_size;\n            __m256i first_block = _mm256_loadu_si256((__m256i*)block_start);\n\n            for (size_t k = 1; k < block_size; k++) {\n                const int* current_block_start = block_start + k * cols;\n                __m256i current_block = _mm256_loadu_si256((__m256i*)current_block_start);\n                if (!_mm256_testc_si256(first_block, current_block)) {\n                    return false;\n                }\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_37_AVX", "completion": "```cpp\nbool matrix_blocks_equal_simd(const int* matrix, size_t block_size, size_t rows, size_t cols) {\n    if (rows % block_size != 0 || cols % block_size != 0) {\n        return false;\n    }\n\n    size_t block_elements = block_size * block_size;\n    size_t num_blocks_row = cols / block_size;\n    size_t num_blocks_col = rows / block_size;\n\n    for (size_t i = 0; i < num_blocks_col; i++) {\n        for (size_t j = 0; j < num_blocks_row; j++) {\n            const int* block_start = matrix + i * block_size * cols + j * block_size;\n            __m256i first_block = _mm256_loadu_si256((__m256i*)block_start);\n\n            for (size_t k = 1; k < block_size; k++) {\n                const int* current_block_start = block_start + k * cols;\n                __m256i current_block = _mm256_loadu_si256((__m256i*)current_block_start);\n                if (!_mm256_testc_si256(first_block, current_block)) {\n                    return false;\n                }\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_37_AVX", "completion": "```\nbool matrix_blocks_equal_simd(const int* matrix, size_t block_size, size_t rows, size_t cols) {\n    if (rows % block_size != 0 || cols % block_size != 0) {\n        return false;\n    }\n\n    size_t block_elements = block_size * block_size;\n    size_t num_blocks_row = cols / block_size;\n    size_t num_blocks_col = rows / block_size;\n\n    for (size_t i = 0; i < num_blocks_col; i++) {\n        for (size_t j = 0; j < num_blocks_row; j++) {\n            const int* block_start = matrix + i * block_size * cols + j * block_size;\n            __m256i first_block = _mm256_loadu_si256((__m256i*)block_start);\n\n            for (size_t k = 1; k < block_size; k++) {\n                const int* current_block_start = block_start + k * cols;\n                __m256i current_block = _mm256_loadu_si256((__m256i*)current_block_start);\n                if (!_mm256_testc_si256(first_block, current_block)) {\n                    return false;\n                }\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_38_AVX", "completion": "```\nbool vector_block_equal_simd(const double* vec, double tolerance, size_t length, size_t block_size) {\n    if (length % block_size != 0 || length < block_size) {\n        return false;\n    }\n\n    const __m256d first_block = _mm256_loadu_pd(vec);\n    const __m256d tolerance_vec = _mm256_set1_pd(tolerance);\n\n    for (size_t i = block_size; i < length; i += block_size) {\n        const __m256d current_block = _mm256_loadu_pd(vec + i);\n        const __m256d diff = _mm256_sub_pd(first_block, current_block);\n        const __m256d abs_diff = _mm256_andnot_pd(_mm256_set1_pd(-0.0), diff);\n        const __m256d cmp = _mm256_cmp_pd(abs_diff, tolerance_vec, _CMP_LE_OQ);\n        if (_mm256_movemask_pd(cmp) != 0b1111) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_38_AVX", "completion": "```cpp\nbool vector_block_equal_simd(const double* vec, double tolerance, size_t length, size_t block_size) {\n    if (length % block_size != 0 || block_size < 4) {\n        return false;\n    }\n\n    const size_t num_blocks = length / block_size;\n    const size_t num_elements = num_blocks * block_size;\n\n    __m256d first_block = _mm256_loadu_pd(vec);\n    for (size_t i = 1; i < num_blocks; ++i) {\n        __m256d current_block = _mm256_loadu_pd(vec + i * block_size);\n        __m256d diff = _mm256_sub_pd(first_block, current_block);\n        __m256d abs_diff = _mm256_and_pd(diff, _mm256_set1_pd(-0.0));\n        __m256d cmp = _mm256_cmp_pd(abs_diff, _mm256_set1_pd(tolerance), _CMP_LE_OQ);\n        int mask = _mm256_movemask_pd(cmp);\n        if (mask != 15) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_38_AVX", "completion": "```\nbool vector_block_equal_simd(const double* vec, double tolerance, size_t length, size_t block_size) {\n    if (length % block_size != 0 || block_size % 4 != 0) {\n        return false;\n    }\n\n    const __m256d first_block = _mm256_loadu_pd(vec);\n    for (size_t i = block_size; i < length; i += block_size) {\n        const __m256d block = _mm256_loadu_pd(vec + i);\n        const __m256d diff = _mm256_sub_pd(first_block, block);\n        const __m256d abs_diff = _mm256_and_pd(diff, _mm256_set1_pd(-0.0));\n        const __m256d cmp = _mm256_cmp_pd(abs_diff, _mm256_set1_pd(tolerance), _CMP_LE_OQ);\n        const int mask = _mm256_movemask_pd(cmp);\n        if (mask != 15) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_38_AVX", "completion": "```cpp\nbool vector_block_equal_simd(const double* vec, double tolerance, size_t length, size_t block_size) {\n    if (length % block_size != 0 || block_size < 4) {\n        return false;\n    }\n\n    const size_t num_blocks = length / block_size;\n    const size_t simd_block_size = 4;\n    const __m256d tolerance_vec = _mm256_set1_pd(tolerance);\n\n    __m256d first_block = _mm256_loadu_pd(vec);\n\n    for (size_t i = 1; i < num_blocks; ++i) {\n        const double* block_start = vec + i * block_size;\n        __m256d block = _mm256_loadu_pd(block_start);\n\n        __m256d diff = _mm256_sub_pd(first_block, block);\n        __m256d abs_diff = _mm256_andnot_pd(_mm256_set1_pd(-0.0), diff); // Absolute difference\n\n        __m256d cmp = _mm256_cmp_pd(abs_diff, tolerance_vec, _CMP_LE_OQ);\n        int mask = _mm256_movemask_pd(cmp);\n\n        if (mask != 15) { // Check if all elements are within tolerance\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_38_AVX", "completion": "```cpp\nbool vector_block_equal_simd(const double* vec, double tolerance, size_t length, size_t block_size) {\n    if (length % block_size != 0 || length < block_size) {\n        return false;\n    }\n\n    const size_t num_blocks = length / block_size;\n    const __m256d tolerance_v = _mm256_set1_pd(tolerance);\n    const __m256i mask = _mm256_set_epi64x(0, 0, 0, -1);\n\n    __m256d first_block = _mm256_loadu_pd(vec);\n    for (size_t i = 1; i < num_blocks; ++i) {\n        const double* block_start = vec + i * block_size;\n        __m256d block = _mm256_loadu_pd(block_start);\n        __m256d diff = _mm256_sub_pd(first_block, block);\n        __m256d abs_diff = _mm256_and_pd(diff, _mm256_castsi256_pd(mask));\n        __m256d cmp = _mm256_cmp_pd(abs_diff, tolerance_v, _CMP_LE_OQ);\n        int mask = _mm256_movemask_pd(cmp);\n        if (mask != 15) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_39_AVX", "completion": "```c\nvoid matrix_row_norm_compare_simd(const double* matrix, const double* thresholds, size_t rows, size_t cols, bool* result) {\n    for (size_t i = 0; i < rows; i++) {\n        __m256d sum = _mm256_setzero_pd();\n        for (size_t j = 0; j < cols; j += 4) {\n            __m256d vec1 = _mm256_loadu_pd(&matrix[i * cols + j]);\n            __m256d vec2 = _mm256_loadu_pd(&matrix[i * cols + j + 4]);\n            __m256d diff1 = _mm256_sub_pd(vec1, _mm256_loadu_pd(&thresholds[j]));\n            __m256d diff2 = _mm256_sub_pd(vec2, _mm256_loadu_pd(&thresholds[j + 4]));\n            sum = _mm256_fmadd_pd(diff1, diff1, sum);\n            sum = _mm256_fmadd_pd(diff2, diff2, sum);\n        }\n        double temp[4];\n        _mm256_storeu_pd(temp, sum);\n        result[i] = (temp[0] + temp[1] + temp[2] + temp[3] > 0);\n    }\n}\n```"}
{"task_id": "SimdBench_39_AVX", "completion": "```cpp\nvoid matrix_row_norm_compare_simd(const double* matrix, const double* thresholds, size_t rows, size_t cols, bool* result) {\n    for (size_t i = 0; i < rows; ++i) {\n        __m256d sum = _mm256_setzero_pd();\n        for (size_t j = 0; j < cols; j += 4) {\n            __m256d vec1 = _mm256_loadu_pd(&matrix[i * cols + j]);\n            __m256d vec2 = _mm256_loadu_pd(&matrix[i * cols + j + 4]);\n            __m256d diff1 = _mm256_sub_pd(vec1, _mm256_loadu_pd(&thresholds[j]));\n            __m256d diff2 = _mm256_sub_pd(vec2, _mm256_loadu_pd(&thresholds[j + 4]));\n            sum = _mm256_fmadd_pd(diff1, diff1, sum);\n            sum = _mm256_fmadd_pd(diff2, diff2, sum);\n        }\n        double temp[4];\n        _mm256_storeu_pd(temp, sum);\n        for (size_t k = 0; k < 4; ++k) {\n            result[i] = result[i] || (temp[k] > thresholds[i * 4 + k]);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_39_AVX", "completion": "```cpp\nvoid matrix_row_norm_compare_simd(const double* matrix, const double* thresholds, size_t rows, size_t cols, bool* result) {\n    for (size_t i = 0; i < rows; ++i) {\n        __m256d sum = _mm256_setzero_pd();\n        for (size_t j = 0; j < cols; j += 4) {\n            __m256d vec1 = _mm256_loadu_pd(&matrix[i * cols + j]);\n            __m256d vec2 = _mm256_loadu_pd(&matrix[i * cols + j + 4]);\n            __m256d diff1 = _mm256_sub_pd(vec1, _mm256_loadu_pd(&thresholds[j]));\n            __m256d diff2 = _mm256_sub_pd(vec2, _mm256_loadu_pd(&thresholds[j + 4]));\n            sum = _mm256_fmadd_pd(diff1, diff1, sum);\n            sum = _mm256_fmadd_pd(diff2, diff2, sum);\n        }\n        double temp[4];\n        _mm256_storeu_pd(temp, sum);\n        result[i] = (temp[0] + temp[1] + temp[2] + temp[3] > thresholds[cols - 4]);\n    }\n}\n```"}
{"task_id": "SimdBench_39_AVX", "completion": "```cpp\nvoid matrix_row_norm_compare_simd(const double* matrix, const double* thresholds, size_t rows, size_t cols, bool* result) {\n    for (size_t i = 0; i < rows; ++i) {\n        __m256d sum = _mm256_setzero_pd();\n        for (size_t j = 0; j < cols; j += 4) {\n            __m256d vec1 = _mm256_loadu_pd(&matrix[i * cols + j]);\n            __m256d vec2 = _mm256_loadu_pd(&matrix[i * cols + j + 4]);\n            __m256d diff1 = _mm256_sub_pd(vec1, _mm256_loadu_pd(&thresholds[j]));\n            __m256d diff2 = _mm256_sub_pd(vec2, _mm256_loadu_pd(&thresholds[j + 4]));\n            sum = _mm256_fmadd_pd(diff1, diff1, sum);\n            sum = _mm256_fmadd_pd(diff2, diff2, sum);\n        }\n        double temp[4];\n        _mm256_storeu_pd(temp, sum);\n        for (size_t k = 0; k < 4; ++k) {\n            result[i] = result[i] || (temp[k] > thresholds[i * cols + k]);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_39_AVX", "completion": "```cpp\nvoid matrix_row_norm_compare_simd(const double* matrix, const double* thresholds, size_t rows, size_t cols, bool* result) {\n    for (size_t i = 0; i < rows; ++i) {\n        __m256d sum = _mm256_setzero_pd();\n        for (size_t j = 0; j < cols; j += 4) {\n            __m256d vec1 = _mm256_loadu_pd(&matrix[i * cols + j]);\n            __m256d vec2 = _mm256_loadu_pd(&matrix[i * cols + j + 4]);\n            __m256d diff1 = _mm256_sub_pd(vec1, _mm256_loadu_pd(&thresholds[j]));\n            __m256d diff2 = _mm256_sub_pd(vec2, _mm256_loadu_pd(&thresholds[j + 4]));\n            sum = _mm256_fmadd_pd(diff1, diff1, sum);\n            sum = _mm256_fmadd_pd(diff2, diff2, sum);\n        }\n        double temp[4];\n        _mm256_storeu_pd(temp, sum);\n        result[i] = (temp[0] + temp[1] + temp[2] + temp[3] > 0);\n    }\n}\n```"}
{"task_id": "SimdBench_40_AVX", "completion": "```cpp\nvoid tensor_bitwise_or_simd(const uint32_t* A, const uint32_t* B, uint32_t* C, size_t length) {\n    const size_t simd_length = length / 8;\n    const __m256i* A_ptr = reinterpret_cast<const __m256i*>(A);\n    const __m256i* B_ptr = reinterpret_cast<const __m256i*>(B);\n    __m256i* C_ptr = reinterpret_cast<__m256i*>(C);\n\n    for (size_t i = 0; i < simd_length; ++i) {\n        __m256i a = _mm256_loadu_si256(A_ptr + i);\n        __m256i b = _mm256_loadu_si256(B_ptr + i);\n        __m256i result = _mm256_or_si256(a, b);\n        _mm256_storeu_si256(C_ptr + i, result);\n    }\n\n    for (size_t i = simd_length * 8; i < length; ++i) {\n        C[i] = A[i] | B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_40_AVX", "completion": "```cpp\nvoid tensor_bitwise_or_simd(const uint32_t* A, const uint32_t* B, uint32_t* C, size_t length) {\n    const size_t simd_length = length / 8;\n    const size_t remainder = length % 8;\n\n    __m256i* A_ptr = (__m256i*)A;\n    __m256i* B_ptr = (__m256i*)B;\n    __m256i* C_ptr = (__m256i*)C;\n\n    for (size_t i = 0; i < simd_length; i++) {\n        __m256i a = _mm256_loadu_si256(A_ptr);\n        __m256i b = _mm256_loadu_si256(B_ptr);\n        __m256i result = _mm256_or_si256(a, b);\n        _mm256_storeu_si256(C_ptr, result);\n\n        A_ptr++;\n        B_ptr++;\n        C_ptr++;\n    }\n\n    for (size_t i = 0; i < remainder; i++) {\n        C[length - remainder + i] = A[length - remainder + i] | B[length - remainder + i];\n    }\n}\n```  "}
{"task_id": "SimdBench_40_AVX", "completion": "```cpp\nvoid tensor_bitwise_or_simd(const uint32_t* A, const uint32_t* B, uint32_t* C, size_t length) {\n    const size_t simd_length = length / 8;\n    const __m256i* A_ptr = reinterpret_cast<const __m256i*>(A);\n    const __m256i* B_ptr = reinterpret_cast<const __m256i*>(B);\n    __m256i* C_ptr = reinterpret_cast<__m256i*>(C);\n\n    for (size_t i = 0; i < simd_length; ++i) {\n        __m256i a = _mm256_loadu_si256(&A_ptr[i]);\n        __m256i b = _mm256_loadu_si256(&B_ptr[i]);\n        __m256i result = _mm256_or_si256(a, b);\n        _mm256_storeu_si256(&C_ptr[i], result);\n    }\n\n    for (size_t i = simd_length * 8; i < length; ++i) {\n        C[i] = A[i] | B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_40_AVX", "completion": "```cpp\nvoid tensor_bitwise_or_simd(const uint32_t* A, const uint32_t* B, uint32_t* C, size_t length) {\n    const size_t simd_length = length / 8;\n    const size_t remainder = length % 8;\n\n    for (size_t i = 0; i < simd_length; ++i) {\n        __m256i a_vec = _mm256_loadu_si256((__m256i*)&A[i * 8]);\n        __m256i b_vec = _mm256_loadu_si256((__m256i*)&B[i * 8]);\n        __m256i result = _mm256_or_si256(a_vec, b_vec);\n        _mm256_storeu_si256((__m256i*)&C[i * 8], result);\n    }\n\n    for (size_t i = simd_length * 8; i < length; ++i) {\n        C[i] = A[i] | B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_40_AVX", "completion": "```cpp\nvoid tensor_bitwise_or_simd(const uint32_t* A, const uint32_t* B, uint32_t* C, size_t length) {\n    const size_t simd_length = length / 8 * 8;\n    \n    for (size_t i = 0; i < simd_length; i += 8) {\n        __m256i a_vec = _mm256_loadu_si256((__m256i*)(A + i));\n        __m256i b_vec = _mm256_loadu_si256((__m256i*)(B + i));\n        __m256i result = _mm256_or_si256(a_vec, b_vec);\n        _mm256_storeu_si256((__m256i*)(C + i), result);\n    }\n    \n    for (size_t i = simd_length; i < length; ++i) {\n        C[i] = A[i] | B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_41_AVX", "completion": "```\nint64_t squarediff_simd(const int8_t * A, const int8_t * B, size_t length) {\n    __m256i sum_squares = _mm256_setzero_si256();\n    __m256i sum_products = _mm256_setzero_si256();\n    \n    for (size_t i = 0; i < length; i += 32) {\n        __m256i a = _mm256_loadu_si256((__m256i*)(A + i));\n        __m256i b = _mm256_loadu_si256((__m256i*)(B + i));\n        \n        __m256i a_squared = _mm256_mullo_epi16(a, a);\n        __m256i b_squared = _mm256_mullo_epi16(b, b);\n        \n        sum_squares = _mm256_add_epi16(sum_squares, a_squared);\n        sum_squares = _mm256_add_epi16(sum_squares, b_squared);\n        \n        __m256i ab_product = _mm256_mullo_epi16(a, b);\n        sum_products = _mm256_add_epi16(sum_products, ab_product);\n    }\n    \n    int64_t result = 0;\n    for (int i = 0; i < 16; i++) {\n        result += ((int64_t*)&sum_squares)[i];\n        result -= ((int64_t*)&sum_products)[i];\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_41_AVX", "completion": "```\nint64_t squarediff_simd(const int8_t * A, const int8_t * B, size_t length) {\n    __m256i sum_squares = _mm256_setzero_si256();\n    __m256i sum_products = _mm256_setzero_si256();\n\n    for (size_t i = 0; i < length; i += 32) {\n        __m256i a = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i b = _mm256_loadu_si256((__m256i*)&B[i]);\n\n        __m256i a_squared = _mm256_mullo_epi16(a, a);\n        __m256i b_squared = _mm256_mullo_epi16(b, b);\n        sum_squares = _mm256_add_epi16(sum_squares, _mm256_add_epi16(a_squared, b_squared));\n\n        __m256i ab = _mm256_mullo_epi16(a, b);\n        sum_products = _mm256_add_epi16(sum_products, ab);\n    }\n\n    int64_t result = 0;\n    for (int i = 0; i < 16; i++) {\n        result += ((int16_t*)&sum_squares)[i];\n        result -= ((int16_t*)&sum_products)[i];\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_41_AVX", "completion": "```\nint64_t squarediff_simd(const int8_t * A, const int8_t * B, size_t length) {\n    __m256i sum_squares = _mm256_setzero_si256();\n    __m256i sum_products = _mm256_setzero_si256();\n    \n    for (size_t i = 0; i < length; i += 32) {\n        __m256i a = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i b = _mm256_loadu_si256((__m256i*)&B[i]);\n        \n        __m256i a_squared = _mm256_mullo_epi16(a, a);\n        __m256i b_squared = _mm256_mullo_epi16(b, b);\n        \n        sum_squares = _mm256_add_epi16(sum_squares, a_squared);\n        sum_squares = _mm256_add_epi16(sum_squares, b_squared);\n        \n        __m256i ab_product = _mm256_mullo_epi16(a, b);\n        sum_products = _mm256_add_epi16(sum_products, ab_product);\n    }\n    \n    __m256i diff = _mm256_sub_epi16(sum_squares, sum_products);\n    \n    int64_t result = 0;\n    for (int i = 0; i < 16; i++) {\n        result += ((int64_t*)&diff)[i];\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_41_AVX", "completion": "```\nint64_t squarediff_simd(const int8_t * A, const int8_t * B, size_t length) {\n    __m256i sum_squares = _mm256_setzero_si256();\n    __m256i sum_products = _mm256_setzero_si256();\n\n    for (size_t i = 0; i < length; i += 32) {\n        __m256i a = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i b = _mm256_loadu_si256((__m256i*)&B[i]);\n\n        __m256i a_squared = _mm256_mullo_epi16(a, a);\n        __m256i b_squared = _mm256_mullo_epi16(b, b);\n        sum_squares = _mm256_add_epi16(sum_squares, _mm256_hadd_epi16(a_squared, b_squared));\n\n        __m256i ab = _mm256_mullo_epi16(a, b);\n        sum_products = _mm256_add_epi16(sum_products, _mm256_hadd_epi16(ab, _mm256_setzero_si256()));\n    }\n\n    __m128i sum_squares_low = _mm256_extracti128_si256(sum_squares, 0);\n    __m128i sum_squares_high = _mm256_extracti128_si256(sum_squares, 1);\n    __m128i sum_products_low = _mm256_extracti128_si256(sum_products, 0);\n    __m128i sum_products_high = _mm256_extracti128_si256(sum_products, 1);\n\n    __m128i sum_squares_final = _mm_add_epi16(sum_squares_low, sum_squares_high);\n    __m128i sum_products_final = _mm_add_epi16(sum_products_low, sum_products_high);\n\n    int64_t result = 0;\n    for (int i = 0; i < 8; i++) {\n        result += _mm_extract_epi16(sum_squares_final, i) - _mm_extract_epi16(sum_products_final, i);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_41_AVX", "completion": "```\nint64_t squarediff_simd(const int8_t * A, const int8_t * B, size_t length) {\n    __m256i sum_squares = _mm256_setzero_si256();\n    __m256i sum_products = _mm256_setzero_si256();\n\n    for (size_t i = 0; i < length; i += 32) {\n        __m256i a = _mm256_loadu_si256((__m256i*)(A + i));\n        __m256i b = _mm256_loadu_si256((__m256i*)(B + i));\n\n        __m256i a_squared = _mm256_mullo_epi16(a, a);\n        __m256i b_squared = _mm256_mullo_epi16(b, b);\n\n        sum_squares = _mm256_add_epi16(sum_squares, _mm256_madd_epi16(a_squared, _mm256_set1_epi16(1)));\n        sum_squares = _mm256_add_epi16(sum_squares, _mm256_madd_epi16(b_squared, _mm256_set1_epi16(1)));\n\n        sum_products = _mm256_add_epi16(sum_products, _mm256_madd_epi16(a, b));\n    }\n\n    int64_t result = 0;\n    for (int i = 0; i < 16; i++) {\n        result += ((int64_t*)&sum_squares)[i];\n        result -= ((int64_t*)&sum_products)[i];\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_42_AVX", "completion": "```cpp\nvoid tensor_bit_clear_simd(const uint64_t* A, const uint64_t* B, uint64_t* C, size_t length) {\n    const size_t simd_length = length / 4 * 4;\n    \n    __m256i* A_ptr = (__m256i*)A;\n    __m256i* B_ptr = (__m256i*)B;\n    __m256i* C_ptr = (__m256i*)C;\n    \n    for (size_t i = 0; i < simd_length; i += 4) {\n        __m256i a = _mm256_loadu_si256(A_ptr);\n        __m256i b = _mm256_loadu_si256(B_ptr);\n        \n        __m256i result = _mm256_andnot_si256(b, a);\n        \n        _mm256_storeu_si256(C_ptr, result);\n        \n        A_ptr++;\n        B_ptr++;\n        C_ptr++;\n    }\n    \n    for (size_t i = simd_length; i < length; ++i) {\n        C[i] = A[i] & ~B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_42_AVX", "completion": "```c\nvoid tensor_bit_clear_simd(const uint64_t* A, const uint64_t* B, uint64_t* C, size_t length) {\n    const size_t simd_length = length / 4 * 4;\n    \n    for (size_t i = 0; i < simd_length; i += 4) {\n        __m256i a_vec = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i b_vec = _mm256_loadu_si256((__m256i*)&B[i]);\n        \n        __m256i result = _mm256_andnot_si256(b_vec, a_vec);\n        \n        _mm256_storeu_si256((__m256i*)&C[i], result);\n    }\n    \n    for (size_t i = simd_length; i < length; ++i) {\n        C[i] = A[i] & ~B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_42_AVX", "completion": "```cpp\nvoid tensor_bit_clear_simd(const uint64_t* A, const uint64_t* B, uint64_t* C, size_t length) {\n    const size_t simd_length = length / 4 * 4;\n    \n    for (size_t i = 0; i < simd_length; i += 4) {\n        __m256i a_vec = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i b_vec = _mm256_loadu_si256((__m256i*)&B[i]);\n        \n        __m256i result = _mm256_andnot_si256(b_vec, a_vec);\n        \n        _mm256_storeu_si256((__m256i*)&C[i], result);\n    }\n    \n    for (size_t i = simd_length; i < length; ++i) {\n        C[i] = A[i] & ~B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_42_AVX", "completion": "```cpp\nvoid tensor_bit_clear_simd(const uint64_t* A, const uint64_t* B, uint64_t* C, size_t length) {\n    const size_t simd_length = length / 4 * 4;\n    __m256i* A_ptr = (__m256i*)A;\n    __m256i* B_ptr = (__m256i*)B;\n    __m256i* C_ptr = (__m256i*)C;\n\n    for (size_t i = 0; i < simd_length; i += 4) {\n        __m256i a = _mm256_loadu_si256(A_ptr + i);\n        __m256i b = _mm256_loadu_si256(B_ptr + i);\n        __m256i result = _mm256_andnot_si256(b, a);\n        _mm256_storeu_si256(C_ptr + i, result);\n    }\n\n    for (size_t i = simd_length; i < length; ++i) {\n        C[i] = A[i] & ~B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_42_AVX", "completion": "```cpp\nvoid tensor_bit_clear_simd(const uint64_t* A, const uint64_t* B, uint64_t* C, size_t length) {\n    const size_t simd_length = 4;\n    const size_t num_simd_iterations = length / simd_length;\n\n    __m256i* A_ptr = (__m256i*)A;\n    __m256i* B_ptr = (__m256i*)B;\n    __m256i* C_ptr = (__m256i*)C;\n\n    for (size_t i = 0; i < num_simd_iterations; ++i) {\n        __m256i a = _mm256_loadu_si256(A_ptr);\n        __m256i b = _mm256_loadu_si256(B_ptr);\n        __m256i result = _mm256_andnot_si256(b, a);\n        _mm256_storeu_si256(C_ptr, result);\n\n        A_ptr++;\n        B_ptr++;\n        C_ptr++;\n    }\n\n    // Handle the remaining elements\n    for (size_t i = num_simd_iterations * simd_length; i < length; ++i) {\n        C[i] = A[i] & ~B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_43_AVX", "completion": "```cpp\nvoid tensor_three_valued_logic_simd(const int8_t* A, const int8_t* B, int8_t* C, size_t length) {\n    for (size_t i = 0; i < length; i += 32) {\n        __m256i a = _mm256_loadu_si256((__m256i*)(A + i));\n        __m256i b = _mm256_loadu_si256((__m256i*)(B + i));\n\n        __m256i both_positive_mask = _mm256_and_si256(_mm256_cmpgt_epi8(a, _mm256_set1_epi8(0)), _mm256_cmpgt_epi8(b, _mm256_set1_epi8(0)));\n        __m256i both_negative_mask = _mm256_and_si256(_mm256_cmpgt_epi8(_mm256_set1_epi8(0), a), _mm256_cmpgt_epi8(_mm256_set1_epi8(0), b));\n\n        __m256i result = _mm256_blendv_epi8(_mm256_set1_epi8(0), _mm256_set1_epi8(1), both_positive_mask);\n        result = _mm256_blendv_epi8(result, _mm256_set1_epi8(-1), both_negative_mask);\n\n        _mm256_storeu_si256((__m256i*)(C + i), result);\n    }\n}\n```"}
{"task_id": "SimdBench_43_AVX", "completion": "```cpp\nvoid tensor_three_valued_logic_simd(const int8_t* A, const int8_t* B, int8_t* C, size_t length) {\n    for (size_t i = 0; i < length; i += 32) {\n        __m256i a = _mm256_loadu_si256((__m256i*)(A + i));\n        __m256i b = _mm256_loadu_si256((__m256i*)(B + i));\n\n        __m256i both_positive_mask = _mm256_and_si256(_mm256_cmpgt_epi8(a, _mm256_set1_epi8(0)), _mm256_cmpgt_epi8(b, _mm256_set1_epi8(0)));\n        __m256i both_negative_mask = _mm256_and_si256(_mm256_cmpgt_epi8(_mm256_set1_epi8(0), a), _mm256_cmpgt_epi8(_mm256_set1_epi8(0), b));\n\n        __m256i result = _mm256_blendv_epi8(_mm256_set1_epi8(0), _mm256_set1_epi8(1), both_positive_mask);\n        result = _mm256_blendv_epi8(result, _mm256_set1_epi8(-1), both_negative_mask);\n\n        _mm256_storeu_si256((__m256i*)(C + i), result);\n    }\n}\n```"}
{"task_id": "SimdBench_43_AVX", "completion": "```cpp\nvoid tensor_three_valued_logic_simd(const int8_t* A, const int8_t* B, int8_t* C, size_t length) {\n    const int8_t zero = 0;\n    const int8_t one = 1;\n    const int8_t minus_one = -1;\n\n    for (size_t i = 0; i < length; i += 32) {\n        __m256i a = _mm256_loadu_si256((__m256i*)(A + i));\n        __m256i b = _mm256_loadu_si256((__m256i*)(B + i));\n\n        __m256i both_positive_mask = _mm256_and_si256(_mm256_cmpgt_epi8(a, zero), _mm256_cmpgt_epi8(b, zero));\n        __m256i both_negative_mask = _mm256_and_si256(_mm256_cmpgt_epi8(zero, a), _mm256_cmpgt_epi8(zero, b));\n\n        __m256i result = _mm256_blendv_epi8(_mm256_set1_epi8(0), _mm256_set1_epi8(1), both_positive_mask);\n        result = _mm256_blendv_epi8(result, _mm256_set1_epi8(-1), both_negative_mask);\n\n        _mm256_storeu_si256((__m256i*)(C + i), result);\n    }\n}\n```"}
{"task_id": "SimdBench_43_AVX", "completion": "```cpp\nvoid tensor_three_valued_logic_simd(const int8_t* A, const int8_t* B, int8_t* C, size_t length) {\n    const size_t simd_length = length / 32;\n    __m256i zero = _mm256_set1_epi8(0);\n    __m256i one = _mm256_set1_epi8(1);\n    __m256i minus_one = _mm256_set1_epi8(-1);\n\n    for (size_t i = 0; i < simd_length; ++i) {\n        __m256i a = _mm256_loadu_si256((__m256i*)(A + 32*i));\n        __m256i b = _mm256_loadu_si256((__m256i*)(B + 32*i));\n\n        __m256i a_pos = _mm256_cmpgt_epi8(a, zero);\n        __m256i b_pos = _mm256_cmpgt_epi8(b, zero);\n        __m256i a_neg = _mm256_cmpgt_epi8(zero, a);\n        __m256i b_neg = _mm256_cmpgt_epi8(zero, b);\n\n        __m256i both_pos = _mm256_and_si256(a_pos, b_pos);\n        __m256i both_neg = _mm256_and_si256(a_neg, b_neg);\n\n        __m256i result = _mm256_blendv_epi8(zero, one, both_pos);\n        result = _mm256_blendv_epi8(result, minus_one, both_neg);\n\n        _mm256_storeu_si256((__m256i*)(C + 32*i), result);\n    }\n\n    for (size_t i = simd_length * 32; i < length; ++i) {\n        if (A[i] > 0 && B[i] > 0) {\n            C[i] = 1;\n        } else if (A[i] < 0 && B[i] < 0) {\n            C[i] = -1;\n        } else {\n            C[i] = 0;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_43_AVX", "completion": "```cpp\nvoid tensor_three_valued_logic_simd(const int8_t* A, const int8_t* B, int8_t* C, size_t length) {\n    const __m256i zero = _mm256_set1_epi8(0);\n    const __m256i one = _mm256_set1_epi8(1);\n    const __m256i minus_one = _mm256_set1_epi8(-1);\n\n    for (size_t i = 0; i < length; i += 32) {\n        __m256i a = _mm256_loadu_si256((__m256i*)(A + i));\n        __m256i b = _mm256_loadu_si256((__m256i*)(B + i));\n\n        __m256i both_positive = _mm256_and_si256(_mm256_cmpgt_epi8(a, zero), _mm256_cmpgt_epi8(b, zero));\n        __m256i both_negative = _mm256_and_si256(_mm256_cmpgt_epi8(zero, a), _mm256_cmpgt_epi8(zero, b));\n\n        __m256i result = _mm256_blendv_epi8(zero, one, both_positive);\n        result = _mm256_blendv_epi8(result, minus_one, both_negative);\n\n        _mm256_storeu_si256((__m256i*)(C + i), result);\n    }\n}\n```"}
{"task_id": "SimdBench_44_AVX", "completion": "```cpp\nvoid tensor_bit_op_simd(const uint16_t* A, const uint16_t* B, uint16_t* C, size_t length) {\n    const size_t midpoint = length / 2;\n    const size_t simd_length = length / 16 * 16;\n\n    __m256i* A_ptr = (__m256i*)A;\n    __m256i* B_ptr = (__m256i*)B;\n    __m256i* C_ptr = (__m256i*)C;\n\n    for (size_t i = 0; i < simd_length; i += 2) {\n        __m256i a_val = _mm256_loadu_si256(A_ptr);\n        __m256i b_val = _mm256_loadu_si256(B_ptr);\n\n        __m256i xor_result = _mm256_xor_si256(a_val, b_val);\n        __m256i and_result = _mm256_and_si256(a_val, b_val);\n\n        __m256i mask = _mm256_set_epi16(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n        mask = _mm256_insert_epi16(mask, 0xFFFF, 7);\n\n        __m256i result = _mm256_blendv_epi8(and_result, xor_result, mask);\n\n        _mm256_storeu_si256(C_ptr, result);\n\n        A_ptr++;\n        B_ptr++;\n        C_ptr++;\n    }\n\n    for (size_t i = simd_length; i < midpoint; ++i) {\n        C[i] = A[i] ^ B[i];\n    }\n\n    C[midpoint] = A[midpoint];\n}\n```  "}
{"task_id": "SimdBench_44_AVX", "completion": "```cpp\nvoid tensor_bit_op_simd(const uint16_t* A, const uint16_t* B, uint16_t* C, size_t length) {\n    const size_t midpoint = length / 2;\n    const size_t simd_length = length / 16 * 16;\n\n    __m256i* A_ptr = (__m256i*)A;\n    __m256i* B_ptr = (__m256i*)B;\n    __m256i* C_ptr = (__m256i*)C;\n\n    for (size_t i = 0; i < simd_length; i += 2) {\n        __m256i a_val = _mm256_loadu_si256(A_ptr);\n        __m256i b_val = _mm256_loadu_si256(B_ptr);\n\n        __m256i xor_result = _mm256_xor_si256(a_val, b_val);\n        __m256i and_result = _mm256_and_si256(a_val, b_val);\n\n        __m256i mask = _mm256_set_epi16(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n        mask = _mm256_insert_epi16(mask, 0xFFFF, 7);\n\n        __m256i result = _mm256_blendv_epi8(and_result, xor_result, mask);\n\n        _mm256_storeu_si256(C_ptr, result);\n\n        A_ptr++;\n        B_ptr++;\n        C_ptr++;\n    }\n\n    for (size_t i = simd_length; i < length; i++) {\n        C[i] = (i < midpoint) ? (A[i] ^ B[i]) : A[i];\n    }\n}\n```"}
{"task_id": "SimdBench_44_AVX", "completion": "```cpp\nvoid tensor_bit_op_simd(const uint16_t* A, const uint16_t* B, uint16_t* C, size_t length) {\n    const size_t midpoint = length / 2;\n    const size_t simd_length = length / 16 * 16;\n\n    __m256i* ptrA = (__m256i*)A;\n    __m256i* ptrB = (__m256i*)B;\n    __m256i* ptrC = (__m256i*)C;\n\n    for (size_t i = 0; i < simd_length; i += 16) {\n        __m256i a = _mm256_loadu_si256(ptrA);\n        __m256i b = _mm256_loadu_si256(ptrB);\n\n        __m256i mask = _mm256_set_epi16(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0xFFFF, 0xFFFF, 0xFFFF);\n        __m256i a_mid = _mm256_and_si256(a, mask);\n        __m256i b_mid = _mm256_andnot_si256(mask, b);\n        __m256i c_mid = _mm256_or_si256(a_mid, b_mid);\n\n        __m256i a_before = _mm256_andnot_si256(mask, a);\n        __m256i b_before = _mm256_and_si256(b, mask);\n        __m256i c_before = _mm256_xor_si256(a_before, b_before);\n\n        _mm256_storeu_si256(ptrC, c_before);\n        _mm256_storeu_si256(ptrC + 1, c_mid);\n\n        ptrA++;\n        ptrB++;\n        ptrC++;\n    }\n\n    for (size_t i = simd_length; i < length; ++i) {\n        C[i] = (i < midpoint) ? (A[i] ^ B[i]) : A[i];\n    }\n}\n```"}
{"task_id": "SimdBench_44_AVX", "completion": "```cpp\nvoid tensor_bit_op_simd(const uint16_t* A, const uint16_t* B, uint16_t* C, size_t length) {\n    const size_t midpoint = length / 2;\n    const size_t simd_length = length / 8;\n\n    __m256i* A_ptr = (__m256i*)A;\n    __m256i* B_ptr = (__m256i*)B;\n    __m256i* C_ptr = (__m256i*)C;\n\n    for (size_t i = 0; i < simd_length; i++) {\n        __m256i a = _mm256_loadu_si256(A_ptr + i);\n        __m256i b = _mm256_loadu_si256(B_ptr + i);\n\n        if (i == midpoint / 8) {\n            _mm256_storeu_si256(C_ptr + i, a);\n        } else if (i < midpoint / 8) {\n            _mm256_storeu_si256(C_ptr + i, _mm256_xor_si256(a, b));\n        } else {\n            _mm256_storeu_si256(C_ptr + i, _mm256_and_si256(a, b));\n        }\n    }\n\n    for (size_t i = simd_length * 8; i < length; i++) {\n        C[i] = (i == midpoint) ? A[i] : (i < midpoint) ? (A[i] ^ B[i]) : (A[i] & B[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_44_AVX", "completion": "```cpp\nvoid tensor_bit_op_simd(const uint16_t* A, const uint16_t* B, uint16_t* C, size_t length) {\n    const size_t midpoint = length / 2;\n    const size_t avx_length = (length / 16) * 16;\n\n    __m256i* A_ptr = (__m256i*)A;\n    __m256i* B_ptr = (__m256i*)B;\n    __m256i* C_ptr = (__m256i*)C;\n\n    for (size_t i = 0; i < avx_length; i += 8) {\n        __m256i a = _mm256_loadu_si256(A_ptr);\n        __m256i b = _mm256_loadu_si256(B_ptr);\n\n        __m256i before_midpoint = _mm256_and_si256(a, b);\n        __m256i at_midpoint = a;\n        __m256i after_midpoint = _mm256_xor_si256(a, b);\n\n        __m256i mask = _mm256_set_epi16(\n            i + 15 < midpoint, i + 14 < midpoint, i + 13 < midpoint, i + 12 < midpoint,\n            i + 11 < midpoint, i + 10 < midpoint, i + 9 < midpoint, i + 8 < midpoint,\n            i + 7 < midpoint, i + 6 < midpoint, i + 5 < midpoint, i + 4 < midpoint,\n            i + 3 < midpoint, i + 2 < midpoint, i + 1 < midpoint, i < midpoint\n        );\n\n        __m256i result = _mm256_blendv_epi8(after_midpoint, at_midpoint, mask);\n        result = _mm256_blendv_epi8(result, before_midpoint, mask);\n\n        _mm256_storeu_si256(C_ptr, result);\n\n        A_ptr++;\n        B_ptr++;\n        C_ptr++;\n    }\n\n    for (size_t i = avx_length; i < length; ++i) {\n        C[i] = (i < midpoint) ? (A[i] & B[i]) : (A[i] ^ B[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_45_AVX", "completion": "```cpp\nvoid tensor_multi_select_simd(const float* A, const float* B, const float* C, const float* D, const bool* cond1, const bool* cond2, float* out, size_t dim1, size_t dim2, size_t dim3) {\n    for (size_t i = 0; i < dim1 * dim2 * dim3; i += 8) {\n        __m256i mask1 = _mm256_loadu_si256((__m256i*)(cond1 + i));\n        __m256i mask2 = _mm256_loadu_si256((__m256i*)(cond2 + i));\n\n        __m256 a = _mm256_maskload_ps(A + i, mask1);\n        __m256 b = _mm256_maskload_ps(B + i, mask1);\n        __m256 c = _mm256_maskload_ps(C + i, _mm256_xor_si256(mask1, _mm256_set1_epi32(-1)));\n        __m256 d = _mm256_maskload_ps(D + i, _mm256_xor_si256(mask1, _mm256_set1_epi32(-1)));\n\n        __m256 result = _mm256_blendv_ps(_mm256_blendv_ps(d, c, mask2), _mm256_blendv_ps(b, a, mask2), mask1);\n\n        _mm256_storeu_ps(out + i, result);\n    }\n}\n```"}
{"task_id": "SimdBench_45_AVX", "completion": "```cpp\nvoid tensor_multi_select_simd(const float* A, const float* B, const float* C, const float* D, const bool* cond1, const bool* cond2, float* out, size_t dim1, size_t dim2, size_t dim3) {\n    for (size_t i = 0; i < dim1 * dim2 * dim3; i += 8) {\n        __m256i mask1 = _mm256_loadu_si256((__m256i*)(cond1 + i));\n        __m256i mask2 = _mm256_loadu_si256((__m256i*)(cond2 + i));\n\n        __m256 a = _mm256_maskload_ps(A + i, mask1);\n        __m256 b = _mm256_maskload_ps(B + i, mask1);\n        __m256 c = _mm256_maskload_ps(C + i, _mm256_xor_si256(mask1, _mm256_set1_epi32(-1)));\n        __m256 d = _mm256_maskload_ps(D + i, _mm256_xor_si256(mask1, _mm256_set1_epi32(-1)));\n\n        __m256 result = _mm256_blendv_ps(_mm256_blendv_ps(d, c, mask2), _mm256_blendv_ps(b, a, mask2), mask1);\n\n        _mm256_storeu_ps(out + i, result);\n    }\n}\n```"}
{"task_id": "SimdBench_45_AVX", "completion": "```cpp\nvoid tensor_multi_select_simd(const float* A, const float* B, const float* C, const float* D, const bool* cond1, const bool* cond2, float* out, size_t dim1, size_t dim2, size_t dim3) {\n    for (size_t i = 0; i < dim1 * dim2 * dim3; i += 8) {\n        __m256i mask1 = _mm256_loadu_si256((__m256i*)(cond1 + i));\n        __m256i mask2 = _mm256_loadu_si256((__m256i*)(cond2 + i));\n\n        __m256 a = _mm256_maskload_ps(A + i, mask1);\n        __m256 b = _mm256_maskload_ps(B + i, mask1);\n        __m256 c = _mm256_maskload_ps(C + i, _mm256_xor_si256(mask1, _mm256_set1_epi32(-1)));\n        __m256 d = _mm256_maskload_ps(D + i, _mm256_xor_si256(mask1, _mm256_set1_epi32(-1)));\n\n        __m256 result = _mm256_blendv_ps(_mm256_blendv_ps(d, c, mask2), _mm256_blendv_ps(b, a, mask2), mask1);\n\n        _mm256_storeu_ps(out + i, result);\n    }\n}\n```"}
{"task_id": "SimdBench_45_AVX", "completion": "```cpp\nvoid tensor_multi_select_simd(const float* A, const float* B, const float* C, const float* D, const bool* cond1, const bool* cond2, float* out, size_t dim1, size_t dim2, size_t dim3) {\n    for (size_t i = 0; i < dim1 * dim2 * dim3; i += 8) {\n        __m256i mask1 = _mm256_loadu_si256((__m256i*)(cond1 + i));\n        __m256i mask2 = _mm256_loadu_si256((__m256i*)(cond2 + i));\n\n        __m256 a = _mm256_maskload_ps(A + i, mask1);\n        __m256 b = _mm256_maskload_ps(B + i, mask1);\n        __m256 c = _mm256_maskload_ps(C + i, _mm256_xor_si256(mask1, _mm256_set1_epi32(-1)));\n        __m256 d = _mm256_maskload_ps(D + i, _mm256_xor_si256(mask1, _mm256_set1_epi32(-1)));\n\n        __m256 result = _mm256_blendv_ps(_mm256_blendv_ps(d, c, mask2), _mm256_blendv_ps(b, a, mask2), mask1);\n\n        _mm256_storeu_ps(out + i, result);\n    }\n}\n```"}
{"task_id": "SimdBench_45_AVX", "completion": "```cpp\nvoid tensor_multi_select_simd(const float* A, const float* B, const float* C, const float* D, const bool* cond1, const bool* cond2, float* out, size_t dim1, size_t dim2, size_t dim3) {\n    for (size_t i = 0; i < dim1 * dim2 * dim3; i += 8) {\n        __m256i mask1 = _mm256_loadu_si256((__m256i*)(cond1 + i));\n        __m256i mask2 = _mm256_loadu_si256((__m256i*)(cond2 + i));\n\n        __m256 a = _mm256_maskload_ps(A + i, mask1);\n        __m256 b = _mm256_maskload_ps(B + i, mask1);\n        __m256 c = _mm256_maskload_ps(C + i, _mm256_xor_si256(mask1, _mm256_set1_epi32(-1)));\n        __m256 d = _mm256_maskload_ps(D + i, _mm256_xor_si256(mask1, _mm256_set1_epi32(-1)));\n\n        __m256 result = _mm256_blendv_ps(_mm256_blendv_ps(d, c, mask2), _mm256_blendv_ps(b, a, mask2), mask1);\n\n        _mm256_storeu_ps(out + i, result);\n    }\n}\n```"}
{"task_id": "SimdBench_46_AVX", "completion": "```c\nvoid tensor_bit_count_simd(const uint32_t* A, uint8_t* out, size_t dim1, size_t dim2, size_t dim3) {\n    for (size_t i = 0; i < dim1 * dim2 * dim3; ++i) {\n        __m256i v = _mm256_set1_epi32(A[i]);\n        __m256i popcnt = _mm256_popcnt_epi32(v);\n        uint32_t count = _mm256_extract_epi32(popcnt, 0) + _mm256_extract_epi32(popcnt, 1) +\n                         _mm256_extract_epi32(popcnt, 2) + _mm256_extract_epi32(popcnt, 3);\n        out[i] = count;\n    }\n}\n```  "}
{"task_id": "SimdBench_46_AVX", "completion": "```cpp\nvoid tensor_bit_count_simd(const uint32_t* A, uint8_t* out, size_t dim1, size_t dim2, size_t dim3) {\n    for (size_t i = 0; i < dim1 * dim2 * dim3; ++i) {\n        __m256i v = _mm256_set1_epi32(A[i]);\n        __m256i popcnt = _mm256_popcnt_epi32(v);\n        uint32_t count = _mm256_extract_epi32(popcnt, 0) + _mm256_extract_epi32(popcnt, 1) +\n                         _mm256_extract_epi32(popcnt, 2) + _mm256_extract_epi32(popcnt, 3);\n        out[i] = count;\n    }\n}\n```  "}
{"task_id": "SimdBench_46_AVX", "completion": "```c\nvoid tensor_bit_count_simd(const uint32_t* A, uint8_t* out, size_t dim1, size_t dim2, size_t dim3) {\n    for (size_t i = 0; i < dim1 * dim2 * dim3; ++i) {\n        __m256i v = _mm256_set1_epi32(A[i]);\n        __m256i popcnt = _mm256_popcnt_epi32(v);\n        uint32_t count = _mm256_extract_epi32(popcnt, 0) + _mm256_extract_epi32(popcnt, 1) +\n                         _mm256_extract_epi32(popcnt, 2) + _mm256_extract_epi32(popcnt, 3);\n        out[i] = count;\n    }\n}\n```  "}
{"task_id": "SimdBench_46_AVX", "completion": "```cpp\nvoid tensor_bit_count_simd(const uint32_t* A, uint8_t* out, size_t dim1, size_t dim2, size_t dim3) {\n    for (size_t i = 0; i < dim1 * dim2 * dim3; ++i) {\n        __m256i v = _mm256_set1_epi32(A[i]);\n        v = _mm256_popcnt_epi32(v);\n        uint32_t count = _mm256_extract_epi32(v, 0) + _mm256_extract_epi32(v, 1) + _mm256_extract_epi32(v, 2) + _mm256_extract_epi32(v, 3);\n        out[i] = count;\n    }\n}\n```"}
{"task_id": "SimdBench_46_AVX", "completion": "```cpp\nvoid tensor_bit_count_simd(const uint32_t* A, uint8_t* out, size_t dim1, size_t dim2, size_t dim3) {\n    for (size_t i = 0; i < dim1 * dim2 * dim3; ++i) {\n        __m256i v = _mm256_set1_epi32(A[i]);\n        __m256i popcnt = _mm256_popcnt_epi32(v);\n        uint32_t count = _mm256_extract_epi32(popcnt, 0) + _mm256_extract_epi32(popcnt, 1) +\n                         _mm256_extract_epi32(popcnt, 2) + _mm256_extract_epi32(popcnt, 3);\n        out[i] = count;\n    }\n}\n```  "}
{"task_id": "SimdBench_47_AVX", "completion": "```cpp\nvoid matrix_conditional_abs_simd(const int* A, int* B, size_t rows, size_t cols) {\n    const int step = 8;\n    const __m256i divisor = _mm256_set1_epi32(3);\n\n    for (size_t i = 0; i < rows * cols; i += step) {\n        __m256i a = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i mask = _mm256_cmpeq_epi32(_mm256_setzero_si256(), _mm256_and_si256(a, divisor));\n        __m256i abs_a = _mm256_abs_epi32(a);\n        __m256i result = _mm256_blendv_epi8(a, abs_a, mask);\n        _mm256_storeu_si256((__m256i*)&B[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_47_AVX", "completion": "```cpp\nvoid matrix_conditional_abs_simd(const int* A, int* B, size_t rows, size_t cols) {\n    const __m256i divisors = _mm256_set1_epi32(3);\n    const __m256i mask_abs = _mm256_set1_epi32(0xFFFFFFFF);\n    const __m256i mask_identity = _mm256_set1_epi32(0);\n\n    for (size_t i = 0; i < rows * cols; i += 8) {\n        __m256i a_values = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i divisible_mask = _mm256_cmpeq_epi32(_mm256_and_si256(a_values, divisors), mask_identity);\n        \n        __m256i abs_values = _mm256_and_si256(a_values, mask_abs);\n        __m256i result = _mm256_blendv_epi8(a_values, abs_values, divisible_mask);\n\n        _mm256_storeu_si256((__m256i*)&B[i], result);\n    }\n}\n```  "}
{"task_id": "SimdBench_47_AVX", "completion": "```c\nvoid matrix_conditional_abs_simd(const int* A, int* B, size_t rows, size_t cols) {\n    const int step = 8;\n    const __m256i divisor = _mm256_set1_epi32(3);\n    for (size_t i = 0; i < rows * cols; i += step) {\n        __m256i a = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i mask = _mm256_cmpeq_epi32(_mm256_setzero_si256(), _mm256_and_si256(a, divisor));\n        __m256i abs_a = _mm256_abs_epi32(a);\n        __m256i result = _mm256_blendv_epi8(a, abs_a, mask);\n        _mm256_storeu_si256((__m256i*)&B[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_47_AVX", "completion": "```cpp\nvoid matrix_conditional_abs_simd(const int* A, int* B, size_t rows, size_t cols) {\n    const int step = 8;\n    const __m256i divisor = _mm256_set1_epi32(3);\n    for (size_t i = 0; i < rows * cols; i += step) {\n        __m256i a = _mm256_loadu_si256((__m256i*)(A + i));\n        __m256i mask = _mm256_cmpeq_epi32(_mm256_setzero_si256(), _mm256_and_si256(a, divisor));\n        __m256i abs_a = _mm256_abs_epi32(a);\n        __m256i result = _mm256_blendv_epi8(a, abs_a, mask);\n        _mm256_storeu_si256((__m256i*)(B + i), result);\n    }\n}\n```"}
{"task_id": "SimdBench_47_AVX", "completion": "```cpp\nvoid matrix_conditional_abs_simd(const int* A, int* B, size_t rows, size_t cols) {\n    const int step = 8;\n    const __m256i divisor = _mm256_set1_epi32(3);\n    for (size_t i = 0; i < rows * cols; i += step) {\n        __m256i a = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i mask = _mm256_cmpeq_epi32(_mm256_setzero_si256(), _mm256_and_si256(a, divisor));\n        __m256i abs_a = _mm256_abs_epi32(a);\n        __m256i result = _mm256_blendv_epi8(a, abs_a, mask);\n        _mm256_storeu_si256((__m256i*)&B[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_48_AVX", "completion": "```c\nvoid matrix_conditional_bit_rotate_simd(const uint32_t* src, uint32_t* dst, uint8_t rotate_bits, size_t length){\n    __m256i rotate_mask = _mm256_set1_epi32(0x0F0F0F0F); // Mask to check low 4 bits\n    __m256i rotate_bits_vec = _mm256_set1_epi32(rotate_bits); // Vector of rotate_bits\n    __m256i negation_mask = _mm256_set1_epi32(0xFFFFFFFF); // Mask for bitwise negation\n\n    for (size_t i = 0; i < length; i += 8) {\n        __m256i src_vec = _mm256_loadu_si256((__m256i*)(src + i));\n        __m256i low_4_bits = _mm256_and_si256(src_vec, rotate_mask);\n        __m256i condition = _mm256_cmpeq_epi32(low_4_bits, rotate_mask);\n        \n        __m256i rotated = _mm256_sllv_epi32(src_vec, rotate_bits_vec);\n        __m256i negated = _mm256_xor_si256(src_vec, negation_mask);\n        \n        __m256i result = _mm256_blendv_epi8(negated, rotated, condition);\n        \n        _mm256_storeu_si256((__m256i*)(dst + i), result);\n    }\n}\n```"}
{"task_id": "SimdBench_48_AVX", "completion": "```c\nvoid matrix_conditional_bit_rotate_simd(const uint32_t* src, uint32_t* dst, uint8_t rotate_bits, size_t length){\n    __m256i rotate = _mm256_set1_epi32(rotate_bits);\n    __m256i all_ones = _mm256_set1_epi32(0x0F0F0F0F);\n    __m256i neg_mask = _mm256_set1_epi32(0xFFFFFFFF);\n    \n    for (size_t i = 0; i < length; i += 8) {\n        __m256i src_vec = _mm256_loadu_si256((__m256i*)(src + i));\n        __m256i low_4_bits = _mm256_and_si256(src_vec, all_ones);\n        __m256i cmp_result = _mm256_cmpeq_epi32(low_4_bits, all_ones);\n        \n        __m256i rotated = _mm256_srlv_epi32(src_vec, rotate);\n        __m256i negated = _mm256_xor_si256(src_vec, neg_mask);\n        \n        __m256i result = _mm256_blendv_epi8(negated, rotated, cmp_result);\n        \n        _mm256_storeu_si256((__m256i*)(dst + i), result);\n    }\n}\n```"}
{"task_id": "SimdBench_48_AVX", "completion": "```c\nvoid matrix_conditional_bit_rotate_simd(const uint32_t* src, uint32_t* dst, uint8_t rotate_bits, size_t length){\n    const __m256i rotate_mask = _mm256_set1_epi32(0x0F0F0F0F);\n    const __m256i rotate_bits_vec = _mm256_set1_epi32(rotate_bits);\n    const __m256i negation_mask = _mm256_set1_epi32(0xFFFFFFFF);\n\n    for (size_t i = 0; i < length; i += 8) {\n        __m256i src_vec = _mm256_loadu_si256((__m256i*)(src + i));\n        __m256i low_4_bits = _mm256_and_si256(src_vec, rotate_mask);\n        __m256i condition = _mm256_cmpeq_epi32(low_4_bits, rotate_mask);\n\n        __m256i rotated = _mm256_srlv_epi32(src_vec, rotate_bits_vec);\n        __m256i negated = _mm256_xor_si256(src_vec, negation_mask);\n\n        __m256i result = _mm256_blendv_epi8(negated, rotated, condition);\n\n        _mm256_storeu_si256((__m256i*)(dst + i), result);\n    }\n}\n```"}
{"task_id": "SimdBench_48_AVX", "completion": "```c\nvoid matrix_conditional_bit_rotate_simd(const uint32_t* src, uint32_t* dst, uint8_t rotate_bits, size_t length){\n    const __m256i rotate_mask = _mm256_set1_epi32(0x0000000F);\n    const __m256i rotate_bits_vec = _mm256_set1_epi32(rotate_bits);\n    const __m256i negation_mask = _mm256_set1_epi32(0xFFFFFFFF);\n\n    for (size_t i = 0; i < length; i += 8) {\n        __m256i src_vec = _mm256_loadu_si256((__m256i*)(src + i));\n        __m256i low_4_bits = _mm256_and_si256(src_vec, rotate_mask);\n        __m256i condition_mask = _mm256_cmpeq_epi32(low_4_bits, rotate_mask);\n\n        __m256i rotated_vec = _mm256_srlv_epi32(src_vec, rotate_bits_vec);\n        __m256i negated_vec = _mm256_xor_si256(src_vec, negation_mask);\n\n        __m256i result_vec = _mm256_blendv_epi8(negated_vec, rotated_vec, condition_mask);\n\n        _mm256_storeu_si256((__m256i*)(dst + i), result_vec);\n    }\n}\n```"}
{"task_id": "SimdBench_48_AVX", "completion": "```c\nvoid matrix_conditional_bit_rotate_simd(const uint32_t* src, uint32_t* dst, uint8_t rotate_bits, size_t length){\n    __m256i rotate = _mm256_set1_epi32(rotate_bits);\n    __m256i mask = _mm256_set1_epi32(0x0F0F0F0F);\n    __m256i neg_mask = _mm256_set1_epi32(0xFFFFFFFF);\n\n    for (size_t i = 0; i < length; i += 8) {\n        __m256i src_vec = _mm256_loadu_si256((__m256i*)(src + i));\n        __m256i low4 = _mm256_and_si256(src_vec, mask);\n        __m256i cmp = _mm256_cmpeq_epi32(low4, mask);\n\n        __m256i rotated = _mm256_srlv_epi32(src_vec, rotate);\n        __m256i negated = _mm256_xor_si256(src_vec, neg_mask);\n\n        __m256i result = _mm256_blendv_epi8(negated, rotated, cmp);\n\n        _mm256_storeu_si256((__m256i*)(dst + i), result);\n    }\n}\n```"}
{"task_id": "SimdBench_49_AVX", "completion": "```cpp\nvoid tensor_ternary_compare_simd(const float* A, const float* B, int8_t* out, float epsilon, size_t length) {\n    const __m256 eps = _mm256_set1_ps(epsilon);\n    const __m256i zero = _mm256_set1_epi8(0);\n    const __m256i one = _mm256_set1_epi8(1);\n    const __m256i minus_one = _mm256_set1_epi8(-1);\n\n    for (size_t i = 0; i < length; i += 8) {\n        __m256 a = _mm256_loadu_ps(&A[i]);\n        __m256 b = _mm256_loadu_ps(&B[i]);\n\n        __m256 diff = _mm256_sub_ps(a, b);\n        __m256 abs_diff = _mm256_andnot_ps(_mm256_set1_ps(-0.0f), diff);\n        __m256 mask_gt = _mm256_cmp_ps(abs_diff, eps, _CMP_GT_OQ);\n        __m256 mask_lt = _mm256_cmp_ps(abs_diff, eps, _CMP_LT_OQ);\n\n        __m256i result = _mm256_blendv_epi8(zero, one, _mm256_castps_si256(mask_gt));\n        result = _mm256_blendv_epi8(result, minus_one, _mm256_castps_si256(mask_lt));\n\n        _mm256_storeu_si256((__m256i*)&out[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_49_AVX", "completion": "```\nvoid tensor_ternary_compare_simd(const float* A, const float* B, int8_t* out, float epsilon, size_t length) {\n    const __m256 eps = _mm256_set1_ps(epsilon);\n    const __m256i zero = _mm256_set1_epi8(0);\n    const __m256i one = _mm256_set1_epi8(1);\n    const __m256i minus_one = _mm256_set1_epi8(-1);\n\n    for (size_t i = 0; i < length; i += 8) {\n        __m256 a = _mm256_loadu_ps(&A[i]);\n        __m256 b = _mm256_loadu_ps(&B[i]);\n\n        __m256 diff = _mm256_sub_ps(a, b);\n        __m256 abs_diff = _mm256_andnot_ps(_mm256_set1_ps(-0.0f), diff);\n        __m256 mask_gt = _mm256_cmp_ps(abs_diff, eps, _CMP_GT_OQ);\n        __m256 mask_lt = _mm256_cmp_ps(abs_diff, eps, _CMP_LT_OQ);\n\n        __m256i result = _mm256_blendv_epi8(zero, one, _mm256_castps_si256(mask_gt));\n        result = _mm256_blendv_epi8(result, minus_one, _mm256_castps_si256(mask_lt));\n\n        _mm256_storeu_si256((__m256i*)&out[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_49_AVX", "completion": "```cpp\nvoid tensor_ternary_compare_simd(const float* A, const float* B, int8_t* out, float epsilon, size_t length) {\n    const __m256 eps = _mm256_set1_ps(epsilon);\n    const __m256i zero = _mm256_set1_epi8(0);\n    const __m256i one = _mm256_set1_epi8(1);\n    const __m256i minus_one = _mm256_set1_epi8(-1);\n\n    for (size_t i = 0; i < length; i += 8) {\n        __m256 a = _mm256_loadu_ps(&A[i]);\n        __m256 b = _mm256_loadu_ps(&B[i]);\n\n        __m256 diff = _mm256_sub_ps(a, b);\n        __m256 abs_diff = _mm256_and_ps(_mm256_cmp_ps(diff, _mm256_setzero_ps(), _CMP_GT_OQ), _mm256_sub_ps(diff, _mm256_setzero_ps()));\n\n        __m256 mask_gt_eps = _mm256_cmp_ps(abs_diff, eps, _CMP_GT_OQ);\n        __m256 mask_lt_minus_eps = _mm256_cmp_ps(abs_diff, _mm256_mul_ps(eps, _mm256_set1_ps(-1)), _CMP_LT_OQ);\n\n        __m256i result = _mm256_blendv_epi8(zero, one, _mm256_castps_si256(mask_gt_eps));\n        result = _mm256_blendv_epi8(result, minus_one, _mm256_castps_si256(mask_lt_minus_eps));\n\n        _mm256_storeu_si256((__m256i*)&out[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_49_AVX", "completion": "```cpp\nvoid tensor_ternary_compare_simd(const float* A, const float* B, int8_t* out, float epsilon, size_t length) {\n    const __m256 eps = _mm256_set1_ps(epsilon);\n    const __m256i zero = _mm256_set1_epi8(0);\n    const __m256i one = _mm256_set1_epi8(1);\n    const __m256i minus_one = _mm256_set1_epi8(-1);\n\n    for (size_t i = 0; i < length; i += 8) {\n        __m256 a = _mm256_loadu_ps(&A[i]);\n        __m256 b = _mm256_loadu_ps(&B[i]);\n\n        __m256 diff = _mm256_sub_ps(a, b);\n        __m256 abs_diff = _mm256_andnot_ps(_mm256_set1_ps(-0.0f), diff);\n        __m256 mask_gt = _mm256_cmp_ps(abs_diff, eps, _CMP_GT_OQ);\n        __m256 mask_lt = _mm256_cmp_ps(abs_diff, eps, _CMP_LT_OQ);\n\n        __m256i result = _mm256_blendv_epi8(zero, one, _mm256_castps_si256(mask_gt));\n        result = _mm256_blendv_epi8(result, minus_one, _mm256_castps_si256(mask_lt));\n\n        _mm256_storeu_si256((__m256i*)&out[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_49_AVX", "completion": "```cpp\nvoid tensor_ternary_compare_simd(const float* A, const float* B, int8_t* out, float epsilon, size_t length) {\n    const __m256 eps = _mm256_set1_ps(epsilon);\n    const __m256i zero = _mm256_set1_epi8(0);\n    const __m256i one = _mm256_set1_epi8(1);\n    const __m256i minus_one = _mm256_set1_epi8(-1);\n\n    for (size_t i = 0; i < length; i += 8) {\n        __m256 a = _mm256_loadu_ps(&A[i]);\n        __m256 b = _mm256_loadu_ps(&B[i]);\n        __m256 diff = _mm256_sub_ps(a, b);\n        __m256 abs_diff = _mm256_andnot_ps(_mm256_set1_ps(-0.0f), diff);\n        __m256 mask_gt = _mm256_cmp_ps(abs_diff, eps, _CMP_GT_OQ);\n        __m256 mask_lt = _mm256_cmp_ps(abs_diff, eps, _CMP_LT_OQ);\n        __m256i result = _mm256_blendv_epi8(zero, one, _mm256_castps_si256(mask_gt));\n        result = _mm256_blendv_epi8(result, minus_one, _mm256_castps_si256(mask_lt));\n        _mm256_storeu_si256((__m256i*)&out[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_50_AVX", "completion": "```\nvoid float_to_int_saturate_simd(const float* A, int32_t* B, size_t size) {\n    const __m256i int32_max = _mm256_set1_epi32(INT32_MAX);\n    const __m256i int32_min = _mm256_set1_epi32(INT32_MIN);\n\n    for (size_t i = 0; i < size; i += 8) {\n        __m256 float_values = _mm256_loadu_ps(&A[i]);\n        __m256i int_values = _mm256_cvtps_epi32(float_values);\n\n        __m256i greater_than_max = _mm256_cmpgt_epi32(int_values, int32_max);\n        __m256i less_than_min = _mm256_cmpgt_epi32(int32_min, int_values);\n\n        __m256i saturated_values = _mm256_blendv_epi8(int_values, int32_max, greater_than_max);\n        saturated_values = _mm256_blendv_epi8(saturated_values, int32_min, less_than_min);\n\n        _mm256_storeu_si256((__m256i*)&B[i], saturated_values);\n    }\n}\n```"}
{"task_id": "SimdBench_50_AVX", "completion": "```cpp\nvoid float_to_int_saturate_simd(const float* A, int32_t* B, size_t size) {\n    const __m256i int32_max = _mm256_set1_epi32(INT32_MAX);\n    const __m256i int32_min = _mm256_set1_epi32(INT32_MIN);\n\n    for (size_t i = 0; i < size; i += 8) {\n        __m256 float_values = _mm256_loadu_ps(&A[i]);\n        __m256i int_values = _mm256_cvtps_epi32(float_values);\n\n        __m256i greater_than_max = _mm256_cmpgt_epi32(int_values, int32_max);\n        __m256i less_than_min = _mm256_cmpgt_epi32(int32_min, int_values);\n\n        __m256i saturated_values = _mm256_blendv_epi8(int_values, int32_max, greater_than_max);\n        saturated_values = _mm256_blendv_epi8(saturated_values, int32_min, less_than_min);\n\n        _mm256_storeu_si256((__m256i*)&B[i], saturated_values);\n    }\n}\n```"}
{"task_id": "SimdBench_50_AVX", "completion": "```\nvoid float_to_int_saturate_simd(const float* A, int32_t* B, size_t size) {\n    const __m256i int32_max = _mm256_set1_epi32(INT32_MAX);\n    const __m256i int32_min = _mm256_set1_epi32(INT32_MIN);\n\n    for (size_t i = 0; i < size; i += 8) {\n        __m256 float_values = _mm256_loadu_ps(&A[i]);\n        __m256i int_values = _mm256_cvtps_epi32(float_values);\n\n        __m256i greater_than_max = _mm256_cmpgt_epi32(int_values, int32_max);\n        __m256i less_than_min = _mm256_cmpgt_epi32(int32_min, int_values);\n\n        __m256i saturated_values = _mm256_blendv_epi8(int_values, int32_max, greater_than_max);\n        saturated_values = _mm256_blendv_epi8(saturated_values, int32_min, less_than_min);\n\n        _mm256_storeu_si256((__m256i*)&B[i], saturated_values);\n    }\n}\n```"}
{"task_id": "SimdBench_50_AVX", "completion": "```\nvoid float_to_int_saturate_simd(const float* A, int32_t* B, size_t size) {\n    const __m256i int32_max = _mm256_set1_epi32(INT32_MAX);\n    const __m256i int32_min = _mm256_set1_epi32(INT32_MIN);\n\n    for (size_t i = 0; i < size; i += 8) {\n        __m256 float_values = _mm256_loadu_ps(&A[i]);\n        __m256i int_values = _mm256_cvtps_epi32(float_values);\n\n        __m256i greater_than_max = _mm256_cmpgt_epi32(int_values, int32_max);\n        __m256i less_than_min = _mm256_cmpgt_epi32(int32_min, int_values);\n\n        __m256i max_values = _mm256_and_si256(int32_max, greater_than_max);\n        __m256i min_values = _mm256_and_si256(int32_min, less_than_min);\n\n        int_values = _mm256_blendv_epi8(int_values, max_values, greater_than_max);\n        int_values = _mm256_blendv_epi8(int_values, min_values, less_than_min);\n\n        _mm256_storeu_si256((__m256i*)&B[i], int_values);\n    }\n}\n```"}
{"task_id": "SimdBench_50_AVX", "completion": "```cpp\nvoid float_to_int_saturate_simd(const float* A, int32_t* B, size_t size) {\n    const __m256i int32_min = _mm256_set1_epi32(INT32_MIN);\n    const __m256i int32_max = _mm256_set1_epi32(INT32_MAX);\n\n    for (size_t i = 0; i < size; i += 8) {\n        __m256 float_values = _mm256_loadu_ps(&A[i]);\n        __m256i int_values = _mm256_cvtps_epi32(float_values);\n        int_values = _mm256_max_epi32(int_values, int32_min);\n        int_values = _mm256_min_epi32(int_values, int32_max);\n        _mm256_storeu_si256((__m256i*)&B[i], int_values);\n    }\n}\n```"}
{"task_id": "SimdBench_51_AVX", "completion": "```c\nvoid int_to_float_scaled_simd(const int32_t* A, int8_t scale, float* B, size_t size) {\n    __m256i scale_vec = _mm256_set1_epi32((int)scale);\n    __m256 scale_float = _mm256_cvtepi32_ps(scale_vec);\n\n    for (size_t i = 0; i < size; i += 8) {\n        __m256i input = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i input_shifted = _mm256_slli_epi32(input, 24);\n        __m256i input_scaled = _mm256_mullo_epi32(input_shifted, scale_vec);\n        __m256 result = _mm256_cvtepi32_ps(input_scaled);\n        _mm256_storeu_ps(&B[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_51_AVX", "completion": "```c\nvoid int_to_float_scaled_simd(const int32_t* A, int8_t scale, float* B, size_t size) {\n    __m256i scale_vec = _mm256_set1_epi32((int32_t)scale);\n    __m256 scale_float = _mm256_set1_ps((float)scale);\n    \n    for (size_t i = 0; i < size; i += 8) {\n        __m256i int_values = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i scaled_int_values = _mm256_mullo_epi32(int_values, scale_vec);\n        __m256 scaled_float_values = _mm256_cvtepi32_ps(scaled_int_values);\n        _mm256_storeu_ps(&B[i], _mm256_mul_ps(scaled_float_values, scale_float));\n    }\n}\n```"}
{"task_id": "SimdBench_51_AVX", "completion": "```cpp\nvoid int_to_float_scaled_simd(const int32_t* A, int8_t scale, float* B, size_t size) {\n    __m256i scale_vec = _mm256_set1_epi32(scale);\n    __m256 scale_float = _mm256_cvtepi32_ps(scale_vec);\n\n    for (size_t i = 0; i < size; i += 8) {\n        __m256i input = _mm256_loadu_si256((__m256i*)(A + i));\n        __m256 input_float = _mm256_cvtepi32_ps(input);\n        __m256 result = _mm256_mul_ps(input_float, scale_float);\n        _mm256_storeu_ps(B + i, result);\n    }\n}\n```"}
{"task_id": "SimdBench_51_AVX", "completion": "```c\nvoid int_to_float_scaled_simd(const int32_t* A, int8_t scale, float* B, size_t size) {\n    __m256i scale_vec = _mm256_set1_epi32((int)scale);\n    __m256 scale_float = _mm256_cvtepi32_ps(scale_vec);\n\n    for (size_t i = 0; i < size; i += 8) {\n        __m256i int_values = _mm256_loadu_si256((__m256i*)(A + i));\n        __m256 float_values = _mm256_cvtepi32_ps(int_values);\n        float_values = _mm256_mul_ps(float_values, scale_float);\n        _mm256_storeu_ps(B + i, float_values);\n    }\n}\n```"}
{"task_id": "SimdBench_51_AVX", "completion": "```c\nvoid int_to_float_scaled_simd(const int32_t* A, int8_t scale, float* B, size_t size) {\n    const __m256i scale_vec = _mm256_set1_epi32((int)scale);\n    const __m256 scale_f = _mm256_set1_ps((float)scale);\n    \n    for (size_t i = 0; i < size; i += 8) {\n        __m256i int_values = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i scaled_int_values = _mm256_mullo_epi32(int_values, scale_vec);\n        __m256 scaled_float_values = _mm256_cvtepi32_ps(scaled_int_values);\n        _mm256_storeu_ps(&B[i], _mm256_mul_ps(scaled_float_values, scale_f));\n    }\n}\n```"}
{"task_id": "SimdBench_52_AVX", "completion": "```cpp\nvoid float_div_round_simd(const float* A, const float* B, int32_t* C, size_t size) {\n    const int step = 8;\n    const __m256i rounding_offset = _mm256_set1_epi32(1 << 30);\n    \n    for (size_t i = 0; i < size; i += step) {\n        __m256 a = _mm256_loadu_ps(&A[i]);\n        __m256 b = _mm256_loadu_ps(&B[i]);\n        \n        __m256 result = _mm256_round_ps(_mm256_div_ps(a, b), _MM_FROUND_TO_NEAREST_INT);\n        __m256i int_result = _mm256_cvtps_epi32(result);\n        int_result = _mm256_add_epi32(int_result, rounding_offset);\n        \n        _mm256_storeu_si256((__m256i*)&C[i], int_result);\n    }\n}\n```"}
{"task_id": "SimdBench_52_AVX", "completion": "```c\nvoid float_div_round_simd(const float* A, const float* B, int32_t* C, size_t size) {\n    const int step = 8;\n    const __m256i rounding_offset = _mm256_set1_epi32(1 << 30);\n    \n    for (size_t i = 0; i < size; i += step) {\n        __m256 a = _mm256_loadu_ps(&A[i]);\n        __m256 b = _mm256_loadu_ps(&B[i]);\n        \n        __m256 result = _mm256_round_ps(_mm256_div_ps(a, b), _MM_FROUND_TO_NEAREST_INT);\n        __m256i int_result = _mm256_cvtps_epi32(result);\n        \n        int_result = _mm256_add_epi32(int_result, rounding_offset);\n        \n        _mm256_storeu_si256((__m256i*)&C[i], int_result);\n    }\n}\n```"}
{"task_id": "SimdBench_52_AVX", "completion": "```cpp\nvoid float_div_round_simd(const float* A, const float* B, int32_t* C, size_t size) {\n    const int step = 8;\n    for (size_t i = 0; i < size; i += step) {\n        __m256 a = _mm256_loadu_ps(&A[i]);\n        __m256 b = _mm256_loadu_ps(&B[i]);\n        __m256 result = _mm256_round_ps(_mm256_div_ps(a, b), _MM_FROUND_TO_NEAREST_INT);\n        _mm256_storeu_si256((__m256i*)&C[i], _mm256_cvtps_epi32(result));\n    }\n}\n```"}
{"task_id": "SimdBench_52_AVX", "completion": "```cpp\nvoid float_div_round_simd(const float* A, const float* B, int32_t* C, size_t size) {\n    const int step = 8;\n    const __m256i rounding_offset = _mm256_set1_epi32(1 << 30);\n    for (size_t i = 0; i < size; i += step) {\n        __m256 a = _mm256_loadu_ps(&A[i]);\n        __m256 b = _mm256_loadu_ps(&B[i]);\n        __m256 result = _mm256_round_ps(_mm256_div_ps(a, b), _MM_FROUND_TO_NEAREST_INT);\n        __m256i int_result = _mm256_cvtps_epi32(result);\n        int_result = _mm256_add_epi32(int_result, rounding_offset);\n        _mm256_storeu_si256((__m256i*)&C[i], int_result);\n    }\n}\n```  "}
{"task_id": "SimdBench_52_AVX", "completion": "```cpp\nvoid float_div_round_simd(const float* A, const float* B, int32_t* C, size_t size) {\n    const int step = 8;\n    for (size_t i = 0; i < size; i += step) {\n        __m256 a = _mm256_loadu_ps(&A[i]);\n        __m256 b = _mm256_loadu_ps(&B[i]);\n        __m256 result = _mm256_round_ps(_mm256_div_ps(a, b), _MM_FROUND_TO_NEAREST_INT);\n        _mm256_storeu_si256((__m256i*)&C[i], _mm256_cvtps_epi32(result));\n    }\n}\n```  "}
{"task_id": "SimdBench_53_AVX", "completion": "```\nvoid double_to_float_saturate_simd(const double* A, float* B, size_t size) {\n    const __m256d max_double = _mm256_set1_pd(FLT_MAX);\n    const __m256d min_double = _mm256_set1_pd(-FLT_MAX);\n    const __m256 max_float = _mm256_set1_ps(FLT_MAX);\n    const __m256 min_float = _mm256_set1_ps(-FLT_MAX);\n\n    for (size_t i = 0; i < size; i += 4) {\n        __m256d input_double = _mm256_loadu_pd(&A[i]);\n        __m256d clamped_double = _mm256_min_pd(_mm256_max_pd(input_double, min_double), max_double);\n        __m256 output_float = _mm256_cvtpd_ps(clamped_double);\n        output_float = _mm256_min_ps(_mm256_max_ps(output_float, min_float), max_float);\n        _mm256_storeu_ps(&B[i], output_float);\n    }\n}\n```"}
{"task_id": "SimdBench_53_AVX", "completion": "```\nvoid double_to_float_saturate_simd(const double* A, float* B, size_t size) {\n    const __m256d max_double = _mm256_set1_pd(FLT_MAX);\n    const __m256d min_double = _mm256_set1_pd(-FLT_MAX);\n    const __m256 max_float = _mm256_set1_ps(FLT_MAX);\n    const __m256 min_float = _mm256_set1_ps(-FLT_MAX);\n\n    for (size_t i = 0; i < size; i += 4) {\n        __m256d val_double = _mm256_loadu_pd(&A[i]);\n        __m256d clamped_double = _mm256_min_pd(_mm256_max_pd(val_double, min_double), max_double);\n        __m256 val_float = _mm256_cvtpd_ps(clamped_double);\n        __m256 clamped_float = _mm256_min_ps(_mm256_max_ps(val_float, min_float), max_float);\n        _mm256_storeu_ps(&B[i], clamped_float);\n    }\n}\n```"}
{"task_id": "SimdBench_53_AVX", "completion": "```cpp\nvoid double_to_float_saturate_simd(const double* A, float* B, size_t size) {\n    const __m256d max_double = _mm256_set1_pd(FLT_MAX);\n    const __m256d min_double = _mm256_set1_pd(-FLT_MAX);\n    const __m256 max_float = _mm256_set1_ps(FLT_MAX);\n    const __m256 min_float = _mm256_set1_ps(-FLT_MAX);\n\n    for (size_t i = 0; i < size; i += 4) {\n        __m256d values = _mm256_loadu_pd(&A[i]);\n        __m256d clipped_values = _mm256_min_pd(_mm256_max_pd(values, min_double), max_double);\n        __m256 converted_values = _mm256_cvtpd_ps(clipped_values);\n        __m256 saturated_values = _mm256_min_ps(_mm256_max_ps(converted_values, min_float), max_float);\n        _mm256_storeu_ps(&B[i], saturated_values);\n    }\n}\n```"}
{"task_id": "SimdBench_53_AVX", "completion": "```\nvoid double_to_float_saturate_simd(const double* A, float* B, size_t size) {\n    const __m256d max_double = _mm256_set1_pd(FLT_MAX);\n    const __m256d min_double = _mm256_set1_pd(-FLT_MAX);\n    const __m256 max_float = _mm256_set1_ps(FLT_MAX);\n    const __m256 min_float = _mm256_set1_ps(-FLT_MAX);\n\n    for (size_t i = 0; i < size; i += 4) {\n        __m256d input_double = _mm256_loadu_pd(&A[i]);\n        __m256d clamped_double = _mm256_min_pd(_mm256_max_pd(input_double, min_double), max_double);\n        __m256 converted_float = _mm256_cvtpd_ps(clamped_double);\n        __m256 saturated_float = _mm256_min_ps(_mm256_max_ps(converted_float, min_float), max_float);\n        _mm256_storeu_ps(&B[i], saturated_float);\n    }\n}\n```"}
{"task_id": "SimdBench_53_AVX", "completion": "```\nvoid double_to_float_saturate_simd(const double* A, float* B, size_t size) {\n    const __m256d max_double = _mm256_set1_pd(FLT_MAX);\n    const __m256d min_double = _mm256_set1_pd(-FLT_MAX);\n    const __m256 max_float = _mm256_set1_ps(FLT_MAX);\n    const __m256 min_float = _mm256_set1_ps(-FLT_MAX);\n\n    for (size_t i = 0; i < size; i += 4) {\n        __m256d input_double = _mm256_loadu_pd(&A[i]);\n        __m256d clamped_double = _mm256_min_pd(_mm256_max_pd(input_double, min_double), max_double);\n        __m256 converted_float = _mm256_cvtpd_ps(clamped_double);\n        converted_float = _mm256_min_ps(_mm256_max_ps(converted_float, min_float), max_float);\n        _mm256_storeu_ps(&B[i], converted_float);\n    }\n}\n```"}
{"task_id": "SimdBench_54_AVX", "completion": "```c\nvoid int16_to_int32_simd(const int16_t* A, int32_t* B, size_t size) {\n    size_t i = 0;\n    for (; i + 8 <= size; i += 8) {\n        __m256i a = _mm256_cvtepi16_epi32(_mm_loadu_si128((__m128i*)&A[i]));\n        _mm256_storeu_si256((__m256i*)&B[i], a);\n    }\n    for (; i < size; ++i) {\n        B[i] = A[i];\n    }\n}\n```"}
{"task_id": "SimdBench_54_AVX", "completion": "```cpp\nvoid int16_to_int32_simd(const int16_t* A, int32_t* B, size_t size) {\n    size_t i = 0;\n    for (; i + 8 <= size; i += 8) {\n        __m256i a = _mm256_cvtepi16_epi32(_mm_loadu_si128((__m128i*)&A[i]));\n        _mm256_storeu_si256((__m256i*)&B[i], a);\n    }\n    for (; i < size; ++i) {\n        B[i] = A[i];\n    }\n}\n```"}
{"task_id": "SimdBench_54_AVX", "completion": "```cpp\nvoid int16_to_int32_simd(const int16_t* A, int32_t* B, size_t size) {\n    size_t i = 0;\n    for (; i + 7 < size; i += 8) {\n        __m256i a = _mm256_cvtepi16_epi32(_mm_loadu_si128((__m128i*)&A[i]));\n        __m256i b = _mm256_cvtepi16_epi32(_mm_loadu_si128((__m128i*)&A[i + 4]));\n        _mm256_storeu_si256((__m256i*)&B[i], a);\n        _mm256_storeu_si256((__m256i*)&B[i + 4], b);\n    }\n    for (; i < size; ++i) {\n        B[i] = A[i];\n    }\n}\n```"}
{"task_id": "SimdBench_54_AVX", "completion": "```cpp\nvoid int16_to_int32_simd(const int16_t* A, int32_t* B, size_t size) {\n    size_t i = 0;\n    for (; i + 8 <= size; i += 8) {\n        __m256i a = _mm256_cvtepi16_epi32(_mm256_loadu_si256((__m256i*)&A[i]));\n        _mm256_storeu_si256((__m256i*)&B[i], a);\n    }\n    for (; i < size; ++i) {\n        B[i] = A[i];\n    }\n}\n```"}
{"task_id": "SimdBench_54_AVX", "completion": "```cpp\nvoid int16_to_int32_simd(const int16_t* A, int32_t* B, size_t size) {\n    size_t i = 0;\n    for (; i + 8 <= size; i += 8) {\n        __m256i a = _mm256_cvtepi16_epi32(_mm_loadu_si128((__m128i*)&A[i]));\n        __m256i b = _mm256_cvtepi16_epi32(_mm_loadu_si128((__m128i*)&A[i + 8]));\n        _mm256_storeu_si256((__m256i*)&B[i], a);\n        _mm256_storeu_si256((__m256i*)&B[i + 8], b);\n    }\n    for (; i < size; ++i) {\n        B[i] = A[i];\n    }\n}\n```"}
{"task_id": "SimdBench_55_AVX", "completion": "```c\nvoid conditional_normalize_simd(const float* A, const int32_t* control, float* B, size_t size, float min_val, float max_val) {\n    __m256 min_val_v = _mm256_set1_ps(min_val);\n    __m256 max_val_v = _mm256_set1_ps(max_val);\n    __m256 zero_v = _mm256_setzero_ps();\n    __m256 one_v = _mm256_set1_ps(1.0f);\n\n    for (size_t i = 0; i < size; i += 8) {\n        __m256 A_val = _mm256_loadu_ps(&A[i]);\n        __m256 control_val = _mm256_cvtepi32_ps(_mm256_loadu_si256((__m256i*)&control[i]));\n\n        __m256 mask = _mm256_cmp_ps(control_val, zero_v, _CMP_GT_OQ);\n        __m256 normalized_val = _mm256_div_ps(_mm256_sub_ps(A_val, min_val_v), _mm256_sub_ps(max_val_v, min_val_v));\n        normalized_val = _mm256_max_ps(zero_v, _mm256_min_ps(one_v, normalized_val));\n\n        __m256 result = _mm256_blendv_ps(A_val, normalized_val, mask);\n\n        _mm256_storeu_ps(&B[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_55_AVX", "completion": "```c\nvoid conditional_normalize_simd(const float* A, const int32_t* control, float* B, size_t size, float min_val, float max_val) {\n    __m256 min_val_v = _mm256_set1_ps(min_val);\n    __m256 max_val_v = _mm256_set1_ps(max_val);\n    __m256 zero_v = _mm256_setzero_ps();\n    __m256 one_v = _mm256_set1_ps(1.0f);\n\n    for (size_t i = 0; i < size; i += 8) {\n        __m256 A_v = _mm256_loadu_ps(&A[i]);\n        __m256i control_v = _mm256_loadu_si256((__m256i*)&control[i]);\n        __m256 mask = _mm256_cmp_ps(_mm256_cvtepi32_ps(control_v), zero_v, _CMP_GT_OQ);\n        \n        __m256 val = _mm256_div_ps(_mm256_sub_ps(A_v, min_val_v), _mm256_sub_ps(max_val_v, min_val_v));\n        val = _mm256_max_ps(zero_v, _mm256_min_ps(one_v, val));\n        \n        __m256 result = _mm256_blendv_ps(A_v, val, mask);\n        \n        _mm256_storeu_ps(&B[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_55_AVX", "completion": "```c\nvoid conditional_normalize_simd(const float* A, const int32_t* control, float* B, size_t size, float min_val, float max_val) {\n    __m256 min_val_v = _mm256_set1_ps(min_val);\n    __m256 max_val_v = _mm256_set1_ps(max_val);\n    __m256 zero_v = _mm256_setzero_ps();\n    __m256 one_v = _mm256_set1_ps(1.0f);\n\n    for (size_t i = 0; i < size; i += 8) {\n        __m256 A_val = _mm256_loadu_ps(&A[i]);\n        __m256 control_val = _mm256_cvtepi32_ps(_mm256_loadu_si256((__m256i*)&control[i]));\n        \n        __m256 mask = _mm256_cmp_ps(control_val, zero_v, _CMP_GT_OQ);\n        \n        __m256 normalized_val = _mm256_div_ps(_mm256_sub_ps(A_val, min_val_v), _mm256_sub_ps(max_val_v, min_val_v));\n        normalized_val = _mm256_min_ps(one_v, _mm256_max_ps(zero_v, normalized_val));\n        \n        __m256 result = _mm256_blendv_ps(A_val, normalized_val, mask);\n        \n        _mm256_storeu_ps(&B[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_55_AVX", "completion": "```c\nvoid conditional_normalize_simd(const float* A, const int32_t* control, float* B, size_t size, float min_val, float max_val) {\n    __m256 min_val_v = _mm256_set1_ps(min_val);\n    __m256 max_val_v = _mm256_set1_ps(max_val);\n    __m256 zero_v = _mm256_setzero_ps();\n    __m256 one_v = _mm256_set1_ps(1.0f);\n\n    for (size_t i = 0; i < size; i += 8) {\n        __m256 A_val = _mm256_loadu_ps(&A[i]);\n        __m256 control_val = _mm256_cvtepi32_ps(_mm256_loadu_si256((__m256i*)&control[i]));\n\n        __m256 mask = _mm256_cmp_ps(control_val, zero_v, _CMP_GT_OQ);\n        __m256 denom = _mm256_sub_ps(max_val_v, min_val_v);\n        __m256 normalized = _mm256_div_ps(_mm256_sub_ps(A_val, min_val_v), denom);\n        normalized = _mm256_max_ps(zero_v, _mm256_min_ps(one_v, normalized));\n\n        __m256 result = _mm256_blendv_ps(A_val, normalized, mask);\n\n        _mm256_storeu_ps(&B[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_55_AVX", "completion": "```c\nvoid conditional_normalize_simd(const float* A, const int32_t* control, float* B, size_t size, float min_val, float max_val) {\n    __m256 min_val_v = _mm256_set1_ps(min_val);\n    __m256 max_val_v = _mm256_set1_ps(max_val);\n    __m256 zero_v = _mm256_setzero_ps();\n    __m256 one_v = _mm256_set1_ps(1.0f);\n\n    for (size_t i = 0; i < size; i += 8) {\n        __m256 A_v = _mm256_loadu_ps(&A[i]);\n        __m256i control_v = _mm256_loadu_si256((__m256i*)&control[i]);\n        __m256 mask = _mm256_cmp_ps(_mm256_cvtepi32_ps(control_v), zero_v, _CMP_GT_OQ);\n        \n        __m256 val = _mm256_div_ps(_mm256_sub_ps(A_v, min_val_v), _mm256_sub_ps(max_val_v, min_val_v));\n        val = _mm256_max_ps(zero_v, _mm256_min_ps(one_v, val));\n        \n        __m256 result = _mm256_blendv_ps(A_v, val, mask);\n        \n        _mm256_storeu_ps(&B[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_56_AVX", "completion": "```cpp\nvoid int_to_float_sqrt_simd(const uint32_t* A, float* B, size_t size) {\n    for (size_t i = 0; i < size; i += 8) {\n        __m256i intValues = _mm256_loadu_si256((__m256i*)(A + i));\n        __m256i high16bits = _mm256_slli_epi32(intValues, 16);\n        __m256 floatValues = _mm256_cvtepi32_ps(high16bits);\n        __m256 sqrtValues = _mm256_sqrt_ps(floatValues);\n        _mm256_storeu_ps(B + i, sqrtValues);\n    }\n}\n```"}
{"task_id": "SimdBench_56_AVX", "completion": "```cpp\nvoid int_to_float_sqrt_simd(const uint32_t* A, float* B, size_t size) {\n    for (size_t i = 0; i < size; i += 8) {\n        __m256i intValues = _mm256_loadu_si256((__m256i*)(A + i));\n        __m256 floatValues = _mm256_cvtepi32_ps(_mm256_srli_epi32(intValues, 16));\n        floatValues = _mm256_sqrt_ps(floatValues);\n        _mm256_storeu_ps(B + i, floatValues);\n    }\n}\n```"}
{"task_id": "SimdBench_56_AVX", "completion": "```cpp\nvoid int_to_float_sqrt_simd(const uint32_t* A, float* B, size_t size) {\n    for (size_t i = 0; i < size; i += 8) {\n        __m256i intValues = _mm256_loadu_si256((__m256i*)(A + i));\n        __m256 floatValues = _mm256_cvtepi32_ps(_mm256_srli_epi32(intValues, 16));\n        floatValues = _mm256_sqrt_ps(floatValues);\n        _mm256_storeu_ps(B + i, floatValues);\n    }\n}\n```"}
{"task_id": "SimdBench_56_AVX", "completion": "```c\nvoid int_to_float_sqrt_simd(const uint32_t* A, float* B, size_t size) {\n    for (size_t i = 0; i < size; i += 8) {\n        __m256i intValues = _mm256_loadu_si256((__m256i*)(A + i));\n        __m256i high16Bits = _mm256_srli_epi32(intValues, 16);\n        __m256 floatValues = _mm256_cvtepi32_ps(high16Bits);\n        __m256 sqrtValues = _mm256_sqrt_ps(floatValues);\n        _mm256_storeu_ps(B + i, sqrtValues);\n    }\n}\n```"}
{"task_id": "SimdBench_56_AVX", "completion": "```c\nvoid int_to_float_sqrt_simd(const uint32_t* A, float* B, size_t size) {\n    for (size_t i = 0; i < size; i += 8) {\n        __m256i intValues = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i high16bits = _mm256_srli_epi32(intValues, 16);\n        __m256 floatValues = _mm256_cvtepi32_ps(high16bits);\n        __m256 sqrtValues = _mm256_sqrt_ps(floatValues);\n        _mm256_storeu_ps(&B[i], sqrtValues);\n    }\n}\n```"}
{"task_id": "SimdBench_57_AVX", "completion": "```c\nvoid int_bits_to_float_simd(const uint32_t* A, float* B, size_t size) {\n    size_t i = 0;\n    for (; i + 8 <= size; i += 8) {\n        __m256i int_values = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256 float_values = _mm256_castsi256_ps(int_values);\n        _mm256_storeu_ps(&B[i], float_values);\n    }\n    for (; i < size; ++i) {\n        B[i] = *(float*)&A[i];\n    }\n}\n```"}
{"task_id": "SimdBench_57_AVX", "completion": "```cpp\nvoid int_bits_to_float_simd(const uint32_t* A, float* B, size_t size) {\n    size_t i = 0;\n    for (; i + 8 <= size; i += 8) {\n        __m256i intValues = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256 floatValues = _mm256_castsi256_ps(intValues);\n        _mm256_storeu_ps(&B[i], floatValues);\n    }\n    for (; i < size; ++i) {\n        B[i] = *(float*)&A[i];\n    }\n}\n```"}
{"task_id": "SimdBench_57_AVX", "completion": "```cpp\nvoid int_bits_to_float_simd(const uint32_t* A, float* B, size_t size) {\n    size_t i = 0;\n    for (; i + 8 <= size; i += 8) {\n        __m256i int_values = _mm256_loadu_si256((__m256i*)(A + i));\n        __m256 float_values = _mm256_castsi256_ps(int_values);\n        _mm256_storeu_ps(B + i, float_values);\n    }\n    for (; i < size; ++i) {\n        B[i] = *(float*)(A + i);\n    }\n}\n```"}
{"task_id": "SimdBench_57_AVX", "completion": "```cpp\nvoid int_bits_to_float_simd(const uint32_t* A, float* B, size_t size) {\n    size_t i = 0;\n    for (; i + 8 <= size; i += 8) {\n        __m256i int_values = _mm256_loadu_si256((__m256i*)(A + i));\n        __m256 float_values = _mm256_castsi256_ps(int_values);\n        _mm256_storeu_ps(B + i, float_values);\n    }\n    for (; i < size; ++i) {\n        B[i] = *(float*)(A + i);\n    }\n}\n```"}
{"task_id": "SimdBench_57_AVX", "completion": "```cpp\nvoid int_bits_to_float_simd(const uint32_t* A, float* B, size_t size) {\n    size_t i = 0;\n    for (; i + 8 <= size; i += 8) {\n        __m256i int_values = _mm256_loadu_si256((__m256i*)(A + i));\n        __m256 float_values = _mm256_castsi256_ps(int_values);\n        _mm256_storeu_ps(B + i, float_values);\n    }\n    for (; i < size; ++i) {\n        B[i] = *(float*)(A + i);\n    }\n}\n```"}
{"task_id": "SimdBench_58_AVX", "completion": "```cpp\nvoid conditional_diff_simd(const int32_t* A, const bool* cond, float* diff, size_t size) {\n    __m256i prev = _mm256_setzero_si256();\n    __m256i mask_true = _mm256_set1_epi32(-1); // All bits set to 1\n    __m256 mask_false = _mm256_setzero_ps();\n    \n    for (size_t i = 0; i < size; i += 8) {\n        __m256i current = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i delta = _mm256_sub_epi32(current, prev);\n        \n        __m256i cond_mask = _mm256_loadu_si256((__m256i*)&cond[i]);\n        __m256i masked_delta = _mm256_and_si256(delta, cond_mask);\n        \n        __m256 delta_float = _mm256_cvtepi32_ps(masked_delta);\n        __m256 result = _mm256_blendv_ps(mask_false, delta_float, _mm256_castsi256_ps(cond_mask));\n        \n        if (i == 0) {\n            result = _mm256_blend_ps(result, mask_false, 1); // Set diff[0] to 0.0f\n        }\n        \n        _mm256_storeu_ps(&diff[i], result);\n        \n        prev = current;\n    }\n}\n```"}
{"task_id": "SimdBench_58_AVX", "completion": "```cpp\nvoid conditional_diff_simd(const int32_t* A, const bool* cond, float* diff, size_t size) {\n    __m256i prev = _mm256_setzero_si256();\n    __m256 zero = _mm256_setzero_ps();\n\n    for (size_t i = 0; i < size; i += 8) {\n        __m256i current = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i mask = _mm256_loadu_si256((__m256i*)&cond[i]);\n\n        __m256i diff_int = _mm256_sub_epi32(current, prev);\n        __m256 diff_float = _mm256_cvtepi32_ps(diff_int);\n\n        __m256 result = _mm256_blendv_ps(zero, diff_float, _mm256_castsi256_ps(mask));\n\n        _mm256_storeu_ps(&diff[i], result);\n\n        prev = current;\n    }\n}\n```"}
{"task_id": "SimdBench_58_AVX", "completion": "```cpp\nvoid conditional_diff_simd(const int32_t* A, const bool* cond, float* diff, size_t size) {\n    __m256i prev = _mm256_setzero_si256();\n    __m256 mask_true = _mm256_castsi256_ps(_mm256_set1_epi32(-1));\n    __m256 mask_false = _mm256_setzero_ps();\n\n    for (size_t i = 0; i < size; i += 8) {\n        __m256i current = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i diff_int = _mm256_sub_epi32(current, prev);\n\n        __m256i cond_int = _mm256_loadu_si256((__m256i*)&cond[i]);\n        __m256 cond_ps = _mm256_castsi256_ps(cond_int);\n\n        __m256 diff_float = _mm256_cvtepi32_ps(diff_int);\n\n        __m256 result = _mm256_blendv_ps(mask_false, diff_float, cond_ps);\n        result = _mm256_blendv_ps(result, mask_false, _mm256_castsi256_ps(_mm256_cmpeq_epi32(cond_int, _mm256_setzero_si256())));\n\n        _mm256_storeu_ps(&diff[i], result);\n\n        prev = current;\n    }\n}\n```"}
{"task_id": "SimdBench_58_AVX", "completion": "```cpp\nvoid conditional_diff_simd(const int32_t* A, const bool* cond, float* diff, size_t size) {\n    __m256i prev = _mm256_setzero_si256();\n    __m256 mask_true = _mm256_castsi256_ps(_mm256_set1_epi32(-1));\n    __m256 mask_false = _mm256_setzero_ps();\n\n    for (size_t i = 0; i < size; i += 8) {\n        __m256i current = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i diff_int = _mm256_sub_epi32(current, prev);\n\n        __m256 mask = _mm256_cmp_ps(mask_true, mask_false, _CMP_EQ_OQ);\n        __m256 diff_float = _mm256_cvtepi32_ps(diff_int);\n        __m256 result = _mm256_blendv_ps(mask_false, diff_float, mask);\n\n        _mm256_storeu_ps(&diff[i], result);\n\n        prev = current;\n    }\n}\n```"}
{"task_id": "SimdBench_58_AVX", "completion": "```cpp\nvoid conditional_diff_simd(const int32_t* A, const bool* cond, float* diff, size_t size) {\n    __m256i prev = _mm256_setzero_si256();\n    __m256 mask_true = _mm256_castsi256_ps(_mm256_set1_epi32(-1));\n    __m256 mask_false = _mm256_setzero_ps();\n\n    for (size_t i = 0; i < size; i += 8) {\n        __m256i current = _mm256_loadu_si256((__m256i*)(A + i));\n        __m256i diff_int = _mm256_sub_epi32(current, prev);\n\n        __m256i cond_int = _mm256_loadu_si256((__m256i*)(cond + i));\n        __m256 cond_ps = _mm256_castsi256_ps(cond_int);\n\n        __m256 diff_float = _mm256_cvtepi32_ps(diff_int);\n\n        __m256 result = _mm256_blendv_ps(mask_false, diff_float, cond_ps);\n\n        if (i == 0) {\n            result = _mm256_blend_ps(result, _mm256_setzero_ps(), 1);\n        }\n\n        _mm256_storeu_ps(diff + i, result);\n\n        prev = current;\n    }\n}\n```"}
{"task_id": "SimdBench_59_AVX", "completion": "```cpp\nvoid widening_uint_simd(const uint32_t* src, uint64_t* dst, size_t length) {\n    size_t i = 0;\n    for (; i + 4 <= length; i += 4) {\n        __m128i src_vec = _mm_loadu_si128((__m128i*)(src + i));\n        __m256i wide_src_vec = _mm256_cvtepu32_epi64(src_vec);\n        __m256i high_bits = _mm256_slli_epi64(_mm256_set1_epi64x(0xFFFFFFFF00000000), 32);\n        __m256i result = _mm256_or_si256(wide_src_vec, high_bits);\n        _mm256_storeu_si256((__m256i*)(dst + i), result);\n    }\n    for (; i < length; i++) {\n        uint64_t val = src[i];\n        val |= 0xFFFFFFFF00000000;\n        dst[i] = val;\n    }\n}\n```"}
{"task_id": "SimdBench_59_AVX", "completion": "```c\nvoid widening_uint_simd(const uint32_t* src, uint64_t* dst, size_t length) {\n    size_t i;\n    for (i = 0; i < length; i += 4) {\n        __m128i src_vec = _mm_loadu_si128((__m128i*)(src + i));\n        __m256i wide_src_vec = _mm256_cvtepu32_epi64(src_vec);\n        __m256i high_bits = _mm256_slli_epi64(_mm256_set1_epi64x(0xFFFFFFFF00000000), 32);\n        __m256i result = _mm256_or_si256(wide_src_vec, high_bits);\n        _mm256_storeu_si256((__m256i*)(dst + i), result);\n    }\n}\n```"}
{"task_id": "SimdBench_59_AVX", "completion": "```cpp\nvoid widening_uint_simd(const uint32_t* src, uint64_t* dst, size_t length) {\n    for (size_t i = 0; i < length; i += 4) {\n        __m128i src_vec = _mm_loadu_si128((__m128i*)(src + i));\n        __m256i wide_src_vec = _mm256_cvtepu32_epi64(src_vec);\n        __m256i mask = _mm256_set1_epi64x(0xFFFFFFFF00000000);\n        __m256i result = _mm256_or_si256(wide_src_vec, mask);\n        _mm256_storeu_si256((__m256i*)(dst + i), result);\n    }\n}\n```"}
{"task_id": "SimdBench_59_AVX", "completion": "```cpp\nvoid widening_uint_simd(const uint32_t* src, uint64_t* dst, size_t length) {\n    for (size_t i = 0; i < length; i += 4) {\n        __m128i src_vec = _mm_loadu_si128((__m128i*)(src + i));\n        __m256i src_wide = _mm256_cvtepu32_epi64(src_vec);\n        \n        __m256i mask = _mm256_set1_epi64x(0xFFFFFFFF00000000);\n        __m256i result = _mm256_or_si256(src_wide, mask);\n        \n        _mm256_storeu_si256((__m256i*)(dst + i), result);\n    }\n}\n```"}
{"task_id": "SimdBench_59_AVX", "completion": "```c\nvoid widening_uint_simd(const uint32_t* src, uint64_t* dst, size_t length) {\n    size_t i;\n    for (i = 0; i < length; i += 4) {\n        __m128i src_vec = _mm_loadu_si128((__m128i*)(src + i));\n        __m256i wide_src_vec = _mm256_cvtepu32_epi64(src_vec);\n        __m256i mask = _mm256_set1_epi64x(0xFFFFFFFF00000000);\n        __m256i result = _mm256_or_si256(wide_src_vec, mask);\n        _mm256_storeu_si256((__m256i*)(dst + i), result);\n    }\n}\n```"}
{"task_id": "SimdBench_60_AVX", "completion": "```\ndouble indexed_sum_simd(const double* vec, const int16_t* index, size_t length) {\n    __m256d sum = _mm256_setzero_pd();\n    \n    for (size_t i = 0; i < length; i += 4) {\n        __m128i indices = _mm_loadu_si128((__m128i*)&index[i]);\n        __m256d values = _mm256_i32gather_pd(vec, indices, 8);\n        sum = _mm256_add_pd(sum, values);\n    }\n    \n    double result[4];\n    _mm256_storeu_pd(result, sum);\n    \n    return result[0] + result[1] + result[2] + result[3];\n}\n```"}
{"task_id": "SimdBench_60_AVX", "completion": "```\ndouble indexed_sum_simd(const double* vec, const int16_t* index, size_t length) {\n    __m256d sum = _mm256_setzero_pd();\n    for (size_t i = 0; i < length; i += 4) {\n        __m128i indices = _mm_loadu_si128((__m128i*)(index + i));\n        __m256d values = _mm256_i32gather_pd(vec, indices, 8);\n        sum = _mm256_add_pd(sum, values);\n    }\n    double result[4];\n    _mm256_storeu_pd(result, sum);\n    return result[0] + result[1] + result[2] + result[3];\n}\n```"}
{"task_id": "SimdBench_60_AVX", "completion": "```\ndouble indexed_sum_simd(const double* vec, const int16_t* index, size_t length) {\n    __m256d sum = _mm256_setzero_pd();\n    for (size_t i = 0; i < length; i += 4) {\n        __m128i idx = _mm_loadu_si128((__m128i*)(index + i));\n        __m256d vals = _mm256_i32gather_pd(vec, idx, 8);\n        sum = _mm256_add_pd(sum, vals);\n    }\n    \n    double result[4];\n    _mm256_storeu_pd(result, sum);\n    \n    return result[0] + result[1] + result[2] + result[3];\n}\n```"}
{"task_id": "SimdBench_60_AVX", "completion": "```\ndouble indexed_sum_simd(const double* vec, const int16_t* index, size_t length) {\n    __m256d sum = _mm256_setzero_pd();\n    for (size_t i = 0; i < length; i += 4) {\n        __m128i indices = _mm_loadu_si128((__m128i*)&index[i]);\n        __m256d values = _mm256_i32gather_pd(vec, indices, 8);\n        sum = _mm256_add_pd(sum, values);\n    }\n    double result[4];\n    _mm256_storeu_pd(result, sum);\n    return result[0] + result[1] + result[2] + result[3];\n}\n```"}
{"task_id": "SimdBench_60_AVX", "completion": "```cpp\ndouble indexed_sum_simd(const double* vec, const int16_t* index, size_t length) {\n    __m256d sum = _mm256_setzero_pd();\n    \n    for (size_t i = 0; i < length; i += 4) {\n        __m128i indices = _mm_loadu_si128((__m128i*)&index[i]);\n        __m256d values = _mm256_i32gather_pd(vec, indices, 8);\n        sum = _mm256_add_pd(sum, values);\n    }\n    \n    alignas(32) double result[4];\n    _mm256_store_pd(result, sum);\n    \n    return result[0] + result[1] + result[2] + result[3];\n}\n```"}
{"task_id": "SimdBench_61_AVX", "completion": "```c\nvoid simple_conv2d_simd(const double* input, const double* kernel, double * output, size_t input_size, size_t kernel_size) {\n    const size_t output_size = input_size - kernel_size + 1;\n    const size_t output_area = output_size * output_size;\n    \n    for (size_t i = 0; i < output_area; ++i) {\n        __m256d sum = _mm256_setzero_pd();\n        size_t input_row = i / output_size;\n        size_t input_col = i % output_size;\n        \n        for (size_t j = 0; j < kernel_size; ++j) {\n            for (size_t k = 0; k < kernel_size; ++k) {\n                size_t input_idx = (input_row + j) * input_size + input_col + k;\n                size_t kernel_idx = j * kernel_size + k;\n                __m256d input_vals = _mm256_loadu_pd(&input[input_idx]);\n                __m256d kernel_vals = _mm256_broadcast_sd(&kernel[kernel_idx]);\n                sum = _mm256_fmadd_pd(input_vals, kernel_vals, sum);\n            }\n        }\n        \n        __m256d zero = _mm256_setzero_pd();\n        sum = _mm256_max_pd(sum, zero);\n        _mm256_storeu_pd(&output[i], sum);\n    }\n}\n```"}
{"task_id": "SimdBench_61_AVX", "completion": "```c\nvoid simple_conv2d_simd(const double* input, const double* kernel, double * output, size_t input_size, size_t kernel_size) {\n    const size_t output_size = input_size - kernel_size + 1;\n    const size_t output_area = output_size * output_size;\n    \n    for (size_t i = 0; i < output_area; ++i) {\n        __m256d sum = _mm256_setzero_pd();\n        for (size_t ky = 0; ky < kernel_size; ++ky) {\n            for (size_t kx = 0; kx < kernel_size; ++kx) {\n                const size_t input_idx = (i / output_size + ky) * input_size + (i % output_size + kx);\n                const size_t kernel_idx = ky * kernel_size + kx;\n                __m256d input_vals = _mm256_loadu_pd(&input[input_idx]);\n                __m256d kernel_vals = _mm256_set1_pd(kernel[kernel_idx]);\n                sum = _mm256_fmadd_pd(input_vals, kernel_vals, sum);\n            }\n        }\n        __m256d zero = _mm256_setzero_pd();\n        sum = _mm256_max_pd(sum, zero);\n        _mm256_storeu_pd(&output[i], sum);\n    }\n}\n```"}
{"task_id": "SimdBench_61_AVX", "completion": "```c\nvoid simple_conv2d_simd(const double* input, const double* kernel, double * output, size_t input_size, size_t kernel_size) {\n    const size_t output_size = input_size - kernel_size + 1;\n    const size_t output_area = output_size * output_size;\n    \n    for (size_t i = 0; i < output_area; ++i) {\n        __m256d sum = _mm256_setzero_pd();\n        size_t output_row = i / output_size;\n        size_t output_col = i % output_size;\n        \n        for (size_t j = 0; j < kernel_size; ++j) {\n            for (size_t k = 0; k < kernel_size; ++k) {\n                size_t input_row = output_row + j;\n                size_t input_col = output_col + k;\n                size_t input_index = input_row * input_size + input_col;\n                size_t kernel_index = j * kernel_size + k;\n                \n                __m256d input_val = _mm256_loadu_pd(&input[input_index]);\n                __m256d kernel_val = _mm256_broadcast_sd(&kernel[kernel_index]);\n                sum = _mm256_fmadd_pd(input_val, kernel_val, sum);\n            }\n        }\n        \n        __m256d zero = _mm256_setzero_pd();\n        sum = _mm256_max_pd(sum, zero);\n        _mm256_storeu_pd(&output[i], sum);\n    }\n}\n```"}
{"task_id": "SimdBench_61_AVX", "completion": "```c\nvoid simple_conv2d_simd(const double* input, const double* kernel, double * output, size_t input_size, size_t kernel_size) {\n    const size_t output_size = input_size - kernel_size + 1;\n    const size_t output_area = output_size * output_size;\n    \n    for (size_t i = 0; i < output_area; ++i) {\n        __m256d sum = _mm256_setzero_pd();\n        \n        for (size_t ky = 0; ky < kernel_size; ++ky) {\n            for (size_t kx = 0; kx < kernel_size; ++kx) {\n                const size_t input_idx = (i / output_size + ky) * input_size + (i % output_size + kx);\n                const size_t kernel_idx = ky * kernel_size + kx;\n                \n                __m256d input_vals = _mm256_loadu_pd(&input[input_idx]);\n                __m256d kernel_vals = _mm256_broadcast_sd(&kernel[kernel_idx]);\n                sum = _mm256_fmadd_pd(input_vals, kernel_vals, sum);\n            }\n        }\n        \n        sum = _mm256_max_pd(sum, _mm256_setzero_pd());\n        _mm256_storeu_pd(&output[i], sum);\n    }\n}\n```"}
{"task_id": "SimdBench_61_AVX", "completion": "```c\nvoid simple_conv2d_simd(const double* input, const double* kernel, double * output, size_t input_size, size_t kernel_size) {\n    size_t output_size = input_size - kernel_size + 1;\n    size_t output_area = output_size * output_size;\n\n    for (size_t i = 0; i < output_area; ++i) {\n        __m256d sum = _mm256_setzero_pd();\n\n        for (size_t ky = 0; ky < kernel_size; ++ky) {\n            for (size_t kx = 0; kx < kernel_size; ++kx) {\n                size_t input_index = (i / output_size + ky) * input_size + i % output_size + kx;\n                size_t kernel_index = ky * kernel_size + kx;\n\n                __m256d input_vals = _mm256_loadu_pd(&input[input_index]);\n                __m256d kernel_vals = _mm256_broadcast_sd(&kernel[kernel_index]);\n                sum = _mm256_fmadd_pd(input_vals, kernel_vals, sum);\n            }\n        }\n\n        __m256d zero = _mm256_setzero_pd();\n        sum = _mm256_max_pd(sum, zero);\n\n        _mm256_storeu_pd(&output[i], sum);\n    }\n}\n```"}
{"task_id": "SimdBench_62_AVX", "completion": "```cpp\nbool has_close_elements_simd(const std::vector<double> & numbers, double threshold){\n    const int n = numbers.size();\n    const int simd_width = 4;\n    const int simd_size = n / simd_width;\n\n    __m256d threshold_v = _mm256_set1_pd(threshold);\n\n    for (int i = 0; i < simd_size; ++i) {\n        __m256d vec1 = _mm256_loadu_pd(&numbers[i * simd_width]);\n        for (int j = i + 1; j < simd_size; ++j) {\n            __m256d vec2 = _mm256_loadu_pd(&numbers[j * simd_width]);\n            __m256d diff = _mm256_sub_pd(vec1, vec2);\n            __m256d abs_diff = _mm256_and_pd(diff, _mm256_set1_pd(-0.0));\n            __m256d cmp = _mm256_cmp_pd(abs_diff, threshold_v, _CMP_LE_OQ);\n            int mask = _mm256_movemask_pd(cmp);\n            if (mask != 0) {\n                return true;\n            }\n        }\n    }\n\n    return false;\n}\n```  "}
{"task_id": "SimdBench_62_AVX", "completion": "```cpp\nbool has_close_elements_simd(const std::vector<double> & numbers, double threshold){\n    const int n = numbers.size();\n    const int simd_width = 4;\n    const int simd_size = n / simd_width;\n    \n    __m256d threshold_v = _mm256_set1_pd(threshold);\n    \n    for (int i = 0; i < simd_size; ++i) {\n        __m256d vec1 = _mm256_loadu_pd(&numbers[i * simd_width]);\n        for (int j = i + 1; j < simd_size; ++j) {\n            __m256d vec2 = _mm256_loadu_pd(&numbers[j * simd_width]);\n            __m256d diff = _mm256_sub_pd(vec1, vec2);\n            __m256d abs_diff = _mm256_andnot_pd(_mm256_set1_pd(-0.0), diff);\n            __m256d cmp = _mm256_cmp_pd(abs_diff, threshold_v, _CMP_LT_OQ);\n            int mask = _mm256_movemask_pd(cmp);\n            if (mask != 0) {\n                return true;\n            }\n        }\n    }\n    \n    return false;\n}\n```"}
{"task_id": "SimdBench_62_AVX", "completion": "```cpp\nbool has_close_elements_simd(const std::vector<double> & numbers, double threshold){\n    const int n = numbers.size();\n    const int simd_width = 4;\n    const int simd_size = n / simd_width;\n\n    __m256d threshold_v = _mm256_set1_pd(threshold);\n\n    for (int i = 0; i < simd_size; ++i) {\n        __m256d vec1 = _mm256_loadu_pd(&numbers[i * simd_width]);\n        for (int j = i + 1; j < simd_size; ++j) {\n            __m256d vec2 = _mm256_loadu_pd(&numbers[j * simd_width]);\n            __m256d diff = _mm256_sub_pd(vec1, vec2);\n            __m256d abs_diff = _mm256_and_pd(diff, _mm256_set1_pd(-0.0));\n            __m256d cmp = _mm256_cmp_pd(abs_diff, threshold_v, _CMP_LT_OQ);\n            int mask = _mm256_movemask_pd(cmp);\n            if (mask != 0) {\n                return true;\n            }\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_62_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nbool has_close_elements_simd(const std::vector<double> & numbers, double threshold){\n    const int n = numbers.size();\n    const int simd_width = 4;\n    const int simd_iterations = n / simd_width;\n\n    __m256d threshold_vec = _mm256_set1_pd(threshold);\n\n    for (int i = 0; i < simd_iterations; ++i) {\n        __m256d vec1 = _mm256_loadu_pd(&numbers[i * simd_width]);\n        for (int j = i + 1; j < simd_iterations; ++j) {\n            __m256d vec2 = _mm256_loadu_pd(&numbers[j * simd_width]);\n            __m256d diff = _mm256_sub_pd(vec1, vec2);\n            __m256d abs_diff = _mm256_andnot_pd(_mm256_set1_pd(-0.0), diff);\n            __m256d cmp = _mm256_cmp_pd(abs_diff, threshold_vec, _CMP_LT_OQ);\n            int mask = _mm256_movemask_pd(cmp);\n            if (mask != 0) {\n                return true;\n            }\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_62_AVX", "completion": "```cpp\nbool has_close_elements_simd(const std::vector<double> & numbers, double threshold){\n    const int n = numbers.size();\n    const int simd_width = 4;\n    const int simd_size = n / simd_width;\n\n    __m256d threshold_v = _mm256_set1_pd(threshold);\n\n    for (int i = 0; i < simd_size; ++i) {\n        __m256d vec1 = _mm256_loadu_pd(&numbers[i * simd_width]);\n        for (int j = i + 1; j < simd_size; ++j) {\n            __m256d vec2 = _mm256_loadu_pd(&numbers[j * simd_width]);\n            __m256d diff = _mm256_sub_pd(vec1, vec2);\n            __m256d abs_diff = _mm256_and_pd(diff, _mm256_set1_pd(-0.0));\n            __m256d cmp = _mm256_cmp_pd(abs_diff, threshold_v, _CMP_LT_OQ);\n            int mask = _mm256_movemask_pd(cmp);\n            if (mask != 0) {\n                return true;\n            }\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_63_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nbool below_zero_simd(std::vector<int> operations){\n    const int size = operations.size();\n    const int chunk_size = 8;\n    \n    for (int i = 0; i < size; i += chunk_size) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&operations[i]);\n        __m256i zero = _mm256_setzero_si256();\n        __m256i sum = _mm256_add_epi32(zero, vec);\n        \n        __m256i mask = _mm256_cmpgt_epi32(zero, sum);\n        if (_mm256_movemask_ps((__m256)mask) != 0) {\n            return true;\n        }\n    }\n    \n    return false;\n}\n```"}
{"task_id": "SimdBench_63_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nbool below_zero_simd(std::vector<int> operations) {\n    const int size = operations.size();\n    const int chunk_size = 8;\n    const int num_chunks = size / chunk_size;\n    \n    __m256i zero = _mm256_setzero_si256();\n    \n    for (int i = 0; i < num_chunks * chunk_size; i += chunk_size) {\n        __m256i chunk = _mm256_loadu_si256((__m256i*)&operations[i]);\n        __m256i sum = _mm256_add_epi32(zero, chunk);\n        \n        __m256i mask = _mm256_cmpgt_epi32(zero, sum);\n        if (!_mm256_testz_si256(mask, mask)) {\n            return true;\n        }\n    }\n    \n    for (int i = num_chunks * chunk_size; i < size; ++i) {\n        if (operations[i] < 0) {\n            return true;\n        }\n    }\n    \n    return false;\n}\n```"}
{"task_id": "SimdBench_63_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nbool below_zero_simd(std::vector<int> operations){\n    const int size = operations.size();\n    const int chunk_size = 8;\n    \n    for (int i = 0; i < size; i += chunk_size) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&operations[i]);\n        __m256i zero = _mm256_set1_epi32(0);\n        __m256i mask = _mm256_cmpgt_epi32(zero, vec);\n        \n        if (_mm256_testz_si256(mask, mask) == 0) {\n            return true;\n        }\n    }\n    \n    return false;\n}\n```  "}
{"task_id": "SimdBench_63_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nbool below_zero_simd(std::vector<int> operations){\n    const int size = operations.size();\n    const int chunk_size = 8;\n    \n    for (int i = 0; i < size; i += chunk_size) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&operations[i]);\n        __m256i sum = _mm256_setzero_si256();\n        \n        sum = _mm256_add_epi32(sum, vec);\n        \n        __m256i mask = _mm256_cmpgt_epi32(sum, _mm256_set1_epi32(0));\n        \n        if (!_mm256_testz_si256(mask, mask)) {\n            return false;\n        }\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_63_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nbool below_zero_simd(std::vector<int> operations){\n    const int size = operations.size();\n    const int simd_width = 8;\n    int i = 0;\n    \n    __m256i balance = _mm256_setzero_si256();\n    \n    for (; i <= size - simd_width; i += simd_width) {\n        __m256i ops = _mm256_loadu_si256((__m256i*)&operations[i]);\n        balance = _mm256_add_epi32(balance, ops);\n        \n        __m256i mask = _mm256_cmpgt_epi32(_mm256_setzero_si256(), balance);\n        if (_mm256_testz_si256(mask, mask) == 0) {\n            return true;\n        }\n    }\n    \n    int remaining_ops[simd_width];\n    for (int j = 0; i < size; ++i, ++j) {\n        remaining_ops[j] = operations[i];\n    }\n    \n    __m256i remaining_balance = _mm256_setzero_si256();\n    for (int j = 0; j < size - i; ++j) {\n        remaining_balance = _mm256_add_epi32(remaining_balance, _mm256_set1_epi32(remaining_ops[j]));\n    }\n    \n    __m256i mask = _mm256_cmpgt_epi32(_mm256_setzero_si256(), remaining_balance);\n    return _mm256_testz_si256(mask, mask) == 0;\n}\n```"}
{"task_id": "SimdBench_64_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\ndouble mean_absolute_deviation_simd(std::vector<double> numbers){\n    int n = numbers.size();\n    int remainder = n % 4;\n    \n    __m256d sum = _mm256_setzero_pd();\n    __m256d mean = _mm256_setzero_pd();\n    \n    for (int i = 0; i < n - remainder; i += 4) {\n        __m256d vec = _mm256_loadu_pd(&numbers[i]);\n        sum = _mm256_add_pd(sum, vec);\n    }\n    \n    if (remainder > 0) {\n        __m256d vec_remainder = _mm256_setzero_pd();\n        for (int i = n - remainder; i < n; ++i) {\n            vec_remainder = _mm256_insertf128_pd(vec_remainder, _mm_set1_pd(numbers[i]), i % 4);\n        }\n        sum = _mm256_add_pd(sum, vec_remainder);\n    }\n    \n    mean = _mm256_div_pd(sum, _mm256_set1_pd(n));\n    \n    __m256d mad_sum = _mm256_setzero_pd();\n    for (int i = 0; i < n - remainder; i += 4) {\n        __m256d vec = _mm256_loadu_pd(&numbers[i]);\n        __m256d diff = _mm256_sub_pd(vec, mean);\n        __m256d abs_diff = _mm256_and_pd(diff, _mm256_set1_pd(-0.0));\n        mad_sum = _mm256_add_pd(mad_sum, abs_diff);\n    }\n    \n    if (remainder > 0) {\n        __m256d vec_remainder = _mm256_setzero_pd();\n        for (int i = n - remainder; i < n; ++i) {\n            vec_remainder = _mm256_insertf128_pd(vec_remainder, _mm_set1_pd(numbers[i]), i % 4);\n        }\n        __m256d diff = _mm256_sub_pd(vec_remainder, mean);\n        __m256d abs_diff = _mm256_and_pd(diff, _mm256_set1_pd(-0.0));\n        mad_sum = _mm256_add_pd(mad_sum, abs_diff);\n    }\n    \n    __m128d mad_sum_low = _mm256_extractf128_pd(mad_sum, 0);\n    __m128d mad_sum_high = _mm256_extractf128_pd(mad_sum, 1);\n    __m128d mad_sum_final = _mm_add_pd(mad_sum_low, mad_sum_high);\n    \n    double mad[2];\n    _mm_storeu_pd(mad, mad_sum_final);\n    \n    return (mad[0] + mad[1]) / n;\n}\n```"}
{"task_id": "SimdBench_64_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\ndouble mean_absolute_deviation_simd(std::vector<double> numbers){\n    int n = numbers.size();\n    int remainder = n % 4;\n    int simd_length = n - remainder;\n\n    __m256d sum = _mm256_setzero_pd();\n    __m256d mean = _mm256_setzero_pd();\n\n    for (int i = 0; i < simd_length; i += 4) {\n        __m256d vec = _mm256_loadu_pd(&numbers[i]);\n        sum = _mm256_add_pd(sum, vec);\n    }\n\n    mean = _mm256_div_pd(sum, _mm256_set1_pd(n));\n\n    __m256d mad_sum = _mm256_setzero_pd();\n\n    for (int i = 0; i < simd_length; i += 4) {\n        __m256d vec = _mm256_loadu_pd(&numbers[i]);\n        __m256d diff = _mm256_sub_pd(vec, mean);\n        __m256d abs_diff = _mm256_and_pd(diff, _mm256_set1_pd(-0.0));\n        mad_sum = _mm256_add_pd(mad_sum, abs_diff);\n    }\n\n    double mad_values[4];\n    _mm256_storeu_pd(mad_values, mad_sum);\n\n    double mad = 0.0;\n    for (int i = 0; i < 4; i++) {\n        mad += mad_values[i];\n    }\n\n    for (int i = simd_length; i < n; i++) {\n        mad += std::abs(numbers[i] - mad / n);\n    }\n\n    return mad / n;\n}\n```"}
{"task_id": "SimdBench_64_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\ndouble mean_absolute_deviation_simd(std::vector<double> numbers){\n    int n = numbers.size();\n    int remainder = n % 4;\n    \n    __m256d sum = _mm256_setzero_pd();\n    __m256d mean = _mm256_setzero_pd();\n    \n    for (int i = 0; i < n - remainder; i += 4) {\n        __m256d vec = _mm256_loadu_pd(&numbers[i]);\n        sum = _mm256_add_pd(sum, vec);\n    }\n    \n    double temp[4] = {0.0, 0.0, 0.0, 0.0};\n    _mm256_storeu_pd(temp, sum);\n    \n    mean = _mm256_set1_pd((temp[0] + temp[1] + temp[2] + temp[3]) / n);\n    \n    __m256d mad_sum = _mm256_setzero_pd();\n    \n    for (int i = 0; i < n - remainder; i += 4) {\n        __m256d vec = _mm256_loadu_pd(&numbers[i]);\n        __m256d diff = _mm256_sub_pd(vec, mean);\n        __m256d abs_diff = _mm256_and_pd(diff, _mm256_set1_pd(-0.0));\n        mad_sum = _mm256_add_pd(mad_sum, abs_diff);\n    }\n    \n    double mad_temp[4] = {0.0, 0.0, 0.0, 0.0};\n    _mm256_storeu_pd(mad_temp, mad_sum);\n    \n    double mad = (mad_temp[0] + mad_temp[1] + mad_temp[2] + mad_temp[3]) / n;\n    \n    return mad;\n}\n```"}
{"task_id": "SimdBench_64_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\ndouble mean_absolute_deviation_simd(std::vector<double> numbers){\n    int n = numbers.size();\n    int remainder = n % 4;\n    int simd_length = n - remainder;\n\n    __m256d sum = _mm256_setzero_pd();\n    for (int i = 0; i < simd_length; i += 4) {\n        __m256d vec = _mm256_loadu_pd(&numbers[i]);\n        sum = _mm256_add_pd(sum, vec);\n    }\n\n    double total_sum = 0.0;\n    for (int i = 0; i < 4; i++) {\n        total_sum += sum[i];\n    }\n\n    double mean = total_sum / n;\n\n    __m256d abs_diff_sum = _mm256_setzero_pd();\n    for (int i = 0; i < simd_length; i += 4) {\n        __m256d vec = _mm256_loadu_pd(&numbers[i]);\n        __m256d diff = _mm256_sub_pd(vec, _mm256_set1_pd(mean));\n        abs_diff_sum = _mm256_add_pd(abs_diff_sum, _mm256_and_pd(diff, _mm256_set1_pd(-0.0)));\n    }\n\n    double total_abs_diff_sum = 0.0;\n    for (int i = 0; i < 4; i++) {\n        total_abs_diff_sum += abs_diff_sum[i];\n    }\n\n    for (int i = simd_length; i < n; i++) {\n        total_abs_diff_sum += std::abs(numbers[i] - mean);\n    }\n\n    return total_abs_diff_sum / n;\n}\n```"}
{"task_id": "SimdBench_64_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\ndouble mean_absolute_deviation_simd(std::vector<double> numbers){\n    int n = numbers.size();\n    int remainder = n % 4;\n    int simd_length = n - remainder;\n\n    __m256d sum = _mm256_setzero_pd();\n    __m256d mean = _mm256_setzero_pd();\n\n    for (int i = 0; i < simd_length; i += 4) {\n        __m256d vec = _mm256_loadu_pd(&numbers[i]);\n        sum = _mm256_add_pd(sum, vec);\n    }\n\n    mean = _mm256_div_pd(sum, _mm256_set1_pd(n));\n\n    __m256d mad_sum = _mm256_setzero_pd();\n\n    for (int i = 0; i < simd_length; i += 4) {\n        __m256d vec = _mm256_loadu_pd(&numbers[i]);\n        __m256d diff = _mm256_sub_pd(vec, mean);\n        __m256d abs_diff = _mm256_and_pd(diff, _mm256_castsi256_pd(_mm256_set1_epi64x(0x7FFFFFFFFFFFFFFF)));\n        mad_sum = _mm256_add_pd(mad_sum, abs_diff);\n    }\n\n    double mad_result[4];\n    _mm256_storeu_pd(mad_result, mad_sum);\n\n    double final_mad = (mad_result[0] + mad_result[1] + mad_result[2] + mad_result[3] + remainder) / n;\n\n    return final_mad;\n}\n```"}
{"task_id": "SimdBench_65_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nstd::vector<int> intersperse_simd(std::vector<int> numbers, int delimeter) {\n    std::vector<int> result(numbers.size() * 2 - 1);\n    __m256i numbers_vec = _mm256_loadu_si256((__m256i*)numbers.data());\n    __m256i delimeter_vec = _mm256_set1_epi32(delimeter);\n    __m256i zero_vec = _mm256_setzero_si256();\n\n    for (size_t i = 0; i < numbers.size(); ++i) {\n        size_t result_idx = i * 2;\n        _mm256_storeu_si256((__m256i*)&result[result_idx], numbers_vec);\n        if (i != numbers.size() - 1) {\n            _mm256_storeu_si256((__m256i*)&result[result_idx + 1], delimeter_vec);\n        }\n        numbers_vec = _mm256_permute2x128_si256(numbers_vec, zero_vec, 0x21);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_65_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nstd::vector<int> intersperse_simd(std::vector<int> numbers, int delimeter) {\n    std::vector<int> result;\n    if (numbers.size() < 2) {\n        return numbers;\n    }\n\n    __m256i delim = _mm256_set1_epi32(delimeter);\n    __m256i* input = (__m256i*)numbers.data();\n    int num_elements = numbers.size() / 8;\n    \n    for (int i = 0; i < num_elements; i++) {\n        __m256i curr = _mm256_loadu_si256(input + i);\n        result.push_back(_mm256_extract_epi32(curr, 0));\n        result.push_back(delimeter);\n        result.push_back(_mm256_extract_epi32(curr, 1));\n        result.push_back(delimeter);\n        result.push_back(_mm256_extract_epi32(curr, 2));\n        result.push_back(delimeter);\n        result.push_back(_mm256_extract_epi32(curr, 3));\n        result.push_back(delimeter);\n        result.push_back(_mm256_extract_epi32(curr, 4));\n        result.push_back(delimeter);\n        result.push_back(_mm256_extract_epi32(curr, 5));\n        result.push_back(delimeter);\n        result.push_back(_mm256_extract_epi32(curr, 6));\n        result.push_back(delimeter);\n        result.push_back(_mm256_extract_epi32(curr, 7));\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_65_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nstd::vector<int> intersperse_simd(std::vector<int> numbers, int delimeter) {\n    int size = numbers.size();\n    int output_size = size + (size - 1);\n    std::vector<int> result(output_size);\n\n    __m256i num = _mm256_set1_epi32(delimeter);\n    int i = 0;\n    for (; i + 8 <= size; i += 8) {\n        __m256i input = _mm256_loadu_si256((__m256i*)&numbers[i]);\n        _mm256_storeu_si256((__m256i*)&result[i + i], input);\n        _mm256_storeu_si256((__m256i*)&result[i + i + 1], num);\n    }\n\n    for (; i < size; ++i) {\n        result[i + i] = numbers[i];\n        if (i != size - 1) {\n            result[i + i + 1] = delimeter;\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_65_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nstd::vector<int> intersperse_simd(std::vector<int> numbers, int delimeter) {\n    std::vector<int> result;\n    int size = numbers.size();\n    \n    if (size == 0) {\n        return result;\n    }\n    \n    __m256i num = _mm256_set1_epi32(numbers[0]);\n    __m256i delim = _mm256_set1_epi32(delimeter);\n    \n    for (int i = 0; i < size - 1; ++i) {\n        result.push_back(numbers[i]);\n        result.push_back(delimeter);\n    }\n    result.push_back(numbers[size - 1]);\n    \n    int resultSize = result.size();\n    int simdSize = resultSize / 8;\n    \n    __m256i* resultPtr = (__m256i*)result.data();\n    __m256i* outputPtr = (__m256i*)_mm_malloc(sizeof(__m256i) * simdSize, 32);\n    \n    for (int i = 0; i < simdSize; ++i) {\n        outputPtr[i] = num;\n        outputPtr[i + 1] = delim;\n    }\n    \n    std::vector<int> finalResult(resultSize + simdSize * 8);\n    std::memcpy(finalResult.data(), result.data(), resultSize * sizeof(int));\n    std::memcpy(finalResult.data() + resultSize, outputPtr, simdSize * 8 * sizeof(int));\n    \n    _mm_free(outputPtr);\n    \n    return finalResult;\n}\n```"}
{"task_id": "SimdBench_65_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nstd::vector<int> intersperse_simd(std::vector<int> numbers, int delimeter){\n    std::vector<int> result;\n    if(numbers.size() < 2) return numbers;\n\n    __m256i nums = _mm256_loadu_si256((__m256i*)numbers.data());\n    __m256i delim = _mm256_set1_epi32(delimeter);\n\n    __m256i shuffled = _mm256_permutevar8x32_epi32(nums, _mm256_setr_epi32(0, 4, 1, 4, 2, 4, 3, 4));\n    __m256i interleaved = _mm256_blend_epi32(nums, shuffled, 0b10101010);\n\n    int result_arr[8];\n    _mm256_storeu_si256((__m256i*)result_arr, interleaved);\n\n    for(int i = 0; i < 8; ++i){\n        result.push_back(result_arr[i]);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_66_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nstd::vector<int64_t> sum_product_simd(std::vector<int16_t> numbers){\n    __m256i sum = _mm256_setzero_si256();\n    __m256i product = _mm256_set1_epi16(1);\n\n    for (size_t i = 0; i < numbers.size(); i += 16) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&numbers[i]);\n        sum = _mm256_add_epi64(sum, _mm256_cvtepi16_epi64(vec));\n        product = _mm256_mullo_epi16(product, vec);\n    }\n\n    int64_t sum_arr[4];\n    _mm256_storeu_si256((__m256i*)sum_arr, sum);\n\n    int64_t product_arr[4];\n    _mm256_storeu_si256((__m256i*)product_arr, product);\n\n    return {sum_arr[0] + sum_arr[1] + sum_arr[2] + sum_arr[3], product_arr[0] * product_arr[1] * product_arr[2] * product_arr[3]};\n}\n```"}
{"task_id": "SimdBench_66_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nstd::vector<int64_t> sum_product_simd(std::vector<int16_t> numbers){\n    __m256i sum = _mm256_setzero_si256();\n    __m256i product = _mm256_set1_epi16(1);\n\n    for (size_t i = 0; i < numbers.size(); i += 16) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&numbers[i]);\n        sum = _mm256_add_epi64(sum, _mm256_cvtepi16_epi64(vec));\n        product = _mm256_mullo_epi16(product, vec);\n    }\n\n    int64_t sum_arr[4];\n    _mm256_storeu_si256((__m256i*)sum_arr, sum);\n\n    int64_t product_arr[4];\n    _mm256_storeu_si256((__m256i*)product_arr, product);\n\n    return {sum_arr[0] + sum_arr[1] + sum_arr[2] + sum_arr[3], product_arr[0] * product_arr[1] * product_arr[2] * product_arr[3]};\n}\n```"}
{"task_id": "SimdBench_66_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nstd::vector<int64_t> sum_product_simd(std::vector<int16_t> numbers){\n    __m256i sum = _mm256_setzero_si256();\n    __m256i product = _mm256_set1_epi16(1);\n\n    for (size_t i = 0; i < numbers.size(); i += 16) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&numbers[i]);\n        sum = _mm256_add_epi64(sum, _mm256_cvtepi16_epi64(vec));\n\n        __m256i vec32 = _mm256_cvtepi16_epi32(vec);\n        __m256i lo = _mm256_mullo_epi32(_mm256_extractf128_si256(vec32, 0), _mm256_extractf128_si256(vec32, 1));\n        __m256i hi = _mm256_mulhi_epi32(_mm256_extractf128_si256(vec32, 0), _mm256_extractf128_si256(vec32, 1));\n        product = _mm256_mullo_epi32(product, _mm256_packs_epi32(lo, hi));\n    }\n\n    int64_t sum_res[4];\n    _mm256_storeu_si256((__m256i*)sum_res, sum);\n\n    int64_t product_res[4];\n    _mm256_storeu_si256((__m256i*)product_res, product);\n\n    return {sum_res[0] + sum_res[1] + sum_res[2] + sum_res[3], product_res[0] * product_res[1] * product_res[2] * product_res[3]};\n}\n```"}
{"task_id": "SimdBench_66_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nstd::vector<int64_t> sum_product_simd(std::vector<int16_t> numbers){\n    __m256i sum = _mm256_setzero_si256();\n    __m256i product = _mm256_set1_epi16(1);\n\n    for (size_t i = 0; i < numbers.size(); i += 16) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&numbers[i]);\n        sum = _mm256_add_epi64(sum, _mm256_cvtepi16_epi64(vec));\n        product = _mm256_mullo_epi16(product, vec);\n    }\n\n    int64_t sum_array[4];\n    _mm256_storeu_si256((__m256i*)sum_array, sum);\n\n    int64_t product_array[4];\n    _mm256_storeu_si256((__m256i*)product_array, product);\n\n    return {sum_array[0] + sum_array[1] + sum_array[2] + sum_array[3], \n            product_array[0] * product_array[1] * product_array[2] * product_array[3]};\n}\n```"}
{"task_id": "SimdBench_66_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nstd::vector<int64_t> sum_product_simd(std::vector<int16_t> numbers){\n    __m256i sum = _mm256_setzero_si256();\n    __m256i product = _mm256_set1_epi16(1);\n\n    for (size_t i = 0; i < numbers.size(); i += 16) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&numbers[i]);\n        sum = _mm256_add_epi64(sum, _mm256_cvtepi16_epi64(vec));\n        product = _mm256_mullo_epi16(product, vec);\n    }\n\n    int64_t sum_arr[4];\n    _mm256_storeu_si256((__m256i*)sum_arr, sum);\n    int64_t product_arr[4];\n    _mm256_storeu_si256((__m256i*)product_arr, product);\n\n    return {sum_arr[0] + sum_arr[1] + sum_arr[2] + sum_arr[3], product_arr[0] * product_arr[1] * product_arr[2] * product_arr[3]};\n}\n```"}
{"task_id": "SimdBench_67_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nstd::vector<int> rolling_max_simd(std::vector<int> numbers){\n    std::vector<int> result(numbers.size());\n    __m256i current_max = _mm256_set1_epi32(INT_MIN);\n\n    for (size_t i = 0; i < numbers.size(); i += 8) {\n        __m256i input = _mm256_loadu_si256((__m256i*)&numbers[i]);\n        current_max = _mm256_max_epi32(current_max, input);\n        _mm256_storeu_si256((__m256i*)&result[i], current_max);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_67_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nstd::vector<int> rolling_max_simd(std::vector<int> numbers){\n    std::vector<int> result(numbers.size());\n    __m256i current_max = _mm256_set1_epi32(INT_MIN);\n    \n    for (size_t i = 0; i < numbers.size(); i += 8) {\n        __m256i input = _mm256_loadu_si256((__m256i*)&numbers[i]);\n        current_max = _mm256_max_epi32(current_max, input);\n        _mm256_storeu_si256((__m256i*)&result[i], current_max);\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_67_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nstd::vector<int> rolling_max_simd(std::vector<int> numbers){\n    std::vector<int> result(numbers.size());\n    __m256i current_max = _mm256_set1_epi32(INT_MIN);\n\n    for (size_t i = 0; i < numbers.size(); i += 8) {\n        __m256i input = _mm256_loadu_si256((__m256i*)&numbers[i]);\n        current_max = _mm256_max_epi32(current_max, input);\n        _mm256_storeu_si256((__m256i*)&result[i], current_max);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_67_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nstd::vector<int> rolling_max_simd(std::vector<int> numbers){\n    std::vector<int> result(numbers.size());\n    __m256i current_max = _mm256_set1_epi32(INT_MIN);\n\n    for (size_t i = 0; i < numbers.size(); i += 8) {\n        __m256i input = _mm256_loadu_si256((__m256i*)&numbers[i]);\n        current_max = _mm256_max_epi32(current_max, input);\n        _mm256_storeu_si256((__m256i*)&result[i], current_max);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_67_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nstd::vector<int> rolling_max_simd(std::vector<int> numbers){\n    std::vector<int> result(numbers.size());\n    __m256i current_max = _mm256_set1_epi32(INT_MIN);\n\n    for (size_t i = 0; i < numbers.size(); i += 8) {\n        __m256i input = _mm256_loadu_si256((__m256i*)&numbers[i]);\n        current_max = _mm256_max_epi32(current_max, input);\n        _mm256_storeu_si256((__m256i*)&result[i], current_max);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_68_AVX", "completion": "```cpp\nstd::string string_xor_simd(std::string a, std::string b){\n    int len = a.size();\n    __m256i* a_ptr = (__m256i*)a.data();\n    __m256i* b_ptr = (__m256i*)b.data();\n    __m256i* result_ptr = (__m256i*)malloc(len * sizeof(__m256i));\n\n    for (int i = 0; i < len / 32; ++i) {\n        __m256i a_val = _mm256_load_si256(&a_ptr[i]);\n        __m256i b_val = _mm256_load_si256(&b_ptr[i]);\n        __m256i result = _mm256_xor_si256(a_val, b_val);\n        _mm256_store_si256(&result_ptr[i], result);\n    }\n\n    std::string result_str(len, '0');\n    __m256i* result_str_ptr = (__m256i*)result_str.data();\n\n    for (int i = 0; i < len / 32; ++i) {\n        __m256i res_val = _mm256_load_si256(&result_ptr[i]);\n        _mm256_store_si256(&result_str_ptr[i], res_val);\n    }\n\n    free(result_ptr);\n    return result_str;\n}\n```"}
{"task_id": "SimdBench_68_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nstd::string string_xor_simd(std::string a, std::string b){\n    int len = a.size();\n    int remainder = len % 32;\n    len = len - remainder;\n\n    __m256i* a_ptr = (__m256i*)a.data();\n    __m256i* b_ptr = (__m256i*)b.data();\n\n    for (int i = 0; i < len; i += 8) {\n        __m256i a_val = _mm256_load_si256(a_ptr + i);\n        __m256i b_val = _mm256_load_si256(b_ptr + i);\n        __m256i result = _mm256_xor_si256(a_val, b_val);\n        _mm256_store_si256(a_ptr + i, result);\n    }\n\n    for (int i = len; i < len + remainder; ++i) {\n        a[i] = (a[i] == b[i]) ? '0' : '1';\n    }\n\n    return a;\n}\n```"}
{"task_id": "SimdBench_68_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nstd::string string_xor_simd(std::string a, std::string b){\n    int len = a.size();\n    int remainder = len % 32;\n    int full_simd_iters = len / 32;\n\n    __m256i* a_ptr = (__m256i*)a.data();\n    __m256i* b_ptr = (__m256i*)b.data();\n\n    for (int i = 0; i < full_simd_iters; ++i) {\n        __m256i a_val = _mm256_load_si256(a_ptr + i);\n        __m256i b_val = _mm256_load_si256(b_ptr + i);\n        __m256i result = _mm256_xor_si256(a_val, b_val);\n        _mm256_store_si256((__m256i*)(a.data() + i * 32), result);\n    }\n\n    for (int i = len - remainder; i < len; ++i) {\n        a[i] = (a[i] != b[i]) ? '1' : '0';\n    }\n\n    return a;\n}\n```"}
{"task_id": "SimdBench_68_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nstd::string string_xor_simd(std::string a, std::string b){\n    int length = a.size();\n    int remainder = length % 32;\n    length -= remainder;\n\n    __m256i* a_ptr = (__m256i*)a.data();\n    __m256i* b_ptr = (__m256i*)b.data();\n\n    for (int i = 0; i < length; i += 8) {\n        __m256i a_val = _mm256_load_si256(a_ptr + i);\n        __m256i b_val = _mm256_load_si256(b_ptr + i);\n        __m256i result = _mm256_xor_si256(a_val, b_val);\n        _mm256_store_si256(a_ptr + i, result);\n    }\n\n    for (int i = length; i < length + remainder; ++i) {\n        a[i] = (a[i] != b[i]) ? '1' : '0';\n    }\n\n    return a;\n}\n```"}
{"task_id": "SimdBench_68_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nstd::string string_xor_simd(std::string a, std::string b){\n    int len = a.size();\n    int remainder = len % 32;\n    int full_simd_iters = len / 32;\n\n    __m256i* a_ptr = (__m256i*)a.data();\n    __m256i* b_ptr = (__m256i*)b.data();\n    __m256i* result_ptr = (__m256i*)malloc(len);\n\n    for (int i = 0; i < full_simd_iters; ++i) {\n        __m256i a_vec = _mm256_load_si256(a_ptr + i);\n        __m256i b_vec = _mm256_load_si256(b_ptr + i);\n        __m256i result_vec = _mm256_xor_si256(a_vec, b_vec);\n        _mm256_store_si256(result_ptr + i, result_vec);\n    }\n\n    uint32_t* result = (uint32_t*)result_ptr;\n    for (int i = full_simd_iters * 8; i < len; ++i) {\n        result[i] = a[i] ^ b[i];\n    }\n\n    return std::string((char*)result, len);\n}\n```"}
{"task_id": "SimdBench_69_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nstd::string longest_simd(const std::vector<std::string> & strings){\n    if(strings.empty()) return \"None\";\n\n    std::string longest = strings[0];\n    size_t max_length = strings[0].size();\n\n    for(size_t i = 1; i < strings.size(); ++i){\n        if(strings[i].size() > max_length){\n            longest = strings[i];\n            max_length = strings[i].size();\n        }\n    }\n\n    return longest;\n}\n```"}
{"task_id": "SimdBench_69_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n#include <vector>\n\nstd::string longest_simd(const std::vector<std::string> & strings){\n    if(strings.empty()) return \"None\";\n\n    size_t max_len = 0;\n    const char* longest_str = nullptr;\n\n    for(const auto& str : strings){\n        if(str.length() > max_len){\n            max_len = str.length();\n            longest_str = str.c_str();\n        }\n    }\n\n    return longest_str;\n}\n```"}
{"task_id": "SimdBench_69_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n#include <vector>\n\nstd::string longest_simd(const std::vector<std::string> & strings){\n    if(strings.empty()) return \"None\";\n\n    size_t max_length = 0;\n    const char* longest_str = strings[0].c_str();\n\n    for(const auto& str : strings){\n        if(str.size() > max_length){\n            max_length = str.size();\n            longest_str = str.c_str();\n        }\n    }\n\n    return std::string(longest_str);\n}\n```"}
{"task_id": "SimdBench_69_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n#include <vector>\n\nstd::string longest_simd(const std::vector<std::string> & strings){\n    if(strings.empty()) return \"None\";\n\n    size_t max_length = 0;\n    const char* longest_str = strings[0].c_str();\n\n    for(const std::string& str : strings){\n        if(str.length() > max_length){\n            max_length = str.length();\n            longest_str = str.c_str();\n        }\n    }\n\n    return std::string(longest_str);\n}\n```"}
{"task_id": "SimdBench_69_AVX", "completion": "```\nstd::string longest_simd(const std::vector<std::string> & strings){\n    if(strings.empty()) {\n        return \"None\";\n    }\n    \n    const int vecSize = 8;\n    int maxLen = 0;\n    std::string longest = strings[0];\n    \n    for(size_t i = 0; i < strings.size(); i += vecSize) {\n        __m256i maxLenVec = _mm256_set1_epi32(maxLen);\n        __m256i indices = _mm256_setr_epi32(0, 1, 2, 3, 4, 5, 6, 7);\n        \n        for(int j = 0; j < vecSize; j++) {\n            if(i + j < strings.size()) {\n                const std::string& str = strings[i + j];\n                int len = str.length();\n                \n                if(len > maxLen) {\n                    maxLen = len;\n                    longest = str;\n                }\n            }\n        }\n    }\n    \n    return longest;\n}\n```"}
{"task_id": "SimdBench_70_AVX", "completion": "```c\n#include <immintrin.h>\n#include <x86intrin.h>\n\nuint64_t greatest_common_divisor_simd(uint64_t a, uint64_t b){\n    __m256i va = _mm256_set1_epi64x(a);\n    __m256i vb = _mm256_set1_epi64x(b);\n    \n    while (a != b) {\n        if (a > b) {\n            a -= b;\n            va = _mm256_sub_epi64(va, vb);\n        } else {\n            b -= a;\n            vb = _mm256_sub_epi64(vb, va);\n        }\n    }\n    \n    return a;\n}\n```  "}
{"task_id": "SimdBench_70_AVX", "completion": "```c\n#include <immintrin.h>\n#include <x86intrin.h>\n\nuint64_t greatest_common_divisor_simd(uint64_t a, uint64_t b){\n    __m256i va = _mm256_set1_epi64x(a);\n    __m256i vb = _mm256_set1_epi64x(b);\n    \n    while (a != b) {\n        if (a > b) {\n            a -= b;\n            va = _mm256_sub_epi64(va, vb);\n        } else {\n            b -= a;\n            vb = _mm256_sub_epi64(vb, va);\n        }\n    }\n    \n    return a;\n}\n```"}
{"task_id": "SimdBench_70_AVX", "completion": "```c\n#include <immintrin.h>\n#include <x86intrin.h>\n\nuint64_t greatest_common_divisor_simd(uint64_t a, uint64_t b){\n    __m256i va = _mm256_set1_epi64x(a);\n    __m256i vb = _mm256_set1_epi64x(b);\n    \n    while (a != b) {\n        if (a > b) {\n            a -= b;\n            va = _mm256_sub_epi64(va, vb);\n        } else {\n            b -= a;\n            vb = _mm256_sub_epi64(vb, va);\n        }\n    }\n    \n    return a;\n}\n```  "}
{"task_id": "SimdBench_70_AVX", "completion": "```c\n#include <immintrin.h>\n#include <x86intrin.h>\n\nuint64_t greatest_common_divisor_simd(uint64_t a, uint64_t b){\n    __m256i va = _mm256_set1_epi64x(a);\n    __m256i vb = _mm256_set1_epi64x(b);\n    \n    while (a != b) {\n        if (a > b) {\n            a -= b;\n            va = _mm256_sub_epi64(va, vb);\n        } else {\n            b -= a;\n            vb = _mm256_sub_epi64(vb, va);\n        }\n    }\n    \n    return a;\n}\n```  "}
{"task_id": "SimdBench_70_AVX", "completion": "```c\n#include <immintrin.h>\n#include <x86intrin.h>\n\nuint64_t greatest_common_divisor_simd(uint64_t a, uint64_t b){\n    __m256i va = _mm256_set1_epi64x(a);\n    __m256i vb = _mm256_set1_epi64x(b);\n    \n    while (a != b) {\n        if (a > b) {\n            a -= b;\n            va = _mm256_sub_epi64(va, vb);\n        } else {\n            b -= a;\n            vb = _mm256_sub_epi64(vb, va);\n        }\n    }\n    \n    return a;\n}\n```"}
{"task_id": "SimdBench_71_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::pair<float, float> find_closest_elements_simd(std::vector<float> numbers) {\n    __m256 closest = _mm256_set1_ps(numbers[0]);\n    __m256 closest_diff = _mm256_set1_ps(FLT_MAX);\n    __m256 num1 = _mm256_set1_ps(0.0f);\n    __m256 num2 = _mm256_set1_ps(0.0f);\n\n    for (size_t i = 0; i < numbers.size(); i += 8) {\n        __m256 current = _mm256_loadu_ps(&numbers[i]);\n        __m256 diff = _mm256_sub_ps(current, closest);\n        diff = _mm256_andnot_ps(_mm256_set1_ps(-0.0f), diff); // Absolute difference\n        __m256 mask = _mm256_cmp_ps(diff, closest_diff, _CMP_LT_OS);\n        closest = _mm256_blendv_ps(closest, current, mask);\n        closest_diff = _mm256_min_ps(closest_diff, diff);\n        num1 = _mm256_blendv_ps(num1, closest, mask);\n        num2 = _mm256_blendv_ps(num2, current, mask);\n    }\n\n    float closest_arr[8];\n    _mm256_storeu_ps(closest_arr, closest);\n\n    float closest_diff_arr[8];\n    _mm256_storeu_ps(closest_diff_arr, closest_diff);\n\n    float min_diff = FLT_MAX;\n    int min_index = 0;\n    for (int i = 0; i < 8; ++i) {\n        if (closest_diff_arr[i] < min_diff) {\n            min_diff = closest_diff_arr[i];\n            min_index = i;\n        }\n    }\n\n    return std::make_pair(closest_arr[min_index], closest_arr[min_index] == closest_arr[min_index+1] ? closest_arr[min_index+2] : closest_arr[min_index+1]);\n}\n```"}
{"task_id": "SimdBench_71_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nstd::pair<float, float> find_closest_elements_simd(std::vector<float> numbers) {\n    __m256 closest_diff = _mm256_set1_ps(FLT_MAX);\n    __m256 closest_a, closest_b;\n    \n    for (size_t i = 0; i < numbers.size(); i += 8) {\n        __m256 a = _mm256_loadu_ps(&numbers[i]);\n        __m256 b = _mm256_loadu_ps(&numbers[i + 8]);\n        \n        __m256 diff = _mm256_sub_ps(a, b);\n        diff = _mm256_and_ps(diff, _mm256_cmp_ps(diff, closest_diff, _CMP_LT_OS));\n        \n        closest_diff = _mm256_min_ps(diff, closest_diff);\n        closest_a = _mm256_blendv_ps(closest_a, a, _mm256_cmp_ps(diff, closest_diff, _CMP_EQ_OS));\n        closest_b = _mm256_blendv_ps(closest_b, b, _mm256_cmp_ps(diff, closest_diff, _CMP_EQ_OS));\n    }\n    \n    float closest_diff_arr[8];\n    _mm256_storeu_ps(closest_diff_arr, closest_diff);\n    \n    float min_diff = FLT_MAX;\n    float closest_pair[2];\n    \n    for (int i = 0; i < 8; ++i) {\n        if (closest_diff_arr[i] < min_diff) {\n            min_diff = closest_diff_arr[i];\n            closest_pair[0] = closest_a[i];\n            closest_pair[1] = closest_b[i];\n        }\n    }\n    \n    return std::make_pair(closest_pair[0], closest_pair[1]);\n}\n```"}
{"task_id": "SimdBench_71_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::pair<float, float> find_closest_elements_simd(std::vector<float> numbers) {\n    if (numbers.size() < 2) {\n        return std::make_pair(0.0f, 0.0f);\n    }\n\n    __m256 closest_diff = _mm256_set1_ps(FLT_MAX);\n    __m256 closest_a = _mm256_set1_ps(0.0f);\n    __m256 closest_b = _mm256_set1_ps(0.0f);\n\n    for (size_t i = 0; i < numbers.size() - 1; i += 8) {\n        __m256 a = _mm256_loadu_ps(&numbers[i]);\n        __m256 b = _mm256_loadu_ps(&numbers[i + 1]);\n\n        __m256 diff = _mm256_sub_ps(a, b);\n        diff = _mm256_and_ps(diff, _mm256_castsi256_ps(_mm256_cmp_ps(diff, closest_diff, _CMP_LT_OQ)));\n\n        closest_diff = _mm256_min_ps(closest_diff, diff);\n        closest_a = _mm256_blendv_ps(closest_a, a, _mm256_castsi256_ps(_mm256_cmp_ps(diff, closest_diff, _CMP_EQ_OQ)));\n        closest_b = _mm256_blendv_ps(closest_b, b, _mm256_castsi256_ps(_mm256_cmp_ps(diff, closest_diff, _CMP_EQ_OQ)));\n    }\n\n    alignas(32) float result_a[8];\n    alignas(32) float result_b[8];\n    _mm256_store_ps(result_a, closest_a);\n    _mm256_store_ps(result_b, closest_b);\n\n    float min_diff = FLT_MAX;\n    float res_a = 0.0f, res_b = 0.0f;\n\n    for (int i = 0; i < 8; ++i) {\n        if (result_a[i] != result_b[i] && result_a[i] - result_b[i] < min_diff) {\n            min_diff = result_a[i] - result_b[i];\n            res_a = result_a[i];\n            res_b = result_b[i];\n        }\n    }\n\n    return std::make_pair(res_a, res_b);\n}\n```"}
{"task_id": "SimdBench_71_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nstd::pair<float, float> find_closest_elements_simd(std::vector<float> numbers){\n    __m256 closest_diff = _mm256_set1_ps(std::numeric_limits<float>::max());\n    __m256 closest_a, closest_b;\n    \n    for (size_t i = 0; i < numbers.size(); i += 8) {\n        __m256 a = _mm256_loadu_ps(&numbers[i]);\n        __m256 b = _mm256_loadu_ps(&numbers[i + 8]);\n        \n        __m256 diff = _mm256_sub_ps(a, b);\n        diff = _mm256_and_ps(diff, _mm256_cmp_ps(diff, closest_diff, _CMP_LT_OS));\n        \n        closest_diff = _mm256_min_ps(diff, closest_diff);\n        closest_a = _mm256_blendv_ps(closest_a, a, _mm256_cmp_ps(diff, closest_diff, _CMP_EQ_OS));\n        closest_b = _mm256_blendv_ps(closest_b, b, _mm256_cmp_ps(diff, closest_diff, _CMP_EQ_OS));\n    }\n    \n    float closest_diff_arr[8];\n    _mm256_storeu_ps(closest_diff_arr, closest_diff);\n    \n    float closest_a_arr[8];\n    _mm256_storeu_ps(closest_a_arr, closest_a);\n    \n    float closest_b_arr[8];\n    _mm256_storeu_ps(closest_b_arr, closest_b);\n    \n    float min_diff = std::numeric_limits<float>::max();\n    float result_a, result_b;\n    \n    for (int i = 0; i < 8; ++i) {\n        if (closest_diff_arr[i] < min_diff) {\n            min_diff = closest_diff_arr[i];\n            result_a = closest_a_arr[i];\n            result_b = closest_b_arr[i];\n        }\n    }\n    \n    return std::make_pair(result_a, result_b);\n}\n```"}
{"task_id": "SimdBench_71_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nstd::pair<float, float> find_closest_elements_simd(std::vector<float> numbers) {\n    const int n = numbers.size();\n    const int simd_width = 8;\n    \n    __m256 closest_diff = _mm256_set1_ps(std::numeric_limits<float>::max());\n    __m256 closest_a, closest_b;\n    \n    for (int i = 0; i < n; i += simd_width) {\n        __m256 a = _mm256_loadu_ps(&numbers[i]);\n        __m256 b = _mm256_loadu_ps(&numbers[i + 1]);\n        \n        __m256 diff = _mm256_sub_ps(a, b);\n        diff = _mm256_and_ps(diff, _mm256_cmp_ps(diff, closest_diff, _CMP_LT_OS));\n        \n        closest_diff = _mm256_min_ps(closest_diff, diff);\n        closest_a = _mm256_blendv_ps(closest_a, a, _mm256_cmp_ps(diff, closest_diff, _CMP_EQ_OS));\n        closest_b = _mm256_blendv_ps(closest_b, b, _mm256_cmp_ps(diff, closest_diff, _CMP_EQ_OS));\n    }\n    \n    float closest_diff_arr[simd_width];\n    _mm256_storeu_ps(closest_diff_arr, closest_diff);\n    \n    float min_diff = std::numeric_limits<float>::max();\n    float result_a, result_b;\n    \n    for (int i = 0; i < simd_width; i++) {\n        if (closest_diff_arr[i] < min_diff) {\n            min_diff = closest_diff_arr[i];\n            result_a = closest_a[i];\n            result_b = closest_b[i];\n        }\n    }\n    \n    return std::make_pair(result_a, result_b);\n}\n```"}
{"task_id": "SimdBench_72_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nstd::vector<float> rescale_to_unit_simd(std::vector<float> numbers){\n    int n = numbers.size();\n    int num_avx = n / 8;\n    int num_remainder = n % 8;\n\n    __m256 min_val = _mm256_set1_ps(*std::min_element(numbers.begin(), numbers.end()));\n    __m256 max_val = _mm256_set1_ps(*std::max_element(numbers.begin(), numbers.end()));\n    __m256 diff = _mm256_sub_ps(max_val, min_val);\n    __m256 one = _mm256_set1_ps(1.0f);\n\n    for (int i = 0; i < num_avx; ++i) {\n        __m256 vec = _mm256_loadu_ps(&numbers[i * 8]);\n        __m256 rescaled = _mm256_div_ps(_mm256_sub_ps(vec, min_val), diff);\n        _mm256_storeu_ps(&numbers[i * 8], rescaled);\n    }\n\n    if (num_remainder > 0) {\n        __m256 vec = _mm256_setzero_ps();\n        for (int i = 0; i < num_remainder; ++i) {\n            ((float*)&vec)[i] = numbers[num_avx * 8 + i];\n        }\n        __m256 rescaled = _mm256_div_ps(_mm256_sub_ps(vec, min_val), diff);\n        for (int i = 0; i < num_remainder; ++i) {\n            numbers[num_avx * 8 + i] = ((float*)&rescaled)[i];\n        }\n    }\n\n    return numbers;\n}\n```"}
{"task_id": "SimdBench_72_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nstd::vector<float> rescale_to_unit_simd(std::vector<float> numbers){\n    const int n = numbers.size();\n    const int remainder = n % 8;\n    const int loop_end = n - remainder;\n\n    __m256 minv = _mm256_set1_ps(numbers[0]);\n    __m256 maxv = _mm256_set1_ps(numbers[0]);\n\n    for (int i = 0; i < loop_end; i += 8) {\n        __m256 v0 = _mm256_loadu_ps(&numbers[i]);\n        __m256 v1 = _mm256_loadu_ps(&numbers[i + 4]);\n\n        minv = _mm256_min_ps(minv, v0);\n        minv = _mm256_min_ps(minv, v1);\n\n        maxv = _mm256_max_ps(maxv, v0);\n        maxv = _mm256_max_ps(maxv, v1);\n    }\n\n    float min_array[8], max_array[8];\n    _mm256_storeu_ps(min_array, minv);\n    _mm256_storeu_ps(max_array, maxv);\n\n    for (int i = 0; i < 8; ++i) {\n        min_array[i] = fminf(min_array[i], min_array[i + 4]);\n        max_array[i] = fmaxf(max_array[i], max_array[i + 4]);\n    }\n\n    float min_val = min_array[0];\n    float max_val = max_array[0];\n\n    for (int i = 1; i < 8; ++i) {\n        min_val = fminf(min_val, min_array[i]);\n        max_val = fmaxf(max_val, max_array[i]);\n    }\n\n    for (int i = 0; i < loop_end; i += 8) {\n        __m256 v0 = _mm256_loadu_ps(&numbers[i]);\n        __m256 v1 = _mm256_loadu_ps(&numbers[i + 4]);\n\n        __m256 numerator0 = _mm256_sub_ps(v0, _mm256_set1_ps(min_val));\n        __m256 numerator1 = _mm256_sub_ps(v1, _mm256_set1_ps(min_val));\n        __m256 denominator = _mm256_set1_ps(max_val - min_val);\n\n        __m256 result0 = _mm256_div_ps(numerator0, denominator);\n        __m256 result1 = _mm256_div_ps(numerator1, denominator);\n\n        _mm256_storeu_ps(&numbers[i], result0);\n        _mm256_storeu_ps(&numbers[i + 4], result1);\n    }\n\n    for (int i = loop_end; i < n; ++i) {\n        numbers[i] = (numbers[i] - min_val) / (max_val - min_val);\n    }\n\n    return numbers;\n}\n```"}
{"task_id": "SimdBench_72_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nstd::vector<float> rescale_to_unit_simd(std::vector<float> numbers){\n    const int n = numbers.size();\n    const int remainder = n % 8;\n    const int loop_end = n - remainder;\n\n    __m256 minv = _mm256_set1_ps(numbers[0]);\n    __m256 maxv = _mm256_set1_ps(numbers[0]);\n\n    for (int i = 0; i < loop_end; i += 8) {\n        __m256 v0 = _mm256_loadu_ps(&numbers[i]);\n        __m256 v1 = _mm256_loadu_ps(&numbers[i + 4]);\n\n        minv = _mm256_min_ps(minv, v0);\n        minv = _mm256_min_ps(minv, v1);\n\n        maxv = _mm256_max_ps(maxv, v0);\n        maxv = _mm256_max_ps(maxv, v1);\n    }\n\n    float min_arr[8], max_arr[8];\n    _mm256_storeu_ps(min_arr, minv);\n    _mm256_storeu_ps(max_arr, maxv);\n\n    float min_val = min_arr[0];\n    float max_val = max_arr[0];\n\n    for (int i = 1; i < 8; ++i) {\n        min_val = std::min(min_val, min_arr[i]);\n        max_val = std::max(max_val, max_arr[i]);\n    }\n\n    for (int i = 0; i < loop_end; i += 8) {\n        __m256 v0 = _mm256_loadu_ps(&numbers[i]);\n        __m256 v1 = _mm256_loadu_ps(&numbers[i + 4]);\n\n        __m256 numerator0 = _mm256_sub_ps(v0, _mm256_set1_ps(min_val));\n        __m256 numerator1 = _mm256_sub_ps(v1, _mm256_set1_ps(min_val));\n        __m256 denominator = _mm256_set1_ps(max_val - min_val);\n\n        __m256 result0 = _mm256_div_ps(numerator0, denominator);\n        __m256 result1 = _mm256_div_ps(numerator1, denominator);\n\n        _mm256_storeu_ps(&numbers[i], result0);\n        _mm256_storeu_ps(&numbers[i + 4], result1);\n    }\n\n    for (int i = loop_end; i < n; ++i) {\n        numbers[i] = (numbers[i] - min_val) / (max_val - min_val);\n    }\n\n    return numbers;\n}\n```"}
{"task_id": "SimdBench_72_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nstd::vector<float> rescale_to_unit_simd(std::vector<float> numbers){\n    int num_elements = numbers.size();\n    int num_vectors = num_elements / 8;\n    \n    __m256 min_val = _mm256_set1_ps(*std::min_element(numbers.begin(), numbers.end()));\n    __m256 max_val = _mm256_set1_ps(*std::max_element(numbers.begin(), numbers.end()));\n    __m256 diff = _mm256_sub_ps(max_val, min_val);\n    __m256 one = _mm256_set1_ps(1.0f);\n    \n    for (int i = 0; i < num_vectors; ++i) {\n        __m256 vec = _mm256_loadu_ps(&numbers[i * 8]);\n        __m256 scaled = _mm256_div_ps(_mm256_sub_ps(vec, min_val), diff);\n        _mm256_storeu_ps(&numbers[i * 8], scaled);\n    }\n    \n    return numbers;\n}\n```  "}
{"task_id": "SimdBench_72_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nstd::vector<float> rescale_to_unit_simd(std::vector<float> numbers){\n    int num_elements = numbers.size();\n    int num_simd = num_elements / 8;\n    \n    __m256 min_val = _mm256_set1_ps(*std::min_element(numbers.begin(), numbers.end()));\n    __m256 max_val = _mm256_set1_ps(*std::max_element(numbers.begin(), numbers.end()));\n    __m256 diff = _mm256_sub_ps(max_val, min_val);\n    __m256 one = _mm256_set1_ps(1.0f);\n    \n    for (int i = 0; i < num_simd; ++i) {\n        __m256 input = _mm256_loadu_ps(&numbers[i * 8]);\n        __m256 scaled = _mm256_div_ps(_mm256_sub_ps(input, min_val), diff);\n        _mm256_storeu_ps(&numbers[i * 8], scaled);\n    }\n    \n    return numbers;\n}\n```  "}
{"task_id": "SimdBench_73_AVX", "completion": "```c\n#include <immintrin.h>\n#include <x86intrin.h>\n\nuint64_t largest_divisor_simd(uint64_t n){\n    __m256i divisor = _mm256_set1_epi64x(n);\n    __m256i one = _mm256_set1_epi64x(1);\n    __m256i indices = _mm256_setr_epi64x(1, 2, 3, 4, 5, 6, 7, 8);\n    __m256i result = _mm256_set1_epi64x(1);\n\n    __m256i mask = _mm256_cmpeq_epi64(_mm256_and_si256(divisor, indices), _mm256_setzero_si256());\n    __m256i masked_indices = _mm256_and_si256(indices, mask);\n    __m256i max_divisor = _mm256_max_epu64(result, masked_indices);\n\n    return _mm256_extract_epi64(max_divisor, 0);\n}\n```"}
{"task_id": "SimdBench_73_AVX", "completion": "```c\n#include <immintrin.h>\n#include <x86intrin.h>\n\nuint64_t largest_divisor_simd(uint64_t n){\n    __m256i divisor = _mm256_set1_epi64x(n);\n    __m256i mask = _mm256_set_epi64x(7, 6, 5, 4, 3, 2, 1, 0);\n    __m256i result = _mm256_and_si256(divisor, mask);\n    uint64_t result_arr[4];\n    _mm256_storeu_si256((__m256i*)result_arr, result);\n    for(int i=3; i>=0; i--){\n        if(n % result_arr[i] == 0){\n            return result_arr[i];\n        }\n    }\n    return 1;\n}\n```"}
{"task_id": "SimdBench_73_AVX", "completion": "```c\nuint64_t largest_divisor_simd(uint64_t n){\n    __m256i num = _mm256_set1_epi64x(n);\n    __m256i divisors = _mm256_setr_epi64x(2, 3, 5, 7, 11, 13, 17, 19);\n    __m256i result = _mm256_sub_epi64(num, divisors);\n    __m256i mask = _mm256_cmpgt_epi64(divisors, result);\n    __m256i masked_result = _mm256_blendv_epi8(result, _mm256_setzero_si256(), mask);\n    uint64_t* masked_result_arr = (uint64_t*)&masked_result;\n    uint64_t max_divisor = 0;\n    for (int i = 0; i < 4; i++) {\n        if (masked_result_arr[i] > max_divisor) {\n            max_divisor = masked_result_arr[i];\n        }\n    }\n    return max_divisor;\n}\n```"}
{"task_id": "SimdBench_73_AVX", "completion": "```c\nuint64_t largest_divisor_simd(uint64_t n){\n    __m256i num = _mm256_set1_epi64x(n);\n    __m256i divisors = _mm256_setr_epi64x(2, 3, 5, 7, 11, 13, 17, 19);\n    __m256i result = _mm256_sub_epi64(num, divisors);\n    __m256i mask = _mm256_cmpgt_epi64(num, divisors);\n    __m256i masked_result = _mm256_and_si256(result, mask);\n    __m128i lo = _mm256_castsi256_si128(masked_result);\n    __m128i hi = _mm256_extracti128_si256(masked_result, 1);\n    __m128i final_result = _mm_max_epu64(lo, hi);\n    return _mm_cvtsi128_si64(final_result);\n}\n```"}
{"task_id": "SimdBench_73_AVX", "completion": "```c\n#include <immintrin.h>\n#include <x86intrin.h>\n\nuint64_t largest_divisor_simd(uint64_t n){\n    __m256i divisor = _mm256_set1_epi64x(n);\n    __m256i one = _mm256_set1_epi64x(1);\n    __m256i mask = _mm256_set1_epi64x(0xFFFFFFFFFFFFFFFF);\n    \n    for (int i = 2; i <= 4; ++i) {\n        __m256i check = _mm256_set1_epi64x(i);\n        __m256i result = _mm256_and_si256(_mm256_cmpeq_epi64(_mm256_and_si256(divisor, mask), _mm256_setzero_si256()), _mm256_cmpeq_epi64(_mm256_and_si256(_mm256_sub_epi64(divisor, one), mask), _mm256_setzero_si256()));\n        if (_mm256_movemask_epi8(result) != 0) {\n            return n / i;\n        }\n    }\n    \n    return 1;\n}\n```"}
{"task_id": "SimdBench_74_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> factorize_simd(int n){\n    std::vector<int> factors;\n    int factor = 2;\n    while (n > 1) {\n        if (n % factor == 0) {\n            factors.push_back(factor);\n            n /= factor;\n        } else {\n            factor++;\n        }\n    }\n    \n    std::vector<int> result;\n    for (int i = 0; i < factors.size(); ++i) {\n        int count = 1;\n        while (i + 1 < factors.size() && factors[i] == factors[i + 1]) {\n            count++;\n            i++;\n        }\n        for (int j = 0; j < count; ++j) {\n            result.push_back(factors[i]);\n        }\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_74_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> factorize_simd(int n){\n    std::vector<int> factors;\n    int factor = 2;\n    while (n > 1) {\n        if (n % factor == 0) {\n            factors.push_back(factor);\n            n /= factor;\n        } else {\n            factor++;\n        }\n    }\n\n    std::vector<int> result;\n    for (int i = 0; i < factors.size(); ++i) {\n        int count = 1;\n        while (i + 1 < factors.size() && factors[i] == factors[i + 1]) {\n            count++;\n            i++;\n        }\n        for (int j = 0; j < count; ++j) {\n            result.push_back(factors[i]);\n        }\n    }\n\n    return result;\n}\n```  "}
{"task_id": "SimdBench_74_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> factorize_simd(int n){\n    std::vector<int> factors;\n    int factor = 2;\n    while (n > 1) {\n        if (n % factor == 0) {\n            factors.push_back(factor);\n            n /= factor;\n        } else {\n            factor++;\n        }\n    }\n    \n    std::vector<int> result;\n    for (int i = 0; i < factors.size(); ++i) {\n        int count = 1;\n        while (i + 1 < factors.size() && factors[i] == factors[i + 1]) {\n            count++;\n            i++;\n        }\n        for (int j = 0; j < count; ++j) {\n            result.push_back(factors[i]);\n        }\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_74_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> factorize_simd(int n){\n    std::vector<int> factors;\n    int factor = 2;\n    while (n > 1) {\n        if (n % factor == 0) {\n            factors.push_back(factor);\n            n /= factor;\n        } else {\n            factor++;\n        }\n    }\n    \n    std::vector<int> result;\n    for (size_t i = 0; i < factors.size(); ++i) {\n        int count = 1;\n        while (i + 1 < factors.size() && factors[i] == factors[i + 1]) {\n            count++;\n            i++;\n        }\n        for (int j = 0; j < count; ++j) {\n            result.push_back(factors[i]);\n        }\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_74_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> factorize_simd(int n){\n    std::vector<int> factors;\n    int factor = 2;\n    \n    while (n > 1) {\n        if (n % factor == 0) {\n            factors.push_back(factor);\n            n /= factor;\n        } else {\n            factor++;\n        }\n    }\n    \n    return factors;\n}\n```"}
{"task_id": "SimdBench_75_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nstd::vector<float> get_positive_simd(const std::vector<float> & l){\n    std::vector<float> result;\n    const int size = l.size();\n    const int simd_size = 8;\n    \n    for (int i = 0; i < size; i += simd_size) {\n        __m256 values = _mm256_loadu_ps(&l[i]);\n        __m256 zero = _mm256_setzero_ps();\n        __m256 mask = _mm256_cmp_ps(values, zero, _CMP_GT_OQ);\n        \n        __m256 positive_values = _mm256_and_ps(values, mask);\n        \n        float temp[simd_size];\n        _mm256_storeu_ps(temp, positive_values);\n        \n        for (int j = 0; j < simd_size; j++) {\n            if (temp[j] > 0) {\n                result.push_back(temp[j]);\n            }\n        }\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_75_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nstd::vector<float> get_positive_simd(const std::vector<float> & l){\n    std::vector<float> result;\n    const int size = l.size();\n    const int simd_size = 8;\n    \n    for (int i = 0; i < size; i += simd_size) {\n        __m256 values = _mm256_loadu_ps(&l[i]);\n        __m256 zero = _mm256_setzero_ps();\n        __m256 mask = _mm256_cmp_ps(values, zero, _CMP_GT_OQ);\n        __m256 positive_values = _mm256_and_ps(values, mask);\n        \n        alignas(32) float temp_result[simd_size];\n        _mm256_store_ps(temp_result, positive_values);\n        \n        for (int j = 0; j < simd_size; j++) {\n            if (temp_result[j] > 0) {\n                result.push_back(temp_result[j]);\n            }\n        }\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_75_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nstd::vector<float> get_positive_simd(const std::vector<float> & l){\n    std::vector<float> result;\n    const int size = l.size();\n    const int simd_size = 8;\n    \n    for (int i = 0; i < size; i += simd_size) {\n        __m256 values = _mm256_loadu_ps(&l[i]);\n        __m256 zero = _mm256_setzero_ps();\n        __m256 mask = _mm256_cmp_ps(values, zero, _CMP_GT_OQ);\n        \n        __m256 positive_values = _mm256_and_ps(values, mask);\n        \n        float temp[simd_size];\n        _mm256_storeu_ps(temp, positive_values);\n        \n        for (int j = 0; j < simd_size; j++) {\n            if (temp[j] > 0) {\n                result.push_back(temp[j]);\n            }\n        }\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_75_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nstd::vector<float> get_positive_simd(const std::vector<float> & l){\n    std::vector<float> result;\n    const int size = l.size();\n    const int simd_size = 8; // AVX can process 8 single-precision floats at a time\n\n    for (int i = 0; i < size; i += simd_size) {\n        __m256 values = _mm256_loadu_ps(&l[i]);\n        __m256 mask = _mm256_cmp_ps(values, _mm256_setzero_ps(), _CMP_GT_OQ);\n        __m256 positive_values = _mm256_and_ps(values, mask);\n\n        float temp[simd_size];\n        _mm256_storeu_ps(temp, positive_values);\n\n        for (int j = 0; j < simd_size; j++) {\n            if (temp[j] > 0) {\n                result.push_back(temp[j]);\n            }\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_75_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nstd::vector<float> get_positive_simd(const std::vector<float> & l){\n    std::vector<float> result;\n    const int size = l.size();\n    const int simd_size = 8;\n    \n    for (int i = 0; i < size; i += simd_size) {\n        __m256 values = _mm256_loadu_ps(&l[i]);\n        __m256 zero = _mm256_setzero_ps();\n        __m256 mask = _mm256_cmp_ps(values, zero, _CMP_GT_OQ);\n        \n        __m256 positive_values = _mm256_blendv_ps(zero, values, mask);\n        \n        float temp[simd_size];\n        _mm256_storeu_ps(temp, positive_values);\n        \n        for (int j = 0; j < simd_size; j++) {\n            if (temp[j] > 0) {\n                result.push_back(temp[j]);\n            }\n        }\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_76_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nbool is_prime_simd(int64_t n){\n    if (n <= 1) {\n        return false;\n    }\n    if (n <= 3) {\n        return true;\n    }\n    if (n % 2 == 0 || n % 3 == 0) {\n        return false;\n    }\n\n    int64_t limit = sqrt(n);\n    __m256i v_n = _mm256_set1_epi64x(n);\n    __m256i v_divisors = _mm256_set_epi64x(5, 7, 11, 13, 17, 19, 23, 29);\n\n    for (int64_t i = 31; i <= limit; i += 30) {\n        __m256i v_i = _mm256_set_epi64x(i, i + 2, i + 6, i + 8, i + 12, i + 18, i + 20, i + 26);\n        __m256i v_mod = _mm256_set1_epi64x(0);\n        v_mod = _mm256_sub_epi64(v_n, _mm256_mullo_epi64(v_divisors, _mm256_srli_epi64(v_n, 1)));\n        if (!_mm256_testz_si256(v_mod, v_mod)) {\n            return false;\n        }\n        v_divisors = _mm256_add_epi64(v_divisors, _mm256_set1_epi64x(30));\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_76_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nbool is_prime_simd(int64_t n){\n    if (n <= 1) {\n        return false;\n    }\n    \n    if (n <= 3) {\n        return true;\n    }\n    \n    if (n % 2 == 0 || n % 3 == 0) {\n        return false;\n    }\n    \n    int64_t limit = sqrt(n);\n    __m256i v_n = _mm256_set1_epi64x(n);\n    \n    for (int64_t i = 5; i <= limit; i += 6) {\n        __m256i v_i1 = _mm256_set_epi64x(i, i+1, i+2, i+3, i+4, i+5, i+6, i+7);\n        __m256i v_mod1 = _mm256_rem_epi64(v_n, v_i1);\n        __m256i v_i2 = _mm256_set_epi64x(i+2, i+3, i+4, i+5, i+6, i+7, i+8, i+9);\n        __m256i v_mod2 = _mm256_rem_epi64(v_n, v_i2);\n        \n        int64_t mod_arr1[4], mod_arr2[4];\n        _mm256_storeu_si256((__m256i*)mod_arr1, v_mod1);\n        _mm256_storeu_si256((__m256i*)mod_arr2, v_mod2);\n        \n        for (int j = 0; j < 4; j++) {\n            if (mod_arr1[j] == 0 || mod_arr2[j] == 0) {\n                return false;\n            }\n        }\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_76_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nbool is_prime_simd(int64_t n){\n    if (n <= 1) {\n        return false;\n    }\n    if (n <= 3) {\n        return true;\n    }\n    if (n % 2 == 0 || n % 3 == 0) {\n        return false;\n    }\n\n    int64_t limit = sqrt(n);\n    __m256i v_n = _mm256_set1_epi64x(n);\n    __m256i v_divisors = _mm256_setr_epi64x(5, 7, 11, 13, 17, 19, 23, 29);\n\n    for (int64_t i = 31; i <= limit; i += 30) {\n        __m256i v_i = _mm256_setr_epi64x(i, i + 2, i + 6, i + 8, i + 12, i + 18, i + 20, i + 26);\n        __m256i v_mod = _mm256_set1_epi64x(0);\n        v_mod = _mm256_sub_epi64(v_n, _mm256_mullo_epi64(v_divisors, _mm256_div_epi64(v_n, v_divisors)));\n        if (_mm256_testz_si256(v_mod, v_mod) == 0) {\n            return false;\n        }\n        v_divisors = _mm256_add_epi64(v_divisors, _mm256_set1_epi64x(30));\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_76_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nbool is_prime_simd(int64_t n){\n    if (n <= 1) {\n        return false;\n    }\n    if (n <= 3) {\n        return true;\n    }\n    if (n % 2 == 0 || n % 3 == 0) {\n        return false;\n    }\n\n    int64_t limit = sqrt(n);\n    __m256i v_n = _mm256_set1_epi64x(n);\n    __m256i v_divisors = _mm256_set_epi64x(5, 7, 11, 13, 17, 19, 23, 29);\n\n    for (int64_t i = 31; i <= limit; i += 30) {\n        __m256i v_i = _mm256_set_epi64x(i, i + 2, i + 6, i + 8, i + 12, i + 18, i + 20, i + 26);\n        __m256i v_mod = _mm256_set1_epi64x(0);\n        v_mod = _mm256_sub_epi64(v_n, _mm256_mullo_epi64(v_divisors, _mm256_srli_epi64(v_n, 1)));\n        if (_mm256_testz_si256(v_mod, v_mod)) {\n            return false;\n        }\n        v_divisors = _mm256_add_epi64(v_divisors, _mm256_set1_epi64x(30));\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_76_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nbool is_prime_simd(int64_t n){\n    if (n <= 1) {\n        return false;\n    }\n    if (n <= 3) {\n        return true;\n    }\n    if (n % 2 == 0 || n % 3 == 0) {\n        return false;\n    }\n    \n    int64_t limit = sqrt(n);\n    __m256i v_n = _mm256_set1_epi64x(n);\n    __m256i v_i = _mm256_set_epi64x(7, 11, 13, 17, 19, 23, 29, 31);\n    \n    for (int64_t i = 35; i <= limit; i += 30) {\n        __m256i v_div = _mm256_set_epi64x(i, i + 2, i + 6, i + 8, i + 12, i + 18, i + 20, i + 26);\n        __m256i v_mod = _mm256_set1_epi64x(0);\n        v_mod = _mm256_sub_epi64(v_n, v_div);\n        v_mod = _mm256_and_si256(v_mod, _mm256_set1_epi64x(0xFFFFFFFFFFFFFFFF));\n        \n        if (_mm256_testz_si256(v_mod, v_mod)) {\n            return false;\n        }\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_77_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nstd::string solve_simd(const std::string & s){\n    std::string result = s;\n    int len = s.size();\n    \n    __m256i lowercase_mask = _mm256_set1_epi8(0b11011111); // Mask to convert lowercase to uppercase\n    __m256i uppercase_mask = _mm256_set1_epi8(0b00100000); // Mask to convert uppercase to lowercase\n    __m256i letter_mask = _mm256_set1_epi8(0b00100000); // Mask to identify letters\n    \n    for (int i = 0; i < len; i += 32) {\n        __m256i chunk = _mm256_loadu_si256((__m256i*)(s.c_str() + i));\n        \n        // Check for letters\n        __m256i is_letter = _mm256_and_si256(_mm256_cmpgt_epi8(chunk, _mm256_set1_epi8(64)), _mm256_cmplt_epi8(chunk, _mm256_set1_epi8(123)));\n        \n        // Convert lowercase to uppercase\n        __m256i lowercase = _mm256_and_si256(chunk, lowercase_mask);\n        __m256i uppercase = _mm256_and_si256(chunk, uppercase_mask);\n        chunk = _mm256_or_si256(uppercase, _mm256_and_si256(_mm256_xor_si256(lowercase, lowercase_mask), is_letter));\n        \n        // Reverse the chunk\n        __m256i rev_chunk = _mm256_shuffle_epi8(chunk, _mm256_set_epi8(\n            31, 30, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16,\n            15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 0\n        ));\n        \n        _mm256_storeu_si256((__m256i*)(result.c_str() + i), rev_chunk);\n    }\n    \n    // Reverse the whole string if no letters were found\n    if (_mm256_testz_si256(is_letter, is_letter)) {\n        std::reverse(result.begin(), result.end());\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_77_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nstd::string solve_simd(const std::string & s){\n    std::string result = s;\n    int len = s.size();\n    \n    __m256i lower_mask = _mm256_set1_epi8(0b11011111); // Mask to convert lowercase to uppercase\n    __m256i upper_mask = _mm256_set1_epi8(0b00100000); // Mask to convert uppercase to lowercase\n    __m256i letter_mask = _mm256_set1_epi8(0b00110111); // Mask to check if character is a letter\n    \n    for (int i = 0; i < len; i += 32) {\n        __m256i chunk = _mm256_loadu_si256((__m256i*)(s.c_str() + i));\n        \n        // Check if character is a letter\n        __m256i is_letter = _mm256_and_si256(_mm256_cmpeq_epi8(_mm256_and_si256(chunk, letter_mask), _mm256_setzero_si256()), _mm256_set1_epi8(0xFF));\n        \n        // Reverse the case of letters\n        __m256i lower_case = _mm256_and_si256(chunk, lower_mask);\n        __m256i upper_case = _mm256_and_si256(chunk, upper_mask);\n        chunk = _mm256_or_si256(_mm256_or_si256(lower_case, upper_case), is_letter);\n        \n        // Reverse the chunk\n        __m256i rev_chunk = _mm256_permutevar8x32_epi32(chunk, _mm256_set_epi32(7, 6, 5, 4, 3, 2, 1, 0));\n        \n        _mm256_storeu_si256((__m256i*)(result.c_str() + i), rev_chunk);\n    }\n    \n    std::reverse(result.begin(), result.end());\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_77_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nstd::string solve_simd(const std::string & s){\n    std::string result = s;\n    int length = s.size();\n    \n    __m256i lowercase_mask = _mm256_set1_epi8(0b11011111); // Mask to convert lowercase to uppercase\n    __m256i uppercase_mask = _mm256_set1_epi8(0b00100000); // Mask to convert uppercase to lowercase\n    __m256i letter_mask = _mm256_set1_epi8(0b00100000); // Mask to identify letters\n    \n    for (int i = 0; i < length; i += 32) {\n        __m256i chunk = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&s[i]));\n        \n        // Check for letters\n        __m256i is_letter = _mm256_and_si256(_mm256_cmpgt_epi8(chunk, _mm256_set1_epi8(64)), _mm256_cmplt_epi8(chunk, _mm256_set1_epi8(123)));\n        \n        // Convert case\n        __m256i lowercase = _mm256_and_si256(chunk, is_letter);\n        __m256i uppercase = _mm256_and_si256(chunk, is_letter);\n        uppercase = _mm256_xor_si256(uppercase, uppercase_mask);\n        lower"}
{"task_id": "SimdBench_77_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nstd::string solve_simd(const std::string & s){\n    std::string result = s;\n    const int n = s.size();\n    const __m256i upper_mask = _mm256_set1_epi8(0xDF); // Mask to convert lowercase to uppercase\n    const __m256i lower_mask = _mm256_set1_epi8(0x20); // Mask to convert uppercase to lowercase\n    const __m256i letter_mask = _mm256_set1_epi8(0x1F); // Mask to detect letters\n\n    for (int i = 0; i < n; i += 32) {\n        __m256i chunk = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&s[i]));\n        __m256i is_letter = _mm256_and_si256(_mm256_cmpgt_epi8(chunk, _mm256_set1_epi8('a' - 1)),\n                                             _mm256_cmplt_epi8(chunk, _mm256_set1_epi8('z' + 1)));\n        __m256i is_upper = _mm256_and_si256(is_letter, _mm256_cmpgt_epi8(chunk, _mm256_set1_epi8('Z')));\n        __m256i is_lower = _mm256_and_si256(is_letter, _mm256_cmpgt_epi8(chunk, _mm256_set1_epi8('z')));\n        \n        __m256i upper_case = _mm256_and_si256(chunk, upper_mask);\n        __m256i lower_case = _mm256_and_si256(chunk, lower_mask);\n        \n        __m256i new_chunk = _mm256_blendv_epi8(chunk, _mm256_xor_si256(upper_case, lower_case), is_upper);\n        new_chunk = _mm256_blendv_epi8(new_chunk, _mm256_xor_si256(upper_case, lower_case), is_lower);\n        \n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(&result[i]), new_chunk);\n    }\n\n    for (int i = 0; i < n / 2; ++i) {\n        std::swap(result[i], result[n - i - 1]);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_77_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nstd::string solve_simd(const std::string & s){\n    std::string result = s;\n    int length = s.size();\n\n    __m256i lowercase_mask = _mm256_set1_epi8(0b11011111); // Mask to convert lowercase to uppercase\n    __m256i uppercase_mask = _mm256_set1_epi8(0b00100001); // Mask to convert uppercase to lowercase\n    __m256i letter_mask = _mm256_set1_epi8(0b00100000); // Mask to detect letters\n\n    for (int i = 0; i < length; i += 32) {\n        __m256i chunk = _mm256_loadu_si256((__m256i*)(s.c_str() + i));\n        __m256i is_letter = _mm256_and_si256(_mm256_cmpgt_epi8(chunk, _mm256_set1_epi8(64)), _mm256_cmplt_epi8(chunk, _mm256_set1_epi8(123)));\n        __m256i lowercase = _mm256_and_si256(chunk, is_letter);\n        __m256i uppercase = _mm256_xor_si256(lowercase, letter_mask);\n        __m256i result_chunk = _mm256_blendv_epi8(chunk, uppercase, _mm256_cmpeq_epi8(chunk, lowercase));\n        result_chunk = _mm256_xor_si256(result_chunk, _mm256_and_si256(is_letter, lowercase_mask));\n        result_chunk = _mm256_xor_si256(result_chunk, _mm256_andnot_si256(is_letter, _mm256_permutevar8x32_epi32(chunk, _mm256_set_epi32(7, 6, 5, 4, 3, 2, 1, 0))));\n        _mm256_storeu_si256((__m256i*)(result.data() + i), result_chunk);\n    }\n\n    for (int i = 0; i < length / 2; ++i) {\n        std::swap(result[i], result[length - i - 1]);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_78_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nstd::vector<int> sort_third_simd(std::vector<int> l){\n    const int size = l.size();\n    const int remainder = size % 8;\n    const int loop_end = size - remainder;\n\n    __m256i mask = _mm256_setr_epi32(0, 0, -1, 0, 0, -1, 0, 0);\n\n    for (int i = 0; i < loop_end; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&l[i]);\n        __m256i sorted = _mm256_permutevar8x32_epi32(vec, mask);\n        _mm256_storeu_si256((__m256i*)&l[i], sorted);\n    }\n\n    for (int i = loop_end; i < size; i += 1) {\n        if (i % 3 == 0) {\n            int temp = l[i];\n            for (int j = i; j > 0 && j % 3 == 0; j -= 3) {\n                l[j] = l[j - 3];\n            }\n            l[i - 2] = temp;\n        }\n    }\n\n    return l;\n}\n```"}
{"task_id": "SimdBench_78_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nstd::vector<int> sort_third_simd(std::vector<int> l){\n    const int size = l.size();\n    const int remainder = size % 8;\n    const int loopSize = size - remainder;\n\n    for (int i = 0; i < loopSize; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&l[i]);\n        __m256i mask = _mm256_set_epi32(0, 0, 0, -1, 0, 0, -1, 0);\n        __m256i sorted = _mm256_permutevar8x32_epi32(vec, mask);\n        _mm256_storeu_si256((__m256i*)&l[i], sorted);\n    }\n\n    for (int i = loopSize; i < size; i += 1) {\n        if (i % 3 == 0) {\n            int temp = l[i];\n            for (int j = i; j > 0; j -= 3) {\n                l[j] = l[j - 3];\n            }\n            l[i - 2] = temp;\n        }\n    }\n\n    return l;\n}\n```"}
{"task_id": "SimdBench_78_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nstd::vector<int> sort_third_simd(std::vector<int> l){\n    const int size = l.size();\n    const int remainder = size % 8;\n    const int loop_size = size - remainder;\n\n    for (int i = 0; i < loop_size; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&l[i]);\n        __m256i mask = _mm256_set_epi32(0, 0, 0, -1, 0, 0, -1, 0);\n        __m256i sorted = _mm256_permutevar8x32_epi32(vec, mask);\n        _mm256_storeu_si256((__m256i*)&l[i], sorted);\n    }\n\n    for (int i = loop_size; i < size; i += 1) {\n        if (i % 3 == 0) {\n            int temp = l[i];\n            for (int j = i; j > 0 && j % 3 == 0; j -= 3) {\n                l[j] = l[j - 3];\n            }\n            l[i - 2] = temp;\n        }\n    }\n\n    return l;\n}\n```"}
{"task_id": "SimdBench_78_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nstd::vector<int> sort_third_simd(std::vector<int> l){\n    const int size = l.size();\n    const int remainder = size % 8;\n    const int loop_end = size - remainder;\n\n    __m256i permute_mask = _mm256_set_epi32(7, 6, 5, 4, 3, 2, 1, 0);\n\n    for (int i = 0; i < loop_end; i += 8) {\n        __m256i input = _mm256_loadu_si256((__m256i*)&l[i]);\n        __m256i sorted = _mm256_permutevar8x32_epi32(input, permute_mask);\n        _mm256_storeu_si256((__m256i*)&l[i], sorted);\n    }\n\n    if (remainder > 0) {\n        int temp[8];\n        __m256i input = _mm256_undefined_si256();\n        _mm256_storeu_si256((__m256i*)temp, input);\n        for (int i = 0; i < remainder; ++i) {\n            l[size - remainder + i] = temp[i];\n        }\n    }\n\n    return l;\n}\n```"}
{"task_id": "SimdBench_78_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nstd::vector<int> sort_third_simd(std::vector<int> l){\n    int size = l.size();\n    int remainder = size % 8;\n    int full_chunks = size - remainder;\n\n    for (int i = 0; i < full_chunks; i += 8) {\n        __m256i vec_l = _mm256_loadu_si256((__m256i*)&l[i]);\n        __m256i mask = _mm256_set_epi32(0, 0, -1, 0, 0, -1, 0, 0);\n        __m256i sorted = _mm256_permutevar8x32_epi32(vec_l, mask);\n        _mm256_storeu_si256((__m256i*)&l[i], sorted);\n    }\n\n    for (int i = full_chunks; i < size; i += 1) {\n        if (i % 3 == 0) {\n            int temp = l[i];\n            for (int j = i; j > 0; j -= 3) {\n                l[j] = l[j - 3];\n            }\n            l[i - 2] = temp;\n        }\n    }\n\n    return l;\n}\n```"}
{"task_id": "SimdBench_79_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nfloat max_element_simd(std::vector<float> l){\n    __m256 max_vec = _mm256_set1_ps(-INFINITY);\n    int size = l.size();\n    int i = 0;\n    \n    for (; i <= size - 8; i += 8) {\n        __m256 input_vec = _mm256_loadu_ps(&l[i]);\n        max_vec = _mm256_max_ps(max_vec, input_vec);\n    }\n    \n    float max_elements[8];\n    _mm256_storeu_ps(max_elements, max_vec);\n    \n    float max_element = -INFINITY;\n    for (int j = 0; j < 8; j++) {\n        if (max_elements[j] > max_element) {\n            max_element = max_elements[j];\n        }\n    }\n    \n    for (; i < size; i++) {\n        if (l[i] > max_element) {\n            max_element = l[i];\n        }\n    }\n    \n    return max_element;\n}\n```"}
{"task_id": "SimdBench_79_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nfloat max_element_simd(std::vector<float> l){\n    __m256 max_vec = _mm256_set1_ps(-INFINITY);\n    int size = l.size();\n    int i = 0;\n    \n    for (; i + 8 <= size; i += 8) {\n        __m256 input_vec = _mm256_loadu_ps(&l[i]);\n        max_vec = _mm256_max_ps(max_vec, input_vec);\n    }\n    \n    float max_values[8];\n    _mm256_storeu_ps(max_values, max_vec);\n    \n    float max_val = -INFINITY;\n    for (int j = 0; j < 8; j++) {\n        if (max_values[j] > max_val) {\n            max_val = max_values[j];\n        }\n    }\n    \n    for (; i < size; i++) {\n        if (l[i] > max_val) {\n            max_val = l[i];\n        }\n    }\n    \n    return max_val;\n}\n```"}
{"task_id": "SimdBench_79_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nfloat max_element_simd(std::vector<float> l){\n    __m256 max_val = _mm256_set1_ps(l[0]);\n    for (size_t i = 0; i < l.size(); i += 8) {\n        __m256 values = _mm256_loadu_ps(&l[i]);\n        max_val = _mm256_max_ps(max_val, values);\n    }\n\n    float result[8];\n    _mm256_storeu_ps(result, max_val);\n\n    float max_element = result[0];\n    for (int i = 1; i < 8; i++) {\n        if (result[i] > max_element) {\n            max_element = result[i];\n        }\n    }\n\n    return max_element;\n}\n```"}
{"task_id": "SimdBench_79_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nfloat max_element_simd(std::vector<float> l){\n    __m256 max_vec = _mm256_set1_ps(std::numeric_limits<float>::lowest());\n    int size = l.size();\n    int i = 0;\n\n    for (; i + 8 <= size; i += 8) {\n        __m256 data = _mm256_loadu_ps(&l[i]);\n        max_vec = _mm256_max_ps(max_vec, data);\n    }\n\n    float max_elements[8];\n    _mm256_storeu_ps(max_elements, max_vec);\n\n    float max_val = std::numeric_limits<float>::lowest();\n    for (int j = 0; j < 8; j++) {\n        max_val = std::max(max_val, max_elements[j]);\n    }\n\n    for (; i < size; i++) {\n        max_val = std::max(max_val, l[i]);\n    }\n\n    return max_val;\n}\n```"}
{"task_id": "SimdBench_79_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nfloat max_element_simd(std::vector<float> l){\n    __m256 max_vec = _mm256_set1_ps(-INFINITY);\n    int size = l.size();\n    int i = 0;\n    \n    for (; i <= size - 8; i += 8) {\n        __m256 data = _mm256_loadu_ps(&l[i]);\n        max_vec = _mm256_max_ps(max_vec, data);\n    }\n    \n    float max_elements[8];\n    _mm256_storeu_ps(max_elements, max_vec);\n    \n    float max_value = -INFINITY;\n    for (int j = 0; j < 8; j++) {\n        if (max_elements[j] > max_value) {\n            max_value = max_elements[j];\n        }\n    }\n    \n    for (; i < size; i++) {\n        if (l[i] > max_value) {\n            max_value = l[i];\n        }\n    }\n    \n    return max_value;\n}\n```"}
{"task_id": "SimdBench_80_AVX", "completion": "```c\n#include <immintrin.h>\n#include <x86intrin.h>\n\nint fizz_buzz_simd(int n){\n    __m256i sevens = _mm256_set1_epi8(7);\n    __m256i elevens = _mm256_set1_epi8(11);\n    __m256i ethirteens = _mm256_set1_epi8(13);\n    int count = 0;\n\n    for (int i = 0; i < n; i += 32) {\n        __m256i nums = _mm256_setr_epi8(i, i+1, i+2, i+3, i+4, i+5, i+6, i+7, i+8, i+9, i+10, i+11, i+12, i+13, i+14, i+15, i+16, i+17, i+18, i+19, i+20, i+21, i+22, i+23, i+24, i+25, i+26, i+27, i+28, i+29, i+30, i+31);\n        __m256i mod11 = _mm256_and_si256(nums, _mm256_set1_epi8(11));\n        __m256i mod13 = _mm256_and_si256(nums, _mm256_set1_epi8(13));\n        __m256i div11 = _mm256_cmpeq_epi8(mod11, _mm256_setzero_si256());\n        __m256i div13 = _mm256_cmpeq_epi8(mod13, _mm256_setzero_si256());\n        __m256i div = _mm256_or_si256(div11, div13);\n        __m256i compare = _mm256_cmpeq_epi8(nums, sevens);\n        __m256i result = _mm256_and_si256(compare, div);\n        count += _mm_popcnt_u32(_mm256_movemask_epi8(result));\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_80_AVX", "completion": "```c\n#include <immintrin.h>\n#include <x86intrin.h>\n\nint fizz_buzz_simd(int n){\n    __m256i count = _mm256_setzero_si256();\n    for (int i = 0; i < n; i += 8) {\n        __m256i values = _mm256_setr_epi32(i, i + 1, i + 2, i + 3, i + 4, i + 5, i + 6, i + 7);\n        __m256i div_11 = _mm256_and_si256(_mm256_cmpeq_epi32(_mm256_setzero_si256(), _mm256_setzero_si256()), _mm256_set1_epi32(11));\n        __m256i div_13 = _mm256_and_si256(_mm256_cmpeq_epi32(_mm256_setzero_si256(), _mm256_setzero_si256()), _mm256_set1_epi32(13));\n        __m256i mod_11 = _mm256_and_si256(values, _mm256_set1_epi32(10));\n        __m256i mod_13 = _mm256_and_si256(values, _mm256_set1_epi32(12));\n        __m256i is_divisible = _mm256_or_si256(_mm256_cmpeq_epi32(mod_11, _mm256_setzero_si256()), _mm256_cmpeq_epi32(mod_13, _mm256_setzero_si256()));\n        __m256i digit_7 = _mm256_setr_epi32(7, 7, 7, 7, 7, 7, 7, 7);\n        __m256i count_7 = _mm256_cmpeq_epi32(values, digit_7);\n        count = _mm256_add_epi32(count, _mm256_and_si256(is_divisible, count_7));\n    }\n    int result[8];\n    _mm256_storeu_si256((__m256i*)result, count);\n    return result[0] + result[1] + result[2] + result[3] + result[4] + result[5] + result[6] + result[7];\n}\n```"}
{"task_id": "SimdBench_80_AVX", "completion": "```c\n#include <immintrin.h>\n#include <x86intrin.h>\n\nint fizz_buzz_simd(int n){\n    __m256i count = _mm256_setzero_si256();\n    for (int i = 0; i < n; i += 8) {\n        __m256i values = _mm256_setr_epi32(i, i+1, i+2, i+3, i+4, i+5, i+6, i+7);\n        __m256i div_11 = _mm256_and_si256(_mm256_cmpeq_epi32(_mm256_setzero_si256(), _mm256_setzero_si256()), _mm256_cmpeq_epi32(_mm256_setzero_si256(), _mm256_setzero_si256()));\n        __m256i div_13 = _mm256_and_si256(_mm256_cmpeq_epi32(_mm256_setzero_si256(), _mm256_setzero_si256()), _mm256_cmpeq_epi32(_mm256_setzero_si256(), _mm256_setzero_si256()));\n        __m256i div_7 = _mm256_and_si256(_mm256_cmpeq_epi32(_mm256_setzero_si256(), _mm256_setzero_si256()), _mm256_cmpeq_epi32(_mm256_setzero_si256(), _mm256_setzero_si256()));\n        \n        for (int j = 0; j < 8; j++) {\n            __m256i curr_val = _mm256_set1_epi32(i + j);\n            __m256i mod_11 = _mm256_and_si256(_mm256_cmpeq_epi32(_mm256_setzero_si256(), _mm256_setzero_si256()), _mm256_cmpeq_epi32(_mm256_setzero_si256(), _mm256_setzero_si256()));\n            __m256i mod_13 = _mm256_and_si256(_mm256_cmpeq_epi32(_mm256_setzero_si256(), _mm256_setzero_si256()), _mm256_cmpeq_epi32(_mm256_setzero_si256(), _mm256_setzero_si256()));\n            __m256i mod_7 = _mm256_and_si256(_mm256_cmpeq_epi32(_mm256_setzero_si256(), _mm256_setzero_si256()), _mm256_cmpeq_epi32(_mm256_setzero_si256(), _mm256_setzero_si256()));\n            \n            div_11 = _mm256_or_si256(div_11, mod_11);\n            div_13 = _mm256_or_si256(div_13, mod_13);\n            div_7 = _mm256_or_si256(div_7, mod_7);\n        }\n        \n        __m256i div_11_13 = _mm256_or_si256(div_11, div_13);\n        __m256i div_11_13_7 = _mm256_and_si256(div_11_13, div_7);\n        \n        count = _mm256_add_epi32(count, _mm256_sad_epu8(_mm256_castsi256_si128(div_11_13_7), _mm256_extractf128_si256(div_11_13_7, 1)));\n    }\n    \n    int result[8];\n    _mm256_storeu_si256((__m256i*)result, count);\n    \n    int total_count = 0;\n    for (int i = 0; i < 8; i++) {\n        total_count += result[i];\n    }\n    \n    return total_count;\n}\n```"}
{"task_id": "SimdBench_80_AVX", "completion": "```c\n#include <immintrin.h>\n#include <x86intrin.h>\n\nint fizz_buzz_simd(int n){\n    int count = 0;\n    __m256i sevens = _mm256_set1_epi32(7);\n    __m256i elevens = _mm256_set1_epi32(11);\n    __m256i ethirteens = _mm256_set1_epi32(13);\n    for (int i = 0; i < n; i += 8) {\n        __m256i values = _mm256_setr_epi32(i, i+1, i+2, i+3, i+4, i+5, i+6, i+7);\n        __m256i mod11 = _mm256_and_si256(_mm256_set1_epi32(1), _mm256_cmpeq_epi32(_mm256_setzero_si256(), _mm256_and_si256(values, elevens)));\n        __m256i mod13 = _mm256_and_si256(_mm256_set1_epi32(1), _mm256_cmpeq_epi32(_mm256_setzero_si256(), _mm256_and_si256(values, ethirteens)));\n        __m256i mod = _mm256_or_si256(mod11, mod13);\n        __m256i div = _mm256_and_si256(_mm256_set1_epi32(1), _mm256_cmpeq_epi32(_mm256_setzero_si256(), mod));\n        __m256i sevens_count = _mm256_and_si256(_mm256_set1_epi32(1), _mm256_cmpeq_epi32(sevens, _mm256_and_si256(values, sevens)));\n        count += _mm_popcnt_u32(_mm256_movemask_ps(_mm256_castsi256_ps(_mm256_and_si256(div, sevens_count))));\n    }\n    return count;\n}\n```"}
{"task_id": "SimdBench_80_AVX", "completion": "```c\n#include <immintrin.h>\n#include <x86intrin.h>\n\nint fizz_buzz_simd(int n){\n    __m256i count = _mm256_setzero_si256();\n    for (int i = 0; i < n; i += 8) {\n        __m256i values = _mm256_setr_epi32(i, i+1, i+2, i+3, i+4, i+5, i+6, i+7);\n        __m256i div_11 = _mm256_and_si256(_mm256_cmpeq_epi32(_mm256_setzero_si256(), _mm256_setzero_si256()), _mm256_cmpeq_epi32(_mm256_setzero_si256(), _mm256_setzero_si256()));\n        __m256i div_13 = _mm256_and_si256(_mm256_cmpeq_epi32(_mm256_setzero_si256(), _mm256_setzero_si256()), _mm256_cmpeq_epi32(_mm256_setzero_si256(), _mm256_setzero_si256()));\n        __m256i has_7 = _mm256_setzero_si256();\n        \n        for (int j = 0; j < 8; j++) {\n            __m256i num = _mm256_add_epi32(values, _mm256_set1_epi32(j));\n            __m256i mod_11 = _mm256_and_si256(_mm256_cmpeq_epi32(_mm256_setzero_si256(), _mm256_setzero_si256()), _mm256_cmpeq_epi32(_mm256_setzero_si256(), _mm256_setzero_si256()));\n            __m256i mod_13 = _mm256_and_si256(_mm256_cmpeq_epi32(_mm256_setzero_si256(), _mm256_setzero_si256()), _mm256_cmpeq_epi32(_mm256_setzero_si256(), _mm256_setzero_si256()));\n            __m256i has_7_mask = _mm256_or_si256(_mm256_cmpeq_epi32(_mm256_setzero_si256(), _mm256_setzero_si256()), _mm256_cmpeq_epi32(_mm256_setzero_si256(), _mm256_setzero_si256()));\n            has_7 = _mm256_add_epi32(has_7, has_7_mask);\n        }\n        \n        count = _mm256_add_epi32(count, has_7);\n    }\n    \n    int result[8];\n    _mm256_storeu_si256((__m256i*)result, count);\n    \n    int total_count = 0;\n    for (int i = 0; i < 8; i++) {\n        total_count += result[i];\n    }\n    \n    return total_count;\n}\n```"}
{"task_id": "SimdBench_81_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nstd::vector<float> sort_even_simd(std::vector<float> l){\n    int n = l.size();\n    int num_floats = n / 8;\n    std::vector<float> result(n);\n\n    for (int i = 0; i < num_floats; ++i) {\n        __m256 vec = _mm256_loadu_ps(&l[i * 8]);\n        __m256 sorted = _mm256_permute_ps(vec, _MM_SHUFFLE(1, 0, 3, 2));\n        _mm256_storeu_ps(&result[i * 8], _mm256_blend_ps(vec, sorted, 0xAA));\n    }\n\n    for (int i = num_floats * 8; i < n; ++i) {\n        result[i] = l[i];\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_81_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nstd::vector<float> sort_even_simd(std::vector<float> l){\n    int n = l.size();\n    int num_floats = n / 8;\n    std::vector<float> result(n);\n\n    for (int i = 0; i < num_floats; ++i) {\n        __m256 vec = _mm256_loadu_ps(&l[i * 8]);\n        __m256 sorted = _mm256_permute_ps(vec, _MM_SHUFFLE(2, 3, 0, 1));\n        _mm256_storeu_ps(&result[i * 8], _mm256_blend_ps(vec, sorted, 0b10101010));\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_81_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nstd::vector<float> sort_even_simd(std::vector<float> l){\n    int n = l.size();\n    int m = n / 2;\n    std::vector<float> result(n);\n\n    __m256i indices = _mm256_setr_epi32(0, 2, 4, 6, 8, 10, 12, 14);\n    __m256i permute_indices = _mm256_setr_epi32(0, 2, 4, 6, 1, 3, 5, 7);\n\n    for (int i = 0; i < m; i += 8) {\n        __m256i idx = _mm256_add_epi32(indices, _mm256_set1_epi32(i));\n        __m256i permuted_idx = _mm256_permutevar8x32_epi32(idx, permute_indices);\n\n        __m256 values = _mm256_i32gather_ps(l.data(), permuted_idx, 4);\n        __m256 sorted_values = _mm256_permute_ps(values, _MM_SHUFFLE(1, 0, 3, 2));\n\n        _mm256_storeu_ps(result.data() + i, values);\n        _mm256_storeu_ps(result.data() + i + m, sorted_values);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_81_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nstd::vector<float> sort_even_simd(std::vector<float> l){\n    int n = l.size();\n    int m = n / 2;\n    std::vector<float> result(n);\n\n    __m256i indices = _mm256_setr_epi32(0, 2, 4, 6, 8, 10, 12, 14);\n    __m256i permute_indices = _mm256_setr_epi32(0, 2, 4, 6, 1, 3, 5, 7);\n\n    for (int i = 0; i < m; i += 8) {\n        __m256 values = _mm256_loadu_ps(&l[i * 2]);\n        __m256 sorted_values = _mm256_permutevar8x32_ps(values, permute_indices);\n        _mm256_storeu_ps(&result[i * 2], sorted_values);\n    }\n\n    for (int i = m; i < n; ++i) {\n        result[i] = l[i];\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_81_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nstd::vector<float> sort_even_simd(std::vector<float> l){\n    int n = l.size();\n    int m = n / 2;\n    std::vector<float> result(n);\n    \n    __m256i indices = _mm256_setr_epi32(0, 2, 4, 6, 8, 10, 12, 14);\n    __m256i permute_indices = _mm256_setr_epi32(0, 2, 4, 6, 1, 3, 5, 7);\n    \n    for (int i = 0; i < m; i += 8) {\n        __m256i v_indices = _mm256_add_epi32(indices, _mm256_set1_epi32(i));\n        __m256i v_permute_indices = _mm256_add_epi32(permute_indices, _mm256_set1_epi32(i));\n        \n        __m256 v_l = _mm256_i32gather_ps(l.data(), v_indices, 4);\n        __m256 v_sorted = _mm256_permutevar8x32_ps(v_l, v_permute_indices);\n        \n        _mm256_storeu_ps(result.data() + i, v_l);\n        _mm256_storeu_ps(result.data() + i + m, v_sorted);\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_82_AVX", "completion": "```\nbool triples_sum_to_zero_simd(std::vector<int> l){\n    const int n = l.size();\n    if (n < 3) {\n        return false;\n    }\n\n    for (int i = 0; i < n - 2; ++i) {\n        __m256i v1 = _mm256_set1_epi32(l[i]);\n        for (int j = i + 1; j < n - 1; ++j) {\n            __m256i v2 = _mm256_set1_epi32(l[j]);\n            for (int k = j + 1; k < n; ++k) {\n                __m256i v3 = _mm256_set1_epi32(l[k]);\n                __m256i sum = _mm256_add_epi32(v1, _mm256_add_epi32(v2, v3));\n                __m256i cmp = _mm256_cmpeq_epi32(sum, _mm256_setzero_si256());\n                int mask = _mm256_movemask_ps((__m256)cmp);\n                if (mask != 0) {\n                    return true;\n                }\n            }\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_82_AVX", "completion": "```\nbool triples_sum_to_zero_simd(std::vector<int> l){\n    const int n = l.size();\n    if (n < 3) {\n        return false;\n    }\n\n    for (int i = 0; i < n - 2; ++i) {\n        __m256i v1 = _mm256_set1_epi32(l[i]);\n        for (int j = i + 1; j < n - 1; ++j) {\n            __m256i v2 = _mm256_set1_epi32(l[j]);\n            for (int k = j + 1; k < n; ++k) {\n                __m256i v3 = _mm256_set1_epi32(l[k]);\n                __m256i sum = _mm256_add_epi32(v1, _mm256_add_epi32(v2, v3));\n                __m256i cmp = _mm256_cmpeq_epi32(sum, _mm256_setzero_si256());\n                int mask = _mm256_movemask_ps((__m256)cmp);\n                if (mask != 0) {\n                    return true;\n                }\n            }\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_82_AVX", "completion": "```\nbool triples_sum_to_zero_simd(std::vector<int> l){\n    const int n = l.size();\n    for (int i = 0; i < n - 2; ++i) {\n        __m256i v1 = _mm256_set1_epi32(l[i]);\n        for (int j = i + 1; j < n - 1; ++j) {\n            __m256i v2 = _mm256_set1_epi32(l[j]);\n            for (int k = j + 1; k < n; ++k) {\n                __m256i v3 = _mm256_set1_epi32(l[k]);\n                __m256i sum = _mm256_add_epi32(v1, _mm256_add_epi32(v2, v3));\n                __m256i cmp = _mm256_cmpeq_epi32(sum, _mm256_setzero_si256());\n                int mask = _mm256_movemask_ps((__m256)cmp);\n                if (mask != 0) {\n                    return true;\n                }\n            }\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_82_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nbool triples_sum_to_zero_simd(std::vector<int> l){\n    const int size = l.size();\n    for (int i = 0; i < size - 2; ++i) {\n        __m256i v1 = _mm256_set1_epi32(l[i]);\n        for (int j = i + 1; j < size - 1; ++j) {\n            __m256i v2 = _mm256_set1_epi32(l[j]);\n            for (int k = j + 1; k < size; ++k) {\n                __m256i v3 = _mm256_set1_epi32(l[k]);\n                __m256i sum = _mm256_add_epi32(v1, _mm256_add_epi32(v2, v3));\n                __m256i cmp = _mm256_cmpeq_epi32(sum, _mm256_setzero_si256());\n                int mask = _mm256_movemask_ps(_mm256_castsi256_ps(cmp));\n                if (mask != 0) {\n                    return true;\n                }\n            }\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_82_AVX", "completion": "```\nbool triples_sum_to_zero_simd(std::vector<int> l){\n    const int size = l.size();\n    if(size < 3) return false;\n\n    for(int i = 0; i < size - 2; ++i){\n        __m256i v1 = _mm256_set1_epi32(l[i]);\n        for(int j = i + 1; j < size - 1; ++j){\n            __m256i v2 = _mm256_set1_epi32(l[j]);\n            for(int k = j + 1; k < size; ++k){\n                __m256i v3 = _mm256_set1_epi32(l[k]);\n                __m256i sum = _mm256_add_epi32(v1, _mm256_add_epi32(v2, v3));\n                __m256i zero = _mm256_setzero_si256();\n                __m256i cmp = _mm256_cmpeq_epi32(sum, zero);\n                int mask = _mm256_movemask_ps((__m256)cmp);\n                if(mask != 0) return true;\n            }\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_83_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nstd::vector<int> incr_list_simd(std::vector<int> l){\n    const int size = l.size();\n    const int remainder = size % 8;\n    const int loop_end = size - remainder;\n\n    __m256i increment = _mm256_set1_epi32(1);\n\n    for (int i = 0; i < loop_end; i += 8) {\n        __m256i input = _mm256_loadu_si256((__m256i*)&l[i]);\n        __m256i result = _mm256_add_epi32(input, increment);\n        _mm256_storeu_si256((__m256i*)&l[i], result);\n    }\n\n    for (int i = loop_end; i < size; ++i) {\n        l[i] += 1;\n    }\n\n    return l;\n}\n```"}
{"task_id": "SimdBench_83_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nstd::vector<int> incr_list_simd(std::vector<int> l){\n    const int size = l.size();\n    const int remainder = size % 8;\n    const int loop_end = size - remainder;\n\n    __m256i increment = _mm256_set1_epi32(1);\n\n    for (int i = 0; i < loop_end; i += 8) {\n        __m256i input = _mm256_loadu_si256((__m256i*)&l[i]);\n        __m256i result = _mm256_add_epi32(input, increment);\n        _mm256_storeu_si256((__m256i*)&l[i], result);\n    }\n\n    for (int i = loop_end; i < size; ++i) {\n        l[i] += 1;\n    }\n\n    return l;\n}\n```"}
{"task_id": "SimdBench_83_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nstd::vector<int> incr_list_simd(std::vector<int> l){\n    const int size = l.size();\n    const int remainder = size % 8;\n    const int loop_end = size - remainder;\n\n    __m256i increment = _mm256_set1_epi32(1);\n    for (int i = 0; i < loop_end; i += 8) {\n        __m256i input = _mm256_loadu_si256((__m256i*)&l[i]);\n        __m256i result = _mm256_add_epi32(input, increment);\n        _mm256_storeu_si256((__m256i*)&l[i], result);\n    }\n\n    for (int i = loop_end; i < size; ++i) {\n        l[i]++;\n    }\n\n    return l;\n}\n```"}
{"task_id": "SimdBench_83_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nstd::vector<int> incr_list_simd(std::vector<int> l){\n    const int size = l.size();\n    const int remainder = size % 8;\n    const int loop_end = size - remainder;\n\n    __m256i increment = _mm256_set1_epi32(1);\n    for (int i = 0; i < loop_end; i += 8) {\n        __m256i input = _mm256_loadu_si256((__m256i*)&l[i]);\n        __m256i result = _mm256_add_epi32(input, increment);\n        _mm256_storeu_si256((__m256i*)&l[i], result);\n    }\n\n    for (int i = loop_end; i < size; ++i) {\n        l[i] += 1;\n    }\n\n    return l;\n}\n```  "}
{"task_id": "SimdBench_83_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nstd::vector<int> incr_list_simd(std::vector<int> l){\n    const int size = l.size();\n    const int remainder = size % 8;\n    const int loop_end = size - remainder;\n\n    __m256i increment = _mm256_set1_epi32(1);\n    for (int i = 0; i < loop_end; i += 8) {\n        __m256i input = _mm256_loadu_si256((__m256i*)&l[i]);\n        __m256i result = _mm256_add_epi32(input, increment);\n        _mm256_storeu_si256((__m256i*)&l[i], result);\n    }\n\n    for (int i = loop_end; i < size; i++) {\n        l[i]++;\n    }\n\n    return l;\n}\n```  "}
{"task_id": "SimdBench_84_AVX", "completion": "```cpp\nbool pairs_sum_to_zero_simd(std::vector<int> l){\n    const int size = l.size();\n    const int simd_size = 8;\n    \n    for (int i = 0; i < size; i += simd_size) {\n        __m256i vec = _mm256_set_epi32(l[i+7], l[i+6], l[i+5], l[i+4], l[i+3], l[i+2], l[i+1], l[i]);\n        \n        __m256i neg_vec = _mm256_sub_epi32(_mm256_setzero_si256(), vec);\n        \n        for (int j = i + 1; j < size; ++j) {\n            __m256i vec2 = _mm256_set_epi32(l[j+7], l[j+6], l[j+5], l[j+4], l[j+3], l[j+2], l[j+1], l[j]);\n            \n            __m256i result = _mm256_add_epi32(vec, vec2);\n            \n            __m256i cmp = _mm256_cmpeq_epi32(result, _mm256_setzero_si256());\n            int mask = _mm256_movemask_ps((__m256)cmp);\n            \n            if (mask != 0) {\n                return true;\n            }\n        }\n    }\n    \n    return false;\n}\n```"}
{"task_id": "SimdBench_84_AVX", "completion": "```cpp\nbool pairs_sum_to_zero_simd(std::vector<int> l){\n    const int size = l.size();\n    const int simd_size = 8;\n    \n    for (int i = 0; i < size; i += simd_size) {\n        __m256i vec = _mm256_set_epi32(l[i+7], l[i+6], l[i+5], l[i+4], l[i+3], l[i+2], l[i+1], l[i]);\n        \n        for (int j = i + 1; j < size; j++) {\n            __m256i vec2 = _mm256_set1_epi32(l[j]);\n            __m256i sum = _mm256_add_epi32(vec, vec2);\n            __m256i cmp = _mm256_cmpeq_epi32(sum, _mm256_setzero_si256());\n            int mask = _mm256_movemask_ps(_mm256_castsi256_ps(cmp));\n            \n            if (mask != 0) {\n                return true;\n            }\n        }\n    }\n    \n    return false;\n}\n```"}
{"task_id": "SimdBench_84_AVX", "completion": "```cpp\nbool pairs_sum_to_zero_simd(std::vector<int> l){\n    const int size = l.size();\n    const int simd_size = 8;\n    \n    for (int i = 0; i < size; i += simd_size) {\n        __m256i vec1 = _mm256_loadu_si256((__m256i*)&l[i]);\n        \n        for (int j = i + 1; j < size; j += simd_size) {\n            __m256i vec2 = _mm256_loadu_si256((__m256i*)&l[j]);\n            __m256i result = _mm256_add_epi32(vec1, vec2);\n            \n            __m256i cmp = _mm256_cmpeq_epi32(result, _mm256_setzero_si256());\n            int mask = _mm256_movemask_ps((__m256)cmp);\n            \n            if (mask != 0) {\n                return true;\n            }\n        }\n    }\n    \n    return false;\n}\n```"}
{"task_id": "SimdBench_84_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nbool pairs_sum_to_zero_simd(std::vector<int> l){\n    const int size = l.size();\n    const int simd_size = 8;\n    \n    for (int i = 0; i < size; i += simd_size) {\n        __m256i vec1 = _mm256_loadu_si256((__m256i*)&l[i]);\n        \n        for (int j = i + 1; j < size; j += simd_size) {\n            __m256i vec2 = _mm256_loadu_si256((__m256i*)&l[j]);\n            __m256i sum = _mm256_add_epi32(vec1, vec2);\n            \n            __m256i cmp = _mm256_cmpeq_epi32(sum, _mm256_setzero_si256());\n            int mask = _mm256_movemask_ps((__m256)cmp);\n            \n            if (mask != 0) {\n                return true;\n            }\n        }\n    }\n    \n    return false;\n}\n```"}
{"task_id": "SimdBench_84_AVX", "completion": "```cpp\nbool pairs_sum_to_zero_simd(std::vector<int> l){\n    const int size = l.size();\n    const int simd_size = 8;\n    \n    for (int i = 0; i < size; i += simd_size) {\n        __m256i vec1 = _mm256_loadu_si256((__m256i*)&l[i]);\n        \n        for (int j = i + 1; j < size; j += simd_size) {\n            __m256i vec2 = _mm256_loadu_si256((__m256i*)&l[j]);\n            __m256i sum = _mm256_add_epi32(vec1, vec2);\n            __m256i cmp = _mm256_cmpeq_epi32(sum, _mm256_setzero_si256());\n            int mask = _mm256_movemask_ps((__m256)cmp);\n            \n            if (mask != 0) {\n                return true;\n            }\n        }\n    }\n    \n    return false;\n}\n```"}
{"task_id": "SimdBench_85_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string change_base_simd(int64_t x, int8_t base){\n    __m256i base_vec = _mm256_set1_epi8(base);\n    __m256i x_vec = _mm256_set1_epi8(x);\n    __m256i quotient, remainder;\n    __m256i result = _mm256_setzero_si256();\n    __m256i ten = _mm256_set1_epi8(10);\n    __m256i zero = _mm256_setzero_si256();\n    __m256i mask = _mm256_set1_epi8(0x0F);\n\n    while (!_mm256_testz_si256(x_vec, x_vec)) {\n        quotient = _mm256_div_epi8(x_vec, base_vec);\n        remainder = _mm256_sub_epi8(x_vec, _mm256_mullo_epi8(quotient, base_vec));\n        x_vec = quotient;\n\n        __m256i ascii = _mm256_add_epi8(remainder, _mm256_set1_epi8('0'));\n        result = _mm256_or_si256(result, _mm256_slli_si256(ascii, 1));\n    }\n\n    __m128i result128 = _mm256_extracti128_si256(result, 0);\n    __m128i result128_shuffled = _mm_shuffle_epi8(result128, _mm_set_epi8(15, 14, 13, 12, 11, 10, 7, 6, 3, 2, 9, 8, 5, 4, 1, 0));\n    uint32_t result_int[4];\n    _mm_storeu_si128((__m128i*)result_int, result128_shuffled);\n\n    std::string result_str;\n    for (int i = 0; i < 4; ++i) {\n        if (result_int[i] != 0 || i == 3) {\n            result_str += std::to_string(result_int[i]);\n        }\n    }\n\n    return result_str;\n}\n```"}
{"task_id": "SimdBench_85_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string change_base_simd(int64_t x, int8_t base){\n    __m256i base_vec = _mm256_set1_epi8(base);\n    __m256i x_vec = _mm256_set1_epi8(x);\n    __m256i quotient, remainder;\n    __m256i result = _mm256_setzero_si256();\n    __m256i ten = _mm256_set1_epi8(10);\n    __m256i zero = _mm256_setzero_si256();\n    __m256i mask = _mm256_set1_epi8(0x0F);\n    __m256i ascii_zero = _mm256_set1_epi8('0');\n\n    while (!_mm256_testz_si256(x_vec, x_vec)) {\n        quotient = _mm256_div_epi8(x_vec, base_vec);\n        remainder = _mm256_sub_epi8(x_vec, _mm256_mullo_epi8(quotient, base_vec));\n        x_vec = quotient;\n\n        __m256i ascii_remainder = _mm256_add_epi8(remainder, ascii_zero);\n        result = _mm256_or_si256(result, _mm256_slli_epi32(ascii_remainder, 24));\n        result = _mm256_permutevar8x32_epi32(result, _mm256_set_epi32(7, 6, 5, 4, 3, 2, 1, 0));\n    }\n\n    __m128i result128 = _mm256_extracti128_si256(result, 0);\n    __m128i result128_2 = _mm256_extracti128_si256(result, 1);\n    __m128i result128_combined = _mm_packs_epi16(result128, result128_2);\n    __m128i result128_masked = _mm_and_si128(result128_combined, mask);\n    __m128i result128_shifted = _mm_or_si128(result128_masked, _mm_slli_epi32(result128_masked, 4));\n    __m128i result128_shifted_ascii = _mm_add_epi8(result128_shifted, ascii_zero);\n\n    char result_arr[16];\n    _mm_storeu_si128((__m128i*)result_arr, result128_shifted_ascii);\n\n    std::string result_str(result_arr);\n\n    return result_str;\n}\n```"}
{"task_id": "SimdBench_85_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string change_base_simd(int64_t x, int8_t base){\n    if (x == 0) return \"0\";\n    \n    __m256i base_vec = _mm256_set1_epi8(base);\n    __m256i x_vec = _mm256_set1_epi8(x);\n    __m256i quotient, remainder;\n    std::string result;\n    \n    while (x > 0) {\n        quotient = _mm256_div_epi8(x_vec, base_vec);\n        remainder = _mm256_sub_epi8(x_vec, _mm256_mullo_epi8(quotient, base_vec));\n        result.insert(result.begin(), _mm256_extract_epi8(remainder, 0) + '0');\n        x = _mm256_extract_epi8(quotient, 0);\n        x_vec = _mm256_set1_epi8(x);\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_85_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string change_base_simd(int64_t x, int8_t base){\n    __m256i base_vec = _mm256_set1_epi8(base);\n    __m256i x_vec = _mm256_set1_epi8(x);\n    __m256i quotient, remainder;\n    __m256i result = _mm256_setzero_si256();\n    __m256i ten = _mm256_set1_epi8(10);\n    __m256i zero = _mm256_setzero_si256();\n    __m256i mask = _mm256_set1_epi8(0x0F);\n    __m256i ascii_zero = _mm256_set1_epi8('0');\n\n    while (!_mm256_testz_si256(x_vec, x_vec)) {\n        quotient = _mm256_div_epi8(x_vec, base_vec);\n        remainder = _mm256_sub_epi8(x_vec, _mm256_mullo_epi8(quotient, base_vec));\n        x_vec = quotient;\n\n        __m256i ascii_digits = _mm256_add_epi8(remainder, ascii_zero);\n        result = _mm256_or_si256(_mm256_slli_si256(result, 1), ascii_digits);\n    }\n\n    char output[32];\n    _mm256_storeu_si256((__m256i*)output, result);\n\n    int len = 32;\n    for (int i = 0; i < 32; ++i) {\n        if (output[i] == '0' && len == 32) {\n            len--;\n        } else if (output[i] >= '0' && output[i] <= '9') {\n            len = i + 1;\n        }\n    }\n\n    return std::string(output, len);\n}\n```"}
{"task_id": "SimdBench_85_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string change_base_simd(int64_t x, int8_t base){\n    __m256i base_vec = _mm256_set1_epi8(base);\n    __m256i x_vec = _mm256_set1_epi8(x);\n    __m256i quotient, remainder;\n\n    std::string result;\n    do {\n        quotient = _mm256_div_epi8(x_vec, base_vec);\n        remainder = _mm256_sub_epi8(x_vec, _mm256_mullo_epi8(quotient, base_vec));\n        result.insert(result.begin(), _mm256_extract_epi8(remainder, 0) + '0');\n        x_vec = quotient;\n    } while (!_mm256_testz_si256(x_vec, x_vec));\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_86_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nbool is_palindrome_simd(std::string text){\n    int len = text.size();\n    int i = 0;\n    int j = len - 1;\n    \n    while (i < j) {\n        __m256i a = _mm256_loadu_si256((__m256i*)(text.data() + i));\n        __m256i b = _mm256_loadu_si256((__m256i*)(text.data() + j));\n        __m256i cmp = _mm256_cmpeq_epi8(a, b);\n        int mask = _mm256_movemask_epi8(cmp);\n        if (mask != 0xFFFFFFFF) {\n            return false;\n        }\n        i += 32;\n        j -= 32;\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_86_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nbool is_palindrome_simd(std::string text){\n    int len = text.size();\n    int i = 0;\n    int j = len - 1;\n    \n    while (i < j) {\n        __m256i a = _mm256_loadu_si256((__m256i*)&text[i]);\n        __m256i b = _mm256_loadu_si256((__m256i*)&text[j]);\n        \n        __m256i cmp = _mm256_cmpeq_epi8(a, b);\n        int mask = _mm256_movemask_epi8(cmp);\n        \n        if (mask != 0xFF) {\n            return false;\n        }\n        \n        i += 32;\n        j -= 32;\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_86_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nbool is_palindrome_simd(std::string text){\n    int len = text.size();\n    int i = 0;\n    int j = len - 1;\n    \n    while (i < j) {\n        __m256i a = _mm256_loadu_si256((__m256i*)&text[i]);\n        __m256i b = _mm256_loadu_si256((__m256i*)&text[j]);\n        \n        __m256i cmp = _mm256_cmpeq_epi8(a, b);\n        int mask = _mm256_movemask_epi8(cmp);\n        \n        if (mask != 0xFF) {\n            return false;\n        }\n        \n        i += 32;\n        j -= 32;\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_86_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nbool is_palindrome_simd(std::string text){\n    int len = text.size();\n    int half_len = len / 2;\n    \n    const char* str = text.c_str();\n    \n    for (int i = 0; i < half_len; ++i) {\n        if (str[i] != str[len - 1 - i]) {\n            return false;\n        }\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_86_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nbool is_palindrome_simd(std::string text){\n    int len = text.length();\n    int i = 0;\n    int j = len - 1;\n    \n    while (i < j) {\n        __m256i first = _mm256_loadu_si256((__m256i*)(text.c_str() + i));\n        __m256i second = _mm256_loadu_si256((__m256i*)(text.c_str() + j));\n        \n        __m256i cmp = _mm256_cmpeq_epi8(first, second);\n        int mask = _mm256_movemask_epi8(cmp);\n        \n        if (mask != 0xFFFFFFFF) {\n            return false;\n        }\n        \n        i += 32;\n        j -= 32;\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_87_AVX", "completion": "```\nstd::string decode_shift_simd(std::string s){\n    std::string out;\n    int i;\n    __m256i shift = _mm256_set1_epi8(5);\n    __m256i a_val = _mm256_set1_epi8('a');\n    __m256i z_val = _mm256_set1_epi8('z');\n    __m256i a_ascii = _mm256_set1_epi8((int)'a');\n    __m256i z_ascii = _mm256_set1_epi8((int)'z');\n    \n    for (i = 0; i < s.length(); i += 32) {\n        __m256i input = _mm256_loadu_si256((__m256i*)(s.c_str() + i));\n        \n        __m256i shifted = _mm256_adds_epu8(input, shift);\n        \n        __m256i a_mask = _mm256_cmpgt_epi8(shifted, a_val);\n        __m256i z_mask = _mm256_cmpgt_epi8(z_val, shifted);\n        \n        __m256i valid_mask = _mm256_and_si256(a_mask, z_mask);\n        \n        __m256i result = _mm256_add_epi8(shifted, _mm256_and_si256(valid_mask, _mm256_sub_epi8(a_ascii, a_val)));\n        \n        _mm256_storeu_si256((__m256i*)(out.c_str() + i), result);\n    }\n    \n    return out;\n}\n```"}
{"task_id": "SimdBench_87_AVX", "completion": "```\nstd::string decode_shift_simd(std::string s){\n    std::string out;\n    int i;\n    __m256i shift = _mm256_set1_epi8(5);\n    __m256i a_val = _mm256_set1_epi8('a');\n    __m256i z_val = _mm256_set1_epi8('z');\n    __m256i a_ascii = _mm256_set1_epi8((int)'a');\n    __m256i z_ascii = _mm256_set1_epi8((int)'z');\n    \n    for (i = 0; i < s.length(); i += 32) {\n        __m256i input = _mm256_loadu_si256((__m256i*)(s.c_str() + i));\n        \n        __m256i shifted = _mm256_sub_epi8(input, shift);\n        __m256i shifted_mod = _mm256_add_epi8(shifted, a_val);\n        \n        __m256i mask1 = _mm256_cmpgt_epi8(shifted_mod, z_val);\n        __m256i mask2 = _mm256_cmpgt_epi8(shifted_mod, z_ascii);\n        \n        __m256i add_val1 = _mm256_and_si256(mask1, _mm256_set1_epi8(26));\n        __m256i add_val2 = _mm256_and_si256(mask2, _mm256_set1_epi8(-26));\n        \n        __m256i final_shifted = _mm256_add_epi8(shifted_mod, add_val1);\n        final_shifted = _mm256_add_epi8(final_shifted, add_val2);\n        \n        out += std::string((char*)&final_shifted, 32);\n    }\n    \n    return out;\n}\n```"}
{"task_id": "SimdBench_87_AVX", "completion": "```\nstd::string decode_shift_simd(std::string s){\n    std::string out;\n    int i;\n    __m256i shift = _mm256_set1_epi8(5);\n    __m256i a_values = _mm256_set1_epi8('a');\n    __m256i z_values = _mm256_set1_epi8('z');\n    __m256i alphabet_size = _mm256_set1_epi8(26);\n    \n    for (i = 0; i < s.length(); i += 32) {\n        __m256i input = _mm256_loadu_si256((__m256i*)(s.c_str() + i));\n        \n        __m256i shifted = _mm256_add_epi8(input, shift);\n        __m256i diff_from_a = _mm256_sub_epi8(shifted, a_values);\n        __m256i mod_result = _mm256_and_si256(diff_from_a, _mm256_set1_epi8(0x1F));\n        __m256i w_values = _mm256_add_epi8(mod_result, a_values);\n        \n        __m256i is_greater_than_z = _mm256_cmpgt_epi8(w_values, z_values);\n        __m256i overflow_adjustment = _mm256_and_si256(is_greater_than_z, alphabet_size);\n        w_values = _mm256_sub_epi8(w_values, overflow_adjustment);\n        \n        _mm256_storeu_si256((__m256i*)(out.c_str() + i), w_values);\n    }\n    \n    return out;\n}\n```"}
{"task_id": "SimdBench_87_AVX", "completion": "```\nstd::string decode_shift_simd(std::string s){\n    std::string out;\n    int i;\n    __m256i v_shift = _mm256_set1_epi8(5);\n    __m256i v_a = _mm256_set1_epi8('a');\n    __m256i v_z = _mm256_set1_epi8('z');\n    __m256i v_26 = _mm256_set1_epi8(26);\n    __m256i v_mask = _mm256_set1_epi8(0x1F); // Mask to keep only lower 5 bits\n\n    for (i = 0; i < s.length(); i += 32) {\n        __m256i v_in = _mm256_loadu_si256((__m256i*)(s.data() + i));\n        \n        // Shift by 5\n        __m256i v_shifted = _mm256_add_epi8(v_in, v_5);\n        \n        // Subtract 'a'\n        __m256i v_sub_a = _mm256_sub_epi8(v_shifted, v_a);\n        \n        // Modulo 26\n        __m256i v_mod = _mm256_and_si256(v_sub_a, v_mask);\n        \n        // Add 'a'\n        __m256i v_result = _mm256_add_epi8(v_mod, v_a);\n        \n        _mm256_storeu_si256((__m256i*)(out.data() + i), v_result);\n    }\n    \n    return out;\n}\n```"}
{"task_id": "SimdBench_87_AVX", "completion": "```\nstd::string decode_shift_simd(std::string s){\n    std::string out;\n    int i;\n    __m256i shift = _mm256_set1_epi8(5);\n    __m256i a_val = _mm256_set1_epi8('a');\n    __m256i z_val = _mm256_set1_epi8('z');\n    __m256i a_ascii = _mm256_set1_epi8((int)'a');\n    __m256i mod_val = _mm256_set1_epi8(26);\n    \n    for (i = 0; i < s.length(); i += 32) {\n        __m256i input = _mm256_loadu_si256((__m256i*)&s[i]);\n        \n        __m256i shifted = _mm256_sub_epi8(input, shift);\n        __m256i diff = _mm256_sub_epi8(shifted, a_val);\n        __m256i mod = _mm256_add_epi8(_mm256_and_si256(_mm256_cmpgt_epi8(diff, _mm256_setzero_si256()), mod_val), diff);\n        __m256i result = _mm256_add_epi8(mod, a_ascii);\n        \n        _mm256_storeu_si256((__m256i*)&out[i], result);\n    }\n    \n    return out;\n}\n```"}
{"task_id": "SimdBench_88_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nbool below_threshold_simd(std::vector<int> l, int t) {\n    const int size = l.size();\n    const int simdSize = 8;\n    \n    for (int i = 0; i < size; i += simdSize) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&l[i]);\n        __m256i threshold = _mm256_set1_epi32(t);\n        __m256i result = _mm256_cmpgt_epi32(threshold, vec);\n        \n        if (!_mm256_testz_si256(result, result)) {\n            return false;\n        }\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_88_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nbool below_threshold_simd(std::vector<int> l, int t) {\n    const int size = l.size();\n    const int* data = l.data();\n    const __m256i threshold = _mm256_set1_epi32(t);\n    bool result = true;\n\n    for (int i = 0; i < size; i += 8) {\n        __m256i values = _mm256_loadu_si256((__m256i*)(data + i));\n        __m256i comparison = _mm256_cmpgt_epi32(threshold, values);\n        int mask = _mm256_movemask_ps(_mm256_castsi256_ps(comparison));\n        if (mask != 255) {\n            result = false;\n            break;\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_88_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nbool below_threshold_simd(std::vector<int> l, int t) {\n    const int size = l.size();\n    const int simdSize = 8;\n    const int numSimdIterations = size / simdSize;\n    \n    __m256i threshold = _mm256_set1_epi32(t);\n    bool result = true;\n    \n    for (int i = 0; i < numSimdIterations; ++i) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&l[i * simdSize]);\n        __m256i compare = _mm256_cmpgt_epi32(threshold, vec);\n        int mask = _mm256_movemask_ps(_mm256_castsi256_ps(compare));\n        \n        if (mask != 255) {\n            result = false;\n            break;\n        }\n    }\n    \n    for (int i = numSimdIterations * simdSize; i < size; ++i) {\n        if (l[i] >= t) {\n            result = false;\n            break;\n        }\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_88_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nbool below_threshold_simd(std::vector<int> l, int t) {\n    const int size = l.size();\n    const int* data = l.data();\n    const __m256i threshold = _mm256_set1_epi32(t);\n    bool result = true;\n\n    for (int i = 0; i < size; i += 8) {\n        __m256i values = _mm256_loadu_si256((__m256i*)(data + i));\n        __m256i compare = _mm256_cmpgt_epi32(threshold, values);\n        int mask = _mm256_movemask_ps(_mm256_castsi256_ps(compare));\n        result = result && (mask == 0xFF);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_88_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nbool below_threshold_simd(std::vector<int> l, int t) {\n    const int size = l.size();\n    const int* data = l.data();\n    const __m256i threshold = _mm256_set1_epi32(t);\n    bool result = true;\n\n    for (int i = 0; i < size; i += 8) {\n        __m256i values = _mm256_loadu_si256((__m256i*)(data + i));\n        __m256i compare = _mm256_cmpgt_epi32(threshold, values);\n        int mask = _mm256_movemask_ps(_mm256_castsi256_ps(compare));\n        if (mask != 255) {\n            result = false;\n            break;\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_89_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nbool correct_bracketing_simd(std::string brackets) {\n    int n = brackets.size();\n    if (n % 32 != 0) {\n        return false;\n    }\n\n    __m256i open = _mm256_set1_epi8('<');\n    __m256i close = _mm256_set1_epi8('>');\n\n    for (int i = 0; i < n; i += 32) {\n        __m256i chunk = _mm256_loadu_si256((__m256i*)&brackets[i]);\n        __m256i cmp_open = _mm256_cmpeq_epi8(chunk, open);\n        __m256i cmp_close = _mm256_cmpeq_epi8(chunk, close);\n        __m256i cmp_result = _mm256_sub_epi8(cmp_open, cmp_close);\n        int mask = _mm256_movemask_epi8(cmp_result);\n        if (mask != 0) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_89_AVX", "completion": "```\nbool correct_bracketing_simd(std::string brackets){\n    int n = brackets.size();\n    int remaining = 0;\n    __m256i open = _mm256_set1_epi8('<');\n    __m256i close = _mm256_set1_epi8('>');\n    \n    for (int i = 0; i < n; i += 32) {\n        __m256i chunk = _mm256_loadu_si256((__m256i*)(brackets.data() + i));\n        \n        __m256i isOpen = _mm256_cmpeq_epi8(chunk, open);\n        __m256i isClose = _mm256_cmpeq_epi8(chunk, close);\n        \n        remaining += _mm256_popcnt_u32(_mm256_movemask_epi8(isOpen)) - _mm256_popcnt_u32(_mm256_movemask_epi8(isClose));\n    }\n    \n    return remaining == 0;\n}\n```"}
{"task_id": "SimdBench_89_AVX", "completion": "```\nbool correct_bracketing_simd(std::string brackets){\n    int n = brackets.size();\n    if (n % 32 != 0) {\n        return false;\n    }\n\n    __m256i open = _mm256_set1_epi8('<');\n    __m256i close = _mm256_set1_epi8('>');\n    __m256i zero = _mm256_setzero_si256();\n    \n    for (int i = 0; i < n; i += 32) {\n        __m256i chunk = _mm256_loadu_si256((__m256i*)(brackets.data() + i));\n        __m256i cmp_open = _mm256_cmpeq_epi8(chunk, open);\n        __m256i cmp_close = _mm256_cmpeq_epi8(chunk, close);\n        __m256i diff = _mm256_sub_epi8(cmp_open, cmp_close);\n        __m256i sum = _mm256_add_epi8(diff, zero);\n        int mask = _mm256_movemask_epi8(sum);\n        if (mask != 0xFFFF) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_89_AVX", "completion": "```\nbool correct_bracketing_simd(std::string brackets){\n    int n = brackets.size();\n    if (n % 32 != 0) {\n        return false;\n    }\n\n    __m256i open = _mm256_set1_epi8('<');\n    __m256i close = _mm256_set1_epi8('>');\n    __m256i zero = _mm256_setzero_si256();\n    int result = 0;\n\n    for (int i = 0; i < n; i += 32) {\n        __m256i chunk = _mm256_loadu_si256((__m256i*)(brackets.data() + i));\n        __m256i cmp_open = _mm256_cmpeq_epi8(chunk, open);\n        __m256i cmp_close = _mm256_cmpeq_epi8(chunk, close);\n        __m256i cmp_result = _mm256_sub_epi8(cmp_open, cmp_close);\n        __m256i cmp_mask = _mm256_cmpeq_epi8(cmp_result, zero);\n        int mask = _mm256_movemask_epi8(cmp_mask);\n        if (mask != 0xFFFFFFFF) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_89_AVX", "completion": "```\nbool correct_bracketing_simd(std::string brackets){\n    int n = brackets.size();\n    if (n % 32 != 0) {\n        return false;\n    }\n    \n    __m256i open = _mm256_set1_epi8('<');\n    __m256i close = _mm256_set1_epi8('>');\n    \n    for (int i = 0; i < n; i += 32) {\n        __m256i chunk = _mm256_loadu_si256((__m256i*)(brackets.c_str() + i));\n        \n        __m256i cmp_open = _mm256_cmpeq_epi8(chunk, open);\n        __m256i cmp_close = _mm256_cmpeq_epi8(chunk, close);\n        \n        int mask_open = _mm256_movemask_epi8(cmp_open);\n        int mask_close = _mm256_movemask_epi8(cmp_close);\n        \n        if (mask_open != mask_close) {\n            return false;\n        }\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_90_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nbool correct_bracketing_simd(std::string brackets) {\n    const char* str = brackets.c_str();\n    int len = brackets.size();\n\n    __m256i open = _mm256_set1_epi8('(');\n    __m256i close = _mm256_set1_epi8(')');\n    __m256i count = _mm256_setzero_si256();\n\n    for (int i = 0; i < len; i += 32) {\n        __m256i chunk = _mm256_loadu_si256((__m256i*)(str + i));\n        __m256i isOpen = _mm256_cmpeq_epi8(chunk, open);\n        __m256i isClose = _mm256_cmpeq_epi8(chunk, close);\n        count = _mm256_add_epi8(count, _mm256_sub_epi8(isOpen, isClose));\n    }\n\n    alignas(32) int result[32];\n    _mm256_store_si256((__m256i*)result, count);\n\n    for (int i = 0; i < 32; ++i) {\n        if (result[i] != 0) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_90_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nbool correct_bracketing_simd(std::string brackets) {\n    int n = brackets.size();\n    if (n % 8 != 0) {\n        return false;\n    }\n\n    __m256i open_brackets = _mm256_set1_epi8('(');\n    __m256i close_brackets = _mm256_set1_epi8(')');\n    __m256i zero = _mm256_setzero_si256();\n    int count = 0;\n\n    for (int i = 0; i < n; i += 32) {\n        __m256i chunk = _mm256_loadu_si256((__m256i*)&brackets[i]);\n        __m256i cmp_open = _mm256_cmpeq_epi8(chunk, open_brackets);\n        __m256i cmp_close = _mm256_cmpeq_epi8(chunk, close_brackets);\n        __m256i diff = _mm256_sad_epu8(cmp_open, cmp_close);\n        count += _mm256_testz_si256(diff, zero);\n    }\n\n    return count == n / 8;\n}\n```"}
{"task_id": "SimdBench_90_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nbool correct_bracketing_simd(std::string brackets) {\n    int n = brackets.size();\n    if (n % 8 != 0) {\n        return false;\n    }\n\n    __m256i open_brackets = _mm256_set1_epi8('(');\n    __m256i close_brackets = _mm256_set1_epi8(')');\n    __m256i zero = _mm256_setzero_si256();\n    int count = 0;\n\n    for (int i = 0; i < n; i += 32) {\n        __m256i chunk = _mm256_loadu_si256((__m256i*)(brackets.c_str() + i));\n        __m256i cmp_open = _mm256_cmpeq_epi8(chunk, open_brackets);\n        __m256i cmp_close = _mm256_cmpeq_epi8(chunk, close_brackets);\n        __m256i diff = _mm256_sad_epu8(cmp_open, cmp_close);\n        count += _mm256_testz_si256(diff, zero);\n    }\n\n    return count == n / 8;\n}\n```"}
{"task_id": "SimdBench_90_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nbool correct_bracketing_simd(std::string brackets) {\n    int n = brackets.size();\n    if (n % 8 != 0) {\n        return false;\n    }\n\n    __m256i open = _mm256_set1_epi8('(');\n    __m256i close = _mm256_set1_epi8(')');\n    __m256i zero = _mm256_setzero_si256();\n    int count = 0;\n\n    for (int i = 0; i < n; i += 32) {\n        __m256i chunk = _mm256_loadu_si256((__m256i*)&brackets[i]);\n\n        __m256i cmp_open = _mm256_cmpeq_epi8(chunk, open);\n        __m256i cmp_close = _mm256_cmpeq_epi8(chunk, close);\n\n        __m256i diff = _mm256_sad_epu8(cmp_open, cmp_close);\n        int diff_arr[32];\n        _mm256_storeu_si256((__m256i*)diff_arr, diff);\n\n        for (int j = 0; j < 32; j++) {\n            count += diff_arr[j];\n        }\n    }\n\n    return count == 0;\n}\n```"}
{"task_id": "SimdBench_90_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nbool correct_bracketing_simd(std::string brackets) {\n    int n = brackets.size();\n    int i = 0;\n    __m256i open_brackets = _mm256_setzero_si256();\n    \n    for (; i + 31 < n; i += 32) {\n        __m256i chunk = _mm256_loadu_si256((__m256i*)(brackets.data() + i));\n        \n        __m256i open_mask = _mm256_cmpeq_epi8(chunk, _mm256_set1_epi8('('));\n        __m256i close_mask = _mm256_cmpeq_epi8(chunk, _mm256_set1_epi8(')'));\n        \n        open_brackets = _mm256_add_epi8(open_brackets, open_mask);\n        open_brackets = _mm256_sub_epi8(open_brackets, close_mask);\n    }\n    \n    alignas(32) int result[32];\n    _mm256_store_si256((__m256i*)result, open_brackets);\n    \n    for (int j = 0; j < 32; ++j) {\n        if (result[j] != 0) {\n            return false;\n        }\n    }\n    \n    for (; i < n; ++i) {\n        if (brackets[i] == '(') {\n            open_brackets = _mm256_add_epi8(open_brackets, _mm256_set1_epi8(1));\n        } else {\n            open_brackets = _mm256_sub_epi8(open_brackets, _mm256_set1_epi8(1));\n        }\n    }\n    \n    alignas(32) int final_result[32];\n    _mm256_store_si256((__m256i*)final_result, open_brackets);\n    \n    for (int j = 0; j < 32; ++j) {\n        if (final_result[j] != 0) {\n            return false;\n        }\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_91_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nstd::vector<float> derivative_simd(std::vector<float> xs){\n    int n = xs.size();\n    int simd_width = 8;\n    int num_simd = n / simd_width;\n    \n    std::vector<float> result;\n    result.reserve(n - 1);\n    \n    for (int i = 0; i < num_simd; ++i) {\n        __m256 coef = _mm256_loadu_ps(&xs[i * simd_width]);\n        __m256 indices = _mm256_set_ps(7, 6, 5, 4, 3, 2, 1, 0);\n        __m256 derivative = _mm256_mul_ps(coef, indices);\n        _mm256_storeu_ps(&result[i * simd_width], derivative);\n    }\n    \n    return result;\n}\n```  "}
{"task_id": "SimdBench_91_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nstd::vector<float> derivative_simd(std::vector<float> xs){\n    int n = xs.size();\n    int simd_width = 8;\n    int num_simd = n / simd_width;\n    \n    std::vector<float> result;\n    result.reserve(n - 1);\n    \n    for (int i = 0; i < num_simd; ++i) {\n        __m256 coeffs = _mm256_loadu_ps(xs.data() + i * simd_width);\n        __m256 indices = _mm256_set_ps(7, 6, 5, 4, 3, 2, 1, 0);\n        __m256 derivative = _mm256_mul_ps(coeffs, indices);\n        \n        _mm256_storeu_ps(result.data() + i * simd_width, derivative);\n    }\n    \n    return result;\n}\n```  "}
{"task_id": "SimdBench_91_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nstd::vector<float> derivative_simd(std::vector<float> xs){\n    std::vector<float> result;\n    int n = xs.size();\n    \n    if(n < 2){\n        return result;\n    }\n    \n    __m256 coef = _mm256_loadu_ps(xs.data());\n    __m256 indices = _mm256_set_ps(3.0f, 2.0f, 1.0f, 0.0f, 3.0f, 2.0f, 1.0f, 0.0f);\n    __m256 powers = _mm256_mul_ps(indices, _mm256_set1_ps(1.0f));\n    \n    for(int i = 0; i < n - 1; i += 8){\n        __m256 next_coef = _mm256_loadu_ps(xs.data() + i + 1);\n        __m256 diff = _mm256_mul_ps(coef, powers);\n        result.resize(result.size() + 8);\n        _mm256_storeu_ps(result.data() + i, diff);\n        coef = next_coef;\n        powers = _mm256_add_ps(powers, _mm256_set1_ps(1.0f));\n    }\n    \n    result.resize(n - 1);\n    return result;\n}\n```"}
{"task_id": "SimdBench_91_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nstd::vector<float> derivative_simd(std::vector<float> xs){\n    int n = xs.size();\n    int simd_width = 8;\n    int num_simd = n / simd_width;\n    \n    std::vector<float> result;\n    result.reserve(n - 1);\n    \n    for (int i = 0; i < num_simd; ++i) {\n        __m256 coef = _mm256_loadu_ps(&xs[i * simd_width]);\n        __m256 indices = _mm256_set_ps(7, 6, 5, 4, 3, 2, 1, 0);\n        __m256 derivative = _mm256_mul_ps(coef, indices);\n        \n        _mm256_storeu_ps(reinterpret_cast<float*>(&result[i * simd_width]), derivative);\n    }\n    \n    return result;\n}\n```  "}
{"task_id": "SimdBench_91_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nstd::vector<float> derivative_simd(std::vector<float> xs){\n    std::vector<float> result;\n    int n = xs.size();\n    int simd_width = 8;\n    int num_simd = n / simd_width;\n    \n    for (int i = 0; i < num_simd; ++i) {\n        __m256 coef = _mm256_loadu_ps(&xs[i * simd_width]);\n        __m256 indices = _mm256_set_ps(7, 6, 5, 4, 3, 2, 1, 0);\n        __m256 derivative = _mm256_mul_ps(coef, indices);\n        _mm256_storeu_ps(&result[i * simd_width], derivative);\n    }\n    \n    return result;\n}\n```  "}
{"task_id": "SimdBench_92_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nint vowels_count_simd(std::string s){\n    const __m256i vowels = _mm256_setr_epi8('a', 'e', 'i', 'o', 'u', 'A', 'E', 'I', 'O', 'U', 'Y', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n    const __m256i y_end_mask = _mm256_set1_epi8(0x80);\n    const __m256i y_end_char = _mm256_set1_epi8('Y');\n\n    int count = 0;\n    int i = 0;\n    while (i < s.size()) {\n        __m256i input = _mm256_loadu_si256((__m256i*)(s.c_str() + i));\n        __m256i cmp_vowels = _mm256_cmpeq_epi8(vowels, _mm256_or_si256(input, y_end_mask));\n        __m256i cmp_y_end = _mm256_cmpeq_epi8(y_end_char, input);\n        __m256i cmp_result = _mm256_or_si256(cmp_vowels, _mm256_slli_si256(cmp_y_end, 1));\n        count += _mm256_popcnt_u32(_mm256_movemask_epi8(cmp_result));\n        i += 32;\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_92_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nint vowels_count_simd(std::string s){\n    const __m256i vowels = _mm256_setr_epi8('a', 'e', 'i', 'o', 'u', 'A', 'E', 'I', 'O', 'U', 'Y', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n    const __m256i end_vowels = _mm256_setr_epi8('a', 'e', 'i', 'o', 'u', 'A', 'E', 'I', 'O', 'U', 'Y', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n\n    int count = 0;\n    int len = s.size();\n    for (int i = 0; i < len; i += 32) {\n        __m256i str = _mm256_loadu_si256((__m256i*)(s.c_str() + i));\n        __m256i cmp_vowels = _mm256_cmpeq_epi8(vowels, _mm256_and_si256(str, _mm256_set1_epi8(0xDF))); // Convert lowercase to uppercase\n        __m256i cmp_end_vowels = _mm256_cmpeq_epi8(end_vowels, _mm256_and_si256(str, _mm256_set1_epi8(0xDF)));\n\n        __m256i cmp_vowels_or_end = _mm256_or_si256(cmp_vowels, cmp_end_vowels);\n\n        count += _mm_popcnt_u32(_mm256_movemask_epi8(cmp_vowels_or_end));\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_92_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nint vowels_count_simd(std::string s){\n    const __m256i vowels = _mm256_setr_epi8('a', 'e', 'i', 'o', 'u', 'A', 'E', 'I', 'O', 'U', 'Y', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n    const __m256i end_vowels = _mm256_set1_epi8('Y');\n    const __m256i mask = _mm256_set1_epi8(0x1);\n\n    int count = 0;\n    int i = 0;\n    while (i < s.size() - 31) {\n        __m256i str = _mm256_loadu_si256((__m256i*)&s[i]);\n        __m256i cmp_vowels = _mm256_cmpeq_epi8(vowels, _mm256_or_si256(_mm256_or_si256(_mm256_cmpeq_epi8(str, vowels), _mm256_cmpeq_epi8(str, end_vowels)), _mm256_cmpeq_epi8(_mm256_set1_epi8(s[i + 31]), end_vowels)));\n        __m256i result = _mm256_and_si256(cmp_vowels, mask);\n        count += _mm256_popcnt_u32(_mm256_movemask_epi8(result));\n        i += 32;\n    }\n\n    for (; i < s.size(); ++i) {\n        if ((s[i] == 'a' || s[i] == 'e' || s[i] == 'i' || s[i] == 'o' || s[i] == 'u' || s[i] == 'A' || s[i] == 'E' || s[i] == 'I' || s[i] == 'O' || s[i] == 'U') && (i == s.size() - 1 || s[i] == 'Y')) {\n            count++;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_92_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nint vowels_count_simd(std::string s){\n    const __m256i vowels = _mm256_setr_epi8('a', 'e', 'i', 'o', 'u', 'A', 'E', 'I', 'O', 'U', 'Y', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n    const __m256i y_end_mask = _mm256_set1_epi8(0x80);\n    const __m256i y_mask = _mm256_set1_epi8('Y');\n\n    int count = 0;\n    int i = 0;\n    while (i < s.size()) {\n        __m256i str = _mm256_loadu_si256((__m256i*)(s.c_str() + i));\n        __m256i cmp_vowels = _mm256_cmpeq_epi8(vowels, _mm256_or_si256(str, y_end_mask));\n        __m256i cmp_y_end = _mm256_cmpeq_epi8(y_mask, str);\n        __m256i y_end_result = _mm256_and_si256(cmp_y_end, _mm256_cmpeq_epi8(y_end_mask, _mm256_set1_epi8(s[i + 4])));\n        __m256i result = _mm256_or_si256(cmp_vowels, y_end_result);\n        count += _mm256_popcnt_u32(_mm256_movemask_epi8(result));\n        i += 32;\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_92_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nint vowels_count_simd(std::string s){\n    const __m256i vowels = _mm256_setr_epi8('a', 'e', 'i', 'o', 'u', 'A', 'E', 'I', 'O', 'U', 'Y', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n    const __m256i y_end_mask = _mm256_set1_epi8(0x80);\n    const __m256i y_end_vowel_mask = _mm256_set1_epi8(0x20);\n    const __m256i zero = _mm256_setzero_si256();\n    \n    int count = 0;\n    int i = 0;\n    while (i < s.size()) {\n        __m256i str = _mm256_loadu_si256((__m256i*)(s.c_str() + i));\n        \n        __m256i is_vowel = _mm256_cmpeq_epi8(vowels, _mm256_and_si256(vowels, _mm256_set1_epi8(0xDF))); // Check for 'Y' at the end\n        \n        __m256i is_y_end = _mm256_cmpeq_epi8(y_end_mask, _mm256_and_si256(str, y_end_mask));\n        is_vowel = _mm256_or_si256(is_vowel, _mm256_and_si256(is_y_end, y_end_vowel_mask));\n        \n        __m256i cmp = _mm256_cmpeq_epi8(vowels, _mm256_and_si256(vowels, str));\n        cmp = _mm256_or_si256(cmp, is_vowel);\n        \n        __m256i result = _mm256_and_si256(cmp, _mm256_set1_epi8(1));\n        count += _mm256_reduce_add_epi8(result);\n        \n        i += 32;\n    }\n    \n    return count;\n}\n```"}
{"task_id": "SimdBench_93_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nint digitSum_simd(std::string s){\n    int sum = 0;\n    __m256i upperLimit = _mm256_set1_epi8('Z');\n    __m256i lowerLimit = _mm256_set1_epi8('A');\n    __m256i zero = _mm256_setzero_si256();\n    \n    for (size_t i = 0; i < s.size(); i += 32) {\n        __m256i str = _mm256_loadu_si256((__m256i*)(s.c_str() + i));\n        \n        __m256i isUpper = _mm256_and_si256(_mm256_cmpgt_epi8(str, lowerLimit), _mm256_cmplt_epi8(str, upperLimit));\n        __m256i upperChars = _mm256_and_si256(str, isUpper);\n        \n        __m256i sum16 = _mm256_sad_epu8(upperChars, zero);\n        sum += _mm256_extract_epi16(sum16, 0) + _mm256_extract_epi16(sum16, 8);\n    }\n    \n    return sum;\n}\n```"}
{"task_id": "SimdBench_93_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nint digitSum_simd(std::string s){\n    int sum = 0;\n    __m256i upperMask = _mm256_set1_epi8(0b01000000); // Mask to check if character is uppercase\n    __m256i asciiMask = _mm256_set1_epi8(0b01111111); // Mask to clear the 7th bit of ASCII code\n\n    for (size_t i = 0; i < s.size(); i += 32) {\n        __m256i str = _mm256_loadu_si256((__m256i*)(s.c_str() + i));\n        __m256i upper = _mm256_and_si256(_mm256_cmpgt_epi8(str, upperMask), str);\n        __m256i cleared = _mm256_and_si256(upper, asciiMask);\n        __m256i sumVec = _mm256_sad_epu8(cleared, _mm256_setzero_si256());\n        sum += _mm256_extract_epi16(sumVec, 0) + _mm256_extract_epi16(sumVec, 8);\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_93_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nint digitSum_simd(std::string s){\n    int sum = 0;\n    __m256i upperMask = _mm256_set1_epi8(0b01000000); // Mask to check if character is uppercase\n    __m256i asciiMask = _mm256_set1_epi8(0b01111111); // Mask to extract ASCII value\n\n    for (size_t i = 0; i < s.size(); i += 32) {\n        __m256i str = _mm256_loadu_si256((__m256i*)(s.c_str() + i));\n        __m256i isUpper = _mm256_and_si256(_mm256_cmpgt_epi8(str, _mm256_set1_epi8('A' - 1)), _mm256_cmplt_epi8(str, _mm256_set1_epi8('Z' + 1)));\n        __m256i upperChars = _mm256_and_si256(str, isUpper);\n        __m256i upperAscii = _mm256_and_si256(_mm256_slli_epi32(upperChars, 1), asciiMask);\n        __m256i sumVec = _mm256_sad_epu8(upperAscii, _mm256_setzero_si256());\n        sum += _mm256_extract_epi16(sumVec, 0) + _mm256_extract_epi16(sumVec, 8);\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_93_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nint digitSum_simd(std::string s){\n    int sum = 0;\n    __m256i upperMask = _mm256_set1_epi8(0b11011111); // Mask to extract upper characters\n\n    for (size_t i = 0; i < s.size(); i += 32) {\n        __m256i input = _mm256_loadu_si256((__m256i*)(s.c_str() + i));\n        __m256i upperChars = _mm256_and_si256(input, upperMask);\n        \n        __m256i sum16 = _mm256_sad_epu8(upperChars, _mm256_setzero_si256());\n        __m128i sum8 = _mm_add_epi16(_mm256_extracti128_si256(sum16, 0), _mm256_extracti128_si256(sum16, 1));\n        sum += _mm_extract_epi16(sum8, 0) + _mm_extract_epi16(sum8, 4) + _mm_extract_epi16(sum8, 8) + _mm_extract_epi16(sum8, 12);\n    }\n\n    return sum;\n}\n```  "}
{"task_id": "SimdBench_93_AVX", "completion": "```\nint digitSum_simd(std::string s){\n    int sum = 0;\n    __m256i upperMask = _mm256_set1_epi8(0b11011111); // Mask to check if a character is uppercase\n    int len = s.length();\n    \n    for (int i = 0; i < len; i += 32) {\n        __m256i asciiCodes = _mm256_setzero_si256();\n        for (int j = 0; j < 32; j++) {\n            if (i + j < len) {\n                asciiCodes = _mm256_insert_epi8(asciiCodes, s[i + j], j);\n            }\n        }\n        \n        __m256i isUpper = _mm256_and_si256(asciiCodes, upperMask);\n        __m256i upperSum = _mm256_sad_epu8(isUpper, _mm256_setzero_si256());\n        \n        sum += _mm256_extract_epi16(upperSum, 0) + _mm256_extract_epi16(upperSum, 8);\n    }\n    \n    return sum;\n}\n```"}
{"task_id": "SimdBench_94_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nstd::vector<int> pluck_simd(std::vector<int> arr){\n    if(arr.empty()) return {};\n\n    const int size = arr.size();\n    const __m256i zero = _mm256_set1_epi32(0);\n    __m256i min_even = _mm256_set1_epi32(2147483647); // Max int value\n    __m256i min_even_index = _mm256_set1_epi32(2147483647); // Max int value\n\n    for(int i = 0; i < size; i += 8){\n        __m256i values = _mm256_loadu_si256((__m256i*)&arr[i]);\n        __m256i even_mask = _mm256_and_si256(values, _mm256_set1_epi32(1)); // Check if even\n        __m256i even_values = _mm256_and_si256(values, _mm256_set1_epi32(-2)); // Clear LSB if odd\n\n        __m256i cmp = _mm256_cmpgt_epi32(min_even, even_values);\n        min_even = _mm256_blendv_epi8(min_even, even_values, cmp);\n        min_even_index = _mm256_blendv_epi8(min_even_index, _mm256_set1_epi32(i), cmp);\n    }\n\n    __m128i min_even_lo = _mm256_castsi256_si128(min_even);\n    __m128i min_even_hi = _mm256_extracti128_si256(min_even, 1);\n    __m128i min_even_index_lo = _mm256_castsi256_si128(min_even_index);\n    __m128i min_even_index_hi = _mm256_extracti128_si256(min_even_index, 1);\n\n    __m128i min_even_final = _mm_min_epu32(min_even_lo, min_even_hi);\n    __m128i min_even_index_final = _mm_blendv_epi8(min_even_index_lo, min_even_index_hi, _mm_cmpeq_epi32(min_even_final, min_even_hi));\n\n    int result[4];\n    _mm_storeu_si128((__m128i*)result, min_even_final);\n    _mm_storeu_si128((__m128i*)(result + 2), min_even_index_final);\n\n    return {result[0], result[2]};\n}\n```"}
{"task_id": "SimdBench_94_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nstd::vector<int> pluck_simd(std::vector<int> arr){\n    if(arr.empty()) return {};\n\n    const __m256i even_mask = _mm256_set1_epi32(1);\n    const __m256i zero = _mm256_setzero_si256();\n    __m256i min_even_value = _mm256_set1_epi32(2147483647); // INT_MAX\n    __m256i min_even_index = _mm256_set1_epi32(2147483647); // INT_MAX\n    __m256i min_even_value_index = _mm256_set1_epi32(2147483647); // INT_MAX\n\n    for (int i = 0; i < arr.size(); i += 8) {\n        __m256i values = _mm256_loadu_si256((__m256i*)&arr[i]);\n        __m256i even_values = _mm256_and_si256(values, even_mask);\n        __m256i is_even = _mm256_cmpeq_epi32(even_values, zero);\n\n        __m256i lt_min_even_value = _mm256_cmpgt_epi32(min_even_value, even_values);\n        __m256i eq_min_even_value = _mm256_cmpeq_epi32(min_even_value, even_values);\n        __m256i lt_min_even_index = _mm256_cmpgt_epi32(min_even_index, _mm256_set1_epi32(i));\n        \n        __m256i update_mask = _mm256_and_si256(is_even, lt_min_even_value);\n        update_mask = _mm256_or_si256(update_mask, _mm256_and_si256(eq_min_even_value, lt_min_even_index));\n\n        min_even_value = _mm256_blendv_epi8(min_even_value, even_values, update_mask);\n        min_even_index = _mm256_blendv_epi8(min_even_index, _mm256_set1_epi32(i), update_mask);\n        min_even_value_index = _mm256_blendv_epi8(min_even_value_index, _mm256_set1_epi32(i), update_mask);\n    }\n\n    int result[8];\n    _mm256_storeu_si256((__m256i*)result, min_even_value);\n    _mm256_storeu_si256((__m256i*)(result + 4), min_even_index);\n\n    int min_val = 2147483647; // INT_MAX\n    int min_idx = 2147483647; // INT_MAX\n    for(int i = 0; i < 8; ++i){\n        if(result[i] < min_val){\n            min_val = result[i];\n            min_idx = result[i + 4];\n        }\n    }\n\n    if(min_val == 2147483647) return {};\n    return {min_val, min_idx};\n}\n```"}
{"task_id": "SimdBench_94_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nstd::vector<int> pluck_simd(std::vector<int> arr){\n    if (arr.empty()) {\n        return {};\n    }\n\n    const int size = arr.size();\n    const __m256i even_mask = _mm256_set1_epi32(1);\n    const __m256i zero = _mm256_setzero_si256();\n    __m256i min_even_val = _mm256_set1_epi32(2147483647); // INT_MAX\n    __m256i min_even_idx = _mm256_set1_epi32(2147483647); // INT_MAX\n\n    for (int i = 0; i < size; i += 8) {\n        __m256i values = _mm256_loadu_si256((__m256i*)&arr[i]);\n        __m256i even_values = _mm256_and_si256(values, even_mask);\n        __m256i even_mask_cmp = _mm256_cmpeq_epi32(even_values, zero);\n        __m256i min_mask = _mm256_cmpgt_epi32(min_even_val, even_values);\n        __m256i min_mask_idx = _mm256_and_si256(min_mask, even_mask_cmp);\n\n        min_even_val = _mm256_blendv_epi8(min_even_val, even_values, min_mask);\n        min_even_idx = _mm256_blendv_epi8(min_even_idx, _mm256_set1_epi32(i), min_mask_idx);\n    }\n\n    alignas(32) int result_val[8];\n    alignas(32) int result_idx[8];\n    _mm256_store_si256((__m256i*)result_val, min_even_val);\n    _mm256_store_si256((__m256i*)result_idx, min_even_idx);\n\n    int min_val = 2147483647; // INT_MAX\n    int min_idx = 2147483647; // INT_MAX\n\n    for (int i = 0; i < 8; ++i) {\n        if (result_val[i] < min_val || (result_val[i] == min_val && result_idx[i] < min_idx)) {\n            min_val = result_val[i];\n            min_idx = result_idx[i];\n        }\n    }\n\n    if (min_val == 2147483647) {\n        return {};\n    } else {\n        return {min_val, min_idx};\n    }\n}\n```"}
{"task_id": "SimdBench_94_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nstd::vector<int> pluck_simd(std::vector<int> arr){\n    if(arr.empty()) return {};\n\n    const int size = arr.size();\n    const __m256i zero = _mm256_setzero_si256();\n    __m256i min_even = _mm256_set1_epi32(2147483647); // Max int value\n    __m256i min_even_idx = _mm256_set1_epi32(2147483647); // Max int value\n\n    for(int i = 0; i < size; i += 8){\n        __m256i values = _mm256_loadu_si256((__m256i*)&arr[i]);\n        __m256i even_mask = _mm256_and_si256(values, _mm256_set1_epi32(1)); // Check for even values\n        __m256i even_values = _mm256_and_si256(values, _mm256_set1_epi32(-2)); // Clear the least significant bit for even values\n        __m256i cmp_mask = _mm256_cmpgt_epi32(min_even, even_values);\n        min_even = _mm256_blendv_epi8(min_even, even_values, cmp_mask);\n        min_even_idx = _mm256_blendv_epi8(min_even_idx, _mm256_set1_epi32(i), cmp_mask);\n    }\n\n    __m128i min_even_lo = _mm256_castsi256_si128(min_even);\n    __m128i min_even_hi = _mm256_extracti128_si256(min_even, 1);\n    __m128i min_even_idx_lo = _mm256_castsi256_si128(min_even_idx);\n    __m128i min_even_idx_hi = _mm256_extracti128_si256(min_even_idx, 1);\n\n    __m128i min_even_final = _mm_min_epu32(min_even_lo, min_even_hi);\n    __m128i min_even_idx_final = _mm_blendv_epi8(min_even_idx_lo, min_even_idx_hi, _mm_cmpeq_epi32(min_even_final, min_even_hi));\n\n    int result[4];\n    _mm_storeu_si128((__m128i*)result, min_even_final);\n    _mm_storeu_si128((__m128i*)(result + 2), min_even_idx_final);\n\n    return {result[0], result[2]};\n}\n```"}
{"task_id": "SimdBench_94_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nstd::vector<int> pluck_simd(std::vector<int> arr){\n    if(arr.empty()) return {};\n\n    const __m256i zero = _mm256_setzero_si256();\n    __m256i min_even = _mm256_set1_epi32(0x7FFFFFFF);\n    __m256i min_even_idx = _mm256_set1_epi32(0x7FFFFFFF);\n    \n    for(size_t i = 0; i < arr.size(); i += 8){\n        __m256i values = _mm256_loadu_si256((__m256i*)&arr[i]);\n        __m256i even_mask = _mm256_and_si256(values, _mm256_set1_epi32(1));\n        __m256i even_values = _mm256_and_si256(values, _mm256_set1_epi32(0xFFFFFFFE));\n        \n        __m256i cmp = _mm256_cmpgt_epi32(min_even, even_values);\n        min_even = _mm256_blendv_epi8(min_even, even_values, cmp);\n        min_even_idx = _mm256_blendv_epi8(min_even_idx, _mm256_set1_epi32(i), cmp);\n    }\n    \n    __m128i min_even_lo = _mm256_castsi256_si128(min_even);\n    __m128i min_even_hi = _mm256_extracti128_si256(min_even, 1);\n    __m128i min_even_idx_lo = _mm256_castsi256_si128(min_even_idx);\n    __m128i min_even_idx_hi = _mm256_extracti128_si256(min_even_idx, 1);\n    \n    __m128i min_even_final = _mm_min_epu32(min_even_lo, min_even_hi);\n    __m128i min_even_idx_final = _mm_blendv_epi8(min_even_idx_lo, min_even_idx_hi, _mm_cmpeq_epi32(min_even_final, min_even_hi));\n    \n    int result[4];\n    _mm_storeu_si128((__m128i*)result, min_even_final);\n    _mm_storeu_si128((__m128i*)(result + 2), min_even_idx_final);\n    \n    return {result[0], result[2]};\n}\n```"}
{"task_id": "SimdBench_95_AVX", "completion": "```\nint search_simd(std::vector<int> lst){\n    const int n = lst.size();\n    const int* data = lst.data();\n    \n    __m256i vcount = _mm256_setzero_si256();\n    __m256i vmax = _mm256_set1_epi32(-1);\n    \n    for (int i = 0; i < n; i += 8) {\n        __m256i vdata = _mm256_loadu_si256((__m256i*)(data + i));\n        \n        __m256i mask = _mm256_cmpeq_epi32(vdata, vmax);\n        vcount = _mm256_add_epi32(vcount, _mm256_and_si256(mask, _mm256_set1_epi32(1)));\n        \n        for (int j = i + 1; j < n; j++) {\n            __m256i vcmp = _mm256_cmpeq_epi32(vdata, _mm256_set1_epi32(data[j]));\n            vcount = _mm256_add_epi32(vcount, _mm256_and_si256(vcmp, _mm256_set1_epi32(1)));\n        }\n    }\n    \n    int result[8];\n    _mm256_storeu_si256((__m256i*)result, vcount);\n    \n    for (int i = 0; i < 8; i++) {\n        if (result[i] > 0 && result[i] >= i + 1) {\n            return i + 1;\n        }\n    }\n    \n    return -1;\n}\n```"}
{"task_id": "SimdBench_95_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint search_simd(std::vector<int> lst) {\n    const int n = lst.size();\n    const int* data = lst.data();\n    \n    __m256i result = _mm256_set1_epi32(-1);\n    \n    for (int i = 0; i < n; i += 8) {\n        __m256i values = _mm256_loadu_si256((__m256i*)(data + i));\n        __m256i counts = _mm256_setzero_si256();\n        \n        for (int j = 0; j < n; ++j) {\n            __m256i cmp = _mm256_cmpeq_epi32(values, _mm256_set1_epi32(data[j]));\n            counts = _mm256_add_epi32(counts, cmp);\n        }\n        \n        __m256i cmp_freq = _mm256_cmpgt_epi32(counts, values);\n        __m256i cmp_result = _mm256_and_si256(cmp_freq, _mm256_cmpgt_epi32(values, result));\n        result = _mm256_blendv_epi8(result, values, cmp_result);\n    }\n    \n    alignas(32) int final_result[8];\n    _mm256_store_si256((__m256i*)final_result, result);\n    \n    for (int i = 0; i < 8; ++i) {\n        if (final_result[i] > 0) {\n            return final_result[i];\n        }\n    }\n    \n    return -1;\n}\n```"}
{"task_id": "SimdBench_95_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint search_simd(std::vector<int> lst){\n    const int N = lst.size();\n    const __m256i threshold = _mm256_set1_epi32(N);\n    \n    __m256i result = _mm256_set1_epi32(-1);\n    \n    for (int i = 0; i < N; i += 8) {\n        __m256i values = _mm256_loadu_si256((__m256i*)&lst[i]);\n        \n        __m256i mask = _mm256_cmpeq_epi32(values, result);\n        __m256i count = _mm256_setzero_si256();\n        \n        for (int j = 0; j < N; j += 8) {\n            __m256i cmp = _mm256_cmpeq_epi32(values, _mm256_loadu_si256((__m256i*)&lst[j]));\n            count = _mm256_add_epi32(count, _mm256_and_si256(cmp, _mm256_set1_epi32(1)));\n        }\n        \n        __m256i greater_than_threshold = _mm256_cmpgt_epi32(count, threshold);\n        __m256i greater_than_result = _mm256_cmpgt_epi32(values, result);\n        \n        result = _mm256_blendv_epi8(result, values, _mm256_and_si256(greater_than_threshold, greater_than_result));\n    }\n    \n    alignas(32) int final_result[8];\n    _mm256_store_si256((__m256i*)final_result, result);\n    \n    for (int i = 0; i < 8; i++) {\n        if (final_result[i] > 0) {\n            return final_result[i];\n        }\n    }\n    \n    return -1;\n}\n```"}
{"task_id": "SimdBench_95_AVX", "completion": "```\nint search_simd(std::vector<int> lst){\n    const int size = lst.size();\n    const int simd_size = 8;\n    \n    __m256i target = _mm256_setzero_si256();\n    __m256i freq = _mm256_setzero_si256();\n    \n    for (int i = 0; i < size; i += simd_size) {\n        __m256i data = _mm256_loadu_si256((__m256i*)&lst[i]);\n        \n        __m256i cmp = _mm256_cmpeq_epi32(data, target);\n        freq = _mm256_add_epi32(freq, cmp);\n    }\n    \n    alignas(32) int result[8];\n    _mm256_store_si256((__m256i*)result, freq);\n    \n    for (int i = 0; i < simd_size; ++i) {\n        if (result[i] > 0 && result[i] >= i + 1) {\n            return i + 1;\n        }\n    }\n    \n    return -1;\n}\n```"}
{"task_id": "SimdBench_95_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint search_simd(std::vector<int> lst){\n    __m256i threshold = _mm256_setzero_si256();\n    __m256i result = _mm256_set1_epi32(-1);\n    \n    for (size_t i = 0; i < lst.size(); i += 8) {\n        __m256i data = _mm256_loadu_si256((__m256i*)&lst[i]);\n        \n        __m256i mask = _mm256_cmpeq_epi32(data, threshold);\n        __m256i counts = _mm256_setzero_si256();\n        \n        for (size_t j = 0; j < lst.size(); j += 8) {\n            __m256i cmp_data = _mm256_loadu_si256((__m256i*)&lst[j]);\n            __m256i cmp_mask = _mm256_cmpeq_epi32(data, cmp_data);\n            counts = _mm256_add_epi32(counts, cmp_mask);\n        }\n        \n        __m256i cmp_result = _mm256_cmpgt_epi32(counts, data);\n        __m256i final_mask = _mm256_and_si256(mask, cmp_result);\n        \n        result = _mm256_blendv_epi8(result, data, final_mask);\n    }\n    \n    alignas(32) int final_result[8];\n    _mm256_store_si256((__m256i*)final_result, result);\n    \n    for (int i = 0; i < 8; ++i) {\n        if (final_result[i] > 0) {\n            return final_result[i];\n        }\n    }\n    \n    return -1;\n}\n```"}
{"task_id": "SimdBench_96_AVX", "completion": "```\nbool will_it_fly_simd(std::vector<int> q, int w) {\n    int size = q.size();\n    if (size == 1) {\n        return q[0] <= w;\n    }\n\n    int sum = 0;\n    for (int i = 0; i < size; i++) {\n        sum += q[i];\n    }\n\n    if (sum > w) {\n        return false;\n    }\n\n    int halfSize = size / 2;\n    for (int i = 0; i < halfSize; i++) {\n        if (q[i] != q[size - 1 - i]) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_96_AVX", "completion": "```\nbool will_it_fly_simd(std::vector<int> q, int w) {\n    int size = q.size();\n    if (size == 1) {\n        return q[0] <= w;\n    }\n\n    __m256i sum = _mm256_setzero_si256();\n    for (int i = 0; i < size / 8 * 8; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&q[i]);\n        sum = _mm256_add_epi32(sum, vec);\n    }\n\n    int remaining = size % 8;\n    if (remaining > 0) {\n        __m256i mask = _mm256_set_epi32(remaining >= 8 ? -1 : 0, remaining >= 7 ? -1 : 0, remaining >= 6 ? -1 : 0, remaining >= 5 ? -1 : 0, remaining >= 4 ? -1 : 0, remaining >= 3 ? -1 : 0, remaining >= 2 ? -1 : 0, remaining >= 1 ? -1 : 0);\n        __m256i vec = _mm256_maskload_epi32((int*)&q[size - remaining], mask);\n        sum = _mm256_add_epi32(sum, vec);\n    }\n\n    int sum_array[8];\n    _mm256_storeu_si256((__m256i*)sum_array, sum);\n    int total_sum = sum_array[0] + sum_array[1] + sum_array[2] + sum_array[3] + sum_array[4] + sum_array[5] + sum_array[6] + sum_array[7];\n\n    if (total_sum > w) {\n        return false;\n    }\n\n    for (int i = 0; i < size / 2; i++) {\n        if (q[i] != q[size - i - 1]) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_96_AVX", "completion": "```\nbool will_it_fly_simd(std::vector<int> q, int w) {\n    int size = q.size();\n    if (size == 1) {\n        return q[0] <= w;\n    }\n    \n    __m256i sum = _mm256_setzero_si256();\n    for (int i = 0; i < size; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&q[i]);\n        sum = _mm256_add_epi32(sum, vec);\n    }\n    \n    int totalSum = 0;\n    alignas(32) int result[8];\n    _mm256_store_si256((__m256i*)result, sum);\n    for (int i = 0; i < 8; i++) {\n        totalSum += result[i];\n    }\n    \n    if (totalSum > w) {\n        return false;\n    }\n    \n    for (int i = 0; i < size / 2; i++) {\n        if (q[i] != q[size - i - 1]) {\n            return false;\n        }\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_96_AVX", "completion": "```\nbool will_it_fly_simd(std::vector<int> q, int w) {\n    int size = q.size();\n    if (size == 1) {\n        return q[0] <= w;\n    }\n    \n    __m256i sum = _mm256_setzero_si256();\n    for (int i = 0; i < size; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&q[i]);\n        sum = _mm256_add_epi32(sum, vec);\n    }\n    \n    int total_sum[8];\n    _mm256_storeu_si256((__m256i*)total_sum, sum);\n    \n    int final_sum = 0;\n    for (int i = 0; i < 8; i++) {\n        final_sum += total_sum[i];\n    }\n    \n    if (final_sum > w) {\n        return false;\n    }\n    \n    for (int i = 0; i < size / 2; i++) {\n        if (q[i] != q[size - i - 1]) {\n            return false;\n        }\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_96_AVX", "completion": "```\nbool will_it_fly_simd(std::vector<int> q, int w) {\n    int size = q.size();\n    if (size == 1) {\n        return q[0] <= w;\n    }\n\n    int sum = 0;\n    for (int i = 0; i < size; i++) {\n        sum += q[i];\n    }\n\n    if (sum > w) {\n        return false;\n    }\n\n    int half_size = size / 2;\n    int* q_ptr = q.data();\n\n    __m256i sum_v = _mm256_setzero_si256();\n    for (int i = 0; i < half_size; i += 8) {\n        __m256i vec1 = _mm256_loadu_si256((__m256i*)(q_ptr + i));\n        __m256i vec2 = _mm256_loadu_si256((__m256i*)(q_ptr + size - i - 8));\n        sum_v = _mm256_add_epi32(sum_v, _mm256_sub_epi32(vec1, vec2));\n    }\n\n    int sum_arr[8];\n    _mm256_storeu_si256((__m256i*)sum_arr, sum_v);\n\n    for (int i = 0; i < 8; i++) {\n        sum += sum_arr[i];\n    }\n\n    return sum <= w;\n}\n```"}
{"task_id": "SimdBench_97_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint smallest_change_simd(std::vector<int> arr){\n    const int n = arr.size();\n    const int simdSize = 8;\n    const int remainder = n % simdSize;\n    const int padding = (remainder == 0) ? 0 : (simdSize - remainder);\n\n    std::vector<int> paddedArr(arr);\n    paddedArr.insert(paddedArr.end(), padding, 0);\n\n    int changes = 0;\n    for (int i = 0; i < n / simdSize; ++i) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&paddedArr[i * simdSize]);\n        __m256i revVec = _mm256_reverse_epi32(vec);\n        __m256i cmp = _mm256_cmpeq_epi32(vec, revVec);\n        changes += _mm256_movemask_ps(_mm256_castsi256_ps(cmp)) ^ 0xFF;\n    }\n\n    return changes;\n}\n```"}
{"task_id": "SimdBench_97_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint smallest_change_simd(std::vector<int> arr){\n    int n = arr.size();\n    int half = n / 2;\n    \n    __m256i changes = _mm256_setzero_si256();\n    \n    for (int i = 0; i < half; i += 8) {\n        __m256i front = _mm256_loadu_si256((__m256i*)&arr[i]);\n        __m256i back = _mm256_loadu_si256((__m256i*)&arr[n - i - 8]);\n        \n        __m256i cmp = _mm256_cmpeq_epi32(front, back);\n        changes = _mm256_sub_epi32(changes, cmp);\n    }\n    \n    int result[8];\n    _mm256_storeu_si256((__m256i*)result, changes);\n    \n    int total_changes = 0;\n    for (int i = 0; i < 8; i++) {\n        total_changes += result[i];\n    }\n    \n    return total_changes;\n}\n```"}
{"task_id": "SimdBench_97_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint smallest_change_simd(std::vector<int> arr){\n    int n = arr.size();\n    int half = n / 2;\n    \n    __m256i changes = _mm256_setzero_si256();\n    \n    for (int i = 0; i < half; i += 8) {\n        __m256i front = _mm256_loadu_si256((__m256i*)&arr[i]);\n        __m256i back = _mm256_loadu_si256((__m256i*)&arr[n - i - 8]);\n        \n        __m256i cmp = _mm256_cmpeq_epi32(front, back);\n        changes = _mm256_sub_epi32(changes, cmp);\n    }\n    \n    int result[8];\n    _mm256_storeu_si256((__m256i*)result, changes);\n    \n    int total_changes = 0;\n    for (int i = 0; i < 8; i++) {\n        total_changes += result[i];\n    }\n    \n    return total_changes;\n}\n```"}
{"task_id": "SimdBench_97_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint smallest_change_simd(std::vector<int> arr){\n    int n = arr.size();\n    int changes = 0;\n    \n    for (int i = 0; i < n / 2; i += 8) {\n        __m256i vec1 = _mm256_loadu_si256((__m256i*)&arr[i]);\n        __m256i vec2 = _mm256_loadu_si256((__m256i*)&arr[n - i - 8]);\n        \n        __m256i cmp = _mm256_cmpeq_epi32(vec1, vec2);\n        int mask = _mm256_movemask_ps(_mm256_castsi256_ps(cmp));\n        \n        changes += _mm_popcnt_u32(mask);\n    }\n    \n    return changes;\n}\n```"}
{"task_id": "SimdBench_97_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nint smallest_change_simd(std::vector<int> arr){\n    int n = arr.size();\n    int half = n / 2;\n    \n    __m256i changes = _mm256_setzero_si256();\n    \n    for (int i = 0; i < half; i += 8) {\n        __m256i front = _mm256_loadu_si256((__m256i*)&arr[i]);\n        __m256i back = _mm256_loadu_si256((__m256i*)&arr[n - i - 8]);\n        \n        __m256i cmp = _mm256_cmpeq_epi32(front, back);\n        changes = _mm256_add_epi32(changes, _mm256_andnot_si256(cmp, _mm256_set1_epi32(1)));\n    }\n    \n    int result[8];\n    _mm256_storeu_si256((__m256i*)result, changes);\n    \n    int total_changes = 0;\n    for (int i = 0; i < 8; i++) {\n        total_changes += result[i];\n    }\n    \n    return total_changes;\n}\n```"}
{"task_id": "SimdBench_98_AVX", "completion": "```\nstd::vector<std::string> total_match_simd(const std::vector<std::string> & lst1, const std::vector<std::string> & lst2){\n    std::vector<std::string> result;\n    __m256i zero = _mm256_setzero_si256();\n    __m256i sum1 = zero, sum2 = zero;\n    \n    for (const auto &str : lst1) {\n        sum1 = _mm256_add_epi32(sum1, _mm256_set1_epi32(str.size()));\n    }\n    \n    for (const auto &str : lst2) {\n        sum2 = _mm256_add_epi32(sum2, _mm256_set1_epi32(str.size()));\n    }\n    \n    __m256i cmp = _mm256_cmpgt_epi32(sum1, sum2);\n    int mask = _mm256_movemask_ps(_mm256_castsi256_ps(cmp));\n    \n    if (mask == 0) {\n        result = lst1;\n    } else {\n        result = lst2;\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_98_AVX", "completion": "```\nstd::vector<std::string> total_match_simd(const std::vector<std::string> & lst1, const std::vector<std::string> & lst2){\n    std::vector<std::string> result;\n    int total_chars_lst1 = 0;\n    int total_chars_lst2 = 0;\n\n    for (const auto& str : lst1) {\n        total_chars_lst1 += str.size();\n    }\n\n    for (const auto& str : lst2) {\n        total_chars_lst2 += str.size();\n    }\n\n    if (total_chars_lst1 < total_chars_lst2) {\n        result = lst1;\n    } else {\n        result = lst2;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_98_AVX", "completion": "```\nstd::vector<std::string> total_match_simd(const std::vector<std::string> & lst1, const std::vector<std::string> & lst2){\n    std::vector<std::string> result;\n    \n    __m256i total_chars1 = _mm256_setzero_si256();\n    __m256i total_chars2 = _mm256_setzero_si256();\n    \n    for (const auto &str : lst1) {\n        total_chars1 = _mm256_add_epi32(total_chars1, _mm256_set1_epi32(str.size()));\n    }\n    \n    for (const auto &str : lst2) {\n        total_chars2 = _mm256_add_epi32(total_chars2, _mm256_set1_epi32(str.size()));\n    }\n    \n    __m256i cmp = _mm256_cmpgt_epi32(total_chars1, total_chars2);\n    \n    for (size_t i = 0; i < lst1.size(); ++i) {\n        if (_mm256_extract_epi32(cmp, i) == 0) {\n            result.push_back(lst1[i]);\n        }\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_98_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nstd::vector<std::string> total_match_simd(const std::vector<std::string> & lst1, const std::vector<std::string> & lst2){\n    std::vector<std::string> result;\n    \n    __m256i total1 = _mm256_setzero_si256();\n    __m256i total2 = _mm256_setzero_si256();\n    \n    for (const std::string& str : lst1) {\n        total1 = _mm256_add_epi32(total1, _mm256_set1_epi32(static_cast<int>(str.size())));\n    }\n    \n    for (const std::string& str : lst2) {\n        total2 = _mm256_add_epi32(total2, _mm256_set1_epi32(static_cast<int>(str.size())));\n    }\n    \n    __m256i cmp = _mm256_cmpgt_epi32(total1, total2);\n    \n    for (size_t i = 0; i < lst1.size(); ++i) {\n        if (_mm256_extract_epi32(cmp, i) == 0) {\n            result.push_back(lst1[i]);\n        }\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_98_AVX", "completion": "```\nstd::vector<std::string> total_match_simd(const std::vector<std::string> & lst1, const std::vector<std::string> & lst2){\n    std::vector<std::string> result;\n    int total_chars_lst1 = 0;\n    int total_chars_lst2 = 0;\n    \n    for (const auto& str : lst1) {\n        total_chars_lst1 += str.size();\n    }\n    \n    for (const auto& str : lst2) {\n        total_chars_lst2 += str.size();\n    }\n    \n    if (total_chars_lst1 < total_chars_lst2) {\n        result = lst1;\n    } else {\n        result = lst2;\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_99_AVX", "completion": "```cpp\nbool is_simple_power_simd(uint64_t x, uint64_t n){\n    if (x == 1) {\n        return true;\n    }\n    \n    if (x % n != 0) {\n        return false;\n    }\n    \n    uint64_t temp = x;\n    while (temp % n == 0) {\n        temp /= n;\n    }\n    \n    return temp == 1;\n}\n```"}
{"task_id": "SimdBench_99_AVX", "completion": "```cpp\nbool is_simple_power_simd(uint64_t x, uint64_t n){\n    if (x == 1) {\n        return true;\n    }\n    \n    if (x % n != 0) {\n        return false;\n    }\n    \n    uint64_t power = 1;\n    while (power < x) {\n        power *= n;\n    }\n    \n    return power == x;\n}\n```"}
{"task_id": "SimdBench_99_AVX", "completion": "```\nbool is_simple_power_simd(uint64_t x, uint64_t n){\n    if (x == 1) {\n        return true;\n    }\n    \n    if (n == 1) {\n        return false;\n    }\n    \n    __m256i vx = _mm256_set1_epi64x(x);\n    __m256i vn = _mm256_set1_epi64x(n);\n    \n    __m256i vresult = _mm256_set1_epi64x(1);\n    \n    while (true) {\n        __m256i vcmp = _mm256_cmpeq_epi64(vresult, vx);\n        if (_mm256_testz_si256(vcmp, _mm256_set1_epi64x(-1))) {\n            return false;\n        }\n        \n        if (_mm256_testc_si256(vcmp, _mm256_set1_epi64x(-1))) {\n            return true;\n        }\n        \n        vresult = _mm256_mullo_epi64(vresult, vn);\n    }\n}\n```"}
{"task_id": "SimdBench_99_AVX", "completion": "```\nbool is_simple_power_simd(uint64_t x, uint64_t n){\n    if (x == 1) {\n        return true;\n    }\n    \n    if (n == 1) {\n        return false;\n    }\n    \n    if (x % n != 0) {\n        return false;\n    }\n    \n    uint64_t temp = x;\n    while (temp % n == 0) {\n        temp /= n;\n    }\n    \n    return temp == 1;\n}\n```"}
{"task_id": "SimdBench_99_AVX", "completion": "```cpp\nbool is_simple_power_simd(uint64_t x, uint64_t n){\n    if (x == 1) return true;\n    if (n == 1) return false;\n\n    __m256i vx = _mm256_set1_epi64x(x);\n    __m256i vn = _mm256_set1_epi64x(n);\n\n    __m256i vresult = _mm256_set1_epi64x(1);\n    __m256i vpower = _mm256_set1_epi64x(1);\n\n    while (true) {\n        vpower = _mm256_mul_epu32(vpower, vn);\n        vresult = _mm256_or_si256(vresult, _mm256_cmpeq_epi64(vpower, vx));\n\n        __m256i cmp = _mm256_cmpgt_epi64(vpower, vx);\n        if (_mm256_testz_si256(cmp, cmp)) break;\n    }\n\n    return !_mm256_testz_si256(vresult, vresult);\n}\n```"}
{"task_id": "SimdBench_100_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nint hex_key_simd(const std::string & num){\n    const __m256i primes = _mm256_setr_epi8(2, 3, 5, 7, 11, 13, 17, 2, 3, 5, 7, 11, 13, 17, 2, 3);\n    const __m256i hex_chars = _mm256_setr_epi8('0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F');\n    const __m256i mask = _mm256_set1_epi8(0x0F);\n    \n    int count = 0;\n    for (size_t i = 0; i < num.size(); i += 32) {\n        __m256i input = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&num[i]));\n        __m256i cmp = _mm256_cmpeq_epi8(_mm256_shuffle_epi8(hex_chars, _mm256_and_si256(input, mask)), hex_chars);\n        __m256i primes_mask = _mm256_shuffle_epi8(primes, _mm256_and_si256(input, mask));\n        __m256i result = _mm256_cmpeq_epi8(cmp, primes_mask);\n        \n        count += _mm_popcnt_u32(_mm256_movemask_epi8(result));\n    }\n    \n    return count;\n}\n```"}
{"task_id": "SimdBench_100_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nint hex_key_simd(const std::string & num){\n    const __m256i primes = _mm256_setr_epi8(2, 3, 5, 7, 11, 13, 17, 0, 2, 3, 5, 7, 11, 13, 17, 0, 2, 3, 5, 7, 11, 13, 17, 0, 2, 3, 5, 7, 11, 13, 17, 0);\n    const __m256i hex_values = _mm256_setr_epi8('0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F');\n    const __m256i mask = _mm256_set1_epi8(0x0F);\n    int count = 0;\n\n    for (size_t i = 0; i < num.size(); i += 32) {\n        __m256i input = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&num[i]));\n        __m256i input_lower = _mm256_and_si256(input, mask);\n        __m256i cmp_result = _mm256_cmpeq_epi8(hex_values, input_lower);\n        __m256i cmp_result_primes = _mm256_shuffle_epi8(primes, input_lower);\n        __m256i cmp_result_final = _mm256_cmpeq_epi8(cmp_result_primes, cmp_result);\n        count += _mm256_popcnt_u32(_mm256_movemask_epi8(cmp_result_final));\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_100_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nint hex_key_simd(const std::string & num){\n    const __m256i primes = _mm256_setr_epi8(2, 3, 5, 7, 11, 13, 17, 0, 2, 3, 5, 7, 11, 13, 17, 0, 2, 3, 5, 7, 11, 13, 17, 0, 2, 3, 5, 7, 11, 13, 17, 0);\n    const __m256i hex_chars = _mm256_setr_epi8('0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F');\n    const __m256i mask = _mm256_set1_epi8(0x0F);\n    __m256i count = _mm256_setzero_si256();\n\n    for (size_t i = 0; i < num.size(); i += 32) {\n        __m256i input = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&num[i]));\n        __m256i cmp = _mm256_cmpeq_epi8(hex_chars, _mm256_and_si256(input, mask));\n        __m256i primes_mask = _mm256_shuffle_epi8(primes, input);\n        __m256i result = _mm256_and_si256(cmp, primes_mask);\n        count = _mm256_add_epi8(count, result);\n    }\n\n    alignas(32) int result[32];\n    _mm256_store_si256((__m256i*)result, count);\n\n    int total_count = 0;\n    for (int i = 0; i < 32; ++i) {\n        total_count += _mm_popcnt_u32(result[i]);\n    }\n\n    return total_count;\n}\n```"}
{"task_id": "SimdBench_100_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nint hex_key_simd(const std::string & num){\n    const __m256i primes = _mm256_set_epi8(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 'D', 0, 'B', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n    const __m256i mask = _mm256_set1_epi8(0x0F);\n    const __m256i ascii_0 = _mm256_set1_epi8('0');\n    const __m256i ascii_9 = _mm256_set1_epi8('9');\n    const __m256i ascii_A = _mm256_set1_epi8('A');\n    const __m256i ascii_F = _mm256_set1_epi8('F');\n    \n    int count = 0;\n    for (size_t i = 0; i < num.size(); i += 32) {\n        __m256i input = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&num[i]));\n        __m256i masked_input = _mm256_and_si256(input, mask);\n        \n        __m256i is_digit = _mm256_and_si256(_mm256_cmpgt_epi8(masked_input, ascii_9), _mm256_cmplt_epi8(masked_input, ascii_A));\n        __m256i is_uppercase = _mm256_and_si256(_mm256_cmpgt_epi8(masked_input, ascii_F), _mm256_cmpgt_epi8(masked_input, ascii_9));\n        __m256i is_valid = _mm256_or_si256(is_digit, is_uppercase);\n        \n        __m256i primes_mask = _mm256_shuffle_epi8(primes, masked_input);\n        __m256i primes_count = _mm256_and_si256(primes_mask, is_valid);\n        \n        count += _mm_popcnt_u32(_mm256_movemask_epi8(primes_count));\n    }\n    \n    return count;\n}\n```"}
{"task_id": "SimdBench_100_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nint hex_key_simd(const std::string & num){\n    const __m256i primes = _mm256_setr_epi8(2, 3, 5, 7, 11, 13, 17, 0, 2, 3, 5, 7, 11, 13, 17, 0, 2, 3, 5, 7, 11, 13, 17, 0, 2, 3, 5, 7, 11, 13, 17, 0);\n    const __m256i hex_chars = _mm256_setr_epi8('0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F');\n    const __m256i mask = _mm256_set1_epi8(0x1);\n    __m256i count = _mm256_setzero_si256();\n\n    for (size_t i = 0; i < num.size(); i += 32) {\n        __m256i input = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&num[i]));\n        __m256i cmp = _mm256_cmpeq_epi8(hex_chars, input);\n        __m256i cmp_primes = _mm256_shuffle_epi8(primes, input);\n        __m256i cmp_result = _mm256_and_si256(cmp, cmp_primes);\n        __m256i count_add = _mm256_and_si256(cmp_result, mask);\n        count = _mm256_add_epi8(count, count_add);\n    }\n\n    alignas(32) int result[32];\n    _mm256_store_si256((__m256i*)result, count);\n\n    int total_count = 0;\n    for (int i = 0; i < 32; ++i) {\n        total_count += result[i];\n    }\n\n    return total_count;\n}\n```"}
{"task_id": "SimdBench_101_AVX", "completion": "```\nbool is_happy_simd(const std::string & s){\n    if(s.size() < 3) return false;\n    \n    const char* str = s.c_str();\n    int size = s.size();\n    \n    for(int i = 0; i <= size - 24; i += 24){\n        __m256i chunk1 = _mm256_loadu_si256((__m256i*)(str + i));\n        __m256i chunk2 = _mm256_loadu_si256((__m256i*)(str + i + 8));\n        __m256i chunk3 = _mm256_loadu_si256((__m256i*)(str + i + 16));\n        \n        __m256i cmp1 = _mm256_cmpeq_epi8(chunk1, chunk2);\n        __m256i cmp2 = _mm256_cmpeq_epi8(chunk2, chunk3);\n        __m256i cmp3 = _mm256_cmpeq_epi8(chunk1, chunk3);\n        \n        if(_mm256_movemask_epi8(_mm256_or_si256(_mm256_or_si256(cmp1, cmp2), cmp3)) != 0){\n            return false;\n        }\n    }\n    \n    for(int i = size - (size % 24); i <= size - 3; ++i){\n        if(str[i] == str[i + 1] || str[i] == str[i + 2] || str[i + 1] == str[i + 2]){\n            return false;\n        }\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_101_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nbool is_happy_simd(const std::string & s){\n    if(s.size() < 3) return false;\n\n    const char* str = s.c_str();\n    int size = s.size();\n\n    for(int i = 0; i <= size - 24; i += 24){\n        __m256i chunk1 = _mm256_loadu_si256((__m256i*)(str + i));\n        __m256i chunk2 = _mm256_loadu_si256((__m256i*)(str + i + 8));\n        __m256i chunk3 = _mm256_loadu_si256((__m256i*)(str + i + 16));\n\n        __m256i cmp1 = _mm256_cmpeq_epi8(chunk1, chunk2);\n        __m256i cmp2 = _mm256_cmpeq_epi8(chunk2, chunk3);\n        __m256i cmp3 = _mm256_cmpeq_epi8(chunk3, chunk1);\n\n        __m256i cmp = _mm256_or_si256(_mm256_or_si256(cmp1, cmp2), cmp3);\n\n        if(_mm256_movemask_epi8(cmp) != 0){\n            return false;\n        }\n    }\n\n    for(int i = size - (size % 24); i <= size - 3; i++){\n        if(str[i] == str[i + 1] || str[i] == str[i + 2] || str[i + 1] == str[i + 2]){\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_101_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nbool is_happy_simd(const std::string & s){\n    if(s.size() < 3) {\n        return false;\n    }\n\n    const char* str = s.c_str();\n    int size = s.size();\n\n    for(int i = 0; i <= size - 24; i += 24) {\n        __m256i chunk1 = _mm256_loadu_si256((__m256i*)(str + i));\n        __m256i chunk2 = _mm256_loadu_si256((__m256i*)(str + i + 8));\n        __m256i chunk3 = _mm256_loadu_si256((__m256i*)(str + i + 16));\n\n        __m256i cmp1 = _mm256_cmpeq_epi8(chunk1, chunk2);\n        __m256i cmp2 = _mm256_cmpeq_epi8(chunk2, chunk3);\n        __m256i cmp3 = _mm256_cmpeq_epi8(chunk3, chunk1);\n\n        __m256i cmp = _mm256_or_si256(_mm256_or_si256(cmp1, cmp2), cmp3);\n\n        if(_mm256_movemask_epi8(cmp) != 0) {\n            return false;\n        }\n    }\n\n    for(int i = size - (size % 24); i <= size - 3; i += 3) {\n        if(str[i] == str[i + 1] || str[i] == str[i + 2] || str[i + 1] == str[i + 2]) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_101_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nbool is_happy_simd(const std::string & s){\n    if(s.size() < 3) {\n        return false;\n    }\n\n    const char* str = s.c_str();\n    int size = s.size();\n\n    for(int i = 0; i <= size - 24; i += 24) {\n        __m256i chunk1 = _mm256_loadu_si256((__m256i*)(str + i));\n        __m256i chunk2 = _mm256_loadu_si256((__m256i*)(str + i + 8));\n        __m256i chunk3 = _mm256_loadu_si256((__m256i*)(str + i + 16));\n\n        __m256i cmp1 = _mm256_cmpeq_epi8(chunk1, chunk2);\n        __m256i cmp2 = _mm256_cmpeq_epi8(chunk2, chunk3);\n        __m256i cmp3 = _mm256_cmpeq_epi8(chunk1, chunk3);\n\n        if(_mm256_movemask_epi8(_mm256_or_si256(_mm256_or_si256(cmp1, cmp2), cmp3)) != 0) {\n            return false;\n        }\n    }\n\n    for(int i = size - (size % 24); i <= size - 3; ++i) {\n        if(str[i] == str[i + 1] || str[i] == str[i + 2] || str[i + 1] == str[i + 2]) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_101_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nbool is_happy_simd(const std::string & s){\n    if(s.size() < 3) return false;\n    \n    const char* str = s.c_str();\n    int size = s.size();\n    \n    for(int i = 0; i <= size - 24; i += 24){\n        __m256i chunk1 = _mm256_loadu_si256((__m256i*)(str + i));\n        __m256i chunk2 = _mm256_loadu_si256((__m256i*)(str + i + 8));\n        __m256i chunk3 = _mm256_loadu_si256((__m256i*)(str + i + 16));\n        \n        __m256i cmp1 = _mm256_cmpeq_epi8(chunk1, chunk2);\n        __m256i cmp2 = _mm256_cmpeq_epi8(chunk2, chunk3);\n        __m256i cmp3 = _mm256_cmpeq_epi8(chunk3, chunk1);\n        \n        if(_mm256_movemask_epi8(_mm256_or_si256(_mm256_or_si256(cmp1, cmp2), cmp3)) != 0){\n            return false;\n        }\n    }\n    \n    for(int i = size - (size % 24); i <= size - 3; i += 3){\n        if(str[i] == str[i + 1] || str[i] == str[i + 2] || str[i + 1] == str[i + 2]){\n            return false;\n        }\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_102_AVX", "completion": "```\nbool prime_length_simd(const std::string & str){\n    int len = str.length();\n    if(len <= 2) return true;\n    \n    __m256i primes = _mm256_set_epi32(2, 3, 5, 7, 11, 13, 17, 19);\n    __m256i divisors = _mm256_set1_epi32(2);\n    \n    for(int i = 2; i * i <= len; ++i){\n        __m256i i_vec = _mm256_set1_epi32(i);\n        __m256i is_prime = _mm256_cmpeq_epi32(_mm256_set1_epi32(0), _mm256_and_si256(_mm256_cmpgt_epi32(_mm256_set1_epi32(0), _mm256_sub_epi32(_mm256_mullo_epi32(i_vec, i_vec), _mm256_set1_epi32(len))), _mm256_set1_epi32(1)));\n        divisors = _mm256_or_si256(divisors, _mm256_and_si256(i_vec, is_prime));\n    }\n    \n    __m256i is_prime_len = _mm256_cmpeq_epi32(_mm256_set1_epi32(0), _mm256_and_si256(_mm256_cmpgt_epi32(_mm256_set1_epi32(0), _mm256_sub_epi32(_mm256_set1_epi32(len), divisors)), _mm256_set1_epi32(1)));\n    \n    return _mm256_testz_si256(is_prime_len, primes);\n}\n```"}
{"task_id": "SimdBench_102_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nbool is_prime(int n) {\n    if (n <= 1) return false;\n    if (n <= 3) return true;\n    if (n % 2 == 0 || n % 3 == 0) return false;\n    for (int i = 5; i * i <= n; i += 6) {\n        if (n % i == 0 || n % (i + 2) == 0) return false;\n    }\n    return true;\n}\n\nbool prime_length_simd(const std::string & str){\n    int length = str.length();\n    return is_prime(length);\n}\n```"}
{"task_id": "SimdBench_102_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nbool is_prime(int n) {\n    if (n <= 1) return false;\n    if (n <= 3) return true;\n    if (n % 2 == 0 || n % 3 == 0) return false;\n    for (int i = 5; i * i <= n; i += 6) {\n        if (n % i == 0 || n % (i + 2) == 0) return false;\n    }\n    return true;\n}\n\nbool prime_length_simd(const std::string & str){\n    int len = str.length();\n    return is_prime(len);\n}\n```"}
{"task_id": "SimdBench_102_AVX", "completion": "```\nbool prime_length_simd(const std::string & str){\n    int len = str.length();\n    if (len <= 2) return true;\n    \n    __m256i primes = _mm256_set_epi32(2, 3, 5, 7, 11, 13, 17, 19);\n    for (int i = 0; i < 8; ++i) {\n        if (len == _mm256_extract_epi32(primes, i)) return true;\n    }\n    \n    for (int i = 20; i * i <= len; i += 20) {\n        __m256i divisors = _mm256_set_epi32(i, i + 1, i + 3, i + 7, i + 9, i + 11, i + 13, i + 17);\n        __m256i mod = _mm256_set1_epi32(len % i);\n        __m256i cmp = _mm256_cmpeq_epi32(mod, _mm256_setzero_si256());\n        if (_mm256_movemask_ps((__m256)cmp) == 0xFF) return false;\n        \n        mod = _mm256_set1_epi32(len % (i + 19));\n        cmp = _mm256_cmpeq_epi32(mod, _mm256_setzero_si256());\n        if (_mm256_movemask_ps((__m256)cmp) == 0xFF) return false;\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_102_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nbool is_prime(int n) {\n    if (n <= 1) return false;\n    if (n <= 3) return true;\n    if (n % 2 == 0 || n % 3 == 0) return false;\n    for (int i = 5; i * i <= n; i += 6) {\n        if (n % i == 0 || n % (i + 2) == 0) return false;\n    }\n    return true;\n}\n\nbool prime_length_simd(const std::string & str){\n    int len = str.length();\n    return is_prime(len);\n}\n```"}
{"task_id": "SimdBench_103_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nstd::string solve_simd(uint64_t N){\n    __m256i sum = _mm256_setzero_si256();\n    __m256i mask = _mm256_set1_epi8(0x0F);\n    __m256i zero = _mm256_setzero_si256();\n    __m256i base = _mm256_set1_epi8(48); // ASCII value for '0'\n\n    while(N > 0){\n        __m256i digits = _mm256_set_epi8(N % 10, (N / 10) % 10, (N / 100) % 10, (N / 1000) % 10,\n                                         (N / 10000) % 10, (N / 100000) % 10, (N / 1000000) % 10, (N / 10000000) % 10,\n                                         N % 10, (N / 10) % 10, (N / 100) % 10, (N / 1000) % 10,\n                                         (N / 10000) % 10, (N / 100000) % 10, (N / 1000000) % 10, (N / 10000000) % 10);\n        __m256i low_nibble = _mm256_and_si256(digits, mask);\n        __m256i high_nibble = _mm256_and_si256(_mm256_srli_epi16(digits, 4), mask);\n        sum = _mm256_add_epi8(sum, low_nibble);\n        sum = _mm256_add_epi8(sum, high_nibble);\n        N /= 100000000;\n    }\n\n    __m256i cmp = _mm256_cmpgt_epi8(zero, sum);\n    __m256i result = _mm256_blendv_epi8(base, _mm256_add_epi8(base, sum), cmp);\n\n    alignas(32) int result_arr[32];\n    _mm256_store_si256((__m256i*)result_arr, result);\n\n    std::string binary_str;\n    for(int i = 0; i < 32; ++i){\n        binary_str += (char)result_arr[i];\n    }\n\n    return binary_str;\n}\n```"}
{"task_id": "SimdBench_103_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nstd::string solve_simd(uint64_t N){\n    __m256i sum = _mm256_setzero_si256();\n    __m256i ascii_0 = _mm256_set1_epi8('0');\n    __m256i ascii_2 = _mm256_set1_epi8('2');\n    \n    while(N > 0){\n        __m256i digits = _mm256_set1_epi8(N % 10);\n        __m256i is_greater_than_1 = _mm256_cmpgt_epi8(digits, ascii_2);\n        __m256i add_val = _mm256_blendv_epi8(digits, _mm256_set1_epi8(1), is_greater_than_1);\n        sum = _mm256_add_epi8(sum, add_val);\n        N /= 10;\n    }\n    \n    alignas(32) int result[32];\n    _mm256_store_si256((__m256i*)result, sum);\n    \n    std::string binary_str;\n    for(int i = 31; i >= 0; i--){\n        binary_str += std::bitset<8>(result[i]).to_string();\n    }\n    \n    return binary_str;\n}\n```"}
{"task_id": "SimdBench_103_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nstd::string solve_simd(uint64_t N){\n    __m256i sum = _mm256_setzero_si256();\n    __m256i ascii_0 = _mm256_set1_epi8('0');\n    __m256i ascii_2 = _mm256_set1_epi8('2');\n    \n    while(N > 0){\n        __m256i digits = _mm256_setr_epi8(N % 2, (N/2) % 2, (N/4) % 2, (N/8) % 2, (N/16) % 2, (N/32) % 2, (N/64) % 2, (N/128) % 2,\n                                           N % 2, (N/2) % 2, (N/4) % 2, (N/8) % 2, (N/16) % 2, (N/32) % 2, (N/64) % 2, (N/128) % 2);\n        __m256i mask = _mm256_cmpgt_epi8(digits, ascii_2);\n        digits = _mm256_sub_epi8(digits, _mm256_and_si256(mask, ascii_2));\n        sum = _mm256_add_epi8(sum, digits);\n        N >>= 8;\n    }\n    \n    alignas(32) int result[32];\n    _mm256_store_si256((__m256i*)result, sum);\n    \n    std::string binary_str;\n    for(int i = 0; i < 32; ++i){\n        binary_str += std::bitset<8>(result[i]).to_string();\n    }\n    \n    return binary_str;\n}\n```"}
{"task_id": "SimdBench_103_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nstd::string solve_simd(uint64_t N){\n    __m256i sum = _mm256_setzero_si256();\n    __m256i ascii_0 = _mm256_set1_epi8('0');\n    __m256i ascii_2 = _mm256_set1_epi8('2');\n    \n    while(N > 0){\n        __m256i digits = _mm256_setr_epi8(N % 2, (N/2) % 2, (N/4) % 2, (N/8) % 2, (N/16) % 2, (N/32) % 2, (N/64) % 2, (N/128) % 2,\n                                           N % 2, (N/2) % 2, (N/4) % 2, (N/8) % 2, (N/16) % 2, (N/32) % 2, (N/64) % 2, (N/128) % 2);\n        __m256i mask = _mm256_cmpgt_epi8(digits, ascii_2);\n        digits = _mm256_and_si256(digits, mask);\n        sum = _mm256_add_epi8(sum, digits);\n        N >>= 8;\n    }\n    \n    alignas(32) int result[32];\n    _mm256_store_si256((__m256i*)result, sum);\n    \n    std::string binary_str;\n    for(int i = 0; i < 32; ++i){\n        binary_str += (char)(result[i] + '0');\n    }\n    \n    return binary_str;\n}\n```"}
{"task_id": "SimdBench_103_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nstd::string solve_simd(uint64_t N){\n    __m256i sum = _mm256_setzero_si256();\n    __m256i mask = _mm256_set1_epi8(0x0F);\n    __m256i zero = _mm256_setzero_si256();\n    __m256i base = _mm256_set1_epi8(48); // ASCII value of '0'\n    \n    while(N > 0){\n        __m256i digits = _mm256_set_epi8(\n            N % 10, (N / 10) % 10, (N / 100) % 10, (N / 1000) % 10,\n            (N / 10000) % 10, (N / 100000) % 10, (N / 1000000) % 10, (N / 10000000) % 10,\n            N % 10, (N / 10) % 10, (N / 100) % 10, (N / 1000) % 10,\n            (N / 10000) % 10, (N / 100000) % 10, (N / 1000000) % 10, (N / 10000000) % 10\n        );\n        __m256i low_nibble = _mm256_and_si256(digits, mask);\n        __m256i high_nibble = _mm256_and_si256(_mm256_srli_epi16(digits, 4), mask);\n        __m256i sum_low = _mm256_sad_epu8(low_nibble, zero);\n        __m256i sum_high = _mm256_sad_epu8(high_nibble, zero);\n        sum = _mm256_add_epi64(sum, _mm256_unpacklo_epi32(sum_low, sum_high));\n        N /= 100000000;\n    }\n    \n    __m128i sum128 = _mm_add_epi64(_mm256_extracti128_si256(sum, 0), _mm256_extracti128_si256(sum, 1));\n    __m128i sum64 = _mm_add_epi64(sum128, _mm_unpackhi_epi64(sum128, _mm_setzero_si128()));\n    \n    uint64_t result;\n    _mm_storel_epi64((__m128i*)&result, sum64);\n    \n    return std::bitset<64>(result).to_string();\n}\n```"}
{"task_id": "SimdBench_104_AVX", "completion": "```cpp\nint add_simd(std::vector<int> lst){\n    __m256i sum = _mm256_setzero_si256();\n    for (int i = 1; i < lst.size(); i += 2) {\n        __m256i values = _mm256_set_epi32(lst[i], lst[i-1], lst[i], lst[i-1], lst[i], lst[i-1], lst[i], lst[i-1]);\n        sum = _mm256_add_epi32(sum, values);\n    }\n    \n    int result[8];\n    _mm256_storeu_si256((__m256i*)result, sum);\n    \n    return result[0] + result[1] + result[2] + result[3];\n}\n```"}
{"task_id": "SimdBench_104_AVX", "completion": "```cpp\nint add_simd(std::vector<int> lst){\n    __m256i sum = _mm256_setzero_si256();\n    for (int i = 1; i < lst.size(); i += 2) {\n        __m256i values = _mm256_set_epi32(lst[i], lst[i-1], lst[i], lst[i-1], lst[i], lst[i-1], lst[i], lst[i-1]);\n        sum = _mm256_add_epi32(sum, values);\n    }\n    int result[8];\n    _mm256_storeu_si256((__m256i*)result, sum);\n    return result[0] + result[1] + result[2] + result[3];\n}\n```"}
{"task_id": "SimdBench_104_AVX", "completion": "```cpp\nint add_simd(std::vector<int> lst){\n    __m256i sum = _mm256_setzero_si256();\n    for (int i = 1; i < lst.size(); i += 2) {\n        __m256i values = _mm256_setr_epi32(lst[i], lst[i], lst[i], lst[i], lst[i], lst[i], lst[i], lst[i]);\n        sum = _mm256_add_epi32(sum, values);\n    }\n    \n    int result[8];\n    _mm256_storeu_si256((__m256i*)result, sum);\n    \n    return result[0] + result[1] + result[2] + result[3];\n}\n```"}
{"task_id": "SimdBench_104_AVX", "completion": "```cpp\nint add_simd(std::vector<int> lst){\n    __m256i sum = _mm256_setzero_si256();\n    for (int i = 1; i < lst.size(); i += 2) {\n        __m256i values = _mm256_setr_epi32(lst[i], lst[i], lst[i], lst[i], lst[i], lst[i], lst[i], lst[i]);\n        sum = _mm256_add_epi32(sum, values);\n    }\n    \n    int result[8];\n    _mm256_storeu_si256((__m256i*)result, sum);\n    \n    return result[0] + result[1] + result[2] + result[3];\n}\n```"}
{"task_id": "SimdBench_104_AVX", "completion": "```cpp\nint add_simd(std::vector<int> lst){\n    __m256i sum = _mm256_setzero_si256();\n    for (int i = 1; i < lst.size(); i += 2) {\n        __m256i values = _mm256_set_epi32(lst[i-1], lst[i], lst[i-1], lst[i], lst[i-1], lst[i], lst[i-1], lst[i]);\n        sum = _mm256_add_epi32(sum, values);\n    }\n    \n    int result[8];\n    _mm256_storeu_si256((__m256i*)result, sum);\n    \n    return result[0] + result[2] + result[4] + result[6];\n}\n```"}
{"task_id": "SimdBench_105_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nstd::string encrypt_simd(const std::string & s){\n    std::string result = s;\n    int len = s.size();\n\n    __m256i shift = _mm256_set1_epi8(2 * 2);\n\n    for (int i = 0; i < len; i += 32) {\n        __m256i input = _mm256_loadu_si256((__m256i*)(s.data() + i));\n        __m256i shifted = _mm256_add_epi8(input, shift);\n        _mm256_storeu_si256((__m256i*)(result.data() + i), shifted);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_105_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nstd::string encrypt_simd(const std::string & s){\n    std::string result = s;\n    __m256i shift = _mm256_set1_epi8(2 * 2);\n    int length = s.size();\n\n    for (int i = 0; i < length; i += 32) {\n        __m256i input = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&s[i]));\n        __m256i shifted = _mm256_add_epi8(input, shift);\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(&result[i]), shifted);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_105_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nstd::string encrypt_simd(const std::string & s){\n    std::string result = s;\n    __m256i shift = _mm256_set1_epi8(2 * 2);\n    int length = s.size();\n    \n    for (int i = 0; i < length; i += 32) {\n        __m256i input = _mm256_loadu_si256((__m256i*)(s.data() + i));\n        \n        // Lowercase letters range from 'a' to 'z' in ASCII\n        __m256i isLowercase = _mm256_and_si256(_mm256_cmpgt_epi8(input, _mm256_set1_epi8('a' - 1)), _mm256_cmplt_epi8(input, _mm256_set1_epi8('z' + 1)));\n        \n        // Uppercase letters range from 'A' to 'Z' in ASCII\n        __m256i isUppercase = _mm256_and_si256(_mm256_cmpgt_epi8(input, _mm256_set1_epi8('A' - 1)), _mm256_cmplt_epi8(input, _mm256_set1_epi8('Z' + 1)));\n        \n        // Shift lowercase letters\n        __m256i shiftedLowercase = _mm256_add_epi8(input, shift);\n        shiftedLowercase = _mm256_blendv_epi8(input, shiftedLowercase, isLowercase);\n        \n        // Shift uppercase letters\n        __m256i shiftedUppercase = _mm256_add_epi8(input, shift);\n        shiftedUppercase = _mm256_blendv_epi8(input, shiftedUppercase, isUppercase);\n        \n        // Combine lowercase and uppercase results\n        __m256i resultVec = _mm256_or_si256(shiftedLowercase, shiftedUppercase);\n        \n        _mm256_storeu_si256((__m256i*)(result.data() + i), resultVec);\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_105_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nstd::string encrypt_simd(const std::string & s){\n    std::string result = s;\n    __m256i shift = _mm256_set1_epi8(2 * 2);\n    int length = s.size();\n\n    for (int i = 0; i < length; i += 32) {\n        __m256i input = _mm256_loadu_si256((__m256i*)(s.data() + i));\n        __m256i upper_case_mask = _mm256_and_si256(_mm256_cmpgt_epi8(input, _mm256_set1_epi8('Z')), _mm256_set1_epi8(0x20));\n        __m256i rotated = _mm256_add_epi8(input, shift);\n        __m256i rotated_upper = _mm256_add_epi8(rotated, upper_case_mask);\n        __m256i result_mask = _mm256_and_si256(_mm256_cmpgt_epi8(rotated_upper, _mm256_set1_epi8('Z')), _mm256_set1_epi8(0x1F));\n        __m256i final_result = _mm256_sub_epi8(rotated_upper, result_mask);\n        _mm256_storeu_si256((__m256i*)(result.data() + i), final_result);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_105_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nstd::string encrypt_simd(const std::string & s){\n    std::string result = s;\n    __m256i shift = _mm256_set1_epi8(2 * 2); // Two places down by two\n\n    for (size_t i = 0; i < s.size(); i += 32) {\n        __m256i input = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&s[i]));\n        __m256i shifted = _mm256_add_epi8(input, shift);\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(&result[i]), shifted);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_106_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nstd::string encode_simd(const std::string & message){\n    std::string result = message;\n    const __m256i lowercase_mask = _mm256_set1_epi8(0b00100000); // Mask to convert uppercase to lowercase\n    const __m256i vowel_mask = _mm256_setr_epi8('A', 'E', 'I', 'O', 'U', 'a', 'e', 'i', 'o', 'u', 0, 0, 0, 0, 0, 0,\n                                                'C', 'E', 'G', 'I', 'K', 'c', 'e', 'g', 'i', 'k', 0, 0, 0, 0, 0, 0);\n    \n    for (size_t i = 0; i < message.size(); i += 32) {\n        __m256i input = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&message[i]));\n        \n        // Convert uppercase to lowercase\n        __m256i is_uppercase = _mm256_cmpgt_epi8(_mm256_set1_epi8('Z'), input);\n        __m256i lowercase = _mm256_or_si256(input, lowercase_mask);\n        __m256i processed = _mm256_blendv_epi8(input, lowercase, is_uppercase);\n        \n        // Replace vowels\n        __m256i is_vowel = _mm256_cmpeq_epi8(vowel_mask, _mm256_set1_epi8(0));\n        __m256i replaced_vowels = _mm256_shuffle_epi8(vowel_mask, processed);\n        processed = _mm256_blendv_epi8(processed, replaced_vowels, is_vowel);\n        \n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(&result[i]), processed);\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_106_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nstd::string encode_simd(const std::string & message){\n    std::string result = message;\n    __m256i lower_case_mask = _mm256_set1_epi8(0x1F); // Mask to convert uppercase to lowercase\n    __m256i vowels_mask = _mm256_setr_epi8('A', 'E', 'I', 'O', 'U', 'a', 'e', 'i', 'o', 'u', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0); // Mask for vowels\n    __m256i alphabet_shift = _mm256_setr_epi8(2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0); // Shift for vowels\n\n    int message_length = message.size();\n    int remaining_length = message_length % 32;\n    int i = 0;\n\n    for (; i < message_length - remaining_length; i += 32) {\n        __m256i input = _mm256_loadu_si256((__m256i*)(message.c_str() + i));\n        __m256i lower_case = _mm256_or_si256(input, lower_case_mask);\n        __m256i is_vowel = _mm256_cmpeq_epi8(lower_case, vowels_mask);\n        __m256i shifted_vowels = _mm256_add_epi8(lower_case, alphabet_shift);\n        __m256i result_vowels = _mm256_blendv_epi8(input, shifted_vowels, is_vowel);\n        _mm256_storeu_si256((__m256i*)(result.data() + i), result_vowels);\n    }\n\n    for (; i < message_length; ++i) {\n        char c = message[i];\n        if (c >= 'A' && c <= 'Z') {\n            c = (c - 'A') + 'a';\n        }\n        if (c == 'a' || c == 'e' || c == 'i' || c == 'o' || c == 'u') {\n            c += 2;\n        }\n        result[i] = c;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_106_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nstd::string encode_simd(const std::string & message){\n    std::string result = message;\n    const __m256i lowercase_mask = _mm256_set1_epi8(0x1F);\n    const __m256i uppercase_mask = _mm256_set1_epi8(0xDF);\n    const __m256i vowels_mask = _mm256_setr_epi8('A', 'E', 'I', 'O', 'U', 'a', 'e', 'i', 'o', 'u', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n\n    for (size_t i = 0; i < message.size(); i += 32) {\n        __m256i chunk = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&message[i]));\n        \n        // Swap case\n        __m256i is_lower = _mm256_and_si256(chunk, lowercase_mask);\n        __m256i is_upper = _mm256_and_si256(chunk, uppercase_mask);\n        chunk = _mm256_or_si256(is_lower, _mm256_slli_epi16(is_upper, 1));\n\n        // Replace vowels\n        __m256i is_vowel = _mm256_cmpeq_epi8(chunk, vowels_mask);\n        __m256i replacement = _mm256_add_epi8(chunk, _mm256_set1_epi8(2));\n        chunk = _mm256_blendv_epi8(chunk, replacement, is_vowel);\n\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(&result[i]), chunk);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_106_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nstd::string encode_simd(const std::string & message){\n    std::string result = message;\n    const __m256i lowerCaseMask = _mm256_set1_epi8(0x1F);\n    const __m256i upperCaseMask = _mm256_set1_epi8(0xDF);\n    const __m256i vowelsMask = _mm256_setr_epi8('A', 'E', 'I', 'O', 'U', 'a', 'e', 'i', 'o', 'u', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n\n    for (size_t i = 0; i < message.size(); i += 32) {\n        __m256i chunk = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&message[i]));\n\n        // Swap case\n        __m256i isLowerCase = _mm256_and_si256(chunk, lowerCaseMask);\n        __m256i isUpperCase = _mm256_and_si256(chunk, upperCaseMask);\n        chunk = _mm256_or_si256(isLowerCase, _mm256_slli_epi16(isUpperCase, 1));\n\n        // Replace vowels\n        __m256i isVowel = _mm256_cmpeq_epi8(chunk, vowelsMask);\n        __m256i replacement = _mm256_add_epi8(chunk, _mm256_set1_epi8(2));\n        chunk = _mm256_blendv_epi8(chunk, replacement, isVowel);\n\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(&result[i]), chunk);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_106_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nstd::string encode_simd(const std::string & message){\n    std::string result = message;\n    const __m256i lowercase_mask = _mm256_set1_epi8(0x1F);\n    const __m256i vowels_mask = _mm256_setr_epi8('A', 'E', 'I', 'O', 'U', 'a', 'e', 'i', 'o', 'u', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n\n    for (size_t i = 0; i < message.size(); i += 32) {\n        __m256i input = _mm256_loadu_si256((__m256i*)(message.c_str() + i));\n        \n        // Swap case of all letters\n        __m256i case_mask = _mm256_and_si256(_mm256_cmpgt_epi8(_mm256_set1_epi8('Z'), input), _mm256_set1_epi8(0x20));\n        __m256i swapped_case = _mm256_xor_si256(input, case_mask);\n\n        // Replace vowels with letters 2 places ahead\n        __m256i is_vowel = _mm256_cmpeq_epi8(_mm256_and_si256(input, lowercase_mask), vowels_mask);\n        __m256i replacement = _mm256_add_epi8(input, _mm256_and_si256(is_vowel, _mm256_set1_epi8(2)));\n        __m256i result_vowels = _mm256_blendv_epi8(input, replacement, is_vowel);\n\n        _mm256_storeu_si256((__m256i*)(result.data() + i), result_vowels);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_107_AVX", "completion": "```\nbool check_dict_case_simd(std::map<std::string, std::string> dict){\n    if(dict.empty()) return false;\n    \n    __m256i lowercase_mask = _mm256_set1_epi8(0x20); // Mask to convert uppercase to lowercase\n    \n    bool all_lowercase = true;\n    bool all_uppercase = true;\n    \n    for(auto it = dict.begin(); it != dict.end(); ++it){\n        std::string key = it->first;\n        \n        __m256i key_vec = _mm256_loadu_si256((__m256i*)key.c_str());\n        __m256i key_lowered = _mm256_or_si256(key_vec, lowercase_mask);\n        \n        __m256i cmp_result = _mm256_cmpeq_epi8(key_vec, key_lowered);\n        \n        int mask = _mm256_movemask_epi8(cmp_result);\n        \n        if(mask != 0xFF) all_lowercase = false;\n        if(mask != 0x00) all_uppercase = false;\n    }\n    \n    return all_lowercase || all_uppercase;\n}\n```"}
{"task_id": "SimdBench_107_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <map>\n#include <string>\n\nbool check_dict_case_simd(std::map<std::string, std::string> dict){\n    if(dict.empty()) return false;\n    \n    bool all_lower = true;\n    bool all_upper = true;\n    \n    for(auto const& entry : dict){\n        const std::string& key = entry.first;\n        \n        __m256i key_vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(key.c_str()));\n        __m256i upper_mask = _mm256_cmpgt_epi8(key_vec, _mm256_set1_epi8('Z'));\n        __m256i lower_mask = _mm256_cmpgt_epi8(_mm256_set1_epi8('a' - 1), key_vec);\n        \n        all_lower = all_lower && _mm256_testz_si256(upper_mask, upper_mask);\n        all_upper = all_upper && _mm256_testz_si256(lower_mask, lower_mask);\n        \n        if(!all_lower && !all_upper) return false;\n    }\n    \n    return all_lower || all_upper;\n}\n```"}
{"task_id": "SimdBench_107_AVX", "completion": "```\nbool check_dict_case_simd(std::map<std::string, std::string> dict){\n    if(dict.empty()) return false;\n    \n    __m256i lowercase_mask = _mm256_set1_epi8(0b00100000); // Mask to convert uppercase to lowercase\n    __m256i all_lowercase = _mm256_set1_epi8(0b01111111); // Mask to check if all characters are lowercase\n    __m256i all_uppercase = _mm256_set1_epi8(0b01011111); // Mask to check if all characters are uppercase\n    \n    for(auto& entry : dict){\n        std::string key = entry.first;\n        __m256i key_vec = _mm256_loadu_si256(reinterpret_cast<__m256i*>(key.c_str()));\n        \n        // Convert uppercase to lowercase\n        __m256i lowercase_key = _mm256_or_si256(key_vec, lowercase_mask);\n        \n        // Check if all characters are lowercase or all characters are uppercase\n        __m256i is_lowercase = _mm256_cmpeq_epi8(lowercase_key, all_lowercase);\n        __m256i is_uppercase = _mm256_cmpeq_epi8(key_vec, all_uppercase);\n        \n        __m256i result = _mm256_or_si256(is_lowercase, is_uppercase);\n        \n        if(!_mm256_testz_si256(result, result)){\n            return false;\n        }\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_107_AVX", "completion": "```\nbool check_dict_case_simd(std::map<std::string, std::string> dict){\n    if(dict.empty()) return false;\n    \n    __m256i lowercase_mask = _mm256_set1_epi8(0x1F); // Mask to convert uppercase to lowercase\n    __m256i all_lowercase = _mm256_set1_epi8(0); // Vector to store lowercase flag\n    __m256i all_uppercase = _mm256_set1_epi8(0); // Vector to store uppercase flag\n    \n    for(auto it = dict.begin(); it != dict.end(); ++it){\n        const std::string& key = it->first;\n        \n        if(key.empty()) continue;\n        \n        __m256i key_vec = _mm256_loadu_si256((__m256i*)key.c_str());\n        __m256i key_lower = _mm256_and_si256(key_vec, lowercase_mask);\n        __m256i key_upper = _mm256_and_si256(key_vec, _mm256_xor_si256(lowercase_mask, _mm256_set1_epi8(0xFF)));\n        \n        all_lowercase = _mm256_or_si256(all_lowercase, _mm256_cmpeq_epi8(key_vec, key_lower));\n        all_uppercase = _mm256_or_si256(all_uppercase, _mm256_cmpeq_epi8(key_vec, key_upper));\n    }\n    \n    __m256i all_lowercase_result = _mm256_cmpeq_epi8(all_lowercase, _mm256_set1_epi8(0xFF));\n    __m256i all_uppercase_result = _mm256_cmpeq_epi8(all_uppercase, _mm256_set1_epi8(0xFF));\n    \n    return _mm256_testz_si256(all_lowercase_result, all_uppercase_result);\n}\n```"}
{"task_id": "SimdBench_107_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <map>\n#include <string>\n\nbool check_dict_case_simd(std::map<std::string, std::string> dict){\n    if(dict.empty()) return false;\n    \n    bool all_lower = true;\n    bool all_upper = true;\n    \n    for(auto const& pair : dict){\n        const std::string& key = pair.first;\n        for(size_t i = 0; i < key.size(); i += 32){\n            __m256i key_chars = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&key[i]));\n            __m256i is_lower = _mm256_and_si256(_mm256_cmpgt_epi8(_mm256_set1_epi8('z'), key_chars), _mm256_cmplt_epi8(_mm256_set1_epi8('a'), key_chars));\n            __m256i is_upper = _mm256_and_si256(_mm256_cmpgt_epi8(_mm256_set1_epi8('Z'), key_chars), _mm256_cmplt_epi8(_mm256_set1_epi8('A'), key_chars));\n            all_lower = all_lower && _mm256_testc_si256(is_lower, _mm256_set1_epi8(255));\n            all_upper = all_upper && _mm256_testc_si256(is_upper, _mm256_set1_epi8(255));\n        }\n    }\n    \n    return all_lower || all_upper;\n}\n```"}
{"task_id": "SimdBench_108_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> count_up_to_simd(int n){\n    std::vector<int> primes;\n    if (n < 2) return primes;\n\n    std::vector<int> is_prime(n, 1);\n    is_prime[0] = is_prime[1] = 0;\n\n    for (int i = 2; i * i < n; i++) {\n        if (is_prime[i]) {\n            for (int j = i * i; j < n; j += i) {\n                is_prime[j] = 0;\n            }\n        }\n    }\n\n    for (int i = 2; i < n; i++) {\n        if (is_prime[i]) {\n            primes.push_back(i);\n        }\n    }\n\n    return primes;\n}\n```"}
{"task_id": "SimdBench_108_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> count_up_to_simd(int n){\n    std::vector<int> primes;\n    if (n < 2) return primes;\n\n    primes.push_back(2);\n    if (n < 3) return primes;\n\n    primes.push_back(3);\n    if (n < 5) return primes;\n\n    __m256i primes_vec = _mm256_setr_epi32(2, 3, 5, 7, 11, 13, 17, 19);\n    __m256i mask = _mm256_cmpgt_epi32(_mm256_set1_epi32(n), primes_vec);\n    int mask_int = _mm256_movemask_ps((__m256)mask);\n\n    for (int i = 0; i < 8; ++i) {\n        if (mask_int & (1 << i)) {\n            primes.push_back(_mm256_extract_epi32(primes_vec, i));\n        }\n    }\n\n    return primes;\n}\n```"}
{"task_id": "SimdBench_108_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> count_up_to_simd(int n) {\n    if (n <= 2) {\n        return {};\n    }\n\n    std::vector<int> primes;\n    primes.reserve(n / 2);\n\n    __m256i primesVec = _mm256_setr_epi32(2, 3, 5, 7, 11, 13, 17, 19);\n    __m256i incrementVec = _mm256_set1_epi32(20);\n    __m256i maskVec = _mm256_set1_epi32(0);\n\n    for (int i = 0; i < n; i += 20) {\n        __m256i checkVec = _mm256_cmpgt_epi32(primesVec, _mm256_set1_epi32(i));\n        maskVec = _mm256_or_si256(maskVec, checkVec);\n    }\n\n    int mask = _mm256_movemask_ps(_mm256_castsi256_ps(maskVec));\n\n    for (int i = 0; i < 8; ++i) {\n        if (mask & (1 << i)) {\n            primes.push_back(_mm256_extract_epi32(primesVec, i));\n        }\n    }\n\n    return primes;\n}\n```"}
{"task_id": "SimdBench_108_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> count_up_to_simd(int n){\n    std::vector<int> primes;\n    if (n < 2) {\n        return primes;\n    }\n\n    primes.push_back(2);\n    if (n < 3) {\n        return primes;\n    }\n\n    primes.push_back(3);\n    if (n < 4) {\n        return primes;\n    }\n\n    __m256i primes_avx = _mm256_set_epi32(17, 13, 11, 7, 5, 3, 2, 0);\n    __m256i increment_avx = _mm256_set1_epi32(30);\n    __m256i current_avx = _mm256_set1_epi32(17);\n\n    for (int i = 19; i < n; i += 2) {\n        __m256i is_prime_mask = _mm256_set1_epi32(1);\n        __m256i sqrt_i_avx = _mm256_set1_epi32((int)sqrt(i));\n\n        for (int j = 0; j < 8; j++) {\n            __m256i prime_avx = _mm256_set1_epi32(primes[j]);\n            __m256i mod_avx = _mm256_and_si256(_mm256_set1_epi32(i), prime_avx);\n            __m256i cmp_avx = _mm256_cmpeq_epi32(_mm256_set1_epi32(0), mod_avx);\n            __m256i cmp_sqrt_avx = _mm256_cmpgt_epi32(sqrt_i_avx, prime_avx);\n            is_prime_mask = _mm256_and_si256(is_prime_mask, _mm256_or_si256(cmp_avx, cmp_sqrt_avx));\n        }\n\n        int mask = _mm256_movemask_ps(_mm256_castsi256_ps(is_prime_mask));\n        if (mask == 255) {\n            primes.push_back(i);\n        }\n\n        current_avx = _mm256_add_epi32(current_avx, increment_avx);\n        if (_mm256_movemask_ps(_mm256_castsi256_ps(_mm256_cmpgt_epi32(current_avx, _mm256_set1_epi32(n))) == 255) {\n            break;\n        }\n    }\n\n    return primes;\n}\n```"}
{"task_id": "SimdBench_108_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> count_up_to_simd(int n){\n    std::vector<int> primes;\n    if (n < 2) return primes;\n\n    primes.push_back(2);\n    if (n < 3) return primes;\n\n    primes.push_back(3);\n    if (n < 5) return primes;\n\n    __m256i primes_vec = _mm256_set_epi32(19, 17, 13, 11, 7, 5, 3, 2);\n    __m256i mask = _mm256_set1_epi32(0xFFFFFFFF);\n\n    for (int i = 21; i < n; i += 2) {\n        __m256i divisors = _mm256_set1_epi32(i);\n        __m256i rem = _mm256_set_epi32(19, 17, 13, 11, 7, 5, 3, 2);\n        __m256i is_prime = _mm256_set1_epi32(1);\n\n        for (int j = 0; j < 8; ++j) {\n            __m256i mod = _mm256_rem_epi32(divisors, rem);\n            __m256i cmp = _mm256_cmpeq_epi32(mod, _mm256_set1_epi32(0));\n            is_prime = _mm256_andnot_si256(cmp, is_prime);\n            rem = _mm256_sub_epi32(rem, _mm256_set1_epi32(1));\n        }\n\n        int prime_mask = _mm256_movemask_ps(_mm256_castsi256_ps(is_prime));\n        if (prime_mask == 0xFF) {\n            primes.push_back(i);\n        }\n    }\n\n    return primes;\n}\n```"}
{"task_id": "SimdBench_109_AVX", "completion": "```cpp\nint count_upper_simd(const std::string & s){\n    const __m256i vowels = _mm256_setr_epi8('A', 'E', 'I', 'O', 'U', 'A', 'E', 'I', 'O', 'U', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n    const __m256i mask = _mm256_set1_epi8(0x1F); // Mask to extract only the lower 5 bits (to ignore case)\n\n    int count = 0;\n    for (size_t i = 0; i < s.size(); i += 32) {\n        __m256i str = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&s[i]));\n        __m256i cmp = _mm256_cmpeq_epi8(_mm256_and_si256(_mm256_or_si256(_mm256_and_si256(str, mask), _mm256_set1_epi8(0x20)), vowels), vowels);\n        count += _mm_popcnt_u32(_mm256_movemask_epi8(cmp));\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_109_AVX", "completion": "```cpp\nint count_upper_simd(const std::string & s){\n    const __m256i vowels = _mm256_setr_epi8('A', 'E', 'I', 'O', 'U', 'a', 'e', 'i', 'o', 'u', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n    const __m256i mask = _mm256_set1_epi8(0x1F);\n    const __m256i indices = _mm256_setr_epi8(0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40, 42, 44, 46, 48, 50, 52, 54, 56, 58, 60, 62);\n\n    int count = 0;\n    for (size_t i = 0; i < s.size(); i += 32) {\n        __m256i str = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&s[i]));\n        __m256i str_upper = _mm256_and_si256(_mm256_or_si256(_mm256_and_si256(str, mask), _mm256_set1_epi8(0x20)), mask);\n        __m256i cmp = _mm256_cmpeq_epi8(vowels, str_upper);\n        __m256i result = _mm256_shuffle_epi8(cmp, indices);\n        count += _mm256_popcnt_u32(_mm256_movemask_epi8(result));\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_109_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nint count_upper_simd(const std::string & s){\n    const char* str = s.c_str();\n    const int len = s.length();\n    const __m256i vowels = _mm256_set_epi8('A', 'E', 'I', 'O', 'U', 'A', 'E', 'I', 'O', 'U', 'A', 'E', 'I', 'O', 'U', 'A', 'E', 'I', 'O', 'U', 'A', 'E', 'I', 'O', 'U', 'A', 'E', 'I', 'O', 'U', 'A', 'E', 'I', 'O', 'U');\n    int count = 0;\n\n    for (int i = 0; i < len; i += 32) {\n        __m256i str_chars = _mm256_loadu_si256((__m256i*)(str + i));\n        __m256i uppercase = _mm256_and_si256(_mm256_cmpeq_epi8(_mm256_and_si256(str_chars, _mm256_set1_epi8(0x20)), _mm256_set1_epi8(0)), _mm256_cmpgt_epi8(vowels, str_chars));\n        count += _mm256_popcnt_u32(_mm256_movemask_epi8(uppercase));\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_109_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nint count_upper_simd(const std::string & s){\n    const int len = s.length();\n    const char* str = s.c_str();\n    __m256i vowels = _mm256_set_epi8('A', 'E', 'I', 'O', 'U', 'A', 'E', 'I', 'O', 'U', 'A', 'E', 'I', 'O', 'U', 'A', 'E', 'I', 'O', 'U', 'A', 'E', 'I', 'O', 'U', 'A', 'E', 'I', 'O', 'U', 'A', 'E', 'I', 'O', 'U');\n    __m256i mask = _mm256_set1_epi8(0x1F);\n    int count = 0;\n\n    for (int i = 0; i < len; i += 32) {\n        __m256i chars = _mm256_loadu_si256((__m256i*)(str + i));\n        __m256i upper = _mm256_and_si256(_mm256_or_si256(_mm256_cmpeq_epi8(chars, _mm256_add_epi8(vowels, _mm256_set1_epi8('a' - 'A'))),\n                                                         _mm256_cmpeq_epi8(chars, _mm256_add_epi8(vowels, _mm256_set1_epi8('e' - 'A')))),\n                                         _mm256_set1_epi8(0x80));\n        __m256i even_indices = _mm256_and_si256(_mm256_setr_epi8(0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1,\n                                                                 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1),\n                                                _mm256_set1_epi8(0x80));\n        __m256i result = _mm256_and_si256(upper, even_indices);\n        count += _mm_popcnt_u32(_mm256_movemask_epi8(result));\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_109_AVX", "completion": "```cpp\nint count_upper_simd(const std::string & s){\n    const __m256i vowels = _mm256_setr_epi8('A', 'E', 'I', 'O', 'U', 'a', 'e', 'i', 'o', 'u', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n    const __m256i mask = _mm256_set1_epi8(0x1F);\n    const __m256i indices = _mm256_setr_epi8(0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40, 42, 44, 46, 48, 50, 52, 54);\n\n    int count = 0;\n    for (size_t i = 0; i < s.size(); i += 32) {\n        __m256i str = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&s[i]));\n        __m256i str_lower = _mm256_and_si256(str, mask);\n        __m256i cmp = _mm256_cmpeq_epi8(vowels, str_lower);\n        __m256i cmp_indices = _mm256_cmpeq_epi8(indices, _mm256_set1_epi8(i));\n        __m256i result = _mm256_and_si256(cmp, cmp_indices);\n        count += _mm256_popcnt_u32(_mm256_movemask_epi8(result));\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_110_AVX", "completion": "```cpp\nstd::vector<int> make_a_pile_simd(int n){\n    std::vector<int> result(n);\n    __m256i stones = _mm256_set1_epi32(n);\n    for (int i = 0; i < n; ++i) {\n        result[i] = n + 2 * i;\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_110_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nstd::vector<int> make_a_pile_simd(int n){\n    std::vector<int> result(n);\n    __m256i stones = _mm256_set1_epi32(n);\n    for(int i = 0; i < n; ++i){\n        result[i] = n + 2 * i;\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_110_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nstd::vector<int> make_a_pile_simd(int n){\n    std::vector<int> result(n);\n    int current_stones = n;\n    for (int i = 0; i < n; ++i) {\n        result[i] = current_stones;\n        current_stones += (n % 2 == 0) ? 2 : 1;\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_110_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> make_a_pile_simd(int n){\n    std::vector<int> result(n);\n    __m256i stones = _mm256_set1_epi32(n);\n    for(int i = 0; i < n; ++i){\n        result[i] = n + 2*i;\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_110_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nstd::vector<int> make_a_pile_simd(int n){\n    std::vector<int> result(n);\n    __m256i stones = _mm256_set1_epi32(n);\n    for(int i = 0; i < n; i += 8){\n        _mm256_storeu_si256((__m256i*)&result[i], stones);\n        stones = _mm256_add_epi32(stones, _mm256_setr_epi32(2, 2, 2, 2, 2, 2, 2, 2));\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_111_AVX", "completion": "```\nstd::string rounded_avg_simd(int64_t n, int64_t m){\n    if(n > m) {\n        return \"-1\";\n    }\n    \n    __m256i sum = _mm256_setzero_si256();\n    int count = 0;\n    \n    for(int i = n; i <= m; i += 8) {\n        __m256i values = _mm256_setr_epi32(i, i+1, i+2, i+3, i+4, i+5, i+6, i+7);\n        sum = _mm256_add_epi32(sum, values);\n        count += 8;\n    }\n    \n    __m256i avg = _mm256_srli_epi32(sum, 3); // Divide sum by count (8) to get average\n    avg = _mm256_add_epi32(avg, _mm256_set1_epi32(1)); // Round to nearest integer by adding 1\n    avg = _mm256_srli_epi32(avg, 1); // Divide by 2 to get the rounded average\n    \n    alignas(32) int result[8];\n    _mm256_store_si256((__m256i*)result, avg);\n    \n    std::string binaryResult = \"\";\n    for(int i = 7; i >= 0; i--) {\n        binaryResult += std::to_string(result[i] % 2);\n    }\n    \n    return binaryResult;\n}\n```"}
{"task_id": "SimdBench_111_AVX", "completion": "```\nstd::string rounded_avg_simd(int64_t n, int64_t m){\n    if(n > m) {\n        return \"-1\";\n    }\n    \n    __m256i sum = _mm256_setzero_si256();\n    int count = 0;\n    for(int i = n; i <= m; i += 8) {\n        __m256i values = _mm256_set_epi64x(i+7, i+6, i+5, i+4, i+3, i+2, i+1, i);\n        sum = _mm256_add_epi64(sum, values);\n        count += 8;\n    }\n    \n    __m256i avg = _mm256_srai_epi64(sum, 3); // Divide sum by count (8) to get average\n    __m256i rounded_avg = _mm256_round_pd(_mm256_cvtepi64_pd(avg), _MM_FROUND_TO_NEG_INF);\n    \n    alignas(32) int64_t result[4];\n    _mm256_store_si256((__m256i*)result, rounded_avg);\n    \n    std::string binary_result = \"\";\n    for(int i = 3; i >= 0; i--) {\n        for(int j = 63; j >= 0; j--) {\n            binary_result += ((result[i] >> j) & 1) ? \"1\" : \"0\";\n        }\n    }\n    \n    return binary_result;\n}\n```"}
{"task_id": "SimdBench_111_AVX", "completion": "```\nstd::string rounded_avg_simd(int64_t n, int64_t m){\n    if(n > m) {\n        return \"-1\";\n    }\n    \n    __m256i sum = _mm256_setzero_si256();\n    int count = 0;\n    \n    for(int i = n; i <= m; i += 8) {\n        __m256i values = _mm256_set_epi64x(i + 7, i + 6, i + 5, i + 4, i + 3, i + 2, i + 1, i);\n        sum = _mm256_add_epi64(sum, values);\n        count += 8;\n    }\n    \n    __m256i avg = _mm256_srli_epi64(sum, 3);\n    \n    int64_t avg_arr[4];\n    _mm256_storeu_si256((__m256i*)avg_arr, avg);\n    \n    int rounded_avg = (avg_arr[0] + avg_arr[1] + avg_arr[2] + avg_arr[3] + count / 2) / count;\n    \n    std::string binary_avg = std::bitset<64>(rounded_avg).to_string();\n    \n    return binary_avg.substr(64 - count, count);\n}\n```"}
{"task_id": "SimdBench_111_AVX", "completion": "```\nstd::string rounded_avg_simd(int64_t n, int64_t m){\n    if(n > m) {\n        return \"-1\";\n    }\n\n    __m256i sum = _mm256_setzero_si256();\n    int count = 0;\n\n    for(int i = n; i <= m; i += 8) {\n        __m256i values = _mm256_set_epi64x(i + 7, i + 6, i + 5, i + 4, i + 3, i + 2, i + 1, i);\n        sum = _mm256_add_epi64(sum, values);\n        count += 8;\n    }\n\n    __m256i avg = _mm256_srli_epi64(sum, 3); // Divide sum by 8 to get average\n    __m256i rounded_avg = _mm256_srai_epi64(_mm256_add_epi64(avg, _mm256_set1_epi64(1)), 1); // Round the average\n\n    alignas(32) int64_t result[4];\n    _mm256_store_si256((__m256i*)result, rounded_avg);\n\n    std::string binary_result = \"\";\n    for(int i = 3; i >= 0; i--) {\n        for(int j = 63; j >= 0; j--) {\n            binary_result += std::to_string((result[i] >> j) & 1);\n        }\n    }\n\n    return binary_result;\n}\n```"}
{"task_id": "SimdBench_111_AVX", "completion": "```\nstd::string rounded_avg_simd(int64_t n, int64_t m){\n    if(n > m) {\n        return \"-1\";\n    }\n    \n    __m256i sum = _mm256_setzero_si256();\n    int count = 0;\n    for(int i = n; i <= m; i += 8) {\n        __m256i values = _mm256_set_epi64x(i+7, i+6, i+5, i+4, i+3, i+2, i+1, i);\n        sum = _mm256_add_epi64(sum, values);\n        count += 8;\n    }\n    \n    __m256i avg = _mm256_srai_epi64(sum, 3); // Divide sum by count\n    __m256i rounded_avg = _mm256_round_epi64(avg, _MM_FROUND_TO_NEG_INF | _MM_FROUND_NO_EXC);\n    \n    alignas(32) int64_t result[4];\n    _mm256_store_si256((__m256i*)result, rounded_avg);\n    \n    std::string binary_result = \"\";\n    for(int i = 0; i < 4; i++) {\n        std::string binary = std::bitset<64>(result[i]).to_string();\n        binary_result += binary.substr(0, 32); // Consider only the lower 32 bits for each element\n    }\n    \n    return binary_result;\n}\n```"}
{"task_id": "SimdBench_112_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nstd::vector<int> func_simd(int n){\n    std::vector<int> result(n);\n    __m256i factorial = _mm256_set1_epi32(1);\n    __m256i sum = _mm256_set1_epi32(0);\n    \n    for (int i = 1; i <= n; i += 8) {\n        __m256i indices = _mm256_setr_epi32(i, i+1, i+2, i+3, i+4, i+5, i+6, i+7);\n        \n        __m256i is_even = _mm256_and_si256(_mm256_set1_epi32(1), _mm256_cmpeq_epi32(_mm256_and_si256(indices, _mm256_set1_epi32(1)), _mm256_set1_epi32(0)));\n        \n        __m256i factorial_mask = _mm256_and_si256(is_even, _mm256_set1_epi32(1));\n        __m256i sum_mask = _mm256_andnot_si256(is_even, _mm256_set1_epi32(1));\n        \n        for (int j = 1; j <= 8; ++j) {\n            factorial = _mm256_mullo_epi32(factorial, _mm256_and_si256(factorial_mask, indices));\n            sum = _mm256_add_epi32(sum, _mm256_and_si256(sum_mask, indices));\n            indices = _mm256_add_epi32(indices, _mm256_set1_epi32(8));\n        }\n    }\n    \n    _mm256_storeu_si256((__m256i*)&result[0], sum);\n    return result;\n}\n```"}
{"task_id": "SimdBench_112_AVX", "completion": "```cpp\nstd::vector<int> func_simd(int n){\n    std::vector<int> result(n);\n    __m256i sum = _mm256_setzero_si256();\n    __m256i fact = _mm256_set1_epi32(1);\n    __m256i mod = _mm256_set1_epi32(10000);\n\n    for (int i = 1; i <= n; i += 8) {\n        __m256i indices = _mm256_setr_epi32(i, i+1, i+2, i+3, i+4, i+5, i+6, i+7);\n        __m256i is_even = _mm256_and_si256(_mm256_set1_epi32(1), _mm256_cmpeq_epi32(_mm256_and_si256(indices, _mm256_set1_epi32(1)), _mm256_setzero_si256()));\n\n        __m256i factorial = _mm256_set1_epi32(1);\n        __m256i sum_partial = _mm256_setzero_si256();\n\n        for (int j = 1; j <= 8; j++) {\n            factorial = _mm256_mullo_epi32(factorial, indices);\n            __m256i mask = _mm256_cmpeq_epi32(is_even, _mm256_setzero_si256());\n            sum_partial = _mm256_add_epi32(sum_partial, _mm256_and_si256(mask, indices));\n            indices = _mm256_add_epi32(indices, _mm256_set1_epi32(1));\n        }\n\n        fact = _mm256_mullo_epi32(fact, factorial);\n        sum = _mm256_add_epi32(sum, sum_partial);\n    }\n\n    _mm256_storeu_si256((__m256i*)&result[0], _mm256_and_si256(sum, mod));\n    return result;\n}\n```"}
{"task_id": "SimdBench_112_AVX", "completion": "```cpp\nstd::vector<int> func_simd(int n){\n    std::vector<int> result(n);\n    __m256i factorial = _mm256_set1_epi32(1);\n    __m256i sum = _mm256_set1_epi32(0);\n    __m256i mod_val = _mm256_set1_epi32(10000);\n    __m256i one = _mm256_set1_epi32(1);\n\n    for (int i = 1; i <= n; i += 8) {\n        __m256i indices = _mm256_setr_epi32(i, i + 1, i + 2, i + 3, i + 4, i + 5, i + 6, i + 7);\n        __m256i is_even = _mm256_and_si256(_mm256_set1_epi32(1), _mm256_cmpeq_epi32(_mm256_and_si256(indices, _mm256_set1_epi32(1)), _mm256_setzero_si256()));\n\n        __m256i factorial_mask = _mm256_and_si256(is_even, _mm256_set1_epi32(-1));\n        __m256i sum_mask = _mm256_andnot_si256(is_even, _mm256_set1_epi32(-1));\n\n        __m256i factorial_indices = _mm256_sub_epi32(indices, one);\n        __m256i sum_indices = _mm256_add_epi32(indices, _mm256_set1_epi32(1));\n\n        __m256i factorial_product = _mm256_set1_epi32(1);\n        __m256i sum_result = _mm256_set1_epi32(0);\n\n        for (int j = 1; j <= 8; ++j) {\n            factorial_product = _mm256_mullo_epi32(factorial_product, _mm256_and_si256(factorial_indices, factorial_mask));\n            sum_result = _mm256_add_epi32(sum_result, _mm256_and_si256(sum_indices, sum_mask));\n            factorial_indices = _mm256_sub_epi32(factorial_indices, one);\n            sum_indices = _mm256_sub_epi32(sum_indices, one);\n        }\n\n        factorial = _mm256_mullo_epi32(factorial, factorial_product);\n        sum = _mm256_add_epi32(sum, sum_result);\n\n        __m256i result_mask = _mm256_blendv_epi8(sum, factorial, is_even);\n        _mm256_storeu_si256((__m256i*)&result[i - 1], _mm256_and_si256(result_mask, mod_val));\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_112_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nstd::vector<int> func_simd(int n){\n    std::vector<int> result(n);\n    \n    __m256i factorial = _mm256_set1_epi32(1);\n    __m256i sum = _mm256_set1_epi32(0);\n    __m256i one = _mm256_set1_epi32(1);\n    __m256i modulo = _mm256_set1_epi32(10000);\n    \n    for (int i = 1; i <= n; i += 8) {\n        __m256i indices = _mm256_setr_epi32(i, i + 1, i + 2, i + 3, i + 4, i + 5, i + 6, i + 7);\n        \n        __m256i is_even = _mm256_and_si256(_mm256_set1_epi32(1), _mm256_cmpeq_epi32(_mm256_and_si256(indices, one), _mm256_set1_epi32(0)));\n        \n        __m256i factorial_mask = _mm256_and_si256(is_even, _mm256_cmpgt_epi32(indices, _mm256_set1_epi32(1)));\n        __m256i sum_mask = _mm256_andnot_si256(is_even, _mm256_cmpgt_epi32(indices, _mm256_set1_epi32(1)));\n        \n        for (int j = 1; j <= 8; j++) {\n            factorial = _mm256_mullo_epi32(factorial, _mm256_and_si256(factorial_mask, indices));\n            sum = _mm256_add_epi32(sum, _mm256_and_si256(sum_mask, indices));\n        }\n        \n        factorial = _mm256_and_si256(factorial, factorial_mask);\n        sum = _mm256_and_si256(sum, sum_mask);\n        \n        __m256i result_mask = _mm256_or_si256(factorial_mask, sum_mask);\n        __m256i final_result = _mm256_add_epi32(factorial, sum);\n        final_result = _mm256_and_si256(final_result, result_mask);\n        final_result = _mm256_and_si256(final_result, modulo);\n        \n        _mm256_storeu_si256((__m256i*)&result[i - 1], final_result);\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_112_AVX", "completion": "```cpp\nstd::vector<int> func_simd(int n){\n    std::vector<int> result(n);\n    __m256i fact = _mm256_set1_epi32(1);\n    __m256i sum = _mm256_set1_epi32(0);\n    __m256i one = _mm256_set1_epi32(1);\n    __m256i ten_thousand = _mm256_set1_epi32(10000);\n    \n    for (int i = 1; i <= n; i += 8) {\n        __m256i indices = _mm256_setr_epi32(i, i+1, i+2, i+3, i+4, i+5, i+6, i+7);\n        \n        __m256i is_even = _mm256_and_si256(_mm256_set1_epi32(1), _mm256_cmpeq_epi32(_mm256_and_si256(indices, one), _mm256_set1_epi32(0)));\n        \n        __m256i factorial = _mm256_set1_epi32(1);\n        __m256i partial_sum = _mm256_set1_epi32(0);\n        \n        for (int j = 1; j <= 8; j++) {\n            factorial = _mm256_mullo_epi32(factorial, indices);\n            __m256i is_factorial = _mm256_and_si256(is_even, _mm256_cmpeq_epi32(indices, _mm256_set1_epi32(i+j-1)));\n            sum = _mm256_add_epi32(sum, _mm256_and_si256(_mm256_andnot_si256(is_factorial, indices), is_even));\n            partial_sum = _mm256_add_epi32(partial_sum, _mm256_and_si256(_mm256_andnot_si256(is_factorial, indices), _mm256_andnot_si256(is_even, ten_thousand)));\n            indices = _mm256_add_epi32(indices, _mm256_set1_epi32(1));\n        }\n        \n        fact = _mm256_mullo_epi32(fact, factorial);\n        sum = _mm256_add_epi32(sum, partial_sum);\n        \n        _mm256_storeu_si256((__m256i*)&result[i-1], _mm256_blendv_epi8(sum, fact, is_even));\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_113_AVX", "completion": "```cpp\nstd::vector<int> even_odd_palindrome_simd(int n){\n    __m256i even_count = _mm256_setzero_si256();\n    __m256i odd_count = _mm256_setzero_si256();\n\n    for (int i = 1; i <= n; ++i) {\n        int rev = 0, temp = i;\n        while (temp > 0) {\n            rev = rev * 10 + temp % 10;\n            temp /= 10;\n        }\n\n        if (rev == i) {\n            if (i % 2 == 0) {\n                even_count = _mm256_add_epi32(even_count, _mm256_set1_epi32(1));\n            } else {\n                odd_count = _mm256_add_epi32(odd_count, _mm256_set1_epi32(1));\n            }\n        }\n    }\n\n    std::vector<int> result(8);\n    _mm256_storeu_si256((__m256i*)&result[0], even_count);\n    _mm256_storeu_si256((__m256i*)&result[4], odd_count);\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_113_AVX", "completion": "```cpp\nstd::vector<int> even_odd_palindrome_simd(int n){\n    __m256i even_count = _mm256_setzero_si256();\n    __m256i odd_count = _mm256_setzero_si256();\n    \n    for (int i = 1; i <= n; ++i) {\n        int rev = 0, temp = i;\n        while (temp > 0) {\n            rev = rev * 10 + temp % 10;\n            temp /= 10;\n        }\n        if (rev == i) {\n            if (i % 2 == 0) {\n                even_count = _mm256_add_epi32(even_count, _mm256_set1_epi32(1));\n            } else {\n                odd_count = _mm256_add_epi32(odd_count, _mm256_set1_epi32(1));\n            }\n        }\n    }\n    \n    std::vector<int> result(8);\n    _mm256_storeu_si256((__m256i*)&result[0], even_count);\n    _mm256_storeu_si256((__m256i*)&result[4], odd_count);\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_113_AVX", "completion": "```\nstd::vector<int> even_odd_palindrome_simd(int n){\n    __m256i even_count = _mm256_setzero_si256();\n    __m256i odd_count = _mm256_setzero_si256();\n    \n    for (int i = 1; i <= n; ++i) {\n        int rev = 0, temp = i;\n        while (temp > 0) {\n            rev = rev * 10 + temp % 10;\n            temp /= 10;\n        }\n        \n        if (rev == i) {\n            if (i % 2 == 0) {\n                even_count = _mm256_add_epi32(even_count, _mm256_set1_epi32(1));\n            } else {\n                odd_count = _mm256_add_epi32(odd_count, _mm256_set1_epi32(1));\n            }\n        }\n    }\n    \n    std::vector<int> result(8);\n    _mm256_storeu_si256((__m256i*)&result[0], even_count);\n    _mm256_storeu_si256((__m256i*)&result[4], odd_count);\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_113_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> even_odd_palindrome_simd(int n){\n    __m256i even_count = _mm256_setzero_si256();\n    __m256i odd_count = _mm256_setzero_si256();\n\n    for (int i = 1; i <= n; ++i) {\n        int rev = 0, temp = i;\n        while (temp > 0) {\n            rev = rev * 10 + temp % 10;\n            temp /= 10;\n        }\n        if (rev == i) {\n            if (i % 2 == 0) {\n                even_count = _mm256_add_epi32(even_count, _mm256_set1_epi32(1));\n            } else {\n                odd_count = _mm256_add_epi32(odd_count, _mm256_set1_epi32(1));\n            }\n        }\n    }\n\n    alignas(32) int even_result[8];\n    alignas(32) int odd_result[8];\n    _mm256_store_si256((__m256i*)even_result, even_count);\n    _mm256_store_si256((__m256i*)odd_result, odd_count);\n\n    return {even_result[0] + even_result[1] + even_result[2] + even_result[3],\n            odd_result[0] + odd_result[1] + odd_result[2] + odd_result[3]};\n}\n```"}
{"task_id": "SimdBench_113_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nstd::vector<int> even_odd_palindrome_simd(int n){\n    __m256i even_count = _mm256_setzero_si256();\n    __m256i odd_count = _mm256_setzero_si256();\n\n    for (int i = 1; i <= n; ++i) {\n        int rev = 0, temp = i;\n        while (temp > 0) {\n            rev = rev * 10 + temp % 10;\n            temp /= 10;\n        }\n        if (rev == i) {\n            if (i % 2 == 0) {\n                even_count = _mm256_add_epi32(even_count, _mm256_set1_epi32(1));\n            } else {\n                odd_count = _mm256_add_epi32(odd_count, _mm256_set1_epi32(1));\n            }\n        }\n    }\n\n    std::vector<int> result(8);\n    _mm256_storeu_si256((__m256i*)&result[0], even_count);\n    _mm256_storeu_si256((__m256i*)&result[4], odd_count);\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_114_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint count_nums_simd(std::vector<int> n) {\n    int count = 0;\n    __m256i zero = _mm256_setzero_si256();\n    __m256i sum_digits = zero;\n\n    for (size_t i = 0; i < n.size(); i += 8) {\n        __m256i nums = _mm256_loadu_si256((__m256i*)&n[i]);\n\n        __m256i abs_nums = _mm256_abs_epi32(nums);\n\n        __m256i digit_sums = zero;\n        for (int j = 0; j < 8; j++) {\n            __m256i num = _mm256_set1_epi32(n[i + j]);\n            __m256i abs_num = _mm256_abs_epi32(num);\n            __m256i sum = zero;\n\n            while (!_mm256_testz_si256(abs_num, abs_num)) {\n                __m256i digit = _mm256_and_si256(abs_num, _mm256_set1_epi32(0xF));\n                sum = _mm256_add_epi32(sum, digit);\n                abs_num = _mm256_srli_epi32(abs_num, 4);\n            }\n\n            digit_sums = _mm256_add_epi32(digit_sums, sum);\n        }\n\n        __m256i mask = _mm256_cmpgt_epi32(digit_sums, zero);\n        sum_digits = _mm256_add_epi32(sum_digits, mask);\n    }\n\n    alignas(32) int result[8];\n    _mm256_store_si256((__m256i*)result, sum_digits);\n\n    for (int i = 0; i < 8; i++) {\n        count += result[i];\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_114_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint count_nums_simd(std::vector<int> n) {\n    int count = 0;\n    __m256i zero = _mm256_setzero_si256();\n    __m256i sum_digits = zero;\n\n    for (size_t i = 0; i < n.size(); i += 8) {\n        __m256i nums = _mm256_loadu_si256((__m256i*)&n[i]);\n\n        __m256i abs_nums = _mm256_abs_epi32(nums);\n\n        __m256i digit_sums = zero;\n        for (int j = 0; j < 8; ++j) {\n            __m256i num = _mm256_permutevar8x32_epi32(abs_nums, _mm256_set1_epi32(j));\n            __m256i digits = _mm256_abs_epi32(_mm256_setr_epi32(_mm256_extract_epi32(num, 0), _mm256_extract_epi32(num, 1), _mm256_extract_epi32(num, 2), _mm256_extract_epi32(num, 3), _mm256_extract_epi32(num, 4), _mm256_extract_epi32(num, 5), _mm256_extract_epi32(num, 6), _mm256_extract_epi32(num, 7)));\n            digit_sums = _mm256_add_epi32(digit_sums, digits);\n        }\n\n        sum_digits = _mm256_add_epi32(sum_digits, digit_sums);\n    }\n\n    alignas(32) int result[8];\n    _mm256_store_si256((__m256i*)result, sum_digits);\n\n    for (int i = 0; i < 8; ++i) {\n        count += (result[i] > 0);\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_114_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint count_nums_simd(std::vector<int> n){\n    int count = 0;\n    __m256i zero = _mm256_setzero_si256();\n    __m256i sum_digits = zero;\n\n    for (size_t i = 0; i < n.size(); i += 8) {\n        __m256i nums = _mm256_loadu_si256((__m256i*)&n[i]);\n\n        // Calculate the sum of digits for each number\n        __m256i abs_nums = _mm256_abs_epi32(nums);\n        __m256i sum_digits_mask = _mm256_cmpgt_epi32(abs_nums, zero);\n        sum_digits = _mm256_add_epi32(sum_digits, sum_digits_mask);\n    }\n\n    alignas(32) int result[8];\n    _mm256_store_si256((__m256i*)result, sum_digits);\n\n    for (int i = 0; i < 8; ++i) {\n        count += result[i];\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_114_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nint count_nums_simd(std::vector<int> n){\n    int count = 0;\n    __m256i zero = _mm256_setzero_si256();\n    __m256i sum_digits = zero;\n    \n    for (size_t i = 0; i < n.size(); i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&n[i]);\n        \n        __m256i abs_vec = _mm256_abs_epi32(vec);\n        \n        __m256i digit_mask = _mm256_cmpgt_epi32(abs_vec, zero);\n        \n        __m256i sum_mask = _mm256_setzero_si256();\n        for (int j = 0; j < 8; j++) {\n            __m256i digit = _mm256_and_si256(abs_vec, _mm256_set1_epi32(9));\n            sum_mask = _mm256_add_epi32(sum_mask, digit);\n            abs_vec = _mm256_div_epi32(abs_vec, _mm256_set1_epi32(10));\n        }\n        \n        sum_mask = _mm256_cmpgt_epi32(sum_mask, zero);\n        \n        __m256i final_mask = _mm256_and_si256(digit_mask, sum_mask);\n        \n        count += _mm_popcnt_u32(_mm256_movemask_ps(_mm256_castsi256_ps(final_mask)));\n    }\n    \n    return count;\n}\n```"}
{"task_id": "SimdBench_114_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint count_nums_simd(std::vector<int> n){\n    int count = 0;\n    __m256i zero = _mm256_setzero_si256();\n    __m256i sum_digits = zero;\n    \n    for (size_t i = 0; i < n.size(); i += 8) {\n        __m256i nums = _mm256_loadu_si256((__m256i*)&n[i]);\n        \n        __m256i abs_nums = _mm256_abs_epi32(nums);\n        __m256i digit_sums = zero;\n        \n        for (int j = 0; j < 8; j++) {\n            __m256i digit_mask = _mm256_set1_epi32(1);\n            __m256i temp = abs_nums;\n            \n            for (int k = 0; k < 10; k++) {\n                __m256i digit = _mm256_set1_epi32(k);\n                __m256i cmp = _mm256_cmpeq_epi32(temp, digit);\n                digit_mask = _mm256_or_si256(digit_mask, cmp);\n                temp = _mm256_srai_epi32(temp, 1);\n            }\n            \n            digit_sums = _mm256_add_epi32(digit_sums, digit_mask);\n        }\n        \n        sum_digits = _mm256_add_epi32(sum_digits, digit_sums);\n    }\n    \n    alignas(32) int result[8];\n    _mm256_store_si256((__m256i*)result, sum_digits);\n    \n    for (int i = 0; i < 8; i++) {\n        count += (result[i] > 0);\n    }\n    \n    return count;\n}\n```"}
{"task_id": "SimdBench_115_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nbool move_one_ball_simd(std::vector<int> arr){\n    if(arr.empty()){\n        return true;\n    }\n    \n    int N = arr.size();\n    __m256i vec = _mm256_loadu_si256((__m256i*)&arr[0]);\n    \n    for(int i = 0; i < N; ++i){\n        __m256i shifted_vec = _mm256_alignr_epi8(vec, vec, i);\n        __m256i cmp_result = _mm256_cmpgt_epi32(vec, shifted_vec);\n        if(_mm256_testz_si256(cmp_result, cmp_result)){\n            return true;\n        }\n    }\n    \n    return false;\n}\n```"}
{"task_id": "SimdBench_115_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nbool move_one_ball_simd(std::vector<int> arr){\n    if(arr.empty()) {\n        return true;\n    }\n    \n    int N = arr.size();\n    __m256i vec = _mm256_loadu_si256((__m256i*)arr.data());\n    \n    for(int i = 0; i < N; i++) {\n        __m256i shifted_vec = _mm256_alignr_epi8(vec, vec, i);\n        __m256i cmp_result = _mm256_cmpgt_epi32(vec, shifted_vec);\n        int mask = _mm256_movemask_ps(_mm256_castsi256_ps(cmp_result));\n        if(mask != 0) {\n            return false;\n        }\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_115_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nbool move_one_ball_simd(std::vector<int> arr){\n    if(arr.empty()){\n        return true;\n    }\n    \n    const int N = arr.size();\n    __m256i vec = _mm256_loadu_si256((__m256i*)&arr[0]);\n    \n    for(int i = 0; i < N; ++i){\n        __m256i shifted_vec = _mm256_alignr_epi8(vec, vec, i);\n        __m256i cmp_result = _mm256_cmpgt_epi32(vec, shifted_vec);\n        if(_mm256_movemask_ps(_mm256_castsi256_ps(cmp_result)) != 0){\n            return false;\n        }\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_115_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nbool move_one_ball_simd(std::vector<int> arr){\n    if(arr.empty()) {\n        return true;\n    }\n    \n    int N = arr.size();\n    __m256i vec = _mm256_loadu_si256((__m256i*)&arr[0]);\n    \n    for(int i = 0; i < N; i++) {\n        __m256i shifted_vec = _mm256_alignr_epi8(vec, vec, i);\n        __m256i cmp_result = _mm256_cmpgt_epi32(vec, shifted_vec);\n        int mask = _mm256_movemask_ps(_mm256_castsi256_ps(cmp_result));\n        if(mask != 0) {\n            return false;\n        }\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_115_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nbool move_one_ball_simd(std::vector<int> arr){\n    if(arr.empty()) {\n        return true;\n    }\n    \n    int N = arr.size();\n    __m256i vec = _mm256_loadu_si256((__m256i*)&arr[0]);\n    \n    for(int i = 0; i < N; i++) {\n        __m256i shifted = _mm256_alignr_epi8(vec, vec, 4);\n        __m256i cmp = _mm256_cmpgt_epi32(vec, shifted);\n        if(_mm256_movemask_ps(_mm256_castsi256_ps(cmp)) != 0) {\n            return false;\n        }\n        vec = shifted;\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_116_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nstd::string myexchange_simd(const std::vector<int>& lst1, const std::vector<int>& lst2) {\n    int size = lst1.size();\n    __m256i mask = _mm256_set1_epi32(1); // Mask for checking odd numbers\n    __m256i all_ones = _mm256_set1_epi32(-1); // Mask of all ones\n\n    for (int i = 0; i < size; i += 8) {\n        __m256i vec1 = _mm256_loadu_si256((__m256i*)&lst1[i]);\n        __m256i vec2 = _mm256_loadu_si256((__m256i*)&lst2[i]);\n\n        // Check if any element in vec1 is odd\n        __m256i odd_mask = _mm256_and_si256(_mm256_and_si256(vec1, mask), all_ones);\n\n        // Check if any element in vec2 is even\n        __m256i even_mask = _mm256_andnot_si256(_mm256_and_si256(vec2, mask), all_ones);\n\n        // Check if there is any overlap between odd elements in vec1 and even elements in vec2\n        __m256i overlap = _mm256_and_si256(odd_mask, even_mask);\n\n        // If there is overlap, return \"NO\"\n        if (!_mm256_testz_si256(overlap, overlap)) {\n            return \"NO\";\n        }\n    }\n\n    return \"YES\";\n}\n```"}
{"task_id": "SimdBench_116_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nstd::string myexchange_simd(const std::vector<int>& lst1, const std::vector<int>& lst2) {\n    int size = lst1.size();\n    __m256i mask = _mm256_set1_epi32(1); // Mask for checking odd numbers\n\n    for (int i = 0; i < size; i += 8) {\n        __m256i vec1 = _mm256_loadu_si256((__m256i*)&lst1[i]);\n        __m256i vec2 = _mm256_loadu_si256((__m256i*)&lst2[i]);\n\n        __m256i odd1 = _mm256_and_si256(vec1, mask);\n        __m256i odd2 = _mm256_and_si256(vec2, mask);\n\n        __m256i odd_mask = _mm256_or_si256(odd1, odd2);\n\n        if (!_mm256_testz_si256(odd_mask, odd_mask)) {\n            return \"NO\";\n        }\n    }\n\n    return \"YES\";\n}\n```"}
{"task_id": "SimdBench_116_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n\nstd::string myexchange_simd(const std::vector<int>& lst1, const std::vector<int>& lst2) {\n    __m256i mask = _mm256_set1_epi32(1); // Mask for checking odd numbers\n    __m256i all_ones = _mm256_set1_epi32(-1); // Mask of all ones\n\n    int size = lst1.size();\n    int i = 0;\n\n    for (; i + 8 <= size; i += 8) {\n        __m256i vec1 = _mm256_loadu_si256((__m256i*)&lst1[i]);\n        __m256i vec2 = _mm256_loadu_si256((__m256i*)&lst2[i]);\n\n        // Check if any element in vec1 is odd\n        __m256i odd_mask = _mm256_and_si256(_mm256_and_si256(vec1, mask), all_ones);\n\n        // Check if any element in vec2 is odd\n        __m256i odd_mask2 = _mm256_and_si256(_mm256_and_si256(vec2, mask), all_ones);\n\n        // Check if there is any odd number in vec1 that cannot be replaced by an even number in vec2\n        __m256i cannot_replace_mask = _mm256_andnot_si256(odd_mask2, odd_mask);\n\n        // If there is any such number, return \"NO\"\n        if (!_mm256_testz_si256(cannot_replace_mask, all_ones)) {\n            return \"NO\";\n        }\n    }\n\n    // Process the remaining elements\n    for (; i < size; ++i) {\n        if (lst1[i] % 2 != 0) {\n            bool replaced = false;\n            for (int j = i; j < size; ++j) {\n                if (lst2[j] % 2 == 0) {\n                    std::swap(lst1[i], lst2[j]);\n                    replaced = true;\n                    break;\n                }\n            }\n            if (!replaced) {\n                return \"NO\";\n            }\n        }\n    }\n\n    return \"YES\";\n}\n```"}
{"task_id": "SimdBench_116_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nstd::string myexchange_simd(const std::vector<int>& lst1, const std::vector<int>& lst2) {\n    int size = lst1.size();\n    __m256i mask = _mm256_set1_epi32(1); // Mask for checking odd numbers\n\n    for (int i = 0; i < size; i += 8) {\n        __m256i vec1 = _mm256_loadu_si256((__m256i*)&lst1[i]);\n        __m256i vec2 = _mm256_loadu_si256((__m256i*)&lst2[i]);\n\n        __m256i odd1 = _mm256_and_si256(vec1, mask);\n        __m256i odd2 = _mm256_and_si256(vec2, mask);\n\n        __m256i odd_mask = _mm256_or_si256(odd1, odd2);\n\n        if (!_mm256_testz_si256(odd_mask, odd_mask)) {\n            return \"NO\";\n        }\n    }\n\n    return \"YES\";\n}\n```"}
{"task_id": "SimdBench_116_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nstd::string myexchange_simd(const std::vector<int>& lst1, const std::vector<int>& lst2) {\n    int size = lst1.size();\n    int remainder = size % 8;\n    \n    __m256i mask = _mm256_set1_epi32(1);\n    __m256i even_mask = _mm256_set1_epi32(0);\n    \n    for (int i = 0; i < size - remainder; i += 8) {\n        __m256i vec1 = _mm256_loadu_si256((__m256i*)&lst1[i]);\n        __m256i vec2 = _mm256_loadu_si256((__m256i*)&lst2[i]);\n        \n        __m256i result = _mm256_and_si256(vec1, mask);\n        __m256i result2 = _mm256_and_si256(vec2, mask);\n        \n        __m256i cmp = _mm256_cmpeq_epi32(result, even_mask);\n        __m256i cmp2 = _mm256_cmpeq_epi32(result2, even_mask);\n        \n        __m256i cmp_result = _mm256_and_si256(cmp, cmp2);\n        \n        int mask_result = _mm256_movemask_ps((__m256)cmp_result);\n        \n        if (mask_result != 255) {\n            return \"NO\";\n        }\n    }\n    \n    for (int i = size - remainder; i < size; ++i) {\n        if (lst1[i] % 2 != 0) {\n            return \"NO\";\n        }\n    }\n    \n    return \"YES\";\n}\n```"}
{"task_id": "SimdBench_117_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nstd::vector<std::string> odd_count_simd(const std::vector<std::string> & lst) {\n    std::vector<std::string> result(lst.size());\n    for (size_t i = 0; i < lst.size(); ++i) {\n        const char* str = lst[i].c_str();\n        size_t len = lst[i].size();\n        __m256i odd_count = _mm256_setzero_si256();\n        for (size_t j = 0; j < len; j += 32) {\n            __m256i digits = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(str + j));\n            __m256i odd_mask = _mm256_set1_epi8(0x55); // Mask for odd digits (1, 3, 5, 7, 9)\n            __m256i odd_digits = _mm256_and_si256(digits, odd_mask);\n            __m256i odd_count_increment = _mm256_sad_epu8(odd_digits, _mm256_setzero_si256());\n            odd_count = _mm256_add_epi64(odd_count, odd_count_increment);\n        }\n        alignas(32) uint64_t count[4];\n        _mm256_store_si256((__m256i*)count, odd_count);\n        result[i] = \"the number of odd elements \" + std::to_string(count[0] + count[1] + count[2] + count[3]) + \"n the str\" + std::to_string(i + 1) + \"ng \" + std::to_string(i + 1) + \" of the \" + std::to_string(i + 1) + \"nput.\";\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_117_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nstd::vector<std::string> odd_count_simd(const std::vector<std::string> & lst){\n    std::vector<std::string> result;\n    for (const std::string& str : lst) {\n        int odd_count = 0;\n        for (size_t i = 0; i < str.size(); ++i) {\n            if ((str[i] - '0') % 2 != 0) {\n                odd_count++;\n            }\n        }\n        result.push_back(\"the number of odd elements \" + std::to_string(odd_count) + \"n the str\" + std::to_string(odd_count) + \"ng \" + str + \" of the \" + std::to_string(odd_count) + \"nput.\");\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_117_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nstd::vector<std::string> odd_count_simd(const std::vector<std::string> & lst) {\n    std::vector<std::string> result(lst.size());\n    for (size_t i = 0; i < lst.size(); ++i) {\n        const char* str = lst[i].c_str();\n        size_t len = lst[i].size();\n        __m256i odd_mask = _mm256_setr_epi8(1, 3, 5, 7, 9, 1, 3, 5, 7, 9, 1, 3, 5, 7, 9, 1, 3, 5, 7, 9, 1, 3, 5, 7, 9, 1, 3, 5, 7, 9, 1, 3, 5);\n        __m256i count = _mm256_setzero_si256();\n        for (size_t j = 0; j < len; j += 32) {\n            __m256i digits = _mm256_cvtepu8_epi32(_mm256_loadu_si256(reinterpret_cast<const __m256i*>(str + j)));\n            __m256i odd_digits = _mm256_and_si256(digits, odd_mask);\n            __m256i odd_count = _mm256_sad_epu8(odd_digits, _mm256_setzero_si256());\n            count = _mm256_add_epi32(count, odd_count);\n        }\n        alignas(32) int result_count[8];\n        _mm256_store_si256(reinterpret_cast<__m256i*>(result_count), count);\n        for (int k = 0; k < 8; ++k) {\n            result[i] += \"the number of odd elements \" + std::to_string(result_count[k]) + \"n the str\" + std::to_string(k) + \"ng \" + std::to_string(k + 1) + \" of the \" + std::to_string(k) + \"nput.\";\n        }\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_117_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nstd::vector<std::string> odd_count_simd(const std::vector<std::string> & lst){\n    std::vector<std::string> result;\n    for (const std::string& str : lst) {\n        int odd_count = 0;\n        __m256i odd_mask = _mm256_setr_epi8(1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0);\n        for (size_t i = 0; i < str.size(); i += 32) {\n            __m256i str_chunk = _mm256_loadu_si256((__m256i*)(str.data() + i));\n            __m256i odd_digits = _mm256_and_si256(str_chunk, odd_mask);\n            odd_count += _mm_popcnt_u32(_mm256_movemask_epi8(odd_digits));\n        }\n        result.push_back(\"the number of odd elements \" + std::to_string(odd_count) + \"n the str\" + std::to_string(result.size() + 1) + \"ng \" + str + \" of the \" + std::to_string(result.size() + 1) + \"nput.\");\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_117_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nstd::vector<std::string> odd_count_simd(const std::vector<std::string> & lst){\n    std::vector<std::string> result;\n    for (const std::string& str : lst) {\n        int odd_count = 0;\n        for (size_t i = 0; i < str.size(); ++i) {\n            if ((str[i] - '0') % 2 != 0) {\n                odd_count++;\n            }\n        }\n        result.push_back(\"the number of odd elements \" + std::to_string(odd_count) + \"n the str\" + std::to_string(odd_count) + \"ng \" + str + \" of the \" + std::to_string(odd_count) + \"nput.\");\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_118_AVX", "completion": "```cpp\nint64_t minSubArraySum_simd(const std::vector<int64_t>& nums){\n    int64_t min_sum = INT64_MAX;\n    int64_t sum = 0;\n    __m256i min_sum_v = _mm256_set1_epi64x(INT64_MAX);\n    __m256i sum_v = _mm256_setzero_si256();\n    \n    for (size_t i = 0; i < nums.size(); i += 4) {\n        __m256i nums_v = _mm256_loadu_si256((__m256i*)&nums[i]);\n        sum_v = _mm256_add_epi64(sum_v, nums_v);\n        min_sum_v = _mm256_min_epi64(min_sum_v, sum_v);\n        sum_v = _mm256_max_epi64(sum_v, _mm256_setzero_si256());\n    }\n    \n    alignas(32) int64_t min_sum_arr[4];\n    _mm256_store_si256((__m256i*)min_sum_arr, min_sum_v);\n    \n    for (int i = 0; i < 4; ++i) {\n        min_sum = std::min(min_sum, min_sum_arr[i]);\n    }\n    \n    return min_sum;\n}\n```"}
{"task_id": "SimdBench_118_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nint64_t minSubArraySum_simd(const std::vector<int64_t>& nums){\n    int64_t min_sum = nums[0];\n    int64_t curr_sum = 0;\n    \n    __m256i min_sum_v = _mm256_set1_epi64x(min_sum);\n    __m256i curr_sum_v = _mm256_setzero_si256();\n    \n    for (size_t i = 0; i < nums.size(); i += 4) {\n        __m256i nums_v = _mm256_loadu_si256((__m256i*)&nums[i]);\n        curr_sum_v = _mm256_add_epi64(curr_sum_v, nums_v);\n        min_sum_v = _mm256_min_epi64(min_sum_v, curr_sum_v);\n        curr_sum_v = _mm256_max_epi64(curr_sum_v, _mm256_setzero_si256());\n    }\n    \n    int64_t min_sum_arr[4];\n    _mm256_storeu_si256((__m256i*)min_sum_arr, min_sum_v);\n    \n    for (int i = 0; i < 4; i++) {\n        min_sum = std::min(min_sum, min_sum_arr[i]);\n    }\n    \n    return min_sum;\n}\n```"}
{"task_id": "SimdBench_118_AVX", "completion": "```cpp\nint64_t minSubArraySum_simd(const std::vector<int64_t>& nums){\n    int64_t min_sum = INT64_MAX;\n    int64_t sum = 0;\n    \n    __m256i min_sum_v = _mm256_set1_epi64x(INT64_MAX);\n    __m256i sum_v = _mm256_setzero_si256();\n    \n    for (size_t i = 0; i < nums.size(); i += 4) {\n        __m256i nums_v = _mm256_loadu_si256((__m256i*)&nums[i]);\n        sum_v = _mm256_add_epi64(sum_v, nums_v);\n        min_sum_v = _mm256_min_epi64(min_sum_v, sum_v);\n        min_sum = std::min(min_sum, _mm256_reduce_min_epi64(min_sum_v));\n        sum = _mm256_reduce_add_epi64(sum_v);\n    }\n    \n    return min_sum;\n}\n```  "}
{"task_id": "SimdBench_118_AVX", "completion": "```cpp\nint64_t minSubArraySum_simd(const std::vector<int64_t>& nums){\n    int64_t min_sum = INT64_MAX;\n    int64_t sum = 0;\n    \n    __m256i min_sum_v = _mm256_set1_epi64x(INT64_MAX);\n    __m256i sum_v = _mm256_setzero_si256();\n    \n    for (size_t i = 0; i < nums.size(); i += 4) {\n        __m256i nums_v = _mm256_loadu_si256((__m256i*)&nums[i]);\n        sum_v = _mm256_add_epi64(sum_v, nums_v);\n        min_sum_v = _mm256_min_epi64(min_sum_v, sum_v);\n        sum_v = _mm256_max_epi64(sum_v, _mm256_setzero_si256());\n    }\n    \n    alignas(32) int64_t min_sum_arr[4];\n    _mm256_store_si256((__m256i*)min_sum_arr, min_sum_v);\n    \n    for (int i = 0; i < 4; ++i) {\n        min_sum = std::min(min_sum, min_sum_arr[i]);\n    }\n    \n    return min_sum;\n}\n```"}
{"task_id": "SimdBench_118_AVX", "completion": "```cpp\nint64_t minSubArraySum_simd(const std::vector<int64_t>& nums){\n    int64_t min_sum = INT64_MAX;\n    int64_t sum = 0;\n    \n    __m256i min_sum_v = _mm256_set1_epi64x(INT64_MAX);\n    __m256i sum_v = _mm256_setzero_si256();\n    \n    for (size_t i = 0; i < nums.size(); i += 4) {\n        __m256i nums_v = _mm256_loadu_si256((__m256i*)&nums[i]);\n        sum_v = _mm256_add_epi64(sum_v, nums_v);\n        min_sum_v = _mm256_min_epi64(min_sum_v, sum_v);\n        sum_v = _mm256_max_epi64(sum_v, _mm256_setzero_si256());\n    }\n    \n    alignas(32) int64_t min_sum_arr[4];\n    _mm256_store_si256((__m256i*)min_sum_arr, min_sum_v);\n    \n    for (int i = 0; i < 4; ++i) {\n        min_sum = std::min(min_sum, min_sum_arr[i]);\n    }\n    \n    return min_sum;\n}\n```"}
{"task_id": "SimdBench_119_AVX", "completion": "```\nint max_fill_simd(const std::vector<std::vector<int> > & grid, int capacity) {\n    int num_rows = grid.size();\n    int num_cols = grid[0].size();\n    int buckets = 0;\n    \n    __m256i capacity_v = _mm256_set1_epi32(capacity);\n    __m256i buckets_v = _mm256_setzero_si256();\n    \n    for (int i = 0; i < num_rows; ++i) {\n        __m256i row_v = _mm256_loadu_si256((__m256i*)&grid[i][0]);\n        __m256i filled_v = _mm256_cmpgt_epi32(row_v, _mm256_setzero_si256());\n        __m256i remaining_v = _mm256_sub_epi32(capacity_v, buckets_v);\n        __m256i extracted_v = _mm256_min_epi32(remaining_v, filled_v);\n        buckets_v = _mm256_add_epi32(buckets_v, extracted_v);\n    }\n    \n    int buckets_arr[8];\n    _mm256_storeu_si256((__m256i*)buckets_arr, buckets_v);\n    \n    for (int i = 0; i < 8; ++i) {\n        buckets += buckets_arr[i];\n    }\n    \n    return buckets;\n}\n```"}
{"task_id": "SimdBench_119_AVX", "completion": "```\nint max_fill_simd(const std::vector<std::vector<int> > & grid, int capacity) {\n    int rows = grid.size();\n    int cols = grid[0].size();\n    int buckets = 0;\n    \n    __m256i capacity_v = _mm256_set1_epi32(capacity);\n    __m256i buckets_v = _mm256_setzero_si256();\n    \n    for (int i = 0; i < rows; ++i) {\n        __m256i row_v = _mm256_loadu_si256((__m256i*)&grid[i][0]);\n        __m256i filled_v = _mm256_cmpgt_epi32(row_v, _mm256_setzero_si256());\n        __m256i remaining_v = _mm256_sub_epi32(capacity_v, buckets_v);\n        __m256i to_fill_v = _mm256_min_epi32(remaining_v, filled_v);\n        buckets_v = _mm256_add_epi32(buckets_v, to_fill_v);\n    }\n    \n    buckets += _mm256_extract_epi32(buckets_v, 0);\n    buckets += _mm256_extract_epi32(buckets_v, 1);\n    buckets += _mm256_extract_epi32(buckets_v, 2);\n    buckets += _mm256_extract_epi32(buckets_v, 3);\n    \n    return buckets;\n}\n```"}
{"task_id": "SimdBench_119_AVX", "completion": "```\nint max_fill_simd(const std::vector<std::vector<int> > & grid, int capacity) {\n    int num_rows = grid.size();\n    int num_cols = grid[0].size();\n    int buckets = 0;\n    \n    __m256i capacity_v = _mm256_set1_epi32(capacity);\n    __m256i buckets_v = _mm256_setzero_si256();\n    \n    for (int i = 0; i < num_rows; ++i) {\n        __m256i row_v = _mm256_loadu_si256((__m256i*)&grid[i][0]);\n        buckets_v = _mm256_add_epi32(buckets_v, row_v);\n        \n        __m256i excess_v = _mm256_sub_epi32(buckets_v, capacity_v);\n        __m256i mask_v = _mm256_cmpgt_epi32(buckets_v, capacity_v);\n        \n        int excess[8];\n        _mm256_storeu_si256((__m256i*)excess, excess_v);\n        \n        for (int j = 0; j < 8; ++j) {\n            if (excess[j] > 0) {\n                buckets += excess[j];\n                buckets_v = _mm256_and_si256(excess_v, mask_v);\n            }\n        }\n    }\n    \n    return buckets;\n}\n```"}
{"task_id": "SimdBench_119_AVX", "completion": "```\nint max_fill_simd(const std::vector<std::vector<int> > & grid, int capacity) {\n    int total = 0;\n    int rows = grid.size();\n    int cols = grid[0].size();\n    \n    __m256i capacity_v = _mm256_set1_epi32(capacity);\n    __m256i total_v = _mm256_setzero_si256();\n    \n    for (int i = 0; i < rows; ++i) {\n        __m256i row_sum_v = _mm256_setzero_si256();\n        for (int j = 0; j < cols; j += 8) {\n            __m256i grid_v = _mm256_loadu_si256((__m256i*)&grid[i][j]);\n            row_sum_v = _mm256_add_epi32(row_sum_v, grid_v);\n        }\n        \n        __m256i buckets_needed_v = _mm256_sub_epi32(row_sum_v, capacity_v);\n        buckets_needed_v = _mm256_max_epi32(buckets_needed_v, _mm256_setzero_si256());\n        total_v = _mm256_add_epi32(total_v, buckets_needed_v);\n    }\n    \n    alignas(32) int total_arr[8];\n    _mm256_store_si256((__m256i*)total_arr, total_v);\n    \n    total = total_arr[0] + total_arr[1] + total_arr[2] + total_arr[3] + total_arr[4] + total_arr[5] + total_arr[6] + total_arr[7];\n    \n    return total;\n}\n```"}
{"task_id": "SimdBench_119_AVX", "completion": "```cpp\nint max_fill_simd(const std::vector<std::vector<int>>& grid, int capacity) {\n    int num_rows = grid.size();\n    int num_cols = grid[0].size();\n    int buckets = 0;\n    \n    __m256i capacity_v = _mm256_set1_epi32(capacity);\n    __m256i buckets_v = _mm256_setzero_si256();\n    \n    for (int i = 0; i < num_rows; ++i) {\n        __m256i row_v = _mm256_loadu_si256((__m256i*)&grid[i][0]);\n        __m256i filled_v = _mm256_cmpgt_epi32(row_v, _mm256_setzero_si256());\n        \n        __m256i to_fill_v = _mm256_sub_epi32(filled_v, buckets_v);\n        __m256i to_fill_positive_v = _mm256_max_epi32(to_fill_v, _mm256_setzero_si256());\n        \n        __m256i buckets_needed_v = _mm256_div_epi32(to_fill_positive_v, capacity_v);\n        buckets += _mm256_hadd_epi32(buckets_needed_v)[0] + _mm256_hadd_epi32(buckets_needed_v)[4];\n        \n        buckets_v = _mm256_add_epi32(buckets_v, _mm256_mullo_epi32(buckets_needed_v, capacity_v));\n    }\n    \n    return buckets;\n}\n```"}
{"task_id": "SimdBench_120_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nint64_t solution_simd(const std::vector<int16_t>& lst){\n    __m256i odd_mask = _mm256_set1_epi16(0x5555); // Mask to extract odd elements\n    __m256i sum = _mm256_setzero_si256(); // Initialize sum to zero\n    int64_t total_sum = 0;\n\n    for (size_t i = 0; i < lst.size(); i += 16) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&lst[i]); // Load 16 elements from the vector\n        __m256i even_pos = _mm256_and_si256(vec, odd_mask); // Extract odd elements in even positions\n        sum = _mm256_add_epi16(sum, even_pos); // Add the extracted odd elements to the sum\n    }\n\n    alignas(32) int16_t result[16];\n    _mm256_store_si256((__m256i*)result, sum);\n\n    for (int i = 0; i < 16; i++) {\n        total_sum += result[i];\n    }\n\n    return total_sum;\n}\n```"}
{"task_id": "SimdBench_120_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nint64_t solution_simd(const std::vector<int16_t>& lst){\n    __m256i odd_mask = _mm256_set1_epi16(0x5555); // Mask to extract odd elements\n    __m256i sum = _mm256_setzero_si256(); // Initialize sum to zero\n    int64_t total_sum = 0;\n\n    for (size_t i = 0; i < lst.size(); i += 16) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&lst[i]); // Load 16 elements into AVX register\n        __m256i even_pos = _mm256_and_si256(vec, odd_mask); // Extract odd elements in even positions\n        sum = _mm256_add_epi16(sum, even_pos); // Add to the running sum\n    }\n\n    alignas(32) int16_t result[16];\n    _mm256_store_si256((__m256i*)result, sum);\n\n    for (int i = 0; i < 16; ++i) {\n        total_sum += result[i];\n    }\n\n    return total_sum;\n}\n```"}
{"task_id": "SimdBench_120_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nint64_t solution_simd(const std::vector<int16_t>& lst){\n    int64_t result = 0;\n    __m256i odd_mask = _mm256_set1_epi16(0x5555); // Mask to extract odd elements\n    __m256i sum = _mm256_setzero_si256(); // Initialize sum to zero\n\n    for (size_t i = 0; i < lst.size(); i += 16) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&lst[i]); // Load 16 elements from the vector\n        __m256i even_pos = _mm256_and_si256(vec, odd_mask); // Extract odd elements in even positions\n        sum = _mm256_add_epi16(sum, even_pos); // Add the extracted elements to the sum\n    }\n\n    alignas(32) int16_t sum_arr[16];\n    _mm256_store_si256((__m256i*)sum_arr, sum);\n\n    for (int i = 0; i < 16; ++i) {\n        result += sum_arr[i];\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_120_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nint64_t solution_simd(const std::vector<int16_t>& lst){\n    const int size = lst.size();\n    const int16_t* data = lst.data();\n    \n    __m256i odd_mask = _mm256_set1_epi16(0x5555); // Mask to extract odd elements\n    __m256i sum = _mm256_setzero_si256(); // Initialize sum to zero\n    \n    for (int i = 0; i < size; i += 16) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)(data + i)); // Load 16 elements\n        __m256i even_pos = _mm256_and_si256(vec, odd_mask); // Extract odd elements in even positions\n        sum = _mm256_add_epi16(sum, even_pos); // Accumulate the sum\n    }\n    \n    alignas(32) int16_t result[16];\n    _mm256_store_si256((__m256i*)result, sum);\n    \n    int64_t final_sum = 0;\n    for (int i = 0; i < 16; ++i) {\n        final_sum += result[i];\n    }\n    \n    return final_sum;\n}\n```"}
{"task_id": "SimdBench_120_AVX", "completion": "```cpp\nint64_t solution_simd(const std::vector<int16_t>& lst){\n    __m256i odd_mask = _mm256_set1_epi16(0x5555); // Mask to extract odd elements\n    __m256i sum = _mm256_setzero_si256(); // Initialize sum to zero\n    for (size_t i = 0; i < lst.size(); i += 16) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&lst[i]); // Load 16 elements into AVX register\n        __m256i even_positions = _mm256_and_si256(_mm256_set1_epi16(0xaaaa), _mm256_setr_epi16(vec)); // Mask to extract elements at even positions\n        __m256i odd_elements = _mm256_and_si256(odd_mask, even_positions); // Extract odd elements at even positions\n        sum = _mm256_add_epi16(sum, odd_elements); // Add odd elements to sum\n    }\n    alignas(32) int16_t result[16];\n    _mm256_store_si256((__m256i*)result, sum); // Store the final sum\n    int64_t final_sum = 0;\n    for (int i = 0; i < 16; ++i) {\n        final_sum += result[i];\n    }\n    return final_sum;\n}\n```"}
{"task_id": "SimdBench_121_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nint add_elements_simd(std::vector<int> arr, int k){\n    __m256i sum = _mm256_setzero_si256();\n    for (int i = 0; i < k; i += 8) {\n        __m256i values = _mm256_loadu_si256((__m256i*)&arr[i]);\n        __m256i mask = _mm256_cmpgt_epi32(values, _mm256_set1_epi32(9));\n        mask = _mm256_or_si256(mask, _mm256_cmplt_epi32(values, _mm256_set1_epi32(100)));\n        __m256i filtered_values = _mm256_and_si256(values, mask);\n        sum = _mm256_add_epi32(sum, filtered_values);\n    }\n    int result[8];\n    _mm256_storeu_si256((__m256i*)result, sum);\n    return result[0] + result[1] + result[2] + result[3];\n}\n```"}
{"task_id": "SimdBench_121_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nint add_elements_simd(std::vector<int> arr, int k) {\n    __m256i sum = _mm256_setzero_si256();\n    int total_sum = 0;\n    \n    for (int i = 0; i < k; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&arr[i]);\n        __m256i mask = _mm256_cmpgt_epi32(vec, _mm256_set1_epi32(9));\n        mask = _mm256_or_si256(mask, _mm256_cmplt_epi32(vec, _mm256_set1_epi32(100)));\n        __m256i filtered_vec = _mm256_and_si256(vec, mask);\n        sum = _mm256_add_epi32(sum, filtered_vec);\n    }\n    \n    alignas(32) int result[8];\n    _mm256_store_si256((__m256i*)result, sum);\n    \n    for (int i = 0; i < 8; i++) {\n        total_sum += result[i];\n    }\n    \n    return total_sum;\n}\n```"}
{"task_id": "SimdBench_121_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nint add_elements_simd(std::vector<int> arr, int k){\n    __m256i sum = _mm256_setzero_si256();\n    int i = 0;\n    for (; i + 8 <= k; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&arr[i]);\n        __m256i mask = _mm256_cmpgt_epi32(vec, _mm256_set1_epi32(9));\n        mask = _mm256_or_si256(mask, _mm256_cmplt_epi32(vec, _mm256_set1_epi32(100)));\n        __m256i filtered = _mm256_and_si256(vec, mask);\n        sum = _mm256_add_epi32(sum, filtered);\n    }\n    int result[8];\n    _mm256_storeu_si256((__m256i*)result, sum);\n    int final_sum = 0;\n    for (int j = 0; j < 8; j++) {\n        final_sum += result[j];\n    }\n    for (; i < k; i++) {\n        if (arr[i] >= 10 && arr[i] < 100) {\n            final_sum += arr[i];\n        }\n    }\n    return final_sum;\n}\n```"}
{"task_id": "SimdBench_121_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nint add_elements_simd(std::vector<int> arr, int k){\n    __m256i sum = _mm256_setzero_si256();\n    int i = 0;\n    for (; i + 8 <= k; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&arr[i]);\n        __m256i mask = _mm256_cmpgt_epi32(vec, _mm256_set1_epi32(9));\n        mask = _mm256_or_si256(mask, _mm256_cmplt_epi32(vec, _mm256_set1_epi32(100)));\n        __m256i filtered = _mm256_and_si256(vec, mask);\n        sum = _mm256_add_epi32(sum, filtered);\n    }\n    \n    int result[8];\n    _mm256_storeu_si256((__m256i*)result, sum);\n    int final_sum = 0;\n    for (int j = 0; j < 8; j++) {\n        final_sum += result[j];\n    }\n    \n    for (; i < k; i++) {\n        if (arr[i] >= 10 && arr[i] < 100) {\n            final_sum += arr[i];\n        }\n    }\n    \n    return final_sum;\n}\n```"}
{"task_id": "SimdBench_121_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nint add_elements_simd(std::vector<int> arr, int k){\n    __m256i sum = _mm256_setzero_si256();\n    int i = 0;\n    for (; i < k - 7; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&arr[i]);\n        __m256i mask = _mm256_cmpgt_epi32(vec, _mm256_set1_epi32(9));\n        mask = _mm256_or_si256(mask, _mm256_cmplt_epi32(vec, _mm256_set1_epi32(100)));\n        __m256i filtered = _mm256_and_si256(vec, mask);\n        sum = _mm256_add_epi32(sum, filtered);\n    }\n    int result[8];\n    _mm256_storeu_si256((__m256i*)result, sum);\n    int final_sum = 0;\n    for (int j = 0; j < 8; j++) {\n        final_sum += result[j];\n    }\n    for (; i < k; i++) {\n        if (arr[i] >= 10 && arr[i] < 100) {\n            final_sum += arr[i];\n        }\n    }\n    return final_sum;\n}\n```"}
{"task_id": "SimdBench_122_AVX", "completion": "```cpp\nbool is_sorted_simd(const std::vector<int> & lst){\n    if(lst.size() <= 1) return true;\n    \n    const int size = lst.size();\n    const int simd_size = 8;\n    \n    for(int i = 0; i < size - simd_size + 1; i += simd_size){\n        __m256i vec = _mm256_loadu_si256((__m256i*)&lst[i]);\n        __m256i next_vec = _mm256_loadu_si256((__m256i*)&lst[i + simd_size]);\n        \n        __m256i cmp = _mm256_cmpgt_epi32(vec, next_vec);\n        if(_mm256_movemask_ps(_mm256_castsi256_ps(cmp)) != 0){\n            return false;\n        }\n    }\n    \n    for(int i = size - size % simd_size; i < size - 1; ++i){\n        if(lst[i] > lst[i + 1]){\n            return false;\n        }\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_122_AVX", "completion": "```cpp\nbool is_sorted_simd(const std::vector<int> & lst){\n    if(lst.size() < 2) return true;\n    \n    const int* data = lst.data();\n    int size = lst.size();\n    \n    __m256i prev = _mm256_set1_epi32(data[0]);\n    \n    for(int i = 8; i < size; i += 8){\n        __m256i current = _mm256_loadu_si256((__m256i*)(data + i));\n        __m256i cmp = _mm256_cmpgt_epi32(current, prev);\n        if(_mm256_movemask_epi8(cmp) != 0xFFFFFFFF) return false;\n        prev = _mm256_set1_epi32(data[i]);\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_122_AVX", "completion": "```cpp\nbool is_sorted_simd(const std::vector<int> & lst){\n    if(lst.size() < 2) return true;\n    \n    const int* data = lst.data();\n    int size = lst.size();\n    \n    __m256i prev = _mm256_set1_epi32(data[0]);\n    \n    for(int i = 8; i <= size; i += 8){\n        __m256i current = _mm256_loadu_si256((__m256i*)&data[i-8]);\n        __m256i cmp = _mm256_cmpgt_epi32(current, prev);\n        if(_mm256_movemask_epi8(cmp) != 0xFFFFFFFF){\n            return false;\n        }\n        prev = _mm256_set1_epi32(data[i-1]);\n    }\n    \n    int remaining = size % 8;\n    if(remaining > 1){\n        __m256i current = _mm256_maskload_epi32(&data[size - remaining], _mm256_setr_epi32(-1, -1, -1, -1, -1, -1, -1, -1));\n        __m256i cmp = _mm256_cmpgt_epi32(current, prev);\n        if(_mm256_movemask_epi8(cmp) != 0xFFFFFFFF){\n            return false;\n        }\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_122_AVX", "completion": "```cpp\nbool is_sorted_simd(const std::vector<int> & lst){\n    if(lst.size() < 2) return true;\n    \n    __m256i prev = _mm256_set1_epi32(lst[0]);\n    \n    for(size_t i = 1; i < lst.size(); i += 8){\n        __m256i current = _mm256_loadu_si256((__m256i*)&lst[i]);\n        __m256i cmp = _mm256_cmpgt_epi32(current, prev);\n        if(_mm256_movemask_epi8(cmp) != 0xFFFFFFFF) return false;\n        prev = _mm256_shuffle_epi32(current, _MM_SHUFFLE(3, 2, 1, 0));\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_122_AVX", "completion": "```cpp\nbool is_sorted_simd(const std::vector<int> & lst){\n    if(lst.size() < 2) return true;\n    \n    __m256i prev = _mm256_set1_epi32(lst[0]);\n    \n    for(size_t i = 1; i < lst.size(); i += 8){\n        __m256i current = _mm256_loadu_si256((__m256i*)&lst[i]);\n        \n        __m256i cmp = _mm256_cmpgt_epi32(current, prev);\n        int mask = _mm256_movemask_ps(_mm256_castsi256_ps(cmp));\n        \n        if(mask != 255) return false;\n        \n        prev = _mm256_permutevar8x32_epi32(current, _mm256_set_epi32(7, 6, 5, 4, 3, 2, 1, 0));\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_123_AVX", "completion": "```cpp\nint prod_signs_simd(const std::vector<int> & arr){\n    if(arr.empty()) return -32768;\n\n    __m256i sum = _mm256_setzero_si256();\n    __m256i signs = _mm256_set1_epi32(1);\n\n    for(size_t i = 0; i < arr.size(); i += 8){\n        __m256i values = _mm256_loadu_si256((__m256i*)&arr[i]);\n        __m256i abs_values = _mm256_abs_epi32(values);\n        __m256i signs_mask = _mm256_cmpgt_epi32(values, _mm256_setzero_si256());\n        signs = _mm256_mullo_epi32(signs, signs_mask);\n        sum = _mm256_add_epi32(sum, abs_values);\n    }\n\n    __m128i sum_lo = _mm256_castsi256_si128(sum);\n    __m128i sum_hi = _mm256_extracti128_si256(sum, 1);\n    __m128i result = _mm_mullo_epi32(_mm_castsi256_si128(signs), _mm_mullo_epi32(sum_lo, sum_hi));\n\n    return _mm_cvtsi128_si32(result);\n}\n```"}
{"task_id": "SimdBench_123_AVX", "completion": "```cpp\nint prod_signs_simd(const std::vector<int> & arr){\n    if(arr.empty()) return -32768;\n    \n    __m256i sum = _mm256_setzero_si256();\n    __m256i signs_product = _mm256_set1_epi32(1);\n    \n    for(size_t i = 0; i < arr.size(); i += 8){\n        __m256i values = _mm256_loadu_si256((__m256i*)&arr[i]);\n        \n        __m256i signs = _mm256_cmpgt_epi32(values, _mm256_setzero_si256());\n        signs = _mm256_sub_epi32(signs, _mm256_cmpgt_epi32(_mm256_setzero_si256(), values));\n        \n        signs_product = _mm256_mullo_epi32(signs_product, signs);\n        \n        __m256i magnitudes = _mm256_abs_epi32(values);\n        sum = _mm256_add_epi32(sum, magnitudes);\n    }\n    \n    __m256i result = _mm256_mullo_epi32(sum, signs_product);\n    \n    int final_result[8];\n    _mm256_storeu_si256((__m256i*)final_result, result);\n    \n    int total = 0;\n    for(int i = 0; i < 8; i++){\n        total += final_result[i];\n    }\n    \n    return total;\n}\n```"}
{"task_id": "SimdBench_123_AVX", "completion": "```cpp\nint prod_signs_simd(const std::vector<int> & arr){\n    if(arr.empty()) return -32768;\n    \n    __m256i sum = _mm256_setzero_si256();\n    __m256i signs_product = _mm256_set1_epi32(1);\n    \n    for(size_t i = 0; i < arr.size(); i += 8){\n        __m256i vec = _mm256_loadu_si256((__m256i*)&arr[i]);\n        \n        __m256i signs = _mm256_cmpgt_epi32(_mm256_setzero_si256(), vec);\n        signs = _mm256_or_si256(signs, _mm256_and_si256(_mm256_cmpeq_epi32(_mm256_setzero_si256(), vec), _mm256_set1_epi32(1)));\n        \n        signs_product = _mm256_mullo_epi32(signs_product, signs);\n        \n        __m256i abs_vec = _mm256_abs_epi32(vec);\n        sum = _mm256_add_epi32(sum, abs_vec);\n    }\n    \n    __m128i sum_lo = _mm256_extractf128_si256(sum, 0);\n    __m128i sum_hi = _mm256_extractf128_si256(sum, 1);\n    __m128i sum_final = _mm_add_epi32(sum_lo, sum_hi);\n    \n    int result = _mm256_extract_epi32(signs_product, 0) * _mm_extract_epi32(sum_final, 0);\n    return result;\n}\n```"}
{"task_id": "SimdBench_123_AVX", "completion": "```cpp\nint prod_signs_simd(const std::vector<int> & arr){\n    if(arr.empty()) return -32768;\n    \n    __m256i sum = _mm256_setzero_si256();\n    __m256i signs_product = _mm256_set1_epi32(1);\n    \n    for(size_t i = 0; i < arr.size(); i += 8){\n        __m256i vec = _mm256_loadu_si256((__m256i*)&arr[i]);\n        \n        __m256i signs = _mm256_cmpgt_epi32(_mm256_setzero_si256(), vec);\n        signs = _mm256_or_si256(signs, _mm256_and_si256(_mm256_cmpeq_epi32(_mm256_setzero_si256(), vec), _mm256_set1_epi32(1)));\n        \n        signs_product = _mm256_mullo_epi32(signs_product, signs);\n        \n        __m256i abs_vec = _mm256_abs_epi32(vec);\n        sum = _mm256_add_epi32(sum, abs_vec);\n    }\n    \n    __m256i result = _mm256_mullo_epi32(sum, signs_product);\n    \n    int final_result[8];\n    _mm256_storeu_si256((__m256i*)final_result, result);\n    \n    return final_result[0] + final_result[1] + final_result[2] + final_result[3];\n}\n```"}
{"task_id": "SimdBench_123_AVX", "completion": "```cpp\nint prod_signs_simd(const std::vector<int> & arr){\n    if(arr.empty()) return -32768;\n\n    __m256i sum = _mm256_setzero_si256();\n    __m256i signs_product = _mm256_set1_epi32(1);\n\n    for(size_t i = 0; i < arr.size(); i += 8){\n        __m256i values = _mm256_loadu_si256((__m256i*)&arr[i]);\n        __m256i signs = _mm256_cmpgt_epi32(values, _mm256_setzero_si256());\n        signs_product = _mm256_mullo_epi32(signs_product, signs);\n        sum = _mm256_add_epi32(sum, _mm256_mullo_epi32(values, signs));\n    }\n\n    __m128i sum_lo = _mm256_extractf128_si256(sum, 0);\n    __m128i sum_hi = _mm256_extractf128_si256(sum, 1);\n    __m128i result = _mm_add_epi32(sum_lo, sum_hi);\n\n    return _mm_cvtsi128_si32(result) * _mm256_extract_epi32(signs_product, 0);\n}\n```"}
{"task_id": "SimdBench_124_AVX", "completion": "```\nstd::vector<int> minPath_simd(const std::vector<std::vector<int> > & grid, int k){\n    std::vector<int> result(k);\n    int n = grid.size();\n    __m256i path = _mm256_set_epi32(0, 0, 0, 0, 0, 0, 0, 0);\n    __m256i indices = _mm256_set_epi32(0, 0, 0, 0, 0, 0, 0, 0);\n\n    for (int i = 0; i < k; i++) {\n        __m256i min_values = _mm256_set1_epi32(INT_MAX);\n        __m256i min_indices = _mm256_set1_epi32(0);\n\n        for (int r = 0; r < n; r++) {\n            for (int c = 0; c < n; c++) {\n                __m256i current_value = _mm256_set1_epi32(grid[r][c]);\n                __m256i cmp = _mm256_cmpgt_epi32(path, indices);\n                __m256i new_min_values = _mm256_min_epu32(min_values, current_value);\n                __m256i new_min_indices = _mm256_blendv_epi8(min_indices, _mm256_set1_epi32(r * n + c + 1), cmp);\n\n                min_values = _mm256_blendv_epi8(min_values, new_min_values, cmp);\n                min_indices = _mm256_blendv_epi8(min_indices, new_min_indices, cmp);\n            }\n        }\n\n        path = min_values;\n        indices = min_indices;\n        result[i] = _mm256_extract_epi32(path, 0);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_124_AVX", "completion": "```\nstd::vector<int> minPath_simd(const std::vector<std::vector<int> > & grid, int k){\n    std::vector<int> result;\n    int n = grid.size();\n    __m256i path = _mm256_set1_epi32(0);\n    __m256i indices = _mm256_setr_epi32(0, 1, 2, 3, 4, 5, 6, 7);\n    \n    for (int i = 0; i < k; i++) {\n        __m256i values = _mm256_set1_epi32(grid[0][0]);\n        __m256i min_index = indices;\n        \n        for (int r = 0; r < n; r++) {\n            for (int c = 0; c < n; c++) {\n                __m256i current_value = _mm256_set1_epi32(grid[r][c]);\n                __m256i cmp = _mm256_cmpgt_epi32(values, current_value);\n                values = _mm256_blendv_epi8(values, current_value, cmp);\n                min_index = _mm256_blendv_epi8(min_index, indices, cmp);\n            }\n        }\n        \n        result.push_back(_mm256_extract_epi32(values, 0));\n        path = _mm256_or_si256(path, _mm256_slli_epi32(_mm256_set1_epi32(1), _mm256_extract_epi32(min_index, 0)));\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_124_AVX", "completion": "```\nstd::vector<int> minPath_simd(const std::vector<std::vector<int>>& grid, int k) {\n    std::vector<int> result(k);\n    int n = grid.size();\n    __m256i min_values = _mm256_set1_epi32(INT_MAX);\n    __m256i min_indices = _mm256_set1_epi32(0);\n\n    for (int i = 0; i < n; ++i) {\n        for (int j = 0; j < n; ++j) {\n            __m256i current_value = _mm256_set1_epi32(grid[i][j]);\n            __m256i current_index = _mm256_set1_epi32(i * n + j + 1);\n\n            __m256i cmp_mask = _mm256_cmpgt_epi32(min_values, current_value);\n            min_values = _mm256_blendv_epi8(min_values, current_value, cmp_mask);\n            min_indices = _mm256_blendv_epi8(min_indices, current_index, cmp_mask);\n        }\n    }\n\n    for (int i = 0; i < k; ++i) {\n        int min_index;\n        _mm256_storeu_si256((__m256i*)&min_index, min_indices);\n\n        int row = (min_index - 1) / n;\n        int col = (min_index - 1) % n;\n\n        result[i] = grid[row][col];\n\n        __m256i new_min_indices = _mm256_setr_epi32(min_index - n, min_index - 1, min_index + 1, min_index + n,\n                                                    min_index - n - 1, min_index - n + 1, min_index + n - 1, min_index + n + 1);\n        min_indices = new_min_indices;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_124_AVX", "completion": "```\nstd::vector<int> minPath_simd(const std::vector<std::vector<int> > & grid, int k){\n    std::vector<int> result;\n    int n = grid.size();\n    __m256i min_values = _mm256_set1_epi32(INT_MAX);\n    __m256i min_indices = _mm256_set1_epi32(0);\n    \n    for (int i = 0; i < n; ++i) {\n        for (int j = 0; j < n; ++j) {\n            __m256i value = _mm256_set1_epi32(grid[i][j]);\n            __m256i indices = _mm256_setr_epi32(i * n + j + 1, 0, 0, 0, 0, 0, 0, 0);\n            \n            __m256i cmp_mask = _mm256_cmpgt_epi32(min_values, value);\n            min_values = _mm256_blendv_epi8(min_values, value, cmp_mask);\n            min_indices = _mm256_blendv_epi8(min_indices, indices, cmp_mask);\n        }\n    }\n    \n    int min_values_arr[8];\n    int min_indices_arr[8];\n    _mm256_storeu_si256((__m256i*)min_values_arr, min_values);\n    _mm256_storeu_si256((__m256i*)min_indices_arr, min_indices);\n    \n    for (int i = 0; i < 8; ++i) {\n        if (min_indices_arr[i] != 0) {\n            result.push_back(min_indices_arr[i]);\n            if (result.size() == k) {\n                break;\n            }\n        }\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_124_AVX", "completion": "```\nstd::vector<int> minPath_simd(const std::vector<std::vector<int> > & grid, int k){\n    std::vector<int> result;\n    int n = grid.size();\n    __m256i path = _mm256_set1_epi32(0);\n    __m256i indices = _mm256_setr_epi32(0, 1, 2, 3, 4, 5, 6, 7);\n    \n    for (int i = 0; i < k; i++) {\n        __m256i values = _mm256_set1_epi32(grid[0][0]);\n        __m256i min_values = _mm256_set1_epi32(1000000);\n        __m256i min_indices = _mm256_set1_epi32(0);\n        \n        for (int r = 0; r < n; r++) {\n            for (int c = 0; c < n; c++) {\n                __m256i current_value = _mm256_set1_epi32(grid[r][c]);\n                __m256i cmp = _mm256_cmpgt_epi32(values, current_value);\n                values = _mm256_min_epi32(values, current_value);\n                min_values = _mm256_blendv_epi8(min_values, current_value, cmp);\n                min_indices = _mm256_blendv_epi8(min_indices, _mm256_set1_epi32(r * n + c), cmp);\n            }\n        }\n        \n        path = _mm256_insert_epi32(path, _mm256_extract_epi32(min_indices, 0), i);\n    }\n    \n    for (int i = 0; i < k; i++) {\n        result.push_back(_mm256_extract_epi32(path, i));\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_125_AVX", "completion": "```c\n#include <immintrin.h>\n#include <x86intrin.h>\n\nuint64_t digits_simd(uint64_t n){\n    __m256i odd_digits = _mm256_set1_epi32(1);\n    __m256i product = _mm256_set1_epi32(1);\n    \n    while(n > 0){\n        uint64_t digit = n % 10;\n        if(digit % 2 != 0){\n            odd_digits = _mm256_mullo_epi32(odd_digits, _mm256_set1_epi32(digit));\n        }\n        n /= 10;\n    }\n    \n    __m128i result = _mm256_extracti128_si256(odd_digits, 0);\n    result = _mm_mullo_epi32(result, _mm256_extracti128_si256(odd_digits, 1));\n    \n    return _mm_cvtsi128_si64(result);\n}\n```"}
{"task_id": "SimdBench_125_AVX", "completion": "```c\nuint64_t digits_simd(uint64_t n){\n    __m256i odd_digits = _mm256_set1_epi8(0);\n    __m256i all_ones = _mm256_set1_epi8(1);\n    __m256i all_zeros = _mm256_setzero_si256();\n    \n    while(n > 0){\n        uint64_t digit = n % 10;\n        if(digit % 2 != 0){\n            __m256i digit_vec = _mm256_set1_epi8(digit);\n            odd_digits = _mm256_mullo_epi16(odd_digits, digit_vec);\n        }\n        n /= 10;\n    }\n    \n    __m256i cmp_result = _mm256_cmpeq_epi8(odd_digits, all_zeros);\n    int mask = _mm256_movemask_epi8(cmp_result);\n    \n    if(mask == 0){\n        __m256i result = _mm256_hmul_epi16(odd_digits, all_ones);\n        return (uint64_t)_mm256_extract_epi64(result, 0);\n    } else {\n        return 0;\n    }\n}\n```"}
{"task_id": "SimdBench_125_AVX", "completion": "```c\nuint64_t digits_simd(uint64_t n){\n    __m256i odd_digits = _mm256_set1_epi8(0);\n    __m256i all_even = _mm256_set1_epi8(1);\n    \n    while(n > 0){\n        uint64_t digit = n % 10;\n        n /= 10;\n        \n        if(digit % 2 == 0){\n            all_even = _mm256_and_si256(all_even, _mm256_set1_epi8(0));\n        } else {\n            odd_digits = _mm256_mullo_epi16(odd_digits, _mm256_set1_epi8(digit));\n        }\n    }\n    \n    __m128i result = _mm256_extracti128_si256(odd_digits, 0);\n    result = _mm_mullo_epi16(result, _mm256_extracti128_si256(odd_digits, 1));\n    \n    return _mm_cvtsi128_si64(result);\n}\n```"}
{"task_id": "SimdBench_125_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nuint64_t digits_simd(uint64_t n){\n    __m256i odd_digits = _mm256_set1_epi64x(1);\n    __m256i result = _mm256_set1_epi64x(1);\n    \n    while(n > 0){\n        uint64_t digit = n % 10;\n        if(digit % 2 == 1){\n            __m256i digit_vec = _mm256_set1_epi64x(digit);\n            result = _mm256_mullo_epi64(result, digit_vec);\n        }\n        n /= 10;\n    }\n    \n    __m128i result_low = _mm256_castsi256_si128(result);\n    __m128i result_high = _mm256_extracti128_si256(result, 1);\n    __m128i final_result = _mm_mullo_epi64(result_low, result_high);\n    \n    return _mm_cvtsi128_si64(final_result);\n}\n```"}
{"task_id": "SimdBench_125_AVX", "completion": "```c\n#include <immintrin.h>\n#include <x86intrin.h>\n\nuint64_t digits_simd(uint64_t n){\n    __m256i odd_digits = _mm256_set1_epi64x(1);\n    __m256i result = _mm256_set1_epi64x(1);\n\n    while (n > 0) {\n        uint64_t digit = n % 10;\n        if (digit % 2 != 0) {\n            odd_digits = _mm256_mullo_epi64(odd_digits, _mm256_set1_epi64x(digit));\n        }\n        n /= 10;\n    }\n\n    __m256i mask = _mm256_cmpgt_epi64(odd_digits, _mm256_set1_epi64x(1));\n    __m256i masked_result = _mm256_and_si256(odd_digits, mask);\n\n    uint64_t final_result[4];\n    _mm256_storeu_si256((__m256i*)final_result, masked_result);\n\n    return final_result[0] * final_result[1] * final_result[2] * final_result[3];\n}\n```"}
{"task_id": "SimdBench_126_AVX", "completion": "```cpp\nuint64_t sum_squares_simd(const std::vector<float> & lst){\n    size_t n = lst.size();\n    __m256 sum = _mm256_setzero_ps();\n    for (size_t i = 0; i < n; i += 8) {\n        __m256 values = _mm256_loadu_ps(&lst[i]);\n        __m256 rounded_values = _mm256_ceil_ps(values);\n        __m256 squared_values = _mm256_mul_ps(rounded_values, rounded_values);\n        sum = _mm256_add_ps(sum, squared_values);\n    }\n    alignas(32) float result[8];\n    _mm256_store_ps(result, sum);\n    uint64_t total = 0;\n    for (int i = 0; i < 8; ++i) {\n        total += static_cast<uint64_t>(result[i]);\n    }\n    return total;\n}\n```"}
{"task_id": "SimdBench_126_AVX", "completion": "```\nuint64_t sum_squares_simd(const std::vector<float> & lst){\n    size_t size = lst.size();\n    size_t simd_size = size / 8 * 8;\n    \n    __m256 sum = _mm256_setzero_ps();\n    \n    for (size_t i = 0; i < simd_size; i += 8) {\n        __m256 vec = _mm256_loadu_ps(&lst[i]);\n        \n        // Round each element to the upper int (ceiling)\n        __m256i rounded = _mm256_cvtps_epi32(_mm256_ceil_ps(vec));\n        \n        // Square each element\n        __m256i squared = _mm256_mullo_epi32(rounded, rounded);\n        \n        // Convert to float\n        __m256 squared_float = _mm256_cvtepi32_ps(squared);\n        \n        // Add to the sum\n        sum = _mm256_add_ps(sum, squared_float);\n    }\n    \n    // Horizontal sum\n    __m128 sum_low = _mm256_castps256_ps128(sum);\n    __m128 sum_high = _mm256_extractf128_ps(sum, 1);\n    __m128 total = _mm_add_ps(sum_low, sum_high);\n    \n    // Extract the result\n    alignas(32) float result[8];\n    _mm_store_ps(result, total);\n    \n    uint64_t final_sum = 0;\n    for (int i = 0; i < 8; i++) {\n        final_sum += static_cast<uint64_t>(result[i]);\n    }\n    \n    return final_sum;\n}\n```"}
{"task_id": "SimdBench_126_AVX", "completion": "```\nuint64_t sum_squares_simd(const std::vector<float> & lst){\n    size_t n = lst.size();\n    __m256 sum = _mm256_setzero_ps();\n    \n    for (size_t i = 0; i < n; i += 8) {\n        __m256 values = _mm256_loadu_ps(&lst[i]);\n        \n        // Round each element to the nearest integer (ceiling)\n        __m256 rounded_values = _mm256_ceil_ps(values);\n        \n        // Square each element\n        __m256 squared_values = _mm256_mul_ps(rounded_values, rounded_values);\n        \n        // Add the squared values to the sum\n        sum = _mm256_add_ps(sum, squared_values);\n    }\n    \n    // Horizontal sum of the elements in the sum vector\n    __m128 sum_low = _mm256_castps256_ps128(sum);\n    __m128 sum_high = _mm256_extractf128_ps(sum, 1);\n    __m128 total = _mm_add_ps(sum_low, sum_high);\n    \n    // Convert the result to a 128-bit integer vector\n    __m128i total_int = _mm_cvtps_epi32(total);\n    \n    // Horizontal sum of the elements in the total_int vector\n    __m128i total_int_low = _mm_cvtepi32_epi64(total_int);\n    __m128i total_int_high = _mm_srli_si128(total_int, 8);\n    __m128i result = _mm_add_epi64(total_int_low, total_int_high);\n    \n    return _mm_cvtsi128_si64(result);\n}\n```"}
{"task_id": "SimdBench_126_AVX", "completion": "```\nuint64_t sum_squares_simd(const std::vector<float> & lst){\n    size_t size = lst.size();\n    size_t simd_size = size / 8 * 8;\n    \n    __m256 sum = _mm256_setzero_ps();\n    \n    for (size_t i = 0; i < simd_size; i += 8) {\n        __m256 vec = _mm256_loadu_ps(&lst[i]);\n        \n        // Round each element to the upper int (ceiling)\n        vec = _mm256_ceil_ps(vec);\n        \n        // Square each element\n        vec = _mm256_mul_ps(vec, vec);\n        \n        // Add to the sum\n        sum = _mm256_add_ps(sum, vec);\n    }\n    \n    alignas(32) float result[8];\n    _mm256_store_ps(result, sum);\n    \n    uint64_t final_sum = 0;\n    for (int i = 0; i < 8; i++) {\n        final_sum += static_cast<uint64_t>(result[i]);\n    }\n    \n    return final_sum;\n}\n```"}
{"task_id": "SimdBench_126_AVX", "completion": "```cpp\nuint64_t sum_squares_simd(const std::vector<float> & lst){\n    __m256 sum = _mm256_setzero_ps();\n    for (size_t i = 0; i < lst.size(); i += 8) {\n        __m256 vec = _mm256_loadu_ps(&lst[i]);\n        vec = _mm256_ceil_ps(vec);\n        vec = _mm256_mul_ps(vec, vec);\n        sum = _mm256_add_ps(sum, vec);\n    }\n    \n    alignas(32) float result[8];\n    _mm256_store_ps(result, sum);\n    \n    uint64_t total = 0;\n    for (int i = 0; i < 8; ++i) {\n        total += static_cast<uint64_t>(result[i]);\n    }\n    \n    return total;\n}\n```"}
{"task_id": "SimdBench_127_AVX", "completion": "```cpp\nint can_arrange_simd(const std::vector<int> & arr){\n    int maxIndex = -1;\n    int size = arr.size();\n    if (size < 8) {\n        for (int i = 1; i < size; ++i) {\n            if (arr[i] < arr[i - 1]) {\n                maxIndex = i - 1;\n                break;\n            }\n        }\n        return maxIndex;\n    }\n    \n    __m256i prev = _mm256_loadu_si256((__m256i*)&arr[0]);\n    for (int i = 8; i < size; i += 8) {\n        __m256i curr = _mm256_loadu_si256((__m256i*)&arr[i]);\n        __m256i cmp = _mm256_cmpgt_epi32(prev, curr);\n        int mask = _mm256_movemask_ps(_mm256_castsi256_ps(cmp));\n        if (mask != 0) {\n            maxIndex = i - 1;\n            break;\n        }\n        prev = curr;\n    }\n    \n    for (int i = size - (size % 8); i < size; ++i) {\n        if (arr[i] < arr[i - 1]) {\n            maxIndex = i - 1;\n            break;\n        }\n    }\n    \n    return maxIndex;\n}\n```"}
{"task_id": "SimdBench_127_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nint can_arrange_simd(const std::vector<int> & arr){\n    if(arr.size() < 8) {\n        for(int i = arr.size()-1; i > 0; i--) {\n            if(arr[i] < arr[i-1]) {\n                return i;\n            }\n        }\n        return -1;\n    }\n\n    const int* data = arr.data();\n    __m256i prev = _mm256_loadu_si256((__m256i*)(data));\n    for(size_t i = 8; i < arr.size(); i += 8) {\n        __m256i curr = _mm256_loadu_si256((__m256i*)(data + i));\n        __m256i cmp = _mm256_cmpgt_epi32(prev, curr);\n        int mask = _mm256_movemask_ps(_mm256_castsi256_ps(cmp));\n        if(mask != 0) {\n            return i + __builtin_ctz(mask);\n        }\n        prev = curr;\n    }\n\n    for(int i = arr.size()-1; i > 0; i--) {\n        if(arr[i] < arr[i-1]) {\n            return i;\n        }\n    }\n    return -1;\n}\n```"}
{"task_id": "SimdBench_127_AVX", "completion": "```cpp\nint can_arrange_simd(const std::vector<int> & arr){\n    int n = arr.size();\n    if (n < 2) return -1;\n\n    __m256i prev = _mm256_set_epi32(arr[7], arr[6], arr[5], arr[4], arr[3], arr[2], arr[1], arr[0]);\n    for (int i = 8; i < n; i += 8) {\n        __m256i curr = _mm256_set_epi32(arr[i+7], arr[i+6], arr[i+5], arr[i+4], arr[i+3], arr[i+2], arr[i+1], arr[i]);\n        __m256i cmp = _mm256_cmpgt_epi32(prev, curr);\n        int mask = _mm256_movemask_ps(_mm256_castsi256_ps(cmp));\n        if (mask != 0) {\n            return i - 1 + _tzcnt_u32(mask);\n        }\n        prev = curr;\n    }\n\n    return -1;\n}\n```"}
{"task_id": "SimdBench_127_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nint can_arrange_simd(const std::vector<int> & arr){\n    if(arr.size() < 2) return -1;\n\n    const int size = arr.size();\n    const int simd_width = 8;\n    const int simd_size = size / simd_width;\n    \n    __m256i prev = _mm256_set1_epi32(arr[0]);\n    \n    for(int i = 1; i < simd_size * simd_width; i += simd_width){\n        __m256i curr = _mm256_loadu_si256((__m256i*)&arr[i]);\n        __m256i cmp = _mm256_cmpgt_epi32(prev, curr);\n        int mask = _mm256_movemask_ps(_mm256_castsi256_ps(cmp));\n        \n        if(mask != 0){\n            int index = i - 1 + __builtin_ctz(mask);\n            return index;\n        }\n        \n        prev = curr;\n    }\n    \n    for(int i = simd_size * simd_width; i < size; ++i){\n        if(arr[i-1] > arr[i]){\n            return i - 1;\n        }\n    }\n    \n    return -1;\n}\n```"}
{"task_id": "SimdBench_127_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nint can_arrange_simd(const std::vector<int> & arr){\n    if(arr.size() < 8) {\n        for(int i = arr.size()-1; i > 0; i--) {\n            if(arr[i] < arr[i-1]) {\n                return i-1;\n            }\n        }\n        return -1;\n    }\n\n    __m256i prev = _mm256_loadu_si256((__m256i*)&arr[0]);\n    for(int i = 8; i < arr.size(); i += 8) {\n        __m256i curr = _mm256_loadu_si256((__m256i*)&arr[i]);\n        __m256i cmp = _mm256_cmpgt_epi32(prev, curr);\n        int mask = _mm256_movemask_ps(_mm256_castsi256_ps(cmp));\n        if(mask != 0) {\n            return i-1 + _tzcnt_u32(mask);\n        }\n        prev = curr;\n    }\n\n    for(int i = (arr.size()/8)*8 - 1; i > 0; i--) {\n        if(arr[i] < arr[i-1]) {\n            return i-1;\n        }\n    }\n    return -1;\n}\n```"}
{"task_id": "SimdBench_128_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nstd::vector<int> largest_smallest_integers_simd(const std::vector<int>& lst){\n    if(lst.empty()) return {0, 0};\n\n    __m256i largest_neg = _mm256_set1_epi32(INT_MIN);\n    __m256i smallest_pos = _mm256_set1_epi32(INT_MAX);\n\n    for(size_t i = 0; i < lst.size(); i += 8){\n        __m256i values = _mm256_loadu_si256((__m256i*)&lst[i]);\n\n        __m256i neg_mask = _mm256_cmpgt_epi32(_mm256_setzero_si256(), values);\n        __m256i pos_mask = _mm256_cmpgt_epi32(values, _mm256_setzero_si256());\n\n        largest_neg = _mm256_max_epi32(largest_neg, _mm256_and_si256(values, neg_mask));\n        smallest_pos = _mm256_min_epi32(smallest_pos, _mm256_and_si256(values, pos_mask));\n    }\n\n    int largest_neg_arr[8];\n    int smallest_pos_arr[8];\n\n    _mm256_storeu_si256((__m256i*)largest_neg_arr, largest_neg);\n    _mm256_storeu_si256((__m256i*)smallest_pos_arr, smallest_pos);\n\n    int largest_neg_res = largest_neg_arr[0];\n    int smallest_pos_res = smallest_pos_arr[0];\n\n    for(int i = 1; i < 8; i++){\n        largest_neg_res = std::max(largest_neg_res, largest_neg_arr[i]);\n        smallest_pos_res = std::min(smallest_pos_res, smallest_pos_arr[i]);\n    }\n\n    return {largest_neg_res, smallest_pos_res};\n}\n```"}
{"task_id": "SimdBench_128_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nstd::vector<int> largest_smallest_integers_simd(const std::vector<int>& lst){\n    if(lst.empty()) return {0, 0};\n\n    __m256i max_neg = _mm256_set1_epi32(INT_MIN);\n    __m256i min_pos = _mm256_set1_epi32(INT_MAX);\n\n    for(size_t i = 0; i < lst.size(); i += 8){\n        __m256i vec = _mm256_loadu_si256((__m256i*)&lst[i]);\n\n        __m256i neg_mask = _mm256_cmpgt_epi32(_mm256_setzero_si256(), vec);\n        __m256i pos_mask = _mm256_cmpgt_epi32(vec, _mm256_setzero_si256());\n\n        max_neg = _mm256_max_epi32(max_neg, _mm256_and_si256(vec, neg_mask));\n        min_pos = _mm256_min_epi32(min_pos, _mm256_and_si256(vec, pos_mask));\n    }\n\n    int max_neg_arr[8], min_pos_arr[8];\n    _mm256_storeu_si256((__m256i*)max_neg_arr, max_neg);\n    _mm256_storeu_si256((__m256i*)min_pos_arr, min_pos);\n\n    int max_neg_res = INT_MIN, min_pos_res = INT_MAX;\n    for(int i = 0; i < 8; ++i){\n        max_neg_res = std::max(max_neg_res, max_neg_arr[i]);\n        min_pos_res = std::min(min_pos_res, min_pos_arr[i]);\n    }\n\n    return {max_neg_res, min_pos_res};\n}\n```"}
{"task_id": "SimdBench_128_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nstd::vector<int> largest_smallest_integers_simd(const std::vector<int>& lst){\n    if(lst.empty()) return {0, 0};\n\n    __m256i max_neg = _mm256_set1_epi32(INT_MIN);\n    __m256i min_pos = _mm256_set1_epi32(INT_MAX);\n\n    for(size_t i = 0; i < lst.size(); i += 8){\n        __m256i vec = _mm256_loadu_si256((__m256i*)&lst[i]);\n\n        __m256i neg_mask = _mm256_cmpgt_epi32(_mm256_setzero_si256(), vec);\n        __m256i pos_mask = _mm256_cmpgt_epi32(vec, _mm256_setzero_si256());\n\n        max_neg = _mm256_max_epi32(max_neg, _mm256_and_si256(vec, neg_mask));\n        min_pos = _mm256_min_epi32(min_pos, _mm256_and_si256(vec, pos_mask));\n    }\n\n    int max_neg_arr[8], min_pos_arr[8];\n    _mm256_storeu_si256((__m256i*)max_neg_arr, max_neg);\n    _mm256_storeu_si256((__m256i*)min_pos_arr, min_pos);\n\n    int max_neg_res = INT_MIN, min_pos_res = INT_MAX;\n    for(int i = 0; i < 8; ++i){\n        max_neg_res = std::max(max_neg_res, max_neg_arr[i]);\n        min_pos_res = std::min(min_pos_res, min_pos_arr[i]);\n    }\n\n    return {max_neg_res, min_pos_res};\n}\n```"}
{"task_id": "SimdBench_128_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nstd::vector<int> largest_smallest_integers_simd(const std::vector<int>& lst){\n    if(lst.empty()) return {0, 0};\n\n    __m256i max_neg = _mm256_set1_epi32(INT_MIN);\n    __m256i min_pos = _mm256_set1_epi32(INT_MAX);\n\n    for(size_t i = 0; i < lst.size(); i += 8){\n        __m256i vec = _mm256_loadu_si256((__m256i*)&lst[i]);\n\n        __m256i neg_mask = _mm256_cmpgt_epi32(_mm256_setzero_si256(), vec);\n        __m256i pos_mask = _mm256_cmpgt_epi32(vec, _mm256_setzero_si256());\n\n        max_neg = _mm256_max_epi32(max_neg, _mm256_and_si256(vec, neg_mask));\n        min_pos = _mm256_min_epi32(min_pos, _mm256_and_si256(vec, pos_mask));\n    }\n\n    int max_neg_arr[8];\n    int min_pos_arr[8];\n    _mm256_storeu_si256((__m256i*)max_neg_arr, max_neg);\n    _mm256_storeu_si256((__m256i*)min_pos_arr, min_pos);\n\n    int max_neg_res = INT_MIN;\n    int min_pos_res = INT_MAX;\n\n    for(int i = 0; i < 8; ++i){\n        max_neg_res = std::max(max_neg_res, max_neg_arr[i]);\n        min_pos_res = std::min(min_pos_res, min_pos_arr[i]);\n    }\n\n    return {max_neg_res, min_pos_res};\n}\n```"}
{"task_id": "SimdBench_128_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nstd::vector<int> largest_smallest_integers_simd(const std::vector<int>& lst){\n    if(lst.empty()) return {0, 0};\n\n    const int size = lst.size();\n    const int* data = lst.data();\n\n    __m256i largest_negative = _mm256_set1_epi32(INT_MIN);\n    __m256i smallest_positive = _mm256_set1_epi32(INT_MAX);\n\n    for(int i = 0; i < size; i += 8){\n        __m256i values = _mm256_loadu_si256((__m256i*)(data + i));\n\n        __m256i is_negative = _mm256_cmpgt_epi32(_mm256_setzero_si256(), values);\n        __m256i is_positive = _mm256_cmpgt_epi32(values, _mm256_setzero_si256());\n\n        largest_negative = _mm256_max_epi32(largest_negative, _mm256_and_si256(values, is_negative));\n        smallest_positive = _mm256_min_epi32(smallest_positive, _mm256_and_si256(values, is_positive));\n    }\n\n    int result[8];\n    _mm256_storeu_si256((__m256i*)result, largest_negative);\n    _mm256_storeu_si256((__m256i*)(result + 4), smallest_positive);\n\n    int largest = INT_MIN;\n    int smallest = INT_MAX;\n\n    for(int i = 0; i < 8; ++i){\n        largest = std::max(largest, result[i]);\n        smallest = std::min(smallest, result[i]);\n    }\n\n    return {largest, smallest};\n}\n```"}
{"task_id": "SimdBench_129_AVX", "completion": "```c\n#include <immintrin.h>\n#include <x86intrin.h>\n\nuint64_t special_factorial_simd(uint64_t n){\n    __m256i result = _mm256_set1_epi64x(1);\n    __m256i factorials = _mm256_setr_epi64x(1, 1, 2, 6, 24, 120, 720, 5040);\n    \n    for (uint64_t i = 8; i <= n; i += 8) {\n        __m256i indices = _mm256_setr_epi64x(i, i-1, i-2, i-3, i-4, i-5, i-6, i-7);\n        result = _mm256_mul_epi32(result, _mm256_permutevar8x32_epi32(factorials, indices));\n    }\n    \n    uint64_t final_result[4];\n    _mm256_storeu_si256((__m256i*)final_result, result);\n    \n    return final_result[0] * final_result[1] * final_result[2] * final_result[3];\n}\n```"}
{"task_id": "SimdBench_129_AVX", "completion": "```c\n#include <immintrin.h>\n#include <x86intrin.h>\n\nuint64_t special_factorial_simd(uint64_t n){\n    __m256i result = _mm256_set1_epi64x(1);\n    __m256i factorials = _mm256_setr_epi64x(1, 1, 2, 6, 24, 120, 720, 5040);\n    \n    for (uint64_t i = 8; i <= n; i += 8) {\n        __m256i indices = _mm256_setr_epi64x(i, i-1, i-2, i-3, i-4, i-5, i-6, i-7);\n        result = _mm256_mul_epi32(result, _mm256_permutevar8x32_epi32(factorials, indices));\n    }\n    \n    uint64_t final_result[4];\n    _mm256_storeu_si256((__m256i*)final_result, result);\n    \n    return final_result[0] * final_result[1] * final_result[2] * final_result[3];\n}\n```  "}
{"task_id": "SimdBench_129_AVX", "completion": "```c\n#include <immintrin.h>\n#include <x86intrin.h>\n\nuint64_t special_factorial_simd(uint64_t n){\n    __m256i result = _mm256_set1_epi64x(1);\n    __m256i multiplier = _mm256_set_epi64x(1, 2, 3, 4);\n    \n    for(uint64_t i = 5; i <= n; i += 4){\n        __m256i indices = _mm256_set_epi64x(i, i-1, i-2, i-3);\n        multiplier = _mm256_mullo_epi64(multiplier, indices);\n        result = _mm256_mullo_epi64(result, multiplier);\n    }\n    \n    uint64_t final_result[4];\n    _mm256_storeu_si256((__m256i*)final_result, result);\n    \n    return final_result[0] * final_result[1] * final_result[2] * final_result[3];\n}\n```"}
{"task_id": "SimdBench_129_AVX", "completion": "```c\n#include <immintrin.h>\n#include <x86intrin.h>\n\nuint64_t special_factorial_simd(uint64_t n){\n    __m256i result = _mm256_set1_epi64x(1);\n    __m256i multiplier = _mm256_set_epi64x(1, 2, 3, 4);\n    \n    for(uint64_t i = 5; i <= n; i += 4){\n        __m256i indices = _mm256_set_epi64x(i, i-1, i-2, i-3);\n        multiplier = _mm256_mullo_epi64(multiplier, indices);\n        result = _mm256_mullo_epi64(result, multiplier);\n    }\n    \n    uint64_t final_result[4];\n    _mm256_storeu_si256((__m256i*)final_result, result);\n    \n    return final_result[0] * final_result[1] * final_result[2] * final_result[3];\n}\n```  "}
{"task_id": "SimdBench_129_AVX", "completion": "```c\n#include <immintrin.h>\n#include <x86intrin.h>\n\nuint64_t special_factorial_simd(uint64_t n){\n    __m256i result = _mm256_set1_epi64x(1);\n    for (uint64_t i = 1; i <= n; i++) {\n        __m256i current = _mm256_set1_epi64x(i);\n        result = _mm256_mul_epi64(result, current);\n    }\n\n    uint64_t final_result[4];\n    _mm256_storeu_si256((__m256i*)final_result, result);\n\n    return final_result[0] * final_result[1] * final_result[2] * final_result[3];\n}\n```"}
{"task_id": "SimdBench_130_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nint sum_squares_simd(const std::vector<int> & lst){\n    int sum = 0;\n    int size = lst.size();\n    int i = 0;\n    \n    __m256i indices = _mm256_setr_epi32(0, 1, 2, 3, 4, 5, 6, 7);\n    __m256i threes = _mm256_set1_epi32(3);\n    __m256i fours = _mm256_set1_epi32(4);\n    \n    for (; i + 8 <= size; i += 8) {\n        __m256i values = _mm256_loadu_si256((__m256i*)&lst[i]);\n        \n        __m256i is_multiple_of_three = _mm256_cmpeq_epi32(_mm256_and_si256(_mm256_set1_epi32(3), indices), _mm256_setzero_si256());\n        __m256i is_multiple_of_four = _mm256_cmpeq_epi32(_mm256_and_si256(_mm256_set1_epi32(4), indices), _mm256_setzero_si256());\n        \n        __m256i squared_values = _mm256_mullo_epi32(values, values);\n        __m256i cubed_values = _mm256_mullo_epi32(_mm256_mullo_epi32(values, values), values);\n        \n        __m256i result = _mm256_blendv_epi8(values, squared_values, is_multiple_of_three);\n        result = _mm256_blendv_epi8(result, cubed_values, _mm256_and_si256(is_multiple_of_four, _mm256_xor_si256(is_multiple_of_three, _mm256_set1_epi32(-1))));\n        \n        __m256i sum_vec = _mm256_hadd_epi32(result, result);\n        sum_vec = _mm256_hadd_epi32(sum_vec, sum_vec);\n        \n        sum += _mm256_extract_epi32(sum_vec, 0);\n    }\n    \n    for (; i < size; ++i) {\n        int index = i % 8;\n        int value = lst[i];\n        \n        if ((index == 3) && (index != 4)) {\n            sum += value * value;\n        } else if ((index == 4) && (index != 3)) {\n            sum += value * value * value;\n        } else {\n            sum += value;\n        }\n    }\n    \n    return sum;\n}\n```"}
{"task_id": "SimdBench_130_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nint sum_squares_simd(const std::vector<int> & lst){\n    int sum = 0;\n    int size = lst.size();\n    int i = 0;\n    \n    __m256i indices = _mm256_setr_epi32(0, 1, 2, 3, 4, 5, 6, 7);\n    __m256i threes = _mm256_set1_epi32(3);\n    __m256i fours = _mm256_set1_epi32(4);\n    \n    for (; i + 8 <= size; i += 8) {\n        __m256i values = _mm256_loadu_si256((__m256i*)&lst[i]);\n        \n        __m256i is_multiple_of_three = _mm256_cmpeq_epi32(_mm256_and_si256(_mm256_set1_epi32(3), indices), _mm256_setzero_si256());\n        __m256i is_multiple_of_four = _mm256_cmpeq_epi32(_mm256_and_si256(_mm256_set1_epi32(4), indices), _mm256_setzero_si256());\n        \n        __m256i squared = _mm256_mullo_epi32(values, values);\n        __m256i cubed = _mm256_mullo_epi32(_mm256_mullo_epi32(values, values), values);\n        \n        __m256i result = _mm256_blendv_epi8(values, squared, is_multiple_of_three);\n        result = _mm256_blendv_epi8(result, cubed, _mm256_and_si256(is_multiple_of_four, _mm256_xor_si256(is_multiple_of_three, _mm256_set1_epi32(-1))));\n        \n        __m256i sum_vec = _mm256_hadd_epi32(result, result);\n        sum_vec = _mm256_hadd_epi32(sum_vec, sum_vec);\n        \n        sum += _mm256_extract_epi32(sum_vec, 0);\n        \n        indices = _mm256_add_epi32(indices, _mm256_set1_epi32(8));\n    }\n    \n    int temp_sum[8];\n    _mm256_storeu_si256((__m256i*)temp_sum, indices);\n    for (int j = 0; i + j < size; j++) {\n        int index = temp_sum[j];\n        int value = lst[i + j];\n        \n        if ((index % 3 == 0) && (index % 4 != 0)) {\n            sum += value * value;\n        } else if ((index % 4 == 0) && (index % 3 != 0)) {\n            sum += value * value * value;\n        }\n    }\n    \n    return sum;\n}\n```"}
{"task_id": "SimdBench_130_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nint sum_squares_simd(const std::vector<int> & lst){\n    int sum = 0;\n    int size = lst.size();\n    int i = 0;\n    \n    __m256i multiples_of_3 = _mm256_setr_epi32(0, 0, 1, 0, 0, 1, 0, 0);\n    __m256i multiples_of_4 = _mm256_setr_epi32(0, 0, 0, 1, 0, 0, 0, 1);\n    \n    for (; i + 7 < size; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&lst[i]);\n        __m256i idx = _mm256_setr_epi32(i % 8 == 2, i % 8 == 3, i % 8 == 4, i % 8 == 5, i % 8 == 6, i % 8 == 7, 0, 0);\n        \n        __m256i square_mask = _mm256_and(vec, multiples_of_3);\n        __m256i cube_mask = _mm256_andnot(multiples_of_3, _mm256_and(vec, multiples_of_4));\n        \n        __m256i squared = _mm256_mullo_epi32(vec, _mm256_and(square_mask, idx));\n        __m256i cubed = _mm256_mullo_epi32(_mm256_mullo_epi32(vec, vec), _mm256_and(cube_mask, idx));\n        \n        __m256i result = _mm256_add_epi32(squared, cubed);\n        \n        sum += _mm256_reduce_add_epi32(result);\n    }\n    \n    for (; i < size; ++i) {\n        int idx = i % 8;\n        int val = lst[i];\n        \n        if (idx == 2 || idx == 3) {\n            sum += val * val;\n        } else if (idx == 4 || idx == 5) {\n            sum += val * val * val;\n        }\n    }\n    \n    return sum;\n}\n```"}
{"task_id": "SimdBench_130_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nint sum_squares_simd(const std::vector<int> & lst){\n    int sum = 0;\n    int size = lst.size();\n    int remainder = size % 8;\n    int i = 0;\n\n    __m256i indices = _mm256_setr_epi32(0, 1, 2, 3, 4, 5, 6, 7);\n    __m256i threes = _mm256_set1_epi32(3);\n    __m256i fours = _mm256_set1_epi32(4);\n    __m256i threes_mask = _mm256_cmpeq_epi32(_mm256_and_si256(indices, threes), _mm256_setzero_si256());\n    __m256i fours_mask = _mm256_cmpeq_epi32(_mm256_and_si256(indices, fours), _mm256_setzero_si256());\n\n    for (; i < size - remainder; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&lst[i]);\n        __m256i squares = _mm256_mullo_epi32(vec, vec);\n        __m256i cubes = _mm256_mullo_epi32(vec, _mm256_mullo_epi32(vec, vec));\n        __m256i result = _mm256_blendv_epi8(vec, squares, threes_mask);\n        result = _mm256_blendv_epi8(result, cubes, fours_mask);\n        sum += _mm256_reduce_add_epi32(result);\n    }\n\n    int temp[8];\n    _mm256_storeu_si256((__m256i*)temp, indices);\n    for (int j = 0; j < remainder; j++) {\n        int index = temp[j];\n        int val = lst[i + j];\n        if (index % 3 == 0) {\n            sum += val * val;\n        } else if (index % 4 == 0) {\n            sum += val * val * val;\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_130_AVX", "completion": "```\nint sum_squares_simd(const std::vector<int> & lst){\n    int sum = 0;\n    __m256i indices = _mm256_set_epi32(11, 10, 9, 8, 7, 6, 5, 4);\n    __m256i squares = _mm256_set1_epi32(2);\n    __m256i cubes = _mm256_set1_epi32(3);\n    __m256i result = _mm256_setzero_si256();\n\n    for (int i = 0; i < lst.size(); i += 8) {\n        __m256i values = _mm256_loadu_si256((__m256i*)&lst[i]);\n        __m256i mask_square = _mm256_cmpeq_epi32(_mm256_and_si256(indices, _mm256_set1_epi32(3)), _mm256_setzero_si256());\n        __m256i mask_cube = _mm256_and_si256(_mm256_cmpeq_epi32(_mm256_and_si256(indices, _mm256_set1_epi32(3)), _mm256_setzero_si256()),\n                                             _mm256_cmpeq_epi32(_mm256_and_si256(indices, _mm256_set1_epi32(4)), _mm256_setzero_si256()));\n        __m256i square_values = _mm256_and_si256(mask_square, _mm256_mullo_epi32(values, values));\n        __m256i cube_values = _mm256_and_si256(mask_cube, _mm256_mullo_epi32(_mm256_mullo_epi32(values, values), values));\n        result = _mm256_add_epi32(result, _mm256_add_epi32(square_values, cube_values));\n        indices = _mm256_add_epi32(indices, _mm256_set1_epi32(8));\n    }\n\n    alignas(32) int final_result[8];\n    _mm256_store_si256((__m256i*)final_result, result);\n    for (int i = 0; i < 8; i++) {\n        sum += final_result[i];\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_131_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nint specialFilter_simd(const std::vector<int> & nums){\n    const int size = nums.size();\n    const __m256i threshold = _mm256_set1_epi32(10);\n    const __m256i oddDigits = _mm256_set_epi32(1, 3, 5, 7, 9, 1, 3, 5);\n\n    int count = 0;\n    for (int i = 0; i < size; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&nums[i]);\n        __m256i absVec = _mm256_abs_epi32(vec);\n        \n        __m256i firstDigit = _mm256_and_si256(absVec, _mm256_set1_epi32(0xF));\n        __m256i lastDigit = _mm256_and_si256(_mm256_srli_epi32(absVec, 28), _mm256_set1_epi32(0xF));\n        \n        __m256i oddFirstDigit = _mm256_cmpeq_epi32(_mm256_and_si256(firstDigit, oddDigits), firstDigit);\n        __m256i oddLastDigit = _mm256_cmpeq_epi32(_mm256_and_si256(lastDigit, oddDigits), lastDigit);\n        \n        __m256i greaterThanThreshold = _mm256_cmpgt_epi32(vec, threshold);\n        \n        __m256i result = _mm256_and_si256(_mm256_and_si256(oddFirstDigit, oddLastDigit), greaterThanThreshold);\n        \n        count += _mm_popcnt_u32(_mm256_movemask_ps(_mm256_castsi256_ps(result)));\n    }\n    \n    return count;\n}\n```"}
{"task_id": "SimdBench_131_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nint specialFilter_simd(const std::vector<int> & nums){\n    const __m256i threshold = _mm256_set1_epi32(10);\n    const __m256i odd_digits = _mm256_set_epi8(9, 7, 5, 3, 1, 9, 7, 5, 3, 1, 9, 7, 5, 3, 1, 9, 7, 5, 3, 1, 9, 7, 5, 3, 1, 9, 7, 5, 3, 1, 9, 7, 5, 3, 1);\n    const __m256i mask = _mm256_set1_epi32(0x0000000F);\n    \n    int count = 0;\n    for (size_t i = 0; i < nums.size(); i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&nums[i]);\n        \n        __m256i abs_vec = _mm256_abs_epi32(vec);\n        __m256i first_digit = _mm256_and_si256(abs_vec, mask);\n        __m256i last_digit = _mm256_and_si256(_mm256_srli_epi32(abs_vec, 28), mask);\n        \n        __m256i odd_first_digit = _mm256_cmpeq_epi8(_mm256_and_si256(first_digit, odd_digits), odd_digits);\n        __m256i odd_last_digit = _mm256_cmpeq_epi8(_mm256_and_si256(last_digit, odd_digits), odd_digits);\n        \n        __m256i greater_than_10 = _mm256_cmpgt_epi32(vec, threshold);\n        \n        __m256i result = _mm256_and_si256(_mm256_and_si256(odd_first_digit, odd_last_digit), greater_than_10);\n        \n        count += _mm_popcnt_u32(_mm256_movemask_ps(_mm256_castsi256_ps(result)));\n    }\n    \n    return count;\n}\n```"}
{"task_id": "SimdBench_131_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nint specialFilter_simd(const std::vector<int> & nums){\n    const __m256i threshold = _mm256_set1_epi32(10);\n    const __m256i oddDigits = _mm256_set_epi32(1, 3, 5, 7, 9, 1, 3, 5);\n\n    int count = 0;\n    for (size_t i = 0; i < nums.size(); i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&nums[i]);\n        \n        __m256i absVec = _mm256_abs_epi32(vec);\n        __m256i firstDigit = _mm256_and_si256(absVec, _mm256_set1_epi32(0xF));\n        __m256i lastDigit = _mm256_and_si256(_mm256_srli_epi32(absVec, 28), _mm256_set1_epi32(0xF));\n\n        __m256i oddFirstDigit = _mm256_cmpeq_epi32(_mm256_and_si256(firstDigit, oddDigits), firstDigit);\n        __m256i oddLastDigit = _mm256_cmpeq_epi32(_mm256_and_si256(lastDigit, oddDigits), lastDigit);\n\n        __m256i greaterThanThreshold = _mm256_cmpgt_epi32(vec, threshold);\n\n        __m256i result = _mm256_and_si256(_mm256_and_si256(oddFirstDigit, oddLastDigit), greaterThanThreshold);\n\n        count += _mm_popcnt_u32(_mm256_movemask_ps(_mm256_castsi256_ps(result)));\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_131_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nint specialFilter_simd(const std::vector<int> & nums){\n    const __m256i odd_digits = _mm256_set_epi8(9, 7, 5, 3, 1, 9, 7, 5, 3, 1, 9, 7, 5, 3, 1, 9, 7, 5, 3, 1, 9, 7, 5, 3, 1, 9, 7, 5, 3, 1, 9, 7, 5, 3, 1);\n    const __m256i ten = _mm256_set1_epi8(10);\n    const __m256i zero = _mm256_setzero_si256();\n    int count = 0;\n\n    for (size_t i = 0; i < nums.size(); i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&nums[i]);\n        \n        __m256i first_digit = _mm256_and_si256(_mm256_abs_epi8(vec), _mm256_set1_epi8(15));\n        __m256i last_digit = _mm256_and_si256(_mm256_abs_epi8(vec), _mm256_set1_epi8(15));\n        last_digit = _mm256_shuffle_epi8(last_digit, odd_digits);\n        \n        __m256i cmp_gt_10 = _mm256_cmpgt_epi8(vec, ten);\n        __m256i cmp_first_odd = _mm256_cmpeq_epi8(first_digit, odd_digits);\n        __m256i cmp_last_odd = _mm256_cmpeq_epi8(last_digit, odd_digits);\n        \n        __m256i mask = _mm256_and_si256(_mm256_and_si256(cmp_gt_10, cmp_first_odd), cmp_last_odd);\n        \n        count += _mm_popcnt_u32(_mm256_movemask_epi8(mask));\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_131_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nint specialFilter_simd(const std::vector<int> & nums){\n    const __m256i threshold = _mm256_set1_epi32(10);\n    const __m256i oddDigits = _mm256_set_epi32(1, 3, 5, 7, 9, 1, 3, 5);\n\n    int count = 0;\n    for (size_t i = 0; i < nums.size(); i += 8) {\n        __m256i input = _mm256_loadu_si256((__m256i*)&nums[i]);\n        \n        __m256i absInput = _mm256_abs_epi32(input);\n        __m256i firstDigit = _mm256_and_si256(absInput, _mm256_set1_epi32(15));\n        __m256i lastDigit = _mm256_and_si256(_mm256_srli_epi32(absInput, 28), _mm256_set1_epi32(15));\n        \n        __m256i oddFirstDigit = _mm256_cmpeq_epi32(_mm256_and_si256(firstDigit, oddDigits), _mm256_setzero_si256());\n        __m256i oddLastDigit = _mm256_cmpeq_epi32(_mm256_and_si256(lastDigit, oddDigits), _mm256_setzero_si256());\n        \n        __m256i greaterThanThreshold = _mm256_cmpgt_epi32(input, threshold);\n        __m256i oddFirstLastDigits = _mm256_and_si256(oddFirstDigit, oddLastDigit);\n        \n        __m256i result = _mm256_and_si256(greaterThanThreshold, oddFirstLastDigits);\n        \n        count += _mm_popcnt_u32(_mm256_movemask_ps(_mm256_castsi256_ps(result)));\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_132_AVX", "completion": "```c\nuint64_t get_max_triples_simd(uint64_t n){\n    uint64_t count = 0;\n    __m256i sum_mod3 = _mm256_setzero_si256();\n    \n    for(uint64_t i = 1; i <= n; i += 8){\n        __m256i indices = _mm256_setr_epi64x(i, i + 1, i + 2, i + 3, i + 4, i + 5, i + 6, i + 7);\n        __m256i values = _mm256_add_epi64(_mm256_sub_epi64(_mm256_mullo_epi64(indices, indices), indices), _mm256_set1_epi64(1));\n        \n        __m256i mod3 = _mm256_and_si256(values, _mm256_set1_epi64(3));\n        sum_mod3 = _mm256_add_epi64(sum_mod3, mod3);\n        \n        if(i >= 3){\n            __m256i valid = _mm256_cmpeq_epi64(sum_mod3, _mm256_setzero_si256());\n            count += _mm_popcnt_u64(_mm256_movemask_pd((__m256d)valid));\n        }\n    }\n    \n    return count;\n}\n```"}
{"task_id": "SimdBench_132_AVX", "completion": "```cpp\nuint64_t get_max_triples_simd(uint64_t n){\n    uint64_t count = 0;\n    __m256i sum_mod3 = _mm256_setzero_si256();\n    for(uint64_t i = 0; i < n; i += 8){\n        __m256i indices = _mm256_setr_epi64x(i+1, i+2, i+3, i+4, i+5, i+6, i+7, i+8);\n        __m256i values = _mm256_sub_epi64(_mm256_mullo_epi64(indices, indices), indices);\n        __m256i mod3 = _mm256_and_si256(values, _mm256_set1_epi64x(3));\n        sum_mod3 = _mm256_add_epi64(sum_mod3, mod3);\n    }\n    uint64_t sum_mod3_arr[4];\n    _mm256_storeu_si256((__m256i*)sum_mod3_arr, sum_mod3);\n    for(int i = 0; i < 4; i++){\n        count += _mm_popcnt_u64(sum_mod3_arr[i]);\n    }\n    return count;\n}\n```"}
{"task_id": "SimdBench_132_AVX", "completion": "```\nuint64_t get_max_triples_simd(uint64_t n){\n    uint64_t count = 0;\n    __m256i sum_mod3 = _mm256_set1_epi64x(0);\n    \n    for (uint64_t i = 1; i <= n; i += 8) {\n        __m256i indices = _mm256_setr_epi64x(i, i + 1, i + 2, i + 3, i + 4, i + 5, i + 6, i + 7);\n        __m256i values = _mm256_sub_epi64(_mm256_add_epi64(_mm256_mullo_epi64(indices, indices), _mm256_sub_epi64(indices, _mm256_set1_epi64x(1))), _mm256_set1_epi64x(1));\n        \n        __m256i mod3 = _mm256_and_si256(values, _mm256_set1_epi64x(3));\n        sum_mod3 = _mm256_add_epi64(sum_mod3, mod3);\n        \n        if (i >= 3) {\n            __m256i valid = _mm256_cmpeq_epi64(sum_mod3, _mm256_setzero_si256());\n            count += _mm_popcnt_u64(_mm256_movemask_pd((__m256d)valid));\n        }\n    }\n    \n    return count;\n}\n```"}
{"task_id": "SimdBench_132_AVX", "completion": "```c\nuint64_t get_max_triples_simd(uint64_t n){\n    uint64_t count = 0;\n    __m256i sum_mod3 = _mm256_setzero_si256();\n    \n    for (uint64_t i = 0; i < n; i += 8) {\n        __m256i indices = _mm256_setr_epi64x(i+1, i+2, i+3, i+4, i+5, i+6, i+7, i+8);\n        __m256i values = _mm256_sub_epi64(_mm256_mullo_epi64(indices, indices), indices);\n        __m256i mod3 = _mm256_and_si256(values, _mm256_set1_epi64x(3));\n        sum_mod3 = _mm256_add_epi64(sum_mod3, mod3);\n        \n        if (i >= 2) {\n            __m256i valid = _mm256_cmpeq_epi64(sum_mod3, _mm256_setzero_si256());\n            count += _mm256_popcnt_u64(_mm256_movemask_pd((__m256d)valid));\n        }\n    }\n    \n    return count;\n}\n```"}
{"task_id": "SimdBench_132_AVX", "completion": "```c\nuint64_t get_max_triples_simd(uint64_t n){\n    uint64_t count = 0;\n    __m256i sum_mod3 = _mm256_setzero_si256();\n    \n    for(uint64_t i = 0; i < n; i += 8){\n        __m256i indices = _mm256_setr_epi64x(i+1, i+2, i+3, i+4, i+5, i+6, i+7, i+8);\n        __m256i values = _mm256_sub_epi64(_mm256_mullo_epi64(indices, indices), indices);\n        __m256i mod3 = _mm256_and_si256(values, _mm256_set1_epi64x(3));\n        sum_mod3 = _mm256_add_epi64(sum_mod3, mod3);\n    }\n    \n    uint64_t sum_mod3_arr[4];\n    _mm256_storeu_si256((__m256i*)sum_mod3_arr, sum_mod3);\n    \n    for(int i = 0; i < 4; i++){\n        count += _mm_popcnt_u64(sum_mod3_arr[i]);\n    }\n    \n    return count;\n}\n```"}
{"task_id": "SimdBench_133_AVX", "completion": "```c\n#include <immintrin.h>\n#include <x86intrin.h>\n\nint x_or_y_simd(int n, int x, int y){\n    int result;\n    __m256i prime_mask = _mm256_set1_epi32(1);\n    for(int i = 2; i*i <= n; i++){\n        if(n % i == 0){\n            prime_mask = _mm256_setzero_si256();\n            break;\n        }\n    }\n    if(n == 1)\n        prime_mask = _mm256_setzero_si256();\n    \n    __m256i x_vec = _mm256_set1_epi32(x);\n    __m256i y_vec = _mm256_set1_epi32(y);\n    \n    __m256i result_vec = _mm256_blendv_epi8(y_vec, x_vec, prime_mask);\n    \n    _mm256_storeu_si256((__m256i*)&result, result_vec);\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_133_AVX", "completion": "```c\n#include <immintrin.h>\n#include <x86intrin.h>\n\nint x_or_y_simd(int n, int x, int y){\n    int prime = 1;\n    for (int i = 2; i * i <= n; i++) {\n        if (n % i == 0) {\n            prime = 0;\n            break;\n        }\n    }\n    \n    __m256i result = _mm256_set1_epi32(prime ? x : y);\n    return _mm256_extract_epi32(result, 0);\n}\n```"}
{"task_id": "SimdBench_133_AVX", "completion": "```c\n#include <immintrin.h>\n#include <x86intrin.h>\n\nint x_or_y_simd(int n, int x, int y){\n    int prime = 1;\n    for (int i = 2; i * i <= n; i++) {\n        if (n % i == 0) {\n            prime = 0;\n            break;\n        }\n    }\n    \n    __m256i result = _mm256_set1_epi32(prime ? x : y);\n    return _mm256_extract_epi32(result, 0);\n}\n```"}
{"task_id": "SimdBench_133_AVX", "completion": "```c\n#include <immintrin.h>\n#include <x86intrin.h>\n\nint x_or_y_simd(int n, int x, int y){\n    int result;\n    __m256i primes = _mm256_setr_epi32(2, 3, 5, 7, 11, 13, 17, 19);\n    __m256i mask = _mm256_set1_epi32(n);\n    __m256i cmp = _mm256_cmpeq_epi32(primes, mask);\n    int cmp_mask = _mm256_movemask_ps((__m256)cmp);\n    \n    if (cmp_mask == 0) {\n        result = y;\n    } else {\n        result = x;\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_133_AVX", "completion": "```c\n#include <immintrin.h>\n#include <x86intrin.h>\n\nint x_or_y_simd(int n, int x, int y){\n    int result;\n    __m256i prime_mask = _mm256_set1_epi32(1);\n    for(int i = 2; i*i <= n; i++){\n        if(n % i == 0){\n            prime_mask = _mm256_setzero_si256();\n            break;\n        }\n    }\n    if(n <= 1){\n        prime_mask = _mm256_setzero_si256();\n    }\n    __m256i x_vec = _mm256_set1_epi32(x);\n    __m256i y_vec = _mm256_set1_epi32(y);\n    __m256i result_vec = _mm256_blendv_epi8(y_vec, x_vec, prime_mask);\n    _mm256_storeu_si256((__m256i*)&result, result_vec);\n    return result;\n}\n```"}
{"task_id": "SimdBench_134_AVX", "completion": "```cpp\nuint64_t double_the_difference_simd(const std::vector<float> & lst){\n    __m256i mask_odd = _mm256_set1_epi32(0x55555555); // Mask to extract odd numbers\n    __m256i mask_negative = _mm256_set1_epi32(0x80000000); // Mask to extract negative numbers\n    __m256i mask_int = _mm256_set1_epi32(0x7FFFFFFF); // Mask to extract integers\n\n    __m256 sum = _mm256_setzero_ps();\n    \n    for (size_t i = 0; i < lst.size(); i += 8) {\n        __m256 values = _mm256_loadu_ps(&lst[i]);\n        \n        // Check for odd numbers\n        __m256i odd_numbers = _mm256_and_si256(_mm256_castps_si256(values), mask_odd);\n        \n        // Check for negative numbers\n        __m256i negative_numbers = _mm256_and_si256(_mm256_castps_si256(values), mask_negative);\n        \n        // Check for integers\n        __m256i integers = _mm256_and_si256(_mm256_castps_si256(values), mask_int);\n        \n        // Check if the number is odd, not negative, and an integer\n        __m256i valid_numbers = _mm256_and_si256(_mm256_and_si256(odd_numbers, _mm256_cmpeq_epi32(negative_numbers, _mm256_setzero_si256())), _mm256_cmpeq_epi32(integers, _mm256_setzero_si256()));\n        \n        // Square the valid numbers\n        __m256 squared_valid_numbers = _mm256_mul_ps(_mm256_castsi256_ps(valid_numbers), _mm256_castsi256_ps(valid_numbers));\n        \n        // Add the squared valid numbers to the sum\n        sum = _mm256_add_ps(sum, squared_valid_numbers);\n    }\n    \n    // Horizontal add to get the final sum\n    __m128 sum_high = _mm256_extractf128_ps(sum, 1);\n    __m128 sum_low = _mm256_castps256_ps128(sum);\n    __m128 final_sum = _mm_add_ps(sum_low, sum_high);\n    \n    // Convert the final sum to uint64_t\n    return _mm_cvtsi128_si64(_mm_castps_si128(final_sum));\n}\n```"}
{"task_id": "SimdBench_134_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nuint64_t double_the_difference_simd(const std::vector<float> & lst){\n    __m256i sum = _mm256_setzero_si256();\n    __m256i mask = _mm256_set1_epi32(0x80000001); // Mask for odd positive integers\n\n    for (size_t i = 0; i < lst.size(); i += 8) {\n        __m256i data = _mm256_loadu_si256((__m256i*)&lst[i]);\n        __m256i abs_data = _mm256_castps_si256(_mm256_and_ps(_mm256_castsi256_ps(data), _mm256_castsi256_ps(_mm256_set1_epi32(0x7FFFFFFF))));\n        __m256i odd_data = _mm256_and_si256(abs_data, mask);\n        __m256i square_data = _mm256_mullo_epi32(odd_data, odd_data);\n        sum = _mm256_add_epi32(sum, square_data);\n    }\n\n    alignas(32) int32_t result[8];\n    _mm256_store_si256((__m256i*)result, sum);\n\n    uint64_t final_sum = 0;\n    for (int i = 0; i < 8; ++i) {\n        final_sum += result[i];\n    }\n\n    return final_sum;\n}\n```"}
{"task_id": "SimdBench_134_AVX", "completion": "```cpp\nuint64_t double_the_difference_simd(const std::vector<float> & lst){\n    __m256i sum = _mm256_setzero_si256();\n    __m256i mask = _mm256_set1_epi32(0x80000000); // Mask to check if number is negative\n    __m256i odd_mask = _mm256_set1_epi32(0x1); // Mask to check if number is odd\n\n    for (size_t i = 0; i < lst.size(); i += 8) {\n        __m256i input = _mm256_castps_si256(_mm256_loadu_ps(&lst[i]));\n\n        // Check if number is negative or not an integer\n        __m256i is_negative = _mm256_cmpgt_epi32(_mm256_and_si256(input, mask), _mm256_setzero_si256());\n        __m256i is_integer = _mm256_cmpeq_epi32(_mm256_cvttps_epi32(_mm256_castsi256_ps(input)), input);\n        __m256i valid_mask = _mm256_andnot_si256(_mm256_or_si256(is_negative, is_integer), _mm256_set1_epi32(0xFFFFFFFF));\n\n        // Check if number is odd\n        __m256i is_odd = _mm256_and_si256(_mm256_and_si256(input, odd_mask), valid_mask);\n\n        // Square the odd numbers\n        __m256i squared_odd = _mm256_mullo_epi32(is_odd, is_odd);\n\n        // Add the squared odd numbers to the sum\n        sum = _mm256_add_epi32(sum, squared_odd);\n    }\n\n    alignas(32) int32_t result[8];\n    _mm256_store_si256((__m256i*)result, sum);\n\n    return result[0] + result[1] + result[2] + result[3] + result[4] + result[5] + result[6] + result[7];\n}\n```"}
{"task_id": "SimdBench_134_AVX", "completion": "```cpp\nuint64_t double_the_difference_simd(const std::vector<float> & lst){\n    __m256i sum = _mm256_setzero_si256();\n    __m256i mask = _mm256_set1_epi32(0x80000000); // Mask to check if number is negative\n    __m256i odd_mask = _mm256_set1_epi32(0x55555555); // Mask to check if number is odd\n\n    for (size_t i = 0; i < lst.size(); i += 8) {\n        __m256 values = _mm256_loadu_ps(&lst[i]);\n        \n        // Check if numbers are integers (by checking if their difference with rounded values is 0)\n        __m256 rounded_values = _mm256_round_ps(values, _MM_FROUND_TO_NEAREST_INT);\n        __m256 diff = _mm256_sub_ps(values, rounded_values);\n        __m256i int_mask = _mm256_castps_si256(_mm256_cmpeq_ps(diff, _mm256_setzero_ps()));\n\n        // Check if numbers are odd\n        __m256i odd_values = _mm256_and_si256(_mm256_castps_si256(values), odd_mask);\n\n        // Check if numbers are positive\n        __m256i positive_values = _mm256_cmpgt_epi32(_mm256_castps_si256(values), _mm256_setzero_si256());\n\n        // Check if numbers are odd, positive, and integers\n        __m256i valid_values = _mm256_and_si256(odd_values, int_mask);\n        valid_values = _mm256_and_si256(valid_values, positive_values);\n\n        // Square the valid values\n        __m256i squared_values = _mm256_mullo_epi32(valid_values, valid_values);\n\n        // Add the squared values to the sum\n        sum = _mm256_add_epi32(sum, squared_values);\n    }\n\n    // Horizontal sum of the 8 values in the sum vector\n    __m128i sum_lo = _mm256_extractf128_si256(sum, 0);\n    __m128i sum_hi = _mm256_extractf128_si256(sum, 1);\n    __m128i sum_final = _mm_add_epi32(sum_lo, sum_hi);\n    sum_final = _mm_hadd_epi32(sum_final, sum_final);\n    sum_final = _mm_hadd_epi32(sum_final, sum_final);\n\n    return _mm_cvtsi128_si64(sum_final);\n}\n```"}
{"task_id": "SimdBench_134_AVX", "completion": "```\nuint64_t double_the_difference_simd(const std::vector<float> & lst){\n    __m256i odd_mask = _mm256_set1_epi32(0x55555555); // Mask to extract odd numbers\n    __m256i zero = _mm256_setzero_si256(); // Zero vector\n    __m256 sum = _mm256_setzero_ps(); // Initialize sum vector\n\n    for (size_t i = 0; i < lst.size(); i += 8) {\n        __m256 values = _mm256_loadu_ps(&lst[i]); // Load 8 float values\n        __m256i int_values = _mm256_cvtps_epi32(values); // Convert float to int\n        __m256i abs_values = _mm256_abs_epi32(int_values); // Get absolute values\n        __m256i odd_values = _mm256_and_si256(abs_values, odd_mask); // Extract odd numbers\n        __m256i non_negative_mask = _mm256_cmpgt_epi32(int_values, zero); // Mask for non-negative numbers\n        __m256i valid_values_mask = _mm256_and_si256(odd_values, non_negative_mask); // Mask for valid numbers\n        __m256 valid_values = _mm256_cvtepi32_ps(valid_values_mask); // Convert valid numbers to float\n        sum = _mm256_add_ps(sum, _mm256_mul_ps(valid_values, valid_values)); // Add squares of valid numbers to sum\n    }\n\n    alignas(32) float result[8];\n    _mm256_store_ps(result, sum); // Store the sum vector\n\n    uint64_t final_sum = 0;\n    for (int i = 0; i < 8; i++) {\n        final_sum += static_cast<uint64_t>(result[i]);\n    }\n\n    return final_sum;\n}\n```"}
{"task_id": "SimdBench_135_AVX", "completion": "```\nstd::vector<int> compare_simd(const std::vector<int>& game, const std::vector<int>& guess){\n    std::vector<int> result(game.size());\n    const int size = game.size();\n    const int simdSize = 8;\n    \n    for (int i = 0; i < size; i += simdSize) {\n        __m256i gameVec = _mm256_loadu_si256((__m256i*)&game[i]);\n        __m256i guessVec = _mm256_loadu_si256((__m256i*)&guess[i]);\n        \n        __m256i diff = _mm256_abs_epi32(_mm256_sub_epi32(gameVec, guessVec));\n        \n        _mm256_storeu_si256((__m256i*)&result[i], diff);\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_135_AVX", "completion": "```\nstd::vector<int> compare_simd(const std::vector<int>& game, const std::vector<int>& guess){\n    int size = game.size();\n    std::vector<int> result(size);\n\n    for (int i = 0; i < size; i += 8) {\n        __m256i game_vec = _mm256_loadu_si256((__m256i*)&game[i]);\n        __m256i guess_vec = _mm256_loadu_si256((__m256i*)&guess[i]);\n\n        __m256i diff = _mm256_abs_epi32(_mm256_sub_epi32(game_vec, guess_vec));\n\n        _mm256_storeu_si256((__m256i*)&result[i], diff);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_135_AVX", "completion": "```\nstd::vector<int> compare_simd(const std::vector<int>& game, const std::vector<int>& guess){\n    std::vector<int> result(game.size());\n    const int size = game.size();\n    const int simdSize = 8;\n    \n    for (int i = 0; i < size; i += simdSize) {\n        __m256i gameVec = _mm256_loadu_si256((__m256i*)&game[i]);\n        __m256i guessVec = _mm256_loadu_si256((__m256i*)&guess[i]);\n        \n        __m256i diff = _mm256_abs_epi32(_mm256_sub_epi32(gameVec, guessVec));\n        \n        _mm256_storeu_si256((__m256i*)&result[i], diff);\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_135_AVX", "completion": "```\nstd::vector<int> compare_simd(const std::vector<int>& game, const std::vector<int>& guess){\n    const int n = game.size();\n    const int simd_size = 8;\n    std::vector<int> result(n);\n\n    for (int i = 0; i < n; i += simd_size) {\n        __m256i game_vec = _mm256_loadu_si256((__m256i*)&game[i]);\n        __m256i guess_vec = _mm256_loadu_si256((__m256i*)&guess[i]);\n        __m256i diff = _mm256_abs_epi32(_mm256_sub_epi32(game_vec, guess_vec));\n        _mm256_storeu_si256((__m256i*)&result[i], diff);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_135_AVX", "completion": "```\nstd::vector<int> compare_simd(const std::vector<int>& game, const std::vector<int>& guess){\n    std::vector<int> result(game.size());\n    const int vecSize = 8;\n    int numVecs = game.size() / vecSize;\n    \n    for (int i = 0; i < numVecs; ++i) {\n        __m256i gameVec = _mm256_loadu_si256((__m256i*)&game[i * vecSize]);\n        __m256i guessVec = _mm256_loadu_si256((__m256i*)&guess[i * vecSize]);\n        \n        __m256i diff = _mm256_abs_epi32(_mm256_sub_epi32(gameVec, guessVec));\n        \n        _mm256_storeu_si256((__m256i*)&result[i * vecSize], diff);\n    }\n    \n    for (int i = numVecs * vecSize; i < game.size(); ++i) {\n        result[i] = std::abs(game[i] - guess[i]);\n    }\n    \n    return result;\n}\n```"}

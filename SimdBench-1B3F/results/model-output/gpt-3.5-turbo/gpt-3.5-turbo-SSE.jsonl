{"task_id": "SimdBench_0_SSE", "completion": "```\nvoid conditional_move_simd(const int64_t *src, int64_t *dst, const bool *mask, size_t length) {\n    for (size_t i = 0; i < length; i += 2) {\n        __m128i src_data = _mm_loadu_si128((__m128i*)&src[i]);\n        __m128i mask_data = _mm_loadu_si128((__m128i*)&mask[i]);\n        __m128i result = _mm_and_si128(src_data, _mm_cmpeq_epi8(mask_data, _mm_set1_epi8(1)));\n        _mm_storeu_si128((__m128i*)&dst[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_0_SSE", "completion": "```c\nvoid conditional_move_simd(const int64_t *src, int64_t *dst, const bool *mask, size_t length) {\n    for (size_t i = 0; i < length; i += 2) {\n        __m128i src_data = _mm_loadu_si128((__m128i*)(src + i));\n        __m128i mask_data = _mm_loadu_si128((__m128i*)(mask + i));\n        \n        __m128i result = _mm_and_si128(src_data, _mm_cmpeq_epi8(mask_data, _mm_set1_epi8(-1)));\n        \n        _mm_storeu_si128((__m128i*)(dst + i), result);\n    }\n}\n```  "}
{"task_id": "SimdBench_0_SSE", "completion": "```\nvoid conditional_move_simd(const int64_t *src, int64_t *dst, const bool *mask, size_t length) {\n    for (size_t i = 0; i < length; i += 2) {\n        __m128i src_val = _mm_loadu_si128((__m128i*)(src + i));\n        __m128i mask_val = _mm_loadu_si128((__m128i*)(mask + i));\n        __m128i result = _mm_and_si128(src_val, mask_val);\n        _mm_storeu_si128((__m128i*)(dst + i), result);\n    }\n}\n```  "}
{"task_id": "SimdBench_0_SSE", "completion": "```\nvoid conditional_move_simd(const int64_t *src, int64_t *dst, const bool *mask, size_t length) {\n    for (size_t i = 0; i < length; i += 2) {\n        __m128i src_vec = _mm_loadu_si128((__m128i*)(src + i));\n        __m128i mask_vec = _mm_loadu_si128((__m128i*)(mask + i));\n        \n        __m128i result = _mm_and_si128(src_vec, mask_vec);\n        \n        _mm_storeu_si128((__m128i*)(dst + i), result);\n    }\n}\n```"}
{"task_id": "SimdBench_0_SSE", "completion": "```\nvoid conditional_move_simd(const int64_t *src, int64_t *dst, const bool *mask, size_t length) {\n    for (size_t i = 0; i < length; i += 2) {\n        __m128i src_vec = _mm_loadu_si128((__m128i*)(src + i));\n        __m128i mask_vec = _mm_loadu_si128((__m128i*)(mask + i));\n        __m128i result = _mm_and_si128(src_vec, _mm_cmpeq_epi8(mask_vec, _mm_set1_epi8(1)));\n        _mm_storeu_si128((__m128i*)(dst + i), result);\n    }\n}\n```"}
{"task_id": "SimdBench_1_SSE", "completion": "```c\nvoid load_modify_store_simd(const int *src, int *dst, int scale, size_t length) {\n    __m128i scale_vec = _mm_set1_epi32(scale);\n    __m128i shift_right = _mm_set1_epi32(3);\n    __m128i shift_left = _mm_set1_epi32(-3);\n\n    for (size_t i = 0; i < length; i += 4) {\n        __m128i src_vec = _mm_loadu_si128((__m128i*)(src + i));\n\n        __m128i tmp1 = _mm_sra_epi32(_mm_mullo_epi32(src_vec, scale_vec), shift_right);\n        __m128i tmp2 = _mm_sll_epi32(_mm_mullo_epi32(src_vec, scale_vec), shift_left);\n\n        __m128i result = _mm_cvtps_epi32(_mm_div_ps(_mm_cvtepi32_ps(_mm_add_epi32(_mm_mullo_epi32(src_vec, scale_vec), _mm_mullo_epi32(tmp1, tmp2))), _mm_set1_ps(7.0f)));\n\n        _mm_storeu_si128((__m128i*)(dst + i), result);\n    }\n}\n```"}
{"task_id": "SimdBench_1_SSE", "completion": "```c\nvoid load_modify_store_simd(const int *src, int *dst, int scale, size_t length) {\n    __m128i scale_vec = _mm_set1_epi32(scale);\n    __m128i shift_right = _mm_set1_epi32(3);\n    __m128i shift_left = _mm_set1_epi32(-3);\n    __m128i div_by_7 = _mm_set1_epi32(7);\n\n    for (size_t i = 0; i < length; i += 4) {\n        __m128i src_vec = _mm_loadu_si128((__m128i*)(src + i));\n\n        __m128i tmp1 = _mm_sra_epi32(_mm_mullo_epi32(src_vec, scale_vec), shift_right);\n        __m128i tmp2 = _mm_sll_epi32(_mm_mullo_epi32(src_vec, scale_vec), shift_left);\n\n        __m128i result = _mm_cvtps_epi32(_mm_div_ps(_mm_cvtepi32_ps(_mm_add_epi32(_mm_mullo_epi32(src_vec, scale_vec), _mm_mullo_epi32(tmp1, tmp2))), _mm_cvtepi32_ps(div_by_7)));\n\n        _mm_storeu_si128((__m128i*)(dst + i), result);\n    }\n}\n```"}
{"task_id": "SimdBench_1_SSE", "completion": "```c\nvoid load_modify_store_simd(const int *src, int *dst, int scale, size_t length) {\n    __m128i scale_vec = _mm_set1_epi32(scale);\n    __m128i shift_right = _mm_set1_epi32(3);\n    __m128i shift_left = _mm_set1_epi32(-3);\n    __m128i div_by_7 = _mm_set1_epi32(7);\n\n    for (size_t i = 0; i < length; i += 4) {\n        __m128i src_vec = _mm_loadu_si128((__m128i*)(src + i));\n\n        __m128i tmp1 = _mm_srai_epi32(_mm_mullo_epi32(src_vec, scale_vec), shift_right);\n        __m128i tmp2 = _mm_slli_epi32(_mm_mullo_epi32(src_vec, scale_vec), shift_left);\n\n        __m128i result = _mm_cvtps_epi32(_mm_div_ps(_mm_cvtepi32_ps(_mm_add_epi32(_mm_mullo_epi32(src_vec, scale_vec), _mm_mullo_epi32(tmp1, tmp2))), _mm_cvtepi32_ps(div_by_7)));\n\n        _mm_storeu_si128((__m128i*)(dst + i), result);\n    }\n}\n```"}
{"task_id": "SimdBench_1_SSE", "completion": "```c\nvoid load_modify_store_simd(const int *src, int *dst, int scale, size_t length) {\n    __m128i scale_vec = _mm_set1_epi32(scale);\n    __m128i shift_right = _mm_set1_epi32(3);\n    __m128i shift_left = _mm_set1_epi32(-3);\n\n    for (size_t i = 0; i < length; i += 4) {\n        __m128i src_vec = _mm_loadu_si128((__m128i*)(src + i));\n\n        __m128i tmp1 = _mm_sra_epi32(_mm_mullo_epi32(src_vec, scale_vec), shift_right);\n        __m128i tmp2 = _mm_sll_epi32(_mm_mullo_epi32(src_vec, scale_vec), shift_left);\n\n        __m128i result = _mm_cvtps_epi32(_mm_div_ps(_mm_cvtepi32_ps(_mm_add_epi32(_mm_mullo_epi32(src_vec, scale_vec), _mm_mullo_epi32(tmp1, tmp2))), _mm_set1_ps(7.0f)));\n\n        _mm_storeu_si128((__m128i*)(dst + i), result);\n    }\n}\n```"}
{"task_id": "SimdBench_1_SSE", "completion": "```c\nvoid load_modify_store_simd(const int *src, int *dst, int scale, size_t length) {\n    __m128i scale_vec = _mm_set1_epi32(scale);\n    __m128i shift_right = _mm_set1_epi32(3);\n    __m128i shift_left = _mm_set1_epi32(-3);\n\n    for (size_t i = 0; i < length; i += 4) {\n        __m128i src_vec = _mm_loadu_si128((__m128i*)(src + i));\n\n        __m128i tmp1 = _mm_sra_epi32(_mm_mullo_epi32(src_vec, scale_vec), shift_right);\n        __m128i tmp2 = _mm_sll_epi32(_mm_mullo_epi32(src_vec, scale_vec), shift_left);\n\n        __m128i result = _mm_cvtps_epi32(_mm_div_ps(_mm_cvtepi32_ps(_mm_add_epi32(_mm_mullo_epi32(src_vec, scale_vec), _mm_mullo_epi32(tmp1, tmp2))), _mm_set1_ps(7.0f)));\n\n        _mm_storeu_si128((__m128i*)(dst + i), result);\n    }\n}\n```"}
{"task_id": "SimdBench_2_SSE", "completion": "```c\nvoid strided_load_store_simd(const double *src, double *dst, size_t rows, size_t cols, size_t stride) {\n    for (size_t r = 0; r < rows; ++r) {\n        __m128d val = _mm_load_sd(&src[r * cols + stride]);\n        _mm_store_sd(&dst[r], val);\n    }\n}\n```"}
{"task_id": "SimdBench_2_SSE", "completion": "```c\nvoid strided_load_store_simd(const double *src, double *dst, size_t rows, size_t cols, size_t stride) {\n    for (size_t r = 0; r < rows; ++r) {\n        __m128d val = _mm_load_sd(&src[r * cols + stride]);\n        _mm_store_sd(&dst[r], val);\n    }\n}\n```"}
{"task_id": "SimdBench_2_SSE", "completion": "```\nvoid strided_load_store_simd(const double *src, double *dst, size_t rows, size_t cols, size_t stride) {\n    for (size_t r = 0; r < rows; ++r) {\n        __m128d val = _mm_load_sd(&src[r * cols + stride]);\n        _mm_store_sd(&dst[r], val);\n    }\n}\n```"}
{"task_id": "SimdBench_2_SSE", "completion": "```\nvoid strided_load_store_simd(const double *src, double *dst, size_t rows, size_t cols, size_t stride) {\n    for (size_t r = 0; r < rows; ++r) {\n        __m128d val = _mm_load_sd(&src[r * cols + stride]);\n        _mm_store_sd(&dst[r], val);\n    }\n}\n```"}
{"task_id": "SimdBench_2_SSE", "completion": "```\nvoid strided_load_store_simd(const double *src, double *dst, size_t rows, size_t cols, size_t stride) {\n    for (size_t r = 0; r < rows; ++r) {\n        __m128d val = _mm_load_sd(&src[r * cols + stride]);\n        _mm_store_sd(&dst[r], val);\n    }\n}\n```"}
{"task_id": "SimdBench_3_SSE", "completion": "```c\nvoid indexed_access_simd(const float *src, const int *indices, float *dst, size_t length) {\n    for (size_t i = 0; i < length; i += 4) {\n        __m128i index = _mm_loadu_si128((__m128i*)(indices + i));\n        __m128 values = _mm_i32gather_ps(src, index, 4);\n        _mm_storeu_ps(dst + i, values);\n    }\n}\n```"}
{"task_id": "SimdBench_3_SSE", "completion": "```c\nvoid indexed_access_simd(const float *src, const int *indices, float *dst, size_t length) {\n    for (size_t i = 0; i < length; i += 4) {\n        __m128i index = _mm_loadu_si128((__m128i*)(indices + i));\n        __m128 src_values = _mm_i32gather_ps(src, index, 4);\n        _mm_storeu_ps(dst + i, src_values);\n    }\n}\n```"}
{"task_id": "SimdBench_3_SSE", "completion": "```c\nvoid indexed_access_simd(const float *src, const int *indices, float *dst, size_t length) {\n    for (size_t i = 0; i < length; i += 4) {\n        __m128i index = _mm_loadu_si128((__m128i*)(indices + i));\n        __m128 src_values = _mm_i32gather_ps(src, index, 4);\n        _mm_storeu_ps(dst + i, src_values);\n    }\n}\n```  "}
{"task_id": "SimdBench_3_SSE", "completion": "```c\nvoid indexed_access_simd(const float *src, const int *indices, float *dst, size_t length) {\n    for (size_t i = 0; i < length; i += 4) {\n        __m128i index = _mm_loadu_si128((__m128i*)&indices[i]);\n        __m128 src_values = _mm_i32gather_ps(src, index, 4);\n        _mm_storeu_ps(&dst[i], src_values);\n        \n        __m128i scatter_index = _mm_loadu_si128((__m128i*)&indices[i]);\n        __m128 scatter_values = _mm_loadu_ps(&src[i]);\n        _mm_i32scatter_ps(dst, scatter_index, scatter_values, 4);\n    }\n}\n```  "}
{"task_id": "SimdBench_3_SSE", "completion": "```c\nvoid indexed_access_simd(const float *src, const int *indices, float *dst, size_t length) {\n    for (size_t i = 0; i < length; i += 4) {\n        __m128i index = _mm_loadu_si128((__m128i*)(indices + i));\n        __m128 src_values = _mm_i32gather_ps(src, index, 4);\n        _mm_storeu_ps(dst + i, src_values);\n    }\n}\n```"}
{"task_id": "SimdBench_4_SSE", "completion": "```\nvoid range_reverse_simd(int16_t *arr, uint64_t start, uint64_t end) {\n    __m128i tmp;\n    int16_t *ptr1 = arr + start;\n    int16_t *ptr2 = arr + end;\n    \n    while (ptr1 < ptr2) {\n        tmp = _mm_loadu_si128((__m128i*)ptr1);\n        _mm_storeu_si128((__m128i*)ptr1, _mm_loadu_si128((__m128i*)ptr2));\n        _mm_storeu_si128((__m128i*)ptr2, tmp);\n        \n        ptr1 += 8;\n        ptr2 -= 8;\n    }\n}\n```"}
{"task_id": "SimdBench_4_SSE", "completion": "```c\nvoid range_reverse_simd(int16_t *arr, uint64_t start, uint64_t end) {\n    __m128i tmp;\n    int16_t *ptr_start = arr + start;\n    int16_t *ptr_end = arr + end;\n    \n    while (ptr_start < ptr_end) {\n        tmp = _mm_loadu_si128((__m128i*)ptr_start);\n        __m128i rev_tmp = _mm_shufflelo_epi16(tmp, _MM_SHUFFLE(0, 1, 2, 3));\n        rev_tmp = _mm_shufflehi_epi16(rev_tmp, _MM_SHUFFLE(0, 1, 2, 3));\n        _mm_storeu_si128((__m128i*)ptr_start, rev_tmp);\n        \n        ptr_start += 8;\n    }\n}\n```  "}
{"task_id": "SimdBench_4_SSE", "completion": "```\nvoid range_reverse_simd(int16_t *arr, uint64_t start, uint64_t end) {\n    __m128i tmp;\n    int16_t *ptr1 = arr + start;\n    int16_t *ptr2 = arr + end;\n    \n    while (ptr1 < ptr2) {\n        tmp = _mm_loadu_si128((__m128i*)ptr1);\n        _mm_storeu_si128((__m128i*)ptr1, _mm_loadu_si128((__m128i*)ptr2));\n        _mm_storeu_si128((__m128i*)ptr2, tmp);\n        \n        ptr1 += 8;\n        ptr2 -= 8;\n    }\n}\n```"}
{"task_id": "SimdBench_4_SSE", "completion": "```c\nvoid range_reverse_simd(int16_t *arr, uint64_t start, uint64_t end) {\n    __m128i tmp;\n    int16_t *ptr1 = arr + start;\n    int16_t *ptr2 = arr + end;\n\n    while (ptr1 < ptr2) {\n        tmp = _mm_loadu_si128((__m128i*)ptr1);\n        _mm_storeu_si128((__m128i*)ptr1, _mm_loadu_si128((__m128i*)ptr2));\n        _mm_storeu_si128((__m128i*)ptr2, tmp);\n        ptr1++;\n        ptr2--;\n    }\n}\n```  "}
{"task_id": "SimdBench_4_SSE", "completion": "```c\nvoid range_reverse_simd(int16_t *arr, uint64_t start, uint64_t end) {\n    __m128i tmp;\n    int16_t *ptr1 = arr + start;\n    int16_t *ptr2 = arr + end;\n\n    while (ptr1 < ptr2) {\n        tmp = _mm_loadu_si128((__m128i*)ptr1);\n        _mm_storeu_si128((__m128i*)ptr1, _mm_loadu_si128((__m128i*)ptr2));\n        _mm_storeu_si128((__m128i*)ptr2, tmp);\n        ptr1 += 8;\n        ptr2 -= 8;\n    }\n}\n```"}
{"task_id": "SimdBench_5_SSE", "completion": "```c\nvoid extract_tensor_slice_simd(const uint8_t *tensor, uint8_t *slice, size_t dim1, size_t dim2, size_t dim3, size_t slice_idx) {\n    size_t slice_size = dim1 * dim2;\n    size_t offset = slice_idx * slice_size;\n\n    for (size_t i = 0; i < dim1; ++i) {\n        for (size_t j = 0; j < dim2; j += 16) {\n            __m128i data = _mm_loadu_si128((__m128i*)(tensor + offset + i * dim2 + j));\n            _mm_storeu_si128((__m128i*)(slice + i * dim2 + j), data);\n        }\n    }\n}\n```  "}
{"task_id": "SimdBench_5_SSE", "completion": "```c\nvoid extract_tensor_slice_simd(const uint8_t *tensor, uint8_t *slice, size_t dim1, size_t dim2, size_t dim3, size_t slice_idx) {\n    size_t slice_size = dim1 * dim2;\n    size_t start_idx = slice_idx * slice_size;\n\n    for (size_t i = 0; i < dim1; i++) {\n        for (size_t j = 0; j < dim2; j += 16) {\n            __m128i data = _mm_loadu_si128((__m128i*)(tensor + start_idx + i * dim2 + j));\n            _mm_storeu_si128((__m128i*)(slice + i * dim2 + j), data);\n        }\n    }\n}\n```  "}
{"task_id": "SimdBench_5_SSE", "completion": "```c\nvoid extract_tensor_slice_simd(const uint8_t *tensor, uint8_t *slice, size_t dim1, size_t dim2, size_t dim3, size_t slice_idx) {\n    size_t slice_size = dim1 * dim2;\n    size_t start_idx = slice_idx * slice_size;\n\n    for (size_t i = 0; i < dim1; i++) {\n        for (size_t j = 0; j < dim2; j += 16) {\n            __m128i data = _mm_loadu_si128((__m128i*)(tensor + start_idx + i * dim2 + j));\n            _mm_storeu_si128((__m128i*)(slice + i * dim2 + j), data);\n        }\n    }\n}\n```  "}
{"task_id": "SimdBench_5_SSE", "completion": "```cpp\nvoid extract_tensor_slice_simd(const uint8_t *tensor, uint8_t *slice, size_t dim1, size_t dim2, size_t dim3, size_t slice_idx) {\n    size_t slice_size = dim1 * dim2;\n    size_t start_idx = slice_idx * slice_size;\n\n    for (size_t i = 0; i < dim1; ++i) {\n        for (size_t j = 0; j < dim2; j += 16) {\n            __m128i data = _mm_loadu_si128((__m128i*)(tensor + start_idx + i * dim2 + j));\n            _mm_storeu_si128((__m128i*)(slice + i * dim2 + j), data);\n        }\n    }\n}\n```  "}
{"task_id": "SimdBench_5_SSE", "completion": "```c\nvoid extract_tensor_slice_simd(const uint8_t *tensor, uint8_t *slice, size_t dim1, size_t dim2, size_t dim3, size_t slice_idx) {\n    size_t slice_size = dim1 * dim2;\n    size_t offset = slice_idx * slice_size;\n\n    for (size_t i = 0; i < dim1; ++i) {\n        for (size_t j = 0; j < dim2; j += 16) {\n            __m128i data = _mm_loadu_si128((__m128i*)(tensor + offset + i * dim2 + j));\n            _mm_storeu_si128((__m128i*)(slice + i * dim2 + j), data);\n        }\n    }\n}\n```  "}
{"task_id": "SimdBench_6_SSE", "completion": "```c\nvoid blocked_matrix_transpose_simd(const int16_t *src, int16_t *dst, size_t rows, size_t cols, size_t block_size) {\n    for (size_t i = 0; i < rows; i += block_size) {\n        for (size_t j = 0; j < cols; j += block_size) {\n            for (size_t ii = i; ii < i + block_size && ii < rows; ii++) {\n                for (size_t jj = j; jj < j + block_size && jj < cols; jj++) {\n                    __m128i a = _mm_loadu_si128((__m128i*)&src[ii * cols + jj]);\n                    __m128i b = _mm_unpacklo_epi16(a, a);\n                    __m128i c = _mm_unpackhi_epi16(a, a);\n                    __m128i d = _mm_unpacklo_epi32(b, c);\n                    __m128i e = _mm_unpackhi_epi32(b, c);\n                    _mm_storeu_si128((__m128i*)&dst[jj * rows + ii], d);\n                    _mm_storeu_si128((__m128i*)&dst[jj * rows + ii + 8], e);\n                }\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_6_SSE", "completion": "```c\nvoid blocked_matrix_transpose_simd(const int16_t *src, int16_t *dst, size_t rows, size_t cols, size_t block_size) {\n    for (size_t i = 0; i < rows; i += block_size) {\n        for (size_t j = 0; j < cols; j += block_size) {\n            for (size_t ii = i; ii < i + block_size && ii < rows; ii++) {\n                for (size_t jj = j; jj < j + block_size && jj < cols; jj++) {\n                    __m128i val = _mm_loadu_si128((__m128i*)&src[ii * cols + jj]);\n                    __m128i transposed = _mm_unpacklo_epi64(val, val);\n                    _mm_storeu_si128((__m128i*)&dst[jj * rows + ii], transposed);\n                }\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_6_SSE", "completion": "```c\nvoid blocked_matrix_transpose_simd(const int16_t *src, int16_t *dst, size_t rows, size_t cols, size_t block_size) {\n    for (size_t i = 0; i < rows; i += block_size) {\n        for (size_t j = 0; j < cols; j += block_size) {\n            for (size_t ii = i; ii < i + block_size && ii < rows; ++ii) {\n                for (size_t jj = j; jj < j + block_size && jj < cols; ++jj) {\n                    __m128i val = _mm_loadu_si128((__m128i*)(src + ii * cols + jj));\n                    __m128i transposed_val = _mm_unpacklo_epi64(val, val);\n                    _mm_storeu_si128((__m128i*)(dst + jj * rows + ii), transposed_val);\n                }\n            }\n        }\n    }\n}\n```  "}
{"task_id": "SimdBench_6_SSE", "completion": "```c\nvoid blocked_matrix_transpose_simd(const int16_t *src, int16_t *dst, size_t rows, size_t cols, size_t block_size) {\n    for (size_t i = 0; i < rows; i += block_size) {\n        for (size_t j = 0; j < cols; j += block_size) {\n            for (size_t ii = i; ii < i + block_size && ii < rows; ii++) {\n                for (size_t jj = j; jj < j + block_size && jj < cols; jj++) {\n                    __m128i val = _mm_loadu_si128((__m128i*)&src[ii * cols + jj]);\n                    __m128i transposed = _mm_unpacklo_epi64(val, val);\n                    _mm_storeu_si128((__m128i*)&dst[jj * rows + ii], transposed);\n                }\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_6_SSE", "completion": "```c\nvoid blocked_matrix_transpose_simd(const int16_t *src, int16_t *dst, size_t rows, size_t cols, size_t block_size) {\n    for (size_t i = 0; i < rows; i += block_size) {\n        for (size_t j = 0; j < cols; j += block_size) {\n            for (size_t ii = i; ii < i + block_size && ii < rows; ii++) {\n                for (size_t jj = j; jj < j + block_size && jj < cols; jj++) {\n                    __m128i val = _mm_loadu_si128((__m128i*)&src[ii * cols + jj]);\n                    __m128i transposed = _mm_unpacklo_epi64(val, val);\n                    _mm_storeu_si128((__m128i*)&dst[jj * rows + ii], transposed);\n                }\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_7_SSE", "completion": "```c\nfloat diagonal_sum_3d_simd(const float *array, size_t dim) {\n    __m128 sum = _mm_setzero_ps();\n    for (size_t i = 0; i < dim; ++i) {\n        size_t index = i * dim * dim + i * dim + i;\n        __m128 values = _mm_loadu_ps(&array[index]);\n        sum = _mm_add_ps(sum, values);\n    }\n    \n    float result[4];\n    _mm_storeu_ps(result, sum);\n    \n    return result[0] + result[1] + result[2] + result[3];\n}\n```"}
{"task_id": "SimdBench_7_SSE", "completion": "```c\nfloat diagonal_sum_3d_simd(const float *array, size_t dim) {\n    __m128 sum = _mm_setzero_ps();\n    for (size_t i = 0; i < dim; ++i) {\n        size_t index = i * dim * dim + i * dim + i;\n        __m128 values = _mm_loadu_ps(&array[index]);\n        sum = _mm_add_ps(sum, values);\n    }\n    \n    float result[4];\n    _mm_storeu_ps(result, sum);\n    \n    return result[0] + result[1] + result[2] + result[3];\n}\n```  "}
{"task_id": "SimdBench_7_SSE", "completion": "```c\nfloat diagonal_sum_3d_simd(const float *array, size_t dim) {\n    __m128 sum = _mm_setzero_ps();\n    for (size_t i = 0; i < dim; ++i) {\n        size_t index = i * dim * dim + i * dim + i;\n        __m128 values = _mm_loadu_ps(&array[index]);\n        sum = _mm_add_ps(sum, values);\n    }\n    \n    float result[4];\n    _mm_storeu_ps(result, sum);\n    \n    return result[0] + result[1] + result[2] + result[3];\n}\n```"}
{"task_id": "SimdBench_7_SSE", "completion": "```c\nfloat diagonal_sum_3d_simd(const float *array, size_t dim) {\n    __m128 sum = _mm_setzero_ps();\n    for (size_t i = 0; i < dim; i++) {\n        __m128 val = _mm_loadu_ps(&array[i * dim * dim + i * dim + i]);\n        sum = _mm_add_ps(sum, val);\n    }\n    \n    float result[4];\n    _mm_storeu_ps(result, sum);\n    \n    return result[0] + result[1] + result[2] + result[3];\n}\n```"}
{"task_id": "SimdBench_7_SSE", "completion": "```c\nfloat diagonal_sum_3d_simd(const float *array, size_t dim) {\n    __m128 sum = _mm_setzero_ps();\n    for (size_t i = 0; i < dim; ++i) {\n        size_t index = i * dim * dim + i * dim + i;\n        __m128 values = _mm_loadu_ps(&array[index]);\n        sum = _mm_add_ps(sum, values);\n    }\n    \n    float result[4];\n    _mm_storeu_ps(result, sum);\n    \n    return result[0] + result[1] + result[2] + result[3];\n}\n```  "}
{"task_id": "SimdBench_8_SSE", "completion": "```c\nvoid conditional_scale_simd(const double *src, double *dst, size_t rows, size_t cols, double threshold, double scale) {\n    __m128d threshold_vec = _mm_set1_pd(threshold);\n    __m128d scale_vec = _mm_set1_pd(scale);\n\n    for (size_t i = 0; i < rows * cols; i += 2) {\n        __m128d src_vec = _mm_loadu_pd(&src[i]);\n        __m128d mask = _mm_cmpgt_pd(src_vec, threshold_vec);\n        __m128d result = _mm_blendv_pd(src_vec, _mm_mul_pd(src_vec, scale_vec), mask);\n        _mm_storeu_pd(&dst[i], result);\n    }\n}\n```  "}
{"task_id": "SimdBench_8_SSE", "completion": "```c\nvoid conditional_scale_simd(const double *src, double *dst, size_t rows, size_t cols, double threshold, double scale) {\n    __m128d threshold_vec = _mm_set1_pd(threshold);\n    __m128d scale_vec = _mm_set1_pd(scale);\n\n    for (size_t i = 0; i < rows * cols; i += 2) {\n        __m128d src_vec = _mm_loadu_pd(&src[i]);\n        __m128d mask = _mm_cmpgt_pd(src_vec, threshold_vec);\n        __m128d result = _mm_blendv_pd(src_vec, _mm_mul_pd(src_vec, scale_vec), mask);\n        _mm_storeu_pd(&dst[i], result);\n    }\n}\n```  "}
{"task_id": "SimdBench_8_SSE", "completion": "```c\nvoid conditional_scale_simd(const double *src, double *dst, size_t rows, size_t cols, double threshold, double scale) {\n    __m128d threshold_vec = _mm_set1_pd(threshold);\n    __m128d scale_vec = _mm_set1_pd(scale);\n\n    for (size_t i = 0; i < rows * cols; i += 2) {\n        __m128d src_vec = _mm_loadu_pd(&src[i]);\n        __m128d mask = _mm_cmpgt_pd(src_vec, threshold_vec);\n        __m128d result = _mm_blendv_pd(src_vec, _mm_mul_pd(src_vec, scale_vec), mask);\n        _mm_storeu_pd(&dst[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_8_SSE", "completion": "```c\nvoid conditional_scale_simd(const double *src, double *dst, size_t rows, size_t cols, double threshold, double scale) {\n    __m128d threshold_vec = _mm_set1_pd(threshold);\n    __m128d scale_vec = _mm_set1_pd(scale);\n\n    for (size_t i = 0; i < rows * cols; i += 2) {\n        __m128d src_vec = _mm_loadu_pd(&src[i]);\n        __m128d cmp_result = _mm_cmpgt_pd(src_vec, threshold_vec);\n        __m128d scaled_values = _mm_mul_pd(src_vec, _mm_blendv_pd(_mm_set1_pd(1.0), scale_vec, cmp_result));\n        _mm_storeu_pd(&dst[i], scaled_values);\n    }\n}\n```  "}
{"task_id": "SimdBench_8_SSE", "completion": "```c\nvoid conditional_scale_simd(const double *src, double *dst, size_t rows, size_t cols, double threshold, double scale) {\n    __m128d threshold_vec = _mm_set1_pd(threshold);\n    __m128d scale_vec = _mm_set1_pd(scale);\n\n    for (size_t i = 0; i < rows * cols; i += 2) {\n        __m128d src_vec = _mm_loadu_pd(&src[i]);\n        __m128d mask = _mm_cmpgt_pd(src_vec, threshold_vec);\n        __m128d result = _mm_blendv_pd(src_vec, _mm_mul_pd(src_vec, scale_vec), mask);\n        _mm_storeu_pd(&dst[i], result);\n    }\n}\n```  "}
{"task_id": "SimdBench_9_SSE", "completion": "```c\nvoid reorder_matrix_rows_simd(const double *src, double *dst, size_t rows, size_t cols, const size_t *indices) {\n    for (size_t i = 0; i < rows; ++i) {\n        size_t index = indices[i];\n        const double *src_row = src + index * cols;\n        double *dst_row = dst + i * cols;\n        for (size_t j = 0; j < cols; j += 2) {\n            __m128d val1 = _mm_loadu_pd(src_row + j);\n            __m128d val2 = _mm_loadu_pd(src_row + j + 2);\n            _mm_storeu_pd(dst_row + j, val1);\n            _mm_storeu_pd(dst_row + j + 2, val2);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_9_SSE", "completion": "```c\nvoid reorder_matrix_rows_simd(const double *src, double *dst, size_t rows, size_t cols, const size_t *indices) {\n    for (size_t i = 0; i < rows; ++i) {\n        size_t index = indices[i];\n        const double *src_row = src + index * cols;\n        double *dst_row = dst + i * cols;\n\n        for (size_t j = 0; j < cols; j += 2) {\n            __m128d src_data = _mm_loadu_pd(src_row + j);\n            _mm_storeu_pd(dst_row + j, src_data);\n        }\n    }\n}\n```  "}
{"task_id": "SimdBench_9_SSE", "completion": "```c\nvoid reorder_matrix_rows_simd(const double *src, double *dst, size_t rows, size_t cols, const size_t *indices) {\n    for (size_t i = 0; i < rows; i += 2) {\n        __m128d row1 = _mm_loadu_pd(&src[indices[i] * cols]);\n        __m128d row2 = _mm_loadu_pd(&src[indices[i + 1] * cols]);\n        _mm_storeu_pd(&dst[i * cols], row1);\n        _mm_storeu_pd(&dst[(i + 1) * cols], row2);\n    }\n}\n```"}
{"task_id": "SimdBench_9_SSE", "completion": "```c\nvoid reorder_matrix_rows_simd(const double *src, double *dst, size_t rows, size_t cols, const size_t *indices) {\n    for (size_t i = 0; i < rows; i += 2) {\n        __m128d row1 = _mm_loadu_pd(&src[indices[i] * cols]);\n        __m128d row2 = _mm_loadu_pd(&src[indices[i + 1] * cols]);\n        _mm_storeu_pd(&dst[i * cols], row1);\n        _mm_storeu_pd(&dst[(i + 1) * cols], row2);\n    }\n}\n```  "}
{"task_id": "SimdBench_9_SSE", "completion": "```c\nvoid reorder_matrix_rows_simd(const double *src, double *dst, size_t rows, size_t cols, const size_t *indices) {\n    for (size_t i = 0; i < rows; i += 2) {\n        __m128d row1 = _mm_loadu_pd(&src[indices[i] * cols]);\n        __m128d row2 = _mm_loadu_pd(&src[indices[i + 1] * cols]);\n        _mm_storeu_pd(&dst[i * cols], row1);\n        _mm_storeu_pd(&dst[(i + 1) * cols], row2);\n    }\n}\n```  "}
{"task_id": "SimdBench_10_SSE", "completion": "```\nvoid vector_vector_add_simd(const int64_t *src1, const int64_t *src2, int64_t *dst, int64_t scalar, size_t length) {\n    __m128i scalar_vec = _mm_set1_epi64x(scalar);\n    for (size_t i = 0; i < length; i += 2) {\n        __m128i src1_vec = _mm_loadu_si128((__m128i*)(src1 + i));\n        __m128i src2_vec = _mm_loadu_si128((__m128i*)(src2 + i));\n        \n        __m128i result = _mm_add_epi64(src1_vec, src2_vec);\n        result = _mm_add_epi64(result, scalar_vec);\n        result = _mm_srai_epi64(result, 1);\n        \n        _mm_storeu_si128((__m128i*)(dst + i), result);\n    }\n}\n```"}
{"task_id": "SimdBench_10_SSE", "completion": "```\nvoid vector_vector_add_simd(const int64_t *src1, const int64_t *src2, int64_t *dst, int64_t scalar, size_t length) {\n    __m128i scalar_vec = _mm_set1_epi64x(scalar);\n    for (size_t i = 0; i < length; i += 2) {\n        __m128i src1_vec = _mm_loadu_si128((__m128i*)&src1[i]);\n        __m128i src2_vec = _mm_loadu_si128((__m128i*)&src2[i]);\n        \n        __m128i result = _mm_add_epi64(src1_vec, src2_vec);\n        result = _mm_add_epi64(result, scalar_vec);\n        result = _mm_srai_epi64(result, 1);\n        \n        _mm_storeu_si128((__m128i*)&dst[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_10_SSE", "completion": "```\nvoid vector_vector_add_simd(const int64_t *src1, const int64_t *src2, int64_t *dst, int64_t scalar, size_t length) {\n    __m128i scalar_vec = _mm_set1_epi64x(scalar);\n    for (size_t i = 0; i < length; i += 2) {\n        __m128i src1_vec = _mm_loadu_si128((__m128i*)(src1 + i));\n        __m128i src2_vec = _mm_loadu_si128((__m128i*)(src2 + i));\n        \n        __m128i result = _mm_add_epi64(src1_vec, src2_vec);\n        result = _mm_add_epi64(result, scalar_vec);\n        result = _mm_srai_epi64(result, 1);\n        \n        _mm_storeu_si128((__m128i*)(dst + i), result);\n    }\n}\n```"}
{"task_id": "SimdBench_10_SSE", "completion": "```\nvoid vector_vector_add_simd(const int64_t *src1, const int64_t *src2, int64_t *dst, int64_t scalar, size_t length) {\n    __m128i scalar_vec = _mm_set1_epi64x(scalar);\n    for (size_t i = 0; i < length; i += 2) {\n        __m128i src1_vec = _mm_loadu_si128((__m128i*)(src1 + i));\n        __m128i src2_vec = _mm_loadu_si128((__m128i*)(src2 + i));\n        \n        __m128i result = _mm_add_epi64(src1_vec, src2_vec);\n        result = _mm_add_epi64(result, scalar_vec);\n        result = _mm_srai_epi64(result, 1);\n        \n        _mm_storeu_si128((__m128i*)(dst + i), result);\n    }\n}\n```"}
{"task_id": "SimdBench_10_SSE", "completion": "```\nvoid vector_vector_add_simd(const int64_t *src1, const int64_t *src2, int64_t *dst, int64_t scalar, size_t length) {\n    __m128i* src1_ptr = (__m128i*)src1;\n    __m128i* src2_ptr = (__m128i*)src2;\n    __m128i* dst_ptr = (__m128i*)dst;\n    __m128i scalar_vec = _mm_set1_epi64x(scalar);\n    __m128i half = _mm_set1_epi64x(2);\n\n    for (size_t i = 0; i < length / 2; i++) {\n        __m128i vec1 = _mm_load_si128(&src1_ptr[i]);\n        __m128i vec2 = _mm_load_si128(&src2_ptr[i]);\n\n        __m128i result = _mm_add_epi64(vec1, vec2);\n        result = _mm_add_epi64(result, scalar_vec);\n        result = _mm_srai_epi64(result, 1);\n\n        _mm_store_si128(&dst_ptr[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_11_SSE", "completion": "```c\nint vector_even_min_simd(const int *src, size_t length){\n    if (length == 0) {\n        return -1;\n    }\n\n    __m128i min_values = _mm_set1_epi32(INT_MAX);\n\n    for (size_t i = 0; i < length; i += 4) {\n        __m128i current_values = _mm_loadu_si128((__m128i*)(src + i));\n        __m128i even_mask = _mm_set_epi32(0, -1, 0, -1);\n        __m128i even_values = _mm_and_si128(current_values, even_mask);\n        min_values = _mm_min_epi32(min_values, even_values);\n    }\n\n    __m128i min_values_shuffled = _mm_shuffle_epi32(min_values, _MM_SHUFFLE(1, 0, 3, 2));\n    __m128i final_min_values = _mm_min_epi32(min_values, min_values_shuffled);\n\n    int result[4];\n    _mm_storeu_si128((__m128i*)result, final_min_values);\n\n    int min_value = INT_MAX;\n    for (int i = 0; i < 4; i++) {\n        if (result[i] < min_value) {\n            min_value = result[i];\n        }\n    }\n\n    return min_value;\n}\n```"}
{"task_id": "SimdBench_11_SSE", "completion": "```\nint vector_even_min_simd(const int *src, size_t length){\n    if (length == 0) {\n        return -1;\n    }\n\n    __m128i min_values = _mm_set1_epi32(INT_MAX);\n\n    for (size_t i = 0; i < length; i += 4) {\n        __m128i current_values = _mm_loadu_si128((__m128i*)(src + i));\n        __m128i even_mask = _mm_set_epi32(0, -1, 0, -1);\n        __m128i even_values = _mm_and_si128(current_values, even_mask);\n        min_values = _mm_min_epi32(min_values, even_values);\n    }\n\n    int result[4];\n    _mm_storeu_si128((__m128i*)result, min_values);\n\n    int min_even = INT_MAX;\n    for (int i = 0; i < 4; i++) {\n        if (result[i] < min_even) {\n            min_even = result[i];\n        }\n    }\n\n    return min_even;\n}\n```"}
{"task_id": "SimdBench_11_SSE", "completion": "```c\nint vector_even_min_simd(const int *src, size_t length){\n    if (length == 0) {\n        return -1;\n    }\n\n    __m128i min_values = _mm_set1_epi32(INT_MAX);\n\n    for (size_t i = 0; i < length; i += 4) {\n        __m128i current_values = _mm_loadu_si128((__m128i*)(src + i));\n        __m128i even_mask = _mm_set_epi32(0, -1, 0, -1);\n        __m128i even_values = _mm_and_si128(current_values, even_mask);\n        min_values = _mm_min_epi32(min_values, even_values);\n    }\n\n    __m128i min_values_permuted = _mm_shuffle_epi32(min_values, _MM_SHUFFLE(0, 0, 3, 2));\n    __m128i final_min_values = _mm_min_epi32(min_values, min_values_permuted);\n    __m128i final_min_values_permuted = _mm_shuffle_epi32(final_min_values, _MM_SHUFFLE(0, 0, 0, 1));\n\n    return _mm_cvtsi128_si32(final_min_values_permuted);\n}\n```"}
{"task_id": "SimdBench_11_SSE", "completion": "```c\nint vector_even_min_simd(const int *src, size_t length){\n    if (length == 0) {\n        return -1;\n    }\n\n    __m128i min_values = _mm_set1_epi32(INT_MAX);\n\n    for (size_t i = 0; i < length; i += 4) {\n        __m128i current_values = _mm_loadu_si128((__m128i*)(src + i));\n        __m128i even_mask = _mm_set1_epi32(0xAAAAAAAA); // Mask to select even elements\n        __m128i even_values = _mm_and_si128(current_values, even_mask);\n        min_values = _mm_min_epi32(min_values, even_values);\n    }\n\n    __m128i min_values_permuted = _mm_shuffle_epi32(min_values, _MM_SHUFFLE(1, 0, 3, 2));\n    __m128i final_min_values = _mm_min_epi32(min_values, min_values_permuted);\n    __m128i final_min_values_permuted = _mm_shuffle_epi32(final_min_values, _MM_SHUFFLE(2, 3, 0, 1));\n\n    int result[4];\n    _mm_storeu_si128((__m128i*)result, final_min_values_permuted);\n\n    return result[0];\n}\n```"}
{"task_id": "SimdBench_11_SSE", "completion": "```c\nint vector_even_min_simd(const int *src, size_t length){\n    if (length == 0) {\n        return -1;\n    }\n\n    __m128i min_values = _mm_set1_epi32(INT_MAX);\n\n    for (size_t i = 0; i < length; i += 4) {\n        __m128i current_values = _mm_loadu_si128((__m128i*)(src + i));\n        __m128i even_mask = _mm_set1_epi32(0xAAAAAAAA); // Mask to select even-numbered elements\n        __m128i even_values = _mm_and_si128(current_values, even_mask);\n        min_values = _mm_min_epi32(min_values, even_values);\n    }\n\n    __m128i min_values_shuffled = _mm_shuffle_epi32(min_values, _MM_SHUFFLE(1, 0, 3, 2));\n    __m128i final_min_values = _mm_min_epi32(min_values, min_values_shuffled);\n    __m128i final_min_values_permuted = _mm_shuffle_epi32(final_min_values, _MM_SHUFFLE(2, 3, 0, 1));\n\n    int result[4];\n    _mm_storeu_si128((__m128i*)result, final_min_values_permuted);\n\n    return result[0];\n}\n```"}
{"task_id": "SimdBench_12_SSE", "completion": "```\nvoid mixed_right_shift_simd(const int *src, int *dst, uint8_t shift, size_t length) {\n    __m128i arith_shift = _mm_set1_epi32((int)shift);\n    __m128i logical_shift = _mm_set1_epi32((int)shift);\n    __m128i* src_ptr = (__m128i*)src;\n    __m128i* dst_ptr = (__m128i*)dst;\n\n    for (size_t i = 0; i < length / 4; i++) {\n        __m128i data = _mm_loadu_si128(src_ptr + i);\n\n        // Arithmetic right shift\n        __m128i arith_result = _mm_sra_epi32(data, arith_shift);\n\n        // Logical right shift\n        __m128i uint_data = _mm_castsi128_ps(data);\n        __m128i uint_result = _mm_srli_epi32(uint_data, shift);\n        __m128i logical_result = _mm_castps_si128(uint_result);\n\n        // Add the results\n        __m128i final_result = _mm_add_epi32(arith_result, logical_result);\n\n        _mm_storeu_si128(dst_ptr + i, final_result);\n    }\n}\n```"}
{"task_id": "SimdBench_12_SSE", "completion": "```\nvoid mixed_right_shift_simd(const int *src, int *dst, uint8_t shift, size_t length) {\n    __m128i arith_shift = _mm_set1_epi32((int)shift);\n    __m128i logical_shift = _mm_set1_epi32((int)shift);\n    __m128i* src_ptr = (__m128i*)src;\n    __m128i* dst_ptr = (__m128i*)dst;\n\n    for (size_t i = 0; i < length / 4; i++) {\n        __m128i src_data = _mm_loadu_si128(&src_ptr[i]);\n        __m128i src_data_uint = _mm_and_si128(src_data, _mm_set1_epi32(0xFFFFFFFF));\n        \n        __m128i arith_result = _mm_sra_epi32(src_data, arith_shift);\n        __m128i logical_result = _mm_srli_epi32(src_data_uint, shift);\n        \n        __m128i final_result = _mm_add_epi32(arith_result, logical_result);\n        \n        _mm_storeu_si128(&dst_ptr[i], final_result);\n    }\n}\n```"}
{"task_id": "SimdBench_12_SSE", "completion": "```\nvoid mixed_right_shift_simd(const int *src, int *dst, uint8_t shift, size_t length) {\n    __m128i arith_shift = _mm_set1_epi32((int)shift);\n    __m128i logical_shift = _mm_set1_epi32((int)shift);\n    __m128i* src_ptr = (__m128i*)src;\n    __m128i* dst_ptr = (__m128i*)dst;\n\n    for (size_t i = 0; i < length/4; i++) {\n        __m128i src_data = _mm_loadu_si128(&src_ptr[i]);\n\n        // Arithmetic right shift\n        __m128i arith_result = _mm_sra_epi32(src_data, arith_shift);\n\n        // Convert int to uint, then logical right shift\n        __m128i uint_data = _mm_and_si128(src_data, _mm_set1_epi32(0xFFFFFFFF));\n        __m128i logical_result = _mm_srli_epi32(uint_data, shift);\n\n        // Cast back to int and add the results\n        __m128i final_result = _mm_add_epi32(arith_result, logical_result);\n\n        _mm_storeu_si128(&dst_ptr[i], final_result);\n    }\n}\n```"}
{"task_id": "SimdBench_12_SSE", "completion": "```\nvoid mixed_right_shift_simd(const int *src, int *dst, uint8_t shift, size_t length) {\n    __m128i arith_shift = _mm_set1_epi32((int)shift);\n    __m128i logical_shift = _mm_set1_epi32((int)shift);\n    __m128i* src_ptr = (__m128i*)src;\n    __m128i* dst_ptr = (__m128i*)dst;\n\n    for (size_t i = 0; i < length / 4; i++) {\n        __m128i data = _mm_loadu_si128(src_ptr + i);\n\n        __m128i arith_result = _mm_sra_epi32(data, arith_shift);\n\n        __m128i data_uint = _mm_and_si128(data, _mm_set1_epi32(0xFFFFFFFF));\n        __m128i logical_result = _mm_srli_epi32(data_uint, shift);\n\n        __m128i final_result = _mm_add_epi32(arith_result, logical_result);\n\n        _mm_storeu_si128(dst_ptr + i, final_result);\n    }\n}\n```"}
{"task_id": "SimdBench_12_SSE", "completion": "```\nvoid mixed_right_shift_simd(const int *src, int *dst, uint8_t shift, size_t length) {\n    __m128i arith_shift = _mm_set1_epi32((int)shift);\n    __m128i logical_shift = _mm_set1_epi32((int)shift);\n    __m128i* src_ptr = (__m128i*)src;\n    __m128i* dst_ptr = (__m128i*)dst;\n\n    for (size_t i = 0; i < length / 4; i++) {\n        __m128i src_data = _mm_loadu_si128(&src_ptr[i]);\n\n        __m128i arith_result = _mm_sra_epi32(src_data, arith_shift);\n\n        __m128i src_data_uint = _mm_and_si128(src_data, _mm_set1_epi32(0xFFFFFFFF));\n        __m128i logical_result_uint = _mm_srli_epi32(src_data_uint, shift);\n        __m128i logical_result = _mm_castsi128_ps(logical_result_uint);\n\n        __m128i final_result = _mm_add_epi32(arith_result, logical_result);\n\n        _mm_storeu_si128(&dst_ptr[i], final_result);\n    }\n}\n```"}
{"task_id": "SimdBench_13_SSE", "completion": "```c\nint64_t matrix_sum_simd(const int *matrix, size_t rows, size_t cols) {\n    __m128i sum = _mm_setzero_si128();\n    for (size_t i = 0; i < rows * cols; i += 4) {\n        __m128i values = _mm_loadu_si128((__m128i*)&matrix[i]);\n        sum = _mm_add_epi32(sum, values);\n    }\n\n    int32_t temp[4];\n    _mm_storeu_si128((__m128i*)temp, sum);\n\n    int64_t total_sum = (int64_t)temp[0] + (int64_t)temp[1] + (int64_t)temp[2] + (int64_t)temp[3];\n\n    for (size_t i = rows * cols - (rows * cols % 4); i < rows * cols; i++) {\n        total_sum += matrix[i];\n    }\n\n    return total_sum;\n}\n```"}
{"task_id": "SimdBench_13_SSE", "completion": "```c\nint64_t matrix_sum_simd(const int *matrix, size_t rows, size_t cols) {\n    __m128i sum = _mm_setzero_si128();\n    \n    for (size_t i = 0; i < rows * cols; i += 4) {\n        __m128i values = _mm_loadu_si128((__m128i*)(matrix + i));\n        sum = _mm_add_epi32(sum, values);\n    }\n    \n    int32_t temp[4];\n    _mm_storeu_si128((__m128i*)temp, sum);\n    \n    int64_t total_sum = 0;\n    for (int j = 0; j < 4; j++) {\n        total_sum += temp[j];\n    }\n    \n    return total_sum;\n}\n```  "}
{"task_id": "SimdBench_13_SSE", "completion": "```c\nint64_t matrix_sum_simd(const int *matrix, size_t rows, size_t cols) {\n    __m128i sum = _mm_setzero_si128();\n    \n    for (size_t i = 0; i < rows * cols; i += 4) {\n        __m128i values = _mm_loadu_si128((__m128i*)(matrix + i));\n        sum = _mm_add_epi32(sum, values);\n    }\n    \n    int32_t temp[4];\n    _mm_storeu_si128((__m128i*)temp, sum);\n    \n    int64_t total_sum = 0;\n    for (int j = 0; j < 4; j++) {\n        total_sum += temp[j];\n    }\n    \n    return total_sum;\n}\n```  "}
{"task_id": "SimdBench_13_SSE", "completion": "```c\nint64_t matrix_sum_simd(const int *matrix, size_t rows, size_t cols) {\n    __m128i sum = _mm_setzero_si128();\n    \n    for (size_t i = 0; i < rows * cols; i += 4) {\n        __m128i values = _mm_loadu_si128((__m128i*)&matrix[i]);\n        sum = _mm_add_epi32(sum, values);\n    }\n    \n    int32_t temp[4];\n    _mm_storeu_si128((__m128i*)temp, sum);\n    \n    int64_t total_sum = 0;\n    for (int i = 0; i < 4; i++) {\n        total_sum += temp[i];\n    }\n    \n    return total_sum;\n}\n```  "}
{"task_id": "SimdBench_13_SSE", "completion": "```c\nint64_t matrix_sum_simd(const int *matrix, size_t rows, size_t cols) {\n    __m128i sum = _mm_setzero_si128();\n    \n    for (size_t i = 0; i < rows * cols; i += 4) {\n        __m128i values = _mm_loadu_si128((__m128i*)(matrix + i));\n        sum = _mm_add_epi32(sum, values);\n    }\n    \n    int32_t temp[4];\n    _mm_storeu_si128((__m128i*)temp, sum);\n    \n    int64_t result = (int64_t)temp[0] + temp[1] + temp[2] + temp[3];\n    \n    for (size_t i = rows * cols - (rows * cols % 4); i < rows * cols; i++) {\n        result += matrix[i];\n    }\n    \n    return result;\n}\n```  "}
{"task_id": "SimdBench_14_SSE", "completion": "```\nsize_t argmax_simd(const int8_t *src, size_t length) {\n    if (length == 0) {\n        return 0;\n    }\n\n    __m128i max_values = _mm_set1_epi8(INT8_MIN);\n    __m128i max_indices = _mm_set_epi32(3, 2, 1, 0);\n\n    for (size_t i = 0; i < length; i += 16) {\n        __m128i data = _mm_loadu_si128((__m128i*)(src + i));\n        __m128i cmp_mask = _mm_cmpgt_epi8(data, max_values);\n        max_values = _mm_max_epi8(data, max_values);\n        max_indices = _mm_blendv_epi8(max_indices, _mm_set1_epi32(i), cmp_mask);\n    }\n\n    alignas(16) int8_t result[16];\n    alignas(16) int32_t index[4];\n    _mm_store_si128((__m128i*)result, max_values);\n    _mm_store_si128((__m128i*)index, max_indices);\n\n    int8_t max_value = result[0];\n    size_t max_index = index[0];\n\n    for (int i = 1; i < 16; ++i) {\n        if (result[i] > max_value) {\n            max_value = result[i];\n            max_index = index[i / 4];\n            max_index += i % 4;\n        }\n    }\n\n    return max_index;\n}\n```"}
{"task_id": "SimdBench_14_SSE", "completion": "```\nsize_t argmax_simd(const int8_t *src, size_t length) {\n    if (length == 0) {\n        return 0;\n    }\n\n    __m128i max_values = _mm_set1_epi8(INT8_MIN);\n    __m128i max_indices = _mm_setzero_si128();\n    size_t i = 0;\n\n    for (; i + 16 <= length; i += 16) {\n        __m128i current_values = _mm_loadu_si128((__m128i*)(src + i));\n        __m128i cmp_mask = _mm_cmpgt_epi8(current_values, max_values);\n        max_values = _mm_max_epi8(max_values, current_values);\n        max_indices = _mm_blendv_epi8(max_indices, _mm_set1_epi8(i), cmp_mask);\n    }\n\n    int8_t max_values_array[16];\n    int8_t max_indices_array[16];\n    _mm_storeu_si128((__m128i*)max_values_array, max_values);\n    _mm_storeu_si128((__m128i*)max_indices_array, max_indices);\n\n    int8_t max_value = INT8_MIN;\n    size_t max_index = 0;\n\n    for (int j = 0; j < 16; j++) {\n        if (max_values_array[j] > max_value) {\n            max_value = max_values_array[j];\n            max_index = i + max_indices_array[j];\n        }\n    }\n\n    for (; i < length; i++) {\n        if (src[i] > max_value) {\n            max_value = src[i];\n            max_index = i;\n        }\n    }\n\n    return max_index;\n}\n```"}
{"task_id": "SimdBench_14_SSE", "completion": "```c\nsize_t argmax_simd(const int8_t *src, size_t length) {\n    if (length == 0) {\n        return 0;\n    }\n\n    __m128i max_values = _mm_set1_epi8(INT8_MIN);\n    __m128i max_indices = _mm_set_epi32(3, 2, 1, 0);\n\n    for (size_t i = 0; i < length; i += 16) {\n        __m128i data = _mm_loadu_si128((__m128i*)(src + i));\n        __m128i cmp_mask = _mm_cmpgt_epi8(data, max_values);\n        max_values = _mm_max_epi8(data, max_values);\n        max_indices = _mm_blendv_epi8(max_indices, _mm_set1_epi32(i), cmp_mask);\n    }\n\n    int8_t max_values_arr[16];\n    int32_t max_indices_arr[4];\n    _mm_storeu_si128((__m128i*)max_values_arr, max_values);\n    _mm_storeu_si128((__m128i*)max_indices_arr, max_indices);\n\n    int8_t max_val = INT8_MIN;\n    size_t max_idx = 0;\n    for (int i = 0; i < 16; i++) {\n        if (max_values_arr[i] > max_val) {\n            max_val = max_values_arr[i];\n            max_idx = max_indices_arr[i / 4];\n        }\n    }\n\n    return max_idx;\n}\n```"}
{"task_id": "SimdBench_14_SSE", "completion": "```c\nsize_t argmax_simd(const int8_t *src, size_t length) {\n    if (length == 0) {\n        return 0;\n    }\n\n    __m128i max_val = _mm_set1_epi8(INT8_MIN);\n    __m128i max_idx = _mm_setzero_si128();\n    size_t i = 0;\n\n    for (; i + 16 <= length; i += 16) {\n        __m128i chunk = _mm_loadu_si128((__m128i*)(src + i));\n        __m128i cmp_mask = _mm_cmpgt_epi8(chunk, max_val);\n        max_val = _mm_max_epi8(chunk, max_val);\n        max_idx = _mm_blendv_epi8(max_idx, _mm_set1_epi8(i), cmp_mask);\n    }\n\n    int8_t max_vals[16];\n    int8_t max_idxs[16];\n    _mm_storeu_si128((__m128i*)max_vals, max_val);\n    _mm_storeu_si128((__m128i*)max_idxs, max_idx);\n\n    int8_t max_val_final = INT8_MIN;\n    size_t max_idx_final = 0;\n\n    for (int j = 0; j < 16; j++) {\n        if (max_vals[j] > max_val_final) {\n            max_val_final = max_vals[j];\n            max_idx_final = max_idxs[j] + i + j;\n        }\n    }\n\n    for (; i < length; i++) {\n        if (src[i] > max_val_final) {\n            max_val_final = src[i];\n            max_idx_final = i;\n        }\n    }\n\n    return max_idx_final;\n}\n```"}
{"task_id": "SimdBench_14_SSE", "completion": "```c\nsize_t argmax_simd(const int8_t *src, size_t length) {\n    if (length == 0) {\n        return 0;\n    }\n\n    __m128i max_val = _mm_set1_epi8(INT8_MIN);\n    __m128i max_idx = _mm_setzero_si128();\n    size_t i = 0;\n\n    for (; i + 16 <= length; i += 16) {\n        __m128i chunk = _mm_loadu_si128((__m128i*)(src + i));\n        __m128i cmp = _mm_cmpgt_epi8(chunk, max_val);\n        max_val = _mm_max_epi8(chunk, max_val);\n        max_idx = _mm_blendv_epi8(max_idx, _mm_set1_epi8(i), cmp);\n    }\n\n    int8_t max_values[16];\n    int8_t max_indices[16];\n    _mm_storeu_si128((__m128i*)max_values, max_val);\n    _mm_storeu_si128((__m128i*)max_indices, max_idx);\n\n    int8_t max_value = INT8_MIN;\n    size_t max_index = 0;\n    for (int j = 0; j < 16; j++) {\n        if (max_values[j] > max_value) {\n            max_value = max_values[j];\n            max_index = max_indices[j] + i + j;\n        }\n    }\n\n    for (; i < length; i++) {\n        if (src[i] > max_value) {\n            max_value = src[i];\n            max_index = i;\n        }\n    }\n\n    return max_index;\n}\n```"}
{"task_id": "SimdBench_15_SSE", "completion": "```c\nvoid vector_blend_simd(const uint16_t* src1, const uint16_t* src2, uint32_t mask, uint16_t* dst, size_t length) {\n    __m128i* src1_ptr = (__m128i*)src1;\n    __m128i* src2_ptr = (__m128i*)src2;\n    __m128i* dst_ptr = (__m128i*)dst;\n    __m128i mask_vec = _mm_set1_epi32(mask);\n\n    for (size_t i = 0; i < length / 8; i++) {\n        __m128i index_vec = _mm_set_epi16(7, 6, 5, 4, 3, 2, 1, 0);\n        index_vec = _mm_add_epi16(index_vec, _mm_set1_epi16(i * 8));\n\n        __m128i result = _mm_and_si128(index_vec, mask_vec);\n        __m128i src1_values = _mm_loadu_si128(src1_ptr + i);\n        __m128i src2_values = _mm_loadu_si128(src2_ptr + i);\n\n        __m128i blend_mask = _mm_cmpeq_epi16(result, _mm_setzero_si128());\n        __m128i blended_values = _mm_blendv_epi8(src2_values, src1_values, blend_mask);\n\n        _mm_storeu_si128(dst_ptr + i, blended_values);\n    }\n}\n```"}
{"task_id": "SimdBench_15_SSE", "completion": "```c\nvoid vector_blend_simd(const uint16_t* src1, const uint16_t* src2, uint32_t mask, uint16_t* dst, size_t length) {\n    __m128i* src1_ptr = (__m128i*)src1;\n    __m128i* src2_ptr = (__m128i*)src2;\n    __m128i* dst_ptr = (__m128i*)dst;\n    __m128i mask_vec = _mm_set1_epi16(mask);\n\n    for (size_t i = 0; i < length / 8; i++) {\n        __m128i index_vec = _mm_setr_epi16(0, 1, 2, 3, 4, 5, 6, 7);\n        index_vec = _mm_add_epi16(index_vec, _mm_set1_epi16(i * 8));\n\n        __m128i and_result = _mm_and_si128(index_vec, mask_vec);\n        __m128i cmp_result = _mm_cmpeq_epi16(and_result, _mm_setzero_si128());\n\n        __m128i src1_val = _mm_loadu_si128(src1_ptr + i);\n        __m128i src2_val = _mm_loadu_si128(src2_ptr + i);\n\n        __m128i blend_result = _mm_blendv_epi8(src2_val, src1_val, cmp_result);\n\n        _mm_storeu_si128(dst_ptr + i, blend_result);\n    }\n}\n```"}
{"task_id": "SimdBench_15_SSE", "completion": "```c\nvoid vector_blend_simd(const uint16_t* src1, const uint16_t* src2, uint32_t mask, uint16_t* dst, size_t length) {\n    __m128i xmm_mask = _mm_set1_epi32(mask);\n    __m128i xmm_index, xmm_src1, xmm_src2, xmm_result;\n\n    for (size_t i = 0; i < length; i += 8) {\n        xmm_index = _mm_setr_epi32(i, i + 1, i + 2, i + 3, i + 4, i + 5, i + 6, i + 7);\n        __m128i xmm_and = _mm_and_si128(xmm_index, xmm_mask);\n\n        xmm_src1 = _mm_loadu_si128((__m128i*)(src1 + i));\n        xmm_src2 = _mm_loadu_si128((__m128i*)(src2 + i));\n\n        xmm_result = _mm_blendv_epi8(xmm_src2, xmm_src1, _mm_cmpeq_epi32(xmm_and, _mm_setzero_si128()));\n\n        _mm_storeu_si128((__m128i*)(dst + i), xmm_result);\n    }\n}\n```"}
{"task_id": "SimdBench_15_SSE", "completion": "```cpp\nvoid vector_blend_simd(const uint16_t* src1, const uint16_t* src2, uint32_t mask, uint16_t* dst, size_t length) {\n    __m128i xmm_mask = _mm_set1_epi32(mask);\n    for (size_t i = 0; i < length; i += 8) {\n        __m128i xmm_index = _mm_set_epi16(i + 7, i + 6, i + 5, i + 4, i + 3, i + 2, i + 1, i);\n        __m128i xmm_result = _mm_and_si128(xmm_index, xmm_mask);\n        \n        __m128i xmm_src1 = _mm_loadu_si128((__m128i*)(src1 + i));\n        __m128i xmm_src2 = _mm_loadu_si128((__m128i*)(src2 + i));\n        \n        __m128i xmm_dst = _mm_blendv_epi8(xmm_src2, xmm_src1, _mm_cmpeq_epi16(xmm_result, _mm_setzero_si128()));\n        \n        _mm_storeu_si128((__m128i*)(dst + i), xmm_dst);\n    }\n}\n```"}
{"task_id": "SimdBench_15_SSE", "completion": "```\nvoid vector_blend_simd(const uint16_t* src1, const uint16_t* src2, uint32_t mask, uint16_t* dst, size_t length) {\n    __m128i mask_vec = _mm_set1_epi32(mask);\n    for (size_t i = 0; i < length; i += 8) {\n        __m128i index_vec = _mm_setr_epi32(i, i + 1, i + 2, i + 3, i + 4, i + 5, i + 6, i + 7);\n        __m128i result = _mm_and_si128(index_vec, mask_vec);\n        \n        __m128i src1_vec = _mm_loadu_si128((__m128i*)(src1 + i));\n        __m128i src2_vec = _mm_loadu_si128((__m128i*)(src2 + i));\n        \n        __m128i blend_mask = _mm_cmpeq_epi32(result, _mm_setzero_si128());\n        __m128i blended_values = _mm_blendv_epi8(src2_vec, src1_vec, blend_mask);\n        \n        _mm_storeu_si128((__m128i*)(dst + i), blended_values);\n    }\n}\n```"}
{"task_id": "SimdBench_16_SSE", "completion": "```\nvoid population_count_simd(const uint32_t* src, uint32_t* dst, size_t length) {\n    for (size_t i = 0; i < length; i += 4) {\n        __m128i vsrc = _mm_loadu_si128((__m128i*)(src + i));\n        __m128i vones = _mm_set1_epi32(1);\n        __m128i vcount = _mm_setzero_si128();\n\n        for (int j = 0; j < 32; ++j) {\n            __m128i vbit = _mm_and_si128(vsrc, vones);\n            vcount = _mm_add_epi32(vcount, vbit);\n            vsrc = _mm_srli_epi32(vsrc, 1);\n        }\n\n        _mm_storeu_si128((__m128i*)(dst + i), vcount);\n    }\n}\n```"}
{"task_id": "SimdBench_16_SSE", "completion": "```\nvoid population_count_simd(const uint32_t* src, uint32_t* dst, size_t length) {\n    for (size_t i = 0; i < length; i += 4) {\n        __m128i data = _mm_loadu_si128((__m128i*)(src + i));\n        __m128i count = _mm_setzero_si128();\n\n        count = _mm_sad_epu8(_mm_set1_epi8(0x01), _mm_and_si128(data, _mm_set1_epi32(0x01010101)));\n        count = _mm_add_epi16(count, _mm_srli_epi16(count, 8));\n        count = _mm_add_epi16(count, _mm_srli_epi16(count, 4));\n        count = _mm_add_epi16(count, _mm_srli_epi16(count, 2));\n        dst[i] = _mm_cvtsi128_si32(count);\n        dst[i + 1] = _mm_extract_epi16(count, 2);\n        dst[i + 2] = _mm_extract_epi16(count, 4);\n        dst[i + 3] = _mm_extract_epi16(count, 6);\n    }\n}\n```"}
{"task_id": "SimdBench_16_SSE", "completion": "```\nvoid population_count_simd(const uint32_t* src, uint32_t* dst, size_t length) {\n    for (size_t i = 0; i < length; i += 4) {\n        __m128i data = _mm_loadu_si128((__m128i*)(src + i));\n        __m128i count = _mm_setzero_si128();\n\n        count = _mm_sad_epu8(_mm_set1_epi8(1), _mm_and_si128(data, _mm_set1_epi32(0x01010101)));\n        count = _mm_add_epi16(count, _mm_srli_epi16(count, 8));\n        count = _mm_add_epi16(count, _mm_srli_epi16(count, 4));\n        count = _mm_add_epi16(count, _mm_srli_epi16(count, 2));\n\n        _mm_storeu_si128((__m128i*)(dst + i), _mm_packus_epi16(count, _mm_setzero_si128()));\n    }\n}\n```"}
{"task_id": "SimdBench_16_SSE", "completion": "```\nvoid population_count_simd(const uint32_t* src, uint32_t* dst, size_t length) {\n    for (size_t i = 0; i < length; i += 4) {\n        __m128i vsrc = _mm_loadu_si128((__m128i*)(src + i));\n        __m128i vones = _mm_set1_epi32(1);\n        __m128i vcount = _mm_setzero_si128();\n\n        for (int j = 0; j < 32; ++j) {\n            __m128i vbit = _mm_and_si128(vsrc, vones);\n            vcount = _mm_add_epi32(vcount, vbit);\n            vsrc = _mm_srli_epi32(vsrc, 1);\n        }\n\n        _mm_storeu_si128((__m128i*)(dst + i), vcount);\n    }\n}\n```"}
{"task_id": "SimdBench_16_SSE", "completion": "```\nvoid population_count_simd(const uint32_t* src, uint32_t* dst, size_t length) {\n    for (size_t i = 0; i < length; i += 4) {\n        __m128i data = _mm_loadu_si128((__m128i*)(src + i));\n        __m128i count = _mm_setzero_si128();\n\n        count = _mm_sad_epu8(_mm_set1_epi8(1), _mm_and_si128(data, _mm_set1_epi32(0x01010101)));\n        count = _mm_add_epi16(count, _mm_srli_si128(count, 8));\n        count = _mm_add_epi16(count, _mm_srli_si128(count, 4));\n\n        _mm_storeu_si128((__m128i*)(dst + i), count);\n    }\n}\n```"}
{"task_id": "SimdBench_17_SSE", "completion": "```cpp\nvoid saturating_add_simd(const uint16_t* src1, const uint16_t* src2, uint16_t* dst, size_t length) {\n    for (size_t i = 0; i < length; i += 8) {\n        __m128i xmm_src1 = _mm_loadu_si128((__m128i*)(src1 + i));\n        __m128i xmm_src2 = _mm_loadu_si128((__m128i*)(src2 + i));\n\n        __m128i xmm_result = _mm_adds_epu16(xmm_src1, xmm_src2);\n\n        _mm_storeu_si128((__m128i*)(dst + i), xmm_result);\n    }\n}\n```"}
{"task_id": "SimdBench_17_SSE", "completion": "```c\nvoid saturating_add_simd(const uint16_t* src1, const uint16_t* src2, uint16_t* dst, size_t length) {\n    size_t i;\n    __m128i xmm_src1, xmm_src2, xmm_result, xmm_max;\n\n    xmm_max = _mm_set1_epi16(UINT16_MAX);\n\n    for (i = 0; i < length; i += 8) {\n        xmm_src1 = _mm_loadu_si128((__m128i*)(src1 + i));\n        xmm_src2 = _mm_loadu_si128((__m128i*)(src2 + i));\n\n        xmm_result = _mm_adds_epu16(xmm_src1, xmm_src2);\n        xmm_result = _mm_min_epu16(xmm_result, xmm_max);\n\n        _mm_storeu_si128((__m128i*)(dst + i), xmm_result);\n    }\n}\n```"}
{"task_id": "SimdBench_17_SSE", "completion": "```c\nvoid saturating_add_simd(const uint16_t* src1, const uint16_t* src2, uint16_t* dst, size_t length) {\n    size_t i;\n    __m128i xmm_src1, xmm_src2, xmm_result, xmm_max;\n\n    xmm_max = _mm_set1_epi16(UINT16_MAX);\n\n    for (i = 0; i < length; i += 8) {\n        xmm_src1 = _mm_loadu_si128((__m128i*)(src1 + i));\n        xmm_src2 = _mm_loadu_si128((__m128i*)(src2 + i));\n\n        xmm_result = _mm_adds_epu16(xmm_src1, xmm_src2);\n        xmm_result = _mm_min_epu16(xmm_result, xmm_max);\n\n        _mm_storeu_si128((__m128i*)(dst + i), xmm_result);\n    }\n\n    for (; i < length; i++) {\n        uint16_t sum = src1[i] + src2[i];\n        dst[i] = sum > UINT16_MAX ? UINT16_MAX : sum;\n    }\n}\n```  "}
{"task_id": "SimdBench_17_SSE", "completion": "```cpp\nvoid saturating_add_simd(const uint16_t* src1, const uint16_t* src2, uint16_t* dst, size_t length) {\n    for (size_t i = 0; i < length; i += 8) {\n        __m128i xmm_src1 = _mm_loadu_si128((__m128i*)(src1 + i));\n        __m128i xmm_src2 = _mm_loadu_si128((__m128i*)(src2 + i));\n\n        __m128i xmm_result = _mm_adds_epu16(xmm_src1, xmm_src2);\n\n        _mm_storeu_si128((__m128i*)(dst + i), xmm_result);\n    }\n}\n```"}
{"task_id": "SimdBench_17_SSE", "completion": "```c\nvoid saturating_add_simd(const uint16_t* src1, const uint16_t* src2, uint16_t* dst, size_t length) {\n    size_t i;\n    __m128i xmm_src1, xmm_src2, xmm_result, xmm_max, xmm_clamped;\n\n    xmm_max = _mm_set1_epi16(UINT16_MAX);\n\n    for (i = 0; i < length; i += 8) {\n        xmm_src1 = _mm_loadu_si128((__m128i*)(src1 + i));\n        xmm_src2 = _mm_loadu_si128((__m128i*)(src2 + i));\n\n        xmm_result = _mm_adds_epu16(xmm_src1, xmm_src2);\n        xmm_clamped = _mm_min_epu16(xmm_result, xmm_max);\n\n        _mm_storeu_si128((__m128i*)(dst + i), xmm_clamped);\n    }\n\n    for (; i < length; i++) {\n        uint16_t sum = src1[i] + src2[i];\n        dst[i] = sum > UINT16_MAX ? UINT16_MAX : sum;\n    }\n}\n```  "}
{"task_id": "SimdBench_18_SSE", "completion": "```\nvoid range_matrix_mul_simd(const double* A, const double* B, double* C, size_t m, size_t n, size_t p) {\n    for (size_t i = 0; i < m; ++i) {\n        for (size_t j = 0; j < p; ++j) {\n            __m128d sum = _mm_setzero_pd();\n            for (size_t k = 0; k < n; k += 2) {\n                __m128d a = _mm_loadu_pd(&A[i * n + k]);\n                __m128d b = _mm_loadu_pd(&B[k * p + j]);\n                __m128d mask_a = _mm_and_pd(_mm_cmpge_pd(a, _mm_set1_pd(-100.0)), _mm_cmple_pd(a, _mm_set1_pd(100.0)));\n                __m128d mask_b = _mm_and_pd(_mm_cmpge_pd(b, _mm_set1_pd(-100.0)), _mm_cmple_pd(b, _mm_set1_pd(100.0)));\n                __m128d mask = _mm_and_pd(mask_a, mask_b);\n                __m128d prod = _mm_mul_pd(a, b);\n                sum = _mm_add_pd(sum, _mm_and_pd(mask, prod));\n            }\n            C[i * p + j] = _mm_cvtsd_f64(sum);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_18_SSE", "completion": "```\nvoid range_matrix_mul_simd(const double* A, const double* B, double* C, size_t m, size_t n, size_t p) {\n    for (size_t i = 0; i < m; ++i) {\n        for (size_t j = 0; j < p; ++j) {\n            __m128d sum = _mm_setzero_pd();\n            for (size_t k = 0; k < n; k += 2) {\n                __m128d a = _mm_loadu_pd(&A[i * n + k]);\n                __m128d b = _mm_loadu_pd(&B[k * p + j]);\n                __m128d mask_a = _mm_and_pd(_mm_cmpge_pd(a, _mm_set1_pd(-100.0)), _mm_cmple_pd(a, _mm_set1_pd(100.0)));\n                __m128d mask_b = _mm_and_pd(_mm_cmpge_pd(b, _mm_set1_pd(-100.0)), _mm_cmple_pd(b, _mm_set1_pd(100.0)));\n                __m128d mask = _mm_and_pd(mask_a, mask_b);\n                __m128d prod = _mm_mul_pd(a, b);\n                sum = _mm_add_pd(sum, _mm_and_pd(prod, mask));\n            }\n            _mm_storeu_pd(&C[i * p + j], sum);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_18_SSE", "completion": "```c\nvoid range_matrix_mul_simd(const double* A, const double* B, double* C, size_t m, size_t n, size_t p) {\n    for (size_t i = 0; i < m; ++i) {\n        for (size_t j = 0; j < p; ++j) {\n            __m128d sum = _mm_setzero_pd();\n            for (size_t k = 0; k < n; k += 2) {\n                __m128d a = _mm_loadu_pd(&A[i * n + k]);\n                __m128d b = _mm_loadu_pd(&B[k * p + j]);\n                __m128d mask_a = _mm_and_pd(_mm_cmpge_pd(a, _mm_set1_pd(-100.0)), _mm_cmple_pd(a, _mm_set1_pd(100.0)));\n                __m128d mask_b = _mm_and_pd(_mm_cmpge_pd(b, _mm_set1_pd(-100.0)), _mm_cmple_pd(b, _mm_set1_pd(100.0)));\n                __m128d mask = _mm_and_pd(mask_a, mask_b);\n                __m128d mul = _mm_mul_pd(a, b);\n                sum = _mm_add_pd(sum, _mm_and_pd(mul, mask));\n            }\n            _mm_storeu_pd(&C[i * p + j], sum);\n        }\n    }\n}\n```  "}
{"task_id": "SimdBench_18_SSE", "completion": "```c\nvoid range_matrix_mul_simd(const double* A, const double* B, double* C, size_t m, size_t n, size_t p) {\n    for (size_t i = 0; i < m; ++i) {\n        for (size_t j = 0; j < p; ++j) {\n            __m128d sum = _mm_setzero_pd();\n            for (size_t k = 0; k < n; k += 2) {\n                __m128d a = _mm_loadu_pd(&A[i * n + k]);\n                __m128d b = _mm_loadu_pd(&B[k * p + j]);\n                __m128d mask_a = _mm_and_pd(_mm_cmpge_pd(a, _mm_set1_pd(-100.0)), _mm_cmple_pd(a, _mm_set1_pd(100.0)));\n                __m128d mask_b = _mm_and_pd(_mm_cmpge_pd(b, _mm_set1_pd(-100.0)), _mm_cmple_pd(b, _mm_set1_pd(100.0)));\n                __m128d mask = _mm_and_pd(mask_a, mask_b);\n                __m128d prod = _mm_mul_pd(a, b);\n                sum = _mm_add_pd(sum, _mm_and_pd(mask, prod));\n            }\n            C[i * p + j] = _mm_cvtsd_f64(sum);\n        }\n    }\n}\n```  "}
{"task_id": "SimdBench_18_SSE", "completion": "```c\nvoid range_matrix_mul_simd(const double* A, const double* B, double* C, size_t m, size_t n, size_t p) {\n    for (size_t i = 0; i < m; ++i) {\n        for (size_t j = 0; j < p; ++j) {\n            __m128d sum = _mm_setzero_pd();\n            for (size_t k = 0; k < n; k += 2) {\n                __m128d a = _mm_loadu_pd(&A[i * n + k]);\n                __m128d b = _mm_loadu_pd(&B[k * p + j]);\n                __m128d mask_a = _mm_and_pd(_mm_cmpge_pd(a, _mm_set1_pd(-100.0)), _mm_cmple_pd(a, _mm_set1_pd(100.0)));\n                __m128d mask_b = _mm_and_pd(_mm_cmpge_pd(b, _mm_set1_pd(-100.0)), _mm_cmple_pd(b, _mm_set1_pd(100.0)));\n                __m128d mask = _mm_and_pd(mask_a, mask_b);\n                __m128d prod = _mm_mul_pd(a, b);\n                sum = _mm_add_pd(sum, _mm_and_pd(mask, prod));\n            }\n            _mm_storeu_pd(&C[i * p + j], sum);\n        }\n    }\n}\n```  "}
{"task_id": "SimdBench_19_SSE", "completion": "```c\nvoid tensor_add_3d_simd(const int64_t* A, const int64_t* B, int64_t* C, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_size = dim1 * dim2 * dim3;\n    size_t simd_size = 2 * sizeof(__m128i) / sizeof(int64_t);\n    \n    for (size_t i = 0; i < total_size; i += simd_size) {\n        __m128i a1 = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i a2 = _mm_loadu_si128((__m128i*)&A[i + simd_size]);\n        __m128i b1 = _mm_loadu_si128((__m128i*)&B[i]);\n        __m128i b2 = _mm_loadu_si128((__m128i*)&B[i + simd_size]);\n        \n        __m128i result1 = _mm_add_epi64(a1, b1);\n        __m128i result2 = _mm_add_epi64(a2, b2);\n        \n        _mm_storeu_si128((__m128i*)&C[i], result1);\n        _mm_storeu_si128((__m128i*)&C[i + simd_size], result2);\n    }\n}\n```"}
{"task_id": "SimdBench_19_SSE", "completion": "```c\nvoid tensor_add_3d_simd(const int64_t* A, const int64_t* B, int64_t* C, size_t dim1, size_t dim2, size_t dim3) {\n    for (size_t i = 0; i < dim1 * dim2 * dim3; i += 2) {\n        __m128i a = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i b = _mm_loadu_si128((__m128i*)&B[i]);\n        __m128i result = _mm_add_epi64(a, b);\n        _mm_storeu_si128((__m128i*)&C[i], result);\n    }\n}\n```  "}
{"task_id": "SimdBench_19_SSE", "completion": "```c\nvoid tensor_add_3d_simd(const int64_t* A, const int64_t* B, int64_t* C, size_t dim1, size_t dim2, size_t dim3) {\n    for (size_t i = 0; i < dim1 * dim2 * dim3; i += 2) {\n        __m128i a = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i b = _mm_loadu_si128((__m128i*)&B[i]);\n        __m128i result = _mm_add_epi64(a, b);\n        _mm_storeu_si128((__m128i*)&C[i], result);\n    }\n}\n```  "}
{"task_id": "SimdBench_19_SSE", "completion": "```c\nvoid tensor_add_3d_simd(const int64_t* A, const int64_t* B, int64_t* C, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_size = dim1 * dim2 * dim3;\n    size_t simd_size = total_size / 2;\n\n    for (size_t i = 0; i < simd_size; ++i) {\n        __m128i a = _mm_loadu_si128((__m128i*)&A[i*2]);\n        __m128i b = _mm_loadu_si128((__m128i*)&B[i*2]);\n        __m128i result = _mm_add_epi64(a, b);\n        _mm_storeu_si128((__m128i*)&C[i*2], result);\n    }\n\n    for (size_t i = simd_size * 2; i < total_size; ++i) {\n        C[i] = A[i] + B[i];\n    }\n}\n```  "}
{"task_id": "SimdBench_19_SSE", "completion": "```\nvoid tensor_add_3d_simd(const int64_t* A, const int64_t* B, int64_t* C, size_t dim1, size_t dim2, size_t dim3) {\n    for (size_t i = 0; i < dim1 * dim2 * dim3; i += 2) {\n        __m128i a = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i b = _mm_loadu_si128((__m128i*)&B[i]);\n        __m128i result = _mm_add_epi64(a, b);\n        _mm_storeu_si128((__m128i*)&C[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_20_SSE", "completion": "```c\nvoid vector_add_round_nearest_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    for (size_t i = 0; i < length; i += 4) {\n        __m128 xmm_src1 = _mm_loadu_ps(src1 + i);\n        __m128 xmm_src2 = _mm_loadu_ps(src2 + i);\n        __m128 xmm_result = _mm_add_ps(xmm_src1, xmm_src2);\n        xmm_result = _mm_round_ps(xmm_result, _MM_FROUND_TO_NEAREST_INT);\n        _mm_storeu_ps(dst + i, xmm_result);\n    }\n}\n```  "}
{"task_id": "SimdBench_20_SSE", "completion": "```c\nvoid vector_add_round_nearest_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    for (size_t i = 0; i < length; i += 4) {\n        __m128 xmm_src1 = _mm_loadu_ps(src1 + i);\n        __m128 xmm_src2 = _mm_loadu_ps(src2 + i);\n        __m128 xmm_result = _mm_add_ps(xmm_src1, xmm_src2);\n        xmm_result = _mm_round_ps(xmm_result, _MM_FROUND_TO_NEAREST_INT);\n        _mm_storeu_ps(dst + i, xmm_result);\n    }\n}\n```  "}
{"task_id": "SimdBench_20_SSE", "completion": "```c\nvoid vector_add_round_nearest_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    size_t i;\n    for (i = 0; i < length; i += 4) {\n        __m128 a = _mm_loadu_ps(src1 + i);\n        __m128 b = _mm_loadu_ps(src2 + i);\n        __m128 sum = _mm_add_ps(a, b);\n        __m128 rounded = _mm_round_ps(sum, _MM_FROUND_TO_NEAREST_INT);\n        _mm_storeu_ps(dst + i, rounded);\n    }\n}\n```  "}
{"task_id": "SimdBench_20_SSE", "completion": "```c\nvoid vector_add_round_nearest_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    for (size_t i = 0; i < length; i += 4) {\n        __m128 xmm_src1 = _mm_loadu_ps(&src1[i]);\n        __m128 xmm_src2 = _mm_loadu_ps(&src2[i]);\n        \n        __m128 xmm_result = _mm_add_ps(xmm_src1, xmm_src2);\n        xmm_result = _mm_round_ps(xmm_result, _MM_FROUND_TO_NEAREST_INT);\n        \n        _mm_storeu_ps(&dst[i], xmm_result);\n    }\n}\n```  "}
{"task_id": "SimdBench_20_SSE", "completion": "```c\nvoid vector_add_round_nearest_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    for (size_t i = 0; i < length; i += 4) {\n        __m128 a = _mm_loadu_ps(src1 + i);\n        __m128 b = _mm_loadu_ps(src2 + i);\n        __m128 sum = _mm_add_ps(a, b);\n        __m128 rounded = _mm_round_ps(sum, _MM_FROUND_TO_NEAREST_INT);\n        _mm_storeu_ps(dst + i, rounded);\n    }\n}\n```"}
{"task_id": "SimdBench_21_SSE", "completion": "```\nvoid vector_mul_round_up_simd(const float* src1, const float* src2, float* dst, size_t length){\n    __m128i mask = _mm_set1_epi32(0x80000000);\n    __m128i fifty = _mm_set1_epi32(50);\n    for (size_t i = 0; i < length; i += 4) {\n        __m128 a = _mm_loadu_ps(src1 + i);\n        __m128 b = _mm_loadu_ps(src2 + i);\n        __m128 diff = _mm_sub_ps(a, b);\n        __m128 abs_diff = _mm_andnot_ps(*(__m128*)&mask, diff);\n        __m128i abs_diff_int = _mm_cvtps_epi32(abs_diff);\n        __m128i abs_diff_mask = _mm_cmplt_epi32(abs_diff_int, fifty);\n        __m128i index_mask = _mm_set_epi32(0, 0, -1, -1);\n        __m128i final_mask = _mm_and_si128(abs_diff_mask, index_mask);\n        __m128 result = _mm_mul_ps(a, b);\n        __m128i result_int = _mm_cvtps_epi32(result);\n        __m128i negative_ones = _mm_set1_epi32(-1);\n        __m128i final_result = _mm_blendv_epi8(negative_ones, result_int, final_mask);\n        _mm_storeu_ps(dst + i, _mm_cvtepi32_ps(final_result));\n    }\n}\n```"}
{"task_id": "SimdBench_21_SSE", "completion": "```\nvoid vector_mul_round_up_simd(const float* src1, const float* src2, float* dst, size_t length){\n    __m128i mask = _mm_set1_epi32(0x80000000);\n    __m128i fifty = _mm_set1_epi32(50);\n    __m128i two = _mm_set1_epi32(2);\n    __m128i one = _mm_set1_epi32(1);\n    __m128i minus_one = _mm_set1_epi32(-1);\n\n    for (size_t i = 0; i < length; i += 4) {\n        __m128 a = _mm_loadu_ps(&src1[i]);\n        __m128 b = _mm_loadu_ps(&src2[i]);\n\n        __m128 diff = _mm_sub_ps(a, b);\n        __m128 abs_diff = _mm_andnot_ps(mask, diff);\n        __m128 abs_diff_cmp = _mm_cmple_ps(abs_diff, _mm_castsi128_ps(fifty));\n        __m128 index_cmp = _mm_cmpeq_epi32(_mm_and_si128(_mm_cvttps_epi32(a), two), _mm_setzero_si128());\n        __m128 result_mask = _mm_and_ps(abs_diff_cmp, _mm_castsi128_ps(index_cmp));\n\n        __m128 result = _mm_round_ps(_mm_mul_ps(a, b), _MM_FROUND_TO_POS_INF);\n\n        __m128 final_result = _mm_blendv_ps(minus_one, result, result_mask);\n\n        _mm_storeu_ps(&dst[i], final_result);\n    }\n}\n```"}
{"task_id": "SimdBench_21_SSE", "completion": "```\nvoid vector_mul_round_up_simd(const float* src1, const float* src2, float* dst, size_t length){\n    __m128i mask = _mm_set1_epi32(0x80000000);\n    __m128i fifty = _mm_set1_epi32(50);\n    __m128i two = _mm_set1_epi32(2);\n    __m128i one = _mm_set1_epi32(1);\n    __m128i minus_one = _mm_set1_epi32(-1);\n\n    for (size_t i = 0; i < length; i += 4) {\n        __m128 a = _mm_loadu_ps(&src1[i]);\n        __m128 b = _mm_loadu_ps(&src2[i]);\n\n        __m128 diff = _mm_sub_ps(a, b);\n        __m128 abs_diff = _mm_andnot_ps(*(__m128*)&mask, diff);\n        __m128 abs_diff_cmp = _mm_cmple_ps(abs_diff, *(__m128*)&fifty);\n        __m128 index_cmp = _mm_cmpeq_epi32(_mm_and_si128(_mm_cvttps_epi32(a), *(__m128i*)&two), _mm_setzero_si128());\n        __m128 mask = _mm_and_ps(abs_diff_cmp, _mm_castsi128_ps(index_cmp));\n\n        __m128 result = _mm_round_ps(_mm_mul_ps(a, b), _MM_FROUND_TO_POS_INF);\n\n        __m128 final_result = _mm_blendv_ps(_mm_set1_ps(-1.0f), result, mask);\n        _mm_storeu_ps(&dst[i], final_result);\n    }\n}\n```"}
{"task_id": "SimdBench_21_SSE", "completion": "```\nvoid vector_mul_round_up_simd(const float* src1, const float* src2, float* dst, size_t length){\n    __m128i mask = _mm_set1_epi32(0x80000000);\n    __m128i fifty = _mm_set1_epi32(50);\n    __m128i two = _mm_set1_epi32(2);\n    __m128i one = _mm_set1_epi32(1);\n\n    for (size_t i = 0; i < length; i += 4) {\n        __m128 a = _mm_loadu_ps(src1 + i);\n        __m128 b = _mm_loadu_ps(src2 + i);\n\n        __m128 diff = _mm_sub_ps(a, b);\n        __m128 abs_diff = _mm_andnot_ps(*(__m128*)&mask, diff);\n\n        __m128i abs_diff_int = _mm_cvtps_epi32(abs_diff);\n        __m128i abs_diff_mask = _mm_cmplt_epi32(abs_diff_int, fifty);\n\n        __m128i index = _mm_set_epi32(i + 3, i + 2, i + 1, i);\n        __m128i index_mod = _mm_and_si128(index, two);\n        __m128i index_mask = _mm_cmpeq_epi32(index_mod, _mm_setzero_si128());\n\n        __m128i final_mask = _mm_and_si128(abs_diff_mask, index_mask);\n        __m128i result = _mm_blendv_epi8(one, _mm_cvtps_epi32(_mm_ceil_ps(_mm_mul_ps(a, b))), final_mask);\n\n        _mm_storeu_ps(dst + i, _mm_cvtepi32_ps(result));\n    }\n}\n```"}
{"task_id": "SimdBench_21_SSE", "completion": "```\nvoid vector_mul_round_up_simd(const float* src1, const float* src2, float* dst, size_t length){\n    __m128i mask = _mm_set1_epi32(0x80000000);\n    __m128i fifty = _mm_set1_epi32(50);\n    __m128i two = _mm_set1_epi32(2);\n    __m128i one = _mm_set1_epi32(1);\n    for (size_t i = 0; i < length; i += 4) {\n        __m128 a = _mm_loadu_ps(src1 + i);\n        __m128 b = _mm_loadu_ps(src2 + i);\n        __m128 diff = _mm_sub_ps(a, b);\n        __m128 abs_diff = _mm_andnot_ps(*(__m128*)&mask, diff);\n        __m128i abs_diff_int = _mm_cvtps_epi32(abs_diff);\n        __m128i abs_diff_mask = _mm_cmplt_epi32(abs_diff_int, fifty);\n        __m128i index_mask = _mm_cmpeq_epi32(_mm_and_si128(_mm_set1_epi32(i), two), _mm_setzero_si128());\n        __m128i final_mask = _mm_and_si128(abs_diff_mask, index_mask);\n        __m128i result = _mm_blendv_epi8(one, _mm_cvtps_epi32(_mm_ceil_ps(_mm_mul_ps(a, b))), final_mask);\n        _mm_storeu_ps(dst + i, _mm_cvtepi32_ps(result));\n    }\n}\n```"}
{"task_id": "SimdBench_22_SSE", "completion": "```c\nvoid matrix_scalar_mul_simd(const double* mat, double scalar, double* dst, size_t m, size_t n) {\n    __m128d scalar_vec = _mm_set1_pd(scalar);\n    for (size_t i = 0; i < m*n; i += 2) {\n        __m128d mat_vec = _mm_loadu_pd(&mat[i]);\n        __m128d result = _mm_mul_pd(mat_vec, scalar_vec);\n        _mm_storeu_pd(&dst[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_22_SSE", "completion": "```c\nvoid matrix_scalar_mul_simd(const double* mat, double scalar, double* dst, size_t m, size_t n) {\n    __m128d scalar_vec = _mm_set1_pd(scalar);\n    size_t size = m * n;\n    size_t i;\n    for (i = 0; i < size; i += 2) {\n        __m128d mat_vec = _mm_loadu_pd(&mat[i]);\n        __m128d result = _mm_mul_pd(mat_vec, scalar_vec);\n        _mm_storeu_pd(&dst[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_22_SSE", "completion": "```c\nvoid matrix_scalar_mul_simd(const double* mat, double scalar, double* dst, size_t m, size_t n) {\n    __m128d scalar_vec = _mm_set1_pd(scalar);\n    for (size_t i = 0; i < m*n; i += 2) {\n        __m128d mat_vec = _mm_loadu_pd(&mat[i]);\n        __m128d result = _mm_mul_pd(mat_vec, scalar_vec);\n        _mm_storeu_pd(&dst[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_22_SSE", "completion": "```c\nvoid matrix_scalar_mul_simd(const double* mat, double scalar, double* dst, size_t m, size_t n) {\n    __m128d scalar_vec = _mm_set1_pd(scalar);\n    for (size_t i = 0; i < m*n; i += 2) {\n        __m128d mat_vec = _mm_loadu_pd(&mat[i]);\n        __m128d result = _mm_mul_pd(mat_vec, scalar_vec);\n        _mm_storeu_pd(&dst[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_22_SSE", "completion": "```c\nvoid matrix_scalar_mul_simd(const double* mat, double scalar, double* dst, size_t m, size_t n) {\n    __m128d scalar_vec = _mm_set1_pd(scalar);\n    for (size_t i = 0; i < m*n; i += 2) {\n        __m128d mat_vec = _mm_loadu_pd(&mat[i]);\n        __m128d result = _mm_mul_pd(mat_vec, scalar_vec);\n        _mm_storeu_pd(&dst[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_23_SSE", "completion": "```c\nvoid matrix_normalize_rows_simd(float* mat, size_t m, size_t n) {\n    for (size_t i = 0; i < m; i++) {\n        __m128 sum = _mm_setzero_ps();\n        for (size_t j = 0; j < n; j += 4) {\n            __m128 values = _mm_loadu_ps(&mat[i * n + j]);\n            sum = _mm_add_ps(sum, _mm_mul_ps(values, values));\n        }\n        sum = _mm_sqrt_ps(sum);\n        for (size_t j = 0; j < n; j += 4) {\n            __m128 values = _mm_loadu_ps(&mat[i * n + j]);\n            _mm_storeu_ps(&mat[i * n + j], _mm_div_ps(values, sum));\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_23_SSE", "completion": "```c\nvoid matrix_normalize_rows_simd(float* mat, size_t m, size_t n) {\n    for (size_t i = 0; i < m; i++) {\n        __m128 sum = _mm_setzero_ps();\n        for (size_t j = 0; j < n; j += 4) {\n            __m128 values = _mm_loadu_ps(&mat[i * n + j]);\n            sum = _mm_add_ps(sum, _mm_mul_ps(values, values));\n        }\n        sum = _mm_hadd_ps(sum, sum);\n        sum = _mm_hadd_ps(sum, sum);\n        sum = _mm_sqrt_ps(sum);\n        for (size_t j = 0; j < n; j += 4) {\n            __m128 values = _mm_loadu_ps(&mat[i * n + j]);\n            _mm_storeu_ps(&mat[i * n + j], _mm_div_ps(values, sum));\n        }\n    }\n}\n```  "}
{"task_id": "SimdBench_23_SSE", "completion": "```c\nvoid matrix_normalize_rows_simd(float* mat, size_t m, size_t n) {\n    for (size_t i = 0; i < m; i++) {\n        __m128 sum = _mm_setzero_ps();\n        for (size_t j = 0; j < n; j += 4) {\n            __m128 data = _mm_loadu_ps(&mat[i * n + j]);\n            sum = _mm_add_ps(sum, _mm_mul_ps(data, data));\n        }\n        sum = _mm_hadd_ps(sum, sum);\n        sum = _mm_hadd_ps(sum, sum);\n        sum = _mm_sqrt_ps(sum);\n        for (size_t j = 0; j < n; j += 4) {\n            __m128 data = _mm_loadu_ps(&mat[i * n + j]);\n            _mm_storeu_ps(&mat[i * n + j], _mm_div_ps(data, sum));\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_23_SSE", "completion": "```c\nvoid matrix_normalize_rows_simd(float* mat, size_t m, size_t n) {\n    for (size_t i = 0; i < m; i++) {\n        __m128 sum = _mm_setzero_ps();\n        for (size_t j = 0; j < n; j += 4) {\n            __m128 val = _mm_loadu_ps(&mat[i * n + j]);\n            sum = _mm_add_ps(sum, _mm_mul_ps(val, val));\n        }\n        sum = _mm_sqrt_ps(sum);\n        for (size_t j = 0; j < n; j += 4) {\n            __m128 val = _mm_loadu_ps(&mat[i * n + j]);\n            _mm_storeu_ps(&mat[i * n + j], _mm_div_ps(val, sum));\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_23_SSE", "completion": "```c\nvoid matrix_normalize_rows_simd(float* mat, size_t m, size_t n) {\n    for (size_t i = 0; i < m; i++) {\n        __m128 sum_squared = _mm_setzero_ps();\n        for (size_t j = 0; j < n; j += 4) {\n            __m128 values = _mm_loadu_ps(&mat[i * n + j]);\n            sum_squared = _mm_add_ps(sum_squared, _mm_mul_ps(values, values));\n        }\n        __m128 sqrt_sum_squared = _mm_sqrt_ps(sum_squared);\n        for (size_t j = 0; j < n; j += 4) {\n            __m128 values = _mm_loadu_ps(&mat[i * n + j]);\n            _mm_storeu_ps(&mat[i * n + j], _mm_div_ps(values, sqrt_sum_squared));\n        }\n    }\n}\n```  "}
{"task_id": "SimdBench_24_SSE", "completion": "```c\nvoid matrix_mul_round_int_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n, size_t p) {\n    for (size_t i = 0; i < m; ++i) {\n        for (size_t j = 0; j < p; ++j) {\n            __m128d sum = _mm_setzero_pd();\n            for (size_t k = 0; k < n; ++k) {\n                __m128d a = _mm_loadu_pd(&mat1[i * n + k]);\n                __m128d b = _mm_loadu_pd(&mat2[k * p + j]);\n                sum = _mm_add_pd(sum, _mm_mul_pd(a, b));\n            }\n            __m128d rounded = _mm_round_pd(sum, _MM_FROUND_TO_NEAREST_INT);\n            _mm_storeu_pd(&dst[i * p + j], rounded);\n        }\n    }\n}\n```  "}
{"task_id": "SimdBench_24_SSE", "completion": "```c\nvoid matrix_mul_round_int_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n, size_t p) {\n    for (size_t i = 0; i < m; ++i) {\n        for (size_t j = 0; j < p; ++j) {\n            __m128d sum = _mm_setzero_pd();\n            for (size_t k = 0; k < n; k += 2) {\n                __m128d a = _mm_loadu_pd(&mat1[i * n + k]);\n                __m128d b = _mm_loadu_pd(&mat2[k * p + j]);\n                sum = _mm_add_pd(sum, _mm_mul_pd(a, b));\n            }\n            __m128d rounded = _mm_round_pd(sum, _MM_FROUND_TO_NEAREST_INT);\n            _mm_storeu_pd(&dst[i * p + j], rounded);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_24_SSE", "completion": "```cpp\nvoid matrix_mul_round_int_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n, size_t p) {\n    for (size_t i = 0; i < m; ++i) {\n        for (size_t j = 0; j < p; ++j) {\n            __m128d sum = _mm_setzero_pd();\n            for (size_t k = 0; k < n; ++k) {\n                __m128d a = _mm_loadu_pd(&mat1[i * n + k]);\n                __m128d b = _mm_loadu_pd(&mat2[k * p + j]);\n                sum = _mm_add_pd(sum, _mm_mul_pd(a, b));\n            }\n            __m128d rounded = _mm_round_pd(sum, _MM_FROUND_TO_NEAREST_INT);\n            _mm_storeu_pd(&dst[i * p + j], rounded);\n        }\n    }\n}\n```  "}
{"task_id": "SimdBench_24_SSE", "completion": "```cpp\nvoid matrix_mul_round_int_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n, size_t p) {\n    for (size_t i = 0; i < m; ++i) {\n        for (size_t j = 0; j < p; ++j) {\n            __m128d sum = _mm_setzero_pd();\n            for (size_t k = 0; k < n; k += 2) {\n                __m128d a = _mm_loadu_pd(&mat1[i * n + k]);\n                __m128d b = _mm_loadu_pd(&mat2[k * p + j]);\n                sum = _mm_add_pd(sum, _mm_mul_pd(a, b));\n            }\n            __m128d rounded = _mm_round_pd(sum, _MM_FROUND_TO_NEAREST_INT);\n            _mm_storeu_pd(&dst[i * p + j], rounded);\n        }\n    }\n}\n```  "}
{"task_id": "SimdBench_24_SSE", "completion": "```cpp\nvoid matrix_mul_round_int_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n, size_t p) {\n    for (size_t i = 0; i < m; ++i) {\n        for (size_t j = 0; j < p; ++j) {\n            __m128d sum = _mm_setzero_pd();\n            for (size_t k = 0; k < n; k += 2) {\n                __m128d a = _mm_loadu_pd(&mat1[i * n + k]);\n                __m128d b = _mm_loadu_pd(&mat2[k * p + j]);\n                sum = _mm_add_pd(sum, _mm_mul_pd(a, b));\n\n                a = _mm_loadu_pd(&mat1[i * n + k + 1]);\n                b = _mm_loadu_pd(&mat2[(k + 1) * p + j]);\n                sum = _mm_add_pd(sum, _mm_mul_pd(a, b));\n            }\n            __m128d rounded = _mm_round_pd(sum, _MM_FROUND_TO_NEAREST_INT);\n            _mm_storeu_pd(&dst[i * p + j], rounded);\n        }\n    }\n}\n```  "}
{"task_id": "SimdBench_25_SSE", "completion": "```c\nvoid matrix_transpose_round_quarter_simd(const float* src, float* dst, size_t rows, size_t cols) {\n    for (size_t i = 0; i < rows; i += 4) {\n        for (size_t j = 0; j < cols; j += 4) {\n            __m128 a0 = _mm_loadu_ps(&src[(j + 0) * rows + i]);\n            __m128 a1 = _mm_loadu_ps(&src[(j + 1) * rows + i]);\n            __m128 a2 = _mm_loadu_ps(&src[(j + 2) * rows + i]);\n            __m128 a3 = _mm_loadu_ps(&src[(j + 3) * rows + i]);\n\n            __m128 b0 = _mm_unpacklo_ps(a0, a1);\n            __m128 b1 = _mm_unpackhi_ps(a0, a1);\n            __m128 b2 = _mm_unpacklo_ps(a2, a3);\n            __m128 b3 = _mm_unpackhi_ps(a2, a3);\n\n            __m128 c0 = _mm_movelh_ps(b0, b2);\n            __m128 c1 = _mm_movehl_ps(b2, b0);\n            __m128 c2 = _mm_movelh_ps(b1, b3);\n            __m128 c3 = _mm_movehl_ps(b3, b1);\n\n            __m128 quarter = _mm_set1_ps(0.25f);\n            c0 = _mm_round_ps(c0, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n            c1 = _mm_round_ps(c1, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n            c2 = _mm_round_ps(c2, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n            c3 = _mm_round_ps(c3, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n\n            c0 = _mm_mul_ps(c0, quarter);\n            c1 = _mm_mul_ps(c1, quarter);\n            c2 = _mm_mul_ps(c2, quarter);\n            c3 = _mm_mul_ps(c3, quarter);\n\n            _mm_storeu_ps(&dst[(i + 0) * cols + j], c0);\n            _mm_storeu_ps(&dst[(i + 1) * cols + j], c1);\n            _mm_storeu_ps(&dst[(i + 2) * cols + j], c2);\n            _mm_storeu_ps(&dst[(i + 3) * cols + j], c3);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_25_SSE", "completion": "```c\nvoid matrix_transpose_round_quarter_simd(const float* src, float* dst, size_t rows, size_t cols) {\n    for (size_t i = 0; i < rows; i += 4) {\n        for (size_t j = 0; j < cols; j += 4) {\n            __m128 row0 = _mm_loadu_ps(&src[(j * rows) + i]);\n            __m128 row1 = _mm_loadu_ps(&src[(j * rows) + i + 1]);\n            __m128 row2 = _mm_loadu_ps(&src[(j * rows) + i + 2]);\n            __m128 row3 = _mm_loadu_ps(&src[(j * rows) + i + 3]);\n\n            __m128 tmp0 = _mm_unpacklo_ps(row0, row1);\n            __m128 tmp1 = _mm_unpackhi_ps(row0, row1);\n            __m128 tmp2 = _mm_unpacklo_ps(row2, row3);\n            __m128 tmp3 = _mm_unpackhi_ps(row2, row3);\n\n            row0 = _mm_movelh_ps(tmp0, tmp2);\n            row1 = _mm_movehl_ps(tmp2, tmp0);\n            row2 = _mm_movelh_ps(tmp1, tmp3);\n            row3 = _mm_movehl_ps(tmp3, tmp1);\n\n            __m128 quarter = _mm_set1_ps(0.25f);\n            row0 = _mm_round_ps(_mm_mul_ps(row0, quarter), _MM_FROUND_TO_NEAREST_INT);\n            row1 = _mm_round_ps(_mm_mul_ps(row1, quarter), _MM_FROUND_TO_NEAREST_INT);\n            row2 = _mm_round_ps(_mm_mul_ps(row2, quarter), _MM_FROUND_TO_NEAREST_INT);\n            row3 = _mm_round_ps(_mm_mul_ps(row3, quarter), _MM_FROUND_TO_NEAREST_INT);\n\n            _mm_storeu_ps(&dst[(i * cols) + j], row0);\n            _mm_storeu_ps(&dst[(i * cols) + j + 1], row1);\n            _mm_storeu_ps(&dst[(i * cols) + j + 2], row2);\n            _mm_storeu_ps(&dst[(i * cols) + j + 3], row3);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_25_SSE", "completion": "```c\nvoid matrix_transpose_round_quarter_simd(const float* src, float* dst, size_t rows, size_t cols) {\n    for (size_t i = 0; i < rows; i += 4) {\n        for (size_t j = 0; j < cols; j += 4) {\n            __m128 a0 = _mm_loadu_ps(&src[(i + 0) * cols + j]);\n            __m128 a1 = _mm_loadu_ps(&src[(i + 1) * cols + j]);\n            __m128 a2 = _mm_loadu_ps(&src[(i + 2) * cols + j]);\n            __m128 a3 = _mm_loadu_ps(&src[(i + 3) * cols + j]);\n\n            __m128 b0 = _mm_unpacklo_ps(a0, a1);\n            __m128 b1 = _mm_unpackhi_ps(a0, a1);\n            __m128 b2 = _mm_unpacklo_ps(a2, a3);\n            __m128 b3 = _mm_unpackhi_ps(a2, a3);\n\n            __m128 c0 = _mm_movelh_ps(b0, b2);\n            __m128 c1 = _mm_movehl_ps(b2, b0);\n            __m128 c2 = _mm_movelh_ps(b1, b3);\n            __m128 c3 = _mm_movehl_ps(b3, b1);\n\n            __m128 quarter = _mm_set1_ps(0.25f);\n            c0 = _mm_round_ps(c0, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n            c1 = _mm_round_ps(c1, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n            c2 = _mm_round_ps(c2, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n            c3 = _mm_round_ps(c3, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n\n            c0 = _mm_mul_ps(c0, quarter);\n            c1 = _mm_mul_ps(c1, quarter);\n            c2 = _mm_mul_ps(c2, quarter);\n            c3 = _mm_mul_ps(c3, quarter);\n\n            _mm_storeu_ps(&dst[(j + 0) * rows + i], c0);\n            _mm_storeu_ps(&dst[(j + 1) * rows + i], c1);\n            _mm_storeu_ps(&dst[(j + 2) * rows + i], c2);\n            _mm_storeu_ps(&dst[(j + 3) * rows + i], c3);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_25_SSE", "completion": "```c\nvoid matrix_transpose_round_quarter_simd(const float* src, float* dst, size_t rows, size_t cols) {\n    for (size_t i = 0; i < rows; i += 4) {\n        for (size_t j = 0; j < cols; j += 4) {\n            __m128 a0 = _mm_loadu_ps(&src[(j + 0) * rows + i]);\n            __m128 a1 = _mm_loadu_ps(&src[(j + 1) * rows + i]);\n            __m128 a2 = _mm_loadu_ps(&src[(j + 2) * rows + i]);\n            __m128 a3 = _mm_loadu_ps(&src[(j + 3) * rows + i]);\n\n            __m128 b0 = _mm_unpacklo_ps(a0, a1);\n            __m128 b1 = _mm_unpackhi_ps(a0, a1);\n            __m128 b2 = _mm_unpacklo_ps(a2, a3);\n            __m128 b3 = _mm_unpackhi_ps(a2, a3);\n\n            __m128 c0 = _mm_movelh_ps(b0, b2);\n            __m128 c1 = _mm_movehl_ps(b2, b0);\n            __m128 c2 = _mm_movelh_ps(b1, b3);\n            __m128 c3 = _mm_movehl_ps(b3, b1);\n\n            __m128i quarter = _mm_set1_epi32(0x3F000000); // 0.25 in IEEE-754 format\n            c0 = _mm_round_ps(_mm_mul_ps(c0, _mm_castsi128_ps(quarter)), _MM_FROUND_TO_NEAREST_INT);\n            c1 = _mm_round_ps(_mm_mul_ps(c1, _mm_castsi128_ps(quarter)), _MM_FROUND_TO_NEAREST_INT);\n            c2 = _mm_round_ps(_mm_mul_ps(c2, _mm_castsi128_ps(quarter)), _MM_FROUND_TO_NEAREST_INT);\n            c3 = _mm_round_ps(_mm_mul_ps(c3, _mm_castsi128_ps(quarter)), _MM_FROUND_TO_NEAREST_INT);\n\n            _mm_storeu_ps(&dst[(i + 0) * cols + j], c0);\n            _mm_storeu_ps(&dst[(i + 1) * cols + j], c1);\n            _mm_storeu_ps(&dst[(i + 2) * cols + j], c2);\n            _mm_storeu_ps(&dst[(i + 3) * cols + j], c3);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_25_SSE", "completion": "```c\nvoid matrix_transpose_round_quarter_simd(const float* src, float* dst, size_t rows, size_t cols) {\n    for (size_t i = 0; i < rows; i += 4) {\n        for (size_t j = 0; j < cols; j += 4) {\n            __m128 row0 = _mm_loadu_ps(&src[(j * rows) + i]);\n            __m128 row1 = _mm_loadu_ps(&src[(j * rows) + i + 1]);\n            __m128 row2 = _mm_loadu_ps(&src[(j * rows) + i + 2]);\n            __m128 row3 = _mm_loadu_ps(&src[(j * rows) + i + 3]);\n\n            __m128 tmp0 = _mm_unpacklo_ps(row0, row1);\n            __m128 tmp1 = _mm_unpackhi_ps(row0, row1);\n            __m128 tmp2 = _mm_unpacklo_ps(row2, row3);\n            __m128 tmp3 = _mm_unpackhi_ps(row2, row3);\n\n            row0 = _mm_movelh_ps(tmp0, tmp2);\n            row1 = _mm_movehl_ps(tmp2, tmp0);\n            row2 = _mm_movelh_ps(tmp1, tmp3);\n            row3 = _mm_movehl_ps(tmp3, tmp1);\n\n            __m128 quarter = _mm_set1_ps(0.25f);\n            row0 = _mm_round_ps(_mm_mul_ps(row0, quarter), _MM_FROUND_TO_NEAREST_INT);\n            row1 = _mm_round_ps(_mm_mul_ps(row1, quarter), _MM_FROUND_TO_NEAREST_INT);\n            row2 = _mm_round_ps(_mm_mul_ps(row2, quarter), _MM_FROUND_TO_NEAREST_INT);\n            row3 = _mm_round_ps(_mm_mul_ps(row3, quarter), _MM_FROUND_TO_NEAREST_INT);\n\n            _mm_storeu_ps(&dst[(i * cols) + j], row0);\n            _mm_storeu_ps(&dst[(i * cols) + j + 1], row1);\n            _mm_storeu_ps(&dst[(i * cols) + j + 2], row2);\n            _mm_storeu_ps(&dst[(i * cols) + j + 3], row3);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_26_SSE", "completion": "```c\nvoid tensor3d_sub_round_zero_simd(const float* tensor1, const float* tensor2, float* dst, size_t dim1, size_t dim2, size_t dim3) {\n    for (size_t i = 0; i < dim1*dim2*dim3; i += 4) {\n        __m128 t1 = _mm_loadu_ps(&tensor1[i]);\n        __m128 t2 = _mm_loadu_ps(&tensor2[i]);\n        __m128 result = _mm_sub_ps(t1, t2);\n        __m128 rounded_result = _mm_cvtepi32_ps(_mm_cvttps_epi32(result));\n        _mm_storeu_ps(&dst[i], rounded_result);\n    }\n}\n```  "}
{"task_id": "SimdBench_26_SSE", "completion": "```cpp\nvoid tensor3d_sub_round_zero_simd(const float* tensor1, const float* tensor2, float* dst, size_t dim1, size_t dim2, size_t dim3) {\n    for (size_t i = 0; i < dim1 * dim2 * dim3; i += 4) {\n        __m128 t1 = _mm_loadu_ps(&tensor1[i]);\n        __m128 t2 = _mm_loadu_ps(&tensor2[i]);\n        __m128 result = _mm_sub_ps(t1, t2);\n        __m128 zero = _mm_setzero_ps();\n        __m128 sign_mask = _mm_cmpgt_ps(zero, result);\n        __m128 round_mask = _mm_and_ps(sign_mask, _mm_set1_ps(-0.5f));\n        result = _mm_add_ps(result, round_mask);\n        _mm_storeu_ps(&dst[i], result);\n    }\n}\n```  "}
{"task_id": "SimdBench_26_SSE", "completion": "```cpp\nvoid tensor3d_sub_round_zero_simd(const float* tensor1, const float* tensor2, float* dst, size_t dim1, size_t dim2, size_t dim3) {\n    for (size_t i = 0; i < dim1 * dim2 * dim3; i += 4) {\n        __m128 t1 = _mm_loadu_ps(&tensor1[i]);\n        __m128 t2 = _mm_loadu_ps(&tensor2[i]);\n        __m128 result = _mm_sub_ps(t1, t2);\n        __m128 zero = _mm_setzero_ps();\n        __m128 sign = _mm_cmpgt_ps(result, zero);\n        __m128 rounded = _mm_cvtepi32_ps(_mm_cvttps_epi32(result));\n        __m128 rounded_neg = _mm_cvtepi32_ps(_mm_cvttps_epi32(_mm_sub_ps(zero, result)));\n        __m128 final_result = _mm_blendv_ps(rounded, rounded_neg, sign);\n        _mm_storeu_ps(&dst[i], final_result);\n    }\n}\n```"}
{"task_id": "SimdBench_26_SSE", "completion": "```cpp\nvoid tensor3d_sub_round_zero_simd(const float* tensor1, const float* tensor2, float* dst, size_t dim1, size_t dim2, size_t dim3) {\n    for (size_t i = 0; i < dim1 * dim2 * dim3; i += 4) {\n        __m128 t1 = _mm_loadu_ps(&tensor1[i]);\n        __m128 t2 = _mm_loadu_ps(&tensor2[i]);\n        __m128 result = _mm_sub_ps(t1, t2);\n        __m128 zero = _mm_setzero_ps();\n        __m128 sign = _mm_cmpgt_ps(result, zero);\n        __m128 rounded = _mm_cvtepi32_ps(_mm_cvttps_epi32(result));\n        __m128 final_result = _mm_blendv_ps(_mm_sub_ps(rounded, _mm_set1_ps(1.0f)), rounded, sign);\n        _mm_storeu_ps(&dst[i], final_result);\n    }\n}\n```  "}
{"task_id": "SimdBench_26_SSE", "completion": "```cpp\nvoid tensor3d_sub_round_zero_simd(const float* tensor1, const float* tensor2, float* dst, size_t dim1, size_t dim2, size_t dim3) {\n    for (size_t i = 0; i < dim1 * dim2 * dim3; i += 4) {\n        __m128 t1 = _mm_loadu_ps(&tensor1[i]);\n        __m128 t2 = _mm_loadu_ps(&tensor2[i]);\n        __m128 result = _mm_sub_ps(t1, t2);\n        __m128 zero = _mm_setzero_ps();\n        __m128 mask = _mm_cmpge_ps(result, zero);\n        __m128 rounded = _mm_cvtepi32_ps(_mm_cvttps_epi32(result));\n        __m128 final_result = _mm_blendv_ps(_mm_sub_ps(rounded, _mm_set1_ps(1.0f)), rounded, mask);\n        _mm_storeu_ps(&dst[i], final_result);\n    }\n}\n```  "}
{"task_id": "SimdBench_27_SSE", "completion": "```c\nvoid matrix_hadamard_product_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n) {\n    for (size_t i = 0; i < m*n; i += 2) {\n        __m128d xmm1 = _mm_loadu_pd(&mat1[i]);\n        __m128d xmm2 = _mm_loadu_pd(&mat2[i]);\n        __m128d result = _mm_mul_pd(xmm1, xmm2);\n        _mm_storeu_pd(&dst[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_27_SSE", "completion": "```c\nvoid matrix_hadamard_product_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n) {\n    for (size_t i = 0; i < m*n; i += 2) {\n        __m128d xmm1 = _mm_loadu_pd(&mat1[i]);\n        __m128d xmm2 = _mm_loadu_pd(&mat2[i]);\n        __m128d result = _mm_mul_pd(xmm1, xmm2);\n        _mm_storeu_pd(&dst[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_27_SSE", "completion": "```c\nvoid matrix_hadamard_product_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n) {\n    for (size_t i = 0; i < m*n; i += 2) {\n        __m128d xmm1 = _mm_loadu_pd(&mat1[i]);\n        __m128d xmm2 = _mm_loadu_pd(&mat2[i]);\n        __m128d result = _mm_mul_pd(xmm1, xmm2);\n        _mm_storeu_pd(&dst[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_27_SSE", "completion": "```c\nvoid matrix_hadamard_product_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n) {\n    for (size_t i = 0; i < m*n; i += 2) {\n        __m128d xmm1 = _mm_loadu_pd(&mat1[i]);\n        __m128d xmm2 = _mm_loadu_pd(&mat2[i]);\n        __m128d result = _mm_mul_pd(xmm1, xmm2);\n        _mm_storeu_pd(&dst[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_27_SSE", "completion": "```c\nvoid matrix_hadamard_product_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n) {\n    for (size_t i = 0; i < m * n; i += 2) {\n        __m128d xmm1 = _mm_loadu_pd(&mat1[i]);\n        __m128d xmm2 = _mm_loadu_pd(&mat2[i]);\n        __m128d result = _mm_mul_pd(xmm1, xmm2);\n        _mm_storeu_pd(&dst[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_28_SSE", "completion": "```c\nvoid matrix_vector_mul_simd(const float* mat, const float* vec, float* dst, size_t m, size_t n) {\n    for (size_t i = 0; i < m; ++i) {\n        __m128 sum = _mm_setzero_ps();\n        for (size_t j = 0; j < n; j += 4) {\n            __m128 mat_row = _mm_loadu_ps(&mat[i * n + j]);\n            __m128 vec_vals = _mm_loadu_ps(&vec[j]);\n            sum = _mm_add_ps(sum, _mm_mul_ps(mat_row, vec_vals));\n        }\n        _mm_storeu_ps(&dst[i], sum);\n    }\n}\n```"}
{"task_id": "SimdBench_28_SSE", "completion": "```c\nvoid matrix_vector_mul_simd(const float* mat, const float* vec, float* dst, size_t m, size_t n) {\n    for (size_t i = 0; i < m; ++i) {\n        __m128 sum = _mm_setzero_ps();\n        for (size_t j = 0; j < n; j += 4) {\n            __m128 mat_row = _mm_loadu_ps(&mat[i * n + j]);\n            __m128 vec_values = _mm_loadu_ps(&vec[j]);\n            sum = _mm_add_ps(sum, _mm_mul_ps(mat_row, vec_values));\n        }\n        _mm_storeu_ps(&dst[i], sum);\n    }\n}\n```  "}
{"task_id": "SimdBench_28_SSE", "completion": "```c\nvoid matrix_vector_mul_simd(const float* mat, const float* vec, float* dst, size_t m, size_t n) {\n    for (size_t i = 0; i < m; ++i) {\n        __m128 sum = _mm_setzero_ps();\n        for (size_t j = 0; j < n; j += 4) {\n            __m128 mat_row = _mm_loadu_ps(&mat[i * n + j]);\n            __m128 vec_values = _mm_loadu_ps(&vec[j]);\n            sum = _mm_add_ps(sum, _mm_mul_ps(mat_row, vec_values));\n        }\n        _mm_storeu_ps(&dst[i], sum);\n    }\n}\n```  "}
{"task_id": "SimdBench_28_SSE", "completion": "```c\nvoid matrix_vector_mul_simd(const float* mat, const float* vec, float* dst, size_t m, size_t n) {\n    for (size_t i = 0; i < m; ++i) {\n        __m128 sum = _mm_setzero_ps();\n        for (size_t j = 0; j < n; j += 4) {\n            __m128 mat_row = _mm_loadu_ps(&mat[i * n + j]);\n            __m128 vec_values = _mm_loadu_ps(&vec[j]);\n            sum = _mm_add_ps(sum, _mm_mul_ps(mat_row, vec_values));\n        }\n        float temp[4];\n        _mm_storeu_ps(temp, sum);\n        dst[i] = temp[0] + temp[1] + temp[2] + temp[3];\n    }\n}\n```  "}
{"task_id": "SimdBench_28_SSE", "completion": "```c\nvoid matrix_vector_mul_simd(const float* mat, const float* vec, float* dst, size_t m, size_t n) {\n    for (size_t i = 0; i < m; ++i) {\n        __m128 sum = _mm_setzero_ps();\n        for (size_t j = 0; j < n; j += 4) {\n            __m128 mat_row = _mm_loadu_ps(&mat[i * n + j]);\n            __m128 vec_values = _mm_loadu_ps(&vec[j]);\n            sum = _mm_add_ps(sum, _mm_mul_ps(mat_row, vec_values));\n        }\n        _mm_storeu_ps(&dst[i], sum);\n    }\n}\n```  "}
{"task_id": "SimdBench_29_SSE", "completion": "```c\ndouble matrix_average_simd(const double* mat, size_t m, size_t n) {\n    __m128d sum = _mm_setzero_pd();\n    size_t total_elements = m * n;\n\n    for (size_t i = 0; i < total_elements; i += 2) {\n        __m128d row = _mm_loadu_pd(&mat[i]);\n        sum = _mm_add_pd(sum, row);\n    }\n\n    double result[2];\n    _mm_storeu_pd(result, sum);\n\n    double average = (result[0] + result[1]) / total_elements;\n    return average;\n}\n```  "}
{"task_id": "SimdBench_29_SSE", "completion": "```\ndouble matrix_average_simd(const double* mat, size_t m, size_t n) {\n    __m128d sum = _mm_setzero_pd();\n    size_t total_elements = m * n;\n    size_t remaining_elements = total_elements % 2;\n    \n    for (size_t i = 0; i < total_elements - remaining_elements; i += 2) {\n        __m128d row1 = _mm_loadu_pd(&mat[i]);\n        __m128d row2 = _mm_loadu_pd(&mat[i + 2]);\n        sum = _mm_add_pd(sum, row1);\n        sum = _mm_add_pd(sum, row2);\n    }\n    \n    double sum_array[2];\n    _mm_storeu_pd(sum_array, sum);\n    \n    double average = (sum_array[0] + sum_array[1]) / total_elements;\n    \n    if (remaining_elements == 1) {\n        average += mat[total_elements - 1] / total_elements;\n    }\n    \n    return average;\n}\n```"}
{"task_id": "SimdBench_29_SSE", "completion": "```c\ndouble matrix_average_simd(const double* mat, size_t m, size_t n) {\n    __m128d sum = _mm_setzero_pd();\n    size_t total_elements = m * n;\n\n    for (size_t i = 0; i < total_elements; i += 2) {\n        __m128d values = _mm_loadu_pd(&mat[i]);\n        sum = _mm_add_pd(sum, values);\n    }\n\n    double result[2];\n    _mm_storeu_pd(result, sum);\n\n    double average = (result[0] + result[1]) / total_elements;\n    return average;\n}\n```  "}
{"task_id": "SimdBench_29_SSE", "completion": "```\ndouble matrix_average_simd(const double* mat, size_t m, size_t n) {\n    __m128d sum = _mm_setzero_pd();\n    size_t total_elements = m * n;\n\n    for (size_t i = 0; i < total_elements; i += 2) {\n        __m128d row = _mm_loadu_pd(&mat[i]);\n        sum = _mm_add_pd(sum, row);\n    }\n\n    double result[2];\n    _mm_storeu_pd(result, sum);\n\n    double average = (result[0] + result[1]) / total_elements;\n    return average;\n}\n```"}
{"task_id": "SimdBench_29_SSE", "completion": "```c\ndouble matrix_average_simd(const double* mat, size_t m, size_t n) {\n    __m128d sum = _mm_setzero_pd();\n    size_t total_elements = m * n;\n\n    for (size_t i = 0; i < total_elements; i += 2) {\n        __m128d values = _mm_loadu_pd(&mat[i]);\n        sum = _mm_add_pd(sum, values);\n    }\n\n    double result[2];\n    _mm_storeu_pd(result, sum);\n\n    double average = (result[0] + result[1]) / total_elements;\n    return average;\n}\n```  "}
{"task_id": "SimdBench_30_SSE", "completion": "```cpp\nbool matrix_rows_sorted_verify_simd(const int* matrix, const bool* directions, size_t rows, size_t cols) {\n    for (size_t i = 0; i < rows; ++i) {\n        __m128i prev = _mm_loadu_si128((__m128i*)(matrix + i * cols));\n        bool direction = directions[i];\n        for (size_t j = 4; j < cols; j += 4) {\n            __m128i current = _mm_loadu_si128((__m128i*)(matrix + i * cols + j));\n            __m128i cmp_result;\n            if (direction) {\n                cmp_result = _mm_cmplt_epi32(prev, current);\n            } else {\n                cmp_result = _mm_cmpgt_epi32(prev, current);\n            }\n            if (_mm_movemask_epi8(cmp_result) != 0xFFFF) {\n                return false;\n            }\n            prev = current;\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_30_SSE", "completion": "```cpp\nbool matrix_rows_sorted_verify_simd(const int* matrix, const bool* directions, size_t rows, size_t cols) {\n    for (size_t i = 0; i < rows; ++i) {\n        __m128i prev = _mm_loadu_si128((__m128i*)(matrix + i * cols));\n        for (size_t j = 1; j < cols / 4; ++j) {\n            __m128i current = _mm_loadu_si128((__m128i*)(matrix + i * cols + j * 4));\n            __m128i cmp = _mm_cmpgt_epi32(prev, current);\n            __m128i dir = _mm_set1_epi32(directions[i] ? 0xFFFFFFFF : 0);\n            if (_mm_movemask_epi8(_mm_cmpeq_epi32(cmp, dir)) != 0xFFFF) {\n                return false;\n            }\n            prev = current;\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_30_SSE", "completion": "```cpp\nbool matrix_rows_sorted_verify_simd(const int* matrix, const bool* directions, size_t rows, size_t cols) {\n    for (size_t i = 0; i < rows; ++i) {\n        __m128i prev = _mm_loadu_si128((__m128i*)(matrix + i * cols));\n        bool ascending = directions[i];\n        for (size_t j = 4; j < cols; j += 4) {\n            __m128i curr = _mm_loadu_si128((__m128i*)(matrix + i * cols + j));\n            if (ascending) {\n                __m128i mask = _mm_cmplt_epi32(prev, curr);\n                if (_mm_movemask_epi8(mask) != 0xFFFF) {\n                    return false;\n                }\n            } else {\n                __m128i mask = _mm_cmpgt_epi32(prev, curr);\n                if (_mm_movemask_epi8(mask) != 0xFFFF) {\n                    return false;\n                }\n            }\n            prev = curr;\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_30_SSE", "completion": "```cpp\nbool matrix_rows_sorted_verify_simd(const int* matrix, const bool* directions, size_t rows, size_t cols) {\n    for (size_t i = 0; i < rows; ++i) {\n        __m128i prev = _mm_loadu_si128((__m128i*)(matrix + i * cols));\n        for (size_t j = 1; j < cols / 4; ++j) {\n            __m128i current = _mm_loadu_si128((__m128i*)(matrix + i * cols + j * 4));\n            __m128i cmp = _mm_cmpgt_epi32(prev, current);\n            __m128i dir = _mm_set1_epi32(directions[i] ? 0xFFFFFFFF : 0);\n            if (_mm_movemask_epi8(_mm_cmpeq_epi32(cmp, dir)) != 0xFFFF) {\n                return false;\n            }\n            prev = current;\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_30_SSE", "completion": "```cpp\nbool matrix_rows_sorted_verify_simd(const int* matrix, const bool* directions, size_t rows, size_t cols) {\n    for (size_t i = 0; i < rows; ++i) {\n        __m128i prev = _mm_loadu_si128((__m128i*)(matrix + i * cols));\n        bool ascending = directions[i];\n        \n        for (size_t j = 4; j < cols; j += 4) {\n            __m128i curr = _mm_loadu_si128((__m128i*)(matrix + i * cols + j));\n            __m128i cmp = ascending ? _mm_cmplt_epi32(prev, curr) : _mm_cmpgt_epi32(prev, curr);\n            if (_mm_movemask_epi8(cmp) != 0xFFFF) {\n                return false;\n            }\n            prev = curr;\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_31_SSE", "completion": "```c\nvoid nearest_multiple_simd(const int16_t* src, int16_t* dst, uint8_t base, size_t length) {\n    __m128i base_vec = _mm_set1_epi16(base);\n    __m128i zero_vec = _mm_setzero_si128();\n    __m128i max_val_vec = _mm_set1_epi16(INT16_MAX);\n\n    for (size_t i = 0; i < length; i += 8) {\n        __m128i src_vec = _mm_loadu_si128((__m128i*)(src + i));\n\n        __m128i div_result = _mm_div_epi16(src_vec, base_vec);\n        __m128i rounded_result = _mm_mullo_epi16(div_result, base_vec);\n\n        __m128i mask = _mm_cmplt_epi16(rounded_result, src_vec);\n        __m128i final_result = _mm_blendv_epi8(rounded_result, _mm_subs_epu16(rounded_result, base_vec), mask);\n        final_result = _mm_min_epi16(final_result, max_val_vec);\n\n        _mm_storeu_si128((__m128i*)(dst + i), final_result);\n    }\n}\n```"}
{"task_id": "SimdBench_31_SSE", "completion": "```c\nvoid nearest_multiple_simd(const int16_t* src, int16_t* dst, uint8_t base, size_t length) {\n    __m128i base_v = _mm_set1_epi16(base);\n    __m128i zero = _mm_setzero_si128();\n    \n    for (size_t i = 0; i < length; i += 8) {\n        __m128i src_v = _mm_loadu_si128((__m128i*)(src + i));\n        \n        __m128i div = _mm_div_epi16(src_v, base_v);\n        __m128i mul = _mm_mullo_epi16(base_v, div);\n        \n        __m128i cmp = _mm_cmplt_epi16(mul, src_v);\n        __m128i result = _mm_blendv_epi8(mul, _mm_sub_epi16(mul, base_v), cmp);\n        \n        _mm_storeu_si128((__m128i*)(dst + i), result);\n    }\n}\n```"}
{"task_id": "SimdBench_31_SSE", "completion": "```c\nvoid nearest_multiple_simd(const int16_t* src, int16_t* dst, uint8_t base, size_t length) {\n    __m128i base_vec = _mm_set1_epi16(base);\n    __m128i zero_vec = _mm_setzero_si128();\n    \n    for (size_t i = 0; i < length; i += 8) {\n        __m128i src_vec = _mm_loadu_si128((__m128i*)(src + i));\n        \n        __m128i div_result = _mm_div_epi16(src_vec, base_vec);\n        __m128i mul_result = _mm_mullo_epi16(base_vec, div_result);\n        \n        __m128i cmp_result = _mm_cmplt_epi16(mul_result, src_vec);\n        __m128i mask = _mm_and_si128(cmp_result, base_vec);\n        \n        __m128i final_result = _mm_sub_epi16(mul_result, mask);\n        \n        _mm_storeu_si128((__m128i*)(dst + i), final_result);\n    }\n}\n```  "}
{"task_id": "SimdBench_31_SSE", "completion": "```c\nvoid nearest_multiple_simd(const int16_t* src, int16_t* dst, uint8_t base, size_t length) {\n    __m128i base_vec = _mm_set1_epi16(base);\n    __m128i zero_vec = _mm_setzero_si128();\n\n    for (size_t i = 0; i < length; i += 8) {\n        __m128i src_vec = _mm_loadu_si128((__m128i*)(src + i));\n        __m128i div_result = _mm_div_epi16(src_vec, base_vec);\n        __m128i mul_result = _mm_mullo_epi16(base_vec, div_result);\n        __m128i cmp_result = _mm_cmpgt_epi16(src_vec, mul_result);\n        __m128i final_result = _mm_blendv_epi8(mul_result, _mm_sub_epi16(mul_result, base_vec), cmp_result);\n        _mm_storeu_si128((__m128i*)(dst + i), final_result);\n    }\n}\n```  "}
{"task_id": "SimdBench_31_SSE", "completion": "```c\nvoid nearest_multiple_simd(const int16_t* src, int16_t* dst, uint8_t base, size_t length) {\n    __m128i base_vec = _mm_set1_epi16(base);\n    __m128i zero_vec = _mm_setzero_si128();\n    __m128i max_val = _mm_set1_epi16(INT16_MAX);\n\n    for (size_t i = 0; i < length; i += 8) {\n        __m128i src_vec = _mm_loadu_si128((__m128i*)(src + i));\n        __m128i div_result = _mm_div_epi16(src_vec, base_vec);\n        __m128i mul_result = _mm_mullo_epi16(base_vec, div_result);\n        __m128i cmp_result = _mm_cmpgt_epi16(src_vec, mul_result);\n        __m128i final_result = _mm_blendv_epi8(mul_result, _mm_subs_epu16(mul_result, base_vec), cmp_result);\n        __m128i clamped_result = _mm_min_epi16(final_result, max_val);\n        _mm_storeu_si128((__m128i*)(dst + i), clamped_result);\n    }\n}\n```  "}
{"task_id": "SimdBench_32_SSE", "completion": "```cpp\nbool matrix_has_row_simd(const double* matrix, const double* vector, size_t rows, size_t cols) {\n    for (size_t i = 0; i < rows; ++i) {\n        const double* row = matrix + i * cols;\n        __m128d sum = _mm_setzero_pd();\n        for (size_t j = 0; j < cols; j += 2) {\n            __m128d a = _mm_loadu_pd(row + j);\n            __m128d b = _mm_loadu_pd(vector + j);\n            __m128d cmp = _mm_cmpeq_pd(a, b);\n            sum = _mm_or_pd(sum, cmp);\n        }\n        if (_mm_movemask_pd(sum) == 3) {\n            return true;\n        }\n    }\n    return false;\n}\n```  "}
{"task_id": "SimdBench_32_SSE", "completion": "```cpp\nbool matrix_has_row_simd(const double* matrix, const double* vector, size_t rows, size_t cols) {\n    __m128d target = _mm_loadu_pd(vector);\n    for (size_t i = 0; i < rows; ++i) {\n        const double* row = matrix + i * cols;\n        bool match = true;\n        for (size_t j = 0; j < cols; j += 2) {\n            __m128d row_data = _mm_loadu_pd(row + j);\n            __m128d cmp = _mm_cmpeq_pd(row_data, target);\n            int mask = _mm_movemask_pd(cmp);\n            if (mask != 3) {\n                match = false;\n                break;\n            }\n        }\n        if (match) {\n            return true;\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_32_SSE", "completion": "```cpp\nbool matrix_has_row_simd(const double* matrix, const double* vector, size_t rows, size_t cols) {\n    for (size_t i = 0; i < rows; i++) {\n        const double* row = matrix + i * cols;\n        __m128d sum = _mm_setzero_pd();\n        for (size_t j = 0; j < cols; j += 2) {\n            __m128d a = _mm_loadu_pd(row + j);\n            __m128d b = _mm_loadu_pd(vector + j);\n            __m128d cmp = _mm_cmpeq_pd(a, b);\n            sum = _mm_or_pd(sum, cmp);\n        }\n        if (_mm_movemask_pd(sum) == 3) {\n            return true;\n        }\n    }\n    return false;\n}\n```  "}
{"task_id": "SimdBench_32_SSE", "completion": "```cpp\nbool matrix_has_row_simd(const double* matrix, const double* vector, size_t rows, size_t cols) {\n    for (size_t i = 0; i < rows; ++i) {\n        const double* row = matrix + i * cols;\n        __m128d sum = _mm_setzero_pd();\n        for (size_t j = 0; j < cols; j += 2) {\n            __m128d a = _mm_loadu_pd(row + j);\n            __m128d b = _mm_loadu_pd(vector + j);\n            __m128d cmp = _mm_cmpeq_pd(a, b);\n            sum = _mm_or_pd(sum, cmp);\n        }\n        if (_mm_movemask_pd(sum) == 3) {\n            return true;\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_32_SSE", "completion": "```cpp\nbool matrix_has_row_simd(const double* matrix, const double* vector, size_t rows, size_t cols) {\n    for (size_t i = 0; i < rows; ++i) {\n        const double* row = matrix + i * cols;\n        __m128d sum = _mm_setzero_pd();\n        for (size_t j = 0; j < cols; j += 2) {\n            __m128d a = _mm_loadu_pd(row + j);\n            __m128d b = _mm_loadu_pd(vector + j);\n            __m128d cmp = _mm_cmpeq_pd(a, b);\n            sum = _mm_or_pd(sum, cmp);\n        }\n        if (_mm_movemask_pd(sum) == 3) {\n            return true;\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_33_SSE", "completion": "```c\nsize_t tensor_4d_equal_count_simd(const uint8_t* A, const uint8_t* B, const size_t dims[4]) {\n    size_t equalCount = 0;\n    size_t totalSize = dims[0] * dims[1] * dims[2] * dims[3];\n    size_t simdSize = totalSize / 16;\n    \n    __m128i* ptrA = (__m128i*)A;\n    __m128i* ptrB = (__m128i*)B;\n    \n    for (size_t i = 0; i < simdSize; i++) {\n        __m128i vecA = _mm_loadu_si128(ptrA);\n        __m128i vecB = _mm_loadu_si128(ptrB);\n        \n        __m128i cmpResult = _mm_cmpeq_epi8(vecA, vecB);\n        \n        equalCount += _mm_popcnt_u32(_mm_movemask_epi8(cmpResult));\n        \n        ptrA++;\n        ptrB++;\n    }\n    \n    for (size_t i = simdSize * 16; i < totalSize; i++) {\n        if (A[i] == B[i]) {\n            equalCount++;\n        }\n    }\n    \n    return equalCount;\n}\n```"}
{"task_id": "SimdBench_33_SSE", "completion": "```c\nsize_t tensor_4d_equal_count_simd(const uint8_t* A, const uint8_t* B, const size_t dims[4]) {\n    size_t equal_count = 0;\n    size_t total_elements = dims[0] * dims[1] * dims[2] * dims[3];\n    size_t simd_iterations = total_elements / 16;\n\n    __m128i* ptrA = (__m128i*)A;\n    __m128i* ptrB = (__m128i*)B;\n\n    for (size_t i = 0; i < simd_iterations; i++) {\n        __m128i vecA = _mm_loadu_si128(ptrA);\n        __m128i vecB = _mm_loadu_si128(ptrB);\n        __m128i cmp = _mm_cmpeq_epi8(vecA, vecB);\n        equal_count += _mm_popcnt_u32(_mm_movemask_epi8(cmp));\n\n        ptrA++;\n        ptrB++;\n    }\n\n    for (size_t i = simd_iterations * 16; i < total_elements; i++) {\n        if (A[i] == B[i]) {\n            equal_count++;\n        }\n    }\n\n    return equal_count;\n}\n```  "}
{"task_id": "SimdBench_33_SSE", "completion": "```c\nsize_t tensor_4d_equal_count_simd(const uint8_t* A, const uint8_t* B, const size_t dims[4]) {\n    size_t count = 0;\n    size_t total_elements = dims[0] * dims[1] * dims[2] * dims[3];\n    size_t simd_elements = total_elements / 16;\n\n    __m128i* ptrA = (__m128i*)A;\n    __m128i* ptrB = (__m128i*)B;\n\n    for (size_t i = 0; i < simd_elements; i++) {\n        __m128i vecA = _mm_loadu_si128(ptrA);\n        __m128i vecB = _mm_loadu_si128(ptrB);\n\n        __m128i cmp = _mm_cmpeq_epi8(vecA, vecB);\n        int mask = _mm_movemask_epi8(cmp);\n\n        count += _mm_popcnt_u32(mask);\n\n        ptrA++;\n        ptrB++;\n    }\n\n    for (size_t i = simd_elements * 16; i < total_elements; i++) {\n        if (A[i] == B[i]) {\n            count++;\n        }\n    }\n\n    return count;\n}\n```  "}
{"task_id": "SimdBench_33_SSE", "completion": "```cpp\nsize_t tensor_4d_equal_count_simd(const uint8_t* A, const uint8_t* B, const size_t dims[4]) {\n    size_t count = 0;\n    size_t total_elements = dims[0] * dims[1] * dims[2] * dims[3];\n    size_t simd_iterations = total_elements / 16;\n\n    __m128i* ptrA = (__m128i*)A;\n    __m128i* ptrB = (__m128i*)B;\n\n    for (size_t i = 0; i < simd_iterations; ++i) {\n        __m128i a = _mm_loadu_si128(ptrA);\n        __m128i b = _mm_loadu_si128(ptrB);\n        __m128i equal = _mm_cmpeq_epi8(a, b);\n        count += _mm_popcnt_u32(_mm_movemask_epi8(equal));\n\n        ptrA++;\n        ptrB++;\n    }\n\n    for (size_t i = simd_iterations * 16; i < total_elements; ++i) {\n        if (A[i] == B[i]) {\n            count++;\n        }\n    }\n\n    return count;\n}\n```  "}
{"task_id": "SimdBench_33_SSE", "completion": "```cpp\nsize_t tensor_4d_equal_count_simd(const uint8_t* A, const uint8_t* B, const size_t dims[4]) {\n    size_t count = 0;\n    size_t total_elements = dims[0] * dims[1] * dims[2] * dims[3];\n    size_t remaining_elements = total_elements;\n\n    __m128i zero = _mm_setzero_si128();\n\n    for (size_t i = 0; i < total_elements; i += 16) {\n        __m128i a = _mm_loadu_si128((__m128i*)(A + i));\n        __m128i b = _mm_loadu_si128((__m128i*)(B + i));\n\n        __m128i cmp = _mm_cmpeq_epi8(a, b);\n        __m128i cmp_packed = _mm_packs_epi16(cmp, zero);\n        __m128i cmp_packed_abs = _mm_abs_epi8(cmp_packed);\n        int mask = _mm_movemask_epi8(cmp_packed_abs);\n\n        count += _mm_popcnt_u32(mask);\n        remaining_elements -= 16;\n    }\n\n    for (size_t i = total_elements - remaining_elements; i < total_elements; ++i) {\n        if (A[i] == B[i]) {\n            count++;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_34_SSE", "completion": "```c\nvoid axm_abs_simd(size_t length, const int64_t a, const int64_t *x, int64_t *y) {\n    __m128i scalar = _mm_set1_epi64x(a);\n    for (size_t i = 0; i < length; i += 2) {\n        __m128i vec_x = _mm_loadu_si128((__m128i*)&x[i]);\n        __m128i vec_result = _mm_abs_epi64(_mm_sub_epi64(_mm_mul_epi32(scalar, vec_x), vec_x));\n        _mm_storeu_si128((__m128i*)&y[i], vec_result);\n    }\n}\n```"}
{"task_id": "SimdBench_34_SSE", "completion": "```\nvoid axm_abs_simd(size_t length, const int64_t a, const int64_t *x, int64_t *y) {\n    __m128i vec_a = _mm_set1_epi64x(a);\n    for (size_t i = 0; i < length; i += 2) {\n        __m128i vec_x = _mm_loadu_si128((__m128i*)(x + i));\n        __m128i vec_result = _mm_abs_epi64(_mm_sub_epi64(_mm_mul_epu32(vec_a, vec_x), _mm_setzero_si128()));\n        _mm_storeu_si128((__m128i*)(y + i), vec_result);\n    }\n}\n```"}
{"task_id": "SimdBench_34_SSE", "completion": "```\nvoid axm_abs_simd(size_t length, const int64_t a, const int64_t *x, int64_t *y) {\n    __m128i scalar_a = _mm_set1_epi64x(a);\n    for (size_t i = 0; i < length; i += 2) {\n        __m128i vec_x = _mm_loadu_si128((__m128i*)&x[i]);\n        __m128i vec_y = _mm_abs_epi64(_mm_sub_epi64(_mm_mul_epi32(scalar_a, vec_x), vec_x));\n        _mm_storeu_si128((__m128i*)&y[i], vec_y);\n    }\n}\n```"}
{"task_id": "SimdBench_34_SSE", "completion": "```\nvoid axm_abs_simd(size_t length, const int64_t a, const int64_t *x, int64_t *y) {\n    __m128i vec_a = _mm_set1_epi64x(a);\n    for (size_t i = 0; i < length; i += 2) {\n        __m128i vec_x = _mm_loadu_si128((__m128i*)&x[i]);\n        __m128i vec_result = _mm_abs_epi64(_mm_sub_epi64(_mm_mul_epi32(vec_a, vec_x), vec_x));\n        _mm_storeu_si128((__m128i*)&y[i], vec_result);\n    }\n}\n```"}
{"task_id": "SimdBench_34_SSE", "completion": "```\nvoid axm_abs_simd(size_t length, const int64_t a, const int64_t *x, int64_t *y) {\n    __m128i scalar_a = _mm_set1_epi64x(a);\n    for (size_t i = 0; i < length; i += 2) {\n        __m128i vec_x = _mm_loadu_si128((__m128i*)&x[i]);\n        __m128i vec_abs = _mm_abs_epi64(vec_x);\n        __m128i result = _mm_sub_epi64(_mm_mullo_epi64(scalar_a, vec_x), vec_abs);\n        _mm_storeu_si128((__m128i*)&y[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_35_SSE", "completion": "```c\ntypedef struct {\n    int16_t min_num;\n    int16_t max_num;\n} MinMaxPair;\n\nMinMaxPair min_max_pair_simd(const int16_t* vec, size_t length) {\n    __m128i min_max = _mm_set1_epi16(vec[0]);\n\n    for (size_t i = 1; i < length; i += 8) {\n        __m128i data = _mm_loadu_si128((__m128i*)(vec + i));\n        __m128i min_data = _mm_min_epi16(min_max, data);\n        __m128i max_data = _mm_max_epi16(min_max, data);\n        min_max = _mm_unpacklo_epi64(min_data, max_data);\n    }\n\n    int16_t result[8];\n    _mm_storeu_si128((__m128i*)result, min_max);\n\n    MinMaxPair result_pair;\n    result_pair.min_num = result[0];\n    result_pair.max_num = result[1];\n\n    for (int i = 2; i < 8; i++) {\n        if (result[i] < result_pair.min_num) {\n            result_pair.min_num = result[i];\n        }\n        if (result[i] > result_pair.max_num) {\n            result_pair.max_num = result[i];\n        }\n    }\n\n    return result_pair;\n}\n```"}
{"task_id": "SimdBench_35_SSE", "completion": "```c\ntypedef struct {\n    int16_t min_num;\n    int16_t max_num;\n} MinMaxPair;\n\nMinMaxPair min_max_pair_simd(const int16_t* vec, size_t length) {\n    __m128i min_val = _mm_set1_epi16(INT16_MAX);\n    __m128i max_val = _mm_set1_epi16(INT16_MIN);\n\n    for (size_t i = 0; i < length; i += 8) {\n        __m128i vec_data = _mm_loadu_si128((__m128i*)&vec[i]);\n        \n        min_val = _mm_min_epi16(min_val, vec_data);\n        max_val = _mm_max_epi16(max_val, vec_data);\n    }\n\n    int16_t min_result[8], max_result[8];\n    _mm_storeu_si128((__m128i*)min_result, min_val);\n    _mm_storeu_si128((__m128i*)max_result, max_val);\n\n    int16_t min_num = min_result[0];\n    int16_t max_num = max_result[0];\n\n    for (int i = 1; i < 8; i++) {\n        if (min_result[i] < min_num) min_num = min_result[i];\n        if (max_result[i] > max_num) max_num = max_result[i];\n    }\n\n    return (MinMaxPair){min_num, max_num};\n}\n```  "}
{"task_id": "SimdBench_35_SSE", "completion": "```c\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\ntypedef struct {\n    int16_t min_num;\n    int16_t max_num;\n} MinMaxPair;\n\nMinMaxPair min_max_pair_simd(const int16_t* vec, size_t length) {\n    __m128i min_val = _mm_set1_epi16(INT16_MAX);\n    __m128i max_val = _mm_set1_epi16(INT16_MIN);\n\n    for (size_t i = 0; i < length; i += 8) {\n        __m128i vec_data = _mm_loadu_si128((__m128i*)&vec[i]);\n\n        min_val = _mm_min_epi16(min_val, vec_data);\n        max_val = _mm_max_epi16(max_val, vec_data);\n    }\n\n    int16_t min_array[8], max_array[8];\n    _mm_storeu_si128((__m128i*)min_array, min_val);\n    _mm_storeu_si128((__m128i*)max_array, max_val);\n\n    int16_t min_num = min_array[0], max_num = max_array[0];\n    for (int i = 1; i < 8; i++) {\n        if (min_array[i] < min_num) min_num = min_array[i];\n        if (max_array[i] > max_num) max_num = max_array[i];\n    }\n\n    MinMaxPair result;\n    result.min_num = min_num;\n    result.max_num = max_num;\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_35_SSE", "completion": "```c\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\ntypedef struct {\n    int16_t min_num;\n    int16_t max_num;\n} MinMaxPair;\n\nMinMaxPair min_max_pair_simd(const int16_t* vec, size_t length) {\n    __m128i min_val = _mm_set1_epi16(INT16_MAX);\n    __m128i max_val = _mm_set1_epi16(INT16_MIN);\n\n    for (size_t i = 0; i < length; i += 8) {\n        __m128i vec_data = _mm_loadu_si128((__m128i*)(vec + i));\n\n        min_val = _mm_min_epi16(min_val, vec_data);\n        max_val = _mm_max_epi16(max_val, vec_data);\n    }\n\n    int16_t min_result[8], max_result[8];\n    _mm_storeu_si128((__m128i*)min_result, min_val);\n    _mm_storeu_si128((__m128i*)max_result, max_val);\n\n    int16_t min_num = min_result[0], max_num = max_result[0];\n    for (int i = 1; i < 8; i++) {\n        if (min_result[i] < min_num) min_num = min_result[i];\n        if (max_result[i] > max_num) max_num = max_result[i];\n    }\n\n    return (MinMaxPair){min_num, max_num};\n}\n```"}
{"task_id": "SimdBench_35_SSE", "completion": "```c\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\ntypedef struct {\n    int16_t min_num;\n    int16_t max_num;\n} MinMaxPair;\n\nMinMaxPair min_max_pair_simd(const int16_t* vec, size_t length) {\n    __m128i min_val = _mm_set1_epi16(INT16_MAX);\n    __m128i max_val = _mm_set1_epi16(INT16_MIN);\n\n    for (size_t i = 0; i < length; i += 8) {\n        __m128i vec_data = _mm_loadu_si128((__m128i*)(vec + i));\n\n        min_val = _mm_min_epi16(min_val, vec_data);\n        max_val = _mm_max_epi16(max_val, vec_data);\n    }\n\n    int16_t min_result[8], max_result[8];\n    _mm_storeu_si128((__m128i*)min_result, min_val);\n    _mm_storeu_si128((__m128i*)max_result, max_val);\n\n    int16_t min_num = min_result[0], max_num = max_result[0];\n    for (int i = 1; i < 8; i++) {\n        min_num = (min_result[i] < min_num) ? min_result[i] : min_num;\n        max_num = (max_result[i] > max_num) ? max_result[i] : max_num;\n    }\n\n    MinMaxPair result = {min_num, max_num};\n    return result;\n}\n```"}
{"task_id": "SimdBench_36_SSE", "completion": "```cpp\nbool matrix_rows_strictly_increasing_simd(const int* matrix, size_t rows, size_t cols) {\n    if (rows == 0) {\n        return false;\n    }\n\n    for (size_t i = 0; i < rows; ++i) {\n        const int* row = matrix + i * cols;\n        __m128i prev_values = _mm_loadu_si128((__m128i*)row);\n\n        for (size_t j = 4; j < cols; j += 4) {\n            __m128i current_values = _mm_loadu_si128((__m128i*)(row + j));\n            __m128i cmp_result = _mm_cmpgt_epi32(current_values, prev_values);\n            if (_mm_movemask_epi8(cmp_result) != 0xFFFF) {\n                return false;\n            }\n            prev_values = current_values;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_36_SSE", "completion": "```\nbool matrix_rows_strictly_increasing_simd(const int* matrix, size_t rows, size_t cols) {\n    if (rows == 0 || cols == 0) {\n        return false;\n    }\n\n    for (size_t i = 0; i < rows; ++i) {\n        const int* row = matrix + i * cols;\n        __m128i prev_values = _mm_loadu_si128((__m128i*)row);\n\n        for (size_t j = 4; j < cols; j += 4) {\n            __m128i current_values = _mm_loadu_si128((__m128i*)(row + j));\n            __m128i cmp_result = _mm_cmpgt_epi32(current_values, prev_values);\n            if (_mm_movemask_epi8(cmp_result) != 0xFFFF) {\n                return false;\n            }\n            prev_values = current_values;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_36_SSE", "completion": "```\nbool matrix_rows_strictly_increasing_simd(const int* matrix, size_t rows, size_t cols) {\n    if (rows == 0) {\n        return false;\n    }\n\n    for (size_t i = 0; i < rows; ++i) {\n        const int* row = matrix + i * cols;\n        __m128i prev_values = _mm_loadu_si128((__m128i*)row);\n\n        for (size_t j = 4; j < cols; j += 4) {\n            __m128i current_values = _mm_loadu_si128((__m128i*)(row + j));\n            __m128i cmp_result = _mm_cmpgt_epi32(current_values, prev_values);\n            int mask = _mm_movemask_epi8(cmp_result);\n            if (mask != 0xFFFF) {\n                return false;\n            }\n            prev_values = current_values;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_36_SSE", "completion": "```\nbool matrix_rows_strictly_increasing_simd(const int* matrix, size_t rows, size_t cols) {\n    if (rows == 0) {\n        return false;\n    }\n\n    for (size_t i = 0; i < rows; ++i) {\n        __m128i prev_row = _mm_loadu_si128((__m128i*)(matrix + i * cols));\n        for (size_t j = 1; j < cols; ++j) {\n            __m128i curr_row = _mm_loadu_si128((__m128i*)(matrix + i * cols + j));\n            __m128i cmp = _mm_cmpgt_epi32(curr_row, prev_row);\n            if (_mm_movemask_epi8(cmp) != 0xFFFF) {\n                return false;\n            }\n            prev_row = curr_row;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_36_SSE", "completion": "```\nbool matrix_rows_strictly_increasing_simd(const int* matrix, size_t rows, size_t cols) {\n    if (rows == 0) {\n        return false;\n    }\n\n    for (size_t i = 0; i < rows; ++i) {\n        __m128i prev_row = _mm_loadu_si128((__m128i*)(matrix + i * cols));\n        for (size_t j = 1; j < cols; ++j) {\n            __m128i curr_row = _mm_loadu_si128((__m128i*)(matrix + i * cols + j));\n            __m128i cmp = _mm_cmpgt_epi32(curr_row, prev_row);\n            if (_mm_movemask_epi8(cmp) != 0xFFFF) {\n                return false;\n            }\n            prev_row = curr_row;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_37_SSE", "completion": "```cpp\nbool matrix_blocks_equal_simd(const int* matrix, size_t block_size, size_t rows, size_t cols) {\n    if (rows % block_size != 0 || cols % block_size != 0) {\n        return false;\n    }\n\n    for (size_t i = 0; i < rows; i += block_size) {\n        for (size_t j = 0; j < cols; j += block_size) {\n            const int* block = matrix + i * cols + j;\n            __m128i first_block = _mm_loadu_si128((__m128i*)block);\n\n            for (size_t k = 0; k < block_size; ++k) {\n                for (size_t l = 0; l < block_size; l += 4) {\n                    __m128i current_block = _mm_loadu_si128((__m128i*)(block + k * cols + l));\n                    if (!_mm_movemask_epi8(_mm_cmpeq_epi32(first_block, current_block))) {\n                        return false;\n                    }\n                }\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_37_SSE", "completion": "```cpp\nbool matrix_blocks_equal_simd(const int* matrix, size_t block_size, size_t rows, size_t cols) {\n    if (rows % block_size != 0 || cols % block_size != 0) {\n        return false;\n    }\n\n    const size_t block_elements = block_size * block_size;\n    const size_t block_bytes = block_elements * sizeof(int);\n\n    __m128i first_block = _mm_loadu_si128((__m128i*)matrix);\n\n    for (size_t i = 0; i < rows; i += block_size) {\n        for (size_t j = 0; j < cols; j += block_size) {\n            const int* block_start = matrix + i * cols + j;\n            __m128i block = _mm_loadu_si128((__m128i*)block_start);\n\n            if (!_mm_test_all_ones(_mm_cmpeq_epi32(first_block, block))) {\n                return false;\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_37_SSE", "completion": "```cpp\nbool matrix_blocks_equal_simd(const int* matrix, size_t block_size, size_t rows, size_t cols) {\n    if (rows % block_size != 0 || cols % block_size != 0) {\n        return false;\n    }\n\n    for (size_t i = 0; i < rows; i += block_size) {\n        for (size_t j = 0; j < cols; j += block_size) {\n            const int* block = matrix + i * cols + j;\n            const __m128i first_block = _mm_loadu_si128((__m128i*)block);\n\n            for (size_t ii = 0; ii < block_size; ++ii) {\n                for (size_t jj = 0; jj < block_size; jj += 4) {\n                    const __m128i current_block = _mm_loadu_si128((__m128i*)(block + ii * cols + jj));\n                    if (!_mm_movemask_epi8(_mm_cmpeq_epi32(first_block, current_block))) {\n                        return false;\n                    }\n                }\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_37_SSE", "completion": "```cpp\nbool matrix_blocks_equal_simd(const int* matrix, size_t block_size, size_t rows, size_t cols) {\n    if (rows % block_size != 0 || cols % block_size != 0) {\n        return false;\n    }\n\n    for (size_t i = 0; i < rows; i += block_size) {\n        for (size_t j = 0; j < cols; j += block_size) {\n            const int* block_start = matrix + i * cols + j;\n            __m128i first_block = _mm_loadu_si128((__m128i*)block_start);\n\n            for (size_t k = 0; k < block_size; ++k) {\n                for (size_t l = 0; l < block_size; l += 4) {\n                    __m128i current_block = _mm_loadu_si128((__m128i*)(block_start + k * cols + l));\n                    if (!_mm_movemask_epi8(_mm_cmpeq_epi32(first_block, current_block)) == 0xFFFF) {\n                        return false;\n                    }\n                }\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_37_SSE", "completion": "```cpp\nbool matrix_blocks_equal_simd(const int* matrix, size_t block_size, size_t rows, size_t cols) {\n    if (rows % block_size != 0 || cols % block_size != 0) {\n        return false;\n    }\n\n    const size_t block_elements = block_size * block_size;\n    const size_t block_count = (rows / block_size) * (cols / block_size);\n\n    __m128i first_block = _mm_loadu_si128((__m128i*)matrix);\n\n    for (size_t i = 1; i < block_count; ++i) {\n        __m128i current_block = _mm_loadu_si128((__m128i*)(matrix + i * block_elements));\n        if (!_mm_test_all_ones(_mm_cmpeq_epi32(first_block, current_block))) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```  "}
{"task_id": "SimdBench_38_SSE", "completion": "```cpp\nbool vector_block_equal_simd(const double* vec, double tolerance, size_t length, size_t block_size) {\n    if (length < block_size || length % block_size != 0) {\n        return false;\n    }\n\n    __m128d tolerance_vec = _mm_set1_pd(tolerance);\n    size_t num_blocks = length / block_size;\n\n    __m128d first_block = _mm_loadu_pd(&vec[0]);\n    for (size_t i = 1; i < num_blocks; ++i) {\n        __m128d block = _mm_loadu_pd(&vec[i * block_size]);\n        __m128d diff = _mm_sub_pd(first_block, block);\n        __m128d abs_diff = _mm_andnot_pd(_mm_set1_pd(-0.0), diff);\n        __m128d cmp = _mm_cmple_pd(abs_diff, tolerance_vec);\n        int mask = _mm_movemask_pd(cmp);\n        if (mask != 3) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```  "}
{"task_id": "SimdBench_38_SSE", "completion": "```cpp\nbool vector_block_equal_simd(const double* vec, double tolerance, size_t length, size_t block_size) {\n    if (length < block_size || length % block_size != 0) {\n        return false;\n    }\n\n    __m128d first_block = _mm_loadu_pd(vec);\n    __m128d tolerance_vec = _mm_set1_pd(tolerance);\n\n    for (size_t i = block_size; i < length; i += block_size) {\n        __m128d block = _mm_loadu_pd(vec + i);\n        __m128d diff = _mm_sub_pd(first_block, block);\n        __m128d abs_diff = _mm_andnot_pd(_mm_set1_pd(-0.0), diff);\n        __m128d cmp = _mm_cmpgt_pd(abs_diff, tolerance_vec);\n        if (_mm_movemask_pd(cmp) != 0) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```  "}
{"task_id": "SimdBench_38_SSE", "completion": "```cpp\nbool vector_block_equal_simd(const double* vec, double tolerance, size_t length, size_t block_size) {\n    if (length < block_size || length % block_size != 0) {\n        return false;\n    }\n\n    const __m128d tolerance_vec = _mm_set1_pd(tolerance);\n    const size_t num_blocks = length / block_size;\n    const size_t elements_per_block = block_size / 2;\n\n    __m128d first_block = _mm_loadu_pd(&vec[0]);\n    for (size_t i = 1; i < num_blocks; ++i) {\n        __m128d block = _mm_loadu_pd(&vec[i * elements_per_block]);\n        __m128d diff = _mm_sub_pd(first_block, block);\n        __m128d abs_diff = _mm_andnot_pd(_mm_set1_pd(-0.0), diff);\n        __m128d cmp = _mm_cmple_pd(abs_diff, tolerance_vec);\n        int mask = _mm_movemask_pd(cmp);\n        if (mask != 3) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_38_SSE", "completion": "```cpp\nbool vector_block_equal_simd(const double* vec, double tolerance, size_t length, size_t block_size) {\n    if (length < block_size || block_size % 2 != 0) {\n        return false;\n    }\n\n    __m128d first_block = _mm_loadu_pd(vec);\n    for (size_t i = block_size; i + block_size <= length; i += block_size) {\n        __m128d block = _mm_loadu_pd(vec + i);\n        __m128d diff = _mm_sub_pd(first_block, block);\n        __m128d abs_diff = _mm_andnot_pd(_mm_set1_pd(-0.0), diff);\n        __m128d cmp = _mm_cmple_pd(abs_diff, _mm_set1_pd(tolerance));\n        if (_mm_movemask_pd(cmp) != 3) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```  "}
{"task_id": "SimdBench_38_SSE", "completion": "```cpp\nbool vector_block_equal_simd(const double* vec, double tolerance, size_t length, size_t block_size) {\n    if (length < block_size || block_size % 2 != 0) {\n        return false;\n    }\n\n    const __m128d tolerance_vec = _mm_set1_pd(tolerance);\n    const size_t num_blocks = length / block_size;\n    const size_t elements_per_block = block_size / 2;\n\n    __m128d first_block = _mm_loadu_pd(&vec[0]);\n    for (size_t i = 1; i < num_blocks; ++i) {\n        __m128d block1 = _mm_loadu_pd(&vec[i * block_size]);\n        __m128d block2 = _mm_loadu_pd(&vec[i * block_size + elements_per_block]);\n\n        __m128d diff1 = _mm_sub_pd(first_block, block1);\n        __m128d diff2 = _mm_sub_pd(first_block, block2);\n\n        __m128d abs_diff1 = _mm_andnot_pd(_mm_set1_pd(-0.0), diff1);\n        __m128d abs_diff2 = _mm_andnot_pd(_mm_set1_pd(-0.0), diff2);\n\n        __m128d cmp1 = _mm_cmple_pd(abs_diff1, tolerance_vec);\n        __m128d cmp2 = _mm_cmple_pd(abs_diff2, tolerance_vec);\n\n        if (_mm_movemask_pd(cmp1) != 3 || _mm_movemask_pd(cmp2) != 3) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_39_SSE", "completion": "```c\nvoid matrix_row_norm_compare_simd(const double* matrix, const double* thresholds, size_t rows, size_t cols, bool* result) {\n    for (size_t i = 0; i < rows; ++i) {\n        const double* row_start = matrix + i * cols;\n        __m128d sum_squared = _mm_setzero_pd();\n\n        for (size_t j = 0; j < cols; j += 2) {\n            __m128d vec1 = _mm_loadu_pd(row_start + j);\n            sum_squared = _mm_add_pd(sum_squared, _mm_mul_pd(vec1, vec1));\n        }\n\n        double norm_squared[2];\n        _mm_storeu_pd(norm_squared, sum_squared);\n\n        result[i] = (norm_squared[0] + norm_squared[1] > thresholds[i]);\n    }\n}\n```  "}
{"task_id": "SimdBench_39_SSE", "completion": "```c\nvoid matrix_row_norm_compare_simd(const double* matrix, const double* thresholds, size_t rows, size_t cols, bool* result) {\n    for (size_t i = 0; i < rows; ++i) {\n        __m128d sum = _mm_setzero_pd();\n        for (size_t j = 0; j < cols; j += 2) {\n            __m128d vec1 = _mm_loadu_pd(&matrix[i * cols + j]);\n            __m128d vec2 = _mm_loadu_pd(&matrix[i * cols + j + 2]);\n            sum = _mm_add_pd(sum, _mm_mul_pd(vec1, vec1));\n            sum = _mm_add_pd(sum, _mm_mul_pd(vec2, vec2));\n        }\n        double temp[2];\n        _mm_storeu_pd(temp, sum);\n        double norm = temp[0] + temp[1];\n        if (norm > thresholds[i]) {\n            result[i] = true;\n        } else {\n            result[i] = false;\n        }\n    }\n}\n```  "}
{"task_id": "SimdBench_39_SSE", "completion": "```c\nvoid matrix_row_norm_compare_simd(const double* matrix, const double* thresholds, size_t rows, size_t cols, bool* result) {\n    for (size_t i = 0; i < rows; ++i) {\n        __m128d sum = _mm_setzero_pd();\n        for (size_t j = 0; j < cols; j += 2) {\n            __m128d vec1 = _mm_loadu_pd(&matrix[i * cols + j]);\n            __m128d vec2 = _mm_loadu_pd(&matrix[i * cols + j + 2]);\n            sum = _mm_add_pd(sum, _mm_mul_pd(vec1, vec1));\n            sum = _mm_add_pd(sum, _mm_mul_pd(vec2, vec2));\n        }\n        double temp[2];\n        _mm_storeu_pd(temp, sum);\n        double norm = temp[0] + temp[1];\n\n        if (norm > thresholds[i]) {\n            result[i] = true;\n        } else {\n            result[i] = false;\n        }\n    }\n}\n```  "}
{"task_id": "SimdBench_39_SSE", "completion": "```c\nvoid matrix_row_norm_compare_simd(const double* matrix, const double* thresholds, size_t rows, size_t cols, bool* result) {\n    for (size_t i = 0; i < rows; ++i) {\n        const double* row_start = matrix + i * cols;\n        __m128d sum = _mm_setzero_pd();\n\n        for (size_t j = 0; j < cols; j += 2) {\n            __m128d a = _mm_loadu_pd(row_start + j);\n            sum = _mm_add_pd(sum, _mm_mul_pd(a, a));\n        }\n\n        double norm[2];\n        _mm_storeu_pd(norm, sum);\n\n        result[i] = (norm[0] + norm[1] > thresholds[i]);\n    }\n}\n```  "}
{"task_id": "SimdBench_39_SSE", "completion": "```c\nvoid matrix_row_norm_compare_simd(const double* matrix, const double* thresholds, size_t rows, size_t cols, bool* result) {\n    for (size_t i = 0; i < rows; ++i) {\n        __m128d sum = _mm_setzero_pd();\n        for (size_t j = 0; j < cols; j += 2) {\n            __m128d vec1 = _mm_loadu_pd(&matrix[i * cols + j]);\n            __m128d vec2 = _mm_loadu_pd(&matrix[i * cols + j + 2]);\n            sum = _mm_add_pd(sum, _mm_mul_pd(vec1, vec1));\n            sum = _mm_add_pd(sum, _mm_mul_pd(vec2, vec2));\n        }\n        double norm;\n        _mm_store_sd(&norm, _mm_sqrt_pd(sum));\n        result[i] = norm > thresholds[i];\n    }\n}\n```  "}
{"task_id": "SimdBench_40_SSE", "completion": "```c\nvoid tensor_bitwise_or_simd(const uint32_t* A, const uint32_t* B, uint32_t* C, size_t length) {\n    size_t i;\n    for (i = 0; i < length; i += 4) {\n        __m128i a = _mm_loadu_si128((__m128i*)(A + i));\n        __m128i b = _mm_loadu_si128((__m128i*)(B + i));\n        __m128i result = _mm_or_si128(a, b);\n        _mm_storeu_si128((__m128i*)(C + i), result);\n    }\n}\n```  "}
{"task_id": "SimdBench_40_SSE", "completion": "```c\nvoid tensor_bitwise_or_simd(const uint32_t* A, const uint32_t* B, uint32_t* C, size_t length) {\n    size_t i;\n    for (i = 0; i < length; i += 4) {\n        __m128i a = _mm_loadu_si128((__m128i*)(A + i));\n        __m128i b = _mm_loadu_si128((__m128i*)(B + i));\n        __m128i result = _mm_or_si128(a, b);\n        _mm_storeu_si128((__m128i*)(C + i), result);\n    }\n}\n```  "}
{"task_id": "SimdBench_40_SSE", "completion": "```cpp\nvoid tensor_bitwise_or_simd(const uint32_t* A, const uint32_t* B, uint32_t* C, size_t length) {\n    size_t i = 0;\n    for (; i + 4 <= length; i += 4) {\n        __m128i a = _mm_loadu_si128((__m128i*)(A + i));\n        __m128i b = _mm_loadu_si128((__m128i*)(B + i));\n        __m128i result = _mm_or_si128(a, b);\n        _mm_storeu_si128((__m128i*)(C + i), result);\n    }\n    for (; i < length; i++) {\n        C[i] = A[i] | B[i];\n    }\n}\n```  "}
{"task_id": "SimdBench_40_SSE", "completion": "```c\nvoid tensor_bitwise_or_simd(const uint32_t* A, const uint32_t* B, uint32_t* C, size_t length) {\n    size_t i;\n    __m128i* ptrA = (__m128i*)A;\n    __m128i* ptrB = (__m128i*)B;\n    __m128i* ptrC = (__m128i*)C;\n    \n    for (i = 0; i < length / 4; i++) {\n        __m128i a = _mm_loadu_si128(ptrA + i);\n        __m128i b = _mm_loadu_si128(ptrB + i);\n        __m128i result = _mm_or_si128(a, b);\n        _mm_storeu_si128(ptrC + i, result);\n    }\n}\n```  "}
{"task_id": "SimdBench_40_SSE", "completion": "```cpp\nvoid tensor_bitwise_or_simd(const uint32_t* A, const uint32_t* B, uint32_t* C, size_t length) {\n    size_t i;\n    for (i = 0; i < length; i += 4) {\n        __m128i a = _mm_loadu_si128((__m128i*)(A + i));\n        __m128i b = _mm_loadu_si128((__m128i*)(B + i));\n        __m128i result = _mm_or_si128(a, b);\n        _mm_storeu_si128((__m128i*)(C + i), result);\n    }\n}\n```  "}
{"task_id": "SimdBench_41_SSE", "completion": "```\nint64_t squarediff_simd(const int8_t * A, const int8_t * B, size_t length) {\n    __m128i sum_squares = _mm_setzero_si128();\n    __m128i sum_products = _mm_setzero_si128();\n\n    for (size_t i = 0; i < length; i += 16) {\n        __m128i a = _mm_loadu_si128((__m128i*)(A + i));\n        __m128i b = _mm_loadu_si128((__m128i*)(B + i));\n\n        __m128i a_squared = _mm_mullo_epi16(a, a);\n        __m128i b_squared = _mm_mullo_epi16(b, b);\n        sum_squares = _mm_add_epi16(sum_squares, a_squared);\n        sum_squares = _mm_add_epi16(sum_squares, b_squared);\n\n        __m128i ab = _mm_mullo_epi16(a, b);\n        sum_products = _mm_add_epi16(sum_products, ab);\n    }\n\n    int64_t result = 0;\n    for (int i = 0; i < 8; i++) {\n        result += ((int64_t*)&sum_squares)[i];\n        result -= ((int64_t*)&sum_products)[i];\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_41_SSE", "completion": "```\nint64_t squarediff_simd(const int8_t * A, const int8_t * B, size_t length) {\n    __m128i sum_squares = _mm_setzero_si128();\n    __m128i sum_products = _mm_setzero_si128();\n    \n    for (size_t i = 0; i < length; i += 16) {\n        __m128i a = _mm_loadu_si128((__m128i*)(A + i));\n        __m128i b = _mm_loadu_si128((__m128i*)(B + i));\n        \n        __m128i a_squared = _mm_mullo_epi16(a, a);\n        __m128i b_squared = _mm_mullo_epi16(b, b);\n        \n        sum_squares = _mm_add_epi16(sum_squares, a_squared);\n        sum_squares = _mm_add_epi16(sum_squares, b_squared);\n        \n        __m128i ab = _mm_mullo_epi16(a, b);\n        sum_products = _mm_add_epi16(sum_products, ab);\n    }\n    \n    int64_t result = 0;\n    int16_t* squares = (int16_t*)&sum_squares;\n    int16_t* products = (int16_t*)&sum_products;\n    \n    for (int i = 0; i < 8; i++) {\n        result += squares[i] - products[i];\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_41_SSE", "completion": "```\nint64_t squarediff_simd(const int8_t * A, const int8_t * B, size_t length) {\n    __m128i sum_squares = _mm_setzero_si128();\n    __m128i sum_products = _mm_setzero_si128();\n\n    for (size_t i = 0; i < length; i += 16) {\n        __m128i a = _mm_loadu_si128((__m128i*)(A + i));\n        __m128i b = _mm_loadu_si128((__m128i*)(B + i));\n\n        __m128i a_squared = _mm_mullo_epi16(a, a);\n        __m128i b_squared = _mm_mullo_epi16(b, b);\n\n        sum_squares = _mm_add_epi16(sum_squares, a_squared);\n        sum_squares = _mm_add_epi16(sum_squares, b_squared);\n\n        __m128i ab = _mm_mullo_epi16(a, b);\n        sum_products = _mm_add_epi16(sum_products, ab);\n    }\n\n    int64_t result = 0;\n    int16_t* sum_squares_ptr = (int16_t*)&sum_squares;\n    int16_t* sum_products_ptr = (int16_t*)&sum_products;\n\n    for (int i = 0; i < 8; i++) {\n        result += (int64_t)sum_squares_ptr[i] - (int64_t)sum_products_ptr[i];\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_41_SSE", "completion": "```\nint64_t squarediff_simd(const int8_t * A, const int8_t * B, size_t length) {\n    __m128i sum_squares = _mm_setzero_si128();\n    __m128i sum_products = _mm_setzero_si128();\n\n    for (size_t i = 0; i < length; i += 16) {\n        __m128i a = _mm_loadu_si128((__m128i*)(A + i));\n        __m128i b = _mm_loadu_si128((__m128i*)(B + i));\n\n        __m128i a_squared = _mm_mullo_epi16(a, a);\n        __m128i b_squared = _mm_mullo_epi16(b, b);\n\n        sum_squares = _mm_add_epi16(sum_squares, a_squared);\n        sum_squares = _mm_add_epi16(sum_squares, b_squared);\n\n        __m128i ab_product = _mm_mullo_epi16(a, b);\n        sum_products = _mm_add_epi16(sum_products, ab_product);\n    }\n\n    int64_t result = 0;\n    int16_t* squares = (int16_t*)&sum_squares;\n    int16_t* products = (int16_t*)&sum_products;\n\n    for (int i = 0; i < 8; ++i) {\n        result += squares[i] - products[i];\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_41_SSE", "completion": "```\nint64_t squarediff_simd(const int8_t * A, const int8_t * B, size_t length) {\n    __m128i sum_squares = _mm_setzero_si128();\n    __m128i sum_products = _mm_setzero_si128();\n\n    for (size_t i = 0; i < length; i += 16) {\n        __m128i a = _mm_loadu_si128((__m128i*)(A + i));\n        __m128i b = _mm_loadu_si128((__m128i*)(B + i));\n\n        __m128i a_squared = _mm_mullo_epi16(a, a);\n        __m128i b_squared = _mm_mullo_epi16(b, b);\n        sum_squares = _mm_add_epi16(sum_squares, a_squared);\n        sum_squares = _mm_add_epi16(sum_squares, b_squared);\n\n        __m128i ab_product = _mm_mullo_epi16(a, b);\n        sum_products = _mm_add_epi16(sum_products, ab_product);\n    }\n\n    int64_t result = 0;\n    for (int i = 0; i < 8; i++) {\n        result += _mm_extract_epi16(sum_squares, i);\n        result -= _mm_extract_epi16(sum_products, i);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_42_SSE", "completion": "```cpp\nvoid tensor_bit_clear_simd(const uint64_t* A, const uint64_t* B, uint64_t* C, size_t length) {\n    for (size_t i = 0; i < length; i += 2) {\n        __m128i a = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i b = _mm_loadu_si128((__m128i*)&B[i]);\n        __m128i result = _mm_and_si128(a, _mm_andnot_si128(b, _mm_set1_epi64x(-1)));\n        _mm_storeu_si128((__m128i*)&C[i], result);\n    }\n}\n```  "}
{"task_id": "SimdBench_42_SSE", "completion": "```c\nvoid tensor_bit_clear_simd(const uint64_t* A, const uint64_t* B, uint64_t* C, size_t length) {\n    size_t i;\n    __m128i* ptrA = (__m128i*)A;\n    __m128i* ptrB = (__m128i*)B;\n    __m128i* ptrC = (__m128i*)C;\n    const size_t simd_length = length / 2;\n\n    for (i = 0; i < simd_length; i++) {\n        __m128i a = _mm_load_si128(&ptrA[i]);\n        __m128i b = _mm_load_si128(&ptrB[i]);\n        __m128i result = _mm_andnot_si128(b, a);\n        _mm_store_si128(&ptrC[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_42_SSE", "completion": "```cpp\nvoid tensor_bit_clear_simd(const uint64_t* A, const uint64_t* B, uint64_t* C, size_t length) {\n    for (size_t i = 0; i < length; i += 2) {\n        __m128i a = _mm_loadu_si128((__m128i*)(A + i));\n        __m128i b = _mm_loadu_si128((__m128i*)(B + i));\n        __m128i result = _mm_and_si128(a, _mm_andnot_si128(b, _mm_set1_epi64x(-1)));\n        _mm_storeu_si128((__m128i*)(C + i), result);\n    }\n}\n```  "}
{"task_id": "SimdBench_42_SSE", "completion": "```c\nvoid tensor_bit_clear_simd(const uint64_t* A, const uint64_t* B, uint64_t* C, size_t length) {\n    for (size_t i = 0; i < length; i += 2) {\n        __m128i a = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i b = _mm_loadu_si128((__m128i*)&B[i]);\n        __m128i result = _mm_and_si128(a, _mm_andnot_si128(b, _mm_set1_epi64x(-1)));\n        _mm_storeu_si128((__m128i*)&C[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_42_SSE", "completion": "```cpp\nvoid tensor_bit_clear_simd(const uint64_t* A, const uint64_t* B, uint64_t* C, size_t length) {\n    for (size_t i = 0; i < length; i += 2) {\n        __m128i a = _mm_loadu_si128((__m128i*)(A + i));\n        __m128i b = _mm_loadu_si128((__m128i*)(B + i));\n        __m128i result = _mm_and_si128(a, _mm_andnot_si128(b, _mm_set1_epi64x(-1)));\n        _mm_storeu_si128((__m128i*)(C + i), result);\n    }\n}\n```"}
{"task_id": "SimdBench_43_SSE", "completion": "```\nvoid tensor_three_valued_logic_simd(const int8_t* A, const int8_t* B, int8_t* C, size_t length) {\n    for (size_t i = 0; i < length; i += 16) {\n        __m128i a = _mm_loadu_si128((__m128i*)(A + i));\n        __m128i b = _mm_loadu_si128((__m128i*)(B + i));\n\n        __m128i positive_mask = _mm_and_si128(_mm_cmpgt_epi8(a, _mm_set1_epi8(0)), _mm_cmpgt_epi8(b, _mm_set1_epi8(0)));\n        __m128i negative_mask = _mm_and_si128(_mm_cmpgt_epi8(_mm_set1_epi8(0), a), _mm_cmpgt_epi8(_mm_set1_epi8(0), b));\n\n        __m128i result = _mm_or_si128(positive_mask, _mm_slli_epi16(negative_mask, 1));\n        _mm_storeu_si128((__m128i*)(C + i), result);\n    }\n}\n```"}
{"task_id": "SimdBench_43_SSE", "completion": "```\nvoid tensor_three_valued_logic_simd(const int8_t* A, const int8_t* B, int8_t* C, size_t length) {\n    for (size_t i = 0; i < length; i += 16) {\n        __m128i a = _mm_loadu_si128((__m128i*)(A + i));\n        __m128i b = _mm_loadu_si128((__m128i*)(B + i));\n\n        __m128i positive_mask = _mm_and_si128(_mm_cmpgt_epi8(a, _mm_set1_epi8(0)), _mm_cmpgt_epi8(b, _mm_set1_epi8(0)));\n        __m128i negative_mask = _mm_and_si128(_mm_cmpgt_epi8(_mm_set1_epi8(0), a), _mm_cmpgt_epi8(_mm_set1_epi8(0), b));\n\n        __m128i result = _mm_or_si128(_mm_and_si128(positive_mask, _mm_set1_epi8(1)), _mm_and_si128(negative_mask, _mm_set1_epi8(-1)));\n\n        _mm_storeu_si128((__m128i*)(C + i), result);\n    }\n}\n```"}
{"task_id": "SimdBench_43_SSE", "completion": "```\nvoid tensor_three_valued_logic_simd(const int8_t* A, const int8_t* B, int8_t* C, size_t length) {\n    for (size_t i = 0; i < length; i += 16) {\n        __m128i a = _mm_loadu_si128((__m128i*)(A + i));\n        __m128i b = _mm_loadu_si128((__m128i*)(B + i));\n\n        __m128i both_positive_mask = _mm_and_si128(_mm_cmpgt_epi8(a, _mm_set1_epi8(0)), _mm_cmpgt_epi8(b, _mm_set1_epi8(0)));\n        __m128i both_negative_mask = _mm_and_si128(_mm_cmplt_epi8(a, _mm_set1_epi8(0)), _mm_cmplt_epi8(b, _mm_set1_epi8(0)));\n\n        __m128i result = _mm_blendv_epi8(_mm_set1_epi8(0), _mm_set1_epi8(1), both_positive_mask);\n        result = _mm_blendv_epi8(result, _mm_set1_epi8(-1), both_negative_mask);\n\n        _mm_storeu_si128((__m128i*)(C + i), result);\n    }\n}\n```"}
{"task_id": "SimdBench_43_SSE", "completion": "```\nvoid tensor_three_valued_logic_simd(const int8_t* A, const int8_t* B, int8_t* C, size_t length) {\n    for (size_t i = 0; i < length; i += 16) {\n        __m128i a = _mm_loadu_si128((__m128i*)(A + i));\n        __m128i b = _mm_loadu_si128((__m128i*)(B + i));\n\n        __m128i positive_mask_a = _mm_cmpgt_epi8(a, _mm_set1_epi8(0));\n        __m128i positive_mask_b = _mm_cmpgt_epi8(b, _mm_set1_epi8(0));\n        __m128i negative_mask_a = _mm_cmplt_epi8(a, _mm_set1_epi8(0));\n        __m128i negative_mask_b = _mm_cmplt_epi8(b, _mm_set1_epi8(0));\n\n        __m128i both_positive_mask = _mm_and_si128(positive_mask_a, positive_mask_b);\n        __m128i both_negative_mask = _mm_and_si128(negative_mask_a, negative_mask_b);\n\n        __m128i result = _mm_blendv_epi8(_mm_set1_epi8(0), _mm_set1_epi8(1), both_positive_mask);\n        result = _mm_blendv_epi8(result, _mm_set1_epi8(-1), both_negative_mask);\n\n        _mm_storeu_si128((__m128i*)(C + i), result);\n    }\n}\n```"}
{"task_id": "SimdBench_43_SSE", "completion": "```\nvoid tensor_three_valued_logic_simd(const int8_t* A, const int8_t* B, int8_t* C, size_t length) {\n    for (size_t i = 0; i < length; i += 16) {\n        __m128i a = _mm_loadu_si128((__m128i*)(A + i));\n        __m128i b = _mm_loadu_si128((__m128i*)(B + i));\n\n        __m128i both_positive_mask = _mm_and_si128(_mm_cmpgt_epi8(a, _mm_set1_epi8(0)), _mm_cmpgt_epi8(b, _mm_set1_epi8(0)));\n        __m128i both_negative_mask = _mm_and_si128(_mm_cmplt_epi8(a, _mm_set1_epi8(0)), _mm_cmplt_epi8(b, _mm_set1_epi8(0)));\n\n        __m128i result = _mm_or_si128(_mm_and_si128(both_positive_mask, _mm_set1_epi8(1)),\n                                      _mm_and_si128(both_negative_mask, _mm_set1_epi8(-1)));\n\n        _mm_storeu_si128((__m128i*)(C + i), result);\n    }\n}\n```"}
{"task_id": "SimdBench_44_SSE", "completion": "```c\nvoid tensor_bit_op_simd(const uint16_t* A, const uint16_t* B, uint16_t* C, size_t length) {\n    __m128i* ptrA = (__m128i*)A;\n    __m128i* ptrB = (__m128i*)B;\n    __m128i* ptrC = (__m128i*)C;\n    \n    size_t midpoint = length / 2;\n    \n    for (size_t i = 0; i < midpoint / 8; i++) {\n        __m128i a = _mm_load_si128(&ptrA[i]);\n        __m128i b = _mm_load_si128(&ptrB[i]);\n        \n        __m128i xor_result = _mm_xor_si128(a, b);\n        __m128i and_result = _mm_and_si128(a, b);\n        \n        _mm_store_si128(&ptrC[i], xor_result);\n        _mm_store_si128(&ptrC[midpoint / 8 + i], and_result);\n    }\n    \n    for (size_t i = midpoint / 8; i < length / 8; i++) {\n        __m128i a = _mm_load_si128(&ptrA[i]);\n        _mm_store_si128(&ptrC[i], a);\n    }\n}\n```  "}
{"task_id": "SimdBench_44_SSE", "completion": "```c\nvoid tensor_bit_op_simd(const uint16_t* A, const uint16_t* B, uint16_t* C, size_t length) {\n    __m128i* ptrA = (__m128i*)A;\n    __m128i* ptrB = (__m128i*)B;\n    __m128i* ptrC = (__m128i*)C;\n\n    size_t i;\n    size_t midpoint = length / 8;\n\n    for (i = 0; i < midpoint; i++) {\n        __m128i a = _mm_load_si128(&ptrA[i]);\n        __m128i b = _mm_load_si128(&ptrB[i]);\n\n        __m128i xor_result = _mm_xor_si128(a, b);\n        __m128i and_result = _mm_and_si128(a, b);\n\n        _mm_store_si128(&ptrC[i], xor_result);\n        _mm_store_si128(&ptrC[midpoint], a);\n        _mm_store_si128(&ptrC[length - 1 - i], and_result);\n    }\n}\n```  "}
{"task_id": "SimdBench_44_SSE", "completion": "```c\nvoid tensor_bit_op_simd(const uint16_t* A, const uint16_t* B, uint16_t* C, size_t length) {\n    __m128i* ptrA = (__m128i*)A;\n    __m128i* ptrB = (__m128i*)B;\n    __m128i* ptrC = (__m128i*)C;\n    \n    size_t midpoint = length / 8;\n    \n    for (size_t i = 0; i < midpoint; i++) {\n        __m128i a = _mm_load_si128(&ptrA[i]);\n        __m128i b = _mm_load_si128(&ptrB[i]);\n        \n        __m128i xor_result = _mm_xor_si128(a, b);\n        __m128i and_result = _mm_and_si128(a, b);\n        \n        _mm_store_si128(&ptrC[i], xor_result);\n        _mm_store_si128(&ptrC[length/8 + i], and_result);\n    }\n    \n    if (length % 8 != 0) {\n        uint16_t* ptrA_remainder = (uint16_t*)&ptrA[midpoint];\n        uint16_t* ptrB_remainder = (uint16_t*)&ptrB[midpoint];\n        uint16_t* ptrC_remainder = (uint16_t*)&ptrC[midpoint];\n        \n        for (size_t i = 0; i < length % 8; i++) {\n            ptrC_remainder[i] = ptrA_remainder[i] ^ ptrB_remainder[i];\n        }\n    }\n}\n```  "}
{"task_id": "SimdBench_44_SSE", "completion": "```c\nvoid tensor_bit_op_simd(const uint16_t* A, const uint16_t* B, uint16_t* C, size_t length) {\n    __m128i* A_ptr = (__m128i*)A;\n    __m128i* B_ptr = (__m128i*)B;\n    __m128i* C_ptr = (__m128i*)C;\n\n    size_t num_simd = length / 8;\n    size_t remaining = length % 8;\n\n    __m128i mask = _mm_set1_epi16(0xFFFF);\n    __m128i midpoint_mask = _mm_set_epi16(0, 0, 0, 0, 0, 0, 0, 0xFFFF);\n\n    for (size_t i = 0; i < num_simd; i++) {\n        __m128i a = _mm_load_si128(&A_ptr[i]);\n        __m128i b = _mm_load_si128(&B_ptr[i]);\n\n        __m128i xor_result = _mm_xor_si128(a, b);\n        __m128i and_result = _mm_and_si128(a, b);\n\n        __m128i mid_result = _mm_and_si128(a, midpoint_mask);\n\n        __m128i result = _mm_or_si128(_mm_or_si128(mid_result, xor_result), and_result);\n\n        _mm_store_si128(&C_ptr[i], result);\n    }\n\n    uint16_t* A_remain = (uint16_t*)&A_ptr[num_simd];\n    uint16_t* B_remain = (uint16_t*)&B_ptr[num_simd];\n    uint16_t* C_remain = (uint16_t*)&C_ptr[num_simd];\n\n    for (size_t i = 0; i < remaining; i++) {\n        if (i == remaining / 2) {\n            C_remain[i] = A_remain[i];\n        } else {\n            C_remain[i] = A_remain[i] ^ B_remain[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_44_SSE", "completion": "```c\nvoid tensor_bit_op_simd(const uint16_t* A, const uint16_t* B, uint16_t* C, size_t length) {\n    __m128i* ptrA = (__m128i*)A;\n    __m128i* ptrB = (__m128i*)B;\n    __m128i* ptrC = (__m128i*)C;\n    \n    size_t midpoint = length / 8;\n    \n    for (size_t i = 0; i < midpoint; i++) {\n        __m128i a = _mm_loadu_si128(&ptrA[i]);\n        __m128i b = _mm_loadu_si128(&ptrB[i]);\n        \n        __m128i xor_result = _mm_xor_si128(a, b);\n        __m128i and_result = _mm_and_si128(a, b);\n        \n        _mm_storeu_si128(&ptrC[i], xor_result);\n        _mm_storeu_si128(&ptrC[length/8 + i], and_result);\n    }\n    \n    if (length % 8 != 0) {\n        uint16_t* tailA = (uint16_t*)&ptrA[midpoint];\n        uint16_t* tailB = (uint16_t*)&ptrB[midpoint];\n        uint16_t* tailC = (uint16_t*)&ptrC[midpoint];\n        \n        for (size_t i = 0; i < length % 8; i++) {\n            tailC[i] = tailA[i] ^ tailB[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_45_SSE", "completion": "```\nvoid tensor_multi_select_simd(const float* A, const float* B, const float* C, const float* D, const bool* cond1, const bool* cond2, float* out, size_t dim1, size_t dim2, size_t dim3) {\n    for (size_t i = 0; i < dim1 * dim2 * dim3; i += 4) {\n        __m128 a = _mm_loadu_ps(&A[i]);\n        __m128 b = _mm_loadu_ps(&B[i]);\n        __m128 c = _mm_loadu_ps(&C[i]);\n        __m128 d = _mm_loadu_ps(&D[i]);\n        \n        __m128i mask1 = _mm_loadu_si128((__m128i*)&cond1[i]);\n        __m128i mask2 = _mm_loadu_si128((__m128i*)&cond2[i]);\n        \n        __m128 result = _mm_blendv_ps(_mm_blendv_ps(d, c, _mm_castsi128_ps(mask2)), _mm_blendv_ps(b, a, _mm_castsi128_ps(mask2)), _mm_castsi128_ps(mask1));\n        \n        _mm_storeu_ps(&out[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_45_SSE", "completion": "```cpp\nvoid tensor_multi_select_simd(const float* A, const float* B, const float* C, const float* D, const bool* cond1, const bool* cond2, float* out, size_t dim1, size_t dim2, size_t dim3) {\n    for (size_t i = 0; i < dim1 * dim2 * dim3; i += 4) {\n        __m128 a_val = _mm_loadu_ps(&A[i]);\n        __m128 b_val = _mm_loadu_ps(&B[i]);\n        __m128 c_val = _mm_loadu_ps(&C[i]);\n        __m128 d_val = _mm_loadu_ps(&D[i]);\n\n        __m128i cond1_val = _mm_loadu_si128((__m128i*)&cond1[i]);\n        __m128i cond2_val = _mm_loadu_si128((__m128i*)&cond2[i]);\n\n        __m128 mask1 = _mm_castsi128_ps(cond1_val);\n        __m128 mask2 = _mm_castsi128_ps(cond2_val);\n\n        __m128 result = _mm_blendv_ps(d_val, c_val, mask2);\n        result = _mm_blendv_ps(result, b_val, mask1);\n        result = _mm_blendv_ps(result, a_val, mask1);\n\n        _mm_storeu_ps(&out[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_45_SSE", "completion": "```\nvoid tensor_multi_select_simd(const float* A, const float* B, const float* C, const float* D, const bool* cond1, const bool* cond2, float* out, size_t dim1, size_t dim2, size_t dim3) {\n    for (size_t i = 0; i < dim1 * dim2 * dim3; i += 4) {\n        __m128 a = _mm_loadu_ps(&A[i]);\n        __m128 b = _mm_loadu_ps(&B[i]);\n        __m128 c = _mm_loadu_ps(&C[i]);\n        __m128 d = _mm_loadu_ps(&D[i]);\n        __m128i cond1_val = _mm_loadu_si128((__m128i*)&cond1[i]);\n        __m128i cond2_val = _mm_loadu_si128((__m128i*)&cond2[i]);\n\n        __m128 mask1 = _mm_castsi128_ps(cond1_val);\n        __m128 mask2 = _mm_castsi128_ps(cond2_val);\n\n        __m128 result = _mm_blendv_ps(d, c, mask2);\n        result = _mm_blendv_ps(result, b, mask1);\n        result = _mm_blendv_ps(result, a, _mm_and_ps(mask1, mask2));\n\n        _mm_storeu_ps(&out[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_45_SSE", "completion": "```cpp\nvoid tensor_multi_select_simd(const float* A, const float* B, const float* C, const float* D, const bool* cond1, const bool* cond2, float* out, size_t dim1, size_t dim2, size_t dim3) {\n    for (size_t i = 0; i < dim1 * dim2 * dim3; i += 4) {\n        __m128 a_val = _mm_loadu_ps(&A[i]);\n        __m128 b_val = _mm_loadu_ps(&B[i]);\n        __m128 c_val = _mm_loadu_ps(&C[i]);\n        __m128 d_val = _mm_loadu_ps(&D[i]);\n\n        __m128i cond1_val = _mm_loadu_si128((__m128i*)&cond1[i]);\n        __m128i cond2_val = _mm_loadu_si128((__m128i*)&cond2[i]);\n\n        __m128 mask1 = _mm_castsi128_ps(cond1_val);\n        __m128 mask2 = _mm_castsi128_ps(cond2_val);\n\n        __m128 result = _mm_blendv_ps(d_val, c_val, mask2);\n        result = _mm_blendv_ps(result, b_val, mask1);\n        result = _mm_blendv_ps(result, a_val, mask1);\n\n        _mm_storeu_ps(&out[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_45_SSE", "completion": "```\nvoid tensor_multi_select_simd(const float* A, const float* B, const float* C, const float* D, const bool* cond1, const bool* cond2, float* out, size_t dim1, size_t dim2, size_t dim3) {\n    for (size_t i = 0; i < dim1 * dim2 * dim3; i += 4) {\n        __m128 a_vals = _mm_loadu_ps(&A[i]);\n        __m128 b_vals = _mm_loadu_ps(&B[i]);\n        __m128 c_vals = _mm_loadu_ps(&C[i]);\n        __m128 d_vals = _mm_loadu_ps(&D[i]);\n\n        __m128i cond1_vals = _mm_loadu_si128((__m128i*)&cond1[i]);\n        __m128i cond2_vals = _mm_loadu_si128((__m128i*)&cond2[i]);\n\n        __m128 mask1 = _mm_castsi128_ps(cond1_vals);\n        __m128 mask2 = _mm_castsi128_ps(cond2_vals);\n\n        __m128 result = _mm_blendv_ps(_mm_blendv_ps(d_vals, c_vals, mask2), _mm_blendv_ps(b_vals, a_vals, mask2), mask1);\n\n        _mm_storeu_ps(&out[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_46_SSE", "completion": "```cpp\nvoid tensor_bit_count_simd(const uint32_t* A, uint8_t* out, size_t dim1, size_t dim2, size_t dim3) {\n    for (size_t i = 0; i < dim1 * dim2 * dim3; ++i) {\n        __m128i v = _mm_set1_epi32(A[i]);\n        v = _mm_popcnt_u32(v);\n        out[i] = _mm_extract_epi8(v, 0);\n    }\n}\n```"}
{"task_id": "SimdBench_46_SSE", "completion": "```c\nvoid tensor_bit_count_simd(const uint32_t* A, uint8_t* out, size_t dim1, size_t dim2, size_t dim3) {\n    for (size_t i = 0; i < dim1 * dim2 * dim3; ++i) {\n        __m128i v = _mm_set1_epi32(A[i]);\n        v = _mm_popcnt_u32(v);\n        out[i] = _mm_cvtsi128_si32(v);\n    }\n}\n```"}
{"task_id": "SimdBench_46_SSE", "completion": "```c\nvoid tensor_bit_count_simd(const uint32_t* A, uint8_t* out, size_t dim1, size_t dim2, size_t dim3) {\n    for (size_t i = 0; i < dim1 * dim2 * dim3; ++i) {\n        __m128i v = _mm_set1_epi32(A[i]);\n        __m128i mask1 = _mm_set1_epi32(0x55555555);\n        __m128i mask2 = _mm_set1_epi32(0x33333333);\n        __m128i mask3 = _mm_set1_epi32(0x0f0f0f0f);\n\n        v = _mm_sub_epi32(_mm_and_si128(_mm_srli_epi32(v, 1), mask1), _mm_and_si128(v, mask1));\n        v = _mm_add_epi32(_mm_and_si128(_mm_srli_epi32(v, 2), mask2), _mm_and_si128(v, mask2));\n        v = _mm_add_epi32(_mm_and_si128(_mm_srli_epi32(v, 4), mask3), _mm_and_si128(v, mask3));\n\n        __m128i result = _mm_sad_epu8(_mm_set1_epi32(0), _mm_packs_epi32(v, _mm_setzero_si128()));\n\n        out[i] = _mm_cvtsi128_si32(result);\n    }\n}\n```"}
{"task_id": "SimdBench_46_SSE", "completion": "```c\nvoid tensor_bit_count_simd(const uint32_t* A, uint8_t* out, size_t dim1, size_t dim2, size_t dim3) {\n    for (size_t i = 0; i < dim1 * dim2 * dim3; ++i) {\n        __m128i v = _mm_set1_epi32(A[i]);\n        v = _mm_popcnt_u32(v);\n        out[i] = _mm_extract_epi8(v, 0);\n    }\n}\n```"}
{"task_id": "SimdBench_46_SSE", "completion": "```c\nvoid tensor_bit_count_simd(const uint32_t* A, uint8_t* out, size_t dim1, size_t dim2, size_t dim3) {\n    for (size_t i = 0; i < dim1 * dim2 * dim3; ++i) {\n        __m128i v = _mm_set1_epi32(A[i]);\n        v = _mm_popcnt_u32(v);\n        out[i] = _mm_cvtsi128_si32(v);\n    }\n}\n```"}
{"task_id": "SimdBench_47_SSE", "completion": "```c\nvoid matrix_conditional_abs_simd(const int* A, int* B, size_t rows, size_t cols) {\n    for (size_t i = 0; i < rows * cols; i += 4) {\n        __m128i a = _mm_loadu_si128((__m128i*)(A + i));\n        __m128i mask = _mm_cmpeq_epi32(_mm_set1_epi32(0), _mm_set1_epi32(3));\n        __m128i abs_a = _mm_abs_epi32(a);\n        __m128i result = _mm_blendv_epi8(a, abs_a, mask);\n        _mm_storeu_si128((__m128i*)(B + i), result);\n    }\n}\n```"}
{"task_id": "SimdBench_47_SSE", "completion": "```c\nvoid matrix_conditional_abs_simd(const int* A, int* B, size_t rows, size_t cols) {\n    for (size_t i = 0; i < rows * cols; i += 4) {\n        __m128i a = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i mask = _mm_cmpeq_epi32(_mm_set1_epi32(0), _mm_set1_epi32(0));\n        __m128i abs_a = _mm_abs_epi32(a);\n        __m128i result = _mm_blendv_epi8(a, abs_a, mask);\n        _mm_storeu_si128((__m128i*)&B[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_47_SSE", "completion": "```c\nvoid matrix_conditional_abs_simd(const int* A, int* B, size_t rows, size_t cols) {\n    for (size_t i = 0; i < rows * cols; i += 4) {\n        __m128i a = _mm_loadu_si128((__m128i*)(A + i));\n        __m128i mask = _mm_cmpeq_epi32(_mm_set1_epi32(0), _mm_set1_epi32(0));\n        __m128i div3 = _mm_set1_epi32(3);\n        __m128i cmp = _mm_cmpeq_epi32(_mm_and_si128(a, div3), _mm_set1_epi32(0));\n        __m128i abs_a = _mm_abs_epi32(a);\n        __m128i result = _mm_blendv_epi8(a, abs_a, cmp);\n        _mm_storeu_si128((__m128i*)(B + i), result);\n    }\n}\n```  "}
{"task_id": "SimdBench_47_SSE", "completion": "```c\nvoid matrix_conditional_abs_simd(const int* A, int* B, size_t rows, size_t cols) {\n    for (size_t i = 0; i < rows * cols; i += 4) {\n        __m128i a = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i mask = _mm_cmpeq_epi32(_mm_set1_epi32(0), _mm_set1_epi32(0));\n        __m128i abs_a = _mm_abs_epi32(a);\n        __m128i result = _mm_blendv_epi8(a, abs_a, mask);\n        _mm_storeu_si128((__m128i*)&B[i], result);\n    }\n}\n```  "}
{"task_id": "SimdBench_47_SSE", "completion": "```cpp\nvoid matrix_conditional_abs_simd(const int* A, int* B, size_t rows, size_t cols) {\n    for (size_t i = 0; i < rows * cols; i += 4) {\n        __m128i a = _mm_loadu_si128((__m128i*)(A + i));\n        __m128i mask = _mm_cmpeq_epi32(_mm_set1_epi32(0), _mm_set1_epi32(0));\n        __m128i div3 = _mm_set1_epi32(3);\n        __m128i cmp = _mm_cmpeq_epi32(_mm_and_si128(a, div3), _mm_set1_epi32(0));\n        __m128i abs_a = _mm_abs_epi32(a);\n        __m128i result = _mm_or_si128(_mm_and_si128(cmp, abs_a), _mm_andnot_si128(cmp, a));\n        _mm_storeu_si128((__m128i*)(B + i), result);\n    }\n}\n```  "}
{"task_id": "SimdBench_48_SSE", "completion": "```c\nvoid matrix_conditional_bit_rotate_simd(const uint32_t* src, uint32_t* dst, uint8_t rotate_bits, size_t length){\n    __m128i rotate_mask = _mm_set1_epi32(0x0F0F0F0F);\n    __m128i rotate_bits_vec = _mm_set1_epi32(rotate_bits);\n    __m128i negation_mask = _mm_set1_epi32(0xFFFFFFFF);\n    \n    for (size_t i = 0; i < length; i += 4) {\n        __m128i src_vec = _mm_loadu_si128((__m128i*)(src + i));\n        __m128i low_nibble = _mm_and_si128(src_vec, rotate_mask);\n        __m128i condition = _mm_cmpeq_epi32(low_nibble, rotate_mask);\n        \n        __m128i rotated = _mm_srl_epi32(src_vec, rotate_bits_vec);\n        __m128i negated = _mm_xor_si128(src_vec, negation_mask);\n        \n        __m128i result = _mm_blendv_epi8(negated, rotated, condition);\n        \n        _mm_storeu_si128((__m128i*)(dst + i), result);\n    }\n}\n```  "}
{"task_id": "SimdBench_48_SSE", "completion": "```c\nvoid matrix_conditional_bit_rotate_simd(const uint32_t* src, uint32_t* dst, uint8_t rotate_bits, size_t length){\n    __m128i rotate_mask = _mm_set1_epi32(0x0F0F0F0F);\n    __m128i rotate_bits_vec = _mm_set1_epi32(rotate_bits);\n    __m128i negation_mask = _mm_set1_epi32(0xFFFFFFFF);\n\n    for (size_t i = 0; i < length; i += 4) {\n        __m128i src_vec = _mm_loadu_si128((__m128i*)(src + i));\n        __m128i low_nibble_mask = _mm_and_si128(src_vec, rotate_mask);\n        __m128i condition_mask = _mm_cmpeq_epi32(low_nibble_mask, rotate_mask);\n\n        __m128i rotated_vec = _mm_srl_epi32(src_vec, rotate_bits_vec);\n        __m128i negated_vec = _mm_xor_si128(src_vec, negation_mask);\n\n        __m128i result_vec = _mm_blendv_epi8(negated_vec, rotated_vec, condition_mask);\n\n        _mm_storeu_si128((__m128i*)(dst + i), result_vec);\n    }\n}\n```"}
{"task_id": "SimdBench_48_SSE", "completion": "```\nvoid matrix_conditional_bit_rotate_simd(const uint32_t* src, uint32_t* dst, uint8_t rotate_bits, size_t length){\n    __m128i rotate = _mm_set1_epi32(rotate_bits);\n    __m128i all_ones = _mm_set1_epi32(0x0F0F0F0F);\n    __m128i neg_mask = _mm_set1_epi32(0xFFFFFFFF);\n    \n    for (size_t i = 0; i < length; i += 4) {\n        __m128i src_vec = _mm_loadu_si128((__m128i*)(src + i));\n        __m128i low_4_bits = _mm_and_si128(src_vec, all_ones);\n        __m128i cmp_result = _mm_cmpeq_epi32(low_4_bits, all_ones);\n        \n        __m128i rotated = _mm_srl_epi32(src_vec, rotate);\n        __m128i negated = _mm_xor_si128(src_vec, neg_mask);\n        \n        __m128i result = _mm_blendv_epi8(negated, rotated, cmp_result);\n        \n        _mm_storeu_si128((__m128i*)(dst + i), result);\n    }\n}\n```"}
{"task_id": "SimdBench_48_SSE", "completion": "```c\nvoid matrix_conditional_bit_rotate_simd(const uint32_t* src, uint32_t* dst, uint8_t rotate_bits, size_t length){\n    __m128i rotate = _mm_set1_epi32(rotate_bits);\n    __m128i allOnes = _mm_set1_epi32(0x0000000F);\n    __m128i zero = _mm_setzero_si128();\n\n    for (size_t i = 0; i < length; i += 4) {\n        __m128i srcVec = _mm_loadu_si128((__m128i*)(src + i));\n        __m128i mask = _mm_cmpeq_epi32(_mm_and_si128(srcVec, allOnes), allOnes);\n        \n        __m128i rotated = _mm_srl_epi32(srcVec, rotate);\n        __m128i negated = _mm_xor_si128(srcVec, _mm_cmpeq_epi32(zero, zero));\n\n        __m128i result = _mm_blendv_epi8(negated, rotated, mask);\n\n        _mm_storeu_si128((__m128i*)(dst + i), result);\n    }\n}\n```  "}
{"task_id": "SimdBench_48_SSE", "completion": "```cpp\nvoid matrix_conditional_bit_rotate_simd(const uint32_t* src, uint32_t* dst, uint8_t rotate_bits, size_t length){\n    __m128i rotate_mask = _mm_set1_epi32(0x0000000F);\n    __m128i rotate_bits_vec = _mm_set1_epi32(rotate_bits);\n    __m128i negation_mask = _mm_set1_epi32(0xFFFFFFFF);\n\n    for (size_t i = 0; i < length; i += 4) {\n        __m128i src_vec = _mm_loadu_si128((__m128i*)(src + i));\n        __m128i low_nibble = _mm_and_si128(src_vec, rotate_mask);\n        __m128i condition_mask = _mm_cmpeq_epi32(low_nibble, rotate_mask);\n\n        __m128i rotated_vec = _mm_srl_epi32(src_vec, rotate_bits_vec);\n        __m128i negated_vec = _mm_xor_si128(src_vec, negation_mask);\n\n        __m128i result_vec = _mm_blendv_epi8(negated_vec, rotated_vec, condition_mask);\n\n        _mm_storeu_si128((__m128i*)(dst + i), result_vec);\n    }\n}\n```"}
{"task_id": "SimdBench_49_SSE", "completion": "```c\nvoid tensor_ternary_compare_simd(const float* A, const float* B, int8_t* out, float epsilon, size_t length) {\n    __m128 eps = _mm_set1_ps(epsilon);\n    __m128 zero = _mm_setzero_ps();\n\n    for (size_t i = 0; i < length; i += 4) {\n        __m128 a = _mm_load_ps(&A[i]);\n        __m128 b = _mm_load_ps(&B[i]);\n\n        __m128 diff = _mm_sub_ps(a, b);\n        __m128 abs_diff = _mm_andnot_ps(_mm_set1_ps(-0.0f), diff); // Absolute value\n\n        __m128 mask_gt = _mm_cmpgt_ps(abs_diff, eps);\n        __m128 mask_lt = _mm_cmplt_ps(abs_diff, _mm_mul_ps(eps, _mm_set1_ps(-1.0f)));\n\n        __m128i result = _mm_packs_epi32(_mm_packs_epi16(_mm_cmpeq_epi32(_mm_setzero_si128(), _mm_setzero_si128()), _mm_packs_epi32(_mm_cmplt_epi32(_mm_castps_si128(abs_diff), _mm_castps_si128(eps)), _mm_cmplt_epi32(_mm_castps_si128(abs_diff), _mm_mul_ps(eps, _mm_set1_ps(-1.0f))))), _mm_setzero_si128());\n        _mm_store_si128((__m128i*)&out[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_49_SSE", "completion": "```c\nvoid tensor_ternary_compare_simd(const float* A, const float* B, int8_t* out, float epsilon, size_t length) {\n    __m128 eps = _mm_set1_ps(epsilon);\n    __m128 zero = _mm_setzero_ps();\n    __m128 neg_eps = _mm_sub_ps(zero, eps);\n\n    for (size_t i = 0; i < length; i += 4) {\n        __m128 a = _mm_loadu_ps(&A[i]);\n        __m128 b = _mm_loadu_ps(&B[i]);\n\n        __m128 diff = _mm_sub_ps(a, b);\n        __m128 abs_diff = _mm_andnot_ps(_mm_set1_ps(-0.0f), diff);\n\n        __m128 mask_gt_eps = _mm_cmpgt_ps(diff, eps);\n        __m128 mask_lt_neg_eps = _mm_cmplt_ps(diff, neg_eps);\n\n        __m128 result = _mm_blendv_ps(zero, _mm_blendv_ps(_mm_set1_ps(1.0f), _mm_set1_ps(-1.0f), mask_lt_neg_eps), mask_gt_eps);\n\n        _mm_storeu_si128((__m128i*)&out[i], _mm_cvtps_epi32(result));\n    }\n}\n```"}
{"task_id": "SimdBench_49_SSE", "completion": "```c\nvoid tensor_ternary_compare_simd(const float* A, const float* B, int8_t* out, float epsilon, size_t length) {\n    __m128 eps = _mm_set1_ps(epsilon);\n    __m128i zero = _mm_setzero_si128();\n    __m128i one = _mm_set1_epi8(1);\n    __m128i neg_one = _mm_set1_epi8(-1);\n\n    for (size_t i = 0; i < length; i += 4) {\n        __m128 a = _mm_load_ps(&A[i]);\n        __m128 b = _mm_load_ps(&B[i]);\n\n        __m128 diff = _mm_sub_ps(a, b);\n        __m128 abs_diff = _mm_and_ps(_mm_cmpge_ps(diff, _mm_setzero_ps()), diff);\n        abs_diff = _mm_or_ps(abs_diff, _mm_andnot_ps(_mm_cmpge_ps(diff, _mm_setzero_ps()), _mm_sub_ps(_mm_setzero_ps(), diff)));\n\n        __m128 mask_gt_eps = _mm_cmpgt_ps(abs_diff, eps);\n        __m128 mask_lt_neg_eps = _mm_cmplt_ps(abs_diff, _mm_mul_ps(eps, _mm_set1_ps(-1.0f)));\n\n        __m128i result = _mm_blendv_epi8(one, neg_one, _mm_castps_si128(mask_lt_neg_eps));\n        result = _mm_blendv_epi8(result, zero, _mm_castps_si128(mask_gt_eps));\n\n        _mm_storeu_si128((__m128i*)&out[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_49_SSE", "completion": "```c\nvoid tensor_ternary_compare_simd(const float* A, const float* B, int8_t* out, float epsilon, size_t length) {\n    __m128 eps = _mm_set1_ps(epsilon);\n    __m128 zero = _mm_setzero_ps();\n    __m128 neg_eps = _mm_sub_ps(zero, eps);\n\n    for (size_t i = 0; i < length; i += 4) {\n        __m128 a = _mm_load_ps(&A[i]);\n        __m128 b = _mm_load_ps(&B[i]);\n\n        __m128 diff = _mm_sub_ps(a, b);\n        __m128 abs_diff = _mm_andnot_ps(_mm_set1_ps(-0.0f), diff); // Absolute value of diff\n\n        __m128 mask_gt_eps = _mm_cmpgt_ps(diff, eps);\n        __m128 mask_lt_neg_eps = _mm_cmplt_ps(diff, neg_eps);\n\n        __m128 mask_eq = _mm_andnot_ps(_mm_or_ps(mask_gt_eps, mask_lt_neg_eps), _mm_set1_ps(1.0f));\n\n        __m128i result = _mm_cvtps_epi32(_mm_or_ps(_mm_and_ps(mask_gt_eps, _mm_set1_ps(1.0f)),\n                                                   _mm_and_ps(mask_lt_neg_eps, _mm_set1_ps(-1.0f))));\n        result = _mm_or_si128(result, _mm_slli_epi32(_mm_castps_si128(mask_eq), 24));\n\n        _mm_store_si128((__m128i*)&out[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_49_SSE", "completion": "```c\nvoid tensor_ternary_compare_simd(const float* A, const float* B, int8_t* out, float epsilon, size_t length) {\n    __m128 eps = _mm_set1_ps(epsilon);\n    __m128 zero = _mm_setzero_ps();\n    __m128 neg_eps = _mm_sub_ps(zero, eps);\n\n    for (size_t i = 0; i < length; i += 4) {\n        __m128 a = _mm_loadu_ps(&A[i]);\n        __m128 b = _mm_loadu_ps(&B[i]);\n\n        __m128 diff = _mm_sub_ps(a, b);\n        __m128 abs_diff = _mm_andnot_ps(_mm_set1_ps(-0.0f), diff); // Absolute value of diff\n\n        __m128 mask_gt_eps = _mm_cmpgt_ps(diff, eps);\n        __m128 mask_lt_neg_eps = _mm_cmplt_ps(diff, neg_eps);\n\n        __m128 result = _mm_blendv_ps(zero, _mm_blendv_ps(_mm_set1_ps(1.0f), _mm_set1_ps(-1.0f), mask_lt_neg_eps), mask_gt_eps);\n\n        _mm_storeu_si128((__m128i*)&out[i], _mm_cvtps_epi32(result));\n    }\n}\n```"}
{"task_id": "SimdBench_50_SSE", "completion": "```\nvoid float_to_int_saturate_simd(const float* A, int32_t* B, size_t size) {\n    const __m128i int32_min = _mm_set1_epi32(INT32_MIN);\n    const __m128i int32_max = _mm_set1_epi32(INT32_MAX);\n\n    for (size_t i = 0; i < size; i += 4) {\n        __m128 float_values = _mm_loadu_ps(&A[i]);\n        __m128i int_values = _mm_cvttps_epi32(float_values);\n        \n        int_values = _mm_max_epi32(int_values, int32_min);\n        int_values = _mm_min_epi32(int_values, int32_max);\n\n        _mm_storeu_si128((__m128i*)&B[i], int_values);\n    }\n}\n```"}
{"task_id": "SimdBench_50_SSE", "completion": "```cpp\nvoid float_to_int_saturate_simd(const float* A, int32_t* B, size_t size) {\n    const __m128i int32_max = _mm_set1_epi32(INT32_MAX);\n    const __m128i int32_min = _mm_set1_epi32(INT32_MIN);\n\n    for (size_t i = 0; i < size; i += 4) {\n        __m128 float_values = _mm_loadu_ps(&A[i]);\n        __m128i int_values = _mm_cvttps_epi32(float_values);\n\n        __m128i greater_than_max = _mm_cmpgt_epi32(int_values, int32_max);\n        __m128i less_than_min = _mm_cmplt_epi32(int_values, int32_min);\n\n        __m128i saturated_values = _mm_blendv_epi8(int_values, int32_max, greater_than_max);\n        saturated_values = _mm_blendv_epi8(saturated_values, int32_min, less_than_min);\n\n        _mm_storeu_si128((__m128i*)&B[i], saturated_values);\n    }\n}\n```"}
{"task_id": "SimdBench_50_SSE", "completion": "```cpp\nvoid float_to_int_saturate_simd(const float* A, int32_t* B, size_t size) {\n    const __m128i int32_min = _mm_set1_epi32(INT32_MIN);\n    const __m128i int32_max = _mm_set1_epi32(INT32_MAX);\n\n    for (size_t i = 0; i < size; i += 4) {\n        __m128 float_values = _mm_loadu_ps(&A[i]);\n        __m128i int_values = _mm_cvtps_epi32(float_values);\n\n        int_values = _mm_max_epi32(int_values, int32_min);\n        int_values = _mm_min_epi32(int_values, int32_max);\n\n        _mm_storeu_si128((__m128i*)&B[i], int_values);\n    }\n}\n```  "}
{"task_id": "SimdBench_50_SSE", "completion": "```\nvoid float_to_int_saturate_simd(const float* A, int32_t* B, size_t size) {\n    __m128i int32_max = _mm_set1_epi32(INT32_MAX);\n    __m128i int32_min = _mm_set1_epi32(INT32_MIN);\n\n    for (size_t i = 0; i < size; i += 4) {\n        __m128 float_values = _mm_loadu_ps(&A[i]);\n        __m128i int_values = _mm_cvtps_epi32(float_values);\n\n        __m128i greater_than_max = _mm_cmpgt_epi32(int_values, int32_max);\n        __m128i less_than_min = _mm_cmplt_epi32(int_values, int32_min);\n\n        __m128i saturated_values = _mm_blendv_epi8(int_values, int32_max, greater_than_max);\n        saturated_values = _mm_blendv_epi8(saturated_values, int32_min, less_than_min);\n\n        _mm_storeu_si128((__m128i*)&B[i], saturated_values);\n    }\n}\n```"}
{"task_id": "SimdBench_50_SSE", "completion": "```cpp\nvoid float_to_int_saturate_simd(const float* A, int32_t* B, size_t size) {\n    const __m128i int32_min = _mm_set1_epi32(INT32_MIN);\n    const __m128i int32_max = _mm_set1_epi32(INT32_MAX);\n\n    for (size_t i = 0; i < size; i += 4) {\n        __m128 float_values = _mm_loadu_ps(&A[i]);\n\n        __m128i int_values = _mm_cvtps_epi32(float_values);\n        int_values = _mm_packs_epi32(int_values, int_values);\n        int_values = _mm_max_epi32(int_values, int32_min);\n        int_values = _mm_min_epi32(int_values, int32_max);\n\n        _mm_storeu_si128((__m128i*)&B[i], int_values);\n    }\n}\n```  "}
{"task_id": "SimdBench_51_SSE", "completion": "```c\nvoid int_to_float_scaled_simd(const int32_t* A, int8_t scale, float* B, size_t size) {\n    __m128i scale_vec = _mm_set1_epi32(scale);\n    __m128i* A_ptr = (__m128i*)A;\n    __m128* B_ptr = (__m128*)B;\n    \n    for (size_t i = 0; i < size / 4; i++) {\n        __m128i A_val = _mm_loadu_si128(A_ptr + i);\n        __m128i scaled_val = _mm_mullo_epi32(A_val, scale_vec);\n        __m128 scaled_float = _mm_cvtepi32_ps(scaled_val);\n        _mm_storeu_ps((float*)(B_ptr + i), scaled_float);\n    }\n}\n```  "}
{"task_id": "SimdBench_51_SSE", "completion": "```c\nvoid int_to_float_scaled_simd(const int32_t* A, int8_t scale, float* B, size_t size) {\n    __m128i scale_vec = _mm_set1_epi32((int)scale);\n    __m128i* A_ptr = (__m128i*)A;\n    __m128* B_ptr = (__m128*)B;\n\n    for (size_t i = 0; i < size / 4; ++i) {\n        __m128i int_values = _mm_loadu_si128(A_ptr + i);\n        __m128i scaled_int_values = _mm_mullo_epi32(int_values, scale_vec);\n        __m128 float_values = _mm_cvtepi32_ps(scaled_int_values);\n        _mm_storeu_ps((float*)(B_ptr + i), float_values);\n    }\n}\n```  "}
{"task_id": "SimdBench_51_SSE", "completion": "```c\nvoid int_to_float_scaled_simd(const int32_t* A, int8_t scale, float* B, size_t size) {\n    __m128i scale_vec = _mm_set1_epi32(scale);\n    __m128i* A_ptr = (__m128i*)A;\n    __m128* B_ptr = (__m128*)B;\n    \n    for (size_t i = 0; i < size / 4; i++) {\n        __m128i int_values = _mm_loadu_si128(A_ptr + i);\n        __m128i scaled_values = _mm_mullo_epi32(int_values, scale_vec);\n        __m128 float_values = _mm_cvtepi32_ps(scaled_values);\n        _mm_storeu_ps((float*)(B_ptr + i), float_values);\n    }\n}\n```  "}
{"task_id": "SimdBench_51_SSE", "completion": "```c\nvoid int_to_float_scaled_simd(const int32_t* A, int8_t scale, float* B, size_t size) {\n    __m128i scale_vec = _mm_set1_epi32(scale);\n    __m128i* A_ptr = (__m128i*)A;\n    __m128* B_ptr = (__m128*)B;\n    \n    for (size_t i = 0; i < size / 4; i++) {\n        __m128i int_values = _mm_loadu_si128(A_ptr + i);\n        __m128i scaled_values = _mm_mullo_epi32(int_values, scale_vec);\n        __m128 float_values = _mm_cvtepi32_ps(scaled_values);\n        _mm_storeu_ps((float*)(B_ptr + i), float_values);\n    }\n}\n```  "}
{"task_id": "SimdBench_51_SSE", "completion": "```c\nvoid int_to_float_scaled_simd(const int32_t* A, int8_t scale, float* B, size_t size) {\n    __m128i scale_vec = _mm_set1_epi32(scale);\n    __m128i* A_ptr = (__m128i*)A;\n    __m128* B_ptr = (__m128*)B;\n    \n    for (size_t i = 0; i < size / 4; i++) {\n        __m128i int_values = _mm_loadu_si128(A_ptr + i);\n        __m128 float_values = _mm_cvtepi32_ps(int_values);\n        float_values = _mm_mul_ps(float_values, _mm_cvtepi32_ps(scale_vec));\n        _mm_storeu_ps((float*)(B_ptr + i), float_values);\n    }\n}\n```"}
{"task_id": "SimdBench_52_SSE", "completion": "```\nvoid float_div_round_simd(const float* A, const float* B, int32_t* C, size_t size) {\n    size_t i;\n    __m128 a, b, result;\n    for (i = 0; i < size; i += 4) {\n        a = _mm_loadu_ps(&A[i]);\n        b = _mm_loadu_ps(&B[i]);\n        result = _mm_cvtps_epi32(_mm_div_ps(a, b));\n        _mm_storeu_si128((__m128i*)&C[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_52_SSE", "completion": "```c\nvoid float_div_round_simd(const float* A, const float* B, int32_t* C, size_t size) {\n    size_t i;\n    __m128 a, b, result;\n    for (i = 0; i < size; i += 4) {\n        a = _mm_loadu_ps(&A[i]);\n        b = _mm_loadu_ps(&B[i]);\n        result = _mm_cvtps_epi32(_mm_div_ps(a, b));\n        _mm_storeu_si128((__m128i*)&C[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_52_SSE", "completion": "```c\nvoid float_div_round_simd(const float* A, const float* B, int32_t* C, size_t size) {\n    size_t i;\n    __m128 a, b, result;\n    for (i = 0; i < size; i += 4) {\n        a = _mm_loadu_ps(&A[i]);\n        b = _mm_loadu_ps(&B[i]);\n        result = _mm_cvtps_epi32(_mm_div_ps(a, b));\n        _mm_storeu_si128((__m128i*)&C[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_52_SSE", "completion": "```c\nvoid float_div_round_simd(const float* A, const float* B, int32_t* C, size_t size) {\n    size_t i;\n    __m128 a, b, result;\n    __m128i rounded_result;\n\n    for (i = 0; i < size; i += 4) {\n        a = _mm_loadu_ps(&A[i]);\n        b = _mm_loadu_ps(&B[i]);\n        result = _mm_div_ps(a, b);\n        rounded_result = _mm_cvtps_epi32(result);\n        _mm_storeu_si128((__m128i*)&C[i], rounded_result);\n    }\n}\n```  "}
{"task_id": "SimdBench_52_SSE", "completion": "```c\nvoid float_div_round_simd(const float* A, const float* B, int32_t* C, size_t size) {\n    size_t i;\n    __m128 a, b, result;\n    for (i = 0; i < size; i += 4) {\n        a = _mm_loadu_ps(&A[i]);\n        b = _mm_loadu_ps(&B[i]);\n        result = _mm_cvtps_epi32(_mm_div_ps(a, b));\n        _mm_storeu_si128((__m128i*)&C[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_53_SSE", "completion": "```\nvoid double_to_float_saturate_simd(const double* A, float* B, size_t size) {\n    __m128d max_double = _mm_set1_pd(FLT_MAX);\n    __m128d min_double = _mm_set1_pd(-FLT_MAX);\n    __m128d* src = (__m128d*)A;\n    __m128* dest = (__m128*)B;\n\n    for (size_t i = 0; i < size / 2; i++) {\n        __m128d val = _mm_load_pd((double*)(src + i));\n        __m128d clamped_val = _mm_min_pd(_mm_max_pd(val, min_double), max_double);\n        __m128 converted_val = _mm_cvtpd_ps(clamped_val);\n        _mm_store_ps((float*)(dest + i), converted_val);\n    }\n\n    if (size % 2 != 0) {\n        double last_val = A[size - 1];\n        float converted_last_val = (last_val > FLT_MAX) ? FLT_MAX : (last_val < -FLT_MAX) ? -FLT_MAX : (float)last_val;\n        B[size - 1] = converted_last_val;\n    }\n}\n```"}
{"task_id": "SimdBench_53_SSE", "completion": "```\nvoid double_to_float_saturate_simd(const double* A, float* B, size_t size) {\n    __m128d max_double = _mm_set1_pd(FLT_MAX);\n    __m128d min_double = _mm_set1_pd(-FLT_MAX);\n    __m128d* src = (__m128d*)A;\n    __m128* dest = (__m128*)B;\n\n    for (size_t i = 0; i < size / 2; i++) {\n        __m128d val = _mm_load_pd((double*)&src[i]);\n        __m128d clamped_val = _mm_min_pd(_mm_max_pd(val, min_double), max_double);\n        __m128 converted_val = _mm_cvtpd_ps(clamped_val);\n        _mm_store_ps((float*)&dest[i], converted_val);\n    }\n\n    if (size % 2 != 0) {\n        double last_val = A[size - 1];\n        float converted_last_val = (last_val > FLT_MAX) ? FLT_MAX : (last_val < -FLT_MAX) ? -FLT_MAX : (float)last_val;\n        B[size - 1] = converted_last_val;\n    }\n}\n```"}
{"task_id": "SimdBench_53_SSE", "completion": "```\nvoid double_to_float_saturate_simd(const double* A, float* B, size_t size) {\n    __m128d max_double = _mm_set1_pd(FLT_MAX);\n    __m128d min_double = _mm_set1_pd(-FLT_MAX);\n    __m128d* ptr_A = (__m128d*)A;\n    __m128* ptr_B = (__m128*)B;\n\n    for (size_t i = 0; i < size / 2; ++i) {\n        __m128d val_double = _mm_load_pd((double*)(ptr_A + i));\n        __m128d clamped_double = _mm_min_pd(_mm_max_pd(val_double, min_double), max_double);\n        __m128 val_float = _mm_cvtpd_ps(clamped_double);\n        _mm_store_ps((ptr_B + i), val_float);\n    }\n}\n```"}
{"task_id": "SimdBench_53_SSE", "completion": "```\nvoid double_to_float_saturate_simd(const double* A, float* B, size_t size) {\n    __m128d max_double = _mm_set1_pd(FLT_MAX);\n    __m128d min_double = _mm_set1_pd(-FLT_MAX);\n    __m128d* src = (__m128d*)A;\n    __m128* dest = (__m128*)B;\n    \n    for (size_t i = 0; i < size / 2; i++) {\n        __m128d val_double = _mm_load_pd((double*)(src + i));\n        __m128d clamped_double = _mm_min_pd(_mm_max_pd(val_double, min_double), max_double);\n        __m128 val_float = _mm_cvtpd_ps(clamped_double);\n        _mm_store_ps((float*)(dest + i), val_float);\n    }\n}\n```"}
{"task_id": "SimdBench_53_SSE", "completion": "```\nvoid double_to_float_saturate_simd(const double* A, float* B, size_t size) {\n    __m128d max_double = _mm_set1_pd(FLT_MAX);\n    __m128d min_double = _mm_set1_pd(-FLT_MAX);\n    __m128d* src = (__m128d*)A;\n    __m128* dest = (__m128*)B;\n\n    for (size_t i = 0; i < size / 2; i++) {\n        __m128d val_double = _mm_load_pd((double*)&src[i]);\n        __m128d clamped_double = _mm_min_pd(_mm_max_pd(val_double, min_double), max_double);\n        __m128 val_float = _mm_cvtpd_ps(clamped_double);\n        _mm_store_ps((float*)&dest[i], val_float);\n    }\n}\n```"}
{"task_id": "SimdBench_54_SSE", "completion": "```c\nvoid int16_to_int32_simd(const int16_t* A, int32_t* B, size_t size) {\n    size_t i;\n    for (i = 0; i < size; i += 8) {\n        __m128i a = _mm_loadu_si128((__m128i*)(A + i));\n        __m128i b = _mm_cvtepi16_epi32(a);\n        _mm_storeu_si128((__m128i*)(B + i), b);\n    }\n}\n```"}
{"task_id": "SimdBench_54_SSE", "completion": "```c\nvoid int16_to_int32_simd(const int16_t* A, int32_t* B, size_t size) {\n    size_t i;\n    for (i = 0; i < size; i += 8) {\n        __m128i a = _mm_loadu_si128((__m128i*)(A + i));\n        __m128i b = _mm_cvtepi16_epi32(a);\n        _mm_storeu_si128((__m128i*)(B + i), b);\n    }\n}\n```"}
{"task_id": "SimdBench_54_SSE", "completion": "```cpp\nvoid int16_to_int32_simd(const int16_t* A, int32_t* B, size_t size) {\n    size_t i;\n    for (i = 0; i < size; i += 8) {\n        __m128i a = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i b = _mm_cvtepi16_epi32(a);\n        _mm_storeu_si128((__m128i*)&B[i], b);\n    }\n}\n```"}
{"task_id": "SimdBench_54_SSE", "completion": "```c\nvoid int16_to_int32_simd(const int16_t* A, int32_t* B, size_t size) {\n    size_t i;\n    for (i = 0; i < size; i += 8) {\n        __m128i a = _mm_loadu_si128((__m128i*)(A + i));\n        __m128i b = _mm_cvtepi16_epi32(a);\n        _mm_storeu_si128((__m128i*)(B + i), b);\n    }\n}\n```"}
{"task_id": "SimdBench_54_SSE", "completion": "```c\nvoid int16_to_int32_simd(const int16_t* A, int32_t* B, size_t size) {\n    size_t i;\n    for (i = 0; i < size; i += 8) {\n        __m128i a = _mm_loadu_si128((__m128i*)(A + i));\n        __m128i b = _mm_cvtepi16_epi32(a);\n        _mm_storeu_si128((__m128i*)(B + i), b);\n    }\n}\n```"}
{"task_id": "SimdBench_55_SSE", "completion": "```\nvoid conditional_normalize_simd(const float* A, const int32_t* control, float* B, size_t size, float min_val, float max_val) {\n    __m128 min_val_sse = _mm_set1_ps(min_val);\n    __m128 max_val_sse = _mm_set1_ps(max_val);\n    __m128 zero = _mm_setzero_ps();\n    \n    for (size_t i = 0; i < size; i += 4) {\n        __m128 a_values = _mm_loadu_ps(&A[i]);\n        __m128 control_values = _mm_cvtepi32_ps(_mm_loadu_si128((__m128i*)&control[i]));\n        \n        __m128 mask = _mm_cmpgt_ps(control_values, zero);\n        \n        __m128 normalized_values = _mm_div_ps(_mm_sub_ps(a_values, min_val_sse), _mm_sub_ps(max_val_sse, min_val_sse));\n        normalized_values = _mm_min_ps(_mm_max_ps(normalized_values, zero), _mm_set1_ps(1.0f));\n        \n        __m128 result = _mm_blendv_ps(a_values, normalized_values, mask);\n        \n        _mm_storeu_ps(&B[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_55_SSE", "completion": "```\nvoid conditional_normalize_simd(const float* A, const int32_t* control, float* B, size_t size, float min_val, float max_val) {\n    __m128 min_val_sse = _mm_set1_ps(min_val);\n    __m128 max_val_sse = _mm_set1_ps(max_val);\n    __m128 zero = _mm_setzero_ps();\n    \n    for (size_t i = 0; i < size; i += 4) {\n        __m128 a = _mm_loadu_ps(&A[i]);\n        __m128i ctrl = _mm_loadu_si128((__m128i*)&control[i]);\n        \n        __m128 mask = _mm_cmpgt_ps(_mm_castsi128_ps(ctrl), zero);\n        \n        __m128 val = _mm_div_ps(_mm_sub_ps(a, min_val_sse), _mm_sub_ps(max_val_sse, min_val_sse));\n        val = _mm_max_ps(zero, val);\n        val = _mm_min_ps(_mm_set1_ps(1.0f), val);\n        \n        __m128 result = _mm_blendv_ps(a, val, mask);\n        \n        _mm_storeu_ps(&B[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_55_SSE", "completion": "```\nvoid conditional_normalize_simd(const float* A, const int32_t* control, float* B, size_t size, float min_val, float max_val) {\n    __m128 min_val_sse = _mm_set1_ps(min_val);\n    __m128 max_val_sse = _mm_set1_ps(max_val);\n    __m128 zero = _mm_setzero_ps();\n    \n    for (size_t i = 0; i < size; i += 4) {\n        __m128 a = _mm_loadu_ps(&A[i]);\n        __m128 control_val = _mm_cvtepi32_ps(_mm_loadu_si128((__m128i*)&control[i]));\n        \n        __m128 mask = _mm_cmpgt_ps(control_val, zero);\n        \n        __m128 normalized = _mm_div_ps(_mm_sub_ps(a, min_val_sse), _mm_sub_ps(max_val_sse, min_val_sse));\n        normalized = _mm_min_ps(_mm_max_ps(normalized, zero), _mm_set1_ps(1.0f));\n        \n        __m128 result = _mm_blendv_ps(a, normalized, mask);\n        \n        _mm_storeu_ps(&B[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_55_SSE", "completion": "```\nvoid conditional_normalize_simd(const float* A, const int32_t* control, float* B, size_t size, float min_val, float max_val) {\n    __m128 min_val_sse = _mm_set1_ps(min_val);\n    __m128 max_val_sse = _mm_set1_ps(max_val);\n    __m128 zero = _mm_setzero_ps();\n    __m128 one = _mm_set1_ps(1.0f);\n\n    for (size_t i = 0; i < size; i += 4) {\n        __m128 a_values = _mm_loadu_ps(&A[i]);\n        __m128 control_values = _mm_cvtepi32_ps(_mm_loadu_si128((__m128i*)&control[i]));\n\n        __m128 mask = _mm_cmpgt_ps(control_values, zero);\n\n        __m128 normalized_values = _mm_div_ps(_mm_sub_ps(a_values, min_val_sse), _mm_sub_ps(max_val_sse, min_val_sse));\n        normalized_values = _mm_max_ps(normalized_values, zero);\n        normalized_values = _mm_min_ps(normalized_values, one);\n\n        __m128 result = _mm_blendv_ps(a_values, normalized_values, mask);\n\n        _mm_storeu_ps(&B[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_55_SSE", "completion": "```\nvoid conditional_normalize_simd(const float* A, const int32_t* control, float* B, size_t size, float min_val, float max_val) {\n    __m128 min_val_vec = _mm_set1_ps(min_val);\n    __m128 max_val_vec = _mm_set1_ps(max_val);\n    __m128 zero_vec = _mm_setzero_ps();\n    __m128 one_vec = _mm_set1_ps(1.0f);\n\n    for (size_t i = 0; i < size; i += 4) {\n        __m128 a_values = _mm_loadu_ps(&A[i]);\n        __m128 control_values = _mm_cvtepi32_ps(_mm_loadu_si128((__m128i*)&control[i]));\n\n        __m128 mask = _mm_cmpgt_ps(control_values, zero_vec);\n\n        __m128 normalized_values = _mm_div_ps(_mm_sub_ps(a_values, min_val_vec), _mm_sub_ps(max_val_vec, min_val_vec));\n        normalized_values = _mm_min_ps(_mm_max_ps(normalized_values, zero_vec), one_vec);\n\n        __m128 result = _mm_blendv_ps(a_values, normalized_values, mask);\n\n        _mm_storeu_ps(&B[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_56_SSE", "completion": "```c\nvoid int_to_float_sqrt_simd(const uint32_t* A, float* B, size_t size) {\n    for (size_t i = 0; i < size; i += 4) {\n        __m128i intValues = _mm_loadu_si128((__m128i*)(A + i));\n        __m128 floatValues = _mm_cvtepi32_ps(_mm_srli_epi32(intValues, 16));\n        floatValues = _mm_sqrt_ps(floatValues);\n        _mm_storeu_ps(B + i, floatValues);\n    }\n}\n```"}
{"task_id": "SimdBench_56_SSE", "completion": "```c\nvoid int_to_float_sqrt_simd(const uint32_t* A, float* B, size_t size) {\n    for (size_t i = 0; i < size; i += 4) {\n        __m128i intValues = _mm_loadu_si128((__m128i*)(A + i));\n        __m128 floatValues = _mm_cvtepi32_ps(_mm_srli_epi32(intValues, 16));\n        floatValues = _mm_sqrt_ps(floatValues);\n        _mm_storeu_ps(B + i, floatValues);\n    }\n}\n```"}
{"task_id": "SimdBench_56_SSE", "completion": "```c\nvoid int_to_float_sqrt_simd(const uint32_t* A, float* B, size_t size) {\n    for (size_t i = 0; i < size; i += 4) {\n        __m128i intValues = _mm_loadu_si128((__m128i*)(A + i));\n        __m128 floatValues = _mm_cvtepi32_ps(_mm_srli_epi32(intValues, 16));\n        floatValues = _mm_sqrt_ps(floatValues);\n        _mm_storeu_ps(B + i, floatValues);\n    }\n}\n```"}
{"task_id": "SimdBench_56_SSE", "completion": "```c\nvoid int_to_float_sqrt_simd(const uint32_t* A, float* B, size_t size) {\n    for (size_t i = 0; i < size; i += 4) {\n        __m128i intValues = _mm_loadu_si128((__m128i*)(A + i));\n        __m128 floatValues = _mm_cvtepi32_ps(_mm_srli_epi32(intValues, 16));\n        floatValues = _mm_sqrt_ps(floatValues);\n        _mm_storeu_ps(B + i, floatValues);\n    }\n}\n```"}
{"task_id": "SimdBench_56_SSE", "completion": "```c\nvoid int_to_float_sqrt_simd(const uint32_t* A, float* B, size_t size) {\n    for (size_t i = 0; i < size; i += 4) {\n        __m128i intValues = _mm_loadu_si128((__m128i*)(A + i));\n        __m128i high16Bits = _mm_srli_epi32(intValues, 16);\n        __m128 floatValues = _mm_cvtepi32_ps(high16Bits);\n        __m128 sqrtValues = _mm_sqrt_ps(floatValues);\n        _mm_storeu_ps(B + i, sqrtValues);\n    }\n}\n```  "}
{"task_id": "SimdBench_57_SSE", "completion": "```c\nvoid int_bits_to_float_simd(const uint32_t* A, float* B, size_t size) {\n    for (size_t i = 0; i < size; i += 4) {\n        __m128i intValues = _mm_loadu_si128((__m128i*)(A + i));\n        __m128 floatValues = _mm_cvtepi32_ps(intValues);\n        _mm_storeu_ps(B + i, floatValues);\n    }\n}\n```"}
{"task_id": "SimdBench_57_SSE", "completion": "```c\nvoid int_bits_to_float_simd(const uint32_t* A, float* B, size_t size) {\n    size_t i;\n    for (i = 0; i < size; i += 4) {\n        __m128i intValues = _mm_loadu_si128((__m128i*)(A + i));\n        __m128 floatValues = _mm_cvtepi32_ps(intValues);\n        _mm_storeu_ps(B + i, floatValues);\n    }\n}\n```"}
{"task_id": "SimdBench_57_SSE", "completion": "```c\nvoid int_bits_to_float_simd(const uint32_t* A, float* B, size_t size) {\n    size_t i;\n    for (i = 0; i < size; i += 4) {\n        __m128i int_values = _mm_loadu_si128((__m128i*)(A + i));\n        __m128 float_values = _mm_cvtepi32_ps(int_values);\n        _mm_storeu_ps(B + i, float_values);\n    }\n}\n```"}
{"task_id": "SimdBench_57_SSE", "completion": "```c\nvoid int_bits_to_float_simd(const uint32_t* A, float* B, size_t size) {\n    for (size_t i = 0; i < size; i += 4) {\n        __m128i intValues = _mm_loadu_si128((__m128i*)(A + i));\n        __m128 floatValues = _mm_cvtepi32_ps(intValues);\n        _mm_storeu_ps(B + i, floatValues);\n    }\n}\n```"}
{"task_id": "SimdBench_57_SSE", "completion": "```c\nvoid int_bits_to_float_simd(const uint32_t* A, float* B, size_t size) {\n    for (size_t i = 0; i < size; i += 4) {\n        __m128i intValues = _mm_loadu_si128((__m128i*)(A + i));\n        __m128 floatValues = _mm_cvtepi32_ps(intValues);\n        _mm_storeu_ps(B + i, floatValues);\n    }\n}\n```"}
{"task_id": "SimdBench_58_SSE", "completion": "```c\nvoid conditional_diff_simd(const int32_t* A, const bool* cond, float* diff, size_t size) {\n    __m128i prev = _mm_setzero_si128();\n    __m128i mask_true = _mm_set1_epi32(-1); // All bits set to 1\n    __m128 mask_false = _mm_setzero_ps();\n\n    for (size_t i = 0; i < size; i += 4) {\n        __m128i curr = _mm_loadu_si128((__m128i*)(A + i));\n        __m128i cond_mask = _mm_loadu_si128((__m128i*)(cond + i));\n\n        __m128i diff_int = _mm_sub_epi32(curr, prev);\n        __m128 diff_float = _mm_cvtepi32_ps(diff_int);\n\n        __m128 result = _mm_blendv_ps(mask_false, diff_float, _mm_castsi128_ps(_mm_cmpeq_epi32(cond_mask, mask_true)));\n\n        if (i == 0) {\n            result = _mm_and_ps(result, _mm_castsi128_ps(_mm_slli_si128(_mm_set1_epi32(-1), 4)));\n        }\n\n        _mm_storeu_ps(diff + i, result);\n\n        prev = curr;\n    }\n}\n```"}
{"task_id": "SimdBench_58_SSE", "completion": "```cpp\nvoid conditional_diff_simd(const int32_t* A, const bool* cond, float* diff, size_t size) {\n    __m128i prev = _mm_setzero_si128();\n    __m128i mask_true = _mm_set1_epi32(0xFFFFFFFF);\n    __m128 mask_false = _mm_setzero_ps();\n\n    for (size_t i = 0; i < size; i += 4) {\n        __m128i curr = _mm_loadu_si128((__m128i*)(A + i));\n        __m128i cond_mask = _mm_loadu_si128((__m128i*)(cond + i));\n\n        __m128i diff_int = _mm_sub_epi32(curr, prev);\n        __m128 diff_float = _mm_cvtepi32_ps(diff_int);\n\n        __m128 diff_result = _mm_blendv_ps(mask_false, diff_float, _mm_castsi128_ps(_mm_and_si128(cond_mask, mask_true)));\n\n        _mm_storeu_ps(diff + i, diff_result);\n\n        prev = curr;\n    }\n}\n```"}
{"task_id": "SimdBench_58_SSE", "completion": "```cpp\nvoid conditional_diff_simd(const int32_t* A, const bool* cond, float* diff, size_t size) {\n    __m128i prevA = _mm_setzero_si128();\n    __m128i maskTrue = _mm_set1_epi32(0xFFFFFFFF);\n    __m128i maskFalse = _mm_setzero_si128();\n    __m128i mask;\n    __m128i currentA, diffInt;\n    __m128 diffFloat;\n\n    for (size_t i = 0; i < size; i += 4) {\n        currentA = _mm_loadu_si128((__m128i*)(A + i));\n        mask = _mm_loadu_si128((__m128i*)(cond + i));\n\n        __m128i cmp = _mm_cmpeq_epi32(mask, maskTrue);\n        __m128i cmpShifted = _mm_alignr_epi8(cmp, prevA, 4);\n        __m128i diffMask = _mm_and_si128(cmpShifted, maskTrue);\n\n        diffInt = _mm_sub_epi32(currentA, prevA);\n        diffInt = _mm_and_si128(diffInt, diffMask);\n\n        diffFloat = _mm_cvtepi32_ps(diffInt);\n        _mm_storeu_ps(diff + i, diffFloat);\n\n        prevA = currentA;\n    }\n}\n```"}
{"task_id": "SimdBench_58_SSE", "completion": "```c\nvoid conditional_diff_simd(const int32_t* A, const bool* cond, float* diff, size_t size) {\n    __m128i prev = _mm_setzero_si128();\n    __m128i mask_true = _mm_set1_epi32(-1); // All bits set to 1\n    __m128i mask_false = _mm_setzero_si128(); // All bits set to 0\n    __m128i mask;\n    __m128i curr, diff_int;\n    __m128 diff_float;\n\n    for (size_t i = 0; i < size; i += 4) {\n        // Load current values from A and cond arrays\n        curr = _mm_loadu_si128((__m128i*)&A[i]);\n        mask = _mm_loadu_si128((__m128i*)&cond[i]);\n\n        // Calculate difference between current and previous values\n        diff_int = _mm_sub_epi32(curr, prev);\n\n        // Convert difference to float\n        diff_float = _mm_cvtepi32_ps(diff_int);\n\n        // Apply mask to set diff to 0.0f where cond is false\n        diff_float = _mm_blendv_ps(_mm_setzero_ps(), diff_float, _mm_castsi128_ps(_mm_cmpeq_epi32(mask, mask_true)));\n\n        // Store the result in diff array\n        _mm_storeu_ps(&diff[i], diff_float);\n\n        // Update prev for the next iteration\n        prev = curr;\n    }\n}\n```"}
{"task_id": "SimdBench_58_SSE", "completion": "```c\nvoid conditional_diff_simd(const int32_t* A, const bool* cond, float* diff, size_t size) {\n    __m128i prev = _mm_setzero_si128();\n    __m128i mask_true = _mm_set1_epi32(-1); // All bits set to 1\n    __m128i mask_false = _mm_setzero_si128(); // All bits set to 0\n    __m128i mask;\n    __m128i curr, diff_int;\n    __m128 diff_float;\n\n    for (size_t i = 0; i < size; i += 4) {\n        // Load current values from A and cond arrays\n        curr = _mm_loadu_si128((__m128i*)(A + i));\n        mask = _mm_loadu_si128((__m128i*)(cond + i));\n\n        // Calculate difference between current and previous values\n        diff_int = _mm_sub_epi32(curr, prev);\n\n        // Convert difference to float\n        diff_float = _mm_cvtepi32_ps(diff_int);\n\n        // Apply mask to set diff to 0.0f where cond is false\n        diff_float = _mm_blendv_ps(_mm_setzero_ps(), diff_float, _mm_castsi128_ps(_mm_cmpeq_epi32(mask, mask_true)));\n\n        // Store the result in diff array\n        _mm_storeu_ps(diff + i, diff_float);\n\n        // Update prev for the next iteration\n        prev = curr;\n    }\n}\n```"}
{"task_id": "SimdBench_59_SSE", "completion": "```c\nvoid widening_uint_simd(const uint32_t* src, uint64_t* dst, size_t length) {\n    size_t i;\n    __m128i* src_ptr = (__m128i*)src;\n    __m128i* dst_ptr = (__m128i*)dst;\n    __m128i mask = _mm_set_epi32(-1, -1, 0, 0);\n\n    for (i = 0; i < length / 2; i++) {\n        __m128i src_values = _mm_load_si128(&src_ptr[i]);\n        __m128i widened_values = _mm_unpacklo_epi32(src_values, _mm_setzero_si128());\n        widened_values = _mm_or_si128(widened_values, mask);\n        _mm_store_si128(&dst_ptr[i], widened_values);\n    }\n}\n```"}
{"task_id": "SimdBench_59_SSE", "completion": "```c\nvoid widening_uint_simd(const uint32_t* src, uint64_t* dst, size_t length) {\n    size_t i;\n    for (i = 0; i < length; i += 2) {\n        __m128i src_vec = _mm_loadu_si128((__m128i*)(src + i));\n        __m128i src_extended = _mm_cvtepu32_epi64(src_vec);\n        __m128i high_bits = _mm_set1_epi64x(0xFFFFFFFF00000000);\n        __m128i result = _mm_or_si128(src_extended, high_bits);\n        _mm_storeu_si128((__m128i*)(dst + i), result);\n    }\n}\n```"}
{"task_id": "SimdBench_59_SSE", "completion": "```c\nvoid widening_uint_simd(const uint32_t* src, uint64_t* dst, size_t length) {\n    size_t i;\n    for (i = 0; i < length; i += 2) {\n        __m128i src_vec = _mm_loadu_si128((__m128i*)(src + i));\n        __m128i src_extended = _mm_cvtepu32_epi64(src_vec);\n        __m128i high_bits = _mm_set1_epi64x(0xFFFFFFFF00000000);\n        __m128i result = _mm_or_si128(src_extended, high_bits);\n        _mm_storeu_si128((__m128i*)(dst + i), result);\n    }\n}\n```  "}
{"task_id": "SimdBench_59_SSE", "completion": "```c\nvoid widening_uint_simd(const uint32_t* src, uint64_t* dst, size_t length) {\n    size_t i;\n    __m128i src_vec, mask_vec;\n    __m128i* src_ptr = (__m128i*)src;\n    __m128i* dst_ptr = (__m128i*)dst;\n    \n    mask_vec = _mm_set_epi32(-1, -1, -1, -1);\n    \n    for (i = 0; i < length / 2; i++) {\n        src_vec = _mm_load_si128(src_ptr);\n        src_ptr++;\n        \n        __m128i src_wide = _mm_cvtepu32_epi64(src_vec);\n        __m128i result = _mm_or_si128(src_wide, _mm_slli_si128(mask_vec, 4));\n        \n        _mm_store_si128(dst_ptr, result);\n        dst_ptr++;\n    }\n}\n```  "}
{"task_id": "SimdBench_59_SSE", "completion": "```c\nvoid widening_uint_simd(const uint32_t* src, uint64_t* dst, size_t length) {\n    size_t i;\n    __m128i src_vec, dst_vec;\n    __m128i high_bits = _mm_set1_epi32(0xFFFFFFFF);\n\n    for (i = 0; i < length; i += 2) {\n        src_vec = _mm_loadu_si128((__m128i*)(src + i));\n        src_vec = _mm_cvtepu32_epi64(src_vec);\n        dst_vec = _mm_or_si128(src_vec, _mm_slli_si128(high_bits, 4));\n        _mm_storeu_si128((__m128i*)(dst + i), dst_vec);\n    }\n}\n```"}
{"task_id": "SimdBench_60_SSE", "completion": "```c\ndouble indexed_sum_simd(const double* vec, const int16_t* index, size_t length) {\n    __m128d sum = _mm_setzero_pd();\n    \n    for (size_t i = 0; i < length; i += 2) {\n        __m128d v1 = _mm_loadu_pd(&vec[index[i]]);\n        __m128d v2 = _mm_loadu_pd(&vec[index[i + 1]]);\n        sum = _mm_add_pd(sum, v1);\n        sum = _mm_add_pd(sum, v2);\n    }\n    \n    double result[2];\n    _mm_storeu_pd(result, sum);\n    \n    return result[0] + result[1];\n}\n```  "}
{"task_id": "SimdBench_60_SSE", "completion": "```c\ndouble indexed_sum_simd(const double* vec, const int16_t* index, size_t length) {\n    __m128d sum = _mm_setzero_pd();\n    \n    for (size_t i = 0; i < length; i += 2) {\n        __m128d v1 = _mm_loadu_pd(&vec[index[i]]);\n        __m128d v2 = _mm_loadu_pd(&vec[index[i + 1]]);\n        sum = _mm_add_pd(sum, v1);\n        sum = _mm_add_pd(sum, v2);\n    }\n    \n    double result[2];\n    _mm_storeu_pd(result, sum);\n    \n    return result[0] + result[1];\n}\n```  "}
{"task_id": "SimdBench_60_SSE", "completion": "```c\ndouble indexed_sum_simd(const double* vec, const int16_t* index, size_t length) {\n    __m128d sum = _mm_setzero_pd();\n    \n    for (size_t i = 0; i < length; i += 2) {\n        __m128d v1 = _mm_loadu_pd(&vec[index[i]]);\n        __m128d v2 = _mm_loadu_pd(&vec[index[i + 1]]);\n        \n        sum = _mm_add_pd(sum, v1);\n        sum = _mm_add_pd(sum, v2);\n    }\n    \n    double result[2];\n    _mm_storeu_pd(result, sum);\n    \n    return result[0] + result[1];\n}\n```  "}
{"task_id": "SimdBench_60_SSE", "completion": "```c\ndouble indexed_sum_simd(const double* vec, const int16_t* index, size_t length) {\n    __m128d sum = _mm_setzero_pd();\n    \n    for (size_t i = 0; i < length; i += 2) {\n        __m128i idx = _mm_loadu_si128((__m128i*)&index[i]);\n        __m128d val = _mm_i32gather_pd(&vec[0], idx, 8);\n        sum = _mm_add_pd(sum, val);\n    }\n    \n    double result[2];\n    _mm_storeu_pd(result, sum);\n    \n    return result[0] + result[1];\n}\n```"}
{"task_id": "SimdBench_60_SSE", "completion": "```c\ndouble indexed_sum_simd(const double* vec, const int16_t* index, size_t length) {\n    __m128d sum = _mm_setzero_pd();\n    \n    for (size_t i = 0; i < length; i += 2) {\n        __m128d v1 = _mm_loadu_pd(&vec[index[i]]);\n        __m128d v2 = _mm_loadu_pd(&vec[index[i + 1]]);\n        \n        sum = _mm_add_pd(sum, v1);\n        sum = _mm_add_pd(sum, v2);\n    }\n    \n    double result[2];\n    _mm_storeu_pd(result, sum);\n    \n    return result[0] + result[1];\n}\n```  "}
{"task_id": "SimdBench_61_SSE", "completion": "```c\nvoid simple_conv2d_simd(const double* input, const double* kernel, double * output, size_t input_size, size_t kernel_size) {\n    size_t output_size = input_size - kernel_size + 1;\n    size_t output_area = output_size * output_size;\n    \n    for (size_t i = 0; i < output_area; ++i) {\n        __m128d sum = _mm_setzero_pd();\n        \n        for (size_t j = 0; j < kernel_size; ++j) {\n            for (size_t k = 0; k < kernel_size; ++k) {\n                size_t input_index = (i / output_size + j) * input_size + i % output_size + k;\n                size_t kernel_index = j * kernel_size + k;\n                \n                __m128d input_val = _mm_loadu_pd(&input[input_index]);\n                __m128d kernel_val = _mm_loadu_pd(&kernel[kernel_index]);\n                \n                sum = _mm_add_pd(sum, _mm_mul_pd(input_val, kernel_val));\n            }\n        }\n        \n        __m128d zero = _mm_setzero_pd();\n        sum = _mm_max_pd(sum, zero);\n        \n        _mm_storeu_pd(&output[i], sum);\n    }\n}\n```  "}
{"task_id": "SimdBench_61_SSE", "completion": "```c\nvoid simple_conv2d_simd(const double* input, const double* kernel, double * output, size_t input_size, size_t kernel_size) {\n    const size_t output_size = input_size - kernel_size + 1;\n    const size_t output_area = output_size * output_size;\n    \n    for (size_t i = 0; i < output_area; ++i) {\n        __m128d sum = _mm_setzero_pd();\n        \n        for (size_t ky = 0; ky < kernel_size; ++ky) {\n            for (size_t kx = 0; kx < kernel_size; ++kx) {\n                size_t input_index = (i / output_size + ky) * input_size + i % output_size + kx;\n                size_t kernel_index = ky * kernel_size + kx;\n                \n                __m128d input_val = _mm_loadu_pd(&input[input_index]);\n                __m128d kernel_val = _mm_loadu_pd(&kernel[kernel_index]);\n                \n                sum = _mm_add_pd(sum, _mm_mul_pd(input_val, kernel_val));\n            }\n        }\n        \n        sum = _mm_max_pd(sum, _mm_setzero_pd());\n        _mm_storeu_pd(&output[i], sum);\n    }\n}\n```  "}
{"task_id": "SimdBench_61_SSE", "completion": "```c\nvoid simple_conv2d_simd(const double* input, const double* kernel, double * output, size_t input_size, size_t kernel_size) {\n    const size_t output_size = input_size - kernel_size + 1;\n    const size_t output_size_sq = output_size * output_size;\n    \n    for (size_t i = 0; i < output_size_sq; ++i) {\n        __m128d sum = _mm_setzero_pd();\n        \n        for (size_t ky = 0; ky < kernel_size; ++ky) {\n            for (size_t kx = 0; kx < kernel_size; ++kx) {\n                size_t input_idx = (i / output_size + ky) * input_size + i % output_size + kx;\n                size_t kernel_idx = ky * kernel_size + kx;\n                \n                __m128d input_val = _mm_loadu_pd(&input[input_idx]);\n                __m128d kernel_val = _mm_loadu_pd(&kernel[kernel_idx]);\n                \n                sum = _mm_add_pd(sum, _mm_mul_pd(input_val, kernel_val));\n            }\n        }\n        \n        sum = _mm_max_pd(sum, _mm_setzero_pd());\n        _mm_storeu_pd(&output[i], sum);\n    }\n}\n```  "}
{"task_id": "SimdBench_61_SSE", "completion": "```c\nvoid simple_conv2d_simd(const double* input, const double* kernel, double * output, size_t input_size, size_t kernel_size) {\n    size_t output_size = input_size - kernel_size + 1;\n    size_t output_area = output_size * output_size;\n\n    for (size_t i = 0; i < output_area; ++i) {\n        __m128d sum = _mm_setzero_pd();\n\n        for (size_t j = 0; j < kernel_size; ++j) {\n            for (size_t k = 0; k < kernel_size; ++k) {\n                size_t input_index = (i / output_size + j) * input_size + (i % output_size + k);\n                size_t kernel_index = j * kernel_size + k;\n\n                __m128d input_val = _mm_loadu_pd(&input[input_index]);\n                __m128d kernel_val = _mm_loadu_pd(&kernel[kernel_index]);\n                sum = _mm_add_pd(sum, _mm_mul_pd(input_val, kernel_val));\n            }\n        }\n\n        sum = _mm_max_pd(sum, _mm_setzero_pd());\n        _mm_storeu_pd(&output[i], sum);\n    }\n}\n```  "}
{"task_id": "SimdBench_61_SSE", "completion": "```c\nvoid simple_conv2d_simd(const double* input, const double* kernel, double * output, size_t input_size, size_t kernel_size) {\n    const size_t output_size = input_size - kernel_size + 1;\n    const size_t output_area = output_size * output_size;\n    \n    for (size_t i = 0; i < output_area; ++i) {\n        __m128d sum = _mm_setzero_pd();\n\n        for (size_t ky = 0; ky < kernel_size; ++ky) {\n            for (size_t kx = 0; kx < kernel_size; ++kx) {\n                size_t input_index = (i / output_size + ky) * input_size + i % output_size + kx;\n                size_t kernel_index = ky * kernel_size + kx;\n                __m128d input_val = _mm_loadu_pd(&input[input_index]);\n                __m128d kernel_val = _mm_loadu_pd(&kernel[kernel_index]);\n                sum = _mm_add_pd(sum, _mm_mul_pd(input_val, kernel_val));\n            }\n        }\n\n        __m128d zero = _mm_setzero_pd();\n        sum = _mm_max_pd(sum, zero);\n        _mm_storeu_pd(&output[i], sum);\n    }\n}\n```  "}
{"task_id": "SimdBench_62_SSE", "completion": "```cpp\nbool has_close_elements_simd(const std::vector<double> & numbers, double threshold){\n    const int n = numbers.size();\n    const int simd_size = 2;\n    __m128d threshold_vec = _mm_set1_pd(threshold);\n\n    for (int i = 0; i < n - simd_size + 1; i += simd_size) {\n        __m128d num1 = _mm_loadu_pd(&numbers[i]);\n        __m128d num2 = _mm_loadu_pd(&numbers[i + 1]);\n\n        __m128d diff = _mm_sub_pd(num1, num2);\n        __m128d abs_diff = _mm_andnot_pd(_mm_set1_pd(-0.0), diff);\n        __m128d cmp = _mm_cmplt_pd(abs_diff, threshold_vec);\n\n        if (_mm_movemask_pd(cmp) != 0) {\n            return true;\n        }\n    }\n\n    return false;\n}\n```  "}
{"task_id": "SimdBench_62_SSE", "completion": "```cpp\nbool has_close_elements_simd(const std::vector<double> & numbers, double threshold){\n    const int n = numbers.size();\n    const int simd_width = 2;\n    const int simd_size = n / simd_width;\n\n    __m128d threshold_vec = _mm_set1_pd(threshold);\n\n    for (int i = 0; i < simd_size; ++i) {\n        __m128d vec1 = _mm_loadu_pd(&numbers[i * simd_width]);\n        __m128d vec2 = _mm_loadu_pd(&numbers[i * simd_width + simd_width]);\n\n        __m128d diff = _mm_sub_pd(vec1, vec2);\n        __m128d abs_diff = _mm_and_pd(diff, _mm_set1_pd(-0.));\n        __m128d cmp = _mm_cmplt_pd(abs_diff, threshold_vec);\n\n        if (_mm_movemask_pd(cmp) != 0) {\n            return true;\n        }\n    }\n\n    return false;\n}\n```  "}
{"task_id": "SimdBench_62_SSE", "completion": "```cpp\nbool has_close_elements_simd(const std::vector<double> & numbers, double threshold){\n    const int size = numbers.size();\n    const int simdSize = 2;\n    \n    for (int i = 0; i < size - simdSize; i += simdSize) {\n        __m128d vec1 = _mm_loadu_pd(&numbers[i]);\n        __m128d vec2 = _mm_loadu_pd(&numbers[i + 2]);\n        \n        __m128d diff = _mm_sub_pd(vec1, vec2);\n        __m128d absDiff = _mm_and_pd(diff, _mm_set1_pd(-0.));\n        __m128d thresholdVec = _mm_set1_pd(threshold);\n        __m128d cmp = _mm_cmplt_pd(absDiff, thresholdVec);\n        \n        if (_mm_movemask_pd(cmp) != 0) {\n            return true;\n        }\n    }\n    \n    return false;\n}\n```  "}
{"task_id": "SimdBench_62_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nbool has_close_elements_simd(const std::vector<double> & numbers, double threshold){\n    const int size = numbers.size();\n    const int simdSize = 2;\n    \n    for (int i = 0; i < size - 1; i += simdSize) {\n        __m128d num1 = _mm_loadu_pd(&numbers[i]);\n        __m128d num2 = _mm_loadu_pd(&numbers[i + 1]);\n        \n        __m128d diff = _mm_sub_pd(num1, num2);\n        __m128d absDiff = _mm_and_pd(diff, _mm_set1_pd(-0.0));\n        __m128d cmp = _mm_cmplt_pd(absDiff, _mm_set1_pd(threshold));\n        \n        if (_mm_movemask_pd(cmp) != 0) {\n            return true;\n        }\n    }\n    \n    return false;\n}\n```  "}
{"task_id": "SimdBench_62_SSE", "completion": "```cpp\nbool has_close_elements_simd(const std::vector<double> & numbers, double threshold){\n    const int n = numbers.size();\n    const int simd_size = 2;\n    const int simd_count = n / simd_size;\n\n    __m128d threshold_vec = _mm_set1_pd(threshold);\n\n    for (int i = 0; i < simd_count; ++i) {\n        __m128d vec1 = _mm_loadu_pd(&numbers[i * simd_size]);\n        __m128d vec2 = _mm_loadu_pd(&numbers[i * simd_size + 2]);\n\n        __m128d diff = _mm_sub_pd(vec1, vec2);\n        __m128d abs_diff = _mm_and_pd(diff, _mm_set1_pd(-0.0));\n        __m128d cmp = _mm_cmplt_pd(abs_diff, threshold_vec);\n\n        if (_mm_movemask_pd(cmp) != 0) {\n            return true;\n        }\n    }\n\n    return false;\n}\n```  "}
{"task_id": "SimdBench_63_SSE", "completion": "```cpp\nbool below_zero_simd(std::vector<int> operations) {\n    const int size = operations.size();\n    const int simdSize = 4;\n    int i = 0;\n    \n    __m128i balance = _mm_setzero_si128();\n    \n    for (; i <= size - simdSize; i += simdSize) {\n        __m128i ops = _mm_loadu_si128((__m128i*)&operations[i]);\n        balance = _mm_add_epi32(balance, ops);\n        \n        __m128i mask = _mm_cmplt_epi32(balance, _mm_setzero_si128());\n        if (_mm_movemask_epi8(mask) != 0) {\n            return true;\n        }\n    }\n    \n    int remainingOps[simdSize];\n    for (int j = 0; i < size; ++i, ++j) {\n        remainingOps[j] = operations[i];\n    }\n    \n    __m128i remaining = _mm_loadu_si128((__m128i*)remainingOps);\n    balance = _mm_add_epi32(balance, remaining);\n    \n    __m128i mask = _mm_cmplt_epi32(balance, _mm_setzero_si128());\n    return _mm_movemask_epi8(mask) != 0;\n}\n```"}
{"task_id": "SimdBench_63_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nbool below_zero_simd(std::vector<int> operations) {\n    __m128i balance = _mm_setzero_si128();\n    \n    for (size_t i = 0; i < operations.size(); i += 4) {\n        __m128i ops = _mm_loadu_si128((__m128i*)&operations[i]);\n        balance = _mm_add_epi32(balance, ops);\n        \n        __m128i mask = _mm_cmplt_epi32(balance, _mm_setzero_si128());\n        if (_mm_movemask_epi8(mask) != 0) {\n            return true;\n        }\n    }\n    \n    return false;\n}\n```"}
{"task_id": "SimdBench_63_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nbool below_zero_simd(std::vector<int> operations) {\n    __m128i balance = _mm_setzero_si128();\n    for (size_t i = 0; i < operations.size(); i += 4) {\n        __m128i ops = _mm_loadu_si128((__m128i*)&operations[i]);\n        balance = _mm_add_epi32(balance, ops);\n        __m128i mask = _mm_cmplt_epi32(balance, _mm_setzero_si128());\n        if (_mm_movemask_epi8(mask) != 0) {\n            return true;\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_63_SSE", "completion": "```cpp\nbool below_zero_simd(std::vector<int> operations){\n    const int size = operations.size();\n    const int simdSize = 4;\n    int i = 0;\n    \n    __m128i balance = _mm_setzero_si128();\n    \n    for (; i <= size - simdSize; i += simdSize) {\n        __m128i depositWithdrawal = _mm_loadu_si128((__m128i*)&operations[i]);\n        balance = _mm_add_epi32(balance, depositWithdrawal);\n        \n        __m128i mask = _mm_cmplt_epi32(balance, _mm_setzero_si128());\n        if (_mm_movemask_epi8(mask) != 0) {\n            return true;\n        }\n    }\n    \n    int remainingOps[simdSize];\n    for (int j = 0; i < size; ++i, ++j) {\n        remainingOps[j] = operations[i];\n    }\n    \n    __m128i remainingBalance = _mm_setzero_si128();\n    for (int j = 0; j < size - i; ++j) {\n        remainingBalance = _mm_add_epi32(remainingBalance, _mm_set1_epi32(remainingOps[j]));\n    }\n    \n    __m128i mask = _mm_cmplt_epi32(remainingBalance, _mm_setzero_si128());\n    return _mm_movemask_epi8(mask) != 0;\n}\n```"}
{"task_id": "SimdBench_63_SSE", "completion": "```cpp\nbool below_zero_simd(std::vector<int> operations) {\n    __m128i balance = _mm_setzero_si128();\n    for (size_t i = 0; i < operations.size(); i += 4) {\n        __m128i ops = _mm_loadu_si128((__m128i*)&operations[i]);\n        balance = _mm_add_epi32(balance, ops);\n        __m128i mask = _mm_cmplt_epi32(balance, _mm_setzero_si128());\n        if (_mm_movemask_epi8(mask) != 0) {\n            return true;\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_64_SSE", "completion": "```\ndouble mean_absolute_deviation_simd(std::vector<double> numbers){\n    __m128d sum = _mm_setzero_pd();\n    __m128d mean = _mm_setzero_pd();\n    int n = numbers.size();\n    \n    for (int i = 0; i < n; i += 2) {\n        __m128d data = _mm_loadu_pd(&numbers[i]);\n        sum = _mm_add_pd(sum, data);\n    }\n    \n    mean = _mm_div_pd(sum, _mm_set1_pd(n));\n    \n    __m128d mad_sum = _mm_setzero_pd();\n    for (int i = 0; i < n; i += 2) {\n        __m128d data = _mm_loadu_pd(&numbers[i]);\n        __m128d diff = _mm_sub_pd(data, mean);\n        __m128d abs_diff = _mm_andnot_pd(_mm_set1_pd(-0.0), diff);\n        mad_sum = _mm_add_pd(mad_sum, abs_diff);\n    }\n    \n    __m128d result = _mm_div_pd(mad_sum, _mm_set1_pd(n));\n    \n    double res[2];\n    _mm_storeu_pd(res, result);\n    \n    return (res[0] + res[1]) / 2.0;\n}\n```"}
{"task_id": "SimdBench_64_SSE", "completion": "```\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\ndouble mean_absolute_deviation_simd(std::vector<double> numbers){\n    int n = numbers.size();\n    __m128d sum = _mm_setzero_pd();\n    __m128d mean = _mm_setzero_pd();\n\n    for (int i = 0; i < n; i += 2) {\n        __m128d vec = _mm_loadu_pd(&numbers[i]);\n        sum = _mm_add_pd(sum, vec);\n    }\n\n    mean = _mm_div_pd(sum, _mm_set1_pd(n));\n\n    __m128d mad_sum = _mm_setzero_pd();\n    for (int i = 0; i < n; i += 2) {\n        __m128d vec = _mm_loadu_pd(&numbers[i]);\n        __m128d diff = _mm_sub_pd(vec, mean);\n        __m128d abs_diff = _mm_and_pd(diff, _mm_set1_pd(-0.0));\n        mad_sum = _mm_add_pd(mad_sum, abs_diff);\n    }\n\n    __m128d result = _mm_div_pd(mad_sum, _mm_set1_pd(n));\n    double mad;\n    _mm_store_sd(&mad, result);\n    \n    return mad;\n}\n```"}
{"task_id": "SimdBench_64_SSE", "completion": "```\ndouble mean_absolute_deviation_simd(std::vector<double> numbers){\n    int n = numbers.size();\n    __m128d sum = _mm_setzero_pd();\n    __m128d mean = _mm_setzero_pd();\n    \n    for (int i = 0; i < n; i += 2) {\n        __m128d data = _mm_loadu_pd(&numbers[i]);\n        sum = _mm_add_pd(sum, data);\n    }\n    \n    mean = _mm_div_pd(sum, _mm_set1_pd(n));\n    \n    __m128d mad_sum = _mm_setzero_pd();\n    for (int i = 0; i < n; i += 2) {\n        __m128d data = _mm_loadu_pd(&numbers[i]);\n        __m128d diff = _mm_sub_pd(data, mean);\n        __m128d abs_diff = _mm_and_pd(diff, _mm_set1_pd(-0.));\n        mad_sum = _mm_add_pd(mad_sum, abs_diff);\n    }\n    \n    __m128d mad = _mm_div_pd(mad_sum, _mm_set1_pd(n));\n    \n    double result[2];\n    _mm_storeu_pd(result, mad);\n    \n    return (result[0] + result[1]) / 2.0;\n}\n```"}
{"task_id": "SimdBench_64_SSE", "completion": "```\ndouble mean_absolute_deviation_simd(std::vector<double> numbers){\n    int n = numbers.size();\n    __m128d sum = _mm_setzero_pd();\n    __m128d mean = _mm_setzero_pd();\n    \n    for (int i = 0; i < n; i += 2) {\n        __m128d vec = _mm_loadu_pd(&numbers[i]);\n        sum = _mm_add_pd(sum, vec);\n    }\n    \n    mean = _mm_div_pd(sum, _mm_set1_pd(n));\n    \n    __m128d mad_sum = _mm_setzero_pd();\n    for (int i = 0; i < n; i += 2) {\n        __m128d vec = _mm_loadu_pd(&numbers[i]);\n        __m128d diff = _mm_sub_pd(vec, mean);\n        __m128d abs_diff = _mm_and_pd(diff, _mm_set1_pd(-0.0));\n        mad_sum = _mm_add_pd(mad_sum, abs_diff);\n    }\n    \n    __m128d result = _mm_div_pd(mad_sum, _mm_set1_pd(n));\n    \n    double res[2];\n    _mm_storeu_pd(res, result);\n    \n    return (res[0] + res[1]) / 2.0;\n}\n```"}
{"task_id": "SimdBench_64_SSE", "completion": "```\ndouble mean_absolute_deviation_simd(std::vector<double> numbers){\n    int n = numbers.size();\n    __m128d sum = _mm_setzero_pd();\n    __m128d mean = _mm_setzero_pd();\n    \n    for (int i = 0; i < n; i += 2) {\n        __m128d data = _mm_loadu_pd(&numbers[i]);\n        sum = _mm_add_pd(sum, data);\n    }\n    \n    mean = _mm_div_pd(sum, _mm_set1_pd(n));\n    sum = _mm_setzero_pd();\n    \n    for (int i = 0; i < n; i += 2) {\n        __m128d data = _mm_loadu_pd(&numbers[i]);\n        __m128d diff = _mm_sub_pd(data, mean);\n        __m128d abs_diff = _mm_and_pd(diff, _mm_set1_pd(-0.0));\n        sum = _mm_add_pd(sum, abs_diff);\n    }\n    \n    __m128d result = _mm_hadd_pd(sum, sum);\n    double mad;\n    _mm_store_sd(&mad, result);\n    \n    return mad / n;\n}\n```"}
{"task_id": "SimdBench_65_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nstd::vector<int> intersperse_simd(std::vector<int> numbers, int delimeter) {\n    std::vector<int> result;\n    __m128i delimiter_vec = _mm_set1_epi32(delimeter);\n    \n    for (size_t i = 0; i < numbers.size(); i += 4) {\n        __m128i numbers_vec = _mm_loadu_si128((__m128i*)&numbers[i]);\n        __m128i shifted_numbers_vec = _mm_alignr_epi8(numbers_vec, numbers_vec, 4);\n        \n        __m128i interspersed_vec = _mm_unpacklo_epi32(numbers_vec, delimiter_vec);\n        __m128i interspersed_shifted_vec = _mm_unpacklo_epi32(shifted_numbers_vec, delimiter_vec);\n        \n        _mm_storeu_si128((__m128i*)&result[i * 2], interspersed_vec);\n        _mm_storeu_si128((__m128i*)&result[i * 2 + 4], interspersed_shifted_vec);\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_65_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nstd::vector<int> intersperse_simd(std::vector<int> numbers, int delimeter) {\n    std::vector<int> result;\n    __m128i delim = _mm_set1_epi32(delimeter);\n    int size = numbers.size();\n    \n    if (size == 0) {\n        return result;\n    }\n    \n    int numPairs = size - 1;\n    int resultSize = size + numPairs;\n    result.resize(resultSize);\n    \n    __m128i* input = (__m128i*)numbers.data();\n    __m128i* output = (__m128i*)result.data();\n    \n    for (int i = 0; i < numPairs; ++i) {\n        _mm_storeu_si128(output++, _mm_loadu_si128(input++));\n        _mm_storeu_si128(output++, delim);\n    }\n    \n    _mm_storeu_si128(output, _mm_loadu_si128(input));\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_65_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nstd::vector<int> intersperse_simd(std::vector<int> numbers, int delimeter){\n    std::vector<int> result;\n    __m128i delim = _mm_set1_epi32(delimeter);\n    int size = numbers.size();\n    \n    if(size == 0){\n        return result;\n    }\n    \n    int numPairs = size - 1;\n    result.reserve(size + numPairs);\n    \n    __m128i* input = (__m128i*)numbers.data();\n    __m128i* output = (__m128i*)result.data();\n    \n    for(int i = 0; i < numPairs; ++i){\n        _mm_storeu_si128(output++, _mm_loadu_si128(input++));\n        _mm_storeu_si128(output++, delim);\n    }\n    \n    _mm_storeu_si128(output, _mm_loadu_si128(input));\n    \n    return result;\n}\n```  "}
{"task_id": "SimdBench_65_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nstd::vector<int> intersperse_simd(std::vector<int> numbers, int delimeter) {\n    std::vector<int> result;\n    if (numbers.size() < 2) {\n        return numbers;\n    }\n\n    __m128i delim = _mm_set1_epi32(delimeter);\n    __m128i* num_ptr = (__m128i*)numbers.data();\n    int num_size = numbers.size();\n\n    for (int i = 0; i < num_size - 1; ++i) {\n        result.push_back(_mm_extract_epi32(num_ptr[i], 0));\n        result.push_back(delimeter);\n        result.push_back(_mm_extract_epi32(num_ptr[i], 1));\n        result.push_back(delimeter);\n        result.push_back(_mm_extract_epi32(num_ptr[i], 2));\n        result.push_back(delimeter);\n        result.push_back(_mm_extract_epi32(num_ptr[i], 3));\n    }\n\n    result.push_back(_mm_extract_epi32(num_ptr[num_size - 1], 0));\n    return result;\n}\n```"}
{"task_id": "SimdBench_65_SSE", "completion": "```cpp\nstd::vector<int> intersperse_simd(std::vector<int> numbers, int delimeter){\n    std::vector<int> result;\n    __m128i delim = _mm_set1_epi32(delimeter);\n    int numElements = numbers.size();\n    \n    if(numElements == 0){\n        return result;\n    }\n    \n    int numPairs = numElements - 1;\n    result.reserve(numElements + numPairs);\n    \n    __m128i* input = (__m128i*)numbers.data();\n    __m128i* output = (__m128i*)result.data();\n    \n    for(int i = 0; i < numPairs; ++i){\n        _mm_storeu_si128(output++, _mm_loadu_si128(input++));\n        _mm_storeu_si128(output++, delim);\n    }\n    \n    _mm_storeu_si128(output, _mm_loadu_si128(input));\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_66_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nstd::vector<int64_t> sum_product_simd(std::vector<int16_t> numbers){\n    __m128i sum = _mm_setzero_si128();\n    __m128i product = _mm_set1_epi16(1);\n\n    for (size_t i = 0; i < numbers.size(); i += 8) {\n        __m128i vec = _mm_loadu_si128((__m128i*)&numbers[i]);\n        sum = _mm_add_epi16(sum, vec);\n        product = _mm_mullo_epi16(product, vec);\n    }\n\n    int16_t sum_arr[8];\n    int16_t product_arr[8];\n    _mm_storeu_si128((__m128i*)sum_arr, sum);\n    _mm_storeu_si128((__m128i*)product_arr, product);\n\n    int64_t sum_result = 0;\n    int64_t product_result = 1;\n    for (int i = 0; i < 8; i++) {\n        sum_result += sum_arr[i];\n        product_result *= product_arr[i];\n    }\n\n    return {sum_result, product_result};\n}\n```"}
{"task_id": "SimdBench_66_SSE", "completion": "```\nstd::vector<int64_t> sum_product_simd(std::vector<int16_t> numbers){\n    __m128i sum = _mm_setzero_si128();\n    __m128i product = _mm_set1_epi16(1);\n\n    for (size_t i = 0; i < numbers.size(); i += 8) {\n        __m128i vec = _mm_loadu_si128((__m128i*)&numbers[i]);\n        sum = _mm_add_epi16(sum, vec);\n        product = _mm_mullo_epi16(product, vec);\n    }\n\n    int16_t sum_arr[8];\n    int16_t product_arr[8];\n    _mm_storeu_si128((__m128i*)sum_arr, sum);\n    _mm_storeu_si128((__m128i*)product_arr, product);\n\n    int64_t sum_result = 0;\n    int64_t product_result = 1;\n\n    for (int i = 0; i < 8; i++) {\n        sum_result += sum_arr[i];\n        product_result *= product_arr[i];\n    }\n\n    return {sum_result, product_result};\n}\n```"}
{"task_id": "SimdBench_66_SSE", "completion": "```\nstd::vector<int64_t> sum_product_simd(std::vector<int16_t> numbers){\n    __m128i sum = _mm_setzero_si128();\n    __m128i product = _mm_set1_epi16(1);\n\n    for (size_t i = 0; i < numbers.size(); i += 8) {\n        __m128i vec = _mm_loadu_si128((__m128i*)&numbers[i]);\n        sum = _mm_add_epi16(sum, vec);\n        product = _mm_mullo_epi16(product, vec);\n    }\n\n    int16_t sum_arr[8];\n    int16_t product_arr[8];\n    _mm_storeu_si128((__m128i*)sum_arr, sum);\n    _mm_storeu_si128((__m128i*)product_arr, product);\n\n    int64_t sum_result = 0;\n    int64_t product_result = 1;\n    for (int i = 0; i < 8; i++) {\n        sum_result += sum_arr[i];\n        product_result *= product_arr[i];\n    }\n\n    return {sum_result, product_result};\n}\n```"}
{"task_id": "SimdBench_66_SSE", "completion": "```\nstd::vector<int64_t> sum_product_simd(std::vector<int16_t> numbers){\n    __m128i sum = _mm_setzero_si128();\n    __m128i product = _mm_set1_epi16(1);\n\n    for (size_t i = 0; i < numbers.size(); i += 8) {\n        __m128i vec = _mm_loadu_si128((__m128i*)&numbers[i]);\n        sum = _mm_add_epi16(sum, vec);\n        product = _mm_mullo_epi16(product, vec);\n    }\n\n    int16_t sum_arr[8];\n    int16_t product_arr[8];\n    _mm_storeu_si128((__m128i*)sum_arr, sum);\n    _mm_storeu_si128((__m128i*)product_arr, product);\n\n    int64_t sum_result = 0;\n    int64_t product_result = 1;\n    for (int i = 0; i < 8; i++) {\n        sum_result += sum_arr[i];\n        product_result *= product_arr[i];\n    }\n\n    return {sum_result, product_result};\n}\n```"}
{"task_id": "SimdBench_66_SSE", "completion": "```\nstd::vector<int64_t> sum_product_simd(std::vector<int16_t> numbers){\n    __m128i sum = _mm_setzero_si128();\n    __m128i product = _mm_set1_epi16(1);\n\n    for (size_t i = 0; i < numbers.size(); i += 8) {\n        __m128i vec = _mm_loadu_si128((__m128i*)&numbers[i]);\n        sum = _mm_add_epi16(sum, vec);\n        product = _mm_mullo_epi16(product, vec);\n    }\n\n    int16_t sum_arr[8];\n    int16_t product_arr[8];\n    _mm_storeu_si128((__m128i*)sum_arr, sum);\n    _mm_storeu_si128((__m128i*)product_arr, product);\n\n    int64_t sum_result = 0;\n    int64_t product_result = 1;\n    for (int i = 0; i < 8; i++) {\n        sum_result += sum_arr[i];\n        product_result *= product_arr[i];\n    }\n\n    return {sum_result, product_result};\n}\n```"}
{"task_id": "SimdBench_67_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nstd::vector<int> rolling_max_simd(std::vector<int> numbers){\n    std::vector<int> result(numbers.size());\n    __m128i current_max = _mm_set1_epi32(INT_MIN);\n\n    for (size_t i = 0; i < numbers.size(); i += 4) {\n        __m128i input = _mm_loadu_si128((__m128i*)&numbers[i]);\n        current_max = _mm_max_epi32(current_max, input);\n        _mm_storeu_si128((__m128i*)&result[i], current_max);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_67_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> rolling_max_simd(std::vector<int> numbers){\n    std::vector<int> result(numbers.size());\n    __m128i current_max = _mm_set1_epi32(INT_MIN);\n\n    for (size_t i = 0; i < numbers.size(); i += 4) {\n        __m128i input = _mm_loadu_si128((__m128i*)&numbers[i]);\n        current_max = _mm_max_epi32(current_max, input);\n        _mm_storeu_si128((__m128i*)&result[i], current_max);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_67_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nstd::vector<int> rolling_max_simd(std::vector<int> numbers){\n    std::vector<int> result(numbers.size());\n    __m128i current_max = _mm_set1_epi32(INT_MIN);\n\n    for (size_t i = 0; i < numbers.size(); i += 4) {\n        __m128i input = _mm_loadu_si128((__m128i*)&numbers[i]);\n        current_max = _mm_max_epi32(current_max, input);\n        _mm_storeu_si128((__m128i*)&result[i], current_max);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_67_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nstd::vector<int> rolling_max_simd(std::vector<int> numbers){\n    std::vector<int> result(numbers.size());\n    __m128i current_max = _mm_set1_epi32(INT_MIN);\n\n    for (size_t i = 0; i < numbers.size(); i += 4) {\n        __m128i input = _mm_loadu_si128((__m128i*)&numbers[i]);\n        current_max = _mm_max_epi32(current_max, input);\n        _mm_storeu_si128((__m128i*)&result[i], current_max);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_67_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> rolling_max_simd(std::vector<int> numbers){\n    std::vector<int> result(numbers.size());\n    __m128i current_max = _mm_set1_epi32(INT_MIN);\n\n    for (size_t i = 0; i < numbers.size(); i += 4) {\n        __m128i input = _mm_loadu_si128((__m128i*)&numbers[i]);\n        current_max = _mm_max_epi32(current_max, input);\n        _mm_storeu_si128((__m128i*)&result[i], current_max);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_68_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string string_xor_simd(std::string a, std::string b) {\n    const __m128i* a_ptr = reinterpret_cast<const __m128i*>(a.data());\n    const __m128i* b_ptr = reinterpret_cast<const __m128i*>(b.data());\n    __m128i result = _mm_xor_si128(*a_ptr, *b_ptr);\n    \n    std::string output(a.size(), '0');\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(&output[0]), result);\n    \n    return output;\n}\n```  "}
{"task_id": "SimdBench_68_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nstd::string string_xor_simd(std::string a, std::string b){\n    int length = a.size();\n    __m128i* a_ptr = (__m128i*)a.data();\n    __m128i* b_ptr = (__m128i*)b.data();\n    __m128i* result_ptr = (__m128i*)malloc(length * sizeof(__m128i));\n\n    for (int i = 0; i < length / 4; ++i) {\n        __m128i a_val = _mm_load_si128(&a_ptr[i]);\n        __m128i b_val = _mm_load_si128(&b_ptr[i]);\n        __m128i result = _mm_xor_si128(a_val, b_val);\n        _mm_store_si128(&result_ptr[i], result);\n    }\n\n    std::string result_str;\n    for (int i = 0; i < length / 4; ++i) {\n        __m128i res = _mm_load_si128(&result_ptr[i]);\n        result_str.append(reinterpret_cast<char*>(&res), sizeof(__m128i));\n    }\n\n    free(result_ptr);\n    return result_str;\n}\n```  "}
{"task_id": "SimdBench_68_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nstd::string string_xor_simd(std::string a, std::string b){\n    const char* str_a = a.c_str();\n    const char* str_b = b.c_str();\n    int length = a.length();\n\n    __m128i* ptr_a = (__m128i*)str_a;\n    __m128i* ptr_b = (__m128i*)str_b;\n\n    __m128i result;\n    __m128i mask = _mm_set1_epi8(0x01);\n\n    for (int i = 0; i < length / 16; ++i) {\n        __m128i val_a = _mm_load_si128(ptr_a + i);\n        __m128i val_b = _mm_load_si128(ptr_b + i);\n        result = _mm_xor_si128(val_a, val_b);\n        _mm_store_si128(ptr_a + i, result);\n    }\n\n    char* result_str = (char*)str_a;\n    return std::string(result_str, length);\n}\n```"}
{"task_id": "SimdBench_68_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nstd::string string_xor_simd(std::string a, std::string b){\n    const char* a_ptr = a.c_str();\n    const char* b_ptr = b.c_str();\n    size_t length = a.size();\n\n    __m128i* a_data = (__m128i*)a_ptr;\n    __m128i* b_data = (__m128i*)b_ptr;\n\n    __m128i* result = (__m128i*)malloc(length / 16 * sizeof(__m128i));\n\n    for (size_t i = 0; i < length / 16; ++i) {\n        __m128i a_val = _mm_load_si128(&a_data[i]);\n        __m128i b_val = _mm_load_si128(&b_data[i]);\n        __m128i xor_result = _mm_xor_si128(a_val, b_val);\n        _mm_store_si128(&result[i], xor_result);\n    }\n\n    char* result_ptr = (char*)result;\n    std::string result_str(result_ptr, length);\n\n    free(result);\n\n    return result_str;\n}\n```"}
{"task_id": "SimdBench_68_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nstd::string string_xor_simd(std::string a, std::string b){\n    const char* a_ptr = a.c_str();\n    const char* b_ptr = b.c_str();\n    size_t length = a.size();\n\n    __m128i* a_mm = (__m128i*)a_ptr;\n    __m128i* b_mm = (__m128i*)b_ptr;\n    __m128i* result_mm = (__m128i*)_mm_malloc(length / 16 * sizeof(__m128i), 16);\n\n    for (size_t i = 0; i < length / 16; ++i) {\n        __m128i a_val = _mm_load_si128(&a_mm[i]);\n        __m128i b_val = _mm_load_si128(&b_mm[i]);\n        __m128i result = _mm_xor_si128(a_val, b_val);\n        _mm_store_si128(&result_mm[i], result);\n    }\n\n    char* result_ptr = (char*)result_mm;\n    std::string result_str(result_ptr, length);\n    _mm_free(result_mm);\n\n    return result_str;\n}\n```  "}
{"task_id": "SimdBench_69_SSE", "completion": "```\nstd::string longest_simd(const std::vector<std::string> & strings){\n    if(strings.empty()) {\n        return \"None\";\n    }\n\n    __m128i max_length = _mm_setzero_si128();\n    const char* longest_string = strings[0].c_str();\n\n    for(const std::string& str : strings) {\n        const char* str_ptr = str.c_str();\n        __m128i str_length = _mm_set1_epi32(str.size());\n\n        __m128i cmp = _mm_cmpgt_epi32(str_length, max_length);\n        max_length = _mm_blendv_epi8(max_length, str_length, cmp);\n\n        longest_string = _mm_blendv_ps(longest_string, str_ptr, (__m128)cmp);\n    }\n\n    return std::string(longest_string);\n}\n```"}
{"task_id": "SimdBench_69_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n\nstd::string longest_simd(const std::vector<std::string> & strings){\n    if(strings.empty()){\n        return \"\";\n    }\n\n    __m128i max_length = _mm_setzero_si128();\n    const char* longest_str = nullptr;\n\n    for(const std::string& str : strings){\n        __m128i str_length = _mm_set1_epi32(static_cast<int>(str.length()));\n        __m128i cmp = _mm_cmpgt_epi32(str_length, max_length);\n        max_length = _mm_blendv_epi8(max_length, str_length, cmp);\n        longest_str = reinterpret_cast<const char*>(_mm_extract_epi32(str_length, 0) == _mm_extract_epi32(max_length, 0) ? str.c_str() : longest_str);\n    }\n\n    return longest_str;\n}\n```"}
{"task_id": "SimdBench_69_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n\nstd::string longest_simd(const std::vector<std::string> & strings){\n    if(strings.empty()){\n        return \"\";\n    }\n\n    __m128i max_length = _mm_set1_epi32(0);\n    __m128i max_index = _mm_set1_epi32(0);\n    \n    for(int i = 0; i < strings.size(); i++){\n        const char* str = strings[i].c_str();\n        int length = strings[i].size();\n        \n        __m128i current_length = _mm_set1_epi32(length);\n        __m128i compare = _mm_cmpgt_epi32(current_length, max_length);\n        \n        max_length = _mm_blendv_epi8(max_length, current_length, compare);\n        max_index = _mm_blendv_epi8(max_index, _mm_set1_epi32(i), compare);\n    }\n    \n    int result_index[4];\n    _mm_storeu_si128((__m128i*)result_index, max_index);\n    \n    return strings[result_index[0]];\n}\n```"}
{"task_id": "SimdBench_69_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n#include <vector>\n\nstd::string longest_simd(const std::vector<std::string> & strings){\n    if (strings.empty()) {\n        return \"\";\n    }\n\n    __m128i max_length = _mm_setzero_si128();\n    const char* longest_str = strings[0].c_str();\n\n    for (const std::string& str : strings) {\n        const char* str_ptr = str.c_str();\n        __m128i str_length = _mm_set1_epi32(str.length());\n\n        max_length = _mm_max_epi32(max_length, str_length);\n        longest_str = (str.length() >= _mm_cvtsi128_si32(max_length)) ? str_ptr : longest_str;\n    }\n\n    return std::string(longest_str);\n}\n```"}
{"task_id": "SimdBench_69_SSE", "completion": "```\nstd::string longest_simd(const std::vector<std::string> & strings){\n    if(strings.empty()) {\n        return \"None\";\n    }\n\n    __m128i max_length = _mm_setzero_si128();\n    const char* longest_str = strings[0].c_str();\n\n    for(const std::string& str : strings) {\n        __m128i str_length = _mm_set1_epi32(str.length());\n        __m128i cmp = _mm_cmpgt_epi32(str_length, max_length);\n        max_length = _mm_blendv_epi8(max_length, str_length, cmp);\n        longest_str = reinterpret_cast<const char*>(_mm_blendv_epi8(\n            _mm_set1_epi64x(reinterpret_cast<int64_t>(longest_str)),\n            _mm_set1_epi64x(reinterpret_cast<int64_t>(str.c_str())),\n            cmp\n        ));\n    }\n\n    return std::string(longest_str);\n}\n```"}
{"task_id": "SimdBench_70_SSE", "completion": "```c\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nuint64_t greatest_common_divisor_simd(uint64_t a, uint64_t b){\n    __m128i va = _mm_set1_epi64x(a);\n    __m128i vb = _mm_set1_epi64x(b);\n    \n    while (a != b) {\n        if (a > b) {\n            a -= b;\n            va = _mm_set1_epi64x(a);\n        } else {\n            b -= a;\n            vb = _mm_set1_epi64x(b);\n        }\n    }\n    \n    return a;\n}\n```"}
{"task_id": "SimdBench_70_SSE", "completion": "```c\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nuint64_t greatest_common_divisor_simd(uint64_t a, uint64_t b){\n    __m128i va = _mm_set1_epi64x(a);\n    __m128i vb = _mm_set1_epi64x(b);\n    \n    while (a != b) {\n        if (a > b) {\n            a -= b;\n            va = _mm_sub_epi64(va, vb);\n        } else {\n            b -= a;\n            vb = _mm_sub_epi64(vb, va);\n        }\n    }\n    \n    return a;\n}\n```  "}
{"task_id": "SimdBench_70_SSE", "completion": "```c\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nuint64_t greatest_common_divisor_simd(uint64_t a, uint64_t b){\n    __m128i va = _mm_set1_epi64x(a);\n    __m128i vb = _mm_set1_epi64x(b);\n    \n    while (a != b) {\n        __m128i cmp = _mm_cmpeq_epi64(va, vb);\n        if (_mm_movemask_epi8(cmp) == 0xFFFF) {\n            break;\n        }\n        \n        __m128i mask = _mm_cmpgt_epi64(va, vb);\n        va = _mm_blendv_epi8(va, _mm_sub_epi64(va, vb), mask);\n        vb = _mm_blendv_epi8(vb, _mm_sub_epi64(vb, va), mask);\n        \n        a = _mm_cvtsi128_si64(va);\n        b = _mm_cvtsi128_si64(vb);\n    }\n    \n    return a;\n}\n```"}
{"task_id": "SimdBench_70_SSE", "completion": "```c\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nuint64_t greatest_common_divisor_simd(uint64_t a, uint64_t b){\n    __m128i va = _mm_set1_epi64x(a);\n    __m128i vb = _mm_set1_epi64x(b);\n    \n    while (a != b) {\n        if (a > b) {\n            a -= b;\n            va = _mm_sub_epi64(va, vb);\n        } else {\n            b -= a;\n            vb = _mm_sub_epi64(vb, va);\n        }\n    }\n    \n    return a;\n}\n```"}
{"task_id": "SimdBench_70_SSE", "completion": "```c\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nuint64_t greatest_common_divisor_simd(uint64_t a, uint64_t b){\n    __m128i va = _mm_set1_epi64x(a);\n    __m128i vb = _mm_set1_epi64x(b);\n    \n    while (a != b) {\n        if (a > b) {\n            a -= b;\n            va = _mm_sub_epi64(va, vb);\n        } else {\n            b -= a;\n            vb = _mm_sub_epi64(vb, va);\n        }\n    }\n    \n    return a;\n}\n```"}
{"task_id": "SimdBench_71_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::pair<float, float> find_closest_elements_simd(std::vector<float> numbers) {\n    __m128 closest_pair = _mm_set_ps1(0.0f);\n    float min_diff = std::numeric_limits<float>::max();\n    \n    for (size_t i = 0; i < numbers.size() - 1; i += 4) {\n        __m128 num1 = _mm_loadu_ps(&numbers[i]);\n        __m128 num2 = _mm_loadu_ps(&numbers[i + 1]);\n        __m128 diff = _mm_sub_ps(num1, num2);\n        __m128 abs_diff = _mm_andnot_ps(_mm_set1_ps(-0.0f), diff);\n        \n        if (_mm_movemask_ps(abs_diff) == 1) {\n            closest_pair = _mm_shuffle_ps(num1, num2, _MM_SHUFFLE(1, 0, 1, 0));\n            min_diff = std::abs(numbers[i] - numbers[i + 1]);\n        }\n    }\n    \n    float result[4];\n    _mm_storeu_ps(result, closest_pair);\n    \n    return std::make_pair(result[0], result[1]);\n}\n```"}
{"task_id": "SimdBench_71_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nstd::pair<float, float> find_closest_elements_simd(std::vector<float> numbers){\n    __m128 min_diff = _mm_set1_ps(FLT_MAX);\n    __m128 closest_pair;\n\n    for (size_t i = 0; i < numbers.size() - 1; i += 4) {\n        __m128 num1 = _mm_loadu_ps(&numbers[i]);\n        __m128 num2 = _mm_loadu_ps(&numbers[i + 1]);\n\n        __m128 diff = _mm_sub_ps(num1, num2);\n        diff = _mm_and_ps(diff, _mm_set1_ps(-0.0f)); // Absolute difference\n\n        __m128 mask = _mm_cmplt_ps(diff, min_diff);\n        min_diff = _mm_min_ps(diff, min_diff);\n        closest_pair = _mm_blendv_ps(closest_pair, _mm_unpacklo_ps(num1, num2), mask);\n    }\n\n    float closest[4];\n    _mm_storeu_ps(closest, closest_pair);\n\n    return std::make_pair(closest[0], closest[1]);\n}\n```"}
{"task_id": "SimdBench_71_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nstd::pair<float, float> find_closest_elements_simd(std::vector<float> numbers){\n    __m128 min_diff = _mm_set1_ps(FLT_MAX);\n    __m128 closest1, closest2;\n    \n    for (size_t i = 0; i < numbers.size() - 1; i += 4) {\n        __m128 num1 = _mm_loadu_ps(&numbers[i]);\n        __m128 num2 = _mm_loadu_ps(&numbers[i + 1]);\n        \n        __m128 diff = _mm_sub_ps(num1, num2);\n        diff = _mm_and_ps(diff, _mm_castsi128_ps(_mm_set1_epi32(0x7FFFFFFF)));\n        \n        __m128 mask = _mm_cmplt_ps(diff, min_diff);\n        min_diff = _mm_min_ps(diff, min_diff);\n        \n        closest1 = _mm_blendv_ps(closest1, num1, mask);\n        closest2 = _mm_blendv_ps(closest2, num2, mask);\n    }\n    \n    float closest[4];\n    _mm_storeu_ps(closest, closest1);\n    _mm_storeu_ps(closest + 2, closest2);\n    \n    return std::make_pair(std::min(closest[0], closest[1]), std::max(closest[2], closest[3]));\n}\n```  "}
{"task_id": "SimdBench_71_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nstd::pair<float, float> find_closest_elements_simd(std::vector<float> numbers){\n    __m128 min_diff = _mm_set1_ps(std::numeric_limits<float>::max());\n    __m128 closest1, closest2;\n    \n    for (size_t i = 0; i < numbers.size() - 1; i += 4) {\n        __m128 num1 = _mm_loadu_ps(&numbers[i]);\n        __m128 num2 = _mm_loadu_ps(&numbers[i + 1]);\n        \n        __m128 diff = _mm_sub_ps(num1, num2);\n        diff = _mm_and_ps(diff, _mm_castsi128_ps(_mm_set1_epi32(0x7FFFFFFF)));\n        \n        __m128 mask = _mm_cmplt_ps(diff, min_diff);\n        min_diff = _mm_min_ps(diff, min_diff);\n        \n        closest1 = _mm_blendv_ps(closest1, num1, mask);\n        closest2 = _mm_blendv_ps(closest2, num2, mask);\n    }\n    \n    float closest[4];\n    _mm_storeu_ps(closest, closest1);\n    _mm_storeu_ps(closest + 2, closest2);\n    \n    float min_diff_arr[4];\n    _mm_storeu_ps(min_diff_arr, min_diff);\n    \n    float min_diff_val = std::numeric_limits<float>::max();\n    int min_index = 0;\n    for (int i = 0; i < 4; ++i) {\n        if (min_diff_arr[i] < min_diff_val) {\n            min_diff_val = min_diff_arr[i];\n            min_index = i;\n        }\n    }\n    \n    return std::make_pair(closest[min_index], closest[min_index + 1]);\n}\n```  "}
{"task_id": "SimdBench_71_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::pair<float, float> find_closest_elements_simd(std::vector<float> numbers) {\n    __m128 min_diff = _mm_set1_ps(FLT_MAX);\n    __m128 closest_pair;\n\n    for (size_t i = 0; i < numbers.size() - 1; i += 4) {\n        __m128 num1 = _mm_loadu_ps(&numbers[i]);\n        __m128 num2 = _mm_loadu_ps(&numbers[i + 1]);\n        __m128 diff = _mm_sub_ps(num1, num2);\n        diff = _mm_and_ps(diff, _mm_set1_ps(-0.0f)); // Absolute difference\n        __m128 mask = _mm_cmplt_ps(diff, min_diff);\n        min_diff = _mm_min_ps(diff, min_diff);\n        closest_pair = _mm_blendv_ps(closest_pair, _mm_unpacklo_ps(num1, num2), mask);\n    }\n\n    float closest[4];\n    _mm_storeu_ps(closest, closest_pair);\n\n    return std::make_pair(closest[0], closest[1]);\n}\n```"}
{"task_id": "SimdBench_72_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nstd::vector<float> rescale_to_unit_simd(std::vector<float> numbers){\n    __m128 min_val = _mm_set1_ps(*std::min_element(numbers.begin(), numbers.end()));\n    __m128 max_val = _mm_set1_ps(*std::max_element(numbers.begin(), numbers.end()));\n    __m128 range = _mm_sub_ps(max_val, min_val);\n    __m128 zero = _mm_setzero_ps();\n    __m128 one = _mm_set1_ps(1.0f);\n\n    for (size_t i = 0; i < numbers.size(); i += 4) {\n        __m128 input = _mm_loadu_ps(&numbers[i]);\n        __m128 scaled = _mm_div_ps(_mm_sub_ps(input, min_val), range);\n        __m128 result = _mm_mul_ps(scaled, one);\n        _mm_storeu_ps(&numbers[i], result);\n    }\n\n    return numbers;\n}\n```"}
{"task_id": "SimdBench_72_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nstd::vector<float> rescale_to_unit_simd(std::vector<float> numbers){\n    __m128 min_val = _mm_set1_ps(*std::min_element(numbers.begin(), numbers.end()));\n    __m128 max_val = _mm_set1_ps(*std::max_element(numbers.begin(), numbers.end()));\n    __m128 range = _mm_sub_ps(max_val, min_val);\n    __m128 zero = _mm_setzero_ps();\n    __m128 one = _mm_set1_ps(1.0f);\n\n    for (size_t i = 0; i < numbers.size(); i += 4) {\n        __m128 input = _mm_loadu_ps(&numbers[i]);\n        __m128 scaled = _mm_div_ps(_mm_sub_ps(input, min_val), range);\n        __m128 result = _mm_mul_ps(scaled, one);\n        _mm_storeu_ps(&numbers[i], result);\n    }\n\n    return numbers;\n}\n```"}
{"task_id": "SimdBench_72_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nstd::vector<float> rescale_to_unit_simd(std::vector<float> numbers){\n    __m128 min_val = _mm_set1_ps(*std::min_element(numbers.begin(), numbers.end()));\n    __m128 max_val = _mm_set1_ps(*std::max_element(numbers.begin(), numbers.end()));\n    __m128 range = _mm_sub_ps(max_val, min_val);\n    __m128 zero = _mm_setzero_ps();\n    __m128 one = _mm_set1_ps(1.0f);\n\n    for (size_t i = 0; i < numbers.size(); i += 4) {\n        __m128 data = _mm_loadu_ps(&numbers[i]);\n        __m128 scaled = _mm_div_ps(_mm_sub_ps(data, min_val), range);\n        __m128 clamped = _mm_min_ps(_mm_max_ps(scaled, zero), one);\n        _mm_storeu_ps(&numbers[i], clamped);\n    }\n\n    return numbers;\n}\n```"}
{"task_id": "SimdBench_72_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nstd::vector<float> rescale_to_unit_simd(std::vector<float> numbers){\n    __m128 min_val = _mm_set1_ps(*std::min_element(numbers.begin(), numbers.end()));\n    __m128 max_val = _mm_set1_ps(*std::max_element(numbers.begin(), numbers.end()));\n    __m128 range = _mm_sub_ps(max_val, min_val);\n    __m128 zero = _mm_setzero_ps();\n    __m128 one = _mm_set1_ps(1.0f);\n\n    for (size_t i = 0; i < numbers.size(); i += 4) {\n        __m128 input = _mm_loadu_ps(&numbers[i]);\n        __m128 scaled = _mm_div_ps(_mm_sub_ps(input, min_val), range);\n        __m128 result = _mm_mul_ps(scaled, one);\n        _mm_storeu_ps(&numbers[i], result);\n    }\n\n    return numbers;\n}\n```"}
{"task_id": "SimdBench_72_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nstd::vector<float> rescale_to_unit_simd(std::vector<float> numbers){\n    __m128 min_val = _mm_set1_ps(*std::min_element(numbers.begin(), numbers.end()));\n    __m128 max_val = _mm_set1_ps(*std::max_element(numbers.begin(), numbers.end()));\n    __m128 range = _mm_sub_ps(max_val, min_val);\n    __m128 zero = _mm_setzero_ps();\n    __m128 one = _mm_set1_ps(1.0f);\n    \n    for (size_t i = 0; i < numbers.size(); i += 4) {\n        __m128 input = _mm_loadu_ps(&numbers[i]);\n        __m128 scaled = _mm_div_ps(_mm_sub_ps(input, min_val), range);\n        __m128 result = _mm_mul_ps(scaled, one);\n        _mm_storeu_ps(&numbers[i], result);\n    }\n    \n    return numbers;\n}\n```  "}
{"task_id": "SimdBench_73_SSE", "completion": "```c\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nuint64_t largest_divisor_simd(uint64_t n){\n    __m128i num = _mm_set1_epi64x(n);\n    __m128i divisors = _mm_set_epi64x(n-1, n-2);\n    __m128i result = _mm_setzero_si128();\n    \n    __m128i mask = _mm_cmplt_epi64(divisors, num);\n    __m128i masked_divisors = _mm_and_si128(divisors, mask);\n    \n    __m128i max_divisor = _mm_max_epi64(masked_divisors, result);\n    \n    uint64_t max_divisor_arr[2];\n    _mm_storeu_si128((__m128i*)max_divisor_arr, max_divisor);\n    \n    return max_divisor_arr[0];\n}\n```"}
{"task_id": "SimdBench_73_SSE", "completion": "```c\nuint64_t largest_divisor_simd(uint64_t n){\n    __m128i num = _mm_set1_epi64x(n);\n    __m128i divisors = _mm_set_epi64x(n-1, n-2);\n    __m128i result = _mm_setzero_si128();\n    \n    __m128i mask = _mm_cmplt_epi64(divisors, num);\n    __m128i masked_divisors = _mm_and_si128(divisors, mask);\n    \n    __m128i max_divisor = _mm_max_epi64(masked_divisors, result);\n    \n    uint64_t max_divisor_arr[2];\n    _mm_storeu_si128((__m128i*)max_divisor_arr, max_divisor);\n    \n    return max_divisor_arr[0];\n}\n```"}
{"task_id": "SimdBench_73_SSE", "completion": "```c\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nuint64_t largest_divisor_simd(uint64_t n){\n    __m128i num = _mm_set1_epi64x(n);\n    __m128i divisors = _mm_set_epi64x(n-1, n-2);\n    __m128i result = _mm_setzero_si128();\n\n    __m128i mask = _mm_cmplt_epi64(divisors, num);\n    __m128i masked_divisors = _mm_and_si128(divisors, mask);\n\n    __m128i max_divisor = _mm_max_epi64(masked_divisors, result);\n\n    uint64_t max_divisor_arr[2];\n    _mm_storeu_si128((__m128i*)max_divisor_arr, max_divisor);\n\n    return max_divisor_arr[0];\n}\n```"}
{"task_id": "SimdBench_73_SSE", "completion": "```c\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nuint64_t largest_divisor_simd(uint64_t n){\n    __m128i num = _mm_set1_epi64x(n);\n    __m128i divisors = _mm_set_epi64x(n-1, n-2);\n    __m128i result = _mm_setzero_si128();\n\n    __m128i mask = _mm_cmplt_epi64(divisors, num);\n    __m128i masked_divisors = _mm_and_si128(divisors, mask);\n\n    __m128i max_divisor = _mm_max_epi64(masked_divisors, result);\n\n    uint64_t max_divisor_array[2];\n    _mm_storeu_si128((__m128i*)max_divisor_array, max_divisor);\n\n    return max_divisor_array[0];\n}\n```"}
{"task_id": "SimdBench_73_SSE", "completion": "```c\nuint64_t largest_divisor_simd(uint64_t n){\n    __m128i num = _mm_set1_epi64x(n);\n    __m128i divisors = _mm_set_epi64x(n-1, n-2);\n    __m128i result = _mm_setzero_si128();\n    \n    __m128i mask = _mm_cmplt_epi64(divisors, num);\n    __m128i masked_divisors = _mm_and_si128(divisors, mask);\n    \n    __m128i max_divisor = _mm_max_epi64(masked_divisors, result);\n    \n    uint64_t max_divisor_array[2];\n    _mm_storeu_si128((__m128i*)max_divisor_array, max_divisor);\n    \n    return max_divisor_array[0];\n}\n```"}
{"task_id": "SimdBench_74_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> factorize_simd(int n){\n    std::vector<int> factors;\n    int factor = 2;\n    while (n > 1) {\n        if (n % factor == 0) {\n            factors.push_back(factor);\n            n /= factor;\n        } else {\n            factor++;\n        }\n    }\n    return factors;\n}\n```"}
{"task_id": "SimdBench_74_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> factorize_simd(int n){\n    std::vector<int> factors;\n    \n    while (n % 2 == 0) {\n        factors.push_back(2);\n        n = n / 2;\n    }\n    \n    for (int i = 3; i * i <= n; i = i + 2) {\n        while (n % i == 0) {\n            factors.push_back(i);\n            n = n / i;\n        }\n    }\n    \n    if (n > 2) {\n        factors.push_back(n);\n    }\n    \n    return factors;\n}\n```  "}
{"task_id": "SimdBench_74_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> factorize_simd(int n){\n    std::vector<int> factors;\n    int factor = 2;\n    __m128i factorVec = _mm_set1_epi32(factor);\n    while (n > 1) {\n        if (n % factor == 0) {\n            factors.push_back(factor);\n            n /= factor;\n        } else {\n            factor += 1;\n            factorVec = _mm_set1_epi32(factor);\n        }\n        __m128i nVec = _mm_set1_epi32(n);\n        __m128i divResult = _mm_cvtps_epi32(_mm_div_ps(_mm_cvtepi32_ps(nVec), _mm_cvtepi32_ps(factorVec)));\n        __m128i cmpResult = _mm_cmpeq_epi32(_mm_mullo_epi32(factorVec, divResult), nVec);\n        int mask = _mm_movemask_epi8(cmpResult);\n        if (mask == 0xFFFF) {\n            factors.push_back(n);\n            break;\n        }\n    }\n    return factors;\n}\n```"}
{"task_id": "SimdBench_74_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> factorize_simd(int n){\n    std::vector<int> factors;\n    int factor = 2;\n    while (n > 1) {\n        if (n % factor == 0) {\n            factors.push_back(factor);\n            n /= factor;\n        } else {\n            factor++;\n        }\n    }\n    return factors;\n}\n```"}
{"task_id": "SimdBench_74_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> factorize_simd(int n){\n    std::vector<int> factors;\n    __m128i factor = _mm_set_epi32(0, 0, 0, 0);\n    \n    while (n % 2 == 0) {\n        factor = _mm_add_epi32(factor, _mm_set_epi32(0, 0, 0, 1));\n        n /= 2;\n    }\n    \n    for (int i = 3; i * i <= n; i += 2) {\n        while (n % i == 0) {\n            factor = _mm_add_epi32(factor, _mm_set_epi32(0, 0, 0, 1));\n            n /= i;\n        }\n    }\n    \n    if (n > 2) {\n        factor = _mm_add_epi32(factor, _mm_set_epi32(0, 0, 0, 1));\n    }\n    \n    int result[4];\n    _mm_storeu_si128((__m128i*)result, factor);\n    \n    std::vector<int> result_vec;\n    for (int i = 0; i < 4; i++) {\n        for (int j = 0; j < result[i]; j++) {\n            result_vec.push_back(i + 2);\n        }\n    }\n    \n    return result_vec;\n}\n```"}
{"task_id": "SimdBench_75_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nstd::vector<float> get_positive_simd(const std::vector<float> & l){\n    std::vector<float> result;\n    const int size = l.size();\n    const int simdSize = 4;\n    int numSimdIterations = size / simdSize;\n\n    for (int i = 0; i < numSimdIterations; ++i) {\n        __m128 values = _mm_loadu_ps(&l[i * simdSize]);\n\n        __m128 mask = _mm_cmpge_ps(values, _mm_setzero_ps());\n        __m128 positiveValues = _mm_and_ps(values, mask);\n\n        _mm_storeu_ps(reinterpret_cast<float*>(&result[i * simdSize]), positiveValues);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_75_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nstd::vector<float> get_positive_simd(const std::vector<float> & l){\n    std::vector<float> result;\n    int size = l.size();\n    int simdSize = 4;\n    int numSimdIterations = size / simdSize;\n    \n    for (int i = 0; i < numSimdIterations; ++i) {\n        __m128 values = _mm_loadu_ps(&l[i * simdSize]);\n        __m128 mask = _mm_cmpge_ps(values, _mm_setzero_ps());\n        __m128 positiveValues = _mm_and_ps(values, mask);\n        \n        float temp[4];\n        _mm_storeu_ps(temp, positiveValues);\n        \n        for (int j = 0; j < simdSize; ++j) {\n            if (temp[j] > 0) {\n                result.push_back(temp[j]);\n            }\n        }\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_75_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nstd::vector<float> get_positive_simd(const std::vector<float> & l){\n    std::vector<float> result;\n    const __m128 zero = _mm_setzero_ps();\n    for (size_t i = 0; i < l.size(); i += 4) {\n        __m128 values = _mm_loadu_ps(&l[i]);\n        __m128 mask = _mm_cmpge_ps(values, zero);\n        __m128 positive_values = _mm_and_ps(values, mask);\n        _mm_storeu_ps(reinterpret_cast<float*>(&result[i]), positive_values);\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_75_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nstd::vector<float> get_positive_simd(const std::vector<float> & l){\n    std::vector<float> result;\n    const int size = l.size();\n    const int simdSize = 4;\n    \n    for (int i = 0; i < size; i += simdSize) {\n        __m128 values = _mm_loadu_ps(&l[i]);\n        __m128 zero = _mm_setzero_ps();\n        __m128 mask = _mm_cmpge_ps(values, zero);\n        __m128 positiveValues = _mm_and_ps(values, mask);\n        \n        float temp[simdSize];\n        _mm_storeu_ps(temp, positiveValues);\n        \n        for (int j = 0; j < simdSize; j++) {\n            if (temp[j] > 0) {\n                result.push_back(temp[j]);\n            }\n        }\n    }\n    \n    return result;\n}\n```  "}
{"task_id": "SimdBench_75_SSE", "completion": "```cpp\nstd::vector<float> get_positive_simd(const std::vector<float> & l){\n    std::vector<float> result;\n    const int size = l.size();\n    const __m128 zero = _mm_setzero_ps();\n    \n    for (int i = 0; i < size; i += 4) {\n        __m128 values = _mm_loadu_ps(&l[i]);\n        __m128 mask = _mm_cmpge_ps(values, zero);\n        __m128 positive_values = _mm_and_ps(values, mask);\n        \n        float temp[4];\n        _mm_storeu_ps(temp, positive_values);\n        \n        for (int j = 0; j < 4; j++) {\n            if (temp[j] > 0) {\n                result.push_back(temp[j]);\n            }\n        }\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_76_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool is_prime_simd(int64_t n){\n    if (n <= 1) {\n        return false;\n    }\n    if (n <= 3) {\n        return true;\n    }\n    if (n % 2 == 0 || n % 3 == 0) {\n        return false;\n    }\n\n    __m128i num = _mm_set1_epi64x(n);\n    __m128i divisors = _mm_set_epi64x(5, 7);\n    __m128i one = _mm_set1_epi64x(1);\n    __m128i zero = _mm_setzero_si128();\n\n    for (int64_t i = 11; i * i <= n; i += 6) {\n        __m128i i_vec = _mm_set_epi64x(i, i + 2);\n        __m128i mod1 = _mm_sub_epi64(num, i_vec);\n        __m128i mod2 = _mm_sub_epi64(num, _mm_add_epi64(i_vec, one));\n        __m128i mod1_res = _mm_cmpeq_epi64(_mm_setzero_si128(), _mm_and_si128(mod1, num));\n        __m128i mod2_res = _mm_cmpeq_epi64(_mm_setzero_si128(), _mm_and_si128(mod2, num));\n        __m128i or_res = _mm_or_si128(mod1_res, mod2_res);\n        if (!_mm_test_all_zeros(or_res, zero)) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_76_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool is_prime_simd(int64_t n){\n    if (n <= 1) {\n        return false;\n    }\n    \n    if (n <= 3) {\n        return true;\n    }\n    \n    if (n % 2 == 0 || n % 3 == 0) {\n        return false;\n    }\n    \n    __m128i divisor = _mm_set_epi64x(5, 7);\n    __m128i increment = _mm_set1_epi64x(6);\n    __m128i limit = _mm_set1_epi64x(n);\n    \n    while (true) {\n        __m128i cmp = _mm_cmplt_epi64(divisor, limit);\n        if (_mm_movemask_epi8(cmp) == 0) {\n            break;\n        }\n        \n        __m128i rem1 = _mm_rem_epi64(divisor, _mm_unpacklo_epi64(divisor, divisor));\n        __m128i rem2 = _mm_rem_epi64(divisor, _mm_unpackhi_epi64(divisor, divisor));\n        \n        if (_mm_movemask_epi8(_mm_or_si128(_mm_cmpeq_epi64(rem1, _mm_setzero_si128()), _mm_cmpeq_epi64(rem2, _mm_setzero_si128()))) != 0) {\n            return false;\n        }\n        \n        divisor = _mm_add_epi64(divisor, increment);\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_76_SSE", "completion": "```c\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool is_prime_simd(int64_t n){\n    if (n <= 1) {\n        return false;\n    }\n    \n    if (n <= 3) {\n        return true;\n    }\n    \n    if (n % 2 == 0 || n % 3 == 0) {\n        return false;\n    }\n    \n    __m128i divisor = _mm_set_epi32(7, 5, 3, 2);\n    __m128i n_sse = _mm_set1_epi32(n);\n    \n    for (int i = 5; i * i <= n; i += 6) {\n        __m128i i_sse = _mm_set1_epi32(i);\n        __m128i i_plus_2_sse = _mm_add_epi32(i_sse, _mm_set1_epi32(2));\n        \n        __m128i mod1 = _mm_cmpeq_epi32(_mm_setzero_si128(), _mm_and_si128(_mm_set1_epi32(0xFFFFFFFF), _mm_sub_epi32(n_sse, i_sse)));\n        __m128i mod2 = _mm_cmpeq_epi32(_mm_setzero_si128(), _mm_and_si128(_mm_set1_epi32(0xFFFFFFFF), _mm_sub_epi32(n_sse, i_plus_2_sse)));\n        \n        __m128i div1 = _mm_cmpeq_epi32(_mm_setzero_si128(), _mm_and_si128(_mm_set1_epi32(0xFFFFFFFF), _mm_srem_epi32(n_sse, divisor)));\n        __m128i div2 = _mm_cmpeq_epi32(_mm_setzero_si128(), _mm_and_si128(_mm_set1_epi32(0xFFFFFFFF), _mm_srem_epi32(n_sse, _mm_add_epi32(divisor, _mm_set1_epi32(6))));\n        \n        if (_mm_movemask_epi8(_mm_or_si128(_mm_or_si128(mod1, mod2), _mm_or_si128(div1, div2))) != 0xFFFF) {\n            return false;\n        }\n        \n        divisor = _mm_add_epi32(divisor, _mm_set1_epi32(12));\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_76_SSE", "completion": "```c\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool is_prime_simd(int64_t n){\n    if (n <= 1) {\n        return false;\n    }\n    \n    if (n <= 3) {\n        return true;\n    }\n    \n    if (n % 2 == 0 || n % 3 == 0) {\n        return false;\n    }\n    \n    __m128i num = _mm_set1_epi32(n);\n    __m128i divisors = _mm_set_epi32(7, 5, 4, 2);\n    \n    __m128i mod_results = _mm_setzero_si128();\n    \n    for (int i = 0; i < 4; i++) {\n        __m128i divisor = _mm_shuffle_epi32(divisors, _MM_SHUFFLE(i, i, i, i));\n        __m128i mod_result = _mm_rem_epi32(num, divisor);\n        mod_results = _mm_or_si128(mod_results, mod_result);\n    }\n    \n    int result[4];\n    _mm_storeu_si128((__m128i*)result, mod_results);\n    \n    return (result[0] != 0 && result[1] != 0 && result[2] != 0 && result[3] != 0);\n}\n```"}
{"task_id": "SimdBench_76_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool is_prime_simd(int64_t n){\n    if (n <= 1) {\n        return false;\n    }\n    \n    if (n <= 3) {\n        return true;\n    }\n    \n    if (n % 2 == 0 || n % 3 == 0) {\n        return false;\n    }\n    \n    __m128i num = _mm_set1_epi32(n);\n    __m128i divisors = _mm_set_epi32(7, 5, 4, 3);\n    \n    __m128i remainder = _mm_setzero_si128();\n    __m128i zero = _mm_setzero_si128();\n    \n    for (int i = 0; i < 4; i++) {\n        __m128i div = _mm_shuffle_epi32(divisors, _MM_SHUFFLE(i, i, i, i));\n        __m128i mod = _mm_srem_epi32(num, div);\n        remainder = _mm_or_si128(remainder, mod);\n    }\n    \n    int result[4];\n    _mm_storeu_si128((__m128i*)result, remainder);\n    \n    return result[0] != 0 && result[1] != 0 && result[2] != 0 && result[3] != 0;\n}\n```"}
{"task_id": "SimdBench_77_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string solve_simd(const std::string & s){\n    std::string result = s;\n    int length = s.size();\n    \n    __m128i lowerMask = _mm_set1_epi8(0b11011111); // Mask to convert lowercase to uppercase\n    __m128i upperMask = _mm_set1_epi8(0b00100001); // Mask to convert uppercase to lowercase\n    __m128i caseMask = _mm_set1_epi8(0b00100000); // Mask to check if character is a letter\n    \n    for (int i = 0; i < length; i += 16) {\n        __m128i chunk = _mm_loadu_si128((__m128i*)(s.data() + i));\n        __m128i isLetter = _mm_and_si128(_mm_cmplt_epi8(chunk, _mm_set1_epi8(123)), _mm_cmpgt_epi8(chunk, _mm_set1_epi8(64)));\n        __m128i lower = _mm_and_si128(chunk, isLetter);\n        __m128i upper = _mm_xor_si128(lower, caseMask);\n        __m128i resultChunk = _mm_blendv_epi8(chunk, upper, _mm_cmpeq_epi8(lower, lowerMask));\n        resultChunk = _mm_blendv_epi8(resultChunk, _mm_xor_si128(resultChunk, caseMask), _mm_cmpeq_epi8(lower, upperMask));\n        _mm_storeu_si128((__m128i*)(result.data() + i), resultChunk);\n    }\n    \n    for (int i = 0; i < length / 2; ++i) {\n        std::swap(result[i], result[length - i - 1]);\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_77_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string solve_simd(const std::string & s) {\n    std::string result = s;\n    int length = s.size();\n\n    __m128i lowercaseMask = _mm_set1_epi8(0b11011111); // Mask to convert lowercase to uppercase\n    __m128i uppercaseMask = _mm_set1_epi8(0b00100000); // Mask to convert uppercase to lowercase\n    __m128i letterMask = _mm_set1_epi8(0b11000000); // Mask to check if a character is a letter\n\n    for (int i = 0; i < length; i += 16) {\n        __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&s[i]));\n        __m128i isLetter = _mm_and_si128(_mm_cmplt_epi8(chunk, _mm_set1_epi8(128)), _mm_cmpgt_epi8(chunk, _mm_set1_epi8(64)));\n        __m128i isNotLetter = _mm_xor_si128(isLetter, _mm_set1_epi8(0xFF));\n\n        __m128i lowercase = _mm_and_si128(chunk, isLetter);\n        __m128i uppercase = _mm_and_si128(chunk, isLetter);\n        uppercase = _mm_xor_si128(uppercase, uppercaseMask);\n        lowercase = _mm_xor_si128(lowercase, lowercaseMask);\n\n        chunk = _mm_or_si128(lowercase, uppercase);\n        chunk = _mm_or_si128(chunk, isNotLetter);\n\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i]), chunk);\n    }\n\n    for (int i = 0; i < length / 2; ++i) {\n        std::swap(result[i], result[length - i - 1]);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_77_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string solve_simd(const std::string & s){\n    int len = s.size();\n    __m128i mask_lower = _mm_set1_epi8(0b11011111); // Mask to convert lowercase to uppercase\n    __m128i mask_upper = _mm_set1_epi8(0b00100000); // Mask to convert uppercase to lowercase\n    __m128i mask_letter = _mm_set1_epi8(0b00100000); // Mask to detect letters\n\n    std::string result(len, ' ');\n\n    for (int i = 0; i < len; i += 16) {\n        __m128i input = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&s[i]));\n        __m128i is_letter = _mm_and_si128(_mm_cmplt_epi8(input, _mm_set1_epi8(123)), _mm_cmpgt_epi8(input, _mm_set1_epi8(64)));\n        __m128i is_lower = _mm_and_si128(is_letter, _mm_cmplt_epi8(input, _mm_set1_epi8(91)));\n        __m128i is_upper = _mm_and_si128(is_letter, _mm_cmpgt_epi8(input, _mm_set1_epi8(96)));\n\n        __m128i result_lower = _mm_or_si128(_mm_andnot_si128(is_letter, input), _mm_and_si128(is_lower, _mm_or_si128(input, mask_upper));\n        __m128i result_upper = _mm_or_si128(_mm_andnot_si128(is_letter, input), _mm_and_si128(is_upper, _mm_or_si128(input, mask_lower));\n\n        __m128i result_mask = _mm_or_si128(is_lower, is_upper);\n        __m128i result_final = _mm_or_si128(_mm_andnot_si128(result_mask, input), _mm_or_si128(_mm_and_si128(is_lower, result_lower), _mm_and_si128(is_upper, result_upper)));\n\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i]), result_final);\n    }\n\n    for (int i = 0; i < len / 2; ++i) {\n        std::swap(result[i], result[len - i - 1]);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_77_SSE", "completion": "```\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string solve_simd(const std::string & s){\n    std::string result = s;\n    int length = s.length();\n    \n    __m128i lowercase_mask = _mm_set1_epi8(0b11011111); // Mask to convert lowercase to uppercase\n    __m128i uppercase_mask = _mm_set1_epi8(0b00100001); // Mask to convert uppercase to lowercase\n    __m128i case_mask = _mm_set1_epi8(0b00100000); // Mask to detect case of a character\n    \n    for (int i = 0; i < length; i += 16) {\n        __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&s[i]));\n        __m128i is_letter = _mm_and_si128(_mm_cmplt_epi8(chunk, _mm_set1_epi8(123)), _mm_cmpgt_epi8(chunk, _mm_set1_epi8(64)));\n        __m128i is_lowercase = _mm_and_si128(is_letter, _mm_cmplt_epi8(_mm_and_si128(chunk, case_mask), _mm_set1_epi8(91)));\n        \n        __m128i lowercase_chars = _mm_and_si128(chunk, lowercase_mask);\n        __m128i uppercase_chars = _mm_and_si128(chunk, uppercase_mask);\n        \n        __m128i new_chunk = _mm_or_si128(_mm_andnot_si128(is_letter, chunk), _mm_or_si128(_mm_and_si128(is_lowercase, uppercase_chars), _mm_and_si128(_mm_andnot_si128(is_lowercase, lowercase_chars), is_letter)));\n        \n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i]), new_chunk);\n    }\n    \n    for (int i = 0; i < length / 2; i++) {\n        std::swap(result[i], result[length - i - 1]);\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_77_SSE", "completion": "```\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string solve_simd(const std::string & s){\n    std::string result = s;\n    int len = s.size();\n    \n    __m128i lower_mask = _mm_set1_epi8(0b11011111); // Mask to convert lowercase to uppercase\n    __m128i upper_mask = _mm_set1_epi8(0b00100000); // Mask to convert uppercase to lowercase\n    __m128i space = _mm_set1_epi8(' '); // Space character\n    \n    for (int i = 0; i < len; i += 16) {\n        __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&s[i]));\n        \n        // Check if the chunk contains any letters\n        __m128i is_letter = _mm_or_si128(_mm_cmplt_epi8(chunk, space), _mm_cmpgt_epi8(chunk, _mm_set1_epi8('z')));\n        \n        // Convert lowercase to uppercase and vice versa\n        __m128i lowercase = _mm_and_si128(chunk, lower_mask);\n        __m128i uppercase = _mm_and_si128(chunk, upper_mask);\n        chunk = _mm_or_si128(_mm_or_si128(_mm_xor_si128(lowercase, lower_mask), _mm_xor_si128(uppercase, upper_mask)), _mm_and_si128(chunk, is_letter));\n        \n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i]), chunk);\n    }\n    \n    // Reverse the string if it contains no letters\n    if (_mm_testz_si128(_mm_cmplt_epi8(_mm_loadu_si128(reinterpret_cast<const __m128i*>(&s[0])), space), _mm_set1_epi8(0xFF))) {\n        for (int i = 0; i < len / 2; ++i) {\n            std::swap(result[i], result[len - i - 1]);\n        }\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_78_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> sort_third_simd(std::vector<int> l){\n    __m128i mask = _mm_set_epi32(0, 0, 0, -1);\n    __m128i indices = _mm_set_epi32(3, 2, 1, 0);\n\n    int size = l.size();\n    int num_simd = size / 4;\n    int remainder = size % 4;\n\n    for (int i = 0; i < num_simd; i++) {\n        __m128i data = _mm_loadu_si128((__m128i*)&l[i * 4]);\n        __m128i shuffled = _mm_shuffle_epi8(data, indices);\n        __m128i result = _mm_blendv_epi8(data, shuffled, mask);\n        _mm_storeu_si128((__m128i*)&l[i * 4], result);\n    }\n\n    for (int i = num_simd * 4; i < size; i += 3) {\n        std::vector<int> temp(l.begin() + i, l.begin() + i + 3);\n        std::sort(temp.begin(), temp.end());\n        std::copy(temp.begin(), temp.end(), l.begin() + i);\n    }\n\n    return l;\n}\n```"}
{"task_id": "SimdBench_78_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> sort_third_simd(std::vector<int> l){\n    const int size = l.size();\n    __m128i* data = (__m128i*)l.data();\n    for (int i = 0; i < size / 4; ++i) {\n        __m128i vec = _mm_loadu_si128(data + i);\n        __m128i mask = _mm_set_epi32(0, -1, -1, -1);\n        __m128i sorted = _mm_shuffle_epi32(vec, _MM_SHUFFLE(2, 1, 0, 3));\n        __m128i result = _mm_blendv_epi8(vec, sorted, mask);\n        _mm_storeu_si128(data + i, result);\n    }\n    return l;\n}\n```"}
{"task_id": "SimdBench_78_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> sort_third_simd(std::vector<int> l){\n    __m128i mask = _mm_set_epi32(0, 0, 0xFFFFFFFF, 0xFFFFFFFF);\n    int size = l.size();\n    int remainder = size % 4;\n    int i = 0;\n    \n    for (; i < size - remainder; i += 4) {\n        __m128i vec = _mm_loadu_si128((__m128i*)&l[i]);\n        __m128i div3_mask = _mm_cmpeq_epi32(_mm_and_si128(vec, mask), _mm_setzero_si128());\n        \n        __m128i sorted = _mm_shuffle_epi32(vec, _MM_SHUFFLE(2, 1, 0, 3));\n        __m128i result = _mm_blendv_epi8(vec, sorted, div3_mask);\n        \n        _mm_storeu_si128((__m128i*)&l[i], result);\n    }\n    \n    for (; i < size; ++i) {\n        if (i % 3 == 0) {\n            int temp = l[i];\n            while (i % 3 == 0) {\n                ++i;\n            }\n            l[i - 3] = l[i];\n            l[i] = temp;\n        }\n    }\n    \n    return l;\n}\n```"}
{"task_id": "SimdBench_78_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> sort_third_simd(std::vector<int> l){\n    __m128i mask = _mm_set_epi32(0, 0, -1, 0);\n    int size = l.size();\n    int num_chunks = size / 4;\n    int remainder = size % 4;\n    \n    for (int i = 0; i < num_chunks; ++i) {\n        __m128i chunk = _mm_loadu_si128((__m128i*)&l[i*4]);\n        __m128i sorted_chunk = _mm_shuffle_epi32(chunk, _MM_SHUFFLE(2, 1, 0, 3));\n        __m128i result = _mm_blendv_epi8(chunk, sorted_chunk, mask);\n        _mm_storeu_si128((__m128i*)&l[i*4], result);\n    }\n    \n    for (int i = size - remainder; i < size; ++i) {\n        if (i % 4 == 0) {\n            l[i] = l[i + 2];\n        }\n    }\n    \n    return l;\n}\n```"}
{"task_id": "SimdBench_78_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> sort_third_simd(std::vector<int> l){\n    if(l.size() % 4 != 0){\n        // Handle cases where the vector size is not a multiple of 4\n        // (for simplicity, you can extend the vector size to the next multiple of 4)\n        int new_size = l.size() + 4 - (l.size() % 4);\n        l.resize(new_size, 0);\n    }\n\n    __m128i* ptr = (__m128i*)&l[0];\n    __m128i mask = _mm_set_epi32(0, -1, -1, -1);\n    __m128i shuffle_mask = _mm_set_epi32(0, 3, 2, 1);\n\n    for(size_t i = 0; i < l.size(); i += 4){\n        __m128i vec = _mm_loadu_si128(ptr);\n        __m128i div_by_three = _mm_and_si128(vec, mask);\n        __m128i sorted_div_by_three = _mm_shuffle_epi32(div_by_three, _MM_SHUFFLE(0, 0, 0, 0));\n        __m128i result = _mm_blendv_epi8(vec, sorted_div_by_three, mask);\n        _mm_storeu_si128(ptr, result);\n        ptr++;\n    }\n\n    return l;\n}\n```"}
{"task_id": "SimdBench_79_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nfloat max_element_simd(std::vector<float> l){\n    __m128 max_val = _mm_set1_ps(-FLT_MAX);\n    int size = l.size();\n    int i = 0;\n    \n    for (; i + 4 <= size; i += 4) {\n        __m128 vec = _mm_loadu_ps(&l[i]);\n        max_val = _mm_max_ps(max_val, vec);\n    }\n    \n    float max_arr[4];\n    _mm_storeu_ps(max_arr, max_val);\n    \n    float max_elem = -FLT_MAX;\n    for (int j = 0; j < 4; ++j) {\n        if (max_arr[j] > max_elem) {\n            max_elem = max_arr[j];\n        }\n    }\n    \n    for (; i < size; ++i) {\n        if (l[i] > max_elem) {\n            max_elem = l[i];\n        }\n    }\n    \n    return max_elem;\n}\n```  "}
{"task_id": "SimdBench_79_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nfloat max_element_simd(std::vector<float> l){\n    __m128 max_val = _mm_set1_ps(-FLT_MAX);\n    int size = l.size();\n    int i = 0;\n    \n    for (; i + 4 <= size; i += 4) {\n        __m128 vec = _mm_loadu_ps(&l[i]);\n        max_val = _mm_max_ps(max_val, vec);\n    }\n    \n    float max_arr[4];\n    _mm_storeu_ps(max_arr, max_val);\n    \n    float result = -FLT_MAX;\n    for (int j = 0; j < 4; j++) {\n        if (max_arr[j] > result) {\n            result = max_arr[j];\n        }\n    }\n    \n    for (; i < size; i++) {\n        if (l[i] > result) {\n            result = l[i];\n        }\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_79_SSE", "completion": "```cpp\nfloat max_element_simd(std::vector<float> l){\n    __m128 max_val = _mm_set1_ps(-FLT_MAX);\n    int size = l.size();\n    int i = 0;\n    \n    for (; i + 4 <= size; i += 4) {\n        __m128 vec = _mm_loadu_ps(&l[i]);\n        max_val = _mm_max_ps(max_val, vec);\n    }\n    \n    float max_arr[4];\n    _mm_storeu_ps(max_arr, max_val);\n    \n    float max_elem = std::max({max_arr[0], max_arr[1], max_arr[2], max_arr[3]});\n    \n    for (; i < size; ++i) {\n        max_elem = std::max(max_elem, l[i]);\n    }\n    \n    return max_elem;\n}\n```"}
{"task_id": "SimdBench_79_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nfloat max_element_simd(std::vector<float> l){\n    __m128 max_val = _mm_set1_ps(l[0]);\n    for (size_t i = 0; i < l.size(); i += 4) {\n        __m128 values = _mm_loadu_ps(&l[i]);\n        max_val = _mm_max_ps(max_val, values);\n    }\n    \n    float max_elements[4];\n    _mm_storeu_ps(max_elements, max_val);\n    \n    float result = max_elements[0];\n    for (int i = 1; i < 4; ++i) {\n        if (max_elements[i] > result) {\n            result = max_elements[i];\n        }\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_79_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nfloat max_element_simd(std::vector<float> l){\n    __m128 max_val = _mm_set1_ps(-FLT_MAX);\n    int size = l.size();\n    int i = 0;\n    \n    for (; i + 4 <= size; i += 4) {\n        __m128 vec = _mm_loadu_ps(&l[i]);\n        max_val = _mm_max_ps(max_val, vec);\n    }\n    \n    float max_elements[4];\n    _mm_storeu_ps(max_elements, max_val);\n    \n    float max_element = -FLT_MAX;\n    for (int j = 0; j < 4; j++) {\n        if (max_elements[j] > max_element) {\n            max_element = max_elements[j];\n        }\n    }\n    \n    for (; i < size; i++) {\n        if (l[i] > max_element) {\n            max_element = l[i];\n        }\n    }\n    \n    return max_element;\n}\n```"}
{"task_id": "SimdBench_80_SSE", "completion": "```c\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint fizz_buzz_simd(int n){\n    __m128i count = _mm_setzero_si128();\n    __m128i divisors = _mm_set_epi32(13, 11, 13, 11);\n\n    for (int i = 0; i < n; i += 4) {\n        __m128i values = _mm_set_epi32(i + 3, i + 2, i + 1, i);\n        __m128i divisible = _mm_cmpeq_epi32(_mm_setzero_si128(), _mm_and_si128(_mm_set1_epi32(1), _mm_set1_epi32(1)));\n        __m128i mod_11 = _mm_cmpeq_epi32(_mm_setzero_si128(), _mm_and_si128(values, _mm_set1_epi32(11)));\n        __m128i mod_13 = _mm_cmpeq_epi32(_mm_setzero_si128(), _mm_and_si128(values, _mm_set1_epi32(13)));\n        __m128i mask = _mm_or_si128(_mm_and_si128(mod_11, _mm_cmpeq_epi32(divisible, _mm_set1_epi32(11))), _mm_and_si128(mod_13, _mm_cmpeq_epi32(divisible, _mm_set1_epi32(13)));\n        count = _mm_add_epi32(count, _mm_and_si128(mask, _mm_set1_epi32(1)));\n    }\n\n    int result[4];\n    _mm_storeu_si128((__m128i*)result, count);\n    return result[0] + result[1] + result[2] + result[3];\n}\n```"}
{"task_id": "SimdBench_80_SSE", "completion": "```c\nint fizz_buzz_simd(int n){\n    __m128i count = _mm_setzero_si128();\n    __m128i sevens = _mm_set1_epi8(7);\n    __m128i elevens = _mm_set1_epi8(11);\n    __m128i thirteens = _mm_set1_epi8(13);\n\n    for (int i = 0; i < n; i += 16) {\n        __m128i values = _mm_setr_epi8(i, i+1, i+2, i+3, i+4, i+5, i+6, i+7, i+8, i+9, i+10, i+11, i+12, i+13, i+14, i+15);\n        __m128i mod11 = _mm_cmpeq_epi8(_mm_setzero_si128(), _mm_and_si128(values, elevens));\n        __m128i mod13 = _mm_cmpeq_epi8(_mm_setzero_si128(), _mm_and_si128(values, thirteens));\n        __m128i mod11_or_13 = _mm_or_si128(mod11, mod13);\n        __m128i compare = _mm_cmpeq_epi8(sevens, values);\n        __m128i result = _mm_and_si128(compare, mod11_or_13);\n        count = _mm_add_epi8(count, result);\n    }\n\n    int result_count = 0;\n    for (int i = 0; i < 16; i++) {\n        result_count += ((int8_t*)&count)[i];\n    }\n\n    return result_count;\n}\n```"}
{"task_id": "SimdBench_80_SSE", "completion": "```\nint fizz_buzz_simd(int n){\n    __m128i sevens = _mm_set1_epi8(7);\n    __m128i elevens = _mm_set1_epi8(11);\n    __m128i thirteens = _mm_set1_epi8(13);\n    __m128i count = _mm_setzero_si128();\n    \n    for (int i = 0; i < n; i += 16) {\n        __m128i values = _mm_setr_epi8(i, i+1, i+2, i+3, i+4, i+5, i+6, i+7, i+8, i+9, i+10, i+11, i+12, i+13, i+14, i+15);\n        \n        __m128i mod11 = _mm_cmpeq_epi8(_mm_setzero_si128(), _mm_and_si128(values, elevens));\n        __m128i mod13 = _mm_cmpeq_epi8(_mm_setzero_si128(), _mm_and_si128(values, thirteens));\n        \n        __m128i mod11_or_mod13 = _mm_or_si128(mod11, mod13);\n        \n        __m128i sevens_count = _mm_cmpeq_epi8(sevens, values);\n        __m128i sevens_in_mod = _mm_and_si128(sevens_count, mod11_or_mod13);\n        \n        count = _mm_add_epi8(count, sevens_in_mod);\n    }\n    \n    int result[16];\n    _mm_storeu_si128((__m128i*)result, count);\n    \n    int total_sevens = 0;\n    for (int i = 0; i < 16; i++) {\n        total_sevens += result[i];\n    }\n    \n    return total_sevens;\n}\n```"}
{"task_id": "SimdBench_80_SSE", "completion": "```c\nint fizz_buzz_simd(int n){\n    __m128i sevens = _mm_set1_epi8(7);\n    __m128i elevens = _mm_set1_epi8(11);\n    __m128i thirteens = _mm_set1_epi8(13);\n    __m128i count = _mm_setzero_si128();\n    \n    for (int i = 0; i < n; i += 16) {\n        __m128i values = _mm_setr_epi8(i, i+1, i+2, i+3, i+4, i+5, i+6, i+7, i+8, i+9, i+10, i+11, i+12, i+13, i+14, i+15);\n        \n        __m128i mod11 = _mm_cmpeq_epi8(_mm_setzero_si128(), _mm_and_si128(values, elevens));\n        __m128i mod13 = _mm_cmpeq_epi8(_mm_setzero_si128(), _mm_and_si128(values, thirteens));\n        \n        __m128i mod11_or_13 = _mm_or_si128(mod11, mod13);\n        \n        __m128i sevens_count = _mm_cmpeq_epi8(sevens, values);\n        __m128i sevens_in_mod = _mm_and_si128(sevens_count, mod11_or_13);\n        \n        count = _mm_add_epi8(count, sevens_in_mod);\n    }\n    \n    int result[16];\n    _mm_storeu_si128((__m128i*)result, count);\n    \n    int total_sevens = 0;\n    for (int i = 0; i < 16; i++) {\n        total_sevens += result[i];\n    }\n    \n    return total_sevens;\n}\n```"}
{"task_id": "SimdBench_80_SSE", "completion": "```c\nint fizz_buzz_simd(int n){\n    __m128i count = _mm_setzero_si128();\n    __m128i sevens = _mm_set1_epi8(7);\n    __m128i elevens = _mm_set1_epi8(11);\n    __m128i thirteens = _mm_set1_epi8(13);\n    \n    for (int i = 0; i < n; i += 16) {\n        __m128i values = _mm_setr_epi8(i, i+1, i+2, i+3, i+4, i+5, i+6, i+7, i+8, i+9, i+10, i+11, i+12, i+13, i+14, i+15);\n        \n        __m128i divisible_by_eleven = _mm_cmpeq_epi8(_mm_setzero_si128(), _mm_and_si128(_mm_set1_epi8(0x1), _mm_cmpeq_epi8(_mm_setzero_si128(), _mm_and_si128(values, elevens))));\n        __m128i divisible_by_thirteen = _mm_cmpeq_epi8(_mm_setzero_si128(), _mm_and_si128(_mm_set1_epi8(0x1), _mm_cmpeq_epi8(_mm_setzero_si128(), _mm_and_si128(values, thirteens)));\n        \n        __m128i divisible_by_eleven_or_thirteen = _mm_or_si128(divisible_by_eleven, divisible_by_thirteen);\n        \n        __m128i sevens_count = _mm_cmpeq_epi8(sevens, _mm_setzero_si128());\n        count = _mm_add_epi8(count, _mm_and_si128(sevens_count, divisible_by_eleven_or_thirteen));\n    }\n    \n    int result[16];\n    _mm_storeu_si128((__m128i*)result, count);\n    \n    int total = 0;\n    for (int i = 0; i < 16; i++) {\n        total += result[i];\n    }\n    \n    return total;\n}\n```"}
{"task_id": "SimdBench_81_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<float> sort_even_simd(std::vector<float> l){\n    if(l.size() % 4 != 0){\n        // Handle case when the input vector size is not a multiple of 4\n        return l;\n    }\n\n    for(size_t i = 0; i < l.size(); i += 4){\n        __m128 vec = _mm_loadu_ps(&l[i]);\n        __m128 sorted = _mm_shuffle_ps(vec, vec, _MM_SHUFFLE(2, 3, 0, 1));\n        _mm_storeu_ps(&l[i], sorted);\n    }\n\n    return l;\n}\n```"}
{"task_id": "SimdBench_81_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<float> sort_even_simd(std::vector<float> l){\n    if(l.size() % 4 != 0){\n        // Handle cases where the input vector size is not a multiple of 4\n        return l;\n    }\n\n    for(size_t i = 0; i < l.size(); i += 4){\n        __m128 vec = _mm_loadu_ps(&l[i]);\n        __m128 sorted = _mm_shuffle_ps(vec, vec, _MM_SHUFFLE(2, 3, 0, 1));\n        _mm_storeu_ps(&l[i], sorted);\n    }\n\n    return l;\n}\n```"}
{"task_id": "SimdBench_81_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<float> sort_even_simd(std::vector<float> l){\n    __m128 even_indices = _mm_set_ps(l[6], l[4], l[2], l[0]);\n    __m128 sorted_even_indices = _mm_shuffle_ps(even_indices, even_indices, _MM_SHUFFLE(2, 3, 0, 1));\n    \n    std::vector<float> result(l.size());\n    _mm_store_ps(&result[0], sorted_even_indices);\n\n    for (size_t i = 1; i < l.size(); i += 2) {\n        result[i] = l[i];\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_81_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<float> sort_even_simd(std::vector<float> l){\n    if (l.size() % 4 != 0) {\n        // Handle cases where the input vector size is not a multiple of 4\n        return l;\n    }\n\n    std::vector<float> result(l.size());\n\n    for (size_t i = 0; i < l.size(); i += 4) {\n        __m128 vec = _mm_loadu_ps(&l[i]);\n        __m128 even_indices = _mm_shuffle_ps(vec, vec, _MM_SHUFFLE(2, 0, 2, 0));\n        __m128 sorted_even_indices = _mm_shuffle_ps(even_indices, even_indices, _MM_SHUFFLE(2, 3, 0, 1));\n        __m128 odd_indices = _mm_shuffle_ps(vec, vec, _MM_SHUFFLE(3, 1, 3, 1));\n        __m128 result_vec = _mm_blend_ps(odd_indices, sorted_even_indices, 0b1010);\n        _mm_storeu_ps(&result[i], result_vec);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_81_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<float> sort_even_simd(std::vector<float> l){\n    __m128 even_indices = _mm_set_ps(l[6], l[4], l[2], l[0]);\n    __m128 sorted_even_indices = _mm_shuffle_ps(even_indices, even_indices, _MM_SHUFFLE(2, 3, 0, 1));\n    \n    for (int i = 0; i < 4; i++) {\n        l[2*i] = _mm_cvtss_f32(sorted_even_indices);\n        sorted_even_indices = _mm_shuffle_ps(sorted_even_indices, sorted_even_indices, _MM_SHUFFLE(2, 3, 0, 1));\n    }\n    \n    return l;\n}\n```"}
{"task_id": "SimdBench_82_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nbool triples_sum_to_zero_simd(std::vector<int> l){\n    for (size_t i = 0; i < l.size(); i += 4) {\n        __m128i v = _mm_loadu_si128((__m128i*)&l[i]);\n        for (size_t j = i + 1; j < l.size(); j += 4) {\n            __m128i v2 = _mm_loadu_si128((__m128i*)&l[j]);\n            for (size_t k = j + 1; k < l.size(); k += 4) {\n                __m128i v3 = _mm_loadu_si128((__m128i*)&l[k]);\n                __m128i sum = _mm_add_epi32(v, _mm_add_epi32(v2, v3));\n                int sum_arr[4];\n                _mm_storeu_si128((__m128i*)sum_arr, sum);\n                for (int idx = 0; idx < 4; ++idx) {\n                    if (sum_arr[idx] == 0) {\n                        return true;\n                    }\n                }\n            }\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_82_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nbool triples_sum_to_zero_simd(std::vector<int> l){\n    for (size_t i = 0; i < l.size(); i += 4) {\n        __m128i v = _mm_loadu_si128((__m128i*)&l[i]);\n        for (size_t j = i + 1; j < l.size(); j += 4) {\n            __m128i v2 = _mm_loadu_si128((__m128i*)&l[j]);\n            for (size_t k = j + 1; k < l.size(); k += 4) {\n                __m128i v3 = _mm_loadu_si128((__m128i*)&l[k]);\n                __m128i sum = _mm_add_epi32(v, _mm_add_epi32(v2, v3));\n                int sum_array[4];\n                _mm_storeu_si128((__m128i*)sum_array, sum);\n                for (int m = 0; m < 4; m++) {\n                    if (sum_array[m] == 0) {\n                        return true;\n                    }\n                }\n            }\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_82_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nbool triples_sum_to_zero_simd(std::vector<int> l){\n    const int size = l.size();\n    for (int i = 0; i < size - 2; ++i) {\n        __m128i a = _mm_set1_epi32(l[i]);\n        for (int j = i + 1; j < size - 1; ++j) {\n            __m128i b = _mm_set1_epi32(l[j]);\n            for (int k = j + 1; k < size; ++k) {\n                __m128i c = _mm_set1_epi32(l[k]);\n                __m128i sum = _mm_add_epi32(_mm_add_epi32(a, b), c);\n                int result[4];\n                _mm_storeu_si128((__m128i*)result, sum);\n                if (result[0] + result[1] + result[2] + result[3] == 0) {\n                    return true;\n                }\n            }\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_82_SSE", "completion": "```cpp\nbool triples_sum_to_zero_simd(std::vector<int> l){\n    for (size_t i = 0; i < l.size(); ++i) {\n        __m128i v1 = _mm_set1_epi32(l[i]);\n        for (size_t j = i + 1; j < l.size(); ++j) {\n            __m128i v2 = _mm_set1_epi32(l[j]);\n            for (size_t k = j + 1; k < l.size(); ++k) {\n                __m128i v3 = _mm_set1_epi32(l[k]);\n                __m128i sum = _mm_add_epi32(v1, _mm_add_epi32(v2, v3));\n                __m128i cmp = _mm_cmpeq_epi32(sum, _mm_setzero_si128());\n                int mask = _mm_movemask_epi8(cmp);\n                if (mask != 0) {\n                    return true;\n                }\n            }\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_82_SSE", "completion": "```cpp\nbool triples_sum_to_zero_simd(std::vector<int> l){\n    const int size = l.size();\n    if(size < 3) return false;\n    \n    for(int i = 0; i < size - 2; ++i){\n        __m128i a = _mm_set1_epi32(l[i]);\n        for(int j = i + 1; j < size - 1; ++j){\n            __m128i b = _mm_set1_epi32(l[j]);\n            for(int k = j + 1; k < size; ++k){\n                __m128i c = _mm_set1_epi32(l[k]);\n                __m128i sum = _mm_add_epi32(a, _mm_add_epi32(b, c));\n                __m128i cmp = _mm_cmpeq_epi32(sum, _mm_setzero_si128());\n                int mask = _mm_movemask_epi8(cmp);\n                if(mask == 0xFFFF) return true;\n            }\n        }\n    }\n    \n    return false;\n}\n```"}
{"task_id": "SimdBench_83_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> incr_list_simd(std::vector<int> l){\n    std::vector<int> result(l.size());\n    __m128i increment = _mm_set1_epi32(1);\n\n    for (size_t i = 0; i < l.size(); i += 4) {\n        __m128i input = _mm_loadu_si128((__m128i*)&l[i]);\n        __m128i result_vec = _mm_add_epi32(input, increment);\n        _mm_storeu_si128((__m128i*)&result[i], result_vec);\n    }\n\n    return result;\n}\n```  "}
{"task_id": "SimdBench_83_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> incr_list_simd(std::vector<int> l) {\n    const int size = l.size();\n    const int simdSize = 4;\n    std::vector<int> result(size);\n\n    for (int i = 0; i < size; i += simdSize) {\n        __m128i vec = _mm_loadu_si128((__m128i*)&l[i]);\n        __m128i increment = _mm_set1_epi32(1);\n        __m128i result_vec = _mm_add_epi32(vec, increment);\n        _mm_storeu_si128((__m128i*)&result[i], result_vec);\n    }\n\n    return result;\n}\n```  "}
{"task_id": "SimdBench_83_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> incr_list_simd(std::vector<int> l){\n    std::vector<int> result(l.size());\n\n    for (size_t i = 0; i < l.size(); i += 4) {\n        __m128i vec = _mm_loadu_si128((__m128i*)&l[i]);\n        __m128i incr = _mm_set1_epi32(1);\n        __m128i result_vec = _mm_add_epi32(vec, incr);\n        _mm_storeu_si128((__m128i*)&result[i], result_vec);\n    }\n\n    return result;\n}\n```  "}
{"task_id": "SimdBench_83_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> incr_list_simd(std::vector<int> l){\n    std::vector<int> result(l.size());\n    const __m128i increment = _mm_set1_epi32(1);\n\n    for (size_t i = 0; i < l.size(); i += 4) {\n        __m128i input = _mm_loadu_si128(reinterpret_cast<__m128i*>(&l[i]));\n        __m128i incremented = _mm_add_epi32(input, increment);\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i]), incremented);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_83_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> incr_list_simd(std::vector<int> l){\n    std::vector<int> result(l.size());\n    __m128i increment = _mm_set1_epi32(1);\n\n    for (size_t i = 0; i < l.size(); i += 4) {\n        __m128i input = _mm_loadu_si128((__m128i*)&l[i]);\n        __m128i incremented = _mm_add_epi32(input, increment);\n        _mm_storeu_si128((__m128i*)&result[i], incremented);\n    }\n\n    return result;\n}\n```  "}
{"task_id": "SimdBench_84_SSE", "completion": "```cpp\nbool pairs_sum_to_zero_simd(std::vector<int> l){\n    const int size = l.size();\n    const int* data = l.data();\n    \n    for (int i = 0; i < size; i += 4) {\n        __m128i vec1 = _mm_loadu_si128((__m128i*)(data + i));\n        for (int j = i + 1; j < size; j += 4) {\n            __m128i vec2 = _mm_loadu_si128((__m128i*)(data + j));\n            __m128i sum = _mm_add_epi32(vec1, vec2);\n            __m128i cmp = _mm_cmpeq_epi32(sum, _mm_setzero_si128());\n            int mask = _mm_movemask_epi8(cmp);\n            if (mask != 0) {\n                return true;\n            }\n        }\n    }\n    \n    return false;\n}\n```  "}
{"task_id": "SimdBench_84_SSE", "completion": "```cpp\nbool pairs_sum_to_zero_simd(std::vector<int> l){\n    const int size = l.size();\n    const int* data = l.data();\n    \n    for (int i = 0; i < size - 1; ++i) {\n        __m128i a = _mm_set1_epi32(data[i]);\n        \n        for (int j = i + 1; j < size; ++j) {\n            __m128i b = _mm_set1_epi32(data[j]);\n            __m128i sum = _mm_add_epi32(a, b);\n            __m128i zero = _mm_setzero_si128();\n            __m128i cmp = _mm_cmpeq_epi32(sum, zero);\n            \n            if (_mm_movemask_epi8(cmp) != 0) {\n                return true;\n            }\n        }\n    }\n    \n    return false;\n}\n```"}
{"task_id": "SimdBench_84_SSE", "completion": "```cpp\nbool pairs_sum_to_zero_simd(std::vector<int> l){\n    const int size = l.size();\n    const int* data = l.data();\n    \n    for (int i = 0; i < size; i += 4) {\n        __m128i v1 = _mm_loadu_si128((__m128i*)(data + i));\n        \n        for (int j = i + 1; j < size; j += 4) {\n            __m128i v2 = _mm_loadu_si128((__m128i*)(data + j));\n            __m128i sum = _mm_add_epi32(v1, v2);\n            __m128i cmp = _mm_cmpeq_epi32(sum, _mm_setzero_si128());\n            int mask = _mm_movemask_epi8(cmp);\n            \n            if (mask != 0) {\n                return true;\n            }\n        }\n    }\n    \n    return false;\n}\n```"}
{"task_id": "SimdBench_84_SSE", "completion": "```cpp\nbool pairs_sum_to_zero_simd(std::vector<int> l){\n    const int size = l.size();\n    const int* data = l.data();\n    \n    for (int i = 0; i < size; i += 4) {\n        __m128i vec1 = _mm_loadu_si128((__m128i*)(data + i));\n        \n        for (int j = i + 1; j < size; j += 4) {\n            __m128i vec2 = _mm_loadu_si128((__m128i*)(data + j));\n            __m128i sum = _mm_add_epi32(vec1, vec2);\n            \n            __m128i cmp = _mm_cmpeq_epi32(sum, _mm_setzero_si128());\n            int mask = _mm_movemask_epi8(cmp);\n            \n            if (mask != 0) {\n                return true;\n            }\n        }\n    }\n    \n    return false;\n}\n```"}
{"task_id": "SimdBench_84_SSE", "completion": "```cpp\nbool pairs_sum_to_zero_simd(std::vector<int> l){\n    const int size = l.size();\n    const int* data = l.data();\n    \n    for (int i = 0; i < size; i += 4) {\n        __m128i v1 = _mm_loadu_si128((__m128i*)(data + i));\n        for (int j = i + 1; j < size; j += 4) {\n            __m128i v2 = _mm_loadu_si128((__m128i*)(data + j));\n            __m128i sum = _mm_add_epi32(v1, v2);\n            __m128i cmp = _mm_cmpeq_epi32(sum, _mm_setzero_si128());\n            int mask = _mm_movemask_epi8(cmp);\n            if (mask != 0) {\n                return true;\n            }\n        }\n    }\n    \n    return false;\n}\n```"}
{"task_id": "SimdBench_85_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string change_base_simd(int64_t x, int8_t base){\n    __m128i base_vec = _mm_set1_epi8(base);\n    __m128i x_vec = _mm_set1_epi8(x);\n    __m128i quotient, remainder;\n    std::string result;\n\n    do {\n        quotient = _mm_div_epi8(x_vec, base_vec);\n        remainder = _mm_sub_epi8(x_vec, _mm_mullo_epi8(quotient, base_vec));\n        result.insert(result.begin(), _mm_extract_epi8(remainder, 0) + '0');\n        x_vec = quotient;\n    } while (!_mm_test_all_zeros(x_vec, x_vec));\n\n    return result;\n}\n```  "}
{"task_id": "SimdBench_85_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string change_base_simd(int64_t x, int8_t base){\n    __m128i base_vec = _mm_set1_epi8(base);\n    __m128i x_vec = _mm_set1_epi8(x);\n    __m128i zero_vec = _mm_setzero_si128();\n    __m128i result_vec = zero_vec;\n\n    while (!_mm_test_all_ones(_mm_cmpeq_epi8(x_vec, zero_vec))) {\n        __m128i quotient = _mm_setzero_si128();\n        __m128i remainder = _mm_setzero_si128();\n\n        _mm_divrem_epi8(x_vec, base_vec, &quotient, &remainder);\n\n        __m128i remainder_char = _mm_add_epi8(remainder, _mm_set1_epi8('0'));\n        result_vec = _mm_or_si128(result_vec, remainder_char);\n\n        x_vec = quotient;\n        result_vec = _mm_slli_epi64(result_vec, 8);\n    }\n\n    char result[16];\n    _mm_storeu_si128((__m128i*)result, result_vec);\n\n    return std::string(result);\n}\n```"}
{"task_id": "SimdBench_85_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string change_base_simd(int64_t x, int8_t base){\n    __m128i base_vec = _mm_set1_epi8(base);\n    __m128i x_vec = _mm_set1_epi8(x);\n    \n    __m128i quotient, remainder;\n    std::string result;\n    \n    do {\n        quotient = _mm_div_epi8(x_vec, base_vec);\n        remainder = _mm_sub_epi8(x_vec, _mm_mullo_epi8(quotient, base_vec));\n        \n        result.insert(result.begin(), _mm_extract_epi8(remainder, 0) + '0');\n        \n        x_vec = quotient;\n    } while (!_mm_test_all_zeros(x_vec, x_vec));\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_85_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string change_base_simd(int64_t x, int8_t base){\n    __m128i base_vec = _mm_set1_epi8(base);\n    __m128i x_vec = _mm_set1_epi8(x);\n    __m128i zero_vec = _mm_setzero_si128();\n    __m128i result_vec = zero_vec;\n\n    while (!_mm_test_all_ones(_mm_cmpeq_epi8(x_vec, zero_vec))) {\n        __m128i quotient = _mm_div_epi8(x_vec, base_vec);\n        __m128i remainder = _mm_sub_epi8(x_vec, _mm_mullo_epi16(quotient, base_vec));\n        result_vec = _mm_add_epi8(result_vec, _mm_mullo_epi16(remainder, _mm_set1_epi8(1)));\n        x_vec = quotient;\n        base_vec = _mm_mullo_epi16(base_vec, _mm_set1_epi8(10));\n    }\n\n    int8_t result[16];\n    _mm_storeu_si128((__m128i*)result, result_vec);\n\n    std::string str_result;\n    for (int i = 0; i < 16; i++) {\n        if (result[i] != 0) {\n            str_result += std::to_string(result[i]);\n        }\n    }\n\n    return str_result;\n}\n```"}
{"task_id": "SimdBench_85_SSE", "completion": "```cpp\nstd::string change_base_simd(int64_t x, int8_t base){\n    __m128i base_vec = _mm_set1_epi8(base);\n    __m128i x_vec = _mm_set1_epi64x(x);\n    __m128i quotient, remainder;\n    std::string result;\n\n    do {\n        quotient = _mm_div_epi8(x_vec, base_vec);\n        remainder = _mm_sub_epi8(x_vec, _mm_mullo_epi8(quotient, base_vec));\n        result.insert(result.begin(), _mm_extract_epi8(remainder, 0) + '0');\n        x_vec = quotient;\n    } while (!_mm_testz_si128(x_vec, x_vec));\n\n    return result;\n}\n```  "}
{"task_id": "SimdBench_86_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nbool is_palindrome_simd(std::string text){\n    int len = text.length();\n    int half_len = len / 2;\n    \n    const char* str = text.c_str();\n    \n    for (int i = 0; i < half_len; i++) {\n        if (str[i] != str[len - 1 - i]) {\n            return false;\n        }\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_86_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nbool is_palindrome_simd(std::string text) {\n    int len = text.size();\n    const char* str = text.c_str();\n    \n    int i = 0;\n    int j = len - 1;\n    \n    while (i < j) {\n        __m128i a = _mm_loadu_si128((__m128i*)(str + i));\n        __m128i b = _mm_loadu_si128((__m128i*)(str + j));\n        \n        __m128i cmp = _mm_cmpeq_epi8(a, b);\n        int mask = _mm_movemask_epi8(cmp);\n        \n        if (mask != 0xFFFF) {\n            return false;\n        }\n        \n        i += 16;\n        j -= 16;\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_86_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nbool is_palindrome_simd(std::string text){\n    int len = text.length();\n    int half_len = len / 2;\n    \n    const char* str = text.c_str();\n    \n    for (int i = 0; i < half_len; ++i) {\n        if (str[i] != str[len - 1 - i]) {\n            return false;\n        }\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_86_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nbool is_palindrome_simd(std::string text) {\n    int len = text.length();\n    const char* str = text.c_str();\n    \n    int i = 0;\n    int j = len - 1;\n    \n    while (i < j) {\n        __m128i a = _mm_loadu_si128((__m128i*)(str + i));\n        __m128i b = _mm_loadu_si128((__m128i*)(str + j));\n        \n        __m128i cmp = _mm_cmpeq_epi8(a, b);\n        int mask = _mm_movemask_epi8(cmp);\n        \n        if (mask != 0xFFFF) {\n            return false;\n        }\n        \n        i += 16;\n        j -= 16;\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_86_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nbool is_palindrome_simd(std::string text) {\n    int len = text.length();\n    int half_len = len / 2;\n    \n    const char* str = text.c_str();\n    \n    for (int i = 0; i < half_len; ++i) {\n        __m128i first = _mm_loadu_si128((__m128i*)(str + i));\n        __m128i second = _mm_loadu_si128((__m128i*)(str + len - i - 16));\n        \n        __m128i cmp = _mm_cmpeq_epi8(first, second);\n        int mask = _mm_movemask_epi8(cmp);\n        \n        if (mask != 0xFFFF) {\n            return false;\n        }\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_87_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string decode_shift_simd(std::string s){\n    std::string out;\n    int i;\n    __m128i shift = _mm_set1_epi8(5);\n    __m128i a_val = _mm_set1_epi8('a');\n    __m128i z_val = _mm_set1_epi8('z');\n    __m128i a_ascii = _mm_set1_epi8((int)'a');\n    __m128i alphabet_size = _mm_set1_epi8(26);\n\n    for (i = 0; i < s.length(); i += 16) {\n        __m128i input = _mm_loadu_si128((__m128i*)(s.c_str() + i));\n        \n        // Subtract 'a' from input\n        __m128i sub_a = _mm_sub_epi8(input, a_val);\n        \n        // Add 5 to input\n        __m128i add_5 = _mm_add_epi8(sub_a, shift);\n        \n        // Modulo 26\n        __m128i mod_26 = _mm_and_si128(add_5, _mm_sub_epi8(alphabet_size, _mm_set1_epi8(1)));\n        \n        // Add 'a' back\n        __m128i result = _mm_add_epi8(mod_26, a_ascii);\n        \n        _mm_storeu_si128((__m128i*)(out.c_str() + i), result);\n    }\n\n    return out;\n}\n```"}
{"task_id": "SimdBench_87_SSE", "completion": "```\nstd::string decode_shift_simd(std::string s){\n    std::string out;\n    int i;\n    __m128i a = _mm_set1_epi8('a');\n    __m128i five = _mm_set1_epi8(5);\n    __m128i mod = _mm_set1_epi8(26);\n    __m128i mask = _mm_set1_epi8(0xFF);\n\n    for (i = 0; i < s.length(); i += 16) {\n        __m128i input = _mm_loadu_si128((__m128i*)(s.c_str() + i));\n        __m128i shifted = _mm_sub_epi8(input, five);\n        __m128i diff = _mm_sub_epi8(shifted, a);\n        __m128i modded = _mm_add_epi8(_mm_and_si128(_mm_add_epi8(diff, mod), mask), a);\n        _mm_storeu_si128((__m128i*)(out.c_str() + i), modded);\n    }\n\n    return out;\n}\n```"}
{"task_id": "SimdBench_87_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string decode_shift_simd(std::string s){\n    std::string out;\n    int i;\n    __m128i shift = _mm_set1_epi8(5);\n    __m128i a_values = _mm_set1_epi8('a');\n    __m128i z_values = _mm_set1_epi8('z');\n    __m128i a_ascii = _mm_set1_epi8('a');\n    __m128i alphabet_size = _mm_set1_epi8(26);\n\n    for (i = 0; i < s.length(); i += 16) {\n        __m128i input = _mm_loadu_si128((__m128i*)(s.c_str() + i));\n        \n        // Subtract 'a'\n        __m128i sub_a = _mm_sub_epi8(input, a_values);\n        \n        // Add 5\n        __m128i add_5 = _mm_add_epi8(sub_a, shift);\n        \n        // Mod 26\n        __m128i mod_26 = _mm_and_si128(add_5, _mm_sub_epi8(alphabet_size, _mm_set1_epi8(1)));\n        \n        // Add 'a'\n        __m128i add_a = _mm_add_epi8(mod_26, a_ascii);\n        \n        _mm_storeu_si128((__m128i*)(out.c_str() + i), add_a);\n    }\n\n    return out;\n}\n```"}
{"task_id": "SimdBench_87_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nstd::string decode_shift_simd(std::string s){\n    std::string out;\n    int i;\n    __m128i shift = _mm_set1_epi8(5);\n    __m128i a_val = _mm_set1_epi8('a');\n    __m128i z_val = _mm_set1_epi8('z');\n    __m128i a_ascii = _mm_set1_epi8((int)'a');\n    __m128i alphabet_size = _mm_set1_epi8(26);\n\n    for (i = 0; i < s.length(); i+=16)\n    {\n        __m128i input = _mm_loadu_si128((__m128i*)(s.c_str() + i));\n        \n        __m128i shifted = _mm_sub_epi8(input, shift);\n        __m128i diff = _mm_sub_epi8(shifted, a_val);\n        __m128i mod = _mm_and_si128(diff, _mm_set1_epi8(0x1F));\n        __m128i result = _mm_add_epi8(mod, a_ascii);\n        \n        __m128i mask = _mm_cmpgt_epi8(result, z_val);\n        result = _mm_blendv_epi8(result, shifted, mask);\n\n        _mm_storeu_si128((__m128i*)(out.c_str() + i), result);\n    }\n\n    return out;\n}\n```"}
{"task_id": "SimdBench_87_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nstd::string decode_shift_simd(std::string s){\n    std::string out;\n    int i;\n    __m128i shift = _mm_set1_epi8(5);\n    __m128i a_val = _mm_set1_epi8('a');\n    __m128i z_val = _mm_set1_epi8('z');\n    __m128i a_ascii = _mm_set1_epi8((int)'a');\n    __m128i mod_val = _mm_set1_epi8(26);\n\n    for (i = 0; i < s.length(); i += 16) {\n        __m128i input = _mm_loadu_si128((__m128i*)(s.c_str() + i));\n        \n        __m128i shifted = _mm_sub_epi8(input, shift);\n        __m128i diff = _mm_sub_epi8(shifted, a_val);\n        __m128i mod = _mm_add_epi8(_mm_and_si128(_mm_cmpgt_epi8(diff, _mm_setzero_si128()), mod_val), diff);\n        __m128i result = _mm_add_epi8(mod, a_ascii);\n\n        _mm_storeu_si128((__m128i*)(out.c_str() + i), result);\n    }\n\n    return out;\n}\n```"}
{"task_id": "SimdBench_88_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool below_threshold_simd(std::vector<int> l, int t) {\n    const __m128i threshold = _mm_set1_epi32(t);\n    bool result = true;\n\n    for (size_t i = 0; i < l.size(); i += 4) {\n        __m128i values = _mm_loadu_si128((__m128i*)&l[i]);\n        __m128i comparison = _mm_cmplt_epi32(values, threshold);\n        int mask = _mm_movemask_epi8(comparison);\n\n        if (mask != 0xFFFF) {\n            result = false;\n            break;\n        }\n    }\n\n    return result;\n}\n```  "}
{"task_id": "SimdBench_88_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool below_threshold_simd(std::vector<int> l, int t) {\n    const int size = l.size();\n    const __m128i threshold = _mm_set1_epi32(t);\n    bool result = true;\n\n    for (int i = 0; i < size; i += 4) {\n        __m128i values = _mm_loadu_si128((__m128i*)&l[i]);\n        __m128i compare = _mm_cmplt_epi32(values, threshold);\n        int mask = _mm_movemask_epi8(compare);\n        if (mask != 0xFFFF) {\n            result = false;\n            break;\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_88_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool below_threshold_simd(std::vector<int> l, int t) {\n    const int size = l.size();\n    const int* data = l.data();\n    const __m128i threshold = _mm_set1_epi32(t);\n    bool result = true;\n\n    for (int i = 0; i < size; i += 4) {\n        __m128i values = _mm_loadu_si128((__m128i*)(data + i));\n        __m128i compare = _mm_cmplt_epi32(values, threshold);\n        int mask = _mm_movemask_epi8(compare);\n        if (mask != 0xFFFF) {\n            result = false;\n            break;\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_88_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool below_threshold_simd(std::vector<int> l, int t) {\n    const int size = l.size();\n    const int* data = l.data();\n    const __m128i threshold = _mm_set1_epi32(t);\n    bool result = true;\n\n    for (int i = 0; i < size; i += 4) {\n        __m128i values = _mm_loadu_si128((__m128i*)(data + i));\n        __m128i compare = _mm_cmplt_epi32(values, threshold);\n        int mask = _mm_movemask_epi8(compare);\n        if (mask != 0xFFFF) {\n            result = false;\n            break;\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_88_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool below_threshold_simd(std::vector<int> l, int t) {\n    const int size = l.size();\n    const int* data = l.data();\n    const __m128i threshold = _mm_set1_epi32(t);\n    bool result = true;\n\n    for (int i = 0; i < size; i += 4) {\n        __m128i values = _mm_loadu_si128(reinterpret_cast<const __m128i*>(data + i));\n        __m128i compare = _mm_cmplt_epi32(values, threshold);\n        int mask = _mm_movemask_epi8(compare);\n        result = result && (mask == 0xFFFF);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_89_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nbool correct_bracketing_simd(std::string brackets) {\n    int count = 0;\n    __m128i open = _mm_set1_epi8('<');\n    __m128i close = _mm_set1_epi8('>');\n    \n    for (size_t i = 0; i < brackets.size(); i += 16) {\n        __m128i chunk = _mm_loadu_si128(reinterpret_cast<__m128i*>(&brackets[i]));\n        \n        __m128i cmp_open = _mm_cmpeq_epi8(chunk, open);\n        __m128i cmp_close = _mm_cmpeq_epi8(chunk, close);\n        \n        int mask_open = _mm_movemask_epi8(cmp_open);\n        int mask_close = _mm_movemask_epi8(cmp_close);\n        \n        count += _mm_popcnt_u32(mask_open) - _mm_popcnt_u32(mask_close);\n    }\n    \n    return count == 0;\n}\n```"}
{"task_id": "SimdBench_89_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nbool correct_bracketing_simd(std::string brackets) {\n    if (brackets.size() % 16 != 0) {\n        return false;\n    }\n\n    __m128i open = _mm_set1_epi8('<');\n    __m128i close = _mm_set1_epi8('>');\n\n    for (size_t i = 0; i < brackets.size(); i += 16) {\n        __m128i chunk = _mm_loadu_si128(reinterpret_cast<__m128i*>(&brackets[i]));\n\n        __m128i cmp_open = _mm_cmpeq_epi8(chunk, open);\n        __m128i cmp_close = _mm_cmpeq_epi8(chunk, close);\n\n        int mask_open = _mm_movemask_epi8(cmp_open);\n        int mask_close = _mm_movemask_epi8(cmp_close);\n\n        if (mask_open != mask_close) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_89_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nbool correct_bracketing_simd(std::string brackets) {\n    if (brackets.size() % 16 != 0) {\n        return false;\n    }\n\n    const __m128i openBracket = _mm_set1_epi8('<');\n    const __m128i closeBracket = _mm_set1_epi8('>');\n\n    for (size_t i = 0; i < brackets.size(); i += 16) {\n        __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&brackets[i]));\n        __m128i openMask = _mm_cmpeq_epi8(chunk, openBracket);\n        __m128i closeMask = _mm_cmpeq_epi8(chunk, closeBracket);\n        int openCount = _mm_popcnt_u32(_mm_movemask_epi8(openMask));\n        int closeCount = _mm_popcnt_u32(_mm_movemask_epi8(closeMask));\n        if (openCount != closeCount) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_89_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nbool correct_bracketing_simd(std::string brackets) {\n    if (brackets.size() % 16 != 0) {\n        return false;\n    }\n\n    __m128i open = _mm_set1_epi8('<');\n    __m128i close = _mm_set1_epi8('>');\n\n    for (size_t i = 0; i < brackets.size(); i += 16) {\n        __m128i chunk = _mm_loadu_si128(reinterpret_cast<__m128i*>(&brackets[i]));\n        __m128i cmp_open = _mm_cmpeq_epi8(chunk, open);\n        __m128i cmp_close = _mm_cmpeq_epi8(chunk, close);\n        __m128i cmp_result = _mm_cmpeq_epi8(cmp_open, cmp_close);\n\n        if (!_mm_test_all_ones(cmp_result)) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```  "}
{"task_id": "SimdBench_89_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nbool correct_bracketing_simd(std::string brackets) {\n    if (brackets.size() % 16 != 0) {\n        return false;\n    }\n\n    const __m128i openBracket = _mm_set1_epi8('<');\n    const __m128i closeBracket = _mm_set1_epi8('>');\n\n    for (size_t i = 0; i < brackets.size(); i += 16) {\n        __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&brackets[i]));\n\n        __m128i cmpOpen = _mm_cmpeq_epi8(chunk, openBracket);\n        __m128i cmpClose = _mm_cmpeq_epi8(chunk, closeBracket);\n\n        int openMask = _mm_movemask_epi8(cmpOpen);\n        int closeMask = _mm_movemask_epi8(cmpClose);\n\n        if (openMask != closeMask) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_90_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nbool correct_bracketing_simd(std::string brackets) {\n    int count = 0;\n    __m128i open = _mm_set1_epi8('(');\n    __m128i close = _mm_set1_epi8(')');\n    \n    for (size_t i = 0; i < brackets.size(); i += 16) {\n        __m128i chunk = _mm_loadu_si128(reinterpret_cast<__m128i*>(&brackets[i]));\n        \n        __m128i cmp_open = _mm_cmpeq_epi8(chunk, open);\n        __m128i cmp_close = _mm_cmpeq_epi8(chunk, close);\n        \n        int open_mask = _mm_movemask_epi8(cmp_open);\n        int close_mask = _mm_movemask_epi8(cmp_close);\n        \n        count += _mm_popcnt_u32(open_mask) - _mm_popcnt_u32(close_mask);\n    }\n    \n    return count == 0;\n}\n```  "}
{"task_id": "SimdBench_90_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool correct_bracketing_simd(std::string brackets) {\n    int count = 0;\n    __m128i open = _mm_set1_epi8('(');\n    __m128i close = _mm_set1_epi8(')');\n    \n    for (size_t i = 0; i < brackets.size(); i += 16) {\n        __m128i chunk = _mm_loadu_si128(reinterpret_cast<__m128i*>(&brackets[i]));\n        \n        __m128i cmp_open = _mm_cmpeq_epi8(chunk, open);\n        __m128i cmp_close = _mm_cmpeq_epi8(chunk, close);\n        \n        int mask_open = _mm_movemask_epi8(cmp_open);\n        int mask_close = _mm_movemask_epi8(cmp_close);\n        \n        count += _mm_popcnt_u32(mask_open) - _mm_popcnt_u32(mask_close);\n    }\n    \n    return count == 0;\n}\n```"}
{"task_id": "SimdBench_90_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nbool correct_bracketing_simd(std::string brackets) {\n    int count = 0;\n    __m128i open = _mm_set1_epi8('(');\n    __m128i close = _mm_set1_epi8(')');\n    \n    for (size_t i = 0; i < brackets.size(); i += 16) {\n        __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&brackets[i]));\n        \n        __m128i cmp_open = _mm_cmpeq_epi8(chunk, open);\n        __m128i cmp_close = _mm_cmpeq_epi8(chunk, close);\n        \n        int open_count = _mm_popcnt_u32(_mm_movemask_epi8(cmp_open));\n        int close_count = _mm_popcnt_u32(_mm_movemask_epi8(cmp_close));\n        \n        count += open_count - close_count;\n    }\n    \n    return count == 0;\n}\n```"}
{"task_id": "SimdBench_90_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nbool correct_bracketing_simd(std::string brackets) {\n    int count = 0;\n    __m128i open = _mm_set1_epi8('(');\n    __m128i close = _mm_set1_epi8(')');\n    \n    for (size_t i = 0; i < brackets.size(); i += 16) {\n        __m128i chunk = _mm_loadu_si128(reinterpret_cast<__m128i*>(&brackets[i]));\n        \n        __m128i isOpen = _mm_cmpeq_epi8(chunk, open);\n        __m128i isClose = _mm_cmpeq_epi8(chunk, close);\n        \n        count += _mm_popcnt_u32(_mm_movemask_epi8(_mm_sub_epi8(isOpen, isClose)));\n    }\n    \n    return count == 0;\n}\n```  "}
{"task_id": "SimdBench_90_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool correct_bracketing_simd(std::string brackets) {\n    int count = 0;\n    __m128i open = _mm_set1_epi8('(');\n    __m128i close = _mm_set1_epi8(')');\n    \n    for (int i = 0; i < brackets.size(); i += 16) {\n        __m128i chunk = _mm_loadu_si128(reinterpret_cast<__m128i*>(&brackets[i]));\n        \n        __m128i cmp_open = _mm_cmpeq_epi8(chunk, open);\n        __m128i cmp_close = _mm_cmpeq_epi8(chunk, close);\n        \n        int open_count = _mm_popcnt_u32(_mm_movemask_epi8(cmp_open));\n        int close_count = _mm_popcnt_u32(_mm_movemask_epi8(cmp_close));\n        \n        count += open_count - close_count;\n    }\n    \n    return count == 0;\n}\n```"}
{"task_id": "SimdBench_91_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<float> derivative_simd(std::vector<float> xs){\n    std::vector<float> result;\n    __m128 coef, x, res;\n    \n    for (int i = 1; i < xs.size(); i += 4) {\n        coef = _mm_loadu_ps(&xs[i]);\n        x = _mm_set_ps(i + 3, i + 2, i + 1, i); // x = {i+3, i+2, i+1, i}\n        res = _mm_mul_ps(coef, x);\n        _mm_storeu_ps(&result[i - 1], res);\n    }\n    \n    return result;\n}\n```  "}
{"task_id": "SimdBench_91_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<float> derivative_simd(std::vector<float> xs){\n    std::vector<float> result;\n    __m128 coef1 = _mm_set_ps(0.0f, xs[3], xs[2], xs[1]);\n    __m128 coef2 = _mm_set_ps(0.0f, 0.0f, xs[4], xs[3]);\n    __m128 coef3 = _mm_set_ps(0.0f, 0.0f, 0.0f, xs[4]);\n    \n    __m128 coef_res1 = _mm_mul_ps(coef1, _mm_set_ps(3.0f, 2.0f, 1.0f, 0.0f));\n    __m128 coef_res2 = _mm_mul_ps(coef2, _mm_set_ps(2.0f, 1.0f, 0.0f, 0.0f));\n    __m128 coef_res3 = _mm_mul_ps(coef3, _mm_set_ps(1.0f, 0.0f, 0.0f, 0.0f));\n    \n    __m128 res = _mm_add_ps(_mm_add_ps(coef_res1, coef_res2), coef_res3);\n    \n    float res_arr[4];\n    _mm_store_ps(res_arr, res);\n    \n    for(int i=0; i<4; i++){\n        if(res_arr[i] != 0.0f){\n            result.push_back(res_arr[i]);\n        }\n    }\n    \n    return result;\n}\n```  "}
{"task_id": "SimdBench_91_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nstd::vector<float> derivative_simd(std::vector<float> xs){\n    std::vector<float> result;\n    __m128 coef = _mm_set_ps(xs[3], xs[2], xs[1], xs[0]);\n    __m128 indices = _mm_set_ps(3.0f, 2.0f, 1.0f, 0.0f);\n    __m128 derivative = _mm_mul_ps(coef, indices);\n    \n    float res[4];\n    _mm_store_ps(res, derivative);\n    \n    for(int i=0; i<4; i++){\n        result.push_back(res[i]);\n    }\n    \n    return result;\n}\n```  "}
{"task_id": "SimdBench_91_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nstd::vector<float> derivative_simd(std::vector<float> xs){\n    std::vector<float> result;\n    __m128 coef1 = _mm_set_ps(0.0f, xs[3], xs[2], xs[1]);\n    __m128 coef2 = _mm_set_ps(0.0f, 0.0f, xs[3], xs[2]);\n    __m128 coef3 = _mm_set_ps(0.0f, 0.0f, 0.0f, xs[3]);\n\n    __m128 res = _mm_add_ps(coef1, _mm_add_ps(_mm_mul_ps(_mm_set1_ps(3.0f), coef2), _mm_mul_ps(_mm_set1_ps(6.0f), coef3)));\n\n    float res_arr[4];\n    _mm_store_ps(res_arr, res);\n\n    for (int i = 0; i < 3; ++i) {\n        result.push_back(res_arr[i]);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_91_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nstd::vector<float> derivative_simd(std::vector<float> xs){\n    std::vector<float> result;\n    int n = xs.size();\n    int simdSize = 4;\n    int simdIterations = n / simdSize;\n\n    for (int i = 0; i < simdIterations; ++i) {\n        __m128 coeffs = _mm_loadu_ps(&xs[i * simdSize]);\n        __m128 indices = _mm_set_ps(3.0f, 2.0f, 1.0f, 0.0f);\n        __m128 derivative = _mm_mul_ps(coeffs, indices);\n        _mm_storeu_ps(&result[i * simdSize], derivative);\n    }\n\n    return result;\n}\n```  "}
{"task_id": "SimdBench_92_SSE", "completion": "```\nint vowels_count_simd(std::string s){\n    const __m128i vowels = _mm_setr_epi8('a', 'e', 'i', 'o', 'u', 'A', 'E', 'I', 'O', 'U', 'Y', 0, 0, 0, 0, 0);\n    const __m128i y_end_mask = _mm_set1_epi8(0x80);\n    const __m128i y_end_check = _mm_set1_epi8('Y');\n    const __m128i zero = _mm_setzero_si128();\n    \n    int count = 0;\n    int i = 0;\n    int len = s.length();\n    \n    for (; i < len - 15; i += 16) {\n        __m128i str = _mm_loadu_si128((__m128i*)(s.c_str() + i));\n        \n        __m128i cmp_vowels = _mm_cmpeq_epi8(vowels, _mm_and_si128(str, _mm_set1_epi8(0xDF))); // case-insensitive comparison\n        __m128i cmp_y_end = _mm_cmpeq_epi8(y_end_check, _mm_and_si128(str, y_end_mask));\n        \n        __m128i cmp_result = _mm_or_si128(cmp_vowels, cmp_y_end);\n        \n        count += _mm_popcnt_u32(_mm_movemask_epi8(cmp_result));\n    }\n    \n    for (; i < len; ++i) {\n        char c = s[i];\n        if ((c == 'Y' || c == 'y') && i == len - 1) {\n            ++count;\n        } else if (c == 'a' || c == 'e' || c == 'i' || c == 'o' || c == 'u' || c == 'A' || c == 'E' || c == 'I' || c == 'O' || c == 'U') {\n            ++count;\n        }\n    }\n    \n    return count;\n}\n```"}
{"task_id": "SimdBench_92_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nint vowels_count_simd(std::string s){\n    const __m128i vowels = _mm_setr_epi8('a', 'e', 'i', 'o', 'u', 'A', 'E', 'I', 'O', 'U', 'Y', 0, 0, 0, 0, 0);\n    const __m128i end_vowels = _mm_setr_epi8('a', 'e', 'i', 'o', 'u', 'A', 'E', 'I', 'O', 'U', 'Y', 'y', 0, 0, 0, 0);\n    const __m128i mask = _mm_set1_epi8(0x1);\n    const __m128i zero = _mm_setzero_si128();\n    \n    int count = 0;\n    int i = 0;\n    for (; i + 15 < s.size(); i += 16) {\n        __m128i str = _mm_loadu_si128((__m128i*)(s.c_str() + i));\n        __m128i cmp = _mm_cmpeq_epi8(vowels, _mm_or_si128(_mm_cmpeq_epi8(str, vowels), _mm_cmpeq_epi8(str, end_vowels)));\n        __m128i result = _mm_and_si128(cmp, mask);\n        count += _mm_popcnt_u32(_mm_movemask_epi8(result));\n    }\n    \n    alignas(16) char leftover[16];\n    int leftover_size = s.size() - i;\n    for (int j = 0; j < leftover_size; j++) {\n        leftover[j] = s[i + j];\n    }\n    for (int j = leftover_size; j < 16; j++) {\n        leftover[j] = 0;\n    }\n    __m128i str = _mm_load_si128((__m128i*)leftover);\n    __m128i cmp = _mm_cmpeq_epi8(vowels, _mm_or_si128(_mm_cmpeq_epi8(str, vowels), _mm_cmpeq_epi8(str, end_vowels)));\n    __m128i result = _mm_and_si128(cmp, mask);\n    count += _mm_popcnt_u32(_mm_movemask_epi8(result) & ((1 << leftover_size) - 1));\n    \n    return count;\n}\n```"}
{"task_id": "SimdBench_92_SSE", "completion": "```\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nint vowels_count_simd(std::string s){\n    const __m128i vowels = _mm_setr_epi8('a', 'e', 'i', 'o', 'u', 'A', 'E', 'I', 'O', 'U', 'Y', 0, 0, 0, 0, 0);\n    const __m128i y_end_mask = _mm_set1_epi8(0x80);\n    const __m128i y_end_check = _mm_set1_epi8('Y');\n\n    int count = 0;\n    int i = 0;\n    for (; i + 15 < s.size(); i += 16) {\n        __m128i str = _mm_loadu_si128((__m128i*)(s.data() + i));\n        __m128i cmp_vowels = _mm_cmpeq_epi8(vowels, _mm_or_si128(str, y_end_mask));\n        __m128i cmp_y_end = _mm_cmpeq_epi8(y_end_check, _mm_and_si128(str, y_end_mask));\n        __m128i cmp_result = _mm_or_si128(cmp_vowels, cmp_y_end);\n        count += _mm_popcnt_u32(_mm_movemask_epi8(cmp_result));\n    }\n\n    alignas(16) char leftover[16];\n    int leftover_size = s.size() - i;\n    if (leftover_size > 0) {\n        for (int j = 0; j < leftover_size; j++) {\n            leftover[j] = s[i + j];\n        }\n        for (int j = leftover_size; j < 16; j++) {\n            leftover[j] = 0;\n        }\n        __m128i str = _mm_load_si128((__m128i*)leftover);\n        __m128i cmp_vowels = _mm_cmpeq_epi8(vowels, _mm_or_si128(str, y_end_mask));\n        __m128i cmp_y_end = _mm_cmpeq_epi8(y_end_check, _mm_and_si128(str, y_end_mask));\n        __m128i cmp_result = _mm_or_si128(cmp_vowels, cmp_y_end);\n        count += _mm_popcnt_u32(_mm_movemask_epi8(cmp_result) & ((1 << leftover_size) - 1));\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_92_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nint vowels_count_simd(std::string s) {\n    const __m128i vowels = _mm_setr_epi8('a', 'e', 'i', 'o', 'u', 'A', 'E', 'I', 'O', 'U', 'Y', 0, 0, 0, 0, 0);\n    const __m128i yEndMask = _mm_set1_epi8(0x80);\n\n    int count = 0;\n    int i = 0;\n    while (i < s.size()) {\n        __m128i input = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&s[i]));\n        __m128i cmpVowels = _mm_cmpeq_epi8(vowels, _mm_or_si128(_mm_or_si128(_mm_sub_epi8(input, _mm_set1_epi8('a')), _mm_sub_epi8(input, _mm_set1_epi8('A'))), yEndMask));\n        count += _mm_popcnt_u32(_mm_movemask_epi8(cmpVowels));\n        i += 16;\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_92_SSE", "completion": "```\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nint vowels_count_simd(std::string s){\n    const __m128i vowels = _mm_set_epi8('u', 'o', 'i', 'e', 'a', 'y', 'U', 'O', 'I', 'E', 'A', 'Y', 'U', 'O', 'I', 'E');\n    const __m128i mask = _mm_set1_epi8(0x1);\n    const __m128i zero = _mm_setzero_si128();\n    int count = 0;\n\n    for (size_t i = 0; i < s.size(); i += 16) {\n        __m128i str = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&s[i]));\n        __m128i cmp = _mm_cmpeq_epi8(vowels, _mm_or_si128(_mm_cmpeq_epi8(str, vowels), _mm_cmpeq_epi8(_mm_srli_si128(str, 1), vowels)));\n        __m128i result = _mm_and_si128(cmp, mask);\n        count += _mm_popcnt_u32(_mm_movemask_epi8(result));\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_93_SSE", "completion": "```\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nint digitSum_simd(std::string s){\n    __m128i sum = _mm_setzero_si128();\n    int len = s.length();\n    for (int i = 0; i < len; i += 16) {\n        __m128i input = _mm_loadu_si128((__m128i*)(s.c_str() + i));\n        __m128i mask_upper = _mm_cmplt_epi8(input, _mm_set1_epi8('a'));\n        mask_upper = _mm_and_si128(mask_upper, _mm_cmplt_epi8(input, _mm_set1_epi8('z')));\n        __m128i upper = _mm_and_si128(input, mask_upper);\n        sum = _mm_add_epi8(sum, upper);\n    }\n    \n    alignas(16) int result[16];\n    _mm_store_si128((__m128i*)result, sum);\n    \n    int total_sum = 0;\n    for (int i = 0; i < 16; i++) {\n        total_sum += result[i];\n    }\n    \n    return total_sum;\n}\n```"}
{"task_id": "SimdBench_93_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nint digitSum_simd(std::string s){\n    __m128i sum = _mm_setzero_si128();\n    for (size_t i = 0; i < s.size(); i += 16) {\n        __m128i input = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&s[i]));\n        __m128i upperMask = _mm_cmplt_epi8(input, _mm_set1_epi8('a'));\n        upperMask = _mm_and_si128(upperMask, _mm_cmpgt_epi8(input, _mm_set1_epi8('Z')));\n        __m128i upperChars = _mm_and_si128(input, upperMask);\n        sum = _mm_add_epi8(sum, upperChars);\n    }\n    alignas(16) int result[16];\n    _mm_store_si128(reinterpret_cast<__m128i*>(result), sum);\n    return result[0] + result[1] + result[2] + result[3] + result[4] + result[5] + result[6] + result[7] +\n           result[8] + result[9] + result[10] + result[11] + result[12] + result[13] + result[14] + result[15];\n}\n```"}
{"task_id": "SimdBench_93_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nint digitSum_simd(std::string s){\n    __m128i sum = _mm_setzero_si128();\n    int length = s.length();\n    for (int i = 0; i < length; i += 16) {\n        __m128i ascii = _mm_set_epi8(\n            s[i + 15], s[i + 14], s[i + 13], s[i + 12],\n            s[i + 11], s[i + 10], s[i + 9], s[i + 8],\n            s[i + 7], s[i + 6], s[i + 5], s[i + 4],\n            s[i + 3], s[i + 2], s[i + 1], s[i]\n        );\n        __m128i mask_upper = _mm_cmpgt_epi8(ascii, _mm_set1_epi8('Z'));\n        __m128i mask_lower = _mm_cmplt_epi8(ascii, _mm_set1_epi8('A'));\n        __m128i mask = _mm_or_si128(mask_upper, mask_lower);\n        ascii = _mm_andnot_si128(mask, ascii);\n        sum = _mm_add_epi8(sum, ascii);\n    }\n    int result[16];\n    _mm_storeu_si128((__m128i*)result, sum);\n    int total_sum = 0;\n    for (int i = 0; i < 16; i++) {\n        total_sum += result[i];\n    }\n    return total_sum;\n}\n```"}
{"task_id": "SimdBench_93_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nint digitSum_simd(std::string s){\n    int sum = 0;\n    __m128i zero = _mm_setzero_si128();\n    __m128i upperMask = _mm_set1_epi8(0b11011111); // Mask to extract upper characters only\n\n    for (size_t i = 0; i < s.size(); i += 16) {\n        __m128i input = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&s[i]));\n        __m128i upperChars = _mm_and_si128(input, upperMask);\n        __m128i upperCharsPacked = _mm_unpacklo_epi8(upperChars, zero);\n        __m128i sumPacked = _mm_add_epi16(upperCharsPacked, _mm_unpackhi_epi8(upperChars, zero));\n        __m128i sumPacked16 = _mm_madd_epi16(sumPacked, _mm_set1_epi16(1));\n        sum += _mm_cvtsi128_si32(sumPacked16);\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_93_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nint digitSum_simd(std::string s){\n    int sum = 0;\n    __m128i upperMask = _mm_set1_epi8(0b11011111); // Mask to extract upper characters only\n\n    for (size_t i = 0; i < s.size(); i += 16) {\n        __m128i input = _mm_loadu_si128(reinterpret_cast<__m128i*>(&s[i])); // Load 16 characters\n        __m128i upperChars = _mm_and_si128(input, upperMask); // Extract upper characters\n        __m128i asciiCodes = _mm_sub_epi8(upperChars, _mm_set1_epi8('A' - 1)); // Convert to ASCII codes starting from 1\n        __m128i asciiSums = _mm_sad_epu8(asciiCodes, _mm_setzero_si128()); // Calculate sum of ASCII codes\n        sum += _mm_extract_epi16(asciiSums, 0) + _mm_extract_epi16(asciiSums, 4); // Accumulate sum\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_94_SSE", "completion": "```\nstd::vector<int> pluck_simd(std::vector<int> arr){\n    if(arr.empty()) return {};\n\n    __m128i min_even = _mm_set1_epi32(2147483647); // Initialize to maximum int value\n    __m128i min_even_index = _mm_set1_epi32(2147483647); // Initialize to maximum int value\n    __m128i even_mask = _mm_set1_epi32(1);\n\n    for(int i = 0; i < arr.size(); i += 4){\n        __m128i values = _mm_loadu_si128((__m128i*)&arr[i]);\n        __m128i even_values = _mm_and_si128(values, even_mask);\n        __m128i cmp = _mm_cmplt_epi32(even_values, min_even);\n\n        min_even = _mm_min_epi32(min_even, even_values);\n        min_even_index = _mm_blendv_epi8(min_even_index, _mm_set1_epi32(i), cmp);\n    }\n\n    int result[4];\n    _mm_storeu_si128((__m128i*)result, min_even);\n    _mm_storeu_si128((__m128i*)(result + 4), min_even_index);\n\n    int smallest_value = result[0];\n    int smallest_index = result[4];\n\n    if(smallest_value == 2147483647) return {};\n\n    return {smallest_value, smallest_index};\n}\n```"}
{"task_id": "SimdBench_94_SSE", "completion": "```\nstd::vector<int> pluck_simd(std::vector<int> arr){\n    if(arr.empty()) return {};\n\n    __m128i min_even = _mm_set1_epi32(2147483647); // Initialize to INT_MAX\n    __m128i min_even_index = _mm_set1_epi32(2147483647); // Initialize to INT_MAX\n    __m128i even_mask = _mm_set1_epi32(1);\n    __m128i index = _mm_set_epi32(3, 2, 1, 0);\n\n    for(int i = 0; i < arr.size(); i += 4){\n        __m128i values = _mm_loadu_si128((__m128i*)&arr[i]);\n        __m128i even_values = _mm_and_si128(values, even_mask);\n        __m128i cmp = _mm_cmplt_epi32(even_values, min_even);\n        min_even = _mm_min_epi32(min_even, even_values);\n        min_even_index = _mm_blendv_epi8(min_even_index, index, cmp);\n        index = _mm_add_epi32(index, _mm_set1_epi32(4));\n    }\n\n    int result[4];\n    _mm_storeu_si128((__m128i*)result, min_even);\n    int min_val = 2147483647;\n    int min_idx = 2147483647;\n    for(int i = 0; i < 4; i++){\n        if(result[i] < min_val){\n            min_val = result[i];\n            min_idx = i;\n        }\n    }\n\n    if(min_val == 2147483647 || min_val % 2 != 0) return {};\n    return {min_val, min_idx};\n}\n```"}
{"task_id": "SimdBench_94_SSE", "completion": "```\nstd::vector<int> pluck_simd(std::vector<int> arr){\n    if(arr.empty()) return {};\n\n    __m128i min_even = _mm_set1_epi32(2147483647); // Initialize to maximum int value\n    __m128i min_even_idx = _mm_set1_epi32(2147483647); // Initialize to maximum int value\n    __m128i zero = _mm_set1_epi32(0);\n    __m128i two = _mm_set1_epi32(2);\n\n    for(int i = 0; i < arr.size(); i += 4){\n        __m128i values = _mm_loadu_si128((__m128i*)&arr[i]);\n        __m128i even_mask = _mm_cmplt_epi32(_mm_and_si128(values, two), two);\n        __m128i even_values = _mm_and_si128(values, even_mask);\n\n        __m128i cmp = _mm_cmplt_epi32(even_values, min_even);\n        min_even = _mm_min_epi32(even_values, min_even);\n        min_even_idx = _mm_blendv_epi8(min_even_idx, _mm_set1_epi32(i), cmp);\n    }\n\n    int result[4];\n    _mm_storeu_si128((__m128i*)result, min_even);\n    int min_val = result[0];\n    int min_idx = result[0];\n\n    for(int i = 1; i < 4; i++){\n        if(result[i] < min_val){\n            min_val = result[i];\n            min_idx = i;\n        }\n    }\n\n    return {min_val, min_idx};\n}\n```"}
{"task_id": "SimdBench_94_SSE", "completion": "```\nstd::vector<int> pluck_simd(std::vector<int> arr){\n    if(arr.empty()) return {};\n\n    __m128i minEven = _mm_set1_epi32(2147483647); // Initialize to maximum int value\n    __m128i minEvenIndex = _mm_set1_epi32(2147483647); // Initialize to maximum int value\n    __m128i evenMask = _mm_set1_epi32(1); // Mask to check if a number is even\n\n    for(int i = 0; i < arr.size(); i+=4){\n        __m128i values = _mm_set_epi32(arr[i+3], arr[i+2], arr[i+1], arr[i]);\n        __m128i evenValuesMask = _mm_cmplt_epi32(_mm_and_si128(values, evenMask), minEven); // Mask for even values smaller than current minEven\n        minEven = _mm_min_epi32(_mm_and_si128(values, evenValuesMask), minEven); // Update minEven with even values\n        minEvenIndex = _mm_blendv_epi8(minEvenIndex, _mm_set1_epi32(i), evenValuesMask); // Update minEvenIndex with the index of even values\n    }\n\n    int result[4];\n    _mm_storeu_si128((__m128i*)result, minEven);\n    int minEvenValue = result[0];\n    int minEvenIndexValue = result[0];\n\n    return {minEvenValue, minEvenIndexValue};\n}\n```"}
{"task_id": "SimdBench_94_SSE", "completion": "```\nstd::vector<int> pluck_simd(std::vector<int> arr){\n    if(arr.empty()) return {};\n\n    __m128i min_even = _mm_set1_epi32(2147483647); // Initialize to maximum int value\n    __m128i min_even_idx = _mm_set1_epi32(2147483647); // Initialize to maximum int value\n    __m128i even_mask = _mm_set1_epi32(1); // Mask for checking even values\n\n    for(int i = 0; i < arr.size(); i+=4){\n        __m128i values = _mm_loadu_si128((__m128i*)&arr[i]);\n        __m128i even_values = _mm_and_si128(values, even_mask);\n        __m128i cmp = _mm_cmplt_epi32(even_values, min_even);\n        min_even = _mm_min_epi32(even_values, min_even);\n        min_even_idx = _mm_blendv_epi8(min_even_idx, _mm_set1_epi32(i), cmp);\n    }\n\n    alignas(16) int result[4];\n    _mm_store_si128((__m128i*)result, min_even);\n    _mm_store_si128((__m128i*)result, min_even_idx);\n\n    std::vector<int> output(result, result + 4);\n    return output;\n}\n```"}
{"task_id": "SimdBench_95_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint search_simd(std::vector<int> lst){\n    __m128i result = _mm_setzero_si128();\n    __m128i freq = _mm_setzero_si128();\n    \n    for (size_t i = 0; i < lst.size(); i += 4) {\n        __m128i values = _mm_loadu_si128((__m128i*)&lst[i]);\n        \n        __m128i mask = _mm_cmpeq_epi32(values, result);\n        freq = _mm_add_epi32(freq, _mm_and_si128(mask, _mm_set1_epi32(1)));\n        \n        __m128i greater_than_zero = _mm_cmpgt_epi32(values, _mm_setzero_si128());\n        __m128i greater_than_freq = _mm_cmpgt_epi32(values, freq);\n        \n        __m128i greater_than_zero_and_freq = _mm_and_si128(greater_than_zero, greater_than_freq);\n        result = _mm_blendv_epi8(result, values, greater_than_zero_and_freq);\n    }\n    \n    alignas(16) int final_result[4];\n    _mm_store_si128((__m128i*)final_result, result);\n    \n    if (final_result[0] > 0 && final_result[0] == freq.m128i_i32[0]) {\n        return final_result[0];\n    } else if (final_result[1] > 0 && final_result[1] == freq.m128i_i32[1]) {\n        return final_result[1];\n    } else if (final_result[2] > 0 && final_result[2] == freq.m128i_i32[2]) {\n        return final_result[2];\n    } else if (final_result[3] > 0 && final_result[3] == freq.m128i_i32[3]) {\n        return final_result[3];\n    }\n    \n    return -1;\n}\n```"}
{"task_id": "SimdBench_95_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint search_simd(std::vector<int> lst){\n    __m128i result = _mm_set1_epi32(0);\n    __m128i freq = _mm_set1_epi32(0);\n    __m128i greater_than_zero = _mm_set1_epi32(0);\n    \n    for (size_t i = 0; i < lst.size(); i += 4) {\n        __m128i data = _mm_loadu_si128((__m128i*)&lst[i]);\n        \n        __m128i cmp_gt_zero = _mm_cmpgt_epi32(data, _mm_set1_epi32(0));\n        greater_than_zero = _mm_or_si128(greater_than_zero, cmp_gt_zero);\n        \n        __m128i mask = _mm_and_si128(cmp_gt_zero, _mm_cmpeq_epi32(data, _mm_set1_epi32(1)));\n        freq = _mm_add_epi32(freq, mask);\n        \n        mask = _mm_and_si128(cmp_gt_zero, _mm_cmpeq_epi32(data, _mm_set1_epi32(2)));\n        freq = _mm_add_epi32(freq, mask);\n        \n        mask = _mm_and_si128(cmp_gt_zero, _mm_cmpeq_epi32(data, _mm_set1_epi32(3)));\n        freq = _mm_add_epi32(freq, mask);\n        \n        mask = _mm_and_si128(cmp_gt_zero, _mm_cmpeq_epi32(data, _mm_set1_epi32(4)));\n        freq = _mm_add_epi32(freq, mask);\n    }\n    \n    __m128i cmp_freq = _mm_cmpgt_epi32(freq, result);\n    __m128i cmp_value = _mm_cmpgt_epi32(freq, _mm_set1_epi32(0));\n    __m128i final_mask = _mm_and_si128(cmp_freq, cmp_value);\n    \n    if (_mm_movemask_epi8(final_mask) == 0) {\n        return -1;\n    }\n    \n    int mask_array[4];\n    _mm_storeu_si128((__m128i*)mask_array, final_mask);\n    \n    for (int i = 0; i < 4; ++i) {\n        if (mask_array[i] != 0) {\n            return i + 1;\n        }\n    }\n    \n    return -1;\n}\n```"}
{"task_id": "SimdBench_95_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint search_simd(std::vector<int> lst){\n    __m128i result = _mm_setzero_si128();\n    __m128i freq = _mm_setzero_si128();\n    \n    for (size_t i = 0; i < lst.size(); i += 4) {\n        __m128i data = _mm_loadu_si128((__m128i*)&lst[i]);\n        \n        __m128i cmp = _mm_cmplt_epi32(data, _mm_set1_epi32(1));\n        freq = _mm_sub_epi32(freq, cmp);\n        \n        __m128i mask = _mm_cmpeq_epi32(data, _mm_set1_epi32(1));\n        result = _mm_blendv_epi8(result, data, mask);\n    }\n    \n    int max_freq = _mm_extract_epi32(freq, 0);\n    int max_result = _mm_extract_epi32(result, 0);\n    \n    if (max_freq >= max_result) {\n        return max_result;\n    } else {\n        return -1;\n    }\n}\n```"}
{"task_id": "SimdBench_95_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint search_simd(std::vector<int> lst){\n    __m128i freq[16] = { _mm_setzero_si128() };\n    __m128i max_freq = _mm_setzero_si128();\n    __m128i max_val = _mm_setzero_si128();\n    \n    for (int i = 0; i < lst.size(); i += 4) {\n        __m128i values = _mm_loadu_si128((__m128i*)&lst[i]);\n        \n        for (int j = 0; j < 4; j++) {\n            __m128i mask = _mm_cmpeq_epi32(values, _mm_set1_epi32(j + 1));\n            freq[j] = _mm_add_epi32(freq[j], mask);\n        }\n    }\n    \n    for (int i = 0; i < 4; i++) {\n        __m128i mask = _mm_cmpgt_epi32(freq[i], _mm_set1_epi32(i + 1));\n        __m128i new_max_freq = _mm_and_si128(freq[i], mask);\n        __m128i new_max_val = _mm_set1_epi32(i + 1);\n        \n        __m128i cmp_mask = _mm_cmpgt_epi32(new_max_freq, max_freq);\n        max_freq = _mm_blendv_epi8(max_freq, new_max_freq, cmp_mask);\n        max_val = _mm_blendv_epi8(max_val, new_max_val, cmp_mask);\n    }\n    \n    int result[4];\n    _mm_storeu_si128((__m128i*)result, max_val);\n    \n    return (result[0] == 0) ? -1 : result[0];\n}\n```"}
{"task_id": "SimdBench_95_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint search_simd(std::vector<int> lst){\n    __m128i target, cmp_result, freq_count;\n    int max_freq = 0, result = -1;\n\n    for (int i = 0; i < lst.size(); ++i) {\n        int val = lst[i];\n        if (val <= max_freq) continue;\n\n        int freq = 0;\n        target = _mm_set1_epi32(val);\n        freq_count = _mm_setzero_si128();\n\n        for (int j = 0; j < lst.size(); j += 4) {\n            __m128i data = _mm_loadu_si128((__m128i*)&lst[j]);\n            cmp_result = _mm_cmpeq_epi32(data, target);\n            freq_count = _mm_add_epi32(freq_count, cmp_result);\n        }\n\n        int freq_array[4];\n        _mm_storeu_si128((__m128i*)freq_array, freq_count);\n        freq = freq_array[0] + freq_array[1] + freq_array[2] + freq_array[3];\n\n        if (freq >= val && val > max_freq) {\n            max_freq = val;\n            result = val;\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_96_SSE", "completion": "```\nbool will_it_fly_simd(std::vector<int> q, int w) {\n    int size = q.size();\n    if (size == 1) {\n        return q[0] <= w;\n    }\n    \n    __m128i sum = _mm_setzero_si128();\n    for (int i = 0; i < size; i += 4) {\n        __m128i vec = _mm_set_epi32(q[i], q[i + 1], q[i + 2], q[i + 3]);\n        sum = _mm_add_epi32(sum, vec);\n    }\n    \n    int sum_arr[4];\n    _mm_storeu_si128((__m128i*)sum_arr, sum);\n    \n    int total_sum = sum_arr[0] + sum_arr[1] + sum_arr[2] + sum_arr[3];\n    \n    if (total_sum > w) {\n        return false;\n    }\n    \n    for (int i = 0; i < size / 2; i++) {\n        if (q[i] != q[size - i - 1]) {\n            return false;\n        }\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_96_SSE", "completion": "```\nbool will_it_fly_simd(std::vector<int> q, int w) {\n    int size = q.size();\n    \n    if (size == 1) {\n        return q[0] <= w;\n    }\n    \n    if (size % 4 != 0) {\n        return false;\n    }\n    \n    __m128i sum = _mm_setzero_si128();\n    for (int i = 0; i < size; i += 4) {\n        __m128i vec = _mm_loadu_si128((__m128i*)&q[i]);\n        sum = _mm_add_epi32(sum, vec);\n    }\n    \n    int total_sum[4];\n    _mm_storeu_si128((__m128i*)total_sum, sum);\n    \n    if (total_sum[0] > w || total_sum[1] > w || total_sum[2] > w || total_sum[3] > w) {\n        return false;\n    }\n    \n    return total_sum[0] == total_sum[3] && total_sum[1] == total_sum[2];\n}\n```"}
{"task_id": "SimdBench_96_SSE", "completion": "```\nbool will_it_fly_simd(std::vector<int> q, int w) {\n    int size = q.size();\n    if (size == 1) {\n        return q[0] <= w;\n    }\n\n    __m128i sum = _mm_setzero_si128();\n    for (int i = 0; i < size; i += 4) {\n        __m128i values = _mm_set_epi32(q[i], q[i + 1], q[i + 2], q[i + 3]);\n        sum = _mm_add_epi32(sum, values);\n    }\n\n    int sum_array[4];\n    _mm_storeu_si128((__m128i*)sum_array, sum);\n\n    int total_sum = sum_array[0] + sum_array[1] + sum_array[2] + sum_array[3];\n    if (total_sum > w) {\n        return false;\n    }\n\n    bool is_balanced = true;\n    for (int i = 0; i < size / 2; i++) {\n        if (q[i] != q[size - i - 1]) {\n            is_balanced = false;\n            break;\n        }\n    }\n\n    return is_balanced;\n}\n```"}
{"task_id": "SimdBench_96_SSE", "completion": "```\nbool will_it_fly_simd(std::vector<int> q, int w) {\n    int size = q.size();\n    if (size == 1) {\n        return q[0] <= w;\n    }\n\n    __m128i sum = _mm_setzero_si128();\n    for (int i = 0; i < size; i += 4) {\n        __m128i data = _mm_loadu_si128((__m128i*)&q[i]);\n        sum = _mm_add_epi32(sum, data);\n    }\n\n    int totalSum = sum.m128i_i32[0] + sum.m128i_i32[1] + sum.m128i_i32[2] + sum.m128i_i32[3];\n    if (totalSum > w) {\n        return false;\n    }\n\n    bool isBalanced = true;\n    for (int i = 0; i < size / 2; i++) {\n        if (q[i] != q[size - 1 - i]) {\n            isBalanced = false;\n            break;\n        }\n    }\n\n    return isBalanced;\n}\n```"}
{"task_id": "SimdBench_96_SSE", "completion": "```\nbool will_it_fly_simd(std::vector<int> q, int w) {\n    int size = q.size();\n    if (size == 1) {\n        return q[0] <= w;\n    }\n\n    __m128i sum = _mm_setzero_si128();\n    for (int i = 0; i < size; i += 4) {\n        __m128i vec = _mm_loadu_si128((__m128i*)&q[i]);\n        sum = _mm_add_epi32(sum, vec);\n    }\n\n    int totalSum = sum.m128i_i32[0] + sum.m128i_i32[1] + sum.m128i_i32[2] + sum.m128i_i32[3];\n    if (totalSum > w) {\n        return false;\n    }\n\n    bool isBalanced = true;\n    for (int i = 0; i < size / 2; i++) {\n        if (q[i] != q[size - 1 - i]) {\n            isBalanced = false;\n            break;\n        }\n    }\n\n    return isBalanced;\n}\n```"}
{"task_id": "SimdBench_97_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint smallest_change_simd(std::vector<int> arr){\n    int n = arr.size();\n    int changes = 0;\n    \n    for (int i = 0; i < n/2; i += 4) {\n        __m128i vec1 = _mm_loadu_si128((__m128i*)&arr[i]);\n        __m128i vec2 = _mm_loadu_si128((__m128i*)&arr[n-4-i]);\n        __m128i cmp = _mm_cmpeq_epi32(vec1, vec2);\n        int mask = _mm_movemask_epi8(cmp);\n        \n        while (mask != 0xFFFF) {\n            changes++;\n            mask &= mask - 1;\n        }\n    }\n    \n    return changes;\n}\n```"}
{"task_id": "SimdBench_97_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint smallest_change_simd(std::vector<int> arr){\n    int n = arr.size();\n    int changes = 0;\n    \n    for (int i = 0; i < n/2; i += 4) {\n        __m128i vec1 = _mm_loadu_si128((__m128i*)&arr[i]);\n        __m128i vec2 = _mm_loadu_si128((__m128i*)&arr[n-4-i]);\n        \n        __m128i cmp = _mm_cmpeq_epi32(vec1, vec2);\n        int mask = _mm_movemask_epi8(cmp);\n        \n        changes += _mm_popcnt_u32(mask);\n    }\n    \n    return changes;\n}\n```"}
{"task_id": "SimdBench_97_SSE", "completion": "```\nint smallest_change_simd(std::vector<int> arr){\n    int n = arr.size();\n    int changes = 0;\n    \n    __m128i* ptr = (__m128i*)arr.data();\n    int simd_size = n / 4;\n    \n    for (int i = 0; i < simd_size; ++i) {\n        __m128i vec = _mm_loadu_si128(ptr + i);\n        __m128i rev_vec = _mm_shuffle_epi32(vec, _MM_SHUFFLE(0, 1, 2, 3));\n        __m128i cmp = _mm_cmpeq_epi32(vec, rev_vec);\n        \n        int mask = _mm_movemask_epi8(cmp);\n        changes += _mm_popcnt_u32(mask);\n    }\n    \n    return changes;\n}\n```"}
{"task_id": "SimdBench_97_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint smallest_change_simd(std::vector<int> arr){\n    int n = arr.size();\n    int changes = 0;\n    \n    for (int i = 0; i < n/2; i += 4) {\n        __m128i vec1 = _mm_loadu_si128((__m128i*)&arr[i]);\n        __m128i vec2 = _mm_loadu_si128((__m128i*)&arr[n-4-i]);\n        \n        __m128i cmp = _mm_cmpeq_epi32(vec1, vec2);\n        int mask = _mm_movemask_epi8(cmp);\n        \n        changes += _mm_popcnt_u32(mask);\n    }\n    \n    return changes;\n}\n```"}
{"task_id": "SimdBench_97_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint smallest_change_simd(std::vector<int> arr){\n    int n = arr.size();\n    int changes = 0;\n    \n    for (int i = 0; i < n / 2; i += 4) {\n        __m128i vec1 = _mm_loadu_si128((__m128i*)&arr[i]);\n        __m128i vec2 = _mm_loadu_si128((__m128i*)&arr[n - i - 4]);\n        \n        __m128i cmp = _mm_cmpeq_epi32(vec1, vec2);\n        int mask = _mm_movemask_epi8(cmp);\n        \n        changes += _mm_popcnt_u32(mask);\n    }\n    \n    return changes;\n}\n```"}
{"task_id": "SimdBench_98_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n\nstd::vector<std::string> total_match_simd(const std::vector<std::string> & lst1, const std::vector<std::string> & lst2){\n    std::vector<std::string> result;\n    int total_chars_lst1 = 0;\n    int total_chars_lst2 = 0;\n\n    for (const auto& str : lst1) {\n        total_chars_lst1 += str.size();\n    }\n\n    for (const auto& str : lst2) {\n        total_chars_lst2 += str.size();\n    }\n\n    if (total_chars_lst1 < total_chars_lst2 || (total_chars_lst1 == total_chars_lst2 && !lst1.empty())) {\n        result = lst1;\n    } else {\n        result = lst2;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_98_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n\nstd::vector<std::string> total_match_simd(const std::vector<std::string> & lst1, const std::vector<std::string> & lst2){\n    std::vector<std::string> result;\n    int total_chars_lst1 = 0;\n    int total_chars_lst2 = 0;\n\n    for (const auto& str : lst1) {\n        total_chars_lst1 += str.size();\n    }\n\n    for (const auto& str : lst2) {\n        total_chars_lst2 += str.size();\n    }\n\n    if (total_chars_lst1 < total_chars_lst2 || (total_chars_lst1 == total_chars_lst2 && !lst1.empty())) {\n        result = lst1;\n    } else {\n        result = lst2;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_98_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n\nstd::vector<std::string> total_match_simd(const std::vector<std::string> & lst1, const std::vector<std::string> & lst2){\n    std::vector<std::string> result;\n    int total_chars1 = 0;\n    int total_chars2 = 0;\n\n    for (const auto& str : lst1) {\n        total_chars1 += str.size();\n    }\n\n    for (const auto& str : lst2) {\n        total_chars2 += str.size();\n    }\n\n    if (total_chars1 < total_chars2 || (total_chars1 == total_chars2 && lst1.size() <= lst2.size())) {\n        result = lst1;\n    } else {\n        result = lst2;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_98_SSE", "completion": "```\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n\nstd::vector<std::string> total_match_simd(const std::vector<std::string> & lst1, const std::vector<std::string> & lst2){\n    std::vector<std::string> result;\n    \n    if(lst1.size() == lst2.size()){\n        return lst1;\n    }\n    \n    int totalChars1 = 0;\n    int totalChars2 = 0;\n    \n    for(const auto& str : lst1){\n        totalChars1 += str.size();\n    }\n    \n    for(const auto& str : lst2){\n        totalChars2 += str.size();\n    }\n    \n    if(totalChars1 < totalChars2){\n        return lst1;\n    } else {\n        return lst2;\n    }\n}\n```"}
{"task_id": "SimdBench_98_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n\nstd::vector<std::string> total_match_simd(const std::vector<std::string> & lst1, const std::vector<std::string> & lst2){\n    std::vector<std::string> result;\n    \n    __m128i zero = _mm_setzero_si128();\n    __m128i sum1 = zero;\n    __m128i sum2 = zero;\n    \n    for (const auto &str : lst1) {\n        sum1 = _mm_add_epi32(sum1, _mm_set1_epi32(static_cast<int>(str.size())));\n    }\n    \n    for (const auto &str : lst2) {\n        sum2 = _mm_add_epi32(sum2, _mm_set1_epi32(static_cast<int>(str.size())));\n    }\n    \n    __m128i cmp = _mm_cmplt_epi32(sum1, sum2);\n    \n    for (size_t i = 0; i < lst1.size(); ++i) {\n        if (_mm_extract_epi32(cmp, i) != 0) {\n            result.push_back(lst1[i]);\n        }\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_99_SSE", "completion": "```cpp\nbool is_simple_power_simd(uint64_t x, uint64_t n){\n    if (x == 1) {\n        return true;\n    }\n    \n    if (n == 1) {\n        return false;\n    }\n    \n    if (x % n != 0) {\n        return false;\n    }\n    \n    uint64_t temp = x;\n    while (temp % n == 0) {\n        temp /= n;\n    }\n    \n    return temp == 1;\n}\n```"}
{"task_id": "SimdBench_99_SSE", "completion": "```cpp\nbool is_simple_power_simd(uint64_t x, uint64_t n){\n    if (x == 1) {\n        return true;\n    }\n    \n    if (n == 1) {\n        return false;\n    }\n    \n    __m128i x_mm = _mm_set1_epi64x(x);\n    __m128i n_mm = _mm_set1_epi64x(n);\n    \n    __m128i result = _mm_set1_epi64x(1);\n    \n    while (x_mm.m128i_u64[0] % n_mm.m128i_u64[0] == 0) {\n        x_mm = _mm_div_epi64(x_mm, n_mm);\n        result = _mm_mul_epi64(result, n_mm);\n    }\n    \n    return x_mm.m128i_u64[0] == 1 && result.m128i_u64[0] == x;\n}\n```"}
{"task_id": "SimdBench_99_SSE", "completion": "```cpp\nbool is_simple_power_simd(uint64_t x, uint64_t n){\n    if (x == 1) {\n        return true;\n    }\n    \n    __m128i x_vec = _mm_set1_epi64x(x);\n    __m128i n_vec = _mm_set1_epi64x(n);\n    \n    __m128i result = _mm_set1_epi64x(1);\n    \n    while (x % n == 0) {\n        x /= n;\n        __m128i x_div_vec = _mm_set1_epi64x(x);\n        result = _mm_and_si128(result, _mm_cmpeq_epi64(x_div_vec, _mm_mul_epu32(x_div_vec, n_vec)));\n        if (x == 1) {\n            break;\n        }\n    }\n    \n    return _mm_movemask_epi8(result) == 0xFFFF;\n}\n```  "}
{"task_id": "SimdBench_99_SSE", "completion": "```cpp\nbool is_simple_power_simd(uint64_t x, uint64_t n){\n    if (x == 1) {\n        return true;\n    }\n    \n    __m128i x_vec = _mm_set1_epi64x(x);\n    __m128i n_vec = _mm_set1_epi64x(n);\n    \n    __m128i result = _mm_set1_epi64x(1);\n    \n    while (x > 1) {\n        __m128i div = _mm_cvtsi64_si128(x);\n        __m128i cmp = _mm_cmpeq_epi64(div, n_vec);\n        if (_mm_movemask_epi8(cmp) == 0xFFFF) {\n            return true;\n        }\n        \n        __m128i mod = _mm_set1_epi64x(0);\n        _mm_divrem_epi64(div, n_vec, &div, &mod);\n        \n        __m128i cmp_mod = _mm_cmpeq_epi64(mod, _mm_set1_epi64x(0));\n        __m128i cmp_div = _mm_cmpeq_epi64(div, _mm_set1_epi64x(1));\n        __m128i cmp_result = _mm_and_si128(cmp_mod, cmp_div);\n        \n        result = _mm_and_si128(result, cmp_result);\n        \n        x = _mm_cvtsi128_si64(div);\n    }\n    \n    return _mm_movemask_epi8(result) == 0xFFFF;\n}\n```"}
{"task_id": "SimdBench_99_SSE", "completion": "```c\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool is_simple_power_simd(uint64_t x, uint64_t n){\n    if (x == 1) {\n        return true;\n    }\n    \n    if (n == 1) {\n        return false;\n    }\n\n    __m128i x_mm = _mm_set1_epi64x(x);\n    __m128i n_mm = _mm_set1_epi64x(n);\n\n    __m128i result = _mm_set1_epi64x(1);\n    __m128i power = _mm_set1_epi64x(1);\n\n    while (1) {\n        power = _mm_mul_epu32(power, n_mm);\n        result = _mm_cmpeq_epi64(power, x_mm);\n        if (_mm_movemask_epi8(result) != 0) {\n            return true;\n        }\n        if (_mm_movemask_epi8(_mm_cmpgt_epi64(power, x_mm)) != 0) {\n            return false;\n        }\n    }\n}\n```  "}
{"task_id": "SimdBench_100_SSE", "completion": "```\nint hex_key_simd(const std::string & num){\n    int count = 0;\n    __m128i primes = _mm_set_epi8(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0x02);\n    __m128i mask = _mm_set1_epi8(0x0F);\n    \n    for (size_t i = 0; i < num.size(); i += 16) {\n        __m128i input = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&num[i]));\n        __m128i input_lower = _mm_and_si128(input, mask);\n        \n        __m128i cmp1 = _mm_cmpeq_epi8(input_lower, primes);\n        __m128i cmp2 = _mm_cmpeq_epi8(input_lower, _mm_srli_epi16(primes, 4));\n        \n        __m128i cmp_result = _mm_or_si128(cmp1, cmp2);\n        \n        int cmp_mask = _mm_movemask_epi8(cmp_result);\n        count += _mm_popcnt_u32(cmp_mask);\n    }\n    \n    return count;\n}\n```"}
{"task_id": "SimdBench_100_SSE", "completion": "```\nint hex_key_simd(const std::string & num){\n    const __m128i primes = _mm_set_epi8(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0x02);\n    const __m128i hex_digits = _mm_set_epi8('F', 'E', 'D', 'C', 'B', 'A', '9', '8', '7', '6', '5', '4', '3', '2', '1', '0');\n    const __m128i mask = _mm_set1_epi8(0x0F);\n    \n    int count = 0;\n    for (size_t i = 0; i < num.size(); i += 16) {\n        __m128i input = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&num[i]));\n        __m128i input_lower = _mm_and_si128(input, mask);\n        __m128i cmp_result = _mm_cmpeq_epi8(input_lower, hex_digits);\n        __m128i cmp_result_primes = _mm_and_si128(cmp_result, primes);\n        \n        count += _mm_popcnt_u32(_mm_movemask_epi8(cmp_result_primes));\n    }\n    \n    return count;\n}\n```"}
{"task_id": "SimdBench_100_SSE", "completion": "```\nint hex_key_simd(const std::string & num){\n    const __m128i primes = _mm_set_epi8(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 'D', 'B', '7', '5');\n    const __m128i mask = _mm_set1_epi8(0x0F);\n    const __m128i zero = _mm_setzero_si128();\n    \n    int count = 0;\n    for (size_t i = 0; i < num.size(); i += 16) {\n        __m128i input = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&num[i]));\n        __m128i input_lower = _mm_and_si128(input, mask);\n        \n        __m128i cmp_result = _mm_cmpeq_epi8(input_lower, primes);\n        int cmp_mask = _mm_movemask_epi8(cmp_result);\n        \n        count += _mm_popcnt_u32(cmp_mask);\n    }\n    \n    return count;\n}\n```"}
{"task_id": "SimdBench_100_SSE", "completion": "```\nint hex_key_simd(const std::string & num){\n    const __m128i primes = _mm_set_epi8(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n    const __m128i digits = _mm_set_epi8('F', 'E', 'D', 'B', '7', '5', '3', '2', 'F', 'E', 'D', 'B', '7', '5', '3', '2');\n    const __m128i mask = _mm_set1_epi8(0x0F);\n    const __m128i zero = _mm_setzero_si128();\n    int count = 0;\n    \n    for (size_t i = 0; i < num.size(); i += 16) {\n        __m128i input = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&num[i]));\n        __m128i input_lower = _mm_and_si128(input, mask);\n        __m128i cmp = _mm_cmpeq_epi8(input_lower, digits);\n        __m128i result = _mm_and_si128(cmp, primes);\n        int result_array[16];\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(result_array), result);\n        \n        for (int j = 0; j < 16; j++) {\n            count += result_array[j];\n        }\n    }\n    \n    return count;\n}\n```"}
{"task_id": "SimdBench_100_SSE", "completion": "```\nint hex_key_simd(const std::string & num){\n    const __m128i primes = _mm_setr_epi8(2, 3, 5, 7, 11, 13, 17, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n    const __m128i hex_values = _mm_setr_epi8('0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F');\n    \n    int count = 0;\n    for (size_t i = 0; i < num.size(); i += 16) {\n        __m128i input = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&num[i]));\n        __m128i cmp = _mm_cmpeq_epi8(hex_values, input);\n        __m128i result = _mm_cmpeq_epi8(primes, input);\n        __m128i masked = _mm_and_si128(cmp, result);\n        int mask = _mm_movemask_epi8(masked);\n        \n        count += _mm_popcnt_u32(mask);\n    }\n    \n    return count;\n}\n```"}
{"task_id": "SimdBench_101_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool is_happy_simd(const std::string & s){\n    if(s.size() < 3){\n        return false;\n    }\n\n    const char* str = s.c_str();\n    int size = s.size();\n\n    for(int i = 0; i <= size - 12; i += 12){\n        __m128i chunk1 = _mm_loadu_si128((__m128i*)(str + i));\n        __m128i chunk2 = _mm_loadu_si128((__m128i*)(str + i + 4));\n        __m128i chunk3 = _mm_loadu_si128((__m128i*)(str + i + 8));\n\n        __m128i cmp1 = _mm_cmpeq_epi8(chunk1, chunk2);\n        __m128i cmp2 = _mm_cmpeq_epi8(chunk1, chunk3);\n        __m128i cmp3 = _mm_cmpeq_epi8(chunk2, chunk3);\n\n        if(_mm_movemask_epi8(_mm_or_si128(_mm_or_si128(cmp1, cmp2), cmp3)) != 0){\n            return false;\n        }\n    }\n\n    for(int i = size - (size % 12); i <= size - 3; ++i){\n        if(str[i] == str[i + 1] || str[i] == str[i + 2] || str[i + 1] == str[i + 2]){\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_101_SSE", "completion": "```\nbool is_happy_simd(const std::string & s){\n    if(s.size() < 3) {\n        return false;\n    }\n\n    const char* str = s.c_str();\n    int len = s.size();\n\n    for(int i = 0; i <= len - 12; i += 12) {\n        __m128i chunk1 = _mm_loadu_si128((__m128i*)(str + i));\n        __m128i chunk2 = _mm_loadu_si128((__m128i*)(str + i + 4));\n        __m128i chunk3 = _mm_loadu_si128((__m128i*)(str + i + 8));\n\n        __m128i cmp1 = _mm_cmpeq_epi8(chunk1, chunk2);\n        __m128i cmp2 = _mm_cmpeq_epi8(chunk2, chunk3);\n        __m128i cmp3 = _mm_cmpeq_epi8(chunk3, chunk1);\n\n        int mask1 = _mm_movemask_epi8(cmp1);\n        int mask2 = _mm_movemask_epi8(cmp2);\n        int mask3 = _mm_movemask_epi8(cmp3);\n\n        if(mask1 != 0xFFFF || mask2 != 0xFFFF || mask3 != 0xFFFF) {\n            return false;\n        }\n    }\n\n    for(int i = len - (len % 12); i <= len - 3; ++i) {\n        if(str[i] == str[i + 1] || str[i] == str[i + 2] || str[i + 1] == str[i + 2]) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_101_SSE", "completion": "```\nbool is_happy_simd(const std::string & s){\n    if(s.size() < 3){\n        return false;\n    }\n\n    int size = s.size() - 2;\n    for(int i = 0; i < size; i += 16){\n        __m128i chunk1 = _mm_loadu_si128((__m128i*)(s.data() + i));\n        __m128i chunk2 = _mm_loadu_si128((__m128i*)(s.data() + i + 16));\n        __m128i chunk3 = _mm_loadu_si128((__m128i*)(s.data() + i + 32));\n\n        __m128i cmp1 = _mm_cmpeq_epi8(chunk1, chunk2);\n        __m128i cmp2 = _mm_cmpeq_epi8(chunk2, chunk3);\n        __m128i cmp3 = _mm_cmpeq_epi8(chunk3, chunk1);\n\n        __m128i cmp_result = _mm_or_si128(_mm_or_si128(cmp1, cmp2), cmp3);\n\n        if(_mm_movemask_epi8(cmp_result) != 0){\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_101_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool is_happy_simd(const std::string & s){\n    if(s.size() < 3) {\n        return false;\n    }\n\n    const char* str = s.c_str();\n    int size = s.size();\n\n    for(int i = 0; i <= size - 12; i += 12) {\n        __m128i chunk1 = _mm_loadu_si128((__m128i*)(str + i));\n        __m128i chunk2 = _mm_loadu_si128((__m128i*)(str + i + 4));\n        __m128i chunk3 = _mm_loadu_si128((__m128i*)(str + i + 8));\n\n        __m128i cmp1 = _mm_cmpeq_epi8(chunk1, chunk2);\n        __m128i cmp2 = _mm_cmpeq_epi8(chunk1, chunk3);\n        __m128i cmp3 = _mm_cmpeq_epi8(chunk2, chunk3);\n\n        __m128i cmp_result = _mm_or_si128(_mm_or_si128(cmp1, cmp2), cmp3);\n\n        if(_mm_movemask_epi8(cmp_result) != 0) {\n            return false;\n        }\n    }\n\n    for(int i = size - (size % 12); i <= size - 3; i++) {\n        if(str[i] == str[i + 1] || str[i] == str[i + 2] || str[i + 1] == str[i + 2]) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_101_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool is_happy_simd(const std::string & s){\n    if(s.size() < 3){\n        return false;\n    }\n\n    const char* str = s.c_str();\n    int len = s.size();\n\n    for(int i = 0; i <= len - 12; i += 12){\n        __m128i chunk1 = _mm_loadu_si128((__m128i*)(str + i));\n        __m128i chunk2 = _mm_loadu_si128((__m128i*)(str + i + 4));\n        __m128i chunk3 = _mm_loadu_si128((__m128i*)(str + i + 8));\n\n        __m128i cmp1 = _mm_cmpeq_epi8(chunk1, chunk2);\n        __m128i cmp2 = _mm_cmpeq_epi8(chunk2, chunk3);\n        __m128i cmp3 = _mm_cmpeq_epi8(chunk3, chunk1);\n\n        __m128i cmp_result = _mm_or_si128(_mm_or_si128(cmp1, cmp2), cmp3);\n\n        if(_mm_movemask_epi8(cmp_result) != 0){\n            return false;\n        }\n    }\n\n    for(int i = len - (len % 12); i <= len - 3; i++){\n        if(str[i] == str[i + 1] || str[i] == str[i + 2] || str[i + 1] == str[i + 2]){\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_102_SSE", "completion": "```\nbool prime_length_simd(const std::string & str){\n    int length = str.length();\n    if (length <= 1) {\n        return false;\n    }\n    \n    int sqrt_length = sqrt(length);\n    for (int i = 2; i <= sqrt_length; i++) {\n        if (length % i == 0) {\n            return false;\n        }\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_102_SSE", "completion": "```\nbool prime_length_simd(const std::string & str){\n    int len = str.length();\n    if (len <= 2) {\n        return len == 2;\n    }\n\n    __m128i zero = _mm_setzero_si128();\n    __m128i one = _mm_set1_epi32(1);\n    __m128i n = _mm_set1_epi32(len);\n\n    __m128i i = _mm_setr_epi32(2, 3, 4, 5);\n    __m128i is_prime = _mm_cmpeq_epi32(zero, zero);\n\n    __m128i mask = _mm_cmplt_epi32(i, n);\n\n    while (_mm_movemask_epi8(mask) != 0) {\n        __m128i rem = _mm_set1_epi32(0);\n        __m128i div = _mm_set1_epi32(0);\n\n        div = _mm_div_epi32(n, i);\n        rem = _mm_sub_epi32(n, _mm_mullo_epi32(i, div));\n\n        __m128i is_divisible = _mm_cmpeq_epi32(rem, zero);\n        __m128i is_not_one = _mm_cmpneq_epi32(i, one);\n\n        is_prime = _mm_and_si128(is_prime, _mm_and_si128(is_not_one, _mm_and_si128(is_divisible, is_prime)));\n\n        i = _mm_add_epi32(i, _mm_set1_epi32(4));\n        mask = _mm_cmplt_epi32(i, n);\n    }\n\n    int result[4];\n    _mm_storeu_si128((__m128i*)result, is_prime);\n\n    return result[0] && result[1] && result[2] && result[3];\n}\n```"}
{"task_id": "SimdBench_102_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nbool is_prime(int n) {\n    if (n <= 1) {\n        return false;\n    }\n    for (int i = 2; i * i <= n; i++) {\n        if (n % i == 0) {\n            return false;\n        }\n    }\n    return true;\n}\n\nbool prime_length_simd(const std::string & str){\n    int length = str.length();\n    __m128i zero = _mm_setzero_si128();\n    __m128i one = _mm_set1_epi32(1);\n    __m128i length_vec = _mm_set1_epi32(length);\n\n    __m128i divisors = _mm_setr_epi32(2, 3, 5, 7);\n\n    __m128i mask = _mm_cmplt_epi32(length_vec, divisors);\n\n    for (int i = 8; i < length; i += 8) {\n        __m128i indices = _mm_add_epi32(_mm_setr_epi32(i, i + 1, i + 2, i + 3), divisors);\n        __m128i divisors_mask = _mm_cmplt_epi32(length_vec, indices);\n        mask = _mm_and_si128(mask, divisors_mask);\n    }\n\n    int mask_arr[4];\n    _mm_storeu_si128((__m128i*)mask_arr, mask);\n\n    for (int i = 0; i < 4; i++) {\n        if (mask_arr[i] != 0) {\n            return false;\n        }\n    }\n\n    return is_prime(length);\n}\n```"}
{"task_id": "SimdBench_102_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nbool is_prime(int n) {\n    if (n <= 1) return false;\n    if (n <= 3) return true;\n    if (n % 2 == 0 || n % 3 == 0) return false;\n    for (int i = 5; i * i <= n; i += 6) {\n        if (n % i == 0 || n % (i + 2) == 0) return false;\n    }\n    return true;\n}\n\nbool prime_length_simd(const std::string & str){\n    int length = str.length();\n    return is_prime(length);\n}\n```  "}
{"task_id": "SimdBench_102_SSE", "completion": "```\nbool prime_length_simd(const std::string & str){\n    int length = str.length();\n    if (length <= 1) {\n        return false;\n    }\n    \n    int sqrt_length = sqrt(length);\n    for (int i = 2; i <= sqrt_length; i++) {\n        if (length % i == 0) {\n            return false;\n        }\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_103_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string solve_simd(uint64_t N){\n    __m128i sum = _mm_setzero_si128();\n    __m128i zero = _mm_setzero_si128();\n    __m128i ten = _mm_set1_epi8(10);\n    __m128i mask = _mm_set1_epi8(0x0F);\n\n    while(N > 0){\n        __m128i digits = _mm_set_epi8(\n            N % 10, (N / 10) % 10, (N / 100) % 10, (N / 1000) % 10,\n            N % 10, (N / 10) % 10, (N / 100) % 10, (N / 1000) % 10,\n            N % 10, (N / 10) % 10, (N / 100) % 10, (N / 1000) % 10,\n            N % 10, (N / 10) % 10, (N / 100) % 10, (N / 1000) % 10\n        );\n        __m128i digits_low = _mm_and_si128(digits, mask);\n        __m128i digits_high = _mm_and_si128(_mm_srli_epi16(digits, 4), mask);\n        sum = _mm_add_epi8(sum, digits_low);\n        sum = _mm_add_epi8(sum, digits_high);\n        N /= 10000;\n    }\n\n    __m128i sum_low = _mm_unpacklo_epi8(sum, zero);\n    __m128i sum_high = _mm_unpackhi_epi8(sum, zero);\n    __m128i total_sum = _mm_add_epi16(sum_low, sum_high);\n\n    uint16_t result[8];\n    _mm_storeu_si128((__m128i*)result, total_sum);\n\n    std::string binary_sum = \"\";\n    for(int i = 0; i < 8; i++){\n        binary_sum = std::to_string(result[i] % 2) + binary_sum;\n        result[i] /= 2;\n        binary_sum = std::to_string(result[i] % 2) + binary_sum;\n        result[i] /= 2;\n    }\n\n    return binary_sum;\n}\n```"}
{"task_id": "SimdBench_103_SSE", "completion": "```\nstd::string solve_simd(uint64_t N){\n    __m128i sum = _mm_setzero_si128();\n    __m128i mask = _mm_set1_epi8(0x0F);\n    __m128i zero = _mm_setzero_si128();\n    \n    while(N > 0){\n        __m128i digits = _mm_set1_epi64x(N);\n        __m128i lower = _mm_and_si128(digits, mask);\n        __m128i upper = _mm_and_si128(_mm_srli_epi64(digits, 4), mask);\n        \n        sum = _mm_add_epi8(sum, lower);\n        sum = _mm_add_epi8(sum, upper);\n        \n        N /= 100;\n    }\n    \n    __m128i shuffle_mask = _mm_set_epi8(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 15, 13, 11, 9, 7, 5, 3, 1);\n    __m128i result = _mm_shuffle_epi8(sum, shuffle_mask);\n    \n    uint8_t result_arr[16];\n    _mm_storeu_si128((__m128i*)result_arr, result);\n    \n    std::string binary_str = \"\";\n    for(int i = 0; i < 16; ++i){\n        binary_str += std::to_string((result_arr[i] >> 3) & 1);\n        binary_str += std::to_string((result_arr[i] >> 2) & 1);\n        binary_str += std::to_string((result_arr[i] >> 1) & 1);\n        binary_str += std::to_string(result_arr[i] & 1);\n    }\n    \n    return binary_str;\n}\n```"}
{"task_id": "SimdBench_103_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <bitset>\n\nstd::string solve_simd(uint64_t N){\n    __m128i sum = _mm_setzero_si128();\n    __m128i zero = _mm_setzero_si128();\n    __m128i ten = _mm_set1_epi8(10);\n    __m128i ascii_0 = _mm_set1_epi8('0');\n\n    while(N > 0){\n        __m128i digit = _mm_set1_epi8(N % 10);\n        sum = _mm_add_epi8(sum, digit);\n        N /= 10;\n    }\n\n    __m128i mask = _mm_cmpeq_epi8(sum, zero);\n    __m128i result = _mm_blendv_epi8(ascii_0, ten, mask);\n\n    alignas(16) int result_arr[16];\n    _mm_store_si128((__m128i*)result_arr, result);\n\n    std::string binary_str = \"\";\n    for(int i = 15; i >= 0; i--){\n        binary_str += std::bitset<8>(result_arr[i]).to_string();\n    }\n\n    return binary_str;\n}\n```"}
{"task_id": "SimdBench_103_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string solve_simd(uint64_t N){\n    __m128i sum = _mm_setzero_si128();\n    __m128i zero = _mm_setzero_si128();\n    __m128i ten = _mm_set1_epi8(10);\n    __m128i ascii_0 = _mm_set1_epi8('0');\n    \n    while(N > 0){\n        __m128i digit = _mm_set1_epi8(N % 10);\n        sum = _mm_add_epi8(sum, digit);\n        N /= 10;\n    }\n    \n    __m128i mask = _mm_cmpeq_epi8(sum, zero);\n    __m128i result = _mm_blendv_epi8(ascii_0, ten, mask);\n    \n    alignas(16) uint8_t output[16];\n    _mm_store_si128((__m128i*)output, result);\n    \n    return std::string((char*)output);\n}\n```"}
{"task_id": "SimdBench_103_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <bitset>\n\nstd::string solve_simd(uint64_t N){\n    __m128i sum = _mm_setzero_si128();\n    __m128i mask = _mm_set1_epi8(0x0F);\n\n    while (N > 0) {\n        __m128i digits = _mm_set1_epi64x(N);\n        __m128i lower_nibbles = _mm_and_si128(digits, mask);\n        sum = _mm_add_epi8(sum, lower_nibbles);\n        N >>= 4;\n    }\n\n    alignas(16) uint8_t result[16];\n    _mm_store_si128((__m128i*)result, sum);\n\n    std::string binary_str = \"\";\n    for (int i = 15; i >= 0; i--) {\n        binary_str += std::bitset<8>(result[i]).to_string();\n    }\n\n    return binary_str;\n}\n```"}
{"task_id": "SimdBench_104_SSE", "completion": "```cpp\nint add_simd(std::vector<int> lst){\n    __m128i sum = _mm_setzero_si128();\n    for (int i = 1; i < lst.size(); i += 2) {\n        __m128i values = _mm_set_epi32(0, 0, 0, lst[i]);\n        sum = _mm_add_epi32(sum, values);\n    }\n    int result[4];\n    _mm_storeu_si128((__m128i*)result, sum);\n    return result[0] + result[1];\n}\n```"}
{"task_id": "SimdBench_104_SSE", "completion": "```cpp\nint add_simd(std::vector<int> lst){\n    __m128i sum = _mm_setzero_si128();\n    for (int i = 1; i < lst.size(); i += 2) {\n        __m128i values = _mm_set_epi32(0, 0, 0, lst[i]);\n        sum = _mm_add_epi32(sum, values);\n    }\n    int result[4];\n    _mm_storeu_si128((__m128i*)result, sum);\n    return result[0] + result[1];\n}\n```"}
{"task_id": "SimdBench_104_SSE", "completion": "```cpp\nint add_simd(std::vector<int> lst){\n    __m128i sum = _mm_setzero_si128();\n    for (int i = 1; i < lst.size(); i += 2) {\n        __m128i values = _mm_set_epi32(0, 0, 0, lst[i]);\n        sum = _mm_add_epi32(sum, values);\n    }\n    int result[4];\n    _mm_storeu_si128((__m128i*)result, sum);\n    return result[0] + result[1];\n}\n```"}
{"task_id": "SimdBench_104_SSE", "completion": "```cpp\nint add_simd(std::vector<int> lst){\n    __m128i sum = _mm_setzero_si128();\n    for (int i = 1; i < lst.size(); i += 2) {\n        __m128i values = _mm_set_epi32(0, 0, 0, lst[i]);\n        sum = _mm_add_epi32(sum, values);\n    }\n    int result[4];\n    _mm_storeu_si128((__m128i*)result, sum);\n    return result[0] + result[1];\n}\n```"}
{"task_id": "SimdBench_104_SSE", "completion": "```cpp\nint add_simd(std::vector<int> lst){\n    __m128i result = _mm_setzero_si128();\n    for (int i = 1; i < lst.size(); i += 2) {\n        __m128i values = _mm_set_epi32(0, 0, 0, lst[i]);\n        result = _mm_add_epi32(result, values);\n    }\n    int sum[4];\n    _mm_storeu_si128((__m128i*)sum, result);\n    return sum[0] + sum[1];\n}\n```"}
{"task_id": "SimdBench_105_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string encrypt_simd(const std::string & s){\n    __m128i shift = _mm_set1_epi8(2 * 2);\n    std::string result = s;\n    int length = s.length();\n    \n    for (int i = 0; i < length; i += 16) {\n        __m128i data = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&s[i]));\n        __m128i shifted_data = _mm_add_epi8(data, shift);\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i]), shifted_data);\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_105_SSE", "completion": "```\nstd::string encrypt_simd(const std::string & s){\n    std::string result = s;\n    __m128i shift = _mm_set1_epi8(2 * 2);\n    for (size_t i = 0; i < s.size(); i += 16) {\n        __m128i data = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&s[i]));\n        __m128i shifted_data = _mm_add_epi8(data, shift);\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i]), shifted_data);\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_105_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string encrypt_simd(const std::string & s){\n    __m128i shift = _mm_set1_epi8(2);\n    __m128i mask_lower = _mm_set1_epi8(0x0F);\n    __m128i mask_upper = _mm_set1_epi8(0xF0);\n\n    std::string result(s.size(), ' ');\n\n    for (size_t i = 0; i < s.size(); i += 16) {\n        __m128i input = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&s[i]));\n\n        __m128i lower_nibble = _mm_and_si128(input, mask_lower);\n        __m128i upper_nibble = _mm_and_si128(input, mask_upper);\n\n        lower_nibble = _mm_add_epi8(lower_nibble, shift);\n        upper_nibble = _mm_add_epi8(upper_nibble, shift);\n\n        lower_nibble = _mm_and_si128(lower_nibble, mask_lower);\n        upper_nibble = _mm_and_si128(upper_nibble, mask_upper);\n\n        __m128i encrypted = _mm_or_si128(lower_nibble, upper_nibble);\n\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i]), encrypted);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_105_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string encrypt_simd(const std::string & s){\n    __m128i shift = _mm_set1_epi8(2 * 2);\n    std::string result = s;\n\n    for (size_t i = 0; i < s.size(); i += 16) {\n        __m128i data = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&s[i]));\n        __m128i shifted_data = _mm_add_epi8(data, shift);\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i]), shifted_data);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_105_SSE", "completion": "```\nstd::string encrypt_simd(const std::string & s){\n    std::string result = s;\n    __m128i shift = _mm_set1_epi8(2);\n    for (size_t i = 0; i < s.size(); i += 16) {\n        __m128i data = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&s[i]));\n        __m128i shifted_data = _mm_add_epi8(data, shift);\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i]), shifted_data);\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_106_SSE", "completion": "```\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string encode_simd(const std::string & message){\n    std::string result = message;\n    __m128i lowercaseMask = _mm_set1_epi8(0x1F); // Mask to convert uppercase to lowercase\n    __m128i vowelsMask = _mm_set_epi8('A', 'E', 'I', 'O', 'U', 'a', 'e', 'i', 'o', 'u', 'A', 'E', 'I', 'O', 'U', 'a');\n    __m128i twoAheadMask = _mm_set_epi8('C', 'G', 'K', 'Q', 'Y', 'c', 'g', 'k', 'q', 'y', 'C', 'G', 'K', 'Q', 'Y', 'c');\n\n    for (size_t i = 0; i < message.size(); i += 16) {\n        __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&message[i]));\n        \n        // Convert uppercase to lowercase\n        __m128i lowercase = _mm_or_si128(_mm_and_si128(chunk, lowercaseMask), _mm_set1_epi8(0x20));\n        \n        // Check for vowels\n        __m128i isVowel = _mm_cmpeq_epi8(chunk, vowelsMask);\n        \n        // Replace vowels with letters 2 places ahead\n        __m128i resultChunk = _mm_blendv_epi8(chunk, twoAheadMask, isVowel);\n        \n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i]), resultChunk);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_106_SSE", "completion": "```\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string encode_simd(const std::string & message) {\n    std::string result = message;\n    __m128i lowercase_mask = _mm_set1_epi8(0x1F);\n    __m128i vowels_mask = _mm_set1_epi8(0x55); // Mask for vowels (A, E, I, O, U)\n    __m128i two_ahead_mask = _mm_set1_epi8(0x1C); // Mask for replacing vowels with letters 2 places ahead\n\n    for (size_t i = 0; i < message.size(); i += 16) {\n        __m128i input = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&message[i]));\n\n        // Convert to uppercase by clearing the 5th bit\n        __m128i uppercase = _mm_and_si128(input, lowercase_mask);\n\n        // Check for vowels\n        __m128i is_vowel = _mm_cmpeq_epi8(uppercase, vowels_mask);\n\n        // Replace vowels with letters 2 places ahead\n        __m128i replaced_vowels = _mm_add_epi8(uppercase, two_ahead_mask);\n        __m128i result_vowels = _mm_and_si128(replaced_vowels, is_vowel);\n        __m128i result_consonants = _mm_andnot_si128(is_vowel, uppercase);\n\n        // Combine vowels and consonants\n        __m128i result_chars = _mm_or_si128(result_vowels, result_consonants);\n\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i]), result_chars);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_106_SSE", "completion": "```\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string encode_simd(const std::string & message){\n    std::string result = message;\n    __m128i lowercase_mask = _mm_set1_epi8(0x1F); // Mask to convert uppercase to lowercase\n    __m128i vowels_mask = _mm_set_epi8('A', 'E', 'I', 'O', 'U', 'a', 'e', 'i', 'o', 'u', 'A', 'E', 'I', 'O', 'U', 'a');\n    __m128i two_ahead_mask = _mm_set_epi8('C', 'H', 'L', 'R', 'X', 'c', 'h', 'l', 'r', 'x', 'C', 'H', 'L', 'R', 'X', 'c');\n\n    int length = message.size();\n    int i = 0;\n    while (i < length) {\n        __m128i chunk = _mm_loadu_si128((__m128i*)(message.c_str() + i));\n        __m128i lowercase = _mm_or_si128(chunk, lowercase_mask);\n        __m128i is_vowel = _mm_cmpeq_epi8(chunk, vowels_mask);\n        __m128i replace_vowel = _mm_blendv_epi8(chunk, two_ahead_mask, is_vowel);\n        __m128i swapped_case = _mm_xor_si128(replace_vowel, lowercase);\n        _mm_storeu_si128((__m128i*)(result.data() + i), swapped_case);\n        i += 16;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_106_SSE", "completion": "```\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string encode_simd(const std::string & message) {\n    const __m128i lowercase_mask = _mm_set1_epi8(0x1F); // Mask to convert uppercase to lowercase\n    const __m128i vowel_mask = _mm_set1_epi8(0x07); // Mask to identify vowels\n    const __m128i vowel_shift = _mm_set1_epi8(2); // Shift value for vowels\n\n    std::string result(message.size(), ' ');\n\n    for (size_t i = 0; i < message.size(); i += 16) {\n        __m128i input = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&message[i]));\n\n        // Convert uppercase to lowercase\n        __m128i lowercase = _mm_or_si128(input, lowercase_mask);\n\n        // Identify vowels\n        __m128i vowels = _mm_cmpeq_epi8(_mm_and_si128(lowercase, vowel_mask), vowel_mask);\n\n        // Shift vowels\n        __m128i shifted_vowels = _mm_add_epi8(vowels, vowel_shift);\n\n        // Replace vowels with shifted values\n        __m128i result_chars = _mm_blendv_epi8(input, shifted_vowels, vowels);\n\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i]), result_chars);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_106_SSE", "completion": "```\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string encode_simd(const std::string & message) {\n    std::string result = message;\n    __m128i lowercase_mask = _mm_set1_epi8(0x1F); // Mask to convert uppercase to lowercase\n    __m128i vowels_mask = _mm_setr_epi8('A', 'E', 'I', 'O', 'U', 'a', 'e', 'i', 'o', 'u', 0, 0, 0, 0, 0, 0); // Vowels mask\n    __m128i alphabet_offset = _mm_set1_epi8(2); // Offset to replace vowels\n\n    for (size_t i = 0; i < message.size(); i += 16) {\n        __m128i input = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&message[i]));\n\n        // Convert uppercase to lowercase\n        __m128i lowercase = _mm_or_si128(input, lowercase_mask);\n\n        // Check for vowels\n        __m128i is_vowel = _mm_cmpeq_epi8(lowercase, vowels_mask);\n        \n        // Replace vowels with letter 2 places ahead\n        __m128i replacement = _mm_add_epi8(lowercase, alphabet_offset);\n        __m128i result_vowels = _mm_and_si128(is_vowel, replacement);\n        __m128i result_consonants = _mm_andnot_si128(is_vowel, lowercase);\n        \n        // Merge vowels and consonants\n        __m128i result_chars = _mm_or_si128(result_vowels, result_consonants);\n\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i]), result_chars);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_107_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <map>\n#include <string>\n\nbool check_dict_case_simd(std::map<std::string, std::string> dict){\n    if(dict.empty()) return false;\n    \n    __m128i lowercase_mask = _mm_setr_epi8('a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a');\n    __m128i uppercase_mask = _mm_setr_epi8('A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A');\n    \n    bool all_lowercase = true;\n    bool all_uppercase = true;\n    \n    for(auto it = dict.begin(); it != dict.end(); ++it){\n        std::string key = it->first;\n        if(key.size() == 0){\n            all_lowercase = false;\n            all_uppercase = false;\n            break;\n        }\n        \n        __m128i key_chars = _mm_loadu_si128((__m128i*)key.c_str());\n        __m128i lowercase_result = _mm_cmpeq_epi8(key_chars, lowercase_mask);\n        __m128i uppercase_result = _mm_cmpeq_epi8(key_chars, uppercase_mask);\n        \n        all_lowercase = all_lowercase && _mm_movemask_epi8(lowercase_result) == 0xFFFF;\n        all_uppercase = all_uppercase && _mm_movemask_epi8(uppercase_result) == 0xFFFF;\n        \n        if(!all_lowercase && !all_uppercase){\n            break;\n        }\n    }\n    \n    return all_lowercase || all_uppercase;\n}\n```"}
{"task_id": "SimdBench_107_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <map>\n#include <string>\n\nbool check_dict_case_simd(std::map<std::string, std::string> dict){\n    if(dict.empty()) return false;\n    \n    __m128i lowercase_mask = _mm_set1_epi8(0x20); // Mask to convert uppercase to lowercase\n    __m128i all_lowercase = _mm_set1_epi8(0); // Vector to check if all keys are lowercase\n    __m128i all_uppercase = _mm_set1_epi8(0); // Vector to check if all keys are uppercase\n    \n    for(auto it = dict.begin(); it != dict.end(); ++it){\n        std::string key = it->first;\n        if(key.empty()) continue;\n        \n        __m128i key_vector = _mm_loadu_si128(reinterpret_cast<const __m128i*>(key.c_str()));\n        __m128i lowercase_key = _mm_or_si128(_mm_cmplt_epi8(key_vector, _mm_set1_epi8('A')), _mm_cmpgt_epi8(key_vector, _mm_set1_epi8('Z')));\n        __m128i uppercase_key = _mm_andnot_si128(lowercase_key, _mm_cmpeq_epi8(_mm_and_si128(key_vector, _mm_set1_epi8(0xDF)), key_vector));\n        \n        all_lowercase = _mm_or_si128(all_lowercase, lowercase_key);\n        all_uppercase = _mm_or_si128(all_uppercase, uppercase_key);\n    }\n    \n    return _mm_testz_si128(all_lowercase, all_uppercase);\n}\n```"}
{"task_id": "SimdBench_107_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <map>\n#include <string>\n\nbool check_dict_case_simd(std::map<std::string, std::string> dict){\n    if (dict.empty()) {\n        return false;\n    }\n\n    __m128i lowercase_mask = _mm_set1_epi8(0x20); // Mask to convert uppercase to lowercase\n    __m128i all_lowercase = _mm_set1_epi8(0); // Vector to track if all keys are lowercase\n    __m128i all_uppercase = _mm_set1_epi8(0); // Vector to track if all keys are uppercase\n\n    for (const auto& entry : dict) {\n        const std::string& key = entry.first;\n        __m128i key_chars = _mm_loadu_si128(reinterpret_cast<const __m128i*>(key.c_str()));\n\n        // Check if all characters are lowercase\n        __m128i lowercase_chars = _mm_or_si128(_mm_cmplt_epi8(key_chars, _mm_set1_epi8('a')),\n                                               _mm_cmpgt_epi8(key_chars, _mm_set1_epi8('z')));\n        all_lowercase = _mm_or_si128(all_lowercase, lowercase_chars);\n\n        // Check if all characters are uppercase\n        __m128i uppercase_chars = _mm_or_si128(_mm_cmplt_epi8(key_chars, _mm_set1_epi8('A')),\n                                               _mm_cmpgt_epi8(key_chars, _mm_set1_epi8('Z')));\n        all_uppercase = _mm_or_si128(all_uppercase, uppercase_chars);\n    }\n\n    // Check if all keys are lowercase or all keys are uppercase\n    __m128i lowercase_result = _mm_cmpeq_epi8(all_lowercase, _mm_set1_epi8(0));\n    __m128i uppercase_result = _mm_cmpeq_epi8(all_uppercase, _mm_set1_epi8(0));\n    __m128i final_result = _mm_or_si128(lowercase_result, uppercase_result);\n\n    return _mm_movemask_epi8(final_result) == 0xFFFF;\n}\n```"}
{"task_id": "SimdBench_107_SSE", "completion": "```\nbool check_dict_case_simd(std::map<std::string, std::string> dict){\n    if(dict.empty()){\n        return false;\n    }\n    \n    __m128i lowercase_mask = _mm_set1_epi8(0x20); // Mask to convert uppercase to lowercase\n    __m128i all_lowercase = _mm_set1_epi8(0); // Vector to check if all keys are lowercase\n    __m128i all_uppercase = _mm_set1_epi8(0); // Vector to check if all keys are uppercase\n    \n    for(auto const& entry : dict){\n        std::string key = entry.first;\n        if(key.empty()){\n            continue;\n        }\n        \n        __m128i key_vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(key.c_str()));\n        __m128i lowercase_key = _mm_or_si128(_mm_cmplt_epi8(key_vec, _mm_set1_epi8('a')),\n                                            _mm_cmpgt_epi8(key_vec, _mm_set1_epi8('z')));\n        __m128i uppercase_key = _mm_or_si128(_mm_cmplt_epi8(key_vec, _mm_set1_epi8('A')),\n                                            _mm_cmpgt_epi8(key_vec, _mm_set1_epi8('Z')));\n        \n        all_lowercase = _mm_or_si128(all_lowercase, lowercase_key);\n        all_uppercase = _mm_or_si128(all_uppercase, uppercase_key);\n    }\n    \n    __m128i lowercase_result = _mm_cmpeq_epi8(all_lowercase, _mm_set1_epi8(0));\n    __m128i uppercase_result = _mm_cmpeq_epi8(all_uppercase, _mm_set1_epi8(0));\n    \n    return _mm_movemask_epi8(_mm_or_si128(lowercase_result, uppercase_result)) == 0xFFFF;\n}\n```"}
{"task_id": "SimdBench_107_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <map>\n#include <string>\n\nbool check_dict_case_simd(std::map<std::string, std::string> dict){\n    if(dict.empty()){\n        return false;\n    }\n\n    __m128i lowercase_mask = _mm_set1_epi8(0x20); // Mask to convert uppercase to lowercase\n    __m128i all_lowercase = _mm_set1_epi8(0); // Vector to check if all keys are lowercase\n    __m128i all_uppercase = _mm_set1_epi8(0); // Vector to check if all keys are uppercase\n\n    for(auto const& entry : dict){\n        std::string key = entry.first;\n        if(key.empty()){\n            continue;\n        }\n\n        __m128i key_vector = _mm_loadu_si128(reinterpret_cast<const __m128i*>(key.c_str()));\n        __m128i lowercase_key = _mm_or_si128(_mm_cmplt_epi8(key_vector, _mm_set1_epi8('a')),\n                                             _mm_cmpgt_epi8(key_vector, _mm_set1_epi8('z')));\n        __m128i uppercase_key = _mm_or_si128(_mm_cmplt_epi8(key_vector, _mm_set1_epi8('A')),\n                                             _mm_cmpgt_epi8(key_vector, _mm_set1_epi8('Z')));\n\n        all_lowercase = _mm_or_si128(all_lowercase, lowercase_key);\n        all_uppercase = _mm_or_si128(all_uppercase, uppercase_key);\n    }\n\n    __m128i lowercase_result = _mm_testz_si128(all_lowercase, all_lowercase);\n    __m128i uppercase_result = _mm_testz_si128(all_uppercase, all_uppercase);\n\n    return _mm_movemask_epi8(_mm_or_si128(lowercase_result, uppercase_result)) == 0xFFFF;\n}\n```"}
{"task_id": "SimdBench_108_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> count_up_to_simd(int n){\n    std::vector<int> primes;\n    if(n < 2) return primes;\n\n    primes.push_back(2);\n    if(n < 3) return primes;\n\n    primes.push_back(3);\n    if(n < 4) return primes;\n\n    __m128i primes_vec = _mm_set_epi32(0, 0, 0, 3);\n    __m128i increment = _mm_set_epi32(4, 4, 4, 4);\n\n    for(int i = 5; i < n; i += 4){\n        __m128i current = _mm_set_epi32(i, i-1, i-2, i-3);\n        __m128i is_prime = _mm_set1_epi32(1);\n\n        for(int j = 2; j*j <= i; j++){\n            __m128i divisor = _mm_set1_epi32(j);\n            __m128i mod = _mm_set_epi32(i%j, i%(j+1), i%(j+2), i%(j+3));\n            __m128i cmp = _mm_cmpeq_epi32(mod, _mm_setzero_si128());\n            __m128i cmp2 = _mm_cmpeq_epi32(divisor, mod);\n            is_prime = _mm_andnot_si128(cmp, is_prime);\n            is_prime = _mm_andnot_si128(cmp2, is_prime);\n        }\n\n        int mask = _mm_movemask_epi8(is_prime);\n        if(mask == 0b1111){\n            primes_vec = _mm_add_epi32(primes_vec, increment);\n        }\n    }\n\n    int result[4];\n    _mm_storeu_si128((__m128i*)result, primes_vec);\n    for(int i = 0; i < 4; i++){\n        if(result[i] < n){\n            primes.push_back(result[i]);\n        }\n    }\n\n    return primes;\n}\n```"}
{"task_id": "SimdBench_108_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> count_up_to_simd(int n){\n    std::vector<int> primes;\n    if (n < 2) return primes;\n\n    primes.push_back(2);\n    if (n < 3) return primes;\n\n    primes.push_back(3);\n    if (n < 4) return primes;\n\n    __m128i mask = _mm_set_epi32(0, 0, 0, 0xFFFFFFFF);\n    __m128i increment = _mm_set_epi32(4, 4, 4, 4);\n    __m128i current = _mm_set_epi32(5, 5, 5, 5);\n\n    while (true) {\n        __m128i sqrt_current = _mm_cvtps_epi32(_mm_sqrt_ps(_mm_cvtepi32_ps(current)));\n        __m128i cmp = _mm_cmplt_epi32(sqrt_current, current);\n        if (_mm_movemask_epi8(cmp) == 0xFFFF) {\n            break;\n        }\n\n        __m128i div = _mm_set_epi32(3, 5, 7, 11);\n        __m128i is_prime = _mm_cmplt_epi32(_mm_set1_epi32(0), _mm_cmpeq_epi32(_mm_set1_epi32(0), _mm_and_si128(_mm_set1_epi32(0), _mm_srli_epi32(_mm_set1_epi32(0), 31))));\n        for (int i = 0; i < 4; i++) {\n            __m128i rem = _mm_set1_epi32(1);\n            for (int j = 2; j < 4; j++) {\n                __m128i div_rem = _mm_set1_epi32(0);\n                div_rem = _mm_sub_epi32(current, _mm_mullo_epi32(div, _mm_srli_epi32(current, 1)));\n                rem = _mm_and_si128(rem, _mm_cmpeq_epi32(_mm_set1_epi32(0), div_rem));\n                div = _mm_add_epi32(div, _mm_set1_epi32(2));\n            }\n            is_prime = _mm_and_si128(is_prime, rem);\n            div = _mm_add_epi32(div, _mm_set1_epi32(4));\n        }\n\n        __m128i result = _mm_and_si128(is_prime, mask);\n        int result_array[4];\n        _mm_storeu_si128((__m128i*)result_array, result);\n        for (int i = 0; i < 4; i++) {\n            if (result_array[i] != 0) {\n                primes.push_back(result_array[i]);\n            }\n        }\n\n        current = _mm_add_epi32(current, increment);\n    }\n\n    return primes;\n}\n```"}
{"task_id": "SimdBench_108_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> count_up_to_simd(int n){\n    std::vector<int> primes;\n    if (n < 2) {\n        return primes;\n    }\n\n    primes.push_back(2);\n    if (n < 3) {\n        return primes;\n    }\n\n    primes.push_back(3);\n    if (n < 5) {\n        return primes;\n    }\n\n    __m128i primes_vec = _mm_set_epi32(0, 0, 0, 3);\n    __m128i increment = _mm_set_epi32(4, 4, 4, 4);\n\n    for (int i = 5; i < n; i += 2) {\n        __m128i check = _mm_cmplt_epi32(primes_vec, _mm_set1_epi32(i));\n        int mask = _mm_movemask_ps(_mm_castsi128_ps(check));\n        if (mask == 15) {\n            primes.push_back(i);\n            primes_vec = _mm_add_epi32(primes_vec, increment);\n        }\n    }\n\n    return primes;\n}\n```"}
{"task_id": "SimdBench_108_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> count_up_to_simd(int n){\n    std::vector<int> primes;\n    if (n < 2) {\n        return primes;\n    }\n\n    primes.push_back(2);\n    if (n < 3) {\n        return primes;\n    }\n\n    primes.push_back(3);\n    if (n < 4) {\n        return primes;\n    }\n\n    __m128i primes_vec = _mm_setr_epi32(2, 3, 5, 7);\n    __m128i increment = _mm_set1_epi32(30);\n    __m128i mask = _mm_set1_epi32(0x80808080);\n\n    for (int i = 11; i < n; i += 30) {\n        __m128i check = _mm_cmplt_epi32(primes_vec, _mm_set1_epi32(n));\n        if (_mm_test_all_zeros(check, mask)) {\n            break;\n        }\n\n        primes_vec = _mm_add_epi32(primes_vec, increment);\n        primes_vec = _mm_or_si128(primes_vec, _mm_set1_epi32(1));\n        primes_vec = _mm_and_si128(primes_vec, _mm_set1_epi32(0xFFFFFFFE));\n\n        for (int j = 0; j < 4; ++j) {\n            int prime;\n            _mm_store_si128((__m128i*)&prime, primes_vec);\n            if (prime < n) {\n                primes.push_back(prime);\n            }\n            primes_vec = _mm_add_epi32(primes_vec, _mm_set1_epi32(2));\n        }\n    }\n\n    return primes;\n}\n```"}
{"task_id": "SimdBench_108_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> count_up_to_simd(int n){\n    std::vector<int> primes;\n    if (n < 2) {\n        return primes;\n    }\n\n    primes.push_back(2);\n    if (n < 3) {\n        return primes;\n    }\n\n    primes.push_back(3);\n    if (n < 4) {\n        return primes;\n    }\n\n    __m128i primes_vec = _mm_set_epi32(7, 5, 3, 2);\n    __m128i increment = _mm_set1_epi32(4);\n    __m128i one = _mm_set1_epi32(1);\n    __m128i mask = _mm_set1_epi32(0xFFFFFFFF);\n\n    for (int i = 5; i < n; i += 2) {\n        __m128i divisors = _mm_set1_epi32(i);\n        __m128i sqrt_i = _mm_cvtps_epi32(_mm_sqrt_ps(_mm_cvtepi32_ps(divisors)));\n        __m128i is_prime = _mm_set1_epi32(1);\n\n        for (int j = 0; j < primes.size(); ++j) {\n            __m128i prime = _mm_set1_epi32(primes[j]);\n            __m128i cmp = _mm_cmplt_epi32(_mm_mullo_epi32(prime, prime), divisors);\n            is_prime = _mm_and_si128(is_prime, cmp);\n        }\n\n        __m128i cmp = _mm_cmpeq_epi32(is_prime, mask);\n        if (_mm_movemask_epi8(cmp) == 0xFFFF) {\n            primes.push_back(i);\n            primes_vec = _mm_add_epi32(primes_vec, increment);\n        }\n    }\n\n    return primes;\n}\n```"}
{"task_id": "SimdBench_109_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nint count_upper_simd(const std::string & s){\n    int count = 0;\n    __m128i vowels = _mm_setr_epi8('A', 'E', 'I', 'O', 'U', 0, 0, 0, 'A', 'E', 'I', 'O', 'U', 0, 0, 0);\n    \n    for (int i = 0; i < s.size(); i += 16) {\n        __m128i str = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&s[i]));\n        __m128i upper = _mm_cmpeq_epi8(_mm_and_si128(str, _mm_set1_epi8(0x20)), _mm_set1_epi8(0x20));\n        __m128i is_vowel = _mm_shuffle_epi8(vowels, str);\n        __m128i result = _mm_and_si128(upper, is_vowel);\n        count += _mm_popcnt_u32(_mm_movemask_epi8(result));\n    }\n    \n    return count;\n}\n```"}
{"task_id": "SimdBench_109_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint count_upper_simd(const std::string & s){\n    int count = 0;\n    __m128i vowels = _mm_set_epi8('A', 'E', 'I', 'O', 'U', 'a', 'e', 'i', 'o', 'u', 0, 0, 0, 0, 0, 0);\n    \n    for (int i = 0; i < s.size(); i += 16) {\n        __m128i str = _mm_loadu_si128((__m128i*)(s.c_str() + i));\n        __m128i upper = _mm_and_si128(_mm_cmpeq_epi8(_mm_and_si128(str, _mm_set1_epi8(0x20)), _mm_set1_epi8(0)), _mm_cmpistrm(vowels, str, 0x28));\n        count += _mm_popcnt_u32(_mm_movemask_epi8(upper));\n    }\n    \n    return count;\n}\n```"}
{"task_id": "SimdBench_109_SSE", "completion": "```\nint count_upper_simd(const std::string & s){\n    int count = 0;\n    __m128i vowels = _mm_setr_epi8('A', 'E', 'I', 'O', 'U', 0, 0, 0, 'A', 'E', 'I', 'O', 'U', 0, 0, 0);\n    int length = s.length();\n    \n    for (int i = 0; i < length; i += 16) {\n        __m128i str = _mm_loadu_si128((__m128i*)(s.c_str() + i));\n        __m128i cmp1 = _mm_cmpeq_epi8(str, vowels);\n        __m128i cmp2 = _mm_cmpeq_epi8(str, _mm_sub_epi8(vowels, _mm_set1_epi8('A' - 'a')));\n        __m128i cmp = _mm_or_si128(cmp1, cmp2);\n        __m128i mask = _mm_setr_epi8(0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1);\n        __m128i result = _mm_and_si128(cmp, mask);\n        count += _mm_popcnt_u32(_mm_movemask_epi8(result));\n    }\n    \n    return count;\n}\n```"}
{"task_id": "SimdBench_109_SSE", "completion": "```\nint count_upper_simd(const std::string & s){\n    int count = 0;\n    __m128i vowels = _mm_set_epi8('U', 'O', 'I', 'E', 'A', 'U', 'O', 'I', 'E', 'A', 'U', 'O', 'I', 'E', 'A', 'U');\n    for (int i = 0; i < s.size(); i += 16) {\n        __m128i str = _mm_loadu_si128((__m128i*)(s.c_str() + i));\n        __m128i cmp = _mm_cmpeq_epi8(vowels, _mm_and_si128(str, _mm_set1_epi8(0xDF))); // 0xDF to convert lowercase to uppercase\n        count += _mm_popcnt_u32(_mm_movemask_epi8(cmp));\n    }\n    return count;\n}\n```"}
{"task_id": "SimdBench_109_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint count_upper_simd(const std::string & s){\n    int count = 0;\n    __m128i vowels = _mm_setr_epi8('A', 'E', 'I', 'O', 'U', 0, 0, 0, 'A', 'E', 'I', 'O', 'U', 0, 0, 0);\n    int len = s.length();\n    for (int i = 0; i < len; i += 16) {\n        __m128i str = _mm_loadu_si128((__m128i*)(s.c_str() + i));\n        __m128i upper = _mm_and_si128(_mm_cmplt_epi8(_mm_set1_epi8('A'), str), _mm_cmplt_epi8(str, _mm_set1_epi8('Z')));\n        __m128i even_indices = _mm_set_epi8(0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1);\n        __m128i vowels_mask = _mm_shuffle_epi8(vowels, _mm_and_si128(upper, even_indices));\n        count += _mm_popcnt_u32(_mm_movemask_epi8(vowels_mask));\n    }\n    return count;\n}\n```"}
{"task_id": "SimdBench_110_SSE", "completion": "```cpp\nstd::vector<int> make_a_pile_simd(int n){\n    std::vector<int> result(n);\n    __m128i stones = _mm_set1_epi32(n);\n    for (int i = 0; i < n; ++i) {\n        result[i] = n + 2 * i;\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_110_SSE", "completion": "```cpp\nstd::vector<int> make_a_pile_simd(int n){\n    std::vector<int> result(n);\n    __m128i stones = _mm_set1_epi32(n);\n    for (int i = 0; i < n; ++i) {\n        result[i] = n + 2 * i;\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_110_SSE", "completion": "```cpp\nstd::vector<int> make_a_pile_simd(int n){\n    std::vector<int> result(n);\n    __m128i stones = _mm_set1_epi32(n);\n    for(int i = 0; i < n; ++i){\n        result[i] = n + 2*i;\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_110_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> make_a_pile_simd(int n){\n    std::vector<int> result(n);\n    __m128i stones = _mm_set1_epi32(n);\n    for (int i = 0; i < n; i += 4) {\n        _mm_storeu_si128((__m128i*)&result[i], stones);\n        stones = _mm_add_epi32(stones, _mm_setr_epi32(1, 2, 3, 4));\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_110_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> make_a_pile_simd(int n){\n    std::vector<int> result(n);\n    __m128i stones = _mm_set1_epi32(n);\n    for(int i = 0; i < n; ++i){\n        result[i] = _mm_cvtsi128_si32(stones);\n        stones = _mm_add_epi32(stones, _mm_set1_epi32(n % 2 == 0 ? 2 : 1));\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_111_SSE", "completion": "```\nstd::string rounded_avg_simd(int64_t n, int64_t m){\n    if(n > m){\n        return \"-1\";\n    }\n    \n    __m128i sum = _mm_setzero_si128();\n    int count = 0;\n    \n    for(int i = n; i <= m; i += 4){\n        __m128i values = _mm_set_epi32(i+3, i+2, i+1, i);\n        sum = _mm_add_epi32(sum, values);\n        count += 4;\n    }\n    \n    __m128i avg = _mm_srli_epi32(sum, 2);\n    \n    int result[4];\n    _mm_storeu_si128((__m128i*)result, avg);\n    \n    int rounded_avg = (result[0] + result[1] + result[2] + result[3] + count/2) / count;\n    \n    std::string binary = std::bitset<32>(rounded_avg).to_string();\n    return binary.substr(binary.find('1'));\n}\n```"}
{"task_id": "SimdBench_111_SSE", "completion": "```\nstd::string rounded_avg_simd(int64_t n, int64_t m){\n    if (n > m) {\n        return \"-1\";\n    }\n\n    __m128i sum = _mm_setzero_si128();\n    int count = 0;\n    for (int i = n; i <= m; i++) {\n        sum = _mm_add_epi32(sum, _mm_set1_epi32(i));\n        count++;\n    }\n\n    __m128i avg = _mm_cvtps_epi32(_mm_div_ps(_mm_cvtepi32_ps(sum), _mm_set1_ps(count)));\n    int avg_int = _mm_cvtsi128_si32(avg);\n\n    std::string binary_avg = \"\";\n    while (avg_int > 0) {\n        binary_avg = std::to_string(avg_int % 2) + binary_avg;\n        avg_int /= 2;\n    }\n\n    return binary_avg;\n}\n```"}
{"task_id": "SimdBench_111_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <bitset>\n#include <string>\n\nstd::string rounded_avg_simd(int64_t n, int64_t m){\n    if (n > m) {\n        return \"-1\";\n    }\n\n    __m128i sum = _mm_setzero_si128();\n    int64_t count = m - n + 1;\n\n    for (int64_t i = n; i <= m; i += 4) {\n        __m128i values = _mm_set_epi64x(i + 3, i + 2);\n        values = _mm_unpacklo_epi32(values, _mm_set_epi64x(i + 1, i));\n        sum = _mm_add_epi64(sum, values);\n    }\n\n    __m128i avg = _mm_srli_epi64(_mm_add_epi64(sum, _mm_set1_epi64x(count / 2)), 6);\n    int64_t result = _mm_cvtsi128_si64(avg);\n\n    return std::bitset<64>(result).to_string().substr(64 - count, count);\n}\n```"}
{"task_id": "SimdBench_111_SSE", "completion": "```\nstd::string rounded_avg_simd(int64_t n, int64_t m){\n    if (n > m) {\n        return \"-1\";\n    }\n    \n    __m128i sum = _mm_setzero_si128();\n    int count = 0;\n    \n    for (int i = n; i <= m; i += 4) {\n        __m128i values = _mm_set_epi64x(i + 3, i + 2);\n        sum = _mm_add_epi64(sum, values);\n        count += 4;\n    }\n    \n    __m128i avg = _mm_srli_epi64(sum, 2);\n    \n    int avg_int[2];\n    _mm_storeu_si128((__m128i*)avg_int, avg);\n    \n    int rounded_avg = (avg_int[1] >= 2) ? avg_int[0] + 1 : avg_int[0];\n    \n    std::string binary_avg = std::bitset<64>(rounded_avg).to_string();\n    return binary_avg.substr(binary_avg.find('1'));\n}\n```"}
{"task_id": "SimdBench_111_SSE", "completion": "```\nstd::string rounded_avg_simd(int64_t n, int64_t m){\n    if (n > m) {\n        return \"-1\";\n    }\n\n    __m128i sum = _mm_setzero_si128();\n    int count = 0;\n\n    for (int i = n; i <= m; i += 4) {\n        __m128i values = _mm_set_epi64x(i + 3, i + 2);\n        sum = _mm_add_epi64(sum, values);\n        count += 4;\n    }\n\n    __m128i avg = _mm_srli_epi64(sum, 2);\n    avg = _mm_add_epi64(avg, _mm_set1_epi64x(count / 2));\n    avg = _mm_srli_epi64(avg, 1);\n\n    int64_t result[2];\n    _mm_storeu_si128((__m128i*)result, avg);\n\n    std::string binaryResult = \"\";\n    for (int i = 1; i >= 0; i--) {\n        for (int j = 63; j >= 0; j--) {\n            binaryResult += ((result[i] >> j) & 1) ? \"1\" : \"0\";\n        }\n    }\n\n    return binaryResult;\n}\n```"}
{"task_id": "SimdBench_112_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> func_simd(int n){\n    std::vector<int> result(n);\n    __m128i factorial = _mm_set_epi32(1, 1, 1, 1);\n    __m128i sum = _mm_set_epi32(0, 1, 3, 6);\n    \n    for (int i = 1; i <= n; i += 4) {\n        __m128i indices = _mm_set_epi32(i+3, i+2, i+1, i);\n        \n        // Calculate factorials\n        factorial = _mm_mullo_epi32(factorial, indices);\n        \n        // Calculate sums\n        sum = _mm_add_epi32(sum, indices);\n        \n        // Store results\n        _mm_storeu_si128((__m128i*)&result[i-1], _mm_blendv_epi8(sum, factorial, _mm_cmplt_epi32(indices, _mm_set1_epi32(10000))));\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_112_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> func_simd(int n){\n    std::vector<int> result(n);\n    __m128i factorial = _mm_set_epi32(1, 1, 1, 1);\n    __m128i sum = _mm_set_epi32(0, 0, 0, 0);\n\n    for (int i = 1; i <= n; i += 4) {\n        __m128i indices = _mm_set_epi32(i+3, i+2, i+1, i);\n        __m128i factorial_mask = _mm_cmplt_epi32(_mm_set_epi32(0, 1, 0, 1), indices);\n\n        for (int j = 1; j <= 4; j++) {\n            __m128i current = _mm_set1_epi32(i + j);\n            factorial = _mm_mullo_epi32(factorial, _mm_and_si128(factorial_mask, current));\n            sum = _mm_add_epi32(sum, _mm_andnot_si128(factorial_mask, current));\n        }\n\n        __m128i factorial_mod = _mm_and_si128(factorial, _mm_set1_epi32(10000));\n        __m128i sum_result = _mm_set_epi32(0, 0, 0, 0);\n        __m128i factorial_result = _mm_set_epi32(0, 0, 0, 0);\n\n        for (int j = 0; j < 4; j++) {\n            int mask = _mm_extract_epi32(factorial_mask, j);\n            int sum_val = _mm_extract_epi32(sum, j);\n            int factorial_val = _mm_extract_epi32(factorial_mod, j);\n\n            sum_result = _mm_insert_epi32(sum_result, mask ? sum_val : factorial_val, j);\n            factorial_result = _mm_insert_epi32(factorial_result, mask ? factorial_val : sum_val, j);\n        }\n\n        _mm_storeu_si128((__m128i*)&result[i-1], sum_result);\n        _mm_storeu_si128((__m128i*)&result[i+3-1], factorial_result);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_112_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> func_simd(int n){\n    std::vector<int> result(n);\n    __m128i factorial = _mm_set_epi32(1, 1, 1, 1);\n    __m128i sum = _mm_set_epi32(0, 1, 3, 6);\n    \n    for (int i = 1; i <= n; i += 4) {\n        __m128i indices = _mm_set_epi32(i+3, i+2, i+1, i);\n        __m128i isEven = _mm_and_si128(indices, _mm_set1_epi32(1));\n        \n        __m128i factMask = _mm_cmpeq_epi32(isEven, _mm_setzero_si128());\n        __m128i sumMask = _mm_cmpeq_epi32(isEven, _mm_set1_epi32(1));\n        \n        __m128i factResult = _mm_mullo_epi32(factorial, indices);\n        factorial = _mm_and_si128(factResult, factMask);\n        \n        __m128i sumResult = _mm_add_epi32(sum, indices);\n        sum = _mm_and_si128(sumResult, sumMask);\n        \n        _mm_storeu_si128((__m128i*)&result[i-1], _mm_or_si128(factorial, sum));\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_112_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> func_simd(int n) {\n    std::vector<int> result(n);\n    __m128i factorial = _mm_set_epi32(1, 1, 2, 6);\n    __m128i sum = _mm_set_epi32(1, 1, 2, 6);\n\n    for (int i = 4; i < n; i += 4) {\n        factorial = _mm_mullo_epi32(factorial, _mm_set_epi32(i, i-1, i-2, i-3));\n        __m128i sum_increment = _mm_set_epi32(i, i-1, i-2, i-3);\n        sum = _mm_add_epi32(sum, sum_increment);\n\n        _mm_storeu_si128((__m128i*)&result[i-4], _mm_and_si128(factorial, _mm_set1_epi32(10000)));\n        _mm_storeu_si128((__m128i*)&result[i-4+1], sum);\n    }\n\n    for (int i = n - (n % 4); i < n; ++i) {\n        if (i % 2 == 0) {\n            int fact = 1;\n            for (int j = 1; j <= i; ++j) {\n                fact = (fact * j) % 10000;\n            }\n            result[i] = fact;\n        } else {\n            int s = 0;\n            for (int j = 1; j <= i; ++j) {\n                s += j;\n            }\n            result[i] = s;\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_112_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> func_simd(int n){\n    std::vector<int> result(n);\n    __m128i factorial = _mm_set_epi32(1, 1, 1, 1);\n    __m128i sum = _mm_set_epi32(0, 0, 0, 0);\n    \n    for (int i = 1; i <= n; i += 4) {\n        __m128i indices = _mm_set_epi32(i+3, i+2, i+1, i);\n        \n        // Calculate factorials\n        factorial = _mm_mullo_epi32(factorial, indices);\n        \n        // Calculate sums\n        __m128i partial_sum = _mm_set_epi32(i, i+1, i+2, i+3);\n        sum = _mm_add_epi32(sum, partial_sum);\n        \n        // Store results\n        __m128i even_mask = _mm_set_epi32(0, 0, 0, 0xFFFF);\n        __m128i odd_mask = _mm_set_epi32(0xFFFF, 0xFFFF, 0xFFFF, 0xFFFF);\n        \n        __m128i even_result = _mm_and_si128(factorial, even_mask);\n        __m128i odd_result = _mm_andnot_si128(even_mask, sum);\n        \n        _mm_storeu_si128((__m128i*)&result[i-1], _mm_or_si128(even_result, odd_result));\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_113_SSE", "completion": "```cpp\nstd::vector<int> even_odd_palindrome_simd(int n){\n    __m128i even_count = _mm_setzero_si128();\n    __m128i odd_count = _mm_setzero_si128();\n\n    for (int i = 1; i <= n; ++i) {\n        int rev = 0;\n        int temp = i;\n        while (temp != 0) {\n            rev = rev * 10 + temp % 10;\n            temp /= 10;\n        }\n        if (rev == i) {\n            if (i % 2 == 0) {\n                even_count = _mm_add_epi32(even_count, _mm_set1_epi32(1));\n            } else {\n                odd_count = _mm_add_epi32(odd_count, _mm_set1_epi32(1));\n            }\n        }\n    }\n\n    std::vector<int> result(2);\n    _mm_storeu_si128((__m128i*)&result[0], even_count);\n    _mm_storeu_si128((__m128i*)&result[1], odd_count);\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_113_SSE", "completion": "```cpp\nstd::vector<int> even_odd_palindrome_simd(int n){\n    __m128i even_count = _mm_setzero_si128();\n    __m128i odd_count = _mm_setzero_si128();\n\n    for (int i = 1; i <= n; ++i) {\n        int rev = 0, temp = i;\n        while (temp > 0) {\n            rev = rev * 10 + temp % 10;\n            temp /= 10;\n        }\n        if (rev == i) {\n            if (i % 2 == 0) {\n                even_count = _mm_add_epi32(even_count, _mm_set1_epi32(1));\n            } else {\n                odd_count = _mm_add_epi32(odd_count, _mm_set1_epi32(1));\n            }\n        }\n    }\n\n    std::vector<int> result(2);\n    _mm_storeu_si128((__m128i*)&result[0], even_count);\n    _mm_storeu_si128((__m128i*)&result[1], odd_count);\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_113_SSE", "completion": "```cpp\nstd::vector<int> even_odd_palindrome_simd(int n){\n    __m128i even_count = _mm_setzero_si128();\n    __m128i odd_count = _mm_setzero_si128();\n\n    for (int i = 1; i <= n; ++i) {\n        int rev = 0, temp = i;\n        while (temp > 0) {\n            rev = rev * 10 + temp % 10;\n            temp /= 10;\n        }\n        if (rev == i) {\n            if (i % 2 == 0) {\n                even_count = _mm_add_epi32(even_count, _mm_set1_epi32(1));\n            } else {\n                odd_count = _mm_add_epi32(odd_count, _mm_set1_epi32(1));\n            }\n        }\n    }\n\n    int even_result[4], odd_result[4];\n    _mm_storeu_si128((__m128i*)even_result, even_count);\n    _mm_storeu_si128((__m128i*)odd_result, odd_count);\n\n    return {even_result[0] + even_result[1] + even_result[2] + even_result[3],\n            odd_result[0] + odd_result[1] + odd_result[2] + odd_result[3]};\n}\n```"}
{"task_id": "SimdBench_113_SSE", "completion": "```cpp\nstd::vector<int> even_odd_palindrome_simd(int n){\n    __m128i even_count = _mm_setzero_si128();\n    __m128i odd_count = _mm_setzero_si128();\n\n    for (int i = 1; i <= n; ++i) {\n        int rev = 0, temp = i;\n        while (temp > 0) {\n            rev = rev * 10 + temp % 10;\n            temp /= 10;\n        }\n        if (rev == i) {\n            if (i % 2 == 0) {\n                even_count = _mm_add_epi32(even_count, _mm_set1_epi32(1));\n            } else {\n                odd_count = _mm_add_epi32(odd_count, _mm_set1_epi32(1));\n            }\n        }\n    }\n\n    std::vector<int> result(2);\n    _mm_storeu_si128((__m128i*)&result[0], even_count);\n    _mm_storeu_si128((__m128i*)&result[1], odd_count);\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_113_SSE", "completion": "```cpp\nstd::vector<int> even_odd_palindrome_simd(int n){\n    __m128i even_count = _mm_setzero_si128();\n    __m128i odd_count = _mm_setzero_si128();\n\n    for (int i = 1; i <= n; ++i) {\n        int rev = 0, temp = i;\n        while (temp > 0) {\n            rev = rev * 10 + temp % 10;\n            temp /= 10;\n        }\n        if (rev == i) {\n            if (i % 2 == 0) {\n                even_count = _mm_add_epi32(even_count, _mm_set1_epi32(1));\n            } else {\n                odd_count = _mm_add_epi32(odd_count, _mm_set1_epi32(1));\n            }\n        }\n    }\n\n    int even_result[4], odd_result[4];\n    _mm_storeu_si128((__m128i*)even_result, even_count);\n    _mm_storeu_si128((__m128i*)odd_result, odd_count);\n\n    return {even_result[0] + even_result[1] + even_result[2] + even_result[3], \n            odd_result[0] + odd_result[1] + odd_result[2] + odd_result[3]};\n}\n```  "}
{"task_id": "SimdBench_114_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint count_nums_simd(std::vector<int> n){\n    int count = 0;\n    __m128i zero = _mm_setzero_si128();\n    \n    for (size_t i = 0; i < n.size(); i += 4) {\n        __m128i nums = _mm_loadu_si128((__m128i*)&n[i]);\n        \n        __m128i abs_nums = _mm_abs_epi32(nums);\n        \n        __m128i digit_sums = _mm_setzero_si128();\n        for (int j = 0; j < 4; j++) {\n            __m128i num = _mm_shuffle_epi32(abs_nums, _MM_SHUFFLE(j, j, j, j));\n            __m128i digits = _mm_set_epi32(0, 0, 0, 1);\n            __m128i digit_sum = _mm_setzero_si128();\n            \n            for (int k = 0; k < 10; k++) {\n                __m128i digit = _mm_set1_epi32(k);\n                __m128i cmp = _mm_cmplt_epi32(digit, num);\n                __m128i mul = _mm_mullo_epi32(cmp, digit);\n                digit_sum = _mm_add_epi32(digit_sum, mul);\n            }\n            \n            digit_sums = _mm_add_epi32(digit_sums, digit_sum);\n        }\n        \n        __m128i sum_gt_zero = _mm_cmpgt_epi32(digit_sums, zero);\n        count += _mm_popcnt_u32(_mm_movemask_epi8(sum_gt_zero));\n    }\n    \n    return count;\n}\n```"}
{"task_id": "SimdBench_114_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint count_nums_simd(std::vector<int> n){\n    int count = 0;\n    __m128i zero = _mm_setzero_si128();\n    __m128i sum_digits = _mm_setzero_si128();\n\n    for (size_t i = 0; i < n.size(); i += 4) {\n        __m128i nums = _mm_loadu_si128((__m128i*)&n[i]);\n\n        __m128i abs_nums = _mm_abs_epi32(nums);\n\n        __m128i units = _mm_set1_epi32(1);\n        __m128i tens = _mm_set1_epi32(10);\n\n        __m128i units_digits = _mm_and_si128(abs_nums, units);\n        __m128i tens_digits = _mm_and_si128(_mm_div_epi32(abs_nums, tens), units);\n        __m128i hundreds_digits = _mm_and_si128(_mm_div_epi32(abs_nums, _mm_mullo_epi32(tens, tens)), units);\n\n        __m128i digits_sum = _mm_add_epi32(_mm_add_epi32(units_digits, tens_digits), hundreds_digits);\n\n        sum_digits = _mm_add_epi32(sum_digits, digits_sum);\n    }\n\n    int sum_array[4];\n    _mm_storeu_si128((__m128i*)sum_array, sum_digits);\n\n    for (int i = 0; i < 4; i++) {\n        if (sum_array[i] > 0) {\n            count++;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_114_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint count_nums_simd(std::vector<int> n){\n    int count = 0;\n    __m128i zero = _mm_setzero_si128();\n    __m128i sum_digits = _mm_setzero_si128();\n    \n    for (size_t i = 0; i < n.size(); i += 4) {\n        __m128i nums = _mm_loadu_si128((__m128i*)&n[i]);\n        \n        __m128i abs_nums = _mm_abs_epi32(nums);\n        \n        __m128i units = _mm_set1_epi32(1);\n        __m128i tens = _mm_set1_epi32(10);\n        \n        __m128i units_digits = _mm_and_si128(abs_nums, units);\n        __m128i tens_digits = _mm_and_si128(_mm_div_epi32(abs_nums, tens), units);\n        __m128i hundreds_digits = _mm_and_si128(_mm_div_epi32(abs_nums, _mm_mullo_epi32(tens, tens)), units);\n        \n        __m128i sum_digits_mask = _mm_or_si128(_mm_or_si128(units_digits, tens_digits), hundreds_digits);\n        \n        sum_digits = _mm_add_epi32(sum_digits, sum_digits_mask);\n    }\n    \n    int sum_digits_array[4];\n    _mm_storeu_si128((__m128i*)sum_digits_array, sum_digits);\n    \n    for (int i = 0; i < 4; i++) {\n        if (sum_digits_array[i] > 0) {\n            count++;\n        }\n    }\n    \n    return count;\n}\n```"}
{"task_id": "SimdBench_114_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint count_nums_simd(std::vector<int> n){\n    int count = 0;\n    __m128i zero = _mm_setzero_si128();\n    \n    for (size_t i = 0; i < n.size(); i += 4) {\n        __m128i nums = _mm_loadu_si128((__m128i*)&n[i]);\n        \n        // Extract individual digits\n        __m128i abs_nums = _mm_abs_epi32(nums);\n        __m128i digits = _mm_set_epi32(1000000000, 100000000, 10000000, 1000000);\n        __m128i divisors = _mm_set_epi32(100000000, 10000000, 1000000, 100000);\n        __m128i sum_digits = _mm_setzero_si128();\n        \n        for (int j = 0; j < 4; j++) {\n            __m128i digit = _mm_div_epi32(_mm_and_si128(abs_nums, digits), divisors);\n            sum_digits = _mm_add_epi32(sum_digits, digit);\n            digits = _mm_srli_epi32(digits, 1);\n            divisors = _mm_srli_epi32(divisors, 1);\n        }\n        \n        // Check if sum of digits > 0\n        __m128i cmp = _mm_cmpgt_epi32(sum_digits, zero);\n        int mask = _mm_movemask_epi8(cmp);\n        \n        // Update count\n        count += _mm_popcnt_u32(mask);\n    }\n    \n    return count;\n}\n```"}
{"task_id": "SimdBench_114_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint count_nums_simd(std::vector<int> n){\n    int count = 0;\n    __m128i zero = _mm_setzero_si128();\n    __m128i sum_digits = _mm_setzero_si128();\n    \n    for (size_t i = 0; i < n.size(); i += 4) {\n        __m128i nums = _mm_loadu_si128((__m128i*)&n[i]);\n        \n        // Calculate sum of digits for each number\n        __m128i abs_nums = _mm_abs_epi32(nums);\n        __m128i digits = _mm_set1_epi32(0);\n        for (int j = 0; j < 4; j++) {\n            __m128i num = _mm_shuffle_epi32(abs_nums, _MM_SHUFFLE(j, j, j, j));\n            __m128i digit_sum = _mm_setzero_si128();\n            for (int k = 0; k < 10; k++) {\n                __m128i cmp = _mm_cmpeq_epi32(num, _mm_set1_epi32(k));\n                digit_sum = _mm_add_epi32(digit_sum, cmp);\n            }\n            digits = _mm_add_epi32(digits, digit_sum);\n        }\n        \n        // Check if sum of digits > 0\n        __m128i mask = _mm_cmpgt_epi32(digits, zero);\n        sum_digits = _mm_add_epi32(sum_digits, mask);\n    }\n    \n    int sum[4];\n    _mm_storeu_si128((__m128i*)sum, sum_digits);\n    count = sum[0] + sum[1] + sum[2] + sum[3];\n    \n    return count;\n}\n```"}
{"task_id": "SimdBench_115_SSE", "completion": "```\nbool move_one_ball_simd(std::vector<int> arr){\n    if(arr.empty()){\n        return true;\n    }\n    \n    int N = arr.size();\n    __m128i vec = _mm_loadu_si128((__m128i*)&arr[0]);\n    \n    for(int i=0; i<N-1; i++){\n        __m128i next_vec = _mm_srli_si128(vec, 4);\n        __m128i cmp = _mm_cmpgt_epi32(vec, next_vec);\n        int mask = _mm_movemask_epi8(cmp);\n        if(mask != 0){\n            return false;\n        }\n        vec = next_vec;\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_115_SSE", "completion": "```\nbool move_one_ball_simd(std::vector<int> arr){\n    if(arr.empty()){\n        return true;\n    }\n    \n    int N = arr.size();\n    __m128i vec = _mm_loadu_si128((__m128i*)&arr[0]);\n    \n    for(int i=0; i<N-1; i++){\n        __m128i next_vec = _mm_srli_si128(vec, 4);\n        __m128i cmp = _mm_cmpgt_epi32(vec, next_vec);\n        int mask = _mm_movemask_epi8(cmp);\n        if(mask != 0){\n            return false;\n        }\n        vec = next_vec;\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_115_SSE", "completion": "```\nbool move_one_ball_simd(std::vector<int> arr){\n    if(arr.empty()){\n        return true;\n    }\n    \n    int N = arr.size();\n    __m128i vec = _mm_loadu_si128((__m128i*)&arr[0]);\n    \n    for(int i=0; i<N-1; i++){\n        __m128i next_vec = _mm_srli_si128(vec, 4);\n        __m128i cmp = _mm_cmpgt_epi32(vec, next_vec);\n        if(_mm_movemask_epi8(cmp)){\n            return false;\n        }\n        vec = next_vec;\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_115_SSE", "completion": "```\nbool move_one_ball_simd(std::vector<int> arr){\n    if(arr.empty()){\n        return true;\n    }\n    \n    int N = arr.size();\n    __m128i vec = _mm_loadu_si128((__m128i*)&arr[0]);\n    \n    for(int i=0; i<N-1; i++){\n        __m128i next_vec = _mm_srli_si128(vec, 4);\n        __m128i cmp_result = _mm_cmpgt_epi32(vec, next_vec);\n        int mask = _mm_movemask_epi8(cmp_result);\n        \n        if(mask != 0){\n            return false;\n        }\n        \n        vec = next_vec;\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_115_SSE", "completion": "```\nbool move_one_ball_simd(std::vector<int> arr){\n    if(arr.empty()){\n        return true;\n    }\n    \n    int N = arr.size();\n    __m128i vec = _mm_loadu_si128((__m128i*)&arr[0]);\n    \n    for(int i=0; i<N-1; i++){\n        __m128i next_vec = _mm_srli_si128(vec, 4);\n        __m128i cmp = _mm_cmpgt_epi32(vec, next_vec);\n        int mask = _mm_movemask_epi8(cmp);\n        \n        if(mask != 0){\n            return false;\n        }\n        \n        vec = next_vec;\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_116_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nstd::string myexchange_simd(const std::vector<int>& lst1, const std::vector<int>& lst2){\n    __m128i even_mask = _mm_set1_epi32(1); // Mask to check if a number is even\n    __m128i all_ones = _mm_set1_epi32(0xFFFFFFFF); // Mask of all ones\n\n    int size = lst1.size();\n    int i = 0;\n\n    for (; i < size - 3; i += 4) {\n        __m128i vec1 = _mm_loadu_si128((__m128i*)&lst1[i]);\n        __m128i vec2 = _mm_loadu_si128((__m128i*)&lst2[i]);\n\n        __m128i even1 = _mm_and_si128(vec1, even_mask);\n        __m128i even2 = _mm_and_si128(vec2, even_mask);\n\n        __m128i odd1 = _mm_andnot_si128(even_mask, vec1);\n        __m128i odd2 = _mm_andnot_si128(even_mask, vec2);\n\n        __m128i odd_mask = _mm_or_si128(odd1, odd2);\n\n        if (!_mm_test_all_zeros(odd_mask, all_ones)) {\n            return \"NO\";\n        }\n    }\n\n    for (; i < size; ++i) {\n        if ((lst1[i] % 2) != 0) {\n            return \"NO\";\n        }\n    }\n\n    return \"YES\";\n}\n```"}
{"task_id": "SimdBench_116_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nstd::string myexchange_simd(const std::vector<int>& lst1, const std::vector<int>& lst2){\n    __m128i mask = _mm_set1_epi32(1); // Mask to check if a number is odd\n    __m128i all_ones = _mm_set1_epi32(-1); // Mask with all bits set to 1\n\n    int size = lst1.size();\n    int i = 0;\n\n    for (; i < size - 3; i += 4) {\n        __m128i vec1 = _mm_loadu_si128((__m128i*)&lst1[i]);\n        __m128i vec2 = _mm_loadu_si128((__m128i*)&lst2[i]);\n\n        __m128i odd1 = _mm_and_si128(vec1, mask);\n        __m128i odd2 = _mm_and_si128(vec2, mask);\n\n        __m128i odd_mask = _mm_or_si128(odd1, odd2);\n\n        if (!_mm_test_all_zeros(odd_mask, all_ones)) {\n            return \"NO\";\n        }\n    }\n\n    for (; i < size; ++i) {\n        if ((lst1[i] % 2) != 0) {\n            return \"NO\";\n        }\n    }\n\n    return \"YES\";\n}\n```"}
{"task_id": "SimdBench_116_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n\nstd::string myexchange_simd(const std::vector<int>& lst1, const std::vector<int>& lst2) {\n    __m128i evenMask = _mm_set1_epi32(1); // Mask for checking if a number is even\n    __m128i allOnes = _mm_set1_epi32(0xFFFFFFFF); // Mask with all bits set to 1\n\n    int size = lst1.size();\n    int i = 0;\n    for (; i + 4 <= size; i += 4) {\n        __m128i vec1 = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&lst1[i]));\n        __m128i vec2 = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&lst2[i]));\n\n        __m128i even1 = _mm_and_si128(vec1, evenMask);\n        __m128i even2 = _mm_and_si128(vec2, evenMask);\n\n        __m128i sum = _mm_add_epi32(even1, even2);\n        __m128i cmp = _mm_cmpeq_epi32(sum, allOnes);\n\n        if (_mm_movemask_epi8(cmp) != 0xFFFF) {\n            return \"NO\";\n        }\n    }\n\n    for (; i < size; ++i) {\n        if ((lst1[i] % 2) != 0) {\n            return \"NO\";\n        }\n    }\n\n    return \"YES\";\n}\n```"}
{"task_id": "SimdBench_116_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n\nstd::string myexchange_simd(const std::vector<int>& lst1, const std::vector<int>& lst2){\n    __m128i even_mask = _mm_set1_epi32(0x1); // Mask to check for even numbers\n    __m128i all_ones = _mm_set1_epi32(0xFFFFFFFF); // Mask of all ones\n\n    int size = lst1.size();\n    int i = 0;\n\n    for (; i < size - 3; i += 4) {\n        __m128i vec1 = _mm_loadu_si128((__m128i*)&lst1[i]);\n        __m128i vec2 = _mm_loadu_si128((__m128i*)&lst2[i]);\n\n        __m128i even1 = _mm_and_si128(vec1, even_mask);\n        __m128i even2 = _mm_and_si128(vec2, even_mask);\n\n        __m128i cmp1 = _mm_cmpeq_epi32(even1, even_mask);\n        __m128i cmp2 = _mm_cmpeq_epi32(even2, even_mask);\n\n        __m128i result = _mm_cmpeq_epi32(cmp1, all_ones);\n        result = _mm_and_si128(result, _mm_cmpeq_epi32(cmp2, all_ones));\n\n        if (_mm_movemask_epi8(result) != 0xFFFF) {\n            return \"NO\";\n        }\n    }\n\n    for (; i < size; ++i) {\n        if ((lst1[i] % 2) != 0) {\n            return \"NO\";\n        }\n    }\n\n    return \"YES\";\n}\n```"}
{"task_id": "SimdBench_116_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nstd::string myexchange_simd(const std::vector<int>& lst1, const std::vector<int>& lst2){\n    __m128i mask = _mm_set1_epi32(1); // Mask to check if number is odd\n    __m128i all_ones = _mm_set1_epi32(-1); // Mask of all ones\n\n    int size = lst1.size();\n    int i = 0;\n\n    for (; i < size - 3; i += 4) {\n        __m128i vec1 = _mm_loadu_si128((__m128i*)&lst1[i]);\n        __m128i vec2 = _mm_loadu_si128((__m128i*)&lst2[i]);\n\n        __m128i odd1 = _mm_and_si128(vec1, mask); // Check if elements in lst1 are odd\n        __m128i odd2 = _mm_and_si128(vec2, mask); // Check if elements in lst2 are odd\n\n        __m128i odd_mask = _mm_or_si128(odd1, odd2); // Combine odd masks\n\n        if (!_mm_test_all_zeros(odd_mask, all_ones)) {\n            return \"NO\";\n        }\n    }\n\n    for (; i < size; ++i) {\n        if ((lst1[i] % 2) != 0) {\n            return \"NO\";\n        }\n    }\n\n    return \"YES\";\n}\n```"}
{"task_id": "SimdBench_117_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nstd::vector<std::string> odd_count_simd(const std::vector<std::string> & lst){\n    std::vector<std::string> result;\n    for (const std::string& str : lst) {\n        int oddCount = 0;\n        __m128i oddMask = _mm_setr_epi8(1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0);\n        for (size_t i = 0; i < str.size(); i += 16) {\n            __m128i input = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&str[i]));\n            __m128i oddDigits = _mm_and_si128(input, oddMask);\n            oddCount += _mm_popcnt_u32(_mm_movemask_epi8(oddDigits));\n        }\n        result.push_back(\"the number of odd elements \" + std::to_string(oddCount) + \"n the str\" + std::to_string(oddCount) + \"ng \" + str + \" of the \" + std::to_string(oddCount) + \"nput.\");\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_117_SSE", "completion": "```\nstd::vector<std::string> odd_count_simd(const std::vector<std::string> & lst){\n    std::vector<std::string> result;\n    for (const std::string& str : lst) {\n        int oddCount = 0;\n        __m128i oddMask = _mm_set1_epi8(0x55); // Mask to check odd digits\n        for (size_t i = 0; i < str.size(); ++i) {\n            __m128i digits = _mm_set1_epi8(str[i] - '0');\n            __m128i oddDigits = _mm_and_si128(digits, oddMask);\n            int oddDigitsCount = _mm_popcnt_u32(_mm_movemask_epi8(oddDigits));\n            oddCount += oddDigitsCount;\n        }\n        result.push_back(\"the number of odd elements \" + std::to_string(oddCount) + \"n the str\" + std::to_string(oddCount) + \"ng \" + str + \" of the \" + std::to_string(oddCount) + \"nput.\");\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_117_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n\nstd::vector<std::string> odd_count_simd(const std::vector<std::string> & lst){\n    std::vector<std::string> result;\n    for (const std::string& str : lst) {\n        int oddCount = 0;\n        __m128i oddMask = _mm_set1_epi8(0x55); // Mask to check odd digits\n        for (size_t i = 0; i < str.size(); ++i) {\n            __m128i digits = _mm_set1_epi8(str[i] - '0');\n            __m128i oddDigits = _mm_and_si128(digits, oddMask);\n            __m128i oddDigitsCount = _mm_sad_epu8(oddDigits, _mm_setzero_si128());\n            oddCount += _mm_extract_epi16(oddDigitsCount, 0) + _mm_extract_epi16(oddDigitsCount, 4);\n        }\n        result.push_back(\"the number of odd elements \" + std::to_string(oddCount) + \"n the str\" + std::to_string(oddCount) + \"ng \" + str + \" of the \" + std::to_string(oddCount) + \"nput.\");\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_117_SSE", "completion": "```\nstd::vector<std::string> odd_count_simd(const std::vector<std::string> & lst){\n    std::vector<std::string> result;\n    for (const std::string& str : lst) {\n        int oddCount = 0;\n        __m128i oddMask = _mm_set1_epi8(0x55); // Mask to check odd digits (0x55 = 01010101 in binary)\n        for (char c : str) {\n            __m128i num = _mm_set1_epi8(c - '0');\n            __m128i oddDigits = _mm_and_si128(num, oddMask);\n            __m128i oddDigitsCount = _mm_sad_epu8(oddDigits, _mm_setzero_si128());\n            oddCount += _mm_extract_epi16(oddDigitsCount, 0) + _mm_extract_epi16(oddDigitsCount, 4);\n        }\n        result.push_back(\"the number of odd elements \" + std::to_string(oddCount) + \"n the str\" + str + \"ng \" + str + \" of the \" + str + \"nput.\");\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_117_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n\nstd::vector<std::string> odd_count_simd(const std::vector<std::string> & lst) {\n    std::vector<std::string> result;\n    for (const std::string& str : lst) {\n        int oddCount = 0;\n        __m128i oddMask = _mm_set1_epi8(0x55); // Mask to check odd digits\n        for (size_t i = 0; i < str.size(); ++i) {\n            __m128i digits = _mm_set1_epi8(str[i] - '0');\n            __m128i oddDigits = _mm_and_si128(digits, oddMask);\n            __m128i oddDigitsCount = _mm_sad_epu8(oddDigits, _mm_setzero_si128());\n            oddCount += _mm_extract_epi16(oddDigitsCount, 0) + _mm_extract_epi16(oddDigitsCount, 4);\n        }\n        result.push_back(\"the number of odd elements \" + std::to_string(oddCount) + \"n the str\" + std::to_string(oddCount) + \"ng \" + str + \" of the \" + std::to_string(oddCount) + \"nput.\");\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_118_SSE", "completion": "```cpp\nint64_t minSubArraySum_simd(const std::vector<int64_t>& nums){\n    int64_t min_sum = INT64_MAX;\n    int64_t sum = 0;\n    \n    __m128i min_sum_v = _mm_set1_epi64x(INT64_MAX);\n    __m128i sum_v = _mm_setzero_si128();\n    \n    for (size_t i = 0; i < nums.size(); i += 2){\n        __m128i nums_v = _mm_loadu_si128((__m128i*)&nums[i]);\n        \n        sum_v = _mm_add_epi64(sum_v, nums_v);\n        min_sum_v = _mm_min_epi64(min_sum_v, sum_v);\n        \n        __m128i sum_v_shuffle = _mm_shuffle_epi32(sum_v, _MM_SHUFFLE(2, 3, 0, 1));\n        sum_v = _mm_add_epi64(sum_v, sum_v_shuffle);\n        \n        min_sum = std::min(min_sum, _mm_cvtsi128_si64(min_sum_v));\n    }\n    \n    return min_sum;\n}\n```"}
{"task_id": "SimdBench_118_SSE", "completion": "```cpp\nint64_t minSubArraySum_simd(const std::vector<int64_t>& nums){\n    int64_t min_sum = INT64_MAX;\n    int64_t sum = 0;\n    __m128i min_sum_v = _mm_set1_epi64x(INT64_MAX);\n    __m128i sum_v = _mm_setzero_si128();\n    \n    for (size_t i = 0; i < nums.size(); i += 2){\n        __m128i nums_v = _mm_loadu_si128((__m128i*)&nums[i]);\n        sum_v = _mm_add_epi64(sum_v, nums_v);\n        min_sum_v = _mm_min_epi64(min_sum_v, sum_v);\n        min_sum = std::min(min_sum, _mm_cvtsi128_si64(min_sum_v));\n        sum = _mm_cvtsi128_si64(sum_v);\n        if (i + 1 < nums.size()){\n            sum += nums[i + 1];\n            min_sum = std::min(min_sum, sum);\n        }\n    }\n    \n    return min_sum;\n}\n```"}
{"task_id": "SimdBench_118_SSE", "completion": "```cpp\nint64_t minSubArraySum_simd(const std::vector<int64_t>& nums){\n    int64_t min_sum = INT64_MAX;\n    int64_t sum = 0;\n    \n    __m128i min_sum_v = _mm_set1_epi64x(INT64_MAX);\n    __m128i sum_v = _mm_setzero_si128();\n    \n    for (size_t i = 0; i < nums.size(); i += 2){\n        __m128i nums_v = _mm_loadu_si128((__m128i*)&nums[i]);\n        sum_v = _mm_add_epi64(sum_v, nums_v);\n        min_sum_v = _mm_min_epi64(min_sum_v, sum_v);\n        \n        __m128i sum_shuffle = _mm_shuffle_epi32(sum_v, _MM_SHUFFLE(2, 3, 0, 1));\n        sum_v = _mm_add_epi64(sum_v, sum_shuffle);\n        min_sum_v = _mm_min_epi64(min_sum_v, sum_v);\n    }\n    \n    int64_t min_sum_arr[2];\n    _mm_storeu_si128((__m128i*)min_sum_arr, min_sum_v);\n    \n    min_sum = std::min(min_sum_arr[0], min_sum_arr[1]);\n    \n    return min_sum;\n}\n```"}
{"task_id": "SimdBench_118_SSE", "completion": "```cpp\nint64_t minSubArraySum_simd(const std::vector<int64_t>& nums){\n    int64_t min_sum = INT64_MAX;\n    int64_t sum = 0;\n    \n    __m128i min_sum_v = _mm_set1_epi64x(INT64_MAX);\n    __m128i sum_v = _mm_setzero_si128();\n    \n    for (size_t i = 0; i < nums.size(); i += 2){\n        __m128i nums_v = _mm_loadu_si128((__m128i*)&nums[i]);\n        \n        sum_v = _mm_add_epi64(sum_v, nums_v);\n        min_sum_v = _mm_min_epi64(min_sum_v, sum_v);\n        \n        __m128i sum_v_perm = _mm_shuffle_epi32(sum_v, _MM_SHUFFLE(2, 3, 0, 1));\n        sum_v = _mm_add_epi64(sum_v, sum_v_perm);\n        \n        min_sum = std::min(min_sum, _mm_cvtsi128_si64(min_sum_v));\n    }\n    \n    return min_sum;\n}\n```"}
{"task_id": "SimdBench_118_SSE", "completion": "```cpp\nint64_t minSubArraySum_simd(const std::vector<int64_t>& nums){\n    int64_t min_sum = INT64_MAX;\n    int64_t current_sum = 0;\n    \n    __m128i min_sum_v = _mm_set1_epi64x(INT64_MAX);\n    __m128i current_sum_v = _mm_setzero_si128();\n    \n    for (size_t i = 0; i < nums.size(); i += 2){\n        __m128i nums_v = _mm_set_epi64x(nums[i+1], nums[i]);\n        \n        current_sum_v = _mm_add_epi64(current_sum_v, nums_v);\n        min_sum_v = _mm_min_epi64(min_sum_v, current_sum_v);\n        \n        current_sum = _mm_cvtsi128_si64(current_sum_v);\n        min_sum = _mm_cvtsi128_si64(min_sum_v);\n    }\n    \n    return min_sum;\n}\n```"}
{"task_id": "SimdBench_119_SSE", "completion": "```\nint max_fill_simd(const std::vector<std::vector<int> > & grid, int capacity) {\n    int count = 0;\n    int rows = grid.size();\n    int cols = grid[0].size();\n    \n    __m128i bucket_capacity = _mm_set1_epi32(capacity);\n    __m128i count_vector = _mm_setzero_si128();\n    \n    for (int i = 0; i < rows; ++i) {\n        __m128i row_sum = _mm_setzero_si128();\n        for (int j = 0; j < cols; j += 4) {\n            __m128i well_values = _mm_loadu_si128((__m128i*)&grid[i][j]);\n            row_sum = _mm_add_epi32(row_sum, well_values);\n            \n            __m128i excess_water = _mm_sub_epi32(row_sum, bucket_capacity);\n            __m128i positive_excess = _mm_max_epi32(excess_water, _mm_setzero_si128());\n            count_vector = _mm_add_epi32(count_vector, positive_excess);\n            \n            row_sum = _mm_sub_epi32(row_sum, positive_excess);\n        }\n    }\n    \n    int count_array[4];\n    _mm_storeu_si128((__m128i*)count_array, count_vector);\n    count = count_array[0] + count_array[1] + count_array[2] + count_array[3];\n    \n    return count;\n}\n```"}
{"task_id": "SimdBench_119_SSE", "completion": "```\nint max_fill_simd(const std::vector<std::vector<int> > & grid, int capacity) {\n    int count = 0;\n    int gridRows = grid.size();\n    int gridCols = grid[0].size();\n    \n    __m128i capacityVec = _mm_set1_epi32(capacity);\n    __m128i countVec = _mm_setzero_si128();\n    \n    for (int i = 0; i < gridRows; ++i) {\n        __m128i rowVec = _mm_loadu_si128((__m128i*)&grid[i][0]);\n        \n        __m128i filledVec = _mm_cmpeq_epi32(rowVec, _mm_set1_epi32(1));\n        __m128i diffVec = _mm_sub_epi32(capacityVec, countVec);\n        __m128i minVec = _mm_min_epi32(filledVec, diffVec);\n        \n        countVec = _mm_add_epi32(countVec, minVec);\n    }\n    \n    int countArray[4];\n    _mm_storeu_si128((__m128i*)countArray, countVec);\n    \n    count = countArray[0] + countArray[1] + countArray[2] + countArray[3];\n    \n    return count;\n}\n```"}
{"task_id": "SimdBench_119_SSE", "completion": "```\nint max_fill_simd(const std::vector<std::vector<int> > & grid, int capacity) {\n    int count = 0;\n    int gridRows = grid.size();\n    int gridCols = grid[0].size();\n    \n    __m128i capacity_vec = _mm_set1_epi32(capacity);\n    __m128i count_vec = _mm_setzero_si128();\n    \n    for (int i = 0; i < gridRows; ++i) {\n        __m128i row_vec = _mm_loadu_si128((__m128i*)&grid[i][0]);\n        \n        __m128i filled_vec = _mm_cmpeq_epi32(row_vec, capacity_vec);\n        count_vec = _mm_add_epi32(count_vec, filled_vec);\n    }\n    \n    int count_array[4];\n    _mm_storeu_si128((__m128i*)count_array, count_vec);\n    \n    count = count_array[0] + count_array[1] + count_array[2] + count_array[3];\n    \n    return count;\n}\n```"}
{"task_id": "SimdBench_119_SSE", "completion": "```\nint max_fill_simd(const std::vector<std::vector<int> > & grid, int capacity) {\n    int count = 0;\n    int rows = grid.size();\n    int cols = grid[0].size();\n    \n    __m128i capacity_vec = _mm_set1_epi32(capacity);\n    __m128i count_vec = _mm_setzero_si128();\n    \n    for (int i = 0; i < rows; ++i) {\n        __m128i row_sum = _mm_setzero_si128();\n        for (int j = 0; j < cols; j += 4) {\n            __m128i grid_row = _mm_loadu_si128((__m128i*)&grid[i][j]);\n            row_sum = _mm_add_epi32(row_sum, grid_row);\n            \n            __m128i excess_water = _mm_sub_epi32(row_sum, capacity_vec);\n            __m128i positive_excess = _mm_max_epi32(excess_water, _mm_setzero_si128());\n            count_vec = _mm_add_epi32(count_vec, positive_excess);\n            \n            row_sum = _mm_sub_epi32(row_sum, _mm_mullo_epi32(positive_excess, _mm_set1_epi32(1)));\n        }\n    }\n    \n    int count_array[4];\n    _mm_storeu_si128((__m128i*)count_array, count_vec);\n    \n    count = count_array[0] + count_array[1] + count_array[2] + count_array[3];\n    \n    return count;\n}\n```"}
{"task_id": "SimdBench_119_SSE", "completion": "```\nint max_fill_simd(const std::vector<std::vector<int> > & grid, int capacity) {\n    int count = 0;\n    __m128i capacity_vec = _mm_set1_epi32(capacity);\n    __m128i count_vec = _mm_setzero_si128();\n\n    for (size_t i = 0; i < grid.size(); ++i) {\n        __m128i row_sum = _mm_setzero_si128();\n        for (size_t j = 0; j < grid[i].size(); j += 4) {\n            __m128i well_values = _mm_loadu_si128((__m128i*)&grid[i][j]);\n            row_sum = _mm_add_epi32(row_sum, well_values);\n            __m128i excess_water = _mm_sub_epi32(row_sum, capacity_vec);\n            __m128i positive_excess = _mm_max_epi32(excess_water, _mm_setzero_si128());\n            count_vec = _mm_add_epi32(count_vec, positive_excess);\n            row_sum = _mm_sub_epi32(row_sum, positive_excess);\n        }\n    }\n\n    int count_array[4];\n    _mm_storeu_si128((__m128i*)count_array, count_vec);\n    count = count_array[0] + count_array[1] + count_array[2] + count_array[3];\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_120_SSE", "completion": "```cpp\nint64_t solution_simd(const std::vector<int16_t>& lst){\n    __m128i sum = _mm_setzero_si128();\n    for (size_t i = 0; i < lst.size(); i += 8) {\n        __m128i vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&lst[i]));\n        __m128i mask = _mm_set1_epi16(0xaaaa); // Mask to select even positions\n        __m128i even_elements = _mm_and_si128(vec, mask);\n        __m128i odd_elements = _mm_srli_epi16(vec, 1);\n        __m128i odd_elements_in_even_pos = _mm_and_si128(odd_elements, mask);\n        sum = _mm_add_epi16(sum, odd_elements_in_even_pos);\n    }\n    __m128i sum_high = _mm_unpackhi_epi64(sum, sum);\n    __m128i sum_total = _mm_add_epi64(sum, sum_high);\n    return _mm_cvtsi128_si64(sum_total);\n}\n```"}
{"task_id": "SimdBench_120_SSE", "completion": "```cpp\nint64_t solution_simd(const std::vector<int16_t>& lst){\n    __m128i sum = _mm_setzero_si128();\n    for (size_t i = 0; i < lst.size(); i += 8) {\n        __m128i vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&lst[i]));\n        __m128i evenMask = _mm_set1_epi16(0xaaaa);\n        __m128i oddMask = _mm_set1_epi16(0x5555);\n        __m128i evenPos = _mm_and_si128(vec, evenMask);\n        __m128i oddElements = _mm_and_si128(vec, oddMask);\n        sum = _mm_add_epi16(sum, _mm_sad_epu8(_mm_packus_epi16(evenPos, _mm_setzero_si128()), _mm_setzero_si128()));\n    }\n    return _mm_extract_epi16(sum, 0) + _mm_extract_epi16(sum, 4);\n}\n```"}
{"task_id": "SimdBench_120_SSE", "completion": "```cpp\nint64_t solution_simd(const std::vector<int16_t>& lst){\n    __m128i sum = _mm_setzero_si128();\n    for (size_t i = 0; i < lst.size(); i += 8) {\n        __m128i values = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&lst[i]));\n        __m128i evenMask = _mm_set1_epi16(0xaaaa); // Mask for even positions\n        __m128i oddMask = _mm_set1_epi16(0x5555); // Mask for odd positions\n        __m128i evenValues = _mm_and_si128(values, evenMask);\n        __m128i oddValues = _mm_and_si128(values, oddMask);\n        __m128i oddSum = _mm_add_epi16(sum, oddValues);\n        sum = _mm_add_epi16(sum, evenValues);\n        sum = _mm_add_epi16(sum, oddSum);\n    }\n    int64_t result = 0;\n    result += _mm_extract_epi16(sum, 0);\n    result += _mm_extract_epi16(sum, 1);\n    result += _mm_extract_epi16(sum, 2);\n    result += _mm_extract_epi16(sum, 3);\n    return result;\n}\n```"}
{"task_id": "SimdBench_120_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint64_t solution_simd(const std::vector<int16_t>& lst){\n    __m128i oddMask = _mm_set1_epi16(0x5555); // Mask to extract odd elements\n    __m128i sum = _mm_setzero_si128(); // Initialize sum to zero\n    for (size_t i = 0; i < lst.size(); i += 8) {\n        __m128i vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&lst[i])); // Load 8 elements\n        __m128i oddElements = _mm_and_si128(vec, oddMask); // Extract odd elements\n        __m128i evenPositions = _mm_srli_epi16(oddElements, 1); // Shift to get elements in even positions\n        sum = _mm_add_epi16(sum, evenPositions); // Add to the running sum\n    }\n    alignas(16) int16_t result[8];\n    _mm_store_si128(reinterpret_cast<__m128i*>(result), sum);\n    return result[0] + result[1] + result[2] + result[3];\n}\n```"}
{"task_id": "SimdBench_120_SSE", "completion": "```cpp\nint64_t solution_simd(const std::vector<int16_t>& lst){\n    __m128i sum = _mm_setzero_si128();\n    for (size_t i = 0; i < lst.size(); i += 8) {\n        __m128i vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&lst[i]));\n        __m128i evenMask = _mm_set1_epi16(0xaaaa); // Mask to select even positions\n        __m128i oddMask = _mm_set1_epi16(0x5555); // Mask to select odd positions\n        __m128i evenPos = _mm_and_si128(vec, evenMask);\n        __m128i oddElements = _mm_and_si128(vec, oddMask);\n        sum = _mm_add_epi16(sum, _mm_sad_epu8(oddElements, _mm_setzero_si128()));\n    }\n    int64_t result = 0;\n    result += _mm_extract_epi16(sum, 0);\n    result += _mm_extract_epi16(sum, 1);\n    result += _mm_extract_epi16(sum, 2);\n    result += _mm_extract_epi16(sum, 3);\n    return result;\n}\n```"}
{"task_id": "SimdBench_121_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint add_elements_simd(std::vector<int> arr, int k){\n    __m128i sum = _mm_setzero_si128();\n    int i = 0;\n    \n    for (; i + 4 <= k; i += 4) {\n        __m128i vec = _mm_loadu_si128((__m128i*)&arr[i]);\n        __m128i mask = _mm_cmplt_epi32(vec, _mm_set1_epi32(100));\n        __m128i masked = _mm_and_si128(vec, mask);\n        sum = _mm_add_epi32(sum, masked);\n    }\n    \n    int result[4];\n    _mm_storeu_si128((__m128i*)result, sum);\n    \n    int final_sum = result[0] + result[1] + result[2] + result[3];\n    \n    for (; i < k; i++) {\n        if (arr[i] < 100) {\n            final_sum += arr[i];\n        }\n    }\n    \n    return final_sum;\n}\n```"}
{"task_id": "SimdBench_121_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint add_elements_simd(std::vector<int> arr, int k){\n    __m128i sum = _mm_setzero_si128();\n    for (int i = 0; i < k; i += 4) {\n        __m128i values = _mm_loadu_si128((__m128i*)&arr[i]);\n        __m128i mask = _mm_cmplt_epi32(values, _mm_set1_epi32(100));\n        __m128i masked_values = _mm_and_si128(values, mask);\n        sum = _mm_add_epi32(sum, masked_values);\n    }\n    \n    int result[4];\n    _mm_storeu_si128((__m128i*)result, sum);\n    \n    return result[0] + result[1] + result[2] + result[3];\n}\n```"}
{"task_id": "SimdBench_121_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint add_elements_simd(std::vector<int> arr, int k){\n    __m128i sum = _mm_setzero_si128();\n    int i = 0;\n    for (; i < k - 3; i += 4) {\n        __m128i values = _mm_loadu_si128((__m128i*)&arr[i]);\n        __m128i mask = _mm_cmplt_epi32(values, _mm_set1_epi32(100));\n        __m128i filtered_values = _mm_and_si128(values, mask);\n        sum = _mm_add_epi32(sum, filtered_values);\n    }\n    \n    int remaining_sum = 0;\n    for (; i < k; ++i) {\n        if (arr[i] < 100) {\n            remaining_sum += arr[i];\n        }\n    }\n    \n    int result[4];\n    _mm_storeu_si128((__m128i*)result, sum);\n    return result[0] + result[1] + result[2] + result[3] + remaining_sum;\n}\n```"}
{"task_id": "SimdBench_121_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint add_elements_simd(std::vector<int> arr, int k){\n    __m128i sum = _mm_setzero_si128();\n    int total_sum = 0;\n    \n    for (int i = 0; i < k; i += 4) {\n        __m128i values = _mm_loadu_si128((__m128i*)&arr[i]);\n        __m128i mask = _mm_cmplt_epi32(values, _mm_set1_epi32(100));\n        __m128i masked_values = _mm_and_si128(values, mask);\n        sum = _mm_add_epi32(sum, masked_values);\n    }\n    \n    int result[4];\n    _mm_storeu_si128((__m128i*)result, sum);\n    \n    for (int i = 0; i < 4; i++) {\n        total_sum += result[i];\n    }\n    \n    return total_sum;\n}\n```"}
{"task_id": "SimdBench_121_SSE", "completion": "```cpp\nint add_elements_simd(std::vector<int> arr, int k) {\n    __m128i sum = _mm_setzero_si128();\n    int total_sum = 0;\n    \n    for (int i = 0; i < k; i += 4) {\n        __m128i values = _mm_loadu_si128((__m128i*)&arr[i]);\n        __m128i mask = _mm_cmplt_epi32(values, _mm_set1_epi32(100));\n        __m128i masked_values = _mm_and_si128(values, mask);\n        sum = _mm_add_epi32(sum, masked_values);\n    }\n    \n    int temp[4];\n    _mm_storeu_si128((__m128i*)temp, sum);\n    for (int i = 0; i < 4; i++) {\n        total_sum += temp[i];\n    }\n    \n    return total_sum;\n}\n```"}
{"task_id": "SimdBench_122_SSE", "completion": "```\nbool is_sorted_simd(const std::vector<int> & lst){\n    if(lst.size() <= 1) {\n        return true;\n    }\n\n    __m128i prev = _mm_set1_epi32(lst[0]);\n    for(size_t i = 1; i < lst.size(); i += 4) {\n        __m128i current = _mm_loadu_si128((__m128i*)&lst[i]);\n        __m128i cmp = _mm_cmplt_epi32(prev, current);\n        int mask = _mm_movemask_epi8(cmp);\n        if(mask != 0xFFFF) {\n            return false;\n        }\n        prev = _mm_shuffle_epi32(current, _MM_SHUFFLE(3, 2, 1, 0));\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_122_SSE", "completion": "```\nbool is_sorted_simd(const std::vector<int> & lst){\n    if(lst.size() <= 1){\n        return true;\n    }\n\n    __m128i prev = _mm_set1_epi32(lst[0]);\n    __m128i current;\n\n    for(size_t i = 1; i < lst.size(); i += 4){\n        current = _mm_loadu_si128((__m128i*)&lst[i]);\n\n        __m128i cmp = _mm_cmplt_epi32(prev, current);\n        if(_mm_movemask_epi8(cmp) != 0xFFFF){\n            return false;\n        }\n\n        prev = _mm_shuffle_epi32(current, _MM_SHUFFLE(3, 2, 1, 0));\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_122_SSE", "completion": "```\nbool is_sorted_simd(const std::vector<int> & lst){\n    if(lst.size() < 2){\n        return true;\n    }\n\n    __m128i prev = _mm_set_epi32(lst[3], lst[2], lst[1], lst[0]);\n    for(size_t i = 4; i < lst.size(); i += 4){\n        __m128i curr = _mm_set_epi32(lst[i], lst[i-1], lst[i-2], lst[i-3]);\n        __m128i cmp = _mm_cmplt_epi32(prev, curr);\n        if(_mm_movemask_epi8(cmp) != 0xFFFF){\n            return false;\n        }\n        prev = curr;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_122_SSE", "completion": "```\nbool is_sorted_simd(const std::vector<int> & lst){\n    if(lst.size() < 2){\n        return true;\n    }\n\n    __m128i prev = _mm_set1_epi32(lst[0]);\n    __m128i result = _mm_set1_epi32(1);\n\n    for(size_t i = 1; i < lst.size(); i += 4){\n        __m128i current = _mm_loadu_si128((__m128i*)&lst[i]);\n        __m128i cmp = _mm_cmplt_epi32(prev, current);\n        result = _mm_and_si128(result, cmp);\n        prev = _mm_shuffle_epi32(current, _MM_SHUFFLE(3, 2, 1, 0));\n    }\n\n    int mask = _mm_movemask_epi8(result);\n    return mask == 0xFFFF;\n}\n```"}
{"task_id": "SimdBench_122_SSE", "completion": "```\nbool is_sorted_simd(const std::vector<int> & lst){\n    if(lst.size() < 2) {\n        return true;\n    }\n\n    __m128i prev = _mm_set_epi32(lst[3], lst[2], lst[1], lst[0]);\n    for(size_t i = 4; i < lst.size(); i += 4) {\n        __m128i curr = _mm_set_epi32(lst[i], lst[i-1], lst[i-2], lst[i-3]);\n        __m128i cmp = _mm_cmplt_epi32(prev, curr);\n        if(_mm_movemask_epi8(cmp) != 0xFFFF) {\n            return false;\n        }\n        prev = curr;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_123_SSE", "completion": "```cpp\nint prod_signs_simd(const std::vector<int> & arr){\n    if(arr.empty()) return -32768;\n\n    __m128i sum = _mm_setzero_si128();\n    __m128i signs_product = _mm_set1_epi32(1);\n\n    for(size_t i = 0; i < arr.size(); i += 4){\n        __m128i values = _mm_loadu_si128((__m128i*)&arr[i]);\n        __m128i signs = _mm_cmplt_epi32(values, _mm_setzero_si128());\n        signs_product = _mm_mullo_epi32(signs_product, signs);\n\n        __m128i abs_values = _mm_abs_epi32(values);\n        sum = _mm_add_epi32(sum, abs_values);\n    }\n\n    __m128i result = _mm_mullo_epi32(sum, signs_product);\n    int final_result = _mm_cvtsi128_si32(result);\n\n    return final_result;\n}\n```"}
{"task_id": "SimdBench_123_SSE", "completion": "```cpp\nint prod_signs_simd(const std::vector<int> & arr){\n    if(arr.empty()) {\n        return -32768;\n    }\n\n    __m128i sum = _mm_setzero_si128();\n    __m128i signs_product = _mm_set1_epi32(1);\n\n    for(size_t i = 0; i < arr.size(); i += 4) {\n        __m128i values = _mm_loadu_si128((__m128i*)&arr[i]);\n        __m128i signs = _mm_sign_epi32(values);\n\n        signs_product = _mm_mullo_epi32(signs_product, signs);\n\n        __m128i abs_values = _mm_abs_epi32(values);\n        sum = _mm_add_epi32(sum, abs_values);\n    }\n\n    int result[4];\n    _mm_storeu_si128((__m128i*)result, sum);\n\n    int final_result = 0;\n    for(int i = 0; i < 4; i++) {\n        final_result += result[i] * _mm_extract_epi32(signs_product, i);\n    }\n\n    return final_result;\n}\n```"}
{"task_id": "SimdBench_123_SSE", "completion": "```cpp\nint prod_signs_simd(const std::vector<int> & arr){\n    if(arr.empty()) {\n        return -32768;\n    }\n\n    __m128i sum = _mm_setzero_si128();\n    __m128i signs_product = _mm_set1_epi32(1);\n\n    for(size_t i = 0; i < arr.size(); i += 4) {\n        __m128i values = _mm_loadu_si128((__m128i*)&arr[i]);\n        __m128i signs = _mm_cmplt_epi32(values, _mm_setzero_si128());\n        signs_product = _mm_mullo_epi32(signs_product, signs);\n        sum = _mm_add_epi32(sum, _mm_abs_epi32(values));\n    }\n\n    int result[4];\n    _mm_storeu_si128((__m128i*)result, sum);\n\n    int final_result = 0;\n    for(int i = 0; i < 4; i++) {\n        final_result += result[i] * _mm_extract_epi32(signs_product, i);\n    }\n\n    return final_result;\n}\n```"}
{"task_id": "SimdBench_123_SSE", "completion": "```cpp\nint prod_signs_simd(const std::vector<int> & arr){\n    if(arr.empty()) return -32768;\n\n    __m128i sum = _mm_setzero_si128();\n    __m128i signs_product = _mm_set1_epi32(1);\n\n    for(size_t i = 0; i < arr.size(); i += 4){\n        __m128i values = _mm_loadu_si128((__m128i*)&arr[i]);\n        __m128i signs = _mm_sign_epi32(values);\n\n        signs_product = _mm_mullo_epi32(signs_product, signs);\n        sum = _mm_add_epi32(sum, _mm_abs_epi32(values));\n    }\n\n    int result[4];\n    _mm_storeu_si128((__m128i*)result, sum);\n\n    int final_result = 0;\n    for(int i = 0; i < 4; i++){\n        final_result += result[i] * _mm_extract_epi32(signs_product, i);\n    }\n\n    return final_result;\n}\n```"}
{"task_id": "SimdBench_123_SSE", "completion": "```cpp\nint prod_signs_simd(const std::vector<int> & arr){\n    if(arr.empty()) return -32768;\n\n    __m128i sum = _mm_setzero_si128();\n    __m128i signs_product = _mm_set1_epi32(1);\n\n    for(size_t i = 0; i < arr.size(); i += 4){\n        __m128i values = _mm_loadu_si128((__m128i*)&arr[i]);\n        __m128i signs = _mm_cmplt_epi32(values, _mm_setzero_si128());\n\n        __m128i abs_values = _mm_abs_epi32(values);\n        __m128i abs_values_times_signs = _mm_mullo_epi32(abs_values, signs);\n\n        signs_product = _mm_mullo_epi32(signs_product, signs);\n        sum = _mm_add_epi32(sum, abs_values_times_signs);\n    }\n\n    __m128i result = _mm_mullo_epi32(sum, signs_product);\n    int final_result = _mm_cvtsi128_si32(result);\n    return final_result;\n}\n```"}
{"task_id": "SimdBench_124_SSE", "completion": "```\nstd::vector<int> minPath_simd(const std::vector<std::vector<int> > & grid, int k){\n    std::vector<int> result;\n    int n = grid.size();\n    __m128i path = _mm_set_epi32(0, 0, 0, 0);\n    __m128i indices = _mm_set_epi32(3, 2, 1, 0);\n\n    for (int i = 0; i < k; ++i) {\n        int row = _mm_extract_epi32(path, 0) / n;\n        int col = _mm_extract_epi32(path, 0) % n;\n        __m128i values = _mm_set_epi32(grid[row+1][col], grid[row][col+1], grid[row-1][col], grid[row][col-1]);\n        __m128i min_value = _mm_min_epu32(values, _mm_shuffle_epi32(values, _MM_SHUFFLE(0, 3, 2, 1)));\n        min_value = _mm_min_epu32(min_value, _mm_shuffle_epi32(min_value, _MM_SHUFFLE(2, 1, 0, 3)));\n        __m128i mask = _mm_cmpeq_epi32(values, min_value);\n        int index = _mm_extract_epi32(_mm_and_si128(mask, indices), 0);\n        result.push_back(grid[row][col]);\n        path = _mm_insert_epi32(path, index, 0);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_124_SSE", "completion": "```\nstd::vector<int> minPath_simd(const std::vector<std::vector<int> > & grid, int k){\n    std::vector<int> result;\n    int n = grid.size();\n    __m128i path = _mm_set_epi32(0, 0, 0, 0);\n    __m128i min_values = _mm_set_epi32(0, 0, 0, 0);\n    __m128i min_indices = _mm_set_epi32(0, 0, 0, 0);\n\n    for (int i = 0; i < k; i++) {\n        __m128i current_values = _mm_set_epi32(grid[0][i], grid[1][i], grid[2][i], grid[3][i]);\n        __m128i cmp_mask = _mm_cmplt_epi32(current_values, min_values);\n        min_values = _mm_blendv_epi8(min_values, current_values, cmp_mask);\n        min_indices = _mm_blendv_epi8(min_indices, _mm_set_epi32(i, i, i, i), cmp_mask);\n    }\n\n    int indices[4];\n    _mm_storeu_si128((__m128i*)indices, min_indices);\n    for (int i = 0; i < 4; i++) {\n        result.push_back(grid[i][indices[i]]);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_124_SSE", "completion": "```\nstd::vector<int> minPath_simd(const std::vector<std::vector<int> > & grid, int k){\n    std::vector<int> result;\n    // Implementing the function using SSE/SSE2 intrinsics for parallelism\n    // Your SIMD code implementation here\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_124_SSE", "completion": "```\nstd::vector<int> minPath_simd(const std::vector<std::vector<int> > & grid, int k){\n    std::vector<int> result;\n    int n = grid.size();\n    __m128i path = _mm_set_epi32(0, 0, 0, 0);\n    \n    for (int i = 0; i < k; ++i) {\n        __m128i min_val = _mm_set1_epi32(1000000);\n        __m128i min_idx = _mm_set1_epi32(0);\n        \n        for (int r = 0; r < n; ++r) {\n            for (int c = 0; c < n; ++c) {\n                __m128i val = _mm_set1_epi32(grid[r][c]);\n                __m128i cmp = _mm_cmplt_epi32(val, min_val);\n                min_val = _mm_blendv_epi8(min_val, val, cmp);\n                min_idx = _mm_blendv_epi8(min_idx, _mm_set1_epi32(r * n + c + 1), cmp);\n            }\n        }\n        \n        result.push_back(_mm_extract_epi32(min_val, 0));\n        path = _mm_insert_epi32(path, _mm_extract_epi32(min_idx, 0), i);\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_124_SSE", "completion": "```\nstd::vector<int> minPath_simd(const std::vector<std::vector<int> > & grid, int k){\n    std::vector<int> result;\n    int N = grid.size();\n    __m128i indices = _mm_set_epi32(3, 2, 1, 0);\n    __m128i shuffle_mask = _mm_set_epi32(3, 2, 1, 0);\n    __m128i min_values = _mm_set1_epi32(INT_MAX);\n\n    for (int i = 0; i < N; ++i) {\n        for (int j = 0; j < N; ++j) {\n            __m128i current_value = _mm_set1_epi32(grid[i][j]);\n            __m128i current_indices = _mm_set1_epi32(i * N + j);\n\n            if (k == 1) {\n                min_values = _mm_min_epi32(min_values, current_value);\n            } else {\n                __m128i new_values = _mm_min_epi32(min_values, current_value);\n                __m128i cmp_mask = _mm_cmpeq_epi32(new_values, current_value);\n                __m128i new_indices = _mm_blendv_epi8(indices, current_indices, cmp_mask);\n                __m128i shuffle_indices = _mm_shuffle_epi8(new_indices, shuffle_mask);\n                min_values = _mm_min_epi32(min_values, new_values);\n                indices = _mm_blendv_epi8(indices, shuffle_indices, cmp_mask);\n            }\n        }\n    }\n\n    int min_values_arr[4];\n    _mm_storeu_si128((__m128i*)min_values_arr, min_values);\n    int min_value = INT_MAX;\n    for (int i = 0; i < 4; ++i) {\n        if (min_values_arr[i] < min_value) {\n            min_value = min_values_arr[i];\n        }\n    }\n\n    result.push_back(min_value);\n    return result;\n}\n```"}
{"task_id": "SimdBench_125_SSE", "completion": "```c\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nuint64_t digits_simd(uint64_t n){\n    __m128i odd_digits = _mm_set1_epi8(1);\n    __m128i result = _mm_set1_epi8(1);\n    \n    while (n > 0) {\n        uint8_t digit = n % 10;\n        n /= 10;\n        \n        if (digit % 2 != 0) {\n            __m128i digit_vec = _mm_set1_epi8(digit);\n            result = _mm_mullo_epi16(result, digit_vec);\n            odd_digits = _mm_and_si128(odd_digits, digit_vec);\n        }\n    }\n    \n    __m128i mask = _mm_cmpeq_epi8(odd_digits, _mm_set1_epi8(1));\n    if (_mm_movemask_epi8(mask) == 0xFFFF) {\n        return 0;\n    }\n    \n    uint16_t product = _mm_extract_epi16(result, 0) * _mm_extract_epi16(result, 4);\n    return product;\n}\n```"}
{"task_id": "SimdBench_125_SSE", "completion": "```c\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nuint64_t digits_simd(uint64_t n){\n    __m128i odd_digits = _mm_set1_epi8(1);\n    __m128i product = _mm_set1_epi8(1);\n    \n    while (n > 0) {\n        uint8_t digit = n % 10;\n        if (digit % 2 != 0) {\n            odd_digits = _mm_mullo_epi16(odd_digits, _mm_set1_epi8(digit));\n        }\n        n /= 10;\n    }\n    \n    __m128i result = _mm_hadd_epi16(odd_digits, odd_digits);\n    result = _mm_hadd_epi16(result, result);\n    \n    return _mm_cvtsi128_si64(result);\n}\n```"}
{"task_id": "SimdBench_125_SSE", "completion": "```c\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nuint64_t digits_simd(uint64_t n){\n    __m128i odd_digits = _mm_set1_epi8(0);\n    __m128i all_even = _mm_set1_epi8(1);\n    \n    while (n > 0) {\n        uint8_t digit = n % 10;\n        n /= 10;\n        \n        if (digit % 2 == 0) {\n            all_even = _mm_and_si128(all_even, _mm_set1_epi8(0));\n        } else {\n            odd_digits = _mm_mullo_epi16(odd_digits, _mm_set1_epi8(digit));\n        }\n    }\n    \n    __m128i result = _mm_set1_epi8(1);\n    for (int i = 0; i < 8; i++) {\n        result = _mm_mullo_epi16(result, odd_digits);\n    }\n    \n    return _mm_cvtsi128_si64(result);\n}\n```"}
{"task_id": "SimdBench_125_SSE", "completion": "```c\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nuint64_t digits_simd(uint64_t n){\n    __m128i odd_digits = _mm_set1_epi8(1);\n    __m128i result = _mm_set1_epi8(1);\n    \n    while (n > 0) {\n        uint8_t digit = n % 10;\n        n /= 10;\n        \n        if (digit % 2 != 0) {\n            __m128i digit_vec = _mm_set1_epi8(digit);\n            result = _mm_mullo_epi16(result, digit_vec);\n            odd_digits = _mm_and_si128(odd_digits, digit_vec);\n        }\n    }\n    \n    __m128i zero = _mm_setzero_si128();\n    __m128i cmp = _mm_cmpeq_epi8(odd_digits, zero);\n    if (_mm_movemask_epi8(cmp) == 0xFFFF) {\n        return 0;\n    }\n    \n    uint64_t product = 1;\n    uint8_t* res_ptr = (uint8_t*)&result;\n    for (int i = 0; i < 16; i++) {\n        product *= res_ptr[i];\n    }\n    \n    return product;\n}\n```  "}
{"task_id": "SimdBench_125_SSE", "completion": "```c\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nuint64_t digits_simd(uint64_t n){\n    __m128i odd_digits = _mm_set1_epi8(1);\n    __m128i result = _mm_set1_epi8(1);\n    \n    while (n > 0) {\n        uint8_t digit = n % 10;\n        if (digit % 2 != 0) {\n            __m128i digit_vec = _mm_set1_epi8(digit);\n            result = _mm_mullo_epi16(result, digit_vec);\n        }\n        n /= 10;\n    }\n    \n    uint16_t result_array[8];\n    _mm_storeu_si128((__m128i*)result_array, result);\n    \n    return (uint64_t)result_array[0] * result_array[1] * result_array[2] * result_array[3];\n}\n```  "}
{"task_id": "SimdBench_126_SSE", "completion": "```cpp\nuint64_t sum_squares_simd(const std::vector<float> & lst){\n    __m128 sum = _mm_setzero_ps();\n    for (size_t i = 0; i < lst.size(); i += 4) {\n        __m128 values = _mm_loadu_ps(&lst[i]);\n        __m128 rounded_values = _mm_ceil_ps(values);\n        __m128 squared_values = _mm_mul_ps(rounded_values, rounded_values);\n        sum = _mm_add_ps(sum, squared_values);\n    }\n    \n    float temp[4];\n    _mm_storeu_ps(temp, sum);\n    \n    uint64_t result = 0;\n    for (int i = 0; i < 4; ++i) {\n        result += static_cast<uint64_t>(temp[i]);\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_126_SSE", "completion": "```cpp\nuint64_t sum_squares_simd(const std::vector<float> & lst){\n    __m128 sum = _mm_setzero_ps();\n    for (size_t i = 0; i < lst.size(); i += 4) {\n        __m128 values = _mm_loadu_ps(&lst[i]);\n        __m128 rounded_values = _mm_ceil_ps(values);\n        __m128 squared_values = _mm_mul_ps(rounded_values, rounded_values);\n        sum = _mm_add_ps(sum, squared_values);\n    }\n    \n    float temp[4];\n    _mm_storeu_ps(temp, sum);\n    \n    uint64_t result = 0;\n    for (int i = 0; i < 4; ++i) {\n        result += static_cast<uint64_t>(temp[i]);\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_126_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nuint64_t sum_squares_simd(const std::vector<float> & lst){\n    __m128 sum = _mm_setzero_ps();\n    __m128i intVals, squaredVals;\n    __m128i ones = _mm_set1_epi32(1);\n    __m128i mask = _mm_set1_epi32(0x80000000);\n    __m128i zero = _mm_setzero_si128();\n    __m128i ceiling;\n\n    for (size_t i = 0; i < lst.size(); i += 4) {\n        intVals = _mm_cvtps_epi32(_mm_loadu_ps(&lst[i]));\n        ceiling = _mm_add_epi32(intVals, ones);\n        ceiling = _mm_andnot_si128(_mm_cmplt_epi32(intVals, zero), ceiling);\n        squaredVals = _mm_mullo_epi32(ceiling, ceiling);\n        sum = _mm_add_ps(sum, _mm_cvtepi32_ps(squaredVals));\n    }\n\n    float temp[4];\n    _mm_storeu_ps(temp, sum);\n    return (uint64_t)(temp[0] + temp[1] + temp[2] + temp[3]);\n}\n```"}
{"task_id": "SimdBench_126_SSE", "completion": "```cpp\nuint64_t sum_squares_simd(const std::vector<float> & lst){\n    __m128 sum = _mm_setzero_ps();\n    for (size_t i = 0; i < lst.size(); i += 4) {\n        __m128 values = _mm_loadu_ps(&lst[i]);\n        __m128 rounded_values = _mm_ceil_ps(values);\n        __m128 squared_values = _mm_mul_ps(rounded_values, rounded_values);\n        sum = _mm_add_ps(sum, squared_values);\n    }\n    \n    float temp[4];\n    _mm_storeu_ps(temp, sum);\n    \n    uint64_t result = 0;\n    for (int i = 0; i < 4; ++i) {\n        result += static_cast<uint64_t>(temp[i]);\n    }\n    \n    return result;\n}\n```  "}
{"task_id": "SimdBench_126_SSE", "completion": "```cpp\nuint64_t sum_squares_simd(const std::vector<float> & lst){\n    __m128 sum = _mm_setzero_ps();\n    __m128i intVals, squaredVals;\n    for (size_t i = 0; i < lst.size(); i += 4) {\n        intVals = _mm_cvtps_epi32(_mm_ceil_ps(_mm_loadu_ps(&lst[i])));\n        squaredVals = _mm_mullo_epi32(intVals, intVals);\n        sum = _mm_add_ps(sum, _mm_cvtepi32_ps(squaredVals));\n    }\n    float temp[4];\n    _mm_storeu_ps(temp, sum);\n    return temp[0] + temp[1] + temp[2] + temp[3];\n}\n```"}
{"task_id": "SimdBench_127_SSE", "completion": "```\nint can_arrange_simd(const std::vector<int> & arr){\n    if(arr.size() < 2) return -1;\n\n    __m128i prev = _mm_loadu_si128((__m128i*)&arr[0]);\n    for(int i = 4; i < arr.size(); i += 4){\n        __m128i curr = _mm_loadu_si128((__m128i*)&arr[i]);\n        __m128i cmp = _mm_cmplt_epi32(curr, prev);\n        int mask = _mm_movemask_ps(_mm_castsi128_ps(cmp));\n        if(mask != 0){\n            int index = i - 4 + __builtin_ctz(mask);\n            return index;\n        }\n        prev = _mm_shuffle_epi32(curr, _MM_SHUFFLE(3, 2, 1, 0));\n    }\n\n    int remaining = arr.size() % 4;\n    if(remaining > 1){\n        __m128i curr = _mm_loadu_si128((__m128i*)&arr[arr.size() - remaining]);\n        __m128i cmp = _mm_cmplt_epi32(curr, prev);\n        int mask = _mm_movemask_ps(_mm_castsi128_ps(cmp));\n        if(mask != 0){\n            int index = arr.size() - remaining - 1 + __builtin_ctz(mask);\n            return index;\n        }\n    }\n\n    return -1;\n}\n```"}
{"task_id": "SimdBench_127_SSE", "completion": "```cpp\nint can_arrange_simd(const std::vector<int> & arr){\n    if(arr.size() < 2) return -1;\n\n    __m128i prev = _mm_loadu_si128((__m128i*)&arr[0]);\n    for (int i = 4; i < arr.size(); i += 4) {\n        __m128i curr = _mm_loadu_si128((__m128i*)&arr[i-1]);\n        __m128i next = _mm_loadu_si128((__m128i*)&arr[i]);\n\n        __m128i cmp_prev = _mm_cmpgt_epi32(prev, curr);\n        __m128i cmp_next = _mm_cmpgt_epi32(next, curr);\n\n        __m128i cmp_result = _mm_and_si128(cmp_prev, cmp_next);\n        int mask = _mm_movemask_epi8(cmp_result);\n\n        if (mask != 0xFFFF) {\n            return i - 1 + _tzcnt_u32(~mask) / 4;\n        }\n\n        prev = next;\n    }\n\n    return -1;\n}\n```"}
{"task_id": "SimdBench_127_SSE", "completion": "```\nint can_arrange_simd(const std::vector<int> & arr){\n    if(arr.size() < 2) return -1;\n\n    __m128i prev = _mm_loadu_si128((__m128i*)&arr[0]);\n    for(int i = 4; i < arr.size(); i += 4){\n        __m128i curr = _mm_loadu_si128((__m128i*)&arr[i-1]);\n        __m128i cmp = _mm_cmpgt_epi32(prev, curr);\n        int mask = _mm_movemask_ps(_mm_castsi128_ps(cmp));\n        if(mask != 0){\n            return i - 2 + __builtin_ctz(mask);\n        }\n        prev = _mm_loadu_si128((__m128i*)&arr[i]);\n    }\n\n    int remaining = arr.size() % 4;\n    if(remaining > 1){\n        __m128i curr = _mm_loadu_si128((__m128i*)&arr[arr.size()-remaining-1]);\n        __m128i cmp = _mm_cmpgt_epi32(prev, curr);\n        int mask = _mm_movemask_ps(_mm_castsi128_ps(cmp));\n        if(mask != 0){\n            return arr.size() - remaining - 1 + __builtin_ctz(mask);\n        }\n    }\n\n    return -1;\n}\n```"}
{"task_id": "SimdBench_127_SSE", "completion": "```\nint can_arrange_simd(const std::vector<int> & arr){\n    if(arr.size() < 2) return -1;\n\n    __m128i prev = _mm_loadu_si128((__m128i*)&arr[0]);\n    for (int i = 4; i < arr.size(); i += 4) {\n        __m128i current = _mm_loadu_si128((__m128i*)&arr[i]);\n        __m128i cmp = _mm_cmpgt_epi32(prev, current);\n        int mask = _mm_movemask_ps(_mm_castsi128_ps(cmp));\n        if (mask != 0) {\n            int index = i - 4 + __builtin_ctz(mask);\n            return index - 1;\n        }\n        prev = _mm_shuffle_epi32(current, _MM_SHUFFLE(3, 2, 1, 0));\n    }\n\n    int remaining = arr.size() % 4;\n    if (remaining > 1) {\n        __m128i current = _mm_loadu_si128((__m128i*)&arr[arr.size() - remaining]);\n        __m128i cmp = _mm_cmpgt_epi32(prev, current);\n        int mask = _mm_movemask_ps(_mm_castsi128_ps(cmp));\n        if (mask != 0) {\n            int index = arr.size() - remaining - 1 + __builtin_ctz(mask);\n            return index;\n        }\n    }\n\n    return -1;\n}\n```"}
{"task_id": "SimdBench_127_SSE", "completion": "```\nint can_arrange_simd(const std::vector<int> & arr){\n    if(arr.size() < 2) return -1;\n\n    __m128i prev = _mm_loadu_si128((__m128i*)&arr[0]);\n    for(int i = 4; i < arr.size(); i += 4){\n        __m128i curr = _mm_loadu_si128((__m128i*)&arr[i]);\n        __m128i cmp = _mm_cmplt_epi32(curr, prev);\n        int mask = _mm_movemask_ps(_mm_castsi128_ps(cmp));\n        if(mask != 0) {\n            int index = i - 4 + __builtin_ctz(mask);\n            return index;\n        }\n        prev = _mm_shuffle_epi32(curr, _MM_SHUFFLE(3, 2, 1, 0));\n    }\n\n    int remaining = arr.size() % 4;\n    if(remaining > 1){\n        __m128i curr = _mm_loadu_si128((__m128i*)&arr[arr.size() - remaining]);\n        __m128i cmp = _mm_cmplt_epi32(curr, prev);\n        int mask = _mm_movemask_ps(_mm_castsi128_ps(cmp));\n        if(mask != 0) {\n            int index = arr.size() - remaining + __builtin_ctz(mask);\n            return index;\n        }\n    }\n\n    return -1;\n}\n```"}
{"task_id": "SimdBench_128_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nstd::vector<int> largest_smallest_integers_simd(const std::vector<int>& lst){\n    if(lst.empty()) {\n        return {0, 0};\n    }\n\n    __m128i max_neg = _mm_set1_epi32(INT_MIN);\n    __m128i min_pos = _mm_set1_epi32(INT_MAX);\n\n    for(size_t i = 0; i < lst.size(); i += 4) {\n        __m128i values = _mm_loadu_si128((__m128i*)&lst[i]);\n        \n        __m128i neg_mask = _mm_cmplt_epi32(values, _mm_setzero_si128());\n        __m128i pos_mask = _mm_cmpgt_epi32(values, _mm_setzero_si128());\n\n        __m128i neg_values = _mm_and_si128(values, neg_mask);\n        __m128i pos_values = _mm_and_si128(values, pos_mask);\n\n        max_neg = _mm_max_epi32(max_neg, neg_values);\n        min_pos = _mm_min_epi32(min_pos, pos_values);\n    }\n\n    int max_neg_arr[4], min_pos_arr[4];\n    _mm_storeu_si128((__m128i*)max_neg_arr, max_neg);\n    _mm_storeu_si128((__m128i*)min_pos_arr, min_pos);\n\n    int largest_neg = std::max(std::max(max_neg_arr[0], max_neg_arr[1]), std::max(max_neg_arr[2], max_neg_arr[3]);\n    int smallest_pos = std::min(std::min(min_pos_arr[0], min_pos_arr[1]), std::min(min_pos_arr[2], min_pos_arr[3]);\n\n    return {largest_neg, smallest_pos};\n}\n```"}
{"task_id": "SimdBench_128_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nstd::vector<int> largest_smallest_integers_simd(const std::vector<int>& lst){\n    std::vector<int> result = {0, 0};\n    \n    if(lst.empty()){\n        return result;\n    }\n    \n    __m128i max_neg = _mm_set1_epi32(INT_MIN);\n    __m128i min_pos = _mm_set1_epi32(INT_MAX);\n    \n    for(size_t i = 0; i < lst.size(); i += 4){\n        __m128i data = _mm_loadu_si128((__m128i*)&lst[i]);\n        \n        __m128i neg_mask = _mm_cmplt_epi32(data, _mm_setzero_si128());\n        __m128i pos_mask = _mm_cmpgt_epi32(data, _mm_setzero_si128());\n        \n        __m128i neg_values = _mm_and_si128(data, neg_mask);\n        __m128i pos_values = _mm_and_si128(data, pos_mask);\n        \n        max_neg = _mm_max_epi32(max_neg, neg_values);\n        min_pos = _mm_min_epi32(min_pos, pos_values);\n    }\n    \n    int max_neg_arr[4];\n    int min_pos_arr[4];\n    \n    _mm_storeu_si128((__m128i*)max_neg_arr, max_neg);\n    _mm_storeu_si128((__m128i*)min_pos_arr, min_pos);\n    \n    for(int i = 0; i < 4; i++){\n        if(max_neg_arr[i] > result[0]){\n            result[0] = max_neg_arr[i];\n        }\n        if(min_pos_arr[i] < result[1]){\n            result[1] = min_pos_arr[i];\n        }\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_128_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nstd::vector<int> largest_smallest_integers_simd(const std::vector<int>& lst){\n    if(lst.empty()) return {0, 0};\n\n    __m128i max_neg = _mm_set1_epi32(INT_MIN);\n    __m128i min_pos = _mm_set1_epi32(INT_MAX);\n\n    for(size_t i = 0; i < lst.size(); i += 4){\n        __m128i values = _mm_loadu_si128((__m128i*)&lst[i]);\n        \n        __m128i neg_mask = _mm_cmplt_epi32(values, _mm_setzero_si128());\n        __m128i pos_mask = _mm_cmpgt_epi32(values, _mm_setzero_si128());\n\n        __m128i neg_values = _mm_and_si128(values, neg_mask);\n        __m128i pos_values = _mm_and_si128(values, pos_mask);\n\n        max_neg = _mm_max_epi32(max_neg, neg_values);\n        min_pos = _mm_min_epi32(min_pos, pos_values);\n    }\n\n    int max_neg_arr[4], min_pos_arr[4];\n    _mm_storeu_si128((__m128i*)max_neg_arr, max_neg);\n    _mm_storeu_si128((__m128i*)min_pos_arr, min_pos);\n\n    int max_neg_val = std::max({max_neg_arr[0], max_neg_arr[1], max_neg_arr[2], max_neg_arr[3]});\n    int min_pos_val = std::min({min_pos_arr[0], min_pos_arr[1], min_pos_arr[2], min_pos_arr[3]});\n\n    return {max_neg_val, min_pos_val};\n}\n```"}
{"task_id": "SimdBench_128_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nstd::vector<int> largest_smallest_integers_simd(const std::vector<int>& lst){\n    if(lst.empty()) return {0, 0};\n\n    __m128i max_neg = _mm_set1_epi32(INT_MIN);\n    __m128i min_pos = _mm_set1_epi32(INT_MAX);\n\n    for(size_t i = 0; i < lst.size(); i += 4){\n        __m128i values = _mm_loadu_si128((__m128i*)&lst[i]);\n        \n        __m128i neg_mask = _mm_cmplt_epi32(values, _mm_setzero_si128());\n        __m128i pos_mask = _mm_cmpgt_epi32(values, _mm_setzero_si128());\n        \n        __m128i neg_values = _mm_and_si128(values, neg_mask);\n        __m128i pos_values = _mm_and_si128(values, pos_mask);\n        \n        max_neg = _mm_max_epi32(max_neg, neg_values);\n        min_pos = _mm_min_epi32(min_pos, pos_values);\n    }\n\n    int max_neg_arr[4], min_pos_arr[4];\n    _mm_storeu_si128((__m128i*)max_neg_arr, max_neg);\n    _mm_storeu_si128((__m128i*)min_pos_arr, min_pos);\n\n    int max_neg_result = std::max({max_neg_arr[0], max_neg_arr[1], max_neg_arr[2], max_neg_arr[3]});\n    int min_pos_result = std::min({min_pos_arr[0], min_pos_arr[1], min_pos_arr[2], min_pos_arr[3]});\n\n    return {max_neg_result, min_pos_result};\n}\n```"}
{"task_id": "SimdBench_128_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> largest_smallest_integers_simd(const std::vector<int>& lst) {\n    if (lst.empty()) {\n        return {0, 0};\n    }\n\n    __m128i max_neg = _mm_set1_epi32(INT_MIN);\n    __m128i min_pos = _mm_set1_epi32(INT_MAX);\n\n    for (size_t i = 0; i < lst.size(); i += 4) {\n        __m128i values = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&lst[i]));\n        \n        __m128i neg_mask = _mm_cmplt_epi32(values, _mm_setzero_si128());\n        __m128i pos_mask = _mm_cmpgt_epi32(values, _mm_setzero_si128());\n        \n        __m128i neg_values = _mm_and_si128(values, neg_mask);\n        __m128i pos_values = _mm_and_si128(values, pos_mask);\n        \n        max_neg = _mm_max_epi32(max_neg, neg_values);\n        min_pos = _mm_min_epi32(min_pos, pos_values);\n    }\n\n    int max_neg_arr[4];\n    int min_pos_arr[4];\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(max_neg_arr), max_neg);\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(min_pos_arr), min_pos);\n\n    int max_neg_result = std::max(std::max(max_neg_arr[0], max_neg_arr[1]), std::max(max_neg_arr[2], max_neg_arr[3]);\n    int min_pos_result = std::min(std::min(min_pos_arr[0], min_pos_arr[1]), std::min(min_pos_arr[2], min_pos_arr[3]);\n\n    return {max_neg_result, min_pos_result};\n}\n```"}
{"task_id": "SimdBench_129_SSE", "completion": "```c\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nuint64_t special_factorial_simd(uint64_t n){\n    __m128i result = _mm_set_epi64x(1, 1);\n    __m128i factorials = _mm_set_epi64x(1, 1);\n    \n    for (uint64_t i = 1; i <= n; i++) {\n        factorials = _mm_mul_epu32(factorials, _mm_set_epi64x(i, i-1));\n        result = _mm_mul_epu32(result, factorials);\n    }\n    \n    uint64_t final_result[2];\n    _mm_store_si128((__m128i*)final_result, result);\n    \n    return final_result[0] * final_result[1];\n}\n```  "}
{"task_id": "SimdBench_129_SSE", "completion": "```c\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nuint64_t special_factorial_simd(uint64_t n){\n    __m128i result = _mm_set1_epi64x(1);\n    __m128i multiplier = _mm_set_epi64x(1, 2);\n    \n    for(uint64_t i = 3; i <= n; i++){\n        multiplier = _mm_mul_epu32(multiplier, _mm_set_epi64x(i-1, i));\n        result = _mm_mul_epu32(result, multiplier);\n    }\n    \n    uint64_t final_result[2];\n    _mm_store_si128((__m128i*)final_result, result);\n    \n    return final_result[0] * final_result[1];\n}\n```"}
{"task_id": "SimdBench_129_SSE", "completion": "```c\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nuint64_t special_factorial_simd(uint64_t n){\n    __m128i result = _mm_set1_epi64x(1);\n    __m128i multiplier = _mm_set_epi64x(1, 2);\n    \n    for(uint64_t i = 3; i <= n; i++){\n        __m128i current = _mm_set1_epi64x(i);\n        multiplier = _mm_mul_epu32(multiplier, current);\n        result = _mm_mul_epu32(result, multiplier);\n    }\n    \n    uint64_t final_result[2];\n    _mm_store_si128((__m128i*)final_result, result);\n    \n    return final_result[0] * final_result[1];\n}\n```"}
{"task_id": "SimdBench_129_SSE", "completion": "```c\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nuint64_t special_factorial_simd(uint64_t n){\n    __m128i result = _mm_set1_epi64x(1);\n    __m128i multiplier = _mm_set_epi64x(1, 2);\n    \n    for(uint64_t i = 3; i <= n; i++){\n        multiplier = _mm_mul_epu32(multiplier, _mm_set_epi64x(i, i-1));\n        result = _mm_mul_epu32(result, multiplier);\n    }\n    \n    uint64_t final_result[2];\n    _mm_storeu_si128((__m128i*)final_result, result);\n    \n    return final_result[0] * final_result[1];\n}\n```"}
{"task_id": "SimdBench_129_SSE", "completion": "```c\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nuint64_t special_factorial_simd(uint64_t n){\n    __m128i result = _mm_set1_epi64x(1);\n    __m128i multiplier = _mm_set_epi64x(1, 2);\n    \n    for(uint64_t i = 3; i <= n; i++){\n        multiplier = _mm_mul_epu32(multiplier, _mm_set_epi64x(i, i-1));\n        result = _mm_mul_epu32(result, multiplier);\n    }\n    \n    uint64_t final_result[2];\n    _mm_storeu_si128((__m128i*)final_result, result);\n    \n    return final_result[0] * final_result[1];\n}\n```  "}
{"task_id": "SimdBench_130_SSE", "completion": "```\nint sum_squares_simd(const std::vector<int> & lst){\n    int sum = 0;\n    __m128i square_mask = _mm_set_epi32(0, 0, 1, 0);\n    __m128i cube_mask = _mm_set_epi32(0, 0, 0, 1);\n    __m128i result = _mm_setzero_si128();\n    \n    for (int i = 0; i < lst.size(); i += 4) {\n        __m128i values = _mm_loadu_si128((__m128i*)&lst[i]);\n        __m128i indices = _mm_set_epi32(i+3, i+2, i+1, i);\n        \n        __m128i is_square = _mm_cmpeq_epi32(_mm_and_si128(indices, square_mask), _mm_setzero_si128());\n        __m128i is_cube = _mm_and_si128(_mm_cmpeq_epi32(_mm_and_si128(indices, cube_mask), _mm_setzero_si128()), _mm_cmpeq_epi32(is_square, _mm_setzero_si128()));\n        \n        __m128i squared_values = _mm_mullo_epi32(values, values);\n        __m128i cubed_values = _mm_mullo_epi32(_mm_mullo_epi32(values, values), values);\n        \n        result = _mm_add_epi32(result, _mm_or_si128(_mm_and_si128(is_square, squared_values), _mm_and_si128(is_cube, cubed_values)));\n    }\n    \n    int temp[4];\n    _mm_storeu_si128((__m128i*)temp, result);\n    sum = temp[0] + temp[1] + temp[2] + temp[3];\n    \n    return sum;\n}\n```"}
{"task_id": "SimdBench_130_SSE", "completion": "```\nint sum_squares_simd(const std::vector<int> & lst){\n    int sum = 0;\n    __m128i square_mask = _mm_set_epi32(0, 0, 1, 0);\n    __m128i cube_mask = _mm_set_epi32(0, 0, 0, 1);\n    __m128i result = _mm_setzero_si128();\n\n    for (int i = 0; i < lst.size(); i += 4) {\n        __m128i values = _mm_loadu_si128((__m128i*)&lst[i]);\n        __m128i indices = _mm_set_epi32(i + 3, i + 2, i + 1, i);\n\n        __m128i is_square = _mm_cmpeq_epi32(_mm_and_si128(indices, square_mask), _mm_setzero_si128());\n        __m128i is_cube = _mm_and_si128(_mm_cmpeq_epi32(_mm_and_si128(indices, cube_mask), _mm_setzero_si128()), _mm_cmpeq_epi32(is_square, _mm_setzero_si128()));\n\n        __m128i squares = _mm_mullo_epi32(values, values);\n        __m128i cubes = _mm_mullo_epi32(_mm_mullo_epi32(values, values), values);\n\n        result = _mm_add_epi32(result, _mm_or_si128(_mm_and_si128(is_square, squares), _mm_and_si128(is_cube, cubes)));\n    }\n\n    int temp[4];\n    _mm_storeu_si128((__m128i*)temp, result);\n    sum = temp[0] + temp[1] + temp[2] + temp[3];\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_130_SSE", "completion": "```\nint sum_squares_simd(const std::vector<int> & lst){\n    int sum = 0;\n    __m128i square_mask = _mm_set_epi32(0, 0, 1, 0);\n    __m128i cube_mask = _mm_set_epi32(0, 0, 0, 1);\n    \n    for (int i = 0; i < lst.size(); i += 4) {\n        __m128i vec = _mm_loadu_si128((__m128i*)&lst[i]);\n        __m128i index = _mm_set_epi32(i+3, i+2, i+1, i);\n        \n        __m128i is_square = _mm_cmpeq_epi32(_mm_and_si128(index, square_mask), square_mask);\n        __m128i is_cube = _mm_and_si128(_mm_cmpeq_epi32(_mm_and_si128(index, cube_mask), cube_mask), _mm_xor_si128(is_square, _mm_set1_epi32(-1)));\n        \n        __m128i square_values = _mm_mullo_epi32(vec, vec);\n        __m128i cube_values = _mm_mullo_epi32(_mm_mullo_epi32(vec, vec), vec);\n        \n        __m128i result = _mm_or_si128(_mm_and_si128(is_square, square_values), _mm_and_si128(is_cube, cube_values));\n        \n        sum += _mm_extract_epi32(result, 0) + _mm_extract_epi32(result, 1) + _mm_extract_epi32(result, 2) + _mm_extract_epi32(result, 3);\n    }\n    \n    return sum;\n}\n```"}
{"task_id": "SimdBench_130_SSE", "completion": "```\nint sum_squares_simd(const std::vector<int> & lst){\n    int sum = 0;\n    __m128i square_mask = _mm_set_epi32(0, 0, 1, 0);\n    __m128i cube_mask = _mm_set_epi32(0, 0, 0, 1);\n    \n    for (int i = 0; i < lst.size(); i += 4) {\n        __m128i values = _mm_loadu_si128((__m128i*)&lst[i]);\n        __m128i indices = _mm_set_epi32(i + 3, i + 2, i + 1, i);\n        \n        __m128i is_square = _mm_cmpeq_epi32(_mm_and_si128(indices, square_mask), square_mask);\n        __m128i is_cube = _mm_and_si128(_mm_cmpeq_epi32(_mm_and_si128(indices, cube_mask), cube_mask), _mm_cmpeq_epi32(is_square, _mm_setzero_si128()));\n        \n        __m128i squares = _mm_mullo_epi32(values, values);\n        __m128i cubes = _mm_mullo_epi32(_mm_mullo_epi32(values, values), values);\n        \n        __m128i result = _mm_or_si128(_mm_and_si128(is_square, squares), _mm_and_si128(is_cube, cubes));\n        \n        sum += _mm_extract_epi32(result, 0) + _mm_extract_epi32(result, 1) + _mm_extract_epi32(result, 2) + _mm_extract_epi32(result, 3);\n    }\n    \n    return sum;\n}\n```"}
{"task_id": "SimdBench_130_SSE", "completion": "```\nint sum_squares_simd(const std::vector<int> & lst){\n    int sum = 0;\n    __m128i square_mask = _mm_set_epi32(0, 0, 1, 0);\n    __m128i cube_mask = _mm_set_epi32(0, 0, 0, 1);\n    __m128i result = _mm_setzero_si128();\n    \n    for (size_t i = 0; i < lst.size(); i += 4) {\n        __m128i values = _mm_loadu_si128((__m128i*)&lst[i]);\n        __m128i indexes = _mm_set_epi32(i + 3, i + 2, i + 1, i);\n        \n        __m128i is_square = _mm_cmpeq_epi32(_mm_and_si128(indexes, square_mask), square_mask);\n        __m128i is_cube = _mm_and_si128(_mm_cmpeq_epi32(_mm_and_si128(indexes, cube_mask), cube_mask), _mm_cmpeq_epi32(is_square, _mm_setzero_si128()));\n        \n        __m128i squares = _mm_mullo_epi32(values, values);\n        __m128i cubes = _mm_mullo_epi32(_mm_mullo_epi32(values, values), values);\n        \n        result = _mm_add_epi32(result, _mm_or_si128(_mm_and_si128(is_square, squares), _mm_and_si128(is_cube, cubes)));\n    }\n    \n    int temp[4];\n    _mm_storeu_si128((__m128i*)temp, result);\n    sum = temp[0] + temp[1] + temp[2] + temp[3];\n    \n    return sum;\n}\n```"}
{"task_id": "SimdBench_131_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint specialFilter_simd(const std::vector<int> & nums){\n    int count = 0;\n    __m128i oddDigits = _mm_set_epi8(9, 7, 5, 3, 1, 9, 7, 5, 3, 1, 9, 7, 5, 3, 1, 9);\n    __m128i threshold = _mm_set1_epi32(10);\n    __m128i zero = _mm_setzero_si128();\n    \n    for (size_t i = 0; i < nums.size(); i += 4) {\n        __m128i vec = _mm_loadu_si128((__m128i*)&nums[i]);\n        \n        __m128i firstDigits = _mm_and_si128(vec, _mm_set1_epi32(0x0000000F));\n        __m128i lastDigits = _mm_and_si128(_mm_srli_epi32(vec, 28), _mm_set1_epi32(0x0000000F));\n        \n        __m128i oddFirstDigits = _mm_cmpeq_epi8(_mm_and_si128(firstDigits, oddDigits), zero);\n        __m128i oddLastDigits = _mm_cmpeq_epi8(_mm_and_si128(lastDigits, oddDigits), zero);\n        \n        __m128i greaterThan10 = _mm_cmpgt_epi32(vec, threshold);\n        \n        __m128i oddFirstLastDigits = _mm_and_si128(oddFirstDigits, oddLastDigits);\n        __m128i result = _mm_and_si128(oddFirstLastDigits, greaterThan10);\n        \n        count += _mm_popcnt_u32(_mm_movemask_epi8(result));\n    }\n    \n    return count;\n}\n```"}
{"task_id": "SimdBench_131_SSE", "completion": "```cpp\nint specialFilter_simd(const std::vector<int> & nums){\n    const __m128i odd_digits = _mm_set_epi8(9, 7, 5, 3, 1, 9, 7, 5, 3, 1, 9, 7, 5, 3, 1, 9);\n    const __m128i ten = _mm_set1_epi8(10);\n    const __m128i zero = _mm_setzero_si128();\n    int count = 0;\n\n    for (size_t i = 0; i < nums.size(); i += 4) {\n        __m128i vec = _mm_loadu_si128((__m128i*)&nums[i]);\n        \n        __m128i abs_vec = _mm_abs_epi8(vec);\n        __m128i first_digit = _mm_and_si128(abs_vec, odd_digits);\n        __m128i last_digit = _mm_shuffle_epi32(abs_vec, _MM_SHUFFLE(0, 3, 2, 1));\n        last_digit = _mm_and_si128(last_digit, odd_digits);\n        \n        __m128i compare_ten = _mm_cmpgt_epi8(vec, ten);\n        __m128i compare_first_last = _mm_and_si128(first_digit, last_digit);\n        compare_first_last = _mm_cmpeq_epi8(compare_first_last, zero);\n        \n        __m128i result = _mm_and_si128(compare_ten, compare_first_last);\n        \n        count += _mm_popcnt_u32(_mm_movemask_epi8(result));\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_131_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint specialFilter_simd(const std::vector<int> & nums){\n    const __m128i oddDigits = _mm_set_epi8(9, 7, 5, 3, 1, 9, 7, 5, 3, 1, 9, 7, 5, 3, 1, 9);\n    const __m128i ten = _mm_set1_epi8(10);\n    const __m128i zero = _mm_setzero_si128();\n    int count = 0;\n\n    for (size_t i = 0; i < nums.size(); i += 4) {\n        __m128i vec = _mm_loadu_si128((__m128i*)&nums[i]);\n        __m128i absVec = _mm_abs_epi8(vec);\n        __m128i firstDigit = _mm_and_si128(absVec, oddDigits);\n        __m128i lastDigit = _mm_shuffle_epi32(absVec, _MM_SHUFFLE(0, 3, 2, 1));\n        lastDigit = _mm_and_si128(lastDigit, oddDigits);\n        __m128i compareTen = _mm_cmpgt_epi8(vec, ten);\n        __m128i bothDigitsOdd = _mm_and_si128(firstDigit, lastDigit);\n        __m128i result = _mm_and_si128(compareTen, bothDigitsOdd);\n        count += _mm_popcnt_u32(_mm_movemask_epi8(result));\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_131_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint specialFilter_simd(const std::vector<int> & nums){\n    int count = 0;\n    __m128i oddDigits = _mm_set_epi8(9, 7, 5, 3, 1, 9, 7, 5, 3, 1, 9, 7, 5, 3, 1, 9);\n    __m128i threshold = _mm_set1_epi32(10);\n    __m128i zero = _mm_setzero_si128();\n    \n    for (size_t i = 0; i < nums.size(); i += 4) {\n        __m128i vec = _mm_loadu_si128((__m128i*)&nums[i]);\n        \n        __m128i firstDigit = _mm_and_si128(vec, _mm_set1_epi32(15));\n        __m128i lastDigit = _mm_and_si128(_mm_srli_epi32(vec, 28), _mm_set1_epi32(15));\n        \n        __m128i oddFirst = _mm_cmpeq_epi8(_mm_cmplt_epi8(firstDigit, oddDigits), zero);\n        __m128i oddLast = _mm_cmpeq_epi8(_mm_cmplt_epi8(lastDigit, oddDigits), zero);\n        \n        __m128i oddFirstLast = _mm_and_si128(oddFirst, oddLast);\n        \n        __m128i aboveThreshold = _mm_cmpgt_epi32(vec, threshold);\n        \n        __m128i result = _mm_and_si128(oddFirstLast, aboveThreshold);\n        \n        count += _mm_popcnt_u32(_mm_movemask_epi8(result));\n    }\n    \n    return count;\n}\n```"}
{"task_id": "SimdBench_131_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint specialFilter_simd(const std::vector<int> & nums){\n    const __m128i oddDigits = _mm_set_epi8(9, 7, 5, 3, 1, 9, 7, 5, 3, 1, 9, 7, 5, 3, 1, 9);\n    const __m128i ten = _mm_set1_epi8(10);\n    const __m128i zero = _mm_setzero_si128();\n    int count = 0;\n\n    for (size_t i = 0; i < nums.size(); i += 4) {\n        __m128i vec = _mm_loadu_si128((__m128i*)&nums[i]);\n        \n        __m128i firstDigit = _mm_and_si128(vec, oddDigits);\n        __m128i lastDigit = _mm_shuffle_epi32(vec, _MM_SHUFFLE(0, 3, 2, 1));\n        lastDigit = _mm_and_si128(lastDigit, oddDigits);\n\n        __m128i compareTen = _mm_cmpgt_epi8(vec, ten);\n        __m128i compareFirstLast = _mm_and_si128(_mm_cmpeq_epi8(firstDigit, zero), _mm_cmpeq_epi8(lastDigit, zero));\n        __m128i result = _mm_and_si128(compareTen, compareFirstLast);\n\n        count += _mm_popcnt_u32(_mm_movemask_epi8(result));\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_132_SSE", "completion": "```c\nuint64_t get_max_triples_simd(uint64_t n){\n    __m128i increment = _mm_set1_epi32(1);\n    __m128i i_values = _mm_set_epi32(4, 3, 2, 1);\n    __m128i result = _mm_setzero_si128();\n    uint64_t count = 0;\n\n    for (uint64_t i = 1; i <= n; i += 4) {\n        __m128i i_squared = _mm_mullo_epi32(i_values, i_values);\n        __m128i a_values = _mm_sub_epi32(i_squared, increment);\n        __m128i sum = _mm_add_epi32(a_values, _mm_shuffle_epi32(a_values, _MM_SHUFFLE(0, 3, 2, 1)));\n        sum = _mm_add_epi32(sum, _mm_shuffle_epi32(sum, _MM_SHUFFLE(0, 3, 2, 1)));\n        __m128i divisible_by_3 = _mm_cmpeq_epi32(_mm_setzero_si128(), _mm_and_si128(sum, _mm_set1_epi32(3)));\n        count += _mm_popcnt_u32(_mm_movemask_epi8(divisible_by_3));\n\n        i_values = _mm_add_epi32(i_values, _mm_set1_epi32(4));\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_132_SSE", "completion": "```c\nuint64_t get_max_triples_simd(uint64_t n){\n    uint64_t count = 0;\n    __m128i increment = _mm_set1_epi64x(1);\n    __m128i mul = _mm_set1_epi64x(3);\n    __m128i sum = _mm_set1_epi64x(0);\n    \n    for (uint64_t i = 1; i <= n; i += 2) {\n        __m128i idx = _mm_set_epi64x(i+1, i);\n        __m128i square = _mm_mul_epu32(idx, idx);\n        __m128i a = _mm_sub_epi64(square, increment);\n        \n        sum = _mm_add_epi64(sum, a);\n        \n        if (i % 6 == 5) {\n            __m128i mod = _mm_and_si128(sum, _mm_set1_epi64x(3));\n            __m128i cmp = _mm_cmpeq_epi64(mod, _mm_setzero_si128());\n            count += _mm_popcnt_u64(_mm_movemask_epi8(cmp));\n            sum = _mm_setzero_si128();\n        }\n    }\n    \n    return count;\n}\n```"}
{"task_id": "SimdBench_132_SSE", "completion": "```c\nuint64_t get_max_triples_simd(uint64_t n){\n    uint64_t count = 0;\n    __m128i increment = _mm_set1_epi64x(1);\n    __m128i increment2 = _mm_set1_epi64x(2);\n    __m128i threes = _mm_set1_epi64x(3);\n    __m128i result = _mm_setzero_si128();\n    \n    for (uint64_t i = 1; i <= n; i += 2){\n        __m128i indices = _mm_set_epi64x(i+1, i, i+1, i);\n        __m128i values = _mm_mul_epu32(indices, _mm_sub_epi64(indices, increment));\n        values = _mm_add_epi64(values, increment);\n        \n        __m128i sum = _mm_hadd_epi32(values, values);\n        sum = _mm_hadd_epi32(sum, sum);\n        \n        result = _mm_add_epi64(result, _mm_and_si128(_mm_cmpeq_epi64(_mm_setzero_si128(), _mm_setzero_si128()), _mm_cmpeq_epi64(_mm_setzero_si128(), _mm_setzero_si128())));\n        result = _mm_add_epi64(result, _mm_and_si128(_mm_cmpeq_epi64(_mm_setzero_si128(), _mm_setzero_si128()), _mm_cmpeq_epi64(_mm_setzero_si128(), _mm_setzero_si128())));\n        result = _mm_add_epi64(result, _mm_and_si128(_mm_cmpeq_epi64(_mm_setzero_si128(), _mm_setzero_si128()), _mm_cmpeq_epi64(_mm_setzero_si128(), _mm_setzero_si128())));\n    }\n    \n    count += _mm_extract_epi64(result, 0) + _mm_extract_epi64(result, 1) + _mm_extract_epi64(result, 2) + _mm_extract_epi64(result, 3);\n    \n    return count;\n}\n```"}
{"task_id": "SimdBench_132_SSE", "completion": "```c\nuint64_t get_max_triples_simd(uint64_t n){\n    __m128i increment = _mm_set1_epi32(1);\n    __m128i increment2 = _mm_set1_epi32(2);\n    __m128i increment3 = _mm_set1_epi32(3);\n    __m128i result = _mm_setzero_si128();\n    uint64_t count = 0;\n\n    for (uint64_t i = 1; i <= n; i += 4) {\n        __m128i indices = _mm_set_epi32(i+3, i+2, i+1, i);\n        __m128i values = _mm_mullo_epi32(indices, indices);\n        values = _mm_sub_epi32(values, indices);\n        values = _mm_add_epi32(values, increment);\n\n        __m128i sum = _mm_setzero_si128();\n        sum = _mm_add_epi32(sum, values);\n        sum = _mm_shuffle_epi32(sum, _MM_SHUFFLE(2, 1, 0, 3));\n        sum = _mm_add_epi32(sum, values);\n        sum = _mm_shuffle_epi32(sum, _MM_SHUFFLE(1, 0, 3, 2));\n        sum = _mm_add_epi32(sum, values);\n\n        __m128i mod3 = _mm_and_si128(sum, increment2);\n        mod3 = _mm_cmpeq_epi32(mod3, _mm_setzero_si128());\n        mod3 = _mm_and_si128(mod3, _mm_cmplt_epi32(indices, _mm_set1_epi32(n)));\n\n        result = _mm_add_epi32(result, mod3);\n    }\n\n    int* res = (int*)&result;\n    for (int i = 0; i < 4; i++) {\n        count += res[i];\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_132_SSE", "completion": "```c\nuint64_t get_max_triples_simd(uint64_t n){\n    __m128i increment = _mm_set1_epi32(1);\n    __m128i increment2 = _mm_set1_epi32(2);\n    __m128i threes = _mm_set1_epi32(3);\n    __m128i count = _mm_setzero_si128();\n    \n    for (uint64_t i = 1; i <= n; i += 4) {\n        __m128i indices = _mm_setr_epi32(i, i+1, i+2, i+3);\n        __m128i i_squared = _mm_mullo_epi32(indices, indices);\n        __m128i a = _mm_sub_epi32(i_squared, indices);\n        a = _mm_add_epi32(a, increment);\n        \n        __m128i a_mod = _mm_and_si128(a, threes);\n        __m128i cmp = _mm_cmpeq_epi32(a_mod, _mm_setzero_si128());\n        \n        __m128i a_perm = _mm_shuffle_epi32(a, _MM_SHUFFLE(2, 1, 0, 3));\n        __m128i a_sum = _mm_add_epi32(a, a_perm);\n        a_sum = _mm_add_epi32(a_sum, _mm_shuffle_epi32(a_sum, _MM_SHUFFLE(1, 0, 3, 2)));\n        \n        __m128i valid = _mm_and_si128(cmp, _mm_cmpeq_epi32(a_sum, _mm_setzero_si128()));\n        count = _mm_add_epi32(count, valid);\n    }\n    \n    uint32_t result[4];\n    _mm_storeu_si128((__m128i*)result, count);\n    \n    return result[0] + result[1] + result[2] + result[3];\n}\n```"}
{"task_id": "SimdBench_133_SSE", "completion": "```c\nint x_or_y_simd(int n, int x, int y){\n    __m128i mask = _mm_set1_epi32(1);\n    __m128i num = _mm_set1_epi32(n);\n    __m128i prime_mask = _mm_cmpeq_epi32(_mm_set1_epi32(1), _mm_and_si128(_mm_cmpeq_epi32(_mm_set1_epi32(1), num), _mm_cmpeq_epi32(_mm_set1_epi32(n), num)));\n    __m128i result = _mm_or_si128(_mm_and_si128(prime_mask, _mm_set1_epi32(x)), _mm_andnot_si128(prime_mask, _mm_set1_epi32(y)));\n    return _mm_cvtsi128_si32(result);\n}\n```"}
{"task_id": "SimdBench_133_SSE", "completion": "```c\nint x_or_y_simd(int n, int x, int y){\n    __m128i mask = _mm_set1_epi32(1);\n    __m128i num = _mm_set1_epi32(n);\n    __m128i cmp = _mm_cmpeq_epi32(_mm_setzero_si128(), _mm_setzero_si128());\n    __m128i result = _mm_blendv_epi8(_mm_set1_epi32(y), _mm_set1_epi32(x), _mm_cmpeq_epi32(num, mask));\n    return _mm_cvtsi128_si32(result);\n}\n```"}
{"task_id": "SimdBench_133_SSE", "completion": "```c\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint x_or_y_simd(int n, int x, int y){\n    int result;\n    __m128i mask = _mm_set1_epi32(1);\n    __m128i num = _mm_set1_epi32(n);\n    __m128i prime_mask = _mm_cmpeq_epi32(_mm_set1_epi32(1), _mm_set1_epi32(1));\n    for (int i = 2; i * i <= n; i++) {\n        if (n % i == 0) {\n            prime_mask = _mm_andnot_si128(prime_mask, mask);\n            break;\n        }\n    }\n    __m128i x_val = _mm_set1_epi32(x);\n    __m128i y_val = _mm_set1_epi32(y);\n    __m128i result_vec = _mm_or_si128(_mm_and_si128(prime_mask, x_val), _mm_andnot_si128(prime_mask, y_val));\n    _mm_storeu_si128((__m128i*)&result, result_vec);\n    return result;\n}\n```"}
{"task_id": "SimdBench_133_SSE", "completion": "```c\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint x_or_y_simd(int n, int x, int y){\n    __m128i mask = _mm_set1_epi32(1);\n    __m128i num = _mm_set1_epi32(n);\n    __m128i zero = _mm_setzero_si128();\n    \n    __m128i cmp = _mm_cmpeq_epi32(_mm_and_si128(num, mask), zero);\n    \n    if (_mm_movemask_epi8(cmp) == 0xFFFF) {\n        return x;\n    } else {\n        return y;\n    }\n}\n```  "}
{"task_id": "SimdBench_133_SSE", "completion": "```c\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint x_or_y_simd(int n, int x, int y){\n    __m128i mask = _mm_set1_epi32(1);\n    __m128i num = _mm_set1_epi32(n);\n    __m128i zero = _mm_setzero_si128();\n    \n    __m128i cmp = _mm_cmpeq_epi32(_mm_and_si128(num, mask), zero);\n    \n    if(_mm_movemask_epi8(cmp) == 0xFFFF){\n        return x;\n    } else {\n        return y;\n    }\n}\n```"}
{"task_id": "SimdBench_134_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nuint64_t double_the_difference_simd(const std::vector<float> & lst){\n    __m128i sum = _mm_setzero_si128();\n    __m128i mask = _mm_set1_epi32(0x80000000); // Mask to check if number is negative\n    __m128i odd_mask = _mm_set1_epi32(0x00000001); // Mask to check if number is odd\n\n    for (size_t i = 0; i < lst.size(); i += 4) {\n        __m128i values = _mm_loadu_si128((__m128i*)&lst[i]);\n        __m128i squared_values = _mm_mullo_epi32(values, values);\n\n        // Check if numbers are negative or not integers\n        __m128i is_valid = _mm_cmpeq_epi32(_mm_andnot_si128(mask, values), _mm_setzero_si128());\n\n        // Check if numbers are odd\n        __m128i is_odd = _mm_and_si128(_mm_cmpeq_epi32(_mm_and_si128(values, odd_mask), _mm_setzero_si128()), is_valid);\n\n        // Accumulate the sum of squares of odd numbers\n        sum = _mm_add_epi32(sum, _mm_and_si128(squared_values, is_odd));\n    }\n\n    // Horizontal sum of the 4 integers in the sum register\n    __m128i sum_perm = _mm_hadd_epi32(sum, sum);\n    __m128i sum_perm_perm = _mm_hadd_epi32(sum_perm, sum_perm);\n\n    // Extract the final sum from the SSE register\n    uint64_t result = _mm_cvtsi128_si64(sum_perm_perm);\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_134_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nuint64_t double_the_difference_simd(const std::vector<float> & lst){\n    __m128i sum = _mm_setzero_si128();\n    __m128i mask_odd = _mm_set1_epi32(0x55555555); // Mask to check if number is odd\n    __m128i mask_negative = _mm_set1_epi32(0x80000000); // Mask to check if number is negative\n    __m128i mask_integer = _mm_set1_epi32(0x7F800000); // Mask to check if number is integer\n\n    for (size_t i = 0; i < lst.size(); i += 4) {\n        __m128 values = _mm_loadu_ps(&lst[i]);\n        \n        // Check if numbers are odd, not negative, and integers\n        __m128i odd_mask = _mm_and_si128(_mm_castps_si128(values), mask_odd);\n        __m128i negative_mask = _mm_and_si128(_mm_castps_si128(values), mask_negative);\n        __m128i integer_mask = _mm_and_si128(_mm_castps_si128(values), mask_integer);\n        \n        // Check if all conditions are met\n        __m128i odd_and_not_negative = _mm_andnot_si128(negative_mask, odd_mask);\n        __m128i odd_and_not_negative_and_integer = _mm_and_si128(odd_and_not_negative, integer_mask);\n        \n        // Square the odd integers\n        __m128 squared_values = _mm_mul_ps(values, values);\n        \n        // Accumulate the sum of squares of odd integers\n        sum = _mm_add_epi32(sum, _mm_cvtps_epi32(_mm_and_ps(_mm_castsi128_ps(odd_and_not_negative_and_integer), squared_values)));\n    }\n\n    // Horizontal sum of the 4 integers in the sum vector\n    __m128i sum_horizontal = _mm_hadd_epi32(sum, sum);\n    sum_horizontal = _mm_hadd_epi32(sum_horizontal, sum_horizontal);\n\n    return _mm_cvtsi128_si64(sum_horizontal);\n}\n```"}
{"task_id": "SimdBench_134_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nuint64_t double_the_difference_simd(const std::vector<float> & lst){\n    __m128i sum = _mm_setzero_si128();\n    __m128i mask = _mm_set1_epi32(0x80000000); // Mask to check if number is negative\n    __m128i odd_mask = _mm_set1_epi32(0x00000001); // Mask to check if number is odd\n\n    for (size_t i = 0; i < lst.size(); i += 4) {\n        __m128i values = _mm_loadu_si128((__m128i*)&lst[i]);\n        __m128i is_negative = _mm_cmplt_epi32(values, _mm_setzero_si128());\n        __m128i is_integer = _mm_cvttps_epi32(_mm_cmpeq_ps(_mm_cvtepi32_ps(values), _mm_loadu_si128((__m128i*)&lst[i])));\n        __m128i is_odd = _mm_and_si128(_mm_and_si128(is_integer, _mm_and_si128(is_negative, _mm_and_si128(values, odd_mask))), odd_mask);\n        __m128i squares = _mm_mullo_epi32(values, values);\n        sum = _mm_add_epi32(sum, _mm_and_si128(squares, is_odd));\n    }\n\n    uint64_t result = 0;\n    result += _mm_extract_epi32(sum, 0);\n    result += _mm_extract_epi32(sum, 1);\n    result += _mm_extract_epi32(sum, 2);\n    result += _mm_extract_epi32(sum, 3);\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_134_SSE", "completion": "```cpp\nuint64_t double_the_difference_simd(const std::vector<float> & lst){\n    __m128i sum = _mm_setzero_si128();\n    __m128i mask_odd = _mm_set1_epi32(0x55555555); // Mask for odd numbers\n    __m128i mask_positive = _mm_set1_epi32(0x80000000); // Mask for positive numbers\n    __m128i zero = _mm_setzero_si128();\n    __m128i result = _mm_setzero_si128();\n    \n    for (size_t i = 0; i < lst.size(); i += 4) {\n        __m128i vec = _mm_loadu_si128((__m128i*)&lst[i]);\n        \n        // Check if numbers are odd, positive, and integers\n        __m128i odd_mask = _mm_and_si128(_mm_cmpeq_epi32(_mm_and_si128(vec, mask_odd), zero), _mm_cmpeq_epi32(_mm_and_si128(vec, mask_positive), zero));\n        \n        // Square the odd numbers\n        __m128i squared_odd = _mm_mullo_epi32(vec, vec);\n        \n        // Mask out non-odd numbers\n        __m128i odd_numbers = _mm_and_si128(squared_odd, odd_mask);\n        \n        // Add the squared odd numbers to the result\n        result = _mm_add_epi32(result, odd_numbers);\n    }\n    \n    // Horizontal add to get the final sum\n    __m128i sum_128 = _mm_hadd_epi32(result, result);\n    sum_128 = _mm_hadd_epi32(sum_128, sum_128);\n    \n    return _mm_cvtsi128_si64(sum_128);\n}\n```"}
{"task_id": "SimdBench_134_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nuint64_t double_the_difference_simd(const std::vector<float> & lst){\n    __m128i odd_mask = _mm_set1_epi32(0x55555555); // Mask to check if number is odd\n    __m128 sum = _mm_setzero_ps();\n    \n    for (size_t i = 0; i < lst.size(); i += 4) {\n        __m128 values = _mm_loadu_ps(&lst[i]);\n        \n        // Check if numbers are odd\n        __m128i int_values = _mm_cvtps_epi32(values);\n        __m128i odd_values = _mm_and_si128(int_values, odd_mask);\n        \n        // Square the odd numbers\n        __m128 squared_values = _mm_mul_ps(_mm_cvtepi32_ps(odd_values), _mm_cvtepi32_ps(odd_values));\n        \n        // Add the squares to the sum\n        sum = _mm_add_ps(sum, squared_values);\n    }\n    \n    alignas(16) float sum_arr[4];\n    _mm_store_ps(sum_arr, sum);\n    \n    return static_cast<uint64_t>(sum_arr[0] + sum_arr[1] + sum_arr[2] + sum_arr[3]);\n}\n```"}
{"task_id": "SimdBench_135_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nstd::vector<int> compare_simd(const std::vector<int>& game, const std::vector<int>& guess){\n    std::vector<int> result(game.size());\n    const int size = game.size();\n    \n    for (int i = 0; i < size; i += 4) {\n        __m128i game_vec = _mm_loadu_si128((__m128i*)&game[i]);\n        __m128i guess_vec = _mm_loadu_si128((__m128i*)&guess[i]);\n        \n        __m128i diff = _mm_abs_epi32(_mm_sub_epi32(game_vec, guess_vec));\n        \n        _mm_storeu_si128((__m128i*)&result[i], diff);\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_135_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nstd::vector<int> compare_simd(const std::vector<int>& game, const std::vector<int>& guess){\n    size_t size = game.size();\n    std::vector<int> result(size);\n\n    for (size_t i = 0; i < size; i += 4) {\n        __m128i game_vec = _mm_loadu_si128((__m128i*)&game[i]);\n        __m128i guess_vec = _mm_loadu_si128((__m128i*)&guess[i]);\n\n        __m128i diff = _mm_abs_epi32(_mm_sub_epi32(game_vec, guess_vec));\n\n        _mm_storeu_si128((__m128i*)&result[i], diff);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_135_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nstd::vector<int> compare_simd(const std::vector<int>& game, const std::vector<int>& guess){\n    size_t n = game.size();\n    std::vector<int> result(n);\n\n    for (size_t i = 0; i < n; i += 4) {\n        __m128i game_vec = _mm_loadu_si128((__m128i*)&game[i]);\n        __m128i guess_vec = _mm_loadu_si128((__m128i*)&guess[i]);\n\n        __m128i diff = _mm_abs_epi32(_mm_sub_epi32(game_vec, guess_vec));\n\n        _mm_storeu_si128((__m128i*)&result[i], diff);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_135_SSE", "completion": "```cpp\nstd::vector<int> compare_simd(const std::vector<int>& game, const std::vector<int>& guess){\n    size_t size = game.size();\n    std::vector<int> result(size);\n\n    for (size_t i = 0; i < size; i += 4) {\n        __m128i game_vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&game[i]));\n        __m128i guess_vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&guess[i]));\n\n        __m128i diff = _mm_abs_epi32(_mm_sub_epi32(game_vec, guess_vec));\n\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i]), diff);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_135_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nstd::vector<int> compare_simd(const std::vector<int>& game, const std::vector<int>& guess){\n    size_t size = game.size();\n    std::vector<int> result(size);\n\n    for (size_t i = 0; i < size; i += 4) {\n        __m128i game_vec = _mm_loadu_si128((__m128i*)&game[i]);\n        __m128i guess_vec = _mm_loadu_si128((__m128i*)&guess[i]);\n\n        __m128i diff = _mm_abs_epi32(_mm_sub_epi32(game_vec, guess_vec));\n\n        _mm_storeu_si128((__m128i*)&result[i], diff);\n    }\n\n    return result;\n}\n```"}

{"task_id": "SimdBench_0_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid conditional_move_simd(const int64_t *src, int64_t *dst, const bool *mask, size_t length) {\n    size_t vl;\n    size_t i = 0;\n\n    while (i < length) {\n        vl = vsetvl_e64m1(length - i); // Set vector length for 64-bit elements\n        vint64m1_t v_src = vle64_v_i64m1(&src[i], vl); // Load src elements\n        vint64m1_t v_dst = vle64_v_i64m1(&dst[i], vl); // Load dst elements\n        vbool8_t v_mask = vle8_v_b8(&mask[i], vl);     // Load mask elements\n\n        v_dst = vmerge_vvm_i64m1(v_dst, v_src, v_mask, vl); // Conditionally merge src into dst\n        vse64_v_i64m1(&dst[i], v_dst, vl);                 // Store result back to dst\n\n        i += vl; // Increment index by vector length\n    }\n}\n```"}
{"task_id": "SimdBench_0_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid conditional_move_simd(const int64_t *src, int64_t *dst, const bool *mask, size_t length) {\n    size_t vl;\n    size_t i = 0;\n\n    while (i < length) {\n        vl = vsetvl_e64m1(length - i); // Set vector length for 64-bit elements\n        vint64m1_t v_src = vle64_v_i64m1(&src[i], vl); // Load src elements\n        vint64m1_t v_dst = vle64_v_i64m1(&dst[i], vl); // Load dst elements\n        vbool8_t v_mask = vle8_v_b8(&mask[i], vl);     // Load mask elements\n\n        v_dst = vmerge_vvm_i64m1(v_dst, v_src, v_mask, vl); // Conditionally merge src into dst\n        vse64_v_i64m1(&dst[i], v_dst, vl);                  // Store updated dst elements\n\n        i += vl; // Increment index by vector length\n    }\n}\n```"}
{"task_id": "SimdBench_0_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid conditional_move_simd(const int64_t *src, int64_t *dst, const bool *mask, size_t length) {\n    size_t vl;\n    size_t i = 0;\n\n    while (i < length) {\n        vl = vsetvl_e64m1(length - i); // Set the vector length for 64-bit elements\n        vint64m1_t v_src = vle64_v_i64m1(&src[i], vl); // Load elements from src\n        vint64m1_t v_dst = vle64_v_i64m1(&dst[i], vl); // Load elements from dst\n        vbool8_t v_mask = vle8_v_b8(&mask[i], vl);     // Load mask values\n\n        // Perform conditional move based on mask\n        vint64m1_t v_result = vmerge_vvm_i64m1(v_dst, v_src, v_mask, vl);\n\n        vse64_v_i64m1(&dst[i], v_result, vl); // Store the result back to dst\n        i += vl; // Increment the index by the vector length\n    }\n}\n```"}
{"task_id": "SimdBench_0_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid conditional_move_simd(const int64_t *src, int64_t *dst, const bool *mask, size_t length) {\n    size_t vl;\n    size_t offset = 0;\n\n    while (offset < length) {\n        vl = vsetvl_e64m1(length - offset);\n\n        vint64m1_t src_vec = vle64_v_i64m1(&src[offset], vl);\n        vint64m1_t dst_vec = vle64_v_i64m1(&dst[offset], vl);\n        vbool8_t mask_vec = vle8_v_b8(&mask[offset], vl);\n\n        dst_vec = vmerge_vvm_i64m1(mask_vec, src_vec, dst_vec, vl);\n\n        vse64_v_i64m1(&dst[offset], dst_vec, vl);\n\n        offset += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_0_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid conditional_move_simd(const int64_t *src, int64_t *dst, const bool *mask, size_t length) {\n    size_t vl;\n    size_t offset = 0;\n\n    while (offset < length) {\n        vl = vsetvl_e64m1(length - offset); // Set vector length for 64-bit elements\n        vbool64_t mask_vec = vle8_v_b64m1(&mask[offset], vl); // Load mask as boolean vector\n        vint64m1_t src_vec = vle64_v_i64m1(&src[offset], vl); // Load source vector\n        vint64m1_t dst_vec = vle64_v_i64m1(&dst[offset], vl); // Load destination vector\n\n        dst_vec = vmerge_vvm_i64m1(mask_vec, src_vec, dst_vec, vl); // Conditionally merge src into dst\n\n        vse64_v_i64m1(&dst[offset], dst_vec, vl); // Store the result back to dst\n        offset += vl; // Increment offset by the vector length\n    }\n}\n```"}
{"task_id": "SimdBench_1_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid load_modify_store_simd(const int *src, int *dst, int scale, size_t length) {\n    size_t vl;\n    size_t i = 0;\n\n    while (i < length) {\n        vl = vsetvl_e32m1(length - i); // Set vector length for 32-bit integers\n        vint32m1_t v_src = vle32_v_i32m1(&src[i], vl); // Load src elements\n        vint32m1_t v_scale = vmv_v_x_i32m1(scale, vl); // Broadcast scale to vector\n\n        vint32m1_t v_tmp1 = vsra_vv_i32m1(vmul_vv_i32m1(v_src, v_scale, vl), vmv_v_x_i32m1(3, vl), vl); // tmp1 = (element * scale) >> 3\n        vint32m1_t v_tmp2 = vsll_vv_i32m1(vmul_vv_i32m1(v_src, v_scale, vl), vmv_v_x_i32m1(3, vl), vl); // tmp2 = (element * scale) << 3\n\n        vint32m1_t v_result = vdiv_vv_i32m1(vadd_vv_i32m1(vmul_vv_i32m1(v_src, v_scale, vl), vmul_vv_i32m1(v_tmp1, v_tmp2, vl), vl), vmv_v_x_i32m1(7, vl), vl); // result = (element * scale + tmp1 * tmp2) / 7\n\n        vse32_v_i32m1(&dst[i], v_result, vl); // Store result in dst\n        i += vl; // Increment index by vector length\n    }\n}\n```"}
{"task_id": "SimdBench_1_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid load_modify_store_simd(const int *src, int *dst, int scale, size_t length) {\n    size_t vl;\n    size_t i = 0;\n\n    while (i < length) {\n        vl = vsetvl_e32m1(length - i); // Set vector length for 32-bit integers\n        vint32m1_t v_src = vle32_v_i32m1(&src[i], vl); // Load src elements\n        vint32m1_t v_scaled = vmul_vx_i32m1(v_src, scale, vl); // element * scale\n\n        vint32m1_t v_tmp1 = vsra_vx_i32m1(v_scaled, 3, vl); // tmp1 = (element * scale) >> 3\n        vint32m1_t v_tmp2 = vsll_vx_i32m1(v_scaled, 3, vl); // tmp2 = (element * scale) << 3\n\n        vint32m1_t v_tmp1_tmp2 = vmul_vv_i32m1(v_tmp1, v_tmp2, vl); // tmp1 * tmp2\n        vint32m1_t v_result = vadd_vv_i32m1(v_scaled, v_tmp1_tmp2, vl); // element * scale + tmp1 * tmp2\n        v_result = vdiv_vx_i32m1(v_result, 7, vl); // Final result divided by 7\n\n        vse32_v_i32m1(&dst[i], v_result, vl); // Store results in dst\n        i += vl; // Increment index by vector length\n    }\n}\n```"}
{"task_id": "SimdBench_1_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid load_modify_store_simd(const int *src, int *dst, int scale, size_t length) {\n    size_t vl;\n    size_t i = 0;\n\n    while (i < length) {\n        vl = vsetvl_e32m1(length - i); // Set vector length for 32-bit integers\n        vint32m1_t v_src = vle32_v_i32m1(&src[i], vl); // Load src vector\n        vint32m1_t v_scale = vmv_v_x_i32m1(scale, vl); // Broadcast scale to vector\n\n        vint32m1_t v_tmp1 = vsra_vv_i32m1(vmul_vv_i32m1(v_src, v_scale, vl), vmv_v_x_i32m1(3, vl), vl); // tmp1 = (element * scale) >> 3\n        vint32m1_t v_tmp2 = vsll_vv_i32m1(vmul_vv_i32m1(v_src, v_scale, vl), vmv_v_x_i32m1(3, vl), vl); // tmp2 = (element * scale) << 3\n\n        vint32m1_t v_result = vadd_vv_i32m1(vmul_vv_i32m1(v_src, v_scale, vl), vmul_vv_i32m1(v_tmp1, v_tmp2, vl), vl); // element * scale + tmp1 * tmp2\n        v_result = vdiv_vv_i32m1(v_result, vmv_v_x_i32m1(7, vl), vl); // Final result divided by 7\n\n        vse32_v_i32m1(&dst[i], v_result, vl); // Store result in dst\n        i += vl; // Increment index by vector length\n    }\n}\n```"}
{"task_id": "SimdBench_1_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid load_modify_store_simd(const int *src, int *dst, int scale, size_t length) {\n    size_t vl;\n    size_t i = 0;\n\n    while (i < length) {\n        vl = vsetvl_e32m1(length - i); // Set the vector length for 32-bit integers\n        vint32m1_t v_src = vle32_v_i32m1(&src[i], vl); // Load src vector\n        vint32m1_t v_scaled = vmul_vx_i32m1(v_src, scale, vl); // element * scale\n\n        vint32m1_t v_tmp1 = vsra_vx_i32m1(v_scaled, 3, vl); // tmp1 = (element * scale) >> 3\n        vint32m1_t v_tmp2 = vsll_vx_i32m1(v_scaled, 3, vl); // tmp2 = (element * scale) << 3\n\n        vint32m1_t v_tmp1_tmp2 = vmul_vv_i32m1(v_tmp1, v_tmp2, vl); // tmp1 * tmp2\n        vint32m1_t v_result = vadd_vv_i32m1(v_scaled, v_tmp1_tmp2, vl); // element * scale + tmp1 * tmp2\n        v_result = vdiv_vx_i32m1(v_result, 7, vl); // (element * scale + tmp1 * tmp2) / 7\n\n        vse32_v_i32m1(&dst[i], v_result, vl); // Store the result in dst\n        i += vl; // Increment the index by the vector length\n    }\n}\n```"}
{"task_id": "SimdBench_1_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid load_modify_store_simd(const int *src, int *dst, int scale, size_t length) {\n    size_t vl;\n    size_t i = 0;\n\n    while (i < length) {\n        vl = vsetvl_e32m1(length - i); // Set vector length for 32-bit elements\n        vint32m1_t v_src = vle32_v_i32m1(&src[i], vl); // Load src vector\n        vint32m1_t v_scaled = vmul_vx_i32m1(v_src, scale, vl); // element * scale\n\n        vint32m1_t v_tmp1 = vsra_vx_i32m1(v_scaled, 3, vl); // tmp1 = (element * scale) >> 3\n        vint32m1_t v_tmp2 = vsll_vx_i32m1(v_scaled, 3, vl); // tmp2 = (element * scale) << 3\n\n        vint32m1_t v_tmp1_tmp2 = vmul_vv_i32m1(v_tmp1, v_tmp2, vl); // tmp1 * tmp2\n        vint32m1_t v_result = vadd_vv_i32m1(v_scaled, v_tmp1_tmp2, vl); // element * scale + tmp1 * tmp2\n        v_result = vdiv_vx_i32m1(v_result, 7, vl); // (element * scale + tmp1 * tmp2) / 7\n\n        vse32_v_i32m1(&dst[i], v_result, vl); // Store result in dst\n        i += vl; // Increment index by vector length\n    }\n}\n```"}
{"task_id": "SimdBench_2_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid strided_load_store_simd(const double *src, double *dst, size_t rows, size_t cols, size_t stride) {\n    size_t vl;\n    size_t r = 0;\n\n    while (r < rows) {\n        vl = vsetvl_e64m1(rows - r); // Set vector length for remaining rows\n        vuint64m1_t indices = vmul_vx_u64m1(vslide1down_vx_u64m1(vle64_v_u64m1(src + r * cols + stride, vl),stride),stride);\n        vfloat64m1_t data = vluxei64_v_f64m1(src, indices, vl); // Gather elements from src using stride\n        vse64_v_f64m1(dst + r, data, vl); // Store gathered elements into dst\n        r += vl; // Increment processed rows\n    }\n}\n```"}
{"task_id": "SimdBench_2_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid strided_load_store_simd(const double *src, double *dst, size_t rows, size_t cols, size_t stride) {\n    size_t vl;\n    size_t r = 0;\n\n    while (r < rows) {\n        vl = vsetvl_e64m1(rows - r); // Set vector length for remaining rows\n        vuint64m1_t indices = vmul_vx_u64m1(vrsub_vx_u64m1(vle64_v_u64m1(&r, vl), stride), cols, vl); // Calculate indices\n        vfloat64m1_t values = vluxei64_v_f64m1(src, indices, vl); // Load values from src using indices\n        vse64_v_f64m1(dst + r, values, vl); // Store values into dst\n        r += vl; // Increment row counter by vector length\n    }\n}\n```"}
{"task_id": "SimdBench_2_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid strided_load_store_simd(const double *src, double *dst, size_t rows, size_t cols, size_t stride) {\n    size_t vl;\n    size_t r = 0;\n\n    while (r < rows) {\n        vl = vsetvl_e64m1(rows - r); // Set vector length for remaining rows\n        vuint64m1_t indices = vmul_vx_u64m1(vrsub_vx_u64m1(vle64_v_u64m1(&r, vl), r), stride, vl); // Compute indices for strided load\n        vfloat64m1_t loaded = vluxei64_v_f64m1(src, indices, vl); // Load elements from src using indices\n        vse64_v_f64m1(dst + r, loaded, vl); // Store elements into dst\n        r += vl; // Increment row counter by vector length\n    }\n}\n```"}
{"task_id": "SimdBench_2_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid strided_load_store_simd(const double *src, double *dst, size_t rows, size_t cols, size_t stride) {\n    size_t vl;\n    size_t r = 0;\n\n    while (r < rows) {\n        vl = vsetvl_e64m1(rows - r); // Set vector length for remaining rows\n        vuint64m1_t indices = vid_v_u64m1(vl); // Generate indices [0, 1, 2, ..., vl-1]\n        vuint64m1_t row_indices = vadd_vx_u64m1(indices, r, vl); // Add current row offset\n        vuint64m1_t src_indices = vmul_vx_u64m1(row_indices, cols, vl); // Multiply by cols\n        src_indices = vadd_vx_u64m1(src_indices, stride, vl); // Add stride to get final indices\n\n        vfloat64m1_t src_values = vluxei64_v_f64m1(src, src_indices, vl); // Load values from src using indices\n        vse_v_f64m1(dst + r, src_values, vl); // Store values into dst\n\n        r += vl; // Increment row counter by vector length\n    }\n}\n```"}
{"task_id": "SimdBench_2_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid strided_load_store_simd(const double *src, double *dst, size_t rows, size_t cols, size_t stride) {\n    size_t vl;\n    size_t r = 0;\n\n    while (r < rows) {\n        vl = vsetvl_e64m1(rows - r); // Determine the vector length for the remaining rows\n        vuint64m1_t indices = vmul_vx_u64m1(vslide1down_vx_u64m1(vundefined_u64m1(), 0, vl), stride); // Generate indices for strided access\n        vfloat64m1_t data = vluxei64_v_f64m1(src, indices, vl); // Load strided elements from src\n        vse64_v_f64m1(dst + r, data, vl); // Store the loaded elements into dst\n        r += vl; // Increment the row counter by the vector length\n    }\n}\n```"}
{"task_id": "SimdBench_3_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid indexed_access_simd(const float *src, const int *indices, float *dst, size_t length) {\n    size_t vl;\n    size_t i = 0;\n\n    while (i < length) {\n        vl = vsetvl_e32m1(length - i);\n\n        // Load indices vector\n        vint32m1_t index_vec = vle32_v_i32m1(&indices[i], vl);\n\n        // Gather operation: Load values from src using indices and store in dst\n        vfloat32m1_t gathered_values = vluxei32_v_f32m1(src, index_vec, vl);\n        vse32_v_f32m1(&dst[i], gathered_values, vl);\n\n        // Scatter operation: Store values from src into dst using indices\n        vfloat32m1_t src_values = vle32_v_f32m1(&src[i], vl);\n        vsuxei32_v_f32m1(dst, index_vec, src_values, vl);\n\n        i += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_3_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid indexed_access_simd(const float *src, const int *indices, float *dst, size_t length) {\n    size_t vl;\n    size_t i = 0;\n\n    while (i < length) {\n        vl = vsetvl_e32m1(length - i);\n\n        // Load indices vector\n        vint32m1_t index_vec = vle32_v_i32m1(&indices[i], vl);\n\n        // Gather operation: Load values from src using indices and store in dst\n        vfloat32m1_t gathered_values = vluxei32_v_f32m1(src, index_vec, vl);\n        vse32_v_f32m1(&dst[i], gathered_values, vl);\n\n        // Scatter operation: Write values from src to dst using indices\n        vfloat32m1_t src_values = vle32_v_f32m1(&src[i], vl);\n        vsuxei32_v_f32m1(dst, index_vec, src_values, vl);\n\n        i += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_3_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid indexed_access_simd(const float *src, const int *indices, float *dst, size_t length) {\n    size_t vl;\n    size_t i = 0;\n\n    while (i < length) {\n        // Determine the vector length for this iteration\n        vl = vsetvl_e32m1(length - i);\n\n        // Load indices into a vector\n        vint32m1_t index_vec = vle32_v_i32m1(&indices[i], vl);\n\n        // Gather values from the source array using indices\n        vfloat32m1_t gathered_values = vluxei32_v_f32m1(src, index_vec, vl);\n\n        // Store gathered values into the destination array\n        vse32_v_f32m1(&dst[i], gathered_values, vl);\n\n        // Scatter values from the source array to the destination array using indices\n        vsuxei32_v_f32m1(dst, index_vec, gathered_values, vl);\n\n        // Increment the loop counter by the vector length\n        i += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_3_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid indexed_access_simd(const float *src, const int *indices, float *dst, size_t length) {\n    size_t vl;\n    size_t i = 0;\n\n    while (i < length) {\n        vl = vsetvl_e32m1(length - i); // Set vector length for 32-bit elements\n\n        // Load indices into a vector\n        vint32m1_t index_vec = vle32_v_i32m1(&indices[i], vl);\n\n        // Gather values from the source array using indices\n        vfloat32m1_t gathered_values = vluxei32_v_f32m1(src, index_vec, vl);\n\n        // Store gathered values into the destination array\n        vse32_v_f32m1(&dst[i], gathered_values, vl);\n\n        // Scatter values from the source array to the destination array using indices\n        vsuxei32_v_f32m1(dst, index_vec, gathered_values, vl);\n\n        i += vl; // Increment by the vector length\n    }\n}\n```"}
{"task_id": "SimdBench_3_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid indexed_access_simd(const float *src, const int *indices, float *dst, size_t length) {\n    size_t vl;\n    size_t i = 0;\n\n    while (i < length) {\n        vl = vsetvl_e32m1(length - i);\n\n        // Load indices\n        vint32m1_t index_vec = vle32_v_i32m1(&indices[i], vl);\n\n        // Gather operation: Load values from src using indices and store in dst\n        vfloat32m1_t gathered_values = vluxei32_v_f32m1(src, index_vec, vl);\n        vse32_v_f32m1(&dst[i], gathered_values, vl);\n\n        // Scatter operation: Store values from src into dst using indices\n        vfloat32m1_t src_values = vle32_v_f32m1(&src[i], vl);\n        vsuxei32_v_f32m1(dst, index_vec, src_values, vl);\n\n        i += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_4_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid range_reverse_simd(int16_t *arr, uint64_t start, uint64_t end) {\n    uint64_t len = end - start + 1;\n    uint64_t vl;\n    while (len > 0) {\n        vl = vsetvl_e16m1(len); // Set vector length for 16-bit elements\n        vint16m1_t vec_start = vle16_v_i16m1(&arr[start], vl); // Load elements from start\n        vint16m1_t vec_end = vle16_v_i16m1(&arr[end - vl + 1], vl); // Load elements from end\n        vse16_v_i16m1(&arr[start], vec_end, vl); // Store reversed elements to start\n        vse16_v_i16m1(&arr[end - vl + 1], vec_start, vl); // Store reversed elements to end\n        start += vl;\n        end -= vl;\n        len -= vl * 2;\n    }\n}\n```"}
{"task_id": "SimdBench_4_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid range_reverse_simd(int16_t *arr, uint64_t start, uint64_t end) {\n    uint64_t n = end - start + 1;\n    uint64_t i = 0;\n\n    while (i < n / 2) {\n        size_t vl = vsetvl_e16m1(n / 2 - i); // Set vector length for 16-bit elements\n        vuint64m1_t indices_front = vid_v_u64m1(vl); // Generate indices for the front\n        vuint64m1_t indices_back = vsub_vx_u64m1(vmv_v_x_u64m1(n - 1 - i, vl), indices_front, vl); // Generate indices for the back\n\n        vuint64m1_t indices_start = vadd_vx_u64m1(indices_front, start + i, vl); // Adjust indices for the start\n        vuint64m1_t indices_end = vadd_vx_u64m1(indices_back, start, vl); // Adjust indices for the end\n\n        vint16m1_t front_vals = vluxei16_v_i16m1(arr, indices_start, vl); // Load front elements\n        vint16m1_t back_vals = vluxei16_v_i16m1(arr, indices_end, vl); // Load back elements\n\n        vsuxei16_v_i16m1(arr, indices_start, back_vals, vl); // Store back elements to the front\n        vsuxei16_v_i16m1(arr, indices_end, front_vals, vl); // Store front elements to the back\n\n        i += vl; // Increment processed elements\n    }\n}\n```"}
{"task_id": "SimdBench_4_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid range_reverse_simd(int16_t *arr, uint64_t start, uint64_t end) {\n    uint64_t n = end - start + 1;\n    size_t vl;\n    while (n > 0) {\n        vl = vsetvl_e16m1(n);\n        vuint64m1_t indices = vrsub_vx_u64m1(vcreate_u64m1(vl), n - 1, vl);\n        vint16m1_t vec_start = vle16_v_i16m1(&arr[start], vl);\n        vint16m1_t vec_end = vle16_v_i16m1(&arr[start + n - vl], vl);\n        vse16_v_i16m1(&arr[start], vec_end, vl);\n        vse16_v_i16m1(&arr[start + n - vl], vec_start, vl);\n        start += vl;\n        n -= vl;\n    }\n}\n```"}
{"task_id": "SimdBench_4_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid range_reverse_simd(int16_t *arr, uint64_t start, uint64_t end) {\n    uint64_t len = end - start + 1;\n    size_t vl;\n    while (len > 0) {\n        vl = vsetvl_e16m1(len); // Set vector length for 16-bit elements\n        vint16m1_t vec_start = vle16_v_i16m1(&arr[start], vl); // Load elements from the start\n        vint16m1_t vec_end = vle16_v_i16m1(&arr[end - vl + 1], vl); // Load elements from the end\n        vse16_v_i16m1(&arr[start], vec_end, vl); // Store reversed elements to the start\n        vse16_v_i16m1(&arr[end - vl + 1], vec_start, vl); // Store reversed elements to the end\n        start += vl; // Move start forward\n        end -= vl; // Move end backward\n        len -= vl; // Reduce remaining length\n    }\n}\n```"}
{"task_id": "SimdBench_4_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid range_reverse_simd(int16_t *arr, uint64_t start, uint64_t end) {\n    uint64_t len = end - start + 1;\n    uint64_t vl;\n\n    while (len > 0) {\n        vl = vsetvl_e16m8(len); // Set vector length for 16-bit elements\n        vuint64m8_t indices = vrsub_vx_u64m8(vcreate_u64m8(vl), len - 1); // Generate reverse indices\n        vint16m8_t vec_start = vle16_v_i16m8(&arr[start], vl); // Load elements from start\n        vint16m8_t vec_end = vluxei16_v_i16m8(&arr[end], indices, vl); // Load elements from end using reverse indices\n\n        vse16_v_i16m8(&arr[start], vec_end, vl); // Store reversed elements to start\n        vsuxei16_v_i16m8(&arr[end], indices, vec_start, vl); // Store reversed elements to end\n\n        start += vl;\n        end -= vl;\n        len -= vl * 2;\n    }\n}\n```"}
{"task_id": "SimdBench_5_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid extract_tensor_slice_simd(const uint8_t *tensor, uint8_t *slice, size_t dim1, size_t dim2, size_t dim3, size_t slice_idx) {\n    size_t slice_size = dim1 * dim2;\n    size_t offset = slice_idx * slice_size;\n\n    size_t vl;\n    for (size_t i = 0; i < slice_size; i += vl) {\n        vl = vsetvl_e8m8(slice_size - i);\n        vuint8m8_t vec = vlse8_v_u8m8(&tensor[offset + i], 1, vl);\n        vse8_v_u8m8(&slice[i], vec, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_5_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid extract_tensor_slice_simd(const uint8_t *tensor, uint8_t *slice, size_t dim1, size_t dim2, size_t dim3, size_t slice_idx) {\n    size_t slice_size = dim1 * dim2;\n    size_t stride = dim3; // Stride to jump between rows in the flattened tensor\n    size_t offset = slice_idx; // Offset for the slice index in the third dimension\n\n    size_t vl;\n    for (size_t i = 0; i < slice_size; i += vl) {\n        vl = vsetvl_e8m1(slice_size - i); // Set vector length for remaining elements\n        vuint8m1_t vec = vlse8_v_u8m1(&tensor[i * stride + offset], stride, vl); // Load with stride\n        vse8_v_u8m1(&slice[i], vec, vl); // Store the extracted slice\n    }\n}\n```"}
{"task_id": "SimdBench_5_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid extract_tensor_slice_simd(const uint8_t *tensor, uint8_t *slice, size_t dim1, size_t dim2, size_t dim3, size_t slice_idx) {\n    size_t slice_size = dim1 * dim2; // Total elements in the 2D slice\n    size_t offset = slice_idx * slice_size; // Offset to the start of the slice in the 1D tensor array\n\n    size_t vl;\n    for (size_t i = 0; i < slice_size; i += vl) {\n        vl = vsetvl_e8m1(slice_size - i); // Set vector length for remaining elements\n        vuint8m1_t vec = vle8_v_u8m1(&tensor[offset + i], vl); // Load elements from tensor\n        vse8_v_u8m1(&slice[i], vec, vl); // Store elements into slice\n    }\n}\n```"}
{"task_id": "SimdBench_5_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid extract_tensor_slice_simd(const uint8_t *tensor, uint8_t *slice, size_t dim1, size_t dim2, size_t dim3, size_t slice_idx) {\n    size_t slice_size = dim1 * dim2;\n    size_t offset = slice_idx * slice_size;\n\n    size_t vl;\n    for (size_t i = 0; i < slice_size; i += vl) {\n        vl = vsetvl_e8m1(slice_size - i); // Set vector length for 8-bit elements\n        vuint8m1_t vec = vle8_v_u8m1(&tensor[offset + i], vl); // Load tensor data\n        vse8_v_u8m1(&slice[i], vec, vl); // Store to slice\n    }\n}\n```"}
{"task_id": "SimdBench_5_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid extract_tensor_slice_simd(const uint8_t *tensor, uint8_t *slice, size_t dim1, size_t dim2, size_t dim3, size_t slice_idx) {\n    size_t slice_offset = slice_idx; // Offset for the slice in the flattened tensor\n    size_t tensor_stride = dim3;    // Stride for each row in the tensor\n    size_t total_elements = dim1 * dim2; // Total elements in the 2D slice\n\n    size_t vl;\n    size_t i = 0;\n\n    while (i < total_elements) {\n        vl = vsetvl_e8m1(total_elements - i); // Set vector length for remaining elements\n        vuint8m1_t vec_data = vle8_v_u8m1(&tensor[i * tensor_stride + slice_offset], vl); // Load data from tensor\n        vse8_v_u8m1(&slice[i], vec_data, vl); // Store data into slice\n        i += vl; // Increment processed elements\n    }\n}\n```"}
{"task_id": "SimdBench_6_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid blocked_matrix_transpose_simd(const int16_t *src, int16_t *dst, size_t rows, size_t cols, size_t block_size) {\n    size_t vl;\n    for (size_t i = 0; i < rows; i += block_size) {\n        for (size_t j = 0; j < cols; j += block_size) {\n            size_t block_rows = (i + block_size <= rows) ? block_size : (rows - i);\n            size_t block_cols = (j + block_size <= cols) ? block_size : (cols - j);\n\n            for (size_t bi = 0; bi < block_rows; bi++) {\n                size_t src_idx = (i + bi) * cols + j;\n                size_t dst_idx = j * rows + (i + bi);\n\n                for (size_t bj = 0; bj < block_cols; bj += vl) {\n                    vl = vsetvl_e16(block_cols - bj);\n                    vint16m1_t vec = vle16_v_i16m1(&src[src_idx + bj], vl);\n                    vse16_v_i16m1(&dst[dst_idx + bj * rows], vec, vl);\n                }\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_6_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid blocked_matrix_transpose_simd(const int16_t *src, int16_t *dst, size_t rows, size_t cols, size_t block_size) {\n    size_t vl;\n    for (size_t i = 0; i < rows; i += block_size) {\n        for (size_t j = 0; j < cols; j += block_size) {\n            size_t block_row_end = i + block_size > rows ? rows : i + block_size;\n            size_t block_col_end = j + block_size > cols ? cols : j + block_size;\n\n            for (size_t bi = i; bi < block_row_end; ++bi) {\n                for (size_t bj = j; bj < block_col_end; bj += vl) {\n                    vl = vsetvl_e16(block_col_end - bj);\n                    vint16m1_t vec = vlseg2e16_v_i16m1(&src[bi * cols + bj], vl);\n                    vse16_v_i16m1(&dst[bj * rows + bi], vec, vl);\n                }\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_6_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid blocked_matrix_transpose_simd(const int16_t *src, int16_t *dst, size_t rows, size_t cols, size_t block_size) {\n    size_t vl;\n    for (size_t row_block = 0; row_block < rows; row_block += block_size) {\n        for (size_t col_block = 0; col_block < cols; col_block += block_size) {\n            size_t row_end = row_block + block_size > rows ? rows : row_block + block_size;\n            size_t col_end = col_block + block_size > cols ? cols : col_block + block_size;\n\n            for (size_t i = row_block; i < row_end; i++) {\n                for (size_t j = col_block; j < col_end; j += vl) {\n                    vl = vsetvl_e16(col_end - j); // Set vector length based on remaining columns\n                    vint16m1_t vec = vle16_v_i16m1(&src[i * cols + j], vl); // Load a vector of elements\n                    vse16_v_i16m1(&dst[j * rows + i], vec, vl); // Store transposed elements\n                }\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_6_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid blocked_matrix_transpose_simd(const int16_t *src, int16_t *dst, size_t rows, size_t cols, size_t block_size) {\n    size_t vl;\n    for (size_t i = 0; i < rows; i += block_size) {\n        for (size_t j = 0; j < cols; j += block_size) {\n            size_t block_rows = (i + block_size > rows) ? rows - i : block_size;\n            size_t block_cols = (j + block_size > cols) ? cols - j : block_size;\n\n            for (size_t bi = 0; bi < block_rows; ++bi) {\n                size_t src_idx = (i + bi) * cols + j;\n                size_t dst_idx = j * rows + (i + bi);\n\n                for (size_t bj = 0; bj < block_cols; bj += vl) {\n                    vl = vsetvl_e16(block_cols - bj);\n                    vint16m1_t vec = vle16_v_i16m1(&src[src_idx + bj], vl);\n                    vse16_v_i16m1(&dst[dst_idx + bj * rows], vec, vl);\n                }\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_6_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid blocked_matrix_transpose_simd(const int16_t *src, int16_t *dst, size_t rows, size_t cols, size_t block_size) {\n    size_t vl;\n    for (size_t i = 0; i < rows; i += block_size) {\n        for (size_t j = 0; j < cols; j += block_size) {\n            size_t block_row_end = (i + block_size > rows) ? rows : i + block_size;\n            size_t block_col_end = (j + block_size > cols) ? cols : j + block_size;\n\n            for (size_t bi = i; bi < block_row_end; ++bi) {\n                for (size_t bj = j; bj < block_col_end; bj += vl) {\n                    vl = vsetvl_e16(block_col_end - bj); // Set vector length based on remaining elements\n                    vint16m1_t vec = vle16_v_i16m1(&src[bi * cols + bj], vl); // Load a vector from the source\n                    vse16_v_i16m1(&dst[bj * rows + bi], vec, vl); // Store the transposed vector to the destination\n                }\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_7_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nfloat diagonal_sum_3d_simd(const float *array, size_t dim) {\n    size_t diagonal_count = dim; // Number of diagonal elements\n    size_t vlmax = vsetvlmax_e32m1(); // Maximum vector length for 32-bit floats\n    size_t vl;\n    float sum = 0.0f;\n\n    for (size_t i = 0; i < diagonal_count; i += vlmax) {\n        vl = vsetvl_e32m1(diagonal_count - i); // Set vector length based on remaining elements\n        vuint32m1_t indices = vid_v_u32m1(vl); // Generate indices [0, 1, 2, ..., vl-1]\n        vuint32m1_t offset = vmul_vx_u32m1(indices, dim * dim + dim + 1, vl); // Calculate offsets for diagonal elements\n        vfloat32m1_t diag_elements = vluxei32_v_f32m1(array, offset, vl); // Load diagonal elements\n        sum += vfmv_s_f_f32m1(vfredsum_vs_f32m1_f32m1(vundefined_f32m1(), diag_elements, vundefined_f32m1(), vl)); // Reduce sum\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_7_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nfloat diagonal_sum_3d_simd(const float *array, size_t dim) {\n    size_t diagonal_count = dim; // Number of diagonal elements\n    size_t vlmax = vsetvlmax_e32m1(); // Maximum vector length for 32-bit floats\n    float sum = 0.0f;\n\n    for (size_t i = 0; i < diagonal_count; i += vlmax) {\n        size_t vl = vsetvl_e32m1(diagonal_count - i); // Set vector length based on remaining elements\n        vuint32m1_t indices = vid_v_u32m1(vl); // Generate indices [0, 1, 2, ...]\n        indices = vadd_vx_u32m1(indices, i, vl); // Adjust indices to start from i\n\n        vuint32m1_t flattened_indices = vmul_vx_u32m1(indices, dim * dim, vl); // i * dim * dim\n        flattened_indices = vadd_vv_u32m1(flattened_indices, vmul_vx_u32m1(indices, dim, vl), vl); // i * dim * dim + i * dim\n        flattened_indices = vadd_vv_u32m1(flattened_indices, indices, vl); // i * dim * dim + i * dim + i\n\n        vfloat32m1_t diagonal_values = vluxei32_v_f32m1(array, flattened_indices, vl); // Load diagonal elements\n        sum += vfmv_f_s_f32m1_f32(vfredsum_vs_f32m1_f32m1(vundefined_f32m1(), diagonal_values, vundefined_f32m1(), vl)); // Reduce sum\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_7_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nfloat diagonal_sum_3d_simd(const float *array, size_t dim) {\n    size_t n = dim; // Number of diagonal elements\n    size_t vlmax = vsetvlmax_e32m1(); // Maximum vector length for 32-bit floats\n    float sum = 0.0f;\n\n    for (size_t i = 0; i < n; i += vlmax) {\n        size_t vl = vsetvl_e32m1(n - i); // Set vector length based on remaining elements\n        vuint32m1_t indices = vid_v_u32m1(vl); // Generate indices [0, 1, 2, ..., vl-1]\n        vuint32m1_t offset = vadd_vx_u32m1(indices, i, vl); // Offset indices by i\n        vuint32m1_t flat_indices = vmul_vx_u32m1(offset, dim * dim + dim + 1, vl); // Calculate flattened indices\n        vfloat32m1_t diagonal_elements = vluxei32_v_f32m1(array, flat_indices, vl); // Load diagonal elements\n        sum += vfmv_s_f_f32m1(vfredsum_vs_f32m1_f32m1(vundefined_f32m1(), diagonal_elements, vundefined_f32m1(), vl)); // Reduce sum\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_7_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nfloat diagonal_sum_3d_simd(const float *array, size_t dim) {\n    size_t n = dim; // The number of diagonal elements\n    size_t stride = dim * dim + dim + 1; // Stride to access diagonal elements in the flattened array\n\n    float sum = 0.0f;\n    size_t vl;\n    vfloat32m1_t vec_sum = vfmv_v_f_f32m1(0.0f, vsetvlmax_e32m1()); // Initialize vector sum to 0\n\n    for (size_t i = 0; i < n; i += vl) {\n        vl = vsetvl_e32m1(n - i); // Set vector length for remaining elements\n        vuint32m1_t indices = vid_v_u32m1(vl); // Generate indices [0, 1, 2, ..., vl-1]\n        indices = vmul_vx_u32m1(indices, stride, vl); // Scale indices by stride\n        vfloat32m1_t vec_elements = vluxei32_v_f32m1(array + i * stride, indices, vl); // Load diagonal elements\n        vec_sum = vfadd_vv_f32m1(vec_sum, vec_elements, vl); // Accumulate into vector sum\n    }\n\n    // Reduce vector sum to a scalar\n    sum = vfmv_f_s_f32m1_f32(vfredsum_vs_f32m1_f32m1(vec_sum, vec_sum, vfmv_s_f_f32m1(0.0f, vl), vl));\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_7_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nfloat diagonal_sum_3d_simd(const float *array, size_t dim) {\n    size_t diagonal_count = dim; // Number of diagonal elements\n    size_t vl;\n    float sum = 0.0f;\n\n    vfloat32m1_t vec_sum = vfmv_v_f_f32m1(0.0f, vsetvlmax_e32m1()); // Initialize vector sum to 0\n\n    for (size_t i = 0; i < diagonal_count; i += vl) {\n        vl = vsetvl_e32m1(diagonal_count - i); // Set vector length\n        vuint32m1_t indices = vid_v_u32m1(vl); // Generate indices [0, 1, 2, ..., vl-1]\n        indices = vadd_vx_u32m1(indices, i, vl); // Offset indices by i\n\n        // Calculate the flat index for diagonal elements: i * (dim * dim + dim + 1)\n        vuint32m1_t flat_indices = vmul_vx_u32m1(indices, dim * dim + dim + 1, vl);\n\n        // Load diagonal elements using flat indices\n        vfloat32m1_t vec_values = vluxei32_v_f32m1(array, flat_indices, vl);\n\n        // Accumulate the values into vec_sum\n        vec_sum = vfadd_vv_f32m1(vec_sum, vec_values, vl);\n    }\n\n    // Reduce the vector sum to a scalar\n    sum = vfmv_f_s_f32m1_f32(vfredsum_vs_f32m1_f32m1(vec_sum, vec_sum, vfmv_s_f_f32m1(0.0f, vl), vl));\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_8_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid conditional_scale_simd(const double *src, double *dst, size_t rows, size_t cols, double threshold, double scale) {\n    size_t total_elements = rows * cols;\n    size_t vl;\n    vfloat64m1_t v_threshold = vfmv_v_f_f64m1(threshold, vsetvlmax_e64m1());\n    vfloat64m1_t v_scale = vfmv_v_f_f64m1(scale, vsetvlmax_e64m1());\n\n    for (size_t i = 0; i < total_elements; i += vl) {\n        vl = vsetvl_e64m1(total_elements - i); // Determine vector length\n        vfloat64m1_t v_src = vle64_v_f64m1(&src[i], vl); // Load source elements\n        vbool64_t mask = vmfgt_vv_f64m1_b64(v_src, v_threshold, vl); // Compare src > threshold\n        vfloat64m1_t v_scaled = vfmul_vv_f64m1(v_src, v_scale, vl); // Scale src by scale factor\n        vfloat64m1_t v_result = vmerge_vvm_f64m1(mask, v_scaled, v_src, vl); // Apply conditional scaling\n        vse64_v_f64m1(&dst[i], v_result, vl); // Store result in destination\n    }\n}\n```"}
{"task_id": "SimdBench_8_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid conditional_scale_simd(const double *src, double *dst, size_t rows, size_t cols, double threshold, double scale) {\n    size_t total_elements = rows * cols;\n    size_t vl;\n    vfloat64m1_t v_threshold = vfmv_v_f_f64m1(threshold, vsetvlmax_e64m1());\n    vfloat64m1_t v_scale = vfmv_v_f_f64m1(scale, vsetvlmax_e64m1());\n\n    for (size_t i = 0; i < total_elements; i += vl) {\n        vl = vsetvl_e64m1(total_elements - i);\n\n        vfloat64m1_t v_src = vle64_v_f64m1(&src[i], vl);\n        vbool64_t mask = vmfgt_vv_f64m1_b64(v_src, v_threshold, vl);\n        vfloat64m1_t v_scaled = vfmul_vv_f64m1(v_src, v_scale, vl);\n        vfloat64m1_t v_result = vmerge_vvm_f64m1(mask, v_scaled, v_src, vl);\n\n        vse64_v_f64m1(&dst[i], v_result, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_8_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid conditional_scale_simd(const double *src, double *dst, size_t rows, size_t cols, double threshold, double scale) {\n    size_t total_elements = rows * cols;\n    size_t vl;\n    vfloat64m1_t v_threshold = vfmv_v_f_f64m1(threshold, vsetvlmax_e64m1());\n    vfloat64m1_t v_scale = vfmv_v_f_f64m1(scale, vsetvlmax_e64m1());\n\n    for (size_t i = 0; i < total_elements; i += vl) {\n        vl = vsetvl_e64m1(total_elements - i);\n        vfloat64m1_t v_src = vle64_v_f64m1(&src[i], vl);\n        vbool64_t mask = vmfgt_vv_f64m1_b64(v_src, v_threshold, vl);\n        vfloat64m1_t v_scaled = vfmul_vv_f64m1(v_src, v_scale, vl);\n        vfloat64m1_t v_result = vmerge_vvm_f64m1(mask, v_scaled, v_src, vl);\n        vse64_v_f64m1(&dst[i], v_result, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_8_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid conditional_scale_simd(const double *src, double *dst, size_t rows, size_t cols, double threshold, double scale) {\n    size_t total_elements = rows * cols;\n    size_t vl;\n    vfloat64m1_t v_threshold = vfmv_v_f_f64m1(threshold, vsetvlmax_e64m1());\n    vfloat64m1_t v_scale = vfmv_v_f_f64m1(scale, vsetvlmax_e64m1());\n\n    for (size_t i = 0; i < total_elements; i += vl) {\n        vl = vsetvl_e64m1(total_elements - i);\n        vfloat64m1_t v_src = vle64_v_f64m1(&src[i], vl);\n        vbool64_t mask = vmfgt_vv_f64m1_b64(v_src, v_threshold, vl);\n        vfloat64m1_t v_scaled = vfmul_vv_f64m1(v_src, v_scale, vl);\n        vfloat64m1_t v_result = vmerge_vvm_f64m1(mask, v_scaled, v_src, vl);\n        vse64_v_f64m1(&dst[i], v_result, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_8_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid conditional_scale_simd(const double *src, double *dst, size_t rows, size_t cols, double threshold, double scale) {\n    size_t total_elements = rows * cols;\n    size_t vl;\n    vfloat64m1_t v_threshold = vfmv_s_f_f64m1(vundefined_f64m1(), threshold, vsetvlmax_e64m1());\n    vfloat64m1_t v_scale = vfmv_s_f_f64m1(vundefined_f64m1(), scale, vsetvlmax_e64m1());\n\n    for (size_t i = 0; i < total_elements; i += vl) {\n        vl = vsetvl_e64m1(total_elements - i);\n        vfloat64m1_t v_src = vle64_v_f64m1(&src[i], vl);\n        vbool64_t mask = vmfgt_vv_f64m1_b64(v_src, v_threshold, vl);\n        vfloat64m1_t v_scaled = vfmul_vv_f64m1(v_src, v_scale, vl);\n        vfloat64m1_t v_result = vmerge_vvm_f64m1(mask, v_scaled, v_src, vl);\n        vse64_v_f64m1(&dst[i], v_result, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_9_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid reorder_matrix_rows_simd(const double *src, double *dst, size_t rows, size_t cols, const size_t *indices) {\n    size_t vl;\n    for (size_t i = 0; i < rows; i++) {\n        // Load the index for the current row\n        size_t index = indices[i];\n        \n        // Calculate the starting address of the source row\n        const double *src_row = src + index * cols;\n        \n        // Calculate the starting address of the destination row\n        double *dst_row = dst + i * cols;\n\n        // Process the row in chunks using RVV\n        for (size_t j = 0; j < cols; j += vl) {\n            vl = vsetvl_e64m1(cols - j); // Set vector length for 64-bit elements\n            vfloat64m1_t vec = vle64_v_f64m1(src_row + j, vl); // Load source row chunk\n            vse64_v_f64m1(dst_row + j, vec, vl); // Store to destination row chunk\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_9_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid reorder_matrix_rows_simd(const double *src, double *dst, size_t rows, size_t cols, const size_t *indices) {\n    size_t vl;\n    size_t col_stride = cols; // Number of columns per row\n\n    for (size_t i = 0; i < rows; i++) {\n        // Load the index for the current row\n        size_t index = indices[i];\n\n        // Compute the source row start address\n        const double *src_row = src + index * col_stride;\n\n        // Compute the destination row start address\n        double *dst_row = dst + i * col_stride;\n\n        // Process the row in chunks using RVV\n        for (size_t j = 0; j < cols; j += vl) {\n            vl = vsetvl_e64m1(cols - j); // Set vector length for 64-bit elements\n            vfloat64m1_t src_vec = vle64_v_f64m1(src_row + j, vl); // Load source row chunk\n            vse64_v_f64m1(dst_row + j, src_vec, vl); // Store to destination row\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_9_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid reorder_matrix_rows_simd(const double *src, double *dst, size_t rows, size_t cols, const size_t *indices) {\n    size_t vl;\n    size_t row_size = cols * sizeof(double); // Size of a single row in bytes\n\n    for (size_t i = 0; i < rows; i += vl) {\n        vl = vsetvl_e64m1(rows - i); // Set vector length based on remaining rows\n\n        // Load indices for the current batch of rows\n        vuint64m1_t index_vec = vle64_v_u64m1(indices + i, vl);\n\n        // Process each row in the batch\n        for (size_t j = 0; j < cols; j++) {\n            // Load column elements from the source matrix based on indices\n            vfloat64m1_t src_vec = vluxei64_v_f64m1(src + j, index_vec, vl);\n\n            // Store reordered elements into the destination matrix\n            vse64_v_f64m1(dst + i * cols + j, src_vec, vl);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_9_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid reorder_matrix_rows_simd(const double *src, double *dst, size_t rows, size_t cols, const size_t *indices) {\n    size_t vl;\n    size_t col_stride = cols * sizeof(double);\n\n    for (size_t i = 0; i < rows; i++) {\n        size_t index = indices[i];\n        const double *src_row = src + index * cols;\n        double *dst_row = dst + i * cols;\n\n        for (size_t j = 0; j < cols; j += vl) {\n            vl = vsetvl_e64m1(cols - j);\n            vfloat64m1_t vec = vle64_v_f64m1(src_row + j, vl);\n            vse64_v_f64m1(dst_row + j, vec, vl);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_9_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid reorder_matrix_rows_simd(const double *src, double *dst, size_t rows, size_t cols, const size_t *indices) {\n    size_t vl;\n    size_t i = 0;\n\n    while (i < rows) {\n        vl = vsetvl_e64m1(rows - i); // Set vector length for 64-bit elements\n        vuint64m1_t index_vec = vle64_v_u64m1(indices + i, vl); // Load indices into vector\n        vfloat64m1_t row_vec;\n\n        for (size_t j = 0; j < cols; j++) {\n            row_vec = vluxei64_v_f64m1(src + j, index_vec, vl); // Gather rows based on indices\n            vse64_v_f64m1(dst + i * cols + j, row_vec, vl); // Store reordered rows into destination\n        }\n\n        i += vl; // Move to the next chunk of rows\n    }\n}\n```"}
{"task_id": "SimdBench_10_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid vector_vector_add_simd(const int64_t *src1, const int64_t *src2, int64_t *dst, int64_t scalar, size_t length) {\n    size_t vl;\n    size_t i = 0;\n\n    while (i < length) {\n        vl = vsetvl_e64m1(length - i); // Set vector length for 64-bit integers\n        vint64m1_t vec_src1 = vle64_v_i64m1(&src1[i], vl); // Load src1 vector\n        vint64m1_t vec_src2 = vle64_v_i64m1(&src2[i], vl); // Load src2 vector\n\n        vint64m1_t vec_sum = vadd_vv_i64m1(vec_src1, vec_src2, vl); // Element-wise addition\n        vint64m1_t vec_scalar = vmv_v_x_i64m1(scalar, vl); // Broadcast scalar to vector\n        vint64m1_t vec_result = vadd_vv_i64m1(vec_sum, vec_scalar, vl); // Add scalar to the sum\n        vint64m1_t vec_final = vsra_vx_i64m1(vec_result, 1, vl); // Divide by 2 (arithmetic right shift)\n\n        vse64_v_i64m1(&dst[i], vec_final, vl); // Store result in dst\n        i += vl; // Increment index by vector length\n    }\n}\n```"}
{"task_id": "SimdBench_10_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid vector_vector_add_simd(const int64_t *src1, const int64_t *src2, int64_t *dst, int64_t scalar, size_t length) {\n    size_t vl;\n    size_t i = 0;\n    vint64m1_t v_scalar = vmv_v_x_i64m1(scalar, vsetvlmax_e64m1());\n    while (i < length) {\n        vl = vsetvl_e64m1(length - i);\n        vint64m1_t v_src1 = vle64_v_i64m1(&src1[i], vl);\n        vint64m1_t v_src2 = vle64_v_i64m1(&src2[i], vl);\n        vint64m1_t v_sum = vadd_vv_i64m1(v_src1, v_src2, vl);\n        vint64m1_t v_sum_with_scalar = vadd_vv_i64m1(v_sum, v_scalar, vl);\n        vint64m1_t v_result = vsra_vx_i64m1(v_sum_with_scalar, 1, vl);\n        vse64_v_i64m1(&dst[i], v_result, vl);\n        i += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_10_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid vector_vector_add_simd(const int64_t *src1, const int64_t *src2, int64_t *dst, int64_t scalar, size_t length) {\n    size_t vl;\n    size_t i = 0;\n    vint64m1_t v_scalar = vmv_v_x_i64m1(scalar, vsetvlmax_e64m1());\n    while (i < length) {\n        vl = vsetvl_e64m1(length - i);\n        vint64m1_t v_src1 = vle64_v_i64m1(&src1[i], vl);\n        vint64m1_t v_src2 = vle64_v_i64m1(&src2[i], vl);\n        vint64m1_t v_sum = vadd_vv_i64m1(v_src1, v_src2, vl);\n        vint64m1_t v_sum_scalar = vadd_vv_i64m1(v_sum, v_scalar, vl);\n        vint64m1_t v_result = vsra_vx_i64m1(v_sum_scalar, 1, vl);\n        vse64_v_i64m1(&dst[i], v_result, vl);\n        i += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_10_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid vector_vector_add_simd(const int64_t *src1, const int64_t *src2, int64_t *dst, int64_t scalar, size_t length) {\n    size_t vl;\n    vint64m1_t v_scalar = vmv_v_x_i64m1(scalar, vsetvlmax_e64m1()); // Broadcast scalar to vector\n    for (size_t i = 0; i < length; i += vl) {\n        vl = vsetvl_e64m1(length - i); // Set vector length\n        vint64m1_t v_src1 = vle64_v_i64m1(&src1[i], vl); // Load src1 elements\n        vint64m1_t v_src2 = vle64_v_i64m1(&src2[i], vl); // Load src2 elements\n        vint64m1_t v_sum = vadd_vv_i64m1(v_src1, v_src2, vl); // Element-wise addition of src1 and src2\n        vint64m1_t v_add_scalar = vadd_vv_i64m1(v_sum, v_scalar, vl); // Add scalar to the result\n        vint64m1_t v_result = vsra_vx_i64m1(v_add_scalar, 1, vl); // Divide by 2 (arithmetic shift right)\n        vse64_v_i64m1(&dst[i], v_result, vl); // Store the result in dst\n    }\n}\n```"}
{"task_id": "SimdBench_10_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid vector_vector_add_simd(const int64_t *src1, const int64_t *src2, int64_t *dst, int64_t scalar, size_t length) {\n    size_t vl;\n    vint64m1_t v_scalar = vmv_v_x_i64m1(scalar, vsetvlmax_e64m1()); // Broadcast scalar to vector\n\n    while (length > 0) {\n        vl = vsetvl_e64m1(length); // Set vector length based on remaining elements\n        vint64m1_t v_src1 = vle64_v_i64m1(src1, vl); // Load src1 vector\n        vint64m1_t v_src2 = vle64_v_i64m1(src2, vl); // Load src2 vector\n\n        vint64m1_t v_sum = vadd_vv_i64m1(v_src1, v_src2, vl); // Element-wise addition of src1 and src2\n        vint64m1_t v_sum_with_scalar = vadd_vv_i64m1(v_sum, v_scalar, vl); // Add scalar to the result\n        vint64m1_t v_result = vsra_vx_i64m1(v_sum_with_scalar, 1, vl); // Divide by 2 (arithmetic right shift)\n\n        vse64_v_i64m1(dst, v_result, vl); // Store the result in dst\n\n        src1 += vl;\n        src2 += vl;\n        dst += vl;\n        length -= vl;\n    }\n}\n```"}
{"task_id": "SimdBench_11_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nint vector_even_min_simd(const int *src, size_t length) {\n    if (length == 0) return -1;\n\n    size_t vl;\n    int min_val = INT32_MAX;\n\n    for (size_t i = 0; i < length; i += vl) {\n        vl = vsetvl_e32m1(length - i);\n        vbool32_t mask = vmsne_vi_b32m1(vand_vi_i32m1(vle32_v_i32m1(&src[i], vl), 1, vl), 0, vl);\n        vint32m1_t vec = vle32_v_i32m1(&src[i], vl);\n        vint32m1_t masked_vec = vmerge_vvm_i32m1(mask, vec, vint32m1_t(), vl);\n        min_val = vmin_vx_i32m1(vredmin_vs_i32m1_i32m1(masked_vec, vint32m1_t(), vl), min_val, vl);\n    }\n\n    return min_val == INT32_MAX ? -1 : min_val;\n}\n```"}
{"task_id": "SimdBench_11_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nint vector_even_min_simd(const int *src, size_t length) {\n    if (length == 0) {\n        return -1;\n    }\n\n    size_t vl;\n    int min_value = INT32_MAX;\n\n    for (size_t i = 0; i < length; i += vl) {\n        vl = vsetvl_e32m1(length - i);\n\n        vbool32_t mask = vmsne_vi_i32m1_b32(vundefined_i32m1(vl), 0, vl); // Mask for even indices\n        vint32m1_t vec = vle32_v_i32m1(src + i, vl);\n        vint32m1_t masked_vec = vmerge_vvm_i32m1(mask, vec, vundefined_i32m1(vl), vl);\n\n        vint32m1_t mins = vmin_vv_i32m1(masked_vec);\n        min_value = mins;\n    }\n\n    return min_value;\n}\n```"}
{"task_id": "SimdBench_11_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nint vector_even_min_simd(const int *src, size_t length) {\n    if (length == 0) {\n        return -1;\n    }\n\n    size_t vl;\n    int min_value = INT32_MAX;\n\n    for (size_t i = 0; i < length; i += vl) {\n        vl = vsetvl_e32m1(length - i);\n\n        vbool32_t mask = vmseq_vx_i32m1_b32(vle32_v_i32m1(src + i, vl), 0, vl);\n        vint32m1_t vec = vle32_v_i32m1(src + i, vl);\n        vint32m1_t masked_vec = vmerge_vvm_i32m1(mask, vec, INT32_MAX, vl);\n\n        min_value = vmin(masked_vec, min_value);\n    }\n\n    return min_value;\n}\n```"}
{"task_id": "SimdBench_11_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nint vector_even_min_simd(const int *src, size_t length) {\n    if (length == 0) {\n        return -1;\n    }\n\n    size_t vl;\n    int min_val = INT32_MAX;\n\n    for (size_t i = 0; i < length; i += vl) {\n        vl = vsetvl_e32m1(length - i);\n        vbool32_t mask = vmsne_vi_b32m1(vand_vi_i32m1(vle32_v_i32m1(src + i, vl), 1, vl), 1, vl);\n        vint32m1_t vec = vcompress_vm_i32m1(mask, vle32_v_i32m1(src + i, vl), vl);\n        if (vcpop_b32(mask) > 0) {\n            min_val = vmin_vv_i32m1(vle32_v_i32m1(&min_val, 1), vec, vl)[0];\n        }\n    }\n\n    return min_val == INT32_MAX ? -1 : min_val;\n}\n```"}
{"task_id": "SimdBench_11_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nint vector_even_min_simd(const int *src, size_t length) {\n    if (length == 0) return -1;\n\n    size_t vl;\n    int min_val = INT32_MAX;\n    vbool32_t mask;\n    vint32m1_t vec_src, vec_min;\n\n    for (size_t i = 0; i < length; i += vl) {\n        vl = vsetvl_e32m1(length - i);\n        vec_src = vle32_v_i32m1(&src[i], vl);\n        mask = vmseq_vx_i32m1_b32(vec_src, 0, vl); // Mask for even numbers\n        vec_min = vmerge_vvm_i32m1(mask, vec_src, vint32m1_t(INT32_MAX), vl);\n        min_val = vmin_vv_i32m1(vec_min, min_val, vl);\n    }\n\n    return min_val;\n}\n```"}
{"task_id": "SimdBench_12_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid mixed_right_shift_simd(const int *src, int *dst, uint8_t shift, size_t length) {\n    size_t vl;\n    size_t offset = 0;\n\n    while (offset < length) {\n        vl = vsetvl_e32m8(length - offset);\n\n        vint32m8_t vec_src = vle32_v_i32m8(&src[offset], vl);\n        vint32m8_t vec_arith_shift = vsra_vx_i32m8(vec_src, shift, vl);\n        vuint32m8_t vec_logical_shift = vsrl_vx_u32m8(vreinterpret_v_i32m8_u32m8(vec_src), shift, vl);\n        vint32m8_t vec_result = vadd_vv_i32m8(vec_arith_shift, vreinterpret_v_u32m8_i32m8(vec_logical_shift), vl);\n\n        vse32_v_i32m8(&dst[offset], vec_result, vl);\n        offset += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_12_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid mixed_right_shift_simd(const int *src, int *dst, uint8_t shift, size_t length) {\n    size_t vl;\n    size_t i = 0;\n\n    while (i < length) {\n        vl = vsetvl_e32m1(length - i); // Set vector length for 32-bit integers\n\n        vint32m1_t vec_src = vle32_v_i32m1(&src[i], vl); // Load source array into vector\n        vint32m1_t vec_arith_shift = vsra_vx_i32m1(vec_src, shift, vl); // Arithmetic right shift\n        vuint32m1_t vec_logical_shift = vsrl_vx_u32m1(vreinterpret_v_i32m1_u32m1(vec_src), shift, vl); // Logical right shift\n        vint32m1_t vec_logical_shift_cast = vreinterpret_v_u32m1_i32m1(vec_logical_shift); // Cast logical shift result back to int\n\n        vint32m1_t vec_result = vadd_vv_i32m1(vec_arith_shift, vec_logical_shift_cast, vl); // Add the two results\n        vse32_v_i32m1(&dst[i], vec_result, vl); // Store the result in the destination array\n\n        i += vl; // Increment index by vector length\n    }\n}\n```"}
{"task_id": "SimdBench_12_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid mixed_right_shift_simd(const int *src, int *dst, uint8_t shift, size_t length) {\n    size_t vl;\n    size_t i = 0;\n\n    while (i < length) {\n        vl = vsetvl_e32m1(length - i); // Set vector length for 32-bit integers\n        vint32m1_t vec_src = vle32_v_i32m1(&src[i], vl); // Load source array into vector\n\n        // Arithmetic right shift\n        vint32m1_t vec_arith_shift = vsra_vx_i32m1(vec_src, shift, vl);\n\n        // Logical right shift (convert to unsigned, shift, then cast back to signed)\n        vuint32m1_t vec_src_unsigned = vreinterpret_v_i32m1_u32m1(vec_src);\n        vuint32m1_t vec_logic_shift = vsrl_vx_u32m1(vec_src_unsigned, shift, vl);\n        vint32m1_t vec_logic_shift_signed = vreinterpret_v_u32m1_i32m1(vec_logic_shift);\n\n        // Add the results of arithmetic and logical shifts\n        vint32m1_t vec_result = vadd_vv_i32m1(vec_arith_shift, vec_logic_shift_signed, vl);\n\n        // Store the result in the destination array\n        vse32_v_i32m1(&dst[i], vec_result, vl);\n\n        i += vl; // Increment index by vector length\n    }\n}\n```"}
{"task_id": "SimdBench_12_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid mixed_right_shift_simd(const int *src, int *dst, uint8_t shift, size_t length) {\n    size_t vl;\n    size_t processed = 0;\n\n    while (processed < length) {\n        vl = vsetvl_e32m1(length - processed);\n\n        vint32m1_t vec_src = vle32_v_i32m1(src + processed, vl);\n        vint32m1_t vec_arith_shift = vsra_vx_i32m1(vec_src, shift, vl);\n        vuint32m1_t vec_logical_shift = vsrl_vx_u32m1(vreinterpret_v_i32m1_u32m1(vec_src), shift, vl);\n        vint32m1_t vec_logical_shift_cast = vreinterpret_v_u32m1_i32m1(vec_logical_shift);\n\n        vint32m1_t vec_result = vadd_vv_i32m1(vec_arith_shift, vec_logical_shift_cast, vl);\n        vse32_v_i32m1(dst + processed, vec_result, vl);\n\n        processed += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_12_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid mixed_right_shift_simd(const int *src, int *dst, uint8_t shift, size_t length) {\n    size_t vl;\n    size_t i = 0;\n\n    while (i < length) {\n        vl = vsetvl_e32m1(length - i); // Set vector length for 32-bit integers\n        vint32m1_t v_src = vle32_v_i32m1(src + i, vl); // Load source array into vector\n\n        // Perform arithmetic right shift\n        vint32m1_t v_arith_shift = vsra_vx_i32m1(v_src, shift, vl);\n\n        // Perform logical right shift (convert to unsigned before shifting)\n        vuint32m1_t v_src_unsigned = vreinterpret_v_i32m1_u32m1(v_src);\n        vuint32m1_t v_logic_shift = vsrl_vx_u32m1(v_src_unsigned, shift, vl);\n        vint32m1_t v_logic_shift_signed = vreinterpret_v_u32m1_i32m1(v_logic_shift);\n\n        // Add the results of arithmetic and logical shifts\n        vint32m1_t v_result = vadd_vv_i32m1(v_arith_shift, v_logic_shift_signed, vl);\n\n        // Store the result in the destination array\n        vse32_v_i32m1(dst + i, v_result, vl);\n\n        i += vl; // Increment index by the vector length\n    }\n}\n```"}
{"task_id": "SimdBench_13_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nint64_t matrix_sum_simd(const int *matrix, size_t rows, size_t cols) {\n    size_t total_elements = rows * cols;\n    size_t vl;\n    int64_t sum = 0;\n    vsetvlmax_e32m1(); // Set the vector length to the maximum supported for 32-bit elements\n\n    for (size_t i = 0; i < total_elements; i += vl) {\n        vl = vsetvl_e32m1(total_elements - i); // Set vector length for the remaining elements\n        vint32m1_t vec = vle32_v_i32m1(&matrix[i], vl); // Load a vector of 32-bit integers\n        vint64m1_t vec_sum = vwredsum_vs_i32m1_i64m1(vundefined_i64m1(), vec, vundefined_i64m1(), vl); // Widen and reduce sum\n        sum += vfmv_f_s_i64m1_i64(vec_sum); // Extract the scalar sum from the vector\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_13_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <stddef.h>\n#include <stdint.h>\n\nint64_t matrix_sum_simd(const int *matrix, size_t rows, size_t cols) {\n    size_t total_elements = rows * cols;\n    size_t vl;\n    int64_t sum = 0;\n    vint64m1_t vsum = vmv_s_x_i64m1(vsum, 0, vsetvlmax_e64m1());\n\n    for (size_t i = 0; i < total_elements; i += vl) {\n        vl = vsetvl_e32m1(total_elements - i);\n        vint32m1_t vdata = vle32_v_i32m1(&matrix[i], vl);\n        vsum = vwredsum_vs_i32m1_i64m1(vsum, vdata, vsum, vl);\n    }\n\n    sum = vmv_x_s_i64m1_i64(vsum);\n    return sum;\n}\n```"}
{"task_id": "SimdBench_13_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <stdint.h>\n\nint64_t matrix_sum_simd(const int *matrix, size_t rows, size_t cols) {\n    size_t total_elements = rows * cols;\n    size_t vl;\n    int64_t sum = 0;\n    vint64m1_t vsum = vmv_v_x_i64m1(0, vsetvlmax_e64m1()); // Initialize vector sum to 0\n\n    for (size_t i = 0; i < total_elements; i += vl) {\n        vl = vsetvl_e32m1(total_elements - i); // Set vector length for remaining elements\n        vint32m1_t vdata = vle32_v_i32m1(&matrix[i], vl); // Load elements into vector\n        vint64m1_t vdata_ext = vwcvte32_v_i64m1(vdata, vl); // Extend 32-bit integers to 64-bit\n        vsum = vadd_vv_i64m1(vsum, vdata_ext, vl); // Accumulate into vsum\n    }\n\n    // Reduce vector sum to a scalar\n    int64_t temp[rvv_vlenb() / sizeof(int64_t)];\n    vse64_v_i64m1(temp, vsum, vsetvlmax_e64m1());\n    for (size_t i = 0; i < vsetvlmax_e64m1(); i++) {\n        sum += temp[i];\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_13_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nint64_t matrix_sum_simd(const int *matrix, size_t rows, size_t cols) {\n    size_t total_elements = rows * cols;\n    size_t vl;\n    int64_t sum = 0;\n\n    for (size_t i = 0; i < total_elements; i += vl) {\n        vl = vsetvl_e32m1(total_elements - i); // Set vector length\n        vint32m1_t vec = vle32_v_i32m1(matrix + i, vl); // Load vector\n        vint64m1_t vec_sum = vwredsum_vs_i32m1_i64m1(vundefined_i64m1(), vec, vl); // Reduce and widen\n        sum += vget_i64m1(vec_sum, 0); // Extract the sum\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_13_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <stdint.h>\n\nint64_t matrix_sum_simd(const int *matrix, size_t rows, size_t cols) {\n    size_t total_elements = rows * cols;\n    size_t vl;\n    int64_t sum = 0;\n    vint64m1_t vsum = vmv_v_x_i64m1(0, vsetvlmax_e64m1()); // Initialize vector sum to 0\n\n    for (size_t i = 0; i < total_elements; i += vl) {\n        vl = vsetvl_e32m1(total_elements - i); // Set vector length\n        vint32m1_t vdata = vle32_v_i32m1(&matrix[i], vl); // Load elements into vector\n        vsum = vwredsum_vs_i32m1_i64m1(vsum, vdata, vsum, vl); // Widen and reduce sum\n    }\n\n    sum = vfmv_f_s_i64m1_i64(vsum); // Extract the final sum from the vector\n    return sum;\n}\n```"}
{"task_id": "SimdBench_14_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nsize_t argmax_simd(const int8_t *src, size_t length) {\n    if (length == 0) {\n        return 0;\n    }\n\n    size_t max_index = 0;\n    int8_t max_value = INT8_MIN;\n\n    size_t i = 0;\n    size_t vl;\n    while (i < length) {\n        vl = vsetvl_e8m1(length - i); // Set vector length for 8-bit integers\n        vint8m1_t vec = vle8_v_i8m1(&src[i], vl); // Load vector from src\n        vint8m1_t max_vec = vmv_v_x_i8m1(max_value, vl); // Initialize max vector with current max_value\n        vbool8_t mask = vmgt_vv_i8m1_b8(vec, max_vec, vl); // Compare vec > max_vec\n        max_vec = vmerge_vvm_i8m1(mask, vec, max_vec, vl); // Merge new max values\n        max_value = vmax_vv_i8m1(max_vec, vl); // Reduce to find max value\n\n        vuint8m1_t index_vec = vid_v_u8m1(vl); // Generate index vector\n        vuint8m1_t max_index_vec = vmv_v_x_u8m1(max_index, vl); // Initialize max index vector\n        max_index_vec = vmerge_vvm_u8m1(mask, index_vec, max_index_vec, vl); // Merge indices\n        max_index = vmax_vv_u8m1(max_index_vec, vl); // Reduce to find max index\n\n        i += vl;\n    }\n\n    return max_index;\n}\n```"}
{"task_id": "SimdBench_14_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nsize_t argmax_simd(const int8_t *src, size_t length) {\n    if (length == 0) {\n        return 0;\n    }\n\n    size_t max_index = 0;\n    int8_t max_value = src[0];\n\n    size_t i = 0;\n    size_t vl;\n    while (i < length) {\n        vl = vsetvl_e8m1(length - i); // Set the vector length based on remaining elements\n        vint8m1_t vec = vle8_v_i8m1(&src[i], vl); // Load a vector of elements\n        vint8m1_t max_vec = vmv_v_x_i8m1(max_value, vl); // Broadcast current max_value\n        vbool8_t mask = vmgt_vv_i8m1_b8(vec, max_vec, vl); // Compare elements with max_value\n\n        if (vfirst_m_b8(mask, vl) != -1) { // Check if any element is greater\n            int8_t new_max = vmax_vv_i8m1(vec, max_vec, vl)[0]; // Find the new max value\n            if (new_max > max_value) {\n                max_value = new_max;\n                size_t index_offset = vfirst_m_b8(mask, vl); // Find the index of the new max\n                max_index = i + index_offset;\n            }\n        }\n\n        i += vl; // Move to the next chunk\n    }\n\n    return max_index;\n}\n```"}
{"task_id": "SimdBench_14_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nsize_t argmax_simd(const int8_t *src, size_t length) {\n    if (length == 0) {\n        return 0;\n    }\n\n    size_t max_index = 0;\n    int8_t max_value = INT8_MIN;\n\n    size_t vl;\n    size_t i = 0;\n\n    while (i < length) {\n        vl = vsetvl_e8m1(length - i);\n        vint8m1_t vec = vle8_v_i8m1(src + i, vl);\n        vint8m1_t max_vec = vmv_v_x_i8m1(max_value, vl);\n        vbool8_t mask = vmgt_vv_i8m1_b8(vec, max_vec, vl);\n\n        if (vfirst_m_b8(mask, vl) != -1) {\n            max_vec = vmerge_vvm_i8m1(mask, vec, max_vec, vl);\n            max_value = vmax_vv_i8m1(max_vec, vl)[0];\n        }\n\n        vint8m1_t indices = vid_v_u8m1(vl);\n        vbool8_t mask_index = vmseq_vx_i8m1_b8(vec, max_value, vl);\n        size_t local_index = vfirst_m_b8(mask_index, vl);\n\n        if (local_index != -1) {\n            max_index = local_index;\n        }\n    }\n    return max_index;\n}\n```"}
{"task_id": "SimdBench_14_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nsize_t argmax_simd(const int8_t *src, size_t length) {\n    if (length == 0) {\n        return 0;\n    }\n\n    size_t max_index = 0;\n    int8_t max_value = INT8_MIN;\n\n    size_t i = 0;\n    size_t vl;\n    while (i < length) {\n        vl = vsetvl_e8m1(length - i); // Set the vector length\n        vint8m1_t vec = vle8_v_i8m1(&src[i], vl); // Load vector from src\n        vint8m1_t max_vec = vmv_v_x_i8m1(max_value, vl); // Broadcast current max_value\n        vbool8_t mask = vmgt_vv_i8m1_b8(vec, max_vec, vl); // Compare vec > max_vec\n        if (vfirst_m_b8(mask, vl) != -1) { // Check if any element is greater\n            max_value = vmax_vv_i8m1(vec, max_vec, vl)[0]; // Update max_value\n            max_index = i+vfirst(mask)\n}\n```"}
{"task_id": "SimdBench_14_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nsize_t argmax_simd(const int8_t *src, size_t length) {\n    if (length == 0) {\n        return 0;\n    }\n\n    size_t max_index = 0;\n    int8_t max_value = INT8_MIN;\n\n    size_t i = 0;\n    size_t vl;\n    while (i < length) {\n        vl = vsetvl_e8m1(length - i); // Set vector length\n        vint8m1_t vec = vle8_v_i8m1(src + i, vl); // Load vector\n        vint8m1_t max_vec = vmv_v_x_i8m1(max_value, vl); // Initialize max vector\n        vbool8_t mask = vmgt_vv_i8m1_b8(vec, max_vec, vl); // Compare values\n        max_vec = vmerge_vvm_i8m1(mask, vec, max_vec, vl); // Update max vector\n\n        int8_t temp_max = vmax_v_i8m1(max_vec, vl); // Find max value in vector\n        if (temp_max > max_value) {\n            max_value = temp_max;\n            for (size_t j = 0; j < vl; j++) {\n                if (src[i + j] == max_value) {\n                    max_index = i + j;\n                    break;\n                }\n            }\n        }\n        i += vl;\n    }\n\n    return max_index;\n}\n```"}
{"task_id": "SimdBench_15_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid vector_blend_simd(const uint16_t* src1, const uint16_t* src2, uint32_t mask, uint16_t* dst, size_t length) {\n    size_t vl;\n    size_t i = 0;\n\n    while (i < length) {\n        vl = vsetvl_e16m1(length - i);\n\n        vuint16m1_t vec_src1 = vle16_v_u16m1(&src1[i], vl);\n        vuint16m1_t vec_src2 = vle16_v_u16m1(&src2[i], vl);\n\n        vuint32m1_t vec_indices = vid_v_u32m1(vl);\n        vuint32m1_t vec_masked_indices = vand_vx_u32m1(vec_indices, mask, vl);\n\n        vbool16_t blend_mask = vmseq_vx_u32m1_b16(vec_masked_indices, 0, vl);\n\n        vuint16m1_t vec_result = vmerge_vvm_u16m1(blend_mask, vec_src1, vec_src2, vl);\n\n        vse16_v_u16m1(&dst[i], vec_result, vl);\n\n        i += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_15_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid vector_blend_simd(const uint16_t* src1, const uint16_t* src2, uint32_t mask, uint16_t* dst, size_t length) {\n    size_t vl;\n    size_t i = 0;\n\n    while (i < length) {\n        vl = vsetvl_e16m1(length - i); // Set vector length for 16-bit elements\n        vuint16m1_t vec_src1 = vle16_v_u16m1(&src1[i], vl); // Load src1 vector\n        vuint16m1_t vec_src2 = vle16_v_u16m1(&src2[i], vl); // Load src2 vector\n\n        // Create a vector of indices\n        vuint32m1_t vec_indices = vid_v_u32m1(vl);\n\n        // Compute (index & mask) != 0\n        vbool16_t blend_mask = vmseq_vx_u32m1_b16(vand_vx_u32m1(vec_indices, mask, vl), 0, vl);\n\n        // Blend src1 and src2 based on the mask\n        vuint16m1_t vec_result = vmerge_vvm_u16m1(blend_mask, vec_src2, vec_src1, vl);\n\n        // Store the result back to dst\n        vse16_v_u16m1(&dst[i], vec_result, vl);\n\n        i += vl; // Increment by the number of processed elements\n    }\n}\n```"}
{"task_id": "SimdBench_15_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid vector_blend_simd(const uint16_t* src1, const uint16_t* src2, uint32_t mask, uint16_t* dst, size_t length) {\n    size_t vl;\n    size_t i = 0;\n\n    while (i < length) {\n        vl = vsetvl_e16m1(length - i);\n\n        vuint16m1_t vec_src1 = vle16_v_u16m1(&src1[i], vl);\n        vuint16m1_t vec_src2 = vle16_v_u16m1(&src2[i], vl);\n\n        vint32m1_t vec_indices = vadd_vx_i32m1(vmv_v_x_i32m1(i, vl), vslide1down_vx_i32m1(vundefined_i32m1(), 0, vl), vl);\n        vuint32m1_t vec_masked = vand_vx_u32m1(vreinterpret_v_i32m1_u32m1(vec_indices), mask, vl);\n\n        vbool16_t blend_mask = vmseq_vx_u32m1_b16(vec_masked, 0, vl);\n        vuint16m1_t vec_result = vmerge_vvm_u16m1(blend_mask, vec_src2, vec_src1, vl);\n\n        vse16_v_u16m1(&dst[i], vec_result, vl);\n        i += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_15_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid vector_blend_simd(const uint16_t* src1, const uint16_t* src2, uint32_t mask, uint16_t* dst, size_t length) {\n    size_t vl;\n    size_t index = 0;\n\n    while (index < length) {\n        vl = vsetvl_e16m1(length - index); // Set vector length for 16-bit elements\n        vuint16m1_t vec_src1 = vle16_v_u16m1(&src1[index], vl); // Load src1 elements\n        vuint16m1_t vec_src2 = vle16_v_u16m1(&src2[index], vl); // Load src2 elements\n\n        // Create an index vector [index, index+1, ..., index+vl-1]\n        vuint32m1_t vec_indices = vid_v_u32m1(vl);\n\n        // Compute (index & mask) != 0 for each index\n        vuint32m1_t vec_mask = vmv_v_x_u32m1(mask, vl); // Broadcast mask\n        vuint32m1_t vec_and = vand_vv_u32m1(vec_indices, vec_mask, vl); // Perform bitwise AND\n        vbool16_t blend_mask = vmseq_vx_u32m1_b16(vec_and, 0, vl); // Check if result is 0\n\n        // Blend src1 and src2 based on the mask\n        vuint16m1_t vec_result = vmerge_vvm_u16m1(blend_mask, vec_src2, vec_src1, vl);\n\n        // Store the result in the destination array\n        vse16_v_u16m1(&dst[index], vec_result, vl);\n\n        index += vl; // Move to the next chunk\n    }\n}\n```"}
{"task_id": "SimdBench_15_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid vector_blend_simd(const uint16_t* src1, const uint16_t* src2, uint32_t mask, uint16_t* dst, size_t length) {\n    size_t vl;\n    size_t i = 0;\n\n    while (i < length) {\n        vl = vsetvl_e16m1(length - i); // Set vector length for 16-bit elements\n        vuint16m1_t v_src1 = vle16_v_u16m1(src1 + i, vl); // Load src1 vector\n        vuint16m1_t v_src2 = vle16_v_u16m1(src2 + i, vl); // Load src2 vector\n\n        // Create a mask vector based on the condition (index & mask != 0)\n        vbool16_t v_mask = vmseq_vx_u32m1_b16(vand_vx_u32m1(vslide1down_vx_u32m1(vundefined_u32m1(), i, vl), mask), 0, vl);\n\n        // Blend src1 and src2 based on the mask\n        vuint16m1_t v_result = vmerge_vvm_u16m1(v_mask, v_src1, v_src2, vl);\n\n        // Store the result in the destination array\n        vse16_v_u16m1(dst + i, v_result, vl);\n\n        i += vl; // Increment index by vector length\n    }\n}\n```"}
{"task_id": "SimdBench_16_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid population_count_simd(const uint32_t* src, uint32_t* dst, size_t length) {\n    size_t vl;\n    size_t i = 0;\n    while (i < length) {\n        vl = vsetvl_e32m1(length - i); // Set vector length based on remaining elements\n        vuint32m1_t vec_src = vle32_v_u32m1(&src[i], vl); // Load source elements into vector\n        vuint32m1_t vec_popcount = vpopc_v_u32m1(vec_src, vl); // Compute population count for each element\n        vse32_v_u32m1(&dst[i], vec_popcount, vl); // Store results into destination array\n        i += vl; // Increment index by vector length\n    }\n}\n```"}
{"task_id": "SimdBench_16_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid population_count_simd(const uint32_t* src, uint32_t* dst, size_t length) {\n    size_t vl;\n    while (length > 0) {\n        vl = vsetvl_e32m1(length); // Set the vector length for 32-bit elements\n        vuint32m1_t vec_src = vle32_v_u32m1(src, vl); // Load source elements into vector\n        vuint32m1_t vec_popcount = vpopc_v_u32m1(vec_src, vl); // Compute population count\n        vse32_v_u32m1(dst, vec_popcount, vl); // Store the result into destination array\n        src += vl; // Move the source pointer forward\n        dst += vl; // Move the destination pointer forward\n        length -= vl; // Reduce the remaining length\n    }\n}\n```"}
{"task_id": "SimdBench_16_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid population_count_simd(const uint32_t* src, uint32_t* dst, size_t length) {\n    size_t vl;\n    while (length > 0) {\n        vl = vsetvl_e32m1(length); // Set vector length for 32-bit elements\n        vuint32m1_t vec_src = vle32_v_u32m1(src, vl); // Load source elements into vector\n        vuint32m1_t vec_popcount = vpopc_v_u32m1(vec_src, vl); // Compute population count\n        vse32_v_u32m1(dst, vec_popcount, vl); // Store result into destination array\n        src += vl;\n        dst += vl;\n        length -= vl;\n    }\n}\n```"}
{"task_id": "SimdBench_16_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid population_count_simd(const uint32_t* src, uint32_t* dst, size_t length) {\n    size_t vl;\n    size_t processed = 0;\n\n    while (processed < length) {\n        vl = vsetvl_e32m1(length - processed); // Set vector length for 32-bit elements\n        vuint32m1_t vec_src = vle32_v_u32m1(src + processed, vl); // Load source elements\n        vuint32m1_t vec_popcount = vpopc_v_u32m1(vec_src, vl); // Compute population count\n        vse32_v_u32m1(dst + processed, vec_popcount, vl); // Store results in destination\n        processed += vl; // Update processed count\n    }\n}\n```"}
{"task_id": "SimdBench_16_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid population_count_simd(const uint32_t* src, uint32_t* dst, size_t length) {\n    size_t vl;\n    size_t processed = 0;\n\n    while (processed < length) {\n        vl = vsetvl_e32m1(length - processed); // Set vector length for 32-bit elements\n        vuint32m1_t vec_src = vle32_v_u32m1(src + processed, vl); // Load source elements\n        vuint32m1_t vec_dst = vpopc_v_u32m1(vec_src, vl); // Compute population count\n        vse32_v_u32m1(dst + processed, vec_dst, vl); // Store results in destination array\n        processed += vl; // Update processed count\n    }\n}\n```"}
{"task_id": "SimdBench_17_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid saturating_add_simd(const uint16_t* src1, const uint16_t* src2, uint16_t* dst, size_t length) {\n    size_t vl;\n    size_t i = 0;\n\n    while (i < length) {\n        vl = vsetvl_e16m1(length - i); // Set vector length for 16-bit elements\n        vuint16m1_t vec1 = vle16_v_u16m1(&src1[i], vl); // Load vector from src1\n        vuint16m1_t vec2 = vle16_v_u16m1(&src2[i], vl); // Load vector from src2\n        vuint16m1_t result = vaddu_vv_u16m1(vec1, vec2, vl); // Perform element-wise addition\n        vuint16m1_t saturated_result = vminu_vx_u16m1(result, UINT16_MAX, vl); // Saturate to UINT16_MAX\n        vse16_v_u16m1(&dst[i], saturated_result, vl); // Store the result in dst\n        i += vl; // Increment index by vector length\n    }\n}\n```"}
{"task_id": "SimdBench_17_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid saturating_add_simd(const uint16_t* src1, const uint16_t* src2, uint16_t* dst, size_t length) {\n    size_t vl;\n    size_t i = 0;\n\n    while (i < length) {\n        vl = vsetvl_e16m1(length - i); // Set the vector length for 16-bit elements\n        vuint16m1_t vec_src1 = vle16_v_u16m1(&src1[i], vl); // Load src1 vector\n        vuint16m1_t vec_src2 = vle16_v_u16m1(&src2[i], vl); // Load src2 vector\n        vuint16m1_t vec_result = vaddu_vv_u16m1(vec_src1, vec_src2, vl); // Perform vector addition\n        vuint16m1_t vec_saturated = vminu_vx_u16m1(vec_result, UINT16_MAX, vl); // Saturate to UINT16_MAX\n        vse16_v_u16m1(&dst[i], vec_saturated, vl); // Store the result in dst\n        i += vl; // Increment the index by the vector length\n    }\n}\n```"}
{"task_id": "SimdBench_17_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid saturating_add_simd(const uint16_t* src1, const uint16_t* src2, uint16_t* dst, size_t length) {\n    size_t vl;\n    size_t i = 0;\n\n    while (i < length) {\n        vl = vsetvl_e16m1(length - i); // Set vector length for 16-bit elements\n        vuint16m1_t vec_src1 = vle16_v_u16m1(&src1[i], vl); // Load src1 vector\n        vuint16m1_t vec_src2 = vle16_v_u16m1(&src2[i], vl); // Load src2 vector\n        vuint16m1_t vec_result = vaddu_vv_u16m1(vec_src1, vec_src2, vl); // Unsigned addition\n        vuint16m1_t vec_saturated = vminu_vx_u16m1(vec_result, UINT16_MAX, vl); // Saturate to UINT16_MAX\n        vse16_v_u16m1(&dst[i], vec_saturated, vl); // Store result to dst\n        i += vl; // Increment index by vector length\n    }\n}\n```"}
{"task_id": "SimdBench_17_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid saturating_add_simd(const uint16_t* src1, const uint16_t* src2, uint16_t* dst, size_t length) {\n    size_t vl;\n    size_t i = 0;\n\n    while (i < length) {\n        vl = vsetvl_e16m1(length - i); // Set vector length for 16-bit elements\n        vuint16m1_t vec1 = vle16_v_u16m1(src1 + i, vl); // Load src1 elements into vector\n        vuint16m1_t vec2 = vle16_v_u16m1(src2 + i, vl); // Load src2 elements into vector\n        vuint16m1_t result = vsadd_vv_u16m1(vec1, vec2, vl); // Saturating addition\n        vse16_v_u16m1(dst + i, result, vl); // Store result into dst\n        i += vl; // Increment index by vector length\n    }\n}\n```"}
{"task_id": "SimdBench_17_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid saturating_add_simd(const uint16_t* src1, const uint16_t* src2, uint16_t* dst, size_t length) {\n    size_t vl;\n    size_t offset = 0;\n\n    while (offset < length) {\n        vl = vsetvl_e16m1(length - offset); // Set the vector length for 16-bit elements\n        vuint16m1_t vec1 = vle16_v_u16m1(&src1[offset], vl); // Load src1 elements into vector\n        vuint16m1_t vec2 = vle16_v_u16m1(&src2[offset], vl); // Load src2 elements into vector\n        vuint16m1_t result = vsaddu_vv_u16m1(vec1, vec2, vl); // Perform saturating addition\n        vse16_v_u16m1(&dst[offset], result, vl); // Store the result into dst\n        offset += vl; // Increment the offset by the vector length\n    }\n}\n```"}
{"task_id": "SimdBench_18_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid range_matrix_mul_simd(const double* A, const double* B, double* C, size_t m, size_t n, size_t p) {\n    size_t vlmax = vsetvlmax_e64m1(); // Maximum vector length for 64-bit elements\n    double lower_bound = -100.0, upper_bound = 100.0;\n\n    for (size_t i = 0; i < m; i++) {\n        for (size_t j = 0; j < p; j++) {\n            double sum = 0.0;\n            size_t k = 0;\n\n            while (k < n) {\n                size_t vl = vsetvl_e64m1(n - k); // Set vector length for remaining elements\n\n                vfloat64m1_t a_vec = vle64_v_f64m1(&A[i * n + k], vl); // Load A row segment\n                vfloat64m1_t b_vec = vle64_v_f64m1(&B[k * p + j], vl); // Load B column segment\n\n                vbool64_t a_mask = vmfge_vf_f64m1_b64(a_vec, lower_bound, vl); // A >= lower_bound\n                a_mask = vmfle_vf_f64m1_b64_m(a_mask, a_mask, a_vec, upper_bound, vl); // A <= upper_bound\n\n                vbool64_t b_mask = vmfge_vf_f64m1_b64(b_vec, lower_bound, vl); // B >= lower_bound\n                b_mask = vmfle_vf_f64m1_b64_m(b_mask, b_mask, b_vec, upper_bound, vl); // B <= upper_bound\n\n                vbool64_t valid_mask = vmand_mm_b64(a_mask, b_mask, vl); // Combine masks\n\n                vfloat64m1_t valid_a = vmerge_vvm_f64m1(vundefined_f64m1(), a_vec, valid_mask, vl);\n                vfloat64m1_t valid_b = vmerge_vvm_f64m1(vundefined_f64m1(), b_vec, valid_mask, vl);\n\n                vfloat64m1_t prod = vfmul_vv_f64m1(valid_a, valid_b, vl); // Multiply valid elements\n                sum += vfredsum_vs_f64m1_f64m1(vundefined_f64m1(), prod, vundefined_f64m1(), vl); // Reduce sum\n\n                k += vl;\n            }\n\n            C[i * p + j] = sum;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_18_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid range_matrix_mul_simd(const double* A, const double* B, double* C, size_t m, size_t n, size_t p) {\n    const double lower_bound = -100.0;\n    const double upper_bound = 100.0;\n\n    for (size_t i = 0; i < m; i++) {\n        for (size_t j = 0; j < p; j++) {\n            double sum = 0.0;\n            size_t k = 0;\n\n            while (k < n) {\n                size_t vl = vsetvl_e64m1(n - k); // Set vector length for remaining elements\n                vfloat64m1_t vec_a = vle64_v_f64m1(&A[i * n + k], vl); // Load A row\n                vfloat64m1_t vec_b = vle64_v_f64m1(&B[j + k * p], vl); // Load B column\n\n                // Check bounds for A\n                vbool64_t mask_a_lower = vmfge_vf_f64m1_b64(vec_a, lower_bound, vl);\n                vbool64_t mask_a_upper = vmfle_vf_f64m1_b64(vec_a, upper_bound, vl);\n                vbool64_t mask_a = vmand_mm_b64(mask_a_lower, mask_a_upper, vl);\n\n                // Check bounds for B\n                vbool64_t mask_b_lower = vmfge_vf_f64m1_b64(vec_b, lower_bound, vl);\n                vbool64_t mask_b_upper = vmfle_vf_f64m1_b64(vec_b, upper_bound, vl);\n                vbool64_t mask_b = vmand_mm_b64(mask_b_lower, mask_b_upper, vl);\n\n                // Combine masks for A and B\n                vbool64_t mask = vmand_mm_b64(mask_a, mask_b, vl);\n\n                // Multiply A and B with masking\n                vfloat64m1_t vec_mul = vfmul_vv_f64m1_m(mask, vfmv_v_f_f64m1(0.0, vl), vec_a, vec_b, vl);\n\n                // Horizontal sum of the masked multiplication\n                sum += vfredsum_vs_f64m1_f64m1(vfmv_s_f_f64m1(0.0, vl), vec_mul, vfmv_s_f_f64m1(0.0, vl), vl);\n\n                k += vl;\n            }\n\n            C[i * p + j] = sum;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_18_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid range_matrix_mul_simd(const double* A, const double* B, double* C, size_t m, size_t n, size_t p) {\n    size_t vlmax = vsetvlmax_e64m1(); // Maximum vector length for 64-bit elements\n    vfloat64m1_t vneg100 = vfmv_v_f_f64m1(-100.0, vlmax);\n    vfloat64m1_t vpos100 = vfmv_v_f_f64m1(100.0, vlmax);\n\n    for (size_t i = 0; i < m; i++) {\n        for (size_t j = 0; j < p; j++) {\n            double sum = 0.0;\n            for (size_t k = 0; k < n; k += vlmax) {\n                size_t vl = vsetvl_e64m1(n - k); // Set vector length for remaining elements\n                vfloat64m1_t va = vle64_v_f64m1(&A[i * n + k], vl);\n                vfloat64m1_t vb = vle64_v_f64m1(&B[k * p + j], vl);\n\n                vbool64_t mask_a = vmfge_vv_f64m1_b64(va, vneg100, vl); // A[i] >= -100\n                mask_a = vmfle_vv_f64m1_b64(va, vpos100, vl);           // A[i] <= 100\n                vbool64_t mask_b = vmfge_vv_f64m1_b64(vb, vneg100, vl); // B[i] >= -100\n                mask_b = vmfle_vv_f64m1_b64(vb, vpos100, vl);           // B[i] <= 100\n                vbool64_t mask = vmand_mm_b64(mask_a, mask_b, vl);      // Combine masks\n\n                vfloat64m1_t vprod = vfmul_vv_f64m1(va, vb, vl);        // Multiply A and B\n                vprod = vmerge_vvm_f64m1(mask, vprod, vfmv_v_f_f64m1(0.0, vl), vl); // Mask invalid products\n\n                sum += vfredsum_vs_f64m1_f64m1(vprod, vfmv_s_f_f64m1(0.0), vl); // Reduce sum\n            }\n            C[i * p + j] = sum;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_18_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid range_matrix_mul_simd(const double* A, const double* B, double* C, size_t m, size_t n, size_t p) {\n    size_t vlmax = vsetvlmax_e64m1(); // Maximum vector length for 64-bit elements\n    vfloat64m1_t v_neg_100 = vfmv_v_f_f64m1(-100.0, vlmax);\n    vfloat64m1_t v_pos_100 = vfmv_v_f_f64m1(100.0, vlmax);\n\n    for (size_t i = 0; i < m; i++) {\n        for (size_t j = 0; j < p; j++) {\n            double sum = 0.0;\n            size_t k = 0;\n\n            for (; k + vlmax <= n; k += vlmax) {\n                size_t vl = vsetvl_e64m1(vlmax);\n\n                vfloat64m1_t v_a = vle64_v_f64m1(&A[i * n + k], vl);\n                vfloat64m1_t v_b = vle64_v_f64m1(&B[k * p + j], vl);\n\n                vbool64_t mask_a = vmfge_vv_f64m1_b64(v_a, v_neg_100, vl);\n                mask_a = vmfle_vv_f64m1_b64(v_a, v_pos_100, vl) & mask_a;\n\n                vbool64_t mask_b = vmfge_vv_f64m1_b64(v_b, v_neg_100, vl);\n                mask_b = vmfle_vv_f64m1_b64(v_b, v_pos_100, vl) & mask_b;\n\n                vbool64_t mask = mask_a & mask_b;\n\n                vfloat64m1_t v_mul = vfmul_vv_f64m1(v_a, v_b, vl);\n                v_mul = vmerge_vvm_f64m1(mask, v_mul, vfmv_v_f_f64m1(0.0, vl), vl);\n\n                sum += vfredsum_vs_f64m1_f64m1(v_mul, vfmv_s_f_f64m1(0.0, vl), vl);\n            }\n\n            for (; k < n; k++) {\n                double a_val = A[i * n + k];\n                double b_val = B[k * p + j];\n                if (a_val >= -100.0 && a_val <= 100.0 && b_val >= -100.0 && b_val <= 100.0) {\n                    sum += a_val * b_val;\n                }\n            }\n\n            C[i * p + j] = sum;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_18_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid range_matrix_mul_simd(const double* A, const double* B, double* C, size_t m, size_t n, size_t p) {\n    const double lower_bound = -100.0;\n    const double upper_bound = 100.0;\n\n    for (size_t i = 0; i < m; i++) {\n        for (size_t j = 0; j < p; j++) {\n            double sum = 0.0;\n            size_t k = 0;\n\n            while (k < n) {\n                size_t vl = vsetvl_e64m1(n - k); // Set the vector length for remaining elements\n\n                vfloat64m1_t vecA = vle64_v_f64m1(&A[i * n + k], vl); // Load A row\n                vfloat64m1_t vecB = vle64_v_f64m1(&B[k * p + j], vl); // Load B column\n\n                // Check bounds for A\n                vbool64_t maskA = vmfle_vf_f64m1_b64(vecA, upper_bound, vl);\n                maskA = vmand_mm_b64(maskA, vmfge_vf_f64m1_b64(vecA, lower_bound, vl));\n\n                // Check bounds for B\n                vbool64_t maskB = vmfle_vf_f64m1_b64(vecB, upper_bound, vl);\n                maskB = vmand_mm_b64(maskB, vmfge_vf_f64m1_b64(vecB, lower_bound, vl));\n\n                // Combine masks for A and B\n                vbool64_t mask = vmand_mm_b64(maskA, maskB);\n\n                // Perform multiplication only for valid elements\n                vfloat64m1_t vecMul = vfmul_vv_f64m1_m(mask, vecA, vecA, vecB, vl);\n\n                // Sum the results\n                sum += vfredsum_vs_f64m1_f64m1(vecMul, vfmv_s_f_f64m1(0.0, vl), vl);\n\n                k += vl;\n            }\n\n            C[i * p + j] = sum;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_19_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid tensor_add_3d_simd(const int64_t* A, const int64_t* B, int64_t* C, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t vl;\n    size_t i = 0;\n\n    while (i < total_elements) {\n        vl = vsetvl_e64m1(total_elements - i); // Set vector length for 64-bit elements\n        vint64m1_t vecA = vle64_v_i64m1(&A[i], vl); // Load vector from A\n        vint64m1_t vecB = vle64_v_i64m1(&B[i], vl); // Load vector from B\n        vint64m1_t vecC = vadd_vv_i64m1(vecA, vecB, vl); // Perform element-wise addition\n        vse64_v_i64m1(&C[i], vecC, vl); // Store the result in C\n        i += vl; // Increment index by the vector length\n    }\n}\n```"}
{"task_id": "SimdBench_19_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid tensor_add_3d_simd(const int64_t* A, const int64_t* B, int64_t* C, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t vl;\n    size_t i = 0;\n\n    while (i < total_elements) {\n        vl = vsetvl_e64m1(total_elements - i); // Set vector length for 64-bit elements\n        vint64m1_t vecA = vle64_v_i64m1(&A[i], vl); // Load vector from A\n        vint64m1_t vecB = vle64_v_i64m1(&B[i], vl); // Load vector from B\n        vint64m1_t vecC = vadd_vv_i64m1(vecA, vecB, vl); // Perform element-wise addition\n        vse64_v_i64m1(&C[i], vecC, vl); // Store result in C\n        i += vl; // Increment index by vector length\n    }\n}\n```"}
{"task_id": "SimdBench_19_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid tensor_add_3d_simd(const int64_t* A, const int64_t* B, int64_t* C, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t vl;\n    size_t i = 0;\n\n    while (i < total_elements) {\n        vl = vsetvl_e64m1(total_elements - i); // Set vector length for 64-bit integers\n        vint64m1_t va = vle64_v_i64m1(&A[i], vl); // Load vector from A\n        vint64m1_t vb = vle64_v_i64m1(&B[i], vl); // Load vector from B\n        vint64m1_t vc = vadd_vv_i64m1(va, vb, vl); // Perform element-wise addition\n        vse64_v_i64m1(&C[i], vc, vl); // Store the result in C\n        i += vl; // Increment the index by the vector length\n    }\n}\n```"}
{"task_id": "SimdBench_19_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid tensor_add_3d_simd(const int64_t* A, const int64_t* B, int64_t* C, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t vl;\n    size_t offset = 0;\n\n    while (offset < total_elements) {\n        vl = vsetvl_e64m1(total_elements - offset); // Set vector length for 64-bit integers\n        vint64m1_t va = vle64_v_i64m1(&A[offset], vl); // Load vector from A\n        vint64m1_t vb = vle64_v_i64m1(&B[offset], vl); // Load vector from B\n        vint64m1_t vc = vadd_vv_i64m1(va, vb, vl);     // Perform element-wise addition\n        vse64_v_i64m1(&C[offset], vc, vl);            // Store the result in C\n        offset += vl;                                 // Increment offset by the vector length\n    }\n}\n```"}
{"task_id": "SimdBench_19_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid tensor_add_3d_simd(const int64_t* A, const int64_t* B, int64_t* C, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t vl;\n    size_t index = 0;\n\n    while (index < total_elements) {\n        vl = vsetvl_e64m1(total_elements - index); // Set vector length for 64-bit integers\n        vint64m1_t vecA = vle64_v_i64m1(&A[index], vl); // Load vector from A\n        vint64m1_t vecB = vle64_v_i64m1(&B[index], vl); // Load vector from B\n        vint64m1_t vecC = vadd_vv_i64m1(vecA, vecB, vl); // Perform element-wise addition\n        vse64_v_i64m1(&C[index], vecC, vl); // Store result in C\n        index += vl; // Move to the next chunk\n    }\n}\n```"}
{"task_id": "SimdBench_20_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid vector_add_round_nearest_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    size_t vl;\n    size_t i = 0;\n\n    while (i < length) {\n        vl = vsetvl_e32m1(length - i); // Set vector length for 32-bit elements\n        vfloat32m1_t v_src1 = vle32_v_f32m1(src1 + i, vl); // Load src1 vector\n        vfloat32m1_t v_src2 = vle32_v_f32m1(src2 + i, vl); // Load src2 vector\n\n        vfloat32m1_t v_sum = vfadd_vv_f32m1(v_src1, v_src2, vl); // Element-wise addition\n        vint32m1_t v_rounded = vfcvt_x_f_v_i32m1(v_sum, vl); // Convert to nearest integer\n\n        vse32_v_f32m1(dst + i, vfcvt_f_x_v_f32m1(v_rounded, vl), vl); // Store rounded results\n        i += vl; // Increment index by vector length\n    }\n}\n```"}
{"task_id": "SimdBench_20_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid vector_add_round_nearest_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    size_t vl;\n    size_t i = 0;\n\n    while (i < length) {\n        vl = vsetvl_e32m1(length - i); // Set the vector length for 32-bit floats\n        vfloat32m1_t v_src1 = vle32_v_f32m1(src1 + i, vl); // Load src1 vector\n        vfloat32m1_t v_src2 = vle32_v_f32m1(src2 + i, vl); // Load src2 vector\n\n        vfloat32m1_t v_sum = vfadd_vv_f32m1(v_src1, v_src2, vl); // Element-wise addition\n        vfloat32m1_t v_rounded = vfrint_v_f32m1(v_sum, vl); // Round to nearest integer\n\n        vse32_v_f32m1(dst + i, v_rounded, vl); // Store the result in dst\n        i += vl; // Increment index by vector length\n    }\n}\n```"}
{"task_id": "SimdBench_20_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid vector_add_round_nearest_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    size_t vl;\n    size_t i = 0;\n\n    while (i < length) {\n        vl = vsetvl_e32m8(length - i); // Set the vector length for 32-bit floats\n        vfloat32m8_t vec1 = vle32_v_f32m8(&src1[i], vl); // Load src1 elements\n        vfloat32m8_t vec2 = vle32_v_f32m8(&src2[i], vl); // Load src2 elements\n        vfloat32m8_t sum = vfadd_vv_f32m8(vec1, vec2, vl); // Perform element-wise addition\n        vfloat32m8_t rounded = vrndn_v_f32m8(sum, vl); // Round to nearest integer\n        vse32_v_f32m8(&dst[i], rounded, vl); // Store the result in dst\n        i += vl; // Increment the index by the vector length\n    }\n}\n```"}
{"task_id": "SimdBench_20_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid vector_add_round_nearest_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    size_t vl;\n    size_t i = 0;\n\n    while (i < length) {\n        vl = vsetvl_e32m8(length - i); // Set the vector length for 32-bit floats\n        vfloat32m8_t vec1 = vle32_v_f32m8(&src1[i], vl); // Load src1 elements\n        vfloat32m8_t vec2 = vle32_v_f32m8(&src2[i], vl); // Load src2 elements\n        vfloat32m8_t sum = vfadd_vv_f32m8(vec1, vec2, vl); // Element-wise addition\n        vfloat32m8_t rounded = vrndn_v_f32m8(sum, vl); // Round to nearest integer\n        vse32_v_f32m8(&dst[i], rounded, vl); // Store the result in dst\n        i += vl; // Increment the index by the vector length\n    }\n}\n```"}
{"task_id": "SimdBench_20_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid vector_add_round_nearest_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    size_t vl;\n    size_t i = 0;\n    while (i < length) {\n        vl = vsetvl_e32m1(length - i); // Set the vector length for 32-bit floats\n        vfloat32m1_t vec_src1 = vle32_v_f32m1(src1 + i, vl); // Load src1 vector\n        vfloat32m1_t vec_src2 = vle32_v_f32m1(src2 + i, vl); // Load src2 vector\n        vfloat32m1_t vec_sum = vfadd_vv_f32m1(vec_src1, vec_src2, vl); // Element-wise addition\n        vint32m1_t vec_rounded = vfcvt_x_f_v_i32m1(vec_sum, vl); // Convert to nearest integer\n        vfloat32m1_t vec_result = vfcvt_f_x_v_f32m1(vec_rounded, vl); // Convert back to float\n        vse32_v_f32m1(dst + i, vec_result, vl); // Store the result in dst\n        i += vl; // Increment index by vector length\n    }\n}\n```"}
{"task_id": "SimdBench_21_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <math.h>\n\nvoid vector_mul_round_up_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    size_t vl;\n    size_t i = 0;\n\n    while (i < length) {\n        vl = vsetvl_e32m1(length - i);\n\n        vfloat32m1_t v_src1 = vle32_v_f32m1(&src1[i], vl);\n        vfloat32m1_t v_src2 = vle32_v_f32m1(&src2[i], vl);\n        vfloat32m1_t v_dst = vfmv_v_f_f32m1(-1.0f, vl);\n\n        vfloat32m1_t v_diff = vfsub_vv_f32m1(v_src1, v_src2, vl);\n        vfloat32m1_t v_abs_diff = vfabs_v_f32m1(v_diff, vl);\n\n        vbool32_t v_cond1 = vmfgt_vf_f32m1_b32(vfsub_vf_f32m1(v_abs_diff, 50.0f, vl), 0.0f, vl);\n        vbool32_t v_cond2 = vmsne_vx_i32m1_b32(vand_vx_i32m1(vreinterpret_v_f32m1_i32m1(vle32_v_f32m1(&src1[i], vl)), 1, vl), 0, vl);\n        vbool32_t v_cond = vmnor_mm_b32(v_cond1, v_cond2, vl);\n\n        vfloat32m1_t v_mul = vfmul_vv_f32m1(v_src1, v_src2, vl);\n        v_mul = vround_v_f32m1(v_mul, vl);\n        v_dst = vmerge_vv_f32m1(v_dst, v_mul, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_21_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <math.h>\n\nvoid vector_mul_round_up_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    size_t vl;\n    size_t i = 0;\n\n    while (i < length) {\n        vl = vsetvl_e32m1(length - i);\n\n        vfloat32m1_t v_src1 = vle32_v_f32m1(&src1[i], vl);\n        vfloat32m1_t v_src2 = vle32_v_f32m1(&src2[i], vl);\n\n        vfloat32m1_t v_diff = vfsub_vv_f32m1(v_src1, v_src2, vl);\n        vfloat32m1_t v_abs_diff = vfabs_v_f32m1(v_diff, vl);\n\n        vuint32m1_t v_indices = vid_v_u32m1(vl);\n        vuint32m1_t v_index_mask = vmseq_vx_u32m1_b32(vand_vx_u32m1(v_indices, 1, vl), 0, vl);\n\n        vbool32_t v_condition1 = vmfle_vf_f32m1_b32(v_abs_diff, 50.0f, vl);\n        vbool32_t v_condition2 = vindex_mask;\n\n        vbool32_t v_final_condition = vmand_mm_b32(v_condition1, v_condition2, vl);\n\n        vfloat32m1_t v_result = vfmul_vv_f32m1(v_src1, v_src2, vl);\n        v_result = vfcvt_rtz_x_f32m1(v_result, vl);\n        v_result = vmerge_vx_f32m1(v_result, -1.0f, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_21_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <math.h>\n\nvoid vector_mul_round_up_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    size_t vl;\n    size_t i = 0;\n\n    while (i < length) {\n        vl = vsetvl_e32m1(length - i);\n\n        vfloat32m1_t v_src1 = vle32_v_f32m1(&src1[i], vl);\n        vfloat32m1_t v_src2 = vle32_v_f32m1(&src2[i], vl);\n\n        vfloat32m1_t v_diff = vfsub_vv_f32m1(v_src1, v_src2, vl);\n        vfloat32m1_t v_abs_diff = vfabs_v_f32m1(v_diff, vl);\n\n        vbool32_t v_within_50 = vmfle_vf_f32m1_b32(v_abs_diff, 50.0f, vl);\n        vuint32m1_t v_indices = vid_v_u32m1(vl);\n        vbool32_t v_even_indices = vmseq_vx_u32m1_b32(vand_vx_u32m1(v_indices, 1, vl), 0, vl);\n\n        vbool32_t v_condition = vmand_mm_b32(v_within_50, v_even_indices, vl);\n\n        vfloat32m1_t v_mul = vfmul_vv_f32m1(v_src1, v_src2, vl);\n        vfloat32m1_t v_ceil_mul = vfcvt_rtz_x_f_v_f32m1(v_mul, vl);\n        v_ceil_mul = vfadd_vf_f32m1(v_ceil_mul, 1.0f, vl);\n        v_ceil_mul = vfmin_vv_f32m1(v_ceil_mul, v_mul, vl);\n\n        vfloat32m1_t v_result = vmv_v_x_f32m1(-1.0f, vl);\n        v_result = vmerge_vvm_f32m1(v_condition, v_ceil_mul, v_result, vl);\n\n        vse32_v_f32m1(&dst[i], v_result, vl);\n\n        i += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_21_RVV", "completion": "```c\n#include <math.h>\n#include <riscv_vector.h>\n\nvoid vector_mul_round_up_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    size_t vl;\n    size_t i = 0;\n\n    while (i < length) {\n        vl = vsetvl_e32m1(length - i);\n\n        vfloat32m1_t v_src1 = vle32_v_f32m1(&src1[i], vl);\n        vfloat32m1_t v_src2 = vle32_v_f32m1(&src2[i], vl);\n\n        vfloat32m1_t v_diff = vfsub_vv_f32m1(v_src1, v_src2, vl);\n        vfloat32m1_t v_abs_diff = vfabs_v_f32m1(v_diff, vl);\n\n        vbool32_t v_within_50 = vmflt_vf_f32m1_b32(v_abs_diff, 50.0f, vl);\n        vbool32_t v_index_multiple_of_2 = vmseq_vi_u32m1_b32(vslide1down_vx_u32m1(vle32_v_u32m1((const uint32_t*)&i, vl), 0, vl), 0, vl);\n\n        vbool32_t v_condition = vmand_mm_b32(v_within_50, v_index_multiple_of_2, vl);\n\n        vfloat32m1_t v_result = vfmul_vv_f32m1(v_src1, v_src2, vl);\n        v_result = vceil_v_f32m1(v_result, vl);\n\n        vfloat32m1_t v_neg_one = vfmv_v_f_f32m1(-1.0f, vl);\n        v_result = vmerge_vvm_f32m1(v_condition, v_result, v_neg_one, vl);\n\n        vse32_v_f32m1(&dst[i], v_result, vl);\n\n        i += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_21_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <math.h>\n\nvoid vector_mul_round_up_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    size_t vl;\n    size_t i = 0;\n    vfloat32m1_t v_neg_one = vfmv_v_f_f32m1(-1.0f, vsetvlmax_e32m1()); // Vector of -1.0\n\n    while (i < length) {\n        vl = vsetvl_e32m1(length - i); // Set vector length\n        vfloat32m1_t v_src1 = vle32_v_f32m1(&src1[i], vl); // Load src1\n        vfloat32m1_t v_src2 = vle32_v_f32m1(&src2[i], vl); // Load src2\n\n        vfloat32m1_t v_diff = vfsub_vv_f32m1(v_src1, v_src2, vl); // Compute src1 - src2\n        vfloat32m1_t v_abs_diff = vfabs_v_f32m1(v_diff, vl); // Compute absolute value of the difference\n\n        vbool32_t v_cond1 = vmfgt_vf_f32m1_b32(vfsub_vf_f32m1(v_abs_diff, 50.0f, vl), 0.0f, vl); // abs_diff > 50\n        vbool32_t v_cond2 = vmsne_vi_i32m1_b32(vand_vx_i32m1(vreinterpret_v_f32m1_i32m1(vslide1down_vx_i32m1(vreinterpret_v_f32m1_i32m1(v_neg_one),0,vl),vl),2),0,vl); // index multiple of 2\n\n        vbool32_t v_final_cond = vmnand_mm_b32(v_cond1,v_cond2,vl); // Combine conditions\n        vfloat32m1_t v_mul = vfmul_vv_f32m1(v_src1, v_src2, vl); // Element-wise multiplication\n        vfloat32m1_t v_rounded = vfceil_v_f32m1(v_mul, vl); // Round up toward positive infinity\n\n        vfloat32m1_t v_result = vmerge_vvm_f32m1(v_final_cond, v_rounded, v_neg_one, vl); // Apply conditions\n        vse32_v_f32m1(&dst[i], v_result, vl); // Store result in dst\n\n        i += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_22_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid matrix_scalar_mul_simd(const double* mat, double scalar, double* dst, size_t m, size_t n) {\n    size_t total_elements = m * n;\n    size_t vl;\n    vfloat64m1_t v_scalar = vfmv_v_f_f64m1(scalar, vsetvlmax_e64m1()); // Broadcast scalar to vector\n\n    for (size_t i = 0; i < total_elements; i += vl) {\n        vl = vsetvl_e64m1(total_elements - i); // Determine vector length\n        vfloat64m1_t v_mat = vle64_v_f64m1(&mat[i], vl); // Load elements from mat\n        vfloat64m1_t v_result = vfmul_vv_f64m1(v_mat, v_scalar, vl); // Multiply mat elements with scalar\n        vse64_v_f64m1(&dst[i], v_result, vl); // Store result in dst\n    }\n}\n```"}
{"task_id": "SimdBench_22_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid matrix_scalar_mul_simd(const double* mat, double scalar, double* dst, size_t m, size_t n) {\n    size_t total_elements = m * n;\n    size_t vl;\n    vfloat64m1_t v_scalar = vfmv_v_f_f64m1(scalar, vsetvlmax_e64m1()); // Broadcast scalar to vector\n\n    for (size_t i = 0; i < total_elements; i += vl) {\n        vl = vsetvl_e64m1(total_elements - i); // Determine vector length for remaining elements\n        vfloat64m1_t v_mat = vle64_v_f64m1(&mat[i], vl); // Load elements from mat\n        vfloat64m1_t v_result = vfmul_vv_f64m1(v_mat, v_scalar, vl); // Multiply mat elements with scalar\n        vse64_v_f64m1(&dst[i], v_result, vl); // Store the result in dst\n    }\n}\n```"}
{"task_id": "SimdBench_22_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid matrix_scalar_mul_simd(const double* mat, double scalar, double* dst, size_t m, size_t n) {\n    size_t total_elements = m * n;\n    size_t vl;\n    vfloat64m1_t v_scalar = vfmv_v_f_f64m1(scalar, vsetvlmax_e64m1());\n    \n    for (size_t i = 0; i < total_elements; i += vl) {\n        vl = vsetvl_e64m1(total_elements - i);\n        vfloat64m1_t v_mat = vle64_v_f64m1(&mat[i], vl);\n        vfloat64m1_t v_result = vfmul_vv_f64m1(v_mat, v_scalar, vl);\n        vse64_v_f64m1(&dst[i], v_result, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_22_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid matrix_scalar_mul_simd(const double* mat, double scalar, double* dst, size_t m, size_t n) {\n    size_t total_elements = m * n;\n    size_t vl;\n    vfloat64m1_t v_scalar = vfmv_v_f_f64m1(scalar, vsetvlmax_e64m1()); // Broadcast scalar to vector\n\n    for (size_t i = 0; i < total_elements; i += vl) {\n        vl = vsetvl_e64m1(total_elements - i); // Set vector length\n        vfloat64m1_t v_mat = vle64_v_f64m1(&mat[i], vl); // Load elements from mat\n        vfloat64m1_t v_result = vfmul_vv_f64m1(v_mat, v_scalar, vl); // Multiply mat elements with scalar\n        vse64_v_f64m1(&dst[i], v_result, vl); // Store the result in dst\n    }\n}\n```"}
{"task_id": "SimdBench_22_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid matrix_scalar_mul_simd(const double* mat, double scalar, double* dst, size_t m, size_t n) {\n    size_t total_elements = m * n;\n    size_t vl;\n    vfloat64m1_t v_scalar = vfmv_v_f_f64m1(scalar, vsetvlmax_e64m1()); // Broadcast scalar to vector\n\n    for (size_t i = 0; i < total_elements; i += vl) {\n        vl = vsetvl_e64m1(total_elements - i); // Set vector length\n        vfloat64m1_t v_mat = vle64_v_f64m1(&mat[i], vl); // Load elements from mat\n        vfloat64m1_t v_result = vfmul_vv_f64m1(v_mat, v_scalar, vl); // Multiply mat elements with scalar\n        vse64_v_f64m1(&dst[i], v_result, vl); // Store result in dst\n    }\n}\n```"}
{"task_id": "SimdBench_23_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <math.h>\n\nvoid matrix_normalize_rows_simd(float* mat, size_t m, size_t n) {\n    size_t vlmax = vsetvlmax_e32m1(); // Maximum vector length for 32-bit floats\n    for (size_t i = 0; i < m; i++) {\n        float* row = mat + i * n;\n        size_t remaining = n;\n        size_t offset = 0;\n        float sum_of_squares = 0.0f;\n\n        // Compute the sum of squares of the row elements\n        while (remaining > 0) {\n            size_t vl = vsetvl_e32m1(remaining);\n            vfloat32m1_t v_row = vle32_v_f32m1(row + offset, vl);\n            vfloat32m1_t v_squared = vfmul_vv_f32m1(v_row, v_row, vl);\n            sum_of_squares += vfredsum_vs_f32m1_f32m1(v_squared, v_squared, vl).val[0];\n            offset += vl;\n            remaining -= vl;\n        }\n\n        float l2_norm = sqrtf(sum_of_squares);\n        if (l2_norm == 0.0f) continue; // Avoid division by zero\n\n        // Normalize the row elements\n        remaining = n;\n        offset = 0;\n        while (remaining > 0) {\n            size_t vl = vsetvl_e32m1(remaining);\n            vfloat32m1_t v_row = vle32_v_f32m1(row + offset, vl);\n            vfloat32m1_t v_normalized = vfdiv_vf_f32m1(v_row, l2_norm, vl);\n            vse32_v_f32m1(row + offset, v_normalized, vl);\n            offset += vl;\n            remaining -= vl;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_23_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <math.h>\n\nvoid matrix_normalize_rows_simd(float* mat, size_t m, size_t n) {\n    size_t vlmax = vsetvlmax_e32m1(); // Maximum vector length for 32-bit floats\n    for (size_t row = 0; row < m; row++) {\n        float* row_ptr = mat + row * n;\n\n        // Step 1: Compute L^2 norm of the row\n        float sum_of_squares = 0.0f;\n        size_t col = 0;\n        while (col < n) {\n            size_t vl = vsetvl_e32m1(n - col); // Set vector length based on remaining elements\n            vfloat32m1_t vec = vle32_v_f32m1(row_ptr + col, vl); // Load elements of the row\n            vfloat32m1_t squared = vfmul_vv_f32m1(vec, vec, vl); // Square the elements\n            sum_of_squares += vfredsum_vs_f32m1_f32m1(vundefined_f32m1(), squared, vl); // Reduce sum\n            col += vl;\n        }\n        float l2_norm = sqrtf(sum_of_squares);\n\n        // Step 2: Normalize the row\n        col = 0;\n        while (col < n) {\n            size_t vl = vsetvl_e32m1(n - col); // Set vector length based on remaining elements\n            vfloat32m1_t vec = vle32_v_f32m1(row_ptr + col, vl); // Load elements of the row\n            vfloat32m1_t normalized = vfdiv_vf_f32m1(vec, l2_norm, vl); // Divide by L^2 norm\n            vse32_v_f32m1(row_ptr + col, normalized, vl); // Store normalized elements back\n            col += vl;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_23_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <math.h>\n\nvoid matrix_normalize_rows_simd(float* mat, size_t m, size_t n) {\n    size_t vlmax = vsetvlmax_e32m1(); // Maximum vector length for 32-bit floats\n    for (size_t i = 0; i < m; i++) {\n        float* row = mat + i * n;\n        size_t remaining = n;\n        size_t offset = 0;\n        vfloat32m1_t vsum = vfmv_v_f_f32m1(0.0f, vlmax); // Initialize sum vector to 0\n\n        // Compute the sum of squares of the row elements\n        while (remaining > 0) {\n            size_t vl = vsetvl_e32m1(remaining);\n            vfloat32m1_t vrow = vle32_v_f32m1(row + offset, vl);\n            vsum = vfmacc_vv_f32m1(vsum, vrow, vrow, vl); // vsum += vrow * vrow\n            remaining -= vl;\n            offset += vl;\n        }\n\n        // Reduce the sum vector to a scalar\n        float sum_of_squares = vfmv_f_s_f32m1_f32(vsum);\n        for (size_t j = 1; j < vlmax; j++) {\n            sum_of_squares += vfmv_f_s_f32m1_f32(vslide1down_vx_f32m1(vsum, 0, j));\n        }\n\n        float l2_norm = sqrtf(sum_of_squares); // Compute L2 norm\n        if (l2_norm == 0.0f) continue; // Avoid division by zero\n\n        float inv_l2_norm = 1.0f / l2_norm; // Precompute reciprocal of L2 norm\n\n        // Normalize the row elements\n        remaining = n;\n        offset = 0;\n        while (remaining > 0) {\n            size_t vl = vsetvl_e32m1(remaining);\n            vfloat32m1_t vrow = vle32_v_f32m1(row + offset, vl);\n            vrow = vfmul_vf_f32m1(vrow, inv_l2_norm, vl); // vrow *= inv_l2_norm\n            vse32_v_f32m1(row + offset, vrow, vl);\n            remaining -= vl;\n            offset += vl;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_23_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <math.h>\n\nvoid matrix_normalize_rows_simd(float* mat, size_t m, size_t n) {\n    size_t vlmax = vsetvlmax_e32m1(); // Maximum vector length for 32-bit floats\n    for (size_t i = 0; i < m; i++) {\n        float* row = mat + i * n;\n        size_t remaining = n;\n        size_t offset = 0;\n        float sum_of_squares = 0.0f;\n\n        // Compute the sum of squares of the row elements\n        while (remaining > 0) {\n            size_t vl = vsetvl_e32m1(remaining);\n            vfloat32m1_t vec_row = vle32_v_f32m1(row + offset, vl);\n            vfloat32m1_t vec_squared = vfmul_vv_f32m1(vec_row, vec_row, vl);\n            sum_of_squares += vfmv_s_f_f32m1(vfredsum_vs_f32m1_f32m1(vec_squared, vec_squared, vfmv_v_f_f32m1(0.0f, vl), vl));\n            offset += vl;\n            remaining -= vl;\n        }\n\n        // Compute the L^2 norm\n        float l2_norm = sqrtf(sum_of_squares);\n\n        // Normalize the row elements\n        remaining = n;\n        offset = 0;\n        while (remaining > 0) {\n            size_t vl = vsetvl_e32m1(remaining);\n            vfloat32m1_t vec_row = vle32_v_f32m1(row + offset, vl);\n            vfloat32m1_t vec_normalized = vfdiv_vf_f32m1(vec_row, l2_norm, vl);\n            vse32_v_f32m1(row + offset, vec_normalized, vl);\n            offset += vl;\n            remaining -= vl;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_23_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <math.h>\n\nvoid matrix_normalize_rows_simd(float* mat, size_t m, size_t n) {\n    size_t vlmax = vsetvlmax_e32m1(); // Maximum vector length for 32-bit floats\n    for (size_t i = 0; i < m; i++) {\n        float* row = mat + i * n;\n        size_t remaining = n;\n        size_t offset = 0;\n        vfloat32m1_t vsum = vfmv_v_f_f32m1(0.0f, vlmax); // Initialize sum vector to 0\n\n        // Compute the sum of squares for the row\n        while (remaining > 0) {\n            size_t vl = vsetvl_e32m1(remaining);\n            vfloat32m1_t vrow = vle32_v_f32m1(row + offset, vl);\n            vsum = vfmacc_vv_f32m1(vsum, vrow, vrow, vl); // Accumulate squares\n            offset += vl;\n            remaining -= vl;\n        }\n\n        // Reduce the sum vector to a scalar\n        float sum = vfmv_f_s_f32m1_f32(vsum);\n        for (size_t j = 1; j < vlmax; j++) {\n            sum += vfmv_f_s_f32m1_f32(vslide1down_vx_f32m1(vsum, 0, j));\n        }\n\n        float norm = sqrtf(sum); // Compute the L2 norm\n        if (norm == 0.0f) continue; // Avoid division by zero\n\n        // Normalize the row\n        remaining = n;\n        offset = 0;\n        while (remaining > 0) {\n            size_t vl = vsetvl_e32m1(remaining);\n            vfloat32m1_t vrow = vle32_v_f32m1(row + offset, vl);\n            vfloat32m1_t vnorm = vfmv_v_f_f32m1(norm, vl);\n            vrow = vfdiv_vv_f32m1(vrow, vnorm, vl); // Divide each element by the norm\n            vse32_v_f32m1(row + offset, vrow, vl);\n            offset += vl;\n            remaining -= vl;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_24_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <math.h>\n\nvoid matrix_mul_round_int_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n, size_t p) {\n    size_t vlmax = vsetvlmax_e64m1(); // Maximum vector length for 64-bit elements\n    for (size_t i = 0; i < m; i++) {\n        for (size_t j = 0; j < p; j++) {\n            double sum = 0.0;\n            size_t k = 0;\n            while (k < n) {\n                size_t vl = vsetvl_e64m1(n - k); // Set vector length based on remaining elements\n                vfloat64m1_t vec_mat1 = vle64_v_f64m1(&mat1[i * n + k], vl);\n                vfloat64m1_t vec_mat2 = vle64_v_f64m1(&mat2[j + k * p], vl);\n                vfloat64m1_t vec_prod = vfmul_vv_f64m1(vec_mat1, vec_mat2, vl);\n                sum += vfredsum_vs_f64m1_f64m1(vec_prod, vec_prod, vl);\n                k += vl;\n            }\n            dst[i * p + j] = round(sum); // Round to the nearest integer\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_24_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <math.h>\n\nvoid matrix_mul_round_int_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n, size_t p) {\n    size_t vl;\n    for (size_t i = 0; i < m; i++) {\n        for (size_t j = 0; j < p; j++) {\n            double sum = 0.0;\n            for (size_t k = 0; k < n; k += vl) {\n                vl = vsetvl_e64m1(n - k); // Set vector length for 64-bit elements\n                vfloat64m1_t vec_mat1 = vle64_v_f64m1(&mat1[i * n + k], vl); // Load a vector from mat1\n                vfloat64m1_t vec_mat2 = vle64_v_f64m1(&mat2[k * p + j], vl); // Load a vector from mat2\n                vfloat64m1_t vec_prod = vfmul_vv_f64m1(vec_mat1, vec_mat2, vl); // Element-wise multiplication\n                sum += vfmv_f_s_f64m1_f64(vfredsum_vs_f64m1_f64m1(vundefined_f64m1(), vec_prod, vundefined_f64m1(), vl)); // Reduce sum\n            }\n            dst[i * p + j] = round(sum); // Round to the nearest integer\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_24_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <math.h>\n\nvoid matrix_mul_round_int_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n, size_t p) {\n    size_t vlmax = vsetvlmax_e64m1(); // Maximum vector length for 64-bit elements\n    for (size_t i = 0; i < m; i++) {\n        for (size_t j = 0; j < p; j++) {\n            double sum = 0.0;\n            size_t k = 0;\n            while (k < n) {\n                size_t vl = vsetvl_e64m1(n - k); // Set vector length based on remaining elements\n                vfloat64m1_t vec_mat1 = vle64_v_f64m1(&mat1[i * n + k], vl); // Load a vector from mat1\n                vfloat64m1_t vec_mat2 = vle64_v_f64m1(&mat2[k * p + j], vl); // Load a vector from mat2\n                vfloat64m1_t vec_prod = vfmul_vv_f64m1(vec_mat1, vec_mat2, vl); // Element-wise multiplication\n                sum += vfredsum_vs_f64m1_f64m1(vec_prod, vec_prod, vl); // Reduce sum of the vector\n                k += vl; // Advance by the vector length\n            }\n            dst[i * p + j] = round(sum); // Round to nearest integer and store in dst\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_24_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <math.h>\n\nvoid matrix_mul_round_int_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n, size_t p) {\n    size_t vlmax = vsetvlmax_e64m1(); // Maximum vector length for 64-bit elements\n    for (size_t i = 0; i < m; i++) {\n        for (size_t j = 0; j < p; j++) {\n            double sum = 0.0;\n            size_t k = 0;\n            while (k < n) {\n                size_t vl = vsetvl_e64m1(n - k); // Determine vector length based on remaining elements\n                vfloat64m1_t vec_mat1 = vle64_v_f64m1(&mat1[i * n + k], vl);\n                vfloat64m1_t vec_mat2 = vle64_v_f64m1(&mat2[j + k * p], vl);\n                vfloat64m1_t vec_prod = vfmul_vv_f64m1(vec_mat1, vec_mat2, vl);\n                sum += vfredsum_vs_f64m1_f64m1(vec_prod, vec_prod, vl).val[0];\n                k += vl;\n            }\n            dst[i * p + j] = round(sum); // Round to nearest integer\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_24_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <math.h>\n\nvoid matrix_mul_round_int_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n, size_t p) {\n    size_t vl;\n    for (size_t i = 0; i < m; i++) {\n        for (size_t j = 0; j < p; j++) {\n            vfloat64m1_t acc = vfmv_v_f_f64m1(0.0, vsetvl_e64m1(1)); // Initialize accumulator to 0\n            for (size_t k = 0; k < n; k += vl) {\n                vl = vsetvl_e64m1(n - k); // Set vector length\n                vfloat64m1_t vec1 = vle64_v_f64m1(&mat1[i * n + k], vl); // Load row of mat1\n                vfloat64m1_t vec2 = vle64_v_f64m1(&mat2[k * p + j], vl); // Load column of mat2\n                acc = vfmacc_vv_f64m1(acc, vec1, vec2, vl); // Multiply and accumulate\n            }\n            double sum = vfmv_f_s_f64m1_f64(acc); // Reduce the accumulator\n            dst[i * p + j] = round(sum); // Round to the nearest integer and store in dst\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_25_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid matrix_transpose_round_quarter_simd(const float* src, float* dst, size_t rows, size_t cols) {\n    size_t vl;\n    for (size_t col = 0; col < cols; col++) {\n        for (size_t row = 0; row < rows; row += vl) {\n            vl = vsetvl_e32m1(rows - row); // Set vector length based on remaining rows\n            vfloat32m1_t vec = vle32_v_f32m1(&src[row * cols + col], vl); // Load a column vector\n            // Round to the nearest quarter (0.25)\n            vfloat32m1_t rounded_vec = vfmul_vf_f32m1(vfredsum_vs_f32m1_f32m1(vec, vfmul_vf_f32m1(vec, 4.0f, vl), vl), 0.25f, vl);\n            vse32_v_f32m1(&dst[col * rows + row], rounded_vec, vl); // Store the transposed and rounded vector\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_25_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid matrix_transpose_round_quarter_simd(const float* src, float* dst, size_t rows, size_t cols) {\n    size_t vl;\n    for (size_t i = 0; i < rows; i++) {\n        for (size_t j = 0; j < cols; j += vl) {\n            vl = vsetvl_e32m1(cols - j); // Set vector length based on remaining columns\n            vfloat32m1_t vec = vle32_v_f32m1(&src[i * cols + j], vl); // Load a vector of elements\n            vec = vfmul_vf_f32m1(vec, 4.0f, vl); // Multiply by 4 to scale for rounding to nearest quarter\n            vec = vfrint_v_f32m1(vec, vl); // Round to nearest integer\n            vec = vfdiv_vf_f32m1(vec, 4.0f, vl); // Divide by 4 to scale back to nearest quarter\n            vse32_v_f32m1(&dst[j * rows + i], vec, vl); // Store transposed and rounded elements\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_25_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid matrix_transpose_round_quarter_simd(const float* src, float* dst, size_t rows, size_t cols) {\n    size_t vl;\n    for (size_t col = 0; col < cols; ++col) {\n        for (size_t row = 0; row < rows; row += vl) {\n            vl = vsetvl_e32m1(rows - row); // Set vector length based on remaining rows\n            vfloat32m1_t vec = vle32_v_f32m1(&src[row * cols + col], vl); // Load a column vector\n            vec = vfmul_vf_f32m1(vec, 4.0f, vl); // Multiply by 4 to prepare for rounding to nearest quarter\n            vec = vfcvt_rtz_x_f_v_f32m1(vfncvt_x_f_w_f32m1(vec, vl), vl); // Convert to integer (truncate)\n            vec = vfmul_vf_f32m1(vec, 0.25f, vl); // Multiply back by 0.25 to get rounded value\n            vse32_v_f32m1(&dst[col * rows + row], vec, vl); // Store the transposed and rounded vector\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_25_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid matrix_transpose_round_quarter_simd(const float* src, float* dst, size_t rows, size_t cols) {\n    size_t vl;\n    for (size_t i = 0; i < rows; i++) {\n        for (size_t j = 0; j < cols; j += vl) {\n            vl = vsetvl_e32(cols - j); // Set vector length based on remaining columns\n            vfloat32m1_t vec_src = vle32_v_f32m1(&src[i * cols + j], vl); // Load a vector of elements from the source matrix\n            vfloat32m1_t vec_scaled = vfmul_vf_f32m1(vec_src, 4.0f, vl); // Multiply by 4 to scale for rounding to quarters\n            vfloat32m1_t vec_rounded = vfncvt_rtz_x_f32m1(vec_scaled, vl); // Round to nearest integer\n            vfloat32m1_t vec_result = vfmul_vf_f32m1(vec_rounded, 0.25f, vl); // Scale back to quarters\n            vse32_v_f32m1(&dst[j * rows + i], vec_result, vl); // Store the transposed and rounded result\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_25_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid matrix_transpose_round_quarter_simd(const float* src, float* dst, size_t rows, size_t cols) {\n    size_t vl;\n    for (size_t col = 0; col < cols; col++) {\n        for (size_t row = 0; row < rows; row += vl) {\n            vl = vsetvl_e32m1(rows - row); // Set vector length based on remaining rows\n            vfloat32m1_t vec = vle32_v_f32m1(&src[row * cols + col], vl); // Load column elements\n            vec = vfmul_vf_f32m1(vec, 4.0f, vl); // Multiply by 4.0\n            vec = vfrint_v_f32m1(vec, vl); // Round to nearest integer\n            vec = vfmul_vf_f32m1(vec, 0.25f, vl); // Divide by 4.0 (round to nearest quarter)\n            vse32_v_f32m1(&dst[col * rows + row], vec, vl); // Store transposed and rounded elements\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_26_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid tensor3d_sub_round_zero_simd(const float* tensor1, const float* tensor2, float* dst, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t vl;\n    size_t i = 0;\n\n    while (i < total_elements) {\n        vl = vsetvl_e32m1(total_elements - i); // Set vector length for 32-bit floats\n        vfloat32m1_t v1 = vle32_v_f32m1(&tensor1[i], vl); // Load tensor1 elements\n        vfloat32m1_t v2 = vle32_v_f32m1(&tensor2[i], vl); // Load tensor2 elements\n        vfloat32m1_t vsub = vsub_vv_f32m1(v1, v2, vl);    // Perform element-wise subtraction\n        vint32m1_t vrounded = vfcvt_x_f_v_i32m1(vsub, vl); // Round towards zero\n        vfloat32m1_t vresult = vfcvt_f_x_v_f32m1(vrounded, vl); // Convert back to float\n        vse32_v_f32m1(&dst[i], vresult, vl);              // Store the result in dst\n        i += vl;                                          // Increment index by vector length\n    }\n}\n```"}
{"task_id": "SimdBench_26_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid tensor3d_sub_round_zero_simd(const float* tensor1, const float* tensor2, float* dst, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t vl;\n    size_t i = 0;\n\n    while (i < total_elements) {\n        vl = vsetvl_e32m8(total_elements - i); // Set vector length for 32-bit floats\n        vfloat32m8_t v1 = vle32_v_f32m8(&tensor1[i], vl); // Load tensor1 elements\n        vfloat32m8_t v2 = vle32_v_f32m8(&tensor2[i], vl); // Load tensor2 elements\n        vfloat32m8_t vsub = vsub_vv_f32m8(v1, v2, vl);    // Perform element-wise subtraction\n        vint32m8_t vtrunc = vfcvt_x_f_v_i32m8(vsub, vl);  // Convert to integer (truncate towards zero)\n        vfloat32m8_t vresult = vfcvt_f_x_v_f32m8(vtrunc, vl); // Convert back to float\n        vse32_v_f32m8(&dst[i], vresult, vl);              // Store the result in dst\n        i += vl;                                          // Increment index by vector length\n    }\n}\n```"}
{"task_id": "SimdBench_26_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid tensor3d_sub_round_zero_simd(const float* tensor1, const float* tensor2, float* dst, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t vl;\n    size_t i = 0;\n\n    while (i < total_elements) {\n        vl = vsetvl_e32m1(total_elements - i); // Set vector length for 32-bit floats\n        vfloat32m1_t v1 = vle32_v_f32m1(&tensor1[i], vl); // Load tensor1 elements\n        vfloat32m1_t v2 = vle32_v_f32m1(&tensor2[i], vl); // Load tensor2 elements\n        vfloat32m1_t vsub = vfsub_vv_f32m1(v1, v2, vl);   // Perform element-wise subtraction\n        vint32m1_t vrounded = vfcvt_x_f_v_i32m1(vsub, vl); // Convert to integer (round towards zero)\n        vfloat32m1_t vresult = vfcvt_f_x_v_f32m1(vrounded, vl); // Convert back to float\n        vse32_v_f32m1(&dst[i], vresult, vl); // Store the result in dst\n        i += vl; // Increment index by vector length\n    }\n}\n```"}
{"task_id": "SimdBench_26_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid tensor3d_sub_round_zero_simd(const float* tensor1, const float* tensor2, float* dst, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t vl;\n    size_t i = 0;\n\n    while (i < total_elements) {\n        vl = vsetvl_e32m1(total_elements - i); // Set vector length for 32-bit floats\n        vfloat32m1_t v1 = vle32_v_f32m1(&tensor1[i], vl); // Load tensor1 elements\n        vfloat32m1_t v2 = vle32_v_f32m1(&tensor2[i], vl); // Load tensor2 elements\n        vfloat32m1_t vsub = vsub_vv_f32m1(v1, v2, vl);    // Perform element-wise subtraction\n        vint32m1_t vrounded = vfcvt_x_f_v_i32m1(vsub, vl); // Convert to integer (round towards zero)\n        vfloat32m1_t vresult = vfcvt_f_x_v_f32m1(vrounded, vl); // Convert back to float\n        vse32_v_f32m1(&dst[i], vresult, vl); // Store the result in dst\n        i += vl; // Move to the next chunk\n    }\n}\n```"}
{"task_id": "SimdBench_26_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid tensor3d_sub_round_zero_simd(const float* tensor1, const float* tensor2, float* dst, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t vl;\n    size_t i = 0;\n\n    while (i < total_elements) {\n        vl = vsetvl_e32m8(total_elements - i); // Set vector length for 32-bit floats\n        vfloat32m8_t v1 = vle32_v_f32m8(&tensor1[i], vl); // Load tensor1 elements\n        vfloat32m8_t v2 = vle32_v_f32m8(&tensor2[i], vl); // Load tensor2 elements\n        vfloat32m8_t vsub = vsub_vv_f32m8(v1, v2, vl);    // Perform element-wise subtraction\n        vint32m8_t vrounded = vfcvt_x_f_v_i32m8(vsub, vl); // Round towards zero\n        vfloat32m8_t vresult = vfcvt_f_x_v_f32m8(vrounded, vl); // Convert back to float\n        vse32_v_f32m8(&dst[i], vresult, vl);              // Store the result in dst\n        i += vl;                                          // Increment index by vector length\n    }\n}\n```"}
{"task_id": "SimdBench_27_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid matrix_hadamard_product_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n) {\n    size_t total_elements = m * n;\n    size_t vl;\n    size_t i = 0;\n\n    while (i < total_elements) {\n        vl = vsetvl_e64m1(total_elements - i); // Set vector length for remaining elements\n        vfloat64m1_t vec1 = vle64_v_f64m1(&mat1[i], vl); // Load elements from mat1\n        vfloat64m1_t vec2 = vle64_v_f64m1(&mat2[i], vl); // Load elements from mat2\n        vfloat64m1_t result = vfmul_vv_f64m1(vec1, vec2, vl); // Perform element-wise multiplication\n        vse64_v_f64m1(&dst[i], result, vl); // Store the result in dst\n        i += vl; // Move to the next set of elements\n    }\n}\n```"}
{"task_id": "SimdBench_27_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid matrix_hadamard_product_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n) {\n    size_t total_elements = m * n;\n    size_t vl;\n    size_t i = 0;\n\n    while (i < total_elements) {\n        vl = vsetvl_e64m1(total_elements - i); // Set vector length for 64-bit elements\n        vfloat64m1_t vmat1 = vle64_v_f64m1(&mat1[i], vl); // Load elements from mat1\n        vfloat64m1_t vmat2 = vle64_v_f64m1(&mat2[i], vl); // Load elements from mat2\n        vfloat64m1_t vresult = vfmul_vv_f64m1(vmat1, vmat2, vl); // Element-wise multiplication\n        vse64_v_f64m1(&dst[i], vresult, vl); // Store the result in dst\n        i += vl; // Move to the next set of elements\n    }\n}\n```"}
{"task_id": "SimdBench_27_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid matrix_hadamard_product_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n) {\n    size_t total_elements = m * n;\n    size_t vl;\n    size_t i = 0;\n\n    while (i < total_elements) {\n        vl = vsetvl_e64m1(total_elements - i); // Set vector length for 64-bit elements\n        vfloat64m1_t vmat1 = vle64_v_f64m1(&mat1[i], vl); // Load elements from mat1\n        vfloat64m1_t vmat2 = vle64_v_f64m1(&mat2[i], vl); // Load elements from mat2\n        vfloat64m1_t vresult = vfmul_vv_f64m1(vmat1, vmat2, vl); // Perform element-wise multiplication\n        vse64_v_f64m1(&dst[i], vresult, vl); // Store the result in dst\n        i += vl; // Increment index by vector length\n    }\n}\n```"}
{"task_id": "SimdBench_27_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid matrix_hadamard_product_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n) {\n    size_t total_elements = m * n;\n    size_t vl;\n    size_t i = 0;\n\n    while (i < total_elements) {\n        vl = vsetvl_e64m1(total_elements - i); // Set vector length for 64-bit elements\n        vfloat64m1_t vec1 = vle64_v_f64m1(&mat1[i], vl); // Load elements from mat1\n        vfloat64m1_t vec2 = vle64_v_f64m1(&mat2[i], vl); // Load elements from mat2\n        vfloat64m1_t result = vfmul_vv_f64m1(vec1, vec2, vl); // Element-wise multiplication\n        vse64_v_f64m1(&dst[i], result, vl); // Store the result in dst\n        i += vl; // Increment index by the vector length\n    }\n}\n```"}
{"task_id": "SimdBench_27_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid matrix_hadamard_product_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n) {\n    size_t total_elements = m * n;\n    size_t vl;\n    size_t i = 0;\n\n    while (i < total_elements) {\n        vl = vsetvl_e64m1(total_elements - i); // Set vector length for 64-bit elements\n        vfloat64m1_t v_mat1 = vle64_v_f64m1(&mat1[i], vl); // Load elements from mat1\n        vfloat64m1_t v_mat2 = vle64_v_f64m1(&mat2[i], vl); // Load elements from mat2\n        vfloat64m1_t v_result = vfmul_vv_f64m1(v_mat1, v_mat2, vl); // Perform element-wise multiplication\n        vse64_v_f64m1(&dst[i], v_result, vl); // Store the result in dst\n        i += vl; // Increment the index by the vector length\n    }\n}\n```"}
{"task_id": "SimdBench_28_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid matrix_vector_mul_simd(const float* mat, const float* vec, float* dst, size_t m, size_t n) {\n    size_t vl;\n    for (size_t i = 0; i < m; i++) {\n        vfloat32m1_t acc = vfmv_v_f_f32m1(0.0f, vsetvlmax_e32m1()); // Initialize accumulator to 0\n        size_t col = 0;\n        while (col < n) {\n            vl = vsetvl_e32m1(n - col); // Set vector length\n            vfloat32m1_t mat_row = vle32_v_f32m1(&mat[i * n + col], vl); // Load a chunk of the matrix row\n            vfloat32m1_t vec_chunk = vle32_v_f32m1(&vec[col], vl);       // Load a chunk of the vector\n            acc = vfmacc_vv_f32m1(acc, mat_row, vec_chunk, vl);          // Multiply and accumulate\n            col += vl;\n        }\n        dst[i] = vfredsum_vs_f32m1_f32m1(acc, acc, vsetvlmax_e32m1()); // Reduce the accumulator to a scalar\n    }\n}\n```"}
{"task_id": "SimdBench_28_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid matrix_vector_mul_simd(const float* mat, const float* vec, float* dst, size_t m, size_t n) {\n    size_t vl;\n    for (size_t i = 0; i < m; i++) {\n        const float* row = mat + i * n;\n        vfloat32m1_t acc = vfmv_v_f_f32m1(0.0f, vsetvlmax_e32m1());\n        size_t col = 0;\n        while (col < n) {\n            vl = vsetvl_e32m1(n - col);\n            vfloat32m1_t mat_vec = vle32_v_f32m1(row + col, vl);\n            vfloat32m1_t vec_vec = vle32_v_f32m1(vec + col, vl);\n            acc = vfmacc_vv_f32m1(acc, mat_vec, vec_vec, vl);\n            col += vl;\n        }\n        dst[i] = vfredsum_vs_f32m1_f32m1(acc, acc, vsetvlmax_e32m1());\n    }\n}\n```"}
{"task_id": "SimdBench_28_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid matrix_vector_mul_simd(const float* mat, const float* vec, float* dst, size_t m, size_t n) {\n    size_t vl;\n    for (size_t i = 0; i < m; i++) {\n        const float* row = mat + i * n;\n        float sum = 0.0f;\n        size_t col = 0;\n\n        while (col < n) {\n            vl = vsetvl_e32m1(n - col); // Set vector length based on remaining columns\n            vfloat32m1_t v_row = vle32_v_f32m1(row + col, vl); // Load a chunk of the matrix row\n            vfloat32m1_t v_vec = vle32_v_f32m1(vec + col, vl); // Load a chunk of the vector\n            vfloat32m1_t v_mul = vfmul_vv_f32m1(v_row, v_vec, vl); // Element-wise multiplication\n            sum += vfredsum_vs_f32m1_f32m1(v_mul, v_mul, vl); // Reduce sum of the vector\n            col += vl; // Move to the next chunk\n        }\n\n        dst[i] = sum; // Store the result in the destination vector\n    }\n}\n```"}
{"task_id": "SimdBench_28_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid matrix_vector_mul_simd(const float* mat, const float* vec, float* dst, size_t m, size_t n) {\n    size_t vl;\n    for (size_t i = 0; i < m; i++) {\n        vfloat32m1_t acc = vfmv_v_f_f32m1(0.0f, vsetvlmax_e32m1()); // Initialize accumulator to 0\n        size_t col = 0;\n        while (col < n) {\n            vl = vsetvl_e32m1(n - col); // Set vector length\n            vfloat32m1_t mat_vec = vle32_v_f32m1(&mat[i * n + col], vl); // Load a chunk of the matrix row\n            vfloat32m1_t vec_vec = vle32_v_f32m1(&vec[col], vl);         // Load a chunk of the vector\n            acc = vfmacc_vv_f32m1(acc, mat_vec, vec_vec, vl);           // Perform fused multiply-add\n            col += vl;\n        }\n        dst[i] = vfredsum_vs_f32m1_f32m1(acc, acc, vsetvlmax_e32m1()); // Reduce the accumulator to a scalar\n    }\n}\n```"}
{"task_id": "SimdBench_28_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid matrix_vector_mul_simd(const float* mat, const float* vec, float* dst, size_t m, size_t n) {\n    size_t vl;\n    for (size_t i = 0; i < m; i++) {\n        const float* row = mat + i * n;\n        vfloat32m1_t acc = vfmv_v_f_f32m1(0.0f, vsetvlmax_e32m1());\n        size_t col = 0;\n        while (col < n) {\n            vl = vsetvl_e32m1(n - col);\n            vfloat32m1_t mat_vec = vle32_v_f32m1(row + col, vl);\n            vfloat32m1_t vec_vec = vle32_v_f32m1(vec + col, vl);\n            acc = vfmacc_vv_f32m1(acc, mat_vec, vec_vec, vl);\n            col += vl;\n        }\n        dst[i] = vfredsum_vs_f32m1_f32m1(acc, acc, vsetvlmax_e32m1());\n    }\n}\n```"}
{"task_id": "SimdBench_29_RVV", "completion": "```c\n#include <riscv_vector.h>\n\ndouble matrix_average_simd(const double* mat, size_t m, size_t n) {\n    size_t total_elements = m * n;\n    size_t vl;\n    double sum = 0.0;\n    vfloat64m1_t vec_sum = vfmv_v_f_f64m1(0.0, vsetvlmax_e64m1());\n\n    for (size_t i = 0; i < total_elements; i += vl) {\n        vl = vsetvl_e64m1(total_elements - i);\n        vfloat64m1_t vec = vle64_v_f64m1(&mat[i], vl);\n        vec_sum = vfadd_vv_f64m1(vec_sum, vec, vl);\n    }\n\n    double partial_sums[vsetvlmax_e64m1()];\n    vse64_v_f64m1(partial_sums, vec_sum, vsetvlmax_e64m1());\n\n    for (size_t i = 0; i < vsetvlmax_e64m1(); i++) {\n        sum += partial_sums[i];\n    }\n\n    return sum / total_elements;\n}\n```"}
{"task_id": "SimdBench_29_RVV", "completion": "```c\n#include <riscv_vector.h>\n\ndouble matrix_average_simd(const double* mat, size_t m, size_t n) {\n    size_t total_elements = m * n;\n    size_t vl;\n    vfloat64m1_t sum_vec = vfmv_v_f_f64m1(0.0, vsetvlmax_e64m1()); // Initialize vector sum to 0\n    size_t i = 0;\n\n    while (i < total_elements) {\n        vl = vsetvl_e64m1(total_elements - i); // Set vector length\n        vfloat64m1_t data_vec = vle64_v_f64m1(&mat[i], vl); // Load elements into vector\n        sum_vec = vfadd_vv_f64m1(sum_vec, data_vec, vl); // Accumulate sum\n        i += vl;\n    }\n\n    // Reduce vector sum to a scalar\n    double sum = vfmv_f_s_f64m1_f64(vfredsum_vs_f64m1_f64m1(sum_vec, sum_vec, vsetvl_e64m1(1)));\n\n    return sum / total_elements; // Compute and return the average\n}\n```"}
{"task_id": "SimdBench_29_RVV", "completion": "```c\n#include <riscv_vector.h>\n\ndouble matrix_average_simd(const double* mat, size_t m, size_t n) {\n    size_t total_elements = m * n;\n    size_t vl;\n    double sum = 0.0;\n    vfloat64m1_t vec_sum = vfmv_v_f_f64m1(0.0, vsetvlmax_e64m1());\n\n    for (size_t i = 0; i < total_elements; i += vl) {\n        vl = vsetvl_e64m1(total_elements - i);\n        vfloat64m1_t vec_mat = vle64_v_f64m1(&mat[i], vl);\n        vec_sum = vfadd_vv_f64m1(vec_sum, vec_mat, vl);\n    }\n\n    double partial_sum[vlmax_e64m1()];\n    vse64_v_f64m1(partial_sum, vec_sum, vsetvlmax_e64m1());\n    for (size_t i = 0; i < vlmax_e64m1(); i++) {\n        sum += partial_sum[i];\n    }\n\n    return sum / total_elements;\n}\n```"}
{"task_id": "SimdBench_29_RVV", "completion": "```c\n#include <riscv_vector.h>\n\ndouble matrix_average_simd(const double* mat, size_t m, size_t n) {\n    size_t total_elements = m * n;\n    size_t vl;\n    double sum = 0.0;\n    vfloat64m1_t vec_sum = vfmv_v_f_f64m1(0.0, vsetvlmax_e64m1());\n\n    for (size_t i = 0; i < total_elements; i += vl) {\n        vl = vsetvl_e64m1(total_elements - i);\n        vfloat64m1_t vec_data = vle64_v_f64m1(&mat[i], vl);\n        vec_sum = vfadd_vv_f64m1(vec_sum, vec_data, vl);\n    }\n\n    double partial_sum[vlmax_e64m1()];\n    vse64_v_f64m1(partial_sum, vec_sum, vsetvlmax_e64m1());\n\n    for (size_t i = 0; i < vsetvlmax_e64m1(); i++) {\n        sum += partial_sum[i];\n    }\n\n    return sum / total_elements;\n}\n```"}
{"task_id": "SimdBench_29_RVV", "completion": "```c\n#include <riscv_vector.h>\n\ndouble matrix_average_simd(const double* mat, size_t m, size_t n) {\n    size_t total_elements = m * n;\n    size_t vl;\n    double sum = 0.0;\n\n    for (size_t i = 0; i < total_elements; i += vl) {\n        vl = vsetvl_e64m1(total_elements - i);\n        vfloat64m1_t vec = vle64_v_f64m1(mat + i, vl);\n        sum += vfmv_f_s_f64m1_f64(vfredsum_vs_f64m1_f64m1(vundefined_f64m1(), vec, vec, vl));\n    }\n\n    return sum / total_elements;\n}\n```"}
{"task_id": "SimdBench_30_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nbool matrix_rows_sorted_verify_simd(const int* matrix, const bool* directions, size_t rows, size_t cols) {\n    for (size_t i = 0; i < rows; i++) {\n        size_t col = 0;\n        size_t vl;\n        bool is_sorted = true;\n\n        while (col < cols - 1) {\n            vl = vsetvl_e32m1(cols - col); // Set vector length based on remaining columns\n            vint32m1_t current = vle32_v_i32m1(&matrix[i * cols + col], vl);\n            vint32m1_t next = vle32_v_i32m1(&matrix[i * cols + col + 1], vl);\n\n            if (directions[i]) {\n                // Ascending order check\n                vbool32_t mask = vmseq_vv_i32m1_b32(vmin_vv_i32m1(current, next, vl), current, vl);\n                if (!vfirst_m_b32(mask, vl)) {\n                    is_sorted = false;\n                    break;\n                }\n            } else {\n                // Descending order check\n                vbool32_t mask = vmseq_vv_i32m1_b32(vmax_vv_i32m1(current, next, vl), current, vl);\n                if (!vfirst_m_b32(mask, vl)) {\n                    is_sorted = false;\n                    break;\n                }\n            }\n            col += vl;\n        }\n\n        if (!is_sorted) {\n            return false;\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_30_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nbool matrix_rows_sorted_verify_simd(const int* matrix, const bool* directions, size_t rows, size_t cols) {\n    for (size_t i = 0; i < rows; i++) {\n        const int* row = matrix + i * cols;\n        bool ascending = directions[i];\n        size_t remaining = cols;\n        size_t offset = 0;\n\n        while (remaining > 0) {\n            size_t vl = vsetvl_e32m1(remaining);\n            vint32m1_t vec = vle32_v_i32m1(row + offset, vl);\n            vint32m1_t vec_next = vle32_v_i32m1(row + offset + 1, vl - 1);\n\n            if (ascending) {\n                // Check ascending order\n                vint32m1_t diff = vsub_vv_i32m1(vec_next, vec, vl - 1);\n                vbool32_t mask = vmflt_vv_i32m1_b32(diff, vmv_v_x_i32m1(0, vl - 1), vl - 1);\n                if (vfirst_m_b32(mask, vl - 1) != -1) {\n                    return false;\n                }\n            } else {\n                // Check descending order\n                vint32m1_t diff = vsub_vv_i32m1(vec, vec_next, vl - 1);\n                vbool32_t mask = vmflt_vv_i32m1_b32(diff, vmv_v_x_i32m1(0, vl - 1), vl - 1);\n                if (vfirst_m_b32(mask, vl - 1) != -1) {\n                    return false;\n                }\n            }\n\n            offset += vl;\n            remaining -= vl;\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_30_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nbool matrix_rows_sorted_verify_simd(const int* matrix, const bool* directions, size_t rows, size_t cols) {\n    size_t vl;\n    for (size_t i = 0; i < rows; i++) {\n        const int* row = matrix + i * cols;\n        bool ascending = directions[i];\n        size_t j = 0;\n\n        while (j < cols - 1) {\n            vl = vsetvl_e32m1(cols - j);\n            vint32m1_t v1 = vle32_v_i32m1(row + j, vl);\n            vint32m1_t v2 = vle32_v_i32m1(row + j + 1, vl);\n\n            if (ascending) {\n                vbool32_t mask = vmflt_vv_i32m1_b32(v1, v2, vl);\n                if (!vcpop_b32(mask)) {\n                    return false;\n                }\n            } else {\n                vbool32_t mask = vmfgt_vv_i32m1_b32(v1, v2, vl);\n                if (!vcpop_b32(mask)) {\n                    return false;\n                }\n            }\n\n            j += vl;\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_30_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nbool matrix_rows_sorted_verify_simd(const int* matrix, const bool* directions, size_t rows, size_t cols) {\n    for (size_t i = 0; i < rows; i++) {\n        const int* row = matrix + i * cols;\n        bool ascending = directions[i];\n        size_t vl = vsetvl_e32m1(cols);\n\n        for (size_t j = 0; j < cols - 1; j += vl) {\n            vl = vsetvl_e32m1(cols - j);\n\n            vint32m1_t vec1 = vle32_v_i32m1(row + j, vl);\n            vint32m1_t vec2 = vle32_v_i32m1(row + j + 1, vl);\n\n            vbool32_t mask;\n            if (ascending) {\n                mask = vmseq_vv_i32m1_b32(vle32_v_i32m1(row + j, vl), vle32_v_i32m1(row + j + 1, vl), vl);\n            } else {\n                mask = vmseq_vv_i32m1_b32(vle32_v_i32m1(row + j, vl), vle32_v_i32m1(row + j + 1, vl), vl);\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_30_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nbool matrix_rows_sorted_verify_simd(const int* matrix, const bool* directions, size_t rows, size_t cols) {\n    for (size_t i = 0; i < rows; i++) {\n        size_t col = 0;\n        size_t vl;\n        bool is_sorted = true;\n\n        while (col < cols - 1) {\n            vl = vsetvl_e32m1(cols - col); // Set vector length based on remaining columns\n            vint32m1_t current = vle32_v_i32m1(&matrix[i * cols + col], vl);\n            vint32m1_t next = vle32_v_i32m1(&matrix[i * cols + col + 1], vl);\n\n            if (directions[i]) {\n                // Ascending order check\n                vbool32_t mask = vmseq_vv_i32m1_b32(vle32_v_i32m1(&matrix[i * cols + col + 1], vl), current, vl);\n                if (vfirst_m_b32(mask, vl) != -1) {\n                    is_sorted = false;\n                    break;\n                }\n            } else {\n                // Descending order check\n                vbool32_t mask = vmseq_vv_i32m1_b32(vle32_v_i32m1(&matrix[i * cols + col + 1], vl), current, vl);\n                if (vfirst_m_b32(mask, vl) != -1) {\n                    is_sorted = false;\n                    break;\n                }\n            }\n            col += vl;\n        }\n\n        if (!is_sorted) {\n            return false;\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_31_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid nearest_multiple_simd(const int16_t* src, int16_t* dst, uint8_t base, size_t length) {\n    size_t vl;\n    vuint16m1_t vbase = vmv_v_x_u16m1(base, vsetvlmax_e16m1()); // Vector of base values\n    size_t offset = 0;\n\n    while (length > 0) {\n        vl = vsetvl_e16m1(length); // Set vector length\n        vint16m1_t vsrc = vle16_v_i16m1(&src[offset], vl); // Load src elements\n        vint16m1_t vdiv = vdivu_vv_i16m1(vsrc, vbase, vl); // Divide src by base\n        vint16m1_t vmul = vmul_vv_i16m1(vdiv, vbase, vl); // Multiply quotient by base\n        vse16_v_i16m1(&dst[offset], vmul, vl); // Store result in dst\n        offset += vl;\n        length -= vl;\n    }\n}\n```"}
{"task_id": "SimdBench_31_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid nearest_multiple_simd(const int16_t* src, int16_t* dst, uint8_t base, size_t length) {\n    size_t vl;\n    size_t i = 0;\n\n    while (i < length) {\n        vl = vsetvl_e16m1(length - i); // Set vector length for 16-bit integers\n        vint16m1_t v_src = vle16_v_i16m1(&src[i], vl); // Load src elements into vector\n        vint16m1_t v_base = vmv_v_x_i16m1(base, vl); // Broadcast base into a vector\n\n        // Perform integer division: src / base\n        vint16m1_t v_div = vdivu_vv_i16m1(v_src, v_base, vl);\n\n        // Multiply back to get the nearest multiple: (src / base) * base\n        vint16m1_t v_result = vmul_vv_i16m1(v_div, v_base, vl);\n\n        // Store the result in dst\n        vse16_v_i16m1(&dst[i], v_result, vl);\n\n        i += vl; // Increment index by vector length\n    }\n}\n```"}
{"task_id": "SimdBench_31_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid nearest_multiple_simd(const int16_t* src, int16_t* dst, uint8_t base, size_t length) {\n    size_t vl;\n    vuint16m1_t vbase = vmv_v_x_u16m1(base, vsetvlmax_e16m1()); // Broadcast base to vector\n    size_t offset = 0;\n\n    while (length > 0) {\n        vl = vsetvl_e16m1(length); // Set vector length\n        vint16m1_t vsrc = vle16_v_i16m1(&src[offset], vl); // Load src vector\n        vint16m1_t vdiv = vdivu_vv_i16m1(vsrc, vbase, vl); // Divide src by base\n        vint16m1_t vnearest = vmul_vv_i16m1(vdiv, vbase, vl); // Multiply quotient by base\n        vse16_v_i16m1(&dst[offset], vnearest, vl); // Store result in dst\n        offset += vl;\n        length -= vl;\n    }\n}\n```"}
{"task_id": "SimdBench_31_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid nearest_multiple_simd(const int16_t* src, int16_t* dst, uint8_t base, size_t length) {\n    size_t vl;\n    vuint16m1_t v_base = vmv_v_x_u16m1(base, vsetvlmax_e16m1()); // Vector of base values\n    size_t offset = 0;\n\n    while (length > 0) {\n        vl = vsetvl_e16m1(length); // Set vector length\n        vint16m1_t v_src = vle16_v_i16m1(&src[offset], vl); // Load src into vector\n        vint16m1_t v_div = vdivu_vv_i16m1(v_src, v_base, vl); // Divide src by base\n        vint16m1_t v_mul = vmul_vx_i16m1(v_div, base, vl); // Multiply quotient by base\n        vse16_v_i16m1(&dst[offset], v_mul, vl); // Store result in dst\n        offset += vl;\n        length -= vl;\n    }\n}\n```"}
{"task_id": "SimdBench_31_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid nearest_multiple_simd(const int16_t* src, int16_t* dst, uint8_t base, size_t length) {\n    size_t vl;\n    size_t i = 0;\n    while (i < length) {\n        vl = vsetvl_e16m1(length - i); // Set vector length for 16-bit integers\n        vint16m1_t src_vec = vle16_v_i16m1(&src[i], vl); // Load src vector\n        vint16m1_t base_vec = vmv_v_x_i16m1(base, vl); // Broadcast base to vector\n        vint16m1_t div_vec = vdivu_vv_u16m1(src_vec, base_vec, vl); // Divide src by base\n        vint16m1_t mul_vec = vmul_vv_i16m1(div_vec, base_vec, vl); // Multiply quotient by base\n        vse16_v_i16m1(&dst[i], mul_vec, vl); // Store result in dst\n        i += vl; // Increment index by vector length\n    }\n}\n```"}
{"task_id": "SimdBench_32_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nbool matrix_has_row_simd(const double* matrix, const double* vector, size_t rows, size_t cols) {\n    size_t vl;\n    for (size_t i = 0; i < rows; i++) {\n        const double* row = matrix + i * cols;\n        size_t col = 0;\n        bool row_matches = true;\n\n        while (col < cols) {\n            vl = vsetvl_e64m1(cols - col);\n            vfloat64m1_t row_vec = vle64_v_f64m1(row + col, vl);\n            vfloat64m1_t vec_vec = vle64_v_f64m1(vector + col, vl);\n            vbool64_t match_mask = vmfeq_vv_f64m1_b64(row_vec, vec_vec, vl);\n\n            if (!vcpop_m_b64(match_mask, vl)) {\n                row_matches = false;\n                break;\n            }\n            col += vl;\n        }\n\n        if (row_matches) {\n            return true;\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_32_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nbool matrix_has_row_simd(const double* matrix, const double* vector, size_t rows, size_t cols) {\n    size_t vl;\n    for (size_t i = 0; i < rows; i++) {\n        const double* row = matrix + i * cols;\n        size_t j = 0;\n        bool row_matches = true;\n\n        while (j < cols) {\n            vl = vsetvl_e64m1(cols - j);\n            vfloat64m1_t row_vec = vle64_v_f64m1(row + j, vl);\n            vfloat64m1_t vector_vec = vle64_v_f64m1(vector + j, vl);\n            vbool64_t mask = vmfeq_vv_f64m1_b64(row_vec, vector_vec, vl);\n\n            if (vcpop_b64(mask) != vl) {\n                row_matches = false;\n                break;\n            }\n            j += vl;\n        }\n\n        if (row_matches) {\n            return true;\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_32_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nbool matrix_has_row_simd(const double* matrix, const double* vector, size_t rows, size_t cols) {\n    size_t vl;\n    for (size_t i = 0; i < rows; i++) {\n        const double* row = matrix + i * cols;\n        size_t col = 0;\n        bool row_matches = true;\n\n        while (col < cols) {\n            vl = vsetvl_e64m1(cols - col);\n            vfloat64m1_t row_vec = vle64_v_f64m1(row + col, vl);\n            vfloat64m1_t vector_vec = vle64_v_f64m1(vector + col, vl);\n            vbool64_t compare_mask = vmfeq_vv_f64m1_b64(row_vec, vector_vec, vl);\n\n            if (!vcpop_m_b64(compare_mask, vl)) {\n                row_matches = false;\n                break;\n            }\n            col += vl;\n        }\n\n        if (row_matches) {\n            return true;\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_32_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nbool matrix_has_row_simd(const double* matrix, const double* vector, size_t rows, size_t cols) {\n    size_t vlmax = vsetvlmax_e64m1(); // Maximum vector length for 64-bit elements\n    for (size_t i = 0; i < rows; i++) {\n        const double* row = matrix + i * cols;\n        size_t remaining = cols;\n        size_t offset = 0;\n        bool row_matches = true;\n\n        while (remaining > 0) {\n            size_t vl = vsetvl_e64m1(remaining); // Set vector length based on remaining elements\n            vfloat64m1_t row_vec = vle64_v_f64m1(row + offset, vl);\n            vfloat64m1_t vector_vec = vle64_v_f64m1(vector + offset, vl);\n            vbool64_t mask = vmfeq_vv_f64m1_b64(row_vec, vector_vec, vl); // Compare row and vector elements\n            if (!vcpop_b64(mask)) { // Check if all elements match\n                row_matches = false;\n                break;\n            }\n            remaining -= vl;\n            offset += vl;\n        }\n\n        if (row_matches) {\n            return true;\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_32_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nbool matrix_has_row_simd(const double* matrix, const double* vector, size_t rows, size_t cols) {\n    size_t vl;\n    for (size_t i = 0; i < rows; i++) {\n        const double* row_ptr = matrix + i * cols;\n        size_t col_idx = 0;\n        bool row_matches = true;\n\n        while (col_idx < cols) {\n            vl = vsetvl_e64m1(cols - col_idx);\n            vfloat64m1_t row_vec = vle64_v_f64m1(row_ptr + col_idx, vl);\n            vfloat64m1_t vec_vec = vle64_v_f64m1(vector + col_idx, vl);\n            vbool64_t cmp_result = vmfeq_vv_f64m1_b64(row_vec, vec_vec, vl);\n\n            if (!vcpop_m_b64(cmp_result, vl)) {\n                row_matches = false;\n                break;\n            }\n            col_idx += vl;\n        }\n\n        if (row_matches) {\n            return true;\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_33_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nsize_t tensor_4d_equal_count_simd(const uint8_t* A, const uint8_t* B, const size_t dims[4]) {\n    size_t total_elements = dims[0] * dims[1] * dims[2] * dims[3];\n    size_t equal_count = 0;\n\n    size_t i = 0;\n    size_t vl;\n    while (i < total_elements) {\n        vl = vsetvl_e8m1(total_elements - i); // Set vector length based on remaining elements\n        vuint8m1_t vecA = vle8_v_u8m1(&A[i], vl); // Load vector from A\n        vuint8m1_t vecB = vle8_v_u8m1(&B[i], vl); // Load vector from B\n\n        vbool8_t mask = vmseq_vv_u8m1_b8(vecA, vecB, vl); // Compare elements for equality\n        equal_count += vcpop_b8(mask, vl); // Count the number of true values in the mask\n\n        i += vl; // Increment index by vector length\n    }\n\n    return equal_count;\n}\n```"}
{"task_id": "SimdBench_33_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nsize_t tensor_4d_equal_count_simd(const uint8_t* A, const uint8_t* B, const size_t dims[4]) {\n    size_t total_elements = dims[0] * dims[1] * dims[2] * dims[3];\n    size_t equal_count = 0;\n\n    size_t i = 0;\n    size_t vl;\n    while (i < total_elements) {\n        vl = vsetvl_e8m1(total_elements - i); // Set vector length for 8-bit elements\n        vuint8m1_t vecA = vle8_v_u8m1(&A[i], vl); // Load vector from A\n        vuint8m1_t vecB = vle8_v_u8m1(&B[i], vl); // Load vector from B\n        vbool8_t mask = vmseq_vv_u8m1_b8(vecA, vecB, vl); // Compare elements\n        equal_count += vcpop_b8(mask, vl); // Count true values in mask\n        i += vl; // Move to next chunk\n    }\n\n    return equal_count;\n}\n```"}
{"task_id": "SimdBench_33_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nsize_t tensor_4d_equal_count_simd(const uint8_t* A, const uint8_t* B, const size_t dims[4]) {\n    size_t total_elements = dims[0] * dims[1] * dims[2] * dims[3];\n    size_t equal_count = 0;\n    size_t i = 0;\n\n    size_t vl;\n    while (i < total_elements) {\n        vl = vsetvl_e8m8(total_elements - i); // Set vector length for 8-bit elements\n        vuint8m8_t vecA = vle8_v_u8m8(&A[i], vl); // Load vector from A\n        vuint8m8_t vecB = vle8_v_u8m8(&B[i], vl); // Load vector from B\n        vbool1_t mask = vmseq_vv_u8m8_b1(vecA, vecB, vl); // Compare A and B for equality\n        equal_count += vcpop_b1(mask); // Count the number of true values in the mask\n        i += vl; // Increment index by the vector length\n    }\n\n    return equal_count;\n}\n```"}
{"task_id": "SimdBench_33_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nsize_t tensor_4d_equal_count_simd(const uint8_t* A, const uint8_t* B, const size_t dims[4]) {\n    size_t total_elements = dims[0] * dims[1] * dims[2] * dims[3];\n    size_t equal_count = 0;\n\n    size_t i = 0;\n    size_t vl;\n    while (i < total_elements) {\n        vl = vsetvl_e8m1(total_elements - i); // Set vector length for remaining elements\n        vuint8m1_t vecA = vle8_v_u8m1(&A[i], vl); // Load vector from A\n        vuint8m1_t vecB = vle8_v_u8m1(&B[i], vl); // Load vector from B\n\n        vbool8_t mask = vmseq_vv_u8m1_b8(vecA, vecB, vl); // Compare elements\n        equal_count += vpopc_m_b8(mask, vl); // Count matches using mask\n\n        i += vl; // Increment index by vector length\n    }\n\n    return equal_count;\n}\n```"}
{"task_id": "SimdBench_33_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nsize_t tensor_4d_equal_count_simd(const uint8_t* A, const uint8_t* B, const size_t dims[4]) {\n    size_t total_elements = dims[0] * dims[1] * dims[2] * dims[3];\n    size_t equal_count = 0;\n    size_t i = 0;\n\n    size_t vl;\n    while (i < total_elements) {\n        vl = vsetvl_e8m1(total_elements - i); // Set vector length based on remaining elements\n        vuint8m1_t vecA = vle8_v_u8m1(&A[i], vl); // Load vector from A\n        vuint8m1_t vecB = vle8_v_u8m1(&B[i], vl); // Load vector from B\n        vbool8_t mask = vmseq_vv_u8m1_b8(vecA, vecB, vl); // Compare elements for equality\n        equal_count += vcpop_b8(mask, vl); // Count the number of true values in the mask\n        i += vl; // Increment index by vector length\n    }\n\n    return equal_count;\n}\n```"}
{"task_id": "SimdBench_34_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid axm_abs_simd(size_t length, const int64_t a, const int64_t *x, int64_t *y) {\n    size_t vl;\n    size_t offset = 0;\n\n    while (offset < length) {\n        vl = vsetvl_e64m1(length - offset);\n\n        vint64m1_t vec_x = vle64_v_i64m1(&x[offset], vl);\n        vint64m1_t vec_y = vle64_v_i64m1(&y[offset], vl);\n\n        vint64m1_t vec_ax = vmul_vx_i64m1(vec_x, a, vl);\n        vec_y = vabs_v_i64m1(vec_y, vl);\n        vec_y = vsub_vv_i64m1(vec_ax, vec_y, vl);\n\n        vse64_v_i64m1(&y[offset], vec_y, vl);\n\n        offset += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_34_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid axm_abs_simd(size_t length, const int64_t a, const int64_t *x, int64_t *y) {\n    size_t vl;\n    size_t offset = 0;\n\n    while (offset < length) {\n        vl = vsetvl_e64m1(length - offset);\n\n        vint64m1_t vec_x = vle64_v_i64m1(&x[offset], vl);\n        vint64m1_t vec_y = vle64_v_i64m1(&y[offset], vl);\n\n        vint64m1_t vec_ax = vmul_vx_i64m1(vec_x, a, vl);\n        vint64m1_t vec_abs_y = vabs_v_i64m1(vec_y, vl);\n\n        vint64m1_t vec_result = vsub_vv_i64m1(vec_ax, vec_abs_y, vl);\n\n        vse64_v_i64m1(&y[offset], vec_result, vl);\n\n        offset += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_34_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid axm_abs_simd(size_t length, const int64_t a, const int64_t *x, int64_t *y) {\n    size_t vl;\n    vsetvlmax_e64m1(); // Set the maximum vector length for 64-bit elements\n    while (length > 0) {\n        vl = vsetvl_e64m1(length); // Set the vector length for the current iteration\n        vint64m1_t vx = vle64_v_i64m1(x, vl); // Load vector x\n        vint64m1_t vy = vle64_v_i64m1(y, vl); // Load vector y\n        vint64m1_t vax = vmul_vx_i64m1(vx, a, vl); // Perform scalar-vector multiplication\n        vy = vsub_vv_i64m1(vax, vabs_v_i64m1(vy, vl), vl); // Subtract absolute value of y from vax\n        vse64_v_i64m1(y, vy, vl); // Store the result back to y\n        x += vl;\n        y += vl;\n        length -= vl;\n    }\n}\n```"}
{"task_id": "SimdBench_34_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid axm_abs_simd(size_t length, const int64_t a, const int64_t *x, int64_t *y) {\n    size_t vl;\n    size_t i = 0;\n\n    while (i < length) {\n        vl = vsetvl_e64(length - i); // Set vector length for 64-bit elements\n        vint64m1_t vx = vle64_v_i64m1(&x[i], vl); // Load vector x\n        vint64m1_t vy = vle64_v_i64m1(&y[i], vl); // Load vector y\n\n        vint64m1_t va = vmv_v_x_i64m1(a, vl); // Broadcast scalar a to vector\n        vint64m1_t vax = vmul_vv_i64m1(va, vx, vl); // Multiply scalar a with vector x\n        vint64m1_t vy_abs = vabs_v_i64m1(vy, vl); // Compute absolute value of vector y\n        vint64m1_t vresult = vsub_vv_i64m1(vax, vy_abs, vl); // Subtract absolute value of y from a*x\n\n        vse64_v_i64m1(&y[i], vresult, vl); // Store the result back to y\n        i += vl; // Increment index by vector length\n    }\n}\n```"}
{"task_id": "SimdBench_34_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid axm_abs_simd(size_t length, const int64_t a, const int64_t *x, int64_t *y) {\n    size_t vl;\n    size_t offset = 0;\n\n    while (offset < length) {\n        vl = vsetvl_e64m1(length - offset);\n\n        vint64m1_t vx = vle64_v_i64m1(x + offset, vl);\n        vint64m1_t vy = vle64_v_i64m1(y + offset, vl);\n\n        vint64m1_t va = vmv_v_x_i64m1(a, vl);\n        vint64m1_t vax = vmul_vv_i64m1(va, vx, vl);\n        vint64m1_t vabs_y = vabs_v_i64m1(vy, vl);\n\n        vint64m1_t vresult = vsub_vv_i64m1(vax, vabs_y, vl);\n        vse64_v_i64m1(y + offset, vresult, vl);\n\n        offset += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_35_RVV", "completion": "```c\n#include <riscv_vector.h>\n\ntypedef struct {\n    int16_t min_num;\n    int16_t max_num;\n} MinMaxPair;\n\nMinMaxPair min_max_pair_simd(const int16_t* vec, size_t length) {\n    size_t vl;\n    vint16m1_t v_min, v_max, v_data;\n\n    // Initialize min and max with the first vector segment\n    vl = vsetvl_e16m1(length);\n    v_data = vle16_v_i16m1(vec, vl);\n    v_min = v_data;\n    v_max = v_data;\n\n    size_t offset = vl;\n    while (offset < length) {\n        vl = vsetvl_e16m1(length - offset);\n        v_data = vle16_v_i16m1(vec + offset, vl);\n\n        v_min = vmin_vv_i16m1(v_min, v_data, vl);\n        v_max = vmax_vv_i16m1(v_max, v_data, vl);\n\n        offset += vl;\n    }\n\n    // Reduce min and max values across the vector\n    int16_t min_result = vmv_x_s_i16m1_i16(v_min);\n    int16_t max_result = vmv_x_s_i16m1_i16(v_max);\n\n    for (size_t i = 1; i < vsetvl_e16m1(1); i++) {\n        min_result = (min_result < vmv_x_s_i16m1_i16(vslide1down_vx_i16m1(v_min, 0, vsetvl_e16m1(1)))) ? min_result : \n    }\n}\n```"}
{"task_id": "SimdBench_35_RVV", "completion": "```c\n#include <riscv_vector.h>\n\ntypedef struct {\n    int16_t min_num;\n    int16_t max_num;\n} MinMaxPair;\n\nMinMaxPair min_max_pair_simd(const int16_t* vec, size_t length) {\n    size_t vl;\n    vint16m1_t vmin, vmax;\n    size_t offset = 0;\n\n    // Initialize min and max vectors with the first chunk of data\n    vl = vsetvl_e16m1(length);\n    vmin = vle16_v_i16m1(vec, vl);\n    vmax = vmin;\n    offset += vl;\n\n    while (offset < length) {\n        vl = vsetvl_e16m1(length - offset);\n        vint16m1_t vdata = vle16_v_i16m1(vec + offset, vl);\n\n        vmin = vmin_vv_i16m1(vmin, vdata, vl);\n        vmax = vmax_vv_i16m1(vmax, vdata, vl);\n\n        offset += vl;\n    }\n\n    // Reduce the min and max vectors to scalar values\n    int16_t min_result = vmv_x_s_i16m1_i16(vredmin_vs_i16m1_i16m1(vmin, vmin, vl));\n    int16_t max_result = vmv_x_s_i16m1_i16(vredmax_vs_i16m1_i16m1(vmax, vmax, vl));\n\n    MinMaxPair result = {min_result, max_result};\n    return result;\n}\n```"}
{"task_id": "SimdBench_35_RVV", "completion": "```c\n#include <riscv_vector.h>\n\ntypedef struct {\n    int16_t min_num;\n    int16_t max_num;\n} MinMaxPair;\n\nMinMaxPair min_max_pair_simd(const int16_t* vec, size_t length) {\n    size_t vl;\n    vint16m1_t v_min, v_max;\n\n    // Initialize min and max vectors with the first chunk of data\n    vl = vsetvl_e16m1(length);\n    v_min = vle16_v_i16m1(vec, vl);\n    v_max = v_min;\n\n    size_t offset = vl;\n\n    while (offset < length) {\n        vl = vsetvl_e16m1(length - offset);\n        vint16m1_t v_data = vle16_v_i16m1(vec + offset, vl);\n\n        v_min = vmin_vv_i16m1(v_min, v_data, vl);\n        v_max = vmax_vv_i16m1(v_max, v_data, vl);\n\n        offset += vl;\n    }\n\n    // Reduce the min and max vectors to scalar values\n    int16_t min_num = vmv_x_s_i16m1_i16(vredmin_vs_i16m1_i16m1(v_min, v_min, vl));\n    int16_t max_num = vmv_x_s_i16m1_i16(vredmax_vs_i16m1_i16m1(v_max, v_max, vl));\n\n    MinMaxPair result = {min_num, max_num};\n    return result;\n}\n```"}
{"task_id": "SimdBench_35_RVV", "completion": "```c\n#include <riscv_vector.h>\n\ntypedef struct {\n    int16_t min_num;\n    int16_t max_num;\n} MinMaxPair;\n\nMinMaxPair min_max_pair_simd(const int16_t* vec, size_t length) {\n    size_t vl;\n    vint16m1_t vmin, vmax;\n    MinMaxPair result;\n\n    // Initialize the vector registers with the first chunk of data\n    vl = vsetvl_e16m1(length);\n    vmin = vle16_v_i16m1(vec, vl);\n    vmax = vmin;\n\n    size_t offset = vl;\n\n    // Process the remaining elements in chunks\n    while (offset < length) {\n        vl = vsetvl_e16m1(length - offset);\n        vint16m1_t vdata = vle16_v_i16m1(vec + offset, vl);\n        vmin = vmin_vv_i16m1(vmin, vdata, vl);\n        vmax = vmax_vv_i16m1(vmax, vdata, vl);\n        offset += vl;\n    }\n\n    // Reduce the vector registers to scalar values\n    result.min_num = vmv_x_s_i16m1_i16(vredmin_vs_i16m1_i16(vmin, vmin, vl));\n    result.max_num = vmv_x_s_i16m1_i16(vredmax_vs_i16m1_i16(vmax, vmax, vl));\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_35_RVV", "completion": "```c\n#include <riscv_vector.h>\n\ntypedef struct {\n    int16_t min_num;\n    int16_t max_num;\n} MinMaxPair;\n\nMinMaxPair min_max_pair_simd(const int16_t* vec, size_t length) {\n    size_t vl;\n    vint16m1_t vmin, vmax;\n    vmin = vle16_v_i16m1(vec, vsetvl_e16m1(length)); // Load initial vector\n    vmax = vmin; // Initialize max vector with the same values as min\n\n    size_t offset = vsetvl_e16m1(length); // Set initial vector length\n    while (offset < length) {\n        vl = vsetvl_e16m1(length - offset); // Determine vector length for remaining elements\n        vint16m1_t vdata = vle16_v_i16m1(vec + offset, vl); // Load next chunk of data\n        vmin = vmin_vv_i16m1(vmin, vdata, vl); // Compute element-wise minimum\n        vmax = vmax_vv_i16m1(vmax, vdata, vl); // Compute element-wise maximum\n        offset += vl; // Update offset\n    }\n\n    int16_t min_num = vmv_x_s_i16m1_i16(vreduce_min_i16m1(vmin, vsetvl_e16m1(1))); // Reduce to scalar minimum\n    int16_t max_num = vmv_x_s_i16m1_i16(vreduce_max_i16m1(vmax, vsetvl_e16m1(1))); // Reduce to scalar maximum\n\n    MinMaxPair result = {min_num, max_num};\n    return result;\n}\n```"}
{"task_id": "SimdBench_36_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nbool matrix_rows_strictly_increasing_simd(const int* matrix, size_t rows, size_t cols) {\n    if (rows == 0 || cols < 2) {\n        return false;\n    }\n\n    size_t vlmax = vsetvlmax_e32m1(); // Maximum vector length for 32-bit integers\n    for (size_t i = 0; i < rows; i++) {\n        const int* row = matrix + i * cols;\n        size_t remaining = cols - 1; // Number of comparisons needed in the row\n        size_t offset = 0;\n\n        while (remaining > 0) {\n            size_t vl = vsetvl_e32m1(remaining); // Set vector length based on remaining elements\n\n            vint32m1_t current = vle32_v_i32m1(row + offset, vl); // Load current elements\n            vint32m1_t next = vle32_v_i32m1(row + offset + 1, vl); // Load next elements\n\n            vbool32_t mask = vmgt_vv_i32m1_b32(next, current, vl); // Compare next > current\n            if (!vcpop_b32(mask)) { // Count true elements in mask; if zero, row is not strictly increasing\n                return false;\n            }\n\n            remaining -= vl;\n            offset += vl;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_36_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nbool matrix_rows_strictly_increasing_simd(const int* matrix, size_t rows, size_t cols) {\n    if (rows == 0 || cols == 0) {\n        return false;\n    }\n\n    size_t vlmax = vsetvlmax_e32m1(); // Maximum vector length for 32-bit integers\n    for (size_t r = 0; r < rows; r++) {\n        const int* row = matrix + r * cols;\n        size_t remaining = cols - 1; // Number of comparisons in the row\n        size_t offset = 0;\n\n        while (remaining > 0) {\n            size_t vl = vsetvl_e32m1(remaining); // Set vector length based on remaining elements\n            vint32m1_t current = vle32_v_i32m1(row + offset, vl); // Load current elements\n            vint32m1_t next = vle32_v_i32m1(row + offset + 1, vl); // Load next elements\n\n            vbool32_t mask = vmgt_vv_i32m1_b32(next, current, vl); // Compare next > current\n            if (vcpop_b32(mask) != vl) { // Check if all comparisons are true\n                return false;\n            }\n\n            offset += vl;\n            remaining -= vl;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_36_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nbool matrix_rows_strictly_increasing_simd(const int* matrix, size_t rows, size_t cols) {\n    if (rows == 0 || cols == 0) {\n        return false;\n    }\n\n    size_t vl;\n    for (size_t i = 0; i < rows; i++) {\n        const int* row_ptr = matrix + i * cols;\n\n        for (size_t j = 0; j < cols - 1;) {\n            vl = vsetvl_e32m1(cols - 1 - j);\n            vint32m1_t current = vle32_v_i32m1(row_ptr + j, vl);\n            vint32m1_t next = vle32_v_i32m1(row_ptr + j + 1, vl);\n\n            vbool32_t mask = vmfle_vv_i32m1_b32(current, next, vl);\n            if (vfirst_m_b32(mask, vl) != -1) {\n                return false;\n            }\n\n            j += vl;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_36_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nbool matrix_rows_strictly_increasing_simd(const int* matrix, size_t rows, size_t cols) {\n    if (rows == 0 || cols == 0) {\n        return false;\n    }\n\n    size_t vl;\n    for (size_t i = 0; i < rows; i++) {\n        const int* row = matrix + i * cols;\n\n        for (size_t j = 0; j < cols - 1; j += vl) {\n            vl = vsetvl_e32m1(cols - 1 - j); // Set vector length based on remaining elements\n            vint32m1_t current = vle32_v_i32m1(row + j, vl); // Load current elements\n            vint32m1_t next = vle32_v_i32m1(row + j + 1, vl); // Load next elements\n\n            vbool32_t mask = vmgt_vv_i32m1_b32(next, current, vl); // Check if next > current\n            if (!vcpop_b32(mask)) { // Count true elements in mask; if any are false, return false\n                return false;\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_36_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nbool matrix_rows_strictly_increasing_simd(const int* matrix, size_t rows, size_t cols) {\n    if (rows == 0 || cols == 0) {\n        return false;\n    }\n\n    size_t vlmax = vsetvlmax_e32m1(); // Maximum vector length for 32-bit integers\n    for (size_t i = 0; i < rows; i++) {\n        const int* row = matrix + i * cols;\n        size_t remaining = cols - 1; // Number of comparisons needed in the row\n        size_t offset = 0;\n\n        while (remaining > 0) {\n            size_t vl = vsetvl_e32m1(remaining); // Set vector length for current iteration\n            vint32m1_t current = vle32_v_i32m1(row + offset, vl); // Load current elements\n            vint32m1_t next = vle32_v_i32m1(row + offset + 1, vl); // Load next elements\n\n            vbool32_t mask = vmgt_vv_i32m1_b32(next, current, vl); // Compare next > current\n            if (!vcpop_b32(mask)) { // Count true elements in mask; if zero, row is not strictly increasing\n                return false;\n            }\n\n            remaining -= vl;\n            offset += vl;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_37_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <stdbool.h>\n#include <stddef.h>\n\nbool matrix_blocks_equal_simd(const int* matrix, size_t block_size, size_t rows, size_t cols) {\n    // Check if block_size is valid\n    if (block_size == 0 || rows % block_size != 0 || cols % block_size != 0) {\n        return false;\n    }\n\n    size_t num_blocks_row = rows / block_size;\n    size_t num_blocks_col = cols / block_size;\n\n    // Compare each block with the first block\n    for (size_t block_row = 0; block_row < num_blocks_row; ++block_row) {\n        for (size_t block_col = 0; block_col < num_blocks_col; ++block_col) {\n            if (block_row == 0 && block_col == 0) {\n                continue; // Skip the first block\n            }\n\n            // Compare the current block with the first block\n            for (size_t i = 0; i < block_size; ++i) {\n                size_t row_offset_first = i;\n                size_t row_offset_current = block_row * block_size + i;\n\n                for (size_t j = 0; j < block_size; j += vsetvl_e32m1(block_size)) {\n                    size_t vl = vsetvl_e32m1(block_size - j);\n\n                    const int* first_block_ptr = matrix + row_offset_first * cols + j;\n                    const int* current_block_ptr = matrix + row_offset_current * cols + block_col * block_size + j;\n\n                    vint32m1_t first_block_vec = vle32_v_i32m1(first_block_ptr, vl);\n                    vint32m1_t current_block_vec = vle32_v_i32m1(current_block_ptr, vl);\n\n                    vbool32_t mask = vmseq_vv_i32m1_b32(first_block_vec, current_block_vec, vl);\n\n                    if (!vcpop_b32(mask)) {\n                        return false;\n                    }\n                }\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_37_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <stdbool.h>\n#include <stddef.h>\n\nbool matrix_blocks_equal_simd(const int* matrix, size_t block_size, size_t rows, size_t cols) {\n    // Check if block_size is valid\n    if (block_size == 0 || rows % block_size != 0 || cols % block_size != 0) {\n        return false;\n    }\n\n    size_t num_blocks_row = rows / block_size;\n    size_t num_blocks_col = cols / block_size;\n    size_t block_elements = block_size * block_size;\n\n    // Load the first block into a vector\n    const int* first_block = matrix;\n    size_t vl = vsetvl_e32m1(block_elements);\n    vint32m1_t first_block_vec = vle32_v_i32m1(first_block, vl);\n\n    // Iterate over all blocks\n    for (size_t block_row = 0; block_row < num_blocks_row; block_row++) {\n        for (size_t block_col = 0; block_col < num_blocks_col; block_col++) {\n            const int* current_block = matrix + (block_row * block_size * cols) + (block_col * block_size);\n\n            // Compare current block with the first block\n            for (size_t i = 0; i < block_size; i++) {\n                const int* current_row = current_block + i * cols;\n                vint32m1_t current_row_vec = vle32_v_i32m1(current_row, vl);\n\n                // Perform vector comparison\n                vbool32_t mask = vmseq_vv_i32m1_b32(current_row_vec, first_block_vec, vl);\n                if (vcpop_b32(mask) != block_size) {\n                    return false;\n                }\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_37_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <stdbool.h>\n#include <stddef.h>\n\nbool matrix_blocks_equal_simd(const int* matrix, size_t block_size, size_t rows, size_t cols) {\n    // Check if block_size is valid\n    if (block_size == 0 || rows % block_size != 0 || cols % block_size != 0) {\n        return false;\n    }\n\n    size_t num_blocks_row = rows / block_size;\n    size_t num_blocks_col = cols / block_size;\n\n    // Compare each block with the first block\n    for (size_t block_row = 0; block_row < num_blocks_row; block_row++) {\n        for (size_t block_col = 0; block_col < num_blocks_col; block_col++) {\n            if (block_row == 0 && block_col == 0) {\n                continue; // Skip the first block\n            }\n\n            // Compare the current block with the first block\n            for (size_t i = 0; i < block_size; i++) {\n                size_t first_block_row = i;\n                size_t current_block_row = block_row * block_size + i;\n\n                const int* first_block_ptr = matrix + first_block_row * cols;\n                const int* current_block_ptr = matrix + current_block_row * cols + block_col * block_size;\n\n                size_t vl = vsetvl_e32m8(block_size);\n                for (size_t j = 0; j < block_size; j += vl) {\n                    vl = vsetvl_e32m8(block_size - j);\n\n                    vint32m8_t first_block_vec = vle32_v_i32m8(first_block_ptr + j, vl);\n                    vint32m8_t current_block_vec = vle32_v_i32m8(current_block_ptr + j, vl);\n\n                    vbool4_t mask = vmseq_vv_i32m8_b4(first_block_vec, current_block_vec, vl);\n                    if (!vcpop_b4(mask)) {\n                        return false; // Blocks are not equal\n                    }\n                }\n            }\n        }\n    }\n\n    return true; // All blocks are equal\n}\n```"}
{"task_id": "SimdBench_37_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <stdbool.h>\n\nbool matrix_blocks_equal_simd(const int* matrix, size_t block_size, size_t rows, size_t cols) {\n    if (block_size == 0 || rows % block_size != 0 || cols % block_size != 0) {\n        return false;\n    }\n\n    size_t num_blocks_row = rows / block_size;\n    size_t num_blocks_col = cols / block_size;\n    size_t block_elements = block_size * block_size;\n\n    const int* first_block = matrix;\n\n    for (size_t br = 0; br < num_blocks_row; br++) {\n        for (size_t bc = 0; bc < num_blocks_col; bc++) {\n            if (br == 0 && bc == 0) {\n                continue; // Skip the first block\n            }\n\n            const int* current_block = matrix + (br * block_size * cols) + (bc * block_size);\n\n            size_t remaining = block_elements;\n            size_t offset = 0;\n\n            while (remaining > 0) {\n                size_t vl = vsetvl_e32m8(remaining);\n                vint32m8_t first_block_vec = vle32_v_i32m8(first_block + offset, vl);\n                vint32m8_t current_block_vec = vle32_v_i32m8(current_block + offset, vl);\n\n                vbool4_t compare_result = vmseq_vv_i32m8_b4(first_block_vec, current_block_vec, vl);\n                if (!vcpop_m_b4(compare_result, vl)) {\n                    return false;\n                }\n\n                remaining -= vl;\n                offset += vl;\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_37_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <stdbool.h>\n\nbool matrix_blocks_equal_simd(const int* matrix, size_t block_size, size_t rows, size_t cols) {\n    if (block_size == 0 || rows % block_size != 0 || cols % block_size != 0) {\n        return false;\n    }\n\n    size_t blocks_per_row = cols / block_size;\n    size_t block_elements = block_size * block_size;\n\n    const int* first_block = matrix;\n\n    for (size_t block_row = 0; block_row < rows / block_size; block_row++) {\n        for (size_t block_col = 0; block_col < blocks_per_row; block_col++) {\n            if (block_row == 0 && block_col == 0) {\n                continue; // Skip the first block\n            }\n\n            const int* current_block = matrix + (block_row * block_size * cols) + (block_col * block_size);\n\n            size_t remaining = block_elements;\n            while (remaining > 0) {\n                size_t vl = vsetvl_e32m8(remaining);\n                vuint32m8_t first_block_vec = vle32_v_u32m8(first_block, vl);\n                vuint32m8_t current_block_vec = vle32_v_u32m8(current_block, vl);\n\n                vbool4_t cmp_result = vmseq_vv_u32m8_b4(first_block_vec, current_block_vec, vl);\n                if (!vcpop_b4(cmp_result) == vl) {\n                    return false;\n                }\n\n                first_block += vl;\n                current_block += vl;\n                remaining -= vl;\n            }\n\n            first_block = matrix; // Reset first_block pointer for next comparison\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_38_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <stdbool.h>\n#include <stddef.h>\n\nbool vector_block_equal_simd(const double* vec, double tolerance, size_t length, size_t block_size) {\n    if (!vec || block_size == 0 || length < block_size) {\n        return false; // Invalid input or no complete blocks\n    }\n\n    size_t num_blocks = length / block_size;\n    size_t tail_elements = length % block_size;\n\n    if (num_blocks == 0) {\n        return false; // No complete blocks\n    }\n\n    size_t vl = vsetvl_e64m1(block_size); // Set vector length for block_size\n    vfloat64m1_t ref_block = vle64_v_f64m1(vec, vl); // Load the first block into vector register\n\n    for (size_t i = 1; i < num_blocks; i++) {\n        const double* current_block = vec + i * block_size;\n        vfloat64m1_t curr_block = vle64_v_f64m1(current_block, vl); // Load current block\n\n        vfloat64m1_t diff = vfsub_vv_f64m1(curr_block, ref_block, vl); // Element-wise subtraction\n        vfloat64m1_t abs_diff = vfabs_v_f64m1(diff, vl); // Absolute difference\n\n        vbool64_t mask = vmfle_vf_f64m1_b64(abs_diff, tolerance, vl); // Compare with tolerance\n        if (vcpop_b64(mask) != block_size) { // Check if all elements are within tolerance\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_38_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <stdbool.h>\n#include <stddef.h>\n\nbool vector_block_equal_simd(const double* vec, double tolerance, size_t length, size_t block_size) {\n    if (!vec || block_size == 0 || length < block_size) {\n        return false; // Illegal input or no complete blocks\n    }\n\n    size_t num_blocks = length / block_size;\n    size_t vlmax = vsetvlmax_e64m1(); // Maximum vector length for 64-bit elements\n    size_t vl = vsetvl_e64m1(block_size); // Vector length for the block size\n\n    if (vl > vlmax) {\n        return false; // Block size exceeds maximum vector length\n    }\n\n    const double* first_block = vec;\n\n    for (size_t i = 1; i < num_blocks; i++) {\n        const double* current_block = vec + i * block_size;\n\n        vfloat64m1_t v_first = vle64_v_f64m1(first_block, vl);\n        vfloat64m1_t v_current = vle64_v_f64m1(current_block, vl);\n\n        vfloat64m1_t v_diff = vfsub_vv_f64m1(v_current, v_first, vl);\n        vfloat64m1_t v_abs_diff = vfabs_v_f64m1(v_diff, vl);\n\n        vbool64_t v_within_tolerance = vmfle_vf_f64m1_b64(v_abs_diff, tolerance, vl);\n\n        if (!vcpop_b64(v_within_tolerance, vl)) {\n            return false; // Found a block not matching within tolerance\n        }\n    }\n\n    return true; // All blocks match within tolerance\n}\n```"}
{"task_id": "SimdBench_38_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <stdbool.h>\n#include <stddef.h>\n\nbool vector_block_equal_simd(const double* vec, double tolerance, size_t length, size_t block_size) {\n    if (!vec || block_size == 0 || length < block_size) {\n        return false; // Illegal input or no complete blocks\n    }\n\n    size_t num_blocks = length / block_size;\n    if (num_blocks < 1) {\n        return false; // No complete blocks\n    }\n\n    size_t vl;\n    vbool64_t mask;\n    vfloat64m1_t ref_block, current_block, diff, abs_diff, tol_vec;\n\n    // Load the first block as the reference block\n    vl = vsetvl_e64m1(block_size);\n    ref_block = vle64_v_f64m1(vec, vl);\n\n    // Create a vector of tolerance values\n    tol_vec = vfmv_v_f_f64m1(tolerance, vl);\n\n    for (size_t i = 1; i < num_blocks; i++) {\n        // Load the current block\n        current_block = vle64_v_f64m1(vec + i * block_size, vl);\n\n        // Compute the absolute difference between the reference block and the current block\n        diff = vfsub_vv_f64m1(ref_block, current_block, vl);\n        abs_diff = vfabs_v_f64m1(diff, vl);\n\n        // Check if all differences are within the tolerance\n        mask = vmfle_vv_f64m1_b64(abs_diff, tol_vec, vl);\n        if (!vcpop_b64(mask, vl)) {\n            return false; // At least one element exceeds the tolerance\n        }\n    }\n\n    return true; // All blocks are equal within the tolerance\n}\n```"}
{"task_id": "SimdBench_38_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <stdbool.h>\n#include <stddef.h>\n\nbool vector_block_equal_simd(const double* vec, double tolerance, size_t length, size_t block_size) {\n    if (!vec || block_size == 0 || length < block_size) {\n        return false; // Illegal input or no complete blocks\n    }\n\n    size_t num_blocks = length / block_size;\n    if (num_blocks < 1) {\n        return false; // No complete blocks\n    }\n\n    size_t vl = vsetvl_e64m1(block_size); // Set vector length for block_size\n    vfloat64m1_t ref_block = vle64_v_f64m1(vec, vl); // Load the first block into vector register\n\n    for (size_t i = 1; i < num_blocks; i++) {\n        const double* current_block = vec + i * block_size;\n        vfloat64m1_t curr_block = vle64_v_f64m1(current_block, vl); // Load current block\n\n        vfloat64m1_t diff = vfsub_vv_f64m1(curr_block, ref_block, vl); // Element-wise subtraction\n        vfloat64m1_t abs_diff = vfabs_v_f64m1(diff, vl); // Compute absolute difference\n\n        vbool64_t mask = vmfle_vf_f64m1_b64(abs_diff, tolerance, vl); // Compare with tolerance\n        if (!vcpop_b64(mask)) {\n            return false; // If any element exceeds tolerance, blocks are not equal\n        }\n    }\n\n    return true; // All blocks are equal within tolerance\n}\n```"}
{"task_id": "SimdBench_38_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <stdbool.h>\n#include <stddef.h>\n\nbool vector_block_equal_simd(const double* vec, double tolerance, size_t length, size_t block_size) {\n    if (!vec || block_size == 0 || length < block_size) {\n        return false;\n    }\n\n    size_t num_blocks = length / block_size;\n    if (num_blocks < 1) {\n        return false;\n    }\n\n    size_t vl = vsetvl_e64m1(block_size);\n    vfloat64m1_t ref_block = vle64_v_f64m1(vec, vl);\n\n    for (size_t i = 1; i < num_blocks; i++) {\n        const double* current_block = vec + i * block_size;\n        vfloat64m1_t curr_block = vle64_v_f64m1(current_block, vl);\n\n        vfloat64m1_t diff = vfsub_vv_f64m1(curr_block, ref_block, vl);\n        vfloat64m1_t abs_diff = vfabs_v_f64m1(diff, vl);\n\n        vbool64_t mask = vmfle_vf_f64m1_b64(abs_diff, tolerance, vl);\n        if (!vcpop_b64(mask)) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_39_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <math.h>\n\nvoid matrix_row_norm_compare_simd(const double* matrix, const double* thresholds, size_t rows, size_t cols, bool* result) {\n    size_t vlmax = vsetvlmax_e64m1(); // Maximum vector length for 64-bit elements\n    for (size_t i = 0; i < rows; i++) {\n        size_t remaining_cols = cols;\n        const double* row_ptr = matrix + i * cols;\n        double row_norm_squared = 0.0;\n\n        while (remaining_cols > 0) {\n            size_t vl = vsetvl_e64m1(remaining_cols); // Set vector length based on remaining columns\n            vfloat64m1_t vec_row = vle64_v_f64m1(row_ptr, vl); // Load row elements\n            vfloat64m1_t vec_squared = vfmul_vv_f64m1(vec_row, vec_row, vl); // Square each element\n            row_norm_squared += vfredsum_vs_f64m1_f64m1(vec_squared, vec_squared, vl).value; // Reduce sum of squares\n            row_ptr += vl;\n            remaining_cols -= vl;\n        }\n\n        double row_norm = sqrt(row_norm_squared); // Compute Euclidean norm\n        result[i] = row_norm > thresholds[i]; // Compare with threshold\n    }\n}\n```"}
{"task_id": "SimdBench_39_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <math.h>\n\nvoid matrix_row_norm_compare_simd(const double* matrix, const double* thresholds, size_t rows, size_t cols, bool* result) {\n    size_t vlmax = vsetvlmax_e64m1(); // Maximum vector length for 64-bit elements\n    for (size_t i = 0; i < rows; i++) {\n        size_t remaining_cols = cols;\n        const double* row_ptr = matrix + i * cols;\n        vfloat64m1_t sum_vec = vfmv_v_f_f64m1(0.0, vlmax); // Initialize sum vector to 0\n\n        while (remaining_cols > 0) {\n            size_t vl = vsetvl_e64m1(remaining_cols); // Set vector length based on remaining columns\n            vfloat64m1_t row_vec = vle64_v_f64m1(row_ptr, vl); // Load row elements\n            vfloat64m1_t squared_vec = vfmul_vv_f64m1(row_vec, row_vec, vl); // Square each element\n            sum_vec = vfadd_vv_f64m1(sum_vec, squared_vec, vl); // Accumulate squared values\n            row_ptr += vl;\n            remaining_cols -= vl;\n        }\n\n        double norm = sqrt(vfredsum_vs_f64m1_f64m1(sum_vec, sum_vec, vlmax)); // Compute Euclidean norm\n        result[i] = norm > thresholds[i]; // Compare norm with threshold\n    }\n}\n```"}
{"task_id": "SimdBench_39_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid matrix_row_norm_compare_simd(const double* matrix, const double* thresholds, size_t rows, size_t cols, bool* result) {\n    size_t vlmax = vsetvlmax_e64m1(); // Maximum vector length for 64-bit elements\n    for (size_t i = 0; i < rows; i++) {\n        size_t remaining = cols;\n        const double* row_ptr = matrix + i * cols;\n        vfloat64m1_t sum_vec = vfmv_v_f_f64m1(0.0, vlmax); // Initialize sum vector to 0\n\n        while (remaining > 0) {\n            size_t vl = vsetvl_e64m1(remaining); // Set vector length based on remaining elements\n            vfloat64m1_t row_vec = vle64_v_f64m1(row_ptr, vl); // Load row elements\n            row_ptr += vl;\n\n            vfloat64m1_t squared_vec = vfmul_vv_f64m1(row_vec, row_vec, vl); // Square each element\n            sum_vec = vfadd_vv_f64m1(sum_vec, squared_vec, vl); // Accumulate squared values\n            remaining -= vl;\n        }\n\n        double norm = vfmv_f_s_f64m1(vfredsum_vs_f64m1_f64m1(sum_vec, sum_vec, vlmax)); // Reduce sum vector to scalar\n        norm = sqrt(norm); // Compute Euclidean norm\n\n        result[i] = norm > thresholds[i]; // Compare norm with threshold\n    }\n}\n```"}
{"task_id": "SimdBench_39_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <math.h>\n\nvoid matrix_row_norm_compare_simd(const double* matrix, const double* thresholds, size_t rows, size_t cols, bool* result) {\n    size_t vlmax = vsetvlmax_e64m1(); // Maximum vector length for 64-bit elements\n    for (size_t i = 0; i < rows; i++) {\n        size_t remaining = cols;\n        size_t offset = i * cols;\n        double row_norm_squared = 0.0;\n\n        while (remaining > 0) {\n            size_t vl = vsetvl_e64m1(remaining); // Set vector length based on remaining elements\n            vfloat64m1_t vec_row = vle64_v_f64m1(&matrix[offset], vl); // Load row elements\n            vfloat64m1_t vec_squared = vfmul_vv_f64m1(vec_row, vec_row, vl); // Square each element\n            row_norm_squared += vfredsum_vs_f64m1_f64m1(vec_squared, vec_squared, vl).val; // Sum squared values\n            offset += vl;\n            remaining -= vl;\n        }\n\n        double row_norm = sqrt(row_norm_squared); // Compute Euclidean norm\n        result[i] = row_norm > thresholds[i]; // Compare with threshold\n    }\n}\n```"}
{"task_id": "SimdBench_39_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <math.h>\n\nvoid matrix_row_norm_compare_simd(const double* matrix, const double* thresholds, size_t rows, size_t cols, bool* result) {\n    size_t vlmax = vsetvlmax_e64m1(); // Maximum vector length for 64-bit elements\n    for (size_t i = 0; i < rows; i++) {\n        size_t remaining = cols;\n        size_t offset = i * cols;\n        double row_sum = 0.0;\n\n        while (remaining > 0) {\n            size_t vl = vsetvl_e64m1(remaining); // Set vector length based on remaining elements\n            vfloat64m1_t row_vec = vle64_v_f64m1(&matrix[offset], vl); // Load row elements\n            vfloat64m1_t squared_vec = vfmul_vv_f64m1(row_vec, row_vec, vl); // Square elements\n            row_sum += vfredsum_vs_f64m1_f64m1(vundefined_f64m1(), squared_vec, vl); // Reduce sum of squared elements\n            offset += vl;\n            remaining -= vl;\n        }\n\n        double norm = sqrt(row_sum); // Compute Euclidean norm\n        result[i] = norm > thresholds[i]; // Compare norm with threshold\n    }\n}\n```"}
{"task_id": "SimdBench_40_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid tensor_bitwise_or_simd(const uint32_t* A, const uint32_t* B, uint32_t* C, size_t length) {\n    size_t vl;\n    while (length > 0) {\n        vl = vsetvl_e32m8(length); // Set vector length for 32-bit elements\n        vuint32m8_t vecA = vle32_v_u32m8(A, vl); // Load vector from A\n        vuint32m8_t vecB = vle32_v_u32m8(B, vl); // Load vector from B\n        vuint32m8_t vecC = vor_vv_u32m8(vecA, vecB, vl); // Perform bitwise OR\n        vse32_v_u32m8(C, vecC, vl); // Store result in C\n        A += vl;\n        B += vl;\n        C += vl;\n        length -= vl;\n    }\n}\n```"}
{"task_id": "SimdBench_40_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid tensor_bitwise_or_simd(const uint32_t* A, const uint32_t* B, uint32_t* C, size_t length) {\n    size_t vl;\n    size_t i = 0;\n\n    while (i < length) {\n        vl = vsetvl_e32m1(length - i); // Set vector length for 32-bit elements\n        vuint32m1_t vecA = vle32_v_u32m1(&A[i], vl); // Load vector from A\n        vuint32m1_t vecB = vle32_v_u32m1(&B[i], vl); // Load vector from B\n        vuint32m1_t vecC = vor_vv_u32m1(vecA, vecB, vl); // Perform bitwise OR\n        vse32_v_u32m1(&C[i], vecC, vl); // Store result in C\n        i += vl; // Increment index by vector length\n    }\n}\n```"}
{"task_id": "SimdBench_40_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid tensor_bitwise_or_simd(const uint32_t* A, const uint32_t* B, uint32_t* C, size_t length) {\n    size_t vl;\n    while (length > 0) {\n        vl = vsetvl_e32m1(length); // Set vector length for 32-bit elements\n        vuint32m1_t vecA = vle32_v_u32m1(A, vl); // Load vector from A\n        vuint32m1_t vecB = vle32_v_u32m1(B, vl); // Load vector from B\n        vuint32m1_t vecC = vor_vv_u32m1(vecA, vecB, vl); // Perform bitwise OR\n        vse32_v_u32m1(C, vecC, vl); // Store result in C\n        A += vl;\n        B += vl;\n        C += vl;\n        length -= vl;\n    }\n}\n```"}
{"task_id": "SimdBench_40_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid tensor_bitwise_or_simd(const uint32_t* A, const uint32_t* B, uint32_t* C, size_t length) {\n    size_t vl;\n    while (length > 0) {\n        vl = vsetvl_e32m8(length); // Set vector length for 32-bit elements\n        vuint32m8_t vecA = vle32_v_u32m8(A, vl); // Load vector from A\n        vuint32m8_t vecB = vle32_v_u32m8(B, vl); // Load vector from B\n        vuint32m8_t vecC = vor_vv_u32m8(vecA, vecB, vl); // Perform bitwise OR\n        vse32_v_u32m8(C, vecC, vl); // Store result in C\n        A += vl;\n        B += vl;\n        C += vl;\n        length -= vl;\n    }\n}\n```"}
{"task_id": "SimdBench_40_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid tensor_bitwise_or_simd(const uint32_t* A, const uint32_t* B, uint32_t* C, size_t length) {\n    size_t vl;\n    size_t offset = 0;\n\n    while (offset < length) {\n        vl = vsetvl_e32m8(length - offset); // Set vector length for 32-bit elements\n        vuint32m8_t va = vle32_v_u32m8(&A[offset], vl); // Load vector from A\n        vuint32m8_t vb = vle32_v_u32m8(&B[offset], vl); // Load vector from B\n        vuint32m8_t vc = vor_vv_u32m8(va, vb, vl); // Perform element-wise bitwise OR\n        vse32_v_u32m8(&C[offset], vc, vl); // Store result in C\n        offset += vl; // Move to the next chunk\n    }\n}\n```"}
{"task_id": "SimdBench_41_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nint64_t squarediff_simd(const int8_t * A, const int8_t * B, size_t length) {\n    size_t vl;\n    int64_t sum_of_squares = 0;\n    int64_t sum_of_products = 0;\n\n    while (length > 0) {\n        vl = vsetvl_e8m1(length);\n\n        vint8m1_t va = vle8_v_i8m1(A, vl);\n        vint8m1_t vb = vle8_v_i8m1(B, vl);\n\n        vint16m2_t va_squared = vmul_vv_i16m2(vsext_vf2_i16m2(va, vl), vsext_vf2_i16m2(va, vl), vl);\n        vint16m2_t vb_squared = vmul_vv_i16m2(vsext_vf2_i16m2(vb, vl), vsext_vf2_i16m2(vb, vl), vl);\n        vint16m2_t vab_product = vmul_vv_i16m2(vsext_vf2_i16m2(va, vl), vsext_vf2_i16m2(vb, vl), vl);\n\n        sum_of_squares += vwmacc_vx_i64m1(vwredsum_vs_i16m2_i64m1(vundefined_i64m1(), va_squared, vl), 1, vwredsum_vs_i16m2_i64m1(vundefined_i64m1(), vb_squared, vl), vl);\n        sum_of_products += vwredsum_vs_i16m2_i64m1(vundefined_i64m1(), vab_product, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_41_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nint64_t squarediff_simd(const int8_t * A, const int8_t * B, size_t length) {\n    size_t vl;\n    int64_t sum_of_squares = 0;\n    int64_t sum_of_products = 0;\n\n    while (length > 0) {\n        vl = vsetvl_e8m1(length);\n\n        vint8m1_t vecA = vle8_v_i8m1(A, vl);\n        vint8m1_t vecB = vle8_v_i8m1(B, vl);\n\n        vint16m2_t vecA_squared = vmul_vv_i16m2(vsext_vf2_i16m2(vecA, vl), vsext_vf2_i16m2(vecA, vl), vl);\n        vint16m2_t vecB_squared = vmul_vv_i16m2(vsext_vf2_i16m2(vecB, vl), vsext_vf2_i16m2(vecB, vl), vl);\n        vint16m2_t vec_product = vmul_vv_i16m2(vsext_vf2_i16m2(vecA, vl), vsext_vf2_i16m2(vecB, vl), vl);\n\n        sum_of_squares += vreduce_sum_i16m2(vecA_squared, vl) + vreduce_sum_i16m2(vecB_squared, vl);\n        sum_of_products += vreduce_sum_i16m2(vec_product, vl);\n\n        A += vl;\n        B += vl;\n        length -= vl;\n    }\n\n    return sum_of_squares - sum_of_products;\n}\n```"}
{"task_id": "SimdBench_41_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nint64_t squarediff_simd(const int8_t * A, const int8_t * B, size_t length) {\n    size_t vl;\n    int64_t sum_of_squares = 0;\n    int64_t sum_of_products = 0;\n\n    while (length > 0) {\n        vl = vsetvl_e8m1(length);\n\n        vint8m1_t vecA = vle8_v_i8m1(A, vl);\n        vint8m1_t vecB = vle8_v_i8m1(B, vl);\n\n        vint16m2_t vecA_squared = vmul_vv_i16m2(vsext_vf2_i16m2(vecA, vl), vsext_vf2_i16m2(vecA, vl), vl);\n        vint16m2_t vecB_squared = vmul_vv_i16m2(vsext_vf2_i16m2(vecB, vl), vsext_vf2_i16m2(vecB, vl), vl);\n        vint16m2_t vecAB_product = vmul_vv_i16m2(vsext_vf2_i16m2(vecA, vl), vsext_vf2_i16m2(vecB, vl), vl);\n\n        sum_of_squares += vwmacc_vx_i64m1(vundefined_i64m1(), 1, vwadd_vv_i32m4(vwadd_vv_i16m2(vecA_squared, vecB_squared, vl), vl), vl);\n        sum_of_products += vwmacc_vx_i64m1(vundefined_i64m1(), 1, vadd_vv_i32m4(vecAB_product, vl), vl);\n        A += vl;\n        B += vl;\n        length -= vl;\n    }\n\n    return sum_of_squares - sum_of_products;\n}\n```"}
{"task_id": "SimdBench_41_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nint64_t squarediff_simd(const int8_t * A, const int8_t * B, size_t length) {\n    size_t vl;\n    int64_t sum_of_squares = 0;\n    int64_t sum_of_products = 0;\n\n    while (length > 0) {\n        vl = vsetvl_e8m1(length);\n\n        vint8m1_t va = vle8_v_i8m1(A, vl);\n        vint8m1_t vb = vle8_v_i8m1(B, vl);\n\n        vint16m2_t va_squared = vmul_vv_i16m2(vsext_vf2_i16m2(va, vl), vsext_vf2_i16m2(va, vl), vl);\n        vint16m2_t vb_squared = vmul_vv_i16m2(vsext_vf2_i16m2(vb, vl), vsext_vf2_i16m2(vb, vl), vl);\n        vint16m2_t vab_product = vmul_vv_i16m2(vsext_vf2_i16m2(va, vl), vsext_vf2_i16m2(vb, vl), vl);\n\n        sum_of_squares += vredsum_vs_i16m2_i64m1(vundefined_i64m1(), va_squared, vl);\n        sum_of_squares += vredsum_vs_i16m2_i64m1(vundefined_i64m1(), vb_squared, vl);\n        sum_of_products += vredsum_vs_i16m2_i64m1(vundefined_i64m1(), vab_product, vl);\n\n        A += vl;\n        B += vl;\n        length -= vl;\n    }\n\n    return sum_of_squares - sum_of_products;\n}\n```"}
{"task_id": "SimdBench_41_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nint64_t squarediff_simd(const int8_t * A, const int8_t * B, size_t length) {\n    size_t vl;\n    int64_t sum_of_squares = 0;\n    int64_t sum_of_products = 0;\n\n    while (length > 0) {\n        vl = vsetvl_e8m1(length);\n\n        vint8m1_t vecA = vle8_v_i8m1(A, vl);\n        vint8m1_t vecB = vle8_v_i8m1(B, vl);\n\n        vint16m2_t squaresA = vmul_vv_i16m2(vsext_vf2_i16m2(vecA, vl), vsext_vf2_i16m2(vecA, vl), vl);\n        vint16m2_t squaresB = vmul_vv_i16m2(vsext_vf2_i16m2(vecB, vl), vsext_vf2_i16m2(vecB, vl), vl);\n        vint16m2_t products = vmul_vv_i16m2(vsext_vf2_i16m2(vecA, vl), vsext_vf2_i16m2(vecB, vl), vl);\n\n        sum_of_squares += vreduce_sum_i16m2(squaresA, vl) + vreduce_sum_i16m2(squaresB, vl);\n        sum_of_products += vreduce_sum_i16m2(products, vl);\n\n        A += vl;\n        B += vl;\n        length -= vl;\n    }\n\n    return sum_of_squares - sum_of_products;\n}\n```"}
{"task_id": "SimdBench_42_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid tensor_bit_clear_simd(const uint64_t* A, const uint64_t* B, uint64_t* C, size_t length) {\n    size_t vl;\n    size_t i = 0;\n\n    while (i < length) {\n        vl = vsetvl_e64m1(length - i); // Set vector length\n        vuint64m1_t va = vle64_v_u64m1(&A[i], vl); // Load vector from A\n        vuint64m1_t vb = vle64_v_u64m1(&B[i], vl); // Load vector from B\n        vuint64m1_t vnot_b = vmnot_v_u64m1(vb, vl); // Compute bitwise NOT of B\n        vuint64m1_t vc = vand_vv_u64m1(va, vnot_b, vl); // Perform bitwise AND\n        vse64_v_u64m1(&C[i], vc, vl); // Store result in C\n        i += vl; // Increment index by vector length\n    }\n}\n```"}
{"task_id": "SimdBench_42_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid tensor_bit_clear_simd(const uint64_t* A, const uint64_t* B, uint64_t* C, size_t length) {\n    size_t vl;\n    size_t offset = 0;\n\n    while (offset < length) {\n        vl = vsetvl_e64m1(length - offset);\n\n        vuint64m1_t va = vle64_v_u64m1(&A[offset], vl);\n        vuint64m1_t vb = vle64_v_u64m1(&B[offset], vl);\n\n        vuint64m1_t vb_not = vmnot_v_u64m1(vb, vl);\n        vuint64m1_t vc = vand_vv_u64m1(va, vb_not, vl);\n\n        vse64_v_u64m1(&C[offset], vc, vl);\n\n        offset += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_42_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid tensor_bit_clear_simd(const uint64_t* A, const uint64_t* B, uint64_t* C, size_t length) {\n    size_t vl;\n    size_t i = 0;\n\n    while (i < length) {\n        vl = vsetvl_e64m1(length - i); // Set the vector length\n        vuint64m1_t va = vle64_v_u64m1(&A[i], vl); // Load vector from A\n        vuint64m1_t vb = vle64_v_u64m1(&B[i], vl); // Load vector from B\n        vuint64m1_t vb_not = vmnot_v_u64m1(vb, vl); // Compute bitwise NOT of B\n        vuint64m1_t vc = vand_vv_u64m1(va, vb_not, vl); // Compute A & ~B\n        vse64_v_u64m1(&C[i], vc, vl); // Store the result in C\n        i += vl; // Increment the index by the vector length\n    }\n}\n```"}
{"task_id": "SimdBench_42_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid tensor_bit_clear_simd(const uint64_t* A, const uint64_t* B, uint64_t* C, size_t length) {\n    size_t vl;\n    size_t i = 0;\n\n    while (i < length) {\n        vl = vsetvl_e64m1(length - i); // Set vector length for 64-bit elements\n        vuint64m1_t va = vle64_v_u64m1(&A[i], vl); // Load vector from A\n        vuint64m1_t vb = vle64_v_u64m1(&B[i], vl); // Load vector from B\n        vuint64m1_t vb_not = vmnot_v_u64m1(vb, vl); // Compute bitwise NOT of B\n        vuint64m1_t vc = vand_vv_u64m1(va, vb_not, vl); // Compute A & ~B\n        vse64_v_u64m1(&C[i], vc, vl); // Store result in C\n        i += vl; // Increment index by vector length\n    }\n}\n```"}
{"task_id": "SimdBench_42_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid tensor_bit_clear_simd(const uint64_t* A, const uint64_t* B, uint64_t* C, size_t length) {\n    size_t vl;\n    size_t offset = 0;\n\n    while (offset < length) {\n        vl = vsetvl_e64m1(length - offset);\n\n        vuint64m1_t va = vle64_v_u64m1(&A[offset], vl);\n        vuint64m1_t vb = vle64_v_u64m1(&B[offset], vl);\n\n        vuint64m1_t vb_not = vmnot_v_u64m1(vb, vl);\n        vuint64m1_t vc = vand_vv_u64m1(va, vb_not, vl);\n\n        vse64_v_u64m1(&C[offset], vc, vl);\n\n        offset += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_43_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid tensor_three_valued_logic_simd(const int8_t* A, const int8_t* B, int8_t* C, size_t length) {\n    size_t vl;\n    size_t offset = 0;\n\n    while (offset < length) {\n        vl = vsetvl_e8m1(length - offset);\n\n        vint8m1_t va = vle8_v_i8m1(&A[offset], vl);\n        vint8m1_t vb = vle8_v_i8m1(&B[offset], vl);\n\n        vbool8_t pos_a = vmgt_vx_i8m1_b8(va, 0, vl); // A > 0\n        vbool8_t pos_b = vmgt_vx_i8m1_b8(vb, 0, vl); // B > 0\n        vbool8_t neg_a = vmslt_vx_i8m1_b8(va, 0, vl); // A < 0\n        vbool8_t neg_b = vmslt_vx_i8m1_b8(vb, 0, vl); // B < 0\n\n        vbool8_t both_positive = vmand_mm_b8(pos_a, pos_b, vl); // A > 0 && B > 0\n        vbool8_t both_negative = vmand_mm_b8(neg_a, neg_b, vl); // A < 0 && B < 0\n\n        vint8m1_t result = vmv_v_x_i8m1(0, vl); // Initialize result to 0\n        result = vmerge_vxm_i8m1(result, 1, both_positive, vl); // Set 1 where both_positive is true\n        result = vmerge_vxm_i8m1(result, -1, both_negative, vl); // Set -1 where both_negative is true\n\n        vse8_v_i8m1(&C[offset], result, vl);\n\n        offset += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_43_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid tensor_three_valued_logic_simd(const int8_t* A, const int8_t* B, int8_t* C, size_t length) {\n    size_t vl;\n    size_t i = 0;\n\n    while (i < length) {\n        vl = vsetvl_e8m1(length - i); // Set vector length for 8-bit integers\n\n        vint8m1_t vecA = vle8_v_i8m1(&A[i], vl); // Load vector from A\n        vint8m1_t vecB = vle8_v_i8m1(&B[i], vl); // Load vector from B\n\n        vbool8_t pos_mask = vmseq_vx_i8m1_b8(vecA, 1, vl) & vmseq_vx_i8m1_b8(vecB, 1, vl); // Both positive\n        vbool8_t neg_mask = vmseq_vx_i8m1_b8(vecA, -1, vl) & vmseq_vx_i8m1_b8(vecB, -1, vl); // Both negative\n\n        vint8m1_t result = vmv_v_x_i8m1(0, vl); // Initialize result vector to 0\n        result = vmerge_vvm_i8m1(result, vmv_v_x_i8m1(1, vl), pos_mask, vl); // Set 1 where both positive\n        result = vmerge_vvm_i8m1(result, vmv_v_x_i8m1(-1, vl), neg_mask, vl); // Set -1 where both negative\n\n        vse8_v_i8m1(&C[i], result, vl); // Store result vector to C\n\n        i += vl; // Increment index by vector length\n    }\n}\n```"}
{"task_id": "SimdBench_43_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid tensor_three_valued_logic_simd(const int8_t* A, const int8_t* B, int8_t* C, size_t length) {\n    size_t vl;\n    size_t i = 0;\n\n    while (i < length) {\n        vl = vsetvl_e8m1(length - i); // Set vector length for 8-bit integers\n        vint8m1_t va = vle8_v_i8m1(&A[i], vl); // Load vector from A\n        vint8m1_t vb = vle8_v_i8m1(&B[i], vl); // Load vector from B\n\n        vbool8_t pos_mask = vmul_vv_i8m1(va, vb, vl) > 0; // Mask for positive product\n        vbool8_t neg_mask = vmul_vv_i8m1(va, vb, vl) < 0; // Mask for negative product\n\n        vint8m1_t vc_pos = vmv_v_x_i8m1(1, vl); // Vector with all elements set to 1\n        vint8m1_t vc_neg = vmv_v_x_i8m1(-1, vl); // Vector with all elements set to -1\n        vint8m1_t vc_zero = vmv_v_x_i8m1(0, vl); // Vector with all elements set to 0\n\n        vint8m1_t vc = vmv_v_x_i8m1(0, vl); // Initialize result vector\n        vc = vmerge_vvm_i8m1(vc, vc_pos, pos_mask, vl); // Apply positive mask\n        vc = vmerge_vvm_i8m1(vc, vc_neg, neg_mask, vl); // Apply negative mask\n\n        vse8_v_i8m1(&C[i], vc, vl); // Store result vector to C\n        i += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_43_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid tensor_three_valued_logic_simd(const int8_t* A, const int8_t* B, int8_t* C, size_t length) {\n    size_t vl;\n    size_t i = 0;\n\n    while (i < length) {\n        vl = vsetvl_e8m1(length - i); // Set vector length for 8-bit elements\n\n        vint8m1_t vecA = vle8_v_i8m1(&A[i], vl); // Load vector from A\n        vint8m1_t vecB = vle8_v_i8m1(&B[i], vl); // Load vector from B\n\n        vbool8_t pos_mask = vmul_vx_i8m1_b8(vecA, vecB, vl); // Element-wise multiplication\n        vbool8_t neg_mask = vmul_vx_i8m1_b8(vecA, vecB, vl); // Element-wise multiplication\n\n        vint8m1_t result = vmerge_vx_i8m1_b8(pos_mask, neg_mask, vl); // Merge results\n\n        vse8_v_i8m1(&C[i], result, vl); // Store result to C\n\n        i += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_43_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid tensor_three_valued_logic_simd(const int8_t* A, const int8_t* B, int8_t* C, size_t length) {\n    size_t vl;\n    size_t i = 0;\n\n    while (i < length) {\n        vl = vsetvl_e8m1(length - i); // Set vector length for 8-bit integers\n\n        vint8m1_t vecA = vle8_v_i8m1(A + i, vl); // Load vector from A\n        vint8m1_t vecB = vle8_v_i8m1(B + i, vl); // Load vector from B\n\n        vbool8_t pos_mask = vmul_vv_i8m1(vecA, vecB, vl) > 0; // Check both positive\n        vbool8_t neg_mask = vmul_vv_i8m1(vecA, vecB, vl) < 0; // Check both negative\n\n        vint8m1_t result = vmv_v_x_i8m1(0, vl); // Initialize result vector with 0\n        result = vmerge_vvm_i8m1(result, 1, pos_mask, vl); // Set 1 where both positive\n        result = vmerge_vvm_i8m1(result, -1, neg_mask, vl); // Set -1 where both negative\n\n        vse8_v_i8m1(C + i, result, vl); // Store result vector to C\n        i += vl; // Increment index by vector length\n    }\n}\n```"}
{"task_id": "SimdBench_44_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid tensor_bit_op_simd(const uint16_t* A, const uint16_t* B, uint16_t* C, size_t length) {\n    size_t midpoint = length / 2;\n    size_t vl;\n    size_t i = 0;\n\n    while (i < length) {\n        vl = vsetvl_e16m1(length - i); // Set vector length for 16-bit elements\n\n        if (i + vl <= midpoint) {\n            // Process elements before the midpoint with XOR operation\n            vuint16m1_t vecA = vle16_v_u16m1(&A[i], vl);\n            vuint16m1_t vecB = vle16_v_u16m1(&B[i], vl);\n            vuint16m1_t vecC = vxor_vv_u16m1(vecA, vecB, vl);\n            vse16_v_u16m1(&C[i], vecC, vl);\n        } else if (i >= midpoint) {\n            // Process elements after the midpoint with AND operation\n            vuint16m1_t vecA = vle16_v_u16m1(&A[i], vl);\n            vuint16m1_t vecB = vle16_v_u16m1(&B[i], vl);\n            vuint16m1_t vecC = vand_vv_u16m1(vecA, vecB, vl);\n            vse16_v_u16m1(&C[i], vecC, vl);\n        } else {\n            // Handle the midpoint element\n            size_t remaining = midpoint - i;\n            vl = vsetvl_e16m1(remaining);\n            vuint16m1_t vecA = vle16_v_u16m1(&A[i], vl);\n            vuint16m1_t vecB = vle16_v_u16m1(&B[i], vl);\n            vuint16m1_t vecC = vxor_vv_u16m1(vecA, vecB, vl);\n            vse16_v_u16m1(&C[i], vecC, vl);\n            i += vl;\n\n            // Process the midpoint element\n            C[midpoint] = A[midpoint];\n            i++;\n            vl = vsetvl_e16m1(length - i);\n            vecA = vle16_v_u16m1(&A[i], vl);\n            vecB = vle16_v_u16m1(&B[i], vl);\n            vecC = vand_vv_u16m1(vecA, vecB, vl);\n            vse16_v_u16m1(&C[i], vecC, vl);\n            break;\n        }\n\n        i += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_44_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid tensor_bit_op_simd(const uint16_t* A, const uint16_t* B, uint16_t* C, size_t length) {\n    size_t vl;\n    size_t midpoint = length / 2;\n\n    size_t i = 0;\n    while (i < length) {\n        vl = vsetvl_e16m1(length - i); // Set vector length for 16-bit elements\n\n        vuint16m1_t vecA = vle16_v_u16m1(&A[i], vl); // Load A vector\n        vuint16m1_t vecB = vle16_v_u16m1(&B[i], vl); // Load B vector\n\n        vuint16m1_t vecC;\n\n        if (i + vl <= midpoint) {\n            // Before midpoint: XOR operation\n            vecC = vxor_vv_u16m1(vecA, vecB, vl);\n        } else if (i >= midpoint) {\n            // After midpoint: AND operation\n            vecC = vand_vv_u16m1(vecA, vecB, vl);\n        } else {\n            // Mixed case: handle elements across midpoint\n            size_t split = midpoint - i;\n\n            vuint16m1_t vecC1 = vxor_vv_u16m1(vecA, vecB, split);\n            vuint16m1_t vecC2 = vand_vv_u16m1(vecA, vecB, vl - split);\n\n            vse16_v_u16m1(&C[i], vecC1, split);\n            vse16_v_u16m1(&C[i + split], vecC2, vl - split);\n            i += vl;\n            continue;\n        }\n\n        vse16_v_u16m1(&C[i], vecC, vl); // Store result in C\n        i += vl;\n    }\n\n    // Handle the exact midpoint element\n    if (length % 2 == 1) {\n        C[midpoint] = A[midpoint];\n    }\n}\n```"}
{"task_id": "SimdBench_44_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid tensor_bit_op_simd(const uint16_t* A, const uint16_t* B, uint16_t* C, size_t length) {\n    size_t midpoint = length / 2;\n    size_t vl;\n    size_t i = 0;\n\n    while (i < length) {\n        vl = vsetvl_e16m1(length - i);\n\n        vuint16m1_t va = vle16_v_u16m1(&A[i], vl);\n        vuint16m1_t vb = vle16_v_u16m1(&B[i], vl);\n        vuint16m1_t vc;\n\n        if (i + vl <= midpoint) {\n            // Before the midpoint: bitwise XOR\n            vc = vxor_vv_u16m1(va, vb, vl);\n        } else if (i >= midpoint) {\n            // After the midpoint: bitwise AND\n            vc = vand_vv_u16m1(va, vb, vl);\n        } else {\n            // Spanning the midpoint\n            size_t before_mid = midpoint - i;\n            size_t after_mid = vl - before_mid;\n\n            vuint16m1_t vc_before = vxor_vv_u16m1(va, vb, before_mid);\n            vuint16m1_t vc_after = vand_vv_u16m1(va, vb, after_mid);\n\n            vse16_v_u16m1(&C[i], vc_before, before_mid);\n            vse16_v_u16m1(&C[i + before_mid], vc_after, after_mid);\n            i += vl;\n            continue;\n        }\n\n        vse16_v_u16m1(&C[i], vc, vl);\n        i += vl;\n    }\n\n    // Handle the exact midpoint element\n    if (length % 2 != 0) {\n        C[midpoint] = A[midpoint];\n    }\n}\n```"}
{"task_id": "SimdBench_44_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid tensor_bit_op_simd(const uint16_t* A, const uint16_t* B, uint16_t* C, size_t length) {\n    size_t vl;\n    size_t midpoint = length / 2;\n\n    size_t i = 0;\n    while (i < length) {\n        vl = vsetvl_e16m1(length - i);\n\n        vuint16m1_t vecA = vle16_v_u16m1(A + i, vl);\n        vuint16m1_t vecB = vle16_v_u16m1(B + i, vl);\n\n        if (i + vl <= midpoint) {\n            vuint16m1_t vecResult = vxor_vv_u16m1(vecA, vecB, vl);\n            vse16_v_u16m1(C + i, vecResult, vl);\n        } else if (i >= midpoint) {\n            vuint16m1_t vecResult = vand_vv_u16m1(vecA, vecB, vl);\n            vse16_v_u16m1(C + i, vecResult, vl);\n        } else {\n            size_t remaining = midpoint - i;\n            size_t vl_mid = vsetvl_e16m1(remaining);\n\n            vuint16m1_t vecResultXOR = vxor_vv_u16m1(vecA, vecB, vl_mid);\n            vse16_v_u16m1(C + i, vecResultXOR, vl_mid);\n\n            i += vl_mid;\n            vl = vsetvl_e16m1(length - i);\n\n            vecA = vle16_v_u16m1(A + i, vl);\n            vecB = vle16_v_u16m1(B + i, vl);\n\n            vuint16m1_t vecResultAND = vand_vv_u16m1(vecA, vecB, vl);\n            vse16_v_u16m1(C + i, vecResultAND, vl);\n        }\n\n        i += vl;\n    }\n\n    if (length % 2 != 0) {\n        C[midpoint] = A[midpoint];\n    }\n}\n```"}
{"task_id": "SimdBench_44_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid tensor_bit_op_simd(const uint16_t* A, const uint16_t* B, uint16_t* C, size_t length) {\n    size_t vl;\n    size_t midpoint = length / 2;\n\n    for (size_t i = 0; i < length;) {\n        vl = vsetvl_e16m1(length - i);\n\n        vuint16m1_t vecA = vle16_v_u16m1(&A[i], vl);\n        vuint16m1_t vecB = vle16_v_u16m1(&B[i], vl);\n        vuint16m1_t vecC;\n\n        if (i + vl <= midpoint) {\n            vecC = vxor_vv_u16m1(vecA, vecB, vl);\n        } else if (i >= midpoint) {\n            vecC = vand_vv_u16m1(vecA, vecB, vl);\n        } else {\n            size_t split = midpoint - i;\n            vuint16m1_t vecC_xor = vxor_vv_u16m1(vecA, vecB, split);\n            vuint16m1_t vecC_and = vand_vv_u16m1(vslide1down_vx_u16m1(vecA, vecA[split], split), vecB, vl);\n            vse16_v_u16m1(&C[i], vecC_xor, split);\n            i+=split;\n        }\n        }\n}\n```"}
{"task_id": "SimdBench_45_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid tensor_multi_select_simd(const float* A, const float* B, const float* C, const float* D, const bool* cond1, const bool* cond2, float* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t vl;\n    size_t i = 0;\n\n    while (i < total_elements) {\n        vl = vsetvl_e32m1(total_elements - i);\n\n        vbool32_t vcond1 = vle8_v_b32(cond1 + i, vl);\n        vbool32_t vcond2 = vle8_v_b32(cond2 + i, vl);\n\n        vfloat32m1_t vA = vle32_v_f32m1(A + i, vl);\n        vfloat32m1_t vB = vle32_v_f32m1(B + i, vl);\n        vfloat32m1_t vC = vle32_v_f32m1(C + i, vl);\n        vfloat32m1_t vD = vle32_v_f32m1(D + i, vl);\n\n        vfloat32m1_t vout = vmerge_vvm_f32m1(vcond1 & vcond2, vA, vmerge_vvm_f32m1(vcond1, vB, vmerge_vvm_f32m1(vcond2, vC, vD, vl), vl), vl);\n\n        vse32_v_f32m1(out + i, vout, vl);\n\n        i += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_45_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid tensor_multi_select_simd(const float* A, const float* B, const float* C, const float* D, const bool* cond1, const bool* cond2, float* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t vl;\n    size_t i = 0;\n\n    while (i < total_elements) {\n        vl = vsetvl_e32m1(total_elements - i);\n\n        vbool32_t vcond1 = vle8_v_b32m1((const uint8_t*)&cond1[i], vl);\n        vbool32_t vcond2 = vle8_v_b32m1((const uint8_t*)&cond2[i], vl);\n\n        vfloat32m1_t vA = vle32_v_f32m1(&A[i], vl);\n        vfloat32m1_t vB = vle32_v_f32m1(&B[i], vl);\n        vfloat32m1_t vC = vle32_v_f32m1(&C[i], vl);\n        vfloat32m1_t vD = vle32_v_f32m1(&D[i], vl);\n\n        vfloat32m1_t vout = vmerge_vvm_f32m1(vcond1, vmerge_vvm_f32m1(vcond2, vA, vC, vl), vmerge_vvm_f32m1(vcond2, vB, vD, vl), vl);\n\n        vse32_v_f32m1(&out[i], vout, vl);\n\n        i += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_45_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid tensor_multi_select_simd(const float* A, const float* B, const float* C, const float* D, const bool* cond1, const bool* cond2, float* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t vl;\n    size_t i = 0;\n\n    while (i < total_elements) {\n        vl = vsetvl_e32m1(total_elements - i);\n\n        vbool32_t vcond1 = vle8_v_b32m1((const uint8_t*)(cond1 + i), vl);\n        vbool32_t vcond2 = vle8_v_b32m1((const uint8_t*)(cond2 + i), vl);\n\n        vfloat32m1_t vA = vle32_v_f32m1(A + i, vl);\n        vfloat32m1_t vB = vle32_v_f32m1(B + i, vl);\n        vfloat32m1_t vC = vle32_v_f32m1(C + i, vl);\n        vfloat32m1_t vD = vle32_v_f32m1(D + i, vl);\n\n        vfloat32m1_t vout = vmerge_vvm_f32m1(vcond1 & vcond2, vA, vD, vl);\n        vout = vmerge_vvm_f32m1(vcond1 & ~vcond2, vB, vout, vl);\n        vout = vmerge_vvm_f32m1(~vcond1 & vcond2, vC, vout, vl);\n\n        vse32_v_f32m1(out + i, vout, vl);\n\n        i += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_45_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid tensor_multi_select_simd(const float* A, const float* B, const float* C, const float* D, const bool* cond1, const bool* cond2, float* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t vl;\n    size_t i = 0;\n\n    while (i < total_elements) {\n        vl = vsetvl_e32m1(total_elements - i);\n\n        vfloat32m1_t vecA = vle32_v_f32m1(&A[i], vl);\n        vfloat32m1_t vecB = vle32_v_f32m1(&B[i], vl);\n        vfloat32m1_t vecC = vle32_v_f32m1(&C[i], vl);\n        vfloat32m1_t vecD = vle32_v_f32m1(&D[i], vl);\n\n        vbool8_t vecCond1 = vle8_v_b8(&cond1[i], vl);\n        vbool8_t vecCond2 = vle8_v_b8(&cond2[i], vl);\n\n        vfloat32m1_t result = vmerge_vvm_f32m1(vecCond1, vecA, vecB, vl);\n        result = vmerge_vvm_f32m1(vecCond2, result, vmerge_vvm_f32m1(vecCond1, vecC, vecD, vl), vl);\n\n        vse32_v_f32m1(&out[i], result, vl);\n\n        i += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_45_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid tensor_multi_select_simd(const float* A, const float* B, const float* C, const float* D, const bool* cond1, const bool* cond2, float* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t vl;\n    size_t i = 0;\n\n    while (i < total_elements) {\n        vl = vsetvl_e32m1(total_elements - i);\n\n        vfloat32m1_t vecA = vle32_v_f32m1(&A[i], vl);\n        vfloat32m1_t vecB = vle32_v_f32m1(&B[i], vl);\n        vfloat32m1_t vecC = vle32_v_f32m1(&C[i], vl);\n        vfloat32m1_t vecD = vle32_v_f32m1(&D[i], vl);\n\n        vbool8_t vecCond1 = vle8_v_b8(&cond1[i], vl);\n        vbool8_t vecCond2 = vle8_v_b8(&cond2[i], vl);\n\n        vfloat32m1_t result = vmerge_vvm_f32m1(vecCond1, vecA, vecB, vl);\n        result = vmerge_vvm_f32m1(vecCond2, result, vecC, vl);\n        result = vmerge_vvm_f32m1(vnot_v_b8(vecCond1, vl), result, vecD, vl);\n\n        vse32_v_f32m1(&out[i], result, vl);\n\n        i += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_46_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid tensor_bit_count_simd(const uint32_t* A, uint8_t* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t vl;\n    size_t i = 0;\n\n    while (i < total_elements) {\n        // Determine the vector length for this iteration\n        vl = vsetvl_e32m1(total_elements - i);\n\n        // Load a vector of 32-bit integers from A\n        vuint32m1_t vecA = vle32_v_u32m1(&A[i], vl);\n\n        // Initialize a vector to store the bit counts\n        vuint8m1_t vecCount = vmv_v_x_u8m1(0, vl);\n\n        // Count the number of bits set to 1 in each element\n        for (int bit = 0; bit < 32; bit++) {\n            // Extract the current bit and accumulate the count\n            vuint32m1_t bitMask = vmv_v_x_u32m1(1 << bit, vl);\n            vuint32m1_t bitSet = vand_vv_u32m1(vecA, bitMask, vl);\n            vuint8m1_t bitCount = vnsra_wx_u8m1(vreinterpret_u8m1_u32m1(bitSet), bit, vl);\n            vecCount = vadd_vv_u8m1(vecCount, bitCount, vl);\n        }\n\n        // Store the result in the output array\n        vse8_v_u8m1(&out[i], vecCount, vl);\n\n        // Move to the next chunk of elements\n        i += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_46_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid tensor_bit_count_simd(const uint32_t* A, uint8_t* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t vl;\n    size_t index = 0;\n\n    while (index < total_elements) {\n        vl = vsetvl_e32m1(total_elements - index); // Set vector length for 32-bit elements\n        vuint32m1_t vecA = vle32_v_u32m1(&A[index], vl); // Load 32-bit elements from A\n        vuint32m1_t bit_counts = vmv_v_x_u32m1(0, vl); // Initialize bit count vector to 0\n\n        for (int i = 0; i < 32; i++) {\n            vuint32m1_t shifted = vsrl_vx_u32m1(vecA, i, vl); // Shift right by i\n            vuint32m1_t masked = vand_vx_u32m1(shifted, 1, vl); // Mask the least significant bit\n            bit_counts = vadd_vv_u32m1(bit_counts, masked, vl); // Accumulate bit counts\n        }\n\n        vse8_v_u8m1(&out[index], vncvt_xu_x_w_u8m1(bit_counts, vl), vl); // Narrow and store results in out\n        index += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_46_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid tensor_bit_count_simd(const uint32_t* A, uint8_t* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t vl;\n    size_t i = 0;\n\n    while (i < total_elements) {\n        vl = vsetvl_e32m1(total_elements - i); // Set vector length for 32-bit elements\n        vuint32m1_t vecA = vle32_v_u32m1(&A[i], vl); // Load 32-bit elements from A\n        vuint32m1_t bit_counts = vmv_v_x_u32m1(0, vl); // Initialize bit count vector to 0\n\n        // Count bits set to 1 using popcount intrinsic\n        bit_counts = vpopc_m_u32m1(bit_counts, vecA, vl);\n\n        // Narrow down the 32-bit results to 8-bit and store in out\n        vuint8m1_t vecOut = vnclipu_wx_u8m1(bit_counts, 0, vl);\n        vse8_v_u8m1(&out[i], vecOut, vl); // Store results in out\n\n        i += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_46_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid tensor_bit_count_simd(const uint32_t* A, uint8_t* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t vl;\n    size_t index = 0;\n\n    while (index < total_elements) {\n        vl = vsetvl_e32m1(total_elements - index); // Set vector length for 32-bit elements\n        vuint32m1_t vecA = vle32_v_u32m1(&A[index], vl); // Load 32-bit elements from A\n        vuint32m1_t bit_count = vmv_v_x_u32m1(0, vl); // Initialize bit count vector to zero\n\n        for (int i = 0; i < 32; i++) {\n            vuint32m1_t mask = vslide1down_vx_u32m1(vecA, 1, vl); // Shift bits\n            bit_count = vadd_vv_u32m1(bit_count, vand_vx_u32m1(vecA, 1, vl), vl); // Count set bits\n            vecA = vsrl_vx_u32m1(vecA, 1, vl); // Logical right shift\n        }\n\n        vuint8m1_t vecOut = vncvt_xu32_u8m1(bit_count, vl); // Narrow down to 8-bit unsigned integers\n        vse8_v_u8m1(&out[index], vecOut, vl); // Store results in out\n        index += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_46_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid tensor_bit_count_simd(const uint32_t* A, uint8_t* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t vl;\n    size_t i = 0;\n\n    while (i < total_elements) {\n        vl = vsetvl_e32m1(total_elements - i); // Set vector length for 32-bit elements\n        vuint32m1_t vecA = vle32_v_u32m1(&A[i], vl); // Load 32-bit elements from A\n        vuint32m1_t bit_counts = vmv_v_x_u32m1(0, vl); // Initialize bit count vector to 0\n\n        // Count bits set to 1 using a loop\n        for (int shift = 0; shift < 32; shift++) {\n            vuint32m1_t mask = vand_vx_u32m1(vecA, 1, vl); // Extract the least significant bit\n            bit_counts = vadd_vx_u32m1(bit_counts, mask, vl); // Accumulate the bit count\n            vecA = vsrl_vx_u32m1(vecA, 1, vl); // Right shift by 1\n        }\n\n        // Narrow the 32-bit bit counts to 8-bit and store in the output tensor\n        vuint8m1_t vecOut = vnclipu_wx_u8m1(bit_counts, 0, vl);\n        vse8_v_u8m1(&out[i], vecOut, vl);\n\n        i += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_47_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid matrix_conditional_abs_simd(const int* A, int* B, size_t rows, size_t cols) {\n    size_t total_elements = rows * cols;\n    size_t vl;\n    size_t i = 0;\n\n    while (i < total_elements) {\n        vl = vsetvl_e32m1(total_elements - i); // Set vector length based on remaining elements\n        vint32m1_t vecA = vle32_v_i32m1(&A[i], vl); // Load elements from A\n        vint32m1_t mod_result = vmul_vx_i32m1(vecA, 0, vl); // Compute A % 3\n        vint32m1_t abs_result = vabs_v_i32m1(vecA, vl); // Compute absolute value of A\n        vint32m1_t condition = vmseq_vx_i32m1(mod_result, 0, vl); // Check if A % 3 == 0\n        vint32m1_t vecB = vmerge_vvm_i32m1(condition, abs_result, vecA, vl); // Merge based on condition\n        vse32_v_i32m1(&B[i], vecB, vl); // Store result in B\n        i += vl; // Move to the next chunk\n    }\n}\n```"}
{"task_id": "SimdBench_47_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid matrix_conditional_abs_simd(const int* A, int* B, size_t rows, size_t cols) {\n    size_t total_elements = rows * cols;\n    size_t vl;\n    size_t index = 0;\n\n    while (index < total_elements) {\n        vl = vsetvl_e32m8(total_elements - index); // Set vector length for 32-bit integers\n        vint32m8_t vecA = vle32_v_i32m8(&A[index], vl); // Load elements from A\n        vint32m8_t absA = vabs_v_i32m8(vecA, vl); // Compute absolute values of A\n        vint32m8_t mod3 = vrem_vx_i32m8(vecA, 3, vl); // Compute A % 3\n        vbool4_t condition = vmseq_vx_i32m8_b4(mod3, 0, vl); // Check if A % 3 == 0\n        vint32m8_t result = vmerge_vvm_i32m8(condition, absA, vecA, vl); // Select absA if condition is true, else vecA\n        vse32_v_i32m8(&B[index], result, vl); // Store the result in B\n        index += vl; // Move to the next chunk of elements\n    }\n}\n```"}
{"task_id": "SimdBench_47_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid matrix_conditional_abs_simd(const int* A, int* B, size_t rows, size_t cols) {\n    size_t total_elements = rows * cols;\n    size_t vl;\n    size_t i = 0;\n\n    while (i < total_elements) {\n        vl = vsetvl_e32m1(total_elements - i); // Set vector length for 32-bit integers\n        vint32m1_t vecA = vle32_v_i32m1(&A[i], vl); // Load elements from A\n        vint32m1_t vecAbsA = vabs_v_i32m1(vecA, vl); // Compute absolute values of A\n        vint32m1_t vecMod3 = vrem_vx_i32m1(vecA, 3, vl); // Compute A % 3\n        vbool32_t mask = vmseq_vx_i32m1_b32(vecMod3, 0, vl); // Check if A % 3 == 0\n        vint32m1_t vecResult = vmerge_vvm_i32m1(mask, vecAbsA, vecA, vl); // Select based on condition\n        vse32_v_i32m1(&B[i], vecResult, vl); // Store result in B\n        i += vl; // Increment index by vector length\n    }\n}\n```"}
{"task_id": "SimdBench_47_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid matrix_conditional_abs_simd(const int* A, int* B, size_t rows, size_t cols) {\n    size_t total_elements = rows * cols;\n    size_t vl;\n    size_t i = 0;\n\n    while (i < total_elements) {\n        vl = vsetvl_e32m1(total_elements - i); // Set vector length for 32-bit integers\n        vint32m1_t vecA = vle32_v_i32m1(&A[i], vl); // Load elements from A\n        vint32m1_t mod3 = vmul_vx_i32m1(vecA, 0, vl); // Calculate A % 3\n        vint32m1_t absA = vabs_v_i32m1(vecA, vl); // Calculate absolute value of A\n        vint32m1_t result = vmerge_vvm_i32m1(absA, vecA, mod3, vl); // Apply condition\n        vse32_v_i32m1(&B[i], result, vl); // Store result in B\n        i += vl; // Increment index by vector length\n    }\n}\n```"}
{"task_id": "SimdBench_47_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid matrix_conditional_abs_simd(const int* A, int* B, size_t rows, size_t cols) {\n    size_t total_elements = rows * cols;\n    size_t vl;\n    size_t i = 0;\n\n    while (i < total_elements) {\n        vl = vsetvl_e32m1(total_elements - i); // Set vector length for 32-bit integers\n        vint32m1_t vecA = vle32_v_i32m1(&A[i], vl); // Load elements from A\n        vint32m1_t mod_result = vmul_vx_i32m1(vecA, 0, vl); // Compute A % 3\n        vint32m1_t absA = vabs_v_i32m1(vecA, vl); // Compute absolute value of A\n        vbool32_t condition = vmseq_vx_i32m1_b32(mod_result, 0, vl); // Check if A % 3 == 0\n        vint32m1_t result = vmerge_vvm_i32m1(condition, absA, vecA, vl); // Apply condition\n        vse32_v_i32m1(&B[i], result, vl); // Store result in B\n        i += vl; // Increment index by vector length\n    }\n}\n```"}
{"task_id": "SimdBench_48_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid matrix_conditional_bit_rotate_simd(const uint32_t* src, uint32_t* dst, uint8_t rotate_bits, size_t length) {\n    size_t vl;\n    size_t offset = 0;\n\n    while (offset < length) {\n        vl = vsetvl_e32m1(length - offset);\n\n        // Load the source vector\n        vuint32m1_t src_vec = vle32_v_u32m1(&src[offset], vl);\n\n        // Check the condition: low 4 bits of src are all 1\n        vuint32m1_t mask_vec = vand_vx_u32m1(src_vec, 0xF, vl); // Extract low 4 bits\n        vbool32_t condition = vmseq_vx_u32m1_b32(mask_vec, 0xF, vl); // Compare to 0xF\n\n        // Perform bitwise rotation\n        vuint32m1_t rotated_vec = vsrl_vx_u32m1(src_vec, rotate_bits, vl); // Logical right shift\n        rotated_vec = vor_vv_u32m1(rotated_vec, vsll_vx_u32m1(src_vec, 32 - rotate_bits, vl), vl); // Combine with left shift\n\n        // Perform bitwise negation\n        vuint32m1_t negated_vec = vmvn_v_u32m1(src_vec, vl);\n\n        // Select based on condition\n        vuint32m1_t result_vec = vmerge_vvm_u32m1(condition, rotated_vec, negated_vec, vl);\n\n        // Store the result in the destination vector\n        vse32_v_u32m1(&dst[offset], result_vec, vl);\n\n        offset += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_48_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid matrix_conditional_bit_rotate_simd(const uint32_t* src, uint32_t* dst, uint8_t rotate_bits, size_t length) {\n    size_t vl;\n    while (length > 0) {\n        vl = vsetvl_e32m1(length); // Set vector length for 32-bit elements\n        vuint32m1_t v_src = vle32_v_u32m1(src, vl); // Load src vector\n        vuint32m1_t v_low_bits = vand_vx_u32m1(v_src, 0xF, vl); // Extract low 4 bits\n        vbool32_t v_condition = vmseq_vx_u32m1_b32(v_low_bits, 0xF, vl); // Check if low 4 bits are all 1\n\n        vuint32m1_t v_rotated = vsrl_vx_u32m1(v_src, rotate_bits, vl) | vsll_vx_u32m1(v_src, 32 - rotate_bits, vl); // Rotate bits\n        vuint32m1_t v_negated = vmnot_v_u32m1(v_src, vl); // Bitwise negation\n\n        vuint32m1_t v_result = vmerge_vvm_u32m1(v_condition, v_rotated, v_negated, vl); // Conditional merge\n        vse32_v_u32m1(dst, v_result, vl); // Store result to dst\n\n        src += vl;\n        dst += vl;\n        length -= vl;\n    }\n}\n```"}
{"task_id": "SimdBench_48_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid matrix_conditional_bit_rotate_simd(const uint32_t* src, uint32_t* dst, uint8_t rotate_bits, size_t length) {\n    size_t vl;\n    size_t i = 0;\n\n    while (i < length) {\n        vl = vsetvl_e32m1(length - i); // Set vector length for 32-bit elements\n        vuint32m1_t vec_src = vle32_v_u32m1(&src[i], vl); // Load src vector\n        vuint32m1_t low_bits_mask = vmv_v_x_u32m1(0xF, vl); // Mask for low 4 bits\n        vuint32m1_t low_bits = vand_vv_u32m1(vec_src, low_bits_mask, vl); // Extract low 4 bits\n        vuint32m1_t rotate_result = vrotate_vx_u32m1(vec_src, rotate_bits, vl); // Rotate src by rotate_bits\n        vuint32m1_t neg_result = vnot_v_u32m1(vec_src, vl); // Bitwise negation of src\n\n        vbool32_t condition = vmseq_vx_u32m1_b32(low_bits, 0xF, vl); // Check if low 4 bits are all 1\n        vuint32m1_t vec_dst = vmerge_vvm_u32m1(condition, rotate_result, neg_result, vl); // Conditional merge\n\n        vse32_v_u32m1(&dst[i], vec_dst, vl); // Store result to dst\n        i += vl; // Increment index by vector length\n    }\n}\n```"}
{"task_id": "SimdBench_48_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid matrix_conditional_bit_rotate_simd(const uint32_t* src, uint32_t* dst, uint8_t rotate_bits, size_t length) {\n    size_t vl;\n    size_t i = 0;\n\n    while (i < length) {\n        vl = vsetvl_e32m1(length - i); // Set vector length for 32-bit elements\n        vuint32m1_t src_vec = vle32_v_u32m1(&src[i], vl); // Load src vector\n        vuint32m1_t low_bits_mask = vmv_v_x_u32m1(0xF, vl); // Mask for low 4 bits\n        vuint32m1_t low_bits = vand_vv_u32m1(src_vec, low_bits_mask, vl); // Extract low 4 bits\n\n        vbool32_t condition = vmseq_vx_u32m1_b32(low_bits, 0xF, vl); // Check if low 4 bits are all 1\n        vuint32m1_t rotated = vror_vx_u32m1(src_vec, rotate_bits, vl); // Rotate src elements by rotate_bits\n        vuint32m1_t negated = vmnot_v_u32m1(src_vec, vl); // Bitwise negation of src elements\n\n        vuint32m1_t result = vmerge_vvm_u32m1(condition, rotated, negated, vl); // Select based on condition\n        vse32_v_u32m1(&dst[i], result, vl); // Store result in dst vector\n\n        i += vl; // Increment index by vector length\n    }\n}\n```"}
{"task_id": "SimdBench_48_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid matrix_conditional_bit_rotate_simd(const uint32_t* src, uint32_t* dst, uint8_t rotate_bits, size_t length) {\n    size_t vl;\n    size_t processed = 0;\n\n    while (processed < length) {\n        vl = vsetvl_e32m1(length - processed);\n\n        // Load the source vector\n        vuint32m1_t src_vec = vle32_v_u32m1(src + processed, vl);\n\n        // Extract the low 4 bits of each element\n        vuint32m1_t low_4_bits = vand_vx_u32m1(src_vec, 0xF, vl);\n\n        // Create a mask where the condition (low 4 bits == 0xF) is true\n        vbool32_t condition_mask = vmseq_vx_u32m1_b32(low_4_bits, 0xF, vl);\n\n        // Perform bitwise rotation for elements where the condition is true\n        vuint32m1_t rotated_vec = vsrl_vx_u32m1(src_vec, rotate_bits, vl);\n        rotated_vec = vor_vv_u32m1(rotated_vec, vsll_vx_u32m1(src_vec, 32 - rotate_bits, vl), vl);\n\n        // Perform bitwise negation for elements where the condition is false\n        vuint32m1_t negated_vec = vmnot_v_u32m1(src_vec, vl);\n\n        // Merge the results based on the condition mask\n        vuint32m1_t result_vec = vmerge_vvm_u32m1(condition_mask, rotated_vec, negated_vec, vl);\n\n        // Store the result in the destination vector\n        vse32_v_u32m1(dst + processed, result_vec, vl);\n\n        processed += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_49_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <math.h>\n\nvoid tensor_ternary_compare_simd(const float* A, const float* B, int8_t* out, float epsilon, size_t length) {\n    size_t vl;\n    vfloat32m1_t v_epsilon = vfmv_v_f_f32m1(epsilon, vsetvlmax_e32m1());\n    vfloat32m1_t v_neg_epsilon = vfmv_v_f_f32m1(-epsilon, vsetvlmax_e32m1());\n\n    while (length > 0) {\n        vl = vsetvl_e32m1(length);\n\n        vfloat32m1_t vA = vle32_v_f32m1(A, vl);\n        vfloat32m1_t vB = vle32_v_f32m1(B, vl);\n\n        vfloat32m1_t v_diff = vfsub_vv_f32m1(vA, vB, vl);\n        vfloat32m1_t v_abs_diff = vfabs_v_f32m1(v_diff, vl);\n\n        vbool32_t mask_gt = vmfgt_vf_f32m1_b32(v_diff, epsilon, vl);\n        vbool32_t mask_lt = vmflt_vf_f32m1_b32(v_diff, -epsilon, vl);\n        vbool32_t mask_eq = vmfle_vv_f32m1_b32(v_abs_diff, v_epsilon, vl);\n\n        vint8m1_t v_out = vmv_v_x_i8m1(0, vl); // Initialize output to 0\n        v_out = vmerge_vxm_i8m1(mask_gt, v_out, 1, vl); // Set 1 where A[i] - B[i] > epsilon\n        v_out = vmerge_vxm_i8m1(mask_lt, v_out, -1, vl); // Set -1 where A[i] - B[i] < -epsilon\n\n        vse8_v_i8m1(out, v_out, vl);\n\n        A += vl;\n        B += vl;\n        out += vl;\n        length -= vl;\n    }\n}\n```"}
{"task_id": "SimdBench_49_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <math.h>\n\nvoid tensor_ternary_compare_simd(const float* A, const float* B, int8_t* out, float epsilon, size_t length) {\n    size_t vl;\n    vfloat32m1_t v_epsilon = vfmv_v_f_f32m1(fabsf(epsilon), vsetvlmax_e32m1());\n    size_t i = 0;\n\n    while (i < length) {\n        vl = vsetvl_e32m1(length - i);\n\n        vfloat32m1_t v_a = vle32_v_f32m1(&A[i], vl);\n        vfloat32m1_t v_b = vle32_v_f32m1(&B[i], vl);\n\n        vfloat32m1_t v_diff = vfsub_vv_f32m1(v_a, v_b, vl);\n        vfloat32m1_t v_abs_diff = vfabs_v_f32m1(v_diff, vl);\n\n        vbool32_t mask_greater = vmfgt_vv_f32m1_b32(v_diff, v_epsilon, vl);\n        vbool32_t mask_less = vmflt_vv_f32m1_b32(v_diff, vfnmsub_vf_f32m1(v_epsilon, -1.0f, v_epsilon, vl), vl);\n        vbool32_t mask_equal = vmfle_vv_f32m1_b32(v_abs_diff, v_epsilon, vl);\n\n        vint8m1_t v_out = vmv_v_x_i8m1(0, vl);\n        v_out = vmerge_vxm_i8m1(v_out, 1, mask_greater, vl);\n        v_out = vmerge_vxm_i8m1(v_out, -1, mask_less, vl);\n\n        vse8_v_i8m1(&out[i], v_out, vl);\n\n        i += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_49_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <math.h>\n\nvoid tensor_ternary_compare_simd(const float* A, const float* B, int8_t* out, float epsilon, size_t length) {\n    size_t vl;\n    vfloat32m1_t v_epsilon = vfmv_v_f_f32m1(epsilon, vsetvlmax_e32m1());\n    vfloat32m1_t v_neg_epsilon = vfmv_v_f_f32m1(-epsilon, vsetvlmax_e32m1());\n\n    while (length > 0) {\n        vl = vsetvl_e32m1(length);\n\n        vfloat32m1_t v_a = vle32_v_f32m1(A, vl);\n        vfloat32m1_t v_b = vle32_v_f32m1(B, vl);\n\n        vfloat32m1_t v_diff = vfsub_vv_f32m1(v_a, v_b, vl);\n        vfloat32m1_t v_abs_diff = vfabs_v_f32m1(v_diff, vl);\n\n        vbool32_t mask_gt = vmfgt_vf_f32m1_b32(v_diff, epsilon, vl);\n        vbool32_t mask_lt = vmflt_vf_f32m1_b32(v_diff, -epsilon, vl);\n        vbool32_t mask_eq = vmfle_vv_f32m1_b32(v_abs_diff, v_epsilon, vl);\n\n        vint8m1_t v_out = vmv_v_x_i8m1(0, vl); // Initialize to 0\n        v_out = vmerge_vxm_i8m1(mask_gt, v_out, 1, vl);  // Set 1 where A[i] - B[i] > epsilon\n        v_out = vmerge_vxm_i8m1(mask_lt, v_out, -1, vl); // Set -1 where A[i] - B[i] < -epsilon\n\n        vse8_v_i8m1(out, v_out, vl);\n\n        A += vl;\n        B += vl;\n        out += vl;\n        length -= vl;\n    }\n}\n```"}
{"task_id": "SimdBench_49_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <math.h>\n\nvoid tensor_ternary_compare_simd(const float* A, const float* B, int8_t* out, float epsilon, size_t length) {\n    size_t vl;\n    vfloat32m1_t v_epsilon = vfmv_v_f_f32m1(fabsf(epsilon), vsetvlmax_e32m1());\n    size_t i = 0;\n\n    while (i < length) {\n        vl = vsetvl_e32m1(length - i);\n\n        vfloat32m1_t v_a = vle32_v_f32m1(&A[i], vl);\n        vfloat32m1_t v_b = vle32_v_f32m1(&B[i], vl);\n\n        vfloat32m1_t v_diff = vfsub_vv_f32m1(v_a, v_b, vl);\n        vfloat32m1_t v_abs_diff = vfabs_v_f32m1(v_diff, vl);\n\n        vbool32_t gt_mask = vmfgt_vv_f32m1_b32(v_diff, v_epsilon, vl);\n        vbool32_t lt_mask = vmflt_vv_f32m1_b32(v_diff, vfneg_v_f32m1(v_epsilon, vl), vl);\n        vbool32_t eq_mask = vmfle_vv_f32m1_b32(v_abs_diff, v_epsilon, vl);\n\n        vint8m1_t v_out = vmv_v_x_i8m1(0, vl);\n        v_out = vmerge_vxm_i8m1(v_out, 1, gt_mask, vl);\n        v_out = vmerge_vxm_i8m1(v_out, -1, lt_mask, vl);\n\n        vse8_v_i8m1(&out[i], v_out, vl);\n\n        i += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_49_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <math.h>\n\nvoid tensor_ternary_compare_simd(const float* A, const float* B, int8_t* out, float epsilon, size_t length) {\n    size_t vl;\n    vfloat32m1_t vA, vB, vDiff, vEpsilon, vNegEpsilon;\n    vfloat32m1_t vAbsDiff;\n    vint8m1_t vResult;\n    vfloat32m1_t vZero = vfmv_v_f_f32m1(0.0f, vsetvlmax_e32m1());\n    vEpsilon = vfmv_v_f_f32m1(fabsf(epsilon), vsetvlmax_e32m1());\n    vNegEpsilon = vfmv_v_f_f32m1(-fabsf(epsilon), vsetvlmax_e32m1());\n\n    for (size_t i = 0; i < length; i += vl) {\n        vl = vsetvl_e32m1(length - i);\n\n        vA = vle32_v_f32m1(&A[i], vl);\n        vB = vle32_v_f32m1(&B[i], vl);\n\n        vDiff = vfsub_vv_f32m1(vA, vB, vl);\n        vAbsDiff = vfabs_v_f32m1(vDiff, vl);\n\n        vint8m1_t vGtEpsilon = vmv_v_x_i8m1(1, vl);\n        vint8m1_t vLtNegEpsilon = vmv_v_x_i8m1(-1, vl);\n        vint8m1_t vEqEpsilon = vmv_v_x_i8m1(0, vl);\n\n        vbool32_t maskGtEpsilon = vmfgt_vv_f32m1_b32(vDiff, vEpsilon, vl);\n        vbool32_t maskLtNegEpsilon = vmflt_vv_f32m1_b32(vDiff, vNegEpsilon, vl);\n        vbool32_t maskEqEpsilon = vmfle_vv_f32m1_b32(vAbsDiff, vEpsilon, vl);\n\n        vResult = vmerge_vvm_i8m1(maskGtEpsilon, vGtEpsilon, vResult, vl);\n        vResult = vmerge_vvm_i8m1(maskLtNegEpsilon, vLtNegEpsilon, vResult, vl);\n        vResult = vmerge_vvm_i8m1(maskEqEpsilon, vEqEpsilon, vResult, vl);\n\n        vse8_v_i8m1(&out[i], vResult, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_50_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <limits.h>\n\nvoid float_to_int_saturate_simd(const float* A, int32_t* B, size_t size) {\n    size_t vl;\n    size_t i = 0;\n    const float max_int32 = (float)INT32_MAX;\n    const float min_int32 = (float)INT32_MIN;\n\n    while (i < size) {\n        vl = vsetvl_e32m1(size - i);\n\n        vfloat32m1_t v_a = vle32_v_f32m1(&A[i], vl);\n        vfloat32m1_t v_max = vfmv_v_f_f32m1(max_int32, vl);\n        vfloat32m1_t v_min = vfmv_v_f_f32m1(min_int32, vl);\n\n        v_a = vfmin_vv_f32m1(v_a, v_max, vl); // Clamp to max_int32\n        v_a = vfmax_vv_f32m1(v_a, v_min, vl); // Clamp to min_int32\n\n        vint32m1_t v_b = vfcvt_x_f_v_i32m1(v_a, vl); // Convert to int32_t\n        vse32_v_i32m1(&B[i], v_b, vl);\n\n        i += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_50_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <limits.h>\n\nvoid float_to_int_saturate_simd(const float* A, int32_t* B, size_t size) {\n    size_t vl;\n    size_t i = 0;\n    const float INT32_MAX_F = (float)INT32_MAX;\n    const float INT32_MIN_F = (float)INT32_MIN;\n\n    while (i < size) {\n        vl = vsetvl_e32m1(size - i); // Set vector length for 32-bit elements\n        vfloat32m1_t vA = vle32_v_f32m1(&A[i], vl); // Load float values from A\n        vfloat32m1_t vMax = vfmv_v_f_f32m1(INT32_MAX_F, vl); // Broadcast INT32_MAX\n        vfloat32m1_t vMin = vfmv_v_f_f32m1(INT32_MIN_F, vl); // Broadcast INT32_MIN\n\n        // Clamp values to INT32_MAX and INT32_MIN\n        vfloat32m1_t vClamped = vfmin_vv_f32m1(vA, vMax, vl); // Clamp to INT32_MAX\n        vClamped = vfmax_vv_f32m1(vClamped, vMin, vl); // Clamp to INT32_MIN\n\n        // Convert clamped float values to int32_t\n        vint32m1_t vB = vfcvt_x_f_v_i32m1(vClamped, vl);\n\n        // Store the result in B\n        vse32_v_i32m1(&B[i], vB, vl);\n\n        i += vl; // Increment index by vector length\n    }\n}\n```"}
{"task_id": "SimdBench_50_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid float_to_int_saturate_simd(const float* A, int32_t* B, size_t size) {\n    size_t vl;\n    size_t i = 0;\n\n    const float INT32_MAX_F = (float)INT32_MAX;\n    const float INT32_MIN_F = (float)INT32_MIN;\n\n    while (i < size) {\n        vl = vsetvl_e32m1(size - i); // Set vector length based on remaining elements\n\n        vfloat32m1_t vA = vle32_v_f32m1(&A[i], vl); // Load float values from A\n        vfloat32m1_t vMax = vfmv_v_f_f32m1(INT32_MAX_F, vl); // Vector with INT32_MAX_F\n        vfloat32m1_t vMin = vfmv_v_f_f32m1(INT32_MIN_F, vl); // Vector with INT32_MIN_F\n\n        // Clamp values to INT32_MAX_F and INT32_MIN_F\n        vfloat32m1_t vClamped = vfmax_vv_f32m1(vfmin_vv_f32m1(vA, vMax, vl), vMin, vl);\n\n        // Convert clamped float values to int32_t\n        vint32m1_t vB = vfcvt_x_f_v_i32m1(vClamped, vl);\n\n        vse32_v_i32m1(&B[i], vB, vl); // Store converted values into B\n        i += vl; // Increment index by vector length\n    }\n}\n```"}
{"task_id": "SimdBench_50_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <limits.h>\n\nvoid float_to_int_saturate_simd(const float* A, int32_t* B, size_t size) {\n    size_t vl;\n    size_t offset = 0;\n    const float INT32_MAX_F = (float)INT32_MAX;\n    const float INT32_MIN_F = (float)INT32_MIN;\n\n    while (offset < size) {\n        vl = vsetvl_e32m8(size - offset);\n\n        vfloat32m8_t v_a = vle32_v_f32m8(&A[offset], vl);\n        vfloat32m8_t v_max = vfmv_v_f_f32m8(INT32_MAX_F, vl);\n        vfloat32m8_t v_min = vfmv_v_f_f32m8(INT32_MIN_F, vl);\n\n        // Clamp values to INT32_MAX and INT32_MIN\n        vfloat32m8_t v_clamped = vfmin_vv_f32m8(vfmax_vv_f32m8(v_a, v_min, vl), v_max, vl);\n\n        // Convert to int32_t\n        vint32m8_t v_b = vfcvt_x_f_v_i32m8(v_clamped, vl);\n\n        vse32_v_i32m8(&B[offset], v_b, vl);\n\n        offset += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_50_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <limits.h>\n\nvoid float_to_int_saturate_simd(const float* A, int32_t* B, size_t size) {\n    size_t vl;\n    size_t i = 0;\n    const float max_int32 = (float)INT32_MAX;\n    const float min_int32 = (float)INT32_MIN;\n\n    while (i < size) {\n        vl = vsetvl_e32m1(size - i);\n\n        vfloat32m1_t v_a = vle32_v_f32m1(&A[i], vl);\n        vfloat32m1_t v_max = vfmv_v_f_f32m1(max_int32, vl);\n        vfloat32m1_t v_min = vfmv_v_f_f32m1(min_int32, vl);\n\n        v_a = vfmin_vv_f32m1(v_a, v_max, vl);\n        v_a = vfmax_vv_f32m1(v_a, v_min, vl);\n\n        vint32m1_t v_b = vfcvt_x_f_v_i32m1(v_a, vl);\n        vse32_v_i32m1(&B[i], v_b, vl);\n\n        i += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_51_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid int_to_float_scaled_simd(const int32_t* A, int8_t scale, float* B, size_t size) {\n    size_t vl;\n    float scale_factor = (float)scale;\n\n    while (size > 0) {\n        vl = vsetvl_e32m1(size); // Set vector length for 32-bit elements\n        vint32m1_t vecA = vle32_v_i32m1(A, vl); // Load int32_t values from A\n        vfloat32m1_t vecB = vfcvt_f_x_v_f32m1(vecA, vl); // Convert int32_t to float\n        vecB = vfmul_vf_f32m1(vecB, scale_factor, vl); // Scale the float values\n        vse32_v_f32m1(B, vecB, vl); // Store the scaled float values into B\n\n        A += vl;\n        B += vl;\n        size -= vl;\n    }\n}\n```"}
{"task_id": "SimdBench_51_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid int_to_float_scaled_simd(const int32_t* A, int8_t scale, float* B, size_t size) {\n    size_t vl;\n    size_t i = 0;\n    float scale_factor = (float)scale;\n\n    while (i < size) {\n        vl = vsetvl_e32m1(size - i); // Determine the vector length for this iteration\n        vint32m1_t vec_int = vle32_v_i32m1(&A[i], vl); // Load int32_t values from A\n        vfloat32m1_t vec_float = vfcvt_f_x_v_f32m1(vec_int, vl); // Convert int32_t to float\n        vec_float = vfmul_vf_f32m1(vec_float, scale_factor, vl); // Scale the float values\n        vse32_v_f32m1(&B[i], vec_float, vl); // Store the scaled float values into B\n        i += vl; // Increment the index by the vector length\n    }\n}\n```"}
{"task_id": "SimdBench_51_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid int_to_float_scaled_simd(const int32_t* A, int8_t scale, float* B, size_t size) {\n    size_t vl;\n    float scale_factor = (float)scale;\n\n    while (size > 0) {\n        vl = vsetvl_e32m8(size); // Set vector length for 32-bit elements\n        vint32m8_t vecA = vle32_v_i32m8(A, vl); // Load int32_t elements from A\n        vfloat32m8_t vecB = vfcvt_f_x_v_f32m8(vecA, vl); // Convert int32_t to float\n        vecB = vfmul_vf_f32m8(vecB, scale_factor, vl); // Scale the float values\n        vse32_v_f32m8(B, vecB, vl); // Store the results into B\n        A += vl;\n        B += vl;\n        size -= vl;\n    }\n}\n```"}
{"task_id": "SimdBench_51_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid int_to_float_scaled_simd(const int32_t* A, int8_t scale, float* B, size_t size) {\n    size_t vl;\n    float scale_factor = (float)scale;\n\n    while (size > 0) {\n        vl = vsetvl_e32m8(size); // Set vector length for 32-bit elements\n        vint32m8_t vecA = vle32_v_i32m8(A, vl); // Load int32_t values from A\n        vfloat32m8_t vecB = vfcvt_f_x_v_f32m8(vecA, vl); // Convert int32_t to float\n        vecB = vfmul_vf_f32m8(vecB, scale_factor, vl); // Scale the float values\n        vse32_v_f32m8(B, vecB, vl); // Store the scaled float values to B\n        A += vl;\n        B += vl;\n        size -= vl;\n    }\n}\n```"}
{"task_id": "SimdBench_51_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid int_to_float_scaled_simd(const int32_t* A, int8_t scale, float* B, size_t size) {\n    size_t vl;\n    size_t i = 0;\n    float scale_factor = (float)scale;\n\n    while (i < size) {\n        vl = vsetvl_e32m1(size - i); // Set vector length for 32-bit elements\n        vint32m1_t vecA = vle32_v_i32m1(&A[i], vl); // Load int32_t elements from A\n        vfloat32m1_t vecB = vfcvt_f_x_v_f32m1(vecA, vl); // Convert int32_t to float\n        vecB = vfmul_vf_f32m1(vecB, scale_factor, vl); // Scale the float values\n        vse32_v_f32m1(&B[i], vecB, vl); // Store the scaled float values into B\n        i += vl; // Increment the index by the vector length\n    }\n}\n```"}
{"task_id": "SimdBench_52_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid float_div_round_simd(const float* A, const float* B, int32_t* C, size_t size) {\n    size_t vl;\n    size_t i = 0;\n    while (i < size) {\n        vl = vsetvl_e32m1(size - i); // Set the vector length for 32-bit elements\n        vfloat32m1_t vecA = vle32_v_f32m1(&A[i], vl); // Load vector from A\n        vfloat32m1_t vecB = vle32_v_f32m1(&B[i], vl); // Load vector from B\n        vfloat32m1_t vecDiv = vfdiv_vv_f32m1(vecA, vecB, vl); // Perform element-wise division\n        vfloat32m1_t vecRounded = vfrint_v_f32m1(vecDiv, vl); // Round to nearest integer\n        vint32m1_t vecResult = vfcvt_x_f_v_i32m1(vecRounded, vl); // Convert to 32-bit integer\n        vse32_v_i32m1(&C[i], vecResult, vl); // Store result in C\n        i += vl; // Increment index by vector length\n    }\n}\n```"}
{"task_id": "SimdBench_52_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid float_div_round_simd(const float* A, const float* B, int32_t* C, size_t size) {\n    size_t vl;\n    size_t i = 0;\n\n    while (i < size) {\n        vl = vsetvl_e32m1(size - i); // Set the vector length for 32-bit elements\n        vfloat32m1_t vecA = vle32_v_f32m1(&A[i], vl); // Load vector from A\n        vfloat32m1_t vecB = vle32_v_f32m1(&B[i], vl); // Load vector from B\n\n        vfloat32m1_t vecDiv = vfdiv_vv_f32m1(vecA, vecB, vl); // Perform element-wise division\n        vint32m1_t vecRounded = vfcvt_rtz_x_f_v_i32m1(vecDiv, vl); // Convert to int32_t with rounding to nearest integer\n\n        vse32_v_i32m1(&C[i], vecRounded, vl); // Store the result in C\n        i += vl; // Increment the index by the vector length\n    }\n}\n```"}
{"task_id": "SimdBench_52_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid float_div_round_simd(const float* A, const float* B, int32_t* C, size_t size) {\n    size_t vl;\n    size_t i = 0;\n\n    while (i < size) {\n        vl = vsetvl_e32m1(size - i); // Set the vector length for 32-bit elements\n        vfloat32m1_t vecA = vle32_v_f32m1(A + i, vl); // Load vector from A\n        vfloat32m1_t vecB = vle32_v_f32m1(B + i, vl); // Load vector from B\n\n        vfloat32m1_t vecDiv = vfdiv_vv_f32m1(vecA, vecB, vl); // Perform element-wise division\n        vfloat32m1_t vecRounded = vfrint_v_f32m1(vecDiv, vl); // Round to nearest integer\n\n        vint32m1_t vecResult = vfcvt_x_f_v_i32m1(vecRounded, vl); // Convert float to int32_t\n        vse32_v_i32m1(C + i, vecResult, vl); // Store the result in C\n\n        i += vl; // Increment the index by the vector length\n    }\n}\n```"}
{"task_id": "SimdBench_52_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid float_div_round_simd(const float* A, const float* B, int32_t* C, size_t size) {\n    size_t vl;\n    size_t i = 0;\n\n    while (i < size) {\n        vl = vsetvl_e32m1(size - i); // Set the vector length for 32-bit elements\n        vfloat32m1_t vecA = vle32_v_f32m1(&A[i], vl); // Load vector from A\n        vfloat32m1_t vecB = vle32_v_f32m1(&B[i], vl); // Load vector from B\n\n        vfloat32m1_t vecDiv = vfdiv_vv_f32m1(vecA, vecB, vl); // Perform element-wise division\n        vfloat32m1_t vecRounded = vfrint_v_f32m1(vecDiv, vl); // Round to nearest integer\n\n        vint32m1_t vecResult = vfcvt_x_f_v_i32m1(vecRounded, vl); // Convert rounded float to int32\n        vse32_v_i32m1(&C[i], vecResult, vl); // Store result in C\n\n        i += vl; // Increment index by vector length\n    }\n}\n```"}
{"task_id": "SimdBench_52_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid float_div_round_simd(const float* A, const float* B, int32_t* C, size_t size) {\n    size_t vl;\n    size_t i = 0;\n\n    while (i < size) {\n        vl = vsetvl_e32m1(size - i); // Set vector length for 32-bit elements\n        vfloat32m1_t vecA = vle32_v_f32m1(&A[i], vl); // Load vector from A\n        vfloat32m1_t vecB = vle32_v_f32m1(&B[i], vl); // Load vector from B\n\n        vfloat32m1_t vecDiv = vfdiv_vv_f32m1(vecA, vecB, vl); // Perform element-wise division\n        vfloat32m1_t vecRounded = vfrint_v_f32m1(vecDiv, vl); // Round to nearest integer\n\n        vint32m1_t vecResult = vfcvt_x_f_v_i32m1(vecRounded, vl); // Convert float to int32_t\n        vse32_v_i32m1(&C[i], vecResult, vl); // Store result in C\n\n        i += vl; // Increment index by vector length\n    }\n}\n```"}
{"task_id": "SimdBench_53_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <float.h>\n\nvoid double_to_float_saturate_simd(const double* A, float* B, size_t size) {\n    size_t vl;\n    vfloat32m1_t vflt_max = vfmv_v_f_f32m1(FLT_MAX, vsetvlmax_e32m1());\n    vfloat32m1_t vflt_min = vfmv_v_f_f32m1(-FLT_MAX, vsetvlmax_e32m1());\n\n    while (size > 0) {\n        vl = vsetvl_e64m1(size);\n\n        vfloat64m1_t vdouble = vle64_v_f64m1(A, vl);\n        vfloat32m1_t vfloat = vfncvt_f_f_w_f32m1(vdouble, vl);\n\n        vfloat = vfmin_vv_f32m1(vfloat, vflt_max, vl);\n        vfloat = vfmax_vv_f32m1(vfloat, vflt_min, vl);\n\n        vse32_v_f32m1(B, vfloat, vl);\n\n        A += vl;\n        B += vl;\n        size -= vl;\n    }\n}\n```"}
{"task_id": "SimdBench_53_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <float.h>\n\nvoid double_to_float_saturate_simd(const double* A, float* B, size_t size) {\n    size_t vl;\n    size_t i = 0;\n    vfloat32m1_t vflt_max = vfmv_v_f_f32m1(FLT_MAX, vsetvlmax_e32m1());\n    vfloat32m1_t vflt_min = vfmv_v_f_f32m1(-FLT_MAX, vsetvlmax_e32m1());\n\n    while (i < size) {\n        vl = vsetvl_e64m1(size - i); // Determine vector length\n        vfloat64m1_t vdouble = vle64_v_f64m1(&A[i], vl); // Load double values\n        vfloat32m1_t vfloat = vfncvt_f_x_f32m1(vdouble, vl); // Convert to float\n\n        // Saturate values\n        vfloat32m1_t vclamped = vfmax_vv_f32m1(vfloat, vflt_min, vl); // Clamp to -FLT_MAX\n        vclamped = vfmin_vv_f32m1(vclamped, vflt_max, vl); // Clamp to FLT_MAX\n\n        vse32_v_f32m1(&B[i], vclamped, vl); // Store results\n        i += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_53_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <float.h>\n\nvoid double_to_float_saturate_simd(const double* A, float* B, size_t size) {\n    size_t vl;\n    size_t i = 0;\n    vfloat32m1_t vflt_max = vfmv_v_f_f32m1(FLT_MAX, vsetvlmax_e32m1());\n    vfloat32m1_t vflt_min = vfmv_v_f_f32m1(-FLT_MAX, vsetvlmax_e32m1());\n\n    while (i < size) {\n        vl = vsetvl_e64m1(size - i);\n        vfloat64m1_t vdouble = vle64_v_f64m1(&A[i], vl);\n        vfloat32m1_t vfloat = vfncvt_f_x_f_w_f32m1(vdouble, vl);\n\n        vbool32_t mask_gt = vmfgt_vv_f32m1_b32(vfloat, vflt_max, vl);\n        vbool32_t mask_lt = vmflt_vv_f32m1_b32(vfloat, vflt_min, vl);\n\n        vfloat = vmerge_vvm_f32m1(mask_gt, vflt_max, vfloat, vl);\n        vfloat = vmerge_vvm_f32m1(mask_lt, vflt_min, vfloat, vl);\n\n        vse32_v_f32m1(&B[i], vfloat, vl);\n        i += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_53_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <float.h>\n\nvoid double_to_float_saturate_simd(const double* A, float* B, size_t size) {\n    size_t vl;\n    size_t i = 0;\n\n    while (i < size) {\n        vl = vsetvl_e64m1(size - i); // Set vector length for 64-bit elements\n        vfloat64m1_t vecA = vle64_v_f64m1(&A[i], vl); // Load double values from A\n        vfloat32m1_t vecB = vfncvt_f_f_w_f32m1(vecA, vl); // Narrow double to float\n\n        // Create saturation masks\n        vfloat32m1_t max_val = vfmv_v_f_f32m1(FLT_MAX, vl);\n        vfloat32m1_t min_val = vfmv_v_f_f32m1(-FLT_MAX, vl);\n\n        vbool32_t mask_gt = vmfgt_vv_f32m1_b32(vecB, max_val, vl); // vecB > FLT_MAX\n        vbool32_t mask_lt = vmflt_vv_f32m1_b32(vecB, min_val, vl); // vecB < -FLT_MAX\n\n        // Apply saturation\n        vecB = vmerge_vvm_f32m1(mask_gt, max_val, vecB, vl); // Set FLT_MAX where vecB > FLT_MAX\n        vecB = vmerge_vvm_f32m1(mask_lt, min_val, vecB, vl); // Set -FLT_MAX where vecB < -FLT_MAX\n\n        vse32_v_f32m1(&B[i], vecB, vl); // Store results to B\n        i += vl; // Increment index by vector length\n    }\n}\n```"}
{"task_id": "SimdBench_53_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <float.h>\n\nvoid double_to_float_saturate_simd(const double* A, float* B, size_t size) {\n    size_t vl;\n    size_t i = 0;\n\n    while (i < size) {\n        vl = vsetvl_e64m1(size - i); // Set vector length for 64-bit elements\n        vfloat64m1_t vecA = vle64_v_f64m1(&A[i], vl); // Load double values from A\n\n        vfloat32m1_t vecB = vfcvt_f_x_v_f32m1(vecA, vl); // Convert double to float\n\n        vfloat32m1_t max_val = vfmv_v_f_f32m1(FLT_MAX, vl); // Vector of FLT_MAX\n        vfloat32m1_t min_val = vfmv_v_f_f32m1(-FLT_MAX, vl); // Vector of -FLT_MAX\n\n        vecB = vfmin_vv_f32m1(vecB, max_val, vl); // Saturate values greater than FLT_MAX\n        vecB = vfmax_vv_f32m1(vecB, min_val, vl); // Saturate values less than -FLT_MAX\n\n        vse32_v_f32m1(&B[i], vecB, vl); // Store the saturated float values into B\n        i += vl; // Increment index by vector length\n    }\n}\n```"}
{"task_id": "SimdBench_54_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid int16_to_int32_simd(const int16_t* A, int32_t* B, size_t size) {\n    size_t vl;\n    size_t i = 0;\n\n    while (i < size) {\n        vl = vsetvl_e16m1(size - i); // Set vector length for 16-bit elements\n        vint16m1_t vecA = vle16_v_i16m1(&A[i], vl); // Load 16-bit integers from A\n        vint32m2_t vecB = vwcvtl_v_i32m2_i16m1(vecA, vl); // Widen 16-bit integers to 32-bit\n        vse32_v_i32m2(&B[i], vecB, vl); // Store widened 32-bit integers to B\n        i += vl; // Increment index by vector length\n    }\n}\n```"}
{"task_id": "SimdBench_54_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid int16_to_int32_simd(const int16_t* A, int32_t* B, size_t size) {\n    size_t vl;\n    size_t i = 0;\n\n    while (i < size) {\n        vl = vsetvl_e16m1(size - i); // Set vector length for 16-bit elements\n        vint16m1_t vecA = vle16_v_i16m1(&A[i], vl); // Load 16-bit integers from A\n        vint32m2_t vecB = vwcvtl_v_i32m2_i16m1(vecA, vl); // Widen to 32-bit integers\n        vse32_v_i32m2(&B[i], vecB, vl); // Store 32-bit integers to B\n        i += vl; // Increment index by vector length\n    }\n}\n```"}
{"task_id": "SimdBench_54_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid int16_to_int32_simd(const int16_t* A, int32_t* B, size_t size) {\n    size_t vl;\n    while (size > 0) {\n        vl = vsetvl_e16m1(size); // Set the vector length for 16-bit elements\n        vint16m1_t vecA = vle16_v_i16m1(A, vl); // Load 16-bit integers from A\n        vint32m2_t vecB = vwcvte_v_i32m2_i16m1(vecA, vl); // Widen 16-bit to 32-bit integers\n        vse32_v_i32m2(B, vecB, vl); // Store the 32-bit integers to B\n        A += vl;\n        B += vl;\n        size -= vl;\n    }\n}\n```"}
{"task_id": "SimdBench_54_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid int16_to_int32_simd(const int16_t* A, int32_t* B, size_t size) {\n    size_t vl;\n    size_t i = 0;\n\n    while (i < size) {\n        vl = vsetvl_e16m1(size - i); // Set vector length for 16-bit elements\n        vint16m1_t vecA = vle16_v_i16m1(&A[i], vl); // Load 16-bit integers from A\n        vint32m2_t vecB = vwcvtl_v_i32m2_i16m1(vecA, vl); // Widen to 32-bit integers\n        vse32_v_i32m2(&B[i], vecB, vl); // Store 32-bit integers into B\n        i += vl; // Increment index by vector length\n    }\n}\n```"}
{"task_id": "SimdBench_54_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid int16_to_int32_simd(const int16_t* A, int32_t* B, size_t size) {\n    size_t vl;\n    while (size > 0) {\n        vl = vsetvl_e16m1(size); // Set vector length for 16-bit elements\n        vint16m1_t vecA = vle16_v_i16m1(A, vl); // Load 16-bit integers from A\n        vint32m2_t vecB = vwcvte_v_i32m2_i16m1(vecA, vl); // Widen to 32-bit integers\n        vse32_v_i32m2(B, vecB, vl); // Store 32-bit integers to B\n        A += vl;\n        B += vl;\n        size -= vl;\n    }\n}\n```"}
{"task_id": "SimdBench_55_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid conditional_normalize_simd(const float* A, const int32_t* control, float* B, size_t size, float min_val, float max_val) {\n    size_t vl;\n    float range = max_val - min_val;\n\n    for (size_t i = 0; i < size; i += vl) {\n        vl = vsetvl_e32m1(size - i);\n\n        vfloat32m1_t vA = vle32_v_f32m1(&A[i], vl);\n        vint32m1_t vControl = vle32_v_i32m1(&control[i], vl);\n        vfloat32m1_t vB;\n\n        vbool32_t mask = vmgt_vx_i32m1_b32(vControl, 0, vl);\n\n        vfloat32m1_t vNormalized = vfsub_vf_f32m1(vA, min_val, vl);\n        vNormalized = vfdiv_vf_f32m1(vNormalized, range, vl);\n        vNormalized = vfmax_vf_f32m1(vNormalized, 0.0f, vl);\n        vNormalized = vfmin_vf_f32m1(vNormalized, 1.0f, vl);\n\n        vB = vmerge_vvm_f32m1(mask, vNormalized, vA, vl);\n\n        vse32_v_f32m1(&B[i], vB, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_55_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid conditional_normalize_simd(const float* A, const int32_t* control, float* B, size_t size, float min_val, float max_val) {\n    size_t vl;\n    float range = max_val - min_val;\n\n    for (size_t i = 0; i < size; i += vl) {\n        vl = vsetvl_e32m8(size - i);\n\n        vfloat32m8_t vA = vle32_v_f32m8(&A[i], vl);\n        vint32m8_t vControl = vle32_v_i32m8(&control[i], vl);\n\n        vfloat32m8_t vNormalized = vfmul_vf_f32m8(vfsub_vf_f32m8(vA, min_val, vl), 1.0f / range, vl);\n        vNormalized = vfmax_vf_f32m8(vNormalized, 0.0f, vl);\n        vNormalized = vfmin_vf_f32m8(vNormalized, 1.0f, vl);\n\n        vbool4_t mask = vmgt_vx_i32m8_b4(vControl, 0, vl);\n\n        vfloat32m8_t vResult = vmerge_vvm_f32m8(mask, vNormalized, vA, vl);\n\n        vse32_v_f32m8(&B[i], vResult, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_55_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid conditional_normalize_simd(const float* A, const int32_t* control, float* B, size_t size, float min_val, float max_val) {\n    size_t vl;\n    float range = max_val - min_val;\n\n    for (size_t i = 0; i < size; i += vl) {\n        vl = vsetvl_e32m1(size - i);\n\n        vfloat32m1_t vA = vle32_v_f32m1(&A[i], vl);\n        vint32m1_t vControl = vle32_v_i32m1(&control[i], vl);\n        vfloat32m1_t vB;\n\n        vbool32_t mask = vmgt_vx_i32m1_b32(vControl, 0, vl);\n\n        vfloat32m1_t vNormalized = vfsub_vf_f32m1(vA, min_val, vl);\n        vNormalized = vfdiv_vf_f32m1(vNormalized, range, vl);\n        vNormalized = vfmax_vf_f32m1(vNormalized, 0.0f, vl);\n        vNormalized = vfmin_vf_f32m1(vNormalized, 1.0f, vl);\n\n        vB = vmerge_vvm_f32m1(mask, vNormalized, vA, vl);\n\n        vse32_v_f32m1(&B[i], vB, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_55_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid conditional_normalize_simd(const float* A, const int32_t* control, float* B, size_t size, float min_val, float max_val) {\n    size_t vl;\n    float range = max_val - min_val;\n\n    for (size_t i = 0; i < size; i += vl) {\n        vl = vsetvl_e32m1(size - i); // Set vector length for 32-bit elements\n\n        vfloat32m1_t vA = vle32_v_f32m1(&A[i], vl); // Load vector of floats from A\n        vint32m1_t vControl = vle32_v_i32m1(&control[i], vl); // Load vector of ints from control\n        vfloat32m1_t vB;\n\n        vbool32_t mask = vmgt_vx_i32m1_b32(vControl, 0, vl); // Mask for control > 0\n\n        vfloat32m1_t vNormalized = vfsub_vf_f32m1(vA, min_val, vl); // A[i] - min_val\n        vNormalized = vfdiv_vf_f32m1(vNormalized, range, vl);       // (A[i] - min_val) / (max_val - min_val)\n        vNormalized = vfmax_vf_f32m1(vNormalized, 0.0f, vl);        // Clamp to 0\n        vNormalized = vfmin_vf_f32m1(vNormalized, 1.0f, vl);        // Clamp to 1\n\n        vB = vmerge_vvm_f32m1(mask, vNormalized, vA, vl); // Use normalized value if control > 0, else copy A[i]\n\n        vse32_v_f32m1(&B[i], vB, vl); // Store result in B\n    }\n}\n```"}
{"task_id": "SimdBench_55_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid conditional_normalize_simd(const float* A, const int32_t* control, float* B, size_t size, float min_val, float max_val) {\n    size_t vl;\n    float range = max_val - min_val;\n\n    for (size_t i = 0; i < size; i += vl) {\n        vl = vsetvl_e32m1(size - i);\n\n        vfloat32m1_t vA = vle32_v_f32m1(&A[i], vl);\n        vint32m1_t vControl = vle32_v_i32m1(&control[i], vl);\n        vfloat32m1_t vB;\n\n        vbool32_t mask = vmgt_vx_i32m1_b32(vControl, 0, vl);\n\n        vfloat32m1_t vNormalized = vfsub_vf_f32m1(vA, min_val, vl);\n        vNormalized = vfdiv_vf_f32m1(vNormalized, range, vl);\n        vNormalized = vfmax_vf_f32m1(vNormalized, 0.0f, vl);\n        vNormalized = vfmin_vf_f32m1(vNormalized, 1.0f, vl);\n\n        vB = vmerge_vvm_f32m1(mask, vNormalized, vA, vl);\n\n        vse32_v_f32m1(&B[i], vB, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_56_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <math.h>\n\nvoid int_to_float_sqrt_simd(const uint32_t* A, float* B, size_t size) {\n    size_t vl;\n    size_t offset = 0;\n\n    while (offset < size) {\n        vl = vsetvl_e32m1(size - offset);\n\n        // Load uint32_t values from A\n        vuint32m1_t vec_a = vle32_v_u32m1(&A[offset], vl);\n\n        // Extract high 16 bits by shifting right\n        vuint32m1_t vec_high16 = vsrl_vx_u32m1(vec_a, 16, vl);\n\n        // Convert high 16 bits to float\n        vfloat32m1_t vec_float = vfcvt_f_xu_v_f32m1(vec_high16, vl);\n\n        // Compute square root\n        vfloat32m1_t vec_sqrt = vfsqrt_v_f32m1(vec_float, vl);\n\n        // Store the result in B\n        vse32_v_f32m1(&B[offset], vec_sqrt, vl);\n\n        offset += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_56_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <math.h>\n\nvoid int_to_float_sqrt_simd(const uint32_t* A, float* B, size_t size) {\n    size_t vl;\n    size_t i = 0;\n\n    while (i < size) {\n        vl = vsetvl_e32m1(size - i); // Set vector length for 32-bit elements\n        vuint32m1_t vecA = vle32_v_u32m1(&A[i], vl); // Load uint32_t elements from A\n        vuint16m1_t high16 = vnsrl_wx_u16m1(vecA, 16, vl); // Extract high 16 bits\n        vfloat32m1_t floatVals = vfcvt_f_xu_v_f32m1(high16, vl); // Convert to float\n        vfloat32m1_t sqrtVals = vfsqrt_v_f32m1(floatVals, vl); // Compute square root\n        vse32_v_f32m1(&B[i], sqrtVals, vl); // Store results in B\n        i += vl; // Increment index by vector length\n    }\n}\n```"}
{"task_id": "SimdBench_56_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <math.h>\n\nvoid int_to_float_sqrt_simd(const uint32_t* A, float* B, size_t size) {\n    size_t vl;\n    size_t i = 0;\n\n    while (i < size) {\n        vl = vsetvl_e32m1(size - i); // Set vector length for 32-bit elements\n        vuint32m1_t vecA = vle32_v_u32m1(&A[i], vl); // Load uint32_t elements from A\n        vuint16m1_t vecHigh16 = vnsrl_wx_u16m1(vecA, 16, vl); // Extract high 16 bits\n        vfloat32m1_t vecFloat = vfcvt_f_xu_v_f32m1(vecHigh16, vl); // Convert to float\n        vfloat32m1_t vecSqrt = vfsqrt_v_f32m1(vecFloat, vl); // Compute square root\n        vse32_v_f32m1(&B[i], vecSqrt, vl); // Store results in B\n        i += vl; // Increment index by vector length\n    }\n}\n```"}
{"task_id": "SimdBench_56_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <math.h>\n\nvoid int_to_float_sqrt_simd(const uint32_t* A, float* B, size_t size) {\n    size_t vl;\n    size_t i = 0;\n\n    while (i < size) {\n        vl = vsetvl_e32m1(size - i); // Set vector length for 32-bit elements\n        vuint32m1_t vecA = vle32_v_u32m1(&A[i], vl); // Load uint32_t elements from A\n        vuint16m1_t vecHighBits = vnsrl_wx_u16m1(vecA, 16, vl); // Extract high 16 bits\n        vfloat32m1_t vecFloat = vfcvt_f_xu_v_f32m1(vecHighBits, vl); // Convert to float\n        vfloat32m1_t vecSqrt = vfsqrt_v_f32m1(vecFloat, vl); // Compute square root\n        vse32_v_f32m1(&B[i], vecSqrt, vl); // Store results in B\n        i += vl; // Increment index by vector length\n    }\n}\n```"}
{"task_id": "SimdBench_56_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <math.h>\n\nvoid int_to_float_sqrt_simd(const uint32_t* A, float* B, size_t size) {\n    size_t vl;\n    size_t i = 0;\n\n    while (i < size) {\n        vl = vsetvl_e32m1(size - i); // Set the vector length based on remaining elements\n        vuint32m1_t vecA = vle32_v_u32m1(&A[i], vl); // Load uint32_t values from A\n        vuint16m1_t vecHigh16 = vnsrl_wx_u16m1(vecA, 16, vl); // Extract high 16 bits\n        vfloat32m1_t vecFloat = vfcvt_f_x_v_f32m1(vecHigh16, vl); // Convert to float\n        vfloat32m1_t vecSqrt = vfsqrt_v_f32m1(vecFloat, vl); // Compute square root\n        vse32_v_f32m1(&B[i], vecSqrt, vl); // Store the result in B\n        i += vl; // Increment the index by the vector length\n    }\n}\n```"}
{"task_id": "SimdBench_57_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid int_bits_to_float_simd(const uint32_t* A, float* B, size_t size) {\n    size_t vl;\n    while (size > 0) {\n        vl = vsetvl_e32m8(size); // Set the vector length for 32-bit elements\n        vuint32m8_t vecA = vle32_v_u32m8(A, vl); // Load uint32_t elements from A\n        vfloat32m8_t vecB = vreinterpret_v_u32m8_f32m8(vecA); // Reinterpret bits as float\n        vse32_v_f32m8(B, vecB, vl); // Store the float elements into B\n        A += vl;\n        B += vl;\n        size -= vl;\n    }\n}\n```"}
{"task_id": "SimdBench_57_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid int_bits_to_float_simd(const uint32_t* A, float* B, size_t size) {\n    size_t vl;\n    while (size > 0) {\n        vl = vsetvl_e32m1(size); // Set vector length for 32-bit elements\n        vuint32m1_t vec_int = vle32_v_u32m1(A, vl); // Load uint32_t values from A\n        vfloat32m1_t vec_float = vreinterpret_v_u32m1_f32m1(vec_int); // Reinterpret as float\n        vse32_v_f32m1(B, vec_float, vl); // Store float values into B\n        A += vl;\n        B += vl;\n        size -= vl;\n    }\n}\n```"}
{"task_id": "SimdBench_57_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid int_bits_to_float_simd(const uint32_t* A, float* B, size_t size) {\n    size_t vl;\n    while (size > 0) {\n        vl = vsetvl_e32m1(size); // Set the vector length based on the remaining size\n        vuint32m1_t vec_uint = vle32_v_u32m1(A, vl); // Load uint32_t values from A\n        vfloat32m1_t vec_float = vreinterpret_v_u32m1_f32m1(vec_uint); // Reinterpret as float32\n        vse32_v_f32m1(B, vec_float, vl); // Store the float32 values into B\n        A += vl;\n        B += vl;\n        size -= vl;\n    }\n}\n```"}
{"task_id": "SimdBench_57_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid int_bits_to_float_simd(const uint32_t* A, float* B, size_t size) {\n    size_t vl;\n    while (size > 0) {\n        vl = vsetvl_e32m1(size); // Set vector length for 32-bit elements\n        vuint32m1_t vec_int = vle32_v_u32m1(A, vl); // Load uint32_t values from A\n        vfloat32m1_t vec_float = vreinterpret_v_u32m1_f32m1(vec_int); // Reinterpret as float\n        vse32_v_f32m1(B, vec_float, vl); // Store float values into B\n        A += vl;\n        B += vl;\n        size -= vl;\n    }\n}\n```"}
{"task_id": "SimdBench_57_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid int_bits_to_float_simd(const uint32_t* A, float* B, size_t size) {\n    size_t vl;\n    while (size > 0) {\n        vl = vsetvl_e32m1(size); // Set vector length for 32-bit elements\n        vuint32m1_t vec_int = vle32_v_u32m1(A, vl); // Load uint32_t values from A\n        vfloat32m1_t vec_float = vreinterpret_v_u32m1_f32m1(vec_int); // Reinterpret bits as float\n        vse32_v_f32m1(B, vec_float, vl); // Store float values into B\n        A += vl;\n        B += vl;\n        size -= vl;\n    }\n}\n```"}
{"task_id": "SimdBench_58_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid conditional_diff_simd(const int32_t* A, const bool* cond, float* diff, size_t size) {\n    size_t vl;\n    size_t i = 0;\n\n    // Set the first element of diff to 0.0f\n    diff[0] = 0.0f;\n\n    while (i < size - 1) {\n        // Load vector length for the current chunk\n        vl = vsetvl_e32m1(size - i);\n\n        // Load A[i] and A[i-1] into vector registers\n        vint32m1_t vec_A_curr = vle32_v_i32m1(&A[i], vl);\n        vint32m1_t vec_A_prev = vle32_v_i32m1(&A[i - 1], vl);\n\n        // Compute the difference (A[i] - A[i-1])\n        vint32m1_t vec_diff = vsub_vv_i32m1(vec_A_curr, vec_A_prev, vl);\n\n        // Load the condition array\n        vbool8_t vec_cond = vle8_v_b8(&cond[i], vl);\n\n        // Masked conversion to float and store in diff\n        vfloat32m1_t vec_diff_float = vfcvt_f_x_v_f32m1(vec_diff, vl);\n        vse32_v_f32m1_m(vec_cond, &diff[i], vec_diff_float, vl);\n\n        // Set diff[i] to 0.0f where cond[i] is false\n        vfloat32m1_t vec_zero = vfmv_v_f_f32m1(0.0f, vl);\n        vse32_v_f32m1_m(vnot_m_b8(vec_cond, vl), &diff[i], vec_zero, vl);\n\n        i += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_58_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid conditional_diff_simd(const int32_t* A, const bool* cond, float* diff, size_t size) {\n    size_t vl;\n    size_t i = 0;\n\n    // Set the first element of diff to 0.0f\n    diff[0] = 0.0f;\n\n    while (i < size - 1) {\n        // Determine the vector length for this iteration\n        vl = vsetvl_e32m1(size - i);\n\n        // Load current and previous elements of A\n        vint32m1_t vec_A_curr = vle32_v_i32m1(&A[i + 1], vl);\n        vint32m1_t vec_A_prev = vle32_v_i32m1(&A[i], vl);\n\n        // Compute the difference between consecutive elements\n        vint32m1_t vec_diff = vsub_vv_i32m1(vec_A_curr, vec_A_prev, vl);\n\n        // Load the condition array\n        vbool8_t vec_cond = vle8_v_b8(&cond[i + 1], vl);\n\n        // Convert the difference to float\n        vfloat32m1_t vec_diff_float = vfcvt_f_x_v_f32m1(vec_diff, vl);\n\n        // Apply the condition: set diff[i] to 0.0f if cond[i] is false\n        vfloat32m1_t vec_result = vmv_v_x_f32m1(0.0f, vl);\n        vec_result = vmerge_vvm_f32m1(vec_cond, vec_diff_float, vec_result, vl);\n\n        // Store the result in the diff array\n        vse32_v_f32m1(&diff[i + 1], vec_result, vl);\n\n        // Increment the index by the vector length\n        i += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_58_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid conditional_diff_simd(const int32_t* A, const bool* cond, float* diff, size_t size) {\n    size_t vl;\n    size_t i = 0;\n\n    // Set the first element of diff to 0.0f\n    diff[0] = 0.0f;\n\n    while (i < size - 1) {\n        // Determine the vector length for this iteration\n        vl = vsetvl_e32m1(size - i);\n\n        // Load the current and previous elements of A\n        vint32m1_t vec_A = vle32_v_i32m1(&A[i], vl);\n        vint32m1_t vec_A_prev = vle32_v_i32m1(&A[i - 1], vl);\n\n        // Load the condition array\n        vbool8_t vec_cond = vle8_v_b8(&cond[i], vl);\n\n        // Compute the difference (A[i] - A[i-1])\n        vint32m1_t vec_diff_int = vsub_vv_i32m1(vec_A, vec_A_prev, vl);\n\n        // Convert the difference to float\n        vfloat32m1_t vec_diff_float = vfcvt_f_x_v_f32m1(vec_diff_int, vl);\n\n        // Apply the condition: set diff[i] to 0.0f if cond[i] is false\n        vfloat32m1_t vec_result = vmv_v_x_f32m1(0.0f, vl); // Initialize with 0.0f\n        vec_result = vmerge_vvm_f32m1(vec_cond, vec_diff_float, vec_result, vl);\n\n        // Store the result in the destination array\n        vse32_v_f32m1(&diff[i], vec_result, vl);\n\n        // Move to the next chunk\n        i += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_58_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid conditional_diff_simd(const int32_t* A, const bool* cond, float* diff, size_t size) {\n    size_t vl;\n    size_t i = 0;\n\n    // Set the first element of diff to 0.0f\n    diff[0] = 0.0f;\n\n    while (i < size - 1) {\n        vl = vsetvl_e32m1(size - i); // Set vector length for 32-bit integers\n\n        // Load current and previous elements of A\n        vint32m1_t vec_A = vle32_v_i32m1(&A[i], vl);\n        vint32m1_t vec_A_prev = vle32_v_i32m1(&A[i - 1], vl);\n\n        // Compute the difference\n        vint32m1_t vec_diff = vsub_vv_i32m1(vec_A, vec_A_prev, vl);\n\n        // Load condition array\n        vbool8_t vec_cond = vle8_v_b8(&cond[i], vl);\n\n        // Masked conversion to float\n        vfloat32m1_t vec_diff_float = vfcvt_f_x_v_f32m1(vec_diff, vl);\n        vfloat32m1_t vec_result = vmv_v_x_f32m1(0.0f, vl); // Initialize result with 0.0f\n        vec_result = vmerge_vvm_f32m1(vec_cond, vec_diff_float, vec_result, vl);\n\n        // Store the result in diff\n        vse32_v_f32m1(&diff[i], vec_result, vl);\n\n        i += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_58_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid conditional_diff_simd(const int32_t* A, const bool* cond, float* diff, size_t size) {\n    size_t vl;\n    size_t i = 0;\n\n    // Set the first element of diff to 0.0f\n    diff[0] = 0.0f;\n\n    while (i < size - 1) {\n        // Load vector length for the current chunk\n        vl = vsetvl_e32m1(size - i);\n\n        // Load the current and previous elements of A\n        vint32m1_t vec_A = vle32_v_i32m1(&A[i], vl);\n        vint32m1_t vec_A_prev = vle32_v_i32m1(&A[i - 1], vl);\n\n        // Compute the difference\n        vint32m1_t vec_diff = vsub_vv_i32m1(vec_A, vec_A_prev, vl);\n\n        // Load the condition vector\n        vbool8_t vec_cond = vle8_v_b8(&cond[i], vl);\n\n        // Mask the difference based on the condition\n        vint32m1_t vec_masked_diff = vmul_vx_i32m1(vec_diff, vec_cond, vl);\n\n        // Convert the masked difference to float\n        vfloat32m1_t vec_float_diff = vfcvt_f_x_v_f32m1(vec_masked_diff, vl);\n\n        // Store the result in the diff array\n        vse32_v_f32m1(&diff[i], vec_float_diff, vl);\n\n        // Increment the index by the vector length\n        i += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_59_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid widening_uint_simd(const uint32_t* src, uint64_t* dst, size_t length) {\n    size_t vl;\n    size_t processed = 0;\n\n    while (processed < length) {\n        vl = vsetvl_e32m1(length - processed); // Set vector length for 32-bit elements\n        vuint32m1_t v_src = vle32_v_u32m1(src + processed, vl); // Load 32-bit source elements\n        vuint64m2_t v_dst = vwadd_vx_u64m2(v_src, 0xFFFFFFFF00000000ULL, vl); // Widen and set high 32 bits to 1\n        vse64_v_u64m2(dst + processed, v_dst, vl); // Store the results in destination\n        processed += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_59_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid widening_uint_simd(const uint32_t* src, uint64_t* dst, size_t length) {\n    size_t vl;\n    size_t i = 0;\n\n    while (i < length) {\n        vl = vsetvl_e32m1(length - i); // Set vector length for 32-bit elements\n        vuint32m1_t v_src = vle32_v_u32m1(src + i, vl); // Load 32-bit source elements\n        vuint64m2_t v_dst = vwadd_vx_u64m2(v_src, 0xFFFFFFFF00000000ULL, vl); // Widen and set high 32 bits to 1\n        vse64_v_u64m2(dst + i, v_dst, vl); // Store the results in destination array\n        i += vl; // Increment index by vector length\n    }\n}\n```"}
{"task_id": "SimdBench_59_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid widening_uint_simd(const uint32_t* src, uint64_t* dst, size_t length) {\n    size_t vl;\n    size_t i = 0;\n\n    while (i < length) {\n        vl = vsetvl_e32m1(length - i); // Set vector length for 32-bit elements\n        vuint32m1_t v_src = vle32_v_u32m1(src + i, vl); // Load 32-bit source elements\n        vuint64m2_t v_dst = vwadd_vx_u64m2(v_src, 0xFFFFFFFF00000000ULL, vl); // Widen and set high 32 bits to 1\n        vse64_v_u64m2(dst + i, v_dst, vl); // Store widened results to destination\n        i += vl; // Increment index by vector length\n    }\n}\n```"}
{"task_id": "SimdBench_59_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid widening_uint_simd(const uint32_t* src, uint64_t* dst, size_t length) {\n    size_t vl;\n    size_t i = 0;\n\n    while (i < length) {\n        vl = vsetvl_e32m1(length - i); // Set vector length for 32-bit elements\n        vuint32m1_t v_src = vle32_v_u32m1(src + i, vl); // Load 32-bit unsigned integers from src\n        vuint64m2_t v_dst = vwadd_vx_u64m2(v_src, 0xFFFFFFFF00000000ULL, vl); // Widen and set high 32 bits to 1\n        vse64_v_u64m2(dst + i, v_dst, vl); // Store the results in dst\n        i += vl; // Increment index by vector length\n    }\n}\n```"}
{"task_id": "SimdBench_59_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid widening_uint_simd(const uint32_t* src, uint64_t* dst, size_t length) {\n    size_t vl;\n    size_t i = 0;\n\n    while (i < length) {\n        vl = vsetvl_e32m1(length - i); // Set vector length for 32-bit elements\n        vuint32m1_t v_src = vle32_v_u32m1(src + i, vl); // Load 32-bit unsigned integers from src\n        vuint64m2_t v_dst = vwadd_vx_u64m2(v_src, 0xFFFFFFFF00000000ULL, vl); // Widen and set high 32 bits to 1\n        vse64_v_u64m2(dst + i, v_dst, vl); // Store the result into dst\n        i += vl; // Increment index by the vector length\n    }\n}\n```"}
{"task_id": "SimdBench_60_RVV", "completion": "```c\n#include <riscv_vector.h>\n\ndouble indexed_sum_simd(const double* vec, const int16_t* index, size_t length) {\n    size_t vl;\n    double sum = 0.0;\n\n    // Initialize the accumulator vector to zero\n    vfloat64m1_t v_sum = vfmv_v_f_f64m1(0.0, vsetvlmax_e64m1());\n\n    for (size_t i = 0; i < length; i += vl) {\n        // Determine the vector length for this iteration\n        vl = vsetvl_e16m1(length - i);\n\n        // Load indices and mask out-of-range values\n        vint16m1_t v_index = vle16_v_i16m1(index + i, vl);\n        vbool16_t mask = vmflt_vx_i16m1_b16(v_index, length, vl);\n\n        // Gather elements from vec using valid indices\n        vfloat64m1_t v_values = vluxei64_v_f64m1(vec, v_index, vl);\n\n        // Apply mask to ignore invalid indices\n        v_values = vmerge_vvm_f64m1(mask, v_values, vfmv_v_f_f64m1(0.0, vl), vl);\n\n        // Accumulate the sum\n        v_sum = vfadd_vv_f64m1(v_sum, v_values, vl);\n    }\n\n    // Reduce the accumulated vector sum to a scalar\n    sum = vfredsum_vs_f64m1_f64m1(v_sum, vfmv_v_f_f64m1(0.0, vsetvlmax_e64m1()), vsetvlmax_e64m1());\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_60_RVV", "completion": "```c\n#include <riscv_vector.h>\n\ndouble indexed_sum_simd(const double* vec, const int16_t* index, size_t length) {\n    size_t vl;\n    double sum = 0.0;\n\n    for (size_t i = 0; i < length; i += vl) {\n        vl = vsetvl_e16m1(length - i); // Set vector length for 16-bit indices\n        vint16m1_t index_vec = vle16_v_i16m1(index + i, vl); // Load index array\n        vbool16_t mask = vmseq_vx_i16m1_b16(index_vec, index_vec, vl); // Mask for valid indices (always true here)\n        vfloat64m1_t vec_values = vluxei16_v_f64m1(vec, index_vec, vl); // Gather elements from vec using indices\n        vfloat64m1_t masked_values = vmerge_vvm_f64m1(mask, vec_values, vfmv_v_f_f64m1(0.0, vl), vl); // Apply mask\n        sum += vfmv_s_f_f64m1(vfredsum_vs_f64m1_f64m1(masked_values, masked_values, vfmv_v_f_f64m1(0.0, vl), vl)); // Reduce sum\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_60_RVV", "completion": "```c\n#include <riscv_vector.h>\n\ndouble indexed_sum_simd(const double* vec, const int16_t* index, size_t length) {\n    size_t vl;\n    double sum = 0.0;\n    vfloat64m1_t sum_vec = vfmv_v_f_f64m1(0.0, vsetvlmax_e64m1()); // Initialize vector sum to 0\n\n    for (size_t i = 0; i < length; i += vl) {\n        vl = vsetvl_e16m1(length - i); // Set vector length based on remaining elements\n        vint16m1_t index_vec = vle16_v_i16m1(&index[i], vl); // Load index array\n        vbool16_t mask = vmseq_vx_i16m1_b16(index_vec, index_vec, vl); // Mask for valid indices\n        vfloat64m1_t vec_values = vluxei16_v_f64m1(vec, index_vec, vl); // Gather elements from vec\n        sum_vec = vfadd_vv_f64m1(sum_vec, vec_values, vl); // Accumulate into sum_vec\n    }\n\n    sum = vfmv_f_s_f64m1_f64(sum_vec); // Reduce vector sum to scalar\n    return sum;\n}\n```"}
{"task_id": "SimdBench_60_RVV", "completion": "```c\n#include <riscv_vector.h>\n\ndouble indexed_sum_simd(const double* vec, const int16_t* index, size_t length) {\n    size_t vl;\n    double sum = 0.0;\n\n    for (size_t i = 0; i < length; i += vl) {\n        vl = vsetvl_e16m1(length - i); // Set vector length for 16-bit integers\n        vint16m1_t index_vec = vle16_v_i16m1(index + i, vl); // Load indices\n        vbool16_t mask = vmflt_vx_i16m1_b16(index_vec, length, vl); // Mask for valid indices (< length)\n        vuint16m1_t masked_indices = vmerge_vvm_u16m1(mask, index_vec, vmv_v_x_u16m1(0, vl), vl); // Masked indices\n\n        vl = vsetvl_e64m1(length - i); // Set vector length for 64-bit floats\n        vfloat64m1_t vec_values = vluxei64_v_f64m1(vec, masked_indices, vl); // Gather values from vec using masked indices\n        sum += vfmv_f_s_f64m1_f64(vfredsum_vs_f64m1_f64m1(vec_values, vec_values, 0.0, vl)); // Reduce sum\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_60_RVV", "completion": "```c\n#include <riscv_vector.h>\n\ndouble indexed_sum_simd(const double* vec, const int16_t* index, size_t length) {\n    size_t vl;\n    double sum = 0.0;\n\n    while (length > 0) {\n        vl = vsetvl_e16m1(length); // Set vector length for 16-bit integers\n        vuint16m1_t indices = vle16_v_u16m1(index, vl); // Load indices\n        vbool16_t mask = vmflt_vx_u16m1_b16(indices, length, vl); // Mask for valid indices (index < length)\n        vfloat64m1_t values = vluxei64_v_f64m1(vec, indices, vl); // Gather values from vec using indices\n        vfloat64m1_t masked_values = vmerge_vvm_f64m1(mask, values, vfmv_v_f_f64m1(0.0, vl), vl); // Apply mask\n        sum += vfredsum_vs_f64m1_f64m1(masked_values, masked_values, vfmv_s_f_f64m1(0.0), vl); // Reduce sum\n        index += vl;\n        length -= vl;\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_61_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid simple_conv2d_simd(const double* input, const double* kernel, double * output, size_t input_size, size_t kernel_size) {\n    size_t output_size = input_size - kernel_size + 1;\n    size_t kernel_elems = kernel_size * kernel_size;\n\n    for (size_t i = 0; i < output_size; i++) {\n        for (size_t j = 0; j < output_size; j++) {\n            double sum = 0.0;\n\n            for (size_t ki = 0; ki < kernel_size; ki++) {\n                size_t input_row = i + ki;\n                size_t input_col_start = j;\n                size_t input_col_end = j + kernel_size;\n\n                size_t input_offset = input_row * input_size + input_col_start;\n                size_t kernel_offset = ki * kernel_size;\n\n                size_t vl = vsetvl_e64m1(kernel_size);\n                while (input_col_start < input_col_end) {\n                    vl = vsetvl_e64m1(input_col_end - input_col_start);\n\n                    vfloat64m1_t input_vec = vle64_v_f64m1(&input[input_offset], vl);\n                    vfloat64m1_t kernel_vec = vle64_v_f64m1(&kernel[kernel_offset], vl);\n\n                    vfloat64m1_t prod_vec = vfmul_vv_f64m1(input_vec, kernel_vec, vl);\n                    sum += vfredsum_vs_f64m1_f64m1(prod_vec, prod_vec, vl);\n\n                    input_offset += vl;\n                    kernel_offset += vl;\n                    input_col_start += vl;\n                }\n            }\n\n            // Apply ReLU activation\n            output[i * output_size + j] = sum > 0.0 ? sum : 0.0;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_61_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid simple_conv2d_simd(const double* input, const double* kernel, double * output, size_t input_size, size_t kernel_size) {\n    size_t output_size = input_size - kernel_size + 1;\n    size_t kernel_elems = kernel_size * kernel_size;\n\n    for (size_t i = 0; i < output_size; i++) {\n        for (size_t j = 0; j < output_size; j++) {\n            double sum = 0.0;\n\n            for (size_t ki = 0; ki < kernel_size; ki++) {\n                size_t input_row_start = (i + ki) * input_size + j;\n                size_t kernel_row_start = ki * kernel_size;\n\n                size_t vl = vsetvl_e64(kernel_size);\n                for (size_t kj = 0; kj < kernel_size; kj += vl) {\n                    vl = vsetvl_e64(kernel_size - kj);\n\n                    vfloat64m1_t input_vec = vle64_v_f64m1(&input[input_row_start + kj], vl);\n                    vfloat64m1_t kernel_vec = vle64_v_f64m1(&kernel[kernel_row_start + kj], vl);\n\n                    vfloat64m1_t prod_vec = vfmul_vv_f64m1(input_vec, kernel_vec, vl);\n                    sum += vfredsum_vs_f64m1_f64m1(vundefined_f64m1(), prod_vec, vundefined_f64m1(), vl);\n                }\n            }\n\n            // Apply ReLU activation\n            output[i * output_size + j] = sum > 0.0 ? sum : 0.0;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_61_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid simple_conv2d_simd(const double* input, const double* kernel, double * output, size_t input_size, size_t kernel_size) {\n    size_t output_size = input_size - kernel_size + 1;\n    size_t kernel_area = kernel_size * kernel_size;\n\n    for (size_t i = 0; i < output_size; i++) {\n        for (size_t j = 0; j < output_size; j++) {\n            double sum = 0.0;\n            size_t vl;\n            for (size_t ki = 0; ki < kernel_size; ki++) {\n                for (size_t kj = 0; kj < kernel_size; kj += vl) {\n                    // Load kernel values\n                    vl = vsetvl_e64m1(kernel_size - kj);\n                    vfloat64m1_t kernel_vec = vle64_v_f64m1(&kernel[ki * kernel_size + kj], vl);\n\n                    // Load input values\n                    size_t input_idx = (i + ki) * input_size + (j + kj);\n                    vfloat64m1_t input_vec = vle64_v_f64m1(&input[input_idx], vl);\n\n                    // Multiply and accumulate\n                    vfloat64m1_t prod_vec = vfmul_vv_f64m1(input_vec, kernel_vec, vl);\n                    sum += vfredsum_vs_f64m1_f64m1(vundefined_f64m1(), prod_vec, vl);\n                }\n            }\n            // Apply ReLU activation\n            output[i * output_size + j] = sum > 0.0 ? sum : 0.0;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_61_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid simple_conv2d_simd(const double* input, const double* kernel, double * output, size_t input_size, size_t kernel_size) {\n    size_t output_size = input_size - kernel_size + 1;\n    size_t kernel_elems = kernel_size * kernel_size;\n\n    for (size_t out_row = 0; out_row < output_size; out_row++) {\n        for (size_t out_col = 0; out_col < output_size; out_col++) {\n            double sum = 0.0;\n            size_t vl = vsetvl_e64(kernel_elems); // Set vector length for kernel elements\n            vfloat64m1_t sum_vec = vfmv_v_f_f64m1(0.0, vl); // Initialize sum vector to 0\n\n            for (size_t k_row = 0; k_row < kernel_size; k_row++) {\n                size_t input_row_start = (out_row + k_row) * input_size + out_col;\n                const double* input_ptr = &input[input_row_start];\n                const double* kernel_ptr = &kernel[k_row * kernel_size];\n\n                size_t vl = vsetvl_e64(kernel_size); // Set vector length for current kernel row\n                vfloat64m1_t input_vec = vle64_v_f64m1(input_ptr, vl); // Load input row\n                vfloat64m1_t kernel_vec = vle64_v_f64m1(kernel_ptr, vl); // Load kernel row\n                sum_vec = vfmacc_vv_f64m1(sum_vec, input_vec, kernel_vec, vl); // Multiply-accumulate\n            }\n\n            sum = vfredsum_vs_f64m1_f64m1(vundefined_f64m1(), sum_vec, sum_vec, vl); // Reduce sum vector\n            sum = sum < 0.0 ? 0.0 : sum; // Apply ReLU activation\n            output[out_row * output_size + out_col] = sum; // Store result in output\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_61_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid simple_conv2d_simd(const double* input, const double* kernel, double * output, size_t input_size, size_t kernel_size) {\n    size_t output_size = input_size - kernel_size + 1;\n    size_t kernel_elements = kernel_size * kernel_size;\n\n    for (size_t i = 0; i < output_size; i++) {\n        for (size_t j = 0; j < output_size; j++) {\n            double sum = 0.0;\n\n            for (size_t ki = 0; ki < kernel_size; ki++) {\n                size_t input_row = i + ki;\n                size_t input_col_start = j;\n\n                size_t kernel_row_start = ki * kernel_size;\n\n                size_t vl = vsetvl_e64m1(kernel_size);\n                vfloat64m1_t input_vec = vle64_v_f64m1(&input[input_row * input_size + input_col_start], vl);\n                vfloat64m1_t kernel_vec = vle64_v_f64m1(&kernel[kernel_row_start], vl);\n\n                vfloat64m1_t mul_vec = vfmul_vv_f64m1(input_vec, kernel_vec, vl);\n                sum += vfredsum_vs_f64m1_f64m1(vundefined_f64m1(), mul_vec, sum, vl);\n            }\n\n            // Apply ReLU activation\n            output[i * output_size + j] = sum > 0.0 ? sum : 0.0;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_62_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <cmath>\n\nbool has_close_elements_simd(const std::vector<double> &numbers, double threshold) {\n    size_t n = numbers.size();\n    if (n < 2) return false;\n\n    size_t vlmax = vsetvlmax_e64m1(); // Maximum vector length for double precision\n    for (size_t i = 0; i < n; i++) {\n        double current = numbers[i];\n        size_t remaining = n - i - 1;\n        size_t vl = vsetvl_e64m1(remaining); // Set vector length based on remaining elements\n\n        // Load the remaining elements into a vector\n        vfloat64m1_t vec = vle64_v_f64m1(&numbers[i + 1], vl);\n\n        // Broadcast the current element to a vector\n        vfloat64m1_t current_vec = vfmv_v_f_f64m1(current, vl);\n\n        // Compute the absolute difference\n        vfloat64m1_t diff = vfsub_vv_f64m1(vec, current_vec, vl);\n        vfloat64m1_t abs_diff = vfabs_v_f64m1(diff, vl);\n\n        // Compare the differences with the threshold\n        vbool64_t mask = vmflt_vf_f64m1_b64(abs_diff, threshold, vl);\n\n        // Check if any element satisfies the condition\n        if (vfirst_m_b64(mask) >= 0) {\n            return true;\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_62_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <cmath>\n\nbool has_close_elements_simd(const std::vector<double> &numbers, double threshold) {\n    size_t n = numbers.size();\n    if (n < 2) {\n        return false;\n    }\n\n    size_t vlmax = vsetvlmax_e64m1(); // Maximum vector length for 64-bit elements\n    for (size_t i = 0; i < n; i++) {\n        double current = numbers[i];\n        size_t remaining = n - i - 1;\n        size_t vl = vsetvl_e64m1(remaining); // Set vector length based on remaining elements\n\n        vfloat64m1_t vec = vle64_v_f64m1(&numbers[i + 1], vl); // Load the next elements into a vector\n        vfloat64m1_t current_vec = vfmv_v_f_f64m1(current, vl); // Broadcast the current element into a vector\n        vfloat64m1_t diff_vec = vfsub_vv_f64m1(vec, current_vec, vl); // Compute differences\n        vfloat64m1_t abs_diff_vec = vfabs_v_f64m1(diff_vec, vl); // Compute absolute differences\n\n        vbool64_t mask = vmflt_vf_f64m1_b64(abs_diff_vec, threshold, vl); // Compare differences with threshold\n        if (vfirst_m_b64(mask) >= 0) { // Check if any element satisfies the condition\n            return true;\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_62_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <cmath>\n\nbool has_close_elements_simd(const std::vector<double> &numbers, double threshold) {\n    size_t n = numbers.size();\n    if (n < 2) return false;\n\n    size_t vlmax = vsetvlmax_e64m1(); // Maximum vector length for double precision\n    for (size_t i = 0; i < n; ++i) {\n        double current = numbers[i];\n        size_t remaining = n - i - 1;\n        size_t vl = vsetvl_e64m1(remaining); // Set vector length based on remaining elements\n\n        vfloat64m1_t vec = vle64_v_f64m1(&numbers[i + 1], vl); // Load remaining elements into vector\n        vfloat64m1_t diff = vfsub_vf_f64m1(vec, current, vl); // Compute differences\n        vfloat64m1_t abs_diff = vfabs_v_f64m1(diff, vl); // Compute absolute differences\n\n        vbool64_t mask = vmflt_vf_f64m1_b64(abs_diff, threshold, vl); // Check if any difference < threshold\n        if (vfirst_m_b64(mask) >= 0) { // If any element satisfies the condition\n            return true;\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_62_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <cmath>\n\nbool has_close_elements_simd(const std::vector<double> &numbers, double threshold) {\n    size_t n = numbers.size();\n    if (n < 2) return false;\n\n    size_t vlmax = vsetvlmax_e64m1(); // Maximum vector length for double precision\n    for (size_t i = 0; i < n; i++) {\n        size_t vl = vsetvl_e64m1(n - i); // Set vector length based on remaining elements\n        double base = numbers[i];\n        vfloat64m1_t vec = vle64_v_f64m1(&numbers[i + 1], vl); // Load vector from numbers[i+1] onwards\n        vfloat64m1_t base_vec = vfmv_v_f_f64m1(base, vl); // Broadcast base value to vector\n        vfloat64m1_t diff = vfsub_vv_f64m1(vec, base_vec, vl); // Compute differences\n        vfloat64m1_t abs_diff = vfabs_v_f64m1(diff, vl); // Compute absolute differences\n        vbool64_t mask = vmflt_vf_f64m1_b64(abs_diff, threshold, vl); // Compare with threshold\n        if (vfirst_m_b64(mask) >= 0) { // Check if any element satisfies the condition\n            return true;\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_62_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <cmath>\n\nbool has_close_elements_simd(const std::vector<double> &numbers, double threshold) {\n    size_t n = numbers.size();\n    if (n < 2) return false;\n\n    size_t vlmax = vsetvlmax_e64m1(); // Maximum vector length for double precision\n    for (size_t i = 0; i < n; i++) {\n        double current = numbers[i];\n        size_t remaining = n - i - 1;\n        size_t vl = vsetvl_e64m1(remaining); // Set vector length based on remaining elements\n\n        vfloat64m1_t vec = vle64_v_f64m1(&numbers[i + 1], vl); // Load remaining elements into vector\n        vfloat64m1_t diff = vfsub_vf_f64m1(vec, current, vl);  // Compute differences\n        vfloat64m1_t abs_diff = vfabs_v_f64m1(diff, vl);       // Compute absolute differences\n\n        vbool64_t mask = vmfle_vf_f64m1_b64(abs_diff, threshold, vl); // Check if differences <= threshold\n        if (vfirst_m_b64(mask) >= 0) { // Check if any element satisfies the condition\n            return true;\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_63_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <vector>\n\nbool below_zero_simd(std::vector<int> operations) {\n    size_t n = operations.size();\n    size_t vl;\n    int balance = 0;\n\n    for (size_t i = 0; i < n; i += vl) {\n        vl = vsetvl_e32m1(n - i); // Set vector length for remaining elements\n        vint32m1_t vec_ops = vle32_v_i32m1(&operations[i], vl); // Load operations into vector\n        vint32m1_t vec_balance = vmv_v_x_i32m1(balance, vl); // Broadcast current balance to vector\n        vec_balance = vadd_vv_i32m1(vec_balance, vec_ops, vl); // Add operations to balance\n\n        // Check if any balance in the vector is below zero\n        vbool32_t mask = vmslt_vx_i32m1_b32(vec_balance, 0, vl);\n        if (vfirst_m_b32(mask, vl) != -1) {\n            return true;\n        }\n\n        // Update scalar balance with the last element of the vector\n        balance = vse32_v_i32m1(vec_balance, vl)[vl - 1];\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_63_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nbool below_zero_simd(std::vector<int> operations) {\n    size_t n = operations.size();\n    size_t vlmax = vsetvlmax_e32m1(); // Maximum vector length for 32-bit integers\n    int balance = 0;\n\n    for (size_t i = 0; i < n; i += vlmax) {\n        size_t vl = vsetvl_e32m1(n - i); // Set vector length based on remaining elements\n        vint32m1_t vec_ops = vle32_v_i32m1(&operations[i], vl); // Load operations into vector\n        vint32m1_t vec_balance = vmv_v_x_i32m1(balance, vl); // Initialize balance vector\n\n        vec_balance = vadd_vv_i32m1(vec_balance, vec_ops, vl); // Update balance vector\n        vbool32_t mask = vmslt_vx_i32m1_b32(vec_balance, 0, vl); // Check if balance < 0\n\n        if (vfirst_m_b32(mask) != -1) { // If any element in mask is true\n            return true;\n        }\n\n        balance = vmv_x_s_i32m1_i32(vec_balance); // Extract the last balance value\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_63_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nbool below_zero_simd(std::vector<int> operations) {\n    size_t n = operations.size();\n    size_t vlmax = vsetvlmax_e32m1(); // Maximum vector length for 32-bit integers\n    int balance = 0;\n\n    for (size_t i = 0; i < n; i += vlmax) {\n        size_t vl = vsetvl_e32m1(n - i); // Set vector length based on remaining elements\n        vint32m1_t vec_ops = vle32_v_i32m1(&operations[i], vl); // Load operations into vector\n        vint32m1_t vec_balance = vadd_vx_i32m1(vec_ops, balance, vl); // Add balance to operations\n\n        // Check if any element in vec_balance is below zero\n        vbool32_t mask = vmflt_vx_i32m1_b32(vec_balance, 0, vl);\n        if (vfirst_m_b32(mask, vl) != -1) {\n            return true; // Found a negative balance\n        }\n\n        // Update scalar balance for next iteration\n        balance += vreduce_sum_vs_i32m1_i32(vec_ops, balance, vl);\n    }\n\n    return false; // No negative balance found\n}\n```"}
{"task_id": "SimdBench_63_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nbool below_zero_simd(std::vector<int> operations) {\n    size_t n = operations.size();\n    size_t vlmax = vsetvlmax_e32m1(); // Maximum vector length for 32-bit integers\n    int balance = 0;\n\n    for (size_t i = 0; i < n; i += vlmax) {\n        size_t vl = vsetvl_e32m1(n - i); // Set vector length based on remaining elements\n        vint32m1_t vec_ops = vle32_v_i32m1(&operations[i], vl); // Load operations into vector\n        vint32m1_t vec_balance = vmv_v_x_i32m1(balance, vl); // Initialize balance vector\n\n        vec_balance = vadd_vv_i32m1(vec_balance, vec_ops, vl); // Update balance vector\n\n        // Check if any element in the balance vector is below zero\n        vbool32_t mask = vmslt_vx_i32m1_b32(vec_balance, 0, vl);\n        if (vfirst_m_b32(mask, vl) != -1) { // If any element is below zero\n            return true;\n        }\n\n        // Update scalar balance for the next iteration\n        balance = vmv_x_s_i32m1_i32(vec_balance);\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_63_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <vector>\n\nbool below_zero_simd(std::vector<int> operations) {\n    size_t n = operations.size();\n    size_t vlmax = vsetvlmax_e32m1(); // Maximum vector length for 32-bit integers\n    int balance = 0;\n\n    for (size_t i = 0; i < n; ) {\n        size_t vl = vsetvl_e32m1(n - i); // Set vector length based on remaining elements\n        vint32m1_t vec_ops = vle32_v_i32m1(&operations[i], vl); // Load operations into vector\n        vint32m1_t vec_balance = vmv_v_x_i32m1(balance, vl); // Broadcast current balance\n\n        vec_balance = vadd_vv_i32m1(vec_balance, vec_ops, vl); // Update balance vector\n        vbool32_t mask = vmslt_vx_i32m1_b32(vec_balance, 0, vl); // Check if balance < 0\n\n        if (vfirst_m_b32(mask) != -1) { // If any element in the mask is true\n            return true;\n        }\n\n        balance = vmv_x_s_i32m1_i32(vslide1down_vx_i32m1(vec_balance, 0, vl)); // Update scalar balance\n        i += vl; // Move to the next chunk\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_64_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <numeric>\n#include <cmath>\n\ndouble mean_absolute_deviation_simd(std::vector<double> numbers) {\n    size_t n = numbers.size();\n    if (n == 0) return 0.0;\n\n    // Calculate mean\n    double sum = std::accumulate(numbers.begin(), numbers.end(), 0.0);\n    double mean = sum / n;\n\n    // Prepare for RVV processing\n    size_t vlmax = vsetvlmax_e64m1(); // Maximum vector length for 64-bit elements\n    size_t i = 0;\n    double mad_sum = 0.0;\n\n    while (i < n) {\n        size_t vl = vsetvl_e64m1(n - i); // Set vector length based on remaining elements\n        vfloat64m1_t v_numbers = vle64_v_f64m1(&numbers[i], vl); // Load vector of numbers\n        vfloat64m1_t v_mean = vfmv_v_f_f64m1(mean, vl); // Broadcast mean to vector\n        vfloat64m1_t v_diff = vfsub_vv_f64m1(v_numbers, v_mean, vl); // Subtract mean\n        vfloat64m1_t v_abs_diff = vfabs_v_f64m1(v_diff, vl); // Absolute difference\n        mad_sum += vfredsum_vs_f64m1_f64m1(v_abs_diff, v_abs_diff, vl); // Reduce sum\n        i += vl; // Move to next chunk\n    }\n\n    return mad_sum / n; // Divide by number of elements to get MAD\n}\n```"}
{"task_id": "SimdBench_64_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <cmath>\n\ndouble mean_absolute_deviation_simd(std::vector<double> numbers) {\n    size_t n = numbers.size();\n    if (n == 0) return 0.0;\n\n    // Step 1: Calculate the mean\n    double mean = 0.0;\n    size_t vl;\n    size_t i = 0;\n    vfloat64m1_t v_sum = vfmv_v_f_f64m1(0.0, vsetvlmax_e64m1());\n\n    while (i < n) {\n        vl = vsetvl_e64m1(n - i);\n        vfloat64m1_t v_data = vle64_v_f64m1(&numbers[i], vl);\n        v_sum = vfadd_vv_f64m1(v_sum, v_data, vl);\n        i += vl;\n    }\n\n    double sum = 0.0;\n    vfloat64m1_t v_temp = v_sum;\n    vl = vsetvl_e64m1(1);\n    while (vl > 0) {\n        sum += vfmv_f_s_f64m1_f64(v_temp);\n        v_temp = vslide1down_vx_f64m1(v_temp, 0, vl);\n        vl = vsetvl_e64m1(vl - 1);\n    }\n\n    mean = sum / n;\n\n    // Step 2: Calculate the Mean Absolute Deviation (MAD)\n    double mad = 0.0;\n    i = 0;\n    vfloat64m1_t v_mad_sum = vfmv_v_f_f64m1(0.0, vsetvlmax_e64m1());\n\n    while (i < n) {\n        vl = vsetvl_e64m1(n - i);\n        vfloat64m1_t v_data = vle64_v_f64m1(&numbers[i], vl);\n        vfloat64m1_t v_diff = vfsub_vf_f64m1(v_data, mean, vl);\n        vfloat64m1_t v_abs_diff = vfabs_v_f64m1(v_diff, vl);\n        v_mad_sum = vfadd_vv_f64m1(v_mad_sum, v_abs_diff, vl);\n        i += vl;\n    }\n\n    double mad_sum = 0.0;\n    v_temp = v_mad_sum;\n    vl = vsetvl_e64m1(1);\n    while (vl > 0) {\n        mad_sum += vfmv_f_s_f64m1_f64(v_temp);\n        v_temp = vslide1down_vx_f64m1(v_temp, 0, vl);\n        vl = vsetvl_e64m1(vl - 1);\n    }\n\n    mad = mad_sum / n;\n\n    return mad;\n}\n```"}
{"task_id": "SimdBench_64_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <cmath>\n\ndouble mean_absolute_deviation_simd(std::vector<double> numbers) {\n    size_t n = numbers.size();\n    if (n == 0) return 0.0;\n\n    // Step 1: Calculate the mean\n    double sum = 0.0;\n    size_t vl;\n    size_t i = 0;\n\n    while (i < n) {\n        vl = vsetvl_e64m1(n - i); // Set vector length\n        vfloat64m1_t vec = vle64_v_f64m1(&numbers[i], vl); // Load vector\n        sum += vfmv_f_s_f64m1_f64(vfredsum_vs_f64m1_f64m1(vundefined_f64m1(), vec, vec, vl)); // Reduce sum\n        i += vl;\n    }\n\n    double mean = sum / n;\n\n    // Step 2: Calculate the Mean Absolute Deviation\n    double mad_sum = 0.0;\n    i = 0;\n\n    while (i < n) {\n        vl = vsetvl_e64m1(n - i); // Set vector length\n        vfloat64m1_t vec = vle64_v_f64m1(&numbers[i], vl); // Load vector\n        vfloat64m1_t diff = vfsub_vf_f64m1(vec, mean, vl); // Subtract mean\n        vfloat64m1_t abs_diff = vfabs_v_f64m1(diff, vl); // Absolute value\n        mad_sum += vfmv_f_s_f64m1_f64(vfredsum_vs_f64m1_f64m1(vundefined_f64m1(), abs_diff, abs_diff, vl)); // Reduce sum\n        i += vl;\n    }\n\n    return mad_sum / n;\n}\n```"}
{"task_id": "SimdBench_64_RVV", "completion": "```c++\n#include <riscv_vector.h>\n#include <vector>\n#include <cmath>\n\ndouble mean_absolute_deviation_simd(std::vector<double> numbers) {\n    size_t n = numbers.size();\n    if (n == 0) return 0.0;\n\n    // Step 1: Calculate the mean\n    double sum = 0.0;\n    size_t vlmax = vsetvlmax_e64m1(); // Maximum vector length for 64-bit elements\n    size_t i = 0;\n\n    for (; i < n; ) {\n        size_t vl = vsetvl_e64m1(n - i); // Set vector length for remaining elements\n        vfloat64m1_t vec = vle64_v_f64m1(&numbers[i], vl); // Load vector\n        sum += vfmv_f_s_f64m1_f64(vfredsum_vs_f64m1_f64m1(vundefined_f64m1(), vec, vec, vl)); // Reduce sum\n        i += vl;\n    }\n\n    double mean = sum / n;\n\n    // Step 2: Calculate the Mean Absolute Deviation\n    double mad_sum = 0.0;\n    i = 0;\n\n    for (; i < n; ) {\n        size_t vl = vsetvl_e64m1(n - i); // Set vector length for remaining elements\n        vfloat64m1_t vec = vle64_v_f64m1(&numbers[i], vl); // Load vector\n        vfloat64m1_t diff = vfsub_vf_f64m1(vec, mean, vl); // Subtract mean\n        vfloat64m1_t abs_diff = vfabs_v_f64m1(diff, vl); // Absolute value\n        mad_sum += vfmv_f_s_f64m1_f64(vfredsum_vs_f64m1_f64m1(vundefined_f64m1(), abs_diff, abs_diff, vl)); // Reduce sum\n        i += vl;\n    }\n\n    return mad_sum / n;\n}\n```"}
{"task_id": "SimdBench_64_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\ndouble mean_absolute_deviation_simd(std::vector<double> numbers) {\n    size_t n = numbers.size();\n    if (n == 0) return 0.0;\n\n    // Calculate mean\n    double mean = 0.0;\n    size_t vlmax = vsetvlmax_e64m1();\n    size_t i = 0;\n    vfloat64m1_t v_sum = vfmv_v_f_f64m1(0.0, vlmax);\n    for (; i < n; i += vlmax) {\n        size_t vl = vsetvl_e64m1(n - i);\n        vfloat64m1_t v_data = vle64_v_f64m1(&numbers[i], vl);\n        v_sum = vfadd_vv_f64m1(v_sum, v_data, vl);\n    }\n    mean = vfmv_f_s_f64m1(vfredsum_vs_f64m1_f64m1(v_sum, v_sum, vlmax)) / n;\n\n    // Calculate Mean Absolute Deviation\n    double mad = 0.0;\n    i = 0;\n    vfloat64m1_t v_mad_sum = vfmv_v_f_f64m1(0.0, vlmax);\n    for (; i < n; i += vlmax) {\n        size_t vl = vsetvl_e64m1(n - i);\n        vfloat64m1_t v_data = vle64_v_f64m1(&numbers[i], vl);\n        vfloat64m1_t v_diff = vfsub_vf_f64m1(v_data, mean, vl);\n        vfloat64m1_t v_abs_diff = vfabs_v_f64m1(v_diff, vl);\n        v_mad_sum = vfadd_vv_f64m1(v_mad_sum, v_abs_diff, vl);\n    }\n    mad = vfmv_f_s_f64m1(vfredsum_vs_f64m1_f64m1(v_mad_sum, v_mad_sum, vlmax)) / n;\n\n    return mad;\n}\n```"}
{"task_id": "SimdBench_65_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> intersperse_simd(std::vector<int> numbers, int delimeter) {\n    size_t n = numbers.size();\n    if (n == 0) return {};\n\n    size_t result_size = 2 * n - 1;\n    std::vector<int> result(result_size);\n\n    size_t vl;\n    size_t i = 0, j = 0;\n\n    while (i < n) {\n        vl = vsetvl_e32m1(n - i); // Set vector length for remaining elements\n        vint32m1_t vec_numbers = vle32_v_i32m1(&numbers[i], vl); // Load input numbers\n        vse32_v_i32m1(&result[j], vec_numbers, vl); // Store numbers into result\n\n        j += vl;\n\n        if (j < result_size) {\n            vint32m1_t vec_delimeter = vmv_v_x_i32m1(delimeter, vl); // Create vector of delimiters\n            vse32_v_i32m1(&result[j], vec_delimeter, vl); // Store delimiters into result\n            j += vl;\n        }\n\n        i += vl;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_65_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> intersperse_simd(std::vector<int> numbers, int delimeter) {\n    size_t n = numbers.size();\n    size_t result_size = 2 * n - (n > 0 ? 1 : 0);\n    std::vector<int> result(result_size);\n\n    size_t vlmax = vsetvlmax_e32m1();\n    size_t i = 0, j = 0;\n\n    while (i < n) {\n        size_t vl = vsetvl_e32m1(n - i);\n        vint32m1_t v_numbers = vle32_v_i32m1(&numbers[i], vl);\n        vint32m1_t v_delimeter = vmv_v_x_i32m1(delimeter, vl);\n\n        vse32_v_i32m1(&result[j], v_numbers, vl);\n        j += vl;\n\n        if (j < result_size) {\n            vse32_v_i32m1(&result[j], v_delimeter, vl);\n            j += vl;\n        }\n\n        i += vl;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_65_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> intersperse_simd(std::vector<int> numbers, int delimeter) {\n    size_t n = numbers.size();\n    size_t out_size = 2 * n - (n > 0 ? 1 : 0);\n    std::vector<int> result(out_size);\n\n    size_t vlmax = vsetvlmax_e32m1();\n    size_t i = 0, j = 0;\n\n    while (i < n) {\n        size_t vl = vsetvl_e32m1(n - i);\n        vint32m1_t v_numbers = vle32_v_i32m1(&numbers[i], vl);\n        vint32m1_t v_delimeters = vmv_v_x_i32m1(delimeter, vl);\n\n        vse32_v_i32m1(&result[j], v_numbers, vl);\n        j += vl;\n\n        if (j < out_size) {\n            vse32_v_i32m1(&result[j], v_delimeters, vl);\n            j += vl;\n        }\n\n        i += vl;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_65_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> intersperse_simd(std::vector<int> numbers, int delimeter) {\n    size_t n = numbers.size();\n    if (n == 0) return {};\n\n    size_t result_size = 2 * n - 1;\n    std::vector<int> result(result_size);\n\n    size_t vl;\n    size_t i = 0, j = 0;\n\n    while (i < n) {\n        vl = vsetvl_e32m1(n - i); // Set vector length\n        vint32m1_t vec_numbers = vle32_v_i32m1(&numbers[i], vl); // Load input numbers\n        vse32_v_i32m1(&result[j], vec_numbers, vl); // Store numbers into result\n\n        i += vl;\n        j += vl;\n\n        if (j < result_size) {\n            vint32m1_t vec_delimeter = vmv_v_x_i32m1(delimeter, vl); // Create vector of delimiters\n            vse32_v_i32m1(&result[j], vec_delimeter, vl); // Store delimiters into result\n            j += vl;\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_65_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> intersperse_simd(std::vector<int> numbers, int delimeter) {\n    size_t n = numbers.size();\n    size_t result_size = 2 * n - (n > 0 ? 1 : 0); // Calculate the size of the output vector\n    std::vector<int> result(result_size);\n\n    size_t vlmax = vsetvlmax_e32m1(); // Maximum vector length for 32-bit elements\n    size_t i = 0, j = 0;\n\n    while (i < n) {\n        size_t vl = vsetvl_e32m1(n - i); // Set vector length based on remaining elements\n        vint32m1_t v_numbers = vle32_v_i32m1(&numbers[i], vl); // Load elements from input vector\n        vint32m1_t v_delimeter = vmv_v_x_i32m1(delimeter, vl); // Create a vector filled with delimeter\n\n        // Scatter interspersed elements into the result vector\n        vint32m1_t v_result_indices = vid_v_i32m1(vl); // Generate indices for the result vector\n        vint32m1_t v_result_indices_shifted = vadd_vx_i32m1(v_result_indices, j); // Shift indices by current offset\n        vse32_v_i32m1(&result[j], v_numbers, vl); // Store input elements at shifted indices\n        j += vl;\n\n        if (i + vl < n) { // Add delimeters between elements\n            vint32m1_t v_delimeter_indices = vadd_vx_i32m1(v_result_indices, j);\n            vse32_v_i32m1(&result[j], v_delimeter, vl);\n            j += vl;\n        }\n\n        i += vl;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_66_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <cstdint>\n\nstd::vector<int64_t> sum_product_simd(std::vector<int16_t> numbers) {\n    size_t n = numbers.size();\n    if (n == 0) {\n        return {0, 1};\n    }\n\n    int64_t sum = 0;\n    int64_t product = 1;\n\n    size_t vlmax = vsetvlmax_e16m1();\n    size_t i = 0;\n\n    while (i < n) {\n        size_t vl = vsetvl_e16m1(n - i);\n        vint16m1_t vec = vle16_v_i16m1(&numbers[i], vl);\n\n        vint32m1_t vec_sum = vwadd_vx_i32m1(vec, 0, vl);\n        vint32m1_t vec_prod = vwmul_vx_i32m1(vec, 1, vl);\n\n        sum += vreduce_sum_vs_i32m1_i32(vec_sum, 0, vl);\n        product *= vreduce_mul_vs_i32m1_i32(vec_prod, 1, vl);\n\n        i += vl;\n    }\n\n    return {sum, product};\n}\n```"}
{"task_id": "SimdBench_66_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int64_t> sum_product_simd(std::vector<int16_t> numbers) {\n    size_t n = numbers.size();\n    if (n == 0) {\n        return {0, 1};\n    }\n\n    size_t vlmax = vsetvlmax_e16m1();\n    int64_t sum = 0;\n    int64_t product = 1;\n\n    for (size_t i = 0; i < n; i += vlmax) {\n        size_t vl = vsetvl_e16m1(n - i);\n        vint16m1_t vec = vle16_v_i16m1(&numbers[i], vl);\n\n        vint64m1_t vec_sum = vwredsum_vs_i16m1_i64m1(vundefined_i64m1(), vec, vl);\n        vint64m1_t vec_prod = vwredprod_vs_i16m1_i64m1(vundefined_i64m1(), vec, vl);\n\n        sum += vmv_x_s_i64m1_i64(vec_sum);\n        product *= vmv_x_s_i64m1_i64(vec_prod);\n    }\n\n    return {sum, product};\n}\n```"}
{"task_id": "SimdBench_66_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int64_t> sum_product_simd(std::vector<int16_t> numbers) {\n    size_t n = numbers.size();\n    if (n == 0) {\n        return {0, 1};\n    }\n\n    size_t vlmax = vsetvlmax_e16m1();\n    int64_t sum = 0;\n    int64_t product = 1;\n\n    for (size_t i = 0; i < n; i += vlmax) {\n        size_t vl = vsetvl_e16m1(n - i);\n        vint16m1_t vec = vle16_v_i16m1(&numbers[i], vl);\n\n        vint32m1_t vec_sum = vwadd_vv_i32m1(vec, vec, vl);\n        vint32m1_t vec_product = vwmul_vv_i32m1(vec, vec, vl);\n\n        sum += vreduce_sum_i32m1(vec_sum, vl);\n        product *= vreduce_prod_i32m1(vec_product, vl);\n    }\n\n    return {sum, product};\n}\n```"}
{"task_id": "SimdBench_66_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <cstdint>\n\nstd::vector<int64_t> sum_product_simd(std::vector<int16_t> numbers) {\n    size_t n = numbers.size();\n    if (n == 0) {\n        return {0, 1};\n    }\n\n    int64_t sum = 0;\n    int64_t product = 1;\n\n    size_t vlmax = vsetvlmax_e16m1(); // Maximum vector length for int16_t\n    size_t offset = 0;\n\n    while (offset < n) {\n        size_t vl = vsetvl_e16m1(n - offset); // Set vector length based on remaining elements\n        vint16m1_t vec = vle16_v_i16m1(&numbers[offset], vl); // Load vector elements\n\n        vint32m1_t vec_sum = vwredsum_vs_i16m1_i32m1(vundefined_i32m1(), vec, vl); // Reduce sum\n        vint32m1_t vec_prod = vredmul_vs_i16m1_i32m1(vundefined_i32m1(), vec, vl); // Reduce product\n\n        sum += vmv_x_s_i32m1_i32(vec_sum); // Extract sum\n        product *= vmv_x_s_i32m1_i32(vec_prod); // Extract product\n\n        offset += vl; // Move to next chunk\n    }\n\n    return {sum, product};\n}\n```"}
{"task_id": "SimdBench_66_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int64_t> sum_product_simd(std::vector<int16_t> numbers) {\n    size_t n = numbers.size();\n    if (n == 0) {\n        return {0, 1};\n    }\n\n    size_t vl;\n    int64_t sum = 0;\n    int64_t product = 1;\n\n    for (size_t i = 0; i < n; i += vl) {\n        vl = vsetvl_e16m1(n - i); // Set vector length for 16-bit integers\n        vint16m1_t vec = vle16_v_i16m1(&numbers[i], vl); // Load vector elements\n\n        vint32m1_t vec_sum = vwredsum_vs_i16m1_i32m1(vundefined_i32m1(), vec, vl); // Reduce sum\n        sum += vget_i32m1(vec_sum, 0); // Extract the sum\n\n        vint32m1_t vec_product = vwredprod_vs_i16m1_i32m1(vundefined_i32m1(), vec, vl); // Reduce product\n        product *= vget_i32m1(vec_product, 0); // Extract the product\n    }\n\n    return {sum, product};\n}\n```"}
{"task_id": "SimdBench_67_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<int> rolling_max_simd(std::vector<int> numbers) {\n    size_t n = numbers.size();\n    std::vector<int> result(n);\n\n    size_t vlmax = vsetvlmax_e32m1(); // Maximum vector length for 32-bit integers\n    size_t i = 0;\n    int current_max = INT_MIN;\n\n    while (i < n) {\n        size_t vl = vsetvl_e32m1(n - i); // Set vector length based on remaining elements\n        vint32m1_t v_numbers = vle32_v_i32m1(&numbers[i], vl); // Load vector\n        vint32m1_t v_current_max = vmv_v_x_i32m1(current_max, vl); // Initialize with current max\n\n        v_current_max = vmax_vv_i32m1(v_current_max, v_numbers, vl); // Compute max\n        vse32_v_i32m1(&result[i], v_current_max, vl); // Store result\n\n        current_max = vmv_x_s_i32m1_i32(v_current_max); // Extract last max value\n        i += vl; // Advance by vector length\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_67_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<int> rolling_max_simd(std::vector<int> numbers) {\n    size_t n = numbers.size();\n    std::vector<int> result(n);\n\n    size_t vlmax = vsetvlmax_e32m1(); // Maximum vector length for 32-bit integers\n    vint32m1_t max_vec = vmv_v_x_i32m1(INT32_MIN, vlmax); // Initialize max vector with minimum int value\n\n    size_t i = 0;\n    while (i < n) {\n        size_t vl = vsetvl_e32m1(n - i); // Set vector length based on remaining elements\n        vint32m1_t input_vec = vle32_v_i32m1(&numbers[i], vl); // Load input vector\n        max_vec = vmax_vv_i32m1(max_vec, input_vec, vl); // Compute rolling max\n        vse32_v_i32m1(&result[i], max_vec, vl); // Store result\n        i += vl; // Move to the next chunk\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_67_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<int> rolling_max_simd(std::vector<int> numbers) {\n    size_t n = numbers.size();\n    std::vector<int> result(n);\n\n    size_t vlmax = vsetvlmax_e32m1(); // Maximum vector length for 32-bit integers\n    vint32m1_t max_vec = vmv_v_x_i32m1(INT32_MIN, vlmax); // Initialize max vector with minimum integer value\n\n    for (size_t i = 0; i < n; i += vlmax) {\n        size_t vl = vsetvl_e32m1(n - i); // Set vector length based on remaining elements\n        vint32m1_t input_vec = vle32_v_i32m1(&numbers[i], vl); // Load input vector\n        max_vec = vmax_vv_i32m1(max_vec, input_vec, vl); // Compute rolling max\n        vse32_v_i32m1(&result[i], max_vec, vl); // Store result\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_67_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<int> rolling_max_simd(std::vector<int> numbers) {\n    size_t n = numbers.size();\n    std::vector<int> result(n);\n\n    size_t vlmax = vsetvlmax_e32m1(); // Maximum vector length for 32-bit integers\n    size_t i = 0;\n    int rolling_max = INT32_MIN;\n\n    while (i < n) {\n        size_t vl = vsetvl_e32m1(n - i); // Set vector length based on remaining elements\n        vint32m1_t vec = vle32_v_i32m1(&numbers[i], vl); // Load vector from input\n        vint32m1_t rolling_max_vec = vmv_v_x_i32m1(rolling_max, vl); // Initialize rolling max vector\n\n        rolling_max_vec = vmax_vv_i32m1(rolling_max_vec, vec, vl); // Compute max element-wise\n        vse32_v_i32m1(&result[i], rolling_max_vec, vl); // Store results back to output\n\n        rolling_max = vmv_x_s_i32m1_i32(rolling_max_vec); // Extract last element of rolling max vector\n        i += vl; // Move to the next chunk\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_67_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<int> rolling_max_simd(std::vector<int> numbers) {\n    size_t n = numbers.size();\n    std::vector<int> result(n);\n    size_t vlmax = vsetvlmax_e32m1(); // Maximum vector length for 32-bit integers\n    int rolling_max = INT32_MIN;\n\n    for (size_t i = 0; i < n; i += vlmax) {\n        size_t vl = vsetvl_e32m1(n - i); // Set vector length based on remaining elements\n        vint32m1_t vec = vle32_v_i32m1(&numbers[i], vl); // Load vector from input\n        vint32m1_t max_vec = vmv_v_x_i32m1(rolling_max, vl); // Initialize max vector with rolling_max\n        max_vec = vmax_vv_i32m1(max_vec, vec, vl); // Compute element-wise maximum\n        vse32_v_i32m1(&result[i], max_vec, vl); // Store result back to output vector\n        rolling_max = vreduce_max_i32m1(max_vec, vl); // Update rolling_max using vector reduction\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_68_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nstd::string string_xor_simd(std::string a, std::string b) {\n    size_t len = a.size();\n    std::string result(len, '0');\n\n    size_t vlmax = vsetvlmax_e8m1();\n    for (size_t i = 0; i < len; i += vlmax) {\n        size_t vl = vsetvl_e8m1(len - i);\n\n        vint8m1_t va = vle8_v_i8m1(reinterpret_cast<const int8_t*>(a.data() + i), vl);\n        vint8m1_t vb = vle8_v_i8m1(reinterpret_cast<const int8_t*>(b.data() + i), vl);\n\n        vint8m1_t vxor = vxor_vv_i8m1(va, vb, vl);\n\n        vse8_v_i8m1(reinterpret_cast<int8_t*>(result.data() + i), vxor, vl);\n    }\n\n    for (size_t i = 0; i < len; ++i) {\n        result[i] = (result[i] & 1) + '0';\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_68_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nstd::string string_xor_simd(std::string a, std::string b) {\n    size_t n = a.size();\n    std::string result(n, '0');\n\n    size_t vlmax = vsetvlmax_e8m1(); // Maximum vector length for 8-bit elements\n    size_t i = 0;\n\n    while (i < n) {\n        size_t vl = vsetvl_e8m1(n - i); // Set vector length based on remaining elements\n\n        vint8m1_t va = vle8_v_i8m1(reinterpret_cast<const int8_t*>(a.data() + i), vl);\n        vint8m1_t vb = vle8_v_i8m1(reinterpret_cast<const int8_t*>(b.data() + i), vl);\n        vint8m1_t vres = vxor_vv_i8m1(va, vb, vl);\n\n        vse8_v_i8m1(reinterpret_cast<int8_t*>(result.data() + i), vres, vl);\n\n        i += vl;\n    }\n\n    for (size_t j = 0; j < n; ++j) {\n        result[j] = (result[j] == 0) ? '0' : '1';\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_68_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nstd::string string_xor_simd(std::string a, std::string b) {\n    size_t n = a.size();\n    std::string result(n, '0');\n\n    size_t vlmax = vsetvlmax_e8m1();\n    for (size_t i = 0; i < n; i += vlmax) {\n        size_t vl = vsetvl_e8m1(n - i);\n        vint8m1_t va = vle8_v_i8m1(reinterpret_cast<const int8_t*>(a.data() + i), vl);\n        vint8m1_t vb = vle8_v_i8m1(reinterpret_cast<const int8_t*>(b.data() + i), vl);\n\n        vint8m1_t vxor = vxor_vv_i8m1(va, vb, vl);\n        vse8_v_i8m1(reinterpret_cast<int8_t*>(result.data() + i), vxor, vl);\n    }\n\n    for (size_t i = 0; i < n; ++i) {\n        result[i] = (result[i] == 0) ? '0' : '1';\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_68_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nstd::string string_xor_simd(std::string a, std::string b) {\n    size_t n = a.size();\n    std::string result(n, '0');\n\n    size_t vlmax = vsetvlmax_e8m1();\n    size_t i = 0;\n\n    while (i < n) {\n        size_t vl = vsetvl_e8m1(n - i);\n        vint8m1_t va = vle8_v_i8m1(reinterpret_cast<const int8_t*>(a.data() + i), vl);\n        vint8m1_t vb = vle8_v_i8m1(reinterpret_cast<const int8_t*>(b.data() + i), vl);\n\n        vint8m1_t vres = vxor_vv_i8m1(va, vb, vl);\n\n        vse8_v_i8m1(reinterpret_cast<int8_t*>(result.data() + i), vres, vl);\n        i += vl;\n    }\n\n    for (size_t j = 0; j < n; ++j) {\n        result[j] = (result[j] == 0) ? '0' : '1';\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_68_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n#include <algorithm>\n\nstd::string string_xor_simd(std::string a, std::string b) {\n    size_t n = a.size();\n    std::string result(n, '0');\n\n    size_t vlmax = vsetvlmax_e8m1(); // Maximum vector length for 8-bit elements\n    size_t i = 0;\n\n    while (i < n) {\n        size_t vl = vsetvl_e8m1(n - i); // Set vector length based on remaining elements\n\n        // Load characters as unsigned 8-bit integers\n        vuint8m1_t va = vle8_v_u8m1(reinterpret_cast<const uint8_t*>(&a[i]), vl);\n        vuint8m1_t vb = vle8_v_u8m1(reinterpret_cast<const uint8_t*>(&b[i]), vl);\n\n        // Convert '0' and '1' characters to binary values (0 and 1)\n        va = vsub_vx_u8m1(va, '0', vl);\n        vb = vsub_vx_u8m1(vb, '0', vl);\n\n        // Perform XOR operation\n        vuint8m1_t vr = vxor_vv_u8m1(va, vb, vl);\n\n        // Convert binary values back to '0' and '1' characters\n        vr = vadd_vx_u8m1(vr, '0', vl);\n\n        // Store the result\n        vse8_v_u8m1(reinterpret_cast<uint8_t*>(&result[i]), vr, vl);\n\n        i += vl;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_69_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <string>\n\nstd::string longest_simd(const std::vector<std::string> &strings) {\n    if (strings.empty()) {\n        return \"\"; // Return empty string if input vector is empty\n    }\n\n    size_t n = strings.size();\n    std::vector<size_t> lengths(n);\n    for (size_t i = 0; i < n; ++i) {\n        lengths[i] = strings[i].length();\n    }\n\n    size_t vlmax = vsetvlmax_e32m1(); // Maximum vector length for 32-bit elements\n    size_t max_length = 0;\n    size_t max_index = 0;\n\n    for (size_t i = 0; i < n; i += vlmax) {\n        size_t vl = vsetvl_e32m1(n - i); // Set vector length for remaining elements\n        vuint32m1_t v_lengths = vle32_v_u32m1(&lengths[i], vl); // Load lengths into vector\n        vbool32_t mask = vmseq_vx_u32m1_b32(v_lengths, max_length, vl); // Compare lengths with current max\n        if (vfirst_m_b32(mask, vl) != -1) {\n            max_index = i + vfirst_m_b32(mask, vl);\n            max_length = lengths[max_index];\n        }\n    }\n\n    return strings[max_index];\n}\n```"}
{"task_id": "SimdBench_69_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <string>\n\nstd::string longest_simd(const std::vector<std::string> &strings) {\n    if (strings.empty()) {\n        return \"\"; // Return empty string if input vector is empty\n    }\n\n    size_t n = strings.size();\n    std::vector<size_t> lengths(n);\n    for (size_t i = 0; i < n; ++i) {\n        lengths[i] = strings[i].size();\n    }\n\n    size_t vlmax = vsetvlmax_e32m1(); // Maximum vector length for 32-bit elements\n    size_t max_length = 0;\n    size_t max_index = 0;\n\n    for (size_t i = 0; i < n; i += vlmax) {\n        size_t vl = vsetvl_e32m1(n - i); // Set vector length for remaining elements\n        vuint32m1_t v_lengths = vle32_v_u32m1(&lengths[i], vl); // Load lengths into vector\n        vbool32_t mask = vmseq_vx_u32m1_b32(v_lengths, max_length, vl); // Compare with current max length\n\n        if (!vfirst_m_b32(mask, vl)) { // If no match, find the new max\n            vuint32m1_t v_max = vredmax_vs_u32m1(v_lengths, v_lengths, vl);\n            max_length = vget_u32m1(v_max, 0);\n        }\n    }\n\n    // Find the first string with the max length\n    for (size_t i = 0; i < n; ++i) {\n        if (strings[i].size() == max_length) {\n            return strings[i];\n        }\n    }\n\n    return \"\";\n}\n```"}
{"task_id": "SimdBench_69_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <string>\n\nstd::string longest_simd(const std::vector<std::string> &strings) {\n    if (strings.empty()) {\n        return \"\"; // Return empty string for empty input\n    }\n\n    size_t n = strings.size();\n    std::vector<size_t> lengths(n);\n    for (size_t i = 0; i < n; i++) {\n        lengths[i] = strings[i].size();\n    }\n\n    size_t max_length = 0;\n    size_t max_index = 0;\n\n    size_t vl;\n    for (size_t i = 0; i < n; i += vl) {\n        vl = vsetvl_e64m1(n - i); // Set vector length\n        vuint64m1_t vec_lengths = vle64_v_u64m1(&lengths[i], vl); // Load lengths into vector\n        vuint64m1_t vec_indices = vid_v_u64m1(vl); // Create index vector\n        vec_indices = vadd_vx_u64m1(vec_indices, i, vl); // Adjust indices for current chunk\n\n        vbool64_t mask = vmseq_vx_u64m1_b64(vec_lengths, max_length, vl); // Mask for equal lengths\n        vuint64m1_t vec_max_indices = vmerge_vvm_u64m1(mask, vec_indices, vundefined_u64m1(), vl); // Merge indices\n\n        uint64_t local_max_length = vmax_vx_u64m1(vec_lengths, max_length, vl); // Find max length\n        vbool64_t update_mask = vmseq_vx_u64m1_b64(vec_lengths, local_max_length, vl); // Mask for new max length\n        vuint64m1_t update_indices = vmerge_vvm_u64m1(update_mask, vec_indices, vundefined_u64m1(), vl); // Merge indices\n\n        max_length = local_max_length;\n        max_index = vfirst_m_b64(update_mask, vl); // Find first index of max length\n    }\n\n    return strings[max_index];\n}\n```"}
{"task_id": "SimdBench_69_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <string>\n\nstd::string longest_simd(const std::vector<std::string> &strings) {\n    if (strings.empty()) {\n        return \"\"; // Return empty string for empty input\n    }\n\n    size_t n = strings.size();\n    std::vector<size_t> lengths(n);\n    for (size_t i = 0; i < n; i++) {\n        lengths[i] = strings[i].size();\n    }\n\n    size_t max_length = 0;\n    size_t max_index = 0;\n\n    size_t vl;\n    for (size_t i = 0; i < n; i += vl) {\n        vl = vsetvl_e64m1(n - i); // Set vector length for 64-bit elements\n        vuint64m1_t v_lengths = vle64_v_u64m1(&lengths[i], vl); // Load lengths into vector\n        vuint64m1_t v_indices = vid_v_u64m1(vl); // Generate indices\n        vuint64m1_t v_max_lengths = vmv_v_x_u64m1(max_length, vl); // Broadcast current max length\n        vbool64_t mask = vmgtu_vv_u64m1_b64(v_lengths, v_max_lengths, vl); // Compare lengths\n\n        // Update max_length and max_index where mask is true\n        v_max_lengths = vmerge_vvm_u64m1(mask, v_lengths, v_max_lengths, vl);\n        vuint64m1_t v_max_indices = vmerge_vvm_u64m1(mask, v_indices, vmv_v_x_u64m1(max_index, vl), vl);\n\n        // Reduce to find the maximum length and corresponding index\n        max_length = vmaxu_vv_u64m1(v_max_lengths, vl)[0];\n        max_index = vmaxu_vv_u64m1(v_max_indices, vl)[0];\n    }\n\n    return strings[max_index];\n}\n```"}
{"task_id": "SimdBench_69_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n#include <vector>\n\nstd::string longest_simd(const std::vector<std::string> &strings) {\n    if (strings.empty()) {\n        return \"\"; // Return empty string for empty input vector\n    }\n\n    size_t n = strings.size();\n    std::vector<size_t> lengths(n);\n\n    // Compute lengths of all strings\n    for (size_t i = 0; i < n; i++) {\n        lengths[i] = strings[i].length();\n    }\n\n    size_t vlmax = vsetvlmax_e32m1(); // Maximum vector length for 32-bit integers\n    size_t max_length = 0;\n    size_t max_index = 0;\n\n    for (size_t i = 0; i < n; i += vlmax) {\n        size_t vl = vsetvl_e32m1(n - i); // Set vector length based on remaining elements\n        vint32m1_t v_lengths = vle32_v_i32m1(&lengths[i], vl); // Load lengths into vector\n        vint32m1_t v_indices = vid_v_i32m1(vl); // Generate indices vector\n\n        vint32m1_t v_max_lengths = vmv_v_x_i32m1(max_length, vl); // Initialize max lengths vector\n        vint32m1_t v_max_indices = vmv_v_x_i32m1(max_index, vl); // Initialize max indices vector\n\n        vbool32_t mask = vmsgt_vv_i32m1_b32(v_lengths, v_max_lengths, vl); // Compare lengths\n        v_max_lengths = vmerge_vvm_i32m1(mask, v_lengths, v_max_lengths, vl); // Update max lengths\n        v_max_indices = vmerge_vvm_i32m1(mask, v_indices, v_max_indices, vl); // Update max indices\n\n        max_length = vmax_vv_i32m1(v_max_lengths, vl); // Reduce to find max length\n        max_index = vmax_vv_i32m1(v_max_indices, vl); // Reduce to find max index\n    }\n\n    return strings[max_index];\n}\n```"}
{"task_id": "SimdBench_70_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nuint64_t greatest_common_divisor_simd(uint64_t a, uint64_t b) {\n    size_t vl;\n    do {\n        vl = vsetvl_e64m1(1); // Set vector length to 1 element of 64-bit integers\n        vuint64m1_t va = vundefined_u64m1();\n        vuint64m1_t vb = vundefined_u64m1();\n        va = vset_u64m1(va, 0, a, vl); // Load 'a' into vector register\n        vb = vset_u64m1(vb, 0, b, vl); // Load 'b' into vector register\n\n        vbool64_t mask = vmseq_u64m1_b64(va, vb, vl); // Check if a == b\n        if (vfirst_m_b64(mask, vl) != -1) {\n            return a; // If a == b, return a (or b)\n        }\n\n        vbool64_t mask_a_gt_b = vmsgtu_u64m1_b64(va, vb, vl); // Check if a > b\n        if (vfirst_m_b64(mask_a_gt_b, vl) != -1) {\n            a -= b; // a = a - b\n        } else {\n            b -= a; // b = b - a\n        }\n    } while (a != 0 && b != 0);\n\n    return a == 0 ? b : a; // Return the non-zero value\n}\n```"}
{"task_id": "SimdBench_70_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nuint64_t greatest_common_divisor_simd(uint64_t a, uint64_t b) {\n    while (b != 0) {\n        size_t vl = vsetvl_e64(1); // Set vector length to 1 for scalar-like operations\n        vuint64m1_t va = vle64_v_u64m1(&a, vl);\n        vuint64m1_t vb = vle64_v_u64m1(&b, vl);\n\n        vuint64m1_t vmod = vremu_vv_u64m1(va, vb, vl); // Compute a % b using vector modulo\n        vse64_v_u64m1(&a, vb, vl); // Update a = b\n        vse64_v_u64m1(&b, vmod, vl); // Update b = a % b\n    }\n    return a;\n}\n```"}
{"task_id": "SimdBench_70_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nuint64_t greatest_common_divisor_simd(uint64_t a, uint64_t b) {\n    size_t vl;\n    do {\n        vl = vsetvl_e64m1(1); // Set vector length to 1 element of 64-bit integers\n        vuint64m1_t va = vundefined_u64m1();\n        vuint64m1_t vb = vundefined_u64m1();\n        va = vset_u64m1(va, a, 0);\n        vb = vset_u64m1(vb, b, 0);\n\n        vbool64_t mask = vmseq_u64m1_b64(vb, vzero_u64m1(vl), vl);\n        if (vfirst_m_b64(mask, vl) >= 0) {\n            return a;\n        }\n\n        vuint64m1_t vtemp = vremu_vv_u64m1(va, vb, vl);\n        va = vb;\n        vb = vtemp;\n\n        a = vget_u64m1(va, 0);\n        b = vget_u64m1(vb, 0);\n    } while (b != 0);\n\n    return a;\n}\n```"}
{"task_id": "SimdBench_70_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nuint64_t greatest_common_divisor_simd(uint64_t a, uint64_t b) {\n    while (b != 0) {\n        size_t vl = vsetvlmax_e64m1();\n        uint64_t temp = b;\n\n        // Load values into vector registers\n        vuint64m1_t va = vle64_v_u64m1(&a, vl);\n        vuint64m1_t vb = vle64_v_u64m1(&b, vl);\n\n        // Perform modulo operation in parallel\n        vuint64m1_t vmod = vremu_vv_u64m1(va, vb, vl);\n\n        // Store the result back\n        vse64_v_u64m1(&a, vb, vl);\n        vse64_v_u64m1(&b, vmod, vl);\n\n        b = temp % b;\n    }\n    return a;\n}\n```"}
{"task_id": "SimdBench_70_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nuint64_t greatest_common_divisor_simd(uint64_t a, uint64_t b) {\n    while (b != 0) {\n        size_t vl = vsetvlmax_e64m1();\n        vuint64m1_t va = vmv_v_x_u64m1(a, vl);\n        vuint64m1_t vb = vmv_v_x_u64m1(b, vl);\n        vuint64m1_t vmod = vremu_vv_u64m1(va, vb, vl);\n        a = b;\n        b = vget_u64m1(vmod, 0);\n    }\n    return a;\n}\n```"}
{"task_id": "SimdBench_71_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <limits>\n#include <cmath>\n\nstd::vector<float> find_closest_elements_simd(std::vector<float> numbers) {\n    size_t n = numbers.size();\n    if (n < 2) {\n        return {}; // Return empty vector if input size is less than 2\n    }\n\n    float min_diff = std::numeric_limits<float>::max();\n    float closest_a = 0.0f, closest_b = 0.0f;\n\n    for (size_t i = 0; i < n - 1; ++i) {\n        size_t remaining = n - i - 1;\n        size_t vl = vsetvl_e32m1(remaining);\n\n        vfloat32m1_t vec_numbers = vle32_v_f32m1(&numbers[i + 1], vl);\n        vfloat32m1_t vec_current = vfmv_v_f_f32m1(numbers[i], vl);\n\n        vfloat32m1_t vec_diff = vfsub_vv_f32m1(vec_numbers, vec_current, vl);\n        vfloat32m1_t vec_abs_diff = vfabs_v_f32m1(vec_diff, vl);\n\n        float diff_array[vl];\n        vse32_v_f32m1(diff_array, vec_abs_diff, vl);\n\n        for (size_t j = 0; j < vl; ++j) {\n            if (diff_array[j] < min_diff) {\n                min_diff = diff_array[j];\n                closest_a = numbers[i];\n                closest_b = numbers[i + 1 + j];\n            }\n        }\n    }\n\n    if (closest_a > closest_b) {\n        std::swap(closest_a, closest_b);\n    }\n\n    return {closest_a, closest_b};\n}\n```"}
{"task_id": "SimdBench_71_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <limits>\n#include <cmath>\n\nstd::vector<float> find_closest_elements_simd(std::vector<float> numbers) {\n    size_t n = numbers.size();\n    if (n < 2) {\n        return {}; // Return empty vector if input size is less than 2\n    }\n\n    float min_diff = std::numeric_limits<float>::max();\n    float closest_a = 0.0f, closest_b = 0.0f;\n\n    for (size_t i = 0; i < n - 1; i++) {\n        size_t remaining = n - i - 1;\n        size_t vl = vsetvl_e32m1(remaining);\n\n        vfloat32m1_t vec_numbers = vle32_v_f32m1(&numbers[i + 1], vl);\n        vfloat32m1_t vec_base = vfmv_v_f_f32m1(numbers[i], vl);\n\n        vfloat32m1_t vec_diff = vfsub_vv_f32m1(vec_numbers, vec_base, vl);\n        vfloat32m1_t vec_abs_diff = vfabs_v_f32m1(vec_diff, vl);\n\n        float temp_min_diff = min_diff;\n        vfloat32m1_t vec_min_diff = vfmv_v_f_f32m1(temp_min_diff, vl);\n        vbool32_t mask = vmflt_vv_f32m1_b32(vec_abs_diff, vec_min_diff, vl);\n\n        if (vfirst_m_b32(mask, vl) != -1) {\n            min_diff = vfmv_f_s_f32m1(vreduce_min_v_f32m1(vec_abs_diff, vl));\n            size_t index = vfirst_m_b32(mask, vl);\n            closest_a = numbers[i];\n            closest_b = numbers[i + 1 + index];\n        }\n    }\n\n    if (closest_a > closest_b) {\n        std::swap(closest_a, closest_b);\n    }\n\n    return {closest_a, closest_b};\n}\n```"}
{"task_id": "SimdBench_71_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <cmath>\n#include <limits>\n\nstd::vector<float> find_closest_elements_simd(std::vector<float> numbers) {\n    size_t n = numbers.size();\n    if (n < 2) {\n        return {}; // Return empty if less than two elements\n    }\n\n    float min_diff = std::numeric_limits<float>::max();\n    float closest_a = 0.0f, closest_b = 0.0f;\n\n    for (size_t i = 0; i < n - 1; i++) {\n        size_t remaining = n - i - 1;\n        size_t vl = vsetvl_e32m1(remaining);\n\n        vfloat32m1_t vec_current = vfmv_v_f_f32m1(numbers[i], vl);\n        vfloat32m1_t vec_rest = vle32_v_f32m1(&numbers[i + 1], vl);\n\n        vfloat32m1_t vec_diff = vfsub_vv_f32m1(vec_rest, vec_current, vl);\n        vfloat32m1_t vec_abs_diff = vfabs_v_f32m1(vec_diff, vl);\n\n        float diffs[vl];\n        vse32_v_f32m1(diffs, vec_abs_diff, vl);\n\n        for (size_t j = 0; j < vl; j++) {\n            if (diffs[j] < min_diff) {\n                min_diff = diffs[j];\n                closest_a = numbers[i];\n                closest_b = numbers[i + 1 + j];\n            }\n        }\n    }\n\n    if (closest_a > closest_b) {\n        std::swap(closest_a, closest_b);\n    }\n\n    return {closest_a, closest_b};\n}\n```"}
{"task_id": "SimdBench_71_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <cmath>\n#include <limits>\n\nstd::vector<float> find_closest_elements_simd(std::vector<float> numbers) {\n    size_t n = numbers.size();\n    if (n < 2) return {};\n\n    float min_diff = std::numeric_limits<float>::max();\n    float closest_a = 0.0f, closest_b = 0.0f;\n\n    for (size_t i = 0; i < n - 1; i++) {\n        size_t remaining = n - i - 1;\n        size_t vl = vsetvl_e32m1(remaining);\n\n        vfloat32m1_t vec1 = vle32_v_f32m1(&numbers[i + 1], vl);\n        vfloat32m1_t vec2 = vfmv_v_f_f32m1(numbers[i], vl);\n        vfloat32m1_t diff = vfsub_vv_f32m1(vec1, vec2, vl);\n        vfloat32m1_t abs_diff = vfabs_v_f32m1(diff, vl);\n\n        float temp[vl];\n        vse32_v_f32m1(temp, abs_diff, vl);\n\n        for (size_t j = 0; j < vl; j++) {\n            if (temp[j] < min_diff) {\n                min_diff = temp[j];\n                closest_a = std::min(numbers[i], numbers[i + 1 + j]);\n                closest_b = std::max(numbers[i], numbers[i + 1 + j]);\n            }\n        }\n    }\n\n    return {closest_a, closest_b};\n}\n```"}
{"task_id": "SimdBench_71_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <limits>\n#include <cmath>\n\nstd::vector<float> find_closest_elements_simd(std::vector<float> numbers) {\n    size_t n = numbers.size();\n    if (n < 2) {\n        return {}; // Return empty vector if there are less than two elements\n    }\n\n    float min_diff = std::numeric_limits<float>::max();\n    float closest_a = 0.0f, closest_b = 0.0f;\n\n    for (size_t i = 0; i < n - 1; i++) {\n        size_t remaining = n - i - 1;\n        size_t vl = vsetvl_e32m1(remaining); // Set vector length based on remaining elements\n\n        vfloat32m1_t vec_numbers = vle32_v_f32m1(&numbers[i + 1], vl); // Load remaining numbers into vector\n        vfloat32m1_t vec_base = vfmv_v_f_f32m1(numbers[i], vl); // Broadcast current number to vector\n\n        vfloat32m1_t vec_diff = vfsub_vv_f32m1(vec_numbers, vec_base, vl); // Compute differences\n        vfloat32m1_t vec_abs_diff = vfabs_v_f32m1(vec_diff, vl); // Compute absolute differences\n\n        float diff_array[vl];\n        vse32_v_f32m1(diff_array, vec_abs_diff, vl); // Store absolute differences back to array\n\n        for (size_t j = 0; j < vl; j++) {\n            if (diff_array[j] < min_diff) {\n                min_diff = diff_array[j];\n                closest_a = numbers[i];\n                closest_b = numbers[i + 1 + j];\n            }\n        }\n    }\n\n    if (closest_a > closest_b) {\n        std::swap(closest_a, closest_b);\n    }\n\n    return {closest_a, closest_b};\n}\n```"}
{"task_id": "SimdBench_72_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <limits>\n\nstd::vector<float> rescale_to_unit_simd(std::vector<float> numbers) {\n    size_t n = numbers.size();\n    if (n < 2) return numbers;\n\n    float min_val = std::numeric_limits<float>::max();\n    float max_val = std::numeric_limits<float>::lowest();\n\n    size_t vlmax = vsetvlmax_e32m1();\n    for (size_t i = 0; i < n; i += vlmax) {\n        size_t vl = vsetvl_e32m1(n - i);\n        vfloat32m1_t vec = vle32_v_f32m1(&numbers[i], vl);\n        min_val = vfredmin_vs_f32m1_f32m1(vundefined_f32m1(), vec, min_val, vl);\n        max_val = vfredmax_vs_f32m1_f32m1(vundefined_f32m1(), vec, max_val, vl);\n    }\n\n    float range = max_val - min_val;\n    if (range == 0) return std::vector<float>(n, 0.0f);\n\n    std::vector<float> result(n);\n    for (size_t i = 0; i < n; i += vlmax) {\n        size_t vl = vsetvl_e32m1(n - i);\n        vfloat32m1_t vec = vle32_v_f32m1(&numbers[i], vl);\n        vec = vfsub_vf_f32m1(vec, min_val, vl);\n        vec = vfdiv_vf_f32m1(vec, range, vl);\n        vse32_v_f32m1(&result[i], vec, vl);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_72_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <limits>\n\nstd::vector<float> rescale_to_unit_simd(std::vector<float> numbers) {\n    size_t n = numbers.size();\n    if (n < 2) return numbers;\n\n    // Find the minimum and maximum values in the vector\n    float min_val = std::numeric_limits<float>::max();\n    float max_val = std::numeric_limits<float>::lowest();\n\n    size_t vlmax = vsetvlmax_e32m1();\n    for (size_t i = 0; i < n; i += vlmax) {\n        size_t vl = vsetvl_e32m1(n - i);\n        vfloat32m1_t vec = vle32_v_f32m1(&numbers[i], vl);\n        min_val = vfredmin_vs_f32m1_f32m1(vundefined_f32m1(), vec, min_val, vl);\n        max_val = vfredmax_vs_f32m1_f32m1(vundefined_f32m1(), vec, max_val, vl);\n    }\n\n    // Compute the range\n    float range = max_val - min_val;\n    if (range == 0.0f) return std::vector<float>(n, 0.0f); // Avoid division by zero\n\n    // Rescale the values\n    std::vector<float> result(n);\n    for (size_t i = 0; i < n; i += vlmax) {\n        size_t vl = vsetvl_e32m1(n - i);\n        vfloat32m1_t vec = vle32_v_f32m1(&numbers[i], vl);\n        vfloat32m1_t vec_min = vfmv_v_f_f32m1(min_val, vl);\n        vfloat32m1_t vec_range = vfmv_v_f_f32m1(range, vl);\n        vfloat32m1_t rescaled = vfsub_vv_f32m1(vec, vec_min, vl);\n        rescaled = vfdiv_vv_f32m1(rescaled, vec_range, vl);\n        vse32_v_f32m1(&result[i], rescaled, vl);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_72_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <limits>\n\nstd::vector<float> rescale_to_unit_simd(std::vector<float> numbers) {\n    size_t n = numbers.size();\n    if (n < 2) return numbers;\n\n    // Find the minimum and maximum values using RVV\n    float min_val = std::numeric_limits<float>::max();\n    float max_val = std::numeric_limits<float>::lowest();\n\n    size_t vlmax = vsetvlmax_e32m1();\n    for (size_t i = 0; i < n; i += vlmax) {\n        size_t vl = vsetvl_e32m1(n - i);\n        vfloat32m1_t vec = vle32_v_f32m1(&numbers[i], vl);\n\n        vfloat32m1_t min_vec = vfmv_v_f_f32m1(min_val, vl);\n        vfloat32m1_t max_vec = vfmv_v_f_f32m1(max_val, vl);\n\n        min_vec = vfredmin_vs_f32m1_f32m1(min_vec, vec, min_vec, vl);\n        max_vec = vfredmax_vs_f32m1_f32m1(max_vec, vec, max_vec, vl);\n\n        min_val = vfmv_f_s_f32m1(min_vec);\n        max_val = vfmv_f_s_f32m1(max_vec);\n    }\n\n    // Compute the scale and offset\n    float range = max_val - min_val;\n    if (range == 0) return std::vector<float>(n, 0.0f);\n\n    // Rescale the values using RVV\n    std::vector<float> result(n);\n    for (size_t i = 0; i < n; i += vlmax) {\n        size_t vl = vsetvl_e32m1(n - i);\n        vfloat32m1_t vec = vle32_v_f32m1(&numbers[i], vl);\n\n        vfloat32m1_t min_vec = vfmv_v_f_f32m1(min_val, vl);\n        vfloat32m1_t range_vec = vfmv_v_f_f32m1(range, vl);\n\n        vfloat32m1_t rescaled_vec = vfsub_vv_f32m1(vec, min_vec, vl);\n        rescaled_vec = vfdiv_vv_f32m1(rescaled_vec, range_vec, vl);\n\n        vse32_v_f32m1(&result[i], rescaled_vec, vl);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_72_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <limits>\n\nstd::vector<float> rescale_to_unit_simd(std::vector<float> numbers) {\n    size_t n = numbers.size();\n    if (n < 2) return numbers;\n\n    float min_val = std::numeric_limits<float>::max();\n    float max_val = std::numeric_limits<float>::lowest();\n\n    size_t vlmax = vsetvlmax_e32m1();\n    for (size_t i = 0; i < n; i += vlmax) {\n        size_t vl = vsetvl_e32m1(n - i);\n        vfloat32m1_t vec = vle32_v_f32m1(&numbers[i], vl);\n        min_val = vfredmin_vs_f32m1_f32m1(vundefined_f32m1(), vec, min_val, vl);\n        max_val = vfredmax_vs_f32m1_f32m1(vundefined_f32m1(), vec, max_val, vl);\n    }\n\n    float range = max_val - min_val;\n    if (range == 0.0f) return std::vector<float>(n, 0.0f);\n\n    std::vector<float> result(n);\n    for (size_t i = 0; i < n; i += vlmax) {\n        size_t vl = vsetvl_e32m1(n - i);\n        vfloat32m1_t vec = vle32_v_f32m1(&numbers[i], vl);\n        vfloat32m1_t rescaled = vfsub_vf_f32m1(vec, min_val, vl);\n        rescaled = vfdiv_vf_f32m1(rescaled, range, vl);\n        vse32_v_f32m1(&result[i], rescaled, vl);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_72_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<float> rescale_to_unit_simd(std::vector<float> numbers) {\n    size_t n = numbers.size();\n    if (n < 2) return numbers;\n\n    // Find the minimum and maximum values in the vector\n    float min_val = numbers[0];\n    float max_val = numbers[0];\n    size_t vlmax = vsetvlmax_e32m1();\n\n    for (size_t i = 0; i < n; i += vlmax) {\n        size_t vl = vsetvl_e32m1(n - i);\n        vfloat32m1_t vec = vle32_v_f32m1(&numbers[i], vl);\n        min_val = std::min(min_val, vfmv_s_f_f32m1_f32(vfredmin_vs_f32m1_f32m1(vec, vec, FLT_MAX, vl)));\n        max_val = std::max(max_val, vfmv_s_f_f32m1_f32(vfredmax_vs_f32m1_f32m1(vec, vec, -FLT_MAX, vl)));\n    }\n\n    float range = max_val - min_val;\n    if (range == 0) return std::vector<float>(n, 0.0f);\n\n    // Rescale the vector to the unit range [0, 1]\n    std::vector<float> result(n);\n    for (size_t i = 0; i < n; i += vlmax) {\n        size_t vl = vsetvl_e32m1(n - i);\n        vfloat32m1_t vec = vle32_v_f32m1(&numbers[i], vl);\n        vfloat32m1_t rescaled = vfmul_vf_f32m1(vfsub_vf_f32m1(vec, min_val, vl), 1.0f / range, vl);\n        vse32_v_f32m1(&result[i], rescaled, vl);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_73_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nuint64_t largest_divisor_simd(uint64_t n) {\n    size_t vlmax = vsetvlmax_e64m1();\n    size_t vl = vsetvl_e64m1(vlmax);\n    uint64_t divisor = 0;\n\n    // Create a vector of numbers from 1 to n-1\n    vuint64m1_t indices = vmv_v_x_u64m1(1, vl);\n    vuint64m1_t step = vmv_v_x_u64m1(1, vl);\n    vuint64m1_t divisors = indices;\n\n    while (vfirst_m_b64(vle_v_u64m1(divisors, vl))) {\n        // Check divisors\n        divisor = divisors;\n    }\n}\n```"}
{"task_id": "SimdBench_73_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nuint64_t largest_divisor_simd(uint64_t n) {\n    size_t vlmax = vsetvlmax_e64m1();\n    size_t vl = vlmax < n ? vlmax : n - 1;\n\n    uint64_t divisors[vlmax];\n    for (size_t i = 0; i < vl; i++) {\n        divisors[i] = i + 1;\n    }\n\n    vuint64m1_t vec_divisors = vle64_v_u64m1(divisors, vl);\n    vuint64m1_t vec_n = vmv_v_x_u64m1(n, vl);\n    vuint64m1_t vec_remainders = vremu_vv_u64m1(vec_n, vec_divisors, vl);\n\n    vbool64_t mask = vmseq_vx_u64m1_b64(vec_remainders, 0, vl);\n    vuint64m1_t vec_filtered = vcompress_vm_u64m1(mask, vec_divisors, vl);\n\n    uint64_t result = 0;\n    size_t filtered_count = vsetvl_e64m1(vlmax);\n    uint64_t filtered[vlmax];\n    vse64_v_u64m1(filtered, vec_filtered, filtered_count);\n\n    for (size_t i = 0; i < filtered_count; i++) {\n        if (filtered[i] < n && filtered[i] > result) {\n            result = filtered[i];\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_73_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nuint64_t largest_divisor_simd(uint64_t n) {\n    size_t vlmax = vsetvlmax_e64m1();\n    size_t vl = vsetvl_e64m1(vlmax);\n    \n    uint64_t divisors[vlmax];\n    for (size_t i = 0; i < vlmax; i++) {\n        divisors[i] = n - i - 1;\n    }\n\n    vuint64m1_t v_divisors = vle64_v_u64m1(divisors, vl);\n    vuint64m1_t v_n = vmv_v_x_u64m1(n, vl);\n    vuint64m1_t v_remainders = vremu_vv_u64m1(v_n, v_divisors, vl);\n\n    vbool64_t v_mask = vmseq_vx_u64m1_b64(v_remainders, 0, vl);\n    uint64_t result = 0;\n\n    for (size_t i = 0; i < vl; i++) {\n        if (v_mask[i]) {\n            result = divisors[i];\n            break;\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_73_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nuint64_t largest_divisor_simd(uint64_t n) {\n    size_t vlmax = vsetvlmax_e64m1(); // Maximum vector length for 64-bit elements\n    for (uint64_t start = n / 2; start > 0; start -= vlmax) {\n        size_t vl = vsetvl_e64m1(start); // Set vector length based on remaining elements\n        vuint64m1_t indices = vslide1down_vx_u64m1(vundefined_u64m1(), start, vl); // Create vector of indices\n        vuint64m1_t divisors = vmul_vx_u64m1(indices, n, vl); // Vector divide\n        if (vfirst_m_b64(vmsle_vx_u64m1(divisors,vl)\n    }\n}\n```"}
{"task_id": "SimdBench_73_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nuint64_t largest_divisor_simd(uint64_t n) {\n    size_t vlmax = vsetvlmax_e64m1();\n    size_t vl = vsetvl_e64m1(vlmax);\n\n    uint64_t divisor = n - 1;\n    uint64_t result = 1;\n\n    while (divisor > 0) {\n        size_t count = divisor < vl ? divisor : vl;\n        vl = vsetvl_e64m1(count);\n\n        vuint64m1_t divisors = vrsub_vx_u64m1(vundefined_u64m1(), divisor, vl);\n        vuint64m1_t n_vec = vmv_v_x_u64m1(n, vl);\n        vuint64m1_t mod_results = vrem_vv_u64m1(n_vec, divisors, vl);\n\n        vbool64_t mask = vmseq_vx_u64m1_b64(mod_results, 0, vl);\n        if (vfirst(mask) != -1) {\n            result = divisor - vfirst(mask);\n            break;\n        }\n\n        divisor -= vl;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_74_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> factorize_simd(int n) {\n    std::vector<int> factors;\n    if (n < 2) return factors;\n\n    int max_factor = n; // Upper bound for factors\n    int vlmax = vsetvlmax_e32m1(); // Maximum vector length for 32-bit integers\n    std::vector<int> primes;\n\n    // Generate a list of potential prime numbers up to max_factor\n    for (int i = 2; i <= max_factor; i++) {\n        primes.push_back(i);\n    }\n\n    size_t size = primes.size();\n    size_t index = 0;\n\n    while (n > 1 && index < size) {\n        size_t vl = vsetvl_e32m1(size - index); // Set vector length\n        vint32m1_t vprimes = vle32_v_i32m1(&primes[index], vl); // Load primes into vector\n        vint32m1_t vcounts = vmv_v_x_i32m1(0, vl); // Initialize counts vector\n\n        // Check divisibility in parallel\n        while (true) {\n            vint32m1_t vdivisible = vmv_v_x_i32m1(0, vl);\n            for (size_t i = 0; i < vl; i++) {\n                if (n%prime[i]==\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_74_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> factorize_simd(int n) {\n    std::vector<int> factors;\n    if (n < 2) return factors;\n\n    int max_factor = n; // Maximum possible factor\n    int vlmax = vsetvlmax_e32m1(); // Maximum vector length for 32-bit integers\n    int factor = 2;\n\n    while (n > 1 && factor <= max_factor) {\n        // Create a vector of potential factors\n        vint32m1_t v_factors = vundefined_e32m1();\n        for (int i = 0; i < vlmax; i++) {\n            v_factors = vslideup_vx_i32m1(v_factors, factor + i, vlmax);\n        }\n\n        // Check divisibility\n        vint32m1_t v_n = vmv_v_x_i32m1(n, vlmax);\n        vint32m1_t v_remainders = vrem_vv_i32m1(v_n, v_factors, vlmax);\n        vbool32_t v_mask = vmseq_vx_i32m1_b32(v_remainders, 0, vlmax);\n\n        // Extract valid factors\n        while (vfirst_m_b32(v_mask) != -1) {\n            factors.push_back(factor);\n            n /= factor;\n            v_n = vmv_v_x_i32m1(n, vlmax);\n            v_remainders = vrem_vv_i32m1(v_n, v_factors, vlmax);\n            v_mask = vmseq_vx_i32m1_b32(v_remainders, 0, vlmax);\n        }\n\n        factor++;\n    }\n\n    return factors;\n}\n```"}
{"task_id": "SimdBench_74_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> factorize_simd(int n) {\n    std::vector<int> factors;\n    if (n < 2) return factors;\n\n    int max_factor = n;\n    int factor = 2;\n\n    while (factor * factor <= max_factor) {\n        size_t vl = vsetvl_e32m1(1); // Set vector length to 1 for scalar processing\n        vint32m1_t v_factor = vmv_v_x_i32m1(factor, vl); // Vectorize the current factor\n        vint32m1_t v_n = vmv_v_x_i32m1(n, vl); // Vectorize the current number\n\n        while (true) {\n            vint32m1_t v_rem = vrem_vv_i32m1(v_n, v_factor, vl); // Compute remainder\n            vint32m1_t v_zero = vmv_v_x_i32m1(0, vl); // Vectorize zero\n            vbool32_t v_is_divisible = vmseq_vv_i32m1_b32(v_rem, v_zero, vl); // Check divisibility\n\n            if (vfirst_m_b32(v_is_divisible)) { // If divisible\n                factors.push_back(factor);\n                v_n = vdiv_vv_i32m1(v_n, v_factor, vl); // Divide n by factor\n                n = vget_first_i32m1(v_n); // Update scalar n\n            } else {\n                break;\n            }\n        }\n\n        factor++;\n    }\n\n    if (n > 1) {\n        factors.push_back(n); // Add the remaining prime factor\n    }\n\n    return factors;\n}\n```"}
{"task_id": "SimdBench_74_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> factorize_simd(int n) {\n    std::vector<int> factors;\n    if (n < 2) return factors;\n\n    int max_factor = n;\n    int factor = 2;\n\n    while (factor <= max_factor) {\n        size_t vl = vsetvl_e32m1(8); // Set vector length\n        vint32m1_t v_factors = vmv_v_x_i32m1(factor, vl); // Initialize vector with current factor\n        vint32m1_t v_n = vmv_v_x_i32m1(n, vl); // Initialize vector with current n\n\n        // Check divisibility\n        vint32m1_t v_remainders = vrem_vv_i32m1(v_n, v_factors, vl);\n        vbool32_t v_mask = vmseq_vx_i32m1_b32(v_remainders, 0, vl); // Mask where n % factor == 0\n\n        while (vfirst_m_b32(v_mask, vl) >= 0) { // While there are divisible elements\n            factors.push_back(factor);\n            n /= factor;\n            v_n = vmv_v_x_i32m1(n, vl); // Update n in vector\n            v_remainders = vrem_vv_i32m1(v_n, v_factors, vl);\n            v_mask = vmseq_vx_i32m1_b32(v_remainders, 0, vl); // Recompute mask\n        }\n\n        factor++;\n    }\n\n    return factors;\n}\n```"}
{"task_id": "SimdBench_74_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> factorize_simd(int n) {\n    std::vector<int> factors;\n    if (n < 2) return factors;\n\n    int max_factor = n; // Upper bound for factors\n    int vlmax = vsetvlmax_e32m1(); // Maximum vector length for 32-bit integers\n    std::vector<int> primes;\n\n    // Generate a list of potential prime numbers up to max_factor\n    for (int i = 2; i <= max_factor; ++i) {\n        primes.push_back(i);\n    }\n\n    size_t prime_count = primes.size();\n    size_t offset = 0;\n\n    while (n > 1 && offset < prime_count) {\n        size_t vl = vsetvl_e32m1(prime_count - offset); // Set vector length\n        vint32m1_t prime_vec = vle32_v_i32m1(&primes[offset], vl); // Load primes into vector\n        vint32m1_t n_vec = vmv_v_x_i32m1(n, vl); // Broadcast n into vector\n\n        // Check divisibility: n % prime == 0\n        vint32m1_t remainder_vec = vrem_vv_i32m1(n_vec, prime_vec, vl);\n        vbool32_t divisible_mask = vmseq_vx_i32m1_b32(remainder_vec, 0, vl);\n\n        // Extract the first divisible prime\n        int divisible_prime = 0;\n        for (size_t i = 0; i < vl; ++i) {\n            if (vfirst_m_b32(divisible_mask)) {\n                divisible_prime = primes[offset + i];\n                break;\n            }\n        }\n\n        if (divisible_prime > 0) {\n            // Divide n by the found prime factor and add it to the result\n            while (n % divisible_prime == 0) {\n                factors.push_back(divisible_prime);\n                n /= divisible_prime;\n            }\n        }\n\n        offset += vl; // Move to the next batch of primes\n    }\n\n    return factors;\n}\n```"}
{"task_id": "SimdBench_75_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<float> get_positive_simd(const std::vector<float> &l) {\n    size_t n = l.size();\n    std::vector<float> result;\n    result.reserve(n);\n\n    size_t vlmax = vsetvlmax_e32m1(); // Maximum vector length for 32-bit elements\n    size_t i = 0;\n\n    while (i < n) {\n        size_t vl = vsetvl_e32m1(n - i); // Set vector length based on remaining elements\n        vfloat32m1_t vec = vle32_v_f32m1(&l[i], vl); // Load vector from input\n        vbool32_t mask = vmflt_vf_f32m1_b32(vec, 0.0f, vl); // Mask for elements < 0\n        vfloat32m1_t filtered = vmerge_vfm_f32m1(mask, vec, 0.0f, vl); // Replace negatives with 0\n        vbool32_t positive_mask = vmfgt_vf_f32m1_b32(filtered, 0.0f, vl); // Mask for positive elements\n\n        size_t count = vcpop_b32(positive_mask); // Count positive elements\n        float temp[count];\n        vse32_v_f32m1(temp, vcompress_vm_f32m1(positive_mask, filtered, vl), count); // Compress positive elements\n        result.insert(result.end(), temp, temp + count);\n\n        i += vl;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_75_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<float> get_positive_simd(const std::vector<float> &l) {\n    size_t n = l.size();\n    std::vector<float> result;\n    result.reserve(n);\n\n    size_t vlmax = vsetvlmax_e32m1(); // Maximum vector length for 32-bit elements\n    size_t i = 0;\n\n    while (i < n) {\n        size_t vl = vsetvl_e32m1(n - i); // Set vector length based on remaining elements\n        vfloat32m1_t vec = vle32_v_f32m1(&l[i], vl); // Load vector from input\n        vbool32_t mask = vmflt_vf_f32m1_b32(vec, 0.0f, vl); // Create mask for positive numbers\n        vfloat32m1_t filtered = vcompress_vm_f32m1(mask, vec, vl); // Compress positive numbers\n\n        size_t filtered_count = vcpop_b32(mask, vl); // Count number of positive elements\n        std::vector<float> temp(filtered_count);\n        vse32_v_f32m1(temp.data(), filtered, filtered_count); // Store filtered elements into temp\n\n        result.insert(result.end(), temp.begin(), temp.end()); // Append to result\n        i += vl;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_75_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<float> get_positive_simd(const std::vector<float> &l) {\n    size_t n = l.size();\n    std::vector<float> result;\n\n    size_t vlmax = vsetvlmax_e32m1(); // Maximum vector length for 32-bit floats\n    size_t i = 0;\n\n    while (i < n) {\n        size_t vl = vsetvl_e32m1(n - i); // Set vector length based on remaining elements\n        vfloat32m1_t vec = vle32_v_f32m1(&l[i], vl); // Load vector elements\n        vbool32_t mask = vmflt_vf_f32m1_b32(vec, 0.0f, vl); // Create mask for elements < 0\n        vfloat32m1_t positive_vec = vmerge_vvm_f32m1(mask, vec, vfmv_v_f_f32m1(0.0f, vl), vl); // Replace negatives with 0\n\n        for (size_t j = 0; j < vl; j++) {\n            float val = vfmv_f_s_f32m1(positive_vec, j); // Extract element\n            if (val > 0) {\n                result.push_back(val); // Append positive value to result\n            }\n        }\n\n        i += vl; // Move to next chunk\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_75_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<float> get_positive_simd(const std::vector<float> &l) {\n    size_t n = l.size();\n    std::vector<float> result;\n\n    size_t vlmax = vsetvlmax_e32m1(); // Maximum vector length for 32-bit elements\n    size_t i = 0;\n\n    while (i < n) {\n        size_t vl = vsetvl_e32m1(n - i); // Set vector length based on remaining elements\n        vfloat32m1_t vec = vle32_v_f32m1(&l[i], vl); // Load vector from input\n        vbool32_t mask = vmflt_vf_f32m1_b32(vec, 0.0f, vl); // Mask for elements less than 0\n        vfloat32m1_t positive_vec = vmerge_vvm_f32m1(mask, vec, vfmv_v_f_f32m1(0.0f, vl), vl); // Replace negatives with 0\n\n        for (size_t j = 0; j < vl; j++) {\n            float val = vfmv_f_s_f32m1(positive_vec, j); // Extract element\n            if (val > 0.0f) {\n                result.push_back(val); // Add positive values to result\n            }\n        }\n        i += vl;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_75_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<float> get_positive_simd(const std::vector<float> &l) {\n    std::vector<float> result;\n    size_t n = l.size();\n    size_t vlmax = vsetvlmax_e32m1(); // Maximum vector length for 32-bit elements\n    size_t i = 0;\n\n    while (i < n) {\n        size_t vl = vsetvl_e32m1(n - i); // Set vector length based on remaining elements\n        vfloat32m1_t vec = vle32_v_f32m1(&l[i], vl); // Load vector\n        vbool32_t mask = vmfgt_vf_f32m1_b32(vec, 0.0f, vl); // Mask for elements > 0\n        size_t count = vcpop_b32(mask); // Count active elements in the mask\n\n        std::vector<float> temp(count);\n        vse32_v_f32m1(temp.data(), vcompress_vm_f32m1(mask, vec, vl), count); // Compress and store positive elements\n        result.insert(result.end(), temp.begin(), temp.end());\n\n        i += vl;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_76_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <stdbool.h>\n\nbool is_prime_simd(int64_t n) {\n    if (n <= 1) return false;\n    if (n <= 3) return true;\n    if (n % 2 == 0 || n % 3 == 0) return false;\n\n    int64_t sqrt_n = (int64_t)sqrt((double)n);\n    size_t vlmax = vsetvlmax_e64m1();\n    for (int64_t i = 5; i <= sqrt_n; i += vlmax * 2) {\n        size_t vl = vsetvl_e64m1(sqrt_n - i + 1);\n        vint64m1_t vec_i = vadd_vx_i64m1(vmul_vx_i64m1(vrsub_vx_i64m1(vundefined_i64m1(), i, vl), 2, vl), i, vl);\n        vint64m1_t vec_n = vmv_v_x_i64m1(n, vl);\n        vint64m1_t vec_mod = vrem_vv_i64m1(vec_n, vec_i, vl);\n        vbool64_t vec_cmp = vmseq_vx_i64m1_b64(vec_mod, 0, vl);\n        if (vfirst_m_b64(vec_cmp, vl) >= 0) return false;\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_76_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nbool is_prime_simd(int64_t n) {\n    if (n <= 1) return false;\n    if (n <= 3) return true;\n    if (n % 2 == 0 || n % 3 == 0) return false;\n\n    int64_t sqrt_n = (int64_t)sqrt((double)n);\n    size_t vlmax = vsetvlmax_e64m1();\n    for (int64_t i = 5; i <= sqrt_n; i += vlmax * 2) {\n        size_t vl = vsetvl_e64m1(sqrt_n - i + 1);\n        vint64m1_t vec_i = vle64_v_i64m1(&i, vl);\n        vint64m1_t vec_n = vmv_v_x_i64m1(n, vl);\n        vint64m1_t vec_mod = vrem_vv_i64m1(vec_n, vec_i, vl);\n\n        vbool64_t vec_zero = vmseq_vx_i64m1_b64(vec_mod, 0, vl);\n        if (vfirst_m_b64(vec_zero)) {\n            return false;\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_76_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <stdbool.h>\n\nbool is_prime_simd(int64_t n) {\n    if (n <= 1) return false;\n    if (n <= 3) return true;\n    if (n % 2 == 0 || n % 3 == 0) return false;\n\n    int64_t sqrt_n = (int64_t)sqrt((double)n);\n    size_t vlmax = vsetvlmax_e64m1();\n    for (int64_t i = 5; i <= sqrt_n; i += vlmax * 2) {\n        size_t vl = vsetvl_e64m1(sqrt_n - i + 1);\n        vint64m1_t vec_i = vadd_vx_i64m1(vmul_vx_i64m1(vrgather_vx_i64m1(vundefined_i64m1(), 0, vl), 2, vl), i, vl);\n        vint64m1_t vec_mod = vrem_vx_i64m1(vrgather_vx_i64m1(vundefined_i64m1(), n, vl), vec_i, vl);\n        vbool64_t vec_cmp = vmseq_vx_i64m1_b64(vec_mod, 0, vl);\n        if (vfirst_m_b64(vec_cmp, vl) >= 0) return false;\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_76_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <stdbool.h>\n\nbool is_prime_simd(int64_t n) {\n    if (n <= 1) return false;\n    if (n <= 3) return true;\n    if (n % 2 == 0 || n % 3 == 0) return false;\n\n    int64_t sqrt_n = (int64_t)sqrt((double)n);\n    size_t vlmax = vsetvlmax_e64m1();\n    for (int64_t i = 5; i <= sqrt_n; i += vlmax * 2) {\n        size_t vl = vsetvl_e64m1(sqrt_n - i + 1);\n        vint64m1_t vec_i = vadd_vx_i64m1(vmul_vx_i64m1(vcreate_i64m1(vl), 2), i);\n        vint64m1_t vec_n = vmul_vx_i64m1(vec_i, vec_i);\n        vbool64_t mask = vmseq_vx_i64m1_b64(vrem_vx_i64m1(vec_n,n),0);\n        if(vpopcount(mask)>0)return false;\n    }\n}\n```"}
{"task_id": "SimdBench_76_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <stdbool.h>\n\nbool is_prime_simd(int64_t n) {\n    if (n <= 1) {\n        return false;\n    }\n    if (n <= 3) {\n        return true;\n    }\n    if (n % 2 == 0 || n % 3 == 0) {\n        return false;\n    }\n\n    int64_t sqrt_n = (int64_t)__builtin_sqrt((double)n);\n    size_t vl;\n    for (int64_t i = 5; i <= sqrt_n; i += vl * 2) {\n        vl = vsetvl_e64((sqrt_n - i + 1) / 2);\n        vint64m1_t vec_i = vslide1down_vx_i64m1(vundefined_i64m1(), i, vl);\n        vint64m1_t vec_step = vmul_vx_i64m1(vec_i, 2, vl);\n        vint64m1_t vec_mod = vmod_vx_i64m1(vec_step, n, vl);\n        if (vany_vx_i64m1(vec_mod, 0, vl)) {\n            return true;\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_77_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n#include <algorithm>\n\nstd::string solve_simd(const std::string &s) {\n    size_t n = s.size();\n    if (n == 0) return s;\n\n    std::string result = s;\n    bool has_letter = false;\n\n    size_t i = 0;\n    size_t vl;\n    while (i < n) {\n        vl = vsetvl_e8m1(n - i); // Set vector length for 8-bit elements\n        vint8m1_t chars = vle8_v_i8m1((const int8_t*)&s[i], vl); // Load characters\n\n        // Check if characters are letters\n        vbool8_t is_lower = vmand_mm_b8(\n            vmsgt_vx_i8m1_b8(chars, 'a' - 1, vl), \n            vmslt_vx_i8m1_b8(chars, 'z' + 1, vl), vl\n        );\n        vbool8_t is_upper = vmand_mm_b8(\n            vmsgt_vx_i8m1_b8(chars, 'A' - 1, vl), \n            vmslt_vx_i8m1_b8(chars, 'Z' + 1, vl), vl\n        );\n        vbool8_t is_letter = vorr_mm_b8(is_lower, is_upper, vl);\n\n        if (vfirst_m_b8(is_letter, vl) != -1) has_letter = true;\n\n        // Reverse case for letters\n        vint8m1_t flipped_case = vmerge_vxm_i8m1(\n            vmerge_vxm_i8m1(chars, chars + ('a' - 'A'), is_upper, vl),\n            chars - ('a' - 'A'), is_lower, vl\n        );\n\n        // Store the result\n        vse8_v_i8m1((int8_t*)&result[i], vmerge_vxm_i8m1(chars, flipped_case, is_letter, vl), vl);\n\n        i += vl;\n    }\n\n    if (!has_letter) {\n        std::reverse(result.begin(), result.end());\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_77_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n#include <algorithm>\n\nstd::string solve_simd(const std::string & s) {\n    size_t n = s.size();\n    std::string result(n, '\\0');\n\n    bool has_letter = false;\n    for (char c : s) {\n        if (std::isalpha(c)) {\n            has_letter = true;\n            break;\n        }\n    }\n\n    if (!has_letter) {\n        std::reverse_copy(s.begin(), s.end(), result.begin());\n        return result;\n    }\n\n    size_t vlmax = vsetvlmax_e8m1();\n    size_t i = 0;\n\n    while (i < n) {\n        size_t vl = vsetvl_e8m1(n - i);\n        vint8m1_t vec = vle8_v_i8m1(reinterpret_cast<const int8_t*>(s.data() + i), vl);\n\n        vint8m1_t is_lower = vmul_vx_i8m1(vmsgt_vx_i8m1(vec, 'a' - 1, vl), vmult_vx_i8m1(vmslt_vx_i8m1(vec, 'z' + 1, vl), vl));\n        vint8m1_t is_upper = vmul_vx_i8m1(vmsgt_vx_i8m1(vec, 'A' - 1, vl), vmult_vx_i8m1(vmslt_vx_i8m1(vec, 'Z' + 1, vl), vl));\n\n        vint8m1_t lower_to_upper = vadd_vx_i8m1(vec, 'A' - 'a', vl);\n        vint8m1_t upper_to_lower = vsub_vx_i8m1(vec, 'A' - 'a', vl);\n\n        vint8m1_t reversed_case = vmul_vx_i8m1(is_lower, lower_to_upper, vl);\n        reversed_case = vadd_vv_i8m1(reversed_case, vmul_vx_i8m1(is_upper, upper_to_lower, vl), vl);\n        vint8m1_t unchanged = vmul_vx_i8m1(vmnand_vx_i8m1(is_lower, is_upper, vl), vec, vl);\n\n        vint8m1_t final_vec = vadd_vv_i8m1(reversed_case, unchanged, vl);\n        vse8_v_i8m1(reinterpret_cast<int8_t*>(result.data() + i), final_vec, vl);\n\n        i += vl;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_77_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nstd::string solve_simd(const std::string &s) {\n    size_t n = s.size();\n    std::string result(n, '\\0');\n    bool has_letter = false;\n\n    for (size_t i = 0; i < n;) {\n        size_t vl = vsetvl_e8m1(n - i); // Set vector length for 8-bit elements\n        vint8m1_t vec = vle8_v_i8m1(reinterpret_cast<const int8_t*>(s.data() + i), vl);\n\n        vint8m1_t is_lower = vmand_vx_i8m1(vec, 0x20, vl); // Check for lowercase letters\n        vint8m1_t is_upper = vmand_vx_i8m1(vec, 0x40, vl); // Check for uppercase letters\n        vint8m1_t is_alpha = vor_vv_i8m1(is_lower, is_upper, vl); // Check for any letter\n\n        has_letter |= vfirst_m_b8(vmsne_vx_i8m1_b8(is_alpha, 0, vl)); // Check if any letter exists\n\n        vint8m1_t toggled_case = vxor_vx_i8m1(vec, 0x20, vl); // Toggle case\n        vint8m1_t result_vec = vmerge_vvm_i8m1(vmsne_vx_i8m1_b8(is_alpha, 0, vl), toggled_case, vec, vl);\n\n        vse8_v_i8m1(reinterpret_cast<int8_t*>(result.data() + i), result_vec, vl);\n        i += vl;\n    }\n\n    if (!has_letter) {\n        std::reverse(result.begin(), result.end());\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_77_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n#include <algorithm>\n\nstd::string solve_simd(const std::string & s) {\n    size_t n = s.size();\n    if (n == 0) return s;\n\n    std::string result = s;\n    bool has_letter = false;\n\n    size_t vlmax = vsetvlmax_e8m1();\n    for (size_t i = 0; i < n; i += vlmax) {\n        size_t vl = vsetvl_e8m1(n - i);\n        vint8m1_t vec = vle8_v_i8m1(reinterpret_cast<const int8_t*>(&s[i]), vl);\n\n        vint8m1_t is_lower = vmul_vx_i8m1(vmsgt_vx_i8m1(vec, 'a' - 1, vl), vmult_vx_i8m1(vec, 'z' + 1, vl));\n        vint8m1_t is_upper = vmul_vx_i8m1(vmsgt_vx_i8m1(vec, 'A' - 1, vl), vmult_vx_i8m1(vec, 'Z' + 1, vl));\n       "}
{"task_id": "SimdBench_77_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nstd::string solve_simd(const std::string &s) {\n    size_t n = s.size();\n    std::string result(n, '\\0');\n\n    size_t vlmax = vsetvlmax_e8m1(); // Maximum vector length for 8-bit elements\n    size_t i = 0;\n\n    while (i < n) {\n        size_t vl = vsetvl_e8m1(n - i); // Set vector length for remaining elements\n\n        // Load characters into vector\n        vint8m1_t vec = vle8_v_i8m1(reinterpret_cast<const int8_t*>(&s[i]), vl);\n\n        // Check if characters are letters (A-Z or a-z)\n        vbool8_t is_upper = vmand_mm_b8(\n            vmsgt_vx_i8m1_b8(vec, 'A' - 1, vl), \n            vmslt_vx_i8m1_b8(vec, 'Z' + 1, vl), \n            vl\n        );\n        vbool8_t is_lower = vmand_mm_b8(\n            vmsgt_vx_i8m1_b8(vec, 'a' - 1, vl), \n            vmslt_vx_i8m1_b8(vec, 'z' + 1, vl), \n            vl\n        );\n        vbool8_t is_letter = vorr_mm_b8(is_upper, is_lower, vl);\n\n        // Reverse case for letters\n        vint8m1_t case_flipped = vec;\n        case_flipped = vadd_vx_i8m1_m(is_upper, case_flipped, 32, vl); // Upper to lower\n        case_flipped = vsub_vx_i8m1_m(is_lower, case_flipped, 32, vl); // Lower to upper\n\n        // Select flipped or original characters\n        vint8m1_t final_vec = vmv_v_v_i8m1_m(is_letter, case_flipped, vec, vl);\n\n        // Store result\n        vse8_v_i8m1(reinterpret_cast<int8_t*>(&result[i]), final_vec, vl);\n\n        i += vl;\n    }\n\n    // If no letters were found, reverse the string\n    if (result == s) {\n        std::reverse(result.begin(), result.end());\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_78_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<int> sort_third_simd(std::vector<int> l) {\n    size_t n = l.size();\n    std::vector<int> result(n);\n    std::vector<int> divisible_by_three;\n\n    // Extract elements at indices divisible by three\n    for (size_t i = 0; i < n; i++) {\n        if (i % 3 == 0) {\n            divisible_by_three.push_back(l[i]);\n        }\n    }\n\n    // Sort the extracted elements\n    std::sort(divisible_by_three.begin(), divisible_by_three.end());\n\n    // Prepare for RVV processing\n    size_t vlmax = vsetvlmax_e32m1();\n    size_t sorted_index = 0;\n\n    for (size_t i = 0; i < n; i += vlmax) {\n        size_t vl = vsetvl_e32m1(n - i);\n        vint32m1_t vec_l = vle32_v_i32m1(&l[i], vl);\n        vint32m1_t vec_result = vec_l;\n\n        for (size_t j = 0; j < vl; j++) {\n            size_t idx = i + j;\n            if (idx % 3 == 0) {\n                vec_result = vse32_v_i32m1(&result[idx], vl);\n                result[idx] = divisible_by_three[sorted_index++];\n            } else {\n                result[idx] = l[idx];\n            }\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_78_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<int> sort_third_simd(std::vector<int> l) {\n    size_t n = l.size();\n    std::vector<int> result = l;\n\n    // Extract indices divisible by 3\n    std::vector<int> divisible_by_three;\n    for (size_t i = 0; i < n; i++) {\n        if (i % 3 == 0) {\n            divisible_by_three.push_back(l[i]);\n        }\n    }\n\n    // Sort the divisible_by_three vector\n    std::sort(divisible_by_three.begin(), divisible_by_three.end());\n\n    // Use RVV to write back sorted values to the result vector\n    size_t sorted_size = divisible_by_three.size();\n    size_t vlmax = vsetvlmax_e32m1();\n    size_t index = 0;\n\n    for (size_t i = 0; i < n; i += vlmax) {\n        size_t vl = vsetvl_e32m1(n - i);\n        vint32m1_t v_indices = vle32_v_i32m1(&l[i], vl);\n        vint32m1_t v_result = vle32_v_i32m1(&result[i], vl);\n\n        for (size_t j = 0; j < vl; j++) {\n            if ((i + j) % 3 == 0 && index < sorted_size) {\n                v_result[j] = divisible_by_three[index++];\n            }\n        }\n\n        vse32_v_i32m1(&result[i], v_result, vl);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_78_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<int> sort_third_simd(std::vector<int> l) {\n    size_t n = l.size();\n    std::vector<int> result = l;\n\n    // Extract elements at indices divisible by 3\n    std::vector<int> divisible_by_three;\n    for (size_t i = 0; i < n; i++) {\n        if (i % 3 == 0) {\n            divisible_by_three.push_back(l[i]);\n        }\n    }\n\n    // Sort the extracted elements\n    std::sort(divisible_by_three.begin(), divisible_by_three.end());\n\n    // Replace the sorted elements back into their original positions using RVV\n    size_t sorted_index = 0;\n    size_t vl;\n    for (size_t i = 0; i < n;) {\n        vl = vsetvl_e32m1(n - i); // Set vector length\n        vbool32_t mask = vmsne_vi_i32m1_b32(vle32_v_i32m1(&l[i], vl), 0, vl); // Mask for indices divisible by 3\n        vint32m1_t vec = vle32_v_i32m1(&result[i], vl);\n        for (size_t j = 0; j < vl; j++) {\n            if ((i + j) % 3 == 0 && sorted_index < divisible_by_three.size()) {\n                result[i + j] = divisible_by_three[sorted_index++];\n            }\n        }\n        i += vl;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_78_RVV", "completion": "```c++\n#include <riscv_vector.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<int> sort_third_simd(std::vector<int> l) {\n    size_t n = l.size();\n    std::vector<int> result = l;\n\n    // Extract indices divisible by 3\n    std::vector<int> divisible_by_three;\n    for (size_t i = 0; i < n; i++) {\n        if (i % 3 == 0) {\n            divisible_by_three.push_back(l[i]);\n        }\n    }\n\n    // Sort the extracted values\n    std::sort(divisible_by_three.begin(), divisible_by_three.end());\n\n    // Use RVV to write back sorted values to the original positions\n    size_t sorted_idx = 0;\n    size_t vl;\n    for (size_t i = 0; i < n; i += vl) {\n        vl = vsetvl_e32m1(n - i); // Set vector length\n        vuint32m1_t indices = vid_v_u32m1(vl); // Generate index vector\n        vuint32m1_t mask = vmseq_vx_u32m1_b32(indices, 0, vl); // Mask for indices divisible by 3\n        vint32m1_t data = vle32_v_i32m1(&l[i], vl); // Load data\n        vint32m1_t sorted_data = vle32_v_i32m1(&divisible_by_three[sorted_idx], vl); // Load sorted data\n        vbool32_t write_mask = vmseq_vx_u32m1_b32(indices, 0, vl); // Mask for write-back\n        vse32_v_i32m1_m(write_mask, &result[i], sorted_data, vl); // Write back sorted data\n        sorted_idx += vl;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_78_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<int> sort_third_simd(std::vector<int> l) {\n    size_t n = l.size();\n    std::vector<int> result(n);\n    std::vector<int> divisible_by_three;\n\n    // Extract elements at indices divisible by 3\n    for (size_t i = 0; i < n; i++) {\n        if (i % 3 == 0) {\n            divisible_by_three.push_back(l[i]);\n        }\n    }\n\n    // Sort the extracted elements\n    std::sort(divisible_by_three.begin(), divisible_by_three.end());\n\n    // Prepare RVV vector processing\n    size_t vlmax = vsetvlmax_e32m1();\n    size_t index = 0;\n\n    for (size_t i = 0; i < n; i += vlmax) {\n        size_t vl = vsetvl_e32m1(n - i);\n        vint32m1_t vec_l = vle32_v_i32m1(&l[i], vl);\n        vint32m1_t vec_result = vec_l;\n\n        // Process indices divisible by 3\n        for (size_t j = 0; j < vl; j++) {\n            size_t idx = i + j;\n            if (idx < n && idx % 3 == 0) {\n                vec_result = vslide1down_vx_i32m1(vec_result, divisible_by_three[index++], vl);\n            }\n        }\n\n        vse32_v_i32m1(&result[i], vec_result, vl);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_79_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <limits>\n\nfloat max_element_simd(std::vector<float> l) {\n    size_t n = l.size();\n    size_t vl;\n    float max_val = -std::numeric_limits<float>::infinity();\n    float *data = l.data();\n\n    for (size_t i = 0; i < n; i += vl) {\n        vl = vsetvl_e32m8(n - i);\n        vfloat32m8_t vec = vle32_v_f32m8(data + i, vl);\n        vfloat32m1_t max_vec = vfredmax_vs_f32m8_f32m1(vundefined_f32m1(), vec, vundefined_f32m1(), vl);\n        max_val = fmax(max_val, vfmv_f_s_f32m1_f32(max_vec));\n    }\n\n    return max_val;\n}\n```"}
{"task_id": "SimdBench_79_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <limits>\n\nfloat max_element_simd(std::vector<float> l) {\n    size_t n = l.size();\n    size_t vlmax = vsetvlmax_e32m1();\n    float max_val = std::numeric_limits<float>::lowest();\n\n    for (size_t i = 0; i < n; i += vlmax) {\n        size_t vl = vsetvl_e32m1(n - i);\n        vfloat32m1_t vec = vle32_v_f32m1(&l[i], vl);\n        vfloat32m1_t max_vec = vfmv_v_f_f32m1(max_val, vl);\n        max_vec = vfmax_vv_f32m1(max_vec, vec, vl);\n        max_val = vfmv_s_f_f32m1(vreduce_max_f32m1(max_vec, vl));\n    }\n\n    return max_val;\n}\n```"}
{"task_id": "SimdBench_79_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <limits>\n\nfloat max_element_simd(std::vector<float> l) {\n    size_t n = l.size();\n    if (n == 0) return std::numeric_limits<float>::lowest();\n\n    size_t vlmax = vsetvlmax_e32m1(); // Maximum vector length for 32-bit floats\n    float max_val = std::numeric_limits<float>::lowest();\n\n    for (size_t i = 0; i < n; i += vlmax) {\n        size_t vl = vsetvl_e32m1(n - i); // Set vector length for remaining elements\n        vfloat32m1_t vec = vle32_v_f32m1(&l[i], vl); // Load vector\n        vfloat32m1_t max_vec = vfmv_s_f_f32m1(vundefined_f32m1(), max_val, vl); // Initialize max vector\n        max_vec = vfmax_vv_f32m1(max_vec, vec, vl); // Compute max element-wise\n        max_val = vfmv_f_s_f32m1_f32(max_vec); // Extract max value from vector\n    }\n\n    return max_val;\n}\n```"}
{"task_id": "SimdBench_79_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <limits>\n\nfloat max_element_simd(std::vector<float> l) {\n    size_t n = l.size();\n    size_t vl;\n    float max_val = -std::numeric_limits<float>::infinity();\n\n    for (size_t i = 0; i < n; i += vl) {\n        vl = vsetvl_e32m8(n - i); // Set vector length\n        vfloat32m8_t vec = vle32_v_f32m8(&l[i], vl); // Load elements into vector\n        vfloat32m1_t max_vec = vfmv_s_f_f32m1(vundefined_f32m1(), max_val); // Initialize max vector\n        max_vec = vfredmax_vs_f32m8_f32m1(max_vec, vec, max_vec, vl); // Reduce max\n        max_val = vfmv_f_s_f32m1_f32(max_vec); // Extract max value\n    }\n\n    return max_val;\n}\n```"}
{"task_id": "SimdBench_79_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <limits>\n\nfloat max_element_simd(std::vector<float> l) {\n    size_t n = l.size();\n    size_t vlmax = vsetvlmax_e32m1();\n    float max_val = std::numeric_limits<float>::lowest();\n\n    for (size_t i = 0; i < n; i += vlmax) {\n        size_t vl = vsetvl_e32m1(n - i);\n        vfloat32m1_t vec = vle32_v_f32m1(&l[i], vl);\n        vfloat32m1_t max_vec = vfredmax_vs_f32m1_f32m1(vundefined_f32m1(), vec, vec, vl);\n        max_val = fmax(max_val, vfmv_f_s_f32m1_f32(max_vec));\n    }\n\n    return max_val;\n}\n```"}
{"task_id": "SimdBench_80_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nint fizz_buzz_simd(int n) {\n    int count = 0;\n    size_t vlmax = vsetvlmax_e32m1();\n    for (int i = 0; i < n; i += vlmax) {\n        size_t vl = vsetvl_e32m1(n - i);\n        vint32m1_t v_indices = vadd_vx_i32m1(vundefined_i32m1(vl), i, vl);\n        vint32m1_t v_mod11 = vrem_vx_i32m1(v_indices, 11, vl);\n        vint32m1_t v_mod13 = vrem_vx_i32m1(v_indices, 13, vl);\n        vbool32_t v_divisible = vor_vv_b32(vmsle_vx_i32m1(v_mod11, 0, vl), vmsle_vx_i32m1(v_mod13, 0, vl), vl);\n\n        vint32m1_t v_sevens = vmul_vx_i32m1(vundefined_i32m1(vl), 0, vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i32m1(vl);\n        vint32m1_t v_temp = vundefined_i"}
{"task_id": "SimdBench_80_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nint fizz_buzz_simd(int n) {\n    int count = 0;\n    size_t vlmax = vsetvlmax_e32m1();\n    for (int i = 0; i < n; i += vlmax) {\n        size_t vl = vsetvl_e32m1(n - i);\n        vint32m1_t indices = vadd_vx_i32m1(vundefined_i32m1(), i, vl);\n        vint32m1_t mod11 = vrem_vx_i32m1(indices, 11, vl);\n        vint32m1_t mod13 = vrem_vx_i32m1(indices, 13, vl);\n        vbool32_t is_divisible = vor_vv_b32(vmsle_vx_i32m1(mod11, 0, vl), vmsle_vx_i32m1(mod13, 0, vl), vl);\n\n        vint32m1_t divisible_indices = vcompress_vm_i32m1(is_divisible, indices, vl);\n        size_t compressed_count = vsetvl_e32m1(vpopc_b32(is_divisible, vl));\n\n        for (size_t j = 0; j < compressed_count; j++) {\n            int value = vget_i32m1(divisible_indices, j);\n            while (value > 0) {\n                if (value % 10 == 7) {\n                    count++;\n                }\n                value /= 10;\n            }\n        }\n    }\n    return count;\n}\n```"}
{"task_id": "SimdBench_80_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nint fizz_buzz_simd(int n) {\n    int count = 0;\n    size_t vl;\n    for (int i = 0; i < n; i += vl) {\n        vl = vsetvl_e32m1(n - i);\n        vint32m1_t indices = vid_v_i32m1(vl);\n        indices = vadd_vx_i32m1(indices, i, vl);\n\n        vint32m1_t mod11 = vrem_vx_i32m1(indices, 11, vl);\n        vint32m1_t mod13 = vrem_vx_i32m1(indices, 13, vl);\n\n        vbool32_t divisible_by_11 = vmseq_vx_i32m1_b32(mod11, 0, vl);\n        vbool32_t divisible_by_13 = vmseq_vx_i32m1_b32(mod13, 0, vl);\n        vbool32_t divisible = vmor_mm_b32(divisible_by_11, divisible_by_13, vl);\n\n        vint32m1_t filtered_indices = vmerge_vxm_i32m1(indices, 0, divisible, vl);\n\n        for (size_t j = 0; j < vl; j++) {\n            int value = vextract_v_i32m1(filtered_indices, j);\n            while (value > 0) {\n                if (value % 10 == 7) {\n                    count++;\n                }\n                value /= 10;\n            }\n        }\n    }\n    return count;\n}\n```"}
{"task_id": "SimdBench_80_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nint fizz_buzz_simd(int n) {\n    int count = 0;\n    size_t vlmax = vsetvlmax_e32m1();\n    for (int i = 0; i < n; i += vlmax) {\n        size_t vl = vsetvl_e32m1(n - i);\n        vint32m1_t v_indices = vadd_vx_i32m1(vundefined_i32m1(vl), i, vl);\n        vint32m1_t v_mod11 = vrem_vx_i32m1(v_indices, 11, vl);\n        vint32m1_t v_mod13 = vrem_vx_i32m1(v_indices, 13, vl);\n        vbool32_t v_divisible = vor_vv_b32(vmsle_vx_i32m1_b32(v_mod11, 0, vl), vmsle_vx_i32m1_b32(v_mod13, 0, vl), vl);\n\n        vint32m1_t v_sevens_count = vmv_v_x_i32m1(0, vl);\n        for (int j = 0; j < vl; j++) {\n            if (v_divisible[j]) {\n                int num = i + j;\n                while (num > 0) {\n                    if (num % 10 == 7) {\n                        v_sevens_count[j]++;\n                    }\n                    num /= 10;\n                }\n            }\n        }\n        count += vreduce_sum_i32m1(v_sevens_count, vl);\n    }\n    return count;\n}\n```"}
{"task_id": "SimdBench_80_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nint fizz_buzz_simd(int n) {\n    int count = 0;\n    for (int i = 0; i < n; i += vsetvlmax_e32m1()) {\n        size_t vl = vsetvl_e32m1(n - i);\n        vint32m1_t v_indices = vmv_v_x_i32m1(i, vl);\n        vint32m1_t v_11 = vmv_v_x_i32m1(11, vl);\n        vint32m1_t v_13 = vmv_v_x_i32m1(13, vl);\n\n        vint32m1_t v_mod_11 = vrem_vv_i32m1(v_indices, v_11, vl);\n        vint32m1_t v_mod_13 = vrem_vv_i32m1(v_indices, v_13, vl);\n\n        vbool32_t v_divisible_11 = vmseq_vx_i32m1_b32(v_mod_11, 0, vl);\n        vbool32_t v_divisible_13 = vmseq_vx_i32m1_b32(v_mod_13, 0, vl);\n\n        vbool32_t v_divisible = vor_b32(v_divisible_11, v_divisible_13, vl);\n\n        vint32m1_t v_filtered = vcompress_vm_i32m1(v_indices, v_divisible, vl);\n\n        for (size_t j = 0; j < vl; j++) {\n            int value = vget_i32m1(v_filtered, j);\n            while (value > 0) {\n                if (value % 10 == 7) {\n                    count++;\n                }\n                value /= 10;\n            }\n        }\n    }\n    return count;\n}\n```"}
{"task_id": "SimdBench_81_RVV", "completion": "```c++\n#include <riscv_vector.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<float> sort_even_simd(std::vector<float> l) {\n    size_t n = l.size();\n    size_t vlmax = vsetvlmax_e32m1(); // Maximum vector length for 32-bit elements\n    std::vector<float> even_elements;\n\n    // Extract even-indexed elements\n    for (size_t i = 0; i < n; i += 2) {\n        even_elements.push_back(l[i]);\n    }\n\n    // Sort the even-indexed elements\n    size_t even_size = even_elements.size();\n    for (size_t i = 0; i < even_size; i += vlmax) {\n        size_t vl = vsetvl_e32m1(even_size - i);\n        vfloat32m1_t vec = vle32_v_f32m1(&even_elements[i], vl);\n        // Sort the vector using a simple bubble sort (SIMD-friendly)\n        for (size_t j = 0; j < vl - 1; ++j) {\n            for (size_t k = 0; k < vl - j - 1; ++k) {\n                float a = vfmv_f_s_f32m1_f32(vec, k);\n                float b = vfmv_f_s_f32m1_f32(vec, k + 1);\n                if (a > b) {\n                    vec = vslide1down_vx_f32m1(vec, a, k + 1);\n                    vec = vslide1up_vx_f32m1(vec, b, k);\n                }\n            }\n        }\n        vse32_v_f32m1(&even_elements[i], vec, vl);\n    }\n\n    // Replace even-indexed elements in the original vector\n    for (size_t i = 0, j = 0; i < n; i += 2, j++) {\n        l[i] = even_elements[j];\n    }\n\n    return l;\n}\n```"}
{"task_id": "SimdBench_81_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<float> sort_even_simd(std::vector<float> l) {\n    size_t n = l.size();\n    size_t vlmax = vsetvlmax_e32m1(); // Maximum vector length for 32-bit elements\n    std::vector<float> even_indices;\n\n    // Extract even indices\n    for (size_t i = 0; i < n; i += 2) {\n        even_indices.push_back(l[i]);\n    }\n\n    // Sort even indices\n    std::sort(even_indices.begin(), even_indices.end());\n\n    // Prepare output vector\n    std::vector<float> result(n);\n\n    size_t even_idx = 0;\n    for (size_t i = 0; i < n; i++) {\n        if (i % 2 == 0) {\n            result[i] = even_indices[even_idx++];\n        } else {\n            result[i] = l[i];\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_81_RVV", "completion": "```c++\n#include <riscv_vector.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<float> sort_even_simd(std::vector<float> l) {\n    size_t n = l.size();\n    size_t vlmax = vsetvlmax_e32m1(); // Maximum vector length for 32-bit elements\n    std::vector<float> even_values;\n\n    // Extract even-indexed elements\n    for (size_t i = 0; i < n; i += 2) {\n        even_values.push_back(l[i]);\n    }\n\n    // Sort the even-indexed elements\n    size_t even_size = even_values.size();\n    for (size_t i = 0; i < even_size; i += vlmax) {\n        size_t vl = vsetvl_e32m1(even_size - i);\n        vfloat32m1_t vec = vle32_v_f32m1(&even_values[i], vl);\n        for (size_t j = 0; j < vl - 1; j++) {\n            for (size_t k = 0; k < vl - j - 1; k++) {\n                vfloat32m1_t a = vslide1down_vx_f32m1(vec, 0, vl);\n                vbool32_t mask = vmflt_vv_f32m1_b32(vec, a, vl);\n                vec = vmerge_vvm_f32m1(mask, a, vec, vl);\n            }\n        }\n        vse32_v_f32m1(&even_values[i], vec, vl);\n    }\n\n    // Reconstruct the result vector\n    std::vector<float> result(n);\n    size_t even_idx = 0;\n    for (size_t i = 0; i < n; i++) {\n        if (i % 2 == 0) {\n            result[i] = even_values[even_idx++];\n        } else {\n            result[i] = l[i];\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_81_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<float> sort_even_simd(std::vector<float> l) {\n    size_t n = l.size();\n    size_t vlmax = vsetvlmax_e32m1(); // Maximum vector length for 32-bit elements\n    std::vector<float> even_indices;\n\n    // Extract even indices\n    for (size_t i = 0; i < n; i += 2) {\n        even_indices.push_back(l[i]);\n    }\n\n    // Sort even indices\n    std::sort(even_indices.begin(), even_indices.end());\n\n    // Prepare output vector\n    std::vector<float> result(n);\n\n    // Use RVV to process the vector\n    size_t even_idx = 0;\n    for (size_t i = 0; i < n; i += vlmax) {\n        size_t vl = vsetvl_e32m1(n - i); // Set vector length\n        vint32m1_t idx = vcreate_v_i32m1(vl); // Create index vector\n        for (size_t j = 0; j < vl; ++j) {\n            if ((i + j) % 2 == 0) {\n                result[i + j] = even_indices[even_idx++];\n            } else {\n                result[i + j] = l[i + j];\n            }\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_81_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<float> sort_even_simd(std::vector<float> l) {\n    size_t n = l.size();\n    size_t vlmax = vsetvlmax_e32m1(); // Maximum vector length for 32-bit elements\n    std::vector<float> even_indices;\n\n    // Extract even-indexed elements\n    for (size_t i = 0; i < n; i += 2) {\n        even_indices.push_back(l[i]);\n    }\n\n    // Sort the even-indexed elements\n    std::sort(even_indices.begin(), even_indices.end());\n\n    // Write back the sorted even-indexed elements to the original vector\n    size_t even_idx = 0;\n    for (size_t i = 0; i < n; i += vlmax) {\n        size_t vl = vsetvl_e32m1(n - i); // Set vector length\n        vuint32m1_t indices = vid_v_u32m1(vl); // Create index vector\n        vuint32m1_t even_mask = vmseq_vx_u32m1(indices, 0, vl); // Mask for even indices\n        vfloat32m1_t vec = vle32_v_f32m1(&l[i], vl); // Load vector\n        vfloat32m1_t sorted_even = vle32_v_f32m1(&even_indices[even_idx], vl); // Load sorted even elements\n        vfloat32m1_t result = vmerge_vvm_f32m1(even_mask, sorted_even, vec, vl); // Merge sorted even elements\n        vse32_v_f32m1(&l[i], result, vl); // Store result back\n        even_idx += vl / 2; // Update even index\n    }\n\n    return l;\n}\n```"}
{"task_id": "SimdBench_82_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nbool triples_sum_to_zero_simd(std::vector<int> l) {\n    size_t n = l.size();\n    if (n < 3) return false;\n\n    for (size_t i = 0; i < n - 2; i++) {\n        for (size_t j = i + 1; j < n - 1; j++) {\n            size_t remaining = n - j - 1;\n            size_t vl = vsetvl_e32m1(remaining); // Set vector length for remaining elements\n            vint32m1_t vec_k = vle32_v_i32m1(&l[j + 1], vl); // Load remaining elements into vector\n            vint32m1_t vec_sum = vmv_v_x_i32m1(l[i] + l[j], vl); // Broadcast sum of l[i] and l[j]\n            vint32m1_t vec_result = vadd_vv_i32m1(vec_sum, vec_k, vl); // Add broadcasted sum to vector elements\n            vbool32_t mask = vmseq_vx_i32m1_b32(vec_result, 0, vl); // Check if any element equals zero\n            if (vfirst_m_b32(mask) != -1) { // If any match is found\n                return true;\n            }\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_82_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <cstdint>\n\nbool triples_sum_to_zero_simd(std::vector<int> l) {\n    size_t n = l.size();\n    if (n < 3) {\n        return false;\n    }\n\n    for (size_t i = 0; i < n - 2; i++) {\n        for (size_t j = i + 1; j < n - 1; j++) {\n            size_t remaining = n - (j + 1);\n            size_t vl = vsetvl_e32m1(remaining);\n            vint32m1_t vec = vle32_v_i32m1(&l[j + 1], vl);\n\n            vint32m1_t sum_vec = vadd_vx_i32m1(vadd_vx_i32m1(vec, l[i], vl), l[j], vl);\n            uint32_t mask = vmfirst_m_b32(vmsle_vx_i32m1_b32(sum_vec, 0, vl));\n\n            if (mask != -1) {\n                return true;\n            }\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_82_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <cstdint>\n\nbool triples_sum_to_zero_simd(std::vector<int> l) {\n    size_t n = l.size();\n    if (n < 3) return false;\n\n    for (size_t i = 0; i < n; i++) {\n        for (size_t j = i + 1; j < n; j++) {\n            size_t remaining = n - j - 1;\n            size_t vl = vsetvl_e32m1(remaining);\n\n            vint32m1_t vec_l = vle32_v_i32m1(&l[j + 1], vl);\n            vint32m1_t vec_sum = vmv_v_x_i32m1(l[i] + l[j], vl);\n            vint32m1_t vec_result = vadd_vv_i32m1(vec_sum, vec_l, vl);\n\n            vbool32_t mask = vmseq_vx_i32m1_b32(vec_result, 0, vl);\n            if (vfirst_m_b32(mask) >= 0) {\n                return true;\n            }\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_82_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <cstdint>\n\nbool triples_sum_to_zero_simd(std::vector<int> l) {\n    size_t n = l.size();\n    if (n < 3) {\n        return false;\n    }\n\n    for (size_t i = 0; i < n - 2; i++) {\n        size_t remaining_size = n - i - 1;\n        size_t vl = vsetvl_e32m1(remaining_size);\n        vint32m1_t vec1 = vle32_v_i32m1(&l[i + 1], vl);\n\n        for (size_t j = i + 1; j < n - 1; j++) {\n            vint32m1_t vec2 = vle32_v_i32m1(&l[j + 1], vl);\n            vint32m1_t sum_vec = vadd_vx_i32m1(vec1, l[i]);\n            sum_vec = vadd_vx_i32m1(sum_vec, l[j]);\n\n            vint32m1_t zero_vec = vmv_v_x_i32m1(0, vl);\n            vbool32_t mask = vmseq_vv_i32m1_b32(sum_vec, zero_vec, vl);\n\n            if (vfirst_m_b32(mask, vl) != -1) {\n                return true;\n            }\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_82_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <cstdint>\n\nbool triples_sum_to_zero_simd(std::vector<int> l) {\n    size_t n = l.size();\n    if (n < 3) return false;\n\n    for (size_t i = 0; i < n - 2; i++) {\n        for (size_t j = i + 1; j < n - 1; j++) {\n            int partial_sum = l[i] + l[j];\n            size_t remaining = n - j - 1;\n            size_t vl;\n            vint32m1_t vec_partial_sum = vmv_v_x_i32m1(partial_sum, vsetvl_e32m1(remaining));\n            vint32m1_t vec_l = vle32_v_i32m1(&l[j + 1], vsetvl_e32m1(remaining));\n            vint32m1_t vec_result = vadd_vv_i32m1(vec_partial_sum, vec_l, vsetvl_e32m1(remaining));\n            vbool32_t mask = vmseq_vx_i32m1_b32(vec_result, 0, vsetvl_e32m1(remaining));\n            if (vfirst_m_b32(mask, vsetvl_e32m1(remaining)) != -1) {\n                return true;\n            }\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_83_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> incr_list_simd(std::vector<int> l) {\n    size_t n = l.size();\n    std::vector<int> result(n);\n\n    size_t vlmax = vsetvlmax_e32m1(); // Maximum vector length for 32-bit integers\n    size_t i = 0;\n\n    while (i < n) {\n        size_t vl = vsetvl_e32m1(n - i); // Set vector length based on remaining elements\n        vint32m1_t vec = vle32_v_i32m1(&l[i], vl); // Load vector from input\n        vec = vadd_vx_i32m1(vec, 1, vl);           // Increment each element by 1\n        vse32_v_i32m1(&result[i], vec, vl);        // Store the result back to output\n        i += vl;                                   // Move to the next chunk\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_83_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> incr_list_simd(std::vector<int> l) {\n    size_t n = l.size();\n    std::vector<int> result(n);\n\n    size_t vlmax = vsetvlmax_e32m1(); // Maximum vector length for 32-bit integers\n    size_t i = 0;\n\n    while (i < n) {\n        size_t vl = vsetvl_e32m1(n - i); // Set vector length based on remaining elements\n        vint32m1_t vec = vle32_v_i32m1(&l[i], vl); // Load vector elements\n        vec = vadd_vx_i32m1(vec, 1, vl); // Increment each element by 1\n        vse32_v_i32m1(&result[i], vec, vl); // Store the result back to the output vector\n        i += vl; // Move to the next chunk\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_83_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> incr_list_simd(std::vector<int> l) {\n    size_t n = l.size();\n    std::vector<int> result(n);\n\n    size_t vlmax = vsetvlmax_e32m1(); // Maximum vector length for 32-bit integers\n    size_t i = 0;\n\n    while (i < n) {\n        size_t vl = vsetvl_e32m1(n - i); // Set vector length based on remaining elements\n        vint32m1_t vec = vle32_v_i32m1(&l[i], vl); // Load vector from input\n        vec = vadd_vx_i32m1(vec, 1, vl);           // Increment each element by 1\n        vse32_v_i32m1(&result[i], vec, vl);        // Store result vector\n        i += vl;                                   // Move to the next chunk\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_83_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> incr_list_simd(std::vector<int> l) {\n    size_t n = l.size();\n    std::vector<int> result(n);\n    size_t vlmax = vsetvlmax_e32m1(); // Maximum vector length for 32-bit integers\n\n    for (size_t i = 0; i < n; i += vlmax) {\n        size_t vl = vsetvl_e32m1(n - i); // Set vector length based on remaining elements\n        vint32m1_t vec = vle32_v_i32m1(&l[i], vl); // Load vector from input\n        vint32m1_t vec_incr = vadd_vx_i32m1(vec, 1, vl); // Increment each element by 1\n        vse32_v_i32m1(&result[i], vec_incr, vl); // Store result vector\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_83_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> incr_list_simd(std::vector<int> l) {\n    size_t n = l.size();\n    std::vector<int> result(n);\n    size_t vlmax = vsetvlmax_e32m1(); // Maximum vector length for 32-bit integers\n    size_t i = 0;\n\n    while (i < n) {\n        size_t vl = vsetvl_e32m1(n - i); // Set vector length based on remaining elements\n        vint32m1_t vec = vle32_v_i32m1(&l[i], vl); // Load elements into vector\n        vec = vadd_vx_i32m1(vec, 1, vl); // Increment each element by 1\n        vse32_v_i32m1(&result[i], vec, vl); // Store the result back to the output vector\n        i += vl; // Move to the next chunk\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_84_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <cstdint>\n\nbool pairs_sum_to_zero_simd(std::vector<int> l) {\n    size_t n = l.size();\n    if (n < 2) return false;\n\n    for (size_t i = 0; i < n; i++) {\n        int32_t current = l[i];\n        size_t remaining = n - i - 1;\n        size_t vl = vsetvl_e32m1(remaining); // Set vector length based on remaining elements\n        vint32m1_t vec = vle32_v_i32m1(&l[i + 1], vl); // Load remaining elements into vector\n        vint32m1_t neg_current_vec = vmv_v_x_i32m1(-current, vl); // Create vector with -current replicated\n        vbool32_t mask = vmseq_vv_i32m1_b32(vec, neg_current_vec, vl); // Compare elements for equality\n        if (vfirst_m_b32(mask, vl) >= 0) { // Check if any match is found\n            return true;\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_84_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nbool pairs_sum_to_zero_simd(std::vector<int> l) {\n    size_t n = l.size();\n    if (n < 2) return false;\n\n    for (size_t i = 0; i < n; i++) {\n        int current = l[i];\n        size_t remaining = n - i - 1;\n        const int *ptr = l.data() + i + 1;\n\n        while (remaining > 0) {\n            size_t vl = vsetvl_e32m1(remaining);\n            vint32m1_t vec = vle32_v_i32m1(ptr, vl);\n            vint32m1_t sum = vadd_vx_i32m1(vec, current, vl);\n            vbool32_t mask = vmseq_vx_i32m1_b32(sum, 0, vl);\n\n            if (vfirst_m_b32(mask) >= 0) {\n                return true;\n            }\n\n            ptr += vl;\n            remaining -= vl;\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_84_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <cstdint>\n\nbool pairs_sum_to_zero_simd(std::vector<int> l) {\n    size_t n = l.size();\n    if (n < 2) return false;\n\n    for (size_t i = 0; i < n; i++) {\n        int32_t current = l[i];\n        size_t remaining = n - i - 1;\n        const int32_t* data = l.data() + i + 1;\n\n        size_t vl;\n        while (remaining > 0) {\n            vl = vsetvl_e32m1(remaining);\n            vint32m1_t vec = vle32_v_i32m1(data, vl);\n            vint32m1_t sum = vadd_vx_i32m1(vec, current, vl);\n            vbool32_t mask = vmseq_vx_i32m1_b32(sum, 0, vl);\n            if (vfirst_m_b32(mask) != -1) {\n                return true;\n            }\n            data += vl;\n            remaining -= vl;\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_84_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nbool pairs_sum_to_zero_simd(std::vector<int> l) {\n    size_t n = l.size();\n    if (n < 2) {\n        return false;\n    }\n\n    for (size_t i = 0; i < n; i++) {\n        int current = l[i];\n        size_t remaining = n - i - 1;\n        size_t vl = vsetvl_e32m1(remaining);\n        vint32m1_t vec = vle32_v_i32m1(&l[i + 1], vl);\n        vint32m1_t neg_current_vec = vmv_v_x_i32m1(-current, vl);\n        vbool32_t mask = vmseq_vv_i32m1_b32(vec, neg_current_vec, vl);\n        if (vfirst_m_b32(mask) != -1) {\n            return true;\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_84_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <cstdint>\n\nbool pairs_sum_to_zero_simd(std::vector<int> l) {\n    size_t n = l.size();\n    if (n < 2) return false;\n\n    for (size_t i = 0; i < n; i++) {\n        int32_t current = l[i];\n        size_t remaining = n - i - 1;\n        size_t vl = vsetvl_e32m1(remaining);\n\n        const int32_t* ptr = l.data() + i + 1;\n        vint32m1_t vec = vle32_v_i32m1(ptr, vl);\n        vint32m1_t neg_vec = vneg_v_i32m1(vec, vl);\n\n        vint32m1_t match = vmv_v_x_i32m1(current, vl);\n        vbool32_t mask = vmseq_vv_i32m1_b32(match, neg_vec, vl);\n\n        if (vfirst_m_b32(mask, vl) >= 0) {\n            return true;\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_85_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nstd::string change_base_simd(int64_t x, int8_t base) {\n    if (base < 2 || base > 9) {\n        return \"\"; // Invalid base\n    }\n\n    const size_t max_digits = 64; // Maximum digits for a 64-bit integer\n    int8_t digits[max_digits];\n    size_t digit_count = 0;\n\n    while (x > 0) {\n        digits[digit_count++] = x % base;\n        x /= base;\n    }\n\n    // Reverse the digits array using RVV\n    size_t vl;\n    for (size_t i = 0; i < digit_count / 2; i += vl) {\n        vl = vsetvl_e8m1(digit_count - i);\n        vint8m1_t vec_front = vle8_v_i8m1(&digits[i], vl);\n        vint8m1_t vec_back = vle8_v_i8m1(&digits[digit_count - vl - i], vl);\n\n        vse8_v_i8m1(&digits[i], vec_back, vl);\n        vse8_v_i8m1(&digits[digit_count - vl - i], vec_front, vl);\n    }\n\n    // Convert digits to string\n    std::string result;\n    for (size_t i = 0; i < digit_count; ++i) {\n        result += '0' + digits[i];\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_85_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nstd::string change_base_simd(int64_t x, int8_t base) {\n    if (base < 2 || base > 9) {\n        return \"\"; // Invalid base\n    }\n\n    const int max_digits = 64; // Maximum digits for a 64-bit number in binary\n    char result[max_digits];\n    int index = max_digits;\n\n    while (x > 0) {\n        size_t vl = vsetvl_e64m1(1); // Set vector length to 1 (scalar operation for simplicity)\n        vint64m1_t vx = vmv_v_x_i64m1(x, vl); // Load x into vector\n        vint64m1_t vbase = vmv_v_x_i64m1(base, vl); // Load base into vector\n        vint64m1_t vrem = vrem_vv_i64m1(vx, vbase, vl); // Compute remainder\n        vint64m1_t vdiv = vdiv_vv_i64m1(vx, vbase, vl); // Compute division\n\n        x = vmv_x_s_i64m1_i64(vdiv); // Extract scalar result from vector\n        int remainder = vmv_x_s_i64m1_i64(vrem); // Extract scalar remainder from vector\n\n        result[--index] = '0' + remainder; // Convert remainder to character\n    }\n\n    return std::string(result + index, result + max_digits); // Return the result as a string\n}\n```"}
{"task_id": "SimdBench_85_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nstd::string change_base_simd(int64_t x, int8_t base) {\n    if (base < 2 || base > 9) return \"\"; // Invalid base\n\n    const int max_digits = 64; // Maximum digits for base conversion\n    char result[max_digits];\n    int index = max_digits;\n\n    while (x > 0) {\n        size_t vl = vsetvl_e64m1(1); // Set vector length to 1 (scalar operation for each digit)\n        vint64m1_t vx = vmv_v_x_i64m1(x, vl); // Load x into vector register\n        vint64m1_t vbase = vmv_v_x_i64m1(base, vl); // Load base into vector register\n        vint64m1_t vrem = vrem_vv_i64m1(vx, vbase, vl); // Compute remainder (x % base)\n        vint64m1_t vdiv = vdiv_vv_i64m1(vx, vbase, vl); // Compute quotient (x / base)\n\n        x = vmv_x_s_i64m1_i64(vdiv); // Extract quotient back to scalar\n        int digit = vmv_x_s_i64m1_i64(vrem); // Extract remainder back to scalar\n        result[--index] = '0' + digit; // Convert digit to character and store\n    }\n\n    return std::string(result + index, result + max_digits); // Return the result as a string\n}\n```"}
{"task_id": "SimdBench_85_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nstd::string change_base_simd(int64_t x, int8_t base) {\n    if (base < 2 || base > 9) return \"\"; // Invalid base\n\n    const int max_digits = 64; // Maximum possible digits for a 64-bit number\n    int8_t digits[max_digits];\n    int count = 0;\n\n    while (x > 0) {\n        digits[count++] = x % base;\n        x /= base;\n    }\n\n    // Reverse the digits array using RVV intrinsics\n    size_t vl;\n    for (size_t i = 0; i < count / 2; i += vl) {\n        vl = vsetvl_e8m1(count - i * 2);\n        vint8m1_t vec_front = vle8_v_i8m1(&digits[i], vl);\n        vint8m1_t vec_back = vle8_v_i8m1(&digits[count - i - vl], vl);\n\n        vse8_v_i8m1(&digits[i], vec_back, vl);\n        vse8_v_i8m1(&digits[count - i - vl], vec_front, vl);\n    }\n\n    // Convert digits to string\n    std::string result;\n    for (int i = 0; i < count; ++i) {\n        result += '0' + digits[i];\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_85_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nstd::string change_base_simd(int64_t x, int8_t base) {\n    if (base < 2 || base > 9) {\n        return \"\"; // Invalid base\n    }\n\n    const int max_digits = 64; // Maximum possible digits for base conversion\n    char result[max_digits];\n    int index = max_digits;\n\n    while (x > 0) {\n        size_t vl = vsetvl_e64m1(1); // Set vector length to 1 for scalar-like operation\n        vint64m1_t vx = vmv_v_x_i64m1(x, vl); // Load x into vector register\n        vint64m1_t vbase = vmv_v_x_i64m1(base, vl); // Load base into vector register\n        vint64m1_t vrem = vrem_vv_i64m1(vx, vbase, vl); // Compute remainder\n        vint64m1_t vdiv = vdiv_vv_i64m1(vx, vbase, vl); // Compute division\n\n        x = vmv_x_s_i64m1_i64(vdiv); // Extract the quotient back to scalar\n        int64_t remainder = vmv_x_s_i64m1_i64(vrem); // Extract the remainder back to scalar\n\n        result[--index] = '0' + remainder; // Convert remainder to character and store\n    }\n\n    return std::string(result + index, result + max_digits); // Return the result as a string\n}\n```"}
{"task_id": "SimdBench_86_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nbool is_palindrome_simd(std::string text) {\n    size_t n = text.size();\n    if (n <= 1) return true;\n\n    size_t vlmax = vsetvlmax_e8m1();\n    size_t i = 0;\n\n    while (i < n / 2) {\n        size_t vl = vsetvl_e8m1(std::min(n / 2 - i, vlmax));\n\n        vint8m1_t vec_start = vle8_v_i8m1(reinterpret_cast<const int8_t*>(text.data() + i), vl);\n        vint8m1_t vec_end = vle8_v_i8m1(reinterpret_cast<const int8_t*>(text.data() + n - i - vl), vl);\n\n        vbool8_t mask = vmseq_vv_i8m1_b8(vec_start, vec_end, vl);\n        if (vcpop_b8(mask, vl) != vl) return false;\n\n        i += vl;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_86_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nbool is_palindrome_simd(std::string text) {\n    size_t n = text.size();\n    if (n <= 1) return true;\n\n    size_t vlmax = vsetvlmax_e8m1();\n    size_t i = 0;\n\n    while (i < n / 2) {\n        size_t vl = vsetvl_e8m1(std::min(n / 2 - i, vlmax));\n        vint8m1_t vec_front = vle8_v_i8m1(reinterpret_cast<const int8_t*>(text.data() + i), vl);\n        vint8m1_t vec_back = vle8_v_i8m1(reinterpret_cast<const int8_t*>(text.data() + n - i - vl), vl);\n\n        vbool8_t mask = vmseq_vv_i8m1_b8(vec_front, vec_back, vl);\n        if (!vcpop_b8(mask)) return false;\n\n        i += vl;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_86_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nbool is_palindrome_simd(std::string text) {\n    size_t n = text.size();\n    if (n <= 1) {\n        return true;\n    }\n\n    size_t vl;\n    size_t i = 0;\n\n    while (i < n / 2) {\n        vl = vsetvl_e8m1(std::min(n / 2 - i, vsetvlmax_e8m1()));\n        vuint8m1_t front = vle8_v_u8m1((const uint8_t*)&text[i], vl);\n        vuint8m1_t back = vle8_v_u8m1((const uint8_t*)&text[n - i - vl], vl);\n        back = vrsub_vx_u8m1(back, 0, vl); // Reverse the back vector\n\n        vbool8_t mask = vmseq_vv_u8m1_b8(front, back, vl);\n        if (!vmsbf_m_b8(mask, vl)) {\n            return false;\n        }\n\n        i += vl;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_86_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nbool is_palindrome_simd(std::string text) {\n    size_t n = text.size();\n    if (n == 0) return true;\n\n    size_t vlmax = vsetvlmax_e8m1();\n    size_t i = 0;\n\n    while (i < n / 2) {\n        size_t vl = vsetvl_e8m1(std::min(n / 2 - i, vlmax));\n        vint8m1_t vec_front = vle8_v_i8m1((const int8_t*)(text.data() + i), vl);\n        vint8m1_t vec_back = vle8_v_i8m1((const int8_t*)(text.data() + n - i - vl), vl);\n\n        vbool8_t mask = vmseq_vv_i8m1_b8(vec_front, vec_back, vl);\n        if (vcpop_b8(mask, vl) != vl) return false;\n\n        i += vl;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_86_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nbool is_palindrome_simd(std::string text) {\n    size_t n = text.size();\n    if (n <= 1) return true;\n\n    size_t vlmax = vsetvlmax_e8m1(); // Maximum vector length for 8-bit elements\n    size_t i = 0;\n\n    while (i < n / 2) {\n        size_t vl = vsetvl(n / 2 - i, vlmax); // Set vector length based on remaining elements\n        vuint8m1_t front_vec = vle8_v_u8m1((const uint8_t*)&text[i], vl);\n        vuint8m1_t back_vec = vle8_v_u8m1((const uint8_t*)&text[n - i - vl], vl);\n\n        // Reverse the back_vec\n        back_vec = vrgather_vv_u8m1(back_vec, vslide1down_vx_u8m1(vundefined_u8m1(), vl - 1, vl), vl);\n\n        // Compare front_vec and reversed back_vec\n        vbool8_t mask = vmseq_vv_u8m1_b8(front_vec, back_vec, vl);\n        if (vfirst_m_b8(mask, vl) != -1) return false;\n\n        i += vl;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_87_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nstd::string decode_shift_simd(std::string s) {\n    size_t len = s.length();\n    std::string out(len, ' '); // Preallocate output string with the same length as input\n\n    size_t i = 0;\n    const int shift = 5;\n    const int base = 'a';\n    const int mod = 26;\n\n    while (i < len) {\n        size_t vl = vsetvl_e8m1(len - i); // Set vector length based on remaining elements\n        vint8m1_t vec_in = vle8_v_i8m1((const int8_t*)&s[i], vl); // Load input characters\n        vint8m1_t vec_shifted = vsub_vx_i8m1(vec_in, shift, vl); // Subtract the shift value\n        vint8m1_t vec_base = vsub_vx_i8m1(vec_shifted, base, vl); // Subtract 'a' to normalize\n        vint8m1_t vec_mod = vrem_vx_i8m1(vec_base, mod, vl); // Apply modulo operation\n        vint8m1_t vec_decoded = vadd_vx_i8m1(vec_mod, base, vl); // Add 'a' back to get decoded characters\n        vse8_v_i8m1((int8_t*)&out[i], vec_decoded, vl); // Store decoded characters into output string\n        i += vl; // Increment index by vector length\n    }\n\n    return out;\n}\n```"}
{"task_id": "SimdBench_87_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nstd::string decode_shift_simd(std::string s) {\n    size_t n = s.length();\n    std::string out(n, ' ');\n\n    size_t vlmax = vsetvlmax_e8m1(); // Maximum vector length for 8-bit elements\n    size_t i = 0;\n\n    while (i < n) {\n        size_t vl = vsetvl_e8m1(n - i); // Set vector length based on remaining elements\n        vint8m1_t vec_in = vle8_v_i8m1((const int8_t*)&s[i], vl); // Load input characters\n        vint8m1_t vec_decoded = vsub_vx_i8m1(vec_in, 5, vl); // Subtract 5 to decode\n        vint8m1_t vec_adjusted = vadd_vx_i8m1(vec_decoded, 26, vl); // Add 26 to handle negative wrap-around\n        vint8m1_t vec_mod = vsub_vx_i8m1(vec_adjusted, 'a', vl); // Subtract 'a' to normalize\n        vint8m1_t vec_result = vrem_vx_i8m1(vec_mod, 26, vl); // Modulo 26\n        vec_result = vadd_vx_i8m1(vec_result, 'a', vl); // Add 'a' back to get final decoded characters\n        vse8_v_i8m1((int8_t*)&out[i], vec_result, vl); // Store the result\n        i += vl;\n    }\n\n    return out;\n}\n```"}
{"task_id": "SimdBench_87_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nstd::string decode_shift_simd(std::string s) {\n    size_t n = s.length();\n    std::string out(n, ' ');\n    size_t vlmax = vsetvlmax_e8m1(); // Maximum vector length for 8-bit elements\n    size_t i = 0;\n\n    while (i < n) {\n        size_t vl = vsetvl_e8m1(n - i); // Set vector length based on remaining elements\n        vint8m1_t vec_in = vle8_v_i8m1((const int8_t*)&s[i], vl); // Load input characters\n        vint8m1_t vec_decoded = vsub_vx_i8m1(vec_in, 5, vl); // Subtract 5 from each character\n        vint8m1_t vec_adjusted = vsub_vx_i8m1(vec_decoded, (int8_t)'a', vl); // Adjust to 'a'-based index\n        vint8m1_t vec_mod = vrem_vx_i8m1(vec_adjusted, 26, vl); // Apply modulo 26\n        vint8m1_t vec_final = vadd_vx_i8m1(vec_mod, (int8_t)'a', vl); // Convert back to ASCII\n        vse8_v_i8m1((int8_t*)&out[i], vec_final, vl); // Store decoded characters\n        i += vl;\n    }\n\n    return out;\n}\n```"}
{"task_id": "SimdBench_87_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nstd::string decode_shift_simd(std::string s) {\n    size_t n = s.length();\n    std::string out(n, ' ');\n\n    size_t vlmax = vsetvlmax_e8m1(); // Maximum vector length for 8-bit elements\n    size_t i = 0;\n\n    while (i < n) {\n        size_t vl = vsetvl_e8m1(n - i); // Set vector length for remaining elements\n        vint8m1_t vec_in = vle8_v_i8m1((const int8_t*)&s[i], vl); // Load input characters\n        vint8m1_t vec_decoded = vsub_vx_i8m1(vec_in, 5, vl); // Subtract 5 to decode\n        vint8m1_t vec_adjusted = vadd_vx_i8m1(vec_decoded, 26, vl); // Add 26 to handle wrap-around\n        vint8m1_t vec_result = vsub_vx_i8m1(vec_adjusted, 'a', vl); // Normalize to 0-25 range\n        vec_result = vrem_vx_i8m1(vec_result, 26, vl); // Modulo 26\n        vec_result = vadd_vx_i8m1(vec_result, 'a', vl); // Convert back to ASCII\n        vse8_v_i8m1((int8_t*)&out[i], vec_result, vl); // Store result\n        i += vl;\n    }\n\n    return out;\n}\n```"}
{"task_id": "SimdBench_87_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nstd::string decode_shift_simd(std::string s) {\n    size_t n = s.length();\n    std::string out(n, ' ');\n\n    size_t vlmax = vsetvlmax_e8m1(); // Maximum vector length for 8-bit elements\n    size_t i = 0;\n\n    while (i < n) {\n        size_t vl = vsetvl_e8m1(n - i); // Set vector length based on remaining elements\n        vint8m1_t vec_in = vle8_v_i8m1((const int8_t*)&s[i], vl); // Load input characters\n        vint8m1_t vec_decoded = vsub_vx_i8m1(vec_in, 5, vl); // Subtract 5 to decode\n        vint8m1_t vec_adjusted = vadd_vx_i8m1(vec_decoded, 26, vl); // Add 26 to handle negative wrap-around\n        vint8m1_t vec_mod = vsub_vx_i8m1(vec_adjusted, 'a', vl); // Subtract 'a' to normalize to 0-25 range\n        vint8m1_t vec_final = vmod_vx_i8m1(vec_mod, 26, vl); // Perform modulo 26\n        vec_final = vadd_vx_i8m1(vec_final, 'a', vl); // Add 'a' back to get final decoded characters\n        vse8_v_i8m1((int8_t*)&out[i], vec_final, vl); // Store decoded characters\n        i += vl;\n    }\n\n    return out;\n}\n```"}
{"task_id": "SimdBench_88_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nbool below_threshold_simd(std::vector<int> l, int t) {\n    size_t n = l.size();\n    size_t vlmax = vsetvlmax_e32m1();\n    for (size_t i = 0; i < n; i += vlmax) {\n        size_t vl = vsetvl_e32m1(n - i);\n        vint32m1_t vec = vle32_v_i32m1(&l[i], vl);\n        vint32m1_t threshold_vec = vmv_v_x_i32m1(t, vl);\n        vbool32_t mask = vmslt_vv_i32m1_b32(vec, threshold_vec, vl);\n        if (!vcpop_b32(mask)) {\n            return false;\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_88_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nbool below_threshold_simd(std::vector<int> l, int t) {\n    size_t n = l.size();\n    size_t vlmax = vsetvlmax_e32m1();\n    size_t i = 0;\n\n    while (i < n) {\n        size_t vl = vsetvl_e32m1(n - i);\n        vint32m1_t vec = vle32_v_i32m1(&l[i], vl);\n        vint32m1_t threshold_vec = vmv_v_x_i32m1(t, vl);\n        vbool32_t mask = vmflt_vv_i32m1_b32(vec, threshold_vec, vl);\n        if (!vcpop_b32(mask)) {\n            return false;\n        }\n        i += vl;\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_88_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nbool below_threshold_simd(std::vector<int> l, int t) {\n    size_t n = l.size();\n    size_t vlmax = vsetvlmax_e32m1(); // Maximum vector length for 32-bit integers\n    size_t i = 0;\n\n    while (i < n) {\n        size_t vl = vsetvl_e32m1(n - i); // Set vector length based on remaining elements\n        vint32m1_t vec = vle32_v_i32m1(&l[i], vl); // Load vector elements\n        vint32m1_t threshold_vec = vmv_v_x_i32m1(t, vl); // Broadcast threshold value\n        vbool32_t mask = vmflt_vv_i32m1_b32(vec, threshold_vec, vl); // Compare elements with threshold\n        if (!vcpop_b32(mask)) { // Check if all elements satisfy the condition\n            return false;\n        }\n        i += vl; // Move to the next chunk\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_88_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nbool below_threshold_simd(std::vector<int> l, int t) {\n    size_t n = l.size();\n    size_t vlmax = vsetvlmax_e32m1();\n    size_t i = 0;\n\n    while (i < n) {\n        size_t vl = vsetvl_e32m1(n - i);\n        vint32m1_t vec = vle32_v_i32m1(&l[i], vl);\n        vint32m1_t threshold_vec = vmv_v_x_i32m1(t, vl);\n        vbool32_t mask = vmflt_vv_i32m1_b32(vec, threshold_vec, vl);\n\n        if (!vcpop_b32(mask, vl)) {\n            return false;\n        }\n        i += vl;\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_88_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nbool below_threshold_simd(std::vector<int> l, int t) {\n    size_t n = l.size();\n    size_t vl;\n    vbool32_t result = vbool32_t(); // Initialize result to true for all lanes\n    for (size_t i = 0; i < n; i += vl) {\n        vl = vsetvl_e32m1(n - i); // Set vector length\n        vint32m1_t vec = vle32_v_i32m1(&l[i], vl); // Load vector elements\n        vbool32_t cmp = vmflt_vx_i32m1_b32(vec, t, vl); // Compare elements with threshold\n        result = vmand_mm_b32(result, cmp, vl); // Combine results\n        if (!vfirst_m_b32(result, vl)) { // Check if any lane is false\n            return false;\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_89_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nbool correct_bracketing_simd(std::string brackets) {\n    size_t n = brackets.size();\n    size_t vlmax = vsetvlmax_e8m1(); // Maximum vector length for 8-bit elements\n    int balance = 0;\n\n    for (size_t i = 0; i < n; i += vlmax) {\n        size_t vl = vsetvl_e8m1(n - i); // Set vector length based on remaining elements\n        vint8m1_t vec = vle8_v_i8m1((const int8_t*)(brackets.data() + i), vl);\n\n        vint8m1_t is_open = vmseq_vx_i8m1(vec, '<', vl); // Check for '<'\n        vint8m1_t is_close = vmseq_vx_i8m1(vec, '>', vl); // Check for '>'\n\n        vint8m1_t delta = vsub_vv_i8m1(vreinterpret_v_i8m1_u8(is_open), vreinterpret_v_i8m1_u8(is_close), vl);\n        balance += vcpop_m_b8(vmslt_vx_i8m1(delta, 0, vl)); // Count imbalance\n\n        if (balance < 0) return false;\n    }\n\n    return balance == 0;\n}\n```"}
{"task_id": "SimdBench_89_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nbool correct_bracketing_simd(std::string brackets) {\n    size_t n = brackets.size();\n    size_t vlmax = vsetvlmax_e8m1();\n    int balance = 0;\n\n    for (size_t i = 0; i < n; i += vlmax) {\n        size_t vl = vsetvl_e8m1(n - i);\n        vint8m1_t vec = vle8_v_i8m1((const int8_t*)(brackets.data() + i), vl);\n\n        vint8m1_t is_open = vmseq_vx_i8m1(vec, '<', vl);\n        vint8m1_t is_close = vmseq_vx_i8m1(vec, '>', vl);\n\n        vint8m1_t delta = vsub_vv_i8m1(vreinterpret_v_i1_i8m1(is_open), vreinterpret_v_i1_i8m1(is_close), vl);\n        balance += vcpop_m_b8(vmslt_vx_i8m1(delta, 0, vl));\n\n        if (balance < 0) return false;\n    }\n\n    return balance == 0;\n}\n```"}
{"task_id": "SimdBench_89_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nbool correct_bracketing_simd(std::string brackets) {\n    size_t n = brackets.size();\n    size_t vlmax = vsetvlmax_e8m1();\n    int balance = 0;\n\n    for (size_t i = 0; i < n; i += vlmax) {\n        size_t vl = vsetvl_e8m1(n - i);\n        vint8m1_t vec = vle8_v_i8m1((const int8_t*)(brackets.data() + i), vl);\n\n        vint8m1_t is_open = vmseq_vx_i8m1(vec, '<', vl);\n        vint8m1_t is_close = vmseq_vx_i8m1(vec, '>', vl);\n\n        vint8m1_t delta = vsub_vv_i8m1(vreinterpret_v_i8m1_u8m1(is_open), vreinterpret_v_i8m1_u8m1(is_close), vl);\n        balance += vcpop_m_b8(vmsgt_vx_i8m1(delta, 0, vl));\n\n        if (balance < 0) return false;\n    }\n\n    return balance == 0;\n}\n```"}
{"task_id": "SimdBench_89_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nbool correct_bracketing_simd(std::string brackets) {\n    size_t n = brackets.size();\n    size_t vlmax = vsetvlmax_e8m1();\n    int balance = 0;\n\n    for (size_t i = 0; i < n; i += vlmax) {\n        size_t vl = vsetvl_e8m1(n - i);\n        vint8m1_t vec = vle8_v_i8m1((const int8_t*)(brackets.data() + i), vl);\n\n        vint8m1_t is_open = vmseq_vx_i8m1(vec, '<', vl);\n        vint8m1_t is_close = vmseq_vx_i8m1(vec, '>', vl);\n\n        vint8m1_t delta = vsub_vv_i8m1(vreinterpret_v_i8m1_u8m1(is_open), vreinterpret_v_i8m1_u8m1(is_close), vl);\n        balance += vcpop_m_b8(vmsgt_vx_i8m1(delta, 0, vl));\n    }\n\n    return balance == 0;\n}\n```"}
{"task_id": "SimdBench_89_RVV", "completion": "```c++\n#include <riscv_vector.h>\n#include <string>\n\nbool correct_bracketing_simd(std::string brackets) {\n    size_t n = brackets.size();\n    size_t vlmax = vsetvlmax_e8m1(); // Maximum vector length for 8-bit elements\n    int balance = 0;\n\n    for (size_t i = 0; i < n; i += vlmax) {\n        size_t vl = vsetvl_e8m1(n - i); // Set vector length for the remaining elements\n        vuint8m1_t vec = vle8_v_u8m1((const uint8_t*)&brackets[i], vl);\n\n        vbool8_t is_open = vmseq_vx_u8m1_b8(vec, '<', vl);  // Compare for '<'\n        vbool8_t is_close = vmseq_vx_u8m1_b8(vec, '>', vl); // Compare for '>'\n\n        vint8m1_t open_count = vmerge_vxm_i8m1(vundefined_i8m1(), 1, is_open, vl);\n        vint8m1_t close_count = vmerge_vxm_i8m1(vundefined_i8m1(), -1, is_close, vl);\n\n        vint8m1_t net_count = vadd_vv_i8m1(open_count, close_count, vl);\n\n        int8_t temp[vlmax];\n        vse8_v_i8m1(temp, net_count, vl);\n\n        for (size_t j = 0; j < vl; ++j) {\n            balance += temp[j];\n            if (balance < 0) {\n                return false; // Early exit if balance goes negative\n            }\n        }\n    }\n\n    return balance == 0; // Valid if balance is zero\n}\n```"}
{"task_id": "SimdBench_90_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nbool correct_bracketing_simd(std::string brackets) {\n    size_t n = brackets.size();\n    if (n == 0) return true;\n\n    int balance = 0;\n    size_t vlmax = vsetvlmax_e8m1(); // Maximum vector length for 8-bit elements\n    size_t i = 0;\n\n    while (i < n) {\n        size_t vl = vsetvl_e8m1(n - i); // Set vector length based on remaining elements\n        vint8m1_t vec = vle8_v_i8m1((int8_t*)(brackets.data() + i), vl);\n\n        vint8m1_t open = vmv_v_x_i8m1('(', vl);\n        vint8m1_t close = vmv_v_x_i8m1(')', vl);\n\n        vbool8_t is_open = vmseq_vv_i8m1_b8(vec, open, vl);\n        vbool8_t is_close = vmseq_vv_i8m1_b8(vec, close, vl);\n\n        vint8m1_t open_count = vpopc_m_b8(is_open, vl);\n        vint8m1_t close_count = vpopc_m_b8(is_close, vl);\n\n        balance += vget_i8m1(open_count, 0) - vget_i8m1(close_count, 0);\n\n        if (balance < 0) return false; // Early exit if balance goes negative\n        i += vl;\n    }\n\n    return balance == 0;\n}\n```"}
{"task_id": "SimdBench_90_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nbool correct_bracketing_simd(std::string brackets) {\n    size_t n = brackets.size();\n    if (n == 0) return true;\n\n    size_t vlmax = vsetvlmax_e8m1();\n    int32_t balance = 0;\n\n    for (size_t i = 0; i < n; i += vlmax) {\n        size_t vl = vsetvl_e8m1(n - i);\n        vint8m1_t vec = vle8_v_i8m1((const int8_t*)brackets.data() + i, vl);\n\n        vint8m1_t open = vmv_v_x_i8m1('(', vl);\n        vint8m1_t close = vmv_v_x_i8m1(')', vl);\n\n        vbool8_t is_open = vmseq_vv_i8m1_b8(vec, open, vl);\n        vbool8_t is_close = vmseq_vv_i8m1_b8(vec, close, vl);\n\n        vint32m1_t open_count = vcpop_m_b8(is_open, vl);\n        vint32m1_t close_count = vcpop_m_b8(is_close, vl);\n\n        balance += vget_first_i32m1(open_count) - vget_first_i32m1(close_count);\n        if (balance < 0) return false;\n    }\n\n    return balance == 0;\n}\n```"}
{"task_id": "SimdBench_90_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nbool correct_bracketing_simd(std::string brackets) {\n    size_t n = brackets.size();\n    size_t vlmax = vsetvlmax_e8m1(); // Maximum vector length for 8-bit elements\n    int32_t balance = 0;\n\n    for (size_t i = 0; i < n; i += vlmax) {\n        size_t vl = vsetvl_e8m1(n - i); // Set vector length based on remaining elements\n        vuint8m1_t vec = vle8_v_u8m1((const uint8_t*)&brackets[i], vl);\n\n        // Map '(' to +1 and ')' to -1\n        vint8m1_t mapped = vsub_vx_i8m1(vreinterpret_v_u8m1_i8m1(vec), 40); // '(' = 40, ')' = 41\n        mapped = vsub_vx_i8m1(mapped, 1); // '(' -> +1, ')' -> -1\n\n        // Compute prefix sum\n        vint32m1_t prefix_sum = vmv_v_x_i32m1(0, vl);\n        vint32m1_t carry = vmv_v_x_i32m1(balance, vl);\n        for (size_t j = 0; j < vl; ++j) {\n            carry = vadd_vv_i32m1(carry, mapped);\n        }\n        balance = carry;\n    }\n}\n```"}
{"task_id": "SimdBench_90_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nbool correct_bracketing_simd(std::string brackets) {\n    size_t n = brackets.size();\n    if (n == 0) return true;\n\n    size_t vlmax = vsetvlmax_e8m1();\n    int32_t balance = 0;\n\n    for (size_t i = 0; i < n; i += vlmax) {\n        size_t vl = vsetvl_e8m1(n - i);\n        vint8m1_t vec = vle8_v_i8m1((const int8_t*)(brackets.data() + i), vl);\n\n        vint8m1_t open_vec = vmv_v_x_i8m1('(', vl);\n        vint8m1_t close_vec = vmv_v_x_i8m1(')', vl);\n\n        vbool8_t is_open = vmseq_vv_i8m1_b8(vec, open_vec, vl);\n        vbool8_t is_close = vmseq_vv_i8m1_b8(vec, close_vec, vl);\n\n        vint32m1_t open_count = vcpop_m_b8(is_open, vl);\n        vint32m1_t close_count = vcpop_m_b8(is_close, vl);\n\n        balance += vgetfirst_i32m1(open_count) - vgetfirst_i32m1(close_count);\n        if (balance < 0) return false;\n    }\n\n    return balance == 0;\n}\n```"}
{"task_id": "SimdBench_90_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nbool correct_bracketing_simd(std::string brackets) {\n    size_t n = brackets.size();\n    if (n == 0) return true;\n\n    size_t vlmax = vsetvlmax_e8m1();\n    int32_t balance = 0;\n\n    for (size_t i = 0; i < n; i += vlmax) {\n        size_t vl = vsetvl_e8m1(n - i);\n        vint8m1_t vec = vle8_v_i8m1((const int8_t*)(brackets.data() + i), vl);\n\n        vint8m1_t open = vmv_v_x_i8m1('(', vl);\n        vint8m1_t close = vmv_v_x_i8m1(')', vl);\n\n        vbool8_t is_open = vmseq_vv_i8m1_b8(vec, open, vl);\n        vbool8_t is_close = vmseq_vv_i8m1_b8(vec, close, vl);\n\n        vint32m1_t open_count = vcpop_b8(is_open, vl);\n        vint32m1_t close_count = vcpop_b8(is_close, vl);\n\n        balance += vget_first_i32m1(open_count) - vget_first_i32m1(close_count);\n        if (balance < 0) return false;\n    }\n\n    return balance == 0;\n}\n```"}
{"task_id": "SimdBench_91_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<float> derivative_simd(std::vector<float> xs) {\n    size_t n = xs.size();\n    if (n <= 1) {\n        return {}; // Derivative of a constant or empty polynomial is empty.\n    }\n\n    std::vector<float> result(n - 1);\n    size_t vlmax = vsetvlmax_e32m1(); // Maximum vector length for 32-bit floats.\n\n    for (size_t i = 1; i < n; i += vlmax) {\n        size_t vl = vsetvl_e32m1(n - i); // Set vector length dynamically based on remaining elements.\n\n        vuint32m1_t indices = vid_v_u32m1(vl); // Create vector of indices [0, 1, 2, ...].\n        vfloat32m1_t coeffs = vle32_v_f32m1(&xs[i], vl); // Load coefficients starting from xs[i].\n        vfloat32m1_t factors = vfcvt_f_x_v_f32m1(vadd_vx_u32m1(indices, i, vl), vl); // Convert indices + i to float.\n\n        vfloat32m1_t product = vfmul_vv_f32m1(coeffs, factors, vl); // Multiply coefficients by their respective factors.\n        vse32_v_f32m1(&result[i - 1], product, vl); // Store the result back to the result vector.\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_91_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<float> derivative_simd(std::vector<float> xs) {\n    size_t n = xs.size();\n    if (n <= 1) {\n        return {}; // Derivative of a constant or empty polynomial is empty\n    }\n\n    std::vector<float> result(n - 1);\n    size_t vlmax = vsetvlmax_e32m1(); // Maximum vector length for 32-bit floats\n    size_t i = 1;\n\n    for (; i < n; i += vlmax) {\n        size_t vl = vsetvl_e32m1(n - i); // Set vector length based on remaining elements\n        vuint32m1_t indices = vid_v_u32m1(vl); // Generate indices [0, 1, 2, ...]\n        vuint32m1_t coeffs = vadd_vx_u32m1(indices, i, vl); // Add offset to indices\n        vfloat32m1_t xs_vec = vle32_v_f32m1(&xs[i], vl); // Load xs[i] into vector\n        vfloat32m1_t result_vec = vfmul_vv_f32m1(vfcvt_f_x_v_f32m1(coeffs, vl), xs_vec, vl); // Multiply coeffs * xs\n        vse32_v_f32m1(&result[i - 1], result_vec, vl); // Store result\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_91_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<float> derivative_simd(std::vector<float> xs) {\n    size_t n = xs.size();\n    if (n <= 1) {\n        return {}; // Derivative of a constant is zero\n    }\n\n    std::vector<float> result(n - 1);\n    size_t vlmax = vsetvlmax_e32m1(); // Maximum vector length for 32-bit floats\n    size_t i = 1;\n\n    while (i < n) {\n        size_t vl = vsetvl_e32m1(n - i); // Set vector length based on remaining elements\n        vuint32m1_t indices = vid_v_u32m1(vl); // Generate indices [0, 1, 2, ...]\n        vfloat32m1_t coeffs = vle32_v_f32m1(&xs[i], vl); // Load coefficients\n        vfloat32m1_t factors = vfcvt_f_x_v_f32m1(vadd_vx_u32m1(indices, i, vl), vl); // Convert indices to float and add offset\n        vfloat32m1_t product = vfmul_vv_f32m1(coeffs, factors, vl); // Multiply coefficients by their respective factors\n        vse32_v_f32m1(&result[i - 1], product, vl); // Store the result\n        i += vl; // Increment index by vector length\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_91_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<float> derivative_simd(std::vector<float> xs) {\n    size_t n = xs.size();\n    if (n <= 1) {\n        return {}; // Derivative of a constant or empty polynomial is empty.\n    }\n\n    std::vector<float> result(n - 1);\n    size_t vlmax = vsetvlmax_e32m1(); // Maximum vector length for 32-bit floats.\n    size_t i = 1;\n\n    while (i < n) {\n        size_t vl = vsetvl_e32m1(n - i); // Set vector length based on remaining elements.\n        vuint32m1_t indices = vid_v_u32m1(vl); // Generate indices [0, 1, 2, ...].\n        vfloat32m1_t coeffs = vle32_v_f32m1(&xs[i], vl); // Load coefficients.\n        vfloat32m1_t factors = vfcvt_f_x_v_f32m1(vadd_vx_u32m1(indices, i, vl), vl); // Convert indices to float and add offset.\n        vfloat32m1_t derivatives = vfmul_vv_f32m1(coeffs, factors, vl); // Multiply coefficients by their respective factors.\n        vse32_v_f32m1(&result[i - 1], derivatives, vl); // Store results.\n        i += vl; // Increment index by vector length.\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_91_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<float> derivative_simd(std::vector<float> xs) {\n    size_t n = xs.size();\n    if (n <= 1) {\n        return {}; // Derivative of a constant or empty polynomial is empty.\n    }\n\n    std::vector<float> result(n - 1);\n    size_t vlmax = vsetvlmax_e32m1(); // Maximum vector length for 32-bit floats.\n    size_t i = 1;\n\n    while (i < n) {\n        size_t vl = vsetvl_e32m1(n - i); // Set vector length based on remaining elements.\n        vuint32m1_t indices = vid_v_u32m1(vl); // Generate indices [0, 1, 2, ...].\n        vfloat32m1_t coeffs = vle32_v_f32m1(&xs[i], vl); // Load coefficients.\n        vfloat32m1_t multipliers = vfcvt_f_x_v_f32m1(vadd_vx_u32m1(indices, i, vl), vl); // Convert indices to float.\n        vfloat32m1_t derivatives = vfmul_vv_f32m1(coeffs, multipliers, vl); // Multiply coefficients by indices.\n        vse32_v_f32m1(&result[i - 1], derivatives, vl); // Store results.\n        i += vl; // Move to the next chunk.\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_92_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nint vowels_count_simd(std::string s) {\n    size_t n = s.size();\n    const char vowels[] = {'a', 'e', 'i', 'o', 'u', 'A', 'E', 'I', 'O', 'U'};\n    size_t vowels_count = sizeof(vowels) / sizeof(vowels[0]);\n\n    // Handle edge case for 'y' at the end of the string\n    bool is_y_vowel = (n > 0 && (s[n - 1] == 'y' || s[n - 1] == 'Y'));\n\n    // Convert the string to lowercase for uniform comparison\n    std::string lower_s = s;\n    for (size_t i = 0; i < n; i++) {\n        if (lower_s[i] >= 'A' && lower_s[i] <= 'Z') {\n            lower_s[i] = lower_s[i] + ('a' - 'A');\n        }\n    }\n\n    // Prepare vectorized processing\n    size_t vlmax = vsetvlmax_e8m1();\n    size_t count = 0;\n\n    for (size_t i = 0; i < n; i += vlmax) {\n        size_t vl = vsetvl_e8m1(n - i);\n        vint8m1_t vec_chars = vle8_v_i8m1((int8_t*)&lower_s[i], vl);\n\n        // Check for vowels\n        vint8m1_t vec_vowel_mask = vmv_v_x_i8m1(0, vl);\n        for (size_t j = 0; j < vowels_count; j++) {\n            vint8m1_t vec_vowel = vmv_v_x_i8m1(vowels[j], vl);\n            vec_vowel_mask = vor_vv_i8m1(vec_vowel_mask, vmseq_vv_i8m1(vec_chars, vec_vowel, vl), vl);\n        }\n\n        // Count matches\n        count += vpopc_m_b8(vmsne_vx_i8m1(vec_vowel_mask, 0, vl), vl);\n    }\n\n    // Add 'y' as a vowel if it is at the end of the string\n    if (is_y_vowel) {\n        count++;\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_92_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nint vowels_count_simd(std::string s) {\n    size_t n = s.size();\n    const char vowels[] = {'a', 'e', 'i', 'o', 'u', 'A', 'E', 'I', 'O', 'U'};\n    const char y_vowel[] = {'y', 'Y'};\n    \n    int count = 0;\n\n    // Process the main part of the string using RVV\n    size_t i = 0;\n    while (i < n) {\n        size_t vl = vsetvl_e8m1(n - i); // Determine vector length\n        vint8m1_t vec = vle8_v_i8m1((const int8_t*)(s.data() + i), vl); // Load characters into vector\n\n        // Check for vowels\n        vint8m1_t result = vmv_v_x_i8m1(0, vl); // Initialize result vector to zero\n        for (size_t j = 0; j < sizeof(vowels); j++) {\n            vint8m1_t vowel_vec = vmv_v_x_i8m1(vowels[j], vl); // Broadcast vowel\n            result = vor_vv_i8m1(result, vmseq_vv_i8m1(vec, vowel_vec, vl), vl); // Compare and accumulate\n        }\n\n        // Count matches\n        count += vpopc_m_b8(vmsne_vx_i8m1(result, 0, vl), vl); // Count non-zero elements in result\n\n        i += vl; // Move to the next chunk\n    }\n\n    // Check if the last character is 'y' or 'Y'\n    if (n > 0 && (s[n - 1] == y_vowel[0] || s[n - 1] == y_vowel[1])) {\n        count++;\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_92_RVV", "completion": "```c++\n#include <riscv_vector.h>\n#include <string>\n\nint vowels_count_simd(std::string s) {\n    size_t n = s.size();\n    if (n == 0) return 0;\n\n    // Convert the string to lowercase for uniform comparison\n    std::string lower_s(n, ' ');\n    for (size_t i = 0; i < n; i++) {\n        lower_s[i] = tolower(s[i]);\n    }\n\n    // Define the vowels\n    const char vowels[] = {'a', 'e', 'i', 'o', 'u'};\n    size_t vowel_count = 5;\n\n    size_t count = 0;\n    size_t i = 0;\n\n    // Process the string in chunks using RVV\n    while (i < n) {\n        size_t vl = vsetvl_e8m1(n - i); // Set vector length\n        vuint8m1_t vec = vle8_v_u8m1((const uint8_t*)&lower_s[i], vl); // Load characters into vector\n\n        // Check for vowels\n        vbool8_t is_vowel = vmv_v_x_b8(0, vl); // Initialize mask to false\n        for (size_t j = 0; j < vowel_count; j++) {\n            vbool8_t match = vmseq_vx_u8m1_b8(vec, vowels[j], vl); // Compare with each vowel\n            is_vowel = vmor_mm_b8(is_vowel, match, vl); // Combine masks\n        }\n\n        // Count the number of vowels in the current chunk\n        count += vcpop_m_b8(is_vowel, vl);\n\n        i += vl;\n    }\n\n    // Check if the last character is 'y' and add it to the count if it's a vowel\n    if (n > 0 && lower_s[n - 1] == 'y') {\n        count++;\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_92_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nint vowels_count_simd(std::string s) {\n    size_t n = s.size();\n    const char vowels[] = {'a', 'e', 'i', 'o', 'u', 'A', 'E', 'I', 'O', 'U'};\n    const char y_vowel[] = {'y', 'Y'};\n    int count = 0;\n\n    size_t vl;\n    for (size_t i = 0; i < n; i += vl) {\n        vl = vsetvl_e8m1(n - i); // Set vector length for remaining elements\n        vint8m1_t vec = vle8_v_i8m1((int8_t*)&s[i], vl); // Load characters into vector\n\n        vint8m1_t vowel_mask = vmv_v_x_i8m1(0, vl); // Initialize mask for vowels\n        for (size_t j = 0; j < sizeof(vowels); ++j) {\n            vowel_mask = vor_vv_i8m1(vowel_mask, vmseq_vx_i8m1(vec, vowels[j], vl), vl);\n        }\n\n        vint8m1_t count_vec = vmv_v_x_i8m1(0, vl); // Initialize count vector\n        count_vec = vadd_vv_i8m1(count_vec, vowel_mask, vl); // Add mask values to count\n\n        count += vpopc_m_b8(vmsne_vx_i8m1(count_vec, 0, vl)); // Count non-zero elements\n    }\n\n    // Check if the last character is 'y' or 'Y'\n    if (n > 0 && (s[n - 1] == y_vowel[0] || s[n - 1] == y_vowel[1])) {\n        count++;\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_92_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nint vowels_count_simd(std::string s) {\n    size_t n = s.size();\n    const char vowels[] = {'a', 'e', 'i', 'o', 'u', 'A', 'E', 'I', 'O', 'U'};\n    size_t vowels_count = sizeof(vowels) / sizeof(vowels[0]);\n\n    // Check if 'y' is a vowel at the end of the string\n    bool is_y_vowel = !s.empty() && (s.back() == 'y' || s.back() == 'Y');\n\n    // Initialize vector length\n    size_t vlmax = vsetvlmax_e8m1();\n    size_t count = 0;\n\n    for (size_t i = 0; i < n; i += vlmax) {\n        size_t vl = vsetvl_e8m1(n - i);\n\n        // Load characters into vector\n        vint8m1_t vec = vle8_v_i8m1((int8_t *)(s.data() + i), vl);\n\n        // Initialize mask for vowels\n        vbool8_t mask = vmv_v_x_b8(vfalse_b8(), vl);\n\n        // Check for each vowel\n        for (size_t j = 0; j < vowels_count; ++j) {\n            vbool8_t temp_mask = vmseq_vx_i8m1_b8(vec, vowels[j], vl);\n            mask = vor_b8(mask, temp_mask, vl);\n        }\n\n        // Count vowels in the current vector\n        count += vpopc_b8(mask, vl);\n    }\n\n    // Add 'y' as a vowel if applicable\n    if (is_y_vowel) {\n        count++;\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_93_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nint digitSum_simd(std::string s) {\n    size_t n = s.size();\n    if (n == 0) return 0;\n\n    const char* str = s.c_str();\n    size_t vlmax = vsetvlmax_e8m1(); // Maximum vector length for 8-bit elements\n    size_t sum = 0;\n\n    for (size_t i = 0; i < n; i += vlmax) {\n        size_t vl = vsetvl_e8m1(n - i); // Set vector length based on remaining elements\n        vint8m1_t vec = vle8_v_i8m1(&str[i], vl); // Load characters into vector\n        vbool8_t mask = vmseq_vx_i8m1_b8(vec, 'A', vl) | // Check for 'A'\n                        vmseq_vx_i8m1_b8(vec, 'Z', vl); // Check for 'Z'\n        vint8m1_t filtered = vmerge_vxm_i8m1(mask, vec, 0, vl); // Filter upper-case letters\n        sum += vredsum_vs_i8m1_i32m1(filtered, vundefined_i32m1(), vl); // Reduce sum\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_93_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <string>\n\nint digitSum_simd(std::string s) {\n    size_t n = s.size();\n    if (n == 0) return 0;\n\n    const char *input = s.c_str();\n    size_t vl;\n    int sum = 0;\n\n    for (size_t i = 0; i < n; i += vl) {\n        vl = vsetvl_e8m1(n - i); // Set vector length for 8-bit elements\n        vuint8m1_t vec = vle8_v_u8m1((const uint8_t *)(input + i), vl); // Load characters into vector\n\n        // Check if characters are uppercase (ASCII range 'A' (65) to 'Z' (90))\n        vbool8_t mask_upper = vmand_mm_b8(\n            vmgeu_vx_u8m1_b8(vec, 65, vl), // vec >= 'A'\n            vmleu_vx_u8m1_b8(vec, 90, vl) // vec <= 'Z'\n        );\n\n        // Masked sum of ASCII values of uppercase characters\n        vuint8m1_t masked_vec = vmerge_vxm_u8m1(mask_upper, vec, 0, vl); // Masked vector\n        sum += vredsum_vs_u8m1_u8m1(vundefined_u8m1(), masked_vec, vundefined_u8m1(), vl); // Reduce sum\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_93_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nint digitSum_simd(std::string s) {\n    size_t n = s.size();\n    if (n == 0) return 0;\n\n    const char *str = s.c_str();\n    size_t vlmax = vsetvlmax_e8m1(); // Maximum vector length for 8-bit elements\n    int sum = 0;\n\n    for (size_t i = 0; i < n; i += vlmax) {\n        size_t vl = vsetvl_e8m1(n - i); // Set vector length based on remaining elements\n        vint8m1_t vec = vle8_v_i8m1(str + i, vl); // Load characters into vector\n        vint8m1_t upper_mask = vmul_vx_i8m1(vmsgt_vx_i8m1(vec, 'A' - 1, vl), 1, vl); // Mask for 'A' <= x\n        vint8m1_t lower_mask = vmul_vx_i8m1(vmslt_vx_i8m1(vec, 'Z' + 1, vl), 1, vl); // Mask for x <= 'Z'\n        vint8m1_t combined_mask = vand_vv_i8m1(upper_mask, lower_mask, vl); // Combine masks for 'A' <= x <= 'Z'\n        vint8m1_t filtered_vec = vmul_vv_i8m1(vec, combined_mask, vl); // Filter upper-case characters\n        sum += vredsum_vs_i8m1_i32m1(vundefined_i32m1(), filtered_vec, vl); // Reduce sum of filtered ASCII values\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_93_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nint digitSum_simd(std::string s) {\n    size_t n = s.size();\n    if (n == 0) return 0;\n\n    const char* str = s.c_str();\n    int sum = 0;\n\n    size_t vlmax = vsetvlmax_e8m1(); // Maximum vector length for 8-bit elements\n    size_t i = 0;\n\n    while (i < n) {\n        size_t vl = vsetvl_e8m1(n - i); // Set vector length based on remaining elements\n        vint8m1_t vec = vle8_v_i8m1(&str[i], vl); // Load characters into vector\n\n        vint8m1_t upper_mask = vmul_vx_i8m1(vmsgt_vx_i8m1(vec, 'A' - 1, vl), vmult_vx_i8m1(vec, 'Z' + 1, vl),vl); // Mask for upper-case letters\n        vint8m1_t upper_ascii = vand_vv_i8m1(vec, upper_mask, vl); // Keep only upper-case ASCII values\n\n        sum += vredsum_vs_i8m1_i32m1(vundefined_i32m1(), upper_ascii, vl); // Reduce sum of upper-case ASCII values\n        i += vl;\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_93_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nint digitSum_simd(std::string s) {\n    size_t n = s.size();\n    if (n == 0) return 0;\n\n    const char *input = s.c_str();\n    int sum = 0;\n\n    size_t vl;\n    for (size_t i = 0; i < n; i += vl) {\n        vl = vsetvl_e8m1(n - i); // Set vector length based on remaining elements\n        vint8m1_t vec = vle8_v_i8m1(input + i, vl); // Load characters into vector\n\n        vint8m1_t upper_mask = vmul_vx_i8m1(vmsgt_vx_i8m1(vec, 'A' - 1, vl), 1, vl); // Mask for upper case (A-Z)\n        upper_mask = vmul_vx_i8m1(vmslt_vx_i8m1(vec, 'Z' + 1, vl), upper_mask, vl); // Refine mask for upper case\n\n        vint8m1_t upper_chars = vmul_vv_i8m1(vec, upper_mask, vl); // Extract upper case characters\n        vint32m4_t widened = vwadd_vx_i32m4(upper_chars, 0, vl); // Widen to 32-bit for summation\n\n        sum += vreduce_sum_i32m4(widened, vl); // Reduce sum of widened vector\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_94_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <limits>\n\nstd::vector<int> pluck_simd(std::vector<int> arr) {\n    size_t n = arr.size();\n    if (n == 0) {\n        return {};\n    }\n\n    const size_t vlmax = vsetvlmax_e32m1();\n    int min_value = std::numeric_limits<int>::max();\n    int min_index = -1;\n\n    for (size_t i = 0; i < n; i += vlmax) {\n        size_t vl = vsetvl_e32m1(n - i);\n\n        vint32m1_t vec = vle32_v_i32m1(&arr[i], vl);\n        vint32m1_t indices = vid_v_i32m1(vl);\n        indices = vadd_vx_i32m1(indices, i, vl);\n\n        vbool32_t even_mask = vmseq_vx_i32m1_b32(vand_vx_i32m1(vec, 1, vl), 0, vl);\n\n        vint32m1_t even_values = vmerge_vxm_i32m1(vmv_v_x_i32m1(std::numeric_limits<int>::max(), vl), vec, even_mask, vl);\n        vint32m1_t even_indices = vmerge_vxm_i32m1(vmv_v_x_i32m1(std::numeric_limits<int>::max(), vl), indices, even_mask, vl);\n\n        int local_min_value = vmv_x_s_i32m1_i32(vredmin_vs_i32m1_i32m1(even_values, even_values, vl));\n        vbool32_t min_mask = vmseq_vx_i32m1_b32(even_values, local_min_value, vl);\n        vint32m1_t min_indices = vmerge_vxm_i32m1(vmv_v_x_i32m1(std::numeric_limits<int>::max(), vl), even_indices, min_mask, vl);\n        int local_min_index = vmv_x_s_i32m1_i32(vredmin_vs_i32m1_i32m1(min_indices, min_indices, vl));\n\n        if (local_min_value < min_value || (local_min_value == min_value && local_min_index < min_index)) {\n            min_value = local_min_value;\n            min_index = local_min_index;\n        }\n    }\n\n    if (min_index == -1) {\n        return {};\n    }\n\n    return {min_value, min_index};\n}\n```"}
{"task_id": "SimdBench_94_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <limits>\n\nstd::vector<int> pluck_simd(std::vector<int> arr) {\n    size_t n = arr.size();\n    if (n == 0) {\n        return {};\n    }\n\n    const size_t vlmax = vsetvlmax_e32m1(); // Maximum vector length for 32-bit integers\n    int smallest_value = std::numeric_limits<int>::max();\n    int smallest_index = -1;\n\n    for (size_t i = 0; i < n; i += vlmax) {\n        size_t vl = vsetvl_e32m1(n - i); // Set vector length for the remaining elements\n        vint32m1_t vec = vle32_v_i32m1(&arr[i], vl); // Load a chunk of the array\n        vint32m1_t even_mask = vmseq_vx_i32m1_b32(vand_vx_i32m1(vec, 1, vl), 0, vl); // Mask for even numbers\n        vint32m1_t even_values = vmerge_vxm_i32m1(vec, std::numeric_limits<int>::max(), even_mask, vl); // Replace odd numbers with max int\n\n        int local_min = vmin_vx_i32m1(vredmin_vs_i32m1_i32m1(even_values, even_values, vl), std::numeric_limits<int>::max(), vl); // Find local minimum\n        if (local_min < smallest_value) {\n            smallest_value = local_min;\n            for (size_t j = 0; j < vl; j++) {\n                if (arr[i + j] == smallest_value && (arr[i + j] % 2 == 0)) {\n                    smallest_index = i + j;\n                    break;\n                }\n            }\n        }\n    }\n\n    if (smallest_index == -1) {\n        return {};\n    }\n\n    return {smallest_value, smallest_index};\n}\n```"}
{"task_id": "SimdBench_94_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <limits>\n\nstd::vector<int> pluck_simd(std::vector<int> arr) {\n    size_t n = arr.size();\n    if (n == 0) {\n        return {};\n    }\n\n    const int32_t MAX_INT = std::numeric_limits<int32_t>::max();\n    int32_t min_even_value = MAX_INT;\n    int32_t min_index = -1;\n\n    size_t vlmax = vsetvlmax_e32m1();\n    size_t i = 0;\n\n    while (i < n) {\n        size_t vl = vsetvl_e32m1(n - i);\n        vint32m1_t vec = vle32_v_i32m1(&arr[i], vl);\n\n        vint32m1_t even_mask = vmseq_vx_i32m1(vec & 1, 0, vl); // Mask for even numbers\n        vint32m1_t even_values = vmerge_vvm_i32m1(even_mask, vec, MAX_INT, vl); // Replace odd numbers with MAX_INT\n\n        int32_t local_min = vmin_vv_i32m1(even_values, even_values, vl).v[0]; // Find minimum even value in the vector\n        vint32m1_t local_min_index = vfindmin_vv_i32m1() \n    }\n}\n```"}
{"task_id": "SimdBench_94_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <limits>\n\nstd::vector<int> pluck_simd(std::vector<int> arr) {\n    size_t n = arr.size();\n    if (n == 0) {\n        return {};\n    }\n\n    const size_t vlmax = vsetvlmax_e32m1();\n    int min_value = std::numeric_limits<int>::max();\n    int min_index = -1;\n\n    for (size_t i = 0; i < n; i += vlmax) {\n        size_t vl = vsetvl_e32m1(n - i);\n\n        vint32m1_t vec = vle32_v_i32m1(&arr[i], vl);\n        vint32m1_t indices = vid_v_i32m1(vl);\n        indices = vadd_vx_i32m1(indices, i, vl);\n\n        vbool32_t even_mask = vmseq_vx_i32m1_b32(vand_vx_i32m1(vec, 1, vl), 0, vl);\n\n        vint32m1_t even_values = vmerge_vxm_i32m1(vundefined_i32m1(), vec, even_mask, vl);\n        vint32m1_t even_indices = vmerge_vxm_i32m1(vundefined_i32m1(), indices, even_mask, vl);\n\n        int local_min_value = std::numeric_limits<int>::max();\n        int local_min_index = -1;\n\n        for (size_t j = 0; j < vl; ++j) {\n            int value = vget_i32m1(even_values, j);\n            int index = vget_i32m1(even_indices, j);\n\n            if (value < local_min_value) {\n                local_min_value = value;\n                local_min_index = index;\n            }\n        }\n\n        if (local_min_value < min_value || (local_min_value == min_value && local_min_index < min_index)) {\n            min_value = local_min_value;\n            min_index = local_min_index;\n        }\n    }\n\n    if (min_index == -1) {\n        return {};\n    }\n\n    return {min_value, min_index};\n}\n```"}
{"task_id": "SimdBench_94_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <limits>\n\nstd::vector<int> pluck_simd(std::vector<int> arr) {\n    size_t n = arr.size();\n    if (n == 0) {\n        return {};\n    }\n\n    const size_t vlmax = vsetvlmax_e32m1();\n    vuint32m1_t min_values = vmv_v_x_u32m1(std::numeric_limits<uint32_t>::max(), vlmax);\n    vuint32m1_t min_indices = vmv_v_x_u32m1(std::numeric_limits<uint32_t>::max(), vlmax);\n\n    for (size_t i = 0; i < n; i += vlmax) {\n        size_t vl = vsetvl_e32m1(n - i);\n\n        vuint32m1_t data = vle32_v_u32m1(&arr[i], vl);\n        vuint32m1_t indices = vid_v_u32m1(vl);\n        indices = vadd_vx_u32m1(indices, i, vl);\n\n        vbool32_t even_mask = vmseq_vx_u32m1_b32(vand_vx_u32m1(data, 1, vl), 0, vl);\n\n        vuint32m1_t filtered_values = vmerge_vxm_u32m1(data, std::numeric_limits<uint32_t>::max(), even_mask, vl);\n        vuint32m1_t filtered_indices = vmerge_vxm_u32m1(indices, std::numeric_limits<uint32_t>::max(), even_mask, vl);\n\n        vbool32_t less_mask = vmsltu_vv_u32m1_b32(filtered_values, min_values, vl);\n        min_values = vmerge_vvm_u32m1(filtered_values, min_values, less_mask, vl);\n        min_indices = vmerge_vvm_u32m1(filtered_indices, min_indices, less_mask, vl);\n\n        vbool32_t equal_mask = vmseq_vv_u32m1_b32(filtered_values, min_values, vl);\n        vbool32_t index_mask = vmsltu_vv_u32m1_b32(filtered_indices, min_indices, vl);\n        vbool32_t final_mask = vmand_mm_b32(equal_mask, index_mask, vl);\n        min_indices = vmerge_vvm_u32m1(filtered_indices, min_indices, final_mask, vl);\n    }\n\n    uint32_t result_value = std::numeric_limits<uint32_t>::max();\n    uint32_t result_index = std::numeric_limits<uint32_t>::max();\n    uint32_t temp_values[vlmax];\n    uint32_t temp_indices[vlmax];\n\n    vse32_v_u32m1(temp_values, min_values, vlmax);\n    vse32_v_u32m1(temp_indices, min_indices, vlmax);\n\n    for (size_t i = 0; i < vlmax; ++i) {\n        if (temp_values[i] < result_value || (temp_values[i] == result_value && temp_indices[i] < result_index)) {\n            result_value = temp_values[i];\n            result_index = temp_indices[i];\n        }\n    }\n\n    if (result_value == std::numeric_limits<uint32_t>::max()) {\n        return {};\n    }\n\n    return {static_cast<int>(result_value), static_cast<int>(result_index)};\n}\n```"}
{"task_id": "SimdBench_95_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <unordered_map>\n#include <algorithm>\n\nint search_simd(std::vector<int> lst) {\n    if (lst.empty()) return -1;\n\n    // Step 1: Count frequencies using RVV\n    std::unordered_map<int, int> freq_map;\n    size_t n = lst.size();\n    size_t vlmax = vsetvlmax_e32m1(); // Maximum vector length for 32-bit integers\n\n    for (size_t i = 0; i < n; i += vlmax) {\n        size_t vl = vsetvl_e32m1(n - i); // Set vector length based on remaining elements\n        vint32m1_t vec = vle32_v_i32m1(&lst[i], vl); // Load vector elements\n        vint32m1_t ones = vmv_v_x_i32m1(1, vl); // Vector of ones\n\n        for (size_t j = 0; j < vl; ++j) {\n            int value = lst[i + j];\n            freq_map[value] += 1;\n        }\n    }\n\n    // Step 2: Find the greatest integer satisfying the condition\n    int result = -1;\n    for (const auto& [key, freq] : freq_map) {\n        if (freq >= key && key > result) {\n            result = key;\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_95_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <unordered_map>\n#include <algorithm>\n\nint search_simd(std::vector<int> lst) {\n    if (lst.empty()) return -1;\n\n    std::unordered_map<int, int> freq_map;\n    size_t n = lst.size();\n\n    // Process the input vector in chunks using RVV intrinsics\n    size_t vlmax = vsetvlmax_e32m1(); // Maximum vector length for 32-bit integers\n    for (size_t i = 0; i < n; i += vlmax) {\n        size_t vl = vsetvl_e32m1(n - i); // Set vector length based on remaining elements\n        vint32m1_t vec = vle32_v_i32m1(&lst[i], vl); // Load vector elements\n        vint32m1_t ones = vmv_v_x_i32m1(1, vl); // Vector of ones\n\n        vint32m1_t counts = vslide1up_vx_i32m1(vec, 0, vl); // Slide up for counting\n        vint32m1_t+="}
{"task_id": "SimdBench_95_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <unordered_map>\n#include <algorithm>\n\nint search_simd(std::vector<int> lst) {\n    if (lst.empty()) return -1;\n\n    // Step 1: Count frequencies using RVV intrinsics\n    std::unordered_map<int, int> freq_map;\n    size_t n = lst.size();\n    size_t vlmax = vsetvlmax_e32m1(); // Maximum vector length for 32-bit integers\n\n    for (size_t i = 0; i < n; i += vlmax) {\n        size_t vl = vsetvl_e32m1(n - i); // Set vector length based on remaining elements\n        vint32m1_t vec = vle32_v_i32m1(&lst[i], vl); // Load vector elements\n        for (size_t j = 0; j < vl; ++j) {\n            freq_map[vget_i32m1(vec, j)]++;\n        }\n    }\n\n    // Step 2: Find the greatest integer satisfying the condition\n    int result = -1;\n    for (const auto& [key, freq] : freq_map) {\n        if (freq >= key && key > result) {\n            result = key;\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_95_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <unordered_map>\n#include <algorithm>\n\nint search_simd(std::vector<int> lst) {\n    if (lst.empty()) return -1;\n\n    size_t n = lst.size();\n    std::unordered_map<int, int> freq_map;\n\n    // Step 1: Count frequencies using RVV\n    size_t vlmax = vsetvlmax_e32m1();\n    for (size_t i = 0; i < n; i += vlmax) {\n        size_t vl = vsetvl_e32m1(n - i);\n        vint32m1_t vec = vle32_v_i32m1(&lst[i], vl);\n\n        for (size_t j = 0; j < vl; ++j) {\n            int value = vmv_x_s_i32m1(vec, j);\n            freq_map[value]++;\n        }\n    }\n\n    // Step 2: Find the greatest integer meeting the condition\n    int result = -1;\n    for (const auto& [key, freq] : freq_map) {\n        if (freq >= key && key > result) {\n            result = key;\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_95_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <unordered_map>\n#include <algorithm>\n\nint search_simd(std::vector<int> lst) {\n    if (lst.empty()) return -1;\n\n    // Step 1: Count frequencies using RVV\n    std::unordered_map<int, int> freq_map;\n    size_t n = lst.size();\n    size_t vlmax = vsetvlmax_e32m1(); // Maximum vector length for 32-bit integers\n\n    for (size_t i = 0; i < n; i += vlmax) {\n        size_t vl = vsetvl_e32m1(n - i); // Set vector length based on remaining elements\n        vint32m1_t vec = vle32_v_i32m1(&lst[i], vl); // Load vector elements\n        for (size_t j = 0; j < vl; ++j) {\n            int value = vec[j];\n            freq_map[value]++;\n        }\n    }\n\n    // Step 2: Find the greatest integer satisfying the condition\n    int result = -1;\n    for (const auto& [key, freq] : freq_map) {\n        if (freq >= key && key > result) {\n            result = key;\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_96_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <cstdint>\n\nbool will_it_fly_simd(std::vector<int> q, int w) {\n    size_t n = q.size();\n    if (n == 0) return false;\n\n    // Check if the vector is palindromic\n    size_t vl;\n    for (size_t i = 0; i < n / 2; i += vl) {\n        vl = vsetvl_e32m1(n / 2 - i);\n        vint32m1_t front = vle32_v_i32m1(&q[i], vl);\n        vint32m1_t back = vle32_v_i32m1(&q[n - i - vl], vl);\n        back = vrev8_v_i32m1(back, vl); // Reverse the back vector\n        vbool32_t mask = vmseq_vv_i32m1_b32(front, back, vl);\n        if (!vcpop_b32(mask)) return false; // If any mismatch, not palindromic\n    }\n\n    // Calculate the sum of the vector\n    int32_t sum = 0;\n    for (size_t i = 0; i < n; i += vl) {\n        vl = vsetvl_e32m1(n - i);\n        vint32m1_t vec = vle32_v_i32m1(&q[i], vl);\n        sum += vredsum_vs_i32m1_i32m1(vundefined_i32m1(), vec, vundefined_i32m1(), vl);\n    }\n\n    // Check if the sum is less than or equal to the maximum weight\n    return sum <= w;\n}\n```"}
{"task_id": "SimdBench_96_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <cstddef>\n\nbool will_it_fly_simd(std::vector<int> q, int w) {\n    size_t n = q.size();\n    if (n == 0) return false;\n\n    // Check if the vector is palindromic (balanced)\n    size_t vl;\n    for (size_t i = 0; i < n / 2; i += vl) {\n        vl = vsetvl_e32m1(n / 2 - i);\n        vint32m1_t vec_front = vle32_v_i32m1(&q[i], vl);\n        vint32m1_t vec_back = vle32_v_i32m1(&q[n - i - vl], vl);\n        vec_back = vrsub_vx_i32m1(vec_back, 0, vl); // Reverse the back part\n        if (vmsne_vv_i32m1_b32(vec_front, vec_back, vl)) {\n            return false;\n        }\n    }\n\n    // Calculate the sum of the elements\n    int sum = 0;\n    for (size_t i = 0; i < n; i += vl) {\n        vl = vsetvl_e32m1(n - i);\n        vint32m1_t vec = vle32_v_i32m1(&q[i], vl);\n        sum += vredsum_vs_i32m1_i32m1(vundefined_i32m1(), vec, vundefined_i32m1(), vl);\n    }\n\n    // Check if the sum is less than or equal to the maximum weight\n    return sum <= w;\n}\n```"}
{"task_id": "SimdBench_96_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nbool will_it_fly_simd(std::vector<int> q, int w) {\n    size_t n = q.size();\n    if (n == 0) return false;\n\n    // Check if the vector is palindromic (balanced)\n    size_t vlmax = vsetvlmax_e32m1();\n    for (size_t i = 0; i < n / 2; i += vlmax) {\n        size_t vl = vsetvl_e32m1(std::min(n / 2 - i, vlmax));\n        vint32m1_t vec_left = vle32_v_i32m1(&q[i], vl);\n        vint32m1_t vec_right = vle32_v_i32m1(&q[n - i - vl], vl);\n        vbool32_t mask = vmseq_vv_i32m1_b32(vec_left, vec_right, vl);\n        if (vcpop_b32(mask) != vl) {\n            return false;\n        }\n    }\n\n    // Calculate the sum of the elements\n    vint32m1_t vec_sum = vmv_v_x_i32m1(0, vlmax);\n    for (size_t i = 0; i < n; i += vlmax) {\n        size_t vl = vsetvl_e32m1(std::min(n - i, vlmax));\n        vint32m1_t vec = vle32_v_i32m1(&q[i], vl);\n        vec_sum = vadd_vv_i32m1(vec_sum, vec, vl);\n    }\n    int sum = vmv_x_s_i32m1_i32(vec_sum);\n\n    // Check if the sum is less than or equal to the maximum weight\n    return sum <= w;\n}\n```"}
{"task_id": "SimdBench_96_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <cstdint>\n\nbool will_it_fly_simd(std::vector<int> q, int w) {\n    size_t n = q.size();\n    if (n == 0) return false;\n\n    // Check if the vector is palindromic\n    size_t vlmax = vsetvlmax_e32m1();\n    for (size_t i = 0; i < n / 2; i += vlmax) {\n        size_t vl = vsetvl_e32m1(n / 2 - i);\n        vint32m1_t vec_left = vle32_v_i32m1(&q[i], vl);\n        vint32m1_t vec_right = vle32_v_i32m1(&q[n - i - vl], vl);\n        vbool32_t mask = vmseq_vv_i32m1_b32(vec_left, vec_right, vl);\n        if (!vcpop_b32(mask)) return false;\n    }\n\n    // Calculate the sum of the elements\n    vint32m1_t sum_vec = vmv_v_x_i32m1(0, vlmax);\n    for (size_t i = 0; i < n; i += vlmax) {\n        size_t vl = vsetvl_e32m1(n - i);\n        vint32m1_t vec = vle32_v_i32m1(&q[i], vl);\n        sum_vec = vadd_vv_i32m1(sum_vec, vec, vl);\n    }\n    int sum = 0;\n    vint32m1_t sum_scalar = vmv_v_x_i32m1(sum, vlmax);\n    sum_scalar = vadd_vv_i32m1(sum_scalar, sum_vec, vlmax);\n    if (sum_scalar > w)return false;\n}\n```"}
{"task_id": "SimdBench_96_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <cstdint>\n\nbool will_it_fly_simd(std::vector<int> q, int w) {\n    size_t n = q.size();\n    if (n == 0) return false;\n\n    // Check if the vector is palindromic (balanced)\n    size_t vl;\n    for (size_t i = 0; i < n / 2; i += vl) {\n        vl = vsetvl_e32m1(n / 2 - i);\n        vint32m1_t vec_left = vle32_v_i32m1(&q[i], vl);\n        vint32m1_t vec_right = vle32_v_i32m1(&q[n - vl - i], vl);\n        vbool32_t mask = vmseq_vv_i32m1_b32(vec_left, vec_right, vl);\n        if (!vcpop_b32(mask)) {\n            return false;\n        }\n    }\n\n    // Calculate the sum of the vector\n    int sum = 0;\n    for (size_t i = 0; i < n; i += vl) {\n        vl = vsetvl_e32m1(n - i);\n        vint32m1_t vec = vle32_v_i32m1(&q[i], vl);\n        sum += vredsum_vs_i32m1_i32m1(vundefined_i32m1(), vec, vundefined_i32m1(), vl);\n    }\n\n    // Check if the sum is less than or equal to the maximum weight\n    return sum <= w;\n}\n```"}
{"task_id": "SimdBench_97_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <algorithm>\n\nint smallest_change_simd(std::vector<int> arr) {\n    size_t n = arr.size();\n    size_t half_n = n / 2;\n    int changes = 0;\n\n    for (size_t i = 0; i < half_n; i += vsetvl_e32m1(half_n - i)) {\n        size_t vl = vsetvl_e32m1(half_n - i);\n\n        vint32m1_t vec_left = vle32_v_i32m1(&arr[i], vl);\n        vint32m1_t vec_right = vle32_v_i32m1(&arr[n - i - vl], vl);\n\n        vbool32_t mask = vmseq_vv_i32m1_b32(vec_left, vec_right, vl);\n        changes += vl - vcpop_b32(mask);\n    }\n\n    return changes;\n}\n```"}
{"task_id": "SimdBench_97_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <algorithm>\n\nint smallest_change_simd(std::vector<int> arr) {\n    size_t n = arr.size();\n    size_t half_n = n / 2;\n    int changes = 0;\n\n    for (size_t i = 0; i < half_n; i += vsetvl_e32m1(half_n - i)) {\n        size_t vl = vsetvl_e32m1(half_n - i);\n        vint32m1_t vec_left = vle32_v_i32m1(&arr[i], vl);\n        vint32m1_t vec_right = vle32_v_i32m1(&arr[n - 1 - i - (vl - 1)], vl);\n\n        vbool32_t mask = vmseq_vv_i32m1_b32(vec_left, vec_right, vl);\n        changes += vl - vcpop_b32(mask);\n    }\n\n    return changes;\n}\n```"}
{"task_id": "SimdBench_97_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <algorithm>\n\nint smallest_change_simd(std::vector<int> arr) {\n    size_t n = arr.size();\n    size_t half = n / 2;\n    int changes = 0;\n\n    for (size_t i = 0; i < half; i += vsetvl_e32m1(half - i)) {\n        size_t vl = vsetvl_e32m1(half - i);\n\n        vint32m1_t vec_left = vle32_v_i32m1(&arr[i], vl);\n        vint32m1_t vec_right = vle32_v_i32m1(&arr[n - i - vl], vl);\n\n        vbool32_t mask = vmseq_vv_i32m1_b32(vec_left, vec_right, vl);\n        changes += vl - vcpop_b32(mask);\n    }\n\n    return changes;\n}\n```"}
{"task_id": "SimdBench_97_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <algorithm>\n\nint smallest_change_simd(std::vector<int> arr) {\n    size_t n = arr.size();\n    size_t half_n = n / 2;\n    int changes = 0;\n\n    for (size_t i = 0; i < half_n; i += vsetvlmax_e32m1()) {\n        size_t vl = vsetvl_e32m1(half_n - i); // Set vector length\n        vint32m1_t vec_left = vle32_v_i32m1(&arr[i], vl);\n        vint32m1_t vec_right = vle32_v_i32m1(&arr[n - i - vl], vl);\n\n        vbool32_t mask = vmseq_vv_i32m1_b32(vec_left, vec_right, vl); // Compare elements\n        changes += vl - vcpop_b32(mask); // Count mismatches\n    }\n\n    return changes;\n}\n```"}
{"task_id": "SimdBench_97_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <algorithm>\n\nint smallest_change_simd(std::vector<int> arr) {\n    size_t n = arr.size();\n    size_t half_n = n / 2;\n    int changes = 0;\n\n    for (size_t i = 0; i < half_n; ) {\n        size_t vl = vsetvl_e32m1(half_n - i); // Set vector length\n        vint32m1_t vec_left = vle32_v_i32m1(&arr[i], vl); // Load left half\n        vint32m1_t vec_right = vle32_v_i32m1(&arr[n - i - vl], vl); // Load right half\n        vbool32_t mask = vmne_vv_i32m1_b32(vec_left, vec_right, vl); // Compare left and right\n        changes += vcpop_b32(mask); // Count mismatches\n        i += vl; // Increment by vector length\n    }\n\n    return changes;\n}\n```"}
{"task_id": "SimdBench_98_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <string>\n\nstd::vector<std::string> total_match_simd(const std::vector<std::string> & lst1, const std::vector<std::string> & lst2) {\n    auto calculate_total_chars = [](const std::vector<std::string>& lst) -> size_t {\n        size_t total_chars = 0;\n        size_t n = lst.size();\n        size_t i = 0;\n\n        while (i < n) {\n            size_t vl = vsetvl_e32m1(n - i); // Set vector length\n            vuint32m1_t char_counts = vmv_v_x_u32m1(0, vl); // Initialize vector to 0\n\n            for (size_t j = 0; j < vl; ++j) {\n                if (i + j < n) {\n                    char_counts = vadd_vx_u32m1(char_counts, lst[i + j].size(), vl);\n                }\n            }\n\n            total_chars += vcpop_m_b32(vmsne_vx_u32m1_b32(char_counts, 0, vl)); // Sum up the vector\n            i += vl;\n        }\n\n        return total_chars;\n    };\n\n    size_t total_chars_lst1 = calculate_total_chars(lst1);\n    size_t total_chars_lst2 = calculate_total_chars(lst2);\n\n    if (total_chars_lst1 < total_chars_lst2) {\n        return lst1;\n    } else if (total_chars_lst1 > total_chars_lst2) {\n        return lst2;\n    } else {\n        return lst1;\n    }\n}\n```"}
{"task_id": "SimdBench_98_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <string>\n\nstd::vector<std::string> total_match_simd(const std::vector<std::string> & lst1, const std::vector<std::string> & lst2) {\n    auto calculate_total_chars = [](const std::vector<std::string>& lst) -> size_t {\n        size_t total_chars = 0;\n        size_t n = lst.size();\n        size_t i = 0;\n\n        while (i < n) {\n            size_t vl = vsetvl_e32m1(n - i); // Set vector length\n            vuint32m1_t char_counts = vmv_v_x_u32m1(0, vl); // Initialize vector to 0\n\n            for (size_t j = 0; j < vl; ++j) {\n                if (i + j < n) {\n                    char_counts = vadd_vx_u32m1(char_counts, lst[i + j].size(), vl);\n                }\n            }\n\n            total_chars += vcpop_m_b32(vmsne_vx_u32m1_b32(char_counts, 0, vl)); // Sum up the vector\n            i += vl;\n        }\n\n        return total_chars;\n    };\n\n    size_t total_chars_lst1 = calculate_total_chars(lst1);\n    size_t total_chars_lst2 = calculate_total_chars(lst2);\n\n    if (total_chars_lst1 < total_chars_lst2) {\n        return lst1;\n    } else if (total_chars_lst2 < total_chars_lst1) {\n        return lst2;\n    } else {\n        return lst1;\n    }\n}\n```"}
{"task_id": "SimdBench_98_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <string>\n\nstd::vector<std::string> total_match_simd(const std::vector<std::string> & lst1, const std::vector<std::string> & lst2) {\n    auto calculate_total_chars = [](const std::vector<std::string>& lst) -> size_t {\n        size_t total_chars = 0;\n        size_t n = lst.size();\n        size_t vl = vsetvl_e32m1(n); // Set vector length based on the number of elements\n        vint32m1_t char_counts = vmv_v_x_i32m1(0, vl); // Initialize vector to zeros\n\n        for (size_t i = 0; i < n; i += vl) {\n            vl = vsetvl_e32m1(n - i); // Adjust vector length for remaining elements\n            vint32m1_t lengths = vmv_v_x_i32m1(0, vl); // Initialize lengths vector\n            for (size_t j = 0; j < vl; ++j) {\n                lengths = vslideup_vx_i32m1(lengths, lst[i + j].size(), j, vl); // Load string lengths into vector\n            }\n            char_counts = vadd_vv_i32m1(char_counts, lengths, vl); // Accumulate lengths\n        }\n\n        vint32m1_t sum_vector = vmv_v_x_i32m1(0, vl); // Initialize sum vector\n        for (size_t i = 0; i < vl; ++i) {\n            total_chars += vextract_i32m1(char_counts, i); // Extract and sum up values\n        }\n        return total_chars;\n    };\n\n    size_t total_chars_lst1 = calculate_total_chars(lst1);\n    size_t total_chars_lst2 = calculate_total_chars(lst2);\n\n    if (total_chars_lst1 <= total_chars_lst2) {\n        return lst1;\n    } else {\n        return lst2;\n    }\n}\n```"}
{"task_id": "SimdBench_98_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <string>\n\nstd::vector<std::string> total_match_simd(const std::vector<std::string> & lst1, const std::vector<std::string> & lst2) {\n    auto calculate_total_chars = [](const std::vector<std::string>& lst) -> size_t {\n        size_t total_chars = 0;\n        size_t n = lst.size();\n        size_t vl = vsetvl_e32m1(n); // Set vector length based on the number of elements\n        vint32m1_t char_counts = vmv_v_x_i32m1(0, vl); // Initialize vector to zero\n\n        for (size_t i = 0; i < n; i += vl) {\n            vl = vsetvl_e32m1(n - i); // Adjust vector length for remaining elements\n            vint32m1_t temp_counts = vmv_v_x_i32m1(0, vl);\n\n            for (size_t j = 0; j < vl; ++j) {\n                temp_counts = vslideup_vx_i32m1(temp_counts, lst[i + j].size(), j, vl);\n            }\n\n            char_counts = vadd_vv_i32m1(char_counts, temp_counts, vl);\n        }\n\n        vint32m1_t sum_vector = vmv_v_x_i32m1(0, vl);\n        for (size_t i = 0; i < vl; ++i) {\n            sum_vector = vadd_vx_i32m1(sum_vector, vextract_i32m1(char_counts, i), vl);\n        }\n\n        total_chars = vextract_i32m1(sum_vector, 0);\n        return total_chars;\n    };\n\n    size_t total_chars_lst1 = calculate_total_chars(lst1);\n    size_t total_chars_lst2 = calculate_total_chars(lst2);\n\n    if (total_chars_lst1 <= total_chars_lst2) {\n        return lst1;\n    } else {\n        return lst2;\n    }\n}\n```"}
{"task_id": "SimdBench_98_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <string>\n\nstd::vector<std::string> total_match_simd(const std::vector<std::string> & lst1, const std::vector<std::string> & lst2) {\n    size_t len1 = lst1.size();\n    size_t len2 = lst2.size();\n\n    // Calculate total characters in lst1\n    size_t total_chars1 = 0;\n    for (size_t i = 0; i < len1; i++) {\n        total_chars1 += lst1[i].size();\n    }\n\n    // Calculate total characters in lst2\n    size_t total_chars2 = 0;\n    for (size_t i = 0; i < len2; i++) {\n        total_chars2 += lst2[i].size();\n    }\n\n    // Compare and return the appropriate vector\n    if (total_chars1 < total_chars2) {\n        return lst1;\n    } else if (total_chars2 < total_chars1) {\n        return lst2;\n    } else {\n        return lst1;\n    }\n}\n```"}
{"task_id": "SimdBench_99_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <stdbool.h>\n\nbool is_simple_power_simd(uint64_t x, uint64_t n) {\n    if (x == 1) {\n        return true; // n**0 = 1 for any n > 0\n    }\n    if (n <= 1) {\n        return false; // n <= 1 cannot form valid powers\n    }\n\n    size_t vlmax = vsetvlmax_e64m1();\n    uint64_t powers[vlmax];\n    for (size_t i = 0; i < vlmax; i++) {\n        powers[i] = 1; // Initialize powers array with 1 (n**0)\n    }\n\n    vuint64m1_t v_powers = vle64_v_u64m1(powers, vlmax);\n    vuint64m1_t v_n = vmv_v_x_u64m1(n, vlmax);\n\n    while (true) {\n        v_powers = vmul_vv_u64m1(v_powers, v_n, vlmax); // Compute next power: n**(i+1)\n\n        vbool64_t match = vmseq_vx_u64m1_b64(v_powers, x, vlmax); // Check if n**i == x\n        if (vfirst_m_b64(match) >= 0) {\n            return true; // Found a match\n        }\n\n        vbool64_t overflow = vmslt_vx_u64m1_b64(v_powers, x, vlmax); // Check for overflow\n        if (vfirst_m_b64(overflow) < 0) {\n            return false; // No match and overflow occurred\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_99_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <stdbool.h>\n#include <stdint.h>\n\nbool is_simple_power_simd(uint64_t x, uint64_t n) {\n    if (x == 1) return true; // n^0 = 1 for any n\n    if (n <= 1) return false; // n <= 1 cannot form valid powers\n\n    size_t vl;\n    uint64_t base = n;\n    uint64_t max_iters = 64; // Limit iterations to prevent infinite loops\n    uint64_t powers[max_iters];\n    size_t i = 0;\n\n    // Generate powers of n until exceeding x or reaching max_iters\n    while (base <= x && i < max_iters) {\n        powers[i++] = base;\n        if (base > UINT64_MAX / n) break; // Prevent overflow\n        base *= n;\n    }\n\n    // Load powers into vector registers\n    vl = vsetvl_e64(i);\n    vuint64m1_t vec_powers = vle64_v_u64m1(powers, vl);\n    vuint64m1_t vec_x = vmv_v_x_u64m1(x, vl);\n\n    // Compare x with each power of n\n    vbool64_t match = vmseq_vv_u64m1_b64(vec_x, vec_powers, vl);\n\n    // Check if any match is found\n    return vfirst_m_b64(match, vl) >= 0;\n}\n```"}
{"task_id": "SimdBench_99_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <stdbool.h>\n#include <stdint.h>\n\nbool is_simple_power_simd(uint64_t x, uint64_t n) {\n    if (x == 1) return true; // n^0 = 1 for any n\n    if (n <= 1) return false; // n <= 1 cannot produce valid powers for x > 1\n\n    size_t vl;\n    uint64_t base = n;\n    uint64_t max_iters = 64; // Limit iterations to prevent infinite loops\n    uint64_t powers[max_iters];\n    size_t count = 0;\n\n    // Generate powers of n up to x or until overflow\n    while (base <= x && count < max_iters) {\n        powers[count++] = base;\n        if (base > UINT64_MAX / n) break; // Prevent overflow\n        base *= n;\n    }\n\n    // Load powers into vector registers\n    vl = vsetvl_e64(count);\n    vuint64m1_t vec_powers = vle64_v_u64m1(powers, vl);\n\n    // Broadcast x into a vector\n    vuint64m1_t vec_x = vmv_v_x_u64m1(x, vl);\n\n    // Compare x with the powers of n\n    vbool64_t match = vmseq_vv_u64m1_b64(vec_x, vec_powers, vl);\n\n    // Check if any match is found\n    return vfirst_m_b64(match, vl) != -1;\n}\n```"}
{"task_id": "SimdBench_99_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <stdbool.h>\n\nbool is_simple_power_simd(uint64_t x, uint64_t n) {\n    if (x == 1) return true; // Special case: n^0 = 1 for any n > 0\n    if (n <= 1) return false; // Invalid base cases: n <= 1 cannot form valid powers\n\n    size_t vlmax = vsetvlmax_e64m1(); // Maximum vector length for 64-bit integers\n    uint64_t powers[vlmax];\n    uint64_t current_power = 1;\n\n    for (size_t i = 0; i < vlmax; i++) {\n        current_power *= n;\n        if (current_power > x) break; // Stop if the power exceeds x\n        powers[i] = current_power;\n    }\n\n    size_t vl = vsetvl_e64m1(vlmax); // Set vector length\n    vint64m1_t v_powers = vle64_v_i64m1(powers, vl); // Load powers into vector\n    vint64m1_t v_x = vmv_v_x_i64m1(x, vl); // Broadcast x into vector\n\n    vbool64_t mask = vmseq_vv_i64m1_b64(v_powers, v_x, vl); // Compare powers with x\n    return vfirst_m_b64(mask) >= 0; // Return true if any match is found\n}\n```"}
{"task_id": "SimdBench_99_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <stdbool.h>\n\nbool is_simple_power_simd(uint64_t x, uint64_t n) {\n    if (x == 1) return true; // 1 is a power of any number\n    if (n <= 1) return false; // n must be greater than 1\n\n    size_t vl;\n    uint64_t base = n;\n    vuint64m1_t powers = vmv_v_x_u64m1(base, vsetvlmax_e64m1()); // Initialize vector with base value\n    vbool64_t match = vfalse_b64(); // Vector to track matches\n\n    while (true) {\n        vl = vsetvl_e64m1(1); // Set vector length for one element\n        vbool64_t eq = vmseq_vx_u64m1_b64(powers, x, vl); // Check if any element equals x\n        match = vmor_mm_b64(match, eq, vl); // Update match vector\n\n        if (vfirst_m_b64(match, vl) >= 0) return true; // If match found, return true\n\n        // Check for overflow (if base * n > x, stop further calculations)\n        vbool64_t overflow = vmslt_vv_u64m1_b64(vmul_vx_u64m1(powers, n, vl), powers, vl);\n        if (vfirst_m_b64(overflow, vl) >= 0) break;\n\n        powers = vmul_vx_u64m1(powers, n, vl); // Multiply powers by n\n    }\n\n    return false; // No match found\n}\n```"}
{"task_id": "SimdBench_100_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nint hex_key_simd(const std::string &num) {\n    if (num.empty()) return 0;\n\n    const char prime_hex_digits[] = {'2', '3', '5', '7', 'B', 'D'};\n    size_t n = num.size();\n    int count = 0;\n\n    // Load the prime hex digits into a vector register\n    size_t prime_count = sizeof(prime_hex_digits) / sizeof(prime_hex_digits[0]);\n    vint8m1_t prime_vec = vle8_v_i8m1((const int8_t*)prime_hex_digits, prime_count);\n\n    for (size_t i = 0; i < n; i += vsetvl_e8m1(n - i)) {\n        size_t vl = vsetvl_e8m1(n - i);\n\n        // Load a chunk of the input string into a vector register\n        vint8m1_t input_vec = vle8_v_i8m1((const int8_t*)(num.data() + i), vl);\n\n        // Compare each input character with the prime hex digits\n        vbool8_t match_mask = vmseq_vx_i8m1_b8(input_vec, prime_hex_digits[0], vl);\n        for (size_t j = 1; j < prime_count; ++j) {\n            match_mask = vor_b8(match_mask, vmseq_vx_i8m1_b8(input_vec, prime_hex_digits[j], vl), vl);\n        }\n\n        // Count the matches\n        count += vcpop_b8(match_mask, vl);\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_100_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nint hex_key_simd(const std::string &num) {\n    if (num.empty()) return 0;\n\n    const char primes[] = {'2', '3', '5', '7', 'B', 'D'};\n    size_t len = num.size();\n    int count = 0;\n\n    size_t vlmax = vsetvlmax_e8m1(); // Maximum vector length for 8-bit elements\n    size_t i = 0;\n\n    while (i < len) {\n        size_t vl = vsetvl_e8m1(len - i); // Set vector length based on remaining elements\n\n        // Load a chunk of the input string into a vector\n        vint8m1_t vec_input = vle8_v_i8m1((const int8_t *)(num.data() + i), vl);\n\n        // Initialize a vector to accumulate matches\n        vint8m1_t vec_match = vmv_v_x_i8m1(0, vl);\n\n        // Compare against each prime digit\n        for (size_t j = 0; j < sizeof(primes); ++j) {\n            vint8m1_t vec_prime = vmv_v_x_i8m1(primes[j], vl);\n            vbool8_t mask = vmseq_vv_i8m1_b8(vec_input, vec_prime, vl);\n            vec_match = vadd_vv_i8m1(vec_match, vmv_v_x_i8m1(1, vl), mask);\n        }\n\n        // Sum up the matches in the current vector\n        count += vredsum_vs_i8m1_i8m1(vec_match, vmv_v_x_i8m1(0, vl), vl);\n\n        i += vl; // Move to the next chunk\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_100_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <string>\n\nint hex_key_simd(const std::string &num) {\n    size_t n = num.size();\n    if (n == 0) return 0;\n\n    // Prime hexadecimal digits: '2', '3', '5', '7', 'B', 'D'\n    const char prime_hex[] = {'2', '3', '5', '7', 'B', 'D'};\n    const size_t prime_count = sizeof(prime_hex) / sizeof(prime_hex[0]);\n\n    int count = 0;\n    size_t i = 0;\n\n    while (i < n) {\n        size_t vl = vsetvl_e8m1(n - i); // Set vector length for remaining elements\n        vuint8m1_t vec = vle8_v_u8m1((const uint8_t *)&num[i], vl); // Load characters into vector\n\n        vint8m1_t result = vmv_v_x_i8m1(0, vl); // Initialize result vector to 0\n\n        for (size_t j = 0; j < prime_count; ++j) {\n            vint8m1_t cmp = vmseq_vx_i8m1(vec, prime_hex[j], vl); // Compare with each prime hex digit\n            result = vor_vv_i8m1(result, cmp, vl); // Accumulate matches\n        }\n\n        count += vredsum_vs_i8m1_i32(result, result, vl); // Sum up matches in the vector\n        i += vl; // Move to the next chunk\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_100_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nint hex_key_simd(const std::string & num) {\n    if (num.empty()) return 0;\n\n    const char prime_hex_digits[] = {'2', '3', '5', '7', 'B', 'D'};\n    size_t n = num.size();\n    size_t prime_count = 0;\n\n    size_t vlmax = vsetvlmax_e8m1(); // Maximum vector length for 8-bit elements\n    size_t i = 0;\n\n    while (i < n) {\n        size_t vl = vsetvl_e8m1(n - i); // Set vector length based on remaining elements\n        vint8m1_t vec_num = vle8_v_i8m1((const int8_t *)(num.data() + i), vl);\n\n        vint8m1_t vec_prime_mask = vmv_v_x_i8m1(0, vl); // Initialize mask to zero\n\n        for (char prime_digit : prime_hex_digits) {\n            vint8m1_t vec_prime_digit = vmv_v_x_i8m1(prime_digit, vl);\n            vbool8_t match = vmseq_vv_i8m1_b8(vec_num, vec_prime_digit, vl);\n            vec_prime_mask = vor_vv_i8m1(vec_prime_mask, vbool_to_vint8m1(match, vl), vl);\n        }\n\n        prime_count += vcpop_m_b8(vbool_to_vmask(vmsne_vx_i8m1_b8(vec_prime_mask, 0, vl), vl)); // Count non-zero mask bits\n        i += vl;\n    }\n\n    return prime_count;\n}\n```"}
{"task_id": "SimdBench_100_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nint hex_key_simd(const std::string &num) {\n    if (num.empty()) return 0;\n\n    // Hexadecimal prime digits: 2, 3, 5, 7, B (11), D (13)\n    const char prime_digits[] = {'2', '3', '5', '7', 'B', 'D'};\n    size_t n = num.size();\n    int count = 0;\n\n    size_t vlmax = vsetvlmax_e8m1(); // Maximum vector length for 8-bit elements\n    size_t i = 0;\n\n    while (i < n) {\n        size_t vl = vsetvl_e8m1(n - i); // Set vector length based on remaining elements\n\n        // Load a chunk of the input string into a vector\n        vint8m1_t input_vec = vle8_v_i8m1((const int8_t *)&num[i], vl);\n\n        // Initialize a vector to accumulate matches\n        vint8m1_t match_vec = vmv_v_x_i8m1(0, vl);\n\n        // Compare against each prime digit\n        for (size_t j = 0; j < sizeof(prime_digits); j++) {\n            vint8m1_t prime_vec = vmv_v_x_i8m1(prime_digits[j], vl);\n            vbool8_t mask = vmseq_vv_i8m1_b8(input_vec, prime_vec, vl);\n            match_vec = vadd_vv_i8m1_m(mask, match_vec, match_vec, vmv_v_x_i8m1(1, vl), vl);\n        }\n\n        // Sum up matches in the vector\n        vint8m1_t sum_vec = vredsum_vs_i8m1_i8m1(match_vec, vmv_v_x_i8m1(0, vl), vl);\n        count += vmv_x_s_i8m1_i8(sum_vec);\n\n        i += vl;\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_101_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nbool is_happy_simd(const std::string &s) {\n    size_t n = s.size();\n    if (n < 3) return false;\n\n    size_t i = 0;\n    size_t vlmax = vsetvlmax_e8m1(); // Maximum vector length for 8-bit elements\n    while (i + 2 < n) {\n        size_t vl = vsetvl_e8m1(n - i - 2); // Set vector length based on remaining elements\n        vint8m1_t v1 = vle8_v_i8m1((const int8_t*)&s[i], vl);       // Load first character of triplets\n        vint8m1_t v2 = vle8_v_i8m1((const int8_t*)&s[i + 1], vl);   // Load second character of triplets\n        vint8m1_t v3 = vle8_v_i8m1((const int8_t*)&s[i + 2], vl);   // Load third character of triplets\n\n        vbool8_t mask1 = vmseq_vv_i8m1_b8(v1, v2, vl); // Check if v1 == v2\n        vbool8_t mask2 = vmseq_vv_i8m1_b8(v2, v3, vl); // Check if v2 == v3\n        vbool8_t mask3 = vmseq_vv_i8m1_b8(v1, v3, vl); // Check if v1 == v3\n\n        vbool8_t combined_mask = vmor_mm_b8(mask1, mask2, vl); // mask1 || mask2\n        combined_mask = vmor_mm_b8(combined_mask, mask3, vl);  // (mask1 || mask2) || mask3\n\n        if (vfirst_m_b8(combined_mask, vl) != -1) {\n            return false; // Found a triplet where characters are not distinct\n        }\n\n        i += vl; // Move to the next set of characters\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_101_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nbool is_happy_simd(const std::string &s) {\n    size_t n = s.size();\n    if (n < 3) return false;\n\n    size_t i = 0;\n    size_t vl;\n    while (i + 2 < n) {\n        vl = vsetvl_e8m1(n - i - 2); // Set vector length for 3 consecutive characters\n        vint8m1_t v1 = vle8_v_i8m1((const int8_t*)&s[i], vl);     // Load first character\n        vint8m1_t v2 = vle8_v_i8m1((const int8_t*)&s[i + 1], vl); // Load second character\n        vint8m1_t v3 = vle8_v_i8m1((const int8_t*)&s[i + 2], vl); // Load third character\n\n        vbool8_t cond1 = vmseq_vv_i8m1_b8(v1, v2, vl); // Check if v1 == v2\n        vbool8_t cond2 = vmseq_vv_i8m1_b8(v2, v3, vl); // Check if v2 == v3\n        vbool8_t cond3 = vmseq_vv_i8m1_b8(v1, v3, vl); // Check if v1 == v3\n\n        vbool8_t any_equal = vmor_mm_b8(vmor_mm_b8(cond1, cond2, vl), cond3, vl); // Combine conditions\n        if (vfirst_m_b8(any_equal, vl) != -1) return false; // If any condition is true, not happy\n\n        i += vl; // Advance by vector length\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_101_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nbool is_happy_simd(const std::string &s) {\n    size_t n = s.size();\n    if (n < 3) {\n        return false;\n    }\n\n    size_t vlmax = vsetvlmax_e8m1(); // Maximum vector length for 8-bit elements\n    for (size_t i = 0; i <= n - 3; i += vlmax) {\n        size_t vl = vsetvl_e8m1(std::min(n - i, vlmax)); // Set vector length for current iteration\n\n        // Load three consecutive characters into vectors\n        vint8m1_t v1 = vle8_v_i8m1((const int8_t *)&s[i], vl);\n        vint8m1_t v2 = vle8_v_i8m1((const int8_t *)&s[i + 1], vl);\n        vint8m1_t v3 = vle8_v_i8m1((const int8_t *)&s[i + 2], vl);\n\n        // Compare v1 with v2 and v2 with v3\n        vbool8_t cmp1 = vmseq_vv_i8m1_b8(v1, v2, vl);\n        vbool8_t cmp2 = vmseq_vv_i8m1_b8(v2, v3, vl);\n\n        // Combine the results to check if any consecutive characters are equal\n        vbool8_t cmp_any = vor_b8(cmp1, cmp2, vl);\n\n        // Check if any element in cmp_any is true\n        if (vfirst_m_b8(cmp_any, vl) != -1) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_101_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nbool is_happy_simd(const std::string &s) {\n    size_t n = s.size();\n    if (n < 3) {\n        return false;\n    }\n\n    size_t vlmax = vsetvlmax_e8m1(); // Maximum vector length for 8-bit elements\n    for (size_t i = 0; i <= n - 3; i += vlmax) {\n        size_t vl = vsetvl_e8m1(std::min(n - i, vlmax)); // Set vector length dynamically\n\n        vint8m1_t v1 = vle8_v_i8m1((const int8_t*)&s[i], vl);       // Load first character\n        vint8m1_t v2 = vle8_v_i8m1((const int8_t*)&s[i + 1], vl);   // Load second character\n        vint8m1_t v3 = vle8_v_i8m1((const int8_t*)&s[i + 2], vl);   // Load third character\n\n        vbool8_t cmp1 = vmseq_vv_i8m1_b8(v1, v2, vl); // Compare v1 == v2\n        vbool8_t cmp2 = vmseq_vv_i8m1_b8(v2, v3, vl); // Compare v2 == v3\n        vbool8_t cmp3 = vmseq_vv_i8m1_b8(v1, v3, vl); // Compare v1 == v3\n\n        vbool8_t any_equal = vor_b8(vor_b8(cmp1, cmp2, vl), cmp3, vl); // Combine comparisons\n\n        if (vfirst_b8(any_equal, vl) != -1) { // Check if any comparison is true\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_101_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nbool is_happy_simd(const std::string &s) {\n    size_t n = s.size();\n    if (n < 3) return false;\n\n    size_t i = 0;\n    size_t vl;\n    while (i + 2 < n) {\n        vl = vsetvl_e8m1(n - i - 2); // Set vector length for 3 consecutive comparisons\n\n        vint8m1_t v1 = vle8_v_i8m1((const int8_t*)&s[i], vl);       // Load current character\n        vint8m1_t v2 = vle8_v_i8m1((const int8_t*)&s[i + 1], vl);   // Load next character\n        vint8m1_t v3 = vle8_v_i8m1((const int8_t*)&s[i + 2], vl);   // Load next-next character\n\n        vbool8_t cmp1 = vmseq_vv_i8m1_b8(v1, v2, vl); // Compare s[i] == s[i+1]\n        vbool8_t cmp2 = vmseq_vv_i8m1_b8(v2, v3, vl); // Compare s[i+1] == s[i+2]\n        vbool8_t cmp3 = vmseq_vv_i8m1_b8(v1, v3, vl); // Compare s[i] == s[i+2]\n\n        vbool8_t any_equal = vmor_mm_b8(cmp1, vmor_mm_b8(cmp2, cmp3, vl), vl); // Any of the three comparisons is true\n\n        if (vfirst_m_b8(any_equal, vl) != -1) { // If any_equal is true for any element\n            return false;\n        }\n\n        i += vl; // Advance by vector length\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_102_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n#include <cmath>\n\nbool prime_length_simd(const std::string &str) {\n    size_t len = str.length();\n    if (len < 2) return false;\n\n    size_t sqrt_len = static_cast<size_t>(std::sqrt(len));\n    size_t range = sqrt_len + 1;\n\n    size_t vl = vsetvl_e32m1(range);\n    vint32m1_t indices = vrgather_vx_i32m1(vundefined_i32m1(), 1, vl);\n    vint32m1_t mod_results = vmod_vx_i32m1(indices, len, vl);\n\n    vint32m1_t zero = vundefined_i32m1();\n    vint32m1_t zero = vundefined_i32m1();\n}\n```"}
{"task_id": "SimdBench_102_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n#include <cmath>\n\nbool prime_length_simd(const std::string & str) {\n    size_t len = str.length();\n    if (len < 2) return false;\n\n    size_t sqrt_len = static_cast<size_t>(std::sqrt(len));\n    size_t range = sqrt_len + 1;\n\n    size_t vl = vsetvl_e32m1(range);\n    vint32m1_t indices = vid_v_u32m1(vl); // Generate indices [0, 1, 2, ..., vl-1]\n\n    vint32m1_t divisors = vadd_vx_u32m1(indices, 1, vl); // Generate [1, 2, ..., range]\n    vint32m1_t remainders = vrem_vx_u32m1(divisors, len, vl); // Compute len % divisors\n\n    vbool32_t is_zero = vmseq_vx_u32m1_b32(remainders, 0, vl); // Check if remainder is zero\n    size_t zero_count = vcpop_b32(is_zero, vl); // Count the number of zeros\n\n    return zero_count == 1; // Only divisible by 1 and itself\n}\n```"}
{"task_id": "SimdBench_102_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nbool prime_length_simd(const std::string &str) {\n    size_t n = str.length();\n    if (n < 2) return false;\n\n    size_t sqrt_n = static_cast<size_t>(sqrt(n)) + 1;\n    size_t range = sqrt_n - 2;\n\n    size_t vl;\n    for (size_t i = 0; i < range; i += vl) {\n        vl = vsetvl_e32m1(range - i);\n        vuint32m1_t indices = vadd_vx_u32m1(vmv_v_x_u32m1(2, vl), i);\n        vuint32m1_t remainders = vrem_vx_u32m1(indices, n, vl);\n        vbool32_t is_zero = vmseq_vx_u32m1_b32(remainders, 0, vl);\n        if (vfirst_m_b32(is_zero, vl) != -1) {\n            return false;\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_102_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n#include <cmath>\n\nbool prime_length_simd(const std::string & str) {\n    size_t len = str.length();\n    if (len < 2) return false;\n\n    size_t sqrt_len = static_cast<size_t>(std::sqrt(len));\n    size_t range = sqrt_len - 1;\n\n    size_t vl = vsetvl_e32m1(range);\n    vint32m1_t indices = vrgather_vx_i32m1(vundefined_i32m1(), 2, vl);\n    vint32m1_t mod_results = vmod_vx_i32m1(indices, len, vl);\n\n    bool is_prime = true;\n    for (size_t i = 0; i < vl; i++) {\n        if (mod_results[i] == 0) {\n            is_prime = false;\n            break;\n        }\n    }\n\n    return is_prime;\n}\n```"}
{"task_id": "SimdBench_102_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n#include <cmath>\n\nbool prime_length_simd(const std::string &str) {\n    size_t len = str.length();\n    if (len < 2) return false;\n\n    size_t sqrt_len = static_cast<size_t>(std::sqrt(len));\n    size_t range = sqrt_len - 1; // Check divisors from 2 to sqrt(len)\n\n    size_t vl;\n    for (size_t i = 2; i <= sqrt_len; i += vl) {\n        vl = vsetvl_e32m1(range); // Set vector length\n        vuint32m1_t indices = vrgather_vx_u32m1(vundefined_u32m1(), i, vl); // Generate indices\n        vuint32m1_t divisors = vadd_vx_u32m1(indices, 0, vl); // Add offset to generate divisors\n        vuint32m1_t len_vec = vmv_v_x_u32m1(len, vl); // Broadcast len to vector\n        vuint32m1_t remainders = vremu_vv_u32m1(len_vec, divisors, vl); // Compute len % divisors\n        vbool32_t is_zero = vmseq_vx_u32m1_b32(remainders, 0, vl); // Check if remainder is zero\n\n        if (vfirst_m_b32(is_zero) >= 0) return false; // If any divisor divides len, it's not prime\n        range -= vl;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_103_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n#include <vector>\n\nstd::string solve_simd(uint64_t N) {\n    // Convert the number to a string to extract digits\n    std::string num_str = std::to_string(N);\n    size_t len = num_str.size();\n\n    // Prepare a vector to hold the digits\n    std::vector<uint8_t> digits(len);\n    for (size_t i = 0; i < len; ++i) {\n        digits[i] = num_str[i] - '0';\n    }\n\n    // Use RVV to sum the digits\n    size_t vlmax = vsetvlmax_e8m1(); // Maximum vector length for 8-bit integers\n    size_t offset = 0;\n    uint64_t sum = 0;\n\n    while (offset < len) {\n        size_t vl = vsetvl_e8m1(len - offset); // Set vector length based on remaining elements\n        vint8m1_t vec_digits = vle8_v_i8m1(&digits[offset], vl); // Load digits into vector\n        vint32m1_t vec_sum = vwredsum_vs_i8m1_i32m1(vundefined_i32m1(), vec_digits, vl); // Reduce sum\n        sum += vmv_x_s_i32m1_i32(vec_sum); // Extract the scalar sum from the vector\n        offset += vl; // Move the offset forward\n    }\n\n    // Convert the sum to binary string\n    std::string binary_result;\n    while (sum > 0) {\n        binary_result = (char)((sum % 2) + '0') + binary_result;\n        sum /= 2;\n    }\n\n    return binary_result.empty() ? \"0\" : binary_result;\n}\n```"}
{"task_id": "SimdBench_103_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n#include <vector>\n\nstd::string solve_simd(uint64_t N) {\n    // Convert the number to a string to extract digits\n    std::string num_str = std::to_string(N);\n    size_t len = num_str.size();\n\n    // Prepare a vector to hold the digits\n    std::vector<uint8_t> digits(len);\n    for (size_t i = 0; i < len; ++i) {\n        digits[i] = num_str[i] - '0';\n    }\n\n    // Use RVV to sum the digits\n    size_t vlmax = vsetvlmax_e8m1(); // Maximum vector length for 8-bit integers\n    size_t offset = 0;\n    uint64_t sum = 0;\n\n    while (offset < len) {\n        size_t vl = vsetvl_e8m1(len - offset); // Set vector length based on remaining elements\n        vint8m1_t vec_digits = vle8_v_i8m1(&digits[offset], vl); // Load digits into vector\n        vint32m1_t vec_sum = vwredsum_vs_i8m1_i32m1(vundefined_i32m1(), vec_digits, vl); // Reduce sum\n        sum += vmv_x_s_i32m1_i32(vec_sum); // Extract the scalar sum\n        offset += vl; // Move the offset\n    }\n\n    // Convert the sum to binary string\n    std::string binary_result;\n    while (sum > 0) {\n        binary_result = (char)((sum % 2) + '0') + binary_result;\n        sum /= 2;\n    }\n\n    return binary_result.empty() ? \"0\" : binary_result;\n}\n```"}
{"task_id": "SimdBench_103_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n#include <vector>\n\nstd::string solve_simd(uint64_t N) {\n    // Convert the number to a string to extract digits\n    std::string num_str = std::to_string(N);\n    size_t len = num_str.size();\n\n    // Prepare a vector to hold the digits\n    std::vector<uint8_t> digits(len);\n    for (size_t i = 0; i < len; ++i) {\n        digits[i] = num_str[i] - '0';\n    }\n\n    // RVV setup\n    size_t vl = vsetvl_e8m1(len); // Set vector length for 8-bit integers\n    uint8_t *digits_ptr = digits.data();\n\n    // Load digits into RVV vector\n    vint8m1_t vec_digits = vle8_v_i8m1(digits_ptr, vl);\n\n    // Compute the sum of digits using RVV\n    vint32m1_t vec_sum = vmv_v_x_i32m1(0, vl); // Initialize sum vector to 0\n    vec_sum = vredsum_vs_i8m1_i32m1(vec_sum, vec_digits, vec_sum, vl);\n\n    // Extract the sum from the vector\n    int32_t sum = vmv_x_s_i32m1_i32(vec_sum);\n\n    // Convert the sum to binary string\n    std::string binary_result;\n    while (sum > 0) {\n        binary_result = (char)((sum % 2) + '0') + binary_result;\n        sum /= 2;\n    }\n\n    return binary_result.empty() ? \"0\" : binary_result;\n}\n```"}
{"task_id": "SimdBench_103_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n#include <vector>\n\nstd::string solve_simd(uint64_t N) {\n    // Convert the number to a string to extract digits\n    std::string num_str = std::to_string(N);\n    size_t len = num_str.size();\n\n    // Prepare a vector to store the digits\n    std::vector<uint32_t> digits(len);\n    for (size_t i = 0; i < len; ++i) {\n        digits[i] = num_str[i] - '0';\n    }\n\n    // RVV vectorized sum of digits\n    size_t vl;\n    uint32_t sum = 0;\n    size_t offset = 0;\n\n    while (offset < len) {\n        vl = vsetvl_e32m1(len - offset); // Set vector length\n        vint32m1_t vec_digits = vle32_v_i32m1(&digits[offset], vl); // Load digits into vector\n        sum += vreduce_sum_u32m1(vec_digits, vl); // Reduce sum of vector elements\n        offset += vl; // Move offset forward\n    }\n\n    // Convert the sum to binary string\n    std::string binary_result;\n    while (sum > 0) {\n        binary_result = (sum % 2 == 0 ? \"0\" : \"1\") + binary_result;\n        sum /= 2;\n    }\n\n    return binary_result.empty() ? \"0\" : binary_result;\n}\n```"}
{"task_id": "SimdBench_103_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n#include <vector>\n\nstd::string solve_simd(uint64_t N) {\n    // Convert the number to a string to extract digits\n    std::string num_str = std::to_string(N);\n    size_t len = num_str.size();\n\n    // Prepare a vector to store the digits\n    std::vector<uint32_t> digits(len);\n    for (size_t i = 0; i < len; ++i) {\n        digits[i] = num_str[i] - '0';\n    }\n\n    // RVV setup\n    size_t vlmax = vsetvlmax_e32m1(); // Get the maximum vector length for 32-bit integers\n    size_t vl;\n    uint32_t sum = 0;\n\n    // Process the digits in chunks using RVV\n    for (size_t i = 0; i < len; i += vlmax) {\n        vl = vsetvl_e32m1(len - i); // Set vector length for the remaining elements\n        vint32m1_t vec_digits = vle32_v_i32m1(&digits[i], vl); // Load digits into vector\n        sum += vredsum_vs_i32m1_i32m1(vundefined_i32m1(), vec_digits, vl); // Reduce sum\n    }\n\n    // Convert the sum to binary string\n    std::string binary_result;\n    while (sum > 0) {\n        binary_result = (char)((sum % 2) + '0') + binary_result;\n        sum /= 2;\n    }\n\n    return binary_result.empty() ? \"0\" : binary_result;\n}\n```"}
{"task_id": "SimdBench_104_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nint add_simd(std::vector<int> lst) {\n    size_t n = lst.size();\n    if (n == 0) return 0;\n\n    size_t vlmax = vsetvlmax_e32m1();\n    int32_t sum = 0;\n\n    for (size_t i = 1; i < n; i += vlmax * 2) {\n        size_t vl = vsetvl_e32m1((n - i) / 2);\n        vint32m1_t indices = vid_v_i32m1(vl);\n        vint32m1_t odd_indices = vadd_vx_i32m1(indices, i, vl);\n        vint32m1_t values = vluxei32_v_i32m1(lst.data(), odd_indices, vl);\n\n        vint32m1_t mask = vmseq_vx_i32m1(values, 0, vl);\n        vint32m1_t even_values = vslide1down_vx_i32m1(mask, vl);\n        sum += vredsum_vs_i32m1_i32m1(even_values, vl);\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_104_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nint add_simd(std::vector<int> lst) {\n    size_t n = lst.size();\n    if (n < 2) return 0;\n\n    size_t vlmax = vsetvlmax_e32m1();\n    int result = 0;\n\n    for (size_t i = 1; i < n; i += vlmax * 2) {\n        size_t vl = vsetvl_e32m1((n - i) / 2);\n        vint32m1_t indices = vrgather_vx_i32m1(vundefined_i32m1(), 2 * vslide1down_vx_i32m1(vundefined_i32m1(), i, vl), vl);\n        vint32m1_t values = vlse_v_i32m1(&lst[0], indices, vl);\n        vint32m1_t mask = vmslt_vx_i32m1(values, vl);\n        vint32m1_t masked_values = vmerge_vx_i32m1(mask, values, vl);\n        result += vadd_vx_i32m1(masked_values, vl);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_104_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nint add_simd(std::vector<int> lst) {\n    size_t n = lst.size();\n    if (n == 0) return 0;\n\n    int sum = 0;\n    size_t vl;\n    size_t i = 1; // Start at the first odd index\n\n    vint32m1_t v_sum = vmv_v_x_i32m1(0, vsetvlmax_e32m1()); // Initialize vector sum to 0\n\n    while (i < n) {\n        vl = vsetvl_e32m1((n - i + 1) / 2); // Set vector length for odd indices\n        vint32m1_t v_data = vle32_v_i32m1(&lst[i], vl); // Load elements at odd indices\n        vbool32_t v_even_mask = vmseq_vx_i32m1_b32(v_data, 0, vl); // Mask for even numbers\n        v_sum = vadd_vv_i32m1_m(v_even_mask, v_sum, v_sum, v_data, vl); // Add even numbers\n        i += 2 * vl; // Move to the next set of odd indices\n    }\n\n    sum = vredsum_vs_i32m1_i32m1(v_sum, v_sum, vsetvlmax_e32m1()); // Reduce vector sum to scalar\n    return sum;\n}\n```"}
{"task_id": "SimdBench_104_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nint add_simd(std::vector<int> lst) {\n    size_t n = lst.size();\n    if (n < 2) return 0;\n\n    size_t vlmax = vsetvlmax_e32m1();\n    int sum = 0;\n\n    for (size_t i = 1; i < n; i += vlmax * 2) {\n        size_t vl = vsetvl_e32m1(n - i);\n        vint32m1_t indices = vmul_vx_i32m1(vslide1down_vx_i32m1(vundefined_i32m1(), 1, vl), 2, vl);\n        vint32m1_t values = vle32_v_i32m1(&lst[i], vl);\n        vbool32_t mask = vmseq_vx_i32m1_b32(vand_vx_i32m1(values, 1, vl), 0, vl);\n        vint32m1_t masked_values = vmerge_vvm_i32m1(mask, values, vundefined_i32m1(), vl);\n        sum += vreduce_sum(masked_values);\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_104_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nint add_simd(std::vector<int> lst) {\n    size_t n = lst.size();\n    if (n < 2) return 0;\n\n    size_t vlmax = vsetvlmax_e32m1();\n    int sum = 0;\n\n    for (size_t i = 1; i < n; i += vlmax * 2) {\n        size_t vl = vsetvl_e32m1((n - i) / 2);\n        vint32m1_t indices = vid_v_i32m1(vl);\n        vint32m1_t odd_indices = vmul_vx_i32m1(indices, 2, vl);\n        odd_indices = vadd_vx_i32m1(odd_indices, i, vl);\n\n        vint32m1_t values = vluxei32_v_i32m1(lst.data(), odd_indices, vl);\n        vbool32_t mask = vmseq_vx_i32m1_b32(values, 0, vl);\n        vint32m1_t even_values = vslide1down_v_i32m1(values, mask, vl);\n\n        sum += vredsum_vs_i32m1_i32m1(even_values, vl);\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_105_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nstd::string encrypt_simd(const std::string &s) {\n    size_t n = s.size();\n    std::string result(n, '\\0');\n\n    size_t vlmax = vsetvlmax_e8m1(); // Maximum vector length for 8-bit elements\n    size_t i = 0;\n\n    while (i < n) {\n        size_t vl = vsetvl_e8m1(n - i); // Set vector length based on remaining elements\n        vint8m1_t vec_input = vle8_v_i8m1((const int8_t *)(s.data() + i), vl); // Load input characters\n        vint8m1_t vec_offset = vmv_v_x_i8m1(4, vl); // Create a vector with the offset value (2 * 2 = 4)\n        vint8m1_t vec_encrypted = vadd_vv_i8m1(vec_input, vec_offset, vl); // Add offset to input characters\n        vse8_v_i8m1((int8_t *)(result.data() + i), vec_encrypted, vl); // Store encrypted characters\n        i += vl;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_105_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nstd::string encrypt_simd(const std::string &s) {\n    size_t n = s.size();\n    std::string result(n, ' ');\n\n    size_t vlmax = vsetvlmax_e8m1(); // Maximum vector length for 8-bit elements\n    size_t i = 0;\n\n    while (i < n) {\n        size_t vl = vsetvl_e8m1(n - i); // Set vector length based on remaining elements\n        vint8m1_t input_vec = vle8_v_i8m1((const int8_t *)&s[i], vl); // Load characters into vector\n        vint8m1_t rotated_vec = input_vec + vint8m1_t(2 * 2); // Rotate alphabet by 2 * 2 positions\n        vse8_v_i8m1((int8_t *)&result[i], rotated_vec, vl); // Store result back to memory\n        i += vl;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_105_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nstd::string encrypt_simd(const std::string &s) {\n    size_t n = s.size();\n    std::string result(n, '\\0');\n\n    size_t vlmax = vsetvlmax_e8m1(); // Maximum vector length for 8-bit elements\n    size_t i = 0;\n\n    while (i < n) {\n        size_t vl = vsetvl_e8m1(n - i); // Set vector length based on remaining elements\n        vint8m1_t input_vec = vle8_v_i8m1((const int8_t*)&s[i], vl); // Load characters into vector\n        vint8m1_t rotated_vec = vadd_vx_i8m1(input_vec, 4, vl); // Rotate alphabet by 4 positions\n        vse8_v_i8m1((int8_t*)&result[i], rotated_vec, vl); // Store results back to the output string\n        i += vl;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_105_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nstd::string encrypt_simd(const std::string &s) {\n    size_t n = s.size();\n    std::string result(n, '\\0');\n\n    size_t vlmax = vsetvlmax_e8m1(); // Maximum vector length for 8-bit elements\n    size_t i = 0;\n\n    while (i < n) {\n        size_t vl = vsetvl_e8m1(n - i); // Set vector length based on remaining elements\n        vint8m1_t input_vec = vle8_v_i8m1(reinterpret_cast<const int8_t*>(&s[i]), vl);\n        vint8m1_t rotated_vec = vadd_vx_i8m1(input_vec, 4, vl); // Rotate alphabet by 2 * 2 = 4\n        vse8_v_i8m1(reinterpret_cast<int8_t*>(&result[i]), rotated_vec, vl);\n        i += vl;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_105_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nstd::string encrypt_simd(const std::string &s) {\n    size_t n = s.size();\n    std::string result(n, '\\0');\n    \n    size_t vlmax = vsetvlmax_e8m1(); // Maximum vector length for 8-bit elements\n    size_t i = 0;\n\n    while (i < n) {\n        size_t vl = vsetvl_e8m1(n - i); // Set vector length based on remaining elements\n        vint8m1_t input_vec = vle8_v_i8m1((const int8_t *)&s[i], vl); // Load characters into vector\n        vint8m1_t rotated_vec = input_vec + vint8m1_t(4); // Rotate alphabet by 4 (2 * 2)\n        vse8_v_i8m1((int8_t *)&result[i], rotated_vec, vl); // Store result back to memory\n        i += vl;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_106_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nstd::string encode_simd(const std::string &message) {\n    size_t len = message.size();\n    std::string result(len, ' ');\n\n    const char vowels[] = {'A', 'E', 'I', 'O', 'U', 'a', 'e', 'i', 'o', 'u'};\n    const char replacements[] = {'C', 'G', 'K', 'Q', 'W', 'c', 'g', 'k', 'q', 'w'};\n    size_t vowel_count = sizeof(vowels) / sizeof(vowels[0]);\n\n    size_t vl = vsetvl_e8m1(len); // Set vector length for 8-bit elements\n    for (size_t i = 0; i < len; i += vl) {\n        vl = vsetvl_e8m1(len - i); // Adjust vector length for remaining elements\n\n        vint8m1_t vec_msg = vle8_v_i8m1(reinterpret_cast<const int8_t *>(&message[i]), vl);\n        vint8m1_t vec_result = vec_msg;\n\n        // Swap case\n        vint8m1_t is_upper = vmul_vx_i8m1(vand_vx_i8m1(vec_msg, 0x20, vl), -1, vl); // Check if upper case\n        vint8m1_t swapped_case = vxor_vx_i8m1(vec_msg, 0x20, vl); // Swap case\n        vec_result = vmerge_vvm_i8m1(vmsne_vx_i8m1(is_upper, 0, vl), swapped_case, vec_msg, vl);\n\n        // Replace vowels\n        for (size_t j = 0; j < vowel_count; ++j) {\n            vint8m1_t is_vowel = vmseq_vx_i8m1(vec_result, vowels[j], vl);\n            vec_result = vmerge_vvm_i8m1(is_vowel, replacements[j], vec_result, vl);\n        }\n\n        vse8_v_i8m1(reinterpret_cast<int8_t *>(&result[i]), vec_result, vl);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_106_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nstd::string encode_simd(const std::string &message) {\n    size_t n = message.size();\n    std::string result(n, ' ');\n\n    size_t vlmax = vsetvlmax_e8m1(); // Maximum vector length for 8-bit elements\n    size_t i = 0;\n\n    while (i < n) {\n        size_t vl = vsetvl_e8m1(n - i); // Set vector length for remaining elements\n\n        vint8m1_t chars = vle8_v_i8m1((const int8_t *)&message[i], vl);\n\n        vint8m1_t is_lowercase = vmseq_vx_i8m1_b8(chars, 'a', vl) | \n                                 vmslt_vx_i8m1_b8(chars, 'a', vl) & \n                                 vmsle_vx_i8m1_b8(chars, 'z', vl);\n        vint8m1_t is_uppercase = vmseq_vx_i8m1_b8(chars, 'A', vl) | \n                                 vmslt_vx_i8m1_b8(chars, 'A', vl) & \n                                 vmsle_vx_i8m1_b8(chars, 'Z', vl);\n\n        vint8m1_t is_vowel = vmseq_vx_i8m1_b8(chars, 'a', vl) | \n                             vmseq_vx_i8m1_b8(chars, 'e', vl) | \n                             vmseq_vx_i8m1_b8(chars, 'i', vl) | \n                             vmseq_vx_i8m1_b8(chars, 'o', vl) | \n                             vmseq_vx_i8m1_b8(chars, 'u', vl) | \n                             vmseq_vx_i8m1_b8(chars, 'A', vl) | \n                             vmseq_vx_i8m1_b8(chars, 'E', vl) | \n                             vmseq_vx_i8m1_b8(chars, 'I', vl) | \n                             vmseq_vx_i8m1_b8(chars, 'O', vl) | \n                             vmseq_vx_i8m1_b8(chars, 'U', vl);\n\n        vint8m1_t case_swapped = vadd_vx_i8m1(chars, 'a' - 'A', vl);\n        vint8m1_t case_swapped_upper = vadd_vx_i8m1(chars, 'A' - 'a', vl);\n\n        vint8m1_t encoded = vadd_vx_i8m1(chars, 2, vl);\n\n        vint8m1_t final_chars = vmerge_vvm_i8m1(is_lowercase, case_swapped_upper, chars, vl);\n        final_chars = vmerge_vvm_i8m1(is_uppercase, case_swapped, final_chars, vl);\n        final_chars = vmerge_vvm_i8m1(is_vowel, encoded, final_chars, vl);\n\n        vse8_v_i8m1((int8_t *)&result[i], final_chars, vl);\n\n        i += vl;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_106_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nstd::string encode_simd(const std::string &message) {\n    size_t len = message.size();\n    std::string encoded(len, '\\0');\n\n    size_t vlmax = vsetvlmax_e8m1(); // Maximum vector length for 8-bit elements\n    size_t i = 0;\n\n    while (i < len) {\n        size_t vl = vsetvl_e8m1(len - i); // Set vector length based on remaining elements\n\n        vint8m1_t vec = vle8_v_i8m1(reinterpret_cast<const int8_t*>(&message[i]), vl);\n        vint8m1_t result = vmv_v_v_i8m1(vec, vl);\n\n        vint8m1_t lower_a = vmv_v_x_i8m1('a', vl);\n        vint8m1_t lower_z = vmv_v_x_i8m1('z', vl);\n        vint8m1_t upper_a = vmv_v_x_i8m1('A', vl);\n        vint8m1_t upper_z = vmv_v_x_i8m1('Z', vl);\n\n        vint8m1_t diff_lower = vmv_v_x_i8m1('a' - 'A', vl);\n        vint8m1_t diff_upper = vmv_v_x_i8m1('A' - 'a', vl);\n\n        vbool8_t is_lower = vmseq_vv_i8m1_b8(vec, lower_a, vl) | vmsle_vv_i8m1_b8(vec, lower_z, vl);\n        vbool8_t is_upper = vmseq_vv_i8m1_b8(vec, upper_a, vl) | vmsle_vv_i8m1_b8(vec, upper_z, vl);\n\n        vint8m1_t swapped_case = vadd_vv_i8m1(vec, diff_lower, vl);\n        swapped_case = vmerge_vvm_i8m1(is_upper, swapped_case, vadd_vv_i8m1(vec, diff_upper, vl), vl);\n\n        vint8m1_t vowels = vmv_v_x_i8m1(0, vl);\n        vowels = vmerge_vvm_i8m1(vmseq_vx_i8m1_b8(vec, 'a', vl) | vmseq_vx_i8m1_b8(vec, 'e', vl) |\n                                 vmseq_vx_i8m1_b8(vec, 'i', vl) | vmseq_vx_i8m1_b8(vec, 'o', vl) |\n                                 vmseq_vx_i8m1_b8(vec, 'u', vl) | vmseq_vx_i8m1_b8(vec, 'A', vl) |\n                                 vmseq_vx_i8m1_b8(vec, 'E', vl) | vmseq_vx_i8m1_b8(vec, 'I', vl) |\n                                 vmseq_vx_i8m1_b8(vec, 'O', vl) | vmseq_vx_i8m1_b8(vec, 'U', vl),\n                                 vadd_vx_i8m1(vec, 2, vl), swapped_case, vl);\n\n        vse8_v_i8m1(reinterpret_cast<int8_t*>(&encoded[i]), vowels, vl);\n        i += vl;\n    }\n\n    return encoded;\n}\n```"}
{"task_id": "SimdBench_106_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nstd::string encode_simd(const std::string &message) {\n    size_t len = message.size();\n    std::string result(len, '\\0');\n\n    const char vowels[] = {'A', 'E', 'I', 'O', 'U', 'a', 'e', 'i', 'o', 'u'};\n    const char vowel_replacements[] = {'C', 'G', 'K', 'Q', 'W', 'c', 'g', 'k', 'q', 'w'};\n\n    size_t vl = vsetvl_e8m1(len); // Set vector length for 8-bit elements\n    vint8m1_t v_message, v_result;\n\n    for (size_t i = 0; i < len; i += vl) {\n        vl = vsetvl_e8m1(len - i); // Adjust vector length for remaining elements\n        v_message = vle8_v_i8m1((const int8_t *)&message[i], vl);\n\n        vint8m1_t v_uppercase = vmul_vx_i8m1(v_message, -1, vl); // Placeholder for case swap\n        vint8m1_t v_vowel_replace =vmul_vx_i8m1(vowel_replacements[],vl); // Placeholder for vowel replacement logic\n    }\n}\n```"}
{"task_id": "SimdBench_106_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nstd::string encode_simd(const std::string &message) {\n    size_t len = message.size();\n    std::string result(len, ' ');\n\n    size_t vlmax = vsetvlmax_e8m1(); // Maximum vector length for 8-bit elements\n    size_t i = 0;\n\n    while (i < len) {\n        size_t vl = vsetvl_e8m1(len - i); // Set vector length based on remaining elements\n\n        vint8m1_t vec = vle8_v_i8m1(reinterpret_cast<const int8_t*>(&message[i]), vl);\n        vint8m1_t is_upper = vmul_vx_i8m1(vmsgt_vx_i8m1(vec, 'A' - 1, vl), -1, vl);\n        vint8m1_t is_lower = vmul_vx_i8m1(vmslt_vx_i8m1(vec, 'z' + 1, vl), -1, vl);\n        vint8m1_t is_vowel = vmul_vx_i8m1(vmslt_vx_i8m1(vec, 'z' + 1, vl), -1, vl);\n"}
{"task_id": "SimdBench_107_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <map>\n#include <string>\n#include <cctype>\n\nbool check_dict_case_simd(std::map<std::string, std::string> dict) {\n    if (dict.empty()) {\n        return false;\n    }\n\n    bool all_lower = true;\n    bool all_upper = true;\n\n    for (const auto& pair : dict) {\n        const std::string& key = pair.first;\n        size_t len = key.size();\n\n        size_t vl = vsetvl_e8m1(len); // Set vector length for 8-bit elements\n        vint8m1_t vec_key = vle8_v_i8m1((const int8_t*)key.data(), vl); // Load key into vector\n\n        vint8m1_t vec_lower = vmul_vx_i8m1(vec_key, 1, vl); // Copy vector for lower case check\n        vint8m1_t vec_upper = vmul_vx_i8m1(vec_key, 1, vl); // Copy vector for upper case check\n\n        vbool8_t mask_lower = vmsltu_vx_i8m1_b8(vec_lower, 'a', vl); // Check if less than 'a'\n        mask_lower = vmor_mm_b8(mask_lower, vmsgtu_vx_i8m1_b8(vec_lower, 'z', vl), vl); // OR with greater than 'z'\n\n        vbool8_t mask_upper = vmsltu_vx_i8m1_b8(vec_upper, 'A', vl); // Check if less than 'A'\n        mask_upper = vmor_mm_b8(mask_upper, vmsgtu_vx_i8m1_b8(vec_upper, 'Z', vl), vl); // OR with greater than 'Z'\n\n        if (vcpop_b8(mask_lower, vl) > 0) {\n            all_lower = false;\n        }\n        if (vcpop_b8(mask_upper, vl) > 0) {\n            all_upper = false;\n        }\n\n        if (!all_lower && !all_upper) {\n            return false;\n        }\n    }\n\n    return all_lower || all_upper;\n}\n```"}
{"task_id": "SimdBench_107_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <map>\n#include <string>\n#include <cctype>\n\nbool check_dict_case_simd(std::map<std::string, std::string> dict) {\n    if (dict.empty()) {\n        return false;\n    }\n\n    bool all_lower = true;\n    bool all_upper = true;\n\n    for (const auto& pair : dict) {\n        const std::string& key = pair.first;\n        size_t len = key.size();\n\n        size_t vl = vsetvl_e8m1(len); // Set vector length for 8-bit elements\n        vint8m1_t vec = vle8_v_i8m1((const int8_t*)key.data(), vl); // Load key into vector\n\n        vint8m1_t lower_mask = vmul_vx_i8m1(vec, 0); // Lower mask\n        vint8m1_t upper_mask = vmul_vx_i8m1(vec, 0); // Upper mask\n\n        for (int i=0;i)\n    }\n}\n```"}
{"task_id": "SimdBench_107_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <map>\n#include <string>\n#include <cctype>\n\nbool check_dict_case_simd(std::map<std::string, std::string> dict) {\n    if (dict.empty()) return false;\n\n    bool all_lower = true;\n    bool all_upper = true;\n\n    for (const auto& pair : dict) {\n        const std::string& key = pair.first;\n        size_t len = key.size();\n\n        size_t vl = vsetvl_e8m1(len); // Set vector length for 8-bit elements\n        vint8m1_t vec_key = vle8_v_i8m1((const int8_t*)key.data(), vl);\n\n        vint8m1_t vec_lower = vmul_vx_i8m1(vec_key, 0, vl); // Initialize vector for lower case check\n        vint8m1_t vec_upper = vmul_vx_i8m1(vec_key, 0, vl); // Initialize vector for upper case check\n\n        for (size_t i = 0; i < len; i += vl) {\n            vl = vsetvl_e8m1(len - i); // Adjust vector length for remaining elements\n            vec_key = vle8_v_i8m1((const int8_t*)(key.data() + i), vl);\n\n            // Check for lower case\n            vint8m1_t is_lower = vand_vv_i8m1(\n                vmsgt_vx_i8m1(vec_key, 'a' - 1, vl), \n                vmslt_vx_i8m1(vec_key, 'z' + 1, vl), vl\n            );\n            vec_lower = vor_vv_i8m1(vec_lower, is_lower, vl);\n\n            // Check for upper case\n            vint8m1_t is_upper = vand_vv_i8m1(\n                vmsgt_vx_i8m1(vec_key, 'A' - 1, vl), \n                vmslt_vx_i8m1(vec_key, 'Z' + 1, vl), vl\n            );\n            vec_upper = vor_vv_i8m1(vec_upper, is_upper, vl);\n        }\n\n        // Reduce results to check if all characters are lower or upper case\n        bool key_is_lower = vfirst_m_b8(vall_v_b8(vle8_v_i8m1((const int8_t*)vec_lower, vl)));\n        bool key_is_upper = vfirst_m_b8(vall_v_b8(vle8_v_i8m1((const int8_t*)vec_upper, vl)));\n\n        all_lower &= key_is_lower;\n        all_upper &= key_is_upper;\n\n        if (!all_lower && !all_upper) return false;\n    }\n\n    return all_lower || all_upper;\n}\n```"}
{"task_id": "SimdBench_107_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <map>\n#include <string>\n#include <cctype>\n\nbool check_dict_case_simd(std::map<std::string, std::string> dict) {\n    if (dict.empty()) {\n        return false;\n    }\n\n    bool all_lower = true;\n    bool all_upper = true;\n\n    for (const auto& pair : dict) {\n        const std::string& key = pair.first;\n        size_t len = key.size();\n\n        size_t vl = vsetvl_e8m1(len); // Set vector length based on key size\n        vint8m1_t vec = vle8_v_i8m1((const int8_t*)key.data(), vl);\n\n        vint8m1_t lower_mask = vmul_vx_i8m1(vec, 0);\n        vint8m1_t upper_mask = vmul_vx_i8m1(vec, 0);\n    }\n}\n```"}
{"task_id": "SimdBench_107_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <map>\n#include <string>\n#include <cctype>\n\nbool check_dict_case_simd(std::map<std::string, std::string> dict) {\n    if (dict.empty()) return false;\n\n    bool all_lower = true, all_upper = true;\n\n    for (const auto& pair : dict) {\n        const std::string& key = pair.first;\n        size_t len = key.size();\n\n        // Load the key into a vector\n        size_t vl = vsetvl_e8m1(len); // Set vector length for 8-bit elements\n        vint8m1_t vec_key = vle8_v_i8m1((const int8_t*)key.data(), vl);\n\n        // Check for lowercase\n        vint8m1_t lower_mask = vmul_vx_i8m1(vec_key, 0); // Initialize mask\n        lower_mask = vmslt_vx_i8m1_b8(vec_key, 'a', vl); // vec_key < 'a'\n        lower_mask = vmsgt_vx_i8m1_b8(vec_key, 'z', vl); // vec_key > 'z'\n        bool is_lower = vfirst_m_b8(lower_mask, vl) == -1;\n\n        // Check for uppercase\n        vint8m1_t upper_mask = vmul_vx_i8m1(vec_key, 0); // Initialize mask\n        upper_mask = vmslt_vx_i8m1_b8(vec_key, 'A', vl); // vec_key < 'A'\n        upper_mask = vmsgt_vx_i8m1_b8(vec_key, 'Z', vl); // vec_key > 'Z'\n        bool is_upper = vfirst_m_b8(upper_mask, vl) == -1;\n\n        all_lower &= is_lower;\n        all_upper &= is_upper;\n\n        // If neither all_lower nor all_upper is true, return false\n        if (!all_lower && !all_upper) return false;\n    }\n\n    return all_lower || all_upper;\n}\n```"}
{"task_id": "SimdBench_108_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> count_up_to_simd(int n) {\n    if (n <= 2) return {};\n\n    std::vector<int> primes;\n    primes.reserve(n / 2); // Reserve space for efficiency\n\n    // Create a boolean array to mark non-prime numbers\n    std::vector<bool> is_prime(n, true);\n    is_prime[0] = false;\n    if (n > 1) is_prime[1] = false;\n\n    size_t vl;\n    for (int i = 2; i * i < n; ++i) {\n        if (is_prime[i]) {\n            // Use RVV to mark multiples of i as non-prime\n            for (int j = i * i; j < n; j += i) {\n                size_t remaining = n - j;\n                vl = vsetvl_e8m1(remaining); // Set vector length\n                vint8m1_t indices = vslide1down_vx_i8m1(vundefined_i8m1(), j, vl);\n                vbool8_t mask = vmseq_vx_i8m1_b8(indices, j, vl);\n                vbool8_t prime_mask = vmnot_m_b8(mask, vl);\n                vse8_v_b8(&is_prime[j], prime_mask, vl);\n            }\n        }\n    }\n\n    // Collect primes into the result vector\n    for (int i = 2; i < n; ++i) {\n        if (is_prime[i]) {\n            primes.push_back(i);\n        }\n    }\n\n    return primes;\n}\n```"}
{"task_id": "SimdBench_108_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> count_up_to_simd(int n) {\n    if (n <= 2) return {};\n\n    std::vector<int> primes;\n    primes.reserve(n);\n\n    size_t vlmax = vsetvlmax_e32m1();\n    std::vector<int> is_prime(n, 1); // Initialize all numbers as prime\n\n    for (int i = 2; i * i < n; i++) {\n        if (is_prime[i]) {\n            size_t vl;\n            for (int j = i * i; j < n; j += vl) {\n                vl = vsetvl_e32m1((n - j + i - 1) / i);\n                vint32m1_t indices = vslide1down_vx_i32m1(vundefined_i32m1(), j, vl);\n                vbool32_t mask = vmseq_vx_i32m1_b32(indices, j, vl);\n                vstore_v_i32m1(&is_prime[j], vmv_v_x_i32m1(0, vl), mask);\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_108_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> count_up_to_simd(int n) {\n    if (n <= 2) return {};\n\n    std::vector<int> primes;\n    primes.reserve(n);\n\n    size_t vlmax = vsetvlmax_e32m1();\n    std::vector<int> is_prime(n, 1);\n    is_prime[0] = is_prime[1] = 0;\n\n    for (int i = 2; i * i < n; ++i) {\n        if (is_prime[i]) {\n            size_t vl;\n            for (int j = i * i; j < n; j += vl) {\n                vl = vsetvl_e32m1((n - j + i - 1) / i);\n                vint32m1_t indices = vslide1down_vx_i32m1(vundefined_i32m1(), j, vl);\n                vbool32_t mask = vmseq_vx_i32m1_b32(indices, j, vl);\n                vbool32_t mask2 = vmseq_vx_i32m1_b32(mask, j);\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_108_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> count_up_to_simd(int n) {\n    if (n <= 2) return {};\n\n    std::vector<int> primes;\n    primes.reserve(n);\n\n    int range = n;\n    std::vector<int> is_prime(range, 1);\n    is_prime[0] = is_prime[1] = 0;\n\n    size_t vlmax = vsetvlmax_e32m1();\n    for (int i = 2; i * i < n; i++) {\n        if (is_prime[i]) {\n            for (int j = i * i; j < n; j += i) {\n                size_t vl = vsetvl_e32m1((n - j + i - 1) / i);\n                vint32m1_t indices = vslide1down_vx_i32m1(vundefined_i32m1(), j, vl);\n                vbool32_t mask = vmseq_vx_i32m1_b32(indices, j, vl);\n                vstore_v_i32m1(&is_prime[j], vmv_v_x_i32m1(mask, vl));\n            }\n        }\n    }\n    for (int i = 2; i < n; i++) {\n        if (is_prime[i]) primes.push_back(i);\n    }\n    return primes;\n}\n```"}
{"task_id": "SimdBench_108_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> count_up_to_simd(int n) {\n    if (n <= 1) return {};\n\n    std::vector<int> primes;\n    primes.reserve(n);\n\n    for (int i = 2; i < n; i += vsetvlmax_e32m1()) {\n        size_t vl = vsetvl_e32m1(n - i); // Set vector length\n        vint32m1_t vec = vadd_vx_i32m1(vundefined_i32m1(), i, vl); // Generate vector of numbers starting from i\n\n        // Check primality for each number in the vector\n        vbool32_t is_prime = vmv_v_x_b32(vtrue_b32(), vl); // Initialize all as true\n        for (int j = 2; j * j < n; ++j) {\n            vint32m1_t divisor = vmv_v_x_i32m1(j, vl); // Vector of divisor j\n            vint32m1_t mod_result = vrem_vv_i32m1(vec, divisor, vl); // Compute vec % j\n            vbool32_t divisible = vmseq_vx_i32m1_b32(mod_result, 0, vl); // Check if divisible\n            is_prime = vmnot_v_b32(is_prime, divisible, vl); // Update is_prime mask\n        }\n\n        // Extract prime numbers from the vector\n        vint32m1_t prime_numbers = vcompress_vm_i32m1(is_prime, vec, vl);\n        size_t prime_count = vcpop_b32(is_prime, vl); // Count number of primes\n        std::vector<int> temp(prime_count);\n        vse_v_i32m1(temp.data(), prime_numbers, vl); // Store primes into temp\n        primes.insert(primes.end(), temp.begin(), temp.end());\n    }\n\n    return primes;\n}\n```"}
{"task_id": "SimdBench_109_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nint count_upper_simd(const std::string &s) {\n    size_t n = s.size();\n    size_t count = 0;\n\n    for (size_t i = 0; i < n; i += vsetvlmax_e8m1()) {\n        size_t vl = vsetvl_e8m1(n - i);\n        vuint8m1_t indices = vid_v_u8m1(vl); // Generate indices\n        vuint8m1_t even_mask = vmseq_vx_u8m1_b8(indices & 1, 0, vl); // Mask for even indices\n\n        vuint8m1_t chars = vle8_v_u8m1((const uint8_t*)&s[i], vl); // Load characters\n        vbool8_t is_upper = vmor_mm_b8(\n            vmor_mm_b8(\n                vmor_mm_b8(\n                    vmor_mm_b8(\n                        vmor_mm_b8(\n                            vmor_mm_b8(\n                                vmor_mm_b8(\n                                    vmor_mm_b8(\n                                        vmor_mm_b8(\n                                       "}
{"task_id": "SimdBench_109_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nint count_upper_simd(const std::string &s) {\n    size_t n = s.size();\n    int count = 0;\n    size_t i = 0;\n\n    while (i < n) {\n        size_t vl = vsetvl_e8m1(n - i); // Set vector length\n        vuint8m1_t indices = vid_v_u8m1(vl); // Generate indices\n        vuint8m1_t even_mask = vmseq_vx_u8m1_b8(vand_vx_u8m1(indices, 1, vl), 0, vl); // Mask for even indices\n\n        vuint8m1_t chars = vle8_v_u8m1((const uint8_t *)&s[i], vl); // Load characters\n        vbool8_t is_upper = vmand_mm_b8(\n            vmand_mm_b8(\n                vmsge_vx_u8m1_b8(chars, 'A', vl), // >= 'A'\n                vmsle_vx_u8m1_b8(chars, 'Z', vl), vl // <= 'Z'\n            ),\n            even_mask, vl // Apply even index mask\n        );\n\n        vbool8_t is_vowel = vor_mm_b8(\n            vor_mm_b8(\n                vor_mm_b8(\n                    vmseq_vx_u8m1_b8(chars, 'A', vl),\n                    vmseq_vx_u8m1_b8(chars, 'E', vl), vl\n                ),\n                vmseq_vx_u8m1_b8(chars, 'I', vl), vl\n            ),\n            vor_mm_b8(\n                vmseq_vx_u8m1_b8(chars, 'O', vl),\n                vmseq_vx_u8m1_b8(chars, 'U', vl), vl\n            ), vl\n        );\n\n        vbool8_t is_upper_vowel = vmand_mm_b8(is_upper, is_vowel, vl); // Combine masks\n        count += vpopc_m_b8(is_upper_vowel, vl); // Count active bits in the mask\n\n        i += vl; // Move to the next chunk\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_109_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nint count_upper_simd(const std::string & s) {\n    size_t n = s.size();\n    size_t count = 0;\n\n    const char uppercase_vowels[] = {'A', 'E', 'I', 'O', 'U'};\n    size_t vowels_len = sizeof(uppercase_vowels) / sizeof(uppercase_vowels[0]);\n\n    for (size_t i = 0; i < n; i += vsetvlmax_e8m1()) {\n        size_t vl = vsetvl_e8m1(n - i);\n        vint8m1_t indices = vle8_v_i8m1((const int8_t*)(s.data() + i), vl);\n\n        vint8m1_t even_mask = vmv_v_x_i8m1(0, vl);\n        for (size_t j = 0; j < vl; j += 2) {\n            even_mask = vslide1down_vx_i8m1(even_mask, 1, vl);\n        }\n        vbool8_t even_indices = vmseq_vx_i8m1_b8(even_mask, 0, vl);\n\n        vbool8_t vowel_mask = vmv_v_x_b8(false, vl);\n        for (size_t j = 0; j < vowels_len; j++) {\n            vowel_mask = vor_vv_b8(vowel_mask, vmseq_vx_i8m1_b8(indices, uppercase_vowels[j], vl), vl);\n        }\n\n        vbool8_t valid_mask = vmand_mm_b8(even_indices, vowel_mask, vl);\n        count += vpopc_m_b8(valid_mask, vl);\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_109_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nint count_upper_simd(const std::string &s) {\n    size_t n = s.size();\n    int count = 0;\n\n    for (size_t i = 0; i < n; i += vsetvlmax_e8m1()) {\n        size_t vl = vsetvl_e8m1(n - i);\n\n        vuint8m1_t indices = vid_v_u8m1(vl);\n        vuint8m1_t even_mask = vmseq_vx_u8m1_b8(indices & 1, 0, vl);\n\n        vuint8m1_t chars = vle8_v_u8m1(&s[i], vl);\n        vuint8m1_t vowels = vmsne_vx_u8m1_b8(chars, 'A', vl);\n        vuint8m1_t vowels = vmsne_vx_u8m1_b8(chars, 'E', vl);\n        vuint8m1_t vowels = vmsne_vx_u8m1_b8(chars, 'I', vl);\n        vuint8m1_t vowels = vmsne_vx_u8m1_b8(chars, 'O', vl);\n        vuint8m1_t vowels = vmsne_vx_u8m1_b8(chars, 'U', vl);\n```"}
{"task_id": "SimdBench_109_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nint count_upper_simd(const std::string &s) {\n    size_t n = s.size();\n    int count = 0;\n    size_t i = 0;\n\n    while (i < n) {\n        size_t vl = vsetvl_e8m1(n - i); // Set vector length\n        vuint8m1_t indices = vid_v_u8m1(vl); // Generate indices [0, 1, 2, ...]\n        vuint8m1_t even_mask = vmseq_vx_u8m1_b8(indices & 1, 0, vl); // Mask for even indices\n\n        vuint8m1_t chars = vle8_v_u8m1((const uint8_t *)(s.data() + i), vl); // Load characters\n        vuint8m1_t upper_mask = vmsle_vx_u8m1_b8(chars, 'Z', vl) & vmsge_vx_u8m1_b8(chars, 'A', vl); // Mask for uppercase letters\n        vuint8m1_t vowel_mask = vmor_vx_u8m1_b8(chars == 'A', chars == 'E', chars == 'I', chars == 'O', chars == 'U', vl); // Mask for vowels\n\n        vuint8m1_t combined_mask = even_mask & upper_mask & vowel_mask; // Combine masks\n        count += vpopc_m_b8(combined_mask, vl); // Count active elements in the combined mask\n\n        i += vl; // Advance by vector length\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_110_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> make_a_pile_simd(int n) {\n    std::vector<int> result(n);\n    size_t vlmax = vsetvlmax_e32m1(); // Maximum vector length for 32-bit integers\n    size_t vl = vsetvl_e32m1(n);     // Set vector length based on n\n\n    vint32m1_t base = vmv_v_x_i32m1(n, vl); // Initialize vector with n\n    vint32m1_t step = vmv_v_x_i32m1((n % 2 == 0) ? 2 : 1, vl); // Step is 2 if n is even, 1 if odd\n    vint32m1_t increment = vmv_v_x_i32m1(2, vl); // Increment is always 2\n\n    for (int i = 0; i < n; i += vl) {\n        vl = vsetvl_e32m1(n - i); // Adjust vector length for remaining elements\n        vint32m1_t levels = vadd_vv_i32m1(step, vmul_vx_i32m1(increment, i, vl), vl); // Calculate levels\n        vse32_v_i32m1(&result[i], levels, vl); // Store results in the output vector\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_110_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> make_a_pile_simd(int n) {\n    std::vector<int> result(n);\n    size_t vl;\n    int start = n;\n    int increment = (n % 2 == 0) ? 2 : 2; // Increment is always 2 for both odd and even cases.\n\n    for (size_t i = 0; i < n; i += vl) {\n        vl = vsetvl_e32m1(n - i); // Set the vector length for the remaining elements.\n        vint32m1_t base = vmv_v_x_i32m1(start, vl); // Initialize the base value.\n        vint32m1_t indices = vid_v_i32m1(vl); // Create a vector of indices [0, 1, 2, ...].\n        vint32m1_t increments = vmul_vx_i32m1(indices, increment, vl); // Calculate increments for each level.\n        vint32m1_t levels = vadd_vv_i32m1(base, increments, vl); // Add base and increments to get the levels.\n        vse32_v_i32m1(result.data() + i, levels, vl); // Store the result back to the vector.\n        start += vl * increment; // Update the start for the next iteration.\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_110_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> make_a_pile_simd(int n) {\n    std::vector<int> result(n);\n    size_t vlmax = vsetvlmax_e32m1(); // Maximum vector length for 32-bit integers\n    size_t vl = vsetvl_e32m1(n);     // Set vector length based on n\n\n    vint32m1_t v_indices = vundefined_e32m1(); // Initialize vector for indices\n    v_indices = vid_v_u32m1(vl);               // Create index vector [0, 1, 2, ...]\n\n    vint32m1_t v_base = vmv_v_x_e32m1(n, vl);  // Create vector with all elements set to n\n    vint32m1_t v_offset = vadd_vx_i32m1(v_indices, 0, vl); // Offset vector [0, 1, 2, ...]\n\n    vint32m1_t v_result = vadd_vv_i32m1(v_base, vadd_vx_i32m1(v_offset, n, vl));\n    return result;\n}\n```"}
{"task_id": "SimdBench_110_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> make_a_pile_simd(int n) {\n    std::vector<int> result(n);\n    size_t vlmax = vsetvlmax_e32m1(); // Maximum vector length for 32-bit integers\n    size_t i = 0;\n\n    // Initialize the first level with n stones\n    int start = n;\n\n    while (i < n) {\n        size_t vl = vsetvl_e32m1(n - i); // Set the vector length for the remaining elements\n        vint32m1_t indices = vid_v_i32m1(vl); // Create a vector of indices [0, 1, 2, ...]\n        vint32m1_t levels = vadd_vx_i32m1(indices, start, vl); // Add start to each index\n        vint32m1_t stones = vadd_vx_i32m1(levels, vl); // Add vl to each level\n        vse_v_i32m1(&result[i], stones, vl); // Store the result back to memory\n        i += vl;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_110_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> make_a_pile_simd(int n) {\n    std::vector<int> result(n);\n    size_t vl;\n    int start = n;\n\n    for (size_t i = 0; i < n; i += vl) {\n        vl = vsetvl_e32m1(n - i); // Set the vector length\n        vint32m1_t base = vmv_v_x_i32m1(start, vl); // Initialize vector with the starting value\n        vint32m1_t seq = vid_v_i32m1(vl); // Create a sequence vector [0, 1, 2, ...]\n        vint32m1_t levels = vadd_vx_i32m1(seq, base, vl); // Add base + sequence\n        vint32m1_t odd_even = vadd_vx_i32m1(seq, (n % 2 == 0 ? 2 : 1), vl); // Adjust for odd/even\n        vint32m1_t stones = vadd_vv_i32m1(levels, odd_even, vl); // Final computation\n\n        vse32_v_i32m1(&result[i], stones, vl); // Store the result back to memory\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_111_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n#include <cmath>\n\nstd::string rounded_avg_simd(int64_t n, int64_t m) {\n    if (n > m) {\n        return \"-1\";\n    }\n\n    int64_t range = m - n + 1;\n    size_t vl = vsetvl_e64(range); // Set vector length for 64-bit integers\n    vint64m1_t vec = vundefined_i64m1(); // Initialize vector\n\n    // Fill vector with integers from n to m\n    for (int64_t i = 0; i < range; i += vl) {\n        vl = vsetvl_e64(range - i); // Adjust vector length for remaining elements\n        vint64m1_t indices = vid_v_i64m1(vl); // Generate indices\n        vec = vadd_vx_i64m1(indices, n + i, vl); // Add base offset\n    }\n\n    // Compute sum using RVV intrinsics\n    vint64m1_t sum_vec = vundefined_i64m1();\n    sum_vec = vredsum_vs_i64m1_i64m1(sum_vec, vec, vundefined_i64m1(), vl);\n\n    int64_t sum = vget_i64m1(sum_vec, 0); // Extract sum from vector\n    int64_t avg = std::round(static_cast<double>(sum) / range); // Compute rounded average\n\n    // Convert average to binary string\n    std::string binary = std::bitset<64>(avg).to_string();\n    binary.erase(0, binary.find_first_not_of('0')); // Remove leading zeros\n\n    return binary;\n}\n```"}
{"task_id": "SimdBench_111_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n#include <cmath>\n\nstd::string rounded_avg_simd(int64_t n, int64_t m) {\n    if (n > m) {\n        return \"-1\";\n    }\n\n    int64_t range = m - n + 1;\n    size_t vlmax = vsetvlmax_e64m1();\n    size_t vl = vsetvl_e64m1(range < vlmax ? range : vlmax);\n\n    vint64m1_t vec = vundefined_e64m1();\n    vec = vslide1down_e64m1(vec, n, vl);\n\n    vint64m1_t sum = vundefined_e64m1();\n    sum = vslide1down_e64m1(sum, n, vl);\n}\n```"}
{"task_id": "SimdBench_111_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n#include <cmath>\n\nstd::string rounded_avg_simd(int64_t n, int64_t m) {\n    if (n > m) {\n        return \"-1\";\n    }\n\n    int64_t range = m - n + 1;\n    size_t vlmax = vsetvlmax_e64m1(); // Maximum vector length for 64-bit integers\n    size_t vl = vsetvl_e64m1(range); // Set vector length based on the range\n\n    int64_t sum = 0;\n    int64_t i = n;\n\n    while (range > 0) {\n        vl = vsetvl_e64m1(range); // Adjust vector length for remaining elements\n        vint64m1_t vec = vlse64_v_i64m1(&i, sizeof(int64_t), vl); // Load vector of integers\n        vint64m1_t ones = vmv_v_x_i64m1(1, vl); // Vector of ones\n        vint64m1_t indices = vadd_vv_i64m1(vec, ones, vl); // Increment indices\n        sum += vreduce_sum_i64m1(vec, vl); // Reduce sum of vector elements\n        i += vl; // Increment pointer\n        range -= vl; // Decrease remaining range\n    }\n\n    int64_t rounded_avg = std::round(sum / (double)(m - n + 1));\n    return std::bitset<64>(rounded_avg).to_string();\n}\n```"}
{"task_id": "SimdBench_111_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n#include <cmath>\n\nstd::string rounded_avg_simd(int64_t n, int64_t m) {\n    if (n > m) {\n        return \"-1\";\n    }\n\n    int64_t range = m - n + 1;\n    int64_t sum = 0;\n\n    size_t vl;\n    int64_t i = n;\n\n    while (i <= m) {\n        vl = vsetvl_e64(m - i + 1); // Set vector length based on remaining elements\n        vint64m1_t vec = vle64_v_i64m1(&i, vl); // Load vector of integers starting from i\n        vint64m1_t inc = vmv_v_x_i64m1(1, vl); // Create a vector of 1s\n        vec = vadd_vv_i64m1(vec, inc, vl); // Increment each element in the vector\n        i += vl; // Update i to move to the next batch\n        sum += vredsum_vs_i64m1_i64m1(vundefined_i64m1(), vec, vundefined_i64m1(), vl); // Reduce sum\n    }\n\n    int64_t avg = std::round((double)sum / range); // Compute rounded average\n    std::string binary = std::bitset<64>(avg).to_string(); // Convert to binary string\n    binary.erase(0, binary.find_first_not_of('0')); // Remove leading zeros\n    return binary.empty() ? \"0\" : binary;\n}\n```"}
{"task_id": "SimdBench_111_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n#include <cmath>\n\nstd::string rounded_avg_simd(int64_t n, int64_t m) {\n    if (n > m) {\n        return \"-1\";\n    }\n\n    int64_t range = m - n + 1;\n    int64_t sum = 0;\n\n    size_t vl;\n    int64_t i = n;\n\n    while (i <= m) {\n        vl = vsetvl_e64(m - i + 1); // Set vector length based on remaining elements\n        vint64m1_t vec = vle64_v_i64m1(&i, vl); // Load values from i to m\n        vint64m1_t indices = vslide1down_vx_i64m1(vec, i, vl); // Generate indices\n        vint64m1_t sum = vadd_vx_i64m1(indices, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_112_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> func_simd(int n) {\n    std::vector<int> result(n);\n    int i = 1;\n\n    while (i <= n) {\n        size_t vl = vsetvl_e32m1(n - i + 1); // Set vector length\n        vint32m1_t indices = vadd_vx_i32m1(vmv_v_x_i32m1(0, vl), i); // Create vector of indices starting from i\n\n        // Compute factorial for even indices\n        vint32m1_t even_mask = vmseq_vx_i32m1_b32(vand_vx_i32m1(indices, 1, vl), 0, vl);\n        vint32m1_t factorial = vmv_v_x_i32m1(1, vl);\n        vint32m1_t temp_indices = indices;\n\n        while (vfirst_m_b32(even_mask, vl) >= 0) {\n            factorial = vmul_vv_i32m1_m(even_mask, factorial, factorial, temp_indices, vl);\n            temp_indices = vsub_vx_i32m1(temp_indices, 1, vl);\n            even_mask = vmand_mm_b32(even_mask, vmsgt_vx_i32m1_b32(temp_indices, 0, vl), vl);\n        }\n        factorial = vrem_vx_i32m1(factorial, 10000, vl);\n\n        // Compute sum for odd indices\n        vint32m1_t odd_mask = vmsne_vx_i32m1_b32(vand_vx_i32m1(indices, 1, vl), 0, vl);\n        vint32m1_t sum = vmul_vx_i32m1(indices, indices + 1, vl) / 2;\n\n        // Merge results\n        vint32m1_t result_vec = vmerge_vvm_i32m1(odd_mask, sum, factorial, vl);\n        vse_v_i32m1(&result[i - 1], result_vec, vl);\n\n        i += vl;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_112_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> func_simd(int n) {\n    std::vector<int> result(n);\n    int vlmax = vsetvlmax_e32m1(); // Maximum vector length for 32-bit integers\n    int i = 1;\n\n    while (i <= n) {\n        int vl = vsetvl_e32m1(n - i + 1); // Set vector length based on remaining elements\n        vint32m1_t indices = vslide1down_vx_i32m1(vundefined_i32m1(), i - 1, vl); // Generate indices starting from i\n        indices = vadd_vx_i32m1(indices, 1, vl); // Increment indices to start from i\n\n        vint32m1_t even_mask = vmseq_vx_i32m1_b32(indices, 0, vl); // Mask for even indices\n        vint32m1_t odd_mask = vmseq_vx_i32m1_b32(indices, 1, vl); // Mask for odd indices\n\n        vint32m1_t factorial = vslide1down_vx_i32m1(vundefined_i32m1(), 1, vl); // Compute factorials\n        vint32m1_t sum"}
{"task_id": "SimdBench_112_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> func_simd(int n) {\n    std::vector<int> result(n);\n    int i = 1;\n\n    while (i <= n) {\n        size_t vl = vsetvl_e32m1(n - i + 1); // Set vector length\n        vint32m1_t indices = vmv_v_x_i32m1(i, vl); // Initialize vector with values starting from i\n        vint32m1_t mod_values = vrem_vx_i32m1(indices, 2, vl); // Compute i % 2 for each index\n\n        vint32m1_t factorials = vmv_v_x_i32m1(1, vl); // Initialize factorials vector\n        vint32m1_t sums = vmv_v_x_i32m1(0, vl); // Initialize sums vector\n\n        vint32m1_t mask_even = vmseq_vx_i32m1(mod_values, 0, vl); // Mask for even indices\n        vint32m1_t mask_odd = vmnot_m_b32(mask_even, vl); // Mask for odd indices\n\n        // Compute factorials for even indices\n        for (int j = 1; j <= n; ++j) {\n            vint32m1_t temp = vmul_vx_i32m1(factorials, j, vl);\n            factorials = vmerge_vvm_i32m1(mask_even, temp, factorials, vl);\n        }\n        factorials = vrem_vx_i32m1(factorials, 10000, vl); // Apply modulo 10,000\n\n        // Compute sums for odd indices\n        for (int j = 1; j <= n; ++j) {\n            vint32m1_t temp = vadd_vx_i32m1(sums, j, vl);\n            sums = vmerge_vvm_i32m1(mask_odd, temp, sums, vl);\n        }\n\n        // Merge results into the final vector\n        vint32m1_t final_values = vmerge_vvm_i32m1(mask_even, factorials, sums, vl);\n        vse_v_i32m1(&result[i - 1], final_values, vl);\n\n        i += vl; // Increment index by vector length\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_112_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> func_simd(int n) {\n    std::vector<int> result(n);\n    int vlmax = vsetvlmax_e32m1(); // Maximum vector length for 32-bit integers\n    for (int i = 0; i < n; i += vlmax) {\n        int vl = vsetvl_e32m1(n - i); // Set vector length based on remaining elements\n        vint32m1_t indices = vadd_vx_i32m1(vundefined_i32m1(), i + 1, vl); // Generate indices starting from i+1\n        vint32m1_t is_even = vand_vx_i32m1(vrem_vx_i32m1(indices, 2, vl), 1, vl); // Check if index is even\n        vint32m1_t factorial = vundefined_i32m1();\n        vint32m1_t sum = vundefined_i32m1();\n\n        // Compute factorial for even indices\n        factorial = vmv_v_x_i32m1(1, vl);\n        for (int j = 1; j <= n; j++) {\n            factorial = vmul_vx_i32m1(factorial, j, vl);\n        }\n\n        // Compute sum for odd indices\n        sum = vmv_v_x_i32m1(0, vl);\n        for (int j = 1; j <= n; j++) {\n            sum = vadd_vx_i32m1(sum, j, vl);\n        }\n\n        // Select factorial or sum based on even/odd condition\n        vint32m1_t result_vec = vmerge_vvm_i32m1(is_even, factorial, sum, vl);\n\n        // Store results back to the output vector\n        vse_v_i32m1(&result[i], result_vec, vl);\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_112_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> func_simd(int n) {\n    std::vector<int> result(n);\n    int i = 1;\n\n    while (i <= n) {\n        size_t vl = vsetvl_e32m1(n - i + 1); // Set the vector length\n        vint32m1_t indices = vmv_v_x_i32m1(i, vl); // Initialize vector with starting index i\n        vint32m1_t is_even = vmv_v_x_i32m1(0, vl); // Vector to store even/odd flags\n        vint32m1_t factorial = vmv_v_x_i32m1(1, vl); // Vector to compute factorial\n        vint32m1_t sum = vmv_v_x_i32m1(0, vl); // Vector to compute sum\n\n        // Compute even/odd flags\n        is_even = vand_vx_i32m1(vrem_vx_i32m1(indices, 2, vl), 1, vl);\n\n        // Compute factorial for even indices\n        vint32m1_t temp_indices = indices;\n        while (vfirst_m_b32(vmsne_vx_i32m1_b32(temp_indices, 1, vl), vl)) {\n            factorial = vmul_vv_i32m1(factorial, temp_indices, vl);\n            temp_indices = vsub_vx_i32m1(temp_indices, 1, vl);\n        }\n        factorial = vrem_vx_i32m1(factorial, 10000, vl); // Modulo 10,000\n\n        // Compute sum for odd indices\n        sum = vmul_vx_i32m1(indices, (indices + 1) / 2, vl); // Sum formula: i * (i + 1) / 2\n\n        // Select results based on even/odd flags\n        vint32m1_t final_result = vmerge_vvm_i32m1(is_even, factorial, sum, vl);\n\n        // Store results in the output vector\n        vse_v_i32m1(&result[i - 1], final_result, vl);\n\n        i += vl; // Increment index by vector length\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_113_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <string>\n\nbool is_palindrome(int num) {\n    std::string s = std::to_string(num);\n    int len = s.size();\n    for (int i = 0; i < len / 2; ++i) {\n        if (s[i] != s[len - i - 1]) {\n            return false;\n        }\n    }\n    return true;\n}\n\nstd::vector<int> even_odd_palindrome_simd(int n) {\n    int even_count = 0, odd_count = 0;\n\n    size_t vl;\n    for (int i = 1; i <= n;) {\n        vl = vsetvl_e32m1(n - i + 1); // Set vector length\n        vint32m1_t indices = vle32_v_i32m1((int32_t*)&i, vl); // Load indices into vector\n\n        vint32m1_t even_mask = vmv_v_x_i32m1(0, vl); // Initialize even mask\n        vint32m1_t odd_mask = vmv_v_x_i32m1(0, vl);  // Initialize odd mask\n\n        for (size_t j = 0; j < vl; ++j) {\n            int num = i + j;\n            if (is_palindrome(num)) {\n                if (num % 2 == 0) {\n                    even_mask[j] = 1;\n                } else {\n                    odd_mask[j] = 1;\n                }\n            }\n        }\n\n        even_count += vpopc_m_b32(vmsne_vx_i32m1_b32(even_mask, 0, vl));\n        odd_count += vpopc_m_b32(vmsne_vx_i32m1_b32(odd_mask, 0, vl));\n\n        i += vl;\n    }\n\n    return {even_count, odd_count};\n}\n```"}
{"task_id": "SimdBench_113_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <string>\n\nbool is_palindrome(int num) {\n    std::string s = std::to_string(num);\n    int len = s.size();\n    for (int i = 0; i < len / 2; ++i) {\n        if (s[i] != s[len - i - 1]) {\n            return false;\n        }\n    }\n    return true;\n}\n\nstd::vector<int> even_odd_palindrome_simd(int n) {\n    int even_count = 0, odd_count = 0;\n\n    // Vector length\n    size_t vl;\n    for (int i = 1; i <= n;) {\n        // Load a vector of integers starting from i\n        vl = vsetvl_e32m1(n - i + 1); // Set vector length\n        vint32m1_t vec = vle32_v_i32m1(&i, vl);\n\n        // Check if each number is a palindrome\n        vint32m1_t is_palindrome_vec = vmv_v_x_i32m1(0, vl);\n        for (size_t j = 0; j < vl; ++j) {\n            int num = i + j;\n            if (is_palindrome(num)) {\n                is_palindrome_vec = vslide1up_vx_i32m1(is_palindrome_vec, 1, vl);\n            }\n        }\n\n        // Check even/odd for palindromes\n        vint32m1_t even_mask = vmv_v_x_i32m1(0, vl);\n        vint32m1_t odd_mask = vmv_v_x_i32m1(0, vl);\n        for (size_t j = 0; j < vl; ++j) {\n            int num = i + j;\n            if (is_palindrome(num)) {\n                if (num % 2 == 0) {\n                    even_mask = vslide1up_vx_i32m1(even_mask, 1, vl);\n                } else {\n                    odd_mask = vslide1up_vx_i32m1(odd_mask, 1, vl);\n                }\n            }\n        }\n\n        // Count even and odd palindromes\n        even_count += vcpop_m_b32(vmsne_vx_i32m1_b32(even_mask, 0, vl));\n        odd_count += vcpop_m_b32(vmsne_vx_i32m1_b32(odd_mask, 0, vl));\n\n        // Increment i by vector length\n        i += vl;\n    }\n\n    return {even_count, odd_count};\n}\n```"}
{"task_id": "SimdBench_113_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <string>\n\nbool is_palindrome(int num) {\n    std::string s = std::to_string(num);\n    int len = s.length();\n    for (int i = 0; i < len / 2; ++i) {\n        if (s[i] != s[len - i - 1]) {\n            return false;\n        }\n    }\n    return true;\n}\n\nstd::vector<int> even_odd_palindrome_simd(int n) {\n    int even_count = 0, odd_count = 0;\n\n    size_t vl;\n    for (int i = 1; i <= n;) {\n        vl = vsetvl_e32m1(n - i + 1); // Set vector length based on remaining elements\n\n        vint32m1_t vec = vle32_v_i32m1(&i, vl); // Load integers starting from i\n        vint32m1_t is_palindrome_vec = vmv_v_x_i32m1(0, vl); // Initialize palindrome flags to 0\n\n        for (size_t j = 0; j < vl; ++j) {\n            int num = i + j;\n            if (is_palindrome(num)) {\n                is_palindrome_vec = vadd_vx_i32m1(is_palindrome_vec, 1, vl); // Mark as palindrome\n            }\n        }\n\n        vint32m1_t even_mask = vmseq_vx_i32m1(vec, 0, vl); // Check if numbers are even\n        vint32m1_t odd_mask = vmnot_m_b32(even_mask, vl);  // Check if numbers are odd\n\n        vint32m1_t even_palindromes = vand_vv_i32m1(is_palindrome_vec, even_mask, vl);\n        vint32m1_t odd_palindromes = vand_vv_i32m1(is_palindrome_vec, odd_mask, vl);\n\n        even_count += vredsum_vs_i32m1_i32m1(vmv_v_x_i32m1(0, vl), even_palindromes, vl);\n        odd_count += vredsum_vs_i32m1_i32m1(vmv_v_x_i32m1(0, vl), odd_palindromes, vl);\n\n        i += vl; // Increment by vector length\n    }\n\n    return {even_count, odd_count};\n}\n```"}
{"task_id": "SimdBench_113_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <string>\n\nbool is_palindrome(int num) {\n    std::string s = std::to_string(num);\n    int len = s.size();\n    for (int i = 0; i < len / 2; i++) {\n        if (s[i] != s[len - i - 1]) {\n            return false;\n        }\n    }\n    return true;\n}\n\nstd::vector<int> even_odd_palindrome_simd(int n) {\n    int even_count = 0, odd_count = 0;\n\n    size_t vl;\n    for (int i = 1; i <= n; i += vl) {\n        vl = vsetvl_e32m1(n - i + 1); // Set vector length\n        vint32m1_t indices = vadd_vx_i32m1(vundefined_i32m1(), i, vl); // Create vector of indices\n        vint32m1_t results = vmv_v_x_i32m1(0, vl); // Initialize results vector to 0\n\n        for (size_t j = 0; j < vl; j++) {\n            int num = i + j;\n            if (is_palindrome(num)) {\n                results = vadd_vx_i32m1(results, num % 2 == 0 ? 2 : 1, vl);\n            }\n        }\n\n        vint32m1_t even_mask = vmseq_vx_i32m1(results, 2, vl); // Mask for even numbers\n        vint32m1_t odd_mask = vmseq_vx_i32m1(results, 1, vl);  // Mask for odd numbers\n\n        even_count += vcpop_m_b32(even_mask, vl); // Count even numbers\n        odd_count += vcpop_m_b32(odd_mask, vl);   // Count odd numbers\n    }\n\n    return {even_count, odd_count};\n}\n```"}
{"task_id": "SimdBench_113_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <string>\n\nbool is_palindrome(int num) {\n    std::string s = std::to_string(num);\n    int len = s.size();\n    for (int i = 0; i < len / 2; ++i) {\n        if (s[i] != s[len - i - 1]) {\n            return false;\n        }\n    }\n    return true;\n}\n\nstd::vector<int> even_odd_palindrome_simd(int n) {\n    int even_count = 0, odd_count = 0;\n\n    size_t vl;\n    for (int i = 1; i <= n;) {\n        vl = vsetvl_e32m1(n - i + 1); // Set vector length based on remaining elements\n        vint32m1_t vec = vle32_v_i32m1(&i, vl); // Load integers starting from i\n        vint32m1_t is_palindrome_vec = vmv_v_x_i32m1(0, vl); // Initialize palindrome vector to 0\n\n        for (size_t j = 0; j < vl; ++j) {\n            int num = i + j;\n            if (is_palindrome(num)) {\n                is_palindrome_vec = vslide1up_vx_i32m1(is_palindrome_vec, 1, vl); // Mark as palindrome\n            }\n        }\n\n        vint32m1_t even_mask = vmseq_vx_i32m1_b32(vand_vx_i32m1(vec, 1, vl), 0, vl); // Check even numbers\n        vint32m1_t odd_mask = vmnot_m_b32(even_mask, vl); // Check odd numbers\n\n        even_count += vpopc_m_b32(even_mask, vl); // Count even palindromes\n        odd_count += vpopc_m_b32(odd_mask, vl); // Count odd palindromes\n\n        i += vl; // Increment i by vector length\n    }\n\n    return {even_count, odd_count};\n}\n```"}
{"task_id": "SimdBench_114_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <vector>\n\nint count_nums_simd(std::vector<int> n) {\n    size_t n_size = n.size();\n    if (n_size == 0) return 0;\n\n    int count = 0;\n    size_t vlmax = vsetvlmax_e32m1(); // Maximum vector length for 32-bit integers\n    size_t i = 0;\n\n    while (i < n_size) {\n        size_t vl = vsetvl_e32m1(n_size - i); // Set vector length based on remaining elements\n        vint32m1_t vec = vle32_v_i32m1(&n[i], vl); // Load vector of integers\n\n        vint32m1_t abs_vec = vabs_v_i32m1(vec, vl); // Compute absolute values\n        vint32m1_t sum_digits = vmv_v_x_i32m1(0, vl); // Initialize sum of digits vector to 0\n\n        // Compute sum of digits for each element\n        while (vfirst_m_b32(vmsne_vx_i32m1_b32(abs_vec, 0, vl), vl) >= 0) {\n            vint32m1_t digit = vrem_vx_i32m1(abs_vec, 10, vl); // Extract last digit\n            sum_digits = vadd_vv_i32m1(sum_digits, digit, vl); // Add to sum of digits\n            abs_vec = vdiv_vx_i32m1(abs_vec, 10, vl); // Remove last digit\n        }\n\n        // Check if sum of digits > 0\n        vbool32_t mask = vmsgt_vx_i32m1_b32(sum_digits, 0, vl);\n        count += vcpop_m_b32(mask, vl); // Count active elements in the mask\n\n        i += vl; // Move to the next chunk\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_114_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <cmath>\n\nint count_nums_simd(std::vector<int> n) {\n    size_t len = n.size();\n    int count = 0;\n\n    size_t vlmax = vsetvlmax_e32m1(); // Maximum vector length for 32-bit integers\n    for (size_t i = 0; i < len; i += vlmax) {\n        size_t vl = vsetvl_e32m1(len - i); // Set vector length based on remaining elements\n        vint32m1_t vec = vle32_v_i32m1(&n[i], vl); // Load vector of integers\n\n        vint32m1_t abs_vec = vabs_v_i32m1(vec, vl); // Take absolute value of integers\n        vint32m1_t sum_digits_vec = vmv_v_x_i32m1(0, vl); // Initialize sum of digits vector\n\n        while (vmin_vv_i32m1(abs_vec, vmv_v_x_i32m1(0, vl), vl) != vmv_v_x_i32m1(0, vl)) {\n            vint32m1_t digit = vrem_vv_i32m1(abs_vec, vmv_v_x_i32m1(10, vl), vl); // Extract last digit\n            sum_digits_vec = vadd_vv_i32m1(sum_digits_vec, digit, vl); // Add digit to sum\n            abs_vec = vdiv_vv_i32m1(abs_vec, vmv_v_x_i32m1(10, vl), vl); // Remove last digit\n        }\n\n        vbool32_t mask = vmgt_vx_i32m1_b32(sum_digits_vec, 0, vl); // Mask for sum of digits > 0\n        count += vcpop_b32(mask); // Count active elements in the mask\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_114_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <cmath>\n\nint count_nums_simd(std::vector<int> n) {\n    size_t len = n.size();\n    int count = 0;\n\n    // Process the vector in chunks using RVV\n    size_t vl;\n    for (size_t i = 0; i < len; i += vl) {\n        vl = vsetvl_e32m1(len - i); // Set vector length for the remaining elements\n\n        vint32m1_t vec = vle32_v_i32m1(&n[i], vl); // Load vector elements\n        vint32m1_t abs_vec = vabs_v_i32m1(vec, vl); // Take absolute value of elements\n\n        vint32m1_t sum_digits = vmv_v_x_i32m1(0, vl); // Initialize sum_digits vector to zero\n\n        // Compute sum of digits for each number\n        while (true) {\n            vint32m1_t digit = vrem_vx_i32m1(abs_vec, 10, vl); // Extract last digit\n            sum_digits = vadd_vv_i32m1(sum_digits, digit, vl); // Add digit to sum_digits\n            abs_vec = vdiv_vx_i32m1(abs_vec, 10, vl); // Remove last digit\n\n            // Break when all numbers are reduced to zero\n            vbool32_t done_mask = vmseq_vx_i32m1_b32(abs_vec, 0, vl);\n            if (vcpop_b32(done_mask) == vl) {\n                break;\n            }\n        }\n\n        // Check if sum of digits > 0\n        vbool32_t mask = vmgt_vx_i32m1_b32(sum_digits, 0, vl);\n        count += vcpop_b32(mask); // Count elements where condition is true\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_114_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <vector>\n\nint count_nums_simd(std::vector<int> n) {\n    size_t n_size = n.size();\n    if (n_size == 0) return 0;\n\n    int count = 0;\n    size_t vlmax = vsetvlmax_e32m1(); // Maximum vector length for 32-bit integers\n    size_t i = 0;\n\n    while (i < n_size) {\n        size_t vl = vsetvl_e32m1(n_size - i); // Set vector length based on remaining elements\n        vint32m1_t vec = vle32_v_i32m1(&n[i], vl); // Load vector of integers\n\n        vint32m1_t abs_vec = vabs_v_i32m1(vec, vl); // Compute absolute values\n        vint32m1_t sum_vec = vmv_v_x_i32m1(0, vl); // Initialize sum vector to 0\n\n        while (vfirst_m_b32(vmsne_vx_i32m1_b32(abs_vec, 0, vl), vl) != -1) {\n            vint32m1_t digit_vec = vrem_vx_i32m1(abs_vec, 10, vl); // Extract last digit\n            sum_vec = vadd_vv_i32m1(sum_vec, digit_vec, vl); // Add digit to sum\n            abs_vec = vdiv_vx_i32m1(abs_vec, 10, vl); // Remove last digit\n        }\n\n        vbool32_t mask = vmgt_vx_i32m1_b32(sum_vec, 0, vl); // Mask for sum > 0\n        count += vpopc_m_b32(mask, vl); // Count elements where sum > 0\n\n        i += vl; // Move to the next chunk\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_114_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <vector>\n\nint count_nums_simd(std::vector<int> n) {\n    size_t n_size = n.size();\n    if (n_size == 0) return 0;\n\n    int count = 0;\n    size_t vlmax = vsetvlmax_e32m1(); // Maximum vector length for 32-bit integers\n    size_t i = 0;\n\n    while (i < n_size) {\n        size_t vl = vsetvl_e32m1(n_size - i); // Set vector length based on remaining elements\n        vint32m1_t vec = vle32_v_i32m1(&n[i], vl); // Load vector of integers\n\n        vint32m1_t abs_vec = vabs_v_i32m1(vec, vl); // Take absolute value of each element\n        vint32m1_t sum_vec = vmv_v_x_i32m1(0, vl); // Initialize sum vector to 0\n\n        // Compute sum of digits for each number in the vector\n        while (true) {\n            vint32m1_t digit_vec = vrem_vx_i32m1(abs_vec, 10, vl); // Extract last digit\n            sum_vec = vadd_vv_i32m1(sum_vec, digit_vec, vl); // Add digit to sum\n            abs_vec = vdiv_vx_i32m1(abs_vec, 10, vl); // Remove last digit\n\n            vbool32_t done_mask = vmseq_vx_i32m1_b32(abs_vec, 0, vl); // Check if abs_vec == 0\n            if (vfirst_m_b32(done_mask, vl) >= 0) break; // Exit loop if all numbers are processed\n        }\n\n        // Check if sum of digits > 0\n        vbool32_t mask = vmsgt_vx_i32m1_b32(sum_vec, 0, vl);\n        count += vcpop_b32(mask); // Count active elements in the mask\n\n        i += vl; // Move to the next chunk of elements\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_115_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <algorithm>\n\nbool move_one_ball_simd(std::vector<int> arr) {\n    size_t N = arr.size();\n    if (N == 0) return true;\n\n    for (size_t shift = 0; shift < N; ++shift) {\n        // Create a shifted version of the array\n        std::vector<int> shifted(N);\n        for (size_t i = 0; i < N; ++i) {\n            shifted[i] = arr[(i + shift) % N];\n        }\n\n        // Check if the shifted array is sorted using RVV intrinsics\n        size_t vl = vsetvl_e32m1(N);\n        bool is_sorted = true;\n\n        for (size_t i = 0; i < N - 1; i += vl) {\n            vl = vsetvl_e32m1(N - i);\n            vint32m1_t v1 = vle32_v_i32m1(&shifted[i], vl);\n            vint32m1_t v2 = vle32_v_i32m1(&shifted[i + 1], vl - 1);\n\n            vbool32_t mask = vmseq_vv_i32m1_b32(vle32_v_i32m1(&shifted[i], vl - 1), v2, vl - 1);\n            if (vfirst_m_b32(mask, vl - 1) != -1) {\n                is_sorted = false;\n                break;\n            }\n        }\n\n        if (is_sorted) return true;\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_115_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <algorithm>\n\nbool move_one_ball_simd(std::vector<int> arr) {\n    size_t n = arr.size();\n    if (n == 0) return true;\n\n    for (size_t shift = 0; shift < n; ++shift) {\n        // Create a shifted version of the array\n        std::vector<int> shifted(n);\n        for (size_t i = 0; i < n; ++i) {\n            shifted[i] = arr[(i + shift) % n];\n        }\n\n        // Use RVV to check if the shifted array is sorted\n        size_t vl = vsetvl_e32m1(n);\n        vint32m1_t vec = vle32_v_i32m1(shifted.data(), vl);\n        vint32m1_t vec_next = vlse32_v_i32m1(shifted.data() + 1, sizeof(int), vl);\n\n        vbool32_t mask = vmseq_vv_i32m1_b32(vec, vec_next, vl);\n        if (vfirst_b32(mask) == -1) {\n            return true;\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_115_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <algorithm>\n\nbool move_one_ball_simd(std::vector<int> arr) {\n    size_t n = arr.size();\n    if (n == 0) return true;\n\n    for (size_t shift = 0; shift < n; ++shift) {\n        // Create a shifted vector\n        std::vector<int> shifted(n);\n        for (size_t i = 0; i < n; ++i) {\n            shifted[i] = arr[(i + shift) % n];\n        }\n\n        // Check if the shifted vector is sorted using RVV\n        size_t vl = vsetvl_e32m1(n);\n        bool is_sorted = true;\n        for (size_t i = 0; i < n - 1; i += vl) {\n            vl = vsetvl_e32m1(n - i);\n            vint32m1_t vec1 = vle32_v_i32m1(&shifted[i], vl);\n            vint32m1_t vec2 = vle32_v_i32m1(&shifted[i + 1], vl - 1);\n            vbool32_t mask = vmseq_vv_i32m1_b32(vec1, vec2, vl - 1);\n            if (vfirst_m_b32(mask, vl - 1) != -1) {\n                is_sorted = false;\n                break;\n            }\n        }\n\n        if (is_sorted) return true;\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_115_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <algorithm>\n\nbool move_one_ball_simd(std::vector<int> arr) {\n    size_t N = arr.size();\n    if (N == 0) return true;\n\n    for (size_t shift = 0; shift < N; ++shift) {\n        // Create a shifted version of the array\n        std::vector<int> shifted(N);\n        for (size_t i = 0; i < N; ++i) {\n            shifted[i] = arr[(i + shift) % N];\n        }\n\n        // Check if the shifted array is sorted using RVV intrinsics\n        size_t vl = vsetvl_e32m1(N);\n        bool is_sorted = true;\n\n        for (size_t i = 0; i < N - 1; i += vl) {\n            vl = vsetvl_e32m1(N - i);\n            vint32m1_t v1 = vle32_v_i32m1(&shifted[i], vl);\n            vint32m1_t v2 = vle32_v_i32m1(&shifted[i + 1], vl - 1);\n\n            vbool32_t mask = vmseq_vv_i32m1_b32(vle32_v_i32m1(&shifted[i], vl - 1), vle32_v_i32m1(&shifted[i + 1], vl - 1), vl - 1);\n            if (vfirst_m_b32(mask, vl - 1) != -1) {\n                is_sorted = false;\n                break;\n            }\n        }\n\n        if (is_sorted) return true;\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_115_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <algorithm>\n\nbool move_one_ball_simd(std::vector<int> arr) {\n    size_t n = arr.size();\n    if (n == 0) return true;\n\n    for (size_t shift = 0; shift < n; ++shift) {\n        // Create a shifted vector\n        std::vector<int> shifted(n);\n        for (size_t i = 0; i < n; ++i) {\n            shifted[i] = arr[(i + shift) % n];\n        }\n\n        // Check if the shifted vector is sorted using RVV\n        size_t vl = vsetvl_e32m1(n);\n        vint32m1_t vec = vle32_v_i32m1(shifted.data(), vl);\n\n        bool is_sorted = true;\n        for (size_t i = 0; i < n - 1; i += vl) {\n            size_t len = std::min(vl, n - i - 1);\n            vint32m1_t vec_next = vle32_v_i32m1(shifted.data() + i + 1, len);\n            vbool32_t mask = vmseq_vv_i32m1_b32(vec, vec_next, len);\n            if (vfirst_m_b32(mask) != -1) {\n                is_sorted = false;\n                break;\n            }\n            vec = vec_next;\n        }\n\n        if (is_sorted) return true;\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_116_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <string>\n\nstd::string myexchange_simd(const std::vector<int>& lst1, const std::vector<int>& lst2) {\n    size_t n1 = lst1.size();\n    size_t n2 = lst2.size();\n    size_t vlmax = vsetvlmax_e32m1();\n    \n    // Check if lst1 already contains only even numbers\n    size_t i = 0;\n    bool all_even = true;\n    while (i < n1) {\n        size_t vl = vsetvl_e32m1(n1 - i);\n        vint32m1_t vec = vle32_v_i32m1(&lst1[i], vl);\n        vbool32_t mask = vmseq_vx_i32m1_b32(vec, 0, vl);\n        vbool32_t even_mask = vmseq_vx_i32m1_b32(vand_vx_i32m1(vec, 1, vl), 0, vl);\n        if (!vfirst_m_b32(even_mask)) {\n            all_even = false;\n            break;\n        }\n        i += vl;\n    }\n    if (all_even) return \"YES\";\n\n    // Count odd numbers in lst1\n    size_t odd_count_lst1 = 0;\n    i = 0;\n    while (i < n1) {\n        size_t vl = vsetvl_e32m1(n1 - i);\n        vint32m1_t vec = vle32_v_i32m1(&lst1[i], vl);\n        vbool32_t odd_mask = vmseq_vx_i32m1_b32(vand_vx_i32m1(vec, 1, vl), 1, vl);\n        odd_count_lst1 += vpopc_m_b32(odd_mask);\n        i += vl;\n    }\n\n    // Count even numbers in lst2\n    size_t even_count_lst2 = 0;\n    i = 0;\n    while (i < n2) {\n        size_t vl = vsetvl_e32m1(n2 - i);\n        vint32m1_t vec = vle32_v_i32m1(&lst2[i], vl);\n        vbool32_t even_mask = vmseq_vx_i32m1_b32(vand_vx_i32m1(vec, 1, vl), 0, vl);\n        even_count_lst2 += vpopc_m_b32(even_mask);\n        i += vl;\n    }\n\n    // If there are enough even numbers in lst2 to replace all odd numbers in lst1, return \"YES\"\n    return (even_count_lst2 >= odd_count_lst1) ? \"YES\" : \"NO\";\n}\n```"}
{"task_id": "SimdBench_116_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <string>\n\nstd::string myexchange_simd(const std::vector<int>& lst1, const std::vector<int>& lst2) {\n    size_t n1 = lst1.size();\n    size_t n2 = lst2.size();\n\n    // Check if lst1 already contains only even numbers\n    size_t vl;\n    bool has_odd = false;\n    for (size_t i = 0; i < n1; i += vl) {\n        vl = vsetvl_e32m1(n1 - i);\n        vint32m1_t vec1 = vle32_v_i32m1(&lst1[i], vl);\n        vbool32_t odd_mask = vmseq_vx_i32m1_b32(vec1 & 1, 1, vl);\n        if (vfirst_m_b32(odd_mask, vl) != -1) {\n            has_odd = true;\n            break;\n        }\n    }\n    if (!has_odd) return \"YES\";\n\n    // Count even numbers in lst2\n    size_t even_count = 0;\n    for (size_t i = 0; i < n2; i += vl) {\n        vl = vsetvl_e32m1(n2 - i);\n        vint32m1_t vec2 = vle32_v_i32m1(&lst2[i], vl);\n        vbool32_t even_mask = vmseq_vx_i32m1_b32(vec2 & 1, 0, vl);\n        even_count += vcpop_m_b32(even_mask, vl);\n    }\n\n    // Count odd numbers in lst1\n    size_t odd_count = 0;\n    for (size_t i = 0; i < n1; i += vl) {\n        vl = vsetvl_e32m1(n1 - i);\n        vint32m1_t vec1 = vle32_v_i32m1(&lst1[i], vl);\n        vbool32_t odd_mask = vmseq_vx_i32m1_b32(vec1 & 1, 1, vl);\n        odd_count += vcpop_m_b32(odd_mask, vl);\n    }\n\n    // Check if lst2 has enough even numbers to replace all odd numbers in lst1\n    return (even_count >= odd_count) ? \"YES\" : \"NO\";\n}\n```"}
{"task_id": "SimdBench_116_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <string>\n\nstd::string myexchange_simd(const std::vector<int>& lst1, const std::vector<int>& lst2) {\n    size_t n1 = lst1.size();\n    size_t n2 = lst2.size();\n\n    // Check if lst1 already contains only even numbers\n    size_t vl;\n    for (size_t i = 0; i < n1; i += vl) {\n        vl = vsetvl_e32m1(n1 - i);\n        vint32m1_t vec1 = vle32_v_i32m1(&lst1[i], vl);\n        vbool32_t odd_mask = vmseq_vx_i32m1_b32(vec1, 1, vl); // Check if lst1[i] % 2 != 0\n        if (vfirst_m_b32(odd_mask, vl) != -1) {\n            break;\n        }\n        if (i + vl >= n1) {\n            return \"YES\";\n        }\n    }\n\n    // Count even numbers in lst2\n    size_t even_count = 0;\n    for (size_t i = 0; i < n2; i += vl) {\n        vl = vsetvl_e32m1(n2 - i);\n        vint32m1_t vec2 = vle32_v_i32m1(&lst2[i], vl);\n        vbool32_t even_mask = vmseq_vx_i32m1_b32(vec2, 0, vl);\n        even_count += vpopc_m_b32(even_mask, vl);\n    }\n\n    // Count odd numbers in lst1\n    size_t odd_count = 0;\n    for (size_t i = 0; i < n1; i += vl) {\n        vl = vsetvl_e32m1(n1 - i);\n        vint32m1_t vec1 = vle32_v_i32m1(&lst1[i], vl);\n        vbool32_t odd_mask = vmseq_vx_i32m1_b32(vec1, 1, vl);\n        odd_count += vpopc_m_b32(odd_mask, vl);\n    }\n\n    // If there are enough even numbers in lst2 to replace all odd numbers in lst1, return \"YES\"\n    return (even_count >= odd_count) ? \"YES\" : \"NO\";\n}\n```"}
{"task_id": "SimdBench_116_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <string>\n\nstd::string myexchange_simd(const std::vector<int>& lst1, const std::vector<int>& lst2) {\n    size_t n1 = lst1.size();\n    size_t n2 = lst2.size();\n\n    // Check if all elements in lst1 are already even\n    size_t vl = vsetvl_e32m1(n1);\n    vint32m1_t vec1 = vle32_v_i32m1(lst1.data(), vl);\n    vbool32_t mask_even1 = vmseq_vx_i32m1_b32(vec1 & 1, 0, vl);\n    if (vcpop_b32(mask_even1) == n1) {\n        return \"YES\";\n    }\n\n    // Load lst2 into vector registers\n    vl = vsetvl_e32m1(n2);\n    vint32m1_t vec2 = vle32_v_i32m1(lst2.data(), vl);\n    vbool32_t mask_even2 = vmseq_vx_i32m1_b32(vec2 & 1, 0, vl);\n\n    // Count the number of even numbers in lst2\n    size_t even_count_lst2 = vcpop_b32(mask_even2);\n\n    // Count the number of odd numbers in lst1\n    vl = vsetvl_e32m1(n1);\n    vbool32_t mask_odd1 = vmseq_vx_i32m1_b32(vec1 & 1, 1, vl);\n    size_t odd_count_lst1 = vcpop_b32(mask_odd1);\n\n    // If lst2 has enough even numbers to replace all odd numbers in lst1, return \"YES\"\n    if (even_count_lst2 >= odd_count_lst1) {\n        return \"YES\";\n    }\n\n    return \"NO\";\n}\n```"}
{"task_id": "SimdBench_116_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <string>\n\nstd::string myexchange_simd(const std::vector<int>& lst1, const std::vector<int>& lst2) {\n    size_t n1 = lst1.size();\n    size_t n2 = lst2.size();\n\n    // Check if lst1 already contains only even numbers\n    size_t vlmax = vsetvlmax_e32m1();\n    for (size_t i = 0; i < n1; i += vlmax) {\n        size_t vl = vsetvl_e32m1(n1 - i);\n        vint32m1_t vec1 = vle32_v_i32m1(&lst1[i], vl);\n        vbool32_t even_mask = vmseq_vx_i32m1_b32(vec1 & 1, 0, vl);\n        if (!vcpop_b32(even_mask)) {\n            break;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_117_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <string>\n\nstd::vector<std::string> odd_count_simd(const std::vector<std::string> & lst) {\n    std::vector<std::string> result;\n    for (const auto& str : lst) {\n        size_t len = str.size();\n        std::vector<uint8_t> digits(len);\n        for (size_t i = 0; i < len; ++i) {\n            digits[i] = str[i] - '0';\n        }\n\n        size_t vl = vsetvl_e8m1(len);\n        vint8m1_t vec_digits = vle8_v_i8m1(digits.data(), vl);\n        vint8m1_t vec_odd_mask = vmseq_vx_i8m1(vec_digits, 1, vl) |\n                                 vmseq_vx_i8m1(vec_digits, 3, vl) |\n                                 vmseq_vx_i8m1(vec_digits, 5, vl) |\n                                 vmseq_vx_i8m1(vec_digits, 7, vl) |\n                                 vmseq_vx_i8m1(vec_digits, 9, vl);\n\n        uint8_t odd_count = vpopc_m_b8(vec_odd_mask, vl);\n\n        std::string output = \"the number of odd elements \" + std::to_string(odd_count) +\n                             \"n the str\" + std::to_string(odd_count) +\n                             \"ng \" + std::to_string(odd_count) + \" of the \" +\n                             std::to_string(odd_count) + \"nput.\";\n        result.push_back(output);\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_117_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <string>\n#include <sstream>\n\nstd::vector<std::string> odd_count_simd(const std::vector<std::string> & lst) {\n    std::vector<std::string> result;\n    for (const auto &str : lst) {\n        size_t len = str.size();\n        std::vector<uint8_t> digits(len);\n        for (size_t i = 0; i < len; ++i) {\n            digits[i] = str[i] - '0';\n        }\n\n        size_t odd_count = 0;\n        size_t vlmax = vsetvlmax_e8m1();\n        size_t processed = 0;\n\n        while (processed < len) {\n            size_t vl = vsetvl_e8m1(len - processed);\n            vint8m1_t vec_digits = vle8_v_i8m1(&digits[processed], vl);\n            vint8m1_t vec_odd_mask = vand_vx_i8m1(vec_digits, 1, vl);\n            vint8m1_t vec_is_odd = vmseq_vx_i8m1(vec_odd_mask, 1, vl);\n            odd_count += vcpop_m_b8(vmslt_vx_i8m1(vec_is_odd, 0, vl));\n            processed += vl;\n        }\n\n        std::ostringstream oss;\n        oss << \"the number of odd elements \" << odd_count << \"n the str\" << odd_count << \"ng \" << odd_count << \" of the \" << odd_count << \"nput.\";\n        result.push_back(oss.str());\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_117_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <string>\n\nstd::vector<std::string> odd_count_simd(const std::vector<std::string> & lst) {\n    std::vector<std::string> result;\n    for (const auto& str : lst) {\n        size_t len = str.size();\n        std::vector<uint8_t> digits(len);\n        for (size_t i = 0; i < len; ++i) {\n            digits[i] = str[i] - '0';\n        }\n\n        size_t odd_count = 0;\n        size_t vl = 0;\n        size_t start = 0;\n\n        while (start < len) {\n            vl = vsetvl_e8m1(len - start);\n            vint8m1_t vec = vle8_v_i8m1(&digits[start], vl);\n            vint8m1_t odd_mask = vmseq_vx_i8m1(vec, 1, vl) |\n                                 vmseq_vx_i8m1(vec, 3, vl) |\n                                 vmseq_vx_i8m1(vec, 5, vl) |\n                                 vmseq_vx_i8m1(vec, 7, vl) |\n                                 vmseq_vx_i8m1(vec, 9, vl);\n            odd_count += vpopc_m_b8(vmslt_vx_i8m1(odd_mask, 1, vl), vl);\n            start += vl;\n        }\n\n        std::string odd_count_str = std::to_string(odd_count);\n        std::string output = \"the number of odd elements \" + odd_count_str + \"n the str\" + odd_count_str + \"ng \" + odd_count_str + \" of the \" + odd_count_str + \"nput.\";\n        result.push_back(output);\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_117_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <string>\n\nstd::vector<std::string> odd_count_simd(const std::vector<std::string> & lst) {\n    std::vector<std::string> result(lst.size());\n    for (size_t i = 0; i < lst.size(); ++i) {\n        const std::string &str = lst[i];\n        size_t len = str.size();\n        std::vector<uint8_t> digits(len);\n\n        // Convert string to vector of digits\n        for (size_t j = 0; j < len; ++j) {\n            digits[j] = str[j] - '0';\n        }\n\n        // Process digits using RVV intrinsics\n        size_t vl = vsetvl_e8m1(len);\n        vint8m1_t vec_digits = vle8_v_i8m1(digits.data(), vl);\n        vint8m1_t odd_mask = vmseq_vx_i8m1(vec_digits, 1, vl); // Check if digit is odd\n        vint8m1_t odd_mask2 = vmseq_vx_i8m1(vec_digits, 3, vl);\n        vint8m1_t odd_mask3 = vmseq_vx_i8m1(vec_digits, 5, vl);\n        vint8m1_t odd_mask4 = vmseq_vx_i8m1(vec_digits, 7, vl);\n"}
{"task_id": "SimdBench_117_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <string>\n\nstd::vector<std::string> odd_count_simd(const std::vector<std::string> & lst) {\n    std::vector<std::string> result;\n    std::string template_str = \"the number of odd elements Xn the strXng X of the Xnput.\";\n\n    for (size_t i = 0; i < lst.size(); ++i) {\n        const std::string &str = lst[i];\n        size_t n = str.size();\n\n        // Prepare RVV vector processing\n        size_t vl;\n        size_t odd_count = 0;\n        for (size_t start = 0; start < n; start += vl) {\n            vl = vsetvl_e8m1(n - start); // Set vector length for 8-bit elements\n            vint8m1_t vec = vle8_v_i8m1((const int8_t *)(str.data() + start), vl);\n\n            // Check if each character is an odd digit\n            vint8m1_t digit_vec = vsub_vx_i8m1(vec, '0', vl); // Convert char to digit\n            vbool8_t is_digit = vmseq_vx_i8m1_b8(vec, '0', vl) | vmsle_vx_i8m1_b8(vec, '9', vl);\n            vbool8_t is_odd = vmseq_vx_i8m1_b8(vand_vx_i8m1(digit_vec, 1, vl), 1, vl);\n\n            // Combine conditions: valid digit and odd\n            vbool8_t valid_odd = vmand_mm_b8(is_digit, is_odd, vl);\n\n            // Count odd digits\n            odd_count += vpopc_m_b8(valid_odd, vl);\n        }\n\n        // Replace 'X' in the template string with the odd count\n        std::string output = template_str;\n        for (char &c : output) {\n            if (c == 'X') {\n                c = '0' + odd_count;\n            }\n        }\n        result.push_back(output);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_118_RVV", "completion": "```c++\n#include <riscv_vector.h>\n#include <vector>\n#include <limits>\n\nint64_t minSubArraySum_simd(const std::vector<int64_t>& nums) {\n    size_t n = nums.size();\n    if (n == 0) return 0;\n\n    size_t vlmax = vsetvlmax_e64m1(); // Maximum vector length for 64-bit elements\n    int64_t global_min = std::numeric_limits<int64_t>::max();\n\n    for (size_t i = 0; i < n; i += vlmax) {\n        size_t vl = vsetvl_e64m1(n - i); // Set vector length for the remaining elements\n        vint64m1_t vnums = vle64_v_i64m1(&nums[i], vl);\n\n        vint64m1_t vcurrent_sum = vnums;\n        vint64m1_t vmin_sum = vnums;\n\n        for (size_t j = 1; j < vl; ++j) {\n            vcurrent_sum = vadd_vv_i64m1(vcurrent_sum, vslide1down_vx_i64m1(vnums, 0, vl));\n            vmin_sum = vmin_vv_i64m1(vmin_sum, vcurrent_sum, vl);\n        }\n\n        int64_t local_min[vlmax];\n        vse64_v_i64m1(local_min, vmin_sum, vl);\n\n        for (size_t k = 0; k < vl; ++k) {\n            if (local_min[k] < global_min) {\n                global_min = local_min[k];\n            }\n        }\n    }\n\n    return global_min;\n}\n```"}
{"task_id": "SimdBench_118_RVV", "completion": "```c++\n#include <riscv_vector.h>\n#include <vector>\n#include <cstdint>\n#include <limits>\n\nint64_t minSubArraySum_simd(const std::vector<int64_t>& nums) {\n    size_t n = nums.size();\n    if (n == 0) return 0;\n\n    size_t vlmax = vsetvlmax_e64m1(); // Maximum vector length for 64-bit integers\n    int64_t global_min = std::numeric_limits<int64_t>::max();\n\n    for (size_t i = 0; i < n; i += vlmax) {\n        size_t vl = vsetvl_e64m1(n - i); // Set vector length based on remaining elements\n        vint64m1_t vec_nums = vle64_v_i64m1(&nums[i], vl); // Load vector of nums\n        vint64m1_t vec_min = vec_nums; // Initialize vector of minimums\n        vint64m1_t vec_sum = vec_nums; // Initialize vector of sums\n\n        for (size_t j = 1; j < n - i; j++) {\n            if (j >= vl) break;\n            vec_nums = vle64_v_i64m1(&nums[i + j], vl); // Load next vector\n            vec_sum = vadd_vv_i64m1(vec_sum, vec_nums, vl); // Update running sum\n            vec_min = vmin_vv_i64m1(vec_min, vec_sum, vl); // Update minimums\n        }\n\n        int64_t local_min[vlmax];\n        vse64_v_i64m1(local_min, vec_min, vl); // Store vector minimums to array\n\n        for (size_t k = 0; k < vl; k++) {\n            if (local_min[k] < global_min) {\n                global_min = local_min[k];\n            }\n        }\n    }\n\n    return global_min;\n}\n```"}
{"task_id": "SimdBench_118_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <cstdint>\n#include <limits>\n\nint64_t minSubArraySum_simd(const std::vector<int64_t>& nums) {\n    size_t n = nums.size();\n    if (n == 0) return 0;\n\n    size_t vlmax = vsetvlmax_e64m1();\n    int64_t global_min = std::numeric_limits<int64_t>::max();\n\n    for (size_t i = 0; i < n; i += vlmax) {\n        size_t vl = vsetvl_e64m1(n - i);\n        vint64m1_t vec_nums = vle64_v_i64m1(&nums[i], vl);\n\n        vint64m1_t vec_min = vec_nums;\n        vint64m1_t vec_curr_sum = vec_nums;\n\n        for (size_t j = 1; j < vl; ++j) {\n            vec_curr_sum = vadd_vv_i64m1(vec_curr_sum, vec_nums, vl);\n            vec_min = vmin_vv_i64m1(vec_min, vec_curr_sum, vl);\n        }\n\n        int64_t local_min[vl];\n        vse64_v_i64m1(local_min, vec_min, vl);\n\n        for (size_t j = 0; j < vl; ++j) {\n            global_min = std::min(global_min, local_min[j]);\n        }\n    }\n\n    return global_min;\n}\n```"}
{"task_id": "SimdBench_118_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <cstdint>\n#include <limits>\n\nint64_t minSubArraySum_simd(const std::vector<int64_t>& nums) {\n    size_t n = nums.size();\n    if (n == 0) return 0;\n\n    size_t vlmax = vsetvlmax_e64m1();\n    int64_t global_min = std::numeric_limits<int64_t>::max();\n\n    for (size_t i = 0; i < n; i += vlmax) {\n        size_t vl = vsetvl_e64m1(n - i);\n        vint64m1_t vec_nums = vle64_v_i64m1(&nums[i], vl);\n\n        vint64m1_t vec_min_sum = vec_nums;\n        vint64m1_t vec_current_sum = vec_nums;\n\n        for (size_t j = 1; j < vl; ++j) {\n            vint64m1_t shifted_vec = vslide1down_vx_i64m1(vec_current_sum, 0, vl);\n            vec_current_sum = vadd_vv_i64m1(vec_nums, shifted_vec, vl);\n            vec_min_sum = vmin_vv_i64m1(vec_min_sum, vec_current_sum, vl);\n        }\n\n        int64_t local_min[vlmax];\n        vse64_v_i64m1(local_min, vec_min_sum, vl);\n\n        for (size_t k = 0; k < vl; ++k) {\n            global_min = std::min(global_min, local_min[k]);\n        }\n    }\n\n    return global_min;\n}\n```"}
{"task_id": "SimdBench_118_RVV", "completion": "```c++\n#include <riscv_vector.h>\n#include <vector>\n#include <cstdint>\n#include <limits>\n\nint64_t minSubArraySum_simd(const std::vector<int64_t>& nums) {\n    size_t n = nums.size();\n    if (n == 0) return 0;\n\n    size_t vlmax = vsetvlmax_e64m1();\n    int64_t global_min = std::numeric_limits<int64_t>::max();\n\n    for (size_t i = 0; i < n; i += vlmax) {\n        size_t vl = vsetvl_e64m1(n - i);\n\n        vint64m1_t vnums = vle64_v_i64m1(&nums[i], vl);\n        vint64m1_t vcurrent_sum = vnums;\n        vint64m1_t vmin_sum = vnums;\n\n        for (size_t j = i + vl; j < n; j += vl) {\n            size_t vl_inner = vsetvl_e64m1(n - j);\n            vint64m1_t vnext = vle64_v_i64m1(&nums[j], vl_inner);\n\n            vcurrent_sum = vadd_vv_i64m1(vcurrent_sum, vnext, vl_inner);\n            vmin_sum = vmin_vv_i64m1(vmin_sum, vcurrent_sum, vl_inner);\n        }\n\n        int64_t local_min[vlmax];\n        vse64_v_i64m1(local_min, vmin_sum, vl);\n\n        for (size_t k = 0; k < vl; k++) {\n            if (local_min[k] < global_min) {\n                global_min = local_min[k];\n            }\n        }\n    }\n\n    return global_min;\n}\n```"}
{"task_id": "SimdBench_119_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nint max_fill_simd(const std::vector<std::vector<int>> &grid, int capacity) {\n    int total_operations = 0;\n\n    for (const auto &row : grid) {\n        size_t n = row.size();\n        int row_operations = 0;\n\n        size_t vl;\n        size_t i = 0;\n        while (i < n) {\n            vl = vsetvl_e32m8(n - i); // Set vector length\n            vint32m8_t vec_row = vle32_v_i32m8(&row[i], vl); // Load row data into vector\n            vint32m8_t vec_sum = vmv_v_x_i32m8(0, vl); // Initialize sum vector to 0\n\n            // Count the number of 1s in the vector\n            vbool4_t mask = vmseq_vx_i32m8_b4(vec_row, 1, vl);\n            vec_sum = vadd_vv_i32m8_m(mask, vec_sum, vec_sum, vec_row, vl);\n\n            // Sum up the vector elements\n            int sum = 0;\n            int temp[vl];\n            vse32_v_i32m8(temp, vec_sum, vl);\n            for (size_t j = 0; j < vl; j++) {\n                sum += temp[j];\n            }\n\n            row_operations += (sum + capacity - 1) / capacity; // Calculate bucket operations\n            i += vl;\n        }\n\n        total_operations += row_operations;\n    }\n\n    return total_operations;\n}\n```"}
{"task_id": "SimdBench_119_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nint max_fill_simd(const std::vector<std::vector<int>> &grid, int capacity) {\n    int total_operations = 0;\n\n    for (const auto &row : grid) {\n        size_t n = row.size();\n        int row_operations = 0;\n\n        size_t vl;\n        size_t i = 0;\n\n        while (i < n) {\n            vl = vsetvl_e32m1(n - i); // Set vector length\n            vint32m1_t vdata = vle32_v_i32m1(&row[i], vl); // Load data from row\n            vint32m1_t vsum = vmv_v_x_i32m1(0, vl); // Initialize sum vector\n\n            // Count the number of 1s in the vector\n            vsum = vredsum_vs_i32m1_i32m1(vsum, vdata, vsum, vl);\n\n            int sum = vmv_x_s_i32m1_i32(vsum); // Extract the scalar sum\n            row_operations += sum;\n\n            i += vl; // Move to the next vector segment\n        }\n\n        total_operations += (row_operations + capacity - 1) / capacity; // Calculate bucket operations\n    }\n\n    return total_operations;\n}\n```"}
{"task_id": "SimdBench_119_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nint max_fill_simd(const std::vector<std::vector<int>> &grid, int capacity) {\n    int total_operations = 0;\n\n    for (const auto &row : grid) {\n        size_t n = row.size();\n        size_t vl;\n        int row_sum = 0;\n\n        for (size_t i = 0; i < n; i += vl) {\n            vl = vsetvl_e32m1(n - i); // Set vector length based on remaining elements\n            vint32m1_t v_row = vle32_v_i32m1(&row[i], vl); // Load elements into vector\n            vint32m1_t v_sum = vslide1down_vx_i32m1(v_row, 0, vl); // Sum elements in vector\n            row_sum += vcpop_m_b32(v_row); // Count number of 1s in the vector\n        }\n\n        total_operations += (row_sum + capacity - 1) / capacity; // Calculate bucket operations\n    }\n\n    return total_operations;\n}\n```"}
{"task_id": "SimdBench_119_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nint max_fill_simd(const std::vector<std::vector<int>> &grid, int capacity) {\n    int total_operations = 0;\n\n    for (const auto &row : grid) {\n        size_t n = row.size();\n        size_t i = 0;\n        int row_sum = 0;\n\n        while (i < n) {\n            size_t vl = vsetvl_e32m8(n - i);\n            vint32m8_t v_row = vle32_v_i32m8(&row[i], vl);\n            vint32m8_t v_sum = vredsum_vs_i32m8_i32m1(vundefined_i32m1(), v_row, vundefined_i32m1(), vl);\n            row_sum += vmv_x_s_i32m1_i32(v_sum);\n            i += vl;\n        }\n\n        total_operations += (row_sum + capacity - 1) / capacity;\n    }\n\n    return total_operations;\n}\n```"}
{"task_id": "SimdBench_119_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nint max_fill_simd(const std::vector<std::vector<int>> &grid, int capacity) {\n    int total_operations = 0;\n\n    for (const auto &row : grid) {\n        size_t n = row.size();\n        int row_operations = 0;\n\n        size_t vl;\n        size_t i = 0;\n        while (i < n) {\n            vl = vsetvl_e32m1(n - i); // Set vector length\n            vint32m1_t vdata = vle32_v_i32m1(&row[i], vl); // Load data from the row\n            vint32m1_t vcount = vmv_v_x_i32m1(0, vl); // Initialize count vector to 0\n\n            // Count the number of 1s in the vector\n            vbool32_t mask = vmseq_vx_i32m1_b32(vdata, 1, vl);\n            vcount = vadd_vx_i32m1_m(mask, vcount, vcount, 1, vl);\n\n            // Sum the vector counts\n            int sum = vredsum_vs_i32m1_i32(vcount, vcount, 0, vl);\n\n            row_operations += sum;\n            i += vl;\n        }\n\n        total_operations += (row_operations + capacity - 1) / capacity; // Calculate bucket operations\n    }\n\n    return total_operations;\n}\n```"}
{"task_id": "SimdBench_120_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nint64_t solution_simd(const std::vector<int16_t>& lst) {\n    size_t n = lst.size();\n    if (n == 0) return 0;\n\n    const size_t vlmax = vsetvlmax_e16m1(); // Maximum vector length for 16-bit integers\n    int64_t sum = 0;\n\n    for (size_t i = 0; i < n; i += vlmax) {\n        size_t vl = vsetvl_e16m1(n - i); // Set vector length based on remaining elements\n        vint16m1_t vec = vle16_v_i16m1(&lst[i], vl); // Load vector from lst\n\n        // Create a mask for even positions\n        vbool16_t even_pos_mask = vmseq_vx_i16m1_b16(vslide1down_vx_i16m1(vec, 0, vl), 0, vl);\n\n        // Create a mask for odd elements\n        vbool16_t odd_mask = vmand_mm_b16(vmsne_vx_i16m1_b16(vec, 0, vl), even_pos_mask);\n\n        // Apply the mask and sum the odd elements in even positions\n        vint16m1_t filtered_vec = vmerge_vvm_i16m1(vec, odd_mask, vl);\n        sum += vredsum_vs_i16m1_i64(filtered_vec, 0, vl);\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_120_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <cstdint>\n\nint64_t solution_simd(const std::vector<int16_t>& lst) {\n    size_t n = lst.size();\n    int64_t sum = 0;\n\n    size_t vl;\n    size_t i = 0;\n\n    vint16m1_t vec_data;\n    vint16m1_t vec_indices;\n    vint16m1_t vec_masked_data;\n    vbool16_t vec_mask_odd;\n    vbool16_t vec_mask_even_positions;\n\n    vint16m1_t vec_zeros = vmv_v_x_i16m1(0, vsetvlmax_e16m1());\n\n    while (i < n) {\n        vl = vsetvlmax_e16m1();\n        vec_data = vlseg2e16_v_i16m1(lst.data() + i, vl);\n        vec_indices = vlseg2e16_v_i16m1(lst.data() + i, vl);\n        vec_masked_data = vlseg2e16_v_i16m1(lst.data() + i, vl);\n        vec_mask_odd = vlseg2e16_v_i16m1(lst.data() + i, vl);\n        vec_mask_even_positions = vlseg2e16_v_i16m1(lst.data() + i, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_120_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <cstdint>\n\nint64_t solution_simd(const std::vector<int16_t>& lst) {\n    size_t n = lst.size();\n    if (n == 0) return 0;\n\n    const int16_t* data = lst.data();\n    size_t vl;\n    int64_t sum = 0;\n\n    for (size_t i = 0; i < n; i += vl) {\n        vl = vsetvl_e16m1(n - i); // Set vector length for 16-bit elements\n        vbool16_t even_mask = vmsne_vi_b16m1(vand_vi_i16m1(vle16_v_i16m1(data + i, vl), 1, vl), 1, vl); // Mask for even positions\n        vbool16_t odd_mask = vmseq_vi_b16m1(vand_vi_i16m1(vle16_v_i16m1(data + i, vl), 1, vl), 0, vl); // Mask for odd positions\n        sum+=``\n    }\n}\n```"}
{"task_id": "SimdBench_120_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <cstdint>\n\nint64_t solution_simd(const std::vector<int16_t>& lst) {\n    size_t n = lst.size();\n    if (n == 0) return 0;\n\n    const int16_t* data = lst.data();\n    size_t vlmax = vsetvlmax_e16m1();\n    int64_t sum = 0;\n\n    for (size_t i = 0; i < n; i += vlmax) {\n        size_t vl = vsetvl_e16m1(n - i);\n\n        vuint16m1_t indices = vid_v_u16m1(vl);\n        vuint16m1_t even_positions = vmul_vx_u16m1(indices, 2, vl);\n        vbool16_t mask = vmsltu_vx_u16m1_b16(even_positions, n, vl);\n\n        vint16m1_t vec = vle16_v_i16m1(data + i, vl);\n        vint16m1_t filtered_vec = vcompress_vm_i16m1(mask, vec, vl);\n\n        vbool16_t odd_mask = vmsne_vx_i16m1_b16(filtered_vec, 0, vl);\n        vint16m1_t odd_values = vcompress_vm_i16m1(odd_mask, filtered_vec, vl);\n\n        sum += vredsum_vs_i16m1_i64(vundefined_i64m1(), odd_values, vl);\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_120_RVV", "completion": "```c++\n#include <riscv_vector.h>\n#include <vector>\n#include <cstdint>\n\nint64_t solution_simd(const std::vector<int16_t>& lst) {\n    size_t n = lst.size();\n    if (n == 0) return 0;\n\n    const int16_t* data = lst.data();\n    size_t vl;\n    int64_t sum = 0;\n\n    for (size_t i = 0; i < n; i += vl) {\n        vl = vsetvl_e16m1(n - i); // Set vector length for 16-bit elements\n        vuint16m1_t indices = vid_v_u16m1(vl); // Generate indices [0, 1, 2, ...]\n        vuint16m1_t even_mask = vmseq_vx_u16m1_b16(indices, 0, vl); // Mask for even positions (i % 2 == 0)\n        even_mask = vmandnot_vv_u16m1_b16(even_mask, vmsne_vx_u16m1_b16(data, 0, vl)); // Filter odd positions\n    }\n}\n```"}
{"task_id": "SimdBench_121_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <vector>\n\nint add_elements_simd(std::vector<int> arr, int k) {\n    size_t n = arr.size();\n    if (n == 0 || k <= 0) return 0;\n\n    size_t vlmax = vsetvlmax_e32m1(); // Maximum vector length for 32-bit integers\n    int sum = 0;\n    size_t i = 0;\n\n    while (i < k) {\n        size_t vl = vsetvl_e32m1(k - i); // Set vector length based on remaining elements\n        vint32m1_t vec = vle32_v_i32m1(&arr[i], vl); // Load vector elements\n        vint32m1_t mask = vmseq_vx_i32m1_b32(vec / 100, 0, vl); // Mask for elements with at most two digits\n        vint32m1_t filtered = vmul_vv_i32m1_m(mask, vec, vec, vl); // Apply mask to keep valid elements\n        sum += vredsum_vs_i32m1_i32m1(vundefined_i32m1(), filtered, vundefined_i32m1(), vl); // Reduce sum\n        i += vl;\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_121_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <vector>\n\nint add_elements_simd(std::vector<int> arr, int k) {\n    size_t n = arr.size();\n    size_t vlmax = vsetvlmax_e32m1(); // Maximum vector length for 32-bit integers\n    int sum = 0;\n    size_t i = 0;\n\n    while (i < k) {\n        size_t vl = vsetvl_e32m1(k - i); // Set vector length based on remaining elements\n        vint32m1_t vec = vle32_v_i32m1(&arr[i], vl); // Load vector elements\n        vint32m1_t mask = vmseq_vx_i32m1_b32(vec / 100, 0, vl); // Mask for elements with at most two digits\n        vint32m1_t filtered = vmul_vv_i32m1_m(mask, vec, vec, vl); // Apply mask to keep valid elements\n        sum += vredsum_vs_i32m1_i32m1(vundefined_i32m1(), filtered, vundefined_i32m1(), vl); // Reduce sum\n        i += vl;\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_121_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <vector>\n\nint add_elements_simd(std::vector<int> arr, int k) {\n    size_t n = arr.size();\n    int sum = 0;\n    size_t vl;\n    size_t i = 0;\n\n    while (i < k) {\n        vl = vsetvl_e32m8(k - i); // Set vector length based on remaining elements\n        vint32m8_t vec = vle32_v_i32m8(&arr[i], vl); // Load elements into vector\n        vint32m8_t mask = vmseq_vx_i32m8(vec / 100, 0, vl); // Mask for two-digit numbers\n        vint32m8_t filtered = vmul_vv_i32m8(vec, mask, vl); // Apply mask to filter values\n        sum += vredsum_vs_i32m8_i32m1(vundefined_i32m1(), filtered, vundefined_i32m1(), vl); // Reduce sum\n        i += vl;\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_121_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <vector>\n\nint add_elements_simd(std::vector<int> arr, int k) {\n    size_t n = arr.size();\n    int sum = 0;\n    size_t vl;\n    size_t i = 0;\n\n    while (i < k) {\n        vl = vsetvl_e32m8(k - i); // Set vector length based on remaining elements\n        vint32m8_t vec = vle32_v_i32m8(&arr[i], vl); // Load elements into vector\n        vint32m8_t mask = vmseq_vx_i32m8(vec / 100, 0, vl); // Check if element has at most two digits\n        vint32m8_t filtered = vmul_vv_i32m8(vec, mask, vl); // Apply mask to filter elements\n        sum += vredsum_vs_i32m8_i32m1(vundefined_i32m1(), filtered, vundefined_i32m1(), vl); // Reduce sum\n        i += vl;\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_121_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <vector>\n\nint add_elements_simd(std::vector<int> arr, int k) {\n    size_t n = arr.size();\n    int sum = 0;\n    size_t i = 0;\n\n    // Process elements in chunks using RVV\n    while (i < k) {\n        size_t vl = vsetvl_e32m1(k - i); // Set vector length\n        vint32m1_t vec = vle32_v_i32m1(&arr[i], vl); // Load vector elements\n        vint32m1_t mask = vmseq_vx_i32m1(vec, vec, vl); // Dummy mask for initialization\n\n        // Mask for two-digit numbers (10 <= abs(x) <= 99)\n        mask = vmand_mm_b32(\n            vmge_vx_i32m1_b32(vec, 10, vl), // vec >= 10\n            vmle_vx_i32m1_b32(vec, 99, vl), // vec <= 99\n        )\n    }\n}\n```"}
{"task_id": "SimdBench_122_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <cstdint>\n\nbool is_sorted_simd(const std::vector<int> & lst) {\n    size_t n = lst.size();\n    if (n <= 1) return true;\n\n    size_t vlmax = vsetvlmax_e32m1();\n    size_t i = 0;\n\n    while (i < n - 1) {\n        size_t vl = vsetvl_e32m1(n - i);\n        vint32m1_t vec1 = vle32_v_i32m1(&lst[i], vl);\n        vint32m1_t vec2 = vle32_v_i32m1(&lst[i + 1], vl);\n\n        vbool32_t mask_asc = vmseq_vv_i32m1_b32(vec1, vec2, vl);\n        vbool32_t mask_gt = vmsgt_vv_i32m1_b32(vec1, vec2, vl);\n\n        if (vfirst_b32(mask_gt) >= 0 || vpopc_b32(mask_asc, vl) > 1) {\n            return false;\n        }\n\n        i += vl;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_122_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nbool is_sorted_simd(const std::vector<int> &lst) {\n    size_t n = lst.size();\n    if (n <= 1) return true;\n\n    size_t vlmax = vsetvlmax_e32m1();\n    size_t i = 0;\n\n    while (i < n - 1) {\n        size_t vl = vsetvl_e32m1(n - 1 - i);\n        vint32m1_t current = vle32_v_i32m1(&lst[i], vl);\n        vint32m1_t next = vle32_v_i32m1(&lst[i + 1], vl);\n\n        vbool32_t is_not_ascending = vmseq_vv_i32m1_b32(current, next, vl);\n        if (vfirst_m_b32(is_not_ascending, vl) != -1) {\n            return false;\n        }\n\n        vbool32_t is_greater = vmsgt_vv_i32m1_b32(current, next, vl);\n        if (vfirst_m_b32(is_greater, vl) != -1) {\n            return false;\n        }\n\n        i += vl;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_122_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <cstdint>\n\nbool is_sorted_simd(const std::vector<int> &lst) {\n    size_t n = lst.size();\n    if (n <= 1) return true;\n\n    size_t vlmax = vsetvlmax_e32m1();\n    size_t i = 0;\n\n    while (i < n - 1) {\n        size_t vl = vsetvl(n - 1 - i, e32, m1);\n        vint32m1_t current = vle32_v_i32m1(&lst[i], vl);\n        vint32m1_t next = vle32_v_i32m1(&lst[i + 1], vl);\n\n        vbool32_t is_less_equal = vmseq_vv_i32m1_b32(current, next, vl);\n        vbool32_t is_greater = vmsgt_vv_i32m1_b32(current, next, vl);\n\n        if (vfirst_m_b32(is_greater, vl) != -1 || vfirst_m_b32(is_less_equal, vl) != -1) {\n            return false;\n        }\n\n        i += vl;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_122_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <cstdint>\n\nbool is_sorted_simd(const std::vector<int> &lst) {\n    size_t n = lst.size();\n    if (n <= 1) return true;\n\n    size_t vlmax = vsetvlmax_e32m1(); // Maximum vector length for 32-bit integers\n    size_t i = 0;\n\n    while (i < n - 1) {\n        size_t vl = vsetvl_e32m1(n - i - 1); // Set vector length for remaining elements\n        vint32m1_t current = vle32_v_i32m1(&lst[i], vl); // Load current elements\n        vint32m1_t next = vle32_v_i32m1(&lst[i + 1], vl); // Load next elements\n\n        vbool32_t is_ascending = vmseq_vv_i32m1_b32(current, next, vl); // Check for duplicates\n        if (vfirst_m_b32(is_ascending, vl) != -1) return false;\n\n        vbool32_t is_not_sorted = vmgt_vv_i32m1_b32(current, next, vl); // Check if not sorted\n        if (vfirst_m_b32(is_not_sorted, vl) != -1) return false;\n\n        i += vl; // Move to the next chunk\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_122_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <cstdint>\n\nbool is_sorted_simd(const std::vector<int> &lst) {\n    size_t n = lst.size();\n    if (n <= 1) return true;\n\n    size_t vl;\n    size_t i = 0;\n\n    while (i < n - 1) {\n        vl = vsetvl_e32m1(n - i); // Set vector length based on remaining elements\n        vint32m1_t current = vle32_v_i32m1(&lst[i], vl); // Load current elements\n        vint32m1_t next = vle32_v_i32m1(&lst[i + 1], vl); // Load next elements\n\n        vbool32_t is_ascending = vmflt_vv_i32m1_b32(current, next, vl); // Check current < next\n        vbool32_t is_equal = vmseq_vv_i32m1_b32(current, next, vl); // Check current == next\n\n        if (!vfirst_m_b32(is_ascending, vl) && !vfirst_m_b32(is_equal, vl)) {\n            return false; // Found an out-of-order pair\n        }\n\n        vbool32_t is_duplicate = vmseq_vv_i32m1_b32(current, next, vl);\n        if (vfirst_m_b32(is_duplicate, vl)) {\n            vint32m1_t next_next = vle32_v_i32m1(&lst[i + 2], vl);\n            vint32m1_t next_next = vle32_v_i32m1(&lst[i + 2], vl);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_123_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <cstdint>\n\nint prod_signs_simd(const std::vector<int> & arr) {\n    if (arr.empty()) {\n        return -32768;\n    }\n\n    size_t n = arr.size();\n    int32_t sign_product = 1;\n    int32_t magnitude_sum = 0;\n\n    size_t vlmax = vsetvlmax_e32m1();\n    for (size_t i = 0; i < n; i += vlmax) {\n        size_t vl = vsetvl_e32m1(n - i);\n\n        vint32m1_t vec = vle32_v_i32m1(&arr[i], vl);\n        vint32m1_t abs_vec = vabs_v_i32m1(vec, vl);\n        vint32m1_t sign_vec = vsgnjx_vv_i32m1(vec, vec, vl);\n\n        magnitude_sum += vredsum_vs_i32m1_i32m1(vundefined_i32m1(), abs_vec, vl);\n        sign_product *= vredprod_vs_i32m1_i32m1(vundefined_i32m1(), sign_vec, vl);\n    }\n\n    return magnitude_sum * sign_product;\n}\n```"}
{"task_id": "SimdBench_123_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nint prod_signs_simd(const std::vector<int> &arr) {\n    if (arr.empty()) {\n        return -32768;\n    }\n\n    size_t n = arr.size();\n    size_t vl;\n    int sum_magnitudes = 0;\n    int product_signs = 1;\n\n    for (size_t i = 0; i < n; i += vl) {\n        vl = vsetvl_e32m1(n - i);\n\n        vint32m1_t vec = vle32_v_i32m1(&arr[i], vl);\n        vint32m1_t abs_vec = vabs_v_i32m1(vec, vl);\n        vint32m1_t sign_vec = vsgn_v_i32m1(vec, vl);\n\n        sum_magnitudes += vredsum_vs_i32m1_i32m1(vundefined_i32m1(), abs_vec, vundefined_i32m1(), vl);\n        product_signs *= vredprod_vs_i32m1_i32m1(vundefined_i32m1(), sign_vec, vundefined_i32m1(), vl);\n    }\n\n    return sum_magnitudes * product_signs;\n}\n```"}
{"task_id": "SimdBench_123_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nint prod_signs_simd(const std::vector<int> &arr) {\n    if (arr.empty()) {\n        return -32768;\n    }\n\n    size_t n = arr.size();\n    int32_t sum_magnitudes = 0;\n    int32_t product_signs = 1;\n\n    size_t vl;\n    size_t i = 0;\n\n    while (i < n) {\n        vl = vsetvl_e32m1(n - i);\n\n        vint32m1_t vec = vle32_v_i32m1(&arr[i], vl);\n        vint32m1_t abs_vec = vabs_v_i32m1(vec, vl);\n        vint32m1_t sign_vec = vsgn_v_i32m1(vec, vl);\n\n        sum_magnitudes += vredsum_vs_i32m1_i32m1(vundefined_i32m1(), abs_vec, vundefined_i32m1(), vl);\n        product_signs *= vredprod_vs_i32m1_i32m1(vundefined_i32m1(), sign_vec, vundefined_i32m1(), vl);\n\n        i += vl;\n    }\n\n    return sum_magnitudes * product_signs;\n}\n```"}
{"task_id": "SimdBench_123_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <cstdint>\n\nint prod_signs_simd(const std::vector<int> &arr) {\n    if (arr.empty()) {\n        return -32768;\n    }\n\n    size_t n = arr.size();\n    const int32_t *data = arr.data();\n\n    int32_t sum_magnitudes = 0;\n    int32_t product_signs = 1;\n\n    size_t vlmax = vsetvlmax_e32m1();\n    size_t i = 0;\n\n    while (i < n) {\n        size_t vl = vsetvl_e32m1(n - i);\n\n        vint32m1_t vec = vle32_v_i32m1(data + i, vl);\n        vint32m1_t abs_vec = vabs_v_i32m1(vec, vl);\n        vint32m1_t sign_vec = vsgnj_vx_i32m1(vec, 1, vl);\n\n        sum_magnitudes += vredsum_vs_i32m1_i32m1(vundefined_i32m1(), abs_vec, vl);\n        product_signs *= vredprod_vs_i32m1_i32m1(vundefined_i32m1(), sign_vec, vl);\n\n        i += vl;\n    }\n\n    return sum_magnitudes * product_signs;\n}\n```"}
{"task_id": "SimdBench_123_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nint prod_signs_simd(const std::vector<int> &arr) {\n    if (arr.empty()) {\n        return -32768;\n    }\n\n    size_t n = arr.size();\n    const int vlmax = vsetvlmax_e32m1(); // Maximum vector length for int32_t\n    int32_t sign_product = 1;\n    int32_t magnitude_sum = 0;\n\n    for (size_t i = 0; i < n; i += vlmax) {\n        size_t vl = vsetvl_e32m1(n - i); // Set vector length based on remaining elements\n\n        vint32m1_t vec = vle32_v_i32m1(&arr[i], vl); // Load vector\n        vint32m1_t abs_vec = vabs_v_i32m1(vec, vl); // Compute absolute values\n        vint32m1_t sign_vec = vsgnjx_v_i32m1(vec, vec, vl); // Extract signs (-1, 0, 1)\n\n        magnitude_sum += vredsum_vs_i32m1_i32m1(vundefined_i32m1(), abs_vec, vl); // Sum magnitudes\n        sign_product *= vredprod_vs_i32m1_i32m1(vundefined_i32m1(), sign_vec, vl); // Product of signs\n    }\n\n    return sign_product * magnitude_sum;\n}\n```"}
{"task_id": "SimdBench_124_RVV", "completion": "```cpp\n#include <vector>\n#include <riscv_vector.h>\n#include <limits>\n#include <algorithm>\n\nstd::vector<int> minPath_simd(const std::vector<std::vector<int>> &grid, int k) {\n    int N = grid.size();\n    std::vector<std::vector<std::vector<std::vector<int>>>> dp(\n        k + 1, std::vector<std::vector<std::vector<int>>>(\n                   N, std::vector<std::vector<int>>(N, std::vector<int>(k, std::numeric_limits<int>::max()))));\n\n    for (int i = 0; i < N; i++) {\n        for (int j = 0; j < N; j++) {\n            dp[1][i][j][0] = grid[i][j];\n        }\n    }\n\n    for (int step = 2; step <= k; step++) {\n        for (int i = 0; i < N; i++) {\n            for (int j = 0; j < N; j++) {\n                std::vector<int> min_path(k, std::numeric_limits<int>::max());\n                for (int di = -1; di <= 1; di++) {\n                    for (int dj = -1; dj <= 1; dj++) {\n                        int ni = i + di;\n                        int nj = j + dj;\n                        if (ni >= 0 && ni < N && nj >= 0 && nj < N) {\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl_e32m1(k);\n                            vsetvl"}
{"task_id": "SimdBench_124_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <climits>\n#include <algorithm>\n\nstd::vector<int> minPath_simd(const std::vector<std::vector<int>> &grid, int k) {\n    int N = grid.size();\n    std::vector<std::vector<std::vector<int>>> dp(k, std::vector<std::vector<int>>(N, std::vector<int>(N, INT_MAX)));\n    std::vector<std::vector<std::vector<std::vector<int>>>> path(k, std::vector<std::vector<std::vector<int>>>(N, std::vector<std::vector<int>>(N)));\n\n    for (int i = 0; i < N; i++) {\n        for (int j = 0; j < N; j++) {\n            dp[0][i][j] = grid[i][j];\n            path[0][i][j] = {grid[i][j]};\n        }\n    }\n\n    for (int step = 1; step < k; step++) {\n        for (int i = 0; i < N; i++) {\n            for (int j = 0; j < N; j++) {\n                size_t vl = vsetvl_e32m1(8);\n                vint32m1_t min_val = vmv_v_x_i32m1(INT_MAX, vl);\n                vint32m1_t min_idx = vmv_v_x_i32m1(-1, vl);\n\n                for (int di = -1; di <= 1; di++) {\n                    for (int dj = -1; dj <= 1; dj++) {\n                        if (di == 0 && dj == 0) continue;\n                        int ni = i + di;\n                        int nj = j + dj;\n                        if (ni >= 0 && ni < N && nj >= 0 && nj < N) {\n                            vint32m1_t cand = dp[step-1][ni][nj] + grid[i][j];\n                            vint32m1_t cand = dp[step-1][ni][nj] + grid[i][j];\n                            vmin"}
{"task_id": "SimdBench_124_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <limits>\n#include <algorithm>\n\nstd::vector<int> minPath_simd(const std::vector<std::vector<int>> &grid, int k) {\n    int N = grid.size();\n    std::vector<std::vector<std::vector<int>>> dp(N, std::vector<std::vector<int>>(N, std::vector<int>(k + 1, std::numeric_limits<int>::max())));\n    std::vector<std::vector<std::vector<std::vector<int>>>> path(N, std::vector<std::vector<std::vector<int>>>(N, std::vector<std::vector<int>>(k + 1)));\n\n    for (int i = 0; i < N; ++i) {\n        for (int j = 0; j < N; ++j) {\n            dp[i][j][1] = grid[i][j];\n            path[i][j][1] = {grid[i][j]};\n        }\n    }\n\n    for (int step = 2; step <= k; ++step) {\n        for (int i = 0; i < N; ++i) {\n            for (int j = 0; j < N; ++j) {\n                vsetvl_e32m1(N * N); // Set vector length\n                vint32m1_t min_values = vundefined_e32m1();\n                vint32m1_t current_values = vundefined_e32m1();\n\n                std::vector<std::vector<int>> neighbors = {{i - 1, j}, {i + 1, j}, {i, j - 1}, {i, j + 1}};\n                for (auto &neighbor : neighbors) {\n                    int ni = neighbor[0], nj = neighbor[1];\n                    if (ni >= 0 && ni < N && nj >= 0 && nj < N) {\n                        vint32m1_t neighbor_values = vle32_v_i32m1(dp[ni][nj][step - 1].data(), N * N);\n                        vint32m1_t grid_values = vle32_v_i32m1(&grid[i][j], N * N);\n                        current_values = vadd_vv_i32m1(neighbor_values, grid_values);\n                        min_values = vmin_vv_i32m1(min_values, current_values);\n                    }\n                }\n\n                dp[i][j][step] = vmv_x_s_i32m1(min_values);\n                path[i][j][step] = path[i][j][step - 1];\n                path[i][j][step].push_back(grid[i][j]);\n            }\n        }\n    }\n\n    std::vector<int> result;\n    std::vector<int> min_path = path[0][0][k];\n    for (int i = 0; i < N; ++i) {\n        for (int j = 0; j < N; ++j) {\n            if (path[i][j][k] < min_path) {\n                min_path = path[i][j][k];\n            }\n        }\n    }\n    result = min_path;\n    return result;\n}\n```"}
{"task_id": "SimdBench_124_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <queue>\n#include <limits>\n#include <algorithm>\n\nstd::vector<int> minPath_simd(const std::vector<std::vector<int>> &grid, int k) {\n    int N = grid.size();\n    int max_val = N * N;\n    std::vector<std::vector<std::vector<std::vector<int>>>> dp(\n        N, std::vector<std::vector<std::vector<int>>>(\n               N, std::vector<std::vector<int>>(k + 1, std::vector<int>(k, max_val))));\n\n    auto cmp = [](const std::vector<int> &a, const std::vector<int> &b) {\n        return a > b;\n    };\n\n    std::priority_queue<std::vector<int>, std::vector<std::vector<int>>, decltype(cmp)> pq(cmp);\n\n    for (int i = 0; i < N; ++i) {\n        for (int j = 0; j < N; ++j) {\n            dp[i][j][1][0] = grid[i][j];\n            pq.push({grid[i][j], i, j, 1});\n        }\n    }\n\n    int dx[] = {0, 0, 1, -1};\n    int dy[] = {1, -1, 0, 0};\n\n    while (!pq.empty()) {\n        auto curr = pq.top();\n        pq.pop();\n\n        int val = curr[0], x = curr[1], y = curr[2], len = curr[3];\n\n        if (len == k) {\n            std::vector<int> result(dp[x][y][len].begin(), dp[x][y][len].begin() + k);\n            return result;\n        }\n\n        for (int d = 0; d < 4; ++d) {\n            int nx = x + dx[d], ny = y + dy[d];\n            if (nx >= 0 && nx < N && ny >= 0 && ny < N) {\n                std::vector<int> new_path = dp[x][y][len];\n                new_path[len] = grid[nx][ny];\n                if (new_path < dp[nx][ny][len + 1]) {\n                    dp[nx][ny][len + 1] = new_path;\n                    pq.push({grid[nx][ny], nx, ny, len + 1});\n                }\n            }\n        }\n    }\n\n    return {};\n}\n```"}
{"task_id": "SimdBench_124_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <algorithm>\n#include <limits>\n\nstd::vector<int> minPath_simd(const std::vector<std::vector<int>> &grid, int k) {\n    int N = grid.size();\n    std::vector<std::vector<std::vector<std::vector<int>>>> dp(\n        k + 1, std::vector<std::vector<std::vector<int>>>(\n                   N, std::vector<std::vector<int>>(N, std::vector<int>(k, std::numeric_limits<int>::max()))));\n\n    for (int i = 0; i < N; i++) {\n        for (int j = 0; j < N; j++) {\n            dp[1][i][j][0] = grid[i][j];\n        }\n    }\n\n    for (int step = 2; step <= k; step++) {\n        for (int i = 0; i < N; i++) {\n            for (int j = 0; j < N; j++) {\n                std::vector<int> min;\n                for (int di = -1; di <= 1; di++) {\n                    for (int dj = -1; dj <= 1; dj++) {\n                        if (di == 0 && dj == 0) continue;\n                        int ni = i + di;\n                        int nj = j + dj;\n                        if (ni >= 0 && nj >= 0 && ni < N && nj < N) {\n                            min.push_back(dp[step - 1][ni][nj][0]);\n                        }\n                    }\n                }\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_125_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nuint64_t digits_simd(uint64_t n) {\n    if (n == 0) return 0;\n\n    uint64_t digits[20];\n    size_t count = 0;\n\n    // Extract digits from the number\n    while (n > 0) {\n        digits[count++] = n % 10;\n        n /= 10;\n    }\n\n    size_t vl = vsetvl_e64m1(count);\n    vuint64m1_t vec_digits = vle64_v_u64m1(digits, vl);\n    vuint64m1_t vec_odd_mask = vmseq_vx_u64m1(vec_digits, 1, vl) |\n                               vmseq_vx_u64m1(vec_digits, 3, vl) |\n                               vmseq_vx_u64m1(vec_digits, 5, vl) |\n                               vmseq_vx_u64m1(vec_digits, 7, vl) |\n                               vmseq_vx_u64m1(vec_digits, 9, vl);\n\n    vuint64m1_t vec_odd_digits = vmerge_vvm_u64m1(vec_odd_mask, vec_digits, vmv_v_x_u64m1(1, vl), vl);\n\n    uint64_t product = 1;\n    for (size_t i = 0; i < count; i++) {\n        product *= digits[i];\n    }\n}\n```"}
{"task_id": "SimdBench_125_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nuint64_t digits_simd(uint64_t n) {\n    if (n == 0) return 0;\n\n    uint8_t digits[20]; // Maximum 20 digits for a 64-bit number\n    size_t count = 0;\n\n    // Extract digits from the number\n    while (n > 0) {\n        digits[count++] = n % 10;\n        n /= 10;\n    }\n\n    // Initialize vector variables\n    size_t vl;\n    vuint8m1_t vec_digits, vec_odd_mask, vec_result;\n    vuint8m1_t vec_ones = vmv_v_x_u8m1(1, vsetvlmax_e8m1()); // Vector of ones\n    uint8_t result[20];\n    uint64_t product = 1;\n    int has_odd = 0;\n\n    for (size_t i = 0; i < count; i += vl) {\n        vl = vsetvl_e8m1(count - i); // Set vector length\n        vec_digits = vle8_v_u8m1(&digits[i], vl); // Load digits into vector\n\n        // Check if digits are odd (digit % 2 != 0)\n        vec_odd_mask = vand_vx_u8m1(vec_digits, 1, vl); // Mask for odd digits\n\n        // Multiply odd digits\n        vec_result = vmerge_vxm_u8m1(vec_ones, vec_digits, vec_odd_mask, vl); // Keep odd digits, replace even with 1\n        vse8_v_u8m1(result, vec_result, vl); // Store result back to array\n\n        for (size_t j = 0; j < vl; j++) {\n            if (result[j] % 2 != 0) {\n                has_odd = 1;\n                product *= result[j];\n            }\n        }\n    }\n\n    return has_odd ? product : 0;\n}\n```"}
{"task_id": "SimdBench_125_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nuint64_t digits_simd(uint64_t n) {\n    uint64_t digits[20];\n    size_t count = 0;\n\n    // Extract digits from the number\n    while (n > 0) {\n        digits[count++] = n % 10;\n        n /= 10;\n    }\n\n    if (count == 0) {\n        return 0;\n    }\n\n    size_t vl;\n    uint64_t result = 1;\n    int has_odd = 0;\n\n    for (size_t i = 0; i < count; i += vl) {\n        vl = vsetvl_e64(count - i);\n\n        vuint64m1_t vec_digits = vle64_v_u64m1(&digits[i], vl);\n        vuint64m1_t vec_mod2 = vand_vx_u64m1(vec_digits, 1, vl);\n        vbool64_t odd_mask = vmseq_vx_u64m1_b64(vec_mod2, 1, vl);\n\n        vuint64m1_t vec_odds = vmerge_vxm_u64m1(odd_mask, vec_digits, 1, vl);\n        uint64_t temp_result = vredmul_vs_u64m1_u64m1(vundefined_u64m1(), vec_odds, 1, vl);\n\n        if (vfirst_m_b64(odd_mask) >= 0) {\n            has_odd = 1;\n        }\n\n        result *= temp_result;\n    }\n\n    return has_odd ? result : 0;\n}\n```"}
{"task_id": "SimdBench_125_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nuint64_t digits_simd(uint64_t n) {\n    if (n == 0) return 0;\n\n    uint64_t digits[19]; // Maximum digits for a 64-bit number\n    size_t count = 0;\n\n    // Extract digits from the number\n    while (n > 0) {\n        digits[count++] = n % 10;\n        n /= 10;\n    }\n\n    // Initialize vector length\n    size_t vl;\n    uint64_t product = 1;\n    int has_odd = 0;\n\n    for (size_t i = 0; i < count; i += vl) {\n        vl = vsetvl_e64(count - i); // Set vector length based on remaining digits\n\n        // Load digits into vector\n        vuint64m1_t vec_digits = vle64_v_u64m1(&digits[i], vl);\n\n        // Check for odd digits (digit % 2 != 0)\n        vuint64m1_t vec_mod2 = vand_vx_u64m1(vec_digits, 1, vl);\n        vbool64_t odd_mask = vmne_vx_u64m1_b64(vec_mod2, 0, vl);\n\n        // Extract odd digits\n        vuint64m1_t vec_odds = vmerge_vxm_u64m1(vundefined_u64m1(), vec_digits, odd_mask, vl);\n\n        // Multiply odd digits\n        uint64_t temp[vl];\n        vse64_v_u64m1(temp, vec_odds, vl);\n        for (size_t j = 0; j < vl; j++) {\n            if (temp[j] != 0) {\n                product *= temp[j];\n                has_odd = 1;\n            }\n        }\n    }\n\n    return has_odd ? product : 0;\n}\n```"}
{"task_id": "SimdBench_125_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nuint64_t digits_simd(uint64_t n) {\n    uint64_t digits[20];\n    size_t count = 0;\n\n    // Extract digits from the number\n    while (n > 0) {\n        digits[count++] = n % 10;\n        n /= 10;\n    }\n\n    if (count == 0) {\n        return 0;\n    }\n\n    size_t vl;\n    uint64_t product = 1;\n    int has_odd = 0;\n\n    for (size_t i = 0; i < count; i += vl) {\n        vl = vsetvl_e64(count - i);\n\n        vuint64m1_t vec_digits = vle64_v_u64m1(&digits[i], vl);\n        vuint64m1_t vec_mod2 = vand_vx_u64m1(vec_digits, 1, vl);\n        vbool64_t odd_mask = vmne_vx_u64m1_b64(vec_mod2, 0, vl);\n\n        if (vfirst_m_b64(odd_mask, vl) >= 0) {\n            has_odd = 1;\n        }\n\n        vuint64m1_t vec_odds = vmerge_vxm_u64m1(vundefined_u64m1(), vec_digits, odd_mask, vl);\n        product *= vredprod_vs_u64m1_u64m1(vundefined_u64m1(), vec_odds, vundefined_u64m1(), vl);\n    }\n\n    return has_odd ? product : 0;\n}\n```"}
{"task_id": "SimdBench_126_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <cmath>\n\nuint64_t sum_squares_simd(const std::vector<float> &lst) {\n    size_t n = lst.size();\n    size_t vlmax = vsetvlmax_e32m1(); // Maximum vector length for 32-bit elements\n    uint64_t result = 0;\n\n    for (size_t i = 0; i < n; i += vlmax) {\n        size_t vl = vsetvl_e32m1(n - i); // Set vector length for remaining elements\n        vfloat32m1_t v_in = vle32_v_f32m1(&lst[i], vl); // Load input elements\n        vfloat32m1_t v_ceil = vceil_v_f32m1(v_in, vl); // Apply ceiling to each element\n        vint32m1_t v_int = vfcvt_x_f_v_i32m1(v_ceil, vl); // Convert to integer\n        vint32m1_t v_squared = vmul_vv_i32m1(v_int, v_int, vl); // Square each element\n        vint64m1_t v_sum = vwredsum_vs_i32m1_i64m1(vundefined_i64m1(), v_squared, vundefined_i64m1(), vl); // Reduce sum\n        result += vmv_x_s_i64m1_i64(v_sum); // Extract scalar result and accumulate\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_126_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <cmath>\n#include <cstdint>\n\nuint64_t sum_squares_simd(const std::vector<float> &lst) {\n    size_t n = lst.size();\n    size_t vl;\n    uint64_t result = 0;\n\n    // Allocate memory for the input and output vectors\n    float *input = const_cast<float*>(lst.data());\n    uint64_t temp_result = 0;\n\n    // Process the vector in chunks using RVV\n    for (size_t i = 0; i < n; i += vl) {\n        vl = vsetvl_e32m1(n - i); // Set vector length for 32-bit floats\n\n        // Load the input vector chunk\n        vfloat32m1_t vec = vle32_v_f32m1(&input[i], vl);\n\n        // Apply ceiling to each element\n        vfloat32m1_t vec_ceil = vceil_v_f32m1(vec, vl);\n\n        // Convert to integers\n        vint32m1_t vec_int = vfcvt_x_f_v_i32m1(vec_ceil, vl);\n\n        // Square each element\n        vint32m1_t vec_squared = vmul_vv_i32m1(vec_int, vec_int, vl);\n\n        // Sum the squared elements\n        vint32m1_t vec_sum = vredsum_vs_i32m1_i32m1(vundefined_i32m1(), vec_squared, vundefined_i32m1(), vl);\n\n        // Extract the sum from the vector\n        temp_result += vmv_x_s_i32m1_i32(vec_sum);\n    }\n\n    result = temp_result;\n    return result;\n}\n```"}
{"task_id": "SimdBench_126_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <cmath>\n\nuint64_t sum_squares_simd(const std::vector<float> & lst) {\n    size_t n = lst.size();\n    size_t vlmax = vsetvlmax_e32m1(); // Maximum vector length for 32-bit elements\n    uint64_t sum = 0;\n\n    for (size_t i = 0; i < n; i += vlmax) {\n        size_t vl = vsetvl_e32m1(n - i); // Set vector length based on remaining elements\n\n        // Load elements into vector register\n        vfloat32m1_t vec = vle32_v_f32m1(&lst[i], vl);\n\n        // Apply ceiling operation\n        vfloat32m1_t vec_ceil = vceil_v_f32m1(vec, vl);\n\n        // Convert to integers\n        vint32m1_t vec_int = vfcvt_x_f_v_i32m1(vec_ceil, vl);\n\n        // Square the elements\n        vint32m1_t vec_squared = vmul_vv_i32m1(vec_int, vec_int, vl);\n\n        // Sum the squared elements\n        vint32m1_t vec_sum = vredsum_vs_i32m1_i32m1(vundefined_i32m1(), vec_squared, vl);\n\n        // Extract the sum from the vector register\n        sum += vmv_x_s_i32m1_i32(vec_sum);\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_126_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <cmath>\n\nuint64_t sum_squares_simd(const std::vector<float> &lst) {\n    size_t n = lst.size();\n    size_t vlmax = vsetvlmax_e32m1(); // Maximum vector length for 32-bit elements\n    uint64_t result = 0;\n\n    for (size_t i = 0; i < n; i += vlmax) {\n        size_t vl = vsetvl_e32m1(n - i); // Set vector length for the remaining elements\n        vfloat32m1_t v_in = vle32_v_f32m1(&lst[i], vl); // Load input elements\n        vfloat32m1_t v_ceil = vceil_v_f32m1(v_in, vl); // Apply ceiling to each element\n        vint32m1_t v_int = vfcvt_x_f_v_i32m1(v_ceil, vl); // Convert to integers\n        vint32m1_t v_squared = vmul_vv_i32m1(v_int, v_int, vl); // Square each element\n        vint64m1_t v_sum = vwredsum_vs_i32m1_i64m1(vundefined_i64m1(), v_squared, vundefined_i64m1(), vl); // Reduce sum\n        result += vmv_x_s_i64m1_i64(v_sum); // Extract the sum and accumulate\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_126_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <cmath>\n\nuint64_t sum_squares_simd(const std::vector<float> &lst) {\n    size_t n = lst.size();\n    size_t vlmax = vsetvlmax_e32m1(); // Maximum vector length for 32-bit elements\n    uint64_t result = 0;\n\n    for (size_t i = 0; i < n; ) {\n        size_t vl = vsetvl_e32m1(n - i); // Set vector length based on remaining elements\n        vfloat32m1_t v_in = vle32_v_f32m1(&lst[i], vl); // Load vector of floats\n        vfloat32m1_t v_ceil = vfcvt_rtz_x_f_v_f32m1(v_in, vl); // Round to nearest integer towards zero\n        vint32m1_t v_int = vfcvt_x_f_v_i32m1(v_ceil, vl); // Convert to integer\n        vint32m1_t v_square = vmul_vv_i32m1(v_int, v_int, vl); // Square the integers\n        vint64m1_t v_sum = vwredsum_vs_i32m1_i64m1(v_square, vundefined_i64m1(), vl); // Reduce sum\n        result += vget_i64m1(v_sum, 0); // Accumulate the result\n        i += vl;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_127_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nint can_arrange_simd(const std::vector<int> &arr) {\n    size_t n = arr.size();\n    if (n < 2) return -1;\n\n    size_t vlmax = vsetvlmax_e32m1(); // Maximum vector length for int32\n    for (size_t i = 0; i < n - 1; i += vlmax) {\n        size_t vl = vsetvl_e32m1(n - i); // Set vector length based on remaining elements\n\n        vint32m1_t current = vle32_v_i32m1(&arr[i], vl);       // Load current elements\n        vint32m1_t next = vle32_v_i32m1(&arr[i + 1], vl - 1); // Load next elements (vl-1)\n\n        vbool32_t mask = vmfle_vv_i32m1_b32(next, current, vl - 1); // Compare next <= current\n\n        int first_fail = vfirst_m_b32(mask, vl - 1); // Find first failing index in mask\n        if (first_fail >= 0) {\n            return i + first_fail + 1; // Return the failing index (adjusted for offset)\n        }\n    }\n\n    return -1; // No failing index found\n}\n```"}
{"task_id": "SimdBench_127_RVV", "completion": "```c++\n#include <riscv_vector.h>\n#include <vector>\n\nint can_arrange_simd(const std::vector<int> &arr) {\n    size_t n = arr.size();\n    if (n < 2) return -1;\n\n    size_t vlmax = vsetvlmax_e32m1(); // Maximum vector length for 32-bit integers\n    int result = -1;\n\n    for (size_t i = 0; i < n - 1; i += vlmax) {\n        size_t vl = vsetvl_e32m1(n - i); // Set vector length based on remaining elements\n\n        vint32m1_t current = vle32_v_i32m1(&arr[i], vl);       // Load current elements\n        vint32m1_t next = vle32_v_i32m1(&arr[i + 1], vl - 1); // Load next elements (shifted)\n\n        vbool32_t mask = vmseq_vv_i32m1_b32(current, next, vl - 1); // Compare current == next\n        mask = vmnot_m_b32(mask, vl - 1);                          // Invert mask for current != next\n\n        uint32_t first_fail = vfirst_m_b32(mask, vl - 1); // Find first failure index in mask\n        if (first_fail != vl - 1) {                       // If a failure is found\n            result = i + first_fail;                     // Calculate the failing index\n            break;\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_127_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nint can_arrange_simd(const std::vector<int> &arr) {\n    size_t n = arr.size();\n    if (n < 2) return -1;\n\n    size_t vlmax = vsetvlmax_e32m1();\n    size_t i = 0;\n\n    while (i < n - 1) {\n        size_t vl = vsetvl_e32m1(n - i);\n        vint32m1_t vec_curr = vle32_v_i32m1(&arr[i], vl);\n        vint32m1_t vec_next = vle32_v_i32m1(&arr[i + 1], vl);\n\n        vbool32_t mask = vmflt_vv_i32m1_b32(vec_next, vec_curr, vl);\n        uint32_t mask_bits = vmsbf_m_b32(mask, vl);\n\n        if (mask_bits != 0) {\n            int offset = __builtin_ctz(mask_bits);\n            return i + offset + 1;\n        }\n\n        i += vl;\n    }\n\n    return -1;\n}\n```"}
{"task_id": "SimdBench_127_RVV", "completion": "```c++\n#include <riscv_vector.h>\n#include <vector>\n\nint can_arrange_simd(const std::vector<int> &arr) {\n    size_t n = arr.size();\n    if (n < 2) return -1;\n\n    size_t vlmax = vsetvlmax_e32m1(); // Maximum vector length for int32\n    size_t i = 0;\n\n    while (i < n - 1) {\n        size_t vl = vsetvl_e32m1(n - 1 - i); // Set vector length based on remaining elements\n        vint32m1_t current = vle32_v_i32m1(&arr[i], vl); // Load current elements\n        vint32m1_t next = vle32_v_i32m1(&arr[i + 1], vl); // Load next elements\n        vbool32_t mask = vmfle_vv_i32m1_b32(next, current, vl); // Compare next <= current\n\n        if (vfirst_m_b32(mask, vl) != -1) { // Check if any comparison is true\n            return i + vfirst_m_b32(mask, vl); // Return the index of the first match\n        }\n\n        i += vl; // Move to the next chunk\n    }\n\n    return -1; // No such element found\n}\n```"}
{"task_id": "SimdBench_127_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nint can_arrange_simd(const std::vector<int> &arr) {\n    size_t n = arr.size();\n    if (n < 2) return -1;\n\n    size_t vlmax = vsetvlmax_e32m1(); // Maximum vector length for 32-bit integers\n    size_t i = 0;\n\n    while (i < n - 1) {\n        size_t vl = vsetvl_e32m1(n - 1 - i); // Set vector length based on remaining elements\n        vint32m1_t current = vle32_v_i32m1(&arr[i], vl); // Load current elements\n        vint32m1_t next = vle32_v_i32m1(&arr[i + 1], vl); // Load next elements\n\n        vbool32_t mask = vmfle_vv_i32m1_b32(next, current, vl); // Compare next <= current\n        uint32_t first_fail = vfirst_m_b32(mask, vl); // Find the first failing index in the mask\n\n        if (first_fail != vl) {\n            return i + first_fail; // Return the failing index\n        }\n\n        i += vl; // Move to the next chunk\n    }\n\n    return -1; // No failing index found\n}\n```"}
{"task_id": "SimdBench_128_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <limits>\n\nstd::vector<int> largest_smallest_integers_simd(const std::vector<int>& lst) {\n    size_t n = lst.size();\n    if (n == 0) {\n        return {0, 0};\n    }\n\n    int largest_negative = std::numeric_limits<int>::min();\n    int smallest_positive = std::numeric_limits<int>::max();\n\n    size_t vl;\n    for (size_t i = 0; i < n; i += vl) {\n        vl = vsetvl_e32m1(n - i);\n\n        vint32m1_t vec = vle32_v_i32m1(&lst[i], vl);\n\n        vint32m1_t neg_mask = vmflt_vx_i32m1_b32(vec, 0, vl);\n        vint32m1_t pos_mask = vmfgt_vx_i32m1_b32(vec, 0, vl);\n\n        vint32m1_t neg_values = vmerge_vxm_i32m1(vundefined_i32m1(), vec, neg_mask, vl);\n        vint32m1_t pos_values = vmerge_vxm_i32m1(vundefined_i32m1(), vec, pos_mask, vl);\n\n        int local_largest_negative = vmax_vx_i32m1_i32(neg_values, largest_negative, vl);\n        int local_smallest_positive = vmin_vx_i32m1_i32(pos_values, smallest_positive, vl);\n\n        largest_negative = local_largest_negative;\n        smallest_positive = local_smallest_positive;\n    }\n\n    if (largest_negative == std::numeric_limits<int>::min()) {\n        largest_negative = 0;\n    }\n    if (smallest_positive == std::numeric_limits<int>::max()) {\n        smallest_positive = 0;\n    }\n\n    return {largest_negative, smallest_positive};\n}\n```"}
{"task_id": "SimdBench_128_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <limits>\n\nstd::vector<int> largest_smallest_integers_simd(const std::vector<int>& lst) {\n    size_t n = lst.size();\n    if (n == 0) {\n        return {0, 0};\n    }\n\n    int largest_negative = std::numeric_limits<int>::min();\n    int smallest_positive = std::numeric_limits<int>::max();\n\n    size_t vlmax = vsetvlmax_e32m1();\n    for (size_t i = 0; i < n; i += vlmax) {\n        size_t vl = vsetvl_e32m1(n - i);\n\n        vint32m1_t vec = vle32_v_i32m1(&lst[i], vl);\n\n        vint32m1_t negative_mask = vmflt_vx_i32m1(vec, 0, vl);\n        vint32m1_t positive_mask = vmfgt_vx_i32m1(vec, 0, vl);\n\n        vint32m1_t negative_values = vmerge_vvm_i32m1(negative_mask, vec, vint32m1_t(), vl);\n        vint32m1_t positive_values = vmerge_vvm_i32m1(positive_mask, vec, vint32m1_t(), vl);\n\n        int max_negative = vmax_vv_i32m1(negative_values, vint32m1_t(), vl);\n        int min_positive = vmin_vv_i32m1(positive_values, vint32m1_t(), vl);\n\n        if (vfirst_m_b32(negative_mask, vl) != -1) {\n            largest_negative = std::max(largest_negative, max_negative);\n        }\n        if (vfirst_m_b32(positive_mask, vl) != -1) {\n            smallest_positive = std::min(smallest_positive, min_positive);\n        }\n    }\n\n    if (largest_negative == std::numeric_limits<int>::min()) {\n        largest_negative = 0;\n    }\n    if (smallest_positive == std::numeric_limits<int>::max()) {\n        smallest_positive = 0;\n    }\n\n    return {largest_negative, smallest_positive};\n}\n```"}
{"task_id": "SimdBench_128_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <limits>\n\nstd::vector<int> largest_smallest_integers_simd(const std::vector<int>& lst) {\n    size_t n = lst.size();\n    if (n == 0) {\n        return {0, 0};\n    }\n\n    int largest_negative = std::numeric_limits<int>::min();\n    int smallest_positive = std::numeric_limits<int>::max();\n\n    size_t vlmax = vsetvlmax_e32m1();\n    for (size_t i = 0; i < n; i += vlmax) {\n        size_t vl = vsetvl_e32m1(n - i);\n\n        vint32m1_t vec = vle32_v_i32m1(&lst[i], vl);\n\n        vint32m1_t negative_mask = vmflt_vx_i32m1(vec, 0, vl);\n        vint32m1_t positive_mask = vmfgt_vx_i32m1(vec, 0, vl);\n\n        vint32m1_t negative_values = vmerge_vvm_i32m1(negative_mask, vec, vint32m1_t(vmv_v_x_i32m1(std::numeric_limits<int>::min(), vl)), vl);\n        vint32m1_t positive_values = vmerge_vvm_i32m1(positive_mask, vec, vint32m1_t(vmv_v_x_i32m1(std::numeric_limits<int>::max(), vl)), vl);\n\n        int max_negative = vreduce_max_i32m1(negative_values, vl);\n        int min_positive = vreduce_min_i32m1(positive_values, vl);\n\n        if (max_negative > largest_negative) {\n            largest_negative = max_negative;\n        }\n        if (min_positive < smallest_positive) {\n            smallest_positive = min_positive;\n        }\n    }\n\n    if (largest_negative == std::numeric_limits<int>::min()) {\n        largest_negative = 0;\n    }\n    if (smallest_positive == std::numeric_limits<int>::max()) {\n        smallest_positive = 0;\n    }\n\n    return {largest_negative, smallest_positive};\n}\n```"}
{"task_id": "SimdBench_128_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <limits>\n\nstd::vector<int> largest_smallest_integers_simd(const std::vector<int>& lst) {\n    size_t n = lst.size();\n    if (n == 0) {\n        return {0, 0};\n    }\n\n    int largest_negative = std::numeric_limits<int>::min();\n    int smallest_positive = std::numeric_limits<int>::max();\n\n    size_t vlmax = vsetvlmax_e32m1();\n    for (size_t i = 0; i < n; i += vlmax) {\n        size_t vl = vsetvl_e32m1(n - i);\n\n        vint32m1_t vec = vle32_v_i32m1(&lst[i], vl);\n\n        vint32m1_t negative_mask = vmflt_vx_i32m1(vec, 0, vl);\n        vint32m1_t positive_mask = vmfgt_vx_i32m1(vec, 0, vl);\n\n        vint32m1_t negative_values = vmerge_vvm_i32m1(negative_mask, vec, vint32m1_t(), vl);\n        vint32m1_t positive_values = vmerge_vvm_i32m1(positive_mask, vec, vint32m1_t(), vl);\n\n        int max_negative = vmax_vv_i32m1(negative_values, vint32m1_t(), vl);\n        int min_positive = vmin_vv_i32m1(positive_values, vint32m1_t(), vl);\n\n        if (vcpop_m_b32(negative_mask, vl) > 0) {\n            largest_negative = std::max(largest_negative, max_negative);\n        }\n        if (vcpop_m_b32(positive_mask, vl) > 0) {\n            smallest_positive = std::min(smallest_positive, min_positive);\n        }\n    }\n\n    if (largest_negative == std::numeric_limits<int>::min()) {\n        largest_negative = 0;\n    }\n    if (smallest_positive == std::numeric_limits<int>::max()) {\n        smallest_positive = 0;\n    }\n\n    return {largest_negative, smallest_positive};\n}\n```"}
{"task_id": "SimdBench_128_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <limits>\n\nstd::vector<int> largest_smallest_integers_simd(const std::vector<int>& lst) {\n    size_t n = lst.size();\n    if (n == 0) {\n        return {0, 0};\n    }\n\n    int largest_negative = std::numeric_limits<int>::min();\n    int smallest_positive = std::numeric_limits<int>::max();\n\n    size_t vl;\n    for (size_t i = 0; i < n; i += vl) {\n        vl = vsetvl_e32m1(n - i);\n\n        vint32m1_t vec = vle32_v_i32m1(&lst[i], vl);\n\n        vint32m1_t neg_mask = vmflt_vx_i32m1_b32(vec, 0, vl);\n        vint32m1_t pos_mask = vmfgt_vx_i32m1_b32(vec, 0, vl);\n\n        vint32m1_t neg_values = vmerge_vxm_i32m1(vec, std::numeric_limits<int>::min(), neg_mask, vl);\n        vint32m1_t pos_values = vmerge_vxm_i32m1(vec, std::numeric_limits<int>::max(), pos_mask, vl);\n\n        int max_neg = vmax_vx_i32m1(neg_values, std::numeric_limits<int>::min(), vl);\n        int min_pos = vmin_vx_i32m1(pos_values, std::numeric_limits<int>::max(), vl);\n\n        largest_negative = std::max(largest_negative, max_neg);\n        smallest_positive = std::min(smallest_positive, min_pos);\n    }\n\n    if (largest_negative == std::numeric_limits<int>::min()) {\n        largest_negative = 0;\n    }\n    if (smallest_positive == std::numeric_limits<int>::max()) {\n        smallest_positive = 0;\n    }\n\n    return {largest_negative, smallest_positive};\n}\n```"}
{"task_id": "SimdBench_129_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nuint64_t special_factorial_simd(uint64_t n) {\n    if (n == 0) return 1;\n\n    uint64_t result = 1;\n    size_t vlmax = vsetvlmax_e64m1(); // Maximum vector length for 64-bit elements\n    uint64_t factorials[n];\n\n    // Compute individual factorials\n    for (uint64_t i = 1; i <= n; i++) {\n        uint64_t fact = 1;\n        for (uint64_t j = 1; j <= i; j++) {\n            fact *= j;\n        }\n        factorials[i - 1] = fact;\n    }\n\n    // Use RVV to multiply factorials in parallel\n    size_t vl = vsetvl_e64m1(n); // Set vector length\n    uint64_t *ptr = factorials;\n    vuint64m1_t vec_result = vmv_v_x_u64m1(1, vl); // Initialize vector with 1\n\n    while (n > 0) {\n        vuint64m1_t vec_factorials = vle64_v_u64m1(ptr, vl); // Load factorials into vector\n        vec_result = vmul_vv_u64m1(vec_result, vec_factorials, vl); // Multiply in parallel\n        ptr += vl; // Move pointer\n        n -= vl; // Reduce remaining length\n        vl = vsetvl_e64m1(n); // Update vector length\n    }\n\n    // Reduce vector to scalar result\n    for (size_t i = 0; i < vlmax; i++) {\n        result *= vec_result[i];\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_129_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nuint64_t special_factorial_simd(uint64_t n) {\n    if (n == 0) return 1;\n\n    uint64_t result = 1;\n    size_t vlmax = vsetvlmax_e64m1();\n    uint64_t factorials[n];\n\n    for (uint64_t i = 1; i <= n; i++) {\n        factorials[i - 1] = 1;\n        for (uint64_t j = 1; j <= i; j++) {\n            factorials[i - 1] *= j;\n        }\n    }\n\n    size_t vl = vsetvl_e64m1(n);\n    uint64_t *ptr = factorials;\n    vuint64m1_t vec_factorials = vle64_v_u64m1(ptr, vl);\n\n    result = vmv_x_s_u64m1(vredsum_vs_u64m1_u64m1(vec_factorials, vec_factorials, vl));\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_129_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nuint64_t special_factorial_simd(uint64_t n) {\n    if (n == 0) return 1;\n\n    uint64_t result = 1;\n\n    for (uint64_t i = 1; i <= n; i += vsetvlmax_e64m1()) {\n        size_t vl = vsetvl_e64m1(n - i + 1);\n        vuint64m1_t indices = vid_v_u64m1(vl);\n        vuint64m1_t values = vadd_vx_u64m1(indices, i - 1, vl);\n\n        vuint64m1_t factorials = vmv_v_x_u64m1(1, vl);\n        for (uint64_t j = 2; j <= n; j++) {\n            vbool64_t mask = vmseq_vx_u64m1_b64(values, j, vl);\n            factorials = vmul_vx_u64m1_m(mask, factorials, factorials, j, vl);\n        }\n\n        result *= vredprod_vs_u64m1_u64m1(factorials, factorials, vl);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_129_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nuint64_t special_factorial_simd(uint64_t n) {\n    if (n == 0) return 1;\n\n    uint64_t result = 1;\n\n    for (uint64_t i = n; i > 0; i -= vsetvlmax_e64m1()) {\n        size_t vl = vsetvl_e64m1(i); // Set vector length based on remaining elements\n        vuint64m1_t indices = vid_v_u64m1(vl); // Create vector [0, 1, 2, ..., vl-1]\n        indices = vadd_vx_u64m1(indices, i - vl, vl); // Adjust indices to [i-vl, ..., i-1]\n\n        vuint64m1_t factorials = vmv_v_x_u64m1(1, vl); // Initialize factorials to 1\n        for (uint64_t j = 1; j <= i; j++) {\n            vuint64m1_t temp = vmul_vx_u64m1(factorials, j, vl); // Compute factorial\n            factorials = vmerge_vvm_u64m1(factorials, temp, vmsltu_vx_u64m1(indices, j, vl), vl);\n        }\n\n        result *= vredprod_vs_u64m1_u64m1(factorials, factorials, vl); // Multiply all factorials\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_129_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nuint64_t special_factorial_simd(uint64_t n) {\n    if (n == 0) return 1;\n\n    uint64_t result = 1;\n    size_t vlmax = vsetvlmax_e64m1(); // Maximum vector length for 64-bit elements\n    uint64_t factorials[n];\n\n    // Compute all factorials from 1! to n! sequentially\n    factorials[0] = 1;\n    for (uint64_t i = 1; i <= n; i++) {\n        factorials[i - 1] = factorials[i - 2] * i;\n    }\n\n    // Use RVV to compute the product of all factorials in parallel\n    for (size_t i = 0; i < n; i += vlmax) {\n        size_t vl = vsetvl_e64m1(n - i); // Set vector length for remaining elements\n        vuint64m1_t vec = vle64_v_u64m1(&factorials[i], vl); // Load factorials into vector\n        result *= vmv_x_s_u64m1_u64(vredprod_vs_u64m1_u64m1(vundefined_u64m1(), vec, vec, vl)); // Reduce product\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_130_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nint sum_squares_simd(const std::vector<int> &lst) {\n    size_t n = lst.size();\n    if (n == 0) return 0;\n\n    int sum = 0;\n    size_t vlmax = vsetvlmax_e32m1(); // Maximum vector length for 32-bit integers\n    size_t i = 0;\n\n    while (i < n) {\n        size_t vl = vsetvl_e32m1(n - i); // Set vector length based on remaining elements\n        vint32m1_t vec = vle32_v_i32m1(&lst[i], vl); // Load vector from lst\n\n        vint32m1_t indices = vid_v_i32m1(vl); // Generate index vector\n        indices = vadd_vx_i32m1(indices, i, vl); // Adjust indices to match current offset\n\n        // Mask for indices that are multiples of 3\n        vbool32_t mask3 = vmseq_vx_i32m1_b32(vrem_vx_i32m1(indices, 3, vl), 0, vl);\n        // Mask for indices that are multiples of 4 but not multiples of 3\n        vbool32_t mask4 = vmseq_vx_i32m1_b32(vrem_vx_i32m1(indices, 4, vl), 0, vl);\n        mask4 = vmnand_mm_b32(mask3, mask4, vl); // Exclude multiples of 3 from multiples of 4\n\n        // Square elements where mask3 is true\n        vint32m1_t squared = vmul_vv_i32m1(vec, vec, vl);\n        vec = vmerge_vvm_i32m1(mask3, squared, vec, vl);\n\n        // Cube elements where mask4 is true\n        vint32m1_t cubed = vmul_vv_i32m1(vec, vec, vl);\n        cubed = vmul_vv_i32m1(cubed, vec, vl);\n        vec = vmerge_vvm_i32m1(mask4, cubed, vec, vl);\n\n        // Sum up the vector\n        sum += vredsum_vs_i32m1_i32m1(vundefined_i32m1(), vec, vundefined_i32m1(), vl);\n\n        i += vl; // Move to the next chunk\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_130_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nint sum_squares_simd(const std::vector<int> &lst) {\n    size_t n = lst.size();\n    if (n == 0) return 0;\n\n    int sum = 0;\n    size_t vlmax = vsetvlmax_e32m1(); // Maximum vector length for 32-bit integers\n    size_t i = 0;\n\n    while (i < n) {\n        size_t vl = vsetvl_e32m1(n - i); // Set vector length based on remaining elements\n        vuint32m1_t indices = vid_v_u32m1(vl); // Generate vector of indices\n        vint32m1_t data = vle32_v_i32m1(&lst[i], vl); // Load data from lst\n\n        // Calculate masks for indices that are multiples of 3 and multiples of 4\n        vbool32_t mask_multiple_of_3 = vmseq_vx_u32m1_b32(indices, 0, vl);\n        mask_multiple_of_3 = vmand_vx_b32(mask_multiple_of_3, 3, vl);\n        vbool32_t mask_multiple_of_4 = vmseq_vx_u32m1_b32(indices, 0, vl);\n        mask_multiple_of_4 = vmand_vx_b32(mask_multiple_of_4, 4, vl);\n        mask_multiple_of_4 = vmnot_m_b32(mask_multiple_of_3, mask_multiple_of_4, vl);\n\n        // Square elements where index is a multiple of 3\n        vint32m1_t squared = vmul_vv_i32m1(data, data, vl);\n        data = vmerge_vvm_i32m1(mask_multiple_of_3, squared, data, vl);\n\n        // Cube elements where index is a multiple of 4 but not a multiple of 3\n        vint32m1_t cubed = vmul_vv_i32m1(squared, data, vl);\n        data = vmerge_vvm_i32m1(mask_multiple_of_4, cubed, data, vl);\n\n        // Sum up the elements\n        sum += vredsum_vs_i32m1_i32m1(vundefined_i32m1(), data, vl);\n\n        i += vl; // Move to the next chunk\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_130_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nint sum_squares_simd(const std::vector<int> &lst) {\n    size_t n = lst.size();\n    if (n == 0) return 0;\n\n    int sum = 0;\n    size_t vlmax = vsetvlmax_e32m1(); // Maximum vector length for 32-bit integers\n    size_t i = 0;\n\n    while (i < n) {\n        size_t vl = vsetvl_e32m1(n - i); // Set vector length based on remaining elements\n\n        vuint32m1_t indices = vid_v_u32m1(vl); // Generate vector of indices\n        vint32m1_t data = vle32_v_i32m1(&lst[i], vl); // Load data from lst\n\n        vbool32_t mask_multiple_of_3 = vmseq_vx_u32m1_b32(indices, 0, vl); // Mask for indices % 3 == 0\n        mask_multiple_of_3 = vmand_mm_b32(mask_multiple_of_3, vmseq_vx_u32m1_b32(vrem_vx_u32m1(indices, 3, vl), 0, vl));\n\n        vbool32_t mask_multiple_of_4 = vmseq_vx_u32m1_b32(indices, 0, vl); // Mask for indices % 4 == 0\n        mask_multiple_of_4 = vmand_mm_b32(mask_multiple_of_4, vmseq_vx_u32m1_b32(vrem_vx_u32m1(indices, 4, vl), 0, vl));\n        mask_multiple_of_4 = vmandnot_mm_b32(mask_multiple_of_3, mask_multiple_of_4); // Exclude indices % 3 == 0\n\n        vint32m1_t squared = vmul_vv_i32m1(data, data, vl); // Square the data\n        vint32m1_t cubed = vmul_vv_i32m1(squared, data, vl); // Cube the data\n\n        data = vmerge_vvm_i32m1(mask_multiple_of_3, data, squared, vl); // Apply square for indices % 3 == 0\n        data = vmerge_vvm_i32m1(mask_multiple_of_4, data, cubed, vl); // Apply cube for indices % 4 == 0\n\n        sum += vredsum_vs_i32m1_i32(data, sum, vl); // Reduce sum\n\n        i += vl; // Move to the next chunk\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_130_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nint sum_squares_simd(const std::vector<int> &lst) {\n    size_t n = lst.size();\n    if (n == 0) return 0;\n\n    int sum = 0;\n    size_t vlmax = vsetvlmax_e32m1(); // Maximum vector length for 32-bit integers\n    size_t i = 0;\n\n    while (i < n) {\n        size_t vl = vsetvl_e32m1(n - i); // Set vector length based on remaining elements\n\n        // Load the vector elements\n        vint32m1_t vec = vle32_v_i32m1(&lst[i], vl);\n\n        // Create index vector\n        vint32m1_t index_vec = vid_v_i32m1(vl);\n\n        // Compute masks for multiples of 3 and 4\n        vbool32_t mask_multiple_of_3 = vmseq_vx_i32m1_b32(index_vec, 3, vl);\n        vbool32_t mask_multiple_of_4 = vmseq_vx_i32m1_b32(index_vec, 4, vl);\n        vbool32_t mask_not_multiple_of_3 = vmnot_m_b32(mask_multiple_of_3, vl);\n        vbool32_t mask_multiple_of_4_not_3 = vmand_mm_b32(mask_multiple_of_4, mask_not_multiple_of_3, vl);\n\n        // Square elements where index is a multiple of 3\n        vint32m1_t squared = vmul_vv_i32m1(vec, vec, vl);\n        vec = vmerge_vvm_i32m1(mask_multiple_of_3, squared, vec, vl);\n\n        // Cube elements where index is a multiple of 4 and not a multiple of 3\n        vint32m1_t cubed = vmul_vv_i32m1(vec, vec, vl);\n        cubed = vmul_vv_i32m1(cubed, vec, vl);\n        vec = vmerge_vvm_i32m1(mask_multiple_of_4_not_3, cubed, vec, vl);\n\n        // Sum the vector elements\n        sum += vredsum_vs_i32m1_i32m1(vundefined_i32m1(), vec, vundefined_i32m1(), vl);\n\n        i += vl;\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_130_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nint sum_squares_simd(const std::vector<int> & lst) {\n    size_t n = lst.size();\n    if (n == 0) return 0;\n\n    int sum = 0;\n    size_t vlmax = vsetvlmax_e32m1(); // Maximum vector length for 32-bit integers\n    size_t i = 0;\n\n    while (i < n) {\n        size_t vl = vsetvl_e32m1(n - i); // Set vector length based on remaining elements\n        vint32m1_t vec = vle32_v_i32m1(&lst[i], vl); // Load vector elements\n\n        vint32m1_t idx = vid_v_i32m1(vl); // Generate index vector\n        idx = vadd_vx_i32m1(idx, i, vl); // Adjust index vector to match global indices\n\n        vint32m1_t mask_multiple_of_3 = vmseq_vx_i32m1_b32(idx, 3, vl); // idx % 3 == 0\n        vint32m1_t mask_multiple_of_4 = vmseq_vx_i32m1_b32(idx, 4, vl); // idx % 4 == 0\n        vint32m1_t mask_not_multiple_of_3 = vmnot_m_b32(mask_multiple_of_3, vl); // !(idx % 3 == 0)\n        vint32m1_t mask_cube = vmand_mm_b32(mask_multiple_of_4, mask_not_multiple_of_3, vl); // idx % 4 == 0 && !(idx % 3 == 0)\n\n        vint32m1_t squared = vmul_vv_i32m1(vec, vec, vl); // Square values\n        vint32m1_t cubed = vmul_vv_i32m1(vec, vmul_vv_i32m1(vec, vec, vl), vl); // Cube values\n\n        vint32m1_t result = vmerge_vvm_i32m1(mask_multiple_of_3, squared, vec, vl); // Apply square mask\n        result = vmerge_vvm_i32m1(mask_cube, cubed, result, vl); // Apply cube mask\n\n        sum += vredsum_vs_i32m1_i32m1(vundefined_i32m1(), result, vl); // Reduce sum\n        i += vl;\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_131_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nint specialFilter_simd(const std::vector<int> &nums) {\n    size_t n = nums.size();\n    size_t vlmax = vsetvlmax_e32m1(); // Maximum vector length for 32-bit integers\n    int count = 0;\n\n    for (size_t i = 0; i < n; i += vlmax) {\n        size_t vl = vsetvl_e32m1(n - i); // Set vector length for remaining elements\n        vint32m1_t vec = vle32_v_i32m1(&nums[i], vl); // Load vector elements\n\n        // Check if elements are greater than 10\n        vbool32_t greater_than_10 = vmgt_vx_i32m1_b32(vec, 10, vl);\n\n        // Get absolute values of the numbers\n        vint32m1_t abs_vec = vabs_v_i32m1(vec, vl);\n\n        // Extract last digit (abs_vec % 10)\n        vint32m1_t last_digit = vrem_vx_i32m1(abs_vec, 10, vl);\n\n        // Check if last digit is odd\n        vbool32_t last_digit_odd = vmseq_vx_i32m1_b32(vand_vx_i32m1(last_digit, 1, vl), 1, vl);\n\n        // Remove last digit and extract first digit\n        vint32m1_t first_digit = abs_vec;\n        while (true) {\n            vbool32_t more_than_9 = vmgt_vx_i32m1_b32(first_digit, 9, vl);\n            if (vfirst_m_b32(more_than_9, vl) < 0) break;\n            first_digit = vdiv_vx_i32m1(first_digit, 10, vl);\n        }\n\n        // Check if first digit is odd\n        vbool32_t first_digit_odd = vmseq_vx_i32m1_b32(vand_vx_i32m1(first_digit, 1, vl), 1, vl);\n\n        // Combine all conditions\n        vbool32_t condition = vmand_mm_b32(vmand_mm_b32(greater_than_10, last_digit_odd, vl), first_digit_odd, vl);\n\n        // Count the number of true elements\n        count += vpopc_m_b32(condition, vl);\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_131_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <cmath>\n\nint specialFilter_simd(const std::vector<int> &nums) {\n    size_t n = nums.size();\n    int count = 0;\n    size_t vlmax = vsetvlmax_e32m1(); // Maximum vector length for 32-bit integers\n    size_t i = 0;\n\n    while (i < n) {\n        size_t vl = vsetvl_e32m1(n - i); // Set vector length based on remaining elements\n        vint32m1_t vec = vle32_v_i32m1(&nums[i], vl); // Load vector elements\n\n        // Check if elements are greater than 10\n        vbool32_t greater_than_10 = vmgt_vx_i32m1_b32(vec, 10, vl);\n\n        // Extract first and last digits\n        vint32m1_t abs_vec = vabs_v_i32m1(vec, vl); // Absolute values\n        vint32m1_t last_digit = vrem_vx_i32m1(abs_vec, 10, vl); // Last digit\n        vint32m1_t first_digit = abs_vec;\n        while (vfirst_m_b32(vmsne_vx_i32m1_b32(first_digit, 0, vl), vl)) {\n            first_digit = vdiv_vx_i32m1(first_digit, 10, vl); // Divide until first digit remains\n        }\n\n        // Check if first and last digits are odd\n        vbool32_t first_odd = vmand_vx_i32m1_b32(vrem_vx_i32m1(first_digit, 2, vl), 1, vl);\n        vbool32_t last_odd = vmand_vx_i32m1_b32(vrem_vx_i32m1(last_digit, 2, vl), 1, vl);\n\n        // Combine conditions\n        vbool32_t valid = vmand_mm_b32(vmand_mm_b32(greater_than_10, first_odd, vl), last_odd, vl);\n\n        // Count valid elements\n        count += vpopc_m_b32(valid, vl);\n\n        i += vl; // Move to the next chunk\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_131_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nint specialFilter_simd(const std::vector<int> &nums) {\n    size_t n = nums.size();\n    int count = 0;\n    size_t vlmax = vsetvlmax_e32m1(); // Maximum vector length for 32-bit integers\n    size_t i = 0;\n\n    while (i < n) {\n        size_t vl = vsetvl_e32m1(n - i); // Set vector length based on remaining elements\n        vint32m1_t vec = vle32_v_i32m1(&nums[i], vl); // Load vector elements\n\n        // Check if elements are greater than 10\n        vbool32_t greater_than_10 = vmgt_vx_i32m1_b32(vec, 10, vl);\n\n        // Get absolute values of the numbers\n        vint32m1_t abs_vec = vabs_v_i32m1(vec, vl);\n\n        // Extract last digit\n        vint32m1_t last_digit = vrem_vx_i32m1(abs_vec, 10, vl);\n\n        // Check if last digit is odd\n        vbool32_t last_digit_odd = vmseq_vx_i32m1_b32(vand_vx_i32m1(last_digit, 1, vl), 1, vl);\n\n        // Remove last digit to get the first digit\n        vint32m1_t first_digit = abs_vec;\n        while (true) {\n            vbool32_t more_than_9 = vmgt_vx_i32m1_b32(first_digit, 9, vl);\n            if (vfirst_m_b32(more_than_9, vl) == -1) break;\n            first_digit = vdiv_vx_i32m1(first_digit, 10, vl);\n        }\n\n        // Check if first digit is odd\n        vbool32_t first_digit_odd = vmseq_vx_i32m1_b32(vand_vx_i32m1(first_digit, 1, vl), 1, vl);\n\n        // Combine all conditions\n        vbool32_t condition = vmand_mm_b32(vmand_mm_b32(greater_than_10, last_digit_odd, vl), first_digit_odd, vl);\n\n        // Count the number of true conditions\n        count += vpopc_m_b32(condition, vl);\n\n        i += vl;\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_131_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nint specialFilter_simd(const std::vector<int> & nums) {\n    size_t n = nums.size();\n    int count = 0;\n\n    size_t vlmax = vsetvlmax_e32m1();\n    for (size_t i = 0; i < n; i += vlmax) {\n        size_t vl = vsetvl_e32m1(n - i);\n\n        vint32m1_t vec = vle32_v_i32m1(&nums[i], vl);\n\n        // Check if elements are greater than 10\n        vbool32_t greater_than_10 = vmgt_vx_i32m1_b32(vec, 10, vl);\n\n        // Extract first and last digits\n        vint32m1_t abs_vec = vabs_v_i32m1(vec, vl);\n        vint32m1_t last_digit = vrem_vx_i32m1(abs_vec, 10, vl);\n        vint32m1_t first_digit = abs_vec;\n        while (true) {\n            vbool32_t is_greater_than_9 = vmgt_vx_i32m1_b32(first_digit, 9, vl);\n            if (vfirst_m_b32(is_greater_than_9, vl) == -1) break;\n            first_digit = vdiv_vx_i32m1(first_digit, 10, vl);\n        }\n\n        // Check if first and last digits are odd\n        vbool32_t first_digit_odd = vred_vx_i32m1_b32(first_digit, 2, vl);\n"}
{"task_id": "SimdBench_131_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nint specialFilter_simd(const std::vector<int> &nums) {\n    size_t n = nums.size();\n    int count = 0;\n\n    size_t vlmax = vsetvlmax_e32m1(); // Maximum vector length for 32-bit integers\n    size_t i = 0;\n\n    while (i < n) {\n        size_t vl = vsetvl_e32m1(n - i); // Set vector length based on remaining elements\n\n        vint32m1_t vec = vle32_v_i32m1(&nums[i], vl); // Load vector elements\n\n        // Check if elements are greater than 10\n        vbool32_t greater_than_10 = vmgt_vx_i32m1_b32(vec, 10, vl);\n\n        // Extract first and last digits\n        vint32m1_t abs_vec = vabs_v_i32m1(vec, vl); // Get absolute values\n        vint32m1_t last_digit = vrem_vx_i32m1(abs_vec, 10, vl); // Last digit\n        vint32m1_t first_digit = abs_vec;\n        while (true) {\n            vbool32_t is_greater_than_9 = vmgt_vx_i32m1_b32(first_digit, 9, vl);\n            if (vfirst_m_b32(is_greater_than_9, vl) == -1) break; // No more digits > 9\n            first_digit = vdiv_vx_i32m1(first_digit, 10, vl); // Divide by 10\n        }\n\n        // Check if first and last digits are odd\n        vbool32_t first_digit_odd = vmand_vx_i32m1_b32(first_digit, 1, vl);\n        vbool32_t last_digit_odd = vmand_vx_i32m1_b32(last_digit, 1, vl);\n\n        // Combine all conditions\n        vbool32_t valid_elements = vmand_mm_b32(\n            vmand_mm_b32(greater_than_10, first_digit_odd, vl),\n            last_digit_odd, vl);\n\n        // Count valid elements\n        count += vpopc_m_b32(valid_elements, vl);\n\n        i += vl; // Move to the next chunk\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_132_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nuint64_t get_max_triples_simd(uint64_t n) {\n    if (n < 3) return 0;\n\n    // Step 1: Create the vector `a` using RVV intrinsics\n    uint64_t a[n];\n    size_t vl;\n    for (size_t i = 0; i < n; i += vl) {\n        vl = vsetvl_e64(n - i); // Set vector length\n        vuint64m1_t v_i = vid_v_u64m1(vl); // Create index vector [0, 1, 2, ...]\n        v_i = vadd_vx_u64m1(v_i, i + 1, vl); // Offset by i + 1 to get [i+1, i+2, ...]\n        vuint64m1_t v_a = vsub_vx_u64m1(vmul_vv_u64m1(v_i, v_i, vl), v_i, vl); // i*i - i\n        v_a = vadd_vx_u64m1(v_a, 1, vl); // i*i - i + 1\n        vse64_v_u64m1(&a[i], v_a, vl); // Store results in array `a`\n    }\n\n    // Step 2: Count the remainders of `a` modulo 3\n    uint64_t count[3] = {0, 0, 0};\n    for (size_t i = 0; i < n; i += vl) {\n        vl = vsetvl_e64(n - i);\n        vuint64m1_t v_a = vle64_v_u64m1(&a[i], vl);\n        vuint64m1_t v_rem = vrem_vx_u64m1(v_a, 3, vl); // Compute a[i] % 3\n        uint64_t temp[vl];\n        vse64_v_u64m1(temp, v_rem, vl);\n        for (size_t j = 0; j < vl; j++) {\n            count[temp[j]]++;\n        }\n    }\n\n    // Step 3: Calculate the number of valid triples\n    uint64_t result = 0;\n\n    // Case 1: All three numbers have remainder 0\n    if (count[0] >= 3) {\n        result += (count[0] * (count[0] - 1) * (count[0] - 2)) / 6;\n    }\n\n    // Case 2: All three numbers have remainder 1\n    if (count[1] >= 3) {\n        result += (count[1] * (count[1] - 1) * (count[1] - 2)) / 6;\n    }\n\n    // Case 3: All three numbers have remainder 2\n    if (count[2] >= 3) {\n        result += (count[2] * (count[2] - 1) * (count[2] - 2)) / 6;\n    }\n\n    // Case 4: One number from each remainder group (0, 1, 2)\n    result += count[0] * count[1] * count[2];\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_132_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nuint64_t get_max_triples_simd(uint64_t n) {\n    // Step 1: Create the vector `a` using RVV\n    uint64_t a[n];\n    size_t vlmax = vsetvlmax_e64m1(); // Maximum vector length for 64-bit integers\n    for (size_t i = 0; i < n; i += vlmax) {\n        size_t vl = vsetvl_e64m1(n - i); // Set vector length for the current iteration\n        vuint64m1_t idx = vid_v_u64m1(vl); // Create index vector [0, 1, 2, ...]\n        idx = vadd_vx_u64m1(idx, i, vl); // Offset index by `i`\n        vuint64m1_t squared = vmul_vv_u64m1(idx, idx, vl); // idx * idx\n        vuint64m1_t linear = vsub_vx_u64m1(squared, idx, vl); // idx * idx - idx\n        vuint64m1_t result = vadd_vx_u64m1(linear, 1, vl); // idx * idx - idx + 1\n        vse64_v_u64m1(&a[i], result, vl); // Store result back to array `a`\n    }\n\n    // Step 2: Count remainders modulo 3\n    uint64_t count[3] = {0, 0, 0};\n    for (size_t i = 0; i < n; i += vlmax) {\n        size_t vl = vsetvl_e64m1(n - i);\n        vuint64m1_t vec_a = vle64_v_u64m1(&a[i], vl); // Load vector from `a`\n        vuint64m1_t mod3 = vrem_vx_u64m1(vec_a, 3, vl); // Compute a[i] % 3\n        uint64_t temp[vlmax];\n        vse64_v_u64m1(temp, mod3, vl); // Store mod3 results to temp array\n        for (size_t j = 0; j < vl; j++) {\n            count[temp[j]]++; // Increment count for each remainder\n        }\n    }\n\n    // Step 3: Calculate the number of valid triples\n    uint64_t c0 = count[0], c1 = count[1], c2 = count[2];\n    uint64_t result = 0;\n\n    // Case 1: All three numbers have remainder 0\n    if (c0 >= 3) result += (c0 * (c0 - 1) * (c0 - 2)) / 6;\n\n    // Case 2: All three numbers have remainder 1\n    if (c1 >= 3) result += (c1 * (c1 - 1) * (c1 - 2)) / 6;\n\n    // Case 3: All three numbers have remainder 2\n    if (c2 >= 3) result += (c2 * (c2 - 1) * (c2 - 2)) / 6;\n\n    // Case 4: One number from each remainder group\n    result += c0 * c1 * c2;\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_132_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <stdint.h>\n\nuint64_t get_max_triples_simd(uint64_t n) {\n    if (n < 3) return 0;\n\n    // Step 1: Compute the array `a` using RVV intrinsics\n    uint64_t count_mod_0 = 0, count_mod_1 = 0, count_mod_2 = 0;\n\n    size_t vl;\n    for (size_t i = 1; i <= n; i += vl) {\n        vl = vsetvl_e64(n - i + 1); // Set vector length\n        vuint64m1_t idx = vid_v_u64m1(vl); // Index vector: [0, 1, 2, ..., vl-1]\n        idx = vadd_vx_u64m1(idx, i, vl); // Adjust index to start from `i`\n        vuint64m1_t a = vsub_vx_u64m1(vmul_vv_u64m1(idx, idx, vl), idx, vl); // i * i - i\n        a = vadd_vx_u64m1(a, 1, vl); // i * i - i + 1\n\n        // Compute a % 3 for each element\n        vuint64m1_t mod_3 = vrem_vx_u64m1(a, 3, vl);\n\n        // Count occurrences of mod 0, 1, 2\n        vbool64_t mask_0 = vmseq_vx_u64m1_b64(mod_3, 0, vl);\n        vbool64_t mask_1 = vmseq_vx_u64m1_b64(mod_3, 1, vl);\n        vbool64_t mask_2 = vmseq_vx_u64m1_b64(mod_3, 2, vl);\n\n        count_mod_0 += vcpop_b64(mask_0);\n        count_mod_1 += vcpop_b64(mask_1);\n        count_mod_2 += vcpop_b64(mask_2);\n    }\n\n    // Step 2: Calculate the number of valid triples\n    uint64_t result = 0;\n\n    // Case 1: All three numbers are divisible by 3\n    if (count_mod_0 >= 3) {\n        result += (count_mod_0 * (count_mod_0 - 1) * (count_mod_0 - 2)) / 6;\n    }\n\n    // Case 2: One number from each mod group (0, 1, 2)\n    result += count_mod_0 * count_mod_1 * count_mod_2;\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_132_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <stdint.h>\n\nuint64_t get_max_triples_simd(uint64_t n) {\n    if (n < 3) return 0;\n\n    // Step 1: Create the vector `a` using RVV intrinsics\n    size_t vl;\n    uint64_t count_mod[3] = {0, 0, 0}; // To store counts of a[i] % 3 == 0, 1, 2\n    uint64_t i = 1;\n\n    while (i <= n) {\n        vl = vsetvl_e64(n - i + 1); // Set vector length\n        vuint64m1_t idx = vid_v_u64m1(vl); // Create index vector\n        idx = vadd_vx_u64m1(idx, i, vl); // Adjust index to start from `i`\n\n        // Compute a[i] = i * i - i + 1\n        vuint64m1_t squared = vmul_vv_u64m1(idx, idx, vl); // i * i\n        vuint64m1_t linear = vsub_vx_u64m1(idx, 1, vl);    // i - 1\n        vuint64m1_t a = vsub_vv_u64m1(squared, linear, vl); // i * i - i + 1\n\n        // Compute a[i] % 3\n        vuint64m1_t mod3 = vrem_vx_u64m1(a, 3, vl);\n\n        // Count occurrences of each remainder\n        uint64_t temp[vl];\n        vse_v_u64m1(temp, mod3, vl);\n        for (size_t j = 0; j < vl; j++) {\n            count_mod[temp[j] % 3]++;\n        }\n\n        i += vl;\n    }\n\n    // Step 2: Calculate the number of valid triples\n    uint64_t count_0 = count_mod[0];\n    uint64_t count_1 = count_mod[1];\n    uint64_t count_2 = count_mod[2];\n\n    // Triples where all three are divisible by 3\n    uint64_t result = (count_0 * (count_0 - 1) * (count_0 - 2)) / 6;\n\n    // Triples where one from each group (1, 1, 1)\n    result += (count_1 * (count_1 - 1) * (count_1 - 2)) / 6;\n\n    // Triples where one from each group (2, 2, 2)\n    result += (count_2 * (count_2 - 1) * (count_2 - 2)) / 6;\n\n    // Triples where one from each group (0, 1, 2)\n    result += count_0 * count_1 * count_2;\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_132_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <stdint.h>\n\nuint64_t get_max_triples_simd(uint64_t n) {\n    if (n < 3) return 0;\n\n    // Step 1: Create the vector `a` using RVV intrinsics\n    uint64_t *a = (uint64_t *)malloc(n * sizeof(uint64_t));\n    size_t vlmax = vsetvlmax_e64m1(); // Maximum vector length for 64-bit elements\n    for (size_t i = 0; i < n; i += vlmax) {\n        size_t vl = vsetvl_e64m1(n - i); // Set vector length for the remaining elements\n        vuint64m1_t v_i = vid_v_u64m1(vl); // Create index vector [0, 1, 2, ..., vl-1]\n        v_i = vadd_vx_u64m1(v_i, i, vl);  // Adjust indices to start from `i`\n        vuint64m1_t v_squared = vmul_vv_u64m1(v_i, v_i, vl); // i * i\n        vuint64m1_t v_result = vsub_vx_u64m1(v_squared, v_i, vl); // i * i - i\n        v_result = vadd_vx_u64m1(v_result, 1, vl); // i * i - i + 1\n        vse64_v_u64m1(a + i, v_result, vl); // Store results in `a`\n    }\n\n    // Step 2: Count triples (a[i], a[j], a[k]) where i < j < k and sum is divisible by 3\n    uint64_t count = 0;\n    for (uint64_t i = 0; i < n; i++) {\n        for (uint64_t j = i + 1; j < n; j++) {\n            for (uint64_t k = j + 1; k < n; k++) {\n                if ((a[i] + a[j] + a[k]) % 3 == 0) {\n                    count++;\n                }\n            }\n        }\n    }\n\n    free(a);\n    return count;\n}\n```"}
{"task_id": "SimdBench_133_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nint x_or_y_simd(int n, int x, int y) {\n    if (n < 2) {\n        return y;\n    }\n\n    size_t vl;\n    int is_prime = 1;\n    for (int i = 2; i * i <= n; i += vl) {\n        vl = vsetvl_e32m1((n - i + 1) > 0 ? (n - i + 1) : 0);\n        vint32m1_t vec_i = vrgather_vx_i32m1(vundefined_i32m1(), i, vl);\n        vint32m1_t vec_n = vrgather_vx_i32m1(vundefined_i32m1(), n, vl);\n        vint32m1_t vec_mod = vmod_vv_i32m1(vec_n, vec_i, vl);\n        if (vfirst_m_b32(vmsne_vx_i32m1_b32(vec_mod, 0, vl)) != -1) {\n            is_prime = 0;\n            break;\n        }\n    }\n\n    return is_prime ? x : y;\n}\n```"}
{"task_id": "SimdBench_133_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nint x_or_y_simd(int n, int x, int y) {\n    size_t vl = vsetvl_e32m1(1); // Set vector length to 1 for scalar processing\n    vint32m1_t vn = vmv_v_x_i32m1(n, vl); // Vector register for n\n    vint32m1_t vx = vmv_v_x_i32m1(x, vl); // Vector register for x\n    vint32m1_t vy = vmv_v_x_i32m1(y, vl); // Vector register for y\n\n    // Check if n is prime\n    int is_prime = 1;\n    if (n <= 1) {\n        is_prime = 0;\n    } else {\n        for (int i = 2; i * i <= n; i++) {\n            if (n % i == 0) {\n                is_prime = 0;\n                break;\n            }\n        }\n    }\n\n    vint32m1_t vresult = is_prime ? vx : vy; // Select x if prime, y otherwise\n    return vmv_x_s_i32m1_i32(vresult); // Extract scalar result from vector register\n}\n```"}
{"task_id": "SimdBench_133_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nint x_or_y_simd(int n, int x, int y) {\n    if (n < 2) {\n        return y;\n    }\n\n    size_t vl;\n    int is_prime = 1;\n    for (int i = 2; i * i <= n; i += vsetvlmax_e32m1()) {\n        vl = vsetvl_e32m1(vsetvlmax_e32m1());\n        vint32m1_t indices = vadd_vx_i32m1(vmv_v_x_i32m1(i, vl), vslide1down_vx_i32m1(vmv_v_x_i32m1(0, vl), 1, vl), vl);\n        vint32m1_t n_vec = vmv_v_x_i32m1(n, vl);\n        vint32m1_t rem = vrem_vv_i32m1(n_vec, indices, vl);\n        vbool32_t is_zero = vmseq_vx_i32m1_b32(rem, 0, vl);\n        if (vfirst_m_b32(is_zero, vl) != -1) {\n            is_prime = 0;\n            break;\n        }\n    }\n\n    return is_prime ? x : y;\n}\n```"}
{"task_id": "SimdBench_133_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nint x_or_y_simd(int n, int x, int y) {\n    if (n < 2) return y;\n\n    size_t vlmax = vsetvlmax_e32m1();\n    vbool32_t is_not_prime = vbool32_t();\n\n    for (int i = 2; i * i <= n; i += vlmax) {\n        size_t vl = vsetvl_e32m1(vlmax);\n        vint32m1_t vec_i = vslide1up_vx_i32m1(vundefined_i32m1(), i, vl);\n        vint32m1_t vec_n = vmv_v_x_i32m1(n, vl);\n        vint32m1_t vec_mod = vrem_vv_i32m1(vec_n, vec_i, vl);\n        is_not_prime = vor_mm_b32(is_not_prime, vmseq_vx_i32m1_b32(vec_mod, 0, vl));\n    }\n\n    return vfirst_m_b32(is_not_prime) ? y : x;\n}\n```"}
{"task_id": "SimdBench_133_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nint x_or_y_simd(int n, int x, int y) {\n    if (n < 2) return y;\n\n    size_t vl = vsetvlmax_e32m1();\n    vint32m1_t indices = vundefined_e32m1();\n    indices = vrgather_vx_i32m1(indices, 0, vl);\n\n    vint32m1_t vec_n = vmv_v_x_i32m1(n, vl);\n    vint32m1_t vec_i = vadd_vx_i32m1(indices, 2, vl); // i = [2, 3, 4, ...]\n\n    vbool32_t is_divisible = vmseq_vv_i32m1_b32(vrem_vv_i32m1(vec_n, vec_i, vl), vmv_v_x_i32m1(0, vl), vl);\n    int prime = !vfirst_m_b32(is_divisible, vl);\n\n    return prime ? x : y;\n}\n```"}
{"task_id": "SimdBench_134_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <cstdint>\n\nuint64_t double_the_difference_simd(const std::vector<float> &lst) {\n    size_t n = lst.size();\n    if (n == 0) return 0;\n\n    uint64_t result = 0;\n    size_t vlmax = vsetvlmax_e32m1(); // Maximum vector length for 32-bit elements\n    size_t i = 0;\n\n    while (i < n) {\n        size_t vl = vsetvl_e32m1(n - i); // Set vector length for remaining elements\n        vfloat32m1_t v = vle32_v_f32m1(&lst[i], vl); // Load vector elements\n        vbool32_t mask_positive = vmflt_vf_f32m1_b32(v, 0.0f, vl); // Mask for negative values\n        vbool32_t mask_odd = vmandnot_mm_b32(mask_positive, vmfne_vf_f32m1_b32(v, 0.0f, vl)); // Mask for odd integers\n        vint32m1_t v_int = vfcvt_x_f_v_i32m1(v, vl); // Convert floats to integers\n        vint32m1_t v_squared = vmul_vv_i32m1(v_int, v_int, vl); // Square the integers\n        vint32m1_t v_masked = vmerge_vvm_i32m1(mask_odd, v_squared, vmv_v_x_i32m1(0, vl), vl); // Apply mask\n        result += vredsum_vs_i32m1_i32m1(v_masked, vmv_v_x_i32m1(0, vl), vl); // Reduce sum\n        i += vl;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_134_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <cmath>\n#include <cstdint>\n\nuint64_t double_the_difference_simd(const std::vector<float> &lst) {\n    size_t n = lst.size();\n    if (n == 0) return 0;\n\n    uint64_t result = 0;\n    size_t vlmax = vsetvlmax_e32m1(); // Maximum vector length for 32-bit elements\n    size_t i = 0;\n\n    while (i < n) {\n        size_t vl = vsetvl_e32m1(n - i); // Set vector length based on remaining elements\n        vfloat32m1_t vec = vle32_v_f32m1(&lst[i], vl); // Load vector of floats\n        vint32m1_t vec_int = vfcvt_x_f_v_i32m1(vec, vl); // Convert floats to integers\n        vbool32_t mask_odd = vmseq_vx_i32m1_b32(vand_vx_i32m1(vec_int, 1, vl), 1, vl); // Mask for odd integers\n        vbool32_t mask_positive = vmgt_vx_i32m1_b32(vec_int, 0, vl); // Mask for positive integers\n        vbool32_t mask = vmand_mm_b32(mask_odd, mask_positive, vl); // Combine masks\n\n        vint32m1_t vec_squared = vmul_vv_i32m1(vec_int, vec_int, vl); // Square the integers\n        vint32m1_t vec_masked = vmerge_vxm_i32m1(vmv_v_x_i32m1(0, vl), vec_squared, mask, vl); // Apply mask\n        result += vredsum_vs_i32m1_i32m1(vmv_v_x_i32m1(0, vl), vec_masked, vmv_v_x_i32m1(0, vl), vl); // Reduce sum\n\n        i += vl;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_134_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <cmath>\n#include <cstdint>\n\nuint64_t double_the_difference_simd(const std::vector<float> &lst) {\n    size_t n = lst.size();\n    if (n == 0) return 0;\n\n    uint64_t result = 0;\n    size_t vl;\n    size_t i = 0;\n\n    while (i < n) {\n        vl = vsetvl_e32m1(n - i); // Set vector length for 32-bit elements\n        vfloat32m1_t vec = vle32_v_f32m1(&lst[i], vl); // Load a chunk of the input vector\n\n        // Convert to integers\n        vint32m1_t int_vec = vfcvt_x_f_v_i32m1(vec, vl);\n\n        // Check if the numbers are odd and positive\n        vint32m1_t odd_mask = vand_vx_i32m1(int_vec, 1, vl); // Mask for odd numbers\n        vint32m1_t positive_mask = vmsgt_vx_i32m1(int_vec, 0, vl); // Mask for positive numbers\n        vbool32_t valid_mask = vmseq_vx_i32m1_b32(odd_mask, 1, vl); // Odd numbers mask\n        valid_mask = vmand_mm_b32(valid_mask, positive_mask, vl); // Combine with positive mask\n\n        // Compute squares of valid numbers\n        vint32m1_t squared = vmul_vv_i32m1(int_vec, int_vec, vl);\n\n        // Mask out invalid numbers\n        vint32m1_t masked_squares = vmv_v_x_i32m1(0, vl); // Initialize masked squares to 0\n        masked_squares = vmerge_vvm_i32m1(masked_squares, squared, valid_mask, vl);\n\n        // Sum up the valid squares\n        result += vredsum_vs_i32m1_i32(masked_squares, masked_squares, 0, vl);\n\n        i += vl; // Move to the next chunk\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_134_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <cmath>\n#include <cstdint>\n\nuint64_t double_the_difference_simd(const std::vector<float> &lst) {\n    size_t n = lst.size();\n    if (n == 0) return 0;\n\n    uint64_t result = 0;\n    size_t vlmax = vsetvlmax_e32m1(); // Maximum vector length for 32-bit elements\n    size_t i = 0;\n\n    while (i < n) {\n        size_t vl = vsetvl_e32m1(n - i); // Set vector length based on remaining elements\n        vfloat32m1_t vec = vle32_v_f32m1(&lst[i], vl); // Load vector of floats\n        vint32m1_t vec_int = vfcvt_x_f_v_i32m1(vec, vl); // Convert floats to integers\n        vbool32_t mask_odd = vmseq_vx_i32m1_b32(vand_vx_i32m1(vec_int, 1, vl), 1, vl); // Mask for odd integers\n        vbool32_t mask_positive = vmsgt_vx_i32m1_b32(vec_int, 0, vl); // Mask for positive integers\n        vbool32_t mask = vmand_mm_b32(mask_odd, mask_positive, vl); // Combine masks\n\n        vint32m1_t vec_squared = vmul_vv_i32m1(vec_int, vec_int, vl); // Square the integers\n        vint32m1_t vec_masked = vmerge_vxm_i32m1(vundefined_i32m1(), vec_squared, mask, vl); // Apply mask\n\n        int32_t temp[vlmax];\n        vse32_v_i32m1(temp, vec_masked, vl); // Store masked results\n\n        for (size_t j = 0; j < vl; j++) {\n            result += temp[j];\n        }\n\n        i += vl;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_134_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <cstdint>\n\nuint64_t double_the_difference_simd(const std::vector<float> &lst) {\n    size_t n = lst.size();\n    if (n == 0) return 0;\n\n    uint64_t result = 0;\n    size_t vlmax = vsetvlmax_e32m1(); // Maximum vector length for 32-bit elements\n    size_t i = 0;\n\n    while (i < n) {\n        size_t vl = vsetvl_e32m1(n - i); // Set vector length based on remaining elements\n        vfloat32m1_t v_input = vle32_v_f32m1(&lst[i], vl); // Load vector of floats\n        vbool32_t v_is_odd = vmfgt_vf_f32m1_b32(v_input, 0.0f, vl); // Check if elements are > 0\n        vuint32m1_t v_ints = vfcvt_x_f_v_u32m1(v_input, vl); // Convert floats to integers\n        vuint32m1_t v_squared = vmul_vv_u32m1(v_ints, v_ints, vl); // Square the integers\n        vuint32m1_t v_masked = vmerge_vvm_u32m1(v_is_odd, v_squared, vmv_v_x_u32m1(0, vl), vl); // Apply mask\n        result += vredsum_vs_u32m1_u32m1(v_masked, vmv_v_x_u32m1(0, vl), vl); // Reduce sum\n        i += vl;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_135_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <cstdlib>\n\nstd::vector<int> compare_simd(const std::vector<int>& game, const std::vector<int>& guess) {\n    size_t n = game.size();\n    std::vector<int> result(n);\n\n    size_t vlmax = vsetvlmax_e32m1(); // Maximum vector length for 32-bit integers\n    size_t i = 0;\n\n    while (i < n) {\n        size_t vl = vsetvl_e32m1(n - i); // Set vector length based on remaining elements\n        vint32m1_t vgame = vle32_v_i32m1(&game[i], vl); // Load game scores\n        vint32m1_t vguess = vle32_v_i32m1(&guess[i], vl); // Load guesses\n\n        vint32m1_t vdiff = vsub_vv_i32m1(vgame, vguess, vl); // Subtract game - guess\n        vint32m1_t vabs_diff = vabs_v_i32m1(vdiff, vl); // Compute absolute difference\n\n        vse32_v_i32m1(&result[i], vabs_diff, vl); // Store result\n        i += vl; // Move to the next chunk\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_135_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <cmath>\n\nstd::vector<int> compare_simd(const std::vector<int>& game, const std::vector<int>& guess) {\n    size_t n = game.size();\n    std::vector<int> result(n);\n\n    size_t vlmax = vsetvlmax_e32m1(); // Maximum vector length for int32\n    size_t i = 0;\n\n    while (i < n) {\n        size_t vl = vsetvl_e32m1(n - i); // Set vector length dynamically based on remaining elements\n\n        vint32m1_t game_vec = vle32_v_i32m1(&game[i], vl); // Load game scores\n        vint32m1_t guess_vec = vle32_v_i32m1(&guess[i], vl); // Load guesses\n\n        vint32m1_t diff_vec = vsub_vv_i32m1(game_vec, guess_vec, vl); // Compute difference\n        vint32m1_t abs_diff_vec = vabs_v_i32m1(diff_vec, vl); // Compute absolute difference\n\n        vse32_v_i32m1(&result[i], abs_diff_vec, vl); // Store result\n\n        i += vl; // Move to the next chunk\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_135_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <cmath>\n\nstd::vector<int> compare_simd(const std::vector<int>& game, const std::vector<int>& guess) {\n    size_t n = game.size();\n    std::vector<int> result(n);\n\n    size_t vlmax = vsetvlmax_e32m1(); // Maximum vector length for int32\n    size_t i = 0;\n\n    while (i < n) {\n        size_t vl = vsetvl_e32m1(n - i); // Set vector length based on remaining elements\n        vint32m1_t vgame = vle32_v_i32m1(&game[i], vl); // Load game scores\n        vint32m1_t vguess = vle32_v_i32m1(&guess[i], vl); // Load guesses\n\n        vint32m1_t vdiff = vsub_vv_i32m1(vgame, vguess, vl); // Compute difference\n        vdiff = vabs_v_i32m1(vdiff, vl); // Take absolute value of the difference\n\n        vse32_v_i32m1(&result[i], vdiff, vl); // Store result\n        i += vl; // Move to the next chunk\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_135_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <cmath>\n\nstd::vector<int> compare_simd(const std::vector<int>& game, const std::vector<int>& guess) {\n    size_t n = game.size();\n    std::vector<int> result(n);\n\n    size_t vlmax = vsetvlmax_e32m1(); // Maximum vector length for int32\n    size_t i = 0;\n\n    while (i < n) {\n        size_t vl = vsetvl_e32m1(n - i); // Set vector length based on remaining elements\n\n        vint32m1_t game_vec = vle32_v_i32m1(&game[i], vl);   // Load game scores\n        vint32m1_t guess_vec = vle32_v_i32m1(&guess[i], vl); // Load guesses\n\n        vint32m1_t diff_vec = vsub_vv_i32m1(game_vec, guess_vec, vl); // Compute difference\n        vint32m1_t abs_diff_vec = vabs_v_i32m1(diff_vec, vl);         // Compute absolute difference\n\n        vse32_v_i32m1(&result[i], abs_diff_vec, vl); // Store result\n\n        i += vl; // Move to the next chunk\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_135_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <cstdlib>\n\nstd::vector<int> compare_simd(const std::vector<int>& game, const std::vector<int>& guess) {\n    size_t n = game.size();\n    std::vector<int> result(n);\n\n    size_t vlmax = vsetvlmax_e32m1(); // Maximum vector length for 32-bit integers\n    size_t i = 0;\n\n    while (i < n) {\n        size_t vl = vsetvl_e32m1(n - i); // Set vector length based on remaining elements\n        vint32m1_t vgame = vle32_v_i32m1(&game[i], vl); // Load game scores\n        vint32m1_t vguess = vle32_v_i32m1(&guess[i], vl); // Load guesses\n        vint32m1_t vdiff = vsub_vv_i32m1(vgame, vguess, vl); // Compute difference\n        vint32m1_t vabs_diff = vabs_v_i32m1(vdiff, vl); // Compute absolute difference\n        vse32_v_i32m1(&result[i], vabs_diff, vl); // Store result\n        i += vl; // Move to the next chunk\n    }\n\n    return result;\n}\n```"}

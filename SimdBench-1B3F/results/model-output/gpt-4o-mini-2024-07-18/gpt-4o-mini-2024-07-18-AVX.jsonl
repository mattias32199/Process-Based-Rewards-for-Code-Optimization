{"task_id": "SimdBench_0_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid conditional_move_simd(const int64_t *src, int64_t *dst, const bool *mask, size_t length) {\n    size_t i = 0;\n    __m256i zero = _mm256_setzero_si256();\n\n    for (; i <= length - 4; i += 4) {\n        __m256i src_vec = _mm256_loadu_si256((__m256i*)&src[i]);\n        __m256i mask_vec = _mm256_loadu_si256((__m256i*)&mask[i]);\n\n        // Convert mask from bool to int (0 or 1)\n        __m256i mask_int = _mm256_and_si256(mask_vec, _mm256_set1_epi64x(1));\n\n        // Create a vector of 64-bit integers where the mask is applied\n        __m256i result = _mm256_blendv_epi8(zero, src_vec, mask_int);\n\n        _mm256_storeu_si256((__m256i*)&dst[i], result);\n    }\n\n    // Handle remaining elements\n    for (; i < length; ++i) {\n        if (mask[i]) {\n            dst[i] = src[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_0_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid conditional_move_simd(const int64_t *src, int64_t *dst, const bool *mask, size_t length) {\n    size_t i = 0;\n\n    // Process 4 elements at a time\n    for (; i + 4 <= length; i += 4) {\n        __m256i src_vec = _mm256_loadu_si256((__m256i*)&src[i]);\n        __m256i mask_vec = _mm256_loadu_si256((__m256i*)&mask[i]);\n\n        // Create a mask for the boolean values\n        __m256i mask_mask = _mm256_cmpeq_epi64(mask_vec, _mm256_set1_epi64x(1));\n\n        // Conditional move\n        __m256i result_vec = _mm256_blendv_epi8(_mm256_setzero_si256(), src_vec, mask_mask);\n\n        _mm256_storeu_si256((__m256i*)&dst[i], result_vec);\n    }\n\n    // Handle remaining elements\n    for (; i < length; i++) {\n        if (mask[i]) {\n            dst[i] = src[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_0_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid conditional_move_simd(const int64_t *src, int64_t *dst, const bool *mask, size_t length) {\n    size_t i = 0;\n    // Process 4 elements at a time\n    for (; i + 4 <= length; i += 4) {\n        __m256i src_vec = _mm256_loadu_si256((__m256i*)&src[i]);\n        __m128 mask_vec_low = _mm_loadu_ps((const float*)&mask[i]);\n        __m128 mask_vec_high = _mm_loadu_ps((const float*)&mask[i + 4]);\n\n        __m256i mask_vec = _mm256_set_epi64x(mask_vec_high[3] ? -1 : 0, mask_vec_high[2] ? -1 : 0, mask_vec_high[1] ? -1 : 0, mask_vec_high[0] ? -1 : 0);\n        mask_vec = _mm256_blend_epi16(mask_vec, _mm256_setzero_si256(), 0x0F); // Zero out the upper half\n\n        __m256i result = _mm256_blendv_epi8(_mm256_setzero_si256(), src_vec, mask_vec);\n        _mm256_storeu_si256((__m256i*)&dst[i], result);\n    }\n    // Handle remaining elements\n    for (; i < length; i++) {\n        if (mask[i]) {\n            dst[i] = src[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_0_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid conditional_move_simd(const int64_t *src, int64_t *dst, const bool *mask, size_t length) {\n    size_t i = 0;\n    // Process 4 elements at a time\n    for (; i + 4 <= length; i += 4) {\n        __m256i src_vec = _mm256_loadu_si256((__m256i*)&src[i]);\n        __m128 mask_vec_low = _mm_loadu_ps((const float*)&mask[i]);\n        __m128 mask_vec_high = _mm_loadu_ps((const float*)&mask[i + 4]);\n\n        __m256i mask_avx = _mm256_set_m128(mask_vec_high, mask_vec_low);\n        __m256i mask_cmp = _mm256_cmpeq_epi64(mask_avx, _mm256_set1_epi64x(1));\n\n        __m256i result = _mm256_blendv_epi8(_mm256_setzero_si256(), src_vec, mask_cmp);\n        _mm256_storeu_si256((__m256i*)&dst[i], result);\n    }\n    // Handle remaining elements\n    for (; i < length; i++) {\n        if (mask[i]) {\n            dst[i] = src[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_0_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid conditional_move_simd(const int64_t *src, int64_t *dst, const bool *mask, size_t length) {\n    size_t i = 0;\n    // Process 4 elements at a time\n    for (; i + 4 <= length; i += 4) {\n        __m256i src_vec = _mm256_loadu_si256((__m256i*)&src[i]);\n        __m128 mask_vec_low = _mm_loadu_ps((const float*)&mask[i]);\n        __m128 mask_vec_high = _mm_loadu_ps((const float*)&mask[i + 2]);\n\n        __m256i mask_vec = _mm256_set_m128(mask_vec_high, mask_vec_low);\n        __m256i mask_cmp = _mm256_cmpgt_epi64(mask_vec, _mm256_setzero_si256());\n\n        __m256i result = _mm256_blendv_epi8(_mm256_setzero_si256(), src_vec, mask_cmp);\n        _mm256_storeu_si256((__m256i*)&dst[i], result);\n    }\n\n    // Handle remaining elements\n    for (; i < length; i++) {\n        if (mask[i]) {\n            dst[i] = src[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_1_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid load_modify_store_simd(const int *src, int *dst, int scale, size_t length) {\n    size_t i = 0;\n    __m256i scale_vec = _mm256_set1_epi32(scale);\n    __m256i divisor = _mm256_set1_epi32(7);\n\n    for (; i <= length - 8; i += 8) {\n        __m256i src_vec = _mm256_loadu_si256((__m256i*)&src[i]);\n        __m256i tmp1 = _mm256_srai_epi32(_mm256_mullo_epi32(src_vec, scale_vec), 3);\n        __m256i tmp2 = _mm256_slli_epi32(_mm256_mullo_epi32(src_vec, scale_vec), 3);\n        __m256i result = _mm256_add_epi32(_mm256_mullo_epi32(src_vec, scale_vec), _mm256_mullo_epi32(tmp1, tmp2));\n        result = _mm256_div_epi32(result, divisor);\n        _mm256_storeu_si256((__m256i*)&dst[i], result);\n    }\n\n    for (; i < length; i++) {\n        dst[i] = (src[i] * scale + ((src[i] * scale) >> 3) * ((src[i] * scale) << 3)) / 7;\n    }\n}\n```"}
{"task_id": "SimdBench_1_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid load_modify_store_simd(const int *src, int *dst, int scale, size_t length) {\n    size_t i;\n    __m256i vec_scale = _mm256_set1_epi32(scale);\n    \n    for (i = 0; i < length; i += 8) {\n        __m256i vec_src = _mm256_loadu_si256((__m256i*)&src[i]);\n        __m256i vec_tmp1 = _mm256_srai_epi32(_mm256_mullo_epi32(vec_src, vec_scale), 3);\n        __m256i vec_tmp2 = _mm256_slli_epi32(_mm256_mullo_epi32(vec_src, vec_scale), 3);\n        __m256i vec_result = _mm256_add_epi32(_mm256_mullo_epi32(vec_tmp1, vec_tmp2), _mm256_mullo_epi32(vec_src, vec_scale));\n        vec_result = _mm256_div_epi32(vec_result, _mm256_set1_epi32(7));\n        _mm256_storeu_si256((__m256i*)&dst[i], vec_result);\n    }\n}\n```"}
{"task_id": "SimdBench_1_AVX", "completion": "```cpp\nvoid load_modify_store_simd(const int *src, int *dst, int scale, size_t length) {\n    __m256i scale_vec = _mm256_set1_epi32(scale);\n    size_t i;\n\n    for (i = 0; i < length / 8; i++) {\n        __m256i src_vec = _mm256_loadu_si256((__m256i*)&src[i * 8]);\n        \n        __m256i scaled_vec = _mm256_mullo_epi32(src_vec, scale_vec);\n        __m256i tmp1 = _mm256_srai_epi32(scaled_vec, 3);\n        __m256i tmp2 = _mm256_slli_epi32(scaled_vec, 3);\n        \n        __m256i result = _mm256_add_epi32(scaled_vec, _mm256_mullo_epi32(tmp1, tmp2));\n        result = _mm256_div_epi32(result, _mm256_set1_epi32(7));\n        \n        _mm256_storeu_si256((__m256i*)&dst[i * 8], result);\n    }\n\n    for (; i < length; i++) {\n        dst[i] = (src[i] * scale + ((src[i] * scale) >> 3) * ((src[i] * scale) << 3)) / 7;\n    }\n}\n```"}
{"task_id": "SimdBench_1_AVX", "completion": "```cpp\nvoid load_modify_store_simd(const int *src, int *dst, int scale, size_t length) {\n    __m256i scale_vec = _mm256_set1_epi32(scale);\n    size_t i;\n    \n    for (i = 0; i < length; i += 8) {\n        __m256i src_vec = _mm256_loadu_si256((__m256i*)&src[i]);\n        \n        __m256i scaled_vec = _mm256_mullo_epi32(src_vec, scale_vec);\n        __m256i tmp1 = _mm256_srai_epi32(scaled_vec, 3);\n        __m256i tmp2 = _mm256_slli_epi32(scaled_vec, 3);\n        \n        __m256i result = _mm256_add_epi32(scaled_vec, _mm256_mullo_epi32(tmp1, tmp2));\n        result = _mm256_div_epi32(result, _mm256_set1_epi32(7));\n        \n        _mm256_storeu_si256((__m256i*)&dst[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_1_AVX", "completion": "```cpp\nvoid load_modify_store_simd(const int *src, int *dst, int scale, size_t length) {\n    __m256i scale_vec = _mm256_set1_epi32(scale);\n    size_t i;\n\n    for (i = 0; i < length / 8; i++) {\n        __m256i src_vec = _mm256_loadu_si256((__m256i*)&src[i * 8]);\n        __m256i scaled_vec = _mm256_mullo_epi32(src_vec, scale_vec);\n        \n        __m256i tmp1 = _mm256_srai_epi32(scaled_vec, 3);\n        __m256i tmp2 = _mm256_slli_epi32(scaled_vec, 3);\n        \n        __m256i result = _mm256_add_epi32(scaled_vec, _mm256_mullo_epi32(tmp1, tmp2));\n        result = _mm256_div_epi32(result, _mm256_set1_epi32(7));\n        \n        _mm256_storeu_si256((__m256i*)&dst[i * 8], result);\n    }\n\n    for (; i < length; i++) {\n        dst[i] = (src[i] * scale + ((src[i] * scale) >> 3) * ((src[i] * scale) << 3)) / 7;\n    }\n}\n```"}
{"task_id": "SimdBench_2_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid strided_load_store_simd(const double *src, double *dst, size_t rows, size_t cols, size_t stride) {\n    size_t i = 0;\n    __m256d vec;\n\n    for (; i <= rows - 4; i += 4) {\n        vec = _mm256_loadu_pd(&src[(i * cols) + stride]);\n        _mm256_storeu_pd(&dst[i], vec);\n    }\n\n    for (; i < rows; ++i) {\n        dst[i] = src[(i * cols) + stride];\n    }\n}\n```"}
{"task_id": "SimdBench_2_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid strided_load_store_simd(const double *src, double *dst, size_t rows, size_t cols, size_t stride) {\n    size_t i = 0;\n    __m256d vec;\n\n    for (; i <= rows - 4; i += 4) {\n        vec = _mm256_loadu_pd(&src[(i * cols) + stride]);\n        _mm256_storeu_pd(&dst[i], vec);\n    }\n\n    for (; i < rows; ++i) {\n        dst[i] = src[(i * cols) + stride];\n    }\n}\n```"}
{"task_id": "SimdBench_2_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid strided_load_store_simd(const double *src, double *dst, size_t rows, size_t cols, size_t stride) {\n    size_t i = 0;\n    __m256d vec;\n\n    for (; i <= rows - 4; i += 4) {\n        vec = _mm256_loadu_pd(&src[(i * cols) + stride]);\n        _mm256_storeu_pd(&dst[i], vec);\n    }\n\n    for (; i < rows; ++i) {\n        dst[i] = src[(i * cols) + stride];\n    }\n}\n```"}
{"task_id": "SimdBench_2_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid strided_load_store_simd(const double *src, double *dst, size_t rows, size_t cols, size_t stride) {\n    size_t i = 0;\n    __m256d vec;\n\n    for (; i <= rows - 4; i += 4) {\n        vec = _mm256_loadu_pd(&src[(i * cols) + stride]);\n        _mm256_storeu_pd(&dst[i], vec);\n    }\n\n    for (; i < rows; ++i) {\n        dst[i] = src[(i * cols) + stride];\n    }\n}\n```"}
{"task_id": "SimdBench_2_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid strided_load_store_simd(const double *src, double *dst, size_t rows, size_t cols, size_t stride) {\n    size_t i = 0;\n    __m256d vec;\n\n    for (; i <= rows - 4; i += 4) {\n        vec = _mm256_loadu_pd(&src[(i * cols) + stride]);\n        _mm256_storeu_pd(&dst[i], vec);\n    }\n\n    for (; i < rows; ++i) {\n        dst[i] = src[(i * cols) + stride];\n    }\n}\n```"}
{"task_id": "SimdBench_3_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid indexed_access_simd(const float *src, const int *indices, float *dst, size_t length) {\n    size_t i = 0;\n\n    // Gather operation\n    for (; i + 8 <= length; i += 8) {\n        __m256i idx = _mm256_loadu_si256((__m256i*)&indices[i]);\n        __m256 gathered = _mm256_i32gather_ps(src, idx, 4);\n        _mm256_storeu_ps(&dst[i], gathered);\n    }\n\n    // Handle remaining elements for gather\n    for (; i < length; i++) {\n        dst[i] = src[indices[i]];\n    }\n\n    // Scatter operation\n    for (i = 0; i + 8 <= length; i += 8) {\n        __m256i idx = _mm256_loadu_si256((__m256i*)&indices[i]);\n        __m256 values = _mm256_loadu_ps(&src[i]);\n        _mm256_i32scatter_ps(dst, idx, values, 4);\n    }\n\n    // Handle remaining elements for scatter\n    for (; i < length; i++) {\n        dst[indices[i]] = src[i];\n    }\n}\n```"}
{"task_id": "SimdBench_3_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid indexed_access_simd(const float *src, const int *indices, float *dst, size_t length) {\n    size_t i = 0;\n\n    // Gather operation\n    for (; i + 8 <= length; i += 8) {\n        __m256i idx = _mm256_loadu_si256((__m256i*)&indices[i]);\n        __m256 gathered = _mm256_i32gather_ps(src, idx, 4);\n        _mm256_storeu_ps(&dst[i], gathered);\n    }\n\n    // Scatter operation\n    for (size_t j = 0; j < length; j++) {\n        int index = indices[j];\n        _mm256_storeu_ps(&dst[index], _mm256_loadu_ps(&src[j]));\n    }\n}\n```"}
{"task_id": "SimdBench_3_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid indexed_access_simd(const float *src, const int *indices, float *dst, size_t length) {\n    size_t i = 0;\n\n    // Gather operation\n    for (; i + 8 <= length; i += 8) {\n        __m256i idx = _mm256_loadu_si256((__m256i*)&indices[i]);\n        __m256 gathered = _mm256_i32gather_ps(src, idx, 4);\n        _mm256_storeu_ps(&dst[i], gathered);\n    }\n\n    // Handle remaining elements for gather\n    for (; i < length; i++) {\n        dst[i] = src[indices[i]];\n    }\n\n    // Scatter operation\n    for (i = 0; i + 8 <= length; i += 8) {\n        __m256i idx = _mm256_loadu_si256((__m256i*)&indices[i]);\n        __m256 values = _mm256_loadu_ps(&src[i]);\n        _mm256_i32scatter_ps(dst, idx, values, 4);\n    }\n\n    // Handle remaining elements for scatter\n    for (; i < length; i++) {\n        dst[indices[i]] = src[i];\n    }\n}\n```"}
{"task_id": "SimdBench_3_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid indexed_access_simd(const float *src, const int *indices, float *dst, size_t length) {\n    size_t i = 0;\n\n    // Gather operation\n    for (; i + 8 <= length; i += 8) {\n        __m256i idx = _mm256_loadu_si256((__m256i*)&indices[i]);\n        __m256 gathered = _mm256_i32gather_ps(src, idx, 4);\n        _mm256_storeu_ps(&dst[i], gathered);\n    }\n\n    // Handle remaining elements for gather\n    for (; i < length; i++) {\n        dst[i] = src[indices[i]];\n    }\n\n    i = 0;\n\n    // Scatter operation\n    for (; i + 8 <= length; i += 8) {\n        __m256i idx = _mm256_loadu_si256((__m256i*)&indices[i]);\n        __m256 values = _mm256_loadu_ps(&src[i]);\n        _mm256_i32scatter_ps(dst, idx, values, 4);\n    }\n\n    // Handle remaining elements for scatter\n    for (; i < length; i++) {\n        dst[indices[i]] = src[i];\n    }\n}\n```"}
{"task_id": "SimdBench_3_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid indexed_access_simd(const float *src, const int *indices, float *dst, size_t length) {\n    size_t i = 0;\n\n    // Gather operation\n    for (; i + 8 <= length; i += 8) {\n        __m256i idx = _mm256_loadu_si256((__m256i*)&indices[i]);\n        __m256 gathered = _mm256_i32gather_ps(src, idx, 4);\n        _mm256_storeu_ps(&dst[i], gathered);\n    }\n\n    // Scatter operation\n    for (size_t j = 0; j < length; j++) {\n        int index = indices[j];\n        _mm256_storeu_ps(&dst[index], _mm256_loadu_ps(&src[j]));\n    }\n}\n```"}
{"task_id": "SimdBench_4_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid range_reverse_simd(int16_t *arr, uint64_t start, uint64_t end) {\n    uint64_t len = end - start + 1;\n    uint64_t half_len = len / 2;\n\n    for (uint64_t i = 0; i < half_len; i += 8) {\n        __m128i left = _mm_loadu_si128((__m128i*)&arr[start + i]);\n        __m128i right = _mm_loadu_si128((__m128i*)&arr[end - i]);\n\n        _mm_storeu_si128((__m128i*)&arr[start + i], right);\n        _mm_storeu_si128((__m128i*)&arr[end - i], left);\n    }\n\n    if (len % 2 != 0 && half_len * 2 < len) {\n        arr[start + half_len] = arr[end - half_len];\n    }\n}\n```"}
{"task_id": "SimdBench_4_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid range_reverse_simd(int16_t *arr, uint64_t start, uint64_t end) {\n    uint64_t len = end - start + 1;\n    uint64_t half_len = len / 2;\n\n    for (uint64_t i = 0; i < half_len; i += 8) {\n        __m128i vec1 = _mm_loadu_si128((__m128i*)&arr[start + i]);\n        __m128i vec2 = _mm_loadu_si128((__m128i*)&arr[end - i]);\n\n        _mm_storeu_si128((__m128i*)&arr[start + i], vec2);\n        _mm_storeu_si128((__m128i*)&arr[end - i], vec1);\n    }\n\n    if (len % 2 != 0 && half_len * 2 < len) {\n        arr[start + half_len] = arr[end - half_len];\n    }\n}\n```"}
{"task_id": "SimdBench_4_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid range_reverse_simd(int16_t *arr, uint64_t start, uint64_t end) {\n    uint64_t len = end - start + 1;\n    uint64_t half_len = len / 2;\n\n    for (uint64_t i = 0; i < half_len; i += 8) {\n        __m128i vec1 = _mm_loadu_si128((__m128i*)&arr[start + i]);\n        __m128i vec2 = _mm_loadu_si128((__m128i*)&arr[end - i]);\n\n        _mm_storeu_si128((__m128i*)&arr[start + i], vec2);\n        _mm_storeu_si128((__m128i*)&arr[end - i], vec1);\n    }\n\n    if (len % 2 != 0 && len > 0) {\n        arr[start + half_len] = arr[end - half_len];\n    }\n}\n```"}
{"task_id": "SimdBench_4_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid range_reverse_simd(int16_t *arr, uint64_t start, uint64_t end) {\n    while (start < end) {\n        __m128i vec_start = _mm_loadu_si128((__m128i*)&arr[start]);\n        __m128i vec_end = _mm_loadu_si128((__m128i*)&arr[end - 1]);\n\n        // Swap elements\n        _mm_storeu_si128((__m128i*)&arr[start], vec_end);\n        _mm_storeu_si128((__m128i*)&arr[end - 1], vec_start);\n\n        start += 8;\n        end -= 8;\n    }\n\n    // Handle the case where the range is not a multiple of 8\n    for (; start < end; ++start, --end) {\n        int16_t temp = arr[start];\n        arr[start] = arr[end];\n        arr[end] = temp;\n    }\n}\n```"}
{"task_id": "SimdBench_4_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid range_reverse_simd(int16_t *arr, uint64_t start, uint64_t end) {\n    while (start < end) {\n        __m128i vec_start = _mm_loadu_si128((__m128i*)&arr[start]);\n        __m128i vec_end = _mm_loadu_si128((__m128i*)&arr[end - 1]);\n\n        // Reverse the elements\n        _mm_storeu_si128((__m128i*)&arr[start], vec_end);\n        _mm_storeu_si128((__m128i*)&arr[end - 1], vec_start);\n\n        start += 8; // Process 8 elements at a time\n        end -= 8;\n    }\n\n    // Handle any remaining elements if the range is not a multiple of 8\n    for (; start < end; ++start, --end) {\n        int16_t temp = arr[start];\n        arr[start] = arr[end];\n        arr[end] = temp;\n    }\n}\n```"}
{"task_id": "SimdBench_5_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid extract_tensor_slice_simd(const uint8_t *tensor, uint8_t *slice, size_t dim1, size_t dim2, size_t dim3, size_t slice_idx) {\n    size_t slice_offset = slice_idx * dim1 * dim2;\n    size_t total_elements = dim1 * dim2;\n\n    for (size_t i = 0; i < total_elements; i += 32) {\n        __m256i data1 = _mm256_loadu_si256((__m256i*)&tensor[slice_offset + i]);\n        __m256i data2 = _mm256_loadu_si256((__m256i*)&tensor[slice_offset + i + 16]);\n        _mm256_storeu_si256((__m256i*)&slice[i], data1);\n        _mm256_storeu_si256((__m256i*)&slice[i + 16], data2);\n    }\n}\n```"}
{"task_id": "SimdBench_5_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid extract_tensor_slice_simd(const uint8_t *tensor, uint8_t *slice, size_t dim1, size_t dim2, size_t dim3, size_t slice_idx) {\n    size_t slice_offset = slice_idx * dim1 * dim2;\n    size_t row_size = dim2;\n\n    for (size_t i = 0; i < dim1; i++) {\n        const uint8_t *src = tensor + slice_offset + i * dim3;\n        uint8_t *dst = slice + i * row_size;\n\n        size_t j = 0;\n        for (; j + 32 <= row_size; j += 32) {\n            __m256i v1 = _mm256_loadu_si256((__m256i*)(src + j));\n            __m256i v2 = _mm256_loadu_si256((__m256i*)(src + j + 32));\n            _mm256_storeu_si256((__m256i*)(dst + j), v1);\n            _mm256_storeu_si256((__m256i*)(dst + j + 32), v2);\n        }\n        for (; j < row_size; j++) {\n            dst[j] = src[j];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_5_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid extract_tensor_slice_simd(const uint8_t *tensor, uint8_t *slice, size_t dim1, size_t dim2, size_t dim3, size_t slice_idx) {\n    size_t slice_offset = slice_idx * dim1 * dim2;\n    size_t total_elements = dim1 * dim2;\n\n    for (size_t i = 0; i < total_elements; i += 32) {\n        __m256i vec1 = _mm256_loadu_si256((__m256i*)&tensor[slice_offset + i]);\n        __m256i vec2 = _mm256_loadu_si256((__m256i*)&tensor[slice_offset + i + 16]);\n        _mm256_storeu_si256((__m256i*)&slice[i], vec1);\n        _mm256_storeu_si256((__m256i*)&slice[i + 16], vec2);\n    }\n}\n```"}
{"task_id": "SimdBench_5_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid extract_tensor_slice_simd(const uint8_t *tensor, uint8_t *slice, size_t dim1, size_t dim2, size_t dim3, size_t slice_idx) {\n    size_t slice_offset = slice_idx * dim1 * dim2;\n    size_t total_elements = dim1 * dim2;\n\n    for (size_t i = 0; i < total_elements; i += 32) {\n        __m256i vec1 = _mm256_loadu_si256((__m256i*)&tensor[slice_offset + i]);\n        __m256i vec2 = _mm256_loadu_si256((__m256i*)&tensor[slice_offset + i + 16]);\n        _mm256_storeu_si256((__m256i*)&slice[i], vec1);\n        _mm256_storeu_si256((__m256i*)&slice[i + 16], vec2);\n    }\n}\n```"}
{"task_id": "SimdBench_5_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid extract_tensor_slice_simd(const uint8_t *tensor, uint8_t *slice, size_t dim1, size_t dim2, size_t dim3, size_t slice_idx) {\n    size_t slice_offset = slice_idx * dim1 * dim2;\n    size_t tensor_offset = slice_offset;\n\n    for (size_t i = 0; i < dim1; ++i) {\n        size_t row_offset = tensor_offset + i * dim3;\n        size_t j = 0;\n\n        // Process 32 bytes at a time\n        for (; j <= dim2 - 32; j += 32) {\n            __m256i data = _mm256_loadu_si256((__m256i*)&tensor[row_offset + j]);\n            _mm256_storeu_si256((__m256i*)&slice[i * dim2 + j], data);\n        }\n\n        // Handle remaining elements\n        for (; j < dim2; ++j) {\n            slice[i * dim2 + j] = tensor[row_offset + j];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_6_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid blocked_matrix_transpose_simd(const int16_t *src, int16_t *dst, size_t rows, size_t cols, size_t block_size) {\n    for (size_t block_row = 0; block_row < rows; block_row += block_size) {\n        for (size_t block_col = 0; block_col < cols; block_col += block_size) {\n            for (size_t i = block_row; i < block_row + block_size && i < rows; ++i) {\n                for (size_t j = block_col; j < block_col + block_size && j < cols; j += 8) {\n                    __m128i row_data = _mm_loadu_si128((__m128i*)&src[i * cols + j]);\n                    __m128i transposed_data = _mm_unpacklo_epi16(row_data, _mm_setzero_si128());\n                    _mm_storeu_si128((__m128i*)&dst[j * rows + i], transposed_data);\n                    if (j + 4 < cols) {\n                        transposed_data = _mm_unpackhi_epi16(row_data, _mm_setzero_si128());\n                        _mm_storeu_si128((__m128i*)&dst[(j + 4) * rows + i], transposed_data);\n                    }\n                }\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_6_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid blocked_matrix_transpose_simd(const int16_t *src, int16_t *dst, size_t rows, size_t cols, size_t block_size) {\n    for (size_t block_row = 0; block_row < rows; block_row += block_size) {\n        for (size_t block_col = 0; block_col < cols; block_col += block_size) {\n            for (size_t i = block_row; i < block_row + block_size && i < rows; ++i) {\n                for (size_t j = block_col; j < block_col + block_size && j < cols; j += 8) {\n                    __m128i row_data = _mm_loadu_si128((__m128i*)&src[i * cols + j]);\n                    __m128i transposed_data = _mm_unpacklo_epi16(row_data, _mm_setzero_si128());\n                    _mm_storeu_si128((__m128i*)&dst[j * rows + i], transposed_data);\n                    if (j + 4 < cols) {\n                        transposed_data = _mm_unpackhi_epi16(row_data, _mm_setzero_si128());\n                        _mm_storeu_si128((__m128i*)&dst[(j + 4) * rows + i], transposed_data);\n                    }\n                }\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_6_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid blocked_matrix_transpose_simd(const int16_t *src, int16_t *dst, size_t rows, size_t cols, size_t block_size) {\n    for (size_t block_row = 0; block_row < rows; block_row += block_size) {\n        for (size_t block_col = 0; block_col < cols; block_col += block_size) {\n            for (size_t i = block_row; i < block_row + block_size && i < rows; ++i) {\n                for (size_t j = block_col; j < block_col + block_size && j < cols; j += 8) {\n                    __m128i row_data = _mm_loadu_si128((__m128i*)&src[i * cols + j]);\n                    __m128i transposed_data = _mm_unpacklo_epi16(row_data, _mm_setzero_si128());\n                    _mm_storeu_si128((__m128i*)&dst[j * rows + i], transposed_data);\n                    if (j + 4 < cols) {\n                        transposed_data = _mm_unpackhi_epi16(row_data, _mm_setzero_si128());\n                        _mm_storeu_si128((__m128i*)&dst[(j + 4) * rows + i], transposed_data);\n                    }\n                }\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_6_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid blocked_matrix_transpose_simd(const int16_t *src, int16_t *dst, size_t rows, size_t cols, size_t block_size) {\n    for (size_t block_row = 0; block_row < rows; block_row += block_size) {\n        for (size_t block_col = 0; block_col < cols; block_col += block_size) {\n            for (size_t i = block_row; i < block_row + block_size && i < rows; ++i) {\n                for (size_t j = block_col; j < block_col + block_size && j < cols; j += 8) {\n                    __m128i vec = _mm_loadu_si128((__m128i*)&src[i * cols + j]);\n                    _mm_storeu_si128((__m128i*)&dst[j * rows + i], vec);\n                }\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_6_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid blocked_matrix_transpose_simd(const int16_t *src, int16_t *dst, size_t rows, size_t cols, size_t block_size) {\n    for (size_t block_row = 0; block_row < rows; block_row += block_size) {\n        for (size_t block_col = 0; block_col < cols; block_col += block_size) {\n            for (size_t i = block_row; i < block_row + block_size && i < rows; ++i) {\n                for (size_t j = block_col; j < block_col + block_size && j < cols; j += 8) {\n                    __m128i row_data = _mm_loadu_si128((__m128i*)&src[i * cols + j]);\n                    __m128i transposed_data = _mm_unpacklo_epi16(row_data, _mm_setzero_si128());\n                    _mm_storeu_si128((__m128i*)&dst[j * rows + i], transposed_data);\n                    if (j + 4 < cols) {\n                        transposed_data = _mm_unpackhi_epi16(row_data, _mm_setzero_si128());\n                        _mm_storeu_si128((__m128i*)&dst[(j + 4) * rows + i], transposed_data);\n                    }\n                }\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_7_AVX", "completion": "```cpp\nfloat diagonal_sum_3d_simd(const float *array, size_t dim) {\n    __m256 sum_vec = _mm256_setzero_ps();\n    size_t num_diagonal_elements = dim; // Number of diagonal elements is equal to dim\n\n    for (size_t i = 0; i < num_diagonal_elements; i += 8) {\n        __m256 vec = _mm256_loadu_ps(&array[i * (dim + 1)]);\n        sum_vec = _mm256_add_ps(sum_vec, vec);\n    }\n\n    float sum_array[8];\n    _mm256_storeu_ps(sum_array, sum_vec);\n\n    float total_sum = 0.0f;\n    for (size_t j = 0; j < 8; j++) {\n        total_sum += sum_array[j];\n    }\n\n    return total_sum;\n}\n```"}
{"task_id": "SimdBench_7_AVX", "completion": "```cpp\nfloat diagonal_sum_3d_simd(const float *array, size_t dim) {\n    __m256 sum_vec = _mm256_setzero_ps();\n    size_t count = dim * dim * dim;\n\n    for (size_t i = 0; i < dim; i += 8) {\n        for (size_t j = 0; j < dim; j++) {\n            size_t index = i * dim * dim + j * dim + j;\n            if (index < count) {\n                __m256 vec = _mm256_loadu_ps(&array[index]);\n                sum_vec = _mm256_add_ps(sum_vec, vec);\n            }\n        }\n    }\n\n    float sum[8];\n    _mm256_storeu_ps(sum, sum_vec);\n    float total_sum = 0.0f;\n    for (int k = 0; k < 8; k++) {\n        total_sum += sum[k];\n    }\n\n    return total_sum;\n}\n```"}
{"task_id": "SimdBench_7_AVX", "completion": "```cpp\nfloat diagonal_sum_3d_simd(const float *array, size_t dim) {\n    __m256 sum_vec = _mm256_setzero_ps();\n    size_t count = dim * dim * dim;\n\n    for (size_t i = 0; i < dim; i += 8) {\n        for (size_t j = 0; j < 8; j++) {\n            if (i + j < dim) {\n                size_t index = (i + j) * dim * dim + (i + j) * dim + (i + j);\n                sum_vec = _mm256_add_ps(sum_vec, _mm256_loadu_ps(&array[index]));\n            }\n        }\n    }\n\n    float sum[8];\n    _mm256_storeu_ps(sum, sum_vec);\n    float total_sum = 0.0f;\n    for (int k = 0; k < 8; k++) {\n        total_sum += sum[k];\n    }\n\n    return total_sum;\n}\n```"}
{"task_id": "SimdBench_7_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nfloat diagonal_sum_3d_simd(const float *array, size_t dim) {\n    __m256 sum_vec = _mm256_setzero_ps();\n    size_t i;\n\n    for (i = 0; i + 7 < dim; i += 8) {\n        __m256 vec = _mm256_loadu_ps(&array[i * dim * dim + i * dim + i]);\n        sum_vec = _mm256_add_ps(sum_vec, vec);\n    }\n\n    float sum[8];\n    _mm256_storeu_ps(sum, sum_vec);\n    float total_sum = 0.0f;\n    for (size_t j = 0; j < 8; j++) {\n        total_sum += sum[j];\n    }\n\n    // Handle remaining elements\n    for (; i < dim; i++) {\n        total_sum += array[i * dim * dim + i * dim + i];\n    }\n\n    return total_sum;\n}\n```"}
{"task_id": "SimdBench_7_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nfloat diagonal_sum_3d_simd(const float *array, size_t dim) {\n    __m256 sum_vec = _mm256_setzero_ps();\n    size_t i;\n\n    for (i = 0; i < dim; i += 8) {\n        __m256 vec = _mm256_loadu_ps(&array[i * dim * dim + i * dim + i]);\n        sum_vec = _mm256_add_ps(sum_vec, vec);\n    }\n\n    float sum[8];\n    _mm256_storeu_ps(sum, sum_vec);\n    \n    float total_sum = 0.0f;\n    for (size_t j = 0; j < 8; j++) {\n        total_sum += sum[j];\n    }\n\n    return total_sum;\n}\n```"}
{"task_id": "SimdBench_8_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid conditional_scale_simd(const double *src, double *dst, size_t rows, size_t cols, double threshold, double scale) {\n    __m256d threshold_vec = _mm256_set1_pd(threshold);\n    __m256d scale_vec = _mm256_set1_pd(scale);\n    \n    size_t total_elements = rows * cols;\n    size_t i;\n\n    for (i = 0; i <= total_elements - 4; i += 4) {\n        __m256d src_vec = _mm256_loadu_pd(&src[i]);\n        __m256d mask = _mm256_cmp_pd(src_vec, threshold_vec, _CMP_GT_OQ);\n        __m256d scaled_vec = _mm256_mul_pd(src_vec, scale_vec);\n        __m256d result_vec = _mm256_blendv_pd(src_vec, scaled_vec, mask);\n        _mm256_storeu_pd(&dst[i], result_vec);\n    }\n\n    for (; i < total_elements; ++i) {\n        dst[i] = src[i] > threshold ? src[i] * scale : src[i];\n    }\n}\n```"}
{"task_id": "SimdBench_8_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid conditional_scale_simd(const double *src, double *dst, size_t rows, size_t cols, double threshold, double scale) {\n    __m256d threshold_vec = _mm256_set1_pd(threshold);\n    __m256d scale_vec = _mm256_set1_pd(scale);\n    \n    size_t total_elements = rows * cols;\n    size_t i;\n\n    for (i = 0; i + 4 <= total_elements; i += 4) {\n        __m256d src_vec = _mm256_loadu_pd(&src[i]);\n        __m256d cmp_mask = _mm256_cmp_pd(src_vec, threshold_vec, _CMP_GT_OQ);\n        __m256d scaled_vec = _mm256_mul_pd(src_vec, scale_vec);\n        __m256d result_vec = _mm256_blendv_pd(src_vec, scaled_vec, cmp_mask);\n        _mm256_storeu_pd(&dst[i], result_vec);\n    }\n\n    for (; i < total_elements; ++i) {\n        dst[i] = (src[i] > threshold) ? src[i] * scale : src[i];\n    }\n}\n```"}
{"task_id": "SimdBench_8_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid conditional_scale_simd(const double *src, double *dst, size_t rows, size_t cols, double threshold, double scale) {\n    __m256d threshold_vec = _mm256_set1_pd(threshold);\n    __m256d scale_vec = _mm256_set1_pd(scale);\n    \n    size_t total_elements = rows * cols;\n    size_t i;\n\n    for (i = 0; i <= total_elements - 4; i += 4) {\n        __m256d src_vec = _mm256_loadu_pd(&src[i]);\n        __m256d cmp_mask = _mm256_cmp_pd(src_vec, threshold_vec, _CMP_GT_OQ);\n        __m256d scaled_vec = _mm256_mul_pd(src_vec, scale_vec);\n        __m256d result_vec = _mm256_blendv_pd(src_vec, scaled_vec, cmp_mask);\n        _mm256_storeu_pd(&dst[i], result_vec);\n    }\n\n    for (; i < total_elements; ++i) {\n        dst[i] = (src[i] > threshold) ? src[i] * scale : src[i];\n    }\n}\n```"}
{"task_id": "SimdBench_8_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid conditional_scale_simd(const double *src, double *dst, size_t rows, size_t cols, double threshold, double scale) {\n    __m256d threshold_vec = _mm256_set1_pd(threshold);\n    __m256d scale_vec = _mm256_set1_pd(scale);\n    \n    size_t total_elements = rows * cols;\n    size_t i;\n\n    for (i = 0; i <= total_elements - 4; i += 4) {\n        __m256d src_vec = _mm256_loadu_pd(&src[i]);\n        __m256d cmp_mask = _mm256_cmp_pd(src_vec, threshold_vec, _CMP_GT_OQ);\n        __m256d scaled_vec = _mm256_mul_pd(src_vec, scale_vec);\n        __m256d result_vec = _mm256_blendv_pd(src_vec, scaled_vec, cmp_mask);\n        _mm256_storeu_pd(&dst[i], result_vec);\n    }\n\n    for (; i < total_elements; i++) {\n        dst[i] = (src[i] > threshold) ? src[i] * scale : src[i];\n    }\n}\n```"}
{"task_id": "SimdBench_8_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid conditional_scale_simd(const double *src, double *dst, size_t rows, size_t cols, double threshold, double scale) {\n    __m256d threshold_vec = _mm256_set1_pd(threshold);\n    __m256d scale_vec = _mm256_set1_pd(scale);\n    \n    for (size_t i = 0; i < rows; ++i) {\n        for (size_t j = 0; j < cols; j += 4) {\n            __m256d src_vec = _mm256_loadu_pd(&src[i * cols + j]);\n            __m256d cmp_mask = _mm256_cmp_pd(src_vec, threshold_vec, _CMP_GT_OS);\n            __m256d scaled_vec = _mm256_mul_pd(src_vec, scale_vec);\n            __m256d result_vec = _mm256_blendv_pd(src_vec, scaled_vec, cmp_mask);\n            _mm256_storeu_pd(&dst[i * cols + j], result_vec);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_9_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid reorder_matrix_rows_simd(const double *src, double *dst, size_t rows, size_t cols, const size_t *indices) {\n    for (size_t i = 0; i < rows; ++i) {\n        size_t index = indices[i];\n        size_t src_offset = index * cols;\n        size_t dst_offset = i * cols;\n\n        for (size_t j = 0; j < cols; j += 4) {\n            __m256d vec = _mm256_loadu_pd(&src[src_offset + j]);\n            _mm256_storeu_pd(&dst[dst_offset + j], vec);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_9_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid reorder_matrix_rows_simd(const double *src, double *dst, size_t rows, size_t cols, const size_t *indices) {\n    size_t i, j;\n    for (i = 0; i < rows; i++) {\n        size_t row_index = indices[i];\n        for (j = 0; j < cols; j += 4) {\n            __m256d data = _mm256_loadu_pd(&src[row_index * cols + j]);\n            _mm256_storeu_pd(&dst[i * cols + j], data);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_9_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid reorder_matrix_rows_simd(const double *src, double *dst, size_t rows, size_t cols, const size_t *indices) {\n    for (size_t r = 0; r < rows; r++) {\n        size_t src_row = indices[r] * cols;\n        size_t dst_row = r * cols;\n\n        for (size_t c = 0; c < cols; c += 4) {\n            __m256d data = _mm256_loadu_pd(&src[src_row + c]);\n            _mm256_storeu_pd(&dst[dst_row + c], data);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_9_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid reorder_matrix_rows_simd(const double *src, double *dst, size_t rows, size_t cols, const size_t *indices) {\n    size_t i, j;\n    __m256d vec;\n\n    for (i = 0; i < rows; i++) {\n        size_t row_index = indices[i];\n        for (j = 0; j < cols; j += 4) {\n            vec = _mm256_loadu_pd(&src[row_index * cols + j]);\n            _mm256_storeu_pd(&dst[i * cols + j], vec);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_9_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid reorder_matrix_rows_simd(const double *src, double *dst, size_t rows, size_t cols, const size_t *indices) {\n    size_t i, j;\n    __m256d vec;\n\n    for (i = 0; i < rows; i++) {\n        size_t row_index = indices[i];\n        for (j = 0; j < cols; j += 4) {\n            vec = _mm256_loadu_pd(&src[row_index * cols + j]);\n            _mm256_storeu_pd(&dst[i * cols + j], vec);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_10_AVX", "completion": "```cpp\nvoid vector_vector_add_simd(const int64_t *src1, const int64_t *src2, int64_t *dst, int64_t scalar, size_t length) {\n    __m256i scalar_vec = _mm256_set1_epi64x(scalar);\n    size_t i;\n\n    for (i = 0; i + 4 <= length; i += 4) {\n        __m256i vec1 = _mm256_loadu_si256((__m256i*)&src1[i]);\n        __m256i vec2 = _mm256_loadu_si256((__m256i*)&src2[i]);\n        __m256i sum = _mm256_add_epi64(vec1, vec2);\n        __m256i result = _mm256_add_epi64(sum, scalar_vec);\n        result = _mm256_srai_epi64(result, 1);\n        _mm256_storeu_si256((__m256i*)&dst[i], result);\n    }\n\n    for (; i < length; i++) {\n        dst[i] = (src1[i] + src2[i] + scalar) / 2;\n    }\n}\n```"}
{"task_id": "SimdBench_10_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid vector_vector_add_simd(const int64_t *src1, const int64_t *src2, int64_t *dst, int64_t scalar, size_t length) {\n    __m256i scalar_vec = _mm256_set1_epi64x(scalar);\n    size_t i;\n\n    for (i = 0; i + 4 <= length; i += 4) {\n        __m256i vec1 = _mm256_loadu_si256((__m256i*)&src1[i]);\n        __m256i vec2 = _mm256_loadu_si256((__m256i*)&src2[i]);\n        __m256i sum = _mm256_add_epi64(vec1, vec2);\n        __m256i result = _mm256_add_epi64(sum, scalar_vec);\n        result = _mm256_srai_epi64(result, 1);\n        _mm256_storeu_si256((__m256i*)&dst[i], result);\n    }\n\n    for (; i < length; i++) {\n        dst[i] = (src1[i] + src2[i] + scalar) / 2;\n    }\n}\n```"}
{"task_id": "SimdBench_10_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid vector_vector_add_simd(const int64_t *src1, const int64_t *src2, int64_t *dst, int64_t scalar, size_t length) {\n    __m256i scalar_vec = _mm256_set1_epi64x(scalar);\n    size_t i;\n\n    for (i = 0; i < length / 4 * 4; i += 4) {\n        __m256i vec1 = _mm256_loadu_si256((__m256i*)&src1[i]);\n        __m256i vec2 = _mm256_loadu_si256((__m256i*)&src2[i]);\n        __m256i sum = _mm256_add_epi64(vec1, vec2);\n        __m256i result = _mm256_add_epi64(sum, scalar_vec);\n        result = _mm256_srli_epi64(result, 1);\n        _mm256_storeu_si256((__m256i*)&dst[i], result);\n    }\n\n    for (; i < length; i++) {\n        dst[i] = (src1[i] + src2[i] + scalar) / 2;\n    }\n}\n```"}
{"task_id": "SimdBench_10_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid vector_vector_add_simd(const int64_t *src1, const int64_t *src2, int64_t *dst, int64_t scalar, size_t length) {\n    __m256i scalar_vec = _mm256_set1_epi64x(scalar);\n    size_t i;\n\n    for (i = 0; i + 4 <= length; i += 4) {\n        __m256i vec1 = _mm256_loadu_si256((__m256i*)&src1[i]);\n        __m256i vec2 = _mm256_loadu_si256((__m256i*)&src2[i]);\n        __m256i sum = _mm256_add_epi64(vec1, vec2);\n        __m256i result = _mm256_add_epi64(sum, scalar_vec);\n        result = _mm256_srli_epi64(result, 1);\n        _mm256_storeu_si256((__m256i*)&dst[i], result);\n    }\n\n    for (; i < length; i++) {\n        dst[i] = (src1[i] + src2[i] + scalar) / 2;\n    }\n}\n```"}
{"task_id": "SimdBench_10_AVX", "completion": "```cpp\nvoid vector_vector_add_simd(const int64_t *src1, const int64_t *src2, int64_t *dst, int64_t scalar, size_t length) {\n    __m256i scalar_vec = _mm256_set1_epi64x(scalar);\n    size_t i;\n\n    for (i = 0; i < length / 4 * 4; i += 4) {\n        __m256i vec1 = _mm256_loadu_si256((__m256i*)&src1[i]);\n        __m256i vec2 = _mm256_loadu_si256((__m256i*)&src2[i]);\n        __m256i sum = _mm256_add_epi64(vec1, vec2);\n        __m256i result = _mm256_add_epi64(sum, scalar_vec);\n        result = _mm256_srli_epi64(result, 1);\n        _mm256_storeu_si256((__m256i*)&dst[i], result);\n    }\n\n    for (; i < length; i++) {\n        dst[i] = (src1[i] + src2[i] + scalar) / 2;\n    }\n}\n```"}
{"task_id": "SimdBench_11_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <limits.h>\n\nint vector_even_min_simd(const int *src, size_t length) {\n    if (length == 0) return -1;\n\n    __m256i min_vec = _mm256_set1_epi32(INT_MAX);\n    size_t i;\n\n    for (i = 0; i < length / 8 * 8; i += 8) {\n        __m256i data = _mm256_loadu_si256((__m256i*)&src[i]);\n        __m256i even_mask = _mm256_set1_epi32(0xAAAAAAAA); // Mask for even indices\n        __m256i even_elements = _mm256_and_si256(data, even_mask);\n        min_vec = _mm256_min_epi32(min_vec, even_elements);\n    }\n\n    // Handle remaining elements\n    for (; i < length; i++) {\n        if (i % 2 == 0) {\n            min_vec = _mm256_min_epi32(min_vec, _mm256_set1_epi32(src[i]));\n        }\n    }\n\n    // Horizontal reduction to find the minimum\n    min_vec = _mm256_min_epi32(min_vec, _mm256_permute2x128_si256(min_vec, min_vec, 1));\n    min_vec = _mm256_min_epi32(min_vec, _mm256_shuffle_epi32(min_vec, _MM_SHUFFLE(1, 0, 3, 2)));\n    \n    int result[8];\n    _mm256_storeu_si256((__m256i*)result, min_vec);\n    \n    int final_min = INT_MAX;\n    for (int j = 0; j < 4; j++) {\n        final_min = final_min < result[j] ? final_min : result[j];\n    }\n\n    return final_min == INT_MAX ? -1 : final_min;\n}\n```"}
{"task_id": "SimdBench_11_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <limits.h>\n\nint vector_even_min_simd(const int *src, size_t length) {\n    if (length == 0) return -1;\n\n    __m256i min_vec = _mm256_set1_epi32(INT_MAX);\n    size_t i;\n\n    for (i = 0; i < length / 8 * 8; i += 8) {\n        __m256i data = _mm256_loadu_si256((__m256i*)&src[i]);\n        __m256i even_mask = _mm256_set1_epi32(0xFFFFFFFF);\n        even_mask = _mm256_and_si256(even_mask, _mm256_set_epi32(0, 0, 0, 0, 0, 0, 0, 1));\n        data = _mm256_and_si256(data, even_mask);\n        min_vec = _mm256_min_epi32(min_vec, data);\n    }\n\n    int min_vals[8];\n    _mm256_storeu_si256((__m256i*)min_vals, min_vec);\n\n    int min_value = INT_MAX;\n    for (int j = 0; j < 8; j++) {\n        if (min_vals[j] < min_value) {\n            min_value = min_vals[j];\n        }\n    }\n\n    for (; i < length; i++) {\n        if (i % 2 == 0 && src[i] < min_value) {\n            min_value = src[i];\n        }\n    }\n\n    return (min_value == INT_MAX) ? -1 : min_value;\n}\n```"}
{"task_id": "SimdBench_11_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <limits.h>\n\nint vector_even_min_simd(const int *src, size_t length) {\n    if (length == 0) return -1;\n\n    __m256i min_vec = _mm256_set1_epi32(INT_MAX);\n    size_t i;\n\n    for (i = 0; i < length / 8 * 8; i += 8) {\n        __m256i data = _mm256_loadu_si256((__m256i*)&src[i]);\n        __m256i even_mask = _mm256_set1_epi32(0xAAAAAAAA); // Mask for even indices\n        __m256i even_elements = _mm256_and_si256(data, even_mask);\n        min_vec = _mm256_min_epi32(min_vec, even_elements);\n    }\n\n    // Handle remaining elements\n    for (; i < length; i++) {\n        if (i % 2 == 0) {\n            min_vec = _mm256_min_epi32(min_vec, _mm256_set1_epi32(src[i]));\n        }\n    }\n\n    // Horizontal reduction to find the minimum\n    int min_array[8];\n    _mm256_storeu_si256((__m256i*)min_array, min_vec);\n    int min_value = INT_MAX;\n    for (int j = 0; j < 8; j++) {\n        if (min_array[j] < min_value) {\n            min_value = min_array[j];\n        }\n    }\n\n    return min_value == INT_MAX ? -1 : min_value;\n}\n```"}
{"task_id": "SimdBench_11_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <limits.h>\n\nint vector_even_min_simd(const int *src, size_t length) {\n    if (length == 0) return -1;\n\n    __m256i min_vec = _mm256_set1_epi32(INT_MAX);\n    size_t i;\n\n    for (i = 0; i < length / 8 * 8; i += 8) {\n        __m256i data = _mm256_loadu_si256((__m256i*)&src[i]);\n        __m256i even_mask = _mm256_set1_epi32(0xAAAAAAAA); // Mask for even indices\n        __m256i even_elements = _mm256_and_si256(data, even_mask);\n        min_vec = _mm256_min_epi32(min_vec, even_elements);\n    }\n\n    // Handle remaining elements\n    for (; i < length; i++) {\n        if (i % 2 == 0) {\n            min_vec = _mm256_min_epi32(min_vec, _mm256_set1_epi32(src[i]));\n        }\n    }\n\n    // Horizontal reduction to find the minimum\n    min_vec = _mm256_min_epi32(min_vec, _mm256_shuffle_epi32(min_vec, _MM_SHUFFLE(2, 3, 0, 1)));\n    min_vec = _mm256_min_epi32(min_vec, _mm256_shuffle_epi32(min_vec, _MM_SHUFFLE(1, 0, 3, 2)));\n    \n    int min_values[8];\n    _mm256_storeu_si256((__m256i*)min_values, min_vec);\n    \n    int min_result = INT_MAX;\n    for (int j = 0; j < 4; j++) {\n        if (min_values[j] < min_result) {\n            min_result = min_values[j];\n        }\n    }\n\n    return (min_result == INT_MAX) ? -1 : min_result;\n}\n```"}
{"task_id": "SimdBench_11_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <limits.h>\n\nint vector_even_min_simd(const int *src, size_t length) {\n    if (length == 0) return -1;\n\n    __m256i min_vec = _mm256_set1_epi32(INT_MAX);\n    size_t i;\n\n    for (i = 0; i < length / 8 * 2; i += 8) {\n        __m256i data = _mm256_loadu_si256((__m256i*)&src[i]);\n        min_vec = _mm256_min_epi32(min_vec, data);\n    }\n\n    // Handle remaining elements\n    for (; i < length; i += 2) {\n        if (i < length) {\n            min_vec = _mm256_min_epi32(min_vec, _mm256_set1_epi32(src[i]));\n        }\n    }\n\n    // Horizontal reduction to find the minimum value\n    min_vec = _mm256_min_epi32(min_vec, _mm256_shuffle_epi32(min_vec, _MM_SHUFFLE(2, 3, 0, 1)));\n    min_vec = _mm256_min_epi32(min_vec, _mm256_shuffle_epi32(min_vec, _MM_SHUFFLE(1, 0, 3, 2)));\n    \n    int min_values[8];\n    _mm256_storeu_si256((__m256i*)min_values, min_vec);\n    \n    int min_result = INT_MAX;\n    for (int j = 0; j < 4; j++) {\n        if (min_values[j] < min_result) {\n            min_result = min_values[j];\n        }\n    }\n\n    return min_result == INT_MAX ? -1 : min_result;\n}\n```"}
{"task_id": "SimdBench_12_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <stdint.h>\n#include <stddef.h>\n\nvoid mixed_right_shift_simd(const int *src, int *dst, uint8_t shift, size_t length) {\n    size_t i = 0;\n    __m256i shift_vec = _mm256_set1_epi32(shift);\n    \n    for (; i <= length - 8; i += 8) {\n        __m256i src_vec = _mm256_loadu_si256((__m256i*)&src[i]);\n        \n        // Arithmetic right shift\n        __m256i arith_shifted = _mm256_srai_epi32(src_vec, shift);\n        \n        // Logical right shift\n        __m256i unsigned_src_vec = _mm256_cvtepi32_epi64(src_vec); // Convert to unsigned\n        __m256i logical_shifted = _mm256_srli_epi64(unsigned_src_vec, shift);\n        logical_shifted = _mm256_cvtepi64_epi32(logical_shifted); // Convert back to int\n        \n        // Add results\n        __m256i result = _mm256_add_epi32(arith_shifted, logical_shifted);\n        \n        _mm256_storeu_si256((__m256i*)&dst[i], result);\n    }\n    \n    // Handle remaining elements\n    for (; i < length; i++) {\n        dst[i] = (src[i] >> shift) + ((uint32_t)src[i] >> shift);\n    }\n}\n```"}
{"task_id": "SimdBench_12_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid mixed_right_shift_simd(const int *src, int *dst, uint8_t shift, size_t length) {\n    size_t i;\n    __m256i shift_vec = _mm256_set1_epi32(shift);\n    \n    for (i = 0; i < length; i += 8) {\n        __m256i src_vec = _mm256_loadu_si256((__m256i*)&src[i]);\n        \n        // Arithmetic right shift\n        __m256i arith_shifted = _mm256_srai_epi32(src_vec, shift);\n        \n        // Logical right shift\n        __m256i unsigned_src_vec = _mm256_cvtepi32_epi64(src_vec);\n        __m256i logical_shifted = _mm256_srli_epi64(unsigned_src_vec, shift);\n        \n        // Cast back to int\n        __m256i logical_shifted_int = _mm256_cvtepi64_epi32(logical_shifted);\n        \n        // Add results\n        __m256i result = _mm256_add_epi32(arith_shifted, logical_shifted_int);\n        \n        _mm256_storeu_si256((__m256i*)&dst[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_12_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <stdint.h>\n#include <stddef.h>\n\nvoid mixed_right_shift_simd(const int *src, int *dst, uint8_t shift, size_t length) {\n    size_t i;\n    __m256i shift_vec = _mm256_set1_epi32(shift);\n    \n    for (i = 0; i < length; i += 8) {\n        __m256i src_vec = _mm256_loadu_si256((__m256i*)&src[i]);\n        \n        // Arithmetic right shift\n        __m256i arith_shifted = _mm256_srai_epi32(src_vec, shift);\n        \n        // Logical right shift\n        __m256i unsigned_src_vec = _mm256_cvtepi32_epi64(src_vec);\n        __m256i logical_shifted = _mm256_srli_epi64(unsigned_src_vec, shift);\n        \n        // Cast back to int\n        __m256i logical_shifted_int = _mm256_cvtepi64_epi32(logical_shifted);\n        \n        // Add results\n        __m256i result = _mm256_add_epi32(arith_shifted, logical_shifted_int);\n        \n        _mm256_storeu_si256((__m256i*)&dst[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_12_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <stdint.h>\n#include <stddef.h>\n\nvoid mixed_right_shift_simd(const int *src, int *dst, uint8_t shift, size_t length) {\n    size_t i;\n    __m256i shift_vec = _mm256_set1_epi32(shift);\n    \n    for (i = 0; i < length; i += 8) {\n        __m256i src_vec = _mm256_loadu_si256((__m256i*)&src[i]);\n        \n        // Arithmetic right shift\n        __m256i arith_shifted = _mm256_srai_epi32(src_vec, shift);\n        \n        // Logical right shift\n        __m256i unsigned_src_vec = _mm256_cvtepi32_epi64(src_vec);\n        __m256i logical_shifted = _mm256_srli_epi64(unsigned_src_vec, shift);\n        \n        // Cast back to int\n        __m256i logical_shifted_int = _mm256_cvtepi64_epi32(logical_shifted);\n        \n        // Add results\n        __m256i result = _mm256_add_epi32(arith_shifted, logical_shifted_int);\n        \n        _mm256_storeu_si256((__m256i*)&dst[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_12_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid mixed_right_shift_simd(const int *src, int *dst, uint8_t shift, size_t length) {\n    size_t i;\n    __m256i shift_vec = _mm256_set1_epi32(shift);\n    \n    for (i = 0; i < length; i += 8) {\n        __m256i src_vec = _mm256_loadu_si256((__m256i*)&src[i]);\n        \n        // Arithmetic right shift\n        __m256i arith_shifted = _mm256_srai_epi32(src_vec, shift);\n        \n        // Logical right shift\n        __m256i unsigned_src_vec = _mm256_cvtepi32_epi64(src_vec);\n        __m256i logical_shifted = _mm256_srli_epi64(unsigned_src_vec, shift);\n        __m256i logical_shifted_int = _mm256_cvtepi64_epi32(logical_shifted);\n        \n        // Add results\n        __m256i result = _mm256_add_epi32(arith_shifted, logical_shifted_int);\n        \n        _mm256_storeu_si256((__m256i*)&dst[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_13_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nint64_t matrix_sum_simd(const int *matrix, size_t rows, size_t cols) {\n    size_t total_elements = rows * cols;\n    size_t i = 0;\n    __m256i sum_vec = _mm256_setzero_si256();\n\n    for (; i <= total_elements - 8; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&matrix[i]);\n        sum_vec = _mm256_add_epi32(sum_vec, vec);\n    }\n\n    int32_t sum_array[8];\n    _mm256_storeu_si256((__m256i*)sum_array, sum_vec);\n\n    int64_t total_sum = 0;\n    for (size_t j = 0; j < 8; j++) {\n        total_sum += sum_array[j];\n    }\n\n    for (; i < total_elements; i++) {\n        total_sum += matrix[i];\n    }\n\n    return total_sum;\n}\n```"}
{"task_id": "SimdBench_13_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nint64_t matrix_sum_simd(const int *matrix, size_t rows, size_t cols) {\n    size_t total_elements = rows * cols;\n    size_t i;\n    __m256i sum_vec = _mm256_setzero_si256();\n\n    for (i = 0; i <= total_elements - 8; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&matrix[i]);\n        sum_vec = _mm256_add_epi32(sum_vec, vec);\n    }\n\n    int32_t temp[8];\n    _mm256_storeu_si256((__m256i*)temp, sum_vec);\n\n    int64_t total_sum = 0;\n    for (size_t j = 0; j < 8; j++) {\n        total_sum += temp[j];\n    }\n\n    for (; i < total_elements; i++) {\n        total_sum += matrix[i];\n    }\n\n    return total_sum;\n}\n```"}
{"task_id": "SimdBench_13_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nint64_t matrix_sum_simd(const int *matrix, size_t rows, size_t cols) {\n    size_t total_elements = rows * cols;\n    size_t i = 0;\n    __m256i sum_vec = _mm256_setzero_si256();\n\n    for (; i <= total_elements - 8; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&matrix[i]);\n        sum_vec = _mm256_add_epi32(sum_vec, vec);\n    }\n\n    int32_t sum_array[8];\n    _mm256_storeu_si256((__m256i*)sum_array, sum_vec);\n\n    int64_t total_sum = 0;\n    for (size_t j = 0; j < 8; j++) {\n        total_sum += sum_array[j];\n    }\n\n    for (; i < total_elements; i++) {\n        total_sum += matrix[i];\n    }\n\n    return total_sum;\n}\n```"}
{"task_id": "SimdBench_13_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nint64_t matrix_sum_simd(const int *matrix, size_t rows, size_t cols) {\n    size_t total_elements = rows * cols;\n    size_t i;\n\n    __m256i sum_vec = _mm256_setzero_si256();\n\n    for (i = 0; i <= total_elements - 8; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&matrix[i]);\n        sum_vec = _mm256_add_epi32(sum_vec, vec);\n    }\n\n    int32_t sum_array[8];\n    _mm256_storeu_si256((__m256i*)sum_array, sum_vec);\n\n    int64_t total_sum = 0;\n    for (size_t j = 0; j < 8; j++) {\n        total_sum += sum_array[j];\n    }\n\n    for (; i < total_elements; i++) {\n        total_sum += matrix[i];\n    }\n\n    return total_sum;\n}\n```"}
{"task_id": "SimdBench_13_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nint64_t matrix_sum_simd(const int *matrix, size_t rows, size_t cols) {\n    size_t total_elements = rows * cols;\n    size_t i = 0;\n    __m256i sum_vec = _mm256_setzero_si256();\n\n    for (; i <= total_elements - 8; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&matrix[i]);\n        sum_vec = _mm256_add_epi32(sum_vec, vec);\n    }\n\n    int32_t temp[8];\n    _mm256_storeu_si256((__m256i*)temp, sum_vec);\n\n    int64_t total_sum = 0;\n    for (size_t j = 0; j < 8; j++) {\n        total_sum += temp[j];\n    }\n\n    for (; i < total_elements; i++) {\n        total_sum += matrix[i];\n    }\n\n    return total_sum;\n}\n```"}
{"task_id": "SimdBench_14_AVX", "completion": "```cpp\nsize_t argmax_simd(const int8_t *src, size_t length) {\n    if (length == 0) return 0;\n\n    __m256i max_val = _mm256_set1_epi8(src[0]);\n    __m256i max_idx = _mm256_set1_epi8(0);\n    size_t idx = 0;\n\n    size_t i;\n    for (i = 0; i <= length - 32; i += 32) {\n        __m256i data = _mm256_loadu_si256((__m256i*)&src[i]);\n        __m256i cmp = _mm256_cmpgt_epi8(data, max_val);\n        max_val = _mm256_max_epi8(max_val, data);\n        max_idx = _mm256_blendv_epi8(max_idx, _mm256_set1_epi8(i), cmp);\n    }\n\n    int8_t max_array[32];\n    _mm256_storeu_si256((__m256i*)max_array, max_idx);\n\n    for (size_t j = 0; j < 32; j++) {\n        if (i + j < length && max_array[j] == i) {\n            idx = i + j;\n        }\n    }\n\n    for (; i < length; i++) {\n        if (src[i] > src[idx]) {\n            idx = i;\n        }\n    }\n\n    return idx;\n}\n```"}
{"task_id": "SimdBench_14_AVX", "completion": "```cpp\nsize_t argmax_simd(const int8_t *src, size_t length) {\n    if (length == 0) return 0;\n\n    __m256i max_val = _mm256_set1_epi8(src[0]);\n    size_t max_index = 0;\n\n    size_t i;\n    for (i = 0; i <= length - 32; i += 32) {\n        __m256i data = _mm256_loadu_si256((__m256i*)&src[i]);\n        __m256i cmp = _mm256_cmpgt_epi8(data, max_val);\n        max_val = _mm256_max_epi8(max_val, data);\n        \n        // Update max_index if necessary\n        for (int j = 0; j < 32; j++) {\n            if (_mm256_extract_epi8(cmp, j)) {\n                max_index = i + j;\n            }\n        }\n    }\n\n    // Handle remaining elements\n    for (; i < length; i++) {\n        if (src[i] > src[max_index]) {\n            max_index = i;\n        }\n    }\n\n    return max_index;\n}\n```"}
{"task_id": "SimdBench_14_AVX", "completion": "```cpp\nsize_t argmax_simd(const int8_t *src, size_t length) {\n    if (length == 0) return 0;\n\n    __m256i max_val = _mm256_set1_epi8(src[0]);\n    __m256i max_idx = _mm256_set1_epi8(0);\n    size_t idx = 0;\n\n    size_t i;\n    for (i = 0; i <= length - 32; i += 32) {\n        __m256i data = _mm256_loadu_si256((__m256i*)&src[i]);\n        __m256i cmp = _mm256_cmpgt_epi8(data, max_val);\n        max_val = _mm256_max_epi8(max_val, data);\n        max_idx = _mm256_blendv_epi8(max_idx, _mm256_set1_epi8(i), cmp);\n    }\n\n    int8_t max_array[32];\n    _mm256_storeu_si256((__m256i*)max_array, max_idx);\n\n    for (size_t j = 0; j < 32; j++) {\n        if (i + j < length && max_array[j] != 0) {\n            idx = i + j;\n            break;\n        }\n    }\n\n    for (; i < length; i++) {\n        if (src[i] > src[idx]) {\n            idx = i;\n        }\n    }\n\n    return idx;\n}\n```"}
{"task_id": "SimdBench_14_AVX", "completion": "```cpp\nsize_t argmax_simd(const int8_t *src, size_t length) {\n    if (length == 0) return 0;\n\n    __m256i max_val = _mm256_set1_epi8(src[0]);\n    __m256i max_idx = _mm256_set1_epi8(0);\n    size_t idx = 0;\n\n    size_t i;\n    for (i = 0; i <= length - 32; i += 32) {\n        __m256i data = _mm256_loadu_si256((__m256i*)&src[i]);\n        __m256i cmp = _mm256_cmpgt_epi8(data, max_val);\n        max_val = _mm256_max_epi8(max_val, data);\n        max_idx = _mm256_blendv_epi8(max_idx, _mm256_set1_epi8(i), cmp);\n    }\n\n    int8_t max_arr[32];\n    _mm256_storeu_si256((__m256i*)max_arr, max_val);\n\n    int8_t max_value = max_arr[0];\n    size_t max_index = idx;\n\n    for (size_t j = 1; j < 32; j++) {\n        if (max_arr[j] > max_value) {\n            max_value = max_arr[j];\n            max_index = i + j;\n        }\n    }\n\n    for (; i < length; i++) {\n        if (src[i] > max_value) {\n            max_value = src[i];\n            max_index = i;\n        }\n    }\n\n    return max_index;\n}\n```"}
{"task_id": "SimdBench_14_AVX", "completion": "```cpp\nsize_t argmax_simd(const int8_t *src, size_t length) {\n    if (length == 0) return 0;\n\n    __m256i max_val = _mm256_set1_epi8(src[0]);\n    __m256i max_idx = _mm256_set1_epi8(0);\n    size_t idx = 0;\n\n    size_t i;\n    for (i = 0; i <= length - 32; i += 32) {\n        __m256i data = _mm256_loadu_si256((__m256i*)&src[i]);\n        __m256i cmp = _mm256_cmpgt_epi8(data, max_val);\n        max_val = _mm256_max_epi8(max_val, data);\n        max_idx = _mm256_blendv_epi8(max_idx, _mm256_set1_epi8(i), cmp);\n    }\n\n    int8_t max_array[32];\n    _mm256_storeu_si256((__m256i*)max_array, max_val);\n    int8_t max_value = max_array[0];\n    size_t max_index = idx;\n\n    for (size_t j = 1; j < 32; j++) {\n        if (max_array[j] > max_value) {\n            max_value = max_array[j];\n            max_index = i + j;\n        }\n    }\n\n    for (; i < length; i++) {\n        if (src[i] > max_value) {\n            max_value = src[i];\n            max_index = i;\n        }\n    }\n\n    return max_index;\n}\n```"}
{"task_id": "SimdBench_15_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid vector_blend_simd(const uint16_t* src1, const uint16_t* src2, uint32_t mask, uint16_t* dst, size_t length) {\n    size_t i = 0;\n    __m256i mask_vec = _mm256_set1_epi32(mask);\n    \n    for (; i <= length - 16; i += 16) {\n        __m256i indices = _mm256_set_epi32(i + 15, i + 14, i + 13, i + 12, i + 11, i + 10, i + 9, i + 8);\n        __m256i and_result = _mm256_and_si256(indices, mask_vec);\n        __m256i blend_mask = _mm256_cmpgt_epi32(and_result, _mm256_setzero_si256());\n\n        __m256i src1_vec = _mm256_loadu_si256((__m256i*)&src1[i]);\n        __m256i src2_vec = _mm256_loadu_si256((__m256i*)&src2[i]);\n        \n        __m256i result = _mm256_blendv_epi8(src2_vec, src1_vec, blend_mask);\n        _mm256_storeu_si256((__m256i*)&dst[i], result);\n    }\n\n    for (; i < length; i++) {\n        dst[i] = (i & mask) ? src1[i] : src2[i];\n    }\n}\n```"}
{"task_id": "SimdBench_15_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid vector_blend_simd(const uint16_t* src1, const uint16_t* src2, uint32_t mask, uint16_t* dst, size_t length) {\n    size_t i = 0;\n    __m256i mask_vec = _mm256_set1_epi32(mask);\n    \n    for (; i <= length - 16; i += 16) {\n        __m256i indices = _mm256_set_epi32(i + 15, i + 14, i + 13, i + 12, i + 11, i + 10, i + 9, i + 8);\n        __m256i and_result = _mm256_and_si256(indices, mask_vec);\n        __m256i blend_mask = _mm256_cmpgt_epi32(and_result, _mm256_setzero_si256());\n\n        __m256i src1_vec = _mm256_loadu_si256((__m256i*)&src1[i]);\n        __m256i src2_vec = _mm256_loadu_si256((__m256i*)&src2[i]);\n        \n        __m256i result = _mm256_blendv_epi8(src2_vec, src1_vec, blend_mask);\n        _mm256_storeu_si256((__m256i*)&dst[i], result);\n    }\n\n    for (; i < length; ++i) {\n        dst[i] = (i & mask) ? src1[i] : src2[i];\n    }\n}\n```"}
{"task_id": "SimdBench_15_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid vector_blend_simd(const uint16_t* src1, const uint16_t* src2, uint32_t mask, uint16_t* dst, size_t length) {\n    size_t i = 0;\n    __m256i mask_vec = _mm256_set1_epi32(mask);\n    \n    for (; i <= length - 16; i += 16) {\n        __m256i indices = _mm256_set_epi32(i + 15, i + 14, i + 13, i + 12, i + 11, i + 10, i + 9, i + 8);\n        __m256i and_result = _mm256_and_si256(indices, mask_vec);\n        __m256i blend_mask = _mm256_cmpgt_epi32(and_result, _mm256_setzero_si256());\n\n        __m256i src1_vec = _mm256_loadu_si256((__m256i*)&src1[i]);\n        __m256i src2_vec = _mm256_loadu_si256((__m256i*)&src2[i]);\n        \n        __m256i result = _mm256_blendv_epi8(src2_vec, src1_vec, blend_mask);\n        _mm256_storeu_si256((__m256i*)&dst[i], result);\n    }\n\n    for (; i < length; ++i) {\n        dst[i] = (i & mask) ? src1[i] : src2[i];\n    }\n}\n```"}
{"task_id": "SimdBench_15_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid vector_blend_simd(const uint16_t* src1, const uint16_t* src2, uint32_t mask, uint16_t* dst, size_t length) {\n    size_t i = 0;\n    __m256i mask_vec = _mm256_set1_epi32(mask);\n    \n    for (; i <= length - 16; i += 16) {\n        __m256i indices = _mm256_set_epi32(i + 15, i + 14, i + 13, i + 12, i + 11, i + 10, i + 9, i + 8);\n        __m256i and_result = _mm256_and_si256(indices, mask_vec);\n        __m256i blend_mask = _mm256_cmpgt_epi32(and_result, _mm256_setzero_si256());\n\n        __m256i src1_vec = _mm256_loadu_si256((__m256i*)&src1[i]);\n        __m256i src2_vec = _mm256_loadu_si256((__m256i*)&src2[i]);\n        \n        __m256i result = _mm256_blendv_epi8(src2_vec, src1_vec, blend_mask);\n        _mm256_storeu_si256((__m256i*)&dst[i], result);\n    }\n\n    for (; i < length; i++) {\n        dst[i] = (i & mask) ? src1[i] : src2[i];\n    }\n}\n```"}
{"task_id": "SimdBench_15_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid vector_blend_simd(const uint16_t* src1, const uint16_t* src2, uint32_t mask, uint16_t* dst, size_t length) {\n    size_t i = 0;\n    __m256i mask_vec = _mm256_set1_epi32(mask);\n    \n    for (; i <= length - 16; i += 16) {\n        __m256i indices = _mm256_set_epi32(i + 15, i + 14, i + 13, i + 12, i + 11, i + 10, i + 9, i + 8);\n        __m256i and_result = _mm256_and_si256(indices, mask_vec);\n        __m256i blend_mask = _mm256_cmpgt_epi32(and_result, _mm256_setzero_si256());\n\n        __m256i src1_vec = _mm256_loadu_si256((__m256i*)&src1[i]);\n        __m256i src2_vec = _mm256_loadu_si256((__m256i*)&src2[i]);\n        \n        __m256i result = _mm256_blendv_epi8(src2_vec, src1_vec, blend_mask);\n        _mm256_storeu_si256((__m256i*)&dst[i], result);\n    }\n\n    for (; i < length; i++) {\n        dst[i] = (i & mask) ? src1[i] : src2[i];\n    }\n}\n```"}
{"task_id": "SimdBench_16_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid population_count_simd(const uint32_t* src, uint32_t* dst, size_t length) {\n    size_t i;\n    for (i = 0; i + 8 <= length; i += 8) {\n        __m256i data = _mm256_loadu_si256((__m256i*)&src[i]);\n        __m256i count = _mm256_setzero_si256();\n\n        count = _mm256_add_epi32(count, _mm256_and_si256(data, _mm256_set1_epi32(1)));\n        data = _mm256_srli_epi32(data, 1);\n        count = _mm256_add_epi32(count, _mm256_and_si256(data, _mm256_set1_epi32(1)));\n        data = _mm256_srli_epi32(data, 1);\n        count = _mm256_add_epi32(count, _mm256_and_si256(data, _mm256_set1_epi32(1)));\n        data = _mm256_srli_epi32(data, 1);\n        count = _mm256_add_epi32(count, _mm256_and_si256(data, _mm256_set1_epi32(1)));\n        data = _mm256_srli_epi32(data, 1);\n        count = _mm256_add_epi32(count, _mm256_and_si256(data, _mm256_set1_epi32(1)));\n        data = _mm256_srli_epi32(data, 1);\n        count = _mm256_add_epi32(count, _mm256_and_si256(data, _mm256_set1_epi32(1)));\n        data = _mm256_srli_epi32(data, 1);\n        count = _mm256_add_epi32(count, _mm256_and_si256(data, _mm256_set1_epi32(1)));\n        data = _mm256_srli_epi32(data, 1);\n        count = _mm256_add_epi32(count, _mm256_and_si256(data, _mm256_set1_epi32(1)));\n\n        _mm256_storeu_si256((__m256i*)&dst[i], count);\n    }\n\n    for (; i < length; i++) {\n        dst[i] = __builtin_popcount(src[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_16_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid population_count_simd(const uint32_t* src, uint32_t* dst, size_t length) {\n    size_t i;\n    for (i = 0; i + 8 <= length; i += 8) {\n        __m256i data = _mm256_loadu_si256((__m256i*)&src[i]);\n        __m256i count = _mm256_setzero_si256();\n\n        count = _mm256_add_epi32(count, _mm256_and_si256(data, _mm256_set1_epi32(1)));\n        data = _mm256_srli_epi32(data, 1);\n        count = _mm256_add_epi32(count, _mm256_and_si256(data, _mm256_set1_epi32(1)));\n        data = _mm256_srli_epi32(data, 1);\n        count = _mm256_add_epi32(count, _mm256_and_si256(data, _mm256_set1_epi32(1)));\n        data = _mm256_srli_epi32(data, 1);\n        count = _mm256_add_epi32(count, _mm256_and_si256(data, _mm256_set1_epi32(1)));\n        data = _mm256_srli_epi32(data, 1);\n        count = _mm256_add_epi32(count, _mm256_and_si256(data, _mm256_set1_epi32(1)));\n        data = _mm256_srli_epi32(data, 1);\n        count = _mm256_add_epi32(count, _mm256_and_si256(data, _mm256_set1_epi32(1)));\n        data = _mm256_srli_epi32(data, 1);\n        count = _mm256_add_epi32(count, _mm256_and_si256(data, _mm256_set1_epi32(1)));\n        data = _mm256_srli_epi32(data, 1);\n        count = _mm256_add_epi32(count, _mm256_and_si256(data, _mm256_set1_epi32(1)));\n\n        count = _mm256_hadd_epi32(count, count);\n        count = _mm256_hadd_epi32(count, count);\n        count = _mm256_permute4x64_epi64(count, _MM_SHUFFLE(2, 3, 0, 1));\n        _mm256_storeu_si256((__m256i*)&dst[i], count);\n    }\n\n    for (; i < length; i++) {\n        dst[i] = __builtin_popcount(src[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_16_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid population_count_simd(const uint32_t* src, uint32_t* dst, size_t length) {\n    size_t i;\n    for (i = 0; i + 8 <= length; i += 8) {\n        __m256i data = _mm256_loadu_si256((__m256i*)&src[i]);\n        __m256i count = _mm256_setzero_si256();\n\n        count = _mm256_add_epi32(count, _mm256_and_si256(data, _mm256_set1_epi32(1)));\n        data = _mm256_srli_epi32(data, 1);\n        count = _mm256_add_epi32(count, _mm256_and_si256(data, _mm256_set1_epi32(1)));\n        data = _mm256_srli_epi32(data, 1);\n        count = _mm256_add_epi32(count, _mm256_and_si256(data, _mm256_set1_epi32(1)));\n        data = _mm256_srli_epi32(data, 1);\n        count = _mm256_add_epi32(count, _mm256_and_si256(data, _mm256_set1_epi32(1)));\n        data = _mm256_srli_epi32(data, 1);\n        count = _mm256_add_epi32(count, _mm256_and_si256(data, _mm256_set1_epi32(1)));\n        data = _mm256_srli_epi32(data, 1);\n        count = _mm256_add_epi32(count, _mm256_and_si256(data, _mm256_set1_epi32(1)));\n        data = _mm256_srli_epi32(data, 1);\n        count = _mm256_add_epi32(count, _mm256_and_si256(data, _mm256_set1_epi32(1)));\n        data = _mm256_srli_epi32(data, 1);\n        count = _mm256_add_epi32(count, _mm256_and_si256(data, _mm256_set1_epi32(1)));\n\n        count = _mm256_hadd_epi32(count, count);\n        count = _mm256_hadd_epi32(count, count);\n        count = _mm256_hadd_epi32(count, count);\n        \n        _mm256_storeu_si256((__m256i*)&dst[i], count);\n    }\n\n    for (; i < length; i++) {\n        dst[i] = __builtin_popcount(src[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_16_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid population_count_simd(const uint32_t* src, uint32_t* dst, size_t length) {\n    size_t i;\n    for (i = 0; i + 8 <= length; i += 8) {\n        __m256i data = _mm256_loadu_si256((__m256i*)&src[i]);\n        __m256i count = _mm256_setzero_si256();\n\n        count = _mm256_add_epi32(count, _mm256_and_si256(data, _mm256_set1_epi32(1)));\n        count = _mm256_add_epi32(count, _mm256_and_si256(_mm256_srli_epi32(data, 1), _mm256_set1_epi32(1)));\n        count = _mm256_add_epi32(count, _mm256_and_si256(_mm256_srli_epi32(data, 2), _mm256_set1_epi32(1)));\n        count = _mm256_add_epi32(count, _mm256_and_si256(_mm256_srli_epi32(data, 3), _mm256_set1_epi32(1)));\n        count = _mm256_add_epi32(count, _mm256_and_si256(_mm256_srli_epi32(data, 4), _mm256_set1_epi32(1)));\n        count = _mm256_add_epi32(count, _mm256_and_si256(_mm256_srli_epi32(data, 5), _mm256_set1_epi32(1)));\n        count = _mm256_add_epi32(count, _mm256_and_si256(_mm256_srli_epi32(data, 6), _mm256_set1_epi32(1)));\n        count = _mm256_add_epi32(count, _mm256_and_si256(_mm256_srli_epi32(data, 7), _mm256_set1_epi32(1)));\n        count = _mm256_add_epi32(count, _mm256_and_si256(_mm256_srli_epi32(data, 8), _mm256_set1_epi32(1)));\n        count = _mm256_add_epi32(count, _mm256_and_si256(_mm256_srli_epi32(data, 9), _mm256_set1_epi32(1)));\n        count = _mm256_add_epi32(count, _mm256_and_si256(_mm256_srli_epi32(data, 10), _mm256_set1_epi32(1)));\n        count = _mm256_add_epi32(count, _mm256_and_si256(_mm256_srli_epi32(data, 11), _mm256_set1_epi32(1)));\n        count = _mm256_add_epi32(count, _mm256_and_si256(_mm256_srli_epi32(data, 12), _mm256_set1_epi32(1)));\n        count = _mm256_add_epi32(count, _mm256_and_si256(_mm256_srli_epi32(data, 13), _mm256_set1_epi32(1)));\n        count = _mm256_add_epi32(count, _mm256_and_si256(_mm256_srli_epi32(data, 14), _mm256_set1_epi32(1)));\n        count = _mm256_add_epi32(count, _mm256_and_si256(_mm256_srli_epi32(data, 15), _mm256_set1_epi32(1)));\n\n        _mm256_storeu_si256((__m256i*)&dst[i], count);\n    }\n\n    for (; i < length; i++) {\n        dst[i] = __builtin_popcount(src[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_16_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid population_count_simd(const uint32_t* src, uint32_t* dst, size_t length) {\n    size_t i;\n    for (i = 0; i + 8 <= length; i += 8) {\n        __m256i data = _mm256_loadu_si256((__m256i*)&src[i]);\n        __m256i count = _mm256_setzero_si256();\n\n        count = _mm256_add_epi32(count, _mm256_and_si256(data, _mm256_set1_epi32(1)));\n        data = _mm256_srli_epi32(data, 1);\n        count = _mm256_add_epi32(count, _mm256_and_si256(data, _mm256_set1_epi32(1)));\n        data = _mm256_srli_epi32(data, 1);\n        count = _mm256_add_epi32(count, _mm256_and_si256(data, _mm256_set1_epi32(1)));\n        data = _mm256_srli_epi32(data, 1);\n        count = _mm256_add_epi32(count, _mm256_and_si256(data, _mm256_set1_epi32(1)));\n        data = _mm256_srli_epi32(data, 1);\n        count = _mm256_add_epi32(count, _mm256_and_si256(data, _mm256_set1_epi32(1)));\n        data = _mm256_srli_epi32(data, 1);\n        count = _mm256_add_epi32(count, _mm256_and_si256(data, _mm256_set1_epi32(1)));\n        data = _mm256_srli_epi32(data, 1);\n        count = _mm256_add_epi32(count, _mm256_and_si256(data, _mm256_set1_epi32(1)));\n        data = _mm256_srli_epi32(data, 1);\n        count = _mm256_add_epi32(count, _mm256_and_si256(data, _mm256_set1_epi32(1)));\n\n        count = _mm256_hadd_epi32(count, count);\n        count = _mm256_hadd_epi32(count, count);\n        count = _mm256_permute2x128_si256(count, count, 1);\n        count = _mm256_add_epi32(count, _mm256_permute2x128_si256(count, count, 0));\n\n        _mm256_storeu_si256((__m256i*)&dst[i], count);\n    }\n\n    for (; i < length; i++) {\n        dst[i] = __builtin_popcount(src[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_17_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <stdint.h>\n#include <stddef.h>\n\nvoid saturating_add_simd(const uint16_t* src1, const uint16_t* src2, uint16_t* dst, size_t length) {\n    size_t i = 0;\n    size_t simd_length = length / 16 * 16; // Process in chunks of 16\n\n    for (; i < simd_length; i += 16) {\n        __m256i a = _mm256_loadu_si256((__m256i*)&src1[i]);\n        __m256i b = _mm256_loadu_si256((__m256i*)&src2[i]);\n        __m256i sum = _mm256_add_epi16(a, b);\n        __m256i max_val = _mm256_set1_epi16(UINT16_MAX);\n        __m256i result = _mm256_min_epi16(sum, max_val);\n        _mm256_storeu_si256((__m256i*)&dst[i], result);\n    }\n\n    for (; i < length; ++i) {\n        uint32_t temp = (uint32_t)src1[i] + (uint32_t)src2[i];\n        dst[i] = (temp > UINT16_MAX) ? UINT16_MAX : (uint16_t)temp;\n    }\n}\n```"}
{"task_id": "SimdBench_17_AVX", "completion": "```cpp\nvoid saturating_add_simd(const uint16_t* src1, const uint16_t* src2, uint16_t* dst, size_t length) {\n    size_t i = 0;\n    __m256i max_val = _mm256_set1_epi16(UINT16_MAX);\n\n    for (; i <= length - 16; i += 16) {\n        __m256i a = _mm256_loadu_si256((__m256i*)&src1[i]);\n        __m256i b = _mm256_loadu_si256((__m256i*)&src2[i]);\n        __m256i sum = _mm256_add_epi16(a, b);\n        __m256i result = _mm256_min_epi16(sum, max_val);\n        _mm256_storeu_si256((__m256i*)&dst[i], result);\n    }\n\n    for (; i < length; i++) {\n        uint32_t temp = (uint32_t)src1[i] + (uint32_t)src2[i];\n        dst[i] = (temp > UINT16_MAX) ? UINT16_MAX : (uint16_t)temp;\n    }\n}\n```"}
{"task_id": "SimdBench_17_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <stdint.h>\n#include <stddef.h>\n\nvoid saturating_add_simd(const uint16_t* src1, const uint16_t* src2, uint16_t* dst, size_t length) {\n    size_t i = 0;\n    size_t simd_length = length / 16 * 16; // Process in chunks of 16\n\n    for (; i < simd_length; i += 16) {\n        __m256i a = _mm256_loadu_si256((__m256i*)&src1[i]);\n        __m256i b = _mm256_loadu_si256((__m256i*)&src2[i]);\n        __m256i sum = _mm256_adds_epu16(a, b);\n        _mm256_storeu_si256((__m256i*)&dst[i], sum);\n    }\n\n    for (; i < length; ++i) {\n        uint32_t temp = (uint32_t)src1[i] + (uint32_t)src2[i];\n        dst[i] = (temp > UINT16_MAX) ? UINT16_MAX : (uint16_t)temp;\n    }\n}\n```"}
{"task_id": "SimdBench_17_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <stdint.h>\n#include <stddef.h>\n\nvoid saturating_add_simd(const uint16_t* src1, const uint16_t* src2, uint16_t* dst, size_t length) {\n    size_t i;\n    for (i = 0; i + 16 <= length; i += 16) {\n        __m256i a = _mm256_loadu_si256((__m256i*)&src1[i]);\n        __m256i b = _mm256_loadu_si256((__m256i*)&src2[i]);\n        __m256i sum = _mm256_adds_epu16(a, b);\n        _mm256_storeu_si256((__m256i*)&dst[i], sum);\n    }\n    for (; i < length; i++) {\n        uint32_t temp = (uint32_t)src1[i] + (uint32_t)src2[i];\n        dst[i] = (temp > UINT16_MAX) ? UINT16_MAX : (uint16_t)temp;\n    }\n}\n```"}
{"task_id": "SimdBench_17_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <stdint.h>\n#include <stddef.h>\n\nvoid saturating_add_simd(const uint16_t* src1, const uint16_t* src2, uint16_t* dst, size_t length) {\n    size_t i = 0;\n    __m256i max_val = _mm256_set1_epi16(UINT16_MAX);\n\n    for (; i <= length - 16; i += 16) {\n        __m256i vec1 = _mm256_loadu_si256((__m256i*)&src1[i]);\n        __m256i vec2 = _mm256_loadu_si256((__m256i*)&src2[i]);\n        __m256i sum = _mm256_add_epi16(vec1, vec2);\n        __m256i result = _mm256_min_epi16(sum, max_val);\n        _mm256_storeu_si256((__m256i*)&dst[i], result);\n    }\n\n    for (; i < length; i++) {\n        uint32_t temp = (uint32_t)src1[i] + (uint32_t)src2[i];\n        dst[i] = (temp > UINT16_MAX) ? UINT16_MAX : (uint16_t)temp;\n    }\n}\n```"}
{"task_id": "SimdBench_18_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid range_matrix_mul_simd(const double* A, const double* B, double* C, size_t m, size_t n, size_t p) {\n    for (size_t i = 0; i < m; i++) {\n        for (size_t j = 0; j < p; j++) {\n            __m256d sum = _mm256_setzero_pd();\n            for (size_t k = 0; k < n; k += 4) {\n                __m256d a = _mm256_loadu_pd(&A[i * n + k]);\n                __m256d b = _mm256_loadu_pd(&B[k * p + j]);\n\n                __m256d maskA = _mm256_and_pd(_mm256_cmp_pd(a, _mm256_set1_pd(-100.0), _MM_CMPINT_GE), \n                                               _mm256_cmp_pd(a, _mm256_set1_pd(100.0), _MM_CMPINT_LE));\n                __m256d maskB = _mm256_and_pd(_mm256_cmp_pd(b, _mm256_set1_pd(-100.0), _MM_CMPINT_GE), \n                                               _mm256_cmp_pd(b, _mm256_set1_pd(100.0), _MM_CMPINT_LE));\n                __m256d mask = _mm256_and_pd(maskA, maskB);\n\n                sum = _mm256_add_pd(sum, _mm256_mul_pd(a, b));\n            }\n            double temp[4];\n            _mm256_storeu_pd(temp, sum);\n            C[i * p + j] = temp[0] + temp[1] + temp[2] + temp[3];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_18_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid range_matrix_mul_simd(const double* A, const double* B, double* C, size_t m, size_t n, size_t p) {\n    for (size_t i = 0; i < m; ++i) {\n        for (size_t j = 0; j < p; ++j) {\n            __m256d sum = _mm256_setzero_pd();\n            for (size_t k = 0; k < n; k += 4) {\n                __m256d a_vals = _mm256_loadu_pd(&A[i * n + k]);\n                __m256d b_vals = _mm256_loadu_pd(&B[k * p + j]);\n\n                __m256d mask_a = _mm256_and_pd(_mm256_cmp_pd(a_vals, _mm256_set1_pd(-100.0), _MM_CMPINT_GE), \n                                                _mm256_cmp_pd(a_vals, _mm256_set1_pd(100.0), _MM_CMPINT_LE));\n                __m256d mask_b = _mm256_and_pd(_mm256_cmp_pd(b_vals, _mm256_set1_pd(-100.0), _MM_CMPINT_GE), \n                                                _mm256_cmp_pd(b_vals, _mm256_set1_pd(100.0), _MM_CMPINT_LE));\n\n                __m256d mask = _mm256_and_pd(mask_a, mask_b);\n                __m256d prod = _mm256_mul_pd(a_vals, b_vals);\n                prod = _mm256_and_pd(prod, mask);\n                sum = _mm256_add_pd(sum, prod);\n            }\n            sum = _mm256_hadd_pd(sum, sum);\n            sum = _mm256_hadd_pd(sum, sum);\n            C[i * p + j] = _mm_cvtsd_f64(sum);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_18_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid range_matrix_mul_simd(const double* A, const double* B, double* C, size_t m, size_t n, size_t p) {\n    for (size_t i = 0; i < m; i++) {\n        for (size_t j = 0; j < p; j++) {\n            __m256d sum = _mm256_setzero_pd();\n            for (size_t k = 0; k < n; k += 4) {\n                __m256d a_vec = _mm256_loadu_pd(&A[i * n + k]);\n                __m256d b_vec = _mm256_loadu_pd(&B[k * p + j]);\n\n                __m256d mask_a = _mm256_and_pd(_mm256_cmp_pd(a_vec, _mm256_set1_pd(-100.0), _MM_CMPINT_GE), \n                                                _mm256_cmp_pd(a_vec, _mm256_set1_pd(100.0), _MM_CMPINT_LE));\n                __m256d mask_b = _mm256_and_pd(_mm256_cmp_pd(b_vec, _mm256_set1_pd(-100.0), _MM_CMPINT_GE), \n                                                _mm256_cmp_pd(b_vec, _mm256_set1_pd(100.0), _MM_CMPINT_LE));\n                __m256d mask = _mm256_and_pd(mask_a, mask_b);\n\n                a_vec = _mm256_and_pd(a_vec, mask);\n                b_vec = _mm256_and_pd(b_vec, mask);\n\n                sum = _mm256_add_pd(sum, _mm256_mul_pd(a_vec, b_vec));\n            }\n            sum = _mm256_hadd_pd(sum, sum);\n            sum = _mm256_hadd_pd(sum, sum);\n            C[i * p + j] += _mm_cvtsd_f64(sum);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_18_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid range_matrix_mul_simd(const double* A, const double* B, double* C, size_t m, size_t n, size_t p) {\n    for (size_t i = 0; i < m; ++i) {\n        for (size_t j = 0; j < p; ++j) {\n            __m256d sum = _mm256_setzero_pd();\n            for (size_t k = 0; k < n; k += 4) {\n                __m256d a_vec = _mm256_loadu_pd(&A[i * n + k]);\n                __m256d b_vec = _mm256_loadu_pd(&B[k * p + j]);\n\n                __m256d mask_a = _mm256_and_pd(_mm256_cmp_pd(a_vec, _mm256_set1_pd(-100.0), _MM_CMPINT_GE), \n                                                _mm256_cmp_pd(a_vec, _mm256_set1_pd(100.0), _MM_CMPINT_LE));\n                __m256d mask_b = _mm256_and_pd(_mm256_cmp_pd(b_vec, _mm256_set1_pd(-100.0), _MM_CMPINT_GE), \n                                                _mm256_cmp_pd(b_vec, _mm256_set1_pd(100.0), _MM_CMPINT_LE));\n\n                __m256d mask = _mm256_and_pd(mask_a, mask_b);\n                __m256d product = _mm256_mul_pd(a_vec, b_vec);\n                product = _mm256_and_pd(product, mask);\n\n                sum = _mm256_add_pd(sum, product);\n            }\n            sum = _mm256_hadd_pd(sum, sum);\n            sum = _mm256_hadd_pd(sum, sum);\n            C[i * p + j] = _mm_cvtsd_f64(sum);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_18_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid range_matrix_mul_simd(const double* A, const double* B, double* C, size_t m, size_t n, size_t p) {\n    for (size_t i = 0; i < m; ++i) {\n        for (size_t j = 0; j < p; ++j) {\n            __m256d sum = _mm256_setzero_pd();\n            for (size_t k = 0; k < n; k += 4) {\n                __m256d a_vals = _mm256_loadu_pd(&A[i * n + k]);\n                __m256d b_vals = _mm256_loadu_pd(&B[k * p + j]);\n\n                __m256d mask_a = _mm256_and_pd(_mm256_cmp_pd(a_vals, _mm256_set1_pd(-100.0), _MM_CMPINT_GE), \n                                                _mm256_cmp_pd(a_vals, _mm256_set1_pd(100.0), _MM_CMPINT_LE));\n                __m256d mask_b = _mm256_and_pd(_mm256_cmp_pd(b_vals, _mm256_set1_pd(-100.0), _MM_CMPINT_GE), \n                                                _mm256_cmp_pd(b_vals, _mm256_set1_pd(100.0), _MM_CMPINT_LE));\n                __m256d mask = _mm256_and_pd(mask_a, mask_b);\n\n                sum = _mm256_add_pd(sum, _mm256_mul_pd(a_vals, b_vals));\n            }\n            sum = _mm256_hadd_pd(sum, sum);\n            sum = _mm256_hadd_pd(sum, sum);\n            C[i * p + j] = _mm_cvtsd_f64(sum);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_19_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid tensor_add_3d_simd(const int64_t* A, const int64_t* B, int64_t* C, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t i;\n\n    // Process 8 elements at a time\n    for (i = 0; i <= total_elements - 8; i += 8) {\n        __m256i a_vec = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i b_vec = _mm256_loadu_si256((__m256i*)&B[i]);\n        __m256i c_vec = _mm256_add_epi64(a_vec, b_vec);\n        _mm256_storeu_si256((__m256i*)&C[i], c_vec);\n    }\n\n    // Handle remaining elements\n    for (; i < total_elements; i++) {\n        C[i] = A[i] + B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_19_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid tensor_add_3d_simd(const int64_t* A, const int64_t* B, int64_t* C, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t i;\n\n    // Process 8 elements at a time using AVX2\n    for (i = 0; i + 7 < total_elements; i += 8) {\n        __m256i a = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i b = _mm256_loadu_si256((__m256i*)&B[i]);\n        __m256i c = _mm256_add_epi64(a, b);\n        _mm256_storeu_si256((__m256i*)&C[i], c);\n    }\n\n    // Handle remaining elements\n    for (; i < total_elements; ++i) {\n        C[i] = A[i] + B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_19_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid tensor_add_3d_simd(const int64_t* A, const int64_t* B, int64_t* C, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t i;\n\n    // Process 8 elements at a time using AVX2\n    for (i = 0; i + 7 < total_elements; i += 8) {\n        __m256i a = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i b = _mm256_loadu_si256((__m256i*)&B[i]);\n        __m256i c = _mm256_add_epi64(a, b);\n        _mm256_storeu_si256((__m256i*)&C[i], c);\n    }\n\n    // Handle remaining elements\n    for (; i < total_elements; ++i) {\n        C[i] = A[i] + B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_19_AVX", "completion": "```cpp\nvoid tensor_add_3d_simd(const int64_t* A, const int64_t* B, int64_t* C, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t i;\n\n    // Process 8 elements at a time using AVX2\n    for (i = 0; i <= total_elements - 8; i += 8) {\n        __m256i a = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i b = _mm256_loadu_si256((__m256i*)&B[i]);\n        __m256i c = _mm256_add_epi64(a, b);\n        _mm256_storeu_si256((__m256i*)&C[i], c);\n    }\n\n    // Handle remaining elements\n    for (; i < total_elements; i++) {\n        C[i] = A[i] + B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_19_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid tensor_add_3d_simd(const int64_t* A, const int64_t* B, int64_t* C, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t i;\n\n    // Process 8 elements at a time using AVX2\n    for (i = 0; i + 7 < total_elements; i += 8) {\n        __m256i a = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i b = _mm256_loadu_si256((__m256i*)&B[i]);\n        __m256i c = _mm256_add_epi64(a, b);\n        _mm256_storeu_si256((__m256i*)&C[i], c);\n    }\n\n    // Handle remaining elements\n    for (; i < total_elements; ++i) {\n        C[i] = A[i] + B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_20_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid vector_add_round_nearest_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    size_t i = 0;\n    for (; i + 8 <= length; i += 8) {\n        __m256 vec1 = _mm256_loadu_ps(&src1[i]);\n        __m256 vec2 = _mm256_loadu_ps(&src2[i]);\n        __m256 sum = _mm256_add_ps(vec1, vec2);\n        __m256 rounded = _mm256_round_ps(sum, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n        _mm256_storeu_ps(&dst[i], rounded);\n    }\n    for (; i < length; i++) {\n        dst[i] = roundf(src1[i] + src2[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_20_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid vector_add_round_nearest_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    size_t i = 0;\n    for (; i + 8 <= length; i += 8) {\n        __m256 vec1 = _mm256_loadu_ps(&src1[i]);\n        __m256 vec2 = _mm256_loadu_ps(&src2[i]);\n        __m256 result = _mm256_add_ps(vec1, vec2);\n        __m256 rounded = _mm256_round_ps(result, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n        _mm256_storeu_ps(&dst[i], rounded);\n    }\n    for (; i < length; i++) {\n        dst[i] = roundf(src1[i] + src2[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_20_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid vector_add_round_nearest_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    size_t i;\n    for (i = 0; i + 8 <= length; i += 8) {\n        __m256 a = _mm256_loadu_ps(&src1[i]);\n        __m256 b = _mm256_loadu_ps(&src2[i]);\n        __m256 sum = _mm256_add_ps(a, b);\n        __m256 rounded = _mm256_round_ps(sum, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n        _mm256_storeu_ps(&dst[i], rounded);\n    }\n    for (; i < length; i++) {\n        dst[i] = roundf(src1[i] + src2[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_20_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid vector_add_round_nearest_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    size_t i = 0;\n    for (; i + 8 <= length; i += 8) {\n        __m256 v1 = _mm256_loadu_ps(&src1[i]);\n        __m256 v2 = _mm256_loadu_ps(&src2[i]);\n        __m256 v_sum = _mm256_add_ps(v1, v2);\n        __m256 v_rounded = _mm256_round_ps(v_sum, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n        _mm256_storeu_ps(&dst[i], v_rounded);\n    }\n    for (; i < length; i++) {\n        dst[i] = roundf(src1[i] + src2[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_20_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid vector_add_round_nearest_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    size_t i = 0;\n    // Process 8 floats at a time\n    for (; i + 8 <= length; i += 8) {\n        __m256 a = _mm256_loadu_ps(&src1[i]);\n        __m256 b = _mm256_loadu_ps(&src2[i]);\n        __m256 sum = _mm256_add_ps(a, b);\n        __m256 rounded = _mm256_round_ps(sum, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n        _mm256_storeu_ps(&dst[i], rounded);\n    }\n    // Handle remaining elements\n    for (; i < length; i++) {\n        dst[i] = roundf(src1[i] + src2[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_21_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <math.h>\n\nvoid vector_mul_round_up_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    size_t i;\n    __m256 v50 = _mm256_set1_ps(50.0f);\n    __m256 vNegOne = _mm256_set1_ps(-1.0f);\n\n    for (i = 0; i < length; i += 8) {\n        __m256 vSrc1 = _mm256_loadu_ps(&src1[i]);\n        __m256 vSrc2 = _mm256_loadu_ps(&src2[i]);\n        \n        __m256 vDiff = _mm256_sub_ps(vSrc1, vSrc2);\n        __m256 vAbsDiff = _mm256_andnot_ps(_mm256_set1_ps(-0.0f), vDiff);\n        \n        __m256 vCondition = _mm256_cmp_ps(vAbsDiff, v50, _CMP_LT_OQ);\n        __m256i vIndex = _mm256_set_epi32(i + 7, i + 6, i + 5, i + 4, i + 3, i + 2, i + 1, i);\n        __m256i vMask = _mm256_and_si256(vIndex, _mm256_set1_epi32(1));\n        vCondition = _mm256_and_ps(vCondition, _mm256_cvtepi32_ps(vMask));\n\n        __m256 vResult = _mm256_mul_ps(vSrc1, vSrc2);\n        vResult = _mm256_round_ps(vResult, _MM_FROUND_UP | _MM_FROUND_NO_EXC);\n        \n        vResult = _mm256_blendv_ps(vNegOne, vResult, vCondition);\n        \n        _mm256_storeu_ps(&dst[i], vResult);\n    }\n}\n```"}
{"task_id": "SimdBench_21_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <cmath>\n\nvoid vector_mul_round_up_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    size_t i;\n    __m256 v50 = _mm256_set1_ps(50.0f);\n    __m256 vNegOne = _mm256_set1_ps(-1.0f);\n\n    for (i = 0; i < length; i += 8) {\n        __m256 vSrc1 = _mm256_loadu_ps(&src1[i]);\n        __m256 vSrc2 = _mm256_loadu_ps(&src2[i]);\n\n        __m256 vDiff = _mm256_sub_ps(vSrc1, vSrc2);\n        __m256 vAbsDiff = _mm256_andnot_ps(_mm256_set1_ps(-0.0f), vDiff);\n        vAbsDiff = _mm256_max_ps(vAbsDiff, _mm256_neg_ps(vDiff));\n\n        __m256 vMask = _mm256_cmp_ps(vAbsDiff, v50, _CMP_LE_OS);\n        __m256i vIndexMask = _mm256_set1_epi32(0xFFFFFFFF);\n        __m256i vIndex = _mm256_set_epi32(i + 7, i + 6, i + 5, i + 4, i + 3, i + 2, i + 1, i);\n        vIndexMask = _mm256_and_si256(vIndexMask, _mm256_and_si256(_mm256_set1_epi32(0xFFFFFFFE), _mm256_cmpgt_epi32(vIndex, _mm256_set1_epi32(length - 1))));\n\n        vMask = _mm256_and_ps(vMask, _mm256_castsi256_ps(vIndexMask));\n\n        __m256 vResult = _mm256_mul_ps(vSrc1, vSrc2);\n        vResult = _mm256_round_ps(vResult, _MM_FROUND_UP | _MM_FROUND_NO_EXC);\n\n        vResult = _mm256_blendv_ps(vNegOne, vResult, vMask);\n\n        _mm256_storeu_ps(&dst[i], vResult);\n    }\n\n    for (; i < length; ++i) {\n        if (i % 2 == 0) {\n            float diff = fabsf(src1[i] - src2[i]);\n            if (diff <= 50.0f) {\n                dst[i] = ceilf(src1[i] * src2[i]);\n            } else {\n                dst[i] = -1.0f;\n            }\n        } else {\n            dst[i] = -1.0f;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_21_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <cmath>\n\nvoid vector_mul_round_up_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    size_t i;\n    __m256 v50 = _mm256_set1_ps(50.0f);\n    __m256 vNegOne = _mm256_set1_ps(-1.0f);\n    \n    for (i = 0; i < length; i += 8) {\n        __m256 vSrc1 = _mm256_loadu_ps(&src1[i]);\n        __m256 vSrc2 = _mm256_loadu_ps(&src2[i]);\n        \n        __m256 vDiff = _mm256_sub_ps(vSrc1, vSrc2);\n        __m256 vAbsDiff = _mm256_andnot_ps(_mm256_set1_ps(-0.0f), vDiff);\n        \n        __m256 vCondition = _mm256_cmp_ps(vAbsDiff, v50, _CMP_LT_OQ);\n        \n        __m256 vResult = _mm256_mul_ps(vSrc1, vSrc2);\n        vResult = _mm256_round_ps(vResult, _MM_FROUND_UP);\n        \n        vResult = _mm256_blendv_ps(vNegOne, vResult, vCondition);\n        \n        _mm256_storeu_ps(&dst[i], vResult);\n    }\n    \n    for (; i < length; i++) {\n        if (i % 2 == 0) {\n            float diff = fabsf(src1[i] - src2[i]);\n            if (diff <= 50.0f) {\n                dst[i] = ceilf(src1[i] * src2[i]);\n            } else {\n                dst[i] = -1.0f;\n            }\n        } else {\n            dst[i] = -1.0f;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_21_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <cmath>\n\nvoid vector_mul_round_up_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    size_t i;\n    __m256 v50 = _mm256_set1_ps(50.0f);\n    __m256 vNegOne = _mm256_set1_ps(-1.0f);\n    \n    for (i = 0; i < length; i += 8) {\n        if (i % 2 == 0) {\n            __m256 vSrc1 = _mm256_loadu_ps(&src1[i]);\n            __m256 vSrc2 = _mm256_loadu_ps(&src2[i]);\n            __m256 vDiff = _mm256_sub_ps(vSrc1, vSrc2);\n            __m256 vAbsDiff = _mm256_abs_ps(vDiff);\n            __m256 vMask = _mm256_cmp_ps(vAbsDiff, v50, _CMP_LE_OS);\n            __m256 vResult = _mm256_mul_ps(vSrc1, vSrc2);\n            vResult = _mm256_round_ps(vResult, _MM_FROUND_UP | _MM_FROUND_NO_EXC);\n            vResult = _mm256_blendv_ps(vNegOne, vResult, vMask);\n            _mm256_storeu_ps(&dst[i], vResult);\n        } else {\n            _mm256_storeu_ps(&dst[i], vNegOne);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_21_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <math.h>\n\nvoid vector_mul_round_up_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    size_t i;\n    __m256 v50 = _mm256_set1_ps(50.0f);\n    __m256 vNegOne = _mm256_set1_ps(-1.0f);\n    \n    for (i = 0; i < length; i += 8) {\n        __m256 vSrc1 = _mm256_loadu_ps(&src1[i]);\n        __m256 vSrc2 = _mm256_loadu_ps(&src2[i]);\n        \n        __m256 vDiff = _mm256_sub_ps(vSrc1, vSrc2);\n        __m256 vAbsDiff = _mm256_andnot_ps(_mm256_set1_ps(-0.0f), vDiff);\n        \n        __m256 vCondition = _mm256_cmp_ps(vAbsDiff, v50, _CMP_LE_OS);\n        \n        __m256 vResult = _mm256_mul_ps(vSrc1, vSrc2);\n        vResult = _mm256_round_ps(vResult, _MM_FROUND_UP);\n        \n        vResult = _mm256_blendv_ps(vNegOne, vResult, vCondition);\n        \n        _mm256_storeu_ps(&dst[i], vResult);\n    }\n    \n    for (; i < length; i++) {\n        if (i % 2 == 0) {\n            float diff = fabsf(src1[i] - src2[i]);\n            if (diff <= 50.0f) {\n                dst[i] = ceilf(src1[i] * src2[i]);\n            } else {\n                dst[i] = -1.0f;\n            }\n        } else {\n            dst[i] = -1.0f;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_22_AVX", "completion": "```cpp\nvoid matrix_scalar_mul_simd(const double* mat, double scalar, double* dst, size_t m, size_t n) {\n    __m256d scalar_vec = _mm256_set1_pd(scalar);\n    size_t total_elements = m * n;\n    size_t i;\n\n    for (i = 0; i <= total_elements - 4; i += 4) {\n        __m256d mat_vec = _mm256_loadu_pd(&mat[i]);\n        __m256d result_vec = _mm256_mul_pd(mat_vec, scalar_vec);\n        _mm256_storeu_pd(&dst[i], result_vec);\n    }\n\n    for (; i < total_elements; ++i) {\n        dst[i] = mat[i] * scalar;\n    }\n}\n```"}
{"task_id": "SimdBench_22_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid matrix_scalar_mul_simd(const double* mat, double scalar, double* dst, size_t m, size_t n) {\n    __m256d scalar_vec = _mm256_set1_pd(scalar);\n    size_t total_elements = m * n;\n    size_t i;\n\n    for (i = 0; i <= total_elements - 4; i += 4) {\n        __m256d mat_vec = _mm256_loadu_pd(&mat[i]);\n        __m256d result_vec = _mm256_mul_pd(mat_vec, scalar_vec);\n        _mm256_storeu_pd(&dst[i], result_vec);\n    }\n\n    for (; i < total_elements; ++i) {\n        dst[i] = mat[i] * scalar;\n    }\n}\n```"}
{"task_id": "SimdBench_22_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid matrix_scalar_mul_simd(const double* mat, double scalar, double* dst, size_t m, size_t n) {\n    size_t total_elements = m * n;\n    __m256d scalar_vec = _mm256_set1_pd(scalar);\n    \n    size_t i;\n    for (i = 0; i <= total_elements - 4; i += 4) {\n        __m256d mat_vec = _mm256_loadu_pd(&mat[i]);\n        __m256d result_vec = _mm256_mul_pd(mat_vec, scalar_vec);\n        _mm256_storeu_pd(&dst[i], result_vec);\n    }\n    \n    for (; i < total_elements; ++i) {\n        dst[i] = mat[i] * scalar;\n    }\n}\n```"}
{"task_id": "SimdBench_22_AVX", "completion": "```cpp\nvoid matrix_scalar_mul_simd(const double* mat, double scalar, double* dst, size_t m, size_t n) {\n    __m256d vec_scalar = _mm256_set1_pd(scalar);\n    size_t total_elements = m * n;\n    size_t i;\n\n    for (i = 0; i <= total_elements - 4; i += 4) {\n        __m256d vec_mat = _mm256_loadu_pd(&mat[i]);\n        __m256d vec_result = _mm256_mul_pd(vec_mat, vec_scalar);\n        _mm256_storeu_pd(&dst[i], vec_result);\n    }\n\n    for (; i < total_elements; ++i) {\n        dst[i] = mat[i] * scalar;\n    }\n}\n```"}
{"task_id": "SimdBench_22_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid matrix_scalar_mul_simd(const double* mat, double scalar, double* dst, size_t m, size_t n) {\n    size_t total_elements = m * n;\n    __m256d scalar_vec = _mm256_set1_pd(scalar);\n    \n    size_t i;\n    for (i = 0; i <= total_elements - 4; i += 4) {\n        __m256d mat_vec = _mm256_loadu_pd(&mat[i]);\n        __m256d result_vec = _mm256_mul_pd(mat_vec, scalar_vec);\n        _mm256_storeu_pd(&dst[i], result_vec);\n    }\n    \n    for (; i < total_elements; ++i) {\n        dst[i] = mat[i] * scalar;\n    }\n}\n```"}
{"task_id": "SimdBench_23_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <math.h>\n\nvoid matrix_normalize_rows_simd(float* mat, size_t m, size_t n) {\n    for (size_t i = 0; i < m; ++i) {\n        __m256 sum_squares = _mm256_setzero_ps();\n        size_t j = 0;\n\n        for (; j + 7 < n; j += 8) {\n            __m256 vec = _mm256_loadu_ps(&mat[i * n + j]);\n            sum_squares = _mm256_fmadd_ps(vec, vec, sum_squares);\n        }\n\n        float sum_squares_array[8];\n        _mm256_storeu_ps(sum_squares_array, sum_squares);\n\n        float norm = 0.0f;\n        for (size_t k = 0; k < 8; ++k) {\n            norm += sum_squares_array[k];\n        }\n        norm = sqrt(norm);\n\n        for (j = 0; j < n; ++j) {\n            mat[i * n + j] /= norm;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_23_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <math.h>\n\nvoid matrix_normalize_rows_simd(float* mat, size_t m, size_t n) {\n    for (size_t i = 0; i < m; ++i) {\n        __m256 sum_squares = _mm256_setzero_ps();\n        size_t j = 0;\n\n        // Compute the sum of squares for the current row\n        for (; j + 8 <= n; j += 8) {\n            __m256 vec = _mm256_loadu_ps(&mat[i * n + j]);\n            sum_squares = _mm256_add_ps(sum_squares, _mm256_mul_ps(vec, vec));\n        }\n\n        // Horizontal sum of the sum_squares vector\n        float squares[8];\n        _mm256_storeu_ps(squares, sum_squares);\n        float norm = 0.0f;\n        for (size_t k = 0; k < 8; ++k) {\n            norm += squares[k];\n        }\n\n        // Handle remaining elements\n        for (; j < n; ++j) {\n            float val = mat[i * n + j];\n            norm += val * val;\n        }\n\n        norm = sqrtf(norm);\n\n        // Normalize the row\n        j = 0;\n        if (norm > 0.0f) {\n            for (; j + 8 <= n; j += 8) {\n                __m256 vec = _mm256_loadu_ps(&mat[i * n + j]);\n                __m256 normalized = _mm256_div_ps(vec, _mm256_set1_ps(norm));\n                _mm256_storeu_ps(&mat[i * n + j], normalized);\n            }\n\n            for (; j < n; ++j) {\n                mat[i * n + j] /= norm;\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_23_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <math.h>\n\nvoid matrix_normalize_rows_simd(float* mat, size_t m, size_t n) {\n    for (size_t i = 0; i < m; ++i) {\n        __m256 sum_squares = _mm256_setzero_ps();\n        for (size_t j = 0; j < n; j += 8) {\n            __m256 vec = _mm256_loadu_ps(&mat[i * n + j]);\n            sum_squares = _mm256_fmadd_ps(vec, vec, sum_squares);\n        }\n        \n        float norm_array[8];\n        _mm256_storeu_ps(norm_array, sum_squares);\n        \n        float norm = sqrt(norm_array[0] + norm_array[1] + norm_array[2] + norm_array[3] +\n                          norm_array[4] + norm_array[5] + norm_array[6] + norm_array[7]);\n        \n        for (size_t j = 0; j < n; j += 8) {\n            __m256 vec = _mm256_loadu_ps(&mat[i * n + j]);\n            __m256 norm_vec = _mm256_set1_ps(norm);\n            __m256 normalized_vec = _mm256_div_ps(vec, norm_vec);\n            _mm256_storeu_ps(&mat[i * n + j], normalized_vec);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_23_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <math.h>\n\nvoid matrix_normalize_rows_simd(float* mat, size_t m, size_t n) {\n    for (size_t i = 0; i < m; ++i) {\n        __m256 sum_squares = _mm256_setzero_ps();\n        for (size_t j = 0; j < n; j += 8) {\n            __m256 vec = _mm256_loadu_ps(&mat[i * n + j]);\n            sum_squares = _mm256_fmadd_ps(vec, vec, sum_squares);\n        }\n        \n        float norm[8];\n        _mm256_storeu_ps(norm, sum_squares);\n        \n        float l2_norm = sqrt(norm[0] + norm[1] + norm[2] + norm[3] + \n                             norm[4] + norm[5] + norm[6] + norm[7]);\n        \n        for (size_t j = 0; j < n; j += 8) {\n            __m256 vec = _mm256_loadu_ps(&mat[i * n + j]);\n            __m256 norm_vec = _mm256_set1_ps(l2_norm);\n            __m256 normalized_vec = _mm256_div_ps(vec, norm_vec);\n            _mm256_storeu_ps(&mat[i * n + j], normalized_vec);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_23_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <math.h>\n\nvoid matrix_normalize_rows_simd(float* mat, size_t m, size_t n) {\n    for (size_t i = 0; i < m; ++i) {\n        __m256 sum_squares = _mm256_setzero_ps();\n        size_t j = 0;\n\n        // Compute the sum of squares for the current row\n        for (; j + 8 <= n; j += 8) {\n            __m256 vec = _mm256_loadu_ps(&mat[i * n + j]);\n            sum_squares = _mm256_add_ps(sum_squares, _mm256_mul_ps(vec, vec));\n        }\n\n        // Horizontal sum of the squares\n        float temp[8];\n        _mm256_storeu_ps(temp, sum_squares);\n        float norm = 0.0f;\n        for (size_t k = 0; k < 8; ++k) {\n            norm += temp[k];\n        }\n\n        // Handle remaining elements\n        for (; j < n; ++j) {\n            norm += mat[i * n + j] * mat[i * n + j];\n        }\n\n        norm = sqrt(norm);\n\n        // Normalize the row\n        j = 0;\n        if (norm != 0.0f) {\n            for (; j + 8 <= n; j += 8) {\n                __m256 vec = _mm256_loadu_ps(&mat[i * n + j]);\n                __m256 normalized = _mm256_div_ps(vec, _mm256_set1_ps(norm));\n                _mm256_storeu_ps(&mat[i * n + j], normalized);\n            }\n\n            for (; j < n; ++j) {\n                mat[i * n + j] /= norm;\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_24_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <cstddef>\n\nvoid matrix_mul_round_int_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n, size_t p) {\n    for (size_t i = 0; i < m; ++i) {\n        for (size_t j = 0; j < p; ++j) {\n            __m256d sum = _mm256_setzero_pd();\n            for (size_t k = 0; k < n; k += 4) {\n                __m256d vec1 = _mm256_loadu_pd(&mat1[i * n + k]);\n                __m256d vec2 = _mm256_loadu_pd(&mat2[k * p + j]);\n                sum = _mm256_fmadd_pd(vec1, vec2, sum);\n            }\n            double result[4];\n            _mm256_storeu_pd(result, sum);\n            dst[i * p + j] = static_cast<double>(static_cast<int64_t>(result[0] + 0.5)) + \n                             static_cast<double>(static_cast<int64_t>(result[1] + 0.5)) + \n                             static_cast<double>(static_cast<int64_t>(result[2] + 0.5)) + \n                             static_cast<double>(static_cast<int64_t>(result[3] + 0.5));\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_24_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid matrix_mul_round_int_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n, size_t p) {\n    for (size_t i = 0; i < m; ++i) {\n        for (size_t j = 0; j < p; ++j) {\n            __m256d sum = _mm256_setzero_pd();\n            for (size_t k = 0; k < n; k += 4) {\n                __m256d vec1 = _mm256_loadu_pd(&mat1[i * n + k]);\n                __m256d vec2 = _mm256_loadu_pd(&mat2[k * p + j]);\n                sum = _mm256_fmadd_pd(vec1, vec2, sum);\n            }\n            double result[4];\n            _mm256_storeu_pd(result, sum);\n            dst[i * p + j] = round(result[0] + result[1] + result[2] + result[3]);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_24_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid matrix_mul_round_int_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n, size_t p) {\n    for (size_t i = 0; i < m; ++i) {\n        for (size_t j = 0; j < p; ++j) {\n            __m256d sum = _mm256_setzero_pd();\n            for (size_t k = 0; k < n; k += 4) {\n                __m256d a = _mm256_loadu_pd(&mat1[i * n + k]);\n                __m256d b = _mm256_loadu_pd(&mat2[k * p + j]);\n                sum = _mm256_fmadd_pd(a, b, sum);\n            }\n            double result[4];\n            _mm256_storeu_pd(result, sum);\n            dst[i * p + j] = round(result[0] + result[1] + result[2] + result[3]);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_24_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid matrix_mul_round_int_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n, size_t p) {\n    for (size_t i = 0; i < m; ++i) {\n        for (size_t j = 0; j < p; ++j) {\n            __m256d sum = _mm256_setzero_pd();\n            for (size_t k = 0; k < n; k += 4) {\n                __m256d a = _mm256_loadu_pd(&mat1[i * n + k]);\n                __m256d b = _mm256_loadu_pd(&mat2[k * p + j]);\n                sum = _mm256_fmadd_pd(a, b, sum);\n            }\n            double result[4];\n            _mm256_storeu_pd(result, sum);\n            dst[i * p + j] = round(result[0] + result[1] + result[2] + result[3]);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_24_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid matrix_mul_round_int_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n, size_t p) {\n    for (size_t i = 0; i < m; ++i) {\n        for (size_t j = 0; j < p; ++j) {\n            __m256d sum = _mm256_setzero_pd();\n            for (size_t k = 0; k < n; k += 4) {\n                __m256d a = _mm256_loadu_pd(&mat1[i * n + k]);\n                __m256d b = _mm256_loadu_pd(&mat2[k * p + j]);\n                sum = _mm256_fmadd_pd(a, b, sum);\n            }\n            double result[4];\n            _mm256_storeu_pd(result, sum);\n            dst[i * p + j] = round(result[0] + result[1] + result[2] + result[3]);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_25_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid matrix_transpose_round_quarter_simd(const float* src, float* dst, size_t rows, size_t cols) {\n    size_t i, j;\n    for (i = 0; i < rows; i += 4) {\n        for (j = 0; j < cols; j += 8) {\n            __m256 row0 = _mm256_loadu_ps(&src[i * cols + j]);\n            __m256 row1 = _mm256_loadu_ps(&src[(i + 1) * cols + j]);\n            __m256 row2 = _mm256_loadu_ps(&src[(i + 2) * cols + j]);\n            __m256 row3 = _mm256_loadu_ps(&src[(i + 3) * cols + j]);\n\n            // Transpose 4x8 block\n            __m256 t0 = _mm256_unpacklo_ps(row0, row1);\n            __m256 t1 = _mm256_unpackhi_ps(row0, row1);\n            __m256 t2 = _mm256_unpacklo_ps(row2, row3);\n            __m256 t3 = _mm256_unpackhi_ps(row2, row3);\n\n            __m256 t4 = _mm256_shuffle_ps(t0, t2, _MM_SHUFFLE(2, 0, 2, 0));\n            __m256 t5 = _mm256_shuffle_ps(t0, t2, _MM_SHUFFLE(3, 1, 3, 1));\n            __m256 t6 = _mm256_shuffle_ps(t1, t3, _MM_SHUFFLE(2, 0, 2, 0));\n            __m256 t7 = _mm256_shuffle_ps(t1, t3, _MM_SHUFFLE(3, 1, 3, 1));\n\n            // Round to nearest quarter\n            __m256 quarter = _mm256_set1_ps(0.25f);\n            t4 = _mm256_round_ps(_mm256_add_ps(t4, _mm256_set1_ps(0.125f)), _MM_FROUND_TO_NEAREST_INT);\n            t5 = _mm256_round_ps(_mm256_add_ps(t5, _mm256_set1_ps(0.125f)), _MM_FROUND_TO_NEAREST_INT);\n            t6 = _mm256_round_ps(_mm256_add_ps(t6, _mm256_set1_ps(0.125f)), _MM_FROUND_TO_NEAREST_INT);\n            t7 = _mm256_round_ps(_mm256_add_ps(t7, _mm256_set1_ps(0.125f)), _MM_FROUND_TO_NEAREST_INT);\n\n            // Store transposed and rounded values\n            _mm256_storeu_ps(&dst[j * rows + i], t4);\n            _mm256_storeu_ps(&dst[j * rows + i + 4], t5);\n            _mm256_storeu_ps(&dst[j * rows + i + 1], t6);\n            _mm256_storeu_ps(&dst[j * rows + i + 5], t7);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_25_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid matrix_transpose_round_quarter_simd(const float* src, float* dst, size_t rows, size_t cols) {\n    for (size_t i = 0; i < rows; i += 8) {\n        for (size_t j = 0; j < cols; j += 8) {\n            __m256 row0 = _mm256_loadu_ps(&src[i * cols + j]);\n            __m256 row1 = _mm256_loadu_ps(&src[(i + 1) * cols + j]);\n            __m256 row2 = _mm256_loadu_ps(&src[(i + 2) * cols + j]);\n            __m256 row3 = _mm256_loadu_ps(&src[(i + 3) * cols + j]);\n            __m256 row4 = _mm256_loadu_ps(&src[(i + 4) * cols + j]);\n            __m256 row5 = _mm256_loadu_ps(&src[(i + 5) * cols + j]);\n            __m256 row6 = _mm256_loadu_ps(&src[(i + 6) * cols + j]);\n            __m256 row7 = _mm256_loadu_ps(&src[(i + 7) * cols + j]);\n\n            // Transpose 8x8 block\n            __m256 t0 = _mm256_unpacklo_ps(row0, row1);\n            __m256 t1 = _mm256_unpackhi_ps(row0, row1);\n            __m256 t2 = _mm256_unpacklo_ps(row2, row3);\n            __m256 t3 = _mm256_unpackhi_ps(row2, row3);\n            __m256 t4 = _mm256_unpacklo_ps(row4, row5);\n            __m256 t5 = _mm256_unpackhi_ps(row4, row5);\n            __m256 t6 = _mm256_unpacklo_ps(row6, row7);\n            __m256 t7 = _mm256_unpackhi_ps(row6, row7);\n\n            __m256 t8 = _mm256_unpacklo_ps(t0, t2);\n            __m256 t9 = _mm256_unpackhi_ps(t0, t2);\n            __m256 t10 = _mm256_unpacklo_ps(t1, t3);\n            __m256 t11 = _mm256_unpackhi_ps(t1, t3);\n            __m256 t12 = _mm256_unpacklo_ps(t4, t6);\n            __m256 t13 = _mm256_unpackhi_ps(t4, t6);\n            __m256 t14 = _mm256_unpacklo_ps(t5, t7);\n            __m256 t15 = _mm256_unpackhi_ps(t5, t7);\n\n            __m256 dst0 = _mm256_unpacklo_ps(t8, t12);\n            __m256 dst1 = _mm256_unpackhi_ps(t8, t12);\n            __m256 dst2 = _mm256_unpacklo_ps(t9, t13);\n            __m256 dst3 = _mm256_unpackhi_ps(t9, t13);\n            __m256 dst4 = _mm256_unpacklo_ps(t10, t14);\n            __m256 dst5 = _mm256_unpackhi_ps(t10, t14);\n            __m256 dst6 = _mm256_unpacklo_ps(t11, t15);\n            __m256 dst7 = _mm256_unpackhi_ps(t11, t15);\n\n            // Round to nearest quarter\n            __m256 quarter = _mm256_set1_ps(0.25f);\n            dst0 = _mm256_round_ps(_mm256_add_ps(dst0, _mm256_set1_ps(0.125f)), _MM_FROUND_TO_NEAREST_INT);\n            dst1 = _mm256_round_ps(_mm256_add_ps(dst1, _mm256_set1_ps(0.125f)), _MM_FROUND_TO_NEAREST_INT);\n            dst2 = _mm256_round_ps(_mm256_add_ps(dst2, _mm256_set1_ps(0.125f)), _MM_FROUND_TO_NEAREST_INT);\n            dst3 = _mm256_round_ps(_mm256_add_ps(dst3, _mm256_set1_ps(0.125f)), _MM_FROUND_TO_NEAREST_INT);\n            dst4 = _mm256_round_ps(_mm256_add_ps(dst4, _mm256_set1_ps(0.125f)), _MM_FROUND_TO_NEAREST_INT);\n            dst5 = _mm256_round_ps(_mm256_add_ps(dst5, _mm256_set1_ps(0.125f)), _MM_FROUND_TO_NEAREST_INT);\n            dst6 = _mm256_round_ps(_mm256_add_ps(dst6, _mm256_set1_ps(0.125f)), _MM_FROUND_TO_NEAREST_INT);\n            dst7 = _mm256_round_ps(_mm256_add_ps(dst7, _mm256_set1_ps(0.125f)), _MM_FROUND_TO_NEAREST_INT);\n\n            // Store transposed and rounded values\n            _mm256_storeu_ps(&dst[j * rows + i], dst0);\n            _mm256_storeu_ps(&dst[j * rows + i + 1], dst1);\n            _mm256_storeu_ps(&dst[j * rows + i + 2], dst2);\n            _mm256_storeu_ps(&dst[j * rows + i + 3], dst3);\n            _mm256_storeu_ps(&dst[j * rows + i + 4], dst4);\n            _mm256_storeu_ps(&dst[j * rows + i + 5], dst5);\n            _mm256_storeu_ps(&dst[j * rows + i + 6], dst6);\n            _mm256_storeu_ps(&dst[j * rows + i + 7], dst7);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_25_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid matrix_transpose_round_quarter_simd(const float* src, float* dst, size_t rows, size_t cols) {\n    for (size_t i = 0; i < rows; i += 8) {\n        for (size_t j = 0; j < cols; j += 8) {\n            __m256 row0 = _mm256_loadu_ps(&src[i * cols + j]);\n            __m256 row1 = _mm256_loadu_ps(&src[(i + 1) * cols + j]);\n            __m256 row2 = _mm256_loadu_ps(&src[(i + 2) * cols + j]);\n            __m256 row3 = _mm256_loadu_ps(&src[(i + 3) * cols + j]);\n            __m256 row4 = _mm256_loadu_ps(&src[(i + 4) * cols + j]);\n            __m256 row5 = _mm256_loadu_ps(&src[(i + 5) * cols + j]);\n            __m256 row6 = _mm256_loadu_ps(&src[(i + 6) * cols + j]);\n            __m256 row7 = _mm256_loadu_ps(&src[(i + 7) * cols + j]);\n\n            // Transpose 8x8 block\n            __m256 t0 = _mm256_unpacklo_ps(row0, row1);\n            __m256 t1 = _mm256_unpackhi_ps(row0, row1);\n            __m256 t2 = _mm256_unpacklo_ps(row2, row3);\n            __m256 t3 = _mm256_unpackhi_ps(row2, row3);\n            __m256 t4 = _mm256_unpacklo_ps(row4, row5);\n            __m256 t5 = _mm256_unpackhi_ps(row4, row5);\n            __m256 t6 = _mm256_unpacklo_ps(row6, row7);\n            __m256 t7 = _mm256_unpackhi_ps(row6, row7);\n\n            __m256 t8 = _mm256_unpacklo_ps(t0, t2);\n            __m256 t9 = _mm256_unpackhi_ps(t0, t2);\n            __m256 t10 = _mm256_unpacklo_ps(t1, t3);\n            __m256 t11 = _mm256_unpackhi_ps(t1, t3);\n            __m256 t12 = _mm256_unpacklo_ps(t4, t6);\n            __m256 t13 = _mm256_unpackhi_ps(t4, t6);\n            __m256 t14 = _mm256_unpacklo_ps(t5, t7);\n            __m256 t15 = _mm256_unpackhi_ps(t5, t7);\n\n            __m256 dst0 = _mm256_unpacklo_ps(t8, t12);\n            __m256 dst1 = _mm256_unpackhi_ps(t8, t12);\n            __m256 dst2 = _mm256_unpacklo_ps(t9, t13);\n            __m256 dst3 = _mm256_unpackhi_ps(t9, t13);\n            __m256 dst4 = _mm256_unpacklo_ps(t10, t14);\n            __m256 dst5 = _mm256_unpackhi_ps(t10, t14);\n            __m256 dst6 = _mm256_unpacklo_ps(t11, t15);\n            __m256 dst7 = _mm256_unpackhi_ps(t11, t15);\n\n            // Round to nearest quarter\n            dst0 = _mm256_round_ps(dst0, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n            dst1 = _mm256_round_ps(dst1, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n            dst2 = _mm256_round_ps(dst2, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n            dst3 = _mm256_round_ps(dst3, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n            dst4 = _mm256_round_ps(dst4, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n            dst5 = _mm256_round_ps(dst5, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n            dst6 = _mm256_round_ps(dst6, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n            dst7 = _mm256_round_ps(dst7, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n\n            // Store transposed and rounded values\n            _mm256_storeu_ps(&dst[j * rows + i], dst0);\n            _mm256_storeu_ps(&dst[j * rows + i + 1], dst1);\n            _mm256_storeu_ps(&dst[j * rows + i + 2], dst2);\n            _mm256_storeu_ps(&dst[j * rows + i + 3], dst3);\n            _mm256_storeu_ps(&dst[j * rows + i + 4], dst4);\n            _mm256_storeu_ps(&dst[j * rows + i + 5], dst5);\n            _mm256_storeu_ps(&dst[j * rows + i + 6], dst6);\n            _mm256_storeu_ps(&dst[j * rows + i + 7], dst7);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_25_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid matrix_transpose_round_quarter_simd(const float* src, float* dst, size_t rows, size_t cols) {\n    for (size_t i = 0; i < rows; i += 8) {\n        for (size_t j = 0; j < cols; j += 8) {\n            __m256 row0 = _mm256_loadu_ps(&src[i * cols + j]);\n            __m256 row1 = _mm256_loadu_ps(&src[(i + 1) * cols + j]);\n            __m256 row2 = _mm256_loadu_ps(&src[(i + 2) * cols + j]);\n            __m256 row3 = _mm256_loadu_ps(&src[(i + 3) * cols + j]);\n            __m256 row4 = _mm256_loadu_ps(&src[(i + 4) * cols + j]);\n            __m256 row5 = _mm256_loadu_ps(&src[(i + 5) * cols + j]);\n            __m256 row6 = _mm256_loadu_ps(&src[(i + 6) * cols + j]);\n            __m256 row7 = _mm256_loadu_ps(&src[(i + 7) * cols + j]);\n\n            __m256 temp[8] = { row0, row1, row2, row3, row4, row5, row6, row7 };\n\n            for (int k = 0; k < 8; ++k) {\n                temp[k] = _mm256_round_ps(temp[k], _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n                temp[k] = _mm256_mul_ps(temp[k], _mm256_set1_ps(4.0f));\n                temp[k] = _mm256_round_ps(temp[k], _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n                temp[k] = _mm256_div_ps(temp[k], _mm256_set1_ps(4.0f));\n            }\n\n            _mm256_storeu_ps(&dst[j * rows + i], temp[0]);\n            _mm256_storeu_ps(&dst[j * rows + i + 1], temp[1]);\n            _mm256_storeu_ps(&dst[j * rows + i + 2], temp[2]);\n            _mm256_storeu_ps(&dst[j * rows + i + 3], temp[3]);\n            _mm256_storeu_ps(&dst[j * rows + i + 4], temp[4]);\n            _mm256_storeu_ps(&dst[j * rows + i + 5], temp[5]);\n            _mm256_storeu_ps(&dst[j * rows + i + 6], temp[6]);\n            _mm256_storeu_ps(&dst[j * rows + i + 7], temp[7]);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_25_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid matrix_transpose_round_quarter_simd(const float* src, float* dst, size_t rows, size_t cols) {\n    for (size_t i = 0; i < rows; i += 8) {\n        for (size_t j = 0; j < cols; j += 8) {\n            __m256 row0 = _mm256_loadu_ps(&src[i * cols + j]);\n            __m256 row1 = _mm256_loadu_ps(&src[(i + 1) * cols + j]);\n            __m256 row2 = _mm256_loadu_ps(&src[(i + 2) * cols + j]);\n            __m256 row3 = _mm256_loadu_ps(&src[(i + 3) * cols + j]);\n            __m256 row4 = _mm256_loadu_ps(&src[(i + 4) * cols + j]);\n            __m256 row5 = _mm256_loadu_ps(&src[(i + 5) * cols + j]);\n            __m256 row6 = _mm256_loadu_ps(&src[(i + 6) * cols + j]);\n            __m256 row7 = _mm256_loadu_ps(&src[(i + 7) * cols + j]);\n\n            __m256 temp[8] = { row0, row1, row2, row3, row4, row5, row6, row7 };\n\n            for (int k = 0; k < 8; ++k) {\n                temp[k] = _mm256_round_ps(temp[k], _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n                temp[k] = _mm256_mul_ps(temp[k], _mm256_set1_ps(4.0f));\n                temp[k] = _mm256_round_ps(temp[k], _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n                temp[k] = _mm256_div_ps(temp[k], _mm256_set1_ps(4.0f));\n            }\n\n            _mm256_storeu_ps(&dst[j * rows + i], temp[0]);\n            _mm256_storeu_ps(&dst[j * rows + i + 1], temp[1]);\n            _mm256_storeu_ps(&dst[j * rows + i + 2], temp[2]);\n            _mm256_storeu_ps(&dst[j * rows + i + 3], temp[3]);\n            _mm256_storeu_ps(&dst[j * rows + i + 4], temp[4]);\n            _mm256_storeu_ps(&dst[j * rows + i + 5], temp[5]);\n            _mm256_storeu_ps(&dst[j * rows + i + 6], temp[6]);\n            _mm256_storeu_ps(&dst[j * rows + i + 7], temp[7]);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_26_AVX", "completion": "```cpp\nvoid tensor3d_sub_round_zero_simd(const float* tensor1, const float* tensor2, float* dst, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t i = 0;\n\n    // Process 8 floats at a time using AVX\n    for (; i + 7 < total_elements; i += 8) {\n        __m256 vec1 = _mm256_loadu_ps(&tensor1[i]);\n        __m256 vec2 = _mm256_loadu_ps(&tensor2[i]);\n        __m256 result = _mm256_sub_ps(vec1, vec2);\n        result = _mm256_round_ps(result, _MM_FROUND_TO_ZERO);\n        _mm256_storeu_ps(&dst[i], result);\n    }\n\n    // Handle remaining elements\n    for (; i < total_elements; i++) {\n        dst[i] = (tensor1[i] - tensor2[i] > 0) ? (float)((int)(tensor1[i] - tensor2[i])) : (float)((int)(tensor1[i] - tensor2[i]));\n    }\n}\n```"}
{"task_id": "SimdBench_26_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid tensor3d_sub_round_zero_simd(const float* tensor1, const float* tensor2, float* dst, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t i = 0;\n\n    for (; i + 8 <= total_elements; i += 8) {\n        __m256 vec1 = _mm256_loadu_ps(&tensor1[i]);\n        __m256 vec2 = _mm256_loadu_ps(&tensor2[i]);\n        __m256 result = _mm256_sub_ps(vec1, vec2);\n        result = _mm256_round_ps(result, _MM_FROUND_TO_ZERO);\n        _mm256_storeu_ps(&dst[i], result);\n    }\n\n    for (; i < total_elements; i++) {\n        dst[i] = (float)((int)(tensor1[i] - tensor2[i]));\n    }\n}\n```"}
{"task_id": "SimdBench_26_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid tensor3d_sub_round_zero_simd(const float* tensor1, const float* tensor2, float* dst, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t i = 0;\n\n    for (; i <= total_elements - 8; i += 8) {\n        __m256 vec1 = _mm256_loadu_ps(&tensor1[i]);\n        __m256 vec2 = _mm256_loadu_ps(&tensor2[i]);\n        __m256 result = _mm256_sub_ps(vec1, vec2);\n        result = _mm256_round_ps(result, _MM_FROUND_TO_ZERO);\n        _mm256_storeu_ps(&dst[i], result);\n    }\n\n    for (; i < total_elements; ++i) {\n        dst[i] = (tensor1[i] - tensor2[i]);\n        dst[i] = (dst[i] > 0) ? (float)((int)dst[i]) : (float)((int)dst[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_26_AVX", "completion": "```cpp\nvoid tensor3d_sub_round_zero_simd(const float* tensor1, const float* tensor2, float* dst, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t i;\n\n    __m256 vec1, vec2, result;\n\n    for (i = 0; i <= total_elements - 8; i += 8) {\n        vec1 = _mm256_loadu_ps(&tensor1[i]);\n        vec2 = _mm256_loadu_ps(&tensor2[i]);\n        result = _mm256_sub_ps(vec1, vec2);\n        result = _mm256_round_ps(result, _MM_FROUND_TO_ZERO | _MM_FROUND_NO_EXC);\n        _mm256_storeu_ps(&dst[i], result);\n    }\n\n    for (; i < total_elements; i++) {\n        dst[i] = (tensor1[i] - tensor2[i]);\n        if (dst[i] > 0) {\n            dst[i] = (float)((int)dst[i]);\n        } else {\n            dst[i] = (float)((int)(dst[i] - 1));\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_26_AVX", "completion": "```cpp\nvoid tensor3d_sub_round_zero_simd(const float* tensor1, const float* tensor2, float* dst, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t i = 0;\n\n    for (; i + 8 <= total_elements; i += 8) {\n        __m256 vec1 = _mm256_loadu_ps(&tensor1[i]);\n        __m256 vec2 = _mm256_loadu_ps(&tensor2[i]);\n        __m256 result = _mm256_sub_ps(vec1, vec2);\n        result = _mm256_round_ps(result, _MM_FROUND_TO_ZERO | _MM_FROUND_NO_EXC);\n        _mm256_storeu_ps(&dst[i], result);\n    }\n\n    for (; i < total_elements; i++) {\n        dst[i] = (float)((int)(tensor1[i] - tensor2[i]));\n    }\n}\n```"}
{"task_id": "SimdBench_27_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid matrix_hadamard_product_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n) {\n    size_t total_elements = m * n;\n    size_t i;\n\n    for (i = 0; i <= total_elements - 4; i += 4) {\n        __m256d a = _mm256_loadu_pd(&mat1[i]);\n        __m256d b = _mm256_loadu_pd(&mat2[i]);\n        __m256d result = _mm256_mul_pd(a, b);\n        _mm256_storeu_pd(&dst[i], result);\n    }\n\n    for (; i < total_elements; ++i) {\n        dst[i] = mat1[i] * mat2[i];\n    }\n}\n```"}
{"task_id": "SimdBench_27_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid matrix_hadamard_product_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n) {\n    size_t total_elements = m * n;\n    size_t i;\n\n    for (i = 0; i < total_elements; i += 4) {\n        __m256d a = _mm256_loadu_pd(&mat1[i]);\n        __m256d b = _mm256_loadu_pd(&mat2[i]);\n        __m256d result = _mm256_mul_pd(a, b);\n        _mm256_storeu_pd(&dst[i], result);\n    }\n\n    for (; i < total_elements; i++) {\n        dst[i] = mat1[i] * mat2[i];\n    }\n}\n```"}
{"task_id": "SimdBench_27_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid matrix_hadamard_product_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n) {\n    size_t total_elements = m * n;\n    size_t i;\n\n    for (i = 0; i <= total_elements - 4; i += 4) {\n        __m256d a = _mm256_loadu_pd(&mat1[i]);\n        __m256d b = _mm256_loadu_pd(&mat2[i]);\n        __m256d result = _mm256_mul_pd(a, b);\n        _mm256_storeu_pd(&dst[i], result);\n    }\n\n    for (; i < total_elements; i++) {\n        dst[i] = mat1[i] * mat2[i];\n    }\n}\n```"}
{"task_id": "SimdBench_27_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid matrix_hadamard_product_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n) {\n    size_t total_elements = m * n;\n    size_t i;\n\n    for (i = 0; i <= total_elements - 4; i += 4) {\n        __m256d a = _mm256_loadu_pd(&mat1[i]);\n        __m256d b = _mm256_loadu_pd(&mat2[i]);\n        __m256d result = _mm256_mul_pd(a, b);\n        _mm256_storeu_pd(&dst[i], result);\n    }\n\n    for (; i < total_elements; i++) {\n        dst[i] = mat1[i] * mat2[i];\n    }\n}\n```"}
{"task_id": "SimdBench_27_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid matrix_hadamard_product_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n) {\n    size_t total_elements = m * n;\n    size_t i;\n\n    for (i = 0; i <= total_elements - 4; i += 4) {\n        __m256d a = _mm256_loadu_pd(&mat1[i]);\n        __m256d b = _mm256_loadu_pd(&mat2[i]);\n        __m256d result = _mm256_mul_pd(a, b);\n        _mm256_storeu_pd(&dst[i], result);\n    }\n\n    for (; i < total_elements; i++) {\n        dst[i] = mat1[i] * mat2[i];\n    }\n}\n```"}
{"task_id": "SimdBench_28_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid matrix_vector_mul_simd(const float* mat, const float* vec, float* dst, size_t m, size_t n) {\n    for (size_t i = 0; i < m; i++) {\n        __m256 sum = _mm256_setzero_ps();\n        size_t j = 0;\n\n        for (; j + 8 <= n; j += 8) {\n            __m256 mat_vec = _mm256_loadu_ps(&mat[i * n + j]);\n            __m256 vec_vec = _mm256_loadu_ps(&vec[j]);\n            sum = _mm256_fmadd_ps(mat_vec, vec_vec, sum);\n        }\n\n        float temp[8];\n        _mm256_storeu_ps(temp, sum);\n        float result = temp[0] + temp[1] + temp[2] + temp[3] + temp[4] + temp[5] + temp[6] + temp[7];\n\n        for (; j < n; j++) {\n            result += mat[i * n + j] * vec[j];\n        }\n\n        dst[i] = result;\n    }\n}\n```"}
{"task_id": "SimdBench_28_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid matrix_vector_mul_simd(const float* mat, const float* vec, float* dst, size_t m, size_t n) {\n    for (size_t i = 0; i < m; ++i) {\n        __m256 sum = _mm256_setzero_ps();\n        for (size_t j = 0; j < n; j += 8) {\n            __m256 mat_vec = _mm256_loadu_ps(&mat[i * n + j]);\n            __m256 vec_vec = _mm256_loadu_ps(&vec[j]);\n            sum = _mm256_fmadd_ps(mat_vec, vec_vec, sum);\n        }\n        sum = _mm256_hadd_ps(sum, sum);\n        sum = _mm256_hadd_ps(sum, sum);\n        _mm256_storeu_ps(&dst[i], sum);\n    }\n}\n```"}
{"task_id": "SimdBench_28_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid matrix_vector_mul_simd(const float* mat, const float* vec, float* dst, size_t m, size_t n) {\n    for (size_t i = 0; i < m; ++i) {\n        __m256 sum = _mm256_setzero_ps();\n        for (size_t j = 0; j < n; j += 8) {\n            __m256 mat_vec = _mm256_loadu_ps(&mat[i * n + j]);\n            __m256 vec_vec = _mm256_loadu_ps(&vec[j]);\n            sum = _mm256_fmadd_ps(mat_vec, vec_vec, sum);\n        }\n        sum = _mm256_hadd_ps(sum, sum);\n        sum = _mm256_hadd_ps(sum, sum);\n        _mm256_storeu_ps(&dst[i], sum);\n    }\n}\n```"}
{"task_id": "SimdBench_28_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid matrix_vector_mul_simd(const float* mat, const float* vec, float* dst, size_t m, size_t n) {\n    for (size_t i = 0; i < m; i++) {\n        __m256 sum = _mm256_setzero_ps();\n        for (size_t j = 0; j < n; j += 8) {\n            __m256 mat_vec = _mm256_loadu_ps(&mat[i * n + j]);\n            __m256 vec_vec = _mm256_loadu_ps(&vec[j]);\n            sum = _mm256_fmadd_ps(mat_vec, vec_vec, sum);\n        }\n        sum = _mm256_hadd_ps(sum, sum);\n        sum = _mm256_hadd_ps(sum, sum);\n        _mm_store_ss(&dst[i], _mm256_castps256_ps128(sum));\n    }\n}\n```"}
{"task_id": "SimdBench_28_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid matrix_vector_mul_simd(const float* mat, const float* vec, float* dst, size_t m, size_t n) {\n    for (size_t i = 0; i < m; ++i) {\n        __m256 sum = _mm256_setzero_ps();\n        for (size_t j = 0; j < n; j += 8) {\n            __m256 mat_vec = _mm256_loadu_ps(&mat[i * n + j]);\n            __m256 vec_vec = _mm256_loadu_ps(&vec[j]);\n            sum = _mm256_fmadd_ps(mat_vec, vec_vec, sum);\n        }\n        sum = _mm256_hadd_ps(sum, sum);\n        sum = _mm256_hadd_ps(sum, sum);\n        _mm_store_ss(&dst[i], _mm256_castps256_ps128(sum));\n    }\n}\n```"}
{"task_id": "SimdBench_29_AVX", "completion": "```cpp\ndouble matrix_average_simd(const double* mat, size_t m, size_t n) {\n    __m256d sum_vec = _mm256_setzero_pd();\n    size_t total_elements = m * n;\n    size_t i;\n\n    for (i = 0; i <= total_elements - 4; i += 4) {\n        __m256d vec = _mm256_loadu_pd(&mat[i]);\n        sum_vec = _mm256_add_pd(sum_vec, vec);\n    }\n\n    double sum[4];\n    _mm256_storeu_pd(sum, sum_vec);\n\n    double total_sum = sum[0] + sum[1] + sum[2] + sum[3];\n\n    // Handle remaining elements\n    for (; i < total_elements; ++i) {\n        total_sum += mat[i];\n    }\n\n    return total_sum / total_elements;\n}\n```"}
{"task_id": "SimdBench_29_AVX", "completion": "```cpp\ndouble matrix_average_simd(const double* mat, size_t m, size_t n) {\n    __m256d sum_vec = _mm256_setzero_pd();\n    size_t total_elements = m * n;\n    size_t i;\n\n    for (i = 0; i <= total_elements - 4; i += 4) {\n        __m256d vec = _mm256_loadu_pd(&mat[i]);\n        sum_vec = _mm256_add_pd(sum_vec, vec);\n    }\n\n    double sum_array[4];\n    _mm256_storeu_pd(sum_array, sum_vec);\n\n    double sum = sum_array[0] + sum_array[1] + sum_array[2] + sum_array[3];\n\n    // Handle remaining elements\n    for (; i < total_elements; ++i) {\n        sum += mat[i];\n    }\n\n    return sum / total_elements;\n}\n```"}
{"task_id": "SimdBench_29_AVX", "completion": "```cpp\ndouble matrix_average_simd(const double* mat, size_t m, size_t n) {\n    __m256d sum_vec = _mm256_setzero_pd();\n    size_t total_elements = m * n;\n    size_t i;\n\n    for (i = 0; i <= total_elements - 4; i += 4) {\n        __m256d vec = _mm256_loadu_pd(&mat[i]);\n        sum_vec = _mm256_add_pd(sum_vec, vec);\n    }\n\n    double sum_array[4];\n    _mm256_storeu_pd(sum_array, sum_vec);\n\n    double sum = sum_array[0] + sum_array[1] + sum_array[2] + sum_array[3];\n\n    // Handle remaining elements\n    for (; i < total_elements; ++i) {\n        sum += mat[i];\n    }\n\n    return sum / total_elements;\n}\n```"}
{"task_id": "SimdBench_29_AVX", "completion": "```cpp\ndouble matrix_average_simd(const double* mat, size_t m, size_t n) {\n    size_t total_elements = m * n;\n    size_t num_vectors = total_elements / 4;\n    size_t remaining_elements = total_elements % 4;\n\n    __m256d sum_vec = _mm256_setzero_pd();\n\n    for (size_t i = 0; i < num_vectors; ++i) {\n        __m256d vec = _mm256_loadu_pd(&mat[i * 4]);\n        sum_vec = _mm256_add_pd(sum_vec, vec);\n    }\n\n    double sum_array[4];\n    _mm256_storeu_pd(sum_array, sum_vec);\n\n    double total_sum = sum_array[0] + sum_array[1] + sum_array[2] + sum_array[3];\n\n    for (size_t j = 0; j < remaining_elements; ++j) {\n        total_sum += mat[num_vectors * 4 + j];\n    }\n\n    return total_sum / total_elements;\n}\n```"}
{"task_id": "SimdBench_29_AVX", "completion": "```cpp\ndouble matrix_average_simd(const double* mat, size_t m, size_t n) {\n    size_t total_elements = m * n;\n    size_t vectorized_elements = total_elements / 4;\n    size_t remaining_elements = total_elements % 4;\n\n    __m256d sum_vec = _mm256_setzero_pd();\n    \n    for (size_t i = 0; i < vectorized_elements; ++i) {\n        __m256d vec = _mm256_loadu_pd(mat + i * 4);\n        sum_vec = _mm256_add_pd(sum_vec, vec);\n    }\n\n    double sum_array[4];\n    _mm256_storeu_pd(sum_array, sum_vec);\n    double total_sum = sum_array[0] + sum_array[1] + sum_array[2] + sum_array[3];\n\n    for (size_t j = 0; j < remaining_elements; ++j) {\n        total_sum += mat[vectorized_elements * 4 + j];\n    }\n\n    return total_sum / total_elements;\n}\n```"}
{"task_id": "SimdBench_30_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nbool matrix_rows_sorted_verify_simd(const int* matrix, const bool* directions, size_t rows, size_t cols) {\n    for (size_t r = 0; r < rows; ++r) {\n        const int* row = matrix + r * cols;\n        bool ascending = directions[r];\n        size_t c = 0;\n        __m256i prev = _mm256_loadu_si256((__m256i*)(row + c));\n\n        for (c = 0; c < cols - 8; c += 8) {\n            __m256i curr = _mm256_loadu_si256((__m256i*)(row + c + 8));\n            __m256i cmp = ascending ? _mm256_cmpgt_epi32(curr, prev) : _mm256_cmpgt_epi32(prev, curr);\n            int mask = _mm256_movemask_epi8(cmp);\n            if (mask != 0) {\n                return false;\n            }\n            prev = curr;\n        }\n\n        for (; c < cols - 1; ++c) {\n            if ((ascending && row[c] > row[c + 1]) || (!ascending && row[c] < row[c + 1])) {\n                return false;\n            }\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_30_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nbool matrix_rows_sorted_verify_simd(const int* matrix, const bool* directions, size_t rows, size_t cols) {\n    for (size_t r = 0; r < rows; ++r) {\n        const int* row = matrix + r * cols;\n        bool is_sorted = true;\n\n        for (size_t c = 0; c < cols - 8; c += 8) {\n            __m256i vec1 = _mm256_loadu_si256((__m256i*)&row[c]);\n            __m256i vec2 = _mm256_loadu_si256((__m256i*)&row[c + 1]);\n\n            __m256i cmp = _mm256_cmpgt_epi32(vec2, vec1);\n            bool ascending = directions[r];\n\n            if (ascending) {\n                if (_mm256_movemask_epi8(cmp) != 0xFFFF) {\n                    is_sorted = false;\n                    break;\n                }\n            } else {\n                if (_mm256_movemask_epi8(_mm256_cmpeq_epi32(vec2, vec1)) != 0xFFFF && _mm256_movemask_epi8(cmp) != 0) {\n                    is_sorted = false;\n                    break;\n                }\n            }\n        }\n\n        for (size_t c = cols - 8; c < cols - 1; ++c) {\n            if ((directions[r] && row[c] > row[c + 1]) || (!directions[r] && row[c] < row[c + 1])) {\n                is_sorted = false;\n                break;\n            }\n        }\n\n        if (!is_sorted) {\n            return false;\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_30_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nbool matrix_rows_sorted_verify_simd(const int* matrix, const bool* directions, size_t rows, size_t cols) {\n    for (size_t r = 0; r < rows; ++r) {\n        const int* row = matrix + r * cols;\n        bool ascending = directions[r];\n        bool sorted = true;\n\n        for (size_t c = 0; c < cols - 8; c += 8) {\n            __m256i vec1 = _mm256_loadu_si256((__m256i*)&row[c]);\n            __m256i vec2 = _mm256_loadu_si256((__m256i*)&row[c + 1]);\n\n            __m256i cmp = ascending ? _mm256_cmpgt_epi32(vec2, vec1) : _mm256_cmpgt_epi32(vec1, vec2);\n            int mask = _mm256_movemask_epi8(cmp);\n\n            if (mask != 0xFFFF) {\n                sorted = false;\n                break;\n            }\n        }\n\n        for (size_t c = cols - 8; c < cols - 1; ++c) {\n            if ((ascending && row[c] > row[c + 1]) || (!ascending && row[c] < row[c + 1])) {\n                sorted = false;\n                break;\n            }\n        }\n\n        if (!sorted) {\n            return false;\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_30_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nbool matrix_rows_sorted_verify_simd(const int* matrix, const bool* directions, size_t rows, size_t cols) {\n    for (size_t r = 0; r < rows; ++r) {\n        const int* row = matrix + r * cols;\n        bool ascending = directions[r];\n\n        size_t c = 0;\n        for (; c + 8 <= cols; c += 8) {\n            __m256i v1 = _mm256_loadu_si256((__m256i*)&row[c]);\n            __m256i v2 = _mm256_loadu_si256((__m256i*)&row[c + 1]);\n\n            __m256i cmp = ascending ? _mm256_cmpgt_epi32(v2, v1) : _mm256_cmpgt_epi32(v1, v2);\n            int mask = _mm256_movemask_epi8(cmp);\n\n            if (mask != 0) {\n                return false;\n            }\n        }\n\n        for (; c + 1 < cols; ++c) {\n            if ((ascending && row[c] > row[c + 1]) || (!ascending && row[c] < row[c + 1])) {\n                return false;\n            }\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_30_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nbool matrix_rows_sorted_verify_simd(const int* matrix, const bool* directions, size_t rows, size_t cols) {\n    for (size_t r = 0; r < rows; ++r) {\n        const int* row = matrix + r * cols;\n        bool ascending = directions[r];\n\n        size_t c = 0;\n        __m256i prev = _mm256_loadu_si256((__m256i*)(row + c));\n        c += 8;\n\n        bool sorted = true;\n        for (; c < cols; c += 8) {\n            __m256i curr = _mm256_loadu_si256((__m256i*)(row + c));\n            __m256i cmp = ascending ? _mm256_cmpgt_epi32(curr, prev) : _mm256_cmpgt_epi32(prev, curr);\n            int mask = _mm256_movemask_epi8(cmp);\n\n            if (mask != 0) {\n                sorted = false;\n                break;\n            }\n            prev = curr;\n        }\n\n        if (!sorted) {\n            return false;\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_31_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid nearest_multiple_simd(const int16_t* src, int16_t* dst, uint8_t base, size_t length) {\n    __m128i base_vec = _mm_set1_epi16(base);\n    __m128i base_minus_one = _mm_set1_epi16(base - 1);\n    \n    size_t i;\n    for (i = 0; i <= length - 8; i += 8) {\n        __m128i src_vec = _mm_loadu_si128((__m128i*)&src[i]);\n        __m128i mod_vec = _mm_and_si128(src_vec, base_minus_one);\n        __m128i nearest_vec = _mm_sub_epi16(src_vec, mod_vec);\n        _mm_storeu_si128((__m128i*)&dst[i], nearest_vec);\n    }\n    \n    for (; i < length; ++i) {\n        dst[i] = src[i] - (src[i] % base);\n    }\n}\n```"}
{"task_id": "SimdBench_31_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid nearest_multiple_simd(const int16_t* src, int16_t* dst, uint8_t base, size_t length) {\n    __m128i base_vec = _mm_set1_epi16(base);\n    __m128i base_minus_one = _mm_set1_epi16(base - 1);\n    \n    size_t i = 0;\n    for (; i + 8 <= length; i += 8) {\n        __m128i src_vec = _mm_loadu_si128((__m128i*)&src[i]);\n        __m128i div_vec = _mm_div_epi16(src_vec, base_vec);\n        __m128i mul_vec = _mm_mullo_epi16(div_vec, base_vec);\n        __m128i nearest_vec = _mm_min_epi16(mul_vec, src_vec);\n        _mm_storeu_si128((__m128i*)&dst[i], nearest_vec);\n    }\n    \n    for (; i < length; i++) {\n        dst[i] = (src[i] / base) * base;\n        if (dst[i] > src[i]) {\n            dst[i] -= base;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_31_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid nearest_multiple_simd(const int16_t* src, int16_t* dst, uint8_t base, size_t length) {\n    __m128i base_vec = _mm_set1_epi16(base);\n    __m128i base_minus_one = _mm_set1_epi16(base - 1);\n    \n    size_t i;\n    for (i = 0; i <= length - 8; i += 8) {\n        __m128i src_vec = _mm_loadu_si128((__m128i*)&src[i]);\n        __m128i remainder = _mm_and_si128(src_vec, base_minus_one);\n        __m128i nearest_multiple = _mm_sub_epi16(src_vec, remainder);\n        _mm_storeu_si128((__m128i*)&dst[i], nearest_multiple);\n    }\n\n    for (; i < length; i++) {\n        dst[i] = (src[i] / base) * base;\n    }\n}\n```"}
{"task_id": "SimdBench_31_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid nearest_multiple_simd(const int16_t* src, int16_t* dst, uint8_t base, size_t length) {\n    __m128i base_vec = _mm_set1_epi16(base);\n    __m128i base_minus_one = _mm_sub_epi16(base_vec, _mm_set1_epi16(1));\n\n    size_t i = 0;\n    for (; i <= length - 8; i += 8) {\n        __m128i src_vec = _mm_loadu_si128((__m128i*)&src[i]);\n        __m128i remainder = _mm_and_si128(src_vec, base_minus_one);\n        __m128i nearest_multiple = _mm_sub_epi16(src_vec, remainder);\n        _mm_storeu_si128((__m128i*)&dst[i], nearest_multiple);\n    }\n\n    for (; i < length; i++) {\n        dst[i] = (src[i] / base) * base;\n    }\n}\n```"}
{"task_id": "SimdBench_31_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid nearest_multiple_simd(const int16_t* src, int16_t* dst, uint8_t base, size_t length) {\n    __m256i base_vec = _mm256_set1_epi16(base);\n    __m256i base_minus_one = _mm256_set1_epi16(base - 1);\n    \n    size_t i;\n    for (i = 0; i <= length - 16; i += 16) {\n        __m256i src_vec = _mm256_loadu_si256((__m256i*)&src[i]);\n        __m256i mod = _mm256_and_si256(src_vec, base_minus_one);\n        __m256i nearest = _mm256_sub_epi16(src_vec, mod);\n        _mm256_storeu_si256((__m256i*)&dst[i], nearest);\n    }\n    \n    for (; i < length; ++i) {\n        dst[i] = (src[i] / base) * base;\n    }\n}\n```"}
{"task_id": "SimdBench_32_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nbool matrix_has_row_simd(const double* matrix, const double* vector, size_t rows, size_t cols) {\n    __m256d vec = _mm256_loadu_pd(vector);\n    \n    for (size_t i = 0; i < rows; ++i) {\n        __m256d row = _mm256_loadu_pd(&matrix[i * cols]);\n        __m256d cmp = _mm256_cmp_pd(row, vec, _CMP_EQ_OQ);\n        int mask = _mm256_movemask_pd(cmp);\n        \n        if (mask == 0x0F) {\n            return true;\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_32_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nbool matrix_has_row_simd(const double* matrix, const double* vector, size_t rows, size_t cols) {\n    __m256d vec = _mm256_loadu_pd(vector);\n    for (size_t i = 0; i < rows; ++i) {\n        __m256d row = _mm256_loadu_pd(&matrix[i * cols]);\n        __m256d cmp = _mm256_cmp_pd(row, vec, _CMP_EQ_OQ);\n        if (_mm256_movemask_pd(cmp) == 0xF) {\n            return true;\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_32_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nbool matrix_has_row_simd(const double* matrix, const double* vector, size_t rows, size_t cols) {\n    __m256d vec = _mm256_loadu_pd(vector);\n    for (size_t i = 0; i < rows; ++i) {\n        __m256d row = _mm256_loadu_pd(&matrix[i * cols]);\n        __m256d cmp = _mm256_cmp_pd(row, vec, _CMP_EQ_OQ);\n        if (_mm256_movemask_pd(cmp) == 0x0F) {\n            return true;\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_32_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nbool matrix_has_row_simd(const double* matrix, const double* vector, size_t rows, size_t cols) {\n    __m256d vec = _mm256_loadu_pd(vector);\n    for (size_t i = 0; i < rows; ++i) {\n        __m256d row = _mm256_loadu_pd(&matrix[i * cols]);\n        __m256d cmp = _mm256_cmp_pd(row, vec, _CMP_EQ_OQ);\n        if (_mm256_movemask_pd(cmp) == 0x0F) {\n            return true;\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_32_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nbool matrix_has_row_simd(const double* matrix, const double* vector, size_t rows, size_t cols) {\n    __m256d vec = _mm256_loadu_pd(vector);\n    for (size_t i = 0; i < rows; ++i) {\n        __m256d row = _mm256_loadu_pd(&matrix[i * cols]);\n        __m256d cmp = _mm256_cmp_pd(row, vec, _CMP_EQ_OQ);\n        if (_mm256_movemask_pd(cmp) == 0x0F) {\n            return true;\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_33_AVX", "completion": "```cpp\nsize_t tensor_4d_equal_count_simd(const uint8_t* A, const uint8_t* B, const size_t dims[4]) {\n    size_t total_elements = dims[0] * dims[1] * dims[2] * dims[3];\n    size_t count = 0;\n    size_t i = 0;\n\n    __m256i count_vec = _mm256_setzero_si256();\n\n    for (; i <= total_elements - 32; i += 32) {\n        __m256i a_vec = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i b_vec = _mm256_loadu_si256((__m256i*)&B[i]);\n        __m256i equal_mask = _mm256_cmpeq_epi8(a_vec, b_vec);\n        count_vec = _mm256_add_epi64(count_vec, _mm256_sad_epu8(equal_mask, _mm256_setzero_si256()));\n    }\n\n    // Horizontal sum of count_vec\n    uint64_t counts[4];\n    _mm256_storeu_si256((__m256i*)counts, count_vec);\n    count += counts[0] + counts[1] + counts[2] + counts[3];\n\n    // Handle remaining elements\n    for (; i < total_elements; ++i) {\n        if (A[i] == B[i]) {\n            count++;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_33_AVX", "completion": "```cpp\nsize_t tensor_4d_equal_count_simd(const uint8_t* A, const uint8_t* B, const size_t dims[4]) {\n    size_t total_elements = dims[0] * dims[1] * dims[2] * dims[3];\n    size_t count = 0;\n    size_t i;\n\n    __m256i count_vec = _mm256_setzero_si256();\n\n    for (i = 0; i <= total_elements - 32; i += 32) {\n        __m256i a_vec1 = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i b_vec1 = _mm256_loadu_si256((__m256i*)&B[i]);\n        __m256i a_vec2 = _mm256_loadu_si256((__m256i*)&A[i + 16]);\n        __m256i b_vec2 = _mm256_loadu_si256((__m256i*)&B[i + 16]);\n\n        __m256i cmp1 = _mm256_cmpeq_epi8(a_vec1, b_vec1);\n        __m256i cmp2 = _mm256_cmpeq_epi8(a_vec2, b_vec2);\n\n        count_vec = _mm256_add_epi8(count_vec, cmp1);\n        count_vec = _mm256_add_epi8(count_vec, cmp2);\n    }\n\n    // Horizontal sum of the count vector\n    uint8_t count_array[32];\n    _mm256_storeu_si256((__m256i*)count_array, count_vec);\n    for (int j = 0; j < 32; j++) {\n        count += count_array[j];\n    }\n\n    // Handle remaining elements\n    for (; i < total_elements; i++) {\n        if (A[i] == B[i]) {\n            count++;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_33_AVX", "completion": "```cpp\nsize_t tensor_4d_equal_count_simd(const uint8_t* A, const uint8_t* B, const size_t dims[4]) {\n    size_t total_elements = dims[0] * dims[1] * dims[2] * dims[3];\n    size_t count = 0;\n    size_t i;\n\n    __m256i count_vec = _mm256_setzero_si256();\n\n    for (i = 0; i <= total_elements - 32; i += 32) {\n        __m256i a_vec1 = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i a_vec2 = _mm256_loadu_si256((__m256i*)&A[i + 16]);\n        __m256i b_vec1 = _mm256_loadu_si256((__m256i*)&B[i]);\n        __m256i b_vec2 = _mm256_loadu_si256((__m256i*)&B[i + 16]);\n\n        __m256i eq1 = _mm256_cmpeq_epi8(a_vec1, b_vec1);\n        __m256i eq2 = _mm256_cmpeq_epi8(a_vec2, b_vec2);\n\n        count_vec = _mm256_add_epi8(count_vec, eq1);\n        count_vec = _mm256_add_epi8(count_vec, eq2);\n    }\n\n    // Horizontal sum of the count_vec\n    uint8_t count_arr[32];\n    _mm256_storeu_si256((__m256i*)count_arr, count_vec);\n    for (size_t j = 0; j < 32; j++) {\n        count += count_arr[j];\n    }\n\n    // Handle remaining elements\n    for (; i < total_elements; i++) {\n        if (A[i] == B[i]) {\n            count++;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_33_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nsize_t tensor_4d_equal_count_simd(const uint8_t* A, const uint8_t* B, const size_t dims[4]) {\n    size_t total_elements = dims[0] * dims[1] * dims[2] * dims[3];\n    size_t count = 0;\n\n    size_t i;\n    __m256i count_vec = _mm256_setzero_si256();\n\n    for (i = 0; i <= total_elements - 32; i += 32) {\n        __m256i a_vec = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i b_vec = _mm256_loadu_si256((__m256i*)&B[i]);\n        __m256i equal_mask = _mm256_cmpeq_epi8(a_vec, b_vec);\n        count_vec = _mm256_add_epi64(count_vec, _mm256_sad_epu8(equal_mask, _mm256_setzero_si256()));\n    }\n\n    // Horizontal sum of count_vec\n    uint64_t counts[4];\n    _mm256_storeu_si256((__m256i*)counts, count_vec);\n    for (int j = 0; j < 4; j++) {\n        count += counts[j];\n    }\n\n    // Handle remaining elements\n    for (; i < total_elements; i++) {\n        if (A[i] == B[i]) {\n            count++;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_33_AVX", "completion": "```cpp\nsize_t tensor_4d_equal_count_simd(const uint8_t* A, const uint8_t* B, const size_t dims[4]) {\n    size_t total_elements = dims[0] * dims[1] * dims[2] * dims[3];\n    size_t count = 0;\n    size_t i;\n\n    __m256i count_vec = _mm256_setzero_si256();\n\n    for (i = 0; i <= total_elements - 32; i += 32) {\n        __m256i a_vec1 = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i a_vec2 = _mm256_loadu_si256((__m256i*)&A[i + 16]);\n        __m256i b_vec1 = _mm256_loadu_si256((__m256i*)&B[i]);\n        __m256i b_vec2 = _mm256_loadu_si256((__m256i*)&B[i + 16]);\n\n        __m256i cmp1 = _mm256_cmpeq_epi8(a_vec1, b_vec1);\n        __m256i cmp2 = _mm256_cmpeq_epi8(a_vec2, b_vec2);\n\n        count_vec = _mm256_add_epi8(count_vec, cmp1);\n        count_vec = _mm256_add_epi8(count_vec, cmp2);\n    }\n\n    // Horizontal sum of the counts\n    uint8_t counts[32];\n    _mm256_storeu_si256((__m256i*)counts, count_vec);\n    for (size_t j = 0; j < 32; j++) {\n        count += counts[j];\n    }\n\n    // Handle remaining elements\n    for (; i < total_elements; i++) {\n        count += (A[i] == B[i]);\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_34_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid axm_abs_simd(size_t length, const int64_t a, const int64_t *x, int64_t *y) {\n    size_t i;\n    __m256i scalar = _mm256_set1_epi64x(a);\n\n    for (i = 0; i < length / 4 * 4; i += 4) {\n        __m256i vec_x = _mm256_loadu_si256((__m256i*)&x[i]);\n        __m256i product = _mm256_mullo_epi64(scalar, vec_x);\n        __m256i abs_y = _mm256_abs_epi64(product);\n        _mm256_storeu_si256((__m256i*)&y[i], abs_y);\n    }\n\n    for (; i < length; i++) {\n        y[i] = abs(a * x[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_34_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid axm_abs_simd(size_t length, const int64_t a, const int64_t *x, int64_t *y) {\n    size_t i;\n    __m256i scalar = _mm256_set1_epi64x(a);\n    \n    for (i = 0; i < length / 4; i++) {\n        __m256i vec_x = _mm256_loadu_si256((__m256i*)&x[i * 4]);\n        __m256i mul_result = _mm256_mullo_epi64(scalar, vec_x);\n        __m256i abs_result = _mm256_abs_epi64(mul_result);\n        _mm256_storeu_si256((__m256i*)&y[i * 4], abs_result);\n    }\n\n    for (; i < length; i++) {\n        y[i] = abs(a * x[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_34_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid axm_abs_simd(size_t length, const int64_t a, const int64_t *x, int64_t *y) {\n    size_t i;\n    __m256i scalar = _mm256_set1_epi64x(a);\n    \n    for (i = 0; i < length / 4 * 4; i += 4) {\n        __m256i vec_x = _mm256_loadu_si256((__m256i*)&x[i]);\n        __m256i mul_result = _mm256_mullo_epi64(scalar, vec_x);\n        __m256i abs_result = _mm256_abs_epi64(mul_result);\n        _mm256_storeu_si256((__m256i*)&y[i], abs_result);\n    }\n\n    for (; i < length; i++) {\n        y[i] = abs(a * x[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_34_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid axm_abs_simd(size_t length, const int64_t a, const int64_t *x, int64_t *y) {\n    size_t i;\n    __m256i scalar = _mm256_set1_epi64x(a);\n    \n    for (i = 0; i < length / 4; i++) {\n        __m256i vec_x = _mm256_loadu_si256((__m256i*)&x[i * 4]);\n        __m256i mul_result = _mm256_mullo_epi64(scalar, vec_x);\n        __m256i abs_result = _mm256_abs_epi64(mul_result);\n        _mm256_storeu_si256((__m256i*)&y[i * 4], abs_result);\n    }\n\n    for (; i < length; i++) {\n        y[i] = abs(a * x[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_34_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid axm_abs_simd(size_t length, const int64_t a, const int64_t *x, int64_t *y) {\n    size_t i;\n    __m256i scalar = _mm256_set1_epi64x(a);\n    \n    for (i = 0; i < length; i += 4) {\n        __m256i vec_x = _mm256_loadu_si256((__m256i*)&x[i]);\n        __m256i mul_result = _mm256_mullo_epi64(scalar, vec_x);\n        __m256i abs_result = _mm256_abs_epi64(mul_result);\n        _mm256_storeu_si256((__m256i*)&y[i], abs_result);\n    }\n}\n```"}
{"task_id": "SimdBench_35_AVX", "completion": "```c\nMinMaxPair min_max_pair_simd(const int16_t* vec, size_t length) {\n    MinMaxPair result;\n    __m256i min_val = _mm256_set1_epi16(INT16_MAX);\n    __m256i max_val = _mm256_set1_epi16(INT16_MIN);\n\n    size_t i;\n    for (i = 0; i < length / 16 * 16; i += 16) {\n        __m256i data = _mm256_loadu_si256((__m256i*)&vec[i]);\n        min_val = _mm256_min_epi16(min_val, data);\n        max_val = _mm256_max_epi16(max_val, data);\n    }\n\n    // Handle remaining elements\n    for (; i < length; i++) {\n        int16_t value = vec[i];\n        if (value < _mm256_extract_epi16(min_val, 0)) {\n            min_val = _mm256_insert_epi16(min_val, value, 0);\n        }\n        if (value > _mm256_extract_epi16(max_val, 0)) {\n            max_val = _mm256_insert_epi16(max_val, value, 0);\n        }\n    }\n\n    // Horizontal reduction to find min and max\n    min_val = _mm256_min_epi16(min_val, _mm256_shuffle_epi32(min_val, _MM_SHUFFLE(2, 3, 0, 1)));\n    min_val = _mm256_min_epi16(min_val, _mm256_shuffle_epi32(min_val, _MM_SHUFFLE(1, 0, 3, 2)));\n    result.min_num = _mm256_extract_epi16(min_val, 0);\n\n    max_val = _mm256_max_epi16(max_val, _mm256_shuffle_epi32(max_val, _MM_SHUFFLE(2, 3, 0, 1)));\n    max_val = _mm256_max_epi16(max_val, _mm256_shuffle_epi32(max_val, _MM_SHUFFLE(1, 0, 3, 2)));\n    result.max_num = _mm256_extract_epi16(max_val, 0);\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_35_AVX", "completion": "```c\nMinMaxPair min_max_pair_simd(const int16_t* vec, size_t length) {\n    MinMaxPair result = {INT16_MAX, INT16_MIN};\n    size_t i;\n\n    __m256i min_vec = _mm256_set1_epi16(INT16_MAX);\n    __m256i max_vec = _mm256_set1_epi16(INT16_MIN);\n\n    for (i = 0; i < length / 16 * 16; i += 16) {\n        __m256i data = _mm256_loadu_si256((__m256i*)&vec[i]);\n        min_vec = _mm256_min_epi16(min_vec, data);\n        max_vec = _mm256_max_epi16(max_vec, data);\n    }\n\n    // Handle remaining elements\n    for (; i < length; i++) {\n        int16_t value = vec[i];\n        if (value < result.min_num) result.min_num = value;\n        if (value > result.max_num) result.max_num = value;\n    }\n\n    // Extract min and max from the vectors\n    int16_t min_array[16], max_array[16];\n    _mm256_storeu_si256((__m256i*)min_array, min_vec);\n    _mm256_storeu_si256((__m256i*)max_array, max_vec);\n\n    for (i = 0; i < 16; i++) {\n        if (min_array[i] < result.min_num) result.min_num = min_array[i];\n        if (max_array[i] > result.max_num) result.max_num = max_array[i];\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_35_AVX", "completion": "```c\n#include <immintrin.h>\n#include <x86intrin.h>\n\ntypedef struct {\n    int16_t min_num;\n    int16_t max_num;\n} MinMaxPair;\n\nMinMaxPair min_max_pair_simd(const int16_t* vec, size_t length) {\n    MinMaxPair result = {INT16_MAX, INT16_MIN};\n    \n    size_t i;\n    __m256i min_vec = _mm256_set1_epi16(INT16_MAX);\n    __m256i max_vec = _mm256_set1_epi16(INT16_MIN);\n\n    for (i = 0; i < length / 16 * 16; i += 16) {\n        __m256i data = _mm256_loadu_si256((__m256i*)&vec[i]);\n        min_vec = _mm256_min_epi16(min_vec, data);\n        max_vec = _mm256_max_epi16(max_vec, data);\n    }\n\n    // Handle remaining elements\n    for (; i < length; i++) {\n        result.min_num = (vec[i] < result.min_num) ? vec[i] : result.min_num;\n        result.max_num = (vec[i] > result.max_num) ? vec[i] : result.max_num;\n    }\n\n    // Reduce min_vec and max_vec to find final min and max\n    int16_t min_arr[16], max_arr[16];\n    _mm256_storeu_si256((__m256i*)min_arr, min_vec);\n    _mm256_storeu_si256((__m256i*)max_arr, max_vec);\n\n    for (int j = 0; j < 16; j++) {\n        result.min_num = (min_arr[j] < result.min_num) ? min_arr[j] : result.min_num;\n        result.max_num = (max_arr[j] > result.max_num) ? max_arr[j] : result.max_num;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_35_AVX", "completion": "```c\nMinMaxPair min_max_pair_simd(const int16_t* vec, size_t length) {\n    MinMaxPair result = {INT16_MAX, INT16_MIN};\n    size_t i = 0;\n\n    __m256i min_vec = _mm256_set1_epi16(INT16_MAX);\n    __m256i max_vec = _mm256_set1_epi16(INT16_MIN);\n\n    for (; i + 16 <= length; i += 16) {\n        __m256i data = _mm256_loadu_si256((__m256i*)&vec[i]);\n        min_vec = _mm256_min_epi16(min_vec, data);\n        max_vec = _mm256_max_epi16(max_vec, data);\n    }\n\n    // Horizontal reduction for min\n    result.min_num = INT16_MAX;\n    for (int j = 0; j < 16; j++) {\n        result.min_num = (result.min_num < _mm256_extract_epi16(min_vec, j)) ? result.min_num : _mm256_extract_epi16(min_vec, j);\n    }\n\n    // Horizontal reduction for max\n    result.max_num = INT16_MIN;\n    for (int j = 0; j < 16; j++) {\n        result.max_num = (result.max_num > _mm256_extract_epi16(max_vec, j)) ? result.max_num : _mm256_extract_epi16(max_vec, j);\n    }\n\n    // Handle remaining elements\n    for (; i < length; i++) {\n        result.min_num = (result.min_num < vec[i]) ? result.min_num : vec[i];\n        result.max_num = (result.max_num > vec[i]) ? result.max_num : vec[i];\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_35_AVX", "completion": "```c\nMinMaxPair min_max_pair_simd(const int16_t* vec, size_t length) {\n    MinMaxPair result = {INT16_MAX, INT16_MIN};\n    \n    __m256i min_vec = _mm256_set1_epi16(INT16_MAX);\n    __m256i max_vec = _mm256_set1_epi16(INT16_MIN);\n    \n    size_t i;\n    for (i = 0; i + 16 <= length; i += 16) {\n        __m256i data = _mm256_loadu_si256((__m256i*)&vec[i]);\n        min_vec = _mm256_min_epi16(min_vec, data);\n        max_vec = _mm256_max_epi16(max_vec, data);\n    }\n\n    // Horizontal reduction for min\n    int16_t min_arr[16];\n    _mm256_storeu_si256((__m256i*)min_arr, min_vec);\n    for (int j = 0; j < 16; j++) {\n        result.min_num = (min_arr[j] < result.min_num) ? min_arr[j] : result.min_num;\n    }\n\n    // Horizontal reduction for max\n    int16_t max_arr[16];\n    _mm256_storeu_si256((__m256i*)max_arr, max_vec);\n    for (int j = 0; j < 16; j++) {\n        result.max_num = (max_arr[j] > result.max_num) ? max_arr[j] : result.max_num;\n    }\n\n    // Handle remaining elements\n    for (; i < length; i++) {\n        result.min_num = (vec[i] < result.min_num) ? vec[i] : result.min_num;\n        result.max_num = (vec[i] > result.max_num) ? vec[i] : result.max_num;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_36_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nbool matrix_rows_strictly_increasing_simd(const int* matrix, size_t rows, size_t cols) {\n    if (rows == 0 || cols == 0) return false;\n\n    for (size_t r = 0; r < rows; ++r) {\n        const int* row = matrix + r * cols;\n        for (size_t c = 0; c < cols - 8; c += 8) {\n            __m256i current = _mm256_loadu_si256((__m256i*)&row[c]);\n            __m256i next = _mm256_loadu_si256((__m256i*)&row[c + 1]);\n\n            __m256i cmp = _mm256_cmpgt_epi32(next, current);\n            if (_mm256_movemask_epi8(cmp) != 0xFFFF) {\n                return false;\n            }\n        }\n        for (size_t c = cols - 8; c < cols - 1; ++c) {\n            if (row[c] >= row[c + 1]) {\n                return false;\n            }\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_36_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nbool matrix_rows_strictly_increasing_simd(const int* matrix, size_t rows, size_t cols) {\n    if (rows == 0 || cols == 0) return false;\n\n    for (size_t r = 0; r < rows; ++r) {\n        const int* row = matrix + r * cols;\n        for (size_t c = 0; c < cols - 8; c += 8) {\n            __m256i current = _mm256_loadu_si256((__m256i*)&row[c]);\n            __m256i next = _mm256_loadu_si256((__m256i*)&row[c + 1]);\n            __m256i cmp = _mm256_cmpgt_epi32(next, current);\n            if (_mm256_movemask_epi8(cmp) != 0xFFFF) {\n                return false;\n            }\n        }\n        for (size_t c = cols - (cols % 8); c < cols - 1; ++c) {\n            if (row[c] >= row[c + 1]) {\n                return false;\n            }\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_36_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nbool matrix_rows_strictly_increasing_simd(const int* matrix, size_t rows, size_t cols) {\n    if (rows == 0 || cols == 0) return false;\n\n    for (size_t r = 0; r < rows; ++r) {\n        const int* row = matrix + r * cols;\n        for (size_t c = 0; c < cols - 8; c += 8) {\n            __m256i current = _mm256_loadu_si256((__m256i*)&row[c]);\n            __m256i next = _mm256_loadu_si256((__m256i*)&row[c + 1]);\n\n            __m256i cmp = _mm256_cmpgt_epi32(next, current);\n            if (_mm256_movemask_epi8(cmp) != 0xFFFF) {\n                return false;\n            }\n        }\n\n        for (size_t c = cols - 8; c < cols - 1; ++c) {\n            if (row[c] >= row[c + 1]) {\n                return false;\n            }\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_36_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nbool matrix_rows_strictly_increasing_simd(const int* matrix, size_t rows, size_t cols) {\n    if (rows == 0 || cols == 0) return false;\n\n    for (size_t r = 0; r < rows; ++r) {\n        const int* row = matrix + r * cols;\n\n        for (size_t c = 0; c < cols - 8; c += 8) {\n            __m256i current = _mm256_loadu_si256((__m256i*)&row[c]);\n            __m256i next = _mm256_loadu_si256((__m256i*)&row[c + 1]);\n\n            __m256i cmp = _mm256_cmpgt_epi32(next, current);\n            if (_mm256_movemask_epi8(cmp) != 0xFFFF) {\n                return false;\n            }\n        }\n\n        for (size_t c = cols - (cols % 8); c < cols - 1; ++c) {\n            if (row[c] >= row[c + 1]) {\n                return false;\n            }\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_36_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nbool matrix_rows_strictly_increasing_simd(const int* matrix, size_t rows, size_t cols) {\n    if (rows == 0 || cols == 0) return false;\n\n    for (size_t r = 0; r < rows; ++r) {\n        const int* row = matrix + r * cols;\n        for (size_t c = 0; c < cols - 8; c += 8) {\n            __m256i current = _mm256_loadu_si256((__m256i*)&row[c]);\n            __m256i next = _mm256_loadu_si256((__m256i*)&row[c + 1]);\n\n            __m256i cmp = _mm256_cmpgt_epi32(next, current);\n            if (_mm256_movemask_epi8(cmp) != 0xFFFF) {\n                return false;\n            }\n        }\n\n        for (size_t c = cols - (cols % 8); c < cols - 1; ++c) {\n            if (row[c] >= row[c + 1]) {\n                return false;\n            }\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_37_AVX", "completion": "```cpp\nbool matrix_blocks_equal_simd(const int* matrix, size_t block_size, size_t rows, size_t cols) {\n    if (block_size == 0 || rows % block_size != 0 || cols % block_size != 0) {\n        return false;\n    }\n\n    size_t num_blocks_row = rows / block_size;\n    size_t num_blocks_col = cols / block_size;\n    size_t block_elements = block_size * block_size;\n\n    const int* first_block = matrix;\n\n    for (size_t i = 0; i < num_blocks_row; ++i) {\n        for (size_t j = 0; j < num_blocks_col; ++j) {\n            const int* current_block = matrix + (i * block_size * cols + j * block_size);\n            __m256i first_block_vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(first_block));\n            for (size_t k = 0; k < block_elements; k += 8) {\n                __m256i current_block_vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(current_block + k));\n                __m256i cmp = _mm256_cmpeq_epi32(first_block_vec, current_block_vec);\n                int mask = _mm256_movemask_epi8(cmp);\n                if (mask != 0xFFFF) {\n                    return false;\n                }\n            }\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_37_AVX", "completion": "```cpp\nbool matrix_blocks_equal_simd(const int* matrix, size_t block_size, size_t rows, size_t cols) {\n    if (block_size == 0 || rows % block_size != 0 || cols % block_size != 0) {\n        return false;\n    }\n\n    size_t num_blocks_row = rows / block_size;\n    size_t num_blocks_col = cols / block_size;\n\n    const int* first_block = matrix;\n\n    for (size_t block_row = 0; block_row < num_blocks_row; ++block_row) {\n        for (size_t block_col = 0; block_col < num_blocks_col; ++block_col) {\n            const int* current_block = matrix + (block_row * block_size * cols + block_col * block_size);\n\n            for (size_t i = 0; i < block_size; ++i) {\n                __m256i first_row = _mm256_loadu_si256((__m256i*)(first_block + i * cols));\n                __m256i current_row = _mm256_loadu_si256((__m256i*)(current_block + i * cols));\n\n                __m256i cmp = _mm256_cmpeq_epi32(first_row, current_row);\n                int mask = _mm256_movemask_epi8(cmp);\n\n                if (mask != 0xFFFF) {\n                    return false;\n                }\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_37_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nbool matrix_blocks_equal_simd(const int* matrix, size_t block_size, size_t rows, size_t cols) {\n    if (block_size == 0 || rows % block_size != 0 || cols % block_size != 0) {\n        return false;\n    }\n\n    size_t num_blocks_row = rows / block_size;\n    size_t num_blocks_col = cols / block_size;\n\n    const int* first_block = matrix;\n\n    for (size_t block_row = 0; block_row < num_blocks_row; ++block_row) {\n        for (size_t block_col = 0; block_col < num_blocks_col; ++block_col) {\n            if (block_row == 0 && block_col == 0) continue;\n\n            const int* current_block = matrix + (block_row * block_size * cols + block_col * block_size);\n\n            for (size_t i = 0; i < block_size; ++i) {\n                __m256i first_row = _mm256_loadu_si256((__m256i*)(first_block + i * cols));\n                __m256i current_row = _mm256_loadu_si256((__m256i*)(current_block + i * cols));\n\n                __m256i cmp = _mm256_cmpeq_epi32(first_row, current_row);\n                int mask = _mm256_movemask_epi8(cmp);\n\n                if (mask != 0xFFFFFFFF) {\n                    return false;\n                }\n            }\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_37_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nbool matrix_blocks_equal_simd(const int* matrix, size_t block_size, size_t rows, size_t cols) {\n    if (block_size == 0 || rows % block_size != 0 || cols % block_size != 0) {\n        return false;\n    }\n\n    size_t num_blocks_row = rows / block_size;\n    size_t num_blocks_col = cols / block_size;\n\n    const int* first_block = matrix;\n\n    for (size_t block_row = 0; block_row < num_blocks_row; ++block_row) {\n        for (size_t block_col = 0; block_col < num_blocks_col; ++block_col) {\n            if (block_row == 0 && block_col == 0) continue; // Skip the first block\n\n            const int* current_block = matrix + (block_row * block_size * cols + block_col * block_size);\n\n            for (size_t i = 0; i < block_size; ++i) {\n                __m256i first_row = _mm256_loadu_si256((__m256i*)(first_block + i * cols));\n                __m256i current_row = _mm256_loadu_si256((__m256i*)(current_block + i * cols));\n\n                __m256i cmp = _mm256_cmpeq_epi32(first_row, current_row);\n                int mask = _mm256_movemask_epi8(cmp);\n\n                if (mask != 0xFFFFFFFF) {\n                    return false;\n                }\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_37_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nbool matrix_blocks_equal_simd(const int* matrix, size_t block_size, size_t rows, size_t cols) {\n    if (block_size == 0 || rows % block_size != 0 || cols % block_size != 0) {\n        return false;\n    }\n\n    size_t num_blocks_row = rows / block_size;\n    size_t num_blocks_col = cols / block_size;\n    size_t block_elements = block_size * block_size;\n\n    const int* first_block = matrix;\n\n    for (size_t block_row = 0; block_row < num_blocks_row; ++block_row) {\n        for (size_t block_col = 0; block_col < num_blocks_col; ++block_col) {\n            const int* current_block = matrix + (block_row * block_size * cols + block_col * block_size);\n\n            for (size_t i = 0; i < block_size; ++i) {\n                __m256i first_row = _mm256_loadu_si256((__m256i*)(first_block + i * cols));\n                __m256i current_row = _mm256_loadu_si256((__m256i*)(current_block + i * cols));\n\n                __m256i cmp = _mm256_cmpeq_epi32(first_row, current_row);\n                int mask = _mm256_movemask_epi8(cmp);\n\n                if (mask != 0xFFFF) {\n                    return false;\n                }\n            }\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_38_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nbool vector_block_equal_simd(const double* vec, double tolerance, size_t length, size_t block_size) {\n    if (vec == nullptr || length < block_size || block_size == 0 || length % block_size != 0) {\n        return false;\n    }\n\n    __m256d tol_vec = _mm256_set1_pd(tolerance);\n    size_t num_blocks = length / block_size;\n\n    __m256d first_block = _mm256_loadu_pd(vec);\n\n    for (size_t i = 1; i < num_blocks; ++i) {\n        __m256d current_block = _mm256_loadu_pd(vec + i * block_size);\n        \n        __m256d diff = _mm256_sub_pd(first_block, current_block);\n        __m256d abs_diff = _mm256_andnot_pd(_mm256_set1_pd(-0.0), diff);\n        \n        __m256d cmp = _mm256_cmp_pd(abs_diff, tol_vec, _CMP_LT_OQ);\n        if (_mm256_movemask_pd(cmp) != 0) {\n            return false;\n        }\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_38_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nbool vector_block_equal_simd(const double* vec, double tolerance, size_t length, size_t block_size) {\n    if (vec == nullptr || block_size == 0 || length < block_size) {\n        return false;\n    }\n\n    size_t num_blocks = length / block_size;\n    __m256d tolerance_vec = _mm256_set1_pd(tolerance);\n\n    for (size_t i = 0; i < num_blocks; ++i) {\n        __m256d first_block = _mm256_loadu_pd(&vec[i * block_size]);\n        bool all_equal = true;\n\n        for (size_t j = 1; j < block_size; ++j) {\n            __m256d current_block = _mm256_loadu_pd(&vec[i * block_size + j]);\n            __m256d diff = _mm256_sub_pd(first_block, current_block);\n            __m256d abs_diff = _mm256_andnot_pd(_mm256_set1_pd(-0.0), diff);\n            __m256d cmp = _mm256_cmp_pd(abs_diff, tolerance_vec, _CMP_LT_OQ);\n\n            if (_mm256_movemask_pd(cmp) != 0xF) {\n                all_equal = false;\n                break;\n            }\n        }\n\n        if (!all_equal) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_38_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nbool vector_block_equal_simd(const double* vec, double tolerance, size_t length, size_t block_size) {\n    if (vec == nullptr || length < block_size || block_size == 0 || length % block_size != 0) {\n        return false;\n    }\n\n    __m256d tol_vec = _mm256_set1_pd(tolerance);\n    size_t num_blocks = length / block_size;\n\n    __m256d first_block = _mm256_loadu_pd(vec);\n\n    for (size_t i = 1; i < num_blocks; ++i) {\n        const double* current_block = vec + i * block_size;\n        __m256d current_vec = _mm256_loadu_pd(current_block);\n\n        __m256d diff = _mm256_sub_pd(first_block, current_vec);\n        __m256d abs_diff = _mm256_andnot_pd(_mm256_set1_pd(-0.0), diff);\n        __m256d cmp = _mm256_cmp_pd(abs_diff, tol_vec, _CMP_LT_OQ);\n\n        if (_mm256_movemask_pd(cmp) != 0xF) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_38_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nbool vector_block_equal_simd(const double* vec, double tolerance, size_t length, size_t block_size) {\n    if (vec == nullptr || block_size == 0 || length < block_size) {\n        return false;\n    }\n\n    size_t num_blocks = length / block_size;\n    __m256d tolerance_vec = _mm256_set1_pd(tolerance);\n\n    for (size_t i = 0; i < num_blocks; ++i) {\n        const double* block_start = vec + i * block_size;\n        __m256d first_block = _mm256_loadu_pd(block_start);\n\n        for (size_t j = 1; j < block_size / 4; ++j) {\n            __m256d current_block = _mm256_loadu_pd(block_start + j * 4);\n            __m256d diff = _mm256_sub_pd(first_block, current_block);\n            __m256d abs_diff = _mm256_andnot_pd(_mm256_set1_pd(-0.0), diff);\n            __m256d within_tolerance = _mm256_cmp_pd(abs_diff, tolerance_vec, _CMP_LE_OQ);\n            if (_mm256_movemask_pd(within_tolerance) != 0xF) {\n                return false;\n            }\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_38_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nbool vector_block_equal_simd(const double* vec, double tolerance, size_t length, size_t block_size) {\n    if (vec == nullptr || length < block_size || block_size == 0 || (length % block_size) != 0) {\n        return false;\n    }\n\n    size_t num_blocks = length / block_size;\n    __m256d tolerance_vec = _mm256_set1_pd(tolerance);\n\n    for (size_t i = 1; i < num_blocks; ++i) {\n        __m256d first_block = _mm256_loadu_pd(&vec[0 + 0 * block_size]);\n        __m256d current_block = _mm256_loadu_pd(&vec[i * block_size]);\n\n        __m256d diff = _mm256_sub_pd(first_block, current_block);\n        __m256d abs_diff = _mm256_andnot_pd(_mm256_set1_pd(-0.0), diff);\n        __m256d cmp = _mm256_cmp_pd(abs_diff, tolerance_vec, _CMP_LT_OQ);\n\n        if (_mm256_movemask_pd(cmp) != 0xF) {\n            return false;\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_39_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <stdbool.h>\n#include <stddef.h>\n\nvoid matrix_row_norm_compare_simd(const double* matrix, const double* thresholds, size_t rows, size_t cols, bool* result) {\n    for (size_t i = 0; i < rows; ++i) {\n        __m256d sum = _mm256_setzero_pd();\n        for (size_t j = 0; j < cols; j += 4) {\n            __m256d vec = _mm256_loadu_pd(&matrix[i * cols + j]);\n            sum = _mm256_add_pd(sum, _mm256_mul_pd(vec, vec));\n        }\n        double norm[4];\n        _mm256_storeu_pd(norm, sum);\n        double euclidean_norm = sqrt(norm[0] + norm[1] + norm[2] + norm[3]);\n\n        result[i] = euclidean_norm > thresholds[i];\n    }\n}\n```"}
{"task_id": "SimdBench_39_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <cmath>\n\nvoid matrix_row_norm_compare_simd(const double* matrix, const double* thresholds, size_t rows, size_t cols, bool* result) {\n    __m256d threshold_vec;\n    __m256d sum_vec, norm_vec;\n\n    for (size_t i = 0; i < rows; ++i) {\n        sum_vec = _mm256_setzero_pd();\n        for (size_t j = 0; j < cols; j += 4) {\n            __m256d row_vec = _mm256_loadu_pd(&matrix[i * cols + j]);\n            sum_vec = _mm256_add_pd(sum_vec, _mm256_mul_pd(row_vec, row_vec));\n        }\n        norm_vec = _mm256_sqrt_pd(sum_vec);\n        threshold_vec = _mm256_loadu_pd(&thresholds[i]);\n\n        __m256d comparison = _mm256_cmp_pd(norm_vec, threshold_vec, _CMP_GT_OQ);\n        result[i] = _mm256_movemask_pd(comparison) != 0;\n    }\n}\n```"}
{"task_id": "SimdBench_39_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <cmath>\n\nvoid matrix_row_norm_compare_simd(const double* matrix, const double* thresholds, size_t rows, size_t cols, bool* result) {\n    __m256d threshold_vec;\n    __m256d norm_vec;\n\n    for (size_t i = 0; i < rows; ++i) {\n        norm_vec = _mm256_setzero_pd();\n        for (size_t j = 0; j < cols; j += 4) {\n            __m256d row_vec = _mm256_loadu_pd(&matrix[i * cols + j]);\n            norm_vec = _mm256_add_pd(norm_vec, _mm256_mul_pd(row_vec, row_vec));\n        }\n        norm_vec = _mm256_sqrt_pd(norm_vec);\n\n        threshold_vec = _mm256_loadu_pd(&thresholds[i]);\n        __m256d comparison = _mm256_cmp_pd(norm_vec, threshold_vec, _CMP_GT_OQ);\n        \n        result[i] = (_mm256_movemask_pd(comparison) != 0);\n    }\n}\n```"}
{"task_id": "SimdBench_39_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <cmath>\n\nvoid matrix_row_norm_compare_simd(const double* matrix, const double* thresholds, size_t rows, size_t cols, bool* result) {\n    for (size_t i = 0; i < rows; ++i) {\n        __m256d sum = _mm256_setzero_pd();\n        for (size_t j = 0; j < cols; j += 4) {\n            __m256d vec = _mm256_loadu_pd(&matrix[i * cols + j]);\n            sum = _mm256_add_pd(sum, _mm256_mul_pd(vec, vec));\n        }\n        double norm[4];\n        _mm256_storeu_pd(norm, sum);\n        double euclidean_norm = std::sqrt(norm[0] + norm[1] + norm[2] + norm[3]);\n\n        result[i] = euclidean_norm > thresholds[i];\n    }\n}\n```"}
{"task_id": "SimdBench_39_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <cmath>\n\nvoid matrix_row_norm_compare_simd(const double* matrix, const double* thresholds, size_t rows, size_t cols, bool* result) {\n    for (size_t i = 0; i < rows; ++i) {\n        __m256d sum = _mm256_setzero_pd();\n        for (size_t j = 0; j < cols; j += 4) {\n            __m256d vec = _mm256_loadu_pd(&matrix[i * cols + j]);\n            sum = _mm256_add_pd(sum, _mm256_mul_pd(vec, vec));\n        }\n        double norm[4];\n        _mm256_storeu_pd(norm, sum);\n        double euclidean_norm = std::sqrt(norm[0] + norm[1] + norm[2] + norm[3]);\n        \n        result[i] = euclidean_norm > thresholds[i];\n    }\n}\n```"}
{"task_id": "SimdBench_40_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid tensor_bitwise_or_simd(const uint32_t* A, const uint32_t* B, uint32_t* C, size_t length) {\n    size_t i = 0;\n\n    // Process 8 elements at a time using AVX2\n    for (; i + 8 <= length; i += 8) {\n        __m256i a = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i b = _mm256_loadu_si256((__m256i*)&B[i]);\n        __m256i c = _mm256_or_si256(a, b);\n        _mm256_storeu_si256((__m256i*)&C[i], c);\n    }\n\n    // Handle remaining elements\n    for (; i < length; i++) {\n        C[i] = A[i] | B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_40_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid tensor_bitwise_or_simd(const uint32_t* A, const uint32_t* B, uint32_t* C, size_t length) {\n    size_t i = 0;\n\n    // Process 8 elements at a time using AVX2\n    for (; i + 8 <= length; i += 8) {\n        __m256i a = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i b = _mm256_loadu_si256((__m256i*)&B[i]);\n        __m256i c = _mm256_or_si256(a, b);\n        _mm256_storeu_si256((__m256i*)&C[i], c);\n    }\n\n    // Handle remaining elements\n    for (; i < length; i++) {\n        C[i] = A[i] | B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_40_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid tensor_bitwise_or_simd(const uint32_t* A, const uint32_t* B, uint32_t* C, size_t length) {\n    size_t i;\n    // Process 8 elements at a time\n    for (i = 0; i + 8 <= length; i += 8) {\n        __m256i a = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i b = _mm256_loadu_si256((__m256i*)&B[i]);\n        __m256i result = _mm256_or_si256(a, b);\n        _mm256_storeu_si256((__m256i*)&C[i], result);\n    }\n    // Handle remaining elements\n    for (; i < length; i++) {\n        C[i] = A[i] | B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_40_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid tensor_bitwise_or_simd(const uint32_t* A, const uint32_t* B, uint32_t* C, size_t length) {\n    size_t i;\n    // Process 8 elements at a time\n    for (i = 0; i <= length - 8; i += 8) {\n        __m256i a = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i b = _mm256_loadu_si256((__m256i*)&B[i]);\n        __m256i c = _mm256_or_si256(a, b);\n        _mm256_storeu_si256((__m256i*)&C[i], c);\n    }\n    // Handle remaining elements\n    for (; i < length; i++) {\n        C[i] = A[i] | B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_40_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid tensor_bitwise_or_simd(const uint32_t* A, const uint32_t* B, uint32_t* C, size_t length) {\n    size_t i;\n    size_t simd_length = length / 8; // Process 8 elements at a time\n    __m256i* a_vec = (__m256i*)A;\n    __m256i* b_vec = (__m256i*)B;\n    __m256i* c_vec = (__m256i*)C;\n\n    for (i = 0; i < simd_length; ++i) {\n        __m256i a = _mm256_loadu_si256(&a_vec[i]);\n        __m256i b = _mm256_loadu_si256(&b_vec[i]);\n        __m256i c = _mm256_or_si256(a, b);\n        _mm256_storeu_si256(&c_vec[i], c);\n    }\n\n    // Handle remaining elements\n    for (i *= 8; i < length; ++i) {\n        C[i] = A[i] | B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_41_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nint64_t squarediff_simd(const int8_t * A, const int8_t * B, size_t length) {\n    __m256i sum_squares = _mm256_setzero_si256();\n    __m256i sum_products = _mm256_setzero_si256();\n\n    size_t i;\n    for (i = 0; i < length / 32 * 32; i += 32) {\n        __m256i a1 = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i b1 = _mm256_loadu_si256((__m256i*)&B[i]);\n        __m256i a2 = _mm256_loadu_si256((__m256i*)&A[i + 16]);\n        __m256i b2 = _mm256_loadu_si256((__m256i*)&B[i + 16]);\n\n        sum_squares = _mm256_add_epi64(sum_squares, _mm256_madd_epi16(_mm256_unpacklo_epi8(a1, _mm256_setzero_si256()), _mm256_unpacklo_epi8(a1, _mm256_setzero_si256())));\n        sum_squares = _mm256_add_epi64(sum_squares, _mm256_madd_epi16(_mm256_unpackhi_epi8(a1, _mm256_setzero_si256()), _mm256_unpackhi_epi8(a1, _mm256_setzero_si256())));\n        sum_squares = _mm256_add_epi64(sum_squares, _mm256_madd_epi16(_mm256_unpacklo_epi8(a2, _mm256_setzero_si256()), _mm256_unpacklo_epi8(a2, _mm256_setzero_si256())));\n        sum_squares = _mm256_add_epi64(sum_squares, _mm256_madd_epi16(_mm256_unpackhi_epi8(a2, _mm256_setzero_si256()), _mm256_unpackhi_epi8(a2, _mm256_setzero_si256())));\n\n        sum_products = _mm256_add_epi64(sum_products, _mm256_madd_epi16(_mm256_unpacklo_epi8(a1, _mm256_setzero_si256()), _mm256_unpacklo_epi8(b1, _mm256_setzero_si256())));\n        sum_products = _mm256_add_epi64(sum_products, _mm256_madd_epi16(_mm256_unpackhi_epi8(a1, _mm256_setzero_si256()), _mm256_unpackhi_epi8(b1, _mm256_setzero_si256())));\n        sum_products = _mm256_add_epi64(sum_products, _mm256_madd_epi16(_mm256_unpacklo_epi8(a2, _mm256_setzero_si256()), _mm256_unpacklo_epi8(b2, _mm256_setzero_si256())));\n        sum_products = _mm256_add_epi64(sum_products, _mm256_madd_epi16(_mm256_unpackhi_epi8(a2, _mm256_setzero_si256()), _mm256_unpackhi_epi8(b2, _mm256_setzero_si256())));\n    }\n\n    int64_t result_squares[4], result_products[4];\n    _mm256_storeu_si256((__m256i*)result_squares, sum_squares);\n    _mm256_storeu_si256((__m256i*)result_products, sum_products);\n\n    int64_t total_squares = result_squares[0] + result_squares[1] + result_squares[2] + result_squares[3];\n    int64_t total_products = result_products[0] + result_products[1] + result_products[2] + result_products[3];\n\n    for (; i < length; i++) {\n        total_squares += A[i] * A[i];\n        total_products += A[i] * B[i];\n    }\n\n    return total_squares - total_products;\n}\n```"}
{"task_id": "SimdBench_41_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nint64_t squarediff_simd(const int8_t * A, const int8_t * B, size_t length) {\n    __m256i sum_squares = _mm256_setzero_si256();\n    __m256i sum_products = _mm256_setzero_si256();\n\n    size_t i;\n    for (i = 0; i <= length - 32; i += 32) {\n        __m256i a1 = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i b1 = _mm256_loadu_si256((__m256i*)&B[i]);\n        __m256i a2 = _mm256_loadu_si256((__m256i*)&A[i + 16]);\n        __m256i b2 = _mm256_loadu_si256((__m256i*)&B[i + 16]);\n\n        sum_squares = _mm256_add_epi64(sum_squares, _mm256_madd_epi16(_mm256_unpacklo_epi8(a1, _mm256_setzero_si256()), _mm256_unpacklo_epi8(a1, _mm256_setzero_si256())));\n        sum_squares = _mm256_add_epi64(sum_squares, _mm256_madd_epi16(_mm256_unpackhi_epi8(a1, _mm256_setzero_si256()), _mm256_unpackhi_epi8(a1, _mm256_setzero_si256())));\n        sum_squares = _mm256_add_epi64(sum_squares, _mm256_madd_epi16(_mm256_unpacklo_epi8(a2, _mm256_setzero_si256()), _mm256_unpacklo_epi8(a2, _mm256_setzero_si256())));\n        sum_squares = _mm256_add_epi64(sum_squares, _mm256_madd_epi16(_mm256_unpackhi_epi8(a2, _mm256_setzero_si256()), _mm256_unpackhi_epi8(a2, _mm256_setzero_si256())));\n\n        sum_products = _mm256_add_epi64(sum_products, _mm256_madd_epi16(_mm256_unpacklo_epi8(a1, _mm256_setzero_si256()), _mm256_unpacklo_epi8(b1, _mm256_setzero_si256())));\n        sum_products = _mm256_add_epi64(sum_products, _mm256_madd_epi16(_mm256_unpackhi_epi8(a1, _mm256_setzero_si256()), _mm256_unpackhi_epi8(b1, _mm256_setzero_si256())));\n        sum_products = _mm256_add_epi64(sum_products, _mm256_madd_epi16(_mm256_unpacklo_epi8(a2, _mm256_setzero_si256()), _mm256_unpacklo_epi8(b2, _mm256_setzero_si256())));\n        sum_products = _mm256_add_epi64(sum_products, _mm256_madd_epi16(_mm256_unpackhi_epi8(a2, _mm256_setzero_si256()), _mm256_unpackhi_epi8(b2, _mm256_setzero_si256())));\n    }\n\n    int64_t squares[4], products[4];\n    _mm256_storeu_si256((__m256i*)squares, sum_squares);\n    _mm256_storeu_si256((__m256i*)products, sum_products);\n\n    int64_t total_squares = squares[0] + squares[1] + squares[2] + squares[3];\n    int64_t total_products = products[0] + products[1] + products[2] + products[3];\n\n    for (; i < length; i++) {\n        total_squares += (int64_t)A[i] * (int64_t)A[i];\n        total_products += (int64_t)A[i] * (int64_t)B[i];\n    }\n\n    return total_squares - total_products;\n}\n```"}
{"task_id": "SimdBench_41_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nint64_t squarediff_simd(const int8_t * A, const int8_t * B, size_t length) {\n    __m256i sum_squares = _mm256_setzero_si256();\n    __m256i sum_products = _mm256_setzero_si256();\n\n    size_t i = 0;\n    for (; i + 32 <= length; i += 32) {\n        __m256i a_vec = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i b_vec = _mm256_loadu_si256((__m256i*)&B[i]);\n\n        sum_squares = _mm256_add_epi64(sum_squares, _mm256_madd_epi16(a_vec, a_vec));\n        sum_products = _mm256_add_epi64(sum_products, _mm256_madd_epi16(a_vec, b_vec));\n    }\n\n    int64_t result_squares[4], result_products[4];\n    _mm256_storeu_si256((__m256i*)result_squares, sum_squares);\n    _mm256_storeu_si256((__m256i*)result_products, sum_products);\n\n    int64_t total_squares = result_squares[0] + result_squares[1] + result_squares[2] + result_squares[3];\n    int64_t total_products = result_products[0] + result_products[1] + result_products[2] + result_products[3];\n\n    for (; i < length; ++i) {\n        total_squares += A[i] * A[i];\n        total_products += A[i] * B[i];\n    }\n\n    return total_squares - total_products;\n}\n```"}
{"task_id": "SimdBench_41_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nint64_t squarediff_simd(const int8_t * A, const int8_t * B, size_t length) {\n    __m256i sum_squares = _mm256_setzero_si256();\n    __m256i sum_products = _mm256_setzero_si256();\n\n    size_t i;\n    for (i = 0; i <= length - 32; i += 32) {\n        __m256i a1 = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i b1 = _mm256_loadu_si256((__m256i*)&B[i]);\n        __m256i a2 = _mm256_loadu_si256((__m256i*)&A[i + 16]);\n        __m256i b2 = _mm256_loadu_si256((__m256i*)&B[i + 16]);\n\n        sum_squares = _mm256_add_epi64(sum_squares, _mm256_madd_epi16(_mm256_unpacklo_epi8(a1, _mm256_setzero_si256()), _mm256_unpacklo_epi8(a1, _mm256_setzero_si256())));\n        sum_squares = _mm256_add_epi64(sum_squares, _mm256_madd_epi16(_mm256_unpackhi_epi8(a1, _mm256_setzero_si256()), _mm256_unpackhi_epi8(a1, _mm256_setzero_si256())));\n        sum_squares = _mm256_add_epi64(sum_squares, _mm256_madd_epi16(_mm256_unpacklo_epi8(a2, _mm256_setzero_si256()), _mm256_unpacklo_epi8(a2, _mm256_setzero_si256())));\n        sum_squares = _mm256_add_epi64(sum_squares, _mm256_madd_epi16(_mm256_unpackhi_epi8(a2, _mm256_setzero_si256()), _mm256_unpackhi_epi8(a2, _mm256_setzero_si256())));\n\n        sum_products = _mm256_add_epi64(sum_products, _mm256_madd_epi16(_mm256_unpacklo_epi8(a1, _mm256_setzero_si256()), _mm256_unpacklo_epi8(b1, _mm256_setzero_si256())));\n        sum_products = _mm256_add_epi64(sum_products, _mm256_madd_epi16(_mm256_unpackhi_epi8(a1, _mm256_setzero_si256()), _mm256_unpackhi_epi8(b1, _mm256_setzero_si256())));\n        sum_products = _mm256_add_epi64(sum_products, _mm256_madd_epi16(_mm256_unpacklo_epi8(a2, _mm256_setzero_si256()), _mm256_unpacklo_epi8(b2, _mm256_setzero_si256())));\n        sum_products = _mm256_add_epi64(sum_products, _mm256_madd_epi16(_mm256_unpackhi_epi8(a2, _mm256_setzero_si256()), _mm256_unpackhi_epi8(b2, _mm256_setzero_si256())));\n    }\n\n    int64_t squares[4], products[4];\n    _mm256_storeu_si256((__m256i*)squares, sum_squares);\n    _mm256_storeu_si256((__m256i*)products, sum_products);\n\n    int64_t total_squares = squares[0] + squares[1] + squares[2] + squares[3];\n    int64_t total_products = products[0] + products[1] + products[2] + products[3];\n\n    for (; i < length; i++) {\n        total_squares += A[i] * A[i];\n        total_products += A[i] * B[i];\n    }\n\n    return total_squares - total_products;\n}\n```"}
{"task_id": "SimdBench_41_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nint64_t squarediff_simd(const int8_t * A, const int8_t * B, size_t length) {\n    __m256i sum_squares = _mm256_setzero_si256();\n    __m256i sum_products = _mm256_setzero_si256();\n\n    size_t i;\n    for (i = 0; i <= length - 32; i += 32) {\n        __m256i a_vec1 = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i a_vec2 = _mm256_loadu_si256((__m256i*)&A[i + 16]);\n        __m256i b_vec1 = _mm256_loadu_si256((__m256i*)&B[i]);\n        __m256i b_vec2 = _mm256_loadu_si256((__m256i*)&B[i + 16]);\n\n        __m256i squares1 = _mm256_mullo_epi16(a_vec1, a_vec1);\n        __m256i squares2 = _mm256_mullo_epi16(a_vec2, a_vec2);\n        __m256i products1 = _mm256_mullo_epi16(a_vec1, b_vec1);\n        __m256i products2 = _mm256_mullo_epi16(a_vec2, b_vec2);\n\n        sum_squares = _mm256_add_epi64(sum_squares, _mm256_add_epi64(squares1, squares2));\n        sum_products = _mm256_add_epi64(sum_products, _mm256_add_epi64(products1, products2));\n    }\n\n    int64_t total_squares = _mm256_reduce_add_epi64(sum_squares);\n    int64_t total_products = _mm256_reduce_add_epi64(sum_products);\n\n    for (; i < length; i++) {\n        total_squares += A[i] * A[i];\n        total_products += A[i] * B[i];\n    }\n\n    return total_squares - total_products;\n}\n```"}
{"task_id": "SimdBench_42_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid tensor_bit_clear_simd(const uint64_t* A, const uint64_t* B, uint64_t* C, size_t length) {\n    size_t i;\n    size_t simd_length = length / 4; // Each AVX2 register can hold 4 uint64_t\n    __m256i* a_vec = (__m256i*)A;\n    __m256i* b_vec = (__m256i*)B;\n    __m256i* c_vec = (__m256i*)C;\n\n    for (i = 0; i < simd_length; i++) {\n        __m256i a = _mm256_loadu_si256(&a_vec[i]);\n        __m256i b = _mm256_loadu_si256(&b_vec[i]);\n        __m256i b_neg = _mm256_andnot_si256(b, _mm256_set1_epi64x(-1));\n        __m256i result = _mm256_and_si256(a, b_neg);\n        _mm256_storeu_si256(&c_vec[i], result);\n    }\n\n    // Handle remaining elements\n    for (; i < length; i++) {\n        C[i] = A[i] & ~B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_42_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid tensor_bit_clear_simd(const uint64_t* A, const uint64_t* B, uint64_t* C, size_t length) {\n    size_t i;\n    size_t vec_size = length / 4; // Each AVX2 register can hold 4 uint64_t\n    __m256i* pA = (__m256i*)A;\n    __m256i* pB = (__m256i*)B;\n    __m256i* pC = (__m256i*)C;\n\n    for (i = 0; i < vec_size; i++) {\n        __m256i a = _mm256_loadu_si256(&pA[i]);\n        __m256i b = _mm256_loadu_si256(&pB[i]);\n        __m256i neg_b = _mm256_andnot_si256(b, _mm256_set1_epi64x(-1));\n        __m256i result = _mm256_and_si256(a, neg_b);\n        _mm256_storeu_si256(&pC[i], result);\n    }\n\n    // Handle remaining elements\n    for (i *= 4; i < length; i++) {\n        C[i] = A[i] & ~B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_42_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid tensor_bit_clear_simd(const uint64_t* A, const uint64_t* B, uint64_t* C, size_t length) {\n    size_t i;\n    size_t vec_size = length / 4 * 4; // Process in chunks of 4 for AVX2\n\n    for (i = 0; i < vec_size; i += 4) {\n        __m256i a = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i b = _mm256_loadu_si256((__m256i*)&B[i]);\n        __m256i b_neg = _mm256_andnot_si256(b, _mm256_set1_epi64x(-1)); // Bitwise negation\n        __m256i result = _mm256_and_si256(a, b_neg);\n        _mm256_storeu_si256((__m256i*)&C[i], result);\n    }\n\n    // Handle remaining elements\n    for (; i < length; ++i) {\n        C[i] = A[i] & ~B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_42_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid tensor_bit_clear_simd(const uint64_t* A, const uint64_t* B, uint64_t* C, size_t length) {\n    size_t i;\n    size_t simd_length = length / 4; // Each AVX2 register can hold 4 uint64_t values\n    __m256i* pA = (__m256i*)A;\n    __m256i* pB = (__m256i*)B;\n    __m256i* pC = (__m256i*)C;\n\n    for (i = 0; i < simd_length; i++) {\n        __m256i a = _mm256_loadu_si256(&pA[i]);\n        __m256i b = _mm256_loadu_si256(&pB[i]);\n        __m256i b_neg = _mm256_andnot_si256(b, _mm256_set1_epi64x(-1)); // Bitwise NOT\n        __m256i result = _mm256_and_si256(a, b_neg);\n        _mm256_storeu_si256(&pC[i], result);\n    }\n\n    // Handle remaining elements\n    for (; i < length; i++) {\n        C[i] = A[i] & ~B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_42_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid tensor_bit_clear_simd(const uint64_t* A, const uint64_t* B, uint64_t* C, size_t length) {\n    size_t i;\n    size_t vec_size = length / 4 * 4; // Process in chunks of 4 for AVX2\n\n    for (i = 0; i < vec_size; i += 4) {\n        __m256i a = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i b = _mm256_loadu_si256((__m256i*)&B[i]);\n        __m256i b_neg = _mm256_andnot_si256(b, _mm256_set1_epi64x(-1)); // Bitwise negation\n        __m256i result = _mm256_and_si256(a, b_neg);\n        _mm256_storeu_si256((__m256i*)&C[i], result);\n    }\n\n    // Handle remaining elements\n    for (; i < length; ++i) {\n        C[i] = A[i] & ~B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_43_AVX", "completion": "```cpp\nvoid tensor_three_valued_logic_simd(const int8_t* A, const int8_t* B, int8_t* C, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 16; i += 16) {\n        __m128i a = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i b = _mm_loadu_si128((__m128i*)&B[i]);\n\n        __m128i a_pos = _mm_cmpgt_epi8(a, _mm_setzero_si128());\n        __m128i b_pos = _mm_cmpgt_epi8(b, _mm_setzero_si128());\n        __m128i a_neg = _mm_cmpgt_epi8(_mm_setzero_si128(), a);\n        __m128i b_neg = _mm_cmpgt_epi8(_mm_setzero_si128(), b);\n\n        __m128i result_pos = _mm_and_si128(a_pos, b_pos);\n        __m128i result_neg = _mm_and_si128(a_neg, b_neg);\n\n        __m128i result = _mm_or_si128(_mm_blendv_epi8(_mm_set1_epi8(1), _mm_set1_epi8(-1), result_neg), \n                                       _mm_blendv_epi8(_mm_set1_epi8(0), _mm_set1_epi8(1), result_pos));\n\n        _mm_storeu_si128((__m128i*)&C[i], result);\n    }\n    for (; i < length; ++i) {\n        C[i] = (A[i] > 0 && B[i] > 0) ? 1 : (A[i] < 0 && B[i] < 0) ? -1 : 0;\n    }\n}\n```"}
{"task_id": "SimdBench_43_AVX", "completion": "```cpp\nvoid tensor_three_valued_logic_simd(const int8_t* A, const int8_t* B, int8_t* C, size_t length) {\n    size_t i = 0;\n    for (; i + 15 < length; i += 16) {\n        __m128i a = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i b = _mm_loadu_si128((__m128i*)&B[i]);\n\n        __m128i a_pos = _mm_cmpgt_epi8(a, _mm_setzero_si128());\n        __m128i b_pos = _mm_cmpgt_epi8(b, _mm_setzero_si128());\n        __m128i a_neg = _mm_cmpgt_epi8(_mm_setzero_si128(), a);\n        __m128i b_neg = _mm_cmpgt_epi8(_mm_setzero_si128(), b);\n\n        __m128i pos_result = _mm_and_si128(a_pos, b_pos);\n        __m128i neg_result = _mm_and_si128(a_neg, b_neg);\n\n        __m128i result = _mm_or_si128(pos_result, _mm_slli_si128(neg_result, 1));\n        result = _mm_or_si128(result, _mm_set1_epi8(0));\n\n        _mm_storeu_si128((__m128i*)&C[i], _mm_blendv_epi8(result, _mm_set1_epi8(1), pos_result));\n        _mm_storeu_si128((__m128i*)&C[i + 8], _mm_blendv_epi8(result, _mm_set1_epi8(-1), neg_result));\n    }\n    for (; i < length; i++) {\n        C[i] = (A[i] > 0 && B[i] > 0) ? 1 : (A[i] < 0 && B[i] < 0) ? -1 : 0;\n    }\n}\n```"}
{"task_id": "SimdBench_43_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid tensor_three_valued_logic_simd(const int8_t* A, const int8_t* B, int8_t* C, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 16; i += 16) {\n        __m128i a = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i b = _mm_loadu_si128((__m128i*)&B[i]);\n\n        __m128i a_pos = _mm_cmpgt_epi8(a, _mm_setzero_si128());\n        __m128i b_pos = _mm_cmpgt_epi8(b, _mm_setzero_si128());\n        __m128i a_neg = _mm_cmpgt_epi8(_mm_setzero_si128(), a);\n        __m128i b_neg = _mm_cmpgt_epi8(_mm_setzero_si128(), b);\n\n        __m128i pos_result = _mm_and_si128(a_pos, b_pos);\n        __m128i neg_result = _mm_and_si128(a_neg, b_neg);\n\n        __m128i result = _mm_or_si128(\n            _mm_blendv_epi8(_mm_set1_epi8(1), _mm_set1_epi8(-1), neg_result),\n            _mm_blendv_epi8(_mm_set1_epi8(0), _mm_set1_epi8(1), pos_result)\n        );\n\n        _mm_storeu_si128((__m128i*)&C[i], result);\n    }\n\n    for (; i < length; ++i) {\n        C[i] = (A[i] > 0 && B[i] > 0) ? 1 : (A[i] < 0 && B[i] < 0) ? -1 : 0;\n    }\n}\n```"}
{"task_id": "SimdBench_43_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid tensor_three_valued_logic_simd(const int8_t* A, const int8_t* B, int8_t* C, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 16; i += 16) {\n        __m128i a = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i b = _mm_loadu_si128((__m128i*)&B[i]);\n\n        __m128i pos_mask = _mm_and_si128(a, b);\n        __m128i neg_mask = _mm_and_si128(_mm_cmpgt_epi8(a, _mm_setzero_si128()), _mm_cmpgt_epi8(b, _mm_setzero_si128()));\n        \n        __m128i result_pos = _mm_cmpeq_epi8(pos_mask, pos_mask);\n        __m128i result_neg = _mm_cmpeq_epi8(neg_mask, neg_mask);\n        \n        __m128i result = _mm_blendv_epi8(_mm_set1_epi8(1), _mm_set1_epi8(-1), result_neg);\n        result = _mm_blendv_epi8(result, _mm_setzero_si128(), _mm_or_si128(result_pos, result_neg));\n\n        _mm_storeu_si128((__m128i*)&C[i], result);\n    }\n    for (; i < length; ++i) {\n        C[i] = (A[i] > 0 && B[i] > 0) ? 1 : (A[i] < 0 && B[i] < 0) ? -1 : 0;\n    }\n}\n```"}
{"task_id": "SimdBench_43_AVX", "completion": "```cpp\nvoid tensor_three_valued_logic_simd(const int8_t* A, const int8_t* B, int8_t* C, size_t length) {\n    size_t i = 0;\n    for (; i + 31 < length; i += 32) {\n        __m256i a = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i b = _mm256_loadu_si256((__m256i*)&B[i]);\n\n        __m256i pos_mask = _mm256_cmpgt_epi8(a, _mm256_setzero_si256());\n        __m256i neg_mask = _mm256_cmpgt_epi8(_mm256_setzero_si256(), a);\n        \n        __m256i b_pos_mask = _mm256_cmpgt_epi8(b, _mm256_setzero_si256());\n        __m256i b_neg_mask = _mm256_cmpgt_epi8(_mm256_setzero_si256(), b);\n\n        __m256i result = _mm256_setzero_si256();\n\n        // Both positive\n        __m256i both_pos = _mm256_and_si256(pos_mask, b_pos_mask);\n        result = _mm256_blendv_epi8(result, _mm256_set1_epi8(1), both_pos);\n\n        // Both negative\n        __m256i both_neg = _mm256_and_si256(neg_mask, b_neg_mask);\n        result = _mm256_blendv_epi8(result, _mm256_set1_epi8(-1), both_neg);\n\n        // Store the result\n        _mm256_storeu_si256((__m256i*)&C[i], result);\n    }\n\n    for (; i < length; i++) {\n        C[i] = (A[i] > 0 && B[i] > 0) ? 1 : (A[i] < 0 && B[i] < 0) ? -1 : 0;\n    }\n}\n```"}
{"task_id": "SimdBench_44_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid tensor_bit_op_simd(const uint16_t* A, const uint16_t* B, uint16_t* C, size_t length) {\n    size_t midpoint = length / 2;\n\n    // Process elements before the midpoint\n    size_t i = 0;\n    for (; i < midpoint / 8 * 8; i += 8) {\n        __m128i a_vec = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i b_vec = _mm_loadu_si128((__m128i*)&B[i]);\n        __m128i result_vec = _mm_xor_si128(a_vec, b_vec);\n        _mm_storeu_si128((__m128i*)&C[i], result_vec);\n    }\n\n    // Handle remaining elements before the midpoint\n    for (; i < midpoint; ++i) {\n        C[i] = A[i] ^ B[i];\n    }\n\n    // Midpoint element\n    if (length % 2 == 0) {\n        C[midpoint] = A[midpoint];\n    }\n\n    // Process elements after the midpoint\n    for (size_t j = midpoint + 1; j < length; ++j) {\n        C[j] = A[j] & B[j];\n    }\n}\n```"}
{"task_id": "SimdBench_44_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid tensor_bit_op_simd(const uint16_t* A, const uint16_t* B, uint16_t* C, size_t length) {\n    size_t midpoint = length / 2;\n    size_t i;\n\n    // Process elements before the midpoint\n    for (i = 0; i < midpoint; i += 8) {\n        __m128i a = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i b = _mm_loadu_si128((__m128i*)&B[i]);\n        __m128i result = _mm_xor_si128(a, b);\n        _mm_storeu_si128((__m128i*)&C[i], result);\n    }\n\n    // Handle the midpoint element\n    if (length % 2 == 0) {\n        C[midpoint] = A[midpoint];\n    }\n\n    // Process elements after the midpoint\n    for (; i < length; i += 8) {\n        __m128i a = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i b = _mm_loadu_si128((__m128i*)&B[i]);\n        __m128i result = _mm_and_si128(a, b);\n        _mm_storeu_si128((__m128i*)&C[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_44_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid tensor_bit_op_simd(const uint16_t* A, const uint16_t* B, uint16_t* C, size_t length) {\n    size_t midpoint = length / 2;\n    size_t i;\n\n    // Process elements before the midpoint\n    for (i = 0; i < midpoint; i += 8) {\n        __m128i a = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i b = _mm_loadu_si128((__m128i*)&B[i]);\n        __m128i result = _mm_xor_si128(a, b);\n        _mm_storeu_si128((__m128i*)&C[i], result);\n    }\n\n    // Handle the midpoint element\n    if (length % 2 == 0) {\n        C[midpoint] = A[midpoint];\n    }\n\n    // Process elements after the midpoint\n    for (; i < length; i += 8) {\n        __m128i a = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i b = _mm_loadu_si128((__m128i*)&B[i]);\n        __m128i result = _mm_and_si128(a, b);\n        _mm_storeu_si128((__m128i*)&C[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_44_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid tensor_bit_op_simd(const uint16_t* A, const uint16_t* B, uint16_t* C, size_t length) {\n    size_t midpoint = length / 2;\n    size_t i;\n\n    // Process elements before the midpoint\n    for (i = 0; i < midpoint; i += 8) {\n        __m128i a = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i b = _mm_loadu_si128((__m128i*)&B[i]);\n        __m128i result = _mm_xor_si128(a, b);\n        _mm_storeu_si128((__m128i*)&C[i], result);\n    }\n\n    // Handle the midpoint element\n    if (length % 2 == 0) {\n        C[midpoint] = A[midpoint];\n    }\n\n    // Process elements after the midpoint\n    for (; i < length; i += 8) {\n        __m128i a = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i b = _mm_loadu_si128((__m128i*)&B[i]);\n        __m128i result = _mm_and_si128(a, b);\n        _mm_storeu_si128((__m128i*)&C[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_44_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid tensor_bit_op_simd(const uint16_t* A, const uint16_t* B, uint16_t* C, size_t length) {\n    size_t midpoint = length / 2;\n    size_t i;\n\n    // Process elements before the midpoint\n    for (i = 0; i < midpoint; i += 8) {\n        __m128i a_vec = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i b_vec = _mm_loadu_si128((__m128i*)&B[i]);\n        __m128i xor_vec = _mm_xor_si128(a_vec, b_vec);\n        _mm_storeu_si128((__m128i*)&C[i], xor_vec);\n    }\n\n    // Handle the midpoint element\n    if (length % 2 == 0) {\n        C[midpoint] = A[midpoint];\n    }\n\n    // Process elements after the midpoint\n    for (; i < length; i += 8) {\n        __m128i a_vec = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i b_vec = _mm_loadu_si128((__m128i*)&B[i]);\n        __m128i and_vec = _mm_and_si128(a_vec, b_vec);\n        _mm_storeu_si128((__m128i*)&C[i], and_vec);\n    }\n}\n```"}
{"task_id": "SimdBench_45_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid tensor_multi_select_simd(const float* A, const float* B, const float* C, const float* D, const bool* cond1, const bool* cond2, float* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t i = 0;\n\n    for (; i + 8 <= total_elements; i += 8) {\n        __m256 a = _mm256_loadu_ps(&A[i]);\n        __m256 b = _mm256_loadu_ps(&B[i]);\n        __m256 c = _mm256_loadu_ps(&C[i]);\n        __m256 d = _mm256_loadu_ps(&D[i]);\n\n        __m256i cond1_mask = _mm256_loadu_si256((__m256i*)&cond1[i]);\n        __m256i cond2_mask = _mm256_loadu_si256((__m256i*)&cond2[i]);\n\n        __m256i cond1_true = _mm256_cmpeq_epi32(cond1_mask, _mm256_set1_epi32(1));\n        __m256i cond2_true = _mm256_cmpeq_epi32(cond2_mask, _mm256_set1_epi32(1));\n\n        __m256i select_a = _mm256_and_si256(cond1_true, cond2_true);\n        __m256i select_b = _mm256_and_si256(cond1_true, _mm256_xor_si256(cond2_true, _mm256_set1_epi32(-1)));\n        __m256i select_c = _mm256_and_si256(_mm256_xor_si256(cond1_true, _mm256_set1_epi32(-1)), cond2_true);\n        __m256i select_d = _mm256_xor_si256(select_a, _mm256_xor_si256(select_b, _mm256_xor_si256(select_c, _mm256_set1_epi32(-1))));\n\n        __m256 result = _mm256_blendv_ps(_mm256_blendv_ps(d, c, _mm256_castsi256_ps(select_c)), \n                                          _mm256_blendv_ps(b, a, _mm256_castsi256_ps(select_a)), \n                                          _mm256_castsi256_ps(select_b));\n\n        _mm256_storeu_ps(&out[i], result);\n    }\n\n    for (; i < total_elements; ++i) {\n        if (cond1[i] && cond2[i]) {\n            out[i] = A[i];\n        } else if (cond1[i] && !cond2[i]) {\n            out[i] = B[i];\n        } else if (!cond1[i] && cond2[i]) {\n            out[i] = C[i];\n        } else {\n            out[i] = D[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_45_AVX", "completion": "```cpp\nvoid tensor_multi_select_simd(const float* A, const float* B, const float* C, const float* D, const bool* cond1, const bool* cond2, float* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t i = 0;\n\n    for (; i <= total_elements - 8; i += 8) {\n        __m256 a = _mm256_loadu_ps(&A[i]);\n        __m256 b = _mm256_loadu_ps(&B[i]);\n        __m256 c = _mm256_loadu_ps(&C[i]);\n        __m256 d = _mm256_loadu_ps(&D[i]);\n\n        __m256i cond1_vec = _mm256_loadu_si256((__m256i*)&cond1[i]);\n        __m256i cond2_vec = _mm256_loadu_si256((__m256i*)&cond2[i]);\n\n        __m256i mask1 = _mm256_cmpeq_epi32(cond1_vec, _mm256_set1_epi32(1));\n        __m256i mask2 = _mm256_cmpeq_epi32(cond2_vec, _mm256_set1_epi32(1));\n\n        __m256i mask_a = _mm256_and_si256(mask1, mask2);\n        __m256i mask_b = _mm256_and_si256(mask1, _mm256_xor_si256(mask2, _mm256_set1_epi32(1)));\n        __m256i mask_c = _mm256_and_si256(_mm256_xor_si256(mask1, _mm256_set1_epi32(1)), mask2);\n        __m256i mask_d = _mm256_xor_si256(mask_a, _mm256_xor_si256(mask_b, _mm256_xor_si256(mask_c, _mm256_set1_epi32(1))));\n\n        __m256 result_a = _mm256_blendv_ps(d, a, _mm256_castsi256_ps(mask_a));\n        __m256 result_b = _mm256_blendv_ps(result_a, b, _mm256_castsi256_ps(mask_b));\n        __m256 result_c = _mm256_blendv_ps(result_b, c, _mm256_castsi256_ps(mask_c));\n\n        _mm256_storeu_ps(&out[i], result_c);\n    }\n\n    for (; i < total_elements; ++i) {\n        out[i] = (cond1[i] && cond2[i]) ? A[i] :\n                  (cond1[i] && !cond2[i]) ? B[i] :\n                  (!cond1[i] && cond2[i]) ? C[i] : D[i];\n    }\n}\n```"}
{"task_id": "SimdBench_45_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid tensor_multi_select_simd(const float* A, const float* B, const float* C, const float* D, const bool* cond1, const bool* cond2, float* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t i = 0;\n\n    for (; i + 8 <= total_elements; i += 8) {\n        __m256 a = _mm256_loadu_ps(&A[i]);\n        __m256 b = _mm256_loadu_ps(&B[i]);\n        __m256 c = _mm256_loadu_ps(&C[i]);\n        __m256 d = _mm256_loadu_ps(&D[i]);\n\n        __m256i cond1_vec = _mm256_loadu_si256((__m256i*)&cond1[i]);\n        __m256i cond2_vec = _mm256_loadu_si256((__m256i*)&cond2[i]);\n\n        __m256i mask1 = _mm256_cmpgt_epi32(cond1_vec, _mm256_setzero_si256());\n        __m256i mask2 = _mm256_cmpgt_epi32(cond2_vec, _mm256_setzero_si256());\n\n        __m256i mask1_mask2 = _mm256_and_si256(mask1, mask2);\n        __m256i mask1_not_mask2 = _mm256_and_si256(mask1, _mm256_xor_si256(mask2, _mm256_set1_epi32(-1)));\n        __m256i not_mask1_mask2 = _mm256_and_si256(_mm256_xor_si256(mask1, _mm256_set1_epi32(-1)), mask2);\n        __m256i not_mask1_not_mask2 = _mm256_and_si256(_mm256_xor_si256(mask1, _mm256_set1_epi32(-1)), _mm256_xor_si256(mask2, _mm256_set1_epi32(-1)));\n\n        __m256 result = _mm256_blendv_ps(_mm256_blendv_ps(d, c, not_mask1_mask2), _mm256_blendv_ps(b, a, mask1_not_mask2), mask1_mask2);\n        \n        _mm256_storeu_ps(&out[i], result);\n    }\n\n    for (; i < total_elements; ++i) {\n        out[i] = (cond1[i] && cond2[i]) ? A[i] :\n                  (cond1[i] && !cond2[i]) ? B[i] :\n                  (!cond1[i] && cond2[i]) ? C[i] : D[i];\n    }\n}\n```"}
{"task_id": "SimdBench_45_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid tensor_multi_select_simd(const float* A, const float* B, const float* C, const float* D, const bool* cond1, const bool* cond2, float* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t i = 0;\n\n    for (; i + 8 <= total_elements; i += 8) {\n        __m256 a = _mm256_loadu_ps(&A[i]);\n        __m256 b = _mm256_loadu_ps(&B[i]);\n        __m256 c = _mm256_loadu_ps(&C[i]);\n        __m256 d = _mm256_loadu_ps(&D[i]);\n\n        __m256i cond1_vec = _mm256_loadu_si256((__m256i*)&cond1[i]);\n        __m256i cond2_vec = _mm256_loadu_si256((__m256i*)&cond2[i]);\n\n        __m256i mask1 = _mm256_cmpgt_epi32(cond1_vec, _mm256_setzero_si256());\n        __m256i mask2 = _mm256_cmpgt_epi32(cond2_vec, _mm256_setzero_si256());\n\n        __m256i mask_a = _mm256_and_si256(mask1, mask2);\n        __m256i mask_b = _mm256_and_si256(mask1, _mm256_xor_si256(mask2, _mm256_set1_epi32(-1)));\n        __m256i mask_c = _mm256_and_si256(_mm256_xor_si256(mask1, _mm256_set1_epi32(-1)), mask2);\n        __m256i mask_d = _mm256_xor_si256(mask_a, _mm256_xor_si256(mask_b, _mm256_xor_si256(mask_c, mask1)));\n\n        __m256 result = _mm256_blendv_ps(_mm256_blendv_ps(d, c, _mm256_castsi256_ps(mask_c)), \n                                          _mm256_blendv_ps(b, a, _mm256_castsi256_ps(mask_a)), \n                                          _mm256_castsi256_ps(mask_b));\n\n        _mm256_storeu_ps(&out[i], result);\n    }\n\n    for (; i < total_elements; ++i) {\n        if (cond1[i] && cond2[i]) {\n            out[i] = A[i];\n        } else if (cond1[i]) {\n            out[i] = B[i];\n        } else if (cond2[i]) {\n            out[i] = C[i];\n        } else {\n            out[i] = D[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_45_AVX", "completion": "```cpp\nvoid tensor_multi_select_simd(const float* A, const float* B, const float* C, const float* D, const bool* cond1, const bool* cond2, float* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t i = 0;\n\n    for (; i + 7 < total_elements; i += 8) {\n        __m256 a = _mm256_loadu_ps(&A[i]);\n        __m256 b = _mm256_loadu_ps(&B[i]);\n        __m256 c = _mm256_loadu_ps(&C[i]);\n        __m256 d = _mm256_loadu_ps(&D[i]);\n\n        __m256i cond1_vec = _mm256_loadu_si256((__m256i*)&cond1[i]);\n        __m256i cond2_vec = _mm256_loadu_si256((__m256i*)&cond2[i]);\n\n        __m256i mask1 = _mm256_cmpeq_epi32(cond1_vec, _mm256_set1_epi32(1));\n        __m256i mask2 = _mm256_cmpeq_epi32(cond2_vec, _mm256_set1_epi32(1));\n\n        __m256i mask_a = _mm256_and_si256(mask1, mask2);\n        __m256i mask_b = _mm256_and_si256(mask1, _mm256_xor_si256(mask2, _mm256_set1_epi32(1)));\n        __m256i mask_c = _mm256_and_si256(_mm256_xor_si256(mask1, _mm256_set1_epi32(1)), mask2);\n        __m256i mask_d = _mm256_xor_si256(mask_a, _mm256_xor_si256(mask_b, _mm256_xor_si256(mask_c, _mm256_set1_epi32(1))));\n\n        __m256 result = _mm256_blendv_ps(\n            _mm256_blendv_ps(d, c, _mm256_castsi256_ps(mask_c)),\n            _mm256_blendv_ps(b, a, _mm256_castsi256_ps(mask_a)),\n            _mm256_castsi256_ps(mask_b)\n        );\n\n        _mm256_storeu_ps(&out[i], result);\n    }\n\n    for (; i < total_elements; ++i) {\n        if (cond1[i] && cond2[i]) {\n            out[i] = A[i];\n        } else if (cond1[i] && !cond2[i]) {\n            out[i] = B[i];\n        } else if (!cond1[i] && cond2[i]) {\n            out[i] = C[i];\n        } else {\n            out[i] = D[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_46_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid tensor_bit_count_simd(const uint32_t* A, uint8_t* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t i;\n\n    for (i = 0; i < total_elements; i += 8) {\n        __m256i data = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i count = _mm256_setzero_si256();\n\n        // Count bits for each byte in the 32-bit integers\n        for (int j = 0; j < 4; j++) {\n            __m256i byte_mask = _mm256_set1_epi8(0x01);\n            __m256i byte_data = _mm256_srli_epi32(data, j * 8);\n            count = _mm256_add_epi8(count, _mm256_and_si256(byte_data, byte_mask));\n            count = _mm256_add_epi8(count, _mm256_srli_epi16(count, 1));\n        }\n\n        // Store the result\n        _mm256_storeu_si256((__m256i*)&out[i], count);\n    }\n}\n```"}
{"task_id": "SimdBench_46_AVX", "completion": "```cpp\nvoid tensor_bit_count_simd(const uint32_t* A, uint8_t* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t i = 0;\n\n    for (; i <= total_elements - 8; i += 8) {\n        __m256i data = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i count = _mm256_setzero_si256();\n\n        // Count bits for each byte in the 32-bit integers\n        for (int j = 0; j < 4; j++) {\n            __m256i byte_mask = _mm256_set1_epi32(0xFF);\n            __m256i byte_data = _mm256_and_si256(data, byte_mask);\n            count = _mm256_add_epi32(count, _mm256_popcnt_epi32(byte_data));\n            data = _mm256_srli_epi32(data, 8);\n        }\n\n        // Horizontal sum of counts\n        count = _mm256_hadd_epi32(count, count);\n        count = _mm256_hadd_epi32(count, count);\n        count = _mm256_permute2x128_si256(count, count, 1);\n        count = _mm256_add_epi32(count, _mm256_permute2x128_si256(count, count, 0));\n\n        // Store the result\n        _mm_storeu_si32((uint32_t*)&out[i], _mm256_extract_epi32(count, 0));\n        out[i + 1] = _mm256_extract_epi32(count, 1);\n        out[i + 2] = _mm256_extract_epi32(count, 2);\n        out[i + 3] = _mm256_extract_epi32(count, 3);\n        out[i + 4] = _mm256_extract_epi32(count, 4);\n        out[i + 5] = _mm256_extract_epi32(count, 5);\n        out[i + 6] = _mm256_extract_epi32(count, 6);\n        out[i + 7] = _mm256_extract_epi32(count, 7);\n    }\n\n    for (; i < total_elements; ++i) {\n        out[i] = __builtin_popcount(A[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_46_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid tensor_bit_count_simd(const uint32_t* A, uint8_t* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t i = 0;\n\n    for (; i <= total_elements - 8; i += 8) {\n        __m256i data = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i count = _mm256_setzero_si256();\n\n        for (int j = 0; j < 32; j++) {\n            __m256i mask = _mm256_set1_epi32(1 << j);\n            __m256i bits = _mm256_and_si256(data, mask);\n            count = _mm256_add_epi32(count, _mm256_srli_epi32(bits, j));\n        }\n\n        count = _mm256_hadd_epi32(count, count);\n        count = _mm256_hadd_epi32(count, count);\n        count = _mm256_packus_epi32(count, count);\n        count = _mm256_permute4x64_epi64(count, _MM_SHUFFLE(2, 3, 0, 1));\n        \n        _mm_storel_epi64((__m128i*)&out[i], _mm256_castsi256_si128(count));\n        out[i + 4] = _mm_extract_epi8(count, 4);\n    }\n\n    for (; i < total_elements; i++) {\n        uint32_t value = A[i];\n        out[i] = __builtin_popcount(value);\n    }\n}\n```"}
{"task_id": "SimdBench_46_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid tensor_bit_count_simd(const uint32_t* A, uint8_t* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t i = 0;\n\n    for (; i + 8 <= total_elements; i += 8) {\n        __m256i data = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i count = _mm256_setzero_si256();\n\n        for (int j = 0; j < 32; j++) {\n            __m256i mask = _mm256_set1_epi32(1 << j);\n            __m256i bits = _mm256_and_si256(data, mask);\n            count = _mm256_add_epi32(count, _mm256_srli_epi32(bits, j));\n        }\n\n        count = _mm256_hadd_epi32(count, count);\n        count = _mm256_hadd_epi32(count, count);\n        count = _mm256_packus_epi32(count, count);\n        count = _mm256_permute4x64_epi64(count, _MM_SHUFFLE(0, 0, 0, 0));\n        \n        _mm_storeu_si128((__m128i*)&out[i], _mm256_castsi256_si128(count));\n    }\n\n    for (; i < total_elements; i++) {\n        uint32_t value = A[i];\n        out[i] = __builtin_popcount(value);\n    }\n}\n```"}
{"task_id": "SimdBench_46_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid tensor_bit_count_simd(const uint32_t* A, uint8_t* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t i;\n\n    for (i = 0; i < total_elements; i += 8) {\n        __m256i data = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i count = _mm256_setzero_si256();\n\n        count = _mm256_add_epi32(count, _mm256_and_si256(data, _mm256_set1_epi32(1)));\n        data = _mm256_srli_epi32(data, 1);\n        count = _mm256_add_epi32(count, _mm256_and_si256(data, _mm256_set1_epi32(1)));\n        data = _mm256_srli_epi32(data, 1);\n        count = _mm256_add_epi32(count, _mm256_and_si256(data, _mm256_set1_epi32(1)));\n        data = _mm256_srli_epi32(data, 1);\n        count = _mm256_add_epi32(count, _mm256_and_si256(data, _mm256_set1_epi32(1)));\n        data = _mm256_srli_epi32(data, 1);\n        count = _mm256_add_epi32(count, _mm256_and_si256(data, _mm256_set1_epi32(1)));\n        data = _mm256_srli_epi32(data, 1);\n        count = _mm256_add_epi32(count, _mm256_and_si256(data, _mm256_set1_epi32(1)));\n        data = _mm256_srli_epi32(data, 1);\n        count = _mm256_add_epi32(count, _mm256_and_si256(data, _mm256_set1_epi32(1)));\n        data = _mm256_srli_epi32(data, 1);\n        count = _mm256_add_epi32(count, _mm256_and_si256(data, _mm256_set1_epi32(1)));\n\n        // Horizontal sum of counts\n        count = _mm256_hadd_epi32(count, count);\n        count = _mm256_hadd_epi32(count, count);\n        count = _mm256_permute2x128_si256(count, count, 1);\n        count = _mm256_add_epi32(count, _mm256_permute2x128_si256(count, count, 0));\n\n        // Store the result\n        uint32_t result = _mm256_extract_epi32(count, 0);\n        out[i] = (uint8_t)result;\n    }\n}\n```"}
{"task_id": "SimdBench_47_AVX", "completion": "```cpp\nvoid matrix_conditional_abs_simd(const int* A, int* B, size_t rows, size_t cols) {\n    size_t total_elements = rows * cols;\n    size_t i;\n\n    for (i = 0; i <= total_elements - 8; i += 8) {\n        __m256i a = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i mod = _mm256_rem_epi32(a, _mm256_set1_epi32(3));\n        __m256i mask = _mm256_cmpeq_epi32(mod, _mm256_setzero_si256());\n        __m256i abs_a = _mm256_abs_epi32(a);\n        __m256i result = _mm256_blendv_epi8(a, abs_a, mask);\n        _mm256_storeu_si256((__m256i*)&B[i], result);\n    }\n\n    for (; i < total_elements; ++i) {\n        B[i] = (A[i] % 3 == 0) ? abs(A[i]) : A[i];\n    }\n}\n```"}
{"task_id": "SimdBench_47_AVX", "completion": "```cpp\nvoid matrix_conditional_abs_simd(const int* A, int* B, size_t rows, size_t cols) {\n    size_t total_elements = rows * cols;\n    size_t i = 0;\n\n    __m256i three = _mm256_set1_epi32(3);\n    __m256i zero = _mm256_setzero_si256();\n\n    for (; i <= total_elements - 8; i += 8) {\n        __m256i a = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i mod = _mm256_rem_epi32(a, three);\n        __m256i mask = _mm256_cmpeq_epi32(mod, zero);\n        __m256i abs_a = _mm256_abs_epi32(a);\n        __m256i result = _mm256_blendv_epi8(a, abs_a, mask);\n        _mm256_storeu_si256((__m256i*)&B[i], result);\n    }\n\n    for (; i < total_elements; i++) {\n        B[i] = (A[i] % 3 == 0) ? abs(A[i]) : A[i];\n    }\n}\n```"}
{"task_id": "SimdBench_47_AVX", "completion": "```cpp\nvoid matrix_conditional_abs_simd(const int* A, int* B, size_t rows, size_t cols) {\n    size_t total_elements = rows * cols;\n    size_t i = 0;\n\n    __m256i three = _mm256_set1_epi32(3);\n    for (; i <= total_elements - 8; i += 8) {\n        __m256i vec_a = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i mod = _mm256_rem_epi32(vec_a, three);\n        __m256i mask = _mm256_cmpeq_epi32(mod, _mm256_setzero_si256());\n        __m256i abs_a = _mm256_abs_epi32(vec_a);\n        __m256i result = _mm256_blendv_epi8(vec_a, abs_a, mask);\n        _mm256_storeu_si256((__m256i*)&B[i], result);\n    }\n\n    for (; i < total_elements; ++i) {\n        if (A[i] % 3 == 0) {\n            B[i] = abs(A[i]);\n        } else {\n            B[i] = A[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_47_AVX", "completion": "```cpp\nvoid matrix_conditional_abs_simd(const int* A, int* B, size_t rows, size_t cols) {\n    size_t total_elements = rows * cols;\n    size_t i = 0;\n\n    __m256i three = _mm256_set1_epi32(3);\n    for (; i <= total_elements - 8; i += 8) {\n        __m256i a = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i mod = _mm256_rem_epi32(a, three);\n        __m256i mask = _mm256_cmpeq_epi32(mod, _mm256_setzero_si256());\n        __m256i abs_a = _mm256_abs_epi32(a);\n        __m256i result = _mm256_blendv_epi8(a, abs_a, mask);\n        _mm256_storeu_si256((__m256i*)&B[i], result);\n    }\n\n    for (; i < total_elements; ++i) {\n        B[i] = (A[i] % 3 == 0) ? abs(A[i]) : A[i];\n    }\n}\n```"}
{"task_id": "SimdBench_47_AVX", "completion": "```cpp\nvoid matrix_conditional_abs_simd(const int* A, int* B, size_t rows, size_t cols) {\n    size_t total_elements = rows * cols;\n    size_t i = 0;\n\n    // Process 8 elements at a time using AVX2\n    for (; i + 8 <= total_elements; i += 8) {\n        __m256i a = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i mod = _mm256_rem_epi32(a, _mm256_set1_epi32(3));\n        __m256i mask = _mm256_cmpeq_epi32(mod, _mm256_setzero_si256());\n        __m256i abs_a = _mm256_abs_epi32(a);\n        __m256i result = _mm256_blendv_epi8(a, abs_a, mask);\n        _mm256_storeu_si256((__m256i*)&B[i], result);\n    }\n\n    // Handle remaining elements\n    for (; i < total_elements; i++) {\n        B[i] = (A[i] % 3 == 0) ? abs(A[i]) : A[i];\n    }\n}\n```"}
{"task_id": "SimdBench_48_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid matrix_conditional_bit_rotate_simd(const uint32_t* src, uint32_t* dst, uint8_t rotate_bits, size_t length) {\n    __m256i rotate_mask = _mm256_set1_epi32(0xF); // Mask for checking low 4 bits\n    __m256i rotate_amount = _mm256_set1_epi32(rotate_bits);\n    __m256i src_vec, rotated_vec, negated_vec, condition_mask;\n\n    for (size_t i = 0; i < length; i += 8) {\n        // Load 8 elements from src\n        src_vec = _mm256_loadu_si256((__m256i*)&src[i]);\n\n        // Check if low 4 bits are all 1\n        condition_mask = _mm256_and_si256(src_vec, rotate_mask);\n        condition_mask = _mm256_cmpeq_epi32(condition_mask, rotate_mask);\n\n        // Perform rotation\n        rotated_vec = _mm256_or_si256(\n            _mm256_srlv_epi32(src_vec, rotate_amount),\n            _mm256_sllv_epi32(src_vec, _mm256_sub_epi32(_mm256_set1_epi32(32), rotate_amount))\n        );\n\n        // Negate the source vector\n        negated_vec = _mm256_xor_si256(src_vec, _mm256_set1_epi32(0xFFFFFFFF));\n\n        // Select between rotated and negated based on condition\n        __m256i result = _mm256_blendv_epi8(negated_vec, rotated_vec, condition_mask);\n\n        // Store the result in dst\n        _mm256_storeu_si256((__m256i*)&dst[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_48_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid matrix_conditional_bit_rotate_simd(const uint32_t* src, uint32_t* dst, uint8_t rotate_bits, size_t length) {\n    __m256i rotate_mask = _mm256_set1_epi32(0xF); // Mask for low 4 bits\n    __m256i rotate_amount = _mm256_set1_epi32(rotate_bits);\n    \n    for (size_t i = 0; i < length; i += 8) {\n        __m256i src_vec = _mm256_loadu_si256((__m256i*)&src[i]);\n        __m256i low_bits = _mm256_and_si256(src_vec, rotate_mask);\n        __m256i all_ones = _mm256_cmpeq_epi32(low_bits, rotate_mask);\n        \n        // Rotate right\n        __m256i rotated = _mm256_or_si256(\n            _mm256_srli_epi32(src_vec, rotate_amount),\n            _mm256_slli_epi32(src_vec, _mm256_sub_epi32(_mm256_set1_epi32(32), rotate_amount))\n        );\n\n        // Conditional selection\n        __m256i negated = _mm256_xor_si256(src_vec, _mm256_set1_epi32(0xFFFFFFFF));\n        __m256i result = _mm256_blendv_epi8(negated, rotated, all_ones);\n\n        _mm256_storeu_si256((__m256i*)&dst[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_48_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid matrix_conditional_bit_rotate_simd(const uint32_t* src, uint32_t* dst, uint8_t rotate_bits, size_t length) {\n    __m256i rotate_mask = _mm256_set1_epi32(0x0F); // Mask for low 4 bits\n    __m256i rotate_amount = _mm256_set1_epi32(rotate_bits);\n    __m256i all_ones = _mm256_set1_epi32(0xFFFFFFFF);\n    \n    size_t i = 0;\n    for (; i <= length - 8; i += 8) {\n        __m256i src_vec = _mm256_loadu_si256((__m256i*)&src[i]);\n        __m256i low_bits = _mm256_and_si256(src_vec, rotate_mask);\n        \n        // Check if low 4 bits are all 1\n        __m256i condition = _mm256_cmpeq_epi32(low_bits, rotate_mask);\n        \n        // Perform rotation\n        __m256i rotated = _mm256_or_si256(\n            _mm256_srlv_epi32(src_vec, rotate_amount), \n            _mm256_sllv_epi32(src_vec, _mm256_sub_epi32(_mm256_set1_epi32(32), rotate_amount))\n        );\n        \n        // Negate src_vec\n        __m256i negated = _mm256_xor_si256(src_vec, all_ones);\n        \n        // Select based on condition\n        __m256i result = _mm256_blendv_epi8(negated, rotated, condition);\n        \n        _mm256_storeu_si256((__m256i*)&dst[i], result);\n    }\n    \n    // Handle remaining elements\n    for (; i < length; ++i) {\n        if ((src[i] & 0x0F) == 0x0F) {\n            dst[i] = (src[i] >> rotate_bits) | (src[i] << (32 - rotate_bits));\n        } else {\n            dst[i] = ~src[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_48_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid matrix_conditional_bit_rotate_simd(const uint32_t* src, uint32_t* dst, uint8_t rotate_bits, size_t length) {\n    __m256i rotate_mask = _mm256_set1_epi32(0xF); // Mask for checking low 4 bits\n    __m256i rotate_amount = _mm256_set1_epi32(rotate_bits);\n    __m256i src_vec, dst_vec, condition_mask, rotated_vec;\n\n    for (size_t i = 0; i < length; i += 8) {\n        // Load 8 elements from src\n        src_vec = _mm256_loadu_si256((__m256i*)&src[i]);\n\n        // Check if the low 4 bits are all 1\n        condition_mask = _mm256_and_si256(src_vec, rotate_mask);\n        condition_mask = _mm256_cmpeq_epi32(condition_mask, rotate_mask);\n\n        // Rotate src_vec by rotate_bits if condition is true\n        rotated_vec = _mm256_or_si256(\n            _mm256_srli_epi32(src_vec, rotate_amount),\n            _mm256_slli_epi32(src_vec, 32 - rotate_amount)\n        );\n\n        // Select between rotated and negated values based on condition\n        dst_vec = _mm256_blendv_epi8(_mm256_xor_si256(src_vec, _mm256_set1_epi32(0xFFFFFFFF)), rotated_vec, condition_mask);\n\n        // Store the result in dst\n        _mm256_storeu_si256((__m256i*)&dst[i], dst_vec);\n    }\n}\n```"}
{"task_id": "SimdBench_48_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid matrix_conditional_bit_rotate_simd(const uint32_t* src, uint32_t* dst, uint8_t rotate_bits, size_t length) {\n    __m256i rotate_mask = _mm256_set1_epi32(0x0F); // Mask for low 4 bits\n    __m256i rotate_amount = _mm256_set1_epi32(rotate_bits);\n    __m256i all_ones = _mm256_set1_epi32(0xFFFFFFFF);\n    \n    for (size_t i = 0; i < length; i += 8) {\n        __m256i src_vec = _mm256_loadu_si256((__m256i*)&src[i]);\n        __m256i low_bits = _mm256_and_si256(src_vec, rotate_mask);\n        __m256i condition = _mm256_cmpeq_epi32(low_bits, rotate_mask);\n        \n        // Rotate right by rotate_bits\n        __m256i rotated = _mm256_or_si256(\n            _mm256_srli_epi32(src_vec, rotate_amount),\n            _mm256_slli_epi32(src_vec, 32 - rotate_amount)\n        );\n\n        // Negate src_vec\n        __m256i negated = _mm256_xor_si256(src_vec, all_ones);\n        \n        // Select between rotated and negated based on condition\n        __m256i result = _mm256_blendv_epi8(negated, rotated, condition);\n        \n        _mm256_storeu_si256((__m256i*)&dst[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_49_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid tensor_ternary_compare_simd(const float* A, const float* B, int8_t* out, float epsilon, size_t length) {\n    __m256 epsilon_vec = _mm256_set1_ps(fabsf(epsilon));\n    size_t i;\n\n    for (i = 0; i + 8 <= length; i += 8) {\n        __m256 a_vec = _mm256_loadu_ps(&A[i]);\n        __m256 b_vec = _mm256_loadu_ps(&B[i]);\n        __m256 diff_vec = _mm256_sub_ps(a_vec, b_vec);\n        \n        __m256 abs_diff_vec = _mm256_andnot_ps(_mm256_set1_ps(-0.0f), diff_vec);\n        __m256 greater_vec = _mm256_cmp_ps(diff_vec, epsilon_vec, _CMP_GT_OS);\n        __m256 less_vec = _mm256_cmp_ps(diff_vec, _mm256_neg_ps(epsilon_vec), _CMP_LT_OS);\n        \n        __m256i result_vec = _mm256_setzero_si256();\n        result_vec = _mm256_blendv_epi8(result_vec, _mm256_set1_epi8(1), _mm256_castps_si256(greater_vec));\n        result_vec = _mm256_blendv_epi8(result_vec, _mm256_set1_epi8(-1), _mm256_castps_si256(less_vec));\n        \n        __m256i zero_vec = _mm256_set1_epi8(0);\n        result_vec = _mm256_blendv_epi8(result_vec, zero_vec, _mm256_castps_si256(_mm256_cmp_ps(abs_diff_vec, epsilon_vec, _CMP_LE_OS)));\n        \n        _mm256_storeu_si256((__m256i*)&out[i], result_vec);\n    }\n\n    for (; i < length; i++) {\n        float diff = A[i] - B[i];\n        if (diff > fabsf(epsilon)) {\n            out[i] = 1;\n        } else if (diff < -fabsf(epsilon)) {\n            out[i] = -1;\n        } else {\n            out[i] = 0;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_49_AVX", "completion": "```cpp\nvoid tensor_ternary_compare_simd(const float* A, const float* B, int8_t* out, float epsilon, size_t length) {\n    __m256 epsilon_vec = _mm256_set1_ps(fabsf(epsilon));\n    size_t i;\n\n    for (i = 0; i + 8 <= length; i += 8) {\n        __m256 a_vec = _mm256_loadu_ps(&A[i]);\n        __m256 b_vec = _mm256_loadu_ps(&B[i]);\n        __m256 diff_vec = _mm256_sub_ps(a_vec, b_vec);\n        \n        __m256 abs_diff_vec = _mm256_andnot_ps(_mm256_set1_ps(-0.0f), diff_vec);\n        __m256 greater_vec = _mm256_cmp_ps(abs_diff_vec, epsilon_vec, _CMP_GT_OQ);\n        __m256 less_vec = _mm256_cmp_ps(abs_diff_vec, _mm256_neg_ps(epsilon_vec), _CMP_LT_OQ);\n        \n        __m256i result_vec = _mm256_setzero_si256();\n        result_vec = _mm256_blendv_epi8(result_vec, _mm256_set1_epi8(1), _mm256_castps_si256(greater_vec));\n        result_vec = _mm256_blendv_epi8(result_vec, _mm256_set1_epi8(-1), _mm256_castps_si256(less_vec));\n        \n        _mm256_storeu_si256((__m256i*)&out[i], result_vec);\n    }\n\n    for (; i < length; i++) {\n        float diff = A[i] - B[i];\n        if (diff > fabsf(epsilon)) {\n            out[i] = 1;\n        } else if (diff < -fabsf(epsilon)) {\n            out[i] = -1;\n        } else {\n            out[i] = 0;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_49_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid tensor_ternary_compare_simd(const float* A, const float* B, int8_t* out, float epsilon, size_t length) {\n    __m256 eps = _mm256_set1_ps(fabsf(epsilon));\n    size_t i = 0;\n\n    for (; i + 8 <= length; i += 8) {\n        __m256 a = _mm256_loadu_ps(&A[i]);\n        __m256 b = _mm256_loadu_ps(&B[i]);\n        __m256 diff = _mm256_sub_ps(a, b);\n        __m256 abs_diff = _mm256_abs_ps(diff);\n\n        __m256 cmp_gt = _mm256_cmp_ps(diff, eps, _CMP_GT_OQ);\n        __m256 cmp_lt = _mm256_cmp_ps(diff, _mm256_neg_ps(eps), _CMP_LT_OQ);\n\n        __m256i result = _mm256_setzero_si256();\n        result = _mm256_blendv_epi8(result, _mm256_set1_epi8(1), _mm256_castps_si256(cmp_gt));\n        result = _mm256_blendv_epi8(result, _mm256_set1_epi8(-1), _mm256_castps_si256(cmp_lt));\n        result = _mm256_blendv_epi8(result, _mm256_set1_epi8(0), _mm256_castps_si256(_mm256_andnot_ps(cmp_gt, cmp_lt)));\n\n        _mm256_storeu_si256((__m256i*)&out[i], result);\n    }\n\n    for (; i < length; i++) {\n        float diff = A[i] - B[i];\n        if (diff > fabsf(epsilon)) {\n            out[i] = 1;\n        } else if (diff < -fabsf(epsilon)) {\n            out[i] = -1;\n        } else {\n            out[i] = 0;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_49_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid tensor_ternary_compare_simd(const float* A, const float* B, int8_t* out, float epsilon, size_t length) {\n    __m256 epsilon_vec = _mm256_set1_ps(fabsf(epsilon));\n    \n    size_t i;\n    for (i = 0; i + 8 <= length; i += 8) {\n        __m256 a_vec = _mm256_loadu_ps(&A[i]);\n        __m256 b_vec = _mm256_loadu_ps(&B[i]);\n        \n        __m256 diff_vec = _mm256_sub_ps(a_vec, b_vec);\n        __m256 abs_diff_vec = _mm256_abs_ps(diff_vec);\n        \n        __m256 cmp_gt_vec = _mm256_cmp_ps(diff_vec, epsilon_vec, _CMP_GT_OS);\n        __m256 cmp_lt_vec = _mm256_cmp_ps(diff_vec, _mm256_neg_ps(epsilon_vec), _CMP_LT_OS);\n        \n        __m256i result_vec = _mm256_setzero_si256();\n        result_vec = _mm256_blendv_epi8(result_vec, _mm256_set1_epi8(1), _mm256_castps_si256(cmp_gt_vec));\n        result_vec = _mm256_blendv_epi8(result_vec, _mm256_set1_epi8(-1), _mm256_castps_si256(cmp_lt_vec));\n        \n        _mm256_storeu_si256((__m256i*)&out[i], result_vec);\n    }\n    \n    for (; i < length; i++) {\n        float diff = A[i] - B[i];\n        if (diff > fabsf(epsilon)) {\n            out[i] = 1;\n        } else if (diff < -fabsf(epsilon)) {\n            out[i] = -1;\n        } else {\n            out[i] = 0;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_49_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid tensor_ternary_compare_simd(const float* A, const float* B, int8_t* out, float epsilon, size_t length) {\n    __m256 epsilon_vec = _mm256_set1_ps(fabsf(epsilon));\n    size_t i;\n\n    for (i = 0; i + 8 <= length; i += 8) {\n        __m256 a_vec = _mm256_loadu_ps(&A[i]);\n        __m256 b_vec = _mm256_loadu_ps(&B[i]);\n        __m256 diff_vec = _mm256_sub_ps(a_vec, b_vec);\n        \n        __m256 abs_diff_vec = _mm256_andnot_ps(_mm256_set1_ps(-0.0f), diff_vec);\n        __m256 greater_vec = _mm256_cmp_ps(diff_vec, epsilon_vec, _CMP_GT_OS);\n        __m256 less_vec = _mm256_cmp_ps(diff_vec, _mm256_neg_ps(epsilon_vec), _CMP_LT_OS);\n        \n        __m256i result_vec = _mm256_setzero_si256();\n        result_vec = _mm256_blendv_epi8(result_vec, _mm256_set1_epi8(1), _mm256_castps_si256(greater_vec));\n        result_vec = _mm256_blendv_epi8(result_vec, _mm256_set1_epi8(-1), _mm256_castps_si256(less_vec));\n        \n        _mm256_storeu_si256((__m256i*)&out[i], result_vec);\n    }\n\n    for (; i < length; ++i) {\n        float diff = A[i] - B[i];\n        if (diff > fabsf(epsilon)) {\n            out[i] = 1;\n        } else if (diff < -fabsf(epsilon)) {\n            out[i] = -1;\n        } else {\n            out[i] = 0;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_50_AVX", "completion": "```cpp\nvoid float_to_int_saturate_simd(const float* A, int32_t* B, size_t size) {\n    __m256 max_val = _mm256_set1_ps((float)INT32_MAX);\n    __m256 min_val = _mm256_set1_ps((float)INT32_MIN);\n    \n    size_t i;\n    for (i = 0; i + 8 <= size; i += 8) {\n        __m256 vec = _mm256_loadu_ps(&A[i]);\n        vec = _mm256_min_ps(vec, max_val);\n        vec = _mm256_max_ps(vec, min_val);\n        __m256i result = _mm256_cvtps_epi32(vec);\n        _mm256_storeu_si256((__m256i*)&B[i], result);\n    }\n    \n    for (; i < size; i++) {\n        float value = A[i];\n        if (value > INT32_MAX) {\n            B[i] = INT32_MAX;\n        } else if (value < INT32_MIN) {\n            B[i] = INT32_MIN;\n        } else {\n            B[i] = (int32_t)value;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_50_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <limits.h>\n\nvoid float_to_int_saturate_simd(const float* A, int32_t* B, size_t size) {\n    size_t i = 0;\n    __m256 max_val = _mm256_set1_ps(INT32_MAX);\n    __m256 min_val = _mm256_set1_ps(INT32_MIN);\n    \n    for (; i <= size - 8; i += 8) {\n        __m256 vec = _mm256_loadu_ps(&A[i]);\n        vec = _mm256_min_ps(vec, max_val);\n        vec = _mm256_max_ps(vec, min_val);\n        __m256i int_vec = _mm256_cvtps_epi32(vec);\n        _mm256_storeu_si256((__m256i*)&B[i], int_vec);\n    }\n    \n    for (; i < size; ++i) {\n        float value = A[i];\n        if (value > INT32_MAX) {\n            B[i] = INT32_MAX;\n        } else if (value < INT32_MIN) {\n            B[i] = INT32_MIN;\n        } else {\n            B[i] = static_cast<int32_t>(value);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_50_AVX", "completion": "```cpp\nvoid float_to_int_saturate_simd(const float* A, int32_t* B, size_t size) {\n    __m256 max_float = _mm256_set1_ps((float)INT32_MAX);\n    __m256 min_float = _mm256_set1_ps((float)INT32_MIN);\n    __m256i max_int = _mm256_set1_epi32(INT32_MAX);\n    __m256i min_int = _mm256_set1_epi32(INT32_MIN);\n\n    size_t i;\n    for (i = 0; i + 8 <= size; i += 8) {\n        __m256 vec = _mm256_loadu_ps(&A[i]);\n        __m256i result = _mm256_cvtps_epi32(vec);\n\n        // Compare and saturate\n        __m256 mask_max = _mm256_cmp_ps(vec, max_float, _CMP_GT_OQ);\n        __m256 mask_min = _mm256_cmp_ps(vec, min_float, _CMP_LT_OQ);\n        \n        result = _mm256_blendv_epi8(result, max_int, _mm256_castps_si256(mask_max));\n        result = _mm256_blendv_epi8(result, min_int, _mm256_castps_si256(mask_min));\n\n        _mm256_storeu_si256((__m256i*)&B[i], result);\n    }\n\n    for (; i < size; i++) {\n        float value = A[i];\n        if (value > INT32_MAX) {\n            B[i] = INT32_MAX;\n        } else if (value < INT32_MIN) {\n            B[i] = INT32_MIN;\n        } else {\n            B[i] = (int32_t)value;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_50_AVX", "completion": "```cpp\nvoid float_to_int_saturate_simd(const float* A, int32_t* B, size_t size) {\n    __m256 max_val = _mm256_set1_ps(static_cast<float>(INT32_MAX));\n    __m256 min_val = _mm256_set1_ps(static_cast<float>(INT32_MIN));\n    \n    size_t i;\n    for (i = 0; i <= size - 8; i += 8) {\n        __m256 vec = _mm256_loadu_ps(&A[i]);\n        vec = _mm256_min_ps(vec, max_val);\n        vec = _mm256_max_ps(vec, min_val);\n        __m256i result = _mm256_cvtps_epi32(vec);\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(&B[i]), result);\n    }\n    \n    for (; i < size; ++i) {\n        float value = A[i];\n        if (value > INT32_MAX) {\n            B[i] = INT32_MAX;\n        } else if (value < INT32_MIN) {\n            B[i] = INT32_MIN;\n        } else {\n            B[i] = static_cast<int32_t>(value);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_50_AVX", "completion": "```cpp\nvoid float_to_int_saturate_simd(const float* A, int32_t* B, size_t size) {\n    __m256 max_val = _mm256_set1_ps((float)INT32_MAX);\n    __m256 min_val = _mm256_set1_ps((float)INT32_MIN);\n    \n    size_t i;\n    for (i = 0; i + 8 <= size; i += 8) {\n        __m256 vec = _mm256_loadu_ps(&A[i]);\n        vec = _mm256_min_ps(vec, max_val);\n        vec = _mm256_max_ps(vec, min_val);\n        __m256i result = _mm256_cvtps_epi32(vec);\n        _mm256_storeu_si256((__m256i*)&B[i], result);\n    }\n    \n    for (; i < size; i++) {\n        float value = A[i];\n        if (value > INT32_MAX) {\n            B[i] = INT32_MAX;\n        } else if (value < INT32_MIN) {\n            B[i] = INT32_MIN;\n        } else {\n            B[i] = (int32_t)value;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_51_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid int_to_float_scaled_simd(const int32_t* A, int8_t scale, float* B, size_t size) {\n    __m256i scale_vec = _mm256_set1_epi32(scale);\n    size_t i;\n\n    for (i = 0; i <= size - 8; i += 8) {\n        __m256i a_vec = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256 a_float = _mm256_cvtepi32_ps(a_vec);\n        __m256 scale_float = _mm256_set1_ps((float)scale);\n        __m256 result = _mm256_mul_ps(a_float, scale_float);\n        _mm256_storeu_ps(&B[i], result);\n    }\n\n    for (; i < size; i++) {\n        B[i] = (float)(A[i] * scale);\n    }\n}\n```"}
{"task_id": "SimdBench_51_AVX", "completion": "```cpp\nvoid int_to_float_scaled_simd(const int32_t* A, int8_t scale, float* B, size_t size) {\n    __m256i scale_vec = _mm256_set1_epi32(scale);\n    size_t i;\n\n    for (i = 0; i <= size - 8; i += 8) {\n        __m256i a_vec = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i scaled_vec = _mm256_mullo_epi32(a_vec, scale_vec);\n        __m256 float_vec = _mm256_cvtepi32_ps(scaled_vec);\n        _mm256_storeu_ps(&B[i], float_vec);\n    }\n\n    for (; i < size; i++) {\n        B[i] = (float)(A[i] * scale);\n    }\n}\n```"}
{"task_id": "SimdBench_51_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid int_to_float_scaled_simd(const int32_t* A, int8_t scale, float* B, size_t size) {\n    __m256i scale_vec = _mm256_set1_epi32(scale);\n    size_t i;\n\n    for (i = 0; i <= size - 8; i += 8) {\n        __m256i a_vec = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256 a_float = _mm256_cvtepi32_ps(a_vec);\n        __m256 scale_float = _mm256_set1_ps((float)scale);\n        __m256 result = _mm256_mul_ps(a_float, scale_float);\n        _mm256_storeu_ps(&B[i], result);\n    }\n\n    for (; i < size; i++) {\n        B[i] = (float)(A[i] * scale);\n    }\n}\n```"}
{"task_id": "SimdBench_51_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid int_to_float_scaled_simd(const int32_t* A, int8_t scale, float* B, size_t size) {\n    __m256i scale_vec = _mm256_set1_epi32(scale);\n    size_t i;\n\n    for (i = 0; i <= size - 8; i += 8) {\n        __m256i a_vec = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i scaled_vec = _mm256_mullo_epi32(a_vec, scale_vec);\n        __m256 float_vec = _mm256_cvtepi32_ps(scaled_vec);\n        _mm256_storeu_ps(&B[i], float_vec);\n    }\n\n    for (; i < size; i++) {\n        B[i] = (float)(A[i] * scale);\n    }\n}\n```"}
{"task_id": "SimdBench_51_AVX", "completion": "```cpp\nvoid int_to_float_scaled_simd(const int32_t* A, int8_t scale, float* B, size_t size) {\n    __m256i scale_vec = _mm256_set1_epi32(scale);\n    size_t i;\n\n    for (i = 0; i <= size - 8; i += 8) {\n        __m256i a_vec = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i scaled_vec = _mm256_mullo_epi32(a_vec, scale_vec);\n        __m256 float_vec = _mm256_cvtepi32_ps(scaled_vec);\n        _mm256_storeu_ps(&B[i], float_vec);\n    }\n\n    for (; i < size; i++) {\n        B[i] = (float)(A[i] * scale);\n    }\n}\n```"}
{"task_id": "SimdBench_52_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid float_div_round_simd(const float* A, const float* B, int32_t* C, size_t size) {\n    size_t i;\n    for (i = 0; i + 8 <= size; i += 8) {\n        __m256 a = _mm256_loadu_ps(&A[i]);\n        __m256 b = _mm256_loadu_ps(&B[i]);\n        __m256 result = _mm256_div_ps(a, b);\n        __m256 rounded = _mm256_round_ps(result, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n        _mm256_storeu_si256((__m256i*)&C[i], _mm256_cvtps_epi32(rounded));\n    }\n    for (; i < size; i++) {\n        C[i] = static_cast<int32_t>(roundf(A[i] / B[i]));\n    }\n}\n```"}
{"task_id": "SimdBench_52_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid float_div_round_simd(const float* A, const float* B, int32_t* C, size_t size) {\n    size_t i = 0;\n    __m256 vecA, vecB, vecResult;\n\n    for (; i + 7 < size; i += 8) {\n        vecA = _mm256_loadu_ps(&A[i]);\n        vecB = _mm256_loadu_ps(&B[i]);\n        vecResult = _mm256_div_ps(vecA, vecB);\n        vecResult = _mm256_round_ps(vecResult, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n        _mm256_storeu_si256((__m256i*)&C[i], _mm256_cvtps_epi32(vecResult));\n    }\n\n    for (; i < size; i++) {\n        C[i] = static_cast<int32_t>(roundf(A[i] / B[i]));\n    }\n}\n```"}
{"task_id": "SimdBench_52_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid float_div_round_simd(const float* A, const float* B, int32_t* C, size_t size) {\n    size_t i = 0;\n    for (; i + 8 <= size; i += 8) {\n        __m256 a = _mm256_loadu_ps(&A[i]);\n        __m256 b = _mm256_loadu_ps(&B[i]);\n        __m256 result = _mm256_div_ps(a, b);\n        __m256 rounded = _mm256_round_ps(result, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n        _mm256_storeu_si256((__m256i*)&C[i], _mm256_cvtps_epi32(rounded));\n    }\n    for (; i < size; i++) {\n        C[i] = static_cast<int32_t>(roundf(A[i] / B[i]));\n    }\n}\n```"}
{"task_id": "SimdBench_52_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid float_div_round_simd(const float* A, const float* B, int32_t* C, size_t size) {\n    size_t i = 0;\n    __m256 vecA, vecB, vecResult;\n\n    for (; i + 7 < size; i += 8) {\n        vecA = _mm256_loadu_ps(&A[i]);\n        vecB = _mm256_loadu_ps(&B[i]);\n        vecResult = _mm256_div_ps(vecA, vecB);\n        vecResult = _mm256_round_ps(vecResult, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n        _mm256_storeu_si256((__m256i*)&C[i], _mm256_cvtps_epi32(vecResult));\n    }\n\n    for (; i < size; i++) {\n        C[i] = static_cast<int32_t>(roundf(A[i] / B[i]));\n    }\n}\n```"}
{"task_id": "SimdBench_52_AVX", "completion": "```cpp\nvoid float_div_round_simd(const float* A, const float* B, int32_t* C, size_t size) {\n    size_t i;\n    __m256 vecA, vecB, vecResult, vecRounded;\n\n    for (i = 0; i + 8 <= size; i += 8) {\n        vecA = _mm256_loadu_ps(&A[i]);\n        vecB = _mm256_loadu_ps(&B[i]);\n        vecResult = _mm256_div_ps(vecA, vecB);\n        vecRounded = _mm256_round_ps(vecResult, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n        _mm256_storeu_si256((__m256i*)&C[i], _mm256_cvtps_epi32(vecRounded));\n    }\n\n    for (; i < size; i++) {\n        C[i] = static_cast<int32_t>(roundf(A[i] / B[i]));\n    }\n}\n```"}
{"task_id": "SimdBench_53_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <float.h>\n\nvoid double_to_float_saturate_simd(const double* A, float* B, size_t size) {\n    size_t i = 0;\n    __m256d max_d = _mm256_set1_pd((double)FLT_MAX);\n    __m256d min_d = _mm256_set1_pd((double)-FLT_MAX);\n    \n    for (; i <= size - 4; i += 4) {\n        __m256d a_vals = _mm256_loadu_pd(&A[i]);\n        __m256d saturated_high = _mm256_min_pd(a_vals, max_d);\n        __m256d saturated_low = _mm256_max_pd(saturated_high, min_d);\n        __m256 a_floats = _mm256_cvtpd_ps(saturated_low);\n        _mm256_storeu_ps(&B[i], a_floats);\n    }\n\n    for (; i < size; ++i) {\n        double val = A[i];\n        if (val > FLT_MAX) {\n            B[i] = FLT_MAX;\n        } else if (val < -FLT_MAX) {\n            B[i] = -FLT_MAX;\n        } else {\n            B[i] = (float)val;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_53_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <float.h>\n\nvoid double_to_float_saturate_simd(const double* A, float* B, size_t size) {\n    size_t i = 0;\n    __m256d max_val = _mm256_set1_pd((double)FLT_MAX);\n    __m256d min_val = _mm256_set1_pd((double)-FLT_MAX);\n    \n    for (; i + 4 <= size; i += 4) {\n        __m256d a_vals = _mm256_loadu_pd(&A[i]);\n        __m256d saturated_vals = _mm256_max_pd(_mm256_min_pd(a_vals, max_val), min_val);\n        __m128 a_low = _mm256_cvtpd_ps(saturated_vals);\n        _mm_storeu_ps(&B[i], a_low);\n        \n        __m128 a_high = _mm256_extractf128_pd(saturated_vals, 1);\n        _mm_storeu_ps(&B[i + 4], a_high);\n    }\n\n    for (; i < size; i++) {\n        double val = A[i];\n        if (val > FLT_MAX) {\n            B[i] = FLT_MAX;\n        } else if (val < -FLT_MAX) {\n            B[i] = -FLT_MAX;\n        } else {\n            B[i] = (float)val;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_53_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <float.h>\n\nvoid double_to_float_saturate_simd(const double* A, float* B, size_t size) {\n    size_t i = 0;\n    __m256d max_val = _mm256_set1_pd((double)FLT_MAX);\n    __m256d min_val = _mm256_set1_pd((double)-FLT_MAX);\n    \n    for (; i + 4 <= size; i += 4) {\n        __m256d vec = _mm256_loadu_pd(&A[i]);\n        __m256d saturated = _mm256_min_pd(_mm256_max_pd(vec, min_val), max_val);\n        __m256 vec_float = _mm256_cvtpd_ps(saturated);\n        _mm256_storeu_ps(&B[i], vec_float);\n    }\n\n    for (; i < size; i++) {\n        double val = A[i];\n        if (val > FLT_MAX) {\n            B[i] = FLT_MAX;\n        } else if (val < -FLT_MAX) {\n            B[i] = -FLT_MAX;\n        } else {\n            B[i] = (float)val;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_53_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <float.h>\n\nvoid double_to_float_saturate_simd(const double* A, float* B, size_t size) {\n    __m256d max_val = _mm256_set1_pd((double)FLT_MAX);\n    __m256d min_val = _mm256_set1_pd((double)-FLT_MAX);\n    \n    size_t i = 0;\n    for (; i + 4 <= size; i += 4) {\n        __m256d a_vals = _mm256_loadu_pd(&A[i]);\n        \n        // Compare with FLT_MAX\n        __m256d cmp_max = _mm256_cmp_pd(a_vals, max_val, _CMP_GT_OQ);\n        __m256d cmp_min = _mm256_cmp_pd(a_vals, min_val, _CMP_LT_OQ);\n        \n        // Set values to FLT_MAX or -FLT_MAX where necessary\n        a_vals = _mm256_blendv_pd(a_vals, max_val, cmp_max);\n        a_vals = _mm256_blendv_pd(a_vals, min_val, cmp_min);\n        \n        // Convert to float and store\n        _mm256_storeu_ps(&B[i], _mm256_cvtpd_ps(a_vals));\n    }\n    \n    // Handle remaining elements\n    for (; i < size; ++i) {\n        double val = A[i];\n        if (val > FLT_MAX) {\n            B[i] = FLT_MAX;\n        } else if (val < -FLT_MAX) {\n            B[i] = -FLT_MAX;\n        } else {\n            B[i] = (float)val;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_53_AVX", "completion": "```cpp\nvoid double_to_float_saturate_simd(const double* A, float* B, size_t size) {\n    __m256d max_val = _mm256_set1_pd(FLT_MAX);\n    __m256d min_val = _mm256_set1_pd(-FLT_MAX);\n    \n    size_t i = 0;\n    for (; i + 4 <= size; i += 4) {\n        __m256d data = _mm256_loadu_pd(&A[i]);\n        __m256d saturated = _mm256_min_pd(_mm256_max_pd(data, min_val), max_val);\n        __m256 float_data = _mm256_cvtpd_ps(saturated);\n        _mm256_storeu_ps(&B[i], float_data);\n    }\n    \n    for (; i < size; i++) {\n        double value = A[i];\n        if (value > FLT_MAX) {\n            B[i] = FLT_MAX;\n        } else if (value < -FLT_MAX) {\n            B[i] = -FLT_MAX;\n        } else {\n            B[i] = static_cast<float>(value);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_54_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid int16_to_int32_simd(const int16_t* A, int32_t* B, size_t size) {\n    size_t i;\n    // Process 8 elements at a time\n    for (i = 0; i <= size - 8; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&A[i]); // Load 8 int16_t values\n        __m256i vec_low = _mm256_unpacklo_epi16(vec, _mm256_setzero_si256()); // Unpack lower half\n        __m256i vec_high = _mm256_unpackhi_epi16(vec, _mm256_setzero_si256()); // Unpack upper half\n        _mm256_storeu_si256((__m256i*)&B[i], vec_low); // Store lower half\n        _mm256_storeu_si256((__m256i*)&B[i + 4], vec_high); // Store upper half\n    }\n    // Handle remaining elements\n    for (; i < size; i++) {\n        B[i] = (int32_t)A[i]; // Fallback for remaining elements\n    }\n}\n```"}
{"task_id": "SimdBench_54_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid int16_to_int32_simd(const int16_t* A, int32_t* B, size_t size) {\n    size_t i = 0;\n    // Process 8 elements at a time\n    for (; i + 8 <= size; i += 8) {\n        __m128i vec = _mm_loadu_si128((__m128i*)&A[i]); // Load 8 int16_t values\n        __m128i vec_low = _mm_unpacklo_epi16(vec, _mm_setzero_si128()); // Unpack lower 8 int16_t to int32_t\n        __m128i vec_high = _mm_unpackhi_epi16(vec, _mm_setzero_si128()); // Unpack upper 8 int16_t to int32_t\n        _mm_storeu_si128((__m128i*)&B[i], vec_low); // Store lower 4 int32_t values\n        _mm_storeu_si128((__m128i*)&B[i + 4], vec_high); // Store upper 4 int32_t values\n    }\n    // Handle remaining elements\n    for (; i < size; i++) {\n        B[i] = (int32_t)A[i];\n    }\n}\n```"}
{"task_id": "SimdBench_54_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid int16_to_int32_simd(const int16_t* A, int32_t* B, size_t size) {\n    size_t i;\n    // Process 8 elements at a time\n    for (i = 0; i <= size - 8; i += 8) {\n        __m128i vec = _mm_loadu_si128((__m128i*)&A[i]); // Load 8 int16_t values\n        __m128i vec_low = _mm_unpacklo_epi16(vec, _mm_setzero_si128()); // Unpack lower 4 int16_t to int32_t\n        __m128i vec_high = _mm_unpackhi_epi16(vec, _mm_setzero_si128()); // Unpack upper 4 int16_t to int32_t\n        _mm_storeu_si128((__m128i*)&B[i], vec_low); // Store lower 4 int32_t\n        _mm_storeu_si128((__m128i*)&B[i + 4], vec_high); // Store upper 4 int32_t\n    }\n    // Handle remaining elements\n    for (; i < size; i++) {\n        B[i] = (int32_t)A[i];\n    }\n}\n```"}
{"task_id": "SimdBench_54_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid int16_to_int32_simd(const int16_t* A, int32_t* B, size_t size) {\n    size_t i;\n    // Process 8 elements at a time\n    for (i = 0; i <= size - 8; i += 8) {\n        __m128i a = _mm_loadu_si128((__m128i*)&A[i]); // Load 8 int16_t values\n        __m128i b = _mm_unpacklo_epi16(a, _mm_setzero_si128()); // Unpack lower 4 int16_t to int32_t\n        __m128i c = _mm_unpackhi_epi16(a, _mm_setzero_si128()); // Unpack upper 4 int16_t to int32_t\n        _mm_storeu_si128((__m128i*)&B[i], b); // Store lower 4 int32_t\n        _mm_storeu_si128((__m128i*)&B[i + 4], c); // Store upper 4 int32_t\n    }\n    // Handle remaining elements\n    for (; i < size; i++) {\n        B[i] = (int32_t)A[i];\n    }\n}\n```"}
{"task_id": "SimdBench_54_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid int16_to_int32_simd(const int16_t* A, int32_t* B, size_t size) {\n    size_t i;\n    // Process 8 elements at a time\n    for (i = 0; i <= size - 8; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&A[i]);\n        // Convert int16_t to int32_t\n        __m256i vec_low = _mm256_unpacklo_epi16(vec, _mm256_setzero_si256());\n        __m256i vec_high = _mm256_unpackhi_epi16(vec, _mm256_setzero_si256());\n        _mm256_storeu_si256((__m256i*)&B[i], vec_low);\n        _mm256_storeu_si256((__m256i*)&B[i + 4], vec_high);\n    }\n    // Handle remaining elements\n    for (; i < size; i++) {\n        B[i] = (int32_t)A[i];\n    }\n}\n```"}
{"task_id": "SimdBench_55_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid conditional_normalize_simd(const float* A, const int32_t* control, float* B, size_t size, float min_val, float max_val) {\n    __m256 min_val_vec = _mm256_set1_ps(min_val);\n    __m256 max_val_vec = _mm256_set1_ps(max_val);\n    __m256 range_vec = _mm256_sub_ps(max_val_vec, min_val_vec);\n    \n    size_t i = 0;\n    for (; i + 8 <= size; i += 8) {\n        __m256 a_vec = _mm256_loadu_ps(&A[i]);\n        __m256 control_vec = _mm256_loadu_si256((__m256i*)&control[i]);\n\n        __m256 mask = _mm256_cmp_ps(control_vec, _mm256_setzero_ps(), _CMP_GT_OS);\n        \n        __m256 normalized = _mm256_div_ps(_mm256_sub_ps(a_vec, min_val_vec), range_vec);\n        normalized = _mm256_max_ps(normalized, _mm256_setzero_ps());\n        normalized = _mm256_min_ps(normalized, _mm256_set1_ps(1.0f));\n        \n        __m256 result = _mm256_blendv_ps(a_vec, normalized, mask);\n        _mm256_storeu_ps(&B[i], result);\n    }\n    \n    for (; i < size; ++i) {\n        if (control[i] > 0) {\n            float normalized = (A[i] - min_val) / (max_val - min_val);\n            B[i] = normalized < 0.0f ? 0.0f : (normalized > 1.0f ? 1.0f : normalized);\n        } else {\n            B[i] = A[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_55_AVX", "completion": "```cpp\nvoid conditional_normalize_simd(const float* A, const int32_t* control, float* B, size_t size, float min_val, float max_val) {\n    __m256 min_val_vec = _mm256_set1_ps(min_val);\n    __m256 max_val_vec = _mm256_set1_ps(max_val);\n    __m256 range_vec = _mm256_sub_ps(max_val_vec, min_val_vec);\n    \n    size_t i = 0;\n    for (; i + 8 <= size; i += 8) {\n        __m256 a_vec = _mm256_loadu_ps(&A[i]);\n        __m256 control_vec = _mm256_loadu_si256((__m256i*)&control[i]);\n\n        __m256 mask = _mm256_cmp_ps(control_vec, _mm256_setzero_ps(), _CMP_GT_OS);\n        \n        __m256 normalized = _mm256_div_ps(_mm256_sub_ps(a_vec, min_val_vec), range_vec);\n        normalized = _mm256_max_ps(normalized, _mm256_setzero_ps());\n        normalized = _mm256_min_ps(normalized, _mm256_set1_ps(1.0f));\n\n        __m256 result = _mm256_blendv_ps(a_vec, normalized, mask);\n        _mm256_storeu_ps(&B[i], result);\n    }\n    \n    for (; i < size; ++i) {\n        if (control[i] > 0) {\n            float normalized = (A[i] - min_val) / (max_val - min_val);\n            B[i] = normalized < 0.0f ? 0.0f : (normalized > 1.0f ? 1.0f : normalized);\n        } else {\n            B[i] = A[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_55_AVX", "completion": "```cpp\nvoid conditional_normalize_simd(const float* A, const int32_t* control, float* B, size_t size, float min_val, float max_val) {\n    __m256 min_val_vec = _mm256_set1_ps(min_val);\n    __m256 max_val_vec = _mm256_set1_ps(max_val);\n    __m256 range_vec = _mm256_sub_ps(max_val_vec, min_val_vec);\n    \n    size_t i = 0;\n    for (; i + 8 <= size; i += 8) {\n        __m256 a_vec = _mm256_loadu_ps(&A[i]);\n        __m256 control_vec = _mm256_loadu_si256((__m256i*)&control[i]);\n\n        __m256 mask = _mm256_cmp_ps(control_vec, _mm256_setzero_ps(), _CMP_GT_OS);\n        \n        __m256 normalized = _mm256_div_ps(_mm256_sub_ps(a_vec, min_val_vec), range_vec);\n        normalized = _mm256_max_ps(normalized, _mm256_setzero_ps());\n        normalized = _mm256_min_ps(normalized, _mm256_set1_ps(1.0f));\n\n        __m256 result = _mm256_blendv_ps(a_vec, normalized, mask);\n\n        _mm256_storeu_ps(&B[i], result);\n    }\n    \n    for (; i < size; i++) {\n        if (control[i] > 0) {\n            float normalized = (A[i] - min_val) / (max_val - min_val);\n            B[i] = (normalized < 0.0f) ? 0.0f : (normalized > 1.0f) ? 1.0f : normalized;\n        } else {\n            B[i] = A[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_55_AVX", "completion": "```cpp\nvoid conditional_normalize_simd(const float* A, const int32_t* control, float* B, size_t size, float min_val, float max_val) {\n    __m256 min_val_vec = _mm256_set1_ps(min_val);\n    __m256 max_val_vec = _mm256_set1_ps(max_val);\n    __m256 range_vec = _mm256_sub_ps(max_val_vec, min_val_vec);\n    \n    size_t i = 0;\n    for (; i + 8 <= size; i += 8) {\n        __m256 a_vec = _mm256_loadu_ps(&A[i]);\n        __m256 control_vec = _mm256_loadu_si256((__m256i*)&control[i]);\n\n        __m256 mask = _mm256_cmp_ps(control_vec, _mm256_setzero_ps(), _CMP_GT_OS);\n        \n        __m256 normalized = _mm256_div_ps(_mm256_sub_ps(a_vec, min_val_vec), range_vec);\n        normalized = _mm256_max_ps(normalized, _mm256_setzero_ps());\n        normalized = _mm256_min_ps(normalized, _mm256_set1_ps(1.0f));\n\n        __m256 result = _mm256_blendv_ps(a_vec, normalized, mask);\n        _mm256_storeu_ps(&B[i], result);\n    }\n    \n    for (; i < size; ++i) {\n        if (control[i] > 0) {\n            float normalized = (A[i] - min_val) / (max_val - min_val);\n            B[i] = normalized < 0.0f ? 0.0f : (normalized > 1.0f ? 1.0f : normalized);\n        } else {\n            B[i] = A[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_55_AVX", "completion": "```cpp\nvoid conditional_normalize_simd(const float* A, const int32_t* control, float* B, size_t size, float min_val, float max_val) {\n    __m256 min_val_vec = _mm256_set1_ps(min_val);\n    __m256 max_val_vec = _mm256_set1_ps(max_val);\n    __m256 range_vec = _mm256_sub_ps(max_val_vec, min_val_vec);\n    \n    size_t i = 0;\n    for (; i + 8 <= size; i += 8) {\n        __m256 a_vec = _mm256_loadu_ps(&A[i]);\n        __m256 control_vec = _mm256_loadu_si256((__m256i*)&control[i]);\n\n        __m256 mask = _mm256_cmp_ps(_mm256_cvtepi32_ps(control_vec), _mm256_setzero_ps(), _MM_CMPINT_GT);\n        \n        __m256 normalized = _mm256_div_ps(_mm256_sub_ps(a_vec, min_val_vec), range_vec);\n        normalized = _mm256_max_ps(normalized, _mm256_setzero_ps());\n        normalized = _mm256_min_ps(normalized, _mm256_set1_ps(1.0f));\n        \n        __m256 result = _mm256_blendv_ps(a_vec, normalized, mask);\n        _mm256_storeu_ps(&B[i], result);\n    }\n    \n    for (; i < size; ++i) {\n        if (control[i] > 0) {\n            float normalized = (A[i] - min_val) / (max_val - min_val);\n            B[i] = normalized < 0.0f ? 0.0f : (normalized > 1.0f ? 1.0f : normalized);\n        } else {\n            B[i] = A[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_56_AVX", "completion": "```cpp\nvoid int_to_float_sqrt_simd(const uint32_t* A, float* B, size_t size) {\n    size_t i;\n    __m256i* pA = (__m256i*)A;\n    __m256* pB = (__m256*)B;\n\n    for (i = 0; i < size / 8; i++) {\n        __m256i data = _mm256_loadu_si256(&pA[i]);\n        __m256i high_bits = _mm256_srli_epi32(data, 16);\n        __m256 float_values = _mm256_cvtepi32_ps(high_bits);\n        __m256 sqrt_values = _mm256_sqrt_ps(float_values);\n        _mm256_storeu_ps(&pB[i], sqrt_values);\n    }\n\n    for (; i < size; i++) {\n        B[i] = sqrtf((A[i] >> 16) & 0xFFFF);\n    }\n}\n```"}
{"task_id": "SimdBench_56_AVX", "completion": "```cpp\nvoid int_to_float_sqrt_simd(const uint32_t* A, float* B, size_t size) {\n    size_t i = 0;\n    __m256i mask = _mm256_set1_epi32(0xFFFF0000);\n    __m256i zero = _mm256_setzero_si256();\n    \n    for (; i <= size - 8; i += 8) {\n        __m256i data = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i high_bits = _mm256_and_si256(data, mask);\n        __m256 high_float = _mm256_cvtepi32_ps(high_bits);\n        __m256 result = _mm256_sqrt_ps(high_float);\n        _mm256_storeu_ps(&B[i], result);\n    }\n    \n    for (; i < size; i++) {\n        B[i] = sqrtf((A[i] & 0xFFFF0000) >> 16);\n    }\n}\n```"}
{"task_id": "SimdBench_56_AVX", "completion": "```cpp\nvoid int_to_float_sqrt_simd(const uint32_t* A, float* B, size_t size) {\n    size_t i = 0;\n    __m256i mask = _mm256_set1_epi32(0xFFFF0000);\n    for (; i <= size - 8; i += 8) {\n        __m256i data = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i high_bits = _mm256_and_si256(data, mask);\n        __m256  float_values = _mm256_cvtepi32_ps(_mm256_srli_epi32(high_bits, 16));\n        __m256 sqrt_values = _mm256_sqrt_ps(float_values);\n        _mm256_storeu_ps(&B[i], sqrt_values);\n    }\n    for (; i < size; i++) {\n        B[i] = sqrtf((A[i] >> 16) & 0xFFFF);\n    }\n}\n```"}
{"task_id": "SimdBench_56_AVX", "completion": "```cpp\nvoid int_to_float_sqrt_simd(const uint32_t* A, float* B, size_t size) {\n    size_t i = 0;\n    __m256i mask = _mm256_set1_epi32(0xFFFF0000);\n    __m256i zero = _mm256_setzero_si256();\n    \n    for (; i <= size - 8; i += 8) {\n        __m256i data = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i high_bits = _mm256_and_si256(data, mask);\n        __m256 high_float = _mm256_cvtepi32_ps(_mm256_srli_epi32(high_bits, 16));\n        __m256 result = _mm256_sqrt_ps(high_float);\n        _mm256_storeu_ps(&B[i], result);\n    }\n    \n    for (; i < size; i++) {\n        B[i] = sqrtf((A[i] & 0xFFFF0000) >> 16);\n    }\n}\n```"}
{"task_id": "SimdBench_56_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid int_to_float_sqrt_simd(const uint32_t* A, float* B, size_t size) {\n    size_t i;\n    for (i = 0; i + 8 <= size; i += 8) {\n        __m256i data = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i high_bits = _mm256_srli_epi32(data, 16);\n        __m256 float_vals = _mm256_cvtepi32_ps(high_bits);\n        __m256 sqrt_vals = _mm256_sqrt_ps(float_vals);\n        _mm256_storeu_ps(&B[i], sqrt_vals);\n    }\n    for (; i < size; i++) {\n        B[i] = sqrtf((float)(A[i] >> 16));\n    }\n}\n```"}
{"task_id": "SimdBench_57_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid int_bits_to_float_simd(const uint32_t* A, float* B, size_t size) {\n    size_t i;\n    for (i = 0; i + 8 <= size; i += 8) {\n        __m256i int_vec = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256 float_vec = _mm256_castsi256_ps(int_vec);\n        _mm256_storeu_ps(&B[i], float_vec);\n    }\n    for (; i < size; i++) {\n        B[i] = *(float*)&A[i];\n    }\n}\n```"}
{"task_id": "SimdBench_57_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid int_bits_to_float_simd(const uint32_t* A, float* B, size_t size) {\n    size_t i = 0;\n    for (; i + 8 <= size; i += 8) {\n        __m256i int_vec = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256 float_vec = _mm256_castsi256_ps(int_vec);\n        _mm256_storeu_ps(&B[i], float_vec);\n    }\n    for (; i < size; i++) {\n        B[i] = *(float*)&A[i];\n    }\n}\n```"}
{"task_id": "SimdBench_57_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid int_bits_to_float_simd(const uint32_t* A, float* B, size_t size) {\n    size_t i;\n    for (i = 0; i + 8 <= size; i += 8) {\n        __m256i int_vec = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256 float_vec = _mm256_castsi256_ps(int_vec);\n        _mm256_storeu_ps(&B[i], float_vec);\n    }\n    for (; i < size; ++i) {\n        B[i] = *(float*)&A[i];\n    }\n}\n```"}
{"task_id": "SimdBench_57_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid int_bits_to_float_simd(const uint32_t* A, float* B, size_t size) {\n    size_t i;\n    size_t simd_size = size / 8 * 8; // Process in chunks of 8 for AVX\n    __m256i* src = (__m256i*)A;\n    __m256* dst = (__m256*)B;\n\n    for (i = 0; i < simd_size; i += 8) {\n        __m256i data = _mm256_loadu_si256(&src[i / 8]);\n        _mm256_storeu_ps(&dst[i / 8], _mm256_castsi256_ps(data));\n    }\n\n    for (; i < size; ++i) {\n        B[i] = *((float*)&A[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_57_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid int_bits_to_float_simd(const uint32_t* A, float* B, size_t size) {\n    size_t i = 0;\n    // Process 8 elements at a time using AVX2\n    for (; i + 8 <= size; i += 8) {\n        __m256i int_vec = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256 float_vec = _mm256_castsi256_ps(int_vec);\n        _mm256_storeu_ps(&B[i], float_vec);\n    }\n    // Handle remaining elements\n    for (; i < size; i++) {\n        B[i] = *(float*)&A[i];\n    }\n}\n```"}
{"task_id": "SimdBench_58_AVX", "completion": "```cpp\nvoid conditional_diff_simd(const int32_t* A, const bool* cond, float* diff, size_t size) {\n    __m256i zero = _mm256_setzero_si256();\n    __m256  zero_f = _mm256_setzero_ps();\n    diff[0] = 0.0f;\n\n    for (size_t i = 1; i < size; i += 8) {\n        __m256i a_curr = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i a_prev = _mm256_loadu_si256((__m256i*)&A[i - 1]);\n        __m256i condition = _mm256_loadu_si256((__m256i*)&cond[i]);\n\n        __m256i diff_int = _mm256_sub_epi32(a_curr, a_prev);\n        __m256 diff_float = _mm256_cvtepi32_ps(diff_int);\n\n        __m256 mask = _mm256_cvtepi32_ps(_mm256_and_si256(condition, _mm256_set1_epi32(1)));\n        mask = _mm256_cmp_ps(mask, zero_f, _CMP_EQ_OQ);\n        \n        __m256 result = _mm256_blendv_ps(zero_f, diff_float, mask);\n        _mm256_storeu_ps(&diff[i], result);\n    }\n\n    for (size_t i = size - (size % 8); i < size; ++i) {\n        diff[i] = cond[i] ? static_cast<float>(A[i] - A[i - 1]) : 0.0f;\n    }\n}\n```"}
{"task_id": "SimdBench_58_AVX", "completion": "```cpp\nvoid conditional_diff_simd(const int32_t* A, const bool* cond, float* diff, size_t size) {\n    __m256i zero = _mm256_setzero_si256();\n    __m256  zero_f = _mm256_setzero_ps();\n    diff[0] = 0.0f;\n\n    size_t i = 1;\n    for (; i + 7 < size; i += 8) {\n        __m256i a_curr = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i a_prev = _mm256_loadu_si256((__m256i*)&A[i - 1]);\n        __m256i condition = _mm256_loadu_si256((__m256i*)&cond[i]);\n\n        __m256i diff_int = _mm256_sub_epi32(a_curr, a_prev);\n        __m256 diff_float = _mm256_cvtepi32_ps(diff_int);\n\n        __m256 mask = _mm256_cvtepi32_ps(_mm256_and_si256(condition, _mm256_set1_epi32(1)));\n        mask = _mm256_cmp_ps(mask, zero_f, _CMP_GT_OQ);\n\n        diff_float = _mm256_blendv_ps(zero_f, diff_float, mask);\n        _mm256_storeu_ps(&diff[i], diff_float);\n    }\n\n    for (; i < size; ++i) {\n        if (cond[i]) {\n            diff[i] = static_cast<float>(A[i] - A[i - 1]);\n        } else {\n            diff[i] = 0.0f;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_58_AVX", "completion": "```cpp\nvoid conditional_diff_simd(const int32_t* A, const bool* cond, float* diff, size_t size) {\n    if (size == 0) return;\n\n    // Set the first element to 0.0f\n    diff[0] = 0.0f;\n\n    size_t i = 1;\n    __m256i zero = _mm256_setzero_si256();\n    __m256  zero_f = _mm256_setzero_ps();\n\n    for (; i + 7 < size; i += 8) {\n        __m256i a_curr = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i a_prev = _mm256_loadu_si256((__m256i*)&A[i - 1]);\n        __m256i condition = _mm256_loadu_si256((__m256i*)&cond[i]);\n\n        __m256i diff_int = _mm256_sub_epi32(a_curr, a_prev);\n        __m256  diff_float = _mm256_cvtepi32_ps(diff_int);\n\n        // Create mask for conditions\n        __m256i mask = _mm256_and_si256(condition, _mm256_set1_epi32(1));\n        __m256 mask_f = _mm256_cvtepi32_ps(mask);\n\n        // Set diff based on condition\n        diff_float = _mm256_blendv_ps(zero_f, diff_float, mask_f);\n\n        _mm256_storeu_ps(&diff[i], diff_float);\n    }\n\n    // Handle remaining elements\n    for (; i < size; ++i) {\n        if (cond[i]) {\n            diff[i] = static_cast<float>(A[i] - A[i - 1]);\n        } else {\n            diff[i] = 0.0f;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_58_AVX", "completion": "```cpp\nvoid conditional_diff_simd(const int32_t* A, const bool* cond, float* diff, size_t size) {\n    __m256i zero = _mm256_setzero_si256();\n    __m256  zero_f = _mm256_setzero_ps();\n    diff[0] = 0.0f;\n\n    size_t i = 1;\n    for (; i + 7 < size; i += 8) {\n        __m256i a_curr = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i a_prev = _mm256_loadu_si256((__m256i*)&A[i - 1]);\n        __m256i condition = _mm256_loadu_si256((__m256i*)&cond[i]);\n\n        __m256i diff_int = _mm256_sub_epi32(a_curr, a_prev);\n        __m256 diff_float = _mm256_cvtepi32_ps(diff_int);\n\n        __m256 mask = _mm256_cvtepi32_ps(_mm256_and_si256(condition, _mm256_set1_epi32(1)));\n        diff_float = _mm256_blendv_ps(zero_f, diff_float, mask);\n\n        _mm256_storeu_ps(&diff[i], diff_float);\n    }\n\n    for (; i < size; ++i) {\n        if (cond[i]) {\n            diff[i] = static_cast<float>(A[i] - A[i - 1]);\n        } else {\n            diff[i] = 0.0f;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_58_AVX", "completion": "```cpp\nvoid conditional_diff_simd(const int32_t* A, const bool* cond, float* diff, size_t size) {\n    __m256i zero = _mm256_setzero_si256();\n    __m256  zero_f = _mm256_setzero_ps();\n    diff[0] = 0.0f;\n\n    size_t i = 1;\n    for (; i + 7 < size; i += 8) {\n        __m256i a_curr = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i a_prev = _mm256_loadu_si256((__m256i*)&A[i - 1]);\n        __m256i condition = _mm256_loadu_si256((__m256i*)&cond[i]);\n\n        __m256i diff_int = _mm256_sub_epi32(a_curr, a_prev);\n        __m256 diff_float = _mm256_cvtepi32_ps(diff_int);\n\n        __m256 mask = _mm256_cvtepi32_ps(_mm256_and_si256(condition, _mm256_set1_epi32(1)));\n        mask = _mm256_cmp_ps(mask, zero_f, _CMP_EQ_OQ);\n        \n        diff_float = _mm256_blendv_ps(zero_f, diff_float, mask);\n        _mm256_storeu_ps(&diff[i], diff_float);\n    }\n\n    for (; i < size; ++i) {\n        if (cond[i]) {\n            diff[i] = static_cast<float>(A[i] - A[i - 1]);\n        } else {\n            diff[i] = 0.0f;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_59_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid widening_uint_simd(const uint32_t* src, uint64_t* dst, size_t length) {\n    size_t i = 0;\n    __m256i mask = _mm256_set1_epi64x(0xFFFFFFFF00000000); // Set high 32 bits to 1\n\n    for (; i <= length - 8; i += 8) {\n        __m256i src_vec = _mm256_loadu_si256((__m256i*)&src[i]); // Load 8 uint32_t\n        __m256i src_vec_64 = _mm256_unpacklo_epi32(src_vec, _mm256_setzero_si256()); // Lower 4 to 64-bit\n        __m256i src_vec_64_high = _mm256_unpackhi_epi32(src_vec, _mm256_setzero_si256()); // Upper 4 to 64-bit\n\n        src_vec_64 = _mm256_or_si256(src_vec_64, mask); // Set high bits to 1\n        src_vec_64_high = _mm256_or_si256(src_vec_64_high, mask); // Set high bits to 1\n\n        _mm256_storeu_si256((__m256i*)&dst[i], src_vec_64); // Store lower 4\n        _mm256_storeu_si256((__m256i*)&dst[i + 4], src_vec_64_high); // Store upper 4\n    }\n\n    for (; i < length; i++) {\n        dst[i] = ((uint64_t)src[i] | 0xFFFFFFFF00000000); // Handle remaining elements\n    }\n}\n```"}
{"task_id": "SimdBench_59_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid widening_uint_simd(const uint32_t* src, uint64_t* dst, size_t length) {\n    size_t i;\n    __m256i mask = _mm256_set1_epi64x(0xFFFFFFFF00000000); // Set high 32 bits to 1\n\n    for (i = 0; i < length / 8; i++) {\n        __m256i src_vec = _mm256_loadu_si256((__m256i*)&src[i * 8]); // Load 8 uint32_t\n        __m256i low_part = _mm256_cvtepu32_epi64(src_vec); // Convert to 64-bit\n        __m256i result = _mm256_or_si256(low_part, mask); // Set high 32 bits to 1\n        _mm256_storeu_si256((__m256i*)&dst[i * 4], result); // Store result\n    }\n\n    // Handle remaining elements\n    for (; i < length; i++) {\n        dst[i] = ((uint64_t)src[i]) | 0xFFFFFFFF00000000; // Handle remaining elements\n    }\n}\n```"}
{"task_id": "SimdBench_59_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid widening_uint_simd(const uint32_t* src, uint64_t* dst, size_t length) {\n    size_t i = 0;\n    __m256i mask = _mm256_set1_epi64x(0xFFFFFFFF00000000); // Set high 32 bits to 1\n\n    for (; i <= length - 8; i += 8) {\n        __m256i src_vec = _mm256_loadu_si256((__m256i*)&src[i]); // Load 8 uint32_t values\n        __m256i src_vec_64 = _mm256_cvtepu32_epi64(src_vec); // Convert to 64-bit\n        src_vec_64 = _mm256_or_si256(src_vec_64, mask); // Set high 32 bits to 1\n        _mm256_storeu_si256((__m256i*)&dst[i], src_vec_64); // Store the result\n    }\n\n    // Handle remaining elements\n    for (; i < length; i++) {\n        dst[i] = ((uint64_t)src[i] | 0xFFFFFFFF00000000);\n    }\n}\n```"}
{"task_id": "SimdBench_59_AVX", "completion": "```cpp\nvoid widening_uint_simd(const uint32_t* src, uint64_t* dst, size_t length) {\n    size_t i;\n    __m256i* src_vec = (__m256i*)src;\n    __m256i* dst_vec = (__m256i*)dst;\n\n    for (i = 0; i < length / 8; i++) {\n        __m256i data = _mm256_loadu_si256(&src_vec[i]);\n        __m256i high_bits = _mm256_set1_epi64x(0xFFFFFFFF00000000);\n        __m256i low_bits = _mm256_cvtepu32_epi64(data);\n        __m256i result = _mm256_or_si256(low_bits, high_bits);\n        _mm256_storeu_si256(&dst_vec[i], result);\n    }\n\n    for (; i < length; i++) {\n        dst[i] = ((uint64_t)src[i] | 0xFFFFFFFF00000000);\n    }\n}\n```"}
{"task_id": "SimdBench_59_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid widening_uint_simd(const uint32_t* src, uint64_t* dst, size_t length) {\n    size_t i;\n    __m256i mask = _mm256_set1_epi64x(0xFFFFFFFF00000000); // High 32 bits set to 1\n\n    for (i = 0; i < length / 8; i++) {\n        __m256i src_vec = _mm256_loadu_si256((__m256i*)&src[i * 8]);\n        __m256i low_bits = _mm256_cvtepu32_epi64(src_vec);\n        __m256i result = _mm256_or_si256(low_bits, mask);\n        _mm256_storeu_si256((__m256i*)&dst[i * 8], result);\n    }\n\n    for (; i < length; i++) {\n        dst[i] = ((uint64_t)src[i] | 0xFFFFFFFF00000000);\n    }\n}\n```"}
{"task_id": "SimdBench_60_AVX", "completion": "```cpp\ndouble indexed_sum_simd(const double* vec, const int16_t* index, size_t length) {\n    __m256d sum_vec = _mm256_setzero_pd();\n    \n    size_t i;\n    for (i = 0; i + 4 <= length; i += 4) {\n        __m128i idx_vec = _mm_loadu_si128((__m128i*)&index[i]);\n        __m256d vec_vec = _mm256_set_pd(vec[_mm_extract_epi16(idx_vec, 3)],\n                                         vec[_mm_extract_epi16(idx_vec, 2)],\n                                         vec[_mm_extract_epi16(idx_vec, 1)],\n                                         vec[_mm_extract_epi16(idx_vec, 0)]);\n        sum_vec = _mm256_add_pd(sum_vec, vec_vec);\n    }\n\n    double sum[4];\n    _mm256_storeu_pd(sum, sum_vec);\n    \n    double total_sum = sum[0] + sum[1] + sum[2] + sum[3];\n\n    for (; i < length; ++i) {\n        total_sum += vec[index[i]];\n    }\n\n    return total_sum;\n}\n```"}
{"task_id": "SimdBench_60_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\ndouble indexed_sum_simd(const double* vec, const int16_t* index, size_t length) {\n    __m256d sum_vec = _mm256_setzero_pd();\n    \n    size_t i = 0;\n    for (; i + 4 <= length; i += 4) {\n        __m128i idx_vec = _mm_loadu_si128((__m128i*)&index[i]);\n        __m256d vec_vec = _mm256_set_pd(\n            vec[_mm_extract_epi16(idx_vec, 3)],\n            vec[_mm_extract_epi16(idx_vec, 2)],\n            vec[_mm_extract_epi16(idx_vec, 1)],\n            vec[_mm_extract_epi16(idx_vec, 0)]\n        );\n        sum_vec = _mm256_add_pd(sum_vec, vec_vec);\n    }\n\n    double sum[4] __attribute__((aligned(32)));\n    _mm256_store_pd(sum, sum_vec);\n    \n    double total_sum = sum[0] + sum[1] + sum[2] + sum[3];\n\n    for (; i < length; i++) {\n        total_sum += vec[index[i]];\n    }\n\n    return total_sum;\n}\n```"}
{"task_id": "SimdBench_60_AVX", "completion": "```cpp\ndouble indexed_sum_simd(const double* vec, const int16_t* index, size_t length) {\n    __m256d sum_vec = _mm256_setzero_pd();\n    \n    size_t i;\n    for (i = 0; i <= length - 4; i += 4) {\n        __m128i idx = _mm_loadu_si128((__m128i*)&index[i]);\n        __m256d vals = _mm256_set_pd(vec[_mm_extract_epi16(idx, 3)],\n                                      vec[_mm_extract_epi16(idx, 2)],\n                                      vec[_mm_extract_epi16(idx, 1)],\n                                      vec[_mm_extract_epi16(idx, 0)]);\n        sum_vec = _mm256_add_pd(sum_vec, vals);\n    }\n\n    double sum[4];\n    _mm256_storeu_pd(sum, sum_vec);\n\n    double total_sum = sum[0] + sum[1] + sum[2] + sum[3];\n\n    for (; i < length; i++) {\n        total_sum += vec[index[i]];\n    }\n\n    return total_sum;\n}\n```"}
{"task_id": "SimdBench_60_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\ndouble indexed_sum_simd(const double* vec, const int16_t* index, size_t length) {\n    __m256d sum_vec = _mm256_setzero_pd();\n    \n    size_t i;\n    for (i = 0; i <= length - 4; i += 4) {\n        __m128i idx_vec = _mm_loadu_si128((__m128i*)&index[i]);\n        __m256d vec_vec = _mm256_set_pd(vec[_mm_extract_epi16(idx_vec, 3)],\n                                         vec[_mm_extract_epi16(idx_vec, 2)],\n                                         vec[_mm_extract_epi16(idx_vec, 1)],\n                                         vec[_mm_extract_epi16(idx_vec, 0)]);\n        sum_vec = _mm256_add_pd(sum_vec, vec_vec);\n    }\n\n    double sum[4];\n    _mm256_storeu_pd(sum, sum_vec);\n    \n    double total_sum = sum[0] + sum[1] + sum[2] + sum[3];\n\n    for (; i < length; i++) {\n        total_sum += vec[index[i]];\n    }\n\n    return total_sum;\n}\n```"}
{"task_id": "SimdBench_60_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\ndouble indexed_sum_simd(const double* vec, const int16_t* index, size_t length) {\n    __m256d sum_vec = _mm256_setzero_pd();\n    \n    size_t i = 0;\n    for (; i + 4 <= length; i += 4) {\n        __m128i idx = _mm_loadu_si128((__m128i*)&index[i]);\n        __m256d vec_vals = _mm256_set_pd(\n            vec[_mm_extract_epi16(idx, 3)],\n            vec[_mm_extract_epi16(idx, 2)],\n            vec[_mm_extract_epi16(idx, 1)],\n            vec[_mm_extract_epi16(idx, 0)]\n        );\n        sum_vec = _mm256_add_pd(sum_vec, vec_vals);\n    }\n\n    double sum[4];\n    _mm256_storeu_pd(sum, sum_vec);\n    \n    double total_sum = sum[0] + sum[1] + sum[2] + sum[3];\n\n    for (; i < length; ++i) {\n        total_sum += vec[index[i]];\n    }\n\n    return total_sum;\n}\n```"}
{"task_id": "SimdBench_61_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid simple_conv2d_simd(const double* input, const double* kernel, double * output, size_t input_size, size_t kernel_size) {\n    size_t output_size = input_size - kernel_size + 1;\n    __m256d k[4];\n\n    for (size_t i = 0; i < kernel_size; i++) {\n        for (size_t j = 0; j < kernel_size; j++) {\n            k[i * kernel_size + j] = _mm256_set1_pd(kernel[i * kernel_size + j]);\n        }\n    }\n\n    for (size_t y = 0; y < output_size; y++) {\n        for (size_t x = 0; x < output_size; x++) {\n            __m256d sum = _mm256_setzero_pd();\n            for (size_t ki = 0; ki < kernel_size; ki++) {\n                for (size_t kj = 0; kj < kernel_size; kj++) {\n                    __m256d input_vec = _mm256_loadu_pd(&input[(y + ki) * input_size + (x + kj)]);\n                    sum = _mm256_fmadd_pd(input_vec, k[ki * kernel_size + kj], sum);\n                }\n            }\n            double result[4];\n            _mm256_storeu_pd(result, sum);\n            double final_sum = result[0] + result[1] + result[2] + result[3];\n            output[y * output_size + x] = final_sum > 0 ? final_sum : 0;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_61_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid simple_conv2d_simd(const double* input, const double* kernel, double * output, size_t input_size, size_t kernel_size) {\n    size_t output_size = input_size - kernel_size + 1;\n    for (size_t i = 0; i < output_size; ++i) {\n        for (size_t j = 0; j < output_size; ++j) {\n            __m256d sum = _mm256_setzero_pd();\n            for (size_t ki = 0; ki < kernel_size; ++ki) {\n                for (size_t kj = 0; kj < kernel_size; kj += 4) {\n                    __m256d k = _mm256_loadu_pd(&kernel[ki * kernel_size + kj]);\n                    __m256d in = _mm256_loadu_pd(&input[(i + ki) * input_size + (j + kj)]);\n                    sum = _mm256_fmadd_pd(k, in, sum);\n                }\n            }\n            double result[4];\n            _mm256_storeu_pd(result, sum);\n            double conv_result = result[0] + result[1] + result[2] + result[3];\n            output[i * output_size + j] = conv_result > 0 ? conv_result : 0;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_61_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid simple_conv2d_simd(const double* input, const double* kernel, double * output, size_t input_size, size_t kernel_size) {\n    size_t output_size = input_size - kernel_size + 1;\n    for (size_t i = 0; i < output_size; i++) {\n        for (size_t j = 0; j < output_size; j++) {\n            __m256d sum = _mm256_setzero_pd();\n            for (size_t ki = 0; ki < kernel_size; ki++) {\n                for (size_t kj = 0; kj < kernel_size; kj += 4) {\n                    __m256d k = _mm256_loadu_pd(&kernel[ki * kernel_size + kj]);\n                    __m256d x = _mm256_loadu_pd(&input[(i + ki) * input_size + (j + kj)]);\n                    sum = _mm256_fmadd_pd(k, x, sum);\n                }\n            }\n            double result[4];\n            _mm256_storeu_pd(result, sum);\n            double conv_result = result[0] + result[1] + result[2] + result[3];\n            output[i * output_size + j] = conv_result > 0 ? conv_result : 0;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_61_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid simple_conv2d_simd(const double* input, const double* kernel, double * output, size_t input_size, size_t kernel_size) {\n    size_t output_size = input_size - kernel_size + 1;\n    for (size_t i = 0; i < output_size; ++i) {\n        for (size_t j = 0; j < output_size; ++j) {\n            __m256d sum = _mm256_setzero_pd();\n            for (size_t ki = 0; ki < kernel_size; ++ki) {\n                for (size_t kj = 0; kj < kernel_size; kj += 4) {\n                    __m256d k = _mm256_loadu_pd(&kernel[ki * kernel_size + kj]);\n                    __m256d v = _mm256_loadu_pd(&input[(i + ki) * input_size + (j + kj)]);\n                    sum = _mm256_fmadd_pd(k, v, sum);\n                }\n            }\n            double result[4];\n            _mm256_storeu_pd(result, sum);\n            double conv_result = result[0] + result[1] + result[2] + result[3];\n            output[i * output_size + j] = conv_result > 0 ? conv_result : 0;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_61_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid simple_conv2d_simd(const double* input, const double* kernel, double * output, size_t input_size, size_t kernel_size) {\n    size_t output_size = input_size - kernel_size + 1;\n    __m256d k[4];\n\n    for (size_t i = 0; i < kernel_size; ++i) {\n        for (size_t j = 0; j < kernel_size; ++j) {\n            k[i * kernel_size + j] = _mm256_set1_pd(kernel[i * kernel_size + j]);\n        }\n    }\n\n    for (size_t y = 0; y < output_size; ++y) {\n        for (size_t x = 0; x < output_size; x += 4) {\n            __m256d sum = _mm256_setzero_pd();\n            for (size_t ky = 0; ky < kernel_size; ++ky) {\n                for (size_t kx = 0; kx < kernel_size; ++kx) {\n                    __m256d input_vec = _mm256_loadu_pd(&input[(y + ky) * input_size + (x + kx)]);\n                    sum = _mm256_fmadd_pd(input_vec, k[ky * kernel_size + kx], sum);\n                }\n            }\n            sum = _mm256_max_pd(sum, _mm256_setzero_pd());\n            _mm256_storeu_pd(&output[y * output_size + x], sum);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_62_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nbool has_close_elements_simd(const std::vector<double> & numbers, double threshold) {\n    size_t n = numbers.size();\n    if (n < 2) return false;\n\n    __m256d threshold_vec = _mm256_set1_pd(threshold);\n    \n    for (size_t i = 0; i < n; i += 4) {\n        for (size_t j = i + 1; j < n; j++) {\n            if (j >= i + 4) break; // Only compare within the next 4 elements\n            \n            __m256d vec_a = _mm256_loadu_pd(&numbers[i]);\n            __m256d vec_b = _mm256_set1_pd(numbers[j]);\n            __m256d diff = _mm256_sub_pd(vec_a, vec_b);\n            diff = _mm256_and_pd(diff, _mm256_cmp_pd(diff, _mm256_setzero_pd(), _CMP_LT_OS));\n            diff = _mm256_max_pd(diff, _mm256_sub_pd(vec_b, vec_a));\n            \n            if (_mm256_movemask_pd(_mm256_cmp_pd(diff, threshold_vec, _CMP_LT_OS)) != 0) {\n                return true;\n            }\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_62_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nbool has_close_elements_simd(const std::vector<double> & numbers, double threshold) {\n    size_t n = numbers.size();\n    if (n < 2) return false;\n\n    __m256d threshold_vec = _mm256_set1_pd(threshold);\n    \n    for (size_t i = 0; i < n; i += 4) {\n        __m256d vec1 = _mm256_loadu_pd(&numbers[i]);\n        \n        for (size_t j = i + 1; j < n; j++) {\n            __m256d vec2 = _mm256_loadu_pd(&numbers[j]);\n            __m256d diff = _mm256_sub_pd(vec1, vec2);\n            diff = _mm256_and_pd(diff, _mm256_cmp_pd(diff, _mm256_setzero_pd(), _MM_CMPINT_LT));\n            diff = _mm256_sub_pd(diff, _mm256_set1_pd(threshold));\n            __m256d close_mask = _mm256_cmp_pd(diff, _mm256_setzero_pd(), _MM_CMPINT_LT);\n            if (_mm256_movemask_pd(close_mask) != 0) {\n                return true;\n            }\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_62_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nbool has_close_elements_simd(const std::vector<double> & numbers, double threshold) {\n    size_t n = numbers.size();\n    if (n < 2) return false;\n\n    __m256d threshold_vec = _mm256_set1_pd(threshold);\n    \n    for (size_t i = 0; i < n; i += 4) {\n        __m256d vec1 = _mm256_loadu_pd(&numbers[i]);\n        for (size_t j = i + 1; j < n; j++) {\n            __m256d vec2 = _mm256_loadu_pd(&numbers[j]);\n            __m256d diff = _mm256_sub_pd(vec1, vec2);\n            diff = _mm256_and_pd(diff, _mm256_cmp_pd(diff, _mm256_setzero_pd(), _MM_CMPINT_LT));\n            diff = _mm256_max_pd(diff, _mm256_sub_pd(vec2, vec1));\n            __m256d close = _mm256_cmp_pd(diff, threshold_vec, _MM_CMPINT_LT);\n            if (_mm256_movemask_pd(close) != 0) {\n                return true;\n            }\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_62_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nbool has_close_elements_simd(const std::vector<double> & numbers, double threshold) {\n    size_t n = numbers.size();\n    if (n < 2) return false;\n\n    __m256d threshold_vec = _mm256_set1_pd(threshold);\n    \n    for (size_t i = 0; i < n; i += 4) {\n        for (size_t j = i + 1; j < n; j++) {\n            if (j >= i + 4) break; // Only compare with the next 4 elements\n\n            __m256d vec_a = _mm256_loadu_pd(&numbers[i]);\n            __m256d vec_b = _mm256_loadu_pd(&numbers[j]);\n\n            __m256d diff = _mm256_sub_pd(vec_a, vec_b);\n            diff = _mm256_and_pd(diff, _mm256_cmp_pd(diff, _mm256_setzero_pd(), _MM_CMPINT_LT));\n            diff = _mm256_max_pd(diff, _mm256_sub_pd(vec_b, vec_a));\n\n            if (_mm256_movemask_pd(_mm256_cmp_pd(diff, threshold_vec, _MM_CMPINT_LT)) != 0) {\n                return true;\n            }\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_62_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nbool has_close_elements_simd(const std::vector<double> & numbers, double threshold) {\n    size_t n = numbers.size();\n    if (n < 2) return false;\n\n    __m256d threshold_vec = _mm256_set1_pd(threshold);\n    \n    for (size_t i = 0; i < n; i += 4) {\n        for (size_t j = i + 1; j < n; j++) {\n            if (j >= i + 4) break;\n\n            __m256d vec1 = _mm256_loadu_pd(&numbers[i]);\n            __m256d vec2 = _mm256_set1_pd(numbers[j]);\n            __m256d diff = _mm256_sub_pd(vec1, vec2);\n            diff = _mm256_and_pd(diff, _mm256_cmp_pd(diff, _mm256_setzero_pd(), _CMP_GT_OS));\n            diff = _mm256_sub_pd(diff, _mm256_set1_pd(threshold));\n            __m256d mask = _mm256_cmp_pd(diff, _mm256_setzero_pd(), _CMP_LT_OS);\n            \n            if (_mm256_movemask_pd(mask) != 0) {\n                return true;\n            }\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_63_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nbool below_zero_simd(std::vector<int> operations) {\n    __m256i zero = _mm256_setzero_si256();\n    __m256i balance = _mm256_setzero_si256();\n    \n    size_t size = operations.size();\n    size_t i = 0;\n\n    for (; i + 8 <= size; i += 8) {\n        __m256i op = _mm256_loadu_si256((__m256i*)&operations[i]);\n        balance = _mm256_add_epi32(balance, op);\n        \n        // Check if any element in balance is less than zero\n        __m256i cmp = _mm256_cmpgt_epi32(zero, balance);\n        if (_mm256_movemask_epi8(cmp)) {\n            return true;\n        }\n    }\n\n    // Handle remaining elements\n    for (; i < size; ++i) {\n        balance = _mm256_add_epi32(balance, _mm256_set1_epi32(operations[i]));\n        if (_mm256_movemask_epi8(_mm256_cmpgt_epi32(zero, balance))) {\n            return true;\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_63_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nbool below_zero_simd(std::vector<int> operations) {\n    __m256i zero = _mm256_setzero_si256();\n    __m256i balance = _mm256_setzero_si256();\n    \n    size_t size = operations.size();\n    size_t i = 0;\n\n    for (; i + 8 <= size; i += 8) {\n        __m256i op = _mm256_loadu_si256((__m256i*)&operations[i]);\n        balance = _mm256_add_epi32(balance, op);\n        __m256i cmp = _mm256_cmpgt_epi32(zero, balance);\n        if (_mm256_movemask_epi8(cmp)) {\n            return true;\n        }\n    }\n\n    for (; i < size; ++i) {\n        balance = _mm256_add_epi32(balance, _mm256_set1_epi32(operations[i]));\n        if (_mm256_movemask_epi8(_mm256_cmpgt_epi32(zero, balance))) {\n            return true;\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_63_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nbool below_zero_simd(std::vector<int> operations) {\n    __m256i zero = _mm256_setzero_si256();\n    __m256i balance = _mm256_setzero_si256();\n    \n    size_t size = operations.size();\n    size_t i;\n\n    for (i = 0; i <= size - 8; i += 8) {\n        __m256i op = _mm256_loadu_si256((__m256i*)&operations[i]);\n        balance = _mm256_add_epi32(balance, op);\n        \n        // Check if any element in balance is less than zero\n        __m256i cmp = _mm256_cmpgt_epi32(zero, balance);\n        if (_mm256_movemask_epi8(cmp) != 0) {\n            return true;\n        }\n    }\n\n    // Handle remaining elements\n    for (; i < size; ++i) {\n        balance = _mm256_add_epi32(balance, _mm256_set1_epi32(operations[i]));\n        if (_mm256_movemask_epi8(_mm256_cmpgt_epi32(zero, balance)) != 0) {\n            return true;\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_63_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nbool below_zero_simd(std::vector<int> operations) {\n    __m256i zero = _mm256_setzero_si256();\n    __m256i balance = _mm256_setzero_si256();\n    \n    size_t size = operations.size();\n    size_t i;\n\n    for (i = 0; i <= size - 8; i += 8) {\n        __m256i op = _mm256_loadu_si256((__m256i*)&operations[i]);\n        balance = _mm256_add_epi32(balance, op);\n        \n        // Check if any element in balance is less than zero\n        __m256i cmp = _mm256_cmpgt_epi32(zero, balance);\n        if (_mm256_movemask_epi8(cmp) != 0) {\n            return true;\n        }\n    }\n\n    // Handle remaining elements\n    for (; i < size; ++i) {\n        balance = _mm256_add_epi32(balance, _mm256_set1_epi32(operations[i]));\n        if (_mm256_extract_epi32(balance, 0) < 0 || \n            _mm256_extract_epi32(balance, 1) < 0 || \n            _mm256_extract_epi32(balance, 2) < 0 || \n            _mm256_extract_epi32(balance, 3) < 0 || \n            _mm256_extract_epi32(balance, 4) < 0 || \n            _mm256_extract_epi32(balance, 5) < 0 || \n            _mm256_extract_epi32(balance, 6) < 0 || \n            _mm256_extract_epi32(balance, 7) < 0) {\n            return true;\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_63_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nbool below_zero_simd(std::vector<int> operations) {\n    __m256i zero = _mm256_setzero_si256();\n    __m256i balance = _mm256_setzero_si256();\n    size_t size = operations.size();\n    \n    for (size_t i = 0; i < size; i += 8) {\n        __m256i op = _mm256_loadu_si256((__m256i*)&operations[i]);\n        balance = _mm256_add_epi32(balance, op);\n        \n        // Check if any element in balance is below zero\n        __m256i cmp = _mm256_cmpgt_epi32(zero, balance);\n        int mask = _mm256_movemask_epi8(cmp);\n        \n        if (mask != 0) {\n            return true;\n        }\n    }\n    \n    // Handle remaining elements\n    for (size_t i = (size / 8) * 8; i < size; ++i) {\n        if ((balance[0] += operations[i]) < 0) {\n            return true;\n        }\n    }\n    \n    return false;\n}\n```"}
{"task_id": "SimdBench_64_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\ndouble mean_absolute_deviation_simd(std::vector<double> numbers) {\n    size_t n = numbers.size();\n    if (n == 0) return 0.0;\n\n    __m256d sum_vec = _mm256_setzero_pd();\n    __m256d sum_abs_vec = _mm256_setzero_pd();\n\n    for (size_t i = 0; i < n; i += 4) {\n        __m256d vec = _mm256_loadu_pd(&numbers[i]);\n        sum_vec = _mm256_add_pd(sum_vec, vec);\n    }\n\n    double sum = _mm256_reduce_add_pd(sum_vec);\n    double mean = sum / n;\n\n    for (size_t i = 0; i < n; i += 4) {\n        __m256d vec = _mm256_loadu_pd(&numbers[i]);\n        __m256d mean_vec = _mm256_set1_pd(mean);\n        __m256d abs_diff_vec = _mm256_sub_pd(vec, mean_vec);\n        abs_diff_vec = _mm256_and_pd(abs_diff_vec, _mm256_cmp_pd(abs_diff_vec, _mm256_setzero_pd(), _CMP_GE_OS));\n        sum_abs_vec = _mm256_add_pd(sum_abs_vec, abs_diff_vec);\n    }\n\n    double sum_abs = _mm256_reduce_add_pd(sum_abs_vec);\n    return sum_abs / n;\n}\n```"}
{"task_id": "SimdBench_64_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\ndouble mean_absolute_deviation_simd(std::vector<double> numbers) {\n    size_t n = numbers.size();\n    if (n == 0) return 0.0;\n\n    __m256d sum_vec = _mm256_setzero_pd();\n    __m256d sum_abs_vec = _mm256_setzero_pd();\n    \n    for (size_t i = 0; i < n; i += 4) {\n        __m256d vec = _mm256_loadu_pd(&numbers[i]);\n        sum_vec = _mm256_add_pd(sum_vec, vec);\n    }\n\n    double sum = _mm256_reduce_add_pd(sum_vec);\n    double mean = sum / n;\n\n    for (size_t i = 0; i < n; i += 4) {\n        __m256d vec = _mm256_loadu_pd(&numbers[i]);\n        __m256d mean_vec = _mm256_set1_pd(mean);\n        __m256d abs_diff_vec = _mm256_sub_pd(vec, mean_vec);\n        abs_diff_vec = _mm256_abs_pd(abs_diff_vec);\n        sum_abs_vec = _mm256_add_pd(sum_abs_vec, abs_diff_vec);\n    }\n\n    double sum_abs = _mm256_reduce_add_pd(sum_abs_vec);\n    return sum_abs / n;\n}\n```"}
{"task_id": "SimdBench_64_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\ndouble mean_absolute_deviation_simd(std::vector<double> numbers) {\n    size_t n = numbers.size();\n    if (n == 0) return 0.0;\n\n    __m256d sum_vec = _mm256_setzero_pd();\n    __m256d sum_abs_vec = _mm256_setzero_pd();\n    \n    for (size_t i = 0; i < n; i += 4) {\n        __m256d vec = _mm256_loadu_pd(&numbers[i]);\n        sum_vec = _mm256_add_pd(sum_vec, vec);\n    }\n\n    double sum = _mm256_reduce_add_pd(sum_vec);\n    double mean = sum / n;\n\n    for (size_t i = 0; i < n; i += 4) {\n        __m256d vec = _mm256_loadu_pd(&numbers[i]);\n        __m256d mean_vec = _mm256_set1_pd(mean);\n        __m256d abs_diff_vec = _mm256_sub_pd(vec, mean_vec);\n        abs_diff_vec = _mm256_and_pd(abs_diff_vec, _mm256_cmp_pd(abs_diff_vec, _mm256_setzero_pd(), _CMP_GE_OQ));\n        sum_abs_vec = _mm256_add_pd(sum_abs_vec, abs_diff_vec);\n    }\n\n    double sum_abs = _mm256_reduce_add_pd(sum_abs_vec);\n    return sum_abs / n;\n}\n```"}
{"task_id": "SimdBench_64_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\ndouble mean_absolute_deviation_simd(std::vector<double> numbers) {\n    size_t n = numbers.size();\n    if (n == 0) return 0.0;\n\n    __m256d sum_vec = _mm256_setzero_pd();\n    __m256d sum_abs_vec = _mm256_setzero_pd();\n    \n    for (size_t i = 0; i < n; i += 4) {\n        __m256d vec = _mm256_loadu_pd(&numbers[i]);\n        sum_vec = _mm256_add_pd(sum_vec, vec);\n    }\n\n    double sum = _mm256_reduce_add_pd(sum_vec);\n    double mean = sum / n;\n\n    for (size_t i = 0; i < n; i += 4) {\n        __m256d vec = _mm256_loadu_pd(&numbers[i]);\n        __m256d mean_vec = _mm256_set1_pd(mean);\n        __m256d abs_diff_vec = _mm256_sub_pd(vec, mean_vec);\n        abs_diff_vec = _mm256_and_pd(abs_diff_vec, _mm256_cmp_pd(abs_diff_vec, _mm256_setzero_pd(), _CMP_GE_OQ));\n        sum_abs_vec = _mm256_add_pd(sum_abs_vec, abs_diff_vec);\n    }\n\n    double sum_abs = _mm256_reduce_add_pd(sum_abs_vec);\n    return sum_abs / n;\n}\n```"}
{"task_id": "SimdBench_64_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n#include <cmath>\n\ndouble mean_absolute_deviation_simd(std::vector<double> numbers) {\n    size_t n = numbers.size();\n    if (n == 0) return 0.0;\n\n    __m256d sum_vec = _mm256_setzero_pd();\n    __m256d sum_abs_vec = _mm256_setzero_pd();\n\n    for (size_t i = 0; i < n; i += 4) {\n        __m256d vec = _mm256_loadu_pd(&numbers[i]);\n        __m256d mean_vec = _mm256_set1_pd(0.0); // Placeholder for mean calculation\n\n        sum_vec = _mm256_add_pd(sum_vec, vec);\n    }\n\n    double sum = _mm256_reduce_add_pd(sum_vec);\n    double mean = sum / n;\n\n    for (size_t i = 0; i < n; i += 4) {\n        __m256d vec = _mm256_loadu_pd(&numbers[i]);\n        __m256d mean_vec = _mm256_set1_pd(mean);\n        __m256d abs_diff_vec = _mm256_sub_pd(vec, mean_vec);\n        abs_diff_vec = _mm256_and_pd(abs_diff_vec, _mm256_cmp_pd(abs_diff_vec, _mm256_setzero_pd(), _CMP_GE_OQ));\n        \n        sum_abs_vec = _mm256_add_pd(sum_abs_vec, abs_diff_vec);\n    }\n\n    double sum_abs = _mm256_reduce_add_pd(sum_abs_vec);\n    return sum_abs / n;\n}\n```"}
{"task_id": "SimdBench_65_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nstd::vector<int> intersperse_simd(std::vector<int> numbers, int delimeter) {\n    size_t n = numbers.size();\n    size_t newSize = n * 2 - 1;\n    std::vector<int> result(newSize);\n\n    __m256i delimiterVec = _mm256_set1_epi32(delimeter);\n\n    size_t i = 0;\n    for (; i + 8 <= n; i += 8) {\n        __m256i numbersVec = _mm256_loadu_si256((__m256i*)&numbers[i]);\n        _mm256_storeu_si256((__m256i*)&result[i * 2], numbersVec);\n        _mm256_storeu_si256((__m256i*)&result[i * 2 + 8], delimiterVec);\n    }\n\n    for (; i < n; ++i) {\n        result[i * 2] = numbers[i];\n        if (i < n - 1) {\n            result[i * 2 + 1] = delimeter;\n        }\n    }\n\n    if (n > 0) {\n        result[newSize - 1] = numbers[n - 1];\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_65_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nstd::vector<int> intersperse_simd(std::vector<int> numbers, int delimeter) {\n    size_t n = numbers.size();\n    size_t newSize = n + (n - 1);\n    std::vector<int> result(newSize);\n\n    __m256i delimiterVec = _mm256_set1_epi32(delimeter);\n\n    size_t i = 0;\n    for (; i + 8 <= n; i += 8) {\n        __m256i numbersVec = _mm256_loadu_si256((__m256i*)&numbers[i]);\n        _mm256_storeu_si256((__m256i*)&result[i * 2], numbersVec);\n        _mm256_storeu_si256((__m256i*)&result[i * 2 + 8], delimiterVec);\n    }\n\n    for (; i < n; ++i) {\n        result[i * 2] = numbers[i];\n        if (i < n - 1) {\n            result[i * 2 + 1] = delimeter;\n        }\n    }\n\n    if (n > 0) {\n        result[newSize - 1] = numbers[n - 1];\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_65_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nstd::vector<int> intersperse_simd(std::vector<int> numbers, int delimeter) {\n    size_t n = numbers.size();\n    size_t newSize = n + (n - 1);\n    std::vector<int> result(newSize);\n\n    __m256i delimiterVec = _mm256_set1_epi32(delimeter);\n    \n    size_t i = 0;\n    for (; i + 8 <= n; i += 8) {\n        __m256i numbersVec = _mm256_loadu_si256((__m256i*)&numbers[i]);\n        _mm256_storeu_si256((__m256i*)&result[i * 2], numbersVec);\n        _mm256_storeu_si256((__m256i*)&result[i * 2 + 8], delimiterVec);\n    }\n\n    for (; i < n; ++i) {\n        result[i * 2] = numbers[i];\n        if (i < n - 1) {\n            result[i * 2 + 1] = delimeter;\n        }\n    }\n\n    if (n > 0) {\n        result[newSize - 1] = numbers[n - 1];\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_65_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nstd::vector<int> intersperse_simd(std::vector<int> numbers, int delimeter) {\n    size_t n = numbers.size();\n    size_t newSize = n + (n - 1);\n    std::vector<int> result(newSize);\n\n    __m256i delimiterVec = _mm256_set1_epi32(delimeter);\n\n    size_t i = 0;\n    for (; i + 8 <= n; i += 8) {\n        __m256i nums = _mm256_loadu_si256((__m256i*)&numbers[i]);\n        _mm256_storeu_si256((__m256i*)&result[i * 2], nums);\n        _mm256_storeu_si256((__m256i*)&result[i * 2 + 8], delimiterVec);\n    }\n\n    for (; i < n; ++i) {\n        result[i * 2] = numbers[i];\n        if (i < n - 1) {\n            result[i * 2 + 1] = delimeter;\n        }\n    }\n\n    if (n > 0) {\n        result[newSize - 1] = numbers[n - 1];\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_65_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nstd::vector<int> intersperse_simd(std::vector<int> numbers, int delimeter) {\n    size_t n = numbers.size();\n    size_t newSize = n + (n - 1); // New size with delimiters\n    std::vector<int> result(newSize);\n\n    if (n == 0) return result;\n\n    __m256i delimiterVec = _mm256_set1_epi32(delimeter);\n    \n    size_t i = 0;\n    for (; i + 8 <= n; i += 8) {\n        __m256i numbersVec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&numbers[i]));\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(&result[i * 2]), numbersVec);\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(&result[i * 2 + 8]), delimiterVec);\n    }\n\n    // Handle remaining elements\n    for (; i < n; ++i) {\n        result[i * 2] = numbers[i];\n        if (i < n - 1) {\n            result[i * 2 + 1] = delimeter;\n        }\n    }\n\n    // Resize the result to the correct size\n    result.resize(newSize);\n    return result;\n}\n```"}
{"task_id": "SimdBench_66_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nstd::vector<int64_t> sum_product_simd(std::vector<int16_t> numbers) {\n    int n = numbers.size();\n    if (n == 0) return {0, 1};\n\n    __m256i sum_vec = _mm256_setzero_si256();\n    __m256i prod_vec = _mm256_set1_epi16(1);\n    \n    int i;\n    for (i = 0; i <= n - 16; i += 16) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&numbers[i]);\n        sum_vec = _mm256_add_epi16(sum_vec, vec);\n        prod_vec = _mm256_mullo_epi16(prod_vec, vec);\n    }\n\n    int16_t sum_arr[16];\n    _mm256_storeu_si256((__m256i*)sum_arr, sum_vec);\n    \n    int64_t sum = 0;\n    for (int j = 0; j < 16; j++) {\n        sum += sum_arr[j];\n    }\n\n    int16_t prod_arr[16];\n    _mm256_storeu_si256((__m256i*)prod_arr, prod_vec);\n    \n    int64_t product = 1;\n    for (int j = 0; j < 16; j++) {\n        product *= prod_arr[j];\n    }\n\n    for (; i < n; i++) {\n        sum += numbers[i];\n        product *= numbers[i];\n    }\n\n    return {sum, product};\n}\n```"}
{"task_id": "SimdBench_66_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nstd::vector<int64_t> sum_product_simd(std::vector<int16_t> numbers) {\n    int64_t sum = 0;\n    int64_t product = 1;\n    size_t size = numbers.size();\n\n    if (size == 0) {\n        return {0, 1};\n    }\n\n    size_t i = 0;\n    __m128i vec_sum = _mm_setzero_si128();\n    __m128i vec_product = _mm_set1_epi16(1);\n\n    for (; i + 8 <= size; i += 8) {\n        __m128i vec_numbers = _mm_loadu_si128((__m128i*)&numbers[i]);\n        vec_sum = _mm_add_epi16(vec_sum, vec_numbers);\n        vec_product = _mm_mullo_epi16(vec_product, vec_numbers);\n    }\n\n    // Horizontal sum\n    vec_sum = _mm_hadd_epi16(vec_sum, vec_sum);\n    vec_sum = _mm_hadd_epi16(vec_sum, vec_sum);\n    sum += _mm_extract_epi16(vec_sum, 0) + _mm_extract_epi16(vec_sum, 1);\n\n    // Calculate product for remaining elements\n    for (; i < size; ++i) {\n        sum += numbers[i];\n        product *= numbers[i];\n    }\n\n    // Horizontal product\n    product *= _mm_extract_epi16(vec_product, 0);\n    product *= _mm_extract_epi16(vec_product, 1);\n    product *= _mm_extract_epi16(vec_product, 2);\n    product *= _mm_extract_epi16(vec_product, 3);\n    \n    return {sum, product};\n}\n```"}
{"task_id": "SimdBench_66_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nstd::vector<int64_t> sum_product_simd(std::vector<int16_t> numbers) {\n    int64_t sum = 0;\n    int64_t product = 1;\n    size_t size = numbers.size();\n\n    if (size == 0) {\n        return {0, 1};\n    }\n\n    size_t i = 0;\n    __m256i vec_sum = _mm256_setzero_si256();\n    __m256i vec_product = _mm256_set1_epi16(1);\n\n    for (; i + 16 <= size; i += 16) {\n        __m256i vec_numbers = _mm256_loadu_si256((__m256i*)&numbers[i]);\n        vec_sum = _mm256_add_epi16(vec_sum, vec_numbers);\n        vec_product = _mm256_mullo_epi16(vec_product, vec_numbers);\n    }\n\n    // Horizontal sum\n    vec_sum = _mm256_hadd_epi16(vec_sum, vec_sum);\n    vec_sum = _mm256_hadd_epi16(vec_sum, vec_sum);\n    vec_sum = _mm256_hadd_epi16(vec_sum, vec_sum);\n    sum += _mm256_extract_epi16(vec_sum, 0) + _mm256_extract_epi16(vec_sum, 8);\n\n    // Calculate product\n    for (size_t j = 0; j < 16; j++) {\n        product *= numbers[i + j];\n    }\n\n    // Handle remaining elements\n    for (; i < size; i++) {\n        sum += numbers[i];\n        product *= numbers[i];\n    }\n\n    return {sum, product};\n}\n```"}
{"task_id": "SimdBench_66_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nstd::vector<int64_t> sum_product_simd(std::vector<int16_t> numbers) {\n    int64_t sum = 0;\n    int64_t product = 1;\n    size_t size = numbers.size();\n\n    if (size == 0) {\n        return {0, 1};\n    }\n\n    __m256i vec_sum = _mm256_setzero_si256();\n    __m256i vec_prod = _mm256_set1_epi16(1);\n    \n    size_t i;\n    for (i = 0; i + 16 <= size; i += 16) {\n        __m256i vec_nums1 = _mm256_loadu_si256((__m256i*)&numbers[i]);\n        __m256i vec_nums2 = _mm256_loadu_si256((__m256i*)&numbers[i + 8]);\n\n        vec_sum = _mm256_add_epi16(vec_sum, vec_nums1);\n        vec_sum = _mm256_add_epi16(vec_sum, vec_nums2);\n\n        vec_prod = _mm256_mullo_epi16(vec_prod, vec_nums1);\n        vec_prod = _mm256_mullo_epi16(vec_prod, vec_nums2);\n    }\n\n    // Horizontal sum\n    vec_sum = _mm256_hadd_epi16(vec_sum, vec_sum);\n    vec_sum = _mm256_hadd_epi16(vec_sum, vec_sum);\n    vec_sum = _mm256_hadd_epi16(vec_sum, vec_sum);\n    sum += _mm256_extract_epi16(vec_sum, 0) + _mm256_extract_epi16(vec_sum, 8);\n\n    // Horizontal product\n    int16_t prod_arr[16];\n    _mm256_storeu_si256((__m256i*)prod_arr, vec_prod);\n    for (int j = 0; j < 16; j++) {\n        product *= prod_arr[j];\n    }\n\n    // Handle remaining elements\n    for (; i < size; i++) {\n        sum += numbers[i];\n        product *= numbers[i];\n    }\n\n    return {sum, product};\n}\n```"}
{"task_id": "SimdBench_66_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nstd::vector<int64_t> sum_product_simd(std::vector<int16_t> numbers) {\n    int64_t sum = 0;\n    int64_t product = 1;\n    size_t size = numbers.size();\n\n    if (size == 0) {\n        return {0, 1};\n    }\n\n    __m256i vec_sum = _mm256_setzero_si256();\n    __m256i vec_product = _mm256_set1_epi16(1);\n    \n    size_t i = 0;\n    for (; i + 16 <= size; i += 16) {\n        __m256i vec_nums = _mm256_loadu_si256((__m256i*)&numbers[i]);\n        vec_sum = _mm256_add_epi16(vec_sum, vec_nums);\n        vec_product = _mm256_mullo_epi16(vec_product, vec_nums);\n    }\n\n    // Horizontal sum\n    vec_sum = _mm256_hadd_epi16(vec_sum, vec_sum);\n    vec_sum = _mm256_hadd_epi16(vec_sum, vec_sum);\n    vec_sum = _mm256_hadd_epi16(vec_sum, vec_sum);\n    sum += _mm256_extract_epi16(vec_sum, 0) + _mm256_extract_epi16(vec_sum, 8);\n\n    // Calculate product for remaining elements\n    for (; i < size; ++i) {\n        product *= numbers[i];\n    }\n\n    // Horizontal product\n    int16_t product_array[16];\n    _mm256_storeu_si256((__m256i*)product_array, vec_product);\n    for (int j = 0; j < 16; ++j) {\n        product *= product_array[j];\n    }\n\n    return {sum, product};\n}\n```"}
{"task_id": "SimdBench_67_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nstd::vector<int> rolling_max_simd(std::vector<int> numbers) {\n    int n = numbers.size();\n    std::vector<int> result(n);\n    \n    if (n == 0) return result;\n\n    __m256i current_max = _mm256_set1_epi32(numbers[0]);\n    result[0] = numbers[0];\n\n    for (int i = 1; i < n; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&numbers[i]);\n        current_max = _mm256_max_epi32(current_max, vec);\n        \n        if (i + 8 <= n) {\n            _mm256_storeu_si256((__m256i*)&result[i], current_max);\n        } else {\n            for (int j = i; j < n; j++) {\n                current_max = _mm256_max_epi32(current_max, _mm256_set1_epi32(numbers[j]));\n                result[j] = _mm256_extract_epi32(current_max, 0);\n            }\n        }\n    }\n\n    for (int i = 1; i < n; i++) {\n        result[i] = std::max(result[i], result[i - 1]);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_67_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nstd::vector<int> rolling_max_simd(std::vector<int> numbers) {\n    size_t n = numbers.size();\n    std::vector<int> result(n);\n    \n    if (n == 0) return result;\n\n    __m256i current_max = _mm256_set1_epi32(numbers[0]);\n    result[0] = numbers[0];\n\n    for (size_t i = 1; i < n; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&numbers[i]);\n        current_max = _mm256_max_epi32(current_max, vec);\n        \n        if (i + 8 <= n) {\n            _mm256_storeu_si256((__m256i*)&result[i], current_max);\n        } else {\n            for (size_t j = i; j < n; ++j) {\n                current_max = _mm256_max_epi32(current_max, _mm256_set1_epi32(numbers[j]));\n                result[j] = _mm256_extract_epi32(current_max, 0);\n            }\n        }\n    }\n\n    for (size_t i = 1; i < n; ++i) {\n        result[i] = std::max(result[i], result[i - 1]);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_67_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nstd::vector<int> rolling_max_simd(std::vector<int> numbers) {\n    size_t n = numbers.size();\n    std::vector<int> result(n);\n    \n    if (n == 0) return result;\n\n    __m256i max_vec = _mm256_set1_epi32(numbers[0]);\n    result[0] = numbers[0];\n\n    for (size_t i = 1; i < n; i += 8) {\n        __m256i current_vec = _mm256_loadu_si256((__m256i*)&numbers[i]);\n        max_vec = _mm256_max_epi32(max_vec, current_vec);\n        \n        // Store the rolling max for the current segment\n        for (size_t j = 0; j < 8 && (i + j) < n; ++j) {\n            if (i + j == 0) {\n                result[i + j] = numbers[i + j];\n            } else {\n                result[i + j] = std::max(result[i + j - 1], numbers[i + j]);\n            }\n        }\n    }\n\n    // Handle remaining elements if n is not a multiple of 8\n    for (size_t i = (n / 8) * 8; i < n; ++i) {\n        result[i] = std::max(result[i - 1], numbers[i]);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_67_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nstd::vector<int> rolling_max_simd(std::vector<int> numbers) {\n    int n = numbers.size();\n    std::vector<int> result(n);\n    \n    if (n == 0) return result;\n\n    __m256i current_max = _mm256_set1_epi32(numbers[0]);\n    result[0] = numbers[0];\n\n    for (int i = 1; i < n; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&numbers[i]);\n        current_max = _mm256_max_epi32(current_max, vec);\n        \n        if (i + 8 <= n) {\n            _mm256_storeu_si256((__m256i*)&result[i], current_max);\n        } else {\n            for (int j = i; j < n; ++j) {\n                result[j] = _mm256_extract_epi32(current_max, j - i);\n            }\n        }\n        \n        current_max = _mm256_max_epi32(current_max, _mm256_set1_epi32(result[i - 1]));\n    }\n\n    for (int i = 1; i < n; ++i) {\n        result[i] = std::max(result[i], result[i - 1]);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_67_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nstd::vector<int> rolling_max_simd(std::vector<int> numbers) {\n    size_t n = numbers.size();\n    std::vector<int> result(n);\n    \n    if (n == 0) return result;\n\n    __m256i current_max = _mm256_set1_epi32(numbers[0]);\n    result[0] = numbers[0];\n\n    for (size_t i = 1; i < n; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&numbers[i]);\n        current_max = _mm256_max_epi32(current_max, vec);\n        \n        if (i + 8 <= n) {\n            _mm256_storeu_si256((__m256i*)&result[i], current_max);\n        } else {\n            for (size_t j = i; j < n; ++j) {\n                current_max = _mm256_max_epi32(current_max, _mm256_set1_epi32(numbers[j]));\n                result[j] = _mm256_extract_epi32(current_max, 0);\n            }\n        }\n    }\n\n    for (size_t i = 1; i < n; ++i) {\n        result[i] = std::max(result[i - 1], result[i]);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_68_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <string>\n\nstd::string string_xor_simd(std::string a, std::string b) {\n    size_t len = a.size();\n    std::string result(len, '0');\n\n    size_t i = 0;\n    for (; i + 32 <= len; i += 32) {\n        __m256i vec_a = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&a[i]));\n        __m256i vec_b = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&b[i]));\n        __m256i vec_result = _mm256_xor_si256(vec_a, vec_b);\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(&result[i]), vec_result);\n    }\n\n    for (; i < len; ++i) {\n        result[i] = (a[i] == b[i]) ? '0' : '1';\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_68_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <string>\n\nstd::string string_xor_simd(std::string a, std::string b) {\n    size_t len = a.size();\n    std::string result(len, '0');\n\n    size_t i = 0;\n    for (; i + 32 <= len; i += 32) {\n        __m256i vec_a = _mm256_loadu_si256((__m256i*)&a[i]);\n        __m256i vec_b = _mm256_loadu_si256((__m256i*)&b[i]);\n        __m256i vec_result = _mm256_xor_si256(vec_a, vec_b);\n        _mm256_storeu_si256((__m256i*)&result[i], vec_result);\n    }\n\n    for (; i < len; ++i) {\n        result[i] = (a[i] == b[i]) ? '0' : '1';\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_68_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <string>\n\nstd::string string_xor_simd(std::string a, std::string b) {\n    size_t len = a.size();\n    std::string result(len, '0');\n\n    size_t i = 0;\n    for (; i + 32 <= len; i += 32) {\n        __m256i vec_a = _mm256_loadu_si256((__m256i*)&a[i]);\n        __m256i vec_b = _mm256_loadu_si256((__m256i*)&b[i]);\n        __m256i vec_result = _mm256_xor_si256(vec_a, vec_b);\n        _mm256_storeu_si256((__m256i*)&result[i], vec_result);\n    }\n\n    for (; i < len; ++i) {\n        result[i] = (a[i] == b[i]) ? '0' : '1';\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_68_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <string>\n\nstd::string string_xor_simd(std::string a, std::string b) {\n    size_t len = a.size();\n    std::string result(len, '0');\n\n    size_t i = 0;\n    // Process 32 bits at a time using AVX2\n    for (; i + 32 <= len; i += 32) {\n        __m256i vec_a = _mm256_loadu_si256((__m256i*)&a[i]);\n        __m256i vec_b = _mm256_loadu_si256((__m256i*)&b[i]);\n        __m256i vec_result = _mm256_xor_si256(vec_a, vec_b);\n        _mm256_storeu_si256((__m256i*)&result[i], vec_result);\n    }\n\n    // Handle remaining characters\n    for (; i < len; ++i) {\n        result[i] = (a[i] == b[i]) ? '0' : '1';\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_68_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <string>\n\nstd::string string_xor_simd(std::string a, std::string b) {\n    size_t len = a.size();\n    std::string result(len, '0');\n\n    size_t i = 0;\n    for (; i + 32 <= len; i += 32) {\n        __m256i vec_a = _mm256_loadu_si256((__m256i*)&a[i]);\n        __m256i vec_b = _mm256_loadu_si256((__m256i*)&b[i]);\n        __m256i vec_result = _mm256_xor_si256(vec_a, vec_b);\n        _mm256_storeu_si256((__m256i*)&result[i], vec_result);\n    }\n\n    for (; i < len; ++i) {\n        result[i] = (a[i] == b[i]) ? '0' : '1';\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_69_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n#include <vector>\n#include <algorithm>\n\nstd::string longest_simd(const std::vector<std::string> & strings) {\n    if (strings.empty()) return \"\";\n\n    size_t max_length = 0;\n    std::string longest_str;\n\n    size_t n = strings.size();\n    size_t i = 0;\n\n    __m256i max_lengths = _mm256_setzero_si256();\n    __m256i current_lengths;\n\n    for (; i + 8 <= n; i += 8) {\n        current_lengths = _mm256_set_epi32(\n            strings[i + 7].size(),\n            strings[i + 6].size(),\n            strings[i + 5].size(),\n            strings[i + 4].size(),\n            strings[i + 3].size(),\n            strings[i + 2].size(),\n            strings[i + 1].size(),\n            strings[i].size()\n        );\n\n        max_lengths = _mm256_max_epi32(max_lengths, current_lengths);\n    }\n\n    int lengths[8];\n    _mm256_storeu_si256((__m256i*)lengths, max_lengths);\n    \n    for (int j = 0; j < 8; ++j) {\n        if (lengths[j] > max_length) {\n            max_length = lengths[j];\n            longest_str = strings[i - 8 + j];\n        }\n    }\n\n    for (; i < n; ++i) {\n        if (strings[i].size() > max_length) {\n            max_length = strings[i].size();\n            longest_str = strings[i];\n        }\n    }\n\n    return longest_str;\n}\n```"}
{"task_id": "SimdBench_69_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n#include <vector>\n#include <algorithm>\n#include <cstring>\n\nstd::string longest_simd(const std::vector<std::string> & strings) {\n    if (strings.empty()) return \"\";\n\n    size_t max_length = 0;\n    std::string longest_str;\n\n    size_t n = strings.size();\n    size_t i = 0;\n\n    // Process 32 bytes at a time (assuming each string is less than 32 characters)\n    for (; i + 4 <= n; i += 4) {\n        __m256i lengths = _mm256_set_epi64x(strings[i + 3].size(), strings[i + 2].size(), strings[i + 1].size(), strings[i].size());\n        __m256i max_lengths = _mm256_max_epi64(lengths, _mm256_set1_epi64x(max_length));\n\n        // Store the maximum length found\n        max_length = _mm256_extract_epi64(max_lengths, 0);\n        for (int j = 1; j < 4; ++j) {\n            max_length = std::max(max_length, (size_t)_mm256_extract_epi64(max_lengths, j));\n        }\n    }\n\n    // Handle remaining strings\n    for (; i < n; ++i) {\n        size_t len = strings[i].size();\n        if (len > max_length) {\n            max_length = len;\n            longest_str = strings[i];\n        }\n    }\n\n    // Find the longest string among those with the maximum length\n    for (const auto& str : strings) {\n        if (str.size() == max_length) {\n            longest_str = str;\n            break;\n        }\n    }\n\n    return longest_str;\n}\n```"}
{"task_id": "SimdBench_69_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n#include <vector>\n#include <algorithm>\n#include <cstring>\n\nstd::string longest_simd(const std::vector<std::string> & strings) {\n    if (strings.empty()) return \"\";\n\n    size_t max_length = 0;\n    std::string longest_str;\n\n    size_t n = strings.size();\n    size_t i = 0;\n\n    __m256i max_lengths = _mm256_setzero_si256();\n    __m256i indices = _mm256_setzero_si256();\n\n    for (; i + 8 <= n; i += 8) {\n        __m256i lengths = _mm256_setr_epi32(strings[i].size(), strings[i + 1].size(), strings[i + 2].size(), strings[i + 3].size(),\n                                             strings[i + 4].size(), strings[i + 5].size(), strings[i + 6].size(), strings[i + 7].size());\n\n        max_lengths = _mm256_max_epi32(max_lengths, lengths);\n        indices = _mm256_add_epi32(indices, _mm256_setr_epi32(0, 1, 2, 3, 4, 5, 6, 7));\n    }\n\n    int32_t max_lengths_array[8];\n    _mm256_storeu_si256((__m256i*)max_lengths_array, max_lengths);\n\n    for (int j = 0; j < 8; j++) {\n        if (max_lengths_array[j] > max_length) {\n            max_length = max_lengths_array[j];\n            longest_str = strings[i + j];\n        }\n    }\n\n    for (; i < n; ++i) {\n        if (strings[i].size() > max_length) {\n            max_length = strings[i].size();\n            longest_str = strings[i];\n        }\n    }\n\n    return longest_str;\n}\n```"}
{"task_id": "SimdBench_69_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n#include <vector>\n#include <algorithm>\n\nstd::string longest_simd(const std::vector<std::string> & strings) {\n    if (strings.empty()) return \"\";\n\n    size_t max_length = 0;\n    std::string longest_str;\n\n    size_t n = strings.size();\n    size_t i = 0;\n\n    // Process 8 strings at a time using AVX2\n    for (; i + 8 <= n; i += 8) {\n        __m256i lengths = _mm256_setr_epi32(\n            strings[i].size(),\n            strings[i + 1].size(),\n            strings[i + 2].size(),\n            strings[i + 3].size(),\n            strings[i + 4].size(),\n            strings[i + 5].size(),\n            strings[i + 6].size(),\n            strings[i + 7].size()\n        );\n\n        // Find the maximum length\n        __m256i max_lengths = _mm256_max_epi32(lengths, _mm256_permute4x64_epi64(lengths, _MM_SHUFFLE(2, 3, 0, 1)));\n        max_lengths = _mm256_max_epi32(max_lengths, _mm256_permute4x64_epi64(max_lengths, _MM_SHUFFLE(1, 0, 3, 2)));\n        max_lengths = _mm256_max_epi32(max_lengths, _mm256_permute4x64_epi64(max_lengths, _MM_SHUFFLE(0, 1, 2, 3)));\n\n        int32_t max_len[8];\n        _mm256_storeu_si256((__m256i*)max_len, max_lengths);\n        \n        for (int j = 0; j < 8; ++j) {\n            if (max_len[j] > max_length) {\n                max_length = max_len[j];\n                longest_str = strings[i + j];\n            }\n        }\n    }\n\n    // Process remaining strings\n    for (; i < n; ++i) {\n        if (strings[i].size() > max_length) {\n            max_length = strings[i].size();\n            longest_str = strings[i];\n        }\n    }\n\n    return longest_str;\n}\n```"}
{"task_id": "SimdBench_69_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n#include <vector>\n#include <algorithm>\n\nstd::string longest_simd(const std::vector<std::string> & strings) {\n    if (strings.empty()) return \"\";\n\n    size_t max_length = 0;\n    std::string longest_str;\n\n    size_t n = strings.size();\n    size_t i = 0;\n\n    // Process 8 strings at a time using AVX2\n    for (; i + 8 <= n; i += 8) {\n        __m256i max_lengths = _mm256_setzero_si256();\n        __m256i indices = _mm256_setzero_si256();\n\n        for (size_t j = 0; j < 8; ++j) {\n            const std::string &str = strings[i + j];\n            __m256i lengths = _mm256_set1_epi32(str.size());\n            max_lengths = _mm256_max_epi32(max_lengths, lengths);\n            indices = _mm256_blend_epi16(indices, _mm256_set1_epi32(j), (lengths == max_lengths) ? 0xFF : 0x00);\n        }\n\n        int32_t lengths[8];\n        _mm256_storeu_si256((__m256i*)lengths, max_lengths);\n        for (size_t j = 0; j < 8; ++j) {\n            if (lengths[j] > max_length) {\n                max_length = lengths[j];\n                longest_str = strings[i + j];\n            }\n        }\n    }\n\n    // Process remaining strings\n    for (; i < n; ++i) {\n        const std::string &str = strings[i];\n        if (str.size() > max_length) {\n            max_length = str.size();\n            longest_str = str;\n        }\n    }\n\n    return longest_str;\n}\n```"}
{"task_id": "SimdBench_70_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nuint64_t greatest_common_divisor_simd(uint64_t a, uint64_t b) {\n    __m256i va = _mm256_set1_epi64x(a);\n    __m256i vb = _mm256_set1_epi64x(b);\n    __m256i vzero = _mm256_setzero_si256();\n    \n    while (!_mm256_testz_si256(va, vb)) {\n        __m256i vmask = _mm256_cmpgt_epi64(va, vb);\n        __m256i vtemp = _mm256_and_si256(vmask, va);\n        va = _mm256_blendv_epi8(va, vb, vmask);\n        vb = vtemp;\n    }\n    \n    return _mm256_extract_epi64(va, 0);\n}\n```"}
{"task_id": "SimdBench_70_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nuint64_t greatest_common_divisor_simd(uint64_t a, uint64_t b) {\n    __m256i va = _mm256_set1_epi64x(a);\n    __m256i vb = _mm256_set1_epi64x(b);\n    __m256i gcd = va;\n\n    for (int i = 0; i < 64; i++) {\n        __m256i mod = _mm256_rem_epi64(gcd, vb);\n        __m256i zero = _mm256_setzero_si256();\n        __m256i mask = _mm256_cmpeq_epi64(mod, zero);\n        gcd = _mm256_blendv_epi8(gcd, vb, mask);\n        vb = mod;\n    }\n\n    return _mm256_extract_epi64(gcd, 0);\n}\n```"}
{"task_id": "SimdBench_70_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nuint64_t greatest_common_divisor_simd(uint64_t a, uint64_t b) {\n    __m256i va = _mm256_set1_epi64x(a);\n    __m256i vb = _mm256_set1_epi64x(b);\n    __m256i vzero = _mm256_setzero_si256();\n\n    while (!_mm256_testz_si256(va, vb)) {\n        __m256i vmask = _mm256_cmpgt_epi64(va, vb);\n        __m256i vtemp = _mm256_and_si256(vmask, va);\n        va = _mm256_blendv_epi8(va, vb, vmask);\n        vb = vtemp;\n    }\n\n    return _mm256_extract_epi64(va, 0);\n}\n```"}
{"task_id": "SimdBench_70_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nuint64_t greatest_common_divisor_simd(uint64_t a, uint64_t b) {\n    __m256i va = _mm256_set1_epi64x(a);\n    __m256i vb = _mm256_set1_epi64x(b);\n    __m256i vzero = _mm256_setzero_si256();\n\n    while (!_mm256_testz_si256(va, vb)) {\n        __m256i vmask = _mm256_cmpgt_epi64(va, vb);\n        __m256i vtemp = _mm256_and_si256(vmask, va);\n        va = _mm256_blendv_epi8(va, vb, vmask);\n        vb = vtemp;\n    }\n\n    return _mm256_extract_epi64(va, 0);\n}\n```"}
{"task_id": "SimdBench_70_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nuint64_t greatest_common_divisor_simd(uint64_t a, uint64_t b) {\n    __m256i va = _mm256_set1_epi64x(a);\n    __m256i vb = _mm256_set1_epi64x(b);\n    __m256i vzero = _mm256_setzero_si256();\n    \n    while (!_mm256_testz_si256(va, vb)) {\n        __m256i vmask = _mm256_cmpgt_epi64(va, vb);\n        __m256i vtemp = _mm256_and_si256(vmask, va);\n        va = _mm256_blendv_epi8(va, vb, vmask);\n        vb = _mm256_blendv_epi8(vb, vtemp, vmask);\n        \n        vmask = _mm256_cmpeq_epi64(vb, vzero);\n        if (_mm256_movemask_epi8(vmask)) {\n            break;\n        }\n    }\n    \n    return _mm256_extract_epi64(va, 0);\n}\n```"}
{"task_id": "SimdBench_71_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n#include <limits>\n#include <algorithm>\n\nstd::vector<float> find_closest_elements_simd(std::vector<float> numbers) {\n    size_t n = numbers.size();\n    if (n < 2) return {};\n\n    __m256 min_diff = _mm256_set1_ps(std::numeric_limits<float>::max());\n    __m256 closest_pair[2];\n\n    for (size_t i = 0; i < n - 7; i += 8) {\n        __m256 vec1 = _mm256_loadu_ps(&numbers[i]);\n        for (size_t j = i + 1; j < n; j++) {\n            __m256 vec2 = _mm256_set1_ps(numbers[j]);\n            __m256 diff = _mm256_sub_ps(vec1, vec2);\n            diff = _mm256_and_ps(diff, _mm256_cmp_ps(diff, _mm256_setzero_ps(), _CMP_GT_OS));\n            diff = _mm256_min_ps(diff, _mm256_sub_ps(vec2, vec1));\n            min_diff = _mm256_min_ps(min_diff, diff);\n            __m256 mask = _mm256_cmpeq_ps(diff, min_diff);\n            closest_pair[0] = _mm256_blendv_ps(closest_pair[0], vec1, mask);\n            closest_pair[1] = _mm256_blendv_ps(closest_pair[1], vec2, mask);\n        }\n    }\n\n    float min_diff_arr[8];\n    _mm256_storeu_ps(min_diff_arr, min_diff);\n    float closest[2] = {0, 0};\n    for (int i = 0; i < 8; i++) {\n        if (min_diff_arr[i] < std::numeric_limits<float>::max()) {\n            closest[0] = closest_pair[0][i];\n            closest[1] = closest_pair[1][i];\n        }\n    }\n\n    std::vector<float> result = {std::min(closest[0], closest[1]), std::max(closest[0], closest[1])};\n    return result;\n}\n```"}
{"task_id": "SimdBench_71_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n#include <limits>\n#include <algorithm>\n\nstd::vector<float> find_closest_elements_simd(std::vector<float> numbers) {\n    size_t n = numbers.size();\n    if (n < 2) return {};\n\n    float min_diff = std::numeric_limits<float>::max();\n    float closest_pair[2] = {0.0f, 0.0f};\n\n    for (size_t i = 0; i < n - 7; i += 8) {\n        __m256 vec1 = _mm256_loadu_ps(&numbers[i]);\n        for (size_t j = i + 1; j < n; ++j) {\n            __m256 vec2 = _mm256_set1_ps(numbers[j]);\n            __m256 diff = _mm256_sub_ps(vec1, vec2);\n            diff = _mm256_and_ps(diff, _mm256_cmp_ps(diff, _mm256_setzero_ps(), _MM_CMPINT_LT));\n            __m256 abs_diff = _mm256_max_ps(diff, _mm256_sub_ps(vec2, vec1));\n            float min_val[8];\n            _mm256_storeu_ps(min_val, abs_diff);\n            for (int k = 0; k < 8; ++k) {\n                if (min_val[k] < min_diff) {\n                    min_diff = min_val[k];\n                    closest_pair[0] = std::min(numbers[i + k], numbers[j]);\n                    closest_pair[1] = std::max(numbers[i + k], numbers[j]);\n                }\n            }\n        }\n    }\n\n    for (size_t i = n - (n % 8); i < n - 1; ++i) {\n        for (size_t j = i + 1; j < n; ++j) {\n            float diff = std::abs(numbers[i] - numbers[j]);\n            if (diff < min_diff) {\n                min_diff = diff;\n                closest_pair[0] = std::min(numbers[i], numbers[j]);\n                closest_pair[1] = std::max(numbers[i], numbers[j]);\n            }\n        }\n    }\n\n    return {closest_pair[0], closest_pair[1]};\n}\n```"}
{"task_id": "SimdBench_71_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n#include <algorithm>\n#include <limits>\n\nstd::vector<float> find_closest_elements_simd(std::vector<float> numbers) {\n    size_t n = numbers.size();\n    if (n < 2) return {};\n\n    float min_diff = std::numeric_limits<float>::max();\n    float closest_pair[2] = {0.0f, 0.0f};\n\n    for (size_t i = 0; i < n; i += 8) {\n        __m256 vec1 = _mm256_loadu_ps(&numbers[i]);\n        for (size_t j = i + 1; j < n; j += 8) {\n            __m256 vec2 = _mm256_loadu_ps(&numbers[j]);\n            __m256 diff = _mm256_sub_ps(vec1, vec2);\n            diff = _mm256_and_ps(diff, _mm256_cmp_ps(diff, _mm256_setzero_ps(), _CMP_GT_OS));\n            diff = _mm256_min_ps(diff, _mm256_sub_ps(vec2, vec1));\n            float temp_diff[8];\n            _mm256_storeu_ps(temp_diff, diff);\n            for (int k = 0; k < 8; k++) {\n                if (temp_diff[k] < min_diff) {\n                    min_diff = temp_diff[k];\n                    closest_pair[0] = std::min(numbers[i], numbers[j]);\n                    closest_pair[1] = std::max(numbers[i], numbers[j]);\n                }\n            }\n        }\n    }\n\n    return {closest_pair[0], closest_pair[1]};\n}\n```"}
{"task_id": "SimdBench_71_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n#include <limits>\n#include <algorithm>\n\nstd::vector<float> find_closest_elements_simd(std::vector<float> numbers) {\n    size_t n = numbers.size();\n    if (n < 2) return {};\n\n    __m256 min_diff = _mm256_set1_ps(std::numeric_limits<float>::max());\n    __m256 closest_pair[2];\n\n    for (size_t i = 0; i < n - 7; i += 8) {\n        __m256 vec1 = _mm256_loadu_ps(&numbers[i]);\n        for (size_t j = i + 1; j < n; j++) {\n            __m256 vec2 = _mm256_set1_ps(numbers[j]);\n            __m256 diff = _mm256_sub_ps(vec1, vec2);\n            diff = _mm256_and_ps(diff, _mm256_cmp_ps(diff, _mm256_setzero_ps(), _MM_CMPINT_LT));\n            __m256 abs_diff = _mm256_max_ps(diff, _mm256_sub_ps(vec2, vec1));\n            min_diff = _mm256_min_ps(min_diff, abs_diff);\n            __m256 mask = _mm256_cmpeq_ps(abs_diff, min_diff);\n            closest_pair[0] = _mm256_blendv_ps(closest_pair[0], vec1, mask);\n            closest_pair[1] = _mm256_blendv_ps(closest_pair[1], vec2, mask);\n        }\n    }\n\n    float min_diff_array[8];\n    _mm256_storeu_ps(min_diff_array, min_diff);\n    float closest_array[8][2];\n    for (int i = 0; i < 8; i++) {\n        closest_array[i][0] = closest_pair[0][i];\n        closest_array[i][1] = closest_pair[1][i];\n    }\n\n    float min_distance = std::numeric_limits<float>::max();\n    float result[2] = {0, 0};\n\n    for (int i = 0; i < 8; i++) {\n        if (min_diff_array[i] < min_distance) {\n            min_distance = min_diff_array[i];\n            result[0] = closest_array[i][0];\n            result[1] = closest_array[i][1];\n        }\n    }\n\n    std::vector<float> output = {std::min(result[0], result[1]), std::max(result[0], result[1])};\n    return output;\n}\n```"}
{"task_id": "SimdBench_71_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n#include <limits>\n#include <algorithm>\n\nstd::vector<float> find_closest_elements_simd(std::vector<float> numbers) {\n    size_t n = numbers.size();\n    if (n < 2) return {};\n\n    __m256 min_diff = _mm256_set1_ps(std::numeric_limits<float>::max());\n    __m256 closest_pair[2];\n\n    for (size_t i = 0; i < n; i += 8) {\n        __m256 vec1 = _mm256_loadu_ps(&numbers[i]);\n        for (size_t j = i + 1; j < n; j++) {\n            __m256 vec2 = _mm256_set1_ps(numbers[j]);\n            __m256 diff = _mm256_sub_ps(vec1, vec2);\n            diff = _mm256_and_ps(diff, _mm256_cmp_ps(diff, _mm256_setzero_ps(), _CMP_GT_OS));\n            diff = _mm256_min_ps(diff, _mm256_sub_ps(vec2, vec1));\n            min_diff = _mm256_min_ps(min_diff, diff);\n            __m256 mask = _mm256_cmpeq_ps(diff, min_diff);\n            closest_pair[0] = _mm256_blendv_ps(closest_pair[0], vec1, mask);\n            closest_pair[1] = _mm256_blendv_ps(closest_pair[1], vec2, mask);\n        }\n    }\n\n    float min_diff_arr[8];\n    _mm256_storeu_ps(min_diff_arr, min_diff);\n    float closest[2] = {0, 0};\n    for (int i = 0; i < 8; i++) {\n        if (min_diff_arr[i] < std::numeric_limits<float>::max()) {\n            closest[0] = closest_pair[0][i];\n            closest[1] = closest_pair[1][i];\n        }\n    }\n\n    std::sort(closest, closest + 2);\n    return {closest[0], closest[1]};\n}\n```"}
{"task_id": "SimdBench_72_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<float> rescale_to_unit_simd(std::vector<float> numbers) {\n    size_t n = numbers.size();\n    float min_val = *std::min_element(numbers.begin(), numbers.end());\n    float max_val = *std::max_element(numbers.begin(), numbers.end());\n    float range = max_val - min_val;\n\n    std::vector<float> result(n);\n    __m256 min_vec = _mm256_set1_ps(min_val);\n    __m256 range_vec = _mm256_set1_ps(range);\n\n    for (size_t i = 0; i < n; i += 8) {\n        __m256 num_vec = _mm256_loadu_ps(&numbers[i]);\n        __m256 scaled_vec = _mm256_div_ps(_mm256_sub_ps(num_vec, min_vec), range_vec);\n        _mm256_storeu_ps(&result[i], scaled_vec);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_72_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<float> rescale_to_unit_simd(std::vector<float> numbers) {\n    size_t n = numbers.size();\n    float min_val = *std::min_element(numbers.begin(), numbers.end());\n    float max_val = *std::max_element(numbers.begin(), numbers.end());\n    float range = max_val - min_val;\n\n    std::vector<float> result(n);\n    __m256 min_vec = _mm256_set1_ps(min_val);\n    __m256 range_vec = _mm256_set1_ps(range);\n\n    for (size_t i = 0; i < n; i += 8) {\n        __m256 num_vec = _mm256_loadu_ps(&numbers[i]);\n        __m256 scaled_vec = _mm256_div_ps(_mm256_sub_ps(num_vec, min_vec), range_vec);\n        _mm256_storeu_ps(&result[i], scaled_vec);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_72_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<float> rescale_to_unit_simd(std::vector<float> numbers) {\n    size_t n = numbers.size();\n    float min_val = *std::min_element(numbers.begin(), numbers.end());\n    float max_val = *std::max_element(numbers.begin(), numbers.end());\n    float range = max_val - min_val;\n\n    std::vector<float> result(n);\n    __m256 min_vec = _mm256_set1_ps(min_val);\n    __m256 range_vec = _mm256_set1_ps(range);\n\n    for (size_t i = 0; i < n; i += 8) {\n        __m256 num_vec = _mm256_loadu_ps(&numbers[i]);\n        __m256 scaled_vec = _mm256_div_ps(_mm256_sub_ps(num_vec, min_vec), range_vec);\n        _mm256_storeu_ps(&result[i], scaled_vec);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_72_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<float> rescale_to_unit_simd(std::vector<float> numbers) {\n    size_t n = numbers.size();\n    float min_val = *std::min_element(numbers.begin(), numbers.end());\n    float max_val = *std::max_element(numbers.begin(), numbers.end());\n    \n    __m256 min_vec = _mm256_set1_ps(min_val);\n    __m256 max_vec = _mm256_set1_ps(max_val);\n    __m256 range_vec = _mm256_sub_ps(max_vec, min_vec);\n    \n    std::vector<float> result(n);\n    \n    size_t i = 0;\n    for (; i + 8 <= n; i += 8) {\n        __m256 num_vec = _mm256_loadu_ps(&numbers[i]);\n        __m256 scaled_vec = _mm256_div_ps(_mm256_sub_ps(num_vec, min_vec), range_vec);\n        _mm256_storeu_ps(&result[i], scaled_vec);\n    }\n    \n    for (; i < n; ++i) {\n        result[i] = (numbers[i] - min_val) / (max_val - min_val);\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_72_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<float> rescale_to_unit_simd(std::vector<float> numbers) {\n    size_t n = numbers.size();\n    __m256 min_val = _mm256_set1_ps(*std::min_element(numbers.begin(), numbers.end()));\n    __m256 max_val = _mm256_set1_ps(*std::max_element(numbers.begin(), numbers.end()));\n    __m256 range = _mm256_sub_ps(max_val, min_val);\n    \n    std::vector<float> result(n);\n    for (size_t i = 0; i < n; i += 8) {\n        __m256 vec = _mm256_loadu_ps(&numbers[i]);\n        vec = _mm256_sub_ps(vec, min_val);\n        vec = _mm256_div_ps(vec, range);\n        _mm256_storeu_ps(&result[i], vec);\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_73_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nuint64_t largest_divisor_simd(uint64_t n) {\n    if (n <= 2) return 1;\n\n    __m256i n_vec = _mm256_set1_epi64x(n);\n    __m256i i_vec = _mm256_set_epi64x(n - 1, n - 2, n - 3, n - 4);\n    __m256i zero_vec = _mm256_setzero_si256();\n    \n    while (1) {\n        __m256i mod_vec = _mm256_rem_epi64(n_vec, i_vec);\n        __m256i cmp_vec = _mm256_cmpeq_epi64(mod_vec, zero_vec);\n        \n        if (_mm256_movemask_epi8(cmp_vec)) {\n            int mask = _mm256_movemask_epi8(cmp_vec);\n            for (int j = 0; j < 4; j++) {\n                if (mask & (1 << (j * 16))) {\n                    return _mm256_extract_epi64(i_vec, j);\n                }\n            }\n        }\n        \n        i_vec = _mm256_sub_epi64(i_vec, _mm256_set1_epi64x(4));\n    }\n}\n```"}
{"task_id": "SimdBench_73_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nuint64_t largest_divisor_simd(uint64_t n) {\n    if (n <= 2) return 1;\n\n    __m256i n_vec = _mm256_set1_epi64x(n);\n    __m256i one_vec = _mm256_set1_epi64x(1);\n    __m256i two_vec = _mm256_set1_epi64x(2);\n    __m256i max_divisor = _mm256_set1_epi64x(1);\n\n    for (uint64_t i = n - 1; i >= 2; i -= 4) {\n        __m256i i_vec = _mm256_set_epi64x(i - 3, i - 2, i - 1, i);\n        __m256i mod_vec = _mm256_rem_epi64(n_vec, i_vec);\n\n        __m256i mask = _mm256_cmpeq_epi64(mod_vec, _mm256_setzero_si256());\n        max_divisor = _mm256_blendv_epi8(max_divisor, i_vec, mask);\n        \n        if (i < 4) break;\n    }\n\n    return _mm256_extract_epi64(max_divisor, 0);\n}\n```"}
{"task_id": "SimdBench_73_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nuint64_t largest_divisor_simd(uint64_t n) {\n    if (n <= 2) return 1; // Handle edge case\n\n    __m256i vec_n = _mm256_set1_epi64x(n);\n    __m256i vec_i = _mm256_set_epi64x(n - 1, n - 2, n - 3, n - 4);\n    __m256i vec_result = _mm256_setzero_si256();\n\n    for (int i = 0; i < 4; i++) {\n        __m256i mod = _mm256_rem_epi64(vec_n, vec_i);\n        __m256i mask = _mm256_cmpeq_epi64(mod, _mm256_setzero_si256());\n        vec_result = _mm256_blendv_epi8(vec_result, vec_i, mask);\n        vec_i = _mm256_sub_epi64(vec_i, _mm256_set1_epi64x(1));\n    }\n\n    return _mm256_extract_epi64(vec_result, 0);\n}\n```"}
{"task_id": "SimdBench_73_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nuint64_t largest_divisor_simd(uint64_t n) {\n    if (n <= 2) return 1;\n\n    __m256i vec_n = _mm256_set1_epi64x(n);\n    __m256i vec_one = _mm256_set1_epi64x(1);\n    __m256i vec_two = _mm256_set1_epi64x(2);\n    \n    __m256i vec_divisors = _mm256_sub_epi64(vec_n, vec_two);\n    __m256i vec_result = _mm256_set1_epi64x(1);\n    \n    for (int i = 0; i < 64; i += 4) {\n        __m256i vec_indices = _mm256_add_epi64(vec_divisors, _mm256_set_epi64x(3, 2, 1, 0));\n        __m256i vec_mod = _mm256_rem_epi64(vec_n, vec_indices);\n        __m256i vec_zero = _mm256_setzero_si256();\n        \n        __m256i mask = _mm256_cmpeq_epi64(vec_mod, vec_zero);\n        vec_result = _mm256_blendv_epi8(vec_result, vec_indices, mask);\n        \n        vec_divisors = _mm256_sub_epi64(vec_divisors, vec_one);\n    }\n    \n    uint64_t result[4];\n    _mm256_storeu_si256((__m256i*)result, vec_result);\n    \n    for (int i = 0; i < 4; i++) {\n        if (result[i] < n) {\n            return result[i];\n        }\n    }\n    \n    return 1;\n}\n```"}
{"task_id": "SimdBench_73_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nuint64_t largest_divisor_simd(uint64_t n) {\n    if (n <= 2) return 1;\n\n    __m256i vec_n = _mm256_set1_epi64x(n);\n    __m256i vec_divisor = _mm256_set_epi64x(n - 1, n - 2, n - 3, n - 4);\n    __m256i vec_zero = _mm256_setzero_si256();\n    \n    while (true) {\n        __m256i remainder = _mm256_rem_epi64(vec_n, vec_divisor);\n        __m256i mask = _mm256_cmpeq_epi64(remainder, vec_zero);\n        \n        if (_mm256_movemask_epi8(mask) != 0) {\n            return _mm256_extract_epi64(vec_divisor, _mm256_movemask_epi8(mask) & 0xF);\n        }\n        \n        vec_divisor = _mm256_sub_epi64(vec_divisor, _mm256_set1_epi64x(1));\n    }\n}\n```"}
{"task_id": "SimdBench_74_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nstd::vector<int> factorize_simd(int n) {\n    std::vector<int> factors;\n    int original_n = n;\n\n    // Handle factor 2\n    while (n % 2 == 0) {\n        factors.push_back(2);\n        n /= 2;\n    }\n\n    // Handle odd factors from 3 to sqrt(n)\n    for (int i = 3; i * i <= n; i += 2) {\n        while (n % i == 0) {\n            factors.push_back(i);\n            n /= i;\n        }\n    }\n\n    // If n is still greater than 2, then it must be prime\n    if (n > 2) {\n        factors.push_back(n);\n    }\n\n    // Using AVX2 to vectorize the output\n    size_t size = factors.size();\n    size_t simd_size = size / 8 * 8; // Round down to the nearest multiple of 8\n    __m256i vec_factors[8];\n\n    for (size_t i = 0; i < simd_size; i += 8) {\n        vec_factors[i / 8] = _mm256_set_epi32(\n            factors[i + 7],\n            factors[i + 6],\n            factors[i + 5],\n            factors[i + 4],\n            factors[i + 3],\n            factors[i + 2],\n            factors[i + 1],\n            factors[i]\n        );\n    }\n\n    // Handle remaining factors\n    for (size_t i = simd_size; i < size; ++i) {\n        factors.push_back(factors[i]);\n    }\n\n    return factors;\n}\n```"}
{"task_id": "SimdBench_74_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nstd::vector<int> factorize_simd(int n) {\n    std::vector<int> factors;\n    if (n < 2) return factors;\n\n    // Check for number of 2s that divide n\n    while (n % 2 == 0) {\n        factors.push_back(2);\n        n /= 2;\n    }\n\n    // Check for odd factors from 3 to sqrt(n)\n    for (int i = 3; i * i <= n; i += 2) {\n        while (n % i == 0) {\n            factors.push_back(i);\n            n /= i;\n        }\n    }\n\n    // If n is a prime number greater than 2\n    if (n > 2) {\n        factors.push_back(n);\n    }\n\n    return factors;\n}\n```"}
{"task_id": "SimdBench_74_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nstd::vector<int> factorize_simd(int n) {\n    std::vector<int> factors;\n    int original_n = n;\n\n    // Handle factor 2\n    while (n % 2 == 0) {\n        factors.push_back(2);\n        n /= 2;\n    }\n\n    // Handle odd factors from 3 onwards\n    for (int i = 3; i * i <= n; i += 2) {\n        while (n % i == 0) {\n            factors.push_back(i);\n            n /= i;\n        }\n    }\n\n    // If n is still greater than 2, then it must be prime\n    if (n > 2) {\n        factors.push_back(n);\n    }\n\n    // Sort factors to ensure they are in order\n    std::sort(factors.begin(), factors.end());\n\n    return factors;\n}\n```"}
{"task_id": "SimdBench_74_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nstd::vector<int> factorize_simd(int n) {\n    std::vector<int> factors;\n    if (n < 2) return factors;\n\n    // Handle factor 2\n    while (n % 2 == 0) {\n        factors.push_back(2);\n        n /= 2;\n    }\n\n    // Handle odd factors from 3 upwards\n    for (int i = 3; i * i <= n; i += 2) {\n        while (n % i == 0) {\n            factors.push_back(i);\n            n /= i;\n        }\n    }\n\n    // If n is still greater than 2, then it must be prime\n    if (n > 2) {\n        factors.push_back(n);\n    }\n\n    return factors;\n}\n```"}
{"task_id": "SimdBench_74_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nstd::vector<int> factorize_simd(int n) {\n    std::vector<int> factors;\n    int original_n = n;\n\n    // Handle factor of 2\n    while (n % 2 == 0) {\n        factors.push_back(2);\n        n /= 2;\n    }\n\n    // Handle odd factors from 3 to sqrt(n)\n    for (int i = 3; i * i <= n; i += 2) {\n        while (n % i == 0) {\n            factors.push_back(i);\n            n /= i;\n        }\n    }\n\n    // If n is still greater than 2, then it is prime\n    if (n > 2) {\n        factors.push_back(n);\n    }\n\n    // Sort factors (not needed if we are adding in order)\n    // std::sort(factors.begin(), factors.end());\n\n    return factors;\n}\n```"}
{"task_id": "SimdBench_75_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nstd::vector<float> get_positive_simd(const std::vector<float> & l) {\n    size_t size = l.size();\n    size_t simd_size = size / 8 * 8; // Process in chunks of 8\n    std::vector<float> result;\n    \n    for (size_t i = 0; i < simd_size; i += 8) {\n        __m256 vec = _mm256_loadu_ps(&l[i]);\n        __m256 zero = _mm256_setzero_ps();\n        __m256 mask = _mm256_cmp_ps(vec, zero, _CMP_GT_OS);\n        __m256 positive_vec = _mm256_and_ps(vec, mask);\n        _mm256_storeu_ps(&result[i], positive_vec);\n    }\n\n    // Handle remaining elements\n    for (size_t i = simd_size; i < size; ++i) {\n        if (l[i] > 0) {\n            result.push_back(l[i]);\n        }\n    }\n\n    // Filter out zeros from the result\n    std::vector<float> final_result;\n    for (float val : result) {\n        if (val > 0) {\n            final_result.push_back(val);\n        }\n    }\n\n    return final_result;\n}\n```"}
{"task_id": "SimdBench_75_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nstd::vector<float> get_positive_simd(const std::vector<float> & l) {\n    size_t size = l.size();\n    size_t simd_size = 8; // AVX processes 8 floats at a time\n    std::vector<float> result;\n    result.reserve(size);\n\n    size_t i = 0;\n    __m256 zero = _mm256_setzero_ps();\n\n    for (; i + simd_size <= size; i += simd_size) {\n        __m256 vec = _mm256_loadu_ps(&l[i]);\n        __m256 mask = _mm256_cmp_ps(vec, zero, _CMP_GT_OS);\n        for (int j = 0; j < simd_size; j++) {\n            if (_mm256_extract_ps(mask, j) != 0) {\n                result.push_back(_mm256_extract_ps(vec, j));\n            }\n        }\n    }\n\n    for (; i < size; i++) {\n        if (l[i] > 0) {\n            result.push_back(l[i]);\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_75_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nstd::vector<float> get_positive_simd(const std::vector<float> & l) {\n    size_t size = l.size();\n    size_t simd_size = 8; // AVX can process 8 floats at once\n    std::vector<float> result;\n    result.reserve(size); // Reserve space to avoid multiple allocations\n\n    size_t i = 0;\n    for (; i + simd_size <= size; i += simd_size) {\n        __m256 vec = _mm256_loadu_ps(&l[i]);\n        __m256 mask = _mm256_cmp_ps(vec, _mm256_setzero_ps(), _CMP_GT_OS);\n        __m256 positive_vec = _mm256_and_ps(vec, mask);\n        _mm256_storeu_ps(&result[result.size()], positive_vec);\n        result.resize(result.size() + simd_size); // Resize to accommodate new elements\n    }\n\n    // Handle remaining elements\n    for (; i < size; ++i) {\n        if (l[i] > 0) {\n            result.push_back(l[i]);\n        }\n    }\n\n    // Remove zeroed elements from result\n    result.erase(std::remove(result.begin(), result.end(), 0.0f), result.end());\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_75_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nstd::vector<float> get_positive_simd(const std::vector<float> & l) {\n    size_t n = l.size();\n    std::vector<float> result;\n    result.reserve(n);\n\n    size_t i = 0;\n    __m256 zero = _mm256_setzero_ps();\n\n    for (; i + 8 <= n; i += 8) {\n        __m256 vec = _mm256_loadu_ps(&l[i]);\n        __m256 mask = _mm256_cmp_ps(vec, zero, _CMP_GT_OS);\n        __m256 positive = _mm256_blendv_ps(zero, vec, mask);\n        _mm256_storeu_ps(&result[result.size()], positive);\n        result.resize(result.size() + _mm_popcnt_u32(_mm256_movemask_ps(mask)));\n    }\n\n    for (; i < n; ++i) {\n        if (l[i] > 0) {\n            result.push_back(l[i]);\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_75_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nstd::vector<float> get_positive_simd(const std::vector<float> & l) {\n    size_t size = l.size();\n    size_t simd_size = size / 8;\n    size_t remainder = size % 8;\n    std::vector<float> result;\n\n    // Process 8 floats at a time\n    for (size_t i = 0; i < simd_size * 8; i += 8) {\n        __m256 vec = _mm256_loadu_ps(&l[i]);\n        __m256 mask = _mm256_cmp_ps(vec, _mm256_setzero_ps(), _CMP_GT_OS);\n        __m256 positive_vec = _mm256_and_ps(vec, mask);\n        _mm256_storeu_ps(&result[i], positive_vec);\n    }\n\n    // Handle remaining elements\n    for (size_t i = simd_size * 8; i < size; ++i) {\n        if (l[i] > 0) {\n            result.push_back(l[i]);\n        }\n    }\n\n    // Remove zeros from the result\n    result.erase(std::remove(result.begin(), result.end(), 0.0f), result.end());\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_76_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <stdint.h>\n#include <stdbool.h>\n\nbool is_prime_simd(int64_t n) {\n    if (n < 2) return false;\n    if (n == 2) return true;\n    if (n % 2 == 0) return false;\n\n    int64_t limit = (int64_t)sqrt(n);\n    __m256i vec_limit = _mm256_set1_epi64x(limit);\n    __m256i vec_n = _mm256_set1_epi64x(n);\n    __m256i vec_two = _mm256_set1_epi64x(2);\n    \n    for (int64_t i = 3; i <= limit; i += 2) {\n        __m256i vec_i = _mm256_set1_epi64x(i);\n        __m256i vec_div = _mm256_div_epi64(vec_n, vec_i);\n        __m256i vec_mod = _mm256_rem_epi64(vec_n, vec_i);\n        \n        __m256i mask = _mm256_cmpeq_epi64(vec_mod, _mm256_setzero_si256());\n        if (_mm256_movemask_epi8(mask) != 0) {\n            return false;\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_76_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <stdint.h>\n#include <stdbool.h>\n\nbool is_prime_simd(int64_t n) {\n    if (n < 2) return false;\n    if (n < 4) return true; // 2 and 3 are prime\n    if (n % 2 == 0) return false; // eliminate even numbers\n\n    int64_t limit = (int64_t)sqrt(n);\n    __m256i vec_limit = _mm256_set1_epi64x(limit);\n    __m256i vec_n = _mm256_set1_epi64x(n);\n    \n    for (int64_t i = 3; i <= limit; i += 2) {\n        __m256i vec_i = _mm256_set1_epi64x(i);\n        __m256i vec_div = _mm256_div_epi64(vec_n, vec_i);\n        __m256i vec_mod = _mm256_rem_epi64(vec_n, vec_i);\n        \n        // Check if any of the mod results is zero\n        if (_mm256_movemask_epi8(_mm256_cmpeq_epi64(vec_mod, _mm256_setzero_si256())) != 0) {\n            return false;\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_76_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <stdbool.h>\n\nbool is_prime_simd(int64_t n) {\n    if (n < 2) return false;\n    if (n == 2) return true;\n    if (n % 2 == 0) return false;\n\n    int64_t limit = (int64_t)sqrt(n);\n    __m256i vec_limit = _mm256_set1_epi64x(limit);\n    __m256i vec_n = _mm256_set1_epi64x(n);\n    __m256i vec_two = _mm256_set1_epi64x(2);\n    __m256i vec_index = _mm256_set_epi64x(0, 1, 2, 3, 4, 5, 6, 7);\n    \n    for (int64_t i = 3; i <= limit; i += 8) {\n        __m256i vec_i = _mm256_add_epi64(vec_index, _mm256_set1_epi64x(i));\n        __m256i vec_mod = _mm256_rem_epi64(vec_n, vec_i);\n        __m256i vec_zero = _mm256_setzero_si256();\n        __m256i cmp = _mm256_cmpeq_epi64(vec_mod, vec_zero);\n        \n        if (_mm256_movemask_epi8(cmp) != 0) {\n            return false;\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_76_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <stdint.h>\n#include <stdbool.h>\n\nbool is_prime_simd(int64_t n) {\n    if (n < 2) return false;\n    if (n < 4) return true; // 2 and 3 are prime\n\n    __m256i vec_n = _mm256_set1_epi64x(n);\n    __m256i vec_two = _mm256_set1_epi64x(2);\n    __m256i vec_three = _mm256_set1_epi64x(3);\n    __m256i vec_sqrt_n = _mm256_sqrt_epi64(vec_n);\n    \n    for (int64_t i = 2; i * i <= n; i += 2) {\n        __m256i vec_i = _mm256_set1_epi64x(i);\n        __m256i vec_i_squared = _mm256_mullo_epi64(vec_i, vec_i);\n        \n        if (_mm256_movemask_epi8(_mm256_cmpgt_epi64(vec_i_squared, vec_n)) != 0) {\n            break; // i^2 > n, no need to check further\n        }\n\n        if (n % i == 0) {\n            return false; // n is divisible by i\n        }\n        \n        if (i + 1 <= n && n % (i + 1) == 0) {\n            return false; // n is divisible by i + 1\n        }\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_76_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <stdint.h>\n#include <stdbool.h>\n\nbool is_prime_simd(int64_t n) {\n    if (n < 2) return false;\n    if (n == 2) return true;\n    if (n % 2 == 0) return false;\n\n    int64_t limit = (int64_t)sqrt(n);\n    __m256i vec_limit = _mm256_set1_epi64x(limit);\n    __m256i vec_n = _mm256_set1_epi64x(n);\n    \n    for (int64_t i = 3; i <= limit; i += 2) {\n        __m256i vec_i = _mm256_set1_epi64x(i);\n        __m256i vec_div = _mm256_div_epi64(vec_n, vec_i);\n        __m256i vec_mod = _mm256_rem_epi64(vec_n, vec_i);\n        \n        __m256i vec_zero = _mm256_setzero_si256();\n        __m256i cmp = _mm256_cmpeq_epi64(vec_mod, vec_zero);\n        \n        if (_mm256_movemask_epi8(cmp) != 0) {\n            return false;\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_77_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <string>\n#include <algorithm>\n\nstd::string solve_simd(const std::string & s) {\n    size_t n = s.size();\n    std::string result(n, ' ');\n\n    __m256i lower_mask = _mm256_set1_epi8(0x20); // Mask to toggle case\n    __m256i zero_mask = _mm256_set1_epi8('A' - 1); // Mask for letters\n    __m256i upper_mask = _mm256_set1_epi8('Z'); // Uppercase limit\n    __m256i lower_limit = _mm256_set1_epi8('a'); // Lowercase limit\n    __m256i lower_limit_check = _mm256_set1_epi8('z'); // Lowercase check\n\n    size_t i;\n    for (i = 0; i + 32 <= n; i += 32) {\n        __m256i data = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&s[i]));\n        __m256i is_lower = _mm256_and_si256(_mm256_cmpgt_epi8(data, lower_limit), _mm256_cmplt_epi8(data, lower_limit_check));\n        __m256i is_upper = _mm256_and_si256(_mm256_cmpgt_epi8(data, zero_mask), _mm256_cmplt_epi8(data, upper_mask));\n\n        __m256i toggled_case = _mm256_xor_si256(data, _mm256_or_si256(is_lower, is_upper));\n        __m256i result_data = _mm256_blendv_epi8(data, toggled_case, _mm256_or_si256(is_lower, is_upper));\n\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(&result[i]), result_data);\n    }\n\n    // Handle remaining characters\n    for (; i < n; ++i) {\n        char c = s[i];\n        if (c >= 'a' && c <= 'z') {\n            result[i] = c - 32; // Convert to uppercase\n        } else if (c >= 'A' && c <= 'Z') {\n            result[i] = c + 32; // Convert to lowercase\n        } else {\n            result[i] = c; // Keep as is\n        }\n    }\n\n    // Check if the string contains any letters\n    bool has_letters = std::any_of(s.begin(), s.end(), [](char c) { return std::isalpha(c); });\n    if (!has_letters) {\n        std::reverse(result.begin(), result.end());\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_77_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <string>\n#include <algorithm>\n\nstd::string solve_simd(const std::string & s) {\n    size_t n = s.size();\n    std::string result(n, ' ');\n\n    __m256i lower_mask = _mm256_set1_epi8(0x20);\n    __m256i upper_mask = _mm256_set1_epi8(0xDF);\n    __m256i alpha_mask = _mm256_set1_epi8(0x60);\n    \n    for (size_t i = 0; i < n; i += 32) {\n        __m256i input = _mm256_loadu_si256((__m256i*)&s[i]);\n        __m256i is_alpha = _mm256_and_si256(input, alpha_mask);\n        \n        __m256i lower_case = _mm256_cmpeq_epi8(is_alpha, _mm256_set1_epi8(0x20));\n        __m256i upper_case = _mm256_cmpeq_epi8(is_alpha, _mm256_set1_epi8(0x00));\n        \n        __m256i toggled = _mm256_xor_si256(input, lower_mask);\n        __m256i result_vec = _mm256_blendv_epi8(input, toggled, lower_case);\n        result_vec = _mm256_blendv_epi8(result_vec, input, upper_case);\n        \n        _mm256_storeu_si256((__m256i*)&result[i], result_vec);\n    }\n\n    if (n % 32 != 0) {\n        for (size_t i = n - (n % 32); i < n; ++i) {\n            if (isalpha(s[i])) {\n                result[i] = islower(s[i]) ? toupper(s[i]) : tolower(s[i]);\n            } else {\n                result[i] = s[n - 1 - (i - (n - (n % 32)))];\n            }\n        }\n    }\n\n    if (std::all_of(s.begin(), s.end(), [](char c) { return !isalpha(c); })) {\n        std::reverse(result.begin(), result.end());\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_77_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <string>\n#include <algorithm>\n\nstd::string solve_simd(const std::string & s) {\n    size_t n = s.size();\n    std::string result(n, ' ');\n\n    __m256i lower_mask = _mm256_set1_epi8(0x20);\n    __m256i upper_mask = _mm256_set1_epi8(0xDF);\n    __m256i digits_mask = _mm256_set1_epi8(0x30);\n    __m256i letters_mask = _mm256_set1_epi8(0x5A);\n    \n    size_t i = 0;\n    for (; i + 32 <= n; i += 32) {\n        __m256i data = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&s[i]));\n        __m256i lower = _mm256_and_si256(data, _mm256_set1_epi8(0x20));\n        __m256i upper = _mm256_and_si256(data, _mm256_set1_epi8(0xDF));\n        \n        __m256i is_letter = _mm256_or_si256(\n            _mm256_and_si256(_mm256_cmpgt_epi8(data, digits_mask), _mm256_cmplt_epi8(data, letters_mask)),\n            _mm256_and_si256(_mm256_cmpgt_epi8(data, upper_mask), _mm256_cmplt_epi8(data, lower_mask))\n        );\n\n        __m256i result_case = _mm256_xor_si256(data, lower_mask);\n        result_case = _mm256_blendv_epi8(data, result_case, is_letter);\n        \n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(&result[i]), result_case);\n    }\n\n    for (; i < n; ++i) {\n        if (isalpha(s[i])) {\n            result[i] = islower(s[i]) ? toupper(s[i]) : tolower(s[i]);\n        } else {\n            result[i] = s[i];\n        }\n    }\n\n    if (std::all_of(s.begin(), s.end(), [](char c) { return !isalpha(c); })) {\n        std::reverse(result.begin(), result.end());\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_77_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <string>\n#include <algorithm>\n\nstd::string solve_simd(const std::string & s) {\n    size_t n = s.size();\n    std::string result(n, ' ');\n\n    __m256i lower_mask = _mm256_set1_epi8(0x20); // Mask to toggle case\n    __m256i upper_mask = _mm256_set1_epi8(0xDF); // Mask for upper case\n    __m256i letters_mask = _mm256_set1_epi8(0x1F); // Mask to identify letters\n    __m256i ascii_a = _mm256_set1_epi8('a');\n    __m256i ascii_z = _mm256_set1_epi8('z');\n    __m256i ascii_A = _mm256_set1_epi8('A');\n    __m256i ascii_Z = _mm256_set1_epi8('Z');\n\n    size_t i = 0;\n    for (; i + 32 <= n; i += 32) {\n        __m256i data = _mm256_loadu_si256((__m256i*)&s[i]);\n        __m256i lower = _mm256_and_si256(data, lower_mask);\n        __m256i upper = _mm256_andnot_si256(lower_mask, data);\n        \n        __m256i is_lower = _mm256_and_si256(_mm256_cmpgt_epi8(data, ascii_a), _mm256_cmpgt_epi8(ascii_z, data));\n        __m256i is_upper = _mm256_and_si256(_mm256_cmpgt_epi8(data, ascii_A), _mm256_cmpgt_epi8(ascii_Z, data));\n        \n        __m256i toggled = _mm256_or_si256(lower, upper);\n        __m256i result_data = _mm256_blendv_epi8(data, toggled, is_lower);\n        \n        _mm256_storeu_si256((__m256i*)&result[i], result_data);\n    }\n\n    for (; i < n; ++i) {\n        if (isalpha(s[i])) {\n            result[i] = islower(s[i]) ? toupper(s[i]) : tolower(s[i]);\n        } else {\n            result[i] = s[n - 1 - i];\n        }\n    }\n\n    if (n == 0 || std::all_of(s.begin(), s.end(), [](char c) { return !isalpha(c); })) {\n        std::reverse(result.begin(), result.end());\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_77_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <string>\n#include <algorithm>\n\nstd::string solve_simd(const std::string & s) {\n    size_t n = s.size();\n    std::string result(n, ' ');\n\n    __m256i lower_mask = _mm256_set1_epi8(0x20);\n    __m256i upper_mask = _mm256_set1_epi8(0xDF);\n    __m256i letters_mask = _mm256_set1_epi8(0x1F);\n    __m256i zero_mask = _mm256_set1_epi8(0);\n    \n    for (size_t i = 0; i < n; i += 32) {\n        __m256i chunk = _mm256_loadu_si256((__m256i*)&s[i]);\n        \n        __m256i is_lower = _mm256_and_si256(chunk, _mm256_set1_epi8(0x20));\n        __m256i is_upper = _mm256_and_si256(chunk, _mm256_set1_epi8(0xDF));\n        \n        __m256i lower_case = _mm256_and_si256(is_lower, upper_mask);\n        __m256i upper_case = _mm256_and_si256(is_upper, lower_mask);\n        \n        __m256i result_chunk = _mm256_or_si256(lower_case, upper_case);\n        \n        // Check if there are any letters\n        __m256i has_letters = _mm256_cmpgt_epi8(_mm256_and_si256(chunk, letters_mask), zero_mask);\n        int mask = _mm256_movemask_epi8(has_letters);\n        \n        if (mask == 0) {\n            // No letters, reverse the string\n            std::reverse(result.begin() + i, result.begin() + std::min(i + 32, n));\n        } else {\n            _mm256_storeu_si256((__m256i*)&result[i], result_chunk);\n        }\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_78_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<int> sort_third_simd(std::vector<int> l) {\n    size_t n = l.size();\n    std::vector<int> result(n);\n    \n    // Process elements in chunks of 8 (AVX2 can handle 8 integers at a time)\n    for (size_t i = 0; i < n; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&l[i]);\n        \n        // Create a mask for indices divisible by 3\n        __m256i indices = _mm256_set_epi32(i + 7, i + 6, i + 5, i + 4, i + 3, i + 2, i + 1, i);\n        __m256i mask = _mm256_and_si256(_mm256_cmpeq_epi32(_mm256_rem_epi32(indices, _mm256_set1_epi32(3)), _mm256_setzero_si256()), _mm256_set1_epi32(1));\n        \n        // Store values that are not divisible by 3\n        _mm256_maskstore_epi32(&result[i], mask, vec);\n        \n        // Collect values that are divisible by 3\n        int temp[8];\n        _mm256_storeu_si256((__m256i*)temp, vec);\n        \n        std::vector<int> to_sort;\n        for (int j = 0; j < 8; j++) {\n            if ((i + j) % 3 == 0) {\n                to_sort.push_back(temp[j]);\n            }\n        }\n        \n        // Sort the collected values\n        std::sort(to_sort.begin(), to_sort.end());\n        \n        // Place sorted values back into the result vector\n        for (int j = 0, k = 0; j < 8; j++) {\n            if ((i + j) % 3 == 0) {\n                result[i + j] = to_sort[k++];\n            }\n        }\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_78_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<int> sort_third_simd(std::vector<int> l) {\n    size_t n = l.size();\n    std::vector<int> result(n);\n    \n    // Process elements in chunks of 8 (AVX2 can handle 8 integers at a time)\n    for (size_t i = 0; i < n; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&l[i]);\n        \n        // Create a mask for indices divisible by 3\n        __m256i indices = _mm256_set_epi32(i + 7, i + 6, i + 5, i + 4, i + 3, i + 2, i + 1, i);\n        __m256i mask = _mm256_and_si256(_mm256_cmpeq_epi32(_mm256_rem_epi32(indices, _mm256_set1_epi32(3)), _mm256_setzero_si256()), _mm256_set1_epi32(1));\n\n        // Store the values that are not divisible by 3\n        _mm256_maskstore_epi32(&result[i], mask, vec);\n        \n        // Extract values that are divisible by 3\n        int temp[8];\n        _mm256_storeu_si256((__m256i*)temp, vec);\n        \n        std::vector<int> to_sort;\n        for (int j = 0; j < 8; j++) {\n            if (i + j < n && (i + j) % 3 == 0) {\n                to_sort.push_back(temp[j]);\n            }\n        }\n        \n        // Sort the values that are divisible by 3\n        std::sort(to_sort.begin(), to_sort.end());\n        \n        // Place sorted values back into the result\n        for (size_t j = 0, k = 0; j < 8; j++) {\n            if (i + j < n && (i + j) % 3 == 0) {\n                result[i + j] = to_sort[k++];\n            }\n        }\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_78_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<int> sort_third_simd(std::vector<int> l) {\n    size_t n = l.size();\n    std::vector<int> result = l;\n\n    // Sort elements at indices divisible by 3\n    std::vector<int> to_sort;\n    for (size_t i = 0; i < n; i += 3) {\n        if (i < n) to_sort.push_back(l[i]);\n    }\n    std::sort(to_sort.begin(), to_sort.end());\n\n    // Place sorted elements back into the result vector\n    size_t sort_index = 0;\n    for (size_t i = 0; i < n; i++) {\n        if (i % 3 == 0) {\n            if (sort_index < to_sort.size()) {\n                result[i] = to_sort[sort_index++];\n            }\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_78_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<int> sort_third_simd(std::vector<int> l) {\n    size_t n = l.size();\n    std::vector<int> result(n);\n    \n    // Process elements in chunks of 8\n    for (size_t i = 0; i < n; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&l[i]);\n        \n        // Create a mask for indices divisible by 3\n        __m256i indices = _mm256_set_epi32(i + 7, i + 6, i + 5, i + 4, i + 3, i + 2, i + 1, i);\n        __m256i mask = _mm256_and_si256(_mm256_cmpeq_epi32(_mm256_rem_epi32(indices, _mm256_set1_epi32(3)), _mm256_setzero_si256()), _mm256_set1_epi32(1));\n        \n        // Store original values where not divisible by 3\n        _mm256_maskstore_epi32(&result[i], mask, vec);\n        \n        // Collect values for sorting\n        int values[8];\n        _mm256_storeu_si256((__m256i*)values, vec);\n        \n        // Sort only the values at indices divisible by 3\n        std::sort(values, values + 8, [](int a, int b) { return (a % 3 == 0) < (b % 3 == 0); });\n        \n        // Store sorted values back to result\n        for (size_t j = 0; j < 8; j++) {\n            if (j % 3 == 0) {\n                result[i + j] = values[j];\n            }\n        }\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_78_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<int> sort_third_simd(std::vector<int> l) {\n    size_t n = l.size();\n    std::vector<int> result(n);\n    \n    // Process elements in chunks of 8 (AVX2 can handle 256 bits = 8 integers)\n    size_t i = 0;\n    for (; i + 8 <= n; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&l[i]);\n        __m256i mask = _mm256_set1_epi32(0xFFFFFFFF);\n        __m256i indices = _mm256_set_epi32(7, 6, 5, 4, 3, 2, 1, 0);\n        \n        // Create a mask for indices divisible by 3\n        __m256i mod3 = _mm256_and_si256(indices, _mm256_set1_epi32(0x3));\n        __m256i maskDiv3 = _mm256_cmpeq_epi32(mod3, _mm256_setzero_si256());\n        \n        // Extract values that are divisible by 3\n        __m256i sortedValues = _mm256_blendv_epi8(vec, _mm256_set1_epi32(0), maskDiv3);\n        \n        // Sort the values that are divisible by 3\n        int temp[8];\n        _mm256_storeu_si256((__m256i*)temp, sortedValues);\n        std::sort(temp, temp + 8);\n        \n        // Place sorted values back into the result\n        for (int j = 0; j < 8; j++) {\n            if (j % 3 == 0) {\n                result[i + j] = temp[j];\n            } else {\n                result[i + j] = l[i + j];\n            }\n        }\n    }\n    \n    // Handle remaining elements\n    for (; i < n; i++) {\n        if (i % 3 == 0) {\n            result[i] = l[i]; // Placeholder for sorted value\n        } else {\n            result[i] = l[i];\n        }\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_79_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n#include <limits>\n\nfloat max_element_simd(std::vector<float> l) {\n    size_t size = l.size();\n    if (size == 0) return std::numeric_limits<float>::quiet_NaN();\n\n    __m256 max_vec = _mm256_set1_ps(l[0]);\n    \n    for (size_t i = 0; i < size; i += 8) {\n        __m256 vec = _mm256_loadu_ps(&l[i]);\n        max_vec = _mm256_max_ps(max_vec, vec);\n    }\n\n    float max_arr[8];\n    _mm256_storeu_ps(max_arr, max_vec);\n    \n    float max_val = max_arr[0];\n    for (int i = 1; i < 8; i++) {\n        max_val = std::max(max_val, max_arr[i]);\n    }\n\n    return max_val;\n}\n```"}
{"task_id": "SimdBench_79_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n#include <limits>\n\nfloat max_element_simd(std::vector<float> l) {\n    size_t size = l.size();\n    if (size == 0) return std::numeric_limits<float>::quiet_NaN();\n\n    __m256 max_val = _mm256_set1_ps(l[0]);\n    \n    size_t i;\n    for (i = 0; i + 8 <= size; i += 8) {\n        __m256 vec = _mm256_loadu_ps(&l[i]);\n        max_val = _mm256_max_ps(max_val, vec);\n    }\n\n    float max_array[8];\n    _mm256_storeu_ps(max_array, max_val);\n    \n    float max_result = max_array[0];\n    for (int j = 1; j < 8; j++) {\n        max_result = std::max(max_result, max_array[j]);\n    }\n\n    for (; i < size; i++) {\n        max_result = std::max(max_result, l[i]);\n    }\n\n    return max_result;\n}\n```"}
{"task_id": "SimdBench_79_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n#include <limits>\n\nfloat max_element_simd(std::vector<float> l) {\n    size_t size = l.size();\n    if (size == 0) return std::numeric_limits<float>::quiet_NaN();\n\n    __m256 max_vec = _mm256_set1_ps(l[0]);\n    size_t i = 1;\n\n    for (; i + 7 < size; i += 8) {\n        __m256 vec = _mm256_loadu_ps(&l[i]);\n        max_vec = _mm256_max_ps(max_vec, vec);\n    }\n\n    float max_array[8];\n    _mm256_storeu_ps(max_array, max_vec);\n\n    float max_value = max_array[0];\n    for (int j = 1; j < 8; j++) {\n        max_value = std::max(max_value, max_array[j]);\n    }\n\n    for (; i < size; i++) {\n        max_value = std::max(max_value, l[i]);\n    }\n\n    return max_value;\n}\n```"}
{"task_id": "SimdBench_79_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n#include <limits>\n\nfloat max_element_simd(std::vector<float> l) {\n    __m256 max_vec = _mm256_set1_ps(std::numeric_limits<float>::lowest());\n    size_t size = l.size();\n    size_t i;\n\n    for (i = 0; i + 8 <= size; i += 8) {\n        __m256 vec = _mm256_loadu_ps(&l[i]);\n        max_vec = _mm256_max_ps(max_vec, vec);\n    }\n\n    float max_array[8];\n    _mm256_storeu_ps(max_array, max_vec);\n\n    float max_value = max_array[0];\n    for (int j = 1; j < 8; j++) {\n        max_value = std::max(max_value, max_array[j]);\n    }\n\n    for (; i < size; i++) {\n        max_value = std::max(max_value, l[i]);\n    }\n\n    return max_value;\n}\n```"}
{"task_id": "SimdBench_79_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n#include <algorithm>\n\nfloat max_element_simd(std::vector<float> l) {\n    size_t size = l.size();\n    if (size == 0) return 0; // Handle empty vector case\n\n    __m256 max_vec = _mm256_set1_ps(l[0]);\n    \n    size_t i;\n    for (i = 0; i + 8 <= size; i += 8) {\n        __m256 vec = _mm256_loadu_ps(&l[i]);\n        max_vec = _mm256_max_ps(max_vec, vec);\n    }\n\n    float max_array[8];\n    _mm256_storeu_ps(max_array, max_vec);\n    \n    float max_val = max_array[0];\n    for (int j = 1; j < 8; j++) {\n        max_val = std::max(max_val, max_array[j]);\n    }\n\n    for (; i < size; i++) {\n        max_val = std::max(max_val, l[i]);\n    }\n\n    return max_val;\n}\n```"}
{"task_id": "SimdBench_80_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nint fizz_buzz_simd(int n) {\n    if (n < 7) return 0;\n\n    int count = 0;\n    __m256i seven = _mm256_set1_epi32(7);\n    __m256i divisor11 = _mm256_set1_epi32(11);\n    __m256i divisor13 = _mm256_set1_epi32(13);\n    __m256i mask = _mm256_set1_epi32(0xFFFFFFFF);\n    \n    for (int i = 0; i < n; i += 8) {\n        __m256i indices = _mm256_add_epi32(_mm256_set1_epi32(i), _mm256_set_epi32(7, 6, 5, 4, 3, 2, 1, 0));\n        __m256i divisible = _mm256_or_si256(_mm256_cmpeq_epi32(_mm256_rem_epi32(indices, divisor11), _mm256_setzero_si256()),\n                                            _mm256_cmpeq_epi32(_mm256_rem_epi32(indices, divisor13), _mm256_setzero_si256()));\n        \n        __m256i is_seven = _mm256_cmpeq_epi32(indices, seven);\n        __m256i result = _mm256_and_si256(divisible, is_seven);\n        \n        count += _mm256_movemask_epi8(result);\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_80_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nint fizz_buzz_simd(int n) {\n    int count = 0;\n    __m256i seven = _mm256_set1_epi8('7');\n    __m256i zero = _mm256_set1_epi8('0');\n    __m256i eleven = _mm256_set1_epi32(11);\n    __m256i thirteen = _mm256_set1_epi32(13);\n    __m256i n_vec = _mm256_set1_epi32(n);\n    \n    for (int i = 0; i < n; i += 32) {\n        __m256i indices = _mm256_setr_epi32(i, i + 1, i + 2, i + 3, i + 4, i + 5, i + 6, i + 7,\n                                             i + 8, i + 9, i + 10, i + 11, i + 12, i + 13, i + 14, i + 15);\n        __m256i div11 = _mm256_rem_epi32(indices, eleven);\n        __m256i div13 = _mm256_rem_epi32(indices, thirteen);\n        __m256i mask11 = _mm256_cmpeq_epi32(div11, _mm256_setzero_si256());\n        __m256i mask13 = _mm256_cmpeq_epi32(div13, _mm256_setzero_si256());\n        __m256i mask = _mm256_or_si256(mask11, mask13);\n        \n        for (int j = 0; j < 32; j++) {\n            if (i + j < n) {\n                int num = i + j;\n                if (mask[j] && (num % 11 == 0 || num % 13 == 0)) {\n                    char str[12];\n                    int len = snprintf(str, sizeof(str), \"%d\", num);\n                    for (int k = 0; k < len; k++) {\n                        if (str[k] == '7') {\n                            count++;\n                        }\n                    }\n                }\n            }\n        }\n    }\n    return count;\n}\n```"}
{"task_id": "SimdBench_80_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nint fizz_buzz_simd(int n) {\n    int count = 0;\n    __m256i seven_mask = _mm256_set1_epi32(7);\n    __m256i eleven = _mm256_set1_epi32(11);\n    __m256i thirteen = _mm256_set1_epi32(13);\n    __m256i n_vec = _mm256_set1_epi32(n);\n    \n    for (int i = 0; i < n; i += 8) {\n        __m256i indices = _mm256_add_epi32(_mm256_set1_epi32(i), _mm256_set_epi32(7, 6, 5, 4, 3, 2, 1, 0));\n        __m256i divisible_by_11 = _mm256_cmpeq_epi32(_mm256_rem_epi32(indices, eleven), _mm256_setzero_si256());\n        __m256i divisible_by_13 = _mm256_cmpeq_epi32(_mm256_rem_epi32(indices, thirteen), _mm256_setzero_si256());\n        __m256i divisible = _mm256_or_si256(divisible_by_11, divisible_by_13);\n        \n        __m256i digit_count = _mm256_setzero_si256();\n        \n        for (int j = 0; j < 8; j++) {\n            int num = i + j;\n            if (num < n) {\n                int temp = num;\n                while (temp > 0) {\n                    if (temp % 10 == 7) {\n                        digit_count = _mm256_add_epi32(digit_count, _mm256_set1_epi32(1));\n                    }\n                    temp /= 10;\n                }\n            }\n        }\n        \n        __m256i result = _mm256_and_si256(divisible, digit_count);\n        count += _mm256_reduce_add_epi32(result);\n    }\n    \n    return count;\n}\n```"}
{"task_id": "SimdBench_80_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nint fizz_buzz_simd(int n) {\n    int count = 0;\n    int limit = n < 0 ? 0 : n;\n    __m256i seven = _mm256_set1_epi32(7);\n    __m256i eleven = _mm256_set1_epi32(11);\n    __m256i thirteen = _mm256_set1_epi32(13);\n    __m256i count_vec = _mm256_setzero_si256();\n\n    for (int i = 0; i < limit; i += 8) {\n        __m256i indices = _mm256_set_epi32(i + 7, i + 6, i + 5, i + 4, i + 3, i + 2, i + 1, i);\n        __m256i divisible = _mm256_or_si256(_mm256_cmpeq_epi32(_mm256_rem_epi32(indices, eleven), _mm256_setzero_si256()),\n                                            _mm256_cmpeq_epi32(_mm256_rem_epi32(indices, thirteen), _mm256_setzero_si256()));\n\n        __m256i digits = _mm256_setzero_si256();\n        for (int j = 0; j < 8; j++) {\n            if (i + j < limit) {\n                int num = i + j;\n                while (num > 0) {\n                    if (num % 10 == 7) {\n                        digits = _mm256_insert_epi32(digits, 1, j);\n                        break;\n                    }\n                    num /= 10;\n                }\n            }\n        }\n\n        __m256i result = _mm256_and_si256(divisible, digits);\n        count_vec = _mm256_add_epi32(count_vec, result);\n    }\n\n    int result[8];\n    _mm256_storeu_si256((__m256i*)result, count_vec);\n    for (int i = 0; i < 8; i++) {\n        count += result[i];\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_80_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nint fizz_buzz_simd(int n) {\n    int count = 0;\n    int limit = n / 11 + 1; // Calculate the limit for 11\n    int limit13 = n / 13 + 1; // Calculate the limit for 13\n    int total_limit = limit > limit13 ? limit : limit13;\n\n    __m256i seven = _mm256_set1_epi32(7);\n    __m256i count_vec = _mm256_setzero_si256();\n\n    for (int i = 0; i < total_limit; i += 8) {\n        __m256i indices = _mm256_setr_epi32(i, i + 1, i + 2, i + 3, i + 4, i + 5, i + 6, i + 7);\n        __m256i divisible_by_11 = _mm256_and_si256(_mm256_cmpeq_epi32(_mm256_rem_epi32(indices, _mm256_set1_epi32(11)), _mm256_setzero_si256()), _mm256_cmpgt_epi32(indices, _mm256_setzero_si256()));\n        __m256i divisible_by_13 = _mm256_and_si256(_mm256_cmpeq_epi32(_mm256_rem_epi32(indices, _mm256_set1_epi32(13)), _mm256_setzero_si256()), _mm256_cmpgt_epi32(indices, _mm256_setzero_si256()));\n        __m256i valid_numbers = _mm256_or_si256(divisible_by_11, divisible_by_13);\n\n        // Check for digit 7\n        for (int j = 0; j < 8; j++) {\n            int num = i + j;\n            if (num < n && (valid_numbers[j] != 0)) {\n                while (num > 0) {\n                    if (num % 10 == 7) {\n                        count_vec = _mm256_add_epi32(count_vec, _mm256_set1_epi32(1));\n                        break;\n                    }\n                    num /= 10;\n                }\n            }\n        }\n    }\n\n    // Horizontal sum of count_vec\n    count_vec = _mm256_hadd_epi32(count_vec, count_vec);\n    count_vec = _mm256_hadd_epi32(count_vec, count_vec);\n    count += _mm256_extract_epi32(count_vec, 0) + _mm256_extract_epi32(count_vec, 4);\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_81_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<float> sort_even_simd(std::vector<float> l) {\n    size_t n = l.size();\n    std::vector<float> even_indices;\n\n    // Collect even indices\n    for (size_t i = 0; i < n; i += 2) {\n        even_indices.push_back(l[i]);\n    }\n\n    // Sort the even indices\n    std::sort(even_indices.begin(), even_indices.end());\n\n    // Place sorted even values back into the original vector\n    for (size_t i = 0, j = 0; i < n; i += 2, j++) {\n        l[i] = even_indices[j];\n    }\n\n    return l;\n}\n```"}
{"task_id": "SimdBench_81_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<float> sort_even_simd(std::vector<float> l) {\n    size_t n = l.size();\n    std::vector<float> even_indices;\n\n    // Collect even indices\n    for (size_t i = 0; i < n; i += 2) {\n        even_indices.push_back(l[i]);\n    }\n\n    // Sort the even indices\n    std::sort(even_indices.begin(), even_indices.end());\n\n    // Place sorted even indices back into the original vector\n    for (size_t i = 0, j = 0; i < n; i += 2, j++) {\n        l[i] = even_indices[j];\n    }\n\n    return l;\n}\n```"}
{"task_id": "SimdBench_81_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<float> sort_even_simd(std::vector<float> l) {\n    size_t n = l.size();\n    std::vector<float> even_indices;\n\n    // Collect even indices\n    for (size_t i = 0; i < n; i += 2) {\n        even_indices.push_back(l[i]);\n    }\n\n    // Sort the even indices\n    std::sort(even_indices.begin(), even_indices.end());\n\n    // Place sorted even indices back into the original vector\n    for (size_t i = 0, j = 0; i < n; i += 2, j++) {\n        l[i] = even_indices[j];\n    }\n\n    return l;\n}\n```"}
{"task_id": "SimdBench_81_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<float> sort_even_simd(std::vector<float> l) {\n    size_t n = l.size();\n    std::vector<float> even_indices;\n\n    // Collect even indexed elements\n    for (size_t i = 0; i < n; i += 2) {\n        even_indices.push_back(l[i]);\n    }\n\n    // Sort the even indexed elements\n    std::sort(even_indices.begin(), even_indices.end());\n\n    // Place sorted even indexed elements back into the original vector\n    for (size_t i = 0, j = 0; i < n; i += 2, j++) {\n        l[i] = even_indices[j];\n    }\n\n    return l;\n}\n```"}
{"task_id": "SimdBench_81_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<float> sort_even_simd(std::vector<float> l) {\n    size_t n = l.size();\n    std::vector<float> even_indices;\n\n    // Collect even indices\n    for (size_t i = 0; i < n; i += 2) {\n        even_indices.push_back(l[i]);\n    }\n\n    // Sort the even indices\n    std::sort(even_indices.begin(), even_indices.end());\n\n    // Place sorted even indices back into the original vector\n    for (size_t i = 0, j = 0; i < n; i += 2, j++) {\n        l[i] = even_indices[j];\n    }\n\n    return l;\n}\n```"}
{"task_id": "SimdBench_82_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n#include <unordered_set>\n\nbool triples_sum_to_zero_simd(std::vector<int> l) {\n    int n = l.size();\n    if (n < 3) return false;\n\n    std::unordered_set<int> seen;\n\n    for (int i = 0; i < n; ++i) {\n        seen.insert(l[i]);\n    }\n\n    for (int i = 0; i < n; ++i) {\n        for (int j = i + 1; j < n; ++j) {\n            int target = -(l[i] + l[j]);\n            if (seen.find(target) != seen.end() && target != l[i] && target != l[j]) {\n                return true;\n            }\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_82_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n#include <unordered_set>\n\nbool triples_sum_to_zero_simd(std::vector<int> l) {\n    int n = l.size();\n    if (n < 3) return false;\n\n    std::unordered_set<int> seen;\n\n    for (int i = 0; i < n; ++i) {\n        seen.insert(l[i]);\n    }\n\n    for (int i = 0; i < n; ++i) {\n        for (int j = i + 1; j < n; ++j) {\n            int target = -(l[i] + l[j]);\n            if (seen.find(target) != seen.end() && target != l[i] && target != l[j]) {\n                return true;\n            }\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_82_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n#include <unordered_set>\n\nbool triples_sum_to_zero_simd(std::vector<int> l) {\n    int n = l.size();\n    if (n < 3) return false;\n\n    std::unordered_set<int> seen;\n\n    for (int i = 0; i < n; ++i) {\n        seen.insert(l[i]);\n    }\n\n    for (int i = 0; i < n; ++i) {\n        for (int j = i + 1; j < n; ++j) {\n            int target = -(l[i] + l[j]);\n            if (seen.find(target) != seen.end() && target != l[i] && target != l[j]) {\n                return true;\n            }\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_82_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n#include <unordered_set>\n\nbool triples_sum_to_zero_simd(std::vector<int> l) {\n    int n = l.size();\n    if (n < 3) return false;\n\n    std::unordered_set<int> seen;\n\n    for (int i = 0; i < n; ++i) {\n        seen.insert(l[i]);\n    }\n\n    for (int i = 0; i < n; ++i) {\n        for (int j = i + 1; j < n; ++j) {\n            int target = -(l[i] + l[j]);\n            if (seen.find(target) != seen.end() && target != l[i] && target != l[j]) {\n                return true;\n            }\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_82_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n#include <unordered_set>\n\nbool triples_sum_to_zero_simd(std::vector<int> l) {\n    int n = l.size();\n    if (n < 3) return false;\n\n    std::unordered_set<int> seen;\n\n    for (int i = 0; i < n; ++i) {\n        seen.insert(l[i]);\n    }\n\n    for (int i = 0; i < n; ++i) {\n        for (int j = i + 1; j < n; ++j) {\n            int target = -(l[i] + l[j]);\n            if (seen.find(target) != seen.end() && target != l[i] && target != l[j]) {\n                return true;\n            }\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_83_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nstd::vector<int> incr_list_simd(std::vector<int> l) {\n    size_t n = l.size();\n    size_t i = 0;\n\n    // Process 8 integers at a time using AVX2\n    for (; i + 8 <= n; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&l[i]);\n        vec = _mm256_add_epi32(vec, _mm256_set1_epi32(1));\n        _mm256_storeu_si256((__m256i*)&l[i], vec);\n    }\n\n    // Handle remaining elements\n    for (; i < n; ++i) {\n        l[i] += 1;\n    }\n\n    return l;\n}\n```"}
{"task_id": "SimdBench_83_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nstd::vector<int> incr_list_simd(std::vector<int> l) {\n    size_t size = l.size();\n    size_t i = 0;\n\n    // Process 8 integers at a time using AVX2\n    for (; i + 8 <= size; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&l[i]);\n        vec = _mm256_add_epi32(vec, _mm256_set1_epi32(1));\n        _mm256_storeu_si256((__m256i*)&l[i], vec);\n    }\n\n    // Handle remaining elements\n    for (; i < size; ++i) {\n        l[i] += 1;\n    }\n\n    return l;\n}\n```"}
{"task_id": "SimdBench_83_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nstd::vector<int> incr_list_simd(std::vector<int> l) {\n    size_t n = l.size();\n    size_t i;\n\n    // Process 8 integers at a time using AVX2\n    for (i = 0; i + 8 <= n; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&l[i]);\n        vec = _mm256_add_epi32(vec, _mm256_set1_epi32(1));\n        _mm256_storeu_si256((__m256i*)&l[i], vec);\n    }\n\n    // Handle remaining elements\n    for (; i < n; i++) {\n        l[i] += 1;\n    }\n\n    return l;\n}\n```"}
{"task_id": "SimdBench_83_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nstd::vector<int> incr_list_simd(std::vector<int> l) {\n    size_t n = l.size();\n    size_t i = 0;\n\n    // Process 8 integers at a time using AVX2\n    for (; i + 8 <= n; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&l[i]);\n        vec = _mm256_add_epi32(vec, _mm256_set1_epi32(1));\n        _mm256_storeu_si256((__m256i*)&l[i], vec);\n    }\n\n    // Handle remaining elements\n    for (; i < n; ++i) {\n        l[i] += 1;\n    }\n\n    return l;\n}\n```"}
{"task_id": "SimdBench_83_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nstd::vector<int> incr_list_simd(std::vector<int> l) {\n    size_t n = l.size();\n    size_t i = 0;\n\n    // Prepare the output vector\n    std::vector<int> result(n);\n\n    // Process 8 integers at a time using AVX2\n    for (; i + 8 <= n; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&l[i]); // Load 8 integers\n        vec = _mm256_add_epi32(vec, _mm256_set1_epi32(1)); // Increment by 1\n        _mm256_storeu_si256((__m256i*)&result[i], vec); // Store the result\n    }\n\n    // Handle remaining elements\n    for (; i < n; ++i) {\n        result[i] = l[i] + 1;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_84_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n#include <unordered_set>\n\nbool pairs_sum_to_zero_simd(std::vector<int> l) {\n    std::unordered_set<int> seen;\n    size_t size = l.size();\n\n    for (size_t i = 0; i < size; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&l[i]);\n        for (int j = 0; j < 8; j++) {\n            if (i + j < size) {\n                int value = l[i + j];\n                if (seen.count(-value)) {\n                    return true;\n                }\n                seen.insert(value);\n            }\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_84_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n#include <unordered_set>\n\nbool pairs_sum_to_zero_simd(std::vector<int> l) {\n    if (l.size() < 2) return false;\n\n    std::unordered_set<int> seen;\n    size_t size = l.size();\n    size_t i = 0;\n\n    // Process 8 integers at a time using AVX2\n    for (; i + 8 <= size; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&l[i]);\n        __m256i neg_vec = _mm256_sub_epi32(_mm256_setzero_si256(), vec);\n        \n        for (int j = 0; j < 8; j++) {\n            int value = _mm256_extract_epi32(vec, j);\n            if (seen.count(value) || seen.count(-value)) {\n                return true;\n            }\n            seen.insert(value);\n        }\n    }\n\n    // Process remaining integers\n    for (; i < size; i++) {\n        int value = l[i];\n        if (seen.count(value) || seen.count(-value)) {\n            return true;\n        }\n        seen.insert(value);\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_84_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n#include <unordered_set>\n\nbool pairs_sum_to_zero_simd(std::vector<int> l) {\n    std::unordered_set<int> seen;\n    size_t size = l.size();\n\n    for (size_t i = 0; i < size; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&l[i]);\n        for (int j = 0; j < 8; j++) {\n            if (i + j < size) {\n                int value = l[i + j];\n                if (seen.count(-value)) {\n                    return true;\n                }\n                seen.insert(value);\n            }\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_84_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n#include <unordered_set>\n\nbool pairs_sum_to_zero_simd(std::vector<int> l) {\n    std::unordered_set<int> seen;\n    size_t size = l.size();\n\n    for (size_t i = 0; i < size; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&l[i]);\n        for (int j = 0; j < 8; j++) {\n            if (i + j < size) {\n                int value = l[i + j];\n                if (seen.count(-value)) {\n                    return true;\n                }\n                seen.insert(value);\n            }\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_84_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n#include <unordered_set>\n\nbool pairs_sum_to_zero_simd(std::vector<int> l) {\n    std::unordered_set<int> seen;\n    size_t size = l.size();\n\n    for (size_t i = 0; i < size; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&l[i]);\n        for (int j = 0; j < 8; j++) {\n            if (i + j < size) {\n                int value = l[i + j];\n                if (seen.count(-value)) {\n                    return true;\n                }\n                seen.insert(value);\n            }\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_85_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n#include <vector>\n\nstd::string change_base_simd(int64_t x, int8_t base) {\n    if (base < 2 || base > 9) return \"\"; // base must be between 2 and 9\n    std::vector<char> result;\n    __m256i base_vec = _mm256_set1_epi8(base);\n    __m256i zero_vec = _mm256_set1_epi8('0');\n\n    while (x > 0) {\n        __m256i x_vec = _mm256_set1_epi64x(x);\n        __m256i remainder = _mm256_rem_epi64(x_vec, base_vec);\n        __m256i char_vec = _mm256_add_epi8(remainder, zero_vec);\n        \n        for (int i = 0; i < 32; i++) {\n            char c = _mm256_extract_epi8(char_vec, i);\n            if (c != 0) result.push_back(c);\n        }\n\n        x = _mm256_extract_epi64(x_vec, 0) / base; // Update x for next iteration\n    }\n\n    std::reverse(result.begin(), result.end());\n    return std::string(result.begin(), result.end());\n}\n```"}
{"task_id": "SimdBench_85_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n#include <vector>\n\nstd::string change_base_simd(int64_t x, int8_t base) {\n    if (base < 2 || base > 9) return \"\"; // Invalid base\n\n    std::vector<char> result;\n    __m256i base_vec = _mm256_set1_epi8(base);\n    __m256i zero_vec = _mm256_set1_epi8('0');\n    \n    while (x > 0) {\n        __m256i x_vec = _mm256_set1_epi64x(x);\n        __m256i remainder_vec = _mm256_rem_epi64(x_vec, base_vec);\n        __m256i char_vec = _mm256_add_epi8(remainder_vec, zero_vec);\n        \n        for (int i = 0; i < 32; i++) {\n            char digit = _mm256_extract_epi8(char_vec, i);\n            if (digit != 0) {\n                result.push_back(digit);\n            }\n        }\n\n        x = _mm256_extract_epi64(x_vec, 0) / base; // Update x for next iteration\n    }\n\n    std::reverse(result.begin(), result.end());\n    return std::string(result.begin(), result.end());\n}\n```"}
{"task_id": "SimdBench_85_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n#include <vector>\n\nstd::string change_base_simd(int64_t x, int8_t base) {\n    if (base < 2 || base > 9) return \"\";\n\n    std::vector<char> result;\n    __m256i base_vec = _mm256_set1_epi8(base);\n    __m256i zero_vec = _mm256_set1_epi8('0');\n    \n    while (x > 0) {\n        __m256i x_vec = _mm256_set1_epi64x(x);\n        __m256i remainder = _mm256_rem_epi64(x_vec, base_vec);\n        __m256i char_vec = _mm256_add_epi8(remainder, zero_vec);\n        \n        for (int i = 0; i < 32; i++) {\n            char c = _mm256_extract_epi8(char_vec, i);\n            if (c != 0) {\n                result.push_back(c);\n            }\n        }\n        \n        x = _mm256_extract_epi64(x_vec, 0) / base;\n    }\n\n    std::reverse(result.begin(), result.end());\n    return std::string(result.begin(), result.end());\n}\n```"}
{"task_id": "SimdBench_85_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n#include <vector>\n\nstd::string change_base_simd(int64_t x, int8_t base) {\n    if (base < 2 || base > 9) return \"\"; // base must be between 2 and 9\n\n    std::vector<char> result;\n    __m256i base_vec = _mm256_set1_epi8(base);\n    __m256i zero_vec = _mm256_set1_epi8('0');\n    \n    while (x > 0) {\n        __m256i x_vec = _mm256_set1_epi64x(x);\n        __m256i remainder_vec = _mm256_rem_epi64(x_vec, base_vec);\n        __m256i char_vec = _mm256_add_epi8(remainder_vec, zero_vec);\n        \n        for (int i = 0; i < 32; i++) {\n            char c = _mm256_extract_epi8(char_vec, i);\n            if (c != 0) result.push_back(c);\n        }\n        \n        x = _mm256_extract_epi64(x_vec, 0) / base; // Update x for the next iteration\n    }\n\n    std::reverse(result.begin(), result.end());\n    return std::string(result.begin(), result.end());\n}\n```"}
{"task_id": "SimdBench_85_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n#include <vector>\n\nstd::string change_base_simd(int64_t x, int8_t base) {\n    if (base < 2 || base > 9) return \"\";\n\n    std::vector<char> result;\n    __m256i base_vec = _mm256_set1_epi8(base);\n    __m256i zero_vec = _mm256_set1_epi8('0');\n\n    while (x > 0) {\n        __m256i x_vec = _mm256_set1_epi64x(x);\n        __m256i remainder = _mm256_rem_epi64(x_vec, base_vec);\n        __m256i char_vec = _mm256_add_epi8(remainder, zero_vec);\n\n        for (int i = 0; i < 32; i++) {\n            int8_t remainder_val = _mm256_extract_epi8(remainder, i);\n            if (remainder_val < 0) break;\n            result.push_back('0' + remainder_val);\n        }\n\n        x = _mm256_extract_epi64(x_vec, 0) / base;\n    }\n\n    std::reverse(result.begin(), result.end());\n    return std::string(result.begin(), result.end());\n}\n```"}
{"task_id": "SimdBench_86_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <string>\n\nbool is_palindrome_simd(std::string text) {\n    int len = text.length();\n    if (len == 0) return true;\n\n    int left = 0;\n    int right = len - 1;\n\n    while (left < right) {\n        __m256i left_chars = _mm256_loadu_si256((__m256i*)&text[left]);\n        __m256i right_chars = _mm256_loadu_si256((__m256i*)&text[right - 31]);\n\n        // Reverse right_chars for comparison\n        right_chars = _mm256_shuffle_epi8(right_chars, _mm256_setr_epi8(31, 30, 29, 28, 27, 26, 25, 24,\n                                                                        23, 22, 21, 20, 19, 18, 17, 16,\n                                                                        15, 14, 13, 12, 11, 10, 9, 8,\n                                                                        7, 6, 5, 4, 3, 2, 1, 0));\n\n        // Compare\n        __m256i cmp = _mm256_cmpeq_epi8(left_chars, right_chars);\n        int mask = _mm256_movemask_epi8(cmp);\n\n        // Check if all characters matched\n        if (mask != 0xFFFFFFFF) {\n            return false;\n        }\n\n        left += 32;\n        right -= 32;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_86_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <string>\n\nbool is_palindrome_simd(std::string text) {\n    int n = text.size();\n    if (n == 0) return true;\n\n    __m256i mask = _mm256_set1_epi8(0xFF);\n    int left = 0, right = n - 1;\n\n    while (left < right) {\n        if (right - left < 32) {\n            for (int i = left; i <= right; i++) {\n                if (text[i] != text[right - (i - left)]) {\n                    return false;\n                }\n            }\n            return true;\n        }\n\n        __m256i left_vec = _mm256_loadu_si256((__m256i*)&text[left]);\n        __m256i right_vec = _mm256_loadu_si256((__m256i*)&text[right - 31]);\n\n        __m256i cmp = _mm256_cmpeq_epi8(left_vec, _mm256_shuffle_epi8(right_vec, _mm256_setr_epi8(31, 30, 29, 28, 27, 26, 25, 24,\n                                                                                      23, 22, 21, 20, 19, 18, 17, 16,\n                                                                                      15, 14, 13, 12, 11, 10, 9, 8,\n                                                                                      7, 6, 5, 4, 3, 2, 1, 0)));\n\n        int mask_result = _mm256_movemask_epi8(cmp);\n        if (mask_result != 0xFFFFFFFF) {\n            return false;\n        }\n\n        left += 32;\n        right -= 32;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_86_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <string>\n\nbool is_palindrome_simd(std::string text) {\n    int len = text.length();\n    if (len <= 1) return true;\n\n    int left = 0;\n    int right = len - 1;\n\n    while (left < right) {\n        __m256i left_chars = _mm256_loadu_si256((__m256i*)&text[left]);\n        __m256i right_chars = _mm256_loadu_si256((__m256i*)&text[right - 31]);\n\n        __m256i reversed_right_chars = _mm256_shuffle_epi8(right_chars, _mm256_setr_epi8(\n            31, 30, 29, 28, 27, 26, 25, 24,\n            23, 22, 21, 20, 19, 18, 17, 16,\n            15, 14, 13, 12, 11, 10, 9, 8,\n            7, 6, 5, 4, 3, 2, 1, 0));\n\n        __m256i cmp = _mm256_cmpeq_epi8(left_chars, reversed_right_chars);\n        int mask = _mm256_movemask_epi8(cmp);\n\n        if (mask != 0xFFFFFFFF) {\n            return false;\n        }\n\n        left += 32;\n        right -= 32;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_86_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <string>\n\nbool is_palindrome_simd(std::string text) {\n    int len = text.length();\n    if (len <= 1) return true;\n\n    const int vec_size = 32; // 32 bytes for AVX\n    int half_len = len / 2;\n\n    for (int i = 0; i < half_len; i += vec_size) {\n        __m256i left = _mm256_loadu_si256((__m256i*)&text[i]);\n        __m256i right = _mm256_loadu_si256((__m256i*)&text[len - i - vec_size]);\n\n        // Compare the two vectors\n        __m256i cmp = _mm256_cmpeq_epi8(left, right);\n        int mask = _mm256_movemask_epi8(cmp);\n\n        // If any byte does not match, return false\n        if (mask != 0xFFFFFFFF) {\n            return false;\n        }\n    }\n\n    // Handle the case for odd length strings\n    if (len % 2 != 0) {\n        if (text[half_len] != text[len - half_len - 1]) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_86_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <string>\n\nbool is_palindrome_simd(std::string text) {\n    int n = text.size();\n    if (n == 0) return true;\n\n    int left = 0;\n    int right = n - 1;\n\n    while (left < right) {\n        __m256i left_chars = _mm256_loadu_si256((__m256i*)&text[left]);\n        __m256i right_chars = _mm256_loadu_si256((__m256i*)&text[right - 31]);\n\n        // Reverse right_chars for comparison\n        right_chars = _mm256_shuffle_epi8(right_chars, _mm256_setr_epi8(31, 30, 29, 28, 27, 26, 25, 24,\n                                                                       23, 22, 21, 20, 19, 18, 17, 16,\n                                                                       15, 14, 13, 12, 11, 10, 9, 8,\n                                                                       7, 6, 5, 4, 3, 2, 1, 0));\n\n        // Compare characters\n        __m256i cmp = _mm256_cmpeq_epi8(left_chars, right_chars);\n        int mask = _mm256_movemask_epi8(cmp);\n\n        if (mask != 0xFFFFFFFF) {\n            return false;\n        }\n\n        left += 32;\n        right -= 32;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_87_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <string>\n\nstd::string decode_shift_simd(std::string s) {\n    size_t len = s.length();\n    std::string out(len, ' ');\n\n    size_t i = 0;\n    __m256i shift = _mm256_set1_epi8(-5);\n    \n    for (; i <= len - 32; i += 32) {\n        __m256i input = _mm256_loadu_si256((__m256i*)&s[i]);\n        __m256i decoded = _mm256_add_epi8(input, shift);\n        __m256i wrapped = _mm256_and_si256(decoded, _mm256_set1_epi8(0x1F)); // Wrap around for 'a' to 'z'\n        _mm256_storeu_si256((__m256i*)&out[i], wrapped);\n    }\n\n    for (; i < len; ++i) {\n        out[i] = (s[i] - 5 + 26) % 26 + 'a';\n    }\n\n    return out;\n}\n```"}
{"task_id": "SimdBench_87_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <string>\n\nstd::string decode_shift_simd(std::string s) {\n    size_t len = s.length();\n    std::string out(len, ' ');\n\n    size_t i = 0;\n    __m256i shift = _mm256_set1_epi8(-5);\n    \n    for (; i <= len - 32; i += 32) {\n        __m256i input = _mm256_loadu_si256((__m256i*)&s[i]);\n        __m256i decoded = _mm256_add_epi8(input, shift);\n        __m256i wrapped = _mm256_and_si256(decoded, _mm256_set1_epi8(0x1F)); // Wrap around for 'a' to 'z'\n        _mm256_storeu_si256((__m256i*)&out[i], wrapped);\n    }\n\n    for (; i < len; ++i) {\n        out[i] = (s[i] - 5 + 26) % 26 + 'a';\n    }\n\n    return out;\n}\n```"}
{"task_id": "SimdBench_87_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <string>\n\nstd::string decode_shift_simd(std::string s) {\n    size_t len = s.length();\n    std::string out(len, ' ');\n\n    size_t i = 0;\n    __m256i shift = _mm256_set1_epi8(-5);\n    __m256i a = _mm256_set1_epi8('a');\n    __m256i z = _mm256_set1_epi8('z');\n    __m256i range = _mm256_set1_epi8(26);\n\n    for (; i + 32 <= len; i += 32) {\n        __m256i input = _mm256_loadu_si256((__m256i*)&s[i]);\n        __m256i decoded = _mm256_add_epi8(input, shift);\n        \n        // Wrap around if less than 'a'\n        __m256i less_than_a = _mm256_cmpgt_epi8(decoded, a);\n        __m256i wrap = _mm256_sub_epi8(decoded, range);\n        decoded = _mm256_blendv_epi8(decoded, wrap, less_than_a);\n\n        _mm256_storeu_si256((__m256i*)&out[i], decoded);\n    }\n\n    for (; i < len; ++i) {\n        out[i] = (char)((((int)s[i] - 'a' + 21) % 26) + 'a');\n    }\n\n    return out;\n}\n```"}
{"task_id": "SimdBench_87_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <string>\n\nstd::string decode_shift_simd(std::string s) {\n    size_t len = s.length();\n    std::string out(len, ' ');\n\n    size_t i = 0;\n    __m256i shift = _mm256_set1_epi8(-5);\n    \n    for (; i <= len - 32; i += 32) {\n        __m256i input = _mm256_loadu_si256((__m256i*)&s[i]);\n        __m256i decoded = _mm256_add_epi8(input, shift);\n        __m256i wrapped = _mm256_and_si256(decoded, _mm256_set1_epi8(0x1F)); // Wrap around for 'a' to 'z'\n        _mm256_storeu_si256((__m256i*)&out[i], wrapped);\n    }\n\n    for (; i < len; ++i) {\n        out[i] = (s[i] - 5 + 26) % 26 + 'a';\n    }\n\n    return out;\n}\n```"}
{"task_id": "SimdBench_87_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <string>\n\nstd::string decode_shift_simd(std::string s) {\n    size_t len = s.length();\n    std::string out(len, ' ');\n\n    size_t i = 0;\n    __m256i shift = _mm256_set1_epi8(-5); // Set the shift value to -5\n\n    for (; i + 32 <= len; i += 32) {\n        __m256i input = _mm256_loadu_si256((__m256i*)&s[i]); // Load 32 bytes\n        __m256i decoded = _mm256_add_epi8(input, shift); // Shift characters by -5\n        __m256i mask = _mm256_cmpgt_epi8(decoded, _mm256_set1_epi8('z')); // Check for overflow\n        decoded = _mm256_sub_epi8(decoded, _mm256_and_si256(mask, _mm256_set1_epi8(26))); // Wrap around if overflow\n        _mm256_storeu_si256((__m256i*)&out[i], decoded); // Store the result\n    }\n\n    // Handle remaining characters\n    for (; i < len; ++i) {\n        out[i] = (s[i] - 'a' + 21) % 26 + 'a'; // Decode remaining characters\n    }\n\n    return out;\n}\n```"}
{"task_id": "SimdBench_88_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nbool below_threshold_simd(std::vector<int> l, int t) {\n    size_t size = l.size();\n    size_t i = 0;\n\n    __m256i threshold = _mm256_set1_epi32(t);\n    __m256i all_below = _mm256_set1_epi32(-1); // Assume all are below initially\n\n    for (; i + 8 <= size; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&l[i]);\n        __m256i cmp = _mm256_cmpgt_epi32(vec, threshold);\n        all_below = _mm256_and_si256(all_below, _mm256_xor_si256(cmp, _mm256_set1_epi32(-1)));\n    }\n\n    // Handle remaining elements\n    for (; i < size; i++) {\n        if (l[i] >= t) {\n            return false;\n        }\n    }\n\n    // Check if all_below is still all ones\n    return _mm256_movemask_epi8(all_below) == 0xFFFF;\n}\n```"}
{"task_id": "SimdBench_88_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nbool below_threshold_simd(std::vector<int> l, int t) {\n    size_t size = l.size();\n    size_t i = 0;\n\n    __m256i threshold = _mm256_set1_epi32(t);\n    \n    for (; i <= size - 8; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&l[i]);\n        __m256i cmp = _mm256_cmpgt_epi32(vec, threshold);\n        if (_mm256_movemask_epi8(cmp) != 0) {\n            return false;\n        }\n    }\n\n    for (; i < size; i++) {\n        if (l[i] >= t) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_88_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nbool below_threshold_simd(std::vector<int> l, int t) {\n    size_t size = l.size();\n    size_t i = 0;\n\n    __m256i threshold = _mm256_set1_epi32(t);\n    __m256i all_below = _mm256_set1_epi32(-1); // Start with all bits set (true)\n\n    for (; i + 8 <= size; i += 8) {\n        __m256i values = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&l[i]));\n        __m256i cmp = _mm256_cmpgt_epi32(values, threshold);\n        all_below = _mm256_and_si256(all_below, _mm256_xor_si256(cmp, _mm256_set1_epi32(-1)));\n    }\n\n    // Handle remaining elements\n    for (; i < size; i++) {\n        if (l[i] >= t) {\n            return false;\n        }\n    }\n\n    // Check if all bits in all_below are still set (true)\n    return _mm256_movemask_epi8(all_below) == 0xFFFF;\n}\n```"}
{"task_id": "SimdBench_88_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nbool below_threshold_simd(std::vector<int> l, int t) {\n    size_t size = l.size();\n    size_t i = 0;\n\n    __m256i threshold = _mm256_set1_epi32(t);\n    \n    for (; i + 8 <= size; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&l[i]);\n        __m256i cmp = _mm256_cmpgt_epi32(vec, threshold);\n        if (_mm256_movemask_epi8(cmp) != 0) {\n            return false;\n        }\n    }\n\n    for (; i < size; ++i) {\n        if (l[i] >= t) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_88_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nbool below_threshold_simd(std::vector<int> l, int t) {\n    size_t size = l.size();\n    size_t i = 0;\n\n    __m256i threshold = _mm256_set1_epi32(t);\n    __m256i all_below = _mm256_set1_epi32(-1); // All bits set to 1\n\n    for (; i + 8 <= size; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&l[i]);\n        __m256i cmp = _mm256_cmpgt_epi32(vec, threshold);\n        all_below = _mm256_and_si256(all_below, _mm256_xor_si256(cmp, _mm256_set1_epi32(-1)));\n    }\n\n    // Handle remaining elements\n    for (; i < size; ++i) {\n        if (l[i] >= t) {\n            return false;\n        }\n    }\n\n    // Check if all bits in all_below are set\n    return _mm256_movemask_epi8(all_below) == 0xFFFF;\n}\n```"}
{"task_id": "SimdBench_89_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nbool correct_bracketing_simd(std::string brackets) {\n    int length = brackets.size();\n    int i = 0;\n    __m256i open_count = _mm256_setzero_si256();\n    \n    for (; i <= length - 32; i += 32) {\n        __m256i data = _mm256_loadu_si256((__m256i*)&brackets[i]);\n        __m256i open_mask = _mm256_cmpeq_epi8(data, _mm256_set1_epi8('<'));\n        __m256i close_mask = _mm256_cmpeq_epi8(data, _mm256_set1_epi8('>'));\n        \n        open_count = _mm256_add_epi8(open_count, open_mask);\n        open_count = _mm256_sub_epi8(open_count, close_mask);\n    }\n    \n    int total_open = _mm256_reduce_add_epi8(open_count);\n    \n    for (; i < length; ++i) {\n        if (brackets[i] == '<') total_open++;\n        else if (brackets[i] == '>') total_open--;\n    }\n    \n    return total_open == 0;\n}\n```"}
{"task_id": "SimdBench_89_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nbool correct_bracketing_simd(std::string brackets) {\n    int len = brackets.size();\n    int count = 0;\n\n    // Process 32 characters at a time\n    for (int i = 0; i < len; i += 32) {\n        __m256i data = _mm256_loadu_si256((__m256i*)&brackets[i]);\n        __m256i open_mask = _mm256_cmpeq_epi8(data, _mm256_set1_epi8('<'));\n        __m256i close_mask = _mm256_cmpeq_epi8(data, _mm256_set1_epi8('>'));\n\n        // Count opening brackets\n        count += _mm256_movemask_epi8(open_mask);\n        // Count closing brackets\n        count -= _mm256_movemask_epi8(close_mask);\n    }\n\n    // Handle any remaining characters\n    for (int i = (len / 32) * 32; i < len; ++i) {\n        if (brackets[i] == '<') count++;\n        if (brackets[i] == '>') count--;\n    }\n\n    return count == 0;\n}\n```"}
{"task_id": "SimdBench_89_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nbool correct_bracketing_simd(std::string brackets) {\n    int length = brackets.length();\n    int count = 0;\n\n    // Process 32 characters at a time using AVX2\n    for (int i = 0; i <= length - 32; i += 32) {\n        __m256i data = _mm256_loadu_si256((__m256i*)&brackets[i]);\n        __m256i open_mask = _mm256_cmpeq_epi8(data, _mm256_set1_epi8('<'));\n        __m256i close_mask = _mm256_cmpeq_epi8(data, _mm256_set1_epi8('>'));\n\n        // Count the number of '<' and '>'\n        int open_count = _mm256_movemask_epi8(open_mask);\n        int close_count = _mm256_movemask_epi8(close_mask);\n\n        count += __builtin_popcount(open_count);\n        count -= __builtin_popcount(close_count);\n    }\n\n    // Handle remaining characters\n    for (int i = length - (length % 32); i < length; ++i) {\n        if (brackets[i] == '<') {\n            count++;\n        } else if (brackets[i] == '>') {\n            count--;\n        }\n    }\n\n    return count == 0;\n}\n```"}
{"task_id": "SimdBench_89_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nbool correct_bracketing_simd(std::string brackets) {\n    size_t length = brackets.length();\n    __m256i count = _mm256_setzero_si256();\n    \n    for (size_t i = 0; i < length; i += 32) {\n        __m256i data = _mm256_loadu_si256((__m256i*)&brackets[i]);\n        __m256i open = _mm256_cmpeq_epi8(data, _mm256_set1_epi8('<'));\n        __m256i close = _mm256_cmpeq_epi8(data, _mm256_set1_epi8('>'));\n        \n        count = _mm256_add_epi8(count, _mm256_sub_epi8(open, close));\n    }\n    \n    int16_t result[16];\n    _mm256_storeu_si256((__m256i*)result, count);\n    \n    int total = 0;\n    for (int i = 0; i < 16; ++i) {\n        total += result[i];\n    }\n    \n    return total == 0;\n}\n```"}
{"task_id": "SimdBench_89_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nbool correct_bracketing_simd(std::string brackets) {\n    int len = brackets.length();\n    if (len % 8 != 0) {\n        return false; // Length must be a multiple of 8 for AVX processing\n    }\n\n    __m256i open_count = _mm256_setzero_si256();\n    __m256i close_count = _mm256_setzero_si256();\n\n    for (int i = 0; i < len; i += 8) {\n        __m256i data = _mm256_loadu_si256((__m256i*)&brackets[i]);\n        __m256i open_mask = _mm256_cmpeq_epi8(data, _mm256_set1_epi8('<'));\n        __m256i close_mask = _mm256_cmpeq_epi8(data, _mm256_set1_epi8('>'));\n\n        open_count = _mm256_add_epi8(open_count, open_mask);\n        close_count = _mm256_add_epi8(close_count, close_mask);\n    }\n\n    // Sum open_count and close_count\n    open_count = _mm256_hadd_epi16(open_count, open_count);\n    open_count = _mm256_hadd_epi16(open_count, open_count);\n    open_count = _mm256_hadd_epi16(open_count, open_count);\n    \n    close_count = _mm256_hadd_epi16(close_count, close_count);\n    close_count = _mm256_hadd_epi16(close_count, close_count);\n    close_count = _mm256_hadd_epi16(close_count, close_count);\n\n    int open_total = _mm256_extract_epi16(open_count, 0);\n    int close_total = _mm256_extract_epi16(close_count, 0);\n\n    return open_total == close_total && open_total > 0;\n}\n```"}
{"task_id": "SimdBench_90_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <string>\n\nbool correct_bracketing_simd(std::string brackets) {\n    int len = brackets.length();\n    if (len % 8 != 0) return false; // Ensure length is a multiple of 8 for AVX\n\n    __m256i balance = _mm256_setzero_si256();\n    for (int i = 0; i < len; i += 8) {\n        __m256i data = _mm256_loadu_si256((__m256i*)&brackets[i]);\n        __m256i open_mask = _mm256_cmpeq_epi8(data, _mm256_set1_epi8('('));\n        __m256i close_mask = _mm256_cmpeq_epi8(data, _mm256_set1_epi8(')'));\n\n        balance = _mm256_add_epi8(balance, _mm256_sub_epi8(open_mask, close_mask));\n    }\n\n    int8_t result[32];\n    _mm256_storeu_si256((__m256i*)result, balance);\n\n    int total_balance = 0;\n    for (int i = 0; i < 32; i++) {\n        total_balance += result[i];\n    }\n\n    return total_balance == 0;\n}\n```"}
{"task_id": "SimdBench_90_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <string>\n\nbool correct_bracketing_simd(std::string brackets) {\n    int n = brackets.size();\n    __m256i balance = _mm256_setzero_si256();\n    \n    for (int i = 0; i < n; i += 32) {\n        __m256i chunk = _mm256_setzero_si256();\n        for (int j = 0; j < 32 && i + j < n; ++j) {\n            if (brackets[i + j] == '(') {\n                chunk = _mm256_add_epi32(chunk, _mm256_set1_epi32(1));\n            } else if (brackets[i + j] == ')') {\n                chunk = _mm256_sub_epi32(chunk, _mm256_set1_epi32(1));\n            }\n        }\n        balance = _mm256_add_epi32(balance, chunk);\n    }\n\n    int32_t result[8];\n    _mm256_storeu_si256((__m256i*)result, balance);\n    \n    int total_balance = 0;\n    for (int i = 0; i < 8; ++i) {\n        total_balance += result[i];\n    }\n\n    return total_balance == 0 && (n == 0 || brackets[0] != ')');\n}\n```"}
{"task_id": "SimdBench_90_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <string>\n\nbool correct_bracketing_simd(std::string brackets) {\n    int n = brackets.size();\n    if (n % 8 != 0) return false; // Ensure the length is a multiple of 8 for AVX\n\n    __m256i balance = _mm256_setzero_si256();\n    \n    for (int i = 0; i < n; i += 8) {\n        __m256i chunk = _mm256_loadu_si256((__m256i*)&brackets[i]);\n        __m256i open_mask = _mm256_cmpeq_epi8(chunk, _mm256_set1_epi8('('));\n        __m256i close_mask = _mm256_cmpeq_epi8(chunk, _mm256_set1_epi8(')'));\n\n        balance = _mm256_add_epi8(balance, _mm256_sub_epi8(open_mask, close_mask));\n    }\n\n    int16_t result[16];\n    _mm256_storeu_si256((__m256i*)result, balance);\n\n    int total_balance = 0;\n    for (int i = 0; i < 16; i++) {\n        total_balance += result[i];\n    }\n\n    return total_balance == 0;\n}\n```"}
{"task_id": "SimdBench_90_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <string>\n\nbool correct_bracketing_simd(std::string brackets) {\n    int length = brackets.length();\n    __m256i balance = _mm256_setzero_si256();\n    \n    for (int i = 0; i < length; i += 32) {\n        __m256i chunk = _mm256_setzero_si256();\n        for (int j = 0; j < 32 && (i + j) < length; j++) {\n            if (brackets[i + j] == '(') {\n                chunk = _mm256_add_epi8(chunk, _mm256_set1_epi8(1));\n            } else if (brackets[i + j] == ')') {\n                chunk = _mm256_sub_epi8(chunk, _mm256_set1_epi8(1));\n            }\n        }\n        balance = _mm256_add_epi8(balance, chunk);\n    }\n\n    int final_balance = 0;\n    for (int i = 0; i < 32; i++) {\n        final_balance += _mm256_extract_epi8(balance, i);\n    }\n\n    return final_balance == 0;\n}\n```"}
{"task_id": "SimdBench_90_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <string>\n\nbool correct_bracketing_simd(std::string brackets) {\n    int n = brackets.size();\n    if (n % 8 != 0) return false; // Ensure the length is a multiple of 8 for AVX\n\n    __m256i balance = _mm256_setzero_si256();\n\n    for (int i = 0; i < n; i += 8) {\n        __m256i data = _mm256_loadu_si256((__m256i*)&brackets[i]);\n        __m256i open_mask = _mm256_cmpeq_epi8(data, _mm256_set1_epi8('('));\n        __m256i close_mask = _mm256_cmpeq_epi8(data, _mm256_set1_epi8(')'));\n\n        __m256i open_count = _mm256_and_si256(open_mask, _mm256_set1_epi8(1));\n        __m256i close_count = _mm256_and_si256(close_mask, _mm256_set1_epi8(1));\n\n        balance = _mm256_add_epi8(balance, open_count);\n        balance = _mm256_sub_epi8(balance, close_count);\n    }\n\n    int8_t result[32];\n    _mm256_storeu_si256((__m256i*)result, balance);\n\n    int total_balance = 0;\n    for (int i = 0; i < 32; i++) {\n        total_balance += result[i];\n    }\n\n    return total_balance == 0;\n}\n```"}
{"task_id": "SimdBench_91_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nstd::vector<float> derivative_simd(std::vector<float> xs) {\n    size_t n = xs.size();\n    std::vector<float> result(n - 1);\n    \n    if (n < 2) return result; // No derivative if less than 2 coefficients\n\n    __m256 coeffs, indices, result_vec;\n    for (size_t i = 1; i < n; i += 8) {\n        coeffs = _mm256_loadu_ps(&xs[i - 1]); // Load coefficients\n        indices = _mm256_set_ps(7 - i, 6 - i, 5 - i, 4 - i, 3 - i, 2 - i, 1 - i, 0 - i); // Set indices\n        \n        result_vec = _mm256_mul_ps(coeffs, indices); // Multiply coefficients by their indices\n        _mm256_storeu_ps(&result[i - 1], result_vec); // Store result\n    }\n    \n    // Handle remaining coefficients if n is not a multiple of 8\n    for (size_t i = n - (n % 8); i < n; ++i) {\n        result[i - 1] = xs[i] * i;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_91_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nstd::vector<float> derivative_simd(std::vector<float> xs) {\n    size_t n = xs.size();\n    if (n < 2) return {}; // No derivative for constant or empty polynomial\n\n    std::vector<float> result(n - 1);\n    size_t i;\n\n    // Process 8 coefficients at a time\n    size_t simd_size = n / 8 * 8; // Largest multiple of 8\n    for (i = 0; i < simd_size; i += 8) {\n        __m256 coeffs = _mm256_loadu_ps(&xs[i]);\n        __m256 indices = _mm256_set_ps(7 - i, 6 - i, 5 - i, 4 - i, 3 - i, 2 - i, 1 - i, 0 - i);\n        __m256 multiplier = _mm256_div_ps(coeffs, indices);\n        _mm256_storeu_ps(&result[i], multiplier);\n    }\n\n    // Handle remaining coefficients\n    for (; i < n - 1; ++i) {\n        result[i] = xs[i + 1] * (i + 1);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_91_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nstd::vector<float> derivative_simd(std::vector<float> xs) {\n    size_t n = xs.size();\n    if (n <= 1) return {};\n\n    std::vector<float> result(n - 1);\n    size_t i;\n\n    __m256 coeffs, indices, result_vec;\n\n    for (i = 0; i + 8 <= n; i += 8) {\n        coeffs = _mm256_loadu_ps(&xs[i + 1]); // Load coefficients xs[1] to xs[8]\n        indices = _mm256_set_ps(7 - i, 6 - i, 5 - i, 4 - i, 3 - i, 2 - i, 1 - i, 0 - i); // Indices for x^n\n        result_vec = _mm256_mul_ps(coeffs, indices); // Multiply coefficients by their respective indices\n        _mm256_storeu_ps(&result[i], result_vec); // Store result\n    }\n\n    for (; i + 4 <= n; i += 4) {\n        coeffs = _mm256_loadu_ps(&xs[i + 1]); // Load coefficients\n        indices = _mm256_set_ps(3 - i, 2 - i, 1 - i, 0 - i); // Indices for x^n\n        result_vec = _mm256_mul_ps(coeffs, indices); // Multiply coefficients by their respective indices\n        _mm256_storeu_ps(&result[i], result_vec); // Store result\n    }\n\n    for (; i < n - 1; ++i) {\n        result[i] = xs[i + 1] * (i + 1);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_91_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nstd::vector<float> derivative_simd(std::vector<float> xs) {\n    size_t n = xs.size();\n    if (n < 2) return {}; // No derivative for constant or empty polynomial\n\n    std::vector<float> result(n - 1);\n    size_t i;\n\n    // Process 8 coefficients at a time using AVX\n    for (i = 0; i + 8 <= n; i += 8) {\n        __m256 coeffs = _mm256_loadu_ps(&xs[i + 1]); // Load coefficients from xs[1] to xs[8]\n        __m256 indices = _mm256_set_ps(7, 6, 5, 4, 3, 2, 1, 0); // Set indices for multiplication\n        __m256 multipliers = _mm256_mul_ps(coeffs, indices); // Multiply coefficients by their indices\n        _mm256_storeu_ps(&result[i], multipliers); // Store result\n    }\n\n    // Handle remaining coefficients\n    for (; i + 1 < n; i++) {\n        result[i] = xs[i + 1] * (i + 1);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_91_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nstd::vector<float> derivative_simd(std::vector<float> xs) {\n    size_t n = xs.size();\n    if (n < 2) return {}; // No derivative for constant polynomial\n\n    std::vector<float> result(n - 1);\n    size_t i;\n\n    // Process in chunks of 8 (AVX)\n    size_t simd_size = n / 8 * 8; // Largest multiple of 8\n    for (i = 1; i < simd_size; i += 8) {\n        __m256 coeffs = _mm256_loadu_ps(&xs[i - 1]); // Load coefficients\n        __m256 indices = _mm256_set_ps(7, 6, 5, 4, 3, 2, 1, 0); // Indices 0 to 7\n        __m256 multiplier = _mm256_set_ps(7, 6, 5, 4, 3, 2, 1, 0); // Multiplier for derivative\n\n        __m256 result_vec = _mm256_mul_ps(coeffs, multiplier); // Multiply coeffs by indices\n        _mm256_storeu_ps(&result[i - 1], result_vec); // Store result\n    }\n\n    // Handle remaining elements\n    for (; i < n; ++i) {\n        result[i - 1] = static_cast<float>(i) * xs[i];\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_92_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <string>\n\nint vowels_count_simd(std::string s) {\n    __m256i vowels_mask = _mm256_setr_epi8('u', 'o', 'i', 'e', 'a', 'u', 'o', 'i', 'e', 'a', 'u', 'o', 'i', 'e', 'a', 'y');\n    __m256i count_mask = _mm256_set1_epi8(1);\n    int count = 0;\n\n    size_t length = s.length();\n    size_t i = 0;\n\n    for (; i + 32 <= length; i += 32) {\n        __m256i data = _mm256_loadu_si256((__m256i*)&s[i]);\n        __m256i cmp = _mm256_cmpeq_epi8(data, vowels_mask);\n        __m256i result = _mm256_and_si256(cmp, count_mask);\n        count += _mm256_sum_epi8(result);\n    }\n\n    for (; i < length; ++i) {\n        if (s[i] == 'a' || s[i] == 'e' || s[i] == 'i' || s[i] == 'o' || s[i] == 'u') {\n            count++;\n        }\n    }\n\n    if (length > 0 && s[length - 1] == 'y') {\n        count++;\n    }\n\n    return count;\n}\n\nint _mm256_sum_epi8(__m256i vec) {\n    int8_t* val = (int8_t*)&vec;\n    int sum = 0;\n    for (int i = 0; i < 32; i++) {\n        sum += val[i];\n    }\n    return sum;\n}\n```"}
{"task_id": "SimdBench_92_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <string>\n\nint vowels_count_simd(std::string s) {\n    int count = 0;\n    size_t length = s.length();\n    size_t i = 0;\n\n    __m256i vowels_mask = _mm256_setr_epi8('u', 'o', 'i', 'e', 'a', 'U', 'O', 'I', 'E', 'A', 'u', 'o', 'i', 'e', 'a', 'Y');\n    __m256i y_mask = _mm256_set1_epi8('y');\n    \n    for (; i <= length - 32; i += 32) {\n        __m256i data = _mm256_loadu_si256((__m256i*)&s[i]);\n        __m256i cmp = _mm256_cmpeq_epi8(data, vowels_mask);\n        __m256i y_check = _mm256_cmpeq_epi8(data, y_mask);\n        \n        __m256i count_mask = _mm256_or_si256(cmp, y_check);\n        count += _mm256_movemask_epi8(count_mask);\n    }\n\n    for (; i < length; ++i) {\n        char c = s[i];\n        if (c == 'a' || c == 'e' || c == 'i' || c == 'o' || c == 'u' || c == 'A' || c == 'E' || c == 'I' || c == 'O' || c == 'U') {\n            count++;\n        } else if (i == length - 1 && (c == 'y' || c == 'Y')) {\n            count++;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_92_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <string>\n\nint vowels_count_simd(std::string s) {\n    __m256i vowels_mask = _mm256_setr_epi8('u', 'o', 'i', 'e', 'a', 'u', 'o', 'i', 'e', 'a', 'u', 'o', 'i', 'e', 'a', 'u');\n    __m256i count_mask = _mm256_set1_epi8(1);\n    int count = 0;\n\n    size_t length = s.length();\n    size_t i = 0;\n\n    for (; i + 32 <= length; i += 32) {\n        __m256i input = _mm256_loadu_si256((__m256i*)&s[i]);\n        __m256i cmp = _mm256_cmpeq_epi8(input, vowels_mask);\n        __m256i result = _mm256_and_si256(cmp, count_mask);\n        count += _mm256_sum_epi8(result);\n    }\n\n    for (; i < length; ++i) {\n        char c = s[i];\n        if (c == 'a' || c == 'e' || c == 'i' || c == 'o' || c == 'u') {\n            count++;\n        }\n    }\n\n    if (length > 0 && s[length - 1] == 'y') {\n        count++;\n    }\n\n    return count;\n}\n\nint _mm256_sum_epi8(__m256i v) {\n    int8_t* val = (int8_t*)&v;\n    int sum = 0;\n    for (int i = 0; i < 32; i++) {\n        sum += val[i];\n    }\n    return sum;\n}\n```"}
{"task_id": "SimdBench_92_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nint vowels_count_simd(std::string s) {\n    int count = 0;\n    size_t length = s.length();\n    size_t i = 0;\n\n    __m256i vowels_mask = _mm256_setr_epi8('a', 'e', 'i', 'o', 'u', 'A', 'E', 'I', 'O', 'U', 0, 0, 0, 0, 0, 0, 0);\n    __m256i y_mask = _mm256_set1_epi8('y');\n    __m256i y_upper_mask = _mm256_set1_epi8('Y');\n\n    for (; i + 32 <= length; i += 32) {\n        __m256i data = _mm256_loadu_si256((__m256i*)&s[i]);\n        __m256i cmp = _mm256_cmpeq_epi8(data, vowels_mask);\n        count += _mm256_movemask_epi8(cmp);\n\n        // Check for 'y' and 'Y' at the end of the string\n        if (i + 32 >= length) {\n            for (size_t j = length - i; j < 32; j++) {\n                if (s[i + j] == 'y' || s[i + j] == 'Y') {\n                    count++;\n                }\n            }\n        }\n    }\n\n    // Process remaining characters\n    for (; i < length; i++) {\n        if (s[i] == 'a' || s[i] == 'e' || s[i] == 'i' || s[i] == 'o' || s[i] == 'u' ||\n            s[i] == 'A' || s[i] == 'E' || s[i] == 'I' || s[i] == 'O' || s[i] == 'U') {\n            count++;\n        }\n        if (i == length - 1 && (s[i] == 'y' || s[i] == 'Y')) {\n            count++;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_92_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <string>\n\nint vowels_count_simd(std::string s) {\n    __m256i vowels_mask = _mm256_setr_epi8('u', 'o', 'i', 'e', 'a', 'u', 'o', 'i', 'e', 'a', 'u', 'o', 'i', 'e', 'a', 'u');\n    __m256i y_mask = _mm256_set1_epi8('y');\n    __m256i end_mask = _mm256_set1_epi8(0);\n    int count = 0;\n\n    size_t len = s.length();\n    size_t i = 0;\n\n    for (; i + 32 <= len; i += 32) {\n        __m256i data = _mm256_loadu_si256((__m256i*)&s[i]);\n        __m256i cmp = _mm256_cmpeq_epi8(data, vowels_mask);\n        __m256i y_check = _mm256_cmpeq_epi8(data, y_mask);\n        \n        __m256i end_check = _mm256_set1_epi8(0);\n        if (i + 32 == len) {\n            end_check = _mm256_set1_epi8(1);\n        }\n\n        cmp = _mm256_or_si256(cmp, _mm256_and_si256(y_check, end_check));\n        count += _mm256_movemask_epi8(cmp);\n    }\n\n    for (; i < len; ++i) {\n        if (s[i] == 'a' || s[i] == 'e' || s[i] == 'i' || s[i] == 'o' || s[i] == 'u' || (s[i] == 'y' && i == len - 1)) {\n            count++;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_93_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <string>\n\nint digitSum_simd(std::string s) {\n    int sum = 0;\n    size_t length = s.length();\n    size_t i = 0;\n\n    __m256i total_sum = _mm256_setzero_si256();\n\n    for (; i + 32 <= length; i += 32) {\n        __m256i data = _mm256_loadu_si256((__m256i*)&s[i]);\n        __m256i mask = _mm256_cmpgt_epi8(data, _mm256_set1_epi8('A' - 1));\n        __m256i mask_upper = _mm256_and_si256(mask, _mm256_cmpgt_epi8(data, _mm256_set1_epi8('Z')));\n        __m256i ascii_values = _mm256_and_si256(mask_upper, data);\n        total_sum = _mm256_add_epi8(total_sum, ascii_values);\n    }\n\n    // Horizontal sum of the total_sum vector\n    total_sum = _mm256_hadd_epi16(total_sum, total_sum);\n    total_sum = _mm256_hadd_epi16(total_sum, total_sum);\n    total_sum = _mm256_hadd_epi16(total_sum, total_sum);\n    \n    sum += _mm256_extract_epi16(total_sum, 0);\n    sum += _mm256_extract_epi16(total_sum, 1);\n    \n    for (; i < length; ++i) {\n        if (s[i] >= 'A' && s[i] <= 'Z') {\n            sum += s[i];\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_93_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <string>\n\nint digitSum_simd(std::string s) {\n    int sum = 0;\n    size_t len = s.length();\n    size_t i = 0;\n\n    __m256i total_sum = _mm256_setzero_si256();\n\n    for (; i + 32 <= len; i += 32) {\n        __m256i data = _mm256_loadu_si256((__m256i*)&s[i]);\n        __m256i mask_upper = _mm256_cmpgt_epi8(data, _mm256_set1_epi8('A' - 1));\n        __m256i mask_lower = _mm256_cmpgt_epi8(_mm256_set1_epi8('Z' + 1), data);\n        __m256i mask = _mm256_and_si256(mask_upper, mask_lower);\n        \n        __m256i ascii_values = _mm256_and_si256(data, mask);\n        total_sum = _mm256_add_epi8(total_sum, ascii_values);\n    }\n\n    // Horizontal sum of the 32 bytes in total_sum\n    total_sum = _mm256_hadd_epi16(total_sum, total_sum);\n    total_sum = _mm256_hadd_epi16(total_sum, total_sum);\n    total_sum = _mm256_hadd_epi16(total_sum, total_sum);\n    \n    // Extract the sum from the resulting vector\n    sum += _mm256_extract_epi16(total_sum, 0);\n    sum += _mm256_extract_epi16(total_sum, 1);\n    \n    // Process remaining characters\n    for (; i < len; ++i) {\n        if (s[i] >= 'A' && s[i] <= 'Z') {\n            sum += static_cast<int>(s[i]);\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_93_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <string>\n\nint digitSum_simd(std::string s) {\n    int sum = 0;\n    size_t length = s.length();\n    size_t i = 0;\n\n    __m256i total_sum = _mm256_setzero_si256();\n\n    for (; i + 32 <= length; i += 32) {\n        __m256i data = _mm256_loadu_si256((__m256i*)&s[i]);\n        __m256i mask = _mm256_cmpgt_epi8(data, _mm256_set1_epi8('A' - 1));\n        __m256i mask_upper = _mm256_and_si256(mask, _mm256_cmpgt_epi8(data, _mm256_set1_epi8('Z')));\n        __m256i ascii_values = _mm256_and_si256(mask_upper, data);\n        total_sum = _mm256_add_epi8(total_sum, ascii_values);\n    }\n\n    // Horizontal sum of the total_sum vector\n    total_sum = _mm256_hadd_epi16(total_sum, total_sum);\n    total_sum = _mm256_hadd_epi16(total_sum, total_sum);\n    total_sum = _mm256_hadd_epi16(total_sum, total_sum);\n    \n    sum += _mm256_extract_epi16(total_sum, 0);\n    sum += _mm256_extract_epi16(total_sum, 1);\n    \n    for (; i < length; ++i) {\n        if (s[i] >= 'A' && s[i] <= 'Z') {\n            sum += s[i];\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_93_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <string>\n\nint digitSum_simd(std::string s) {\n    int sum = 0;\n    size_t length = s.length();\n    size_t i = 0;\n\n    __m256i total_sum = _mm256_setzero_si256();\n\n    for (; i + 32 <= length; i += 32) {\n        __m256i data = _mm256_loadu_si256((__m256i*)&s[i]);\n        __m256i mask = _mm256_cmpgt_epi8(data, _mm256_set1_epi8('A' - 1));\n        __m256i mask_upper = _mm256_cmpgt_epi8(data, _mm256_set1_epi8('Z'));\n        mask = _mm256_and_si256(mask, mask_upper);\n        \n        data = _mm256_and_si256(data, mask);\n        total_sum = _mm256_add_epi8(total_sum, data);\n    }\n\n    // Horizontal sum of the 32 bytes in total_sum\n    total_sum = _mm256_hadd_epi16(total_sum, total_sum);\n    total_sum = _mm256_hadd_epi16(total_sum, total_sum);\n    total_sum = _mm256_hadd_epi16(total_sum, total_sum);\n    \n    // Extract the sum from the resulting vector\n    sum += _mm256_extract_epi16(total_sum, 0);\n    sum += _mm256_extract_epi16(total_sum, 1);\n    \n    // Process remaining characters\n    for (; i < length; ++i) {\n        if (s[i] >= 'A' && s[i] <= 'Z') {\n            sum += static_cast<int>(s[i]);\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_93_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <string>\n\nint digitSum_simd(std::string s) {\n    int sum = 0;\n    size_t length = s.length();\n    size_t i = 0;\n\n    __m256i total_sum = _mm256_setzero_si256();\n\n    for (; i + 32 <= length; i += 32) {\n        __m256i data = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&s[i]));\n        __m256i mask = _mm256_cmpgt_epi8(data, _mm256_set1_epi8('A' - 1));\n        __m256i mask_upper = _mm256_and_si256(mask, _mm256_cmpgt_epi8(data, _mm256_set1_epi8('Z')));\n        __m256i ascii_values = _mm256_and_si256(mask_upper, data);\n        total_sum = _mm256_add_epi8(total_sum, ascii_values);\n    }\n\n    // Horizontal sum of the 32 bytes in total_sum\n    total_sum = _mm256_hadd_epi16(total_sum, total_sum);\n    total_sum = _mm256_hadd_epi16(total_sum, total_sum);\n    total_sum = _mm256_hadd_epi16(total_sum, total_sum);\n    \n    // Extract the sum from the resulting vector\n    sum += _mm256_extract_epi16(total_sum, 0);\n    sum += _mm256_extract_epi16(total_sum, 1);\n    \n    // Handle remaining characters\n    for (; i < length; ++i) {\n        if (s[i] >= 'A' && s[i] <= 'Z') {\n            sum += static_cast<int>(s[i]);\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_94_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nstd::vector<int> pluck_simd(std::vector<int> arr) {\n    const int n = arr.size();\n    if (n == 0) return {};\n\n    __m256i min_even = _mm256_set1_epi32(INT32_MAX);\n    __m256i min_index = _mm256_set1_epi32(-1);\n    __m256i indices = _mm256_setr_epi32(0, 1, 2, 3, 4, 5, 6, 7);\n    \n    int i = 0;\n    for (; i <= n - 8; i += 8) {\n        __m256i values = _mm256_loadu_si256((__m256i*)&arr[i]);\n        __m256i mask = _mm256_and_si256(values, _mm256_set1_epi32(1)); // Check for even\n        __m256i even_values = _mm256_blendv_epi8(values, _mm256_set1_epi32(INT32_MAX), mask);\n        \n        // Compare and find minimum even value\n        min_even = _mm256_min_epi32(min_even, even_values);\n        \n        // Update indices for even values\n        __m256i valid_indices = _mm256_blendv_epi8(indices, _mm256_set1_epi32(-1), mask);\n        min_index = _mm256_blendv_epi8(min_index, valid_indices, _mm256_cmpeq_epi32(even_values, min_even));\n    }\n\n    // Handle remaining elements\n    for (; i < n; ++i) {\n        if (arr[i] % 2 == 0) {\n            if (arr[i] < _mm256_extract_epi32(min_even, 0)) {\n                min_even = _mm256_set1_epi32(arr[i]);\n                min_index = _mm256_set1_epi32(i);\n            }\n        }\n    }\n\n    int smallest_value = _mm256_extract_epi32(min_even, 0);\n    int smallest_index = _mm256_extract_epi32(min_index, 0);\n\n    if (smallest_value == INT32_MAX) return {};\n\n    return {smallest_value, smallest_index};\n}\n```"}
{"task_id": "SimdBench_94_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n#include <limits>\n\nstd::vector<int> pluck_simd(std::vector<int> arr) {\n    const int n = arr.size();\n    if (n == 0) return {};\n\n    __m256i min_even = _mm256_set1_epi32(std::numeric_limits<int>::max());\n    __m256i min_index = _mm256_set1_epi32(-1);\n    __m256i zero = _mm256_set1_epi32(0);\n    __m256i index_vec = _mm256_set_epi32(n-1, n-2, n-3, n-4, n-5, n-6, n-7, n-8);\n    \n    int i = 0;\n    for (; i <= n - 8; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&arr[i]);\n        __m256i is_even = _mm256_and_si256(vec, _mm256_set1_epi32(1));\n        __m256i even_mask = _mm256_cmpeq_epi32(is_even, zero);\n        \n        __m256i even_values = _mm256_blendv_epi8(vec, _mm256_set1_epi32(std::numeric_limits<int>::max()), even_mask);\n        min_even = _mm256_min_epi32(min_even, even_values);\n        \n        __m256i index_mask = _mm256_cmpeq_epi32(even_values, min_even);\n        min_index = _mm256_blendv_epi8(min_index, index_vec, index_mask);\n        \n        index_vec = _mm256_sub_epi32(index_vec, _mm256_set1_epi32(1));\n    }\n\n    int min_even_val = std::numeric_limits<int>::max();\n    int min_even_idx = -1;\n\n    for (; i < n; ++i) {\n        if (arr[i] % 2 == 0 && arr[i] < min_even_val) {\n            min_even_val = arr[i];\n            min_even_idx = i;\n        }\n    }\n\n    int result_even[8], result_index[8];\n    _mm256_storeu_si256((__m256i*)result_even, min_even);\n    _mm256_storeu_si256((__m256i*)result_index, min_index);\n\n    for (int j = 0; j < 8; ++j) {\n        if (result_even[j] < min_even_val) {\n            min_even_val = result_even[j];\n            min_even_idx = result_index[j];\n        }\n    }\n\n    if (min_even_idx == -1) return {};\n    return {min_even_val, min_even_idx};\n}\n```"}
{"task_id": "SimdBench_94_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nstd::vector<int> pluck_simd(std::vector<int> arr) {\n    const int n = arr.size();\n    if (n == 0) return {};\n\n    __m256i min_even = _mm256_set1_epi32(INT32_MAX);\n    __m256i min_index = _mm256_set1_epi32(-1);\n    __m256i indices = _mm256_setr_epi32(0, 1, 2, 3, 4, 5, 6, 7);\n    \n    int i = 0;\n    for (; i <= n - 8; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&arr[i]);\n        __m256i mask = _mm256_and_si256(vec, _mm256_set1_epi32(1)); // Check for even numbers\n        __m256i even_values = _mm256_blendv_epi8(vec, _mm256_set1_epi32(INT32_MAX), mask); // Replace odd with max int\n        \n        // Compare with current minimum even value\n        __m256i cmp_mask = _mm256_cmpgt_epi32(min_even, even_values);\n        min_even = _mm256_blendv_epi8(min_even, even_values, cmp_mask);\n        \n        // Update indices for the minimum even values\n        __m256i index_mask = _mm256_blendv_epi8(min_index, indices, cmp_mask);\n        min_index = _mm256_blendv_epi8(min_index, index_mask, cmp_mask);\n        \n        indices = _mm256_add_epi32(indices, _mm256_set1_epi32(8));\n    }\n\n    // Handle remaining elements\n    for (; i < n; ++i) {\n        if (arr[i] % 2 == 0 && arr[i] < min_even[0]) {\n            min_even = _mm256_set1_epi32(arr[i]);\n            min_index = _mm256_set1_epi32(i);\n        }\n    }\n\n    // Extract results\n    int smallest_value = min_even[0];\n    int smallest_index = min_index[0];\n\n    if (smallest_value == INT32_MAX) return {};\n\n    return {smallest_value, smallest_index};\n}\n```"}
{"task_id": "SimdBench_94_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nstd::vector<int> pluck_simd(std::vector<int> arr) {\n    const int n = arr.size();\n    if (n == 0) return {};\n\n    __m256i min_even = _mm256_set1_epi32(INT32_MAX);\n    __m256i min_index = _mm256_set1_epi32(-1);\n    int index = 0;\n    int min_value = INT32_MAX;\n\n    for (int i = 0; i < n; i += 8) {\n        __m256i values = _mm256_loadu_si256((__m256i*)&arr[i]);\n        __m256i mask = _mm256_and_si256(values, _mm256_set1_epi32(1)); // mask for even numbers\n        __m256i even_values = _mm256_blendv_epi8(values, _mm256_set1_epi32(INT32_MAX), mask); // set odd to max\n\n        min_even = _mm256_min_epi32(min_even, even_values);\n        \n        __m256i indices = _mm256_set_epi32(i + 7, i + 6, i + 5, i + 4, i + 3, i + 2, i + 1, i);\n        __m256i index_mask = _mm256_cmpeq_epi32(even_values, min_even);\n        min_index = _mm256_blendv_epi8(min_index, indices, index_mask);\n    }\n\n    // Extract the minimum even value and its index\n    int min_even_array[8];\n    int min_index_array[8];\n    _mm256_storeu_si256((__m256i*)min_even_array, min_even);\n    _mm256_storeu_si256((__m256i*)min_index_array, min_index);\n\n    for (int j = 0; j < 8; ++j) {\n        if (min_even_array[j] < min_value) {\n            min_value = min_even_array[j];\n            index = min_index_array[j];\n        }\n    }\n\n    if (min_value == INT32_MAX) return {};\n    return {min_value, index};\n}\n```"}
{"task_id": "SimdBench_94_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nstd::vector<int> pluck_simd(std::vector<int> arr) {\n    const int n = arr.size();\n    if (n == 0) return {};\n\n    __m256i min_even = _mm256_set1_epi32(INT32_MAX);\n    __m256i min_index = _mm256_set1_epi32(-1);\n    __m256i indices = _mm256_setr_epi32(0, 1, 2, 3, 4, 5, 6, 7);\n\n    int i = 0;\n    for (; i <= n - 8; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&arr[i]);\n        __m256i mask = _mm256_and_si256(vec, _mm256_set1_epi32(1)); // Check for even\n        __m256i even_values = _mm256_blendv_epi8(vec, _mm256_set1_epi32(INT32_MAX), mask);\n\n        min_even = _mm256_min_epi32(min_even, even_values);\n        __m256i index_mask = _mm256_cmpeq_epi32(even_values, min_even);\n        min_index = _mm256_blendv_epi8(min_index, indices, index_mask);\n    }\n\n    // Handle remaining elements\n    for (; i < n; ++i) {\n        if (arr[i] % 2 == 0) {\n            if (arr[i] < min_even[0]) {\n                min_even = _mm256_set1_epi32(arr[i]);\n                min_index = _mm256_set1_epi32(i);\n            } else if (arr[i] == min_even[0] && i < min_index[0]) {\n                min_index = _mm256_set1_epi32(i);\n            }\n        }\n    }\n\n    if (min_even[0] == INT32_MAX) return {};\n\n    return {min_even[0], min_index[0]};\n}\n```"}
{"task_id": "SimdBench_95_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n#include <unordered_map>\n\nint search_simd(std::vector<int> lst) {\n    const int size = lst.size();\n    int max_value = 0;\n\n    // Count frequencies using a hash map\n    std::unordered_map<int, int> frequency_map;\n    for (int num : lst) {\n        frequency_map[num]++;\n        if (num > max_value) {\n            max_value = num;\n        }\n    }\n\n    // Prepare to check frequencies using AVX2\n    __m256i max_freq = _mm256_set1_epi32(-1);\n    __m256i result = _mm256_set1_epi32(-1);\n\n    for (int i = 1; i <= max_value; i += 8) {\n        __m256i indices = _mm256_set_epi32(i + 7, i + 6, i + 5, i + 4, i + 3, i + 2, i + 1, i);\n        __m256i freqs = _mm256_set_epi32(\n            frequency_map[i + 7],\n            frequency_map[i + 6],\n            frequency_map[i + 5],\n            frequency_map[i + 4],\n            frequency_map[i + 3],\n            frequency_map[i + 2],\n            frequency_map[i + 1],\n            frequency_map[i]\n        );\n\n        __m256i mask = _mm256_cmpgt_epi32(freqs, indices);\n        if (_mm256_movemask_epi8(mask) != 0) {\n            // Find the maximum valid index\n            for (int j = 0; j < 8; j++) {\n                if (_mm256_extract_epi32(mask, j) > 0) {\n                    result = _mm256_max_epi32(result, indices);\n                }\n            }\n        }\n    }\n\n    // Extract the maximum value from the result\n    int final_result = -1;\n    for (int i = 0; i < 8; i++) {\n        final_result = std::max(final_result, _mm256_extract_epi32(result, i));\n    }\n\n    return final_result > 0 ? final_result : -1;\n}\n```"}
{"task_id": "SimdBench_95_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n#include <unordered_map>\n\nint search_simd(std::vector<int> lst) {\n    const int size = lst.size();\n    std::unordered_map<int, int> frequency;\n\n    // Count frequencies using SIMD\n    for (int i = 0; i < size; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&lst[i]);\n        for (int j = 0; j < 8; ++j) {\n            int value = _mm256_extract_epi32(vec, j);\n            if (value > 0) {\n                frequency[value]++;\n            }\n        }\n    }\n\n    int result = -1;\n    for (const auto& pair : frequency) {\n        if (pair.first <= pair.second) {\n            result = std::max(result, pair.first);\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_95_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n#include <unordered_map>\n\nint search_simd(std::vector<int> lst) {\n    const int size = lst.size();\n    const int max_val = 100; // Assuming the maximum value in the vector is 100 for frequency counting\n    std::unordered_map<int, int> freq_map;\n\n    // Count frequencies using SIMD\n    for (int i = 0; i < size; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&lst[i]);\n        for (int j = 0; j < 8; ++j) {\n            int value = _mm256_extract_epi32(vec, j);\n            if (value > 0) {\n                freq_map[value]++;\n            }\n        }\n    }\n\n    // Find the greatest integer with required frequency\n    int result = -1;\n    for (int i = 1; i <= max_val; ++i) {\n        if (freq_map[i] >= i) {\n            result = i;\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_95_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n#include <unordered_map>\n\nint search_simd(std::vector<int> lst) {\n    const int size = lst.size();\n    const int max_value = 256; // Assuming the maximum integer value in lst is less than 256\n    std::unordered_map<int, int> frequency;\n\n    // Count frequencies using SIMD\n    for (int i = 0; i < size; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&lst[i]);\n        for (int j = 0; j < 8; ++j) {\n            int value = ((int*)&vec)[j];\n            if (value > 0) {\n                frequency[value]++;\n            }\n        }\n    }\n\n    // Find the greatest integer that meets the criteria\n    int result = -1;\n    for (int i = 1; i < max_value; ++i) {\n        if (frequency[i] >= i) {\n            result = i;\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_95_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n#include <unordered_map>\n\nint search_simd(std::vector<int> lst) {\n    const int size = lst.size();\n    int max_value = 0;\n\n    // Count frequencies using a hash map\n    std::unordered_map<int, int> frequency_map;\n    for (int num : lst) {\n        frequency_map[num]++;\n        if (num > max_value) {\n            max_value = num;\n        }\n    }\n\n    // Prepare to check frequencies using AVX2\n    __m256i max_freq = _mm256_set1_epi32(-1);\n    __m256i result = _mm256_set1_epi32(-1);\n\n    for (int i = 1; i <= max_value; i += 8) {\n        __m256i indices = _mm256_set_epi32(i + 7, i + 6, i + 5, i + 4, i + 3, i + 2, i + 1, i);\n        __m256i freqs = _mm256_set_epi32(\n            frequency_map[i + 7],\n            frequency_map[i + 6],\n            frequency_map[i + 5],\n            frequency_map[i + 4],\n            frequency_map[i + 3],\n            frequency_map[i + 2],\n            frequency_map[i + 1],\n            frequency_map[i]\n        );\n\n        __m256i mask = _mm256_cmpgt_epi32(freqs, indices);\n        if (_mm256_movemask_epi8(mask) != 0) {\n            result = _mm256_blendv_epi8(result, indices, mask);\n        }\n    }\n\n    // Extract the maximum valid result\n    int max_result = -1;\n    for (int i = 0; i < 8; i++) {\n        int val = _mm256_extract_epi32(result, i);\n        if (val > max_result) {\n            max_result = val;\n        }\n    }\n\n    return max_result > 0 ? max_result : -1;\n}\n```"}
{"task_id": "SimdBench_96_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nbool will_it_fly_simd(std::vector<int> q, int w) {\n    int n = q.size();\n    if (n == 0) return false;\n\n    // Check if the vector is balanced (palindromic)\n    for (int i = 0; i < n / 2; ++i) {\n        if (q[i] != q[n - 1 - i]) {\n            return false;\n        }\n    }\n\n    // Calculate the sum using AVX2\n    __m256i sum_vec = _mm256_setzero_si256();\n    int i = 0;\n\n    for (; i <= n - 8; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&q[i]);\n        sum_vec = _mm256_add_epi32(sum_vec, vec);\n    }\n\n    // Handle remaining elements\n    int sum = _mm256_reduce_add_epi32(sum_vec);\n    for (; i < n; ++i) {\n        sum += q[i];\n    }\n\n    return sum <= w;\n}\n```"}
{"task_id": "SimdBench_96_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nbool will_it_fly_simd(std::vector<int> q, int w) {\n    int n = q.size();\n    if (n == 0) return false;\n\n    // Check if the vector is balanced (palindromic)\n    for (int i = 0; i < n / 2; ++i) {\n        if (q[i] != q[n - 1 - i]) {\n            return false;\n        }\n    }\n\n    // Calculate the sum using AVX2\n    __m256i sum_vec = _mm256_setzero_si256();\n    int i = 0;\n\n    for (; i <= n - 8; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&q[i]);\n        sum_vec = _mm256_add_epi32(sum_vec, vec);\n    }\n\n    // Handle remaining elements\n    int sum = _mm256_extract_epi32(sum_vec, 0) + _mm256_extract_epi32(sum_vec, 1) +\n              _mm256_extract_epi32(sum_vec, 2) + _mm256_extract_epi32(sum_vec, 3) +\n              _mm256_extract_epi32(sum_vec, 4) + _mm256_extract_epi32(sum_vec, 5) +\n              _mm256_extract_epi32(sum_vec, 6) + _mm256_extract_epi32(sum_vec, 7);\n\n    for (; i < n; ++i) {\n        sum += q[i];\n    }\n\n    return sum <= w;\n}\n```"}
{"task_id": "SimdBench_96_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nbool will_it_fly_simd(std::vector<int> q, int w) {\n    int n = q.size();\n    if (n == 0) return false;\n\n    // Check if the vector is balanced (palindromic)\n    for (int i = 0; i < n / 2; i++) {\n        if (q[i] != q[n - 1 - i]) {\n            return false;\n        }\n    }\n\n    // Calculate the sum using AVX2\n    __m256i sum_vec = _mm256_setzero_si256();\n    int i = 0;\n\n    for (; i <= n - 8; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&q[i]);\n        sum_vec = _mm256_add_epi32(sum_vec, vec);\n    }\n\n    // Handle remaining elements\n    int sum = _mm256_extract_epi32(sum_vec, 0) + _mm256_extract_epi32(sum_vec, 1) +\n              _mm256_extract_epi32(sum_vec, 2) + _mm256_extract_epi32(sum_vec, 3) +\n              _mm256_extract_epi32(sum_vec, 4) + _mm256_extract_epi32(sum_vec, 5) +\n              _mm256_extract_epi32(sum_vec, 6) + _mm256_extract_epi32(sum_vec, 7);\n\n    for (; i < n; i++) {\n        sum += q[i];\n    }\n\n    return sum <= w;\n}\n```"}
{"task_id": "SimdBench_96_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nbool will_it_fly_simd(std::vector<int> q, int w) {\n    int n = q.size();\n    if (n == 0) return false;\n\n    // Check for balance (palindromic)\n    for (int i = 0; i < n / 2; ++i) {\n        if (q[i] != q[n - 1 - i]) {\n            return false;\n        }\n    }\n\n    // Calculate sum using AVX2\n    __m256i sum_vec = _mm256_setzero_si256();\n    int i = 0;\n\n    for (; i <= n - 8; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&q[i]);\n        sum_vec = _mm256_add_epi32(sum_vec, vec);\n    }\n\n    // Horizontal sum for remaining elements\n    int sum = _mm256_extract_epi32(sum_vec, 0) + _mm256_extract_epi32(sum_vec, 1) +\n              _mm256_extract_epi32(sum_vec, 2) + _mm256_extract_epi32(sum_vec, 3) +\n              _mm256_extract_epi32(sum_vec, 4) + _mm256_extract_epi32(sum_vec, 5) +\n              _mm256_extract_epi32(sum_vec, 6) + _mm256_extract_epi32(sum_vec, 7);\n\n    for (; i < n; ++i) {\n        sum += q[i];\n    }\n\n    return sum <= w;\n}\n```"}
{"task_id": "SimdBench_96_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nbool will_it_fly_simd(std::vector<int> q, int w) {\n    int n = q.size();\n    if (n == 0) return false;\n\n    // Check for balance (palindromic)\n    for (int i = 0; i < n / 2; ++i) {\n        if (q[i] != q[n - 1 - i]) {\n            return false;\n        }\n    }\n\n    // Calculate the sum using AVX2\n    __m256i sum_vec = _mm256_setzero_si256();\n    int i = 0;\n\n    for (; i <= n - 8; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&q[i]);\n        sum_vec = _mm256_add_epi32(sum_vec, vec);\n    }\n\n    // Handle remaining elements\n    int sum = _mm256_extract_epi32(sum_vec, 0) + _mm256_extract_epi32(sum_vec, 1) +\n              _mm256_extract_epi32(sum_vec, 2) + _mm256_extract_epi32(sum_vec, 3) +\n              _mm256_extract_epi32(sum_vec, 4) + _mm256_extract_epi32(sum_vec, 5) +\n              _mm256_extract_epi32(sum_vec, 6) + _mm256_extract_epi32(sum_vec, 7);\n\n    for (; i < n; ++i) {\n        sum += q[i];\n    }\n\n    return sum <= w;\n}\n```"}
{"task_id": "SimdBench_97_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nint smallest_change_simd(std::vector<int> arr) {\n    int n = arr.size();\n    int changes = 0;\n\n    for (int i = 0; i < n / 2; i += 8) {\n        __m256i left = _mm256_loadu_si256((__m256i*)&arr[i]);\n        __m256i right = _mm256_loadu_si256((__m256i*)&arr[n - 1 - i]);\n\n        // Compare left and right elements\n        __m256i cmp = _mm256_cmpeq_epi32(left, right);\n        // Count the number of equal elements\n        int mask = _mm256_movemask_epi8(cmp);\n        changes += 8 - __builtin_popcount(mask);\n    }\n\n    // Handle the case where n is odd\n    if (n % 2 != 0) {\n        changes += (arr[n / 2] != arr[n / 2]);\n    }\n\n    return changes;\n}\n```"}
{"task_id": "SimdBench_97_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n#include <algorithm>\n\nint smallest_change_simd(std::vector<int> arr) {\n    int n = arr.size();\n    int changes = 0;\n\n    for (int i = 0; i < n / 2; i += 8) {\n        __m256i left = _mm256_loadu_si256((__m256i*)&arr[i]);\n        __m256i right = _mm256_loadu_si256((__m256i*)&arr[n - 1 - i]);\n\n        // Compare elements\n        __m256i cmp = _mm256_cmpeq_epi32(left, right);\n        // Count mismatches\n        int mask = _mm256_movemask_epi8(cmp);\n        changes += __builtin_popcount(mask ^ 0xFFFF); // Count bits that are not equal\n    }\n\n    if (n % 2 != 0) {\n        // Handle the middle element for odd-length arrays\n        changes += 0; // No change needed for the middle element\n    }\n\n    return changes;\n}\n```"}
{"task_id": "SimdBench_97_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n#include <algorithm>\n\nint smallest_change_simd(std::vector<int> arr) {\n    int n = arr.size();\n    int changes = 0;\n\n    // Process pairs from both ends towards the center\n    for (int i = 0; i < n / 2; i += 8) {\n        __m256i left = _mm256_loadu_si256((__m256i*)&arr[i]);\n        __m256i right = _mm256_loadu_si256((__m256i*)&arr[n - 1 - i]);\n\n        // Compare left and right elements\n        __m256i cmp = _mm256_cmpeq_epi32(left, right);\n        int mask = _mm256_movemask_epi8(cmp);\n\n        // Count mismatches\n        changes += __builtin_popcount(mask ^ 0xFFFF); // Count bits that are not equal\n    }\n\n    // Handle the case for odd length arrays\n    if (n % 2 != 0) {\n        changes += (arr[n / 2] != arr[n / 2]) ? 1 : 0;\n    }\n\n    return changes;\n}\n```"}
{"task_id": "SimdBench_97_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n#include <algorithm>\n\nint smallest_change_simd(std::vector<int> arr) {\n    int n = arr.size();\n    int changes = 0;\n\n    for (int i = 0; i < n / 2; i += 8) {\n        __m256i left = _mm256_loadu_si256((__m256i*)&arr[i]);\n        __m256i right = _mm256_loadu_si256((__m256i*)&arr[n - i - 8]);\n\n        __m256i cmp = _mm256_cmpeq_epi32(left, right);\n        int mask = _mm256_movemask_epi8(cmp);\n\n        changes += 8 - __builtin_popcount(mask);\n    }\n\n    if (n % 2 != 0) {\n        changes += (arr[n / 2] != arr[n / 2]);\n    }\n\n    return changes;\n}\n```"}
{"task_id": "SimdBench_97_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nint smallest_change_simd(std::vector<int> arr) {\n    int n = arr.size();\n    int changes = 0;\n\n    for (int i = 0; i < n / 2; i += 8) {\n        __m256i left = _mm256_loadu_si256((__m256i*)&arr[i]);\n        __m256i right = _mm256_loadu_si256((__m256i*)&arr[n - 1 - i]);\n\n        // Compare left and right elements\n        __m256i cmp = _mm256_cmpeq_epi32(left, right);\n        // Count mismatches\n        int mask = _mm256_movemask_epi8(cmp);\n        changes += __builtin_popcount(mask ^ 0xFFFF); // Count the number of differing bits\n    }\n\n    // Handle the case where the number of elements is odd\n    if (n % 2 != 0) {\n        changes += (arr[n / 2] != arr[n / 2]) ? 1 : 0;\n    }\n\n    return changes;\n}\n```"}
{"task_id": "SimdBench_98_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n\nstd::vector<std::string> total_match_simd(const std::vector<std::string> & lst1, const std::vector<std::string> & lst2) {\n    size_t total1 = 0, total2 = 0;\n\n    size_t size1 = lst1.size();\n    size_t size2 = lst2.size();\n\n    // Calculate total characters in lst1\n    for (size_t i = 0; i < size1; ++i) {\n        total1 += lst1[i].size();\n    }\n\n    // Calculate total characters in lst2\n    for (size_t i = 0; i < size2; ++i) {\n        total2 += lst2[i].size();\n    }\n\n    if (total1 < total2) {\n        return lst1;\n    } else {\n        return lst2;\n    }\n}\n```"}
{"task_id": "SimdBench_98_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n\nstd::vector<std::string> total_match_simd(const std::vector<std::string> & lst1, const std::vector<std::string> & lst2) {\n    size_t total1 = 0, total2 = 0;\n\n    size_t size1 = lst1.size();\n    size_t size2 = lst2.size();\n\n    // Calculate total length for lst1\n    for (size_t i = 0; i < size1; ++i) {\n        total1 += lst1[i].size();\n    }\n\n    // Calculate total length for lst2\n    for (size_t i = 0; i < size2; ++i) {\n        total2 += lst2[i].size();\n    }\n\n    if (total1 < total2) {\n        return lst1;\n    } else {\n        return lst2;\n    }\n}\n```"}
{"task_id": "SimdBench_98_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n\nstd::vector<std::string> total_match_simd(const std::vector<std::string> & lst1, const std::vector<std::string> & lst2) {\n    size_t total1 = 0, total2 = 0;\n\n    size_t size1 = lst1.size();\n    size_t size2 = lst2.size();\n\n    size_t i = 0;\n    for (; i + 4 <= size1; i += 4) {\n        __m256i lengths = _mm256_set_epi32(lst1[i + 3].length(), lst1[i + 2].length(), lst1[i + 1].length(), lst1[i].length());\n        total1 += _mm256_extract_epi32(lengths, 0) + _mm256_extract_epi32(lengths, 1) + _mm256_extract_epi32(lengths, 2) + _mm256_extract_epi32(lengths, 3);\n    }\n    for (; i < size1; ++i) {\n        total1 += lst1[i].length();\n    }\n\n    i = 0;\n    for (; i + 4 <= size2; i += 4) {\n        __m256i lengths = _mm256_set_epi32(lst2[i + 3].length(), lst2[i + 2].length(), lst2[i + 1].length(), lst2[i].length());\n        total2 += _mm256_extract_epi32(lengths, 0) + _mm256_extract_epi32(lengths, 1) + _mm256_extract_epi32(lengths, 2) + _mm256_extract_epi32(lengths, 3);\n    }\n    for (; i < size2; ++i) {\n        total2 += lst2[i].length();\n    }\n\n    if (total1 < total2) {\n        return lst1;\n    } else {\n        return lst2;\n    }\n}\n```"}
{"task_id": "SimdBench_98_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n\nstd::vector<std::string> total_match_simd(const std::vector<std::string> & lst1, const std::vector<std::string> & lst2) {\n    size_t total1 = 0, total2 = 0;\n\n    size_t size1 = lst1.size();\n    size_t size2 = lst2.size();\n\n    // Calculate total characters in lst1\n    for (size_t i = 0; i < size1; ++i) {\n        total1 += lst1[i].size();\n    }\n\n    // Calculate total characters in lst2\n    for (size_t i = 0; i < size2; ++i) {\n        total2 += lst2[i].size();\n    }\n\n    if (total1 < total2) {\n        return lst1;\n    } else {\n        return lst2;\n    }\n}\n```"}
{"task_id": "SimdBench_98_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n\nstd::vector<std::string> total_match_simd(const std::vector<std::string> & lst1, const std::vector<std::string> & lst2) {\n    size_t total1 = 0, total2 = 0;\n\n    size_t size1 = lst1.size();\n    size_t size2 = lst2.size();\n    \n    size_t minSize = std::min(size1, size2);\n    \n    // Process lst1\n    for (size_t i = 0; i < minSize; i += 4) {\n        __m128i lengths = _mm_setzero_si128();\n        for (size_t j = 0; j < 4 && (i + j) < size1; ++j) {\n            lengths = _mm_add_epi32(lengths, _mm_set1_epi32(lst1[i + j].size()));\n        }\n        total1 += _mm_extract_epi32(lengths, 0) + _mm_extract_epi32(lengths, 1) + _mm_extract_epi32(lengths, 2) + _mm_extract_epi32(lengths, 3);\n    }\n    \n    // Process lst2\n    for (size_t i = 0; i < minSize; i += 4) {\n        __m128i lengths = _mm_setzero_si128();\n        for (size_t j = 0; j < 4 && (i + j) < size2; ++j) {\n            lengths = _mm_add_epi32(lengths, _mm_set1_epi32(lst2[i + j].size()));\n        }\n        total2 += _mm_extract_epi32(lengths, 0) + _mm_extract_epi32(lengths, 1) + _mm_extract_epi32(lengths, 2) + _mm_extract_epi32(lengths, 3);\n    }\n\n    if (total1 < total2) {\n        return lst1;\n    } else {\n        return lst2;\n    }\n}\n```"}
{"task_id": "SimdBench_99_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <stdint.h>\n\nbool is_simple_power_simd(uint64_t x, uint64_t n) {\n    if (n <= 1) return x == n; // Handle edge cases for n = 0, 1\n    if (x < 1) return false; // x must be at least 1\n\n    __m256i n_vec = _mm256_set1_epi64x(n);\n    __m256i x_vec = _mm256_set1_epi64x(x);\n    __m256i result = _mm256_set1_epi64x(0);\n\n    for (uint64_t power = 1; power <= 63; power++) {\n        __m256i power_vec = _mm256_set1_epi64x(power);\n        __m256i n_pow_vec = _mm256_pow_epi64(n_vec, power_vec);\n        \n        __m256i cmp = _mm256_cmpeq_epi64(n_pow_vec, x_vec);\n        result = _mm256_or_si256(result, cmp);\n    }\n\n    return _mm256_movemask_epi8(result) != 0;\n}\n```"}
{"task_id": "SimdBench_99_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <stdint.h>\n\nbool is_simple_power_simd(uint64_t x, uint64_t n) {\n    if (n <= 1) return false;\n    if (x == 1) return true;\n\n    __m256i n_vec = _mm256_set1_epi64x(n);\n    __m256i x_vec = _mm256_set1_epi64x(x);\n    __m256i result = _mm256_set1_epi64x(0);\n    \n    for (uint64_t i = 1; i <= 64; i++) {\n        __m256i power_vec = _mm256_set1_epi64x(1);\n        for (uint64_t j = 0; j < i; j++) {\n            power_vec = _mm256_mullo_epi64(power_vec, n_vec);\n        }\n        result = _mm256_or_si256(result, _mm256_cmpeq_epi64(power_vec, x_vec));\n    }\n\n    return _mm256_movemask_epi8(result) != 0;\n}\n```"}
{"task_id": "SimdBench_99_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <stdint.h>\n\nbool is_simple_power_simd(uint64_t x, uint64_t n) {\n    if (n <= 1) return false;\n    if (x == 1) return true;\n\n    __m256i n_vec = _mm256_set1_epi64x(n);\n    __m256i x_vec = _mm256_set1_epi64x(x);\n    __m256i result = _mm256_set1_epi64x(0);\n    \n    for (uint64_t i = 1; i <= 64; i++) {\n        __m256i power_vec = _mm256_set1_epi64x(1);\n        for (uint64_t j = 0; j < i; j++) {\n            power_vec = _mm256_mullo_epi64(power_vec, n_vec);\n        }\n        result = _mm256_or_si256(result, _mm256_cmpeq_epi64(power_vec, x_vec));\n    }\n\n    return _mm256_movemask_epi8(result) != 0;\n}\n```"}
{"task_id": "SimdBench_99_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <stdint.h>\n\nbool is_simple_power_simd(uint64_t x, uint64_t n) {\n    if (n <= 1) return false;\n    if (x == 1) return true;\n\n    __m256i n_vec = _mm256_set1_epi64x(n);\n    __m256i x_vec = _mm256_set1_epi64x(x);\n    __m256i result = _mm256_set1_epi64x(0);\n\n    for (uint64_t power = 1; power <= 63; power++) {\n        __m256i power_vec = _mm256_set1_epi64x(power);\n        __m256i n_pow_vec = _mm256_pow_epi64(n_vec, power_vec);\n        \n        __m256i cmp = _mm256_cmpeq_epi64(n_pow_vec, x_vec);\n        result = _mm256_or_si256(result, cmp);\n    }\n\n    return _mm256_movemask_epi8(result) != 0;\n}\n```"}
{"task_id": "SimdBench_99_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <stdint.h>\n\nbool is_simple_power_simd(uint64_t x, uint64_t n) {\n    if (n <= 1) return x == n; // Handle edge cases for n = 0, 1\n    if (x < 1) return false; // x must be at least 1\n\n    __m256i n_vec = _mm256_set1_epi64x(n);\n    __m256i x_vec = _mm256_set1_epi64x(x);\n    __m256i power_vec = _mm256_set1_epi64x(1);\n    \n    for (int i = 0; i < 64; i++) {\n        if (_mm256_extract_epi64(power_vec, 0) == x) return true;\n        power_vec = _mm256_mullo_epi64(power_vec, n_vec);\n        if (_mm256_extract_epi64(power_vec, 0) > x) break;\n    }\n    \n    return false;\n}\n```"}
{"task_id": "SimdBench_100_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <string>\n\nint hex_key_simd(const std::string & num) {\n    const __m256i primes = _mm256_setr_epi8(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n                                            0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n    const __m256i hex_values = _mm256_setr_epi8(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, \n                                                10, 11, 12, 13, 14, 15, 0);\n    const __m256i mask = _mm256_setr_epi8(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n                                          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n                                          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n                                          0, 0);\n    int count = 0;\n    size_t length = num.length();\n    size_t i = 0;\n\n    for (; i + 32 <= length; i += 32) {\n        __m256i data = _mm256_setr_epi8(num[i + 31], num[i + 30], num[i + 29], num[i + 28],\n                                         num[i + 27], num[i + 26], num[i + 25], num[i + 24],\n                                         num[i + 23], num[i + 22], num[i + 21], num[i + 20],\n                                         num[i + 19], num[i + 18], num[i + 17], num[i + 16],\n                                         num[i + 15], num[i + 14], num[i + 13], num[i + 12],\n                                         num[i + 11], num[i + 10], num[i + 9], num[i + 8],\n                                         num[i + 7], num[i + 6], num[i + 5], num[i + 4],\n                                         num[i + 3], num[i + 2], num[i + 1], num[i]);\n\n        __m256i cmp = _mm256_cmpeq_epi8(data, _mm256_setr_epi8('2', '3', '5', '7', 'B', 'D', \n                                                                '2', '3', '5', '7', 'B', 'D', \n                                                                '2', '3', '5', '7', 'B', 'D', \n                                                                '2', '3', '5', '7', 'B', 'D', \n                                                                '2', '3', '5', '7', 'B', 'D', \n                                                                '2', '3', '5', '7', 'B', 'D'));\n\n        count += _mm256_movemask_epi8(cmp);\n    }\n\n    for (; i < length; ++i) {\n        char c = num[i];\n        if (c == '2' || c == '3' || c == '5' || c == '7' || c == 'B' || c == 'D') {\n            count++;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_100_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <string>\n\nint hex_key_simd(const std::string & num) {\n    const __m256i primes = _mm256_setr_epi8(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n    const __m256i mask = _mm256_setr_epi8(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n    \n    int count = 0;\n    size_t length = num.length();\n    size_t i = 0;\n\n    for (; i + 32 <= length; i += 32) {\n        __m256i hex_chars = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(num.data() + i));\n        __m256i hex_values = _mm256_sub_epi8(hex_chars, _mm256_set1_epi8('0'));\n        __m256i is_prime = _mm256_or_si256(\n            _mm256_cmpeq_epi8(hex_values, _mm256_set1_epi8(2)),\n            _mm256_or_si256(\n                _mm256_cmpeq_epi8(hex_values, _mm256_set1_epi8(3)),\n                _mm256_or_si256(\n                    _mm256_cmpeq_epi8(hex_values, _mm256_set1_epi8(5)),\n                    _mm256_or_si256(\n                        _mm256_cmpeq_epi8(hex_values, _mm256_set1_epi8(7)),\n                        _mm256_or_si256(\n                            _mm256_cmpeq_epi8(hex_values, _mm256_set1_epi8(11)),\n                            _mm256_cmpeq_epi8(hex_values, _mm256_set1_epi8(13))\n                        )\n                    )\n                )\n            )\n        );\n\n        count += _mm256_movemask_epi8(is_prime);\n    }\n\n    for (; i < length; ++i) {\n        char c = num[i];\n        if (c == '2' || c == '3' || c == '5' || c == '7' || c == 'B' || c == 'D') {\n            count++;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_100_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <string>\n\nint hex_key_simd(const std::string & num) {\n    const __m256i primes = _mm256_setr_epi8(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n                                            0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n    const __m256i hex_values = _mm256_setr_epi8(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15);\n    const __m256i prime_mask = _mm256_setr_epi8(0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0);\n\n    int count = 0;\n    size_t len = num.length();\n    size_t i = 0;\n\n    for (; i + 32 <= len; i += 32) {\n        __m256i input = _mm256_setr_epi8(num[i + 31], num[i + 30], num[i + 29], num[i + 28], \n                                          num[i + 27], num[i + 26], num[i + 25], num[i + 24],\n                                          num[i + 23], num[i + 22], num[i + 21], num[i + 20],\n                                          num[i + 19], num[i + 18], num[i + 17], num[i + 16],\n                                          num[i + 15], num[i + 14], num[i + 13], num[i + 12],\n                                          num[i + 11], num[i + 10], num[i + 9], num[i + 8],\n                                          num[i + 7], num[i + 6], num[i + 5], num[i + 4],\n                                          num[i + 3], num[i + 2], num[i + 1], num[i]);\n\n        __m256i hex_digits = _mm256_sub_epi8(input, _mm256_set1_epi8('0'));\n        __m256i mask = _mm256_or_si256(_mm256_cmpeq_epi8(hex_digits, _mm256_set1_epi8(10)), \n                                        _mm256_cmpeq_epi8(hex_digits, _mm256_set1_epi8(11)));\n        hex_digits = _mm256_andnot_si256(mask, hex_digits);\n\n        __m256i prime_check = _mm256_and_si256(prime_mask, _mm256_cmpeq_epi8(hex_digits, primes));\n        count += _mm256_movemask_epi8(prime_check);\n    }\n\n    for (; i < len; ++i) {\n        char c = num[i];\n        if (c >= '0' && c <= '9') {\n            if (c == '2' || c == '3' || c == '5' || c == '7') count++;\n        } else if (c >= 'A' && c <= 'F') {\n            if (c == 'B' || c == 'D') count++;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_100_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <string>\n\nint hex_key_simd(const std::string & num) {\n    const __m256i primes_mask = _mm256_setr_epi8(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n                                                0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n    const __m256i hex_values = _mm256_setr_epi8(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15);\n    const __m256i prime_digits = _mm256_setr_epi8(0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0);\n    \n    int count = 0;\n    size_t length = num.length();\n    size_t i = 0;\n\n    for (; i + 32 <= length; i += 32) {\n        __m256i input = _mm256_setr_epi8(num[i + 31], num[i + 30], num[i + 29], num[i + 28], \n                                          num[i + 27], num[i + 26], num[i + 25], num[i + 24],\n                                          num[i + 23], num[i + 22], num[i + 21], num[i + 20],\n                                          num[i + 19], num[i + 18], num[i + 17], num[i + 16],\n                                          num[i + 15], num[i + 14], num[i + 13], num[i + 12],\n                                          num[i + 11], num[i + 10], num[i + 9], num[i + 8],\n                                          num[i + 7], num[i + 6], num[i + 5], num[i + 4],\n                                          num[i + 3], num[i + 2], num[i + 1], num[i]);\n\n        __m256i hex_indices = _mm256_sub_epi8(input, _mm256_set1_epi8('0'));\n        __m256i mask = _mm256_and_si256(_mm256_cmpgt_epi8(hex_indices, _mm256_set1_epi8(9)), \n                                         _mm256_set1_epi8(0x0F));\n        hex_indices = _mm256_add_epi8(hex_indices, mask);\n        \n        __m256i prime_check = _mm256_and_si256(_mm256_cmpgt_epi8(hex_indices, _mm256_set1_epi8(1)), \n                                                _mm256_and_si256(_mm256_cmpeq_epi8(prime_digits, hex_indices), \n                                                _mm256_set1_epi8(1)));\n\n        count += _mm256_movemask_epi8(prime_check);\n    }\n\n    for (; i < length; ++i) {\n        char c = num[i];\n        if ((c == '2') || (c == '3') || (c == '5') || (c == '7') || (c == 'B') || (c == 'D')) {\n            count++;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_100_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <string>\n\nint hex_key_simd(const std::string & num) {\n    const __m256i primes_mask = _mm256_setr_epi8(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n                                                0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n    const __m256i hex_digits = _mm256_setr_epi8('0', '1', '2', '3', '4', '5', '6', '7', \n                                                '8', '9', 'A', 'B', 'C', 'D', 'E', 'F');\n    const __m256i prime_digits = _mm256_setr_epi8(0, 0, 1, 1, 0, 1, 0, 1, \n                                                  0, 0, 1, 0, 1, 0, 0, 0);\n\n    int count = 0;\n    size_t length = num.length();\n    size_t i = 0;\n\n    for (; i + 32 <= length; i += 32) {\n        __m256i input = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(num.data() + i));\n        __m256i cmp = _mm256_cmpeq_epi8(input, hex_digits);\n        __m256i prime_check = _mm256_and_si256(cmp, prime_digits);\n        count += _mm256_movemask_epi8(prime_check);\n    }\n\n    for (; i < length; ++i) {\n        char c = num[i];\n        if (c == '2' || c == '3' || c == '5' || c == '7' || c == 'B' || c == 'D') {\n            count++;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_101_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <string>\n\nbool is_happy_simd(const std::string & s) {\n    size_t len = s.length();\n    if (len < 3) return false;\n\n    __m256i distinct_mask = _mm256_set1_epi8(0);\n    \n    for (size_t i = 0; i <= len - 3; i += 32) {\n        __m256i chars1 = _mm256_loadu_si256((__m256i*)&s[i]);\n        __m256i chars2 = _mm256_loadu_si256((__m256i*)&s[i + 1]);\n        __m256i chars3 = _mm256_loadu_si256((__m256i*)&s[i + 2]);\n\n        __m256i combined = _mm256_or_si256(_mm256_or_si256(chars1, chars2), chars3);\n        distinct_mask = _mm256_or_si256(distinct_mask, combined);\n        \n        __m256i cmp1 = _mm256_cmpeq_epi8(chars1, chars2);\n        __m256i cmp2 = _mm256_cmpeq_epi8(chars1, chars3);\n        __m256i cmp3 = _mm256_cmpeq_epi8(chars2, chars3);\n        \n        if (_mm256_movemask_epi8(cmp1) || _mm256_movemask_epi8(cmp2) || _mm256_movemask_epi8(cmp3)) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_101_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <string>\n\nbool is_happy_simd(const std::string & s) {\n    size_t n = s.length();\n    if (n < 3) return false;\n\n    __m256i distinct_mask = _mm256_set1_epi8(0xFF);\n    for (size_t i = 0; i <= n - 3; i += 32) {\n        __m256i chars1 = _mm256_loadu_si256((__m256i*)&s[i]);\n        __m256i chars2 = _mm256_loadu_si256((__m256i*)&s[i + 16]);\n        \n        __m256i combined = _mm256_or_si256(chars1, _mm256_slli_epi64(chars2, 128));\n        \n        __m256i cmp1 = _mm256_cmpeq_epi8(chars1, _mm256_slli_epi64(chars1, 1));\n        __m256i cmp2 = _mm256_cmpeq_epi8(chars1, _mm256_slli_epi64(chars1, 2));\n        __m256i cmp3 = _mm256_cmpeq_epi8(chars2, _mm256_slli_epi64(chars2, 1));\n        __m256i cmp4 = _mm256_cmpeq_epi8(chars2, _mm256_slli_epi64(chars2, 2));\n        \n        if (_mm256_movemask_epi8(cmp1) || _mm256_movemask_epi8(cmp2) || \n            _mm256_movemask_epi8(cmp3) || _mm256_movemask_epi8(cmp4)) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_101_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <string>\n\nbool is_happy_simd(const std::string & s) {\n    size_t len = s.length();\n    if (len < 3) return false;\n\n    __m256i distinct_mask = _mm256_set1_epi8(0xFF);\n    for (size_t i = 0; i <= len - 3; i += 32) {\n        __m256i chars1 = _mm256_loadu_si256((__m256i*)&s[i]);\n        __m256i chars2 = _mm256_loadu_si256((__m256i*)&s[i + 16]);\n        \n        __m256i combined = _mm256_or_si256(chars1, _mm256_slli_epi64(chars2, 128));\n        \n        __m256i cmp1 = _mm256_cmpeq_epi8(chars1, _mm256_srli_epi64(combined, 8));\n        __m256i cmp2 = _mm256_cmpeq_epi8(chars1, _mm256_srli_epi64(combined, 16));\n        __m256i cmp3 = _mm256_cmpeq_epi8(chars1, _mm256_srli_epi64(combined, 24));\n        \n        __m256i result = _mm256_or_si256(cmp1, _mm256_or_si256(cmp2, cmp3));\n        \n        if (_mm256_movemask_epi8(result) != 0) return false;\n    }\n\n    for (size_t i = len - 2; i < len; ++i) {\n        if (s[i] == s[i - 1] || (i > 1 && s[i] == s[i - 2])) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_101_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <string>\n\nbool is_happy_simd(const std::string & s) {\n    size_t n = s.length();\n    if (n < 3) return false;\n\n    __m256i distinct_mask = _mm256_set1_epi8(0xFF);\n    for (size_t i = 0; i <= n - 3; i += 32) {\n        __m256i chars1 = _mm256_loadu_si256((__m256i*)&s[i]);\n        __m256i chars2 = _mm256_loadu_si256((__m256i*)&s[i + 16]);\n        \n        __m256i combined = _mm256_or_si256(chars1, _mm256_slli_epi64(chars2, 8));\n        combined = _mm256_and_si256(combined, distinct_mask);\n        \n        __m256i cmp1 = _mm256_cmpeq_epi8(chars1, _mm256_slli_epi64(chars1, 1));\n        __m256i cmp2 = _mm256_cmpeq_epi8(chars1, _mm256_slli_epi64(chars1, 2));\n        __m256i cmp3 = _mm256_cmpeq_epi8(chars2, _mm256_slli_epi64(chars2, 1));\n        __m256i cmp4 = _mm256_cmpeq_epi8(chars2, _mm256_slli_epi64(chars2, 2));\n        \n        if (_mm256_movemask_epi8(cmp1) || _mm256_movemask_epi8(cmp2) || \n            _mm256_movemask_epi8(cmp3) || _mm256_movemask_epi8(cmp4)) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_101_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <string>\n\nbool is_happy_simd(const std::string & s) {\n    size_t n = s.size();\n    if (n < 3) return false;\n\n    __m256i distinct_mask = _mm256_set1_epi8(0);\n    for (size_t i = 0; i <= n - 3; i += 32) {\n        __m256i chars = _mm256_loadu_si256((__m256i*)&s[i]);\n        __m256i next_chars = _mm256_loadu_si256((__m256i*)&s[i + 1]);\n        __m256i next_next_chars = _mm256_loadu_si256((__m256i*)&s[i + 2]);\n\n        __m256i combined = _mm256_or_si256(chars, _mm256_or_si256(next_chars, next_next_chars));\n        distinct_mask = _mm256_or_si256(distinct_mask, combined);\n        \n        // Check for duplicates\n        __m256i cmp1 = _mm256_cmpeq_epi8(chars, next_chars);\n        __m256i cmp2 = _mm256_cmpeq_epi8(chars, next_next_chars);\n        __m256i cmp3 = _mm256_cmpeq_epi8(next_chars, next_next_chars);\n        \n        if (_mm256_movemask_epi8(cmp1) || _mm256_movemask_epi8(cmp2) || _mm256_movemask_epi8(cmp3)) {\n            return false;\n        }\n    }\n\n    // Check remaining characters\n    for (size_t i = n - 3; i < n; ++i) {\n        if (s[i] == s[i + 1] || s[i] == s[i + 2] || s[i + 1] == s[i + 2]) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_102_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <string>\n\nbool is_prime(int n) {\n    if (n <= 1) return false;\n    if (n <= 3) return true;\n    if (n % 2 == 0 || n % 3 == 0) return false;\n    for (int i = 5; i * i <= n; i += 6) {\n        if (n % i == 0 || n % (i + 2) == 0) return false;\n    }\n    return true;\n}\n\nbool prime_length_simd(const std::string & str) {\n    int length = str.length();\n    if (length < 2) return false;\n\n    __m256i vec_length = _mm256_set1_epi32(length);\n    __m256i vec_two = _mm256_set1_epi32(2);\n    __m256i vec_three = _mm256_set1_epi32(3);\n    \n    __m256i is_prime_mask = _mm256_set1_epi32(1); // Assume true\n    __m256i is_not_prime_mask = _mm256_set1_epi32(0); // Assume false\n\n    // Check if length <= 1\n    __m256i less_than_two = _mm256_cmpgt_epi32(vec_length, vec_two);\n    is_prime_mask = _mm256_blendv_epi8(is_prime_mask, is_not_prime_mask, _mm256_cmpeq_epi32(vec_length, vec_two));\n\n    // Check if length <= 3\n    __m256i less_than_four = _mm256_cmpgt_epi32(vec_length, vec_three);\n    is_prime_mask = _mm256_blendv_epi8(is_prime_mask, is_not_prime_mask, _mm256_cmpeq_epi32(vec_length, vec_three));\n\n    // Check for even numbers\n    __m256i is_even = _mm256_and_si256(_mm256_cmpeq_epi32(_mm256_and_si256(vec_length, vec_two), vec_two), less_than_four);\n    is_prime_mask = _mm256_blendv_epi8(is_prime_mask, is_not_prime_mask, is_even);\n\n    // Check for divisibility from 5 to sqrt(length)\n    for (int i = 5; i * i <= length; i += 6) {\n        __m256i vec_i = _mm256_set1_epi32(i);\n        __m256i vec_i_plus_2 = _mm256_set1_epi32(i + 2);\n        \n        __m256i divisible_by_i = _mm256_cmpeq_epi32(_mm256_rem_epi32(vec_length, vec_i), _mm256_setzero_si256());\n        __m256i divisible_by_i_plus_2 = _mm256_cmpeq_epi32(_mm256_rem_epi32(vec_length, vec_i_plus_2), _mm256_setzero_si256());\n\n        is_prime_mask = _mm256_blendv_epi8(is_prime_mask, is_not_prime_mask, _mm256_or_si256(divisible_by_i, divisible_by_i_plus_2));\n    }\n\n    return _mm256_movemask_epi8(is_prime_mask) != 0;\n}\n```"}
{"task_id": "SimdBench_102_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <string>\n\nbool is_prime(int n) {\n    if (n <= 1) return false;\n    if (n <= 3) return true;\n    if (n % 2 == 0 || n % 3 == 0) return false;\n    for (int i = 5; i * i <= n; i += 6) {\n        if (n % i == 0 || n % (i + 2) == 0) return false;\n    }\n    return true;\n}\n\nbool prime_length_simd(const std::string & str) {\n    int length = str.length();\n    if (length < 2) return false;\n\n    __m256i vec_length = _mm256_set1_epi32(length);\n    __m256i vec_two = _mm256_set1_epi32(2);\n    __m256i vec_three = _mm256_set1_epi32(3);\n    __m256i vec_length_check = _mm256_cmpgt_epi32(vec_length, vec_two);\n    \n    // Check if length is less than or equal to 3\n    if (_mm256_movemask_epi8(_mm256_cmpeq_epi32(vec_length, vec_two)) || \n        _mm256_movemask_epi8(_mm256_cmpeq_epi32(vec_length, vec_three))) {\n        return true;\n    }\n\n    // Check if divisible by 2 or 3\n    if (_mm256_movemask_epi8(_mm256_cmpeq_epi32(_mm256_rem_epi32(vec_length, vec_two), _mm256_setzero_si256())) || \n        _mm256_movemask_epi8(_mm256_cmpeq_epi32(_mm256_rem_epi32(vec_length, vec_three), _mm256_setzero_si256()))) {\n        return false;\n    }\n\n    // Check for factors from 5 to sqrt(length)\n    for (int i = 5; i * i <= length; i += 6) {\n        __m256i vec_i = _mm256_set1_epi32(i);\n        __m256i vec_i_plus_2 = _mm256_set1_epi32(i + 2);\n        if (_mm256_movemask_epi8(_mm256_cmpeq_epi32(_mm256_rem_epi32(vec_length, vec_i), _mm256_setzero_si256())) || \n            _mm256_movemask_epi8(_mm256_cmpeq_epi32(_mm256_rem_epi32(vec_length, vec_i_plus_2), _mm256_setzero_si256()))) {\n            return false;\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_102_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <string>\n\nbool is_prime(int n) {\n    if (n <= 1) return false;\n    if (n <= 3) return true;\n    if (n % 2 == 0 || n % 3 == 0) return false;\n    for (int i = 5; i * i <= n; i += 6) {\n        if (n % i == 0 || n % (i + 2) == 0) return false;\n    }\n    return true;\n}\n\nbool prime_length_simd(const std::string & str) {\n    int length = str.length();\n    if (length < 8) {\n        return is_prime(length);\n    }\n\n    __m256i vec_length = _mm256_set1_epi32(length);\n    __m256i vec_two = _mm256_set1_epi32(2);\n    __m256i vec_three = _mm256_set1_epi32(3);\n    __m256i vec_six = _mm256_set1_epi32(6);\n    \n    __m256i mod_two = _mm256_rem_epi32(vec_length, vec_two);\n    __m256i mod_three = _mm256_rem_epi32(vec_length, vec_three);\n    \n    __m256i is_prime_vec = _mm256_and_si256(\n        _mm256_cmpgt_epi32(vec_length, vec_two),\n        _mm256_andnot_si256(\n            _mm256_or_si256(\n                _mm256_cmpeq_epi32(mod_two, _mm256_setzero_si256()),\n                _mm256_cmpeq_epi32(mod_three, _mm256_setzero_si256())\n            ),\n            _mm256_set1_epi32(1)\n        )\n    );\n\n    for (int i = 5; i * i <= length; i += 6) {\n        __m256i vec_i = _mm256_set1_epi32(i);\n        __m256i vec_i_plus_2 = _mm256_set1_epi32(i + 2);\n        \n        __m256i mod_i = _mm256_rem_epi32(vec_length, vec_i);\n        __m256i mod_i_plus_2 = _mm256_rem_epi32(vec_length, vec_i_plus_2);\n        \n        is_prime_vec = _mm256_and_si256(is_prime_vec, \n            _mm256_andnot_si256(\n                _mm256_or_si256(\n                    _mm256_cmpeq_epi32(mod_i, _mm256_setzero_si256()),\n                    _mm256_cmpeq_epi32(mod_i_plus_2, _mm256_setzero_si256())\n                ),\n                _mm256_set1_epi32(1)\n            )\n        );\n    }\n\n    return _mm256_movemask_epi8(is_prime_vec) != 0;\n}\n```"}
{"task_id": "SimdBench_102_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <string>\n\nbool is_prime(int n) {\n    if (n <= 1) return false;\n    if (n <= 3) return true;\n    if (n % 2 == 0 || n % 3 == 0) return false;\n    for (int i = 5; i * i <= n; i += 6) {\n        if (n % i == 0 || n % (i + 2) == 0) return false;\n    }\n    return true;\n}\n\nbool prime_length_simd(const std::string & str) {\n    int length = str.length();\n    if (length < 8) {\n        return is_prime(length);\n    }\n\n    __m256i vec_length = _mm256_set1_epi32(length);\n    __m256i vec_two = _mm256_set1_epi32(2);\n    __m256i vec_three = _mm256_set1_epi32(3);\n    __m256i vec_six = _mm256_set1_epi32(6);\n    \n    __m256i is_prime_vec = _mm256_set1_epi32(1); // Assume prime\n    __m256i is_not_prime = _mm256_set1_epi32(0); // Not prime\n\n    // Check if divisible by 2 or 3\n    __m256i mod_two = _mm256_rem_epi32(vec_length, vec_two);\n    __m256i mod_three = _mm256_rem_epi32(vec_length, vec_three);\n    is_prime_vec = _mm256_blendv_epi8(is_prime_vec, is_not_prime, _mm256_or_si256(_mm256_cmpeq_epi32(mod_two, _mm256_setzero_si256()), _mm256_cmpeq_epi32(mod_three, _mm256_setzero_si256())));\n\n    // Check for factors from 5 to sqrt(length)\n    for (int i = 5; i * i <= length; i += 6) {\n        __m256i vec_i = _mm256_set1_epi32(i);\n        __m256i vec_i_plus_2 = _mm256_set1_epi32(i + 2);\n        \n        __m256i mod_i = _mm256_rem_epi32(vec_length, vec_i);\n        __m256i mod_i_plus_2 = _mm256_rem_epi32(vec_length, vec_i_plus_2);\n        \n        is_prime_vec = _mm256_blendv_epi8(is_prime_vec, is_not_prime, _mm256_or_si256(_mm256_cmpeq_epi32(mod_i, _mm256_setzero_si256()), _mm256_cmpeq_epi32(mod_i_plus_2, _mm256_setzero_si256())));\n    }\n\n    // Check final result\n    return _mm256_movemask_epi8(is_prime_vec) != 0;\n}\n```"}
{"task_id": "SimdBench_102_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <string>\n\nbool is_prime(int n) {\n    if (n <= 1) return false;\n    if (n <= 3) return true;\n    if (n % 2 == 0 || n % 3 == 0) return false;\n    for (int i = 5; i * i <= n; i += 6) {\n        if (n % i == 0 || n % (i + 2) == 0) return false;\n    }\n    return true;\n}\n\nbool prime_length_simd(const std::string & str) {\n    int length = str.length();\n    if (length < 8) {\n        return is_prime(length);\n    }\n\n    __m256i vec_length = _mm256_set1_epi32(length);\n    __m256i vec_two = _mm256_set1_epi32(2);\n    __m256i vec_three = _mm256_set1_epi32(3);\n    __m256i vec_six = _mm256_set1_epi32(6);\n    __m256i vec_limit = _mm256_set1_epi32(100); // Arbitrary limit for prime checking\n\n    __m256i is_prime_vec = _mm256_set1_epi32(1); // Assume prime\n    __m256i is_not_prime = _mm256_setzero_si256(); // Not prime\n\n    // Check for even numbers and multiples of 3\n    __m256i mod_two = _mm256_rem_epi32(vec_length, vec_two);\n    __m256i mod_three = _mm256_rem_epi32(vec_length, vec_three);\n    is_prime_vec = _mm256_and_si256(is_prime_vec, _mm256_cmpeq_epi32(mod_two, vec_not_prime));\n    is_prime_vec = _mm256_and_si256(is_prime_vec, _mm256_cmpeq_epi32(mod_three, vec_not_prime));\n\n    // Check for factors from 5 to sqrt(length)\n    for (int i = 5; i * i <= length; i += 6) {\n        __m256i vec_i = _mm256_set1_epi32(i);\n        __m256i vec_i_plus_2 = _mm256_set1_epi32(i + 2);\n        __m256i mod_i = _mm256_rem_epi32(vec_length, vec_i);\n        __m256i mod_i_plus_2 = _mm256_rem_epi32(vec_length, vec_i_plus_2);\n        is_prime_vec = _mm256_and_si256(is_prime_vec, _mm256_andnot_si256(_mm256_cmpeq_epi32(mod_i, is_not_prime), is_prime_vec));\n        is_prime_vec = _mm256_and_si256(is_prime_vec, _mm256_andnot_si256(_mm256_cmpeq_epi32(mod_i_plus_2, is_not_prime), is_prime_vec));\n    }\n\n    // Final check\n    return _mm256_movemask_epi8(is_prime_vec) != 0;\n}\n```"}
{"task_id": "SimdBench_103_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n#include <bitset>\n\nstd::string solve_simd(uint64_t N) {\n    // Count the number of 1s in the binary representation of N\n    __m256i count = _mm256_setzero_si256();\n    for (int i = 0; i < 64; i += 8) {\n        __m256i mask = _mm256_set1_epi64x(1ULL << i);\n        __m256i bits = _mm256_and_si256(_mm256_set1_epi64x(N), mask);\n        count = _mm256_add_epi64(count, _mm256_srli_epi64(bits, i));\n    }\n\n    // Horizontal sum of the counts\n    count = _mm256_hadd_epi64(count, count);\n    count = _mm256_hadd_epi64(count, count);\n    uint64_t total_sum = _mm256_extract_epi64(count, 0) + _mm256_extract_epi64(count, 4);\n\n    // Convert total_sum to binary string\n    std::string binary = std::bitset<64>(total_sum).to_string();\n    // Remove leading zeros\n    size_t pos = binary.find('1');\n    return pos == std::string::npos ? \"0\" : binary.substr(pos);\n}\n```"}
{"task_id": "SimdBench_103_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n#include <bitset>\n\nstd::string solve_simd(uint64_t N) {\n    __m256i count = _mm256_setzero_si256();\n    uint64_t mask = 1;\n\n    for (int i = 0; i < 64; i += 8) {\n        __m256i bits = _mm256_set1_epi64x(N & (mask * 255));\n        count = _mm256_add_epi64(count, _mm256_and_si256(bits, _mm256_set1_epi64x(1)));\n        N >>= 8;\n    }\n\n    int64_t sum = _mm256_extract_epi64(count, 0) + _mm256_extract_epi64(count, 1) +\n                  _mm256_extract_epi64(count, 2) + _mm256_extract_epi64(count, 3) +\n                  _mm256_extract_epi64(count, 4) + _mm256_extract_epi64(count, 5) +\n                  _mm256_extract_epi64(count, 6) + _mm256_extract_epi64(count, 7);\n\n    return std::bitset<64>(sum).to_string().substr(64 - std::bitset<64>(sum).count());\n}\n```"}
{"task_id": "SimdBench_103_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string solve_simd(uint64_t N) {\n    uint64_t count = 0;\n\n    // Count the number of 1s in the binary representation of N\n    while (N) {\n        count += N & 1;\n        N >>= 1;\n    }\n\n    // Convert count to binary string\n    std::string binary;\n    if (count == 0) return \"0\";\n    while (count > 0) {\n        binary.insert(binary.begin(), (count % 2) + '0');\n        count /= 2;\n    }\n\n    return binary;\n}\n```"}
{"task_id": "SimdBench_103_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <string>\n#include <bitset>\n\nstd::string solve_simd(uint64_t N) {\n    __m256i count = _mm256_setzero_si256();\n    for (int i = 0; i < 64; i += 8) {\n        __m256i mask = _mm256_set1_epi64x(1ULL << i);\n        __m256i bits = _mm256_and_si256(_mm256_set1_epi64x(N), mask);\n        count = _mm256_add_epi64(count, _mm256_srlv_epi64(bits, _mm256_set1_epi64x(i)));\n    }\n    \n    // Horizontal sum of the counts\n    count = _mm256_hadd_epi64(count, count);\n    count = _mm256_hadd_epi64(count, count);\n    \n    uint64_t total_sum = _mm256_extract_epi64(count, 0);\n    \n    return std::bitset<64>(total_sum).to_string().substr(64 - (total_sum ? (int)log2(total_sum) + 1 : 1));\n}\n```"}
{"task_id": "SimdBench_103_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <string>\n#include <bitset>\n\nstd::string solve_simd(uint64_t N) {\n    __m256i count = _mm256_setzero_si256();\n    for (int i = 0; i < 64; i += 8) {\n        __m256i mask = _mm256_set1_epi64x(1ULL << i);\n        __m256i bits = _mm256_and_si256(_mm256_set1_epi64x(N), mask);\n        count = _mm256_add_epi64(count, _mm256_srli_epi64(bits, i));\n    }\n    \n    int64_t total_sum = _mm256_extract_epi64(count, 0) +\n                        _mm256_extract_epi64(count, 1) +\n                        _mm256_extract_epi64(count, 2) +\n                        _mm256_extract_epi64(count, 3) +\n                        _mm256_extract_epi64(count, 4) +\n                        _mm256_extract_epi64(count, 5) +\n                        _mm256_extract_epi64(count, 6) +\n                        _mm256_extract_epi64(count, 7);\n    \n    return std::bitset<64>(total_sum).to_string().substr(64 - std::bitset<64>(total_sum).count());\n}\n```"}
{"task_id": "SimdBench_104_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nint add_simd(std::vector<int> lst) {\n    int sum = 0;\n    size_t size = lst.size();\n    size_t i;\n\n    __m256i total_sum = _mm256_setzero_si256();\n\n    for (i = 1; i + 7 < size; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&lst[i]);\n        __m256i mask = _mm256_and_si256(vec, _mm256_set1_epi32(1)); // Mask for even numbers\n        __m256i even_elements = _mm256_and_si256(vec, _mm256_cmpeq_epi32(mask, _mm256_setzero_si256()));\n        total_sum = _mm256_add_epi32(total_sum, even_elements);\n    }\n\n    // Horizontal sum of the vector\n    total_sum = _mm256_hadd_epi32(total_sum, total_sum);\n    total_sum = _mm256_hadd_epi32(total_sum, total_sum);\n    sum += _mm256_extract_epi32(total_sum, 0);\n\n    // Handle remaining elements\n    for (; i < size; i += 2) {\n        if (lst[i] % 2 == 0) {\n            sum += lst[i];\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_104_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nint add_simd(std::vector<int> lst) {\n    int sum = 0;\n    int n = lst.size();\n    __m256i total = _mm256_setzero_si256();\n\n    for (int i = 1; i < n; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&lst[i]);\n        __m256i mask = _mm256_and_si256(vec, _mm256_set1_epi32(1)); // Mask for even numbers\n        __m256i odd_indices = _mm256_set1_epi32(0);\n        odd_indices = _mm256_add_epi32(odd_indices, _mm256_set_epi32(0, 1, 0, 1, 0, 1, 0, 1)); // 0, 1, 0, 1, 0, 1, 0, 1\n        __m256i result = _mm256_and_si256(mask, odd_indices);\n        total = _mm256_add_epi32(total, result);\n    }\n\n    int32_t temp[8];\n    _mm256_storeu_si256((__m256i*)temp, total);\n    for (int i = 0; i < 8; i++) {\n        sum += temp[i];\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_104_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nint add_simd(std::vector<int> lst) {\n    int sum = 0;\n    int size = lst.size();\n    __m256i vec_sum = _mm256_setzero_si256();\n\n    for (int i = 1; i < size; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&lst[i]);\n        __m256i mask = _mm256_and_si256(vec, _mm256_set1_epi32(1)); // Mask for even numbers\n        __m256i odd_indices_mask = _mm256_set1_epi32(0xAAAAAAAA); // Mask for odd indices\n        __m256i even_elements = _mm256_and_si256(vec, odd_indices_mask);\n        vec_sum = _mm256_add_epi32(vec_sum, even_elements);\n    }\n\n    // Horizontal sum of the vector\n    vec_sum = _mm256_hadd_epi32(vec_sum, vec_sum);\n    vec_sum = _mm256_hadd_epi32(vec_sum, vec_sum);\n    sum += _mm256_extract_epi32(vec_sum, 0) + _mm256_extract_epi32(vec_sum, 4);\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_104_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nint add_simd(std::vector<int> lst) {\n    int sum = 0;\n    size_t size = lst.size();\n    size_t i;\n\n    __m256i vec_sum = _mm256_setzero_si256();\n\n    for (i = 1; i + 7 < size; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&lst[i]);\n        __m256i mask = _mm256_and_si256(vec, _mm256_set1_epi32(1)); // mask for even numbers\n        __m256i even_elements = _mm256_and_si256(vec, _mm256_cmpeq_epi32(mask, _mm256_setzero_si256()));\n        vec_sum = _mm256_add_epi32(vec_sum, even_elements);\n    }\n\n    for (; i < size; i += 2) {\n        if (lst[i] % 2 == 0) {\n            sum += lst[i];\n        }\n    }\n\n    int result[8];\n    _mm256_storeu_si256((__m256i*)result, vec_sum);\n    for (int j = 0; j < 8; j++) {\n        sum += result[j];\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_104_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nint add_simd(std::vector<int> lst) {\n    int sum = 0;\n    size_t size = lst.size();\n    size_t i;\n\n    // Process 8 integers at a time\n    __m256i total_sum = _mm256_setzero_si256();\n    \n    for (i = 1; i < size; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&lst[i]);\n        __m256i mask = _mm256_and_si256(vec, _mm256_set1_epi32(1)); // Mask for even numbers\n        __m256i odd_indices = _mm256_set_epi32(0, 0, 0, 0, 0, 0, 0, 1); // Mask for odd indices\n        __m256i even_mask = _mm256_cmpeq_epi32(mask, _mm256_setzero_si256()); // Mask for even elements\n        __m256i result = _mm256_and_si256(vec, even_mask);\n        result = _mm256_and_si256(result, odd_indices);\n        total_sum = _mm256_add_epi32(total_sum, result);\n    }\n\n    // Horizontal sum of the vector\n    int32_t temp[8];\n    _mm256_storeu_si256((__m256i*)temp, total_sum);\n    for (int j = 0; j < 8; j++) {\n        sum += temp[j];\n    }\n\n    // Handle remaining elements\n    for (; i < size; i++) {\n        if (i % 2 == 1 && lst[i] % 2 == 0) {\n            sum += lst[i];\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_105_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <string>\n\nstd::string encrypt_simd(const std::string & s) {\n    size_t len = s.size();\n    std::string result(len, ' ');\n\n    size_t i = 0;\n    __m256i shift = _mm256_set1_epi8(2); // Set the shift value (2)\n    __m256i base = _mm256_set1_epi8('a'); // Base for lowercase letters\n    __m256i range = _mm256_set1_epi8(26); // Range for alphabet\n\n    for (; i + 32 <= len; i += 32) {\n        __m256i input = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&s[i]));\n        __m256i mask = _mm256_cmpgt_epi8(input, base); // Mask for valid lowercase letters\n        __m256i adjusted = _mm256_sub_epi8(input, base); // Adjust to 0-25 range\n        adjusted = _mm256_add_epi8(adjusted, shift); // Shift by 2\n        adjusted = _mm256_mod_epi8(adjusted, range); // Wrap around using modulo\n        adjusted = _mm256_add_epi8(adjusted, base); // Adjust back to ASCII range\n        adjusted = _mm256_and_si256(adjusted, mask); // Apply mask to keep non-lowercase letters\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(&result[i]), adjusted);\n    }\n\n    for (; i < len; ++i) {\n        char c = s[i];\n        if (c >= 'a' && c <= 'z') {\n            result[i] = (c - 'a' + 2) % 26 + 'a';\n        } else {\n            result[i] = c;\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_105_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <string>\n\nstd::string encrypt_simd(const std::string & s) {\n    size_t len = s.length();\n    std::string result(len, ' ');\n\n    size_t i = 0;\n    __m256i shift = _mm256_set1_epi8(2); // Shift by 2\n    __m256i base = _mm256_set1_epi8('a'); // Base for lowercase letters\n    __m256i max_char = _mm256_set1_epi8('z'); // Max char for wrapping\n\n    for (; i + 32 <= len; i += 32) {\n        __m256i input = _mm256_loadu_si256((__m256i*)&s[i]);\n        __m256i mask = _mm256_cmpgt_epi8(input, base);\n        __m256i wrapped = _mm256_add_epi8(input, shift);\n        wrapped = _mm256_and_si256(wrapped, mask);\n        __m256i overflow = _mm256_cmpgt_epi8(wrapped, max_char);\n        wrapped = _mm256_sub_epi8(wrapped, _mm256_and_si256(overflow, _mm256_set1_epi8(26)));\n        _mm256_storeu_si256((__m256i*)&result[i], wrapped);\n    }\n\n    for (; i < len; ++i) {\n        char c = s[i];\n        if (c >= 'a' && c <= 'z') {\n            c = (c - 'a' + 2) % 26 + 'a';\n        }\n        result[i] = c;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_105_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <string>\n\nstd::string encrypt_simd(const std::string & s) {\n    size_t len = s.length();\n    std::string result(len, ' ');\n\n    size_t i = 0;\n    __m256i shift = _mm256_set1_epi8(2); // Set shift value of 2\n    __m256i base = _mm256_set1_epi8('a'); // Base for lowercase letters\n    __m256i max_char = _mm256_set1_epi8('z'); // Max character for wrapping\n\n    for (; i + 32 <= len; i += 32) {\n        __m256i input = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&s[i]));\n        __m256i mask = _mm256_cmpgt_epi8(input, base); // Mask for lowercase letters\n        __m256i wrapped = _mm256_add_epi8(input, shift); // Shift letters by 2\n\n        // Wrap around if greater than 'z'\n        __m256i overflow = _mm256_cmpgt_epi8(wrapped, max_char);\n        wrapped = _mm256_sub_epi8(wrapped, _mm256_and_si256(overflow, _mm256_set1_epi8(26)));\n\n        // Apply mask to only modify lowercase letters\n        wrapped = _mm256_blendv_epi8(input, wrapped, mask);\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(&result[i]), wrapped);\n    }\n\n    // Process remaining characters\n    for (; i < len; ++i) {\n        char c = s[i];\n        if (c >= 'a' && c <= 'z') {\n            c = (c - 'a' + 2) % 26 + 'a';\n        }\n        result[i] = c;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_105_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <string>\n\nstd::string encrypt_simd(const std::string & s) {\n    size_t len = s.size();\n    std::string result(len, ' ');\n\n    size_t i = 0;\n    __m256i shift = _mm256_set1_epi8(2); // Shift by 2\n    __m256i base = _mm256_set1_epi8('a'); // Base for lowercase letters\n    __m256i upper_base = _mm256_set1_epi8('A'); // Base for uppercase letters\n\n    for (; i + 32 <= len; i += 32) {\n        __m256i input = _mm256_loadu_si256((__m256i*)&s[i]);\n        __m256i lower_mask = _mm256_cmpgt_epi8(input, base);\n        __m256i upper_mask = _mm256_cmpgt_epi8(input, upper_base);\n\n        // Rotate lowercase letters\n        __m256i lower_shifted = _mm256_add_epi8(input, shift);\n        lower_shifted = _mm256_and_si256(lower_shifted, lower_mask);\n        lower_shifted = _mm256_sub_epi8(lower_shifted, _mm256_set1_epi8(26));\n        lower_shifted = _mm256_add_epi8(lower_shifted, base);\n\n        // Rotate uppercase letters\n        __m256i upper_shifted = _mm256_add_epi8(input, shift);\n        upper_shifted = _mm256_and_si256(upper_shifted, upper_mask);\n        upper_shifted = _mm256_sub_epi8(upper_shifted, _mm256_set1_epi8(26));\n        upper_shifted = _mm256_add_epi8(upper_shifted, upper_base);\n\n        // Combine results\n        __m256i result_vec = _mm256_or_si256(lower_shifted, upper_shifted);\n        _mm256_storeu_si256((__m256i*)&result[i], result_vec);\n    }\n\n    for (; i < len; ++i) {\n        char c = s[i];\n        if (c >= 'a' && c <= 'z') {\n            result[i] = (c - 'a' + 2) % 26 + 'a';\n        } else if (c >= 'A' && c <= 'Z') {\n            result[i] = (c - 'A' + 2) % 26 + 'A';\n        } else {\n            result[i] = c; // Non-alphabetic characters remain unchanged\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_105_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <string>\n\nstd::string encrypt_simd(const std::string & s) {\n    std::string result(s.size(), ' ');\n    size_t i = 0;\n    size_t len = s.size();\n\n    // Process 32 bytes at a time\n    for (; i + 31 < len; i += 32) {\n        __m256i input = _mm256_loadu_si256((__m256i*)&s[i]);\n        __m256i offset = _mm256_set1_epi8(2);\n        __m256i rotated = _mm256_add_epi8(input, offset);\n        \n        // Handle wrapping for lowercase letters\n        __m256i lower_bound = _mm256_set1_epi8('a');\n        __m256i upper_bound = _mm256_set1_epi8('z' + 1);\n        __m256i mask = _mm256_cmpgt_epi8(rotated, upper_bound);\n        rotated = _mm256_sub_epi8(rotated, _mm256_and_si256(mask, _mm256_set1_epi8(26)));\n\n        _mm256_storeu_si256((__m256i*)&result[i], rotated);\n    }\n\n    // Process remaining characters\n    for (; i < len; ++i) {\n        char c = s[i];\n        if (c >= 'a' && c <= 'z') {\n            c = (c - 'a' + 2) % 26 + 'a';\n        }\n        result[i] = c;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_106_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <string>\n\nstd::string encode_simd(const std::string & message) {\n    std::string result(message.size(), ' ');\n    size_t length = message.size();\n    size_t i = 0;\n\n    __m256i vowels = _mm256_set1_epi8('A');\n    __m256i vowel_mask = _mm256_set1_epi8(0x1F); // Mask for vowels\n    __m256i two_ahead = _mm256_set1_epi8(2); // For shifting vowels ahead\n\n    for (; i <= length - 32; i += 32) {\n        __m256i input = _mm256_loadu_si256((__m256i*)&message[i]);\n        __m256i upper = _mm256_and_si256(input, _mm256_set1_epi8(0xDF)); // Convert to upper case\n        __m256i lower = _mm256_and_si256(input, _mm256_set1_epi8(0x20)); // Mask for lower case\n\n        // Check for vowels\n        __m256i is_vowel = _mm256_or_si256(\n            _mm256_cmpeq_epi8(upper, _mm256_set1_epi8('A')),\n            _mm256_or_si256(\n                _mm256_cmpeq_epi8(upper, _mm256_set1_epi8('E')),\n                _mm256_or_si256(\n                    _mm256_cmpeq_epi8(upper, _mm256_set1_epi8('I')),\n                    _mm256_or_si256(\n                        _mm256_cmpeq_epi8(upper, _mm256_set1_epi8('O')),\n                        _mm256_cmpeq_epi8(upper, _mm256_set1_epi8('U'))\n                    )\n                )\n            )\n        );\n\n        // Replace vowels with the letter that appears 2 places ahead\n        __m256i shifted_vowels = _mm256_add_epi8(upper, two_ahead);\n        __m256i result_chars = _mm256_blendv_epi8(upper, shifted_vowels, is_vowel);\n\n        // Handle case swapping\n        result_chars = _mm256_xor_si256(result_chars, lower);\n\n        _mm256_storeu_si256((__m256i*)&result[i], result_chars);\n    }\n\n    // Handle remaining characters\n    for (; i < length; ++i) {\n        char c = message[i];\n        if (c >= 'a' && c <= 'z') {\n            c = c - 32; // Convert to upper case\n        } else if (c >= 'A' && c <= 'Z') {\n            c = c + 32; // Convert to lower case\n        }\n        if (c == 'A') c = 'C';\n        else if (c == 'E') c = 'G';\n        else if (c == 'I') c = 'K';\n        else if (c == 'O') c = 'Q';\n        else if (c == 'U') c = 'W';\n        result[i] = c;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_106_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <string>\n\nstd::string encode_simd(const std::string & message) {\n    std::string result(message.size(), ' ');\n    size_t i = 0;\n    size_t len = message.size();\n\n    for (; i + 32 <= len; i += 32) {\n        __m256i input = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&message[i]));\n        \n        // Create masks for vowels\n        __m256i vowels = _mm256_setr_epi8('a', 'e', 'i', 'o', 'u', 'A', 'E', 'I', 'O', 'U', 0, 0, 0, 0, 0, 0, 0);\n        __m256i two_ahead = _mm256_setr_epi8('c', 'g', 'k', 'o', 'q', 'C', 'G', 'K', 'O', 'Q', 0, 0, 0, 0, 0, 0, 0);\n        \n        // Swap case\n        __m256i swapped_case = _mm256_xor_si256(input, _mm256_set1_epi8(0x20));\n        \n        // Check for vowels\n        __m256i is_vowel = _mm256_cmpeq_epi8(swapped_case, vowels);\n        __m256i is_not_vowel = _mm256_andnot_si256(is_vowel, _mm256_set1_epi8(-1));\n        \n        // Replace vowels with two places ahead\n        __m256i encoded = _mm256_blendv_epi8(swapped_case, two_ahead, is_vowel);\n        \n        // Store result\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(&result[i]), encoded);\n    }\n\n    // Handle remaining characters\n    for (; i < len; ++i) {\n        char c = message[i];\n        if (isalpha(c)) {\n            if (islower(c)) {\n                c = toupper(c);\n            } else {\n                c = tolower(c);\n            }\n            if (strchr(\"AEIOUaeiou\", c)) {\n                c = c + 2;\n                if ((c == 'Z' + 1) || (c == 'z' + 1)) c -= 26; // wrap around\n            }\n        }\n        result[i] = c;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_106_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <string>\n\nstd::string encode_simd(const std::string & message) {\n    std::string result(message.size(), ' ');\n    size_t i = 0;\n    size_t length = message.size();\n\n    __m256i vowels = _mm256_setr_epi8('A', 'E', 'I', 'O', 'U', 'a', 'e', 'i', 'o', 'u', 0, 0, 0, 0, 0, 0);\n    __m256i offset = _mm256_set1_epi8(2);\n    __m256i lower_bound = _mm256_set1_epi8('a');\n    __m256i upper_bound = _mm256_set1_epi8('z');\n    __m256i upper_case_offset = _mm256_set1_epi8('A' - 'a');\n\n    for (; i + 32 <= length; i += 32) {\n        __m256i input = _mm256_loadu_si256((__m256i*)&message[i]);\n        __m256i is_lower = _mm256_cmpgt_epi8(input, lower_bound);\n        __m256i is_upper = _mm256_cmpgt_epi8(upper_bound, input);\n        \n        __m256i swapped_case = _mm256_xor_si256(input, _mm256_or_si256(\n            _mm256_and_si256(is_lower, upper_case_offset),\n            _mm256_andnot_si256(is_upper, upper_case_offset)\n        ));\n\n        __m256i is_vowel = _mm256_cmpeq_epi8(swapped_case, vowels);\n        __m256i encoded_vowels = _mm256_add_epi8(swapped_case, offset);\n        __m256i final_chars = _mm256_blendv_epi8(swapped_case, encoded_vowels, is_vowel);\n\n        _mm256_storeu_si256((__m256i*)&result[i], final_chars);\n    }\n\n    for (; i < length; ++i) {\n        char c = message[i];\n        if (c >= 'a' && c <= 'z') {\n            c ^= ('A' - 'a');\n        } else if (c >= 'A' && c <= 'Z') {\n            c ^= ('A' - 'a');\n        }\n        if (c == 'a' || c == 'e' || c == 'i' || c == 'o' || c == 'u' || c == 'A' || c == 'E' || c == 'I' || c == 'O' || c == 'U') {\n            c += 2;\n        }\n        result[i] = c;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_106_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <string>\n\nstd::string encode_simd(const std::string & message) {\n    std::string result(message.size(), ' ');\n    size_t i = 0;\n    size_t length = message.size();\n\n    __m256i vowels = _mm256_set1_epi8('a');\n    __m256i a = _mm256_set1_epi8('a');\n    __m256i e = _mm256_set1_epi8('e');\n    __m256i i_char = _mm256_set1_epi8('i');\n    __m256i o = _mm256_set1_epi8('o');\n    __m256i u = _mm256_set1_epi8('u');\n    __m256i A = _mm256_set1_epi8('A');\n    __m256i E = _mm256_set1_epi8('E');\n    __m256i I = _mm256_set1_epi8('I');\n    __m256i O = _mm256_set1_epi8('O');\n    __m256i U = _mm256_set1_epi8('U');\n    __m256i two_ahead = _mm256_set1_epi8(2);\n\n    for (; i + 32 <= length; i += 32) {\n        __m256i data = _mm256_loadu_si256((__m256i*)&message[i]);\n        __m256i lower_mask = _mm256_cmpgt_epi8(data, _mm256_set1_epi8('Z'));\n        __m256i upper_mask = _mm256_cmpgt_epi8(data, _mm256_set1_epi8('A'));\n        __m256i is_lower = _mm256_and_si256(lower_mask, upper_mask);\n        \n        // Swap case\n        data = _mm256_xor_si256(data, _mm256_and_si256(is_lower, _mm256_set1_epi8(0x20)));\n\n        // Replace vowels\n        __m256i is_vowel = _mm256_or_si256(\n            _mm256_cmpeq_epi8(data, a),\n            _mm256_or_si256(\n                _mm256_cmpeq_epi8(data, e),\n                _mm256_or_si256(\n                    _mm256_cmpeq_epi8(data, i_char),\n                    _mm256_or_si256(\n                        _mm256_cmpeq_epi8(data, o),\n                        _mm256_cmpeq_epi8(data, u)\n                    )\n                )\n            )\n        );\n\n        __m256i is_vowel_upper = _mm256_or_si256(\n            _mm256_cmpeq_epi8(data, A),\n            _mm256_or_si256(\n                _mm256_cmpeq_epi8(data, E),\n                _mm256_or_si256(\n                    _mm256_cmpeq_epi8(data, I),\n                    _mm256_or_si256(\n                        _mm256_cmpeq_epi8(data, O),\n                        _mm256_cmpeq_epi8(data, U)\n                    )\n                )\n            )\n        );\n\n        is_vowel = _mm256_or_si256(is_vowel, is_vowel_upper);\n\n        __m256i replaced_vowels = _mm256_add_epi8(data, two_ahead);\n        data = _mm256_blendv_epi8(data, replaced_vowels, is_vowel);\n\n        _mm256_storeu_si256((__m256i*)&result[i], data);\n    }\n\n    for (; i < length; ++i) {\n        char c = message[i];\n        if (c >= 'a' && c <= 'z') {\n            c ^= 0x20; // Swap case\n            if (c == 'a' || c == 'e' || c == 'i' || c == 'o' || c == 'u') {\n                c += 2; // Replace vowel\n            }\n        } else if (c >= 'A' && c <= 'Z') {\n            c ^= 0x20; // Swap case\n            if (c == 'A' || c == 'E' || c == 'I' || c == 'O' || c == 'U') {\n                c += 2; // Replace vowel\n            }\n        }\n        result[i] = c;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_106_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <string>\n\nstd::string encode_simd(const std::string & message) {\n    std::string result = message;\n    size_t length = message.length();\n    size_t i = 0;\n\n    __m256i vowels = _mm256_set1_epi8('A');\n    __m256i offset = _mm256_set1_epi8(2);\n    __m256i lower_a = _mm256_set1_epi8('a');\n    __m256i lower_z = _mm256_set1_epi8('z');\n    __m256i upper_a = _mm256_set1_epi8('A');\n    __m256i upper_z = _mm256_set1_epi8('Z');\n\n    while (i + 32 <= length) {\n        __m256i data = _mm256_loadu_si256((__m256i*)&message[i]);\n        __m256i upper_mask = _mm256_cmpgt_epi8(data, lower_a);\n        upper_mask = _mm256_and_si256(upper_mask, _mm256_cmpgt_epi8(upper_z, data));\n        __m256i lower_mask = _mm256_cmpgt_epi8(data, upper_a);\n        lower_mask = _mm256_and_si256(lower_mask, _mm256_cmpgt_epi8(upper_z, data));\n\n        // Swap case\n        data = _mm256_xor_si256(data, _mm256_and_si256(upper_mask, _mm256_set1_epi8(0x20)));\n\n        // Replace vowels\n        __m256i is_vowel = _mm256_or_si256(\n            _mm256_cmpeq_epi8(data, _mm256_set1_epi8('A')),\n            _mm256_or_si256(\n                _mm256_cmpeq_epi8(data, _mm256_set1_epi8('E')),\n                _mm256_or_si256(\n                    _mm256_cmpeq_epi8(data, _mm256_set1_epi8('I')),\n                    _mm256_or_si256(\n                        _mm256_cmpeq_epi8(data, _mm256_set1_epi8('O')),\n                        _mm256_cmpeq_epi8(data, _mm256_set1_epi8('U'))\n                    )\n                )\n            )\n        );\n\n        __m256i new_vowels = _mm256_add_epi8(data, offset);\n        data = _mm256_blendv_epi8(data, new_vowels, is_vowel);\n\n        _mm256_storeu_si256((__m256i*)&result[i], data);\n        i += 32;\n    }\n\n    // Handle remaining characters\n    for (; i < length; ++i) {\n        char c = message[i];\n        if (c >= 'a' && c <= 'z') {\n            c = c - 32; // to upper case\n        } else if (c >= 'A' && c <= 'Z') {\n            c = c + 32; // to lower case\n        }\n        if (c == 'A' || c == 'E' || c == 'I' || c == 'O' || c == 'U' ||\n            c == 'a' || c == 'e' || c == 'i' || c == 'o' || c == 'u') {\n            c += 2;\n        }\n        result[i] = c;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_107_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <string>\n#include <map>\n\nbool check_dict_case_simd(std::map<std::string, std::string> dict) {\n    if (dict.empty()) return false;\n\n    bool all_lower = true;\n    bool all_upper = true;\n\n    for (const auto& pair : dict) {\n        const std::string& key = pair.first;\n        size_t len = key.length();\n        size_t i = 0;\n\n        // Process 32 bytes at a time using AVX2\n        for (; i + 32 <= len; i += 32) {\n            __m256i vec = _mm256_loadu_si256((__m256i*)&key[i]);\n            __m256i lower_mask = _mm256_cmpgt_epi8(vec, _mm256_set1_epi8('a' - 1));\n            __m256i upper_mask = _mm256_cmpgt_epi8(vec, _mm256_set1_epi8('A' - 1));\n            lower_mask = _mm256_and_si256(lower_mask, _mm256_cmpgt_epi8(_mm256_set1_epi8('z' + 1), vec));\n            upper_mask = _mm256_and_si256(upper_mask, _mm256_cmpgt_epi8(_mm256_set1_epi8('Z' + 1), vec));\n\n            if (_mm256_movemask_epi8(lower_mask) != 0xFFFFFFFF) {\n                all_upper = false;\n            }\n            if (_mm256_movemask_epi8(upper_mask) != 0xFFFFFFFF) {\n                all_lower = false;\n            }\n        }\n\n        // Process remaining characters\n        for (; i < len; ++i) {\n            if (key[i] < 'a' || key[i] > 'z') all_lower = false;\n            if (key[i] < 'A' || key[i] > 'Z') all_upper = false;\n        }\n\n        if (!all_lower && !all_upper) {\n            return false;\n        }\n    }\n\n    return all_lower || all_upper;\n}\n```"}
{"task_id": "SimdBench_107_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <string>\n#include <map>\n\nbool check_dict_case_simd(std::map<std::string, std::string> dict) {\n    if (dict.empty()) return false;\n\n    bool all_lower = true;\n    bool all_upper = true;\n\n    for (const auto& pair : dict) {\n        const std::string& key = pair.first;\n        size_t len = key.length();\n        size_t i = 0;\n\n        __m256i lower_mask = _mm256_set1_epi8('a');\n        __m256i upper_mask = _mm256_set1_epi8('A');\n        __m256i alpha_mask = _mm256_set1_epi8(0x1F); // Mask for alphabetic characters\n\n        while (i < len) {\n            size_t remaining = len - i;\n            size_t chunk_size = remaining < 32 ? remaining : 32;\n\n            __m256i keys = _mm256_loadu_si256((__m256i*)&key[i]);\n            __m256i lower_check = _mm256_cmpgt_epi8(keys, lower_mask);\n            __m256i upper_check = _mm256_cmpgt_epi8(keys, upper_mask);\n            __m256i alpha_check = _mm256_and_si256(keys, alpha_mask);\n\n            // Check if all characters are lower case\n            if (chunk_size == 32) {\n                all_lower &= _mm256_movemask_epi8(lower_check);\n            } else {\n                all_lower &= _mm256_movemask_epi8(_mm256_and_si256(lower_check, _mm256_set1_epi8(0xFF >> (8 * (32 - chunk_size)))));\n            }\n\n            // Check if all characters are upper case\n            if (chunk_size == 32) {\n                all_upper &= _mm256_movemask_epi8(upper_check);\n            } else {\n                all_upper &= _mm256_movemask_epi8(_mm256_and_si256(upper_check, _mm256_set1_epi8(0xFF >> (8 * (32 - chunk_size)))));\n            }\n\n            i += chunk_size;\n        }\n    }\n\n    return all_lower || all_upper;\n}\n```"}
{"task_id": "SimdBench_107_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <string>\n#include <map>\n\nbool check_dict_case_simd(std::map<std::string, std::string> dict) {\n    if (dict.empty()) return false;\n\n    bool all_lower = true;\n    bool all_upper = true;\n\n    for (const auto& pair : dict) {\n        const std::string& key = pair.first;\n        size_t len = key.length();\n        size_t i = 0;\n\n        // Process 32 bytes at a time\n        for (; i + 32 <= len; i += 32) {\n            __m256i data = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(key.data() + i));\n            __m256i lower_mask = _mm256_cmpgt_epi8(data, _mm256_set1_epi8('a' - 1));\n            __m256i upper_mask = _mm256_cmpgt_epi8(data, _mm256_set1_epi8('A' - 1));\n            __m256i lower_bound = _mm256_cmpgt_epi8(data, _mm256_set1_epi8('z'));\n            __m256i upper_bound = _mm256_cmpgt_epi8(data, _mm256_set1_epi8('Z'));\n\n            // Check if all characters are lower case\n            all_lower &= _mm256_movemask_epi8(lower_mask) == 0xFFFFFFFF && _mm256_movemask_epi8(lower_bound) == 0;\n\n            // Check if all characters are upper case\n            all_upper &= _mm256_movemask_epi8(upper_mask) == 0xFFFFFFFF && _mm256_movemask_epi8(upper_bound) == 0;\n        }\n\n        // Process remaining characters\n        for (; i < len; ++i) {\n            char c = key[i];\n            if (c < 'a' || c > 'z') all_lower = false;\n            if (c < 'A' || c > 'Z') all_upper = false;\n        }\n\n        if (!all_lower && !all_upper) return false;\n    }\n\n    return all_lower || all_upper;\n}\n```"}
{"task_id": "SimdBench_107_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <string>\n#include <map>\n\nbool check_dict_case_simd(std::map<std::string, std::string> dict) {\n    if (dict.empty()) return false;\n\n    bool all_lower = true;\n    bool all_upper = true;\n\n    for (const auto& pair : dict) {\n        const std::string& key = pair.first;\n        size_t len = key.length();\n        size_t i = 0;\n\n        // Process 32 bytes at a time\n        for (; i + 32 <= len; i += 32) {\n            __m256i keys = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(key.data() + i));\n            __m256i lower_mask = _mm256_cmpgt_epi8(keys, _mm256_set1_epi8('a' - 1));\n            __m256i upper_mask = _mm256_cmpgt_epi8(keys, _mm256_set1_epi8('A' - 1));\n            __m256i lower_bound = _mm256_cmpgt_epi8(keys, _mm256_set1_epi8('z'));\n            __m256i upper_bound = _mm256_cmpgt_epi8(keys, _mm256_set1_epi8('Z'));\n\n            // Check if all characters are lower case\n            all_lower &= _mm256_movemask_epi8(lower_mask) == 0xFFFFFFFF && _mm256_movemask_epi8(lower_bound) == 0;\n\n            // Check if all characters are upper case\n            all_upper &= _mm256_movemask_epi8(upper_mask) == 0xFFFFFFFF && _mm256_movemask_epi8(upper_bound) == 0;\n        }\n\n        // Process remaining characters\n        for (; i < len; ++i) {\n            char c = key[i];\n            if (c < 'a' || c > 'z') all_lower = false;\n            if (c < 'A' || c > 'Z') all_upper = false;\n        }\n\n        if (!all_lower && !all_upper) return false;\n    }\n\n    return all_lower || all_upper;\n}\n```"}
{"task_id": "SimdBench_107_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <string>\n#include <map>\n\nbool check_dict_case_simd(std::map<std::string, std::string> dict) {\n    if (dict.empty()) return false;\n\n    bool all_lower = true;\n    bool all_upper = true;\n\n    for (const auto& pair : dict) {\n        const std::string& key = pair.first;\n        size_t len = key.length();\n        size_t i = 0;\n\n        // Process 32 bytes at a time\n        for (; i + 32 <= len; i += 32) {\n            __m256i data = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(key.data() + i));\n            __m256i lower_mask = _mm256_cmpgt_epi8(data, _mm256_set1_epi8('a' - 1));\n            __m256i upper_mask = _mm256_cmpgt_epi8(data, _mm256_set1_epi8('A' - 1));\n            lower_mask = _mm256_and_si256(lower_mask, _mm256_cmpgt_epi8(_mm256_set1_epi8('z' + 1), data));\n            upper_mask = _mm256_and_si256(upper_mask, _mm256_cmpgt_epi8(_mm256_set1_epi8('Z' + 1), data));\n\n            all_lower &= _mm256_movemask_epi8(lower_mask) == 0xFFFFFFFF;\n            all_upper &= _mm256_movemask_epi8(upper_mask) == 0xFFFFFFFF;\n        }\n\n        // Process remaining characters\n        for (; i < len; ++i) {\n            char c = key[i];\n            if (c >= 'a' && c <= 'z') {\n                all_upper = false;\n            } else if (c >= 'A' && c <= 'Z') {\n                all_lower = false;\n            } else {\n                all_lower = false;\n                all_upper = false;\n            }\n        }\n\n        if (!all_lower && !all_upper) {\n            return false;\n        }\n    }\n\n    return all_lower || all_upper;\n}\n```"}
{"task_id": "SimdBench_108_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nstd::vector<int> count_up_to_simd(int n) {\n    if (n < 2) return {};\n\n    std::vector<int> primes;\n    bool* is_prime = new bool[n];\n    std::fill(is_prime, is_prime + n, true);\n    is_prime[0] = is_prime[1] = false;\n\n    for (int i = 2; i * i < n; i++) {\n        if (is_prime[i]) {\n            for (int j = i * i; j < n; j += i) {\n                is_prime[j] = false;\n            }\n        }\n    }\n\n    __m256i mask = _mm256_set1_epi32(0);\n    for (int i = 2; i < n; i += 8) {\n        mask = _mm256_set1_epi32(1);\n        __m256i idx = _mm256_set_epi32(i + 7, i + 6, i + 5, i + 4, i + 3, i + 2, i + 1, i);\n        __m256i prime_mask = _mm256_set_epi32(is_prime[i + 7], is_prime[i + 6], is_prime[i + 5], is_prime[i + 4], is_prime[i + 3], is_prime[i + 2], is_prime[i + 1], is_prime[i]);\n\n        __m256i result_mask = _mm256_and_si256(mask, prime_mask);\n        for (int j = 0; j < 8; j++) {\n            if (_mm256_extract_epi32(result_mask, j) != 0) {\n                primes.push_back(_mm256_extract_epi32(idx, j));\n            }\n        }\n    }\n\n    delete[] is_prime;\n    return primes;\n}\n```"}
{"task_id": "SimdBench_108_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nstd::vector<int> count_up_to_simd(int n) {\n    if (n < 2) return {};\n\n    std::vector<int> primes;\n    const int vector_size = 8; // AVX2 can process 8 integers at a time\n    __m256i sieve = _mm256_set1_epi32(1); // Initialize sieve with 1s\n\n    for (int i = 2; i * i < n; i++) {\n        if (sieve[i]) {\n            for (int j = i * i; j < n; j += i) {\n                if (j % vector_size == 0) {\n                    __m256i indices = _mm256_set_epi32(j + 7, j + 6, j + 5, j + 4, j + 3, j + 2, j + 1, j);\n                    sieve = _mm256_or_si256(sieve, _mm256_set1_epi32(1 << (j % vector_size)));\n                }\n            }\n        }\n    }\n\n    for (int i = 2; i < n; i++) {\n        if (!(sieve[i] & 1)) {\n            primes.push_back(i);\n        }\n    }\n\n    return primes;\n}\n```"}
{"task_id": "SimdBench_108_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nstd::vector<int> count_up_to_simd(int n) {\n    if (n < 2) return {};\n\n    std::vector<int> primes;\n    bool is_prime[32] = { false }; // To hold prime status for numbers < 32\n    for (int i = 2; i < 32; ++i) is_prime[i] = true;\n\n    for (int i = 2; i * i < 32; ++i) {\n        if (is_prime[i]) {\n            for (int j = i * i; j < 32; j += i) {\n                is_prime[j] = false;\n            }\n        }\n    }\n\n    __m256i vec_n = _mm256_set1_epi32(n);\n    for (int i = 2; i < n; i += 8) {\n        __m256i vec_i = _mm256_set_epi32(i + 7, i + 6, i + 5, i + 4, i + 3, i + 2, i + 1, i);\n        __m256i mask = _mm256_cmpgt_epi32(vec_i, vec_n);\n        if (_mm256_movemask_epi8(mask) == 0) {\n            for (int j = 0; j < 8; ++j) {\n                int idx = i + j;\n                if (idx < n && is_prime[idx]) {\n                    primes.push_back(idx);\n                }\n            }\n        }\n    }\n\n    return primes;\n}\n```"}
{"task_id": "SimdBench_108_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nstd::vector<int> count_up_to_simd(int n) {\n    if (n < 2) return {};\n\n    std::vector<int> primes;\n    std::vector<bool> is_prime(n, true);\n    is_prime[0] = is_prime[1] = false;\n\n    for (int i = 2; i * i < n; i++) {\n        if (is_prime[i]) {\n            for (int j = i * i; j < n; j += i) {\n                is_prime[j] = false;\n            }\n        }\n    }\n\n    __m256i vec_n = _mm256_set1_epi32(n);\n    for (int i = 2; i < n; i += 8) {\n        __m256i vec_i = _mm256_set_epi32(i + 7, i + 6, i + 5, i + 4, i + 3, i + 2, i + 1, i);\n        __m256i mask = _mm256_cmpgt_epi32(vec_i, vec_n);\n        if (_mm256_movemask_epi8(mask) == 0) {\n            __m256i prime_mask = _mm256_set1_epi32(0);\n            for (int j = 2; j * j < n; j++) {\n                if (is_prime[j]) {\n                    __m256i vec_j = _mm256_set1_epi32(j);\n                    __m256i cmp_mask = _mm256_cmpeq_epi32(vec_i, vec_j);\n                    prime_mask = _mm256_or_si256(prime_mask, cmp_mask);\n                }\n            }\n            for (int k = 0; k < 8; k++) {\n                if (_mm256_extract_epi32(prime_mask, k) != 0) {\n                    primes.push_back(i + k);\n                }\n            }\n        }\n    }\n    return primes;\n}\n```"}
{"task_id": "SimdBench_108_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nstd::vector<int> count_up_to_simd(int n) {\n    if (n < 2) return {};\n\n    std::vector<int> primes;\n    bool* is_prime = new bool[n];\n    std::fill(is_prime, is_prime + n, true);\n    is_prime[0] = is_prime[1] = false;\n\n    for (int i = 2; i * i < n; i++) {\n        if (is_prime[i]) {\n            for (int j = i * i; j < n; j += i) {\n                is_prime[j] = false;\n            }\n        }\n    }\n\n    __m256i mask = _mm256_set1_epi32(1);\n    for (int i = 2; i < n; i += 8) {\n        __m256i indices = _mm256_set_epi32(i + 7, i + 6, i + 5, i + 4, i + 3, i + 2, i + 1, i);\n        __m256i prime_mask = _mm256_loadu_si256((__m256i*)&is_prime[i]);\n        __m256i result_mask = _mm256_and_si256(prime_mask, mask);\n        \n        for (int j = 0; j < 8; j++) {\n            if (_mm256_extract_epi32(result_mask, j) != 0) {\n                primes.push_back(i + j);\n            }\n        }\n    }\n\n    delete[] is_prime;\n    return primes;\n}\n```"}
{"task_id": "SimdBench_109_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <string>\n\nint count_upper_simd(const std::string & s) {\n    int count = 0;\n    size_t length = s.length();\n    size_t i;\n\n    __m256i vowels_mask = _mm256_setr_epi8('A', 0, 'E', 0, 'I', 0, 'O', 0, 'U', 0, 'A', 0, 'E', 0, 'I', 0, 'O', 0, 'U');\n    __m256i upper_mask = _mm256_set1_epi8(0xDF); // Mask to check for uppercase letters\n\n    for (i = 0; i < length; i += 32) {\n        __m256i data = _mm256_loadu_si256((__m256i*)&s[i]);\n        __m256i even_indices = _mm256_and_si256(data, upper_mask);\n        __m256i cmp_vowels = _mm256_cmpeq_epi8(even_indices, vowels_mask);\n        count += _mm256_movemask_epi8(cmp_vowels);\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_109_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <string>\n\nint count_upper_simd(const std::string & s) {\n    int count = 0;\n    size_t length = s.length();\n    size_t i;\n\n    __m256i vowels = _mm256_setr_epi8('A', 0, 'E', 0, 'I', 0, 'O', 0, 'U', 0, 'A', 0, 'E', 0, 'I', 0, 'O', 0, 'U');\n    __m256i mask = _mm256_set1_epi8(0x20); // Mask for lowercase conversion\n\n    for (i = 0; i < length; i += 32) {\n        __m256i data = _mm256_loadu_si256((__m256i*)&s[i]);\n        __m256i even_indices = _mm256_and_si256(data, _mm256_set1_epi8(0x01)); // Mask for even indices\n        __m256i upper_case = _mm256_andnot_si256(mask, data); // Get uppercase characters\n        __m256i is_vowel = _mm256_cmpeq_epi8(upper_case, vowels); // Compare with vowels\n\n        // Count the number of vowels in even indices\n        __m256i result = _mm256_and_si256(is_vowel, even_indices);\n        count += _mm256_movemask_epi8(result);\n    }\n\n    // Handle remaining characters\n    for (; i < length; ++i) {\n        if (i % 2 == 0 && (s[i] == 'A' || s[i] == 'E' || s[i] == 'I' || s[i] == 'O' || s[i] == 'U')) {\n            count++;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_109_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <string>\n\nint count_upper_simd(const std::string & s) {\n    const __m256i vowels = _mm256_setr_epi8('A', 0, 'E', 0, 'I', 0, 'O', 0, 'U', 0, 'A', 0, 'E', 0, 'I', 0, 'O', 0, 'U', 0);\n    const __m256i mask = _mm256_set1_epi8(0x20); // Mask to check uppercase\n    int count = 0;\n\n    size_t length = s.length();\n    size_t i = 0;\n\n    for (; i + 32 <= length; i += 32) {\n        __m256i data = _mm256_loadu_si256((__m256i*)&s[i]);\n        __m256i even_indices = _mm256_and_si256(data, _mm256_set1_epi8(0x01)); // Mask for even indices\n        __m256i upper_case = _mm256_andnot_si256(mask, data); // Check for uppercase\n\n        __m256i is_vowel = _mm256_cmpeq_epi8(upper_case, vowels);\n        __m256i result = _mm256_and_si256(is_vowel, even_indices);\n\n        count += _mm256_movemask_epi8(result);\n    }\n\n    for (; i < length; i += 2) {\n        if (i < length && (s[i] >= 'A' && s[i] <= 'Z') && (s[i] == 'A' || s[i] == 'E' || s[i] == 'I' || s[i] == 'O' || s[i] == 'U')) {\n            count++;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_109_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <string>\n\nint count_upper_simd(const std::string & s) {\n    int count = 0;\n    size_t length = s.length();\n    size_t i;\n\n    __m256i vowels_mask = _mm256_setr_epi8('A', 'E', 'I', 'O', 'U', 0, 0, 0, 0, \n                                            'A', 'E', 'I', 'O', 'U', 0, 0, 0);\n    __m256i upper_mask = _mm256_set1_epi8(0x20); // Mask to check for uppercase\n\n    for (i = 0; i < length; i += 32) {\n        __m256i data = _mm256_loadu_si256((__m256i*)&s[i]);\n        __m256i even_indices = _mm256_and_si256(data, _mm256_set1_epi8(0x01)); // Mask for even indices\n        __m256i upper_case = _mm256_andnot_si256(upper_mask, data); // Check for uppercase\n\n        // Compare with vowels\n        __m256i cmp_vowels = _mm256_cmpeq_epi8(data, vowels_mask);\n        __m256i result = _mm256_and_si256(cmp_vowels, upper_case);\n\n        // Count the number of set bits in result\n        int mask = _mm256_movemask_epi8(result);\n        count += __builtin_popcount(mask);\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_109_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <string>\n\nint count_upper_simd(const std::string & s) {\n    int count = 0;\n    size_t length = s.length();\n    size_t i;\n\n    __m256i vowels = _mm256_setr_epi8('A', 0, 'E', 0, 'I', 0, 'O', 0, 'U', 0, 'A', 0, 'E', 0, 'I', 0, 'O', 0, 'U');\n    __m256i mask = _mm256_set1_epi8(0x20); // Mask for lowercase conversion\n\n    for (i = 0; i < length; i += 32) {\n        __m256i data = _mm256_loadu_si256((__m256i*)&s[i]);\n        __m256i even_indices = _mm256_and_si256(data, _mm256_set1_epi8(0x01)); // Mask for even indices\n        __m256i upper_case = _mm256_andnot_si256(mask, data); // Get uppercase characters\n        __m256i is_vowel = _mm256_cmpeq_epi8(upper_case, vowels); // Compare with vowels\n\n        // Count the number of vowels in even indices\n        __m256i result = _mm256_and_si256(is_vowel, even_indices);\n        count += _mm256_movemask_epi8(result);\n    }\n\n    // Handle remaining characters\n    for (; i < length; ++i) {\n        if (i % 2 == 0 && (s[i] == 'A' || s[i] == 'E' || s[i] == 'I' || s[i] == 'O' || s[i] == 'U')) {\n            count++;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_110_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nstd::vector<int> make_a_pile_simd(int n) {\n    int levels = n;\n    std::vector<int> stones(levels);\n    \n    __m256i odd_start = _mm256_set1_epi32(n);\n    __m256i even_start = _mm256_set1_epi32(n + (n % 2 == 0 ? 2 : 1));\n    \n    for (int i = 0; i < levels; i += 8) {\n        __m256i indices = _mm256_add_epi32(_mm256_set1_epi32(i), odd_start);\n        if (n % 2 == 0) {\n            indices = _mm256_add_epi32(indices, _mm256_set1_epi32(1));\n        }\n        _mm256_storeu_si256((__m256i*)&stones[i], indices);\n        \n        odd_start = _mm256_add_epi32(odd_start, _mm256_set1_epi32(2));\n        even_start = _mm256_add_epi32(even_start, _mm256_set1_epi32(2));\n    }\n    \n    return stones;\n}\n```"}
{"task_id": "SimdBench_110_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nstd::vector<int> make_a_pile_simd(int n) {\n    std::vector<int> result(n);\n    if (n <= 0) return result;\n\n    __m256i stones;\n    if (n % 2 == 0) {\n        stones = _mm256_set_epi32(n + 6, n + 4, n + 2, n, n + 6, n + 4, n + 2, n);\n    } else {\n        stones = _mm256_set_epi32(n + 6, n + 4, n + 2, n, n + 6, n + 4, n + 2, n);\n    }\n\n    for (int i = 0; i < n; i += 8) {\n        if (i + 8 <= n) {\n            _mm256_storeu_si256((__m256i*)&result[i], stones);\n        } else {\n            for (int j = 0; j < n - i; ++j) {\n                result[i + j] = n + 2 * (i + j);\n            }\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_110_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nstd::vector<int> make_a_pile_simd(int n) {\n    std::vector<int> result(n);\n    if (n <= 0) return result;\n\n    __m256i odd_start = _mm256_set1_epi32(n | 1); // Start with the next odd number if n is odd\n    __m256i even_start = _mm256_set1_epi32(n & ~1); // Start with the next even number if n is even\n    __m256i increment = _mm256_set1_epi32(2); // Increment by 2 for each level\n\n    for (int i = 0; i < n; i += 8) {\n        __m256i level_indices = _mm256_add_epi32(_mm256_set1_epi32(i), _mm256_set1_epi32(1));\n        __m256i stones;\n\n        if (n % 2 == 0) {\n            stones = _mm256_add_epi32(even_start, _mm256_mullo_epi32(level_indices, increment));\n        } else {\n            stones = _mm256_add_epi32(odd_start, _mm256_mullo_epi32(level_indices, increment));\n        }\n\n        _mm256_storeu_si256((__m256i*)&result[i], stones);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_110_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nstd::vector<int> make_a_pile_simd(int n) {\n    int levels = n;\n    std::vector<int> result(levels);\n    \n    __m256i odd_start = _mm256_set1_epi32(n);\n    __m256i even_start = _mm256_set1_epi32(n + (n % 2 == 0 ? 2 : 1));\n    \n    for (int i = 0; i < levels; i += 8) {\n        __m256i indices = _mm256_add_epi32(_mm256_set1_epi32(i), odd_start);\n        if (n % 2 == 0) {\n            indices = _mm256_add_epi32(indices, _mm256_set1_epi32(1));\n        }\n        _mm256_storeu_si256((__m256i*)&result[i], indices);\n        odd_start = _mm256_add_epi32(odd_start, _mm256_set1_epi32(2));\n        even_start = _mm256_add_epi32(even_start, _mm256_set1_epi32(2));\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_110_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nstd::vector<int> make_a_pile_simd(int n) {\n    int levels = n;\n    std::vector<int> result(levels);\n    \n    __m256i stones;\n    if (n % 2 == 0) {\n        stones = _mm256_set_epi32(n + 6, n + 4, n + 2, n, 0, 0, 0, 0);\n    } else {\n        stones = _mm256_set_epi32(n + 6, n + 4, n + 2, n, 0, 0, 0, 0);\n    }\n\n    for (int i = 0; i < levels; i += 8) {\n        if (i < levels) _mm256_storeu_si256((__m256i*)&result[i], stones);\n        stones = _mm256_add_epi32(stones, _mm256_set1_epi32(2));\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_111_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n#include <cmath>\n\nstd::string rounded_avg_simd(int64_t n, int64_t m) {\n    if (n > m) return \"-1\";\n\n    int64_t count = m - n + 1;\n    __m256i sum_vec = _mm256_setzero_si256();\n    int64_t i;\n\n    for (i = n; i <= m - 7; i += 8) {\n        __m256i vec = _mm256_set_epi64x(i + 7, i + 6, i + 5, i + 4, i + 3, i + 2, i + 1, i);\n        sum_vec = _mm256_add_epi64(sum_vec, vec);\n    }\n\n    int64_t sum = 0;\n    for (; i <= m; ++i) {\n        sum += i;\n    }\n\n    // Horizontal sum of the vector\n    int64_t sum_arr[4];\n    _mm256_storeu_si256((__m256i*)sum_arr, sum_vec);\n    sum = sum_arr[0] + sum_arr[1] + sum_arr[2] + sum_arr[3];\n\n    sum += (count % 8) * (m + n) / 2; // Add remaining elements\n\n    int64_t avg = sum / count;\n    if (sum % count != 0) {\n        avg = (sum < 0) ? (avg - 1) : avg; // Round down\n    }\n\n    std::string binary;\n    while (avg > 0) {\n        binary = char((avg % 2) + '0') + binary;\n        avg /= 2;\n    }\n\n    return binary.empty() ? \"0\" : binary;\n}\n```"}
{"task_id": "SimdBench_111_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n#include <sstream>\n\nstd::string rounded_avg_simd(int64_t n, int64_t m) {\n    if (n > m) return \"-1\";\n\n    __m256i sum = _mm256_setzero_si256();\n    int64_t count = m - n + 1;\n    int64_t i;\n\n    // Process 16 integers at a time\n    for (i = n; i <= m - 15; i += 16) {\n        __m256i vec = _mm256_set_epi64x(i + 15, i + 14, i + 13, i + 12,\n                                         i + 11, i + 10, i + 9, i + 8);\n        sum = _mm256_add_epi64(sum, vec);\n    }\n\n    // Handle remaining integers\n    for (; i <= m; ++i) {\n        sum = _mm256_add_epi64(sum, _mm256_set_epi64x(0, 0, 0, i));\n    }\n\n    // Horizontal sum\n    int64_t total[4];\n    _mm256_storeu_si256((__m256i*)total, sum);\n    int64_t total_sum = total[0] + total[1] + total[2] + total[3];\n\n    // Calculate average\n    int64_t avg = total_sum / count;\n\n    // Convert to binary\n    std::stringstream binary;\n    while (avg > 0) {\n        binary << (avg % 2);\n        avg /= 2;\n    }\n\n    std::string result = binary.str();\n    std::reverse(result.begin(), result.end());\n    return result.empty() ? \"0\" : result;\n}\n```"}
{"task_id": "SimdBench_111_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n#include <cmath>\n\nstd::string rounded_avg_simd(int64_t n, int64_t m) {\n    if (n > m) return \"-1\";\n\n    int64_t count = m - n + 1;\n    __m256i sum_vec = _mm256_setzero_si256();\n    int64_t i;\n\n    for (i = n; i <= m - 4; i += 4) {\n        __m256i vec = _mm256_set_epi64x(i + 3, i + 2, i + 1, i);\n        sum_vec = _mm256_add_epi64(sum_vec, vec);\n    }\n\n    int64_t sum = 0;\n    for (; i <= m; ++i) {\n        sum += i;\n    }\n\n    // Horizontal sum of the vector\n    int64_t temp[4];\n    _mm256_storeu_si256((__m256i*)temp, sum_vec);\n    sum += temp[0] + temp[1] + temp[2] + temp[3];\n\n    // Calculate average\n    int64_t avg = sum / count;\n\n    // Round down\n    int64_t rounded_avg = avg;\n\n    // Convert to binary\n    std::string binary;\n    if (rounded_avg == 0) return \"0\";\n    while (rounded_avg > 0) {\n        binary.insert(binary.begin(), (rounded_avg % 2) + '0');\n        rounded_avg /= 2;\n    }\n\n    return binary;\n}\n```"}
{"task_id": "SimdBench_111_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n#include <vector>\n\nstd::string rounded_avg_simd(int64_t n, int64_t m) {\n    if (n > m) return \"-1\";\n\n    int64_t count = m - n + 1;\n    __m256i sum_vec = _mm256_setzero_si256();\n    int64_t i;\n\n    for (i = n; i <= m - 7; i += 8) {\n        __m256i vec = _mm256_set_epi64x(i + 7, i + 6, i + 5, i + 4, i + 3, i + 2, i + 1, i);\n        sum_vec = _mm256_add_epi64(sum_vec, vec);\n    }\n\n    int64_t sum = 0;\n    for (; i <= m; ++i) {\n        sum += i;\n    }\n\n    // Horizontal sum of the vector\n    int64_t temp[4];\n    _mm256_storeu_si256((__m256i*)temp, sum_vec);\n    sum = temp[0] + temp[1] + temp[2] + temp[3];\n\n    // Add remaining sum\n    sum += (count % 8) * (m + n) / 2;\n\n    // Calculate average\n    int64_t avg = sum / count;\n\n    // Convert to binary string\n    std::string binary;\n    while (avg > 0) {\n        binary.insert(binary.begin(), (avg % 2) + '0');\n        avg /= 2;\n    }\n\n    return binary.empty() ? \"0\" : binary;\n}\n```"}
{"task_id": "SimdBench_111_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n#include <vector>\n\nstd::string rounded_avg_simd(int64_t n, int64_t m) {\n    if (n > m) return \"-1\";\n\n    int64_t count = m - n + 1;\n    int64_t sum = 0;\n\n    // Using AVX2 to sum integers from n to m\n    __m256i vec_sum = _mm256_setzero_si256();\n    __m256i vec_n = _mm256_set_epi64x(m, m - 1, m - 2, m - 3);\n    \n    for (int64_t i = n; i <= m; i += 4) {\n        vec_sum = _mm256_add_epi64(vec_sum, vec_n);\n        vec_n = _mm256_sub_epi64(vec_n, _mm256_set1_epi64x(4));\n    }\n\n    // Horizontal sum\n    int64_t temp[4];\n    _mm256_storeu_si256((__m256i*)temp, vec_sum);\n    sum = temp[0] + temp[1] + temp[2] + temp[3];\n\n    // Calculate average\n    int64_t avg = sum / count;\n\n    // Convert to binary\n    std::string binary;\n    while (avg > 0) {\n        binary.insert(binary.begin(), (avg % 2) + '0');\n        avg /= 2;\n    }\n\n    return binary.empty() ? \"0\" : binary;\n}\n```"}
{"task_id": "SimdBench_112_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nstd::vector<int> func_simd(int n) {\n    std::vector<int> result(n);\n    int i;\n\n    for (i = 0; i < n; i += 8) {\n        __m256i indices = _mm256_set_epi32(i + 7, i + 6, i + 5, i + 4, i + 3, i + 2, i + 1, i);\n        __m256i factorials = _mm256_set1_epi32(1);\n        __m256i sums = _mm256_set1_epi32(0);\n        \n        for (int j = 1; j <= 8; j++) {\n            __m256i current_indices = _mm256_add_epi32(indices, _mm256_set1_epi32(j));\n            __m256i is_even = _mm256_and_si256(_mm256_set1_epi32(1), current_indices);\n            __m256i is_odd = _mm256_xor_si256(is_even, _mm256_set1_epi32(1));\n\n            // Calculate factorial for even indices\n            __m256i factorial_mask = _mm256_cmpeq_epi32(is_even, _mm256_set1_epi32(0));\n            for (int k = 1; k <= 8; k++) {\n                factorials = _mm256_mullo_epi32(factorials, _mm256_blendv_epi8(factorials, _mm256_set1_epi32(k), factorial_mask));\n            }\n\n            // Calculate sum for odd indices\n            sums = _mm256_add_epi32(sums, _mm256_blendv_epi8(sums, _mm256_add_epi32(current_indices, _mm256_set1_epi32(1)), is_odd));\n        }\n\n        __m256i result_vector = _mm256_blendv_epi8(factorials, sums, is_odd);\n        _mm256_storeu_si256((__m256i*)&result[i], result_vector);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_112_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nstd::vector<int> func_simd(int n) {\n    std::vector<int> result(n);\n    int i = 0;\n\n    for (; i <= n - 8; i += 8) {\n        __m256i indices = _mm256_set_epi32(i + 7, i + 6, i + 5, i + 4, i + 3, i + 2, i + 1, i);\n        __m256i is_even = _mm256_and_si256(indices, _mm256_set1_epi32(1));\n        \n        __m256i factorials = _mm256_set1_epi32(1);\n        __m256i sums = _mm256_set1_epi32(0);\n        \n        for (int j = 1; j <= 8; ++j) {\n            __m256i current_index = _mm256_add_epi32(indices, _mm256_set1_epi32(1));\n            __m256i current_factorial = _mm256_set1_epi32(1);\n            __m256i current_sum = _mm256_set1_epi32(0);\n            \n            for (int k = 1; k <= j; ++k) {\n                current_factorial = _mm256_mullo_epi32(current_factorial, _mm256_set1_epi32(k));\n                current_sum = _mm256_add_epi32(current_sum, _mm256_set1_epi32(k));\n            }\n            \n            __m256i result_value = _mm256_blendv_epi8(current_sum, current_factorial, is_even);\n            factorials = _mm256_blendv_epi8(factorials, result_value, is_even);\n            sums = _mm256_blendv_epi8(sums, current_sum, is_even);\n        }\n        \n        _mm256_storeu_si256((__m256i*)&result[i], factorials);\n    }\n\n    for (; i < n; ++i) {\n        if (i % 2 == 0) {\n            int factorial = 1;\n            for (int j = 1; j <= i; ++j) {\n                factorial *= j;\n            }\n            result[i] = factorial % 10000;\n        } else {\n            result[i] = (i * (i + 1)) / 2;\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_112_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nstd::vector<int> func_simd(int n) {\n    std::vector<int> result(n);\n    int i = 0;\n\n    // Process in chunks of 8\n    for (; i <= n - 8; i += 8) {\n        __m256i indices = _mm256_set_epi32(i + 8, i + 7, i + 6, i + 5, i + 4, i + 3, i + 2, i + 1);\n        __m256i even_mask = _mm256_and_si256(indices, _mm256_set1_epi32(1)); // Mask for even indices\n\n        // Calculate factorials for even indices\n        __m256i factorials = _mm256_set1_epi32(1);\n        for (int j = 1; j <= 8; j++) {\n            __m256i current_index = _mm256_set1_epi32(j);\n            __m256i is_even = _mm256_cmpeq_epi32(_mm256_and_si256(current_index, _mm256_set1_epi32(1)), _mm256_setzero_si256());\n            factorials = _mm256_blendv_epi8(factorials, _mm256_mullo_epi32(factorials, current_index), is_even);\n        }\n\n        // Calculate sums for odd indices\n        __m256i sums = _mm256_setzero_si256();\n        for (int j = 1; j <= 8; j++) {\n            __m256i current_index = _mm256_set1_epi32(j);\n            __m256i is_odd = _mm256_cmpeq_epi32(_mm256_and_si256(current_index, _mm256_set1_epi32(1)), _mm256_setzero_si256());\n            sums = _mm256_blendv_epi8(sums, _mm256_add_epi32(sums, current_index), is_odd);\n        }\n\n        // Combine results\n        __m256i result_vec = _mm256_blendv_epi8(factorials, sums, even_mask);\n        _mm256_storeu_si256((__m256i*)&result[i], result_vec);\n    }\n\n    // Handle remaining elements\n    for (; i < n; i++) {\n        if (i % 2 == 0) {\n            int factorial = 1;\n            for (int j = 1; j <= i; j++) {\n                factorial = (factorial * j) % 10000;\n            }\n            result[i] = factorial;\n        } else {\n            result[i] = (i * (i + 1)) / 2; // Sum of first i numbers\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_112_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nstd::vector<int> func_simd(int n) {\n    std::vector<int> result(n);\n    int i;\n\n    for (i = 0; i < n; i += 8) {\n        __m256i indices = _mm256_set_epi32(i + 7, i + 6, i + 5, i + 4, i + 3, i + 2, i + 1, i);\n        __m256i is_even = _mm256_and_si256(indices, _mm256_set1_epi32(1));\n        \n        __m256i factorials = _mm256_set1_epi32(1);\n        __m256i sums = _mm256_set1_epi32(0);\n        \n        for (int j = 1; j <= 8; ++j) {\n            __m256i current_index = _mm256_add_epi32(indices, _mm256_set1_epi32(1));\n            __m256i is_current_even = _mm256_and_si256(current_index, _mm256_set1_epi32(1));\n            \n            // Calculate factorial for even indices\n            __m256i factorial_mask = _mm256_cmpeq_epi32(is_current_even, _mm256_setzero_si256());\n            __m256i temp_factorials = factorials;\n            for (int k = 1; k <= j; ++k) {\n                temp_factorials = _mm256_mullo_epi32(temp_factorials, _mm256_set1_epi32(k));\n            }\n            factorials = _mm256_blendv_epi8(factorials, temp_factorials, factorial_mask);\n            \n            // Calculate sum for odd indices\n            __m256i temp_sums = _mm256_add_epi32(sums, current_index);\n            sums = _mm256_blendv_epi8(sums, temp_sums, factorial_mask);\n        }\n\n        __m256i result_vec = _mm256_blendv_epi8(factorials, sums, _mm256_set1_epi32(1));\n        _mm256_storeu_si256((__m256i*)&result[i], result_vec);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_112_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nstd::vector<int> func_simd(int n) {\n    std::vector<int> result(n);\n    int i = 0;\n\n    for (; i <= n - 8; i += 8) {\n        __m256i indices = _mm256_set_epi32(i + 8, i + 7, i + 6, i + 5, i + 4, i + 3, i + 2, i + 1);\n        __m256i is_even = _mm256_and_si256(indices, _mm256_set1_epi32(1));\n        \n        // Calculate factorials for even indices\n        __m256i factorial = _mm256_set1_epi32(1);\n        for (int j = 1; j <= 8; ++j) {\n            __m256i mask = _mm256_cmpeq_epi32(is_even, _mm256_set1_epi32(0));\n            __m256i current_index = _mm256_add_epi32(indices, _mm256_set1_epi32(-1));\n            factorial = _mm256_mullo_epi32(factorial, current_index);\n            is_even = _mm256_srli_epi32(is_even, 1);\n            factorial = _mm256_blendv_epi8(factorial, _mm256_set1_epi32(0), mask);\n        }\n\n        // Calculate sums for odd indices\n        __m256i sum = _mm256_setzero_si256();\n        for (int j = 1; j <= 8; ++j) {\n            __m256i current_index = _mm256_add_epi32(indices, _mm256_set1_epi32(-1));\n            __m256i mask = _mm256_cmpeq_epi32(is_even, _mm256_set1_epi32(1));\n            sum = _mm256_add_epi32(sum, current_index);\n            is_even = _mm256_srli_epi32(is_even, 1);\n            factorial = _mm256_blendv_epi8(factorial, sum, mask);\n        }\n\n        _mm256_storeu_si256((__m256i*)&result[i], factorial);\n    }\n\n    for (; i < n; ++i) {\n        if (i % 2 == 0) {\n            int fact = 1;\n            for (int j = 1; j <= i; ++j) {\n                fact = (fact * j) % 10000;\n            }\n            result[i] = fact;\n        } else {\n            result[i] = (i * (i + 1)) / 2;\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_113_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nbool is_palindrome(int num) {\n    int original = num, reversed = 0;\n    while (num > 0) {\n        reversed = reversed * 10 + num % 10;\n        num /= 10;\n    }\n    return original == reversed;\n}\n\nstd::vector<int> even_odd_palindrome_simd(int n) {\n    __m256i even_count = _mm256_setzero_si256();\n    __m256i odd_count = _mm256_setzero_si256();\n\n    for (int i = 1; i <= n; i += 8) {\n        __m256i indices = _mm256_setr_epi32(i, i + 1, i + 2, i + 3, i + 4, i + 5, i + 6, i + 7);\n        __m256i palindromes = _mm256_setzero_si256();\n        \n        for (int j = 0; j < 8 && (i + j) <= n; j++) {\n            if (is_palindrome(i + j)) {\n                palindromes = _mm256_insert_epi32(palindromes, 1, j);\n            }\n        }\n\n        __m256i even_mask = _mm256_and_si256(palindromes, _mm256_set1_epi32(0x1));\n        __m256i odd_mask = _mm256_and_si256(palindromes, _mm256_set1_epi32(0x0));\n\n        even_count = _mm256_add_epi32(even_count, _mm256_and_si256(even_mask, _mm256_set1_epi32(1)));\n        odd_count = _mm256_add_epi32(odd_count, _mm256_and_si256(odd_mask, _mm256_set1_epi32(1)));\n    }\n\n    int even_result = _mm256_extract_epi32(even_count, 0);\n    int odd_result = _mm256_extract_epi32(odd_count, 0);\n\n    return {even_result, odd_result};\n}\n```"}
{"task_id": "SimdBench_113_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nbool is_palindrome(int num) {\n    int reversed = 0, original = num;\n    while (num > 0) {\n        reversed = reversed * 10 + num % 10;\n        num /= 10;\n    }\n    return original == reversed;\n}\n\nstd::vector<int> even_odd_palindrome_simd(int n) {\n    __m256i even_count = _mm256_setzero_si256();\n    __m256i odd_count = _mm256_setzero_si256();\n\n    for (int i = 1; i <= n; i += 8) {\n        __m256i indices = _mm256_setr_epi32(i, i + 1, i + 2, i + 3, i + 4, i + 5, i + 6, i + 7);\n        __m256i palindromes = _mm256_setzero_si256();\n        \n        for (int j = 0; j < 8 && (i + j) <= n; j++) {\n            if (is_palindrome(i + j)) {\n                palindromes = _mm256_insert_epi32(palindromes, 1, j);\n            }\n        }\n\n        __m256i even_mask = _mm256_and_si256(palindromes, _mm256_set1_epi32(0));\n        __m256i odd_mask = _mm256_and_si256(palindromes, _mm256_set1_epi32(1));\n\n        even_count = _mm256_add_epi32(even_count, even_mask);\n        odd_count = _mm256_add_epi32(odd_count, odd_mask);\n    }\n\n    int even_result[8], odd_result[8];\n    _mm256_storeu_si256((__m256i*)even_result, even_count);\n    _mm256_storeu_si256((__m256i*)odd_result, odd_count);\n\n    int even_total = 0, odd_total = 0;\n    for (int i = 0; i < 8; i++) {\n        even_total += even_result[i];\n        odd_total += odd_result[i];\n    }\n\n    return {even_total, odd_total};\n}\n```"}
{"task_id": "SimdBench_113_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nbool is_palindrome(int num) {\n    int reversed = 0, original = num;\n    while (num > 0) {\n        reversed = reversed * 10 + num % 10;\n        num /= 10;\n    }\n    return original == reversed;\n}\n\nstd::vector<int> even_odd_palindrome_simd(int n) {\n    __m256i even_count = _mm256_setzero_si256();\n    __m256i odd_count = _mm256_setzero_si256();\n\n    for (int i = 1; i <= n; i += 8) {\n        __m256i indices = _mm256_set_epi32(i + 7, i + 6, i + 5, i + 4, i + 3, i + 2, i + 1, i);\n        __m256i palindromes = _mm256_setzero_si256();\n        \n        for (int j = 0; j < 8; ++j) {\n            int num = i + j;\n            if (is_palindrome(num)) {\n                palindromes = _mm256_insert_epi32(palindromes, num, j);\n            }\n        }\n\n        for (int j = 0; j < 8; ++j) {\n            int num = _mm256_extract_epi32(palindromes, j);\n            if (num != 0) {\n                if (num % 2 == 0) {\n                    even_count = _mm256_add_epi32(even_count, _mm256_set1_epi32(1));\n                } else {\n                    odd_count = _mm256_add_epi32(odd_count, _mm256_set1_epi32(1));\n                }\n            }\n        }\n    }\n\n    int even_result[8], odd_result[8];\n    _mm256_storeu_si256((__m256i*)even_result, even_count);\n    _mm256_storeu_si256((__m256i*)odd_result, odd_count);\n\n    int total_even = 0, total_odd = 0;\n    for (int i = 0; i < 8; i++) {\n        total_even += even_result[i];\n        total_odd += odd_result[i];\n    }\n\n    return {total_even, total_odd};\n}\n```"}
{"task_id": "SimdBench_113_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nbool is_palindrome(int num) {\n    int reversed = 0, original = num;\n    while (num > 0) {\n        reversed = reversed * 10 + num % 10;\n        num /= 10;\n    }\n    return original == reversed;\n}\n\nstd::vector<int> even_odd_palindrome_simd(int n) {\n    int even_count = 0, odd_count = 0;\n    __m256i even_mask = _mm256_set1_epi32(0);\n    __m256i odd_mask = _mm256_set1_epi32(0);\n    \n    for (int i = 1; i <= n; i += 8) {\n        __m256i indices = _mm256_set_epi32(i + 7, i + 6, i + 5, i + 4, i + 3, i + 2, i + 1, i);\n        __m256i palindromes = _mm256_setzero_si256();\n        \n        for (int j = 0; j < 8; j++) {\n            int num = i + j;\n            if (is_palindrome(num)) {\n                palindromes = _mm256_insert_epi32(palindromes, num, j);\n            }\n        }\n        \n        for (int j = 0; j < 8; j++) {\n            int num = _mm256_extract_epi32(palindromes, j);\n            if (num != 0) {\n                if (num % 2 == 0) {\n                    even_count++;\n                } else {\n                    odd_count++;\n                }\n            }\n        }\n    }\n    \n    return {even_count, odd_count};\n}\n```"}
{"task_id": "SimdBench_113_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nbool is_palindrome(int num) {\n    int reversed = 0, original = num;\n    while (num > 0) {\n        reversed = reversed * 10 + num % 10;\n        num /= 10;\n    }\n    return original == reversed;\n}\n\nstd::vector<int> even_odd_palindrome_simd(int n) {\n    __m256i even_count = _mm256_setzero_si256();\n    __m256i odd_count = _mm256_setzero_si256();\n\n    for (int i = 1; i <= n; i += 8) {\n        __m256i indices = _mm256_setr_epi32(i, i + 1, i + 2, i + 3, i + 4, i + 5, i + 6, i + 7);\n        __m256i palin_mask = _mm256_setzero_si256();\n\n        for (int j = 0; j < 8; ++j) {\n            if (i + j > n) break;\n            if (is_palindrome(i + j)) {\n                palin_mask = _mm256_insert_epi32(palin_mask, 1, j);\n            }\n        }\n\n        __m256i even_mask = _mm256_and_si256(palin_mask, _mm256_setr_epi32(0, 1, 0, 1, 0, 1, 0, 1));\n        __m256i odd_mask = _mm256_andnot_si256(even_mask, palin_mask);\n\n        even_count = _mm256_add_epi32(even_count, even_mask);\n        odd_count = _mm256_add_epi32(odd_count, odd_mask);\n    }\n\n    int even_result[8], odd_result[8];\n    _mm256_storeu_si256((__m256i*)even_result, even_count);\n    _mm256_storeu_si256((__m256i*)odd_result, odd_count);\n\n    int even_total = 0, odd_total = 0;\n    for (int i = 0; i < 8; ++i) {\n        even_total += even_result[i];\n        odd_total += odd_result[i];\n    }\n\n    return {even_total, odd_total};\n}\n```"}
{"task_id": "SimdBench_114_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nint count_nums_simd(std::vector<int> n) {\n    int count = 0;\n    size_t size = n.size();\n    size_t i = 0;\n\n    __m256i zero = _mm256_setzero_si256();\n    __m256i sum_mask = _mm256_set1_epi32(0);\n\n    for (; i + 8 <= size; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&n[i]);\n        __m256i abs_vec = _mm256_abs_epi32(vec);\n\n        __m256i sum_digits = _mm256_setzero_si256();\n        for (int j = 0; j < 10; j++) {\n            __m256i digit_mask = _mm256_set1_epi32(j);\n            __m256i is_digit = _mm256_cmpeq_epi32(_mm256_and_si256(abs_vec, _mm256_set1_epi32(0xF)), digit_mask);\n            sum_digits = _mm256_add_epi32(sum_digits, is_digit);\n            abs_vec = _mm256_srli_epi32(abs_vec, 4);\n        }\n\n        __m256i greater_than_zero = _mm256_cmpgt_epi32(sum_digits, zero);\n        count += _mm256_movemask_epi8(greater_than_zero);\n    }\n\n    for (; i < size; i++) {\n        int sum = 0;\n        int num = n[i];\n        while (num != 0) {\n            sum += std::abs(num % 10);\n            num /= 10;\n        }\n        if (sum > 0) count++;\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_114_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nint count_nums_simd(std::vector<int> n) {\n    int count = 0;\n    size_t size = n.size();\n    size_t i = 0;\n\n    __m256i zero = _mm256_setzero_si256();\n    __m256i sum_mask = _mm256_set1_epi32(0);\n\n    for (; i + 8 <= size; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&n[i]);\n        __m256i abs_vec = _mm256_abs_epi32(vec);\n        \n        __m256i sum_digits = _mm256_setzero_si256();\n        for (int j = 0; j < 32; j += 8) {\n            __m256i mask = _mm256_set1_epi32(0x0F);\n            __m256i digits = _mm256_and_si256(abs_vec, mask);\n            sum_digits = _mm256_add_epi32(sum_digits, digits);\n            abs_vec = _mm256_srli_epi32(abs_vec, 4);\n        }\n\n        __m256i greater_than_zero = _mm256_cmpgt_epi32(sum_digits, zero);\n        count += _mm256_movemask_epi8(greater_than_zero);\n    }\n\n    for (; i < size; i++) {\n        int sum = 0;\n        int num = n[i];\n        while (num != 0) {\n            sum += std::abs(num % 10);\n            num /= 10;\n        }\n        if (sum > 0) count++;\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_114_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nint count_nums_simd(std::vector<int> n) {\n    int count = 0;\n    size_t size = n.size();\n    size_t i = 0;\n\n    __m256i zero = _mm256_setzero_si256();\n    __m256i sum_mask = _mm256_set1_epi32(0);\n\n    for (; i + 8 <= size; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&n[i]);\n        __m256i abs_vec = _mm256_abs_epi32(vec);\n\n        // Sum the digits\n        __m256i sum_digits = _mm256_setzero_si256();\n        for (int j = 0; j < 10; j++) {\n            __m256i digit_mask = _mm256_set1_epi32(j);\n            __m256i is_digit = _mm256_cmpeq_epi32(_mm256_and_si256(abs_vec, _mm256_set1_epi32(0xF)), digit_mask);\n            sum_digits = _mm256_add_epi32(sum_digits, is_digit);\n            abs_vec = _mm256_srli_epi32(abs_vec, 4);\n        }\n\n        // Check if sum of digits > 0\n        __m256i is_positive = _mm256_cmpgt_epi32(sum_digits, zero);\n        count += _mm256_movemask_epi8(is_positive);\n    }\n\n    // Handle remaining elements\n    for (; i < size; i++) {\n        int num = n[i];\n        int sum = 0;\n        while (num != 0) {\n            sum += abs(num % 10);\n            num /= 10;\n        }\n        if (sum > 0) count++;\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_114_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nint count_nums_simd(std::vector<int> n) {\n    int count = 0;\n    size_t size = n.size();\n    size_t i = 0;\n\n    __m256i zero = _mm256_setzero_si256();\n    __m256i sum_mask = _mm256_set1_epi32(0);\n    \n    for (; i + 8 <= size; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&n[i]);\n        __m256i abs_vec = _mm256_abs_epi32(vec);\n        \n        __m256i digits_sum = _mm256_setzero_si256();\n        for (int j = 0; j < 10; j++) {\n            __m256i digit_mask = _mm256_set1_epi32(j);\n            __m256i is_digit = _mm256_cmpeq_epi32(_mm256_rem_epi32(abs_vec, digit_mask), zero);\n            digits_sum = _mm256_add_epi32(digits_sum, _mm256_and_si256(is_digit, digit_mask));\n            abs_vec = _mm256_div_epi32(abs_vec, _mm256_set1_epi32(10));\n        }\n\n        __m256i greater_than_zero = _mm256_cmpgt_epi32(digits_sum, zero);\n        count += _mm256_movemask_epi8(greater_than_zero);\n    }\n\n    for (; i < size; i++) {\n        int sum = 0;\n        int num = n[i];\n        while (num != 0) {\n            sum += std::abs(num % 10);\n            num /= 10;\n        }\n        if (sum > 0) count++;\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_114_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nint count_nums_simd(std::vector<int> n) {\n    int count = 0;\n    size_t size = n.size();\n    size_t i = 0;\n\n    __m256i zero = _mm256_setzero_si256();\n    __m256i sum_mask = _mm256_set1_epi32(0);\n\n    for (; i + 8 <= size; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&n[i]);\n        __m256i abs_vec = _mm256_abs_epi32(vec);\n\n        // Calculate sum of digits\n        __m256i sum_digits = _mm256_setzero_si256();\n        for (int j = 0; j < 10; j++) {\n            __m256i mod = _mm256_set1_epi32(10);\n            __m256i digit = _mm256_rem_epi32(abs_vec, mod);\n            sum_digits = _mm256_add_epi32(sum_digits, digit);\n            abs_vec = _mm256_div_epi32(abs_vec, mod);\n        }\n\n        // Compare sum of digits with zero\n        __m256i cmp = _mm256_cmpgt_epi32(sum_digits, zero);\n        count += _mm256_movemask_epi8(cmp);\n    }\n\n    // Handle remaining elements\n    for (; i < size; i++) {\n        int sum = 0, num = n[i];\n        while (num != 0) {\n            sum += abs(num % 10);\n            num /= 10;\n        }\n        if (sum > 0) count++;\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_115_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nbool move_one_ball_simd(std::vector<int> arr) {\n    int N = arr.size();\n    if (N == 0) return true;\n\n    // Load the array into AVX2 registers\n    __m256i max_val = _mm256_set1_epi32(arr[0]);\n    __m256i min_val = _mm256_set1_epi32(arr[0]);\n    \n    for (int i = 0; i < N; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&arr[i]);\n        max_val = _mm256_max_epi32(max_val, vec);\n        min_val = _mm256_min_epi32(min_val, vec);\n    }\n\n    // Check if the max and min values are in the correct order\n    int max = _mm256_extract_epi32(max_val, 0);\n    int min = _mm256_extract_epi32(min_val, 0);\n    \n    for (int i = 1; i < 8 && i < N; i++) {\n        max = std::max(max, _mm256_extract_epi32(max_val, i));\n        min = std::min(min, _mm256_extract_epi32(min_val, i));\n    }\n\n    // Check if the difference between max and min is less than N\n    return (max - min) < N;\n}\n```"}
{"task_id": "SimdBench_115_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nbool move_one_ball_simd(std::vector<int> arr) {\n    int N = arr.size();\n    if (N == 0) return true;\n\n    // Load the array into AVX2 registers\n    __m256i max_val = _mm256_set1_epi32(arr[0]);\n    __m256i min_val = _mm256_set1_epi32(arr[0]);\n    \n    for (int i = 0; i < N; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&arr[i]);\n        max_val = _mm256_max_epi32(max_val, vec);\n        min_val = _mm256_min_epi32(min_val, vec);\n    }\n\n    // Check if the max and min values are in the correct order\n    int max = _mm256_extract_epi32(max_val, 0);\n    int min = _mm256_extract_epi32(min_val, 0);\n    \n    for (int i = 1; i < 8 && i < N; i++) {\n        max = std::max(max, _mm256_extract_epi32(max_val, i));\n        min = std::min(min, _mm256_extract_epi32(min_val, i));\n    }\n\n    // Check if the array can be sorted by right shifts\n    return (max - min == N - 1);\n}\n```"}
{"task_id": "SimdBench_115_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nbool move_one_ball_simd(std::vector<int> arr) {\n    int N = arr.size();\n    if (N == 0) return true;\n\n    // Load the array into AVX2 registers\n    __m256i current, next;\n    bool is_sorted = true;\n\n    for (int i = 0; i < N; i += 8) {\n        current = _mm256_loadu_si256((__m256i*)&arr[i]);\n        next = _mm256_loadu_si256((__m256i*)&arr[(i + 1) % N]);\n\n        // Compare current and next elements\n        __m256i cmp = _mm256_cmpgt_epi32(current, next);\n        if (_mm256_movemask_epi8(cmp) != 0) {\n            is_sorted = false;\n            break;\n        }\n    }\n\n    return is_sorted;\n}\n```"}
{"task_id": "SimdBench_115_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nbool move_one_ball_simd(std::vector<int> arr) {\n    int N = arr.size();\n    if (N == 0) return true;\n\n    // Load the array into AVX2 registers\n    __m256i prev = _mm256_set1_epi32(arr[N - 1]);\n    __m256i curr;\n\n    for (int i = 0; i < N; i += 8) {\n        curr = _mm256_loadu_si256((__m256i*)&arr[i]);\n        \n        // Check if the current element is less than the previous element\n        __m256i cmp = _mm256_cmpgt_epi32(prev, curr);\n        int mask = _mm256_movemask_epi8(cmp);\n        \n        // If any element is greater than the previous one, we cannot sort\n        if (mask != 0) {\n            // Check if we have a wrap-around case\n            if (i + 8 < N) {\n                prev = curr;\n            } else {\n                // Check the last few elements\n                for (int j = i; j < N; ++j) {\n                    if (arr[j] < arr[j - 1]) {\n                        return false;\n                    }\n                }\n                return true;\n            }\n        } else {\n            prev = curr;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_115_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nbool move_one_ball_simd(std::vector<int> arr) {\n    int N = arr.size();\n    if (N == 0) return true;\n\n    // Load the array into AVX2 registers\n    __m256i max_val = _mm256_set1_epi32(arr[0]);\n    __m256i min_val = _mm256_set1_epi32(arr[0]);\n    \n    // Check for the maximum and minimum values in the array\n    for (int i = 0; i < N; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&arr[i]);\n        max_val = _mm256_max_epi32(max_val, vec);\n        min_val = _mm256_min_epi32(min_val, vec);\n    }\n\n    // Check if the sorted order can be achieved\n    int max = _mm256_extract_epi32(max_val, 0);\n    int min = _mm256_extract_epi32(min_val, 0);\n    \n    for (int i = 1; i < 8; i++) {\n        max = std::max(max, _mm256_extract_epi32(max_val, i));\n        min = std::min(min, _mm256_extract_epi32(min_val, i));\n    }\n\n    // Check if the difference between max and min is equal to N - 1\n    return (max - min == N - 1);\n}\n```"}
{"task_id": "SimdBench_116_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n#include <string>\n\nstd::string myexchange_simd(const std::vector<int>& lst1, const std::vector<int>& lst2) {\n    size_t n = lst1.size();\n    __m256i even_mask = _mm256_set1_epi32(1);\n    __m256i lst1_mask, lst2_mask;\n    int count_odd_lst1 = 0, count_even_lst2 = 0;\n\n    for (size_t i = 0; i < n; i += 8) {\n        lst1_mask = _mm256_loadu_si256((__m256i*)&lst1[i]);\n        lst2_mask = _mm256_loadu_si256((__m256i*)&lst2[i]);\n\n        __m256i odd_mask = _mm256_and_si256(lst1_mask, even_mask);\n        count_odd_lst1 += _mm256_movemask_epi8(odd_mask) ? 0 : 8;\n\n        odd_mask = _mm256_andnot_si256(even_mask, lst2_mask);\n        count_even_lst2 += _mm256_movemask_epi8(odd_mask) ? 0 : 8;\n    }\n\n    if (count_odd_lst1 <= count_even_lst2) {\n        return \"YES\";\n    } else {\n        return \"NO\";\n    }\n}\n```"}
{"task_id": "SimdBench_116_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n#include <string>\n\nstd::string myexchange_simd(const std::vector<int>& lst1, const std::vector<int>& lst2) {\n    size_t n = lst1.size();\n    __m256i even_mask = _mm256_set1_epi32(1);\n    __m256i lst1_mask = _mm256_set1_epi32(0);\n    __m256i lst2_mask = _mm256_set1_epi32(0);\n    \n    for (size_t i = 0; i < n; i += 8) {\n        __m256i vec1 = _mm256_loadu_si256((__m256i*)&lst1[i]);\n        __m256i vec2 = _mm256_loadu_si256((__m256i*)&lst2[i]);\n        \n        __m256i even_elements = _mm256_and_si256(vec1, even_mask);\n        __m256i odd_elements = _mm256_andnot_si256(even_mask, vec1);\n        \n        lst1_mask = _mm256_add_epi32(lst1_mask, _mm256_cmpeq_epi32(even_elements, _mm256_setzero_si256()));\n        lst2_mask = _mm256_add_epi32(lst2_mask, _mm256_cmpeq_epi32(odd_elements, _mm256_setzero_si256()));\n    }\n    \n    int lst1_even_count = _mm256_extract_epi32(lst1_mask, 0) + _mm256_extract_epi32(lst1_mask, 1) +\n                         _mm256_extract_epi32(lst1_mask, 2) + _mm256_extract_epi32(lst1_mask, 3) +\n                         _mm256_extract_epi32(lst1_mask, 4) + _mm256_extract_epi32(lst1_mask, 5) +\n                         _mm256_extract_epi32(lst1_mask, 6) + _mm256_extract_epi32(lst1_mask, 7);\n    \n    int lst2_odd_count = _mm256_extract_epi32(lst2_mask, 0) + _mm256_extract_epi32(lst2_mask, 1) +\n                        _mm256_extract_epi32(lst2_mask, 2) + _mm256_extract_epi32(lst2_mask, 3) +\n                        _mm256_extract_epi32(lst2_mask, 4) + _mm256_extract_epi32(lst2_mask, 5) +\n                        _mm256_extract_epi32(lst2_mask, 6) + _mm256_extract_epi32(lst2_mask, 7);\n    \n    if (lst1_even_count + lst2_odd_count >= n) {\n        return \"YES\";\n    } else {\n        return \"NO\";\n    }\n}\n```"}
{"task_id": "SimdBench_116_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n#include <string>\n\nstd::string myexchange_simd(const std::vector<int>& lst1, const std::vector<int>& lst2) {\n    size_t n = lst1.size();\n    __m256i even_mask = _mm256_set1_epi32(1);\n    __m256i lst1_vec, lst2_vec, lst1_even, lst2_even;\n    int lst1_odd_count = 0, lst2_even_count = 0;\n\n    for (size_t i = 0; i < n; i += 8) {\n        lst1_vec = _mm256_loadu_si256((__m256i*)&lst1[i]);\n        lst2_vec = _mm256_loadu_si256((__m256i*)&lst2[i]);\n\n        lst1_even = _mm256_and_si256(lst1_vec, even_mask);\n        lst1_odd_count += _mm256_movemask_epi8(_mm256_cmpeq_epi32(lst1_even, _mm256_setzero_si256()));\n\n        lst2_even = _mm256_and_si256(lst2_vec, even_mask);\n        lst2_even_count += _mm256_movemask_epi8(_mm256_cmpeq_epi32(lst2_even, _mm256_setzero_si256()));\n    }\n\n    if (lst1_odd_count <= lst2_even_count) {\n        return \"YES\";\n    } else {\n        return \"NO\";\n    }\n}\n```"}
{"task_id": "SimdBench_116_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n#include <string>\n\nstd::string myexchange_simd(const std::vector<int>& lst1, const std::vector<int>& lst2) {\n    size_t n = lst1.size();\n    __m256i even_mask = _mm256_set1_epi32(1);\n    __m256i lst1_mask, lst2_mask;\n    int even_count = 0, odd_count = 0;\n\n    for (size_t i = 0; i < n; i += 8) {\n        lst1_mask = _mm256_loadu_si256((__m256i*)&lst1[i]);\n        lst2_mask = _mm256_loadu_si256((__m256i*)&lst2[i]);\n\n        __m256i lst1_even = _mm256_and_si256(lst1_mask, even_mask);\n        __m256i lst1_odd = _mm256_xor_si256(lst1_mask, lst1_even);\n\n        __m256i lst2_even = _mm256_and_si256(lst2_mask, even_mask);\n        __m256i lst2_odd = _mm256_xor_si256(lst2_mask, lst2_even);\n\n        even_count += _mm256_movemask_epi8(lst1_even) != 0 ? 1 : 0;\n        odd_count += _mm256_movemask_epi8(lst1_odd) != 0 ? 1 : 0;\n    }\n\n    return (odd_count <= even_count) ? \"YES\" : \"NO\";\n}\n```"}
{"task_id": "SimdBench_116_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n#include <string>\n\nstd::string myexchange_simd(const std::vector<int>& lst1, const std::vector<int>& lst2) {\n    size_t n = lst1.size();\n    __m256i even_mask = _mm256_set1_epi32(1);\n    __m256i lst1_vec, lst2_vec, lst1_even, lst2_even;\n    int lst1_odd_count = 0, lst2_even_count = 0;\n\n    for (size_t i = 0; i < n; i += 8) {\n        lst1_vec = _mm256_loadu_si256((__m256i*)&lst1[i]);\n        lst2_vec = _mm256_loadu_si256((__m256i*)&lst2[i]);\n\n        lst1_even = _mm256_and_si256(lst1_vec, even_mask);\n        lst2_even = _mm256_and_si256(lst2_vec, even_mask);\n\n        lst1_odd_count += _mm256_movemask_epi8(_mm256_cmpeq_epi32(lst1_even, _mm256_setzero_si256()));\n        lst2_even_count += _mm256_movemask_epi8(_mm256_cmpeq_epi32(lst2_even, even_mask));\n    }\n\n    if (lst1_odd_count <= lst2_even_count) {\n        return \"YES\";\n    } else {\n        return \"NO\";\n    }\n}\n```"}
{"task_id": "SimdBench_117_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n#include <sstream>\n\nstd::vector<std::string> odd_count_simd(const std::vector<std::string> & lst) {\n    std::vector<std::string> result;\n    for (const auto& str : lst) {\n        int odd_count = 0;\n        size_t length = str.length();\n        size_t i = 0;\n\n        // Process 32 characters at a time\n        for (; i + 31 < length; i += 32) {\n            __m256i data = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(str.data() + i));\n            __m256i odd_mask = _mm256_set1_epi8(1); // Mask for odd digits\n            __m256i odd_digits = _mm256_and_si256(data, odd_mask);\n            odd_count += _mm_popcnt_u32(_mm256_movemask_epi8(odd_digits));\n        }\n\n        // Process remaining characters\n        for (; i < length; ++i) {\n            if ((str[i] - '0') % 2 != 0) {\n                odd_count++;\n            }\n        }\n\n        std::ostringstream oss;\n        oss << \"the number of odd elements \" << odd_count << \"n the str\" << odd_count << \"ng \" << odd_count << \" of the \" << odd_count << \"nput.\";\n        result.push_back(oss.str());\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_117_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n#include <sstream>\n\nstd::vector<std::string> odd_count_simd(const std::vector<std::string> & lst) {\n    std::vector<std::string> result;\n    for (const auto& str : lst) {\n        int odd_count = 0;\n        size_t len = str.length();\n        size_t i = 0;\n\n        // Process 32 bytes at a time\n        for (; i + 32 <= len; i += 32) {\n            __m256i data = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(str.c_str() + i));\n            __m256i odd_mask = _mm256_set1_epi8(1); // Mask for odd digits\n            __m256i digits = _mm256_sub_epi8(data, _mm256_set1_epi8('0')); // Convert chars to digits\n            __m256i odd_digits = _mm256_and_si256(digits, odd_mask); // Isolate odd digits\n            odd_count += _mm_popcnt_u32(_mm256_movemask_epi8(odd_digits));\n        }\n\n        // Process remaining characters\n        for (; i < len; ++i) {\n            if ((str[i] - '0') % 2 != 0) {\n                odd_count++;\n            }\n        }\n\n        std::ostringstream oss;\n        oss << \"the number of odd elements \" << odd_count << \"n the str\" << odd_count << \"ng \" << odd_count << \" of the \" << odd_count << \"nput.\";\n        result.push_back(oss.str());\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_117_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n#include <sstream>\n\nstd::vector<std::string> odd_count_simd(const std::vector<std::string> & lst) {\n    std::vector<std::string> result;\n    for (const auto& str : lst) {\n        int odd_count = 0;\n        size_t len = str.length();\n        size_t i = 0;\n\n        // Process 32 bytes at a time\n        for (; i + 32 <= len; i += 32) {\n            __m256i data = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(str.c_str() + i));\n            __m256i mask = _mm256_set1_epi8(1); // Mask for odd digits\n            __m256i odd_mask = _mm256_or_si256(\n                _mm256_cmpeq_epi8(data, _mm256_set1_epi8('1')),\n                _mm256_or_si256(\n                    _mm256_cmpeq_epi8(data, _mm256_set1_epi8('3')),\n                    _mm256_or_si256(\n                        _mm256_cmpeq_epi8(data, _mm256_set1_epi8('5')),\n                        _mm256_or_si256(\n                            _mm256_cmpeq_epi8(data, _mm256_set1_epi8('7')),\n                            _mm256_cmpeq_epi8(data, _mm256_set1_epi8('9'))\n                        )\n                    )\n                )\n            );\n\n            odd_count += _mm_popcnt_u32(_mm256_movemask_epi8(odd_mask));\n        }\n\n        // Process remaining characters\n        for (; i < len; ++i) {\n            if ((str[i] - '0') % 2 != 0) {\n                odd_count++;\n            }\n        }\n\n        std::ostringstream oss;\n        oss << \"the number of odd elements \" << odd_count << \"n the str\" << odd_count << \"ng \" << odd_count << \" of the \" << odd_count << \"nput.\";\n        result.push_back(oss.str());\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_117_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n#include <sstream>\n\nstd::vector<std::string> odd_count_simd(const std::vector<std::string> & lst) {\n    std::vector<std::string> result;\n    for (const auto& str : lst) {\n        int odd_count = 0;\n        size_t len = str.length();\n        size_t i = 0;\n\n        // Process 32 bytes at a time\n        __m256i odd_mask = _mm256_set1_epi8(0b01010101); // Mask for odd digits\n        __m256i odd_count_vec = _mm256_setzero_si256();\n\n        for (; i + 32 <= len; i += 32) {\n            __m256i data = _mm256_loadu_si256((__m256i*)&str[i]);\n            __m256i digits = _mm256_sub_epi8(data, _mm256_set1_epi8('0'));\n            __m256i is_odd = _mm256_and_si256(digits, odd_mask);\n            odd_count_vec = _mm256_add_epi8(odd_count_vec, is_odd);\n        }\n\n        // Horizontal sum of odd_count_vec\n        odd_count += _mm256_extract_epi8(odd_count_vec, 0);\n        odd_count += _mm256_extract_epi8(odd_count_vec, 1);\n        odd_count += _mm256_extract_epi8(odd_count_vec, 2);\n        odd_count += _mm256_extract_epi8(odd_count_vec, 3);\n        odd_count += _mm256_extract_epi8(odd_count_vec, 4);\n        odd_count += _mm256_extract_epi8(odd_count_vec, 5);\n        odd_count += _mm256_extract_epi8(odd_count_vec, 6);\n        odd_count += _mm256_extract_epi8(odd_count_vec, 7);\n        odd_count += _mm256_extract_epi8(odd_count_vec, 8);\n        odd_count += _mm256_extract_epi8(odd_count_vec, 9);\n        odd_count += _mm256_extract_epi8(odd_count_vec, 10);\n        odd_count += _mm256_extract_epi8(odd_count_vec, 11);\n        odd_count += _mm256_extract_epi8(odd_count_vec, 12);\n        odd_count += _mm256_extract_epi8(odd_count_vec, 13);\n        odd_count += _mm256_extract_epi8(odd_count_vec, 14);\n        odd_count += _mm256_extract_epi8(odd_count_vec, 15);\n\n        // Process remaining characters\n        for (; i < len; ++i) {\n            if ((str[i] - '0') % 2 != 0) {\n                odd_count++;\n            }\n        }\n\n        // Create the output string\n        std::ostringstream oss;\n        oss << \"the number of odd elements \" << odd_count << \"n the str\" << odd_count << \"ng \" << odd_count << \" of the \" << odd_count << \"nput.\";\n        result.push_back(oss.str());\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_117_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n#include <sstream>\n\nstd::vector<std::string> odd_count_simd(const std::vector<std::string> & lst) {\n    std::vector<std::string> result;\n    for (const auto& str : lst) {\n        int odd_count = 0;\n        size_t len = str.length();\n        size_t i = 0;\n\n        // Process 32 bytes at a time\n        for (; i + 32 <= len; i += 32) {\n            __m256i data = _mm256_loadu_si256((__m256i*)&str[i]);\n            __m256i odd_mask = _mm256_set1_epi8(1);\n            __m256i digits = _mm256_sub_epi8(data, _mm256_set1_epi8('0'));\n            __m256i is_odd = _mm256_and_si256(digits, odd_mask);\n            odd_count += _mm_popcnt_u32(_mm256_movemask_epi8(is_odd));\n        }\n\n        // Process remaining characters\n        for (; i < len; ++i) {\n            if ((str[i] - '0') % 2 != 0) {\n                odd_count++;\n            }\n        }\n\n        std::ostringstream oss;\n        oss << \"the number of odd elements \" << odd_count << \"n the str\" << odd_count << \"ng \" << odd_count << \" of the \" << odd_count << \"nput.\";\n        result.push_back(oss.str());\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_118_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n#include <cstdint>\n#include <limits>\n\nint64_t minSubArraySum_simd(const std::vector<int64_t>& nums) {\n    int64_t min_sum = std::numeric_limits<int64_t>::max();\n    size_t size = nums.size();\n    size_t i = 0;\n\n    __m256i current_sum = _mm256_setzero_si256();\n    __m256i min_sum_vec = _mm256_set1_epi64x(min_sum);\n\n    for (; i + 4 <= size; i += 4) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&nums[i]);\n        current_sum = _mm256_add_epi64(current_sum, vec);\n        min_sum_vec = _mm256_min_epi64(min_sum_vec, current_sum);\n    }\n\n    // Handle remaining elements\n    for (; i < size; ++i) {\n        current_sum = _mm256_add_epi64(current_sum, _mm256_set1_epi64x(nums[i]));\n        min_sum_vec = _mm256_min_epi64(min_sum_vec, current_sum);\n    }\n\n    int64_t result[4];\n    _mm256_storeu_si256((__m256i*)result, min_sum_vec);\n    for (int j = 0; j < 4; ++j) {\n        min_sum = std::min(min_sum, result[j]);\n    }\n\n    return min_sum;\n}\n```"}
{"task_id": "SimdBench_118_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n#include <cstdint>\n#include <limits>\n\nint64_t minSubArraySum_simd(const std::vector<int64_t>& nums) {\n    int64_t min_sum = std::numeric_limits<int64_t>::max();\n    size_t size = nums.size();\n    size_t i = 0;\n\n    __m256i current_sum = _mm256_setzero_si256();\n    __m256i min_sum_vec = _mm256_set1_epi64x(min_sum);\n    \n    for (; i + 4 <= size; i += 4) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&nums[i]);\n        current_sum = _mm256_add_epi64(current_sum, vec);\n        min_sum_vec = _mm256_min_epi64(min_sum_vec, current_sum);\n    }\n\n    for (; i < size; ++i) {\n        current_sum = _mm256_add_epi64(current_sum, _mm256_set1_epi64x(nums[i]));\n        min_sum_vec = _mm256_min_epi64(min_sum_vec, current_sum);\n    }\n\n    int64_t result[4];\n    _mm256_storeu_si256((__m256i*)result, min_sum_vec);\n    for (int j = 0; j < 4; ++j) {\n        min_sum = std::min(min_sum, result[j]);\n    }\n\n    return min_sum;\n}\n```"}
{"task_id": "SimdBench_118_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n#include <cstdint>\n#include <limits>\n\nint64_t minSubArraySum_simd(const std::vector<int64_t>& nums) {\n    int64_t min_sum = std::numeric_limits<int64_t>::max();\n    size_t n = nums.size();\n    size_t i = 0;\n\n    __m256i current_sum = _mm256_setzero_si256();\n    __m256i min_current_sum = _mm256_set1_epi64x(std::numeric_limits<int64_t>::max());\n\n    for (; i + 4 <= n; i += 4) {\n        __m256i vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&nums[i]));\n        current_sum = _mm256_add_epi64(current_sum, vec);\n        min_current_sum = _mm256_min_epi64(min_current_sum, current_sum);\n    }\n\n    for (; i < n; ++i) {\n        current_sum = _mm256_add_epi64(current_sum, _mm256_set1_epi64x(nums[i]));\n        min_sum = std::min(min_sum, current_sum[0]);\n    }\n\n    int64_t min_values[4];\n    _mm256_storeu_si256(reinterpret_cast<__m256i*>(min_values), min_current_sum);\n    for (int j = 0; j < 4; ++j) {\n        min_sum = std::min(min_sum, min_values[j]);\n    }\n\n    return min_sum;\n}\n```"}
{"task_id": "SimdBench_118_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n#include <cstdint>\n#include <limits>\n\nint64_t minSubArraySum_simd(const std::vector<int64_t>& nums) {\n    int64_t min_sum = std::numeric_limits<int64_t>::max();\n    size_t n = nums.size();\n    size_t i = 0;\n\n    __m256i current_sum = _mm256_setzero_si256();\n    __m256i min_current_sum = _mm256_set1_epi64x(std::numeric_limits<int64_t>::max());\n\n    for (; i + 4 <= n; i += 4) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&nums[i]);\n        current_sum = _mm256_add_epi64(current_sum, vec);\n        min_current_sum = _mm256_min_epi64(min_current_sum, current_sum);\n    }\n\n    for (; i < n; ++i) {\n        current_sum = _mm256_add_epi64(current_sum, _mm256_set1_epi64x(nums[i]));\n        min_sum = std::min(min_sum, current_sum[0]);\n    }\n\n    int64_t min_array[4];\n    _mm256_storeu_si256((__m256i*)min_array, min_current_sum);\n    for (int j = 0; j < 4; ++j) {\n        min_sum = std::min(min_sum, min_array[j]);\n    }\n\n    return min_sum;\n}\n```"}
{"task_id": "SimdBench_118_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n#include <cstdint>\n#include <limits>\n\nint64_t minSubArraySum_simd(const std::vector<int64_t>& nums) {\n    size_t n = nums.size();\n    if (n == 0) return 0;\n\n    __m256i min_sum = _mm256_set1_epi64x(std::numeric_limits<int64_t>::max());\n    __m256i current_sum = _mm256_setzero_si256();\n    \n    size_t i = 0;\n    for (; i + 4 <= n; i += 4) {\n        __m256i vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&nums[i]));\n        current_sum = _mm256_add_epi64(current_sum, vec);\n        min_sum = _mm256_min_epi64(min_sum, current_sum);\n    }\n\n    int64_t final_min = std::numeric_limits<int64_t>::max();\n    for (size_t j = 0; j < 4; ++j) {\n        if (i + j < n) {\n            current_sum = _mm256_add_epi64(current_sum, _mm256_set1_epi64x(nums[i + j]));\n            final_min = std::min(final_min, current_sum[0]);\n        }\n    }\n\n    int64_t result = std::numeric_limits<int64_t>::max();\n    for (int k = 0; k < 4; ++k) {\n        result = std::min(result, min_sum[k]);\n    }\n\n    return std::min(result, final_min);\n}\n```"}
{"task_id": "SimdBench_119_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nint max_fill_simd(const std::vector<std::vector<int>> &grid, int capacity) {\n    int total_buckets = 0;\n    int rows = grid.size();\n    int cols = grid[0].size();\n\n    for (int i = 0; i < rows; ++i) {\n        __m256i sum = _mm256_setzero_si256();\n        for (int j = 0; j < cols; j += 8) {\n            __m256i data = _mm256_loadu_si256((__m256i*)&grid[i][j]);\n            sum = _mm256_add_epi32(sum, data);\n        }\n        int water_units[8];\n        _mm256_storeu_si256((__m256i*)water_units, sum);\n        for (int k = 0; k < 8; ++k) {\n            total_buckets += (water_units[k] + capacity - 1) / capacity;\n        }\n    }\n    return total_buckets;\n}\n```"}
{"task_id": "SimdBench_119_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nint max_fill_simd(const std::vector<std::vector<int>> &grid, int capacity) {\n    int total_buckets = 0;\n    int rows = grid.size();\n    int cols = grid[0].size();\n\n    for (int i = 0; i < rows; ++i) {\n        __m256i sum = _mm256_setzero_si256();\n        for (int j = 0; j < cols; j += 8) {\n            __m256i data = _mm256_loadu_si256((__m256i*)&grid[i][j]);\n            sum = _mm256_add_epi32(sum, data);\n        }\n        int water_units[8];\n        _mm256_storeu_si256((__m256i*)water_units, sum);\n        for (int k = 0; k < 8; ++k) {\n            total_buckets += (water_units[k] + capacity - 1) / capacity;\n        }\n    }\n    return total_buckets;\n}\n```"}
{"task_id": "SimdBench_119_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nint max_fill_simd(const std::vector<std::vector<int>>& grid, int capacity) {\n    int total_buckets = 0;\n    int rows = grid.size();\n    int cols = grid[0].size();\n\n    for (int i = 0; i < rows; ++i) {\n        __m256i water_count = _mm256_setzero_si256();\n        for (int j = 0; j < cols; j += 8) {\n            __m256i current = _mm256_loadu_si256((__m256i*)&grid[i][j]);\n            water_count = _mm256_add_epi32(water_count, current);\n        }\n        \n        // Horizontal sum of water_count\n        int counts[8];\n        _mm256_storeu_si256((__m256i*)counts, water_count);\n        int total_water = counts[0] + counts[1] + counts[2] + counts[3] +\n                          counts[4] + counts[5] + counts[6] + counts[7];\n\n        total_buckets += (total_water + capacity - 1) / capacity; // Ceiling division\n    }\n\n    return total_buckets;\n}\n```"}
{"task_id": "SimdBench_119_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nint max_fill_simd(const std::vector<std::vector<int>> &grid, int capacity) {\n    int total_buckets = 0;\n    int rows = grid.size();\n    int cols = grid[0].size();\n\n    for (int i = 0; i < rows; ++i) {\n        __m256i sum = _mm256_setzero_si256();\n        for (int j = 0; j < cols; j += 8) {\n            __m256i data = _mm256_loadu_si256((__m256i*)&grid[i][j]);\n            sum = _mm256_add_epi32(sum, data);\n        }\n        int water_units[8];\n        _mm256_storeu_si256((__m256i*)water_units, sum);\n        for (int k = 0; k < 8; ++k) {\n            total_buckets += (water_units[k] + capacity - 1) / capacity;\n        }\n    }\n    return total_buckets;\n}\n```"}
{"task_id": "SimdBench_119_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nint max_fill_simd(const std::vector<std::vector<int>> &grid, int capacity) {\n    int total_buckets = 0;\n    int rows = grid.size();\n    int cols = grid[0].size();\n\n    for (int i = 0; i < rows; ++i) {\n        __m256i sum = _mm256_setzero_si256();\n        for (int j = 0; j < cols; j += 8) {\n            __m256i data = _mm256_loadu_si256((__m256i*)&grid[i][j]);\n            sum = _mm256_add_epi32(sum, data);\n        }\n        int water_units[8];\n        _mm256_storeu_si256((__m256i*)water_units, sum);\n        for (int k = 0; k < 8; ++k) {\n            total_buckets += (water_units[k] + capacity - 1) / capacity;\n        }\n    }\n    return total_buckets;\n}\n```"}
{"task_id": "SimdBench_120_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nint64_t solution_simd(const std::vector<int16_t>& lst) {\n    int64_t sum = 0;\n    size_t size = lst.size();\n    size_t i = 0;\n\n    __m256i total_sum = _mm256_setzero_si256();\n\n    for (; i + 16 <= size; i += 16) {\n        __m256i data = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&lst[i]));\n        __m256i even_positions = _mm256_set_epi32(0, data.m256i_i16[15], 0, data.m256i_i16[13], 0, data.m256i_i16[11], 0, data.m256i_i16[9]);\n        \n        __m256i odd_mask = _mm256_and_si256(even_positions, _mm256_set1_epi16(1));\n        __m256i odd_elements = _mm256_and_si256(even_positions, odd_mask);\n        \n        total_sum = _mm256_add_epi64(total_sum, _mm256_sad_epu8(odd_elements, _mm256_setzero_si256()));\n    }\n\n    for (; i < size; ++i) {\n        if (i % 2 == 0 && lst[i] % 2 != 0) {\n            sum += lst[i];\n        }\n    }\n\n    int64_t result[4];\n    _mm256_storeu_si256(reinterpret_cast<__m256i*>(result), total_sum);\n    for (int j = 0; j < 4; ++j) {\n        sum += result[j];\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_120_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint64_t solution_simd(const std::vector<int16_t>& lst) {\n    int64_t sum = 0;\n    size_t size = lst.size();\n    size_t i;\n\n    __m128i odd_mask = _mm_set1_epi16(1);\n    __m128i sum_vec = _mm_setzero_si128();\n\n    for (i = 0; i + 8 <= size; i += 8) {\n        __m128i vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&lst[i]));\n        __m128i even_pos_vec = _mm_and_si128(vec, _mm_set1_epi16(0xFFFF)); // Load all elements\n\n        // Create a mask for odd elements\n        __m128i odd_elements = _mm_and_si128(even_pos_vec, odd_mask);\n        __m128i even_pos_mask = _mm_set_epi16(0, 1, 0, 1, 0, 1, 0, 1); // Mask for even positions\n        __m128i filtered_odds = _mm_and_si128(odd_elements, even_pos_mask);\n\n        sum_vec = _mm_add_epi16(sum_vec, filtered_odds);\n    }\n\n    // Horizontal sum of the vector\n    sum_vec = _mm_hadd_epi16(sum_vec, sum_vec);\n    sum_vec = _mm_hadd_epi16(sum_vec, sum_vec);\n    \n    sum += _mm_extract_epi16(sum_vec, 0);\n    \n    // Handle remaining elements\n    for (; i < size; i++) {\n        if (i % 2 == 0 && lst[i] % 2 != 0) {\n            sum += lst[i];\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_120_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nint64_t solution_simd(const std::vector<int16_t>& lst) {\n    int64_t sum = 0;\n    size_t size = lst.size();\n    size_t i = 0;\n\n    __m128i odd_mask = _mm_set1_epi16(1);\n    __m128i sum_vec = _mm_setzero_si128();\n\n    for (; i + 8 <= size; i += 8) {\n        __m128i vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&lst[i]));\n        __m128i even_pos_vec = _mm_and_si128(vec, _mm_set1_epi16(0xFFFF)); // Load all elements\n\n        // Extract odd elements in even positions\n        __m128i odd_elements = _mm_and_si128(even_pos_vec, odd_mask);\n        __m128i odd_positions = _mm_and_si128(vec, _mm_set1_epi16(0x0001));\n\n        // Add only odd elements in even positions\n        sum_vec = _mm_add_epi16(sum_vec, _mm_and_si128(odd_elements, odd_positions));\n    }\n\n    // Horizontal sum of the vector\n    sum_vec = _mm_hadd_epi16(sum_vec, sum_vec);\n    sum_vec = _mm_hadd_epi16(sum_vec, sum_vec);\n    sum += _mm_cvtsi128_si32(sum_vec);\n\n    // Handle remaining elements\n    for (; i < size; i += 2) {\n        if (i < size && lst[i] % 2 != 0) {\n            sum += lst[i];\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_120_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nint64_t solution_simd(const std::vector<int16_t>& lst) {\n    int64_t sum = 0;\n    size_t size = lst.size();\n    size_t i;\n\n    __m128i odd_mask = _mm_set1_epi16(1);\n    __m128i sum_vec = _mm_setzero_si128();\n\n    for (i = 0; i < size / 8 * 8; i += 8) {\n        __m128i vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&lst[i]));\n        __m128i even_pos_vec = _mm_and_si128(vec, _mm_set1_epi16(0x0001)); // Mask to get odd elements\n        __m128i even_pos_mask = _mm_set_epi16(0, 0, 0, 0, 0, 0, 0, 1); // Mask for even positions\n\n        __m128i result = _mm_and_si128(even_pos_vec, even_pos_mask);\n        sum_vec = _mm_add_epi16(sum_vec, result);\n    }\n\n    // Horizontal sum of the vector\n    sum_vec = _mm_hadd_epi16(sum_vec, sum_vec);\n    sum_vec = _mm_hadd_epi16(sum_vec, sum_vec);\n    sum += _mm_extract_epi16(sum_vec, 0);\n\n    // Handle remaining elements\n    for (; i < size; ++i) {\n        if (i % 2 == 0 && lst[i] % 2 != 0) {\n            sum += lst[i];\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_120_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nint64_t solution_simd(const std::vector<int16_t>& lst) {\n    int64_t sum = 0;\n    size_t n = lst.size();\n    size_t i = 0;\n\n    __m128i odd_mask = _mm_set1_epi16(1);\n    __m128i zero = _mm_setzero_si128();\n\n    for (; i + 8 <= n; i += 8) {\n        __m128i vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&lst[i]));\n        __m128i even_pos_elements = _mm_and_si128(vec, _mm_set1_epi16(0xFFFF));\n        \n        // Check for odd elements\n        __m128i is_odd = _mm_and_si128(even_pos_elements, odd_mask);\n        \n        // Mask to keep only elements at even positions\n        __m128i even_pos_mask = _mm_set_epi16(0, 0, 0, 0, 0, 0, 0, 1);\n        __m128i masked_elements = _mm_and_si128(even_pos_elements, even_pos_mask);\n        \n        // Add odd elements from even positions\n        masked_elements = _mm_and_si128(masked_elements, is_odd);\n        \n        // Horizontal sum\n        sum += _mm_extract_epi16(masked_elements, 0);\n        sum += _mm_extract_epi16(masked_elements, 1);\n        sum += _mm_extract_epi16(masked_elements, 2);\n        sum += _mm_extract_epi16(masked_elements, 3);\n        sum += _mm_extract_epi16(masked_elements, 4);\n        sum += _mm_extract_epi16(masked_elements, 5);\n        sum += _mm_extract_epi16(masked_elements, 6);\n        sum += _mm_extract_epi16(masked_elements, 7);\n    }\n\n    // Handle remaining elements\n    for (; i < n; ++i) {\n        if (i % 2 == 0 && lst[i] % 2 != 0) {\n            sum += lst[i];\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_121_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nint add_elements_simd(std::vector<int> arr, int k) {\n    int sum = 0;\n    int i = 0;\n\n    // Process up to k elements in chunks of 8\n    for (; i <= k - 8; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&arr[i]);\n        // Create a mask for elements with at most two digits\n        __m256i mask = _mm256_cmpgt_epi32(vec, _mm256_set1_epi32(99));\n        // Set elements greater than 99 to 0\n        vec = _mm256_blendv_epi8(vec, _mm256_setzero_si256(), mask);\n        // Sum the elements\n        sum += _mm256_reduce_add_epi32(vec);\n    }\n\n    // Process remaining elements\n    for (; i < k; ++i) {\n        if (arr[i] <= 99) {\n            sum += arr[i];\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_121_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nint add_elements_simd(std::vector<int> arr, int k) {\n    int sum = 0;\n    int limit = std::min(k, static_cast<int>(arr.size()));\n    int i = 0;\n\n    // Process 8 elements at a time using AVX2\n    for (; i <= limit - 8; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&arr[i]);\n        __m256i mask = _mm256_cmpgt_epi32(vec, _mm256_set1_epi32(99)); // Elements greater than 99\n        __m256i filtered = _mm256_and_si256(vec, mask); // Zero out elements greater than 99\n        sum += _mm256_reduce_add_epi32(filtered); // Sum the elements\n    }\n\n    // Process remaining elements\n    for (; i < limit; ++i) {\n        if (arr[i] <= 99) {\n            sum += arr[i];\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_121_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nint add_elements_simd(std::vector<int> arr, int k) {\n    int sum = 0;\n    int limit = std::min(k, static_cast<int>(arr.size()));\n    int i = 0;\n\n    // Process 8 integers at a time using AVX2\n    for (; i <= limit - 8; i += 8) {\n        __m256i vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&arr[i]));\n        __m256i mask = _mm256_cmpgt_epi32(vec, _mm256_set1_epi32(99)); // mask for elements > 99\n        __m256i filtered = _mm256_and_si256(vec, mask);\n        __m256i sum_vec = _mm256_hadd_epi32(filtered, filtered);\n        sum_vec = _mm256_hadd_epi32(sum_vec, sum_vec);\n        sum += _mm256_extract_epi32(sum_vec, 0);\n    }\n\n    // Handle remaining elements\n    for (; i < limit; ++i) {\n        if (arr[i] <= 99) {\n            sum += arr[i];\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_121_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nint add_elements_simd(std::vector<int> arr, int k) {\n    int sum = 0;\n    int limit = std::min(k, static_cast<int>(arr.size()));\n    int i = 0;\n\n    // Process 8 integers at a time using AVX2\n    for (; i <= limit - 8; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&arr[i]);\n        __m256i mask = _mm256_cmpgt_epi32(vec, _mm256_set1_epi32(99)); // mask for elements > 99\n        __m256i filtered = _mm256_andnot_si256(mask, vec); // keep elements <= 99\n        sum += _mm256_reduce_add_epi32(filtered); // sum the elements\n    }\n\n    // Handle remaining elements\n    for (; i < limit; ++i) {\n        if (arr[i] <= 99) {\n            sum += arr[i];\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_121_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nint add_elements_simd(std::vector<int> arr, int k) {\n    int sum = 0;\n    int limit = std::min(k, static_cast<int>(arr.size()));\n    int i = 0;\n\n    // Process 8 integers at a time using AVX2\n    for (; i <= limit - 8; i += 8) {\n        __m256i vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&arr[i]));\n        __m256i mask = _mm256_cmpgt_epi32(vec, _mm256_set1_epi32(99)); // Mask for values > 99\n        __m256i filtered = _mm256_and_si256(vec, mask);\n        __m256i sum_vec = _mm256_hadd_epi32(filtered, filtered);\n        sum_vec = _mm256_hadd_epi32(sum_vec, sum_vec);\n        sum += _mm256_extract_epi32(sum_vec, 0);\n    }\n\n    // Process remaining elements\n    for (; i < limit; ++i) {\n        if (arr[i] <= 99) {\n            sum += arr[i];\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_122_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nbool is_sorted_simd(const std::vector<int> & lst) {\n    size_t n = lst.size();\n    if (n <= 1) return true;\n\n    __m256i prev = _mm256_set1_epi32(lst[0]);\n    for (size_t i = 1; i < n; i += 8) {\n        __m256i curr = _mm256_loadu_si256((__m256i*)&lst[i]);\n        __m256i cmp = _mm256_cmpgt_epi32(curr, prev);\n        if (_mm256_movemask_epi8(cmp) != 0xFFFF) return false;\n\n        __m256i dup_check = _mm256_cmpeq_epi32(curr, prev);\n        if (_mm256_movemask_epi8(dup_check) != 0) return false;\n\n        prev = curr;\n    }\n\n    // Handle remaining elements\n    for (size_t i = n - (n % 8); i < n; ++i) {\n        if (lst[i] < lst[i - 1] || lst[i] == lst[i - 1]) return false;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_122_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nbool is_sorted_simd(const std::vector<int> & lst) {\n    size_t n = lst.size();\n    if (n < 2) return true;\n\n    __m256i prev = _mm256_set1_epi32(lst[0]);\n    for (size_t i = 1; i < n; i += 8) {\n        __m256i curr = _mm256_loadu_si256((__m256i*)&lst[i]);\n        __m256i cmp = _mm256_cmpgt_epi32(curr, prev);\n        if (_mm256_movemask_epi8(cmp) != 0xFFFF) return false;\n\n        __m256i dup_check = _mm256_cmpeq_epi32(curr, prev);\n        if (_mm256_movemask_epi8(dup_check) != 0) return false;\n\n        prev = curr;\n    }\n\n    // Handle remaining elements\n    for (size_t i = n - (n % 8); i < n; ++i) {\n        if (lst[i] < lst[i - 1] || lst[i] == lst[i - 1]) return false;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_122_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nbool is_sorted_simd(const std::vector<int> & lst) {\n    size_t n = lst.size();\n    if (n < 2) return true;\n\n    __m256i prev = _mm256_set1_epi32(lst[0]);\n    for (size_t i = 1; i < n; i += 8) {\n        __m256i current = _mm256_loadu_si256((__m256i*)&lst[i]);\n        __m256i cmp = _mm256_cmpgt_epi32(current, prev);\n        if (_mm256_movemask_epi8(cmp) != 0xFFFF) return false;\n\n        __m256i dup_check = _mm256_cmpeq_epi32(current, prev);\n        if (_mm256_movemask_epi8(dup_check) != 0) return false;\n\n        prev = current;\n    }\n\n    // Handle remaining elements\n    for (size_t i = n - (n % 8); i < n; ++i) {\n        if (lst[i] < lst[i - 1] || lst[i] == lst[i - 1]) return false;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_122_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nbool is_sorted_simd(const std::vector<int> & lst) {\n    size_t n = lst.size();\n    if (n <= 1) return true;\n\n    __m256i prev = _mm256_set1_epi32(lst[0]);\n    for (size_t i = 1; i < n; i += 8) {\n        __m256i curr = _mm256_loadu_si256((__m256i*)&lst[i]);\n        __m256i cmp = _mm256_cmpgt_epi32(curr, prev);\n        if (_mm256_movemask_epi8(cmp) != 0xFFFF) return false;\n\n        __m256i dup_check = _mm256_cmpeq_epi32(curr, prev);\n        if (_mm256_movemask_epi8(dup_check) != 0) return false;\n\n        prev = curr;\n    }\n\n    for (size_t i = n - (n % 8); i < n; ++i) {\n        if (lst[i] < lst[i - 1] || lst[i] == lst[i - 1]) return false;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_122_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nbool is_sorted_simd(const std::vector<int> & lst) {\n    size_t n = lst.size();\n    if (n <= 1) return true;\n\n    __m256i prev = _mm256_set1_epi32(lst[0]);\n    for (size_t i = 1; i < n; i += 8) {\n        __m256i current = _mm256_loadu_si256((__m256i*)&lst[i]);\n        \n        // Check if current is less than or equal to previous\n        __m256i cmp = _mm256_cmpgt_epi32(current, prev);\n        int mask = _mm256_movemask_epi8(cmp);\n        if (mask != 0xFFFF) return false; // Found a non-ascending order\n        \n        // Check for duplicates\n        __m256i dup_check = _mm256_cmpeq_epi32(current, prev);\n        mask = _mm256_movemask_epi8(dup_check);\n        if (mask != 0) return false; // Found duplicates\n\n        prev = current;\n    }\n\n    // Handle remaining elements\n    for (size_t i = n - (n % 8); i < n; ++i) {\n        if (lst[i] < lst[i - 1] || lst[i] == lst[i - 1]) return false;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_123_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nint prod_signs_simd(const std::vector<int> & arr) {\n    if (arr.empty()) return -32768;\n\n    __m256i sum_magnitudes = _mm256_setzero_si256();\n    __m256i prod_signs = _mm256_set1_epi32(1);\n    const int size = arr.size();\n    int i = 0;\n\n    for (; i <= size - 8; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&arr[i]);\n        __m256i magnitudes = _mm256_abs_epi32(vec);\n        sum_magnitudes = _mm256_add_epi32(sum_magnitudes, magnitudes);\n\n        __m256i signs = _mm256_sign_epi32(vec, _mm256_set1_epi32(1));\n        prod_signs = _mm256_mullo_epi32(prod_signs, signs);\n    }\n\n    int sum = 0;\n    int prod = 1;\n    for (int j = 0; j < 8; ++j) {\n        int magnitude = _mm256_extract_epi32(sum_magnitudes, j);\n        sum += magnitude;\n\n        int sign = _mm256_extract_epi32(prod_signs, j);\n        if (sign > 0) prod *= 1;\n        else if (sign < 0) prod *= -1;\n    }\n\n    for (; i < size; ++i) {\n        int value = arr[i];\n        sum += abs(value);\n        if (value > 0) prod *= 1;\n        else if (value < 0) prod *= -1;\n    }\n\n    return sum * prod;\n}\n```"}
{"task_id": "SimdBench_123_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nint prod_signs_simd(const std::vector<int> & arr) {\n    if (arr.empty()) return -32768;\n\n    __m256i sum_magnitudes = _mm256_setzero_si256();\n    __m256i product_signs = _mm256_set1_epi32(1);\n    int n = arr.size();\n    int i = 0;\n\n    for (; i <= n - 8; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&arr[i]);\n        __m256i abs_vec = _mm256_abs_epi32(vec);\n        sum_magnitudes = _mm256_add_epi32(sum_magnitudes, abs_vec);\n\n        __m256i sign_mask = _mm256_cmpgt_epi32(vec, _mm256_setzero_si256());\n        __m256i neg_mask = _mm256_cmplt_epi32(vec, _mm256_setzero_si256());\n        product_signs = _mm256_mullo_epi32(product_signs, _mm256_blendv_epi8(\n            _mm256_set1_epi32(-1), _mm256_set1_epi32(1), sign_mask));\n        product_signs = _mm256_mullo_epi32(product_signs, _mm256_blendv_epi8(\n            _mm256_set1_epi32(0), _mm256_set1_epi32(1), _mm256_cmpeq_epi32(vec, _mm256_setzero_si256())));\n    }\n\n    // Handle remaining elements\n    for (; i < n; ++i) {\n        int val = arr[i];\n        sum_magnitudes = _mm256_add_epi32(sum_magnitudes, _mm256_set1_epi32(abs(val)));\n        if (val > 0) {\n            product_signs = _mm256_mullo_epi32(product_signs, _mm256_set1_epi32(1));\n        } else if (val < 0) {\n            product_signs = _mm256_mullo_epi32(product_signs, _mm256_set1_epi32(-1));\n        } else {\n            product_signs = _mm256_mullo_epi32(product_signs, _mm256_set1_epi32(0));\n        }\n    }\n\n    // Sum up the magnitudes\n    int32_t sum[8];\n    _mm256_storeu_si256((__m256i*)sum, sum_magnitudes);\n    int total_magnitude = sum[0] + sum[1] + sum[2] + sum[3] + sum[4] + sum[5] + sum[6] + sum[7];\n\n    // Calculate final result\n    int product_sign = 1;\n    _mm256_storeu_si256((__m256i*)sum, product_signs);\n    for (int j = 0; j < 8; ++j) {\n        product_sign *= sum[j];\n    }\n\n    return total_magnitude * product_sign;\n}\n```"}
{"task_id": "SimdBench_123_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nint prod_signs_simd(const std::vector<int> & arr) {\n    if (arr.empty()) return -32768;\n\n    __m256i sum_magnitudes = _mm256_setzero_si256();\n    __m256i product_signs = _mm256_set1_epi32(1);\n    int n = arr.size();\n    int i = 0;\n\n    for (; i <= n - 8; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&arr[i]);\n        __m256i abs_vec = _mm256_abs_epi32(vec);\n        sum_magnitudes = _mm256_add_epi32(sum_magnitudes, abs_vec);\n\n        __m256i sign_mask = _mm256_cmpgt_epi32(vec, _mm256_setzero_si256());\n        __m256i neg_mask = _mm256_cmpgt_epi32(_mm256_setzero_si256(), vec);\n        product_signs = _mm256_mullo_epi32(product_signs, _mm256_blendv_epi8(\n            _mm256_set1_epi32(-1), _mm256_set1_epi32(1), sign_mask));\n        product_signs = _mm256_mullo_epi32(product_signs, _mm256_blendv_epi8(\n            _mm256_set1_epi32(0), _mm256_set1_epi32(1), _mm256_cmpeq_epi32(vec, _mm256_setzero_si256())));\n    }\n\n    // Handle remaining elements\n    for (; i < n; ++i) {\n        int val = arr[i];\n        sum_magnitudes = _mm256_add_epi32(sum_magnitudes, _mm256_set1_epi32(abs(val)));\n        if (val > 0) {\n            product_signs = _mm256_mullo_epi32(product_signs, _mm256_set1_epi32(1));\n        } else if (val < 0) {\n            product_signs = _mm256_mullo_epi32(product_signs, _mm256_set1_epi32(-1));\n        }\n    }\n\n    int magnitudes[8];\n    _mm256_storeu_si256((__m256i*)magnitudes, sum_magnitudes);\n    int total_magnitude = magnitudes[0] + magnitudes[1] + magnitudes[2] + magnitudes[3] +\n                          magnitudes[4] + magnitudes[5] + magnitudes[6] + magnitudes[7];\n\n    int sign_product = _mm256_extract_epi32(product_signs, 0);\n    return total_magnitude * sign_product;\n}\n```"}
{"task_id": "SimdBench_123_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nint prod_signs_simd(const std::vector<int> & arr) {\n    if (arr.empty()) return -32768;\n\n    __m256i sum_magnitudes = _mm256_setzero_si256();\n    __m256i product_signs = _mm256_set1_epi32(1);\n    int n = arr.size();\n    int i;\n\n    for (i = 0; i <= n - 8; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&arr[i]);\n        __m256i abs_vec = _mm256_abs_epi32(vec);\n        sum_magnitudes = _mm256_add_epi32(sum_magnitudes, abs_vec);\n\n        __m256i sign_mask = _mm256_cmpgt_epi32(vec, _mm256_setzero_si256());\n        __m256i neg_mask = _mm256_cmpgt_epi32(_mm256_setzero_si256(), vec);\n        product_signs = _mm256_mullo_epi32(product_signs, _mm256_blendv_epi8(\n            _mm256_set1_epi32(-1), _mm256_set1_epi32(1), sign_mask));\n        product_signs = _mm256_mullo_epi32(product_signs, _mm256_blendv_epi8(\n            _mm256_set1_epi32(0), _mm256_set1_epi32(1), _mm256_cmpeq_epi32(vec, _mm256_setzero_si256())));\n    }\n\n    // Handle remaining elements\n    for (; i < n; ++i) {\n        int val = arr[i];\n        sum_magnitudes = _mm256_add_epi32(sum_magnitudes, _mm256_set1_epi32(abs(val)));\n        if (val > 0) {\n            product_signs = _mm256_mullo_epi32(product_signs, _mm256_set1_epi32(1));\n        } else if (val < 0) {\n            product_signs = _mm256_mullo_epi32(product_signs, _mm256_set1_epi32(-1));\n        } else {\n            product_signs = _mm256_setzero_si256();\n        }\n    }\n\n    // Sum up the magnitudes\n    int32_t sum[8];\n    _mm256_storeu_si256((__m256i*)sum, sum_magnitudes);\n    int total_magnitude = sum[0] + sum[1] + sum[2] + sum[3] + sum[4] + sum[5] + sum[6] + sum[7];\n\n    // Calculate final result\n    int sign_product = _mm256_extract_epi32(product_signs, 0);\n    return total_magnitude * sign_product;\n}\n```"}
{"task_id": "SimdBench_123_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nint prod_signs_simd(const std::vector<int> & arr) {\n    if (arr.empty()) return -32768;\n\n    __m256i sum_magnitudes = _mm256_setzero_si256();\n    __m256i product_signs = _mm256_set1_epi32(1);\n    const int n = arr.size();\n    int i = 0;\n\n    for (; i <= n - 8; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&arr[i]);\n        __m256i abs_vec = _mm256_abs_epi32(vec);\n        sum_magnitudes = _mm256_add_epi32(sum_magnitudes, abs_vec);\n\n        __m256i sign_mask = _mm256_cmpgt_epi32(vec, _mm256_setzero_si256());\n        __m256i neg_mask = _mm256_cmpgt_epi32(_mm256_setzero_si256(), vec);\n        product_signs = _mm256_mullo_epi32(product_signs, _mm256_blendv_epi8(\n            _mm256_set1_epi32(-1), _mm256_set1_epi32(1), sign_mask));\n        product_signs = _mm256_mullo_epi32(product_signs, _mm256_blendv_epi8(\n            _mm256_set1_epi32(0), _mm256_set1_epi32(1), neg_mask));\n    }\n\n    int sum[8];\n    _mm256_storeu_si256((__m256i*)sum, sum_magnitudes);\n    int total_sum = sum[0] + sum[1] + sum[2] + sum[3] + sum[4] + sum[5] + sum[6] + sum[7];\n\n    int product_signs_array[8];\n    _mm256_storeu_si256((__m256i*)product_signs_array, product_signs);\n    int total_product_signs = product_signs_array[0] + product_signs_array[1] + product_signs_array[2] + product_signs_array[3] + product_signs_array[4] + product_signs_array[5] + product_signs_array[6] + product_signs_array[7];\n\n    for (; i < n; ++i) {\n        total_sum += std::abs(arr[i]);\n        if (arr[i] > 0) {\n            total_product_signs *= 1;\n        } else if (arr[i] < 0) {\n            total_product_signs *= -1;\n        } else {\n            total_product_signs = 0;\n        }\n    }\n\n    return total_sum * total_product_signs;\n}\n```"}
{"task_id": "SimdBench_124_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<int> minPath_simd(const std::vector<std::vector<int>> &grid, int k) {\n    int N = grid.size();\n    std::vector<int> result(k);\n    std::vector<int> path(N * N);\n    \n    for (int i = 0; i < N; ++i) {\n        for (int j = 0; j < N; ++j) {\n            path[i * N + j] = grid[i][j];\n        }\n    }\n\n    __m256i min_path = _mm256_set1_epi32(INT32_MAX);\n    for (int start = 0; start < N * N; ++start) {\n        std::vector<int> current_path;\n        int x = start / N, y = start % N;\n        current_path.push_back(path[start]);\n\n        for (int step = 1; step < k; ++step) {\n            std::vector<int> candidates;\n            if (x > 0) candidates.push_back(path[(x - 1) * N + y]); // up\n            if (x < N - 1) candidates.push_back(path[(x + 1) * N + y]); // down\n            if (y > 0) candidates.push_back(path[x * N + (y - 1)]); // left\n            if (y < N - 1) candidates.push_back(path[x * N + (y + 1)]); // right\n\n            std::sort(candidates.begin(), candidates.end());\n            current_path.push_back(candidates[0]);\n            x = (candidates[0] - 1) / N;\n            y = (candidates[0] - 1) % N;\n        }\n\n        if (std::lexicographical_compare(current_path.begin(), current_path.end(), result.begin(), result.end())) {\n            result = current_path;\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_124_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<int> minPath_simd(const std::vector<std::vector<int>> &grid, int k) {\n    int N = grid.size();\n    std::vector<int> result(k);\n    std::vector<int> path(N * N);\n    \n    // Flatten the grid into a 1D array for easier processing\n    for (int i = 0; i < N; ++i) {\n        for (int j = 0; j < N; ++j) {\n            path[i * N + j] = grid[i][j];\n        }\n    }\n\n    // Initialize the minimum path with a large value\n    std::vector<int> minPath(k, INT_MAX);\n    \n    // AVX2 processing\n    for (int start = 0; start < N * N; ++start) {\n        std::vector<int> currentPath;\n        int x = start / N;\n        int y = start % N;\n\n        // Collect values for the path of length k\n        for (int step = 0; step < k; ++step) {\n            if (x < 0 || x >= N || y < 0 || y >= N) break;\n            currentPath.push_back(grid[x][y]);\n            // Move to the next cell (for simplicity, we can just go right)\n            y = (y + 1) % N; // wrap around for demonstration\n            if (y == 0) x++; // move to next row if we wrap around\n        }\n\n        // Compare with the current minimum path\n        if (currentPath.size() == k) {\n            if (std::lexicographical_compare(currentPath.begin(), currentPath.end(), minPath.begin(), minPath.end())) {\n                minPath = currentPath;\n            }\n        }\n    }\n\n    return minPath;\n}\n```"}
{"task_id": "SimdBench_124_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<int> minPath_simd(const std::vector<std::vector<int>> &grid, int k) {\n    int N = grid.size();\n    std::vector<int> result(k);\n    std::vector<int> path(N * N);\n    \n    // Flatten the grid into a single array\n    for (int i = 0; i < N; ++i) {\n        for (int j = 0; j < N; ++j) {\n            path[i * N + j] = grid[i][j];\n        }\n    }\n\n    // Initialize the minimum path with a large value\n    std::vector<int> minPath(k, INT_MAX);\n    \n    // SIMD processing\n    for (int start = 0; start < N * N; ++start) {\n        std::vector<int> currentPath;\n        int x = start / N;\n        int y = start % N;\n        \n        // Use a queue for BFS to explore paths\n        std::vector<std::pair<int, int>> queue;\n        queue.push_back({x, y});\n        \n        while (!queue.empty() && currentPath.size() < k) {\n            auto [cx, cy] = queue.back();\n            queue.pop_back();\n            currentPath.push_back(grid[cx][cy]);\n            \n            if (currentPath.size() == k) {\n                // Compare lexicographically\n                if (std::lexicographical_compare(currentPath.begin(), currentPath.end(), minPath.begin(), minPath.end())) {\n                    minPath = currentPath;\n                }\n                currentPath.pop_back();\n                continue;\n            }\n            \n            // Explore neighbors\n            if (cx > 0) queue.push_back({cx - 1, cy}); // Up\n            if (cx < N - 1) queue.push_back({cx + 1, cy}); // Down\n            if (cy > 0) queue.push_back({cx, cy - 1}); // Left\n            if (cy < N - 1) queue.push_back({cx, cy + 1}); // Right\n        }\n    }\n    \n    // Copy the result to the output vector\n    std::copy(minPath.begin(), minPath.end(), result.begin());\n    return result;\n}\n```"}
{"task_id": "SimdBench_124_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<int> minPath_simd(const std::vector<std::vector<int>> &grid, int k) {\n    int N = grid.size();\n    std::vector<int> result(k);\n    std::vector<int> path(N * N);\n    \n    // Flatten the grid into a 1D array\n    for (int i = 0; i < N; ++i) {\n        for (int j = 0; j < N; ++j) {\n            path[i * N + j] = grid[i][j];\n        }\n    }\n\n    // Initialize the result with the first k elements\n    for (int i = 0; i < k; ++i) {\n        result[i] = path[i];\n    }\n\n    // Use AVX2 to find the minimum path\n    for (int i = 0; i < N * N; i += 8) {\n        __m256i current = _mm256_loadu_si256((__m256i*)&path[i]);\n        for (int j = 0; j < k; ++j) {\n            __m256i min_val = _mm256_min_epi32(current, _mm256_set1_epi32(result[j]));\n            _mm256_storeu_si256((__m256i*)&result[j], min_val);\n        }\n    }\n\n    // Sort the result to ensure lexicographical order\n    std::sort(result.begin(), result.end());\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_124_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<int> minPath_simd(const std::vector<std::vector<int>> &grid, int k) {\n    int N = grid.size();\n    std::vector<int> result(k);\n    std::vector<int> path(N * N);\n    \n    // Flatten the grid into a 1D array\n    for (int i = 0; i < N; ++i) {\n        for (int j = 0; j < N; ++j) {\n            path[i * N + j] = grid[i][j];\n        }\n    }\n\n    // Initialize the minimum path with a large value\n    std::vector<int> minPath(k, INT_MAX);\n    \n    // SIMD processing\n    for (int start = 0; start < N * N; ++start) {\n        std::vector<int> currentPath;\n        int x = start / N;\n        int y = start % N;\n\n        // Use a queue for BFS\n        std::vector<std::pair<int, int>> queue;\n        queue.push_back({x, y});\n        \n        while (!queue.empty() && currentPath.size() < k) {\n            auto [cx, cy] = queue.back();\n            queue.pop_back();\n            currentPath.push_back(grid[cx][cy]);\n\n            if (currentPath.size() == k) {\n                // Compare lexicographically\n                if (std::lexicographical_compare(currentPath.begin(), currentPath.end(), minPath.begin(), minPath.end())) {\n                    minPath = currentPath;\n                }\n                currentPath.pop_back();\n                continue;\n            }\n\n            // Explore neighbors\n            for (int dx = -1; dx <= 1; ++dx) {\n                for (int dy = -1; dy <= 1; ++dy) {\n                    if (abs(dx) + abs(dy) == 1) { // Only orthogonal moves\n                        int nx = cx + dx;\n                        int ny = cy + dy;\n                        if (nx >= 0 && nx < N && ny >= 0 && ny < N) {\n                            queue.push_back({nx, ny});\n                        }\n                    }\n                }\n            }\n            currentPath.pop_back();\n        }\n    }\n\n    // Copy the result\n    std::copy(minPath.begin(), minPath.end(), result.begin());\n    return result;\n}\n```"}
{"task_id": "SimdBench_125_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nuint64_t digits_simd(uint64_t n) {\n    __m256i odd_mask = _mm256_set1_epi8(0x01);\n    __m256i product = _mm256_set1_epi8(1);\n    __m256i zero = _mm256_set1_epi8(0);\n    __m256i result = zero;\n\n    uint8_t digits[32];\n    int i = 0;\n\n    while (n > 0) {\n        digits[i++] = n % 10;\n        n /= 10;\n    }\n\n    for (; i < 32; i++) {\n        digits[i] = 0;\n    }\n\n    __m256i vec = _mm256_loadu_si256((__m256i*)digits);\n\n    vec = _mm256_and_si256(vec, _mm256_set1_epi8(0x0F)); // Mask to get only odd digits\n    __m256i odd_digits = _mm256_and_si256(vec, odd_mask);\n\n    for (int j = 0; j < 32; j += 32) {\n        __m256i temp = _mm256_loadu_si256((__m256i*)&digits[j]);\n        __m256i odd_check = _mm256_and_si256(temp, odd_mask);\n        __m256i is_odd = _mm256_cmpeq_epi8(odd_check, odd_mask);\n\n        product = _mm256_blendv_epi8(product, temp, is_odd);\n    }\n\n    for (int j = 0; j < 32; j++) {\n        if (digits[j] % 2 != 0) {\n            result = _mm256_mullo_epi8(result, _mm256_set1_epi8(digits[j]));\n        }\n    }\n\n    return _mm256_extract_epi64(result, 0);\n}\n```"}
{"task_id": "SimdBench_125_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nuint64_t digits_simd(uint64_t n) {\n    __m256i product = _mm256_set1_epi64x(1);\n    __m256i zero = _mm256_set1_epi64x(0);\n    __m256i odd_mask = _mm256_set1_epi64x(0xAAAAAAAAAAAAAAAA); // Mask for odd digits\n    __m256i even_mask = _mm256_set1_epi64x(0x5555555555555555); // Mask for even digits\n\n    uint64_t digits[10];\n    int count = 0;\n\n    while (n > 0) {\n        digits[count++] = n % 10;\n        n /= 10;\n    }\n\n    for (int i = 0; i < count; i += 4) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&digits[i]);\n        __m256i odd_digits = _mm256_and_si256(vec, odd_mask);\n        __m256i even_digits = _mm256_and_si256(vec, even_mask);\n        \n        // Replace even digits with 1 (neutral for multiplication)\n        odd_digits = _mm256_blendv_epi8(odd_digits, _mm256_set1_epi64x(1), even_digits);\n        \n        product = _mm256_mullo_epi64(product, odd_digits);\n    }\n\n    // Reduce the product\n    uint64_t result[4];\n    _mm256_storeu_si256((__m256i*)result, product);\n    \n    uint64_t final_product = 1;\n    for (int i = 0; i < 4; i++) {\n        final_product *= result[i];\n    }\n\n    return (final_product == 1) ? 0 : final_product;\n}\n```"}
{"task_id": "SimdBench_125_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nuint64_t digits_simd(uint64_t n) {\n    __m256i odd_mask = _mm256_set1_epi8(0x01);\n    __m256i product = _mm256_set1_epi8(1);\n    __m256i zero = _mm256_set1_epi8(0);\n    __m256i result = zero;\n\n    uint8_t digits[32];\n    int count = 0;\n\n    while (n > 0) {\n        digits[count++] = n % 10;\n        n /= 10;\n    }\n\n    for (int i = 0; i < count; i += 32) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&digits[i]);\n        __m256i odd_digits = _mm256_and_si256(vec, odd_mask);\n        __m256i is_non_zero = _mm256_cmpgt_epi8(odd_digits, zero);\n        __m256i product_masked = _mm256_blendv_epi8(zero, odd_digits, is_non_zero);\n        product = _mm256_mullo_epi8(product, product_masked);\n    }\n\n    for (int i = 0; i < 32; i++) {\n        if (digits[i] % 2 != 0) {\n            result = _mm256_mullo_epi8(result, _mm256_set1_epi8(digits[i]));\n        }\n    }\n\n    uint64_t final_product = 1;\n    for (int i = 0; i < 32; i++) {\n        if (digits[i] % 2 != 0) {\n            final_product *= digits[i];\n        }\n    }\n\n    return final_product == 1 ? 0 : final_product;\n}\n```"}
{"task_id": "SimdBench_125_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nuint64_t digits_simd(uint64_t n) {\n    __m256i odd_mask = _mm256_set1_epi8(0x01);\n    __m256i product = _mm256_set1_epi8(1);\n    __m256i zero = _mm256_set1_epi8(0);\n    __m256i all_even = _mm256_set1_epi8(1);\n    \n    uint8_t digits[32];\n    int count = 0;\n\n    while (n > 0) {\n        digits[count++] = n % 10;\n        n /= 10;\n    }\n\n    __m256i vec_digits = _mm256_loadu_si256((__m256i*)digits);\n    vec_digits = _mm256_and_si256(vec_digits, _mm256_set1_epi8(0x0F)); // Mask to get only odd digits\n\n    for (int i = 0; i < count; i += 32) {\n        __m256i current = _mm256_loadu_si256((__m256i*)&digits[i]);\n        __m256i odd_digits = _mm256_and_si256(current, odd_mask);\n        __m256i is_odd = _mm256_cmpgt_epi8(odd_digits, zero);\n        \n        // Multiply odd digits\n        product = _mm256_mullo_epi8(product, odd_digits);\n        \n        // Check if all are even\n        all_even = _mm256_and_si256(all_even, _mm256_cmpeq_epi8(is_odd, zero));\n    }\n\n    // Check if product is zero (meaning all were even)\n    uint8_t result[32];\n    _mm256_storeu_si256((__m256i*)result, product);\n    \n    uint64_t final_product = 1;\n    for (int i = 0; i < 32; i++) {\n        if (result[i] != 0) {\n            final_product *= result[i];\n        }\n    }\n\n    return (all_even[0] == 1) ? 0 : final_product;\n}\n```"}
{"task_id": "SimdBench_125_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nuint64_t digits_simd(uint64_t n) {\n    __m256i odd_mask = _mm256_set1_epi8(0x01);\n    __m256i product = _mm256_set1_epi8(1);\n    __m256i zero = _mm256_set1_epi8(0);\n    __m256i result = zero;\n\n    uint8_t digits[32];\n    int count = 0;\n\n    while (n > 0) {\n        digits[count++] = n % 10;\n        n /= 10;\n    }\n\n    for (int i = 0; i < count; i += 32) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&digits[i]);\n        __m256i odd_digits = _mm256_and_si256(vec, odd_mask);\n        __m256i is_odd = _mm256_cmpgt_epi8(odd_digits, zero);\n        __m256i product_temp = _mm256_blendv_epi8(zero, odd_digits, is_odd);\n\n        product = _mm256_mullo_epi8(product, product_temp);\n    }\n\n    for (int i = 0; i < 32; i++) {\n        result = _mm256_add_epi8(result, _mm256_extract_epi8(product, i));\n    }\n\n    return _mm256_extract_epi8(result, 0) == 0 ? 0 : _mm256_extract_epi8(result, 0);\n}\n```"}
{"task_id": "SimdBench_126_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n#include <cmath>\n#include <cstdint>\n\nuint64_t sum_squares_simd(const std::vector<float> & lst) {\n    size_t n = lst.size();\n    size_t i = 0;\n    __m256 sum_vec = _mm256_setzero_ps();\n\n    for (; i + 8 <= n; i += 8) {\n        __m256 vec = _mm256_loadu_ps(&lst[i]);\n        vec = _mm256_ceil_ps(vec);\n        sum_vec = _mm256_add_ps(sum_vec, _mm256_mul_ps(vec, vec));\n    }\n\n    float sum_array[8];\n    _mm256_storeu_ps(sum_array, sum_vec);\n\n    uint64_t sum = 0;\n    for (size_t j = 0; j < 8; j++) {\n        sum += static_cast<uint64_t>(sum_array[j]);\n    }\n\n    for (; i < n; i++) {\n        sum += static_cast<uint64_t>(std::ceil(lst[i]) * std::ceil(lst[i]));\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_126_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n#include <cmath>\n#include <cstdint>\n\nuint64_t sum_squares_simd(const std::vector<float> & lst) {\n    size_t n = lst.size();\n    size_t i = 0;\n    __m256 sum_vec = _mm256_setzero_ps();\n\n    for (; i + 8 <= n; i += 8) {\n        __m256 vec = _mm256_loadu_ps(&lst[i]);\n        vec = _mm256_ceil_ps(vec);\n        sum_vec = _mm256_add_ps(sum_vec, _mm256_mul_ps(vec, vec));\n    }\n\n    float sum_array[8];\n    _mm256_storeu_ps(sum_array, sum_vec);\n\n    uint64_t sum = 0;\n    for (size_t j = 0; j < 8; j++) {\n        sum += static_cast<uint64_t>(sum_array[j]);\n    }\n\n    for (; i < n; i++) {\n        sum += static_cast<uint64_t>(std::ceil(lst[i]) * std::ceil(lst[i]));\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_126_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n#include <cmath>\n#include <cstdint>\n\nuint64_t sum_squares_simd(const std::vector<float> & lst) {\n    size_t n = lst.size();\n    size_t i = 0;\n    __m256 sum_vec = _mm256_setzero_ps();\n\n    for (; i + 8 <= n; i += 8) {\n        __m256 vec = _mm256_loadu_ps(&lst[i]);\n        vec = _mm256_ceil_ps(vec);\n        sum_vec = _mm256_add_ps(sum_vec, _mm256_mul_ps(vec, vec));\n    }\n\n    float sum_array[8];\n    _mm256_storeu_ps(sum_array, sum_vec);\n\n    uint64_t sum = 0;\n    for (size_t j = 0; j < 8; ++j) {\n        sum += static_cast<uint64_t>(sum_array[j]);\n    }\n\n    for (; i < n; ++i) {\n        sum += static_cast<uint64_t>(std::ceil(lst[i]) * std::ceil(lst[i]));\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_126_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n#include <cmath>\n#include <cstdint>\n\nuint64_t sum_squares_simd(const std::vector<float> & lst) {\n    size_t n = lst.size();\n    size_t i = 0;\n    __m256 sum_vec = _mm256_setzero_ps();\n\n    for (; i + 8 <= n; i += 8) {\n        __m256 vec = _mm256_loadu_ps(&lst[i]);\n        vec = _mm256_ceil_ps(vec);\n        sum_vec = _mm256_add_ps(sum_vec, _mm256_mul_ps(vec, vec));\n    }\n\n    float sum_array[8];\n    _mm256_storeu_ps(sum_array, sum_vec);\n\n    uint64_t sum = 0;\n    for (size_t j = 0; j < 8; j++) {\n        sum += static_cast<uint64_t>(sum_array[j]);\n    }\n\n    for (; i < n; i++) {\n        sum += static_cast<uint64_t>(std::ceil(lst[i]) * std::ceil(lst[i]));\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_126_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n#include <cmath>\n#include <cstdint>\n\nuint64_t sum_squares_simd(const std::vector<float> & lst) {\n    size_t n = lst.size();\n    size_t i = 0;\n    __m256 sum_vec = _mm256_setzero_ps();\n\n    for (; i + 8 <= n; i += 8) {\n        __m256 vec = _mm256_loadu_ps(&lst[i]);\n        vec = _mm256_ceil_ps(vec);\n        sum_vec = _mm256_add_ps(sum_vec, _mm256_mul_ps(vec, vec));\n    }\n\n    float sum_array[8];\n    _mm256_storeu_ps(sum_array, sum_vec);\n\n    uint64_t sum = 0;\n    for (size_t j = 0; j < 8; j++) {\n        sum += static_cast<uint64_t>(sum_array[j]);\n    }\n\n    for (; i < n; i++) {\n        sum += static_cast<uint64_t>(std::ceil(lst[i]) * std::ceil(lst[i]));\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_127_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nint can_arrange_simd(const std::vector<int> & arr) {\n    int n = arr.size();\n    if (n < 2) return -1;\n\n    __m256i prev, curr;\n    int result = -1;\n\n    for (int i = 0; i < n - 1; i += 8) {\n        prev = _mm256_loadu_si256((__m256i*)&arr[i]);\n        curr = _mm256_loadu_si256((__m256i*)&arr[i + 1]);\n\n        __m256i cmp = _mm256_cmpgt_epi32(prev, curr);\n        int mask = _mm256_movemask_epi8(cmp);\n\n        if (mask) {\n            for (int j = 0; j < 8; ++j) {\n                if (mask & (1 << (j * 2))) {\n                    result = i + j + 1;\n                }\n            }\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_127_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nint can_arrange_simd(const std::vector<int> & arr) {\n    int n = arr.size();\n    if (n < 2) return -1;\n\n    __m256i prev, curr;\n    int index = -1;\n\n    for (int i = 0; i < n - 1; i += 8) {\n        prev = _mm256_loadu_si256((__m256i*)&arr[i]);\n        curr = _mm256_loadu_si256((__m256i*)&arr[i + 1]);\n\n        __m256i cmp = _mm256_cmpgt_epi32(prev, curr);\n        int mask = _mm256_movemask_epi8(cmp);\n\n        if (mask) {\n            for (int j = 0; j < 8; j++) {\n                if (mask & (1 << (j * 2))) {\n                    index = i + j;\n                }\n            }\n        }\n    }\n\n    for (int i = n - 1; i >= n - 8 && i > 0; --i) {\n        if (arr[i] < arr[i - 1]) {\n            index = i;\n            break;\n        }\n    }\n\n    return index;\n}\n```"}
{"task_id": "SimdBench_127_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nint can_arrange_simd(const std::vector<int> & arr) {\n    int n = arr.size();\n    if (n < 2) return -1;\n\n    __m256i max_index = _mm256_set1_epi32(-1);\n    __m256i prev = _mm256_set1_epi32(arr[0]);\n    \n    for (int i = 1; i < n; i += 8) {\n        __m256i current = _mm256_loadu_si256((__m256i*)&arr[i]);\n        __m256i cmp = _mm256_cmpgt_epi32(prev, current);\n        int mask = _mm256_movemask_epi8(cmp);\n        \n        if (mask) {\n            int index = i + __builtin_ctz(mask) / 4; // Find the first set bit\n            max_index = _mm256_max_epi32(max_index, _mm256_set1_epi32(index));\n        }\n        \n        prev = current;\n    }\n\n    int result = -1;\n    int indices[8];\n    _mm256_storeu_si256((__m256i*)indices, max_index);\n    \n    for (int i = 0; i < 8; i++) {\n        if (indices[i] != -1) {\n            result = std::max(result, indices[i]);\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_127_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nint can_arrange_simd(const std::vector<int> & arr) {\n    int n = arr.size();\n    if (n < 2) return -1;\n\n    __m256i prev, curr;\n    int result = -1;\n\n    for (int i = 1; i < n; i += 8) {\n        prev = _mm256_loadu_si256((__m256i*)&arr[i - 1]);\n        curr = _mm256_loadu_si256((__m256i*)&arr[i]);\n\n        __m256i cmp = _mm256_cmpgt_epi32(prev, curr);\n        int mask = _mm256_movemask_epi8(cmp);\n\n        if (mask) {\n            for (int j = 0; j < 8; j++) {\n                if (mask & (1 << (j * 2))) {\n                    result = i + j - 1;\n                }\n            }\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_127_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nint can_arrange_simd(const std::vector<int> & arr) {\n    int n = arr.size();\n    if (n < 2) return -1;\n\n    __m256i max_index = _mm256_set1_epi32(-1);\n    __m256i prev = _mm256_set1_epi32(arr[0]);\n\n    for (int i = 1; i < n; i += 8) {\n        __m256i current = _mm256_loadu_si256((__m256i*)&arr[i]);\n        __m256i cmp = _mm256_cmpgt_epi32(prev, current);\n        int mask = _mm256_movemask_epi8(cmp);\n\n        if (mask) {\n            int idx = __builtin_ctz(mask) / 4; // Get the first index where condition is true\n            max_index = _mm256_max_epi32(max_index, _mm256_set1_epi32(i + idx - 1));\n        }\n\n        prev = current;\n    }\n\n    int result = _mm256_extract_epi32(max_index, 0);\n    for (int i = 1; i < 8; ++i) {\n        result = std::max(result, _mm256_extract_epi32(max_index, i));\n    }\n\n    return result == -1 ? -1 : result;\n}\n```"}
{"task_id": "SimdBench_128_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nstd::vector<int> largest_smallest_integers_simd(const std::vector<int>& lst) {\n    __m256i max_neg = _mm256_set1_epi32(INT32_MIN);\n    __m256i min_pos = _mm256_set1_epi32(INT32_MAX);\n    int size = lst.size();\n    \n    for (int i = 0; i < size; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&lst[i]);\n        \n        __m256i mask_neg = _mm256_cmpgt_epi32(_mm256_setzero_si256(), vec);\n        __m256i mask_pos = _mm256_cmpgt_epi32(vec, _mm256_setzero_si256());\n        \n        max_neg = _mm256_max_epi32(max_neg, _mm256_and_si256(vec, mask_neg));\n        min_pos = _mm256_min_epi32(min_pos, _mm256_and_si256(vec, mask_pos));\n    }\n\n    int max_neg_arr[8], min_pos_arr[8];\n    _mm256_storeu_si256((__m256i*)max_neg_arr, max_neg);\n    _mm256_storeu_si256((__m256i*)min_pos_arr, min_pos);\n    \n    int largest_neg = INT32_MIN;\n    for (int i = 0; i < 8; ++i) {\n        if (max_neg_arr[i] > largest_neg) {\n            largest_neg = max_neg_arr[i];\n        }\n    }\n    \n    int smallest_pos = INT32_MAX;\n    for (int i = 0; i < 8; ++i) {\n        if (min_pos_arr[i] < smallest_pos) {\n            smallest_pos = min_pos_arr[i];\n        }\n    }\n    \n    if (largest_neg == INT32_MIN) largest_neg = 0;\n    if (smallest_pos == INT32_MAX) smallest_pos = 0;\n\n    return {largest_neg, smallest_pos};\n}\n```"}
{"task_id": "SimdBench_128_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n#include <limits>\n\nstd::vector<int> largest_smallest_integers_simd(const std::vector<int>& lst) {\n    __m256i max_neg = _mm256_set1_epi32(std::numeric_limits<int>::min());\n    __m256i min_pos = _mm256_set1_epi32(std::numeric_limits<int>::max());\n    int size = lst.size();\n    \n    for (int i = 0; i < size; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&lst[i]);\n        \n        __m256i mask_neg = _mm256_cmpgt_epi32(_mm256_setzero_si256(), vec);\n        __m256i mask_pos = _mm256_cmpgt_epi32(vec, _mm256_setzero_si256());\n        \n        __m256i neg_vals = _mm256_blendv_epi8(max_neg, vec, mask_neg);\n        __m256i pos_vals = _mm256_blendv_epi8(min_pos, vec, mask_pos);\n        \n        max_neg = _mm256_max_epi32(max_neg, neg_vals);\n        min_pos = _mm256_min_epi32(min_pos, pos_vals);\n    }\n\n    int largest_neg = _mm256_extract_epi32(max_neg, 0);\n    for (int i = 1; i < 8; ++i) {\n        largest_neg = std::max(largest_neg, _mm256_extract_epi32(max_neg, i));\n    }\n\n    int smallest_pos = _mm256_extract_epi32(min_pos, 0);\n    for (int i = 1; i < 8; ++i) {\n        smallest_pos = std::min(smallest_pos, _mm256_extract_epi32(min_pos, i));\n    }\n\n    if (largest_neg == std::numeric_limits<int>::min()) largest_neg = 0;\n    if (smallest_pos == std::numeric_limits<int>::max()) smallest_pos = 0;\n\n    return {largest_neg, smallest_pos};\n}\n```"}
{"task_id": "SimdBench_128_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n#include <limits>\n\nstd::vector<int> largest_smallest_integers_simd(const std::vector<int>& lst) {\n    __m256i max_neg = _mm256_set1_epi32(std::numeric_limits<int>::min());\n    __m256i min_pos = _mm256_set1_epi32(std::numeric_limits<int>::max());\n    int size = lst.size();\n    int i = 0;\n\n    for (; i <= size - 8; i += 8) {\n        __m256i vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&lst[i]));\n        \n        __m256i neg_mask = _mm256_cmpgt_epi32(vec, _mm256_setzero_si256());\n        __m256i pos_mask = _mm256_cmpgt_epi32(_mm256_setzero_si256(), vec);\n        \n        __m256i neg_values = _mm256_blendv_epi8(vec, _mm256_set1_epi32(std::numeric_limits<int>::min()), neg_mask);\n        __m256i pos_values = _mm256_blendv_epi8(vec, _mm256_set1_epi32(std::numeric_limits<int>::max()), pos_mask);\n        \n        max_neg = _mm256_max_epi32(max_neg, neg_values);\n        min_pos = _mm256_min_epi32(min_pos, pos_values);\n    }\n\n    int max_neg_arr[8], min_pos_arr[8];\n    _mm256_storeu_si256(reinterpret_cast<__m256i*>(max_neg_arr), max_neg);\n    _mm256_storeu_si256(reinterpret_cast<__m256i*>(min_pos_arr), min_pos);\n\n    int largest_neg = std::numeric_limits<int>::min();\n    for (int j = 0; j < 8; ++j) {\n        if (max_neg_arr[j] > largest_neg && max_neg_arr[j] < 0) {\n            largest_neg = max_neg_arr[j];\n        }\n    }\n\n    int smallest_pos = std::numeric_limits<int>::max();\n    for (int j = 0; j < 8; ++j) {\n        if (min_pos_arr[j] < smallest_pos && min_pos_arr[j] > 0) {\n            smallest_pos = min_pos_arr[j];\n        }\n    }\n\n    if (largest_neg == std::numeric_limits<int>::min()) largest_neg = 0;\n    if (smallest_pos == std::numeric_limits<int>::max()) smallest_pos = 0;\n\n    return {largest_neg, smallest_pos};\n}\n```"}
{"task_id": "SimdBench_128_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n#include <limits>\n\nstd::vector<int> largest_smallest_integers_simd(const std::vector<int>& lst) {\n    __m256i max_neg = _mm256_set1_epi32(std::numeric_limits<int>::min());\n    __m256i min_pos = _mm256_set1_epi32(std::numeric_limits<int>::max());\n    int size = lst.size();\n    int i = 0;\n\n    for (; i <= size - 8; i += 8) {\n        __m256i vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&lst[i]));\n        __m256i neg_mask = _mm256_cmpgt_epi32(vec, _mm256_setzero_si256());\n        __m256i pos_mask = _mm256_cmpgt_epi32(_mm256_setzero_si256(), vec);\n\n        max_neg = _mm256_blendv_epi8(max_neg, vec, neg_mask);\n        min_pos = _mm256_blendv_epi8(min_pos, vec, pos_mask);\n    }\n\n    int max_neg_arr[8], min_pos_arr[8];\n    _mm256_storeu_si256(reinterpret_cast<__m256i*>(max_neg_arr), max_neg);\n    _mm256_storeu_si256(reinterpret_cast<__m256i*>(min_pos_arr), min_pos);\n\n    for (int j = 0; j < 8; ++j) {\n        if (max_neg_arr[j] < 0) {\n            max_neg = _mm256_max_epi32(max_neg, _mm256_set1_epi32(max_neg_arr[j]));\n        }\n        if (min_pos_arr[j] > 0) {\n            min_pos = _mm256_min_epi32(min_pos, _mm256_set1_epi32(min_pos_arr[j]));\n        }\n    }\n\n    int largest_neg = std::numeric_limits<int>::min();\n    int smallest_pos = std::numeric_limits<int>::max();\n\n    for (int j = 0; j < 8; ++j) {\n        largest_neg = std::max(largest_neg, max_neg_arr[j]);\n        smallest_pos = std::min(smallest_pos, min_pos_arr[j]);\n    }\n\n    if (largest_neg == std::numeric_limits<int>::min()) largest_neg = 0;\n    if (smallest_pos == std::numeric_limits<int>::max()) smallest_pos = 0;\n\n    return {largest_neg, smallest_pos};\n}\n```"}
{"task_id": "SimdBench_128_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n#include <limits>\n\nstd::vector<int> largest_smallest_integers_simd(const std::vector<int>& lst) {\n    __m256i max_neg = _mm256_set1_epi32(std::numeric_limits<int>::min());\n    __m256i min_pos = _mm256_set1_epi32(std::numeric_limits<int>::max());\n    \n    size_t size = lst.size();\n    size_t i = 0;\n\n    for (; i + 8 <= size; i += 8) {\n        __m256i vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&lst[i]));\n        \n        __m256i neg_mask = _mm256_cmpgt_epi32(vec, _mm256_setzero_si256());\n        __m256i pos_mask = _mm256_cmpgt_epi32(_mm256_setzero_si256(), vec);\n        \n        __m256i neg_values = _mm256_blendv_epi8(vec, _mm256_set1_epi32(std::numeric_limits<int>::min()), neg_mask);\n        __m256i pos_values = _mm256_blendv_epi8(vec, _mm256_set1_epi32(std::numeric_limits<int>::max()), pos_mask);\n        \n        max_neg = _mm256_max_epi32(max_neg, neg_values);\n        min_pos = _mm256_min_epi32(min_pos, pos_values);\n    }\n\n    int max_neg_result = std::numeric_limits<int>::min();\n    int min_pos_result = std::numeric_limits<int>::max();\n\n    for (; i < size; ++i) {\n        if (lst[i] < 0) {\n            max_neg_result = std::max(max_neg_result, lst[i]);\n        } else if (lst[i] > 0) {\n            min_pos_result = std::min(min_pos_result, lst[i]);\n        }\n    }\n\n    int* max_neg_arr = (int*)&max_neg;\n    int* min_pos_arr = (int*)&min_pos;\n\n    for (int j = 0; j < 8; ++j) {\n        max_neg_result = std::max(max_neg_result, max_neg_arr[j]);\n        min_pos_result = std::min(min_pos_result, min_pos_arr[j]);\n    }\n\n    if (max_neg_result == std::numeric_limits<int>::min()) max_neg_result = 0;\n    if (min_pos_result == std::numeric_limits<int>::max()) min_pos_result = 0;\n\n    return {max_neg_result, min_pos_result};\n}\n```"}
{"task_id": "SimdBench_129_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nuint64_t special_factorial_simd(uint64_t n) {\n    if (n == 0) return 1;\n\n    __m256i result = _mm256_set1_epi64x(1);\n    for (uint64_t i = 1; i <= n; i += 4) {\n        __m256i values = _mm256_set_epi64x(i + 3, i + 2, i + 1, i);\n        __m256i factorials = _mm256_set1_epi64x(1);\n        for (int j = 0; j < 4; ++j) {\n            uint64_t val = _mm256_extract_epi64(values, j);\n            for (uint64_t k = 1; k <= val; ++k) {\n                factorials = _mm256_mullo_epi64(factorials, _mm256_set1_epi64x(k));\n            }\n        }\n        result = _mm256_mullo_epi64(result, factorials);\n    }\n\n    uint64_t final_result[4];\n    _mm256_storeu_si256((__m256i*)final_result, result);\n    return final_result[0] * final_result[1] * final_result[2] * final_result[3];\n}\n```"}
{"task_id": "SimdBench_129_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nuint64_t special_factorial_simd(uint64_t n) {\n    if (n == 0) return 1;\n\n    __m256i result = _mm256_set1_epi64x(1);\n    for (uint64_t i = 1; i <= n; i += 4) {\n        __m256i idx = _mm256_set_epi64x(i + 3, i + 2, i + 1, i);\n        __m256i factorials = _mm256_set_epi64x(1, 1, 1, 1);\n        \n        for (int j = 0; j < 4; ++j) {\n            uint64_t fact = 1;\n            for (uint64_t k = 1; k <= idx[j]; ++k) {\n                fact *= k;\n            }\n            factorials = _mm256_insert_epi64(factorials, fact, j);\n        }\n        \n        result = _mm256_mullo_epi64(result, factorials);\n    }\n\n    uint64_t final_result[4];\n    _mm256_storeu_si256((__m256i*)final_result, result);\n    \n    uint64_t total = 1;\n    for (int i = 0; i < 4; ++i) {\n        total *= final_result[i];\n    }\n\n    return total;\n}\n```"}
{"task_id": "SimdBench_129_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nuint64_t special_factorial_simd(uint64_t n) {\n    if (n == 0) return 1;\n\n    __m256i result = _mm256_set1_epi64x(1);\n    for (uint64_t i = 1; i <= n; i += 4) {\n        __m256i values = _mm256_set_epi64x(i + 3, i + 2, i + 1, i);\n        result = _mm256_mullo_epi64(result, values);\n    }\n\n    uint64_t final_result[4];\n    _mm256_storeu_si256((__m256i*)final_result, result);\n    \n    uint64_t total = 1;\n    for (int j = 0; j < 4; j++) {\n        total *= final_result[j];\n    }\n\n    return total;\n}\n```"}
{"task_id": "SimdBench_129_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nuint64_t special_factorial_simd(uint64_t n) {\n    if (n == 0) return 1;\n\n    __m256i result = _mm256_set1_epi64x(1);\n    for (uint64_t i = 1; i <= n; i += 4) {\n        __m256i values = _mm256_set_epi64x(i + 3, i + 2, i + 1, i);\n        result = _mm256_mullo_epi64(result, values);\n    }\n\n    uint64_t res[4];\n    _mm256_storeu_si256((__m256i*)res, result);\n    uint64_t final_result = 1;\n    for (int j = 0; j < 4; j++) {\n        final_result *= res[j];\n    }\n\n    return final_result;\n}\n```"}
{"task_id": "SimdBench_129_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nuint64_t special_factorial_simd(uint64_t n) {\n    if (n == 0) return 1;\n\n    __m256i result = _mm256_set1_epi64x(1);\n    for (uint64_t i = 1; i <= n; ++i) {\n        __m256i current = _mm256_set1_epi64x(i);\n        result = _mm256_mullo_epi64(result, current);\n    }\n\n    uint64_t final_result = 1;\n    for (int i = 0; i < 4; ++i) {\n        final_result *= _mm256_extract_epi64(result, i);\n    }\n\n    return final_result;\n}\n```"}
{"task_id": "SimdBench_130_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nint sum_squares_simd(const std::vector<int> & lst) {\n    int sum = 0;\n    size_t size = lst.size();\n    size_t i = 0;\n\n    __m256i sum_vec = _mm256_setzero_si256();\n    \n    for (; i + 8 <= size; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&lst[i]);\n        __m256i index = _mm256_set_epi32(i + 7, i + 6, i + 5, i + 4, i + 3, i + 2, i + 1, i);\n        \n        __m256i mask_square = _mm256_cmpeq_epi32(_mm256_rem_epi32(index, _mm256_set1_epi32(3)), _mm256_setzero_si256());\n        __m256i mask_cube = _mm256_andnot_si256(mask_square, _mm256_cmpeq_epi32(_mm256_rem_epi32(index, _mm256_set1_epi32(4)), _mm256_setzero_si256()));\n        \n        __m256i squared = _mm256_mullo_epi32(vec, vec);\n        __m256i cubed = _mm256_mullo_epi32(_mm256_mullo_epi32(vec, vec), vec);\n        \n        vec = _mm256_blendv_epi8(vec, squared, mask_square);\n        vec = _mm256_blendv_epi8(vec, cubed, mask_cube);\n        \n        sum_vec = _mm256_add_epi32(sum_vec, vec);\n    }\n\n    int temp[8];\n    _mm256_storeu_si256((__m256i*)temp, sum_vec);\n    for (int j = 0; j < 8; j++) {\n        sum += temp[j];\n    }\n\n    for (; i < size; i++) {\n        if (i % 3 == 0) {\n            sum += lst[i] * lst[i];\n        } else if (i % 4 == 0) {\n            sum += lst[i] * lst[i] * lst[i];\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_130_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nint sum_squares_simd(const std::vector<int> & lst) {\n    int sum = 0;\n    size_t size = lst.size();\n    size_t i;\n\n    __m256i sum_vec = _mm256_setzero_si256();\n    \n    for (i = 0; i + 8 <= size; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&lst[i]);\n        __m256i index = _mm256_set_epi32(i + 7, i + 6, i + 5, i + 4, i + 3, i + 2, i + 1, i);\n\n        __m256i mask_square = _mm256_cmpeq_epi32(_mm256_rem_epi32(index, _mm256_set1_epi32(3)), _mm256_setzero_si256());\n        __m256i mask_cube = _mm256_andnot_si256(mask_square, _mm256_cmpeq_epi32(_mm256_rem_epi32(index, _mm256_set1_epi32(4)), _mm256_setzero_si256()));\n\n        __m256i squared = _mm256_mullo_epi32(vec, vec);\n        __m256i cubed = _mm256_mullo_epi32(_mm256_mullo_epi32(vec, vec), vec);\n\n        vec = _mm256_blendv_epi8(vec, squared, mask_square);\n        vec = _mm256_blendv_epi8(vec, cubed, mask_cube);\n\n        sum_vec = _mm256_add_epi32(sum_vec, vec);\n    }\n\n    // Horizontal sum of the vector\n    sum_vec = _mm256_hadd_epi32(sum_vec, sum_vec);\n    sum_vec = _mm256_hadd_epi32(sum_vec, sum_vec);\n    sum += _mm256_extract_epi32(sum_vec, 0) + _mm256_extract_epi32(sum_vec, 4);\n\n    // Process remaining elements\n    for (; i < size; ++i) {\n        if (i % 3 == 0) {\n            sum += lst[i] * lst[i];\n        } else if (i % 4 == 0) {\n            sum += lst[i] * lst[i] * lst[i];\n        } else {\n            sum += lst[i];\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_130_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nint sum_squares_simd(const std::vector<int> & lst) {\n    int sum = 0;\n    size_t size = lst.size();\n    size_t i;\n\n    __m256i vec_sum = _mm256_setzero_si256();\n\n    for (i = 0; i + 8 <= size; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&lst[i]);\n\n        __m256i mask3 = _mm256_set_epi32(i + 7, i + 6, i + 5, i + 4, i + 3, i + 2, i + 1, i);\n        __m256i mask4 = _mm256_set_epi32(i + 7, i + 6, i + 5, i + 4, i + 3, i + 2, i + 1, i);\n\n        __m256i idx3 = _mm256_and_si256(mask3, _mm256_set1_epi32(3));\n        __m256i idx4 = _mm256_and_si256(mask4, _mm256_set1_epi32(4));\n\n        __m256i square_mask = _mm256_cmpeq_epi32(idx3, _mm256_setzero_si256());\n        __m256i cube_mask = _mm256_andnot_si256(square_mask, _mm256_cmpeq_epi32(idx4, _mm256_setzero_si256()));\n\n        __m256i squared = _mm256_mullo_epi32(vec, vec);\n        __m256i cubed = _mm256_mullo_epi32(_mm256_mullo_epi32(vec, vec), vec);\n\n        vec = _mm256_blendv_epi8(vec, squared, square_mask);\n        vec = _mm256_blendv_epi8(vec, cubed, cube_mask);\n\n        vec_sum = _mm256_add_epi32(vec_sum, vec);\n    }\n\n    // Horizontal sum\n    int32_t temp[8];\n    _mm256_storeu_si256((__m256i*)temp, vec_sum);\n    for (int j = 0; j < 8; j++) {\n        sum += temp[j];\n    }\n\n    // Handle remaining elements\n    for (; i < size; i++) {\n        if (i % 3 == 0) {\n            sum += lst[i] * lst[i];\n        } else if (i % 4 == 0) {\n            sum += lst[i] * lst[i] * lst[i];\n        } else {\n            sum += lst[i];\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_130_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nint sum_squares_simd(const std::vector<int> & lst) {\n    int sum = 0;\n    size_t size = lst.size();\n    size_t i;\n\n    __m256i sum_vec = _mm256_setzero_si256();\n\n    for (i = 0; i + 8 <= size; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&lst[i]);\n        __m256i indices = _mm256_set_epi32(i + 7, i + 6, i + 5, i + 4, i + 3, i + 2, i + 1, i);\n\n        __m256i mask_square = _mm256_cmpeq_epi32(_mm256_rem_epi32(indices, _mm256_set1_epi32(3)), _mm256_setzero_si256());\n        __m256i mask_cube = _mm256_andnot_si256(mask_square, _mm256_cmpeq_epi32(_mm256_rem_epi32(indices, _mm256_set1_epi32(4)), _mm256_setzero_si256()));\n\n        __m256i squared = _mm256_and_si256(mask_square, _mm256_mullo_epi32(vec, vec));\n        __m256i cubed = _mm256_and_si256(mask_cube, _mm256_mullo_epi32(_mm256_mullo_epi32(vec, vec), vec));\n\n        vec = _mm256_add_epi32(squared, cubed);\n        sum_vec = _mm256_add_epi32(sum_vec, vec);\n    }\n\n    // Horizontal sum of the vector\n    sum_vec = _mm256_hadd_epi32(sum_vec, sum_vec);\n    sum_vec = _mm256_hadd_epi32(sum_vec, sum_vec);\n    sum += _mm256_extract_epi32(sum_vec, 0) + _mm256_extract_epi32(sum_vec, 4);\n\n    // Process remaining elements\n    for (; i < size; ++i) {\n        if (i % 3 == 0) {\n            sum += lst[i] * lst[i];\n        } else if (i % 4 == 0) {\n            sum += lst[i] * lst[i] * lst[i];\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_130_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nint sum_squares_simd(const std::vector<int> & lst) {\n    int sum = 0;\n    size_t size = lst.size();\n    size_t i = 0;\n\n    __m256i sum_vec = _mm256_setzero_si256();\n\n    for (; i + 8 <= size; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&lst[i]);\n        __m256i indices = _mm256_set_epi32(i + 7, i + 6, i + 5, i + 4, i + 3, i + 2, i + 1, i);\n\n        __m256i mask_square = _mm256_cmpeq_epi32(_mm256_rem_epi32(indices, _mm256_set1_epi32(3)), _mm256_setzero_si256());\n        __m256i mask_cube = _mm256_andnot_si256(mask_square, _mm256_cmpeq_epi32(_mm256_rem_epi32(indices, _mm256_set1_epi32(4)), _mm256_setzero_si256()));\n\n        __m256i squared = _mm256_mullo_epi32(vec, vec);\n        __m256i cubed = _mm256_mullo_epi32(_mm256_mullo_epi32(vec, vec), vec);\n\n        vec = _mm256_blendv_epi8(vec, squared, mask_square);\n        vec = _mm256_blendv_epi8(vec, cubed, mask_cube);\n\n        sum_vec = _mm256_add_epi32(sum_vec, vec);\n    }\n\n    for (; i < size; ++i) {\n        if (i % 3 == 0) {\n            sum += lst[i] * lst[i];\n        } else if (i % 4 == 0) {\n            sum += lst[i] * lst[i] * lst[i];\n        } else {\n            sum += lst[i];\n        }\n    }\n\n    int32_t temp[8];\n    _mm256_storeu_si256((__m256i*)temp, sum_vec);\n    for (int j = 0; j < 8; ++j) {\n        sum += temp[j];\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_131_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nint specialFilter_simd(const std::vector<int> & nums) {\n    int count = 0;\n    size_t size = nums.size();\n    size_t i = 0;\n\n    __m256i odd_mask = _mm256_set1_epi32(0xAAAAAAAA); // Mask for odd digits\n    __m256i ten_mask = _mm256_set1_epi32(10); // Mask for comparison with 10\n    __m256i count_mask = _mm256_set1_epi32(0xFFFFFFFF); // For counting\n\n    for (; i + 8 <= size; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&nums[i]);\n        __m256i greater_than_ten = _mm256_cmpgt_epi32(vec, ten_mask);\n\n        // Extract first and last digits\n        __m256i first_digit = _mm256_and_si256(_mm256_srli_epi32(vec, 28), _mm256_set1_epi32(0xF));\n        __m256i last_digit = _mm256_and_si256(vec, _mm256_set1_epi32(0xF));\n\n        // Check if first and last digits are odd\n        __m256i first_odd = _mm256_and_si256(first_digit, odd_mask);\n        __m256i last_odd = _mm256_and_si256(last_digit, odd_mask);\n        __m256i both_odd = _mm256_and_si256(first_odd, last_odd);\n\n        // Combine conditions\n        __m256i valid_condition = _mm256_and_si256(greater_than_ten, both_odd);\n\n        // Count valid elements\n        count += _mm256_movemask_epi8(valid_condition);\n    }\n\n    // Handle remaining elements\n    for (; i < size; ++i) {\n        if (nums[i] > 10) {\n            int first_digit = (nums[i] < 0 ? -nums[i] : nums[i]);\n            while (first_digit >= 10) first_digit /= 10;\n            int last_digit = nums[i] % 10;\n            if ((first_digit % 2 != 0) && (last_digit % 2 != 0)) {\n                count++;\n            }\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_131_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nint specialFilter_simd(const std::vector<int> & nums) {\n    int count = 0;\n    size_t size = nums.size();\n    size_t i = 0;\n\n    __m256i odd_mask = _mm256_set1_epi32(0xAAAAAAAA); // Mask for odd digits\n    __m256i ten_mask = _mm256_set1_epi32(10);\n    \n    for (; i + 8 <= size; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&nums[i]);\n        \n        // Check if greater than 10\n        __m256i greater_than_ten = _mm256_cmpgt_epi32(vec, ten_mask);\n        \n        // Extract first and last digits\n        __m256i first_digit = _mm256_abs_epi32(_mm256_div_epi32(vec, _mm256_set1_epi32(10)));\n        __m256i last_digit = _mm256_abs_epi32(_mm256_rem_epi32(vec, _mm256_set1_epi32(10)));\n        \n        // Check if first and last digits are odd\n        __m256i first_odd = _mm256_and_si256(first_digit, odd_mask);\n        __m256i last_odd = _mm256_and_si256(last_digit, odd_mask);\n        \n        // Combine conditions\n        __m256i conditions = _mm256_and_si256(greater_than_ten, _mm256_and_si256(first_odd, last_odd));\n        \n        // Count the number of true conditions\n        count += _mm256_movemask_epi8(conditions);\n    }\n\n    // Handle remaining elements\n    for (; i < size; ++i) {\n        if (nums[i] > 10) {\n            int first_digit = std::abs(nums[i]);\n            while (first_digit >= 10) first_digit /= 10;\n            int last_digit = std::abs(nums[i]) % 10;\n            if ((first_digit % 2 != 0) && (last_digit % 2 != 0)) {\n                count++;\n            }\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_131_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nint specialFilter_simd(const std::vector<int> & nums) {\n    int count = 0;\n    size_t size = nums.size();\n    size_t i = 0;\n\n    __m256i ten = _mm256_set1_epi32(10);\n    __m256i odd_mask = _mm256_set1_epi32(0xAAAAAAAA); // Mask for odd digits (1, 3, 5, 7, 9)\n\n    for (; i + 8 <= size; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&nums[i]);\n        __m256i greater_than_ten = _mm256_cmpgt_epi32(vec, ten);\n\n        // Extract first and last digits\n        __m256i first_digit = _mm256_and_si256(vec, _mm256_set1_epi32(0xF0000000)); // Get first digit\n        __m256i last_digit = _mm256_and_si256(vec, _mm256_set1_epi32(0x0000000F)); // Get last digit\n\n        // Check if first and last digits are odd\n        __m256i first_odd = _mm256_and_si256(first_digit, odd_mask);\n        __m256i last_odd = _mm256_and_si256(last_digit, odd_mask);\n\n        __m256i both_odd = _mm256_and_si256(first_odd, last_odd);\n        __m256i valid_numbers = _mm256_and_si256(greater_than_ten, both_odd);\n\n        // Count valid numbers\n        count += _mm256_movemask_epi8(valid_numbers);\n    }\n\n    // Handle remaining elements\n    for (; i < size; ++i) {\n        if (nums[i] > 10) {\n            int first_digit = std::to_string(nums[i]).front() - '0';\n            int last_digit = std::to_string(nums[i]).back() - '0';\n            if (first_digit % 2 != 0 && last_digit % 2 != 0) {\n                count++;\n            }\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_131_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nint specialFilter_simd(const std::vector<int> & nums) {\n    int count = 0;\n    size_t size = nums.size();\n    size_t i = 0;\n\n    __m256i odd_mask = _mm256_set1_epi32(0xAAAAAAAA); // Mask for odd digits\n    __m256i ten_mask = _mm256_set1_epi32(10); // Mask for comparison with 10\n    __m256i count_mask = _mm256_set1_epi32(1); // Mask for counting\n\n    for (; i + 8 <= size; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&nums[i]);\n        __m256i greater_than_ten = _mm256_cmpgt_epi32(vec, ten_mask);\n\n        // Extract first and last digits\n        __m256i first_digit = _mm256_abs_epi32(_mm256_div_epi32(vec, _mm256_set1_epi32(10)));\n        __m256i last_digit = _mm256_abs_epi32(_mm256_rem_epi32(vec, _mm256_set1_epi32(10)));\n\n        // Check if first and last digits are odd\n        __m256i first_odd = _mm256_and_si256(first_digit, odd_mask);\n        __m256i last_odd = _mm256_and_si256(last_digit, odd_mask);\n        __m256i both_odd = _mm256_and_si256(first_odd, last_odd);\n\n        // Combine conditions\n        __m256i valid_mask = _mm256_and_si256(greater_than_ten, both_odd);\n\n        // Count valid elements\n        count += _mm256_movemask_epi8(valid_mask);\n    }\n\n    // Handle remaining elements\n    for (; i < size; ++i) {\n        if (nums[i] > 10) {\n            int first_digit = std::abs(nums[i]);\n            while (first_digit >= 10) first_digit /= 10;\n            int last_digit = std::abs(nums[i]) % 10;\n\n            if ((first_digit % 2 != 0) && (last_digit % 2 != 0)) {\n                count++;\n            }\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_131_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nint specialFilter_simd(const std::vector<int> & nums) {\n    int count = 0;\n    size_t size = nums.size();\n    size_t i = 0;\n\n    __m256i ten = _mm256_set1_epi32(10);\n    __m256i odd_mask = _mm256_set1_epi32(0xAAAAAAAA); // Mask for odd digits\n\n    for (; i + 8 <= size; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i*)&nums[i]);\n        \n        // Check if elements are greater than 10\n        __m256i greater_than_ten = _mm256_cmpgt_epi32(vec, ten);\n        \n        // Extract first and last digits\n        __m256i first_digit = _mm256_and_si256(_mm256_srli_epi32(vec, 28), _mm256_set1_epi32(0xF)); // First digit\n        __m256i last_digit = _mm256_and_si256(vec, _mm256_set1_epi32(0xF)); // Last digit\n        \n        // Check if first and last digits are odd\n        __m256i first_odd = _mm256_and_si256(first_digit, odd_mask);\n        __m256i last_odd = _mm256_and_si256(last_digit, odd_mask);\n        \n        __m256i both_odd = _mm256_and_si256(first_odd, last_odd);\n        \n        // Combine conditions\n        __m256i valid = _mm256_and_si256(greater_than_ten, both_odd);\n        \n        // Count valid elements\n        int mask = _mm256_movemask_epi8(valid);\n        count += __builtin_popcount(mask);\n    }\n\n    // Handle remaining elements\n    for (; i < size; ++i) {\n        if (nums[i] > 10) {\n            int first_digit = std::to_string(nums[i]).front() - '0';\n            int last_digit = nums[i] % 10;\n            if (first_digit % 2 != 0 && last_digit % 2 != 0) {\n                count++;\n            }\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_132_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nuint64_t get_max_triples_simd(uint64_t n) {\n    if (n < 3) return 0;\n\n    uint64_t count = 0;\n    uint64_t* a = new uint64_t[n];\n\n    // Calculate the values of a[i] = i * i - i + 1\n    for (uint64_t i = 1; i <= n; i++) {\n        a[i - 1] = i * i - i + 1;\n    }\n\n    // Count the number of triples (i, j, k) such that a[i] + a[j] + a[k] is a multiple of 3\n    for (uint64_t i = 0; i < n - 2; i++) {\n        for (uint64_t j = i + 1; j < n - 1; j++) {\n            for (uint64_t k = j + 1; k < n; k++) {\n                __m256i vec_a = _mm256_set_epi64x(a[k], a[j], a[i], 0);\n                __m256i vec_sum = _mm256_hadd_epi64(vec_a, vec_a);\n                vec_sum = _mm256_hadd_epi64(vec_sum, vec_sum);\n                \n                int64_t sum = _mm256_extract_epi64(vec_sum, 0);\n                if (sum % 3 == 0) {\n                    count++;\n                }\n            }\n        }\n    }\n\n    delete[] a;\n    return count;\n}\n```"}
{"task_id": "SimdBench_132_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nuint64_t get_max_triples_simd(uint64_t n) {\n    if (n < 3) return 0;\n\n    uint64_t count = 0;\n    uint64_t *a = new uint64_t[n];\n\n    // Calculate the values of a[i] = i * i - i + 1\n    for (uint64_t i = 1; i <= n; i++) {\n        a[i - 1] = i * i - i + 1;\n    }\n\n    // Count the number of triples (a[i], a[j], a[k]) such that a[i] + a[j] + a[k] is a multiple of 3\n    for (uint64_t i = 0; i < n - 2; i++) {\n        for (uint64_t j = i + 1; j < n - 1; j++) {\n            for (uint64_t k = j + 1; k < n; k++) {\n                if ((a[i] + a[j] + a[k]) % 3 == 0) {\n                    count++;\n                }\n            }\n        }\n    }\n\n    delete[] a;\n    return count;\n}\n```"}
{"task_id": "SimdBench_132_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <stdint.h>\n\nuint64_t get_max_triples_simd(uint64_t n) {\n    if (n < 3) return 0;\n\n    uint64_t count = 0;\n    uint64_t* a = (uint64_t*)_mm_malloc(n * sizeof(uint64_t), 32);\n\n    for (uint64_t i = 1; i <= n; i++) {\n        a[i - 1] = i * i - i + 1;\n    }\n\n    __m256i mod3_count = _mm256_setzero_si256();\n    \n    for (uint64_t i = 0; i < n; i += 8) {\n        __m256i indices = _mm256_set_epi64x(i + 7, i + 6, i + 5, i + 4, i + 3, i + 2, i + 1, i);\n        __m256i values = _mm256_i64gather_epi64(a, indices, 1);\n        __m256i mod3 = _mm256_rem_epi64(values, _mm256_set1_epi64x(3));\n        \n        for (int j = 0; j < 8; j++) {\n            int index = _mm256_extract_epi64(mod3, j);\n            mod3_count = _mm256_add_epi64(mod3_count, _mm256_set1_epi64x(index));\n        }\n    }\n\n    // Count valid triples\n    for (int i = 0; i < 3; i++) {\n        uint64_t count_i = _mm256_extract_epi64(mod3_count, i);\n        count += (count_i * (count_i - 1) * (count_i - 2)) / 6;\n    }\n\n    _mm_free(a);\n    return count;\n}\n```"}
{"task_id": "SimdBench_132_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nuint64_t get_max_triples_simd(uint64_t n) {\n    if (n < 3) return 0;\n\n    uint64_t count = 0;\n    uint64_t *a = new uint64_t[n];\n\n    // Fill the array using the formula a[i] = i * i - i + 1\n    for (uint64_t i = 0; i < n; ++i) {\n        a[i] = (i + 1) * (i + 1) - (i + 1) + 1;\n    }\n\n    // Count the occurrences of a[i] % 3\n    uint64_t mod_count[3] = {0, 0, 0};\n    for (uint64_t i = 0; i < n; ++i) {\n        mod_count[a[i] % 3]++;\n    }\n\n    // Calculate the number of valid triples\n    count += (mod_count[0] * (mod_count[0] - 1) * (mod_count[0] - 2)) / 6; // All mod 0\n    count += (mod_count[1] * (mod_count[1] - 1) * (mod_count[1] - 2)) / 6; // All mod 1\n    count += (mod_count[2] * (mod_count[2] - 1) * (mod_count[2] - 2)) / 6; // All mod 2\n    count += mod_count[0] * mod_count[1] * mod_count[2]; // One of each\n\n    delete[] a;\n    return count;\n}\n```"}
{"task_id": "SimdBench_132_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <stdint.h>\n\nuint64_t get_max_triples_simd(uint64_t n) {\n    if (n < 3) return 0;\n\n    uint64_t count = 0;\n    uint64_t *a = (uint64_t*)_mm_malloc(n * sizeof(uint64_t), 32);\n\n    for (uint64_t i = 1; i <= n; ++i) {\n        a[i - 1] = i * i - i + 1;\n    }\n\n    __m256i mod3_count = _mm256_setzero_si256();\n    \n    for (uint64_t i = 0; i < n; i += 4) {\n        __m256i values = _mm256_load_si256((__m256i*)&a[i]);\n        __m256i mod3 = _mm256_rem_epi64(values, _mm256_set1_epi64x(3));\n        \n        for (int j = 0; j < 4; ++j) {\n            int index = _mm256_extract_epi64(mod3, j);\n            mod3_count = _mm256_add_epi64(mod3_count, _mm256_set1_epi64x(index));\n        }\n    }\n\n    // Count the occurrences of each mod 3 value\n    uint64_t counts[3] = {0};\n    for (uint64_t i = 0; i < n; ++i) {\n        counts[a[i] % 3]++;\n    }\n\n    // Calculate the number of valid triples\n    count += counts[0] * (counts[0] - 1) * (counts[0] - 2) / 6; // (0, 0, 0)\n    count += counts[1] * counts[1] * counts[1] / 6; // (1, 1, 1)\n    count += counts[2] * counts[2] * counts[2] / 6; // (2, 2, 2)\n    count += counts[0] * counts[1] * counts[2]; // (0, 1, 2)\n\n    _mm_free(a);\n    return count;\n}\n```"}
{"task_id": "SimdBench_133_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nint is_prime(int n) {\n    if (n <= 1) return 0;\n    if (n <= 3) return 1;\n    if (n % 2 == 0 || n % 3 == 0) return 0;\n    for (int i = 5; i * i <= n; i += 6) {\n        if (n % i == 0 || n % (i + 2) == 0) return 0;\n    }\n    return 1;\n}\n\nint x_or_y_simd(int n, int x, int y) {\n    __m256i n_vec = _mm256_set1_epi32(n);\n    __m256i x_vec = _mm256_set1_epi32(x);\n    __m256i y_vec = _mm256_set1_epi32(y);\n    \n    int primes[8] = {0};\n    for (int i = 0; i < 8; i++) {\n        primes[i] = is_prime(n);\n    }\n    \n    __m256i prime_vec = _mm256_loadu_si256((__m256i*)primes);\n    __m256i result = _mm256_blendv_epi8(y_vec, x_vec, prime_vec);\n    \n    return _mm256_extract_epi32(result, 0);\n}\n```"}
{"task_id": "SimdBench_133_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nint is_prime(int n) {\n    if (n <= 1) return 0;\n    if (n <= 3) return 1;\n    if (n % 2 == 0 || n % 3 == 0) return 0;\n    for (int i = 5; i * i <= n; i += 6) {\n        if (n % i == 0 || n % (i + 2) == 0) return 0;\n    }\n    return 1;\n}\n\nint x_or_y_simd(int n, int x, int y) {\n    __m256i n_vec = _mm256_set1_epi32(n);\n    __m256i x_vec = _mm256_set1_epi32(x);\n    __m256i y_vec = _mm256_set1_epi32(y);\n    \n    __m256i primes = _mm256_set1_epi32(0);\n    for (int i = 0; i < 8; i++) {\n        int num = n + i; // Check for n, n+1, ..., n+7\n        primes = _mm256_insert_epi32(primes, is_prime(num), i);\n    }\n    \n    __m256i result = _mm256_blendv_epi8(y_vec, x_vec, primes);\n    \n    return _mm256_extract_epi32(result, 0); // Return the first element\n}\n```"}
{"task_id": "SimdBench_133_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nint is_prime(int n) {\n    if (n <= 1) return 0;\n    if (n <= 3) return 1;\n    if (n % 2 == 0 || n % 3 == 0) return 0;\n    for (int i = 5; i * i <= n; i += 6) {\n        if (n % i == 0 || n % (i + 2) == 0) return 0;\n    }\n    return 1;\n}\n\nint x_or_y_simd(int n, int x, int y) {\n    __m256i n_vec = _mm256_set1_epi32(n);\n    __m256i x_vec = _mm256_set1_epi32(x);\n    __m256i y_vec = _mm256_set1_epi32(y);\n    \n    int primes[8] = {0};\n    for (int i = 0; i < 8; i++) {\n        primes[i] = is_prime(n);\n    }\n    \n    __m256i prime_vec = _mm256_loadu_si256((__m256i*)primes);\n    __m256i result_vec = _mm256_blendv_epi8(y_vec, x_vec, prime_vec);\n    \n    return _mm256_extract_epi32(result_vec, 0);\n}\n```"}
{"task_id": "SimdBench_133_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nint is_prime(int n) {\n    if (n <= 1) return 0;\n    if (n <= 3) return 1;\n    if (n % 2 == 0 || n % 3 == 0) return 0;\n    for (int i = 5; i * i <= n; i += 6) {\n        if (n % i == 0 || n % (i + 2) == 0) return 0;\n    }\n    return 1;\n}\n\nint x_or_y_simd(int n, int x, int y) {\n    __m256i n_vec = _mm256_set1_epi32(n);\n    __m256i x_vec = _mm256_set1_epi32(x);\n    __m256i y_vec = _mm256_set1_epi32(y);\n    \n    __m256i primes = _mm256_set_epi32(is_prime(n), is_prime(n), is_prime(n), is_prime(n),\n                                      is_prime(n), is_prime(n), is_prime(n), is_prime(n));\n    \n    __m256i result = _mm256_blendv_epi8(y_vec, x_vec, primes);\n    \n    return _mm256_extract_epi32(result, 0);\n}\n```"}
{"task_id": "SimdBench_133_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nint is_prime(int n) {\n    if (n <= 1) return 0;\n    if (n <= 3) return 1;\n    if (n % 2 == 0 || n % 3 == 0) return 0;\n    for (int i = 5; i * i <= n; i += 6) {\n        if (n % i == 0 || n % (i + 2) == 0) return 0;\n    }\n    return 1;\n}\n\nint x_or_y_simd(int n, int x, int y) {\n    __m256i n_vec = _mm256_set1_epi32(n);\n    __m256i x_vec = _mm256_set1_epi32(x);\n    __m256i y_vec = _mm256_set1_epi32(y);\n    \n    __m256i result = _mm256_blendv_epi8(y_vec, x_vec, _mm256_set1_epi32(is_prime(n)));\n    \n    return _mm256_extract_epi32(result, 0);\n}\n```"}
{"task_id": "SimdBench_134_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n#include <cstdint>\n\nuint64_t double_the_difference_simd(const std::vector<float> & lst) {\n    size_t n = lst.size();\n    if (n == 0) return 0;\n\n    __m256 sum = _mm256_setzero_ps();\n    size_t i;\n\n    for (i = 0; i + 8 <= n; i += 8) {\n        __m256 vec = _mm256_loadu_ps(&lst[i]);\n        __m256 mask = _mm256_cmp_ps(vec, _mm256_setzero_ps(), _CMP_GT_OS);\n        __m256 odd_mask = _mm256_and_ps(mask, _mm256_cmp_ps(vec, _mm256_set1_ps(0.5f), _CMP_EQ_OQ));\n        \n        vec = _mm256_mul_ps(vec, vec); // Square the values\n        vec = _mm256_and_ps(vec, odd_mask); // Zero out even and non-positive numbers\n        \n        sum = _mm256_add_ps(sum, vec);\n    }\n\n    // Horizontal sum of the vector\n    float temp[8];\n    _mm256_storeu_ps(temp, sum);\n    uint64_t total_sum = 0;\n    for (int j = 0; j < 8; j++) {\n        total_sum += static_cast<uint64_t>(temp[j]);\n    }\n\n    // Handle remaining elements\n    for (; i < n; i++) {\n        if (lst[i] > 0 && static_cast<int>(lst[i]) % 2 != 0) {\n            total_sum += static_cast<uint64_t>(lst[i] * lst[i]);\n        }\n    }\n\n    return total_sum;\n}\n```"}
{"task_id": "SimdBench_134_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nuint64_t double_the_difference_simd(const std::vector<float> & lst) {\n    size_t n = lst.size();\n    if (n == 0) return 0;\n\n    __m256 sum = _mm256_setzero_ps();\n    size_t i;\n\n    for (i = 0; i <= n - 8; i += 8) {\n        __m256 vec = _mm256_loadu_ps(&lst[i]);\n        __m256 mask = _mm256_cmp_ps(vec, _mm256_set1_ps(0), _MM_CMPINT_GT);\n        __m256 odd_mask = _mm256_and_ps(mask, _mm256_cmp_ps(vec, _mm256_set1_ps(0), _MM_CMPINT_EQ));\n        \n        vec = _mm256_and_ps(odd_mask, vec);\n        vec = _mm256_mul_ps(vec, vec);\n        sum = _mm256_add_ps(sum, vec);\n    }\n\n    float temp[8];\n    _mm256_storeu_ps(temp, sum);\n    uint64_t total = 0;\n    for (size_t j = 0; j < 8; j++) {\n        total += static_cast<uint64_t>(temp[j]);\n    }\n\n    for (; i < n; i++) {\n        if (lst[i] > 0 && static_cast<int>(lst[i]) % 2 != 0) {\n            total += static_cast<uint64_t>(lst[i] * lst[i]);\n        }\n    }\n\n    return total;\n}\n```"}
{"task_id": "SimdBench_134_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nuint64_t double_the_difference_simd(const std::vector<float> & lst) {\n    size_t size = lst.size();\n    if (size == 0) return 0;\n\n    __m256 sum_squares = _mm256_setzero_ps();\n    size_t i = 0;\n\n    for (; i + 8 <= size; i += 8) {\n        __m256 vec = _mm256_loadu_ps(&lst[i]);\n        __m256 mask_odd = _mm256_and_ps(vec, _mm256_set1_ps(1.0f));\n        __m256 mask_positive = _mm256_cmp_ps(vec, _mm256_setzero_ps(), _CMP_GT_OS);\n        __m256 mask = _mm256_and_ps(mask_odd, mask_positive);\n\n        vec = _mm256_mul_ps(vec, vec);\n        vec = _mm256_and_ps(vec, mask);\n        sum_squares = _mm256_add_ps(sum_squares, vec);\n    }\n\n    float result[8];\n    _mm256_storeu_ps(result, sum_squares);\n\n    uint64_t total = 0;\n    for (size_t j = 0; j < 8; ++j) {\n        total += static_cast<uint64_t>(result[j]);\n    }\n\n    for (; i < size; ++i) {\n        if (lst[i] > 0 && static_cast<int>(lst[i]) % 2 != 0) {\n            total += static_cast<uint64_t>(lst[i] * lst[i]);\n        }\n    }\n\n    return total;\n}\n```"}
{"task_id": "SimdBench_134_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nuint64_t double_the_difference_simd(const std::vector<float> & lst) {\n    size_t size = lst.size();\n    if (size == 0) return 0;\n\n    __m256i sum = _mm256_setzero_si256();\n    __m256i mask_odd = _mm256_set1_epi32(1);\n    __m256i mask_negative = _mm256_set1_epi32(0);\n    \n    size_t i = 0;\n    for (; i + 8 <= size; i += 8) {\n        __m256 input = _mm256_loadu_ps(&lst[i]);\n        __m256i int_input = _mm256_cvtps_epi32(input);\n        \n        __m256i odd_mask = _mm256_and_si256(int_input, mask_odd);\n        __m256i negative_mask = _mm256_cmpgt_epi32(int_input, mask_negative);\n        \n        __m256i valid_mask = _mm256_andnot_si256(negative_mask, odd_mask);\n        __m256i squares = _mm256_mullo_epi32(int_input, int_input);\n        \n        squares = _mm256_and_si256(squares, valid_mask);\n        sum = _mm256_add_epi32(sum, squares);\n    }\n\n    uint64_t result = 0;\n    for (; i < size; ++i) {\n        if (lst[i] >= 0 && static_cast<int>(lst[i]) % 2 != 0) {\n            result += static_cast<int>(lst[i]) * static_cast<int>(lst[i]);\n        }\n    }\n\n    int32_t temp[8];\n    _mm256_storeu_si256((__m256i*)temp, sum);\n    for (int j = 0; j < 8; ++j) {\n        result += temp[j];\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_134_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nuint64_t double_the_difference_simd(const std::vector<float> & lst) {\n    __m256 sum = _mm256_setzero_ps();\n    size_t size = lst.size();\n    size_t i;\n\n    for (i = 0; i + 8 <= size; i += 8) {\n        __m256 vec = _mm256_loadu_ps(&lst[i]);\n        __m256 mask_odd = _mm256_cmp_ps(vec, _mm256_set1_ps(0), _CMP_GT_OS);\n        __m256 mask_int = _mm256_cmp_ps(vec, _mm256_set1_ps(0), _CMP_EQ_OQ);\n        __m256 mask = _mm256_and_ps(mask_odd, mask_int);\n        \n        __m256 odd_mask = _mm256_and_ps(mask, _mm256_cmp_ps(vec, _mm256_set1_ps(0), _CMP_EQ_OQ));\n        __m256 odd_squares = _mm256_mul_ps(vec, vec);\n        odd_squares = _mm256_and_ps(odd_squares, odd_mask);\n        \n        sum = _mm256_add_ps(sum, odd_squares);\n    }\n\n    float result[8];\n    _mm256_storeu_ps(result, sum);\n    uint64_t total_sum = 0;\n    for (size_t j = 0; j < 8; j++) {\n        total_sum += static_cast<uint64_t>(result[j]);\n    }\n\n    for (; i < size; i++) {\n        if (lst[i] > 0 && static_cast<int>(lst[i]) % 2 != 0) {\n            total_sum += static_cast<uint64_t>(lst[i] * lst[i]);\n        }\n    }\n\n    return total_sum;\n}\n```"}
{"task_id": "SimdBench_135_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<int> compare_simd(const std::vector<int>& game, const std::vector<int>& guess) {\n    size_t size = game.size();\n    std::vector<int> result(size);\n    \n    size_t i = 0;\n    for (; i + 8 <= size; i += 8) {\n        __m256i game_vec = _mm256_loadu_si256((__m256i*)&game[i]);\n        __m256i guess_vec = _mm256_loadu_si256((__m256i*)&guess[i]);\n        __m256i diff_vec = _mm256_sub_epi32(game_vec, guess_vec);\n        __m256i abs_diff_vec = _mm256_abs_epi32(diff_vec);\n        _mm256_storeu_si256((__m256i*)&result[i], abs_diff_vec);\n    }\n    \n    for (; i < size; ++i) {\n        result[i] = std::abs(game[i] - guess[i]);\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_135_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<int> compare_simd(const std::vector<int>& game, const std::vector<int>& guess) {\n    size_t n = game.size();\n    std::vector<int> result(n);\n    \n    size_t i = 0;\n    for (; i + 8 <= n; i += 8) {\n        __m256i game_vec = _mm256_loadu_si256((__m256i*)&game[i]);\n        __m256i guess_vec = _mm256_loadu_si256((__m256i*)&guess[i]);\n        __m256i diff_vec = _mm256_sub_epi32(game_vec, guess_vec);\n        __m256i abs_diff_vec = _mm256_abs_epi32(diff_vec);\n        _mm256_storeu_si256((__m256i*)&result[i], abs_diff_vec);\n    }\n    \n    for (; i < n; ++i) {\n        result[i] = std::abs(game[i] - guess[i]);\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_135_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<int> compare_simd(const std::vector<int>& game, const std::vector<int>& guess) {\n    size_t size = game.size();\n    std::vector<int> result(size);\n    \n    size_t i = 0;\n    for (; i + 8 <= size; i += 8) {\n        __m256i game_vec = _mm256_loadu_si256((__m256i*)&game[i]);\n        __m256i guess_vec = _mm256_loadu_si256((__m256i*)&guess[i]);\n        \n        __m256i diff_vec = _mm256_sub_epi32(game_vec, guess_vec);\n        __m256i abs_diff_vec = _mm256_abs_epi32(diff_vec);\n        \n        _mm256_storeu_si256((__m256i*)&result[i], abs_diff_vec);\n    }\n    \n    for (; i < size; ++i) {\n        result[i] = std::abs(game[i] - guess[i]);\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_135_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<int> compare_simd(const std::vector<int>& game, const std::vector<int>& guess) {\n    size_t n = game.size();\n    std::vector<int> result(n);\n    \n    size_t i = 0;\n    for (; i + 8 <= n; i += 8) {\n        __m256i game_vec = _mm256_loadu_si256((__m256i*)&game[i]);\n        __m256i guess_vec = _mm256_loadu_si256((__m256i*)&guess[i]);\n        \n        __m256i diff_vec = _mm256_sub_epi32(game_vec, guess_vec);\n        __m256i abs_diff_vec = _mm256_abs_epi32(diff_vec);\n        \n        _mm256_storeu_si256((__m256i*)&result[i], abs_diff_vec);\n    }\n    \n    for (; i < n; ++i) {\n        result[i] = std::abs(game[i] - guess[i]);\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_135_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<int> compare_simd(const std::vector<int>& game, const std::vector<int>& guess) {\n    size_t n = game.size();\n    std::vector<int> result(n);\n    \n    size_t i = 0;\n    for (; i + 8 <= n; i += 8) {\n        __m256i game_vec = _mm256_loadu_si256((__m256i*)&game[i]);\n        __m256i guess_vec = _mm256_loadu_si256((__m256i*)&guess[i]);\n        __m256i diff_vec = _mm256_sub_epi32(game_vec, guess_vec);\n        __m256i abs_diff_vec = _mm256_abs_epi32(diff_vec);\n        _mm256_storeu_si256((__m256i*)&result[i], abs_diff_vec);\n    }\n    \n    for (; i < n; ++i) {\n        result[i] = std::abs(game[i] - guess[i]);\n    }\n    \n    return result;\n}\n```"}

{"task_id": "SimdBench_0_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid conditional_move_simd(const int64_t *src, int64_t *dst, const bool *mask, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 4; i += 4) {\n        __m256i src_vec = _mm256_loadu_si256((__m256i const*)(src + i));\n        __m256i dst_vec = _mm256_loadu_si256((__m256i const*)(dst + i));\n        __m256i mask_vec = _mm256_set_epi64x(mask[i+3], mask[i+2], mask[i+1], mask[i]);\n        mask_vec = _mm256_cmpgt_epi64(mask_vec, _mm256_setzero_si256());\n        __m256i result_vec = _mm256_blendv_epi8(dst_vec, src_vec, mask_vec);\n        _mm256_storeu_si256((__m256i*)(dst + i), result_vec);\n    }\n    for (; i < length; ++i) {\n        if (mask[i]) {\n            dst[i] = src[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_0_AVX", "completion": "```cpp\nvoid conditional_move_simd(const int64_t *src, int64_t *dst, const bool *mask, size_t length) {\n    size_t i = 0;\n    __m256i zero = _mm256_setzero_si256();\n    for (; i <= length - 4; i += 4) {\n        __m256i src_vec = _mm256_loadu_si256((__m256i const*)(src + i));\n        __m256i dst_vec = _mm256_loadu_si256((__m256i const*)(dst + i));\n        __m256i mask_vec = _mm256_loadu_si256((__m256i const*)(mask + i));\n        \n        // Convert boolean mask to integer mask\n        __m256i int_mask = _mm256_cmpgt_epi8(mask_vec, zero);\n        int_mask = _mm256_and_si256(int_mask, _mm256_set1_epi32(0x01010101));\n\n        // Blend src and dst based on the mask\n        __m256i result = _mm256_blendv_epi8(dst_vec, src_vec, int_mask);\n        _mm256_storeu_si256((__m256i*)(dst + i), result);\n    }\n\n    // Handle remaining elements\n    for (; i < length; ++i) {\n        if (mask[i]) {\n            dst[i] = src[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_0_AVX", "completion": "```cpp\nvoid conditional_move_simd(const int64_t *src, int64_t *dst, const bool *mask, size_t length) {\n    size_t i = 0;\n    __m256i zero = _mm256_setzero_si256();\n    for (; i <= length - 4; i += 4) {\n        __m256i src_vec = _mm256_loadu_si256((__m256i const*)(src + i));\n        __m256i dst_vec = _mm256_loadu_si256((__m256i const*)(dst + i));\n        __m256i mask_vec = _mm256_loadu_si256((__m256i const*)(mask + i));\n        mask_vec = _mm256_and_si256(mask_vec, _mm256_set1_epi64x(0xFFFFFFFFFFFFFFFF));\n        __m256i result = _mm256_blendv_epi8(dst_vec, src_vec, mask_vec);\n        _mm256_storeu_si256((__m256i*)(dst + i), result);\n    }\n    for (; i < length; ++i) {\n        dst[i] = mask[i] ? src[i] : dst[i];\n    }\n}\n```"}
{"task_id": "SimdBench_0_AVX", "completion": "```cpp\nvoid conditional_move_simd(const int64_t *src, int64_t *dst, const bool *mask, size_t length) {\n    size_t i = 0;\n    __m256i zero = _mm256_setzero_si256();\n    for (; i <= length - 4; i += 4) {\n        __m256i src_vec = _mm256_loadu_si256((__m256i const*)(src + i));\n        __m256i dst_vec = _mm256_loadu_si256((__m256i const*)(dst + i));\n        __m128i mask_vec = _mm_loadu_si128((__m128i const*)(mask + i));\n        __m256i mask_ext = _mm256_cvtepi8_epi64(mask_vec);\n        __m256i result = _mm256_blendv_epi8(dst_vec, src_vec, mask_ext);\n        _mm256_storeu_si256((__m256i*)(dst + i), result);\n    }\n    for (; i < length; ++i) {\n        if (mask[i]) {\n            dst[i] = src[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_0_AVX", "completion": "```cpp\nvoid conditional_move_simd(const int64_t *src, int64_t *dst, const bool *mask, size_t length) {\n    size_t i = 0;\n    __m256i zero = _mm256_setzero_si256();\n    for (; i <= length - 4; i += 4) {\n        __m256i src_vec = _mm256_loadu_si256((__m256i const*)(src + i));\n        __m256i dst_vec = _mm256_loadu_si256((__m256i const*)(dst + i));\n        __m256i mask_vec = _mm256_loadu_si256((__m256i const*)(mask + i));\n        mask_vec = _mm256_and_si256(mask_vec, _mm256_set1_epi64x(0xFFFFFFFFFFFFFFFF));\n        __m256i result = _mm256_blendv_epi8(dst_vec, src_vec, mask_vec);\n        _mm256_storeu_si256((__m256i*)(dst + i), result);\n    }\n    for (; i < length; ++i) {\n        dst[i] = mask[i] ? src[i] : dst[i];\n    }\n}\n```"}
{"task_id": "SimdBench_1_AVX", "completion": "```cpp\nvoid load_modify_store_simd(const int *src, int *dst, int scale, size_t length) {\n    __m256i scale_vec = _mm256_set1_epi32(scale);\n    __m256i shift_right_3 = _mm256_set1_epi32(3);\n    __m256i shift_left_3 = _mm256_set1_epi32(3);\n    __m256i divisor = _mm256_set1_epi32(7);\n\n    for (size_t i = 0; i <= length - 8; i += 8) {\n        __m256i src_vec = _mm256_loadu_si256((__m256i const*)(src + i));\n        __m256i tmp1 = _mm256_srai_epi32(_mm256_mullo_epi32(src_vec, scale_vec), 3);\n        __m256i tmp2 = _mm256_slli_epi32(_mm256_mullo_epi32(src_vec, scale_vec), 3);\n        __m256i result = _mm256_mullo_epi32(src_vec, scale_vec);\n        result = _mm256_add_epi32(result, _mm256_mullo_epi32(tmp1, tmp2));\n        result = _mm256_div_epi32(result, divisor);\n        _mm256_storeu_si256((__m256i*)(dst + i), result);\n    }\n\n    // Handle remaining elements\n    for (size_t i = (length / 8) * 8; i < length; ++i) {\n        int tmp1 = (src[i] * scale) >> 3;\n        int tmp2 = (src[i] * scale) << 3;\n        dst[i] = (src[i] * scale + tmp1 * tmp2) / 7;\n    }\n}\n```"}
{"task_id": "SimdBench_1_AVX", "completion": "```cpp\nvoid load_modify_store_simd(const int *src, int *dst, int scale, size_t length) {\n    __m256i scale_vec = _mm256_set1_epi32(scale);\n    __m256i shift_right_3 = _mm256_set1_epi32(3);\n    __m256i shift_left_3 = _mm256_set1_epi32(3);\n    __m256i divisor = _mm256_set1_epi32(7);\n\n    for (size_t i = 0; i <= length - 8; i += 8) {\n        __m256i src_vec = _mm256_loadu_si256((__m256i const*)(src + i));\n        __m256i scaled_vec = _mm256_mullo_epi32(src_vec, scale_vec);\n        __m256i tmp1 = _mm256_srai_epi32(scaled_vec, 3);\n        __m256i tmp2 = _mm256_slli_epi32(scaled_vec, 3);\n        __m256i tmp1_tmp2 = _mm256_mullo_epi32(tmp1, tmp2);\n        __m256i result = _mm256_add_epi32(scaled_vec, tmp1_tmp2);\n        result = _mm256_div_epi32(result, divisor);\n        _mm256_storeu_si256((__m256i*)(dst + i), result);\n    }\n\n    // Handle remaining elements\n    for (size_t i = (length / 8) * 8; i < length; ++i) {\n        int element = src[i];\n        int tmp1 = (element * scale) >> 3;\n        int tmp2 = (element * scale) << 3;\n        int result = (element * scale + tmp1 * tmp2) / 7;\n        dst[i] = result;\n    }\n}\n```"}
{"task_id": "SimdBench_1_AVX", "completion": "```cpp\nvoid load_modify_store_simd(const int *src, int *dst, int scale, size_t length) {\n    __m256i scale_vec = _mm256_set1_epi32(scale);\n    __m256i shift_right_3 = _mm256_set1_epi32(3);\n    __m256i shift_left_3 = _mm256_set1_epi32(3);\n    __m256i divisor = _mm256_set1_epi32(7);\n\n    size_t i;\n    for (i = 0; i <= length - 8; i += 8) {\n        __m256i src_vec = _mm256_loadu_si256((__m256i const*)(src + i));\n        __m256i tmp1 = _mm256_srai_epi32(_mm256_mullo_epi32(src_vec, scale_vec), 3);\n        __m256i tmp2 = _mm256_slli_epi32(_mm256_mullo_epi32(src_vec, scale_vec), 3);\n        __m256i result = _mm256_mullo_epi32(src_vec, scale_vec);\n        result = _mm256_add_epi32(result, _mm256_mullo_epi32(tmp1, tmp2));\n        result = _mm256_div_epi32(result, divisor);\n        _mm256_storeu_si256((__m256i*)(dst + i), result);\n    }\n\n    for (; i < length; ++i) {\n        int tmp1 = (src[i] * scale) >> 3;\n        int tmp2 = (src[i] * scale) << 3;\n        dst[i] = (src[i] * scale + tmp1 * tmp2) / 7;\n    }\n}\n```"}
{"task_id": "SimdBench_1_AVX", "completion": "```cpp\nvoid load_modify_store_simd(const int *src, int *dst, int scale, size_t length) {\n    __m256i scale_vec = _mm256_set1_epi32(scale);\n    __m256i shift_right_3 = _mm256_set1_epi32(3);\n    __m256i shift_left_3 = _mm256_set1_epi32(3);\n    __m256i divisor = _mm256_set1_epi32(7);\n\n    size_t i;\n    for (i = 0; i <= length - 8; i += 8) {\n        __m256i src_vec = _mm256_loadu_si256((__m256i const*)(src + i));\n        __m256i tmp1 = _mm256_srai_epi32(_mm256_mullo_epi32(src_vec, scale_vec), 3);\n        __m256i tmp2 = _mm256_slli_epi32(_mm256_mullo_epi32(src_vec, scale_vec), 3);\n        __m256i result = _mm256_mullo_epi32(src_vec, scale_vec);\n        result = _mm256_add_epi32(result, _mm256_mullo_epi32(tmp1, tmp2));\n        result = _mm256_div_epi32(result, divisor);\n        _mm256_storeu_si256((__m256i*)(dst + i), result);\n    }\n\n    for (; i < length; ++i) {\n        int tmp1 = (src[i] * scale) >> 3;\n        int tmp2 = (src[i] * scale) << 3;\n        dst[i] = (src[i] * scale + tmp1 * tmp2) / 7;\n    }\n}\n```"}
{"task_id": "SimdBench_1_AVX", "completion": "```cpp\nvoid load_modify_store_simd(const int *src, int *dst, int scale, size_t length) {\n    __m256i scale_vec = _mm256_set1_epi32(scale);\n    __m256i shift_right_3 = _mm256_set1_epi32(3);\n    __m256i shift_left_3 = _mm256_set1_epi32(3);\n    __m256i divisor = _mm256_set1_epi32(7);\n\n    for (size_t i = 0; i <= length - 8; i += 8) {\n        __m256i src_vec = _mm256_loadu_si256((__m256i const*)(src + i));\n        __m256i scaled_vec = _mm256_mullo_epi32(src_vec, scale_vec);\n        __m256i tmp1 = _mm256_srai_epi32(scaled_vec, 3);\n        __m256i tmp2 = _mm256_slli_epi32(scaled_vec, 3);\n        __m256i tmp1_tmp2 = _mm256_mullo_epi32(tmp1, tmp2);\n        __m256i result = _mm256_add_epi32(scaled_vec, tmp1_tmp2);\n        result = _mm256_div_epi32(result, divisor);\n        _mm256_storeu_si256((__m256i*)(dst + i), result);\n    }\n\n    // Handle remaining elements\n    for (size_t i = (length / 8) * 8; i < length; ++i) {\n        int element = src[i];\n        int tmp1 = (element * scale) >> 3;\n        int tmp2 = (element * scale) << 3;\n        int result = (element * scale + tmp1 * tmp2) / 7;\n        dst[i] = result;\n    }\n}\n```"}
{"task_id": "SimdBench_2_AVX", "completion": "```cpp\nvoid strided_load_store_simd(const double *src, double *dst, size_t rows, size_t cols, size_t stride) {\n    size_t i = 0;\n    __m256d vsrc;\n    for (; i <= rows - 4; i += 4) {\n        vsrc = _mm256_loadu_pd(&src[(i + 0) * cols + stride]);\n        _mm256_storeu_pd(&dst[i], vsrc);\n    }\n    for (; i < rows; ++i) {\n        dst[i] = src[i * cols + stride];\n    }\n}\n```"}
{"task_id": "SimdBench_2_AVX", "completion": "```cpp\nvoid strided_load_store_simd(const double *src, double *dst, size_t rows, size_t cols, size_t stride) {\n    size_t i = 0;\n    __m256d vsrc;\n    for (; i <= rows - 4; i += 4) {\n        vsrc = _mm256_loadu_pd(&src[(i + 0) * cols + stride]);\n        _mm256_storeu_pd(&dst[i], vsrc);\n    }\n    for (; i < rows; ++i) {\n        dst[i] = src[i * cols + stride];\n    }\n}\n```"}
{"task_id": "SimdBench_2_AVX", "completion": "```cpp\nvoid strided_load_store_simd(const double *src, double *dst, size_t rows, size_t cols, size_t stride) {\n    size_t i = 0;\n    __m256d vec_src;\n    for (; i <= rows - 4; i += 4) {\n        vec_src = _mm256_loadu_pd(&src[(i * cols) + stride]);\n        _mm256_storeu_pd(&dst[i], vec_src);\n    }\n    for (; i < rows; ++i) {\n        dst[i] = src[(i * cols) + stride];\n    }\n}\n```"}
{"task_id": "SimdBench_2_AVX", "completion": "```cpp\nvoid strided_load_store_simd(const double *src, double *dst, size_t rows, size_t cols, size_t stride) {\n    size_t i = 0;\n    __m256d vsrc;\n    for (; i <= rows - 4; i += 4) {\n        vsrc = _mm256_loadu_pd(&src[(i + 0) * cols + stride]);\n        _mm256_storeu_pd(&dst[i], vsrc);\n    }\n    for (; i < rows; ++i) {\n        dst[i] = src[i * cols + stride];\n    }\n}\n```"}
{"task_id": "SimdBench_2_AVX", "completion": "```cpp\nvoid strided_load_store_simd(const double *src, double *dst, size_t rows, size_t cols, size_t stride) {\n    size_t i = 0;\n    __m256d vsrc;\n    for (; i <= rows - 4; i += 4) {\n        vsrc = _mm256_loadu_pd(&src[(i + 0) * cols + stride]);\n        _mm256_storeu_pd(&dst[i], vsrc);\n    }\n    for (; i < rows; ++i) {\n        dst[i] = src[i * cols + stride];\n    }\n}\n```"}
{"task_id": "SimdBench_3_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid indexed_access_simd(const float *src, const int *indices, float *dst, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 8; i += 8) {\n        __m256i idx = _mm256_loadu_si256((__m256i const*)(indices + i));\n        __m256 gathered_values = _mm256_i32gather_ps(src, idx, 4);\n        _mm256_storeu_ps(dst + i, gathered_values);\n\n        __m256 scattered_values = _mm256_loadu_ps(src + i);\n        _mm256_i32scatter_ps(dst, idx, scattered_values, 4);\n    }\n\n    for (; i < length; ++i) {\n        dst[i] = src[indices[i]];\n        dst[indices[i]] = src[i];\n    }\n}\n```"}
{"task_id": "SimdBench_3_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid indexed_access_simd(const float *src, const int *indices, float *dst, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 8; i += 8) {\n        __m256i idx = _mm256_loadu_si256((__m256i const*)(indices + i));\n        __m256 gathered_values = _mm256_i32gather_ps(src, idx, 4);\n        _mm256_storeu_ps(dst + i, gathered_values);\n\n        __m256 scattered_values = _mm256_loadu_ps(src + i);\n        _mm256_i32scatter_ps(dst, idx, scattered_values, 4);\n    }\n\n    for (; i < length; ++i) {\n        dst[i] = src[indices[i]];\n        dst[indices[i]] = src[i];\n    }\n}\n```"}
{"task_id": "SimdBench_3_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid indexed_access_simd(const float *src, const int *indices, float *dst, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 8; i += 8) {\n        __m256i idx = _mm256_loadu_si256((__m256i const*)(indices + i));\n        __m256 gathered_values = _mm256_i32gather_ps(src, idx, 4);\n        _mm256_storeu_ps(dst + i, gathered_values);\n\n        __m256 scattered_values = _mm256_loadu_ps(src + i);\n        _mm256_i32scatter_ps(dst, idx, scattered_values, 4);\n    }\n\n    for (; i < length; ++i) {\n        dst[i] = src[indices[i]];\n        dst[indices[i]] = src[i];\n    }\n}\n```"}
{"task_id": "SimdBench_3_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid indexed_access_simd(const float *src, const int *indices, float *dst, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 8; i += 8) {\n        __m256i idx = _mm256_loadu_si256((__m256i const*)(indices + i));\n        __m256 gathered_values = _mm256_i32gather_ps(src, idx, 4);\n        _mm256_storeu_ps(dst + i, gathered_values);\n\n        __m256 scattered_values = _mm256_loadu_ps(src + i);\n        _mm256_i32scatter_ps(dst, idx, scattered_values, 4);\n    }\n\n    for (; i < length; ++i) {\n        dst[i] = src[indices[i]];\n        dst[indices[i]] = src[i];\n    }\n}\n```"}
{"task_id": "SimdBench_3_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid indexed_access_simd(const float *src, const int *indices, float *dst, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 8; i += 8) {\n        __m256i idx = _mm256_loadu_si256((__m256i const*)(indices + i));\n        __m256 gathered_values = _mm256_i32gather_ps(src, idx, 4);\n        _mm256_storeu_ps(dst + i, gathered_values);\n\n        __m256 scattered_values = _mm256_loadu_ps(src + i);\n        _mm256_i32scatter_ps(dst, idx, scattered_values, 4);\n    }\n\n    for (; i < length; ++i) {\n        dst[i] = src[indices[i]];\n        dst[indices[i]] = src[i];\n    }\n}\n```"}
{"task_id": "SimdBench_4_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid range_reverse_simd(int16_t *arr, uint64_t start, uint64_t end) {\n    while (start + 7 < end) {\n        __m128i vec1 = _mm_loadu_si128((__m128i*)&arr[start]);\n        __m128i vec2 = _mm_loadu_si128((__m128i*)&arr[end - 7]);\n\n        __m128i shuffled_vec1 = _mm_shuffle_epi8(vec1, _mm_setr_epi8(30, 31, 28, 29, 26, 27, 24, 25, 22, 23, 20, 21, 18, 19, 16, 17));\n        __m128i shuffled_vec2 = _mm_shuffle_epi8(vec2, _mm_setr_epi8(30, 31, 28, 29, 26, 27, 24, 25, 22, 23, 20, 21, 18, 19, 16, 17));\n\n        _mm_storeu_si128((__m128i*)&arr[start], shuffled_vec2);\n        _mm_storeu_si128((__m128i*)&arr[end - 7], shuffled_vec1);\n\n        start += 8;\n        end -= 8;\n    }\n\n    while (start < end) {\n        int16_t temp = arr[start];\n        arr[start] = arr[end];\n        arr[end] = temp;\n        start++;\n        end--;\n    }\n}\n```"}
{"task_id": "SimdBench_4_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid range_reverse_simd(int16_t *arr, uint64_t start, uint64_t end) {\n    while (start + 7 < end) {\n        __m256i vec1 = _mm256_loadu_si256((__m256i*)&arr[start]);\n        __m256i vec2 = _mm256_loadu_si256((__m256i*)&arr[end - 7]);\n\n        __m256i shuffled_vec1 = _mm256_permute4x64_epi64(_mm256_shufflehi_epi16(_mm256_shufflelo_epi16(vec1, _MM_SHUFFLE(0, 1, 2, 3)), _MM_SHUFFLE(0, 1, 2, 3)), _MM_SHUFFLE(3, 0, 1, 2));\n        __m256i shuffled_vec2 = _mm256_permute4x64_epi64(_mm256_shufflehi_epi16(_mm256_shufflelo_epi16(vec2, _MM_SHUFFLE(0, 1, 2, 3)), _MM_SHUFFLE(0, 1, 2, 3)), _MM_SHUFFLE(3, 0, 1, 2));\n\n        __m256i reversed_vec1 = _mm256_shuffle_epi8(shuffled_vec2, _mm256_setr_epi8(30, 31, 28, 29, 26, 27, 24, 25, 22, 23, 20, 21, 18, 19, 16, 17, 14, 15, 12, 13, 10, 11, 8, 9, 6, 7, 4, 5, 2, 3, 0, 1));\n        __m256i reversed_vec2 = _mm256_shuffle_epi8(shuffled_vec1, _mm256_setr_epi8(30, 31, 28, 29, 26, 27, 24, 25, 22, 23, 20, 21, 18, 19, 16, 17, 14, 15, 12, 13, 10, 11, 8, 9, 6, 7, 4, 5, 2, 3, 0, 1));\n\n        _mm256_storeu_si256((__m256i*)&arr[start], reversed_vec1);\n        _mm256_storeu_si256((__m256i*)&arr[end - 7], reversed_vec2);\n\n        start += 8;\n        end -= 8;\n    }\n\n    while (start < end) {\n        int16_t temp = arr[start];\n        arr[start] = arr[end];\n        arr[end] = temp;\n        start++;\n        end--;\n    }\n}\n```"}
{"task_id": "SimdBench_4_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid range_reverse_simd(int16_t *arr, uint64_t start, uint64_t end) {\n    while (start + 7 < end) {\n        __m256i vec1 = _mm256_loadu_si256((__m256i*)&arr[start]);\n        __m256i vec2 = _mm256_loadu_si256((__m256i*)&arr[end - 7]);\n\n        __m256i shuffled_vec1 = _mm256_permute4x64_epi64(_mm256_shufflehi_epi16(_mm256_shufflelo_epi16(vec1, _MM_SHUFFLE(0, 1, 2, 3)), _MM_SHUFFLE(0, 1, 2, 3)), 0b11011000);\n        __m256i shuffled_vec2 = _mm256_permute4x64_epi64(_mm256_shufflehi_epi16(_mm256_shufflelo_epi16(vec2, _MM_SHUFFLE(0, 1, 2, 3)), _MM_SHUFFLE(0, 1, 2, 3)), 0b11011000);\n\n        __m256i reversed_vec1 = _mm256_shuffle_epi8(shuffled_vec2, _mm256_setr_epi8(30, 31, 28, 29, 26, 27, 24, 25, 22, 23, 20, 21, 18, 19, 16, 17, 14, 15, 12, 13, 10, 11, 8, 9, 6, 7, 4, 5, 2, 3, 0, 1));\n        __m256i reversed_vec2 = _mm256_shuffle_epi8(shuffled_vec1, _mm256_setr_epi8(30, 31, 28, 29, 26, 27, 24, 25, 22, 23, 20, 21, 18, 19, 16, 17, 14, 15, 12, 13, 10, 11, 8, 9, 6, 7, 4, 5, 2, 3, 0, 1));\n\n        _mm256_storeu_si256((__m256i*)&arr[start], reversed_vec1);\n        _mm256_storeu_si256((__m256i*)&arr[end - 7], reversed_vec2);\n\n        start += 8;\n        end -= 8;\n    }\n\n    while (start < end) {\n        int16_t temp = arr[start];\n        arr[start] = arr[end];\n        arr[end] = temp;\n        start++;\n        end--;\n    }\n}\n```"}
{"task_id": "SimdBench_4_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid range_reverse_simd(int16_t *arr, uint64_t start, uint64_t end) {\n    while (start + 7 < end) {\n        __m256i vec1 = _mm256_loadu_si256((__m256i*)&arr[start]);\n        __m256i vec2 = _mm256_loadu_si256((__m256i*)&arr[end - 7]);\n\n        __m256i rev_vec1 = _mm256_shufflehi_epi16(_mm256_shufflelo_epi16(vec2, _MM_SHUFFLE(0, 1, 2, 3)), _MM_SHUFFLE(0, 1, 2, 3));\n        __m256i rev_vec2 = _mm256_shufflehi_epi16(_mm256_shufflelo_epi16(vec1, _MM_SHUFFLE(0, 1, 2, 3)), _MM_SHUFFLE(0, 1, 2, 3));\n\n        _mm256_storeu_si256((__m256i*)&arr[start], rev_vec1);\n        _mm256_storeu_si256((__m256i*)&arr[end - 7], rev_vec2);\n\n        start += 8;\n        end -= 8;\n    }\n\n    while (start < end) {\n        int16_t temp = arr[start];\n        arr[start] = arr[end];\n        arr[end] = temp;\n        start++;\n        end--;\n    }\n}\n```"}
{"task_id": "SimdBench_4_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid range_reverse_simd(int16_t *arr, uint64_t start, uint64_t end) {\n    while (start + 7 < end) {\n        __m256i vec1 = _mm256_loadu_si256((__m256i*)&arr[start]);\n        __m256i vec2 = _mm256_loadu_si256((__m256i*)&arr[end - 7]);\n\n        __m256i shuffled_vec1 = _mm256_permute4x64_epi64(vec1, 0xD8);\n        __m256i shuffled_vec2 = _mm256_permute4x64_epi64(vec2, 0xD8);\n\n        __m256i reversed_vec1 = _mm256_shufflehi_epi16(_mm256_shufflelo_epi16(shuffled_vec2, _MM_SHUFFLE(0, 1, 2, 3)), _MM_SHUFFLE(0, 1, 2, 3));\n        __m256i reversed_vec2 = _mm256_shufflehi_epi16(_mm256_shufflelo_epi16(shuffled_vec1, _MM_SHUFFLE(0, 1, 2, 3)), _MM_SHUFFLE(0, 1, 2, 3));\n\n        _mm256_storeu_si256((__m256i*)&arr[start], reversed_vec1);\n        _mm256_storeu_si256((__m256i*)&arr[end - 7], reversed_vec2);\n\n        start += 8;\n        end -= 8;\n    }\n\n    while (start < end) {\n        int16_t temp = arr[start];\n        arr[start] = arr[end];\n        arr[end] = temp;\n        start++;\n        end--;\n    }\n}\n```"}
{"task_id": "SimdBench_5_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid extract_tensor_slice_simd(const uint8_t *tensor, uint8_t *slice, size_t dim1, size_t dim2, size_t dim3, size_t slice_idx) {\n    size_t offset = slice_idx * dim2 * dim3;\n    size_t total_elements = dim2 * dim3;\n\n    for (size_t i = 0; i < total_elements; i += 32) {\n        __m256i vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(tensor + offset + i));\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(slice + i), vec);\n    }\n\n    // Handle remaining elements that are not multiples of 32\n    for (size_t i = (total_elements / 32) * 32; i < total_elements; ++i) {\n        slice[i] = tensor[offset + i];\n    }\n}\n```"}
{"task_id": "SimdBench_5_AVX", "completion": "```cpp\nvoid extract_tensor_slice_simd(const uint8_t *tensor, uint8_t *slice, size_t dim1, size_t dim2, size_t dim3, size_t slice_idx) {\n    size_t slice_offset = slice_idx * dim2 * dim3;\n    size_t total_elements = dim2 * dim3;\n\n    for (size_t i = 0; i < total_elements; i += 32) {\n        __m256i vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(tensor + slice_offset + i));\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(slice + i), vec);\n    }\n\n    // Handle remaining elements that are not multiples of 32\n    for (size_t i = (total_elements / 32) * 32; i < total_elements; ++i) {\n        slice[i] = tensor[slice_offset + i];\n    }\n}\n```"}
{"task_id": "SimdBench_5_AVX", "completion": "```cpp\nvoid extract_tensor_slice_simd(const uint8_t *tensor, uint8_t *slice, size_t dim1, size_t dim2, size_t dim3, size_t slice_idx) {\n    size_t slice_size = dim1 * dim2;\n    const uint8_t *src = tensor + slice_idx * slice_size;\n    size_t i = 0;\n\n    for (; i <= slice_size - 32; i += 32) {\n        __m256i data = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(src + i));\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(slice + i), data);\n    }\n\n    for (; i <= slice_size - 16; i += 16) {\n        __m128i data = _mm_loadu_si128(reinterpret_cast<const __m128i*>(src + i));\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(slice + i), data);\n    }\n\n    for (; i < slice_size; ++i) {\n        slice[i] = src[i];\n    }\n}\n```"}
{"task_id": "SimdBench_5_AVX", "completion": "```cpp\nvoid extract_tensor_slice_simd(const uint8_t *tensor, uint8_t *slice, size_t dim1, size_t dim2, size_t dim3, size_t slice_idx) {\n    size_t slice_size = dim1 * dim2;\n    const uint8_t *src = tensor + slice_idx * slice_size;\n    size_t i = 0;\n\n    for (; i <= slice_size - 32; i += 32) {\n        __m256i vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(src + i));\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(slice + i), vec);\n    }\n\n    for (; i <= slice_size - 16; i += 16) {\n        __m128i vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(src + i));\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(slice + i), vec);\n    }\n\n    for (; i < slice_size; ++i) {\n        slice[i] = src[i];\n    }\n}\n```"}
{"task_id": "SimdBench_5_AVX", "completion": "```cpp\nvoid extract_tensor_slice_simd(const uint8_t *tensor, uint8_t *slice, size_t dim1, size_t dim2, size_t dim3, size_t slice_idx) {\n    size_t slice_offset = slice_idx * dim2 * dim3;\n    size_t total_elements = dim2 * dim3;\n\n    for (size_t i = 0; i < total_elements; i += 32) {\n        __m256i vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(tensor + slice_offset + i));\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(slice + i), vec);\n    }\n\n    // Handle remaining elements that do not fit into a full AVX vector\n    for (size_t i = (total_elements / 32) * 32; i < total_elements; ++i) {\n        slice[i] = tensor[slice_offset + i];\n    }\n}\n```"}
{"task_id": "SimdBench_6_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid blocked_matrix_transpose_simd(const int16_t *src, int16_t *dst, size_t rows, size_t cols, size_t block_size) {\n    for (size_t i = 0; i < rows; i += block_size) {\n        for (size_t j = 0; j < cols; j += block_size) {\n            for (size_t bi = 0; bi < block_size && i + bi < rows; ++bi) {\n                for (size_t bj = 0; bj < block_size && j + bj < cols; bj += 8) {\n                    __m256i vec = _mm256_loadu_si256((__m256i const*)(src + (i + bi) * cols + j + bj));\n                    _mm256_storeu_si256((__m256i*)(dst + (j + bj) * rows + i + bi), vec);\n                }\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_6_AVX", "completion": "```cpp\nvoid blocked_matrix_transpose_simd(const int16_t *src, int16_t *dst, size_t rows, size_t cols, size_t block_size) {\n    for (size_t i = 0; i < rows; i += block_size) {\n        for (size_t j = 0; j < cols; j += block_size) {\n            for (size_t bi = 0; bi < block_size && i + bi < rows; ++bi) {\n                for (size_t bj = 0; bj < block_size && j + bj < cols; bj += 8) {\n                    __m256i vec = _mm256_loadu_si256((__m256i const*)(src + (i + bi) * cols + j + bj));\n                    _mm256_storeu_si256((__m256i*)(dst + (j + bj) * rows + i + bi), vec);\n                }\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_6_AVX", "completion": "```cpp\nvoid blocked_matrix_transpose_simd(const int16_t *src, int16_t *dst, size_t rows, size_t cols, size_t block_size) {\n    for (size_t i = 0; i < rows; i += block_size) {\n        for (size_t j = 0; j < cols; j += block_size) {\n            for (size_t bi = 0; bi < block_size && i + bi < rows; ++bi) {\n                for (size_t bj = 0; bj < block_size && j + bj < cols; bj += 8) {\n                    __m256i vec = _mm256_loadu_si256((__m256i const*)(src + (i + bi) * cols + j + bj));\n                    _mm256_storeu_si256((__m256i*)(dst + (j + bj) * rows + i + bi), vec);\n                }\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_6_AVX", "completion": "```cpp\nvoid blocked_matrix_transpose_simd(const int16_t *src, int16_t *dst, size_t rows, size_t cols, size_t block_size) {\n    for (size_t i = 0; i < rows; i += block_size) {\n        for (size_t j = 0; j < cols; j += block_size) {\n            for (size_t bi = 0; bi < block_size && i + bi < rows; ++bi) {\n                for (size_t bj = 0; bj < block_size && j + bj < cols; bj += 8) {\n                    __m256i vec = _mm256_loadu_si256((__m256i const*)(src + (i + bi) * cols + j + bj));\n                    _mm256_storeu_si256((__m256i*)(dst + (j + bj) * rows + i + bi), vec);\n                }\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_6_AVX", "completion": "```cpp\nvoid blocked_matrix_transpose_simd(const int16_t *src, int16_t *dst, size_t rows, size_t cols, size_t block_size) {\n    for (size_t i = 0; i < rows; i += block_size) {\n        for (size_t j = 0; j < cols; j += block_size) {\n            for (size_t bi = 0; bi < block_size && i + bi < rows; ++bi) {\n                for (size_t bj = 0; bj < block_size && j + bj < cols; bj += 8) {\n                    __m256i vec = _mm256_loadu_si256((__m256i const*)(src + (i + bi) * cols + j + bj));\n                    _mm256_storeu_si256((__m256i*)(dst + (j + bj) * rows + i + bi), vec);\n                }\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_7_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nfloat diagonal_sum_3d_simd(const float *array, size_t dim) {\n    __m256 sum = _mm256_setzero_ps();\n    size_t i = 0;\n\n    for (; i <= dim - 8; i += 8) {\n        size_t index = i * dim * dim + i * dim + i;\n        __m256 values = _mm256_loadu_ps(&array[index]);\n        sum = _mm256_add_ps(sum, values);\n    }\n\n    float result[8];\n    _mm256_storeu_ps(result, sum);\n\n    float total_sum = result[0] + result[1] + result[2] + result[3] + result[4] + result[5] + result[6] + result[7];\n\n    for (; i < dim; ++i) {\n        size_t index = i * dim * dim + i * dim + i;\n        total_sum += array[index];\n    }\n\n    return total_sum;\n}\n```"}
{"task_id": "SimdBench_7_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nfloat diagonal_sum_3d_simd(const float *array, size_t dim) {\n    __m256 sum_vec = _mm256_setzero_ps();\n    size_t i = 0;\n\n    for (; i <= dim - 8; i += 8) {\n        size_t index = i * dim * dim + i * dim + i;\n        __m256 values = _mm256_loadu_ps(&array[index]);\n        sum_vec = _mm256_add_ps(sum_vec, values);\n    }\n\n    float sum_arr[8];\n    _mm256_storeu_ps(sum_arr, sum_vec);\n    float sum = sum_arr[0] + sum_arr[1] + sum_arr[2] + sum_arr[3] + sum_arr[4] + sum_arr[5] + sum_arr[6] + sum_arr[7];\n\n    for (; i < dim; ++i) {\n        size_t index = i * dim * dim + i * dim + i;\n        sum += array[index];\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_7_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nfloat diagonal_sum_3d_simd(const float *array, size_t dim) {\n    __m256 sum_vec = _mm256_setzero_ps();\n    size_t i = 0;\n\n    for (; i <= dim - 8; i += 8) {\n        size_t index = i * dim * dim + i * dim + i;\n        __m256 values = _mm256_loadu_ps(&array[index]);\n        sum_vec = _mm256_add_ps(sum_vec, values);\n    }\n\n    float sum_array[8];\n    _mm256_storeu_ps(sum_array, sum_vec);\n    float sum = sum_array[0] + sum_array[1] + sum_array[2] + sum_array[3] +\n                sum_array[4] + sum_array[5] + sum_array[6] + sum_array[7];\n\n    for (; i < dim; ++i) {\n        size_t index = i * dim * dim + i * dim + i;\n        sum += array[index];\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_7_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nfloat diagonal_sum_3d_simd(const float *array, size_t dim) {\n    __m256 sum = _mm256_setzero_ps();\n    size_t i = 0;\n\n    for (; i <= dim - 8; i += 8) {\n        __m256 values = _mm256_loadu_ps(&array[i * dim * dim + i * dim + i]);\n        sum = _mm256_add_ps(sum, values);\n    }\n\n    float result[8];\n    _mm256_storeu_ps(result, sum);\n\n    float total_sum = result[0] + result[1] + result[2] + result[3] + result[4] + result[5] + result[6] + result[7];\n\n    for (; i < dim; ++i) {\n        total_sum += array[i * dim * dim + i * dim + i];\n    }\n\n    return total_sum;\n}\n```"}
{"task_id": "SimdBench_7_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nfloat diagonal_sum_3d_simd(const float *array, size_t dim) {\n    __m256 sum_vec = _mm256_setzero_ps();\n    size_t i = 0;\n\n    for (; i <= dim - 8; i += 8) {\n        size_t index = i * dim * dim + i * dim + i;\n        __m256 values = _mm256_loadu_ps(&array[index]);\n        sum_vec = _mm256_add_ps(sum_vec, values);\n    }\n\n    float sum_array[8];\n    _mm256_storeu_ps(sum_array, sum_vec);\n    float sum = sum_array[0] + sum_array[1] + sum_array[2] + sum_array[3] +\n                sum_array[4] + sum_array[5] + sum_array[6] + sum_array[7];\n\n    for (; i < dim; ++i) {\n        size_t index = i * dim * dim + i * dim + i;\n        sum += array[index];\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_8_AVX", "completion": "```cpp\nvoid conditional_scale_simd(const double *src, double *dst, size_t rows, size_t cols, double threshold, double scale) {\n    __m256d v_threshold = _mm256_set1_pd(threshold);\n    __m256d v_scale = _mm256_set1_pd(scale);\n\n    for (size_t i = 0; i < rows; ++i) {\n        for (size_t j = 0; j < cols; j += 4) {\n            __m256d v_src = _mm256_loadu_pd(&src[i * cols + j]);\n            __m256d v_mask = _mm256_cmp_pd(v_src, v_threshold, _CMP_GT_OS);\n            __m256d v_scaled = _mm256_mul_pd(v_src, v_scale);\n            __m256d v_result = _mm256_blendv_pd(v_src, v_scaled, v_mask);\n            _mm256_storeu_pd(&dst[i * cols + j], v_result);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_8_AVX", "completion": "```cpp\nvoid conditional_scale_simd(const double *src, double *dst, size_t rows, size_t cols, double threshold, double scale) {\n    __m256d v_threshold = _mm256_set1_pd(threshold);\n    __m256d v_scale = _mm256_set1_pd(scale);\n\n    for (size_t i = 0; i < rows; ++i) {\n        for (size_t j = 0; j < cols; j += 4) {\n            __m256d v_src = _mm256_loadu_pd(&src[i * cols + j]);\n            __m256d v_mask = _mm256_cmp_pd(v_src, v_threshold, _CMP_GT_OS);\n            __m256d v_scaled = _mm256_mul_pd(v_src, v_scale);\n            __m256d v_result = _mm256_blendv_pd(v_src, v_scaled, v_mask);\n            _mm256_storeu_pd(&dst[i * cols + j], v_result);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_8_AVX", "completion": "```cpp\nvoid conditional_scale_simd(const double *src, double *dst, size_t rows, size_t cols, double threshold, double scale) {\n    __m256d v_threshold = _mm256_set1_pd(threshold);\n    __m256d v_scale = _mm256_set1_pd(scale);\n\n    for (size_t i = 0; i < rows; ++i) {\n        for (size_t j = 0; j < cols; j += 4) {\n            __m256d v_src = _mm256_loadu_pd(&src[i * cols + j]);\n            __m256d v_mask = _mm256_cmp_pd(v_src, v_threshold, _CMP_GT_OS);\n            __m256d v_scaled = _mm256_mul_pd(v_src, v_scale);\n            __m256d v_result = _mm256_blendv_pd(v_src, v_scaled, v_mask);\n            _mm256_storeu_pd(&dst[i * cols + j], v_result);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_8_AVX", "completion": "```cpp\nvoid conditional_scale_simd(const double *src, double *dst, size_t rows, size_t cols, double threshold, double scale) {\n    __m256d v_threshold = _mm256_set1_pd(threshold);\n    __m256d v_scale = _mm256_set1_pd(scale);\n\n    for (size_t i = 0; i < rows; ++i) {\n        for (size_t j = 0; j < cols; j += 4) {\n            __m256d v_src = _mm256_loadu_pd(&src[i * cols + j]);\n            __m256d v_mask = _mm256_cmp_pd(v_src, v_threshold, _CMP_GT_OS);\n            __m256d v_scaled = _mm256_mul_pd(v_src, v_scale);\n            __m256d v_result = _mm256_blendv_pd(v_src, v_scaled, v_mask);\n            _mm256_storeu_pd(&dst[i * cols + j], v_result);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_8_AVX", "completion": "```cpp\nvoid conditional_scale_simd(const double *src, double *dst, size_t rows, size_t cols, double threshold, double scale) {\n    __m256d v_threshold = _mm256_set1_pd(threshold);\n    __m256d v_scale = _mm256_set1_pd(scale);\n\n    for (size_t i = 0; i < rows; ++i) {\n        for (size_t j = 0; j < cols; j += 4) {\n            __m256d v_src = _mm256_loadu_pd(&src[i * cols + j]);\n            __m256d v_mask = _mm256_cmp_pd(v_src, v_threshold, _CMP_GT_OS);\n            __m256d v_scaled = _mm256_mul_pd(v_src, v_scale);\n            __m256d v_result = _mm256_blendv_pd(v_src, v_scaled, v_mask);\n            _mm256_storeu_pd(&dst[i * cols + j], v_result);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_9_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid reorder_matrix_rows_simd(const double *src, double *dst, size_t rows, size_t cols, const size_t *indices) {\n    for (size_t i = 0; i < rows; ++i) {\n        size_t idx = indices[i];\n        for (size_t j = 0; j < cols; j += 4) {\n            __m256d src_vec = _mm256_loadu_pd(&src[idx * cols + j]);\n            _mm256_storeu_pd(&dst[i * cols + j], src_vec);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_9_AVX", "completion": "```cpp\nvoid reorder_matrix_rows_simd(const double *src, double *dst, size_t rows, size_t cols, const size_t *indices) {\n    for (size_t i = 0; i < rows; ++i) {\n        size_t idx = indices[i];\n        for (size_t j = 0; j < cols; j += 4) {\n            __m256d row = _mm256_loadu_pd(&src[idx * cols + j]);\n            _mm256_storeu_pd(&dst[i * cols + j], row);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_9_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid reorder_matrix_rows_simd(const double *src, double *dst, size_t rows, size_t cols, const size_t *indices) {\n    for (size_t i = 0; i < rows; ++i) {\n        size_t idx = indices[i];\n        for (size_t j = 0; j < cols; j += 4) {\n            __m256d row = _mm256_loadu_pd(&src[idx * cols + j]);\n            _mm256_storeu_pd(&dst[i * cols + j], row);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_9_AVX", "completion": "```cpp\nvoid reorder_matrix_rows_simd(const double *src, double *dst, size_t rows, size_t cols, const size_t *indices) {\n    for (size_t i = 0; i < rows; ++i) {\n        size_t idx = indices[i];\n        for (size_t j = 0; j < cols; j += 4) {\n            __m256d row = _mm256_loadu_pd(&src[idx * cols + j]);\n            _mm256_storeu_pd(&dst[i * cols + j], row);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_9_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid reorder_matrix_rows_simd(const double *src, double *dst, size_t rows, size_t cols, const size_t *indices) {\n    for (size_t i = 0; i < rows; ++i) {\n        size_t idx = indices[i];\n        for (size_t j = 0; j < cols; j += 4) {\n            __m256d row = _mm256_loadu_pd(&src[idx * cols + j]);\n            _mm256_storeu_pd(&dst[i * cols + j], row);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_10_AVX", "completion": "```cpp\nvoid vector_vector_add_simd(const int64_t *src1, const int64_t *src2, int64_t *dst, int64_t scalar, size_t length) {\n    __m256i scalar_vec = _mm256_set1_epi64x(scalar);\n    size_t i;\n    for (i = 0; i <= length - 4; i += 4) {\n        __m256i vec1 = _mm256_loadu_si256((__m256i const*)(src1 + i));\n        __m256i vec2 = _mm256_loadu_si256((__m256i const*)(src2 + i));\n        __m256i sum = _mm256_add_epi64(vec1, vec2);\n        __m256i result = _mm256_add_epi64(sum, scalar_vec);\n        result = _mm256_srli_epi64(result, 1);\n        _mm256_storeu_si256((__m256i*)(dst + i), result);\n    }\n    for (; i < length; ++i) {\n        dst[i] = (src1[i] + src2[i] + scalar) / 2;\n    }\n}\n```"}
{"task_id": "SimdBench_10_AVX", "completion": "```cpp\nvoid vector_vector_add_simd(const int64_t *src1, const int64_t *src2, int64_t *dst, int64_t scalar, size_t length) {\n    __m256i scalar_vec = _mm256_set1_epi64x(scalar);\n    size_t i;\n    for (i = 0; i <= length - 4; i += 4) {\n        __m256i vec1 = _mm256_loadu_si256((__m256i const *)(src1 + i));\n        __m256i vec2 = _mm256_loadu_si256((__m256i const *)(src2 + i));\n        __m256i sum = _mm256_add_epi64(vec1, vec2);\n        __m256i result = _mm256_add_epi64(sum, scalar_vec);\n        result = _mm256_srli_epi64(result, 1);\n        _mm256_storeu_si256((__m256i *)(dst + i), result);\n    }\n    for (; i < length; ++i) {\n        dst[i] = (src1[i] + src2[i] + scalar) / 2;\n    }\n}\n```"}
{"task_id": "SimdBench_10_AVX", "completion": "```cpp\nvoid vector_vector_add_simd(const int64_t *src1, const int64_t *src2, int64_t *dst, int64_t scalar, size_t length) {\n    __m256i scalar_vec = _mm256_set1_epi64x(scalar);\n    size_t i;\n    for (i = 0; i <= length - 4; i += 4) {\n        __m256i vec1 = _mm256_loadu_si256((__m256i const*)(src1 + i));\n        __m256i vec2 = _mm256_loadu_si256((__m256i const*)(src2 + i));\n        __m256i sum = _mm256_add_epi64(vec1, vec2);\n        __m256i result = _mm256_add_epi64(sum, scalar_vec);\n        result = _mm256_srai_epi64(result, 1);\n        _mm256_storeu_si256((__m256i*)(dst + i), result);\n    }\n    for (; i < length; ++i) {\n        dst[i] = (src1[i] + src2[i] + scalar) / 2;\n    }\n}\n```"}
{"task_id": "SimdBench_10_AVX", "completion": "```cpp\nvoid vector_vector_add_simd(const int64_t *src1, const int64_t *src2, int64_t *dst, int64_t scalar, size_t length) {\n    __m256i scalar_vec = _mm256_set1_epi64x(scalar);\n    size_t i;\n    for (i = 0; i <= length - 4; i += 4) {\n        __m256i vec1 = _mm256_loadu_si256((__m256i const*)(src1 + i));\n        __m256i vec2 = _mm256_loadu_si256((__m256i const*)(src2 + i));\n        __m256i sum = _mm256_add_epi64(vec1, vec2);\n        __m256i result = _mm256_add_epi64(sum, scalar_vec);\n        result = _mm256_srai_epi64(result, 1);\n        _mm256_storeu_si256((__m256i*)(dst + i), result);\n    }\n    for (; i < length; ++i) {\n        dst[i] = (src1[i] + src2[i] + scalar) / 2;\n    }\n}\n```"}
{"task_id": "SimdBench_10_AVX", "completion": "```cpp\nvoid vector_vector_add_simd(const int64_t *src1, const int64_t *src2, int64_t *dst, int64_t scalar, size_t length) {\n    __m256i scalar_vec = _mm256_set1_epi64x(scalar);\n    size_t i;\n    for (i = 0; i <= length - 4; i += 4) {\n        __m256i vec1 = _mm256_loadu_si256((__m256i const *)(src1 + i));\n        __m256i vec2 = _mm256_loadu_si256((__m256i const *)(src2 + i));\n        __m256i sum = _mm256_add_epi64(vec1, vec2);\n        __m256i result = _mm256_add_epi64(sum, scalar_vec);\n        result = _mm256_srli_epi64(result, 1);\n        _mm256_storeu_si256((__m256i *)(dst + i), result);\n    }\n    for (; i < length; ++i) {\n        dst[i] = (src1[i] + src2[i] + scalar) / 2;\n    }\n}\n```"}
{"task_id": "SimdBench_11_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nint vector_even_min_simd(const int *src, size_t length) {\n    if (length == 0) return -1;\n\n    __m256i min_vec = _mm256_set1_epi32(INT_MAX);\n    size_t i = 0;\n\n    // Process 8 elements at a time\n    for (; i <= length - 8; i += 8) {\n        __m256i data = _mm256_loadu_si256((__m256i const*)(src + i));\n        __m256i even_data = _mm256_and_si256(data, _mm256_set_epi32(0, 1, 0, 1, 0, 1, 0, 1));\n        min_vec = _mm256_min_epi32(min_vec, even_data);\n    }\n\n    // Handle remaining elements\n    int min_array[8];\n    _mm256_storeu_si256((__m256i*)min_array, min_vec);\n    int min_val = INT_MAX;\n    for (size_t j = 0; j < 8; ++j) {\n        if (min_array[j] < min_val) min_val = min_array[j];\n    }\n\n    // Check remaining elements that were not processed in the loop\n    for (; i < length; i += 2) {\n        if (src[i] < min_val) min_val = src[i];\n    }\n\n    return min_val;\n}\n```"}
{"task_id": "SimdBench_11_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nint vector_even_min_simd(const int *src, size_t length) {\n    if (length == 0) return -1;\n\n    __m256i min_vec = _mm256_set1_epi32(INT_MAX);\n    size_t i = 0;\n\n    for (; i <= length - 8; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i const*)(src + i));\n        __m256i even_vec = _mm256_and_si256(vec, _mm256_set1_epi32(0xFFFFFFFE));\n        min_vec = _mm256_min_epi32(min_vec, even_vec);\n    }\n\n    int min_values[8];\n    _mm256_storeu_si256((__m256i*)min_values, min_vec);\n\n    int min_val = INT_MAX;\n    for (size_t j = 0; j < 8; ++j) {\n        if (min_values[j] < min_val) {\n            min_val = min_values[j];\n        }\n    }\n\n    for (; i < length; ++i) {\n        if (src[i] < min_val && (i % 2 == 0)) {\n            min_val = src[i];\n        }\n    }\n\n    return min_val;\n}\n```"}
{"task_id": "SimdBench_11_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nint vector_even_min_simd(const int *src, size_t length) {\n    if (length == 0) return -1;\n\n    __m256i min_vec = _mm256_set1_epi32(INT_MAX);\n    size_t i = 0;\n\n    // Process 8 elements at a time\n    for (; i <= length - 8; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i const*)(src + i));\n        __m256i even_vec = _mm256_and_si256(vec, _mm256_set1_epi32(0xFFFFFFFE));\n        min_vec = _mm256_min_epi32(min_vec, even_vec);\n    }\n\n    // Find the minimum in the min_vec\n    int min_array[8];\n    _mm256_storeu_si256((__m256i*)min_array, min_vec);\n    int min_val = min_array[0];\n    for (size_t j = 1; j < 8; ++j) {\n        if (min_array[j] < min_val) min_val = min_array[j];\n    }\n\n    // Check remaining elements\n    for (; i < length; ++i) {\n        if (src[i] < min_val && (src[i] % 2 == 0)) min_val = src[i];\n    }\n\n    return min_val;\n}\n```"}
{"task_id": "SimdBench_11_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nint vector_even_min_simd(const int *src, size_t length) {\n    if (length == 0) return -1;\n\n    __m256i min_vec = _mm256_set1_epi32(INT_MAX);\n    size_t i = 0;\n\n    for (; i <= length - 8; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i const*)(src + i));\n        __m256i even_vec = _mm256_and_si256(vec, _mm256_set1_epi32(0xFFFFFFFE));\n        min_vec = _mm256_min_epi32(min_vec, even_vec);\n    }\n\n    int min_array[8];\n    _mm256_storeu_si256((__m256i*)min_array, min_vec);\n\n    int min_val = INT_MAX;\n    for (size_t j = 0; j < 8; ++j) {\n        if (min_array[j] < min_val) {\n            min_val = min_array[j];\n        }\n    }\n\n    for (; i < length; ++i) {\n        if (src[i] < min_val && (i % 2 == 0)) {\n            min_val = src[i];\n        }\n    }\n\n    return min_val;\n}\n```"}
{"task_id": "SimdBench_11_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nint vector_even_min_simd(const int *src, size_t length) {\n    if (length == 0) return -1;\n\n    __m256i min_vec = _mm256_set1_epi32(INT_MAX);\n    size_t i = 0;\n\n    for (; i <= length - 8; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i const*)(src + i));\n        __m256i even_vec = _mm256_and_si256(vec, _mm256_set1_epi32(0xFFFFFFFE));\n        min_vec = _mm256_min_epi32(min_vec, even_vec);\n    }\n\n    int min_values[8];\n    _mm256_storeu_si256((__m256i*)min_values, min_vec);\n\n    int min_result = INT_MAX;\n    for (size_t j = 0; j < 8; ++j) {\n        if (min_values[j] < min_result) {\n            min_result = min_values[j];\n        }\n    }\n\n    for (; i < length; ++i) {\n        if (src[i] < min_result && (i % 2 == 0)) {\n            min_result = src[i];\n        }\n    }\n\n    return min_result;\n}\n```"}
{"task_id": "SimdBench_12_AVX", "completion": "```cpp\nvoid mixed_right_shift_simd(const int *src, int *dst, uint8_t shift, size_t length) {\n    size_t i = 0;\n    __m256i shift_mask = _mm256_set1_epi32(shift);\n    __m256i zero = _mm256_setzero_si256();\n\n    for (; i <= length - 8; i += 8) {\n        __m256i src_vec = _mm256_loadu_si256((__m256i const*)(src + i));\n        __m256i arith_shift = _mm256_srai_epi32(src_vec, shift);\n        __m256i logic_shift = _mm256_srli_epi32(_mm256_castsi256_si256(_mm256_cvtepi32_epi64(src_vec)), shift);\n        logic_shift = _mm256_castsi128_si256(_mm256_cvtepi32_epi64(_mm256_castsi256_si128(logic_shift)));\n        __m256i result = _mm256_add_epi32(arith_shift, logic_shift);\n        _mm256_storeu_si256((__m256i*)(dst + i), result);\n    }\n\n    for (; i < length; ++i) {\n        int arith_shift = src[i] >> shift;\n        int logic_shift = (unsigned int)src[i] >> shift;\n        dst[i] = arith_shift + logic_shift;\n    }\n}\n```"}
{"task_id": "SimdBench_12_AVX", "completion": "```cpp\nvoid mixed_right_shift_simd(const int *src, int *dst, uint8_t shift, size_t length) {\n    size_t i = 0;\n    __m256i zero = _mm256_setzero_si256();\n    __m256i shift_mask = _mm256_set1_epi32(shift);\n\n    for (; i <= length - 8; i += 8) {\n        __m256i src_vec = _mm256_loadu_si256((__m256i const*)(src + i));\n\n        // Arithmetic right shift\n        __m256i arith_shift = _mm256_srai_epi32(src_vec, shift);\n\n        // Logical right shift\n        __m256i logic_shift = _mm256_srli_epi32(_mm256_castsi256_si256(_mm256_cvtepi32_epi64(src_vec)), shift);\n        logic_shift = _mm256_castsi128_si256(_mm256_cvtepi64_epi32(logic_shift));\n\n        // Add the results\n        __m256i result = _mm256_add_epi32(arith_shift, logic_shift);\n\n        _mm256_storeu_si256((__m256i*)(dst + i), result);\n    }\n\n    // Handle remaining elements\n    for (; i < length; ++i) {\n        int arith_shift = src[i] >> shift;\n        unsigned int logic_shift = (unsigned int)src[i] >> shift;\n        dst[i] = arith_shift + (int)logic_shift;\n    }\n}\n```"}
{"task_id": "SimdBench_12_AVX", "completion": "```cpp\nvoid mixed_right_shift_simd(const int *src, int *dst, uint8_t shift, size_t length) {\n    size_t i = 0;\n    __m256i vshift = _mm256_set1_epi32(shift);\n    for (; i <= length - 8; i += 8) {\n        __m256i vsrc = _mm256_loadu_si256((__m256i const*)(src + i));\n        __m256i varith_shift = _mm256_srai_epi32(vsrc, shift);\n        __m256i vlogic_shift = _mm256_srli_epi32(_mm256_castsi256_si256(_mm256_cvtepi32_epi64(vsrc)), shift);\n        __m256i vresult = _mm256_add_epi32(varith_shift, vlogic_shift);\n        _mm256_storeu_si256((__m256i*)(dst + i), vresult);\n    }\n    for (; i < length; ++i) {\n        int varith_shift = src[i] >> shift;\n        int vlogic_shift = (unsigned int)src[i] >> shift;\n        dst[i] = varith_shift + vlogic_shift;\n    }\n}\n```"}
{"task_id": "SimdBench_12_AVX", "completion": "```cpp\nvoid mixed_right_shift_simd(const int *src, int *dst, uint8_t shift, size_t length) {\n    size_t i = 0;\n    __m256i zero = _mm256_setzero_si256();\n    __m256i shift_mask = _mm256_set1_epi32(shift);\n\n    for (; i <= length - 8; i += 8) {\n        __m256i src_vec = _mm256_loadu_si256((__m256i const*)(src + i));\n\n        // Arithmetic right shift\n        __m256i arith_shifted = _mm256_srai_epi32(src_vec, shift);\n\n        // Logical right shift\n        __m256i logic_shifted = _mm256_srli_epi32(src_vec, shift);\n\n        // Add the results\n        __m256i result = _mm256_add_epi32(arith_shifted, logic_shifted);\n\n        // Store the result\n        _mm256_storeu_si256((__m256i*)(dst + i), result);\n    }\n\n    // Handle remaining elements\n    for (; i < length; ++i) {\n        int arith_shifted = src[i] >> shift;\n        int logic_shifted = (unsigned int)src[i] >> shift;\n        dst[i] = arith_shifted + logic_shifted;\n    }\n}\n```"}
{"task_id": "SimdBench_12_AVX", "completion": "```cpp\nvoid mixed_right_shift_simd(const int *src, int *dst, uint8_t shift, size_t length) {\n    size_t i = 0;\n    __m256i shift_mask = _mm256_set1_epi32(shift);\n    __m256i zero = _mm256_setzero_si256();\n\n    for (; i <= length - 8; i += 8) {\n        __m256i src_vec = _mm256_loadu_si256((__m256i const*)(src + i));\n        __m256i arith_shift = _mm256_srai_epi32(src_vec, shift);\n        __m256i logic_shift = _mm256_srli_epi32(_mm256_castsi256_si256(_mm256_cvtepi32_epi64(src_vec)), shift);\n        logic_shift = _mm256_castsi128_si256(_mm256_cvtepi32_epi64(_mm256_castsi256_si128(logic_shift)));\n        __m256i result = _mm256_add_epi32(arith_shift, logic_shift);\n        _mm256_storeu_si256((__m256i*)(dst + i), result);\n    }\n\n    for (; i < length; ++i) {\n        int arith_shift = src[i] >> shift;\n        unsigned int logic_shift = (unsigned int)src[i] >> shift;\n        dst[i] = arith_shift + (int)logic_shift;\n    }\n}\n```"}
{"task_id": "SimdBench_13_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nint64_t matrix_sum_simd(const int *matrix, size_t rows, size_t cols) {\n    __m256i sum_vec = _mm256_setzero_si256();\n    size_t total_elements = rows * cols;\n    size_t i = 0;\n\n    for (; i <= total_elements - 8; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i const*)(matrix + i));\n        sum_vec = _mm256_add_epi32(sum_vec, vec);\n    }\n\n    int32_t sum_array[8];\n    _mm256_storeu_si256((__m256i*)sum_array, sum_vec);\n\n    int64_t sum = 0;\n    for (size_t j = 0; j < 8; ++j) {\n        sum += sum_array[j];\n    }\n\n    for (; i < total_elements; ++i) {\n        sum += matrix[i];\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_13_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nint64_t matrix_sum_simd(const int *matrix, size_t rows, size_t cols) {\n    __m256i sum_vec = _mm256_setzero_si256();\n    size_t total_elements = rows * cols;\n    size_t i = 0;\n\n    for (; i <= total_elements - 8; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i const*)(matrix + i));\n        sum_vec = _mm256_add_epi32(sum_vec, vec);\n    }\n\n    int32_t sum_array[8];\n    _mm256_storeu_si256((__m256i*)sum_array, sum_vec);\n\n    int64_t sum = 0;\n    for (size_t j = 0; j < 8; ++j) {\n        sum += sum_array[j];\n    }\n\n    for (; i < total_elements; ++i) {\n        sum += matrix[i];\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_13_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nint64_t matrix_sum_simd(const int *matrix, size_t rows, size_t cols) {\n    __m256i sum_vec = _mm256_setzero_si256();\n    size_t total_elements = rows * cols;\n    size_t i = 0;\n\n    for (; i <= total_elements - 8; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i const*)(matrix + i));\n        sum_vec = _mm256_add_epi32(sum_vec, vec);\n    }\n\n    __m128i sum_vec128 = _mm_add_epi32(_mm256_extracti128_si256(sum_vec, 0), _mm256_extracti128_si256(sum_vec, 1));\n    __m128i sum_vec64 = _mm_add_epi32(sum_vec128, _mm_srli_si128(sum_vec128, 8));\n    __m128i sum_vec32 = _mm_add_epi32(sum_vec64, _mm_srli_si128(sum_vec64, 4));\n\n    int32_t sum_array[8];\n    _mm_storeu_si128((__m128i*)sum_array, sum_vec32);\n\n    int64_t sum = sum_array[0];\n\n    for (; i < total_elements; ++i) {\n        sum += matrix[i];\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_13_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nint64_t matrix_sum_simd(const int *matrix, size_t rows, size_t cols) {\n    __m256i sum = _mm256_setzero_si256();\n    size_t total_elements = rows * cols;\n    size_t i = 0;\n\n    for (; i <= total_elements - 8; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i const*)(matrix + i));\n        sum = _mm256_add_epi32(sum, vec);\n    }\n\n    __m128i sum128 = _mm_add_epi32(_mm256_extracti128_si256(sum, 0), _mm256_extracti128_si256(sum, 1));\n    sum128 = _mm_add_epi32(sum128, _mm_srli_si128(sum128, 8));\n    sum128 = _mm_add_epi32(sum128, _mm_srli_si128(sum128, 4));\n\n    int32_t result = _mm_cvtsi128_si32(sum128);\n\n    for (; i < total_elements; ++i) {\n        result += matrix[i];\n    }\n\n    return static_cast<int64_t>(result);\n}\n```"}
{"task_id": "SimdBench_13_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nint64_t matrix_sum_simd(const int *matrix, size_t rows, size_t cols) {\n    __m256i sum = _mm256_setzero_si256();\n    size_t total_elements = rows * cols;\n    size_t i = 0;\n\n    for (; i <= total_elements - 8; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i const*)(matrix + i));\n        sum = _mm256_add_epi32(sum, vec);\n    }\n\n    __m128i sum128 = _mm_add_epi32(_mm256_extracti128_si256(sum, 0), _mm256_extracti128_si256(sum, 1));\n    sum128 = _mm_add_epi32(sum128, _mm_srli_si128(sum128, 8));\n    sum128 = _mm_add_epi32(sum128, _mm_srli_si128(sum128, 4));\n\n    int32_t result = _mm_cvtsi128_si32(sum128);\n\n    for (; i < total_elements; ++i) {\n        result += matrix[i];\n    }\n\n    return static_cast<int64_t>(result);\n}\n```"}
{"task_id": "SimdBench_14_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nsize_t argmax_simd(const int8_t *src, size_t length) {\n    if (length == 0) return 0;\n\n    __m256i max_vec = _mm256_set1_epi8(src[0]);\n    __m256i index_vec = _mm256_setr_epi32(0, 1, 2, 3, 4, 5, 6, 7);\n    __m256i base_index_vec = _mm256_setzero_si256();\n    size_t max_index = 0;\n    int8_t max_value = src[0];\n\n    for (size_t i = 0; i < length; i += 32) {\n        __m256i current_vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(src + i));\n        __m256i mask = _mm256_cmpgt_epi8(current_vec, max_vec);\n        max_vec = _mm256_max_epi8(max_vec, current_vec);\n        __m256i new_indices = _mm256_add_epi32(index_vec, base_index_vec);\n        __m256i updated_indices = _mm256_blendv_epi8(_mm256_set1_epi32(max_index), new_indices, mask);\n        max_index = _mm256_extract_epi32(updated_indices, 0);\n        base_index_vec = _mm256_add_epi32(base_index_vec, _mm256_set1_epi32(32));\n    }\n\n    for (size_t i = (length / 32) * 32; i < length; ++i) {\n        if (src[i] > max_value) {\n            max_value = src[i];\n            max_index = i;\n        }\n    }\n\n    return max_index;\n}\n```"}
{"task_id": "SimdBench_14_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nsize_t argmax_simd(const int8_t *src, size_t length) {\n    if (length == 0) return 0;\n\n    __m256i max_val = _mm256_set1_epi8(src[0]);\n    __m256i max_idx = _mm256_set_epi8(15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 0);\n    __m256i idx_offset = _mm256_set1_epi8(16);\n\n    size_t i = 0;\n    for (; i <= length - 32; i += 32) {\n        __m256i current = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(src + i));\n        __m256i mask = _mm256_cmpgt_epi8(current, max_val);\n        max_val = _mm256_max_epi8(max_val, current);\n        __m256i new_idx = _mm256_add_epi8(max_idx, idx_offset);\n        max_idx = _mm256_blendv_epi8(max_idx, new_idx, mask);\n        idx_offset = _mm256_add_epi8(idx_offset, _mm256_set1_epi8(32));\n    }\n\n    int8_t max_array[32];\n    int8_t idx_array[32];\n    _mm256_storeu_si256(reinterpret_cast<__m256i*>(max_array), max_val);\n    _mm256_storeu_si256(reinterpret_cast<__m256i*>(idx_array), max_idx);\n\n    int8_t max_scalar = max_array[0];\n    size_t max_index = idx_array[0];\n\n    for (size_t j = 1; j < 32; ++j) {\n        if (max_array[j] > max_scalar) {\n            max_scalar = max_array[j];\n            max_index = idx_array[j];\n        }\n    }\n\n    for (; i < length; ++i) {\n        if (src[i] > max_scalar) {\n            max_scalar = src[i];\n            max_index = i;\n        }\n    }\n\n    return max_index;\n}\n```"}
{"task_id": "SimdBench_14_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nsize_t argmax_simd(const int8_t *src, size_t length) {\n    if (length == 0) return 0;\n\n    __m256i max_val = _mm256_set1_epi8(src[0]);\n    __m256i max_idx = _mm256_set_epi32(7, 6, 5, 4, 3, 2, 1, 0);\n    __m256i idx_base = _mm256_set1_epi32(0);\n\n    size_t i = 0;\n    for (; i <= length - 32; i += 32) {\n        __m256i current = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(src + i));\n        __m256i mask = _mm256_cmpgt_epi8(current, max_val);\n        max_val = _mm256_max_epi8(max_val, current);\n        __m256i new_idx = _mm256_add_epi32(max_idx, idx_base);\n        max_idx = _mm256_blendv_epi8(max_idx, new_idx, mask);\n        idx_base = _mm256_add_epi32(idx_base, _mm256_set1_epi32(32));\n    }\n\n    int8_t max_vals[32];\n    int idxs[32];\n    _mm256_storeu_si256(reinterpret_cast<__m256i*>(max_vals), max_val);\n    _mm256_storeu_si256(reinterpret_cast<__m256i*>(idxs), max_idx);\n\n    int8_t max_scalar = max_vals[0];\n    size_t max_index = idxs[0];\n\n    for (size_t j = 1; j < 32; ++j) {\n        if (max_vals[j] > max_scalar) {\n            max_scalar = max_vals[j];\n            max_index = idxs[j];\n        }\n    }\n\n    for (; i < length; ++i) {\n        if (src[i] > max_scalar) {\n            max_scalar = src[i];\n            max_index = i;\n        }\n    }\n\n    return max_index;\n}\n```"}
{"task_id": "SimdBench_14_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nsize_t argmax_simd(const int8_t *src, size_t length) {\n    if (length == 0) return 0;\n\n    __m256i max_val = _mm256_set1_epi8(src[0]);\n    __m256i max_idx = _mm256_set_epi8(23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 0);\n    __m256i idx_offset = _mm256_set1_epi8(0);\n\n    size_t i = 0;\n    for (; i <= length - 32; i += 32) {\n        __m256i current = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(src + i));\n        __m256i mask = _mm256_cmpgt_epi8(current, max_val);\n        max_val = _mm256_max_epi8(max_val, current);\n        __m256i new_idx = _mm256_add_epi8(max_idx, idx_offset);\n        max_idx = _mm256_blendv_epi8(max_idx, new_idx, mask);\n        idx_offset = _mm256_add_epi8(idx_offset, _mm256_set1_epi8(32));\n    }\n\n    int8_t max_array[32];\n    int8_t idx_array[32];\n    _mm256_storeu_si256(reinterpret_cast<__m256i*>(max_array), max_val);\n    _mm256_storeu_si256(reinterpret_cast<__m256i*>(idx_array), max_idx);\n\n    int8_t max_scalar = max_array[0];\n    size_t max_index = idx_array[0];\n\n    for (size_t j = 1; j < 32 && i - 32 + j < length; ++j) {\n        if (max_array[j] > max_scalar) {\n            max_scalar = max_array[j];\n            max_index = idx_array[j];\n        }\n    }\n\n    for (; i < length; ++i) {\n        if (src[i] > max_scalar) {\n            max_scalar = src[i];\n            max_index = i;\n        }\n    }\n\n    return max_index;\n}\n```"}
{"task_id": "SimdBench_14_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nsize_t argmax_simd(const int8_t *src, size_t length) {\n    if (length == 0) return 0;\n\n    __m256i max_vec = _mm256_set1_epi8(src[0]);\n    __m256i idx_vec = _mm256_set_epi8(31, 30, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16,\n                                      15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 0);\n    __m256i max_idx = idx_vec;\n    size_t i = 0;\n\n    for (; i <= length - 32; i += 32) {\n        __m256i vec = _mm256_loadu_si256((__m256i const*)(src + i));\n        __m256i cmp_mask = _mm256_cmpgt_epi8(vec, max_vec);\n        max_vec = _mm256_max_epi8(vec, max_vec);\n        idx_vec = _mm256_add_epi8(idx_vec, _mm256_set1_epi8(32));\n        max_idx = _mm256_blendv_epi8(max_idx, idx_vec, cmp_mask);\n    }\n\n    int8_t max_val[32];\n    int8_t max_idx_val[32];\n    _mm256_storeu_si256((__m256i*)max_val, max_vec);\n    _mm256_storeu_si256((__m256i*)max_idx_val, max_idx);\n\n    int8_t max_scalar = max_val[0];\n    size_t max_index = max_idx_val[0];\n\n    for (size_t j = 1; j < 32; ++j) {\n        if (max_val[j] > max_scalar) {\n            max_scalar = max_val[j];\n            max_index = max_idx_val[j];\n        }\n    }\n\n    for (; i < length; ++i) {\n        if (src[i] > max_scalar) {\n            max_scalar = src[i];\n            max_index = i;\n        }\n    }\n\n    return max_index;\n}\n```"}
{"task_id": "SimdBench_15_AVX", "completion": "```cpp\nvoid vector_blend_simd(const uint16_t* src1, const uint16_t* src2, uint32_t mask, uint16_t* dst, size_t length) {\n    __m256i mask_vec = _mm256_set1_epi16(mask);\n    size_t i = 0;\n    for (; i <= length - 16; i += 16) {\n        __m256i index_vec = _mm256_add_epi16(_mm256_set_epi16(15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 0),\n                                             _mm256_set1_epi16(i));\n        __m256i index_masked = _mm256_and_si256(index_vec, mask_vec);\n        __m256i mask_cmp = _mm256_cmpeq_epi16(index_masked, _mm256_setzero_si256());\n        __m256i src1_vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(src1 + i));\n        __m256i src2_vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(src2 + i));\n        __m256i result_vec = _mm256_blendv_epi8(src2_vec, src1_vec, mask_cmp);\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(dst + i), result_vec);\n    }\n    for (; i < length; ++i) {\n        dst[i] = ((i & mask) != 0) ? src1[i] : src2[i];\n    }\n}\n```"}
{"task_id": "SimdBench_15_AVX", "completion": "```cpp\nvoid vector_blend_simd(const uint16_t* src1, const uint16_t* src2, uint32_t mask, uint16_t* dst, size_t length) {\n    __m256i mask_vec = _mm256_set1_epi16(mask);\n    size_t i = 0;\n    for (; i <= length - 16; i += 16) {\n        __m256i index_vec = _mm256_add_epi16(_mm256_set_epi16(15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 0),\n                                             _mm256_set1_epi16(i));\n        __m256i index_mask_vec = _mm256_and_si256(index_vec, mask_vec);\n        __m256i zero_vec = _mm256_setzero_si256();\n        __m256i cmp_vec = _mm256_cmpgt_epi16(index_mask_vec, zero_vec);\n        __m256i src1_vec = _mm256_loadu_si256((__m256i*)(src1 + i));\n        __m256i src2_vec = _mm256_loadu_si256((__m256i*)(src2 + i));\n        __m256i result_vec = _mm256_blendv_epi8(src2_vec, src1_vec, cmp_vec);\n        _mm256_storeu_si256((__m256i*)(dst + i), result_vec);\n    }\n    for (; i < length; ++i) {\n        dst[i] = ((i & mask) != 0) ? src1[i] : src2[i];\n    }\n}\n```"}
{"task_id": "SimdBench_15_AVX", "completion": "```cpp\nvoid vector_blend_simd(const uint16_t* src1, const uint16_t* src2, uint32_t mask, uint16_t* dst, size_t length) {\n    __m256i mask_vec = _mm256_set1_epi16(mask);\n    size_t i = 0;\n    for (; i <= length - 16; i += 16) {\n        __m256i index_vec = _mm256_add_epi16(_mm256_set_epi16(15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 0),\n                                             _mm256_set1_epi16(i));\n        __m256i index_mask_vec = _mm256_and_si256(index_vec, mask_vec);\n        __m256i mask_cmp_vec = _mm256_cmpeq_epi16(index_mask_vec, _mm256_setzero_si256());\n        __m256i src1_vec = _mm256_loadu_si256((__m256i*)(src1 + i));\n        __m256i src2_vec = _mm256_loadu_si256((__m256i*)(src2 + i));\n        __m256i result_vec = _mm256_blendv_epi8(src2_vec, src1_vec, mask_cmp_vec);\n        _mm256_storeu_si256((__m256i*)(dst + i), result_vec);\n    }\n    for (; i < length; ++i) {\n        dst[i] = ((i & mask) != 0) ? src1[i] : src2[i];\n    }\n}\n```"}
{"task_id": "SimdBench_15_AVX", "completion": "```cpp\nvoid vector_blend_simd(const uint16_t* src1, const uint16_t* src2, uint32_t mask, uint16_t* dst, size_t length) {\n    __m256i mask_vec = _mm256_set1_epi16(mask);\n    size_t i = 0;\n    for (; i <= length - 16; i += 16) {\n        __m256i index_vec = _mm256_add_epi16(_mm256_set_epi16(15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 0),\n                                             _mm256_set1_epi16(i));\n        __m256i index_mask_vec = _mm256_and_si256(index_vec, mask_vec);\n        __m256i zero_vec = _mm256_setzero_si256();\n        __m256i mask_cmp_vec = _mm256_cmpgt_epi16(index_mask_vec, zero_vec);\n        __m256i src1_vec = _mm256_loadu_si256((__m256i*)(src1 + i));\n        __m256i src2_vec = _mm256_loadu_si256((__m256i*)(src2 + i));\n        __m256i result_vec = _mm256_blendv_epi8(src2_vec, src1_vec, mask_cmp_vec);\n        _mm256_storeu_si256((__m256i*)(dst + i), result_vec);\n    }\n    for (; i < length; ++i) {\n        dst[i] = ((i & mask) != 0) ? src1[i] : src2[i];\n    }\n}\n```"}
{"task_id": "SimdBench_15_AVX", "completion": "```cpp\nvoid vector_blend_simd(const uint16_t* src1, const uint16_t* src2, uint32_t mask, uint16_t* dst, size_t length) {\n    __m256i mask_vec = _mm256_set1_epi16(mask);\n    size_t i = 0;\n    for (; i <= length - 16; i += 16) {\n        __m256i index_vec = _mm256_add_epi16(_mm256_set_epi16(15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 0),\n                                             _mm256_set1_epi16(i));\n        __m256i index_masked = _mm256_and_si256(index_vec, mask_vec);\n        __m256i mask_cmp = _mm256_cmpeq_epi16(index_masked, _mm256_setzero_si256());\n        __m256i src1_vec = _mm256_loadu_si256((__m256i*)(src1 + i));\n        __m256i src2_vec = _mm256_loadu_si256((__m256i*)(src2 + i));\n        __m256i result_vec = _mm256_blendv_epi8(src2_vec, src1_vec, mask_cmp);\n        _mm256_storeu_si256((__m256i*)(dst + i), result_vec);\n    }\n    for (; i < length; ++i) {\n        dst[i] = ((i & mask) != 0) ? src1[i] : src2[i];\n    }\n}\n```"}
{"task_id": "SimdBench_16_AVX", "completion": "```cpp\nvoid population_count_simd(const uint32_t* src, uint32_t* dst, size_t length) {\n    size_t i = 0;\n    const __m256i zero = _mm256_setzero_si256();\n    for (; i <= length - 8; i += 8) {\n        __m256i data = _mm256_loadu_si256((__m256i const*)(src + i));\n        __m256i popcnt = _mm256_popcnt_epi32(data);\n        _mm256_storeu_si256((__m256i*)(dst + i), popcnt);\n    }\n    for (; i < length; ++i) {\n        dst[i] = __builtin_popcount(src[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_16_AVX", "completion": "```cpp\nvoid population_count_simd(const uint32_t* src, uint32_t* dst, size_t length) {\n    size_t i = 0;\n    const size_t step = 8; // Process 8 elements at a time\n\n    for (; i <= length - step; i += step) {\n        __m256i vec = _mm256_loadu_si256((__m256i const*)(src + i));\n        __m256i popcnt = _mm256_popcnt_epi32(vec);\n        _mm256_storeu_si256((__m256i*)(dst + i), popcnt);\n    }\n\n    // Handle remaining elements\n    for (; i < length; ++i) {\n        dst[i] = __builtin_popcount(src[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_16_AVX", "completion": "```cpp\nvoid population_count_simd(const uint32_t* src, uint32_t* dst, size_t length) {\n    size_t i = 0;\n    const size_t step = 8; // Process 8 elements at a time\n\n    for (; i <= length - step; i += step) {\n        __m256i vec = _mm256_loadu_si256((__m256i const*)(src + i));\n        __m256i popcnt = _mm256_popcnt_epi32(vec);\n        _mm256_storeu_si256((__m256i*)(dst + i), popcnt);\n    }\n\n    // Handle remaining elements\n    for (; i < length; ++i) {\n        dst[i] = __builtin_popcount(src[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_16_AVX", "completion": "```cpp\nvoid population_count_simd(const uint32_t* src, uint32_t* dst, size_t length) {\n    size_t i = 0;\n    const size_t step = 8; // Process 8 elements at a time\n\n    for (; i <= length - step; i += step) {\n        __m256i vec = _mm256_loadu_si256((__m256i const*)(src + i));\n        __m256i popcnt = _mm256_popcnt_epi32(vec);\n        _mm256_storeu_si256((__m256i*)(dst + i), popcnt);\n    }\n\n    // Handle remaining elements\n    for (; i < length; ++i) {\n        dst[i] = __builtin_popcount(src[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_16_AVX", "completion": "```cpp\nvoid population_count_simd(const uint32_t* src, uint32_t* dst, size_t length) {\n    size_t i = 0;\n    const size_t step = 8; // Process 8 elements at a time\n\n    for (; i <= length - step; i += step) {\n        __m256i vec = _mm256_loadu_si256((__m256i const*)(src + i));\n        __m256i popcnt = _mm256_popcnt_epi32(vec);\n        _mm256_storeu_si256((__m256i*)(dst + i), popcnt);\n    }\n\n    // Handle remaining elements\n    for (; i < length; ++i) {\n        dst[i] = __builtin_popcount(src[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_17_AVX", "completion": "```cpp\nvoid saturating_add_simd(const uint16_t* src1, const uint16_t* src2, uint16_t* dst, size_t length) {\n    size_t i = 0;\n    const size_t num_simd_elements = 16; // AVX2 processes 16 uint16_t elements at a time\n\n    while (i <= length - num_simd_elements) {\n        __m256i v1 = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(src1 + i));\n        __m256i v2 = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(src2 + i));\n        __m256i v_result = _mm256_adds_epu16(v1, v2);\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(dst + i), v_result);\n        i += num_simd_elements;\n    }\n\n    // Handle remaining elements\n    for (; i < length; ++i) {\n        dst[i] = std::min<uint16_t>(UINT16_MAX, src1[i] + src2[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_17_AVX", "completion": "```cpp\nvoid saturating_add_simd(const uint16_t* src1, const uint16_t* src2, uint16_t* dst, size_t length) {\n    size_t i = 0;\n    __m256i max_val = _mm256_set1_epi16(UINT16_MAX);\n\n    for (; i <= length - 16; i += 16) {\n        __m256i a = _mm256_loadu_si256((__m256i*)(src1 + i));\n        __m256i b = _mm256_loadu_si256((__m256i*)(src2 + i));\n        __m256i sum = _mm256_adds_epu16(a, b);\n        _mm256_storeu_si256((__m256i*)(dst + i), sum);\n    }\n\n    for (; i < length; ++i) {\n        dst[i] = src1[i] + src2[i] > UINT16_MAX ? UINT16_MAX : src1[i] + src2[i];\n    }\n}\n```"}
{"task_id": "SimdBench_17_AVX", "completion": "```cpp\nvoid saturating_add_simd(const uint16_t* src1, const uint16_t* src2, uint16_t* dst, size_t length) {\n    size_t i = 0;\n    const size_t num_simd_elements = 16; // AVX2 processes 16 uint16_t elements at a time\n\n    for (; i <= length - num_simd_elements; i += num_simd_elements) {\n        __m256i vec1 = _mm256_loadu_si256((__m256i const*)(src1 + i));\n        __m256i vec2 = _mm256_loadu_si256((__m256i const*)(src2 + i));\n        __m256i result = _mm256_adds_epu16(vec1, vec2);\n        _mm256_storeu_si256((__m256i*)(dst + i), result);\n    }\n\n    // Handle remaining elements\n    for (; i < length; ++i) {\n        dst[i] = src1[i] + src2[i] > UINT16_MAX ? UINT16_MAX : src1[i] + src2[i];\n    }\n}\n```"}
{"task_id": "SimdBench_17_AVX", "completion": "```cpp\nvoid saturating_add_simd(const uint16_t* src1, const uint16_t* src2, uint16_t* dst, size_t length) {\n    size_t i = 0;\n    __m256i max_val = _mm256_set1_epi16(UINT16_MAX);\n\n    for (; i <= length - 16; i += 16) {\n        __m256i a = _mm256_loadu_si256((__m256i*)(src1 + i));\n        __m256i b = _mm256_loadu_si256((__m256i*)(src2 + i));\n        __m256i sum = _mm256_adds_epu16(a, b);\n        _mm256_storeu_si256((__m256i*)(dst + i), sum);\n    }\n\n    for (; i < length; ++i) {\n        dst[i] = src1[i] + src2[i] > UINT16_MAX ? UINT16_MAX : src1[i] + src2[i];\n    }\n}\n```"}
{"task_id": "SimdBench_17_AVX", "completion": "```cpp\nvoid saturating_add_simd(const uint16_t* src1, const uint16_t* src2, uint16_t* dst, size_t length) {\n    size_t i = 0;\n    __m256i max_val = _mm256_set1_epi16(UINT16_MAX);\n\n    for (; i <= length - 16; i += 16) {\n        __m256i a = _mm256_loadu_si256((__m256i*)(src1 + i));\n        __m256i b = _mm256_loadu_si256((__m256i*)(src2 + i));\n        __m256i sum = _mm256_adds_epu16(a, b);\n        _mm256_storeu_si256((__m256i*)(dst + i), sum);\n    }\n\n    for (; i < length; ++i) {\n        dst[i] = src1[i] + src2[i] > UINT16_MAX ? UINT16_MAX : src1[i] + src2[i];\n    }\n}\n```"}
{"task_id": "SimdBench_18_AVX", "completion": "```cpp\nvoid range_matrix_mul_simd(const double* A, const double* B, double* C, size_t m, size_t n, size_t p) {\n    __m256d lower_bound = _mm256_set1_pd(-100.0);\n    __m256d upper_bound = _mm256_set1_pd(100.0);\n\n    for (size_t i = 0; i < m; ++i) {\n        for (size_t j = 0; j < p; ++j) {\n            __m256d c_sum = _mm256_setzero_pd();\n            for (size_t k = 0; k < n; k += 4) {\n                __m256d a_vals = _mm256_loadu_pd(&A[i * n + k]);\n                __m256d b_vals = _mm256_loadu_pd(&B[j + k * p]);\n\n                __m256d mask_a = _mm256_and_pd(_mm256_cmp_pd(a_vals, lower_bound, _CMP_GE_OS), _mm256_cmp_pd(a_vals, upper_bound, _CMP_LE_OS));\n                __m256d mask_b = _mm256_and_pd(_mm256_cmp_pd(b_vals, lower_bound, _CMP_GE_OS), _mm256_cmp_pd(b_vals, upper_bound, _CMP_LE_OS));\n\n                __m256d valid_a = _mm256_and_pd(a_vals, mask_a);\n                __m256d valid_b = _mm256_and_pd(b_vals, mask_b);\n\n                __m256d prod = _mm256_mul_pd(valid_a, valid_b);\n                c_sum = _mm256_add_pd(c_sum, prod);\n            }\n\n            double c_temp[4];\n            _mm256_storeu_pd(c_temp, c_sum);\n            C[i * p + j] = c_temp[0] + c_temp[1] + c_temp[2] + c_temp[3];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_18_AVX", "completion": "```cpp\nvoid range_matrix_mul_simd(const double* A, const double* B, double* C, size_t m, size_t n, size_t p) {\n    __m256d lower_bound = _mm256_set1_pd(-100.0);\n    __m256d upper_bound = _mm256_set1_pd(100.0);\n\n    for (size_t i = 0; i < m; ++i) {\n        for (size_t j = 0; j < p; ++j) {\n            __m256d c_sum = _mm256_setzero_pd();\n            for (size_t k = 0; k < n; k += 4) {\n                __m256d a_vals = _mm256_loadu_pd(&A[i * n + k]);\n                __m256d b_vals = _mm256_loadu_pd(&B[j + k * p]);\n\n                __m256d mask_a = _mm256_and_pd(_mm256_cmp_pd(a_vals, lower_bound, _CMP_GE_OS), _mm256_cmp_pd(a_vals, upper_bound, _CMP_LE_OS));\n                __m256d mask_b = _mm256_and_pd(_mm256_cmp_pd(b_vals, lower_bound, _CMP_GE_OS), _mm256_cmp_pd(b_vals, upper_bound, _CMP_LE_OS));\n\n                __m256d valid_a = _mm256_and_pd(a_vals, mask_a);\n                __m256d valid_b = _mm256_and_pd(b_vals, mask_b);\n\n                __m256d prod = _mm256_mul_pd(valid_a, valid_b);\n                c_sum = _mm256_add_pd(c_sum, prod);\n            }\n\n            double c_temp[4];\n            _mm256_storeu_pd(c_temp, c_sum);\n            C[i * p + j] = c_temp[0] + c_temp[1] + c_temp[2] + c_temp[3];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_18_AVX", "completion": "```cpp\nvoid range_matrix_mul_simd(const double* A, const double* B, double* C, size_t m, size_t n, size_t p) {\n    __m256d range_min = _mm256_set1_pd(-100.0);\n    __m256d range_max = _mm256_set1_pd(100.0);\n\n    for (size_t i = 0; i < m; ++i) {\n        for (size_t j = 0; j < p; ++j) {\n            __m256d c_sum = _mm256_setzero_pd();\n            for (size_t k = 0; k < n; k += 4) {\n                __m256d a_vals = _mm256_loadu_pd(&A[i * n + k]);\n                __m256d b_vals = _mm256_loadu_pd(&B[j + k * p]);\n\n                __m256d mask_a = _mm256_and_pd(_mm256_cmp_pd(a_vals, range_min, _CMP_GE_OS), _mm256_cmp_pd(a_vals, range_max, _CMP_LE_OS));\n                __m256d mask_b = _mm256_and_pd(_mm256_cmp_pd(b_vals, range_min, _CMP_GE_OS), _mm256_cmp_pd(b_vals, range_max, _CMP_LE_OS));\n                __m256d mask = _mm256_and_pd(mask_a, mask_b);\n\n                __m256d a_masked = _mm256_and_pd(a_vals, mask);\n                __m256d b_masked = _mm256_and_pd(b_vals, mask);\n\n                __m256d prod = _mm256_mul_pd(a_masked, b_masked);\n                c_sum = _mm256_add_pd(c_sum, prod);\n            }\n\n            double c_temp[4];\n            _mm256_storeu_pd(c_temp, c_sum);\n            C[i * p + j] = c_temp[0] + c_temp[1] + c_temp[2] + c_temp[3];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_18_AVX", "completion": "```cpp\nvoid range_matrix_mul_simd(const double* A, const double* B, double* C, size_t m, size_t n, size_t p) {\n    __m256d lower_bound = _mm256_set1_pd(-100.0);\n    __m256d upper_bound = _mm256_set1_pd(100.0);\n\n    for (size_t i = 0; i < m; ++i) {\n        for (size_t j = 0; j < p; ++j) {\n            __m256d c_sum = _mm256_setzero_pd();\n            for (size_t k = 0; k < n; k += 4) {\n                __m256d a_vals = _mm256_loadu_pd(&A[i * n + k]);\n                __m256d b_vals = _mm256_loadu_pd(&B[j + k * p]);\n\n                __m256d mask_a = _mm256_and_pd(_mm256_cmp_pd(a_vals, lower_bound, _CMP_GE_OS), _mm256_cmp_pd(a_vals, upper_bound, _CMP_LE_OS));\n                __m256d mask_b = _mm256_and_pd(_mm256_cmp_pd(b_vals, lower_bound, _CMP_GE_OS), _mm256_cmp_pd(b_vals, upper_bound, _CMP_LE_OS));\n                __m256d mask = _mm256_and_pd(mask_a, mask_b);\n\n                __m256d a_masked = _mm256_and_pd(a_vals, mask);\n                __m256d b_masked = _mm256_and_pd(b_vals, mask);\n\n                __m256d prod = _mm256_mul_pd(a_masked, b_masked);\n                c_sum = _mm256_add_pd(c_sum, prod);\n            }\n\n            double c_temp[4];\n            _mm256_storeu_pd(c_temp, c_sum);\n            C[i * p + j] = c_temp[0] + c_temp[1] + c_temp[2] + c_temp[3];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_18_AVX", "completion": "```cpp\nvoid range_matrix_mul_simd(const double* A, const double* B, double* C, size_t m, size_t n, size_t p) {\n    __m256d lower_bound = _mm256_set1_pd(-100.0);\n    __m256d upper_bound = _mm256_set1_pd(100.0);\n\n    for (size_t i = 0; i < m; ++i) {\n        for (size_t j = 0; j < p; ++j) {\n            __m256d c_sum = _mm256_setzero_pd();\n            for (size_t k = 0; k < n; k += 4) {\n                __m256d a_vals = _mm256_loadu_pd(&A[i * n + k]);\n                __m256d b_vals = _mm256_loadu_pd(&B[j + k * p]);\n\n                __m256d mask_a = _mm256_and_pd(_mm256_cmp_pd(a_vals, lower_bound, _CMP_GE_OS), _mm256_cmp_pd(a_vals, upper_bound, _CMP_LE_OS));\n                __m256d mask_b = _mm256_and_pd(_mm256_cmp_pd(b_vals, lower_bound, _CMP_GE_OS), _mm256_cmp_pd(b_vals, upper_bound, _CMP_LE_OS));\n\n                __m256d valid_a = _mm256_and_pd(a_vals, mask_a);\n                __m256d valid_b = _mm256_and_pd(b_vals, mask_b);\n\n                __m256d prod = _mm256_mul_pd(valid_a, valid_b);\n                c_sum = _mm256_add_pd(c_sum, prod);\n            }\n\n            double c_temp[4];\n            _mm256_storeu_pd(c_temp, c_sum);\n            C[i * p + j] = c_temp[0] + c_temp[1] + c_temp[2] + c_temp[3];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_19_AVX", "completion": "```cpp\nvoid tensor_add_3d_simd(const int64_t* A, const int64_t* B, int64_t* C, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t i = 0;\n\n    for (; i <= total_elements - 4; i += 4) {\n        __m256i vecA = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i vecB = _mm256_loadu_si256((__m256i*)&B[i]);\n        __m256i vecC = _mm256_add_epi64(vecA, vecB);\n        _mm256_storeu_si256((__m256i*)&C[i], vecC);\n    }\n\n    for (; i < total_elements; ++i) {\n        C[i] = A[i] + B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_19_AVX", "completion": "```cpp\nvoid tensor_add_3d_simd(const int64_t* A, const int64_t* B, int64_t* C, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t i = 0;\n\n    for (; i <= total_elements - 4; i += 4) {\n        __m256i vecA = _mm256_loadu_si256((__m256i const*)(A + i));\n        __m256i vecB = _mm256_loadu_si256((__m256i const*)(B + i));\n        __m256i vecC = _mm256_add_epi64(vecA, vecB);\n        _mm256_storeu_si256((__m256i*)(C + i), vecC);\n    }\n\n    for (; i < total_elements; ++i) {\n        C[i] = A[i] + B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_19_AVX", "completion": "```cpp\nvoid tensor_add_3d_simd(const int64_t* A, const int64_t* B, int64_t* C, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t i = 0;\n\n    for (; i <= total_elements - 4; i += 4) {\n        __m256i vecA = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i vecB = _mm256_loadu_si256((__m256i*)&B[i]);\n        __m256i vecC = _mm256_add_epi64(vecA, vecB);\n        _mm256_storeu_si256((__m256i*)&C[i], vecC);\n    }\n\n    for (; i < total_elements; ++i) {\n        C[i] = A[i] + B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_19_AVX", "completion": "```cpp\nvoid tensor_add_3d_simd(const int64_t* A, const int64_t* B, int64_t* C, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t i = 0;\n\n    for (; i <= total_elements - 4; i += 4) {\n        __m256i vecA = _mm256_loadu_si256((__m256i*)&A[i]);\n        __m256i vecB = _mm256_loadu_si256((__m256i*)&B[i]);\n        __m256i vecC = _mm256_add_epi64(vecA, vecB);\n        _mm256_storeu_si256((__m256i*)&C[i], vecC);\n    }\n\n    for (; i < total_elements; ++i) {\n        C[i] = A[i] + B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_19_AVX", "completion": "```cpp\nvoid tensor_add_3d_simd(const int64_t* A, const int64_t* B, int64_t* C, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t i = 0;\n\n    for (; i <= total_elements - 4; i += 4) {\n        __m256i vecA = _mm256_loadu_si256((__m256i const*)(A + i));\n        __m256i vecB = _mm256_loadu_si256((__m256i const*)(B + i));\n        __m256i vecC = _mm256_add_epi64(vecA, vecB);\n        _mm256_storeu_si256((__m256i*)(C + i), vecC);\n    }\n\n    for (; i < total_elements; ++i) {\n        C[i] = A[i] + B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_20_AVX", "completion": "```cpp\nvoid vector_add_round_nearest_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 8; i += 8) {\n        __m256 vec1 = _mm256_loadu_ps(&src1[i]);\n        __m256 vec2 = _mm256_loadu_ps(&src2[i]);\n        __m256 sum = _mm256_add_ps(vec1, vec2);\n        __m256 rounded_sum = _mm256_round_ps(sum, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n        _mm256_storeu_ps(&dst[i], rounded_sum);\n    }\n    for (; i < length; ++i) {\n        dst[i] = std::round(src1[i] + src2[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_20_AVX", "completion": "```cpp\nvoid vector_add_round_nearest_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 8; i += 8) {\n        __m256 vec1 = _mm256_loadu_ps(&src1[i]);\n        __m256 vec2 = _mm256_loadu_ps(&src2[i]);\n        __m256 sum = _mm256_add_ps(vec1, vec2);\n        __m256 rounded_sum = _mm256_round_ps(sum, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n        _mm256_storeu_ps(&dst[i], rounded_sum);\n    }\n    for (; i < length; ++i) {\n        dst[i] = std::round(src1[i] + src2[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_20_AVX", "completion": "```cpp\nvoid vector_add_round_nearest_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 8; i += 8) {\n        __m256 vec1 = _mm256_loadu_ps(&src1[i]);\n        __m256 vec2 = _mm256_loadu_ps(&src2[i]);\n        __m256 sum = _mm256_add_ps(vec1, vec2);\n        __m256 rounded_sum = _mm256_round_ps(sum, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n        _mm256_storeu_ps(&dst[i], rounded_sum);\n    }\n    for (; i < length; ++i) {\n        dst[i] = std::round(src1[i] + src2[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_20_AVX", "completion": "```cpp\nvoid vector_add_round_nearest_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 8; i += 8) {\n        __m256 vec1 = _mm256_loadu_ps(&src1[i]);\n        __m256 vec2 = _mm256_loadu_ps(&src2[i]);\n        __m256 sum = _mm256_add_ps(vec1, vec2);\n        __m256 rounded_sum = _mm256_round_ps(sum, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n        _mm256_storeu_ps(&dst[i], rounded_sum);\n    }\n    for (; i < length; ++i) {\n        dst[i] = std::round(src1[i] + src2[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_20_AVX", "completion": "```cpp\nvoid vector_add_round_nearest_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 8; i += 8) {\n        __m256 vec1 = _mm256_loadu_ps(&src1[i]);\n        __m256 vec2 = _mm256_loadu_ps(&src2[i]);\n        __m256 sum = _mm256_add_ps(vec1, vec2);\n        __m256 rounded = _mm256_round_ps(sum, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n        _mm256_storeu_ps(&dst[i], rounded);\n    }\n    for (; i < length; ++i) {\n        dst[i] = std::round(src1[i] + src2[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_21_AVX", "completion": "```cpp\nvoid vector_mul_round_up_simd(const float* src1, const float* src2, float* dst, size_t length){\n    __m256 fifty = _mm256_set1_ps(50.0f);\n    __m256 neg_one = _mm256_set1_ps(-1.0f);\n    __m256 two = _mm256_set1_ps(2.0f);\n\n    for (size_t i = 0; i < length; i += 8) {\n        __m256 s1 = _mm256_loadu_ps(&src1[i]);\n        __m256 s2 = _mm256_loadu_ps(&src2[i]);\n\n        __m256 diff = _mm256_sub_ps(s1, s2);\n        __m256 abs_diff = _mm256_andnot_ps(_mm256_set1_ps(-0.0f), diff);\n        __m256 mask_within_50 = _mm256_cmp_ps(abs_diff, fifty, _CMP_LE_OS);\n\n        __m256 index = _mm256_set_ps(i + 7, i + 6, i + 5, i + 4, i + 3, i + 2, i + 1, i);\n        __m256 mask_multiple_of_2 = _mm256_cmpeq_ps(_mm256_and_ps(index, two), _mm256_setzero_ps());\n\n        __m256 mask = _mm256_and_ps(mask_within_50, mask_multiple_of_2);\n\n        __m256 mul = _mm256_mul_ps(s1, s2);\n        __m256 rounded_up = _mm256_ceil_ps(mul);\n\n        __m256 result = _mm256_blendv_ps(neg_one, rounded_up, mask);\n\n        _mm256_storeu_ps(&dst[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_21_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid vector_mul_round_up_simd(const float* src1, const float* src2, float* dst, size_t length){\n    __m256 fifty = _mm256_set1_ps(50.0f);\n    __m256 neg_one = _mm256_set1_ps(-1.0f);\n    __m256 two = _mm256_set1_ps(2.0f);\n\n    for (size_t i = 0; i < length; i += 8) {\n        __m256 s1 = _mm256_loadu_ps(&src1[i]);\n        __m256 s2 = _mm256_loadu_ps(&src2[i]);\n\n        __m256 diff = _mm256_sub_ps(s1, s2);\n        __m256 abs_diff = _mm256_andnot_ps(_mm256_set1_ps(-0.0f), diff);\n        __m256 mask_within_50 = _mm256_cmp_ps(abs_diff, fifty, _CMP_LE_OS);\n\n        __m256 index = _mm256_set_ps(i + 7, i + 6, i + 5, i + 4, i + 3, i + 2, i + 1, i);\n        __m256 mask_multiple_of_2 = _mm256_cmpeq_ps(_mm256_and_ps(index, two), _mm256_setzero_ps());\n\n        __m256 mask = _mm256_and_ps(mask_within_50, mask_multiple_of_2);\n\n        __m256 mul_result = _mm256_mul_ps(s1, s2);\n        __m256 rounded_result = _mm256_ceil_ps(mul_result);\n\n        __m256 result = _mm256_blendv_ps(neg_one, rounded_result, mask);\n\n        _mm256_storeu_ps(&dst[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_21_AVX", "completion": "```cpp\nvoid vector_mul_round_up_simd(const float* src1, const float* src2, float* dst, size_t length){\n    __m256 fifty = _mm256_set1_ps(50.0f);\n    __m256 neg_one = _mm256_set1_ps(-1.0f);\n    __m256 two = _mm256_set1_ps(2.0f);\n    __m256i indices = _mm256_set_epi32(7, 6, 5, 4, 3, 2, 1, 0);\n\n    for (size_t i = 0; i < length; i += 8) {\n        __m256 a = _mm256_loadu_ps(&src1[i]);\n        __m256 b = _mm256_loadu_ps(&src2[i]);\n\n        __m256 diff = _mm256_sub_ps(a, b);\n        __m256 abs_diff = _mm256_andnot_ps(_mm256_set1_ps(-0.0f), diff);\n        __m256 mask_within_50 = _mm256_cmp_ps(abs_diff, fifty, _CMP_LE_OS);\n\n        __m256i index_vec = _mm256_add_epi32(_mm256_set1_epi32(i), indices);\n        __m256 mask_multiple_of_2 = _mm256_cmpeq_epi32(_mm256_and_epi32(index_vec, _mm256_castps_si256(two)), _mm256_setzero_si256());\n\n        __m256 mask = _mm256_and_ps(mask_within_50, _mm256_castsi256_ps(mask_multiple_of_2));\n\n        __m256 result = _mm256_mul_ps(a, b);\n        result = _mm256_blendv_ps(neg_one, result, mask);\n\n        __m256 rounded_result = _mm256_ceil_ps(result);\n        _mm256_storeu_ps(&dst[i], rounded_result);\n    }\n}\n```"}
{"task_id": "SimdBench_21_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid vector_mul_round_up_simd(const float* src1, const float* src2, float* dst, size_t length){\n    __m256 fifty = _mm256_set1_ps(50.0f);\n    __m256 neg_one = _mm256_set1_ps(-1.0f);\n    __m256 two = _mm256_set1_ps(2.0f);\n\n    for (size_t i = 0; i < length; i += 8) {\n        __m256 s1 = _mm256_loadu_ps(&src1[i]);\n        __m256 s2 = _mm256_loadu_ps(&src2[i]);\n\n        __m256 diff = _mm256_sub_ps(s1, s2);\n        __m256 abs_diff = _mm256_andnot_ps(_mm256_set1_ps(-0.0f), diff);\n        __m256 mask_within_50 = _mm256_cmp_ps(abs_diff, fifty, _CMP_LE_OS);\n\n        __m256 index = _mm256_set_ps(i + 7, i + 6, i + 5, i + 4, i + 3, i + 2, i + 1, i);\n        __m256 mask_multiple_of_2 = _mm256_cmpeq_ps(_mm256_and_ps(index, two), _mm256_setzero_ps());\n\n        __m256 mask = _mm256_and_ps(mask_within_50, mask_multiple_of_2);\n\n        __m256 mul_result = _mm256_mul_ps(s1, s2);\n        __m256 rounded_result = _mm256_ceil_ps(mul_result);\n\n        __m256 final_result = _mm256_blendv_ps(neg_one, rounded_result, mask);\n\n        _mm256_storeu_ps(&dst[i], final_result);\n    }\n}\n```"}
{"task_id": "SimdBench_21_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid vector_mul_round_up_simd(const float* src1, const float* src2, float* dst, size_t length){\n    __m256 fifty = _mm256_set1_ps(50.0f);\n    __m256 neg_one = _mm256_set1_ps(-1.0f);\n    __m256 two = _mm256_set1_ps(2.0f);\n\n    for (size_t i = 0; i < length; i += 8) {\n        __m256 a = _mm256_loadu_ps(&src1[i]);\n        __m256 b = _mm256_loadu_ps(&src2[i]);\n\n        __m256 diff = _mm256_sub_ps(a, b);\n        __m256 abs_diff = _mm256_andnot_ps(_mm256_set1_ps(-0.0f), diff);\n        __m256 mask_within_50 = _mm256_cmp_ps(abs_diff, fifty, _CMP_LE_OS);\n\n        __m256 index = _mm256_set_ps(i + 7, i + 6, i + 5, i + 4, i + 3, i + 2, i + 1, i);\n        __m256 mask_multiple_of_2 = _mm256_cmpeq_ps(_mm256_and_ps(index, two), _mm256_setzero_ps());\n\n        __m256 mask = _mm256_and_ps(mask_within_50, mask_multiple_of_2);\n        __m256 result = _mm256_mul_ps(a, b);\n        result = _mm256_round_ps(result, _MM_FROUND_TO_POS_INF | _MM_FROUND_NO_EXC);\n        result = _mm256_blendv_ps(neg_one, result, mask);\n\n        _mm256_storeu_ps(&dst[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_22_AVX", "completion": "```cpp\nvoid matrix_scalar_mul_simd(const double* mat, double scalar, double* dst, size_t m, size_t n) {\n    __m256d scalar_vec = _mm256_set1_pd(scalar);\n    size_t total_elements = m * n;\n    size_t i = 0;\n\n    for (; i <= total_elements - 4; i += 4) {\n        __m256d mat_vec = _mm256_loadu_pd(&mat[i]);\n        __m256d result_vec = _mm256_mul_pd(mat_vec, scalar_vec);\n        _mm256_storeu_pd(&dst[i], result_vec);\n    }\n\n    for (; i < total_elements; ++i) {\n        dst[i] = mat[i] * scalar;\n    }\n}\n```"}
{"task_id": "SimdBench_22_AVX", "completion": "```cpp\nvoid matrix_scalar_mul_simd(const double* mat, double scalar, double* dst, size_t m, size_t n) {\n    __m256d scalar_vec = _mm256_set1_pd(scalar);\n    size_t total_elements = m * n;\n    size_t i = 0;\n\n    for (; i <= total_elements - 4; i += 4) {\n        __m256d mat_vec = _mm256_loadu_pd(&mat[i]);\n        __m256d result_vec = _mm256_mul_pd(mat_vec, scalar_vec);\n        _mm256_storeu_pd(&dst[i], result_vec);\n    }\n\n    for (; i < total_elements; ++i) {\n        dst[i] = mat[i] * scalar;\n    }\n}\n```"}
{"task_id": "SimdBench_22_AVX", "completion": "```cpp\nvoid matrix_scalar_mul_simd(const double* mat, double scalar, double* dst, size_t m, size_t n) {\n    __m256d scalar_vec = _mm256_set1_pd(scalar);\n    size_t total_elements = m * n;\n    size_t i = 0;\n\n    for (; i <= total_elements - 4; i += 4) {\n        __m256d mat_vec = _mm256_loadu_pd(&mat[i]);\n        __m256d result_vec = _mm256_mul_pd(mat_vec, scalar_vec);\n        _mm256_storeu_pd(&dst[i], result_vec);\n    }\n\n    for (; i < total_elements; ++i) {\n        dst[i] = mat[i] * scalar;\n    }\n}\n```"}
{"task_id": "SimdBench_22_AVX", "completion": "```cpp\nvoid matrix_scalar_mul_simd(const double* mat, double scalar, double* dst, size_t m, size_t n) {\n    __m256d scalar_vec = _mm256_set1_pd(scalar);\n    size_t total_elements = m * n;\n    size_t i = 0;\n\n    for (; i <= total_elements - 4; i += 4) {\n        __m256d mat_vec = _mm256_loadu_pd(&mat[i]);\n        __m256d result_vec = _mm256_mul_pd(mat_vec, scalar_vec);\n        _mm256_storeu_pd(&dst[i], result_vec);\n    }\n\n    for (; i < total_elements; ++i) {\n        dst[i] = mat[i] * scalar;\n    }\n}\n```"}
{"task_id": "SimdBench_22_AVX", "completion": "```cpp\nvoid matrix_scalar_mul_simd(const double* mat, double scalar, double* dst, size_t m, size_t n) {\n    __m256d scalar_vec = _mm256_set1_pd(scalar);\n    size_t total_elements = m * n;\n    size_t i = 0;\n\n    for (; i <= total_elements - 4; i += 4) {\n        __m256d mat_vec = _mm256_loadu_pd(&mat[i]);\n        __m256d result_vec = _mm256_mul_pd(mat_vec, scalar_vec);\n        _mm256_storeu_pd(&dst[i], result_vec);\n    }\n\n    for (; i < total_elements; ++i) {\n        dst[i] = mat[i] * scalar;\n    }\n}\n```"}
{"task_id": "SimdBench_23_AVX", "completion": "```cpp\nvoid matrix_normalize_rows_simd(float* mat, size_t m, size_t n) {\n    for (size_t i = 0; i < m; ++i) {\n        float* row = mat + i * n;\n        __m256 sum = _mm256_setzero_ps();\n        size_t j = 0;\n\n        // Process 8 elements at a time\n        for (; j <= n - 8; j += 8) {\n            __m256 vec = _mm256_loadu_ps(row + j);\n            vec = _mm256_mul_ps(vec, vec);\n            sum = _mm256_add_ps(sum, vec);\n        }\n\n        // Horizontal add to get the sum of squares\n        __m128 sum_low = _mm_add_ps(_mm256_castps256_ps128(sum), _mm256_extractf128_ps(sum, 1));\n        sum_low = _mm_add_ps(sum_low, _mm_movehl_ps(sum_low, sum_low));\n        sum_low = _mm_add_ss(sum_low, _mm_shuffle_ps(sum_low, sum_low, 1));\n\n        float norm = sqrtf(_mm_cvtss_f32(sum_low));\n\n        // Avoid division by zero\n        if (norm == 0.0f) continue;\n\n        __m256 norm_vec = _mm256_set1_ps(norm);\n\n        // Normalize 8 elements at a time\n        j = 0;\n        for (; j <= n - 8; j += 8) {\n            __m256 vec = _mm256_loadu_ps(row + j);\n            vec = _mm256_div_ps(vec, norm_vec);\n            _mm256_storeu_ps(row + j, vec);\n        }\n\n        // Handle remaining elements\n        for (; j < n; ++j) {\n            row[j] /= norm;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_23_AVX", "completion": "```cpp\nvoid matrix_normalize_rows_simd(float* mat, size_t m, size_t n) {\n    for (size_t i = 0; i < m; ++i) {\n        float* row = mat + i * n;\n        __m256 sum = _mm256_setzero_ps();\n        size_t j = 0;\n\n        // Process 8 elements at a time\n        for (; j <= n - 8; j += 8) {\n            __m256 vec = _mm256_loadu_ps(row + j);\n            vec = _mm256_mul_ps(vec, vec);\n            sum = _mm256_add_ps(sum, vec);\n        }\n\n        // Horizontal add to get the sum of squares\n        __m128 sum_low = _mm_add_ps(_mm256_castps256_ps128(sum), _mm256_extractf128_ps(sum, 1));\n        sum_low = _mm_add_ps(sum_low, _mm_movehl_ps(sum_low, sum_low));\n        sum_low = _mm_add_ss(sum_low, _mm_shuffle_ps(sum_low, sum_low, 1));\n\n        float norm = sqrtf(_mm_cvtss_f32(sum_low));\n\n        // Avoid division by zero\n        if (norm == 0.0f) continue;\n\n        // Normalize the row\n        j = 0;\n        for (; j <= n - 8; j += 8) {\n            __m256 vec = _mm256_loadu_ps(row + j);\n            vec = _mm256_div_ps(vec, _mm256_set1_ps(norm));\n            _mm256_storeu_ps(row + j, vec);\n        }\n\n        // Handle remaining elements\n        for (; j < n; ++j) {\n            row[j] /= norm;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_23_AVX", "completion": "```cpp\nvoid matrix_normalize_rows_simd(float* mat, size_t m, size_t n) {\n    for (size_t i = 0; i < m; ++i) {\n        float* row = mat + i * n;\n        __m256 sum = _mm256_setzero_ps();\n        size_t j = 0;\n\n        // Process 8 elements at a time\n        for (; j <= n - 8; j += 8) {\n            __m256 vec = _mm256_loadu_ps(&row[j]);\n            vec = _mm256_mul_ps(vec, vec);\n            sum = _mm256_add_ps(sum, vec);\n        }\n\n        // Horizontal add to get the sum of squares\n        __m128 sum_low = _mm_add_ps(_mm256_castps256_ps128(sum), _mm256_extractf128_ps(sum, 1));\n        sum_low = _mm_add_ps(sum_low, _mm_movehl_ps(sum_low, sum_low));\n        sum_low = _mm_add_ss(sum_low, _mm_shuffle_ps(sum_low, sum_low, 1));\n\n        float norm = sqrtf(_mm_cvtss_f32(sum_low));\n\n        // Avoid division by zero\n        if (norm == 0.0f) continue;\n\n        __m256 norm_vec = _mm256_set1_ps(norm);\n\n        // Normalize 8 elements at a time\n        j = 0;\n        for (; j <= n - 8; j += 8) {\n            __m256 vec = _mm256_loadu_ps(&row[j]);\n            vec = _mm256_div_ps(vec, norm_vec);\n            _mm256_storeu_ps(&row[j], vec);\n        }\n\n        // Handle remaining elements\n        for (; j < n; ++j) {\n            row[j] /= norm;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_23_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid matrix_normalize_rows_simd(float* mat, size_t m, size_t n) {\n    for (size_t i = 0; i < m; ++i) {\n        float* row = mat + i * n;\n        __m256 sum = _mm256_setzero_ps();\n        size_t j = 0;\n\n        // Process 8 elements at a time\n        for (; j <= n - 8; j += 8) {\n            __m256 vec = _mm256_loadu_ps(&row[j]);\n            vec = _mm256_mul_ps(vec, vec);\n            sum = _mm256_add_ps(sum, vec);\n        }\n\n        // Horizontal add to get the sum of squares\n        __m128 sum_low = _mm_add_ps(_mm256_castps256_ps128(sum), _mm256_extractf128_ps(sum, 1));\n        sum_low = _mm_add_ps(sum_low, _mm_movehl_ps(sum_low, sum_low));\n        sum_low = _mm_add_ss(sum_low, _mm_shuffle_ps(sum_low, sum_low, 1));\n\n        float norm = sqrtf(_mm_cvtss_f32(sum_low));\n\n        // Avoid division by zero\n        if (norm == 0.0f) continue;\n\n        // Normalize the row\n        j = 0;\n        for (; j <= n - 8; j += 8) {\n            __m256 vec = _mm256_loadu_ps(&row[j]);\n            vec = _mm256_div_ps(vec, _mm256_set1_ps(norm));\n            _mm256_storeu_ps(&row[j], vec);\n        }\n\n        // Handle remaining elements\n        for (; j < n; ++j) {\n            row[j] /= norm;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_23_AVX", "completion": "```cpp\nvoid matrix_normalize_rows_simd(float* mat, size_t m, size_t n) {\n    for (size_t i = 0; i < m; ++i) {\n        float* row = mat + i * n;\n        __m256 sum = _mm256_setzero_ps();\n        size_t j = 0;\n\n        // Process 8 elements at a time\n        for (; j <= n - 8; j += 8) {\n            __m256 vec = _mm256_loadu_ps(&row[j]);\n            vec = _mm256_mul_ps(vec, vec);\n            sum = _mm256_add_ps(sum, vec);\n        }\n\n        // Horizontal add to get the sum of squares\n        __m128 sum_low = _mm_add_ps(_mm256_castps256_ps128(sum), _mm256_extractf128_ps(sum, 1));\n        sum_low = _mm_add_ps(sum_low, _mm_movehl_ps(sum_low, sum_low));\n        sum_low = _mm_add_ss(sum_low, _mm_shuffle_ps(sum_low, sum_low, 1));\n\n        float norm = sqrtf(_mm_cvtss_f32(sum_low));\n\n        // Avoid division by zero\n        if (norm == 0.0f) continue;\n\n        __m256 norm_vec = _mm256_set1_ps(norm);\n\n        // Normalize 8 elements at a time\n        j = 0;\n        for (; j <= n - 8; j += 8) {\n            __m256 vec = _mm256_loadu_ps(&row[j]);\n            vec = _mm256_div_ps(vec, norm_vec);\n            _mm256_storeu_ps(&row[j], vec);\n        }\n\n        // Handle remaining elements\n        for (; j < n; ++j) {\n            row[j] /= norm;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_24_AVX", "completion": "```cpp\nvoid matrix_mul_round_int_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n, size_t p) {\n    for (size_t i = 0; i < m; ++i) {\n        for (size_t j = 0; j < p; j += 4) {\n            __m256d sum = _mm256_setzero_pd();\n            for (size_t k = 0; k < n; ++k) {\n                __m256d a = _mm256_broadcast_sd(&mat1[i * n + k]);\n                __m256d b = _mm256_loadu_pd(&mat2[k * p + j]);\n                sum = _mm256_fmadd_pd(a, b, sum);\n            }\n            __m256d rounded = _mm256_round_pd(sum, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n            _mm256_storeu_pd(&dst[i * p + j], rounded);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_24_AVX", "completion": "```cpp\nvoid matrix_mul_round_int_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n, size_t p) {\n    for (size_t i = 0; i < m; ++i) {\n        for (size_t j = 0; j < p; j += 4) {\n            __m256d sum = _mm256_setzero_pd();\n            for (size_t k = 0; k < n; ++k) {\n                __m256d mat1_vec = _mm256_broadcast_sd(&mat1[i * n + k]);\n                __m256d mat2_vec = _mm256_loadu_pd(&mat2[k * p + j]);\n                sum = _mm256_fmadd_pd(mat1_vec, mat2_vec, sum);\n            }\n            __m256d rounded_sum = _mm256_round_pd(sum, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n            _mm256_storeu_pd(&dst[i * p + j], rounded_sum);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_24_AVX", "completion": "```cpp\nvoid matrix_mul_round_int_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n, size_t p) {\n    for (size_t i = 0; i < m; ++i) {\n        for (size_t j = 0; j < p; j += 4) {\n            __m256d sum = _mm256_setzero_pd();\n            for (size_t k = 0; k < n; ++k) {\n                __m256d a = _mm256_broadcast_sd(&mat1[i * n + k]);\n                __m256d b = _mm256_loadu_pd(&mat2[k * p + j]);\n                sum = _mm256_fmadd_pd(a, b, sum);\n            }\n            __m256d rounded = _mm256_round_pd(sum, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n            _mm256_storeu_pd(&dst[i * p + j], rounded);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_24_AVX", "completion": "```cpp\nvoid matrix_mul_round_int_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n, size_t p) {\n    for (size_t i = 0; i < m; ++i) {\n        for (size_t j = 0; j < p; j += 4) {\n            __m256d sum = _mm256_setzero_pd();\n            for (size_t k = 0; k < n; ++k) {\n                __m256d a = _mm256_broadcast_sd(&mat1[i * n + k]);\n                __m256d b = _mm256_loadu_pd(&mat2[k * p + j]);\n                sum = _mm256_fmadd_pd(a, b, sum);\n            }\n            __m256d rounded = _mm256_round_pd(sum, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n            _mm256_storeu_pd(&dst[i * p + j], rounded);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_24_AVX", "completion": "```cpp\nvoid matrix_mul_round_int_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n, size_t p) {\n    for (size_t i = 0; i < m; ++i) {\n        for (size_t j = 0; j < p; j += 4) {\n            __m256d sum = _mm256_setzero_pd();\n            for (size_t k = 0; k < n; ++k) {\n                __m256d a = _mm256_broadcast_sd(&mat1[i * n + k]);\n                __m256d b = _mm256_loadu_pd(&mat2[k * p + j]);\n                sum = _mm256_fmadd_pd(a, b, sum);\n            }\n            __m256d rounded = _mm256_round_pd(sum, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n            _mm256_storeu_pd(&dst[i * p + j], rounded);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_25_AVX", "completion": "```cpp\nvoid matrix_transpose_round_quarter_simd(const float* src, float* dst, size_t rows, size_t cols) {\n    const __m256 quarter = _mm256_set1_ps(0.25f);\n    const __m256 half = _mm256_set1_ps(0.5f);\n\n    for (size_t c = 0; c < cols; c += 8) {\n        for (size_t r = 0; r < rows; ++r) {\n            __m256 row = _mm256_loadu_ps(&src[r * cols + c]);\n            row = _mm256_round_ps(_mm256_add_ps(row, half), _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n            row = _mm256_mul_ps(row, quarter);\n            row = _mm256_round_ps(_mm256_add_ps(row, half), _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n            row = _mm256_mul_ps(row, _mm256_set1_ps(4.0f));\n            _mm256_storeu_ps(&dst[c * rows + r], row);\n        }\n    }\n\n    // Handle remaining columns (if cols % 8 != 0)\n    if (cols % 8 != 0) {\n        for (size_t c = cols - (cols % 8); c < cols; ++c) {\n            for (size_t r = 0; r < rows; ++r) {\n                float value = src[r * cols + c];\n                value = std::round(value * 4.0f) / 4.0f;\n                dst[c * rows + r] = value;\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_25_AVX", "completion": "```cpp\nvoid matrix_transpose_round_quarter_simd(const float* src, float* dst, size_t rows, size_t cols) {\n    const __m256 quarter = _mm256_set1_ps(0.25f);\n    const __m256 half = _mm256_set1_ps(0.5f);\n\n    for (size_t c = 0; c < cols; c += 8) {\n        for (size_t r = 0; r < rows; ++r) {\n            __m256 row = _mm256_loadu_ps(&src[r * cols + c]);\n            row = _mm256_round_ps(_mm256_add_ps(row, half), _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n            row = _mm256_mul_ps(row, quarter);\n            row = _mm256_round_ps(_mm256_add_ps(row, half), _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n            row = _mm256_mul_ps(row, _mm256_set1_ps(4.0f));\n            _mm256_storeu_ps(&dst[c * rows + r], row);\n        }\n    }\n\n    // Handle remaining columns (if cols % 8 != 0)\n    if (cols % 8 != 0) {\n        for (size_t c = cols - cols % 8; c < cols; ++c) {\n            for (size_t r = 0; r < rows; ++r) {\n                float value = src[r * cols + c];\n                value = std::round(value * 4.0f) / 4.0f;\n                dst[c * rows + r] = value;\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_25_AVX", "completion": "```cpp\nvoid matrix_transpose_round_quarter_simd(const float* src, float* dst, size_t rows, size_t cols) {\n    const __m256 quarter = _mm256_set1_ps(0.25f);\n    const __m256 half = _mm256_set1_ps(0.5f);\n\n    for (size_t c = 0; c < cols; c += 8) {\n        for (size_t r = 0; r < rows; ++r) {\n            __m256 row = _mm256_loadu_ps(&src[r * cols + c]);\n            row = _mm256_round_ps(_mm256_add_ps(row, half), _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n            row = _mm256_mul_ps(_mm256_div_ps(row, quarter), quarter);\n            _mm256_storeu_ps(&dst[c * rows + r], row);\n        }\n    }\n\n    // Handle remaining columns (if cols % 8 != 0)\n    if (cols % 8 != 0) {\n        for (size_t c = cols - cols % 8; c < cols; ++c) {\n            for (size_t r = 0; r < rows; ++r) {\n                float value = src[r * cols + c];\n                value = roundf(value / 0.25f) * 0.25f;\n                dst[c * rows + r] = value;\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_25_AVX", "completion": "```cpp\nvoid matrix_transpose_round_quarter_simd(const float* src, float* dst, size_t rows, size_t cols) {\n    const __m256 quarter = _mm256_set1_ps(0.25f);\n    const __m256 half = _mm256_set1_ps(0.5f);\n\n    for (size_t c = 0; c < cols; c += 8) {\n        for (size_t r = 0; r < rows; ++r) {\n            __m256 row = _mm256_loadu_ps(&src[r * cols + c]);\n            row = _mm256_round_ps(_mm256_add_ps(row, half), _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n            row = _mm256_mul_ps(row, quarter);\n            row = _mm256_round_ps(_mm256_add_ps(row, half), _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n            row = _mm256_mul_ps(row, _mm256_set1_ps(4.0f));\n            _mm256_storeu_ps(&dst[c * rows + r], row);\n        }\n    }\n\n    // Handle remaining columns (if any)\n    for (size_t c = (cols / 8) * 8; c < cols; ++c) {\n        for (size_t r = 0; r < rows; ++r) {\n            float value = src[r * cols + c];\n            value = std::round(value * 4.0f) / 4.0f;\n            dst[c * rows + r] = value;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_25_AVX", "completion": "```cpp\nvoid matrix_transpose_round_quarter_simd(const float* src, float* dst, size_t rows, size_t cols) {\n    const __m256 quarter = _mm256_set1_ps(0.25f);\n    const __m256 half = _mm256_set1_ps(0.5f);\n\n    for (size_t c = 0; c < cols; c += 8) {\n        for (size_t r = 0; r < rows; ++r) {\n            __m256 row = _mm256_loadu_ps(&src[r * cols + c]);\n            row = _mm256_round_ps(_mm256_add_ps(row, half), _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n            row = _mm256_mul_ps(row, quarter);\n            row = _mm256_round_ps(_mm256_add_ps(row, half), _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n            row = _mm256_mul_ps(row, _mm256_set1_ps(4.0f));\n            _mm256_storeu_ps(&dst[c * rows + r], row);\n        }\n    }\n\n    // Handle remaining columns (if cols % 8 != 0)\n    if (cols % 8 != 0) {\n        for (size_t c = cols - (cols % 8); c < cols; ++c) {\n            for (size_t r = 0; r < rows; ++r) {\n                float value = src[r * cols + c];\n                value = std::round(value * 4.0f) / 4.0f;\n                dst[c * rows + r] = value;\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_26_AVX", "completion": "```cpp\nvoid tensor3d_sub_round_zero_simd(const float* tensor1, const float* tensor2, float* dst, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t i = 0;\n\n    for (; i <= total_elements - 8; i += 8) {\n        __m256 vec1 = _mm256_loadu_ps(&tensor1[i]);\n        __m256 vec2 = _mm256_loadu_ps(&tensor2[i]);\n        __m256 result = _mm256_sub_ps(vec1, vec2);\n        __m256 rounded_result = _mm256_round_ps(result, _MM_FROUND_TO_ZERO);\n        _mm256_storeu_ps(&dst[i], rounded_result);\n    }\n\n    for (; i < total_elements; ++i) {\n        dst[i] = (float)((int)(tensor1[i] - tensor2[i]));\n    }\n}\n```"}
{"task_id": "SimdBench_26_AVX", "completion": "```cpp\nvoid tensor3d_sub_round_zero_simd(const float* tensor1, const float* tensor2, float* dst, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t i = 0;\n\n    for (; i <= total_elements - 8; i += 8) {\n        __m256 vec1 = _mm256_loadu_ps(&tensor1[i]);\n        __m256 vec2 = _mm256_loadu_ps(&tensor2[i]);\n        __m256 result = _mm256_sub_ps(vec1, vec2);\n        __m256 rounded_result = _mm256_round_ps(result, _MM_FROUND_TO_ZERO);\n        _mm256_storeu_ps(&dst[i], rounded_result);\n    }\n\n    for (; i < total_elements; ++i) {\n        dst[i] = (float)((int)(tensor1[i] - tensor2[i]));\n    }\n}\n```"}
{"task_id": "SimdBench_26_AVX", "completion": "```cpp\nvoid tensor3d_sub_round_zero_simd(const float* tensor1, const float* tensor2, float* dst, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t i = 0;\n    for (; i <= total_elements - 8; i += 8) {\n        __m256 vec1 = _mm256_loadu_ps(&tensor1[i]);\n        __m256 vec2 = _mm256_loadu_ps(&tensor2[i]);\n        __m256 result = _mm256_sub_ps(vec1, vec2);\n        __m256 rounded_result = _mm256_round_ps(result, _MM_FROUND_TO_ZERO);\n        _mm256_storeu_ps(&dst[i], rounded_result);\n    }\n    for (; i < total_elements; ++i) {\n        dst[i] = (float)((int)(tensor1[i] - tensor2[i]));\n    }\n}\n```"}
{"task_id": "SimdBench_26_AVX", "completion": "```cpp\nvoid tensor3d_sub_round_zero_simd(const float* tensor1, const float* tensor2, float* dst, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t i = 0;\n    for (; i <= total_elements - 8; i += 8) {\n        __m256 vec1 = _mm256_loadu_ps(&tensor1[i]);\n        __m256 vec2 = _mm256_loadu_ps(&tensor2[i]);\n        __m256 result = _mm256_sub_ps(vec1, vec2);\n        __m256 rounded_result = _mm256_round_ps(result, _MM_FROUND_TO_ZERO);\n        _mm256_storeu_ps(&dst[i], rounded_result);\n    }\n    for (; i < total_elements; ++i) {\n        dst[i] = (float)((int)(tensor1[i] - tensor2[i]));\n    }\n}\n```"}
{"task_id": "SimdBench_26_AVX", "completion": "```cpp\nvoid tensor3d_sub_round_zero_simd(const float* tensor1, const float* tensor2, float* dst, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t i = 0;\n    for (; i <= total_elements - 8; i += 8) {\n        __m256 vec1 = _mm256_loadu_ps(&tensor1[i]);\n        __m256 vec2 = _mm256_loadu_ps(&tensor2[i]);\n        __m256 result = _mm256_sub_ps(vec1, vec2);\n        __m256 rounded_result = _mm256_round_ps(result, _MM_FROUND_TO_ZERO);\n        _mm256_storeu_ps(&dst[i], rounded_result);\n    }\n    for (; i < total_elements; ++i) {\n        dst[i] = (float)((int)(tensor1[i] - tensor2[i]));\n    }\n}\n```"}
{"task_id": "SimdBench_27_AVX", "completion": "```cpp\nvoid matrix_hadamard_product_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n) {\n    size_t total_elements = m * n;\n    size_t i = 0;\n\n    // Process 4 elements at a time using AVX\n    for (; i <= total_elements - 4; i += 4) {\n        __m256d vec1 = _mm256_loadu_pd(&mat1[i]);\n        __m256d vec2 = _mm256_loadu_pd(&mat2[i]);\n        __m256d result = _mm256_mul_pd(vec1, vec2);\n        _mm256_storeu_pd(&dst[i], result);\n    }\n\n    // Process remaining elements\n    for (; i < total_elements; ++i) {\n        dst[i] = mat1[i] * mat2[i];\n    }\n}\n```"}
{"task_id": "SimdBench_27_AVX", "completion": "```cpp\nvoid matrix_hadamard_product_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n) {\n    size_t total_elements = m * n;\n    size_t i = 0;\n\n    for (; i <= total_elements - 4; i += 4) {\n        __m256d vec1 = _mm256_loadu_pd(&mat1[i]);\n        __m256d vec2 = _mm256_loadu_pd(&mat2[i]);\n        __m256d result = _mm256_mul_pd(vec1, vec2);\n        _mm256_storeu_pd(&dst[i], result);\n    }\n\n    for (; i < total_elements; ++i) {\n        dst[i] = mat1[i] * mat2[i];\n    }\n}\n```"}
{"task_id": "SimdBench_27_AVX", "completion": "```cpp\nvoid matrix_hadamard_product_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n) {\n    size_t total_elements = m * n;\n    size_t i = 0;\n\n    for (; i <= total_elements - 4; i += 4) {\n        __m256d vec1 = _mm256_loadu_pd(&mat1[i]);\n        __m256d vec2 = _mm256_loadu_pd(&mat2[i]);\n        __m256d result = _mm256_mul_pd(vec1, vec2);\n        _mm256_storeu_pd(&dst[i], result);\n    }\n\n    for (; i < total_elements; ++i) {\n        dst[i] = mat1[i] * mat2[i];\n    }\n}\n```"}
{"task_id": "SimdBench_27_AVX", "completion": "```cpp\nvoid matrix_hadamard_product_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n) {\n    size_t total_elements = m * n;\n    size_t i = 0;\n\n    for (; i <= total_elements - 4; i += 4) {\n        __m256d vec1 = _mm256_loadu_pd(&mat1[i]);\n        __m256d vec2 = _mm256_loadu_pd(&mat2[i]);\n        __m256d result = _mm256_mul_pd(vec1, vec2);\n        _mm256_storeu_pd(&dst[i], result);\n    }\n\n    for (; i < total_elements; ++i) {\n        dst[i] = mat1[i] * mat2[i];\n    }\n}\n```"}
{"task_id": "SimdBench_27_AVX", "completion": "```cpp\nvoid matrix_hadamard_product_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n) {\n    size_t total_elements = m * n;\n    size_t i = 0;\n\n    for (; i <= total_elements - 4; i += 4) {\n        __m256d vec1 = _mm256_loadu_pd(&mat1[i]);\n        __m256d vec2 = _mm256_loadu_pd(&mat2[i]);\n        __m256d result = _mm256_mul_pd(vec1, vec2);\n        _mm256_storeu_pd(&dst[i], result);\n    }\n\n    for (; i < total_elements; ++i) {\n        dst[i] = mat1[i] * mat2[i];\n    }\n}\n```"}
{"task_id": "SimdBench_28_AVX", "completion": "```cpp\nvoid matrix_vector_mul_simd(const float* mat, const float* vec, float* dst, size_t m, size_t n) {\n    for (size_t i = 0; i < m; ++i) {\n        __m256 sum = _mm256_setzero_ps();\n        size_t j = 0;\n        for (; j <= n - 8; j += 8) {\n            __m256 mat_row = _mm256_loadu_ps(&mat[i * n + j]);\n            __m256 vec_col = _mm256_loadu_ps(&vec[j]);\n            sum = _mm256_fmadd_ps(mat_row, vec_col, sum);\n        }\n        float temp[8];\n        _mm256_storeu_ps(temp, sum);\n        float s = temp[0] + temp[1] + temp[2] + temp[3] + temp[4] + temp[5] + temp[6] + temp[7];\n\n        for (; j < n; ++j) {\n            s += mat[i * n + j] * vec[j];\n        }\n        dst[i] = s;\n    }\n}\n```"}
{"task_id": "SimdBench_28_AVX", "completion": "```cpp\nvoid matrix_vector_mul_simd(const float* mat, const float* vec, float* dst, size_t m, size_t n) {\n    for (size_t i = 0; i < m; ++i) {\n        __m256 sum = _mm256_setzero_ps();\n        size_t j = 0;\n        for (; j <= n - 8; j += 8) {\n            __m256 mat_row = _mm256_loadu_ps(&mat[i * n + j]);\n            __m256 vec_col = _mm256_loadu_ps(&vec[j]);\n            sum = _mm256_fmadd_ps(mat_row, vec_col, sum);\n        }\n        float temp[8];\n        _mm256_storeu_ps(temp, sum);\n        float s = temp[0] + temp[1] + temp[2] + temp[3] + temp[4] + temp[5] + temp[6] + temp[7];\n\n        for (; j < n; ++j) {\n            s += mat[i * n + j] * vec[j];\n        }\n        dst[i] = s;\n    }\n}\n```"}
{"task_id": "SimdBench_28_AVX", "completion": "```cpp\nvoid matrix_vector_mul_simd(const float* mat, const float* vec, float* dst, size_t m, size_t n) {\n    for (size_t i = 0; i < m; ++i) {\n        __m256 sum = _mm256_setzero_ps();\n        size_t j;\n        for (j = 0; j <= n - 8; j += 8) {\n            __m256 mat_row = _mm256_loadu_ps(&mat[i * n + j]);\n            __m256 vec_col = _mm256_loadu_ps(&vec[j]);\n            sum = _mm256_fmadd_ps(mat_row, vec_col, sum);\n        }\n        float temp[8];\n        _mm256_storeu_ps(temp, sum);\n        float s = temp[0] + temp[1] + temp[2] + temp[3] + temp[4] + temp[5] + temp[6] + temp[7];\n\n        for (; j < n; ++j) {\n            s += mat[i * n + j] * vec[j];\n        }\n        dst[i] = s;\n    }\n}\n```"}
{"task_id": "SimdBench_28_AVX", "completion": "```cpp\nvoid matrix_vector_mul_simd(const float* mat, const float* vec, float* dst, size_t m, size_t n) {\n    for (size_t i = 0; i < m; ++i) {\n        __m256 sum = _mm256_setzero_ps();\n        size_t j;\n        for (j = 0; j <= n - 8; j += 8) {\n            __m256 mat_row = _mm256_loadu_ps(&mat[i * n + j]);\n            __m256 vec_col = _mm256_loadu_ps(&vec[j]);\n            sum = _mm256_fmadd_ps(mat_row, vec_col, sum);\n        }\n        float temp[8];\n        _mm256_storeu_ps(temp, sum);\n        float s = temp[0] + temp[1] + temp[2] + temp[3] + temp[4] + temp[5] + temp[6] + temp[7];\n\n        for (; j < n; ++j) {\n            s += mat[i * n + j] * vec[j];\n        }\n        dst[i] = s;\n    }\n}\n```"}
{"task_id": "SimdBench_28_AVX", "completion": "```cpp\nvoid matrix_vector_mul_simd(const float* mat, const float* vec, float* dst, size_t m, size_t n) {\n    for (size_t i = 0; i < m; ++i) {\n        __m256 sum = _mm256_setzero_ps();\n        size_t j = 0;\n        for (; j <= n - 8; j += 8) {\n            __m256 mat_row = _mm256_loadu_ps(&mat[i * n + j]);\n            __m256 vec_col = _mm256_loadu_ps(&vec[j]);\n            sum = _mm256_fmadd_ps(mat_row, vec_col, sum);\n        }\n        float temp[8];\n        _mm256_storeu_ps(temp, sum);\n        float s = temp[0] + temp[1] + temp[2] + temp[3] + temp[4] + temp[5] + temp[6] + temp[7];\n\n        for (; j < n; ++j) {\n            s += mat[i * n + j] * vec[j];\n        }\n        dst[i] = s;\n    }\n}\n```"}
{"task_id": "SimdBench_29_AVX", "completion": "```cpp\ndouble matrix_average_simd(const double* mat, size_t m, size_t n) {\n    __m256d sum = _mm256_setzero_pd();\n    size_t total_elements = m * n;\n    size_t i = 0;\n\n    for (; i <= total_elements - 4; i += 4) {\n        __m256d vec = _mm256_loadu_pd(&mat[i]);\n        sum = _mm256_add_pd(sum, vec);\n    }\n\n    double temp[4];\n    _mm256_storeu_pd(temp, sum);\n    double total_sum = temp[0] + temp[1] + temp[2] + temp[3];\n\n    for (; i < total_elements; ++i) {\n        total_sum += mat[i];\n    }\n\n    return total_sum / total_elements;\n}\n```"}
{"task_id": "SimdBench_29_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\ndouble matrix_average_simd(const double* mat, size_t m, size_t n) {\n    size_t total_elements = m * n;\n    size_t i = 0;\n    __m256d sum = _mm256_setzero_pd();\n    double result[4] = {0.0};\n\n    for (; i <= total_elements - 4; i += 4) {\n        __m256d vec = _mm256_loadu_pd(&mat[i]);\n        sum = _mm256_add_pd(sum, vec);\n    }\n\n    _mm256_storeu_pd(result, sum);\n    double total_sum = result[0] + result[1] + result[2] + result[3];\n\n    for (; i < total_elements; ++i) {\n        total_sum += mat[i];\n    }\n\n    return total_sum / total_elements;\n}\n```"}
{"task_id": "SimdBench_29_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\ndouble matrix_average_simd(const double* mat, size_t m, size_t n) {\n    size_t total_elements = m * n;\n    size_t i = 0;\n    __m256d sum = _mm256_setzero_pd();\n    double result[4] = {0.0};\n\n    for (; i <= total_elements - 4; i += 4) {\n        __m256d vec = _mm256_loadu_pd(&mat[i]);\n        sum = _mm256_add_pd(sum, vec);\n    }\n\n    _mm256_storeu_pd(result, sum);\n    double total_sum = result[0] + result[1] + result[2] + result[3];\n\n    for (; i < total_elements; ++i) {\n        total_sum += mat[i];\n    }\n\n    return total_sum / total_elements;\n}\n```"}
{"task_id": "SimdBench_29_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\ndouble matrix_average_simd(const double* mat, size_t m, size_t n) {\n    size_t total_elements = m * n;\n    size_t i = 0;\n    __m256d sum_vec = _mm256_setzero_pd();\n    double sum[4] = {0.0};\n\n    for (; i <= total_elements - 4; i += 4) {\n        __m256d mat_vec = _mm256_loadu_pd(&mat[i]);\n        sum_vec = _mm256_add_pd(sum_vec, mat_vec);\n    }\n\n    _mm256_storeu_pd(sum, sum_vec);\n\n    double total_sum = sum[0] + sum[1] + sum[2] + sum[3];\n\n    for (; i < total_elements; ++i) {\n        total_sum += mat[i];\n    }\n\n    return total_sum / total_elements;\n}\n```"}
{"task_id": "SimdBench_29_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\ndouble matrix_average_simd(const double* mat, size_t m, size_t n) {\n    size_t total_elements = m * n;\n    size_t i = 0;\n    __m256d sum_vec = _mm256_setzero_pd();\n    double sum[4] = {0.0};\n\n    for (; i <= total_elements - 4; i += 4) {\n        __m256d mat_vec = _mm256_loadu_pd(&mat[i]);\n        sum_vec = _mm256_add_pd(sum_vec, mat_vec);\n    }\n\n    _mm256_storeu_pd(sum, sum_vec);\n\n    double total_sum = sum[0] + sum[1] + sum[2] + sum[3];\n\n    for (; i < total_elements; ++i) {\n        total_sum += mat[i];\n    }\n\n    return total_sum / total_elements;\n}\n```"}
{"task_id": "SimdBench_30_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nbool matrix_rows_sorted_verify_simd(const int* matrix, const bool* directions, size_t rows, size_t cols) {\n    for (size_t i = 0; i < rows; ++i) {\n        const int* row = matrix + i * cols;\n        __m256i prev = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(row));\n        __m256i mask_asc = _mm256_setzero_si256();\n        __m256i mask_desc = _mm256_setzero_si256();\n\n        for (size_t j = 1; j <= cols - 8; j += 8) {\n            __m256i curr = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(row + j));\n            mask_asc = _mm256_or_si256(mask_asc, _mm256_cmpgt_epi32(prev, curr));\n            mask_desc = _mm256_or_si256(mask_desc, _mm256_cmplt_epi32(prev, curr));\n            prev = curr;\n        }\n\n        if (directions[i]) {\n            if (!_mm256_testz_si256(mask_asc, mask_asc)) {\n                return false;\n            }\n        } else {\n            if (!_mm256_testz_si256(mask_desc, mask_desc)) {\n                return false;\n            }\n        }\n\n        // Handle remaining elements\n        for (size_t j = (cols / 8) * 8; j < cols - 1; ++j) {\n            if ((directions[i] && row[j] > row[j + 1]) || (!directions[i] && row[j] < row[j + 1])) {\n                return false;\n            }\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_30_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nbool matrix_rows_sorted_verify_simd(const int* matrix, const bool* directions, size_t rows, size_t cols) {\n    for (size_t i = 0; i < rows; ++i) {\n        const int* row = matrix + i * cols;\n        __m256i prev = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(row));\n        __m256i mask_asc = _mm256_setzero_si256();\n        __m256i mask_desc = _mm256_setzero_si256();\n\n        for (size_t j = 1; j <= cols - 8; j += 8) {\n            __m256i curr = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(row + j));\n            mask_asc = _mm256_or_si256(mask_asc, _mm256_cmpgt_epi32(prev, curr));\n            mask_desc = _mm256_or_si256(mask_desc, _mm256_cmplt_epi32(prev, curr));\n            prev = curr;\n        }\n\n        if (directions[i]) {\n            if (!_mm256_testz_si256(mask_asc, mask_asc)) {\n                return false;\n            }\n        } else {\n            if (!_mm256_testz_si256(mask_desc, mask_desc)) {\n                return false;\n            }\n        }\n\n        // Handle remaining elements\n        for (size_t j = (cols / 8) * 8; j < cols - 1; ++j) {\n            if ((directions[i] && row[j] > row[j + 1]) || (!directions[i] && row[j] < row[j + 1])) {\n                return false;\n            }\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_30_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nbool matrix_rows_sorted_verify_simd(const int* matrix, const bool* directions, size_t rows, size_t cols) {\n    for (size_t i = 0; i < rows; ++i) {\n        __m256i prev = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(matrix + i * cols));\n        __m256i mask_asc = _mm256_set1_epi32(0);\n        __m256i mask_desc = _mm256_set1_epi32(0);\n\n        for (size_t j = 1; j <= cols - 8; j += 8) {\n            __m256i curr = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(matrix + i * cols + j));\n            mask_asc = _mm256_or_si256(mask_asc, _mm256_cmpgt_epi32(prev, curr));\n            mask_desc = _mm256_or_si256(mask_desc, _mm256_cmplt_epi32(prev, curr));\n            prev = curr;\n        }\n\n        if (directions[i]) {\n            if (!_mm256_testz_si256(mask_asc, mask_asc)) {\n                return false;\n            }\n        } else {\n            if (!_mm256_testz_si256(mask_desc, mask_desc)) {\n                return false;\n            }\n        }\n\n        for (size_t j = (cols / 8) * 8; j < cols; ++j) {\n            if (directions[i] && matrix[i * cols + j] < matrix[i * cols + j - 1]) {\n                return false;\n            }\n            if (!directions[i] && matrix[i * cols + j] > matrix[i * cols + j - 1]) {\n                return false;\n            }\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_30_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nbool matrix_rows_sorted_verify_simd(const int* matrix, const bool* directions, size_t rows, size_t cols) {\n    for (size_t i = 0; i < rows; ++i) {\n        __m256i prev = _mm256_set1_epi32(matrix[i * cols]);\n        __m256i mask_asc = _mm256_setzero_si256();\n        __m256i mask_desc = _mm256_setzero_si256();\n        bool ascending = directions[i];\n\n        for (size_t j = 1; j <= cols - 8; j += 8) {\n            __m256i current = _mm256_loadu_si256((__m256i const*)(matrix + i * cols + j));\n            mask_asc = _mm256_or_si256(mask_asc, _mm256_cmpgt_epi32(prev, current));\n            mask_desc = _mm256_or_si256(mask_desc, _mm256_cmplt_epi32(prev, current));\n            prev = current;\n        }\n\n        if (ascending && !_mm256_testz_si256(mask_asc, mask_asc)) {\n            return false;\n        }\n        if (!ascending && !_mm256_testz_si256(mask_desc, mask_desc)) {\n            return false;\n        }\n\n        // Handle remaining elements\n        for (size_t j = ((cols - 1) / 8) * 8 + 1; j < cols; ++j) {\n            if ((ascending && matrix[i * cols + j - 1] > matrix[i * cols + j]) ||\n                (!ascending && matrix[i * cols + j - 1] < matrix[i * cols + j])) {\n                return false;\n            }\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_30_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nbool matrix_rows_sorted_verify_simd(const int* matrix, const bool* directions, size_t rows, size_t cols) {\n    for (size_t i = 0; i < rows; ++i) {\n        __m256i prev = _mm256_set1_epi32(matrix[i * cols]);\n        __m256i mask_asc = _mm256_setzero_si256();\n        __m256i mask_desc = _mm256_setzero_si256();\n\n        for (size_t j = 1; j <= cols - 8; j += 8) {\n            __m256i current = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&matrix[i * cols + j]));\n            mask_asc = _mm256_or_si256(mask_asc, _mm256_cmpgt_epi32(prev, current));\n            mask_desc = _mm256_or_si256(mask_desc, _mm256_cmplt_epi32(prev, current));\n            prev = current;\n        }\n\n        if (directions[i]) {\n            if (!_mm256_testz_si256(mask_asc, mask_asc)) {\n                return false;\n            }\n        } else {\n            if (!_mm256_testz_si256(mask_desc, mask_desc)) {\n                return false;\n            }\n        }\n\n        for (size_t j = ((cols - 1) / 8) * 8 + 1; j < cols; ++j) {\n            if (directions[i] && matrix[i * cols + j - 1] > matrix[i * cols + j]) {\n                return false;\n            }\n            if (!directions[i] && matrix[i * cols + j - 1] < matrix[i * cols + j]) {\n                return false;\n            }\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_31_AVX", "completion": "```cpp\nvoid nearest_multiple_simd(const int16_t* src, int16_t* dst, uint8_t base, size_t length) {\n    __m256i base_vec = _mm256_set1_epi16(base);\n    size_t i = 0;\n    for (; i <= length - 16; i += 16) {\n        __m256i src_vec = _mm256_loadu_si256((__m256i const*)(src + i));\n        __m256i div_vec = _mm256_div_epi16(src_vec, base_vec);\n        __m256i result_vec = _mm256_mullo_epi16(div_vec, base_vec);\n        _mm256_storeu_si256((__m256i*)(dst + i), result_vec);\n    }\n    for (; i < length; ++i) {\n        dst[i] = (src[i] / base) * base;\n    }\n}\n```"}
{"task_id": "SimdBench_31_AVX", "completion": "```cpp\nvoid nearest_multiple_simd(const int16_t* src, int16_t* dst, uint8_t base, size_t length) {\n    __m256i base_vec = _mm256_set1_epi16(base);\n    size_t i = 0;\n    for (; i <= length - 16; i += 16) {\n        __m256i src_vec = _mm256_loadu_si256((__m256i const*)(src + i));\n        __m256i div_result = _mm256_div_epi16(src_vec, base_vec);\n        __m256i result = _mm256_mullo_epi16(div_result, base_vec);\n        _mm256_storeu_si256((__m256i*)(dst + i), result);\n    }\n    for (; i < length; ++i) {\n        dst[i] = (src[i] / base) * base;\n    }\n}\n```"}
{"task_id": "SimdBench_31_AVX", "completion": "```cpp\nvoid nearest_multiple_simd(const int16_t* src, int16_t* dst, uint8_t base, size_t length) {\n    __m256i base_vec = _mm256_set1_epi16(base);\n    size_t i = 0;\n    for (; i <= length - 16; i += 16) {\n        __m256i src_vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(src + i));\n        __m256i div_result = _mm256_div_epi16(src_vec, base_vec);\n        __m256i result = _mm256_mullo_epi16(div_result, base_vec);\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(dst + i), result);\n    }\n    for (; i < length; ++i) {\n        dst[i] = (src[i] / base) * base;\n    }\n}\n```"}
{"task_id": "SimdBench_31_AVX", "completion": "```cpp\nvoid nearest_multiple_simd(const int16_t* src, int16_t* dst, uint8_t base, size_t length) {\n    __m256i base_vec = _mm256_set1_epi16(base);\n    size_t i = 0;\n    for (; i <= length - 16; i += 16) {\n        __m256i src_vec = _mm256_loadu_si256((__m256i const*)(src + i));\n        __m256i div_result = _mm256_div_epi16(src_vec, base_vec);\n        __m256i result = _mm256_mullo_epi16(div_result, base_vec);\n        _mm256_storeu_si256((__m256i*)(dst + i), result);\n    }\n    for (; i < length; ++i) {\n        dst[i] = (src[i] / base) * base;\n    }\n}\n```"}
{"task_id": "SimdBench_31_AVX", "completion": "```cpp\nvoid nearest_multiple_simd(const int16_t* src, int16_t* dst, uint8_t base, size_t length) {\n    __m256i base_vec = _mm256_set1_epi16(base);\n    size_t i = 0;\n    for (; i <= length - 16; i += 16) {\n        __m256i src_vec = _mm256_loadu_si256((__m256i const*)(src + i));\n        __m256i div_result = _mm256_div_epi16(src_vec, base_vec);\n        __m256i result = _mm256_mullo_epi16(div_result, base_vec);\n        _mm256_storeu_si256((__m256i*)(dst + i), result);\n    }\n    for (; i < length; ++i) {\n        dst[i] = (src[i] / base) * base;\n    }\n}\n```"}
{"task_id": "SimdBench_32_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nbool matrix_has_row_simd(const double* matrix, const double* vector, size_t rows, size_t cols) {\n    __m256d vec = _mm256_loadu_pd(vector);\n    size_t i = 0;\n    for (; i <= rows - 4; i += 4) {\n        __m256d row1 = _mm256_loadu_pd(&matrix[i * cols]);\n        __m256d row2 = _mm256_loadu_pd(&matrix[(i + 1) * cols]);\n        __m256d row3 = _mm256_loadu_pd(&matrix[(i + 2) * cols]);\n        __m256d row4 = _mm256_loadu_pd(&matrix[(i + 3) * cols]);\n\n        __m256d cmp1 = _mm256_cmpeq_pd(row1, vec);\n        __m256d cmp2 = _mm256_cmpeq_pd(row2, vec);\n        __m256d cmp3 = _mm256_cmpeq_pd(row3, vec);\n        __m256d cmp4 = _mm256_cmpeq_pd(row4, vec);\n\n        if (_mm256_movemask_pd(cmp1) == 0xF && _mm256_testz_pd(cmp1, cmp1) == 0) return true;\n        if (_mm256_movemask_pd(cmp2) == 0xF && _mm256_testz_pd(cmp2, cmp2) == 0) return true;\n        if (_mm256_movemask_pd(cmp3) == 0xF && _mm256_testz_pd(cmp3, cmp3) == 0) return true;\n        if (_mm256_movemask_pd(cmp4) == 0xF && _mm256_testz_pd(cmp4, cmp4) == 0) return true;\n    }\n\n    for (; i < rows; ++i) {\n        bool match = true;\n        for (size_t j = 0; j < cols; ++j) {\n            if (matrix[i * cols + j] != vector[j]) {\n                match = false;\n                break;\n            }\n        }\n        if (match) return true;\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_32_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nbool matrix_has_row_simd(const double* matrix, const double* vector, size_t rows, size_t cols) {\n    __m256d vec = _mm256_loadu_pd(vector);\n    for (size_t i = 0; i < rows; ++i) {\n        bool match = true;\n        for (size_t j = 0; j < cols; j += 4) {\n            __m256d mat = _mm256_loadu_pd(&matrix[i * cols + j]);\n            __m256d cmp = _mm256_cmp_pd(mat, vec, _CMP_EQ_OQ);\n            if (_mm256_movemask_pd(cmp) != 0xF) {\n                match = false;\n                break;\n            }\n        }\n        if (match) {\n            return true;\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_32_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nbool matrix_has_row_simd(const double* matrix, const double* vector, size_t rows, size_t cols) {\n    __m256d vec = _mm256_loadu_pd(vector);\n    size_t i = 0;\n    for (; i <= rows - 4; i += 4) {\n        __m256d row1 = _mm256_loadu_pd(&matrix[i * cols]);\n        __m256d row2 = _mm256_loadu_pd(&matrix[(i + 1) * cols]);\n        __m256d row3 = _mm256_loadu_pd(&matrix[(i + 2) * cols]);\n        __m256d row4 = _mm256_loadu_pd(&matrix[(i + 3) * cols]);\n\n        __m256d cmp1 = _mm256_cmpeq_pd(row1, vec);\n        __m256d cmp2 = _mm256_cmpeq_pd(row2, vec);\n        __m256d cmp3 = _mm256_cmpeq_pd(row3, vec);\n        __m256d cmp4 = _mm256_cmpeq_pd(row4, vec);\n\n        if (_mm256_movemask_pd(cmp1) == 0xF && _mm256_testz_pd(cmp1, cmp1) == 0) return true;\n        if (_mm256_movemask_pd(cmp2) == 0xF && _mm256_testz_pd(cmp2, cmp2) == 0) return true;\n        if (_mm256_movemask_pd(cmp3) == 0xF && _mm256_testz_pd(cmp3, cmp3) == 0) return true;\n        if (_mm256_movemask_pd(cmp4) == 0xF && _mm256_testz_pd(cmp4, cmp4) == 0) return true;\n    }\n\n    for (; i < rows; ++i) {\n        bool match = true;\n        for (size_t j = 0; j < cols; ++j) {\n            if (matrix[i * cols + j] != vector[j]) {\n                match = false;\n                break;\n            }\n        }\n        if (match) return true;\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_32_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nbool matrix_has_row_simd(const double* matrix, const double* vector, size_t rows, size_t cols) {\n    __m256d vec = _mm256_loadu_pd(vector);\n    for (size_t i = 0; i < rows; ++i) {\n        const double* row = matrix + i * cols;\n        size_t j = 0;\n        for (; j <= cols - 4; j += 4) {\n            __m256d row_vec = _mm256_loadu_pd(row + j);\n            __m256d cmp = _mm256_cmp_pd(row_vec, vec, _CMP_EQ_OQ);\n            if (_mm256_movemask_pd(cmp) == 0xF) {\n                return true;\n            }\n        }\n        for (; j < cols; ++j) {\n            if (row[j] == vector[j % 4]) {\n                return true;\n            }\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_32_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nbool matrix_has_row_simd(const double* matrix, const double* vector, size_t rows, size_t cols) {\n    __m256d vec = _mm256_loadu_pd(vector);\n    for (size_t i = 0; i < rows; ++i) {\n        const double* row = matrix + i * cols;\n        size_t j = 0;\n        for (; j <= cols - 4; j += 4) {\n            __m256d row_vec = _mm256_loadu_pd(row + j);\n            __m256d cmp = _mm256_cmp_pd(row_vec, vec, _CMP_EQ_OQ);\n            if (_mm256_movemask_pd(cmp) == 0xF) {\n                return true;\n            }\n        }\n        for (; j < cols; ++j) {\n            if (row[j] == vector[j % 4]) {\n                return true;\n            }\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_33_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nsize_t tensor_4d_equal_count_simd(const uint8_t* A, const uint8_t* B, const size_t dims[4]) {\n    size_t total_elements = dims[0] * dims[1] * dims[2] * dims[3];\n    size_t i = 0;\n    __m256i count = _mm256_setzero_si256();\n\n    for (; i <= total_elements - 32; i += 32) {\n        __m256i vecA = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(A + i));\n        __m256i vecB = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(B + i));\n        __m256i eq = _mm256_cmpeq_epi8(vecA, vecB);\n        count = _mm256_add_epi8(count, eq);\n    }\n\n    __m256i horizontal_sum = _mm256_sad_epu8(count, _mm256_setzero_si256());\n    int64_t sum = _mm256_extract_epi64(horizontal_sum, 0) + _mm256_extract_epi64(horizontal_sum, 1);\n\n    for (; i < total_elements; ++i) {\n        sum += (A[i] == B[i]);\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_33_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nsize_t tensor_4d_equal_count_simd(const uint8_t* A, const uint8_t* B, const size_t dims[4]) {\n    size_t total_elements = dims[0] * dims[1] * dims[2] * dims[3];\n    size_t i = 0;\n    __m256i count = _mm256_setzero_si256();\n\n    for (; i <= total_elements - 32; i += 32) {\n        __m256i vecA = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(A + i));\n        __m256i vecB = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(B + i));\n        __m256i eq = _mm256_cmpeq_epi8(vecA, vecB);\n        count = _mm256_add_epi8(count, eq);\n    }\n\n    __m256i horizontal_sum = _mm256_sad_epu8(count, _mm256_setzero_si256());\n    int64_t sum = _mm256_extract_epi64(horizontal_sum, 0) + _mm256_extract_epi64(horizontal_sum, 1);\n\n    for (; i < total_elements; ++i) {\n        sum += (A[i] == B[i]);\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_33_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nsize_t tensor_4d_equal_count_simd(const uint8_t* A, const uint8_t* B, const size_t dims[4]) {\n    size_t total_elements = dims[0] * dims[1] * dims[2] * dims[3];\n    size_t i = 0;\n    __m256i count = _mm256_setzero_si256();\n\n    for (; i <= total_elements - 32; i += 32) {\n        __m256i vecA = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(A + i));\n        __m256i vecB = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(B + i));\n        __m256i eq = _mm256_cmpeq_epi8(vecA, vecB);\n        count = _mm256_add_epi8(count, eq);\n    }\n\n    __m256i horizontal_sum = _mm256_sad_epu8(count, _mm256_setzero_si256());\n    int64_t sum = _mm256_extract_epi64(horizontal_sum, 0) + _mm256_extract_epi64(horizontal_sum, 1);\n\n    for (; i < total_elements; ++i) {\n        sum += (A[i] == B[i]);\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_33_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nsize_t tensor_4d_equal_count_simd(const uint8_t* A, const uint8_t* B, const size_t dims[4]) {\n    size_t total_elements = dims[0] * dims[1] * dims[2] * dims[3];\n    size_t i = 0;\n    __m256i count = _mm256_setzero_si256();\n\n    for (; i <= total_elements - 32; i += 32) {\n        __m256i vecA = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(A + i));\n        __m256i vecB = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(B + i));\n        __m256i eq = _mm256_cmpeq_epi8(vecA, vecB);\n        count = _mm256_add_epi8(count, eq);\n    }\n\n    __m256i horizontal_sum = _mm256_sad_epu8(count, _mm256_setzero_si256());\n    int64_t sum = _mm256_extract_epi64(horizontal_sum, 0) + _mm256_extract_epi64(horizontal_sum, 1);\n\n    for (; i < total_elements; ++i) {\n        sum += (A[i] == B[i]);\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_33_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nsize_t tensor_4d_equal_count_simd(const uint8_t* A, const uint8_t* B, const size_t dims[4]) {\n    size_t total_elements = dims[0] * dims[1] * dims[2] * dims[3];\n    size_t i = 0;\n    __m256i count = _mm256_setzero_si256();\n\n    for (; i <= total_elements - 32; i += 32) {\n        __m256i vecA = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(A + i));\n        __m256i vecB = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(B + i));\n        __m256i eq = _mm256_cmpeq_epi8(vecA, vecB);\n        count = _mm256_add_epi8(count, eq);\n    }\n\n    __m256i horizontal_sum = _mm256_sad_epu8(count, _mm256_setzero_si256());\n    int64_t sum = _mm256_extract_epi64(horizontal_sum, 0) + _mm256_extract_epi64(horizontal_sum, 1);\n\n    for (; i < total_elements; ++i) {\n        sum += (A[i] == B[i]);\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_34_AVX", "completion": "```cpp\nvoid axm_abs_simd(size_t length, const int64_t a, const int64_t *x, int64_t *y) {\n    size_t i = 0;\n    __m256i va = _mm256_set1_epi64x(a);\n    for (; i <= length - 4; i += 4) {\n        __m256i vx = _mm256_loadu_si256((__m256i const*)(x + i));\n        __m256i vy = _mm256_loadu_si256((__m256i const*)(y + i));\n        __m256i vax = _mm256_mullo_epi64(va, vx);\n        __m256i vabsy = _mm256_abs_epi64(vy);\n        __m256i vresult = _mm256_sub_epi64(vax, vabsy);\n        _mm256_storeu_si256((__m256i*)(y + i), vresult);\n    }\n    for (; i < length; ++i) {\n        y[i] = a * x[i] - abs(y[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_34_AVX", "completion": "```cpp\nvoid axm_abs_simd(size_t length, const int64_t a, const int64_t *x, int64_t *y) {\n    size_t i = 0;\n    __m256i va = _mm256_set1_epi64x(a);\n    for (; i <= length - 4; i += 4) {\n        __m256i vx = _mm256_loadu_si256((__m256i const*)(x + i));\n        __m256i vy = _mm256_loadu_si256((__m256i const*)(y + i));\n        __m256i vax = _mm256_mullo_epi64(va, vx);\n        __m256i vabsy = _mm256_abs_epi64(vy);\n        __m256i vresult = _mm256_sub_epi64(vax, vabsy);\n        _mm256_storeu_si256((__m256i*)(y + i), vresult);\n    }\n    for (; i < length; ++i) {\n        y[i] = a * x[i] - abs(y[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_34_AVX", "completion": "```cpp\nvoid axm_abs_simd(size_t length, const int64_t a, const int64_t *x, int64_t *y) {\n    size_t i = 0;\n    __m256i va = _mm256_set1_epi64x(a);\n    for (; i <= length - 4; i += 4) {\n        __m256i vx = _mm256_loadu_si256((__m256i const*)(x + i));\n        __m256i vy = _mm256_loadu_si256((__m256i const*)(y + i));\n        __m256i vax = _mm256_mullo_epi64(va, vx);\n        __m256i vabsy = _mm256_abs_epi64(vy);\n        __m256i vresult = _mm256_sub_epi64(vax, vabsy);\n        _mm256_storeu_si256((__m256i*)(y + i), vresult);\n    }\n    for (; i < length; ++i) {\n        y[i] = a * x[i] - abs(y[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_34_AVX", "completion": "```cpp\nvoid axm_abs_simd(size_t length, const int64_t a, const int64_t *x, int64_t *y) {\n    size_t i = 0;\n    __m256i va = _mm256_set1_epi64x(a);\n    for (; i <= length - 4; i += 4) {\n        __m256i vx = _mm256_loadu_si256((__m256i const*)(x + i));\n        __m256i vy = _mm256_loadu_si256((__m256i const*)(y + i));\n        __m256i vax = _mm256_mullo_epi64(va, vx);\n        __m256i vabsy = _mm256_abs_epi64(vy);\n        __m256i vresult = _mm256_sub_epi64(vax, vabsy);\n        _mm256_storeu_si256((__m256i*)(y + i), vresult);\n    }\n    for (; i < length; ++i) {\n        y[i] = a * x[i] - abs(y[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_34_AVX", "completion": "```cpp\nvoid axm_abs_simd(size_t length, const int64_t a, const int64_t *x, int64_t *y) {\n    size_t i = 0;\n    __m256i va = _mm256_set1_epi64x(a);\n    for (; i <= length - 4; i += 4) {\n        __m256i vx = _mm256_loadu_si256((__m256i const*)(x + i));\n        __m256i vy = _mm256_loadu_si256((__m256i const*)(y + i));\n        __m256i vax = _mm256_mullo_epi64(va, vx);\n        __m256i vabsy = _mm256_abs_epi64(vy);\n        __m256i vresult = _mm256_sub_epi64(vax, vabsy);\n        _mm256_storeu_si256((__m256i*)(y + i), vresult);\n    }\n    for (; i < length; ++i) {\n        y[i] = a * x[i] - abs(y[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_35_AVX", "completion": "```c\n#include <immintrin.h>\n#include <x86intrin.h>\n\ntypedef struct {\n    int16_t min_num;\n    int16_t max_num;\n} MinMaxPair;\n\nMinMaxPair min_max_pair_simd(const int16_t* vec, size_t length) {\n    __m256i min_val = _mm256_set1_epi16(INT16_MAX);\n    __m256i max_val = _mm256_set1_epi16(INT16_MIN);\n\n    size_t i = 0;\n    for (; i <= length - 16; i += 16) {\n        __m256i data = _mm256_loadu_si256((__m256i const*)(vec + i));\n        min_val = _mm256_min_epi16(min_val, data);\n        max_val = _mm256_max_epi16(max_val, data);\n    }\n\n    int16_t min_array[16], max_array[16];\n    _mm256_storeu_si256((__m256i*)min_array, min_val);\n    _mm256_storeu_si256((__m256i*)max_array, max_val);\n\n    int16_t min_result = min_array[0];\n    int16_t max_result = max_array[0];\n\n    for (size_t j = 1; j < 16; ++j) {\n        min_result = (min_result < min_array[j]) ? min_result : min_array[j];\n        max_result = (max_result > max_array[j]) ? max_result : max_array[j];\n    }\n\n    for (; i < length; ++i) {\n        min_result = (min_result < vec[i]) ? min_result : vec[i];\n        max_result = (max_result > vec[i]) ? max_result : vec[i];\n    }\n\n    return (MinMaxPair){min_result, max_result};\n}\n```"}
{"task_id": "SimdBench_35_AVX", "completion": "```c\n#include <immintrin.h>\n#include <x86intrin.h>\n\ntypedef struct {\n    int16_t min_num;\n    int16_t max_num;\n} MinMaxPair;\n\nMinMaxPair min_max_pair_simd(const int16_t* vec, size_t length) {\n    __m256i min_val = _mm256_set1_epi16(INT16_MAX);\n    __m256i max_val = _mm256_set1_epi16(INT16_MIN);\n\n    size_t i = 0;\n    for (; i <= length - 16; i += 16) {\n        __m256i current = _mm256_loadu_si256((__m256i const*)(vec + i));\n        min_val = _mm256_min_epi16(min_val, current);\n        max_val = _mm256_max_epi16(max_val, current);\n    }\n\n    int16_t min_array[16], max_array[16];\n    _mm256_storeu_si256((__m256i*)min_array, min_val);\n    _mm256_storeu_si256((__m256i*)max_array, max_val);\n\n    int16_t min_result = min_array[0];\n    int16_t max_result = max_array[0];\n\n    for (size_t j = 1; j < 16; ++j) {\n        min_result = (min_result < min_array[j]) ? min_result : min_array[j];\n        max_result = (max_result > max_array[j]) ? max_result : max_array[j];\n    }\n\n    for (; i < length; ++i) {\n        min_result = (min_result < vec[i]) ? min_result : vec[i];\n        max_result = (max_result > vec[i]) ? max_result : vec[i];\n    }\n\n    return (MinMaxPair){min_result, max_result};\n}\n```"}
{"task_id": "SimdBench_35_AVX", "completion": "```c\n#include <immintrin.h>\n#include <x86intrin.h>\n\ntypedef struct {\n    int16_t min_num;\n    int16_t max_num;\n} MinMaxPair;\n\nMinMaxPair min_max_pair_simd(const int16_t* vec, size_t length) {\n    __m256i min_val = _mm256_set1_epi16(INT16_MAX);\n    __m256i max_val = _mm256_set1_epi16(INT16_MIN);\n\n    size_t i = 0;\n    for (; i <= length - 16; i += 16) {\n        __m256i current = _mm256_loadu_si256((__m256i const*)(vec + i));\n        min_val = _mm256_min_epi16(min_val, current);\n        max_val = _mm256_max_epi16(max_val, current);\n    }\n\n    int16_t min_array[16];\n    int16_t max_array[16];\n    _mm256_storeu_si256((__m256i*)min_array, min_val);\n    _mm256_storeu_si256((__m256i*)max_array, max_val);\n\n    int16_t min_result = INT16_MAX;\n    int16_t max_result = INT16_MIN;\n\n    for (size_t j = 0; j < 16; ++j) {\n        if (min_array[j] < min_result) min_result = min_array[j];\n        if (max_array[j] > max_result) max_result = max_array[j];\n    }\n\n    for (; i < length; ++i) {\n        if (vec[i] < min_result) min_result = vec[i];\n        if (vec[i] > max_result) max_result = vec[i];\n    }\n\n    return (MinMaxPair){min_result, max_result};\n}\n```"}
{"task_id": "SimdBench_35_AVX", "completion": "```c\n#include <immintrin.h>\n#include <x86intrin.h>\n\ntypedef struct {\n    int16_t min_num;\n    int16_t max_num;\n} MinMaxPair;\n\nMinMaxPair min_max_pair_simd(const int16_t* vec, size_t length) {\n    __m256i min_val = _mm256_set1_epi16(INT16_MAX);\n    __m256i max_val = _mm256_set1_epi16(INT16_MIN);\n\n    size_t i = 0;\n    for (; i <= length - 16; i += 16) {\n        __m256i current = _mm256_loadu_si256((__m256i const*)(vec + i));\n        min_val = _mm256_min_epi16(min_val, current);\n        max_val = _mm256_max_epi16(max_val, current);\n    }\n\n    int16_t min_array[16], max_array[16];\n    _mm256_storeu_si256((__m256i*)min_array, min_val);\n    _mm256_storeu_si256((__m256i*)max_array, max_val);\n\n    int16_t min_result = min_array[0];\n    int16_t max_result = max_array[0];\n\n    for (size_t j = 1; j < 16; ++j) {\n        min_result = (min_result < min_array[j]) ? min_result : min_array[j];\n        max_result = (max_result > max_array[j]) ? max_result : max_array[j];\n    }\n\n    for (; i < length; ++i) {\n        min_result = (min_result < vec[i]) ? min_result : vec[i];\n        max_result = (max_result > vec[i]) ? max_result : vec[i];\n    }\n\n    return (MinMaxPair){min_result, max_result};\n}\n```"}
{"task_id": "SimdBench_35_AVX", "completion": "```c\n#include <immintrin.h>\n#include <x86intrin.h>\n\ntypedef struct {\n    int16_t min_num;\n    int16_t max_num;\n} MinMaxPair;\n\nMinMaxPair min_max_pair_simd(const int16_t* vec, size_t length) {\n    __m256i min_val = _mm256_set1_epi16(INT16_MAX);\n    __m256i max_val = _mm256_set1_epi16(INT16_MIN);\n\n    size_t i = 0;\n    for (; i <= length - 16; i += 16) {\n        __m256i vec_data = _mm256_loadu_si256((__m256i const*)(vec + i));\n        min_val = _mm256_min_epi16(min_val, vec_data);\n        max_val = _mm256_max_epi16(max_val, vec_data);\n    }\n\n    int16_t min_array[16], max_array[16];\n    _mm256_storeu_si256((__m256i*)min_array, min_val);\n    _mm256_storeu_si256((__m256i*)max_array, max_val);\n\n    int16_t min_result = INT16_MAX;\n    int16_t max_result = INT16_MIN;\n\n    for (size_t j = 0; j < 16; ++j) {\n        if (min_array[j] < min_result) min_result = min_array[j];\n        if (max_array[j] > max_result) max_result = max_array[j];\n    }\n\n    for (; i < length; ++i) {\n        if (vec[i] < min_result) min_result = vec[i];\n        if (vec[i] > max_result) max_result = vec[i];\n    }\n\n    return (MinMaxPair){min_result, max_result};\n}\n```"}
{"task_id": "SimdBench_36_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nbool matrix_rows_strictly_increasing_simd(const int* matrix, size_t rows, size_t cols) {\n    if (rows == 0 || cols == 0) return false;\n\n    for (size_t i = 0; i < rows; ++i) {\n        const int* row = matrix + i * cols;\n        __m256i prev = _mm256_set1_epi32(row[0]);\n        size_t j = 1;\n\n        for (; j <= cols - 8; j += 8) {\n            __m256i current = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(row + j));\n            __m256i cmp = _mm256_cmpgt_epi32(current, prev);\n            if (_mm256_movemask_epi8(cmp) != 0xFFFF) return false;\n            prev = current;\n        }\n\n        for (; j < cols; ++j) {\n            if (row[j] <= row[j - 1]) return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_36_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nbool matrix_rows_strictly_increasing_simd(const int* matrix, size_t rows, size_t cols) {\n    if (rows == 0 || cols == 0) return false;\n\n    for (size_t i = 0; i < rows; ++i) {\n        const int* row = matrix + i * cols;\n        __m256i prev = _mm256_set1_epi32(row[0]);\n        size_t j = 1;\n\n        for (; j <= cols - 8; j += 8) {\n            __m256i current = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(row + j));\n            __m256i cmp = _mm256_cmpgt_epi32(current, prev);\n            if (_mm256_movemask_epi8(cmp) != 0xFFFF) return false;\n            prev = current;\n        }\n\n        for (; j < cols; ++j) {\n            if (row[j] <= row[j - 1]) return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_36_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nbool matrix_rows_strictly_increasing_simd(const int* matrix, size_t rows, size_t cols) {\n    if (rows == 0 || cols == 0) return false;\n\n    for (size_t i = 0; i < rows; ++i) {\n        const int* row = matrix + i * cols;\n        __m256i prev = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(row));\n        __m256i mask = _mm256_set1_epi32(0xFFFFFFFF);\n\n        for (size_t j = 32; j < cols; j += 32) {\n            __m256i curr = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(row + j));\n            __m256i cmp = _mm256_cmpgt_epi32(curr, prev);\n            mask = _mm256_and_si256(mask, cmp);\n            prev = curr;\n        }\n\n        // Handle remaining elements\n        for (size_t j = (cols / 32) * 32; j < cols - 1; ++j) {\n            if (row[j] >= row[j + 1]) {\n                return false;\n            }\n        }\n\n        // Check if all comparisons were true\n        if (_mm256_testz_si256(mask, mask) != 0) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_36_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nbool matrix_rows_strictly_increasing_simd(const int* matrix, size_t rows, size_t cols) {\n    if (rows == 0 || cols == 0) return false;\n\n    for (size_t i = 0; i < rows; ++i) {\n        const int* row = matrix + i * cols;\n        __m256i prev = _mm256_set1_epi32(row[0]);\n        size_t j = 1;\n\n        for (; j <= cols - 8; j += 8) {\n            __m256i current = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(row + j));\n            __m256i cmp = _mm256_cmpgt_epi32(current, prev);\n            if (_mm256_movemask_epi8(cmp) != 0xFFFF) return false;\n            prev = current;\n        }\n\n        for (; j < cols; ++j) {\n            if (row[j] <= row[j - 1]) return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_36_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nbool matrix_rows_strictly_increasing_simd(const int* matrix, size_t rows, size_t cols) {\n    if (rows == 0 || cols == 0) return false;\n\n    for (size_t i = 0; i < rows; ++i) {\n        const int* row = matrix + i * cols;\n        __m256i prev = _mm256_set1_epi32(row[0]);\n        size_t j = 1;\n\n        for (; j <= cols - 8; j += 8) {\n            __m256i current = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(row + j));\n            __m256i cmp = _mm256_cmpgt_epi32(current, prev);\n            if (_mm256_movemask_epi8(cmp) != 0xFFFF) return false;\n            prev = current;\n        }\n\n        for (; j < cols; ++j) {\n            if (row[j] <= row[j - 1]) return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_37_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nbool matrix_blocks_equal_simd(const int* matrix, size_t block_size, size_t rows, size_t cols) {\n    if (block_size == 0 || rows % block_size != 0 || cols % block_size != 0) {\n        return false;\n    }\n\n    size_t num_blocks_row = rows / block_size;\n    size_t num_blocks_col = cols / block_size;\n\n    __m256i first_block[8];\n    for (size_t i = 0; i < block_size; ++i) {\n        first_block[i] = _mm256_loadu_si256((__m256i const*)(matrix + i * cols));\n    }\n\n    for (size_t block_row = 0; block_row < num_blocks_row; ++block_row) {\n        for (size_t block_col = 0; block_col < num_blocks_col; ++block_col) {\n            if (block_row == 0 && block_col == 0) continue;\n\n            size_t offset = block_row * block_size * cols + block_col * block_size;\n            for (size_t i = 0; i < block_size; ++i) {\n                __m256i current_block = _mm256_loadu_si256((__m256i const*)(matrix + offset + i * cols));\n                __m256i comparison = _mm256_cmpeq_epi32(current_block, first_block[i]);\n                if (_mm256_movemask_epi8(comparison) != 0xFFFFFFFF) {\n                    return false;\n                }\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_37_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nbool matrix_blocks_equal_simd(const int* matrix, size_t block_size, size_t rows, size_t cols) {\n    if (block_size == 0 || rows % block_size != 0 || cols % block_size != 0) {\n        return false;\n    }\n\n    size_t num_blocks_row = rows / block_size;\n    size_t num_blocks_col = cols / block_size;\n\n    __m256i first_block[8];\n    for (size_t i = 0; i < block_size; ++i) {\n        first_block[i] = _mm256_loadu_si256((__m256i const*)(matrix + i * cols));\n    }\n\n    for (size_t block_row = 0; block_row < num_blocks_row; ++block_row) {\n        for (size_t block_col = 0; block_col < num_blocks_col; ++block_col) {\n            if (block_row == 0 && block_col == 0) {\n                continue;\n            }\n\n            for (size_t i = 0; i < block_size; ++i) {\n                __m256i current_block = _mm256_loadu_si256((__m256i const*)(matrix + (block_row * block_size + i) * cols + block_col * block_size));\n                __m256i cmp_result = _mm256_cmpeq_epi32(current_block, first_block[i]);\n                if (_mm256_movemask_epi8(cmp_result) != 0xFFFFFFFF) {\n                    return false;\n                }\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_37_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nbool matrix_blocks_equal_simd(const int* matrix, size_t block_size, size_t rows, size_t cols) {\n    if (block_size == 0 || rows % block_size != 0 || cols % block_size != 0) {\n        return false;\n    }\n\n    size_t num_blocks_row = rows / block_size;\n    size_t num_blocks_col = cols / block_size;\n\n    __m256i first_block[8];\n    for (size_t i = 0; i < block_size; ++i) {\n        first_block[i] = _mm256_loadu_si256((__m256i const*)(matrix + i * cols));\n    }\n\n    for (size_t block_row = 0; block_row < num_blocks_row; ++block_row) {\n        for (size_t block_col = 0; block_col < num_blocks_col; ++block_col) {\n            if (block_row == 0 && block_col == 0) {\n                continue;\n            }\n\n            size_t offset = block_row * block_size * cols + block_col * block_size;\n            for (size_t i = 0; i < block_size; ++i) {\n                __m256i current_block = _mm256_loadu_si256((__m256i const*)(matrix + offset + i * cols));\n                __m256i comparison = _mm256_cmpeq_epi32(current_block, first_block[i]);\n                if (_mm256_movemask_epi8(comparison) != 0xFFFFFFFF) {\n                    return false;\n                }\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_37_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nbool matrix_blocks_equal_simd(const int* matrix, size_t block_size, size_t rows, size_t cols) {\n    if (block_size == 0 || rows % block_size != 0 || cols % block_size != 0) {\n        return false;\n    }\n\n    size_t num_blocks_row = rows / block_size;\n    size_t num_blocks_col = cols / block_size;\n\n    __m256i first_block[8];\n    for (size_t i = 0; i < block_size; ++i) {\n        first_block[i] = _mm256_loadu_si256((__m256i const*)(matrix + i * cols));\n    }\n\n    for (size_t block_row = 0; block_row < num_blocks_row; ++block_row) {\n        for (size_t block_col = 0; block_col < num_blocks_col; ++block_col) {\n            if (block_row == 0 && block_col == 0) continue;\n\n            size_t offset = block_row * block_size * cols + block_col * block_size;\n            for (size_t i = 0; i < block_size; ++i) {\n                __m256i current_block = _mm256_loadu_si256((__m256i const*)(matrix + offset + i * cols));\n                __m256i comparison = _mm256_cmpeq_epi32(current_block, first_block[i]);\n                if (_mm256_movemask_epi8(comparison) != 0xFFFFFFFF) {\n                    return false;\n                }\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_37_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nbool matrix_blocks_equal_simd(const int* matrix, size_t block_size, size_t rows, size_t cols) {\n    if (block_size == 0 || rows % block_size != 0 || cols % block_size != 0) {\n        return false;\n    }\n\n    size_t num_blocks_row = rows / block_size;\n    size_t num_blocks_col = cols / block_size;\n\n    __m256i first_block[8];\n    for (size_t i = 0; i < block_size && i < 8; ++i) {\n        first_block[i] = _mm256_loadu_si256((__m256i const*)(matrix + i * cols));\n    }\n\n    for (size_t block_row = 0; block_row < num_blocks_row; ++block_row) {\n        for (size_t block_col = 0; block_col < num_blocks_col; ++block_col) {\n            if (block_row == 0 && block_col == 0) continue;\n\n            for (size_t i = 0; i < block_size; ++i) {\n                __m256i current_block = _mm256_loadu_si256((__m256i const*)(matrix + (block_row * block_size + i) * cols + block_col * block_size));\n                __m256i comparison = _mm256_cmpeq_epi32(current_block, first_block[i % 8]);\n                if (_mm256_movemask_epi8(comparison) != 0xFFFFFFFF) {\n                    return false;\n                }\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_38_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nbool vector_block_equal_simd(const double* vec, double tolerance, size_t length, size_t block_size) {\n    if (!vec || length < block_size || block_size == 0) {\n        return false;\n    }\n\n    __m256d tolerance_vec = _mm256_set1_pd(tolerance);\n    __m256d first_block = _mm256_loadu_pd(vec);\n\n    for (size_t i = block_size; i <= length - block_size; i += block_size) {\n        __m256d current_block = _mm256_loadu_pd(&vec[i]);\n        __m256d diff = _mm256_sub_pd(current_block, first_block);\n        __m256d abs_diff = _mm256_andnot_pd(_mm256_set1_pd(-0.0), diff);\n        __m256d mask = _mm256_cmp_pd(abs_diff, tolerance_vec, _CMP_LE_OS);\n\n        if (_mm256_movemask_pd(mask) != 0xF) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_38_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nbool vector_block_equal_simd(const double* vec, double tolerance, size_t length, size_t block_size) {\n    if (!vec || length < block_size || block_size == 0) {\n        return false;\n    }\n\n    __m256d tol_vec = _mm256_set1_pd(tolerance);\n    __m256d first_block = _mm256_loadu_pd(vec);\n\n    for (size_t i = block_size; i <= length - block_size; i += block_size) {\n        __m256d current_block = _mm256_loadu_pd(&vec[i]);\n        __m256d diff = _mm256_sub_pd(current_block, first_block);\n        __m256d abs_diff = _mm256_andnot_pd(_mm256_set1_pd(-0.0), diff);\n        __m256d mask = _mm256_cmp_pd(abs_diff, tol_vec, _CMP_LE_OS);\n\n        if (_mm256_movemask_pd(mask) != 0b1111) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_38_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nbool vector_block_equal_simd(const double* vec, double tolerance, size_t length, size_t block_size) {\n    if (!vec || length < block_size || block_size == 0) {\n        return false;\n    }\n\n    __m256d tolerance_vec = _mm256_set1_pd(tolerance);\n    __m256d first_block = _mm256_loadu_pd(vec);\n\n    for (size_t i = block_size; i <= length - block_size; i += block_size) {\n        __m256d current_block = _mm256_loadu_pd(&vec[i]);\n        __m256d diff = _mm256_sub_pd(current_block, first_block);\n        __m256d abs_diff = _mm256_andnot_pd(_mm256_set1_pd(-0.0), diff);\n        __m256d mask = _mm256_cmp_pd(abs_diff, tolerance_vec, _CMP_LE_OS);\n\n        if (_mm256_movemask_pd(mask) != 0b1111) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_38_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nbool vector_block_equal_simd(const double* vec, double tolerance, size_t length, size_t block_size) {\n    if (!vec || length < block_size || block_size == 0) {\n        return false;\n    }\n\n    __m256d tolerance_vec = _mm256_set1_pd(tolerance);\n    __m256d first_block = _mm256_loadu_pd(vec);\n\n    for (size_t i = block_size; i <= length - block_size; i += block_size) {\n        __m256d current_block = _mm256_loadu_pd(&vec[i]);\n        __m256d diff = _mm256_sub_pd(current_block, first_block);\n        __m256d abs_diff = _mm256_andnot_pd(_mm256_set1_pd(-0.0), diff);\n        __m256d mask = _mm256_cmp_pd(abs_diff, tolerance_vec, _CMP_LE_OS);\n\n        if (_mm256_movemask_pd(mask) != 0b1111) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_38_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nbool vector_block_equal_simd(const double* vec, double tolerance, size_t length, size_t block_size) {\n    if (!vec || block_size == 0 || length < block_size) {\n        return false;\n    }\n\n    __m256d tolerance_vec = _mm256_set1_pd(tolerance);\n    __m256d first_block = _mm256_loadu_pd(vec);\n\n    for (size_t i = block_size; i <= length - block_size; i += block_size) {\n        __m256d current_block = _mm256_loadu_pd(&vec[i]);\n        __m256d diff = _mm256_sub_pd(current_block, first_block);\n        __m256d abs_diff = _mm256_andnot_pd(_mm256_set1_pd(-0.0), diff);\n        __m256d mask = _mm256_cmp_pd(abs_diff, tolerance_vec, _CMP_LE_OS);\n\n        if (_mm256_movemask_pd(mask) != 0xF) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_39_AVX", "completion": "```cpp\nvoid matrix_row_norm_compare_simd(const double* matrix, const double* thresholds, size_t rows, size_t cols, bool* result) {\n    for (size_t i = 0; i < rows; ++i) {\n        __m256d sum = _mm256_setzero_pd();\n        size_t j;\n        for (j = 0; j <= cols - 4; j += 4) {\n            __m256d row = _mm256_loadu_pd(&matrix[i * cols + j]);\n            row = _mm256_mul_pd(row, row);\n            sum = _mm256_add_pd(sum, row);\n        }\n        double sums[4];\n        _mm256_storeu_pd(sums, sum);\n        double row_norm = sqrt(sums[0] + sums[1] + sums[2] + sums[3]);\n\n        for (; j < cols; ++j) {\n            double val = matrix[i * cols + j];\n            row_norm += val * val;\n        }\n        row_norm = sqrt(row_norm);\n\n        result[i] = (row_norm > thresholds[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_39_AVX", "completion": "```cpp\nvoid matrix_row_norm_compare_simd(const double* matrix, const double* thresholds, size_t rows, size_t cols, bool* result) {\n    for (size_t i = 0; i < rows; ++i) {\n        __m256d sum = _mm256_setzero_pd();\n        size_t j;\n        for (j = 0; j <= cols - 4; j += 4) {\n            __m256d row = _mm256_loadu_pd(&matrix[i * cols + j]);\n            row = _mm256_mul_pd(row, row);\n            sum = _mm256_add_pd(sum, row);\n        }\n        double sums[4];\n        _mm256_storeu_pd(sums, sum);\n        double row_norm = sqrt(sums[0] + sums[1] + sums[2] + sums[3]);\n\n        for (; j < cols; ++j) {\n            double val = matrix[i * cols + j];\n            row_norm += val * val;\n        }\n        row_norm = sqrt(row_norm);\n\n        result[i] = (row_norm > thresholds[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_39_AVX", "completion": "```cpp\nvoid matrix_row_norm_compare_simd(const double* matrix, const double* thresholds, size_t rows, size_t cols, bool* result) {\n    for (size_t i = 0; i < rows; ++i) {\n        __m256d sum = _mm256_setzero_pd();\n        size_t j;\n        for (j = 0; j <= cols - 4; j += 4) {\n            __m256d row = _mm256_loadu_pd(&matrix[i * cols + j]);\n            row = _mm256_mul_pd(row, row);\n            sum = _mm256_add_pd(sum, row);\n        }\n        double sums[4];\n        _mm256_storeu_pd(sums, sum);\n        double norm_squared = sums[0] + sums[1] + sums[2] + sums[3];\n        for (; j < cols; ++j) {\n            double val = matrix[i * cols + j];\n            norm_squared += val * val;\n        }\n        result[i] = (norm_squared > thresholds[i] * thresholds[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_39_AVX", "completion": "```cpp\nvoid matrix_row_norm_compare_simd(const double* matrix, const double* thresholds, size_t rows, size_t cols, bool* result) {\n    for (size_t i = 0; i < rows; ++i) {\n        __m256d sum = _mm256_setzero_pd();\n        for (size_t j = 0; j < cols; j += 4) {\n            __m256d row = _mm256_loadu_pd(&matrix[i * cols + j]);\n            row = _mm256_mul_pd(row, row);\n            sum = _mm256_add_pd(sum, row);\n        }\n        __m256d norm = _mm256_sqrt_pd(sum);\n        __m256d threshold = _mm256_set1_pd(thresholds[i]);\n        __m256d comparison = _mm256_cmp_pd(norm, threshold, _CMP_GT_OS);\n        int mask = _mm256_movemask_epi8((__m256i)comparison);\n        result[i] = (mask & 0x80) != 0;\n    }\n}\n```"}
{"task_id": "SimdBench_39_AVX", "completion": "```cpp\nvoid matrix_row_norm_compare_simd(const double* matrix, const double* thresholds, size_t rows, size_t cols, bool* result) {\n    for (size_t i = 0; i < rows; ++i) {\n        __m256d sum = _mm256_setzero_pd();\n        size_t j;\n        for (j = 0; j <= cols - 4; j += 4) {\n            __m256d row = _mm256_loadu_pd(&matrix[i * cols + j]);\n            row = _mm256_mul_pd(row, row);\n            sum = _mm256_add_pd(sum, row);\n        }\n        double sums[4];\n        _mm256_storeu_pd(sums, sum);\n        double row_norm = sqrt(sums[0] + sums[1] + sums[2] + sums[3]);\n\n        for (; j < cols; ++j) {\n            double val = matrix[i * cols + j];\n            row_norm += val * val;\n        }\n        row_norm = sqrt(row_norm);\n\n        result[i] = (row_norm > thresholds[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_40_AVX", "completion": "```cpp\nvoid tensor_bitwise_or_simd(const uint32_t* A, const uint32_t* B, uint32_t* C, size_t length) {\n    size_t i = 0;\n    __m256i vecA, vecB, vecResult;\n    for (; i <= length - 8; i += 8) {\n        vecA = _mm256_loadu_si256((__m256i*)(A + i));\n        vecB = _mm256_loadu_si256((__m256i*)(B + i));\n        vecResult = _mm256_or_si256(vecA, vecB);\n        _mm256_storeu_si256((__m256i*)(C + i), vecResult);\n    }\n    for (; i < length; ++i) {\n        C[i] = A[i] | B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_40_AVX", "completion": "```cpp\nvoid tensor_bitwise_or_simd(const uint32_t* A, const uint32_t* B, uint32_t* C, size_t length) {\n    size_t i = 0;\n    __m256i vecA, vecB, vecResult;\n    for (; i <= length - 8; i += 8) {\n        vecA = _mm256_loadu_si256((__m256i*)(A + i));\n        vecB = _mm256_loadu_si256((__m256i*)(B + i));\n        vecResult = _mm256_or_si256(vecA, vecB);\n        _mm256_storeu_si256((__m256i*)(C + i), vecResult);\n    }\n    for (; i < length; ++i) {\n        C[i] = A[i] | B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_40_AVX", "completion": "```cpp\nvoid tensor_bitwise_or_simd(const uint32_t* A, const uint32_t* B, uint32_t* C, size_t length) {\n    size_t i = 0;\n    __m256i vecA, vecB, vecResult;\n    for (; i <= length - 8; i += 8) {\n        vecA = _mm256_loadu_si256((__m256i*)(A + i));\n        vecB = _mm256_loadu_si256((__m256i*)(B + i));\n        vecResult = _mm256_or_si256(vecA, vecB);\n        _mm256_storeu_si256((__m256i*)(C + i), vecResult);\n    }\n    for (; i < length; ++i) {\n        C[i] = A[i] | B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_40_AVX", "completion": "```cpp\nvoid tensor_bitwise_or_simd(const uint32_t* A, const uint32_t* B, uint32_t* C, size_t length) {\n    size_t i = 0;\n    __m256i vecA, vecB, vecResult;\n    for (; i <= length - 8; i += 8) {\n        vecA = _mm256_loadu_si256((__m256i*)(A + i));\n        vecB = _mm256_loadu_si256((__m256i*)(B + i));\n        vecResult = _mm256_or_si256(vecA, vecB);\n        _mm256_storeu_si256((__m256i*)(C + i), vecResult);\n    }\n    for (; i < length; ++i) {\n        C[i] = A[i] | B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_40_AVX", "completion": "```cpp\nvoid tensor_bitwise_or_simd(const uint32_t* A, const uint32_t* B, uint32_t* C, size_t length) {\n    size_t i = 0;\n    __m256i vecA, vecB, vecResult;\n    for (; i <= length - 8; i += 8) {\n        vecA = _mm256_loadu_si256((__m256i*)(A + i));\n        vecB = _mm256_loadu_si256((__m256i*)(B + i));\n        vecResult = _mm256_or_si256(vecA, vecB);\n        _mm256_storeu_si256((__m256i*)(C + i), vecResult);\n    }\n    for (; i < length; ++i) {\n        C[i] = A[i] | B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_41_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nint64_t squarediff_simd(const int8_t * A, const int8_t * B, size_t length) {\n    __m256i sum_squares = _mm256_setzero_si256();\n    __m256i sum_products = _mm256_setzero_si256();\n    size_t i = 0;\n\n    for (; i <= length - 32; i += 32) {\n        __m256i a = _mm256_loadu_si256((__m256i const*)(A + i));\n        __m256i b = _mm256_loadu_si256((__m256i const*)(B + i));\n\n        __m256i a_squared = _mm256_maddubs_epi16(a, a);\n        __m256i b_squared = _mm256_maddubs_epi16(b, b);\n        __m256i products = _mm256_maddubs_epi16(a, b);\n\n        sum_squares = _mm256_add_epi32(sum_squares, _mm256_add_epi32(a_squared, b_squared));\n        sum_products = _mm256_add_epi32(sum_products, products);\n    }\n\n    __m128i sum_squares_lo = _mm256_castsi256_si128(sum_squares);\n    __m128i sum_squares_hi = _mm256_extracti128_si256(sum_squares, 1);\n    __m128i sum_products_lo = _mm256_castsi256_si128(sum_products);\n    __m128i sum_products_hi = _mm256_extracti128_si256(sum_products, 1);\n\n    sum_squares_lo = _mm_add_epi32(sum_squares_lo, sum_squares_hi);\n    sum_products_lo = _mm_add_epi32(sum_products_lo, sum_products_hi);\n\n    sum_squares_lo = _mm_add_epi32(sum_squares_lo, _mm_srli_si128(sum_squares_lo, 8));\n    sum_products_lo = _mm_add_epi32(sum_products_lo, _mm_srli_si128(sum_products_lo, 8));\n\n    sum_squares_lo = _mm_add_epi32(sum_squares_lo, _mm_srli_si128(sum_squares_lo, 4));\n    sum_products_lo = _mm_add_epi32(sum_products_lo, _mm_srli_si128(sum_products_lo, 4));\n\n    int32_t sum_squares_total = _mm_cvtsi128_si32(sum_squares_lo);\n    int32_t sum_products_total = _mm_cvtsi128_si32(sum_products_lo);\n\n    for (; i < length; ++i) {\n        int16_t a = A[i];\n        int16_t b = B[i];\n        sum_squares_total += a * a + b * b;\n        sum_products_total += a * b;\n    }\n\n    return sum_squares_total - sum_products_total;\n}\n```"}
{"task_id": "SimdBench_41_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nint64_t squarediff_simd(const int8_t * A, const int8_t * B, size_t length) {\n    __m256i sum_squares = _mm256_setzero_si256();\n    __m256i sum_products = _mm256_setzero_si256();\n    size_t i = 0;\n\n    for (; i <= length - 32; i += 32) {\n        __m256i a = _mm256_loadu_si256((__m256i const*)(A + i));\n        __m256i b = _mm256_loadu_si256((__m256i const*)(B + i));\n\n        __m256i a_squared = _mm256_maddubs_epi16(a, a);\n        __m256i b_squared = _mm256_maddubs_epi16(b, b);\n        __m256i products = _mm256_maddubs_epi16(a, b);\n\n        sum_squares = _mm256_add_epi32(sum_squares, _mm256_add_epi32(a_squared, b_squared));\n        sum_products = _mm256_add_epi32(sum_products, products);\n    }\n\n    __m128i sum_squares_lo = _mm256_castsi256_si128(sum_squares);\n    __m128i sum_squares_hi = _mm256_extracti128_si256(sum_squares, 1);\n    __m128i sum_products_lo = _mm256_castsi256_si128(sum_products);\n    __m128i sum_products_hi = _mm256_extracti128_si256(sum_products, 1);\n\n    sum_squares_lo = _mm_add_epi32(sum_squares_lo, sum_squares_hi);\n    sum_products_lo = _mm_add_epi32(sum_products_lo, sum_products_hi);\n\n    sum_squares_lo = _mm_add_epi32(sum_squares_lo, _mm_srli_si128(sum_squares_lo, 8));\n    sum_products_lo = _mm_add_epi32(sum_products_lo, _mm_srli_si128(sum_products_lo, 8));\n\n    sum_squares_lo = _mm_add_epi32(sum_squares_lo, _mm_srli_si128(sum_squares_lo, 4));\n    sum_products_lo = _mm_add_epi32(sum_products_lo, _mm_srli_si128(sum_products_lo, 4));\n\n    int32_t sum_squares_total = _mm_cvtsi128_si32(sum_squares_lo);\n    int32_t sum_products_total = _mm_cvtsi128_si32(sum_products_lo);\n\n    for (; i < length; ++i) {\n        int16_t a = A[i];\n        int16_t b = B[i];\n        sum_squares_total += a * a + b * b;\n        sum_products_total += a * b;\n    }\n\n    return sum_squares_total - sum_products_total;\n}\n```"}
{"task_id": "SimdBench_41_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nint64_t squarediff_simd(const int8_t * A, const int8_t * B, size_t length) {\n    __m256i sum_squares = _mm256_setzero_si256();\n    __m256i sum_products = _mm256_setzero_si256();\n    size_t i = 0;\n\n    for (; i <= length - 32; i += 32) {\n        __m256i a = _mm256_loadu_si256((__m256i const*)(A + i));\n        __m256i b = _mm256_loadu_si256((__m256i const*)(B + i));\n\n        __m256i a_squared = _mm256_maddubs_epi16(a, a);\n        __m256i b_squared = _mm256_maddubs_epi16(b, b);\n        __m256i products = _mm256_maddubs_epi16(a, b);\n\n        sum_squares = _mm256_add_epi32(sum_squares, _mm256_add_epi32(a_squared, b_squared));\n        sum_products = _mm256_add_epi32(sum_products, products);\n    }\n\n    __m128i sum_squares_lo = _mm256_castsi256_si128(sum_squares);\n    __m128i sum_squares_hi = _mm256_extracti128_si256(sum_squares, 1);\n    __m128i sum_products_lo = _mm256_castsi256_si128(sum_products);\n    __m128i sum_products_hi = _mm256_extracti128_si256(sum_products, 1);\n\n    sum_squares_lo = _mm_add_epi32(sum_squares_lo, sum_squares_hi);\n    sum_products_lo = _mm_add_epi32(sum_products_lo, sum_products_hi);\n\n    sum_squares_lo = _mm_add_epi32(sum_squares_lo, _mm_srli_si128(sum_squares_lo, 8));\n    sum_products_lo = _mm_add_epi32(sum_products_lo, _mm_srli_si128(sum_products_lo, 8));\n\n    sum_squares_lo = _mm_add_epi32(sum_squares_lo, _mm_srli_si128(sum_squares_lo, 4));\n    sum_products_lo = _mm_add_epi32(sum_products_lo, _mm_srli_si128(sum_products_lo, 4));\n\n    int32_t sum_squares_total = _mm_cvtsi128_si32(sum_squares_lo);\n    int32_t sum_products_total = _mm_cvtsi128_si32(sum_products_lo);\n\n    for (; i < length; ++i) {\n        int16_t a = A[i];\n        int16_t b = B[i];\n        sum_squares_total += a * a + b * b;\n        sum_products_total += a * b;\n    }\n\n    return sum_squares_total - sum_products_total;\n}\n```"}
{"task_id": "SimdBench_41_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nint64_t squarediff_simd(const int8_t * A, const int8_t * B, size_t length) {\n    __m256i sum_squares = _mm256_setzero_si256();\n    __m256i sum_products = _mm256_setzero_si256();\n    size_t i = 0;\n\n    for (; i <= length - 32; i += 32) {\n        __m256i a = _mm256_loadu_si256((__m256i const*)(A + i));\n        __m256i b = _mm256_loadu_si256((__m256i const*)(B + i));\n\n        __m256i a_squared = _mm256_maddubs_epi16(a, a);\n        __m256i b_squared = _mm256_maddubs_epi16(b, b);\n        __m256i products = _mm256_maddubs_epi16(a, b);\n\n        sum_squares = _mm256_add_epi32(sum_squares, _mm256_add_epi32(a_squared, b_squared));\n        sum_products = _mm256_add_epi32(sum_products, products);\n    }\n\n    __m128i sum_squares_lo = _mm256_castsi256_si128(sum_squares);\n    __m128i sum_squares_hi = _mm256_extracti128_si256(sum_squares, 1);\n    __m128i sum_products_lo = _mm256_castsi256_si128(sum_products);\n    __m128i sum_products_hi = _mm256_extracti128_si256(sum_products, 1);\n\n    sum_squares_lo = _mm_add_epi32(sum_squares_lo, sum_squares_hi);\n    sum_products_lo = _mm_add_epi32(sum_products_lo, sum_products_hi);\n\n    sum_squares_lo = _mm_add_epi32(sum_squares_lo, _mm_srli_si128(sum_squares_lo, 8));\n    sum_products_lo = _mm_add_epi32(sum_products_lo, _mm_srli_si128(sum_products_lo, 8));\n\n    sum_squares_lo = _mm_add_epi32(sum_squares_lo, _mm_srli_si128(sum_squares_lo, 4));\n    sum_products_lo = _mm_add_epi32(sum_products_lo, _mm_srli_si128(sum_products_lo, 4));\n\n    int32_t sum_squares_total = _mm_cvtsi128_si32(sum_squares_lo);\n    int32_t sum_products_total = _mm_cvtsi128_si32(sum_products_lo);\n\n    for (; i < length; ++i) {\n        int16_t a = A[i];\n        int16_t b = B[i];\n        sum_squares_total += a * a + b * b;\n        sum_products_total += a * b;\n    }\n\n    return sum_squares_total - sum_products_total;\n}\n```"}
{"task_id": "SimdBench_41_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nint64_t squarediff_simd(const int8_t * A, const int8_t * B, size_t length) {\n    __m256i sum_squares = _mm256_setzero_si256();\n    __m256i sum_products = _mm256_setzero_si256();\n    size_t i = 0;\n\n    for (; i <= length - 32; i += 32) {\n        __m256i a = _mm256_loadu_si256((__m256i const*)(A + i));\n        __m256i b = _mm256_loadu_si256((__m256i const*)(B + i));\n\n        __m256i a_squared = _mm256_maddubs_epi16(a, a);\n        __m256i b_squared = _mm256_maddubs_epi16(b, b);\n        __m256i products = _mm256_maddubs_epi16(a, b);\n\n        sum_squares = _mm256_add_epi32(sum_squares, _mm256_add_epi32(a_squared, b_squared));\n        sum_products = _mm256_add_epi32(sum_products, products);\n    }\n\n    __m128i sum_squares_lo = _mm256_castsi256_si128(sum_squares);\n    __m128i sum_squares_hi = _mm256_extracti128_si256(sum_squares, 1);\n    __m128i sum_products_lo = _mm256_castsi256_si128(sum_products);\n    __m128i sum_products_hi = _mm256_extracti128_si256(sum_products, 1);\n\n    sum_squares_lo = _mm_add_epi32(sum_squares_lo, sum_squares_hi);\n    sum_products_lo = _mm_add_epi32(sum_products_lo, sum_products_hi);\n\n    sum_squares_lo = _mm_add_epi32(sum_squares_lo, _mm_srli_si128(sum_squares_lo, 8));\n    sum_products_lo = _mm_add_epi32(sum_products_lo, _mm_srli_si128(sum_products_lo, 8));\n\n    sum_squares_lo = _mm_add_epi32(sum_squares_lo, _mm_srli_si128(sum_squares_lo, 4));\n    sum_products_lo = _mm_add_epi32(sum_products_lo, _mm_srli_si128(sum_products_lo, 4));\n\n    int32_t sum_squares_total = _mm_cvtsi128_si32(sum_squares_lo);\n    int32_t sum_products_total = _mm_cvtsi128_si32(sum_products_lo);\n\n    for (; i < length; ++i) {\n        int16_t a = A[i];\n        int16_t b = B[i];\n        sum_squares_total += a * a + b * b;\n        sum_products_total += a * b;\n    }\n\n    return sum_squares_total - sum_products_total;\n}\n```"}
{"task_id": "SimdBench_42_AVX", "completion": "```cpp\nvoid tensor_bit_clear_simd(const uint64_t* A, const uint64_t* B, uint64_t* C, size_t length) {\n    size_t i = 0;\n    __m256i zero = _mm256_setzero_si256();\n    for (; i <= length - 4; i += 4) {\n        __m256i a = _mm256_loadu_si256((__m256i*)(A + i));\n        __m256i b = _mm256_loadu_si256((__m256i*)(B + i));\n        __m256i not_b = _mm256_xor_si256(b, _mm256_cmpeq_epi64(zero, zero));\n        __m256i result = _mm256_and_si256(a, not_b);\n        _mm256_storeu_si256((__m256i*)(C + i), result);\n    }\n    for (; i < length; ++i) {\n        C[i] = A[i] & (~B[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_42_AVX", "completion": "```cpp\nvoid tensor_bit_clear_simd(const uint64_t* A, const uint64_t* B, uint64_t* C, size_t length) {\n    size_t i = 0;\n    __m256i zero = _mm256_setzero_si256();\n    for (; i <= length - 4; i += 4) {\n        __m256i a = _mm256_loadu_si256((__m256i*)(A + i));\n        __m256i b = _mm256_loadu_si256((__m256i*)(B + i));\n        __m256i not_b = _mm256_xor_si256(b, _mm256_cmpeq_epi64(zero, zero));\n        __m256i result = _mm256_and_si256(a, not_b);\n        _mm256_storeu_si256((__m256i*)(C + i), result);\n    }\n    for (; i < length; ++i) {\n        C[i] = A[i] & (~B[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_42_AVX", "completion": "```cpp\nvoid tensor_bit_clear_simd(const uint64_t* A, const uint64_t* B, uint64_t* C, size_t length) {\n    size_t i = 0;\n    __m256i zero = _mm256_setzero_si256();\n    for (; i <= length - 4; i += 4) {\n        __m256i a = _mm256_loadu_si256((__m256i*)(A + i));\n        __m256i b = _mm256_loadu_si256((__m256i*)(B + i));\n        __m256i not_b = _mm256_xor_si256(b, _mm256_cmpeq_epi64(zero, zero));\n        __m256i result = _mm256_and_si256(a, not_b);\n        _mm256_storeu_si256((__m256i*)(C + i), result);\n    }\n    for (; i < length; ++i) {\n        C[i] = A[i] & (~B[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_42_AVX", "completion": "```cpp\nvoid tensor_bit_clear_simd(const uint64_t* A, const uint64_t* B, uint64_t* C, size_t length) {\n    size_t i = 0;\n    __m256i vecA, vecB, vecC, vecNotB;\n\n    for (; i <= length - 4; i += 4) {\n        vecA = _mm256_loadu_si256((__m256i*)(A + i));\n        vecB = _mm256_loadu_si256((__m256i*)(B + i));\n        vecNotB = _mm256_andnot_si256(vecB, _mm256_set1_epi64x(-1));\n        vecC = _mm256_and_si256(vecA, vecNotB);\n        _mm256_storeu_si256((__m256i*)(C + i), vecC);\n    }\n\n    for (; i < length; ++i) {\n        C[i] = A[i] & (~B[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_42_AVX", "completion": "```cpp\nvoid tensor_bit_clear_simd(const uint64_t* A, const uint64_t* B, uint64_t* C, size_t length) {\n    size_t i = 0;\n    __m256i zero = _mm256_setzero_si256();\n    for (; i <= length - 4; i += 4) {\n        __m256i a = _mm256_loadu_si256((__m256i*)(A + i));\n        __m256i b = _mm256_loadu_si256((__m256i*)(B + i));\n        __m256i not_b = _mm256_xor_si256(b, _mm256_cmpeq_epi64(zero, zero));\n        __m256i result = _mm256_and_si256(a, not_b);\n        _mm256_storeu_si256((__m256i*)(C + i), result);\n    }\n    for (; i < length; ++i) {\n        C[i] = A[i] & (~B[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_43_AVX", "completion": "```cpp\nvoid tensor_three_valued_logic_simd(const int8_t* A, const int8_t* B, int8_t* C, size_t length) {\n    size_t i = 0;\n    __m256i zero = _mm256_setzero_si256();\n    __m256i one = _mm256_set1_epi8(1);\n    __m256i minus_one = _mm256_set1_epi8(-1);\n\n    for (; i <= length - 32; i += 32) {\n        __m256i a = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(A + i));\n        __m256i b = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(B + i));\n\n        __m256i pos_mask = _mm256_and_si256(_mm256_cmpgt_epi8(a, zero), _mm256_cmpgt_epi8(b, zero));\n        __m256i neg_mask = _mm256_and_si256(_mm256_cmplt_epi8(a, zero), _mm256_cmplt_epi8(b, zero));\n\n        __m256i result = _mm256_or_si256(_mm256_and_si256(pos_mask, one), _mm256_and_si256(neg_mask, minus_one));\n\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(C + i), result);\n    }\n\n    for (; i < length; ++i) {\n        if (A[i] > 0 && B[i] > 0) {\n            C[i] = 1;\n        } else if (A[i] < 0 && B[i] < 0) {\n            C[i] = -1;\n        } else {\n            C[i] = 0;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_43_AVX", "completion": "```cpp\nvoid tensor_three_valued_logic_simd(const int8_t* A, const int8_t* B, int8_t* C, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 32; i += 32) {\n        __m256i a = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(A + i));\n        __m256i b = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(B + i));\n\n        __m256i zero = _mm256_setzero_si256();\n        __m256i pos_mask = _mm256_cmpgt_epi8(a, zero);\n        __m256i neg_mask = _mm256_cmplt_epi8(a, zero);\n\n        __m256i b_pos_mask = _mm256_cmpgt_epi8(b, zero);\n        __m256i b_neg_mask = _mm256_cmplt_epi8(b, zero);\n\n        __m256i both_pos = _mm256_and_si256(pos_mask, b_pos_mask);\n        __m256i both_neg = _mm256_and_si256(neg_mask, b_neg_mask);\n\n        __m256i result = _mm256_or_si256(_mm256_and_si256(both_pos, _mm256_set1_epi8(1)),\n                                         _mm256_and_si256(both_neg, _mm256_set1_epi8(-1)));\n\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(C + i), result);\n    }\n\n    for (; i < length; ++i) {\n        if (A[i] > 0 && B[i] > 0) {\n            C[i] = 1;\n        } else if (A[i] < 0 && B[i] < 0) {\n            C[i] = -1;\n        } else {\n            C[i] = 0;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_43_AVX", "completion": "```cpp\nvoid tensor_three_valued_logic_simd(const int8_t* A, const int8_t* B, int8_t* C, size_t length) {\n    size_t i = 0;\n    __m256i zero = _mm256_setzero_si256();\n    __m256i one = _mm256_set1_epi8(1);\n    __m256i minus_one = _mm256_set1_epi8(-1);\n\n    for (; i <= length - 32; i += 32) {\n        __m256i a = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(A + i));\n        __m256i b = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(B + i));\n\n        __m256i pos_a = _mm256_cmpgt_epi8(a, zero);\n        __m256i pos_b = _mm256_cmpgt_epi8(b, zero);\n        __m256i neg_a = _mm256_cmplt_epi8(a, zero);\n        __m256i neg_b = _mm256_cmplt_epi8(b, zero);\n\n        __m256i result_pos = _mm256_and_si256(pos_a, pos_b);\n        __m256i result_neg = _mm256_and_si256(neg_a, neg_b);\n\n        __m256i result = _mm256_or_si256(_mm256_and_si256(result_pos, one), _mm256_and_si256(result_neg, minus_one));\n\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(C + i), result);\n    }\n\n    for (; i < length; ++i) {\n        if (A[i] > 0 && B[i] > 0) {\n            C[i] = 1;\n        } else if (A[i] < 0 && B[i] < 0) {\n            C[i] = -1;\n        } else {\n            C[i] = 0;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_43_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid tensor_three_valued_logic_simd(const int8_t* A, const int8_t* B, int8_t* C, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 32; i += 32) {\n        __m256i a = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(A + i));\n        __m256i b = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(B + i));\n\n        __m256i zero = _mm256_setzero_si256();\n        __m256i pos_mask = _mm256_cmpgt_epi8(a, zero);\n        __m256i neg_mask = _mm256_cmplt_epi8(a, zero);\n\n        __m256i b_pos_mask = _mm256_cmpgt_epi8(b, zero);\n        __m256i b_neg_mask = _mm256_cmplt_epi8(b, zero);\n\n        __m256i both_pos = _mm256_and_si256(pos_mask, b_pos_mask);\n        __m256i both_neg = _mm256_and_si256(neg_mask, b_neg_mask);\n\n        __m256i result = _mm256_or_si256(_mm256_and_si256(both_pos, _mm256_set1_epi8(1)),\n                                         _mm256_and_si256(both_neg, _mm256_set1_epi8(-1)));\n\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(C + i), result);\n    }\n\n    for (; i < length; ++i) {\n        if (A[i] > 0 && B[i] > 0) {\n            C[i] = 1;\n        } else if (A[i] < 0 && B[i] < 0) {\n            C[i] = -1;\n        } else {\n            C[i] = 0;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_43_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid tensor_three_valued_logic_simd(const int8_t* A, const int8_t* B, int8_t* C, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 32; i += 32) {\n        __m256i a = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(A + i));\n        __m256i b = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(B + i));\n\n        __m256i zero = _mm256_setzero_si256();\n        __m256i pos_mask = _mm256_cmpgt_epi8(a, zero);\n        __m256i neg_mask = _mm256_cmplt_epi8(a, zero);\n\n        __m256i b_pos_mask = _mm256_cmpgt_epi8(b, zero);\n        __m256i b_neg_mask = _mm256_cmplt_epi8(b, zero);\n\n        __m256i both_pos = _mm256_and_si256(pos_mask, b_pos_mask);\n        __m256i both_neg = _mm256_and_si256(neg_mask, b_neg_mask);\n\n        __m256i result = _mm256_or_si256(_mm256_and_si256(both_pos, _mm256_set1_epi8(1)),\n                                         _mm256_and_si256(both_neg, _mm256_set1_epi8(-1)));\n\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(C + i), result);\n    }\n\n    for (; i < length; ++i) {\n        if (A[i] > 0 && B[i] > 0) {\n            C[i] = 1;\n        } else if (A[i] < 0 && B[i] < 0) {\n            C[i] = -1;\n        } else {\n            C[i] = 0;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_44_AVX", "completion": "```cpp\nvoid tensor_bit_op_simd(const uint16_t* A, const uint16_t* B, uint16_t* C, size_t length) {\n    size_t midpoint = length / 2;\n    size_t i = 0;\n\n    // Process elements before the midpoint\n    for (; i + 8 <= midpoint; i += 8) {\n        __m256i vecA = _mm256_loadu_si256((__m256i*)(A + i));\n        __m256i vecB = _mm256_loadu_si256((__m256i*)(B + i));\n        __m256i xorResult = _mm256_xor_si256(vecA, vecB);\n        _mm256_storeu_si256((__m256i*)(C + i), xorResult);\n    }\n\n    // Process remaining elements before the midpoint\n    for (; i < midpoint; ++i) {\n        C[i] = A[i] ^ B[i];\n    }\n\n    // Process the midpoint element\n    if (length % 2 != 0) {\n        C[midpoint] = A[midpoint];\n    }\n\n    // Process elements after the midpoint\n    for (i = midpoint + 1; i + 8 <= length; i += 8) {\n        __m256i vecA = _mm256_loadu_si256((__m256i*)(A + i));\n        __m256i vecB = _mm256_loadu_si256((__m256i*)(B + i));\n        __m256i andResult = _mm256_and_si256(vecA, vecB);\n        _mm256_storeu_si256((__m256i*)(C + i), andResult);\n    }\n\n    // Process remaining elements after the midpoint\n    for (; i < length; ++i) {\n        C[i] = A[i] & B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_44_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid tensor_bit_op_simd(const uint16_t* A, const uint16_t* B, uint16_t* C, size_t length) {\n    size_t midpoint = length / 2;\n    size_t i = 0;\n\n    // Process elements before the midpoint\n    for (; i <= midpoint - 16; i += 16) {\n        __m256i vecA = _mm256_loadu_si256((__m256i*)(A + i));\n        __m256i vecB = _mm256_loadu_si256((__m256i*)(B + i));\n        __m256i vecXOR = _mm256_xor_si256(vecA, vecB);\n        __m256i vecAND = _mm256_and_si256(vecA, vecB);\n        _mm256_storeu_si256((__m256i*)(C + i), vecAND);\n        _mm256_storeu_si256((__m256i*)(C + i + 8), vecXOR);\n    }\n\n    // Handle remaining elements before the midpoint\n    for (; i < midpoint; ++i) {\n        if (i % 2 == 0) {\n            C[i] = A[i] & B[i];\n        } else {\n            C[i] = A[i] ^ B[i];\n        }\n    }\n\n    // Process the midpoint element\n    C[midpoint] = A[midpoint];\n\n    // Process elements after the midpoint\n    for (i = midpoint + 1; i <= length - 16; i += 16) {\n        __m256i vecA = _mm256_loadu_si256((__m256i*)(A + i));\n        __m256i vecB = _mm256_loadu_si256((__m256i*)(B + i));\n        __m256i vecXOR = _mm256_xor_si256(vecA, vecB);\n        __m256i vecAND = _mm256_and_si256(vecA, vecB);\n        _mm256_storeu_si256((__m256i*)(C + i), vecAND);\n        _mm256_storeu_si256((__m256i*)(C + i + 8), vecXOR);\n    }\n\n    // Handle remaining elements after the midpoint\n    for (; i < length; ++i) {\n        if ((i - midpoint - 1) % 2 == 0) {\n            C[i] = A[i] & B[i];\n        } else {\n            C[i] = A[i] ^ B[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_44_AVX", "completion": "```cpp\nvoid tensor_bit_op_simd(const uint16_t* A, const uint16_t* B, uint16_t* C, size_t length) {\n    size_t midpoint = length / 2;\n    size_t i = 0;\n\n    // Process elements before the midpoint\n    for (; i + 8 <= midpoint; i += 8) {\n        __m256i vecA = _mm256_loadu_si256((__m256i*)(A + i));\n        __m256i vecB = _mm256_loadu_si256((__m256i*)(B + i));\n        __m256i xorResult = _mm256_xor_si256(vecA, vecB);\n        _mm256_storeu_si256((__m256i*)(C + i), xorResult);\n    }\n\n    // Process remaining elements before the midpoint\n    for (; i < midpoint; ++i) {\n        C[i] = A[i] ^ B[i];\n    }\n\n    // Process the midpoint element\n    if (length % 2 != 0) {\n        C[midpoint] = A[midpoint];\n    }\n\n    // Process elements after the midpoint\n    for (i = midpoint + 1; i + 8 <= length; i += 8) {\n        __m256i vecA = _mm256_loadu_si256((__m256i*)(A + i));\n        __m256i vecB = _mm256_loadu_si256((__m256i*)(B + i));\n        __m256i andResult = _mm256_and_si256(vecA, vecB);\n        _mm256_storeu_si256((__m256i*)(C + i), andResult);\n    }\n\n    // Process remaining elements after the midpoint\n    for (; i < length; ++i) {\n        C[i] = A[i] & B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_44_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid tensor_bit_op_simd(const uint16_t* A, const uint16_t* B, uint16_t* C, size_t length) {\n    size_t midpoint = length / 2;\n    size_t i = 0;\n\n    // Process elements before the midpoint\n    for (; i <= midpoint - 8; i += 8) {\n        __m256i vecA = _mm256_loadu_si256((__m256i*)(A + i));\n        __m256i vecB = _mm256_loadu_si256((__m256i*)(B + i));\n        __m256i vecXOR = _mm256_xor_si256(vecA, vecB);\n        __m256i vecAND = _mm256_and_si256(vecA, vecB);\n        __m256i mask = _mm256_setr_epi16(0xFFFF, 0xFFFF, 0xFFFF, 0xFFFF, 0xFFFF, 0xFFFF, 0xFFFF, 0x0000);\n        __m256i result = _mm256_blendv_epi8(vecXOR, vecAND, mask);\n        _mm256_storeu_si256((__m256i*)(C + i), result);\n    }\n\n    // Handle the midpoint element if length is odd\n    if (length % 2 != 0 && i == midpoint - 1) {\n        C[midpoint] = A[midpoint];\n        i++;\n    }\n\n    // Process remaining elements after the midpoint\n    for (; i < length; i++) {\n        if (i == midpoint) {\n            C[i] = A[i];\n        } else {\n            C[i] = A[i] & B[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_44_AVX", "completion": "```cpp\nvoid tensor_bit_op_simd(const uint16_t* A, const uint16_t* B, uint16_t* C, size_t length) {\n    size_t midpoint = length / 2;\n    size_t i = 0;\n\n    // Process elements before the midpoint\n    for (; i + 8 <= midpoint; i += 8) {\n        __m256i vecA = _mm256_loadu_si256((__m256i*)(A + i));\n        __m256i vecB = _mm256_loadu_si256((__m256i*)(B + i));\n        __m256i xorResult = _mm256_xor_si256(vecA, vecB);\n        _mm256_storeu_si256((__m256i*)(C + i), xorResult);\n    }\n\n    // Process remaining elements before the midpoint\n    for (; i < midpoint; ++i) {\n        C[i] = A[i] ^ B[i];\n    }\n\n    // Process the midpoint element\n    if (length % 2 != 0) {\n        C[midpoint] = A[midpoint];\n    }\n\n    // Process elements after the midpoint\n    for (i = midpoint + 1; i + 8 <= length; i += 8) {\n        __m256i vecA = _mm256_loadu_si256((__m256i*)(A + i));\n        __m256i vecB = _mm256_loadu_si256((__m256i*)(B + i));\n        __m256i andResult = _mm256_and_si256(vecA, vecB);\n        _mm256_storeu_si256((__m256i*)(C + i), andResult);\n    }\n\n    // Process remaining elements after the midpoint\n    for (; i < length; ++i) {\n        C[i] = A[i] & B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_45_AVX", "completion": "```cpp\nvoid tensor_multi_select_simd(const float* A, const float* B, const float* C, const float* D, const bool* cond1, const bool* cond2, float* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t i = 0;\n\n    for (; i <= total_elements - 8; i += 8) {\n        __m256 va = _mm256_loadu_ps(&A[i]);\n        __m256 vb = _mm256_loadu_ps(&B[i]);\n        __m256 vc = _mm256_loadu_ps(&C[i]);\n        __m256 vd = _mm256_loadu_ps(&D[i]);\n\n        __m256i vcond1 = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&cond1[i]));\n        __m256i vcond2 = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&cond2[i]));\n\n        __m256i vcond1_true = _mm256_cmpeq_epi32(vcond1, _mm256_set1_epi32(true));\n        __m256i vcond2_true = _mm256_cmpeq_epi32(vcond2, _mm256_set1_epi32(true));\n\n        __m256i vcond1_and_vcond2 = _mm256_and_si256(vcond1_true, vcond2_true);\n        __m256i vcond1_and_not_vcond2 = _mm256_and_si256(vcond1_true, _mm256_xor_si256(vcond2_true, _mm256_set1_epi32(-1)));\n        __m256i vnot_vcond1_and_vcond2 = _mm256_and_si256(_mm256_xor_si256(vcond1_true, _mm256_set1_epi32(-1)), vcond2_true);\n\n        __m256 result = _mm256_blendv_ps(vd, vc, _mm256_castsi256_ps(vnot_vcond1_and_vcond2));\n        result = _mm256_blendv_ps(result, vb, _mm256_castsi256_ps(vcond1_and_not_vcond2));\n        result = _mm256_blendv_ps(result, va, _mm256_castsi256_ps(vcond1_and_vcond2));\n\n        _mm256_storeu_ps(&out[i], result);\n    }\n\n    for (; i < total_elements; ++i) {\n        if (cond1[i] && cond2[i]) {\n            out[i] = A[i];\n        } else if (cond1[i]) {\n            out[i] = B[i];\n        } else if (cond2[i]) {\n            out[i] = C[i];\n        } else {\n            out[i] = D[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_45_AVX", "completion": "```cpp\nvoid tensor_multi_select_simd(const float* A, const float* B, const float* C, const float* D, const bool* cond1, const bool* cond2, float* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t i = 0;\n\n    for (; i <= total_elements - 8; i += 8) {\n        __m256 va = _mm256_loadu_ps(&A[i]);\n        __m256 vb = _mm256_loadu_ps(&B[i]);\n        __m256 vc = _mm256_loadu_ps(&C[i]);\n        __m256 vd = _mm256_loadu_ps(&D[i]);\n\n        __m256i vcond1 = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&cond1[i]));\n        __m256i vcond2 = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&cond2[i]));\n\n        __m256i vcond1_true = _mm256_cmpeq_epi32(vcond1, _mm256_set1_epi32(1));\n        __m256i vcond2_true = _mm256_cmpeq_epi32(vcond2, _mm256_set1_epi32(1));\n\n        __m256i vcond1_and_cond2 = _mm256_and_si256(vcond1_true, vcond2_true);\n        __m256i vcond1_and_not_cond2 = _mm256_and_si256(vcond1_true, _mm256_xor_si256(vcond2_true, _mm256_set1_epi32(1)));\n        __m256i vnot_cond1_and_cond2 = _mm256_and_si256(_mm256_xor_si256(vcond1_true, _mm256_set1_epi32(1)), vcond2_true);\n\n        __m256 result = _mm256_blendv_ps(vd, vc, _mm256_castsi256_ps(vnot_cond1_and_cond2));\n        result = _mm256_blendv_ps(result, vb, _mm256_castsi256_ps(vcond1_and_not_cond2));\n        result = _mm256_blendv_ps(result, va, _mm256_castsi256_ps(vcond1_and_cond2));\n\n        _mm256_storeu_ps(&out[i], result);\n    }\n\n    for (; i < total_elements; ++i) {\n        if (cond1[i] && cond2[i]) {\n            out[i] = A[i];\n        } else if (cond1[i]) {\n            out[i] = B[i];\n        } else if (cond2[i]) {\n            out[i] = C[i];\n        } else {\n            out[i] = D[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_45_AVX", "completion": "```cpp\nvoid tensor_multi_select_simd(const float* A, const float* B, const float* C, const float* D, const bool* cond1, const bool* cond2, float* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t i = 0;\n\n    for (; i <= total_elements - 8; i += 8) {\n        __m256 va = _mm256_loadu_ps(&A[i]);\n        __m256 vb = _mm256_loadu_ps(&B[i]);\n        __m256 vc = _mm256_loadu_ps(&C[i]);\n        __m256 vd = _mm256_loadu_ps(&D[i]);\n\n        __m256i vcond1 = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&cond1[i]));\n        __m256i vcond2 = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&cond2[i]));\n\n        __m256i vcond1_and_cond2 = _mm256_and_si256(vcond1, vcond2);\n        __m256i vcond1_and_not_cond2 = _mm256_andnot_si256(vcond2, vcond1);\n        __m256i vnot_cond1_and_cond2 = _mm256_andnot_si256(vcond1, vcond2);\n\n        __m256 result = _mm256_blendv_ps(vd, vc, _mm256_castsi256_ps(vnot_cond1_and_cond2));\n        result = _mm256_blendv_ps(result, vb, _mm256_castsi256_ps(vcond1_and_not_cond2));\n        result = _mm256_blendv_ps(result, va, _mm256_castsi256_ps(vcond1_and_cond2));\n\n        _mm256_storeu_ps(&out[i], result);\n    }\n\n    for (; i < total_elements; ++i) {\n        if (cond1[i] && cond2[i]) {\n            out[i] = A[i];\n        } else if (cond1[i]) {\n            out[i] = B[i];\n        } else if (cond2[i]) {\n            out[i] = C[i];\n        } else {\n            out[i] = D[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_45_AVX", "completion": "```cpp\nvoid tensor_multi_select_simd(const float* A, const float* B, const float* C, const float* D, const bool* cond1, const bool* cond2, float* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t i = 0;\n\n    for (; i <= total_elements - 8; i += 8) {\n        __m256 va = _mm256_loadu_ps(&A[i]);\n        __m256 vb = _mm256_loadu_ps(&B[i]);\n        __m256 vc = _mm256_loadu_ps(&C[i]);\n        __m256 vd = _mm256_loadu_ps(&D[i]);\n\n        __m256i vcond1 = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&cond1[i]));\n        __m256i vcond2 = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&cond2[i]));\n\n        __m256i vcond1_true = _mm256_cmpeq_epi32(vcond1, _mm256_set1_epi32(1));\n        __m256i vcond2_true = _mm256_cmpeq_epi32(vcond2, _mm256_set1_epi32(1));\n\n        __m256i vcond1_and_cond2 = _mm256_and_si256(vcond1_true, vcond2_true);\n        __m256i vcond1_and_not_cond2 = _mm256_and_si256(vcond1_true, _mm256_xor_si256(vcond2_true, _mm256_set1_epi32(1)));\n        __m256i vnot_cond1_and_cond2 = _mm256_and_si256(_mm256_xor_si256(vcond1_true, _mm256_set1_epi32(1)), vcond2_true);\n\n        __m256 result = _mm256_blendv_ps(vd, vc, _mm256_castsi256_ps(vnot_cond1_and_cond2));\n        result = _mm256_blendv_ps(result, vb, _mm256_castsi256_ps(vcond1_and_not_cond2));\n        result = _mm256_blendv_ps(result, va, _mm256_castsi256_ps(vcond1_and_cond2));\n\n        _mm256_storeu_ps(&out[i], result);\n    }\n\n    for (; i < total_elements; ++i) {\n        if (cond1[i] && cond2[i]) {\n            out[i] = A[i];\n        } else if (cond1[i]) {\n            out[i] = B[i];\n        } else if (cond2[i]) {\n            out[i] = C[i];\n        } else {\n            out[i] = D[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_45_AVX", "completion": "```cpp\nvoid tensor_multi_select_simd(const float* A, const float* B, const float* C, const float* D, const bool* cond1, const bool* cond2, float* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t i = 0;\n\n    for (; i <= total_elements - 8; i += 8) {\n        __m256 va = _mm256_loadu_ps(&A[i]);\n        __m256 vb = _mm256_loadu_ps(&B[i]);\n        __m256 vc = _mm256_loadu_ps(&C[i]);\n        __m256 vd = _mm256_loadu_ps(&D[i]);\n\n        __m256i vcond1 = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&cond1[i]));\n        __m256i vcond2 = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&cond2[i]));\n\n        __m256i vcond1_true = _mm256_cmpeq_epi32(vcond1, _mm256_set1_epi32(1));\n        __m256i vcond2_true = _mm256_cmpeq_epi32(vcond2, _mm256_set1_epi32(1));\n\n        __m256i vcond1_and_vcond2 = _mm256_and_si256(vcond1_true, vcond2_true);\n        __m256i vcond1_and_not_vcond2 = _mm256_and_si256(vcond1_true, _mm256_xor_si256(vcond2_true, _mm256_set1_epi32(1)));\n        __m256i vnot_vcond1_and_vcond2 = _mm256_and_si256(_mm256_xor_si256(vcond1_true, _mm256_set1_epi32(1)), vcond2_true);\n\n        __m256 result = _mm256_blendv_ps(vd, vc, _mm256_castsi256_ps(vnot_vcond1_and_vcond2));\n        result = _mm256_blendv_ps(result, vb, _mm256_castsi256_ps(vcond1_and_not_vcond2));\n        result = _mm256_blendv_ps(result, va, _mm256_castsi256_ps(vcond1_and_vcond2));\n\n        _mm256_storeu_ps(&out[i], result);\n    }\n\n    for (; i < total_elements; ++i) {\n        if (cond1[i] && cond2[i]) {\n            out[i] = A[i];\n        } else if (cond1[i]) {\n            out[i] = B[i];\n        } else if (cond2[i]) {\n            out[i] = C[i];\n        } else {\n            out[i] = D[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_46_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid tensor_bit_count_simd(const uint32_t* A, uint8_t* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t i = 0;\n\n    for (; i <= total_elements - 8; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i const*)(A + i));\n        __m256i bit_count = _mm256_popcnt_epi32(vec);\n        __m128i low = _mm256_castsi256_si128(bit_count);\n        __m128i high = _mm256_extracti128_si256(bit_count, 1);\n        __m128i packed = _mm_packus_epi16(low, high);\n        _mm_storeu_si128((__m128i*)(out + i), packed);\n    }\n\n    for (; i < total_elements; ++i) {\n        out[i] = __builtin_popcount(A[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_46_AVX", "completion": "```cpp\nvoid tensor_bit_count_simd(const uint32_t* A, uint8_t* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t i = 0;\n\n    for (; i <= total_elements - 8; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i const*)(A + i));\n        __m256i bit_count = _mm256_popcnt_epi32(vec);\n        __m128i lo = _mm_add_epi8(_mm_packus_epi16(_mm256_extracti128_si256(bit_count, 0), _mm256_extracti128_si256(bit_count, 1)),\n                                 _mm_setzero_si128());\n        _mm_storeu_si128((__m128i*)(out + i), lo);\n    }\n\n    for (; i < total_elements; ++i) {\n        out[i] = __builtin_popcount(A[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_46_AVX", "completion": "```cpp\nvoid tensor_bit_count_simd(const uint32_t* A, uint8_t* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t i = 0;\n\n    for (; i <= total_elements - 8; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i const*)(A + i));\n        __m256i bit_count = _mm256_popcnt_epi32(vec);\n        __m128i bit_count_16 = _mm_add_epi8(_mm_packus_epi32(bit_count, bit_count), _mm_packus_epi32(bit_count, bit_count));\n        __m128i bit_count_8 = _mm_add_epi8(bit_count_16, _mm_srli_epi16(bit_count_16, 8));\n        _mm_storel_epi64((__m128i*)(out + i), bit_count_8);\n    }\n\n    for (; i < total_elements; ++i) {\n        out[i] = __builtin_popcount(A[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_46_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid tensor_bit_count_simd(const uint32_t* A, uint8_t* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t i = 0;\n\n    for (; i <= total_elements - 8; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i const*)(A + i));\n        __m256i bit_count = _mm256_popcnt_epi32(vec);\n        __m128i bit_count_16 = _mm_add_epi8(_mm_packus_epi32(_mm256_extracti128_si256(bit_count, 0), _mm256_extracti128_si256(bit_count, 1)), _mm_setzero_si128());\n        _mm_storeu_si128((__m128i*)(out + i), bit_count_16);\n    }\n\n    for (; i < total_elements; ++i) {\n        out[i] = __builtin_popcount(A[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_46_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid tensor_bit_count_simd(const uint32_t* A, uint8_t* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t i = 0;\n\n    for (; i <= total_elements - 8; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i const*)(A + i));\n        __m256i bit_count = _mm256_popcnt_epi32(vec);\n        __m128i bit_count_16 = _mm_add_epi8(_mm_packus_epi32(_mm256_extracti128_si256(bit_count, 0), _mm256_extracti128_si256(bit_count, 1)), _mm_setzero_si128());\n        _mm_storeu_si128((__m128i*)(out + i), bit_count_16);\n    }\n\n    for (; i < total_elements; ++i) {\n        out[i] = __builtin_popcount(A[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_47_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid matrix_conditional_abs_simd(const int* A, int* B, size_t rows, size_t cols) {\n    size_t total_elements = rows * cols;\n    size_t i = 0;\n\n    // Process 8 elements at a time\n    for (; i <= total_elements - 8; i += 8) {\n        __m256i vecA = _mm256_loadu_si256((__m256i const*)(A + i));\n        __m256i three = _mm256_set1_epi32(3);\n        __m256i zero = _mm256_setzero_si256();\n\n        // Check divisibility by 3\n        __m256i mod3 = _mm256_rem_epi32(vecA, three);\n        __m256i mask = _mm256_cmpeq_epi32(mod3, zero);\n\n        // Compute absolute values\n        __m256i absVecA = _mm256_abs_epi32(vecA);\n\n        // Blend based on the mask\n        __m256i result = _mm256_blendv_epi8(vecA, absVecA, mask);\n\n        _mm256_storeu_si256((__m256i*)(B + i), result);\n    }\n\n    // Handle remaining elements\n    for (; i < total_elements; ++i) {\n        B[i] = (A[i] % 3 == 0) ? abs(A[i]) : A[i];\n    }\n}\n```"}
{"task_id": "SimdBench_47_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid matrix_conditional_abs_simd(const int* A, int* B, size_t rows, size_t cols) {\n    size_t total_elements = rows * cols;\n    size_t i = 0;\n\n    // Process 8 elements at a time\n    for (; i <= total_elements - 8; i += 8) {\n        __m256i vecA = _mm256_loadu_si256((__m256i const*)(A + i));\n        __m256i three = _mm256_set1_epi32(3);\n        __m256i zero = _mm256_setzero_si256();\n\n        // Check divisibility by 3\n        __m256i mod3 = _mm256_rem_epi32(vecA, three);\n        __m256i mask = _mm256_cmpeq_epi32(mod3, zero);\n\n        // Compute absolute values\n        __m256i absVecA = _mm256_abs_epi32(vecA);\n\n        // Blend based on the mask\n        __m256i result = _mm256_blendv_epi8(vecA, absVecA, mask);\n\n        _mm256_storeu_si256((__m256i*)(B + i), result);\n    }\n\n    // Handle remaining elements\n    for (; i < total_elements; ++i) {\n        B[i] = (A[i] % 3 == 0) ? abs(A[i]) : A[i];\n    }\n}\n```"}
{"task_id": "SimdBench_47_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid matrix_conditional_abs_simd(const int* A, int* B, size_t rows, size_t cols) {\n    size_t total_elements = rows * cols;\n    size_t i = 0;\n\n    // Process 8 elements at a time\n    for (; i <= total_elements - 8; i += 8) {\n        __m256i vecA = _mm256_loadu_si256((__m256i const*)(A + i));\n        __m256i three = _mm256_set1_epi32(3);\n        __m256i zero = _mm256_setzero_si256();\n\n        // Check divisibility by 3\n        __m256i mod3 = _mm256_rem_epi32(vecA, three);\n        __m256i mask = _mm256_cmpeq_epi32(mod3, zero);\n\n        // Compute absolute values\n        __m256i absVecA = _mm256_abs_epi32(vecA);\n\n        // Blend based on the mask\n        __m256i result = _mm256_blendv_epi8(vecA, absVecA, mask);\n\n        _mm256_storeu_si256((__m256i*)(B + i), result);\n    }\n\n    // Handle remaining elements\n    for (; i < total_elements; ++i) {\n        B[i] = (A[i] % 3 == 0) ? abs(A[i]) : A[i];\n    }\n}\n```"}
{"task_id": "SimdBench_47_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid matrix_conditional_abs_simd(const int* A, int* B, size_t rows, size_t cols) {\n    size_t total_elements = rows * cols;\n    size_t i = 0;\n\n    // Process 8 elements at a time\n    for (; i <= total_elements - 8; i += 8) {\n        __m256i vecA = _mm256_loadu_si256((__m256i const*)(A + i));\n        __m256i three = _mm256_set1_epi32(3);\n        __m256i zero = _mm256_setzero_si256();\n\n        // Check divisibility by 3\n        __m256i mod3 = _mm256_rem_epi32(vecA, three);\n        __m256i mask = _mm256_cmpeq_epi32(mod3, zero);\n\n        // Compute absolute values\n        __m256i absA = _mm256_abs_epi32(vecA);\n\n        // Blend based on mask\n        __m256i result = _mm256_blendv_epi8(vecA, absA, mask);\n\n        _mm256_storeu_si256((__m256i*)(B + i), result);\n    }\n\n    // Handle remaining elements\n    for (; i < total_elements; ++i) {\n        B[i] = (A[i] % 3 == 0) ? abs(A[i]) : A[i];\n    }\n}\n```"}
{"task_id": "SimdBench_47_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid matrix_conditional_abs_simd(const int* A, int* B, size_t rows, size_t cols) {\n    size_t total_elements = rows * cols;\n    size_t i = 0;\n\n    // Process 8 elements at a time\n    for (; i <= total_elements - 8; i += 8) {\n        __m256i vecA = _mm256_loadu_si256((__m256i const*)(A + i));\n        __m256i three = _mm256_set1_epi32(3);\n        __m256i zero = _mm256_setzero_si256();\n\n        // Check divisibility by 3\n        __m256i mod3 = _mm256_rem_epi32(vecA, three);\n        __m256i mask = _mm256_cmpeq_epi32(mod3, zero);\n\n        // Compute absolute values\n        __m256i absVecA = _mm256_abs_epi32(vecA);\n\n        // Blend based on the mask\n        __m256i result = _mm256_blendv_epi8(vecA, absVecA, mask);\n\n        _mm256_storeu_si256((__m256i*)(B + i), result);\n    }\n\n    // Handle remaining elements\n    for (; i < total_elements; ++i) {\n        B[i] = (A[i] % 3 == 0) ? abs(A[i]) : A[i];\n    }\n}\n```"}
{"task_id": "SimdBench_48_AVX", "completion": "```cpp\nvoid matrix_conditional_bit_rotate_simd(const uint32_t* src, uint32_t* dst, uint8_t rotate_bits, size_t length){\n    __m256i mask = _mm256_set1_epi32(0xF);\n    __m256i ones = _mm256_set1_epi32(0xF);\n    __m256i rotate_mask = _mm256_set1_epi32((1 << rotate_bits) - 1);\n\n    for (size_t i = 0; i < length; i += 8) {\n        __m256i src_vec = _mm256_loadu_si256((__m256i const*)(src + i));\n        __m256i low_bits = _mm256_and_si256(src_vec, mask);\n        __m256i condition = _mm256_cmpeq_epi32(low_bits, ones);\n\n        __m256i rotated = _mm256_or_si256(\n            _mm256_and_si256(_mm256_srli_epi32(src_vec, rotate_bits), rotate_mask),\n            _mm256_slli_epi32(src_vec, 32 - rotate_bits)\n        );\n\n        __m256i negated = _mm256_xor_si256(src_vec, _mm256_set1_epi32(-1));\n\n        __m256i result = _mm256_blendv_epi8(negated, rotated, condition);\n\n        _mm256_storeu_si256((__m256i*)(dst + i), result);\n    }\n}\n```"}
{"task_id": "SimdBench_48_AVX", "completion": "```cpp\nvoid matrix_conditional_bit_rotate_simd(const uint32_t* src, uint32_t* dst, uint8_t rotate_bits, size_t length){\n    __m256i mask = _mm256_set1_epi32(0xF);\n    __m256i ones = _mm256_set1_epi32(0xF);\n    __m256i rotate_mask = _mm256_set1_epi32((1 << rotate_bits) - 1);\n\n    for (size_t i = 0; i < length; i += 8) {\n        __m256i src_vec = _mm256_loadu_si256((__m256i const*)(src + i));\n        __m256i low_bits = _mm256_and_si256(src_vec, mask);\n        __m256i condition = _mm256_cmpeq_epi32(low_bits, ones);\n\n        __m256i rotated = _mm256_or_si256(\n            _mm256_and_si256(_mm256_srli_epi32(src_vec, rotate_bits), rotate_mask),\n            _mm256_slli_epi32(src_vec, 32 - rotate_bits)\n        );\n\n        __m256i negated = _mm256_xor_si256(src_vec, _mm256_set1_epi32(0xFFFFFFFF));\n\n        __m256i result = _mm256_blendv_epi8(negated, rotated, condition);\n\n        _mm256_storeu_si256((__m256i*)(dst + i), result);\n    }\n}\n```"}
{"task_id": "SimdBench_48_AVX", "completion": "```cpp\nvoid matrix_conditional_bit_rotate_simd(const uint32_t* src, uint32_t* dst, uint8_t rotate_bits, size_t length){\n    __m256i mask = _mm256_set1_epi32(0xF);\n    __m256i ones = _mm256_set1_epi32(0xF);\n    __m256i rotate_mask = _mm256_set1_epi32((1 << rotate_bits) - 1);\n\n    for (size_t i = 0; i < length; i += 8) {\n        __m256i src_vec = _mm256_loadu_si256((__m256i const*)(src + i));\n        __m256i low_bits = _mm256_and_si256(src_vec, mask);\n        __m256i condition = _mm256_cmpeq_epi32(low_bits, ones);\n\n        __m256i rotated = _mm256_or_si256(\n            _mm256_and_si256(_mm256_srli_epi32(src_vec, rotate_bits), rotate_mask),\n            _mm256_slli_epi32(src_vec, 32 - rotate_bits)\n        );\n\n        __m256i negated = _mm256_xor_si256(src_vec, _mm256_set1_epi32(0xFFFFFFFF));\n\n        __m256i result = _mm256_blendv_epi8(negated, rotated, condition);\n\n        _mm256_storeu_si256((__m256i*)(dst + i), result);\n    }\n}\n```"}
{"task_id": "SimdBench_48_AVX", "completion": "```cpp\nvoid matrix_conditional_bit_rotate_simd(const uint32_t* src, uint32_t* dst, uint8_t rotate_bits, size_t length){\n    __m256i mask = _mm256_set1_epi32(0xF);\n    __m256i ones = _mm256_set1_epi32(0xF);\n    __m256i rotate_mask = _mm256_set1_epi32((1 << rotate_bits) - 1);\n\n    for (size_t i = 0; i < length; i += 8) {\n        __m256i src_vec = _mm256_loadu_si256((__m256i const*)(src + i));\n        __m256i low_bits = _mm256_and_si256(src_vec, mask);\n        __m256i condition = _mm256_cmpeq_epi32(low_bits, ones);\n\n        __m256i rotated = _mm256_or_si256(\n            _mm256_and_si256(_mm256_srli_epi32(src_vec, rotate_bits), rotate_mask),\n            _mm256_slli_epi32(src_vec, 32 - rotate_bits)\n        );\n\n        __m256i negated = _mm256_xor_si256(src_vec, _mm256_set1_epi32(-1));\n\n        __m256i result = _mm256_blendv_epi8(negated, rotated, condition);\n\n        _mm256_storeu_si256((__m256i*)(dst + i), result);\n    }\n}\n```"}
{"task_id": "SimdBench_48_AVX", "completion": "```cpp\nvoid matrix_conditional_bit_rotate_simd(const uint32_t* src, uint32_t* dst, uint8_t rotate_bits, size_t length){\n    __m256i mask = _mm256_set1_epi32(0xF);\n    __m256i ones = _mm256_set1_epi32(0xF);\n    __m256i rotate_mask = _mm256_set1_epi32((1 << rotate_bits) - 1);\n\n    for (size_t i = 0; i < length; i += 8) {\n        __m256i src_vec = _mm256_loadu_si256((__m256i const*)(src + i));\n        __m256i low_bits = _mm256_and_si256(src_vec, mask);\n        __m256i condition = _mm256_cmpeq_epi32(low_bits, ones);\n\n        __m256i rotated = _mm256_or_si256(\n            _mm256_and_si256(_mm256_srli_epi32(src_vec, rotate_bits), rotate_mask),\n            _mm256_slli_epi32(src_vec, 32 - rotate_bits)\n        );\n\n        __m256i negated = _mm256_xor_si256(src_vec, _mm256_set1_epi32(-1));\n\n        __m256i result = _mm256_blendv_epi8(negated, rotated, condition);\n\n        _mm256_storeu_si256((__m256i*)(dst + i), result);\n    }\n}\n```"}
{"task_id": "SimdBench_49_AVX", "completion": "```cpp\nvoid tensor_ternary_compare_simd(const float* A, const float* B, int8_t* out, float epsilon, size_t length) {\n    __m256 eps_vec = _mm256_set1_ps(fabsf(epsilon));\n    size_t i = 0;\n    for (; i <= length - 8; i += 8) {\n        __m256 a_vec = _mm256_loadu_ps(&A[i]);\n        __m256 b_vec = _mm256_loadu_ps(&B[i]);\n        __m256 diff_vec = _mm256_sub_ps(a_vec, b_vec);\n        __m256 abs_diff_vec = _mm256_andnot_ps(_mm256_set1_ps(-0.0f), diff_vec);\n\n        __m256 mask_gt = _mm256_cmp_ps(abs_diff_vec, eps_vec, _CMP_GT_OS);\n        __m256 mask_lt = _mm256_cmp_ps(diff_vec, _mm256_setzero_ps(), _CMP_LT_OS);\n\n        __m256i result_vec = _mm256_setzero_si256();\n        result_vec = _mm256_or_si256(result_vec, _mm256_and_si256(_mm256_castps_si256(mask_gt), _mm256_set1_epi32(1)));\n        result_vec = _mm256_or_si256(result_vec, _mm256_and_si256(_mm256_castps_si256(mask_lt), _mm256_set1_epi32(-1)));\n\n        _mm256_storeu_si256((__m256i*)&out[i], result_vec);\n    }\n\n    for (; i < length; ++i) {\n        float diff = A[i] - B[i];\n        if (fabsf(diff) > fabsf(epsilon)) {\n            out[i] = (diff > 0) ? 1 : -1;\n        } else {\n            out[i] = 0;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_49_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid tensor_ternary_compare_simd(const float* A, const float* B, int8_t* out, float epsilon, size_t length) {\n    __m256 eps_vec = _mm256_set1_ps(epsilon);\n    __m256 neg_eps_vec = _mm256_set1_ps(-epsilon);\n\n    size_t i = 0;\n    for (; i <= length - 8; i += 8) {\n        __m256 a_vec = _mm256_loadu_ps(&A[i]);\n        __m256 b_vec = _mm256_loadu_ps(&B[i]);\n\n        __m256 diff_vec = _mm256_sub_ps(a_vec, b_vec);\n        __m256 abs_diff_vec = _mm256_andnot_ps(_mm256_set1_ps(-0.0f), diff_vec);\n\n        __m256 mask_gt = _mm256_cmp_ps(diff_vec, eps_vec, _CMP_GT_OS);\n        __m256 mask_lt = _mm256_cmp_ps(diff_vec, neg_eps_vec, _CMP_LT_OS);\n        __m256 mask_eq = _mm256_cmp_ps(abs_diff_vec, eps_vec, _CMP_LE_OS);\n\n        __m256i result_vec = _mm256_setzero_si256();\n        result_vec = _mm256_or_si256(result_vec, _mm256_and_si256(_mm256_castps_si256(mask_gt), _mm256_set1_epi32(1)));\n        result_vec = _mm256_or_si256(result_vec, _mm256_and_si256(_mm256_castps_si256(mask_lt), _mm256_set1_epi32(-1)));\n\n        __m256i eq_mask = _mm256_castps_si256(mask_eq);\n        result_vec = _mm256_blendv_epi8(result_vec, _mm256_setzero_si256(), eq_mask);\n\n        _mm256_storeu_si256((__m256i*)&out[i], result_vec);\n    }\n\n    for (; i < length; ++i) {\n        float diff = A[i] - B[i];\n        if (diff > epsilon) {\n            out[i] = 1;\n        } else if (diff < -epsilon) {\n            out[i] = -1;\n        } else {\n            out[i] = 0;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_49_AVX", "completion": "```cpp\nvoid tensor_ternary_compare_simd(const float* A, const float* B, int8_t* out, float epsilon, size_t length) {\n    __m256 epsilon_vec = _mm256_set1_ps(fabsf(epsilon));\n    size_t i = 0;\n    for (; i <= length - 8; i += 8) {\n        __m256 a_vec = _mm256_loadu_ps(&A[i]);\n        __m256 b_vec = _mm256_loadu_ps(&B[i]);\n        __m256 diff_vec = _mm256_sub_ps(a_vec, b_vec);\n        __m256 abs_diff_vec = _mm256_andnot_ps(_mm256_set1_ps(-0.0f), diff_vec);\n\n        __m256 mask_gt = _mm256_cmp_ps(abs_diff_vec, epsilon_vec, _CMP_GT_OS);\n        __m256 mask_lt = _mm256_cmp_ps(diff_vec, _mm256_setzero_ps(), _CMP_LT_OS);\n\n        __m256i result_vec = _mm256_setzero_si256();\n        result_vec = _mm256_or_si256(result_vec, _mm256_and_si256(_mm256_castps_si256(mask_gt), _mm256_set1_epi32(1)));\n        result_vec = _mm256_or_si256(result_vec, _mm256_and_si256(_mm256_castps_si256(mask_lt), _mm256_set1_epi32(-1)));\n\n        _mm256_storeu_si256((__m256i*)&out[i], result_vec);\n    }\n\n    for (; i < length; ++i) {\n        float diff = A[i] - B[i];\n        if (fabsf(diff) > fabsf(epsilon)) {\n            out[i] = (diff > 0) ? 1 : -1;\n        } else {\n            out[i] = 0;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_49_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid tensor_ternary_compare_simd(const float* A, const float* B, int8_t* out, float epsilon, size_t length) {\n    __m256 epsilon_vec = _mm256_set1_ps(epsilon);\n    __m256 neg_epsilon_vec = _mm256_set1_ps(-epsilon);\n\n    size_t i = 0;\n    for (; i <= length - 8; i += 8) {\n        __m256 a_vec = _mm256_loadu_ps(&A[i]);\n        __m256 b_vec = _mm256_loadu_ps(&B[i]);\n\n        __m256 diff_vec = _mm256_sub_ps(a_vec, b_vec);\n        __m256 abs_diff_vec = _mm256_andnot_ps(_mm256_set1_ps(-0.0f), diff_vec);\n\n        __m256 mask_gt = _mm256_cmp_ps(diff_vec, epsilon_vec, _CMP_GT_OS);\n        __m256 mask_lt = _mm256_cmp_ps(diff_vec, neg_epsilon_vec, _CMP_LT_OS);\n        __m256 mask_eq = _mm256_cmp_ps(abs_diff_vec, epsilon_vec, _CMP_LE_OS);\n\n        __m256i result_vec = _mm256_setzero_si256();\n        result_vec = _mm256_or_si256(result_vec, _mm256_and_si256(_mm256_castps_si256(mask_gt), _mm256_set1_epi32(1)));\n        result_vec = _mm256_or_si256(result_vec, _mm256_and_si256(_mm256_castps_si256(mask_lt), _mm256_set1_epi32(-1)));\n\n        __m256i eq_mask = _mm256_castps_si256(mask_eq);\n        result_vec = _mm256_blendv_epi8(result_vec, _mm256_setzero_si256(), eq_mask);\n\n        _mm256_storeu_si256((__m256i*)&out[i], result_vec);\n    }\n\n    for (; i < length; ++i) {\n        float diff = A[i] - B[i];\n        if (diff > epsilon) {\n            out[i] = 1;\n        } else if (diff < -epsilon) {\n            out[i] = -1;\n        } else {\n            out[i] = 0;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_49_AVX", "completion": "```cpp\nvoid tensor_ternary_compare_simd(const float* A, const float* B, int8_t* out, float epsilon, size_t length) {\n    __m256 eps_vec = _mm256_set1_ps(fabsf(epsilon));\n    size_t i = 0;\n    for (; i <= length - 8; i += 8) {\n        __m256 a_vec = _mm256_loadu_ps(&A[i]);\n        __m256 b_vec = _mm256_loadu_ps(&B[i]);\n        __m256 diff_vec = _mm256_sub_ps(a_vec, b_vec);\n        __m256 abs_diff_vec = _mm256_andnot_ps(_mm256_set1_ps(-0.0f), diff_vec);\n\n        __m256 mask_gt = _mm256_cmp_ps(abs_diff_vec, eps_vec, _CMP_GT_OS);\n        __m256 mask_lt = _mm256_cmp_ps(diff_vec, _mm256_setzero_ps(), _CMP_LT_OS);\n\n        __m256i result_vec = _mm256_setzero_si256();\n        result_vec = _mm256_or_si256(result_vec, _mm256_and_si256(_mm256_castps_si256(mask_gt), _mm256_set1_epi32(1)));\n        result_vec = _mm256_or_si256(result_vec, _mm256_and_si256(_mm256_castps_si256(mask_lt), _mm256_set1_epi32(-1)));\n\n        _mm256_storeu_si256((__m256i*)&out[i], result_vec);\n    }\n\n    for (; i < length; ++i) {\n        float diff = A[i] - B[i];\n        if (fabsf(diff) > fabsf(epsilon)) {\n            out[i] = (diff > 0) ? 1 : -1;\n        } else {\n            out[i] = 0;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_50_AVX", "completion": "```cpp\nvoid float_to_int_saturate_simd(const float* A, int32_t* B, size_t size) {\n    const __m256i int_max = _mm256_set1_epi32(INT32_MAX);\n    const __m256i int_min = _mm256_set1_epi32(INT32_MIN);\n    const __m256 float_max = _mm256_castsi256_ps(int_max);\n    const __m256 float_min = _mm256_castsi256_ps(int_min);\n\n    size_t i = 0;\n    for (; i <= size - 8; i += 8) {\n        __m256 vec = _mm256_loadu_ps(&A[i]);\n        vec = _mm256_min_ps(_mm256_max_ps(vec, float_min), float_max);\n        __m256i result = _mm256_cvtps_epi32(vec);\n        _mm256_storeu_si256((__m256i*)&B[i], result);\n    }\n\n    for (; i < size; ++i) {\n        float val = A[i];\n        if (val > INT32_MAX) val = INT32_MAX;\n        else if (val < INT32_MIN) val = INT32_MIN;\n        B[i] = static_cast<int32_t>(val);\n    }\n}\n```"}
{"task_id": "SimdBench_50_AVX", "completion": "```cpp\nvoid float_to_int_saturate_simd(const float* A, int32_t* B, size_t size) {\n    const __m256i int_max = _mm256_set1_epi32(INT32_MAX);\n    const __m256i int_min = _mm256_set1_epi32(INT32_MIN);\n    const __m256 float_max = _mm256_castsi256_ps(int_max);\n    const __m256 float_min = _mm256_castsi256_ps(int_min);\n\n    size_t i;\n    for (i = 0; i <= size - 8; i += 8) {\n        __m256 vec = _mm256_loadu_ps(&A[i]);\n        vec = _mm256_min_ps(vec, float_max);\n        vec = _mm256_max_ps(vec, float_min);\n        __m256i int_vec = _mm256_cvtps_epi32(vec);\n        _mm256_storeu_si256((__m256i*)&B[i], int_vec);\n    }\n\n    for (; i < size; ++i) {\n        float val = A[i];\n        if (val > INT32_MAX) val = INT32_MAX;\n        else if (val < INT32_MIN) val = INT32_MIN;\n        B[i] = static_cast<int32_t>(val);\n    }\n}\n```"}
{"task_id": "SimdBench_50_AVX", "completion": "```cpp\nvoid float_to_int_saturate_simd(const float* A, int32_t* B, size_t size) {\n    const __m256i int_max = _mm256_set1_epi32(INT32_MAX);\n    const __m256i int_min = _mm256_set1_epi32(INT32_MIN);\n    const __m256 float_max = _mm256_castsi256_ps(int_max);\n    const __m256 float_min = _mm256_castsi256_ps(int_min);\n\n    size_t i = 0;\n    for (; i <= size - 8; i += 8) {\n        __m256 vec = _mm256_loadu_ps(&A[i]);\n        vec = _mm256_min_ps(_mm256_max_ps(vec, float_min), float_max);\n        __m256i int_vec = _mm256_cvtps_epi32(vec);\n        _mm256_storeu_si256((__m256i*)&B[i], int_vec);\n    }\n\n    for (; i < size; ++i) {\n        float val = A[i];\n        if (val > INT32_MAX) val = INT32_MAX;\n        else if (val < INT32_MIN) val = INT32_MIN;\n        B[i] = static_cast<int32_t>(val);\n    }\n}\n```"}
{"task_id": "SimdBench_50_AVX", "completion": "```cpp\nvoid float_to_int_saturate_simd(const float* A, int32_t* B, size_t size) {\n    const __m256i int_max = _mm256_set1_epi32(INT32_MAX);\n    const __m256i int_min = _mm256_set1_epi32(INT32_MIN);\n    const __m256 float_max = _mm256_castsi256_ps(int_max);\n    const __m256 float_min = _mm256_castsi256_ps(int_min);\n\n    size_t i = 0;\n    for (; i <= size - 8; i += 8) {\n        __m256 vec = _mm256_loadu_ps(&A[i]);\n        vec = _mm256_min_ps(_mm256_max_ps(vec, float_min), float_max);\n        __m256i int_vec = _mm256_cvtps_epi32(vec);\n        _mm256_storeu_si256((__m256i*)&B[i], int_vec);\n    }\n\n    for (; i < size; ++i) {\n        float val = A[i];\n        if (val > INT32_MAX) val = INT32_MAX;\n        else if (val < INT32_MIN) val = INT32_MIN;\n        B[i] = static_cast<int32_t>(val);\n    }\n}\n```"}
{"task_id": "SimdBench_50_AVX", "completion": "```cpp\nvoid float_to_int_saturate_simd(const float* A, int32_t* B, size_t size) {\n    const __m256i int_max = _mm256_set1_epi32(INT32_MAX);\n    const __m256i int_min = _mm256_set1_epi32(INT32_MIN);\n    const __m256 float_max = _mm256_castsi256_ps(int_max);\n    const __m256 float_min = _mm256_castsi256_ps(int_min);\n\n    size_t i;\n    for (i = 0; i <= size - 8; i += 8) {\n        __m256 vec = _mm256_loadu_ps(&A[i]);\n        vec = _mm256_min_ps(_mm256_max_ps(vec, float_min), float_max);\n        __m256i int_vec = _mm256_cvtps_epi32(vec);\n        _mm256_storeu_si256((__m256i*)&B[i], int_vec);\n    }\n\n    for (; i < size; ++i) {\n        float val = A[i];\n        if (val > INT32_MAX) val = INT32_MAX;\n        else if (val < INT32_MIN) val = INT32_MIN;\n        B[i] = static_cast<int32_t>(val);\n    }\n}\n```"}
{"task_id": "SimdBench_51_AVX", "completion": "```cpp\nvoid int_to_float_scaled_simd(const int32_t* A, int8_t scale, float* B, size_t size) {\n    __m256i v_scale = _mm256_set1_epi32(scale);\n    size_t i = 0;\n    for (; i <= size - 8; i += 8) {\n        __m256i v_ints = _mm256_loadu_si256((__m256i const*)(A + i));\n        __m256 v_floats = _mm256_cvtepi32_ps(v_ints);\n        __m256 v_scaled_floats = _mm256_mul_ps(v_floats, _mm256_cvtepi32_ps(v_scale));\n        _mm256_storeu_ps(B + i, v_scaled_floats);\n    }\n    for (; i < size; ++i) {\n        B[i] = static_cast<float>(A[i]) * scale;\n    }\n}\n```"}
{"task_id": "SimdBench_51_AVX", "completion": "```cpp\nvoid int_to_float_scaled_simd(const int32_t* A, int8_t scale, float* B, size_t size) {\n    __m256i v_scale = _mm256_set1_epi32(scale);\n    size_t i = 0;\n    for (; i <= size - 8; i += 8) {\n        __m256i v_ints = _mm256_loadu_si256((__m256i const*)(A + i));\n        __m256 v_floats = _mm256_cvtepi32_ps(v_ints);\n        __m256 v_scaled_floats = _mm256_mul_ps(v_floats, _mm256_cvtepi32_ps(v_scale));\n        _mm256_storeu_ps(B + i, v_scaled_floats);\n    }\n    for (; i < size; ++i) {\n        B[i] = static_cast<float>(A[i]) * scale;\n    }\n}\n```"}
{"task_id": "SimdBench_51_AVX", "completion": "```cpp\nvoid int_to_float_scaled_simd(const int32_t* A, int8_t scale, float* B, size_t size) {\n    __m256i scale_vec = _mm256_set1_epi32(scale);\n    size_t i = 0;\n    for (; i <= size - 8; i += 8) {\n        __m256i int_vec = _mm256_loadu_si256((__m256i const*)(A + i));\n        __m256 float_vec = _mm256_cvtepi32_ps(int_vec);\n        __m256 scaled_float_vec = _mm256_mul_ps(float_vec, _mm256_cvtepi32_ps(scale_vec));\n        _mm256_storeu_ps(B + i, scaled_float_vec);\n    }\n    for (; i < size; ++i) {\n        B[i] = static_cast<float>(A[i]) * scale;\n    }\n}\n```"}
{"task_id": "SimdBench_51_AVX", "completion": "```cpp\nvoid int_to_float_scaled_simd(const int32_t* A, int8_t scale, float* B, size_t size) {\n    __m256i v_scale = _mm256_set1_epi32(scale);\n    size_t i = 0;\n    for (; i <= size - 8; i += 8) {\n        __m256i v_ints = _mm256_loadu_si256((__m256i const*)(A + i));\n        __m256 v_floats = _mm256_cvtepi32_ps(v_ints);\n        __m256 v_scaled_floats = _mm256_mul_ps(v_floats, _mm256_cvtepi32_ps(v_scale));\n        _mm256_storeu_ps(B + i, v_scaled_floats);\n    }\n    for (; i < size; ++i) {\n        B[i] = static_cast<float>(A[i]) * scale;\n    }\n}\n```"}
{"task_id": "SimdBench_51_AVX", "completion": "```cpp\nvoid int_to_float_scaled_simd(const int32_t* A, int8_t scale, float* B, size_t size) {\n    __m256i v_scale = _mm256_set1_epi32(scale);\n    size_t i = 0;\n    for (; i <= size - 8; i += 8) {\n        __m256i v_ints = _mm256_loadu_si256((__m256i const*)(A + i));\n        __m256 v_floats = _mm256_cvtepi32_ps(v_ints);\n        __m256 v_scaled_floats = _mm256_mul_ps(v_floats, _mm256_cvtepi32_ps(v_scale));\n        _mm256_storeu_ps(B + i, v_scaled_floats);\n    }\n    for (; i < size; ++i) {\n        B[i] = static_cast<float>(A[i]) * scale;\n    }\n}\n```"}
{"task_id": "SimdBench_52_AVX", "completion": "```cpp\nvoid float_div_round_simd(const float* A, const float* B, int32_t* C, size_t size) {\n    size_t i = 0;\n    for (; i <= size - 8; i += 8) {\n        __m256 vecA = _mm256_loadu_ps(&A[i]);\n        __m256 vecB = _mm256_loadu_ps(&B[i]);\n        __m256 vecResult = _mm256_div_ps(vecA, vecB);\n        __m256i vecRounded = _mm256_cvtps_epi32(_mm256_round_ps(vecResult, _MM_FROUND_TO_NEAREST_INT));\n        _mm256_storeu_si256((__m256i*)&C[i], vecRounded);\n    }\n    for (; i < size; ++i) {\n        C[i] = std::lround(A[i] / B[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_52_AVX", "completion": "```cpp\nvoid float_div_round_simd(const float* A, const float* B, int32_t* C, size_t size) {\n    size_t i = 0;\n    for (; i <= size - 8; i += 8) {\n        __m256 va = _mm256_loadu_ps(&A[i]);\n        __m256 vb = _mm256_loadu_ps(&B[i]);\n        __m256 vresult = _mm256_div_ps(va, vb);\n        __m256i vrounded = _mm256_cvtps_epi32(vresult);\n        _mm256_storeu_si256((__m256i*)&C[i], vrounded);\n    }\n    for (; i < size; ++i) {\n        C[i] = (int32_t)roundf(A[i] / B[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_52_AVX", "completion": "```cpp\nvoid float_div_round_simd(const float* A, const float* B, int32_t* C, size_t size) {\n    size_t i = 0;\n    for (; i <= size - 8; i += 8) {\n        __m256 va = _mm256_loadu_ps(&A[i]);\n        __m256 vb = _mm256_loadu_ps(&B[i]);\n        __m256 vresult = _mm256_div_ps(va, vb);\n        __m256i vrounded = _mm256_cvtps_epi32(vresult);\n        _mm256_storeu_si256((__m256i*)&C[i], vrounded);\n    }\n    for (; i < size; ++i) {\n        C[i] = std::lrintf(A[i] / B[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_52_AVX", "completion": "```cpp\nvoid float_div_round_simd(const float* A, const float* B, int32_t* C, size_t size) {\n    size_t i = 0;\n    for (; i <= size - 8; i += 8) {\n        __m256 va = _mm256_loadu_ps(&A[i]);\n        __m256 vb = _mm256_loadu_ps(&B[i]);\n        __m256 vresult = _mm256_div_ps(va, vb);\n        __m256i vrounded = _mm256_cvtps_epi32(vresult);\n        _mm256_storeu_si256((__m256i*)&C[i], vrounded);\n    }\n    for (; i < size; ++i) {\n        C[i] = (int32_t)roundf(A[i] / B[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_52_AVX", "completion": "```cpp\nvoid float_div_round_simd(const float* A, const float* B, int32_t* C, size_t size) {\n    size_t i = 0;\n    for (; i <= size - 8; i += 8) {\n        __m256 va = _mm256_loadu_ps(&A[i]);\n        __m256 vb = _mm256_loadu_ps(&B[i]);\n        __m256 vresult = _mm256_div_ps(va, vb);\n        __m256i vrounded = _mm256_cvtps_epi32(vresult);\n        _mm256_storeu_si256((__m256i*)&C[i], vrounded);\n    }\n    for (; i < size; ++i) {\n        C[i] = (int32_t)roundf(A[i] / B[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_53_AVX", "completion": "```cpp\nvoid double_to_float_saturate_simd(const double* A, float* B, size_t size) {\n    const __m256 max_float = _mm256_set1_ps(FLT_MAX);\n    const __m256 min_float = _mm256_set1_ps(-FLT_MAX);\n\n    size_t i = 0;\n    for (; i <= size - 4; i += 4) {\n        __m256d double_values = _mm256_loadu_pd(&A[i]);\n        __m256 float_values = _mm256_cvtpd_ps(double_values);\n        __m256 saturated_values = _mm256_max_ps(_mm256_min_ps(float_values, max_float), min_float);\n        _mm256_storeu_ps(&B[i], saturated_values);\n    }\n\n    for (; i < size; ++i) {\n        double value = A[i];\n        if (value > FLT_MAX) {\n            B[i] = FLT_MAX;\n        } else if (value < -FLT_MAX) {\n            B[i] = -FLT_MAX;\n        } else {\n            B[i] = static_cast<float>(value);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_53_AVX", "completion": "```cpp\nvoid double_to_float_saturate_simd(const double* A, float* B, size_t size) {\n    const __m256 max_float = _mm256_set1_ps(FLT_MAX);\n    const __m256 min_float = _mm256_set1_ps(-FLT_MAX);\n\n    size_t i;\n    for (i = 0; i <= size - 4; i += 4) {\n        __m256d double_values = _mm256_loadu_pd(&A[i]);\n        __m256 float_values = _mm256_cvtpd_ps(double_values);\n\n        __m256 saturated_values = _mm256_max_ps(_mm256_min_ps(float_values, max_float), min_float);\n        _mm256_storeu_ps(&B[i], saturated_values);\n    }\n\n    for (; i < size; ++i) {\n        double value = A[i];\n        if (value > FLT_MAX) {\n            B[i] = FLT_MAX;\n        } else if (value < -FLT_MAX) {\n            B[i] = -FLT_MAX;\n        } else {\n            B[i] = static_cast<float>(value);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_53_AVX", "completion": "```cpp\nvoid double_to_float_saturate_simd(const double* A, float* B, size_t size) {\n    const __m256 max_float = _mm256_set1_ps(FLT_MAX);\n    const __m256 neg_max_float = _mm256_set1_ps(-FLT_MAX);\n\n    size_t i;\n    for (i = 0; i + 4 <= size; i += 4) {\n        __m256d input = _mm256_loadu_pd(&A[i]);\n        __m256 output = _mm256_cvtpd_ps(input);\n        __m256 mask_gt = _mm256_cmp_ps(output, max_float, _CMP_GT_OS);\n        __m256 mask_lt = _mm256_cmp_ps(output, neg_max_float, _CMP_LT_OS);\n        output = _mm256_blendv_ps(output, max_float, mask_gt);\n        output = _mm256_blendv_ps(output, neg_max_float, mask_lt);\n        _mm256_storeu_ps(&B[i], output);\n    }\n\n    for (; i < size; ++i) {\n        double val = A[i];\n        if (val > FLT_MAX) {\n            B[i] = FLT_MAX;\n        } else if (val < -FLT_MAX) {\n            B[i] = -FLT_MAX;\n        } else {\n            B[i] = static_cast<float>(val);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_53_AVX", "completion": "```cpp\nvoid double_to_float_saturate_simd(const double* A, float* B, size_t size) {\n    const __m256 max_float = _mm256_set1_ps(FLT_MAX);\n    const __m256 neg_max_float = _mm256_set1_ps(-FLT_MAX);\n\n    size_t i;\n    for (i = 0; i <= size - 8; i += 8) {\n        __m256d double_values = _mm256_loadu_pd(&A[i]);\n        __m256 float_values = _mm256_cvtpd_ps(double_values);\n\n        __m256 saturated_values = _mm256_max_ps(_mm256_min_ps(float_values, max_float), neg_max_float);\n        _mm256_storeu_ps(&B[i], saturated_values);\n    }\n\n    for (; i < size; ++i) {\n        double value = A[i];\n        if (value > FLT_MAX) {\n            B[i] = FLT_MAX;\n        } else if (value < -FLT_MAX) {\n            B[i] = -FLT_MAX;\n        } else {\n            B[i] = static_cast<float>(value);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_53_AVX", "completion": "```cpp\nvoid double_to_float_saturate_simd(const double* A, float* B, size_t size) {\n    const __m256 max_float = _mm256_set1_ps(FLT_MAX);\n    const __m256 min_float = _mm256_set1_ps(-FLT_MAX);\n\n    size_t i;\n    for (i = 0; i <= size - 8; i += 8) {\n        __m256d double_values = _mm256_loadu_pd(&A[i]);\n        __m256 float_values = _mm256_cvtpd_ps(double_values);\n\n        __m256 saturated_values = _mm256_max_ps(_mm256_min_ps(float_values, max_float), min_float);\n        _mm256_storeu_ps(&B[i], saturated_values);\n    }\n\n    for (; i < size; ++i) {\n        double value = A[i];\n        if (value > FLT_MAX) {\n            B[i] = FLT_MAX;\n        } else if (value < -FLT_MAX) {\n            B[i] = -FLT_MAX;\n        } else {\n            B[i] = static_cast<float>(value);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_54_AVX", "completion": "```cpp\nvoid int16_to_int32_simd(const int16_t* A, int32_t* B, size_t size) {\n    size_t i = 0;\n    for (; i <= size - 8; i += 8) {\n        __m128i vec16 = _mm_loadu_si128((__m128i*)&A[i]);\n        __m256i vec32 = _mm256_cvtepi16_epi32(vec16);\n        _mm256_storeu_si256((__m256i*)&B[i], vec32);\n    }\n    for (; i < size; ++i) {\n        B[i] = static_cast<int32_t>(A[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_54_AVX", "completion": "```cpp\nvoid int16_to_int32_simd(const int16_t* A, int32_t* B, size_t size) {\n    size_t i = 0;\n    for (; i <= size - 8; i += 8) {\n        __m128i vec16 = _mm_loadu_si128((__m128i const*)(A + i));\n        __m256i vec32 = _mm256_cvtepi16_epi32(vec16);\n        _mm256_storeu_si256((__m256i*)(B + i), vec32);\n    }\n    for (; i < size; ++i) {\n        B[i] = static_cast<int32_t>(A[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_54_AVX", "completion": "```cpp\nvoid int16_to_int32_simd(const int16_t* A, int32_t* B, size_t size) {\n    size_t i = 0;\n    for (; i <= size - 8; i += 8) {\n        __m128i vec16 = _mm_loadu_si128((__m128i const*)(A + i));\n        __m256i vec32 = _mm256_cvtepi16_epi32(vec16);\n        _mm256_storeu_si256((__m256i*)(B + i), vec32);\n    }\n    for (; i < size; ++i) {\n        B[i] = static_cast<int32_t>(A[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_54_AVX", "completion": "```cpp\nvoid int16_to_int32_simd(const int16_t* A, int32_t* B, size_t size) {\n    size_t i = 0;\n    for (; i <= size - 8; i += 8) {\n        __m128i vec16 = _mm_loadu_si128((__m128i const*)(A + i));\n        __m256i vec32 = _mm256_cvtepi16_epi32(vec16);\n        _mm256_storeu_si256((__m256i*)(B + i), vec32);\n    }\n    for (; i < size; ++i) {\n        B[i] = static_cast<int32_t>(A[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_54_AVX", "completion": "```cpp\nvoid int16_to_int32_simd(const int16_t* A, int32_t* B, size_t size) {\n    size_t i = 0;\n    for (; i <= size - 8; i += 8) {\n        __m128i vec16 = _mm_loadu_si128((__m128i const*)(A + i));\n        __m256i vec32 = _mm256_cvtepi16_epi32(vec16);\n        _mm256_storeu_si256((__m256i*)(B + i), vec32);\n    }\n    for (; i < size; ++i) {\n        B[i] = static_cast<int32_t>(A[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_55_AVX", "completion": "```cpp\nvoid conditional_normalize_simd(const float* A, const int32_t* control, float* B, size_t size, float min_val, float max_val) {\n    __m256 v_min = _mm256_set1_ps(min_val);\n    __m256 v_max = _mm256_set1_ps(max_val);\n    __m256 v_one = _mm256_set1_ps(1.0f);\n    __m256 v_zero = _mm256_set1_ps(0.0f);\n\n    size_t i = 0;\n    for (; i <= size - 8; i += 8) {\n        __m256 v_a = _mm256_loadu_ps(&A[i]);\n        __m256 v_normalized = _mm256_sub_ps(v_a, v_min);\n        v_normalized = _mm256_div_ps(v_normalized, _mm256_sub_ps(v_max, v_min));\n        v_normalized = _mm256_max_ps(v_normalized, v_zero);\n        v_normalized = _mm256_min_ps(v_normalized, v_one);\n\n        __m256i v_control = _mm256_loadu_si256((__m256i*)&control[i]);\n        __m256i v_mask = _mm256_cmpgt_epi32(v_control, _mm256_setzero_si256());\n\n        __m256 v_result = _mm256_blendv_ps(v_a, v_normalized, _mm256_castsi256_ps(v_mask));\n        _mm256_storeu_ps(&B[i], v_result);\n    }\n\n    for (; i < size; ++i) {\n        if (control[i] > 0) {\n            float val = (A[i] - min_val) / (max_val - min_val);\n            B[i] = val < 0.0f ? 0.0f : (val > 1.0f ? 1.0f : val);\n        } else {\n            B[i] = A[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_55_AVX", "completion": "```cpp\nvoid conditional_normalize_simd(const float* A, const int32_t* control, float* B, size_t size, float min_val, float max_val) {\n    __m256 v_min = _mm256_set1_ps(min_val);\n    __m256 v_max = _mm256_set1_ps(max_val);\n    __m256 v_one = _mm256_set1_ps(1.0f);\n    __m256 v_zero = _mm256_set1_ps(0.0f);\n\n    size_t i = 0;\n    for (; i <= size - 8; i += 8) {\n        __m256 v_a = _mm256_loadu_ps(&A[i]);\n        __m256 v_control = _mm256_cvtepi32_ps(_mm256_loadu_si256((__m256i*)&control[i]));\n\n        __m256 v_subtracted = _mm256_sub_ps(v_a, v_min);\n        __m256 v_denominator = _mm256_sub_ps(v_max, v_min);\n        __m256 v_divided = _mm256_div_ps(v_subtracted, v_denominator);\n\n        __m256 v_clamped = _mm256_min_ps(_mm256_max_ps(v_divided, v_zero), v_one);\n\n        __m256 v_mask = _mm256_cmp_ps(v_control, v_zero, _CMP_GT_OS);\n        __m256 v_result = _mm256_blendv_ps(v_a, v_clamped, v_mask);\n\n        _mm256_storeu_ps(&B[i], v_result);\n    }\n\n    for (; i < size; ++i) {\n        if (control[i] > 0) {\n            float val = (A[i] - min_val) / (max_val - min_val);\n            B[i] = val < 0.0f ? 0.0f : (val > 1.0f ? 1.0f : val);\n        } else {\n            B[i] = A[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_55_AVX", "completion": "```cpp\nvoid conditional_normalize_simd(const float* A, const int32_t* control, float* B, size_t size, float min_val, float max_val) {\n    __m256 v_min = _mm256_set1_ps(min_val);\n    __m256 v_max = _mm256_set1_ps(max_val);\n    __m256 v_one = _mm256_set1_ps(1.0f);\n    __m256 v_zero = _mm256_set1_ps(0.0f);\n\n    size_t i = 0;\n    for (; i <= size - 8; i += 8) {\n        __m256 v_a = _mm256_loadu_ps(&A[i]);\n        __m256 v_control = _mm256_cvtepi32_ps(_mm256_loadu_si256((__m256i*)&control[i]));\n\n        __m256 v_mask = _mm256_cmp_ps(v_control, v_zero, _CMP_GT_OS);\n        __m256 v_normalized = _mm256_sub_ps(v_a, v_min);\n        v_normalized = _mm256_div_ps(v_normalized, _mm256_sub_ps(v_max, v_min));\n        v_normalized = _mm256_max_ps(v_normalized, v_zero);\n        v_normalized = _mm256_min_ps(v_normalized, v_one);\n\n        __m256 v_result = _mm256_blendv_ps(v_a, v_normalized, v_mask);\n        _mm256_storeu_ps(&B[i], v_result);\n    }\n\n    for (; i < size; ++i) {\n        if (control[i] > 0) {\n            float val = (A[i] - min_val) / (max_val - min_val);\n            B[i] = val < 0.0f ? 0.0f : (val > 1.0f ? 1.0f : val);\n        } else {\n            B[i] = A[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_55_AVX", "completion": "```cpp\nvoid conditional_normalize_simd(const float* A, const int32_t* control, float* B, size_t size, float min_val, float max_val) {\n    __m256 v_min = _mm256_set1_ps(min_val);\n    __m256 v_max = _mm256_set1_ps(max_val);\n    __m256 v_one = _mm256_set1_ps(1.0f);\n    __m256 v_zero = _mm256_set1_ps(0.0f);\n\n    size_t i = 0;\n    for (; i <= size - 8; i += 8) {\n        __m256 v_a = _mm256_loadu_ps(&A[i]);\n        __m256 v_control = _mm256_cvtepi32_ps(_mm256_loadu_si256((__m256i*)&control[i]));\n\n        __m256 v_sub = _mm256_sub_ps(v_a, v_min);\n        __m256 v_div = _mm256_div_ps(v_sub, _mm256_sub_ps(v_max, v_min));\n        __m256 v_clamp = _mm256_min_ps(_mm256_max_ps(v_div, v_zero), v_one);\n\n        __m256 v_mask = _mm256_cmp_ps(v_control, v_zero, _CMP_GT_OS);\n        __m256 v_result = _mm256_blendv_ps(v_a, v_clamp, v_mask);\n\n        _mm256_storeu_ps(&B[i], v_result);\n    }\n\n    for (; i < size; ++i) {\n        if (control[i] > 0) {\n            float val = (A[i] - min_val) / (max_val - min_val);\n            B[i] = val < 0.0f ? 0.0f : (val > 1.0f ? 1.0f : val);\n        } else {\n            B[i] = A[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_55_AVX", "completion": "```cpp\nvoid conditional_normalize_simd(const float* A, const int32_t* control, float* B, size_t size, float min_val, float max_val) {\n    __m256 v_min = _mm256_set1_ps(min_val);\n    __m256 v_max = _mm256_set1_ps(max_val);\n    __m256 v_one = _mm256_set1_ps(1.0f);\n    __m256 v_zero = _mm256_set1_ps(0.0f);\n\n    size_t i = 0;\n    for (; i <= size - 8; i += 8) {\n        __m256 v_a = _mm256_loadu_ps(&A[i]);\n        __m256 v_control = _mm256_cvtepi32_ps(_mm256_loadu_si256((__m256i*)&control[i]));\n\n        __m256 v_mask = _mm256_cmp_ps(v_control, v_zero, _CMP_GT_OS);\n        __m256 v_sub = _mm256_sub_ps(v_a, v_min);\n        __m256 v_div = _mm256_div_ps(v_sub, _mm256_sub_ps(v_max, v_min));\n        __m256 v_clamp = _mm256_max_ps(v_zero, _mm256_min_ps(v_div, v_one));\n\n        __m256 v_result = _mm256_blendv_ps(v_a, v_clamp, v_mask);\n        _mm256_storeu_ps(&B[i], v_result);\n    }\n\n    for (; i < size; ++i) {\n        if (control[i] > 0) {\n            float val = (A[i] - min_val) / (max_val - min_val);\n            B[i] = val < 0.0f ? 0.0f : (val > 1.0f ? 1.0f : val);\n        } else {\n            B[i] = A[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_56_AVX", "completion": "```cpp\nvoid int_to_float_sqrt_simd(const uint32_t* A, float* B, size_t size) {\n    size_t i = 0;\n    __m256i vA;\n    __m256 vB, vC;\n    const __m256i shift = _mm256_set1_epi32(16);\n\n    for (; i <= size - 8; i += 8) {\n        vA = _mm256_loadu_si256((__m256i*)(A + i));\n        vA = _mm256_srli_epi32(vA, 16);\n        vB = _mm256_cvtepi32_ps(vA);\n        vC = _mm256_sqrt_ps(vB);\n        _mm256_storeu_ps(B + i, vC);\n    }\n\n    for (; i < size; ++i) {\n        uint32_t high16 = (A[i] >> 16);\n        B[i] = sqrtf((float)high16);\n    }\n}\n```"}
{"task_id": "SimdBench_56_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid int_to_float_sqrt_simd(const uint32_t* A, float* B, size_t size) {\n    size_t i = 0;\n    for (; i <= size - 8; i += 8) {\n        __m256i vec_int = _mm256_loadu_si256((__m256i const*)(A + i));\n        __m256i vec_high_bits = _mm256_srli_epi32(vec_int, 16);\n        __m256 vec_float = _mm256_cvtepi32_ps(vec_high_bits);\n        __m256 vec_sqrt = _mm256_sqrt_ps(vec_float);\n        _mm256_storeu_ps(B + i, vec_sqrt);\n    }\n    for (; i < size; ++i) {\n        uint32_t high_bits = A[i] >> 16;\n        float value = static_cast<float>(high_bits);\n        B[i] = std::sqrt(value);\n    }\n}\n```"}
{"task_id": "SimdBench_56_AVX", "completion": "```cpp\nvoid int_to_float_sqrt_simd(const uint32_t* A, float* B, size_t size) {\n    size_t i = 0;\n    __m256i vA;\n    __m256 vB, vC, vHighBits;\n    __m128i vHighBits128;\n\n    for (; i <= size - 8; i += 8) {\n        vA = _mm256_loadu_si256((__m256i const*)(A + i));\n        vHighBits = _mm256_srli_epi32(vA, 16);\n        vHighBits128 = _mm256_castsi256_si128(vHighBits);\n        vB = _mm256_cvtepi32_ps(_mm_maskz_mov_epi32(0xFF, vHighBits128));\n        vHighBits128 = _mm256_extracti128_si256(vHighBits, 1);\n        vC = _mm256_cvtepi32_ps(_mm_maskz_mov_epi32(0xFF, vHighBits128));\n        vB = _mm256_sqrt_ps(vB);\n        vC = _mm256_sqrt_ps(vC);\n        _mm256_storeu_ps(B + i, vB);\n        _mm256_storeu_ps(B + i + 4, vC);\n    }\n\n    for (; i < size; ++i) {\n        uint32_t highBits = (A[i] >> 16);\n        B[i] = sqrtf((float)highBits);\n    }\n}\n```"}
{"task_id": "SimdBench_56_AVX", "completion": "```cpp\nvoid int_to_float_sqrt_simd(const uint32_t* A, float* B, size_t size) {\n    size_t i = 0;\n    __m256i zero = _mm256_setzero_si256();\n    __m256 half = _mm256_set1_ps(0.5f);\n\n    for (; i <= size - 8; i += 8) {\n        __m256i vecA = _mm256_loadu_si256((__m256i const*)(A + i));\n        __m256i high16 = _mm256_srli_epi32(vecA, 16);\n        __m256 vecF = _mm256_cvtepi32_ps(high16);\n        __m256 sqrtF = _mm256_sqrt_ps(vecF);\n        _mm256_storeu_ps(B + i, sqrtF);\n    }\n\n    for (; i < size; ++i) {\n        uint32_t high16 = A[i] >> 16;\n        B[i] = std::sqrt(static_cast<float>(high16));\n    }\n}\n```"}
{"task_id": "SimdBench_56_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nvoid int_to_float_sqrt_simd(const uint32_t* A, float* B, size_t size) {\n    size_t i = 0;\n    for (; i <= size - 8; i += 8) {\n        __m256i vec_int = _mm256_loadu_si256((__m256i const*)(A + i));\n        __m256i vec_high_bits = _mm256_srli_epi32(vec_int, 16);\n        __m256 vec_float = _mm256_cvtepi32_ps(vec_high_bits);\n        __m256 vec_sqrt = _mm256_sqrt_ps(vec_float);\n        _mm256_storeu_ps(B + i, vec_sqrt);\n    }\n    for (; i < size; ++i) {\n        uint32_t high_bits = A[i] >> 16;\n        float value = static_cast<float>(high_bits);\n        B[i] = std::sqrt(value);\n    }\n}\n```"}
{"task_id": "SimdBench_57_AVX", "completion": "```cpp\nvoid int_bits_to_float_simd(const uint32_t* A, float* B, size_t size) {\n    size_t i = 0;\n    for (; i <= size - 8; i += 8) {\n        __m256i int_vec = _mm256_loadu_si256((__m256i const*)(A + i));\n        __m256 float_vec = _mm256_castsi256_ps(int_vec);\n        _mm256_storeu_ps(B + i, float_vec);\n    }\n    for (; i < size; ++i) {\n        B[i] = reinterpret_cast<const float&>(A[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_57_AVX", "completion": "```cpp\nvoid int_bits_to_float_simd(const uint32_t* A, float* B, size_t size) {\n    size_t i = 0;\n    for (; i <= size - 8; i += 8) {\n        __m256i int_vec = _mm256_loadu_si256((__m256i const*)(A + i));\n        __m256 float_vec = _mm256_castsi256_ps(int_vec);\n        _mm256_storeu_ps(B + i, float_vec);\n    }\n    for (; i < size; ++i) {\n        B[i] = reinterpret_cast<const float&>(A[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_57_AVX", "completion": "```cpp\nvoid int_bits_to_float_simd(const uint32_t* A, float* B, size_t size) {\n    size_t i = 0;\n    __m256i zero = _mm256_setzero_si256();\n    for (; i <= size - 8; i += 8) {\n        __m256i int_vec = _mm256_loadu_si256((__m256i const*)(A + i));\n        __m256 float_vec = _mm256_castsi256_ps(int_vec);\n        _mm256_storeu_ps(B + i, float_vec);\n    }\n    for (; i < size; ++i) {\n        B[i] = reinterpret_cast<const float&>(A[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_57_AVX", "completion": "```cpp\nvoid int_bits_to_float_simd(const uint32_t* A, float* B, size_t size) {\n    size_t i = 0;\n    for (; i <= size - 8; i += 8) {\n        __m256i int_vec = _mm256_loadu_si256((__m256i const*)(A + i));\n        __m256 float_vec = _mm256_castsi256_ps(int_vec);\n        _mm256_storeu_ps(B + i, float_vec);\n    }\n    for (; i < size; ++i) {\n        B[i] = reinterpret_cast<const float&>(A[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_57_AVX", "completion": "```cpp\nvoid int_bits_to_float_simd(const uint32_t* A, float* B, size_t size) {\n    size_t i = 0;\n    __m256i zero = _mm256_setzero_si256();\n    for (; i <= size - 8; i += 8) {\n        __m256i int_vec = _mm256_loadu_si256((__m256i const*)(A + i));\n        __m256 float_vec = _mm256_castsi256_ps(int_vec);\n        _mm256_storeu_ps(B + i, float_vec);\n    }\n    for (; i < size; ++i) {\n        B[i] = reinterpret_cast<const float&>(A[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_58_AVX", "completion": "```cpp\nvoid conditional_diff_simd(const int32_t* A, const bool* cond, float* diff, size_t size) {\n    __m256i zero = _mm256_setzero_si256();\n    __m256 zero_float = _mm256_setzero_ps();\n\n    if (size > 0) {\n        diff[0] = 0.0f;\n    }\n\n    for (size_t i = 1; i < size; i += 8) {\n        __m256i a_curr = _mm256_loadu_si256((__m256i*)(A + i));\n        __m256i a_prev = _mm256_loadu_si256((__m256i*)(A + i - 1));\n        __m256i diff_int = _mm256_sub_epi32(a_curr, a_prev);\n\n        __m256i cond_vec = _mm256_loadu_si256((__m256i*)(cond + i));\n        __m256i mask = _mm256_cmpgt_epi32(cond_vec, zero);\n\n        __m256 diff_float = _mm256_cvtepi32_ps(diff_int);\n        diff_float = _mm256_and_ps(_mm256_castsi256_ps(mask), diff_float);\n\n        _mm256_storeu_ps(diff + i, diff_float);\n    }\n\n    // Handle remaining elements\n    for (size_t i = (size / 8) * 8; i < size; ++i) {\n        diff[i] = cond[i] ? static_cast<float>(A[i] - A[i - 1]) : 0.0f;\n    }\n}\n```"}
{"task_id": "SimdBench_58_AVX", "completion": "```cpp\nvoid conditional_diff_simd(const int32_t* A, const bool* cond, float* diff, size_t size) {\n    __m256i zero = _mm256_setzero_si256();\n    __m256 zero_float = _mm256_setzero_ps();\n\n    if (size > 0) {\n        diff[0] = 0.0f;\n    }\n\n    for (size_t i = 1; i < size; i += 8) {\n        __m256i a_curr = _mm256_loadu_si256((__m256i*)(A + i));\n        __m256i a_prev = _mm256_loadu_si256((__m256i*)(A + i - 1));\n        __m256i diff_int = _mm256_sub_epi32(a_curr, a_prev);\n\n        __m256i cond_vec = _mm256_loadu_si256((__m256i*)(cond + i));\n        __m256i mask = _mm256_cmpgt_epi32(cond_vec, zero);\n\n        __m256 diff_float = _mm256_cvtepi32_ps(diff_int);\n        diff_float = _mm256_and_ps(_mm256_castsi256_ps(mask), diff_float);\n\n        _mm256_storeu_ps(diff + i, diff_float);\n    }\n\n    // Handle remaining elements\n    for (size_t i = (size / 8) * 8; i < size; ++i) {\n        diff[i] = cond[i] ? static_cast<float>(A[i] - A[i - 1]) : 0.0f;\n    }\n}\n```"}
{"task_id": "SimdBench_58_AVX", "completion": "```cpp\nvoid conditional_diff_simd(const int32_t* A, const bool* cond, float* diff, size_t size) {\n    __m256i zero = _mm256_setzero_si256();\n    __m256 zero_float = _mm256_setzero_ps();\n\n    if (size > 0) {\n        diff[0] = 0.0f;\n    }\n\n    for (size_t i = 1; i < size; i += 8) {\n        __m256i a_curr = _mm256_loadu_si256((__m256i*)(A + i));\n        __m256i a_prev = _mm256_loadu_si256((__m256i*)(A + i - 1));\n        __m256i diff_int = _mm256_sub_epi32(a_curr, a_prev);\n\n        __m256i cond_vec = _mm256_loadu_si256((__m256i*)(cond + i));\n        __m256i mask = _mm256_cmpgt_epi32(cond_vec, zero);\n\n        __m256 diff_float = _mm256_cvtepi32_ps(diff_int);\n        diff_float = _mm256_and_ps(_mm256_castsi256_ps(mask), diff_float);\n\n        _mm256_storeu_ps(diff + i, diff_float);\n    }\n\n    // Handle remaining elements\n    for (size_t i = (size / 8) * 8; i < size; ++i) {\n        diff[i] = cond[i] ? static_cast<float>(A[i] - A[i - 1]) : 0.0f;\n    }\n}\n```"}
{"task_id": "SimdBench_58_AVX", "completion": "```cpp\nvoid conditional_diff_simd(const int32_t* A, const bool* cond, float* diff, size_t size) {\n    __m256i zero = _mm256_setzero_si256();\n    __m256 zero_float = _mm256_setzero_ps();\n\n    if (size > 0) {\n        diff[0] = 0.0f;\n    }\n\n    for (size_t i = 1; i < size; i += 8) {\n        __m256i a_curr = _mm256_loadu_si256((__m256i*)(A + i));\n        __m256i a_prev = _mm256_loadu_si256((__m256i*)(A + i - 1));\n        __m256i diff_int = _mm256_sub_epi32(a_curr, a_prev);\n\n        __m256i cond_vec = _mm256_loadu_si256((__m256i*)(cond + i));\n        __m256i mask = _mm256_cmpgt_epi32(cond_vec, zero);\n\n        __m256 diff_float = _mm256_cvtepi32_ps(diff_int);\n        diff_float = _mm256_and_ps(_mm256_castsi256_ps(mask), diff_float);\n\n        _mm256_storeu_ps(diff + i, diff_float);\n    }\n\n    // Handle remaining elements\n    for (size_t i = (size / 8) * 8; i < size; ++i) {\n        diff[i] = cond[i] ? static_cast<float>(A[i] - A[i - 1]) : 0.0f;\n    }\n}\n```"}
{"task_id": "SimdBench_58_AVX", "completion": "```cpp\nvoid conditional_diff_simd(const int32_t* A, const bool* cond, float* diff, size_t size) {\n    __m256i zero = _mm256_setzero_si256();\n    __m256 zero_float = _mm256_setzero_ps();\n\n    if (size > 0) {\n        diff[0] = 0.0f;\n    }\n\n    for (size_t i = 1; i < size; i += 8) {\n        __m256i a_curr = _mm256_loadu_si256((__m256i*)(A + i));\n        __m256i a_prev = _mm256_loadu_si256((__m256i*)(A + i - 1));\n        __m256i diff_int = _mm256_sub_epi32(a_curr, a_prev);\n\n        __m256i cond_vec = _mm256_loadu_si256((__m256i*)(cond + i));\n        __m256i mask = _mm256_cmpgt_epi32(cond_vec, zero);\n\n        __m256 diff_float = _mm256_cvtepi32_ps(diff_int);\n        diff_float = _mm256_and_ps(diff_float, _mm256_castsi256_ps(mask));\n\n        _mm256_storeu_ps(diff + i, diff_float);\n    }\n\n    // Handle remaining elements\n    for (size_t i = (size / 8) * 8; i < size; ++i) {\n        diff[i] = cond[i] ? static_cast<float>(A[i] - A[i - 1]) : 0.0f;\n    }\n}\n```"}
{"task_id": "SimdBench_59_AVX", "completion": "```cpp\nvoid widening_uint_simd(const uint32_t* src, uint64_t* dst, size_t length) {\n    __m256i ones = _mm256_set1_epi32(0xFFFFFFFF);\n    size_t i = 0;\n    for (; i <= length - 8; i += 8) {\n        __m256i src_vec = _mm256_loadu_si256((__m256i const*)(src + i));\n        __m256i high_bits = _mm256_slli_epi64(src_vec, 32);\n        __m256i result = _mm256_or_si256(high_bits, ones);\n        _mm256_storeu_si256((__m256i*)(dst + i), result);\n    }\n    for (; i < length; ++i) {\n        dst[i] = ((uint64_t)src[i] << 32) | 0xFFFFFFFF;\n    }\n}\n```"}
{"task_id": "SimdBench_59_AVX", "completion": "```cpp\nvoid widening_uint_simd(const uint32_t* src, uint64_t* dst, size_t length) {\n    __m256i ones = _mm256_set1_epi32(0xFFFFFFFF);\n    size_t i = 0;\n    for (; i <= length - 8; i += 8) {\n        __m256i src_vec = _mm256_loadu_si256((__m256i const*)(src + i));\n        __m256i high_bits = _mm256_slli_epi64(src_vec, 32);\n        __m256i result = _mm256_or_si256(high_bits, ones);\n        _mm256_storeu_si256((__m256i*)(dst + i), result);\n    }\n    for (; i < length; ++i) {\n        dst[i] = ((uint64_t)src[i] << 32) | 0xFFFFFFFF;\n    }\n}\n```"}
{"task_id": "SimdBench_59_AVX", "completion": "```cpp\nvoid widening_uint_simd(const uint32_t* src, uint64_t* dst, size_t length) {\n    __m256i ones = _mm256_set1_epi32(0xFFFFFFFF);\n    size_t i = 0;\n    for (; i <= length - 8; i += 8) {\n        __m256i src_vec = _mm256_loadu_si256((__m256i const*)(src + i));\n        __m256i high_bits = _mm256_slli_epi64(src_vec, 32);\n        __m256i result = _mm256_or_si256(high_bits, ones);\n        _mm256_storeu_si256((__m256i*)(dst + i), result);\n    }\n    for (; i < length; ++i) {\n        dst[i] = ((uint64_t)src[i] << 32) | 0xFFFFFFFF;\n    }\n}\n```"}
{"task_id": "SimdBench_59_AVX", "completion": "```cpp\nvoid widening_uint_simd(const uint32_t* src, uint64_t* dst, size_t length) {\n    __m256i ones = _mm256_set1_epi32(0xFFFFFFFF);\n    size_t i = 0;\n    for (; i <= length - 8; i += 8) {\n        __m256i src_vec = _mm256_loadu_si256((__m256i const*)(src + i));\n        __m256i high_bits = _mm256_slli_epi64(src_vec, 32);\n        __m256i result = _mm256_or_si256(high_bits, ones);\n        _mm256_storeu_si256((__m256i*)(dst + i), result);\n    }\n    for (; i < length; ++i) {\n        dst[i] = ((uint64_t)src[i] << 32) | 0xFFFFFFFF;\n    }\n}\n```"}
{"task_id": "SimdBench_59_AVX", "completion": "```cpp\nvoid widening_uint_simd(const uint32_t* src, uint64_t* dst, size_t length) {\n    __m256i ones = _mm256_set1_epi32(0xFFFFFFFF);\n    size_t i = 0;\n    for (; i <= length - 8; i += 8) {\n        __m256i src_vec = _mm256_loadu_si256((__m256i const*)(src + i));\n        __m256i high_bits = _mm256_slli_epi64(src_vec, 32);\n        __m256i result = _mm256_or_si256(high_bits, ones);\n        _mm256_storeu_si256((__m256i*)(dst + i), result);\n    }\n    for (; i < length; ++i) {\n        dst[i] = ((uint64_t)src[i] << 32) | 0xFFFFFFFF;\n    }\n}\n```"}
{"task_id": "SimdBench_60_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\ndouble indexed_sum_simd(const double* vec, const int16_t* index, size_t length) {\n    __m256d sum = _mm256_setzero_pd();\n    size_t i = 0;\n\n    for (; i <= length - 4; i += 4) {\n        __m128i idx = _mm_loadu_si128((__m128i*)&index[i]);\n        __m256d v0 = _mm256_i32gather_pd(vec, _mm256_castsi128_si256(idx), 8);\n        sum = _mm256_add_pd(sum, v0);\n    }\n\n    double result[4];\n    _mm256_storeu_pd(result, sum);\n\n    double total = result[0] + result[1] + result[2] + result[3];\n\n    for (; i < length; ++i) {\n        total += vec[index[i]];\n    }\n\n    return total;\n}\n```"}
{"task_id": "SimdBench_60_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\ndouble indexed_sum_simd(const double* vec, const int16_t* index, size_t length) {\n    __m256d sum = _mm256_setzero_pd();\n    size_t i = 0;\n\n    for (; i <= length - 4; i += 4) {\n        __m128i idx = _mm_loadu_si128((__m128i*)&index[i]);\n        __m256d v0 = _mm256_i32gather_pd(vec, _mm256_cvtepi16_epi32(_mm_castsi128_si64(idx)), 8);\n        __m256d v1 = _mm256_i32gather_pd(vec, _mm256_cvtepi16_epi32(_mm_srli_si128(idx, 8)), 8);\n        sum = _mm256_add_pd(sum, _mm256_add_pd(v0, v1));\n    }\n\n    double result[4];\n    _mm256_storeu_pd(result, sum);\n\n    for (; i < length; ++i) {\n        result[0] += vec[index[i]];\n    }\n\n    return result[0] + result[1] + result[2] + result[3];\n}\n```"}
{"task_id": "SimdBench_60_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\ndouble indexed_sum_simd(const double* vec, const int16_t* index, size_t length) {\n    __m256d sum = _mm256_setzero_pd();\n    size_t i = 0;\n\n    for (; i <= length - 4; i += 4) {\n        __m128i idx = _mm_loadu_si128((__m128i*)&index[i]);\n        __m256d v0 = _mm256_i32gather_pd(vec, _mm256_cvtepi16_epi32(_mm_castsi128_si64(idx)), 8);\n        __m256d v1 = _mm256_i32gather_pd(vec, _mm256_cvtepi16_epi32(_mm_srli_si128(idx, 8)), 8);\n        sum = _mm256_add_pd(sum, _mm256_add_pd(v0, v1));\n    }\n\n    double result[4];\n    _mm256_storeu_pd(result, sum);\n\n    for (; i < length; ++i) {\n        result[0] += vec[index[i]];\n    }\n\n    return result[0] + result[1] + result[2] + result[3];\n}\n```"}
{"task_id": "SimdBench_60_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\ndouble indexed_sum_simd(const double* vec, const int16_t* index, size_t length) {\n    __m256d sum = _mm256_setzero_pd();\n    size_t i = 0;\n\n    for (; i <= length - 4; i += 4) {\n        __m128i idx = _mm_loadu_si128((__m128i*)&index[i]);\n        __m256d v0 = _mm256_i32gather_pd(vec, _mm256_cvtepi16_epi32(_mm_castsi128_si64(idx)), 8);\n        __m256d v1 = _mm256_i32gather_pd(vec, _mm256_cvtepi16_epi32(_mm_srli_si128(idx, 8)), 8);\n        sum = _mm256_add_pd(sum, _mm256_add_pd(v0, v1));\n    }\n\n    double result[4];\n    _mm256_storeu_pd(result, sum);\n\n    for (; i < length; ++i) {\n        result[0] += vec[index[i]];\n    }\n\n    return result[0] + result[1] + result[2] + result[3];\n}\n```"}
{"task_id": "SimdBench_60_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\ndouble indexed_sum_simd(const double* vec, const int16_t* index, size_t length) {\n    __m256d sum = _mm256_setzero_pd();\n    size_t i = 0;\n\n    for (; i <= length - 4; i += 4) {\n        __m128i idx = _mm_loadu_si128((__m128i*)&index[i]);\n        __m256d v0 = _mm256_i32gather_pd(vec, _mm256_castsi128_si256(idx), 8);\n        sum = _mm256_add_pd(sum, v0);\n    }\n\n    double result[4];\n    _mm256_storeu_pd(result, sum);\n\n    double total = result[0] + result[1] + result[2] + result[3];\n\n    for (; i < length; ++i) {\n        total += vec[index[i]];\n    }\n\n    return total;\n}\n```"}
{"task_id": "SimdBench_61_AVX", "completion": "```cpp\nvoid simple_conv2d_simd(const double* input, const double* kernel, double * output, size_t input_size, size_t kernel_size) {\n    size_t output_size = input_size - kernel_size + 1;\n    __m256d zero = _mm256_setzero_pd();\n\n    for (size_t i = 0; i < output_size; ++i) {\n        for (size_t j = 0; j < output_size; ++j) {\n            __m256d sum = _mm256_setzero_pd();\n            for (size_t ki = 0; ki < kernel_size; ++ki) {\n                for (size_t kj = 0; kj < kernel_size; kj += 4) {\n                    __m256d input_vec = _mm256_loadu_pd(&input[(i + ki) * input_size + j + kj]);\n                    __m256d kernel_vec = _mm256_loadu_pd(&kernel[ki * kernel_size + kj]);\n                    sum = _mm256_add_pd(sum, _mm256_mul_pd(input_vec, kernel_vec));\n                }\n            }\n            // Horizontal sum of the 4 elements in sum\n            double tmp[4];\n            _mm256_storeu_pd(tmp, sum);\n            double result = tmp[0] + tmp[1] + tmp[2] + tmp[3];\n            // Apply ReLU activation\n            result = result > 0 ? result : 0;\n            output[i * output_size + j] = result;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_61_AVX", "completion": "```cpp\nvoid simple_conv2d_simd(const double* input, const double* kernel, double * output, size_t input_size, size_t kernel_size) {\n    size_t output_size = input_size - kernel_size + 1;\n    __m256d zero = _mm256_setzero_pd();\n\n    for (size_t i = 0; i < output_size; ++i) {\n        for (size_t j = 0; j < output_size; ++j) {\n            __m256d sum = _mm256_setzero_pd();\n            for (size_t ki = 0; ki < kernel_size; ++ki) {\n                for (size_t kj = 0; kj < kernel_size; kj += 4) {\n                    __m256d input_vec = _mm256_loadu_pd(&input[(i + ki) * input_size + j + kj]);\n                    __m256d kernel_vec = _mm256_loadu_pd(&kernel[ki * kernel_size + kj]);\n                    sum = _mm256_fmadd_pd(input_vec, kernel_vec, sum);\n                }\n            }\n            // Horizontal sum of the 4 elements in sum\n            __m128d sum_low = _mm256_castpd256_pd128(sum);\n            __m128d sum_high = _mm256_extractf128_pd(sum, 1);\n            sum_low = _mm_add_pd(sum_low, sum_high);\n            double result[2];\n            _mm_storeu_pd(result, sum_low);\n            double final_sum = result[0] + result[1];\n\n            // Apply ReLU activation\n            final_sum = final_sum > 0 ? final_sum : 0;\n\n            output[i * output_size + j] = final_sum;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_61_AVX", "completion": "```cpp\nvoid simple_conv2d_simd(const double* input, const double* kernel, double * output, size_t input_size, size_t kernel_size) {\n    size_t output_size = input_size - kernel_size + 1;\n    __m256d zero = _mm256_setzero_pd();\n\n    for (size_t i = 0; i < output_size; ++i) {\n        for (size_t j = 0; j < output_size; ++j) {\n            __m256d sum = _mm256_setzero_pd();\n            for (size_t ki = 0; ki < kernel_size; ++ki) {\n                for (size_t kj = 0; kj < kernel_size; kj += 4) {\n                    __m256d input_vec = _mm256_loadu_pd(&input[(i + ki) * input_size + j + kj]);\n                    __m256d kernel_vec = _mm256_loadu_pd(&kernel[ki * kernel_size + kj]);\n                    sum = _mm256_add_pd(sum, _mm256_mul_pd(input_vec, kernel_vec));\n                }\n            }\n            // Horizontal sum of the 4 elements in sum\n            double tmp[4];\n            _mm256_storeu_pd(tmp, sum);\n            double result = tmp[0] + tmp[1] + tmp[2] + tmp[3];\n            // Apply ReLU activation\n            result = result > 0 ? result : 0;\n            output[i * output_size + j] = result;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_61_AVX", "completion": "```cpp\nvoid simple_conv2d_simd(const double* input, const double* kernel, double * output, size_t input_size, size_t kernel_size) {\n    size_t output_size = input_size - kernel_size + 1;\n    __m256d zero = _mm256_setzero_pd();\n\n    for (size_t i = 0; i < output_size; ++i) {\n        for (size_t j = 0; j < output_size; ++j) {\n            __m256d sum = _mm256_setzero_pd();\n            for (size_t ki = 0; ki < kernel_size; ++ki) {\n                for (size_t kj = 0; kj < kernel_size; kj += 4) {\n                    __m256d input_vec = _mm256_loadu_pd(&input[(i + ki) * input_size + j + kj]);\n                    __m256d kernel_vec = _mm256_loadu_pd(&kernel[ki * kernel_size + kj]);\n                    sum = _mm256_add_pd(sum, _mm256_mul_pd(input_vec, kernel_vec));\n                }\n            }\n            // Horizontal sum of the 4 elements in sum\n            double tmp[4];\n            _mm256_storeu_pd(tmp, sum);\n            double result = tmp[0] + tmp[1] + tmp[2] + tmp[3];\n            // Apply ReLU activation\n            result = result > 0 ? result : 0;\n            output[i * output_size + j] = result;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_61_AVX", "completion": "```cpp\nvoid simple_conv2d_simd(const double* input, const double* kernel, double * output, size_t input_size, size_t kernel_size) {\n    size_t output_size = input_size - kernel_size + 1;\n    __m256d zero = _mm256_setzero_pd();\n\n    for (size_t i = 0; i < output_size; ++i) {\n        for (size_t j = 0; j < output_size; ++j) {\n            __m256d sum = _mm256_setzero_pd();\n            for (size_t ki = 0; ki < kernel_size; ++ki) {\n                for (size_t kj = 0; kj < kernel_size; kj += 4) {\n                    __m256d input_vec = _mm256_loadu_pd(&input[(i + ki) * input_size + j + kj]);\n                    __m256d kernel_vec = _mm256_loadu_pd(&kernel[ki * kernel_size + kj]);\n                    sum = _mm256_add_pd(sum, _mm256_mul_pd(input_vec, kernel_vec));\n                }\n            }\n            // Horizontal sum of the 4 elements in sum\n            double tmp[4];\n            _mm256_storeu_pd(tmp, sum);\n            double result = tmp[0] + tmp[1] + tmp[2] + tmp[3];\n            // Apply ReLU activation\n            result = result > 0 ? result : 0;\n            output[i * output_size + j] = result;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_62_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nbool has_close_elements_simd(const std::vector<double> & numbers, double threshold){\n    int n = numbers.size();\n    if (n < 2) return false;\n\n    __m256d thresh_vec = _mm256_set1_pd(threshold);\n\n    for (int i = 0; i < n; ++i) {\n        __m256d vec1 = _mm256_set1_pd(numbers[i]);\n        for (int j = i + 1; j <= n - 4; j += 4) {\n            __m256d vec2 = _mm256_loadu_pd(&numbers[j]);\n            __m256d diff = _mm256_abs_pd(_mm256_sub_pd(vec1, vec2));\n            __m256d cmp = _mm256_cmp_pd(diff, thresh_vec, _CMP_LT_OS);\n            if (!_mm256_testz_si256((__m256i)cmp, (__m256i)cmp)) {\n                return true;\n            }\n        }\n        for (int j = n - (n % 4); j < n; ++j) {\n            if (std::abs(numbers[i] - numbers[j]) < threshold) {\n                return true;\n            }\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_62_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nbool has_close_elements_simd(const std::vector<double> & numbers, double threshold){\n    int n = numbers.size();\n    if (n < 2) return false;\n\n    __m256d threshold_vec = _mm256_set1_pd(threshold);\n\n    for (int i = 0; i < n; ++i) {\n        __m256d vec1 = _mm256_set1_pd(numbers[i]);\n        for (int j = i + 1; j <= n - 4; j += 4) {\n            __m256d vec2 = _mm256_loadu_pd(&numbers[j]);\n            __m256d diff = _mm256_abs_pd(_mm256_sub_pd(vec1, vec2));\n            __m256d cmp = _mm256_cmp_pd(diff, threshold_vec, _CMP_LT_OS);\n            if (!_mm256_testz_si256((__m256i)cmp, (__m256i)cmp)) {\n                return true;\n            }\n        }\n        for (int j = n - (n % 4); j < n; ++j) {\n            if (std::abs(numbers[i] - numbers[j]) < threshold) {\n                return true;\n            }\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_62_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nbool has_close_elements_simd(const std::vector<double> & numbers, double threshold){\n    int n = numbers.size();\n    if (n < 2) return false;\n\n    __m256d thresh_vec = _mm256_set1_pd(threshold);\n\n    for (int i = 0; i < n; ++i) {\n        __m256d vec1 = _mm256_set1_pd(numbers[i]);\n        for (int j = i + 1; j <= n - 4; j += 4) {\n            __m256d vec2 = _mm256_loadu_pd(&numbers[j]);\n            __m256d diff = _mm256_sub_pd(vec1, vec2);\n            __m256d abs_diff = _mm256_andnot_pd(_mm256_set1_pd(-0.0), diff);\n            __m256d cmp = _mm256_cmp_pd(abs_diff, thresh_vec, _CMP_LT_OS);\n            if (!_mm256_testz_si256((__m256i)cmp, (__m256i)cmp)) {\n                return true;\n            }\n        }\n        for (int j = n - (n % 4); j < n; ++j) {\n            if (std::abs(numbers[i] - numbers[j]) < threshold) {\n                return true;\n            }\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_62_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nbool has_close_elements_simd(const std::vector<double> & numbers, double threshold){\n    int n = numbers.size();\n    if (n < 2) return false;\n\n    __m256d thresh_vec = _mm256_set1_pd(threshold);\n\n    for (int i = 0; i < n; ++i) {\n        __m256d vec1 = _mm256_set1_pd(numbers[i]);\n        for (int j = i + 1; j <= n - 4; j += 4) {\n            __m256d vec2 = _mm256_loadu_pd(&numbers[j]);\n            __m256d diff = _mm256_abs_pd(_mm256_sub_pd(vec1, vec2));\n            __m256d cmp = _mm256_cmp_pd(diff, thresh_vec, _CMP_LT_OS);\n            if (!_mm256_testz_si256((__m256i)cmp, (__m256i)cmp)) {\n                return true;\n            }\n        }\n        for (int j = n - (n % 4); j < n; ++j) {\n            if (std::abs(numbers[i] - numbers[j]) < threshold) {\n                return true;\n            }\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_62_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nbool has_close_elements_simd(const std::vector<double> & numbers, double threshold){\n    int n = numbers.size();\n    if (n < 2) return false;\n\n    __m256d thresh_vec = _mm256_set1_pd(threshold);\n\n    for (int i = 0; i < n; ++i) {\n        __m256d vec1 = _mm256_set1_pd(numbers[i]);\n        for (int j = i + 1; j <= n - 4; j += 4) {\n            __m256d vec2 = _mm256_loadu_pd(&numbers[j]);\n            __m256d diff = _mm256_abs_pd(_mm256_sub_pd(vec1, vec2));\n            __m256d cmp = _mm256_cmp_pd(diff, thresh_vec, _CMP_LT_OS);\n            if (!_mm256_testz_si256((__m256i)cmp, (__m256i)cmp)) {\n                return true;\n            }\n        }\n        for (int j = n - (n % 4); j < n; ++j) {\n            if (std::abs(numbers[i] - numbers[j]) < threshold) {\n                return true;\n            }\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_63_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nbool below_zero_simd(std::vector<int> operations) {\n    __m256i balance = _mm256_setzero_si256();\n    __m256i zero = _mm256_setzero_si256();\n    int n = operations.size();\n    int i = 0;\n\n    for (; i <= n - 8; i += 8) {\n        __m256i ops = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&operations[i]));\n        balance = _mm256_add_epi32(balance, ops);\n        __m256i mask = _mm256_cmpgt_epi32(zero, balance);\n        if (_mm256_movemask_epi8(mask) != 0) {\n            return true;\n        }\n    }\n\n    int remaining_balance[8];\n    _mm256_storeu_si256(reinterpret_cast<__m256i*>(remaining_balance), balance);\n\n    for (; i < n; ++i) {\n        remaining_balance[i % 8] += operations[i];\n        if (remaining_balance[i % 8] < 0) {\n            return true;\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_63_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nbool below_zero_simd(std::vector<int> operations) {\n    int n = operations.size();\n    if (n == 0) return false;\n\n    __m256i balance = _mm256_setzero_si256();\n    __m256i zero = _mm256_setzero_si256();\n    int i = 0;\n\n    for (; i <= n - 8; i += 8) {\n        __m256i ops = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&operations[i]));\n        balance = _mm256_add_epi32(balance, ops);\n        __m256i mask = _mm256_cmpgt_epi32(zero, balance);\n        if (_mm256_movemask_epi8(mask) != 0) {\n            return true;\n        }\n    }\n\n    int remaining_balance[8];\n    _mm256_storeu_si256(reinterpret_cast<__m256i*>(remaining_balance), balance);\n\n    for (; i < n; ++i) {\n        remaining_balance[i % 8] += operations[i];\n        if (remaining_balance[i % 8] < 0) {\n            return true;\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_63_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nbool below_zero_simd(std::vector<int> operations) {\n    __m256i balance = _mm256_setzero_si256();\n    __m256i zero = _mm256_setzero_si256();\n    int n = operations.size();\n    int i = 0;\n\n    for (; i <= n - 8; i += 8) {\n        __m256i ops = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&operations[i]));\n        balance = _mm256_add_epi32(balance, ops);\n        __m256i mask = _mm256_cmpgt_epi32(zero, balance);\n        if (_mm256_movemask_epi8(mask) != 0) {\n            return true;\n        }\n    }\n\n    int remaining_balance[8];\n    _mm256_storeu_si256(reinterpret_cast<__m256i*>(remaining_balance), balance);\n\n    int scalar_balance = 0;\n    for (int j = 0; j < 8; ++j) {\n        scalar_balance += remaining_balance[j];\n        if (scalar_balance < 0) {\n            return true;\n        }\n    }\n\n    for (; i < n; ++i) {\n        scalar_balance += operations[i];\n        if (scalar_balance < 0) {\n            return true;\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_63_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nbool below_zero_simd(std::vector<int> operations) {\n    __m256i balance = _mm256_setzero_si256();\n    __m256i zero = _mm256_setzero_si256();\n    int n = operations.size();\n    int i = 0;\n\n    for (; i <= n - 8; i += 8) {\n        __m256i ops = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&operations[i]));\n        balance = _mm256_add_epi32(balance, ops);\n        __m256i mask = _mm256_cmpgt_epi32(zero, balance);\n        if (_mm256_movemask_epi8(mask) != 0) {\n            return true;\n        }\n    }\n\n    int remaining_balance[8];\n    _mm256_storeu_si256(reinterpret_cast<__m256i*>(remaining_balance), balance);\n\n    for (; i < n; ++i) {\n        remaining_balance[i % 8] += operations[i];\n        if (remaining_balance[i % 8] < 0) {\n            return true;\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_63_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nbool below_zero_simd(std::vector<int> operations) {\n    __m256i balance = _mm256_setzero_si256();\n    __m256i zero = _mm256_setzero_si256();\n    int n = operations.size();\n    int i = 0;\n\n    for (; i <= n - 8; i += 8) {\n        __m256i ops = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&operations[i]));\n        balance = _mm256_add_epi32(balance, ops);\n        __m256i mask = _mm256_cmpgt_epi32(zero, balance);\n        if (_mm256_movemask_epi8(mask) != 0) {\n            return true;\n        }\n    }\n\n    int remaining_balance[8];\n    _mm256_storeu_si256(reinterpret_cast<__m256i*>(remaining_balance), balance);\n\n    for (; i < n; ++i) {\n        remaining_balance[i % 8] += operations[i];\n        if (remaining_balance[i % 8] < 0) {\n            return true;\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_64_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\ndouble mean_absolute_deviation_simd(const std::vector<double>& numbers) {\n    if (numbers.empty()) return 0.0;\n\n    int n = numbers.size();\n    double sum = 0.0;\n    __m256d sum_vec = _mm256_setzero_pd();\n    __m256d mean_vec;\n\n    // Calculate the mean\n    for (int i = 0; i <= n - 4; i += 4) {\n        __m256d vec = _mm256_loadu_pd(&numbers[i]);\n        sum_vec = _mm256_add_pd(sum_vec, vec);\n    }\n    double temp[4];\n    _mm256_storeu_pd(temp, sum_vec);\n    sum = temp[0] + temp[1] + temp[2] + temp[3];\n\n    for (int i = n - n % 4; i < n; ++i) {\n        sum += numbers[i];\n    }\n\n    double mean = sum / n;\n    mean_vec = _mm256_set1_pd(mean);\n\n    sum = 0.0;\n    sum_vec = _mm256_setzero_pd();\n\n    // Calculate the mean absolute deviation\n    for (int i = 0; i <= n - 4; i += 4) {\n        __m256d vec = _mm256_loadu_pd(&numbers[i]);\n        __m256d diff = _mm256_sub_pd(vec, mean_vec);\n        __m256d abs_diff = _mm256_andnot_pd(_mm256_set1_pd(-0.0), diff);\n        sum_vec = _mm256_add_pd(sum_vec, abs_diff);\n    }\n    _mm256_storeu_pd(temp, sum_vec);\n    sum = temp[0] + temp[1] + temp[2] + temp[3];\n\n    for (int i = n - n % 4; i < n; ++i) {\n        sum += std::abs(numbers[i] - mean);\n    }\n\n    return sum / n;\n}\n```"}
{"task_id": "SimdBench_64_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\ndouble mean_absolute_deviation_simd(const std::vector<double>& numbers) {\n    if (numbers.empty()) return 0.0;\n\n    int n = numbers.size();\n    double sum = 0.0;\n    __m256d sum_vec = _mm256_setzero_pd();\n    __m256d mean_vec;\n\n    // Calculate the mean\n    for (int i = 0; i <= n - 4; i += 4) {\n        __m256d vec = _mm256_loadu_pd(&numbers[i]);\n        sum_vec = _mm256_add_pd(sum_vec, vec);\n    }\n    double temp[4];\n    _mm256_storeu_pd(temp, sum_vec);\n    sum = temp[0] + temp[1] + temp[2] + temp[3];\n\n    for (int i = n - (n % 4); i < n; ++i) {\n        sum += numbers[i];\n    }\n\n    double mean = sum / n;\n    mean_vec = _mm256_set1_pd(mean);\n\n    sum = 0.0;\n    sum_vec = _mm256_setzero_pd();\n\n    // Calculate the mean absolute deviation\n    for (int i = 0; i <= n - 4; i += 4) {\n        __m256d vec = _mm256_loadu_pd(&numbers[i]);\n        __m256d diff = _mm256_sub_pd(vec, mean_vec);\n        __m256d abs_diff = _mm256_andnot_pd(_mm256_set1_pd(-0.0), diff);\n        sum_vec = _mm256_add_pd(sum_vec, abs_diff);\n    }\n\n    _mm256_storeu_pd(temp, sum_vec);\n    sum = temp[0] + temp[1] + temp[2] + temp[3];\n\n    for (int i = n - (n % 4); i < n; ++i) {\n        sum += std::abs(numbers[i] - mean);\n    }\n\n    return sum / n;\n}\n```"}
{"task_id": "SimdBench_64_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\ndouble mean_absolute_deviation_simd(const std::vector<double>& numbers) {\n    if (numbers.empty()) return 0.0;\n\n    int n = numbers.size();\n    double sum = 0.0;\n    __m256d sum_vec = _mm256_setzero_pd();\n    __m256d mean_vec;\n\n    // Calculate mean\n    for (int i = 0; i <= n - 4; i += 4) {\n        __m256d vec = _mm256_loadu_pd(&numbers[i]);\n        sum_vec = _mm256_add_pd(sum_vec, vec);\n    }\n    double temp[4];\n    _mm256_storeu_pd(temp, sum_vec);\n    sum = temp[0] + temp[1] + temp[2] + temp[3];\n\n    for (int i = n - (n % 4); i < n; ++i) {\n        sum += numbers[i];\n    }\n\n    double mean = sum / n;\n    mean_vec = _mm256_set1_pd(mean);\n\n    sum = 0.0;\n    sum_vec = _mm256_setzero_pd();\n\n    // Calculate mean absolute deviation\n    for (int i = 0; i <= n - 4; i += 4) {\n        __m256d vec = _mm256_loadu_pd(&numbers[i]);\n        __m256d diff = _mm256_sub_pd(vec, mean_vec);\n        __m256d abs_diff = _mm256_andnot_pd(_mm256_set1_pd(-0.0), diff);\n        sum_vec = _mm256_add_pd(sum_vec, abs_diff);\n    }\n    _mm256_storeu_pd(temp, sum_vec);\n    sum = temp[0] + temp[1] + temp[2] + temp[3];\n\n    for (int i = n - (n % 4); i < n; ++i) {\n        sum += std::abs(numbers[i] - mean);\n    }\n\n    return sum / n;\n}\n```"}
{"task_id": "SimdBench_64_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\ndouble mean_absolute_deviation_simd(const std::vector<double>& numbers) {\n    if (numbers.empty()) return 0.0;\n\n    int n = numbers.size();\n    double sum = 0.0;\n    __m256d sum_vec = _mm256_setzero_pd();\n    __m256d mean_vec;\n\n    // Calculate the mean\n    for (int i = 0; i <= n - 4; i += 4) {\n        __m256d vec = _mm256_loadu_pd(&numbers[i]);\n        sum_vec = _mm256_add_pd(sum_vec, vec);\n    }\n    double temp[4];\n    _mm256_storeu_pd(temp, sum_vec);\n    sum = temp[0] + temp[1] + temp[2] + temp[3];\n\n    for (int i = n - (n % 4); i < n; ++i) {\n        sum += numbers[i];\n    }\n\n    double mean = sum / n;\n    mean_vec = _mm256_set1_pd(mean);\n\n    sum = 0.0;\n    sum_vec = _mm256_setzero_pd();\n\n    // Calculate the mean absolute deviation\n    for (int i = 0; i <= n - 4; i += 4) {\n        __m256d vec = _mm256_loadu_pd(&numbers[i]);\n        __m256d diff = _mm256_sub_pd(vec, mean_vec);\n        __m256d abs_diff = _mm256_andnot_pd(_mm256_set1_pd(-0.0), diff);\n        sum_vec = _mm256_add_pd(sum_vec, abs_diff);\n    }\n    _mm256_storeu_pd(temp, sum_vec);\n    sum = temp[0] + temp[1] + temp[2] + temp[3];\n\n    for (int i = n - (n % 4); i < n; ++i) {\n        sum += std::abs(numbers[i] - mean);\n    }\n\n    return sum / n;\n}\n```"}
{"task_id": "SimdBench_64_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\ndouble mean_absolute_deviation_simd(const std::vector<double>& numbers) {\n    if (numbers.empty()) return 0.0;\n\n    int n = numbers.size();\n    double sum = 0.0;\n    __m256d sum_vec = _mm256_setzero_pd();\n    __m256d mean_vec;\n\n    // Calculate the mean\n    for (int i = 0; i <= n - 4; i += 4) {\n        __m256d vec = _mm256_loadu_pd(&numbers[i]);\n        sum_vec = _mm256_add_pd(sum_vec, vec);\n    }\n    double temp[4];\n    _mm256_storeu_pd(temp, sum_vec);\n    sum = temp[0] + temp[1] + temp[2] + temp[3];\n\n    for (int i = n - n % 4; i < n; ++i) {\n        sum += numbers[i];\n    }\n\n    double mean = sum / n;\n    mean_vec = _mm256_set1_pd(mean);\n\n    sum = 0.0;\n    sum_vec = _mm256_setzero_pd();\n\n    // Calculate the mean absolute deviation\n    for (int i = 0; i <= n - 4; i += 4) {\n        __m256d vec = _mm256_loadu_pd(&numbers[i]);\n        __m256d abs_diff = _mm256_sub_pd(_mm256_max_pd(vec, mean_vec), _mm256_min_pd(vec, mean_vec));\n        sum_vec = _mm256_add_pd(sum_vec, abs_diff);\n    }\n    _mm256_storeu_pd(temp, sum_vec);\n    sum = temp[0] + temp[1] + temp[2] + temp[3];\n\n    for (int i = n - n % 4; i < n; ++i) {\n        sum += std::abs(numbers[i] - mean);\n    }\n\n    return sum / n;\n}\n```"}
{"task_id": "SimdBench_65_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> intersperse_simd(std::vector<int> numbers, int delimeter) {\n    std::vector<int> result;\n    if (numbers.empty()) return result;\n\n    int n = numbers.size();\n    int aligned_n = (n + 7) & ~7; // Align to 8 elements\n    result.resize(n + (n - 1));\n\n    __m256i delimiter_vec = _mm256_set1_epi32(delimeter);\n\n    for (int i = 0; i < aligned_n; i += 8) {\n        __m256i input_vec;\n        if (i + 8 <= n) {\n            input_vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&numbers[i]));\n        } else {\n            int temp[8] = {0};\n            for (int j = 0; j < n - i; ++j) {\n                temp[j] = numbers[i + j];\n            }\n            input_vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(temp));\n        }\n\n        __m256i output_vec1 = _mm256_permutevar8x32_epi32(input_vec, _mm256_setr_epi32(0, 1, 1, 2, 2, 3, 3, 4));\n        __m256i output_vec2 = _mm256_permutevar8x32_epi32(input_vec, _mm256_setr_epi32(4, 4, 5, 5, 6, 6, 7, 7));\n\n        output_vec1 = _mm256_blendv_epi8(output_vec1, delimiter_vec, _mm256_setr_epi8(-1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0));\n        output_vec2 = _mm256_blendv_epi8(output_vec2, delimiter_vec, _mm256_setr_epi8(0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0));\n\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(&result[i * 2]), output_vec1);\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(&result[i * 2 + 8]), output_vec2);\n    }\n\n    // Handle the last element if n is odd\n    if (n % 2 != 0) {\n        result[n * 2 - 2] = numbers[n - 1];\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_65_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> intersperse_simd(std::vector<int> numbers, int delimeter) {\n    std::vector<int> result;\n    if (numbers.empty()) return result;\n\n    int n = numbers.size();\n    int aligned_n = (n + 7) & ~7; // Align to 8 elements\n    result.resize(n + (n - 1));\n\n    __m256i delimiter_vec = _mm256_set1_epi32(delimeter);\n\n    for (int i = 0; i < aligned_n; i += 8) {\n        __m256i input_vec;\n        if (i + 8 <= n) {\n            input_vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&numbers[i]));\n        } else {\n            int temp[8] = {0};\n            for (int j = 0; j < n - i; ++j) {\n                temp[j] = numbers[i + j];\n            }\n            input_vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(temp));\n        }\n\n        __m256i output_vec1 = _mm256_permutevar8x32_epi32(input_vec, _mm256_setr_epi32(0, 1, 1, 2, 2, 3, 3, 4));\n        __m256i output_vec2 = _mm256_permutevar8x32_epi32(input_vec, _mm256_setr_epi32(4, 4, 5, 5, 6, 6, 7, 7));\n\n        output_vec1 = _mm256_blendv_epi8(output_vec1, delimiter_vec, _mm256_setr_epi8(-1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0));\n        output_vec2 = _mm256_blendv_epi8(output_vec2, delimiter_vec, _mm256_setr_epi8(0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0));\n\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(&result[i * 2]), output_vec1);\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(&result[i * 2 + 8]), output_vec2);\n    }\n\n    // Handle the last element if n is odd\n    if (n % 2 != 0) {\n        result[n * 2 - 2] = numbers[n - 1];\n    }\n\n    // Remove extra elements added due to alignment\n    result.resize(n + (n - 1));\n    return result;\n}\n```"}
{"task_id": "SimdBench_65_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> intersperse_simd(std::vector<int> numbers, int delimeter) {\n    std::vector<int> result;\n    if (numbers.empty()) return result;\n\n    int n = numbers.size();\n    int aligned_n = (n + 7) & ~7; // Align to 8 elements\n    result.resize(n + (n - 1));\n\n    __m256i delimiter_vec = _mm256_set1_epi32(delimeter);\n\n    for (int i = 0; i < aligned_n; i += 8) {\n        __m256i input_vec;\n        if (i + 8 <= n) {\n            input_vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&numbers[i]));\n        } else {\n            int temp[8] = {0};\n            for (int j = 0; j < n - i; ++j) {\n                temp[j] = numbers[i + j];\n            }\n            input_vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(temp));\n        }\n\n        __m256i output_vec1 = _mm256_permutevar8x32_epi32(input_vec, _mm256_setr_epi32(0, 1, 1, 2, 2, 3, 3, 4));\n        __m256i output_vec2 = _mm256_permutevar8x32_epi32(input_vec, _mm256_setr_epi32(4, 4, 5, 5, 6, 6, 7, 7));\n\n        output_vec1 = _mm256_blendv_epi8(output_vec1, delimiter_vec, _mm256_setr_epi8(-1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0));\n        output_vec2 = _mm256_blendv_epi8(output_vec2, delimiter_vec, _mm256_setr_epi8(0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0));\n\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(&result[i * 2]), output_vec1);\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(&result[i * 2 + 8]), output_vec2);\n    }\n\n    // Handle the last element if n is odd\n    if (n % 2 != 0) {\n        result[n * 2 - 2] = numbers[n - 1];\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_65_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> intersperse_simd(std::vector<int> numbers, int delimeter) {\n    std::vector<int> result;\n    if (numbers.empty()) return result;\n\n    int n = numbers.size();\n    int aligned_n = (n + 7) & ~7; // Align to 8 elements\n    result.resize(n + (n - 1));\n\n    __m256i delimiter_vec = _mm256_set1_epi32(delimeter);\n\n    for (int i = 0; i < aligned_n; i += 8) {\n        __m256i input_vec;\n        if (i + 8 <= n) {\n            input_vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&numbers[i]));\n        } else {\n            int temp[8] = {0};\n            for (int j = 0; j < n - i; ++j) {\n                temp[j] = numbers[i + j];\n            }\n            input_vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(temp));\n        }\n\n        __m256i output_vec1 = _mm256_permutevar8x32_epi32(input_vec, _mm256_setr_epi32(0, 1, 1, 2, 2, 3, 3, 4));\n        __m256i output_vec2 = _mm256_permutevar8x32_epi32(input_vec, _mm256_setr_epi32(4, 4, 5, 5, 6, 6, 7, 7));\n\n        output_vec1 = _mm256_blendv_epi8(output_vec1, delimiter_vec, _mm256_setr_epi8(-1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0));\n        output_vec2 = _mm256_blendv_epi8(output_vec2, delimiter_vec, _mm256_setr_epi8(0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0));\n\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(&result[i * 2]), output_vec1);\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(&result[i * 2 + 8]), output_vec2);\n    }\n\n    // Handle the last element if n is odd\n    if (n % 2 != 0) {\n        result[n * 2 - 2] = numbers[n - 1];\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_65_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> intersperse_simd(std::vector<int> numbers, int delimeter) {\n    std::vector<int> result;\n    if (numbers.empty()) return result;\n\n    int n = numbers.size();\n    int aligned_n = (n + 7) & ~7; // Align to 8 elements\n    result.resize(n + (n - 1));\n\n    __m256i delimiter_vec = _mm256_set1_epi32(delimeter);\n\n    for (int i = 0; i < aligned_n; i += 8) {\n        __m256i input_vec;\n        if (i + 8 <= n) {\n            input_vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&numbers[i]));\n        } else {\n            int temp[8] = {0};\n            for (int j = 0; j < n - i; ++j) {\n                temp[j] = numbers[i + j];\n            }\n            input_vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(temp));\n        }\n\n        __m256i output_vec1 = _mm256_permutevar8x32_epi32(input_vec, _mm256_setr_epi32(0, 1, 1, 2, 2, 3, 3, 4));\n        __m256i output_vec2 = _mm256_permutevar8x32_epi32(input_vec, _mm256_setr_epi32(4, 4, 5, 5, 6, 6, 7, 7));\n\n        output_vec1 = _mm256_blendv_epi8(output_vec1, delimiter_vec, _mm256_setr_epi8(-1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0));\n        output_vec2 = _mm256_blendv_epi8(output_vec2, delimiter_vec, _mm256_setr_epi8(0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0));\n\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(&result[i * 2]), output_vec1);\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(&result[i * 2 + 8]), output_vec2);\n    }\n\n    // Handle the last element if n is odd\n    if (n % 2 != 0) {\n        result[n * 2 - 2] = numbers[n - 1];\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_66_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int64_t> sum_product_simd(std::vector<int16_t> numbers) {\n    if (numbers.empty()) {\n        return {0, 1};\n    }\n\n    __m256i sum = _mm256_setzero_si256();\n    __m256i prod = _mm256_set1_epi16(1);\n\n    size_t i = 0;\n    for (; i + 16 <= numbers.size(); i += 16) {\n        __m256i num_vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&numbers[i]));\n        sum = _mm256_add_epi16(sum, num_vec);\n        prod = _mm256_mullo_epi16(prod, num_vec);\n    }\n\n    int16_t sum_arr[16];\n    int16_t prod_arr[16];\n    _mm256_storeu_si256(reinterpret_cast<__m256i*>(sum_arr), sum);\n    _mm256_storeu_si256(reinterpret_cast<__m256i*>(prod_arr), prod);\n\n    int64_t total_sum = 0;\n    int64_t total_prod = 1;\n    for (size_t j = 0; j < 16; ++j) {\n        total_sum += sum_arr[j];\n        total_prod *= prod_arr[j];\n    }\n\n    for (; i < numbers.size(); ++i) {\n        total_sum += numbers[i];\n        total_prod *= numbers[i];\n    }\n\n    return {total_sum, total_prod};\n}\n```"}
{"task_id": "SimdBench_66_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int64_t> sum_product_simd(std::vector<int16_t> numbers) {\n    __m256i sum = _mm256_setzero_si256();\n    __m256i prod = _mm256_set1_epi16(1);\n\n    size_t i = 0;\n    for (; i + 15 <= numbers.size(); i += 16) {\n        __m256i num_vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&numbers[i]));\n        sum = _mm256_add_epi16(sum, num_vec);\n        prod = _mm256_mullo_epi16(prod, num_vec);\n    }\n\n    int16_t sum_arr[16];\n    int16_t prod_arr[16];\n    _mm256_storeu_si256(reinterpret_cast<__m256i*>(sum_arr), sum);\n    _mm256_storeu_si256(reinterpret_cast<__m256i*>(prod_arr), prod);\n\n    int64_t total_sum = 0;\n    int64_t total_prod = 1;\n    for (size_t j = 0; j < 16; ++j) {\n        total_sum += sum_arr[j];\n        total_prod *= prod_arr[j];\n    }\n\n    for (; i < numbers.size(); ++i) {\n        total_sum += numbers[i];\n        total_prod *= numbers[i];\n    }\n\n    return {total_sum, total_prod};\n}\n```"}
{"task_id": "SimdBench_66_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int64_t> sum_product_simd(std::vector<int16_t> numbers) {\n    if (numbers.empty()) {\n        return {0, 1};\n    }\n\n    __m256i sum = _mm256_setzero_si256();\n    __m256i prod = _mm256_set1_epi16(1);\n\n    size_t i = 0;\n    for (; i + 15 <= numbers.size(); i += 16) {\n        __m256i num_vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&numbers[i]));\n        sum = _mm256_add_epi16(sum, num_vec);\n        prod = _mm256_mullo_epi16(prod, num_vec);\n    }\n\n    int16_t sum_arr[16];\n    int16_t prod_arr[16];\n    _mm256_storeu_si256(reinterpret_cast<__m256i*>(sum_arr), sum);\n    _mm256_storeu_si256(reinterpret_cast<__m256i*>(prod_arr), prod);\n\n    int64_t total_sum = 0;\n    int64_t total_prod = 1;\n    for (size_t j = 0; j < 16; ++j) {\n        total_sum += sum_arr[j];\n        total_prod *= prod_arr[j];\n    }\n\n    for (; i < numbers.size(); ++i) {\n        total_sum += numbers[i];\n        total_prod *= numbers[i];\n    }\n\n    return {total_sum, total_prod};\n}\n```"}
{"task_id": "SimdBench_66_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int64_t> sum_product_simd(std::vector<int16_t> numbers) {\n    __m256i sum = _mm256_setzero_si256();\n    __m256i prod = _mm256_set1_epi16(1);\n\n    size_t i = 0;\n    for (; i + 16 <= numbers.size(); i += 16) {\n        __m256i num_vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&numbers[i]));\n        sum = _mm256_add_epi16(sum, num_vec);\n        prod = _mm256_mullo_epi16(prod, num_vec);\n    }\n\n    int16_t sum_arr[16];\n    int16_t prod_arr[16];\n    _mm256_storeu_si256(reinterpret_cast<__m256i*>(sum_arr), sum);\n    _mm256_storeu_si256(reinterpret_cast<__m256i*>(prod_arr), prod);\n\n    int64_t total_sum = 0;\n    int64_t total_prod = 1;\n    for (size_t j = 0; j < 16; ++j) {\n        total_sum += sum_arr[j];\n        total_prod *= prod_arr[j];\n    }\n\n    for (; i < numbers.size(); ++i) {\n        total_sum += numbers[i];\n        total_prod *= numbers[i];\n    }\n\n    return {total_sum, total_prod};\n}\n```"}
{"task_id": "SimdBench_66_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int64_t> sum_product_simd(std::vector<int16_t> numbers) {\n    __m256i sum = _mm256_setzero_si256();\n    __m256i prod = _mm256_set1_epi16(1);\n\n    size_t i = 0;\n    for (; i + 15 <= numbers.size(); i += 16) {\n        __m256i num_vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&numbers[i]));\n        sum = _mm256_add_epi16(sum, num_vec);\n        prod = _mm256_mullo_epi16(prod, num_vec);\n    }\n\n    int16_t sum_arr[16];\n    int16_t prod_arr[16];\n    _mm256_storeu_si256(reinterpret_cast<__m256i*>(sum_arr), sum);\n    _mm256_storeu_si256(reinterpret_cast<__m256i*>(prod_arr), prod);\n\n    int64_t total_sum = 0;\n    int64_t total_prod = 1;\n    for (size_t j = 0; j < 16; ++j) {\n        total_sum += sum_arr[j];\n        total_prod *= prod_arr[j];\n    }\n\n    for (; i < numbers.size(); ++i) {\n        total_sum += numbers[i];\n        total_prod *= numbers[i];\n    }\n\n    return {total_sum, total_prod};\n}\n```"}
{"task_id": "SimdBench_67_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> rolling_max_simd(std::vector<int> numbers) {\n    int n = numbers.size();\n    std::vector<int> result(n);\n    if (n == 0) return result;\n\n    __m256i max_vec = _mm256_set1_epi32(numbers[0]);\n    int i = 0;\n\n    // Process 8 elements at a time\n    for (; i <= n - 8; i += 8) {\n        __m256i num_vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&numbers[i]));\n        max_vec = _mm256_max_epi32(max_vec, num_vec);\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(&result[i]), max_vec);\n    }\n\n    // Handle remaining elements\n    int current_max = _mm256_extract_epi32(max_vec, 7);\n    for (; i < n; ++i) {\n        current_max = std::max(current_max, numbers[i]);\n        result[i] = current_max;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_67_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> rolling_max_simd(std::vector<int> numbers) {\n    int n = numbers.size();\n    std::vector<int> result(n);\n    if (n == 0) return result;\n\n    __m256i max_vec = _mm256_set1_epi32(numbers[0]);\n    int i = 0;\n\n    // Process 8 elements at a time\n    for (; i <= n - 8; i += 8) {\n        __m256i num_vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&numbers[i]));\n        max_vec = _mm256_max_epi32(max_vec, num_vec);\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(&result[i]), max_vec);\n    }\n\n    // Handle remaining elements\n    int current_max = _mm256_extract_epi32(max_vec, 7);\n    for (; i < n; ++i) {\n        current_max = std::max(current_max, numbers[i]);\n        result[i] = current_max;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_67_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> rolling_max_simd(std::vector<int> numbers) {\n    int n = numbers.size();\n    std::vector<int> result(n);\n    if (n == 0) return result;\n\n    __m256i max_vec = _mm256_set1_epi32(numbers[0]);\n    int i = 0;\n\n    // Process 8 elements at a time\n    for (; i <= n - 8; i += 8) {\n        __m256i num_vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&numbers[i]));\n        max_vec = _mm256_max_epi32(max_vec, num_vec);\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(&result[i]), max_vec);\n    }\n\n    // Handle remaining elements\n    int current_max = _mm256_extract_epi32(max_vec, 7);\n    for (; i < n; ++i) {\n        current_max = std::max(current_max, numbers[i]);\n        result[i] = current_max;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_67_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> rolling_max_simd(std::vector<int> numbers) {\n    int n = numbers.size();\n    std::vector<int> result(n);\n    if (n == 0) return result;\n\n    __m256i max_vec = _mm256_set1_epi32(numbers[0]);\n    int i = 0;\n\n    // Process 8 elements at a time\n    for (; i <= n - 8; i += 8) {\n        __m256i num_vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&numbers[i]));\n        max_vec = _mm256_max_epi32(max_vec, num_vec);\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(&result[i]), max_vec);\n    }\n\n    // Handle remaining elements\n    int current_max = _mm256_extract_epi32(max_vec, 7);\n    for (; i < n; ++i) {\n        current_max = std::max(current_max, numbers[i]);\n        result[i] = current_max;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_67_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> rolling_max_simd(std::vector<int> numbers) {\n    int n = numbers.size();\n    std::vector<int> result(n);\n    if (n == 0) return result;\n\n    __m256i max_vec = _mm256_set1_epi32(numbers[0]);\n    int i = 0;\n\n    // Process 8 elements at a time\n    for (; i <= n - 8; i += 8) {\n        __m256i input_vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&numbers[i]));\n        max_vec = _mm256_max_epi32(max_vec, input_vec);\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(&result[i]), max_vec);\n    }\n\n    // Handle remaining elements\n    int current_max = _mm256_extract_epi32(max_vec, 7);\n    for (; i < n; ++i) {\n        current_max = std::max(current_max, numbers[i]);\n        result[i] = current_max;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_68_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n#include <cstring>\n\nstd::string string_xor_simd(std::string a, std::string b){\n    size_t len = a.size();\n    if (len != b.size()) {\n        throw std::invalid_argument(\"Strings must be of equal length\");\n    }\n\n    std::string result(len, '0');\n    const char* a_ptr = a.c_str();\n    const char* b_ptr = b.c_str();\n    char* result_ptr = &result[0];\n\n    size_t i = 0;\n    for (; i <= len - 32; i += 32) {\n        __m256i vec_a = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(a_ptr + i));\n        __m256i vec_b = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(b_ptr + i));\n        __m256i vec_xor = _mm256_xor_si256(vec_a, vec_b);\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(result_ptr + i), vec_xor);\n    }\n\n    for (; i < len; ++i) {\n        result_ptr[i] = (a_ptr[i] == b_ptr[i]) ? '0' : '1';\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_68_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n#include <algorithm>\n\nstd::string string_xor_simd(std::string a, std::string b){\n    size_t len = std::min(a.size(), b.size());\n    size_t aligned_len = (len / 32) * 32;\n    std::string result(len, '0');\n\n    for (size_t i = 0; i < aligned_len; i += 32) {\n        __m256i vec_a = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(a.data() + i));\n        __m256i vec_b = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(b.data() + i));\n        __m256i vec_xor = _mm256_xor_si256(vec_a, vec_b);\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(result.data() + i), vec_xor);\n    }\n\n    for (size_t i = aligned_len; i < len; ++i) {\n        result[i] = (a[i] == b[i]) ? '0' : '1';\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_68_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n#include <algorithm>\n\nstd::string string_xor_simd(std::string a, std::string b) {\n    size_t len = std::min(a.size(), b.size());\n    std::string result(len, '0');\n\n    const char* a_ptr = a.c_str();\n    const char* b_ptr = b.c_str();\n    char* result_ptr = result.data();\n\n    size_t i = 0;\n    for (; i <= len - 32; i += 32) {\n        __m256i vec_a = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(a_ptr + i));\n        __m256i vec_b = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(b_ptr + i));\n        __m256i vec_xor = _mm256_xor_si256(vec_a, vec_b);\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(result_ptr + i), vec_xor);\n    }\n\n    for (; i < len; ++i) {\n        result_ptr[i] = (a_ptr[i] == b_ptr[i]) ? '0' : '1';\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_68_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n#include <algorithm>\n\nstd::string string_xor_simd(std::string a, std::string b) {\n    size_t len = std::min(a.size(), b.size());\n    std::string result(len, '0');\n\n    const char* a_ptr = a.c_str();\n    const char* b_ptr = b.c_str();\n    char* result_ptr = result.data();\n\n    size_t i = 0;\n    for (; i <= len - 32; i += 32) {\n        __m256i va = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(a_ptr + i));\n        __m256i vb = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(b_ptr + i));\n        __m256i vxor = _mm256_xor_si256(va, vb);\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(result_ptr + i), vxor);\n    }\n\n    for (; i < len; ++i) {\n        result_ptr[i] = (a_ptr[i] == b_ptr[i]) ? '0' : '1';\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_68_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n#include <algorithm>\n\nstd::string string_xor_simd(std::string a, std::string b){\n    if (a.size() != b.size()) {\n        throw std::invalid_argument(\"Strings must be of equal length\");\n    }\n\n    size_t len = a.size();\n    std::string result(len, '0');\n\n    const char* a_ptr = a.c_str();\n    const char* b_ptr = b.c_str();\n    char* result_ptr = &result[0];\n\n    size_t i = 0;\n    for (; i <= len - 32; i += 32) {\n        __m256i va = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(a_ptr + i));\n        __m256i vb = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(b_ptr + i));\n        __m256i vxor = _mm256_xor_si256(va, vb);\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(result_ptr + i), vxor);\n    }\n\n    for (; i < len; ++i) {\n        result[i] = (a[i] == b[i]) ? '0' : '1';\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_69_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n#include <algorithm>\n\nstd::string longest_simd(const std::vector<std::string> & strings){\n    if (strings.empty()) {\n        return \"\";\n    }\n\n    const int numStrings = strings.size();\n    const int simdWidth = 8; // AVX2 processes 256 bits, which can hold 8 x 32-bit integers\n    int maxLengths[simdWidth] = {0};\n    int maxIndices[simdWidth] = {0};\n    int overallMaxLength = 0;\n    int overallMaxIndex = 0;\n\n    __m256i maxLengthVec = _mm256_setzero_si256();\n    __m256i maxIndexVec = _mm256_setzero_si256();\n\n    for (int i = 0; i < numStrings; i += simdWidth) {\n        __m256i lengthVec = _mm256_setzero_si256();\n        __m256i indexVec = _mm256_set_epi32(\n            i + 7, i + 6, i + 5, i + 4, i + 3, i + 2, i + 1, i\n        );\n\n        for (int j = 0; j < simdWidth && (i + j) < numStrings; ++j) {\n            int len = strings[i + j].length();\n            maxLengths[j] = len;\n            maxIndices[j] = i + j;\n            lengthVec = _mm256_insert_epi32(lengthVec, len, j);\n        }\n\n        __m256i cmpMask = _mm256_cmpgt_epi32(lengthVec, maxLengthVec);\n        maxLengthVec = _mm256_max_epi32(lengthVec, maxLengthVec);\n        maxIndexVec = _mm256_blendv_epi8(maxIndexVec, indexVec, cmpMask);\n\n        if ((i + simdWidth) >= numStrings) {\n            _mm256_storeu_si256(reinterpret_cast<__m256i*>(maxLengths), maxLengthVec);\n            _mm256_storeu_si256(reinterpret_cast<__m256i*>(maxIndices), maxIndexVec);\n\n            for (int j = 0; j < simdWidth && (i + j) < numStrings; ++j) {\n                if (maxLengths[j] > overallMaxLength) {\n                    overallMaxLength = maxLengths[j];\n                    overallMaxIndex = maxIndices[j];\n                }\n            }\n        }\n    }\n\n    return strings[overallMaxIndex];\n}\n```"}
{"task_id": "SimdBench_69_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n#include <algorithm>\n\nstd::string longest_simd(const std::vector<std::string> & strings){\n    if (strings.empty()) {\n        return \"\";\n    }\n\n    const int num_strings = strings.size();\n    const int batch_size = 8; // AVX2 can process 8 integers at a time\n    int max_length = 0;\n    int max_index = 0;\n\n    for (int i = 0; i < num_strings; i += batch_size) {\n        __m256i lengths = _mm256_setzero_si256();\n        int local_max_length = 0;\n        int local_max_index = 0;\n\n        for (int j = 0; j < batch_size && (i + j) < num_strings; ++j) {\n            int len = strings[i + j].length();\n            lengths = _mm256_insert_epi32(lengths, len, j);\n            if (len > local_max_length) {\n                local_max_length = len;\n                local_max_index = i + j;\n            }\n        }\n\n        __m256i max_lengths = _mm256_max_epi32(lengths, _mm256_permutevar8x32_epi32(lengths, _mm256_setr_epi32(1, 0, 3, 2, 5, 4, 7, 6)));\n        max_lengths = _mm256_max_epi32(max_lengths, _mm256_permutevar8x32_epi32(max_lengths, _mm256_setr_epi32(2, 3, 0, 1, 6, 7, 4, 5)));\n        max_lengths = _mm256_max_epi32(max_lengths, _mm256_permutevar8x32_epi32(max_lengths, _mm256_setr_epi32(4, 5, 6, 7, 0, 1, 2, 3)));\n\n        int max_in_batch = _mm256_extract_epi32(max_lengths, 0);\n\n        if (max_in_batch > max_length) {\n            max_length = max_in_batch;\n            max_index = local_max_index;\n        }\n    }\n\n    return strings[max_index];\n}\n```"}
{"task_id": "SimdBench_69_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n#include <algorithm>\n\nstd::string longest_simd(const std::vector<std::string> & strings){\n    if (strings.empty()) {\n        return \"\";\n    }\n\n    const int numStrings = strings.size();\n    const int simdWidth = 8; // AVX2 processes 256 bits, which can hold 8 x 32-bit integers\n    int maxLengths[simdWidth] = {0};\n    int maxIndices[simdWidth] = {0};\n    int globalMaxLength = 0;\n    int globalMaxIndex = 0;\n\n    __m256i maxLengthVec = _mm256_setzero_si256();\n    __m256i maxIndexVec = _mm256_setzero_si256();\n\n    for (int i = 0; i < numStrings; i += simdWidth) {\n        __m256i lengthVec = _mm256_setzero_si256();\n        __m256i indexVec = _mm256_set_epi32(\n            i + 7, i + 6, i + 5, i + 4, i + 3, i + 2, i + 1, i\n        );\n\n        for (int j = 0; j < simdWidth && (i + j) < numStrings; ++j) {\n            int len = strings[i + j].length();\n            maxLengths[j] = len;\n            maxIndices[j] = i + j;\n            lengthVec = _mm256_insert_epi32(lengthVec, len, j);\n        }\n\n        __m256i cmpMask = _mm256_cmpgt_epi32(lengthVec, maxLengthVec);\n        maxLengthVec = _mm256_max_epi32(lengthVec, maxLengthVec);\n        maxIndexVec = _mm256_blendv_epi8(maxIndexVec, indexVec, cmpMask);\n\n        if ((i + simdWidth) >= numStrings) {\n            _mm256_storeu_si256(reinterpret_cast<__m256i*>(maxLengths), maxLengthVec);\n            _mm256_storeu_si256(reinterpret_cast<__m256i*>(maxIndices), maxIndexVec);\n\n            for (int j = 0; j < simdWidth && (i + j) < numStrings; ++j) {\n                if (maxLengths[j] > globalMaxLength) {\n                    globalMaxLength = maxLengths[j];\n                    globalMaxIndex = maxIndices[j];\n                }\n            }\n        }\n    }\n\n    return strings[globalMaxIndex];\n}\n```"}
{"task_id": "SimdBench_69_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n#include <algorithm>\n\nstd::string longest_simd(const std::vector<std::string> & strings){\n    if (strings.empty()) {\n        return \"\";\n    }\n\n    const int numStrings = strings.size();\n    const int simdWidth = 8; // AVX2 processes 256 bits, which can hold 8 x 32-bit integers\n    int maxLengths[simdWidth] = {0};\n    int maxIndices[simdWidth] = {0};\n    int overallMaxLength = 0;\n    int overallMaxIndex = 0;\n\n    __m256i maxLengthVec = _mm256_setzero_si256();\n    __m256i maxIndexVec = _mm256_setzero_si256();\n\n    for (int i = 0; i < numStrings; i += simdWidth) {\n        __m256i lengthVec = _mm256_setzero_si256();\n        __m256i indexVec = _mm256_set_epi32(i + 7, i + 6, i + 5, i + 4, i + 3, i + 2, i + 1, i);\n\n        for (int j = 0; j < simdWidth && i + j < numStrings; ++j) {\n            int len = strings[i + j].length();\n            maxLengths[j] = len;\n            maxIndices[j] = i + j;\n            lengthVec = _mm256_insert_epi32(lengthVec, len, j);\n        }\n\n        __m256i cmpMask = _mm256_cmpgt_epi32(lengthVec, maxLengthVec);\n        maxLengthVec = _mm256_max_epi32(lengthVec, maxLengthVec);\n        maxIndexVec = _mm256_blendv_epi8(maxIndexVec, indexVec, cmpMask);\n    }\n\n    _mm256_storeu_si256(reinterpret_cast<__m256i*>(maxLengths), maxLengthVec);\n    _mm256_storeu_si256(reinterpret_cast<__m256i*>(maxIndices), maxIndexVec);\n\n    for (int i = 0; i < simdWidth; ++i) {\n        if (maxLengths[i] > overallMaxLength) {\n            overallMaxLength = maxLengths[i];\n            overallMaxIndex = maxIndices[i];\n        }\n    }\n\n    return strings[overallMaxIndex];\n}\n```"}
{"task_id": "SimdBench_69_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n#include <algorithm>\n\nstd::string longest_simd(const std::vector<std::string> & strings){\n    if (strings.empty()) {\n        return \"\";\n    }\n\n    const int numStrings = strings.size();\n    const int simdWidth = 8; // AVX2 processes 256 bits, which can hold 8 x 32-bit integers\n    int maxLengths[simdWidth] = {0};\n    int maxIndices[simdWidth] = {0};\n    int globalMaxLength = 0;\n    int globalMaxIndex = 0;\n\n    __m256i maxLengthVec = _mm256_setzero_si256();\n    __m256i maxIndexVec = _mm256_setzero_si256();\n\n    for (int i = 0; i < numStrings; i += simdWidth) {\n        __m256i lengthVec = _mm256_setzero_si256();\n        __m256i indexVec = _mm256_set_epi32(\n            i + 7, i + 6, i + 5, i + 4, i + 3, i + 2, i + 1, i\n        );\n\n        for (int j = 0; j < simdWidth && (i + j) < numStrings; ++j) {\n            int len = strings[i + j].length();\n            maxLengths[j] = len;\n            maxIndices[j] = i + j;\n            lengthVec = _mm256_insert_epi32(lengthVec, len, j);\n        }\n\n        __m256i cmpMask = _mm256_cmpgt_epi32(lengthVec, maxLengthVec);\n        maxLengthVec = _mm256_max_epi32(lengthVec, maxLengthVec);\n        maxIndexVec = _mm256_blendv_epi8(maxIndexVec, indexVec, cmpMask);\n\n        if ((i + simdWidth) >= numStrings) {\n            _mm256_storeu_si256(reinterpret_cast<__m256i*>(maxLengths), maxLengthVec);\n            _mm256_storeu_si256(reinterpret_cast<__m256i*>(maxIndices), maxIndexVec);\n\n            for (int j = 0; j < simdWidth && (i + j) < numStrings; ++j) {\n                if (maxLengths[j] > globalMaxLength) {\n                    globalMaxLength = maxLengths[j];\n                    globalMaxIndex = maxIndices[j];\n                }\n            }\n        }\n    }\n\n    return strings[globalMaxIndex];\n}\n```"}
{"task_id": "SimdBench_70_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nuint64_t greatest_common_divisor_simd(uint64_t a, uint64_t b) {\n    __m256i va = _mm256_set1_epi64x(a);\n    __m256i vb = _mm256_set1_epi64x(b);\n    __m256i zero = _mm256_setzero_si256();\n\n    while (_mm256_movemask_epi8(_mm256_or_si256(va, vb)) != 0) {\n        __m256i even_mask = _mm256_and_si256(va, _mm256_set1_epi64x(1));\n        __m256i odd_mask = _mm256_andnot_si256(even_mask, _mm256_set1_epi64x(-1));\n\n        va = _mm256_blendv_epi8(_mm256_srli_epi64(va, 1), va, odd_mask);\n        vb = _mm256_blendv_epi8(_mm256_srli_epi64(vb, 1), vb, odd_mask);\n\n        __m256i gt_mask = _mm256_cmpgt_epi64(va, vb);\n        va = _mm256_blendv_epi8(va, vb, gt_mask);\n        vb = _mm256_sub_epi64(va, vb);\n        vb = _mm256_andnot_si256(gt_mask, vb);\n    }\n\n    return _mm256_extract_epi64(va, 0);\n}\n```"}
{"task_id": "SimdBench_70_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nuint64_t greatest_common_divisor_simd(uint64_t a, uint64_t b) {\n    __m256i vec_a = _mm256_set1_epi64x(a);\n    __m256i vec_b = _mm256_set1_epi64x(b);\n    __m256i zero = _mm256_setzero_si256();\n\n    while (_mm256_movemask_epi8(_mm256_or_si256(vec_a, vec_b)) != 0) {\n        __m256i even_mask = _mm256_and_si256(vec_a, _mm256_set1_epi64x(1));\n        __m256i odd_mask = _mm256_andnot_si256(even_mask, _mm256_set1_epi64x(-1));\n\n        vec_a = _mm256_blendv_epi8(_mm256_srli_epi64(vec_a, 1), vec_a, odd_mask);\n        vec_b = _mm256_blendv_epi8(_mm256_srli_epi64(vec_b, 1), vec_b, odd_mask);\n\n        __m256i gt_mask = _mm256_cmpgt_epi64(vec_a, vec_b);\n        vec_a = _mm256_blendv_epi8(vec_a, vec_b, gt_mask);\n        vec_b = _mm256_sub_epi64(vec_a, _mm256_and_si256(vec_b, gt_mask));\n    }\n\n    return _mm256_extract_epi64(vec_a, 0);\n}\n```"}
{"task_id": "SimdBench_70_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nuint64_t greatest_common_divisor_simd(uint64_t a, uint64_t b){\n    __m256i va = _mm256_set1_epi64x(a);\n    __m256i vb = _mm256_set1_epi64x(b);\n    __m256i zero = _mm256_setzero_si256();\n    __m256i one = _mm256_set1_epi64x(1);\n\n    while (_mm256_testz_si256(vb, vb) == 0) {\n        __m256i temp = vb;\n        vb = _mm256_and_si256(_mm256_sub_epi64(va, vb), _mm256_cmpgt_epi64(va, vb));\n        va = _mm256_or_si256(temp, _mm256_andnot_si256(_mm256_cmpgt_epi64(va, vb), va));\n    }\n\n    return _mm256_extract_epi64(va, 0);\n}\n```"}
{"task_id": "SimdBench_70_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nuint64_t greatest_common_divisor_simd(uint64_t a, uint64_t b) {\n    __m256i va = _mm256_set1_epi64x(a);\n    __m256i vb = _mm256_set1_epi64x(b);\n    __m256i zero = _mm256_setzero_si256();\n\n    while (_mm256_movemask_epi8(_mm256_or_si256(va, vb)) != 0) {\n        __m256i even_mask = _mm256_and_si256(va, _mm256_set1_epi64x(1));\n        __m256i odd_mask = _mm256_andnot_si256(even_mask, _mm256_set1_epi64x(-1));\n\n        va = _mm256_blendv_epi8(_mm256_srli_epi64(va, 1), va, odd_mask);\n        vb = _mm256_blendv_epi8(_mm256_srli_epi64(vb, 1), vb, odd_mask);\n\n        __m256i gt_mask = _mm256_cmpgt_epi64(va, vb);\n        __m256i sub_result = _mm256_sub_epi64(va, vb);\n\n        va = _mm256_blendv_epi8(vb, va, gt_mask);\n        vb = _mm256_blendv_epi8(sub_result, vb, gt_mask);\n    }\n\n    return _mm256_extract_epi64(va, 0);\n}\n```"}
{"task_id": "SimdBench_70_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nuint64_t greatest_common_divisor_simd(uint64_t a, uint64_t b) {\n    __m256i va = _mm256_set1_epi64x(a);\n    __m256i vb = _mm256_set1_epi64x(b);\n    __m256i zero = _mm256_setzero_si256();\n\n    while (_mm256_movemask_epi8(_mm256_or_si256(va, vb)) != 0) {\n        __m256i even_mask = _mm256_and_si256(va, _mm256_set1_epi64x(1));\n        __m256i odd_mask = _mm256_andnot_si256(even_mask, _mm256_set1_epi64x(-1));\n\n        va = _mm256_blendv_epi8(_mm256_srli_epi64(va, 1), va, odd_mask);\n        vb = _mm256_blendv_epi8(_mm256_srli_epi64(vb, 1), vb, odd_mask);\n\n        __m256i gt_mask = _mm256_cmpgt_epi64(va, vb);\n        __m256i sub_result = _mm256_sub_epi64(va, vb);\n\n        va = _mm256_blendv_epi8(vb, va, gt_mask);\n        vb = _mm256_blendv_epi8(zero, sub_result, gt_mask);\n    }\n\n    return _mm256_extract_epi64(va, 0);\n}\n```"}
{"task_id": "SimdBench_71_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n#include <cmath>\n#include <limits>\n\nstd::vector<float> find_closest_elements_simd(std::vector<float> numbers) {\n    float min_diff = std::numeric_limits<float>::max();\n    __m256 min_pair = _mm256_setzero_ps();\n    int n = numbers.size();\n\n    for (int i = 0; i < n - 8; i += 8) {\n        __m256 vec1 = _mm256_loadu_ps(&numbers[i]);\n        for (int j = i + 8; j < n; j += 8) {\n            __m256 vec2 = _mm256_loadu_ps(&numbers[j]);\n            __m256 diff1 = _mm256_sub_ps(vec1, vec2);\n            __m256 diff2 = _mm256_sub_ps(vec2, vec1);\n            __m256 abs_diff = _mm256_min_ps(diff1, diff2);\n            __m256 mask = _mm256_cmp_ps(abs_diff, _mm256_set1_ps(min_diff), _CMP_LT_OS);\n            if (_mm256_movemask_epi8(mask) != 0) {\n                for (int k = 0; k < 8; ++k) {\n                    float d = std::abs(numbers[i + k] - numbers[j]);\n                    if (d < min_diff) {\n                        min_diff = d;\n                        min_pair = _mm256_set_ps(numbers[j + 7], numbers[j + 6], numbers[j + 5], numbers[j + 4],\n                                                 numbers[j + 3], numbers[j + 2], numbers[j + 1], numbers[j]);\n                        min_pair = _mm256_blendv_ps(min_pair, _mm256_set_ps(numbers[i + 7], numbers[i + 6], numbers[i + 5], numbers[i + 4],\n                                                                             numbers[i + 3], numbers[i + 2], numbers[i + 1], numbers[i]), mask);\n                    }\n                }\n            }\n        }\n    }\n\n    // Handle remaining elements\n    for (int i = n / 8 * 8; i < n - 1; ++i) {\n        for (int j = i + 1; j < n; ++j) {\n            float d = std::abs(numbers[i] - numbers[j]);\n            if (d < min_diff) {\n                min_diff = d;\n                min_pair = _mm256_set_ps(numbers[j], numbers[i], 0, 0, 0, 0, 0, 0);\n            }\n        }\n    }\n\n    float result[8];\n    _mm256_storeu_ps(result, min_pair);\n    return {result[7], result[6]};\n}\n```"}
{"task_id": "SimdBench_71_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n#include <cmath>\n#include <limits>\n\nstd::vector<float> find_closest_elements_simd(std::vector<float> numbers) {\n    float min_diff = std::numeric_limits<float>::max();\n    __m256 min_pair = _mm256_setzero_ps();\n    int n = numbers.size();\n\n    for (int i = 0; i < n - 8; i += 8) {\n        __m256 vec1 = _mm256_loadu_ps(&numbers[i]);\n        for (int j = i + 8; j < n; j += 8) {\n            __m256 vec2 = _mm256_loadu_ps(&numbers[j]);\n            __m256 diff1 = _mm256_sub_ps(vec1, vec2);\n            __m256 diff2 = _mm256_sub_ps(vec2, vec1);\n            __m256 abs_diff = _mm256_min_ps(diff1, diff2);\n            __m256 mask = _mm256_cmp_ps(abs_diff, _mm256_set1_ps(min_diff), _CMP_LT_OS);\n            if (_mm256_movemask_epi8(mask) != 0) {\n                min_diff = _mm256_cvtss_f32(_mm256_min_ps(abs_diff, _mm256_set1_ps(min_diff)));\n                for (int k = 0; k < 8; ++k) {\n                    for (int l = 0; l < 8; ++l) {\n                        float a = numbers[i + k];\n                        float b = numbers[j + l];\n                        float diff = std::fabs(a - b);\n                        if (diff == min_diff) {\n                            min_pair = _mm256_set_ps(0, 0, 0, 0, 0, 0, std::fmin(a, b), std::fmax(a, b));\n                        }\n                    }\n                }\n            }\n        }\n    }\n\n    float result[8];\n    _mm256_storeu_ps(result, min_pair);\n    return {result[6], result[7]};\n}\n```"}
{"task_id": "SimdBench_71_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n#include <cmath>\n#include <limits>\n\nstd::vector<float> find_closest_elements_simd(std::vector<float> numbers) {\n    float min_diff = std::numeric_limits<float>::max();\n    __m256 min_pair = _mm256_setzero_ps();\n    int n = numbers.size();\n\n    for (int i = 0; i < n - 8; i += 8) {\n        __m256 vec1 = _mm256_loadu_ps(&numbers[i]);\n        for (int j = i + 8; j < n; j += 8) {\n            __m256 vec2 = _mm256_loadu_ps(&numbers[j]);\n            __m256 diff1 = _mm256_sub_ps(vec1, vec2);\n            __m256 diff2 = _mm256_sub_ps(vec2, vec1);\n            __m256 abs_diff = _mm256_min_ps(diff1, diff2);\n            __m256 mask = _mm256_cmp_ps(abs_diff, _mm256_set1_ps(min_diff), _CMP_LT_OS);\n            if (_mm256_movemask_epi8(mask) != 0) {\n                min_diff = _mm256_cvtss_f32(_mm256_min_ps(abs_diff, _mm256_set1_ps(min_diff)));\n                __m256 min_vec = _mm256_blendv_ps(vec1, vec2, mask);\n                __m256 max_vec = _mm256_blendv_ps(vec2, vec1, mask);\n                min_pair = _mm256_min_ps(min_pair, min_vec);\n                min_pair = _mm256_max_ps(min_pair, max_vec);\n            }\n        }\n    }\n\n    float result[8];\n    _mm256_storeu_ps(result, min_pair);\n\n    float min_val = std::numeric_limits<float>::max();\n    float max_val = std::numeric_limits<float>::lowest();\n    for (int i = 0; i < 8; i++) {\n        if (result[i] < min_val && result[i] > 0) min_val = result[i];\n        if (result[i] > max_val) max_val = result[i];\n    }\n\n    return {min_val, max_val};\n}\n```"}
{"task_id": "SimdBench_71_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n#include <cmath>\n#include <limits>\n\nstd::vector<float> find_closest_elements_simd(std::vector<float> numbers) {\n    float min_diff = std::numeric_limits<float>::max();\n    __m256 min_pair = _mm256_setzero_ps();\n    int n = numbers.size();\n\n    for (int i = 0; i < n - 8; i += 8) {\n        __m256 vec1 = _mm256_loadu_ps(&numbers[i]);\n        for (int j = i + 8; j < n; j += 8) {\n            __m256 vec2 = _mm256_loadu_ps(&numbers[j]);\n            __m256 diff1 = _mm256_sub_ps(vec1, vec2);\n            __m256 diff2 = _mm256_sub_ps(vec2, vec1);\n            __m256 abs_diff = _mm256_min_ps(diff1, diff2);\n            __m256 mask = _mm256_cmp_ps(abs_diff, _mm256_set1_ps(min_diff), _CMP_LT_OS);\n            if (_mm256_movemask_epi8(mask) != 0) {\n                min_diff = _mm256_cvtss_f32(_mm256_min_ps(abs_diff, _mm256_set1_ps(min_diff)));\n                for (int k = 0; k < 8; ++k) {\n                    for (int l = 0; l < 8; ++l) {\n                        float a = numbers[i + k];\n                        float b = numbers[j + l];\n                        if (std::fabs(a - b) == min_diff) {\n                            min_pair = _mm256_set_ps(0, 0, 0, 0, 0, 0, std::max(a, b), std::min(a, b));\n                        }\n                    }\n                }\n            }\n        }\n    }\n\n    // Handle remaining elements\n    for (int i = n / 8 * 8; i < n - 1; ++i) {\n        for (int j = i + 1; j < n; ++j) {\n            float diff = std::fabs(numbers[i] - numbers[j]);\n            if (diff < min_diff) {\n                min_diff = diff;\n                min_pair = _mm256_set_ps(0, 0, 0, 0, 0, 0, std::max(numbers[i], numbers[j]), std::min(numbers[i], numbers[j]));\n            }\n        }\n    }\n\n    float result[8];\n    _mm256_storeu_ps(result, min_pair);\n    return {result[7], result[6]};\n}\n```"}
{"task_id": "SimdBench_71_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <cmath>\n#include <limits>\n\nstd::vector<float> find_closest_elements_simd(std::vector<float> numbers) {\n    float min_diff = std::numeric_limits<float>::max();\n    __m256 min_pair = _mm256_setzero_ps();\n    int n = numbers.size();\n\n    for (int i = 0; i < n - 8; i += 8) {\n        __m256 vec1 = _mm256_loadu_ps(&numbers[i]);\n        for (int j = i + 8; j < n; j += 8) {\n            __m256 vec2 = _mm256_loadu_ps(&numbers[j]);\n            __m256 diff1 = _mm256_sub_ps(vec1, vec2);\n            __m256 diff2 = _mm256_sub_ps(vec2, vec1);\n            __m256 abs_diff = _mm256_min_ps(diff1, diff2);\n            __m256 mask = _mm256_cmp_ps(abs_diff, _mm256_set1_ps(min_diff), _CMP_LT_OS);\n            if (_mm256_movemask_epi8(mask) != 0) {\n                min_diff = _mm256_cvtss_f32(_mm256_min_ps(abs_diff, _mm256_set1_ps(min_diff)));\n                for (int k = 0; k < 8; ++k) {\n                    for (int l = 0; l < 8; ++l) {\n                        float a = numbers[i + k];\n                        float b = numbers[j + l];\n                        float diff = std::fabs(a - b);\n                        if (diff == min_diff) {\n                            min_pair = _mm256_set_ps(0, 0, 0, 0, 0, 0, std::fmin(a, b), std::fmax(a, b));\n                        }\n                    }\n                }\n            }\n        }\n    }\n\n    float result[8];\n    _mm256_storeu_ps(result, min_pair);\n    return {result[6], result[7]};\n}\n```"}
{"task_id": "SimdBench_72_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<float> rescale_to_unit_simd(std::vector<float> numbers) {\n    if (numbers.size() < 2) return numbers;\n\n    float* data = numbers.data();\n    size_t n = numbers.size();\n\n    // Find min and max using SIMD\n    __m256 v_min = _mm256_set1_ps(data[0]);\n    __m256 v_max = _mm256_set1_ps(data[0]);\n\n    for (size_t i = 0; i <= n - 8; i += 8) {\n        __m256 v = _mm256_loadu_ps(&data[i]);\n        v_min = _mm256_min_ps(v_min, v);\n        v_max = _mm256_max_ps(v_max, v);\n    }\n\n    float min_vals[8], max_vals[8];\n    _mm256_storeu_ps(min_vals, v_min);\n    _mm256_storeu_ps(max_vals, v_max);\n\n    float min_val = *std::min_element(min_vals, min_vals + 8);\n    float max_val = *std::max_element(max_vals, max_vals + 8);\n\n    for (size_t i = (n / 8) * 8; i < n; ++i) {\n        min_val = std::min(min_val, data[i]);\n        max_val = std::max(max_val, data[i]);\n    }\n\n    float range = max_val - min_val;\n    if (range == 0.0f) return numbers; // Avoid division by zero\n\n    __m256 v_range = _mm256_set1_ps(range);\n    __m256 v_min_val = _mm256_set1_ps(min_val);\n\n    for (size_t i = 0; i <= n - 8; i += 8) {\n        __m256 v = _mm256_loadu_ps(&data[i]);\n        v = _mm256_sub_ps(v, v_min_val);\n        v = _mm256_div_ps(v, v_range);\n        _mm256_storeu_ps(&data[i], v);\n    }\n\n    for (size_t i = (n / 8) * 8; i < n; ++i) {\n        data[i] = (data[i] - min_val) / range;\n    }\n\n    return numbers;\n}\n```"}
{"task_id": "SimdBench_72_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n#include <limits>\n\nstd::vector<float> rescale_to_unit_simd(std::vector<float> numbers) {\n    if (numbers.size() < 2) return numbers;\n\n    float min_val = std::numeric_limits<float>::max();\n    float max_val = std::numeric_limits<float>::lowest();\n\n    // Find min and max values using SIMD\n    __m256 v_min = _mm256_set1_ps(min_val);\n    __m256 v_max = _mm256_set1_ps(max_val);\n\n    size_t i = 0;\n    for (; i <= numbers.size() - 8; i += 8) {\n        __m256 v = _mm256_loadu_ps(&numbers[i]);\n        v_min = _mm256_min_ps(v_min, v);\n        v_max = _mm256_max_ps(v_max, v);\n    }\n\n    // Reduce min and max values\n    __m128 v_min_lo = _mm256_castps256_ps128(v_min);\n    __m128 v_min_hi = _mm256_extractf128_ps(v_min, 1);\n    __m128 v_max_lo = _mm256_castps256_ps128(v_max);\n    __m128 v_max_hi = _mm256_extractf128_ps(v_max, 1);\n\n    v_min_lo = _mm_min_ps(v_min_lo, v_min_hi);\n    v_max_lo = _mm_max_ps(v_max_lo, v_max_hi);\n\n    v_min_lo = _mm_min_ps(v_min_lo, _mm_shuffle_ps(v_min_lo, v_min_lo, _MM_SHUFFLE(1, 0, 3, 2)));\n    v_max_lo = _mm_max_ps(v_max_lo, _mm_shuffle_ps(v_max_lo, v_max_lo, _MM_SHUFFLE(1, 0, 3, 2)));\n\n    v_min_lo = _mm_min_ps(v_min_lo, _mm_shuffle_ps(v_min_lo, v_min_lo, _MM_SHUFFLE(2, 3, 0, 1)));\n    v_max_lo = _mm_max_ps(v_max_lo, _mm_shuffle_ps(v_max_lo, v_max_lo, _MM_SHUFFLE(2, 3, 0, 1)));\n\n    _mm_store_ss(&min_val, v_min_lo);\n    _mm_store_ss(&max_val, v_max_lo);\n\n    // Continue with scalar for remaining elements\n    for (; i < numbers.size(); ++i) {\n        min_val = std::min(min_val, numbers[i]);\n        max_val = std::max(max_val, numbers[i]);\n    }\n\n    float range = max_val - min_val;\n    if (range == 0.0f) return std::vector<float>(numbers.size(), 0.0f);\n\n    __m256 v_range = _mm256_set1_ps(range);\n    __m256 v_min_val = _mm256_set1_ps(min_val);\n\n    i = 0;\n    for (; i <= numbers.size() - 8; i += 8) {\n        __m256 v = _mm256_loadu_ps(&numbers[i]);\n        v = _mm256_sub_ps(v, v_min_val);\n        v = _mm256_div_ps(v, v_range);\n        _mm256_storeu_ps(&numbers[i], v);\n    }\n\n    for (; i < numbers.size(); ++i) {\n        numbers[i] = (numbers[i] - min_val) / range;\n    }\n\n    return numbers;\n}\n```"}
{"task_id": "SimdBench_72_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<float> rescale_to_unit_simd(std::vector<float> numbers) {\n    if (numbers.size() < 2) return numbers;\n\n    float* data = numbers.data();\n    size_t n = numbers.size();\n\n    // Find min and max using SIMD\n    __m256 v_min = _mm256_set1_ps(data[0]);\n    __m256 v_max = _mm256_set1_ps(data[0]);\n\n    for (size_t i = 0; i <= n - 8; i += 8) {\n        __m256 v = _mm256_loadu_ps(&data[i]);\n        v_min = _mm256_min_ps(v_min, v);\n        v_max = _mm256_max_ps(v_max, v);\n    }\n\n    float min_vals[8], max_vals[8];\n    _mm256_storeu_ps(min_vals, v_min);\n    _mm256_storeu_ps(max_vals, v_max);\n\n    float min_val = *std::min_element(min_vals, min_vals + 8);\n    float max_val = *std::max_element(max_vals, max_vals + 8);\n\n    for (size_t i = (n / 8) * 8; i < n; ++i) {\n        min_val = std::min(min_val, data[i]);\n        max_val = std::max(max_val, data[i]);\n    }\n\n    float range = max_val - min_val;\n    if (range == 0.0f) return std::vector<float>(n, 0.0f);\n\n    __m256 v_range = _mm256_set1_ps(range);\n    __m256 v_min_val = _mm256_set1_ps(min_val);\n\n    for (size_t i = 0; i <= n - 8; i += 8) {\n        __m256 v = _mm256_loadu_ps(&data[i]);\n        v = _mm256_sub_ps(v, v_min_val);\n        v = _mm256_div_ps(v, v_range);\n        _mm256_storeu_ps(&data[i], v);\n    }\n\n    for (size_t i = (n / 8) * 8; i < n; ++i) {\n        data[i] = (data[i] - min_val) / range;\n    }\n\n    return numbers;\n}\n```"}
{"task_id": "SimdBench_72_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n#include <limits>\n\nstd::vector<float> rescale_to_unit_simd(std::vector<float> numbers) {\n    if (numbers.size() < 2) return numbers;\n\n    float min_val = std::numeric_limits<float>::max();\n    float max_val = std::numeric_limits<float>::lowest();\n\n    // Find min and max values using SIMD\n    __m256 v_min = _mm256_set1_ps(min_val);\n    __m256 v_max = _mm256_set1_ps(max_val);\n\n    size_t i = 0;\n    for (; i <= numbers.size() - 8; i += 8) {\n        __m256 v = _mm256_loadu_ps(&numbers[i]);\n        v_min = _mm256_min_ps(v_min, v);\n        v_max = _mm256_max_ps(v_max, v);\n    }\n\n    float min_vals[8], max_vals[8];\n    _mm256_storeu_ps(min_vals, v_min);\n    _mm256_storeu_ps(max_vals, v_max);\n\n    for (size_t j = 0; j < 8; ++j) {\n        min_val = std::min(min_val, min_vals[j]);\n        max_val = std::max(max_val, max_vals[j]);\n    }\n\n    for (; i < numbers.size(); ++i) {\n        min_val = std::min(min_val, numbers[i]);\n        max_val = std::max(max_val, numbers[i]);\n    }\n\n    float scale = 1.0f / (max_val - min_val);\n\n    // Rescale numbers using SIMD\n    __m256 v_scale = _mm256_set1_ps(scale);\n    __m256 v_min_val = _mm256_set1_ps(min_val);\n\n    for (i = 0; i <= numbers.size() - 8; i += 8) {\n        __m256 v = _mm256_loadu_ps(&numbers[i]);\n        v = _mm256_sub_ps(v, v_min_val);\n        v = _mm256_mul_ps(v, v_scale);\n        _mm256_storeu_ps(&numbers[i], v);\n    }\n\n    for (; i < numbers.size(); ++i) {\n        numbers[i] = (numbers[i] - min_val) * scale;\n    }\n\n    return numbers;\n}\n```"}
{"task_id": "SimdBench_72_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<float> rescale_to_unit_simd(std::vector<float> numbers) {\n    if (numbers.size() < 2) return numbers;\n\n    float* data = numbers.data();\n    size_t size = numbers.size();\n\n    __m256 min_val = _mm256_set1_ps(data[0]);\n    __m256 max_val = _mm256_set1_ps(data[0]);\n\n    for (size_t i = 0; i <= size - 8; i += 8) {\n        __m256 vec = _mm256_loadu_ps(&data[i]);\n        min_val = _mm256_min_ps(min_val, vec);\n        max_val = _mm256_max_ps(max_val, vec);\n    }\n\n    float min_arr[8], max_arr[8];\n    _mm256_storeu_ps(min_arr, min_val);\n    _mm256_storeu_ps(max_arr, max_val);\n\n    float min_scalar = *std::min_element(min_arr, min_arr + 8);\n    float max_scalar = *std::max_element(max_arr, max_arr + 8);\n\n    for (size_t i = size - size % 8; i < size; ++i) {\n        min_scalar = std::min(min_scalar, data[i]);\n        max_scalar = std::max(max_scalar, data[i]);\n    }\n\n    float range = max_scalar - min_scalar;\n    __m256 scale = _mm256_set1_ps(1.0f / range);\n    __m256 offset = _mm256_set1_ps(-min_scalar / range);\n\n    for (size_t i = 0; i <= size - 8; i += 8) {\n        __m256 vec = _mm256_loadu_ps(&data[i]);\n        vec = _mm256_sub_ps(vec, _mm256_set1_ps(min_scalar));\n        vec = _mm256_div_ps(vec, _mm256_set1_ps(range));\n        _mm256_storeu_ps(&data[i], vec);\n    }\n\n    for (size_t i = size - size % 8; i < size; ++i) {\n        data[i] = (data[i] - min_scalar) / range;\n    }\n\n    return numbers;\n}\n```"}
{"task_id": "SimdBench_73_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nuint64_t largest_divisor_simd(uint64_t n) {\n    __m256i vec_n = _mm256_set1_epi64x(n);\n    __m256i vec_divisors = _mm256_sub_epi64(vec_n, _mm256_setr_epi64x(1, 2, 3, 4));\n    __m256i vec_zero = _mm256_setzero_si256();\n    __m256i vec_ones = _mm256_cmpgt_epi64(_mm256_set1_epi64x(0), vec_zero);\n    __m256i vec_results = vec_zero;\n\n    for (uint64_t i = 5; i <= n / 2; i += 4) {\n        vec_divisors = _mm256_add_epi64(vec_divisors, vec_ones);\n        __m256i vec_remainders = _mm256_rem_epu64(vec_n, vec_divisors);\n        __m256i vec_mask = _mm256_cmpeq_epi64(vec_remainders, vec_zero);\n        vec_results = _mm256_blendv_epi8(vec_results, vec_divisors, vec_mask);\n    }\n\n    uint64_t results[4];\n    _mm256_storeu_si256((__m256i*)results, vec_results);\n\n    uint64_t max_result = 0;\n    for (int i = 0; i < 4; ++i) {\n        if (results[i] > max_result && results[i] < n) {\n            max_result = results[i];\n        }\n    }\n\n    return max_result;\n}\n```"}
{"task_id": "SimdBench_73_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nuint64_t largest_divisor_simd(uint64_t n) {\n    __m256i vec_n = _mm256_set1_epi64x(n);\n    __m256i vec_divisors = _mm256_sub_epi64(vec_n, _mm256_setr_epi64x(1, 2, 3, 4));\n    __m256i vec_zero = _mm256_setzero_si256();\n    __m256i vec_ones = _mm256_cmpgt_epi64(_mm256_set1_epi64x(0), vec_zero);\n    __m256i vec_results = vec_zero;\n\n    for (uint64_t i = 5; i <= n / 2; i += 4) {\n        vec_divisors = _mm256_add_epi64(vec_divisors, vec_ones);\n        __m256i vec_remainders = _mm256_rem_epu64(vec_n, vec_divisors);\n        __m256i vec_mask = _mm256_cmpeq_epi64(vec_remainders, vec_zero);\n        vec_results = _mm256_blendv_epi8(vec_results, vec_divisors, vec_mask);\n    }\n\n    uint64_t results[4];\n    _mm256_storeu_si256((__m256i*)results, vec_results);\n\n    uint64_t largest_divisor = 0;\n    for (int i = 0; i < 4; ++i) {\n        if (results[i] < n && results[i] > largest_divisor) {\n            largest_divisor = results[i];\n        }\n    }\n\n    return largest_divisor;\n}\n```"}
{"task_id": "SimdBench_73_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nuint64_t largest_divisor_simd(uint64_t n) {\n    __m256i vec_n = _mm256_set1_epi64x(n);\n    __m256i vec_i = _mm256_setr_epi64x(n-1, n-2, n-3, n-4);\n    __m256i zero = _mm256_setzero_si256();\n    __m256i result = zero;\n\n    while (_mm256_movemask_epi8(_mm256_cmpgt_epi64(vec_i, zero)) != 0) {\n        __m256i remainder = _mm256_rem_epu64(vec_n, vec_i);\n        __m256i mask = _mm256_cmpeq_epi64(remainder, zero);\n        result = _mm256_blendv_epi8(result, vec_i, mask);\n        vec_i = _mm256_sub_epi64(vec_i, _mm256_set1_epi64x(4));\n    }\n\n    uint64_t results[4];\n    _mm256_storeu_si256((__m256i*)results, result);\n\n    for (int i = 0; i < 4; ++i) {\n        if (results[i] != 0) {\n            return results[i];\n        }\n    }\n\n    return 1; // Fallback, should not happen for n > 1\n}\n```"}
{"task_id": "SimdBench_73_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nuint64_t largest_divisor_simd(uint64_t n) {\n    __m256i vec_n = _mm256_set1_epi64x(n);\n    __m256i vec_i = _mm256_setr_epi64x(n-1, n-2, n-3, n-4);\n    __m256i zero = _mm256_setzero_si256();\n    __m256i result = zero;\n\n    while (_mm256_movemask_epi8(_mm256_cmpgt_epi64(vec_i, zero)) != 0) {\n        __m256i remainder = _mm256_rem_epu64(vec_n, vec_i);\n        __m256i is_divisor = _mm256_cmpeq_epi64(remainder, zero);\n        result = _mm256_blendv_epi8(result, vec_i, is_divisor);\n\n        vec_i = _mm256_sub_epi64(vec_i, _mm256_set1_epi64x(4));\n    }\n\n    uint64_t divisors[4];\n    _mm256_storeu_si256((__m256i*)divisors, result);\n\n    for (int i = 3; i >= 0; --i) {\n        if (divisors[i] != 0) {\n            return divisors[i];\n        }\n    }\n\n    return 0;\n}\n```"}
{"task_id": "SimdBench_73_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nuint64_t largest_divisor_simd(uint64_t n) {\n    __m256i vec_n = _mm256_set1_epi64x(n);\n    __m256i vec_i = _mm256_setr_epi64x(n-1, n-2, n-3, n-4);\n    __m256i zero = _mm256_setzero_si256();\n    __m256i result = zero;\n\n    while (_mm256_movemask_epi8(_mm256_cmpgt_epi64(vec_i, zero))) {\n        __m256i remainder = _mm256_rem_epu64(vec_n, vec_i);\n        __m256i mask = _mm256_cmpeq_epi64(remainder, zero);\n        result = _mm256_blendv_epi8(result, vec_i, mask);\n        vec_i = _mm256_sub_epi64(vec_i, _mm256_set1_epi64x(4));\n    }\n\n    uint64_t results[4];\n    _mm256_storeu_si256((__m256i*)results, result);\n\n    for (int i = 0; i < 4; ++i) {\n        if (results[i] != 0) {\n            return results[i];\n        }\n    }\n\n    return 1; // Fallback, should not happen for n > 1\n}\n```"}
{"task_id": "SimdBench_74_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> factorize_simd(int n) {\n    std::vector<int> factors;\n    __m256i divisor = _mm256_set1_epi32(2);\n    __m256i zero = _mm256_setzero_si256();\n    __m256i one = _mm256_set1_epi32(1);\n\n    while (n > 1) {\n        __m256i num = _mm256_set1_epi32(n);\n        __m256i remainder = _mm256_rem_epi32(num, divisor);\n        __m256i mask = _mm256_cmpeq_epi32(remainder, zero);\n\n        if (_mm256_movemask_epi8(mask) != 0) {\n            n /= 2;\n            factors.push_back(2);\n        } else {\n            break;\n        }\n    }\n\n    int div = 3;\n    while (div * div <= n) {\n        __m256i divisor = _mm256_set1_epi32(div);\n        __m256i num = _mm256_set1_epi32(n);\n        __m256i remainder = _mm256_rem_epi32(num, divisor);\n        __m256i mask = _mm256_cmpeq_epi32(remainder, zero);\n\n        if (_mm256_movemask_epi8(mask) != 0) {\n            n /= div;\n            factors.push_back(div);\n        } else {\n            div += 2;\n        }\n    }\n\n    if (n > 1) {\n        factors.push_back(n);\n    }\n\n    return factors;\n}\n```"}
{"task_id": "SimdBench_74_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> factorize_simd(int n) {\n    std::vector<int> factors;\n    __m256i twos = _mm256_set1_epi32(2);\n    __m256i fives = _mm256_set1_epi32(5);\n    __m256i sevens = _mm256_set1_epi32(7);\n    __m256i ones = _mm256_set1_epi32(1);\n\n    while (n % 2 == 0) {\n        factors.push_back(2);\n        n /= 2;\n    }\n\n    while (n % 5 == 0) {\n        factors.push_back(5);\n        n /= 5;\n    }\n\n    while (n % 7 == 0) {\n        factors.push_back(7);\n        n /= 7;\n    }\n\n    if (n > 1) {\n        int i = 11;\n        while (i * i <= n) {\n            if (n % i == 0) {\n                factors.push_back(i);\n                n /= i;\n            } else {\n                i += 2;\n            }\n        }\n        if (n > 1) {\n            factors.push_back(n);\n        }\n    }\n\n    return factors;\n}\n```"}
{"task_id": "SimdBench_74_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> factorize_simd(int n) {\n    std::vector<int> factors;\n    __m256i divisor = _mm256_set1_epi32(2);\n    __m256i zero = _mm256_setzero_si256();\n    __m256i one = _mm256_set1_epi32(1);\n\n    while (n > 1) {\n        __m256i num = _mm256_set1_epi32(n);\n        __m256i remainder = _mm256_rem_epi32(num, divisor);\n        __m256i mask = _mm256_cmpeq_epi32(remainder, zero);\n\n        if (_mm256_movemask_epi8(mask) != 0) {\n            n /= 2;\n            factors.push_back(2);\n        } else {\n            break;\n        }\n    }\n\n    int div = 3;\n    while (div * div <= n) {\n        __m256i divisor = _mm256_set1_epi32(div);\n        __m256i num = _mm256_set1_epi32(n);\n        __m256i remainder = _mm256_rem_epi32(num, divisor);\n        __m256i mask = _mm256_cmpeq_epi32(remainder, zero);\n\n        if (_mm256_movemask_epi8(mask) != 0) {\n            n /= div;\n            factors.push_back(div);\n        } else {\n            div += 2;\n        }\n    }\n\n    if (n > 1) {\n        factors.push_back(n);\n    }\n\n    return factors;\n}\n```"}
{"task_id": "SimdBench_74_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> factorize_simd(int n) {\n    std::vector<int> factors;\n    __m256i divisor = _mm256_set1_epi32(2);\n    __m256i zero = _mm256_setzero_si256();\n    __m256i one = _mm256_set1_epi32(1);\n\n    while (n > 1) {\n        __m256i num = _mm256_set1_epi32(n);\n        __m256i remainder = _mm256_rem_epi32(num, divisor);\n        __m256i mask = _mm256_cmpeq_epi32(remainder, zero);\n\n        if (_mm256_movemask_epi8(mask) != 0) {\n            n /= 2;\n            factors.push_back(2);\n        } else {\n            break;\n        }\n    }\n\n    int odd_divisor = 3;\n    while (odd_divisor * odd_divisor <= n) {\n        __m256i divisor = _mm256_set1_epi32(odd_divisor);\n        __m256i num = _mm256_set1_epi32(n);\n        __m256i remainder = _mm256_rem_epi32(num, divisor);\n        __m256i mask = _mm256_cmpeq_epi32(remainder, zero);\n\n        if (_mm256_movemask_epi8(mask) != 0) {\n            n /= odd_divisor;\n            factors.push_back(odd_divisor);\n        } else {\n            odd_divisor += 2;\n        }\n    }\n\n    if (n > 1) {\n        factors.push_back(n);\n    }\n\n    return factors;\n}\n```"}
{"task_id": "SimdBench_74_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> factorize_simd(int n) {\n    std::vector<int> factors;\n    __m256i divisor = _mm256_set1_epi32(2);\n    __m256i zero = _mm256_setzero_si256();\n    __m256i one = _mm256_set1_epi32(1);\n\n    while (n > 1) {\n        __m256i num = _mm256_set1_epi32(n);\n        __m256i remainder = _mm256_rem_epi32(num, divisor);\n        __m256i mask = _mm256_cmpeq_epi32(remainder, zero);\n\n        if (_mm256_movemask_epi8(mask) != 0) {\n            n /= 2;\n            factors.push_back(2);\n        } else {\n            break;\n        }\n    }\n\n    int div = 3;\n    while (div * div <= n) {\n        __m256i divisor = _mm256_set1_epi32(div);\n        __m256i num = _mm256_set1_epi32(n);\n        __m256i remainder = _mm256_rem_epi32(num, divisor);\n        __m256i mask = _mm256_cmpeq_epi32(remainder, zero);\n\n        if (_mm256_movemask_epi8(mask) != 0) {\n            n /= div;\n            factors.push_back(div);\n        } else {\n            div += 2;\n        }\n    }\n\n    if (n > 1) {\n        factors.push_back(n);\n    }\n\n    return factors;\n}\n```"}
{"task_id": "SimdBench_75_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<float> get_positive_simd(const std::vector<float> & l){\n    std::vector<float> result;\n    int n = l.size();\n    int i = 0;\n\n    __m256 zero = _mm256_setzero_ps();\n\n    while (i <= n - 8) {\n        __m256 vec = _mm256_loadu_ps(&l[i]);\n        __m256 mask = _mm256_cmp_ps(vec, zero, _CMP_GT_OS);\n        int mask_int = _mm256_movemask_epi8((__m256i)mask);\n\n        for (int j = 0; j < 8; ++j) {\n            if ((mask_int >> (j * 4)) & 0xF) {\n                result.push_back(l[i + j]);\n            }\n        }\n\n        i += 8;\n    }\n\n    while (i < n) {\n        if (l[i] > 0) {\n            result.push_back(l[i]);\n        }\n        ++i;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_75_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<float> get_positive_simd(const std::vector<float> & l) {\n    std::vector<float> result;\n    int n = l.size();\n    int i = 0;\n\n    __m256 zero = _mm256_setzero_ps();\n\n    while (i <= n - 8) {\n        __m256 vec = _mm256_loadu_ps(&l[i]);\n        __m256 mask = _mm256_cmp_ps(vec, zero, _CMP_GT_OS);\n        int mask_int = _mm256_movemask_epi8(_mm256_castps_si256(mask));\n\n        for (int j = 0; j < 8; ++j) {\n            if ((mask_int >> (j * 4)) & 0xF) {\n                result.push_back(l[i + j]);\n            }\n        }\n\n        i += 8;\n    }\n\n    while (i < n) {\n        if (l[i] > 0) {\n            result.push_back(l[i]);\n        }\n        ++i;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_75_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<float> get_positive_simd(const std::vector<float> & l) {\n    std::vector<float> result;\n    int n = l.size();\n    int i = 0;\n\n    __m256 zero = _mm256_setzero_ps();\n\n    while (i <= n - 8) {\n        __m256 vec = _mm256_loadu_ps(&l[i]);\n        __m256 mask = _mm256_cmp_ps(vec, zero, _CMP_GT_OS);\n        int mask_int = _mm256_movemask_epi8((__m256i)mask);\n\n        for (int j = 0; j < 8; ++j) {\n            if ((mask_int >> (j * 4)) & 0xF) {\n                result.push_back(l[i + j]);\n            }\n        }\n\n        i += 8;\n    }\n\n    while (i < n) {\n        if (l[i] > 0) {\n            result.push_back(l[i]);\n        }\n        ++i;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_75_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<float> get_positive_simd(const std::vector<float> & l){\n    std::vector<float> result;\n    int n = l.size();\n    int i = 0;\n\n    __m256 zero = _mm256_setzero_ps();\n\n    while (i <= n - 8) {\n        __m256 vec = _mm256_loadu_ps(&l[i]);\n        __m256 mask = _mm256_cmp_ps(vec, zero, _CMP_GT_OS);\n        int mask_int = _mm256_movemask_epi8((__m256i)mask);\n\n        for (int j = 0; j < 8; ++j) {\n            if ((mask_int >> (j * 4)) & 0xF) {\n                result.push_back(l[i + j]);\n            }\n        }\n\n        i += 8;\n    }\n\n    while (i < n) {\n        if (l[i] > 0) {\n            result.push_back(l[i]);\n        }\n        ++i;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_75_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<float> get_positive_simd(const std::vector<float> & l) {\n    std::vector<float> result;\n    int n = l.size();\n    int i = 0;\n\n    __m256 zero = _mm256_setzero_ps();\n\n    while (i <= n - 8) {\n        __m256 vec = _mm256_loadu_ps(&l[i]);\n        __m256 mask = _mm256_cmp_ps(vec, zero, _CMP_GT_OS);\n        int mask_int = _mm256_movemask_epi8((__m256i)mask);\n\n        for (int j = 0; j < 8; ++j) {\n            if ((mask_int >> (j * 4)) & 0xF) {\n                result.push_back(l[i + j]);\n            }\n        }\n\n        i += 8;\n    }\n\n    while (i < n) {\n        if (l[i] > 0) {\n            result.push_back(l[i]);\n        }\n        ++i;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_76_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nbool is_prime_simd(int64_t n) {\n    if (n <= 1) return false;\n    if (n <= 3) return true;\n    if (n % 2 == 0 || n % 3 == 0) return false;\n\n    int64_t i = 5;\n    __m256i step = _mm256_set1_epi64x(6);\n    __m256i limit = _mm256_set1_epi64x(static_cast<int64_t>(std::sqrt(n)) + 1);\n\n    while (_mm256_cmpgt_epi64(limit, _mm256_set1_epi64x(i)).m256i_i64[0]) {\n        __m256i i_vec = _mm256_setr_epi64x(i, i + 2, i + 4, i + 6);\n        __m256i div1 = _mm256_div_epi64(i_vec, _mm256_set1_epi64x(n));\n        __m256i div2 = _mm256_div_epi64(_mm256_add_epi64(i_vec, _mm256_set1_epi64x(2)), _mm256_set1_epi64x(n));\n        __m256i cmp1 = _mm256_cmpeq_epi64(_mm256_mullo_epi64(div1, _mm256_set1_epi64x(n)), i_vec);\n        __m256i cmp2 = _mm256_cmpeq_epi64(_mm256_mullo_epi64(div2, _mm256_set1_epi64x(n)), _mm256_add_epi64(i_vec, _mm256_set1_epi64x(2)));\n        __m256i result = _mm256_or_si256(cmp1, cmp2);\n        if (_mm256_movemask_epi8(result) != 0) return false;\n        i += 6;\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_76_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nbool is_prime_simd(int64_t n) {\n    if (n <= 1) return false;\n    if (n <= 3) return true;\n    if (n % 2 == 0 || n % 3 == 0) return false;\n\n    int64_t i = 5;\n    __m256i step = _mm256_set1_epi64x(6);\n    __m256i limit = _mm256_set1_epi64x(static_cast<int64_t>(sqrt(n)) + 1);\n\n    while (_mm256_cmpgt_epi64(limit, _mm256_set1_epi64x(i)).m256i_i64[0]) {\n        __m256i i_vec = _mm256_setr_epi64x(i, i + 2, i + 4, i + 6);\n        __m256i div1 = _mm256_div_epi64(i_vec, _mm256_set1_epi64x(n));\n        __m256i rem1 = _mm256_sub_epi64(i_vec, _mm256_mullo_epi64(div1, _mm256_set1_epi64x(n)));\n        __m256i div2 = _mm256_div_epi64(_mm256_add_epi64(i_vec, _mm256_set1_epi64x(2)), _mm256_set1_epi64x(n));\n        __m256i rem2 = _mm256_sub_epi64(_mm256_add_epi64(i_vec, _mm256_set1_epi64x(2)), _mm256_mullo_epi64(div2, _mm256_set1_epi64x(n)));\n\n        if (!_mm256_testz_si256(rem1, rem1) && !_mm256_testz_si256(rem2, rem2)) {\n            i += 6;\n        } else {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_76_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nbool is_prime_simd(int64_t n) {\n    if (n <= 1) return false;\n    if (n <= 3) return true;\n    if (n % 2 == 0 || n % 3 == 0) return false;\n\n    int64_t i = 5;\n    __m256i step = _mm256_set1_epi64x(6);\n    __m256i limit = _mm256_set1_epi64x(static_cast<int64_t>(std::sqrt(n)) + 1);\n\n    while (_mm256_cmpgt_epi64(limit, _mm256_set1_epi64x(i)).m256i_i64[0]) {\n        __m256i i_vec = _mm256_setr_epi64x(i, i + 2, i + 4, i + 6);\n        __m256i div1 = _mm256_div_epi64(_mm256_set1_epi64x(n), i_vec);\n        __m256i rem1 = _mm256_sub_epi64(i_vec, _mm256_mullo_epi64(div1, i_vec));\n        __m256i zero_mask1 = _mm256_cmpeq_epi64(_mm256_setzero_si256(), rem1);\n\n        __m256i i_vec2 = _mm256_add_epi64(i_vec, _mm256_set1_epi64x(4));\n        __m256i div2 = _mm256_div_epi64(_mm256_set1_epi64x(n), i_vec2);\n        __m256i rem2 = _mm256_sub_epi64(i_vec2, _mm256_mullo_epi64(div2, i_vec2));\n        __m256i zero_mask2 = _mm256_cmpeq_epi64(_mm256_setzero_si256(), rem2);\n\n        __m256i combined_mask = _mm256_or_si256(zero_mask1, zero_mask2);\n        if (!_mm256_testz_si256(combined_mask, combined_mask)) {\n            return false;\n        }\n        i += 12;\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_76_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nbool is_prime_simd(int64_t n) {\n    if (n <= 1) return false;\n    if (n <= 3) return true;\n    if (n % 2 == 0 || n % 3 == 0) return false;\n\n    int64_t i = 5;\n    __m256i step = _mm256_set1_epi64x(6);\n    __m256i limit = _mm256_set1_epi64x(static_cast<int64_t>(std::sqrt(n)) + 1);\n\n    while (_mm256_cmpgt_epi64(limit, _mm256_set1_epi64x(i)).m256i_i64[0]) {\n        __m256i i_vec = _mm256_setr_epi64x(i, i + 2, i + 4, i + 6);\n        __m256i div1 = _mm256_div_epi64(_mm256_set1_epi64x(n), i_vec);\n        __m256i rem1 = _mm256_sub_epi64(i_vec, _mm256_mullo_epi64(div1, i_vec));\n        __m256i zero_mask1 = _mm256_cmpeq_epi64(_mm256_setzero_si256(), rem1);\n\n        __m256i i_vec2 = _mm256_add_epi64(i_vec, _mm256_set1_epi64x(4));\n        __m256i div2 = _mm256_div_epi64(_mm256_set1_epi64x(n), i_vec2);\n        __m256i rem2 = _mm256_sub_epi64(i_vec2, _mm256_mullo_epi64(div2, i_vec2));\n        __m256i zero_mask2 = _mm256_cmpeq_epi64(_mm256_setzero_si256(), rem2);\n\n        __m256i combined_mask = _mm256_or_si256(zero_mask1, zero_mask2);\n        if (!_mm256_testz_si256(combined_mask, combined_mask)) {\n            return false;\n        }\n        i += 12;\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_76_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nbool is_prime_simd(int64_t n) {\n    if (n <= 1) return false;\n    if (n <= 3) return true;\n    if (n % 2 == 0 || n % 3 == 0) return false;\n\n    int64_t i = 5;\n    __m256i increment = _mm256_set_epi64x(10, 8, 6, 4);\n    __m256i limit = _mm256_set1_epi64x(static_cast<int64_t>(std::sqrt(n)) + 1);\n\n    while (_mm256_movemask_epi8(_mm256_cmpgt_epi64(limit, _mm256_set1_epi64x(i))) != 0) {\n        __m256i multiples_of_i = _mm256_set1_epi64x(i);\n        __m256i divisors = _mm256_or_si256(multiples_of_i, _mm256_add_epi64(multiples_of_i, increment));\n        __m256i remainders = _mm256_rem_epu64(_mm256_set1_epi64x(n), divisors);\n        if (_mm256_testz_si256(remainders, remainders) == 0) {\n            return false;\n        }\n        i += 6;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_77_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n#include <algorithm>\n\nstd::string solve_simd(const std::string & s) {\n    int n = s.size();\n    if (n == 0) return s;\n\n    std::string result(n, ' ');\n    bool has_letters = false;\n\n    const __m256i lower_mask = _mm256_set1_epi8(0x20);\n    const __m256i letter_mask = _mm256_set1_epi8(0x60);\n    const __m256i zero = _mm256_setzero_si256();\n\n    for (int i = 0; i <= n - 32; i += 32) {\n        __m256i chunk = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(s.data() + i));\n        __m256i is_letter = _mm256_and_si256(chunk, letter_mask);\n        is_letter = _mm256_cmpeq_epi8(is_letter, lower_mask);\n        has_letters |= _mm256_movemask_epi8(is_letter) != 0;\n\n        __m256i toggled = _mm256_xor_si256(chunk, _mm256_and_si256(is_letter, lower_mask));\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(result.data() + i), toggled);\n    }\n\n    for (int i = (n / 32) * 32; i < n; ++i) {\n        if (s[i] >= 'a' && s[i] <= 'z') {\n            result[i] = s[i] - 'a' + 'A';\n            has_letters = true;\n        } else if (s[i] >= 'A' && s[i] <= 'Z') {\n            result[i] = s[i] - 'A' + 'a';\n            has_letters = true;\n        } else {\n            result[i] = s[i];\n        }\n    }\n\n    if (!has_letters) {\n        std::reverse(result.begin(), result.end());\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_77_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n#include <algorithm>\n\nstd::string solve_simd(const std::string & s) {\n    int n = s.size();\n    if (n == 0) return s;\n\n    std::string result(n, ' ');\n    bool has_letters = false;\n\n    const __m256i lowercase_mask = _mm256_set1_epi8(0x20);\n    const __m256i lowercase_a = _mm256_set1_epi8('a');\n    const __m256i lowercase_z = _mm256_set1_epi8('z');\n    const __m256i uppercase_A = _mm256_set1_epi8('A');\n    const __m256i uppercase_Z = _mm256_set1_epi8('Z');\n\n    for (int i = 0; i <= n - 32; i += 32) {\n        __m256i chunk = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(s.data() + i));\n        __m256i is_lowercase = _mm256_and_si256(_mm256_cmpgt_epi8(chunk, lowercase_a), _mm256_cmpgt_epi8(lowercase_z, chunk));\n        __m256i is_uppercase = _mm256_and_si256(_mm256_cmpgt_epi8(chunk, uppercase_A), _mm256_cmpgt_epi8(uppercase_Z, chunk));\n        __m256i is_letter = _mm256_or_si256(is_lowercase, is_uppercase);\n\n        if (!_mm256_testz_si256(is_letter, is_letter)) {\n            has_letters = true;\n            chunk = _mm256_xor_si256(chunk, lowercase_mask);\n        }\n\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(result.data() + i), chunk);\n    }\n\n    for (int i = (n / 32) * 32; i < n; ++i) {\n        if (s[i] >= 'a' && s[i] <= 'z') {\n            has_letters = true;\n            result[i] = s[i] - 0x20;\n        } else if (s[i] >= 'A' && s[i] <= 'Z') {\n            has_letters = true;\n            result[i] = s[i] + 0x20;\n        } else {\n            result[i] = s[i];\n        }\n    }\n\n    if (!has_letters) {\n        std::reverse(result.begin(), result.end());\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_77_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n#include <algorithm>\n\nstd::string solve_simd(const std::string & s) {\n    int n = s.size();\n    if (n == 0) return s;\n\n    std::string result(n, ' ');\n\n    const __m256i lower_mask = _mm256_set1_epi8(0x20);\n    const __m256i letter_mask = _mm256_set1_epi8(0x60);\n    const __m256i zero = _mm256_setzero_si256();\n\n    int i = 0;\n    bool has_letters = false;\n\n    for (; i <= n - 32; i += 32) {\n        __m256i input = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(s.data() + i));\n        __m256i is_letter = _mm256_and_si256(_mm256_cmplt_epi8(input, _mm256_set1_epi8('z' + 1)),\n                                             _mm256_cmpgt_epi8(input, _mm256_set1_epi8('A' - 1)));\n        __m256i is_lower = _mm256_and_si256(is_letter, _mm256_cmpgt_epi8(input, _mm256_set1_epi8('a' - 1)));\n        __m256i is_upper = _mm256_and_si256(is_letter, _mm256_cmple_epi8(input, _mm256_set1_epi8('Z')));\n        __m256i toggled = _mm256_xor_si256(input, _mm256_and_si256(lower_mask, _mm256_or_si256(is_lower, is_upper)));\n        __m256i result_chunk = _mm256_blendv_epi8(input, toggled, is_letter);\n\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(result.data() + i), result_chunk);\n        has_letters |= !_mm256_testz_si256(is_letter, is_letter);\n    }\n\n    for (; i < n; ++i) {\n        char c = s[i];\n        if ((c >= 'a' && c <= 'z') || (c >= 'A' && c <= 'Z')) {\n            has_letters = true;\n            result[i] = (c >= 'a' && c <= 'z') ? (c - 'a' + 'A') : (c - 'A' + 'a');\n        } else {\n            result[i] = c;\n        }\n    }\n\n    if (!has_letters) {\n        std::reverse(result.begin(), result.end());\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_77_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n#include <algorithm>\n\nstd::string solve_simd(const std::string & s) {\n    int n = s.size();\n    if (n == 0) return s;\n\n    std::string result(n, ' ');\n\n    const __m256i lower_mask = _mm256_set1_epi8(0x20);\n    const __m256i letter_mask = _mm256_set1_epi8(0x60);\n    const __m256i zero = _mm256_setzero_si256();\n\n    int i = 0;\n    bool has_letters = false;\n\n    for (; i <= n - 32; i += 32) {\n        __m256i input = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(s.data() + i));\n        __m256i is_letter = _mm256_and_si256(_mm256_cmplt_epi8(input, _mm256_set1_epi8('z' + 1)),\n                                             _mm256_cmpgt_epi8(input, _mm256_set1_epi8('A' - 1)));\n        __m256i is_lower = _mm256_and_si256(is_letter, _mm256_cmpgt_epi8(input, _mm256_set1_epi8('a' - 1)));\n        __m256i is_upper = _mm256_and_si256(is_letter, _mm256_cmple_epi8(input, _mm256_set1_epi8('Z')));\n        __m256i toggled = _mm256_xor_si256(input, _mm256_and_si256(lower_mask, _mm256_or_si256(is_lower, is_upper)));\n        __m256i result_chunk = _mm256_blendv_epi8(input, toggled, is_letter);\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(result.data() + i), result_chunk);\n        has_letters |= !_mm256_testz_si256(is_letter, is_letter);\n    }\n\n    for (; i < n; ++i) {\n        char c = s[i];\n        if ((c >= 'a' && c <= 'z') || (c >= 'A' && c <= 'Z')) {\n            has_letters = true;\n            result[i] = (c >= 'a' && c <= 'z') ? (c - 'a' + 'A') : (c - 'A' + 'a');\n        } else {\n            result[i] = c;\n        }\n    }\n\n    if (!has_letters) {\n        std::reverse(result.begin(), result.end());\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_77_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n#include <algorithm>\n\nstd::string solve_simd(const std::string & s) {\n    int n = s.size();\n    if (n == 0) return s;\n\n    std::string result(n, ' ');\n    bool has_letters = false;\n\n    const __m256i lower_case_mask = _mm256_set1_epi8(0x20);\n    const __m256i lower_bound = _mm256_set1_epi8('a');\n    const __m256i upper_bound = _mm256_set1_epi8('z');\n    const __m256i upper_bound_cap = _mm256_set1_epi8('Z');\n\n    for (int i = 0; i <= n - 32; i += 32) {\n        __m256i chunk = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(s.data() + i));\n        __m256i is_lower = _mm256_andnot_si256(_mm256_cmpgt_epi8(chunk, upper_bound), _mm256_cmpgt_epi8(chunk, lower_bound));\n        __m256i is_upper = _mm256_cmpgt_epi8(chunk, upper_bound_cap);\n        __m256i is_letter = _mm256_or_si256(is_lower, is_upper);\n        has_letters |= _mm256_movemask_epi8(is_letter) != 0;\n        __m256i toggled = _mm256_xor_si256(chunk, _mm256_and_si256(is_letter, lower_case_mask));\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(result.data() + i), toggled);\n    }\n\n    for (int i = (n / 32) * 32; i < n; ++i) {\n        if (s[i] >= 'a' && s[i] <= 'z') {\n            result[i] = s[i] - 'a' + 'A';\n            has_letters = true;\n        } else if (s[i] >= 'A' && s[i] <= 'Z') {\n            result[i] = s[i] - 'A' + 'a';\n            has_letters = true;\n        } else {\n            result[i] = s[i];\n        }\n    }\n\n    if (!has_letters) {\n        std::reverse(result.begin(), result.end());\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_78_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<int> sort_third_simd(std::vector<int> l) {\n    int n = l.size();\n    std::vector<int> result(n);\n    int* data = l.data();\n    int* res_data = result.data();\n\n    for (int i = 0; i < n; i += 8) {\n        __m256i vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(data + i));\n        __m256i indices = _mm256_set_epi32(i + 7, i + 6, i + 5, i + 4, i + 3, i + 2, i + 1, i);\n        __m256i mod3_mask = _mm256_set1_epi32(3);\n        __m256i zero = _mm256_setzero_si256();\n        __m256i div3_mask = _mm256_cmpeq_epi32(_mm256_and_epi32(_mm256_srli_epi32(indices, 2), mod3_mask), zero);\n\n        int temp[8];\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(temp), vec);\n\n        std::vector<int> div3_elements;\n        for (int j = 0; j < 8; ++j) {\n            if (_mm256_extract_epi32(div3_mask, j)) {\n                div3_elements.push_back(temp[j]);\n            }\n        }\n\n        std::sort(div3_elements.begin(), div3_elements.end());\n\n        int div3_index = 0;\n        for (int j = 0; j < 8; ++j) {\n            if (_mm256_extract_epi32(div3_mask, j)) {\n                temp[j] = div3_elements[div3_index++];\n            }\n        }\n\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(res_data + i), _mm256_loadu_si256(reinterpret_cast<const __m256i*>(temp)));\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_78_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<int> sort_third_simd(std::vector<int> l) {\n    int n = l.size();\n    std::vector<int> result(n);\n    int* data = l.data();\n    int* res_data = result.data();\n\n    for (int i = 0; i < n; i += 12) {\n        __m256i vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(data + i));\n        __m256i indices = _mm256_setr_epi32(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11);\n        __m256i mod3_mask = _mm256_setr_epi32(1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0);\n        __m256i zero = _mm256_setzero_si256();\n\n        __m256i mod3_indices = _mm256_and_si256(indices, mod3_mask);\n        __m256i non_mod3_mask = _mm256_cmpeq_epi32(mod3_indices, zero);\n        __m256i mod3_values = _mm256_maskz_compress_epi32(_mm256_movemask_epi8(non_mod3_mask), vec);\n\n        int mod3_array[8];\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(mod3_array), mod3_values);\n        std::sort(mod3_array, mod3_array + 8);\n\n        __m256i sorted_mod3_values = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(mod3_array));\n        __m256i result_vec = _mm256_mask_blend_epi32(_mm256_movemask_epi8(non_mod3_mask), vec, sorted_mod3_values);\n\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(res_data + i), result_vec);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_78_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<int> sort_third_simd(std::vector<int> l) {\n    int n = l.size();\n    std::vector<int> result(n);\n    int* data = l.data();\n    int* res_data = result.data();\n\n    for (int i = 0; i < n; i += 12) {\n        __m256i vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(data + i));\n        __m256i indices = _mm256_set_epi32(11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 0);\n        __m256i mod3_mask = _mm256_set1_epi32(3);\n        __m256i zero = _mm256_setzero_si256();\n\n        // Create a mask for indices divisible by 3\n        __m256i div3_mask = _mm256_cmpeq_epi32(_mm256_and_si256(indices, mod3_mask), zero);\n\n        // Extract elements at indices divisible by 3\n        __m256i div3_elements = _mm256_maskz_compress_epi32(div3_mask, vec);\n\n        // Sort the extracted elements\n        int temp[8];\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(temp), div3_elements);\n        std::sort(temp, temp + 8);\n\n        // Create a mask for non-divisible by 3\n        __m256i non_div3_mask = _mm256_xor_si256(div3_mask, _mm256_cmpeq_epi32(zero, zero));\n\n        // Blend the sorted elements back into the original vector\n        __m256i sorted_vec = _mm256_maskz_expand_epi32(div3_mask, _mm256_loadu_si256(reinterpret_cast<const __m256i*>(temp)));\n        __m256i result_vec = _mm256_mask_blend_epi32(div3_mask, vec, sorted_vec);\n\n        // Store the result\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(res_data + i), result_vec);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_78_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<int> sort_third_simd(std::vector<int> l) {\n    int n = l.size();\n    std::vector<int> result(n);\n    int* data = l.data();\n    int* res_data = result.data();\n\n    for (int i = 0; i < n; i += 8) {\n        __m256i vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(data + i));\n        __m256i indices = _mm256_set_epi32(i + 7, i + 6, i + 5, i + 4, i + 3, i + 2, i + 1, i);\n        __m256i mod3_mask = _mm256_set1_epi32(3);\n        __m256i zero = _mm256_setzero_si256();\n        __m256i div3_mask = _mm256_cmpeq_epi32(_mm256_and_epi32(_mm256_srli_epi32(indices, 1), mod3_mask), zero);\n\n        int temp[8];\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(temp), vec);\n\n        std::vector<int> div3_elements;\n        for (int j = 0; j < 8; ++j) {\n            if ((div3_mask.m256i_i32[j] & 0xFFFFFFFF) != 0) {\n                div3_elements.push_back(temp[j]);\n            }\n        }\n\n        std::sort(div3_elements.begin(), div3_elements.end());\n\n        int div3_index = 0;\n        for (int j = 0; j < 8; ++j) {\n            if ((div3_mask.m256i_i32[j] & 0xFFFFFFFF) != 0) {\n                temp[j] = div3_elements[div3_index++];\n            }\n        }\n\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(res_data + i), _mm256_loadu_si256(reinterpret_cast<const __m256i*>(temp)));\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_78_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<int> sort_third_simd(std::vector<int> l) {\n    int n = l.size();\n    std::vector<int> result(n);\n    int* data = l.data();\n    int* res_data = result.data();\n\n    for (int i = 0; i < n; i += 8) {\n        __m256i vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(data + i));\n        __m256i indices = _mm256_set_epi32(i + 7, i + 6, i + 5, i + 4, i + 3, i + 2, i + 1, i);\n        __m256i mod3_mask = _mm256_set1_epi32(3);\n        __m256i zero = _mm256_setzero_si256();\n        __m256i div3_mask = _mm256_cmpeq_epi32(_mm256_and_epi32(_mm256_srli_epi32(indices, 1), mod3_mask), zero);\n\n        int temp[8];\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(temp), vec);\n\n        std::vector<int> div3_elements;\n        for (int j = 0; j < 8; ++j) {\n            if ((div3_mask.m256i_i32[j] & 0xFFFFFFFF) != 0) {\n                div3_elements.push_back(temp[j]);\n            }\n        }\n\n        std::sort(div3_elements.begin(), div3_elements.end());\n\n        int div3_index = 0;\n        for (int j = 0; j < 8; ++j) {\n            if ((div3_mask.m256i_i32[j] & 0xFFFFFFFF) != 0) {\n                temp[j] = div3_elements[div3_index++];\n            }\n        }\n\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(res_data + i), _mm256_loadu_si256(reinterpret_cast<const __m256i*>(temp)));\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_79_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n\nfloat max_element_simd(const std::vector<float>& l) {\n    __m256 max_vec = _mm256_set1_ps(l[0]);\n    size_t i = 0;\n    for (; i + 7 < l.size(); i += 8) {\n        __m256 vec = _mm256_loadu_ps(&l[i]);\n        max_vec = _mm256_max_ps(max_vec, vec);\n    }\n\n    float max_array[8];\n    _mm256_storeu_ps(max_array, max_vec);\n\n    float max_val = *std::max_element(max_array, max_array + 8);\n    for (; i < l.size(); ++i) {\n        max_val = std::max(max_val, l[i]);\n    }\n\n    return max_val;\n}\n```"}
{"task_id": "SimdBench_79_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n\nfloat max_element_simd(const std::vector<float>& l) {\n    __m256 max_vec = _mm256_set1_ps(l[0]);\n    size_t i = 0;\n    for (; i <= l.size() - 8; i += 8) {\n        __m256 vec = _mm256_loadu_ps(&l[i]);\n        max_vec = _mm256_max_ps(max_vec, vec);\n    }\n    float max_array[8];\n    _mm256_storeu_ps(max_array, max_vec);\n    float max_val = *std::max_element(max_array, max_array + 8);\n    for (; i < l.size(); ++i) {\n        max_val = std::max(max_val, l[i]);\n    }\n    return max_val;\n}\n```"}
{"task_id": "SimdBench_79_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n\nfloat max_element_simd(const std::vector<float>& l) {\n    __m256 max_vec = _mm256_set1_ps(l[0]);\n    size_t i = 0;\n    size_t n = l.size();\n\n    for (; i <= n - 8; i += 8) {\n        __m256 vec = _mm256_loadu_ps(&l[i]);\n        max_vec = _mm256_max_ps(max_vec, vec);\n    }\n\n    float max_array[8];\n    _mm256_storeu_ps(max_array, max_vec);\n\n    float max_val = *std::max_element(max_array, max_array + 8);\n\n    for (; i < n; ++i) {\n        max_val = std::max(max_val, l[i]);\n    }\n\n    return max_val;\n}\n```"}
{"task_id": "SimdBench_79_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n\nfloat max_element_simd(const std::vector<float>& l) {\n    __m256 max_vec = _mm256_set1_ps(l[0]);\n    size_t i = 0;\n    for (; i <= l.size() - 8; i += 8) {\n        __m256 vec = _mm256_loadu_ps(&l[i]);\n        max_vec = _mm256_max_ps(max_vec, vec);\n    }\n    float max_array[8];\n    _mm256_storeu_ps(max_array, max_vec);\n    float max_val = *std::max_element(max_array, max_array + 8);\n    for (; i < l.size(); ++i) {\n        max_val = std::max(max_val, l[i]);\n    }\n    return max_val;\n}\n```"}
{"task_id": "SimdBench_79_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n\nfloat max_element_simd(const std::vector<float>& l) {\n    __m256 max_vec = _mm256_set1_ps(l[0]);\n    size_t i = 0;\n    size_t n = l.size();\n\n    for (; i <= n - 8; i += 8) {\n        __m256 vec = _mm256_loadu_ps(&l[i]);\n        max_vec = _mm256_max_ps(max_vec, vec);\n    }\n\n    float max_array[8];\n    _mm256_storeu_ps(max_array, max_vec);\n\n    float max_val = *std::max_element(max_array, max_array + 8);\n\n    for (; i < n; ++i) {\n        max_val = std::max(max_val, l[i]);\n    }\n\n    return max_val;\n}\n```"}
{"task_id": "SimdBench_80_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nint fizz_buzz_simd(int n) {\n    int count = 0;\n    __m256i seven = _mm256_set1_epi32(7);\n    __m256i eleven = _mm256_set1_epi32(11);\n    __m256i thirteen = _mm256_set1_epi32(13);\n    __m256i zero = _mm256_setzero_si256();\n    __m256i mask = _mm256_set1_epi32(0xF);\n\n    for (int i = 0; i < n; i += 8) {\n        __m256i nums = _mm256_setr_epi32(i, i + 1, i + 2, i + 3, i + 4, i + 5, i + 6, i + 7);\n        __m256i div11 = _mm256_cmpeq_epi32(_mm256_rem_epi32(nums, eleven), zero);\n        __m256i div13 = _mm256_cmpeq_epi32(_mm256_rem_epi32(nums, thirteen), zero);\n        __m256i divisible = _mm256_or_si256(div11, div13);\n        __m256i sevens = _mm256_cmpeq_epi32(nums, seven);\n        __m256i result = _mm256_and_si256(divisible, sevens);\n        __m256i counts = _mm256_movemask_epi8(result);\n        count += _mm_popcnt_u32(counts) / 4;\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_80_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nint fizz_buzz_simd(int n) {\n    int count = 0;\n    __m256i seven = _mm256_set1_epi32(7);\n    __m256i eleven = _mm256_set1_epi32(11);\n    __m256i thirteen = _mm256_set1_epi32(13);\n    __m256i zero = _mm256_setzero_si256();\n    __m256i mask = _mm256_set1_epi32(0xF);\n\n    for (int i = 0; i < n; i += 8) {\n        __m256i indices = _mm256_setr_epi32(i, i + 1, i + 2, i + 3, i + 4, i + 5, i + 6, i + 7);\n        __m256i divisible_by_11 = _mm256_cmpeq_epi32(_mm256_rem_epi32(indices, eleven), zero);\n        __m256i divisible_by_13 = _mm256_cmpeq_epi32(_mm256_rem_epi32(indices, thirteen), zero);\n        __m256i divisible_by_11_or_13 = _mm256_or_si256(divisible_by_11, divisible_by_13);\n        __m256i numbers = indices;\n        __m256i shifted_numbers = _mm256_srli_epi32(numbers, 4);\n        __m256i last_digit = _mm256_and_si256(numbers, mask);\n        __m256i first_digit = _mm256_and_si256(shifted_numbers, mask);\n        __m256i contains_seven_last = _mm256_cmpeq_epi32(last_digit, seven);\n        __m256i contains_seven_first = _mm256_cmpeq_epi32(first_digit, seven);\n        __m256i contains_seven = _mm256_or_si256(contains_seven_last, contains_seven_first);\n        __m256i result = _mm256_and_si256(divisible_by_11_or_13, contains_seven);\n        int horizontal_sum = _mm256_movemask_epi8(result);\n        count += __builtin_popcount(horizontal_sum) / 8;\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_80_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nint fizz_buzz_simd(int n) {\n    int count = 0;\n    __m256i seven = _mm256_set1_epi32(7);\n    __m256i eleven = _mm256_set1_epi32(11);\n    __m256i thirteen = _mm256_set1_epi32(13);\n    __m256i zero = _mm256_setzero_si256();\n    __m256i mask = _mm256_set1_epi32(0xF);\n\n    for (int i = 0; i < n; i += 8) {\n        __m256i nums = _mm256_setr_epi32(i, i + 1, i + 2, i + 3, i + 4, i + 5, i + 6, i + 7);\n        __m256i div_by_11 = _mm256_cmpeq_epi32(_mm256_rem_epi32(nums, eleven), zero);\n        __m256i div_by_13 = _mm256_cmpeq_epi32(_mm256_rem_epi32(nums, thirteen), zero);\n        __m256i valid_nums = _mm256_or_si256(div_by_11, div_by_13);\n\n        __m256i nums_valid = _mm256_and_si256(nums, valid_nums);\n        __m256i sevens = _mm256_cmpeq_epi32(nums_valid, seven);\n\n        __m256i sevens_mask = _mm256_and_si256(sevens, mask);\n        int sevens_count = _mm256_movemask_epi8(sevens_mask);\n        count += __builtin_popcount(sevens_count);\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_80_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nint fizz_buzz_simd(int n) {\n    int count = 0;\n    __m256i seven = _mm256_set1_epi32(7);\n    __m256i eleven = _mm256_set1_epi32(11);\n    __m256i thirteen = _mm256_set1_epi32(13);\n    __m256i zero = _mm256_setzero_si256();\n    __m256i mask = _mm256_set1_epi32(0xF);\n\n    for (int i = 0; i < n; i += 8) {\n        __m256i nums = _mm256_setr_epi32(i, i + 1, i + 2, i + 3, i + 4, i + 5, i + 6, i + 7);\n        __m256i divisible_by_11 = _mm256_cmpeq_epi32(_mm256_and_epi32(_mm256_div_epi32(nums, eleven), mask), zero);\n        __m256i divisible_by_13 = _mm256_cmpeq_epi32(_mm256_and_epi32(_mm256_div_epi32(nums, thirteen), mask), zero);\n        __m256i divisible_by_11_or_13 = _mm256_or_si256(divisible_by_11, divisible_by_13);\n\n        for (int j = 0; j < 8 && i + j < n; ++j) {\n            if (_mm256_extract_epi32(divisible_by_11_or_13, j)) {\n                int num = i + j;\n                while (num > 0) {\n                    if (num % 10 == 7) {\n                        count++;\n                    }\n                    num /= 10;\n                }\n            }\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_80_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nint fizz_buzz_simd(int n) {\n    int count = 0;\n    __m256i seven = _mm256_set1_epi32(7);\n    __m256i eleven = _mm256_set1_epi32(11);\n    __m256i thirteen = _mm256_set1_epi32(13);\n    __m256i zero = _mm256_setzero_si256();\n    __m256i mask = _mm256_set1_epi32(0xF);\n\n    for (int i = 0; i < n; i += 8) {\n        __m256i nums = _mm256_setr_epi32(i, i + 1, i + 2, i + 3, i + 4, i + 5, i + 6, i + 7);\n        __m256i divisible_by_11 = _mm256_cmpeq_epi32(_mm256_rem_epi32(nums, eleven), zero);\n        __m256i divisible_by_13 = _mm256_cmpeq_epi32(_mm256_rem_epi32(nums, thirteen), zero);\n        __m256i divisible_by_11_or_13 = _mm256_or_si256(divisible_by_11, divisible_by_13);\n        __m256i nums_divisible = _mm256_and_si256(nums, divisible_by_11_or_13);\n        __m256i sevens = _mm256_cmpeq_epi32(nums_divisible, seven);\n        __m256i sevens_masked = _mm256_and_si256(sevens, mask);\n        int sevens_count = _mm256_movemask_epi8(sevens_masked);\n        count += __builtin_popcount(sevens_count);\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_81_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<float> sort_even_simd(std::vector<float> l) {\n    int n = l.size();\n    if (n < 2) return l;\n\n    __m256 vec;\n    float buffer[8];\n    std::vector<float> even_elements;\n\n    // Collect even index elements\n    for (int i = 0; i < n; i += 2) {\n        even_elements.push_back(l[i]);\n    }\n\n    // Sort even elements\n    std::sort(even_elements.begin(), even_elements.end());\n\n    // Process in chunks of 8\n    for (int i = 0; i < n; i += 8) {\n        vec = _mm256_loadu_ps(&l[i]);\n\n        // Extract even indices\n        __m128 even_low = _mm256_extractf128_ps(vec, 0);\n        __m128 even_high = _mm256_extractf128_ps(vec, 1);\n        __m128 even_indices = _mm_shuffle_ps(even_low, even_high, _MM_SHUFFLE(2, 0, 2, 0));\n\n        // Load sorted even elements\n        __m128 sorted_even = _mm_loadu_ps(&even_elements[i / 2]);\n\n        // Combine sorted even and original odd\n        __m128 result_low = _mm_blend_ps(sorted_even, even_low, 0b1010);\n        __m128 result_high = _mm_blend_ps(sorted_even, even_high, 0b1010);\n\n        // Interleave low and high parts\n        __m256 result = _mm256_set_m128(result_high, result_low);\n\n        // Store result back\n        _mm256_storeu_ps(&l[i], result);\n    }\n\n    // Handle remaining elements\n    for (int i = (n / 8) * 8; i < n; i += 2) {\n        l[i] = even_elements[i / 2];\n    }\n\n    return l;\n}\n```"}
{"task_id": "SimdBench_81_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<float> sort_even_simd(std::vector<float> l) {\n    int n = l.size();\n    if (n < 2) return l;\n\n    __m256 vec;\n    float buffer[8];\n    std::vector<float> even_elements;\n\n    for (int i = 0; i < n; i += 8) {\n        vec = _mm256_loadu_ps(&l[i]);\n        _mm256_storeu_ps(buffer, vec);\n        for (int j = 0; j < 8 && i + j < n; j += 2) {\n            even_elements.push_back(buffer[j]);\n        }\n    }\n\n    std::sort(even_elements.begin(), even_elements.end());\n\n    int even_index = 0;\n    for (int i = 0; i < n; i += 8) {\n        vec = _mm256_loadu_ps(&l[i]);\n        _mm256_storeu_ps(buffer, vec);\n        for (int j = 0; j < 8 && i + j < n; j += 2) {\n            buffer[j] = even_elements[even_index++];\n        }\n        _mm256_storeu_ps(&l[i], _mm256_loadu_ps(buffer));\n    }\n\n    return l;\n}\n```"}
{"task_id": "SimdBench_81_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<float> sort_even_simd(std::vector<float> l) {\n    int n = l.size();\n    if (n < 2) return l;\n\n    __m256 vec;\n    float buffer[8];\n\n    for (int i = 0; i < n; i += 8) {\n        vec = _mm256_loadu_ps(&l[i]);\n        _mm256_storeu_ps(buffer, vec);\n\n        // Sort only even indices\n        std::sort(buffer, buffer + 8, [](float a, float b) {\n            return false; // Placeholder, actual sorting logic needed\n        });\n\n        // Manually sort even indices\n        std::sort(buffer + 0, buffer + 1);\n        std::sort(buffer + 2, buffer + 3);\n        std::sort(buffer + 4, buffer + 5);\n        std::sort(buffer + 6, buffer + 7);\n\n        vec = _mm256_loadu_ps(buffer);\n        _mm256_storeu_ps(&l[i], vec);\n    }\n\n    // Handle remaining elements\n    for (int i = 0; i < n; i += 2) {\n        for (int j = i + 2; j < n; j += 2) {\n            if (l[i] > l[j]) {\n                std::swap(l[i], l[j]);\n            }\n        }\n    }\n\n    return l;\n}\n```"}
{"task_id": "SimdBench_81_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<float> sort_even_simd(std::vector<float> l) {\n    int n = l.size();\n    if (n < 2) return l;\n\n    __m256 vec;\n    float buffer[8];\n\n    for (int i = 0; i < n; i += 8) {\n        vec = _mm256_loadu_ps(&l[i]);\n        _mm256_storeu_ps(buffer, vec);\n\n        // Sort even indices in the buffer\n        std::sort(buffer, buffer + 8, [](float a, float b) {\n            return false; // Placeholder, actual sorting logic needed\n        });\n\n        // Manually sort even indices\n        std::sort(buffer + 0, buffer + 1);\n        std::sort(buffer + 2, buffer + 3);\n        std::sort(buffer + 4, buffer + 5);\n        std::sort(buffer + 6, buffer + 7);\n\n        vec = _mm256_setr_ps(buffer[0], buffer[1], buffer[2], buffer[3], buffer[4], buffer[5], buffer[6], buffer[7]);\n        _mm256_storeu_ps(&l[i], vec);\n    }\n\n    // Handle remaining elements\n    for (int i = 0; i < n; i += 2) {\n        for (int j = i + 2; j < n; j += 2) {\n            if (l[i] > l[j]) {\n                std::swap(l[i], l[j]);\n            }\n        }\n    }\n\n    return l;\n}\n```"}
{"task_id": "SimdBench_81_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<float> sort_even_simd(std::vector<float> l) {\n    int n = l.size();\n    if (n < 2) return l;\n\n    __m256 vec;\n    float buffer[8];\n    std::vector<float> even_elements;\n\n    for (int i = 0; i < n; i += 8) {\n        vec = _mm256_loadu_ps(&l[i]);\n        _mm256_storeu_ps(buffer, vec);\n        for (int j = 0; j < 8 && i + j < n; j += 2) {\n            even_elements.push_back(buffer[j]);\n        }\n    }\n\n    std::sort(even_elements.begin(), even_elements.end());\n\n    int even_index = 0;\n    for (int i = 0; i < n; i += 8) {\n        vec = _mm256_loadu_ps(&l[i]);\n        _mm256_storeu_ps(buffer, vec);\n        for (int j = 0; j < 8 && i + j < n; j += 2) {\n            buffer[j] = even_elements[even_index++];\n        }\n        _mm256_storeu_ps(&l[i], _mm256_loadu_ps(buffer));\n    }\n\n    return l;\n}\n```"}
{"task_id": "SimdBench_82_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nbool triples_sum_to_zero_simd(std::vector<int> l) {\n    int n = l.size();\n    if (n < 3) return false;\n\n    for (int i = 0; i < n - 2; ++i) {\n        __m256i vi = _mm256_set1_epi32(l[i]);\n        for (int j = i + 1; j < n - 1; j += 8) {\n            __m256i vj = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&l[j]));\n            __m256i vk = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&l[j + 1]));\n\n            __m256i vij = _mm256_add_epi32(vi, vj);\n            __m256i vik = _mm256_add_epi32(vi, vk);\n\n            for (int k = j + 1; k < n; ++k) {\n                __m256i vk_single = _mm256_set1_epi32(l[k]);\n                __m256i vij_k = _mm256_add_epi32(vij, vk_single);\n                __m256i vik_k = _mm256_add_epi32(vik, vk_single);\n\n                __m256i cmp1 = _mm256_cmpeq_epi32(vij_k, _mm256_setzero_si256());\n                __m256i cmp2 = _mm256_cmpeq_epi32(vik_k, _mm256_setzero_si256());\n\n                if (_mm256_movemask_epi8(cmp1) != 0 || _mm256_movemask_epi8(cmp2) != 0) {\n                    return true;\n                }\n            }\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_82_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nbool triples_sum_to_zero_simd(std::vector<int> l) {\n    int n = l.size();\n    if (n < 3) return false;\n\n    for (int i = 0; i < n - 2; ++i) {\n        __m256i vi = _mm256_set1_epi32(l[i]);\n        for (int j = i + 1; j < n - 1; j += 8) {\n            __m256i vj = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&l[j]));\n            __m256i vk = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&l[j + 1]));\n            __m256i vij = _mm256_add_epi32(vi, vj);\n            __m256i vik = _mm256_add_epi32(vi, vk);\n            __m256i vnegk = _mm256_negate_epi32(vk);\n            __m256i vcmp1 = _mm256_cmpeq_epi32(vij, vnegk);\n            __m256i vcmp2 = _mm256_cmpeq_epi32(vik, _mm256_negate_epi32(_mm256_loadu_si256(reinterpret_cast<const __m256i*>(&l[j + 2]))));\n            __m256i vcmp3 = _mm256_cmpeq_epi32(vik, _mm256_negate_epi32(_mm256_loadu_si256(reinterpret_cast<const __m256i*>(&l[j + 3]))));\n            __m256i vcmp4 = _mm256_cmpeq_epi32(vik, _mm256_negate_epi32(_mm256_loadu_si256(reinterpret_cast<const __m256i*>(&l[j + 4]))));\n            __m256i vcmp5 = _mm256_cmpeq_epi32(vik, _mm256_negate_epi32(_mm256_loadu_si256(reinterpret_cast<const __m256i*>(&l[j + 5]))));\n            __m256i vcmp6 = _mm256_cmpeq_epi32(vik, _mm256_negate_epi32(_mm256_loadu_si256(reinterpret_cast<const __m256i*>(&l[j + 6]))));\n            __m256i vcmp7 = _mm256_cmpeq_epi32(vik, _mm256_negate_epi32(_mm256_loadu_si256(reinterpret_cast<const __m256i*>(&l[j + 7]))));\n\n            if (_mm256_movemask_epi8(vcmp1) || _mm256_movemask_epi8(vcmp2) || _mm256_movemask_epi8(vcmp3) ||\n                _mm256_movemask_epi8(vcmp4) || _mm256_movemask_epi8(vcmp5) || _mm256_movemask_epi8(vcmp6) ||\n                _mm256_movemask_epi8(vcmp7)) {\n                return true;\n            }\n        }\n        for (int j = std::max(i + 1, n - 8); j < n - 1; ++j) {\n            for (int k = j + 1; k < n; ++k) {\n                if (l[i] + l[j] + l[k] == 0) {\n                    return true;\n                }\n            }\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_82_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nbool triples_sum_to_zero_simd(std::vector<int> l) {\n    int n = l.size();\n    if (n < 3) return false;\n\n    for (int i = 0; i < n - 2; ++i) {\n        __m256i vi = _mm256_set1_epi32(l[i]);\n        for (int j = i + 1; j < n - 1; ++j) {\n            __m256i vj = _mm256_set1_epi32(l[j]);\n            __m256i vk = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&l[j + 1]));\n            __m256i vsum = _mm256_add_epi32(_mm256_add_epi32(vi, vj), vk);\n            __m256i vzero = _mm256_setzero_si256();\n            __m256i vcmp = _mm256_cmpeq_epi32(vsum, vzero);\n            int mask = _mm256_movemask_epi8(vcmp);\n            if (mask != 0) {\n                for (int k = 0; k < 8; ++k) {\n                    if ((mask & (0xFF << (k * 4))) && (j + 1 + k < n)) {\n                        if (l[i] + l[j] + l[j + 1 + k] == 0) {\n                            return true;\n                        }\n                    }\n                }\n            }\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_82_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nbool triples_sum_to_zero_simd(std::vector<int> l) {\n    int n = l.size();\n    if (n < 3) return false;\n\n    for (int i = 0; i < n - 2; ++i) {\n        __m256i vi = _mm256_set1_epi32(l[i]);\n        for (int j = i + 1; j < n - 1; j += 8) {\n            __m256i vj = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&l[j]));\n            __m256i vk = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&l[j + 1]));\n            __m256i vij = _mm256_add_epi32(vi, vj);\n            __m256i vik = _mm256_add_epi32(vi, vk);\n            __m256i vijk = _mm256_add_epi32(vij, vk);\n\n            __m256i zero = _mm256_setzero_si256();\n            __m256i mask = _mm256_cmpeq_epi32(vijk, zero);\n\n            if (_mm256_movemask_epi8(mask) != 0) {\n                return true;\n            }\n        }\n        for (int j = std::max(i + 1, n - 8); j < n - 1; ++j) {\n            for (int k = j + 1; k < n; ++k) {\n                if (l[i] + l[j] + l[k] == 0) {\n                    return true;\n                }\n            }\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_82_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nbool triples_sum_to_zero_simd(std::vector<int> l) {\n    int n = l.size();\n    if (n < 3) return false;\n\n    for (int i = 0; i < n - 2; ++i) {\n        __m256i vi = _mm256_set1_epi32(l[i]);\n        for (int j = i + 1; j < n - 1; j += 8) {\n            __m256i vj = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&l[j]));\n            __m256i vk = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&l[j + 1]));\n            __m256i vij = _mm256_add_epi32(vi, vj);\n            __m256i vik = _mm256_add_epi32(vi, vk);\n            __m256i vijk = _mm256_add_epi32(vij, vk);\n\n            int mask = _mm256_movemask_epi8(_mm256_cmpeq_epi32(vijk, _mm256_setzero_si256()));\n            if (mask != 0) {\n                for (int k = 0; k < 8; ++k) {\n                    if ((mask & (1 << (k * 4))) && (j + k + 1 != i)) {\n                        return true;\n                    }\n                }\n            }\n\n            vjk = _mm256_add_epi32(vj, vk);\n            vijk = _mm256_add_epi32(vij, vjk);\n\n            mask = _mm256_movemask_epi8(_mm256_cmpeq_epi32(vijk, _mm256_setzero_si256()));\n            if (mask != 0) {\n                for (int k = 0; k < 8; ++k) {\n                    if ((mask & (1 << (k * 4))) && (j + k + 1 != i)) {\n                        return true;\n                    }\n                }\n            }\n        }\n        for (int j = std::max(i + 1, n - (n % 8)); j < n - 1; ++j) {\n            for (int k = j + 1; k < n; ++k) {\n                if (l[i] + l[j] + l[k] == 0) {\n                    return true;\n                }\n            }\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_83_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> incr_list_simd(std::vector<int> l) {\n    int n = l.size();\n    std::vector<int> result(n);\n\n    int i = 0;\n    __m256i increment = _mm256_set1_epi32(1);\n\n    for (; i <= n - 8; i += 8) {\n        __m256i vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&l[i]));\n        vec = _mm256_add_epi32(vec, increment);\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(&result[i]), vec);\n    }\n\n    for (; i < n; ++i) {\n        result[i] = l[i] + 1;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_83_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> incr_list_simd(std::vector<int> l) {\n    int n = l.size();\n    std::vector<int> result(n);\n    int* input = l.data();\n    int* output = result.data();\n    int i = 0;\n\n    __m256i increment = _mm256_set1_epi32(1);\n\n    for (; i <= n - 8; i += 8) {\n        __m256i vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(input + i));\n        vec = _mm256_add_epi32(vec, increment);\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(output + i), vec);\n    }\n\n    for (; i < n; ++i) {\n        output[i] = input[i] + 1;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_83_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> incr_list_simd(std::vector<int> l) {\n    int n = l.size();\n    std::vector<int> result(n);\n\n    int i = 0;\n    __m256i increment = _mm256_set1_epi32(1);\n\n    for (; i <= n - 8; i += 8) {\n        __m256i vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&l[i]));\n        vec = _mm256_add_epi32(vec, increment);\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(&result[i]), vec);\n    }\n\n    for (; i < n; ++i) {\n        result[i] = l[i] + 1;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_83_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> incr_list_simd(std::vector<int> l) {\n    int n = l.size();\n    std::vector<int> result(n);\n\n    int i = 0;\n    __m256i increment = _mm256_set1_epi32(1);\n\n    for (; i <= n - 8; i += 8) {\n        __m256i vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&l[i]));\n        vec = _mm256_add_epi32(vec, increment);\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(&result[i]), vec);\n    }\n\n    for (; i < n; ++i) {\n        result[i] = l[i] + 1;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_83_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> incr_list_simd(std::vector<int> l) {\n    int n = l.size();\n    std::vector<int> result(n);\n\n    int i = 0;\n    __m256i increment = _mm256_set1_epi32(1);\n\n    for (; i <= n - 8; i += 8) {\n        __m256i vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&l[i]));\n        vec = _mm256_add_epi32(vec, increment);\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(&result[i]), vec);\n    }\n\n    for (; i < n; ++i) {\n        result[i] = l[i] + 1;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_84_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nbool pairs_sum_to_zero_simd(const std::vector<int>& l) {\n    int n = l.size();\n    if (n < 2) return false;\n\n    __m256i vec1, vec2, neg_vec1, zero_vec = _mm256_setzero_si256();\n\n    for (int i = 0; i < n; i += 8) {\n        vec1 = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&l[i]));\n        neg_vec1 = _mm256_negate_epi32(vec1);\n\n        for (int j = i + 8; j < n; j += 8) {\n            vec2 = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&l[j]));\n\n            __m256i cmp1 = _mm256_cmpeq_epi32(vec1, neg_vec1);\n            __m256i cmp2 = _mm256_cmpeq_epi32(vec2, neg_vec1);\n\n            if (!_mm256_testz_si256(cmp1, cmp1) || !_mm256_testz_si256(cmp2, cmp2)) {\n                return true;\n            }\n        }\n\n        // Check for pairs within the same chunk\n        __m256i cmp_within = _mm256_cmpeq_epi32(vec1, neg_vec1);\n        if (!_mm256_testz_si256(cmp_within, cmp_within)) {\n            return true;\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_84_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nbool pairs_sum_to_zero_simd(const std::vector<int>& l) {\n    int n = l.size();\n    if (n < 2) return false;\n\n    __m256i zero = _mm256_setzero_si256();\n\n    for (int i = 0; i < n; ++i) {\n        __m256i vec1 = _mm256_set1_epi32(l[i]);\n        for (int j = i + 1; j <= n - 8; j += 8) {\n            __m256i vec2 = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&l[j]));\n            __m256i sum = _mm256_add_epi32(vec1, vec2);\n            __m256i mask = _mm256_cmpeq_epi32(sum, zero);\n            if (!_mm256_testz_si256(mask, mask)) {\n                return true;\n            }\n        }\n        for (int j = n - (n % 8); j < n; ++j) {\n            if (l[i] + l[j] == 0) {\n                return true;\n            }\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_84_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nbool pairs_sum_to_zero_simd(const std::vector<int>& l) {\n    int n = l.size();\n    if (n < 2) return false;\n\n    __m256i zero = _mm256_setzero_si256();\n\n    for (int i = 0; i < n; ++i) {\n        __m256i vec1 = _mm256_set1_epi32(l[i]);\n        for (int j = i + 1; j <= n - 8; j += 8) {\n            __m256i vec2 = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&l[j]));\n            __m256i sum = _mm256_add_epi32(vec1, vec2);\n            __m256i mask = _mm256_cmpeq_epi32(sum, zero);\n            if (!_mm256_testz_si256(mask, mask)) {\n                return true;\n            }\n        }\n        for (int j = n - (n % 8); j < n; ++j) {\n            if (l[i] + l[j] == 0) {\n                return true;\n            }\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_84_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nbool pairs_sum_to_zero_simd(const std::vector<int>& l) {\n    int n = l.size();\n    if (n < 2) return false;\n\n    __m256i vec1, vec2, neg_vec1, zero_vec = _mm256_setzero_si256();\n\n    for (int i = 0; i < n; i += 8) {\n        vec1 = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&l[i]));\n        neg_vec1 = _mm256_negate_epi32(vec1);\n\n        for (int j = i + 8; j < n; j += 8) {\n            vec2 = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&l[j]));\n\n            __m256i cmp1 = _mm256_cmpeq_epi32(vec1, neg_vec1);\n            __m256i cmp2 = _mm256_cmpeq_epi32(vec2, neg_vec1);\n\n            if (!_mm256_testz_si256(cmp1, cmp1) || !_mm256_testz_si256(cmp2, cmp2)) {\n                return true;\n            }\n        }\n\n        // Check for pairs within the same chunk\n        __m256i cmp_within = _mm256_cmpeq_epi32(vec1, neg_vec1);\n        if (!_mm256_testz_si256(cmp_within, cmp_within)) {\n            return true;\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_84_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nbool pairs_sum_to_zero_simd(const std::vector<int>& l) {\n    int n = l.size();\n    if (n < 2) return false;\n\n    __m256i zero = _mm256_setzero_si256();\n\n    for (int i = 0; i < n; ++i) {\n        __m256i vec1 = _mm256_set1_epi32(l[i]);\n        for (int j = i + 1; j <= n - 8; j += 8) {\n            __m256i vec2 = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&l[j]));\n            __m256i sum = _mm256_add_epi32(vec1, vec2);\n            __m256i mask = _mm256_cmpeq_epi32(sum, zero);\n            if (!_mm256_testz_si256(mask, mask)) {\n                return true;\n            }\n        }\n        for (int j = n - (n % 8); j < n; ++j) {\n            if (l[i] + l[j] == 0) {\n                return true;\n            }\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_85_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n#include <algorithm>\n\nstd::string change_base_simd(int64_t x, int8_t base) {\n    if (base < 2 || base > 9) return \"\";\n\n    char buffer[65];\n    int pos = 64;\n    buffer[pos] = '\\0';\n\n    __m256i divisors = _mm256_set1_epi32(base);\n    __m256i remainders;\n    __m256i quotients;\n\n    while (x > 0) {\n        __m256i values = _mm256_setr_epi32(x & 0xFFFFFFFF, (x >> 32) & 0xFFFFFFFF, 0, 0, 0, 0, 0, 0);\n        quotients = _mm256_div_epi32(values, divisors);\n        remainders = _mm256_sub_epi32(values, _mm256_mullo_epi32(quotients, divisors));\n\n        int32_t rem_array[8];\n        _mm256_storeu_si256((__m256i*)rem_array, remainders);\n\n        for (int i = 0; i < 2 && x > 0; ++i) {\n            buffer[--pos] = '0' + rem_array[i];\n            x = _mm256_extract_epi32(quotients, i);\n        }\n    }\n\n    return std::string(buffer + pos);\n}\n```"}
{"task_id": "SimdBench_85_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n#include <algorithm>\n\nstd::string change_base_simd(int64_t x, int8_t base) {\n    if (base < 2 || base > 9) return \"\";\n\n    char buffer[65];\n    int pos = 64;\n    buffer[pos] = '\\0';\n\n    __m256i divisors = _mm256_set1_epi64x(base);\n    __m256i remainders;\n    __m256i quotients;\n\n    while (x > 0) {\n        __m256i num = _mm256_set1_epi64x(x);\n        quotients = _mm256_div_epi64(num, divisors);\n        remainders = _mm256_sub_epi64(num, _mm256_mullo_epi64(quotients, divisors));\n\n        int8_t rem[4];\n        _mm_storeu_si128((__m128i*)rem, _mm256_castsi256_si128(remainders));\n        for (int i = 0; i < 4; ++i) {\n            if (pos > 0) buffer[--pos] = '0' + rem[i];\n        }\n\n        x = _mm256_extract_epi64(quotients, 0);\n    }\n\n    return std::string(buffer + pos);\n}\n```"}
{"task_id": "SimdBench_85_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n#include <algorithm>\n\nstd::string change_base_simd(int64_t x, int8_t base) {\n    if (base < 2 || base > 9) return \"\";\n\n    char buffer[65];\n    int pos = 64;\n    buffer[pos] = '\\0';\n\n    __m256i divisors = _mm256_set1_epi64x(base);\n    __m256i remainders;\n    __m256i zero = _mm256_setzero_si256();\n    __m256i ones = _mm256_set1_epi64x(1);\n\n    while (x > 0) {\n        __m256i num = _mm256_set1_epi64x(x);\n        remainders = _mm256_rem_epu64(num, divisors);\n        num = _mm256_div_epu64(num, divisors);\n\n        __m256i mask = _mm256_cmpgt_epi64(zero, _mm256_sub_epi64(num, ones));\n        x = _mm256_extract_epi64(_mm256_blendv_epi8(num, zero, mask), 0);\n\n        for (int i = 0; i < 4; ++i) {\n            int remainder = _mm256_extract_epi64(remainders, i);\n            if (pos > 0) buffer[--pos] = '0' + remainder;\n        }\n    }\n\n    return std::string(buffer + pos);\n}\n```"}
{"task_id": "SimdBench_85_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n#include <algorithm>\n\nstd::string change_base_simd(int64_t x, int8_t base) {\n    if (base < 2 || base > 9) return \"\";\n\n    char buffer[65];\n    int pos = 64;\n    buffer[pos] = '\\0';\n\n    __m256i divisors = _mm256_set1_epi32(base);\n    __m256i remainders;\n    __m256i quotients;\n    __m256i values = _mm256_set_epi32(0, 0, 0, 0, 0, 0, 0, static_cast<int32_t>(x));\n\n    while (_mm256_movemask_epi8(_mm256_cmpgt_epi32(values, _mm256_setzero_si256())) != 0) {\n        remainders = _mm256_rem_epi32(values, divisors);\n        quotients = _mm256_div_epi32(values, divisors);\n        values = quotients;\n\n        __m128i low_remainders = _mm256_extracti128_si256(remainders, 0);\n        __m128i high_remainders = _mm256_extracti128_si256(remainders, 1);\n\n        int32_t low_array[4], high_array[4];\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(low_array), low_remainders);\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(high_array), high_remainders);\n\n        for (int i = 0; i < 4; ++i) {\n            if (low_array[i] != 0) buffer[--pos] = '0' + low_array[i];\n            if (high_array[i] != 0) buffer[--pos] = '0' + high_array[i];\n        }\n    }\n\n    return std::string(buffer + pos);\n}\n```"}
{"task_id": "SimdBench_85_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n#include <algorithm>\n\nstd::string change_base_simd(int64_t x, int8_t base) {\n    if (base < 2 || base > 9) return \"\";\n\n    char buffer[65];\n    int pos = 64;\n    buffer[pos] = '\\0';\n\n    __m256i divisors = _mm256_set1_epi64x(base);\n    __m256i remainders;\n    __m256i quotients;\n\n    while (x > 0) {\n        __m256i num = _mm256_set1_epi64x(x);\n        quotients = _mm256_div_epi64(num, divisors);\n        remainders = _mm256_sub_epi64(num, _mm256_mullo_epi64(quotients, divisors));\n\n        int8_t rem[4];\n        _mm_storeu_si128((__m128i*)rem, _mm256_castsi256_si128(remainders));\n        for (int i = 0; i < 4 && x > 0; ++i) {\n            buffer[--pos] = '0' + rem[i];\n            x = _mm256_extract_epi64(quotients, i);\n        }\n    }\n\n    return std::string(buffer + pos);\n}\n```"}
{"task_id": "SimdBench_86_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nbool is_palindrome_simd(std::string text) {\n    int n = text.size();\n    if (n <= 1) return true;\n\n    const char* str = text.c_str();\n    int i = 0, j = n - 1;\n\n    while (i < j) {\n        __m256i left = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(str + i));\n        __m256i right = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(str + j - 31));\n\n        // Reverse the right part\n        __m256i reversed_right = _mm256_shuffle_epi8(right, _mm256_setr_epi8(31, 30, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 0));\n\n        // Compare left and reversed right\n        __m256i cmp = _mm256_cmpeq_epi8(left, reversed_right);\n        uint32_t mask = _mm256_movemask_epi8(cmp);\n\n        if (mask != 0xFFFFFFFF) {\n            // Find the first mismatch\n            int pos = __builtin_ctz(~mask);\n            if (str[i + pos] != str[j - pos]) return false;\n        }\n\n        i += 32;\n        j -= 32;\n    }\n\n    // Check remaining characters\n    while (i < j) {\n        if (str[i] != str[j]) return false;\n        i++;\n        j--;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_86_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nbool is_palindrome_simd(std::string text) {\n    int n = text.size();\n    if (n <= 1) return true;\n\n    const char* str = text.c_str();\n    int i = 0, j = n - 1;\n\n    while (i < j) {\n        __m256i left = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(str + i));\n        __m256i right = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(str + j - 31));\n\n        // Reverse the right part\n        __m256i reversed_right = _mm256_shuffle_epi8(right, _mm256_setr_epi8(31, 30, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 0));\n\n        // Compare left and reversed right\n        __m256i cmp = _mm256_cmpeq_epi8(left, reversed_right);\n        uint32_t mask = _mm256_movemask_epi8(cmp);\n\n        if (mask != 0xFFFFFFFF) {\n            // Find the first mismatch\n            int pos = __builtin_ctz(~mask);\n            if (str[i + pos] != str[j - pos]) return false;\n        }\n\n        i += 32;\n        j -= 32;\n    }\n\n    // Check remaining characters\n    while (i < j) {\n        if (str[i] != str[j]) return false;\n        i++;\n        j--;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_86_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nbool is_palindrome_simd(std::string text) {\n    int n = text.size();\n    if (n <= 1) return true;\n\n    const char* str = text.c_str();\n    int i = 0, j = n - 1;\n\n    while (i < j) {\n        __m256i left = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(str + i));\n        __m256i right = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(str + j - 31));\n\n        right = _mm256_shuffle_epi8(right, _mm256_setr_epi8(31, 30, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 0));\n\n        __m256i cmp = _mm256_cmpeq_epi8(left, right);\n        uint32_t mask = _mm256_movemask_epi8(cmp);\n\n        if (mask != 0xFFFFFFFF) {\n            int offset = __builtin_ctz(~mask);\n            return str[i + offset] == str[j - offset];\n        }\n\n        i += 32;\n        j -= 32;\n    }\n\n    while (i < j) {\n        if (str[i] != str[j]) return false;\n        i++;\n        j--;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_86_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nbool is_palindrome_simd(std::string text) {\n    int n = text.size();\n    if (n <= 1) return true;\n\n    const char* str = text.c_str();\n    int i = 0, j = n - 1;\n\n    while (i < j) {\n        __m256i left = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(str + i));\n        __m256i right = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(str + j - 31));\n\n        __m256i reversed_right = _mm256_shuffle_epi8(right, _mm256_setr_epi8(31, 30, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 0));\n\n        __m256i cmp = _mm256_cmpeq_epi8(left, reversed_right);\n        uint32_t mask = _mm256_movemask_epi8(cmp);\n\n        if (mask != 0xFFFFFFFF) {\n            int offset = __builtin_ctz(~mask);\n            return str[i + offset] == str[j - offset];\n        }\n\n        i += 32;\n        j -= 32;\n    }\n\n    while (i < j) {\n        if (str[i] != str[j]) return false;\n        i++;\n        j--;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_86_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nbool is_palindrome_simd(std::string text) {\n    int n = text.size();\n    if (n <= 1) return true;\n\n    const char* str = text.c_str();\n    int i = 0, j = n - 1;\n\n    while (i < j) {\n        __m256i left = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(str + i));\n        __m256i right = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(str + j - 31));\n\n        // Reverse the right part\n        __m256i reversed_right = _mm256_shuffle_epi8(right, _mm256_setr_epi8(31, 30, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 0));\n\n        // Compare left and reversed right\n        __m256i cmp = _mm256_cmpeq_epi8(left, reversed_right);\n        uint32_t mask = _mm256_movemask_epi8(cmp);\n\n        if (mask != 0xFFFFFFFF) {\n            // Find the first mismatch\n            int pos = __builtin_ctz(~mask);\n            if (str[i + pos] != str[j - pos]) return false;\n        }\n\n        i += 32;\n        j -= 32;\n    }\n\n    // Check remaining characters\n    while (i < j) {\n        if (str[i] != str[j]) return false;\n        i++;\n        j--;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_87_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string decode_shift_simd(std::string s) {\n    std::string out(s.length(), ' ');\n    const __m256i shift = _mm256_set1_epi8(5);\n    const __m256i a = _mm256_set1_epi8('a');\n    const __m256i z = _mm256_set1_epi8('z');\n    const __m256i alphabet_size = _mm256_set1_epi8(26);\n\n    size_t i = 0;\n    for (; i <= s.length() - 32; i += 32) {\n        __m256i vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(s.data() + i));\n        vec = _mm256_sub_epi8(vec, shift);\n        __m256i mask = _mm256_cmpgt_epi8(a, vec);\n        vec = _mm256_add_epi8(vec, _mm256_and_si256(mask, alphabet_size));\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(out.data() + i), vec);\n    }\n\n    for (; i < s.length(); ++i) {\n        int w = ((int)s[i] - 5 - (int)'a') % 26;\n        if (w < 0) w += 26;\n        out[i] = (char)(w + 'a');\n    }\n\n    return out;\n}\n```"}
{"task_id": "SimdBench_87_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string decode_shift_simd(std::string s) {\n    std::string out(s.length(), ' ');\n    const __m256i shift = _mm256_set1_epi8(-5);\n    const __m256i a = _mm256_set1_epi8('a');\n    const __m256i z = _mm256_set1_epi8('z');\n    const __m256i wrap = _mm256_set1_epi8(26);\n\n    size_t i = 0;\n    for (; i <= s.length() - 32; i += 32) {\n        __m256i vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(s.data() + i));\n        vec = _mm256_sub_epi8(vec, shift);\n        __m256i lt_a = _mm256_cmpgt_epi8(a, vec);\n        vec = _mm256_add_epi8(vec, _mm256_and_si256(lt_a, wrap));\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(out.data() + i), vec);\n    }\n\n    for (; i < s.length(); ++i) {\n        int w = ((int)s[i] - 5 - (int)'a') % 26;\n        if (w < 0) w += 26;\n        out[i] = w + 'a';\n    }\n\n    return out;\n}\n```"}
{"task_id": "SimdBench_87_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string decode_shift_simd(std::string s) {\n    std::string out(s.length(), ' ');\n    const __m256i shift = _mm256_set1_epi8(5);\n    const __m256i a = _mm256_set1_epi8('a');\n    const __m256i z = _mm256_set1_epi8('z');\n    const __m256i alphabet_size = _mm256_set1_epi8(26);\n\n    size_t i = 0;\n    for (; i <= s.length() - 32; i += 32) {\n        __m256i vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(s.data() + i));\n        vec = _mm256_sub_epi8(vec, shift);\n        __m256i mask = _mm256_cmpgt_epi8(a, vec);\n        vec = _mm256_add_epi8(vec, _mm256_and_si256(mask, alphabet_size));\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(out.data() + i), vec);\n    }\n\n    for (; i < s.length(); ++i) {\n        int w = ((int)s[i] - 5 - (int)'a') % 26;\n        if (w < 0) w += 26;\n        out[i] = (char)(w + 'a');\n    }\n\n    return out;\n}\n```"}
{"task_id": "SimdBench_87_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string decode_shift_simd(std::string s) {\n    std::string out(s.length(), ' ');\n    const __m256i shift = _mm256_set1_epi8(5);\n    const __m256i a = _mm256_set1_epi8('a');\n    const __m256i z = _mm256_set1_epi8('z');\n    const __m256i alphabet_size = _mm256_set1_epi8(26);\n\n    size_t i = 0;\n    for (; i <= s.length() - 32; i += 32) {\n        __m256i vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(s.data() + i));\n        vec = _mm256_sub_epi8(vec, shift);\n        __m256i mask = _mm256_cmpgt_epi8(a, vec);\n        vec = _mm256_add_epi8(vec, _mm256_and_si256(mask, alphabet_size));\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(out.data() + i), vec);\n    }\n\n    for (; i < s.length(); ++i) {\n        int w = ((int)s[i] - 5 - (int)'a') % 26;\n        if (w < 0) w += 26;\n        out[i] = w + 'a';\n    }\n\n    return out;\n}\n```"}
{"task_id": "SimdBench_87_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string decode_shift_simd(std::string s) {\n    std::string out(s.length(), ' ');\n    const __m256i shift = _mm256_set1_epi8(5);\n    const __m256i a = _mm256_set1_epi8('a');\n    const __m256i z = _mm256_set1_epi8('z');\n    const __m256i alphabet_size = _mm256_set1_epi8(26);\n\n    size_t i = 0;\n    for (; i <= s.length() - 32; i += 32) {\n        __m256i input = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(s.data() + i));\n        __m256i sub_a = _mm256_sub_epi8(input, a);\n        __m256i sub_shift = _mm256_sub_epi8(sub_a, shift);\n        __m256i add_alphabet_size = _mm256_add_epi8(sub_shift, alphabet_size);\n        __m256i cmp = _mm256_cmpgt_epi8(sub_shift, _mm256_setzero_si256());\n        __m256i result = _mm256_blendv_epi8(add_alphabet_size, sub_shift, cmp);\n        __m256i final_result = _mm256_add_epi8(result, a);\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(out.data() + i), final_result);\n    }\n\n    for (; i < s.length(); ++i) {\n        int w = ((int)s[i] - 5 - (int)'a' + 26) % 26 + (int)'a';\n        out[i] = (char)w;\n    }\n\n    return out;\n}\n```"}
{"task_id": "SimdBench_88_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nbool below_threshold_simd(std::vector<int> l, int t) {\n    int n = l.size();\n    __m256i threshold = _mm256_set1_epi32(t);\n    __m256i ones = _mm256_set1_epi32(1);\n    __m256i result = _mm256_setzero_si256();\n\n    for (int i = 0; i <= n - 8; i += 8) {\n        __m256i vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&l[i]));\n        __m256i cmp = _mm256_cmpgt_epi32(vec, threshold);\n        result = _mm256_or_si256(result, cmp);\n    }\n\n    // Check remaining elements\n    for (int i = (n / 8) * 8; i < n; ++i) {\n        if (l[i] >= t) {\n            return false;\n        }\n    }\n\n    // Reduce result to a single boolean value\n    int mask = _mm256_movemask_epi8(result);\n    return mask == 0;\n}\n```"}
{"task_id": "SimdBench_88_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nbool below_threshold_simd(std::vector<int> l, int t) {\n    int n = l.size();\n    __m256i threshold = _mm256_set1_epi32(t);\n    __m256i ones = _mm256_set1_epi32(1);\n    __m256i result = _mm256_setzero_si256();\n\n    for (int i = 0; i <= n - 8; i += 8) {\n        __m256i vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&l[i]));\n        __m256i cmp = _mm256_cmpgt_epi32(vec, threshold);\n        result = _mm256_or_si256(result, cmp);\n    }\n\n    // Check remaining elements\n    for (int i = (n / 8) * 8; i < n; ++i) {\n        if (l[i] >= t) {\n            return false;\n        }\n    }\n\n    // Reduce result to a single boolean value\n    int mask = _mm256_movemask_epi8(result);\n    return mask == 0;\n}\n```"}
{"task_id": "SimdBench_88_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nbool below_threshold_simd(std::vector<int> l, int t) {\n    int n = l.size();\n    __m256i threshold = _mm256_set1_epi32(t);\n    __m256i ones = _mm256_set1_epi32(1);\n    __m256i result = _mm256_setzero_si256();\n\n    for (int i = 0; i <= n - 8; i += 8) {\n        __m256i vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&l[i]));\n        __m256i cmp = _mm256_cmpgt_epi32(vec, threshold);\n        result = _mm256_or_si256(result, cmp);\n    }\n\n    // Check remaining elements\n    for (int i = (n / 8) * 8; i < n; ++i) {\n        if (l[i] >= t) {\n            return false;\n        }\n    }\n\n    // Reduce result to a single boolean value\n    int mask = _mm256_movemask_epi8(result);\n    return mask == 0;\n}\n```"}
{"task_id": "SimdBench_88_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nbool below_threshold_simd(std::vector<int> l, int t) {\n    int n = l.size();\n    __m256i threshold = _mm256_set1_epi32(t);\n    __m256i ones = _mm256_set1_epi32(1);\n    __m256i result = _mm256_setzero_si256();\n\n    for (int i = 0; i <= n - 8; i += 8) {\n        __m256i vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&l[i]));\n        __m256i cmp = _mm256_cmpgt_epi32(vec, threshold);\n        result = _mm256_or_si256(result, cmp);\n    }\n\n    // Check remaining elements\n    for (int i = (n / 8) * 8; i < n; ++i) {\n        if (l[i] >= t) {\n            return false;\n        }\n    }\n\n    // Reduce result to a single boolean value\n    int mask = _mm256_movemask_epi8(result);\n    return mask == 0;\n}\n```"}
{"task_id": "SimdBench_88_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nbool below_threshold_simd(std::vector<int> l, int t) {\n    int n = l.size();\n    __m256i threshold = _mm256_set1_epi32(t);\n    __m256i ones = _mm256_set1_epi32(1);\n    __m256i result = _mm256_setzero_si256();\n\n    for (int i = 0; i <= n - 8; i += 8) {\n        __m256i vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&l[i]));\n        __m256i cmp = _mm256_cmpgt_epi32(vec, threshold);\n        result = _mm256_or_si256(result, cmp);\n    }\n\n    // Check remaining elements\n    for (int i = (n / 8) * 8; i < n; ++i) {\n        if (l[i] >= t) {\n            return false;\n        }\n    }\n\n    // Reduce result to a single boolean value\n    int mask = _mm256_movemask_epi8(result);\n    return mask == 0;\n}\n```"}
{"task_id": "SimdBench_89_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nbool correct_bracketing_simd(std::string brackets) {\n    int len = brackets.size();\n    if (len == 0) return true;\n\n    __m256i balance = _mm256_setzero_si256();\n    __m256i open_bracket = _mm256_set1_epi8('<');\n    __m256i close_bracket = _mm256_set1_epi8('>');\n\n    for (int i = 0; i <= len - 32; i += 32) {\n        __m256i chunk = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(brackets.data() + i));\n        __m256i open_count = _mm256_cmpeq_epi8(chunk, open_bracket);\n        __m256i close_count = _mm256_cmpeq_epi8(chunk, close_bracket);\n\n        __m256i open_sum = _mm256_sub_epi8(_mm256_setzero_si256(), open_count);\n        balance = _mm256_add_epi8(balance, open_sum);\n        balance = _mm256_add_epi8(balance, close_count);\n\n        __m256i zero = _mm256_setzero_si256();\n        __m256i underflow = _mm256_cmpgt_epi8(zero, balance);\n        if (!_mm256_testz_si256(underflow, underflow)) {\n            return false;\n        }\n    }\n\n    int remaining = len % 32;\n    int balance_scalar = 0;\n    for (int i = len - remaining; i < len; ++i) {\n        if (brackets[i] == '<') {\n            balance_scalar--;\n        } else if (brackets[i] == '>') {\n            balance_scalar++;\n        }\n        if (balance_scalar < 0) {\n            return false;\n        }\n    }\n\n    __m256i sum = _mm256_sad_epu8(balance, _mm256_setzero_si256());\n    __m128i low = _mm256_castsi256_si128(sum);\n    __m128i high = _mm256_extracti128_si256(sum, 1);\n    low = _mm_add_epi32(low, high);\n    int total_balance = _mm_cvtsi128_si32(low);\n\n    return balance_scalar + total_balance == 0;\n}\n```"}
{"task_id": "SimdBench_89_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nbool correct_bracketing_simd(std::string brackets) {\n    int len = brackets.size();\n    if (len == 0) return true;\n\n    __m256i balance = _mm256_setzero_si256();\n    __m256i open_bracket = _mm256_set1_epi8('<');\n    __m256i close_bracket = _mm256_set1_epi8('>');\n\n    for (int i = 0; i <= len - 32; i += 32) {\n        __m256i chunk = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(brackets.c_str() + i));\n        __m256i open_count = _mm256_cmpeq_epi8(chunk, open_bracket);\n        __m256i close_count = _mm256_cmpeq_epi8(chunk, close_bracket);\n\n        __m256i open_sum = _mm256_sub_epi8(_mm256_setzero_si256(), open_count);\n        __m256i close_sum = close_count;\n\n        balance = _mm256_add_epi8(balance, _mm256_add_epi8(open_sum, close_sum));\n\n        __m256i zero = _mm256_setzero_si256();\n        if (_mm256_movemask_epi8(_mm256_cmpgt_epi8(zero, balance)) != 0) {\n            return false;\n        }\n    }\n\n    int remaining = len % 32;\n    int current_balance = 0;\n    for (int i = len - remaining; i < len; ++i) {\n        if (brackets[i] == '<') {\n            current_balance++;\n        } else if (brackets[i] == '>') {\n            current_balance--;\n        }\n        if (current_balance < 0) {\n            return false;\n        }\n    }\n\n    __m256i zero = _mm256_setzero_si256();\n    return _mm256_testz_si256(balance, balance) && current_balance == 0;\n}\n```"}
{"task_id": "SimdBench_89_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nbool correct_bracketing_simd(std::string brackets) {\n    int len = brackets.size();\n    if (len == 0) return true;\n\n    __m256i balance = _mm256_setzero_si256();\n    __m256i open_bracket = _mm256_set1_epi8('<');\n    __m256i close_bracket = _mm256_set1_epi8('>');\n\n    for (int i = 0; i <= len - 32; i += 32) {\n        __m256i chunk = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&brackets[i]));\n        __m256i open_count = _mm256_cmpeq_epi8(chunk, open_bracket);\n        __m256i close_count = _mm256_cmpeq_epi8(chunk, close_bracket);\n\n        __m256i open_sum = _mm256_sub_epi8(_mm256_setzero_si256(), open_count);\n        balance = _mm256_add_epi8(balance, open_sum);\n        balance = _mm256_add_epi8(balance, close_count);\n\n        __m256i zero = _mm256_setzero_si256();\n        __m256i underflow = _mm256_cmpgt_epi8(zero, balance);\n        if (!_mm256_testz_si256(underflow, underflow)) {\n            return false;\n        }\n    }\n\n    int remaining = len % 32;\n    int balance_scalar = 0;\n    for (int i = len - remaining; i < len; ++i) {\n        if (brackets[i] == '<') {\n            balance_scalar--;\n        } else if (brackets[i] == '>') {\n            balance_scalar++;\n        }\n        if (balance_scalar < 0) {\n            return false;\n        }\n    }\n\n    __m256i sum = _mm256_sad_epu8(balance, _mm256_setzero_si256());\n    __m128i low = _mm256_castsi256_si128(sum);\n    __m128i high = _mm256_extracti128_si256(sum, 1);\n    low = _mm_add_epi32(low, high);\n    int total_balance = _mm_cvtsi128_si32(low);\n\n    return balance_scalar + total_balance == 0;\n}\n```"}
{"task_id": "SimdBench_89_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nbool correct_bracketing_simd(std::string brackets) {\n    int len = brackets.size();\n    if (len == 0) return true;\n\n    __m256i balance = _mm256_setzero_si256();\n    __m256i open_bracket = _mm256_set1_epi8('<');\n    __m256i close_bracket = _mm256_set1_epi8('>');\n\n    for (int i = 0; i <= len - 32; i += 32) {\n        __m256i chunk = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&brackets[i]));\n        __m256i open_count = _mm256_cmpeq_epi8(chunk, open_bracket);\n        __m256i close_count = _mm256_cmpeq_epi8(chunk, close_bracket);\n\n        __m256i open_sum = _mm256_sub_epi8(_mm256_setzero_si256(), open_count);\n        __m256i close_sum = close_count;\n\n        balance = _mm256_add_epi8(balance, open_sum);\n        balance = _mm256_add_epi8(balance, close_sum);\n\n        __m256i zero = _mm256_setzero_si256();\n        __m256i underflow = _mm256_cmpgt_epi8(zero, balance);\n\n        if (!_mm256_testz_si256(underflow, underflow)) {\n            return false;\n        }\n    }\n\n    int remaining = len % 32;\n    int current_balance = 0;\n    for (int i = len - remaining; i < len; ++i) {\n        if (brackets[i] == '<') {\n            current_balance++;\n        } else if (brackets[i] == '>') {\n            current_balance--;\n        }\n        if (current_balance < 0) {\n            return false;\n        }\n    }\n\n    __m256i sum = _mm256_sad_epu8(balance, _mm256_setzero_si256());\n    __m128i low_sum = _mm256_castsi256_si128(sum);\n    __m128i high_sum = _mm256_extracti128_si256(sum, 1);\n    low_sum = _mm_add_epi32(low_sum, high_sum);\n    int total_balance = _mm_cvtsi128_si32(low_sum);\n\n    return total_balance == 0;\n}\n```"}
{"task_id": "SimdBench_89_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nbool correct_bracketing_simd(std::string brackets) {\n    int len = brackets.size();\n    if (len == 0) return true;\n\n    __m256i balance = _mm256_setzero_si256();\n    __m256i open_bracket = _mm256_set1_epi8('<');\n    __m256i close_bracket = _mm256_set1_epi8('>');\n\n    for (int i = 0; i <= len - 32; i += 32) {\n        __m256i chunk = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(brackets.c_str() + i));\n        __m256i open_count = _mm256_cmpeq_epi8(chunk, open_bracket);\n        __m256i close_count = _mm256_cmpeq_epi8(chunk, close_bracket);\n\n        __m256i open_sum = _mm256_sub_epi8(_mm256_setzero_si256(), open_count);\n        __m256i close_sum = close_count;\n\n        balance = _mm256_add_epi8(balance, _mm256_add_epi8(open_sum, close_sum));\n\n        __m256i zero = _mm256_setzero_si256();\n        if (_mm256_movemask_epi8(_mm256_cmpgt_epi8(zero, balance)) != 0) {\n            return false;\n        }\n    }\n\n    int remaining = len % 32;\n    int current_balance = 0;\n    for (int i = len - remaining; i < len; ++i) {\n        if (brackets[i] == '<') {\n            current_balance++;\n        } else if (brackets[i] == '>') {\n            current_balance--;\n        }\n        if (current_balance < 0) {\n            return false;\n        }\n    }\n\n    __m256i zero = _mm256_setzero_si256();\n    return _mm256_testz_si256(balance, balance) && current_balance == 0;\n}\n```"}
{"task_id": "SimdBench_90_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nbool correct_bracketing_simd(std::string brackets) {\n    int len = brackets.size();\n    if (len == 0) return true;\n\n    __m256i open_bracket = _mm256_set1_epi8('(');\n    __m256i close_bracket = _mm256_set1_epi8(')');\n    __m256i zero = _mm256_setzero_si256();\n    __m256i balance = _mm256_setzero_si256();\n\n    int i = 0;\n    for (; i <= len - 32; i += 32) {\n        __m256i chunk = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(brackets.data() + i));\n        __m256i open_count = _mm256_cmpeq_epi8(chunk, open_bracket);\n        __m256i close_count = _mm256_cmpeq_epi8(chunk, close_bracket);\n\n        __m256i open_sum = _mm256_sub_epi8(_mm256_set1_epi8(-1), open_count);\n        __m256i close_sum = _mm256_sub_epi8(_mm256_set1_epi8(-1), close_count);\n\n        balance = _mm256_add_epi8(balance, open_sum);\n        balance = _mm256_add_epi8(balance, close_sum);\n\n        __m256i underflow_check = _mm256_cmplt_epi8(balance, zero);\n        if (!_mm256_testz_si256(underflow_check, underflow_check)) {\n            return false;\n        }\n    }\n\n    int remaining_balance = 0;\n    for (; i < len; ++i) {\n        if (brackets[i] == '(') {\n            remaining_balance++;\n        } else if (brackets[i] == ')') {\n            remaining_balance--;\n        }\n        if (remaining_balance < 0) {\n            return false;\n        }\n    }\n\n    __m256i horizontal_sum = _mm256_sad_epu8(balance, zero);\n    int final_balance = _mm256_extract_epi16(horizontal_sum, 0) + _mm256_extract_epi16(horizontal_sum, 4);\n\n    return final_balance + remaining_balance == 0;\n}\n```"}
{"task_id": "SimdBench_90_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nbool correct_bracketing_simd(std::string brackets) {\n    int len = brackets.size();\n    if (len == 0) return true;\n\n    __m256i open_bracket = _mm256_set1_epi8('(');\n    __m256i close_bracket = _mm256_set1_epi8(')');\n    __m256i zero = _mm256_setzero_si256();\n    __m256i balance = _mm256_setzero_si256();\n\n    int i = 0;\n    for (; i <= len - 32; i += 32) {\n        __m256i chunk = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&brackets[i]));\n        __m256i open_count = _mm256_cmpeq_epi8(chunk, open_bracket);\n        __m256i close_count = _mm256_cmpeq_epi8(chunk, close_bracket);\n\n        __m256i open_sum = _mm256_sub_epi8(_mm256_set1_epi8(-1), open_count);\n        __m256i close_sum = _mm256_sub_epi8(close_count, zero);\n\n        balance = _mm256_add_epi8(balance, open_sum);\n        balance = _mm256_add_epi8(balance, close_sum);\n\n        __m256i underflow_check = _mm256_cmplt_epi8(balance, zero);\n        if (!_mm256_testz_si256(underflow_check, underflow_check)) {\n            return false;\n        }\n    }\n\n    int remaining_balance = 0;\n    int8_t* balance_ptr = (int8_t*)&balance;\n    for (int j = 0; j < 32; ++j) {\n        remaining_balance += balance_ptr[j];\n    }\n\n    for (; i < len; ++i) {\n        if (brackets[i] == '(') {\n            remaining_balance++;\n        } else if (brackets[i] == ')') {\n            remaining_balance--;\n        }\n        if (remaining_balance < 0) {\n            return false;\n        }\n    }\n\n    return remaining_balance == 0;\n}\n```"}
{"task_id": "SimdBench_90_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nbool correct_bracketing_simd(std::string brackets) {\n    int len = brackets.size();\n    if (len == 0) return true;\n\n    __m256i open_bracket = _mm256_set1_epi8('(');\n    __m256i close_bracket = _mm256_set1_epi8(')');\n    __m256i zero = _mm256_setzero_si256();\n    __m256i balance = _mm256_setzero_si256();\n\n    int i = 0;\n    for (; i <= len - 32; i += 32) {\n        __m256i chunk = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(brackets.data() + i));\n        __m256i open_count = _mm256_cmpeq_epi8(chunk, open_bracket);\n        __m256i close_count = _mm256_cmpeq_epi8(chunk, close_bracket);\n\n        __m256i open_sum = _mm256_sub_epi8(_mm256_set1_epi8(-1), open_count);\n        __m256i close_sum = _mm256_sub_epi8(_mm256_set1_epi8(-1), close_count);\n\n        balance = _mm256_add_epi8(balance, open_sum);\n        balance = _mm256_add_epi8(balance, close_sum);\n\n        __m256i underflow_check = _mm256_cmplt_epi8(balance, zero);\n        if (!_mm256_testz_si256(underflow_check, underflow_check)) {\n            return false;\n        }\n    }\n\n    int remaining_balance = 0;\n    for (; i < len; ++i) {\n        if (brackets[i] == '(') {\n            remaining_balance++;\n        } else if (brackets[i] == ')') {\n            remaining_balance--;\n        }\n        if (remaining_balance < 0) {\n            return false;\n        }\n    }\n\n    __m256i horizontal_sum = _mm256_sad_epu8(balance, zero);\n    int final_balance = _mm256_extract_epi16(horizontal_sum, 0) + _mm256_extract_epi16(horizontal_sum, 4);\n\n    return final_balance + remaining_balance == 0;\n}\n```"}
{"task_id": "SimdBench_90_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nbool correct_bracketing_simd(std::string brackets) {\n    int len = brackets.size();\n    if (len == 0) return true;\n\n    __m256i open_bracket = _mm256_set1_epi8('(');\n    __m256i close_bracket = _mm256_set1_epi8(')');\n    __m256i zero = _mm256_setzero_si256();\n    __m256i balance = _mm256_setzero_si256();\n\n    int i = 0;\n    for (; i <= len - 32; i += 32) {\n        __m256i chunk = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&brackets[i]));\n        __m256i open_count = _mm256_cmpeq_epi8(chunk, open_bracket);\n        __m256i close_count = _mm256_cmpeq_epi8(chunk, close_bracket);\n\n        __m256i open_sum = _mm256_sub_epi8(_mm256_set1_epi8(-1), open_count);\n        __m256i close_sum = _mm256_sub_epi8(close_count, zero);\n\n        balance = _mm256_add_epi8(balance, open_sum);\n        balance = _mm256_add_epi8(balance, close_sum);\n\n        __m256i underflow_check = _mm256_cmplt_epi8(balance, zero);\n        if (!_mm256_testz_si256(underflow_check, underflow_check)) {\n            return false;\n        }\n    }\n\n    int remaining_balance = 0;\n    for (; i < len; ++i) {\n        if (brackets[i] == '(') {\n            remaining_balance++;\n        } else if (brackets[i] == ')') {\n            remaining_balance--;\n        }\n        if (remaining_balance < 0) {\n            return false;\n        }\n    }\n\n    __m256i horizontal_sum = _mm256_sad_epu8(balance, zero);\n    int final_balance = _mm256_extract_epi16(horizontal_sum, 0) + _mm256_extract_epi16(horizontal_sum, 4);\n\n    return final_balance + remaining_balance == 0;\n}\n```"}
{"task_id": "SimdBench_90_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nbool correct_bracketing_simd(std::string brackets) {\n    int len = brackets.size();\n    if (len == 0) return true;\n\n    __m256i open_bracket = _mm256_set1_epi8('(');\n    __m256i close_bracket = _mm256_set1_epi8(')');\n    __m256i zero = _mm256_setzero_si256();\n    __m256i balance = _mm256_setzero_si256();\n\n    int i = 0;\n    for (; i <= len - 32; i += 32) {\n        __m256i chunk = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(brackets.data() + i));\n        __m256i open_count = _mm256_cmpeq_epi8(chunk, open_bracket);\n        __m256i close_count = _mm256_cmpeq_epi8(chunk, close_bracket);\n\n        __m256i open_sum = _mm256_sub_epi8(_mm256_set1_epi8(-1), open_count);\n        __m256i close_sum = _mm256_sub_epi8(_mm256_set1_epi8(-1), close_count);\n\n        balance = _mm256_add_epi8(balance, open_sum);\n        balance = _mm256_add_epi8(balance, close_sum);\n\n        __m256i underflow_check = _mm256_cmplt_epi8(balance, zero);\n        if (!_mm256_testz_si256(underflow_check, underflow_check)) {\n            return false;\n        }\n    }\n\n    int remaining_balance = 0;\n    for (; i < len; ++i) {\n        if (brackets[i] == '(') {\n            remaining_balance++;\n        } else if (brackets[i] == ')') {\n            remaining_balance--;\n        }\n        if (remaining_balance < 0) {\n            return false;\n        }\n    }\n\n    __m256i horizontal_sum = _mm256_sad_epu8(balance, zero);\n    int final_balance = _mm256_extract_epi16(horizontal_sum, 0) + _mm256_extract_epi16(horizontal_sum, 4);\n\n    return final_balance + remaining_balance == 0;\n}\n```"}
{"task_id": "SimdBench_91_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<float> derivative_simd(std::vector<float> xs){\n    std::vector<float> result;\n    if (xs.size() <= 1) return result;\n\n    int n = xs.size();\n    result.resize(n - 1);\n\n    __m256 mul = _mm256_set_ps(7.0f, 6.0f, 5.0f, 4.0f, 3.0f, 2.0f, 1.0f, 0.0f);\n    float* input = xs.data() + 1;\n    float* output = result.data();\n\n    for (int i = 0; i <= n - 9; i += 8) {\n        __m256 coeffs = _mm256_loadu_ps(input + i);\n        __m256 deriv = _mm256_mul_ps(coeffs, mul);\n        _mm256_storeu_ps(output + i, deriv);\n        mul = _mm256_add_ps(mul, _mm256_set1_ps(8.0f));\n    }\n\n    for (int i = (n - 9) > 0 ? (n - 9) : 0; i < n - 1; ++i) {\n        output[i] = input[i] * (i + 1);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_91_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<float> derivative_simd(std::vector<float> xs){\n    std::vector<float> result;\n    if (xs.size() <= 1) return result;\n\n    int n = xs.size();\n    result.resize(n - 1);\n\n    __m256 mul = _mm256_set_ps(7.0f, 6.0f, 5.0f, 4.0f, 3.0f, 2.0f, 1.0f, 0.0f);\n    float* input = xs.data() + 1;\n    float* output = result.data();\n\n    for (int i = 0; i <= n - 9; i += 8) {\n        __m256 coeffs = _mm256_loadu_ps(input + i);\n        __m256 deriv = _mm256_mul_ps(coeffs, mul);\n        _mm256_storeu_ps(output + i, deriv);\n        mul = _mm256_add_ps(mul, _mm256_set1_ps(8.0f));\n    }\n\n    for (int i = (n - 9) > 0 ? (n - 9) : 0; i < n - 1; ++i) {\n        result[i] = xs[i + 1] * (i + 1);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_91_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<float> derivative_simd(std::vector<float> xs){\n    std::vector<float> result;\n    if (xs.size() <= 1) return result;\n\n    int n = xs.size();\n    result.resize(n - 1);\n\n    __m256 mul = _mm256_set_ps(7.0f, 6.0f, 5.0f, 4.0f, 3.0f, 2.0f, 1.0f, 0.0f);\n    float* input = xs.data() + 1;\n    float* output = result.data();\n    int i = 0;\n\n    for (; i <= n - 9; i += 8) {\n        __m256 coeffs = _mm256_loadu_ps(input + i);\n        __m256 derived = _mm256_mul_ps(coeffs, mul);\n        _mm256_storeu_ps(output + i, derived);\n        mul = _mm256_add_ps(mul, _mm256_set1_ps(8.0f));\n    }\n\n    for (; i <= n - 2; ++i) {\n        output[i] = input[i] * (i + 1);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_91_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<float> derivative_simd(std::vector<float> xs){\n    std::vector<float> result;\n    if (xs.size() <= 1) return result;\n\n    int n = xs.size();\n    result.resize(n - 1);\n\n    __m256 mul = _mm256_set_ps(7.0f, 6.0f, 5.0f, 4.0f, 3.0f, 2.0f, 1.0f, 0.0f);\n    float* input = xs.data() + 1;\n    float* output = result.data();\n    int i = 0;\n\n    for (; i <= n - 9; i += 8) {\n        __m256 coeffs = _mm256_loadu_ps(input + i);\n        __m256 derived = _mm256_mul_ps(coeffs, mul);\n        _mm256_storeu_ps(output + i, derived);\n        mul = _mm256_add_ps(mul, _mm256_set1_ps(8.0f));\n    }\n\n    for (; i <= n - 2; ++i) {\n        output[i] = input[i] * (i + 1);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_91_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<float> derivative_simd(std::vector<float> xs){\n    std::vector<float> result;\n    if (xs.size() <= 1) return result;\n\n    int n = xs.size();\n    result.resize(n - 1);\n\n    __m256 mul = _mm256_set_ps(7.0f, 6.0f, 5.0f, 4.0f, 3.0f, 2.0f, 1.0f, 0.0f);\n    float* input = xs.data() + 1;\n    float* output = result.data();\n    int i = 0;\n\n    for (; i <= n - 9; i += 8) {\n        __m256 coeffs = _mm256_loadu_ps(input + i);\n        __m256 deriv = _mm256_mul_ps(coeffs, mul);\n        _mm256_storeu_ps(output + i, deriv);\n        mul = _mm256_add_ps(mul, _mm256_set1_ps(8.0f));\n    }\n\n    for (; i <= n - 2; i++) {\n        result[i] = xs[i + 1] * (i + 1);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_92_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n#include <cctype>\n\nint vowels_count_simd(const std::string& s) {\n    int count = 0;\n    const char* str = s.c_str();\n    int len = s.size();\n    int i = 0;\n\n    __m256i vowels1 = _mm256_setr_epi8('a', 'e', 'i', 'o', 'u', 'A', 'E', 'I', 'O', 'U', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n    __m256i vowels2 = _mm256_setr_epi8('y', 'Y', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n\n    while (i <= len - 32) {\n        __m256i chunk = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(str + i));\n        __m256i cmp1 = _mm256_cmpeq_epi8(chunk, vowels1);\n        __m256i cmp2 = _mm256_cmpeq_epi8(chunk, vowels2);\n        __m256i cmp = _mm256_or_si256(cmp1, cmp2);\n        count += _mm256_movemask_epi8(cmp) & 0xFFFFFFFF;\n        i += 32;\n    }\n\n    while (i < len - 16) {\n        __m256i chunk = _mm256_maskz_loadu_epi8(0xFFFF, reinterpret_cast<const __m256i*>(str + i));\n        __m256i cmp1 = _mm256_cmpeq_epi8(chunk, vowels1);\n        __m256i cmp2 = _mm256_cmpeq_epi8(chunk, vowels2);\n        __m256i cmp = _mm256_or_si256(cmp1, cmp2);\n        count += _mm256_movemask_epi8(cmp) & 0xFFFF;\n        i += 16;\n    }\n\n    while (i < len) {\n        if (str[i] == 'a' || str[i] == 'e' || str[i] == 'i' || str[i] == 'o' || str[i] == 'u' ||\n            str[i] == 'A' || str[i] == 'E' || str[i] == 'I' || str[i] == 'O' || str[i] == 'U') {\n            count++;\n        } else if (str[i] == 'y' || str[i] == 'Y') {\n            if (i == len - 1) {\n                count++;\n            }\n        }\n        i++;\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_92_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nint vowels_count_simd(std::string s) {\n    int len = s.length();\n    const char* str = s.c_str();\n    int count = 0;\n\n    __m256i vowels1 = _mm256_setr_epi8('a', 'e', 'i', 'o', 'u', 'A', 'E', 'I', 'O', 'U', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n    __m256i vowels2 = _mm256_setr_epi8('y', 'Y', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n\n    for (int i = 0; i <= len - 32; i += 32) {\n        __m256i chunk = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(str + i));\n        __m256i cmp1 = _mm256_cmpeq_epi8(chunk, vowels1);\n        __m256i cmp2 = _mm256_cmpeq_epi8(chunk, vowels2);\n        __m256i cmp_or = _mm256_or_si256(cmp1, cmp2);\n        count += _mm256_popcnt_u32(_mm256_movemask_epi8(cmp_or));\n    }\n\n    for (int i = len - (len % 32); i < len - 1; ++i) {\n        if (str[i] == 'a' || str[i] == 'e' || str[i] == 'i' || str[i] == 'o' || str[i] == 'u' ||\n            str[i] == 'A' || str[i] == 'E' || str[i] == 'I' || str[i] == 'O' || str[i] == 'U') {\n            count++;\n        }\n    }\n\n    if (len > 0 && (str[len - 1] == 'y' || str[len - 1] == 'Y')) {\n        count++;\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_92_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n#include <cctype>\n\nint vowels_count_simd(const std::string& s) {\n    int count = 0;\n    int len = s.length();\n    const char* str = s.c_str();\n\n    __m256i vowels1 = _mm256_setr_epi8('a', 'e', 'i', 'o', 'u', 'A', 'E', 'I', 'O', 'U', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n    __m256i vowels2 = _mm256_setr_epi8('y', 'Y', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n\n    int i = 0;\n    for (; i <= len - 32; i += 32) {\n        __m256i chunk = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(str + i));\n        __m256i cmp1 = _mm256_cmpeq_epi8(chunk, vowels1);\n        __m256i cmp2 = _mm256_cmpeq_epi8(chunk, vowels2);\n        __m256i cmp_or = _mm256_or_si256(cmp1, cmp2);\n        count += _mm256_popcnt_u32(_mm256_movemask_epi8(cmp_or));\n    }\n\n    for (; i < len; ++i) {\n        char c = std::tolower(str[i]);\n        if (c == 'a' || c == 'e' || c == 'i' || c == 'o' || c == 'u' || (c == 'y' && i == len - 1)) {\n            count++;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_92_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n#include <cctype>\n\nint vowels_count_simd(const std::string& s) {\n    const int len = s.length();\n    const char* str = s.c_str();\n    int count = 0;\n\n    __m256i vowels1 = _mm256_setr_epi8('a', 'e', 'i', 'o', 'u', 'A', 'E', 'I', 'O', 'U', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n    __m256i vowels2 = _mm256_setr_epi8('y', 'Y', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n\n    for (int i = 0; i <= len - 32; i += 32) {\n        __m256i chunk = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(str + i));\n        __m256i cmp1 = _mm256_cmpeq_epi8(chunk, vowels1);\n        __m256i cmp2 = _mm256_cmpeq_epi8(chunk, vowels2);\n        __m256i cmp_or = _mm256_or_si256(cmp1, cmp2);\n        count += _mm256_movemask_epi8(cmp_or) & 0xFFFFFFFF;\n    }\n\n    for (int i = (len / 32) * 32; i < len; ++i) {\n        char c = std::tolower(str[i]);\n        if (c == 'a' || c == 'e' || c == 'i' || c == 'o' || c == 'u' || (c == 'y' && i == len - 1)) {\n            count++;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_92_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n#include <cctype>\n\nint vowels_count_simd(const std::string& s) {\n    int count = 0;\n    const char* str = s.c_str();\n    int len = s.size();\n    int i = 0;\n\n    __m256i vowels1 = _mm256_setr_epi8('a', 'e', 'i', 'o', 'u', 'A', 'E', 'I', 'O', 'U', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n    __m256i vowels2 = _mm256_setr_epi8('y', 'Y', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n\n    while (i <= len - 32) {\n        __m256i chunk = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(str + i));\n        __m256i cmp1 = _mm256_cmpeq_epi8(chunk, vowels1);\n        __m256i cmp2 = _mm256_cmpeq_epi8(chunk, vowels2);\n        __m256i cmp = _mm256_or_si256(cmp1, cmp2);\n        count += _mm256_movemask_epi8(cmp) & 0xFFFFFFFF;\n        i += 32;\n    }\n\n    while (i < len - 16) {\n        __m256i chunk = _mm256_maskz_loadu_epi8(0xFFFF, reinterpret_cast<const __m256i*>(str + i));\n        __m256i cmp1 = _mm256_cmpeq_epi8(chunk, vowels1);\n        __m256i cmp2 = _mm256_cmpeq_epi8(chunk, vowels2);\n        __m256i cmp = _mm256_or_si256(cmp1, cmp2);\n        count += _mm256_movemask_epi8(cmp) & 0xFFFF;\n        i += 16;\n    }\n\n    for (; i < len; ++i) {\n        char c = str[i];\n        if (c == 'a' || c == 'e' || c == 'i' || c == 'o' || c == 'u' ||\n            c == 'A' || c == 'E' || c == 'I' || c == 'O' || c == 'U' ||\n            (c == 'y' || c == 'Y') && i == len - 1) {\n            count++;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_93_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nint digitSum_simd(std::string s) {\n    int sum = 0;\n    int len = s.length();\n    const char* str = s.c_str();\n\n    __m256i zero = _mm256_setzero_si256();\n    __m256i upper_bound = _mm256_set1_epi8('Z');\n    __m256i lower_bound = _mm256_set1_epi8('A');\n    __m256i ascii_sum = _mm256_setzero_si256();\n\n    for (int i = 0; i <= len - 32; i += 32) {\n        __m256i chunk = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(str + i));\n        __m256i mask = _mm256_and_si256(_mm256_cmpgt_epi8(chunk, lower_bound), _mm256_cmpgt_epi8(upper_bound, chunk));\n        __m256i upper_chars = _mm256_and_si256(chunk, mask);\n        ascii_sum = _mm256_add_epi8(ascii_sum, upper_chars);\n    }\n\n    __m128i high_half = _mm256_extracti128_si256(ascii_sum, 1);\n    __m128i low_half = _mm256_castsi256_si128(ascii_sum);\n    __m128i combined = _mm_add_epi16(low_half, high_half);\n\n    for (int i = 0; i < 8; ++i) {\n        sum += static_cast<int>(_mm_extract_epi16(combined, i));\n    }\n\n    for (int i = len & ~31; i < len; ++i) {\n        if (str[i] >= 'A' && str[i] <= 'Z') {\n            sum += static_cast<int>(str[i]);\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_93_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nint digitSum_simd(std::string s) {\n    int sum = 0;\n    const char* str = s.c_str();\n    size_t len = s.length();\n    size_t i = 0;\n\n    __m256i zero = _mm256_setzero_si256();\n    __m256i upper_bound = _mm256_set1_epi8('Z');\n    __m256i lower_bound = _mm256_set1_epi8('A');\n\n    while (len >= 32) {\n        __m256i chunk = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(str + i));\n        __m256i mask = _mm256_and_si256(_mm256_cmpgt_epi8(chunk, lower_bound), _mm256_cmpgt_epi8(upper_bound, chunk));\n        __m256i filtered = _mm256_and_si256(chunk, mask);\n        __m256i shuffled = _mm256_add_epi16(_mm256_maddubs_epi16(filtered, zero), _mm256_maddubs_epi16(_mm256_srli_si256(filtered, 8), zero));\n        __m256i summed = _mm256_add_epi16(shuffled, _mm256_srli_si256(shuffled, 8));\n        __m256i final_sum = _mm256_add_epi16(summed, _mm256_srli_si256(summed, 4));\n        int32_t result[8];\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(result), final_sum);\n        sum += result[0] + result[1] + result[2] + result[3];\n        i += 32;\n        len -= 32;\n    }\n\n    for (; i < len; ++i) {\n        if (str[i] >= 'A' && str[i] <= 'Z') {\n            sum += static_cast<int>(str[i]);\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_93_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nint digitSum_simd(std::string s) {\n    int sum = 0;\n    const char* str = s.c_str();\n    size_t len = s.length();\n    size_t i = 0;\n\n    __m256i zero = _mm256_setzero_si256();\n    __m256i upper_bound = _mm256_set1_epi8('Z');\n    __m256i lower_bound = _mm256_set1_epi8('A');\n\n    while (len >= 32) {\n        __m256i chunk = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(str + i));\n        __m256i mask = _mm256_and_si256(_mm256_cmpgt_epi8(chunk, lower_bound), _mm256_cmpgt_epi8(upper_bound, chunk));\n        __m256i filtered = _mm256_and_si256(chunk, mask);\n        __m256i shuffled = _mm256_add_epi16(_mm256_maddubs_epi16(filtered, zero), _mm256_maddubs_epi16(_mm256_srli_si256(filtered, 8), zero));\n        __m256i summed = _mm256_add_epi16(shuffled, _mm256_srli_si256(shuffled, 8));\n        __m256i final_sum = _mm256_add_epi16(summed, _mm256_srli_si256(summed, 4));\n        int32_t result = _mm256_extract_epi16(final_sum, 0) + _mm256_extract_epi16(final_sum, 4) + _mm256_extract_epi16(final_sum, 8) + _mm256_extract_epi16(final_sum, 12);\n        sum += result;\n        i += 32;\n        len -= 32;\n    }\n\n    for (; i < len; ++i) {\n        if (str[i] >= 'A' && str[i] <= 'Z') {\n            sum += static_cast<int>(str[i]);\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_93_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nint digitSum_simd(std::string s) {\n    int sum = 0;\n    int len = s.length();\n    const char* str = s.c_str();\n\n    __m256i zero = _mm256_setzero_si256();\n    __m256i upper_bound = _mm256_set1_epi8('Z');\n    __m256i lower_bound = _mm256_set1_epi8('A');\n    __m256i ascii_sum = _mm256_setzero_si256();\n\n    for (int i = 0; i <= len - 32; i += 32) {\n        __m256i chunk = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(str + i));\n        __m256i upper_mask = _mm256_cmpgt_epi8(chunk, lower_bound);\n        __m256i lower_mask = _mm256_cmpgt_epi8(upper_bound, chunk);\n        __m256i mask = _mm256_and_si256(upper_mask, lower_mask);\n        __m256i masked_chunk = _mm256_and_si256(chunk, mask);\n        ascii_sum = _mm256_add_epi8(ascii_sum, masked_chunk);\n    }\n\n    __m128i high_half = _mm256_extracti128_si256(ascii_sum, 1);\n    __m128i low_half = _mm256_castsi256_si128(ascii_sum);\n    low_half = _mm_add_epi8(low_half, high_half);\n\n    low_half = _mm_add_epi8(low_half, _mm_srli_si128(low_half, 8));\n    low_half = _mm_add_epi8(low_half, _mm_srli_si128(low_half, 4));\n    low_half = _mm_add_epi8(low_half, _mm_srli_si128(low_half, 2));\n    low_half = _mm_add_epi8(low_half, _mm_srli_si128(low_half, 1));\n\n    sum += _mm_extract_epi8(low_half, 0);\n\n    for (int i = (len & ~31); i < len; ++i) {\n        if (str[i] >= 'A' && str[i] <= 'Z') {\n            sum += static_cast<int>(str[i]);\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_93_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nint digitSum_simd(std::string s) {\n    int sum = 0;\n    const char* str = s.c_str();\n    size_t len = s.length();\n    size_t i = 0;\n\n    __m256i zero = _mm256_setzero_si256();\n    __m256i upper_bound = _mm256_set1_epi8('Z');\n    __m256i lower_bound = _mm256_set1_epi8('A');\n\n    while (len >= 32) {\n        __m256i chunk = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(str + i));\n        __m256i mask = _mm256_and_si256(_mm256_cmpgt_epi8(chunk, lower_bound), _mm256_cmpgt_epi8(upper_bound, chunk));\n        __m256i filtered = _mm256_and_si256(chunk, mask);\n        __m256i sum_chunk = _mm256_sad_epu8(filtered, zero);\n        __m128i sum_low = _mm256_castsi256_si128(sum_chunk);\n        __m128i sum_high = _mm256_extracti128_si256(sum_chunk, 1);\n        sum_low = _mm_add_epi32(sum_low, sum_high);\n        sum += _mm_cvtsi128_si32(sum_low) + _mm_extract_epi32(sum_low, 1);\n        i += 32;\n        len -= 32;\n    }\n\n    for (; i < len; ++i) {\n        if (str[i] >= 'A' && str[i] <= 'Z') {\n            sum += static_cast<int>(str[i]);\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_94_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <limits>\n\nstd::vector<int> pluck_simd(std::vector<int> arr) {\n    if (arr.empty()) return {};\n\n    int min_even = std::numeric_limits<int>::max();\n    int min_index = -1;\n    int n = arr.size();\n\n    const int* data = arr.data();\n    int i = 0;\n\n    __m256i min_even_vec = _mm256_set1_epi32(min_even);\n    __m256i min_index_vec = _mm256_set1_epi32(-1);\n    __m256i index_vec = _mm256_setr_epi32(0, 1, 2, 3, 4, 5, 6, 7);\n    __m256i increment = _mm256_set1_epi32(8);\n\n    for (; i <= n - 8; i += 8) {\n        __m256i vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(data + i));\n        __m256i mask = _mm256_and_si256(vec, _mm256_set1_epi32(1));\n        mask = _mm256_cmpeq_epi32(mask, _mm256_setzero_si256());\n\n        __m256i even_vec = _mm256_blendv_epi8(_mm256_set1_epi32(min_even), vec, mask);\n        __m256i index_mask = _mm256_cmplt_epi32(even_vec, min_even_vec);\n        min_even_vec = _mm256_min_epi32(min_even_vec, even_vec);\n        min_index_vec = _mm256_blendv_epi8(min_index_vec, index_vec, index_mask);\n\n        index_vec = _mm256_add_epi32(index_vec, increment);\n    }\n\n    int min_even_arr[8], min_index_arr[8];\n    _mm256_storeu_si256(reinterpret_cast<__m256i*>(min_even_arr), min_even_vec);\n    _mm256_storeu_si256(reinterpret_cast<__m256i*>(min_index_arr), min_index_vec);\n\n    for (int j = 0; j < 8; ++j) {\n        if (min_even_arr[j] < min_even) {\n            min_even = min_even_arr[j];\n            min_index = min_index_arr[j] + i - 8;\n        }\n    }\n\n    for (; i < n; ++i) {\n        if (arr[i] % 2 == 0 && arr[i] < min_even) {\n            min_even = arr[i];\n            min_index = i;\n        }\n    }\n\n    if (min_index == -1) return {};\n    return {min_even, min_index};\n}\n```"}
{"task_id": "SimdBench_94_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <limits>\n\nstd::vector<int> pluck_simd(std::vector<int> arr) {\n    if (arr.empty()) return {};\n\n    int min_even = std::numeric_limits<int>::max();\n    int min_index = -1;\n    int n = arr.size();\n\n    const __m256i even_mask = _mm256_set1_epi32(1);\n    const __m256i max_vec = _mm256_set1_epi32(min_even);\n\n    for (int i = 0; i < n; i += 8) {\n        __m256i vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&arr[i]));\n        __m256i is_even = _mm256_cmpeq_epi32(_mm256_and_si256(vec, even_mask), _mm256_setzero_si256());\n        __m256i even_vals = _mm256_blendv_epi8(max_vec, vec, is_even);\n\n        __m256i min_in_vec = _mm256_min_epi32(even_vals, max_vec);\n        int min_val = _mm256_extract_epi32(min_in_vec, 0);\n        for (int j = 0; j < 8 && i + j < n; ++j) {\n            int val = arr[i + j];\n            if ((val & 1) == 0 && val < min_even) {\n                min_even = val;\n                min_index = i + j;\n            }\n        }\n    }\n\n    if (min_index == -1) return {};\n    return {min_even, min_index};\n}\n```"}
{"task_id": "SimdBench_94_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <limits>\n\nstd::vector<int> pluck_simd(std::vector<int> arr) {\n    if (arr.empty()) return {};\n\n    int min_even = std::numeric_limits<int>::max();\n    int min_index = -1;\n    int n = arr.size();\n\n    const __m256i even_mask = _mm256_set1_epi32(1);\n    const __m256i max_vec = _mm256_set1_epi32(min_even);\n\n    for (int i = 0; i < n; i += 8) {\n        __m256i vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&arr[i]));\n        __m256i is_even = _mm256_cmpeq_epi32(_mm256_and_si256(vec, even_mask), _mm256_setzero_si256());\n        __m256i even_vals = _mm256_blendv_epi8(max_vec, vec, is_even);\n\n        __m256i min_in_vec = _mm256_min_epi32(even_vals, max_vec);\n        int min_val = _mm256_extract_epi32(min_in_vec, 0);\n        for (int j = 0; j < 8 && i + j < n; ++j) {\n            int val = arr[i + j];\n            if ((val & 1) == 0 && val < min_even) {\n                min_even = val;\n                min_index = i + j;\n            }\n        }\n    }\n\n    if (min_index == -1) return {};\n    return {min_even, min_index};\n}\n```"}
{"task_id": "SimdBench_94_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n#include <limits>\n\nstd::vector<int> pluck_simd(std::vector<int> arr) {\n    if (arr.empty()) return {};\n\n    int min_even = std::numeric_limits<int>::max();\n    int min_index = -1;\n    int n = arr.size();\n\n    const __m256i even_mask = _mm256_set1_epi32(1);\n    const __m256i max_vec = _mm256_set1_epi32(min_even);\n\n    for (int i = 0; i < n; i += 8) {\n        __m256i vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&arr[i]));\n        __m256i is_even = _mm256_cmpeq_epi32(_mm256_and_si256(vec, even_mask), _mm256_setzero_si256());\n        __m256i even_vals = _mm256_blendv_epi8(max_vec, vec, is_even);\n\n        __m256i min_in_vec = _mm256_min_epi32(even_vals, max_vec);\n        int min_val = _mm256_extract_epi32(min_in_vec, 0);\n        for (int j = 0; j < 8 && i + j < n; ++j) {\n            int val = arr[i + j];\n            if ((val & 1) == 0 && val < min_even) {\n                min_even = val;\n                min_index = i + j;\n            }\n        }\n    }\n\n    if (min_index == -1) return {};\n    return {min_even, min_index};\n}\n```"}
{"task_id": "SimdBench_94_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <limits>\n\nstd::vector<int> pluck_simd(std::vector<int> arr) {\n    if (arr.empty()) return {};\n\n    int min_even = std::numeric_limits<int>::max();\n    int min_index = -1;\n    int n = arr.size();\n\n    const __m256i even_mask = _mm256_set1_epi32(1);\n    const __m256i max_vec = _mm256_set1_epi32(min_even);\n\n    for (int i = 0; i < n; i += 8) {\n        __m256i vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&arr[i]));\n        __m256i is_even = _mm256_cmpeq_epi32(_mm256_and_si256(vec, even_mask), _mm256_setzero_si256());\n        __m256i even_vals = _mm256_blendv_epi8(max_vec, vec, is_even);\n\n        __m256i min_in_vec = _mm256_min_epi32(even_vals, max_vec);\n        int min_val = _mm256_extract_epi32(min_in_vec, 0);\n        for (int j = 0; j < 8 && i + j < n; ++j) {\n            int val = arr[i + j];\n            if ((val & 1) == 0 && val < min_even) {\n                min_even = val;\n                min_index = i + j;\n            }\n        }\n    }\n\n    if (min_index == -1) return {};\n    return {min_even, min_index};\n}\n```"}
{"task_id": "SimdBench_95_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <unordered_map>\n\nint search_simd(std::vector<int> lst) {\n    std::unordered_map<int, int> frequency;\n    int n = lst.size();\n    int* data = lst.data();\n\n    for (int i = 0; i <= n - 8; i += 8) {\n        __m256i vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(data + i));\n        __m256i vec1 = _mm256_srli_epi32(vec, 16);\n        __m256i vec2 = _mm256_and_si256(vec, _mm256_set1_epi32(0xFFFF));\n        __m256i vec3 = _mm256_srli_epi32(vec1, 16);\n        __m256i vec4 = _mm256_and_si256(vec1, _mm256_set1_epi32(0xFFFF));\n\n        __m256i combined1 = _mm256_packs_epi32(vec2, vec4);\n        __m128i low = _mm256_extracti128_si256(combined1, 0);\n        __m128i high = _mm256_extracti128_si256(combined1, 1);\n\n        int arr[8];\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(arr), low);\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(arr + 4), high);\n\n        for (int j = 0; j < 8; ++j) {\n            frequency[arr[j]]++;\n        }\n    }\n\n    for (int i = (n / 8) * 8; i < n; ++i) {\n        frequency[data[i]]++;\n    }\n\n    int result = -1;\n    for (const auto& pair : frequency) {\n        if (pair.first > 0 && pair.second >= pair.first) {\n            result = std::max(result, pair.first);\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_95_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <unordered_map>\n\nint search_simd(std::vector<int> lst) {\n    std::unordered_map<int, int> frequency;\n    int n = lst.size();\n    int* data = lst.data();\n\n    for (int i = 0; i <= n - 8; i += 8) {\n        __m256i vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(data + i));\n        __m256i vec1 = _mm256_srli_epi32(vec, 16);\n        __m256i vec2 = _mm256_and_si256(vec, _mm256_set1_epi32(0xFFFF));\n        __m256i vec3 = _mm256_srli_epi32(vec1, 16);\n        __m256i vec4 = _mm256_and_si256(vec1, _mm256_set1_epi32(0xFFFF));\n\n        __m256i combined1 = _mm256_packs_epi32(vec2, vec4);\n        __m128i combined2 = _mm_add_epi32(_mm256_extracti128_si256(combined1, 0), _mm256_extracti128_si256(combined1, 1));\n\n        int arr[4];\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(arr), combined2);\n\n        for (int j = 0; j < 4; ++j) {\n            frequency[arr[j]]++;\n        }\n    }\n\n    for (int i = (n / 8) * 8; i < n; ++i) {\n        frequency[data[i]]++;\n    }\n\n    int result = -1;\n    for (const auto& pair : frequency) {\n        if (pair.first > 0 && pair.second >= pair.first) {\n            result = std::max(result, pair.first);\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_95_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n\nint search_simd(std::vector<int> lst) {\n    if (lst.empty()) return -1;\n\n    int max_val = *std::max_element(lst.begin(), lst.end());\n    std::vector<int> freq(max_val + 1, 0);\n\n    int n = lst.size();\n    int* data = lst.data();\n\n    for (int i = 0; i < n; i += 8) {\n        __m256i vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(data + i));\n        __m256i ones = _mm256_set1_epi32(1);\n\n        for (int j = 0; j < 8; ++j) {\n            int val = _mm256_extract_epi32(vec, j);\n            if (val <= max_val) {\n                freq[val] += 1;\n            }\n        }\n    }\n\n    for (int i = max_val; i > 0; --i) {\n        if (freq[i] >= i) {\n            return i;\n        }\n    }\n\n    return -1;\n}\n```"}
{"task_id": "SimdBench_95_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n#include <algorithm>\n#include <unordered_map>\n\nint search_simd(std::vector<int> lst) {\n    std::unordered_map<int, int> frequency;\n    for (int num : lst) {\n        frequency[num]++;\n    }\n\n    int result = -1;\n    for (const auto& [num, freq] : frequency) {\n        if (freq >= num && num > result) {\n            result = num;\n        }\n    }\n\n    return result;\n}\n```\n\n```cpp\n#include <immintrin.h>\n#include <vector>\n#include <algorithm>\n\nint search_simd(std::vector<int> lst) {\n    if (lst.empty()) return -1;\n\n    alignas(32) int count[8] = {0};\n    int max_val = *std::max_element(lst.begin(), lst.end());\n    int* counts = new int[max_val + 1]();\n\n    for (size_t i = 0; i <= max_val; i += 8) {\n        __m256i zero = _mm256_setzero_si256();\n        __m256i indices = _mm256_set_epi32(i + 7, i + 6, i + 5, i + 4, i + 3, i + 2, i + 1, i);\n        __m256i mask = _mm256_cmpgt_epi32(indices, _mm256_set1_epi32(max_val));\n        __m256i counts_vec = _mm256_i32gather_epi32(counts, indices, 4);\n        counts_vec = _mm256_andnot_si256(mask, counts_vec);\n\n        for (size_t j = 0; j < lst.size(); j += 8) {\n            __m256i vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&lst[j]));\n            __m256i cmp0 = _mm256_cmpeq_epi32(vec, _mm256_set1_epi32(i));\n            __m256i cmp1 = _mm256_cmpeq_epi32(vec, _mm256_set1_epi32(i + 1));\n            __m256i cmp2 = _mm256_cmpeq_epi32(vec, _mm256_set1_epi32(i + 2));\n            __m256i cmp3 = _mm256_cmpeq_epi32(vec, _mm256_set1_epi32(i + 3));\n            __m256i cmp4 = _mm256_cmpeq_epi32(vec, _mm256_set1_epi32(i + 4));\n            __m256i cmp5 = _mm256_cmpeq_epi32(vec, _mm256_set1_epi32(i + 5));\n            __m256i cmp6 = _mm256_cmpeq_epi32(vec, _mm256_set1_epi32(i + 6));\n            __m256i cmp7 = _mm256_cmpeq_epi32(vec, _mm256_set1_epi32(i + 7));\n\n            counts_vec = _mm256_add_epi32(counts_vec, _mm256_or_si256(cmp0, cmp1));\n            counts_vec = _mm256_add_epi32(counts_vec, _mm256_or_si256(cmp2, cmp3));\n            counts_vec = _mm256_add_epi32(counts_vec, _mm256_or_si256(cmp4, cmp5));\n            counts_vec = _mm256_add_epi32(counts_vec, _mm256_or_si256(cmp6, cmp7));\n        }\n\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(count), counts_vec);\n        for (int k = 0; k < 8; ++k) {\n            if (i + k <= max_val && count[k] >= i + k) {\n                result = std::max(result, i + k);\n            }\n        }\n    }\n\n    delete[] counts;\n    return result;\n}\n```"}
{"task_id": "SimdBench_95_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n#include <unordered_map>\n\nint search_simd(std::vector<int> lst) {\n    std::unordered_map<int, int> frequency;\n    for (int num : lst) {\n        frequency[num]++;\n    }\n\n    int result = -1;\n    __m256i max_val = _mm256_set1_epi32(-1);\n    __m256i freq_mask = _mm256_set1_epi32(0);\n\n    for (const auto& [num, count] : frequency) {\n        __m256i num_vec = _mm256_set1_epi32(num);\n        __m256i count_vec = _mm256_set1_epi32(count);\n        __m256i cmp_vec = _mm256_cmpgt_epi32(count_vec, num_vec);\n        __m256i valid_vec = _mm256_and_si256(cmp_vec, num_vec);\n\n        freq_mask = _mm256_or_si256(freq_mask, valid_vec);\n    }\n\n    int freq_arr[8];\n    _mm256_storeu_si256(reinterpret_cast<__m256i*>(freq_arr), freq_mask);\n\n    for (int i = 0; i < 8; ++i) {\n        if (freq_arr[i] > result) {\n            result = freq_arr[i];\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_96_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nbool will_it_fly_simd(std::vector<int> q, int w) {\n    int n = q.size();\n    if (n == 0) return false;\n\n    // Check if the vector is a palindrome\n    int* data = q.data();\n    __m256i* vec_start = reinterpret_cast<__m256i*>(data);\n    __m256i* vec_end = reinterpret_cast<__m256i*>(data + n - 8);\n    while (vec_start < vec_end) {\n        __m256i v1 = _mm256_loadu_si256(vec_start);\n        __m256i v2 = _mm256_loadu_si256(vec_end);\n        __m256i v2_reversed = _mm256_permutevar8x32_epi32(v2, _mm256_setr_epi32(7, 6, 5, 4, 3, 2, 1, 0));\n        if (!_mm256_cmpeq_epi32(v1, v2_reversed)) {\n            return false;\n        }\n        vec_start++;\n        vec_end--;\n    }\n\n    // Check remaining elements for palindrome property\n    int start = (n / 8) * 8;\n    int end = n - 1;\n    while (start < end) {\n        if (data[start] != data[end]) {\n            return false;\n        }\n        start++;\n        end--;\n    }\n\n    // Calculate the sum of the elements\n    __m256i sum_vec = _mm256_setzero_si256();\n    vec_start = reinterpret_cast<__m256i*>(data);\n    vec_end = reinterpret_cast<__m256i*>(data + n - 8);\n    while (vec_start < vec_end) {\n        sum_vec = _mm256_add_epi32(sum_vec, _mm256_loadu_si256(vec_start));\n        vec_start++;\n    }\n\n    // Sum the remaining elements\n    int sum = 0;\n    int* remaining_start = data + (n / 8) * 8;\n    for (int i = 0; i < n % 8; ++i) {\n        sum += remaining_start[i];\n    }\n\n    // Horizontally add the elements of sum_vec\n    __m128i sum_128 = _mm_add_epi32(_mm256_extracti128_si256(sum_vec, 0), _mm256_extracti128_si256(sum_vec, 1));\n    sum_128 = _mm_add_epi32(sum_128, _mm_srli_si128(sum_128, 8));\n    sum_128 = _mm_add_epi32(sum_128, _mm_srli_si128(sum_128, 4));\n    sum += _mm_cvtsi128_si32(sum_128);\n\n    return sum <= w;\n}\n```"}
{"task_id": "SimdBench_96_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nbool will_it_fly_simd(std::vector<int> q, int w) {\n    int n = q.size();\n    if (n == 0) return false;\n\n    // Check if the vector is a palindrome\n    int* data = q.data();\n    __m256i* vec_start = reinterpret_cast<__m256i*>(data);\n    __m256i* vec_end = reinterpret_cast<__m256i*>(data + n - 8);\n    while (vec_start < vec_end) {\n        __m256i vec1 = _mm256_loadu_si256(vec_start);\n        __m256i vec2 = _mm256_loadu_si256(vec_end);\n        __m256i reversed_vec2 = _mm256_permute4x64_epi64(_mm256_shuffle_epi32(vec2, _MM_SHUFFLE(0, 1, 2, 3)), _MM_SHUFFLE(0, 1, 2, 3));\n        if (!_mm256_cmpeq_epi32(vec1, reversed_vec2)) {\n            return false;\n        }\n        vec_start++;\n        vec_end--;\n    }\n\n    // Check remaining elements for palindrome property\n    int start = (n / 8) * 8;\n    int end = n - 1;\n    while (start < end) {\n        if (data[start] != data[end]) {\n            return false;\n        }\n        start++;\n        end--;\n    }\n\n    // Calculate the sum of the elements\n    __m256i sum = _mm256_setzero_si256();\n    vec_start = reinterpret_cast<__m256i*>(data);\n    vec_end = reinterpret_cast<__m256i*>(data + n - 8);\n    while (vec_start < vec_end) {\n        sum = _mm256_add_epi32(sum, _mm256_loadu_si256(vec_start));\n        vec_start++;\n    }\n\n    // Sum remaining elements\n    int scalar_sum = 0;\n    start = (n / 8) * 8;\n    while (start < n) {\n        scalar_sum += data[start];\n        start++;\n    }\n\n    // Horizontal sum of the vector sum\n    __m128i sum_low = _mm_add_epi32(_mm256_extracti128_si256(sum, 0), _mm256_extracti128_si256(sum, 1));\n    sum_low = _mm_add_epi32(sum_low, _mm_srli_si128(sum_low, 8));\n    sum_low = _mm_add_epi32(sum_low, _mm_srli_si128(sum_low, 4));\n    int total_sum = _mm_cvtsi128_si32(sum_low) + scalar_sum;\n\n    return total_sum <= w;\n}\n```"}
{"task_id": "SimdBench_96_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nbool will_it_fly_simd(std::vector<int> q, int w) {\n    int n = q.size();\n    if (n == 0) return false;\n\n    // Check if the vector is a palindrome\n    int* data = q.data();\n    __m256i* vec_start = reinterpret_cast<__m256i*>(data);\n    __m256i* vec_end = reinterpret_cast<__m256i*>(data + n - 8);\n    while (vec_start < vec_end) {\n        __m256i v1 = _mm256_loadu_si256(vec_start);\n        __m256i v2 = _mm256_loadu_si256(vec_end);\n        __m256i v2_reversed = _mm256_permute4x64_epi64(_mm256_shuffle_epi32(v2, _MM_SHUFFLE(0, 1, 2, 3)), _MM_SHUFFLE(0, 1, 2, 3));\n        v2_reversed = _mm256_permutevar8x32_epi32(v2_reversed, _mm256_setr_epi32(7, 6, 5, 4, 3, 2, 1, 0));\n        if (_mm256_movemask_epi8(_mm256_cmpeq_epi32(v1, v2_reversed)) != 0xFFFFFFFF) {\n            return false;\n        }\n        vec_start++;\n        vec_end--;\n    }\n\n    // Check remaining elements for palindrome property\n    int start = (n / 8) * 8;\n    int end = n - 1;\n    while (start < end) {\n        if (data[start] != data[end]) {\n            return false;\n        }\n        start++;\n        end--;\n    }\n\n    // Calculate the sum of elements\n    __m256i sum = _mm256_setzero_si256();\n    vec_start = reinterpret_cast<__m256i*>(data);\n    vec_end = reinterpret_cast<__m256i*>(data + n - 8);\n    while (vec_start < vec_end) {\n        sum = _mm256_add_epi32(sum, _mm256_loadu_si256(vec_start));\n        vec_start++;\n    }\n\n    // Sum remaining elements\n    int remaining_sum = 0;\n    start = (n / 8) * 8;\n    while (start < n) {\n        remaining_sum += data[start];\n        start++;\n    }\n\n    // Add the sums together\n    int total_sum[8];\n    _mm256_storeu_si256(reinterpret_cast<__m256i*>(total_sum), sum);\n    int final_sum = total_sum[0] + total_sum[1] + total_sum[2] + total_sum[3] + total_sum[4] + total_sum[5] + total_sum[6] + total_sum[7] + remaining_sum;\n\n    return final_sum <= w;\n}\n```"}
{"task_id": "SimdBench_96_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nbool will_it_fly_simd(std::vector<int> q, int w) {\n    int n = q.size();\n    if (n == 0) return false;\n\n    // Check if the vector is a palindrome\n    __m256i *data = reinterpret_cast<__m256i*>(q.data());\n    int i = 0;\n    for (; i <= n / 2 - 8; i += 8) {\n        __m256i vec = _mm256_loadu_si256(&data[i]);\n        __m256i rev_vec = _mm256_loadu_si256(&data[n / 8 - 1 - i]);\n        rev_vec = _mm256_permute4x64_epi64(rev_vec, 0b11011000);\n        rev_vec = _mm256_shuffle_epi32(rev_vec, _MM_SHUFFLE(0, 1, 2, 3));\n        if (!_mm256_test_all_ones((__m256i)_mm256_cmpeq_epi32(vec, rev_vec))) {\n            return false;\n        }\n    }\n\n    // Check remaining elements for palindrome\n    for (; i < n / 2; ++i) {\n        if (q[i] != q[n - 1 - i]) {\n            return false;\n        }\n    }\n\n    // Calculate the sum of elements\n    __m256i sum_vec = _mm256_setzero_si256();\n    i = 0;\n    for (; i <= n - 8; i += 8) {\n        __m256i vec = _mm256_loadu_si256(&data[i]);\n        sum_vec = _mm256_add_epi32(sum_vec, vec);\n    }\n\n    // Horizontally add the elements of sum_vec\n    int sum_array[8];\n    _mm256_storeu_si256(reinterpret_cast<__m256i*>(sum_array), sum_vec);\n    int sum = sum_array[0] + sum_array[1] + sum_array[2] + sum_array[3] + sum_array[4] + sum_array[5] + sum_array[6] + sum_array[7];\n\n    // Add remaining elements\n    for (; i < n; ++i) {\n        sum += q[i];\n    }\n\n    return sum <= w;\n}\n```"}
{"task_id": "SimdBench_96_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nbool will_it_fly_simd(std::vector<int> q, int w) {\n    int n = q.size();\n    if (n == 0) return false;\n\n    // Check if the vector is a palindrome\n    int* data = q.data();\n    __m256i* vec_data = reinterpret_cast<__m256i*>(data);\n    int num_vectors = n / 8;\n    int remainder = n % 8;\n\n    for (int i = 0; i < num_vectors; ++i) {\n        __m256i vec1 = _mm256_loadu_si256(&vec_data[i]);\n        __m256i vec2 = _mm256_loadu_si256(&vec_data[num_vectors - i - 1]);\n        __m256i reversed_vec2 = _mm256_permutevar8x32_epi32(vec2, _mm256_setr_epi32(7, 6, 5, 4, 3, 2, 1, 0));\n        if (_mm256_movemask_epi8(_mm256_cmpeq_epi32(vec1, reversed_vec2)) != 0xFFFF) {\n            return false;\n        }\n    }\n\n    // Check remaining elements for palindrome\n    for (int i = 0; i < remainder; ++i) {\n        if (data[i] != data[n - i - 1]) {\n            return false;\n        }\n    }\n\n    // Calculate the sum of the elements\n    __m256i sum = _mm256_setzero_si256();\n    for (int i = 0; i < num_vectors; ++i) {\n        sum = _mm256_add_epi32(sum, _mm256_loadu_si256(&vec_data[i]));\n    }\n\n    // Horizontal add for the sum\n    __m128i sum128 = _mm_add_epi32(_mm256_extracti128_si256(sum, 0), _mm256_extracti128_si256(sum, 1));\n    sum128 = _mm_add_epi32(sum128, _mm_shuffle_epi32(sum128, 0x0E));\n    sum128 = _mm_add_epi32(sum128, _mm_shuffle_epi32(sum128, 0x01));\n\n    int total_sum = _mm_cvtsi128_si32(sum128);\n\n    // Add remaining elements to the sum\n    for (int i = 0; i < remainder; ++i) {\n        total_sum += data[num_vectors * 8 + i];\n    }\n\n    return total_sum <= w;\n}\n```"}
{"task_id": "SimdBench_97_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint smallest_change_simd(std::vector<int> arr) {\n    int n = arr.size();\n    int changes = 0;\n    int* data = arr.data();\n\n    for (int i = 0; i <= n / 8; i += 8) {\n        __m256i left = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(data + i));\n        __m256i right = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(data + n - i - 8));\n        right = _mm256_permutevar8x32_epi32(right, _mm256_setr_epi32(7, 6, 5, 4, 3, 2, 1, 0));\n\n        __m256i cmp = _mm256_cmpeq_epi32(left, right);\n        __m256i not_cmp = _mm256_andnot_si256(cmp, _mm256_set1_epi32(1));\n        changes += _mm256_reduce_add_epi32(not_cmp);\n    }\n\n    // Handle the remaining elements\n    for (int i = n / 2; i < n - n / 2; ++i) {\n        if (data[i] != data[n - i - 1]) {\n            changes++;\n        }\n    }\n\n    return changes;\n}\n```"}
{"task_id": "SimdBench_97_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint smallest_change_simd(std::vector<int> arr) {\n    int n = arr.size();\n    int changes = 0;\n    int* data = arr.data();\n\n    for (int i = 0; i <= n / 8; i += 8) {\n        __m256i left = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(data + i));\n        __m256i right = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(data + n - i - 8));\n        __m256i cmp = _mm256_cmpeq_epi32(left, right);\n        int mask = _mm256_movemask_epi8(cmp);\n        changes += __builtin_popcount(~mask) / 4;\n    }\n\n    // Handle the remaining elements\n    for (int i = n / 2; i < n - n / 2; ++i) {\n        if (data[i] != data[n - i - 1]) {\n            ++changes;\n        }\n    }\n\n    return changes / 2;\n}\n```"}
{"task_id": "SimdBench_97_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint smallest_change_simd(std::vector<int> arr) {\n    int n = arr.size();\n    int changes = 0;\n    int* data = arr.data();\n\n    for (int i = 0; i <= n / 8; i += 8) {\n        __m256i left = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(data + i));\n        __m256i right = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(data + n - i - 8));\n        right = _mm256_permutevar8x32_epi32(right, _mm256_setr_epi32(7, 6, 5, 4, 3, 2, 1, 0));\n\n        __m256i cmp = _mm256_cmpeq_epi32(left, right);\n        __m256i ones = _mm256_set1_epi32(1);\n        __m256i not_cmp = _mm256_andnot_si256(cmp, ones);\n        changes += _mm256_reduce_add_epi32(not_cmp);\n    }\n\n    // Handle the remaining elements\n    for (int i = n / 2; i < n - n / 2; ++i) {\n        if (data[i] != data[n - i - 1]) {\n            changes++;\n        }\n    }\n\n    return changes / 2;\n}\n```"}
{"task_id": "SimdBench_97_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint smallest_change_simd(std::vector<int> arr) {\n    int n = arr.size();\n    int changes = 0;\n\n    int i = 0;\n    for (; i <= n / 8 * 8 - 8; i += 8) {\n        __m256i vec1 = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&arr[i]));\n        __m256i vec2 = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&arr[n - i - 8]));\n        __m256i cmp = _mm256_cmpeq_epi32(vec1, vec2);\n        int mask = _mm256_movemask_epi8(cmp);\n        changes += 8 - __builtin_popcount(mask >> 1 & 0x55555555);\n    }\n\n    for (; i < n / 2; ++i) {\n        if (arr[i] != arr[n - i - 1]) {\n            ++changes;\n        }\n    }\n\n    return changes;\n}\n```"}
{"task_id": "SimdBench_97_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint smallest_change_simd(std::vector<int> arr) {\n    int n = arr.size();\n    int changes = 0;\n    int *data = arr.data();\n\n    for (int i = 0; i <= n / 8; i += 8) {\n        __m256i left = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(data + i));\n        __m256i right = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(data + n - i - 8));\n        right = _mm256_permutevar8x32_epi32(right, _mm256_setr_epi32(7, 6, 5, 4, 3, 2, 1, 0));\n\n        __m256i cmp = _mm256_cmpeq_epi32(left, right);\n        __m256i not_cmp = _mm256_andnot_si256(cmp, _mm256_set1_epi32(1));\n        changes += _mm256_reduce_add_epi32(not_cmp);\n    }\n\n    // Handle the remaining elements\n    for (int i = (n / 8) * 8; i < n / 2; ++i) {\n        if (data[i] != data[n - i - 1]) {\n            ++changes;\n        }\n    }\n\n    return changes;\n}\n```"}
{"task_id": "SimdBench_98_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n\nstd::vector<std::string> total_match_simd(const std::vector<std::string> & lst1, const std::vector<std::string> & lst2){\n    auto sum_chars = [](const std::vector<std::string> & lst) {\n        __m256i total = _mm256_setzero_si256();\n        for (const auto & str : lst) {\n            size_t len = str.size();\n            for (size_t i = 0; i <= len - 32; i += 32) {\n                __m256i chunk = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(str.data() + i));\n                __m256i ones = _mm256_set1_epi8(1);\n                __m256i count = _mm256_cmpeq_epi8(chunk, ones);\n                total = _mm256_add_epi32(total, _mm256_sad_epu8(count, _mm256_setzero_si256()));\n            }\n            for (size_t i = (len / 32) * 32; i < len; ++i) {\n                total = _mm256_add_epi32(total, _mm256_set1_epi32(1));\n            }\n        }\n        int totals[8];\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(totals), total);\n        return totals[0] + totals[1] + totals[2] + totals[3] + totals[4] + totals[5] + totals[6] + totals[7];\n    };\n\n    int sum1 = sum_chars(lst1);\n    int sum2 = sum_chars(lst2);\n\n    return sum1 < sum2 ? lst1 : lst2;\n}\n```"}
{"task_id": "SimdBench_98_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n\nstd::vector<std::string> total_match_simd(const std::vector<std::string> & lst1, const std::vector<std::string> & lst2){\n    auto sum_chars = [](const std::vector<std::string> & lst) {\n        __m256i total = _mm256_setzero_si256();\n        for (const auto & str : lst) {\n            size_t len = str.size();\n            for (size_t i = 0; i <= len - 32; i += 32) {\n                __m256i chunk = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(str.data() + i));\n                __m256i ones = _mm256_set1_epi8(1);\n                __m256i count = _mm256_cmpeq_epi8(chunk, ones);\n                total = _mm256_add_epi32(total, _mm256_sad_epu8(count, _mm256_setzero_si256()));\n            }\n            for (size_t i = (len / 32) * 32; i < len; ++i) {\n                total = _mm256_add_epi32(total, _mm256_set1_epi32(1));\n            }\n        }\n        int total_chars[8];\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(total_chars), total);\n        return total_chars[0] + total_chars[1] + total_chars[2] + total_chars[3] +\n               total_chars[4] + total_chars[5] + total_chars[6] + total_chars[7];\n    };\n\n    int sum1 = sum_chars(lst1);\n    int sum2 = sum_chars(lst2);\n\n    return sum1 < sum2 ? lst1 : lst2;\n}\n```"}
{"task_id": "SimdBench_98_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n\nstd::vector<std::string> total_match_simd(const std::vector<std::string> & lst1, const std::vector<std::string> & lst2){\n    auto sum_chars = [](const std::vector<std::string> & lst) {\n        __m256i total = _mm256_setzero_si256();\n        for (const auto & str : lst) {\n            size_t len = str.size();\n            for (size_t i = 0; i <= len - 32; i += 32) {\n                __m256i chunk = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(str.c_str() + i));\n                __m256i ones = _mm256_set1_epi8(1);\n                __m256i count = _mm256_cmpeq_epi8(chunk, ones);\n                total = _mm256_add_epi32(total, _mm256_sad_epu8(count, _mm256_setzero_si256()));\n            }\n            for (size_t i = (len / 32) * 32; i < len; ++i) {\n                total = _mm256_add_epi32(total, _mm256_set1_epi32(1));\n            }\n        }\n        int totals[8];\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(totals), total);\n        return totals[0] + totals[1] + totals[2] + totals[3] + totals[4] + totals[5] + totals[6] + totals[7];\n    };\n\n    int sum1 = sum_chars(lst1);\n    int sum2 = sum_chars(lst2);\n\n    return sum1 < sum2 ? lst1 : lst2;\n}\n```"}
{"task_id": "SimdBench_98_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n\nstd::vector<std::string> total_match_simd(const std::vector<std::string> & lst1, const std::vector<std::string> & lst2){\n    auto sum_chars = [](const std::vector<std::string> & lst) {\n        __m256i total = _mm256_setzero_si256();\n        for (const auto & str : lst) {\n            size_t len = str.size();\n            for (size_t i = 0; i <= len - 32; i += 32) {\n                __m256i chunk = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(str.c_str() + i));\n                __m256i ones = _mm256_set1_epi8(1);\n                __m256i counts = _mm256_cmpeq_epi8(chunk, ones);\n                total = _mm256_add_epi32(total, _mm256_sad_epu8(counts, _mm256_setzero_si256()));\n            }\n            for (size_t i = (len / 32) * 32; i < len; ++i) {\n                total = _mm256_add_epi32(total, _mm256_set1_epi32(1));\n            }\n        }\n        int totals[8];\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(totals), total);\n        return totals[0] + totals[1] + totals[2] + totals[3] + totals[4] + totals[5] + totals[6] + totals[7];\n    };\n\n    int sum1 = sum_chars(lst1);\n    int sum2 = sum_chars(lst2);\n\n    return sum1 < sum2 ? lst1 : lst2;\n}\n```"}
{"task_id": "SimdBench_98_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n\nstd::vector<std::string> total_match_simd(const std::vector<std::string> & lst1, const std::vector<std::string> & lst2){\n    auto sum_chars = [](const std::vector<std::string> & lst) {\n        __m256i total = _mm256_setzero_si256();\n        for (const auto & str : lst) {\n            size_t len = str.size();\n            for (size_t i = 0; i <= len - 32; i += 32) {\n                __m256i chunk = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(str.c_str() + i));\n                __m256i ones = _mm256_set1_epi8(1);\n                __m256i counts = _mm256_cmpeq_epi8(chunk, ones);\n                __m256i horizontal_sum = _mm256_sad_epu8(counts, _mm256_setzero_si256());\n                total = _mm256_add_epi32(total, horizontal_sum);\n            }\n            for (size_t i = (len / 32) * 32; i < len; ++i) {\n                total = _mm256_add_epi32(total, _mm256_set1_epi32(1));\n            }\n        }\n        int totals[8];\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(totals), total);\n        return totals[0] + totals[1] + totals[2] + totals[3] + totals[4] + totals[5] + totals[6] + totals[7];\n    };\n\n    int sum1 = sum_chars(lst1);\n    int sum2 = sum_chars(lst2);\n\n    return sum1 < sum2 ? lst1 : lst2;\n}\n```"}
{"task_id": "SimdBench_99_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nbool is_simple_power_simd(uint64_t x, uint64_t n) {\n    if (n == 1) return x == 1;\n    if (n == 0) return x == 0;\n\n    __m256i vx = _mm256_set1_epi64x(x);\n    __m256i vn = _mm256_set1_epi64x(n);\n    __m256i vone = _mm256_set1_epi64x(1);\n    __m256i vzero = _mm256_setzero_si256();\n    __m256i vpowers = vone;\n\n    while (true) {\n        vpowers = _mm256_mullo_epi64(vpowers, vn);\n        __m256i vcmp = _mm256_cmpeq_epi64(vpowers, vx);\n        if (_mm256_movemask_epi8(vcmp) != 0) return true;\n\n        __m256i voverflow = _mm256_cmpgt_epi64(vpowers, vx);\n        if (_mm256_movemask_epi8(voverflow) != 0) break;\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_99_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nbool is_simple_power_simd(uint64_t x, uint64_t n) {\n    if (n == 1) return x == 1;\n    if (n == 0) return x == 0;\n\n    __m256i vx = _mm256_set1_epi64x(x);\n    __m256i vn = _mm256_set1_epi64x(n);\n    __m256i vone = _mm256_set1_epi64x(1);\n    __m256i vzero = _mm256_setzero_si256();\n    __m256i vpowers = vone;\n\n    while (true) {\n        vpowers = _mm256_mullo_epi64(vpowers, vn);\n        __m256i vcmp = _mm256_cmpeq_epi64(vpowers, vx);\n        if (_mm256_movemask_epi8(vcmp) != 0) return true;\n\n        __m256i voverflow = _mm256_cmpgt_epi64(vpowers, vx);\n        if (_mm256_movemask_epi8(voverflow) != 0) break;\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_99_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nbool is_simple_power_simd(uint64_t x, uint64_t n) {\n    if (n == 0 || (n == 1 && x != 1)) return false;\n    if (x == 1) return true;\n\n    __m256i vx = _mm256_set1_epi64x(x);\n    __m256i vn = _mm256_set1_epi64x(n);\n    __m256i vone = _mm256_set1_epi64x(1);\n    __m256i vzero = _mm256_setzero_si256();\n    __m256i vpowers = vone;\n\n    while (true) {\n        vpowers = _mm256_mullo_epi64(vpowers, vn);\n        __m256i vcmp = _mm256_cmpeq_epi64(vpowers, vx);\n        if (!_mm256_testz_si256(vcmp, vcmp)) return true;\n\n        __m256i voverflow = _mm256_cmpgt_epi64(vpowers, vx);\n        if (!_mm256_testz_si256(voverflow, voverflow)) break;\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_99_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nbool is_simple_power_simd(uint64_t x, uint64_t n) {\n    if (n == 1) return x == 1;\n    if (n == 0) return x == 0;\n\n    __m256i vx = _mm256_set1_epi64x(x);\n    __m256i vn = _mm256_set1_epi64x(n);\n    __m256i vone = _mm256_set1_epi64x(1);\n    __m256i vzero = _mm256_setzero_si256();\n    __m256i vpowers = vone;\n\n    while (true) {\n        vpowers = _mm256_mullo_epi64(vpowers, vn);\n        __m256i vcmp = _mm256_cmpeq_epi64(vpowers, vx);\n        if (_mm256_movemask_epi8(vcmp) != 0) return true;\n\n        __m256i voverflow = _mm256_cmpgt_epi64(vpowers, vx);\n        if (_mm256_movemask_epi8(voverflow) != 0) break;\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_99_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nbool is_simple_power_simd(uint64_t x, uint64_t n) {\n    if (n == 1) return x == 1;\n    if (n == 0) return x == 0;\n\n    __m256i vx = _mm256_set1_epi64x(x);\n    __m256i vn = _mm256_set1_epi64x(n);\n    __m256i vone = _mm256_set1_epi64x(1);\n    __m256i vzero = _mm256_setzero_si256();\n    __m256i vpowers = vone;\n\n    while (true) {\n        __m256i vcmp = _mm256_cmpeq_epi64(vpowers, vx);\n        if (_mm256_movemask_epi8(vcmp) != 0) return true;\n\n        vpowers = _mm256_mullo_epi64(vpowers, vn);\n        vcmp = _mm256_cmpgt_epi64(vpowers, vx);\n        if (_mm256_movemask_epi8(vcmp) != 0) break;\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_100_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nint hex_key_simd(const std::string & num) {\n    const int len = num.size();\n    const char* str = num.c_str();\n    int count = 0;\n\n    __m256i primes = _mm256_setr_epi8('2', '3', '5', '7', 'B', 'D', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, '2', '3', '5', '7', 'B', 'D', 0, 0, 0, 0, 0, 0, 0, 0);\n    __m256i zero = _mm256_setzero_si256();\n\n    for (int i = 0; i <= len - 32; i += 32) {\n        __m256i chunk = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(str + i));\n        __m256i mask = _mm256_cmpeq_epi8(chunk, primes);\n        __m256i horizontal_sum = _mm256_movemask_epi8(mask);\n        count += __builtin_popcount(horizontal_sum);\n    }\n\n    for (int i = (len / 32) * 32; i < len; ++i) {\n        if (str[i] == '2' || str[i] == '3' || str[i] == '5' || str[i] == '7' || str[i] == 'B' || str[i] == 'D') {\n            count++;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_100_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nint hex_key_simd(const std::string & num) {\n    const __m256i primes = _mm256_setr_epi8(2, 3, 5, 7, 11, 13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n    const __m256i hex_map = _mm256_setr_epi8(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 11, 0, 13, 0, 15, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 11, 0, 13, 0, 15);\n    int count = 0;\n    size_t len = num.size();\n    size_t i = 0;\n\n    while (i <= len - 32) {\n        __m256i input = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(num.data() + i));\n        __m256i mapped = _mm256_shuffle_epi8(hex_map, input);\n        __m256i mask = _mm256_cmpeq_epi8(_mm256_shuffle_epi8(primes, mapped), primes);\n        count += _mm256_popcnt_u32(_mm256_movemask_epi8(mask)) / 2;\n        i += 32;\n    }\n\n    while (i < len) {\n        char c = num[i];\n        if ((c >= '0' && c <= '9') || (c >= 'A' && c <= 'F')) {\n            int val = (c <= '9') ? c - '0' : c - 'A' + 10;\n            if (val == 2 || val == 3 || val == 5 || val == 7 || val == 11 || val == 13) {\n                count++;\n            }\n        }\n        i++;\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_100_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nint hex_key_simd(const std::string & num) {\n    const int len = num.size();\n    if (len == 0) return 0;\n\n    __m256i primes = _mm256_setr_epi8('2', '3', '5', '7', 'B', 'D', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n                                      '2', '3', '5', '7', 'B', 'D', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n    int count = 0;\n\n    for (int i = 0; i <= len - 32; i += 32) {\n        __m256i chunk = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&num[i]));\n        __m256i mask = _mm256_cmpeq_epi8(chunk, primes);\n        count += _mm256_movemask_epi8(mask) & 0x3F;\n        count += (_mm256_movemask_epi8(mask) >> 8) & 0x3F;\n        count += (_mm256_movemask_epi8(mask) >> 16) & 0x3F;\n        count += (_mm256_movemask_epi8(mask) >> 24) & 0x3F;\n    }\n\n    for (int i = (len / 32) * 32; i < len; ++i) {\n        if (num[i] == '2' || num[i] == '3' || num[i] == '5' || num[i] == '7' || num[i] == 'B' || num[i] == 'D') {\n            ++count;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_100_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nint hex_key_simd(const std::string & num) {\n    const int len = num.size();\n    const char* str = num.c_str();\n    int count = 0;\n\n    __m256i primes = _mm256_setr_epi8('2', '3', '5', '7', 'B', 'D', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, '2', '3', '5', '7', 'B', 'D', 0, 0, 0, 0, 0, 0, 0, 0);\n    __m256i zero = _mm256_setzero_si256();\n\n    for (int i = 0; i <= len - 32; i += 32) {\n        __m256i chunk = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(str + i));\n        __m256i mask = _mm256_cmpeq_epi8(chunk, primes);\n        __m256i sum = _mm256_cmpeq_epi8(mask, _mm256_set1_epi8(-1));\n        int horizontal_sum = _mm256_movemask_epi8(sum);\n        count += __builtin_popcount(horizontal_sum);\n    }\n\n    for (int i = (len / 32) * 32; i < len; ++i) {\n        if (str[i] == '2' || str[i] == '3' || str[i] == '5' || str[i] == '7' || str[i] == 'B' || str[i] == 'D') {\n            count++;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_100_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nint hex_key_simd(const std::string & num) {\n    const int len = num.size();\n    const char* str = num.c_str();\n    int count = 0;\n\n    __m256i primes = _mm256_setr_epi8('2', '3', '5', '7', 'B', 'D', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, '2', '3', '5', '7', 'B', 'D', 0, 0, 0, 0, 0, 0, 0, 0);\n    __m256i zero = _mm256_setzero_si256();\n\n    for (int i = 0; i <= len - 32; i += 32) {\n        __m256i chunk = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(str + i));\n        __m256i mask = _mm256_cmpeq_epi8(chunk, primes);\n        __m256i horizontal_sum = _mm256_movemask_epi8(mask);\n        count += __builtin_popcount(horizontal_sum);\n    }\n\n    for (int i = (len / 32) * 32; i < len; ++i) {\n        if (str[i] == '2' || str[i] == '3' || str[i] == '5' || str[i] == '7' || str[i] == 'B' || str[i] == 'D') {\n            count++;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_101_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nbool is_happy_simd(const std::string & s) {\n    if (s.size() < 3) return false;\n\n    const char* str = s.c_str();\n    size_t len = s.size();\n\n    __m256i zero = _mm256_setzero_si256();\n    __m256i mask = _mm256_set1_epi8(0);\n\n    for (size_t i = 0; i <= len - 32; i += 30) {\n        __m256i vec0 = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(str + i));\n        __m256i vec1 = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(str + i + 1));\n        __m256i vec2 = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(str + i + 2));\n\n        __m256i cmp0 = _mm256_cmpeq_epi8(vec0, vec1);\n        __m256i cmp1 = _mm256_cmpeq_epi8(vec1, vec2);\n        __m256i cmp2 = _mm256_cmpeq_epi8(vec0, vec2);\n\n        mask = _mm256_or_si256(mask, cmp0);\n        mask = _mm256_or_si256(mask, cmp1);\n        mask = _mm256_or_si256(mask, cmp2);\n    }\n\n    for (size_t i = len - 30; i <= len - 3; ++i) {\n        if (str[i] == str[i + 1] || str[i + 1] == str[i + 2] || str[i] == str[i + 2]) {\n            return false;\n        }\n    }\n\n    return _mm256_testz_si256(mask, mask) != 0;\n}\n```"}
{"task_id": "SimdBench_101_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nbool is_happy_simd(const std::string & s) {\n    if (s.size() < 3) return false;\n\n    const char* str = s.c_str();\n    size_t len = s.size();\n    size_t i = 0;\n\n    // Process 16 characters at a time\n    for (; i <= len - 16; i += 15) {\n        __m256i vec1 = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(str + i));\n        __m256i vec2 = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(str + i + 1));\n        __m256i vec3 = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(str + i + 2));\n\n        __m256i cmp1 = _mm256_cmpeq_epi8(vec1, vec2);\n        __m256i cmp2 = _mm256_cmpeq_epi8(vec1, vec3);\n        __m256i cmp3 = _mm256_cmpeq_epi8(vec2, vec3);\n\n        __m256i result = _mm256_or_si256(_mm256_or_si256(cmp1, cmp2), cmp3);\n        int mask = _mm256_movemask_epi8(result);\n\n        if (mask != 0) return false;\n    }\n\n    // Process remaining characters\n    for (; i <= len - 3; ++i) {\n        if (str[i] == str[i + 1] || str[i] == str[i + 2] || str[i + 1] == str[i + 2]) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_101_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nbool is_happy_simd(const std::string & s) {\n    if (s.length() < 3) return false;\n\n    int len = s.length();\n    const char* str = s.c_str();\n\n    __m256i zero = _mm256_setzero_si256();\n    __m256i ones = _mm256_set1_epi8(1);\n\n    for (int i = 0; i <= len - 32; i += 30) {\n        __m256i vec0 = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(str + i));\n        __m256i vec1 = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(str + i + 1));\n        __m256i vec2 = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(str + i + 2));\n\n        __m256i cmp0 = _mm256_cmpeq_epi8(vec0, vec1);\n        __m256i cmp1 = _mm256_cmpeq_epi8(vec1, vec2);\n        __m256i cmp2 = _mm256_cmpeq_epi8(vec0, vec2);\n\n        __m256i or0 = _mm256_or_si256(cmp0, cmp1);\n        __m256i or1 = _mm256_or_si256(or0, cmp2);\n\n        __m256i result = _mm256_andnot_si256(or1, ones);\n\n        if (_mm256_testz_si256(result, result) == 0) {\n            return false;\n        }\n    }\n\n    for (int i = len - 30; i <= len - 3; ++i) {\n        if (str[i] == str[i + 1] || str[i] == str[i + 2] || str[i + 1] == str[i + 2]) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_101_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nbool is_happy_simd(const std::string & s) {\n    if (s.length() < 3) return false;\n\n    const char* str = s.c_str();\n    int len = s.length();\n    int i = 0;\n\n    // Process 16 characters at a time\n    for (; i <= len - 16; i += 15) {\n        __m256i vec1 = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(str + i));\n        __m256i vec2 = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(str + i + 1));\n        __m256i vec3 = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(str + i + 2));\n\n        __m256i cmp1 = _mm256_cmpeq_epi8(vec1, vec2);\n        __m256i cmp2 = _mm256_cmpeq_epi8(vec1, vec3);\n        __m256i cmp3 = _mm256_cmpeq_epi8(vec2, vec3);\n\n        __m256i result = _mm256_or_si256(_mm256_or_si256(cmp1, cmp2), cmp3);\n        if (!_mm256_testz_si256(result, result)) {\n            return false;\n        }\n    }\n\n    // Process remaining characters\n    for (; i <= len - 3; ++i) {\n        if (str[i] == str[i + 1] || str[i] == str[i + 2] || str[i + 1] == str[i + 2]) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_101_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nbool is_happy_simd(const std::string & s) {\n    if (s.size() < 3) return false;\n\n    const char* str = s.c_str();\n    int len = s.size();\n\n    __m256i zero = _mm256_setzero_si256();\n    __m256i mask = _mm256_set1_epi8(0);\n\n    for (int i = 0; i <= len - 32; i += 30) {\n        __m256i vec0 = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(str + i));\n        __m256i vec1 = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(str + i + 1));\n        __m256i vec2 = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(str + i + 2));\n\n        __m256i cmp0 = _mm256_cmpeq_epi8(vec0, vec1);\n        __m256i cmp1 = _mm256_cmpeq_epi8(vec1, vec2);\n        __m256i cmp2 = _mm256_cmpeq_epi8(vec0, vec2);\n\n        mask = _mm256_or_si256(mask, cmp0);\n        mask = _mm256_or_si256(mask, cmp1);\n        mask = _mm256_or_si256(mask, cmp2);\n    }\n\n    for (int i = len - 30; i <= len - 3; ++i) {\n        if (str[i] == str[i + 1] || str[i + 1] == str[i + 2] || str[i] == str[i + 2]) {\n            return false;\n        }\n    }\n\n    return _mm256_testz_si256(mask, mask) != 0;\n}\n```"}
{"task_id": "SimdBench_102_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n#include <cmath>\n\nbool prime_length_simd(const std::string & str) {\n    int length = str.length();\n    if (length < 2) return false;\n\n    __m256i v_length = _mm256_set1_epi32(length);\n    __m256i v_zero = _mm256_setzero_si256();\n    __m256i v_two = _mm256_set1_epi32(2);\n    __m256i v_sqrt_length = _mm256_set1_epi32(static_cast<int>(std::sqrt(length)));\n\n    __m256i v_i = v_two;\n    while (_mm256_movemask_epi8(_mm256_cmpgt_epi32(v_sqrt_length, v_i)) != 0) {\n        __m256i v_div = _mm256_div_epi32(v_length, v_i);\n        __m256i v_mul = _mm256_mullo_epi32(v_div, v_i);\n        __m256i v_eq = _mm256_cmpeq_epi32(v_mul, v_length);\n        if (_mm256_movemask_epi8(v_eq) != 0) {\n            return false;\n        }\n        v_i = _mm256_add_epi32(v_i, v_two);\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_102_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n#include <cmath>\n\nbool prime_length_simd(const std::string & str) {\n    int length = str.length();\n    if (length <= 1) return false;\n    if (length <= 3) return true;\n    if (length % 2 == 0 || length % 3 == 0) return false;\n\n    int i = 5;\n    while (i * i <= length) {\n        __m256i multiples_of_i = _mm256_setr_epi32(i, i + 6, i + 12, i + 18, i + 24, i + 30, i + 36, i + 42);\n        __m256i multiples_of_i_plus_2 = _mm256_setr_epi32(i + 2, i + 8, i + 14, i + 20, i + 26, i + 32, i + 38, i + 44);\n        __m256i multiples_of_i_plus_4 = _mm256_setr_epi32(i + 4, i + 10, i + 16, i + 22, i + 28, i + 34, i + 40, i + 46);\n\n        __m256i length_vec = _mm256_set1_epi32(length);\n        __m256i mask1 = _mm256_cmpeq_epi32(length_vec, multiples_of_i);\n        __m256i mask2 = _mm256_cmpeq_epi32(length_vec, multiples_of_i_plus_2);\n        __m256i mask3 = _mm256_cmpeq_epi32(length_vec, multiples_of_i_plus_4);\n\n        if (_mm256_movemask_epi8(mask1) != 0 || _mm256_movemask_epi8(mask2) != 0 || _mm256_movemask_epi8(mask3) != 0) {\n            return false;\n        }\n        i += 6;\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_102_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n#include <cmath>\n\nbool prime_length_simd(const std::string & str) {\n    int length = str.length();\n    if (length <= 1) return false;\n    if (length <= 3) return true;\n    if (length % 2 == 0 || length % 3 == 0) return false;\n\n    int i = 5;\n    while (i * i <= length) {\n        __m256i multiples_of_i = _mm256_setr_epi32(i, i + 6, i + 12, i + 18, i + 24, i + 30, i + 36, i + 42);\n        __m256i multiples_of_i_plus_2 = _mm256_setr_epi32(i + 2, i + 8, i + 14, i + 20, i + 26, i + 32, i + 38, i + 44);\n        __m256i multiples_of_i_plus_4 = _mm256_setr_epi32(i + 4, i + 10, i + 16, i + 22, i + 28, i + 34, i + 40, i + 46);\n\n        __m256i length_vec = _mm256_set1_epi32(length);\n        __m256i mask1 = _mm256_cmpeq_epi32(length_vec, multiples_of_i);\n        __m256i mask2 = _mm256_cmpeq_epi32(length_vec, multiples_of_i_plus_2);\n        __m256i mask3 = _mm256_cmpeq_epi32(length_vec, multiples_of_i_plus_4);\n\n        if (_mm256_movemask_epi8(mask1) != 0 || _mm256_movemask_epi8(mask2) != 0 || _mm256_movemask_epi8(mask3) != 0) {\n            return false;\n        }\n        i += 6;\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_102_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n#include <cmath>\n\nbool prime_length_simd(const std::string & str) {\n    int length = str.length();\n    if (length <= 1) return false;\n    if (length <= 3) return true;\n    if (length % 2 == 0 || length % 3 == 0) return false;\n\n    int i = 5;\n    while (i * i <= length) {\n        __m256i multiples_of_i = _mm256_setr_epi32(i, i + 6, i + 12, i + 18, i + 24, i + 30, i + 36, i + 42);\n        __m256i multiples_of_i_plus_2 = _mm256_setr_epi32(i + 2, i + 8, i + 14, i + 20, i + 26, i + 32, i + 38, i + 44);\n        __m256i multiples_of_i_plus_4 = _mm256_setr_epi32(i + 4, i + 10, i + 16, i + 22, i + 28, i + 34, i + 40, i + 46);\n\n        __m256i length_vec = _mm256_set1_epi32(length);\n        __m256i mask1 = _mm256_cmpeq_epi32(_mm256_rem_epi32(length_vec, multiples_of_i), _mm256_setzero_si256());\n        __m256i mask2 = _mm256_cmpeq_epi32(_mm256_rem_epi32(length_vec, multiples_of_i_plus_2), _mm256_setzero_si256());\n        __m256i mask3 = _mm256_cmpeq_epi32(_mm256_rem_epi32(length_vec, multiples_of_i_plus_4), _mm256_setzero_si256());\n\n        if (_mm256_movemask_epi8(mask1) != 0 || _mm256_movemask_epi8(mask2) != 0 || _mm256_movemask_epi8(mask3) != 0) {\n            return false;\n        }\n        i += 6;\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_102_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n#include <cmath>\n\nbool prime_length_simd(const std::string & str) {\n    int length = str.length();\n    if (length < 2) return false;\n\n    __m256i v_length = _mm256_set1_epi32(length);\n    __m256i v_zero = _mm256_setzero_si256();\n    __m256i v_one = _mm256_set1_epi32(1);\n    __m256i v_two = _mm256_set1_epi32(2);\n\n    // Check divisibility from 2 to sqrt(length)\n    int limit = static_cast<int>(std::sqrt(length)) + 1;\n    for (int i = 2; i <= limit; ++i) {\n        __m256i v_i = _mm256_set1_epi32(i);\n        __m256i v_div = _mm256_div_epi32(v_length, v_i);\n        __m256i v_mul = _mm256_mullo_epi32(v_div, v_i);\n        __m256i v_cmp = _mm256_cmpeq_epi32(v_mul, v_length);\n        if (!_mm256_testz_si256(v_cmp, v_cmp)) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_103_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <bitset>\n#include <string>\n\nstd::string solve_simd(uint64_t N) {\n    __m256i ones = _mm256_set1_epi8(1);\n    __m256i counts = _mm256_setzero_si256();\n\n    uint8_t bytes[32];\n    for (int i = 0; i < 8; ++i) {\n        bytes[i] = (N >> (i * 8)) & 0xFF;\n    }\n\n    __m256i byte_vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(bytes));\n    __m256i shifted;\n\n    for (int i = 0; i < 8; ++i) {\n        shifted = _mm256_srli_epi8(byte_vec, i);\n        counts = _mm256_add_epi8(counts, _mm256_and_si256(shifted, ones));\n    }\n\n    int sum = 0;\n    for (int i = 0; i < 32; ++i) {\n        sum += reinterpret_cast<int8_t*>(&counts)[i];\n    }\n\n    return std::bitset<64>(sum).to_string().substr(64 - std::bitset<64>(sum).count());\n}\n```"}
{"task_id": "SimdBench_103_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n#include <bitset>\n\nstd::string solve_simd(uint64_t N) {\n    __m256i count = _mm256_setzero_si256();\n    __m256i ones = _mm256_set1_epi8(1);\n\n    while (N > 0) {\n        __m256i bits = _mm256_set_epi64x(\n            (N >> 56) & 0xFF, (N >> 48) & 0xFF, (N >> 40) & 0xFF, (N >> 32) & 0xFF,\n            (N >> 24) & 0xFF, (N >> 16) & 0xFF, (N >> 8) & 0xFF, N & 0xFF\n        );\n\n        bits = _mm256_and_si256(bits, ones);\n        count = _mm256_add_epi8(count, bits);\n\n        N >>= 8;\n    }\n\n    int horizontal_sum = _mm256_extract_epi16(_mm256_sad_epu8(count, _mm256_setzero_si256()), 0);\n    return std::bitset<64>(horizontal_sum).to_string().substr(64 - std::bitset<64>(horizontal_sum).count());\n}\n```"}
{"task_id": "SimdBench_103_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <bitset>\n#include <string>\n\nstd::string solve_simd(uint64_t N) {\n    __m256i counts = _mm256_setzero_si256();\n    __m256i ones = _mm256_set1_epi8(1);\n\n    while (N) {\n        __m256i bits = _mm256_set_epi64x(0, 0, 0, N);\n        counts = _mm256_add_epi8(counts, _mm256_and_si256(bits, ones));\n        N >>= 8;\n    }\n\n    int8_t count_array[32];\n    _mm256_storeu_si256(reinterpret_cast<__m256i*>(count_array), counts);\n\n    int sum = 0;\n    for (int i = 0; i < 32; ++i) {\n        sum += count_array[i];\n    }\n\n    return std::bitset<64>(sum).to_string().substr(64 - std::bitset<64>(sum).count());\n}\n```"}
{"task_id": "SimdBench_103_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n#include <bitset>\n\nstd::string solve_simd(uint64_t N) {\n    __m256i ones = _mm256_set1_epi8(1);\n    __m256i counts = _mm256_setzero_si256();\n\n    while (N > 0) {\n        __m256i bits = _mm256_set_epi64x(\n            (N >> 56) & 0xFF, (N >> 48) & 0xFF, (N >> 40) & 0xFF, (N >> 32) & 0xFF,\n            (N >> 24) & 0xFF, (N >> 16) & 0xFF, (N >> 8) & 0xFF, N & 0xFF\n        );\n        counts = _mm256_add_epi8(counts, _mm256_and_si256(bits, ones));\n        N >>= 8;\n    }\n\n    int horizontal_sum = 0;\n    for (int i = 0; i < 32; ++i) {\n        horizontal_sum += ((uint8_t*)&counts)[i];\n    }\n\n    return std::bitset<64>(horizontal_sum).to_string().substr(64 - std::bitset<64>(horizontal_sum).count());\n}\n```"}
{"task_id": "SimdBench_103_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n#include <bitset>\n\nstd::string solve_simd(uint64_t N) {\n    __m256i count = _mm256_setzero_si256();\n    __m256i ones = _mm256_set1_epi8(1);\n\n    while (N) {\n        __m256i bits = _mm256_set_epi64x(\n            (N >> 56) & 0xFF, (N >> 48) & 0xFF, (N >> 40) & 0xFF, (N >> 32) & 0xFF,\n            (N >> 24) & 0xFF, (N >> 16) & 0xFF, (N >> 8) & 0xFF, N & 0xFF\n        );\n        count = _mm256_add_epi8(count, _mm256_and_si256(bits, ones));\n        N >>= 8;\n    }\n\n    int horizontal_sum = 0;\n    for (int i = 0; i < 4; ++i) {\n        __m128i lo = _mm256_castsi256_si128(count);\n        __m128i hi = _mm256_extracti128_si256(count, 1);\n        __m128i sum = _mm_add_epi8(lo, hi);\n        sum = _mm_add_epi8(sum, _mm_srli_epi16(sum, 8));\n        sum = _mm_add_epi8(sum, _mm_srli_epi16(sum, 16));\n        horizontal_sum += _mm_cvtsi128_si32(sum) & 0xFF;\n        count = _mm256_srli_epi64(count, 16);\n    }\n\n    return std::bitset<64>(horizontal_sum).to_string().substr(64 - std::bitset<64>(horizontal_sum).count());\n}\n```"}
{"task_id": "SimdBench_104_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint add_simd(std::vector<int> lst){\n    int sum = 0;\n    int n = lst.size();\n    __m256i even_mask = _mm256_set1_epi32(0xAAAAAAAA); // Mask to check for even numbers\n    __m256i zero = _mm256_setzero_si256();\n    __m256i acc = _mm256_setzero_si256();\n\n    for (int i = 1; i < n; i += 8) {\n        __m256i vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&lst[i]));\n        __m256i odd_indices = _mm256_srli_epi32(vec, 1);\n        __m256i even_check = _mm256_and_si256(odd_indices, even_mask);\n        __m256i even_numbers = _mm256_and_si256(even_check, vec);\n        acc = _mm256_add_epi32(acc, even_numbers);\n    }\n\n    int temp[8];\n    _mm256_storeu_si256(reinterpret_cast<__m256i*>(temp), acc);\n    for (int i = 0; i < 8; ++i) {\n        sum += temp[i];\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_104_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint add_simd(std::vector<int> lst){\n    int sum = 0;\n    int n = lst.size();\n    __m256i zero = _mm256_setzero_si256();\n    __m256i even_mask = _mm256_set1_epi32(0xAAAAAAAA); // Mask to check even numbers\n\n    for (int i = 1; i < n; i += 8) {\n        __m256i vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&lst[i]));\n        __m256i odd_indices = _mm256_srli_epi32(vec, 1); // Shift right to get bit 0 from each int\n        __m256i even_numbers = _mm256_and_si256(vec, even_mask);\n        __m256i even_at_odd_indices = _mm256_and_si256(even_numbers, odd_indices);\n        __m256i abs_even_at_odd_indices = _mm256_abs_epi32(even_at_odd_indices);\n        sum += _mm256_reduce_add_epi32(abs_even_at_odd_indices);\n    }\n\n    // Handle remaining elements\n    for (int i = (n / 8) * 8 + 1; i < n; i += 2) {\n        if ((lst[i] & 1) == 0) { // Check if the number is even\n            sum += lst[i];\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_104_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint add_simd(std::vector<int> lst) {\n    int sum = 0;\n    int n = lst.size();\n    int* data = lst.data();\n\n    __m256i zero = _mm256_setzero_si256();\n    __m256i even_mask = _mm256_set1_epi32(0xAAAAAAAA); // Mask to check if a number is even\n\n    for (int i = 1; i < n; i += 8) {\n        __m256i vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&data[i]));\n        __m256i odd_indices = _mm256_srli_epi32(vec, 1); // Shift right by 1 to simulate odd index effect\n        __m256i even_elements = _mm256_and_si256(odd_indices, even_mask);\n        __m256i abs_even_elements = _mm256_abs_epi32(even_elements); // Ensure positive values\n        sum += _mm256_reduce_add_epi32(abs_even_elements);\n    }\n\n    // Handle remaining elements\n    for (int i = (n / 8) * 8 + 1; i < n; i += 2) {\n        if ((data[i] & 1) == 0) { // Check if even\n            sum += data[i];\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_104_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint add_simd(std::vector<int> lst){\n    int sum = 0;\n    int n = lst.size();\n    __m256i zero = _mm256_setzero_si256();\n    __m256i even_mask = _mm256_set1_epi32(0xAAAAAAAA); // Mask to check if a number is even\n\n    for (int i = 1; i < n; i += 8) {\n        __m256i vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&lst[i]));\n        __m256i odd_indices = _mm256_srli_epi32(vec, 1); // Shift right by 1 to simulate odd index effect\n        __m256i even_elements = _mm256_and_si256(odd_indices, even_mask);\n        __m256i signed_even_elements = _mm256_sign_epi32(even_elements, odd_indices);\n        sum += _mm256_reduce_add_epi32(signed_even_elements);\n    }\n\n    // Handle remaining elements\n    for (int i = (n / 8) * 8 + 1; i < n; i += 2) {\n        if ((lst[i] & 1) == 0) { // Check if the element is even\n            sum += lst[i];\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_104_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint add_simd(std::vector<int> lst){\n    int sum = 0;\n    int n = lst.size();\n    __m256i zero = _mm256_setzero_si256();\n    __m256i even_mask = _mm256_set1_epi32(0xAAAAAAAA); // Mask to check if a number is even\n\n    for (int i = 1; i < n; i += 8) {\n        __m256i vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&lst[i]));\n        __m256i odd_indices = _mm256_srli_epi32(vec, 1); // Shift right to get the least significant bit\n        __m256i even_elements = _mm256_and_si256(vec, even_mask);\n        __m256i even_at_odd_indices = _mm256_and_si256(even_elements, odd_indices);\n        __m256i abs_even_at_odd_indices = _mm256_abs_epi32(even_at_odd_indices);\n        sum += _mm256_reduce_add_epi32(abs_even_at_odd_indices);\n    }\n\n    // Handle remaining elements\n    for (int i = (n / 8) * 8 + 1; i < n; i += 2) {\n        if ((lst[i] & 1) == 0) { // Check if the element is even\n            sum += lst[i];\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_105_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string encrypt_simd(const std::string & s){\n    const int shift = 4; // 2 * 2\n    int n = s.size();\n    std::string result(n, ' ');\n\n    for (int i = 0; i <= n - 32; i += 32) {\n        __m256i input = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(s.data() + i));\n        __m256i shifted = _mm256_add_epi8(input, _mm256_set1_epi8(shift));\n        __m256i wrapped = _mm256_or_si256(\n            _mm256_and_si256(_mm256_cmpgt_epi8(shifted, _mm256_set1_epi8('z')), _mm256_sub_epi8(shifted, _mm256_set1_epi8(26))),\n            _mm256_andnot_si256(_mm256_cmpgt_epi8(shifted, _mm256_set1_epi8('z')), shifted)\n        );\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(result.data() + i), wrapped);\n    }\n\n    // Handle remaining characters\n    for (int i = (n / 32) * 32; i < n; ++i) {\n        char c = s[i];\n        if (c >= 'a' && c <= 'z') {\n            c = ((c - 'a' + shift) % 26) + 'a';\n        }\n        result[i] = c;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_105_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string encrypt_simd(const std::string & s) {\n    const int shift = 4; // 2 * 2\n    const int len = s.size();\n    std::string result(len, ' ');\n\n    for (int i = 0; i <= len - 32; i += 32) {\n        __m256i input = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(s.data() + i));\n        __m256i shifted = _mm256_add_epi8(input, _mm256_set1_epi8(shift));\n        __m256i wrapped = _mm256_or_si256(\n            _mm256_and_si256(_mm256_cmpgt_epi8(shifted, _mm256_set1_epi8('z')), _mm256_sub_epi8(shifted, _mm256_set1_epi8(26))),\n            _mm256_andnot_si256(_mm256_cmpgt_epi8(shifted, _mm256_set1_epi8('z')), shifted)\n        );\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(result.data() + i), wrapped);\n    }\n\n    for (int i = (len / 32) * 32; i < len; ++i) {\n        char c = s[i];\n        c += shift;\n        if (c > 'z') c -= 26;\n        result[i] = c;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_105_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string encrypt_simd(const std::string & s) {\n    const int shift = 4; // 2 * 2\n    const int len = s.size();\n    std::string result(len, ' ');\n\n    for (int i = 0; i <= len - 32; i += 32) {\n        __m256i input = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(s.data() + i));\n        __m256i shifted = _mm256_add_epi8(input, _mm256_set1_epi8(shift));\n        __m256i wrapped = _mm256_or_si256(\n            _mm256_and_si256(_mm256_cmpgt_epi8(shifted, _mm256_set1_epi8('z')), _mm256_sub_epi8(shifted, _mm256_set1_epi8(26))),\n            _mm256_andnot_si256(_mm256_cmpgt_epi8(shifted, _mm256_set1_epi8('z')), shifted)\n        );\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(result.data() + i), wrapped);\n    }\n\n    for (int i = (len / 32) * 32; i < len; ++i) {\n        char c = s[i];\n        if (c >= 'a' && c <= 'z') {\n            c = ((c - 'a' + shift) % 26) + 'a';\n        }\n        result[i] = c;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_105_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string encrypt_simd(const std::string & s){\n    std::string result(s.size(), ' ');\n    const int shift = 4; // 2 * 2\n    const __m256i shift_vec = _mm256_set1_epi8(shift);\n    const __m256i a = _mm256_set1_epi8('a');\n    const __m256i z = _mm256_set1_epi8('z');\n\n    for (size_t i = 0; i < s.size(); i += 32) {\n        __m256i input = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(s.data() + i));\n        __m256i lower = _mm256_max_epu8(_mm256_sub_epi8(input, a), _mm256_setzero_si256());\n        __m256i upper = _mm256_min_epu8(lower, _mm256_sub_epi8(z, a));\n        __m256i shifted = _mm256_add_epi8(upper, shift_vec);\n        __m256i wrapped = _mm256_min_epu8(shifted, _mm256_sub_epi8(z, a));\n        __m256i encrypted = _mm256_add_epi8(wrapped, a);\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(result.data() + i), encrypted);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_105_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string encrypt_simd(const std::string & s) {\n    const int shift = 4; // 2 * 2\n    const int len = s.size();\n    std::string result(len, ' ');\n\n    for (int i = 0; i <= len - 32; i += 32) {\n        __m256i input = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(s.data() + i));\n        __m256i shifted = _mm256_add_epi8(input, _mm256_set1_epi8(shift));\n        __m256i wrapped = _mm256_or_si256(\n            _mm256_and_si256(_mm256_cmpgt_epi8(shifted, _mm256_set1_epi8('z')), _mm256_sub_epi8(shifted, _mm256_set1_epi8(26))),\n            _mm256_andnot_si256(_mm256_cmpgt_epi8(shifted, _mm256_set1_epi8('z')), shifted)\n        );\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(result.data() + i), wrapped);\n    }\n\n    for (int i = (len / 32) * 32; i < len; ++i) {\n        char c = s[i];\n        if (c >= 'a' && c <= 'z') {\n            c = ((c - 'a' + shift) % 26) + 'a';\n        }\n        result[i] = c;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_106_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string encode_simd(const std::string & message) {\n    const int len = message.size();\n    std::string result(len, ' ');\n\n    const __m256i vowels_lower = _mm256_setr_epi8('a', 'e', 'i', 'o', 'u', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n    const __m256i vowels_upper = _mm256_setr_epi8('A', 'E', 'I', 'O', 'U', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n    const __m256i shift = _mm256_set1_epi8(2);\n\n    for (int i = 0; i <= len - 32; i += 32) {\n        __m256i input = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(message.data() + i));\n        __m256i lower_mask = _mm256_cmplt_epi8(input, _mm256_set1_epi8('a'));\n        __m256i upper_mask = _mm256_cmpgt_epi8(input, _mm256_set1_epi8('z'));\n        __m256i letter_mask = _mm256_andnot_si256(_mm256_or_si256(lower_mask, upper_mask), _mm256_set1_epi8(-1));\n\n        __m256i swapped_case = _mm256_xor_si256(input, _mm256_set1_epi8(0x20));\n\n        __m256i is_vowel_lower = _mm256_cmpeq_epi8(_mm256_shuffle_epi8(vowels_lower, input), _mm256_set1_epi8(-1));\n        __m256i is_vowel_upper = _mm256_cmpeq_epi8(_mm256_shuffle_epi8(vowels_upper, input), _mm256_set1_epi8(-1));\n        __m256i is_vowel = _mm256_or_si256(is_vowel_lower, is_vowel_upper);\n\n        __m256i replaced_vowels = _mm256_add_epi8(swapped_case, _mm256_and_si256(is_vowel, shift));\n\n        __m256i result_chunk = _mm256_or_si256(_mm256_andnot_si256(letter_mask, input), _mm256_and_si256(letter_mask, replaced_vowels));\n\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(result.data() + i), result_chunk);\n    }\n\n    // Handle remaining characters\n    for (int i = (len / 32) * 32; i < len; ++i) {\n        char c = message[i];\n        if (c >= 'a' && c <= 'z') {\n            c = c - 'a' + 'A';\n        } else if (c >= 'A' && c <= 'Z') {\n            c = c - 'A' + 'a';\n        }\n        switch (c) {\n            case 'a': c = 'c'; break;\n            case 'e': c = 'g'; break;\n            case 'i': c = 'k'; break;\n            case 'o': c = 'q'; break;\n            case 'u': c = 'w'; break;\n            case 'A': c = 'C'; break;\n            case 'E': c = 'G'; break;\n            case 'I': c = 'K'; break;\n            case 'O': c = 'Q'; break;\n            case 'U': c = 'W'; break;\n        }\n        result[i] = c;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_106_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string encode_simd(const std::string & message) {\n    const int len = message.size();\n    std::string result(len, ' ');\n\n    const __m256i vowels_lower = _mm256_setr_epi8('a', 'e', 'i', 'o', 'u', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n    const __m256i vowels_upper = _mm256_setr_epi8('A', 'E', 'I', 'O', 'U', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n    const __m256i shift = _mm256_set1_epi8(2);\n\n    for (int i = 0; i <= len - 32; i += 32) {\n        __m256i input = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(message.data() + i));\n        __m256i lower_case_mask = _mm256_cmpgt_epi8(input, _mm256_set1_epi8('Z'));\n        __m256i upper_case_mask = _mm256_cmpgt_epi8(_mm256_set1_epi8('z'), input);\n        __m256i swapped_case = _mm256_or_si256(_mm256_and_si256(lower_case_mask, _mm256_sub_epi8(input, _mm256_set1_epi8(32))),\n                                               _mm256_and_si256(upper_case_mask, _mm256_add_epi8(input, _mm256_set1_epi8(32))));\n\n        __m256i is_vowel_lower = _mm256_cmpeq_epi8(_mm256_shuffle_epi8(vowels_lower, swapped_case), _mm256_set1_epi8('a'));\n        __m256i is_vowel_upper = _mm256_cmpeq_epi8(_mm256_shuffle_epi8(vowels_upper, swapped_case), _mm256_set1_epi8('A'));\n        __m256i is_vowel = _mm256_or_si256(is_vowel_lower, is_vowel_upper);\n\n        __m256i shifted_vowels = _mm256_add_epi8(swapped_case, shift);\n        __m256i encoded = _mm256_or_si256(_mm256_andnot_si256(is_vowel, swapped_case),\n                                          _mm256_and_si256(is_vowel, shifted_vowels));\n\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(result.data() + i), encoded);\n    }\n\n    // Handle remaining characters\n    for (int i = (len / 32) * 32; i < len; ++i) {\n        char c = message[i];\n        if (c >= 'a' && c <= 'z') {\n            c = c - 32;\n        } else if (c >= 'A' && c <= 'Z') {\n            c = c + 32;\n        }\n        if (c == 'a' || c == 'e' || c == 'i' || c == 'o' || c == 'u') {\n            c = c + 2;\n        } else if (c == 'A' || c == 'E' || c == 'I' || c == 'O' || c == 'U') {\n            c = c + 2;\n        }\n        result[i] = c;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_106_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string encode_simd(const std::string & message) {\n    const int len = message.size();\n    std::string result(len, ' ');\n\n    const __m256i vowels_lower = _mm256_setr_epi8('a', 'e', 'i', 'o', 'u', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n    const __m256i vowels_upper = _mm256_setr_epi8('A', 'E', 'I', 'O', 'U', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n    const __m256i shift = _mm256_set1_epi8(2);\n\n    for (int i = 0; i <= len - 32; i += 32) {\n        __m256i input = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(message.c_str() + i));\n        __m256i lower_mask = _mm256_cmplt_epi8(input, _mm256_set1_epi8('a'));\n        __m256i upper_mask = _mm256_cmpgt_epi8(input, _mm256_set1_epi8('z'));\n        __m256i letter_mask = _mm256_andnot_si256(_mm256_or_si256(lower_mask, upper_mask), _mm256_set1_epi8(-1));\n\n        __m256i swapped_case = _mm256_xor_si256(input, _mm256_set1_epi8(0x20));\n\n        __m256i is_vowel_lower = _mm256_cmpeq_epi8(_mm256_shuffle_epi8(vowels_lower, input), _mm256_set1_epi8(-1));\n        __m256i is_vowel_upper = _mm256_cmpeq_epi8(_mm256_shuffle_epi8(vowels_upper, input), _mm256_set1_epi8(-1));\n        __m256i is_vowel = _mm256_or_si256(is_vowel_lower, is_vowel_upper);\n\n        __m256i replaced_vowels = _mm256_add_epi8(swapped_case, _mm256_and_si256(is_vowel, shift));\n\n        __m256i result_chunk = _mm256_or_si256(_mm256_andnot_si256(letter_mask, input), _mm256_and_si256(letter_mask, replaced_vowels));\n\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(result.data() + i), result_chunk);\n    }\n\n    // Handle remaining characters\n    for (int i = (len / 32) * 32; i < len; ++i) {\n        char c = message[i];\n        if (c >= 'a' && c <= 'z') {\n            c = c - 'a' + 'A';\n        } else if (c >= 'A' && c <= 'Z') {\n            c = c - 'A' + 'a';\n        }\n        if (c == 'a' || c == 'e' || c == 'i' || c == 'o' || c == 'u') {\n            c += 2;\n        } else if (c == 'A' || c == 'E' || c == 'I' || c == 'O' || c == 'U') {\n            c += 2;\n        }\n        result[i] = c;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_106_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string encode_simd(const std::string & message) {\n    const int len = message.size();\n    std::string result(len, ' ');\n\n    const __m256i vowels_lower = _mm256_setr_epi8('a', 'e', 'i', 'o', 'u', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n    const __m256i vowels_upper = _mm256_setr_epi8('A', 'E', 'I', 'O', 'U', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n    const __m256i shift = _mm256_set1_epi8(2);\n\n    for (int i = 0; i <= len - 32; i += 32) {\n        __m256i input = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(message.data() + i));\n\n        // Swap case\n        __m256i lower_mask = _mm256_cmpgt_epi8(input, _mm256_set1_epi8('Z'));\n        __m256i swapped_case = _mm256_xor_si256(input, _mm256_and_si256(_mm256_set1_epi8(0x20), _mm256_cmpeq_epi8(lower_mask, _mm256_set1_epi8(0))));\n\n        // Check for vowels and shift\n        __m256i is_vowel_lower = _mm256_cmpeq_epi8(swapped_case, vowels_lower);\n        __m256i is_vowel_upper = _mm256_cmpeq_epi8(swapped_case, vowels_upper);\n        __m256i is_vowel = _mm256_or_si256(is_vowel_lower, is_vowel_upper);\n        __m256i shifted_vowels = _mm256_add_epi8(swapped_case, _mm256_and_si256(shift, is_vowel));\n\n        // Combine results\n        __m256i result_chunk = _mm256_or_si256(_mm256_andnot_si256(is_vowel, swapped_case), _mm256_and_si256(is_vowel, shifted_vowels));\n\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(result.data() + i), result_chunk);\n    }\n\n    // Handle remaining characters\n    for (int i = (len / 32) * 32; i < len; ++i) {\n        char c = message[i];\n        if (c >= 'a' && c <= 'z') {\n            c = toupper(c);\n        } else if (c >= 'A' && c <= 'Z') {\n            c = tolower(c);\n        }\n        switch (c) {\n            case 'a': c = 'c'; break;\n            case 'e': c = 'g'; break;\n            case 'i': c = 'k'; break;\n            case 'o': c = 'q'; break;\n            case 'u': c = 'w'; break;\n            case 'A': c = 'C'; break;\n            case 'E': c = 'G'; break;\n            case 'I': c = 'K'; break;\n            case 'O': c = 'Q'; break;\n            case 'U': c = 'W'; break;\n        }\n        result[i] = c;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_106_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string encode_simd(const std::string & message) {\n    const int len = message.size();\n    std::string result(len, ' ');\n\n    const __m256i vowels_lower = _mm256_setr_epi8('a', 'e', 'i', 'o', 'u', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n    const __m256i vowels_upper = _mm256_setr_epi8('A', 'E', 'I', 'O', 'U', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n    const __m256i shift = _mm256_set1_epi8(2);\n\n    for (int i = 0; i <= len - 32; i += 32) {\n        __m256i input = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(message.data() + i));\n\n        // Swap case\n        __m256i lower_mask = _mm256_cmpgt_epi8(input, _mm256_set1_epi8('Z'));\n        __m256i swapped_case = _mm256_xor_si256(input, _mm256_and_si256(_mm256_set1_epi8(0x20), _mm256_cmpeq_epi8(lower_mask, _mm256_set1_epi8(0))));\n\n        // Check for vowels and shift\n        __m256i is_vowel_lower = _mm256_cmpeq_epi8(swapped_case, vowels_lower);\n        __m256i is_vowel_upper = _mm256_cmpeq_epi8(swapped_case, vowels_upper);\n        __m256i is_vowel = _mm256_or_si256(is_vowel_lower, is_vowel_upper);\n        __m256i shifted_vowels = _mm256_add_epi8(swapped_case, shift);\n        __m256i encoded = _mm256_blendv_epi8(swapped_case, shifted_vowels, is_vowel);\n\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(result.data() + i), encoded);\n    }\n\n    // Handle remaining characters\n    for (int i = (len / 32) * 32; i < len; ++i) {\n        char c = message[i];\n        if (c >= 'a' && c <= 'z') {\n            c = toupper(c);\n        } else if (c >= 'A' && c <= 'Z') {\n            c = tolower(c);\n        }\n        if (c == 'a' || c == 'e' || c == 'i' || c == 'o' || c == 'u') {\n            c += 2;\n        } else if (c == 'A' || c == 'E' || c == 'I' || c == 'O' || c == 'U') {\n            c += 2;\n        }\n        result[i] = c;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_107_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <map>\n#include <string>\n#include <cctype>\n\nbool check_dict_case_simd(std::map<std::string, std::string> dict) {\n    if (dict.empty()) return false;\n\n    bool all_lower = true;\n    bool all_upper = true;\n\n    for (const auto& pair : dict) {\n        const std::string& key = pair.first;\n        size_t len = key.size();\n        size_t i = 0;\n\n        for (; i <= len - 32; i += 32) {\n            __m256i chunk = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(key.c_str() + i));\n            __m256i lower_mask = _mm256_cmplt_epi8(chunk, _mm256_set1_epi8('a'));\n            __m256i upper_mask = _mm256_cmpgt_epi8(chunk, _mm256_set1_epi8('Z'));\n            __m256i alpha_mask = _mm256_or_si256(_mm256_cmplt_epi8(chunk, _mm256_set1_epi8('A')), _mm256_cmpgt_epi8(chunk, _mm256_set1_epi8('z')));\n\n            if (!_mm256_testz_si256(lower_mask, lower_mask)) all_lower = false;\n            if (!_mm256_testz_si256(upper_mask, upper_mask)) all_upper = false;\n            if (!_mm256_testz_si256(alpha_mask, alpha_mask)) return false;\n        }\n\n        for (; i < len; ++i) {\n            char c = key[i];\n            if (!std::islower(c)) all_lower = false;\n            if (!std::isupper(c)) all_upper = false;\n            if (!std::isalpha(c)) return false;\n        }\n    }\n\n    return all_lower || all_upper;\n}\n```"}
{"task_id": "SimdBench_107_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <map>\n#include <string>\n#include <cctype>\n\nbool check_dict_case_simd(std::map<std::string, std::string> dict) {\n    if (dict.empty()) return false;\n\n    bool all_lower = true;\n    bool all_upper = true;\n\n    for (const auto& pair : dict) {\n        const std::string& key = pair.first;\n        size_t len = key.size();\n        size_t i = 0;\n\n        for (; i <= len - 32; i += 32) {\n            __m256i chunk = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(key.c_str() + i));\n            __m256i lower_mask = _mm256_cmplt_epi8(chunk, _mm256_set1_epi8('a'));\n            __m256i upper_mask = _mm256_cmpgt_epi8(chunk, _mm256_set1_epi8('Z'));\n            __m256i alpha_mask = _mm256_or_si256(lower_mask, upper_mask);\n            __m256i non_alpha_mask = _mm256_andnot_si256(alpha_mask, _mm256_cmplt_epi8(chunk, _mm256_set1_epi8('a')));\n            __m256i lower_check = _mm256_cmplt_epi8(chunk, _mm256_set1_epi8('a'));\n            __m256i upper_check = _mm256_cmpgt_epi8(chunk, _mm256_set1_epi8('Z'));\n\n            if (!_mm256_testz_si256(lower_mask, lower_mask)) all_lower = false;\n            if (!_mm256_testz_si256(upper_mask, upper_mask)) all_upper = false;\n            if (!_mm256_testz_si256(non_alpha_mask, non_alpha_mask)) return false;\n        }\n\n        for (; i < len; ++i) {\n            char c = key[i];\n            if (!std::isalpha(c)) return false;\n            if (!std::islower(c)) all_lower = false;\n            if (!std::isupper(c)) all_upper = false;\n        }\n    }\n\n    return all_lower || all_upper;\n}\n```"}
{"task_id": "SimdBench_107_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <map>\n#include <string>\n#include <cctype>\n\nbool check_dict_case_simd(std::map<std::string, std::string> dict) {\n    if (dict.empty()) return false;\n\n    bool all_lower = true;\n    bool all_upper = true;\n\n    for (const auto& pair : dict) {\n        const std::string& key = pair.first;\n        size_t len = key.size();\n        size_t i = 0;\n\n        for (; i <= len - 32; i += 32) {\n            __m256i chunk = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(key.c_str() + i));\n            __m256i lower_mask = _mm256_cmplt_epi8(chunk, _mm256_set1_epi8('a'));\n            __m256i upper_mask = _mm256_cmpgt_epi8(chunk, _mm256_set1_epi8('Z'));\n            __m256i alpha_mask = _mm256_or_si256(_mm256_cmplt_epi8(chunk, _mm256_set1_epi8('A')), _mm256_cmpgt_epi8(chunk, _mm256_set1_epi8('z')));\n\n            if (!_mm256_testz_si256(lower_mask, lower_mask)) all_lower = false;\n            if (!_mm256_testz_si256(upper_mask, upper_mask)) all_upper = false;\n            if (!_mm256_testz_si256(alpha_mask, alpha_mask)) return false;\n        }\n\n        for (; i < len; ++i) {\n            char c = key[i];\n            if (!std::islower(c)) all_lower = false;\n            if (!std::isupper(c)) all_upper = false;\n            if (!std::isalpha(c)) return false;\n        }\n    }\n\n    return all_lower || all_upper;\n}\n```"}
{"task_id": "SimdBench_107_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <map>\n#include <string>\n#include <cctype>\n\nbool check_dict_case_simd(std::map<std::string, std::string> dict) {\n    if (dict.empty()) return false;\n\n    bool all_lower = true;\n    bool all_upper = true;\n\n    for (const auto& pair : dict) {\n        const std::string& key = pair.first;\n        size_t len = key.size();\n        size_t i = 0;\n\n        for (; i <= len - 32; i += 32) {\n            __m256i str = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(key.c_str() + i));\n            __m256i lower_mask = _mm256_cmplt_epi8(str, _mm256_set1_epi8('a'));\n            __m256i upper_mask = _mm256_cmpgt_epi8(str, _mm256_set1_epi8('Z'));\n            __m256i alpha_mask = _mm256_or_si256(lower_mask, upper_mask);\n            __m256i lower_check = _mm256_andnot_si256(lower_mask, alpha_mask);\n            __m256i upper_check = _mm256_andnot_si256(upper_mask, alpha_mask);\n\n            if (!_mm256_testz_si256(lower_check, lower_check)) all_lower = false;\n            if (!_mm256_testz_si256(upper_check, upper_check)) all_upper = false;\n        }\n\n        for (; i < len; ++i) {\n            char c = key[i];\n            if (!std::islower(c)) all_lower = false;\n            if (!std::isupper(c)) all_upper = false;\n        }\n\n        if (!all_lower && !all_upper) return false;\n    }\n\n    return all_lower || all_upper;\n}\n```"}
{"task_id": "SimdBench_107_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <map>\n#include <string>\n#include <cctype>\n\nbool check_dict_case_simd(std::map<std::string, std::string> dict) {\n    if (dict.empty()) return false;\n\n    bool all_lower = true;\n    bool all_upper = true;\n\n    for (const auto& pair : dict) {\n        const std::string& key = pair.first;\n        size_t len = key.size();\n        size_t i = 0;\n\n        for (; i <= len - 32; i += 32) {\n            __m256i chunk = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(key.c_str() + i));\n            __m256i lower_mask = _mm256_cmplt_epi8(chunk, _mm256_set1_epi8('a'));\n            __m256i upper_mask = _mm256_cmpgt_epi8(chunk, _mm256_set1_epi8('Z'));\n            __m256i alpha_mask = _mm256_or_si256(_mm256_cmplt_epi8(chunk, _mm256_set1_epi8('A')), _mm256_cmpgt_epi8(chunk, _mm256_set1_epi8('z')));\n\n            if (!_mm256_testz_si256(lower_mask, lower_mask)) all_lower = false;\n            if (!_mm256_testz_si256(upper_mask, upper_mask)) all_upper = false;\n            if (!_mm256_testz_si256(alpha_mask, alpha_mask)) return false;\n        }\n\n        for (; i < len; ++i) {\n            char c = key[i];\n            if (!std::islower(c)) all_lower = false;\n            if (!std::isupper(c)) all_upper = false;\n            if (!std::isalpha(c)) return false;\n        }\n    }\n\n    return all_lower || all_upper;\n}\n```"}
{"task_id": "SimdBench_108_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <cmath>\n\nstd::vector<int> count_up_to_simd(int n) {\n    std::vector<int> primes;\n    if (n <= 2) return primes;\n\n    std::vector<bool> is_prime(n, true);\n    is_prime[0] = is_prime[1] = false;\n\n    int limit = static_cast<int>(std::sqrt(n)) + 1;\n    for (int i = 2; i < limit; ++i) {\n        if (!is_prime[i]) continue;\n\n        __m256i index = _mm256_setr_epi32(i * 2, i * 3, i * 4, i * 5, i * 6, i * 7, i * 8, i * 9);\n        __m256i increment = _mm256_set1_epi32(i);\n\n        for (int j = i * i; j < n; ) {\n            __m256i mask = _mm256_cmpgt_epi32(_mm256_set1_epi32(n), index);\n            int valid_mask = _mm256_movemask_epi8(mask);\n            if (!valid_mask) break;\n\n            for (int k = 0; k < 8; ++k) {\n                if ((valid_mask >> (k * 4)) & 0xF) {\n                    is_prime[index.m256i_i32[k]] = false;\n                }\n            }\n\n            index = _mm256_add_epi32(index, increment);\n            j += i * 8;\n        }\n    }\n\n    for (int i = 2; i < n; ++i) {\n        if (is_prime[i]) {\n            primes.push_back(i);\n        }\n    }\n\n    return primes;\n}\n```"}
{"task_id": "SimdBench_108_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <cmath>\n\nstd::vector<int> count_up_to_simd(int n) {\n    std::vector<int> primes;\n    if (n <= 2) return primes;\n\n    std::vector<bool> is_prime(n, true);\n    is_prime[0] = is_prime[1] = false;\n\n    int limit = static_cast<int>(std::sqrt(n)) + 1;\n    for (int i = 2; i < limit; ++i) {\n        if (!is_prime[i]) continue;\n\n        __m256i index = _mm256_setr_epi32(i * 2, i * 3, i * 4, i * 5, i * 6, i * 7, i * 8, i * 9);\n        __m256i increment = _mm256_set1_epi32(i);\n\n        for (int j = i * i; j < n;) {\n            __m256i mask = _mm256_cmpgt_epi32(_mm256_set1_epi32(n), index);\n            int valid_mask = _mm256_movemask_epi8(mask);\n            if (valid_mask == 0) break;\n\n            for (int k = 0; k < 8; ++k) {\n                if ((valid_mask >> (k * 4)) & 0xF) {\n                    int idx = _mm256_extract_epi32(index, k);\n                    if (idx < n) is_prime[idx] = false;\n                }\n            }\n\n            index = _mm256_add_epi32(index, increment);\n        }\n    }\n\n    for (int i = 2; i < n; ++i) {\n        if (is_prime[i]) primes.push_back(i);\n    }\n\n    return primes;\n}\n```"}
{"task_id": "SimdBench_108_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <cmath>\n\nstd::vector<int> count_up_to_simd(int n) {\n    std::vector<int> primes;\n    if (n <= 2) return primes;\n\n    std::vector<bool> is_prime(n, true);\n    is_prime[0] = is_prime[1] = false;\n\n    int limit = static_cast<int>(std::sqrt(n)) + 1;\n    for (int i = 2; i < limit; ++i) {\n        if (!is_prime[i]) continue;\n\n        __m256i index = _mm256_setr_epi32(i * 2, i * 3, i * 4, i * 5, i * 6, i * 7, i * 8, i * 9);\n        __m256i increment = _mm256_set1_epi32(i);\n\n        for (int j = i * i; j < n; ) {\n            __m256i mask = _mm256_cmpgt_epi32(_mm256_set1_epi32(n), index);\n            int valid_mask = _mm256_movemask_epi8(mask);\n            if (!valid_mask) break;\n\n            for (int k = 0; k < 8; ++k) {\n                if ((valid_mask >> (k * 4)) & 0xF) {\n                    is_prime[index.m256i_i32[k]] = false;\n                }\n            }\n\n            index = _mm256_add_epi32(index, increment);\n            j += i * 8;\n        }\n    }\n\n    for (int i = 2; i < n; ++i) {\n        if (is_prime[i]) {\n            primes.push_back(i);\n        }\n    }\n\n    return primes;\n}\n```"}
{"task_id": "SimdBench_108_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <cmath>\n\nstd::vector<int> count_up_to_simd(int n) {\n    std::vector<int> primes;\n    if (n <= 2) return primes;\n\n    std::vector<bool> is_prime(n, true);\n    is_prime[0] = is_prime[1] = false;\n\n    int limit = static_cast<int>(std::sqrt(n)) + 1;\n    for (int i = 2; i < limit; ++i) {\n        if (!is_prime[i]) continue;\n\n        __m256i index = _mm256_setr_epi32(i * 2, i * 3, i * 4, i * 5, i * 6, i * 7, i * 8, i * 9);\n        __m256i increment = _mm256_set1_epi32(i);\n\n        for (int j = i * i; j < n;) {\n            __m256i mask = _mm256_cmpgt_epi32(_mm256_set1_epi32(n), index);\n            int valid_mask = _mm256_movemask_epi8(mask);\n            if (valid_mask == 0) break;\n\n            for (int k = 0; k < 8; ++k) {\n                if ((valid_mask >> (k * 4)) & 0xF) {\n                    int idx = _mm256_extract_epi32(index, k);\n                    if (idx < n) is_prime[idx] = false;\n                }\n            }\n            index = _mm256_add_epi32(index, increment);\n        }\n    }\n\n    for (int i = 2; i < n; ++i) {\n        if (is_prime[i]) primes.push_back(i);\n    }\n\n    return primes;\n}\n```"}
{"task_id": "SimdBench_108_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <cmath>\n\nstd::vector<int> count_up_to_simd(int n) {\n    std::vector<int> primes;\n    if (n <= 2) return primes;\n\n    std::vector<bool> is_prime(n, true);\n    is_prime[0] = is_prime[1] = false;\n\n    int limit = static_cast<int>(std::sqrt(n)) + 1;\n    for (int i = 2; i < limit; ++i) {\n        if (!is_prime[i]) continue;\n\n        __m256i index = _mm256_setr_epi32(i * 2, i * 3, i * 4, i * 5, i * 6, i * 7, i * 8, i * 9);\n        __m256i increment = _mm256_set1_epi32(i);\n\n        for (int j = i * i; j < n;) {\n            __m256i mask = _mm256_cmpgt_epi32(_mm256_set1_epi32(n), index);\n            int mask_value = _mm256_movemask_epi8(mask);\n            if (mask_value == 0) break;\n\n            for (int k = 0; k < 8; ++k) {\n                if ((mask_value >> (4 * k)) & 0xF) {\n                    is_prime[index.m256i_i32[k]] = false;\n                }\n            }\n\n            index = _mm256_add_epi32(index, increment);\n            j += 8 * i;\n        }\n    }\n\n    for (int i = 2; i < n; ++i) {\n        if (is_prime[i]) {\n            primes.push_back(i);\n        }\n    }\n\n    return primes;\n}\n```"}
{"task_id": "SimdBench_109_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nint count_upper_simd(const std::string & s){\n    int count = 0;\n    const char* str = s.c_str();\n    int len = s.size();\n    __m256i vowels = _mm256_setr_epi8('A', 0, 'E', 0, 'I', 0, 'O', 0, 'U', 0, 0, 0, 0, 0, 0, 0, 'A', 0, 'E', 0, 'I', 0, 'O', 0, 'U', 0, 0, 0, 0, 0, 0, 0);\n    __m256i mask = _mm256_set1_epi8(0x80);\n    __m256i zero = _mm256_setzero_si256();\n\n    for (int i = 0; i <= len - 32; i += 32) {\n        __m256i chars = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(str + i));\n        __m256i even_chars = _mm256_andnot_si256(mask, chars);\n        __m256i cmp = _mm256_cmpeq_epi8(even_chars, vowels);\n        __m256i upper_vowels = _mm256_and_si256(cmp, even_chars);\n        __m256i upper_vowels_mask = _mm256_cmpgt_epi8(upper_vowels, zero);\n        count += _mm_popcnt_u32(_mm256_movemask_epi8(upper_vowels_mask) & 0xAAAAAAAA);\n    }\n\n    for (int i = (len & ~31); i < len; i += 2) {\n        if (str[i] == 'A' || str[i] == 'E' || str[i] == 'I' || str[i] == 'O' || str[i] == 'U') {\n            count++;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_109_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nint count_upper_simd(const std::string & s){\n    int count = 0;\n    const char* str = s.c_str();\n    int len = s.size();\n    __m256i vowels = _mm256_setr_epi8('A', 0, 'E', 0, 'I', 0, 'O', 0, 'U', 0, 0, 0, 0, 0, 0, 0, 'A', 0, 'E', 0, 'I', 0, 'O', 0, 'U', 0, 0, 0, 0, 0, 0, 0);\n    __m256i mask = _mm256_set1_epi8(0x80);\n    __m256i zero = _mm256_setzero_si256();\n\n    for (int i = 0; i <= len - 32; i += 32) {\n        __m256i chars = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(str + i));\n        __m256i even_chars = _mm256_and_si256(chars, mask);\n        __m256i vowel_check = _mm256_cmpeq_epi8(even_chars, vowels);\n        __m256i upper_check = _mm256_cmpgt_epi8(chars, _mm256_set1_epi8('@'));\n        __m256i result = _mm256_and_si256(vowel_check, upper_check);\n        int match_count = _mm256_movemask_epi8(result);\n        count += __builtin_popcount(match_count);\n    }\n\n    for (int i = (len / 32) * 32; i < len; i += 2) {\n        if (str[i] >= 'A' && str[i] <= 'Z' && (str[i] == 'A' || str[i] == 'E' || str[i] == 'I' || str[i] == 'O' || str[i] == 'U')) {\n            count++;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_109_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nint count_upper_simd(const std::string & s){\n    int count = 0;\n    const char* str = s.c_str();\n    int len = s.size();\n    __m256i vowels = _mm256_setr_epi8('A', 0, 'E', 0, 'I', 0, 'O', 0, 'U', 0, 0, 0, 0, 0, 0, 0, 'A', 0, 'E', 0, 'I', 0, 'O', 0, 'U', 0, 0, 0, 0, 0, 0, 0);\n    __m256i mask = _mm256_set1_epi8(0x80);\n    __m256i upper_mask = _mm256_setr_epi8(0x80, 0, 0x80, 0, 0x80, 0, 0x80, 0, 0x80, 0, 0, 0, 0, 0, 0, 0, 0x80, 0, 0x80, 0, 0x80, 0, 0x80, 0, 0x80, 0, 0, 0, 0, 0, 0, 0);\n\n    for (int i = 0; i <= len - 32; i += 32) {\n        __m256i data = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(str + i));\n        __m256i even_indices = _mm256_and_si256(data, mask);\n        __m256i is_upper = _mm256_and_si256(data, upper_mask);\n        __m256i is_vowel = _mm256_cmpeq_epi8(_mm256_or_si256(even_indices, vowels), vowels);\n        __m256i result = _mm256_and_si256(is_upper, is_vowel);\n        count += _mm_popcnt_u32(_mm256_movemask_epi8(result));\n    }\n\n    for (int i = (len / 32) * 32; i < len; i += 2) {\n        if (str[i] >= 'A' && str[i] <= 'Z' && (str[i] == 'A' || str[i] == 'E' || str[i] == 'I' || str[i] == 'O' || str[i] == 'U')) {\n            count++;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_109_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nint count_upper_simd(const std::string & s){\n    int count = 0;\n    const char* str = s.c_str();\n    int len = s.size();\n    __m256i vowels = _mm256_setr_epi8('A', 0, 'E', 0, 'I', 0, 'O', 0, 'U', 0, 0, 0, 0, 0, 0, 0, 'A', 0, 'E', 0, 'I', 0, 'O', 0, 'U', 0, 0, 0, 0, 0, 0, 0);\n    __m256i mask = _mm256_set1_epi8(0x80);\n    __m256i ones = _mm256_set1_epi8(1);\n\n    for (int i = 0; i <= len - 32; i += 32) {\n        __m256i chars = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(str + i));\n        __m256i even_chars = _mm256_andnot_si256(mask, chars);\n        __m256i cmp = _mm256_cmpeq_epi8(even_chars, vowels);\n        __m256i upper_vowels = _mm256_and_si256(cmp, ones);\n        __m256i sum = _mm256_sad_epu8(upper_vowels, _mm256_setzero_si256());\n        __m128i low_sum = _mm_add_epi32(_mm256_castsi256_si128(sum), _mm256_extracti128_si256(sum, 1));\n        low_sum = _mm_add_epi32(low_sum, _mm_srli_si128(low_sum, 4));\n        low_sum = _mm_add_epi32(low_sum, _mm_srli_si128(low_sum, 8));\n        count += _mm_cvtsi128_si32(low_sum);\n    }\n\n    for (int i = (len / 32) * 32; i < len; i += 2) {\n        if (str[i] == 'A' || str[i] == 'E' || str[i] == 'I' || str[i] == 'O' || str[i] == 'U') {\n            count++;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_109_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nint count_upper_simd(const std::string & s){\n    int count = 0;\n    const char* str = s.c_str();\n    int len = s.size();\n    __m256i vowels = _mm256_setr_epi8('A', 0, 'E', 0, 'I', 0, 'O', 0, 'U', 0, 0, 0, 0, 0, 0, 0, 'A', 0, 'E', 0, 'I', 0, 'O', 0, 'U', 0, 0, 0, 0, 0, 0, 0);\n    __m256i mask = _mm256_set1_epi8(0x80);\n    __m256i zero = _mm256_setzero_si256();\n\n    for (int i = 0; i <= len - 32; i += 32) {\n        __m256i chars = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(str + i));\n        __m256i even_chars = _mm256_and_si256(chars, mask);\n        __m256i vowel_check = _mm256_cmpeq_epi8(_mm256_or_si256(even_chars, vowels), vowels);\n        __m256i shifted = _mm256_srli_epi16(vowel_check, 7);\n        __m256i summed = _mm256_sad_epu8(shifted, zero);\n        int partial_count = _mm256_extract_epi16(summed, 0) + _mm256_extract_epi16(summed, 4) + _mm256_extract_epi16(summed, 8) + _mm256_extract_epi16(summed, 12);\n        count += partial_count / 256;\n    }\n\n    for (int i = (len / 32) * 32; i < len; i += 2) {\n        if (str[i] == 'A' || str[i] == 'E' || str[i] == 'I' || str[i] == 'O' || str[i] == 'U') {\n            count++;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_110_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> make_a_pile_simd(int n){\n    std::vector<int> result(n);\n    int* result_ptr = result.data();\n\n    __m256i increment;\n    if (n % 2 == 0) {\n        increment = _mm256_set1_epi32(2);\n    } else {\n        increment = _mm256_set1_epi32(2);\n    }\n\n    __m256i current_values = _mm256_setr_epi32(n, n+2, n+4, n+6, n+8, n+10, n+12, n+14);\n\n    int i = 0;\n    for (; i <= n-8; i += 8) {\n        _mm256_storeu_si256((__m256i*)(result_ptr + i), current_values);\n        current_values = _mm256_add_epi32(current_values, increment);\n    }\n\n    for (; i < n; ++i) {\n        result_ptr[i] = n + 2 * i;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_110_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> make_a_pile_simd(int n){\n    std::vector<int> result(n);\n    int* result_ptr = result.data();\n\n    __m256i increment;\n    if (n % 2 == 0) {\n        increment = _mm256_set1_epi32(2);\n    } else {\n        increment = _mm256_set1_epi32(2);\n    }\n\n    __m256i current_values = _mm256_setr_epi32(n, n+2, n+4, n+6, n+8, n+10, n+12, n+14);\n\n    int i = 0;\n    for (; i <= n-8; i += 8) {\n        _mm256_storeu_si256((__m256i*)(result_ptr + i), current_values);\n        current_values = _mm256_add_epi32(current_values, increment);\n    }\n\n    for (; i < n; ++i) {\n        result_ptr[i] = n + 2 * i;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_110_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> make_a_pile_simd(int n) {\n    std::vector<int> result(n);\n    int* result_ptr = result.data();\n\n    __m256i increment;\n    if (n % 2 == 0) {\n        increment = _mm256_set1_epi32(2); // Even increment\n    } else {\n        increment = _mm256_set1_epi32(2); // Odd increment\n    }\n\n    __m256i current_values = _mm256_setr_epi32(n, n + 2, n + 4, n + 6, n + 8, n + 10, n + 12, n + 14);\n\n    int i;\n    for (i = 0; i <= n - 8; i += 8) {\n        _mm256_storeu_si256((__m256i*)(result_ptr + i), current_values);\n        current_values = _mm256_add_epi32(current_values, increment);\n    }\n\n    // Handle remaining elements\n    for (; i < n; ++i) {\n        result_ptr[i] = n + 2 * i;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_110_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> make_a_pile_simd(int n){\n    std::vector<int> result(n);\n    int* result_ptr = result.data();\n\n    __m256i increment;\n    if (n % 2 == 0) {\n        increment = _mm256_set1_epi32(2);\n    } else {\n        increment = _mm256_set1_epi32(2);\n    }\n\n    __m256i current_values = _mm256_setr_epi32(n, n+2, n+4, n+6, n+8, n+10, n+12, n+14);\n\n    int i;\n    for (i = 0; i <= n - 8; i += 8) {\n        _mm256_storeu_si256((__m256i*)(result_ptr + i), current_values);\n        current_values = _mm256_add_epi32(current_values, increment);\n    }\n\n    for (; i < n; ++i) {\n        result_ptr[i] = n + 2 * i;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_110_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> make_a_pile_simd(int n) {\n    std::vector<int> result(n);\n    int* result_ptr = result.data();\n\n    __m256i increment;\n    if (n % 2 == 0) {\n        increment = _mm256_set1_epi32(2); // Even increment\n    } else {\n        increment = _mm256_set1_epi32(2); // Odd increment\n    }\n\n    __m256i current_values = _mm256_setr_epi32(n, n + 2, n + 4, n + 6, n + 8, n + 10, n + 12, n + 14);\n\n    int i = 0;\n    for (; i <= n - 8; i += 8) {\n        _mm256_storeu_si256((__m256i*)(result_ptr + i), current_values);\n        current_values = _mm256_add_epi32(current_values, increment);\n    }\n\n    // Handle remaining elements\n    for (; i < n; ++i) {\n        result_ptr[i] = n + 2 * i;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_111_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n#include <bitset>\n\nstd::string rounded_avg_simd(int64_t n, int64_t m){\n    if (n > m) {\n        return \"-1\";\n    }\n\n    __m256i n_vec = _mm256_set1_epi64x(n);\n    __m256i m_vec = _mm256_set1_epi64x(m);\n    __m256i one_vec = _mm256_set1_epi64x(1);\n\n    __m256i sum_vec = _mm256_add_epi64(n_vec, m_vec);\n    __m256i avg_vec = _mm256_srli_epi64(_mm256_add_epi64(sum_vec, one_vec), 1);\n\n    int64_t avg_array[4];\n    _mm256_storeu_si256((__m256i*)avg_array, avg_vec);\n\n    int64_t avg = avg_array[0]; // All elements in avg_array should be the same\n\n    std::string binary = std::bitset<64>(avg).to_string();\n    auto pos = binary.find('1');\n    if (pos != std::string::npos) {\n        return binary.substr(pos);\n    }\n    return \"0\";\n}\n```"}
{"task_id": "SimdBench_111_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n#include <bitset>\n\nstd::string rounded_avg_simd(int64_t n, int64_t m){\n    if (n > m) {\n        return \"-1\";\n    }\n\n    __m256i n_vec = _mm256_set1_epi64x(n);\n    __m256i m_vec = _mm256_set1_epi64x(m);\n    __m256i one_vec = _mm256_set1_epi64x(1);\n\n    __m256i sum_vec = _mm256_add_epi64(n_vec, m_vec);\n    __m256i avg_vec = _mm256_srli_epi64(_mm256_add_epi64(sum_vec, one_vec), 1);\n\n    int64_t avg_array[4];\n    _mm256_storeu_si256((__m256i*)avg_array, avg_vec);\n\n    int64_t avg = avg_array[0]; // All elements in avg_array should be the same\n\n    std::string binary = std::bitset<64>(avg).to_string();\n    auto pos = binary.find('1');\n    if (pos != std::string::npos) {\n        return binary.substr(pos);\n    }\n    return \"0\";\n}\n```"}
{"task_id": "SimdBench_111_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n#include <bitset>\n\nstd::string rounded_avg_simd(int64_t n, int64_t m){\n    if (n > m) {\n        return \"-1\";\n    }\n\n    __m256i n_vec = _mm256_set1_epi64x(n);\n    __m256i m_vec = _mm256_set1_epi64x(m);\n    __m256i one_vec = _mm256_set1_epi64x(1);\n\n    __m256i sum_vec = _mm256_add_epi64(n_vec, m_vec);\n    __m256i avg_vec = _mm256_srli_epi64(_mm256_add_epi64(sum_vec, one_vec), 1);\n\n    int64_t avg_array[4];\n    _mm256_storeu_si256((__m256i*)avg_array, avg_vec);\n\n    int64_t avg = avg_array[0]; // All elements in avg_array should be the same\n\n    std::string binary = std::bitset<64>(avg).to_string();\n    auto pos = binary.find('1');\n    return (pos != std::string::npos) ? binary.substr(pos) : \"0\";\n}\n```"}
{"task_id": "SimdBench_111_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n#include <bitset>\n\nstd::string rounded_avg_simd(int64_t n, int64_t m){\n    if (n > m) {\n        return \"-1\";\n    }\n\n    __m256i n_vec = _mm256_set1_epi64x(n);\n    __m256i m_vec = _mm256_set1_epi64x(m);\n    __m256i one_vec = _mm256_set1_epi64x(1);\n\n    __m256i sum_vec = _mm256_add_epi64(n_vec, m_vec);\n    __m256i avg_vec = _mm256_srli_epi64(_mm256_add_epi64(sum_vec, one_vec), 1);\n\n    int64_t avg_array[4];\n    _mm256_storeu_si256((__m256i*)avg_array, avg_vec);\n\n    int64_t avg = avg_array[0]; // All elements in avg_array should be the same\n\n    std::string binary = std::bitset<64>(avg).to_string();\n    auto pos = binary.find('1');\n    if (pos != std::string::npos) {\n        return binary.substr(pos);\n    }\n    return \"0\";\n}\n```"}
{"task_id": "SimdBench_111_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <string>\n#include <bitset>\n\nstd::string rounded_avg_simd(int64_t n, int64_t m){\n    if (n > m) {\n        return \"-1\";\n    }\n\n    __m256i n_vec = _mm256_set1_epi64x(n);\n    __m256i m_vec = _mm256_set1_epi64x(m);\n    __m256i one_vec = _mm256_set1_epi64x(1);\n\n    __m256i sum_vec = _mm256_add_epi64(n_vec, m_vec);\n    __m256i avg_vec = _mm256_srli_epi64(_mm256_add_epi64(sum_vec, one_vec), 1);\n\n    int64_t avg_array[4];\n    _mm256_storeu_si256((__m256i*)avg_array, avg_vec);\n\n    int64_t avg = avg_array[0]; // All elements in avg_array should be the same\n\n    std::string binary = std::bitset<64>(avg).to_string();\n    auto pos = binary.find('1');\n    if (pos != std::string::npos) {\n        return binary.substr(pos);\n    }\n    return \"0\";\n}\n```"}
{"task_id": "SimdBench_112_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> func_simd(int n) {\n    std::vector<int> result(n);\n    int* result_ptr = result.data();\n    const int mod = 10000;\n\n    for (int i = 0; i < n; i += 8) {\n        __m256i indices = _mm256_setr_epi32(i + 1, i + 2, i + 3, i + 4, i + 5, i + 6, i + 7, i + 8);\n        __m256i factorials = _mm256_set1_epi32(1);\n        __m256i sums = _mm256_set1_epi32(0);\n        __m256i ones = _mm256_set1_epi32(1);\n        __m256i twos = _mm256_set1_epi32(2);\n\n        for (int j = 1; j <= 8 && i + j <= n; ++j) {\n            __m256i j_vec = _mm256_set1_epi32(j);\n            factorials = _mm256_mullo_epi32(factorials, j_vec);\n            factorials = _mm256_min_epi32(factorials, _mm256_set1_epi32(mod));\n            sums = _mm256_add_epi32(sums, j_vec);\n        }\n\n        __m256i even_mask = _mm256_and_si256(_mm256_cmpgt_epi32(indices, ones), _mm256_cmpeq_epi32(_mm256_and_si256(indices, twos), ones));\n        __m256i result_vec = _mm256_blendv_epi8(sums, factorials, even_mask);\n\n        _mm256_storeu_si256((__m256i*)(result_ptr + i), result_vec);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_112_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> func_simd(int n) {\n    std::vector<int> result(n);\n    const int mod = 10000;\n    __m256i mod_vec = _mm256_set1_epi32(mod);\n\n    for (int i = 0; i < n; i += 8) {\n        __m256i indices = _mm256_setr_epi32(i + 1, i + 2, i + 3, i + 4, i + 5, i + 6, i + 7, i + 8);\n        __m256i factorials = _mm256_set1_epi32(1);\n        __m256i sums = _mm256_set1_epi32(0);\n        __m256i ones = _mm256_set1_epi32(1);\n        __m256i twos = _mm256_set1_epi32(2);\n\n        for (int j = 0; j < 8; ++j) {\n            __m256i current_indices = _mm256_add_epi32(indices, _mm256_set1_epi32(j));\n            __m256i evens = _mm256_and_epi32(current_indices, ones);\n            __m256i odds = _mm256_sub_epi32(current_indices, evens);\n\n            factorials = _mm256_mullo_epi32(factorials, _mm256_add_epi32(current_indices, ones));\n            factorials = _mm256_min_epi32(factorials, mod_vec);\n\n            __m256i range_sums = _mm256_mullo_epi32(_mm256_add_epi32(odds, twos), odds);\n            range_sums = _mm256_srli_epi32(range_sums, 1);\n            sums = _mm256_add_epi32(sums, range_sums);\n            sums = _mm256_min_epi32(sums, mod_vec);\n        }\n\n        __m256i results = _mm256_blendv_epi8(sums, factorials, _mm256_and_epi32(indices, ones));\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(&result[i]), results);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_112_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> func_simd(int n) {\n    std::vector<int> result(n);\n    int* result_ptr = result.data();\n    const int mod = 10000;\n\n    for (int i = 0; i < n; i += 8) {\n        __m256i indices = _mm256_setr_epi32(i + 1, i + 2, i + 3, i + 4, i + 5, i + 6, i + 7, i + 8);\n        __m256i factorials = _mm256_set1_epi32(1);\n        __m256i sums = _mm256_set1_epi32(0);\n        __m256i ones = _mm256_set1_epi32(1);\n        __m256i twos = _mm256_set1_epi32(2);\n\n        for (int j = 1; j <= i + 8; ++j) {\n            __m256i j_vec = _mm256_set1_epi32(j);\n            factorials = _mm256_mullo_epi32(factorials, j_vec);\n            factorials = _mm256_min_epi32(factorials, _mm256_set1_epi32(mod));\n            sums = _mm256_add_epi32(sums, j_vec);\n        }\n\n        __m256i evens = _mm256_and_si256(indices, ones);\n        __m256i odds = _mm256_cmpeq_epi32(evens, _mm256_setzero_si256());\n        __m256i results = _mm256_blendv_epi8(sums, factorials, odds);\n\n        _mm256_storeu_si256((__m256i*)(result_ptr + i), results);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_112_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> func_simd(int n) {\n    std::vector<int> result(n);\n    const int mod = 10000;\n    __m256i mod_vec = _mm256_set1_epi32(mod);\n\n    for (int i = 0; i < n; i += 8) {\n        __m256i indices = _mm256_setr_epi32(i + 1, i + 2, i + 3, i + 4, i + 5, i + 6, i + 7, i + 8);\n        __m256i factorials = _mm256_set1_epi32(1);\n        __m256i sums = _mm256_set1_epi32(0);\n        __m256i ones = _mm256_set1_epi32(1);\n        __m256i twos = _mm256_set1_epi32(2);\n\n        for (int j = 0; j < 8; ++j) {\n            __m256i current_indices = _mm256_add_epi32(indices, _mm256_set1_epi32(j));\n            __m256i evens = _mm256_and_epi32(current_indices, ones);\n            __m256i odds = _mm256_sub_epi32(current_indices, evens);\n\n            factorials = _mm256_mullo_epi32(factorials, _mm256_add_epi32(current_indices, ones));\n            factorials = _mm256_min_epi32(factorials, mod_vec);\n\n            __m256i partial_sums = _mm256_srli_epi32(_mm256_mullo_epi32(current_indices, _mm256_add_epi32(current_indices, ones)), 1);\n            sums = _mm256_add_epi32(sums, partial_sums);\n            sums = _mm256_min_epi32(sums, mod_vec);\n        }\n\n        __m256i evens_mask = _mm256_cmpeq_epi32(_mm256_and_epi32(indices, ones), _mm256_setzero_si256());\n        __m256i results = _mm256_blendv_epi8(sums, factorials, evens_mask);\n\n        _mm256_storeu_si256((__m256i*)&result[i], results);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_112_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> func_simd(int n) {\n    std::vector<int> result(n);\n    const int mod = 10000;\n    __m256i mod_vec = _mm256_set1_epi32(mod);\n\n    for (int i = 0; i < n; i += 8) {\n        __m256i indices = _mm256_setr_epi32(i + 1, i + 2, i + 3, i + 4, i + 5, i + 6, i + 7, i + 8);\n        __m256i factorials = _mm256_set1_epi32(1);\n        __m256i sums = _mm256_set1_epi32(0);\n        __m256i ones = _mm256_set1_epi32(1);\n        __m256i twos = _mm256_set1_epi32(2);\n\n        for (int j = 1; j <= 8 && i + j <= n; ++j) {\n            __m256i j_vec = _mm256_set1_epi32(j);\n            factorials = _mm256_mullo_epi32(factorials, j_vec);\n            factorials = _mm256_min_epi32(factorials, mod_vec);\n            sums = _mm256_add_epi32(sums, j_vec);\n        }\n\n        __m256i even_mask = _mm256_and_si256(_mm256_cmpgt_epi32(indices, ones), _mm256_cmpeq_epi32(_mm256_and_si256(indices, twos), ones));\n        __m256i result_vec = _mm256_blendv_epi8(sums, factorials, even_mask);\n\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(&result[i]), result_vec);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_113_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> even_odd_palindrome_simd(int n){\n    __m256i even_count = _mm256_setzero_si256();\n    __m256i odd_count = _mm256_setzero_si256();\n    __m256i ones = _mm256_set1_epi32(1);\n\n    for (int i = 1; i <= n; i += 8) {\n        __m256i numbers = _mm256_setr_epi32(i, i+1, i+2, i+3, i+4, i+5, i+6, i+7);\n        __m256i reversed = numbers;\n        __m256i mask = _mm256_set1_epi32(0xF);\n        __m256i is_palindrome = _mm256_set1_epi32(1);\n\n        for (int shift = 1; shift < 10; shift++) {\n            __m256i shifted = _mm256_srli_epi32(numbers, shift * 4);\n            __m256i masked = _mm256_and_si256(shifted, mask);\n            __m256i rev_masked = _mm256_and_si256(reversed, mask);\n            is_palindrome = _mm256_and_si256(is_palindrome, _mm256_cmpeq_epi32(masked, rev_masked));\n            reversed = _mm256_srli_epi32(reversed, 4);\n        }\n\n        __m256i even_mask = _mm256_and_si256(is_palindrome, _mm256_and_si256(numbers, ones));\n        __m256i odd_mask = _mm256_andnot_si256(even_mask, is_palindrome);\n\n        even_count = _mm256_add_epi32(even_count, even_mask);\n        odd_count = _mm256_add_epi32(odd_count, odd_mask);\n    }\n\n    int even_result[8], odd_result[8];\n    _mm256_storeu_si256((__m256i*)even_result, even_count);\n    _mm256_storeu_si256((__m256i*)odd_result, odd_count);\n\n    int total_even = 0, total_odd = 0;\n    for (int i = 0; i < 8; ++i) {\n        total_even += even_result[i];\n        total_odd += odd_result[i];\n    }\n\n    return {total_even, total_odd};\n}\n```"}
{"task_id": "SimdBench_113_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> even_odd_palindrome_simd(int n) {\n    __m256i even_count = _mm256_setzero_si256();\n    __m256i odd_count = _mm256_setzero_si256();\n    __m256i ones = _mm256_set1_epi32(1);\n\n    for (int i = 1; i <= n; i += 8) {\n        __m256i numbers = _mm256_setr_epi32(i, i + 1, i + 2, i + 3, i + 4, i + 5, i + 6, i + 7);\n        __m256i reversed = numbers;\n        __m256i mask = _mm256_set1_epi32(0xF0F0F0F);\n        __m256i shift_mask = _mm256_set1_epi32(0xFF);\n\n        // Reverse the numbers\n        for (int j = 0; j < 3; ++j) {\n            __m256i lo = _mm256_and_si256(reversed, mask);\n            __m256i hi = _mm256_and_si256(_mm256_srli_epi32(reversed, 4), mask);\n            lo = _mm256_slli_epi32(lo, 4);\n            reversed = _mm256_or_si256(lo, hi);\n            mask = _mm256_slli_epi32(mask, 8);\n            shift_mask = _mm256_slli_epi32(shift_mask, 8);\n        }\n\n        // Check if the number is a palindrome\n        __m256i is_palindrome = _mm256_cmpeq_epi32(numbers, reversed);\n\n        // Check if the number is even\n        __m256i is_even = _mm256_and_si256(numbers, ones);\n        is_even = _mm256_cmpeq_epi32(is_even, _mm256_setzero_si256());\n\n        // Count even palindromes\n        __m256i even_palindrome = _mm256_and_si256(is_palindrome, is_even);\n        even_count = _mm256_add_epi32(even_count, even_palindrome);\n\n        // Count odd palindromes\n        __m256i odd_palindrome = _mm256_andnot_si256(is_even, is_palindrome);\n        odd_count = _mm256_add_epi32(odd_count, odd_palindrome);\n    }\n\n    int even_result[8], odd_result[8];\n    _mm256_storeu_si256((__m256i*)even_result, even_count);\n    _mm256_storeu_si256((__m256i*)odd_result, odd_count);\n\n    int total_even = 0, total_odd = 0;\n    for (int i = 0; i < 8; ++i) {\n        total_even += even_result[i];\n        total_odd += odd_result[i];\n    }\n\n    return {total_even, total_odd};\n}\n```"}
{"task_id": "SimdBench_113_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> even_odd_palindrome_simd(int n) {\n    int even_count = 0;\n    int odd_count = 0;\n\n    auto is_palindrome = [](int num) {\n        int original = num, reversed = 0;\n        while (num > 0) {\n            int digit = num % 10;\n            reversed = reversed * 10 + digit;\n            num /= 10;\n        }\n        return original == reversed;\n    };\n\n    for (int i = 1; i <= n; i += 8) {\n        __m256i nums = _mm256_setr_epi32(i, i+1, i+2, i+3, i+4, i+5, i+6, i+7);\n        __m256i ones = _mm256_set1_epi32(1);\n        __m256i evens = _mm256_and_si256(nums, ones);\n        __m256i odds = _mm256_sub_epi32(ones, evens);\n\n        int mask = 0xFF;\n        for (int j = 0; j < 8 && i + j <= n; ++j) {\n            if (is_palindrome(i + j)) {\n                mask &= (is_palindrome(i + j) ? (1 << j) : 0);\n            } else {\n                mask &= ~(1 << j);\n            }\n        }\n\n        even_count += _mm_popcnt_u32(_mm256_movemask_epi8(evens) & mask);\n        odd_count += _mm_popcnt_u32(_mm256_movemask_epi8(odds) & mask);\n    }\n\n    return {even_count, odd_count};\n}\n```"}
{"task_id": "SimdBench_113_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> even_odd_palindrome_simd(int n){\n    __m256i even_count = _mm256_setzero_si256();\n    __m256i odd_count = _mm256_setzero_si256();\n    __m256i ones = _mm256_set1_epi32(1);\n\n    for (int i = 1; i <= n; i += 8) {\n        __m256i numbers = _mm256_setr_epi32(i, i+1, i+2, i+3, i+4, i+5, i+6, i+7);\n        __m256i reversed = numbers;\n        __m256i mask = _mm256_set1_epi32(0xF);\n        __m256i is_palindrome = _mm256_set1_epi32(1);\n\n        for (int shift = 1; shift < 10; shift++) {\n            __m256i shifted = _mm256_srli_epi32(numbers, shift * 4);\n            __m256i masked = _mm256_and_si256(shifted, mask);\n            __m256i rev_masked = _mm256_and_si256(reversed, mask);\n            is_palindrome = _mm256_and_si256(is_palindrome, _mm256_cmpeq_epi32(masked, rev_masked));\n            reversed = _mm256_srli_epi32(reversed, 4);\n        }\n\n        __m256i even_mask = _mm256_and_si256(is_palindrome, _mm256_and_si256(numbers, ones));\n        __m256i odd_mask = _mm256_and_si256(is_palindrome, _mm256_andnot_si256(numbers, ones));\n\n        even_count = _mm256_add_epi32(even_count, even_mask);\n        odd_count = _mm256_add_epi32(odd_count, odd_mask);\n    }\n\n    int even_result[8], odd_result[8];\n    _mm256_storeu_si256((__m256i*)even_result, even_count);\n    _mm256_storeu_si256((__m256i*)odd_result, odd_count);\n\n    int total_even = 0, total_odd = 0;\n    for (int i = 0; i < 8; ++i) {\n        total_even += even_result[i] != 0;\n        total_odd += odd_result[i] != 0;\n    }\n\n    return {total_even, total_odd};\n}\n```"}
{"task_id": "SimdBench_113_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> even_odd_palindrome_simd(int n) {\n    __m256i even_count = _mm256_setzero_si256();\n    __m256i odd_count = _mm256_setzero_si256();\n    __m256i ones = _mm256_set1_epi32(1);\n\n    for (int i = 1; i <= n; i += 8) {\n        __m256i numbers = _mm256_setr_epi32(i, i + 1, i + 2, i + 3, i + 4, i + 5, i + 6, i + 7);\n        __m256i reversed = numbers;\n        __m256i mask = _mm256_set1_epi32(0xF0F0F0F);\n        __m256i shift_mask = _mm256_set1_epi32(0xFF);\n\n        // Reverse the numbers\n        for (int j = 0; j < 3; ++j) {\n            __m256i lo = _mm256_and_si256(reversed, mask);\n            __m256i hi = _mm256_and_si256(_mm256_srli_epi32(reversed, 4), mask);\n            lo = _mm256_slli_epi32(lo, 4);\n            hi = _mm256_srli_epi32(hi, 4);\n            reversed = _mm256_or_si256(lo, hi);\n            mask = _mm256_slli_epi32(mask, 8);\n            shift_mask = _mm256_slli_epi32(shift_mask, 8);\n        }\n\n        __m256i is_palindrome = _mm256_cmpeq_epi32(numbers, reversed);\n        __m256i even = _mm256_and_si256(is_palindrome, _mm256_and_si256(numbers, _mm256_set1_epi32(1)));\n        __m256i odd = _mm256_andnot_si256(even, is_palindrome);\n\n        even_count = _mm256_add_epi32(even_count, _mm256_sub_epi32(ones, even));\n        odd_count = _mm256_add_epi32(odd_count, _mm256_sub_epi32(ones, odd));\n    }\n\n    int even_result[8], odd_result[8];\n    _mm256_storeu_si256((__m256i*)even_result, even_count);\n    _mm256_storeu_si256((__m256i*)odd_result, odd_count);\n\n    int even_sum = 0, odd_sum = 0;\n    for (int i = 0; i < 8; ++i) {\n        even_sum += even_result[i];\n        odd_sum += odd_result[i];\n    }\n\n    return {even_sum, odd_sum};\n}\n```"}
{"task_id": "SimdBench_114_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint count_nums_simd(const std::vector<int>& n) {\n    int count = 0;\n    int size = n.size();\n    int i = 0;\n\n    __m256i zero = _mm256_setzero_si256();\n    __m256i ones = _mm256_set1_epi32(1);\n\n    while (i <= size - 8) {\n        __m256i nums = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&n[i]));\n        __m256i sum_digits = zero;\n\n        for (int j = 0; j < 4; ++j) {\n            __m256i abs_nums = _mm256_abs_epi32(nums);\n            __m256i digits_sum = _mm256_setzero_si256();\n\n            for (int k = 0; k < 3; ++k) {\n                __m256i digit = _mm256_sub_epi32(abs_nums, _mm256_srli_epi32(abs_nums, 8 * (k + 1)));\n                digit = _mm256_and_epi32(digit, _mm256_set1_epi32(0xFF));\n                digits_sum = _mm256_add_epi32(digits_sum, digit);\n                abs_nums = _mm256_srli_epi32(abs_nums, 8);\n            }\n\n            sum_digits = _mm256_add_epi32(sum_digits, digits_sum);\n            nums = _mm256_srai_epi32(nums, 31); // Extract sign bit\n        }\n\n        __m256i mask = _mm256_cmpgt_epi32(sum_digits, zero);\n        __m256i result = _mm256_and_epi32(mask, ones);\n        int horizontal_sum = _mm256_reduce_add_epi32(result);\n\n        count += horizontal_sum;\n        i += 8;\n    }\n\n    for (; i < size; ++i) {\n        int num = n[i];\n        int sum = 0;\n        int abs_num = std::abs(num);\n\n        while (abs_num > 0) {\n            sum += abs_num % 10;\n            abs_num /= 10;\n        }\n\n        if (sum > 0) {\n            count++;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_114_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint count_nums_simd(const std::vector<int>& n) {\n    int count = 0;\n    int size = n.size();\n    int i = 0;\n\n    __m256i zero = _mm256_setzero_si256();\n    __m256i ones = _mm256_set1_epi32(1);\n\n    while (i <= size - 8) {\n        __m256i nums = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&n[i]));\n        __m256i sum_digits = zero;\n\n        for (int j = 0; j < 4; ++j) {\n            __m256i abs_nums = _mm256_abs_epi32(nums);\n            __m256i digits_sum = _mm256_setzero_si256();\n\n            for (int k = 0; k < 3; ++k) {\n                __m256i digit = _mm256_sub_epi32(abs_nums, _mm256_srli_epi32(abs_nums, 8 * (k + 1)));\n                digit = _mm256_and_epi32(digit, _mm256_set1_epi32(0xFF));\n                digits_sum = _mm256_add_epi32(digits_sum, digit);\n                abs_nums = _mm256_srli_epi32(abs_nums, 8);\n            }\n\n            sum_digits = _mm256_add_epi32(sum_digits, digits_sum);\n            nums = _mm256_srai_epi32(nums, 31);\n        }\n\n        __m256i mask = _mm256_cmpgt_epi32(sum_digits, zero);\n        __m256i result = _mm256_and_epi32(mask, ones);\n        int horizontal_sum = _mm256_reduce_add_epi32(result);\n\n        count += horizontal_sum;\n        i += 8;\n    }\n\n    for (; i < size; ++i) {\n        int num = n[i];\n        int sum = 0;\n        int abs_num = std::abs(num);\n\n        while (abs_num > 0) {\n            sum += abs_num % 10;\n            abs_num /= 10;\n        }\n\n        if (sum > 0) {\n            count++;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_114_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint count_nums_simd(const std::vector<int>& n) {\n    int count = 0;\n    int size = n.size();\n    int i = 0;\n\n    __m256i zero = _mm256_setzero_si256();\n    __m256i ones = _mm256_set1_epi32(1);\n\n    while (i <= size - 8) {\n        __m256i nums = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&n[i]));\n        __m256i sum_digits = _mm256_setzero_si256();\n\n        for (int j = 0; j < 32; ++j) {\n            __m256i abs_nums = _mm256_abs_epi32(nums);\n            __m256i digits = _mm256_sub_epi32(abs_nums, _mm256_srli_epi32(_mm256_mullo_epi32(abs_nums, _mm256_set1_epi32(10)), 29));\n            sum_digits = _mm256_add_epi32(sum_digits, digits);\n            nums = _mm256_srli_epi32(nums, 4);\n        }\n\n        __m256i mask = _mm256_cmpgt_epi32(sum_digits, zero);\n        __m256i result = _mm256_and_si256(mask, ones);\n        count += _mm256_reduce_add_epi32(result);\n\n        i += 8;\n    }\n\n    for (; i < size; ++i) {\n        int num = n[i];\n        int sum = 0;\n        while (num != 0) {\n            sum += num % 10;\n            num /= 10;\n        }\n        if (sum > 0) {\n            count++;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_114_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint count_nums_simd(const std::vector<int>& n) {\n    int count = 0;\n    int size = n.size();\n    int i = 0;\n\n    __m256i zero = _mm256_setzero_si256();\n    __m256i ones = _mm256_set1_epi32(1);\n\n    while (i <= size - 8) {\n        __m256i nums = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&n[i]));\n        __m256i sum_digits = zero;\n\n        for (int j = 0; j < 4; ++j) {\n            __m256i abs_nums = _mm256_abs_epi32(nums);\n            __m256i digits_sum = _mm256_setzero_si256();\n\n            for (int k = 0; k < 3; ++k) {\n                __m256i digit = _mm256_sub_epi32(abs_nums, _mm256_srli_epi32(abs_nums, 8 * (k + 1)));\n                digit = _mm256_and_si256(digit, _mm256_set1_epi32(0xFF));\n                digits_sum = _mm256_add_epi32(digits_sum, digit);\n                abs_nums = _mm256_srli_epi32(abs_nums, 8);\n            }\n\n            sum_digits = _mm256_add_epi32(sum_digits, digits_sum);\n            nums = _mm256_srai_epi32(nums, 31); // Extract sign bit\n        }\n\n        __m256i mask = _mm256_cmpgt_epi32(sum_digits, zero);\n        __m256i result = _mm256_and_si256(mask, ones);\n        int horizontal_sum = _mm256_reduce_add_epi32(result);\n\n        count += horizontal_sum;\n        i += 8;\n    }\n\n    for (; i < size; ++i) {\n        int num = n[i];\n        int sum = 0;\n        int abs_num = std::abs(num);\n\n        while (abs_num > 0) {\n            sum += abs_num % 10;\n            abs_num /= 10;\n        }\n\n        if (sum > 0) {\n            count++;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_114_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nint count_nums_simd(const std::vector<int>& n) {\n    int count = 0;\n    int size = n.size();\n    int i = 0;\n\n    __m256i zero = _mm256_setzero_si256();\n    __m256i ones = _mm256_set1_epi32(1);\n\n    while (i <= size - 8) {\n        __m256i nums = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&n[i]));\n        __m256i sign_mask = _mm256_cmpgt_epi32(zero, nums);\n        __m256i abs_nums = _mm256_abs_epi32(nums);\n        __m256i sum_digits = zero;\n\n        for (int j = 0; j < 10; ++j) {\n            __m256i digit = _mm256_sub_epi32(abs_nums, _mm256_srli_epi32(abs_nums, 4));\n            sum_digits = _mm256_add_epi32(sum_digits, digit);\n            abs_nums = _mm256_srli_epi32(abs_nums, 4);\n        }\n\n        sum_digits = _mm256_sub_epi32(sum_digits, _mm256_and_si256(sign_mask, _mm256_slli_epi32(sign_mask, 3)));\n        __m256i mask = _mm256_cmpgt_epi32(sum_digits, zero);\n        __m256i result = _mm256_and_si256(mask, ones);\n        count += _mm256_reduce_add_epi32(result);\n\n        i += 8;\n    }\n\n    for (; i < size; ++i) {\n        int num = n[i];\n        int sum_digits = 0;\n        bool is_negative = num < 0;\n        num = std::abs(num);\n\n        while (num > 0) {\n            sum_digits += num % 10;\n            num /= 10;\n        }\n\n        if (is_negative) {\n            sum_digits -= 2 * (n[i] % 10);\n        }\n\n        if (sum_digits > 0) {\n            count++;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_115_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nbool move_one_ball_simd(std::vector<int> arr) {\n    int n = arr.size();\n    if (n == 0) return true;\n\n    __m256i vec, vec_shifted, vec_sorted;\n    int buffer[8];\n    bool found = false;\n\n    for (int i = 0; i < n; ++i) {\n        for (int j = 0; j < 8; ++j) {\n            buffer[j] = arr[(i + j) % n];\n        }\n        vec = _mm256_loadu_si256(reinterpret_cast<__m256i*>(buffer));\n        vec_shifted = _mm256_alignr_epi8(vec, vec, 4);\n\n        for (int j = 0; j < 7; ++j) {\n            vec_sorted = _mm256_cmpgt_epi32(_mm256_permutevar8x32_epi32(vec_shifted, _mm256_setr_epi32(j, j+1, j+2, j+3, j+4, j+5, j+6, j+7)), vec_shifted);\n            if (_mm256_testz_si256(vec_sorted, vec_sorted)) {\n                found = true;\n                break;\n            }\n        }\n        if (found) break;\n    }\n\n    return found;\n}\n```"}
{"task_id": "SimdBench_115_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nbool move_one_ball_simd(std::vector<int> arr) {\n    int n = arr.size();\n    if (n == 0) return true;\n\n    __m256i vec, vec_shifted, vec_sorted;\n    int buffer[8];\n    bool found = false;\n\n    for (int i = 0; i < n; ++i) {\n        for (int j = 0; j < 8; ++j) {\n            buffer[j] = arr[(i + j) % n];\n        }\n        vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(buffer));\n        vec_shifted = _mm256_alignr_epi8(vec, vec, 4);\n\n        for (int j = 0; j < 7; ++j) {\n            vec_sorted = _mm256_cmpgt_epi32(_mm256_permutevar8x32_epi32(vec_shifted, _mm256_setr_epi32(j, j+1, j+2, j+3, j+4, j+5, j+6, j+7)), vec_shifted);\n            if (_mm256_testz_si256(vec_sorted, vec_sorted)) {\n                found = true;\n                break;\n            }\n        }\n        if (found) break;\n    }\n\n    return found;\n}\n```"}
{"task_id": "SimdBench_115_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nbool move_one_ball_simd(std::vector<int> arr) {\n    int n = arr.size();\n    if (n == 0) return true;\n\n    __m256i vec, vec_shifted, vec_sorted;\n    int buffer[8];\n    bool is_sorted = false;\n\n    for (int shift = 0; shift < n; ++shift) {\n        is_sorted = true;\n        for (int i = 0; i < n; i += 8) {\n            int len = std::min(8, n - i);\n            for (int j = 0; j < len; ++j) {\n                buffer[j] = arr[(i + j + shift) % n];\n            }\n            vec = _mm256_loadu_si256(reinterpret_cast<__m256i*>(buffer));\n            vec_shifted = _mm256_permutevar8x32_epi32(vec, _mm256_setr_epi32(1, 2, 3, 4, 5, 6, 7, 0));\n            vec_sorted = _mm256_cmpgt_epi32(vec, vec_shifted);\n            if (_mm256_movemask_epi8(vec_sorted) != 0) {\n                is_sorted = false;\n                break;\n            }\n        }\n        if (is_sorted) return true;\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_115_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n\nbool move_one_ball_simd(std::vector<int> arr) {\n    int N = arr.size();\n    if (N == 0) return true;\n\n    __m256i vec, vec_shifted, vec_sorted;\n    int buffer[8];\n    bool found = false;\n\n    for (int i = 0; i < N; ++i) {\n        // Load 8 integers into a YMM register\n        vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&arr[i]));\n        \n        // Perform a right shift operation\n        vec_shifted = _mm256_permutevar8x32_epi32(vec, _mm256_setr_epi32(7, 0, 1, 2, 3, 4, 5, 6));\n        \n        // Check if the shifted vector is sorted\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(buffer), vec_shifted);\n        bool is_sorted = true;\n        for (int j = 0; j < 7 && i + j + 1 < N; ++j) {\n            if (buffer[j] > buffer[j + 1]) {\n                is_sorted = false;\n                break;\n            }\n        }\n        if (is_sorted && (i + 7 >= N || buffer[7] <= arr[(i + 8) % N])) {\n            found = true;\n            break;\n        }\n    }\n\n    return found;\n}\n```"}
{"task_id": "SimdBench_115_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nbool move_one_ball_simd(std::vector<int> arr) {\n    int n = arr.size();\n    if (n == 0) return true;\n\n    __m256i vec, vec_shifted, vec_sorted;\n    int buffer[8];\n    bool is_sorted;\n\n    for (int shift = 0; shift < n; ++shift) {\n        is_sorted = true;\n        for (int i = 0; i < n; i += 8) {\n            int len = std::min(8, n - i);\n            for (int j = 0; j < len; ++j) {\n                buffer[j] = arr[(i + j + shift) % n];\n            }\n            vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(buffer));\n            vec_shifted = _mm256_permutevar8x32_epi32(vec, _mm256_setr_epi32(1, 2, 3, 4, 5, 6, 7, 0));\n            vec_sorted = _mm256_cmpgt_epi32(vec, vec_shifted);\n            if (_mm256_movemask_epi8(vec_sorted) != 0) {\n                is_sorted = false;\n                break;\n            }\n        }\n        if (is_sorted) return true;\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_116_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n\nstd::string myexchange_simd(const std::vector<int>& lst1, const std::vector<int>& lst2) {\n    int n1 = lst1.size();\n    int n2 = lst2.size();\n\n    __m256i even_mask = _mm256_set1_epi32(1);\n    __m256i has_odd = _mm256_setzero_si256();\n\n    for (int i = 0; i < n1; i += 8) {\n        __m256i vec1 = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&lst1[i]));\n        __m256i odd_check = _mm256_and_si256(vec1, even_mask);\n        has_odd = _mm256_or_si256(has_odd, odd_check);\n    }\n\n    __m256i has_even_in_lst2 = _mm256_setzero_si256();\n\n    for (int i = 0; i < n2; i += 8) {\n        __m256i vec2 = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&lst2[i]));\n        __m256i even_check = _mm256_andnot_si256(even_mask, vec2);\n        has_even_in_lst2 = _mm256_or_si256(has_even_in_lst2, even_check);\n    }\n\n    int has_odd_mask = _mm256_movemask_epi8(has_odd);\n    int has_even_in_lst2_mask = _mm256_movemask_epi8(has_even_in_lst2);\n\n    if ((has_odd_mask & 0xaaaaaaaa) && !(has_even_in_lst2_mask & 0xaaaaaaaa)) {\n        return \"NO\";\n    }\n\n    return \"YES\";\n}\n```"}
{"task_id": "SimdBench_116_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n\nstd::string myexchange_simd(const std::vector<int>& lst1, const std::vector<int>& lst2) {\n    int n1 = lst1.size();\n    int n2 = lst2.size();\n\n    // Check if there are enough even numbers in lst2 to replace odd numbers in lst1\n    __m256i even_mask = _mm256_set1_epi32(1);\n    int odd_count_lst1 = 0;\n    int even_count_lst2 = 0;\n\n    // Count odd numbers in lst1\n    for (int i = 0; i <= n1 - 8; i += 8) {\n        __m256i vec1 = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&lst1[i]));\n        __m256i odd_vec1 = _mm256_and_si256(vec1, even_mask);\n        odd_count_lst1 += 8 - _mm_popcnt_u32(_mm256_movemask_epi8(_mm256_cmpeq_epi32(odd_vec1, _mm256_setzero_si256())));\n    }\n    for (int i = (n1 / 8) * 8; i < n1; ++i) {\n        odd_count_lst1 += lst1[i] % 2;\n    }\n\n    // Count even numbers in lst2\n    for (int i = 0; i <= n2 - 8; i += 8) {\n        __m256i vec2 = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&lst2[i]));\n        __m256i odd_vec2 = _mm256_and_si256(vec2, even_mask);\n        even_count_lst2 += _mm_popcnt_u32(_mm256_movemask_epi8(_mm256_cmpeq_epi32(odd_vec2, _mm256_setzero_si256()))) / 4;\n    }\n    for (int i = (n2 / 8) * 8; i < n2; ++i) {\n        even_count_lst2 += !(lst2[i] % 2);\n    }\n\n    return even_count_lst2 >= odd_count_lst1 ? \"YES\" : \"NO\";\n}\n```"}
{"task_id": "SimdBench_116_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n\nstd::string myexchange_simd(const std::vector<int>& lst1, const std::vector<int>& lst2) {\n    int n1 = lst1.size();\n    int n2 = lst2.size();\n\n    __m256i even_mask = _mm256_set1_epi32(1);\n\n    // Check lst1 for odd numbers\n    for (int i = 0; i < n1; i += 8) {\n        __m256i vec1 = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&lst1[i]));\n        __m256i odd_check = _mm256_and_si256(vec1, even_mask);\n        if (!_mm256_testz_si256(odd_check, odd_check)) {\n            // Found odd numbers in lst1, check lst2 for even numbers\n            bool has_even_in_lst2 = false;\n            for (int j = 0; j < n2; j += 8) {\n                __m256i vec2 = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&lst2[j]));\n                __m256i even_check = _mm256_andnot_si256(even_mask, vec2);\n                if (!_mm256_testz_si256(even_check, even_check)) {\n                    has_even_in_lst2 = true;\n                    break;\n                }\n            }\n            if (!has_even_in_lst2) {\n                return \"NO\";\n            }\n        }\n    }\n\n    return \"YES\";\n}\n```"}
{"task_id": "SimdBench_116_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n\nstd::string myexchange_simd(const std::vector<int>& lst1, const std::vector<int>& lst2) {\n    int n1 = lst1.size();\n    int n2 = lst2.size();\n\n    // Check if there is at least one even number in lst2\n    __m256i even_mask = _mm256_set1_epi32(1);\n    __m256i has_even = _mm256_setzero_si256();\n\n    for (int i = 0; i < n2; i += 8) {\n        __m256i vec2 = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&lst2[i]));\n        __m256i is_even = _mm256_and_si256(_mm256_andnot_si256(vec2, even_mask), even_mask);\n        has_even = _mm256_or_si256(has_even, is_even);\n    }\n\n    // Check if there is at least one zero in has_even (indicating an even number)\n    int mask = _mm256_movemask_epi8(has_even);\n    if (mask != 0) {\n        return \"YES\";\n    }\n\n    // Check if all numbers in lst1 are already even\n    for (int i = 0; i < n1; i += 8) {\n        __m256i vec1 = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&lst1[i]));\n        __m256i is_even = _mm256_and_si256(_mm256_andnot_si256(vec1, even_mask), even_mask);\n        __m256i all_even = _mm256_cmpeq_epi32(is_even, even_mask);\n        int all_even_mask = _mm256_movemask_epi8(all_even);\n        if ((all_even_mask & 0xaaaaaaaa) != 0xaaaaaaaa) {\n            return \"NO\";\n        }\n    }\n\n    return \"YES\";\n}\n```"}
{"task_id": "SimdBench_116_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n\nstd::string myexchange_simd(const std::vector<int>& lst1, const std::vector<int>& lst2) {\n    int n1 = lst1.size();\n    int n2 = lst2.size();\n\n    // Check if there is at least one even number in lst2\n    __m256i even_mask = _mm256_set1_epi32(1);\n    __m256i has_even = _mm256_setzero_si256();\n\n    for (int i = 0; i < n2; i += 8) {\n        __m256i vec2 = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&lst2[i]));\n        __m256i is_even = _mm256_and_si256(_mm256_srli_epi32(vec2, 1), even_mask);\n        has_even = _mm256_or_si256(has_even, is_even);\n    }\n\n    // Check if there is at least one zero in has_even (indicating an even number)\n    int mask = _mm256_movemask_epi8(has_even);\n    if (mask != 0) {\n        return \"YES\";\n    }\n\n    // Check if all numbers in lst1 are already even\n    for (int i = 0; i < n1; i += 8) {\n        __m256i vec1 = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&lst1[i]));\n        __m256i is_even = _mm256_and_si256(_mm256_srli_epi32(vec1, 1), even_mask);\n        __m256i all_even = _mm256_cmpeq_epi32(is_even, even_mask);\n        int all_even_mask = _mm256_movemask_epi8(all_even);\n        if ((all_even_mask & 0xaaaaaaaa) != 0xaaaaaaaa) {\n            return \"NO\";\n        }\n    }\n\n    return \"YES\";\n}\n```"}
{"task_id": "SimdBench_117_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n#include <cstring>\n\nstd::vector<std::string> odd_count_simd(const std::vector<std::string> & lst){\n    std::vector<std::string> result;\n    const __m256i odd_mask = _mm256_set1_epi8(0x1);\n    const __m256i zero = _mm256_setzero_si256();\n\n    for (const auto & str : lst) {\n        int odd_count = 0;\n        size_t len = str.size();\n        const char * ptr = str.c_str();\n\n        for (size_t i = 0; i <= len - 32; i += 32) {\n            __m256i chars = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(ptr + i));\n            __m256i is_digit = _mm256_cmpgt_epi8(chars, _mm256_set1_epi8('0') - 1);\n            is_digit = _mm256_and_si256(is_digit, _mm256_cmpgt_epi8(_mm256_set1_epi8('9') + 1, chars));\n            __m256i odds = _mm256_and_si256(is_digit, _mm256_and_si256(chars, odd_mask));\n            odd_count += 16 - _mm256_movemask_epi8(_mm256_cmpeq_epi8(odds, zero)) / 2;\n        }\n\n        for (size_t i = (len / 32) * 32; i < len; ++i) {\n            if ((str[i] - '0') % 2 != 0) {\n                odd_count++;\n            }\n        }\n\n        char buffer[100];\n        snprintf(buffer, sizeof(buffer), \"the number of odd elements %dn the str%ng %d of the %dnput.\", odd_count, odd_count, odd_count);\n        result.push_back(std::string(buffer));\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_117_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n#include <sstream>\n\nstd::vector<std::string> odd_count_simd(const std::vector<std::string> & lst){\n    std::vector<std::string> result;\n    for (const auto& str : lst) {\n        int odd_count = 0;\n        size_t len = str.size();\n        const char* ptr = str.c_str();\n\n        __m256i odd_mask = _mm256_set1_epi8(0x1);\n        __m256i zero = _mm256_setzero_si256();\n        __m256i ones = _mm256_set1_epi8(1);\n\n        for (size_t i = 0; i <= len - 32; i += 32) {\n            __m256i chars = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(ptr + i));\n            __m256i is_digit = _mm256_and_si256(_mm256_cmpgt_epi8(chars, _mm256_set1_epi8('0') - 1),\n                                                _mm256_cmpgt_epi8(_mm256_set1_epi8('9') + 1, chars));\n            __m256i odds = _mm256_and_si256(is_digit, odd_mask);\n            __m256i count = _mm256_sub_epi8(odds, zero);\n            odd_count += _mm256_reduce_add_epi8(count);\n        }\n\n        for (size_t i = (len / 32) * 32; i < len; ++i) {\n            if ((str[i] - '0') % 2 != 0) {\n                odd_count++;\n            }\n        }\n\n        std::ostringstream oss;\n        oss << \"the number of odd elements \" << odd_count << \"n the str\" << odd_count << \"ng \" << odd_count << \" of the \" << odd_count << \"nput.\";\n        result.push_back(oss.str());\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_117_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n#include <cstring>\n\nstd::vector<std::string> odd_count_simd(const std::vector<std::string> & lst){\n    std::vector<std::string> result;\n    const __m256i odd_mask = _mm256_set1_epi8(0x1);\n    const __m256i zero = _mm256_setzero_si256();\n\n    for (const auto & str : lst) {\n        int odd_count = 0;\n        size_t len = str.size();\n        const char * ptr = str.c_str();\n\n        for (size_t i = 0; i <= len - 32; i += 32) {\n            __m256i chars = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(ptr + i));\n            __m256i digits = _mm256_sub_epi8(chars, _mm256_set1_epi8('0'));\n            __m256i odds = _mm256_and_epi8(digits, odd_mask);\n            __m256i cmp = _mm256_cmpeq_epi8(odds, odd_mask);\n            odd_count += _mm256_popcnt_u32(_mm256_movemask_epi8(cmp));\n        }\n\n        for (size_t i = (len / 32) * 32; i < len; ++i) {\n            if ((str[i] - '0') % 2 != 0) {\n                odd_count++;\n            }\n        }\n\n        char buffer[100];\n        snprintf(buffer, sizeof(buffer), \"the number of odd elements %dn the str%ng %d of the %dnput.\", odd_count, odd_count, odd_count);\n        result.push_back(std::string(buffer));\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_117_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n#include <cstring>\n\nstd::vector<std::string> odd_count_simd(const std::vector<std::string> & lst){\n    std::vector<std::string> result;\n    const __m256i odd_mask = _mm256_set1_epi8(0x01);\n\n    for (const auto & str : lst) {\n        int odd_count = 0;\n        size_t len = str.size();\n        size_t i = 0;\n\n        // Process 32 characters at a time\n        for (; i <= len - 32; i += 32) {\n            __m256i chunk = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(str.c_str() + i));\n            __m256i odd_digits = _mm256_and_si256(chunk, odd_mask);\n            __m256i cmp_result = _mm256_cmpeq_epi8(odd_digits, odd_mask);\n            odd_count += _mm256_popcnt_u32(_mm256_movemask_epi8(cmp_result));\n        }\n\n        // Process remaining characters\n        for (; i < len; ++i) {\n            odd_count += (str[i] - '0') % 2;\n        }\n\n        char buffer[100];\n        snprintf(buffer, sizeof(buffer), \"the number of odd elements %dn the str%ng %d of the %dnput.\", odd_count, odd_count, odd_count);\n        result.push_back(std::string(buffer));\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_117_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n#include <cstring>\n\nstd::vector<std::string> odd_count_simd(const std::vector<std::string> & lst){\n    std::vector<std::string> result;\n    const __m256i odd_mask = _mm256_set1_epi8(0x1);\n    const __m256i zero = _mm256_setzero_si256();\n\n    for (const auto & str : lst) {\n        int odd_count = 0;\n        size_t len = str.size();\n        size_t i = 0;\n\n        for (; i <= len - 32; i += 32) {\n            __m256i chunk = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(str.c_str() + i));\n            __m256i is_digit = _mm256_cmpgt_epi8(chunk, _mm256_set1_epi8('0') - 1);\n            is_digit = _mm256_and_si256(is_digit, _mm256_cmpgt_epi8(_mm256_set1_epi8('9') + 1, chunk));\n            __m256i is_odd = _mm256_and_si256(is_digit, _mm256_and_si256(chunk, odd_mask));\n            __m256i count = _mm256_sub_epi8(is_odd, zero);\n            odd_count += _mm256_adds_epi16(_mm256_maddubs_epi16(count, _mm256_set1_epi16(1)), _mm256_setzero_si256())[0];\n        }\n\n        for (; i < len; ++i) {\n            if ((str[i] >= '0' && str[i] <= '9') && (str[i] - '0') % 2 != 0) {\n                ++odd_count;\n            }\n        }\n\n        char buffer[100];\n        snprintf(buffer, sizeof(buffer), \"the number of odd elements %dn the str%ng %d of the %dnput.\", odd_count, odd_count, odd_count);\n        result.push_back(std::string(buffer));\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_118_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n#include <limits>\n\nint64_t minSubArraySum_simd(const std::vector<int64_t>& nums) {\n    if (nums.empty()) return 0;\n\n    int64_t min_sum = std::numeric_limits<int64_t>::max();\n    int64_t current_min = 0;\n    const int64_t* data = nums.data();\n    size_t size = nums.size();\n    size_t i = 0;\n\n    __m256i v_min = _mm256_set1_epi64x(std::numeric_limits<int64_t>::max());\n    __m256i v_current_min = _mm256_setzero_si256();\n\n    for (; i <= size - 4; i += 4) {\n        __m256i v_nums = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(data + i));\n        v_current_min = _mm256_add_epi64(v_current_min, v_nums);\n        v_current_min = _mm256_min_epi64(v_current_min, v_nums);\n        v_min = _mm256_min_epi64(v_min, v_current_min);\n    }\n\n    int64_t min_vals[4];\n    _mm256_storeu_si256(reinterpret_cast<__m256i*>(min_vals), v_min);\n    min_sum = *std::min_element(min_vals, min_vals + 4);\n\n    for (; i < size; ++i) {\n        current_min = std::min(current_min + data[i], data[i]);\n        min_sum = std::min(min_sum, current_min);\n    }\n\n    return min_sum;\n}\n```"}
{"task_id": "SimdBench_118_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n#include <limits>\n\nint64_t minSubArraySum_simd(const std::vector<int64_t>& nums) {\n    if (nums.empty()) return 0;\n\n    int64_t min_sum = std::numeric_limits<int64_t>::max();\n    int64_t current_min = 0;\n    const int64_t* data = nums.data();\n    size_t size = nums.size();\n\n    __m256i min_vec = _mm256_set1_epi64x(std::numeric_limits<int64_t>::max());\n    __m256i current_min_vec = _mm256_setzero_si256();\n\n    size_t i = 0;\n    for (; i <= size - 4; i += 4) {\n        __m256i num_vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(data + i));\n        current_min_vec = _mm256_add_epi64(current_min_vec, num_vec);\n        current_min_vec = _mm256_min_epi64(current_min_vec, num_vec);\n        min_vec = _mm256_min_epi64(min_vec, current_min_vec);\n    }\n\n    int64_t min_arr[4];\n    _mm256_storeu_si256(reinterpret_cast<__m256i*>(min_arr), min_vec);\n    min_sum = *std::min_element(min_arr, min_arr + 4);\n\n    for (; i < size; ++i) {\n        current_min = std::min(current_min + data[i], data[i]);\n        min_sum = std::min(min_sum, current_min);\n    }\n\n    return min_sum;\n}\n```"}
{"task_id": "SimdBench_118_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n#include <limits>\n\nint64_t minSubArraySum_simd(const std::vector<int64_t>& nums) {\n    if (nums.empty()) return 0;\n\n    int64_t min_sum = std::numeric_limits<int64_t>::max();\n    int64_t current_min = 0;\n    const int64_t* data = nums.data();\n    size_t size = nums.size();\n    size_t i = 0;\n\n    __m256i v_min = _mm256_set1_epi64x(std::numeric_limits<int64_t>::max());\n    __m256i v_current_min = _mm256_setzero_si256();\n\n    for (; i <= size - 4; i += 4) {\n        __m256i v_nums = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(data + i));\n        v_current_min = _mm256_add_epi64(v_current_min, v_nums);\n        v_current_min = _mm256_min_epi64(v_current_min, v_nums);\n        v_min = _mm256_min_epi64(v_min, v_current_min);\n    }\n\n    int64_t min_vals[4];\n    _mm256_storeu_si256(reinterpret_cast<__m256i*>(min_vals), v_min);\n\n    min_sum = *std::min_element(min_vals, min_vals + 4);\n\n    for (; i < size; ++i) {\n        current_min = std::min(current_min + data[i], data[i]);\n        min_sum = std::min(min_sum, current_min);\n    }\n\n    return min_sum;\n}\n```"}
{"task_id": "SimdBench_118_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n#include <limits>\n\nint64_t minSubArraySum_simd(const std::vector<int64_t>& nums) {\n    if (nums.empty()) return 0;\n\n    int64_t min_sum = std::numeric_limits<int64_t>::max();\n    int64_t current_min = 0;\n    const int64_t* data = nums.data();\n    size_t size = nums.size();\n    size_t i = 0;\n\n    __m256i v_min = _mm256_set1_epi64x(std::numeric_limits<int64_t>::max());\n    __m256i v_current_min = _mm256_setzero_si256();\n\n    for (; i <= size - 4; i += 4) {\n        __m256i v_nums = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(data + i));\n        v_current_min = _mm256_add_epi64(v_current_min, v_nums);\n        v_current_min = _mm256_min_epi64(v_current_min, v_nums);\n        v_min = _mm256_min_epi64(v_min, v_current_min);\n    }\n\n    int64_t min_vals[4];\n    _mm256_storeu_si256(reinterpret_cast<__m256i*>(min_vals), v_min);\n\n    min_sum = *std::min_element(min_vals, min_vals + 4);\n\n    for (; i < size; ++i) {\n        current_min = std::min(current_min + data[i], data[i]);\n        min_sum = std::min(min_sum, current_min);\n    }\n\n    return min_sum;\n}\n```"}
{"task_id": "SimdBench_118_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n#include <limits>\n\nint64_t minSubArraySum_simd(const std::vector<int64_t>& nums) {\n    if (nums.empty()) return 0;\n\n    const int64_t* data = nums.data();\n    size_t n = nums.size();\n    int64_t min_sum = std::numeric_limits<int64_t>::max();\n    int64_t current_min = 0;\n\n    __m256i min_vec = _mm256_set1_epi64x(std::numeric_limits<int64_t>::max());\n    __m256i current_min_vec = _mm256_setzero_si256();\n\n    size_t i = 0;\n    for (; i <= n - 4; i += 4) {\n        __m256i num_vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(data + i));\n        current_min_vec = _mm256_add_epi64(current_min_vec, num_vec);\n        current_min_vec = _mm256_min_epi64(current_min_vec, num_vec);\n        min_vec = _mm256_min_epi64(min_vec, current_min_vec);\n    }\n\n    int64_t min_arr[4];\n    _mm256_storeu_si256(reinterpret_cast<__m256i*>(min_arr), min_vec);\n    min_sum = *std::min_element(min_arr, min_arr + 4);\n\n    for (; i < n; ++i) {\n        current_min = std::min(current_min + data[i], data[i]);\n        min_sum = std::min(min_sum, current_min);\n    }\n\n    return min_sum;\n}\n```"}
{"task_id": "SimdBench_119_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint max_fill_simd(const std::vector<std::vector<int> > & grid, int capacity) {\n    int total_drops = 0;\n    int num_rows = grid.size();\n    if (num_rows == 0) return 0;\n    int num_cols = grid[0].size();\n    int num_simd_iters = num_cols / 8; // 8 integers per 256-bit AVX register\n    int remainder = num_cols % 8;\n\n    for (int i = 0; i < num_rows; ++i) {\n        const int* row = grid[i].data();\n        __m256i sum = _mm256_setzero_si256();\n\n        for (int j = 0; j < num_simd_iters; ++j) {\n            __m256i data = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(row + j * 8));\n            sum = _mm256_add_epi32(sum, data);\n        }\n\n        // Horizontal sum of 8 integers in sum\n        __m128i sum128 = _mm_add_epi32(_mm256_extracti128_si256(sum, 0), _mm256_extracti128_si256(sum, 1));\n        sum128 = _mm_add_epi32(sum128, _mm_srli_si128(sum128, 8));\n        sum128 = _mm_add_epi32(sum128, _mm_srli_si128(sum128, 4));\n        int row_sum = _mm_cvtsi128_si32(sum128);\n\n        // Add remaining elements\n        for (int j = num_simd_iters * 8; j < num_cols; ++j) {\n            row_sum += row[j];\n        }\n\n        total_drops += (row_sum + capacity - 1) / capacity; // Ceiling division\n    }\n\n    return total_drops;\n}\n```"}
{"task_id": "SimdBench_119_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint max_fill_simd(const std::vector<std::vector<int> > & grid, int capacity) {\n    int total_drops = 0;\n    int num_rows = grid.size();\n    if (num_rows == 0) return 0;\n    int num_cols = grid[0].size();\n    int num_simd_iters = num_cols / 8; // 8 integers per 256-bit AVX register\n    int remainder = num_cols % 8;\n\n    for (int i = 0; i < num_rows; ++i) {\n        const int* row = grid[i].data();\n        __m256i sum = _mm256_setzero_si256();\n\n        for (int j = 0; j < num_simd_iters; ++j) {\n            __m256i data = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(row + j * 8));\n            sum = _mm256_add_epi32(sum, data);\n        }\n\n        // Horizontal sum of 8 integers in sum\n        __m128i sum128 = _mm_add_epi32(_mm256_extracti128_si256(sum, 1), _mm256_castsi256_si128(sum));\n        sum128 = _mm_add_epi32(sum128, _mm_srli_si128(sum128, 8));\n        sum128 = _mm_add_epi32(sum128, _mm_srli_si128(sum128, 4));\n        int row_sum = _mm_cvtsi128_si32(sum128);\n\n        // Add remaining elements\n        for (int j = num_simd_iters * 8; j < num_cols; ++j) {\n            row_sum += row[j];\n        }\n\n        total_drops += (row_sum + capacity - 1) / capacity; // Ceiling division\n    }\n\n    return total_drops;\n}\n```"}
{"task_id": "SimdBench_119_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint max_fill_simd(const std::vector<std::vector<int> > & grid, int capacity) {\n    int total_drops = 0;\n    int num_rows = grid.size();\n    if (num_rows == 0) return 0;\n    int num_cols = grid[0].size();\n    int num_simd_iters = num_cols / 8; // 8 integers per 256-bit AVX register\n    int remainder = num_cols % 8;\n\n    for (int i = 0; i < num_rows; ++i) {\n        const int* row = grid[i].data();\n        __m256i sum = _mm256_setzero_si256();\n\n        for (int j = 0; j < num_simd_iters; ++j) {\n            __m256i data = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(row + j * 8));\n            sum = _mm256_add_epi32(sum, data);\n        }\n\n        // Horizontal sum of 8 integers in sum\n        __m128i sum128 = _mm_add_epi32(_mm256_extracti128_si256(sum, 0), _mm256_extracti128_si256(sum, 1));\n        sum128 = _mm_add_epi32(sum128, _mm_srli_si128(sum128, 8));\n        sum128 = _mm_add_epi32(sum128, _mm_srli_si128(sum128, 4));\n        int row_sum = _mm_cvtsi128_si32(sum128);\n\n        // Add remaining elements\n        for (int j = num_simd_iters * 8; j < num_cols; ++j) {\n            row_sum += row[j];\n        }\n\n        total_drops += (row_sum + capacity - 1) / capacity; // Ceiling division\n    }\n\n    return total_drops;\n}\n```"}
{"task_id": "SimdBench_119_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint max_fill_simd(const std::vector<std::vector<int> > & grid, int capacity) {\n    int total_drops = 0;\n    int num_rows = grid.size();\n    if (num_rows == 0) return 0;\n    int num_cols = grid[0].size();\n    int num_simd_elements = 8; // AVX2 processes 256 bits, which is 8 integers\n\n    for (int i = 0; i < num_rows; ++i) {\n        int drops_in_row = 0;\n        int j = 0;\n        __m256i capacity_vec = _mm256_set1_epi32(capacity);\n        __m256i zero_vec = _mm256_setzero_si256();\n        __m256i sum_vec = _mm256_setzero_si256();\n\n        for (; j <= num_cols - num_simd_elements; j += num_simd_elements) {\n            __m256i row_vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&grid[i][j]));\n            __m256i count_vec = _mm256_cmpeq_epi32(row_vec, _mm256_set1_epi32(1));\n            count_vec = _mm256_and_si256(count_vec, _mm256_set1_epi32(1));\n            sum_vec = _mm256_add_epi32(sum_vec, count_vec);\n        }\n\n        // Horizontal sum of sum_vec\n        int horizontal_sum[8];\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(horizontal_sum), sum_vec);\n        drops_in_row = horizontal_sum[0] + horizontal_sum[1] + horizontal_sum[2] + horizontal_sum[3] +\n                       horizontal_sum[4] + horizontal_sum[5] + horizontal_sum[6] + horizontal_sum[7];\n\n        // Handle remaining elements\n        for (; j < num_cols; ++j) {\n            drops_in_row += grid[i][j];\n        }\n\n        total_drops += (drops_in_row + capacity - 1) / capacity; // Ceiling division\n    }\n\n    return total_drops;\n}\n```"}
{"task_id": "SimdBench_119_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint max_fill_simd(const std::vector<std::vector<int> > & grid, int capacity) {\n    int total_drops = 0;\n    int num_rows = grid.size();\n    if (num_rows == 0) return 0;\n    int num_cols = grid[0].size();\n    int num_simd_iters = num_cols / 8; // 8 integers per 256-bit AVX register\n    int remainder = num_cols % 8;\n\n    for (int i = 0; i < num_rows; ++i) {\n        const int* row = grid[i].data();\n        __m256i sum = _mm256_setzero_si256();\n\n        for (int j = 0; j < num_simd_iters; ++j) {\n            __m256i data = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(row + j * 8));\n            sum = _mm256_add_epi32(sum, data);\n        }\n\n        int sum_array[8];\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(sum_array), sum);\n\n        int row_sum = 0;\n        for (int j = 0; j < 8; ++j) {\n            row_sum += sum_array[j];\n        }\n\n        for (int j = num_simd_iters * 8; j < num_cols; ++j) {\n            row_sum += row[j];\n        }\n\n        total_drops += (row_sum + capacity - 1) / capacity; // Ceiling division\n    }\n\n    return total_drops;\n}\n```"}
{"task_id": "SimdBench_120_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint64_t solution_simd(const std::vector<int16_t>& lst){\n    __m256i sum = _mm256_setzero_si256();\n    int n = lst.size();\n    int i = 0;\n\n    for (; i <= n - 16; i += 16) {\n        __m256i data = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&lst[i]));\n        __m256i mask_even_positions = _mm256_set_epi16(0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1);\n        __m256i even_positions = _mm256_and_si256(data, mask_even_positions);\n        __m256i mask_odds = _mm256_set1_epi16(1);\n        __m256i odds = _mm256_and_si256(even_positions, mask_odds);\n        sum = _mm256_add_epi16(sum, odds);\n    }\n\n    __m128i sum_low = _mm256_extracti128_si256(sum, 0);\n    __m128i sum_high = _mm256_extracti128_si256(sum, 1);\n    sum_low = _mm_add_epi16(sum_low, sum_high);\n\n    sum_low = _mm_hadd_epi16(sum_low, sum_low);\n    sum_low = _mm_hadd_epi16(sum_low, sum_low);\n\n    int16_t result[8];\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(result), sum_low);\n\n    int64_t total_sum = 0;\n    for (int j = 0; j < 8; ++j) {\n        total_sum += result[j];\n    }\n\n    for (; i < n; ++i) {\n        if (i % 2 == 0 && lst[i] % 2 != 0) {\n            total_sum += lst[i];\n        }\n    }\n\n    return total_sum;\n}\n```"}
{"task_id": "SimdBench_120_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint64_t solution_simd(const std::vector<int16_t>& lst){\n    __m256i sum = _mm256_setzero_si256();\n    __m256i odd_mask = _mm256_set1_epi16(1);\n    int i;\n\n    for (i = 0; i <= (int)lst.size() - 16; i += 16) {\n        __m256i vec = _mm256_loadu_si256((__m256i const*)(lst.data() + i));\n        __m256i even_positions = _mm256_and_si256(vec, _mm256_setr_epi16(0xFFFF, 0, 0xFFFF, 0, 0xFFFF, 0, 0xFFFF, 0));\n        __m256i odd_elements = _mm256_and_si256(even_positions, odd_mask);\n        sum = _mm256_add_epi16(sum, odd_elements);\n    }\n\n    __m128i sum_low = _mm256_castsi256_si128(sum);\n    __m128i sum_high = _mm256_extracti128_si256(sum, 1);\n    sum_low = _mm_add_epi16(sum_low, sum_high);\n\n    int16_t result[8];\n    _mm_storeu_si128((__m128i*)result, sum_low);\n\n    int64_t total_sum = 0;\n    for (int j = 0; j < 8; ++j) {\n        total_sum += result[j];\n    }\n\n    for (; i < (int)lst.size(); ++i) {\n        if (i % 2 == 0 && lst[i] % 2 != 0) {\n            total_sum += lst[i];\n        }\n    }\n\n    return total_sum;\n}\n```"}
{"task_id": "SimdBench_120_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint64_t solution_simd(const std::vector<int16_t>& lst){\n    __m256i sum = _mm256_setzero_si256();\n    __m256i odd_mask = _mm256_set1_epi16(1);\n    int i = 0;\n    for (; i <= (int)lst.size() - 16; i += 16) {\n        __m256i vec = _mm256_loadu_si256((__m256i const*)&lst[i]);\n        __m256i even_positions = _mm256_and_si256(vec, _mm256_setr_epi16(0xFFFF, 0, 0xFFFF, 0, 0xFFFF, 0, 0xFFFF, 0));\n        __m256i odd_elements = _mm256_and_si256(even_positions, odd_mask);\n        sum = _mm256_add_epi16(sum, odd_elements);\n    }\n    __m128i sum_low = _mm256_castsi256_si128(sum);\n    __m128i sum_high = _mm256_extracti128_si256(sum, 1);\n    sum_low = _mm_add_epi16(sum_low, sum_high);\n    sum_low = _mm_hadd_epi16(sum_low, sum_low);\n    sum_low = _mm_hadd_epi16(sum_low, sum_low);\n    int16_t result[8];\n    _mm_storeu_si128((__m128i*)result, sum_low);\n    int64_t total_sum = result[0];\n\n    for (; i < (int)lst.size(); i += 2) {\n        if (lst[i] % 2 != 0) {\n            total_sum += lst[i];\n        }\n    }\n    return total_sum;\n}\n```"}
{"task_id": "SimdBench_120_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint64_t solution_simd(const std::vector<int16_t>& lst){\n    __m256i sum = _mm256_setzero_si256();\n    int n = lst.size();\n    int i = 0;\n\n    for (; i <= n - 16; i += 16) {\n        __m256i data = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&lst[i]));\n        __m256i mask_even_positions = _mm256_set_epi16(0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1);\n        __m256i even_positions = _mm256_and_si256(data, mask_even_positions);\n        __m256i mask_odds = _mm256_set1_epi16(1);\n        __m256i odds = _mm256_and_si256(even_positions, mask_odds);\n        sum = _mm256_add_epi16(sum, odds);\n    }\n\n    __m128i sum_low = _mm256_extracti128_si256(sum, 0);\n    __m128i sum_high = _mm256_extracti128_si256(sum, 1);\n    sum_low = _mm_add_epi16(sum_low, sum_high);\n\n    sum_low = _mm_add_epi16(sum_low, _mm_srli_si128(sum_low, 8));\n    sum_low = _mm_add_epi16(sum_low, _mm_srli_si128(sum_low, 4));\n    sum_low = _mm_add_epi16(sum_low, _mm_srli_si128(sum_low, 2));\n\n    int16_t result = _mm_extract_epi16(sum_low, 0);\n\n    for (; i < n; i += 2) {\n        if (lst[i] % 2 != 0) {\n            result += lst[i];\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_120_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint64_t solution_simd(const std::vector<int16_t>& lst){\n    __m256i sum = _mm256_setzero_si256();\n    __m256i odd_mask = _mm256_set1_epi16(1);\n    int i = 0;\n    for (; i <= lst.size() - 16; i += 16) {\n        __m256i vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&lst[i]));\n        __m256i even_positions = _mm256_and_si256(vec, _mm256_setr_epi16(0xFFFF, 0, 0xFFFF, 0, 0xFFFF, 0, 0xFFFF, 0));\n        __m256i odd_elements = _mm256_and_si256(even_positions, odd_mask);\n        sum = _mm256_add_epi16(sum, odd_elements);\n    }\n    __m128i sum_low = _mm_add_epi16(_mm256_extracti128_si256(sum, 0), _mm256_extracti128_si256(sum, 1));\n    sum_low = _mm_add_epi16(sum_low, _mm_srli_si128(sum_low, 8));\n    sum_low = _mm_add_epi16(sum_low, _mm_srli_si128(sum_low, 4));\n    int16_t result = _mm_extract_epi16(sum_low, 0);\n\n    for (; i < lst.size(); i += 2) {\n        if (lst[i] % 2 != 0) {\n            result += lst[i];\n        }\n    }\n\n    return static_cast<int64_t>(result);\n}\n```"}
{"task_id": "SimdBench_121_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint add_elements_simd(std::vector<int> arr, int k) {\n    __m256i sum = _mm256_setzero_si256();\n    __m256i threshold = _mm256_set1_epi32(100);\n\n    int i = 0;\n    for (; i <= k - 8; i += 8) {\n        __m256i values = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&arr[i]));\n        __m256i mask = _mm256_cmpgt_epi32(threshold, values);\n        __m256i filtered_values = _mm256_and_si256(values, mask);\n        sum = _mm256_add_epi32(sum, filtered_values);\n    }\n\n    int result[8];\n    _mm256_storeu_si256(reinterpret_cast<__m256i*>(result), sum);\n\n    int total_sum = 0;\n    for (int j = 0; j < 8; ++j) {\n        total_sum += result[j];\n    }\n\n    for (; i < k; ++i) {\n        if (arr[i] < 100) {\n            total_sum += arr[i];\n        }\n    }\n\n    return total_sum;\n}\n```"}
{"task_id": "SimdBench_121_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint add_elements_simd(std::vector<int> arr, int k) {\n    __m256i sum = _mm256_setzero_si256();\n    __m256i threshold = _mm256_set1_epi32(99);\n    int i = 0;\n\n    for (; i <= k - 8; i += 8) {\n        __m256i vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&arr[i]));\n        __m256i mask = _mm256_cmpgt_epi32(threshold, vec);\n        __m256i filtered = _mm256_and_si256(mask, vec);\n        sum = _mm256_add_epi32(sum, filtered);\n    }\n\n    int result[8];\n    _mm256_storeu_si256(reinterpret_cast<__m256i*>(result), sum);\n\n    int total_sum = 0;\n    for (int j = 0; j < 8; ++j) {\n        total_sum += result[j];\n    }\n\n    for (; i < k; ++i) {\n        if (arr[i] <= 99) {\n            total_sum += arr[i];\n        }\n    }\n\n    return total_sum;\n}\n```"}
{"task_id": "SimdBench_121_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint add_elements_simd(std::vector<int> arr, int k) {\n    __m256i sum = _mm256_setzero_si256();\n    __m256i threshold = _mm256_set1_epi32(100);\n\n    int i = 0;\n    for (; i <= k - 8; i += 8) {\n        __m256i vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&arr[i]));\n        __m256i mask = _mm256_cmpgt_epi32(threshold, vec);\n        __m256i filtered = _mm256_and_si256(mask, vec);\n        sum = _mm256_add_epi32(sum, filtered);\n    }\n\n    int result[8];\n    _mm256_storeu_si256(reinterpret_cast<__m256i*>(result), sum);\n\n    int total_sum = 0;\n    for (int j = 0; j < 8; ++j) {\n        total_sum += result[j];\n    }\n\n    for (; i < k; ++i) {\n        if (arr[i] < 100) {\n            total_sum += arr[i];\n        }\n    }\n\n    return total_sum;\n}\n```"}
{"task_id": "SimdBench_121_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint add_elements_simd(std::vector<int> arr, int k) {\n    __m256i sum = _mm256_setzero_si256();\n    __m256i threshold = _mm256_set1_epi32(99);\n\n    int i = 0;\n    for (; i <= k - 8; i += 8) {\n        __m256i values = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&arr[i]));\n        __m256i mask = _mm256_cmpgt_epi32(threshold, values);\n        __m256i filtered_values = _mm256_and_si256(values, mask);\n        sum = _mm256_add_epi32(sum, filtered_values);\n    }\n\n    int result[8];\n    _mm256_storeu_si256(reinterpret_cast<__m256i*>(result), sum);\n\n    int total_sum = 0;\n    for (int j = 0; j < 8; ++j) {\n        total_sum += result[j];\n    }\n\n    for (; i < k; ++i) {\n        if (arr[i] <= 99) {\n            total_sum += arr[i];\n        }\n    }\n\n    return total_sum;\n}\n```"}
{"task_id": "SimdBench_121_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint add_elements_simd(std::vector<int> arr, int k) {\n    __m256i sum = _mm256_setzero_si256();\n    int i = 0;\n\n    // Process 8 elements at a time\n    for (; i <= k - 8; i += 8) {\n        __m256i vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&arr[i]));\n        __m256i mask = _mm256_cmpgt_epi32(_mm256_set1_epi32(99), vec);\n        vec = _mm256_and_si256(vec, mask);\n        sum = _mm256_add_epi32(sum, vec);\n    }\n\n    // Horizontal sum of the 8 elements in sum\n    int temp[8];\n    _mm256_storeu_si256(reinterpret_cast<__m256i*>(temp), sum);\n    int result = temp[0] + temp[1] + temp[2] + temp[3] + temp[4] + temp[5] + temp[6] + temp[7];\n\n    // Add remaining elements\n    for (; i < k; ++i) {\n        if (arr[i] <= 99) {\n            result += arr[i];\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_122_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nbool is_sorted_simd(const std::vector<int> & lst) {\n    if (lst.size() <= 1) return true;\n\n    int n = lst.size();\n    __m256i prev = _mm256_set1_epi32(lst[0]);\n    __m256i ones = _mm256_set1_epi32(1);\n    __m256i mask = _mm256_setzero_si256();\n\n    for (int i = 1; i + 7 < n; i += 8) {\n        __m256i curr = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&lst[i]));\n        __m256i next = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&lst[i + 1]));\n\n        __m256i cmp1 = _mm256_cmpgt_epi32(prev, curr);\n        __m256i cmp2 = _mm256_cmpeq_epi32(curr, next);\n\n        mask = _mm256_or_si256(mask, cmp1);\n        mask = _mm256_or_si256(mask, cmp2);\n\n        prev = curr;\n    }\n\n    int hmask = _mm256_movemask_epi8(mask);\n    if (hmask != 0) return false;\n\n    for (int i = (n / 8) * 8; i < n - 1; ++i) {\n        if (lst[i] > lst[i + 1] || (i > 0 && lst[i] == lst[i - 1] && lst[i] == lst[i + 1])) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_122_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nbool is_sorted_simd(const std::vector<int> & lst) {\n    if (lst.size() <= 1) return true;\n\n    __m256i prev = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&lst[0]));\n    __m256i ones = _mm256_set1_epi32(1);\n    __m256i mask = _mm256_setzero_si256();\n    __m256i dup_mask = _mm256_setzero_si256();\n\n    for (size_t i = 8; i < lst.size(); i += 8) {\n        __m256i curr = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&lst[i - 8]));\n        __m256i next = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&lst[i]));\n\n        __m256i cmp1 = _mm256_cmpgt_epi32(curr, next);\n        __m256i cmp2 = _mm256_cmpeq_epi32(curr, _mm256_add_epi32(next, ones));\n        __m256i cmp3 = _mm256_cmpeq_epi32(curr, next);\n\n        mask = _mm256_or_si256(mask, cmp1);\n        dup_mask = _mm256_or_si256(dup_mask, cmp3);\n\n        prev = next;\n    }\n\n    // Check remaining elements\n    for (size_t i = (lst.size() / 8) * 8; i < lst.size() - 1; ++i) {\n        if (lst[i] > lst[i + 1]) return false;\n        if (lst[i] == lst[i + 1] && (i > 0 && lst[i] == lst[i - 1])) return false;\n    }\n\n    // Check if any element was out of order or duplicated\n    int mask_result = _mm256_movemask_epi8(mask);\n    int dup_mask_result = _mm256_movemask_epi8(dup_mask);\n\n    return mask_result == 0 && (dup_mask_result & 0xaaaaaaaa) == 0;\n}\n```"}
{"task_id": "SimdBench_122_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nbool is_sorted_simd(const std::vector<int> & lst) {\n    if (lst.size() <= 1) return true;\n\n    __m256i prev = _mm256_set1_epi32(lst[0]);\n    __m256i mask = _mm256_set1_epi32(0xFFFFFFFF);\n    __m256i zero = _mm256_setzero_si256();\n\n    for (size_t i = 1; i + 7 < lst.size(); i += 8) {\n        __m256i curr = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&lst[i]));\n        __m256i next = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&lst[i + 1]));\n\n        __m256i cmp_le = _mm256_cmple_epi32(prev, curr);\n        __m256i cmp_eq = _mm256_cmpeq_epi32(curr, next);\n\n        mask = _mm256_and_si256(mask, cmp_le);\n        mask = _mm256_andnot_si256(cmp_eq, mask);\n\n        prev = curr;\n    }\n\n    int mask_result = _mm256_movemask_epi8(mask);\n    if ((mask_result & 0xAAAAAAAA) != 0xAAAAAAAA) return false;\n\n    for (size_t i = (lst.size() / 8) * 8; i < lst.size() - 1; ++i) {\n        if (lst[i] > lst[i + 1] || (i > 0 && lst[i] == lst[i - 1] && lst[i] == lst[i + 1])) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_122_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nbool is_sorted_simd(const std::vector<int> & lst) {\n    if (lst.size() <= 1) return true;\n\n    __m256i prev = _mm256_set1_epi32(lst[0]);\n    __m256i mask = _mm256_set1_epi32(0xFFFFFFFF);\n    __m256i zero = _mm256_setzero_si256();\n\n    for (size_t i = 1; i + 7 < lst.size(); i += 8) {\n        __m256i curr = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&lst[i]));\n        __m256i next = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&lst[i + 1]));\n\n        __m256i cmp1 = _mm256_cmpgt_epi32(prev, curr);\n        __m256i cmp2 = _mm256_cmpeq_epi32(curr, next);\n\n        mask = _mm256_andnot_si256(cmp1, mask);\n        mask = _mm256_andnot_si256(cmp2, mask);\n\n        prev = curr;\n    }\n\n    int mask_result = _mm256_movemask_epi8(mask);\n    if (mask_result != 0xFFFFFFFF) return false;\n\n    for (size_t i = (lst.size() / 8) * 8; i < lst.size() - 1; ++i) {\n        if (lst[i] > lst[i + 1] || (i > 0 && lst[i] == lst[i - 1] && lst[i] == lst[i + 1])) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_122_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nbool is_sorted_simd(const std::vector<int> & lst) {\n    if (lst.size() <= 1) return true;\n\n    __m256i prev = _mm256_set1_epi32(lst[0]);\n    __m256i ones = _mm256_set1_epi32(1);\n    __m256i mask = _mm256_setzero_si256();\n\n    for (size_t i = 1; i + 7 < lst.size(); i += 8) {\n        __m256i curr = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&lst[i]));\n        __m256i next = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&lst[i + 1]));\n\n        __m256i cmp1 = _mm256_cmpgt_epi32(prev, curr);\n        __m256i cmp2 = _mm256_cmpeq_epi32(curr, next);\n\n        mask = _mm256_or_si256(mask, cmp1);\n        mask = _mm256_or_si256(mask, cmp2);\n\n        prev = curr;\n    }\n\n    int hmask = _mm256_movemask_epi8(mask);\n    if (hmask != 0) return false;\n\n    for (size_t i = (lst.size() / 8) * 8; i < lst.size() - 1; ++i) {\n        if (lst[i] > lst[i + 1] || lst[i] == lst[i + 1]) return false;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_123_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint prod_signs_simd(const std::vector<int> & arr){\n    if (arr.empty()) return -32768;\n\n    __m256i sum_magnitudes = _mm256_setzero_si256();\n    __m256i sign_product = _mm256_set1_epi32(1);\n\n    size_t i = 0;\n    for (; i + 7 < arr.size(); i += 8) {\n        __m256i vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&arr[i]));\n\n        // Calculate magnitudes\n        __m256i abs_vec = _mm256_abs_epi32(vec);\n        sum_magnitudes = _mm256_add_epi32(sum_magnitudes, abs_vec);\n\n        // Calculate sign product\n        __m256i sign_mask = _mm256_cmpgt_epi32(_mm256_setzero_si256(), vec);\n        __m256i sign_vec = _mm256_sub_epi32(_mm256_xor_si256(sign_mask, _mm256_set1_epi32(1)), _mm256_set1_epi32(1));\n        sign_product = _mm256_mullo_epi32(sign_product, sign_vec);\n    }\n\n    // Horizontal sum of magnitudes\n    int magnitudes[8];\n    _mm256_storeu_si256(reinterpret_cast<__m256i*>(magnitudes), sum_magnitudes);\n    int sum = magnitudes[0] + magnitudes[1] + magnitudes[2] + magnitudes[3] + magnitudes[4] + magnitudes[5] + magnitudes[6] + magnitudes[7];\n\n    // Horizontal product of signs\n    int signs[8];\n    _mm256_storeu_si256(reinterpret_cast<__m256i*>(signs), sign_product);\n    int product = signs[0] * signs[1] * signs[2] * signs[3] * signs[4] * signs[5] * signs[6] * signs[7];\n\n    // Process remaining elements\n    for (; i < arr.size(); ++i) {\n        sum += std::abs(arr[i]);\n        product *= (arr[i] > 0) - (arr[i] < 0);\n    }\n\n    return sum * product;\n}\n```"}
{"task_id": "SimdBench_123_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint prod_signs_simd(const std::vector<int> & arr){\n    if (arr.empty()) return -32768;\n\n    __m256i sum_magnitudes = _mm256_setzero_si256();\n    __m256i sign_product = _mm256_set1_epi32(1);\n\n    int n = arr.size();\n    int i = 0;\n\n    for (; i <= n - 8; i += 8) {\n        __m256i vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&arr[i]));\n        __m256i abs_vec = _mm256_abs_epi32(vec);\n        sum_magnitudes = _mm256_add_epi32(sum_magnitudes, abs_vec);\n\n        __m256i sign_mask = _mm256_cmpgt_epi32(_mm256_setzero_si256(), vec);\n        __m256i sign_vec = _mm256_sub_epi32(_mm256_xor_si256(sign_mask, _mm256_set1_epi32(1)), _mm256_srli_epi32(sign_mask, 31));\n        sign_product = _mm256_mullo_epi32(sign_product, sign_vec);\n    }\n\n    int sum_magnitudes_arr[8];\n    int sign_product_arr[8];\n    _mm256_storeu_si256(reinterpret_cast<__m256i*>(sum_magnitudes_arr), sum_magnitudes);\n    _mm256_storeu_si256(reinterpret_cast<__m256i*>(sign_product_arr), sign_product);\n\n    int total_sum_magnitudes = 0;\n    int total_sign_product = 1;\n    for (int j = 0; j < 8; ++j) {\n        total_sum_magnitudes += sum_magnitudes_arr[j];\n        total_sign_product *= sign_product_arr[j];\n    }\n\n    for (; i < n; ++i) {\n        total_sum_magnitudes += std::abs(arr[i]);\n        total_sign_product *= (arr[i] > 0) - (arr[i] < 0);\n    }\n\n    return total_sum_magnitudes * total_sign_product;\n}\n```"}
{"task_id": "SimdBench_123_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint prod_signs_simd(const std::vector<int> & arr){\n    if (arr.empty()) return -32768;\n\n    __m256i sum_magnitudes = _mm256_setzero_si256();\n    __m256i sign_product = _mm256_set1_epi32(1);\n\n    size_t i = 0;\n    for (; i + 7 < arr.size(); i += 8) {\n        __m256i vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&arr[i]));\n\n        // Calculate magnitudes\n        __m256i abs_vec = _mm256_abs_epi32(vec);\n        sum_magnitudes = _mm256_add_epi32(sum_magnitudes, abs_vec);\n\n        // Calculate sign product\n        __m256i sign_mask = _mm256_cmpgt_epi32(_mm256_setzero_si256(), vec);\n        __m256i sign_vec = _mm256_sub_epi32(_mm256_xor_si256(sign_mask, _mm256_set1_epi32(1)), _mm256_set1_epi32(1));\n        sign_product = _mm256_mullo_epi32(sign_product, sign_vec);\n    }\n\n    // Horizontal sum of magnitudes\n    int magnitudes[8];\n    _mm256_storeu_si256(reinterpret_cast<__m256i*>(magnitudes), sum_magnitudes);\n    int sum = magnitudes[0] + magnitudes[1] + magnitudes[2] + magnitudes[3] + magnitudes[4] + magnitudes[5] + magnitudes[6] + magnitudes[7];\n\n    // Horizontal product of signs\n    int signs[8];\n    _mm256_storeu_si256(reinterpret_cast<__m256i*>(signs), sign_product);\n    int product = signs[0] * signs[1] * signs[2] * signs[3] * signs[4] * signs[5] * signs[6] * signs[7];\n\n    // Process remaining elements\n    for (; i < arr.size(); ++i) {\n        sum += std::abs(arr[i]);\n        product *= (arr[i] > 0) - (arr[i] < 0);\n    }\n\n    return sum * product;\n}\n```"}
{"task_id": "SimdBench_123_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint prod_signs_simd(const std::vector<int> & arr){\n    if (arr.empty()) return -32768;\n\n    __m256i sum_magnitudes = _mm256_setzero_si256();\n    __m256i sign_product = _mm256_set1_epi32(1);\n\n    int n = arr.size();\n    int i = 0;\n\n    for (; i <= n - 8; i += 8) {\n        __m256i vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&arr[i]));\n\n        // Calculate magnitudes\n        __m256i abs_vec = _mm256_abs_epi32(vec);\n        sum_magnitudes = _mm256_add_epi32(sum_magnitudes, abs_vec);\n\n        // Calculate sign product\n        __m256i sign_mask = _mm256_cmpgt_epi32(_mm256_setzero_si256(), vec);\n        __m256i sign_vec = _mm256_sub_epi32(_mm256_xor_si256(sign_mask, _mm256_set1_epi32(1)), _mm256_set1_epi32(1));\n        sign_product = _mm256_mullo_epi32(sign_product, sign_vec);\n\n        // Check for zero elements\n        __m256i zero_mask = _mm256_cmpeq_epi32(vec, _mm256_setzero_si256());\n        if (_mm256_movemask_epi8(zero_mask) != 0) {\n            return 0;\n        }\n    }\n\n    // Horizontal sum of magnitudes\n    int magnitudes[8];\n    _mm256_storeu_si256(reinterpret_cast<__m256i*>(magnitudes), sum_magnitudes);\n    int sum = magnitudes[0] + magnitudes[1] + magnitudes[2] + magnitudes[3] + magnitudes[4] + magnitudes[5] + magnitudes[6] + magnitudes[7];\n\n    // Horizontal product of signs\n    int signs[8];\n    _mm256_storeu_si256(reinterpret_cast<__m256i*>(signs), sign_product);\n    int product = signs[0] * signs[1] * signs[2] * signs[3] * signs[4] * signs[5] * signs[6] * signs[7];\n\n    // Process remaining elements\n    for (; i < n; ++i) {\n        int val = arr[i];\n        sum += std::abs(val);\n        product *= (val > 0) - (val < 0);\n        if (val == 0) return 0;\n    }\n\n    return sum * product;\n}\n```"}
{"task_id": "SimdBench_123_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint prod_signs_simd(const std::vector<int> & arr){\n    if (arr.empty()) return -32768;\n\n    __m256i sum_magnitudes = _mm256_setzero_si256();\n    __m256i prod_signs = _mm256_set1_epi32(1);\n\n    size_t i = 0;\n    for (; i + 7 < arr.size(); i += 8) {\n        __m256i vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&arr[i]));\n        __m256i abs_vec = _mm256_abs_epi32(vec);\n        sum_magnitudes = _mm256_add_epi32(sum_magnitudes, abs_vec);\n\n        __m256i sign_mask = _mm256_cmpgt_epi32(_mm256_setzero_si256(), vec);\n        __m256i sign_vec = _mm256_sub_epi32(_mm256_xor_si256(sign_mask, _mm256_set1_epi32(1)), _mm256_set1_epi32(1));\n        sign_vec = _mm256_andnot_si256(_mm256_cmpeq_epi32(vec, _mm256_setzero_si256()), sign_vec);\n        prod_signs = _mm256_mullo_epi32(prod_signs, sign_vec);\n    }\n\n    int sum_magnitudes_arr[8];\n    int prod_signs_arr[8];\n    _mm256_storeu_si256(reinterpret_cast<__m256i*>(sum_magnitudes_arr), sum_magnitudes);\n    _mm256_storeu_si256(reinterpret_cast<__m256i*>(prod_signs_arr), prod_signs);\n\n    int total_sum_magnitudes = 0;\n    int total_prod_signs = 1;\n    for (size_t j = 0; j < 8; ++j) {\n        total_sum_magnitudes += sum_magnitudes_arr[j];\n        total_prod_signs *= prod_signs_arr[j];\n    }\n\n    for (; i < arr.size(); ++i) {\n        total_sum_magnitudes += std::abs(arr[i]);\n        total_prod_signs *= (arr[i] > 0) - (arr[i] < 0);\n    }\n\n    return total_sum_magnitudes * total_prod_signs;\n}\n```"}
{"task_id": "SimdBench_124_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n#include <climits>\n\nstd::vector<int> minPath_simd(const std::vector<std::vector<int> > & grid, int k) {\n    int N = grid.size();\n    std::vector<int> result(k, INT_MAX);\n    __m256i min_path = _mm256_set1_epi32(INT_MAX);\n\n    for (int i = 0; i < N; ++i) {\n        for (int j = 0; j < N; ++j) {\n            std::vector<int> path;\n            path.push_back(grid[i][j]);\n\n            std::function<void(int, int, int)> dfs = [&](int x, int y, int depth) {\n                if (depth == k) {\n                    __m256i current_path = _mm256_setr_epi32(\n                        path[0], path[1], path[2], path[3],\n                        path[4], path[5], path[6], path[7]\n                    );\n                    __m256i mask = _mm256_cmpgt_epi32(min_path, current_path);\n                    if (_mm256_movemask_epi8(mask) != 0) {\n                        min_path = current_path;\n                        for (int l = 0; l < k; ++l) {\n                            result[l] = path[l];\n                        }\n                    }\n                    return;\n                }\n\n                static const int dx[] = {-1, 1, 0, 0};\n                static const int dy[] = {0, 0, -1, 1};\n\n                for (int dir = 0; dir < 4; ++dir) {\n                    int nx = x + dx[dir];\n                    int ny = y + dy[dir];\n                    if (nx >= 0 && nx < N && ny >= 0 && ny < N) {\n                        path.push_back(grid[nx][ny]);\n                        dfs(nx, ny, depth + 1);\n                        path.pop_back();\n                    }\n                }\n            };\n\n            dfs(i, j, 1);\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_124_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n#include <climits>\n\nstd::vector<int> minPath_simd(const std::vector<std::vector<int> > & grid, int k) {\n    int N = grid.size();\n    std::vector<int> result(k, INT_MAX);\n    __m256i min_path = _mm256_set1_epi32(INT_MAX);\n\n    for (int i = 0; i < N; ++i) {\n        for (int j = 0; j < N; ++j) {\n            std::vector<int> path;\n            path.push_back(grid[i][j]);\n\n            std::function<void(int, int, int)> dfs = [&](int x, int y, int depth) {\n                if (depth == k) {\n                    __m256i current_path = _mm256_set_epi32(\n                        path[7], path[6], path[5], path[4],\n                        path[3], path[2], path[1], path[0]\n                    );\n                    __m256i mask = _mm256_cmpgt_epi32(min_path, current_path);\n                    if (_mm256_movemask_epi8(mask) != 0) {\n                        min_path = current_path;\n                        result = path;\n                    }\n                    return;\n                }\n\n                static const int dx[] = {0, 0, -1, 1};\n                static const int dy[] = {-1, 1, 0, 0};\n\n                for (int dir = 0; dir < 4; ++dir) {\n                    int nx = x + dx[dir];\n                    int ny = y + dy[dir];\n                    if (nx >= 0 && nx < N && ny >= 0 && ny < N) {\n                        path.push_back(grid[nx][ny]);\n                        dfs(nx, ny, depth + 1);\n                        path.pop_back();\n                    }\n                }\n            };\n\n            dfs(i, j, 1);\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_124_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n#include <climits>\n\nstd::vector<int> minPath_simd(const std::vector<std::vector<int> > & grid, int k) {\n    int N = grid.size();\n    std::vector<int> result(k, INT_MAX);\n    __m256i min_path = _mm256_set1_epi32(INT_MAX);\n\n    for (int i = 0; i < N; ++i) {\n        for (int j = 0; j < N; ++j) {\n            std::vector<int> path;\n            path.push_back(grid[i][j]);\n\n            std::function<void(int, int, int)> dfs = [&](int x, int y, int depth) {\n                if (depth == k) {\n                    __m256i current_path = _mm256_set_epi32(\n                        path[7], path[6], path[5], path[4],\n                        path[3], path[2], path[1], path[0]\n                    );\n                    __m256i mask = _mm256_cmpgt_epi32(min_path, current_path);\n                    if (_mm256_movemask_epi8(mask) != 0) {\n                        min_path = current_path;\n                        for (int l = 0; l < k; ++l) {\n                            result[l] = path[l];\n                        }\n                    }\n                    return;\n                }\n\n                static const int dx[] = {-1, 1, 0, 0};\n                static const int dy[] = {0, 0, -1, 1};\n\n                for (int dir = 0; dir < 4; ++dir) {\n                    int nx = x + dx[dir];\n                    int ny = y + dy[dir];\n                    if (nx >= 0 && nx < N && ny >= 0 && ny < N) {\n                        path.push_back(grid[nx][ny]);\n                        dfs(nx, ny, depth + 1);\n                        path.pop_back();\n                    }\n                }\n            };\n\n            dfs(i, j, 1);\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_124_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n#include <climits>\n\nstd::vector<int> minPath_simd(const std::vector<std::vector<int> > & grid, int k) {\n    int N = grid.size();\n    std::vector<int> result(k, INT_MAX);\n    __m256i min_path = _mm256_set1_epi32(INT_MAX);\n\n    for (int i = 0; i < N; ++i) {\n        for (int j = 0; j < N; ++j) {\n            std::vector<int> path;\n            path.push_back(grid[i][j]);\n\n            std::function<void(int, int, int)> dfs = [&](int x, int y, int depth) {\n                if (depth == k) {\n                    __m256i current_path = _mm256_setr_epi32(\n                        path[0], path[1], path[2], path[3],\n                        path[4], path[5], path[6], path[7]\n                    );\n                    __m256i mask = _mm256_cmpgt_epi32(min_path, current_path);\n                    if (_mm256_movemask_epi8(mask) != 0) {\n                        min_path = current_path;\n                        for (int l = 0; l < k; ++l) {\n                            result[l] = path[l];\n                        }\n                    }\n                    return;\n                }\n\n                static const int dx[] = {-1, 1, 0, 0};\n                static const int dy[] = {0, 0, -1, 1};\n\n                for (int dir = 0; dir < 4; ++dir) {\n                    int nx = x + dx[dir];\n                    int ny = y + dy[dir];\n                    if (nx >= 0 && nx < N && ny >= 0 && ny < N) {\n                        path.push_back(grid[nx][ny]);\n                        dfs(nx, ny, depth + 1);\n                        path.pop_back();\n                    }\n                }\n            };\n\n            dfs(i, j, 1);\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_124_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n#include <climits>\n\nstd::vector<int> minPath_simd(const std::vector<std::vector<int> > & grid, int k) {\n    int N = grid.size();\n    std::vector<int> result(k, INT_MAX);\n    __m256i min_path = _mm256_set1_epi32(INT_MAX);\n\n    for (int i = 0; i < N; ++i) {\n        for (int j = 0; j < N; ++j) {\n            std::vector<int> path;\n            path.push_back(grid[i][j]);\n\n            std::function<void(int, int, int)> dfs = [&](int x, int y, int depth) {\n                if (depth == k) {\n                    __m256i current_path = _mm256_set_epi32(\n                        path[7], path[6], path[5], path[4],\n                        path[3], path[2], path[1], path[0]\n                    );\n                    __m256i mask = _mm256_cmpgt_epi32(min_path, current_path);\n                    if (_mm256_movemask_epi8(mask) != 0) {\n                        min_path = current_path;\n                        result = path;\n                    }\n                    return;\n                }\n\n                static const int dx[] = {-1, 1, 0, 0};\n                static const int dy[] = {0, 0, -1, 1};\n\n                for (int dir = 0; dir < 4; ++dir) {\n                    int nx = x + dx[dir];\n                    int ny = y + dy[dir];\n                    if (nx >= 0 && nx < N && ny >= 0 && ny < N) {\n                        path.push_back(grid[nx][ny]);\n                        dfs(nx, ny, depth + 1);\n                        path.pop_back();\n                    }\n                }\n            };\n\n            dfs(i, j, 1);\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_125_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nuint64_t digits_simd(uint64_t n) {\n    __m256i odd_product = _mm256_set1_epi32(1);\n    __m256i zero = _mm256_setzero_si256();\n    __m256i has_odd = _mm256_setzero_si256();\n\n    while (n > 0) {\n        __m256i digits = _mm256_setr_epi32(n % 10, (n / 10) % 10, (n / 100) % 10, (n / 1000) % 10,\n                                           (n / 10000) % 10, (n / 100000) % 10, (n / 1000000) % 10, (n / 10000000) % 10);\n        n /= 100000000;\n\n        __m256i is_odd = _mm256_andnot_si256(_mm256_cmpeq_epi32(_mm256_and_si256(digits, _mm256_set1_epi32(1)), zero), _mm256_set1_epi32(1));\n        __m256i odd_digits = _mm256_and_si256(digits, is_odd);\n        odd_product = _mm256_mullo_epi32(odd_product, _mm256_or_si256(odd_digits, _mm256_andnot_si256(is_odd, _mm256_set1_epi32(1))));\n        has_odd = _mm256_or_si256(has_odd, is_odd);\n    }\n\n    __m256i result = _mm256_mullo_epi32(odd_product, _mm256_mullo_epi32(_mm256_shuffle_epi32(odd_product, _MM_SHUFFLE(0, 1, 2, 3)),\n                                                                   _mm256_shuffle_epi32(odd_product, _MM_SHUFFLE(2, 3, 0, 1))));\n    result = _mm256_mullo_epi32(result, _mm256_shuffle_epi32(result, _MM_SHUFFLE(1, 0, 3, 2)));\n\n    int32_t final_result = _mm256_extract_epi32(result, 0);\n\n    return _mm256_testz_si256(has_odd, has_odd) ? 0 : final_result;\n}\n```"}
{"task_id": "SimdBench_125_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nuint64_t digits_simd(uint64_t n) {\n    __m256i odd_product = _mm256_set1_epi32(1);\n    __m256i zero = _mm256_setzero_si256();\n    __m256i has_odd = zero;\n\n    while (n > 0) {\n        uint32_t digits[8] = {0};\n        for (int i = 0; i < 8 && n > 0; ++i) {\n            digits[i] = n % 10;\n            n /= 10;\n        }\n\n        __m256i digit_vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(digits));\n        __m256i is_odd = _mm256_and_si256(_mm256_cmpeq_epi32(_mm256_and_si256(digit_vec, _mm256_set1_epi32(1)), _mm256_set1_epi32(1)), _mm256_cmpgt_epi32(digit_vec, zero));\n        __m256i odd_digits = _mm256_blendv_epi8(zero, digit_vec, is_odd);\n        odd_product = _mm256_mullo_epi32(odd_product, odd_digits);\n        has_odd = _mm256_or_si256(has_odd, is_odd);\n    }\n\n    int32_t result[8];\n    _mm256_storeu_si256(reinterpret_cast<__m256i*>(result), odd_product);\n    int32_t has_odd_result[8];\n    _mm256_storeu_si256(reinterpret_cast<__m256i*>(has_odd_result), has_odd);\n\n    uint64_t final_product = 1;\n    bool has_any_odd = false;\n    for (int i = 0; i < 8; ++i) {\n        if (has_odd_result[i] != 0) {\n            has_any_odd = true;\n            final_product *= result[i];\n        }\n    }\n\n    return has_any_odd ? final_product : 0;\n}\n```"}
{"task_id": "SimdBench_125_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nuint64_t digits_simd(uint64_t n) {\n    __m256i odd_product = _mm256_set1_epi32(1);\n    __m256i zero = _mm256_setzero_si256();\n    __m256i has_odd = _mm256_setzero_si256();\n\n    while (n > 0) {\n        __m256i digits = _mm256_setr_epi32(n % 10, (n / 10) % 10, (n / 100) % 10, (n / 1000) % 10,\n                                           (n / 10000) % 10, (n / 100000) % 10, (n / 1000000) % 10, (n / 10000000) % 10);\n        n /= 100000000;\n\n        __m256i is_odd = _mm256_andnot_si256(_mm256_cmpeq_epi32(_mm256_and_si256(digits, _mm256_set1_epi32(1)), zero), _mm256_set1_epi32(1));\n        __m256i odd_digits = _mm256_and_si256(digits, is_odd);\n        odd_product = _mm256_mullo_epi32(odd_product, _mm256_or_si256(odd_digits, _mm256_andnot_si256(is_odd, _mm256_set1_epi32(1))));\n        has_odd = _mm256_or_si256(has_odd, is_odd);\n    }\n\n    __m256i result = _mm256_mullo_epi32(odd_product, _mm256_mullo_epi32(_mm256_shuffle_epi32(odd_product, _MM_SHUFFLE(0, 1, 2, 3)),\n                                                                   _mm256_shuffle_epi32(odd_product, _MM_SHUFFLE(2, 3, 0, 1))));\n    result = _mm256_mullo_epi32(result, _mm256_shuffle_epi32(result, _MM_SHUFFLE(1, 0, 3, 2)));\n\n    int32_t final_result = _mm256_extract_epi32(result, 0) * _mm256_extract_epi32(result, 4);\n\n    return _mm256_testz_si256(has_odd, has_odd) ? 0 : final_result;\n}\n```"}
{"task_id": "SimdBench_125_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nuint64_t digits_simd(uint64_t n) {\n    __m256i ones = _mm256_set1_epi8(1);\n    __m256i fives = _mm256_set1_epi8(5);\n    __m256i nines = _mm256_set1_epi8(9);\n    __m256i odds = _mm256_setr_epi8(1, 3, 5, 7, 9, 1, 3, 5, 7, 9, 1, 3, 5, 7, 9, 1, 3, 5, 7, 9, 1, 3, 5, 7, 9, 1, 3, 5, 7, 9);\n    __m256i result = _mm256_set1_epi8(1);\n    __m256i zero = _mm256_setzero_si256();\n    __m256i has_odd = zero;\n\n    while (n > 0) {\n        __m256i digits = _mm256_setr_epi8(\n            n % 10, (n / 10) % 10, (n / 100) % 10, (n / 1000) % 10,\n            (n / 10000) % 10, (n / 100000) % 10, (n / 1000000) % 10, (n / 10000000) % 10,\n            (n / 100000000) % 10, (n / 1000000000) % 10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n        );\n\n        __m256i is_odd = _mm256_cmpeq_epi8(_mm256_and_epi8(digits, ones), ones);\n        __m256i odd_digits = _mm256_and_epi8(digits, is_odd);\n        __m256i odd_mask = _mm256_cmpeq_epi8(_mm256_and_epi8(odd_digits, odds), odd_digits);\n\n        result = _mm256_mullo_epi8(result, odd_digits);\n        has_odd = _mm256_or_si256(has_odd, odd_mask);\n\n        n /= 10000000000;\n    }\n\n    __m256i horizontal_product = _mm256_mullo_epi8(\n        _mm256_mullo_epi8(_mm256_extracti128_si256(result, 0), _mm256_extracti128_si256(result, 1)),\n        _mm256_set1_epi8(1)\n    );\n\n    for (int i = 1; i < 16; i *= 2) {\n        horizontal_product = _mm256_mullo_epi8(horizontal_product, _mm256_srli_epi16(horizontal_product, i));\n    }\n\n    uint8_t final_result = _mm256_extract_epi8(horizontal_product, 0);\n    uint8_t has_odd_result = _mm256_movemask_epi8(has_odd);\n\n    return (has_odd_result == 0) ? 0 : final_result;\n}\n```"}
{"task_id": "SimdBench_125_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nuint64_t digits_simd(uint64_t n) {\n    __m256i odd_product = _mm256_set1_epi32(1);\n    __m256i zero = _mm256_setzero_si256();\n    __m256i has_odd = zero;\n\n    while (n > 0) {\n        uint32_t digits[8] = {0};\n        for (int i = 0; i < 8 && n > 0; ++i) {\n            digits[i] = n % 10;\n            n /= 10;\n        }\n\n        __m256i digit_vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(digits));\n        __m256i is_odd = _mm256_and_si256(_mm256_cmpeq_epi32(_mm256_and_si256(digit_vec, _mm256_set1_epi32(1)), _mm256_set1_epi32(1)), _mm256_cmpgt_epi32(digit_vec, zero));\n        __m256i odd_digits = _mm256_blendv_epi8(zero, digit_vec, is_odd);\n        odd_product = _mm256_mullo_epi32(odd_product, odd_digits);\n        has_odd = _mm256_or_si256(has_odd, is_odd);\n    }\n\n    int32_t result[8];\n    _mm256_storeu_si256(reinterpret_cast<__m256i*>(result), odd_product);\n    int32_t has_odd_result[8];\n    _mm256_storeu_si256(reinterpret_cast<__m256i*>(has_odd_result), has_odd);\n\n    uint64_t final_product = 1;\n    bool has_any_odd = false;\n    for (int i = 0; i < 8; ++i) {\n        final_product *= result[i];\n        has_any_odd |= (has_odd_result[i] != 0);\n    }\n\n    return has_any_odd ? final_product : 0;\n}\n```"}
{"task_id": "SimdBench_126_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nuint64_t sum_squares_simd(const std::vector<float> & lst){\n    uint64_t sum = 0;\n    size_t n = lst.size();\n    size_t i = 0;\n\n    __m256 vsum = _mm256_setzero_ps();\n\n    for (; i <= n - 8; i += 8) {\n        __m256 v = _mm256_loadu_ps(&lst[i]);\n        __m256 vceil = _mm256_ceil_ps(v);\n        __m256 vsquared = _mm256_mul_ps(vceil, vceil);\n        vsum = _mm256_add_ps(vsum, vsquared);\n    }\n\n    float sum_array[8];\n    _mm256_storeu_ps(sum_array, vsum);\n\n    for (size_t j = 0; j < 8; ++j) {\n        sum += static_cast<uint64_t>(sum_array[j]);\n    }\n\n    for (; i < n; ++i) {\n        float ceil_val = std::ceil(lst[i]);\n        sum += static_cast<uint64_t>(ceil_val * ceil_val);\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_126_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nuint64_t sum_squares_simd(const std::vector<float> & lst){\n    uint64_t sum = 0;\n    size_t i = 0;\n    size_t n = lst.size();\n    __m256 vsum = _mm256_setzero_ps();\n\n    for (; i <= n - 8; i += 8) {\n        __m256 v = _mm256_loadu_ps(&lst[i]);\n        __m256 vceil = _mm256_ceil_ps(v);\n        __m256 vsquared = _mm256_mul_ps(vceil, vceil);\n        vsum = _mm256_add_ps(vsum, vsquared);\n    }\n\n    float sum_array[8];\n    _mm256_storeu_ps(sum_array, vsum);\n    for (size_t j = 0; j < 8; ++j) {\n        sum += static_cast<uint64_t>(sum_array[j]);\n    }\n\n    for (; i < n; ++i) {\n        float val = std::ceil(lst[i]);\n        sum += static_cast<uint64_t>(val * val);\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_126_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nuint64_t sum_squares_simd(const std::vector<float> & lst){\n    uint64_t sum = 0;\n    size_t i = 0;\n    size_t n = lst.size();\n    __m256 vsum = _mm256_setzero_ps();\n\n    for (; i <= n - 8; i += 8) {\n        __m256 v = _mm256_loadu_ps(&lst[i]);\n        __m256 vceil = _mm256_ceil_ps(v);\n        __m256 vsquared = _mm256_mul_ps(vceil, vceil);\n        vsum = _mm256_add_ps(vsum, vsquared);\n    }\n\n    float sum_array[8];\n    _mm256_storeu_ps(sum_array, vsum);\n    for (size_t j = 0; j < 8; ++j) {\n        sum += static_cast<uint64_t>(sum_array[j]);\n    }\n\n    for (; i < n; ++i) {\n        float ceil_val = std::ceil(lst[i]);\n        sum += static_cast<uint64_t>(ceil_val * ceil_val);\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_126_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nuint64_t sum_squares_simd(const std::vector<float> & lst){\n    uint64_t sum = 0;\n    size_t n = lst.size();\n    size_t i = 0;\n\n    // Process 8 floats at a time\n    for (; i <= n - 8; i += 8) {\n        __m256 vec = _mm256_loadu_ps(&lst[i]);\n        __m256 ceil_vec = _mm256_ceil_ps(vec);\n        __m256 squared_vec = _mm256_mul_ps(ceil_vec, ceil_vec);\n        __m128i high_half = _mm256_castps_si256(_mm256_extractf128_ps(squared_vec, 1));\n        __m128i low_half = _mm256_castps_si256(_mm256_castps256_ps128(squared_vec));\n        __m128i sum_half = _mm_add_epi32(low_half, high_half);\n        __m128i sum_quarter = _mm_add_epi32(sum_half, _mm_shuffle_epi32(sum_half, _MM_SHUFFLE(2, 3, 0, 1)));\n        __m128i sum_eighth = _mm_add_epi32(sum_quarter, _mm_shuffle_epi32(sum_quarter, _MM_SHUFFLE(1, 0, 3, 2)));\n        sum += _mm_cvtsi128_si32(sum_eighth);\n    }\n\n    // Process remaining elements\n    for (; i < n; ++i) {\n        int ceil_val = static_cast<int>(std::ceil(lst[i]));\n        sum += static_cast<uint64_t>(ceil_val) * ceil_val;\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_126_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nuint64_t sum_squares_simd(const std::vector<float> & lst){\n    uint64_t sum = 0;\n    size_t n = lst.size();\n    size_t i = 0;\n\n    __m256 vsum = _mm256_setzero_ps();\n\n    for (; i <= n - 8; i += 8) {\n        __m256 v = _mm256_loadu_ps(&lst[i]);\n        __m256 vceil = _mm256_ceil_ps(v);\n        __m256 vsquared = _mm256_mul_ps(vceil, vceil);\n        vsum = _mm256_add_ps(vsum, vsquared);\n    }\n\n    float sum_array[8];\n    _mm256_storeu_ps(sum_array, vsum);\n\n    for (size_t j = 0; j < 8; ++j) {\n        sum += static_cast<uint64_t>(sum_array[j]);\n    }\n\n    for (; i < n; ++i) {\n        int64_t ceil_val = static_cast<int64_t>(std::ceil(lst[i]));\n        sum += ceil_val * ceil_val;\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_127_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint can_arrange_simd(const std::vector<int> & arr) {\n    int n = arr.size();\n    if (n < 2) return -1;\n\n    __m256i indices = _mm256_set_epi32(7, 6, 5, 4, 3, 2, 1, 0);\n    __m256i max_index = _mm256_set1_epi32(-1);\n    __m256i prev_values;\n    __m256i curr_values;\n    __m256i mask;\n\n    int i = 0;\n    for (; i <= n - 8; i += 8) {\n        prev_values = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&arr[i]));\n        curr_values = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&arr[i + 1]));\n\n        mask = _mm256_cmpgt_epi32(curr_values, prev_values);\n        mask = _mm256_andnot_si256(mask, indices);\n\n        max_index = _mm256_max_epi32(max_index, mask);\n\n        indices = _mm256_add_epi32(indices, _mm256_set1_epi32(8));\n    }\n\n    int result[8];\n    _mm256_storeu_si256(reinterpret_cast<__m256i*>(result), max_index);\n\n    int max_idx = -1;\n    for (int j = 0; j < 8; ++j) {\n        max_idx = std::max(max_idx, result[j]);\n    }\n\n    for (; i < n - 1; ++i) {\n        if (arr[i + 1] < arr[i]) {\n            max_idx = i + 1;\n        }\n    }\n\n    return max_idx;\n}\n```"}
{"task_id": "SimdBench_127_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint can_arrange_simd(const std::vector<int> & arr) {\n    int n = arr.size();\n    if (n < 2) return -1;\n\n    __m256i prev = _mm256_set1_epi32(arr[0]);\n    __m256i indices = _mm256_setr_epi32(1, 2, 3, 4, 5, 6, 7, 8);\n    __m256i result = _mm256_set1_epi32(-1);\n    int max_index = -1;\n\n    for (int i = 1; i < n; i += 8) {\n        __m256i current = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&arr[i]));\n        __m256i mask = _mm256_cmpgt_epi32(current, prev);\n\n        int mask_val = _mm256_movemask_epi8(mask);\n        if (mask_val != 0) {\n            for (int j = 0; j < 8 && (i + j) < n; ++j) {\n                if ((mask_val >> (4 * j)) & 0xF) {\n                    max_index = i + j - 1;\n                }\n            }\n        }\n\n        prev = current;\n        indices = _mm256_add_epi32(indices, _mm256_set1_epi32(8));\n    }\n\n    return max_index;\n}\n```"}
{"task_id": "SimdBench_127_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint can_arrange_simd(const std::vector<int> & arr){\n    int n = arr.size();\n    if (n < 2) return -1;\n\n    __m256i indices = _mm256_set_epi32(7, 6, 5, 4, 3, 2, 1, 0);\n    __m256i result = _mm256_set1_epi32(-1);\n    __m256i max_index = _mm256_set1_epi32(-1);\n\n    for (int i = 0; i <= n - 8; i += 8) {\n        __m256i vec1 = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&arr[i]));\n        __m256i vec2 = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&arr[i + 1]));\n\n        __m256i cmp = _mm256_cmpgt_epi32(vec2, vec1);\n        __m256i mask = _mm256_andnot_si256(cmp, _mm256_cmpeq_epi32(cmp, cmp));\n\n        __m256i masked_indices = _mm256_and_si256(indices, mask);\n        __m256i max_masked_indices = _mm256_max_epi32(masked_indices, max_index);\n        max_index = max_masked_indices;\n\n        indices = _mm256_add_epi32(indices, _mm256_set1_epi32(8));\n    }\n\n    int max_index_array[8];\n    _mm256_storeu_si256(reinterpret_cast<__m256i*>(max_index_array), max_index);\n\n    int max_val = -1;\n    for (int i = 0; i < 8; ++i) {\n        if (max_index_array[i] > max_val) {\n            max_val = max_index_array[i];\n        }\n    }\n\n    for (int i = (n / 8) * 8; i < n - 1; ++i) {\n        if (arr[i + 1] < arr[i]) {\n            max_val = i + 1;\n        }\n    }\n\n    return max_val;\n}\n```"}
{"task_id": "SimdBench_127_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint can_arrange_simd(const std::vector<int> & arr){\n    int n = arr.size();\n    if (n < 2) return -1;\n\n    __m256i prev = _mm256_set1_epi32(arr[0]);\n    __m256i indices = _mm256_setr_epi32(1, 2, 3, 4, 5, 6, 7, 8);\n    __m256i max_index = _mm256_set1_epi32(-1);\n\n    for (int i = 1; i <= n - 8; i += 8) {\n        __m256i current = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&arr[i]));\n        __m256i mask = _mm256_cmpgt_epi32(current, prev);\n        mask = _mm256_andnot_si256(mask, _mm256_cmpeq_epi32(mask, mask)); // Invert mask\n        __m256i valid_indices = _mm256_and_si256(indices, mask);\n        max_index = _mm256_max_epi32(max_index, valid_indices);\n        prev = current;\n        indices = _mm256_add_epi32(indices, _mm256_set1_epi32(8));\n    }\n\n    int result[8];\n    _mm256_storeu_si256(reinterpret_cast<__m256i*>(result), max_index);\n\n    int max_idx = -1;\n    for (int i = 0; i < 8; ++i) {\n        max_idx = std::max(max_idx, result[i]);\n    }\n\n    for (int i = (n / 8) * 8; i < n; ++i) {\n        if (arr[i] < arr[i - 1]) {\n            max_idx = i;\n        }\n    }\n\n    return max_idx;\n}\n```"}
{"task_id": "SimdBench_127_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint can_arrange_simd(const std::vector<int> & arr) {\n    int n = arr.size();\n    if (n < 2) return -1;\n\n    __m256i indices = _mm256_set_epi32(7, 6, 5, 4, 3, 2, 1, 0);\n    __m256i max_index = _mm256_set1_epi32(-1);\n    __m256i offset = _mm256_set1_epi32(8);\n\n    for (int i = 0; i <= n - 8; i += 8) {\n        __m256i vec1 = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&arr[i]));\n        __m256i vec2 = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&arr[i + 1]));\n\n        __m256i cmp = _mm256_cmpgt_epi32(vec2, vec1);\n        __m256i not_cmp = _mm256_andnot_si256(cmp, _mm256_cmpeq_epi32(cmp, cmp));\n\n        __m256i valid_indices = _mm256_add_epi32(indices, _mm256_set1_epi32(i));\n        __m256i masked_indices = _mm256_and_si256(valid_indices, not_cmp);\n\n        max_index = _mm256_max_epi32(max_index, masked_indices);\n\n        indices = _mm256_add_epi32(indices, offset);\n    }\n\n    int result[8];\n    _mm256_storeu_si256(reinterpret_cast<__m256i*>(result), max_index);\n\n    int max_idx = -1;\n    for (int i = 0; i < 8; ++i) {\n        max_idx = std::max(max_idx, result[i]);\n    }\n\n    // Check remaining elements\n    for (int i = (n / 8) * 8; i < n - 1; ++i) {\n        if (arr[i + 1] < arr[i]) {\n            max_idx = i + 1;\n        }\n    }\n\n    return max_idx;\n}\n```"}
{"task_id": "SimdBench_128_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <limits>\n\nstd::vector<int> largest_smallest_integers_simd(const std::vector<int>& lst) {\n    if (lst.empty()) {\n        return {0, 0};\n    }\n\n    __m256i max_neg = _mm256_set1_epi32(std::numeric_limits<int>::min());\n    __m256i min_pos = _mm256_set1_epi32(std::numeric_limits<int>::max());\n\n    size_t i = 0;\n    for (; i + 8 <= lst.size(); i += 8) {\n        __m256i vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&lst[i]));\n\n        __m256i neg_mask = _mm256_cmpgt_epi32(_mm256_setzero_si256(), vec);\n        __m256i pos_mask = _mm256_cmpgt_epi32(vec, _mm256_setzero_si256());\n\n        __m256i neg_vec = _mm256_blendv_epi8(max_neg, vec, neg_mask);\n        __m256i pos_vec = _mm256_blendv_epi8(min_pos, vec, pos_mask);\n\n        max_neg = _mm256_max_epi32(max_neg, neg_vec);\n        min_pos = _mm256_min_epi32(min_pos, pos_vec);\n    }\n\n    int max_neg_arr[8], min_pos_arr[8];\n    _mm256_storeu_si256(reinterpret_cast<__m256i*>(max_neg_arr), max_neg);\n    _mm256_storeu_si256(reinterpret_cast<__m256i*>(min_pos_arr), min_pos);\n\n    int largest_neg = std::numeric_limits<int>::min();\n    int smallest_pos = std::numeric_limits<int>::max();\n\n    for (int j = 0; j < 8; ++j) {\n        if (max_neg_arr[j] > largest_neg && max_neg_arr[j] < 0) {\n            largest_neg = max_neg_arr[j];\n        }\n        if (min_pos_arr[j] < smallest_pos && min_pos_arr[j] > 0) {\n            smallest_pos = min_pos_arr[j];\n        }\n    }\n\n    for (; i < lst.size(); ++i) {\n        if (lst[i] < 0 && lst[i] > largest_neg) {\n            largest_neg = lst[i];\n        }\n        if (lst[i] > 0 && lst[i] < smallest_pos) {\n            smallest_pos = lst[i];\n        }\n    }\n\n    if (largest_neg == std::numeric_limits<int>::min()) {\n        largest_neg = 0;\n    }\n    if (smallest_pos == std::numeric_limits<int>::max()) {\n        smallest_pos = 0;\n    }\n\n    return {largest_neg, smallest_pos};\n}\n```"}
{"task_id": "SimdBench_128_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <limits>\n\nstd::vector<int> largest_smallest_integers_simd(const std::vector<int>& lst) {\n    if (lst.empty()) {\n        return {0, 0};\n    }\n\n    __m256i max_neg = _mm256_set1_epi32(std::numeric_limits<int>::min());\n    __m256i min_pos = _mm256_set1_epi32(std::numeric_limits<int>::max());\n\n    size_t i = 0;\n    for (; i + 8 <= lst.size(); i += 8) {\n        __m256i vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&lst[i]));\n\n        __m256i neg_mask = _mm256_cmpgt_epi32(_mm256_setzero_si256(), vec);\n        __m256i pos_mask = _mm256_cmpgt_epi32(vec, _mm256_setzero_si256());\n\n        __m256i neg_vals = _mm256_blendv_epi8(max_neg, vec, neg_mask);\n        __m256i pos_vals = _mm256_blendv_epi8(min_pos, vec, pos_mask);\n\n        max_neg = _mm256_max_epi32(max_neg, neg_vals);\n        min_pos = _mm256_min_epi32(min_pos, pos_vals);\n    }\n\n    int max_neg_arr[8], min_pos_arr[8];\n    _mm256_storeu_si256(reinterpret_cast<__m256i*>(max_neg_arr), max_neg);\n    _mm256_storeu_si256(reinterpret_cast<__m256i*>(min_pos_arr), min_pos);\n\n    int final_max_neg = std::numeric_limits<int>::min();\n    int final_min_pos = std::numeric_limits<int>::max();\n\n    for (size_t j = 0; j < 8; ++j) {\n        if (max_neg_arr[j] > final_max_neg && max_neg_arr[j] < 0) {\n            final_max_neg = max_neg_arr[j];\n        }\n        if (min_pos_arr[j] < final_min_pos && min_pos_arr[j] > 0) {\n            final_min_pos = min_pos_arr[j];\n        }\n    }\n\n    for (; i < lst.size(); ++i) {\n        if (lst[i] < 0 && lst[i] > final_max_neg) {\n            final_max_neg = lst[i];\n        }\n        if (lst[i] > 0 && lst[i] < final_min_pos) {\n            final_min_pos = lst[i];\n        }\n    }\n\n    if (final_max_neg == std::numeric_limits<int>::min()) {\n        final_max_neg = 0;\n    }\n    if (final_min_pos == std::numeric_limits<int>::max()) {\n        final_min_pos = 0;\n    }\n\n    return {final_max_neg, final_min_pos};\n}\n```"}
{"task_id": "SimdBench_128_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <limits>\n\nstd::vector<int> largest_smallest_integers_simd(const std::vector<int>& lst) {\n    if (lst.empty()) {\n        return {0, 0};\n    }\n\n    __m256i max_neg = _mm256_set1_epi32(std::numeric_limits<int>::min());\n    __m256i min_pos = _mm256_set1_epi32(std::numeric_limits<int>::max());\n\n    size_t i = 0;\n    for (; i + 8 <= lst.size(); i += 8) {\n        __m256i vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&lst[i]));\n\n        __m256i neg_mask = _mm256_cmpgt_epi32(_mm256_setzero_si256(), vec);\n        __m256i pos_mask = _mm256_cmpgt_epi32(vec, _mm256_setzero_si256());\n\n        __m256i neg_vals = _mm256_blendv_epi8(max_neg, vec, neg_mask);\n        __m256i pos_vals = _mm256_blendv_epi8(min_pos, vec, pos_mask);\n\n        max_neg = _mm256_max_epi32(max_neg, neg_vals);\n        min_pos = _mm256_min_epi32(min_pos, pos_vals);\n    }\n\n    int max_neg_arr[8], min_pos_arr[8];\n    _mm256_storeu_si256(reinterpret_cast<__m256i*>(max_neg_arr), max_neg);\n    _mm256_storeu_si256(reinterpret_cast<__m256i*>(min_pos_arr), min_pos);\n\n    int largest_neg = std::numeric_limits<int>::min();\n    int smallest_pos = std::numeric_limits<int>::max();\n\n    for (int j = 0; j < 8; ++j) {\n        if (max_neg_arr[j] > largest_neg && max_neg_arr[j] < 0) {\n            largest_neg = max_neg_arr[j];\n        }\n        if (min_pos_arr[j] < smallest_pos && min_pos_arr[j] > 0) {\n            smallest_pos = min_pos_arr[j];\n        }\n    }\n\n    for (; i < lst.size(); ++i) {\n        if (lst[i] < 0 && lst[i] > largest_neg) {\n            largest_neg = lst[i];\n        }\n        if (lst[i] > 0 && lst[i] < smallest_pos) {\n            smallest_pos = lst[i];\n        }\n    }\n\n    if (largest_neg == std::numeric_limits<int>::min()) {\n        largest_neg = 0;\n    }\n    if (smallest_pos == std::numeric_limits<int>::max()) {\n        smallest_pos = 0;\n    }\n\n    return {largest_neg, smallest_pos};\n}\n```"}
{"task_id": "SimdBench_128_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <vector>\n#include <limits>\n\nstd::vector<int> largest_smallest_integers_simd(const std::vector<int>& lst) {\n    if (lst.empty()) {\n        return {0, 0};\n    }\n\n    __m256i max_neg = _mm256_set1_epi32(std::numeric_limits<int>::min());\n    __m256i min_pos = _mm256_set1_epi32(std::numeric_limits<int>::max());\n\n    size_t i = 0;\n    for (; i + 8 <= lst.size(); i += 8) {\n        __m256i vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&lst[i]));\n\n        __m256i neg_mask = _mm256_cmpgt_epi32(_mm256_setzero_si256(), vec);\n        __m256i pos_mask = _mm256_cmpgt_epi32(vec, _mm256_setzero_si256());\n\n        __m256i neg_vals = _mm256_blendv_epi8(max_neg, vec, neg_mask);\n        __m256i pos_vals = _mm256_blendv_epi8(min_pos, vec, pos_mask);\n\n        max_neg = _mm256_max_epi32(max_neg, neg_vals);\n        min_pos = _mm256_min_epi32(min_pos, pos_vals);\n    }\n\n    int max_neg_arr[8], min_pos_arr[8];\n    _mm256_storeu_si256(reinterpret_cast<__m256i*>(max_neg_arr), max_neg);\n    _mm256_storeu_si256(reinterpret_cast<__m256i*>(min_pos_arr), min_pos);\n\n    int final_max_neg = std::numeric_limits<int>::min();\n    int final_min_pos = std::numeric_limits<int>::max();\n\n    for (int j = 0; j < 8; ++j) {\n        if (max_neg_arr[j] > final_max_neg && max_neg_arr[j] < 0) {\n            final_max_neg = max_neg_arr[j];\n        }\n        if (min_pos_arr[j] < final_min_pos && min_pos_arr[j] > 0) {\n            final_min_pos = min_pos_arr[j];\n        }\n    }\n\n    for (; i < lst.size(); ++i) {\n        if (lst[i] < 0 && lst[i] > final_max_neg) {\n            final_max_neg = lst[i];\n        }\n        if (lst[i] > 0 && lst[i] < final_min_pos) {\n            final_min_pos = lst[i];\n        }\n    }\n\n    if (final_max_neg == std::numeric_limits<int>::min()) {\n        final_max_neg = 0;\n    }\n    if (final_min_pos == std::numeric_limits<int>::max()) {\n        final_min_pos = 0;\n    }\n\n    return {final_max_neg, final_min_pos};\n}\n```"}
{"task_id": "SimdBench_128_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <limits>\n\nstd::vector<int> largest_smallest_integers_simd(const std::vector<int>& lst) {\n    if (lst.empty()) {\n        return {0, 0};\n    }\n\n    __m256i max_neg = _mm256_set1_epi32(std::numeric_limits<int>::min());\n    __m256i min_pos = _mm256_set1_epi32(std::numeric_limits<int>::max());\n\n    size_t i = 0;\n    for (; i + 8 <= lst.size(); i += 8) {\n        __m256i vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&lst[i]));\n\n        __m256i neg_mask = _mm256_cmpgt_epi32(_mm256_setzero_si256(), vec);\n        __m256i pos_mask = _mm256_cmpgt_epi32(vec, _mm256_setzero_si256());\n\n        __m256i neg_vec = _mm256_blendv_epi8(max_neg, vec, neg_mask);\n        __m256i pos_vec = _mm256_blendv_epi8(min_pos, vec, pos_mask);\n\n        max_neg = _mm256_max_epi32(max_neg, neg_vec);\n        min_pos = _mm256_min_epi32(min_pos, pos_vec);\n    }\n\n    int max_neg_arr[8], min_pos_arr[8];\n    _mm256_storeu_si256(reinterpret_cast<__m256i*>(max_neg_arr), max_neg);\n    _mm256_storeu_si256(reinterpret_cast<__m256i*>(min_pos_arr), min_pos);\n\n    int largest_neg = std::numeric_limits<int>::min();\n    int smallest_pos = std::numeric_limits<int>::max();\n\n    for (int j = 0; j < 8; ++j) {\n        if (max_neg_arr[j] > largest_neg && max_neg_arr[j] < 0) {\n            largest_neg = max_neg_arr[j];\n        }\n        if (min_pos_arr[j] < smallest_pos && min_pos_arr[j] > 0) {\n            smallest_pos = min_pos_arr[j];\n        }\n    }\n\n    for (; i < lst.size(); ++i) {\n        if (lst[i] < 0 && lst[i] > largest_neg) {\n            largest_neg = lst[i];\n        }\n        if (lst[i] > 0 && lst[i] < smallest_pos) {\n            smallest_pos = lst[i];\n        }\n    }\n\n    if (largest_neg == std::numeric_limits<int>::min()) {\n        largest_neg = 0;\n    }\n    if (smallest_pos == std::numeric_limits<int>::max()) {\n        smallest_pos = 0;\n    }\n\n    return {largest_neg, smallest_pos};\n}\n```"}
{"task_id": "SimdBench_129_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nuint64_t special_factorial_simd(uint64_t n) {\n    if (n == 0) return 1;\n\n    __m256i factorials = _mm256_set1_epi64x(1);\n    __m256i ones = _mm256_set1_epi64x(1);\n    __m256i indices = _mm256_setr_epi64x(1, 2, 3, 4);\n\n    while (indices[0] <= n) {\n        __m256i current_factorials = factorials;\n        for (int i = 0; i < 4 && indices[i] <= n; ++i) {\n            for (uint64_t j = indices[i] + 1; j <= n; ++j) {\n                current_factorials = _mm256_mullo_epi64(current_factorials, _mm256_set1_epi64x(j));\n            }\n        }\n        factorials = _mm256_mullo_epi64(factorials, current_factorials);\n        indices = _mm256_add_epi64(indices, _mm256_set1_epi64x(4));\n    }\n\n    uint64_t result[4];\n    _mm256_storeu_si256((__m256i*)result, factorials);\n\n    return result[0] * result[1] * result[2] * result[3];\n}\n```"}
{"task_id": "SimdBench_129_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nuint64_t special_factorial_simd(uint64_t n) {\n    if (n == 0) return 1;\n\n    __m256i factorials = _mm256_set1_epi64x(1);\n    __m256i ones = _mm256_set1_epi64x(1);\n    __m256i indices = _mm256_setr_epi64x(1, 2, 3, 4);\n\n    while (indices[0] <= n) {\n        __m256i current_factorials = factorials;\n        for (int i = 0; i < 4 && indices[i] <= n; ++i) {\n            for (uint64_t j = indices[i] + 1; j <= n; ++j) {\n                current_factorials = _mm256_mullo_epi64(current_factorials, _mm256_set1_epi64x(j));\n            }\n        }\n        factorials = _mm256_mullo_epi64(factorials, current_factorials);\n        indices = _mm256_add_epi64(indices, _mm256_set1_epi64x(4));\n    }\n\n    uint64_t result[4];\n    _mm256_storeu_si256((__m256i*)result, factorials);\n\n    return result[0] * result[1] * result[2] * result[3];\n}\n```"}
{"task_id": "SimdBench_129_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nuint64_t special_factorial_simd(uint64_t n) {\n    if (n == 0) return 1;\n\n    __m256i factorials = _mm256_set1_epi64x(1);\n    __m256i ones = _mm256_set1_epi64x(1);\n    __m256i indices = _mm256_setr_epi64x(1, 2, 3, 4);\n\n    while (indices[0] <= n) {\n        __m256i current_factorials = factorials;\n        for (int i = 1; i < indices[0]; ++i) {\n            current_factorials = _mm256_mullo_epi64(current_factorials, indices);\n        }\n        factorials = _mm256_mullo_epi64(factorials, current_factorials);\n\n        indices = _mm256_add_epi64(indices, ones);\n    }\n\n    uint64_t result[4];\n    _mm256_storeu_si256((__m256i*)result, factorials);\n\n    return result[0] * result[1] * result[2] * result[3];\n}\n```"}
{"task_id": "SimdBench_129_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nuint64_t special_factorial_simd(uint64_t n) {\n    if (n == 0) return 1;\n\n    __m256i factorials = _mm256_set1_epi64x(1);\n    __m256i ones = _mm256_set1_epi64x(1);\n    __m256i indices = _mm256_setr_epi64x(1, 2, 3, 4);\n\n    while (indices[0] <= n) {\n        __m256i current_factorials = factorials;\n        for (int i = 0; i < 4 && indices[i] <= n; ++i) {\n            for (uint64_t j = indices[i] + 1; j <= n; ++j) {\n                current_factorials = _mm256_mullo_epi64(current_factorials, _mm256_set1_epi64x(j));\n            }\n        }\n        factorials = _mm256_mullo_epi64(factorials, current_factorials);\n        indices = _mm256_add_epi64(indices, _mm256_set1_epi64x(4));\n    }\n\n    uint64_t result[4];\n    _mm256_storeu_si256((__m256i*)result, factorials);\n\n    return result[0] * result[1] * result[2] * result[3];\n}\n```"}
{"task_id": "SimdBench_129_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nuint64_t special_factorial_simd(uint64_t n) {\n    if (n == 0) return 1;\n\n    __m256i factorials = _mm256_set1_epi64x(1);\n    __m256i ones = _mm256_set1_epi64x(1);\n    __m256i indices = _mm256_setr_epi64x(1, 2, 3, 4);\n\n    while (indices[0] <= n) {\n        __m256i current_factorials = factorials;\n        for (int i = 0; i < 4 && indices[i] <= n; ++i) {\n            for (uint64_t j = indices[i] + 1; j <= n; ++j) {\n                current_factorials = _mm256_mullo_epi64(current_factorials, _mm256_set1_epi64x(j));\n            }\n        }\n        factorials = _mm256_mullo_epi64(factorials, current_factorials);\n        indices = _mm256_add_epi64(indices, _mm256_set1_epi64x(4));\n    }\n\n    uint64_t result[4];\n    _mm256_storeu_si256((__m256i*)result, factorials);\n\n    return result[0] * result[1] * result[2] * result[3];\n}\n```"}
{"task_id": "SimdBench_130_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint sum_squares_simd(const std::vector<int> & lst) {\n    int sum = 0;\n    int n = lst.size();\n    int i = 0;\n\n    __m256i sum_vec = _mm256_setzero_si256();\n\n    for (; i <= n - 8; i += 8) {\n        __m256i vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&lst[i]));\n\n        __m256i indices = _mm256_set_epi32(i + 7, i + 6, i + 5, i + 4, i + 3, i + 2, i + 1, i);\n        __m256i multiples_of_3 = _mm256_cmpeq_epi32(_mm256_and_si256(indices, _mm256_set1_epi32(3)), _mm256_setzero_si256());\n        __m256i multiples_of_4_not_3 = _mm256_andnot_si256(multiples_of_3, _mm256_cmpeq_epi32(_mm256_and_si256(indices, _mm256_set1_epi32(4)), _mm256_setzero_si256()));\n\n        __m256i squares = _mm256_mullo_epi32(vec, vec);\n        __m256i cubes = _mm256_mullo_epi32(squares, vec);\n\n        __m256i result = _mm256_blendv_epi8(vec, squares, multiples_of_3);\n        result = _mm256_blendv_epi8(result, cubes, multiples_of_4_not_3);\n\n        sum_vec = _mm256_add_epi32(sum_vec, result);\n    }\n\n    int temp_sum[8];\n    _mm256_storeu_si256(reinterpret_cast<__m256i*>(temp_sum), sum_vec);\n    sum = temp_sum[0] + temp_sum[1] + temp_sum[2] + temp_sum[3] + temp_sum[4] + temp_sum[5] + temp_sum[6] + temp_sum[7];\n\n    for (; i < n; ++i) {\n        if (i % 3 == 0) {\n            sum += lst[i] * lst[i];\n        } else if (i % 4 == 0) {\n            sum += lst[i] * lst[i] * lst[i];\n        } else {\n            sum += lst[i];\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_130_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint sum_squares_simd(const std::vector<int> & lst) {\n    int n = lst.size();\n    if (n == 0) return 0;\n\n    __m256i sum = _mm256_setzero_si256();\n    int i = 0;\n\n    for (; i <= n - 8; i += 8) {\n        __m256i vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&lst[i]));\n        __m256i indices = _mm256_set_epi32(i + 7, i + 6, i + 5, i + 4, i + 3, i + 2, i + 1, i);\n        \n        __m256i multiples_of_3 = _mm256_and_si256(_mm256_cmpeq_epi32(_mm256_and_si256(indices, _mm256_set1_epi32(3)), _mm256_setzero_si256()), vec);\n        __m256i multiples_of_4_not_3 = _mm256_andnot_si256(multiples_of_3, _mm256_and_si256(_mm256_cmpeq_epi32(_mm256_and_si256(indices, _mm256_set1_epi32(4)), _mm256_setzero_si256()), vec));\n\n        multiples_of_3 = _mm256_mullo_epi32(multiples_of_3, multiples_of_3);\n        multiples_of_4_not_3 = _mm256_mullo_epi32(multiples_of_4_not_3, _mm256_mullo_epi32(multiples_of_4_not_3, multiples_of_4_not_3));\n\n        vec = _mm256_blendv_epi8(vec, multiples_of_3, _mm256_cmpgt_epi32(multiples_of_3, _mm256_setzero_si256()));\n        vec = _mm256_blendv_epi8(vec, multiples_of_4_not_3, _mm256_cmpgt_epi32(multiples_of_4_not_3, _mm256_setzero_si256()));\n\n        sum = _mm256_add_epi32(sum, vec);\n    }\n\n    int total_sum = 0;\n    int temp[8];\n    _mm256_storeu_si256(reinterpret_cast<__m256i*>(temp), sum);\n    for (int j = 0; j < 8; ++j) {\n        total_sum += temp[j];\n    }\n\n    for (; i < n; ++i) {\n        if (i % 3 == 0) {\n            total_sum += lst[i] * lst[i];\n        } else if (i % 4 == 0) {\n            total_sum += lst[i] * lst[i] * lst[i];\n        } else {\n            total_sum += lst[i];\n        }\n    }\n\n    return total_sum;\n}\n```"}
{"task_id": "SimdBench_130_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint sum_squares_simd(const std::vector<int> & lst) {\n    int n = lst.size();\n    if (n == 0) return 0;\n\n    __m256i sum = _mm256_setzero_si256();\n    int i = 0;\n\n    for (; i <= n - 8; i += 8) {\n        __m256i vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&lst[i]));\n        __m256i indices = _mm256_set_epi32(i + 7, i + 6, i + 5, i + 4, i + 3, i + 2, i + 1, i);\n        \n        __m256i multiples_of_3 = _mm256_cmpeq_epi32(_mm256_and_si256(indices, _mm256_set1_epi32(3)), _mm256_setzero_si256());\n        __m256i multiples_of_4_not_3 = _mm256_andnot_si256(multiples_of_3, _mm256_cmpeq_epi32(_mm256_and_si256(indices, _mm256_set1_epi32(4)), _mm256_setzero_si256()));\n\n        __m256i squares = _mm256_mullo_epi32(vec, vec);\n        __m256i cubes = _mm256_mullo_epi32(squares, vec);\n\n        __m256i result = _mm256_blendv_epi8(vec, squares, multiples_of_3);\n        result = _mm256_blendv_epi8(result, cubes, multiples_of_4_not_3);\n\n        sum = _mm256_add_epi32(sum, result);\n    }\n\n    int total_sum = 0;\n    int temp[8];\n    _mm256_storeu_si256(reinterpret_cast<__m256i*>(temp), sum);\n    for (int j = 0; j < 8; ++j) {\n        total_sum += temp[j];\n    }\n\n    for (; i < n; ++i) {\n        if (i % 3 == 0) {\n            total_sum += lst[i] * lst[i];\n        } else if (i % 4 == 0) {\n            total_sum += lst[i] * lst[i] * lst[i];\n        } else {\n            total_sum += lst[i];\n        }\n    }\n\n    return total_sum;\n}\n```"}
{"task_id": "SimdBench_130_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint sum_squares_simd(const std::vector<int> & lst) {\n    int n = lst.size();\n    if (n == 0) return 0;\n\n    __m256i sum = _mm256_setzero_si256();\n    int i = 0;\n\n    for (; i <= n - 8; i += 8) {\n        __m256i vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&lst[i]));\n        __m256i indices = _mm256_setr_epi32(i, i + 1, i + 2, i + 3, i + 4, i + 5, i + 6, i + 7);\n        \n        __m256i multiples_of_3 = _mm256_cmpeq_epi32(_mm256_and_si256(indices, _mm256_set1_epi32(3)), _mm256_setzero_si256());\n        __m256i multiples_of_4_not_3 = _mm256_andnot_si256(multiples_of_3, _mm256_cmpeq_epi32(_mm256_and_si256(indices, _mm256_set1_epi32(4)), _mm256_setzero_si256()));\n\n        __m256i squares = _mm256_mullo_epi32(vec, vec);\n        __m256i cubes = _mm256_mullo_epi32(squares, vec);\n\n        __m256i result = _mm256_blendv_epi8(squares, cubes, multiples_of_4_not_3);\n        result = _mm256_blendv_epi8(result, vec, _mm256_or_si256(multiples_of_3, multiples_of_4_not_3));\n\n        sum = _mm256_add_epi32(sum, result);\n    }\n\n    int total_sum = 0;\n    int temp[8];\n    _mm256_storeu_si256(reinterpret_cast<__m256i*>(temp), sum);\n    for (int j = 0; j < 8; ++j) {\n        total_sum += temp[j];\n    }\n\n    for (; i < n; ++i) {\n        if (i % 3 == 0) {\n            total_sum += lst[i] * lst[i];\n        } else if (i % 4 == 0) {\n            total_sum += lst[i] * lst[i] * lst[i];\n        } else {\n            total_sum += lst[i];\n        }\n    }\n\n    return total_sum;\n}\n```"}
{"task_id": "SimdBench_130_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint sum_squares_simd(const std::vector<int> & lst) {\n    int n = lst.size();\n    if (n == 0) return 0;\n\n    __m256i sum = _mm256_setzero_si256();\n    int i = 0;\n\n    for (; i <= n - 8; i += 8) {\n        __m256i vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&lst[i]));\n        __m256i indices = _mm256_setr_epi32(i, i+1, i+2, i+3, i+4, i+5, i+6, i+7);\n        __m256i multiples_of_3 = _mm256_cmpeq_epi32(_mm256_and_si256(indices, _mm256_set1_epi32(3)), _mm256_setzero_si256());\n        __m256i multiples_of_4_not_3 = _mm256_andnot_si256(multiples_of_3, _mm256_cmpeq_epi32(_mm256_and_si256(indices, _mm256_set1_epi32(4)), _mm256_setzero_si256()));\n\n        __m256i squares = _mm256_mullo_epi32(vec, vec);\n        __m256i cubes = _mm256_mullo_epi32(squares, vec);\n\n        __m256i result = _mm256_blendv_epi8(vec, squares, multiples_of_3);\n        result = _mm256_blendv_epi8(result, cubes, multiples_of_4_not_3);\n\n        sum = _mm256_add_epi32(sum, result);\n    }\n\n    int total_sum[8];\n    _mm256_storeu_si256(reinterpret_cast<__m256i*>(total_sum), sum);\n\n    for (; i < n; ++i) {\n        if (i % 3 == 0) {\n            total_sum[0] += lst[i] * lst[i];\n        } else if (i % 4 == 0) {\n            total_sum[0] += lst[i] * lst[i] * lst[i];\n        } else {\n            total_sum[0] += lst[i];\n        }\n    }\n\n    return total_sum[0] + total_sum[1] + total_sum[2] + total_sum[3] + total_sum[4] + total_sum[5] + total_sum[6] + total_sum[7];\n}\n```"}
{"task_id": "SimdBench_131_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint specialFilter_simd(const std::vector<int> & nums){\n    int count = 0;\n    int n = nums.size();\n    const int* data = nums.data();\n\n    __m256i ten = _mm256_set1_epi32(10);\n    __m256i odd_mask = _mm256_set1_epi32(0x1);\n    __m256i first_last_odd_mask = _mm256_set1_epi32(0x101);\n\n    for (int i = 0; i <= n - 8; i += 8) {\n        __m256i vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(data + i));\n\n        // Check if greater than 10\n        __m256i gt_ten = _mm256_cmpgt_epi32(vec, ten);\n\n        // Extract first and last digits\n        __m256i abs_vec = _mm256_abs_epi32(vec);\n        __m256i last_digit = _mm256_and_si256(abs_vec, odd_mask);\n        __m256i first_digit = _mm256_cvtepi32_epi64(_mm256_srli_epi32(abs_vec, 28));\n        first_digit = _mm256_and_si256(first_digit, odd_mask);\n\n        // Check if both first and last digits are odd\n        __m256i first_last_odd = _mm256_and_si256(last_digit, first_digit);\n        first_last_odd = _mm256_cmpeq_epi32(first_last_odd, odd_mask);\n\n        // Combine conditions\n        __m256i result = _mm256_and_si256(gt_ten, first_last_odd);\n\n        // Count true values\n        int mask = _mm256_movemask_epi8(result);\n        count += __builtin_popcount(mask) / 4;\n    }\n\n    // Handle remaining elements\n    for (int i = (n / 8) * 8; i < n; ++i) {\n        int num = nums[i];\n        if (num > 10) {\n            int abs_num = std::abs(num);\n            int last_digit = abs_num % 10;\n            int first_digit = abs_num;\n            while (first_digit >= 10) {\n                first_digit /= 10;\n            }\n            if ((last_digit % 2 != 0) && (first_digit % 2 != 0)) {\n                count++;\n            }\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_131_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint specialFilter_simd(const std::vector<int> & nums){\n    int count = 0;\n    int n = nums.size();\n    const int* data = nums.data();\n    __m256i ten = _mm256_set1_epi32(10);\n    __m256i odd_digits = _mm256_set1_epi32(0x101); // Mask to check if first and last digits are odd\n    __m256i mask = _mm256_setzero_si256();\n\n    for (int i = 0; i <= n - 8; i += 8) {\n        __m256i vec = _mm256_loadu_si256((__m256i const*)(data + i));\n        __m256i gt_ten = _mm256_cmpgt_epi32(vec, ten);\n        __m256i abs_vec = _mm256_abs_epi32(vec);\n        __m256i last_digit_odd = _mm256_test_epi32(abs_vec, odd_digits);\n        __m256i first_last_odd = _mm256_and_si256(gt_ten, last_digit_odd);\n        mask = _mm256_or_si256(mask, first_last_odd);\n    }\n\n    int mask_result = _mm256_movemask_epi8(mask);\n    count += __builtin_popcount(mask_result) / 4;\n\n    for (int i = (n / 8) * 8; i < n; ++i) {\n        int num = nums[i];\n        int abs_num = std::abs(num);\n        if (num > 10 && (abs_num % 10) % 2 == 1 && (abs_num / 100000000) % 2 == 1) {\n            count++;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_131_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint specialFilter_simd(const std::vector<int> & nums){\n    int count = 0;\n    int n = nums.size();\n    const int* data = nums.data();\n\n    __m256i ten = _mm256_set1_epi32(10);\n    __m256i odd_digits = _mm256_set1_epi32(0x101); // Mask to check first and last digits\n    __m256i odd_mask = _mm256_set1_epi32(0x55555555); // Mask to isolate odd digits\n\n    for (int i = 0; i <= n - 8; i += 8) {\n        __m256i vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(data + i));\n        __m256i gt_ten = _mm256_cmpgt_epi32(vec, ten);\n\n        __m256i abs_vec = _mm256_abs_epi32(vec);\n        __m256i last_digit = _mm256_and_si256(abs_vec, _mm256_set1_epi32(9));\n        __m256i first_digit = _mm256_srli_epi32(abs_vec, 28);\n        __m256i combined_digits = _mm256_or_si256(_mm256_slli_epi32(last_digit, 4), first_digit);\n        __m256i odd_combined_digits = _mm256_and_si256(combined_digits, odd_mask);\n        __m256i valid_digits = _mm256_cmpeq_epi32(odd_combined_digits, odd_digits);\n\n        __m256i result = _mm256_and_si256(gt_ten, valid_digits);\n        int mask = _mm256_movemask_epi8(result);\n        count += __builtin_popcount(mask) / 8;\n    }\n\n    // Handle remaining elements\n    for (int i = (n / 8) * 8; i < n; ++i) {\n        int num = nums[i];\n        if (num > 10) {\n            int abs_num = std::abs(num);\n            int last_digit = abs_num % 10;\n            int first_digit = (abs_num >> 28) & 0xF;\n            if ((last_digit & 1) && (first_digit & 1)) {\n                count++;\n            }\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_131_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint specialFilter_simd(const std::vector<int> & nums){\n    int count = 0;\n    int n = nums.size();\n    const int* data = nums.data();\n    __m256i ten = _mm256_set1_epi32(10);\n    __m256i odd_digits = _mm256_set1_epi32(0x101); // Mask to check if first and last digits are odd\n\n    for (int i = 0; i <= n - 8; i += 8) {\n        __m256i vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(data + i));\n        __m256i gt_ten = _mm256_cmpgt_epi32(vec, ten);\n\n        // Extract last digit\n        __m256i abs_vec = _mm256_abs_epi32(vec);\n        __m256i last_digit = _mm256_and_epi32(abs_vec, _mm256_set1_epi32(9));\n\n        // Extract first digit\n        __m256i first_digit = _mm256_srli_epi32(abs_vec, 28); // Shift right by 28 to get the first digit\n        first_digit = _mm256_and_epi32(first_digit, _mm256_set1_epi32(9));\n\n        // Check if both first and last digits are odd\n        __m256i odd_first_last = _mm256_and_epi32(first_digit, last_digit);\n        odd_first_last = _mm256_cmpeq_epi32(odd_first_last, odd_digits);\n\n        // Combine conditions\n        __m256i result = _mm256_and_epi32(gt_ten, odd_first_last);\n\n        // Count true values\n        int mask = _mm256_movemask_epi8(result);\n        count += __builtin_popcount(mask) / 4;\n    }\n\n    // Handle remaining elements\n    for (int i = (n / 8) * 8; i < n; ++i) {\n        int num = nums[i];\n        if (num > 10) {\n            int last_digit = abs(num) % 10;\n            int first_digit = abs(num);\n            while (first_digit >= 10) {\n                first_digit /= 10;\n            }\n            if ((last_digit % 2 != 0) && (first_digit % 2 != 0)) {\n                count++;\n            }\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_131_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint specialFilter_simd(const std::vector<int> & nums){\n    int count = 0;\n    int n = nums.size();\n    const int* data = nums.data();\n\n    __m256i ten = _mm256_set1_epi32(10);\n    __m256i odd_digits = _mm256_set1_epi32(0x101); // Mask to check if first and last digits are odd\n\n    for (int i = 0; i <= n - 8; i += 8) {\n        __m256i vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(data + i));\n\n        // Check if elements are greater than 10\n        __m256i gt_ten = _mm256_cmpgt_epi32(vec, ten);\n\n        // Extract last digit\n        __m256i last_digit = _mm256_and_si256(vec, _mm256_set1_epi32(9));\n\n        // Extract first digit\n        __m256i abs_vec = _mm256_abs_epi32(vec);\n        __m256i first_digit = _mm256_setzero_si256();\n        for (int shift = 31; shift >= 0; shift -= 4) {\n            __m256i shifted = _mm256_srli_epi32(abs_vec, shift);\n            first_digit = _mm256_or_si256(first_digit, _mm256_and_si256(shifted, _mm256_set1_epi32(9)));\n        }\n\n        // Check if both first and last digits are odd\n        __m256i odd_first_last = _mm256_cmpeq_epi32(_mm256_and_si256(first_digit, odd_digits), odd_digits);\n        odd_first_last = _mm256_and_si256(odd_first_last, _mm256_cmpeq_epi32(_mm256_and_si256(last_digit, odd_digits), odd_digits));\n\n        // Combine conditions\n        __m256i result = _mm256_and_si256(gt_ten, odd_first_last);\n\n        // Count true values\n        int mask = _mm256_movemask_epi8(result);\n        count += __builtin_popcount(mask) / 4;\n    }\n\n    // Handle remaining elements\n    for (int i = (n / 8) * 8; i < n; ++i) {\n        int num = data[i];\n        int last_digit = abs(num) % 10;\n        int first_digit = abs(num);\n        while (first_digit >= 10) {\n            first_digit /= 10;\n        }\n        if (num > 10 && (first_digit & 1) && (last_digit & 1)) {\n            ++count;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_132_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nuint64_t get_max_triples_simd(uint64_t n){\n    uint64_t count = 0;\n    if (n < 3) return 0;\n\n    __m256i* a = (__m256i*)_mm_malloc(((n + 7) / 8) * sizeof(__m256i), 32);\n    __m256i indices = _mm256_set_epi64x(7, 6, 5, 4, 3, 2, 1, 0);\n    __m256i ones = _mm256_set1_epi64x(1);\n    __m256i twos = _mm256_set1_epi64x(2);\n\n    for (uint64_t i = 0; i < n; i += 8) {\n        __m256i idx = _mm256_add_epi64(indices, _mm256_set1_epi64x(i));\n        __m256i idx_sq = _mm256_mullo_epi64(idx, idx);\n        __m256i idx_sq_minus_idx = _mm256_sub_epi64(idx_sq, idx);\n        a[i / 8] = _mm256_add_epi64(idx_sq_minus_idx, ones);\n    }\n\n    for (uint64_t i = 0; i < n; ++i) {\n        for (uint64_t j = i + 1; j < n; ++j) {\n            for (uint64_t k = j + 1; k < n; ++k) {\n                uint64_t sum = ((uint64_t*)&a[i / 8])[i % 8] +\n                               ((uint64_t*)&a[j / 8])[j % 8] +\n                               ((uint64_t*)&a[k / 8])[k % 8];\n                if (sum % 3 == 0) {\n                    count++;\n                }\n            }\n        }\n    }\n\n    _mm_free(a);\n    return count;\n}\n```"}
{"task_id": "SimdBench_132_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nuint64_t get_max_triples_simd(uint64_t n){\n    uint64_t count = 0;\n    if (n < 3) return 0;\n\n    __m256i* a = (__m256i*)_mm_malloc(sizeof(__m256i) * ((n + 7) / 8), 32);\n    __m256i indices = _mm256_set_epi64x(7, 6, 5, 4, 3, 2, 1, 0);\n    __m256i ones = _mm256_set1_epi64x(1);\n    __m256i twos = _mm256_set1_epi64x(2);\n\n    for (uint64_t i = 0; i < n; i += 8) {\n        __m256i idx = _mm256_add_epi64(indices, _mm256_set1_epi64x(i));\n        __m256i idx_sq = _mm256_mullo_epi64(idx, idx);\n        __m256i idx_sq_minus_idx = _mm256_sub_epi64(idx_sq, idx);\n        a[i / 8] = _mm256_add_epi64(idx_sq_minus_idx, ones);\n    }\n\n    for (uint64_t i = 0; i < n; ++i) {\n        for (uint64_t j = i + 1; j < n; ++j) {\n            for (uint64_t k = j + 1; k < n; ++k) {\n                uint64_t sum = ((uint64_t*)&a[i / 8])[i % 8] +\n                               ((uint64_t*)&a[j / 8])[j % 8] +\n                               ((uint64_t*)&a[k / 8])[k % 8];\n                if (sum % 3 == 0) {\n                    count++;\n                }\n            }\n        }\n    }\n\n    _mm_free(a);\n    return count;\n}\n```"}
{"task_id": "SimdBench_132_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nuint64_t get_max_triples_simd(uint64_t n) {\n    uint64_t count = 0;\n    if (n < 3) return 0;\n\n    __m256i* a = (__m256i*)_mm_malloc(((n + 7) / 8) * sizeof(__m256i), 32);\n    __m256i indices = _mm256_set_epi64x(7, 6, 5, 4, 3, 2, 1, 0);\n    __m256i ones = _mm256_set1_epi64x(1);\n    __m256i twos = _mm256_set1_epi64x(2);\n\n    for (uint64_t i = 0; i < n; i += 8) {\n        __m256i idx = _mm256_add_epi64(indices, _mm256_set1_epi64x(i));\n        __m256i idx_sq = _mm256_mullo_epi64(idx, idx);\n        __m256i idx_sq_minus_idx = _mm256_sub_epi64(idx_sq, idx);\n        a[i / 8] = _mm256_add_epi64(idx_sq_minus_idx, ones);\n        indices = _mm256_add_epi64(indices, eights);\n    }\n\n    for (uint64_t i = 0; i < n; ++i) {\n        for (uint64_t j = i + 1; j < n; ++j) {\n            for (uint64_t k = j + 1; k < n; ++k) {\n                uint64_t sum = ((uint64_t*)&a[i / 8])[i % 8] +\n                               ((uint64_t*)&a[j / 8])[j % 8] +\n                               ((uint64_t*)&a[k / 8])[k % 8];\n                if (sum % 3 == 0) {\n                    count++;\n                }\n            }\n        }\n    }\n\n    _mm_free(a);\n    return count;\n}\n```"}
{"task_id": "SimdBench_132_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nuint64_t get_max_triples_simd(uint64_t n) {\n    uint64_t count = 0;\n    if (n < 3) return 0;\n\n    __m256i* a = (__m256i*)_mm_malloc(((n + 7) / 8) * sizeof(__m256i), 32);\n    __m256i indices = _mm256_set_epi64x(7, 6, 5, 4, 3, 2, 1, 0);\n    __m256i ones = _mm256_set1_epi64x(1);\n    __m256i twos = _mm256_set1_epi64x(2);\n\n    for (uint64_t i = 0; i < n; i += 8) {\n        __m256i idx = _mm256_add_epi64(indices, _mm256_set1_epi64x(i));\n        __m256i idx_sq = _mm256_mullo_epi64(idx, idx);\n        __m256i idx_sq_minus_idx = _mm256_sub_epi64(idx_sq, idx);\n        a[i / 8] = _mm256_add_epi64(idx_sq_minus_idx, ones);\n        indices = _mm256_add_epi64(indices, eights);\n    }\n\n    for (uint64_t i = 0; i < n; ++i) {\n        for (uint64_t j = i + 1; j < n; ++j) {\n            for (uint64_t k = j + 1; k < n; ++k) {\n                uint64_t sum = ((uint64_t*)&a[i / 8])[i % 8] +\n                               ((uint64_t*)&a[j / 8])[j % 8] +\n                               ((uint64_t*)&a[k / 8])[k % 8];\n                if (sum % 3 == 0) {\n                    count++;\n                }\n            }\n        }\n    }\n\n    _mm_free(a);\n    return count;\n}\n```"}
{"task_id": "SimdBench_132_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nuint64_t get_max_triples_simd(uint64_t n) {\n    uint64_t count = 0;\n    if (n < 3) return 0;\n\n    __m256i* a = (__m256i*)_mm_malloc(((n + 7) / 8) * sizeof(__m256i), 32);\n    __m256i indices = _mm256_set_epi64x(7, 6, 5, 4, 3, 2, 1, 0);\n    __m256i ones = _mm256_set1_epi64x(1);\n    __m256i twos = _mm256_set1_epi64x(2);\n\n    for (uint64_t i = 0; i < n; i += 8) {\n        __m256i idx = _mm256_add_epi64(indices, _mm256_set1_epi64x(i));\n        __m256i idx_sq = _mm256_mullo_epi64(idx, idx);\n        __m256i idx_sq_minus_idx = _mm256_sub_epi64(idx_sq, idx);\n        a[i / 8] = _mm256_add_epi64(idx_sq_minus_idx, ones);\n        indices = _mm256_add_epi64(indices, eights);\n    }\n\n    for (uint64_t i = 0; i < n; ++i) {\n        for (uint64_t j = i + 1; j < n; ++j) {\n            for (uint64_t k = j + 1; k < n; ++k) {\n                uint64_t sum = ((uint64_t*)&a[i / 8])[i % 8] +\n                               ((uint64_t*)&a[j / 8])[j % 8] +\n                               ((uint64_t*)&a[k / 8])[k % 8];\n                if (sum % 3 == 0) {\n                    count++;\n                }\n            }\n        }\n    }\n\n    _mm_free(a);\n    return count;\n}\n```"}
{"task_id": "SimdBench_133_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nint x_or_y_simd(int n, int x, int y) {\n    __m256i n_vec = _mm256_set1_epi32(n);\n    __m256i x_vec = _mm256_set1_epi32(x);\n    __m256i y_vec = _mm256_set1_epi32(y);\n    __m256i zero = _mm256_setzero_si256();\n    __m256i ones = _mm256_cmpeq_epi32(zero, zero);\n\n    // Check for divisibility from 2 to 16\n    __m256i divisors = _mm256_setr_epi32(2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 1);\n    __m256i remainder = _mm256_rem_epi32(n_vec, divisors);\n    __m256i is_not_prime = _mm256_cmpgt_epi32(zero, _mm256_add_epi32(_mm256_cmpeq_epi32(remainder, zero), _mm256_cmpeq_epi32(n_vec, divisors)));\n\n    // Check if n is 1 or 0\n    __m256i is_zero_or_one = _mm256_cmple_epi32(n_vec, ones);\n\n    // Combine conditions\n    is_not_prime = _mm256_or_si256(is_not_prime, is_zero_or_one);\n\n    // Select x or y based on the condition\n    __m256i result = _mm256_blendv_epi8(x_vec, y_vec, is_not_prime);\n\n    // Extract the result for the first element\n    int output;\n    _mm256_storeu_si256((__m256i*)&output, result);\n    return output;\n}\n```"}
{"task_id": "SimdBench_133_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nint x_or_y_simd(int n, int x, int y) {\n    __m256i n_vec = _mm256_set1_epi32(n);\n    __m256i x_vec = _mm256_set1_epi32(x);\n    __m256i y_vec = _mm256_set1_epi32(y);\n    __m256i zero = _mm256_setzero_si256();\n    __m256i ones = _mm256_cmpeq_epi32(zero, zero);\n\n    // Check for divisibility from 2 to 16\n    __m256i divisors = _mm256_setr_epi32(2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 1);\n    __m256i remainder = _mm256_rem_epi32(n_vec, divisors);\n    __m256i is_not_prime = _mm256_cmpgt_epi32(zero, _mm256_add_epi32(_mm256_cmpeq_epi32(remainder, zero), _mm256_cmpeq_epi32(n_vec, divisors)));\n\n    // Check if n is 1 or 0\n    __m256i is_zero_or_one = _mm256_or_si256(_mm256_cmpeq_epi32(n_vec, _mm256_set1_epi32(0)), _mm256_cmpeq_epi32(n_vec, _mm256_set1_epi32(1)));\n    is_not_prime = _mm256_or_si256(is_not_prime, is_zero_or_one);\n\n    // If n is prime, result should be x, otherwise y\n    __m256i result = _mm256_blendv_epi8(y_vec, x_vec, _mm256_cmpeq_epi32(is_not_prime, zero));\n\n    // Extract the first element of the result vector\n    int output;\n    _mm256_storeu_si256((__m256i*)&output, result);\n    return output;\n}\n```"}
{"task_id": "SimdBench_133_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nint x_or_y_simd(int n, int x, int y) {\n    __m256i n_vec = _mm256_set1_epi32(n);\n    __m256i x_vec = _mm256_set1_epi32(x);\n    __m256i y_vec = _mm256_set1_epi32(y);\n    __m256i zero = _mm256_setzero_si256();\n    __m256i ones = _mm256_cmpeq_epi32(zero, zero);\n\n    // Check for divisibility from 2 to 16\n    __m256i divisors = _mm256_setr_epi32(2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 1);\n    __m256i remainder = _mm256_rem_epi32(n_vec, divisors);\n    __m256i is_divisible = _mm256_cmpeq_epi32(remainder, zero);\n    __m256i is_not_prime = _mm256_or_si256(is_divisible, _mm256_cmpgt_epi32(divisors, n_vec));\n\n    // Set result to y if n is not prime, otherwise x\n    __m256i result = _mm256_blendv_epi8(x_vec, y_vec, is_not_prime);\n\n    // Extract the first element of the result vector\n    int output;\n    _mm256_storeu_si256((__m256i*)&output, result);\n    return output;\n}\n```"}
{"task_id": "SimdBench_133_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nint x_or_y_simd(int n, int x, int y) {\n    __m256i n_vec = _mm256_set1_epi32(n);\n    __m256i x_vec = _mm256_set1_epi32(x);\n    __m256i y_vec = _mm256_set1_epi32(y);\n    __m256i zero = _mm256_setzero_si256();\n    __m256i ones = _mm256_cmpeq_epi32(zero, zero);\n\n    // Check for divisibility from 2 to 16\n    __m256i divisors = _mm256_setr_epi32(2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 1);\n    __m256i remainder = _mm256_rem_epi32(n_vec, divisors);\n    __m256i is_not_prime = _mm256_cmpgt_epi32(zero, _mm256_add_epi32(_mm256_cmpeq_epi32(remainder, zero), _mm256_cmpeq_epi32(n_vec, divisors)));\n\n    // Check if n is 1 or 0\n    __m256i is_one_or_zero = _mm256_cmpgt_epi32(ones, n_vec);\n\n    // Combine conditions\n    is_not_prime = _mm256_or_si256(is_not_prime, is_one_or_zero);\n\n    // Select x or y based on the condition\n    __m256i result = _mm256_blendv_epi8(x_vec, y_vec, is_not_prime);\n\n    // Extract the first element of the result vector\n    int output;\n    _mm256_storeu_si256((__m256i*)&output, result);\n    return output;\n}\n```"}
{"task_id": "SimdBench_133_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n\nint x_or_y_simd(int n, int x, int y) {\n    __m256i n_vec = _mm256_set1_epi32(n);\n    __m256i zero = _mm256_setzero_si256();\n    __m256i one = _mm256_set1_epi32(1);\n    __m256i two = _mm256_set1_epi32(2);\n    __m256i x_vec = _mm256_set1_epi32(x);\n    __m256i y_vec = _mm256_set1_epi32(y);\n\n    __m256i is_prime = _mm256_cmpgt_epi32(n_vec, two);\n    __m256i i = _mm256_add_epi32(two, zero);\n\n    while (_mm256_movemask_epi8(is_prime)) {\n        __m256i div = _mm256_div_epi32(n_vec, i);\n        __m256i mul = _mm256_mullo_epi32(div, i);\n        __m256i cmp = _mm256_cmpeq_epi32(mul, n_vec);\n        is_prime = _mm256_andnot_epi32(cmp, is_prime);\n        i = _mm256_add_epi32(i, one);\n    }\n\n    __m256i result = _mm256_blendv_epi8(y_vec, x_vec, is_prime);\n    int output[8];\n    _mm256_storeu_si256((__m256i*)output, result);\n    return output[0];\n}\n```"}
{"task_id": "SimdBench_134_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nuint64_t double_the_difference_simd(const std::vector<float> & lst){\n    uint64_t sum = 0;\n    size_t n = lst.size();\n    size_t i = 0;\n\n    __m256i zero = _mm256_setzero_si256();\n    __m256 one = _mm256_set1_ps(1.0f);\n\n    for (; i <= n - 8; i += 8) {\n        __m256 vec = _mm256_loadu_ps(&lst[i]);\n        __m256 mask = _mm256_cmp_ps(vec, _mm256_setzero_ps(), _CMP_GT_OS);\n        vec = _mm256_and_ps(vec, mask);\n        __m256i int_vec = _mm256_cvtps_epi32(vec);\n        __m256i float_int_vec = _mm256_cvtepi32_ps(int_vec);\n        mask = _mm256_cmp_ps(vec, float_int_vec, _CMP_EQ_OS);\n        int_vec = _mm256_and_si256(int_vec, mask);\n        __m256i odd_mask = _mm256_set1_epi32(1);\n        __m256i odd_check = _mm256_and_si256(int_vec, odd_mask);\n        mask = _mm256_cmp_epi32(odd_check, zero, _CMP_NEQ_OQ);\n        int_vec = _mm256_and_si256(int_vec, mask);\n        __m256 squares = _mm256_mul_ps(_mm256_cvtepi32_ps(int_vec), _mm256_cvtepi32_ps(int_vec));\n        __m256i sum_squares = _mm256_cvtps_epi32(squares);\n        sum += _mm256_extract_epi32(sum_squares, 0);\n        sum += _mm256_extract_epi32(sum_squares, 1);\n        sum += _mm256_extract_epi32(sum_squares, 2);\n        sum += _mm256_extract_epi32(sum_squares, 3);\n        sum += _mm256_extract_epi32(sum_squares, 4);\n        sum += _mm256_extract_epi32(sum_squares, 5);\n        sum += _mm256_extract_epi32(sum_squares, 6);\n        sum += _mm256_extract_epi32(sum_squares, 7);\n    }\n\n    for (; i < n; ++i) {\n        if (lst[i] > 0 && lst[i] == static_cast<int>(lst[i]) && static_cast<int>(lst[i]) % 2 != 0) {\n            sum += static_cast<uint64_t>(lst[i]) * static_cast<uint64_t>(lst[i]);\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_134_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nuint64_t double_the_difference_simd(const std::vector<float> & lst) {\n    uint64_t sum = 0;\n    size_t n = lst.size();\n    size_t i = 0;\n\n    __m256i zero = _mm256_setzero_si256();\n    __m256 half = _mm256_set1_ps(0.5f);\n\n    while (i <= n - 8) {\n        __m256 vec = _mm256_loadu_ps(&lst[i]);\n        __m256i int_vec = _mm256_cvtps_epi32(vec);\n        __m256i abs_int_vec = _mm256_abs_epi32(int_vec);\n        __m256i is_positive = _mm256_cmpgt_epi32(abs_int_vec, zero);\n        __m256i is_odd = _mm256_and_si256(_mm256_cmpeq_epi32(_mm256_and_si256(abs_int_vec, _mm256_set1_epi32(1)), _mm256_set1_epi32(1)), is_positive);\n        __m256 filtered_vec = _mm256_and_ps(_mm256_castsi256_ps(is_odd), vec);\n        __m256 squared_vec = _mm256_mul_ps(filtered_vec, filtered_vec);\n        __m256i rounded_squared_vec = _mm256_cvtps_epi32(_mm256_round_ps(squared_vec, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC));\n        __m256i sum_vec = _mm256_sad_epu8(rounded_squared_vec, zero);\n        sum += _mm256_extract_epi64(sum_vec, 0) + _mm256_extract_epi64(sum_vec, 1);\n        i += 8;\n    }\n\n    for (; i < n; ++i) {\n        float num = lst[i];\n        int int_num = static_cast<int>(num);\n        if (int_num > 0 && int_num % 2 != 0) {\n            sum += int_num * int_num;\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_134_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nuint64_t double_the_difference_simd(const std::vector<float> & lst) {\n    uint64_t sum = 0;\n    size_t n = lst.size();\n    size_t i = 0;\n\n    __m256i zero = _mm256_setzero_si256();\n    __m256 half = _mm256_set1_ps(0.5f);\n\n    for (; i <= n - 8; i += 8) {\n        __m256 vec = _mm256_loadu_ps(&lst[i]);\n        __m256i int_vec = _mm256_cvtps_epi32(vec);\n        __m256 float_int_vec = _mm256_cvtepi32_ps(int_vec);\n        __m256 mask = _mm256_cmp_ps(vec, float_int_vec, _CMP_EQ_OS);\n        __m256 positive_mask = _mm256_cmp_ps(vec, _mm256_setzero_ps(), _CMP_GT_OS);\n        __m256 combined_mask = _mm256_and_ps(mask, positive_mask);\n        __m256 odd_mask = _mm256_andnot_ps(_mm256_and_ps(_mm256_mul_ps(float_int_vec, half), _mm256_set1_ps(1.0f)), _mm256_set1_ps(1.0f));\n        __m256 valid_mask = _mm256_and_ps(combined_mask, odd_mask);\n        __m256 squared = _mm256_mul_ps(vec, vec);\n        __m256 masked_squared = _mm256_and_ps(squared, valid_mask);\n        __m256i int_squared = _mm256_cvtps_epi32(masked_squared);\n        __m256i even_shifted = _mm256_srli_epi32(int_squared, 31);\n        __m256i zeroed = _mm256_andnot_si256(even_shifted, int_squared);\n        __m256i summed = _mm256_add_epi32(zeroed, zero);\n        sum += _mm256_extract_epi32(summed, 0);\n        sum += _mm256_extract_epi32(summed, 1);\n        sum += _mm256_extract_epi32(summed, 2);\n        sum += _mm256_extract_epi32(summed, 3);\n        sum += _mm256_extract_epi32(summed, 4);\n        sum += _mm256_extract_epi32(summed, 5);\n        sum += _mm256_extract_epi32(summed, 6);\n        sum += _mm256_extract_epi32(summed, 7);\n    }\n\n    for (; i < n; ++i) {\n        float val = lst[i];\n        if (val >= 0 && val == static_cast<int>(val) && static_cast<int>(val) % 2 != 0) {\n            sum += static_cast<uint64_t>(val * val);\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_134_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nuint64_t double_the_difference_simd(const std::vector<float> & lst){\n    uint64_t sum = 0;\n    size_t n = lst.size();\n    size_t i = 0;\n\n    __m256i zero = _mm256_setzero_si256();\n    __m256 one = _mm256_set1_ps(1.0f);\n    __m256 two = _mm256_set1_ps(2.0f);\n\n    for (; i <= n - 8; i += 8) {\n        __m256 vec = _mm256_loadu_ps(&lst[i]);\n        __m256 mask = _mm256_cmp_ps(vec, _mm256_setzero_ps(), _CMP_GT_OS); // Check if > 0\n        __m256i intVec = _mm256_cvtps_epi32(vec);\n        __m256i evenMask = _mm256_and_si256(intVec, _mm256_set1_epi32(1)); // Check if odd\n        __m256 valid = _mm256_and_ps(mask, _mm256_castsi256_ps(evenMask));\n        __m256 squared = _mm256_mul_ps(valid, valid);\n        __m256i squaredInt = _mm256_cvtps_epi32(squared);\n        __m256i sumVec = _mm256_add_epi32(squaredInt, zero);\n        sum += _mm256_extract_epi32(sumVec, 0);\n        sum += _mm256_extract_epi32(sumVec, 1);\n        sum += _mm256_extract_epi32(sumVec, 2);\n        sum += _mm256_extract_epi32(sumVec, 3);\n        sum += _mm256_extract_epi32(sumVec, 4);\n        sum += _mm256_extract_epi32(sumVec, 5);\n        sum += _mm256_extract_epi32(sumVec, 6);\n        sum += _mm256_extract_epi32(sumVec, 7);\n    }\n\n    for (; i < n; ++i) {\n        float val = lst[i];\n        if (val > 0 && static_cast<int>(val) % 2 != 0) {\n            sum += static_cast<uint64_t>(val * val);\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_134_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nuint64_t double_the_difference_simd(const std::vector<float> & lst) {\n    uint64_t sum = 0;\n    size_t n = lst.size();\n    size_t i = 0;\n\n    __m256i zero = _mm256_setzero_si256();\n    __m256i one = _mm256_set1_epi32(1);\n    __m256i two = _mm256_set1_epi32(2);\n\n    while (i <= n - 8) {\n        __m256 vec = _mm256_loadu_ps(&lst[i]);\n        __m256i int_vec = _mm256_cvtps_epi32(vec);\n        __m256i abs_vec = _mm256_abs_epi32(int_vec);\n        __m256i is_positive = _mm256_cmpgt_epi32(abs_vec, zero);\n        __m256i is_odd = _mm256_andnot_si256(_mm256_cmpeq_epi32(_mm256_and_si256(abs_vec, two), zero), is_positive);\n        __m256i odd_squares = _mm256_mullo_epi32(abs_vec, abs_vec);\n        __m256i masked_squares = _mm256_and_si256(odd_squares, is_odd);\n        __m256i even_mask = _mm256_set_epi32(0xFFFFFFFF, 0, 0xFFFFFFFF, 0, 0xFFFFFFFF, 0, 0xFFFFFFFF, 0);\n        __m256i low_squares = _mm256_and_si256(masked_squares, even_mask);\n        __m256i high_squares = _mm256_srli_epi64(masked_squares, 32);\n        __m256i combined_squares = _mm256_add_epi32(low_squares, high_squares);\n        __m128i low_sum = _mm_add_epi32(_mm256_castsi256_si128(combined_squares), _mm256_extracti128_si256(combined_squares, 1));\n        low_sum = _mm_add_epi32(low_sum, _mm_srli_epi64(low_sum, 32));\n        low_sum = _mm_add_epi32(low_sum, _mm_srli_epi64(low_sum, 16));\n        low_sum = _mm_add_epi32(low_sum, _mm_srli_epi64(low_sum, 8));\n        low_sum = _mm_add_epi32(low_sum, _mm_srli_epi64(low_sum, 4));\n        low_sum = _mm_add_epi32(low_sum, _mm_srli_epi64(low_sum, 2));\n        low_sum = _mm_add_epi32(low_sum, _mm_srli_epi64(low_sum, 1));\n        sum += _mm_cvtsi128_si32(low_sum);\n        i += 8;\n    }\n\n    for (; i < n; ++i) {\n        int val = static_cast<int>(lst[i]);\n        if (val > 0 && val % 2 != 0) {\n            sum += static_cast<uint64_t>(val) * val;\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_135_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> compare_simd(const std::vector<int>& game, const std::vector<int>& guess) {\n    size_t n = game.size();\n    std::vector<int> result(n);\n\n    size_t i = 0;\n    for (; i <= n - 8; i += 8) {\n        __m256i game_vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&game[i]));\n        __m256i guess_vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&guess[i]));\n        __m256i diff_vec = _mm256_abs_epi32(_mm256_sub_epi32(game_vec, guess_vec));\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(&result[i]), diff_vec);\n    }\n\n    for (; i < n; ++i) {\n        result[i] = (game[i] == guess[i]) ? 0 : std::abs(game[i] - guess[i]);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_135_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> compare_simd(const std::vector<int>& game, const std::vector<int>& guess) {\n    std::vector<int> result(game.size());\n    int n = game.size();\n    int i = 0;\n\n    for (; i <= n - 8; i += 8) {\n        __m256i game_vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&game[i]));\n        __m256i guess_vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&guess[i]));\n        __m256i diff_vec = _mm256_abs_epi32(_mm256_sub_epi32(game_vec, guess_vec));\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(&result[i]), diff_vec);\n    }\n\n    for (; i < n; ++i) {\n        result[i] = (game[i] == guess[i]) ? 0 : std::abs(game[i] - guess[i]);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_135_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> compare_simd(const std::vector<int>& game, const std::vector<int>& guess) {\n    size_t n = game.size();\n    std::vector<int> result(n);\n\n    for (size_t i = 0; i < n; i += 8) {\n        __m256i game_vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&game[i]));\n        __m256i guess_vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&guess[i]));\n\n        __m256i diff_vec = _mm256_sub_epi32(game_vec, guess_vec);\n        __m256i abs_diff_vec = _mm256_abs_epi32(diff_vec);\n\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(&result[i]), abs_diff_vec);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_135_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> compare_simd(const std::vector<int>& game, const std::vector<int>& guess) {\n    size_t n = game.size();\n    std::vector<int> result(n);\n\n    for (size_t i = 0; i < n; i += 8) {\n        __m256i game_vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&game[i]));\n        __m256i guess_vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&guess[i]));\n\n        __m256i diff_vec = _mm256_sub_epi32(game_vec, guess_vec);\n        __m256i abs_diff_vec = _mm256_abs_epi32(diff_vec);\n\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(&result[i]), abs_diff_vec);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_135_AVX", "completion": "```cpp\n#include <immintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> compare_simd(const std::vector<int>& game, const std::vector<int>& guess) {\n    size_t n = game.size();\n    std::vector<int> result(n);\n\n    for (size_t i = 0; i < n; i += 8) {\n        __m256i game_vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&game[i]));\n        __m256i guess_vec = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&guess[i]));\n\n        __m256i diff_vec = _mm256_sub_epi32(game_vec, guess_vec);\n        __m256i abs_diff_vec = _mm256_abs_epi32(diff_vec);\n\n        _mm256_storeu_si256(reinterpret_cast<__m256i*>(&result[i]), abs_diff_vec);\n    }\n\n    return result;\n}\n```"}

{"task_id": "SimdBench_0_SSE", "completion": "```cpp\nvoid conditional_move_simd(const int64_t *src, int64_t *dst, const bool *mask, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 2; i += 2) {\n        __m128i src_vec = _mm_loadu_si128((__m128i*)&src[i]);\n        __m128i dst_vec = _mm_loadu_si128((__m128i*)&dst[i]);\n        __m128i mask_vec = _mm_set_epi64x(mask[i+1], mask[i]);\n        mask_vec = _mm_cmpeq_epi64(mask_vec, _mm_set1_epi64x(1));\n        __m128i result_vec = _mm_or_si128(_mm_and_si128(mask_vec, src_vec), _mm_andnot_si128(mask_vec, dst_vec));\n        _mm_storeu_si128((__m128i*)&dst[i], result_vec);\n    }\n    for (; i < length; ++i) {\n        dst[i] = mask[i] ? src[i] : dst[i];\n    }\n}\n```"}
{"task_id": "SimdBench_0_SSE", "completion": "```cpp\nvoid conditional_move_simd(const int64_t *src, int64_t *dst, const bool *mask, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 2; i += 2) {\n        __m128i src_vec = _mm_loadu_si128((__m128i*)&src[i]);\n        __m128i dst_vec = _mm_loadu_si128((__m128i*)&dst[i]);\n        __m128i mask_vec = _mm_set_epi64x(mask[i + 1], mask[i]);\n        mask_vec = _mm_cmpeq_epi64(mask_vec, _mm_set1_epi64x(1));\n        __m128i result_vec = _mm_or_si128(_mm_and_si128(mask_vec, src_vec), _mm_andnot_si128(mask_vec, dst_vec));\n        _mm_storeu_si128((__m128i*)&dst[i], result_vec);\n    }\n    for (; i < length; ++i) {\n        dst[i] = mask[i] ? src[i] : dst[i];\n    }\n}\n```"}
{"task_id": "SimdBench_0_SSE", "completion": "```cpp\nvoid conditional_move_simd(const int64_t *src, int64_t *dst, const bool *mask, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 2; i += 2) {\n        __m128i src_vec = _mm_loadu_si128((__m128i*)&src[i]);\n        __m128i dst_vec = _mm_loadu_si128((__m128i*)&dst[i]);\n        __m128i mask_vec = _mm_set_epi64x(mask[i+1], mask[i]);\n        mask_vec = _mm_cmpeq_epi64(mask_vec, _mm_set1_epi64x(1));\n        __m128i result_vec = _mm_or_si128(_mm_and_si128(mask_vec, src_vec), _mm_andnot_si128(mask_vec, dst_vec));\n        _mm_storeu_si128((__m128i*)&dst[i], result_vec);\n    }\n    for (; i < length; ++i) {\n        dst[i] = mask[i] ? src[i] : dst[i];\n    }\n}\n```"}
{"task_id": "SimdBench_0_SSE", "completion": "```cpp\nvoid conditional_move_simd(const int64_t *src, int64_t *dst, const bool *mask, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 2; i += 2) {\n        __m128i src_vec = _mm_loadu_si128((__m128i*)&src[i]);\n        __m128i dst_vec = _mm_loadu_si128((__m128i*)&dst[i]);\n        __m128i mask_vec = _mm_set_epi64x(mask[i+1], mask[i]);\n        mask_vec = _mm_cmpeq_epi64(mask_vec, _mm_set1_epi64x(1));\n        __m128i result_vec = _mm_or_si128(_mm_and_si128(mask_vec, src_vec), _mm_andnot_si128(mask_vec, dst_vec));\n        _mm_storeu_si128((__m128i*)&dst[i], result_vec);\n    }\n    for (; i < length; ++i) {\n        dst[i] = mask[i] ? src[i] : dst[i];\n    }\n}\n```"}
{"task_id": "SimdBench_0_SSE", "completion": "```cpp\nvoid conditional_move_simd(const int64_t *src, int64_t *dst, const bool *mask, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 2; i += 2) {\n        __m128i src_vec = _mm_loadu_si128((__m128i*)&src[i]);\n        __m128i dst_vec = _mm_loadu_si128((__m128i*)&dst[i]);\n        __m128i mask_vec = _mm_set_epi64x(mask[i+1], mask[i]);\n        mask_vec = _mm_cmpeq_epi64(mask_vec, _mm_set1_epi64x(1));\n        __m128i result_vec = _mm_or_si128(_mm_and_si128(mask_vec, src_vec), _mm_andnot_si128(mask_vec, dst_vec));\n        _mm_storeu_si128((__m128i*)&dst[i], result_vec);\n    }\n    for (; i < length; ++i) {\n        dst[i] = mask[i] ? src[i] : dst[i];\n    }\n}\n```"}
{"task_id": "SimdBench_1_SSE", "completion": "```cpp\nvoid load_modify_store_simd(const int *src, int *dst, int scale, size_t length) {\n    __m128i scale_vec = _mm_set1_epi32(scale);\n    __m128i seven_vec = _mm_set1_epi32(7);\n\n    for (size_t i = 0; i <= length - 4; i += 4) {\n        __m128i src_vec = _mm_loadu_si128((__m128i const*)(src + i));\n        \n        __m128i tmp1 = _mm_mullo_epi32(src_vec, scale_vec);\n        tmp1 = _mm_srai_epi32(tmp1, 3);\n\n        __m128i tmp2 = _mm_mullo_epi32(src_vec, scale_vec);\n        tmp2 = _mm_slli_epi32(tmp2, 3);\n\n        __m128i result = _mm_mullo_epi32(src_vec, scale_vec);\n        __m128i tmp1_tmp2 = _mm_mullo_epi32(tmp1, tmp2);\n        result = _mm_add_epi32(result, tmp1_tmp2);\n        result = _mm_div_epi32(result, seven_vec);\n\n        _mm_storeu_si128((__m128i*)(dst + i), result);\n    }\n\n    // Handle remaining elements\n    for (size_t i = (length / 4) * 4; i < length; ++i) {\n        int tmp1 = (src[i] * scale) >> 3;\n        int tmp2 = (src[i] * scale) << 3;\n        dst[i] = (src[i] * scale + tmp1 * tmp2) / 7;\n    }\n}\n```"}
{"task_id": "SimdBench_1_SSE", "completion": "```cpp\nvoid load_modify_store_simd(const int *src, int *dst, int scale, size_t length) {\n    __m128i scale_vec = _mm_set1_epi32(scale);\n    __m128i seven_vec = _mm_set1_epi32(7);\n\n    for (size_t i = 0; i <= length - 4; i += 4) {\n        __m128i src_vec = _mm_loadu_si128((__m128i const*)(src + i));\n        \n        __m128i tmp1 = _mm_mullo_epi32(src_vec, scale_vec);\n        tmp1 = _mm_srai_epi32(tmp1, 3);\n\n        __m128i tmp2 = _mm_mullo_epi32(src_vec, scale_vec);\n        tmp2 = _mm_slli_epi32(tmp2, 3);\n\n        __m128i result = _mm_mullo_epi32(src_vec, scale_vec);\n        __m128i tmp1_tmp2 = _mm_mullo_epi32(tmp1, tmp2);\n        result = _mm_add_epi32(result, tmp1_tmp2);\n        result = _mm_idiv_epi32(result, seven_vec);\n\n        _mm_storeu_si128((__m128i*)(dst + i), result);\n    }\n\n    // Handle remaining elements\n    for (size_t i = (length / 4) * 4; i < length; ++i) {\n        int tmp1 = (src[i] * scale) >> 3;\n        int tmp2 = (src[i] * scale) << 3;\n        dst[i] = (src[i] * scale + tmp1 * tmp2) / 7;\n    }\n}\n```"}
{"task_id": "SimdBench_1_SSE", "completion": "```cpp\nvoid load_modify_store_simd(const int *src, int *dst, int scale, size_t length) {\n    __m128i scale_vec = _mm_set1_epi32(scale);\n    __m128i seven_vec = _mm_set1_epi32(7);\n\n    for (size_t i = 0; i <= length - 4; i += 4) {\n        __m128i src_vec = _mm_loadu_si128((__m128i const*)(src + i));\n        \n        __m128i tmp1 = _mm_mullo_epi32(src_vec, scale_vec);\n        tmp1 = _mm_srai_epi32(tmp1, 3);\n\n        __m128i tmp2 = _mm_mullo_epi32(src_vec, scale_vec);\n        tmp2 = _mm_slli_epi32(tmp2, 3);\n\n        __m128i result = _mm_mullo_epi32(src_vec, scale_vec);\n        __m128i tmp1_tmp2 = _mm_mullo_epi32(tmp1, tmp2);\n        result = _mm_add_epi32(result, tmp1_tmp2);\n        result = _mm_div_epi32(result, seven_vec);\n\n        _mm_storeu_si128((__m128i*)(dst + i), result);\n    }\n\n    // Handle remaining elements\n    for (size_t i = (length / 4) * 4; i < length; ++i) {\n        int tmp1 = (src[i] * scale) >> 3;\n        int tmp2 = (src[i] * scale) << 3;\n        dst[i] = (src[i] * scale + tmp1 * tmp2) / 7;\n    }\n}\n```"}
{"task_id": "SimdBench_1_SSE", "completion": "```cpp\nvoid load_modify_store_simd(const int *src, int *dst, int scale, size_t length) {\n    __m128i scale_vec = _mm_set1_epi32(scale);\n    __m128i seven_vec = _mm_set1_epi32(7);\n\n    for (size_t i = 0; i <= length - 4; i += 4) {\n        __m128i src_vec = _mm_loadu_si128((__m128i const*)(src + i));\n        \n        __m128i tmp1 = _mm_mullo_epi32(src_vec, scale_vec);\n        tmp1 = _mm_srai_epi32(tmp1, 3);\n\n        __m128i tmp2 = _mm_mullo_epi32(src_vec, scale_vec);\n        tmp2 = _mm_slli_epi32(tmp2, 3);\n\n        __m128i result = _mm_mullo_epi32(src_vec, scale_vec);\n        __m128i tmp1_tmp2 = _mm_mullo_epi32(tmp1, tmp2);\n        result = _mm_add_epi32(result, tmp1_tmp2);\n        result = _mm_div_epi32(result, seven_vec);\n\n        _mm_storeu_si128((__m128i*)(dst + i), result);\n    }\n\n    // Handle remaining elements\n    for (size_t i = (length / 4) * 4; i < length; ++i) {\n        int tmp1 = (src[i] * scale) >> 3;\n        int tmp2 = (src[i] * scale) << 3;\n        dst[i] = (src[i] * scale + tmp1 * tmp2) / 7;\n    }\n}\n```"}
{"task_id": "SimdBench_1_SSE", "completion": "```cpp\nvoid load_modify_store_simd(const int *src, int *dst, int scale, size_t length) {\n    __m128i scale_vec = _mm_set1_epi32(scale);\n    __m128i seven_vec = _mm_set1_epi32(7);\n\n    for (size_t i = 0; i <= length - 4; i += 4) {\n        __m128i src_vec = _mm_loadu_si128((__m128i const*)(src + i));\n        \n        __m128i tmp1 = _mm_mullo_epi32(src_vec, scale_vec);\n        tmp1 = _mm_srai_epi32(tmp1, 3);\n\n        __m128i tmp2 = _mm_mullo_epi32(src_vec, scale_vec);\n        tmp2 = _mm_slli_epi32(tmp2, 3);\n\n        __m128i result = _mm_mullo_epi32(src_vec, scale_vec);\n        __m128i tmp1_tmp2 = _mm_mullo_epi32(tmp1, tmp2);\n        result = _mm_add_epi32(result, tmp1_tmp2);\n        result = _mm_div_epi32(result, seven_vec);\n\n        _mm_storeu_si128((__m128i*)(dst + i), result);\n    }\n\n    // Handle remaining elements\n    for (size_t i = (length / 4) * 4; i < length; ++i) {\n        int tmp1 = (src[i] * scale) >> 3;\n        int tmp2 = (src[i] * scale) << 3;\n        dst[i] = (src[i] * scale + tmp1 * tmp2) / 7;\n    }\n}\n```"}
{"task_id": "SimdBench_2_SSE", "completion": "```cpp\nvoid strided_load_store_simd(const double *src, double *dst, size_t rows, size_t cols, size_t stride) {\n    size_t i = 0;\n    __m128d zero = _mm_setzero_pd();\n    for (; i <= rows - 2; i += 2) {\n        size_t index1 = i * cols + stride;\n        size_t index2 = (i + 1) * cols + stride;\n        __m128d values = _mm_set_pd(src[index2], src[index1]);\n        _mm_storeu_pd(&dst[i], values);\n    }\n    for (; i < rows; ++i) {\n        size_t index = i * cols + stride;\n        dst[i] = src[index];\n    }\n}\n```"}
{"task_id": "SimdBench_2_SSE", "completion": "```cpp\nvoid strided_load_store_simd(const double *src, double *dst, size_t rows, size_t cols, size_t stride) {\n    size_t i = 0;\n    for (; i <= rows - 4; i += 4) {\n        __m128d values = _mm_loadu_pd(&src[(i + 0) * cols + stride]);\n        values = _mm_insertf64x2(values, _mm_loadu_pd(&src[(i + 1) * cols + stride]), 1);\n        __m128d values2 = _mm_loadu_pd(&src[(i + 2) * cols + stride]);\n        values2 = _mm_insertf64x2(values2, _mm_loadu_pd(&src[(i + 3) * cols + stride]), 1);\n        _mm_storeu_pd(&dst[i], values);\n        _mm_storeu_pd(&dst[i + 2], values2);\n    }\n    for (; i < rows; ++i) {\n        dst[i] = src[i * cols + stride];\n    }\n}\n```"}
{"task_id": "SimdBench_2_SSE", "completion": "```cpp\nvoid strided_load_store_simd(const double *src, double *dst, size_t rows, size_t cols, size_t stride) {\n    size_t i = 0;\n    __m128d zero = _mm_setzero_pd();\n    for (; i <= rows - 2; i += 2) {\n        size_t index1 = i * cols + stride;\n        size_t index2 = (i + 1) * cols + stride;\n        __m128d values = _mm_set_pd(src[index2], src[index1]);\n        _mm_storeu_pd(&dst[i], values);\n    }\n    for (; i < rows; ++i) {\n        size_t index = i * cols + stride;\n        dst[i] = src[index];\n    }\n}\n```"}
{"task_id": "SimdBench_2_SSE", "completion": "```cpp\nvoid strided_load_store_simd(const double *src, double *dst, size_t rows, size_t cols, size_t stride) {\n    size_t i = 0;\n    for (; i <= rows - 2; i += 2) {\n        __m128d values = _mm_loadu_pd(&src[(i * cols + stride)]);\n        _mm_storeu_pd(&dst[i], values);\n    }\n    for (; i < rows; ++i) {\n        dst[i] = src[i * cols + stride];\n    }\n}\n```"}
{"task_id": "SimdBench_2_SSE", "completion": "```cpp\nvoid strided_load_store_simd(const double *src, double *dst, size_t rows, size_t cols, size_t stride) {\n    size_t i = 0;\n    __m128d zero = _mm_setzero_pd();\n    for (; i <= rows - 2; i += 2) {\n        size_t index1 = i * cols + stride;\n        size_t index2 = (i + 1) * cols + stride;\n        __m128d values = _mm_set_pd(src[index2], src[index1]);\n        _mm_storeu_pd(&dst[i], values);\n    }\n    for (; i < rows; ++i) {\n        size_t index = i * cols + stride;\n        dst[i] = src[index];\n    }\n}\n```"}
{"task_id": "SimdBench_3_SSE", "completion": "```cpp\nvoid indexed_access_simd(const float *src, const int *indices, float *dst, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 4; i += 4) {\n        __m128i idx = _mm_loadu_si128((__m128i*)&indices[i]);\n        __m128 gathered = _mm_i32gather_ps(src, idx, 4);\n        _mm_storeu_ps(&dst[i], gathered);\n\n        __m128 scattered = _mm_loadu_ps(&src[i]);\n        for (int j = 0; j < 4; ++j) {\n            dst[indices[i + j]] = scattered.m128_f32[j];\n        }\n    }\n\n    for (; i < length; ++i) {\n        dst[i] = src[indices[i]];\n        dst[indices[i]] = src[i];\n    }\n}\n```"}
{"task_id": "SimdBench_3_SSE", "completion": "```cpp\nvoid indexed_access_simd(const float *src, const int *indices, float *dst, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 4; i += 4) {\n        __m128i idx = _mm_loadu_si128((__m128i*)&indices[i]);\n        __m128 gathered = _mm_i32gather_ps(src, idx, 4);\n        _mm_storeu_ps(&dst[i], gathered);\n\n        __m128 scattered = _mm_loadu_ps(&src[i]);\n        for (int j = 0; j < 4; ++j) {\n            dst[indices[i + j]] = scattered.m128_f32[j];\n        }\n    }\n\n    for (; i < length; ++i) {\n        dst[i] = src[indices[i]];\n        dst[indices[i]] = src[i];\n    }\n}\n```"}
{"task_id": "SimdBench_3_SSE", "completion": "```cpp\nvoid indexed_access_simd(const float *src, const int *indices, float *dst, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 4; i += 4) {\n        __m128i idx = _mm_loadu_si128((__m128i*)&indices[i]);\n        __m128 gathered_values = _mm_i32gather_ps(src, idx, 4);\n        _mm_storeu_ps(&dst[i], gathered_values);\n\n        __m128 scatter_values = _mm_loadu_ps(&src[i]);\n        for (int j = 0; j < 4; ++j) {\n            dst[indices[i + j]] = scatter_values.m128_f32[j];\n        }\n    }\n\n    for (; i < length; ++i) {\n        dst[i] = src[indices[i]];\n        dst[indices[i]] = src[i];\n    }\n}\n```"}
{"task_id": "SimdBench_3_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid indexed_access_simd(const float *src, const int *indices, float *dst, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 4; i += 4) {\n        __m128i idx = _mm_loadu_si128((__m128i*)&indices[i]);\n        __m128 gathered = _mm_i32gather_ps(src, idx, 4);\n        _mm_storeu_ps(&dst[i], gathered);\n\n        __m128 scattered = _mm_loadu_ps(&src[i]);\n        _mm_maskmoveu_si128((__m128i)scattered, _mm_cmpeq_epi32(idx, idx), (char*)&dst[0]);\n    }\n\n    for (; i < length; ++i) {\n        dst[i] = src[indices[i]];\n        dst[indices[i]] = src[i];\n    }\n}\n```"}
{"task_id": "SimdBench_3_SSE", "completion": "```cpp\nvoid indexed_access_simd(const float *src, const int *indices, float *dst, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 4; i += 4) {\n        __m128 src_values = _mm_loadu_ps(&src[i]);\n        __m128i idx_values = _mm_loadu_si128((__m128i*)&indices[i]);\n\n        // Gather operation\n        __m128 gathered_values = _mm_set_ps(\n            src[_mm_extract_epi32(idx_values, 3)],\n            src[_mm_extract_epi32(idx_values, 2)],\n            src[_mm_extract_epi32(idx_values, 1)],\n            src[_mm_extract_epi32(idx_values, 0)]\n        );\n        _mm_storeu_ps(&dst[i], gathered_values);\n\n        // Scatter operation\n        dst[_mm_extract_epi32(idx_values, 0)] = _mm_cvtss_f32(_mm_shuffle_ps(src_values, src_values, _MM_SHUFFLE(0, 0, 0, 0)));\n        dst[_mm_extract_epi32(idx_values, 1)] = _mm_cvtss_f32(_mm_shuffle_ps(src_values, src_values, _MM_SHUFFLE(1, 1, 1, 1)));\n        dst[_mm_extract_epi32(idx_values, 2)] = _mm_cvtss_f32(_mm_shuffle_ps(src_values, src_values, _MM_SHUFFLE(2, 2, 2, 2)));\n        dst[_mm_extract_epi32(idx_values, 3)] = _mm_cvtss_f32(_mm_shuffle_ps(src_values, src_values, _MM_SHUFFLE(3, 3, 3, 3)));\n    }\n\n    // Handle remaining elements\n    for (; i < length; ++i) {\n        dst[i] = src[indices[i]]; // Gather\n        dst[indices[i]] = src[i]; // Scatter\n    }\n}\n```"}
{"task_id": "SimdBench_4_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid range_reverse_simd(int16_t *arr, uint64_t start, uint64_t end) {\n    while (start + 7 < end) {\n        __m128i a = _mm_loadu_si128((__m128i*)&arr[start]);\n        __m128i b = _mm_loadu_si128((__m128i*)&arr[end - 7]);\n\n        __m128i shuffled_a = _mm_shuffle_epi8(a, _mm_setr_epi8(30, 31, 28, 29, 26, 27, 24, 25, 22, 23, 20, 21, 18, 19, 16, 17));\n        __m128i shuffled_b = _mm_shuffle_epi8(b, _mm_setr_epi8(30, 31, 28, 29, 26, 27, 24, 25, 22, 23, 20, 21, 18, 19, 16, 17));\n\n        _mm_storeu_si128((__m128i*)&arr[start], shuffled_b);\n        _mm_storeu_si128((__m128i*)&arr[end - 7], shuffled_a);\n\n        start += 8;\n        end -= 8;\n    }\n\n    while (start < end) {\n        int16_t temp = arr[start];\n        arr[start] = arr[end];\n        arr[end] = temp;\n        start++;\n        end--;\n    }\n}\n```"}
{"task_id": "SimdBench_4_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid range_reverse_simd(int16_t *arr, uint64_t start, uint64_t end) {\n    while (start + 7 < end) {\n        __m128i a = _mm_loadu_si128((__m128i*)&arr[start]);\n        __m128i b = _mm_loadu_si128((__m128i*)&arr[end - 7]);\n\n        __m128i shuffled_a = _mm_shuffle_epi8(a, _mm_setr_epi8(30, 29, 28, 27, 26, 25, 24, 23, 31, 31, 31, 31, 31, 31, 31, 31));\n        __m128i shuffled_b = _mm_shuffle_epi8(b, _mm_setr_epi8(30, 29, 28, 27, 26, 25, 24, 23, 31, 31, 31, 31, 31, 31, 31, 31));\n\n        __m128i swapped = _mm_or_si128(_mm_and_si128(shuffled_a, _mm_set1_epi16(0xFF00)), _mm_srli_epi16(shuffled_b, 8));\n        __m128i swapped_b = _mm_or_si128(_mm_and_si128(shuffled_b, _mm_set1_epi16(0xFF00)), _mm_srli_epi16(shuffled_a, 8));\n\n        _mm_storeu_si128((__m128i*)&arr[end - 7], swapped);\n        _mm_storeu_si128((__m128i*)&arr[start], swapped_b);\n\n        start += 8;\n        end -= 8;\n    }\n\n    while (start < end) {\n        int16_t temp = arr[start];\n        arr[start] = arr[end];\n        arr[end] = temp;\n        start++;\n        end--;\n    }\n}\n```"}
{"task_id": "SimdBench_4_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid range_reverse_simd(int16_t *arr, uint64_t start, uint64_t end) {\n    while (start + 7 < end) {\n        __m128i a = _mm_loadu_si128((__m128i*)&arr[start]);\n        __m128i b = _mm_loadu_si128((__m128i*)&arr[end - 7]);\n\n        __m128i shuffled_a = _mm_shuffle_epi8(a, _mm_setr_epi8(30, 31, 28, 29, 26, 27, 24, 25, 22, 23, 20, 21, 18, 19, 16, 17));\n        __m128i shuffled_b = _mm_shuffle_epi8(b, _mm_setr_epi8(30, 31, 28, 29, 26, 27, 24, 25, 22, 23, 20, 21, 18, 19, 16, 17));\n\n        _mm_storeu_si128((__m128i*)&arr[end - 7], shuffled_a);\n        _mm_storeu_si128((__m128i*)&arr[start], shuffled_b);\n\n        start += 8;\n        end -= 8;\n    }\n\n    while (start < end) {\n        int16_t temp = arr[start];\n        arr[start] = arr[end];\n        arr[end] = temp;\n        start++;\n        end--;\n    }\n}\n```"}
{"task_id": "SimdBench_4_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid range_reverse_simd(int16_t *arr, uint64_t start, uint64_t end) {\n    while (start + 7 < end) {\n        __m128i a = _mm_loadu_si128((__m128i*)&arr[start]);\n        __m128i b = _mm_loadu_si128((__m128i*)&arr[end - 7]);\n\n        __m128i shuffled_a = _mm_shuffle_epi8(a, _mm_setr_epi8(30, 31, 28, 29, 26, 27, 24, 25, 22, 23, 20, 21, 18, 19, 16, 17));\n        __m128i shuffled_b = _mm_shuffle_epi8(b, _mm_setr_epi8(30, 31, 28, 29, 26, 27, 24, 25, 22, 23, 20, 21, 18, 19, 16, 17));\n\n        _mm_storeu_si128((__m128i*)&arr[end - 7], shuffled_a);\n        _mm_storeu_si128((__m128i*)&arr[start], shuffled_b);\n\n        start += 8;\n        end -= 8;\n    }\n\n    while (start < end) {\n        int16_t temp = arr[start];\n        arr[start] = arr[end];\n        arr[end] = temp;\n        start++;\n        end--;\n    }\n}\n```"}
{"task_id": "SimdBench_4_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid range_reverse_simd(int16_t *arr, uint64_t start, uint64_t end) {\n    while (start + 7 < end) {\n        __m128i a = _mm_loadu_si128((__m128i*)&arr[start]);\n        __m128i b = _mm_loadu_si128((__m128i*)&arr[end - 7]);\n\n        __m128i shuffled_a = _mm_shuffle_epi8(a, _mm_setr_epi8(30, 31, 28, 29, 26, 27, 24, 25, 22, 23, 20, 21, 18, 19, 16, 17));\n        __m128i shuffled_b = _mm_shuffle_epi8(b, _mm_setr_epi8(30, 31, 28, 29, 26, 27, 24, 25, 22, 23, 20, 21, 18, 19, 16, 17));\n\n        _mm_storeu_si128((__m128i*)&arr[end - 7], shuffled_a);\n        _mm_storeu_si128((__m128i*)&arr[start], shuffled_b);\n\n        start += 8;\n        end -= 8;\n    }\n\n    while (start < end) {\n        int16_t temp = arr[start];\n        arr[start] = arr[end];\n        arr[end] = temp;\n        start++;\n        end--;\n    }\n}\n```"}
{"task_id": "SimdBench_5_SSE", "completion": "```cpp\nvoid extract_tensor_slice_simd(const uint8_t *tensor, uint8_t *slice, size_t dim1, size_t dim2, size_t dim3, size_t slice_idx) {\n    size_t offset = slice_idx * dim2 * dim3;\n    size_t total_elements = dim2 * dim3;\n\n    for (size_t i = 0; i < total_elements; i += 16) {\n        __m128i data = _mm_loadu_si128(reinterpret_cast<const __m128i*>(tensor + offset + i));\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(slice + i), data);\n    }\n}\n```"}
{"task_id": "SimdBench_5_SSE", "completion": "```cpp\nvoid extract_tensor_slice_simd(const uint8_t *tensor, uint8_t *slice, size_t dim1, size_t dim2, size_t dim3, size_t slice_idx) {\n    size_t offset = slice_idx * dim2 * dim3;\n    size_t total_elements = dim2 * dim3;\n\n    for (size_t i = 0; i < total_elements; i += 16) {\n        __m128i data = _mm_loadu_si128(reinterpret_cast<const __m128i*>(tensor + offset + i));\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(slice + i), data);\n    }\n}\n```"}
{"task_id": "SimdBench_5_SSE", "completion": "```cpp\nvoid extract_tensor_slice_simd(const uint8_t *tensor, uint8_t *slice, size_t dim1, size_t dim2, size_t dim3, size_t slice_idx) {\n    size_t offset = slice_idx * dim2 * dim3;\n    size_t total_elements = dim2 * dim3;\n\n    for (size_t i = 0; i < total_elements; i += 16) {\n        __m128i data = _mm_loadu_si128(reinterpret_cast<const __m128i*>(tensor + offset + i));\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(slice + i), data);\n    }\n}\n```"}
{"task_id": "SimdBench_5_SSE", "completion": "```cpp\nvoid extract_tensor_slice_simd(const uint8_t *tensor, uint8_t *slice, size_t dim1, size_t dim2, size_t dim3, size_t slice_idx) {\n    size_t offset = slice_idx * dim2 * dim3;\n    size_t total_elements = dim2 * dim3;\n\n    for (size_t i = 0; i < total_elements; i += 16) {\n        __m128i data = _mm_loadu_si128(reinterpret_cast<const __m128i*>(tensor + offset + i));\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(slice + i), data);\n    }\n}\n```"}
{"task_id": "SimdBench_5_SSE", "completion": "```cpp\nvoid extract_tensor_slice_simd(const uint8_t *tensor, uint8_t *slice, size_t dim1, size_t dim2, size_t dim3, size_t slice_idx) {\n    size_t slice_offset = slice_idx * dim2 * dim3;\n    size_t total_elements = dim2 * dim3;\n\n    for (size_t i = 0; i < total_elements; i += 16) {\n        __m128i src = _mm_loadu_si128((__m128i const*)(tensor + slice_offset + i));\n        _mm_storeu_si128((__m128i*)(slice + i), src);\n    }\n}\n```"}
{"task_id": "SimdBench_6_SSE", "completion": "```cpp\nvoid blocked_matrix_transpose_simd(const int16_t *src, int16_t *dst, size_t rows, size_t cols, size_t block_size) {\n    for (size_t i = 0; i < rows; i += block_size) {\n        for (size_t j = 0; j < cols; j += block_size) {\n            for (size_t bi = 0; bi < block_size && i + bi < rows; ++bi) {\n                for (size_t bj = 0; bj < block_size && j + bj < cols; bj += 8) {\n                    __m128i row = _mm_loadu_si128((__m128i*)&src[(i + bi) * cols + j + bj]);\n                    __m128i row1 = _mm_unpacklo_epi16(row, _mm_setzero_si128());\n                    __m128i row2 = _mm_unpackhi_epi16(row, _mm_setzero_si128());\n                    _mm_storeu_si128((__m128i*)&dst[(j + bj) * rows + i + bi], row1);\n                    _mm_storeu_si128((__m128i*)&dst[(j + bj + 4) * rows + i + bi], row2);\n                }\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_6_SSE", "completion": "```cpp\nvoid blocked_matrix_transpose_simd(const int16_t *src, int16_t *dst, size_t rows, size_t cols, size_t block_size) {\n    for (size_t i = 0; i < rows; i += block_size) {\n        for (size_t j = 0; j < cols; j += block_size) {\n            for (size_t bi = 0; bi < block_size && i + bi < rows; ++bi) {\n                for (size_t bj = 0; bj < block_size && j + bj < cols; bj += 8) {\n                    __m128i row = _mm_loadu_si128((__m128i*)&src[(i + bi) * cols + j + bj]);\n                    __m128i row1 = _mm_unpacklo_epi16(row, _mm_setzero_si128());\n                    __m128i row2 = _mm_unpackhi_epi16(row, _mm_setzero_si128());\n\n                    __m128i col1 = _mm_movelh_epi64(row1, row2);\n                    __m128i col2 = _mm_movehl_epi64(row2, row1);\n\n                    _mm_storeu_si128((__m128i*)&dst[(j + bj) * rows + i + bi], col1);\n                    _mm_storeu_si128((__m128i*)&dst[(j + bj + 4) * rows + i + bi], col2);\n                }\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_6_SSE", "completion": "```cpp\nvoid blocked_matrix_transpose_simd(const int16_t *src, int16_t *dst, size_t rows, size_t cols, size_t block_size) {\n    for (size_t i = 0; i < rows; i += block_size) {\n        for (size_t j = 0; j < cols; j += block_size) {\n            for (size_t bi = 0; bi < block_size && i + bi < rows; ++bi) {\n                for (size_t bj = 0; bj < block_size && j + bj < cols; bj += 8) {\n                    __m128i row = _mm_loadu_si128((__m128i*)&src[(i + bi) * cols + j + bj]);\n                    __m128i row1 = _mm_unpacklo_epi16(row, _mm_setzero_si128());\n                    __m128i row2 = _mm_unpackhi_epi16(row, _mm_setzero_si128());\n                    __m128i transposed1 = _mm_mshuffle_epi32(row1, 0x4E);\n                    __m128i transposed2 = _mm_mshuffle_epi32(row2, 0x4E);\n                    __m128i transposed3 = _mm_shufflelo_epi16(transposed1, 0xB1);\n                    __m128i transposed4 = _mm_shufflelo_epi16(transposed2, 0xB1);\n                    __m128i transposed5 = _mm_shufflehi_epi16(transposed1, 0xB1);\n                    __m128i transposed6 = _mm_shufflehi_epi16(transposed2, 0xB1);\n                    __m128i transposed7 = _mm_packs_epi32(transposed3, transposed4);\n                    __m128i transposed8 = _mm_packs_epi32(transposed5, transposed6);\n                    _mm_storeu_si128((__m128i*)&dst[(j + bj) * rows + i + bi], transposed7);\n                    _mm_storeu_si128((__m128i*)&dst[(j + bj + 4) * rows + i + bi], transposed8);\n                }\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_6_SSE", "completion": "```cpp\nvoid blocked_matrix_transpose_simd(const int16_t *src, int16_t *dst, size_t rows, size_t cols, size_t block_size) {\n    for (size_t i = 0; i < rows; i += block_size) {\n        for (size_t j = 0; j < cols; j += block_size) {\n            for (size_t bi = 0; bi < block_size && i + bi < rows; ++bi) {\n                for (size_t bj = 0; bj < block_size && j + bj < cols; bj += 8) {\n                    __m128i row = _mm_loadu_si128((__m128i const*)(src + (i + bi) * cols + j + bj));\n                    __m128i row1 = _mm_unpacklo_epi16(row, _mm_setzero_si128());\n                    __m128i row2 = _mm_unpackhi_epi16(row, _mm_setzero_si128());\n                    __m128i col1 = _mm_movelh_epi64(row1, row2);\n                    __m128i col2 = _mm_movehl_epi64(row2, row1);\n                    _mm_storeu_si128((__m128i*)(dst + (j + bj) * rows + i + bi), col1);\n                    _mm_storeu_si128((__m128i*)(dst + (j + bj + 4) * rows + i + bi), col2);\n                }\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_6_SSE", "completion": "```cpp\nvoid blocked_matrix_transpose_simd(const int16_t *src, int16_t *dst, size_t rows, size_t cols, size_t block_size) {\n    for (size_t i = 0; i < rows; i += block_size) {\n        for (size_t j = 0; j < cols; j += block_size) {\n            for (size_t bi = 0; bi < block_size && i + bi < rows; ++bi) {\n                for (size_t bj = 0; bj < block_size && j + bj < cols; bj += 8) {\n                    __m128i row = _mm_loadu_si128((__m128i*)&src[(i + bi) * cols + j + bj]);\n                    __m128i row1 = _mm_unpacklo_epi16(row, _mm_setzero_si128());\n                    __m128i row2 = _mm_unpackhi_epi16(row, _mm_setzero_si128());\n                    __m128i transposed1 = _mm_mshuffle_epi32(row1, 0x4E);\n                    __m128i transposed2 = _mm_mshuffle_epi32(row2, 0x4E);\n                    __m128i transposed3 = _mm_shufflelo_epi16(transposed1, 0xB1);\n                    __m128i transposed4 = _mm_shufflelo_epi16(transposed2, 0xB1);\n                    __m128i transposed5 = _mm_shufflehi_epi16(transposed1, 0xB1);\n                    __m128i transposed6 = _mm_shufflehi_epi16(transposed2, 0xB1);\n                    __m128i transposed7 = _mm_packs_epi32(transposed3, transposed4);\n                    __m128i transposed8 = _mm_packs_epi32(transposed5, transposed6);\n                    _mm_storeu_si128((__m128i*)&dst[(j + bj) * rows + i + bi], transposed7);\n                    _mm_storeu_si128((__m128i*)&dst[(j + bj + 4) * rows + i + bi], transposed8);\n                }\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_7_SSE", "completion": "```cpp\nfloat diagonal_sum_3d_simd(const float *array, size_t dim) {\n    __m128 sum = _mm_setzero_ps();\n    for (size_t i = 0; i < dim; i += 4) {\n        __m128 values = _mm_loadu_ps(&array[i * dim * dim + i * dim + i]);\n        sum = _mm_add_ps(sum, values);\n    }\n    float result[4];\n    _mm_storeu_ps(result, sum);\n    return result[0] + result[1] + result[2] + result[3];\n}\n```"}
{"task_id": "SimdBench_7_SSE", "completion": "```cpp\nfloat diagonal_sum_3d_simd(const float *array, size_t dim) {\n    __m128 sum = _mm_setzero_ps();\n    for (size_t i = 0; i < dim; i += 4) {\n        __m128 values = _mm_loadu_ps(&array[i * dim * dim + i * dim + i]);\n        sum = _mm_add_ps(sum, values);\n    }\n    float result[4];\n    _mm_storeu_ps(result, sum);\n    return result[0] + result[1] + result[2] + result[3];\n}\n```"}
{"task_id": "SimdBench_7_SSE", "completion": "```cpp\nfloat diagonal_sum_3d_simd(const float *array, size_t dim) {\n    __m128 sum = _mm_setzero_ps();\n    for (size_t i = 0; i < dim; i += 4) {\n        __m128 values = _mm_loadu_ps(&array[i * dim * dim + i * dim + i]);\n        sum = _mm_add_ps(sum, values);\n    }\n    float result[4];\n    _mm_storeu_ps(result, sum);\n    return result[0] + result[1] + result[2] + result[3];\n}\n```"}
{"task_id": "SimdBench_7_SSE", "completion": "```cpp\nfloat diagonal_sum_3d_simd(const float *array, size_t dim) {\n    __m128 sum = _mm_setzero_ps();\n    for (size_t i = 0; i < dim; i += 4) {\n        __m128 values = _mm_loadu_ps(&array[i * dim * dim + i * dim + i]);\n        sum = _mm_add_ps(sum, values);\n    }\n    float result[4];\n    _mm_storeu_ps(result, sum);\n    return result[0] + result[1] + result[2] + result[3];\n}\n```"}
{"task_id": "SimdBench_7_SSE", "completion": "```cpp\nfloat diagonal_sum_3d_simd(const float *array, size_t dim) {\n    __m128 sum = _mm_setzero_ps();\n    for (size_t i = 0; i < dim; i += 4) {\n        __m128 values = _mm_loadu_ps(&array[i * dim * dim + i * dim + i]);\n        sum = _mm_add_ps(sum, values);\n    }\n    float result[4];\n    _mm_storeu_ps(result, sum);\n    return result[0] + result[1] + result[2] + result[3];\n}\n```"}
{"task_id": "SimdBench_8_SSE", "completion": "```cpp\nvoid conditional_scale_simd(const double *src, double *dst, size_t rows, size_t cols, double threshold, double scale) {\n    __m128d threshold_vec = _mm_set1_pd(threshold);\n    __m128d scale_vec = _mm_set1_pd(scale);\n\n    for (size_t i = 0; i < rows; ++i) {\n        for (size_t j = 0; j < cols; j += 2) {\n            __m128d src_vec = _mm_loadu_pd(&src[i * cols + j]);\n            __m128d mask = _mm_cmpgt_pd(src_vec, threshold_vec);\n            __m128d scaled_vec = _mm_mul_pd(src_vec, scale_vec);\n            __m128d result_vec = _mm_blendv_pd(src_vec, scaled_vec, mask);\n            _mm_storeu_pd(&dst[i * cols + j], result_vec);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_8_SSE", "completion": "```cpp\nvoid conditional_scale_simd(const double *src, double *dst, size_t rows, size_t cols, double threshold, double scale) {\n    __m128d threshold_vec = _mm_set1_pd(threshold);\n    __m128d scale_vec = _mm_set1_pd(scale);\n\n    for (size_t i = 0; i < rows; ++i) {\n        for (size_t j = 0; j < cols; j += 2) {\n            __m128d src_vec = _mm_loadu_pd(&src[i * cols + j]);\n            __m128d mask = _mm_cmpgt_pd(src_vec, threshold_vec);\n            __m128d scaled_vec = _mm_mul_pd(src_vec, scale_vec);\n            __m128d result_vec = _mm_blendv_pd(src_vec, scaled_vec, mask);\n            _mm_storeu_pd(&dst[i * cols + j], result_vec);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_8_SSE", "completion": "```cpp\nvoid conditional_scale_simd(const double *src, double *dst, size_t rows, size_t cols, double threshold, double scale) {\n    __m128d threshold_vec = _mm_set1_pd(threshold);\n    __m128d scale_vec = _mm_set1_pd(scale);\n\n    for (size_t i = 0; i < rows; ++i) {\n        for (size_t j = 0; j < cols; j += 2) {\n            __m128d src_vec = _mm_loadu_pd(&src[i * cols + j]);\n            __m128d mask = _mm_cmpgt_pd(src_vec, threshold_vec);\n            __m128d scaled_vec = _mm_mul_pd(src_vec, scale_vec);\n            __m128d result_vec = _mm_blendv_pd(src_vec, scaled_vec, mask);\n            _mm_storeu_pd(&dst[i * cols + j], result_vec);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_8_SSE", "completion": "```cpp\nvoid conditional_scale_simd(const double *src, double *dst, size_t rows, size_t cols, double threshold, double scale) {\n    __m128d threshold_vec = _mm_set1_pd(threshold);\n    __m128d scale_vec = _mm_set1_pd(scale);\n\n    for (size_t i = 0; i < rows; ++i) {\n        for (size_t j = 0; j < cols; j += 2) {\n            __m128d src_vec = _mm_loadu_pd(&src[i * cols + j]);\n            __m128d mask = _mm_cmpgt_pd(src_vec, threshold_vec);\n            __m128d scaled_vec = _mm_mul_pd(src_vec, scale_vec);\n            __m128d result_vec = _mm_blendv_pd(src_vec, scaled_vec, mask);\n            _mm_storeu_pd(&dst[i * cols + j], result_vec);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_8_SSE", "completion": "```cpp\nvoid conditional_scale_simd(const double *src, double *dst, size_t rows, size_t cols, double threshold, double scale) {\n    __m128d threshold_vec = _mm_set1_pd(threshold);\n    __m128d scale_vec = _mm_set1_pd(scale);\n\n    for (size_t i = 0; i < rows; ++i) {\n        for (size_t j = 0; j < cols; j += 2) {\n            __m128d src_vec = _mm_loadu_pd(&src[i * cols + j]);\n            __m128d mask = _mm_cmpgt_pd(src_vec, threshold_vec);\n            __m128d scaled_vec = _mm_mul_pd(src_vec, scale_vec);\n            __m128d result_vec = _mm_blendv_pd(src_vec, scaled_vec, mask);\n            _mm_storeu_pd(&dst[i * cols + j], result_vec);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_9_SSE", "completion": "```cpp\nvoid reorder_matrix_rows_simd(const double *src, double *dst, size_t rows, size_t cols, const size_t *indices) {\n    for (size_t i = 0; i < rows; ++i) {\n        size_t index = indices[i];\n        for (size_t j = 0; j < cols; j += 2) {\n            __m128d row = _mm_loadu_pd(&src[index * cols + j]);\n            _mm_storeu_pd(&dst[i * cols + j], row);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_9_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid reorder_matrix_rows_simd(const double *src, double *dst, size_t rows, size_t cols, const size_t *indices) {\n    for (size_t i = 0; i < rows; ++i) {\n        size_t idx = indices[i];\n        for (size_t j = 0; j < cols; j += 2) {\n            __m128d row = _mm_loadu_pd(&src[idx * cols + j]);\n            _mm_storeu_pd(&dst[i * cols + j], row);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_9_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid reorder_matrix_rows_simd(const double *src, double *dst, size_t rows, size_t cols, const size_t *indices) {\n    for (size_t i = 0; i < rows; ++i) {\n        size_t index = indices[i];\n        for (size_t j = 0; j < cols; j += 2) {\n            __m128d row = _mm_loadu_pd(&src[index * cols + j]);\n            _mm_storeu_pd(&dst[i * cols + j], row);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_9_SSE", "completion": "```cpp\nvoid reorder_matrix_rows_simd(const double *src, double *dst, size_t rows, size_t cols, const size_t *indices) {\n    for (size_t i = 0; i < rows; ++i) {\n        size_t idx = indices[i];\n        for (size_t j = 0; j < cols; j += 2) {\n            __m128d row = _mm_loadu_pd(&src[idx * cols + j]);\n            _mm_storeu_pd(&dst[i * cols + j], row);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_9_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid reorder_matrix_rows_simd(const double *src, double *dst, size_t rows, size_t cols, const size_t *indices) {\n    for (size_t i = 0; i < rows; ++i) {\n        size_t index = indices[i];\n        for (size_t j = 0; j < cols; j += 2) {\n            __m128d row = _mm_loadu_pd(&src[index * cols + j]);\n            _mm_storeu_pd(&dst[i * cols + j], row);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_10_SSE", "completion": "```cpp\nvoid vector_vector_add_simd(const int64_t *src1, const int64_t *src2, int64_t *dst, int64_t scalar, size_t length) {\n    __m128i scalar_vec = _mm_set1_epi64x(scalar);\n    for (size_t i = 0; i < length; i += 2) {\n        __m128i vec1 = _mm_loadu_si128((__m128i*)&src1[i]);\n        __m128i vec2 = _mm_loadu_si128((__m128i*)&src2[i]);\n        __m128i sum = _mm_add_epi64(vec1, vec2);\n        __m128i result = _mm_add_epi64(sum, scalar_vec);\n        __m128i final_result = _mm_srli_epi64(result, 1);\n        _mm_storeu_si128((__m128i*)&dst[i], final_result);\n    }\n}\n```"}
{"task_id": "SimdBench_10_SSE", "completion": "```cpp\nvoid vector_vector_add_simd(const int64_t *src1, const int64_t *src2, int64_t *dst, int64_t scalar, size_t length) {\n    __m128i scalar_vec = _mm_set1_epi64x(scalar);\n    for (size_t i = 0; i < length; i += 2) {\n        __m128i vec1 = _mm_loadu_si128((__m128i*)&src1[i]);\n        __m128i vec2 = _mm_loadu_si128((__m128i*)&src2[i]);\n        __m128i sum = _mm_add_epi64(vec1, vec2);\n        __m128i result = _mm_add_epi64(sum, scalar_vec);\n        __m128i final_result = _mm_srli_epi64(result, 1);\n        _mm_storeu_si128((__m128i*)&dst[i], final_result);\n    }\n}\n```"}
{"task_id": "SimdBench_10_SSE", "completion": "```cpp\nvoid vector_vector_add_simd(const int64_t *src1, const int64_t *src2, int64_t *dst, int64_t scalar, size_t length) {\n    __m128i scalar_vec = _mm_set1_epi64x(scalar);\n    size_t i;\n    for (i = 0; i <= length - 2; i += 2) {\n        __m128i vec1 = _mm_loadu_si128((__m128i*)&src1[i]);\n        __m128i vec2 = _mm_loadu_si128((__m128i*)&src2[i]);\n        __m128i sum = _mm_add_epi64(vec1, vec2);\n        __m128i result = _mm_add_epi64(sum, scalar_vec);\n        result = _mm_srli_epi64(result, 1);\n        _mm_storeu_si128((__m128i*)&dst[i], result);\n    }\n    for (; i < length; ++i) {\n        dst[i] = (src1[i] + src2[i] + scalar) / 2;\n    }\n}\n```"}
{"task_id": "SimdBench_10_SSE", "completion": "```cpp\nvoid vector_vector_add_simd(const int64_t *src1, const int64_t *src2, int64_t *dst, int64_t scalar, size_t length) {\n    __m128i scalar_vec = _mm_set1_epi64x(scalar);\n    size_t i;\n    for (i = 0; i <= length - 2; i += 2) {\n        __m128i vec1 = _mm_loadu_si128((__m128i*)&src1[i]);\n        __m128i vec2 = _mm_loadu_si128((__m128i*)&src2[i]);\n        __m128i sum = _mm_add_epi64(vec1, vec2);\n        __m128i result = _mm_add_epi64(sum, scalar_vec);\n        result = _mm_srli_epi64(result, 1);\n        _mm_storeu_si128((__m128i*)&dst[i], result);\n    }\n    for (; i < length; ++i) {\n        dst[i] = (src1[i] + src2[i] + scalar) / 2;\n    }\n}\n```"}
{"task_id": "SimdBench_10_SSE", "completion": "```cpp\nvoid vector_vector_add_simd(const int64_t *src1, const int64_t *src2, int64_t *dst, int64_t scalar, size_t length) {\n    __m128i scalar_vec = _mm_set1_epi64x(scalar);\n    for (size_t i = 0; i < length; i += 2) {\n        __m128i vec1 = _mm_loadu_si128((__m128i*)&src1[i]);\n        __m128i vec2 = _mm_loadu_si128((__m128i*)&src2[i]);\n        __m128i sum = _mm_add_epi64(vec1, vec2);\n        __m128i result = _mm_add_epi64(sum, scalar_vec);\n        __m128i final_result = _mm_srli_epi64(result, 1);\n        _mm_storeu_si128((__m128i*)&dst[i], final_result);\n    }\n}\n```"}
{"task_id": "SimdBench_11_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint vector_even_min_simd(const int *src, size_t length){\n    if (length == 0) return -1;\n\n    __m128i min_val = _mm_set1_epi32(src[0]);\n    size_t i = 0;\n\n    for (; i <= length - 4; i += 4) {\n        __m128i data = _mm_loadu_si128((__m128i const*)(src + i));\n        __m128i even_elements = _mm_shuffle_epi32(data, _MM_SHUFFLE(2, 0, 2, 0));\n        min_val = _mm_min_epi32(min_val, even_elements);\n    }\n\n    int result[4];\n    _mm_storeu_si128((__m128i*)result, min_val);\n\n    int min_result = result[0];\n    for (; i < length; i += 2) {\n        if (src[i] < min_result) {\n            min_result = src[i];\n        }\n    }\n\n    return min_result;\n}\n```"}
{"task_id": "SimdBench_11_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint vector_even_min_simd(const int *src, size_t length){\n    if (length == 0) return -1;\n\n    __m128i min_val = _mm_set1_epi32(src[0]);\n    size_t i = 0;\n\n    for (; i <= length - 4; i += 4) {\n        __m128i data = _mm_loadu_si128((__m128i*)&src[i]);\n        __m128i even_elements = _mm_shuffle_epi32(data, _MM_SHUFFLE(2, 0, 2, 0));\n        min_val = _mm_min_epi32(min_val, even_elements);\n    }\n\n    int result[4];\n    _mm_storeu_si128((__m128i*)result, min_val);\n\n    int min_result = result[0];\n    for (; i < length; i += 2) {\n        if (src[i] < min_result) {\n            min_result = src[i];\n        }\n    }\n\n    return min_result;\n}\n```"}
{"task_id": "SimdBench_11_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint vector_even_min_simd(const int *src, size_t length){\n    if (length == 0) return -1;\n\n    __m128i min_val = _mm_set1_epi32(src[0]);\n    size_t i = 0;\n\n    for (; i <= length - 4; i += 4) {\n        __m128i data = _mm_loadu_si128((__m128i const*)(src + i));\n        __m128i even_elements = _mm_shuffle_epi32(data, _MM_SHUFFLE(2, 0, 2, 0));\n        min_val = _mm_min_epi32(min_val, even_elements);\n    }\n\n    int result[4];\n    _mm_storeu_si128((__m128i*)result, min_val);\n\n    int min_result = result[0];\n    for (; i < length; i += 2) {\n        if (src[i] < min_result) {\n            min_result = src[i];\n        }\n    }\n\n    return min_result;\n}\n```"}
{"task_id": "SimdBench_11_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint vector_even_min_simd(const int *src, size_t length){\n    if (length == 0) return -1;\n\n    __m128i min_val = _mm_set1_epi32(src[0]);\n    size_t i = 0;\n\n    for (; i <= length - 4; i += 4) {\n        __m128i data = _mm_loadu_si128((__m128i*)&src[i]);\n        __m128i even_elements = _mm_shuffle_epi32(data, _MM_SHUFFLE(2, 0, 2, 0));\n        min_val = _mm_min_epi32(min_val, even_elements);\n    }\n\n    int result[4];\n    _mm_storeu_si128((__m128i*)result, min_val);\n\n    int min_result = result[0];\n    for (; i < length; i += 2) {\n        if (src[i] < min_result) {\n            min_result = src[i];\n        }\n    }\n\n    return min_result;\n}\n```"}
{"task_id": "SimdBench_11_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint vector_even_min_simd(const int *src, size_t length){\n    if (length == 0) return -1;\n\n    __m128i min_val = _mm_set1_epi32(src[0]);\n    size_t i = 0;\n\n    for (; i <= length - 4; i += 4) {\n        __m128i data = _mm_loadu_si128((__m128i*)&src[i]);\n        __m128i even_elements = _mm_shuffle_epi32(data, _MM_SHUFFLE(2, 0, 2, 0));\n        min_val = _mm_min_epi32(min_val, even_elements);\n    }\n\n    int result[4];\n    _mm_storeu_si128((__m128i*)result, min_val);\n\n    int min_result = result[0];\n    for (; i < length; i += 2) {\n        if (src[i] < min_result) {\n            min_result = src[i];\n        }\n    }\n\n    return min_result;\n}\n```"}
{"task_id": "SimdBench_12_SSE", "completion": "```cpp\nvoid mixed_right_shift_simd(const int *src, int *dst, uint8_t shift, size_t length) {\n    size_t i = 0;\n    __m128i shift_mask = _mm_set1_epi32(shift);\n    __m128i zero = _mm_setzero_si128();\n\n    for (; i <= length - 4; i += 4) {\n        __m128i src_vec = _mm_loadu_si128((__m128i const*)(src + i));\n        __m128i arith_shift = _mm_srai_epi32(src_vec, shift);\n        __m128i logic_shift = _mm_srli_epi32(_mm_castsi128_ps(src_vec), shift);\n        __m128i result = _mm_add_epi32(arith_shift, logic_shift);\n        _mm_storeu_si128((__m128i*)(dst + i), result);\n    }\n\n    for (; i < length; ++i) {\n        int arith_shift = src[i] >> shift;\n        int logic_shift = (unsigned int)src[i] >> shift;\n        dst[i] = arith_shift + logic_shift;\n    }\n}\n```"}
{"task_id": "SimdBench_12_SSE", "completion": "```cpp\nvoid mixed_right_shift_simd(const int *src, int *dst, uint8_t shift, size_t length) {\n    size_t i = 0;\n    __m128i shift_mask = _mm_set1_epi32(shift);\n    __m128i zero = _mm_setzero_si128();\n\n    for (; i <= length - 4; i += 4) {\n        __m128i src_vec = _mm_loadu_si128((__m128i const*)(src + i));\n        __m128i arith_shift = _mm_srai_epi32(src_vec, shift);\n\n        // Convert to unsigned for logical shift\n        __m128i logical_shift = _mm_srli_epi32(src_vec, shift);\n\n        // Add the results\n        __m128i result = _mm_add_epi32(arith_shift, logical_shift);\n\n        _mm_storeu_si128((__m128i*)(dst + i), result);\n    }\n\n    // Handle remaining elements\n    for (; i < length; ++i) {\n        int arith_shift = src[i] >> shift;\n        int logical_shift = (unsigned int)src[i] >> shift;\n        dst[i] = arith_shift + logical_shift;\n    }\n}\n```"}
{"task_id": "SimdBench_12_SSE", "completion": "```cpp\nvoid mixed_right_shift_simd(const int *src, int *dst, uint8_t shift, size_t length) {\n    size_t i = 0;\n    __m128i shift_mask = _mm_set1_epi32(shift);\n    __m128i zero = _mm_setzero_si128();\n\n    for (; i <= length - 4; i += 4) {\n        __m128i src_vec = _mm_loadu_si128((__m128i const*)(src + i));\n\n        // Arithmetic right shift\n        __m128i arith_shifted = _mm_srai_epi32(src_vec, shift);\n\n        // Logical right shift\n        __m128i logic_shifted = _mm_srli_epi32(src_vec, shift);\n\n        // Add the results\n        __m128i result = _mm_add_epi32(arith_shifted, logic_shifted);\n\n        _mm_storeu_si128((__m128i*)(dst + i), result);\n    }\n\n    // Handle remaining elements\n    for (; i < length; ++i) {\n        int arith_shifted = src[i] >> shift;\n        int logic_shifted = (unsigned int)src[i] >> shift;\n        dst[i] = arith_shifted + logic_shifted;\n    }\n}\n```"}
{"task_id": "SimdBench_12_SSE", "completion": "```cpp\nvoid mixed_right_shift_simd(const int *src, int *dst, uint8_t shift, size_t length) {\n    size_t i = 0;\n    __m128i shift_mask = _mm_set1_epi32(shift);\n    __m128i zero = _mm_setzero_si128();\n\n    for (; i <= length - 4; i += 4) {\n        __m128i src_vec = _mm_loadu_si128((__m128i const*)(src + i));\n        __m128i arith_shift = _mm_srai_epi32(src_vec, shift);\n\n        // Convert to unsigned for logical shift\n        __m128i logical_shift = _mm_srli_epi32(src_vec, shift);\n\n        // Add the results\n        __m128i result = _mm_add_epi32(arith_shift, logical_shift);\n\n        _mm_storeu_si128((__m128i*)(dst + i), result);\n    }\n\n    // Handle remaining elements\n    for (; i < length; ++i) {\n        int arith_shift = src[i] >> shift;\n        int logical_shift = (unsigned int)src[i] >> shift;\n        dst[i] = arith_shift + logical_shift;\n    }\n}\n```"}
{"task_id": "SimdBench_12_SSE", "completion": "```cpp\nvoid mixed_right_shift_simd(const int *src, int *dst, uint8_t shift, size_t length) {\n    size_t i = 0;\n    __m128i shift_mask = _mm_set1_epi32(shift);\n    __m128i zero = _mm_setzero_si128();\n\n    for (; i <= length - 4; i += 4) {\n        __m128i src_vec = _mm_loadu_si128((__m128i const*)(src + i));\n\n        // Arithmetic right shift\n        __m128i arith_shift = _mm_srai_epi32(src_vec, shift);\n\n        // Logical right shift\n        __m128i logic_shift = _mm_srli_epi32(src_vec, shift);\n\n        // Add the results\n        __m128i result = _mm_add_epi32(arith_shift, logic_shift);\n\n        _mm_storeu_si128((__m128i*)(dst + i), result);\n    }\n\n    // Handle remaining elements\n    for (; i < length; ++i) {\n        int arith_shift = src[i] >> shift;\n        int logic_shift = (unsigned int)src[i] >> shift;\n        dst[i] = arith_shift + logic_shift;\n    }\n}\n```"}
{"task_id": "SimdBench_13_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint64_t matrix_sum_simd(const int *matrix, size_t rows, size_t cols) {\n    __m128i sum = _mm_setzero_si128();\n    size_t total_elements = rows * cols;\n    size_t i = 0;\n\n    for (; i <= total_elements - 4; i += 4) {\n        __m128i chunk = _mm_loadu_si128((__m128i const*)(matrix + i));\n        sum = _mm_add_epi32(sum, chunk);\n    }\n\n    int temp[4];\n    _mm_storeu_si128((__m128i*)temp, sum);\n    int64_t result = temp[0] + temp[1] + temp[2] + temp[3];\n\n    for (; i < total_elements; ++i) {\n        result += matrix[i];\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_13_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint64_t matrix_sum_simd(const int *matrix, size_t rows, size_t cols) {\n    __m128i sum = _mm_setzero_si128();\n    size_t total_elements = rows * cols;\n    size_t i = 0;\n\n    for (; i <= total_elements - 4; i += 4) {\n        __m128i chunk = _mm_loadu_si128((__m128i const*)(matrix + i));\n        sum = _mm_add_epi32(sum, chunk);\n    }\n\n    int temp[4];\n    _mm_storeu_si128((__m128i*)temp, sum);\n    int64_t result = temp[0] + temp[1] + temp[2] + temp[3];\n\n    for (; i < total_elements; ++i) {\n        result += matrix[i];\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_13_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint64_t matrix_sum_simd(const int *matrix, size_t rows, size_t cols) {\n    __m128i sum = _mm_setzero_si128();\n    size_t total_elements = rows * cols;\n    size_t i = 0;\n\n    for (; i <= total_elements - 4; i += 4) {\n        __m128i chunk = _mm_loadu_si128((__m128i const*)(matrix + i));\n        sum = _mm_add_epi32(sum, chunk);\n    }\n\n    int32_t sum_array[4];\n    _mm_storeu_si128((__m128i*)sum_array, sum);\n\n    int64_t result = sum_array[0] + sum_array[1] + sum_array[2] + sum_array[3];\n\n    for (; i < total_elements; ++i) {\n        result += matrix[i];\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_13_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint64_t matrix_sum_simd(const int *matrix, size_t rows, size_t cols) {\n    __m128i sum = _mm_setzero_si128();\n    size_t total_elements = rows * cols;\n    size_t i = 0;\n\n    for (; i <= total_elements - 4; i += 4) {\n        __m128i chunk = _mm_loadu_si128((__m128i const*)(matrix + i));\n        sum = _mm_add_epi32(sum, chunk);\n    }\n\n    int temp[4];\n    _mm_storeu_si128((__m128i*)temp, sum);\n    int64_t result = temp[0] + temp[1] + temp[2] + temp[3];\n\n    for (; i < total_elements; ++i) {\n        result += matrix[i];\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_13_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint64_t matrix_sum_simd(const int *matrix, size_t rows, size_t cols) {\n    __m128i sum = _mm_setzero_si128();\n    size_t total_elements = rows * cols;\n    size_t i = 0;\n\n    for (; i <= total_elements - 4; i += 4) {\n        __m128i chunk = _mm_loadu_si128((__m128i const*)(matrix + i));\n        sum = _mm_add_epi32(sum, chunk);\n    }\n\n    int temp[4];\n    _mm_storeu_si128((__m128i*)temp, sum);\n    int64_t result = temp[0] + temp[1] + temp[2] + temp[3];\n\n    for (; i < total_elements; ++i) {\n        result += matrix[i];\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_14_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nsize_t argmax_simd(const int8_t *src, size_t length) {\n    if (length == 0) return 0;\n\n    __m128i max_val = _mm_set1_epi8(src[0]);\n    __m128i max_idx = _mm_set1_epi32(0);\n    __m128i idx = _mm_setr_epi32(0, 1, 2, 3, 4, 5, 6, 7);\n    __m128i step = _mm_set1_epi32(8);\n\n    size_t i = 0;\n    for (; i <= length - 8; i += 8) {\n        __m128i current = _mm_loadu_si128((__m128i const*)(src + i));\n        __m128i mask = _mm_cmpgt_epi8(current, max_val);\n        max_val = _mm_max_epi8(max_val, current);\n        __m128i new_idx = _mm_blendv_epi8(max_idx, idx, mask);\n        max_idx = new_idx;\n        idx = _mm_add_epi32(idx, step);\n    }\n\n    int8_t max_array[16];\n    int32_t idx_array[4];\n    _mm_storeu_si128((__m128i*)max_array, max_val);\n    _mm_storeu_si128((__m128i*)idx_array, max_idx);\n\n    int8_t max_scalar = max_array[0];\n    size_t result = idx_array[0];\n    for (size_t j = 1; j < 8 && i - 8 + j < length; ++j) {\n        if (max_array[j] > max_scalar) {\n            max_scalar = max_array[j];\n            result = idx_array[j / 4] + (j % 4);\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_14_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nsize_t argmax_simd(const int8_t *src, size_t length) {\n    if (length == 0) return 0;\n\n    __m128i max_val = _mm_set1_epi8(src[0]);\n    __m128i max_idx = _mm_set1_epi32(0);\n    __m128i idx = _mm_setr_epi32(0, 1, 2, 3, 4, 5, 6, 7);\n    __m128i step = _mm_set1_epi32(8);\n\n    size_t i = 0;\n    for (; i <= length - 8; i += 8) {\n        __m128i current = _mm_loadu_si128((__m128i const*)(src + i));\n        __m128i mask = _mm_cmpgt_epi8(current, max_val);\n        max_val = _mm_max_epi8(max_val, current);\n        __m128i new_idx = _mm_add_epi32(idx, _mm_and_si128(mask, _mm_set1_epi32(i)));\n        max_idx = _mm_blendv_epi8(max_idx, new_idx, mask);\n        idx = _mm_add_epi32(idx, step);\n    }\n\n    int8_t max_array[16];\n    int32_t idx_array[4];\n    _mm_storeu_si128((__m128i*)max_array, max_val);\n    _mm_storeu_si128((__m128i*)idx_array, max_idx);\n\n    int8_t max_scalar = max_array[0];\n    size_t result = idx_array[0];\n    for (size_t j = 1; j < 8 && i - 8 + j < length; ++j) {\n        if (max_array[j] > max_scalar) {\n            max_scalar = max_array[j];\n            result = idx_array[j / 4] + (j % 4);\n        }\n    }\n\n    for (; i < length; ++i) {\n        if (src[i] > max_scalar) {\n            max_scalar = src[i];\n            result = i;\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_14_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nsize_t argmax_simd(const int8_t *src, size_t length) {\n    if (length == 0) return 0;\n\n    __m128i max_val = _mm_set1_epi8(src[0]);\n    __m128i max_idx = _mm_set1_epi32(0);\n    __m128i idx = _mm_setr_epi32(0, 1, 2, 3, 4, 5, 6, 7);\n    __m128i step = _mm_set1_epi32(8);\n\n    size_t i = 0;\n    for (; i <= length - 8; i += 8) {\n        __m128i current = _mm_loadu_si128((__m128i const*)(src + i));\n        __m128i mask = _mm_cmpgt_epi8(current, max_val);\n        max_val = _mm_max_epi8(max_val, current);\n        __m128i new_idx = _mm_blendv_epi8(max_idx, idx, mask);\n        max_idx = new_idx;\n        idx = _mm_add_epi32(idx, step);\n    }\n\n    int8_t max_array[16];\n    int32_t idx_array[4];\n    _mm_storeu_si128((__m128i*)max_array, max_val);\n    _mm_storeu_si128((__m128i*)idx_array, max_idx);\n\n    int8_t max_scalar = max_array[0];\n    size_t result = idx_array[0];\n    for (size_t j = 1; j < 8 && i - 8 + j < length; ++j) {\n        if (max_array[j] > max_scalar) {\n            max_scalar = max_array[j];\n            result = idx_array[j / 4] + (j % 4);\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_14_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nsize_t argmax_simd(const int8_t *src, size_t length) {\n    if (length == 0) return 0;\n\n    __m128i max_val = _mm_set1_epi8(src[0]);\n    __m128i max_idx = _mm_set1_epi32(0);\n    __m128i idx = _mm_setr_epi32(0, 1, 2, 3, 4, 5, 6, 7);\n    __m128i step = _mm_set1_epi32(8);\n\n    size_t i = 0;\n    for (; i <= length - 8; i += 8) {\n        __m128i current = _mm_loadu_si128((__m128i const*)(src + i));\n        __m128i mask = _mm_cmpgt_epi8(current, max_val);\n        max_val = _mm_max_epi8(max_val, current);\n        __m128i new_idx = _mm_add_epi32(idx, _mm_and_si128(mask, _mm_set1_epi32(i)));\n        max_idx = _mm_blendv_epi8(max_idx, new_idx, mask);\n        idx = _mm_add_epi32(idx, step);\n    }\n\n    int8_t max_array[16];\n    int32_t idx_array[4];\n    _mm_storeu_si128((__m128i*)max_array, max_val);\n    _mm_storeu_si128((__m128i*)idx_array, max_idx);\n\n    int8_t max_scalar = max_array[0];\n    size_t result = idx_array[0];\n    for (size_t j = 1; j < 8 && i - 8 + j < length; ++j) {\n        if (max_array[j] > max_scalar) {\n            max_scalar = max_array[j];\n            result = idx_array[j / 4] + (j % 4);\n        }\n    }\n\n    for (; i < length; ++i) {\n        if (src[i] > max_scalar) {\n            max_scalar = src[i];\n            result = i;\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_14_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nsize_t argmax_simd(const int8_t *src, size_t length) {\n    if (length == 0) return 0;\n\n    __m128i max_val = _mm_set1_epi8(src[0]);\n    __m128i max_idx = _mm_set1_epi32(0);\n    __m128i idx = _mm_setr_epi32(0, 1, 2, 3, 4, 5, 6, 7);\n    __m128i step = _mm_set1_epi32(8);\n\n    size_t i = 0;\n    for (; i <= length - 8; i += 8) {\n        __m128i current = _mm_loadu_si128((__m128i const*)(src + i));\n        __m128i mask = _mm_cmpgt_epi8(current, max_val);\n        max_val = _mm_max_epi8(max_val, current);\n        __m128i new_idx = _mm_add_epi32(idx, _mm_and_si128(mask, _mm_set1_epi32(i)));\n        max_idx = _mm_blendv_epi8(max_idx, new_idx, mask);\n        idx = _mm_add_epi32(idx, step);\n    }\n\n    int8_t max_array[16];\n    int32_t idx_array[4];\n    _mm_storeu_si128((__m128i*)max_array, max_val);\n    _mm_storeu_si128((__m128i*)idx_array, max_idx);\n\n    int8_t max_scalar = max_array[0];\n    size_t result = idx_array[0];\n    for (size_t j = 1; j < 8 && i - 8 + j < length; ++j) {\n        if (max_array[j] > max_scalar) {\n            max_scalar = max_array[j];\n            result = idx_array[j / 4] + (j % 4);\n        }\n    }\n\n    for (; i < length; ++i) {\n        if (src[i] > max_scalar) {\n            max_scalar = src[i];\n            result = i;\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_15_SSE", "completion": "```cpp\nvoid vector_blend_simd(const uint16_t* src1, const uint16_t* src2, uint32_t mask, uint16_t* dst, size_t length) {\n    __m128i mask_vec = _mm_set1_epi16(mask);\n    size_t i = 0;\n    for (; i <= length - 8; i += 8) {\n        __m128i index_vec = _mm_setr_epi16(i, i+1, i+2, i+3, i+4, i+5, i+6, i+7);\n        __m128i and_result = _mm_and_si128(index_vec, mask_vec);\n        __m128i mask_cmp = _mm_cmpeq_epi16(and_result, _mm_setzero_si128());\n        __m128i src1_vec = _mm_loadu_si128((__m128i*)(src1 + i));\n        __m128i src2_vec = _mm_loadu_si128((__m128i*)(src2 + i));\n        __m128i blended_vec = _mm_blendv_epi8(src2_vec, src1_vec, mask_cmp);\n        _mm_storeu_si128((__m128i*)(dst + i), blended_vec);\n    }\n    for (; i < length; ++i) {\n        dst[i] = ((i & mask) != 0) ? src1[i] : src2[i];\n    }\n}\n```"}
{"task_id": "SimdBench_15_SSE", "completion": "```cpp\nvoid vector_blend_simd(const uint16_t* src1, const uint16_t* src2, uint32_t mask, uint16_t* dst, size_t length) {\n    __m128i mask_vec = _mm_set1_epi16(mask);\n    size_t i = 0;\n    for (; i <= length - 8; i += 8) {\n        __m128i index_vec = _mm_setr_epi16(i, i+1, i+2, i+3, i+4, i+5, i+6, i+7);\n        __m128i and_result = _mm_and_si128(index_vec, mask_vec);\n        __m128i mask_cmp = _mm_cmpeq_epi16(and_result, _mm_setzero_si128());\n        __m128i src1_vec = _mm_loadu_si128((__m128i*)(src1 + i));\n        __m128i src2_vec = _mm_loadu_si128((__m128i*)(src2 + i));\n        __m128i blended_vec = _mm_blendv_epi8(src2_vec, src1_vec, mask_cmp);\n        _mm_storeu_si128((__m128i*)(dst + i), blended_vec);\n    }\n    for (; i < length; ++i) {\n        dst[i] = ((i & mask) != 0) ? src1[i] : src2[i];\n    }\n}\n```"}
{"task_id": "SimdBench_15_SSE", "completion": "```cpp\nvoid vector_blend_simd(const uint16_t* src1, const uint16_t* src2, uint32_t mask, uint16_t* dst, size_t length) {\n    __m128i mask_vec = _mm_set1_epi16(mask);\n    size_t i = 0;\n    for (; i <= length - 8; i += 8) {\n        __m128i index_vec = _mm_setr_epi16(i, i+1, i+2, i+3, i+4, i+5, i+6, i+7);\n        __m128i and_result = _mm_and_si128(index_vec, mask_vec);\n        __m128i mask_cmp = _mm_cmpeq_epi16(and_result, _mm_setzero_si128());\n        __m128i src1_vec = _mm_loadu_si128((__m128i*)(src1 + i));\n        __m128i src2_vec = _mm_loadu_si128((__m128i*)(src2 + i));\n        __m128i blended_vec = _mm_blendv_epi8(src2_vec, src1_vec, mask_cmp);\n        _mm_storeu_si128((__m128i*)(dst + i), blended_vec);\n    }\n    for (; i < length; ++i) {\n        dst[i] = ((i & mask) != 0) ? src1[i] : src2[i];\n    }\n}\n```"}
{"task_id": "SimdBench_15_SSE", "completion": "```cpp\nvoid vector_blend_simd(const uint16_t* src1, const uint16_t* src2, uint32_t mask, uint16_t* dst, size_t length) {\n    __m128i mask_vec = _mm_set1_epi16(mask);\n    size_t i = 0;\n    for (; i <= length - 8; i += 8) {\n        __m128i index_vec = _mm_setr_epi16(i, i+1, i+2, i+3, i+4, i+5, i+6, i+7);\n        __m128i and_result = _mm_and_si128(index_vec, mask_vec);\n        __m128i mask_cmp = _mm_cmpeq_epi16(and_result, _mm_setzero_si128());\n        __m128i src1_vec = _mm_loadu_si128((__m128i*)(src1 + i));\n        __m128i src2_vec = _mm_loadu_si128((__m128i*)(src2 + i));\n        __m128i blended_vec = _mm_blendv_epi8(src2_vec, src1_vec, mask_cmp);\n        _mm_storeu_si128((__m128i*)(dst + i), blended_vec);\n    }\n    for (; i < length; ++i) {\n        dst[i] = ((i & mask) != 0) ? src1[i] : src2[i];\n    }\n}\n```"}
{"task_id": "SimdBench_15_SSE", "completion": "```cpp\nvoid vector_blend_simd(const uint16_t* src1, const uint16_t* src2, uint32_t mask, uint16_t* dst, size_t length) {\n    __m128i mask_vec = _mm_set1_epi16(mask);\n    size_t i = 0;\n    for (; i <= length - 8; i += 8) {\n        __m128i index_vec = _mm_setr_epi16(i, i+1, i+2, i+3, i+4, i+5, i+6, i+7);\n        __m128i and_result = _mm_and_si128(index_vec, mask_vec);\n        __m128i mask_cmp = _mm_cmpeq_epi16(and_result, _mm_setzero_si128());\n        __m128i src1_vec = _mm_loadu_si128((__m128i*)(src1 + i));\n        __m128i src2_vec = _mm_loadu_si128((__m128i*)(src2 + i));\n        __m128i blended_vec = _mm_blendv_epi8(src2_vec, src1_vec, mask_cmp);\n        _mm_storeu_si128((__m128i*)(dst + i), blended_vec);\n    }\n    for (; i < length; ++i) {\n        dst[i] = ((i & mask) != 0) ? src1[i] : src2[i];\n    }\n}\n```"}
{"task_id": "SimdBench_16_SSE", "completion": "```cpp\nvoid population_count_simd(const uint32_t* src, uint32_t* dst, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 4; i += 4) {\n        __m128i data = _mm_loadu_si128((__m128i const*)(src + i));\n        __m128i ones = _mm_set1_epi8(1);\n\n        __m128i popcnt = _mm_setzero_si128();\n        for (int j = 0; j < 32; ++j) {\n            __m128i shift = _mm_srli_epi32(data, j);\n            popcnt = _mm_add_epi32(popcnt, _mm_and_si128(shift, ones));\n        }\n\n        _mm_storeu_si128((__m128i*)(dst + i), popcnt);\n    }\n\n    for (; i < length; ++i) {\n        dst[i] = __builtin_popcount(src[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_16_SSE", "completion": "```cpp\nvoid population_count_simd(const uint32_t* src, uint32_t* dst, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 4; i += 4) {\n        __m128i data = _mm_loadu_si128((__m128i const*)(src + i));\n        __m128i ones = _mm_set1_epi8(1);\n        __m128i popcnt = _mm_setzero_si128();\n\n        for (int j = 0; j < 32; ++j) {\n            __m128i shift = _mm_srli_epi32(data, j);\n            popcnt = _mm_add_epi32(popcnt, _mm_and_si128(shift, ones));\n        }\n\n        _mm_storeu_si128((__m128i*)(dst + i), popcnt);\n    }\n\n    for (; i < length; ++i) {\n        dst[i] = __builtin_popcount(src[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_16_SSE", "completion": "```cpp\nvoid population_count_simd(const uint32_t* src, uint32_t* dst, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 4; i += 4) {\n        __m128i data = _mm_loadu_si128((__m128i const*)(src + i));\n        __m128i ones = _mm_set1_epi8(1);\n\n        __m128i popcnt = _mm_setzero_si128();\n        for (int j = 0; j < 32; ++j) {\n            popcnt = _mm_add_epi8(popcnt, _mm_and_si128(data, ones));\n            data = _mm_srli_epi32(data, 1);\n        }\n\n        __m128i popcnt_16bit = _mm_add_epi16(popcnt, _mm_srli_epi16(popcnt, 8));\n        __m128i popcnt_32bit = _mm_add_epi32(popcnt_16bit, _mm_srli_epi32(popcnt_16bit, 16));\n\n        _mm_storeu_si128((__m128i*)(dst + i), _mm_packus_epi32(popcnt_32bit, popcnt_32bit));\n    }\n\n    for (; i < length; ++i) {\n        dst[i] = __builtin_popcount(src[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_16_SSE", "completion": "```cpp\nvoid population_count_simd(const uint32_t* src, uint32_t* dst, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 4; i += 4) {\n        __m128i data = _mm_loadu_si128((__m128i const*)(src + i));\n        __m128i ones = _mm_set1_epi32(1);\n\n        __m128i popcnt = _mm_setzero_si128();\n        for (int j = 0; j < 32; ++j) {\n            __m128i shift = _mm_slli_epi32(data, j);\n            __m128i and_result = _mm_and_si128(shift, ones);\n            popcnt = _mm_add_epi32(popcnt, and_result);\n        }\n\n        _mm_storeu_si128((__m128i*)(dst + i), popcnt);\n    }\n\n    for (; i < length; ++i) {\n        dst[i] = __builtin_popcount(src[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_16_SSE", "completion": "```cpp\nvoid population_count_simd(const uint32_t* src, uint32_t* dst, size_t length) {\n    size_t i = 0;\n    __m128i zero = _mm_setzero_si128();\n    for (; i <= length - 4; i += 4) {\n        __m128i data = _mm_loadu_si128((__m128i const*)(src + i));\n        __m128i ones = _mm_popcnt_epi32(data);\n        _mm_storeu_si128((__m128i*)(dst + i), ones);\n    }\n    for (; i < length; ++i) {\n        dst[i] = __builtin_popcount(src[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_17_SSE", "completion": "```cpp\nvoid saturating_add_simd(const uint16_t* src1, const uint16_t* src2, uint16_t* dst, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 8; i += 8) {\n        __m128i a = _mm_loadu_si128((__m128i*)(src1 + i));\n        __m128i b = _mm_loadu_si128((__m128i*)(src2 + i));\n        __m128i result = _mm_adds_epu16(a, b);\n        _mm_storeu_si128((__m128i*)(dst + i), result);\n    }\n    for (; i < length; ++i) {\n        dst[i] = src1[i] + src2[i] > UINT16_MAX ? UINT16_MAX : src1[i] + src2[i];\n    }\n}\n```"}
{"task_id": "SimdBench_17_SSE", "completion": "```cpp\nvoid saturating_add_simd(const uint16_t* src1, const uint16_t* src2, uint16_t* dst, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 8; i += 8) {\n        __m128i a = _mm_loadu_si128((__m128i*)(src1 + i));\n        __m128i b = _mm_loadu_si128((__m128i*)(src2 + i));\n        __m128i result = _mm_adds_epu16(a, b);\n        _mm_storeu_si128((__m128i*)(dst + i), result);\n    }\n    for (; i < length; ++i) {\n        dst[i] = src1[i] + src2[i] > UINT16_MAX ? UINT16_MAX : src1[i] + src2[i];\n    }\n}\n```"}
{"task_id": "SimdBench_17_SSE", "completion": "```cpp\nvoid saturating_add_simd(const uint16_t* src1, const uint16_t* src2, uint16_t* dst, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 8; i += 8) {\n        __m128i a = _mm_loadu_si128((__m128i*)(src1 + i));\n        __m128i b = _mm_loadu_si128((__m128i*)(src2 + i));\n        __m128i result = _mm_adds_epu16(a, b);\n        _mm_storeu_si128((__m128i*)(dst + i), result);\n    }\n    for (; i < length; ++i) {\n        dst[i] = src1[i] + src2[i] > UINT16_MAX ? UINT16_MAX : src1[i] + src2[i];\n    }\n}\n```"}
{"task_id": "SimdBench_17_SSE", "completion": "```cpp\nvoid saturating_add_simd(const uint16_t* src1, const uint16_t* src2, uint16_t* dst, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 8; i += 8) {\n        __m128i a = _mm_loadu_si128((__m128i*)(src1 + i));\n        __m128i b = _mm_loadu_si128((__m128i*)(src2 + i));\n        __m128i result = _mm_adds_epu16(a, b);\n        _mm_storeu_si128((__m128i*)(dst + i), result);\n    }\n    for (; i < length; ++i) {\n        dst[i] = src1[i] + src2[i] > UINT16_MAX ? UINT16_MAX : src1[i] + src2[i];\n    }\n}\n```"}
{"task_id": "SimdBench_17_SSE", "completion": "```cpp\nvoid saturating_add_simd(const uint16_t* src1, const uint16_t* src2, uint16_t* dst, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 8; i += 8) {\n        __m128i a = _mm_loadu_si128((__m128i*)(src1 + i));\n        __m128i b = _mm_loadu_si128((__m128i*)(src2 + i));\n        __m128i result = _mm_adds_epu16(a, b);\n        _mm_storeu_si128((__m128i*)(dst + i), result);\n    }\n    for (; i < length; ++i) {\n        dst[i] = src1[i] + src2[i] > UINT16_MAX ? UINT16_MAX : src1[i] + src2[i];\n    }\n}\n```"}
{"task_id": "SimdBench_18_SSE", "completion": "```cpp\nvoid range_matrix_mul_simd(const double* A, const double* B, double* C, size_t m, size_t n, size_t p) {\n    __m128d range_min = _mm_set1_pd(-100.0);\n    __m128d range_max = _mm_set1_pd(100.0);\n\n    for (size_t i = 0; i < m; ++i) {\n        for (size_t j = 0; j < p; ++j) {\n            __m128d c_sum = _mm_setzero_pd();\n            for (size_t k = 0; k < n; k += 2) {\n                __m128d a_vals = _mm_loadu_pd(&A[i * n + k]);\n                __m128d b_vals = _mm_loadu_pd(&B[j + k * p]);\n\n                __m128d a_in_range = _mm_and_pd(_mm_cmpge_pd(a_vals, range_min), _mm_cmple_pd(a_vals, range_max));\n                __m128d b_in_range = _mm_and_pd(_mm_cmpge_pd(b_vals, range_min), _mm_cmple_pd(b_vals, range_max));\n\n                __m128d a_masked = _mm_and_pd(a_vals, a_in_range);\n                __m128d b_masked = _mm_and_pd(b_vals, b_in_range);\n\n                __m128d prod = _mm_mul_pd(a_masked, b_masked);\n                c_sum = _mm_add_pd(c_sum, prod);\n            }\n            double c_temp[2];\n            _mm_storeu_pd(c_temp, c_sum);\n            C[i * p + j] = c_temp[0] + c_temp[1];\n\n            // Handle remaining element if n is odd\n            if (n % 2 != 0) {\n                size_t k = n - 1;\n                double a_val = A[i * n + k];\n                double b_val = B[j + k * p];\n                if (a_val >= -100.0 && a_val <= 100.0 && b_val >= -100.0 && b_val <= 100.0) {\n                    C[i * p + j] += a_val * b_val;\n                }\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_18_SSE", "completion": "```cpp\nvoid range_matrix_mul_simd(const double* A, const double* B, double* C, size_t m, size_t n, size_t p) {\n    __m128d lower_bound = _mm_set1_pd(-100.0);\n    __m128d upper_bound = _mm_set1_pd(100.0);\n\n    for (size_t i = 0; i < m; ++i) {\n        for (size_t j = 0; j < p; ++j) {\n            __m128d c_sum = _mm_setzero_pd();\n            for (size_t k = 0; k < n; k += 2) {\n                __m128d a_vals = _mm_loadu_pd(&A[i * n + k]);\n                __m128d b_vals = _mm_loadu_pd(&B[j + k * p]);\n\n                __m128d a_in_range = _mm_and_pd(_mm_cmpge_pd(a_vals, lower_bound), _mm_cmple_pd(a_vals, upper_bound));\n                __m128d b_in_range = _mm_and_pd(_mm_cmpge_pd(b_vals, lower_bound), _mm_cmple_pd(b_vals, upper_bound));\n\n                __m128d a_masked = _mm_and_pd(a_vals, a_in_range);\n                __m128d b_masked = _mm_and_pd(b_vals, b_in_range);\n\n                __m128d prod = _mm_mul_pd(a_masked, b_masked);\n                c_sum = _mm_add_pd(c_sum, prod);\n            }\n            double c_temp[2];\n            _mm_storeu_pd(c_temp, c_sum);\n            C[i * p + j] = c_temp[0] + c_temp[1];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_18_SSE", "completion": "```cpp\nvoid range_matrix_mul_simd(const double* A, const double* B, double* C, size_t m, size_t n, size_t p) {\n    __m128d lower_bound = _mm_set1_pd(-100.0);\n    __m128d upper_bound = _mm_set1_pd(100.0);\n\n    for (size_t i = 0; i < m; ++i) {\n        for (size_t j = 0; j < p; ++j) {\n            __m128d c_sum = _mm_setzero_pd();\n            for (size_t k = 0; k < n; k += 2) {\n                __m128d a_vals = _mm_loadu_pd(&A[i * n + k]);\n                __m128d b_vals = _mm_loadu_pd(&B[j + k * p]);\n\n                __m128d a_in_range = _mm_and_pd(_mm_cmpge_pd(a_vals, lower_bound), _mm_cmple_pd(a_vals, upper_bound));\n                __m128d b_in_range = _mm_and_pd(_mm_cmpge_pd(b_vals, lower_bound), _mm_cmple_pd(b_vals, upper_bound));\n\n                __m128d a_masked = _mm_and_pd(a_vals, a_in_range);\n                __m128d b_masked = _mm_and_pd(b_vals, b_in_range);\n\n                __m128d prod = _mm_mul_pd(a_masked, b_masked);\n                c_sum = _mm_add_pd(c_sum, prod);\n            }\n            double c_temp[2];\n            _mm_storeu_pd(c_temp, c_sum);\n            C[i * p + j] = c_temp[0] + c_temp[1];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_18_SSE", "completion": "```cpp\nvoid range_matrix_mul_simd(const double* A, const double* B, double* C, size_t m, size_t n, size_t p) {\n    __m128d range_min = _mm_set1_pd(-100.0);\n    __m128d range_max = _mm_set1_pd(100.0);\n\n    for (size_t i = 0; i < m; ++i) {\n        for (size_t j = 0; j < p; ++j) {\n            __m128d c_sum = _mm_setzero_pd();\n            for (size_t k = 0; k < n; k += 2) {\n                __m128d a_vals = _mm_loadu_pd(&A[i * n + k]);\n                __m128d b_vals = _mm_loadu_pd(&B[j + k * p]);\n\n                __m128d a_in_range = _mm_and_pd(_mm_cmpge_pd(a_vals, range_min), _mm_cmple_pd(a_vals, range_max));\n                __m128d b_in_range = _mm_and_pd(_mm_cmpge_pd(b_vals, range_min), _mm_cmple_pd(b_vals, range_max));\n\n                __m128d a_masked = _mm_and_pd(a_vals, a_in_range);\n                __m128d b_masked = _mm_and_pd(b_vals, b_in_range);\n\n                __m128d prod = _mm_mul_pd(a_masked, b_masked);\n                c_sum = _mm_add_pd(c_sum, prod);\n            }\n\n            double c_temp[2];\n            _mm_storeu_pd(c_temp, c_sum);\n            C[i * p + j] = c_temp[0] + c_temp[1];\n\n            // Handle remaining element if n is odd\n            if (n % 2 != 0) {\n                size_t k = n - 1;\n                double a_val = A[i * n + k];\n                double b_val = B[j + k * p];\n                if (a_val >= -100.0 && a_val <= 100.0 && b_val >= -100.0 && b_val <= 100.0) {\n                    C[i * p + j] += a_val * b_val;\n                }\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_18_SSE", "completion": "```cpp\nvoid range_matrix_mul_simd(const double* A, const double* B, double* C, size_t m, size_t n, size_t p) {\n    __m128d lower_bound = _mm_set1_pd(-100.0);\n    __m128d upper_bound = _mm_set1_pd(100.0);\n\n    for (size_t i = 0; i < m; ++i) {\n        for (size_t j = 0; j < p; ++j) {\n            __m128d c_sum = _mm_setzero_pd();\n            for (size_t k = 0; k < n; k += 2) {\n                __m128d a_vals = _mm_loadu_pd(&A[i * n + k]);\n                __m128d b_vals = _mm_loadu_pd(&B[j + k * p]);\n\n                __m128d a_in_range = _mm_and_pd(_mm_cmpge_pd(a_vals, lower_bound), _mm_cmple_pd(a_vals, upper_bound));\n                __m128d b_in_range = _mm_and_pd(_mm_cmpge_pd(b_vals, lower_bound), _mm_cmple_pd(b_vals, upper_bound));\n\n                __m128d a_masked = _mm_and_pd(a_vals, a_in_range);\n                __m128d b_masked = _mm_and_pd(b_vals, b_in_range);\n\n                __m128d prod = _mm_mul_pd(a_masked, b_masked);\n                c_sum = _mm_add_pd(c_sum, prod);\n            }\n            double c_temp[2];\n            _mm_storeu_pd(c_temp, c_sum);\n            C[i * p + j] = c_temp[0] + c_temp[1];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_19_SSE", "completion": "```cpp\nvoid tensor_add_3d_simd(const int64_t* A, const int64_t* B, int64_t* C, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t i = 0;\n\n    for (; i <= total_elements - 2; i += 2) {\n        __m128i a = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i b = _mm_loadu_si128((__m128i*)&B[i]);\n        __m128i c = _mm_add_epi64(a, b);\n        _mm_storeu_si128((__m128i*)&C[i], c);\n    }\n\n    // Handle any remaining elements\n    for (; i < total_elements; ++i) {\n        C[i] = A[i] + B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_19_SSE", "completion": "```cpp\nvoid tensor_add_3d_simd(const int64_t* A, const int64_t* B, int64_t* C, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t i = 0;\n\n    for (; i <= total_elements - 2; i += 2) {\n        __m128i a = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i b = _mm_loadu_si128((__m128i*)&B[i]);\n        __m128i c = _mm_add_epi64(a, b);\n        _mm_storeu_si128((__m128i*)&C[i], c);\n    }\n\n    for (; i < total_elements; ++i) {\n        C[i] = A[i] + B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_19_SSE", "completion": "```cpp\nvoid tensor_add_3d_simd(const int64_t* A, const int64_t* B, int64_t* C, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t i = 0;\n\n    for (; i <= total_elements - 2; i += 2) {\n        __m128i a = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i b = _mm_loadu_si128((__m128i*)&B[i]);\n        __m128i c = _mm_add_epi64(a, b);\n        _mm_storeu_si128((__m128i*)&C[i], c);\n    }\n\n    // Handle any remaining elements\n    for (; i < total_elements; ++i) {\n        C[i] = A[i] + B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_19_SSE", "completion": "```cpp\nvoid tensor_add_3d_simd(const int64_t* A, const int64_t* B, int64_t* C, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t i = 0;\n\n    for (; i <= total_elements - 2; i += 2) {\n        __m128i a = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i b = _mm_loadu_si128((__m128i*)&B[i]);\n        __m128i c = _mm_add_epi64(a, b);\n        _mm_storeu_si128((__m128i*)&C[i], c);\n    }\n\n    for (; i < total_elements; ++i) {\n        C[i] = A[i] + B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_19_SSE", "completion": "```cpp\nvoid tensor_add_3d_simd(const int64_t* A, const int64_t* B, int64_t* C, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t i = 0;\n\n    for (; i <= total_elements - 2; i += 2) {\n        __m128i a = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i b = _mm_loadu_si128((__m128i*)&B[i]);\n        __m128i c = _mm_add_epi64(a, b);\n        _mm_storeu_si128((__m128i*)&C[i], c);\n    }\n\n    for (; i < total_elements; ++i) {\n        C[i] = A[i] + B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_20_SSE", "completion": "```cpp\nvoid vector_add_round_nearest_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 4; i += 4) {\n        __m128 a = _mm_loadu_ps(&src1[i]);\n        __m128 b = _mm_loadu_ps(&src2[i]);\n        __m128 sum = _mm_add_ps(a, b);\n        __m128 rounded = _mm_round_ps(sum, _MM_FROUND_TO_NEAREST_INT);\n        _mm_storeu_ps(&dst[i], rounded);\n    }\n    for (; i < length; ++i) {\n        dst[i] = std::round(src1[i] + src2[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_20_SSE", "completion": "```cpp\nvoid vector_add_round_nearest_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 4; i += 4) {\n        __m128 vec1 = _mm_loadu_ps(&src1[i]);\n        __m128 vec2 = _mm_loadu_ps(&src2[i]);\n        __m128 sum = _mm_add_ps(vec1, vec2);\n        __m128 rounded = _mm_round_ps(sum, _MM_FROUND_TO_NEAREST_INT);\n        _mm_storeu_ps(&dst[i], rounded);\n    }\n    for (; i < length; ++i) {\n        dst[i] = std::round(src1[i] + src2[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_20_SSE", "completion": "```cpp\nvoid vector_add_round_nearest_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 4; i += 4) {\n        __m128 a = _mm_loadu_ps(&src1[i]);\n        __m128 b = _mm_loadu_ps(&src2[i]);\n        __m128 sum = _mm_add_ps(a, b);\n        __m128 rounded = _mm_round_ps(sum, _MM_FROUND_TO_NEAREST_INT);\n        _mm_storeu_ps(&dst[i], rounded);\n    }\n    for (; i < length; ++i) {\n        dst[i] = std::round(src1[i] + src2[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_20_SSE", "completion": "```cpp\nvoid vector_add_round_nearest_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 4; i += 4) {\n        __m128 a = _mm_loadu_ps(&src1[i]);\n        __m128 b = _mm_loadu_ps(&src2[i]);\n        __m128 sum = _mm_add_ps(a, b);\n        __m128 rounded = _mm_round_ps(sum, _MM_FROUND_TO_NEAREST_INT);\n        _mm_storeu_ps(&dst[i], rounded);\n    }\n    for (; i < length; ++i) {\n        dst[i] = std::round(src1[i] + src2[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_20_SSE", "completion": "```cpp\nvoid vector_add_round_nearest_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 4; i += 4) {\n        __m128 a = _mm_loadu_ps(&src1[i]);\n        __m128 b = _mm_loadu_ps(&src2[i]);\n        __m128 sum = _mm_add_ps(a, b);\n        __m128 rounded = _mm_round_ps(sum, _MM_FROUND_TO_NEAREST_INT);\n        _mm_storeu_ps(&dst[i], rounded);\n    }\n    for (; i < length; ++i) {\n        dst[i] = std::round(src1[i] + src2[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_21_SSE", "completion": "```cpp\nvoid vector_mul_round_up_simd(const float* src1, const float* src2, float* dst, size_t length){\n    __m128 fifty = _mm_set1_ps(50.0f);\n    __m128 neg_one = _mm_set1_ps(-1.0f);\n    __m128i mask = _mm_set_epi32(0, 0xFFFFFFFF, 0, 0xFFFFFFFF);\n\n    for (size_t i = 0; i < length; i += 4) {\n        __m128 a = _mm_loadu_ps(&src1[i]);\n        __m128 b = _mm_loadu_ps(&src2[i]);\n\n        __m128 diff = _mm_sub_ps(a, b);\n        __m128 abs_diff = _mm_andnot_ps(_mm_set1_ps(-0.0f), diff);\n        __m128 cmp = _mm_cmple_ps(abs_diff, fifty);\n\n        __m128 mul = _mm_mul_ps(a, b);\n        __m128 rounded = _mm_ceil_ps(mul);\n\n        __m128i index_mask = _mm_set_epi32(i + 3, i + 2, i + 1, i);\n        __m128i even_index_mask = _mm_and_si128(index_mask, mask);\n        __m128i valid_mask = _mm_castps_si128(cmp);\n        __m128i final_mask = _mm_and_si128(even_index_mask, valid_mask);\n\n        __m128 result = _mm_blendv_ps(neg_one, rounded, _mm_castsi128_ps(final_mask));\n\n        _mm_storeu_ps(&dst[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_21_SSE", "completion": "```cpp\nvoid vector_mul_round_up_simd(const float* src1, const float* src2, float* dst, size_t length){\n    __m128 fifty = _mm_set1_ps(50.0f);\n    __m128 neg_one = _mm_set1_ps(-1.0f);\n    __m128i two = _mm_set1_epi32(2);\n\n    for (size_t i = 0; i < length; i += 4) {\n        __m128 a = _mm_loadu_ps(&src1[i]);\n        __m128 b = _mm_loadu_ps(&src2[i]);\n\n        __m128 diff = _mm_sub_ps(a, b);\n        __m128 abs_diff = _mm_andnot_ps(_mm_set1_ps(-0.0f), diff);\n        __m128 mask_diff = _mm_cmple_ps(abs_diff, fifty);\n\n        __m128i indices = _mm_set_epi32(i + 3, i + 2, i + 1, i);\n        __m128i mask_index = _mm_cmpeq_epi32(_mm_and_si128(indices, two), _mm_setzero_si128());\n\n        __m128 mask = _mm_and_ps(mask_diff, _mm_castsi128_ps(mask_index));\n\n        __m128 mul = _mm_mul_ps(a, b);\n        __m128 rounded = _mm_ceil_ps(mul);\n\n        __m128 result = _mm_or_ps(_mm_andnot_ps(mask, neg_one), _mm_and_ps(mask, rounded));\n\n        _mm_storeu_ps(&dst[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_21_SSE", "completion": "```cpp\nvoid vector_mul_round_up_simd(const float* src1, const float* src2, float* dst, size_t length){\n    __m128 fifty = _mm_set1_ps(50.0f);\n    __m128 neg_fifty = _mm_set1_ps(-50.0f);\n    __m128 minus_one = _mm_set1_ps(-1.0f);\n\n    for (size_t i = 0; i < length; i += 4) {\n        __m128 s1 = _mm_loadu_ps(&src1[i]);\n        __m128 s2 = _mm_loadu_ps(&src2[i]);\n\n        __m128 diff = _mm_sub_ps(s1, s2);\n        __m128 abs_diff = _mm_max_ps(diff, _mm_mul_ps(diff, _mm_set1_ps(-1.0f)));\n\n        __m128 mask_within_range = _mm_and_ps(_mm_cmpge_ps(abs_diff, neg_fifty), _mm_cmple_ps(abs_diff, fifty));\n        __m128 mask_even_index = _mm_castsi128_ps(_mm_set_epi32(0, -1, 0, -1));\n\n        __m128 mask = _mm_and_ps(mask_within_range, mask_even_index);\n        __m128 mul_result = _mm_mul_ps(s1, s2);\n        __m128 rounded_result = _mm_ceil_ps(mul_result);\n\n        __m128 result = _mm_or_ps(_mm_andnot_ps(mask, minus_one), _mm_and_ps(mask, rounded_result));\n\n        _mm_storeu_ps(&dst[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_21_SSE", "completion": "```cpp\nvoid vector_mul_round_up_simd(const float* src1, const float* src2, float* dst, size_t length){\n    __m128 fifty = _mm_set1_ps(50.0f);\n    __m128 neg_one = _mm_set1_ps(-1.0f);\n    __m128i two = _mm_set1_epi32(2);\n\n    for (size_t i = 0; i < length; i += 4) {\n        __m128 a = _mm_loadu_ps(&src1[i]);\n        __m128 b = _mm_loadu_ps(&src2[i]);\n\n        __m128 diff = _mm_sub_ps(a, b);\n        __m128 abs_diff = _mm_andnot_ps(_mm_set1_ps(-0.0f), diff);\n        __m128 mask_diff = _mm_cmple_ps(abs_diff, fifty);\n\n        __m128i indices = _mm_set_epi32(i + 3, i + 2, i + 1, i);\n        __m128i mod_two_mask = _mm_cmpeq_epi32(_mm_and_si128(indices, two), _mm_setzero_si128());\n\n        __m128 mul_result = _mm_mul_ps(a, b);\n        __m128 rounded_result = _mm_ceil_ps(mul_result);\n\n        __m128i final_mask = _mm_and_si128(_mm_castps_si128(mask_diff), mod_two_mask);\n        __m128 result = _mm_or_ps(_mm_and_ps(_mm_castsi128_ps(final_mask), rounded_result), _mm_andnot_ps(_mm_castsi128_ps(final_mask), neg_one));\n\n        _mm_storeu_ps(&dst[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_21_SSE", "completion": "```cpp\nvoid vector_mul_round_up_simd(const float* src1, const float* src2, float* dst, size_t length){\n    __m128 fifty = _mm_set1_ps(50.0f);\n    __m128 neg_one = _mm_set1_ps(-1.0f);\n    __m128i mask_even = _mm_set_epi32(0, -1, 0, -1);\n\n    for (size_t i = 0; i < length; i += 4) {\n        __m128 a = _mm_loadu_ps(&src1[i]);\n        __m128 b = _mm_loadu_ps(&src2[i]);\n\n        __m128 diff = _mm_sub_ps(a, b);\n        __m128 abs_diff = _mm_andnot_ps(_mm_set1_ps(-0.0f), diff);\n        __m128 cmp = _mm_cmple_ps(abs_diff, fifty);\n\n        __m128 mul = _mm_mul_ps(a, b);\n        __m128 rounded = _mm_ceil_ps(mul);\n\n        __m128i index_mask = _mm_set_epi32(i + 3, i + 2, i + 1, i);\n        __m128i even_mask = _mm_and_si128(index_mask, mask_even);\n        __m128i valid_mask = _mm_castps_si128(cmp);\n\n        __m128i final_mask = _mm_and_si128(even_mask, valid_mask);\n        __m128 result = _mm_blendv_ps(neg_one, rounded, _mm_castsi128_ps(final_mask));\n\n        _mm_storeu_ps(&dst[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_22_SSE", "completion": "```cpp\nvoid matrix_scalar_mul_simd(const double* mat, double scalar, double* dst, size_t m, size_t n) {\n    __m128d scalar_vec = _mm_set1_pd(scalar);\n    size_t total_elements = m * n;\n    size_t i = 0;\n\n    for (; i <= total_elements - 2; i += 2) {\n        __m128d mat_vec = _mm_loadu_pd(&mat[i]);\n        __m128d result_vec = _mm_mul_pd(mat_vec, scalar_vec);\n        _mm_storeu_pd(&dst[i], result_vec);\n    }\n\n    for (; i < total_elements; ++i) {\n        dst[i] = mat[i] * scalar;\n    }\n}\n```"}
{"task_id": "SimdBench_22_SSE", "completion": "```cpp\nvoid matrix_scalar_mul_simd(const double* mat, double scalar, double* dst, size_t m, size_t n) {\n    __m128d scalar_vec = _mm_set1_pd(scalar);\n    size_t total_elements = m * n;\n    size_t i = 0;\n\n    for (; i <= total_elements - 2; i += 2) {\n        __m128d mat_vec = _mm_loadu_pd(&mat[i]);\n        __m128d result_vec = _mm_mul_pd(mat_vec, scalar_vec);\n        _mm_storeu_pd(&dst[i], result_vec);\n    }\n\n    for (; i < total_elements; ++i) {\n        dst[i] = mat[i] * scalar;\n    }\n}\n```"}
{"task_id": "SimdBench_22_SSE", "completion": "```cpp\nvoid matrix_scalar_mul_simd(const double* mat, double scalar, double* dst, size_t m, size_t n) {\n    __m128d scalar_vec = _mm_set1_pd(scalar);\n    size_t total_elements = m * n;\n    size_t i = 0;\n\n    for (; i <= total_elements - 2; i += 2) {\n        __m128d mat_vec = _mm_loadu_pd(&mat[i]);\n        __m128d result_vec = _mm_mul_pd(mat_vec, scalar_vec);\n        _mm_storeu_pd(&dst[i], result_vec);\n    }\n\n    for (; i < total_elements; ++i) {\n        dst[i] = mat[i] * scalar;\n    }\n}\n```"}
{"task_id": "SimdBench_22_SSE", "completion": "```cpp\nvoid matrix_scalar_mul_simd(const double* mat, double scalar, double* dst, size_t m, size_t n) {\n    __m128d scalar_vec = _mm_set1_pd(scalar);\n    size_t total_elements = m * n;\n    size_t i = 0;\n\n    for (; i <= total_elements - 2; i += 2) {\n        __m128d mat_vec = _mm_loadu_pd(&mat[i]);\n        __m128d result_vec = _mm_mul_pd(mat_vec, scalar_vec);\n        _mm_storeu_pd(&dst[i], result_vec);\n    }\n\n    for (; i < total_elements; ++i) {\n        dst[i] = mat[i] * scalar;\n    }\n}\n```"}
{"task_id": "SimdBench_22_SSE", "completion": "```cpp\nvoid matrix_scalar_mul_simd(const double* mat, double scalar, double* dst, size_t m, size_t n) {\n    __m128d scalar_vec = _mm_set1_pd(scalar);\n    size_t total_elements = m * n;\n    size_t i = 0;\n\n    for (; i <= total_elements - 2; i += 2) {\n        __m128d mat_vec = _mm_loadu_pd(&mat[i]);\n        __m128d result_vec = _mm_mul_pd(mat_vec, scalar_vec);\n        _mm_storeu_pd(&dst[i], result_vec);\n    }\n\n    for (; i < total_elements; ++i) {\n        dst[i] = mat[i] * scalar;\n    }\n}\n```"}
{"task_id": "SimdBench_23_SSE", "completion": "```cpp\nvoid matrix_normalize_rows_simd(float* mat, size_t m, size_t n) {\n    for (size_t i = 0; i < m; ++i) {\n        float* row = mat + i * n;\n        __m128 sum = _mm_setzero_ps();\n        size_t j = 0;\n\n        // Process 4 elements at a time\n        for (; j <= n - 4; j += 4) {\n            __m128 vec = _mm_loadu_ps(&row[j]);\n            vec = _mm_mul_ps(vec, vec);\n            sum = _mm_add_ps(sum, vec);\n        }\n\n        // Horizontal add to get the sum of squares\n        __m128 hsum = _mm_hadd_ps(sum, sum);\n        hsum = _mm_hadd_ps(hsum, hsum);\n        float norm = _mm_cvtss_f32(_mm_sqrt_ss(hsum));\n\n        // Handle remaining elements\n        for (; j < n; ++j) {\n            norm += row[j] * row[j];\n        }\n        norm = sqrtf(norm);\n\n        // Normalize the row\n        j = 0;\n        for (; j <= n - 4; j += 4) {\n            __m128 vec = _mm_loadu_ps(&row[j]);\n            vec = _mm_div_ps(vec, _mm_set1_ps(norm));\n            _mm_storeu_ps(&row[j], vec);\n        }\n\n        // Handle remaining elements\n        for (; j < n; ++j) {\n            row[j] /= norm;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_23_SSE", "completion": "```cpp\nvoid matrix_normalize_rows_simd(float* mat, size_t m, size_t n) {\n    for (size_t i = 0; i < m; ++i) {\n        float* row = mat + i * n;\n        __m128 sum = _mm_setzero_ps();\n        size_t j = 0;\n\n        // Process 4 elements at a time\n        for (; j <= n - 4; j += 4) {\n            __m128 vec = _mm_loadu_ps(&row[j]);\n            vec = _mm_mul_ps(vec, vec);\n            sum = _mm_add_ps(sum, vec);\n        }\n\n        // Horizontal add to get the sum of squares\n        __m128 hsum = _mm_hadd_ps(sum, sum);\n        hsum = _mm_hadd_ps(hsum, hsum);\n        float norm = _mm_cvtss_f32(_mm_sqrt_ss(hsum));\n\n        // Handle remaining elements\n        for (; j < n; ++j) {\n            norm += row[j] * row[j];\n        }\n        norm = sqrtf(norm);\n\n        // Normalize the row\n        j = 0;\n        for (; j <= n - 4; j += 4) {\n            __m128 vec = _mm_loadu_ps(&row[j]);\n            vec = _mm_div_ps(vec, _mm_set1_ps(norm));\n            _mm_storeu_ps(&row[j], vec);\n        }\n\n        // Handle remaining elements\n        for (; j < n; ++j) {\n            row[j] /= norm;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_23_SSE", "completion": "```cpp\nvoid matrix_normalize_rows_simd(float* mat, size_t m, size_t n) {\n    for (size_t i = 0; i < m; ++i) {\n        float* row = mat + i * n;\n        __m128 sum = _mm_setzero_ps();\n        size_t j = 0;\n\n        // Process 4 elements at a time\n        for (; j <= n - 4; j += 4) {\n            __m128 vec = _mm_loadu_ps(&row[j]);\n            vec = _mm_mul_ps(vec, vec);\n            sum = _mm_add_ps(sum, vec);\n        }\n\n        // Horizontal add to get the sum of squares\n        __m128 hsum = _mm_hadd_ps(sum, sum);\n        hsum = _mm_hadd_ps(hsum, hsum);\n        float norm = _mm_cvtss_f32(_mm_sqrt_ss(hsum));\n\n        // Handle remaining elements\n        for (; j < n; ++j) {\n            norm += row[j] * row[j];\n        }\n        norm = sqrtf(norm);\n\n        // Normalize the row\n        j = 0;\n        for (; j <= n - 4; j += 4) {\n            __m128 vec = _mm_loadu_ps(&row[j]);\n            vec = _mm_div_ps(vec, _mm_set1_ps(norm));\n            _mm_storeu_ps(&row[j], vec);\n        }\n\n        // Handle remaining elements\n        for (; j < n; ++j) {\n            row[j] /= norm;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_23_SSE", "completion": "```cpp\nvoid matrix_normalize_rows_simd(float* mat, size_t m, size_t n) {\n    for (size_t i = 0; i < m; ++i) {\n        float* row = mat + i * n;\n        __m128 sum = _mm_setzero_ps();\n        size_t j = 0;\n\n        // Process 4 elements at a time\n        for (; j <= n - 4; j += 4) {\n            __m128 vec = _mm_loadu_ps(&row[j]);\n            vec = _mm_mul_ps(vec, vec);\n            sum = _mm_add_ps(sum, vec);\n        }\n\n        // Horizontal add to get the sum of squares\n        __m128 hsum = _mm_hadd_ps(sum, sum);\n        hsum = _mm_hadd_ps(hsum, hsum);\n        float norm = _mm_cvtss_f32(_mm_sqrt_ss(hsum));\n\n        // Handle remaining elements\n        for (; j < n; ++j) {\n            norm += row[j] * row[j];\n        }\n        norm = sqrtf(norm);\n\n        // Normalize the row\n        j = 0;\n        for (; j <= n - 4; j += 4) {\n            __m128 vec = _mm_loadu_ps(&row[j]);\n            vec = _mm_div_ps(vec, _mm_set1_ps(norm));\n            _mm_storeu_ps(&row[j], vec);\n        }\n\n        // Handle remaining elements\n        for (; j < n; ++j) {\n            row[j] /= norm;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_23_SSE", "completion": "```cpp\nvoid matrix_normalize_rows_simd(float* mat, size_t m, size_t n) {\n    for (size_t i = 0; i < m; ++i) {\n        float* row = mat + i * n;\n        __m128 sum = _mm_setzero_ps();\n        size_t j = 0;\n\n        // Process 4 elements at a time\n        for (; j <= n - 4; j += 4) {\n            __m128 vec = _mm_loadu_ps(&row[j]);\n            vec = _mm_mul_ps(vec, vec);\n            sum = _mm_add_ps(sum, vec);\n        }\n\n        // Horizontal add to get the sum of squares\n        __m128 hsum = _mm_hadd_ps(sum, sum);\n        hsum = _mm_hadd_ps(hsum, hsum);\n        float norm = _mm_cvtss_f32(_mm_sqrt_ss(hsum));\n\n        // Handle remaining elements\n        for (; j < n; ++j) {\n            norm += row[j] * row[j];\n        }\n        norm = sqrtf(norm);\n\n        // Normalize the row\n        j = 0;\n        for (; j <= n - 4; j += 4) {\n            __m128 vec = _mm_loadu_ps(&row[j]);\n            vec = _mm_div_ps(vec, _mm_set1_ps(norm));\n            _mm_storeu_ps(&row[j], vec);\n        }\n\n        // Handle remaining elements\n        for (; j < n; ++j) {\n            row[j] /= norm;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_24_SSE", "completion": "```cpp\nvoid matrix_mul_round_int_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n, size_t p) {\n    for (size_t i = 0; i < m; ++i) {\n        for (size_t j = 0; j < p; j += 2) {\n            __m128d sum = _mm_setzero_pd();\n            for (size_t k = 0; k < n; k += 2) {\n                __m128d a = _mm_loadu_pd(&mat1[i * n + k]);\n                __m128d b = _mm_loadu_pd(&mat2[k * p + j]);\n                __m128d prod = _mm_mul_pd(a, b);\n                sum = _mm_add_pd(sum, prod);\n            }\n            sum = _mm_round_pd(sum, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n            _mm_storeu_pd(&dst[i * p + j], sum);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_24_SSE", "completion": "```cpp\nvoid matrix_mul_round_int_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n, size_t p) {\n    for (size_t i = 0; i < m; ++i) {\n        for (size_t j = 0; j < p; j += 2) {\n            __m128d sum = _mm_setzero_pd();\n            for (size_t k = 0; k < n; k += 2) {\n                __m128d a = _mm_loadu_pd(&mat1[i * n + k]);\n                __m128d b = _mm_loadu_pd(&mat2[k * p + j]);\n                __m128d prod = _mm_mul_pd(a, b);\n                sum = _mm_add_pd(sum, prod);\n            }\n            sum = _mm_round_pd(sum, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n            _mm_storeu_pd(&dst[i * p + j], sum);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_24_SSE", "completion": "```cpp\nvoid matrix_mul_round_int_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n, size_t p) {\n    for (size_t i = 0; i < m; ++i) {\n        for (size_t j = 0; j < p; j += 2) {\n            __m128d sum = _mm_setzero_pd();\n            for (size_t k = 0; k < n; k += 2) {\n                __m128d a = _mm_loadu_pd(&mat1[i * n + k]);\n                __m128d b = _mm_loadu_pd(&mat2[k * p + j]);\n                __m128d prod = _mm_mul_pd(a, b);\n                sum = _mm_add_pd(sum, prod);\n            }\n            sum = _mm_round_pd(sum, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n            _mm_storeu_pd(&dst[i * p + j], sum);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_24_SSE", "completion": "```cpp\nvoid matrix_mul_round_int_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n, size_t p) {\n    for (size_t i = 0; i < m; ++i) {\n        for (size_t j = 0; j < p; j += 2) {\n            __m128d sum = _mm_setzero_pd();\n            for (size_t k = 0; k < n; k += 2) {\n                __m128d a = _mm_loadu_pd(&mat1[i * n + k]);\n                __m128d b = _mm_loadu_pd(&mat2[k * p + j]);\n                __m128d prod = _mm_mul_pd(a, b);\n                sum = _mm_add_pd(sum, prod);\n            }\n            sum = _mm_round_pd(sum, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n            _mm_storeu_pd(&dst[i * p + j], sum);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_24_SSE", "completion": "```cpp\nvoid matrix_mul_round_int_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n, size_t p) {\n    for (size_t i = 0; i < m; ++i) {\n        for (size_t j = 0; j < p; j += 2) {\n            __m128d sum = _mm_setzero_pd();\n            for (size_t k = 0; k < n; k += 2) {\n                __m128d a = _mm_loadu_pd(&mat1[i * n + k]);\n                __m128d b = _mm_loadu_pd(&mat2[k * p + j]);\n                __m128d prod = _mm_mul_pd(a, b);\n                sum = _mm_add_pd(sum, prod);\n            }\n            if (n % 2 != 0) {\n                double a = mat1[i * n + n - 1];\n                double b = mat2[(n - 1) * p + j];\n                double c = mat2[(n - 1) * p + j + 1];\n                sum = _mm_add_sd(sum, _mm_set_sd(a * b));\n                if (j + 1 < p) {\n                    sum = _mm_add_sd(_mm_unpackhi_pd(sum, sum), _mm_set_sd(a * c));\n                }\n            }\n            sum = _mm_round_pd(sum, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n            _mm_storeu_pd(&dst[i * p + j], sum);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_25_SSE", "completion": "```cpp\nvoid matrix_transpose_round_quarter_simd(const float* src, float* dst, size_t rows, size_t cols) {\n    __m128 quarter = _mm_set1_ps(0.25f);\n    __m128 half = _mm_set1_ps(0.5f);\n\n    for (size_t c = 0; c < cols; c += 4) {\n        for (size_t r = 0; r < rows; ++r) {\n            __m128 row = _mm_loadu_ps(&src[r * cols + c]);\n            __m128 rounded = _mm_round_ps(_mm_add_ps(row, half), _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n            __m128 quarters = _mm_mul_ps(rounded, quarter);\n            _mm_storeu_ps(&dst[c * rows + r], quarters);\n        }\n    }\n\n    // Handle remaining columns if cols % 4 != 0\n    if (cols % 4 != 0) {\n        for (size_t c = cols - cols % 4; c < cols; ++c) {\n            for (size_t r = 0; r < rows; ++r) {\n                float value = src[r * cols + c];\n                int rounded = (int)(value + 0.5f);\n                dst[c * rows + r] = (float)(rounded) * 0.25f;\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_25_SSE", "completion": "```cpp\nvoid matrix_transpose_round_quarter_simd(const float* src, float* dst, size_t rows, size_t cols) {\n    __m128 quarter = _mm_set1_ps(0.25f);\n    __m128 half = _mm_set1_ps(0.5f);\n\n    for (size_t c = 0; c < cols; c += 4) {\n        for (size_t r = 0; r < rows; ++r) {\n            __m128 row = _mm_loadu_ps(&src[r * cols + c]);\n            __m128 rounded = _mm_round_ps(_mm_add_ps(row, half), _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n            __m128 quarters = _mm_mul_ps(rounded, quarter);\n            __m128 transposed = _mm_permute_ps(quarters, _MM_SHUFFLE(0, 1, 2, 3));\n            _mm_storeu_ps(&dst[c * rows + r], transposed);\n        }\n    }\n\n    // Handle remaining columns (if cols % 4 != 0)\n    if (cols % 4 != 0) {\n        for (size_t c = cols - cols % 4; c < cols; ++c) {\n            for (size_t r = 0; r < rows; ++r) {\n                float value = src[r * cols + c];\n                float rounded = roundf(value * 4.0f) / 4.0f;\n                dst[c * rows + r] = rounded;\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_25_SSE", "completion": "```cpp\nvoid matrix_transpose_round_quarter_simd(const float* src, float* dst, size_t rows, size_t cols) {\n    __m128 quarter = _mm_set1_ps(0.25f);\n    __m128 half = _mm_set1_ps(0.5f);\n\n    for (size_t c = 0; c < cols; c += 4) {\n        for (size_t r = 0; r < rows; ++r) {\n            __m128 row = _mm_loadu_ps(&src[r * cols + c]);\n            __m128 rounded = _mm_round_ps(_mm_add_ps(row, half), _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n            __m128 quarters = _mm_mul_ps(rounded, quarter);\n            _mm_storeu_ps(&dst[c * rows + r], quarters);\n        }\n    }\n\n    // Handle remaining columns (if cols % 4 != 0)\n    if (cols % 4 != 0) {\n        for (size_t c = cols - cols % 4; c < cols; ++c) {\n            for (size_t r = 0; r < rows; ++r) {\n                float value = src[r * cols + c];\n                int rounded = (int)(value + 0.5f);\n                dst[c * rows + r] = (float)(rounded) * 0.25f;\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_25_SSE", "completion": "```cpp\nvoid matrix_transpose_round_quarter_simd(const float* src, float* dst, size_t rows, size_t cols) {\n    __m128 quarter = _mm_set1_ps(0.25f);\n    __m128 half = _mm_set1_ps(0.5f);\n\n    for (size_t c = 0; c < cols; c += 4) {\n        for (size_t r = 0; r < rows; ++r) {\n            __m128 row = _mm_loadu_ps(&src[r * cols + c]);\n            __m128 rounded = _mm_round_ps(_mm_add_ps(row, half), _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n            __m128 quarters = _mm_mul_ps(rounded, quarter);\n            _mm_storeu_ps(&dst[c * rows + r], quarters);\n        }\n    }\n\n    // Handle remaining columns (if cols % 4 != 0)\n    if (cols % 4 != 0) {\n        for (size_t c = cols - cols % 4; c < cols; ++c) {\n            for (size_t r = 0; r < rows; ++r) {\n                float value = src[r * cols + c];\n                int rounded = (int)(value + 0.5f);\n                dst[c * rows + r] = (float)(rounded) * 0.25f;\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_25_SSE", "completion": "```cpp\nvoid matrix_transpose_round_quarter_simd(const float* src, float* dst, size_t rows, size_t cols) {\n    __m128 quarter = _mm_set1_ps(0.25f);\n    __m128 half = _mm_set1_ps(0.5f);\n\n    for (size_t c = 0; c < cols; c += 4) {\n        for (size_t r = 0; r < rows; ++r) {\n            __m128 row = _mm_loadu_ps(&src[r * cols + c]);\n            row = _mm_round_ps(_mm_add_ps(row, half), _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n            row = _mm_mul_ps(_mm_div_ps(row, quarter), quarter);\n            _mm_storeu_ps(&dst[c * rows + r], row);\n        }\n    }\n\n    // Handle remaining columns (if cols % 4 != 0)\n    if (cols % 4 != 0) {\n        for (size_t c = cols - cols % 4; c < cols; ++c) {\n            for (size_t r = 0; r < rows; ++r) {\n                float value = src[r * cols + c];\n                value = roundf(value / 0.25f) * 0.25f;\n                dst[c * rows + r] = value;\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_26_SSE", "completion": "```cpp\nvoid tensor3d_sub_round_zero_simd(const float* tensor1, const float* tensor2, float* dst, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t i = 0;\n\n    for (; i <= total_elements - 4; i += 4) {\n        __m128 a = _mm_loadu_ps(&tensor1[i]);\n        __m128 b = _mm_loadu_ps(&tensor2[i]);\n        __m128 sub = _mm_sub_ps(a, b);\n        __m128 rounded = _mm_cvtepi32_ps(_mm_cvtps_epi32(sub));\n        _mm_storeu_ps(&dst[i], rounded);\n    }\n\n    for (; i < total_elements; ++i) {\n        dst[i] = static_cast<float>(static_cast<int>(tensor1[i] - tensor2[i]));\n    }\n}\n```"}
{"task_id": "SimdBench_26_SSE", "completion": "```cpp\nvoid tensor3d_sub_round_zero_simd(const float* tensor1, const float* tensor2, float* dst, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t i = 0;\n\n    for (; i <= total_elements - 4; i += 4) {\n        __m128 a = _mm_loadu_ps(&tensor1[i]);\n        __m128 b = _mm_loadu_ps(&tensor2[i]);\n        __m128 sub = _mm_sub_ps(a, b);\n        __m128 rounded = _mm_cvtepi32_ps(_mm_cvtps_epi32(sub));\n        _mm_storeu_ps(&dst[i], rounded);\n    }\n\n    for (; i < total_elements; ++i) {\n        dst[i] = static_cast<float>(static_cast<int>(tensor1[i] - tensor2[i]));\n    }\n}\n```"}
{"task_id": "SimdBench_26_SSE", "completion": "```cpp\nvoid tensor3d_sub_round_zero_simd(const float* tensor1, const float* tensor2, float* dst, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t i = 0;\n\n    for (; i <= total_elements - 4; i += 4) {\n        __m128 a = _mm_loadu_ps(&tensor1[i]);\n        __m128 b = _mm_loadu_ps(&tensor2[i]);\n        __m128 sub = _mm_sub_ps(a, b);\n        __m128 rounded = _mm_cvtepi32_ps(_mm_cvtps_epi32(sub));\n        _mm_storeu_ps(&dst[i], rounded);\n    }\n\n    for (; i < total_elements; ++i) {\n        dst[i] = static_cast<float>(static_cast<int>(tensor1[i] - tensor2[i]));\n    }\n}\n```"}
{"task_id": "SimdBench_26_SSE", "completion": "```cpp\nvoid tensor3d_sub_round_zero_simd(const float* tensor1, const float* tensor2, float* dst, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t i = 0;\n\n    for (; i <= total_elements - 4; i += 4) {\n        __m128 a = _mm_loadu_ps(&tensor1[i]);\n        __m128 b = _mm_loadu_ps(&tensor2[i]);\n        __m128 sub = _mm_sub_ps(a, b);\n        __m128 rounded = _mm_cvtepi32_ps(_mm_cvtps_epi32(sub));\n        _mm_storeu_ps(&dst[i], rounded);\n    }\n\n    for (; i < total_elements; ++i) {\n        dst[i] = static_cast<float>(static_cast<int>(tensor1[i] - tensor2[i]));\n    }\n}\n```"}
{"task_id": "SimdBench_26_SSE", "completion": "```cpp\nvoid tensor3d_sub_round_zero_simd(const float* tensor1, const float* tensor2, float* dst, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t i = 0;\n\n    for (; i <= total_elements - 4; i += 4) {\n        __m128 a = _mm_loadu_ps(&tensor1[i]);\n        __m128 b = _mm_loadu_ps(&tensor2[i]);\n        __m128 sub = _mm_sub_ps(a, b);\n        __m128 rounded = _mm_cvtepi32_ps(_mm_cvtps_epi32(sub));\n        _mm_storeu_ps(&dst[i], rounded);\n    }\n\n    for (; i < total_elements; ++i) {\n        dst[i] = static_cast<float>(static_cast<int>(tensor1[i] - tensor2[i]));\n    }\n}\n```"}
{"task_id": "SimdBench_27_SSE", "completion": "```cpp\nvoid matrix_hadamard_product_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n) {\n    size_t total_elements = m * n;\n    size_t i = 0;\n\n    for (; i <= total_elements - 4; i += 4) {\n        __m128d vec1 = _mm_loadu_pd(&mat1[i]);\n        __m128d vec2 = _mm_loadu_pd(&mat2[i]);\n        __m128d result = _mm_mul_pd(vec1, vec2);\n        _mm_storeu_pd(&dst[i], result);\n\n        vec1 = _mm_loadu_pd(&mat1[i + 2]);\n        vec2 = _mm_loadu_pd(&mat2[i + 2]);\n        result = _mm_mul_pd(vec1, vec2);\n        _mm_storeu_pd(&dst[i + 2], result);\n    }\n\n    for (; i < total_elements; ++i) {\n        dst[i] = mat1[i] * mat2[i];\n    }\n}\n```"}
{"task_id": "SimdBench_27_SSE", "completion": "```cpp\nvoid matrix_hadamard_product_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n) {\n    size_t total_elements = m * n;\n    size_t i = 0;\n\n    for (; i <= total_elements - 4; i += 4) {\n        __m128d vec1 = _mm_loadu_pd(&mat1[i]);\n        __m128d vec2 = _mm_loadu_pd(&mat2[i]);\n        __m128d result = _mm_mul_pd(vec1, vec2);\n        _mm_storeu_pd(&dst[i], result);\n\n        vec1 = _mm_loadu_pd(&mat1[i + 2]);\n        vec2 = _mm_loadu_pd(&mat2[i + 2]);\n        result = _mm_mul_pd(vec1, vec2);\n        _mm_storeu_pd(&dst[i + 2], result);\n    }\n\n    for (; i < total_elements; ++i) {\n        dst[i] = mat1[i] * mat2[i];\n    }\n}\n```"}
{"task_id": "SimdBench_27_SSE", "completion": "```cpp\nvoid matrix_hadamard_product_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n) {\n    size_t total_elements = m * n;\n    size_t i = 0;\n\n    for (; i <= total_elements - 4; i += 4) {\n        __m128d vec1 = _mm_loadu_pd(&mat1[i]);\n        __m128d vec2 = _mm_loadu_pd(&mat2[i]);\n        __m128d result = _mm_mul_pd(vec1, vec2);\n        _mm_storeu_pd(&dst[i], result);\n\n        vec1 = _mm_loadu_pd(&mat1[i + 2]);\n        vec2 = _mm_loadu_pd(&mat2[i + 2]);\n        result = _mm_mul_pd(vec1, vec2);\n        _mm_storeu_pd(&dst[i + 2], result);\n    }\n\n    for (; i < total_elements; ++i) {\n        dst[i] = mat1[i] * mat2[i];\n    }\n}\n```"}
{"task_id": "SimdBench_27_SSE", "completion": "```cpp\nvoid matrix_hadamard_product_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n) {\n    size_t total_elements = m * n;\n    size_t i = 0;\n\n    for (; i <= total_elements - 4; i += 4) {\n        __m128d vec1 = _mm_loadu_pd(&mat1[i]);\n        __m128d vec2 = _mm_loadu_pd(&mat2[i]);\n        __m128d result = _mm_mul_pd(vec1, vec2);\n        _mm_storeu_pd(&dst[i], result);\n\n        vec1 = _mm_loadu_pd(&mat1[i + 2]);\n        vec2 = _mm_loadu_pd(&mat2[i + 2]);\n        result = _mm_mul_pd(vec1, vec2);\n        _mm_storeu_pd(&dst[i + 2], result);\n    }\n\n    for (; i < total_elements; ++i) {\n        dst[i] = mat1[i] * mat2[i];\n    }\n}\n```"}
{"task_id": "SimdBench_27_SSE", "completion": "```cpp\nvoid matrix_hadamard_product_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n) {\n    size_t total_elements = m * n;\n    size_t i = 0;\n\n    for (; i <= total_elements - 4; i += 4) {\n        __m128d vec1 = _mm_loadu_pd(&mat1[i]);\n        __m128d vec2 = _mm_loadu_pd(&mat2[i]);\n        __m128d result = _mm_mul_pd(vec1, vec2);\n        _mm_storeu_pd(&dst[i], result);\n\n        vec1 = _mm_loadu_pd(&mat1[i + 2]);\n        vec2 = _mm_loadu_pd(&mat2[i + 2]);\n        result = _mm_mul_pd(vec1, vec2);\n        _mm_storeu_pd(&dst[i + 2], result);\n    }\n\n    for (; i < total_elements; ++i) {\n        dst[i] = mat1[i] * mat2[i];\n    }\n}\n```"}
{"task_id": "SimdBench_28_SSE", "completion": "```cpp\nvoid matrix_vector_mul_simd(const float* mat, const float* vec, float* dst, size_t m, size_t n) {\n    for (size_t i = 0; i < m; ++i) {\n        __m128 sum = _mm_setzero_ps();\n        for (size_t j = 0; j < n; j += 4) {\n            __m128 mat_row = _mm_loadu_ps(&mat[i * n + j]);\n            __m128 vec_col = _mm_loadu_ps(&vec[j]);\n            __m128 prod = _mm_mul_ps(mat_row, vec_col);\n            sum = _mm_add_ps(sum, prod);\n        }\n        // Horizontal add to get the sum of the four floats in sum\n        __m128 hsum1 = _mm_hadd_ps(sum, sum);\n        __m128 hsum2 = _mm_hadd_ps(hsum1, hsum1);\n        _mm_store_ss(&dst[i], hsum2);\n    }\n}\n```"}
{"task_id": "SimdBench_28_SSE", "completion": "```cpp\nvoid matrix_vector_mul_simd(const float* mat, const float* vec, float* dst, size_t m, size_t n) {\n    for (size_t i = 0; i < m; ++i) {\n        __m128 sum = _mm_setzero_ps();\n        for (size_t j = 0; j < n; j += 4) {\n            __m128 mat_row = _mm_loadu_ps(&mat[i * n + j]);\n            __m128 vec_col = _mm_loadu_ps(&vec[j]);\n            __m128 prod = _mm_mul_ps(mat_row, vec_col);\n            sum = _mm_add_ps(sum, prod);\n        }\n        // Horizontal add to get the sum of the four floats in sum\n        __m128 hsum1 = _mm_hadd_ps(sum, sum);\n        __m128 hsum2 = _mm_hadd_ps(hsum1, hsum1);\n        _mm_store_ss(&dst[i], hsum2);\n    }\n}\n```"}
{"task_id": "SimdBench_28_SSE", "completion": "```cpp\nvoid matrix_vector_mul_simd(const float* mat, const float* vec, float* dst, size_t m, size_t n) {\n    for (size_t i = 0; i < m; ++i) {\n        __m128 sum = _mm_setzero_ps();\n        for (size_t j = 0; j < n; j += 4) {\n            __m128 mat_row = _mm_loadu_ps(&mat[i * n + j]);\n            __m128 vec_col = _mm_loadu_ps(&vec[j]);\n            __m128 prod = _mm_mul_ps(mat_row, vec_col);\n            sum = _mm_add_ps(sum, prod);\n        }\n        // Horizontal add to get the sum of the four floats in sum\n        __m128 hsum1 = _mm_hadd_ps(sum, sum);\n        __m128 hsum2 = _mm_hadd_ps(hsum1, hsum1);\n        _mm_store_ss(&dst[i], hsum2);\n    }\n}\n```"}
{"task_id": "SimdBench_28_SSE", "completion": "```cpp\nvoid matrix_vector_mul_simd(const float* mat, const float* vec, float* dst, size_t m, size_t n) {\n    for (size_t i = 0; i < m; ++i) {\n        __m128 sum = _mm_setzero_ps();\n        for (size_t j = 0; j < n; j += 4) {\n            __m128 mat_row = _mm_loadu_ps(&mat[i * n + j]);\n            __m128 vec_col = _mm_loadu_ps(&vec[j]);\n            __m128 prod = _mm_mul_ps(mat_row, vec_col);\n            sum = _mm_add_ps(sum, prod);\n        }\n        // Horizontal add to get the sum of the four floats in sum\n        __m128 hsum1 = _mm_hadd_ps(sum, sum);\n        __m128 hsum2 = _mm_hadd_ps(hsum1, hsum1);\n        _mm_store_ss(&dst[i], hsum2);\n    }\n}\n```"}
{"task_id": "SimdBench_28_SSE", "completion": "```cpp\nvoid matrix_vector_mul_simd(const float* mat, const float* vec, float* dst, size_t m, size_t n) {\n    for (size_t i = 0; i < m; ++i) {\n        __m128 sum = _mm_setzero_ps();\n        for (size_t j = 0; j < n; j += 4) {\n            __m128 mat_row = _mm_loadu_ps(&mat[i * n + j]);\n            __m128 vec_col = _mm_loadu_ps(&vec[j]);\n            __m128 prod = _mm_mul_ps(mat_row, vec_col);\n            sum = _mm_add_ps(sum, prod);\n        }\n        // Horizontal add to get the sum of the four floats in sum\n        __m128 hsum1 = _mm_hadd_ps(sum, sum);\n        __m128 hsum2 = _mm_hadd_ps(hsum1, hsum1);\n        _mm_store_ss(&dst[i], hsum2);\n    }\n}\n```"}
{"task_id": "SimdBench_29_SSE", "completion": "```cpp\ndouble matrix_average_simd(const double* mat, size_t m, size_t n) {\n    __m128d sum = _mm_setzero_pd();\n    size_t total_elements = m * n;\n    size_t i = 0;\n\n    for (; i <= total_elements - 2; i += 2) {\n        __m128d row = _mm_loadu_pd(&mat[i]);\n        sum = _mm_add_pd(sum, row);\n    }\n\n    double sum_array[2];\n    _mm_storeu_pd(sum_array, sum);\n\n    double total_sum = sum_array[0] + sum_array[1];\n\n    for (; i < total_elements; ++i) {\n        total_sum += mat[i];\n    }\n\n    return total_sum / total_elements;\n}\n```"}
{"task_id": "SimdBench_29_SSE", "completion": "```cpp\ndouble matrix_average_simd(const double* mat, size_t m, size_t n) {\n    __m128d sum = _mm_setzero_pd();\n    size_t total_elements = m * n;\n    size_t i = 0;\n\n    for (; i <= total_elements - 4; i += 4) {\n        __m128d vec = _mm_loadu_pd(&mat[i]);\n        sum = _mm_add_pd(sum, vec);\n    }\n\n    double temp[2];\n    _mm_storeu_pd(temp, sum);\n    double result = temp[0] + temp[1];\n\n    for (; i < total_elements; ++i) {\n        result += mat[i];\n    }\n\n    return result / total_elements;\n}\n```"}
{"task_id": "SimdBench_29_SSE", "completion": "```cpp\ndouble matrix_average_simd(const double* mat, size_t m, size_t n) {\n    __m128d sum = _mm_setzero_pd();\n    size_t total_elements = m * n;\n    size_t i = 0;\n\n    for (; i <= total_elements - 4; i += 4) {\n        __m128d vec = _mm_loadu_pd(&mat[i]);\n        sum = _mm_add_pd(sum, vec);\n    }\n\n    double temp[2];\n    _mm_storeu_pd(temp, sum);\n    double result = temp[0] + temp[1];\n\n    for (; i < total_elements; ++i) {\n        result += mat[i];\n    }\n\n    return result / total_elements;\n}\n```"}
{"task_id": "SimdBench_29_SSE", "completion": "```cpp\ndouble matrix_average_simd(const double* mat, size_t m, size_t n) {\n    __m128d sum = _mm_setzero_pd();\n    size_t total_elements = m * n;\n    size_t i = 0;\n\n    for (; i <= total_elements - 2; i += 2) {\n        __m128d row = _mm_loadu_pd(&mat[i]);\n        sum = _mm_add_pd(sum, row);\n    }\n\n    double sum_array[2];\n    _mm_storeu_pd(sum_array, sum);\n\n    double total_sum = sum_array[0] + sum_array[1];\n\n    for (; i < total_elements; ++i) {\n        total_sum += mat[i];\n    }\n\n    return total_sum / total_elements;\n}\n```"}
{"task_id": "SimdBench_29_SSE", "completion": "```cpp\ndouble matrix_average_simd(const double* mat, size_t m, size_t n) {\n    __m128d sum = _mm_setzero_pd();\n    size_t total_elements = m * n;\n    size_t i = 0;\n\n    for (; i <= total_elements - 2; i += 2) {\n        __m128d row = _mm_loadu_pd(&mat[i]);\n        sum = _mm_add_pd(sum, row);\n    }\n\n    double sum_array[2];\n    _mm_storeu_pd(sum_array, sum);\n\n    double total_sum = sum_array[0] + sum_array[1];\n\n    for (; i < total_elements; ++i) {\n        total_sum += mat[i];\n    }\n\n    return total_sum / total_elements;\n}\n```"}
{"task_id": "SimdBench_30_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool matrix_rows_sorted_verify_simd(const int* matrix, const bool* directions, size_t rows, size_t cols) {\n    for (size_t i = 0; i < rows; ++i) {\n        const int* row = matrix + i * cols;\n        __m128i prev = _mm_loadu_si128((__m128i*)row);\n        __m128i curr;\n        bool ascending = directions[i];\n        size_t j = 4;\n\n        if (ascending) {\n            for (; j <= cols - 4; j += 4) {\n                curr = _mm_loadu_si128((__m128i*)(row + j));\n                __m128i mask = _mm_cmpgt_epi32(prev, curr);\n                if (!_mm_test_all_zeros(mask, mask)) {\n                    return false;\n                }\n                prev = curr;\n            }\n        } else {\n            for (; j <= cols - 4; j += 4) {\n                curr = _mm_loadu_si128((__m128i*)(row + j));\n                __m128i mask = _mm_cmplt_epi32(prev, curr);\n                if (!_mm_test_all_zeros(mask, mask)) {\n                    return false;\n                }\n                prev = curr;\n            }\n        }\n\n        for (; j < cols; ++j) {\n            if ((ascending && row[j - 1] > row[j]) || (!ascending && row[j - 1] < row[j])) {\n                return false;\n            }\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_30_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool matrix_rows_sorted_verify_simd(const int* matrix, const bool* directions, size_t rows, size_t cols) {\n    for (size_t i = 0; i < rows; ++i) {\n        __m128i prev = _mm_loadu_si128((__m128i*)(matrix + i * cols));\n        __m128i curr;\n        bool ascending = directions[i];\n        size_t j = 0;\n\n        for (; j <= cols - 4; j += 4) {\n            curr = _mm_loadu_si128((__m128i*)(matrix + i * cols + j + 1));\n            __m128i cmp_asc = _mm_cmpgt_epi32(prev, curr);\n            __m128i cmp_desc = _mm_cmplt_epi32(prev, curr);\n            __m128i cmp = ascending ? cmp_asc : cmp_desc;\n            if (_mm_movemask_epi8(cmp) != 0) {\n                return false;\n            }\n            prev = curr;\n        }\n\n        for (; j < cols - 1; ++j) {\n            if ((ascending && matrix[i * cols + j] > matrix[i * cols + j + 1]) ||\n                (!ascending && matrix[i * cols + j] < matrix[i * cols + j + 1])) {\n                return false;\n            }\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_30_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool matrix_rows_sorted_verify_simd(const int* matrix, const bool* directions, size_t rows, size_t cols) {\n    for (size_t i = 0; i < rows; ++i) {\n        __m128i prev = _mm_loadu_si128(reinterpret_cast<const __m128i*>(matrix + i * cols));\n        __m128i curr;\n        bool ascending = directions[i];\n        size_t j = 0;\n\n        for (; j <= cols - 4; j += 4) {\n            curr = _mm_loadu_si128(reinterpret_cast<const __m128i*>(matrix + i * cols + j + 1));\n            __m128i cmp_asc = _mm_cmpgt_epi32(prev, curr);\n            __m128i cmp_desc = _mm_cmplt_epi32(prev, curr);\n            __m128i result = ascending ? cmp_asc : cmp_desc;\n            if (_mm_movemask_epi8(result) != 0) {\n                return false;\n            }\n            prev = curr;\n        }\n\n        for (; j < cols - 1; ++j) {\n            if ((ascending && matrix[i * cols + j] > matrix[i * cols + j + 1]) ||\n                (!ascending && matrix[i * cols + j] < matrix[i * cols + j + 1])) {\n                return false;\n            }\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_30_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool matrix_rows_sorted_verify_simd(const int* matrix, const bool* directions, size_t rows, size_t cols) {\n    for (size_t i = 0; i < rows; ++i) {\n        const int* row = matrix + i * cols;\n        __m128i prev = _mm_loadu_si128(reinterpret_cast<const __m128i*>(row));\n        __m128i curr;\n        bool ascending = directions[i];\n        size_t j = 4;\n\n        if (ascending) {\n            for (; j <= cols - 4; j += 4) {\n                curr = _mm_loadu_si128(reinterpret_cast<const __m128i*>(row + j));\n                __m128i cmp = _mm_cmpgt_epi32(prev, curr);\n                if (!_mm_test_all_zeros(cmp, cmp)) {\n                    return false;\n                }\n                prev = curr;\n            }\n        } else {\n            for (; j <= cols - 4; j += 4) {\n                curr = _mm_loadu_si128(reinterpret_cast<const __m128i*>(row + j));\n                __m128i cmp = _mm_cmplt_epi32(prev, curr);\n                if (!_mm_test_all_zeros(cmp, cmp)) {\n                    return false;\n                }\n                prev = curr;\n            }\n        }\n\n        for (; j < cols; ++j) {\n            if ((ascending && row[j - 1] > row[j]) || (!ascending && row[j - 1] < row[j])) {\n                return false;\n            }\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_30_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool matrix_rows_sorted_verify_simd(const int* matrix, const bool* directions, size_t rows, size_t cols) {\n    for (size_t i = 0; i < rows; ++i) {\n        __m128i prev = _mm_loadu_si128(reinterpret_cast<const __m128i*>(matrix + i * cols));\n        __m128i curr;\n        bool ascending = directions[i];\n        size_t j = 0;\n\n        for (; j <= cols - 4; j += 4) {\n            curr = _mm_loadu_si128(reinterpret_cast<const __m128i*>(matrix + i * cols + j + 1));\n            __m128i cmp_asc = _mm_cmpgt_epi32(prev, curr);\n            __m128i cmp_desc = _mm_cmplt_epi32(prev, curr);\n            __m128i result = ascending ? cmp_asc : cmp_desc;\n            if (_mm_movemask_epi8(result) != 0) {\n                return false;\n            }\n            prev = curr;\n        }\n\n        for (; j < cols - 1; ++j) {\n            if ((ascending && matrix[i * cols + j] > matrix[i * cols + j + 1]) ||\n                (!ascending && matrix[i * cols + j] < matrix[i * cols + j + 1])) {\n                return false;\n            }\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_31_SSE", "completion": "```cpp\nvoid nearest_multiple_simd(const int16_t* src, int16_t* dst, uint8_t base, size_t length) {\n    __m128i base_vec = _mm_set1_epi16(base);\n    size_t i = 0;\n    for (; i <= length - 8; i += 8) {\n        __m128i src_vec = _mm_loadu_si128((__m128i const*)(src + i));\n        __m128i div_result = _mm_div_epi16(src_vec, base_vec);\n        __m128i result = _mm_mullo_epi16(div_result, base_vec);\n        _mm_storeu_si128((__m128i*)(dst + i), result);\n    }\n    for (; i < length; ++i) {\n        dst[i] = (src[i] / base) * base;\n    }\n}\n```"}
{"task_id": "SimdBench_31_SSE", "completion": "```cpp\nvoid nearest_multiple_simd(const int16_t* src, int16_t* dst, uint8_t base, size_t length) {\n    __m128i base_vec = _mm_set1_epi16(base);\n    __m128i zero_vec = _mm_setzero_si128();\n\n    for (size_t i = 0; i < length; i += 8) {\n        __m128i src_vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(src + i));\n        __m128i div_result = _mm_div_epi16(src_vec, base_vec);\n        __m128i result = _mm_mullo_epi16(div_result, base_vec);\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(dst + i), result);\n    }\n}\n```"}
{"task_id": "SimdBench_31_SSE", "completion": "```cpp\nvoid nearest_multiple_simd(const int16_t* src, int16_t* dst, uint8_t base, size_t length) {\n    __m128i base_vec = _mm_set1_epi16(base);\n    __m128i zero_vec = _mm_setzero_si128();\n\n    for (size_t i = 0; i < length; i += 8) {\n        __m128i src_vec = _mm_loadu_si128((__m128i const*)(src + i));\n        __m128i div_result = _mm_div_epi16(src_vec, base_vec);\n        __m128i result = _mm_mullo_epi16(div_result, base_vec);\n        _mm_storeu_si128((__m128i*)(dst + i), result);\n    }\n}\n```"}
{"task_id": "SimdBench_31_SSE", "completion": "```cpp\nvoid nearest_multiple_simd(const int16_t* src, int16_t* dst, uint8_t base, size_t length) {\n    __m128i base_vec = _mm_set1_epi16(base);\n    size_t i = 0;\n    for (; i <= length - 8; i += 8) {\n        __m128i src_vec = _mm_loadu_si128((__m128i const*)(src + i));\n        __m128i div_result = _mm_div_epi16(src_vec, base_vec);\n        __m128i result = _mm_mullo_epi16(div_result, base_vec);\n        _mm_storeu_si128((__m128i*)(dst + i), result);\n    }\n    for (; i < length; ++i) {\n        dst[i] = (src[i] / base) * base;\n    }\n}\n```"}
{"task_id": "SimdBench_31_SSE", "completion": "```cpp\nvoid nearest_multiple_simd(const int16_t* src, int16_t* dst, uint8_t base, size_t length) {\n    __m128i base_vec = _mm_set1_epi16(base);\n    __m128i zero_vec = _mm_setzero_si128();\n\n    for (size_t i = 0; i < length; i += 8) {\n        __m128i src_vec = _mm_loadu_si128((__m128i const*)(src + i));\n        __m128i div_result = _mm_div_epi16(src_vec, base_vec);\n        __m128i result = _mm_mullo_epi16(div_result, base_vec);\n        _mm_storeu_si128((__m128i*)(dst + i), result);\n    }\n}\n```"}
{"task_id": "SimdBench_32_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool matrix_has_row_simd(const double* matrix, const double* vector, size_t rows, size_t cols) {\n    __m128d vec = _mm_loadu_pd(vector);\n    for (size_t i = 0; i < rows; ++i) {\n        bool match = true;\n        for (size_t j = 0; j < cols; j += 2) {\n            __m128d mat = _mm_loadu_pd(&matrix[i * cols + j]);\n            __m128d cmp = _mm_cmpeq_pd(mat, vec);\n            int mask = _mm_movemask_pd(cmp);\n            if (mask != 3) {\n                match = false;\n                break;\n            }\n        }\n        if (match) {\n            return true;\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_32_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool matrix_has_row_simd(const double* matrix, const double* vector, size_t rows, size_t cols) {\n    __m128d vec = _mm_loadu_pd(vector);\n    for (size_t i = 0; i < rows; ++i) {\n        bool match = true;\n        for (size_t j = 0; j < cols; j += 2) {\n            __m128d mat = _mm_loadu_pd(&matrix[i * cols + j]);\n            __m128d cmp = _mm_cmpeq_pd(mat, vec);\n            int mask = _mm_movemask_pd(cmp);\n            if (mask != 3) {\n                match = false;\n                break;\n            }\n        }\n        if (match) {\n            return true;\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_32_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool matrix_has_row_simd(const double* matrix, const double* vector, size_t rows, size_t cols) {\n    __m128d vec = _mm_loadu_pd(vector);\n    for (size_t i = 0; i < rows; ++i) {\n        bool match = true;\n        for (size_t j = 0; j < cols; j += 2) {\n            __m128d row = _mm_loadu_pd(&matrix[i * cols + j]);\n            __m128d cmp = _mm_cmpeq_pd(row, vec);\n            int mask = _mm_movemask_pd(cmp);\n            if (mask != 3) {\n                match = false;\n                break;\n            }\n        }\n        if (match) {\n            return true;\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_32_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool matrix_has_row_simd(const double* matrix, const double* vector, size_t rows, size_t cols) {\n    __m128d vec = _mm_loadu_pd(vector);\n    for (size_t i = 0; i < rows; ++i) {\n        bool match = true;\n        for (size_t j = 0; j < cols; j += 2) {\n            __m128d mat = _mm_loadu_pd(&matrix[i * cols + j]);\n            __m128d cmp = _mm_cmpeq_pd(mat, vec);\n            int mask = _mm_movemask_pd(cmp);\n            if (mask != 3) {\n                match = false;\n                break;\n            }\n        }\n        if (match) {\n            return true;\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_32_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool matrix_has_row_simd(const double* matrix, const double* vector, size_t rows, size_t cols) {\n    __m128d vec = _mm_loadu_pd(vector);\n    for (size_t i = 0; i < rows; ++i) {\n        bool match = true;\n        for (size_t j = 0; j < cols; j += 2) {\n            __m128d mat = _mm_loadu_pd(&matrix[i * cols + j]);\n            __m128d cmp = _mm_cmpeq_pd(mat, vec);\n            int mask = _mm_movemask_pd(cmp);\n            if (mask != 3) {\n                match = false;\n                break;\n            }\n        }\n        if (match) {\n            return true;\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_33_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nsize_t tensor_4d_equal_count_simd(const uint8_t* A, const uint8_t* B, const size_t dims[4]) {\n    size_t total_elements = dims[0] * dims[1] * dims[2] * dims[3];\n    size_t i = 0;\n    size_t count = 0;\n\n    for (; i <= total_elements - 16; i += 16) {\n        __m128i vecA = _mm_loadu_si128(reinterpret_cast<const __m128i*>(A + i));\n        __m128i vecB = _mm_loadu_si128(reinterpret_cast<const __m128i*>(B + i));\n        __m128i eq = _mm_cmpeq_epi8(vecA, vecB);\n        __m128i ones = _mm_set1_epi8(1);\n        __m128i eq_count = _mm_and_si128(eq, ones);\n        count += _mm_popcnt_u32(_mm_movemask_epi8(eq_count));\n    }\n\n    for (; i < total_elements; ++i) {\n        count += (A[i] == B[i]);\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_33_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nsize_t tensor_4d_equal_count_simd(const uint8_t* A, const uint8_t* B, const size_t dims[4]) {\n    size_t total_elements = dims[0] * dims[1] * dims[2] * dims[3];\n    size_t i = 0;\n    size_t count = 0;\n\n    for (; i <= total_elements - 16; i += 16) {\n        __m128i vecA = _mm_loadu_si128(reinterpret_cast<const __m128i*>(A + i));\n        __m128i vecB = _mm_loadu_si128(reinterpret_cast<const __m128i*>(B + i));\n        __m128i eq = _mm_cmpeq_epi8(vecA, vecB);\n        __m128i ones = _mm_set1_epi8(1);\n        __m128i eq_count = _mm_and_si128(eq, ones);\n        __m128i sum = _mm_sad_epu8(eq_count, _mm_setzero_si128());\n        count += _mm_extract_epi16(sum, 0) + _mm_extract_epi16(sum, 4);\n    }\n\n    for (; i < total_elements; ++i) {\n        count += (A[i] == B[i]);\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_33_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nsize_t tensor_4d_equal_count_simd(const uint8_t* A, const uint8_t* B, const size_t dims[4]) {\n    size_t total_elements = dims[0] * dims[1] * dims[2] * dims[3];\n    size_t i = 0;\n    size_t count = 0;\n\n    for (; i <= total_elements - 16; i += 16) {\n        __m128i vecA = _mm_loadu_si128(reinterpret_cast<const __m128i*>(A + i));\n        __m128i vecB = _mm_loadu_si128(reinterpret_cast<const __m128i*>(B + i));\n        __m128i eq = _mm_cmpeq_epi8(vecA, vecB);\n        __m128i ones = _mm_set1_epi8(1);\n        __m128i eq_count = _mm_and_si128(eq, ones);\n        count += _mm_popcnt_u32(_mm_movemask_epi8(eq_count));\n    }\n\n    for (; i < total_elements; ++i) {\n        count += (A[i] == B[i]);\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_33_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nsize_t tensor_4d_equal_count_simd(const uint8_t* A, const uint8_t* B, const size_t dims[4]) {\n    size_t total_elements = dims[0] * dims[1] * dims[2] * dims[3];\n    size_t i = 0;\n    size_t count = 0;\n\n    for (; i <= total_elements - 16; i += 16) {\n        __m128i vecA = _mm_loadu_si128(reinterpret_cast<const __m128i*>(A + i));\n        __m128i vecB = _mm_loadu_si128(reinterpret_cast<const __m128i*>(B + i));\n        __m128i eq = _mm_cmpeq_epi8(vecA, vecB);\n        __m128i ones = _mm_set1_epi8(1);\n        __m128i eq_count = _mm_and_si128(eq, ones);\n        __m128i sum = _mm_sad_epu8(eq_count, _mm_setzero_si128());\n        count += _mm_extract_epi16(sum, 0) + _mm_extract_epi16(sum, 4);\n    }\n\n    for (; i < total_elements; ++i) {\n        count += (A[i] == B[i]);\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_33_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nsize_t tensor_4d_equal_count_simd(const uint8_t* A, const uint8_t* B, const size_t dims[4]) {\n    size_t total_elements = dims[0] * dims[1] * dims[2] * dims[3];\n    size_t i = 0;\n    size_t count = 0;\n\n    for (; i <= total_elements - 16; i += 16) {\n        __m128i vecA = _mm_loadu_si128(reinterpret_cast<const __m128i*>(A + i));\n        __m128i vecB = _mm_loadu_si128(reinterpret_cast<const __m128i*>(B + i));\n        __m128i eq = _mm_cmpeq_epi8(vecA, vecB);\n        __m128i ones = _mm_set1_epi8(1);\n        __m128i eq_count = _mm_and_si128(eq, ones);\n        count += _mm_popcnt_u32(_mm_movemask_epi8(eq_count));\n    }\n\n    for (; i < total_elements; ++i) {\n        count += (A[i] == B[i]);\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_34_SSE", "completion": "```cpp\nvoid axm_abs_simd(size_t length, const int64_t a, const int64_t *x, int64_t *y) {\n    __m128i scalar = _mm_set1_epi64x(a);\n    size_t i = 0;\n\n    for (; i <= length - 2; i += 2) {\n        __m128i vx = _mm_loadu_si128((__m128i*)&x[i]);\n        __m128i vy = _mm_loadu_si128((__m128i*)&y[i]);\n\n        __m128i vax = _mm_mullo_epi64(scalar, vx);\n        __m128i vabs_y = _mm_abs_epi64(vy);\n\n        __m128i result = _mm_sub_epi64(vabs_y, vax);\n        _mm_storeu_si128((__m128i*)&y[i], result);\n    }\n\n    // Handle remaining elements\n    for (; i < length; ++i) {\n        y[i] = llabs(y[i]) - a * x[i];\n    }\n}\n```"}
{"task_id": "SimdBench_34_SSE", "completion": "```cpp\nvoid axm_abs_simd(size_t length, const int64_t a, const int64_t *x, int64_t *y) {\n    __m128i scalar = _mm_set1_epi64x(a);\n    size_t i = 0;\n\n    for (; i <= length - 2; i += 2) {\n        __m128i vec_x = _mm_loadu_si128((__m128i*)&x[i]);\n        __m128i vec_y = _mm_loadu_si128((__m128i*)&y[i]);\n\n        __m128i mul_result = _mm_mullo_epi64(scalar, vec_x);\n        __m128i abs_result = _mm_abs_epi64(vec_y);\n\n        __m128i sub_result = _mm_sub_epi64(abs_result, mul_result);\n        _mm_storeu_si128((__m128i*)&y[i], sub_result);\n    }\n\n    for (; i < length; ++i) {\n        y[i] = llabs(y[i]) - a * x[i];\n    }\n}\n```"}
{"task_id": "SimdBench_34_SSE", "completion": "```cpp\nvoid axm_abs_simd(size_t length, const int64_t a, const int64_t *x, int64_t *y) {\n    __m128i scalar = _mm_set1_epi64x(a);\n    size_t i = 0;\n\n    for (; i <= length - 2; i += 2) {\n        __m128i vec_x = _mm_loadu_si128((__m128i*)&x[i]);\n        __m128i vec_y = _mm_loadu_si128((__m128i*)&y[i]);\n\n        __m128i mul_result = _mm_mullo_epi64(scalar, vec_x);\n        __m128i abs_result = _mm_abs_epi64(vec_y);\n\n        __m128i sub_result = _mm_sub_epi64(abs_result, mul_result);\n\n        _mm_storeu_si128((__m128i*)&y[i], sub_result);\n    }\n\n    // Handle remaining elements\n    for (; i < length; ++i) {\n        y[i] = llabs(y[i]) - a * x[i];\n    }\n}\n```"}
{"task_id": "SimdBench_34_SSE", "completion": "```cpp\nvoid axm_abs_simd(size_t length, const int64_t a, const int64_t *x, int64_t *y) {\n    __m128i scalar = _mm_set1_epi64x(a);\n    size_t i = 0;\n\n    for (; i <= length - 2; i += 2) {\n        __m128i vec_x = _mm_loadu_si128((__m128i*)&x[i]);\n        __m128i vec_y = _mm_loadu_si128((__m128i*)&y[i]);\n\n        __m128i mul_result = _mm_mullo_epi64(scalar, vec_x);\n        __m128i abs_result = _mm_abs_epi64(vec_y);\n\n        __m128i sub_result = _mm_sub_epi64(abs_result, mul_result);\n\n        _mm_storeu_si128((__m128i*)&y[i], sub_result);\n    }\n\n    // Handle remaining elements\n    for (; i < length; ++i) {\n        y[i] = llabs(y[i]) - a * x[i];\n    }\n}\n```"}
{"task_id": "SimdBench_34_SSE", "completion": "```cpp\nvoid axm_abs_simd(size_t length, const int64_t a, const int64_t *x, int64_t *y) {\n    __m128i scalar = _mm_set1_epi64x(a);\n    for (size_t i = 0; i < length; i += 2) {\n        __m128i vec_x = _mm_loadu_si128((__m128i*)&x[i]);\n        __m128i vec_y = _mm_loadu_si128((__m128i*)&y[i]);\n        __m128i mul_result = _mm_mullo_epi64(scalar, vec_x);\n        __m128i abs_result = _mm_abs_epi64(vec_y);\n        __m128i sub_result = _mm_sub_epi64(abs_result, mul_result);\n        _mm_storeu_si128((__m128i*)&y[i], sub_result);\n    }\n}\n```"}
{"task_id": "SimdBench_35_SSE", "completion": "```c\nMinMaxPair min_max_pair_simd(const int16_t* vec, size_t length) {\n    __m128i min_val = _mm_set1_epi16(INT16_MAX);\n    __m128i max_val = _mm_set1_epi16(INT16_MIN);\n\n    size_t i = 0;\n    for (; i <= length - 8; i += 8) {\n        __m128i current = _mm_loadu_si128((__m128i const*)(vec + i));\n        min_val = _mm_min_epi16(min_val, current);\n        max_val = _mm_max_epi16(max_val, current);\n    }\n\n    int16_t min_array[8], max_array[8];\n    _mm_storeu_si128((__m128i*)min_array, min_val);\n    _mm_storeu_si128((__m128i*)max_array, max_val);\n\n    int16_t min_result = min_array[0];\n    int16_t max_result = max_array[0];\n\n    for (size_t j = 1; j < 8; ++j) {\n        if (min_array[j] < min_result) min_result = min_array[j];\n        if (max_array[j] > max_result) max_result = max_array[j];\n    }\n\n    for (; i < length; ++i) {\n        if (vec[i] < min_result) min_result = vec[i];\n        if (vec[i] > max_result) max_result = vec[i];\n    }\n\n    return (MinMaxPair){min_result, max_result};\n}\n```"}
{"task_id": "SimdBench_35_SSE", "completion": "```c\nMinMaxPair min_max_pair_simd(const int16_t* vec, size_t length) {\n    __m128i min_val = _mm_set1_epi16(INT16_MAX);\n    __m128i max_val = _mm_set1_epi16(INT16_MIN);\n\n    size_t i = 0;\n    for (; i <= length - 8; i += 8) {\n        __m128i current = _mm_loadu_si128((__m128i const*)(vec + i));\n        min_val = _mm_min_epi16(min_val, current);\n        max_val = _mm_max_epi16(max_val, current);\n    }\n\n    int16_t min_array[8], max_array[8];\n    _mm_storeu_si128((__m128i*)min_array, min_val);\n    _mm_storeu_si128((__m128i*)max_array, max_val);\n\n    int16_t min_result = min_array[0];\n    int16_t max_result = max_array[0];\n\n    for (size_t j = 1; j < 8; ++j) {\n        if (min_array[j] < min_result) min_result = min_array[j];\n        if (max_array[j] > max_result) max_result = max_array[j];\n    }\n\n    for (; i < length; ++i) {\n        if (vec[i] < min_result) min_result = vec[i];\n        if (vec[i] > max_result) max_result = vec[i];\n    }\n\n    return (MinMaxPair){min_result, max_result};\n}\n```"}
{"task_id": "SimdBench_35_SSE", "completion": "```c\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\ntypedef struct {\n    int16_t min_num;\n    int16_t max_num;\n} MinMaxPair;\n\nMinMaxPair min_max_pair_simd(const int16_t* vec, size_t length) {\n    __m128i min_val = _mm_set1_epi16(INT16_MAX);\n    __m128i max_val = _mm_set1_epi16(INT16_MIN);\n\n    size_t i = 0;\n    for (; i <= length - 8; i += 8) {\n        __m128i current = _mm_loadu_si128((__m128i const*)(vec + i));\n        min_val = _mm_min_epi16(min_val, current);\n        max_val = _mm_max_epi16(max_val, current);\n    }\n\n    int16_t min_array[8], max_array[8];\n    _mm_storeu_si128((__m128i*)min_array, min_val);\n    _mm_storeu_si128((__m128i*)max_array, max_val);\n\n    int16_t min_result = min_array[0];\n    int16_t max_result = max_array[0];\n\n    for (size_t j = 1; j < 8; ++j) {\n        if (min_array[j] < min_result) min_result = min_array[j];\n        if (max_array[j] > max_result) max_result = max_array[j];\n    }\n\n    for (; i < length; ++i) {\n        if (vec[i] < min_result) min_result = vec[i];\n        if (vec[i] > max_result) max_result = vec[i];\n    }\n\n    return (MinMaxPair){min_result, max_result};\n}\n```"}
{"task_id": "SimdBench_35_SSE", "completion": "```c\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\ntypedef struct {\n    int16_t min_num;\n    int16_t max_num;\n} MinMaxPair;\n\nMinMaxPair min_max_pair_simd(const int16_t* vec, size_t length) {\n    __m128i min_val = _mm_set1_epi16(INT16_MAX);\n    __m128i max_val = _mm_set1_epi16(INT16_MIN);\n\n    size_t i = 0;\n    for (; i <= length - 8; i += 8) {\n        __m128i current = _mm_loadu_si128((__m128i const*)(vec + i));\n        min_val = _mm_min_epi16(min_val, current);\n        max_val = _mm_max_epi16(max_val, current);\n    }\n\n    int16_t min_array[8], max_array[8];\n    _mm_storeu_si128((__m128i*)min_array, min_val);\n    _mm_storeu_si128((__m128i*)max_array, max_val);\n\n    int16_t min_result = min_array[0];\n    int16_t max_result = max_array[0];\n\n    for (size_t j = 1; j < 8; ++j) {\n        if (min_array[j] < min_result) min_result = min_array[j];\n        if (max_array[j] > max_result) max_result = max_array[j];\n    }\n\n    for (; i < length; ++i) {\n        if (vec[i] < min_result) min_result = vec[i];\n        if (vec[i] > max_result) max_result = vec[i];\n    }\n\n    return (MinMaxPair){min_result, max_result};\n}\n```"}
{"task_id": "SimdBench_35_SSE", "completion": "```c\nMinMaxPair min_max_pair_simd(const int16_t* vec, size_t length) {\n    __m128i min_val = _mm_set1_epi16(INT16_MAX);\n    __m128i max_val = _mm_set1_epi16(INT16_MIN);\n\n    size_t i = 0;\n    for (; i <= length - 8; i += 8) {\n        __m128i current = _mm_loadu_si128((__m128i const*)(vec + i));\n        min_val = _mm_min_epi16(min_val, current);\n        max_val = _mm_max_epi16(max_val, current);\n    }\n\n    int16_t min_array[8], max_array[8];\n    _mm_storeu_si128((__m128i*)min_array, min_val);\n    _mm_storeu_si128((__m128i*)max_array, max_val);\n\n    int16_t min_result = min_array[0];\n    int16_t max_result = max_array[0];\n\n    for (size_t j = 1; j < 8; ++j) {\n        if (min_array[j] < min_result) min_result = min_array[j];\n        if (max_array[j] > max_result) max_result = max_array[j];\n    }\n\n    for (; i < length; ++i) {\n        if (vec[i] < min_result) min_result = vec[i];\n        if (vec[i] > max_result) max_result = vec[i];\n    }\n\n    return (MinMaxPair){min_result, max_result};\n}\n```"}
{"task_id": "SimdBench_36_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool matrix_rows_strictly_increasing_simd(const int* matrix, size_t rows, size_t cols) {\n    if (rows == 0 || cols == 0) return false;\n\n    for (size_t i = 0; i < rows; ++i) {\n        const int* row = matrix + i * cols;\n        __m128i prev = _mm_loadu_si128(reinterpret_cast<const __m128i*>(row));\n        __m128i mask = _mm_set1_epi32(0xFFFFFFFF);\n\n        for (size_t j = 1; j <= cols - 4; j += 4) {\n            __m128i curr = _mm_loadu_si128(reinterpret_cast<const __m128i*>(row + j));\n            __m128i cmp = _mm_cmpgt_epi32(prev, curr);\n            mask = _mm_and_si128(mask, cmp);\n            prev = curr;\n        }\n\n        if (_mm_movemask_epi8(mask) != 0) return false;\n\n        // Check remaining elements\n        for (size_t j = (cols / 4) * 4; j < cols - 1; ++j) {\n            if (row[j] >= row[j + 1]) return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_36_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool matrix_rows_strictly_increasing_simd(const int* matrix, size_t rows, size_t cols) {\n    if (rows == 0 || cols == 0) return false;\n\n    for (size_t i = 0; i < rows; ++i) {\n        const int* row = matrix + i * cols;\n        __m128i prev = _mm_loadu_si128(reinterpret_cast<const __m128i*>(row));\n        __m128i mask = _mm_set1_epi32(0xFFFFFFFF);\n\n        for (size_t j = 1; j <= cols - 4; j += 4) {\n            __m128i curr = _mm_loadu_si128(reinterpret_cast<const __m128i*>(row + j));\n            __m128i cmp = _mm_cmpgt_epi32(prev, curr);\n            mask = _mm_and_si128(mask, cmp);\n            prev = curr;\n        }\n\n        if (_mm_movemask_epi8(mask) != 0) return false;\n\n        // Check remaining elements\n        for (size_t j = (cols / 4) * 4; j < cols - 1; ++j) {\n            if (row[j] >= row[j + 1]) return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_36_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool matrix_rows_strictly_increasing_simd(const int* matrix, size_t rows, size_t cols) {\n    if (rows == 0 || cols == 0) return false;\n\n    for (size_t i = 0; i < rows; ++i) {\n        const int* row = matrix + i * cols;\n        __m128i prev = _mm_loadu_si128(reinterpret_cast<const __m128i*>(row));\n        __m128i mask = _mm_set1_epi32(0xFFFFFFFF);\n\n        for (size_t j = 1; j <= cols - 4; j += 4) {\n            __m128i curr = _mm_loadu_si128(reinterpret_cast<const __m128i*>(row + j));\n            __m128i cmp = _mm_cmpgt_epi32(prev, curr);\n            mask = _mm_and_si128(mask, cmp);\n            prev = curr;\n        }\n\n        if (_mm_movemask_epi8(mask) != 0) return false;\n\n        // Check remaining elements\n        for (size_t j = (cols / 4) * 4; j < cols - 1; ++j) {\n            if (row[j] >= row[j + 1]) return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_36_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool matrix_rows_strictly_increasing_simd(const int* matrix, size_t rows, size_t cols) {\n    if (rows == 0 || cols == 0) return false;\n\n    for (size_t i = 0; i < rows; ++i) {\n        const int* row = matrix + i * cols;\n        __m128i prev = _mm_loadu_si128(reinterpret_cast<const __m128i*>(row));\n        __m128i mask = _mm_set1_epi32(0xFFFFFFFF);\n\n        for (size_t j = 1; j <= cols - 4; j += 4) {\n            __m128i curr = _mm_loadu_si128(reinterpret_cast<const __m128i*>(row + j));\n            __m128i cmp = _mm_cmpgt_epi32(prev, curr);\n            mask = _mm_and_si128(mask, cmp);\n            prev = curr;\n        }\n\n        if (_mm_movemask_epi8(mask) != 0) return false;\n\n        // Check remaining elements\n        for (size_t j = (cols / 4) * 4; j < cols - 1; ++j) {\n            if (row[j] >= row[j + 1]) return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_36_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool matrix_rows_strictly_increasing_simd(const int* matrix, size_t rows, size_t cols) {\n    if (rows == 0 || cols == 0) return false;\n\n    for (size_t i = 0; i < rows; ++i) {\n        const int* row = matrix + i * cols;\n        __m128i prev = _mm_loadu_si128(reinterpret_cast<const __m128i*>(row));\n        __m128i mask = _mm_set1_epi32(0xFFFFFFFF);\n\n        for (size_t j = 1; j <= cols - 4; j += 4) {\n            __m128i curr = _mm_loadu_si128(reinterpret_cast<const __m128i*>(row + j));\n            __m128i cmp = _mm_cmpgt_epi32(prev, curr);\n            mask = _mm_and_si128(mask, cmp);\n            prev = curr;\n        }\n\n        if (_mm_movemask_epi8(mask) != 0) return false;\n\n        // Check remaining elements\n        for (size_t j = (cols / 4) * 4; j < cols - 1; ++j) {\n            if (row[j] >= row[j + 1]) return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_37_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool matrix_blocks_equal_simd(const int* matrix, size_t block_size, size_t rows, size_t cols) {\n    if (block_size == 0 || rows % block_size != 0 || cols % block_size != 0) {\n        return false;\n    }\n\n    size_t num_blocks_row = cols / block_size;\n    size_t num_blocks_col = rows / block_size;\n\n    __m128i first_block[4];\n    for (size_t i = 0; i < block_size && i < 4; ++i) {\n        first_block[i] = _mm_loadu_si128((__m128i const*)(matrix + i * cols));\n    }\n\n    for (size_t block_row = 0; block_row < num_blocks_col; ++block_row) {\n        for (size_t block_col = 0; block_col < num_blocks_row; ++block_col) {\n            if (block_row == 0 && block_col == 0) {\n                continue;\n            }\n\n            __m128i current_block[4];\n            for (size_t i = 0; i < block_size && i < 4; ++i) {\n                current_block[i] = _mm_loadu_si128((__m128i const*)(matrix + (block_row * block_size + i) * cols + block_col * block_size));\n            }\n\n            for (size_t i = 0; i < block_size && i < 4; ++i) {\n                __m128i cmp = _mm_cmpeq_epi32(first_block[i], current_block[i]);\n                if (_mm_movemask_epi8(cmp) != 0xFFFF) {\n                    return false;\n                }\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_37_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool matrix_blocks_equal_simd(const int* matrix, size_t block_size, size_t rows, size_t cols) {\n    if (block_size == 0 || rows % block_size != 0 || cols % block_size != 0) {\n        return false;\n    }\n\n    size_t num_blocks_row = cols / block_size;\n    size_t num_blocks_col = rows / block_size;\n\n    __m128i first_block[4];\n    for (size_t i = 0; i < block_size; ++i) {\n        first_block[i] = _mm_loadu_si128((__m128i const*)(matrix + i * cols));\n    }\n\n    for (size_t block_y = 0; block_y < num_blocks_col; ++block_y) {\n        for (size_t block_x = 0; block_x < num_blocks_row; ++block_x) {\n            if (block_y == 0 && block_x == 0) {\n                continue;\n            }\n\n            for (size_t i = 0; i < block_size; ++i) {\n                __m128i current_block = _mm_loadu_si128((__m128i const*)(matrix + (block_y * block_size + i) * cols + block_x * block_size));\n                __m128i cmp_result = _mm_cmpeq_epi32(current_block, first_block[i]);\n                int mask = _mm_movemask_epi8(cmp_result);\n                if (mask != 0xFFFF) {\n                    return false;\n                }\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_37_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool matrix_blocks_equal_simd(const int* matrix, size_t block_size, size_t rows, size_t cols) {\n    if (block_size == 0 || rows % block_size != 0 || cols % block_size != 0) {\n        return false;\n    }\n\n    size_t num_blocks_row = cols / block_size;\n    size_t num_blocks_col = rows / block_size;\n\n    __m128i first_block[4];\n    for (size_t i = 0; i < block_size; ++i) {\n        first_block[i] = _mm_loadu_si128((__m128i const*)(matrix + i * cols));\n    }\n\n    for (size_t block_row = 0; block_row < num_blocks_col; ++block_row) {\n        for (size_t block_col = 0; block_col < num_blocks_row; ++block_col) {\n            if (block_row == 0 && block_col == 0) continue;\n\n            size_t offset = block_row * block_size * cols + block_col * block_size;\n            for (size_t i = 0; i < block_size; ++i) {\n                __m128i current_block = _mm_loadu_si128((__m128i const*)(matrix + offset + i * cols));\n                __m128i cmp_result = _mm_cmpeq_epi32(current_block, first_block[i]);\n                int mask = _mm_movemask_epi8(cmp_result);\n                if (mask != 0xFFFF) {\n                    return false;\n                }\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_37_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool matrix_blocks_equal_simd(const int* matrix, size_t block_size, size_t rows, size_t cols) {\n    if (block_size == 0 || rows % block_size != 0 || cols % block_size != 0) {\n        return false;\n    }\n\n    size_t num_blocks_row = cols / block_size;\n    size_t num_blocks_col = rows / block_size;\n\n    __m128i first_block[4];\n    for (size_t i = 0; i < block_size; ++i) {\n        first_block[i] = _mm_loadu_si128((__m128i const*)(matrix + i * cols));\n    }\n\n    for (size_t block_row = 0; block_row < num_blocks_col; ++block_row) {\n        for (size_t block_col = 0; block_col < num_blocks_row; ++block_col) {\n            if (block_row == 0 && block_col == 0) continue;\n\n            __m128i current_block[4];\n            for (size_t i = 0; i < block_size; ++i) {\n                current_block[i] = _mm_loadu_si128((__m128i const*)(matrix + (block_row * block_size + i) * cols + block_col * block_size));\n            }\n\n            for (size_t i = 0; i < block_size; ++i) {\n                __m128i cmp = _mm_cmpeq_epi32(first_block[i], current_block[i]);\n                if (_mm_movemask_epi8(cmp) != 0xFFFF) {\n                    return false;\n                }\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_37_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool matrix_blocks_equal_simd(const int* matrix, size_t block_size, size_t rows, size_t cols) {\n    if (block_size == 0 || rows % block_size != 0 || cols % block_size != 0) {\n        return false;\n    }\n\n    size_t num_blocks_row = cols / block_size;\n    size_t num_blocks_col = rows / block_size;\n\n    __m128i first_block[4];\n    for (size_t i = 0; i < block_size; ++i) {\n        first_block[i] = _mm_loadu_si128((__m128i const*)(matrix + i * cols));\n    }\n\n    for (size_t block_y = 0; block_y < num_blocks_col; ++block_y) {\n        for (size_t block_x = 0; block_x < num_blocks_row; ++block_x) {\n            if (block_y == 0 && block_x == 0) {\n                continue;\n            }\n\n            for (size_t i = 0; i < block_size; ++i) {\n                __m128i current_block = _mm_loadu_si128((__m128i const*)(matrix + (block_y * block_size + i) * cols + block_x * block_size));\n                __m128i cmp_result = _mm_cmpeq_epi32(current_block, first_block[i]);\n                int mask = _mm_movemask_epi8(cmp_result);\n                if (mask != 0xFFFF) {\n                    return false;\n                }\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_38_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool vector_block_equal_simd(const double* vec, double tolerance, size_t length, size_t block_size) {\n    if (!vec || length < block_size || block_size == 0) {\n        return false;\n    }\n\n    __m128d tolerance_vec = _mm_set1_pd(tolerance);\n    __m128d first_block0 = _mm_loadu_pd(&vec[0]);\n    __m128d first_block1 = _mm_loadu_pd(&vec[2]);\n\n    for (size_t i = block_size; i <= length - block_size; i += block_size) {\n        __m128d block0 = _mm_loadu_pd(&vec[i]);\n        __m128d block1 = _mm_loadu_pd(&vec[i + 2]);\n\n        __m128d diff0 = _mm_sub_pd(block0, first_block0);\n        __m128d diff1 = _mm_sub_pd(block1, first_block1);\n\n        __m128d abs_diff0 = _mm_andnot_pd(_mm_set1_pd(-0.0), diff0);\n        __m128d abs_diff1 = _mm_andnot_pd(_mm_set1_pd(-0.0), diff1);\n\n        __m128d mask0 = _mm_cmple_pd(abs_diff0, tolerance_vec);\n        __m128d mask1 = _mm_cmple_pd(abs_diff1, tolerance_vec);\n\n        if (_mm_movemask_epi8(_mm_castpd_si128(mask0)) != 0xFFFF || \n            _mm_movemask_epi8(_mm_castpd_si128(mask1)) != 0xFFFF) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_38_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool vector_block_equal_simd(const double* vec, double tolerance, size_t length, size_t block_size) {\n    if (!vec || length < block_size || block_size == 0) {\n        return false;\n    }\n\n    __m128d tol_vec = _mm_set1_pd(tolerance);\n    __m128d first_block0 = _mm_loadu_pd(&vec[0]);\n    __m128d first_block1 = _mm_loadu_pd(&vec[2]);\n\n    for (size_t i = block_size; i <= length - block_size; i += block_size) {\n        __m128d block0 = _mm_loadu_pd(&vec[i]);\n        __m128d block1 = _mm_loadu_pd(&vec[i + 2]);\n\n        __m128d diff0 = _mm_sub_pd(block0, first_block0);\n        __m128d diff1 = _mm_sub_pd(block1, first_block1);\n\n        __m128d abs_diff0 = _mm_andnot_pd(_mm_set1_pd(-0.0), diff0);\n        __m128d abs_diff1 = _mm_andnot_pd(_mm_set1_pd(-0.0), diff1);\n\n        __m128d cmp0 = _mm_cmpgt_pd(abs_diff0, tol_vec);\n        __m128d cmp1 = _mm_cmpgt_pd(abs_diff1, tol_vec);\n\n        if (_mm_movemask_pd(cmp0) != 0 || _mm_movemask_pd(cmp1) != 0) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_38_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool vector_block_equal_simd(const double* vec, double tolerance, size_t length, size_t block_size) {\n    if (!vec || length < block_size || block_size == 0) {\n        return false;\n    }\n\n    __m128d tol = _mm_set1_pd(tolerance);\n    __m128d first_block0 = _mm_loadu_pd(&vec[0]);\n    __m128d first_block1 = _mm_loadu_pd(&vec[2]);\n\n    size_t num_blocks = length / block_size;\n    if (num_blocks < 2) {\n        return false;\n    }\n\n    for (size_t i = 1; i < num_blocks; ++i) {\n        __m128d block0 = _mm_loadu_pd(&vec[i * block_size]);\n        __m128d block1 = _mm_loadu_pd(&vec[i * block_size + 2]);\n\n        __m128d diff0 = _mm_sub_pd(block0, first_block0);\n        __m128d diff1 = _mm_sub_pd(block1, first_block1);\n\n        __m128d abs_diff0 = _mm_andnot_pd(_mm_set1_pd(-0.0), diff0);\n        __m128d abs_diff1 = _mm_andnot_pd(_mm_set1_pd(-0.0), diff1);\n\n        __m128d cmp0 = _mm_cmpgt_pd(abs_diff0, tol);\n        __m128d cmp1 = _mm_cmpgt_pd(abs_diff1, tol);\n\n        if (_mm_movemask_pd(cmp0) != 0 || _mm_movemask_pd(cmp1) != 0) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_38_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool vector_block_equal_simd(const double* vec, double tolerance, size_t length, size_t block_size) {\n    if (!vec || length < block_size || block_size == 0) {\n        return false;\n    }\n\n    __m128d tol = _mm_set1_pd(tolerance);\n    __m128d first_block0 = _mm_loadu_pd(&vec[0]);\n    __m128d first_block1 = _mm_loadu_pd(&vec[2]);\n\n    for (size_t i = block_size; i <= length - block_size; i += block_size) {\n        __m128d block0 = _mm_loadu_pd(&vec[i]);\n        __m128d block1 = _mm_loadu_pd(&vec[i + 2]);\n\n        __m128d diff0 = _mm_sub_pd(block0, first_block0);\n        __m128d diff1 = _mm_sub_pd(block1, first_block1);\n\n        __m128d abs_diff0 = _mm_andnot_pd(_mm_set1_pd(-0.0), diff0);\n        __m128d abs_diff1 = _mm_andnot_pd(_mm_set1_pd(-0.0), diff1);\n\n        __m128d cmp0 = _mm_cmpgt_pd(abs_diff0, tol);\n        __m128d cmp1 = _mm_cmpgt_pd(abs_diff1, tol);\n\n        if (_mm_movemask_pd(cmp0) || _mm_movemask_pd(cmp1)) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_38_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool vector_block_equal_simd(const double* vec, double tolerance, size_t length, size_t block_size) {\n    if (!vec || length < block_size || block_size == 0) {\n        return false;\n    }\n\n    __m128d tol = _mm_set1_pd(tolerance);\n    __m128d first_block0 = _mm_loadu_pd(&vec[0]);\n    __m128d first_block1 = _mm_loadu_pd(&vec[2]);\n\n    for (size_t i = block_size; i <= length - block_size; i += block_size) {\n        __m128d block0 = _mm_loadu_pd(&vec[i]);\n        __m128d block1 = _mm_loadu_pd(&vec[i + 2]);\n\n        __m128d diff0 = _mm_sub_pd(block0, first_block0);\n        __m128d diff1 = _mm_sub_pd(block1, first_block1);\n\n        __m128d abs_diff0 = _mm_andnot_pd(_mm_set1_pd(-0.0), diff0);\n        __m128d abs_diff1 = _mm_andnot_pd(_mm_set1_pd(-0.0), diff1);\n\n        __m128d cmp0 = _mm_cmple_pd(abs_diff0, tol);\n        __m128d cmp1 = _mm_cmple_pd(abs_diff1, tol);\n\n        if (_mm_movemask_pd(cmp0) != 0x3 || _mm_movemask_pd(cmp1) != 0x3) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_39_SSE", "completion": "```cpp\nvoid matrix_row_norm_compare_simd(const double* matrix, const double* thresholds, size_t rows, size_t cols, bool* result) {\n    for (size_t i = 0; i < rows; ++i) {\n        __m128d sum = _mm_setzero_pd();\n        for (size_t j = 0; j < cols; j += 2) {\n            __m128d row = _mm_loadu_pd(&matrix[i * cols + j]);\n            row = _mm_mul_pd(row, row);\n            sum = _mm_add_pd(sum, row);\n        }\n        __m128d norm = _mm_sqrt_pd(sum);\n        __m128d threshold = _mm_load_sd(&thresholds[i]);\n        threshold = _mm_unpacklo_pd(threshold, threshold);\n        __m128d comparison = _mm_cmpgt_pd(norm, threshold);\n        int mask = _mm_movemask_pd(comparison);\n        result[i] = (mask & 3) != 0;\n    }\n}\n```"}
{"task_id": "SimdBench_39_SSE", "completion": "```cpp\nvoid matrix_row_norm_compare_simd(const double* matrix, const double* thresholds, size_t rows, size_t cols, bool* result) {\n    for (size_t i = 0; i < rows; ++i) {\n        __m128d sum = _mm_setzero_pd();\n        for (size_t j = 0; j < cols; j += 2) {\n            __m128d row = _mm_loadu_pd(&matrix[i * cols + j]);\n            row = _mm_mul_pd(row, row);\n            sum = _mm_add_pd(sum, row);\n        }\n        sum = _mm_hadd_pd(sum, sum);\n        double norm = _mm_cvtsd_f64(sum);\n        result[i] = (norm > thresholds[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_39_SSE", "completion": "```cpp\nvoid matrix_row_norm_compare_simd(const double* matrix, const double* thresholds, size_t rows, size_t cols, bool* result) {\n    for (size_t i = 0; i < rows; ++i) {\n        __m128d sum = _mm_setzero_pd();\n        for (size_t j = 0; j < cols; j += 2) {\n            __m128d row = _mm_loadu_pd(&matrix[i * cols + j]);\n            row = _mm_mul_pd(row, row);\n            sum = _mm_add_pd(sum, row);\n        }\n        sum = _mm_hadd_pd(sum, sum);\n        double norm = _mm_cvtsd_f64(sum);\n        result[i] = (norm > thresholds[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_39_SSE", "completion": "```cpp\nvoid matrix_row_norm_compare_simd(const double* matrix, const double* thresholds, size_t rows, size_t cols, bool* result) {\n    for (size_t i = 0; i < rows; ++i) {\n        __m128d sum = _mm_setzero_pd();\n        for (size_t j = 0; j < cols; j += 2) {\n            __m128d row = _mm_loadu_pd(&matrix[i * cols + j]);\n            row = _mm_mul_pd(row, row);\n            sum = _mm_add_pd(sum, row);\n        }\n        __m128d norm = _mm_sqrt_pd(sum);\n        __m128d threshold = _mm_load_sd(&thresholds[i]);\n        threshold = _mm_unpacklo_pd(threshold, threshold);\n        __m128d comparison = _mm_cmpgt_pd(norm, threshold);\n        int mask = _mm_movemask_pd(comparison);\n        result[i] = (mask & 3) != 0;\n    }\n}\n```"}
{"task_id": "SimdBench_39_SSE", "completion": "```cpp\nvoid matrix_row_norm_compare_simd(const double* matrix, const double* thresholds, size_t rows, size_t cols, bool* result) {\n    for (size_t i = 0; i < rows; ++i) {\n        __m128d sum = _mm_setzero_pd();\n        for (size_t j = 0; j < cols; j += 2) {\n            __m128d row = _mm_loadu_pd(&matrix[i * cols + j]);\n            row = _mm_mul_pd(row, row);\n            sum = _mm_add_pd(sum, row);\n        }\n        sum = _mm_hadd_pd(sum, sum);\n        double norm = _mm_cvtsd_f64(sum);\n        result[i] = (norm > thresholds[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_40_SSE", "completion": "```cpp\nvoid tensor_bitwise_or_simd(const uint32_t* A, const uint32_t* B, uint32_t* C, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 4; i += 4) {\n        __m128i a = _mm_loadu_si128((__m128i*)(A + i));\n        __m128i b = _mm_loadu_si128((__m128i*)(B + i));\n        __m128i result = _mm_or_si128(a, b);\n        _mm_storeu_si128((__m128i*)(C + i), result);\n    }\n    for (; i < length; ++i) {\n        C[i] = A[i] | B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_40_SSE", "completion": "```cpp\nvoid tensor_bitwise_or_simd(const uint32_t* A, const uint32_t* B, uint32_t* C, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 4; i += 4) {\n        __m128i a = _mm_loadu_si128((__m128i*)(A + i));\n        __m128i b = _mm_loadu_si128((__m128i*)(B + i));\n        __m128i result = _mm_or_si128(a, b);\n        _mm_storeu_si128((__m128i*)(C + i), result);\n    }\n    for (; i < length; ++i) {\n        C[i] = A[i] | B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_40_SSE", "completion": "```cpp\nvoid tensor_bitwise_or_simd(const uint32_t* A, const uint32_t* B, uint32_t* C, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 4; i += 4) {\n        __m128i a = _mm_loadu_si128((__m128i*)(A + i));\n        __m128i b = _mm_loadu_si128((__m128i*)(B + i));\n        __m128i result = _mm_or_si128(a, b);\n        _mm_storeu_si128((__m128i*)(C + i), result);\n    }\n    for (; i < length; ++i) {\n        C[i] = A[i] | B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_40_SSE", "completion": "```cpp\nvoid tensor_bitwise_or_simd(const uint32_t* A, const uint32_t* B, uint32_t* C, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 4; i += 4) {\n        __m128i a = _mm_loadu_si128((__m128i*)(A + i));\n        __m128i b = _mm_loadu_si128((__m128i*)(B + i));\n        __m128i result = _mm_or_si128(a, b);\n        _mm_storeu_si128((__m128i*)(C + i), result);\n    }\n    for (; i < length; ++i) {\n        C[i] = A[i] | B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_40_SSE", "completion": "```cpp\nvoid tensor_bitwise_or_simd(const uint32_t* A, const uint32_t* B, uint32_t* C, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 4; i += 4) {\n        __m128i a = _mm_loadu_si128((__m128i*)(A + i));\n        __m128i b = _mm_loadu_si128((__m128i*)(B + i));\n        __m128i result = _mm_or_si128(a, b);\n        _mm_storeu_si128((__m128i*)(C + i), result);\n    }\n    for (; i < length; ++i) {\n        C[i] = A[i] | B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_41_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint64_t squarediff_simd(const int8_t * A, const int8_t * B, size_t length) {\n    __m128i sum_squares = _mm_setzero_si128();\n    __m128i sum_products = _mm_setzero_si128();\n    size_t i = 0;\n\n    for (; i <= length - 16; i += 16) {\n        __m128i a = _mm_loadu_si128((__m128i const*)(A + i));\n        __m128i b = _mm_loadu_si128((__m128i const*)(B + i));\n\n        __m128i a_squared = _mm_maddubs_epi16(a, a);\n        __m128i b_squared = _mm_maddubs_epi16(b, b);\n        __m128i products = _mm_maddubs_epi16(a, b);\n\n        sum_squares = _mm_add_epi32(sum_squares, _mm_add_epi32(a_squared, b_squared));\n        sum_products = _mm_add_epi32(sum_products, products);\n    }\n\n    int32_t sum_squares_array[4];\n    int32_t sum_products_array[4];\n\n    _mm_storeu_si128((__m128i*)sum_squares_array, sum_squares);\n    _mm_storeu_si128((__m128i*)sum_products_array, sum_products);\n\n    int64_t total_sum_squares = 0;\n    int64_t total_sum_products = 0;\n\n    for (size_t j = 0; j < 4; ++j) {\n        total_sum_squares += sum_squares_array[j];\n        total_sum_products += sum_products_array[j];\n    }\n\n    for (; i < length; ++i) {\n        int16_t a = A[i];\n        int16_t b = B[i];\n        total_sum_squares += a * a + b * b;\n        total_sum_products += a * b;\n    }\n\n    return total_sum_squares - total_sum_products;\n}\n```"}
{"task_id": "SimdBench_41_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint64_t squarediff_simd(const int8_t * A, const int8_t * B, size_t length) {\n    __m128i sum_squares = _mm_setzero_si128();\n    __m128i sum_products = _mm_setzero_si128();\n    size_t i = 0;\n\n    for (; i <= length - 16; i += 16) {\n        __m128i a = _mm_loadu_si128((__m128i const*)(A + i));\n        __m128i b = _mm_loadu_si128((__m128i const*)(B + i));\n\n        __m128i a_squared = _mm_maddubs_epi16(a, a);\n        __m128i b_squared = _mm_maddubs_epi16(b, b);\n        __m128i products = _mm_maddubs_epi16(a, b);\n\n        sum_squares = _mm_add_epi32(sum_squares, _mm_add_epi32(a_squared, b_squared));\n        sum_products = _mm_add_epi32(sum_products, products);\n    }\n\n    int32_t sum_squares_array[4];\n    int32_t sum_products_array[4];\n\n    _mm_storeu_si128((__m128i*)sum_squares_array, sum_squares);\n    _mm_storeu_si128((__m128i*)sum_products_array, sum_products);\n\n    int64_t total_sum_squares = 0;\n    int64_t total_sum_products = 0;\n\n    for (size_t j = 0; j < 4; ++j) {\n        total_sum_squares += sum_squares_array[j];\n        total_sum_products += sum_products_array[j];\n    }\n\n    for (; i < length; ++i) {\n        int16_t a = A[i];\n        int16_t b = B[i];\n        total_sum_squares += a * a + b * b;\n        total_sum_products += a * b;\n    }\n\n    return total_sum_squares - total_sum_products;\n}\n```"}
{"task_id": "SimdBench_41_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint64_t squarediff_simd(const int8_t * A, const int8_t * B, size_t length) {\n    __m128i sum_squares = _mm_setzero_si128();\n    __m128i sum_products = _mm_setzero_si128();\n    size_t i = 0;\n\n    for (; i <= length - 16; i += 16) {\n        __m128i a = _mm_loadu_si128((__m128i const*)(A + i));\n        __m128i b = _mm_loadu_si128((__m128i const*)(B + i));\n\n        __m128i a_squared = _mm_maddubs_epi16(a, a);\n        __m128i b_squared = _mm_maddubs_epi16(b, b);\n        __m128i products = _mm_maddubs_epi16(a, b);\n\n        sum_squares = _mm_add_epi32(sum_squares, _mm_add_epi32(a_squared, b_squared));\n        sum_products = _mm_add_epi32(sum_products, products);\n    }\n\n    int32_t sum_squares_array[4];\n    int32_t sum_products_array[4];\n\n    _mm_storeu_si128((__m128i*)sum_squares_array, sum_squares);\n    _mm_storeu_si128((__m128i*)sum_products_array, sum_products);\n\n    int64_t total_sum_squares = 0;\n    int64_t total_sum_products = 0;\n\n    for (size_t j = 0; j < 4; ++j) {\n        total_sum_squares += sum_squares_array[j];\n        total_sum_products += sum_products_array[j];\n    }\n\n    for (; i < length; ++i) {\n        int16_t a = A[i];\n        int16_t b = B[i];\n        total_sum_squares += a * a + b * b;\n        total_sum_products += a * b;\n    }\n\n    return total_sum_squares - total_sum_products;\n}\n```"}
{"task_id": "SimdBench_41_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint64_t squarediff_simd(const int8_t * A, const int8_t * B, size_t length) {\n    __m128i sum_squares = _mm_setzero_si128();\n    __m128i sum_products = _mm_setzero_si128();\n    size_t i = 0;\n\n    for (; i <= length - 16; i += 16) {\n        __m128i a = _mm_loadu_si128((__m128i const*)(A + i));\n        __m128i b = _mm_loadu_si128((__m128i const*)(B + i));\n\n        __m128i a_squared = _mm_maddubs_epi16(a, a);\n        __m128i b_squared = _mm_maddubs_epi16(b, b);\n        __m128i products = _mm_maddubs_epi16(a, b);\n\n        sum_squares = _mm_add_epi32(sum_squares, _mm_add_epi32(a_squared, b_squared));\n        sum_products = _mm_add_epi32(sum_products, products);\n    }\n\n    int32_t sum_squares_array[4];\n    int32_t sum_products_array[4];\n\n    _mm_storeu_si128((__m128i*)sum_squares_array, sum_squares);\n    _mm_storeu_si128((__m128i*)sum_products_array, sum_products);\n\n    int64_t total_sum_squares = 0;\n    int64_t total_sum_products = 0;\n\n    for (size_t j = 0; j < 4; ++j) {\n        total_sum_squares += sum_squares_array[j];\n        total_sum_products += sum_products_array[j];\n    }\n\n    for (; i < length; ++i) {\n        int16_t a = A[i];\n        int16_t b = B[i];\n        total_sum_squares += a * a + b * b;\n        total_sum_products += a * b;\n    }\n\n    return total_sum_squares - total_sum_products;\n}\n```"}
{"task_id": "SimdBench_41_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint64_t squarediff_simd(const int8_t * A, const int8_t * B, size_t length) {\n    __m128i sum_squares = _mm_setzero_si128();\n    __m128i sum_products = _mm_setzero_si128();\n    size_t i = 0;\n\n    for (; i <= length - 16; i += 16) {\n        __m128i a = _mm_loadu_si128((__m128i const*)(A + i));\n        __m128i b = _mm_loadu_si128((__m128i const*)(B + i));\n\n        __m128i a_squared = _mm_maddubs_epi16(a, a);\n        __m128i b_squared = _mm_maddubs_epi16(b, b);\n        __m128i products = _mm_maddubs_epi16(a, b);\n\n        sum_squares = _mm_add_epi32(sum_squares, _mm_add_epi32(a_squared, b_squared));\n        sum_products = _mm_add_epi32(sum_products, products);\n    }\n\n    int32_t sum_squares_array[4];\n    int32_t sum_products_array[4];\n\n    _mm_storeu_si128((__m128i*)sum_squares_array, sum_squares);\n    _mm_storeu_si128((__m128i*)sum_products_array, sum_products);\n\n    int64_t total_sum_squares = 0;\n    int64_t total_sum_products = 0;\n\n    for (size_t j = 0; j < 4; ++j) {\n        total_sum_squares += sum_squares_array[j];\n        total_sum_products += sum_products_array[j];\n    }\n\n    for (; i < length; ++i) {\n        int16_t a = A[i];\n        int16_t b = B[i];\n        total_sum_squares += a * a + b * b;\n        total_sum_products += a * b;\n    }\n\n    return total_sum_squares - total_sum_products;\n}\n```"}
{"task_id": "SimdBench_42_SSE", "completion": "```cpp\nvoid tensor_bit_clear_simd(const uint64_t* A, const uint64_t* B, uint64_t* C, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 2; i += 2) {\n        __m128i a = _mm_loadu_si128((__m128i*)(A + i));\n        __m128i b = _mm_loadu_si128((__m128i*)(B + i));\n        __m128i not_b = _mm_xor_si128(b, _mm_set1_epi64x(-1));\n        __m128i result = _mm_and_si128(a, not_b);\n        _mm_storeu_si128((__m128i*)(C + i), result);\n    }\n    for (; i < length; ++i) {\n        C[i] = A[i] & (~B[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_42_SSE", "completion": "```cpp\nvoid tensor_bit_clear_simd(const uint64_t* A, const uint64_t* B, uint64_t* C, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 2; i += 2) {\n        __m128i a = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i b = _mm_loadu_si128((__m128i*)&B[i]);\n        __m128i not_b = _mm_xor_si128(b, _mm_set1_epi64x(-1));\n        __m128i result = _mm_and_si128(a, not_b);\n        _mm_storeu_si128((__m128i*)&C[i], result);\n    }\n    for (; i < length; ++i) {\n        C[i] = A[i] & (~B[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_42_SSE", "completion": "```cpp\nvoid tensor_bit_clear_simd(const uint64_t* A, const uint64_t* B, uint64_t* C, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 2; i += 2) {\n        __m128i a = _mm_loadu_si128((__m128i*)(A + i));\n        __m128i b = _mm_loadu_si128((__m128i*)(B + i));\n        __m128i not_b = _mm_xor_si128(b, _mm_set1_epi64x(-1));\n        __m128i result = _mm_and_si128(a, not_b);\n        _mm_storeu_si128((__m128i*)(C + i), result);\n    }\n    for (; i < length; ++i) {\n        C[i] = A[i] & (~B[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_42_SSE", "completion": "```cpp\nvoid tensor_bit_clear_simd(const uint64_t* A, const uint64_t* B, uint64_t* C, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 2; i += 2) {\n        __m128i a = _mm_loadu_si128((__m128i*)(A + i));\n        __m128i b = _mm_loadu_si128((__m128i*)(B + i));\n        __m128i not_b = _mm_xor_si128(b, _mm_set1_epi64x(-1));\n        __m128i result = _mm_and_si128(a, not_b);\n        _mm_storeu_si128((__m128i*)(C + i), result);\n    }\n    for (; i < length; ++i) {\n        C[i] = A[i] & (~B[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_42_SSE", "completion": "```cpp\nvoid tensor_bit_clear_simd(const uint64_t* A, const uint64_t* B, uint64_t* C, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 2; i += 2) {\n        __m128i a = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i b = _mm_loadu_si128((__m128i*)&B[i]);\n        __m128i not_b = _mm_xor_si128(b, _mm_set1_epi64x(-1));\n        __m128i result = _mm_and_si128(a, not_b);\n        _mm_storeu_si128((__m128i*)&C[i], result);\n    }\n    for (; i < length; ++i) {\n        C[i] = A[i] & (~B[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_43_SSE", "completion": "```cpp\nvoid tensor_three_valued_logic_simd(const int8_t* A, const int8_t* B, int8_t* C, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 16; i += 16) {\n        __m128i a = _mm_loadu_si128(reinterpret_cast<const __m128i*>(A + i));\n        __m128i b = _mm_loadu_si128(reinterpret_cast<const __m128i*>(B + i));\n\n        __m128i zero = _mm_setzero_si128();\n        __m128i pos_mask = _mm_cmpgt_epi8(a, zero);\n        __m128i neg_mask = _mm_cmplt_epi8(a, zero);\n\n        __m128i b_pos_mask = _mm_cmpgt_epi8(b, zero);\n        __m128i b_neg_mask = _mm_cmplt_epi8(b, zero);\n\n        __m128i both_pos = _mm_and_si128(pos_mask, b_pos_mask);\n        __m128i both_neg = _mm_and_si128(neg_mask, b_neg_mask);\n\n        __m128i result = _mm_or_si128(_mm_and_si128(both_pos, _mm_set1_epi8(1)),\n                                     _mm_and_si128(both_neg, _mm_set1_epi8(-1)));\n\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(C + i), result);\n    }\n\n    for (; i < length; ++i) {\n        if (A[i] > 0 && B[i] > 0) {\n            C[i] = 1;\n        } else if (A[i] < 0 && B[i] < 0) {\n            C[i] = -1;\n        } else {\n            C[i] = 0;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_43_SSE", "completion": "```cpp\nvoid tensor_three_valued_logic_simd(const int8_t* A, const int8_t* B, int8_t* C, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 16; i += 16) {\n        __m128i a = _mm_loadu_si128(reinterpret_cast<const __m128i*>(A + i));\n        __m128i b = _mm_loadu_si128(reinterpret_cast<const __m128i*>(B + i));\n\n        __m128i zero = _mm_setzero_si128();\n        __m128i pos_mask = _mm_cmpgt_epi8(a, zero);\n        __m128i neg_mask = _mm_cmplt_epi8(a, zero);\n\n        __m128i b_pos_mask = _mm_cmpgt_epi8(b, zero);\n        __m128i b_neg_mask = _mm_cmplt_epi8(b, zero);\n\n        __m128i both_pos = _mm_and_si128(pos_mask, b_pos_mask);\n        __m128i both_neg = _mm_and_si128(neg_mask, b_neg_mask);\n\n        __m128i result = _mm_or_si128(_mm_and_si128(both_pos, _mm_set1_epi8(1)),\n                                      _mm_and_si128(both_neg, _mm_set1_epi8(-1)));\n\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(C + i), result);\n    }\n\n    for (; i < length; ++i) {\n        if (A[i] > 0 && B[i] > 0) {\n            C[i] = 1;\n        } else if (A[i] < 0 && B[i] < 0) {\n            C[i] = -1;\n        } else {\n            C[i] = 0;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_43_SSE", "completion": "```cpp\nvoid tensor_three_valued_logic_simd(const int8_t* A, const int8_t* B, int8_t* C, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 16; i += 16) {\n        __m128i a = _mm_loadu_si128(reinterpret_cast<const __m128i*>(A + i));\n        __m128i b = _mm_loadu_si128(reinterpret_cast<const __m128i*>(B + i));\n\n        __m128i zero = _mm_setzero_si128();\n        __m128i pos_mask = _mm_cmpgt_epi8(a, zero);\n        __m128i neg_mask = _mm_cmplt_epi8(a, zero);\n\n        __m128i b_pos_mask = _mm_cmpgt_epi8(b, zero);\n        __m128i b_neg_mask = _mm_cmplt_epi8(b, zero);\n\n        __m128i both_pos = _mm_and_si128(pos_mask, b_pos_mask);\n        __m128i both_neg = _mm_and_si128(neg_mask, b_neg_mask);\n\n        __m128i result = _mm_or_si128(_mm_and_si128(both_pos, _mm_set1_epi8(1)),\n                                     _mm_and_si128(both_neg, _mm_set1_epi8(-1)));\n\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(C + i), result);\n    }\n\n    for (; i < length; ++i) {\n        if (A[i] > 0 && B[i] > 0) {\n            C[i] = 1;\n        } else if (A[i] < 0 && B[i] < 0) {\n            C[i] = -1;\n        } else {\n            C[i] = 0;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_43_SSE", "completion": "```cpp\nvoid tensor_three_valued_logic_simd(const int8_t* A, const int8_t* B, int8_t* C, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 16; i += 16) {\n        __m128i a = _mm_loadu_si128(reinterpret_cast<const __m128i*>(A + i));\n        __m128i b = _mm_loadu_si128(reinterpret_cast<const __m128i*>(B + i));\n\n        __m128i zero = _mm_setzero_si128();\n        __m128i pos_mask = _mm_cmpgt_epi8(a, zero);\n        __m128i neg_mask = _mm_cmplt_epi8(a, zero);\n\n        __m128i b_pos_mask = _mm_cmpgt_epi8(b, zero);\n        __m128i b_neg_mask = _mm_cmplt_epi8(b, zero);\n\n        __m128i both_pos = _mm_and_si128(pos_mask, b_pos_mask);\n        __m128i both_neg = _mm_and_si128(neg_mask, b_neg_mask);\n\n        __m128i result = _mm_or_si128(_mm_and_si128(both_pos, _mm_set1_epi8(1)),\n                                     _mm_and_si128(both_neg, _mm_set1_epi8(-1)));\n\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(C + i), result);\n    }\n\n    for (; i < length; ++i) {\n        if (A[i] > 0 && B[i] > 0) {\n            C[i] = 1;\n        } else if (A[i] < 0 && B[i] < 0) {\n            C[i] = -1;\n        } else {\n            C[i] = 0;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_43_SSE", "completion": "```cpp\nvoid tensor_three_valued_logic_simd(const int8_t* A, const int8_t* B, int8_t* C, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 16; i += 16) {\n        __m128i a = _mm_loadu_si128(reinterpret_cast<const __m128i*>(A + i));\n        __m128i b = _mm_loadu_si128(reinterpret_cast<const __m128i*>(B + i));\n\n        __m128i zero = _mm_setzero_si128();\n        __m128i pos_mask = _mm_cmpgt_epi8(a, zero);\n        __m128i neg_mask = _mm_cmplt_epi8(a, zero);\n\n        __m128i b_pos_mask = _mm_cmpgt_epi8(b, zero);\n        __m128i b_neg_mask = _mm_cmplt_epi8(b, zero);\n\n        __m128i both_pos = _mm_and_si128(pos_mask, b_pos_mask);\n        __m128i both_neg = _mm_and_si128(neg_mask, b_neg_mask);\n\n        __m128i result = _mm_or_si128(_mm_and_si128(both_pos, _mm_set1_epi8(1)),\n                                     _mm_and_si128(both_neg, _mm_set1_epi8(-1)));\n\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(C + i), result);\n    }\n\n    for (; i < length; ++i) {\n        if (A[i] > 0 && B[i] > 0) {\n            C[i] = 1;\n        } else if (A[i] < 0 && B[i] < 0) {\n            C[i] = -1;\n        } else {\n            C[i] = 0;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_44_SSE", "completion": "```cpp\nvoid tensor_bit_op_simd(const uint16_t* A, const uint16_t* B, uint16_t* C, size_t length) {\n    size_t midpoint = length / 2;\n    size_t i = 0;\n\n    // Process elements before the midpoint\n    for (; i + 7 < midpoint; i += 8) {\n        __m128i a = _mm_loadu_si128((__m128i*)(A + i));\n        __m128i b = _mm_loadu_si128((__m128i*)(B + i));\n        __m128i xor_result = _mm_xor_si128(a, b);\n        __m128i and_result = _mm_and_si128(a, b);\n        _mm_storeu_si128((__m128i*)(C + i), xor_result);\n        _mm_storeu_si128((__m128i*)(C + i + 4), and_result);\n    }\n\n    // Handle remaining elements before the midpoint\n    for (; i < midpoint; ++i) {\n        if (i % 2 == 0) {\n            C[i] = A[i] ^ B[i];\n        } else {\n            C[i] = A[i] & B[i];\n        }\n    }\n\n    // Process the midpoint element\n    if (length % 2 == 1) {\n        C[midpoint] = A[midpoint];\n    }\n\n    // Process elements after the midpoint\n    for (i = midpoint + 1; i + 7 < length; i += 8) {\n        __m128i a = _mm_loadu_si128((__m128i*)(A + i));\n        _mm_storeu_si128((__m128i*)(C + i), a);\n    }\n\n    // Handle remaining elements after the midpoint\n    for (; i < length; ++i) {\n        C[i] = A[i];\n    }\n}\n```"}
{"task_id": "SimdBench_44_SSE", "completion": "```cpp\nvoid tensor_bit_op_simd(const uint16_t* A, const uint16_t* B, uint16_t* C, size_t length) {\n    size_t midpoint = length / 2;\n    size_t i = 0;\n\n    // Process elements before the midpoint\n    for (; i + 7 < midpoint; i += 8) {\n        __m128i a = _mm_loadu_si128((__m128i*)(A + i));\n        __m128i b = _mm_loadu_si128((__m128i*)(B + i));\n        __m128i xor_result = _mm_xor_si128(a, b);\n        _mm_storeu_si128((__m128i*)(C + i), xor_result);\n    }\n\n    // Process remaining elements before the midpoint\n    for (; i < midpoint; ++i) {\n        C[i] = A[i] ^ B[i];\n    }\n\n    // Process the midpoint element\n    if (length % 2 != 0) {\n        C[midpoint] = A[midpoint];\n    }\n\n    // Process elements after the midpoint\n    for (i = midpoint + 1; i + 7 < length; i += 8) {\n        __m128i a = _mm_loadu_si128((__m128i*)(A + i));\n        __m128i b = _mm_loadu_si128((__m128i*)(B + i));\n        __m128i and_result = _mm_and_si128(a, b);\n        _mm_storeu_si128((__m128i*)(C + i), and_result);\n    }\n\n    // Process remaining elements after the midpoint\n    for (; i < length; ++i) {\n        C[i] = A[i] & B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_44_SSE", "completion": "```cpp\nvoid tensor_bit_op_simd(const uint16_t* A, const uint16_t* B, uint16_t* C, size_t length) {\n    size_t midpoint = length / 2;\n    size_t i = 0;\n\n    // Process elements before the midpoint\n    for (; i + 7 < midpoint; i += 8) {\n        __m128i a = _mm_loadu_si128((__m128i*)(A + i));\n        __m128i b = _mm_loadu_si128((__m128i*)(B + i));\n        __m128i xor_result = _mm_xor_si128(a, b);\n        _mm_storeu_si128((__m128i*)(C + i), xor_result);\n    }\n\n    // Process remaining elements before the midpoint\n    for (; i < midpoint; ++i) {\n        C[i] = A[i] ^ B[i];\n    }\n\n    // Process the midpoint element\n    if (length % 2 != 0) {\n        C[midpoint] = A[midpoint];\n    }\n\n    // Process elements after the midpoint\n    for (i = midpoint + 1; i + 7 < length; i += 8) {\n        __m128i a = _mm_loadu_si128((__m128i*)(A + i));\n        __m128i b = _mm_loadu_si128((__m128i*)(B + i));\n        __m128i and_result = _mm_and_si128(a, b);\n        _mm_storeu_si128((__m128i*)(C + i), and_result);\n    }\n\n    // Process remaining elements after the midpoint\n    for (; i < length; ++i) {\n        C[i] = A[i] & B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_44_SSE", "completion": "```cpp\nvoid tensor_bit_op_simd(const uint16_t* A, const uint16_t* B, uint16_t* C, size_t length) {\n    size_t midpoint = length / 2;\n    size_t i = 0;\n\n    // Process elements before the midpoint\n    for (; i + 7 < midpoint; i += 8) {\n        __m128i a = _mm_loadu_si128((__m128i*)(A + i));\n        __m128i b = _mm_loadu_si128((__m128i*)(B + i));\n        __m128i xor_result = _mm_xor_si128(a, b);\n        __m128i and_result = _mm_and_si128(a, b);\n        _mm_storeu_si128((__m128i*)(C + i), and_result);\n        _mm_storeu_si128((__m128i*)(C + i + 4), xor_result);\n    }\n\n    // Handle remaining elements before the midpoint\n    for (; i < midpoint; ++i) {\n        if (i % 2 == 0) {\n            C[i] = A[i] & B[i];\n        } else {\n            C[i] = A[i] ^ B[i];\n        }\n    }\n\n    // Process the midpoint element\n    if (length % 2 == 1) {\n        C[midpoint] = A[midpoint];\n    }\n\n    // Process elements after the midpoint\n    for (i = midpoint + 1; i + 7 < length; i += 8) {\n        __m128i a = _mm_loadu_si128((__m128i*)(A + i));\n        __m128i b = _mm_loadu_si128((__m128i*)(B + i));\n        __m128i xor_result = _mm_xor_si128(a, b);\n        __m128i and_result = _mm_and_si128(a, b);\n        _mm_storeu_si128((__m128i*)(C + i), and_result);\n        _mm_storeu_si128((__m128i*)(C + i + 4), xor_result);\n    }\n\n    // Handle remaining elements after the midpoint\n    for (; i < length; ++i) {\n        if (i % 2 == 0) {\n            C[i] = A[i] & B[i];\n        } else {\n            C[i] = A[i] ^ B[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_44_SSE", "completion": "```cpp\nvoid tensor_bit_op_simd(const uint16_t* A, const uint16_t* B, uint16_t* C, size_t length) {\n    size_t midpoint = length / 2;\n    size_t i = 0;\n\n    // Process elements before the midpoint\n    for (; i + 7 < midpoint; i += 8) {\n        __m128i a = _mm_loadu_si128((__m128i*)(A + i));\n        __m128i b = _mm_loadu_si128((__m128i*)(B + i));\n        __m128i xor_result = _mm_xor_si128(a, b);\n        __m128i and_result = _mm_and_si128(a, b);\n        _mm_storeu_si128((__m128i*)(C + i), and_result);\n        _mm_storeu_si128((__m128i*)(C + i + 4), xor_result);\n    }\n\n    // Handle remaining elements before the midpoint\n    for (; i < midpoint; ++i) {\n        if (i % 2 == 0) {\n            C[i] = A[i] & B[i];\n        } else {\n            C[i] = A[i] ^ B[i];\n        }\n    }\n\n    // Process the midpoint element\n    if (length % 2 == 1) {\n        C[midpoint] = A[midpoint];\n    }\n\n    // Process elements after the midpoint\n    for (i = midpoint + 1; i + 7 < length; i += 8) {\n        __m128i a = _mm_loadu_si128((__m128i*)(A + i));\n        _mm_storeu_si128((__m128i*)(C + i), a);\n    }\n\n    // Handle remaining elements after the midpoint\n    for (; i < length; ++i) {\n        C[i] = A[i];\n    }\n}\n```"}
{"task_id": "SimdBench_45_SSE", "completion": "```cpp\nvoid tensor_multi_select_simd(const float* A, const float* B, const float* C, const float* D, const bool* cond1, const bool* cond2, float* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t i = 0;\n\n    for (; i <= total_elements - 4; i += 4) {\n        __m128 a = _mm_loadu_ps(&A[i]);\n        __m128 b = _mm_loadu_ps(&B[i]);\n        __m128 c = _mm_loadu_ps(&C[i]);\n        __m128 d = _mm_loadu_ps(&D[i]);\n\n        __m128i cond1_mask = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&cond1[i]));\n        __m128i cond2_mask = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&cond2[i]));\n\n        __m128i both_true = _mm_and_si128(cond1_mask, cond2_mask);\n        __m128i cond1_true_cond2_false = _mm_andnot_si128(cond2_mask, cond1_mask);\n        __m128i cond1_false_cond2_true = _mm_andnot_si128(cond1_mask, cond2_mask);\n\n        __m128 result = _mm_or_ps(_mm_and_ps(_mm_castsi128_ps(both_true), a),\n                                 _mm_and_ps(_mm_castsi128_ps(cond1_true_cond2_false), b));\n        result = _mm_or_ps(result, _mm_and_ps(_mm_castsi128_ps(cond1_false_cond2_true), c));\n        result = _mm_or_ps(result, _mm_andnot_ps(_mm_or_si128(both_true, cond1_true_cond2_false), d));\n\n        _mm_storeu_ps(&out[i], result);\n    }\n\n    for (; i < total_elements; ++i) {\n        if (cond1[i] && cond2[i]) {\n            out[i] = A[i];\n        } else if (cond1[i]) {\n            out[i] = B[i];\n        } else if (cond2[i]) {\n            out[i] = C[i];\n        } else {\n            out[i] = D[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_45_SSE", "completion": "```cpp\nvoid tensor_multi_select_simd(const float* A, const float* B, const float* C, const float* D, const bool* cond1, const bool* cond2, float* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t i = 0;\n\n    for (; i <= total_elements - 4; i += 4) {\n        __m128 a = _mm_loadu_ps(&A[i]);\n        __m128 b = _mm_loadu_ps(&B[i]);\n        __m128 c = _mm_loadu_ps(&C[i]);\n        __m128 d = _mm_loadu_ps(&D[i]);\n\n        __m128i cond1_vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&cond1[i]));\n        __m128i cond2_vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&cond2[i]));\n\n        __m128i cond1_and_cond2 = _mm_and_si128(cond1_vec, cond2_vec);\n        __m128i cond1_and_not_cond2 = _mm_andnot_si128(cond2_vec, cond1_vec);\n        __m128i not_cond1_and_cond2 = _mm_andnot_si128(cond1_vec, cond2_vec);\n\n        __m128 result = _mm_or_ps(\n            _mm_and_ps(_mm_castsi128_ps(cond1_and_cond2), a),\n            _mm_or_ps(\n                _mm_and_ps(_mm_castsi128_ps(cond1_and_not_cond2), b),\n                _mm_and_ps(_mm_castsi128_ps(not_cond1_and_cond2), c)\n            )\n        );\n\n        result = _mm_or_ps(result, _mm_andnot_ps(_mm_castsi128_ps(_mm_or_si128(cond1_and_cond2, _mm_or_si128(cond1_and_not_cond2, not_cond1_and_cond2))), d));\n\n        _mm_storeu_ps(&out[i], result);\n    }\n\n    for (; i < total_elements; ++i) {\n        if (cond1[i] && cond2[i]) {\n            out[i] = A[i];\n        } else if (cond1[i]) {\n            out[i] = B[i];\n        } else if (cond2[i]) {\n            out[i] = C[i];\n        } else {\n            out[i] = D[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_45_SSE", "completion": "```cpp\nvoid tensor_multi_select_simd(const float* A, const float* B, const float* C, const float* D, const bool* cond1, const bool* cond2, float* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t i = 0;\n\n    for (; i <= total_elements - 4; i += 4) {\n        __m128 va = _mm_loadu_ps(&A[i]);\n        __m128 vb = _mm_loadu_ps(&B[i]);\n        __m128 vc = _mm_loadu_ps(&C[i]);\n        __m128 vd = _mm_loadu_ps(&D[i]);\n\n        __m128i vcond1 = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&cond1[i]));\n        __m128i vcond2 = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&cond2[i]));\n\n        __m128i vcond1_and_vcond2 = _mm_and_si128(vcond1, vcond2);\n        __m128i vcond1_and_not_vcond2 = _mm_andnot_si128(vcond2, vcond1);\n        __m128i vnot_vcond1_and_vcond2 = _mm_andnot_si128(vcond1, vcond2);\n\n        __m128 result = _mm_or_ps(\n            _mm_and_ps(_mm_castsi128_ps(vcond1_and_vcond2), va),\n            _mm_or_ps(\n                _mm_and_ps(_mm_castsi128_ps(vcond1_and_not_vcond2), vb),\n                _mm_and_ps(_mm_castsi128_ps(vnot_vcond1_and_vcond2), vc)\n            )\n        );\n\n        result = _mm_or_ps(result, _mm_andnot_ps(_mm_castsi128_ps(_mm_or_si128(vcond1_and_vcond2, _mm_or_si128(vcond1_and_not_vcond2, vnot_vcond1_and_vcond2))), vd));\n\n        _mm_storeu_ps(&out[i], result);\n    }\n\n    for (; i < total_elements; ++i) {\n        if (cond1[i] && cond2[i]) {\n            out[i] = A[i];\n        } else if (cond1[i] && !cond2[i]) {\n            out[i] = B[i];\n        } else if (!cond1[i] && cond2[i]) {\n            out[i] = C[i];\n        } else {\n            out[i] = D[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_45_SSE", "completion": "```cpp\nvoid tensor_multi_select_simd(const float* A, const float* B, const float* C, const float* D, const bool* cond1, const bool* cond2, float* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t i = 0;\n\n    for (; i <= total_elements - 4; i += 4) {\n        __m128 a = _mm_loadu_ps(&A[i]);\n        __m128 b = _mm_loadu_ps(&B[i]);\n        __m128 c = _mm_loadu_ps(&C[i]);\n        __m128 d = _mm_loadu_ps(&D[i]);\n\n        __m128i cond1_mask = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&cond1[i]));\n        __m128i cond2_mask = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&cond2[i]));\n\n        __m128i both_true = _mm_and_si128(cond1_mask, cond2_mask);\n        __m128i cond1_true_cond2_false = _mm_andnot_si128(cond2_mask, cond1_mask);\n        __m128i cond1_false_cond2_true = _mm_andnot_si128(cond1_mask, cond2_mask);\n\n        __m128 result = _mm_or_ps(\n            _mm_and_ps(_mm_castsi128_ps(both_true), a),\n            _mm_or_ps(\n                _mm_and_ps(_mm_castsi128_ps(cond1_true_cond2_false), b),\n                _mm_and_ps(_mm_castsi128_ps(cond1_false_cond2_true), c)\n            )\n        );\n\n        result = _mm_or_ps(result, _mm_andnot_ps(_mm_castsi128_ps(_mm_or_si128(both_true, _mm_or_si128(cond1_true_cond2_false, cond1_false_cond2_true))), d));\n\n        _mm_storeu_ps(&out[i], result);\n    }\n\n    for (; i < total_elements; ++i) {\n        if (cond1[i] && cond2[i]) {\n            out[i] = A[i];\n        } else if (cond1[i]) {\n            out[i] = B[i];\n        } else if (cond2[i]) {\n            out[i] = C[i];\n        } else {\n            out[i] = D[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_45_SSE", "completion": "```cpp\nvoid tensor_multi_select_simd(const float* A, const float* B, const float* C, const float* D, const bool* cond1, const bool* cond2, float* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t i = 0;\n\n    for (; i <= total_elements - 4; i += 4) {\n        __m128 a = _mm_loadu_ps(&A[i]);\n        __m128 b = _mm_loadu_ps(&B[i]);\n        __m128 c = _mm_loadu_ps(&C[i]);\n        __m128 d = _mm_loadu_ps(&D[i]);\n\n        __m128i cond1_vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&cond1[i]));\n        __m128i cond2_vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&cond2[i]));\n\n        __m128i cond1_and_cond2 = _mm_and_si128(cond1_vec, cond2_vec);\n        __m128i cond1_and_not_cond2 = _mm_andnot_si128(cond2_vec, cond1_vec);\n        __m128i not_cond1_and_cond2 = _mm_andnot_si128(cond1_vec, cond2_vec);\n\n        __m128 result = _mm_or_ps(\n            _mm_and_ps(_mm_castsi128_ps(cond1_and_cond2), a),\n            _mm_or_ps(\n                _mm_and_ps(_mm_castsi128_ps(cond1_and_not_cond2), b),\n                _mm_and_ps(_mm_castsi128_ps(not_cond1_and_cond2), c)\n            )\n        );\n\n        result = _mm_or_ps(result, _mm_andnot_ps(_mm_castsi128_ps(_mm_or_si128(cond1_and_cond2, _mm_or_si128(cond1_and_not_cond2, not_cond1_and_cond2))), d));\n\n        _mm_storeu_ps(&out[i], result);\n    }\n\n    for (; i < total_elements; ++i) {\n        if (cond1[i] && cond2[i]) {\n            out[i] = A[i];\n        } else if (cond1[i] && !cond2[i]) {\n            out[i] = B[i];\n        } else if (!cond1[i] && cond2[i]) {\n            out[i] = C[i];\n        } else {\n            out[i] = D[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_46_SSE", "completion": "```cpp\nvoid tensor_bit_count_simd(const uint32_t* A, uint8_t* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t i = 0;\n\n    for (; i <= total_elements - 16; i += 16) {\n        __m128i vec = _mm_loadu_si128((__m128i*)(A + i));\n        __m128i ones = _mm_setzero_si128();\n\n        // Count bits set in each 32-bit integer\n        for (int j = 0; j < 5; ++j) {\n            ones = _mm_add_epi8(ones, _mm_and_si128(vec, _mm_set1_epi32(0x01010101)));\n            vec = _mm_srli_epi32(vec, 1);\n        }\n\n        // Horizontal sum of bytes to get bit counts\n        __m128i high_bits = _mm_srli_epi64(ones, 8);\n        ones = _mm_add_epi8(ones, high_bits);\n        high_bits = _mm_srli_epi64(ones, 16);\n        ones = _mm_add_epi8(ones, high_bits);\n        high_bits = _mm_srli_epi64(ones, 32);\n        ones = _mm_add_epi8(ones, high_bits);\n\n        // Store the results\n        _mm_storeu_si128((__m128i*)(out + i), ones);\n    }\n\n    // Handle remaining elements\n    for (; i < total_elements; ++i) {\n        uint32_t val = A[i];\n        uint8_t bit_count = 0;\n        for (int j = 0; j < 32; ++j) {\n            bit_count += (val & 1);\n            val >>= 1;\n        }\n        out[i] = bit_count;\n    }\n}\n```"}
{"task_id": "SimdBench_46_SSE", "completion": "```cpp\nvoid tensor_bit_count_simd(const uint32_t* A, uint8_t* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t i = 0;\n\n    for (; i <= total_elements - 16; i += 16) {\n        __m128i a = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i b = _mm_loadu_si128((__m128i*)&A[i + 4]);\n        __m128i c = _mm_loadu_si128((__m128i*)&A[i + 8]);\n        __m128i d = _mm_loadu_si128((__m128i*)&A[i + 12]);\n\n        __m128i popcnt_a = _mm_popcnt_epi32(a);\n        __m128i popcnt_b = _mm_popcnt_epi32(b);\n        __m128i popcnt_c = _mm_popcnt_epi32(c);\n        __m128i popcnt_d = _mm_popcnt_epi32(d);\n\n        __m128i pack_ab = _mm_packus_epi16(popcnt_a, popcnt_b);\n        __m128i pack_cd = _mm_packus_epi16(popcnt_c, popcnt_d);\n        __m128i pack_abcd = _mm_packus_epi16(pack_ab, pack_cd);\n\n        _mm_storeu_si128((__m128i*)&out[i], pack_abcd);\n    }\n\n    for (; i < total_elements; ++i) {\n        out[i] = __builtin_popcount(A[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_46_SSE", "completion": "```cpp\nvoid tensor_bit_count_simd(const uint32_t* A, uint8_t* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t i = 0;\n\n    for (; i <= total_elements - 16; i += 16) {\n        __m128i vec = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i ones = _mm_setzero_si128();\n\n        ones = _mm_add_epi8(ones, _mm_and_si128(vec, _mm_set1_epi32(0x01010101)));\n        ones = _mm_add_epi8(ones, _mm_and_si128(_mm_srli_epi32(vec, 1), _mm_set1_epi32(0x01010101)));\n        ones = _mm_add_epi8(ones, _mm_and_si128(_mm_srli_epi32(vec, 2), _mm_set1_epi32(0x01010101)));\n        ones = _mm_add_epi8(ones, _mm_and_si128(_mm_srli_epi32(vec, 3), _mm_set1_epi32(0x01010101)));\n        ones = _mm_add_epi8(ones, _mm_and_si128(_mm_srli_epi32(vec, 4), _mm_set1_epi32(0x01010101)));\n        ones = _mm_add_epi8(ones, _mm_and_si128(_mm_srli_epi32(vec, 5), _mm_set1_epi32(0x01010101)));\n        ones = _mm_add_epi8(ones, _mm_and_si128(_mm_srli_epi32(vec, 6), _mm_set1_epi32(0x01010101)));\n        ones = _mm_add_epi8(ones, _mm_and_si128(_mm_srli_epi32(vec, 7), _mm_set1_epi32(0x01010101)));\n        ones = _mm_add_epi8(ones, _mm_and_si128(_mm_srli_epi32(vec, 8), _mm_set1_epi32(0x01010101)));\n        ones = _mm_add_epi8(ones, _mm_and_si128(_mm_srli_epi32(vec, 9), _mm_set1_epi32(0x01010101)));\n        ones = _mm_add_epi8(ones, _mm_and_si128(_mm_srli_epi32(vec, 10), _mm_set1_epi32(0x01010101)));\n        ones = _mm_add_epi8(ones, _mm_and_si128(_mm_srli_epi32(vec, 11), _mm_set1_epi32(0x01010101)));\n        ones = _mm_add_epi8(ones, _mm_and_si128(_mm_srli_epi32(vec, 12), _mm_set1_epi32(0x01010101)));\n        ones = _mm_add_epi8(ones, _mm_and_si128(_mm_srli_epi32(vec, 13), _mm_set1_epi32(0x01010101)));\n        ones = _mm_add_epi8(ones, _mm_and_si128(_mm_srli_epi32(vec, 14), _mm_set1_epi32(0x01010101)));\n        ones = _mm_add_epi8(ones, _mm_and_si128(_mm_srli_epi32(vec, 15), _mm_set1_epi32(0x01010101)));\n\n        _mm_storeu_si128((__m128i*)&out[i], ones);\n    }\n\n    for (; i < total_elements; ++i) {\n        uint32_t val = A[i];\n        uint8_t count = __builtin_popcount(val);\n        out[i] = count;\n    }\n}\n```"}
{"task_id": "SimdBench_46_SSE", "completion": "```cpp\nvoid tensor_bit_count_simd(const uint32_t* A, uint8_t* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t i = 0;\n\n    for (; i <= total_elements - 16; i += 16) {\n        __m128i a = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i b = _mm_loadu_si128((__m128i*)&A[i + 4]);\n        __m128i c = _mm_loadu_si128((__m128i*)&A[i + 8]);\n        __m128i d = _mm_loadu_si128((__m128i*)&A[i + 12]);\n\n        __m128i popcnt_a = _mm_popcnt_epi32(a);\n        __m128i popcnt_b = _mm_popcnt_epi32(b);\n        __m128i popcnt_c = _mm_popcnt_epi32(c);\n        __m128i popcnt_d = _mm_popcnt_epi32(d);\n\n        __m128i pack_ab = _mm_packus_epi16(popcnt_a, popcnt_b);\n        __m128i pack_cd = _mm_packus_epi16(popcnt_c, popcnt_d);\n        __m128i pack_abcd = _mm_packus_epi16(pack_ab, pack_cd);\n\n        _mm_storeu_si128((__m128i*)&out[i], pack_abcd);\n    }\n\n    for (; i < total_elements; ++i) {\n        out[i] = __builtin_popcount(A[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_46_SSE", "completion": "```cpp\nvoid tensor_bit_count_simd(const uint32_t* A, uint8_t* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t i = 0;\n\n    for (; i <= total_elements - 16; i += 16) {\n        __m128i a = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i b = _mm_loadu_si128((__m128i*)&A[i + 4]);\n        __m128i c = _mm_loadu_si128((__m128i*)&A[i + 8]);\n        __m128i d = _mm_loadu_si128((__m128i*)&A[i + 12]);\n\n        __m128i popcnt_a = _mm_popcnt_epi32(a);\n        __m128i popcnt_b = _mm_popcnt_epi32(b);\n        __m128i popcnt_c = _mm_popcnt_epi32(c);\n        __m128i popcnt_d = _mm_popcnt_epi32(d);\n\n        __m128i pack_ab = _mm_packus_epi16(popcnt_a, popcnt_b);\n        __m128i pack_cd = _mm_packus_epi16(popcnt_c, popcnt_d);\n        __m128i pack_abcd = _mm_packus_epi16(pack_ab, pack_cd);\n\n        _mm_storeu_si128((__m128i*)&out[i], pack_abcd);\n    }\n\n    for (; i < total_elements; ++i) {\n        out[i] = __builtin_popcount(A[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_47_SSE", "completion": "```cpp\nvoid matrix_conditional_abs_simd(const int* A, int* B, size_t rows, size_t cols) {\n    size_t total_elements = rows * cols;\n    size_t i = 0;\n\n    for (; i <= total_elements - 4; i += 4) {\n        __m128i vecA = _mm_loadu_si128((__m128i const*)(A + i));\n        __m128i three = _mm_set1_epi32(3);\n        __m128i zero = _mm_setzero_si128();\n        __m128i mod3 = _mm_rem_epi32(vecA, three);\n        __m128i mask = _mm_cmpeq_epi32(mod3, zero);\n        __m128i absVecA = _mm_abs_epi32(vecA);\n        __m128i result = _mm_blendv_epi8(vecA, absVecA, mask);\n        _mm_storeu_si128((__m128i*)(B + i), result);\n    }\n\n    for (; i < total_elements; ++i) {\n        B[i] = (A[i] % 3 == 0) ? abs(A[i]) : A[i];\n    }\n}\n```"}
{"task_id": "SimdBench_47_SSE", "completion": "```cpp\nvoid matrix_conditional_abs_simd(const int* A, int* B, size_t rows, size_t cols) {\n    size_t total_elements = rows * cols;\n    size_t i = 0;\n\n    for (; i <= total_elements - 4; i += 4) {\n        __m128i vecA = _mm_loadu_si128((__m128i const*)(A + i));\n        __m128i three = _mm_set1_epi32(3);\n        __m128i zero = _mm_setzero_si128();\n        __m128i mod_result = _mm_rem_epi32(vecA, three);\n        __m128i mask = _mm_cmpeq_epi32(mod_result, zero);\n        __m128i abs_vecA = _mm_abs_epi32(vecA);\n        __m128i result = _mm_blendv_epi8(vecA, abs_vecA, mask);\n        _mm_storeu_si128((__m128i*)(B + i), result);\n    }\n\n    for (; i < total_elements; ++i) {\n        B[i] = (A[i] % 3 == 0) ? abs(A[i]) : A[i];\n    }\n}\n```"}
{"task_id": "SimdBench_47_SSE", "completion": "```cpp\nvoid matrix_conditional_abs_simd(const int* A, int* B, size_t rows, size_t cols) {\n    size_t total_elements = rows * cols;\n    size_t i = 0;\n\n    for (; i <= total_elements - 4; i += 4) {\n        __m128i a = _mm_loadu_si128((__m128i const*)(A + i));\n        __m128i three = _mm_set1_epi32(3);\n        __m128i zero = _mm_setzero_si128();\n        __m128i mod_result = _mm_rem_epi32(a, three);\n        __m128i mask = _mm_cmpeq_epi32(mod_result, zero);\n        __m128i abs_a = _mm_abs_epi32(a);\n        __m128i result = _mm_blendv_epi8(a, abs_a, mask);\n        _mm_storeu_si128((__m128i*)(B + i), result);\n    }\n\n    for (; i < total_elements; ++i) {\n        B[i] = (A[i] % 3 == 0) ? abs(A[i]) : A[i];\n    }\n}\n```"}
{"task_id": "SimdBench_47_SSE", "completion": "```cpp\nvoid matrix_conditional_abs_simd(const int* A, int* B, size_t rows, size_t cols) {\n    size_t total_elements = rows * cols;\n    size_t i = 0;\n\n    for (; i <= total_elements - 4; i += 4) {\n        __m128i a = _mm_loadu_si128((__m128i const*)(A + i));\n        __m128i three = _mm_set1_epi32(3);\n        __m128i zero = _mm_setzero_si128();\n        __m128i mod_result = _mm_srai_epi32(_mm_mullo_epi32(a, three), 31);\n        __m128i abs_a = _mm_abs_epi32(a);\n        __m128i result = _mm_or_si128(_mm_andnot_si128(mod_result, a), _mm_and_si128(mod_result, abs_a));\n        _mm_storeu_si128((__m128i*)(B + i), result);\n    }\n\n    for (; i < total_elements; ++i) {\n        B[i] = (A[i] % 3 == 0) ? abs(A[i]) : A[i];\n    }\n}\n```"}
{"task_id": "SimdBench_47_SSE", "completion": "```cpp\nvoid matrix_conditional_abs_simd(const int* A, int* B, size_t rows, size_t cols) {\n    size_t total_elements = rows * cols;\n    size_t i = 0;\n\n    for (; i <= total_elements - 4; i += 4) {\n        __m128i vecA = _mm_loadu_si128((__m128i const*)(A + i));\n        __m128i three = _mm_set1_epi32(3);\n        __m128i zero = _mm_setzero_si128();\n        __m128i mask = _mm_cmpeq_epi32(_mm_sra_epi32(vecA, _mm_cvtsi32_si128(31)), zero);\n        mask = _mm_and_epi32(mask, _mm_cmpeq_epi32(_mm_mullo_epi32(vecA, three), vecA));\n        __m128i absVecA = _mm_abs_epi32(vecA);\n        __m128i result = _mm_or_epi32(_mm_and_epi32(mask, absVecA), _mm_andnot_epi32(mask, vecA));\n        _mm_storeu_si128((__m128i*)(B + i), result);\n    }\n\n    for (; i < total_elements; ++i) {\n        B[i] = (A[i] % 3 == 0) ? abs(A[i]) : A[i];\n    }\n}\n```"}
{"task_id": "SimdBench_48_SSE", "completion": "```cpp\nvoid matrix_conditional_bit_rotate_simd(const uint32_t* src, uint32_t* dst, uint8_t rotate_bits, size_t length){\n    __m128i mask = _mm_set1_epi32(0xF); // Mask to check the low 4 bits\n    __m128i ones = _mm_set1_epi32(0xF); // All 1s in the low 4 bits\n    __m128i rotate_mask = _mm_set1_epi32((1 << rotate_bits) - 1);\n    __m128i shift_count = _mm_set1_epi32(rotate_bits);\n\n    for (size_t i = 0; i < length; i += 4) {\n        __m128i src_vec = _mm_loadu_si128((__m128i const*)(src + i));\n        __m128i low_bits = _mm_and_si128(src_vec, mask);\n        __m128i condition = _mm_cmpeq_epi32(low_bits, ones);\n        \n        __m128i rotated = _mm_or_si128(\n            _mm_srli_epi32(src_vec, rotate_bits),\n            _mm_slli_epi32(src_vec, 32 - rotate_bits)\n        );\n        rotated = _mm_and_si128(rotated, rotate_mask);\n        \n        __m128i negated = _mm_xor_si128(src_vec, _mm_set1_epi32(0xFFFFFFFF));\n        \n        __m128i result = _mm_blendv_epi8(negated, rotated, condition);\n        \n        _mm_storeu_si128((__m128i*)(dst + i), result);\n    }\n}\n```"}
{"task_id": "SimdBench_48_SSE", "completion": "```cpp\nvoid matrix_conditional_bit_rotate_simd(const uint32_t* src, uint32_t* dst, uint8_t rotate_bits, size_t length){\n    __m128i mask = _mm_set1_epi32(0xF); // Mask to check the low 4 bits\n    __m128i ones = _mm_set1_epi32(0xF); // All 1s in the low 4 bits\n    __m128i rotate_mask = _mm_set1_epi32((1 << rotate_bits) - 1);\n    __m128i shift_count = _mm_set1_epi32(rotate_bits);\n\n    for (size_t i = 0; i < length; i += 4) {\n        __m128i src_vec = _mm_loadu_si128((__m128i const*)(src + i));\n        __m128i low_bits = _mm_and_si128(src_vec, mask);\n        __m128i condition = _mm_cmpeq_epi32(low_bits, ones);\n        \n        __m128i rotated = _mm_or_si128(\n            _mm_srli_epi32(src_vec, rotate_bits),\n            _mm_slli_epi32(src_vec, 32 - rotate_bits)\n        );\n        rotated = _mm_and_si128(rotated, rotate_mask);\n        \n        __m128i negated = _mm_xor_si128(src_vec, _mm_set1_epi32(0xFFFFFFFF));\n        \n        __m128i result = _mm_blendv_epi8(negated, rotated, condition);\n        \n        _mm_storeu_si128((__m128i*)(dst + i), result);\n    }\n}\n```"}
{"task_id": "SimdBench_48_SSE", "completion": "```cpp\nvoid matrix_conditional_bit_rotate_simd(const uint32_t* src, uint32_t* dst, uint8_t rotate_bits, size_t length){\n    __m128i mask = _mm_set1_epi32(0xF); // Mask to check the low 4 bits\n    __m128i ones = _mm_set1_epi32(0xF); // All 1s in the low 4 bits\n    __m128i rotate_mask = _mm_set1_epi32((1 << rotate_bits) - 1);\n    __m128i shift_count = _mm_set1_epi32(rotate_bits);\n\n    for (size_t i = 0; i < length; i += 4) {\n        __m128i src_vec = _mm_loadu_si128((__m128i const*)(src + i));\n        __m128i low_bits = _mm_and_si128(src_vec, mask);\n        __m128i condition = _mm_cmpeq_epi32(low_bits, ones);\n        \n        __m128i rotated = _mm_or_si128(\n            _mm_srli_epi32(src_vec, rotate_bits),\n            _mm_slli_epi32(src_vec, 32 - rotate_bits)\n        );\n        rotated = _mm_and_si128(rotated, rotate_mask);\n        \n        __m128i negated = _mm_xor_si128(src_vec, _mm_set1_epi32(0xFFFFFFFF));\n        \n        __m128i result = _mm_blendv_epi8(negated, rotated, condition);\n        \n        _mm_storeu_si128((__m128i*)(dst + i), result);\n    }\n}\n```"}
{"task_id": "SimdBench_48_SSE", "completion": "```cpp\nvoid matrix_conditional_bit_rotate_simd(const uint32_t* src, uint32_t* dst, uint8_t rotate_bits, size_t length){\n    __m128i mask = _mm_set1_epi32(0xF);\n    __m128i ones = _mm_set1_epi32(0xF);\n    __m128i rotate_mask = _mm_set1_epi32((1 << rotate_bits) - 1);\n    size_t i = 0;\n\n    for (; i <= length - 4; i += 4) {\n        __m128i src_vec = _mm_loadu_si128((__m128i*)(src + i));\n        __m128i low_bits = _mm_and_si128(src_vec, mask);\n        __m128i condition = _mm_cmpeq_epi32(low_bits, ones);\n        \n        __m128i rotated = _mm_srl_epi32(src_vec, _mm_cvtsi32_si128(rotate_bits));\n        __m128i negated = _mm_xor_si128(src_vec, _mm_set1_epi32(0xFFFFFFFF));\n        \n        __m128i result = _mm_blendv_epi8(negated, rotated, condition);\n        _mm_storeu_si128((__m128i*)(dst + i), result);\n    }\n\n    for (; i < length; ++i) {\n        uint32_t value = src[i];\n        if ((value & 0xF) == 0xF) {\n            dst[i] = (value >> rotate_bits) | (value << (32 - rotate_bits));\n        } else {\n            dst[i] = ~value;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_48_SSE", "completion": "```cpp\nvoid matrix_conditional_bit_rotate_simd(const uint32_t* src, uint32_t* dst, uint8_t rotate_bits, size_t length){\n    __m128i mask = _mm_set1_epi32(0xF);\n    __m128i ones = _mm_set1_epi32(0xF);\n    __m128i rotate_mask = _mm_set1_epi32((1 << rotate_bits) - 1);\n    __m128i shift_count = _mm_set1_epi32(rotate_bits);\n\n    for (size_t i = 0; i < length; i += 4) {\n        __m128i src_vec = _mm_loadu_si128((__m128i const*)(src + i));\n        __m128i low_bits = _mm_and_si128(src_vec, mask);\n        __m128i condition = _mm_cmpeq_epi32(low_bits, ones);\n        __m128i rotated = _mm_or_si128(_mm_srl_epi32(src_vec, shift_count), _mm_sll_epi32(src_vec, _mm_sub_epi32(_mm_set1_epi32(32), shift_count)));\n        __m128i negated = _mm_xor_si128(src_vec, _mm_set1_epi32(0xFFFFFFFF));\n        __m128i result = _mm_blendv_epi8(negated, rotated, condition);\n        _mm_storeu_si128((__m128i*)(dst + i), result);\n    }\n}\n```"}
{"task_id": "SimdBench_49_SSE", "completion": "```cpp\nvoid tensor_ternary_compare_simd(const float* A, const float* B, int8_t* out, float epsilon, size_t length) {\n    __m128 eps_vec = _mm_set1_ps(fabsf(epsilon));\n    size_t i = 0;\n    for (; i <= length - 4; i += 4) {\n        __m128 a_vec = _mm_loadu_ps(&A[i]);\n        __m128 b_vec = _mm_loadu_ps(&B[i]);\n        __m128 diff_vec = _mm_sub_ps(a_vec, b_vec);\n        __m128 abs_diff_vec = _mm_andnot_ps(_mm_set1_ps(-0.0f), diff_vec);\n\n        __m128 mask_gt = _mm_cmpgt_ps(abs_diff_vec, eps_vec);\n        __m128 mask_lt = _mm_cmplt_ps(diff_vec, _mm_xor_ps(eps_vec, _mm_set1_ps(-0.0f)));\n\n        __m128i result_vec = _mm_setzero_si128();\n        result_vec = _mm_or_si128(result_vec, _mm_and_si128(_mm_castps_si128(mask_gt), _mm_set1_epi32(1)));\n        result_vec = _mm_or_si128(result_vec, _mm_and_si128(_mm_castps_si128(mask_lt), _mm_set1_epi32(-1)));\n\n        _mm_storeu_si128((__m128i*)&out[i], result_vec);\n    }\n\n    for (; i < length; ++i) {\n        float diff = A[i] - B[i];\n        if (fabsf(diff) > fabsf(epsilon)) {\n            out[i] = (diff > 0) ? 1 : -1;\n        } else {\n            out[i] = 0;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_49_SSE", "completion": "```cpp\nvoid tensor_ternary_compare_simd(const float* A, const float* B, int8_t* out, float epsilon, size_t length) {\n    __m128 eps_vec = _mm_set1_ps(fabsf(epsilon));\n    size_t i = 0;\n    for (; i <= length - 4; i += 4) {\n        __m128 a_vec = _mm_loadu_ps(&A[i]);\n        __m128 b_vec = _mm_loadu_ps(&B[i]);\n        __m128 diff_vec = _mm_sub_ps(a_vec, b_vec);\n        __m128 abs_diff_vec = _mm_andnot_ps(_mm_set1_ps(-0.0f), diff_vec);\n\n        __m128 mask_gt = _mm_cmpgt_ps(abs_diff_vec, eps_vec);\n        __m128 mask_lt = _mm_cmplt_ps(diff_vec, _mm_xor_ps(eps_vec, _mm_set1_ps(-0.0f)));\n\n        __m128i result_vec = _mm_setzero_si128();\n        result_vec = _mm_or_si128(result_vec, _mm_and_si128(_mm_castps_si128(mask_gt), _mm_set1_epi32(0x00000001)));\n        result_vec = _mm_or_si128(result_vec, _mm_and_si128(_mm_castps_si128(mask_lt), _mm_set1_epi32(0xFFFFFFFE)));\n\n        _mm_storeu_si128((__m128i*)&out[i], result_vec);\n    }\n\n    for (; i < length; ++i) {\n        float diff = A[i] - B[i];\n        if (fabsf(diff) > fabsf(epsilon)) {\n            out[i] = (diff > 0) ? 1 : -1;\n        } else {\n            out[i] = 0;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_49_SSE", "completion": "```cpp\nvoid tensor_ternary_compare_simd(const float* A, const float* B, int8_t* out, float epsilon, size_t length) {\n    __m128 eps_vec = _mm_set1_ps(fabsf(epsilon));\n    size_t i = 0;\n    for (; i <= length - 4; i += 4) {\n        __m128 a_vec = _mm_loadu_ps(&A[i]);\n        __m128 b_vec = _mm_loadu_ps(&B[i]);\n        __m128 diff_vec = _mm_sub_ps(a_vec, b_vec);\n        __m128 abs_diff_vec = _mm_andnot_ps(_mm_set1_ps(-0.0f), diff_vec);\n\n        __m128 gt_mask = _mm_cmpgt_ps(abs_diff_vec, eps_vec);\n        __m128 lt_mask = _mm_cmplt_ps(diff_vec, _mm_xor_ps(eps_vec, _mm_set1_ps(-0.0f)));\n\n        __m128i result_vec = _mm_setzero_si128();\n        result_vec = _mm_or_si128(result_vec, _mm_and_si128(_mm_castps_si128(gt_mask), _mm_set1_epi32(1)));\n        result_vec = _mm_or_si128(result_vec, _mm_and_si128(_mm_castps_si128(lt_mask), _mm_set1_epi32(-1)));\n\n        _mm_storeu_si128((__m128i*)&out[i], result_vec);\n    }\n\n    for (; i < length; ++i) {\n        float diff = A[i] - B[i];\n        if (fabsf(diff) > fabsf(epsilon)) {\n            out[i] = (diff > 0) ? 1 : -1;\n        } else {\n            out[i] = 0;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_49_SSE", "completion": "```cpp\nvoid tensor_ternary_compare_simd(const float* A, const float* B, int8_t* out, float epsilon, size_t length) {\n    __m128 eps_vec = _mm_set1_ps(fabsf(epsilon));\n    size_t i = 0;\n    for (; i <= length - 4; i += 4) {\n        __m128 a_vec = _mm_loadu_ps(&A[i]);\n        __m128 b_vec = _mm_loadu_ps(&B[i]);\n        __m128 diff_vec = _mm_sub_ps(a_vec, b_vec);\n        __m128 abs_diff_vec = _mm_andnot_ps(_mm_set1_ps(-0.0f), diff_vec);\n\n        __m128 mask_gt = _mm_cmpgt_ps(abs_diff_vec, eps_vec);\n        __m128 mask_lt = _mm_cmplt_ps(diff_vec, _mm_xor_ps(eps_vec, _mm_set1_ps(-0.0f)));\n\n        __m128i result_vec = _mm_setzero_si128();\n        result_vec = _mm_or_si128(result_vec, _mm_and_si128(_mm_castps_si128(mask_gt), _mm_set1_epi32(1)));\n        result_vec = _mm_or_si128(result_vec, _mm_and_si128(_mm_castps_si128(mask_lt), _mm_set1_epi32(-1)));\n\n        _mm_storeu_si128((__m128i*)&out[i], result_vec);\n    }\n\n    for (; i < length; ++i) {\n        float diff = A[i] - B[i];\n        if (fabsf(diff) > fabsf(epsilon)) {\n            out[i] = (diff > 0) ? 1 : -1;\n        } else {\n            out[i] = 0;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_49_SSE", "completion": "```cpp\nvoid tensor_ternary_compare_simd(const float* A, const float* B, int8_t* out, float epsilon, size_t length) {\n    __m128 eps_vec = _mm_set1_ps(fabsf(epsilon));\n    size_t i = 0;\n    for (; i <= length - 4; i += 4) {\n        __m128 a_vec = _mm_loadu_ps(&A[i]);\n        __m128 b_vec = _mm_loadu_ps(&B[i]);\n        __m128 diff_vec = _mm_sub_ps(a_vec, b_vec);\n        __m128 abs_diff_vec = _mm_andnot_ps(_mm_set1_ps(-0.0f), diff_vec);\n\n        __m128 mask_gt = _mm_cmpgt_ps(abs_diff_vec, eps_vec);\n        __m128 mask_lt = _mm_cmplt_ps(diff_vec, _mm_xor_ps(eps_vec, _mm_set1_ps(-0.0f)));\n\n        __m128i result_vec = _mm_setzero_si128();\n        result_vec = _mm_or_si128(result_vec, _mm_and_si128(_mm_castps_si128(mask_gt), _mm_set1_epi32(1)));\n        result_vec = _mm_or_si128(result_vec, _mm_and_si128(_mm_castps_si128(mask_lt), _mm_set1_epi32(-1)));\n\n        _mm_storeu_si128((__m128i*)&out[i], result_vec);\n    }\n\n    for (; i < length; ++i) {\n        float diff = A[i] - B[i];\n        if (fabsf(diff) > fabsf(epsilon)) {\n            out[i] = (diff > 0) ? 1 : -1;\n        } else {\n            out[i] = 0;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_50_SSE", "completion": "```cpp\nvoid float_to_int_saturate_simd(const float* A, int32_t* B, size_t size) {\n    const __m128i int_max = _mm_set1_epi32(INT32_MAX);\n    const __m128i int_min = _mm_set1_epi32(INT32_MIN);\n    const __m128 float_max = _mm_castsi128_ps(int_max);\n    const __m128 float_min = _mm_castsi128_ps(int_min);\n\n    size_t i = 0;\n    for (; i <= size - 4; i += 4) {\n        __m128 vec = _mm_loadu_ps(&A[i]);\n        vec = _mm_min_ps(_mm_max_ps(vec, float_min), float_max);\n        __m128i int_vec = _mm_cvtps_epi32(vec);\n        _mm_storeu_si128((__m128i*)&B[i], int_vec);\n    }\n\n    for (; i < size; ++i) {\n        float val = A[i];\n        if (val > INT32_MAX) val = INT32_MAX;\n        else if (val < INT32_MIN) val = INT32_MIN;\n        B[i] = static_cast<int32_t>(val);\n    }\n}\n```"}
{"task_id": "SimdBench_50_SSE", "completion": "```cpp\nvoid float_to_int_saturate_simd(const float* A, int32_t* B, size_t size) {\n    const __m128 max_int = _mm_set1_ps(static_cast<float>(INT32_MAX));\n    const __m128 min_int = _mm_set1_ps(static_cast<float>(INT32_MIN));\n\n    size_t i = 0;\n    for (; i <= size - 4; i += 4) {\n        __m128 vec = _mm_loadu_ps(&A[i]);\n        vec = _mm_min_ps(_mm_max_ps(vec, min_int), max_int);\n        __m128i int_vec = _mm_cvtps_epi32(vec);\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&B[i]), int_vec);\n    }\n\n    for (; i < size; ++i) {\n        float val = A[i];\n        if (val > INT32_MAX) val = INT32_MAX;\n        else if (val < INT32_MIN) val = INT32_MIN;\n        B[i] = static_cast<int32_t>(val);\n    }\n}\n```"}
{"task_id": "SimdBench_50_SSE", "completion": "```cpp\nvoid float_to_int_saturate_simd(const float* A, int32_t* B, size_t size) {\n    const __m128i int_max = _mm_set1_epi32(INT32_MAX);\n    const __m128i int_min = _mm_set1_epi32(INT32_MIN);\n    const __m128 float_max = _mm_castsi128_ps(int_max);\n    const __m128 float_min = _mm_castsi128_ps(int_min);\n\n    size_t i = 0;\n    for (; i <= size - 4; i += 4) {\n        __m128 vec = _mm_loadu_ps(&A[i]);\n        vec = _mm_min_ps(_mm_max_ps(vec, float_min), float_max);\n        __m128i int_vec = _mm_cvtps_epi32(vec);\n        _mm_storeu_si128((__m128i*)&B[i], int_vec);\n    }\n\n    for (; i < size; ++i) {\n        float val = A[i];\n        if (val > INT32_MAX) val = INT32_MAX;\n        else if (val < INT32_MIN) val = INT32_MIN;\n        B[i] = static_cast<int32_t>(val);\n    }\n}\n```"}
{"task_id": "SimdBench_50_SSE", "completion": "```cpp\nvoid float_to_int_saturate_simd(const float* A, int32_t* B, size_t size) {\n    const __m128i int_max = _mm_set1_epi32(INT32_MAX);\n    const __m128i int_min = _mm_set1_epi32(INT32_MIN);\n    const __m128 float_max = _mm_castsi128_ps(int_max);\n    const __m128 float_min = _mm_castsi128_ps(int_min);\n\n    size_t i;\n    for (i = 0; i <= size - 4; i += 4) {\n        __m128 vec = _mm_loadu_ps(&A[i]);\n        vec = _mm_min_ps(_mm_max_ps(vec, float_min), float_max);\n        __m128i int_vec = _mm_cvtps_epi32(vec);\n        _mm_storeu_si128((__m128i*)&B[i], int_vec);\n    }\n\n    for (; i < size; ++i) {\n        float val = A[i];\n        if (val > INT32_MAX) val = INT32_MAX;\n        else if (val < INT32_MIN) val = INT32_MIN;\n        B[i] = static_cast<int32_t>(val);\n    }\n}\n```"}
{"task_id": "SimdBench_50_SSE", "completion": "```cpp\nvoid float_to_int_saturate_simd(const float* A, int32_t* B, size_t size) {\n    const __m128i int_max = _mm_set1_epi32(INT32_MAX);\n    const __m128i int_min = _mm_set1_epi32(INT32_MIN);\n    const __m128 float_max = _mm_castsi128_ps(int_max);\n    const __m128 float_min = _mm_castsi128_ps(int_min);\n\n    size_t i;\n    for (i = 0; i <= size - 4; i += 4) {\n        __m128 vec = _mm_loadu_ps(&A[i]);\n        vec = _mm_min_ps(_mm_max_ps(vec, float_min), float_max);\n        __m128i int_vec = _mm_cvtps_epi32(vec);\n        _mm_storeu_si128((__m128i*)&B[i], int_vec);\n    }\n\n    for (; i < size; ++i) {\n        float val = A[i];\n        if (val > INT32_MAX) val = INT32_MAX;\n        else if (val < INT32_MIN) val = INT32_MIN;\n        B[i] = static_cast<int32_t>(val);\n    }\n}\n```"}
{"task_id": "SimdBench_51_SSE", "completion": "```cpp\nvoid int_to_float_scaled_simd(const int32_t* A, int8_t scale, float* B, size_t size) {\n    __m128i scale_vec = _mm_set1_epi32(scale);\n    size_t i = 0;\n    for (; i <= size - 4; i += 4) {\n        __m128i int_vec = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128 float_vec = _mm_cvtepi32_ps(int_vec);\n        __m128 scaled_float_vec = _mm_mul_ps(float_vec, _mm_cvtepi32_ps(scale_vec));\n        _mm_storeu_ps(&B[i], scaled_float_vec);\n    }\n    for (; i < size; ++i) {\n        B[i] = static_cast<float>(A[i]) * scale;\n    }\n}\n```"}
{"task_id": "SimdBench_51_SSE", "completion": "```cpp\nvoid int_to_float_scaled_simd(const int32_t* A, int8_t scale, float* B, size_t size) {\n    __m128i scale_vec = _mm_set1_epi32(scale);\n    size_t i = 0;\n    for (; i <= size - 4; i += 4) {\n        __m128i int_vec = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128 float_vec = _mm_cvtepi32_ps(int_vec);\n        __m128 scaled_float_vec = _mm_mul_ps(float_vec, _mm_cvtepi32_ps(scale_vec));\n        _mm_storeu_ps(&B[i], scaled_float_vec);\n    }\n    for (; i < size; ++i) {\n        B[i] = static_cast<float>(A[i]) * scale;\n    }\n}\n```"}
{"task_id": "SimdBench_51_SSE", "completion": "```cpp\nvoid int_to_float_scaled_simd(const int32_t* A, int8_t scale, float* B, size_t size) {\n    __m128i scale_vec = _mm_set1_epi32(scale);\n    size_t i = 0;\n    for (; i <= size - 4; i += 4) {\n        __m128i int_vec = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128 float_vec = _mm_cvtepi32_ps(int_vec);\n        __m128 scaled_float_vec = _mm_mul_ps(float_vec, _mm_cvtepi32_ps(scale_vec));\n        _mm_storeu_ps(&B[i], scaled_float_vec);\n    }\n    for (; i < size; ++i) {\n        B[i] = static_cast<float>(A[i]) * scale;\n    }\n}\n```"}
{"task_id": "SimdBench_51_SSE", "completion": "```cpp\nvoid int_to_float_scaled_simd(const int32_t* A, int8_t scale, float* B, size_t size) {\n    __m128i scale_vec = _mm_set1_epi32(scale);\n    size_t i = 0;\n    for (; i <= size - 4; i += 4) {\n        __m128i int_vec = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128 float_vec = _mm_cvtepi32_ps(int_vec);\n        __m128 scaled_float_vec = _mm_mul_ps(float_vec, _mm_cvtepi32_ps(scale_vec));\n        _mm_storeu_ps(&B[i], scaled_float_vec);\n    }\n    for (; i < size; ++i) {\n        B[i] = static_cast<float>(A[i]) * scale;\n    }\n}\n```"}
{"task_id": "SimdBench_51_SSE", "completion": "```cpp\nvoid int_to_float_scaled_simd(const int32_t* A, int8_t scale, float* B, size_t size) {\n    __m128i scale_vec = _mm_set1_epi32(scale);\n    size_t i = 0;\n    for (; i <= size - 4; i += 4) {\n        __m128i int_vec = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128 float_vec = _mm_cvtepi32_ps(int_vec);\n        __m128 scaled_float_vec = _mm_mul_ps(float_vec, _mm_cvtepi32_ps(scale_vec));\n        _mm_storeu_ps(&B[i], scaled_float_vec);\n    }\n    for (; i < size; ++i) {\n        B[i] = static_cast<float>(A[i]) * scale;\n    }\n}\n```"}
{"task_id": "SimdBench_52_SSE", "completion": "```cpp\nvoid float_div_round_simd(const float* A, const float* B, int32_t* C, size_t size) {\n    size_t i = 0;\n    for (; i <= size - 4; i += 4) {\n        __m128 a = _mm_loadu_ps(&A[i]);\n        __m128 b = _mm_loadu_ps(&B[i]);\n        __m128 div_result = _mm_div_ps(a, b);\n        __m128 rounded_result = _mm_round_ps(div_result, _MM_FROUND_TO_NEAREST_INT);\n        _mm_storeu_si128((__m128i*)&C[i], _mm_cvtps_epi32(rounded_result));\n    }\n    for (; i < size; ++i) {\n        C[i] = (int32_t)std::round(A[i] / B[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_52_SSE", "completion": "```cpp\nvoid float_div_round_simd(const float* A, const float* B, int32_t* C, size_t size) {\n    size_t i = 0;\n    for (; i <= size - 4; i += 4) {\n        __m128 a = _mm_loadu_ps(&A[i]);\n        __m128 b = _mm_loadu_ps(&B[i]);\n        __m128 div_result = _mm_div_ps(a, b);\n        __m128 rounded_result = _mm_round_ps(div_result, _MM_FROUND_TO_NEAREST_INT);\n        _mm_storeu_si128((__m128i*)&C[i], _mm_cvtps_epi32(rounded_result));\n    }\n    for (; i < size; ++i) {\n        C[i] = (int32_t)std::round(A[i] / B[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_52_SSE", "completion": "```cpp\nvoid float_div_round_simd(const float* A, const float* B, int32_t* C, size_t size) {\n    size_t i = 0;\n    for (; i <= size - 4; i += 4) {\n        __m128 a = _mm_loadu_ps(&A[i]);\n        __m128 b = _mm_loadu_ps(&B[i]);\n        __m128 div_result = _mm_div_ps(a, b);\n        __m128 rounded_result = _mm_round_ps(div_result, _MM_FROUND_TO_NEAREST_INT);\n        _mm_storeu_si128((__m128i*)&C[i], _mm_cvtps_epi32(rounded_result));\n    }\n    for (; i < size; ++i) {\n        C[i] = (int32_t)std::round(A[i] / B[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_52_SSE", "completion": "```cpp\nvoid float_div_round_simd(const float* A, const float* B, int32_t* C, size_t size) {\n    size_t i = 0;\n    for (; i <= size - 4; i += 4) {\n        __m128 a = _mm_loadu_ps(&A[i]);\n        __m128 b = _mm_loadu_ps(&B[i]);\n        __m128 div_result = _mm_div_ps(a, b);\n        __m128 rounded_result = _mm_round_ps(div_result, _MM_FROUND_TO_NEAREST_INT);\n        _mm_storeu_si128((__m128i*)&C[i], _mm_cvtps_epi32(rounded_result));\n    }\n    for (; i < size; ++i) {\n        C[i] = (int32_t)std::round(A[i] / B[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_52_SSE", "completion": "```cpp\nvoid float_div_round_simd(const float* A, const float* B, int32_t* C, size_t size) {\n    size_t i = 0;\n    for (; i <= size - 4; i += 4) {\n        __m128 a = _mm_loadu_ps(&A[i]);\n        __m128 b = _mm_loadu_ps(&B[i]);\n        __m128 div_result = _mm_div_ps(a, b);\n        __m128 rounded_result = _mm_round_ps(div_result, _MM_FROUND_TO_NEAREST_INT);\n        _mm_storeu_si128((__m128i*)&C[i], _mm_cvtps_epi32(rounded_result));\n    }\n    for (; i < size; ++i) {\n        C[i] = (int32_t)std::round(A[i] / B[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_53_SSE", "completion": "```cpp\nvoid double_to_float_saturate_simd(const double* A, float* B, size_t size) {\n    const __m128 flt_max = _mm_set1_ps(FLT_MAX);\n    const __m128 flt_min = _mm_set1_ps(-FLT_MAX);\n\n    for (size_t i = 0; i <= size - 4; i += 4) {\n        __m128d a = _mm_loadu_pd(&A[i]);\n        __m128d a_hi = _mm_loadu_pd(&A[i + 2]);\n\n        __m128 b_lo = _mm_cvtpd_ps(a);\n        __m128 b_hi = _mm_cvtpd_ps(a_hi);\n\n        b_lo = _mm_min_ps(b_lo, flt_max);\n        b_lo = _mm_max_ps(b_lo, flt_min);\n        b_hi = _mm_min_ps(b_hi, flt_max);\n        b_hi = _mm_max_ps(b_hi, flt_min);\n\n        _mm_storeu_ps(&B[i], b_lo);\n        _mm_storeu_ps(&B[i + 2], b_hi);\n    }\n\n    for (size_t i = (size / 4) * 4; i < size; ++i) {\n        double val = A[i];\n        if (val > FLT_MAX) {\n            B[i] = FLT_MAX;\n        } else if (val < -FLT_MAX) {\n            B[i] = -FLT_MAX;\n        } else {\n            B[i] = static_cast<float>(val);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_53_SSE", "completion": "```cpp\nvoid double_to_float_saturate_simd(const double* A, float* B, size_t size) {\n    const __m128 flt_max = _mm_set1_ps(FLT_MAX);\n    const __m128 flt_min = _mm_set1_ps(-FLT_MAX);\n\n    for (size_t i = 0; i <= size - 4; i += 4) {\n        __m128d a = _mm_loadu_pd(&A[i]);\n        __m128d a1 = _mm_loadu_pd(&A[i + 2]);\n\n        __m128 b = _mm_cvtpd_ps(a);\n        __m128 b1 = _mm_cvtpd_ps(a1);\n\n        b = _mm_max_ps(b, flt_min);\n        b = _mm_min_ps(b, flt_max);\n        b1 = _mm_max_ps(b1, flt_min);\n        b1 = _mm_min_ps(b1, flt_max);\n\n        _mm_storeu_ps(&B[i], b);\n        _mm_storeu_ps(&B[i + 2], b1);\n    }\n\n    for (size_t i = (size / 4) * 4; i < size; ++i) {\n        double val = A[i];\n        if (val > FLT_MAX) {\n            B[i] = FLT_MAX;\n        } else if (val < -FLT_MAX) {\n            B[i] = -FLT_MAX;\n        } else {\n            B[i] = static_cast<float>(val);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_53_SSE", "completion": "```cpp\nvoid double_to_float_saturate_simd(const double* A, float* B, size_t size) {\n    const __m128 max_float = _mm_set1_ps(FLT_MAX);\n    const __m128 min_float = _mm_set1_ps(-FLT_MAX);\n\n    size_t i = 0;\n    for (; i <= size - 4; i += 4) {\n        __m128d double_values = _mm_loadu_pd(&A[i]);\n        __m128 float_values1 = _mm_cvtpd_ps(double_values);\n        double_values = _mm_loadu_pd(&A[i + 2]);\n        __m128 float_values2 = _mm_cvtpd_ps(double_values);\n\n        float_values1 = _mm_min_ps(float_values1, max_float);\n        float_values1 = _mm_max_ps(float_values1, min_float);\n        float_values2 = _mm_min_ps(float_values2, max_float);\n        float_values2 = _mm_max_ps(float_values2, min_float);\n\n        __m128 combined_values = _mm_shuffle_ps(float_values1, float_values2, _MM_SHUFFLE(1, 0, 1, 0));\n        _mm_storeu_ps(&B[i], combined_values);\n    }\n\n    for (; i < size; ++i) {\n        double value = A[i];\n        if (value > FLT_MAX) {\n            B[i] = FLT_MAX;\n        } else if (value < -FLT_MAX) {\n            B[i] = -FLT_MAX;\n        } else {\n            B[i] = static_cast<float>(value);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_53_SSE", "completion": "```cpp\nvoid double_to_float_saturate_simd(const double* A, float* B, size_t size) {\n    const __m128 flt_max = _mm_set1_ps(FLT_MAX);\n    const __m128 flt_min = _mm_set1_ps(-FLT_MAX);\n\n    size_t i = 0;\n    for (; i <= size - 4; i += 4) {\n        __m128d a = _mm_loadu_pd(&A[i]);\n        __m128d a_hi = _mm_loadu_pd(&A[i + 2]);\n\n        __m128 b_lo = _mm_cvtpd_ps(a);\n        __m128 b_hi = _mm_cvtpd_ps(a_hi);\n\n        b_lo = _mm_min_ps(b_lo, flt_max);\n        b_lo = _mm_max_ps(b_lo, flt_min);\n        b_hi = _mm_min_ps(b_hi, flt_max);\n        b_hi = _mm_max_ps(b_hi, flt_min);\n\n        _mm_storeu_ps(&B[i], b_lo);\n        _mm_storeu_ps(&B[i + 2], b_hi);\n    }\n\n    for (; i < size; ++i) {\n        double val = A[i];\n        if (val > FLT_MAX) {\n            B[i] = FLT_MAX;\n        } else if (val < -FLT_MAX) {\n            B[i] = -FLT_MAX;\n        } else {\n            B[i] = static_cast<float>(val);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_53_SSE", "completion": "```cpp\nvoid double_to_float_saturate_simd(const double* A, float* B, size_t size) {\n    const __m128 flt_max = _mm_set1_ps(FLT_MAX);\n    const __m128 flt_min = _mm_set1_ps(-FLT_MAX);\n\n    size_t i = 0;\n    for (; i <= size - 4; i += 4) {\n        __m128d a = _mm_loadu_pd(&A[i]);\n        __m128d a_hi = _mm_loadu_pd(&A[i + 2]);\n\n        __m128 b_lo = _mm_cvtpd_ps(a);\n        __m128 b_hi = _mm_cvtpd_ps(a_hi);\n\n        b_lo = _mm_min_ps(b_lo, flt_max);\n        b_lo = _mm_max_ps(b_lo, flt_min);\n        b_hi = _mm_min_ps(b_hi, flt_max);\n        b_hi = _mm_max_ps(b_hi, flt_min);\n\n        _mm_storeu_ps(&B[i], b_lo);\n        _mm_storeu_ps(&B[i + 2], b_hi);\n    }\n\n    for (; i < size; ++i) {\n        double val = A[i];\n        if (val > FLT_MAX) {\n            B[i] = FLT_MAX;\n        } else if (val < -FLT_MAX) {\n            B[i] = -FLT_MAX;\n        } else {\n            B[i] = static_cast<float>(val);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_54_SSE", "completion": "```cpp\nvoid int16_to_int32_simd(const int16_t* A, int32_t* B, size_t size) {\n    size_t i = 0;\n    for (; i <= size - 8; i += 8) {\n        __m128i a = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i b = _mm_cvtepi16_epi32(_mm_unpacklo_epi16(a, _mm_setzero_si128()));\n        __m128i c = _mm_cvtepi16_epi32(_mm_unpackhi_epi16(a, _mm_setzero_si128()));\n        _mm_storeu_si128((__m128i*)&B[i], b);\n        _mm_storeu_si128((__m128i*)&B[i + 4], c);\n    }\n    for (; i < size; ++i) {\n        B[i] = static_cast<int32_t>(A[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_54_SSE", "completion": "```cpp\nvoid int16_to_int32_simd(const int16_t* A, int32_t* B, size_t size) {\n    size_t i = 0;\n    for (; i <= size - 8; i += 8) {\n        __m128i a = _mm_loadu_si128((__m128i const*)(A + i));\n        __m128i b = _mm_cvtepi16_epi32(_mm_unpacklo_epi16(a, _mm_setzero_si128()));\n        __m128i c = _mm_cvtepi16_epi32(_mm_unpackhi_epi16(a, _mm_setzero_si128()));\n        _mm_storeu_si128((__m128i*)(B + i), b);\n        _mm_storeu_si128((__m128i*)(B + i + 4), c);\n    }\n    for (; i < size; ++i) {\n        B[i] = static_cast<int32_t>(A[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_54_SSE", "completion": "```cpp\nvoid int16_to_int32_simd(const int16_t* A, int32_t* B, size_t size) {\n    size_t i = 0;\n    for (; i <= size - 8; i += 8) {\n        __m128i input = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i output_low = _mm_cvtepi16_epi32(_mm_unpacklo_epi16(input, _mm_setzero_si128()));\n        __m128i output_high = _mm_cvtepi16_epi32(_mm_unpackhi_epi16(input, _mm_setzero_si128()));\n        _mm_storeu_si128((__m128i*)&B[i], output_low);\n        _mm_storeu_si128((__m128i*)&B[i + 4], output_high);\n    }\n    for (; i < size; ++i) {\n        B[i] = static_cast<int32_t>(A[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_54_SSE", "completion": "```cpp\nvoid int16_to_int32_simd(const int16_t* A, int32_t* B, size_t size) {\n    size_t i = 0;\n    for (; i <= size - 8; i += 8) {\n        __m128i a = _mm_loadu_si128((__m128i const*)(A + i));\n        __m128i b = _mm_cvtepi16_epi32(_mm_unpacklo_epi16(a, _mm_setzero_si128()));\n        __m128i c = _mm_cvtepi16_epi32(_mm_unpackhi_epi16(a, _mm_setzero_si128()));\n        _mm_storeu_si128((__m128i*)(B + i), b);\n        _mm_storeu_si128((__m128i*)(B + i + 4), c);\n    }\n    for (; i < size; ++i) {\n        B[i] = static_cast<int32_t>(A[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_54_SSE", "completion": "```cpp\nvoid int16_to_int32_simd(const int16_t* A, int32_t* B, size_t size) {\n    size_t i = 0;\n    for (; i <= size - 8; i += 8) {\n        __m128i a = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i b = _mm_cvtepi16_epi32(_mm_unpacklo_epi16(a, _mm_setzero_si128()));\n        __m128i c = _mm_cvtepi16_epi32(_mm_unpackhi_epi16(a, _mm_setzero_si128()));\n        _mm_storeu_si128((__m128i*)&B[i], b);\n        _mm_storeu_si128((__m128i*)&B[i + 4], c);\n    }\n    for (; i < size; ++i) {\n        B[i] = static_cast<int32_t>(A[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_55_SSE", "completion": "```cpp\nvoid conditional_normalize_simd(const float* A, const int32_t* control, float* B, size_t size, float min_val, float max_val) {\n    __m128 min_vec = _mm_set1_ps(min_val);\n    __m128 max_vec = _mm_set1_ps(max_val);\n    __m128 one_vec = _mm_set1_ps(1.0f);\n    __m128 zero_vec = _mm_set1_ps(0.0f);\n    __m128 range_vec = _mm_sub_ps(max_vec, min_vec);\n\n    for (size_t i = 0; i <= size - 4; i += 4) {\n        __m128 a_vec = _mm_loadu_ps(&A[i]);\n        __m128 control_vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&control[i]));\n        __m128i mask = _mm_cmpgt_epi32(control_vec, _mm_setzero_si128());\n\n        __m128 normalized_vec = _mm_sub_ps(a_vec, min_vec);\n        normalized_vec = _mm_div_ps(normalized_vec, range_vec);\n        normalized_vec = _mm_max_ps(normalized_vec, zero_vec);\n        normalized_vec = _mm_min_ps(normalized_vec, one_vec);\n\n        __m128 result_vec = _mm_blendv_ps(a_vec, normalized_vec, _mm_castsi128_ps(mask));\n        _mm_storeu_ps(&B[i], result_vec);\n    }\n\n    // Handle remaining elements\n    for (size_t i = (size / 4) * 4; i < size; ++i) {\n        if (control[i] > 0) {\n            float val = (A[i] - min_val) / (max_val - min_val);\n            B[i] = val < 0.0f ? 0.0f : (val > 1.0f ? 1.0f : val);\n        } else {\n            B[i] = A[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_55_SSE", "completion": "```cpp\nvoid conditional_normalize_simd(const float* A, const int32_t* control, float* B, size_t size, float min_val, float max_val) {\n    __m128 min_vec = _mm_set1_ps(min_val);\n    __m128 max_vec = _mm_set1_ps(max_val);\n    __m128 one_vec = _mm_set1_ps(1.0f);\n    __m128 zero_vec = _mm_set1_ps(0.0f);\n    __m128 range_vec = _mm_sub_ps(max_vec, min_vec);\n\n    for (size_t i = 0; i < size; i += 4) {\n        __m128 a_vec = _mm_loadu_ps(&A[i]);\n        __m128 control_vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&control[i]));\n        __m128i mask = _mm_cmpgt_epi32(control_vec, _mm_setzero_si128());\n\n        __m128 normalized_vec = _mm_sub_ps(a_vec, min_vec);\n        normalized_vec = _mm_div_ps(normalized_vec, range_vec);\n        normalized_vec = _mm_max_ps(normalized_vec, zero_vec);\n        normalized_vec = _mm_min_ps(normalized_vec, one_vec);\n\n        __m128 result_vec = _mm_blendv_ps(a_vec, normalized_vec, _mm_castsi128_ps(mask));\n        _mm_storeu_ps(&B[i], result_vec);\n    }\n}\n```"}
{"task_id": "SimdBench_55_SSE", "completion": "```cpp\nvoid conditional_normalize_simd(const float* A, const int32_t* control, float* B, size_t size, float min_val, float max_val) {\n    __m128 min_vec = _mm_set1_ps(min_val);\n    __m128 max_vec = _mm_set1_ps(max_val);\n    __m128 one_vec = _mm_set1_ps(1.0f);\n    __m128 zero_vec = _mm_setzero_ps();\n    __m128 range_vec = _mm_sub_ps(max_vec, min_vec);\n\n    for (size_t i = 0; i <= size - 4; i += 4) {\n        __m128 a_vec = _mm_loadu_ps(&A[i]);\n        __m128 control_vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&control[i]));\n        __m128i mask = _mm_cmpgt_epi32(control_vec, _mm_setzero_si128());\n\n        __m128 normalized_vec = _mm_sub_ps(a_vec, min_vec);\n        normalized_vec = _mm_div_ps(normalized_vec, range_vec);\n        normalized_vec = _mm_max_ps(normalized_vec, zero_vec);\n        normalized_vec = _mm_min_ps(normalized_vec, one_vec);\n\n        __m128 result_vec = _mm_blendv_ps(a_vec, normalized_vec, _mm_castsi128_ps(mask));\n        _mm_storeu_ps(&B[i], result_vec);\n    }\n\n    // Handle remaining elements\n    for (size_t i = (size / 4) * 4; i < size; ++i) {\n        if (control[i] > 0) {\n            float val = (A[i] - min_val) / (max_val - min_val);\n            B[i] = val < 0.0f ? 0.0f : (val > 1.0f ? 1.0f : val);\n        } else {\n            B[i] = A[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_55_SSE", "completion": "```cpp\nvoid conditional_normalize_simd(const float* A, const int32_t* control, float* B, size_t size, float min_val, float max_val) {\n    __m128 min_vec = _mm_set1_ps(min_val);\n    __m128 max_vec = _mm_set1_ps(max_val);\n    __m128 one_vec = _mm_set1_ps(1.0f);\n    __m128 zero_vec = _mm_set1_ps(0.0f);\n    __m128 range_vec = _mm_sub_ps(max_vec, min_vec);\n\n    for (size_t i = 0; i <= size - 4; i += 4) {\n        __m128 a_vec = _mm_loadu_ps(&A[i]);\n        __m128 control_vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&control[i]));\n        __m128 mask_vec = _mm_cmpgt_epi32(control_vec, _mm_setzero_si128());\n        mask_vec = _mm_castsi128_ps(mask_vec);\n\n        __m128 normalized_vec = _mm_sub_ps(a_vec, min_vec);\n        normalized_vec = _mm_div_ps(normalized_vec, range_vec);\n        normalized_vec = _mm_max_ps(normalized_vec, zero_vec);\n        normalized_vec = _mm_min_ps(normalized_vec, one_vec);\n\n        __m128 result_vec = _mm_or_ps(_mm_andnot_ps(mask_vec, a_vec), _mm_and_ps(mask_vec, normalized_vec));\n        _mm_storeu_ps(&B[i], result_vec);\n    }\n\n    // Handle remaining elements\n    for (size_t i = (size / 4) * 4; i < size; ++i) {\n        if (control[i] > 0) {\n            float val = (A[i] - min_val) / (max_val - min_val);\n            B[i] = val < 0.0f ? 0.0f : (val > 1.0f ? 1.0f : val);\n        } else {\n            B[i] = A[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_55_SSE", "completion": "```cpp\nvoid conditional_normalize_simd(const float* A, const int32_t* control, float* B, size_t size, float min_val, float max_val) {\n    __m128 min_vec = _mm_set1_ps(min_val);\n    __m128 max_vec = _mm_set1_ps(max_val);\n    __m128 one_vec = _mm_set1_ps(1.0f);\n    __m128 zero_vec = _mm_setzero_ps();\n    __m128 range_vec = _mm_sub_ps(max_vec, min_vec);\n\n    size_t i = 0;\n    for (; i <= size - 4; i += 4) {\n        __m128 a_vec = _mm_loadu_ps(&A[i]);\n        __m128 control_vec = _mm_loadu_si128((__m128i*)&control[i]);\n        __m128i mask = _mm_cmpgt_epi32(control_vec, _mm_setzero_si128());\n\n        __m128 normalized_vec = _mm_sub_ps(a_vec, min_vec);\n        normalized_vec = _mm_div_ps(normalized_vec, range_vec);\n        normalized_vec = _mm_max_ps(normalized_vec, zero_vec);\n        normalized_vec = _mm_min_ps(normalized_vec, one_vec);\n\n        __m128 result_vec = _mm_blendv_ps(a_vec, normalized_vec, _mm_castsi128_ps(mask));\n        _mm_storeu_ps(&B[i], result_vec);\n    }\n\n    for (; i < size; ++i) {\n        if (control[i] > 0) {\n            float val = (A[i] - min_val) / (max_val - min_val);\n            val = val < 0.0f ? 0.0f : val;\n            val = val > 1.0f ? 1.0f : val;\n            B[i] = val;\n        } else {\n            B[i] = A[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_56_SSE", "completion": "```cpp\nvoid int_to_float_sqrt_simd(const uint32_t* A, float* B, size_t size) {\n    size_t i = 0;\n    for (; i <= size - 4; i += 4) {\n        __m128i int_values = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i shifted_values = _mm_srli_epi32(int_values, 16);\n        __m128 float_values = _mm_cvtepi32_ps(shifted_values);\n        __m128 sqrt_values = _mm_sqrt_ps(float_values);\n        _mm_storeu_ps(&B[i], sqrt_values);\n    }\n    for (; i < size; ++i) {\n        uint32_t high_16_bits = A[i] >> 16;\n        B[i] = std::sqrt(static_cast<float>(high_16_bits));\n    }\n}\n```"}
{"task_id": "SimdBench_56_SSE", "completion": "```cpp\nvoid int_to_float_sqrt_simd(const uint32_t* A, float* B, size_t size) {\n    size_t i = 0;\n    for (; i <= size - 4; i += 4) {\n        __m128i int_values = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i shifted_values = _mm_srli_epi32(int_values, 16);\n        __m128 float_values = _mm_cvtepi32_ps(shifted_values);\n        __m128 sqrt_values = _mm_sqrt_ps(float_values);\n        _mm_storeu_ps(&B[i], sqrt_values);\n    }\n    for (; i < size; ++i) {\n        uint32_t high_16_bits = A[i] >> 16;\n        B[i] = std::sqrt(static_cast<float>(high_16_bits));\n    }\n}\n```"}
{"task_id": "SimdBench_56_SSE", "completion": "```cpp\nvoid int_to_float_sqrt_simd(const uint32_t* A, float* B, size_t size) {\n    size_t i = 0;\n    for (; i <= size - 4; i += 4) {\n        __m128i int_values = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i shifted_values = _mm_srli_epi32(int_values, 16);\n        __m128 float_values = _mm_cvtepi32_ps(shifted_values);\n        __m128 sqrt_values = _mm_sqrt_ps(float_values);\n        _mm_storeu_ps(&B[i], sqrt_values);\n    }\n    for (; i < size; ++i) {\n        uint32_t high_16_bits = A[i] >> 16;\n        B[i] = std::sqrt(static_cast<float>(high_16_bits));\n    }\n}\n```"}
{"task_id": "SimdBench_56_SSE", "completion": "```cpp\nvoid int_to_float_sqrt_simd(const uint32_t* A, float* B, size_t size) {\n    size_t i = 0;\n    for (; i <= size - 4; i += 4) {\n        __m128i int_values = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i shifted_ints = _mm_srli_epi32(int_values, 16);\n        __m128 float_values = _mm_cvtepi32_ps(shifted_ints);\n        __m128 sqrt_values = _mm_sqrt_ps(float_values);\n        _mm_storeu_ps(&B[i], sqrt_values);\n    }\n    for (; i < size; ++i) {\n        uint32_t high_16_bits = A[i] >> 16;\n        B[i] = std::sqrt(static_cast<float>(high_16_bits));\n    }\n}\n```"}
{"task_id": "SimdBench_56_SSE", "completion": "```cpp\nvoid int_to_float_sqrt_simd(const uint32_t* A, float* B, size_t size) {\n    size_t i = 0;\n    for (; i <= size - 4; i += 4) {\n        __m128i int_values = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i shifted_ints = _mm_srli_epi32(int_values, 16);\n        __m128 float_values = _mm_cvtepi32_ps(shifted_ints);\n        __m128 sqrt_values = _mm_sqrt_ps(float_values);\n        _mm_storeu_ps(&B[i], sqrt_values);\n    }\n    for (; i < size; ++i) {\n        uint32_t high_16_bits = A[i] >> 16;\n        B[i] = std::sqrt(static_cast<float>(high_16_bits));\n    }\n}\n```"}
{"task_id": "SimdBench_57_SSE", "completion": "```cpp\nvoid int_bits_to_float_simd(const uint32_t* A, float* B, size_t size) {\n    size_t i = 0;\n    for (; i <= size - 4; i += 4) {\n        __m128i int_vec = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128 float_vec = _mm_castsi128_ps(int_vec);\n        _mm_storeu_ps(&B[i], float_vec);\n    }\n    for (; i < size; ++i) {\n        B[i] = reinterpret_cast<const float&>(A[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_57_SSE", "completion": "```cpp\nvoid int_bits_to_float_simd(const uint32_t* A, float* B, size_t size) {\n    size_t i = 0;\n    for (; i <= size - 4; i += 4) {\n        __m128i int_vec = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128 float_vec = _mm_castsi128_ps(int_vec);\n        _mm_storeu_ps(&B[i], float_vec);\n    }\n    for (; i < size; ++i) {\n        B[i] = *reinterpret_cast<const float*>(&A[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_57_SSE", "completion": "```cpp\nvoid int_bits_to_float_simd(const uint32_t* A, float* B, size_t size) {\n    size_t i = 0;\n    for (; i <= size - 4; i += 4) {\n        __m128i int_vector = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128 float_vector = _mm_castsi128_ps(int_vector);\n        _mm_storeu_ps(&B[i], float_vector);\n    }\n    for (; i < size; ++i) {\n        B[i] = *reinterpret_cast<const float*>(&A[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_57_SSE", "completion": "```cpp\nvoid int_bits_to_float_simd(const uint32_t* A, float* B, size_t size) {\n    size_t i = 0;\n    for (; i <= size - 4; i += 4) {\n        __m128i int_vec = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128 float_vec = _mm_castsi128_ps(int_vec);\n        _mm_storeu_ps(&B[i], float_vec);\n    }\n    for (; i < size; ++i) {\n        B[i] = *reinterpret_cast<const float*>(&A[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_57_SSE", "completion": "```cpp\nvoid int_bits_to_float_simd(const uint32_t* A, float* B, size_t size) {\n    size_t i = 0;\n    for (; i <= size - 4; i += 4) {\n        __m128i int_vec = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128 float_vec = _mm_castsi128_ps(int_vec);\n        _mm_storeu_ps(&B[i], float_vec);\n    }\n    for (; i < size; ++i) {\n        B[i] = *reinterpret_cast<const float*>(&A[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_58_SSE", "completion": "```cpp\nvoid conditional_diff_simd(const int32_t* A, const bool* cond, float* diff, size_t size) {\n    __m128i zero = _mm_setzero_si128();\n    __m128 zero_float = _mm_setzero_ps();\n\n    if (size > 0) {\n        diff[0] = 0.0f;\n    }\n\n    for (size_t i = 1; i < size; i += 4) {\n        __m128i a_curr = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i a_prev = _mm_loadu_si128((__m128i*)&A[i - 1]);\n        __m128i cond_vec = _mm_loadu_si128((__m128i*)&cond[i]);\n\n        // Convert bool to mask (0xFFFFFFFF for true, 0x00000000 for false)\n        cond_vec = _mm_and_si128(cond_vec, _mm_set1_epi32(0x01));\n        cond_vec = _mm_cmpeq_epi32(cond_vec, _mm_set1_epi32(0x01));\n\n        // Compute differences\n        __m128i diff_int = _mm_sub_epi32(a_curr, a_prev);\n\n        // Convert differences to float\n        __m128 diff_float = _mm_cvtepi32_ps(diff_int);\n\n        // Apply condition mask\n        diff_float = _mm_and_ps(diff_float, _mm_castsi128_ps(cond_vec));\n\n        // Store results\n        _mm_storeu_ps(&diff[i], diff_float);\n    }\n}\n```"}
{"task_id": "SimdBench_58_SSE", "completion": "```cpp\nvoid conditional_diff_simd(const int32_t* A, const bool* cond, float* diff, size_t size) {\n    __m128i zero = _mm_setzero_si128();\n    __m128 zero_float = _mm_setzero_ps();\n\n    if (size > 0) {\n        diff[0] = 0.0f;\n    }\n\n    for (size_t i = 1; i < size; i += 4) {\n        __m128i a_curr = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i a_prev = _mm_loadu_si128((__m128i*)&A[i - 1]);\n        __m128i cond_vec = _mm_loadu_si128((__m128i*)&cond[i]);\n\n        // Convert bool to mask (0xFFFFFFFF if true, 0x00000000 if false)\n        cond_vec = _mm_and_si128(cond_vec, _mm_set1_epi32(0xFF));\n\n        // Calculate differences\n        __m128i diff_int = _mm_sub_epi32(a_curr, a_prev);\n\n        // Convert int differences to float\n        __m128 diff_float = _mm_cvtepi32_ps(diff_int);\n\n        // Apply condition mask\n        __m128 mask = _mm_cvtepi32_ps(cond_vec);\n        mask = _mm_cmpneq_ps(mask, zero_float);\n        diff_float = _mm_and_ps(diff_float, mask);\n\n        // Store results\n        _mm_storeu_ps(&diff[i], diff_float);\n    }\n}\n```"}
{"task_id": "SimdBench_58_SSE", "completion": "```cpp\nvoid conditional_diff_simd(const int32_t* A, const bool* cond, float* diff, size_t size) {\n    __m128i zero = _mm_setzero_si128();\n    __m128 zero_float = _mm_setzero_ps();\n\n    if (size > 0) {\n        diff[0] = 0.0f;\n    }\n\n    for (size_t i = 1; i < size; i += 4) {\n        __m128i a_curr = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i a_prev = _mm_loadu_si128((__m128i*)&A[i - 1]);\n        __m128i cond_vec = _mm_loadu_si128((__m128i*)&cond[i]);\n\n        // Convert bool to mask\n        __m128i cond_mask = _mm_cmpeq_epi32(cond_vec, _mm_set1_epi32(0xFFFFFFFF));\n\n        // Compute differences\n        __m128i diff_int = _mm_sub_epi32(a_curr, a_prev);\n\n        // Convert differences to float\n        __m128 diff_float = _mm_cvtepi32_ps(diff_int);\n\n        // Apply condition mask\n        __m128 result = _mm_and_ps(_mm_castsi128_ps(cond_mask), diff_float);\n\n        // Blend with zero where condition is false\n        result = _mm_or_ps(result, _mm_andnot_ps(_mm_castsi128_ps(cond_mask), zero_float));\n\n        // Store result\n        _mm_storeu_ps(&diff[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_58_SSE", "completion": "```cpp\nvoid conditional_diff_simd(const int32_t* A, const bool* cond, float* diff, size_t size) {\n    __m128i zero = _mm_setzero_si128();\n    __m128 zero_float = _mm_setzero_ps();\n\n    if (size > 0) {\n        diff[0] = 0.0f;\n    }\n\n    for (size_t i = 1; i < size; i += 4) {\n        __m128i a_curr = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i a_prev = _mm_loadu_si128((__m128i*)&A[i - 1]);\n        __m128i cond_vec = _mm_loadu_si128((__m128i*)&cond[i]);\n\n        // Convert bool to mask\n        __m128i cond_mask = _mm_cmpeq_epi32(cond_vec, _mm_set1_epi32(-1));\n\n        // Calculate differences\n        __m128i diff_int = _mm_sub_epi32(a_curr, a_prev);\n\n        // Convert differences to float\n        __m128 diff_float = _mm_cvtepi32_ps(diff_int);\n\n        // Apply condition mask\n        __m128 result = _mm_and_ps(_mm_castsi128_ps(cond_mask), diff_float);\n\n        // Blend with zero where condition is false\n        result = _mm_or_ps(result, _mm_andnot_ps(_mm_castsi128_ps(cond_mask), zero_float));\n\n        // Store result\n        _mm_storeu_ps(&diff[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_58_SSE", "completion": "```cpp\nvoid conditional_diff_simd(const int32_t* A, const bool* cond, float* diff, size_t size) {\n    __m128i zero = _mm_setzero_si128();\n    __m128 zero_float = _mm_setzero_ps();\n\n    if (size > 0) {\n        diff[0] = 0.0f;\n    }\n\n    for (size_t i = 1; i < size; i += 4) {\n        __m128i a_curr = _mm_loadu_si128((__m128i*)(A + i));\n        __m128i a_prev = _mm_loadu_si128((__m128i*)(A + i - 1));\n\n        __m128i diff_int = _mm_sub_epi32(a_curr, a_prev);\n\n        __m128i cond_mask = _mm_loadu_si128((__m128i*)(cond + i));\n        cond_mask = _mm_and_si128(cond_mask, _mm_cmpeq_epi32(cond_mask, _mm_set1_epi32(0xFFFFFFFF)));\n\n        __m128 diff_float = _mm_cvtepi32_ps(diff_int);\n        diff_float = _mm_and_ps(diff_float, _mm_castsi128_ps(cond_mask));\n\n        _mm_storeu_ps(diff + i, diff_float);\n    }\n}\n```"}
{"task_id": "SimdBench_59_SSE", "completion": "```cpp\nvoid widening_uint_simd(const uint32_t* src, uint64_t* dst, size_t length) {\n    __m128i ones = _mm_set1_epi32(0xFFFFFFFF);\n    size_t i = 0;\n    for (; i <= length - 4; i += 4) {\n        __m128i low = _mm_loadu_si128((__m128i*)(src + i));\n        __m128i high = _mm_cvtepu32_epi64(low);\n        __m128i low_shifted = _mm_cvtepu32_epi64(_mm_srli_epi32(low, 16));\n        __m128i combined = _mm_or_si128(high, _mm_slli_epi64(low_shifted, 32));\n        _mm_storeu_si128((__m128i*)(dst + i), combined);\n    }\n    for (; i < length; ++i) {\n        dst[i] = 0xFFFFFFFF00000000ULL | src[i];\n    }\n}\n```"}
{"task_id": "SimdBench_59_SSE", "completion": "```cpp\nvoid widening_uint_simd(const uint32_t* src, uint64_t* dst, size_t length) {\n    __m128i ones = _mm_set1_epi32(0xFFFFFFFF);\n    size_t i = 0;\n    for (; i <= length - 4; i += 4) {\n        __m128i low = _mm_loadu_si128((__m128i*)(src + i));\n        __m128i high = _mm_cvtepu32_epi64(low);\n        __m128i low_shifted = _mm_cvtepu32_epi64(_mm_srli_epi32(low, 16));\n        __m128i combined = _mm_or_si128(high, _mm_slli_epi64(low_shifted, 32));\n        _mm_storeu_si128((__m128i*)(dst + i), combined);\n    }\n    for (; i < length; ++i) {\n        dst[i] = 0xFFFFFFFF00000000ULL | src[i];\n    }\n}\n```"}
{"task_id": "SimdBench_59_SSE", "completion": "```cpp\nvoid widening_uint_simd(const uint32_t* src, uint64_t* dst, size_t length) {\n    __m128i ones = _mm_set1_epi32(0xFFFFFFFF);\n    size_t i = 0;\n    for (; i <= length - 4; i += 4) {\n        __m128i low = _mm_loadu_si128((__m128i*)(src + i));\n        __m128i high = _mm_cvtepu32_epi64(low);\n        __m128i low_shifted = _mm_cvtepu32_epi64(_mm_srli_epi32(low, 16));\n        __m128i combined = _mm_or_si128(high, _mm_slli_epi64(low_shifted, 32));\n        _mm_storeu_si128((__m128i*)(dst + i), combined);\n    }\n    for (; i < length; ++i) {\n        dst[i] = 0xFFFFFFFF00000000ULL | src[i];\n    }\n}\n```"}
{"task_id": "SimdBench_59_SSE", "completion": "```cpp\nvoid widening_uint_simd(const uint32_t* src, uint64_t* dst, size_t length) {\n    __m128i ones = _mm_set1_epi32(0xFFFFFFFF);\n    size_t i = 0;\n    for (; i <= length - 4; i += 4) {\n        __m128i low = _mm_loadu_si128((__m128i*)&src[i]);\n        __m128i high = _mm_cvtepu32_epi64(low);\n        __m128i low_shifted = _mm_cvtepu32_epi64(_mm_srli_epi32(low, 16));\n        __m128i combined = _mm_or_si128(high, _mm_slli_epi64(low_shifted, 32));\n        _mm_storeu_si128((__m128i*)&dst[i], combined);\n    }\n    for (; i < length; ++i) {\n        dst[i] = 0xFFFFFFFF00000000ULL | src[i];\n    }\n}\n```"}
{"task_id": "SimdBench_59_SSE", "completion": "```cpp\nvoid widening_uint_simd(const uint32_t* src, uint64_t* dst, size_t length) {\n    __m128i ones = _mm_set1_epi32(0xFFFFFFFF);\n    size_t i = 0;\n    for (; i <= length - 4; i += 4) {\n        __m128i low = _mm_loadu_si128((__m128i*)&src[i]);\n        __m128i high = _mm_cvtepu32_epi64(low);\n        __m128i low_shifted = _mm_cvtepu32_epi64(_mm_srli_epi32(low, 16));\n        __m128i combined = _mm_or_si128(high, _mm_slli_epi64(low_shifted, 32));\n        _mm_storeu_si128((__m128i*)&dst[i], combined);\n    }\n    for (; i < length; ++i) {\n        dst[i] = 0xFFFFFFFF00000000ULL | src[i];\n    }\n}\n```"}
{"task_id": "SimdBench_60_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\ndouble indexed_sum_simd(const double* vec, const int16_t* index, size_t length) {\n    __m128d sum = _mm_setzero_pd();\n    size_t i = 0;\n\n    for (; i <= length - 4; i += 4) {\n        __m128i idx = _mm_loadu_si128((__m128i*)&index[i]);\n        __m128d v0 = _mm_loadu_pd(&vec[_mm_extract_epi16(idx, 0)]);\n        __m128d v1 = _mm_loadu_pd(&vec[_mm_extract_epi16(idx, 1)]);\n        __m128d v2 = _mm_loadu_pd(&vec[_mm_extract_epi16(idx, 2)]);\n        __m128d v3 = _mm_loadu_pd(&vec[_mm_extract_epi16(idx, 3)]);\n\n        __m128d s0 = _mm_add_pd(v0, v1);\n        __m128d s1 = _mm_add_pd(v2, v3);\n        sum = _mm_add_pd(sum, _mm_add_pd(s0, s1));\n    }\n\n    for (; i < length; ++i) {\n        sum = _mm_add_sd(sum, _mm_loadu_pd(&vec[index[i]]));\n    }\n\n    double result[2];\n    _mm_storeu_pd(result, sum);\n    return result[0] + result[1];\n}\n```"}
{"task_id": "SimdBench_60_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\ndouble indexed_sum_simd(const double* vec, const int16_t* index, size_t length) {\n    __m128d sum = _mm_setzero_pd();\n    size_t i = 0;\n\n    for (; i <= length - 4; i += 4) {\n        __m128i idx = _mm_loadu_si128((__m128i*)&index[i]);\n        __m128d v0 = _mm_loadu_pd(&vec[_mm_extract_epi16(idx, 0)]);\n        __m128d v1 = _mm_loadu_pd(&vec[_mm_extract_epi16(idx, 1)]);\n        __m128d v2 = _mm_loadu_pd(&vec[_mm_extract_epi16(idx, 2)]);\n        __m128d v3 = _mm_loadu_pd(&vec[_mm_extract_epi16(idx, 3)]);\n\n        __m128d s0 = _mm_add_pd(v0, v1);\n        __m128d s1 = _mm_add_pd(v2, v3);\n        sum = _mm_add_pd(sum, _mm_add_pd(s0, s1));\n    }\n\n    double result[2];\n    _mm_storeu_pd(result, sum);\n\n    for (; i < length; ++i) {\n        result[0] += vec[index[i]];\n    }\n\n    return result[0] + result[1];\n}\n```"}
{"task_id": "SimdBench_60_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\ndouble indexed_sum_simd(const double* vec, const int16_t* index, size_t length) {\n    __m128d sum = _mm_setzero_pd();\n    size_t i = 0;\n\n    for (; i <= length - 4; i += 4) {\n        __m128i idx = _mm_loadu_si128((__m128i*)&index[i]);\n        __m128d v0 = _mm_loadu_pd(&vec[_mm_extract_epi16(idx, 0)]);\n        __m128d v1 = _mm_loadu_pd(&vec[_mm_extract_epi16(idx, 1)]);\n        __m128d v2 = _mm_loadu_pd(&vec[_mm_extract_epi16(idx, 2)]);\n        __m128d v3 = _mm_loadu_pd(&vec[_mm_extract_epi16(idx, 3)]);\n\n        __m128d s0 = _mm_add_pd(v0, v1);\n        __m128d s1 = _mm_add_pd(v2, v3);\n        sum = _mm_add_pd(sum, _mm_add_pd(s0, s1));\n    }\n\n    for (; i < length; ++i) {\n        sum = _mm_add_sd(sum, _mm_loadu_pd(&vec[index[i]]));\n    }\n\n    double result[2];\n    _mm_storeu_pd(result, sum);\n    return result[0] + result[1];\n}\n```"}
{"task_id": "SimdBench_60_SSE", "completion": "```cpp\ndouble indexed_sum_simd(const double* vec, const int16_t* index, size_t length) {\n    __m128d sum = _mm_setzero_pd();\n    size_t i = 0;\n\n    for (; i <= length - 4; i += 4) {\n        __m128i idx = _mm_loadu_si128((__m128i*)&index[i]);\n        __m128d v0 = _mm_loadu_pd(&vec[_mm_extract_epi16(idx, 0)]);\n        __m128d v1 = _mm_loadu_pd(&vec[_mm_extract_epi16(idx, 1)]);\n        __m128d v2 = _mm_loadu_pd(&vec[_mm_extract_epi16(idx, 2)]);\n        __m128d v3 = _mm_loadu_pd(&vec[_mm_extract_epi16(idx, 3)]);\n\n        __m128d s0 = _mm_add_pd(v0, v1);\n        __m128d s1 = _mm_add_pd(v2, v3);\n        sum = _mm_add_pd(sum, _mm_add_pd(s0, s1));\n    }\n\n    double result[2];\n    _mm_storeu_pd(result, sum);\n\n    for (; i < length; ++i) {\n        result[0] += vec[index[i]];\n    }\n\n    return result[0] + result[1];\n}\n```"}
{"task_id": "SimdBench_60_SSE", "completion": "```cpp\ndouble indexed_sum_simd(const double* vec, const int16_t* index, size_t length) {\n    __m128d sum = _mm_setzero_pd();\n    size_t i = 0;\n\n    for (; i <= length - 4; i += 4) {\n        __m128i idx = _mm_loadu_si128((__m128i*)&index[i]);\n        __m128d v0 = _mm_loadu_pd(&vec[_mm_extract_epi16(idx, 0)]);\n        __m128d v1 = _mm_loadu_pd(&vec[_mm_extract_epi16(idx, 1)]);\n        __m128d v2 = _mm_loadu_pd(&vec[_mm_extract_epi16(idx, 2)]);\n        __m128d v3 = _mm_loadu_pd(&vec[_mm_extract_epi16(idx, 3)]);\n\n        __m128d s0 = _mm_add_pd(v0, v1);\n        __m128d s1 = _mm_add_pd(v2, v3);\n        sum = _mm_add_pd(sum, _mm_add_pd(s0, s1));\n    }\n\n    double result[2];\n    _mm_storeu_pd(result, sum);\n\n    for (; i < length; ++i) {\n        result[0] += vec[index[i]];\n    }\n\n    return result[0] + result[1];\n}\n```"}
{"task_id": "SimdBench_61_SSE", "completion": "```cpp\nvoid simple_conv2d_simd(const double* input, const double* kernel, double * output, size_t input_size, size_t kernel_size) {\n    size_t output_size = input_size - kernel_size + 1;\n    __m128d zero = _mm_setzero_pd();\n\n    for (size_t i = 0; i < output_size; ++i) {\n        for (size_t j = 0; j < output_size; ++j) {\n            __m128d sum = _mm_setzero_pd();\n            for (size_t ki = 0; ki < kernel_size; ++ki) {\n                for (size_t kj = 0; kj < kernel_size; kj += 2) {\n                    __m128d input_vec = _mm_loadu_pd(&input[(i + ki) * input_size + j + kj]);\n                    __m128d kernel_vec = _mm_loadu_pd(&kernel[ki * kernel_size + kj]);\n                    sum = _mm_add_pd(sum, _mm_mul_pd(input_vec, kernel_vec));\n                }\n            }\n            // Horizontal add to get the sum of two elements in sum\n            double conv_result[2];\n            _mm_storeu_pd(conv_result, sum);\n            double result = conv_result[0] + conv_result[1];\n            // Apply ReLU activation\n            result = result > 0 ? result : 0;\n            output[i * output_size + j] = result;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_61_SSE", "completion": "```cpp\nvoid simple_conv2d_simd(const double* input, const double* kernel, double * output, size_t input_size, size_t kernel_size) {\n    size_t output_size = input_size - kernel_size + 1;\n    __m128d zero = _mm_setzero_pd();\n\n    for (size_t i = 0; i < output_size; ++i) {\n        for (size_t j = 0; j < output_size; ++j) {\n            __m128d sum = _mm_setzero_pd();\n            for (size_t ki = 0; ki < kernel_size; ++ki) {\n                for (size_t kj = 0; kj < kernel_size; kj += 2) {\n                    __m128d input_vec = _mm_loadu_pd(&input[(i + ki) * input_size + j + kj]);\n                    __m128d kernel_vec = _mm_loadu_pd(&kernel[ki * kernel_size + kj]);\n                    sum = _mm_add_pd(sum, _mm_mul_pd(input_vec, kernel_vec));\n                }\n            }\n            // Horizontal add to get the sum of the two elements in the sum vector\n            double sum_array[2];\n            _mm_storeu_pd(sum_array, sum);\n            double result = sum_array[0] + sum_array[1];\n            // Apply ReLU activation\n            result = result > 0 ? result : 0;\n            output[i * output_size + j] = result;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_61_SSE", "completion": "```cpp\nvoid simple_conv2d_simd(const double* input, const double* kernel, double * output, size_t input_size, size_t kernel_size) {\n    size_t output_size = input_size - kernel_size + 1;\n    __m128d zero = _mm_setzero_pd();\n\n    for (size_t i = 0; i < output_size; ++i) {\n        for (size_t j = 0; j < output_size; ++j) {\n            __m128d sum = _mm_setzero_pd();\n            for (size_t ki = 0; ki < kernel_size; ++ki) {\n                for (size_t kj = 0; kj < kernel_size; kj += 2) {\n                    __m128d input_vec = _mm_loadu_pd(&input[(i + ki) * input_size + j + kj]);\n                    __m128d kernel_vec = _mm_loadu_pd(&kernel[ki * kernel_size + kj]);\n                    sum = _mm_add_pd(sum, _mm_mul_pd(input_vec, kernel_vec));\n                }\n            }\n            // Handle odd kernel size case\n            if (kernel_size % 2 != 0) {\n                double last_sum = 0.0;\n                for (size_t ki = 0; ki < kernel_size; ++ki) {\n                    last_sum += input[(i + ki) * input_size + j + kernel_size - 1] * kernel[ki * kernel_size + kernel_size - 1];\n                }\n                double sums[2];\n                _mm_storeu_pd(sums, sum);\n                sums[0] += last_sum;\n                sums[1] = fmax(sums[1], 0.0);\n                output[i * output_size + j] = fmax(sums[0], 0.0);\n            } else {\n                double sums[2];\n                _mm_storeu_pd(sums, sum);\n                output[i * output_size + j] = fmax(sums[0], 0.0);\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_61_SSE", "completion": "```cpp\nvoid simple_conv2d_simd(const double* input, const double* kernel, double * output, size_t input_size, size_t kernel_size) {\n    size_t output_size = input_size - kernel_size + 1;\n    __m128d zero = _mm_setzero_pd();\n\n    for (size_t i = 0; i < output_size; ++i) {\n        for (size_t j = 0; j < output_size; ++j) {\n            __m128d sum = _mm_setzero_pd();\n            for (size_t ki = 0; ki < kernel_size; ++ki) {\n                for (size_t kj = 0; kj < kernel_size; kj += 2) {\n                    __m128d input_vec = _mm_loadu_pd(&input[(i + ki) * input_size + j + kj]);\n                    __m128d kernel_vec = _mm_loadu_pd(&kernel[ki * kernel_size + kj]);\n                    sum = _mm_add_pd(sum, _mm_mul_pd(input_vec, kernel_vec));\n                }\n            }\n            // Handle odd kernel size case\n            if (kernel_size % 2 != 0) {\n                double last_sum = 0.0;\n                for (size_t ki = 0; ki < kernel_size; ++ki) {\n                    last_sum += input[(i + ki) * input_size + j + kernel_size - 1] * kernel[ki * kernel_size + kernel_size - 1];\n                }\n                double sums[2];\n                _mm_storeu_pd(sums, sum);\n                sums[0] += last_sum;\n                sums[1] = 0.0; // Ensure second element is zero for ReLU\n                sum = _mm_loadu_pd(sums);\n            }\n            // Apply ReLU activation\n            sum = _mm_max_pd(sum, zero);\n            _mm_storeu_pd(output + i * output_size + j, sum);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_61_SSE", "completion": "```cpp\nvoid simple_conv2d_simd(const double* input, const double* kernel, double * output, size_t input_size, size_t kernel_size) {\n    size_t output_size = input_size - kernel_size + 1;\n    __m128d zero = _mm_setzero_pd();\n\n    for (size_t i = 0; i < output_size; ++i) {\n        for (size_t j = 0; j < output_size; ++j) {\n            __m128d sum = _mm_setzero_pd();\n            for (size_t ki = 0; ki < kernel_size; ++ki) {\n                for (size_t kj = 0; kj < kernel_size; kj += 2) {\n                    __m128d input_vec = _mm_loadu_pd(&input[(i + ki) * input_size + j + kj]);\n                    __m128d kernel_vec = _mm_loadu_pd(&kernel[ki * kernel_size + kj]);\n                    sum = _mm_add_pd(sum, _mm_mul_pd(input_vec, kernel_vec));\n                }\n            }\n            // Handle odd kernel size case\n            if (kernel_size % 2 != 0) {\n                double last_sum = 0.0;\n                for (size_t ki = 0; ki < kernel_size; ++ki) {\n                    last_sum += input[(i + ki) * input_size + j + kernel_size - 1] * kernel[ki * kernel_size + kernel_size - 1];\n                }\n                sum = _mm_add_sd(sum, _mm_set_sd(last_sum));\n            }\n            // Apply ReLU activation\n            sum = _mm_max_pd(sum, zero);\n            _mm_storeu_pd(&output[i * output_size + j], sum);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_62_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nbool has_close_elements_simd(const std::vector<double> & numbers, double threshold){\n    int n = numbers.size();\n    if (n < 2) return false;\n\n    __m128d thresh = _mm_set1_pd(threshold);\n\n    for (int i = 0; i < n - 1; i += 2) {\n        __m128d a = _mm_loadu_pd(&numbers[i]);\n        for (int j = i + 2; j < n - 1; j += 2) {\n            __m128d b = _mm_loadu_pd(&numbers[j]);\n            __m128d diff1 = _mm_sub_pd(a, b);\n            __m128d abs_diff1 = _mm_andnot_pd(_mm_set1_pd(-0.0), diff1);\n            if (_mm_movemask_epi8(_mm_cmplt_pd(abs_diff1, thresh))) {\n                return true;\n            }\n            __m128d b_next = _mm_loadu_pd(&numbers[j + 1]);\n            __m128d diff2 = _mm_sub_pd(a, b_next);\n            __m128d abs_diff2 = _mm_andnot_pd(_mm_set1_pd(-0.0), diff2);\n            if (_mm_movemask_epi8(_mm_cmplt_pd(abs_diff2, thresh))) {\n                return true;\n            }\n        }\n        if (n % 2 == 0 || i + 2 != n - 1) continue;\n        __m128d last = _mm_set_sd(numbers[n - 1]);\n        __m128d diff = _mm_sub_pd(a, last);\n        __m128d abs_diff = _mm_andnot_pd(_mm_set1_pd(-0.0), diff);\n        if (_mm_movemask_epi8(_mm_cmplt_pd(abs_diff, thresh))) {\n            return true;\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_62_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nbool has_close_elements_simd(const std::vector<double> & numbers, double threshold){\n    int n = numbers.size();\n    if (n < 2) return false;\n\n    __m128d thresh = _mm_set1_pd(threshold);\n\n    for (int i = 0; i < n - 2; i += 2) {\n        __m128d a = _mm_loadu_pd(&numbers[i]);\n        __m128d b = _mm_loadu_pd(&numbers[i + 1]);\n\n        for (int j = i + 2; j < n - 2; j += 2) {\n            __m128d c = _mm_loadu_pd(&numbers[j]);\n            __m128d d = _mm_loadu_pd(&numbers[j + 1]);\n\n            __m128d diff1 = _mm_sub_pd(a, c);\n            __m128d diff2 = _mm_sub_pd(a, d);\n            __m128d diff3 = _mm_sub_pd(b, c);\n            __m128d diff4 = _mm_sub_pd(b, d);\n\n            __m128d abs_diff1 = _mm_andnot_pd(_mm_set1_pd(-0.0), diff1);\n            __m128d abs_diff2 = _mm_andnot_pd(_mm_set1_pd(-0.0), diff2);\n            __m128d abs_diff3 = _mm_andnot_pd(_mm_set1_pd(-0.0), diff3);\n            __m128d abs_diff4 = _mm_andnot_pd(_mm_set1_pd(-0.0), diff4);\n\n            __m128d cmp1 = _mm_cmplt_pd(abs_diff1, thresh);\n            __m128d cmp2 = _mm_cmplt_pd(abs_diff2, thresh);\n            __m128d cmp3 = _mm_cmplt_pd(abs_diff3, thresh);\n            __m128d cmp4 = _mm_cmplt_pd(abs_diff4, thresh);\n\n            if (_mm_movemask_pd(cmp1) || _mm_movemask_pd(cmp2) || _mm_movemask_pd(cmp3) || _mm_movemask_pd(cmp4)) {\n                return true;\n            }\n        }\n\n        if (n % 2 != 0 && i + 2 == n - 2) {\n            __m128d c = _mm_loadu_pd(&numbers[n - 2]);\n            __m128d last = _mm_set_sd(numbers[n - 1]);\n\n            __m128d diff1 = _mm_sub_pd(a, c);\n            __m128d diff2 = _mm_sub_pd(a, last);\n            __m128d diff3 = _mm_sub_pd(b, c);\n            __m128d diff4 = _mm_sub_pd(b, last);\n\n            __m128d abs_diff1 = _mm_andnot_pd(_mm_set1_pd(-0.0), diff1);\n            __m128d abs_diff2 = _mm_andnot_pd(_mm_set1_pd(-0.0), diff2);\n            __m128d abs_diff3 = _mm_andnot_pd(_mm_set1_pd(-0.0), diff3);\n            __m128d abs_diff4 = _mm_andnot_pd(_mm_set1_pd(-0.0), diff4);\n\n            __m128d cmp1 = _mm_cmplt_pd(abs_diff1, thresh);\n            __m128d cmp2 = _mm_cmplt_pd(abs_diff2, thresh);\n            __m128d cmp3 = _mm_cmplt_pd(abs_diff3, thresh);\n            __m128d cmp4 = _mm_cmplt_pd(abs_diff4, thresh);\n\n            if (_mm_movemask_pd(cmp1) || _mm_movemask_pd(cmp2) || _mm_movemask_pd(cmp3) || _mm_movemask_pd(cmp4)) {\n                return true;\n            }\n        }\n    }\n\n    if (n % 2 != 0) {\n        for (int i = 0; i < n - 1; ++i) {\n            double diff = std::abs(numbers[i] - numbers[n - 1]);\n            if (diff < threshold) {\n                return true;\n            }\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_62_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nbool has_close_elements_simd(const std::vector<double> & numbers, double threshold){\n    int n = numbers.size();\n    if (n < 2) return false;\n\n    __m128d thresh = _mm_set1_pd(threshold);\n\n    for (int i = 0; i < n - 1; i += 2) {\n        __m128d a = _mm_loadu_pd(&numbers[i]);\n        for (int j = i + 2; j < n - 1; j += 2) {\n            __m128d b = _mm_loadu_pd(&numbers[j]);\n            __m128d diff1 = _mm_sub_pd(a, b);\n            __m128d abs_diff1 = _mm_andnot_pd(_mm_set1_pd(-0.0), diff1);\n            if (_mm_movemask_epi8(_mm_cmplt_pd(abs_diff1, thresh))) {\n                return true;\n            }\n            __m128d b_next = _mm_loadu_pd(&numbers[j + 1]);\n            __m128d diff2 = _mm_sub_pd(a, b_next);\n            __m128d abs_diff2 = _mm_andnot_pd(_mm_set1_pd(-0.0), diff2);\n            if (_mm_movemask_epi8(_mm_cmplt_pd(abs_diff2, thresh))) {\n                return true;\n            }\n        }\n        if (n % 2 != 0 && i + 2 == n - 1) {\n            double last_diff = std::abs(numbers[i] - numbers[n - 1]);\n            if (last_diff < threshold) {\n                return true;\n            }\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_62_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nbool has_close_elements_simd(const std::vector<double> & numbers, double threshold){\n    int n = numbers.size();\n    if (n < 2) return false;\n\n    __m128d thresh = _mm_set1_pd(threshold);\n\n    for (int i = 0; i < n - 1; i += 2) {\n        __m128d a = _mm_loadu_pd(&numbers[i]);\n        for (int j = i + 2; j < n - 1; j += 2) {\n            __m128d b = _mm_loadu_pd(&numbers[j]);\n            __m128d diff1 = _mm_sub_pd(a, b);\n            __m128d abs_diff1 = _mm_andnot_pd(_mm_set1_pd(-0.0), diff1);\n            __m128d cmp1 = _mm_cmplt_pd(abs_diff1, thresh);\n\n            __m128d b_next = _mm_loadu_pd(&numbers[j + 1]);\n            __m128d diff2 = _mm_sub_pd(a, b_next);\n            __m128d abs_diff2 = _mm_andnot_pd(_mm_set1_pd(-0.0), diff2);\n            __m128d cmp2 = _mm_cmplt_pd(abs_diff2, thresh);\n\n            if (_mm_movemask_pd(cmp1) || _mm_movemask_pd(cmp2)) {\n                return true;\n            }\n        }\n        if (n % 2 == 1 && i + 2 == n - 1) {\n            double last_diff = std::abs(numbers[i] - numbers[n - 1]);\n            if (last_diff < threshold) {\n                return true;\n            }\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_62_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nbool has_close_elements_simd(const std::vector<double> & numbers, double threshold){\n    int n = numbers.size();\n    if (n < 2) return false;\n\n    __m128d thresh = _mm_set1_pd(threshold);\n\n    for (int i = 0; i < n - 2; i += 2) {\n        __m128d a = _mm_loadu_pd(&numbers[i]);\n        for (int j = i + 2; j < n - 2; j += 2) {\n            __m128d b = _mm_loadu_pd(&numbers[j]);\n            __m128d diff1 = _mm_sub_pd(a, b);\n            __m128d abs_diff1 = _mm_andnot_pd(_mm_set1_pd(-0.0), diff1);\n            __m128d cmp1 = _mm_cmplt_pd(abs_diff1, thresh);\n            if (!_mm_movemask_pd(cmp1) == 0) return true;\n\n            __m128d b_next = _mm_loadu_pd(&numbers[j + 1]);\n            __m128d diff2 = _mm_sub_pd(a, b_next);\n            __m128d abs_diff2 = _mm_andnot_pd(_mm_set1_pd(-0.0), diff2);\n            __m128d cmp2 = _mm_cmplt_pd(abs_diff2, thresh);\n            if (!_mm_movemask_pd(cmp2) == 0) return true;\n        }\n        if (n % 2 != 0 && i + 2 < n - 1) {\n            __m128d b_last = _mm_load_sd(&numbers[n - 1]);\n            b_last = _mm_loadh_pd(b_last, _mm_load_sd(&numbers[n - 2]));\n            __m128d diff = _mm_sub_pd(a, b_last);\n            __m128d abs_diff = _mm_andnot_pd(_mm_set1_pd(-0.0), diff);\n            __m128d cmp = _mm_cmplt_pd(abs_diff, thresh);\n            if (!_mm_movemask_pd(cmp) == 0) return true;\n        }\n    }\n\n    if (n % 2 != 0) {\n        for (int i = 0; i < n - 1; ++i) {\n            double diff = std::abs(numbers[i] - numbers[n - 1]);\n            if (diff < threshold) return true;\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_63_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nbool below_zero_simd(std::vector<int> operations) {\n    __m128i balance = _mm_setzero_si128();\n    __m128i zero = _mm_setzero_si128();\n    int n = operations.size();\n    int i = 0;\n\n    for (; i <= n - 4; i += 4) {\n        __m128i ops = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&operations[i]));\n        balance = _mm_add_epi32(balance, ops);\n        __m128i mask = _mm_cmplt_epi32(balance, zero);\n        if (_mm_movemask_epi8(mask) != 0) {\n            return true;\n        }\n    }\n\n    int remaining_balance[4];\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(remaining_balance), balance);\n\n    for (; i < n; ++i) {\n        remaining_balance[i % 4] += operations[i];\n        if (remaining_balance[i % 4] < 0) {\n            return true;\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_63_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nbool below_zero_simd(std::vector<int> operations) {\n    __m128i balance = _mm_setzero_si128();\n    __m128i zero = _mm_setzero_si128();\n    int n = operations.size();\n    int i = 0;\n\n    for (; i <= n - 4; i += 4) {\n        __m128i ops = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&operations[i]));\n        balance = _mm_add_epi32(balance, ops);\n        __m128i mask = _mm_cmplt_epi32(balance, zero);\n        if (_mm_movemask_epi8(mask) != 0) {\n            return true;\n        }\n    }\n\n    int remaining_balance[4];\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(remaining_balance), balance);\n\n    for (; i < n; ++i) {\n        remaining_balance[i % 4] += operations[i];\n        if (remaining_balance[i % 4] < 0) {\n            return true;\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_63_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nbool below_zero_simd(std::vector<int> operations) {\n    __m128i balance = _mm_setzero_si128();\n    __m128i zero = _mm_setzero_si128();\n    int n = operations.size();\n    int i = 0;\n\n    for (; i <= n - 4; i += 4) {\n        __m128i ops = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&operations[i]));\n        balance = _mm_add_epi32(balance, ops);\n        __m128i mask = _mm_cmplt_epi32(balance, zero);\n        if (_mm_movemask_epi8(mask) != 0) {\n            return true;\n        }\n    }\n\n    int remaining_balance[4];\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(remaining_balance), balance);\n\n    for (; i < n; ++i) {\n        remaining_balance[i % 4] += operations[i];\n        if (remaining_balance[i % 4] < 0) {\n            return true;\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_63_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nbool below_zero_simd(std::vector<int> operations) {\n    __m128i balance = _mm_setzero_si128();\n    __m128i zero = _mm_setzero_si128();\n    int n = operations.size();\n    int i = 0;\n\n    for (; i <= n - 4; i += 4) {\n        __m128i ops = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&operations[i]));\n        balance = _mm_add_epi32(balance, ops);\n        __m128i mask = _mm_cmplt_epi32(balance, zero);\n        if (_mm_movemask_epi8(mask) != 0) {\n            return true;\n        }\n    }\n\n    int remaining_balance[4];\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(remaining_balance), balance);\n\n    for (; i < n; ++i) {\n        remaining_balance[i % 4] += operations[i];\n        if (remaining_balance[i % 4] < 0) {\n            return true;\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_63_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nbool below_zero_simd(std::vector<int> operations) {\n    int balance = 0;\n    int n = operations.size();\n    int i = 0;\n\n    __m128i balance_vec = _mm_setzero_si128();\n    __m128i zero_vec = _mm_setzero_si128();\n\n    for (; i <= n - 4; i += 4) {\n        __m128i ops_vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&operations[i]));\n        balance_vec = _mm_add_epi32(balance_vec, ops_vec);\n        __m128i mask = _mm_cmplt_epi32(balance_vec, zero_vec);\n        if (_mm_movemask_epi8(mask) != 0) {\n            return true;\n        }\n    }\n\n    for (; i < n; ++i) {\n        balance += operations[i];\n        if (balance < 0) {\n            return true;\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_64_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\ndouble mean_absolute_deviation_simd(std::vector<double> numbers){\n    int n = numbers.size();\n    if (n == 0) return 0.0;\n\n    __m128d sum = _mm_setzero_pd();\n    __m128d mean = _mm_setzero_pd();\n\n    // Calculate sum of all elements\n    for (int i = 0; i <= n - 4; i += 4) {\n        __m128d num = _mm_loadu_pd(&numbers[i]);\n        sum = _mm_add_pd(sum, num);\n    }\n\n    // Handle remaining elements\n    double temp_sum[2] = {0.0, 0.0};\n    _mm_storeu_pd(temp_sum, sum);\n    for (int i = (n & ~3); i < n; ++i) {\n        temp_sum[0] += numbers[i];\n    }\n    double total_sum = temp_sum[0] + temp_sum[1];\n\n    // Calculate mean\n    double mean_value = total_sum / n;\n    mean = _mm_set1_pd(mean_value);\n\n    __m128d mad_sum = _mm_setzero_pd();\n\n    // Calculate sum of absolute deviations\n    for (int i = 0; i <= n - 4; i += 4) {\n        __m128d num = _mm_loadu_pd(&numbers[i]);\n        __m128d diff = _mm_sub_pd(num, mean);\n        __m128d abs_diff = _mm_andnot_pd(_mm_set1_pd(-0.0), diff);\n        mad_sum = _mm_add_pd(mad_sum, abs_diff);\n    }\n\n    // Handle remaining elements\n    double temp_mad[2] = {0.0, 0.0};\n    _mm_storeu_pd(temp_mad, mad_sum);\n    for (int i = (n & ~3); i < n; ++i) {\n        temp_mad[0] += std::abs(numbers[i] - mean_value);\n    }\n    double total_mad = temp_mad[0] + temp_mad[1];\n\n    // Calculate mean absolute deviation\n    return total_mad / n;\n}\n```"}
{"task_id": "SimdBench_64_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\ndouble mean_absolute_deviation_simd(std::vector<double> numbers){\n    int n = numbers.size();\n    if (n == 0) return 0.0;\n\n    __m128d sum = _mm_setzero_pd();\n    __m128d mean;\n    double* data = numbers.data();\n\n    // Calculate sum of all elements\n    for (int i = 0; i <= n - 4; i += 4) {\n        __m128d v = _mm_loadu_pd(&data[i]);\n        sum = _mm_add_pd(sum, v);\n    }\n\n    // Handle remaining elements\n    for (int i = (n & ~3); i < n; ++i) {\n        sum = _mm_add_sd(sum, _mm_set_sd(data[i]));\n    }\n\n    // Horizontal add to get the total sum\n    double total_sum[2];\n    _mm_storeu_pd(total_sum, sum);\n    double sum_scalar = total_sum[0] + total_sum[1];\n\n    // Calculate mean\n    double mean_scalar = sum_scalar / n;\n    mean = _mm_set1_pd(mean_scalar);\n\n    __m128d abs_diff_sum = _mm_setzero_pd();\n\n    // Calculate sum of absolute differences\n    for (int i = 0; i <= n - 4; i += 4) {\n        __m128d v = _mm_loadu_pd(&data[i]);\n        __m128d diff = _mm_sub_pd(v, mean);\n        __m128d abs_diff = _mm_andnot_pd(_mm_set1_pd(-0.0), diff); // Absolute value\n        abs_diff_sum = _mm_add_pd(abs_diff_sum, abs_diff);\n    }\n\n    // Handle remaining elements\n    for (int i = (n & ~3); i < n; ++i) {\n        double diff = data[i] - mean_scalar;\n        double abs_diff = diff < 0 ? -diff : diff;\n        abs_diff_sum = _mm_add_sd(abs_diff_sum, _mm_set_sd(abs_diff));\n    }\n\n    // Horizontal add to get the total absolute difference sum\n    double abs_diff_total[2];\n    _mm_storeu_pd(abs_diff_total, abs_diff_sum);\n    double abs_diff_sum_scalar = abs_diff_total[0] + abs_diff_total[1];\n\n    // Calculate mean absolute deviation\n    return abs_diff_sum_scalar / n;\n}\n```"}
{"task_id": "SimdBench_64_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\ndouble mean_absolute_deviation_simd(std::vector<double> numbers){\n    int n = numbers.size();\n    if (n == 0) return 0.0;\n\n    __m128d sum = _mm_setzero_pd();\n    __m128d mean = _mm_setzero_pd();\n\n    // Calculate sum of all elements\n    for (int i = 0; i <= n - 4; i += 4) {\n        __m128d num = _mm_loadu_pd(&numbers[i]);\n        sum = _mm_add_pd(sum, num);\n    }\n\n    // Handle remaining elements\n    double temp_sum[2] = {0.0, 0.0};\n    _mm_storeu_pd(temp_sum, sum);\n    for (int i = (n & ~3); i < n; ++i) {\n        temp_sum[0] += numbers[i];\n    }\n    double total_sum = temp_sum[0] + temp_sum[1];\n    double mean_value = total_sum / n;\n    mean = _mm_set1_pd(mean_value);\n\n    __m128d mad_sum = _mm_setzero_pd();\n\n    // Calculate sum of absolute differences\n    for (int i = 0; i <= n - 4; i += 4) {\n        __m128d num = _mm_loadu_pd(&numbers[i]);\n        __m128d diff = _mm_sub_pd(num, mean);\n        __m128d abs_diff = _mm_andnot_pd(_mm_set1_pd(-0.0), diff);\n        mad_sum = _mm_add_pd(mad_sum, abs_diff);\n    }\n\n    // Handle remaining elements\n    double temp_mad[2] = {0.0, 0.0};\n    _mm_storeu_pd(temp_mad, mad_sum);\n    for (int i = (n & ~3); i < n; ++i) {\n        temp_mad[0] += std::abs(numbers[i] - mean_value);\n    }\n    double total_mad = temp_mad[0] + temp_mad[1];\n\n    return total_mad / n;\n}\n```"}
{"task_id": "SimdBench_64_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\ndouble mean_absolute_deviation_simd(std::vector<double> numbers){\n    int n = numbers.size();\n    if (n == 0) return 0.0;\n\n    __m128d sum = _mm_setzero_pd();\n    __m128d mean;\n    double* data = numbers.data();\n\n    // Calculate sum of all elements\n    for (int i = 0; i <= n - 4; i += 4) {\n        __m128d v = _mm_loadu_pd(&data[i]);\n        sum = _mm_add_pd(sum, v);\n    }\n\n    // Handle remaining elements\n    for (int i = (n & ~3); i < n; ++i) {\n        sum = _mm_add_sd(sum, _mm_set_sd(data[i]));\n    }\n\n    // Horizontal add to get the total sum\n    double total_sum[2];\n    _mm_storeu_pd(total_sum, sum);\n    double sum_scalar = total_sum[0] + total_sum[1];\n\n    // Calculate mean\n    double mean_scalar = sum_scalar / n;\n    mean = _mm_set1_pd(mean_scalar);\n\n    __m128d abs_diff_sum = _mm_setzero_pd();\n\n    // Calculate sum of absolute differences\n    for (int i = 0; i <= n - 4; i += 4) {\n        __m128d v = _mm_loadu_pd(&data[i]);\n        __m128d diff = _mm_sub_pd(v, mean);\n        __m128d abs_diff = _mm_andnot_pd(_mm_set1_pd(-0.0), diff); // Absolute value\n        abs_diff_sum = _mm_add_pd(abs_diff_sum, abs_diff);\n    }\n\n    // Handle remaining elements\n    for (int i = (n & ~3); i < n; ++i) {\n        double diff = data[i] - mean_scalar;\n        double abs_diff = diff < 0 ? -diff : diff;\n        abs_diff_sum = _mm_add_sd(abs_diff_sum, _mm_set_sd(abs_diff));\n    }\n\n    // Horizontal add to get the total absolute difference sum\n    double abs_diff_total[2];\n    _mm_storeu_pd(abs_diff_total, abs_diff_sum);\n    double abs_diff_sum_scalar = abs_diff_total[0] + abs_diff_total[1];\n\n    // Calculate mean absolute deviation\n    return abs_diff_sum_scalar / n;\n}\n```"}
{"task_id": "SimdBench_64_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\ndouble mean_absolute_deviation_simd(std::vector<double> numbers){\n    int n = numbers.size();\n    if (n == 0) return 0.0;\n\n    __m128d sum = _mm_setzero_pd();\n    __m128d mean = _mm_setzero_pd();\n\n    // Calculate sum of all elements\n    for (int i = 0; i <= n - 4; i += 4) {\n        __m128d num = _mm_loadu_pd(&numbers[i]);\n        sum = _mm_add_pd(sum, num);\n    }\n\n    // Handle remaining elements\n    for (int i = (n & ~3); i < n; ++i) {\n        sum = _mm_add_sd(sum, _mm_set_sd(numbers[i]));\n    }\n\n    // Calculate mean\n    double sum_array[2];\n    _mm_storeu_pd(sum_array, sum);\n    double total_sum = sum_array[0] + sum_array[1];\n    mean = _mm_set1_pd(total_sum / n);\n\n    __m128d mad_sum = _mm_setzero_pd();\n\n    // Calculate sum of absolute deviations\n    for (int i = 0; i <= n - 4; i += 4) {\n        __m128d num = _mm_loadu_pd(&numbers[i]);\n        __m128d diff = _mm_sub_pd(num, mean);\n        __m128d abs_diff = _mm_andnot_pd(_mm_set1_pd(-0.0), diff);\n        mad_sum = _mm_add_pd(mad_sum, abs_diff);\n    }\n\n    // Handle remaining elements\n    for (int i = (n & ~3); i < n; ++i) {\n        double diff = numbers[i] - (total_sum / n);\n        double abs_diff = diff < 0 ? -diff : diff;\n        mad_sum = _mm_add_sd(mad_sum, _mm_set_sd(abs_diff));\n    }\n\n    // Calculate mean absolute deviation\n    _mm_storeu_pd(sum_array, mad_sum);\n    double mad_total = sum_array[0] + sum_array[1];\n    return mad_total / n;\n}\n```"}
{"task_id": "SimdBench_65_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> intersperse_simd(std::vector<int> numbers, int delimeter){ \n    std::vector<int> result;\n    if (numbers.empty()) return result;\n\n    int n = numbers.size();\n    result.resize(n * 2 - 1);\n\n    __m128i delimiter_vec = _mm_set1_epi32(delimeter);\n\n    for (int i = 0; i < n; i += 4) {\n        __m128i num_vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&numbers[i]));\n        \n        // Shift numbers to make space for delimiters\n        __m128i shifted_num_vec = _mm_srli_si128(num_vec, 4);\n        shifted_num_vec = _mm_insert_epi32(shifted_num_vec, _mm_extract_epi32(num_vec, 3), 0);\n\n        // Interleave delimiters and numbers\n        __m128i interleave1 = _mm_unpacklo_epi32(num_vec, delimiter_vec);\n        __m128i interleave2 = _mm_unpackhi_epi32(shifted_num_vec, delimiter_vec);\n\n        // Store the first 8 results\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i * 2]), interleave1);\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i * 2 + 6]), interleave2);\n    }\n\n    // Handle the last few elements if the size is not a multiple of 4\n    for (int i = (n / 4) * 4; i < n - 1; ++i) {\n        result[i * 2] = numbers[i];\n        result[i * 2 + 1] = delimeter;\n    }\n    result[(n - 1) * 2] = numbers[n - 1];\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_65_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> intersperse_simd(std::vector<int> numbers, int delimeter){ \n    std::vector<int> result;\n    if (numbers.empty()) return result;\n\n    int n = numbers.size();\n    result.resize(n * 2 - 1);\n\n    __m128i delimiter_vec = _mm_set1_epi32(delimeter);\n\n    for (int i = 0; i < n; i += 4) {\n        __m128i num_vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&numbers[i]));\n        __m128i shuffled = _mm_shuffle_epi32(num_vec, _MM_SHUFFLE(3, 3, 2, 1));\n        __m128i interleaved1 = _mm_unpacklo_epi32(num_vec, delimiter_vec);\n        __m128i interleaved2 = _mm_unpackhi_epi32(shuffled, delimiter_vec);\n\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i * 2]), interleaved1);\n        if (i + 4 < n) {\n            _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i * 2 + 6]), interleaved2);\n        } else {\n            // Handle the last element(s) if the size is not a multiple of 4\n            for (int j = 0; j < n % 4; ++j) {\n                result[i * 2 + j * 2 + 1] = delimeter;\n                if (i + j + 1 < n) {\n                    result[i * 2 + j * 2 + 2] = numbers[i + j + 1];\n                }\n            }\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_65_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> intersperse_simd(std::vector<int> numbers, int delimeter){ \n    std::vector<int> result;\n    if (numbers.empty()) return result;\n\n    int n = numbers.size();\n    result.resize(n * 2 - 1);\n\n    __m128i delimiter_vec = _mm_set1_epi32(delimeter);\n\n    for (int i = 0; i < n; i += 4) {\n        __m128i num_vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&numbers[i]));\n        __m128i shuffled = _mm_shuffle_epi32(num_vec, _MM_SHUFFLE(3, 0, 2, 1));\n        __m128i interlaced1 = _mm_unpacklo_epi32(num_vec, delimiter_vec);\n        __m128i interlaced2 = _mm_unpackhi_epi32(shuffled, delimiter_vec);\n\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i * 2]), interlaced1);\n        if (i + 4 < n) {\n            _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i * 2 + 6]), interlaced2);\n        } else {\n            // Handle the last elements if the size is not a multiple of 4\n            for (int j = 0; j < n - i; ++j) {\n                result[i * 2 + j * 2] = numbers[i + j];\n                if (i + j + 1 < n) {\n                    result[i * 2 + j * 2 + 1] = delimeter;\n                }\n            }\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_65_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> intersperse_simd(std::vector<int> numbers, int delimeter){ \n    std::vector<int> result;\n    if (numbers.empty()) return result;\n\n    int n = numbers.size();\n    result.resize(n * 2 - 1);\n\n    __m128i delimiter_vec = _mm_set1_epi32(delimeter);\n\n    for (int i = 0; i < n; i += 4) {\n        __m128i num_vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&numbers[i]));\n        __m128i shuffled = _mm_shuffle_epi32(num_vec, _MM_SHUFFLE(3, 3, 2, 1));\n        __m128i interleaved1 = _mm_unpacklo_epi32(num_vec, delimiter_vec);\n        __m128i interleaved2 = _mm_unpackhi_epi32(shuffled, delimiter_vec);\n\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i * 2]), interleaved1);\n        if (i + 2 < n) {\n            _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i * 2 + 4]), interleaved2);\n        } else {\n            _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i * 2 + 4]), _mm_and_si128(interleaved2, _mm_setr_epi32(-1, -1, (i + 3 < n) ? -1 : 0, 0)));\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_65_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> intersperse_simd(std::vector<int> numbers, int delimeter){ \n    std::vector<int> result;\n    if (numbers.empty()) return result;\n\n    int n = numbers.size();\n    result.resize(n * 2 - 1);\n\n    __m128i delimiter_vec = _mm_set1_epi32(delimeter);\n\n    for (int i = 0; i < n; i += 4) {\n        __m128i num_vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&numbers[i]));\n        __m128i shuffled = _mm_shuffle_epi32(num_vec, _MM_SHUFFLE(3, 3, 2, 1));\n        __m128i interleaved1 = _mm_unpacklo_epi32(num_vec, delimiter_vec);\n        __m128i interleaved2 = _mm_unpackhi_epi32(shuffled, delimiter_vec);\n\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i * 2]), interleaved1);\n        if (i + 4 < n) {\n            _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i * 2 + 6]), interleaved2);\n        } else {\n            // Handle the last elements if the size is not a multiple of 4\n            for (int j = 0; j < n % 4; ++j) {\n                result[i * 2 + j * 2 + 1] = delimeter;\n                if (i + j + 1 < n) {\n                    result[i * 2 + j * 2 + 2] = numbers[i + j + 1];\n                }\n            }\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_66_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int64_t> sum_product_simd(std::vector<int16_t> numbers) {\n    if (numbers.empty()) {\n        return {0, 1};\n    }\n\n    __m128i sum = _mm_setzero_si128();\n    __m128i prod = _mm_set1_epi16(1);\n\n    size_t i = 0;\n    for (; i + 8 <= numbers.size(); i += 8) {\n        __m128i num = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&numbers[i]));\n        sum = _mm_add_epi16(sum, num);\n        prod = _mm_mullo_epi16(prod, num);\n    }\n\n    int16_t sum_array[8];\n    int16_t prod_array[8];\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(sum_array), sum);\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(prod_array), prod);\n\n    int32_t total_sum = 0;\n    int32_t total_prod = 1;\n    for (size_t j = 0; j < 8; ++j) {\n        total_sum += sum_array[j];\n        total_prod *= prod_array[j];\n    }\n\n    for (; i < numbers.size(); ++i) {\n        total_sum += numbers[i];\n        total_prod *= numbers[i];\n    }\n\n    return {total_sum, total_prod};\n}\n```"}
{"task_id": "SimdBench_66_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int64_t> sum_product_simd(std::vector<int16_t> numbers){\n    __m128i sum = _mm_setzero_si128();\n    __m128i prod = _mm_set1_epi16(1);\n\n    size_t i = 0;\n    for (; i + 7 < numbers.size(); i += 8) {\n        __m128i num = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&numbers[i]));\n        sum = _mm_add_epi16(sum, num);\n        prod = _mm_mullo_epi16(prod, num);\n    }\n\n    int16_t sum_arr[8], prod_arr[8];\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(sum_arr), sum);\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(prod_arr), prod);\n\n    int64_t total_sum = 0;\n    int64_t total_prod = 1;\n    for (size_t j = 0; j < 8; ++j) {\n        total_sum += sum_arr[j];\n        total_prod *= prod_arr[j];\n    }\n\n    for (; i < numbers.size(); ++i) {\n        total_sum += numbers[i];\n        total_prod *= numbers[i];\n    }\n\n    return {total_sum, total_prod};\n}\n```"}
{"task_id": "SimdBench_66_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int64_t> sum_product_simd(std::vector<int16_t> numbers){\n    __m128i sum = _mm_setzero_si128();\n    __m128i prod = _mm_set1_epi16(1);\n    \n    size_t i = 0;\n    for (; i + 7 < numbers.size(); i += 8) {\n        __m128i num = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&numbers[i]));\n        sum = _mm_add_epi16(sum, num);\n        prod = _mm_mullo_epi16(prod, num);\n    }\n    \n    int16_t sum_arr[8], prod_arr[8];\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(sum_arr), sum);\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(prod_arr), prod);\n    \n    int64_t total_sum = 0;\n    int64_t total_prod = 1;\n    for (size_t j = 0; j < 8; ++j) {\n        total_sum += sum_arr[j];\n        total_prod *= prod_arr[j];\n    }\n    \n    for (; i < numbers.size(); ++i) {\n        total_sum += numbers[i];\n        total_prod *= numbers[i];\n    }\n    \n    return {total_sum, total_prod};\n}\n```"}
{"task_id": "SimdBench_66_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int64_t> sum_product_simd(std::vector<int16_t> numbers) {\n    if (numbers.empty()) {\n        return {0, 1};\n    }\n\n    __m128i sum = _mm_setzero_si128();\n    __m128i product = _mm_set1_epi16(1);\n\n    size_t i = 0;\n    for (; i + 7 < numbers.size(); i += 8) {\n        __m128i num = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&numbers[i]));\n        sum = _mm_add_epi16(sum, num);\n        product = _mm_mullo_epi16(product, num);\n    }\n\n    int16_t sum_array[8];\n    int16_t product_array[8];\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(sum_array), sum);\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(product_array), product);\n\n    int64_t total_sum = 0;\n    int64_t total_product = 1;\n    for (size_t j = 0; j < 8; ++j) {\n        total_sum += sum_array[j];\n        total_product *= product_array[j];\n    }\n\n    for (; i < numbers.size(); ++i) {\n        total_sum += numbers[i];\n        total_product *= numbers[i];\n    }\n\n    return {total_sum, total_product};\n}\n```"}
{"task_id": "SimdBench_66_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int64_t> sum_product_simd(std::vector<int16_t> numbers) {\n    __m128i sum = _mm_setzero_si128();\n    __m128i prod = _mm_set1_epi16(1);\n\n    size_t i = 0;\n    for (; i + 7 < numbers.size(); i += 8) {\n        __m128i num = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&numbers[i]));\n        sum = _mm_add_epi16(sum, num);\n        prod = _mm_mullo_epi16(prod, num);\n    }\n\n    int16_t sum_arr[8], prod_arr[8];\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(sum_arr), sum);\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(prod_arr), prod);\n\n    int64_t total_sum = 0;\n    int64_t total_prod = 1;\n    for (size_t j = 0; j < 8; ++j) {\n        total_sum += sum_arr[j];\n        total_prod *= prod_arr[j];\n    }\n\n    for (; i < numbers.size(); ++i) {\n        total_sum += numbers[i];\n        total_prod *= numbers[i];\n    }\n\n    return {total_sum, total_prod};\n}\n```"}
{"task_id": "SimdBench_67_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> rolling_max_simd(std::vector<int> numbers) {\n    std::vector<int> result(numbers.size());\n    if (numbers.empty()) return result;\n\n    __m128i max_vec = _mm_set1_epi32(numbers[0]);\n    int i = 0;\n    for (; i <= static_cast<int>(numbers.size()) - 4; i += 4) {\n        __m128i current_vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&numbers[i]));\n        max_vec = _mm_max_epi32(max_vec, current_vec);\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i]), max_vec);\n    }\n\n    // Handle remaining elements\n    int current_max = _mm_extract_epi32(max_vec, 3);\n    for (; i < numbers.size(); ++i) {\n        current_max = std::max(current_max, numbers[i]);\n        result[i] = current_max;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_67_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> rolling_max_simd(std::vector<int> numbers){\n    std::vector<int> result(numbers.size());\n    if (numbers.empty()) return result;\n\n    __m128i max_vec = _mm_set1_epi32(numbers[0]);\n    int i = 0;\n    for (; i <= static_cast<int>(numbers.size()) - 4; i += 4) {\n        __m128i current_vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&numbers[i]));\n        max_vec = _mm_max_epi32(max_vec, current_vec);\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i]), max_vec);\n    }\n\n    // Handle remaining elements\n    int current_max = result[i-1];\n    for (; i < numbers.size(); ++i) {\n        current_max = std::max(current_max, numbers[i]);\n        result[i] = current_max;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_67_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> rolling_max_simd(std::vector<int> numbers) {\n    std::vector<int> result(numbers.size());\n    if (numbers.empty()) return result;\n\n    __m128i max_vec = _mm_set1_epi32(numbers[0]);\n    int i = 0;\n    for (; i <= static_cast<int>(numbers.size()) - 4; i += 4) {\n        __m128i current_vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&numbers[i]));\n        max_vec = _mm_max_epi32(max_vec, current_vec);\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i]), max_vec);\n    }\n\n    // Handle remaining elements\n    int current_max = result[i - 1];\n    for (; i < numbers.size(); ++i) {\n        current_max = std::max(current_max, numbers[i]);\n        result[i] = current_max;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_67_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> rolling_max_simd(std::vector<int> numbers){\n    std::vector<int> result(numbers.size());\n    if (numbers.empty()) return result;\n\n    __m128i max_vec = _mm_set1_epi32(numbers[0]);\n    int i = 0;\n    for (; i <= static_cast<int>(numbers.size()) - 4; i += 4) {\n        __m128i current_vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&numbers[i]));\n        max_vec = _mm_max_epi32(max_vec, current_vec);\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i]), max_vec);\n    }\n\n    // Handle remaining elements\n    int current_max = result[i - 1];\n    for (; i < numbers.size(); ++i) {\n        current_max = std::max(current_max, numbers[i]);\n        result[i] = current_max;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_67_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> rolling_max_simd(std::vector<int> numbers) {\n    std::vector<int> result(numbers.size());\n    if (numbers.empty()) return result;\n\n    __m128i max_vec = _mm_set1_epi32(numbers[0]);\n    int i = 0;\n    for (; i <= static_cast<int>(numbers.size()) - 4; i += 4) {\n        __m128i current_vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&numbers[i]));\n        max_vec = _mm_max_epi32(max_vec, current_vec);\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i]), max_vec);\n    }\n\n    // Handle remaining elements\n    int current_max = result[i - 1];\n    for (; i < numbers.size(); ++i) {\n        current_max = std::max(current_max, numbers[i]);\n        result[i] = current_max;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_68_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string string_xor_simd(std::string a, std::string b){\n    if (a.size() != b.size()) return \"\";\n    size_t len = a.size();\n    std::string result(len, '0');\n    \n    size_t i = 0;\n    for (; i <= len - 16; i += 16) {\n        __m128i vec_a = _mm_loadu_si128(reinterpret_cast<const __m128i*>(a.c_str() + i));\n        __m128i vec_b = _mm_loadu_si128(reinterpret_cast<const __m128i*>(b.c_str() + i));\n        __m128i vec_xor = _mm_xor_si128(vec_a, vec_b);\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(result.data() + i), vec_xor);\n    }\n    \n    for (; i < len; ++i) {\n        result[i] = (a[i] == b[i]) ? '0' : '1';\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_68_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string string_xor_simd(std::string a, std::string b){\n    if (a.size() != b.size()) return \"\";\n    std::string result(a.size(), '0');\n    int len = a.size();\n    int i = 0;\n    for (; i <= len - 16; i += 16) {\n        __m128i vec_a = _mm_loadu_si128(reinterpret_cast<const __m128i*>(a.c_str() + i));\n        __m128i vec_b = _mm_loadu_si128(reinterpret_cast<const __m128i*>(b.c_str() + i));\n        __m128i vec_xor = _mm_xor_si128(vec_a, vec_b);\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(result.data() + i), vec_xor);\n    }\n    for (; i < len; ++i) {\n        result[i] = (a[i] == b[i]) ? '0' : '1';\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_68_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string string_xor_simd(std::string a, std::string b){\n    if (a.size() != b.size()) return \"\";\n    size_t len = a.size();\n    std::string result(len, '0');\n    \n    size_t i = 0;\n    for (; i <= len - 16; i += 16) {\n        __m128i vec_a = _mm_loadu_si128(reinterpret_cast<const __m128i*>(a.c_str() + i));\n        __m128i vec_b = _mm_loadu_si128(reinterpret_cast<const __m128i*>(b.c_str() + i));\n        __m128i vec_xor = _mm_xor_si128(vec_a, vec_b);\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i]), vec_xor);\n    }\n    \n    for (; i < len; ++i) {\n        result[i] = (a[i] == b[i]) ? '0' : '1';\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_68_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string string_xor_simd(std::string a, std::string b){\n    if (a.size() != b.size()) return \"\";\n    size_t len = a.size();\n    std::string result(len, '0');\n    \n    size_t i = 0;\n    for (; i <= len - 16; i += 16) {\n        __m128i vec_a = _mm_loadu_si128(reinterpret_cast<const __m128i*>(a.c_str() + i));\n        __m128i vec_b = _mm_loadu_si128(reinterpret_cast<const __m128i*>(b.c_str() + i));\n        __m128i vec_xor = _mm_xor_si128(vec_a, vec_b);\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i]), vec_xor);\n    }\n    \n    for (; i < len; ++i) {\n        result[i] = (a[i] == b[i]) ? '0' : '1';\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_68_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n#include <algorithm>\n\nstd::string string_xor_simd(std::string a, std::string b) {\n    if (a.size() != b.size()) {\n        throw std::invalid_argument(\"Strings must be of equal length\");\n    }\n\n    size_t len = a.size();\n    std::string result(len, '0');\n\n    size_t i = 0;\n    for (; i <= len - 16; i += 16) {\n        __m128i vec_a = _mm_loadu_si128(reinterpret_cast<const __m128i*>(a.c_str() + i));\n        __m128i vec_b = _mm_loadu_si128(reinterpret_cast<const __m128i*>(b.c_str() + i));\n        __m128i vec_xor = _mm_xor_si128(vec_a, vec_b);\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(result.data() + i), vec_xor);\n    }\n\n    for (; i < len; ++i) {\n        result[i] = (a[i] == b[i]) ? '0' : '1';\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_69_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n#include <algorithm>\n\nstd::string longest_simd(const std::vector<std::string> & strings){\n    if (strings.empty()) {\n        return \"\";\n    }\n\n    const int numStrings = strings.size();\n    const int simdWidth = 4; // SSE processes 4 integers at a time\n    int maxLengths[simdWidth] = {0};\n    int maxIndices[simdWidth] = {0};\n\n    __m128i maxLengthsSIMD = _mm_setzero_si128();\n    __m128i maxIndicesSIMD = _mm_setzero_si128();\n\n    for (int i = 0; i < numStrings; i += simdWidth) {\n        __m128i lengthsSIMD = _mm_set_epi32(\n            (i + 3 < numStrings) ? strings[i + 3].length() : 0,\n            (i + 2 < numStrings) ? strings[i + 2].length() : 0,\n            (i + 1 < numStrings) ? strings[i + 1].length() : 0,\n            (i + 0 < numStrings) ? strings[i + 0].length() : 0\n        );\n\n        __m128i indicesSIMD = _mm_set_epi32(i + 3, i + 2, i + 1, i + 0);\n\n        __m128i cmpGT = _mm_cmpgt_epi32(lengthsSIMD, maxLengthsSIMD);\n        maxLengthsSIMD = _mm_max_epi32(lengthsSIMD, maxLengthsSIMD);\n        maxIndicesSIMD = _mm_blendv_epi8(maxIndicesSIMD, indicesSIMD, cmpGT);\n    }\n\n    _mm_storeu_si128((__m128i*)maxLengths, maxLengthsSIMD);\n    _mm_storeu_si128((__m128i*)maxIndices, maxIndicesSIMD);\n\n    int globalMaxLength = *std::max_element(maxLengths, maxLengths + simdWidth);\n    int globalMaxIndex = maxIndices[std::distance(maxLengths, std::find(maxLengths, maxLengths + simdWidth, globalMaxLength))];\n\n    return strings[globalMaxIndex];\n}\n```"}
{"task_id": "SimdBench_69_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n#include <algorithm>\n\nstd::string longest_simd(const std::vector<std::string> & strings){\n    if (strings.empty()) {\n        return \"\";\n    }\n\n    const int numStrings = strings.size();\n    const int simdWidth = 4; // SSE processes 4 integers at a time\n    int maxLengths[simdWidth] = {0};\n    int maxIndices[simdWidth] = {0};\n\n    __m128i maxLengthsSIMD = _mm_setzero_si128();\n    __m128i maxIndicesSIMD = _mm_setzero_si128();\n\n    for (int i = 0; i < numStrings; i += simdWidth) {\n        __m128i lengthsSIMD = _mm_set_epi32(\n            (i + 3 < numStrings) ? strings[i + 3].size() : 0,\n            (i + 2 < numStrings) ? strings[i + 2].size() : 0,\n            (i + 1 < numStrings) ? strings[i + 1].size() : 0,\n            (i + 0 < numStrings) ? strings[i + 0].size() : 0\n        );\n\n        __m128i indicesSIMD = _mm_set_epi32(i + 3, i + 2, i + 1, i + 0);\n\n        __m128i cmpGT = _mm_cmpgt_epi32(lengthsSIMD, maxLengthsSIMD);\n        maxLengthsSIMD = _mm_max_epi32(lengthsSIMD, maxLengthsSIMD);\n        maxIndicesSIMD = _mm_blendv_epi8(maxIndicesSIMD, indicesSIMD, cmpGT);\n    }\n\n    _mm_storeu_si128((__m128i*)maxLengths, maxLengthsSIMD);\n    _mm_storeu_si128((__m128i*)maxIndices, maxIndicesSIMD);\n\n    int globalMaxLength = *std::max_element(maxLengths, maxLengths + simdWidth);\n    int globalMaxIndex = maxIndices[std::distance(maxLengths, std::find(maxLengths, maxLengths + simdWidth, globalMaxLength))];\n\n    return strings[globalMaxIndex];\n}\n```"}
{"task_id": "SimdBench_69_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n#include <algorithm>\n\nstd::string longest_simd(const std::vector<std::string> & strings){\n    if (strings.empty()) {\n        return \"\";\n    }\n\n    const int numStrings = strings.size();\n    const int simdWidth = 4; // SSE processes 4 integers at a time\n    int maxLengths[simdWidth] = {0};\n    int maxIndices[simdWidth] = {0};\n\n    __m128i maxLengthsSIMD = _mm_setzero_si128();\n    __m128i maxIndicesSIMD = _mm_setzero_si128();\n\n    for (int i = 0; i < numStrings; i += simdWidth) {\n        __m128i lengthsSIMD = _mm_set_epi32(\n            (i + 3 < numStrings) ? strings[i + 3].size() : 0,\n            (i + 2 < numStrings) ? strings[i + 2].size() : 0,\n            (i + 1 < numStrings) ? strings[i + 1].size() : 0,\n            (i + 0 < numStrings) ? strings[i + 0].size() : 0\n        );\n\n        __m128i indicesSIMD = _mm_set_epi32(i + 3, i + 2, i + 1, i + 0);\n\n        __m128i cmpGT = _mm_cmpgt_epi32(lengthsSIMD, maxLengthsSIMD);\n        maxLengthsSIMD = _mm_max_epi32(lengthsSIMD, maxLengthsSIMD);\n        maxIndicesSIMD = _mm_blendv_epi8(maxIndicesSIMD, indicesSIMD, cmpGT);\n    }\n\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(maxLengths), maxLengthsSIMD);\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(maxIndices), maxIndicesSIMD);\n\n    int globalMaxLength = *std::max_element(maxLengths, maxLengths + simdWidth);\n    int globalMaxIndex = maxIndices[std::distance(maxLengths, std::find(maxLengths, maxLengths + simdWidth, globalMaxLength))];\n\n    return strings[globalMaxIndex];\n}\n```"}
{"task_id": "SimdBench_69_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n#include <algorithm>\n\nstd::string longest_simd(const std::vector<std::string> & strings){\n    if (strings.empty()) {\n        return \"\";\n    }\n\n    const int numStrings = strings.size();\n    const int simdWidth = 4; // SSE processes 4 integers at a time\n    int maxLengths[simdWidth] = {0};\n    int maxIndices[simdWidth] = {0};\n\n    __m128i maxLengthsSIMD = _mm_setzero_si128();\n    __m128i maxIndicesSIMD = _mm_setzero_si128();\n\n    for (int i = 0; i < numStrings; i += simdWidth) {\n        __m128i lengthsSIMD = _mm_set_epi32(\n            (i + 3 < numStrings) ? strings[i + 3].size() : 0,\n            (i + 2 < numStrings) ? strings[i + 2].size() : 0,\n            (i + 1 < numStrings) ? strings[i + 1].size() : 0,\n            (i + 0 < numStrings) ? strings[i + 0].size() : 0\n        );\n\n        __m128i indicesSIMD = _mm_set_epi32(i + 3, i + 2, i + 1, i + 0);\n\n        __m128i cmpGT = _mm_cmpgt_epi32(lengthsSIMD, maxLengthsSIMD);\n        maxLengthsSIMD = _mm_max_epi32(lengthsSIMD, maxLengthsSIMD);\n        maxIndicesSIMD = _mm_blendv_epi8(maxIndicesSIMD, indicesSIMD, cmpGT);\n    }\n\n    _mm_storeu_si128((__m128i*)maxLengths, maxLengthsSIMD);\n    _mm_storeu_si128((__m128i*)maxIndices, maxIndicesSIMD);\n\n    int globalMaxIndex = maxIndices[0];\n    int globalMaxLength = maxLengths[0];\n\n    for (int i = 1; i < simdWidth; ++i) {\n        if (maxLengths[i] > globalMaxLength) {\n            globalMaxLength = maxLengths[i];\n            globalMaxIndex = maxIndices[i];\n        }\n    }\n\n    return strings[globalMaxIndex];\n}\n```"}
{"task_id": "SimdBench_69_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n#include <algorithm>\n\nstd::string longest_simd(const std::vector<std::string> & strings){\n    if (strings.empty()) {\n        return \"\";\n    }\n\n    size_t max_length = 0;\n    const char* longest_string = nullptr;\n\n    size_t i = 0;\n    __m128i lengths = _mm_setzero_si128();\n    __m128i indices = _mm_set_epi32(7, 6, 5, 4, 3, 2, 1, 0);\n    __m128i max_lengths = _mm_setzero_si128();\n    __m128i max_indices = _mm_setzero_si128();\n\n    while (i <= strings.size() - 8) {\n        for (size_t j = 0; j < 8; ++j) {\n            lengths = _mm_insert_epi32(lengths, strings[i + j].size(), j);\n        }\n\n        __m128i cmpgt = _mm_cmpgt_epi32(lengths, max_lengths);\n        max_lengths = _mm_max_epi32(lengths, max_lengths);\n        max_indices = _mm_blendv_epi8(max_indices, indices, cmpgt);\n\n        indices = _mm_add_epi32(indices, _mm_set1_epi32(8));\n        i += 8;\n    }\n\n    int max_index = _mm_extract_epi32(max_indices, 0);\n    max_length = _mm_extract_epi32(max_lengths, 0);\n    longest_string = strings[max_index].c_str();\n\n    for (; i < strings.size(); ++i) {\n        if (strings[i].size() > max_length) {\n            max_length = strings[i].size();\n            longest_string = strings[i].c_str();\n        }\n    }\n\n    return std::string(longest_string);\n}\n```"}
{"task_id": "SimdBench_70_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nuint64_t greatest_common_divisor_simd(uint64_t a, uint64_t b){\n    __m128i x = _mm_set_epi64x(0, 0, 0, a);\n    __m128i y = _mm_set_epi64x(0, 0, 0, b);\n\n    while (_mm_extract_epi64(y, 0) != 0) {\n        __m128i temp = _mm_and_si128(y, _mm_cmpeq_epi64(_mm_and_si128(y, _mm_set1_epi64x(1)), _mm_set1_epi64x(1)));\n        y = _mm_sub_epi64(x, _mm_and_si128(_mm_srli_epi64(y, 1), _mm_cmpeq_epi64(temp, _mm_setzero_si128())));\n        x = _mm_sub_epi64(_mm_and_si128(x, _mm_cmpeq_epi64(temp, _mm_setzero_si128())), _mm_srli_epi64(y, 1));\n        __m128i swap = _mm_cmplt_epi64(y, x);\n        x = _mm_or_si128(_mm_and_si128(x, _mm_cmpeq_epi64(swap, _mm_setzero_si128())), _mm_and_si128(y, swap));\n        y = _mm_or_si128(_mm_and_si128(y, _mm_cmpeq_epi64(swap, _mm_setzero_si128())), _mm_and_si128(x, swap));\n    }\n\n    return _mm_extract_epi64(x, 0);\n}\n```"}
{"task_id": "SimdBench_70_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nuint64_t greatest_common_divisor_simd(uint64_t a, uint64_t b){\n    __m128i x = _mm_set_epi64x(0, 0, 0, a);\n    __m128i y = _mm_set_epi64x(0, 0, 0, b);\n\n    while (_mm_extract_epi64(y, 0) != 0) {\n        __m128i temp = _mm_and_si128(y, _mm_cmpeq_epi64(_mm_and_si128(y, _mm_set1_epi64x(1)), _mm_set1_epi64x(1)));\n        y = _mm_sub_epi64(x, _mm_and_si128(_mm_srli_epi64(y, 1), _mm_cmpeq_epi64(temp, _mm_setzero_si128())));\n        x = _mm_sub_epi64(y, _mm_and_si128(_mm_srli_epi64(x, 1), _mm_cmpeq_epi64(temp, _mm_set1_epi64x(1))));\n    }\n\n    return _mm_extract_epi64(x, 0);\n}\n```"}
{"task_id": "SimdBench_70_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nuint64_t greatest_common_divisor_simd(uint64_t a, uint64_t b){\n    __m128i x = _mm_set_epi64x(0, 0, 0, a);\n    __m128i y = _mm_set_epi64x(0, 0, 0, b);\n\n    while (_mm_cvtsi128_si64(y) != 0) {\n        __m128i temp = _mm_and_si128(y, _mm_set1_epi64x(1));\n        y = _mm_srli_epi64(y, 1);\n        x = _mm_sub_epi64(x, _mm_and_si128(temp, _mm_sub_epi64(x, y)));\n        temp = _mm_and_si128(x, _mm_set1_epi64x(1));\n        x = _mm_srli_epi64(x, 1);\n        y = _mm_add_epi64(y, _mm_and_si128(temp, _mm_sub_epi64(y, x)));\n    }\n\n    return _mm_cvtsi128_si64(x) << _mm_ctzll(_mm_cvtsi128_si64(_mm_or_si128(x, y)));\n}\n```"}
{"task_id": "SimdBench_70_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nuint64_t greatest_common_divisor_simd(uint64_t a, uint64_t b){\n    __m128i x = _mm_set_epi64x(0, 0, 0, a);\n    __m128i y = _mm_set_epi64x(0, 0, 0, b);\n\n    while (_mm_cvtsi128_si64(y) != 0) {\n        __m128i temp = _mm_and_si128(y, _mm_set1_epi64x(1));\n        y = _mm_srli_epi64(y, 1);\n        x = _mm_sub_epi64(x, _mm_and_si128(temp, _mm_sub_epi64(x, y)));\n        temp = _mm_and_si128(x, _mm_set1_epi64x(1));\n        x = _mm_srli_epi64(x, 1);\n        y = _mm_add_epi64(y, _mm_and_si128(temp, _mm_sub_epi64(y, x)));\n    }\n\n    return _mm_cvtsi128_si64(x) << _mm_ctzll(_mm_cvtsi128_si64(_mm_or_si128(x, y)));\n}\n```"}
{"task_id": "SimdBench_70_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nuint64_t greatest_common_divisor_simd(uint64_t a, uint64_t b){\n    __m128i x = _mm_set_epi64x(0, 0, 0, a);\n    __m128i y = _mm_set_epi64x(0, 0, 0, b);\n\n    while (_mm_extract_epi64(y, 0) != 0) {\n        __m128i temp = _mm_and_si128(y, _mm_set_epi64x(0, 0, 0, 1));\n        y = _mm_srli_epi64(_mm_sub_epi64(x, _mm_and_si128(y, _mm_cmpeq_epi64(temp, _mm_setzero_si128()))), 1);\n        x = _mm_and_si128(x, _mm_cmpeq_epi64(temp, _mm_setzero_si128())) | _mm_and_si128(y, _mm_cmpeq_epi64(temp, _mm_set_epi64x(0, 0, 0, 1)));\n    }\n\n    return _mm_extract_epi64(x, 0);\n}\n```"}
{"task_id": "SimdBench_71_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <cmath>\n#include <limits>\n\nstd::vector<float> find_closest_elements_simd(std::vector<float> numbers) {\n    float min_diff = std::numeric_limits<float>::max();\n    __m128 min_pair = _mm_setzero_ps();\n    int n = numbers.size();\n\n    for (int i = 0; i <= n - 4; i += 4) {\n        __m128 vec1 = _mm_loadu_ps(&numbers[i]);\n        for (int j = i + 4; j <= n - 4; j += 4) {\n            __m128 vec2 = _mm_loadu_ps(&numbers[j]);\n            __m128 diff1 = _mm_sub_ps(_mm_shuffle_ps(vec1, vec1, _MM_SHUFFLE(0, 0, 0, 0)), vec2);\n            __m128 diff2 = _mm_sub_ps(_mm_shuffle_ps(vec1, vec1, _MM_SHUFFLE(1, 1, 1, 1)), vec2);\n            __m128 diff3 = _mm_sub_ps(_mm_shuffle_ps(vec1, vec1, _MM_SHUFFLE(2, 2, 2, 2)), vec2);\n            __m128 diff4 = _mm_sub_ps(_mm_shuffle_ps(vec1, vec1, _MM_SHUFFLE(3, 3, 3, 3)), vec2);\n\n            __m128 abs_diff1 = _mm_andnot_ps(_mm_set1_ps(-0.0f), diff1);\n            __m128 abs_diff2 = _mm_andnot_ps(_mm_set1_ps(-0.0f), diff2);\n            __m128 abs_diff3 = _mm_andnot_ps(_mm_set1_ps(-0.0f), diff3);\n            __m128 abs_diff4 = _mm_andnot_ps(_mm_set1_ps(-0.0f), diff4);\n\n            __m128 min_abs_diff = _mm_min_ps(_mm_min_ps(abs_diff1, abs_diff2), _mm_min_ps(abs_diff3, abs_diff4));\n            __m128 mask = _mm_cmplt_ps(min_abs_diff, _mm_set1_ps(min_diff));\n\n            if (_mm_movemask_epi8((__m128i)mask) != 0) {\n                float diff_array[4];\n                _mm_storeu_ps(diff_array, min_abs_diff);\n                float min_val = std::numeric_limits<float>::max();\n                int min_idx = -1;\n                for (int k = 0; k < 4; ++k) {\n                    if (diff_array[k] < min_val) {\n                        min_val = diff_array[k];\n                        min_idx = k;\n                    }\n                }\n                float a = _mm_cvtss_f32(_mm_shuffle_ps(vec1, vec1, _MM_SHUFFLE(min_idx, min_idx, min_idx, min_idx)));\n                float b = _mm_cvtss_f32(_mm_shuffle_ps(vec2, vec2, _MM_SHUFFLE(min_idx, min_idx, min_idx, min_idx)));\n                if (a > b) std::swap(a, b);\n                min_diff = min_val;\n                min_pair = _mm_set_ps(0.0f, 0.0f, b, a);\n            }\n        }\n    }\n\n    float result[4];\n    _mm_storeu_ps(result, min_pair);\n    return {result[2], result[3]};\n}\n```"}
{"task_id": "SimdBench_71_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <cmath>\n#include <limits>\n\nstd::vector<float> find_closest_elements_simd(std::vector<float> numbers) {\n    float min_diff = std::numeric_limits<float>::max();\n    __m128 min_pair = _mm_setzero_ps();\n    int n = numbers.size();\n\n    for (int i = 0; i <= n - 4; i += 4) {\n        __m128 vec1 = _mm_loadu_ps(&numbers[i]);\n        for (int j = i + 4; j < n; j += 4) {\n            __m128 vec2 = _mm_loadu_ps(&numbers[j]);\n            __m128 diff1 = _mm_sub_ps(_mm_shuffle_ps(vec1, vec1, _MM_SHUFFLE(0, 0, 0, 0)), vec2);\n            __m128 diff2 = _mm_sub_ps(_mm_shuffle_ps(vec1, vec1, _MM_SHUFFLE(1, 1, 1, 1)), vec2);\n            __m128 diff3 = _mm_sub_ps(_mm_shuffle_ps(vec1, vec1, _MM_SHUFFLE(2, 2, 2, 2)), vec2);\n            __m128 diff4 = _mm_sub_ps(_mm_shuffle_ps(vec1, vec1, _MM_SHUFFLE(3, 3, 3, 3)), vec2);\n\n            __m128 abs_diff1 = _mm_andnot_ps(_mm_set1_ps(-0.0f), diff1);\n            __m128 abs_diff2 = _mm_andnot_ps(_mm_set1_ps(-0.0f), diff2);\n            __m128 abs_diff3 = _mm_andnot_ps(_mm_set1_ps(-0.0f), diff3);\n            __m128 abs_diff4 = _mm_andnot_ps(_mm_set1_ps(-0.0f), diff4);\n\n            __m128 min_abs_diff = _mm_min_ps(_mm_min_ps(abs_diff1, abs_diff2), _mm_min_ps(abs_diff3, abs_diff4));\n            __m128 mask = _mm_cmplt_ps(min_abs_diff, _mm_set1_ps(min_diff));\n\n            if (_mm_movemask_epi8((__m128i)mask) != 0) {\n                float diff_array[4];\n                _mm_storeu_ps(diff_array, min_abs_diff);\n                float min_val = std::numeric_limits<float>::max();\n                int idx = -1;\n                for (int k = 0; k < 4; ++k) {\n                    if (diff_array[k] < min_val) {\n                        min_val = diff_array[k];\n                        idx = k;\n                    }\n                }\n                if (idx != -1) {\n                    min_diff = min_val;\n                    float a = _mm_cvtss_f32(_mm_shuffle_ps(vec1, vec1, _MM_SHUFFLE(idx, idx, idx, idx)));\n                    float b = _mm_cvtss_f32(_mm_shuffle_ps(vec2, vec2, _MM_SHUFFLE(0, 0, 0, 0)));\n                    if (a > b) std::swap(a, b);\n                    min_pair = _mm_setr_ps(a, b, 0.0f, 0.0f);\n                }\n            }\n        }\n    }\n\n    float result[4];\n    _mm_storeu_ps(result, min_pair);\n    return {result[0], result[1]};\n}\n```"}
{"task_id": "SimdBench_71_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <cmath>\n#include <limits>\n\nstd::vector<float> find_closest_elements_simd(std::vector<float> numbers) {\n    float min_diff = std::numeric_limits<float>::max();\n    __m128 min_pair = _mm_setzero_ps();\n    int n = numbers.size();\n\n    for (int i = 0; i <= n - 4; i += 4) {\n        __m128 vec1 = _mm_loadu_ps(&numbers[i]);\n        for (int j = i + 4; j < n; j += 4) {\n            __m128 vec2 = _mm_loadu_ps(&numbers[j]);\n            __m128 diff1 = _mm_sub_ps(_mm_shuffle_ps(vec1, vec1, _MM_SHUFFLE(0, 0, 0, 0)), vec2);\n            __m128 diff2 = _mm_sub_ps(_mm_shuffle_ps(vec1, vec1, _MM_SHUFFLE(1, 1, 1, 1)), vec2);\n            __m128 diff3 = _mm_sub_ps(_mm_shuffle_ps(vec1, vec1, _MM_SHUFFLE(2, 2, 2, 2)), vec2);\n            __m128 diff4 = _mm_sub_ps(_mm_shuffle_ps(vec1, vec1, _MM_SHUFFLE(3, 3, 3, 3)), vec2);\n\n            __m128 abs_diff1 = _mm_andnot_ps(_mm_set1_ps(-0.0f), diff1);\n            __m128 abs_diff2 = _mm_andnot_ps(_mm_set1_ps(-0.0f), diff2);\n            __m128 abs_diff3 = _mm_andnot_ps(_mm_set1_ps(-0.0f), diff3);\n            __m128 abs_diff4 = _mm_andnot_ps(_mm_set1_ps(-0.0f), diff4);\n\n            __m128 min_abs_diff = _mm_min_ps(_mm_min_ps(abs_diff1, abs_diff2), _mm_min_ps(abs_diff3, abs_diff4));\n            float min_scalar_diff = _mm_cvtss_f32(min_abs_diff);\n\n            if (min_scalar_diff < min_diff) {\n                min_diff = min_scalar_diff;\n                int idx = _mm_cmple_ss(min_abs_diff, abs_diff1) ? 0 :\n                          _mm_cmple_ss(min_abs_diff, abs_diff2) ? 1 :\n                          _mm_cmple_ss(min_abs_diff, abs_diff3) ? 2 : 3;\n                float a = _mm_cvtss_f32(_mm_shuffle_ps(vec1, vec1, _MM_SHUFFLE(idx, idx, idx, idx)));\n                float b = _mm_cvtss_f32(_mm_shuffle_ps(vec2, vec2, _MM_SHUFFLE(0, 0, 0, 0)));\n                if (a > b) std::swap(a, b);\n                min_pair = _mm_setr_ps(a, b, 0.0f, 0.0f);\n            }\n        }\n    }\n\n    // Handle remaining elements\n    for (int i = (n / 4) * 4; i < n - 1; ++i) {\n        for (int j = i + 1; j < n; ++j) {\n            float diff = std::fabs(numbers[i] - numbers[j]);\n            if (diff < min_diff) {\n                min_diff = diff;\n                min_pair = _mm_setr_ps(std::min(numbers[i], numbers[j]), std::max(numbers[i], numbers[j]), 0.0f, 0.0f);\n            }\n        }\n    }\n\n    float result[4];\n    _mm_storeu_ps(result, min_pair);\n    return {result[0], result[1]};\n}\n```"}
{"task_id": "SimdBench_71_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <cmath>\n#include <limits>\n\nstd::vector<float> find_closest_elements_simd(std::vector<float> numbers) {\n    float min_diff = std::numeric_limits<float>::max();\n    __m128 min_pair = _mm_setzero_ps();\n    int n = numbers.size();\n\n    for (int i = 0; i < n - 4; i += 4) {\n        __m128 vec1 = _mm_loadu_ps(&numbers[i]);\n        __m128 vec2 = _mm_loadu_ps(&numbers[i + 1]);\n\n        __m128 diff1 = _mm_sub_ps(vec1, _mm_shuffle_ps(vec2, vec2, _MM_SHUFFLE(0, 0, 0, 0)));\n        __m128 diff2 = _mm_sub_ps(vec1, _mm_shuffle_ps(vec2, vec2, _MM_SHUFFLE(1, 1, 1, 1)));\n        __m128 diff3 = _mm_sub_ps(vec1, _mm_shuffle_ps(vec2, vec2, _MM_SHUFFLE(2, 2, 2, 2)));\n        __m128 diff4 = _mm_sub_ps(vec1, _mm_shuffle_ps(vec2, vec2, _MM_SHUFFLE(3, 3, 3, 3)));\n\n        diff1 = _mm_andnot_ps(_mm_cmplt_ps(diff1, _mm_setzero_ps()), diff1);\n        diff2 = _mm_andnot_ps(_mm_cmplt_ps(diff2, _mm_setzero_ps()), diff2);\n        diff3 = _mm_andnot_ps(_mm_cmplt_ps(diff3, _mm_setzero_ps()), diff3);\n        diff4 = _mm_andnot_ps(_mm_cmplt_ps(diff4, _mm_setzero_ps()), diff4);\n\n        __m128 min_diffs = _mm_min_ps(_mm_min_ps(diff1, diff2), _mm_min_ps(diff3, diff4));\n        __m128 mask = _mm_cmplt_ps(min_diffs, _mm_set1_ps(min_diff));\n\n        if (_mm_movemask_epi8((__m128i)mask) != 0) {\n            float temp_diffs[4];\n            _mm_storeu_ps(temp_diffs, min_diffs);\n            float temp_values[4];\n            _mm_storeu_ps(temp_values, vec1);\n            float temp_values2[4];\n            _mm_storeu_ps(temp_values2, vec2);\n\n            for (int j = 0; j < 4; ++j) {\n                if (temp_diffs[j] < min_diff) {\n                    min_diff = temp_diffs[j];\n                    if (temp_values[j] < temp_values2[j]) {\n                        min_pair = _mm_set_ps(0, 0, temp_values2[j], temp_values[j]);\n                    } else {\n                        min_pair = _mm_set_ps(0, 0, temp_values[j], temp_values2[j]);\n                    }\n                }\n            }\n        }\n    }\n\n    float result[4];\n    _mm_storeu_ps(result, min_pair);\n    return {result[2], result[3]};\n}\n```"}
{"task_id": "SimdBench_71_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <cmath>\n#include <limits>\n\nstd::vector<float> find_closest_elements_simd(std::vector<float> numbers) {\n    float min_diff = std::numeric_limits<float>::max();\n    __m128 min_pair = _mm_setzero_ps();\n    int n = numbers.size();\n\n    for (int i = 0; i <= n - 4; i += 4) {\n        __m128 vec1 = _mm_loadu_ps(&numbers[i]);\n        for (int j = i + 4; j < n; j += 4) {\n            __m128 vec2 = _mm_loadu_ps(&numbers[j]);\n            __m128 diff1 = _mm_sub_ps(_mm_shuffle_ps(vec1, vec1, _MM_SHUFFLE(0, 0, 0, 0)), vec2);\n            __m128 diff2 = _mm_sub_ps(_mm_shuffle_ps(vec1, vec1, _MM_SHUFFLE(1, 1, 1, 1)), vec2);\n            __m128 diff3 = _mm_sub_ps(_mm_shuffle_ps(vec1, vec1, _MM_SHUFFLE(2, 2, 2, 2)), vec2);\n            __m128 diff4 = _mm_sub_ps(_mm_shuffle_ps(vec1, vec1, _MM_SHUFFLE(3, 3, 3, 3)), vec2);\n\n            __m128 abs_diff1 = _mm_andnot_ps(_mm_set1_ps(-0.0f), diff1);\n            __m128 abs_diff2 = _mm_andnot_ps(_mm_set1_ps(-0.0f), diff2);\n            __m128 abs_diff3 = _mm_andnot_ps(_mm_set1_ps(-0.0f), diff3);\n            __m128 abs_diff4 = _mm_andnot_ps(_mm_set1_ps(-0.0f), diff4);\n\n            __m128 min_abs_diff = _mm_min_ps(_mm_min_ps(abs_diff1, abs_diff2), _mm_min_ps(abs_diff3, abs_diff4));\n            float min_scalar_diff = _mm_cvtss_f32(min_abs_diff);\n\n            if (min_scalar_diff < min_diff) {\n                min_diff = min_scalar_diff;\n                int idx = _mm_cmple_ss(min_abs_diff, abs_diff1) ? 0 :\n                          _mm_cmple_ss(min_abs_diff, abs_diff2) ? 1 :\n                          _mm_cmple_ss(min_abs_diff, abs_diff3) ? 2 : 3;\n                float a = _mm_cvtss_f32(_mm_shuffle_ps(vec1, vec1, _MM_SHUFFLE(idx, idx, idx, idx)));\n                float b = _mm_cvtss_f32(_mm_shuffle_ps(vec2, vec2, _MM_SHUFFLE(0, 0, 0, 0)));\n                if (a > b) std::swap(a, b);\n                min_pair = _mm_setr_ps(a, b, 0.0f, 0.0f);\n            }\n        }\n    }\n\n    // Handle remaining elements\n    for (int i = (n / 4) * 4; i < n - 1; ++i) {\n        for (int j = i + 1; j < n; ++j) {\n            float diff = std::fabs(numbers[i] - numbers[j]);\n            if (diff < min_diff) {\n                min_diff = diff;\n                min_pair = _mm_setr_ps(std::min(numbers[i], numbers[j]), std::max(numbers[i], numbers[j]), 0.0f, 0.0f);\n            }\n        }\n    }\n\n    float result[4];\n    _mm_storeu_ps(result, min_pair);\n    return {result[0], result[1]};\n}\n```"}
{"task_id": "SimdBench_72_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<float> rescale_to_unit_simd(std::vector<float> numbers){\n    if (numbers.size() < 2) return numbers;\n\n    float* data = numbers.data();\n    size_t n = numbers.size();\n\n    __m128 min_val = _mm_set1_ps(data[0]);\n    __m128 max_val = _mm_set1_ps(data[0]);\n\n    for (size_t i = 0; i <= n - 4; i += 4) {\n        __m128 vec = _mm_loadu_ps(&data[i]);\n        min_val = _mm_min_ps(min_val, vec);\n        max_val = _mm_max_ps(max_val, vec);\n    }\n\n    float min_arr[4], max_arr[4];\n    _mm_storeu_ps(min_arr, min_val);\n    _mm_storeu_ps(max_arr, max_val);\n\n    float min_scalar = *std::min_element(min_arr, min_arr + 4);\n    float max_scalar = *std::max_element(max_arr, max_arr + 4);\n\n    for (size_t i = (n / 4) * 4; i < n; ++i) {\n        min_scalar = std::min(min_scalar, data[i]);\n        max_scalar = std::max(max_scalar, data[i]);\n    }\n\n    float range = max_scalar - min_scalar;\n    if (range == 0.0f) return numbers;\n\n    __m128 scale = _mm_set1_ps(1.0f / range);\n    __m128 offset = _mm_set1_ps(-min_scalar / range);\n\n    for (size_t i = 0; i <= n - 4; i += 4) {\n        __m128 vec = _mm_loadu_ps(&data[i]);\n        vec = _mm_sub_ps(vec, _mm_set1_ps(min_scalar));\n        vec = _mm_mul_ps(vec, scale);\n        _mm_storeu_ps(&data[i], vec);\n    }\n\n    for (size_t i = (n / 4) * 4; i < n; ++i) {\n        data[i] = (data[i] - min_scalar) / range;\n    }\n\n    return numbers;\n}\n```"}
{"task_id": "SimdBench_72_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<float> rescale_to_unit_simd(std::vector<float> numbers){\n    if (numbers.size() < 2) return numbers;\n\n    float* data = numbers.data();\n    size_t size = numbers.size();\n\n    __m128 min_val = _mm_set1_ps(data[0]);\n    __m128 max_val = _mm_set1_ps(data[0]);\n\n    for (size_t i = 0; i <= size - 4; i += 4) {\n        __m128 vec = _mm_loadu_ps(&data[i]);\n        min_val = _mm_min_ps(min_val, vec);\n        max_val = _mm_max_ps(max_val, vec);\n    }\n\n    float min_vals[4], max_vals[4];\n    _mm_storeu_ps(min_vals, min_val);\n    _mm_storeu_ps(max_vals, max_val);\n\n    float min_value = *std::min_element(min_vals, min_vals + 4);\n    float max_value = *std::max_element(max_vals, max_vals + 4);\n\n    for (size_t i = size - 4; i < size; ++i) {\n        min_value = std::min(min_value, data[i]);\n        max_value = std::max(max_value, data[i]);\n    }\n\n    float range = max_value - min_value;\n    if (range == 0.0f) return numbers;\n\n    __m128 scale = _mm_set1_ps(1.0f / range);\n    __m128 offset = _mm_set1_ps(-min_value / range);\n\n    for (size_t i = 0; i <= size - 4; i += 4) {\n        __m128 vec = _mm_loadu_ps(&data[i]);\n        vec = _mm_mul_ps(_mm_add_ps(vec, offset), scale);\n        _mm_storeu_ps(&data[i], vec);\n    }\n\n    for (size_t i = size - 4; i < size; ++i) {\n        data[i] = (data[i] - min_value) / range;\n    }\n\n    return numbers;\n}\n```"}
{"task_id": "SimdBench_72_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<float> rescale_to_unit_simd(std::vector<float> numbers){\n    if (numbers.size() < 2) return numbers;\n\n    float* data = numbers.data();\n    size_t n = numbers.size();\n\n    __m128 min_val = _mm_set1_ps(data[0]);\n    __m128 max_val = _mm_set1_ps(data[0]);\n\n    for (size_t i = 0; i <= n - 4; i += 4) {\n        __m128 v = _mm_loadu_ps(&data[i]);\n        min_val = _mm_min_ps(min_val, v);\n        max_val = _mm_max_ps(max_val, v);\n    }\n\n    float min_vals[4], max_vals[4];\n    _mm_storeu_ps(min_vals, min_val);\n    _mm_storeu_ps(max_vals, max_val);\n\n    float min_value = *std::min_element(min_vals, min_vals + 4);\n    float max_value = *std::max_element(max_vals, max_vals + 4);\n\n    for (size_t i = n - (n % 4); i < n; ++i) {\n        min_value = std::min(min_value, data[i]);\n        max_value = std::max(max_value, data[i]);\n    }\n\n    float range = max_value - min_value;\n    if (range == 0.0f) return numbers;\n\n    __m128 scale = _mm_set1_ps(1.0f / range);\n    __m128 offset = _mm_set1_ps(-min_value / range);\n\n    for (size_t i = 0; i <= n - 4; i += 4) {\n        __m128 v = _mm_loadu_ps(&data[i]);\n        v = _mm_mul_ps(_mm_add_ps(v, offset), scale);\n        _mm_storeu_ps(&data[i], v);\n    }\n\n    for (size_t i = n - (n % 4); i < n; ++i) {\n        data[i] = (data[i] - min_value) / range;\n    }\n\n    return numbers;\n}\n```"}
{"task_id": "SimdBench_72_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<float> rescale_to_unit_simd(std::vector<float> numbers){\n    if (numbers.size() < 2) return numbers;\n\n    float* data = numbers.data();\n    size_t size = numbers.size();\n\n    __m128 min_val = _mm_set1_ps(data[0]);\n    __m128 max_val = _mm_set1_ps(data[0]);\n\n    for (size_t i = 0; i <= size - 4; i += 4) {\n        __m128 vec = _mm_loadu_ps(&data[i]);\n        min_val = _mm_min_ps(min_val, vec);\n        max_val = _mm_max_ps(max_val, vec);\n    }\n\n    float min_arr[4], max_arr[4];\n    _mm_storeu_ps(min_arr, min_val);\n    _mm_storeu_ps(max_arr, max_val);\n\n    float min_scalar = *std::min_element(min_arr, min_arr + 4);\n    float max_scalar = *std::max_element(max_arr, max_arr + 4);\n\n    for (size_t i = size - 4; i < size; ++i) {\n        min_scalar = std::min(min_scalar, data[i]);\n        max_scalar = std::max(max_scalar, data[i]);\n    }\n\n    float range = max_scalar - min_scalar;\n    __m128 scale = _mm_set1_ps(1.0f / range);\n    __m128 offset = _mm_set1_ps(-min_scalar / range);\n\n    for (size_t i = 0; i <= size - 4; i += 4) {\n        __m128 vec = _mm_loadu_ps(&data[i]);\n        vec = _mm_sub_ps(vec, _mm_set1_ps(min_scalar));\n        vec = _mm_mul_ps(vec, scale);\n        _mm_storeu_ps(&data[i], vec);\n    }\n\n    for (size_t i = size - 4; i < size; ++i) {\n        data[i] = (data[i] - min_scalar) / range;\n    }\n\n    return numbers;\n}\n```"}
{"task_id": "SimdBench_72_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<float> rescale_to_unit_simd(std::vector<float> numbers){\n    if (numbers.size() < 2) return numbers;\n\n    float* data = numbers.data();\n    size_t n = numbers.size();\n\n    __m128 min_val = _mm_set1_ps(data[0]);\n    __m128 max_val = _mm_set1_ps(data[0]);\n\n    for (size_t i = 0; i <= n - 4; i += 4) {\n        __m128 vec = _mm_loadu_ps(&data[i]);\n        min_val = _mm_min_ps(min_val, vec);\n        max_val = _mm_max_ps(max_val, vec);\n    }\n\n    float min_arr[4], max_arr[4];\n    _mm_storeu_ps(min_arr, min_val);\n    _mm_storeu_ps(max_arr, max_val);\n\n    float min_scalar = *std::min_element(min_arr, min_arr + 4);\n    float max_scalar = *std::max_element(max_arr, max_arr + 4);\n\n    for (size_t i = (n / 4) * 4; i < n; ++i) {\n        min_scalar = std::min(min_scalar, data[i]);\n        max_scalar = std::max(max_scalar, data[i]);\n    }\n\n    float range = max_scalar - min_scalar;\n    if (range == 0.0f) return numbers;\n\n    __m128 scale = _mm_set1_ps(1.0f / range);\n    __m128 offset = _mm_set1_ps(-min_scalar / range);\n\n    for (size_t i = 0; i <= n - 4; i += 4) {\n        __m128 vec = _mm_loadu_ps(&data[i]);\n        vec = _mm_sub_ps(vec, _mm_set1_ps(min_scalar));\n        vec = _mm_mul_ps(vec, scale);\n        _mm_storeu_ps(&data[i], vec);\n    }\n\n    for (size_t i = (n / 4) * 4; i < n; ++i) {\n        data[i] = (data[i] - min_scalar) / range;\n    }\n\n    return numbers;\n}\n```"}
{"task_id": "SimdBench_73_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nuint64_t largest_divisor_simd(uint64_t n) {\n    __m128i n_vec = _mm_set1_epi64x(n);\n    __m128i one_vec = _mm_set1_epi64x(1);\n    __m128i i_vec = _mm_sub_epi64(n_vec, one_vec);\n    __m128i zero_vec = _mm_setzero_si128();\n    __m128i result_vec = zero_vec;\n\n    while (_mm_movemask_epi8(_mm_cmpgt_epi64(i_vec, zero_vec))) {\n        __m128i remainder_vec = _mm_rem_epu64(n_vec, i_vec);\n        __m128i is_zero_mask = _mm_cmpeq_epi64(remainder_vec, zero_vec);\n        result_vec = _mm_blendv_epi8(result_vec, i_vec, is_zero_mask);\n        i_vec = _mm_sub_epi64(i_vec, one_vec);\n    }\n\n    return _mm_cvtsi128_si64(result_vec);\n}\n```"}
{"task_id": "SimdBench_73_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nuint64_t largest_divisor_simd(uint64_t n) {\n    __m128i n_vec = _mm_set1_epi64x(n);\n    __m128i one_vec = _mm_set1_epi64x(1);\n    __m128i i_vec = _mm_sub_epi64(n_vec, one_vec);\n    __m128i zero_vec = _mm_setzero_si128();\n    __m128i result_vec = zero_vec;\n\n    while (_mm_movemask_epi8(_mm_cmpgt_epi64(i_vec, zero_vec))) {\n        __m128i remainder_vec = _mm_rem_epu64(n_vec, i_vec);\n        __m128i is_zero_mask = _mm_cmpeq_epi64(remainder_vec, zero_vec);\n        result_vec = _mm_blendv_epi8(result_vec, i_vec, is_zero_mask);\n        i_vec = _mm_sub_epi64(i_vec, one_vec);\n    }\n\n    return _mm_cvtsi128_si64(result_vec);\n}\n```"}
{"task_id": "SimdBench_73_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nuint64_t largest_divisor_simd(uint64_t n) {\n    __m128i n_vec = _mm_set1_epi64x(n);\n    __m128i one_vec = _mm_set1_epi64x(1);\n    __m128i i_vec = _mm_sub_epi64(n_vec, one_vec);\n    __m128i zero_vec = _mm_setzero_si128();\n    __m128i result_vec = zero_vec;\n\n    while (_mm_movemask_epi8(_mm_cmpgt_epi64(i_vec, zero_vec))) {\n        __m128i remainder_vec = _mm_rem_epu64(n_vec, i_vec);\n        __m128i is_zero_mask = _mm_cmpeq_epi64(remainder_vec, zero_vec);\n        result_vec = _mm_blendv_epi8(result_vec, i_vec, is_zero_mask);\n        i_vec = _mm_sub_epi64(i_vec, one_vec);\n    }\n\n    return _mm_cvtsi128_si64(result_vec);\n}\n```"}
{"task_id": "SimdBench_73_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nuint64_t largest_divisor_simd(uint64_t n) {\n    __m128i n_vec = _mm_set1_epi64x(n);\n    __m128i one_vec = _mm_set1_epi64x(1);\n    __m128i i_vec = _mm_sub_epi64(n_vec, one_vec);\n    __m128i zero_vec = _mm_setzero_si128();\n    __m128i result_vec = zero_vec;\n\n    while (_mm_movemask_epi8(_mm_cmpgt_epi64(i_vec, zero_vec))) {\n        __m128i remainder_vec = _mm_rem_epu64(n_vec, i_vec);\n        __m128i is_zero_mask = _mm_cmpeq_epi64(remainder_vec, zero_vec);\n        result_vec = _mm_blendv_epi8(result_vec, i_vec, is_zero_mask);\n        i_vec = _mm_sub_epi64(i_vec, one_vec);\n    }\n\n    return _mm_cvtsi128_si64(result_vec);\n}\n```"}
{"task_id": "SimdBench_73_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nuint64_t largest_divisor_simd(uint64_t n) {\n    __m128i n_vec = _mm_set1_epi64x(n);\n    __m128i i_vec = _mm_setr_epi64x(n - 1, n - 2, n - 3, n - 4);\n    __m128i zero_vec = _mm_setzero_si128();\n    __m128i result_vec = zero_vec;\n\n    while (_mm_movemask_epi8(_mm_cmpgt_epi64(i_vec, zero_vec)) != 0) {\n        __m128i remainder_vec = _mm_rem_epu64(n_vec, i_vec);\n        __m128i mask_vec = _mm_cmpeq_epi64(remainder_vec, zero_vec);\n        result_vec = _mm_blendv_epi8(result_vec, i_vec, mask_vec);\n        i_vec = _mm_sub_epi64(i_vec, _mm_set1_epi64x(4));\n    }\n\n    return _mm_extract_epi64(result_vec, 0);\n}\n```"}
{"task_id": "SimdBench_74_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> factorize_simd(int n) {\n    std::vector<int> factors;\n    __m128i divisor = _mm_set1_epi32(2);\n    __m128i zero = _mm_setzero_si128();\n    __m128i one = _mm_set1_epi32(1);\n\n    while (n > 1) {\n        __m128i num = _mm_set1_epi32(n);\n        __m128i remainder = _mm_rem_epi32(num, divisor);\n        int mask = _mm_movemask_epi8(_mm_cmpeq_epi32(remainder, zero));\n\n        if (mask == 0xFFFF) { // All elements are zero, divisible\n            n /= 2;\n            factors.push_back(2);\n        } else {\n            _mm_add_epi32(divisor, one);\n            int div = _mm_extract_epi32(divisor, 0);\n            while (n % div != 0) {\n                div += 2;\n            }\n            divisor = _mm_set1_epi32(div);\n            n /= div;\n            factors.push_back(div);\n        }\n    }\n\n    return factors;\n}\n```"}
{"task_id": "SimdBench_74_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> factorize_simd(int n) {\n    std::vector<int> factors;\n    __m128i divisor = _mm_set1_epi32(2);\n    __m128i zero = _mm_setzero_si128();\n    __m128i one = _mm_set1_epi32(1);\n\n    while (n > 1) {\n        __m128i num = _mm_set1_epi32(n);\n        __m128i remainder = _mm_rem_epi32(num, divisor);\n        int mask = _mm_movemask_epi8(_mm_cmpeq_epi32(remainder, zero));\n\n        if (mask == 0xFFFF) { // All elements are zero, divisible\n            n /= 2;\n            factors.push_back(2);\n        } else {\n            divisor = _mm_add_epi32(divisor, one);\n            int divisors[4];\n            _mm_storeu_si128((__m128i*)divisors, divisor);\n            bool found = false;\n            for (int i = 0; i < 4; ++i) {\n                if (n % divisors[i] == 0) {\n                    n /= divisors[i];\n                    factors.push_back(divisors[i]);\n                    found = true;\n                    break;\n                }\n            }\n            if (!found) {\n                divisor = _mm_set1_epi32(divisors[3] + 1);\n            }\n        }\n    }\n\n    return factors;\n}\n```"}
{"task_id": "SimdBench_74_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> factorize_simd(int n) {\n    std::vector<int> factors;\n    __m128i divisor = _mm_set1_epi32(2);\n    __m128i zero = _mm_setzero_si128();\n    __m128i one = _mm_set1_epi32(1);\n\n    while (n > 1) {\n        __m128i num = _mm_set1_epi32(n);\n        __m128i remainder = _mm_rem_epi32(num, divisor);\n        int mask = _mm_movemask_epi8(_mm_cmpeq_epi32(remainder, zero));\n\n        if (mask == 0xFFFF) { // All elements are zero, divisible\n            n /= 2;\n            factors.push_back(2);\n        } else {\n            divisor = _mm_add_epi32(divisor, one);\n            int divisors[4];\n            _mm_storeu_si128((__m128i*)divisors, divisor);\n            bool found = false;\n            for (int i = 0; i < 4; ++i) {\n                if (n % divisors[i] == 0) {\n                    n /= divisors[i];\n                    factors.push_back(divisors[i]);\n                    found = true;\n                    break;\n                }\n            }\n            if (!found) {\n                divisor = _mm_set1_epi32(divisors[3] + 1);\n            }\n        }\n    }\n\n    return factors;\n}\n```"}
{"task_id": "SimdBench_74_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> factorize_simd(int n) {\n    std::vector<int> factors;\n    __m128i divisor = _mm_set1_epi32(2);\n    __m128i zero = _mm_setzero_si128();\n    __m128i one = _mm_set1_epi32(1);\n\n    while (n > 1) {\n        __m128i num = _mm_set1_epi32(n);\n        __m128i remainder = _mm_rem_epi32(num, divisor);\n        int mask = _mm_movemask_epi8(_mm_cmpeq_epi32(remainder, zero));\n\n        if (mask == 0xFFFF) { // All elements are zero, divisor is a factor\n            n /= 2;\n            factors.push_back(2);\n        } else {\n            divisor = _mm_add_epi32(divisor, one);\n        }\n    }\n\n    return factors;\n}\n```"}
{"task_id": "SimdBench_74_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> factorize_simd(int n) {\n    std::vector<int> factors;\n    __m128i divisor = _mm_set1_epi32(2);\n    __m128i zero = _mm_setzero_si128();\n    __m128i one = _mm_set1_epi32(1);\n\n    while (n > 1) {\n        __m128i num = _mm_set1_epi32(n);\n        __m128i remainder = _mm_rem_epi32(num, divisor);\n        int mask = _mm_movemask_epi8(_mm_cmpeq_epi32(remainder, zero));\n\n        if (mask == 0xFFFF) { // All elements are zero, divisible\n            n /= 2;\n            factors.push_back(2);\n        } else {\n            divisor = _mm_add_epi32(divisor, one);\n            int div[4];\n            _mm_storeu_si128((__m128i*)div, divisor);\n            for (int i = 0; i < 4 && div[i] * div[i] <= n; ++i) {\n                while (n % div[i] == 0) {\n                    n /= div[i];\n                    factors.push_back(div[i]);\n                }\n            }\n        }\n    }\n\n    return factors;\n}\n```"}
{"task_id": "SimdBench_75_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<float> get_positive_simd(const std::vector<float> & l){\n    std::vector<float> result;\n    int n = l.size();\n    int i = 0;\n\n    __m128 zero = _mm_setzero_ps();\n\n    while (i <= n - 4) {\n        __m128 input = _mm_loadu_ps(&l[i]);\n        __m128 mask = _mm_cmpgt_ps(input, zero);\n        float output[4];\n        _mm_storeu_ps(output, _mm_and_ps(input, mask));\n\n        for (int j = 0; j < 4; ++j) {\n            if (output[j] != 0) {\n                result.push_back(output[j]);\n            }\n        }\n        i += 4;\n    }\n\n    while (i < n) {\n        if (l[i] > 0) {\n            result.push_back(l[i]);\n        }\n        i++;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_75_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<float> get_positive_simd(const std::vector<float> & l){\n    std::vector<float> result;\n    int n = l.size();\n    int i = 0;\n\n    __m128 zero = _mm_setzero_ps();\n\n    while (i <= n - 4) {\n        __m128 input = _mm_loadu_ps(&l[i]);\n        __m128 mask = _mm_cmpgt_ps(input, zero);\n        float output[4];\n        _mm_storeu_ps(output, _mm_and_ps(input, mask));\n\n        for (int j = 0; j < 4; ++j) {\n            if (output[j] != 0) {\n                result.push_back(output[j]);\n            }\n        }\n        i += 4;\n    }\n\n    while (i < n) {\n        if (l[i] > 0) {\n            result.push_back(l[i]);\n        }\n        i++;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_75_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<float> get_positive_simd(const std::vector<float> & l){\n    std::vector<float> result;\n    int n = l.size();\n    int i = 0;\n\n    __m128 zero = _mm_setzero_ps();\n\n    while (i <= n - 4) {\n        __m128 input = _mm_loadu_ps(&l[i]);\n        __m128 mask = _mm_cmpgt_ps(input, zero);\n        float output[4];\n        _mm_storeu_ps(output, _mm_and_ps(input, mask));\n\n        for (int j = 0; j < 4; ++j) {\n            if (output[j] != 0) {\n                result.push_back(output[j]);\n            }\n        }\n        i += 4;\n    }\n\n    while (i < n) {\n        if (l[i] > 0) {\n            result.push_back(l[i]);\n        }\n        i++;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_75_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<float> get_positive_simd(const std::vector<float> & l){\n    std::vector<float> result;\n    int n = l.size();\n    int i = 0;\n\n    __m128 zero = _mm_setzero_ps();\n\n    while (i <= n - 4) {\n        __m128 input = _mm_loadu_ps(&l[i]);\n        __m128 mask = _mm_cmpgt_ps(input, zero);\n        int mask_int = _mm_movemask_ps(mask);\n\n        if (mask_int == 0xF) {\n            result.insert(result.end(), &l[i], &l[i + 4]);\n        } else {\n            for (int j = 0; j < 4; ++j) {\n                if ((mask_int >> j) & 1) {\n                    result.push_back(l[i + j]);\n                }\n            }\n        }\n        i += 4;\n    }\n\n    while (i < n) {\n        if (l[i] > 0) {\n            result.push_back(l[i]);\n        }\n        i++;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_75_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<float> get_positive_simd(const std::vector<float> & l){\n    std::vector<float> result;\n    int n = l.size();\n    int i = 0;\n\n    __m128 zero = _mm_setzero_ps();\n\n    while (i <= n - 4) {\n        __m128 input = _mm_loadu_ps(&l[i]);\n        __m128 mask = _mm_cmpgt_ps(input, zero);\n        float output[4];\n        _mm_storeu_ps(output, _mm_and_ps(input, mask));\n\n        for (int j = 0; j < 4; ++j) {\n            if (output[j] != 0.0f) {\n                result.push_back(output[j]);\n            }\n        }\n        i += 4;\n    }\n\n    while (i < n) {\n        if (l[i] > 0.0f) {\n            result.push_back(l[i]);\n        }\n        i++;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_76_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool is_prime_simd(int64_t n) {\n    if (n <= 1) return false;\n    if (n <= 3) return true;\n    if (n % 2 == 0 || n % 3 == 0) return false;\n\n    __m128i increments = _mm_set_epi32(0, 6, 4, 6);\n    __m128i i = _mm_set1_epi32(5);\n    int32_t results[4];\n\n    while (true) {\n        __m128i i_squared = _mm_mullo_epi32(i, i);\n        _mm_storeu_si128((__m128i*)results, i_squared);\n\n        if (results[0] > n && results[1] > n && results[2] > n && results[3] > n) break;\n\n        __m128i n_vec = _mm_set1_epi32(n);\n        __m128i mod_results = _mm_rem_epi32(n_vec, i);\n\n        _mm_storeu_si128((__m128i*)results, mod_results);\n\n        if (results[0] == 0 || results[1] == 0 || results[2] == 0 || results[3] == 0) return false;\n\n        i = _mm_add_epi32(i, increments);\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_76_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool is_prime_simd(int64_t n) {\n    if (n <= 1) return false;\n    if (n <= 3) return true;\n    if ((n % 2 == 0) || (n % 3 == 0)) return false;\n\n    __m128i increments = _mm_set_epi32(0, 6, 4, 2);\n    __m128i i = _mm_set1_epi32(5);\n    int32_t results[4];\n\n    while (true) {\n        __m128i i_squared = _mm_mullo_epi32(i, i);\n        _mm_storeu_si128((__m128i*)results, i_squared);\n        if (results[0] > n && results[1] > n && results[2] > n && results[3] > n) break;\n\n        __m128i n_vec = _mm_set1_epi32(n);\n        __m128i div_results = _mm_div_epi32(n_vec, i);\n        __m128i remainders = _mm_sub_epi32(n_vec, _mm_mullo_epi32(div_results, i));\n        __m128i zero_mask = _mm_cmpeq_epi32(remainders, _mm_setzero_si128());\n\n        if (_mm_movemask_epi8(zero_mask) != 0) return false;\n\n        i = _mm_add_epi32(i, increments);\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_76_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool is_prime_simd(int64_t n) {\n    if (n <= 1) return false;\n    if (n <= 3) return true;\n    if (n % 2 == 0 || n % 3 == 0) return false;\n\n    __m128i increments = _mm_set_epi32(0, 6, 4, 2);\n    __m128i i = _mm_set1_epi32(5);\n    int32_t results[4];\n\n    while (true) {\n        __m128i i_squared = _mm_mullo_epi32(i, i);\n        _mm_storeu_si128((__m128i*)results, i_squared);\n        if (results[0] > n && results[1] > n && results[2] > n && results[3] > n) break;\n\n        __m128i n_vec = _mm_set1_epi32(n);\n        __m128i div_results = _mm_div_epi32(n_vec, i);\n        __m128i remainders = _mm_sub_epi32(n_vec, _mm_mullo_epi32(div_results, i));\n        __m128i zero_mask = _mm_cmpeq_epi32(remainders, _mm_setzero_si128());\n        if (_mm_movemask_epi8(zero_mask) != 0) return false;\n\n        i = _mm_add_epi32(i, increments);\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_76_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool is_prime_simd(int64_t n) {\n    if (n <= 1) return false;\n    if (n <= 3) return true;\n    if ((n % 2 == 0) || (n % 3 == 0)) return false;\n\n    __m128i increments = _mm_set_epi32(0, 6, 4, 2);\n    __m128i i = _mm_set1_epi32(5);\n    int32_t results[4];\n\n    while (true) {\n        __m128i i_squared = _mm_mullo_epi32(i, i);\n        _mm_storeu_si128((__m128i*)results, i_squared);\n        if (results[0] > n && results[1] > n && results[2] > n && results[3] > n) break;\n\n        __m128i n_vec = _mm_set1_epi32(n);\n        __m128i div_results = _mm_div_epi32(n_vec, i);\n        __m128i remainders = _mm_sub_epi32(n_vec, _mm_mullo_epi32(div_results, i));\n        __m128i zero_mask = _mm_cmpeq_epi32(remainders, _mm_setzero_si128());\n        if (_mm_movemask_epi8(zero_mask) != 0) return false;\n\n        i = _mm_add_epi32(i, increments);\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_76_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool is_prime_simd(int64_t n) {\n    if (n <= 1) return false;\n    if (n <= 3) return true;\n    if ((n % 2 == 0) || (n % 3 == 0)) return false;\n\n    __m128i increments = _mm_set_epi32(0, 6, 4, 2);\n    __m128i i = _mm_set1_epi32(5);\n    int32_t results[4];\n\n    while (true) {\n        __m128i i_squared = _mm_mullo_epi32(i, i);\n        _mm_storeu_si128((__m128i*)results, i_squared);\n\n        if (results[0] > n && results[1] > n && results[2] > n && results[3] > n) break;\n\n        __m128i n_vec = _mm_set1_epi32(n);\n        __m128i div_results = _mm_div_epi32(n_vec, i);\n        __m128i rem_results = _mm_sub_epi32(n_vec, _mm_mullo_epi32(div_results, i));\n        __m128i zero_mask = _mm_cmpeq_epi32(rem_results, _mm_setzero_si128());\n\n        if (_mm_movemask_epi8(zero_mask) != 0) return false;\n\n        i = _mm_add_epi32(i, increments);\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_77_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n#include <algorithm>\n\nstd::string solve_simd(const std::string & s) {\n    int n = s.size();\n    if (n == 0) return s;\n\n    std::string result(n, ' ');\n\n    const __m128i lower_mask = _mm_set1_epi8(0x20);\n    const __m128i letter_mask = _mm_set1_epi8(0x5F);\n    const __m128i a_z_mask = _mm_setr_epi8('a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p');\n    const __m128i A_Z_mask = _mm_setr_epi8('A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P');\n\n    bool has_letters = false;\n    for (int i = 0; i < n; i += 16) {\n        __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(s.data() + i));\n        __m128i is_letter = _mm_cmpeq_epi8(_mm_and_si128(chunk, letter_mask), a_z_mask);\n        __m128i is_upper = _mm_cmpeq_epi8(_mm_and_si128(chunk, letter_mask), A_Z_mask);\n        __m128i toggled = _mm_xor_si128(chunk, lower_mask);\n        __m128i result_chunk = _mm_or_si128(_mm_andnot_si128(is_letter, chunk), _mm_and_si128(is_letter, toggled));\n\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(result.data() + i), result_chunk);\n\n        has_letters |= _mm_movemask_epi8(_mm_or_si128(is_letter, is_upper)) != 0;\n    }\n\n    if (!has_letters) {\n        std::reverse(result.begin(), result.end());\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_77_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n#include <algorithm>\n\nstd::string solve_simd(const std::string & s) {\n    int n = s.size();\n    if (n == 0) return s;\n\n    std::string result(n, ' ');\n    bool has_letters = false;\n\n    for (int i = 0; i <= n - 16; i += 16) {\n        __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(s.data() + i));\n        __m128i lower_mask = _mm_and_si128(chunk, _mm_set1_epi8(0x20));\n        __m128i is_alpha = _mm_or_si128(_mm_cmpgt_epi8(chunk, _mm_set1_epi8('A' - 1)),\n                                         _mm_cmpgt_epi8(chunk, _mm_set1_epi8('a' - 1)));\n        __m128i is_alpha_lower = _mm_and_si128(is_alpha, _mm_cmpgt_epi8(chunk, _mm_set1_epi8('Z')));\n        __m128i is_alpha_upper = _mm_and_si128(is_alpha, _mm_cmplt_epi8(chunk, _mm_set1_epi8('a')));\n        __m128i toggle_case = _mm_or_si128(is_alpha_lower, is_alpha_upper);\n        __m128i toggled_chunk = _mm_xor_si128(chunk, _mm_and_si128(toggle_case, _mm_set1_epi8(0x20)));\n\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(result.data() + i), toggled_chunk);\n        has_letters |= _mm_movemask_epi8(toggle_case) != 0;\n    }\n\n    for (int i = (n / 16) * 16; i < n; ++i) {\n        char c = s[i];\n        if ((c >= 'a' && c <= 'z') || (c >= 'A' && c <= 'Z')) {\n            has_letters = true;\n            c ^= 0x20;\n        }\n        result[i] = c;\n    }\n\n    if (!has_letters) {\n        std::reverse(result.begin(), result.end());\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_77_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n#include <algorithm>\n\nstd::string solve_simd(const std::string & s) {\n    int len = s.size();\n    if (len == 0) return s;\n\n    std::string result(len, ' ');\n\n    const __m128i lower_mask = _mm_set1_epi8(0x20);\n    const __m128i letter_mask = _mm_set1_epi8(0x5F);\n    const __m128i zero = _mm_setzero_si128();\n\n    int i = 0;\n    bool has_letters = false;\n\n    for (; i <= len - 16; i += 16) {\n        __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(s.data() + i));\n        __m128i is_letter = _mm_and_si128(chunk, letter_mask);\n        __m128i is_lower = _mm_cmpgt_epi8(is_letter, _mm_set1_epi8('`'));\n        __m128i is_upper = _mm_cmpgt_epi8(_mm_set1_epi8('['), is_letter);\n        __m128i toggle_case = _mm_and_si128(_mm_or_si128(is_lower, is_upper), lower_mask);\n        __m128i result_chunk = _mm_xor_si128(chunk, toggle_case);\n\n        has_letters |= !_mm_test_all_zeros(toggle_case, toggle_case);\n\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(result.data() + i), result_chunk);\n    }\n\n    for (; i < len; ++i) {\n        char c = s[i];\n        if ((c >= 'a' && c <= 'z') || (c >= 'A' && c <= 'Z')) {\n            has_letters = true;\n            result[i] = (c >= 'a' && c <= 'z') ? (c - 'a' + 'A') : (c - 'A' + 'a');\n        } else {\n            result[i] = c;\n        }\n    }\n\n    if (!has_letters) {\n        std::reverse(result.begin(), result.end());\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_77_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n#include <algorithm>\n\nstd::string solve_simd(const std::string & s) {\n    int n = s.size();\n    if (n == 0) return s;\n\n    std::string result(n, ' ');\n    bool has_letters = false;\n\n    for (int i = 0; i <= n - 16; i += 16) {\n        __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(s.data() + i));\n        __m128i lower_mask = _mm_cmplt_epi8(chunk, _mm_set1_epi8('a'));\n        __m128i upper_mask = _mm_cmpgt_epi8(chunk, _mm_set1_epi8('Z'));\n        __m128i letter_mask = _mm_andnot_si128(_mm_or_si128(lower_mask, upper_mask), _mm_or_si128(_mm_cmpgt_epi8(chunk, _mm_set1_epi8('@')), _mm_cmplt_epi8(chunk, _mm_set1_epi8('['))));\n\n        if (!_mm_testz_si128(letter_mask, letter_mask)) {\n            has_letters = true;\n            __m128i lower_case = _mm_and_si128(letter_mask, _mm_cmpgt_epi8(chunk, _mm_set1_epi8('`')));\n            __m128i upper_case = _mm_and_si128(letter_mask, _mm_cmpgt_epi8(chunk, _mm_set1_epi8('A')));\n            __m128i toggle_case = _mm_or_si128(lower_case, upper_case);\n            chunk = _mm_xor_si128(chunk, _mm_and_si128(toggle_case, _mm_set1_epi8(0x20)));\n        }\n\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(result.data() + i), chunk);\n    }\n\n    for (int i = (n / 16) * 16; i < n; ++i) {\n        if (isalpha(s[i])) {\n            has_letters = true;\n            result[i] = islower(s[i]) ? toupper(s[i]) : tolower(s[i]);\n        } else {\n            result[i] = s[i];\n        }\n    }\n\n    if (!has_letters) {\n        std::reverse(result.begin(), result.end());\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_77_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n#include <algorithm>\n\nstd::string solve_simd(const std::string & s) {\n    int len = s.size();\n    if (len == 0) return s;\n\n    std::string result(len, ' ');\n\n    const __m128i lower_mask = _mm_set1_epi8(0x20);\n    const __m128i letter_mask = _mm_set1_epi8(0x5F);\n    const __m128i zero = _mm_setzero_si128();\n\n    int i = 0;\n    bool has_letters = false;\n\n    for (; i <= len - 16; i += 16) {\n        __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(s.data() + i));\n        __m128i is_letter = _mm_and_si128(chunk, letter_mask);\n        __m128i is_lower = _mm_cmpgt_epi8(is_letter, _mm_set1_epi8('`'));\n        __m128i is_upper = _mm_cmpgt_epi8(is_letter, _mm_set1_epi8('@'));\n        __m128i toggle_case = _mm_and_si128(_mm_or_si128(is_lower, is_upper), lower_mask);\n        __m128i result_chunk = _mm_xor_si128(chunk, toggle_case);\n\n        has_letters |= !_mm_test_all_zeros(_mm_or_si128(is_lower, is_upper), zero);\n\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(result.data() + i), result_chunk);\n    }\n\n    for (; i < len; ++i) {\n        char c = s[i];\n        if ((c >= 'a' && c <= 'z') || (c >= 'A' && c <= 'Z')) {\n            has_letters = true;\n            result[i] = (c >= 'a' && c <= 'z') ? (c - 'a' + 'A') : (c - 'A' + 'a');\n        } else {\n            result[i] = c;\n        }\n    }\n\n    if (!has_letters) {\n        std::reverse(result.begin(), result.end());\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_78_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<int> sort_third_simd(std::vector<int> l) {\n    int n = l.size();\n    std::vector<int> sorted_elements;\n\n    // Collect elements at indices divisible by 3\n    for (int i = 0; i < n; i += 3) {\n        sorted_elements.push_back(l[i]);\n    }\n\n    // Sort the collected elements\n    std::sort(sorted_elements.begin(), sorted_elements.end());\n\n    // Place sorted elements back into their original positions\n    for (int i = 0, j = 0; i < n; i += 3, ++j) {\n        l[i] = sorted_elements[j];\n    }\n\n    return l;\n}\n```"}
{"task_id": "SimdBench_78_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<int> sort_third_simd(std::vector<int> l) {\n    int n = l.size();\n    std::vector<int> sorted_thirds;\n    \n    // Collect elements at indices divisible by 3\n    for (int i = 0; i < n; i += 3) {\n        sorted_thirds.push_back(l[i]);\n    }\n    \n    // Sort the collected elements\n    std::sort(sorted_thirds.begin(), sorted_thirds.end());\n    \n    // Use SSE to replace elements at indices divisible by 3 with sorted elements\n    __m128i* data = reinterpret_cast<__m128i*>(&l[0]);\n    __m128i* sorted_data = reinterpret_cast<__m128i*>(&sorted_thirds[0]);\n    int sorted_index = 0;\n    \n    for (int i = 0; i < n / 12; ++i) {\n        __m128i vec = _mm_loadu_si128(data + i);\n        __m128i mask = _mm_set_epi32(0xFFFFFFFF, 0, 0xFFFFFFFF, 0, 0xFFFFFFFF, 0, 0xFFFFFFFF, 0);\n        __m128i sorted_vec = _mm_loadu_si128(sorted_data + sorted_index);\n        sorted_index += 4;\n        \n        __m128i result = _mm_blendv_epi8(vec, sorted_vec, mask);\n        _mm_storeu_si128(data + i, result);\n    }\n    \n    // Handle remaining elements\n    for (int i = (n / 12) * 12; i < n; i += 3) {\n        if (i % 3 == 0) {\n            l[i] = sorted_thirds[sorted_index++];\n        }\n    }\n    \n    return l;\n}\n```"}
{"task_id": "SimdBench_78_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<int> sort_third_simd(std::vector<int> l) {\n    int n = l.size();\n    std::vector<int> sorted_thirds;\n    \n    // Collect elements at indices divisible by 3\n    for (int i = 0; i < n; i += 3) {\n        sorted_thirds.push_back(l[i]);\n    }\n    \n    // Sort the collected elements\n    std::sort(sorted_thirds.begin(), sorted_thirds.end());\n    \n    // Use SSE to replace elements at indices divisible by 3 with sorted elements\n    __m128i* data = reinterpret_cast<__m128i*>(&l[0]);\n    __m128i* sorted_data = reinterpret_cast<__m128i*>(&sorted_thirds[0]);\n    int sorted_index = 0;\n    \n    for (int i = 0; i < n / 12; ++i) {\n        __m128i vec = _mm_loadu_si128(data + i);\n        __m128i mask = _mm_set_epi32(0, -1, 0, -1, 0, -1, 0, -1); // Mask for indices divisible by 3\n        __m128i sorted_vec = _mm_loadu_si128(sorted_data + sorted_index);\n        sorted_index += 3;\n        \n        // Blend the sorted values into the original vector at the correct positions\n        vec = _mm_blendv_epi8(vec, sorted_vec, mask);\n        _mm_storeu_si128(data + i, vec);\n    }\n    \n    // Handle remaining elements\n    for (int i = (n / 12) * 12; i < n; i += 3) {\n        if (i < n) l[i] = sorted_thirds[sorted_index++];\n        if (i + 1 < n) l[i + 1] = l[i + 1];\n        if (i + 2 < n) l[i + 2] = l[i + 2];\n    }\n    \n    return l;\n}\n```"}
{"task_id": "SimdBench_78_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<int> sort_third_simd(std::vector<int> l) {\n    int n = l.size();\n    std::vector<int> sorted_elements;\n\n    // Collect elements at indices divisible by 3\n    for (int i = 0; i < n; i += 3) {\n        sorted_elements.push_back(l[i]);\n    }\n\n    // Sort the collected elements\n    std::sort(sorted_elements.begin(), sorted_elements.end());\n\n    // Place sorted elements back into their original positions\n    for (int i = 0, j = 0; i < n; i += 3, ++j) {\n        l[i] = sorted_elements[j];\n    }\n\n    return l;\n}\n```"}
{"task_id": "SimdBench_78_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<int> sort_third_simd(std::vector<int> l) {\n    int n = l.size();\n    std::vector<int> sorted_elements;\n\n    // Collect elements at indices divisible by 3\n    for (int i = 0; i < n; i += 3) {\n        sorted_elements.push_back(l[i]);\n    }\n\n    // Sort the collected elements\n    std::sort(sorted_elements.begin(), sorted_elements.end());\n\n    // Place sorted elements back into their original positions\n    for (int i = 0, j = 0; i < n; i += 3, ++j) {\n        l[i] = sorted_elements[j];\n    }\n\n    return l;\n}\n```"}
{"task_id": "SimdBench_79_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nfloat max_element_simd(std::vector<float> l) {\n    __m128 max_val = _mm_set1_ps(l[0]);\n    size_t i = 0;\n    for (; i + 4 <= l.size(); i += 4) {\n        __m128 vec = _mm_loadu_ps(&l[i]);\n        max_val = _mm_max_ps(max_val, vec);\n    }\n    float max_array[4];\n    _mm_storeu_ps(max_array, max_val);\n    float max_result = max_array[0];\n    for (size_t j = 1; j < 4; ++j) {\n        if (max_array[j] > max_result) {\n            max_result = max_array[j];\n        }\n    }\n    for (; i < l.size(); ++i) {\n        if (l[i] > max_result) {\n            max_result = l[i];\n        }\n    }\n    return max_result;\n}\n```"}
{"task_id": "SimdBench_79_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nfloat max_element_simd(std::vector<float> l) {\n    __m128 max_val = _mm_set1_ps(l[0]);\n    size_t i = 0;\n    for (; i + 4 <= l.size(); i += 4) {\n        __m128 vec = _mm_loadu_ps(&l[i]);\n        max_val = _mm_max_ps(max_val, vec);\n    }\n    float max_array[4];\n    _mm_storeu_ps(max_array, max_val);\n    float max_result = max_array[0];\n    for (size_t j = 1; j < 4; ++j) {\n        if (max_array[j] > max_result) {\n            max_result = max_array[j];\n        }\n    }\n    for (; i < l.size(); ++i) {\n        if (l[i] > max_result) {\n            max_result = l[i];\n        }\n    }\n    return max_result;\n}\n```"}
{"task_id": "SimdBench_79_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nfloat max_element_simd(const std::vector<float>& l) {\n    __m128 max_val = _mm_set1_ps(l[0]);\n    size_t i = 0;\n    for (; i + 4 <= l.size(); i += 4) {\n        __m128 vec = _mm_loadu_ps(&l[i]);\n        max_val = _mm_max_ps(max_val, vec);\n    }\n    float max_array[4];\n    _mm_storeu_ps(max_array, max_val);\n    float max_result = max_array[0];\n    for (size_t j = 1; j < 4; ++j) {\n        if (max_array[j] > max_result) {\n            max_result = max_array[j];\n        }\n    }\n    for (; i < l.size(); ++i) {\n        if (l[i] > max_result) {\n            max_result = l[i];\n        }\n    }\n    return max_result;\n}\n```"}
{"task_id": "SimdBench_79_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nfloat max_element_simd(std::vector<float> l) {\n    __m128 max_val = _mm_set1_ps(l[0]);\n    size_t i = 0;\n    for (; i + 4 <= l.size(); i += 4) {\n        __m128 vec = _mm_loadu_ps(&l[i]);\n        max_val = _mm_max_ps(max_val, vec);\n    }\n    float max_array[4];\n    _mm_storeu_ps(max_array, max_val);\n    float max_result = max_array[0];\n    for (size_t j = 1; j < 4; ++j) {\n        if (max_array[j] > max_result) {\n            max_result = max_array[j];\n        }\n    }\n    for (; i < l.size(); ++i) {\n        if (l[i] > max_result) {\n            max_result = l[i];\n        }\n    }\n    return max_result;\n}\n```"}
{"task_id": "SimdBench_79_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nfloat max_element_simd(std::vector<float> l) {\n    __m128 max_val = _mm_set1_ps(l[0]);\n    size_t i = 0;\n    for (; i + 4 <= l.size(); i += 4) {\n        __m128 vec = _mm_loadu_ps(&l[i]);\n        max_val = _mm_max_ps(max_val, vec);\n    }\n    float max_array[4];\n    _mm_storeu_ps(max_array, max_val);\n    float max_result = max_array[0];\n    for (size_t j = 1; j < 4; ++j) {\n        if (max_array[j] > max_result) {\n            max_result = max_array[j];\n        }\n    }\n    for (; i < l.size(); ++i) {\n        if (l[i] > max_result) {\n            max_result = l[i];\n        }\n    }\n    return max_result;\n}\n```"}
{"task_id": "SimdBench_80_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint fizz_buzz_simd(int n) {\n    int count = 0;\n    __m128i seven = _mm_set1_epi32(7);\n    __m128i eleven = _mm_set1_epi32(11);\n    __m128i thirteen = _mm_set1_epi32(13);\n    __m128i zero = _mm_setzero_si128();\n    __m128i mask = _mm_set1_epi32(0xF);\n\n    for (int i = 0; i < n; i += 4) {\n        __m128i nums = _mm_setr_epi32(i, i + 1, i + 2, i + 3);\n        __m128i div_by_11 = _mm_cmpeq_epi32(_mm_mod_epi32(nums, eleven), zero);\n        __m128i div_by_13 = _mm_cmpeq_epi32(_mm_mod_epi32(nums, thirteen), zero);\n        __m128i div_by_11_or_13 = _mm_or_si128(div_by_11, div_by_13);\n\n        for (int j = 0; j < 4; ++j) {\n            if (_mm_extract_epi32(div_by_11_or_13, j)) {\n                int num = i + j;\n                while (num > 0) {\n                    if ((num % 10) == 7) {\n                        count++;\n                    }\n                    num /= 10;\n                }\n            }\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_80_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint fizz_buzz_simd(int n){\n    int count = 0;\n    __m128i seven = _mm_set1_epi32(7);\n    __m128i eleven = _mm_set1_epi32(11);\n    __m128i thirteen = _mm_set1_epi32(13);\n    __m128i zero = _mm_setzero_si128();\n    __m128i mask = _mm_set1_epi32(0xFFFFFFFF);\n\n    for (int i = 0; i < n; i += 4) {\n        __m128i nums = _mm_setr_epi32(i, i + 1, i + 2, i + 3);\n        __m128i div_by_11 = _mm_cmpeq_epi32(_mm_rem_epi32(nums, eleven), zero);\n        __m128i div_by_13 = _mm_cmpeq_epi32(_mm_rem_epi32(nums, thirteen), zero);\n        __m128i div_by_11_or_13 = _mm_or_si128(div_by_11, div_by_13);\n\n        __m128i nums_copy = nums;\n        __m128i count_sevens = _mm_setzero_si128();\n        for (int j = 0; j < 32; ++j) {\n            __m128i sevens_in_pos = _mm_cmpeq_epi32(nums_copy, seven);\n            count_sevens = _mm_add_epi32(count_sevens, _mm_and_si128(sevens_in_pos, div_by_11_or_13));\n            nums_copy = _mm_srli_epi32(nums_copy, 1);\n        }\n\n        __m128i horizontal_sum = _mm_add_epi32(count_sevens, _mm_srli_epi32(count_sevens, 16));\n        horizontal_sum = _mm_add_epi32(horizontal_sum, _mm_srli_epi32(horizontal_sum, 8));\n        count += _mm_cvtsi128_si32(horizontal_sum) & 0xFF;\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_80_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint fizz_buzz_simd(int n) {\n    int count = 0;\n    __m128i seven = _mm_set1_epi32(7);\n    __m128i eleven = _mm_set1_epi32(11);\n    __m128i thirteen = _mm_set1_epi32(13);\n    __m128i zero = _mm_setzero_si128();\n    __m128i mask = _mm_set1_epi32(0xF);\n\n    for (int i = 0; i < n; i += 4) {\n        __m128i nums = _mm_setr_epi32(i, i + 1, i + 2, i + 3);\n        __m128i div_by_11 = _mm_cmpeq_epi32(_mm_rem_epi32(nums, eleven), zero);\n        __m128i div_by_13 = _mm_cmpeq_epi32(_mm_rem_epi32(nums, thirteen), zero);\n        __m128i div_by_11_or_13 = _mm_or_si128(div_by_11, div_by_13);\n\n        for (int j = 0; j < 4; ++j) {\n            if ((i + j) >= n) break;\n            if (_mm_extract_epi32(div_by_11_or_13, j)) {\n                int num = i + j;\n                while (num > 0) {\n                    if ((num % 10) == 7) {\n                        count++;\n                    }\n                    num /= 10;\n                }\n            }\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_80_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint fizz_buzz_simd(int n){\n    int count = 0;\n    __m128i seven = _mm_set1_epi32(7);\n    __m128i eleven = _mm_set1_epi32(11);\n    __m128i thirteen = _mm_set1_epi32(13);\n    __m128i zero = _mm_setzero_si128();\n    __m128i mask = _mm_set1_epi32(0xF);\n\n    for (int i = 0; i < n; i += 4) {\n        __m128i nums = _mm_setr_epi32(i, i+1, i+2, i+3);\n        __m128i div_by_11 = _mm_cmpeq_epi32(_mm_mod_epi32(nums, eleven), zero);\n        __m128i div_by_13 = _mm_cmpeq_epi32(_mm_mod_epi32(nums, thirteen), zero);\n        __m128i div_by_11_or_13 = _mm_or_si128(div_by_11, div_by_13);\n\n        __m128i nums_masked = _mm_and_si128(nums, mask);\n        __m128i sevens = _mm_cmpeq_epi32(nums_masked, seven);\n        __m128i result = _mm_and_si128(sevens, div_by_11_or_13);\n\n        int mask_result = _mm_movemask_epi8(result);\n        count += __builtin_popcount(mask_result >> 28) + __builtin_popcount((mask_result >> 14) & 0xF) + __builtin_popcount((mask_result >> 7) & 0xF) + __builtin_popcount(mask_result & 0xF);\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_80_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint fizz_buzz_simd(int n) {\n    int count = 0;\n    __m128i seven = _mm_set1_epi32(7);\n    __m128i eleven = _mm_set1_epi32(11);\n    __m128i thirteen = _mm_set1_epi32(13);\n    __m128i zero = _mm_setzero_si128();\n    __m128i mask = _mm_set1_epi32(0xF);\n\n    for (int i = 0; i < n; i += 4) {\n        __m128i nums = _mm_setr_epi32(i, i + 1, i + 2, i + 3);\n        __m128i div_by_11 = _mm_cmpeq_epi32(_mm_rem_epi32(nums, eleven), zero);\n        __m128i div_by_13 = _mm_cmpeq_epi32(_mm_rem_epi32(nums, thirteen), zero);\n        __m128i div_by_11_or_13 = _mm_or_si128(div_by_11, div_by_13);\n\n        for (int j = 0; j < 4; ++j) {\n            if (_mm_extract_epi32(div_by_11_or_13, j)) {\n                int num = i + j;\n                while (num > 0) {\n                    if ((num % 10) == 7) {\n                        count++;\n                    }\n                    num /= 10;\n                }\n            }\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_81_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<float> sort_even_simd(std::vector<float> l) {\n    int n = l.size();\n    if (n < 2) return l;\n\n    __m128 vec = _mm_loadu_ps(&l[0]);\n    __m128 even_mask = _mm_set_ps(0, -1, 0, -1);\n    __m128 odd_mask = _mm_set_ps(-1, 0, -1, 0);\n\n    __m128 even_values = _mm_and_ps(vec, even_mask);\n    __m128 odd_values = _mm_and_ps(vec, odd_mask);\n\n    float even_array[4];\n    _mm_storeu_ps(even_array, even_values);\n\n    std::sort(even_array, even_array + 4);\n\n    __m128 sorted_even_values = _mm_set_ps(even_array[3], 0, even_array[1], 0);\n    __m128 result = _mm_or_ps(sorted_even_values, odd_values);\n\n    _mm_storeu_ps(&l[0], result);\n\n    return l;\n}\n```"}
{"task_id": "SimdBench_81_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<float> sort_even_simd(std::vector<float> l) {\n    int n = l.size();\n    if (n < 2) return l;\n\n    __m128 vec = _mm_loadu_ps(&l[0]);\n    __m128 even_mask = _mm_set_ps(0, -1, 0, -1);\n    __m128 odd_mask = _mm_set_ps(-1, 0, -1, 0);\n\n    __m128 even_values = _mm_and_ps(vec, even_mask);\n    __m128 odd_values = _mm_and_ps(vec, odd_mask);\n\n    float even_array[4];\n    _mm_storeu_ps(even_array, even_values);\n\n    std::sort(even_array, even_array + 4);\n\n    __m128 sorted_even_values = _mm_loadu_ps(even_array);\n    sorted_even_values = _mm_and_ps(sorted_even_values, even_mask);\n    odd_values = _mm_and_ps(odd_values, odd_mask);\n\n    __m128 result = _mm_or_ps(sorted_even_values, odd_values);\n\n    _mm_storeu_ps(&l[0], result);\n\n    return l;\n}\n```"}
{"task_id": "SimdBench_81_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<float> sort_even_simd(std::vector<float> l) {\n    int n = l.size();\n    if (n < 2) return l;\n\n    __m128 vec;\n    float temp[4];\n\n    for (int i = 0; i < n; i += 4) {\n        vec = _mm_loadu_ps(&l[i]);\n        _mm_storeu_ps(temp, vec);\n\n        // Sort only the even indices of the loaded vector\n        std::sort(&temp[0], &temp[0] + 1);\n        std::sort(&temp[2], &temp[2] + 1);\n\n        vec = _mm_loadu_ps(temp);\n        _mm_storeu_ps(&l[i], vec);\n    }\n\n    // Handle the remaining elements if n is not a multiple of 4\n    if (n % 4 != 0) {\n        std::sort(&l[n - n % 4], &l[n]);\n    }\n\n    return l;\n}\n```"}
{"task_id": "SimdBench_81_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<float> sort_even_simd(std::vector<float> l) {\n    int n = l.size();\n    if (n < 2) return l;\n\n    __m128 vec;\n    float temp[4];\n\n    for (int i = 0; i < n; i += 4) {\n        vec = _mm_loadu_ps(&l[i]);\n        _mm_storeu_ps(temp, vec);\n\n        // Sort only the even indices of the loaded vector\n        if (i + 2 < n) std::swap(temp[0], temp[2]);\n        if (i + 4 < n) std::sort(&temp[0], &temp[4], [](float a, float b) { return (int)&a % 8 < (int)&b % 8 ? a < b : true; });\n\n        vec = _mm_loadu_ps(temp);\n        _mm_storeu_ps(&l[i], vec);\n    }\n\n    // Handle the remaining elements if the size is not a multiple of 4\n    if (n % 4 != 0) {\n        std::sort(&l[n - n % 4], &l[n], [](float a, float b) { return (int)&a % 8 < (int)&b % 8 ? a < b : true; });\n    }\n\n    return l;\n}\n```"}
{"task_id": "SimdBench_81_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<float> sort_even_simd(std::vector<float> l) {\n    int n = l.size();\n    if (n < 2) return l;\n\n    __m128 vec = _mm_loadu_ps(&l[0]);\n    __m128 even_indices = _mm_setr_ps(l[0], l[2], l[4], l[6]);\n    __m128 odd_indices = _mm_setr_ps(l[1], l[3], l[5], l[7]);\n\n    float even_arr[4];\n    _mm_storeu_ps(even_arr, even_indices);\n\n    std::sort(even_arr, even_arr + (n / 2) + (n % 2));\n\n    even_indices = _mm_loadu_ps(even_arr);\n    vec = _mm_shuffle_ps(even_indices, odd_indices, _MM_SHUFFLE(2, 0, 2, 0));\n    _mm_storeu_ps(&l[0], vec);\n\n    if (n > 4) {\n        for (int i = 4; i < n; i += 4) {\n            vec = _mm_loadu_ps(&l[i]);\n            even_indices = _mm_setr_ps(l[i], l[i + 2], l[i + 4], l[i + 6]);\n            odd_indices = _mm_setr_ps(l[i + 1], l[i + 3], l[i + 5], l[i + 7]);\n\n            _mm_storeu_ps(even_arr, even_indices);\n            std::sort(even_arr, even_arr + (n - i) / 2 + ((n - i) % 2));\n\n            even_indices = _mm_loadu_ps(even_arr);\n            vec = _mm_shuffle_ps(even_indices, odd_indices, _MM_SHUFFLE(2, 0, 2, 0));\n            _mm_storeu_ps(&l[i], vec);\n        }\n    }\n\n    return l;\n}\n```"}
{"task_id": "SimdBench_82_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nbool triples_sum_to_zero_simd(std::vector<int> l) {\n    int n = l.size();\n    if (n < 3) return false;\n\n    for (int i = 0; i < n - 2; ++i) {\n        __m128i a = _mm_set1_epi32(-l[i]);\n        for (int j = i + 1; j < n - 1; j += 4) {\n            __m128i b = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&l[j]));\n            __m128i c = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&l[j + 1]));\n            __m128i sum1 = _mm_add_epi32(a, b);\n            __m128i sum2 = _mm_add_epi32(a, c);\n            __m128i cmp1 = _mm_cmpeq_epi32(sum1, _mm_loadu_si128(reinterpret_cast<const __m128i*>(&l[j + 2])));\n            __m128i cmp2 = _mm_cmpeq_epi32(sum2, _mm_loadu_si128(reinterpret_cast<const __m128i*>(&l[j + 3])));\n            if (_mm_movemask_epi8(cmp1) || _mm_movemask_epi8(cmp2)) {\n                return true;\n            }\n        }\n        for (int j = std::max(i + 1, n - 3); j < n - 1; ++j) {\n            for (int k = j + 1; k < n; ++k) {\n                if (l[i] + l[j] + l[k] == 0) {\n                    return true;\n                }\n            }\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_82_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nbool triples_sum_to_zero_simd(std::vector<int> l) {\n    int n = l.size();\n    if (n < 3) return false;\n\n    for (int i = 0; i < n - 2; ++i) {\n        __m128i a = _mm_set1_epi32(-l[i]);\n        for (int j = i + 1; j < n - 1; j += 4) {\n            __m128i b = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&l[j]));\n            __m128i c = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&l[j + 1]));\n            __m128i sum1 = _mm_add_epi32(a, b);\n            __m128i sum2 = _mm_add_epi32(a, c);\n            __m128i cmp1 = _mm_cmpeq_epi32(sum1, _mm_loadu_si128(reinterpret_cast<const __m128i*>(&l[j + 2])));\n            __m128i cmp2 = _mm_cmpeq_epi32(sum2, _mm_loadu_si128(reinterpret_cast<const __m128i*>(&l[j + 3])));\n            if (_mm_movemask_epi8(cmp1) || _mm_movemask_epi8(cmp2)) {\n                return true;\n            }\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_82_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nbool triples_sum_to_zero_simd(std::vector<int> l) {\n    int n = l.size();\n    if (n < 3) return false;\n\n    for (int i = 0; i < n - 2; ++i) {\n        __m128i a = _mm_set1_epi32(-l[i]);\n        for (int j = i + 1; j < n - 1; j += 4) {\n            __m128i b = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&l[j]));\n            __m128i c = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&l[j + 1]));\n            __m128i sum1 = _mm_add_epi32(a, b);\n            __m128i sum2 = _mm_add_epi32(a, c);\n            __m128i cmp1 = _mm_cmpeq_epi32(sum1, _mm_loadu_si128(reinterpret_cast<const __m128i*>(&l[j + 2])));\n            __m128i cmp2 = _mm_cmpeq_epi32(sum2, _mm_loadu_si128(reinterpret_cast<const __m128i*>(&l[j + 3])));\n            if (_mm_movemask_epi8(cmp1) || _mm_movemask_epi8(cmp2)) {\n                return true;\n            }\n        }\n        for (int j = std::max(i + 1, n - 3); j < n - 1; ++j) {\n            for (int k = j + 1; k < n; ++k) {\n                if (l[i] + l[j] + l[k] == 0) {\n                    return true;\n                }\n            }\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_82_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nbool triples_sum_to_zero_simd(std::vector<int> l) {\n    int n = l.size();\n    if (n < 3) return false;\n\n    for (int i = 0; i < n - 2; ++i) {\n        __m128i a = _mm_set1_epi32(-l[i]);\n        for (int j = i + 1; j < n - 1; j += 4) {\n            __m128i b = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&l[j]));\n            __m128i c = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&l[j + 1]));\n            __m128i sum1 = _mm_add_epi32(a, b);\n            __m128i sum2 = _mm_add_epi32(a, c);\n            __m128i cmp1 = _mm_cmpeq_epi32(sum1, _mm_loadu_si128(reinterpret_cast<const __m128i*>(&l[j + 2])));\n            __m128i cmp2 = _mm_cmpeq_epi32(sum2, _mm_loadu_si128(reinterpret_cast<const __m128i*>(&l[j + 3])));\n            if (_mm_movemask_epi8(cmp1) || _mm_movemask_epi8(cmp2)) {\n                return true;\n            }\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_82_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nbool triples_sum_to_zero_simd(std::vector<int> l) {\n    int n = l.size();\n    if (n < 3) return false;\n\n    for (int i = 0; i < n - 2; ++i) {\n        __m128i a = _mm_set1_epi32(-l[i]);\n        for (int j = i + 1; j < n - 1; j += 4) {\n            __m128i b = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&l[j]));\n            __m128i c = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&l[j + 1]));\n            __m128i sum1 = _mm_add_epi32(a, b);\n            __m128i sum2 = _mm_add_epi32(a, c);\n            __m128i cmp1 = _mm_cmpeq_epi32(sum1, _mm_loadu_si128(reinterpret_cast<const __m128i*>(&l[j + 2])));\n            __m128i cmp2 = _mm_cmpeq_epi32(sum2, _mm_loadu_si128(reinterpret_cast<const __m128i*>(&l[j + 3])));\n            if (_mm_movemask_epi8(cmp1) || _mm_movemask_epi8(cmp2)) {\n                return true;\n            }\n        }\n        for (int j = std::max(i + 1, n - 3); j < n - 1; ++j) {\n            for (int k = j + 1; k < n; ++k) {\n                if (l[i] + l[j] + l[k] == 0) {\n                    return true;\n                }\n            }\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_83_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> incr_list_simd(std::vector<int> l) {\n    int n = l.size();\n    std::vector<int> result(n);\n\n    __m128i increment = _mm_set1_epi32(1);\n\n    for (int i = 0; i <= n - 4; i += 4) {\n        __m128i vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&l[i]));\n        vec = _mm_add_epi32(vec, increment);\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i]), vec);\n    }\n\n    for (int i = (n / 4) * 4; i < n; ++i) {\n        result[i] = l[i] + 1;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_83_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> incr_list_simd(std::vector<int> l) {\n    int n = l.size();\n    std::vector<int> result(n);\n    int* input = l.data();\n    int* output = result.data();\n    __m128i increment = _mm_set1_epi32(1);\n\n    for (int i = 0; i <= n - 4; i += 4) {\n        __m128i vec = _mm_loadu_si128((__m128i*)&input[i]);\n        vec = _mm_add_epi32(vec, increment);\n        _mm_storeu_si128((__m128i*)&output[i], vec);\n    }\n\n    for (int i = (n / 4) * 4; i < n; ++i) {\n        output[i] = input[i] + 1;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_83_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> incr_list_simd(std::vector<int> l) {\n    int n = l.size();\n    std::vector<int> result(n);\n    int i = 0;\n\n    __m128i increment = _mm_set1_epi32(1);\n\n    for (; i <= n - 4; i += 4) {\n        __m128i vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&l[i]));\n        vec = _mm_add_epi32(vec, increment);\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i]), vec);\n    }\n\n    for (; i < n; ++i) {\n        result[i] = l[i] + 1;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_83_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> incr_list_simd(std::vector<int> l) {\n    int n = l.size();\n    std::vector<int> result(n);\n\n    __m128i increment = _mm_set1_epi32(1);\n    int i = 0;\n    for (; i <= n - 4; i += 4) {\n        __m128i vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&l[i]));\n        vec = _mm_add_epi32(vec, increment);\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i]), vec);\n    }\n\n    for (; i < n; ++i) {\n        result[i] = l[i] + 1;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_83_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> incr_list_simd(std::vector<int> l) {\n    int n = l.size();\n    std::vector<int> result(n);\n\n    __m128i increment = _mm_set1_epi32(1);\n    int i = 0;\n    for (; i <= n - 4; i += 4) {\n        __m128i vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&l[i]));\n        vec = _mm_add_epi32(vec, increment);\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i]), vec);\n    }\n\n    for (; i < n; ++i) {\n        result[i] = l[i] + 1;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_84_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nbool pairs_sum_to_zero_simd(std::vector<int> l) {\n    int n = l.size();\n    if (n < 2) return false;\n\n    __m128i zero = _mm_setzero_si128();\n\n    for (int i = 0; i < n; ++i) {\n        __m128i a = _mm_set1_epi32(l[i]);\n        for (int j = i + 1; j <= n - 4; j += 4) {\n            __m128i b = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&l[j]));\n            __m128i sum = _mm_add_epi32(a, b);\n            __m128i mask = _mm_cmpeq_epi32(sum, zero);\n            if (!_mm_test_all_zeros(mask, mask)) {\n                return true;\n            }\n        }\n        for (int j = n - (n % 4); j < n; ++j) {\n            if (l[i] + l[j] == 0) {\n                return true;\n            }\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_84_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nbool pairs_sum_to_zero_simd(std::vector<int> l) {\n    int n = l.size();\n    if (n < 2) return false;\n\n    __m128i zero = _mm_setzero_si128();\n\n    for (int i = 0; i < n; ++i) {\n        __m128i a = _mm_set1_epi32(l[i]);\n        for (int j = i + 1; j <= n - 4; j += 4) {\n            __m128i b = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&l[j]));\n            __m128i sum = _mm_add_epi32(a, b);\n            __m128i mask = _mm_cmpeq_epi32(sum, zero);\n            if (!_mm_test_all_zeros(mask, mask)) {\n                return true;\n            }\n        }\n        for (int j = std::max(i + 1, n - 3); j < n; ++j) {\n            if (l[i] + l[j] == 0) {\n                return true;\n            }\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_84_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nbool pairs_sum_to_zero_simd(std::vector<int> l) {\n    int n = l.size();\n    if (n < 2) return false;\n\n    __m128i zero = _mm_setzero_si128();\n\n    for (int i = 0; i < n; ++i) {\n        __m128i a = _mm_set1_epi32(l[i]);\n        for (int j = i + 1; j <= n - 4; j += 4) {\n            __m128i b = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&l[j]));\n            __m128i sum = _mm_add_epi32(a, b);\n            __m128i cmp = _mm_cmpeq_epi32(sum, zero);\n            if (_mm_movemask_epi8(cmp) != 0) {\n                return true;\n            }\n        }\n        for (int j = n - (n % 4); j < n; ++j) {\n            if (l[i] + l[j] == 0) {\n                return true;\n            }\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_84_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nbool pairs_sum_to_zero_simd(std::vector<int> l) {\n    int n = l.size();\n    if (n < 2) return false;\n\n    __m128i zero = _mm_setzero_si128();\n\n    for (int i = 0; i < n; ++i) {\n        __m128i a = _mm_set1_epi32(l[i]);\n        for (int j = i + 1; j <= n - 4; j += 4) {\n            __m128i b = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&l[j]));\n            __m128i sum = _mm_add_epi32(a, b);\n            __m128i mask = _mm_cmpeq_epi32(sum, zero);\n            if (!_mm_test_all_zeros(mask, mask)) {\n                return true;\n            }\n        }\n        for (int j = n - (n % 4); j < n; ++j) {\n            if (l[i] + l[j] == 0) {\n                return true;\n            }\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_84_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nbool pairs_sum_to_zero_simd(std::vector<int> l) {\n    int n = l.size();\n    if (n < 2) return false;\n\n    __m128i zero = _mm_setzero_si128();\n\n    for (int i = 0; i < n; ++i) {\n        __m128i a = _mm_set1_epi32(l[i]);\n        for (int j = i + 1; j <= n - 4; j += 4) {\n            __m128i b = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&l[j]));\n            __m128i sum = _mm_add_epi32(a, b);\n            __m128i mask = _mm_cmpeq_epi32(sum, zero);\n            if (!_mm_test_all_zeros(mask, mask)) {\n                return true;\n            }\n        }\n        for (int j = n - (n % 4); j < n; ++j) {\n            if (l[i] + l[j] == 0) {\n                return true;\n            }\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_85_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n#include <algorithm>\n\nstd::string change_base_simd(int64_t x, int8_t base) {\n    if (base < 2 || base > 9) return \"\";\n\n    char buffer[65];\n    int index = 64;\n    buffer[index] = '\\0';\n\n    __m128i zero = _mm_setzero_si128();\n    __m128i base_vec = _mm_set1_epi8(base);\n    __m128i x_vec = _mm_cvtsi64_si128(x);\n\n    while (_mm_movemask_epi8(_mm_cmpgt_epi8(x_vec, zero))) {\n        __m128i remainder = _mm_slli_epi64(x_vec, 56);\n        remainder = _mm_srli_epi64(remainder, 56);\n        remainder = _mm_cvtepi8_epi32(remainder);\n        remainder = _mm_cvtsi128_si32(remainder);\n\n        buffer[--index] = '0' + remainder % base;\n\n        x_vec = _mm_div_epi64(x_vec, base_vec);\n    }\n\n    return std::string(buffer + index);\n}\n```"}
{"task_id": "SimdBench_85_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n#include <algorithm>\n\nstd::string change_base_simd(int64_t x, int8_t base) {\n    if (base < 2 || base > 9) return \"\";\n\n    char buffer[65];\n    int index = 64;\n    buffer[index] = '\\0';\n\n    __m128i value = _mm_set1_epi64x(x);\n    __m128i base_vec = _mm_set1_epi64x(base);\n    __m128i zero = _mm_setzero_si128();\n    __m128i ten = _mm_set1_epi64x(10);\n\n    while (_mm_cvtsi128_si64(_mm_or_si128(value, _mm_srli_si128(value, 8))) != 0) {\n        __m128i div_result = _mm_div_epi64(value, base_vec);\n        __m128i mod_result = _mm_sub_epi64(value, _mm_mul_epi64(div_result, base_vec));\n        __m128i ascii_offset = _mm_set1_epi64x('0');\n        __m128i ascii_char = _mm_add_epi64(mod_result, ascii_offset);\n\n        _mm_storeu_si128((__m128i*)&buffer[index - 16], ascii_char);\n        value = div_result;\n        index -= 2; // Process two characters at a time\n    }\n\n    std::string result(buffer + index + 1);\n    std::reverse(result.begin(), result.end());\n    return result;\n}\n```"}
{"task_id": "SimdBench_85_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n#include <algorithm>\n\nstd::string change_base_simd(int64_t x, int8_t base) {\n    if (base < 2 || base > 9) return \"\";\n\n    char buffer[65];\n    int index = 64;\n    buffer[index] = '\\0';\n\n    __m128i zero = _mm_setzero_si128();\n    __m128i base_vec = _mm_set1_epi8(base);\n    __m128i x_vec = _mm_cvtsi64_si128(x);\n\n    while (_mm_movemask_epi8(_mm_cmpgt_epi8(x_vec, zero))) {\n        __m128i remainder = _mm_slli_epi64(x_vec, 56);\n        remainder = _mm_srli_epi64(remainder, 56);\n        remainder = _mm_cvtepi8_epi32(remainder);\n        remainder = _mm_cvtsi128_si32(remainder);\n\n        buffer[--index] = '0' + remainder;\n\n        x_vec = _mm_div_epi64(x_vec, base_vec);\n    }\n\n    return std::string(buffer + index);\n}\n```"}
{"task_id": "SimdBench_85_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n#include <algorithm>\n\nstd::string change_base_simd(int64_t x, int8_t base) {\n    if (base < 2 || base > 9) return \"\";\n\n    char buffer[65];\n    char* p = buffer + 64;\n    *p = '\\0';\n\n    __m128i zero = _mm_setzero_si128();\n    __m128i base_vec = _mm_set1_epi8(base);\n    __m128i x_vec = _mm_cvtsi64_si128(x);\n\n    while (x > 0) {\n        __m128i remainder = _mm_rem_epi8(x_vec, base_vec);\n        __m128i quotient = _mm_div_epi8(x_vec, base_vec);\n\n        x_vec = quotient;\n        x = _mm_cvtsi128_si32(x_vec);\n\n        _mm_storeu_si128((__m128i*)p, remainder);\n        p -= 16;\n\n        if (x == 0) break;\n    }\n\n    std::string result(p + 16);\n    std::reverse(result.begin(), result.end());\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_85_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string change_base_simd(int64_t x, int8_t base){\n    std::string result;\n    __m128i num = _mm_set1_epi32(x);\n    __m128i base_vec = _mm_set1_epi32(base);\n    __m128i zero = _mm_setzero_si128();\n    __m128i one = _mm_set1_epi32(1);\n\n    while (_mm_movemask_epi8(_mm_cmpgt_epi32(num, zero)) != 0) {\n        __m128i remainder = _mm_srai_epi32(_mm_mullo_epi32(num, _mm_set1_epi32(10 - base)), 29);\n        __m128i quotient = _mm_sub_epi32(_mm_srli_epi32(_mm_add_epi32(num, remainder), 1), _mm_mullo_epi32(remainder, base_vec));\n        num = quotient;\n\n        __m128i digit = _mm_add_epi32(remainder, _mm_set1_epi32('0'));\n        char digits[16];\n        _mm_storeu_si128((__m128i*)digits, digit);\n\n        for (int i = 0; i < 4; ++i) {\n            if (digits[i] != '0') {\n                result = digits[i] + result;\n            }\n        }\n    }\n\n    return result.empty() ? \"0\" : result;\n}\n```"}
{"task_id": "SimdBench_86_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nbool is_palindrome_simd(std::string text) {\n    int n = text.size();\n    if (n <= 1) return true;\n\n    const char* str = text.c_str();\n    int i = 0, j = n - 1;\n\n    while (i < j) {\n        __m128i a = _mm_loadu_si128(reinterpret_cast<const __m128i*>(str + i));\n        __m128i b = _mm_loadu_si128(reinterpret_cast<const __m128i*>(str + j - 15));\n\n        __m128i reversed_b = _mm_shuffle_epi8(b, _mm_setr_epi8(15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 0));\n\n        __m128i cmp = _mm_cmpeq_epi8(a, reversed_b);\n        int mask = _mm_movemask_epi8(cmp);\n\n        if (mask != 0xFFFF) {\n            int first_mismatch = __builtin_ctz(~mask);\n            if (i + first_mismatch >= j - first_mismatch) return false;\n        }\n\n        i += 16;\n        j -= 16;\n    }\n\n    while (i < j) {\n        if (str[i] != str[j]) return false;\n        i++;\n        j--;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_86_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nbool is_palindrome_simd(std::string text) {\n    int n = text.size();\n    if (n <= 1) return true;\n\n    const char* str = text.c_str();\n    int i = 0, j = n - 1;\n\n    while (i < j) {\n        __m128i a = _mm_loadu_si128(reinterpret_cast<const __m128i*>(str + i));\n        __m128i b = _mm_loadu_si128(reinterpret_cast<const __m128i*>(str + j - 15));\n\n        __m128i cmp = _mm_cmpeq_epi8(a, _mm_bswap_epi16(b));\n\n        int mask = _mm_movemask_epi8(cmp);\n        if (mask != 0xFFFF) {\n            int first_mismatch = __builtin_ctz(~mask);\n            return str[i + first_mismatch] == str[j - first_mismatch];\n        }\n\n        i += 16;\n        j -= 16;\n    }\n\n    while (i < j) {\n        if (str[i] != str[j]) return false;\n        i++;\n        j--;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_86_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nbool is_palindrome_simd(std::string text) {\n    int n = text.size();\n    if (n <= 1) return true;\n\n    const char* str = text.c_str();\n    int i = 0, j = n - 1;\n\n    while (i < j) {\n        __m128i left = _mm_loadu_si128(reinterpret_cast<const __m128i*>(str + i));\n        __m128i right = _mm_loadu_si128(reinterpret_cast<const __m128i*>(str + j - 15));\n\n        __m128i reversed_right = _mm_shuffle_epi8(right, _mm_setr_epi8(15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 0));\n\n        __m128i cmp = _mm_cmpeq_epi8(left, reversed_right);\n        int mask = _mm_movemask_epi8(cmp);\n\n        if (mask != 0xFFFF) {\n            int first_mismatch = __builtin_ctz(~mask);\n            if (i + first_mismatch >= j - first_mismatch) return false;\n        }\n\n        i += 16;\n        j -= 16;\n    }\n\n    while (i < j) {\n        if (str[i] != str[j]) return false;\n        i++;\n        j--;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_86_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nbool is_palindrome_simd(std::string text) {\n    int n = text.size();\n    if (n <= 1) return true;\n\n    const char* str = text.c_str();\n    int i = 0, j = n - 1;\n\n    while (i < j) {\n        __m128i a = _mm_loadu_si128(reinterpret_cast<const __m128i*>(str + i));\n        __m128i b = _mm_loadu_si128(reinterpret_cast<const __m128i*>(str + j - 15));\n\n        __m128i cmp = _mm_cmpeq_epi8(a, _mm_srli_si128(b, 16));\n        int mask = _mm_movemask_epi8(cmp);\n\n        if (mask != 0xFFFF) {\n            int first_mismatch = __builtin_ctz(~mask);\n            return str[i + first_mismatch] == str[j - first_mismatch];\n        }\n\n        i += 16;\n        j -= 16;\n    }\n\n    while (i < j) {\n        if (str[i] != str[j]) return false;\n        i++;\n        j--;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_86_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nbool is_palindrome_simd(std::string text) {\n    int n = text.size();\n    if (n <= 1) return true;\n\n    const char* str = text.c_str();\n    int i = 0, j = n - 1;\n\n    while (i < j) {\n        __m128i a = _mm_loadu_si128(reinterpret_cast<const __m128i*>(str + i));\n        __m128i b = _mm_loadu_si128(reinterpret_cast<const __m128i*>(str + j - 15));\n\n        b = _mm_shuffle_epi8(b, _mm_setr_epi8(15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 0));\n\n        __m128i cmp = _mm_cmpeq_epi8(a, b);\n        int mask = _mm_movemask_epi8(cmp);\n\n        if (mask != 0xFFFF) {\n            int first_mismatch = __builtin_ctz(~mask);\n            if (i + first_mismatch >= j - first_mismatch) return false;\n        }\n\n        i += 16;\n        j -= 16;\n    }\n\n    while (i < j) {\n        if (str[i] != str[j]) return false;\n        i++;\n        j--;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_87_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nstd::string decode_shift_simd(std::string s) {\n    std::string out(s.length(), ' ');\n    const __m128i shift = _mm_set1_epi8(5);\n    const __m128i a = _mm_set1_epi8('a');\n    const __m128i z = _mm_set1_epi8('z');\n    const __m128i alphabet_size = _mm_set1_epi8(26);\n\n    size_t i = 0;\n    for (; i <= s.length() - 16; i += 16) {\n        __m128i input = _mm_loadu_si128(reinterpret_cast<const __m128i*>(s.data() + i));\n        __m128i sub_a = _mm_sub_epi8(input, a);\n        __m128i sub_shift = _mm_sub_epi8(sub_a, shift);\n        __m128i add_alphabet_size = _mm_add_epi8(sub_shift, alphabet_size);\n        __m128i cmp = _mm_cmpgt_epi8(sub_shift, _mm_setzero_si128());\n        __m128i result = _mm_blendv_epi8(add_alphabet_size, sub_shift, cmp);\n        __m128i final_result = _mm_add_epi8(result, a);\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(out.data() + i), final_result);\n    }\n\n    for (; i < s.length(); ++i) {\n        int w = ((int)s[i] - 5 - (int)'a' + 26) % 26 + (int)'a';\n        out[i] = (char)w;\n    }\n\n    return out;\n}\n```"}
{"task_id": "SimdBench_87_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nstd::string decode_shift_simd(std::string s) {\n    std::string out(s.length(), ' ');\n    const __m128i shift = _mm_set1_epi8(5);\n    const __m128i a = _mm_set1_epi8('a');\n    const __m128i z = _mm_set1_epi8('z');\n    const __m128i alphabet_size = _mm_set1_epi8(26);\n\n    size_t i = 0;\n    for (; i <= s.length() - 16; i += 16) {\n        __m128i in = _mm_loadu_si128(reinterpret_cast<const __m128i*>(s.data() + i));\n        __m128i sub_a = _mm_sub_epi8(in, a);\n        __m128i sub_shift = _mm_sub_epi8(sub_a, shift);\n        __m128i add_alphabet_size = _mm_add_epi8(sub_shift, alphabet_size);\n        __m128i cmp = _mm_cmpgt_epi8(sub_shift, _mm_setzero_si128());\n        __m128i result = _mm_blendv_epi8(add_alphabet_size, sub_shift, cmp);\n        __m128i final_result = _mm_add_epi8(result, a);\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(out.data() + i), final_result);\n    }\n\n    for (; i < s.length(); ++i) {\n        int w = ((int)s[i] - 5 - (int)'a' + 26) % 26 + (int)'a';\n        out[i] = (char)w;\n    }\n\n    return out;\n}\n```"}
{"task_id": "SimdBench_87_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nstd::string decode_shift_simd(std::string s) {\n    std::string out(s.length(), ' ');\n    const __m128i shift = _mm_set1_epi8(5);\n    const __m128i a = _mm_set1_epi8('a');\n    const __m128i z = _mm_set1_epi8('z');\n    const __m128i alphabet_size = _mm_set1_epi8(26);\n\n    size_t i = 0;\n    for (; i <= s.length() - 16; i += 16) {\n        __m128i in = _mm_loadu_si128(reinterpret_cast<const __m128i*>(s.data() + i));\n        __m128i sub_a = _mm_sub_epi8(in, a);\n        __m128i sub_shift = _mm_sub_epi8(sub_a, shift);\n        __m128i add_alphabet_size = _mm_add_epi8(sub_shift, alphabet_size);\n        __m128i cmp = _mm_cmpgt_epi8(sub_shift, _mm_setzero_si128());\n        __m128i result = _mm_blendv_epi8(add_alphabet_size, sub_shift, cmp);\n        __m128i final_result = _mm_add_epi8(result, a);\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(out.data() + i), final_result);\n    }\n\n    for (; i < s.length(); ++i) {\n        int w = ((int)s[i] - 5 - (int)'a' + 26) % 26 + (int)'a';\n        out[i] = (char)w;\n    }\n\n    return out;\n}\n```"}
{"task_id": "SimdBench_87_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nstd::string decode_shift_simd(std::string s) {\n    std::string out(s.length(), ' ');\n    const __m128i shift = _mm_set1_epi8(5);\n    const __m128i a = _mm_set1_epi8('a');\n    const __m128i z = _mm_set1_epi8('z');\n    const __m128i alphabet_size = _mm_set1_epi8(26);\n\n    size_t i = 0;\n    for (; i <= s.length() - 16; i += 16) {\n        __m128i in = _mm_loadu_si128(reinterpret_cast<const __m128i*>(s.data() + i));\n        __m128i sub_a = _mm_sub_epi8(in, a);\n        __m128i sub_shift = _mm_sub_epi8(sub_a, shift);\n        __m128i add_alphabet_size = _mm_add_epi8(sub_shift, alphabet_size);\n        __m128i cmp = _mm_cmpgt_epi8(sub_shift, _mm_setzero_si128());\n        __m128i result = _mm_blendv_epi8(add_alphabet_size, sub_shift, cmp);\n        __m128i final_result = _mm_add_epi8(result, a);\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(out.data() + i), final_result);\n    }\n\n    for (; i < s.length(); ++i) {\n        int w = ((int)s[i] - 5 - (int)'a' + 26) % 26 + (int)'a';\n        out[i] = (char)w;\n    }\n\n    return out;\n}\n```"}
{"task_id": "SimdBench_87_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nstd::string decode_shift_simd(std::string s) {\n    std::string out(s.length(), ' ');\n    const __m128i shift = _mm_set1_epi8(5);\n    const __m128i a = _mm_set1_epi8('a');\n    const __m128i z = _mm_set1_epi8('z');\n    const __m128i alphabet_size = _mm_set1_epi8(26);\n\n    size_t i = 0;\n    for (; i <= s.length() - 16; i += 16) {\n        __m128i input = _mm_loadu_si128(reinterpret_cast<const __m128i*>(s.data() + i));\n        __m128i sub_a = _mm_sub_epi8(input, a);\n        __m128i sub_shift = _mm_sub_epi8(sub_a, shift);\n        __m128i add_alphabet_size = _mm_add_epi8(sub_shift, alphabet_size);\n        __m128i cmp = _mm_cmpgt_epi8(sub_shift, _mm_setzero_si128());\n        __m128i result = _mm_blendv_epi8(add_alphabet_size, sub_shift, cmp);\n        __m128i final_result = _mm_add_epi8(result, a);\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(out.data() + i), final_result);\n    }\n\n    for (; i < s.length(); ++i) {\n        int w = ((int)s[i] - 5 - (int)'a' + 26) % 26 + (int)'a';\n        out[i] = (char)w;\n    }\n\n    return out;\n}\n```"}
{"task_id": "SimdBench_88_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nbool below_threshold_simd(std::vector<int> l, int t) {\n    __m128i threshold = _mm_set1_epi32(t);\n    int n = l.size();\n    int i = 0;\n\n    for (; i <= n - 4; i += 4) {\n        __m128i vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&l[i]));\n        __m128i cmp = _mm_cmpgt_epi32(vec, threshold);\n        if (!_mm_testz_si128(cmp, cmp)) {\n            return false;\n        }\n    }\n\n    for (; i < n; ++i) {\n        if (l[i] >= t) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_88_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nbool below_threshold_simd(std::vector<int> l, int t) {\n    __m128i threshold = _mm_set1_epi32(t);\n    int n = l.size();\n    int i = 0;\n\n    for (; i <= n - 4; i += 4) {\n        __m128i vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&l[i]));\n        __m128i cmp = _mm_cmplt_epi32(vec, threshold);\n        if (_mm_movemask_epi8(cmp) != 0xFFFF) {\n            return false;\n        }\n    }\n\n    for (; i < n; ++i) {\n        if (l[i] >= t) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_88_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nbool below_threshold_simd(std::vector<int> l, int t) {\n    __m128i threshold = _mm_set1_epi32(t);\n    int n = l.size();\n    int i = 0;\n\n    for (; i <= n - 4; i += 4) {\n        __m128i vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&l[i]));\n        __m128i cmp = _mm_cmpgt_epi32(vec, threshold);\n        if (!_mm_testz_si128(cmp, cmp)) {\n            return false;\n        }\n    }\n\n    for (; i < n; ++i) {\n        if (l[i] >= t) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_88_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nbool below_threshold_simd(std::vector<int> l, int t) {\n    __m128i threshold = _mm_set1_epi32(t);\n    int n = l.size();\n    int i = 0;\n\n    for (; i <= n - 4; i += 4) {\n        __m128i vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&l[i]));\n        __m128i cmp = _mm_cmpgt_epi32(vec, threshold);\n        if (!_mm_testz_si128(cmp, cmp)) {\n            return false;\n        }\n    }\n\n    for (; i < n; ++i) {\n        if (l[i] >= t) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_88_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nbool below_threshold_simd(std::vector<int> l, int t) {\n    __m128i threshold = _mm_set1_epi32(t);\n    int n = l.size();\n    int i = 0;\n\n    for (; i <= n - 4; i += 4) {\n        __m128i vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&l[i]));\n        __m128i cmp = _mm_cmpgt_epi32(vec, threshold);\n        if (!_mm_testz_si128(cmp, cmp)) {\n            return false;\n        }\n    }\n\n    for (; i < n; ++i) {\n        if (l[i] >= t) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_89_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool correct_bracketing_simd(std::string brackets) {\n    int len = brackets.size();\n    if (len == 0) return true;\n\n    __m128i balance = _mm_setzero_si128();\n    __m128i one = _mm_set1_epi8(1);\n    __m128i zero = _mm_setzero_si128();\n\n    for (int i = 0; i < len; i += 16) {\n        __m128i chunk;\n        if (i + 16 <= len) {\n            chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&brackets[i]));\n        } else {\n            char temp[16] = {0};\n            memcpy(temp, &brackets[i], len - i);\n            chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(temp));\n        }\n\n        __m128i cmp_open = _mm_cmpeq_epi8(chunk, _mm_set1_epi8('<'));\n        __m128i cmp_close = _mm_cmpeq_epi8(chunk, _mm_set1_epi8('>'));\n        __m128i add_open = _mm_and_si128(cmp_open, one);\n        __m128i sub_close = _mm_and_si128(cmp_close, one);\n        balance = _mm_add_epi8(balance, add_open);\n        balance = _mm_sub_epi8(balance, sub_close);\n\n        __m128i underflow_mask = _mm_cmplt_epi8(balance, zero);\n        if (!_mm_test_all_zeros(underflow_mask, underflow_mask)) {\n            return false;\n        }\n    }\n\n    __m128i sum = _mm_sad_epu8(balance, zero);\n    int result = _mm_extract_epi16(sum, 0) + _mm_extract_epi16(sum, 4);\n    return result == 0;\n}\n```"}
{"task_id": "SimdBench_89_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool correct_bracketing_simd(std::string brackets) {\n    int len = brackets.size();\n    if (len == 0) return true;\n\n    __m128i balance = _mm_setzero_si128();\n    __m128i one = _mm_set1_epi8(1);\n    __m128i zero = _mm_setzero_si128();\n\n    for (int i = 0; i < len; i += 16) {\n        __m128i chunk;\n        if (i + 16 <= len) {\n            chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(brackets.c_str() + i));\n        } else {\n            char temp[16] = {0};\n            memcpy(temp, brackets.c_str() + i, len - i);\n            chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(temp));\n        }\n\n        __m128i cmp_open = _mm_cmpeq_epi8(chunk, _mm_set1_epi8('<'));\n        __m128i cmp_close = _mm_cmpeq_epi8(chunk, _mm_set1_epi8('>'));\n        __m128i open_count = _mm_and_si128(cmp_open, one);\n        __m128i close_count = _mm_and_si128(cmp_close, one);\n\n        balance = _mm_add_epi8(balance, open_count);\n        balance = _mm_sub_epi8(balance, close_count);\n\n        __m128i underflow_mask = _mm_cmplt_epi8(balance, zero);\n        if (!_mm_testz_si128(underflow_mask, underflow_mask)) {\n            return false;\n        }\n    }\n\n    __m128i sum = _mm_sad_epu8(balance, zero);\n    int result = _mm_extract_epi16(sum, 0) + _mm_extract_epi16(sum, 4);\n    return result == 0;\n}\n```"}
{"task_id": "SimdBench_89_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool correct_bracketing_simd(std::string brackets) {\n    int len = brackets.size();\n    if (len == 0) return true;\n\n    __m128i balance = _mm_setzero_si128();\n    __m128i one = _mm_set1_epi8(1);\n    __m128i zero = _mm_setzero_si128();\n\n    for (int i = 0; i < len; i += 16) {\n        __m128i chunk;\n        if (i + 16 <= len) {\n            chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&brackets[i]));\n        } else {\n            char temp[16] = {0};\n            memcpy(temp, &brackets[i], len - i);\n            chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(temp));\n        }\n\n        __m128i increment = _mm_cmpeq_epi8(chunk, _mm_set1_epi8('<'));\n        __m128i decrement = _mm_cmpeq_epi8(chunk, _mm_set1_epi8('>'));\n        balance = _mm_add_epi8(balance, _mm_sub_epi8(_mm_and_si128(increment, one), _mm_and_si128(decrement, one)));\n\n        __m128i underflow = _mm_cmplt_epi8(balance, zero);\n        if (!_mm_test_all_zeros(underflow, underflow)) {\n            return false;\n        }\n    }\n\n    __m128i sum = _mm_sad_epu8(balance, zero);\n    int result = _mm_extract_epi16(sum, 0) + _mm_extract_epi16(sum, 4);\n    return result == 0;\n}\n```"}
{"task_id": "SimdBench_89_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool correct_bracketing_simd(std::string brackets) {\n    int len = brackets.size();\n    if (len == 0) return true;\n\n    __m128i balance = _mm_setzero_si128();\n    __m128i one = _mm_set1_epi8(1);\n    __m128i zero = _mm_setzero_si128();\n\n    for (int i = 0; i < len; i += 16) {\n        __m128i chunk;\n        if (i + 16 <= len) {\n            chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(brackets.c_str() + i));\n        } else {\n            char temp[16] = {0};\n            memcpy(temp, brackets.c_str() + i, len - i);\n            chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(temp));\n        }\n\n        __m128i cmp_open = _mm_cmpeq_epi8(chunk, _mm_set1_epi8('<'));\n        __m128i cmp_close = _mm_cmpeq_epi8(chunk, _mm_set1_epi8('>'));\n        __m128i add_open = _mm_and_si128(cmp_open, one);\n        __m128i sub_close = _mm_and_si128(cmp_close, one);\n        balance = _mm_add_epi8(balance, add_open);\n        balance = _mm_sub_epi8(balance, sub_close);\n\n        __m128i underflow = _mm_cmplt_epi8(balance, zero);\n        if (!_mm_test_all_zeros(underflow, underflow)) {\n            return false;\n        }\n    }\n\n    __m128i sum = _mm_sad_epu8(balance, zero);\n    int result = _mm_extract_epi16(sum, 0) + _mm_extract_epi16(sum, 4);\n    return result == 0;\n}\n```"}
{"task_id": "SimdBench_89_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool correct_bracketing_simd(std::string brackets) {\n    int len = brackets.size();\n    if (len == 0) return true;\n\n    __m128i balance = _mm_setzero_si128();\n    __m128i one = _mm_set1_epi8(1);\n    __m128i zero = _mm_setzero_si128();\n\n    for (int i = 0; i < len; i += 16) {\n        __m128i chunk;\n        if (i + 16 <= len) {\n            chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(brackets.data() + i));\n        } else {\n            char temp[16] = {0};\n            memcpy(temp, brackets.data() + i, len - i);\n            chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(temp));\n        }\n\n        __m128i cmp_open = _mm_cmpeq_epi8(chunk, _mm_set1_epi8('<'));\n        __m128i cmp_close = _mm_cmpeq_epi8(chunk, _mm_set1_epi8('>'));\n        __m128i add_open = _mm_and_si128(cmp_open, one);\n        __m128i sub_close = _mm_and_si128(cmp_close, one);\n\n        balance = _mm_add_epi8(balance, add_open);\n        balance = _mm_sub_epi8(balance, sub_close);\n\n        __m128i underflow_mask = _mm_cmplt_epi8(balance, zero);\n        if (!_mm_test_all_zeros(underflow_mask, underflow_mask)) {\n            return false;\n        }\n    }\n\n    __m128i sum = _mm_sad_epu8(balance, zero);\n    int result = _mm_extract_epi16(sum, 0) + _mm_extract_epi16(sum, 4);\n    return result == 0;\n}\n```"}
{"task_id": "SimdBench_90_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool correct_bracketing_simd(std::string brackets) {\n    int len = brackets.size();\n    if (len == 0) return true;\n\n    __m128i balance = _mm_setzero_si128();\n    __m128i open_bracket = _mm_set1_epi8('(');\n    __m128i close_bracket = _mm_set1_epi8(')');\n    __m128i one = _mm_set1_epi8(1);\n\n    for (int i = 0; i < len; i += 16) {\n        __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&brackets[i]));\n        __m128i open_mask = _mm_cmpeq_epi8(chunk, open_bracket);\n        __m128i close_mask = _mm_cmpeq_epi8(chunk, close_bracket);\n\n        __m128i open_count = _mm_and_si128(open_mask, one);\n        __m128i close_count = _mm_and_si128(close_mask, one);\n\n        balance = _mm_add_epi8(balance, open_count);\n        balance = _mm_sub_epi8(balance, close_count);\n\n        __m128i zero = _mm_setzero_si128();\n        __m128i negative_balance = _mm_cmplt_epi8(balance, zero);\n\n        if (!_mm_test_all_zeros(negative_balance, negative_balance)) {\n            return false;\n        }\n    }\n\n    int32_t final_balance[4];\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(final_balance), balance);\n\n    return (final_balance[0] + final_balance[1] + final_balance[2] + final_balance[3]) == 0;\n}\n```"}
{"task_id": "SimdBench_90_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool correct_bracketing_simd(std::string brackets){\n    int len = brackets.size();\n    if (len == 0) return true;\n\n    __m128i balance = _mm_setzero_si128();\n    __m128i one = _mm_set1_epi8(1);\n    __m128i zero = _mm_setzero_si128();\n\n    for (int i = 0; i < len; i += 16) {\n        __m128i chunk;\n        if (i + 16 <= len) {\n            chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&brackets[i]));\n        } else {\n            char temp[16] = {0};\n            memcpy(temp, &brackets[i], len - i);\n            chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(temp));\n        }\n\n        __m128i open_brackets = _mm_cmpeq_epi8(chunk, _mm_set1_epi8('('));\n        __m128i close_brackets = _mm_cmpeq_epi8(chunk, _mm_set1_epi8(')'));\n\n        balance = _mm_add_epi8(balance, _mm_and_si128(open_brackets, one));\n        balance = _mm_sub_epi8(balance, _mm_and_si128(close_brackets, one));\n\n        __m128i underflow = _mm_cmplt_epi8(balance, zero);\n        if (!_mm_test_all_zeros(underflow, underflow)) {\n            return false;\n        }\n    }\n\n    __m128i sum = _mm_sad_epu8(balance, zero);\n    int result = _mm_extract_epi16(sum, 0) + _mm_extract_epi16(sum, 4);\n    return result == 0;\n}\n```"}
{"task_id": "SimdBench_90_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool correct_bracketing_simd(std::string brackets) {\n    int len = brackets.size();\n    if (len == 0) return true;\n\n    __m128i balance = _mm_setzero_si128();\n    __m128i open_bracket = _mm_set1_epi8('(');\n    __m128i close_bracket = _mm_set1_epi8(')');\n    __m128i one = _mm_set1_epi8(1);\n\n    for (int i = 0; i < len; i += 16) {\n        __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&brackets[i]));\n        __m128i open_mask = _mm_cmpeq_epi8(chunk, open_bracket);\n        __m128i close_mask = _mm_cmpeq_epi8(chunk, close_bracket);\n\n        __m128i open_count = _mm_and_si128(open_mask, one);\n        __m128i close_count = _mm_and_si128(close_mask, one);\n\n        balance = _mm_add_epi8(balance, open_count);\n        balance = _mm_sub_epi8(balance, close_count);\n\n        __m128i zero = _mm_setzero_si128();\n        __m128i negative_balance = _mm_cmplt_epi8(balance, zero);\n\n        if (!_mm_test_all_zeros(negative_balance, negative_balance)) {\n            return false;\n        }\n    }\n\n    int32_t final_balance[4];\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(final_balance), balance);\n\n    return (final_balance[0] + final_balance[1] + final_balance[2] + final_balance[3]) == 0;\n}\n```"}
{"task_id": "SimdBench_90_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool correct_bracketing_simd(std::string brackets){\n    int len = brackets.size();\n    if (len == 0) return true;\n\n    __m128i balance = _mm_setzero_si128();\n    __m128i open_bracket = _mm_set1_epi8('(');\n    __m128i close_bracket = _mm_set1_epi8(')');\n    __m128i one = _mm_set1_epi8(1);\n\n    for (int i = 0; i < len; i += 16) {\n        __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&brackets[i]));\n        __m128i open_mask = _mm_cmpeq_epi8(chunk, open_bracket);\n        __m128i close_mask = _mm_cmpeq_epi8(chunk, close_bracket);\n        __m128i open_count = _mm_and_si128(open_mask, one);\n        __m128i close_count = _mm_and_si128(close_mask, one);\n        balance = _mm_add_epi8(balance, _mm_sub_epi8(open_count, close_count));\n\n        __m128i zero = _mm_setzero_si128();\n        __m128i negative_balance = _mm_cmplt_epi8(balance, zero);\n        if (!_mm_testz_si128(negative_balance, negative_balance)) {\n            return false;\n        }\n    }\n\n    int balance_array[16];\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(balance_array), balance);\n    int total_balance = 0;\n    for (int i = 0; i < 16; ++i) {\n        total_balance += balance_array[i];\n    }\n\n    return total_balance == 0;\n}\n```"}
{"task_id": "SimdBench_90_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool correct_bracketing_simd(std::string brackets) {\n    int len = brackets.size();\n    if (len == 0) return true;\n\n    __m128i balance = _mm_setzero_si128();\n    __m128i one = _mm_set1_epi8(1);\n    __m128i zero = _mm_setzero_si128();\n\n    for (int i = 0; i < len; i += 16) {\n        __m128i chunk;\n        if (i + 16 <= len) {\n            chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&brackets[i]));\n        } else {\n            char temp[16] = {0};\n            memcpy(temp, &brackets[i], len - i);\n            chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(temp));\n        }\n\n        __m128i open_brackets = _mm_cmpeq_epi8(chunk, _mm_set1_epi8('('));\n        __m128i close_brackets = _mm_cmpeq_epi8(chunk, _mm_set1_epi8(')'));\n\n        balance = _mm_add_epi8(balance, _mm_and_si128(open_brackets, one));\n        balance = _mm_sub_epi8(balance, _mm_and_si128(close_brackets, one));\n\n        __m128i underflow = _mm_cmplt_epi8(balance, zero);\n        if (!_mm_test_all_zeros(underflow, underflow)) {\n            return false;\n        }\n    }\n\n    __m128i sum = _mm_sad_epu8(balance, zero);\n    int result = _mm_extract_epi16(sum, 0) + _mm_extract_epi16(sum, 4);\n    return result == 0;\n}\n```"}
{"task_id": "SimdBench_91_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<float> derivative_simd(std::vector<float> xs){\n    std::vector<float> result;\n    if (xs.size() <= 1) return result;\n\n    int n = xs.size();\n    result.resize(n - 1);\n\n    __m128 x_vec, coeff_vec, result_vec;\n    float* result_ptr = result.data();\n    const float* xs_ptr = xs.data();\n\n    for (int i = 1; i < n; i += 4) {\n        coeff_vec = _mm_loadu_ps(&xs_ptr[i]);\n        x_vec = _mm_set_ps(i + 3, i + 2, i + 1, i);\n        result_vec = _mm_mul_ps(coeff_vec, x_vec);\n        _mm_storeu_ps(result_ptr, result_vec);\n        result_ptr += 4;\n    }\n\n    // Handle the remaining elements\n    for (int i = (n - 1) / 4 * 4 + 1; i < n; ++i) {\n        result[i - 1] = xs[i] * i;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_91_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<float> derivative_simd(std::vector<float> xs){\n    std::vector<float> result;\n    if (xs.size() <= 1) return result;\n\n    int n = xs.size();\n    result.resize(n - 1);\n\n    __m128 x_vec, coeff_vec, result_vec;\n    float* result_ptr = result.data();\n    const float* xs_ptr = xs.data();\n\n    for (int i = 1; i < n; i += 4) {\n        coeff_vec = _mm_loadu_ps(&xs_ptr[i]);\n        x_vec = _mm_set_ps(i + 3, i + 2, i + 1, i);\n        result_vec = _mm_mul_ps(coeff_vec, x_vec);\n        _mm_storeu_ps(result_ptr, result_vec);\n        result_ptr += 4;\n    }\n\n    // Handle remaining elements\n    for (int i = (n - 1) / 4 * 4; i < n - 1; ++i) {\n        result[i - 1] = xs[i] * i;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_91_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<float> derivative_simd(std::vector<float> xs){\n    std::vector<float> result;\n    if (xs.size() <= 1) return result;\n\n    int n = xs.size();\n    result.resize(n - 1);\n\n    __m128 x_vec, coeff_vec, result_vec;\n    float* result_ptr = result.data();\n    const float* xs_ptr = xs.data();\n\n    for (int i = 1; i < n; i += 4) {\n        coeff_vec = _mm_loadu_ps(&xs_ptr[i]);\n        x_vec = _mm_set_ps(i + 3, i + 2, i + 1, i);\n        result_vec = _mm_mul_ps(coeff_vec, x_vec);\n        _mm_storeu_ps(result_ptr, result_vec);\n        result_ptr += 4;\n    }\n\n    // Handle remaining elements\n    for (int i = (n - 1) / 4 * 4; i < n - 1; ++i) {\n        result[i - 1] = xs[i] * i;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_91_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<float> derivative_simd(std::vector<float> xs){\n    std::vector<float> result;\n    if (xs.size() <= 1) return result;\n\n    int n = xs.size();\n    result.resize(n - 1);\n\n    __m128 x_vec, coeff_vec, result_vec;\n    float* result_ptr = result.data();\n    const float* xs_ptr = xs.data();\n\n    for (int i = 1; i < n; i += 4) {\n        coeff_vec = _mm_loadu_ps(&xs_ptr[i]);\n        x_vec = _mm_set_ps(i + 3, i + 2, i + 1, i);\n        result_vec = _mm_mul_ps(coeff_vec, x_vec);\n        _mm_storeu_ps(result_ptr, result_vec);\n        result_ptr += 4;\n    }\n\n    // Handle remaining elements\n    for (int i = (n - 1) / 4 * 4; i < n - 1; ++i) {\n        result[i - 1] = xs[i] * i;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_91_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<float> derivative_simd(std::vector<float> xs){\n    std::vector<float> result;\n    if (xs.size() <= 1) return result;\n\n    int n = xs.size();\n    result.resize(n - 1);\n\n    __m128 x_vec, coeff_vec, result_vec;\n    float* result_ptr = result.data();\n    const float* xs_ptr = xs.data();\n\n    for (int i = 1; i < n; i += 4) {\n        coeff_vec = _mm_loadu_ps(&xs_ptr[i]);\n        x_vec = _mm_set_ps(i + 3, i + 2, i + 1, i);\n        result_vec = _mm_mul_ps(coeff_vec, x_vec);\n        _mm_storeu_ps(result_ptr, result_vec);\n        result_ptr += 4;\n    }\n\n    // Handle remaining elements\n    for (int i = (n - 1) / 4 * 4; i < n - 1; ++i) {\n        result[i - 1] = xs[i] * i;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_92_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nint vowels_count_simd(std::string s) {\n    int count = 0;\n    const char* str = s.c_str();\n    int len = s.size();\n    __m128i vowels = _mm_setr_epi8('a', 'e', 'i', 'o', 'u', 'A', 'E', 'I', 'O', 'U', 0, 0, 0, 0, 0, 0);\n    __m128i y_vowel = _mm_setr_epi8('y', 'Y', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n\n    for (int i = 0; i <= len - 16; i += 16) {\n        __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(str + i));\n        __m128i cmp = _mm_cmpeq_epi8(chunk, vowels);\n        int mask = _mm_movemask_epi8(cmp);\n        count += __builtin_popcount(mask);\n    }\n\n    for (int i = len - (len % 16); i < len - 1; ++i) {\n        if (str[i] == 'a' || str[i] == 'e' || str[i] == 'i' || str[i] == 'o' || str[i] == 'u' ||\n            str[i] == 'A' || str[i] == 'E' || str[i] == 'I' || str[i] == 'O' || str[i] == 'U') {\n            count++;\n        }\n    }\n\n    if (len > 0 && (str[len - 1] == 'y' || str[len - 1] == 'Y')) {\n        count++;\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_92_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nint vowels_count_simd(std::string s) {\n    int count = 0;\n    int len = s.length();\n    const char* str = s.c_str();\n\n    __m128i vowels = _mm_setr_epi8('a', 'e', 'i', 'o', 'u', 'A', 'E', 'I', 'O', 'U', 0, 0, 0, 0, 0, 0);\n    __m128i y_vowel = _mm_setr_epi8('y', 'Y', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n\n    for (int i = 0; i <= len - 16; i += 16) {\n        __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(str + i));\n        __m128i cmp = _mm_cmpeq_epi8(chunk, vowels);\n        int mask = _mm_movemask_epi8(cmp);\n        count += __builtin_popcount(mask);\n    }\n\n    for (int i = len - (len % 16); i < len - 1; ++i) {\n        if (str[i] == 'a' || str[i] == 'e' || str[i] == 'i' || str[i] == 'o' || str[i] == 'u' ||\n            str[i] == 'A' || str[i] == 'E' || str[i] == 'I' || str[i] == 'O' || str[i] == 'U') {\n            count++;\n        }\n    }\n\n    if (len > 0 && (str[len - 1] == 'y' || str[len - 1] == 'Y')) {\n        count++;\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_92_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nint vowels_count_simd(std::string s) {\n    int count = 0;\n    int len = s.length();\n    const char* str = s.c_str();\n\n    __m128i vowels = _mm_setr_epi8('a', 'e', 'i', 'o', 'u', 'A', 'E', 'I', 'O', 'U', 0, 0, 0, 0, 0, 0);\n    __m128i y_vowel = _mm_setr_epi8('y', 'Y', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n\n    for (int i = 0; i <= len - 16; i += 16) {\n        __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(str + i));\n        __m128i cmp = _mm_cmpeq_epi8(chunk, vowels);\n        int mask = _mm_movemask_epi8(cmp);\n        count += __builtin_popcount(mask);\n    }\n\n    for (int i = len - (len % 16); i < len - 1; ++i) {\n        if (str[i] == 'a' || str[i] == 'e' || str[i] == 'i' || str[i] == 'o' || str[i] == 'u' ||\n            str[i] == 'A' || str[i] == 'E' || str[i] == 'I' || str[i] == 'O' || str[i] == 'U') {\n            count++;\n        }\n    }\n\n    if (len > 0 && (str[len - 1] == 'y' || str[len - 1] == 'Y')) {\n        count++;\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_92_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nint vowels_count_simd(std::string s) {\n    int count = 0;\n    int len = s.length();\n    const char* str = s.c_str();\n\n    __m128i vowels = _mm_set_epi8('u', 'U', 'o', 'O', 'i', 'I', 'e', 'E', 'a', 'A', 0, 0, 0, 0, 0, 0);\n    __m128i y_vowel = _mm_set_epi8('y', 'Y', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n\n    for (int i = 0; i <= len - 16; i += 16) {\n        __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(str + i));\n        __m128i cmp = _mm_cmpeq_epi8(chunk, vowels);\n        count += _mm_popcnt_u32(_mm_movemask_epi8(cmp));\n    }\n\n    for (int i = len - (len % 16); i < len - 1; ++i) {\n        if (str[i] == 'a' || str[i] == 'A' || str[i] == 'e' || str[i] == 'E' ||\n            str[i] == 'i' || str[i] == 'I' || str[i] == 'o' || str[i] == 'O' ||\n            str[i] == 'u' || str[i] == 'U') {\n            count++;\n        }\n    }\n\n    if (len > 0 && (str[len - 1] == 'y' || str[len - 1] == 'Y')) {\n        count++;\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_92_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nint vowels_count_simd(std::string s) {\n    int count = 0;\n    int len = s.length();\n    const char* str = s.c_str();\n\n    __m128i vowels = _mm_setr_epi8('a', 'e', 'i', 'o', 'u', 'A', 'E', 'I', 'O', 'U', 0, 0, 0, 0, 0, 0);\n    __m128i y_vowel = _mm_setr_epi8('y', 'Y', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n\n    for (int i = 0; i <= len - 16; i += 16) {\n        __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(str + i));\n        __m128i cmp = _mm_cmpeq_epi8(chunk, vowels);\n        int mask = _mm_movemask_epi8(cmp);\n        count += __builtin_popcount(mask);\n    }\n\n    for (int i = len - (len % 16); i < len - 1; ++i) {\n        if (str[i] == 'a' || str[i] == 'e' || str[i] == 'i' || str[i] == 'o' || str[i] == 'u' ||\n            str[i] == 'A' || str[i] == 'E' || str[i] == 'I' || str[i] == 'O' || str[i] == 'U') {\n            count++;\n        }\n    }\n\n    if (len > 0 && (str[len - 1] == 'y' || str[len - 1] == 'Y')) {\n        count++;\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_93_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nint digitSum_simd(std::string s) {\n    int sum = 0;\n    int len = s.size();\n    const char* str = s.c_str();\n\n    __m128i zero = _mm_setzero_si128();\n    __m128i upper_mask = _mm_set1_epi8(0x80);\n    __m128i upper_bound = _mm_set1_epi8('A');\n    __m128i lower_bound = _mm_set1_epi8('Z');\n\n    for (int i = 0; i <= len - 16; i += 16) {\n        __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(str + i));\n        __m128i upper_check = _mm_and_si128(chunk, upper_mask);\n        __m128i in_range = _mm_and_si128(_mm_cmpgt_epi8(chunk, upper_bound), _mm_cmple_epi8(chunk, lower_bound));\n        __m128i filtered = _mm_and_si128(chunk, in_range);\n        __m128i sum_chunk = _mm_sad_epu8(filtered, zero);\n        sum += _mm_extract_epi16(sum_chunk, 0) + _mm_extract_epi16(sum_chunk, 4);\n    }\n\n    for (int i = len & ~15; i < len; ++i) {\n        if (str[i] >= 'A' && str[i] <= 'Z') {\n            sum += static_cast<int>(str[i]);\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_93_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nint digitSum_simd(std::string s) {\n    int sum = 0;\n    int len = s.size();\n    const char* str = s.c_str();\n\n    __m128i zero = _mm_setzero_si128();\n    __m128i upper_mask = _mm_set1_epi8(0x80);\n    __m128i a_mask = _mm_set1_epi8('A');\n    __m128i z_mask = _mm_set1_epi8('Z');\n\n    for (int i = 0; i <= len - 16; i += 16) {\n        __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(str + i));\n        __m128i is_upper = _mm_and_si128(chunk, upper_mask);\n        __m128i is_between_a_z = _mm_and_si128(_mm_cmpgt_epi8(chunk, a_mask), _mm_cmple_epi8(chunk, z_mask));\n        __m128i is_upper_alpha = _mm_and_si128(is_upper, is_between_a_z);\n\n        __m128i ascii_sum = _mm_and_si128(chunk, is_upper_alpha);\n        __m128i sum_16bit = _mm_sad_epu8(ascii_sum, zero);\n        __m128i sum_32bit = _mm_add_epi32(sum_16bit, _mm_srli_si128(sum_16bit, 8));\n        sum += _mm_cvtsi128_si32(sum_32bit);\n    }\n\n    for (int i = len & ~15; i < len; ++i) {\n        if (s[i] >= 'A' && s[i] <= 'Z') {\n            sum += static_cast<int>(s[i]);\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_93_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nint digitSum_simd(std::string s) {\n    int sum = 0;\n    int len = s.size();\n    const char* str = s.c_str();\n\n    __m128i zero = _mm_setzero_si128();\n    __m128i upper_mask = _mm_set1_epi8(0x80);\n    __m128i upper_bound = _mm_set1_epi8('A');\n    __m128i lower_bound = _mm_set1_epi8('Z');\n\n    for (int i = 0; i <= len - 16; i += 16) {\n        __m128i chars = _mm_loadu_si128(reinterpret_cast<const __m128i*>(str + i));\n        __m128i upper_check = _mm_and_si128(chars, upper_mask);\n        __m128i in_range = _mm_and_si128(_mm_cmpgt_epi8(chars, upper_bound), _mm_cmple_epi8(chars, lower_bound));\n        __m128i upper_chars = _mm_and_si128(chars, in_range);\n        __m128i upper_sum = _mm_sad_epu8(upper_chars, zero);\n        sum += _mm_extract_epi16(upper_sum, 0) + _mm_extract_epi16(upper_sum, 4);\n    }\n\n    for (int i = len & ~15; i < len; ++i) {\n        if (str[i] >= 'A' && str[i] <= 'Z') {\n            sum += static_cast<int>(str[i]);\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_93_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nint digitSum_simd(std::string s) {\n    int sum = 0;\n    int len = s.length();\n    const char* str = s.c_str();\n\n    __m128i zero = _mm_setzero_si128();\n    __m128i upper_mask = _mm_set1_epi8(0x80);\n    __m128i a_mask = _mm_set1_epi8('A');\n    __m128i z_mask = _mm_set1_epi8('Z');\n\n    for (int i = 0; i <= len - 16; i += 16) {\n        __m128i chars = _mm_loadu_si128(reinterpret_cast<const __m128i*>(str + i));\n        __m128i upper_check = _mm_and_si128(chars, upper_mask);\n        __m128i a_check = _mm_cmpgt_epi8(chars, a_mask);\n        __m128i z_check = _mm_cmplt_epi8(chars, z_mask);\n        __m128i upper_and_a = _mm_and_si128(upper_check, a_check);\n        __m128i valid_upper = _mm_and_si128(upper_and_a, z_check);\n        __m128i ascii_sum = _mm_and_si128(chars, valid_upper);\n        __m128i sum_epi32 = _mm_sad_epu8(ascii_sum, zero);\n        __m64 low_sum = _mm_cvtsi128_si64(sum_epi32);\n        __m64 high_sum = _mm_cvtsi128_si64(_mm_srli_si128(sum_epi32, 8));\n        sum += static_cast<int>(low_sum) + static_cast<int>(high_sum);\n    }\n\n    for (int i = (len & ~15); i < len; ++i) {\n        if (s[i] >= 'A' && s[i] <= 'Z') {\n            sum += static_cast<int>(s[i]);\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_93_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nint digitSum_simd(std::string s) {\n    int sum = 0;\n    int len = s.size();\n    const char* str = s.c_str();\n\n    __m128i zero = _mm_setzero_si128();\n    __m128i upper_mask = _mm_set1_epi8(0x80);\n    __m128i upper_bound = _mm_set1_epi8('A');\n    __m128i lower_bound = _mm_set1_epi8('Z');\n\n    for (int i = 0; i <= len - 16; i += 16) {\n        __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(str + i));\n        __m128i is_upper = _mm_and_si128(_mm_cmplt_epi8(chunk, lower_bound), _mm_cmpgt_epi8(chunk, upper_bound));\n        __m128i upper_chars = _mm_and_si128(chunk, is_upper);\n        __m128i upper_chars_sad = _mm_sad_epu8(upper_chars, zero);\n        __m128i upper_chars_sum = _mm_add_epi16(_mm_srli_si128(upper_chars_sad, 8), upper_chars_sad);\n        sum += _mm_cvtsi128_si32(upper_chars_sum);\n    }\n\n    for (int i = len & ~15; i < len; ++i) {\n        if (str[i] >= 'A' && str[i] <= 'Z') {\n            sum += static_cast<int>(str[i]);\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_94_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <limits>\n\nstd::vector<int> pluck_simd(std::vector<int> arr) {\n    if (arr.empty()) return {};\n\n    __m128i min_even = _mm_set1_epi32(std::numeric_limits<int>::max());\n    __m128i min_index = _mm_set1_epi32(-1);\n    __m128i indices = _mm_setr_epi32(0, 1, 2, 3);\n    int step = 4;\n    int n = arr.size();\n    int min_val = std::numeric_limits<int>::max();\n    int min_idx = -1;\n\n    for (int i = 0; i < n; i += step) {\n        __m128i values = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&arr[i]));\n        __m128i even_mask = _mm_and_si128(values, _mm_set1_epi32(1));\n        even_mask = _mm_cmpeq_epi32(even_mask, _mm_setzero_si128());\n\n        __m128i masked_values = _mm_or_si128(_mm_and_si128(values, even_mask), _mm_set1_epi32(std::numeric_limits<int>::max()));\n        __m128i masked_indices = _mm_or_si128(_mm_and_si128(indices, even_mask), _mm_set1_epi32(-1));\n\n        __m128i min_vals = _mm_min_epi32(masked_values, min_even);\n        __m128i min_idxs = _mm_blendv_epi8(min_index, masked_indices, _mm_cmplt_epi32(masked_values, min_even));\n\n        min_even = min_vals;\n        min_index = min_idxs;\n\n        indices = _mm_add_epi32(indices, _mm_set1_epi32(step));\n    }\n\n    int results[4];\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(results), min_even);\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(results + 2), min_index);\n\n    for (int i = 0; i < 4; ++i) {\n        if (results[i] < min_val && results[i + 2] != -1) {\n            min_val = results[i];\n            min_idx = results[i + 2];\n        }\n    }\n\n    if (min_idx == -1) return {};\n    return {min_val, min_idx};\n}\n```"}
{"task_id": "SimdBench_94_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <limits>\n\nstd::vector<int> pluck_simd(std::vector<int> arr) {\n    if (arr.empty()) return {};\n\n    int min_even = std::numeric_limits<int>::max();\n    int min_index = -1;\n    int n = arr.size();\n\n    __m128i min_even_vec = _mm_set1_epi32(min_even);\n    __m128i min_index_vec = _mm_set1_epi32(-1);\n    __m128i indices = _mm_setr_epi32(0, 1, 2, 3);\n\n    for (int i = 0; i < n; i += 4) {\n        __m128i values = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&arr[i]));\n        __m128i evens = _mm_and_si128(values, _mm_set1_epi32(1));\n        __m128i masked_values = _mm_or_si128(_mm_andnot_si128(evens, values), _mm_set1_epi32(min_even));\n\n        __m128i cmp = _mm_cmplt_epi32(masked_values, min_even_vec);\n        min_even_vec = _mm_min_epi32(masked_values, min_even_vec);\n        min_index_vec = _mm_blendv_epi8(min_index_vec, indices, cmp);\n\n        indices = _mm_add_epi32(indices, _mm_set1_epi32(4));\n    }\n\n    int min_even_arr[4];\n    int min_index_arr[4];\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(min_even_arr), min_even_vec);\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(min_index_arr), min_index_vec);\n\n    for (int i = 0; i < 4; ++i) {\n        if (min_even_arr[i] < min_even) {\n            min_even = min_even_arr[i];\n            min_index = min_index_arr[i];\n        }\n    }\n\n    if (min_index == -1) return {};\n    return {min_even, min_index};\n}\n```"}
{"task_id": "SimdBench_94_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <limits>\n\nstd::vector<int> pluck_simd(std::vector<int> arr) {\n    if (arr.empty()) return {};\n\n    __m128i min_even = _mm_set1_epi32(std::numeric_limits<int>::max());\n    __m128i min_index = _mm_set1_epi32(-1);\n    __m128i indices = _mm_setr_epi32(0, 1, 2, 3);\n    int step = 4;\n    int n = arr.size();\n    int min_val = std::numeric_limits<int>::max();\n    int min_idx = -1;\n\n    for (int i = 0; i < n; i += step) {\n        __m128i vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&arr[i]));\n        __m128i even_mask = _mm_and_si128(vec, _mm_set1_epi32(1));\n        even_mask = _mm_cmpeq_epi32(even_mask, _mm_setzero_si128());\n\n        __m128i masked_vec = _mm_and_si128(vec, even_mask);\n        __m128i masked_indices = _mm_and_si128(indices, even_mask);\n\n        __m128i cmp = _mm_cmpgt_epi32(min_even, masked_vec);\n        min_even = _mm_min_epi32(min_even, masked_vec);\n        min_index = _mm_blendv_epi8(min_index, masked_indices, cmp);\n\n        indices = _mm_add_epi32(indices, _mm_set1_epi32(step));\n    }\n\n    int min_vals[4];\n    int min_idxs[4];\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(min_vals), min_even);\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(min_idxs), min_index);\n\n    for (int i = 0; i < 4; ++i) {\n        if (min_vals[i] < min_val && min_idxs[i] != -1) {\n            min_val = min_vals[i];\n            min_idx = min_idxs[i] + (min_idx / step) * step;\n        }\n    }\n\n    if (min_idx == -1) return {};\n    return {min_val, min_idx};\n}\n```"}
{"task_id": "SimdBench_94_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <limits>\n\nstd::vector<int> pluck_simd(std::vector<int> arr) {\n    if (arr.empty()) return {};\n\n    int min_even = std::numeric_limits<int>::max();\n    int min_index = -1;\n    int n = arr.size();\n\n    __m128i min_even_vec = _mm_set1_epi32(min_even);\n    __m128i min_index_vec = _mm_set1_epi32(-1);\n    __m128i indices = _mm_setr_epi32(0, 1, 2, 3);\n\n    for (int i = 0; i < n; i += 4) {\n        __m128i values = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&arr[i]));\n        __m128i evens = _mm_and_si128(values, _mm_set1_epi32(1));\n        __m128i masked_values = _mm_or_si128(_mm_andnot_si128(evens, values), _mm_set1_epi32(min_even));\n\n        __m128i cmp = _mm_cmplt_epi32(masked_values, min_even_vec);\n        min_even_vec = _mm_min_epi32(masked_values, min_even_vec);\n        min_index_vec = _mm_blendv_epi8(min_index_vec, indices, cmp);\n\n        indices = _mm_add_epi32(indices, _mm_set1_epi32(4));\n    }\n\n    int min_even_arr[4];\n    int min_index_arr[4];\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(min_even_arr), min_even_vec);\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(min_index_arr), min_index_vec);\n\n    for (int i = 0; i < 4; ++i) {\n        if (min_even_arr[i] < min_even) {\n            min_even = min_even_arr[i];\n            min_index = min_index_arr[i];\n        }\n    }\n\n    if (min_index == -1) return {};\n    return {min_even, min_index};\n}\n```"}
{"task_id": "SimdBench_94_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <limits>\n\nstd::vector<int> pluck_simd(std::vector<int> arr) {\n    if (arr.empty()) return {};\n\n    int min_even = std::numeric_limits<int>::max();\n    int min_index = -1;\n    int n = arr.size();\n\n    __m128i min_even_vec = _mm_set1_epi32(min_even);\n    __m128i min_index_vec = _mm_set1_epi32(-1);\n    __m128i index_vec = _mm_setr_epi32(0, 1, 2, 3);\n    __m128i increment_vec = _mm_set1_epi32(4);\n\n    for (int i = 0; i < n; i += 4) {\n        __m128i vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&arr[i]));\n        __m128i mask = _mm_and_si128(vec, _mm_set1_epi32(1));\n        mask = _mm_cmpeq_epi32(mask, _mm_setzero_si128());\n\n        __m128i even_vec = _mm_and_si128(vec, mask);\n        __m128i min_mask = _mm_cmplt_epi32(even_vec, min_even_vec);\n        min_even_vec = _mm_min_epi32(min_even_vec, even_vec);\n\n        __m128i index_mask = _mm_and_si128(index_vec, mask);\n        __m128i min_index_candidate = _mm_blendv_epi8(min_index_vec, index_mask, min_mask);\n        min_index_vec = _mm_min_epi32(min_index_vec, min_index_candidate);\n\n        index_vec = _mm_add_epi32(index_vec, increment_vec);\n    }\n\n    int min_even_arr[4];\n    int min_index_arr[4];\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(min_even_arr), min_even_vec);\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(min_index_arr), min_index_vec);\n\n    for (int i = 0; i < 4; ++i) {\n        if (min_even_arr[i] < min_even) {\n            min_even = min_even_arr[i];\n            min_index = min_index_arr[i];\n        }\n    }\n\n    if (min_index == -1) return {};\n    return {min_even, min_index};\n}\n```"}
{"task_id": "SimdBench_95_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n\nint search_simd(std::vector<int> lst) {\n    if (lst.empty()) return -1;\n\n    int max_val = *std::max_element(lst.begin(), lst.end());\n    std::vector<int> freq(max_val + 1, 0);\n\n    for (size_t i = 0; i < lst.size(); i += 4) {\n        __m128i vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&lst[i]));\n        __m128i ones = _mm_set1_epi32(1);\n\n        for (int j = 0; j < 4 && i + j < lst.size(); ++j) {\n            int val = _mm_extract_epi32(vec, j);\n            freq[val] += 1;\n        }\n    }\n\n    for (int i = max_val; i > 0; --i) {\n        if (freq[i] >= i) {\n            return i;\n        }\n    }\n\n    return -1;\n}\n```"}
{"task_id": "SimdBench_95_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n\nint search_simd(std::vector<int> lst) {\n    if (lst.empty()) return -1;\n\n    int max_val = *std::max_element(lst.begin(), lst.end());\n    std::vector<int> freq(max_val + 1, 0);\n\n    for (size_t i = 0; i < lst.size(); i += 4) {\n        __m128i vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&lst[i]));\n        __m128i ones = _mm_set1_epi32(1);\n\n        for (int j = 0; j < 4 && i + j < lst.size(); ++j) {\n            int val = _mm_extract_epi32(vec, j);\n            freq[val] += 1;\n        }\n    }\n\n    for (int i = max_val; i > 0; --i) {\n        if (freq[i] >= i) {\n            return i;\n        }\n    }\n\n    return -1;\n}\n```"}
{"task_id": "SimdBench_95_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n\nint search_simd(std::vector<int> lst) {\n    if (lst.empty()) return -1;\n\n    int max_val = *std::max_element(lst.begin(), lst.end());\n    std::vector<int> freq(max_val + 1, 0);\n\n    for (size_t i = 0; i < lst.size(); i += 4) {\n        __m128i vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&lst[i]));\n        __m128i zero = _mm_setzero_si128();\n        __m128i cmp = _mm_cmpgt_epi32(vec, zero);\n        __m128i mask = _mm_and_si128(cmp, _mm_cmplt_epi32(vec, _mm_set1_epi32(freq.size())));\n        for (int j = 0; j < 4; ++j) {\n            if (_mm_extract_epi32(mask, j)) {\n                freq[_mm_extract_epi32(vec, j)]++;\n            }\n        }\n    }\n\n    for (int i = max_val; i > 0; --i) {\n        if (freq[i] >= i) {\n            return i;\n        }\n    }\n\n    return -1;\n}\n```"}
{"task_id": "SimdBench_95_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n\nint search_simd(std::vector<int> lst) {\n    if (lst.empty()) return -1;\n\n    int max_val = *std::max_element(lst.begin(), lst.end());\n    std::vector<int> freq(max_val + 1, 0);\n\n    for (size_t i = 0; i < lst.size(); i += 4) {\n        __m128i vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&lst[i]));\n        __m128i ones = _mm_set1_epi32(1);\n\n        for (int j = 0; j < 4 && i + j < lst.size(); ++j) {\n            int val = _mm_extract_epi32(vec, j);\n            freq[val] += 1;\n        }\n    }\n\n    for (int i = max_val; i > 0; --i) {\n        if (freq[i] >= i) {\n            return i;\n        }\n    }\n\n    return -1;\n}\n```"}
{"task_id": "SimdBench_95_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n\nint search_simd(std::vector<int> lst) {\n    if (lst.empty()) return -1;\n\n    int max_val = *std::max_element(lst.begin(), lst.end());\n    std::vector<int> freq(max_val + 1, 0);\n\n    for (size_t i = 0; i < lst.size(); i += 4) {\n        __m128i vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&lst[i]));\n        __m128i zero = _mm_setzero_si128();\n        __m128i cmp = _mm_cmpgt_epi32(vec, zero);\n        __m128i mask = _mm_and_si128(cmp, _mm_cmplt_epi32(vec, _mm_set1_epi32(freq.size())));\n        for (int j = 0; j < 4; ++j) {\n            if (_mm_extract_epi32(mask, j)) {\n                freq[_mm_extract_epi32(vec, j)]++;\n            }\n        }\n    }\n\n    for (int i = max_val; i > 0; --i) {\n        if (freq[i] >= i) {\n            return i;\n        }\n    }\n\n    return -1;\n}\n```"}
{"task_id": "SimdBench_96_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nbool will_it_fly_simd(std::vector<int> q, int w) {\n    int n = q.size();\n    if (n == 0) return false;\n\n    // Check if the vector is a palindrome\n    for (int i = 0; i < n / 2; ++i) {\n        if (q[i] != q[n - i - 1]) {\n            return false;\n        }\n    }\n\n    // Calculate the sum using SSE\n    __m128i sum = _mm_setzero_si128();\n    int i = 0;\n    for (; i <= n - 4; i += 4) {\n        __m128i vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&q[i]));\n        sum = _mm_add_epi32(sum, vec);\n    }\n\n    // Horizontally add the four integers in sum\n    int temp[4];\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(temp), sum);\n    int total_sum = temp[0] + temp[1] + temp[2] + temp[3];\n\n    // Add remaining elements\n    for (; i < n; ++i) {\n        total_sum += q[i];\n    }\n\n    return total_sum <= w;\n}\n```"}
{"task_id": "SimdBench_96_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nbool will_it_fly_simd(std::vector<int> q, int w) {\n    int n = q.size();\n    if (n == 0) return false;\n\n    // Check if the vector is a palindrome\n    for (int i = 0; i < n / 2; ++i) {\n        if (q[i] != q[n - i - 1]) {\n            return false;\n        }\n    }\n\n    // Calculate the sum using SSE\n    __m128i sum = _mm_setzero_si128();\n    int i = 0;\n    for (; i <= n - 4; i += 4) {\n        __m128i vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&q[i]));\n        sum = _mm_add_epi32(sum, vec);\n    }\n\n    // Horizontally add the four integers in sum\n    int temp[4];\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(temp), sum);\n    int total_sum = temp[0] + temp[1] + temp[2] + temp[3];\n\n    // Add remaining elements\n    for (; i < n; ++i) {\n        total_sum += q[i];\n    }\n\n    return total_sum <= w;\n}\n```"}
{"task_id": "SimdBench_96_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nbool will_it_fly_simd(std::vector<int> q, int w) {\n    int n = q.size();\n    if (n == 0) return false;\n\n    // Check if the vector is a palindrome\n    for (int i = 0; i < n / 2; ++i) {\n        if (q[i] != q[n - i - 1]) {\n            return false;\n        }\n    }\n\n    // Calculate the sum using SSE\n    __m128i sum = _mm_setzero_si128();\n    int i = 0;\n    for (; i <= n - 4; i += 4) {\n        __m128i vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&q[i]));\n        sum = _mm_add_epi32(sum, vec);\n    }\n\n    // Horizontally add the four integers in sum\n    int temp[4];\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(temp), sum);\n    int total_sum = temp[0] + temp[1] + temp[2] + temp[3];\n\n    // Add remaining elements\n    for (; i < n; ++i) {\n        total_sum += q[i];\n    }\n\n    return total_sum <= w;\n}\n```"}
{"task_id": "SimdBench_96_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nbool will_it_fly_simd(std::vector<int> q, int w) {\n    int n = q.size();\n    if (n == 0) return false;\n\n    // Check if the vector is a palindrome\n    for (int i = 0; i < n / 2; ++i) {\n        if (q[i] != q[n - i - 1]) {\n            return false;\n        }\n    }\n\n    // Calculate the sum using SSE\n    __m128i sum = _mm_setzero_si128();\n    int i = 0;\n    for (; i <= n - 4; i += 4) {\n        __m128i vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&q[i]));\n        sum = _mm_add_epi32(sum, vec);\n    }\n\n    // Horizontally add the four integers in sum\n    int horizontal_sum = _mm_extract_epi32(sum, 0) + _mm_extract_epi32(sum, 1) +\n                         _mm_extract_epi32(sum, 2) + _mm_extract_epi32(sum, 3);\n\n    // Add remaining elements\n    for (; i < n; ++i) {\n        horizontal_sum += q[i];\n    }\n\n    return horizontal_sum <= w;\n}\n```"}
{"task_id": "SimdBench_96_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nbool will_it_fly_simd(std::vector<int> q, int w) {\n    int n = q.size();\n    if (n == 0) return false;\n\n    // Check if the vector is a palindrome\n    for (int i = 0; i < n / 2; ++i) {\n        if (q[i] != q[n - i - 1]) {\n            return false;\n        }\n    }\n\n    // Calculate the sum using SSE\n    __m128i sum = _mm_setzero_si128();\n    int i = 0;\n    for (; i <= n - 4; i += 4) {\n        __m128i vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&q[i]));\n        sum = _mm_add_epi32(sum, vec);\n    }\n\n    // Horizontally add the four integers in sum\n    int temp[4];\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(temp), sum);\n    int total_sum = temp[0] + temp[1] + temp[2] + temp[3];\n\n    // Add remaining elements\n    for (; i < n; ++i) {\n        total_sum += q[i];\n    }\n\n    return total_sum <= w;\n}\n```"}
{"task_id": "SimdBench_97_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint smallest_change_simd(std::vector<int> arr) {\n    int n = arr.size();\n    int changes = 0;\n    int* data = arr.data();\n\n    for (int i = 0; i <= n / 2 - 4; i += 4) {\n        __m128i left = _mm_loadu_si128((__m128i*)(data + i));\n        __m128i right = _mm_loadu_si128((__m128i*)(data + n - i - 4));\n        __m128i cmp = _mm_cmpeq_epi32(left, right);\n        int mask = _mm_movemask_epi8(cmp);\n        changes += 4 - __builtin_popcount(mask >> 15);\n    }\n\n    for (int i = (n / 2) & ~3; i < n / 2; ++i) {\n        if (data[i] != data[n - i - 1]) {\n            ++changes;\n        }\n    }\n\n    return changes;\n}\n```"}
{"task_id": "SimdBench_97_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint smallest_change_simd(std::vector<int> arr) {\n    int n = arr.size();\n    int changes = 0;\n    int* data = arr.data();\n\n    for (int i = 0; i <= n / 2 - 4; i += 4) {\n        __m128i a = _mm_loadu_si128((__m128i*)(data + i));\n        __m128i b = _mm_loadu_si128((__m128i*)(data + n - i - 4));\n        __m128i cmp = _mm_cmpeq_epi32(a, b);\n        int mask = _mm_movemask_epi8(cmp);\n        changes += 4 - __builtin_popcount(mask >> 1 & 0x55555555);\n    }\n\n    for (int i = (n / 2) & ~3; i < n / 2; ++i) {\n        if (data[i] != data[n - i - 1]) {\n            ++changes;\n        }\n    }\n\n    return changes;\n}\n```"}
{"task_id": "SimdBench_97_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint smallest_change_simd(std::vector<int> arr) {\n    int n = arr.size();\n    int changes = 0;\n    int* data = arr.data();\n\n    for (int i = 0; i <= n / 2 - 4; i += 4) {\n        __m128i a = _mm_loadu_si128((__m128i*)(data + i));\n        __m128i b = _mm_loadu_si128((__m128i*)(data + n - i - 4));\n        __m128i cmp = _mm_cmpeq_epi32(a, b);\n        int mask = _mm_movemask_epi8(cmp);\n        changes += 4 - (__builtin_popcount(mask) >> 2);\n    }\n\n    for (int i = (n / 2) & ~3; i < n / 2; ++i) {\n        if (data[i] != data[n - i - 1]) {\n            ++changes;\n        }\n    }\n\n    return changes;\n}\n```"}
{"task_id": "SimdBench_97_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint smallest_change_simd(std::vector<int> arr) {\n    int n = arr.size();\n    int changes = 0;\n    int* data = arr.data();\n\n    for (int i = 0; i <= n / 8; i += 2) {\n        __m128i a = _mm_loadu_si128(reinterpret_cast<const __m128i*>(data + i * 4));\n        __m128i b = _mm_loadu_si128(reinterpret_cast<const __m128i*>(data + n - i * 4 - 8));\n\n        __m128i cmp = _mm_cmpeq_epi32(a, b);\n        __m128i not_cmp = _mm_xor_si128(cmp, _mm_set1_epi32(-1));\n\n        changes += _mm_popcnt_u32(_mm_movemask_epi8(not_cmp)) / 4;\n    }\n\n    return changes;\n}\n```"}
{"task_id": "SimdBench_97_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint smallest_change_simd(std::vector<int> arr) {\n    int n = arr.size();\n    int changes = 0;\n    int* data = arr.data();\n\n    for (int i = 0; i <= n / 8; i += 2) {\n        __m128i left = _mm_loadu_si128((__m128i*)(data + i * 4));\n        __m128i right = _mm_loadu_si128((__m128i*)(data + n - i * 4 - 8));\n\n        __m128i cmp1 = _mm_cmpeq_epi32(left, _mm_shuffle_epi32(right, _MM_SHUFFLE(0, 1, 2, 3)));\n        __m128i cmp2 = _mm_cmpeq_epi32(_mm_srli_si128(left, 4), _mm_shuffle_epi32(right, _MM_SHUFFLE(3, 2, 1, 0)));\n\n        __m128i not_equal1 = _mm_andnot_si128(cmp1, _mm_set1_epi32(1));\n        __m128i not_equal2 = _mm_andnot_si128(cmp2, _mm_set1_epi32(1));\n\n        changes += _mm_popcnt_u32(_mm_movemask_epi8(not_equal1)) / 8;\n        changes += _mm_popcnt_u32(_mm_movemask_epi8(not_equal2)) / 8;\n    }\n\n    return changes;\n}\n```"}
{"task_id": "SimdBench_98_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n\nstd::vector<std::string> total_match_simd(const std::vector<std::string> & lst1, const std::vector<std::string> & lst2){\n    int len1 = 0, len2 = 0;\n\n    // Calculate total length of strings in lst1 using SSE\n    const int* ptr1 = reinterpret_cast<const int*>(lst1.data());\n    __m128i sum1 = _mm_setzero_si128();\n    for (size_t i = 0; i < lst1.size(); ++i) {\n        const char* str = lst1[i].c_str();\n        size_t str_len = lst1[i].length();\n        len1 += str_len;\n        for (size_t j = 0; j <= str_len - 16; j += 16) {\n            __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(str + j));\n            __m128i ones = _mm_set1_epi8(1);\n            __m128i counts = _mm_cmpeq_epi8(chunk, ones);\n            sum1 = _mm_add_epi16(sum1, _mm_sad_epu8(counts, _mm_setzero_si128()));\n        }\n        for (size_t j = (str_len / 16) * 16; j < str_len; ++j) {\n            len1 += str[j] != '\\0';\n        }\n    }\n\n    // Calculate total length of strings in lst2 using SSE\n    const int* ptr2 = reinterpret_cast<const int*>(lst2.data());\n    __m128i sum2 = _mm_setzero_si128();\n    for (size_t i = 0; i < lst2.size(); ++i) {\n        const char* str = lst2[i].c_str();\n        size_t str_len = lst2[i].length();\n        len2 += str_len;\n        for (size_t j = 0; j <= str_len - 16; j += 16) {\n            __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(str + j));\n            __m128i ones = _mm_set1_epi8(1);\n            __m128i counts = _mm_cmpeq_epi8(chunk, ones);\n            sum2 = _mm_add_epi16(sum2, _mm_sad_epu8(counts, _mm_setzero_si128()));\n        }\n        for (size_t j = (str_len / 16) * 16; j < str_len; ++j) {\n            len2 += str[j] != '\\0';\n        }\n    }\n\n    // Sum up the results from SSE\n    int total1 = len1;\n    int total2 = len2;\n\n    // Compare total lengths and return the appropriate vector\n    if (total1 < total2) {\n        return lst1;\n    } else if (total2 < total1) {\n        return lst2;\n    } else {\n        return lst1;\n    }\n}\n```"}
{"task_id": "SimdBench_98_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n\nstd::vector<std::string> total_match_simd(const std::vector<std::string> & lst1, const std::vector<std::string> & lst2){\n    int len1 = 0, len2 = 0;\n\n    // Process lst1\n    const int* ptr1 = reinterpret_cast<const int*>(lst1.data());\n    int size1 = lst1.size();\n    __m128i sum1 = _mm_setzero_si128();\n    for (int i = 0; i < size1; ++i) {\n        const char* str = lst1[i].c_str();\n        int length = lst1[i].size();\n        len1 += length;\n        while (length >= 16) {\n            __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(str));\n            __m128i ones = _mm_set1_epi8(1);\n            __m128i counts = _mm_cmpeq_epi8(chunk, ones);\n            sum1 = _mm_add_epi16(sum1, _mm_sad_epu8(counts, _mm_setzero_si128()));\n            str += 16;\n            length -= 16;\n        }\n        // Handle remaining characters\n        while (length > 0) {\n            sum1 = _mm_add_epi32(sum1, _mm_cvtsi32_si128(*str));\n            ++str;\n            --length;\n        }\n    }\n\n    // Process lst2\n    const int* ptr2 = reinterpret_cast<const int*>(lst2.data());\n    int size2 = lst2.size();\n    __m128i sum2 = _mm_setzero_si128();\n    for (int i = 0; i < size2; ++i) {\n        const char* str = lst2[i].c_str();\n        int length = lst2[i].size();\n        len2 += length;\n        while (length >= 16) {\n            __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(str));\n            __m128i ones = _mm_set1_epi8(1);\n            __m128i counts = _mm_cmpeq_epi8(chunk, ones);\n            sum2 = _mm_add_epi16(sum2, _mm_sad_epu8(counts, _mm_setzero_si128()));\n            str += 16;\n            length -= 16;\n        }\n        // Handle remaining characters\n        while (length > 0) {\n            sum2 = _mm_add_epi32(sum2, _mm_cvtsi32_si128(*str));\n            ++str;\n            --length;\n        }\n    }\n\n    // Sum up the results\n    int total1 = len1 + _mm_extract_epi16(_mm_sad_epu8(sum1, _mm_setzero_si128()), 0);\n    int total2 = len2 + _mm_extract_epi16(_mm_sad_epu8(sum2, _mm_setzero_si128()), 0);\n\n    return total1 < total2 ? lst1 : lst2;\n}\n```"}
{"task_id": "SimdBench_98_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n\nstd::vector<std::string> total_match_simd(const std::vector<std::string> & lst1, const std::vector<std::string> & lst2){\n    int len1 = 0, len2 = 0;\n\n    // Process lst1\n    const int* ptr1 = reinterpret_cast<const int*>(lst1.data());\n    size_t size1 = lst1.size();\n    for (size_t i = 0; i < size1; ++i) {\n        const char* str = lst1[i].c_str();\n        size_t str_len = lst1[i].length();\n        len1 += str_len;\n    }\n\n    // Process lst2\n    const int* ptr2 = reinterpret_cast<const int*>(lst2.data());\n    size_t size2 = lst2.size();\n    for (size_t i = 0; i < size2; ++i) {\n        const char* str = lst2[i].c_str();\n        size_t str_len = lst2[i].length();\n        len2 += str_len;\n    }\n\n    // Compare lengths\n    if (len1 < len2) {\n        return lst1;\n    } else if (len2 < len1) {\n        return lst2;\n    } else {\n        return lst1;\n    }\n}\n```"}
{"task_id": "SimdBench_98_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n\nstd::vector<std::string> total_match_simd(const std::vector<std::string> & lst1, const std::vector<std::string> & lst2){\n    int len1 = 0, len2 = 0;\n\n    // Process lst1\n    const int* ptr1 = reinterpret_cast<const int*>(lst1.data());\n    int size1 = lst1.size();\n    __m128i sum1 = _mm_setzero_si128();\n    for (int i = 0; i < size1; ++i) {\n        const char* str = lst1[i].c_str();\n        int length = lst1[i].size();\n        len1 += length;\n        while (length >= 16) {\n            __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(str));\n            __m128i ones = _mm_set1_epi8(1);\n            __m128i counts = _mm_cmpeq_epi8(chunk, ones);\n            sum1 = _mm_add_epi16(sum1, _mm_sad_epu8(counts, _mm_setzero_si128()));\n            str += 16;\n            length -= 16;\n        }\n        if (length > 0) {\n            __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(str));\n            __m128i mask = _mm_cmplt_epi8(_mm_setzero_si128(), chunk);\n            __m128i counts = _mm_and_si128(mask, _mm_set1_epi8(1));\n            sum1 = _mm_add_epi16(sum1, _mm_sad_epu8(counts, _mm_setzero_si128()));\n        }\n    }\n\n    // Process lst2\n    const int* ptr2 = reinterpret_cast<const int*>(lst2.data());\n    int size2 = lst2.size();\n    __m128i sum2 = _mm_setzero_si128();\n    for (int i = 0; i < size2; ++i) {\n        const char* str = lst2[i].c_str();\n        int length = lst2[i].size();\n        len2 += length;\n        while (length >= 16) {\n            __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(str));\n            __m128i ones = _mm_set1_epi8(1);\n            __m128i counts = _mm_cmpeq_epi8(chunk, ones);\n            sum2 = _mm_add_epi16(sum2, _mm_sad_epu8(counts, _mm_setzero_si128()));\n            str += 16;\n            length -= 16;\n        }\n        if (length > 0) {\n            __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(str));\n            __m128i mask = _mm_cmplt_epi8(_mm_setzero_si128(), chunk);\n            __m128i counts = _mm_and_si128(mask, _mm_set1_epi8(1));\n            sum2 = _mm_add_epi16(sum2, _mm_sad_epu8(counts, _mm_setzero_si128()));\n        }\n    }\n\n    int total1 = len1 + _mm_extract_epi16(_mm_sad_epu8(sum1, _mm_setzero_si128()), 0);\n    int total2 = len2 + _mm_extract_epi16(_mm_sad_epu8(sum2, _mm_setzero_si128()), 0);\n\n    return total1 < total2 ? lst1 : lst2;\n}\n```"}
{"task_id": "SimdBench_98_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n\nstd::vector<std::string> total_match_simd(const std::vector<std::string> & lst1, const std::vector<std::string> & lst2){\n    int len1 = 0, len2 = 0;\n\n    // Process lst1\n    const int* ptr1 = reinterpret_cast<const int*>(lst1.data());\n    int size1 = lst1.size();\n    __m128i sum1 = _mm_setzero_si128();\n    for (int i = 0; i < size1; i += 4) {\n        __m128i str1 = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&ptr1[i]));\n        __m128i lengths1 = _mm_cvtepu8_epi32(_mm_setr_epi8(lst1[i].size(), lst1[i+1].size(), lst1[i+2].size(), lst1[i+3].size(), 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0));\n        sum1 = _mm_add_epi32(sum1, lengths1);\n    }\n    int temp1[4];\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(temp1), sum1);\n    len1 = temp1[0] + temp1[1] + temp1[2] + temp1[3];\n\n    // Process lst2\n    const int* ptr2 = reinterpret_cast<const int*>(lst2.data());\n    int size2 = lst2.size();\n    __m128i sum2 = _mm_setzero_si128();\n    for (int i = 0; i < size2; i += 4) {\n        __m128i str2 = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&ptr2[i]));\n        __m128i lengths2 = _mm_cvtepu8_epi32(_mm_setr_epi8(lst2[i].size(), lst2[i+1].size(), lst2[i+2].size(), lst2[i+3].size(), 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0));\n        sum2 = _mm_add_epi32(sum2, lengths2);\n    }\n    int temp2[4];\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(temp2), sum2);\n    len2 = temp2[0] + temp2[1] + temp2[2] + temp2[3];\n\n    // Calculate remaining lengths\n    for (int i = (size1 % 4); i < size1; ++i) {\n        len1 += lst1[i].size();\n    }\n    for (int i = (size2 % 4); i < size2; ++i) {\n        len2 += lst2[i].size();\n    }\n\n    return len1 < len2 ? lst1 : lst2;\n}\n```"}
{"task_id": "SimdBench_99_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool is_simple_power_simd(uint64_t x, uint64_t n){\n    if (n == 1) return x == 1;\n    if (n == 0) return x == 0;\n\n    __m128i xmm_x = _mm_set1_epi64x(x);\n    __m128i xmm_n = _mm_set1_epi64x(n);\n    __m128i xmm_one = _mm_set1_epi64x(1);\n    __m128i xmm_result = xmm_one;\n\n    while (true) {\n        __m128i xmm_temp = _mm_mullo_epi64(xmm_result, xmm_n);\n        __m128i xmm_mask = _mm_cmpeq_epi64(xmm_temp, xmm_x);\n        int mask = _mm_movemask_epi8(xmm_mask);\n\n        if (mask == 0xFFFF) return true;\n\n        xmm_mask = _mm_cmpgt_epi64(xmm_temp, xmm_x);\n        mask = _mm_movemask_epi8(xmm_mask);\n\n        if (mask == 0xFFFF) return false;\n\n        xmm_result = xmm_temp;\n    }\n}\n```"}
{"task_id": "SimdBench_99_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool is_simple_power_simd(uint64_t x, uint64_t n) {\n    if (n == 1) return x == 1;\n    if (n == 0) return x == 0;\n\n    __m128i x_vec = _mm_set1_epi64x(x);\n    __m128i n_vec = _mm_set1_epi64x(n);\n    __m128i one_vec = _mm_set1_epi64x(1);\n    __m128i result_vec = one_vec;\n\n    while (true) {\n        result_vec = _mm_mullo_epi64(result_vec, n_vec);\n        __m128i cmp_vec = _mm_cmpeq_epi64(result_vec, x_vec);\n        int mask = _mm_movemask_epi8(cmp_vec);\n\n        if (mask & 0x80) return true; // Check if the highest bit is set\n\n        __m128i overflow_vec = _mm_cmpgt_epi64(result_vec, x_vec);\n        mask = _mm_movemask_epi8(overflow_vec);\n\n        if (mask & 0x80) break; // Check if the highest bit is set\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_99_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool is_simple_power_simd(uint64_t x, uint64_t n){\n    if (n == 1) return x == 1;\n    if (n == 0) return x == 0;\n\n    __m128i x_vec = _mm_set1_epi64x(x);\n    __m128i n_vec = _mm_set1_epi64x(n);\n    __m128i one_vec = _mm_set1_epi64x(1);\n    __m128i result_vec = one_vec;\n\n    while (true) {\n        result_vec = _mm_mullo_epi64(result_vec, n_vec);\n        __m128i cmp_vec = _mm_cmpeq_epi64(result_vec, x_vec);\n        int mask = _mm_movemask_epi8(cmp_vec);\n        if (mask & 0x80) return true;\n\n        __m128i overflow_vec = _mm_cmpgt_epi64(result_vec, x_vec);\n        mask = _mm_movemask_epi8(overflow_vec);\n        if (mask & 0x80) return false;\n    }\n}\n```"}
{"task_id": "SimdBench_99_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool is_simple_power_simd(uint64_t x, uint64_t n){\n    if (n == 1) return x == 1;\n    if (n == 0) return x == 0;\n\n    __m128i xmm_x = _mm_set1_epi64x(x);\n    __m128i xmm_n = _mm_set1_epi64x(n);\n    __m128i xmm_one = _mm_set1_epi64x(1);\n    __m128i xmm_result = xmm_one;\n\n    while (true) {\n        __m128i xmm_temp = _mm_mullo_epi64(xmm_result, xmm_n);\n        __m128i xmm_mask = _mm_cmpeq_epi64(xmm_temp, xmm_x);\n        int mask = _mm_movemask_epi8(xmm_mask);\n\n        if (mask == 0xFFFF) return true;\n\n        xmm_mask = _mm_cmpgt_epi64(xmm_temp, xmm_x);\n        mask = _mm_movemask_epi8(xmm_mask);\n\n        if (mask == 0xFFFF) return false;\n\n        xmm_result = xmm_temp;\n    }\n}\n```"}
{"task_id": "SimdBench_99_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool is_simple_power_simd(uint64_t x, uint64_t n){\n    if (n == 1) return x == 1;\n    if (n == 0) return x == 0;\n\n    __m128i xmm_x = _mm_set1_epi64x(x);\n    __m128i xmm_n = _mm_set1_epi64x(n);\n    __m128i xmm_one = _mm_set1_epi64x(1);\n    __m128i xmm_result = xmm_one;\n\n    while (true) {\n        __m128i xmm_temp = _mm_mullo_epi64(xmm_result, xmm_n);\n        __m128i xmm_mask = _mm_cmpeq_epi64(xmm_temp, xmm_x);\n        if (_mm_movemask_epi8(xmm_mask) != 0) return true;\n        xmm_result = xmm_temp;\n        xmm_mask = _mm_cmpgt_epi64(xmm_result, xmm_x);\n        if (_mm_movemask_epi8(xmm_mask) != 0) break;\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_100_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint hex_key_simd(const std::string & num){\n    int count = 0;\n    const int len = num.size();\n    const char* str = num.c_str();\n\n    __m128i primes = _mm_set_epi8(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0xD, 0xB, 0x7, 0x5, 0x3);\n    __m128i twos = _mm_set1_epi8(0x2);\n\n    for (int i = 0; i <= len - 16; i += 16) {\n        __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(str + i));\n        __m128i cmp1 = _mm_cmpeq_epi8(chunk, primes);\n        __m128i cmp2 = _mm_cmpeq_epi8(chunk, twos);\n        __m128i result = _mm_or_si128(cmp1, cmp2);\n        count += _mm_popcnt_u32(_mm_movemask_epi8(result));\n    }\n\n    for (int i = len & ~15; i < len; ++i) {\n        char c = str[i];\n        if (c == '2' || c == '3' || c == '5' || c == '7' || c == 'B' || c == 'D') {\n            ++count;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_100_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint hex_key_simd(const std::string & num){\n    int count = 0;\n    const int len = num.size();\n    const char* str = num.c_str();\n\n    __m128i primes = _mm_set_epi8(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0xD, 0xB, 0x7, 0x5, 0x3);\n    __m128i twos = _mm_set1_epi8(0x2);\n\n    for (int i = 0; i <= len - 16; i += 16) {\n        __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(str + i));\n        __m128i cmp1 = _mm_cmpeq_epi8(chunk, primes);\n        __m128i cmp2 = _mm_cmpeq_epi8(chunk, twos);\n        __m128i or_result = _mm_or_si128(cmp1, cmp2);\n        __m128i mask = _mm_movemask_epi8(or_result);\n        count += __builtin_popcount(mask);\n    }\n\n    for (int i = len & ~15; i < len; ++i) {\n        char c = str[i];\n        if (c == '2' || c == '3' || c == '5' || c == '7' || c == 'B' || c == 'D') {\n            ++count;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_100_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint hex_key_simd(const std::string & num){\n    int count = 0;\n    const int len = num.size();\n    const char* str = num.c_str();\n\n    __m128i primes = _mm_set_epi8(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0xD, 0xB, 0x7, 0x5, 0x3);\n    __m128i twos = _mm_set1_epi8(0x2);\n\n    for (int i = 0; i <= len - 16; i += 16) {\n        __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(str + i));\n        __m128i cmp1 = _mm_cmpeq_epi8(chunk, primes);\n        __m128i cmp2 = _mm_cmpeq_epi8(chunk, twos);\n        __m128i or_result = _mm_or_si128(cmp1, cmp2);\n        __m128i mask = _mm_movemask_epi8(or_result);\n        count += __builtin_popcount(mask);\n    }\n\n    for (int i = len & ~15; i < len; ++i) {\n        char c = str[i];\n        if (c == '2' || c == '3' || c == '5' || c == '7' || c == 'B' || c == 'D') {\n            ++count;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_100_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint hex_key_simd(const std::string & num){\n    int count = 0;\n    const int len = num.size();\n    const char* str = num.c_str();\n\n    __m128i primes = _mm_set_epi8(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0xD, 0xB, 0x7, 0x5, 0x3);\n    __m128i twos = _mm_set1_epi8(0x2);\n\n    for (int i = 0; i <= len - 16; i += 16) {\n        __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(str + i));\n        __m128i cmp1 = _mm_cmpeq_epi8(chunk, primes);\n        __m128i cmp2 = _mm_cmpeq_epi8(chunk, twos);\n        __m128i result = _mm_or_si128(cmp1, cmp2);\n        count += _mm_popcnt_u32(_mm_movemask_epi8(result));\n    }\n\n    for (int i = len & ~15; i < len; ++i) {\n        char c = str[i];\n        if (c == '2' || c == '3' || c == '5' || c == '7' || c == 'B' || c == 'D') {\n            ++count;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_100_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint hex_key_simd(const std::string & num){\n    int count = 0;\n    const int len = num.size();\n    const char* str = num.c_str();\n\n    __m128i primes = _mm_set_epi8(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0xD, 0xB, 0x7, 0x5, 0x3);\n    __m128i twos = _mm_set1_epi8(0x2);\n\n    for (int i = 0; i <= len - 16; i += 16) {\n        __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(str + i));\n        __m128i cmp1 = _mm_cmpeq_epi8(chunk, primes);\n        __m128i cmp2 = _mm_cmpeq_epi8(chunk, twos);\n        __m128i or_result = _mm_or_si128(cmp1, cmp2);\n        __m128i mask = _mm_movemask_epi8(or_result);\n        count += __builtin_popcount(mask);\n    }\n\n    for (int i = len & ~15; i < len; ++i) {\n        char c = str[i];\n        if (c == '2' || c == '3' || c == '5' || c == '7' || c == 'B' || c == 'D') {\n            count++;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_101_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool is_happy_simd(const std::string & s){\n    int n = s.size();\n    if (n < 3) return false;\n\n    const char* str = s.c_str();\n    __m128i zero = _mm_setzero_si128();\n\n    for (int i = 0; i <= n - 16; i += 15) {\n        __m128i vec1 = _mm_loadu_si128(reinterpret_cast<const __m128i*>(str + i));\n        __m128i vec2 = _mm_loadu_si128(reinterpret_cast<const __m128i*>(str + i + 1));\n        __m128i vec3 = _mm_loadu_si128(reinterpret_cast<const __m128i*>(str + i + 2));\n\n        __m128i cmp1 = _mm_cmpeq_epi8(vec1, vec2);\n        __m128i cmp2 = _mm_cmpeq_epi8(vec1, vec3);\n        __m128i cmp3 = _mm_cmpeq_epi8(vec2, vec3);\n\n        __m128i or1 = _mm_or_si128(cmp1, cmp2);\n        __m128i or2 = _mm_or_si128(or1, cmp3);\n\n        __m128i result = _mm_or_si128(or2, zero);\n        if (!_mm_test_all_zeros(result, result)) {\n            return false;\n        }\n    }\n\n    for (int i = n - 15; i <= n - 3; ++i) {\n        if (str[i] == str[i + 1] || str[i] == str[i + 2] || str[i + 1] == str[i + 2]) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_101_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool is_happy_simd(const std::string & s){\n    int n = s.size();\n    if (n < 3) return false;\n\n    const char* str = s.c_str();\n    __m128i zero = _mm_setzero_si128();\n\n    for (int i = 0; i <= n - 16; i += 15) {\n        __m128i vec1 = _mm_loadu_si128(reinterpret_cast<const __m128i*>(str + i));\n        __m128i vec2 = _mm_loadu_si128(reinterpret_cast<const __m128i*>(str + i + 1));\n        __m128i vec3 = _mm_loadu_si128(reinterpret_cast<const __m128i*>(str + i + 2));\n\n        __m128i cmp1 = _mm_cmpeq_epi8(vec1, vec2);\n        __m128i cmp2 = _mm_cmpeq_epi8(vec1, vec3);\n        __m128i cmp3 = _mm_cmpeq_epi8(vec2, vec3);\n\n        __m128i or1 = _mm_or_si128(cmp1, cmp2);\n        __m128i or2 = _mm_or_si128(or1, cmp3);\n\n        if (!_mm_testz_si128(or2, or2)) {\n            return false;\n        }\n    }\n\n    for (int i = n - 15; i <= n - 3; ++i) {\n        if (str[i] == str[i + 1] || str[i] == str[i + 2] || str[i + 1] == str[i + 2]) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_101_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool is_happy_simd(const std::string & s){\n    int n = s.size();\n    if (n < 3) return false;\n\n    const char* str = s.c_str();\n    __m128i zero = _mm_setzero_si128();\n\n    for (int i = 0; i <= n - 16; i += 15) {\n        __m128i a = _mm_loadu_si128(reinterpret_cast<const __m128i*>(str + i));\n        __m128i b = _mm_loadu_si128(reinterpret_cast<const __m128i*>(str + i + 1));\n        __m128i c = _mm_loadu_si128(reinterpret_cast<const __m128i*>(str + i + 2));\n\n        __m128i eq_ab = _mm_cmpeq_epi8(a, b);\n        __m128i eq_bc = _mm_cmpeq_epi8(b, c);\n        __m128i eq_ac = _mm_cmpeq_epi8(a, c);\n\n        __m128i or_eq = _mm_or_si128(_mm_or_si128(eq_ab, eq_bc), eq_ac);\n        if (!_mm_testz_si128(or_eq, or_eq)) {\n            return false;\n        }\n    }\n\n    for (int i = n - 15; i < n - 2; ++i) {\n        if (str[i] == str[i + 1] || str[i] == str[i + 2] || str[i + 1] == str[i + 2]) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_101_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool is_happy_simd(const std::string & s){\n    int n = s.size();\n    if (n < 3) return false;\n\n    const char* str = s.c_str();\n    __m128i zero = _mm_setzero_si128();\n\n    for (int i = 0; i <= n - 16; i += 15) {\n        __m128i vec1 = _mm_loadu_si128(reinterpret_cast<const __m128i*>(str + i));\n        __m128i vec2 = _mm_loadu_si128(reinterpret_cast<const __m128i*>(str + i + 1));\n        __m128i vec3 = _mm_loadu_si128(reinterpret_cast<const __m128i*>(str + i + 2));\n\n        __m128i cmp1 = _mm_cmpeq_epi8(vec1, vec2);\n        __m128i cmp2 = _mm_cmpeq_epi8(vec1, vec3);\n        __m128i cmp3 = _mm_cmpeq_epi8(vec2, vec3);\n\n        __m128i or1 = _mm_or_si128(cmp1, cmp2);\n        __m128i or2 = _mm_or_si128(or1, cmp3);\n\n        if (!_mm_test_all_zeros(or2, or2)) {\n            return false;\n        }\n    }\n\n    for (int i = n - 15; i <= n - 3; ++i) {\n        if (str[i] == str[i + 1] || str[i] == str[i + 2] || str[i + 1] == str[i + 2]) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_101_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool is_happy_simd(const std::string & s){\n    int n = s.size();\n    if (n < 3) return false;\n\n    const char* str = s.c_str();\n    __m128i zero = _mm_setzero_si128();\n\n    for (int i = 0; i <= n - 16; i += 15) {\n        __m128i a = _mm_loadu_si128(reinterpret_cast<const __m128i*>(str + i));\n        __m128i b = _mm_loadu_si128(reinterpret_cast<const __m128i*>(str + i + 1));\n        __m128i c = _mm_loadu_si128(reinterpret_cast<const __m128i*>(str + i + 2));\n\n        __m128i eq_ab = _mm_cmpeq_epi8(a, b);\n        __m128i eq_ac = _mm_cmpeq_epi8(a, c);\n        __m128i eq_bc = _mm_cmpeq_epi8(b, c);\n\n        __m128i or_eq = _mm_or_si128(_mm_or_si128(eq_ab, eq_ac), eq_bc);\n        if (!_mm_testz_si128(or_eq, or_eq)) {\n            return false;\n        }\n    }\n\n    for (int i = n - 15; i < n - 2; ++i) {\n        if (str[i] == str[i + 1] || str[i] == str[i + 2] || str[i + 1] == str[i + 2]) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_102_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n#include <cmath>\n\nbool prime_length_simd(const std::string & str) {\n    int length = str.length();\n    if (length < 2) return false;\n\n    __m128i limit = _mm_set1_epi32(static_cast<int>(std::sqrt(length)));\n    __m128i two = _mm_set1_epi32(2);\n    __m128i i = _mm_set1_epi32(2);\n\n    while (true) {\n        __m128i div = _mm_div_epi32(_mm_set1_epi32(length), i);\n        __m128i rem = _mm_sub_epi32(_mm_mullo_epi32(div, i), _mm_set1_epi32(length));\n        __m128i mask = _mm_cmpeq_epi32(rem, _mm_setzero_si128());\n\n        if (_mm_movemask_epi8(mask) != 0) return false;\n\n        i = _mm_add_epi32(i, two);\n        __m128i cmp = _mm_cmpgt_epi32(i, limit);\n        if (_mm_movemask_epi8(cmp) == 0xFFFF) break;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_102_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n#include <cmath>\n\nbool prime_length_simd(const std::string & str) {\n    int length = str.length();\n    if (length < 2) return false;\n\n    __m128i limit = _mm_set1_epi32(static_cast<int>(std::sqrt(length)));\n    __m128i two = _mm_set1_epi32(2);\n    __m128i i = _mm_set1_epi32(2);\n\n    while (true) {\n        __m128i div = _mm_div_epi32(_mm_set1_epi32(length), i);\n        __m128i rem = _mm_sub_epi32(_mm_mullo_epi32(div, i), _mm_set1_epi32(length));\n        __m128i mask = _mm_cmpeq_epi32(rem, _mm_setzero_si128());\n\n        if (_mm_movemask_epi8(mask) != 0) return false;\n\n        i = _mm_add_epi32(i, two);\n        __m128i cmp = _mm_cmpgt_epi32(i, limit);\n        if (_mm_movemask_epi8(cmp) == 0xFFFF) break;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_102_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n#include <cmath>\n\nbool prime_length_simd(const std::string & str) {\n    int length = str.length();\n    if (length < 2) return false;\n\n    __m128i limit = _mm_set1_epi32(static_cast<int>(std::sqrt(length)));\n    __m128i two = _mm_set1_epi32(2);\n    __m128i i = _mm_set1_epi32(2);\n\n    while (true) {\n        __m128i div = _mm_div_epi32(_mm_set1_epi32(length), i);\n        __m128i rem = _mm_sub_epi32(_mm_mullo_epi32(div, i), _mm_set1_epi32(length));\n        __m128i mask = _mm_cmpeq_epi32(rem, _mm_setzero_si128());\n\n        if (_mm_movemask_epi8(mask) != 0) return false;\n\n        i = _mm_add_epi32(i, two);\n        __m128i cmp = _mm_cmpgt_epi32(i, limit);\n        if (_mm_movemask_epi8(cmp) == 0xFFFF) break;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_102_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n#include <cmath>\n\nbool prime_length_simd(const std::string & str) {\n    int length = str.length();\n    if (length < 2) return false;\n\n    __m128i limit = _mm_set1_epi32(static_cast<int>(std::sqrt(length)));\n    __m128i two = _mm_set1_epi32(2);\n    __m128i i = _mm_set1_epi32(2);\n\n    while (true) {\n        __m128i div = _mm_div_epi32(_mm_set1_epi32(length), i);\n        __m128i rem = _mm_sub_epi32(_mm_mullo_epi32(div, i), _mm_set1_epi32(length));\n        __m128i mask = _mm_cmpeq_epi32(rem, _mm_setzero_si128());\n\n        if (_mm_movemask_epi8(mask) != 0) return false;\n\n        i = _mm_add_epi32(i, two);\n        __m128i cmp = _mm_cmpgt_epi32(i, limit);\n        if (_mm_movemask_epi8(cmp) == 0xFFFF) break;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_102_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n#include <cmath>\n\nbool prime_length_simd(const std::string & str) {\n    int length = str.length();\n    if (length < 2) return false;\n\n    __m128i limit = _mm_set1_epi32(static_cast<int>(std::sqrt(length)));\n    __m128i two = _mm_set1_epi32(2);\n    __m128i i = _mm_set1_epi32(2);\n\n    while (true) {\n        __m128i div = _mm_div_epi32(_mm_set1_epi32(length), i);\n        __m128i rem = _mm_sub_epi32(_mm_mullo_epi32(div, i), _mm_set1_epi32(length));\n        __m128i mask = _mm_cmpeq_epi32(rem, _mm_setzero_si128());\n\n        if (_mm_movemask_epi8(mask) != 0) return false;\n\n        i = _mm_add_epi32(i, two);\n        __m128i cmp = _mm_cmpgt_epi32(i, limit);\n        if (_mm_movemask_epi8(cmp) == 0xFFFF) break;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_103_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <bitset>\n#include <string>\n\nstd::string solve_simd(uint64_t N) {\n    __m128i count = _mm_setzero_si128();\n    __m128i ones = _mm_set1_epi8(1);\n\n    while (N > 0) {\n        __m128i bits = _mm_set_epi64x(0, N);\n        __m128i bit_count = _mm_popcnt_epi64(bits);\n        count = _mm_add_epi32(count, bit_count);\n\n        N >>= 64;\n    }\n\n    int horizontal_sum = _mm_extract_epi16(_mm_sad_epu8(count, _mm_setzero_si128()), 0);\n    return std::bitset<64>(horizontal_sum).to_string().substr(64 - std::bitset<64>(horizontal_sum).count());\n}\n```"}
{"task_id": "SimdBench_103_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <bitset>\n#include <string>\n\nstd::string solve_simd(uint64_t N) {\n    __m128i count = _mm_setzero_si128();\n    __m128i ones = _mm_set1_epi8(1);\n\n    while (N > 0) {\n        __m128i bits = _mm_set_epi64x(0, N);\n        __m128i bit_count = _mm_popcnt_epi64(bits);\n        count = _mm_add_epi32(count, bit_count);\n\n        N >>= 64;\n    }\n\n    int horizontal_sum = _mm_extract_epi16(_mm_sad_epu8(count, _mm_setzero_si128()), 0);\n    return std::bitset<64>(horizontal_sum).to_string().substr(64 - std::bitset<64>(horizontal_sum).count());\n}\n```"}
{"task_id": "SimdBench_103_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <bitset>\n#include <string>\n\nstd::string solve_simd(uint64_t N) {\n    __m128i count = _mm_setzero_si128();\n    __m128i ones = _mm_set1_epi8(1);\n\n    while (N > 0) {\n        __m128i bits = _mm_set_epi64x(0, N);\n        count = _mm_add_epi8(count, _mm_and_si128(bits, ones));\n        N >>= 8;\n    }\n\n    int horizontal_sum = _mm_extract_epi16(_mm_sad_epu8(count, _mm_setzero_si128()), 0);\n    return std::bitset<8>(horizontal_sum).to_string().substr(8 - std::bitset<8>(horizontal_sum).count());\n}\n```"}
{"task_id": "SimdBench_103_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <bitset>\n#include <string>\n\nstd::string solve_simd(uint64_t N) {\n    __m128i count = _mm_setzero_si128();\n    __m128i ones = _mm_set1_epi8(1);\n\n    while (N) {\n        __m128i bits = _mm_cvtsi64_si128(N);\n        bits = _mm_and_si128(bits, _mm_set1_epi8(0x01));\n        count = _mm_add_epi8(count, bits);\n        N >>= 8;\n    }\n\n    int horizontal_sum = _mm_extract_epi16(_mm_sad_epu8(count, _mm_setzero_si128()), 0);\n    return std::bitset<8>(horizontal_sum).to_string().substr(8 - std::bitset<8>(horizontal_sum).count());\n}\n```"}
{"task_id": "SimdBench_103_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <bitset>\n#include <string>\n\nstd::string solve_simd(uint64_t N) {\n    __m128i count = _mm_setzero_si128();\n    __m128i ones = _mm_set1_epi8(1);\n\n    while (N > 0) {\n        __m128i bits = _mm_set_epi64x(0, N);\n        __m128i bit_count = _mm_popcnt_epi64(bits);\n        count = _mm_add_epi32(count, bit_count);\n\n        N >>= 64;\n    }\n\n    int horizontal_sum = _mm_extract_epi16(_mm_sad_epu8(count, _mm_setzero_si128()), 0);\n    return std::bitset<64>(horizontal_sum).to_string().substr(64 - std::bitset<64>(horizontal_sum).count());\n}\n```"}
{"task_id": "SimdBench_104_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint add_simd(std::vector<int> lst){\n    int sum = 0;\n    int n = lst.size();\n    __m128i zero = _mm_setzero_si128();\n    __m128i even_sum = _mm_setzero_si128();\n\n    for (int i = 1; i < n; i += 4) {\n        __m128i vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&lst[i]));\n        __m128i mask = _mm_set_epi32(0, -1, 0, -1);\n        __m128i even_elements = _mm_and_si128(vec, mask);\n        __m128i shifted = _mm_srli_epi32(even_elements, 31);\n        __m128i masked_even_elements = _mm_andnot_si128(shifted, even_elements);\n        even_sum = _mm_add_epi32(even_sum, masked_even_elements);\n    }\n\n    int result[4];\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(result), even_sum);\n    for (int i = 0; i < 4; ++i) {\n        sum += result[i];\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_104_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint add_simd(std::vector<int> lst){\n    int sum = 0;\n    int n = lst.size();\n    __m128i zero = _mm_setzero_si128();\n    __m128i even_sum = _mm_setzero_si128();\n\n    for (int i = 1; i < n; i += 4) {\n        __m128i values = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&lst[i]));\n        __m128i mask = _mm_set_epi32(0, -1, 0, -1);\n        __m128i even_values = _mm_and_si128(values, mask);\n        __m128i shifted = _mm_srli_epi32(even_values, 31);\n        __m128i masked_even_values = _mm_andnot_si128(shifted, even_values);\n        even_sum = _mm_add_epi32(even_sum, masked_even_values);\n    }\n\n    int result[4];\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(result), even_sum);\n    for (int i = 0; i < 4; ++i) {\n        sum += result[i];\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_104_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint add_simd(std::vector<int> lst){\n    int sum = 0;\n    int n = lst.size();\n    __m128i zero = _mm_setzero_si128();\n    __m128i even_sum = _mm_setzero_si128();\n\n    for (int i = 1; i < n; i += 4) {\n        __m128i values = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&lst[i]));\n        __m128i mask = _mm_set_epi32(0, -1, 0, -1);\n        __m128i even_values = _mm_and_si128(values, mask);\n        even_sum = _mm_add_epi32(even_sum, even_values);\n    }\n\n    even_sum = _mm_hadd_epi32(even_sum, even_sum);\n    even_sum = _mm_hadd_epi32(even_sum, even_sum);\n    _mm_store_ss(&sum, _mm_castsi128_ps(even_sum));\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_104_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint add_simd(std::vector<int> lst){\n    int sum = 0;\n    int n = lst.size();\n    __m128i zero = _mm_setzero_si128();\n    __m128i even_sum = _mm_setzero_si128();\n\n    for (int i = 1; i < n; i += 4) {\n        __m128i values = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&lst[i]));\n        __m128i mask = _mm_set_epi32(0, -1, 0, -1);\n        __m128i odd_indices = _mm_and_si128(values, mask);\n        __m128i even_mask = _mm_set1_epi32(2);\n        __m128i even_elements = _mm_and_si128(odd_indices, even_mask);\n        even_sum = _mm_add_epi32(even_sum, even_elements);\n    }\n\n    int result[4];\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(result), even_sum);\n    for (int i = 0; i < 4; ++i) {\n        sum += result[i];\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_104_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint add_simd(std::vector<int> lst){\n    __m128i sum = _mm_setzero_si128();\n    int n = lst.size();\n    int* data = lst.data();\n\n    for (int i = 1; i < n; i += 4) {\n        __m128i values = _mm_loadu_si128((__m128i*)&data[i]);\n        __m128i mask = _mm_set_epi32(0, -1, 0, -1);\n        __m128i evens = _mm_and_si128(values, mask);\n        sum = _mm_add_epi32(sum, evens);\n    }\n\n    int result[4];\n    _mm_storeu_si128((__m128i*)result, sum);\n    return result[0] + result[1] + result[2] + result[3];\n}\n```"}
{"task_id": "SimdBench_105_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string encrypt_simd(const std::string & s){\n    std::string result(s.size(), ' ');\n    const int shift = 4; // 2 * 2\n    const __m128i shift_vec = _mm_set1_epi8(shift);\n    const __m128i a = _mm_set1_epi8('a');\n    const __m128i z = _mm_set1_epi8('z');\n\n    for (size_t i = 0; i < s.size(); i += 16) {\n        __m128i input = _mm_loadu_si128(reinterpret_cast<const __m128i*>(s.data() + i));\n        __m128i shifted = _mm_add_epi8(input, shift_vec);\n\n        // Handle wrap-around for lowercase letters\n        __m128i wrapped = _mm_subs_epi8(_mm_add_epi8(shifted, _mm_cmpgt_epi8(z, shifted)), a);\n        __m128i masked = _mm_or_si128(_mm_andnot_si128(_mm_cmpgt_epi8(z, shifted), shifted),\n                                      _mm_and_si128(_mm_cmpgt_epi8(z, shifted), wrapped));\n\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(result.data() + i), masked);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_105_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string encrypt_simd(const std::string & s){\n    std::string result(s.size(), ' ');\n    const int shift = 4; // 2 * 2\n    const __m128i shift_vec = _mm_set1_epi8(shift);\n    const __m128i a = _mm_set1_epi8('a');\n    const __m128i z = _mm_set1_epi8('z');\n\n    for (size_t i = 0; i < s.size(); i += 16) {\n        __m128i input = _mm_loadu_si128(reinterpret_cast<const __m128i*>(s.data() + i));\n        __m128i shifted = _mm_add_epi8(input, shift_vec);\n        __m128i wrapped = _mm_or_si128(\n            _mm_and_si128(_mm_cmpgt_epi8(shifted, z), _mm_sub_epi8(shifted, _mm_set1_epi8(26))),\n            _mm_andnot_si128(_mm_cmpgt_epi8(shifted, z), shifted)\n        );\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(result.data() + i), wrapped);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_105_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string encrypt_simd(const std::string & s){\n    std::string result(s.size(), ' ');\n    const int shift = 4; // 2 * 2\n    const __m128i shift_vec = _mm_set1_epi8(shift);\n    const __m128i a = _mm_set1_epi8('a');\n    const __m128i z = _mm_set1_epi8('z');\n\n    for (size_t i = 0; i < s.size(); i += 16) {\n        __m128i input = _mm_loadu_si128(reinterpret_cast<const __m128i*>(s.data() + i));\n        __m128i shifted = _mm_add_epi8(input, shift_vec);\n        __m128i wrapped = _mm_or_si128(\n            _mm_and_si128(_mm_cmpgt_epi8(shifted, z), _mm_sub_epi8(shifted, _mm_set1_epi8(26))),\n            _mm_andnot_si128(_mm_cmpgt_epi8(shifted, z), shifted)\n        );\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(result.data() + i), wrapped);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_105_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string encrypt_simd(const std::string & s){\n    std::string result(s.size(), ' ');\n    const int shift = 4; // 2 * 2\n    const __m128i shift_vec = _mm_set1_epi8(shift);\n    const __m128i a = _mm_set1_epi8('a');\n    const __m128i z = _mm_set1_epi8('z');\n\n    for (size_t i = 0; i < s.size(); i += 16) {\n        __m128i input = _mm_loadu_si128(reinterpret_cast<const __m128i*>(s.data() + i));\n        __m128i shifted = _mm_add_epi8(input, shift_vec);\n        __m128i wrapped = _mm_or_si128(\n            _mm_and_si128(_mm_cmpgt_epi8(shifted, z), _mm_sub_epi8(shifted, _mm_set1_epi8(26))),\n            _mm_andnot_si128(_mm_cmpgt_epi8(shifted, z), shifted)\n        );\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(result.data() + i), wrapped);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_105_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string encrypt_simd(const std::string & s){\n    std::string result(s.size(), ' ');\n    const int shift = 4; // 2 * 2\n    const __m128i shift_vec = _mm_set1_epi8(shift);\n    const __m128i a = _mm_set1_epi8('a');\n    const __m128i z = _mm_set1_epi8('z');\n\n    for (size_t i = 0; i < s.size(); i += 16) {\n        __m128i input = _mm_loadu_si128(reinterpret_cast<const __m128i*>(s.data() + i));\n        __m128i shifted = _mm_add_epi8(input, shift_vec);\n\n        // Handle wrap-around for lowercase letters\n        __m128i wrapped = _mm_subs_epi8(_mm_add_epi8(shifted, _mm_cmplt_epi8(z, shifted)), z);\n        __m128i masked = _mm_or_si128(_mm_andnot_si128(_mm_cmpgt_epi8(input, z), shifted), wrapped);\n\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(result.data() + i), masked);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_106_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string encode_simd(const std::string & message){\n    std::string result(message.size(), ' ');\n    const char* input = message.c_str();\n    char* output = &result[0];\n    int len = message.size();\n    int i = 0;\n\n    __m128i vowels_lower = _mm_setr_epi8('a', 'e', 'i', 'o', 'u', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n    __m128i vowels_upper = _mm_setr_epi8('A', 'E', 'I', 'O', 'U', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n    __m128i shift = _mm_set1_epi8(2);\n\n    for (; i <= len - 16; i += 16) {\n        __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(input + i));\n        __m128i lower_case_mask = _mm_cmpgt_epi8(chunk, _mm_set1_epi8('Z'));\n        __m128i upper_chunk = _mm_andnot_si128(lower_case_mask, chunk);\n        __m128i lower_chunk = _mm_and_si128(lower_case_mask, chunk);\n\n        __m128i swapped_case = _mm_or_si128(\n            _mm_andnot_si128(lower_case_mask, _mm_sub_epi8(chunk, _mm_set1_epi8('A' - 'a'))),\n            _mm_and_si128(lower_case_mask, _mm_add_epi8(chunk, _mm_set1_epi8('A' - 'a')))\n        );\n\n        __m128i is_vowel_lower = _mm_cmpeq_epi8(_mm_shuffle_epi8(vowels_lower, swapped_case), _mm_set1_epi8('a'));\n        __m128i is_vowel_upper = _mm_cmpeq_epi8(_mm_shuffle_epi8(vowels_upper, swapped_case), _mm_set1_epi8('A'));\n\n        __m128i shifted_vowels = _mm_add_epi8(swapped_case, shift);\n        __m128i result_chunk = _mm_or_si128(\n            _mm_or_si128(\n                _mm_andnot_si128(is_vowel_lower, swapped_case),\n                _mm_and_si128(is_vowel_lower, shifted_vowels)\n            ),\n            _mm_and_si128(is_vowel_upper, shifted_vowels)\n        );\n\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(output + i), result_chunk);\n    }\n\n    for (; i < len; ++i) {\n        char c = input[i];\n        if (c >= 'a' && c <= 'z') {\n            c = c - 'a' + 'A';\n        } else if (c >= 'A' && c <= 'Z') {\n            c = c - 'A' + 'a';\n        }\n        if (c == 'a' || c == 'e' || c == 'i' || c == 'o' || c == 'u') {\n            c += 2;\n        } else if (c == 'A' || c == 'E' || c == 'I' || c == 'O' || c == 'U') {\n            c += 2;\n        }\n        output[i] = c;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_106_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string encode_simd(const std::string & message){\n    std::string result(message.size(), ' ');\n    const char* input = message.c_str();\n    char* output = &result[0];\n    int len = message.size();\n    int i = 0;\n\n    __m128i vowels_lower = _mm_setr_epi8('a', 'e', 'i', 'o', 'u', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n    __m128i vowels_upper = _mm_setr_epi8('A', 'E', 'I', 'O', 'U', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n    __m128i two = _mm_set1_epi8(2);\n\n    for (; i <= len - 16; i += 16) {\n        __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(input + i));\n\n        // Swap case\n        __m128i mask = _mm_and_si128(chunk, _mm_set1_epi8(0x20));\n        __m128i swapped_case = _mm_xor_si128(chunk, mask);\n\n        // Check for vowels and replace\n        __m128i is_vowel_lower = _mm_cmpeq_epi8(_mm_shuffle_epi8(vowels_lower, swapped_case), _mm_set1_epi8(1));\n        __m128i is_vowel_upper = _mm_cmpeq_epi8(_mm_shuffle_epi8(vowels_upper, swapped_case), _mm_set1_epi8(1));\n        __m128i is_vowel = _mm_or_si128(is_vowel_lower, is_vowel_upper);\n        __m128i replaced_vowels = _mm_add_epi8(swapped_case, _mm_and_si128(is_vowel, two));\n\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(output + i), replaced_vowels);\n    }\n\n    // Handle remaining characters\n    for (; i < len; ++i) {\n        char c = input[i];\n        if (c >= 'a' && c <= 'z') {\n            c = c - 'a' + 'A';\n        } else if (c >= 'A' && c <= 'Z') {\n            c = c - 'A' + 'a';\n        }\n        if (c == 'a' || c == 'e' || c == 'i' || c == 'o' || c == 'u') {\n            c += 2;\n        } else if (c == 'A' || c == 'E' || c == 'I' || c == 'O' || c == 'U') {\n            c += 2;\n        }\n        output[i] = c;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_106_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string encode_simd(const std::string & message){\n    std::string result(message.size(), ' ');\n    const char* input = message.c_str();\n    char* output = &result[0];\n    int len = message.size();\n    int i = 0;\n\n    __m128i vowels_lower = _mm_setr_epi8('a', 'e', 'i', 'o', 'u', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n    __m128i vowels_upper = _mm_setr_epi8('A', 'E', 'I', 'O', 'U', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n    __m128i two = _mm_set1_epi8(2);\n\n    for (; i <= len - 16; i += 16) {\n        __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(input + i));\n\n        // Swap case\n        __m128i mask = _mm_and_si128(chunk, _mm_set1_epi8(0x20));\n        __m128i swapped_case = _mm_xor_si128(chunk, mask);\n\n        // Check for vowels and add 2\n        __m128i is_vowel_lower = _mm_cmpeq_epi8(_mm_shuffle_epi8(vowels_lower, swapped_case), _mm_set1_epi8(1));\n        __m128i is_vowel_upper = _mm_cmpeq_epi8(_mm_shuffle_epi8(vowels_upper, swapped_case), _mm_set1_epi8(1));\n        __m128i is_vowel = _mm_or_si128(is_vowel_lower, is_vowel_upper);\n        __m128i replaced_vowels = _mm_add_epi8(swapped_case, _mm_and_si128(is_vowel, two));\n\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(output + i), replaced_vowels);\n    }\n\n    // Handle remaining characters\n    for (; i < len; ++i) {\n        char c = input[i];\n        if (c >= 'a' && c <= 'z') {\n            c = c - 'a' + 'A';\n        } else if (c >= 'A' && c <= 'Z') {\n            c = c - 'A' + 'a';\n        }\n        if (c == 'a' || c == 'e' || c == 'i' || c == 'o' || c == 'u') {\n            c += 2;\n        } else if (c == 'A' || c == 'E' || c == 'I' || c == 'O' || c == 'U') {\n            c += 2;\n        }\n        output[i] = c;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_106_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string encode_simd(const std::string & message){\n    std::string result(message.size(), ' ');\n    const char* input = message.c_str();\n    char* output = &result[0];\n    int len = message.size();\n    int i = 0;\n\n    __m128i vowels_lower = _mm_setr_epi8('a', 'e', 'i', 'o', 'u', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n    __m128i vowels_upper = _mm_setr_epi8('A', 'E', 'I', 'O', 'U', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n    __m128i shift = _mm_set1_epi8(2);\n\n    for (; i <= len - 16; i += 16) {\n        __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(input + i));\n        __m128i lower_case_mask = _mm_cmpgt_epi8(chunk, _mm_set1_epi8('Z'));\n        __m128i upper_case_mask = _mm_cmple_epi8(chunk, _mm_set1_epi8('Z'));\n\n        __m128i swapped_case = _mm_or_si128(\n            _mm_and_si128(_mm_sub_epi8(chunk, _mm_set1_epi8('a')), lower_case_mask),\n            _mm_and_si128(_mm_add_epi8(chunk, _mm_set1_epi8('a' - 'A')), upper_case_mask)\n        );\n\n        swapped_case = _mm_or_si128(\n            _mm_andnot_si128(lower_case_mask, swapped_case),\n            _mm_andnot_si128(upper_case_mask, swapped_case)\n        );\n\n        __m128i is_vowel_lower = _mm_cmpeq_epi8(_mm_shuffle_epi8(vowels_lower, swapped_case), _mm_set1_epi8(0));\n        __m128i is_vowel_upper = _mm_cmpeq_epi8(_mm_shuffle_epi8(vowels_upper, swapped_case), _mm_set1_epi8(0));\n\n        __m128i shifted_vowels = _mm_add_epi8(swapped_case, shift);\n\n        __m128i result_chunk = _mm_or_si128(\n            _mm_and_si128(shifted_vowels, _mm_andnot_si128(is_vowel_lower, _mm_set1_epi8(-1))),\n            _mm_and_si128(swapped_case, is_vowel_lower)\n        );\n\n        result_chunk = _mm_or_si128(\n            _mm_and_si128(shifted_vowels, _mm_andnot_si128(is_vowel_upper, _mm_set1_epi8(-1))),\n            _mm_and_si128(result_chunk, is_vowel_upper)\n        );\n\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(output + i), result_chunk);\n    }\n\n    for (; i < len; ++i) {\n        char c = input[i];\n        if (c >= 'a' && c <= 'z') {\n            c = c - 'a' + 'A';\n        } else if (c >= 'A' && c <= 'Z') {\n            c = c - 'A' + 'a';\n        }\n        if (c == 'a' || c == 'e' || c == 'i' || c == 'o' || c == 'u') {\n            c += 2;\n        } else if (c == 'A' || c == 'E' || c == 'I' || c == 'O' || c == 'U') {\n            c += 2;\n        }\n        output[i] = c;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_106_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string encode_simd(const std::string & message){\n    std::string result(message.size(), ' ');\n    const char* input = message.c_str();\n    char* output = &result[0];\n    int len = message.size();\n\n    __m128i vowels_lower = _mm_setr_epi8('a', 'e', 'i', 'o', 'u', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n    __m128i vowels_upper = _mm_setr_epi8('A', 'E', 'I', 'O', 'U', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n    __m128i shift = _mm_set1_epi8(2);\n\n    for (int i = 0; i <= len - 16; i += 16) {\n        __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(input + i));\n\n        // Swap case\n        __m128i mask = _mm_and_si128(chunk, _mm_set1_epi8(0x20));\n        __m128i swapped_case = _mm_xor_si128(chunk, mask);\n\n        // Check for vowels and shift\n        __m128i is_vowel_lower = _mm_cmpeq_epi8(_mm_shuffle_epi8(vowels_lower, swapped_case), _mm_set1_epi8(0xFF));\n        __m128i is_vowel_upper = _mm_cmpeq_epi8(_mm_shuffle_epi8(vowels_upper, swapped_case), _mm_set1_epi8(0xFF));\n        __m128i is_vowel = _mm_or_si128(is_vowel_lower, is_vowel_upper);\n        __m128i shifted_vowels = _mm_add_epi8(swapped_case, shift);\n        __m128i encoded_chunk = _mm_or_si128(_mm_andnot_si128(is_vowel, swapped_case), _mm_and_si128(is_vowel, shifted_vowels));\n\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(output + i), encoded_chunk);\n    }\n\n    // Handle remaining characters\n    for (int i = (len / 16) * 16; i < len; ++i) {\n        char c = input[i];\n        if (c >= 'a' && c <= 'z') {\n            c = c - 'a' + 'A';\n        } else if (c >= 'A' && c <= 'Z') {\n            c = c - 'A' + 'a';\n        }\n        if (c == 'a' || c == 'e' || c == 'i' || c == 'o' || c == 'u') {\n            c += 2;\n        } else if (c == 'A' || c == 'E' || c == 'I' || c == 'O' || c == 'U') {\n            c += 2;\n        }\n        output[i] = c;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_107_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <map>\n#include <string>\n\nbool check_dict_case_simd(std::map<std::string, std::string> dict) {\n    if (dict.empty()) return false;\n\n    bool all_lower = true;\n    bool all_upper = true;\n\n    for (const auto& pair : dict) {\n        const std::string& key = pair.first;\n        if (key.empty()) continue;\n\n        size_t len = key.size();\n        size_t i = 0;\n\n        for (; i <= len - 16; i += 16) {\n            __m128i str = _mm_loadu_si128(reinterpret_cast<const __m128i*>(key.c_str() + i));\n            __m128i lower_mask = _mm_cmplt_epi8(str, _mm_set1_epi8('a'));\n            __m128i upper_mask = _mm_cmpgt_epi8(str, _mm_set1_epi8('Z'));\n            __m128i non_alpha_mask = _mm_or_si128(_mm_cmplt_epi8(str, _mm_set1_epi8('A')), _mm_cmpgt_epi8(str, _mm_set1_epi8('z')));\n\n            if (_mm_movemask_epi8(lower_mask) != 0) all_upper = false;\n            if (_mm_movemask_epi8(upper_mask) != 0) all_lower = false;\n            if (_mm_movemask_epi8(non_alpha_mask) != 0) return false;\n        }\n\n        for (; i < len; ++i) {\n            char c = key[i];\n            if (c < 'a') all_upper = false;\n            if (c > 'Z') all_lower = false;\n            if ((c < 'A' || c > 'z')) return false;\n        }\n    }\n\n    return all_lower || all_upper;\n}\n```"}
{"task_id": "SimdBench_107_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <map>\n#include <string>\n\nbool check_dict_case_simd(std::map<std::string, std::string> dict) {\n    if (dict.empty()) return false;\n\n    bool all_lower = true;\n    bool all_upper = true;\n\n    for (const auto& pair : dict) {\n        const std::string& key = pair.first;\n        if (key.empty()) continue;\n\n        size_t len = key.size();\n        size_t i = 0;\n\n        for (; i <= len - 16; i += 16) {\n            __m128i str = _mm_loadu_si128(reinterpret_cast<const __m128i*>(key.data() + i));\n            __m128i lower_mask = _mm_cmplt_epi8(str, _mm_set1_epi8('a'));\n            __m128i upper_mask = _mm_cmpgt_epi8(str, _mm_set1_epi8('Z'));\n            __m128i non_alpha_mask = _mm_or_si128(_mm_cmplt_epi8(str, _mm_set1_epi8('A')), _mm_cmpgt_epi8(str, _mm_set1_epi8('z')));\n\n            if (_mm_movemask_epi8(lower_mask) != 0) all_upper = false;\n            if (_mm_movemask_epi8(upper_mask) != 0) all_lower = false;\n            if (_mm_movemask_epi8(non_alpha_mask) != 0) return false;\n        }\n\n        for (; i < len; ++i) {\n            char c = key[i];\n            if (c < 'a') all_upper = false;\n            if (c > 'Z') all_lower = false;\n            if ((c < 'A' || c > 'z')) return false;\n        }\n    }\n\n    return all_lower || all_upper;\n}\n```"}
{"task_id": "SimdBench_107_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <map>\n#include <string>\n\nbool check_dict_case_simd(std::map<std::string, std::string> dict) {\n    if (dict.empty()) return false;\n\n    bool all_lower = true;\n    bool all_upper = true;\n\n    for (const auto& pair : dict) {\n        const std::string& key = pair.first;\n        if (key.empty()) continue;\n\n        size_t len = key.size();\n        size_t i = 0;\n\n        for (; i <= len - 16; i += 16) {\n            __m128i str = _mm_loadu_si128(reinterpret_cast<const __m128i*>(key.data() + i));\n            __m128i lower_mask = _mm_cmplt_epi8(str, _mm_set1_epi8('a'));\n            __m128i upper_mask = _mm_cmpgt_epi8(str, _mm_set1_epi8('Z'));\n            __m128i non_alpha_mask = _mm_or_si128(_mm_cmplt_epi8(str, _mm_set1_epi8('A')), _mm_cmpgt_epi8(str, _mm_set1_epi8('z')));\n\n            if (_mm_movemask_epi8(lower_mask) != 0) all_upper = false;\n            if (_mm_movemask_epi8(upper_mask) != 0) all_lower = false;\n            if (_mm_movemask_epi8(non_alpha_mask) != 0) return false;\n        }\n\n        for (; i < len; ++i) {\n            char c = key[i];\n            if (c < 'a') all_upper = false;\n            if (c > 'Z') all_lower = false;\n            if ((c < 'A' || c > 'z')) return false;\n        }\n    }\n\n    return all_lower || all_upper;\n}\n```"}
{"task_id": "SimdBench_107_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <map>\n#include <string>\n\nbool check_dict_case_simd(std::map<std::string, std::string> dict) {\n    if (dict.empty()) return false;\n\n    bool all_lower = true;\n    bool all_upper = true;\n\n    for (const auto& pair : dict) {\n        const std::string& key = pair.first;\n        if (key.empty()) continue;\n\n        size_t len = key.size();\n        size_t i = 0;\n\n        for (; i <= len - 16; i += 16) {\n            __m128i str = _mm_loadu_si128(reinterpret_cast<const __m128i*>(key.data() + i));\n            __m128i lower_mask = _mm_cmplt_epi8(str, _mm_set1_epi8('a'));\n            __m128i upper_mask = _mm_cmpgt_epi8(str, _mm_set1_epi8('Z'));\n            __m128i non_alpha_mask = _mm_or_si128(_mm_cmplt_epi8(str, _mm_set1_epi8('A')), _mm_cmpgt_epi8(str, _mm_set1_epi8('z')));\n\n            if (_mm_movemask_epi8(lower_mask) != 0) all_upper = false;\n            if (_mm_movemask_epi8(upper_mask) != 0) all_lower = false;\n            if (_mm_movemask_epi8(non_alpha_mask) != 0) return false;\n        }\n\n        for (; i < len; ++i) {\n            char c = key[i];\n            if (c < 'a') all_upper = false;\n            if (c > 'Z') all_lower = false;\n            if ((c < 'A' || c > 'z')) return false;\n        }\n    }\n\n    return all_lower || all_upper;\n}\n```"}
{"task_id": "SimdBench_107_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <map>\n#include <string>\n\nbool check_dict_case_simd(std::map<std::string, std::string> dict) {\n    if (dict.empty()) return false;\n\n    bool all_lower = true;\n    bool all_upper = true;\n\n    for (const auto& pair : dict) {\n        const std::string& key = pair.first;\n        if (key.empty()) continue;\n\n        size_t len = key.size();\n        size_t i = 0;\n\n        for (; i <= len - 16; i += 16) {\n            __m128i str = _mm_loadu_si128(reinterpret_cast<const __m128i*>(key.c_str() + i));\n            __m128i lower_mask = _mm_cmplt_epi8(str, _mm_set1_epi8('a'));\n            __m128i upper_mask = _mm_cmpgt_epi8(str, _mm_set1_epi8('Z'));\n            __m128i non_alpha_mask = _mm_or_si128(_mm_cmplt_epi8(str, _mm_set1_epi8('A')), _mm_cmpgt_epi8(str, _mm_set1_epi8('z')));\n\n            if (_mm_movemask_epi8(lower_mask) != 0) all_upper = false;\n            if (_mm_movemask_epi8(upper_mask) != 0) all_lower = false;\n            if (_mm_movemask_epi8(non_alpha_mask) != 0) return false;\n        }\n\n        for (; i < len; ++i) {\n            char c = key[i];\n            if (c < 'a') all_upper = false;\n            if (c > 'Z') all_lower = false;\n            if ((c < 'A' || c > 'z')) return false;\n        }\n    }\n\n    return all_lower || all_upper;\n}\n```"}
{"task_id": "SimdBench_108_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <cmath>\n\nstd::vector<int> count_up_to_simd(int n) {\n    std::vector<int> primes;\n    if (n <= 2) return primes;\n\n    std::vector<bool> is_prime(n, true);\n    is_prime[0] = is_prime[1] = false;\n\n    for (int i = 2; i <= std::sqrt(n); ++i) {\n        if (is_prime[i]) {\n            for (int j = i * i; j < n; j += i) {\n                is_prime[j] = false;\n            }\n        }\n    }\n\n    for (int i = 2; i < n; ++i) {\n        if (is_prime[i]) {\n            primes.push_back(i);\n        }\n    }\n\n    return primes;\n}\n```"}
{"task_id": "SimdBench_108_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <cmath>\n\nstd::vector<int> count_up_to_simd(int n) {\n    std::vector<int> primes;\n    if (n <= 2) return primes;\n\n    std::vector<bool> is_prime(n, true);\n    is_prime[0] = is_prime[1] = false;\n\n    for (int i = 2; i <= std::sqrt(n); ++i) {\n        if (is_prime[i]) {\n            for (int j = i * i; j < n; j += i) {\n                is_prime[j] = false;\n            }\n        }\n    }\n\n    for (int i = 2; i < n; ++i) {\n        if (is_prime[i]) {\n            primes.push_back(i);\n        }\n    }\n\n    return primes;\n}\n```"}
{"task_id": "SimdBench_108_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <cmath>\n\nstd::vector<int> count_up_to_simd(int n) {\n    std::vector<int> primes;\n    if (n <= 2) return primes;\n\n    std::vector<bool> is_prime(n, true);\n    is_prime[0] = is_prime[1] = false;\n\n    int limit = static_cast<int>(std::sqrt(n)) + 1;\n    for (int i = 2; i < limit; ++i) {\n        if (is_prime[i]) {\n            __m128i index = _mm_setr_epi32(i * 2, i * 3, i * 4, i * 5);\n            __m128i step = _mm_set1_epi32(i);\n            for (int j = i * i; j < n; ) {\n                __m128i mask = _mm_cmplt_epi32(index, _mm_set1_epi32(n));\n                if (_mm_movemask_epi8(mask) == 0) break;\n                __m128i indices = _mm_and_si128(index, mask);\n                int* indices_ptr = (int*)&indices;\n                for (int k = 0; k < 4; ++k) {\n                    if (indices_ptr[k] < n) {\n                        is_prime[indices_ptr[k]] = false;\n                    }\n                }\n                index = _mm_add_epi32(index, step);\n                j += i * 4;\n            }\n        }\n    }\n\n    for (int i = 2; i < n; ++i) {\n        if (is_prime[i]) {\n            primes.push_back(i);\n        }\n    }\n\n    return primes;\n}\n```"}
{"task_id": "SimdBench_108_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <cmath>\n\nstd::vector<int> count_up_to_simd(int n) {\n    std::vector<int> primes;\n    if (n <= 2) return primes;\n\n    std::vector<bool> is_prime(n, true);\n    is_prime[0] = is_prime[1] = false;\n\n    for (int i = 2; i <= std::sqrt(n); ++i) {\n        if (is_prime[i]) {\n            for (int j = i * i; j < n; j += i) {\n                is_prime[j] = false;\n            }\n        }\n    }\n\n    for (int i = 2; i < n; ++i) {\n        if (is_prime[i]) {\n            primes.push_back(i);\n        }\n    }\n\n    return primes;\n}\n```"}
{"task_id": "SimdBench_108_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <cmath>\n\nstd::vector<int> count_up_to_simd(int n) {\n    std::vector<int> primes;\n    if (n <= 2) return primes;\n\n    std::vector<bool> is_prime(n, true);\n    is_prime[0] = is_prime[1] = false;\n\n    for (int i = 2; i <= std::sqrt(n); ++i) {\n        if (is_prime[i]) {\n            for (int j = i * i; j < n; j += i) {\n                is_prime[j] = false;\n            }\n        }\n    }\n\n    for (int i = 2; i < n; ++i) {\n        if (is_prime[i]) {\n            primes.push_back(i);\n        }\n    }\n\n    return primes;\n}\n```"}
{"task_id": "SimdBench_109_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint count_upper_simd(const std::string & s){\n    int count = 0;\n    const char* str = s.c_str();\n    int len = s.size();\n    __m128i vowels = _mm_set_epi8('U', 'O', 'I', 'E', 'A', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n    __m128i mask = _mm_set1_epi8(0x80);\n\n    for (int i = 0; i <= len - 16; i += 16) {\n        __m128i chars = _mm_loadu_si128(reinterpret_cast<const __m128i*>(str + i));\n        __m128i even_indices = _mm_and_si128(chars, mask);\n        __m128i upper_vowels = _mm_cmpeq_epi8(even_indices, vowels);\n        __m128i upper_vowels_mask = _mm_cmpeq_epi8(_mm_and_si128(upper_vowels, _mm_set1_epi8(0x80)), _mm_set1_epi8(0x80));\n        count += _mm_popcnt_u32(_mm_movemask_epi8(upper_vowels_mask));\n    }\n\n    for (int i = (len & ~15); i < len; i += 2) {\n        if (str[i] >= 'A' && str[i] <= 'Z') {\n            char c = str[i];\n            if (c == 'A' || c == 'E' || c == 'I' || c == 'O' || c == 'U') {\n                count++;\n            }\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_109_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint count_upper_simd(const std::string & s){\n    int count = 0;\n    const char* str = s.c_str();\n    int len = s.size();\n    __m128i vowels = _mm_set_epi8('U', 'O', 'I', 'E', 'A', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n    __m128i mask = _mm_set1_epi8(0x80);\n\n    for (int i = 0; i <= len - 16; i += 16) {\n        __m128i chars = _mm_loadu_si128(reinterpret_cast<const __m128i*>(str + i));\n        __m128i even_chars = _mm_and_si128(chars, mask);\n        __m128i upper_vowels = _mm_cmpeq_epi8(even_chars, vowels);\n        __m128i upper_vowels_mask = _mm_cmpeq_epi8(upper_vowels, _mm_set1_epi8(-1));\n        count += _mm_popcnt_u32(_mm_movemask_epi8(upper_vowels_mask));\n    }\n\n    for (int i = (len / 16) * 16; i < len; i += 2) {\n        if (str[i] >= 'A' && str[i] <= 'Z') {\n            char c = str[i];\n            if (c == 'A' || c == 'E' || c == 'I' || c == 'O' || c == 'U') {\n                count++;\n            }\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_109_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint count_upper_simd(const std::string & s){\n    int count = 0;\n    const char* str = s.c_str();\n    int len = s.size();\n    __m128i vowels = _mm_set_epi8('U', 'O', 'I', 'E', 'A', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n    __m128i mask = _mm_set1_epi8(0x80);\n\n    for (int i = 0; i <= len - 16; i += 16) {\n        __m128i chars = _mm_loadu_si128(reinterpret_cast<const __m128i*>(str + i));\n        __m128i even_indices = _mm_and_si128(chars, mask);\n        __m128i upper_vowels = _mm_cmpeq_epi8(even_indices, vowels);\n        __m128i upper_vowels_mask = _mm_cmpeq_epi8(upper_vowels, _mm_set1_epi8(-1));\n        count += _mm_popcnt_u32(_mm_movemask_epi8(upper_vowels_mask));\n    }\n\n    for (int i = (len / 16) * 16; i < len; i += 2) {\n        if (str[i] >= 'A' && str[i] <= 'Z') {\n            char c = str[i];\n            if (c == 'A' || c == 'E' || c == 'I' || c == 'O' || c == 'U') {\n                count++;\n            }\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_109_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint count_upper_simd(const std::string & s){\n    int count = 0;\n    const char* str = s.c_str();\n    int len = s.size();\n    __m128i vowels = _mm_set_epi8('U', 'O', 'I', 'E', 'A', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n    __m128i mask = _mm_set1_epi8(0x80);\n\n    for (int i = 0; i <= len - 16; i += 16) {\n        __m128i chars = _mm_loadu_si128(reinterpret_cast<const __m128i*>(str + i));\n        __m128i even_indices = _mm_and_si128(chars, mask);\n        __m128i upper_vowels = _mm_cmpeq_epi8(even_indices, vowels);\n        __m128i upper_vowels_mask = _mm_cmpeq_epi8(_mm_and_si128(upper_vowels, _mm_set1_epi8(0x7F)), _mm_set1_epi8(0x7F));\n        count += _mm_popcnt_u32(_mm_movemask_epi8(upper_vowels_mask));\n    }\n\n    for (int i = (len / 16) * 16; i < len; i += 2) {\n        if (str[i] >= 'A' && str[i] <= 'Z') {\n            if (str[i] == 'A' || str[i] == 'E' || str[i] == 'I' || str[i] == 'O' || str[i] == 'U') {\n                count++;\n            }\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_109_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint count_upper_simd(const std::string & s){\n    int count = 0;\n    const char* str = s.c_str();\n    int len = s.size();\n    __m128i vowels = _mm_set_epi8('U', 'O', 'I', 'E', 'A', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n    __m128i mask = _mm_set1_epi8(0x80);\n\n    for (int i = 0; i <= len - 16; i += 16) {\n        __m128i chars = _mm_loadu_si128(reinterpret_cast<const __m128i*>(str + i));\n        __m128i even_indices = _mm_and_si128(chars, mask);\n        __m128i upper_vowels = _mm_cmpeq_epi8(even_indices, vowels);\n        __m128i upper_vowels_mask = _mm_cmpeq_epi8(_mm_and_si128(upper_vowels, _mm_set1_epi8(0x80)), _mm_set1_epi8(0x80));\n        count += _mm_popcnt_u32(_mm_movemask_epi8(upper_vowels_mask));\n    }\n\n    for (int i = (len / 16) * 16; i < len; i += 2) {\n        if (str[i] >= 'A' && str[i] <= 'Z') {\n            if (str[i] == 'A' || str[i] == 'E' || str[i] == 'I' || str[i] == 'O' || str[i] == 'U') {\n                count++;\n            }\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_110_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> make_a_pile_simd(int n){\n    std::vector<int> result(n);\n    int* result_ptr = result.data();\n\n    __m128i stone_counts;\n    __m128i increments;\n    __m128i ones = _mm_set1_epi32(1);\n    __m128i twos = _mm_set1_epi32(2);\n\n    if (n % 2 == 0) {\n        increments = _mm_setr_epi32(2, 4, 6, 8);\n    } else {\n        increments = _mm_setr_epi32(1, 3, 5, 7);\n    }\n\n    int i = 0;\n    for (; i <= n - 4; i += 4) {\n        stone_counts = _mm_setr_epi32(n, n-1, n-2, n-3);\n        stone_counts = _mm_sub_epi32(stone_counts, increments);\n        stone_counts = _mm_add_epi32(stone_counts, ones);\n        _mm_storeu_si128((__m128i*)(result_ptr + i), stone_counts);\n        increments = _mm_add_epi32(increments, twos);\n    }\n\n    for (; i < n; ++i) {\n        result[i] = n + (i * 2) + (n % 2);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_110_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> make_a_pile_simd(int n){\n    std::vector<int> result(n);\n    int* result_ptr = result.data();\n\n    __m128i stone_counts;\n    __m128i increments;\n    __m128i ones = _mm_set1_epi32(1);\n    __m128i twos = _mm_set1_epi32(2);\n\n    if (n % 2 == 0) {\n        increments = _mm_setr_epi32(2, 4, 6, 8);\n    } else {\n        increments = _mm_setr_epi32(1, 3, 5, 7);\n    }\n\n    int i = 0;\n    for (; i <= n - 4; i += 4) {\n        stone_counts = _mm_setr_epi32(n, n-1, n-2, n-3);\n        stone_counts = _mm_sub_epi32(stone_counts, increments);\n        stone_counts = _mm_add_epi32(stone_counts, twos);\n        _mm_storeu_si128((__m128i*)(result_ptr + i), stone_counts);\n        increments = _mm_add_epi32(increments, twos);\n    }\n\n    for (; i < n; ++i) {\n        result[i] = n + (i * 2) + (n % 2);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_110_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> make_a_pile_simd(int n){\n    std::vector<int> result(n);\n    int* result_ptr = result.data();\n\n    __m128i increment;\n    if (n % 2 == 0) {\n        increment = _mm_set1_epi32(2); // Even increment\n    } else {\n        increment = _mm_set1_epi32(2); // Odd increment, start with 2 to adjust in loop\n    }\n\n    __m128i current = _mm_setr_epi32(n, n + 2, n + 4, n + 6);\n\n    for (int i = 0; i < n; i += 4) {\n        if (i == 0 && n % 2 != 0) {\n            // Adjust for the first element if n is odd\n            current = _mm_add_epi32(current, _mm_setr_epi32(0, -2, -4, -6));\n        }\n        _mm_storeu_si128((__m128i*)(result_ptr + i), current);\n        current = _mm_add_epi32(current, increment);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_110_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> make_a_pile_simd(int n){\n    std::vector<int> result(n);\n    int* result_ptr = result.data();\n\n    __m128i stone_counts;\n    __m128i increments;\n    __m128i ones = _mm_set1_epi32(1);\n    __m128i twos = _mm_set1_epi32(2);\n\n    if (n % 2 == 0) {\n        increments = _mm_setr_epi32(2, 4, 6, 8);\n    } else {\n        increments = _mm_setr_epi32(1, 3, 5, 7);\n    }\n\n    for (int i = 0; i < n; i += 4) {\n        int count = n - i;\n        if (count >= 4) {\n            stone_counts = _mm_setr_epi32(n - i, n - i - 1, n - i - 2, n - i - 3);\n            stone_counts = _mm_mullo_epi32(stone_counts, ones);\n            stone_counts = _mm_add_epi32(stone_counts, increments);\n            _mm_storeu_si128((__m128i*)(result_ptr + i), stone_counts);\n            increments = _mm_add_epi32(increments, twos);\n        } else {\n            for (int j = 0; j < count; ++j) {\n                result_ptr[i + j] = n - i - j + ((n % 2 == 0) ? (2 * j) : (2 * j + 1));\n            }\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_110_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> make_a_pile_simd(int n){\n    std::vector<int> result(n);\n    int* result_ptr = result.data();\n\n    __m128i stone_counts;\n    __m128i increments;\n    __m128i ones = _mm_set1_epi32(1);\n    __m128i twos = _mm_set1_epi32(2);\n\n    if (n % 2 == 0) {\n        increments = _mm_setr_epi32(2, 4, 6, 8);\n    } else {\n        increments = _mm_setr_epi32(1, 3, 5, 7);\n    }\n\n    for (int i = 0; i < n; i += 4) {\n        int count = n - i;\n        if (count >= 4) {\n            stone_counts = _mm_setr_epi32(n - i, n - i - 1, n - i - 2, n - i - 3);\n            stone_counts = _mm_mullo_epi32(stone_counts, ones);\n            stone_counts = _mm_add_epi32(stone_counts, increments);\n            _mm_storeu_si128((__m128i*)(result_ptr + i), stone_counts);\n            increments = _mm_add_epi32(increments, twos);\n        } else {\n            for (int j = 0; j < count; ++j) {\n                result_ptr[i + j] = n - i - j + ((n % 2 == 0) ? (2 * j) : (2 * j + 1));\n            }\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_111_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n#include <bitset>\n\nstd::string rounded_avg_simd(int64_t n, int64_t m){\n    if (n > m) {\n        return \"-1\";\n    }\n\n    __m128i n_vec = _mm_set1_epi64x(n);\n    __m128i m_vec = _mm_set1_epi64x(m);\n    __m128i sum_vec = _mm_add_epi64(n_vec, m_vec);\n    __m128i two_vec = _mm_set1_epi64x(2);\n    __m128i avg_vec = _mm_srli_epi64(_mm_add_epi64(sum_vec, _mm_set1_epi64x(1)), 1);\n\n    int64_t avg = _mm_cvtsi128_si64(avg_vec);\n    std::string binary = std::bitset<64>(avg).to_string();\n    binary.erase(0, binary.find_first_not_of('0'));\n\n    return binary;\n}\n```"}
{"task_id": "SimdBench_111_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n#include <bitset>\n\nstd::string rounded_avg_simd(int64_t n, int64_t m){\n    if (n > m) {\n        return \"-1\";\n    }\n\n    __m128i n_vec = _mm_set1_epi64x(n);\n    __m128i m_vec = _mm_set1_epi64x(m);\n    __m128i sum_vec = _mm_add_epi64(n_vec, m_vec);\n    __m128i two_vec = _mm_set1_epi64x(2);\n    __m128i avg_vec = _mm_srli_epi64(_mm_add_epi64(sum_vec, _mm_set1_epi64x(1)), 1);\n\n    int64_t avg = _mm_cvtsi128_si64(avg_vec);\n    std::string binary = std::bitset<64>(avg).to_string();\n    auto pos = binary.find('1');\n    if (pos != std::string::npos) {\n        return binary.substr(pos);\n    }\n    return \"0\";\n}\n```"}
{"task_id": "SimdBench_111_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n#include <bitset>\n\nstd::string rounded_avg_simd(int64_t n, int64_t m){\n    if (n > m) {\n        return \"-1\";\n    }\n\n    __m128i n_vec = _mm_set1_epi64x(n);\n    __m128i m_vec = _mm_set1_epi64x(m);\n    __m128i sum_vec = _mm_add_epi64(n_vec, m_vec);\n    __m128i two_vec = _mm_set1_epi64x(2);\n    __m128i avg_vec = _mm_srli_epi64(_mm_add_epi64(sum_vec, _mm_set1_epi64x(1)), 1);\n\n    int64_t avg = _mm_cvtsi128_si64(avg_vec);\n    std::string binary = std::bitset<64>(avg).to_string();\n    auto pos = binary.find('1');\n    return pos != std::string::npos ? binary.substr(pos) : \"0\";\n}\n```"}
{"task_id": "SimdBench_111_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n#include <bitset>\n\nstd::string rounded_avg_simd(int64_t n, int64_t m){\n    if (n > m) {\n        return \"-1\";\n    }\n\n    __m128i n_vec = _mm_set1_epi64x(n);\n    __m128i m_vec = _mm_set1_epi64x(m);\n    __m128i sum_vec = _mm_add_epi64(n_vec, m_vec);\n    __m128i two_vec = _mm_set1_epi64x(2);\n    __m128i avg_vec = _mm_srli_epi64(_mm_add_epi64(sum_vec, _mm_set1_epi64x(1)), 1);\n\n    int64_t avg = _mm_cvtsi128_si64(avg_vec);\n    std::string binary = std::bitset<64>(avg).to_string();\n    auto pos = binary.find('1');\n    return pos != std::string::npos ? binary.substr(pos) : \"0\";\n}\n```"}
{"task_id": "SimdBench_111_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n#include <bitset>\n\nstd::string rounded_avg_simd(int64_t n, int64_t m){\n    if (n > m) {\n        return \"-1\";\n    }\n\n    __m128i n_vec = _mm_set1_epi64x(n);\n    __m128i m_vec = _mm_set1_epi64x(m);\n    __m128i sum_vec = _mm_add_epi64(n_vec, m_vec);\n    __m128i two_vec = _mm_set1_epi64x(2);\n    __m128i avg_vec = _mm_srli_epi64(_mm_add_epi64(sum_vec, _mm_set1_epi64x(1)), 1);\n\n    int64_t avg = _mm_cvtsi128_si64(avg_vec);\n    std::string binary = std::bitset<64>(avg).to_string();\n    size_t pos = binary.find('1');\n    if (pos != std::string::npos) {\n        return binary.substr(pos);\n    }\n    return \"0\";\n}\n```"}
{"task_id": "SimdBench_112_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> func_simd(int n) {\n    std::vector<int> result(n);\n    int* result_ptr = result.data();\n\n    __m128i factorials = _mm_set1_epi32(1);\n    __m128i sums = _mm_set1_epi32(0);\n    __m128i indices = _mm_setr_epi32(1, 2, 3, 4);\n    __m128i ones = _mm_set1_epi32(1);\n    __m128i tens = _mm_set1_epi32(10000);\n\n    for (int i = 0; i < n; i += 4) {\n        __m128i even_mask = _mm_and_si128(indices, ones);\n        even_mask = _mm_cmpeq_epi32(even_mask, _mm_setzero_si128());\n\n        __m128i next_indices = _mm_add_epi32(indices, _mm_set1_epi32(4));\n        __m128i increments = _mm_setr_epi32(1, 2, 3, 4);\n\n        __m128i new_sums = _mm_add_epi32(sums, increments);\n        sums = _mm_add_epi32(sums, next_indices);\n\n        __m128i new_factorials = _mm_mullo_epi32(factorials, next_indices);\n        factorials = _mm_mullo_epi32(factorials, _mm_add_epi32(next_indices, ones));\n\n        factorials = _mm_min_epi32(factorials, tens);\n        new_factorials = _mm_min_epi32(new_factorials, tens);\n\n        __m128i results = _mm_blendv_epi8(new_sums, new_factorials, even_mask);\n\n        _mm_storeu_si128((__m128i*)(result_ptr + i), results);\n\n        indices = next_indices;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_112_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> func_simd(int n) {\n    std::vector<int> result(n);\n    int* result_ptr = result.data();\n\n    __m128i factorials = _mm_set1_epi32(1);\n    __m128i sums = _mm_set1_epi32(0);\n    __m128i indices = _mm_setr_epi32(1, 2, 3, 4);\n    __m128i ones = _mm_set1_epi32(1);\n    __m128i tens = _mm_set1_epi32(10000);\n\n    for (int i = 0; i < n; i += 4) {\n        __m128i even_mask = _mm_and_si128(indices, ones);\n        even_mask = _mm_cmpeq_epi32(even_mask, _mm_setzero_si128());\n\n        __m128i next_indices = _mm_add_epi32(indices, _mm_set1_epi32(4));\n        __m128i increments = _mm_setr_epi32(1, 2, 3, 4);\n\n        __m128i new_sums = _mm_add_epi32(sums, increments);\n        sums = _mm_add_epi32(sums, next_indices);\n\n        __m128i new_factorials = _mm_mullo_epi32(factorials, next_indices);\n        factorials = _mm_mullo_epi32(factorials, _mm_add_epi32(next_indices, ones));\n\n        factorials = _mm_min_epi32(factorials, tens);\n        new_factorials = _mm_min_epi32(new_factorials, tens);\n\n        __m128i results = _mm_blendv_epi8(new_sums, new_factorials, even_mask);\n\n        _mm_storeu_si128((__m128i*)(result_ptr + i), results);\n\n        indices = next_indices;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_112_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> func_simd(int n) {\n    std::vector<int> result(n);\n    int* result_ptr = result.data();\n\n    __m128i factorials = _mm_set1_epi32(1);\n    __m128i sums = _mm_set1_epi32(0);\n    __m128i indices = _mm_setr_epi32(1, 2, 3, 4);\n    __m128i ones = _mm_set1_epi32(1);\n    __m128i tens = _mm_set1_epi32(10000);\n\n    for (int i = 0; i < n; i += 4) {\n        __m128i even_mask = _mm_and_si128(indices, ones);\n        even_mask = _mm_cmpeq_epi32(even_mask, _mm_setzero_si128());\n\n        __m128i next_indices = _mm_add_epi32(indices, _mm_set1_epi32(4));\n        __m128i increments = _mm_setr_epi32(1, 2, 3, 4);\n\n        __m128i new_sums = _mm_add_epi32(sums, increments);\n        sums = _mm_add_epi32(sums, next_indices);\n\n        __m128i new_factorials = _mm_mullo_epi32(factorials, next_indices);\n        factorials = _mm_mullo_epi32(factorials, _mm_add_epi32(next_indices, ones));\n\n        factorials = _mm_min_epi32(factorials, tens);\n        new_factorials = _mm_min_epi32(new_factorials, tens);\n\n        __m128i results = _mm_blendv_epi8(new_sums, new_factorials, even_mask);\n\n        _mm_storeu_si128((__m128i*)(result_ptr + i), results);\n\n        indices = next_indices;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_112_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> func_simd(int n) {\n    std::vector<int> result(n);\n    int* result_ptr = result.data();\n\n    __m128i factorials = _mm_set1_epi32(1);\n    __m128i sums = _mm_set1_epi32(0);\n    __m128i indices = _mm_setr_epi32(1, 2, 3, 4);\n    __m128i ones = _mm_set1_epi32(1);\n    __m128i tens = _mm_set1_epi32(10000);\n\n    for (int i = 0; i < n; i += 4) {\n        __m128i even_mask = _mm_and_si128(indices, ones);\n        even_mask = _mm_cmpeq_epi32(even_mask, _mm_setzero_si128());\n\n        __m128i next_indices = _mm_add_epi32(indices, _mm_set1_epi32(4));\n        __m128i next_factorials = _mm_mullo_epi32(factorials, next_indices);\n        next_factorials = _mm_min_epi32(next_factorials, tens);\n\n        __m128i next_sums = _mm_add_epi32(sums, indices);\n        next_sums = _mm_add_epi32(next_sums, _mm_setr_epi32(2, 3, 4, 5));\n\n        factorials = _mm_blendv_epi8(factorials, next_factorials, even_mask);\n        sums = _mm_blendv_epi8(sums, next_sums, _mm_xor_si128(even_mask, _mm_cmpeq_epi32(_mm_setzero_si128(), _mm_setzero_si128())));\n\n        _mm_storeu_si128((__m128i*)(result_ptr + i), _mm_blendv_epi8(sums, factorials, even_mask));\n\n        indices = next_indices;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_112_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> func_simd(int n) {\n    std::vector<int> result(n);\n    int* result_ptr = result.data();\n\n    __m128i factorials = _mm_set1_epi32(1);\n    __m128i sums = _mm_set1_epi32(0);\n    __m128i indices = _mm_setr_epi32(1, 2, 3, 4);\n    __m128i ones = _mm_set1_epi32(1);\n    __m128i tens = _mm_set1_epi32(10000);\n\n    for (int i = 0; i < n; i += 4) {\n        __m128i even_mask = _mm_and_si128(indices, ones);\n        even_mask = _mm_cmpeq_epi32(even_mask, _mm_setzero_si128());\n\n        __m128i next_indices = _mm_add_epi32(indices, _mm_set1_epi32(4));\n        __m128i increments = _mm_setr_epi32(1, 2, 3, 4);\n\n        __m128i new_sums = _mm_add_epi32(sums, increments);\n        sums = _mm_add_epi32(sums, next_indices);\n\n        __m128i new_factorials = _mm_mullo_epi32(factorials, next_indices);\n        factorials = _mm_mullo_epi32(factorials, _mm_add_epi32(next_indices, ones));\n\n        factorials = _mm_min_epi32(factorials, tens);\n        new_factorials = _mm_min_epi32(new_factorials, tens);\n\n        __m128i results = _mm_blendv_epi8(new_sums, new_factorials, even_mask);\n\n        _mm_storeu_si128((__m128i*)(result_ptr + i), results);\n\n        indices = next_indices;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_113_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> even_odd_palindrome_simd(int n){\n    __m128i even_count = _mm_setzero_si128();\n    __m128i odd_count = _mm_setzero_si128();\n\n    for (int i = 1; i <= n; i += 8) {\n        __m128i numbers = _mm_set_epi32(i + 7, i + 6, i + 5, i + 4, i + 3, i + 2, i + 1, i);\n        __m128i reversed_numbers = _mm_setzero_si128();\n        __m128i masks = _mm_setzero_si128();\n\n        for (int j = 0; j < 8; ++j) {\n            int num = i + j;\n            int reversed_num = 0;\n            int temp = num;\n            while (temp > 0) {\n                reversed_num = reversed_num * 10 + temp % 10;\n                temp /= 10;\n            }\n            reversed_numbers = _mm_insert_epi32(reversed_numbers, reversed_num, j);\n            masks = _mm_insert_epi32(masks, (num == reversed_num) ? 1 : 0, j);\n        }\n\n        __m128i equal_mask = _mm_cmpeq_epi32(numbers, reversed_numbers);\n        __m128i valid_mask = _mm_and_si128(equal_mask, masks);\n\n        __m128i even_mask = _mm_and_si128(valid_mask, _mm_set1_epi32(0x1));\n        __m128i odd_mask = _mm_andnot_si128(even_mask, valid_mask);\n\n        even_count = _mm_add_epi32(even_count, even_mask);\n        odd_count = _mm_add_epi32(odd_count, odd_mask);\n    }\n\n    int even_result[4], odd_result[4];\n    _mm_storeu_si128((__m128i*)even_result, even_count);\n    _mm_storeu_si128((__m128i*)odd_result, odd_count);\n\n    int total_even = even_result[0] + even_result[1] + even_result[2] + even_result[3];\n    int total_odd = odd_result[0] + odd_result[1] + odd_result[2] + odd_result[3];\n\n    return {total_even, total_odd};\n}\n```"}
{"task_id": "SimdBench_113_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> even_odd_palindrome_simd(int n) {\n    __m128i even_count = _mm_setzero_si128();\n    __m128i odd_count = _mm_setzero_si128();\n\n    for (int i = 1; i <= n; i += 8) {\n        __m128i numbers = _mm_set_epi32(i + 7, i + 6, i + 5, i + 4, i + 3, i + 2, i + 1, i);\n        __m128i reversed_numbers = _mm_setzero_si128();\n        __m128i mask = _mm_set1_epi32(0xF);\n\n        for (int j = 0; j < 4; ++j) {\n            __m128i shifted = _mm_srli_epi32(numbers, j * 4);\n            __m128i digits = _mm_and_si128(shifted, mask);\n            reversed_numbers = _mm_or_si128(_mm_slli_epi32(digits, (3 - j) * 4), reversed_numbers);\n        }\n\n        __m128i palindromes = _mm_cmpeq_epi32(numbers, reversed_numbers);\n        __m128i evens = _mm_and_si128(palindromes, _mm_set1_epi32(0x2));\n        __m128i odds = _mm_andnot_si128(evens, palindromes);\n\n        even_count = _mm_add_epi32(even_count, _mm_srli_epi32(_mm_castps_si128(_mm_movemask_ps(_mm_castsi128_ps(evens))), 23));\n        odd_count = _mm_add_epi32(odd_count, _mm_srli_epi32(_mm_castps_si128(_mm_movemask_ps(_mm_castsi128_ps(odds))), 23));\n    }\n\n    int even_result[4], odd_result[4];\n    _mm_storeu_si128((__m128i*)even_result, even_count);\n    _mm_storeu_si128((__m128i*)odd_result, odd_count);\n\n    int total_even = even_result[0] + even_result[1] + even_result[2] + even_result[3];\n    int total_odd = odd_result[0] + odd_result[1] + odd_result[2] + odd_result[3];\n\n    return {total_even, total_odd};\n}\n```"}
{"task_id": "SimdBench_113_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> even_odd_palindrome_simd(int n){\n    __m128i even_count = _mm_setzero_si128();\n    __m128i odd_count = _mm_setzero_si128();\n    __m128i ones = _mm_set1_epi32(1);\n\n    for (int i = 1; i <= n; i += 4) {\n        __m128i nums = _mm_setr_epi32(i, i+1, i+2, i+3);\n        __m128i rev_nums = _mm_setzero_si128();\n        __m128i mask = _mm_set1_epi32(0xF);\n\n        for (int j = 0; j < 8; ++j) {\n            __m128i shifted = _mm_srli_epi32(nums, j * 4);\n            __m128i digit = _mm_and_si128(shifted, mask);\n            rev_nums = _mm_or_si128(_mm_slli_epi32(digit, (7 - j) * 4), rev_nums);\n        }\n\n        __m128i is_palindrome = _mm_cmpeq_epi32(nums, rev_nums);\n        __m128i is_even = _mm_and_si128(is_palindrome, _mm_and_si128(nums, _mm_set1_epi32(1)));\n\n        even_count = _mm_add_epi32(even_count, is_even);\n        odd_count = _mm_add_epi32(odd_count, _mm_andnot_si128(is_even, is_palindrome));\n    }\n\n    int even_result[4], odd_result[4];\n    _mm_storeu_si128((__m128i*)even_result, even_count);\n    _mm_storeu_si128((__m128i*)odd_result, odd_count);\n\n    int total_even = even_result[0] + even_result[1] + even_result[2] + even_result[3];\n    int total_odd = odd_result[0] + odd_result[1] + odd_result[2] + odd_result[3];\n\n    return {total_even, total_odd};\n}\n```"}
{"task_id": "SimdBench_113_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> even_odd_palindrome_simd(int n){\n    __m128i even_count = _mm_setzero_si128();\n    __m128i odd_count = _mm_setzero_si128();\n\n    for (int i = 1; i <= n; i += 8) {\n        __m128i numbers = _mm_set_epi32(i + 7, i + 6, i + 5, i + 4, i + 3, i + 2, i + 1, i);\n        __m128i reversed_numbers = _mm_setzero_si128();\n        __m128i mask = _mm_set1_epi32(0xF);\n\n        for (int j = 0; j < 4; ++j) {\n            __m128i shifted = _mm_srli_epi32(numbers, j * 4);\n            __m128i digits = _mm_and_si128(shifted, mask);\n            reversed_numbers = _mm_or_si128(_mm_slli_epi32(digits, (3 - j) * 4), reversed_numbers);\n        }\n\n        __m128i palindromes = _mm_cmpeq_epi32(numbers, reversed_numbers);\n        __m128i even_mask = _mm_and_si128(palindromes, _mm_set1_epi32(1));\n        __m128i odd_mask = _mm_andnot_si128(even_mask, palindromes);\n\n        even_count = _mm_add_epi32(even_count, even_mask);\n        odd_count = _mm_add_epi32(odd_count, odd_mask);\n    }\n\n    int even_result[4], odd_result[4];\n    _mm_storeu_si128((__m128i*)even_result, even_count);\n    _mm_storeu_si128((__m128i*)odd_result, odd_count);\n\n    int total_even = even_result[0] + even_result[1] + even_result[2] + even_result[3];\n    int total_odd = odd_result[0] + odd_result[1] + odd_result[2] + odd_result[3];\n\n    return {total_even, total_odd};\n}\n```"}
{"task_id": "SimdBench_113_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> even_odd_palindrome_simd(int n){\n    __m128i even_count = _mm_setzero_si128();\n    __m128i odd_count = _mm_setzero_si128();\n\n    for (int i = 1; i <= n; i += 8) {\n        __m128i numbers = _mm_set_epi32(i + 7, i + 6, i + 5, i + 4, i + 3, i + 2, i + 1, i);\n        __m128i reversed_numbers = _mm_setzero_si128();\n        __m128i masks = _mm_setzero_si128();\n\n        for (int j = 0; j < 8; ++j) {\n            int num = i + j;\n            int reversed_num = 0;\n            int temp = num;\n            while (temp > 0) {\n                reversed_num = reversed_num * 10 + temp % 10;\n                temp /= 10;\n            }\n            __m128i reversed_num_vec = _mm_set1_epi32(reversed_num);\n            reversed_numbers = _mm_insert_epi32(reversed_numbers, reversed_num, j);\n            masks = _mm_insert_epi32(masks, (num == reversed_num) ? 1 : 0, j);\n        }\n\n        __m128i equal_mask = _mm_cmpeq_epi32(numbers, reversed_numbers);\n        __m128i palindrome_mask = _mm_and_si128(equal_mask, masks);\n\n        __m128i even_mask = _mm_and_si128(palindrome_mask, _mm_set1_epi32(0x1));\n        __m128i odd_mask = _mm_andnot_si128(even_mask, palindrome_mask);\n\n        even_count = _mm_add_epi32(even_count, even_mask);\n        odd_count = _mm_add_epi32(odd_count, odd_mask);\n    }\n\n    int even_sum[4], odd_sum[4];\n    _mm_storeu_si128((__m128i*)even_sum, even_count);\n    _mm_storeu_si128((__m128i*)odd_sum, odd_count);\n\n    int total_even = even_sum[0] + even_sum[1] + even_sum[2] + even_sum[3];\n    int total_odd = odd_sum[0] + odd_sum[1] + odd_sum[2] + odd_sum[3];\n\n    return {total_even, total_odd};\n}\n```"}
{"task_id": "SimdBench_114_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint count_nums_simd(std::vector<int> n) {\n    int count = 0;\n    int size = n.size();\n    int* data = n.data();\n\n    for (int i = 0; i <= size - 4; i += 4) {\n        __m128i nums = _mm_loadu_si128((__m128i*)&data[i]);\n        __m128i zero = _mm_setzero_si128();\n        __m128i ones = _mm_set1_epi32(1);\n        __m128i sign_mask = _mm_set1_epi32(0x80000000);\n\n        // Check if numbers are negative\n        __m128i is_negative = _mm_and_si128(nums, sign_mask);\n        __m128i abs_nums = _mm_xor_si128(nums, is_negative);\n        abs_nums = _mm_sub_epi32(abs_nums, is_negative);\n\n        // Sum of digits calculation\n        __m128i sum_digits = zero;\n        for (int j = 0; j < 10; ++j) {\n            __m128i digit = _mm_and_si128(abs_nums, _mm_set1_epi32(9));\n            sum_digits = _mm_add_epi32(sum_digits, digit);\n            abs_nums = _mm_srli_epi32(abs_nums, 4);\n        }\n\n        // Adjust sum for negative numbers\n        sum_digits = _mm_sub_epi32(sum_digits, _mm_and_si128(is_negative, _mm_set1_epi32(1)));\n\n        // Count numbers with sum of digits > 0\n        __m128i gt_zero = _mm_cmpgt_epi32(sum_digits, zero);\n        __m128i mask = _mm_movemask_epi8(gt_zero);\n        count += _mm_popcnt_u32(mask) / 4;\n    }\n\n    // Handle remaining elements\n    for (int i = (size & ~3); i < size; ++i) {\n        int num = data[i];\n        int sum_digits = 0;\n        bool is_negative = num < 0;\n        num = std::abs(num);\n\n        while (num > 0) {\n            sum_digits += num % 10;\n            num /= 10;\n        }\n\n        if (is_negative) {\n            sum_digits -= 1;\n        }\n\n        if (sum_digits > 0) {\n            count++;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_114_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint count_nums_simd(std::vector<int> n) {\n    int count = 0;\n    int size = n.size();\n    int* data = n.data();\n\n    for (int i = 0; i <= size - 4; i += 4) {\n        __m128i nums = _mm_loadu_si128((__m128i*)&data[i]);\n        __m128i zero = _mm_setzero_si128();\n        __m128i ones = _mm_set1_epi32(1);\n        __m128i sign_mask = _mm_set1_epi32(0x80000000);\n\n        __m128i abs_nums = _mm_abs_epi32(nums);\n        __m128i sum_digits = _mm_setzero_si128();\n\n        for (int j = 0; j < 10; ++j) {\n            __m128i digit = _mm_and_si128(abs_nums, _mm_set1_epi32(9));\n            sum_digits = _mm_add_epi32(sum_digits, digit);\n            abs_nums = _mm_srli_epi32(abs_nums, 4);\n        }\n\n        __m128i is_positive = _mm_cmpeq_epi32(_mm_and_si128(nums, sign_mask), zero);\n        sum_digits = _mm_and_si128(sum_digits, is_positive);\n\n        __m128i gt_zero = _mm_cmpgt_epi32(sum_digits, zero);\n        __m128i mask = _mm_movemask_epi8(gt_zero);\n\n        count += __builtin_popcount(mask >> 1) / 4;\n    }\n\n    for (int i = (size & ~3); i < size; ++i) {\n        int num = data[i];\n        int sum = 0;\n        int n = num < 0 ? -num : num;\n        while (n > 0) {\n            sum += n % 10;\n            n /= 10;\n        }\n        if ((num >= 0 && sum > 0) || (num < 0 && sum > 0)) {\n            count++;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_114_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint count_nums_simd(const std::vector<int>& n) {\n    int count = 0;\n    int size = n.size();\n    int i = 0;\n\n    __m128i zero = _mm_setzero_si128();\n    __m128i ones = _mm_set1_epi32(1);\n\n    while (i <= size - 4) {\n        __m128i nums = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&n[i]));\n        __m128i sign_mask = _mm_srai_epi32(nums, 31);\n        __m128i abs_nums = _mm_xor_si128(nums, sign_mask);\n        abs_nums = _mm_sub_epi32(abs_nums, sign_mask);\n\n        __m128i sum_digits = zero;\n        for (int j = 0; j < 10; ++j) {\n            __m128i digit = _mm_and_si128(abs_nums, _mm_set1_epi32(9));\n            sum_digits = _mm_add_epi32(sum_digits, digit);\n            abs_nums = _mm_srli_epi32(abs_nums, 4);\n        }\n\n        __m128i mask = _mm_cmpgt_epi32(sum_digits, zero);\n        __m128i result = _mm_and_si128(mask, ones);\n        int horizontal_sum = _mm_cvtsi128_si32(_mm_sad_epu8(result, zero)) >> 1;\n        count += horizontal_sum;\n\n        i += 4;\n    }\n\n    for (; i < size; ++i) {\n        int num = n[i];\n        int sum_digits = 0;\n        bool is_negative = num < 0;\n        num = is_negative ? -num : num;\n\n        while (num > 0) {\n            sum_digits += num % 10;\n            num /= 10;\n        }\n\n        if (is_negative) {\n            sum_digits = -sum_digits + 2 * (sum_digits % 10);\n        }\n\n        if (sum_digits > 0) {\n            count++;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_114_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint count_nums_simd(const std::vector<int>& n) {\n    int count = 0;\n    int size = n.size();\n    int i = 0;\n\n    __m128i zero = _mm_setzero_si128();\n    __m128i ones = _mm_set1_epi32(1);\n\n    while (i <= size - 4) {\n        __m128i nums = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&n[i]));\n        __m128i sign_mask = _mm_srai_epi32(nums, 31);\n        __m128i abs_nums = _mm_xor_si128(nums, sign_mask);\n        abs_nums = _mm_sub_epi32(abs_nums, sign_mask);\n\n        __m128i sum_digits = zero;\n        for (int j = 0; j < 10; ++j) {\n            __m128i digit = _mm_and_si128(abs_nums, _mm_set1_epi32(9));\n            sum_digits = _mm_add_epi32(sum_digits, digit);\n            abs_nums = _mm_srli_epi32(abs_nums, 4);\n        }\n\n        __m128i mask = _mm_cmpgt_epi32(sum_digits, zero);\n        __m128i result = _mm_and_si128(mask, ones);\n        int horizontal_sum = _mm_hadd_epi32(result, result)[0];\n        horizontal_sum = _mm_hadd_epi32(_mm_set1_epi32(horizontal_sum), zero)[0];\n\n        count += horizontal_sum;\n        i += 4;\n    }\n\n    for (; i < size; ++i) {\n        int num = n[i];\n        int sum_digits = 0;\n        bool is_negative = num < 0;\n        num = is_negative ? -num : num;\n\n        while (num > 0) {\n            sum_digits += num % 10;\n            num /= 10;\n        }\n\n        if (is_negative) {\n            sum_digits = sum_digits - 2 * (n[i] % 10);\n        }\n\n        if (sum_digits > 0) {\n            count++;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_114_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint count_nums_simd(const std::vector<int>& n) {\n    int count = 0;\n    int size = n.size();\n    int i = 0;\n\n    __m128i zero = _mm_setzero_si128();\n    __m128i ones = _mm_set1_epi32(1);\n\n    while (i <= size - 4) {\n        __m128i nums = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&n[i]));\n        __m128i sign_mask = _mm_srai_epi32(nums, 31);\n        __m128i abs_nums = _mm_xor_si128(nums, sign_mask);\n        abs_nums = _mm_sub_epi32(abs_nums, sign_mask);\n\n        __m128i sum_digits = zero;\n        for (int j = 0; j < 10; ++j) {\n            __m128i digit = _mm_and_si128(abs_nums, _mm_set1_epi32(9));\n            sum_digits = _mm_add_epi32(sum_digits, digit);\n            abs_nums = _mm_srli_epi32(abs_nums, 4);\n        }\n\n        __m128i mask = _mm_cmpgt_epi32(sum_digits, zero);\n        __m128i result = _mm_and_si128(mask, ones);\n        int horizontal_sum = _mm_hadd_epi32(result, result)[0];\n        horizontal_sum = _mm_hadd_epi32(_mm_set1_epi32(horizontal_sum), zero)[0];\n\n        count += horizontal_sum;\n        i += 4;\n    }\n\n    for (; i < size; ++i) {\n        int num = n[i];\n        int sum_digits = 0;\n        bool is_negative = num < 0;\n        num = is_negative ? -num : num;\n\n        while (num > 0) {\n            sum_digits += num % 10;\n            num /= 10;\n        }\n\n        if (is_negative) {\n            sum_digits = sum_digits - 2 * (n[i] % 10);\n        }\n\n        if (sum_digits > 0) {\n            count++;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_115_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nbool move_one_ball_simd(std::vector<int> arr) {\n    int n = arr.size();\n    if (n == 0) return true;\n\n    __m128i vec1, vec2, mask, cmp_mask;\n    int shift_count = 0;\n    bool found = false;\n\n    while (!found && shift_count < n) {\n        for (int i = 0; i <= n - 4; i += 4) {\n            vec1 = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&arr[i]));\n            vec2 = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&arr[(i + 1) % n]));\n\n            cmp_mask = _mm_cmpgt_epi32(vec1, vec2);\n            mask = _mm_cmpeq_epi32(cmp_mask, _mm_setzero_si128());\n\n            if (_mm_movemask_epi8(mask) != 0xFFFF) {\n                found = false;\n                break;\n            }\n            found = true;\n        }\n\n        if (found) break;\n\n        int last = arr[n - 1];\n        for (int i = n - 1; i > 0; --i) {\n            arr[i] = arr[i - 1];\n        }\n        arr[0] = last;\n        ++shift_count;\n    }\n\n    return found;\n}\n```"}
{"task_id": "SimdBench_115_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nbool move_one_ball_simd(std::vector<int> arr) {\n    int n = arr.size();\n    if (n == 0) return true;\n\n    __m128i vec1, vec2, mask, cmp;\n    int shift_count = 0;\n    bool found = false;\n\n    while (!found && shift_count < n) {\n        for (int i = 0; i < n; i += 4) {\n            vec1 = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&arr[i]));\n            vec2 = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&arr[(i + 1) % n]));\n\n            cmp = _mm_cmpgt_epi32(vec1, vec2);\n            mask = _mm_cmpeq_epi32(cmp, _mm_set1_epi32(0));\n\n            if (_mm_movemask_epi8(mask) != 0xFFFF) {\n                found = false;\n                break;\n            }\n            found = true;\n        }\n        if (!found) {\n            std::rotate(arr.rbegin(), arr.rbegin() + 1, arr.rend());\n            shift_count++;\n        }\n    }\n\n    return found;\n}\n```"}
{"task_id": "SimdBench_115_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nbool move_one_ball_simd(std::vector<int> arr) {\n    int n = arr.size();\n    if (n == 0) return true;\n\n    __m128i vec1, vec2, mask, cmp_mask;\n    int shift_count = 0;\n    bool found = false;\n\n    while (shift_count < n && !found) {\n        for (int i = 0; i < n; i += 4) {\n            vec1 = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&arr[i]));\n            vec2 = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&arr[(i + 1) % n]));\n\n            cmp_mask = _mm_cmpgt_epi32(vec1, vec2);\n            mask = _mm_cmpeq_epi32(cmp_mask, _mm_setzero_si128());\n\n            if (_mm_movemask_epi8(mask) != 0xFFFF) {\n                found = false;\n                break;\n            }\n            found = true;\n        }\n        if (!found) {\n            std::rotate(arr.rbegin(), arr.rbegin() + 1, arr.rend());\n            shift_count++;\n        }\n    }\n\n    return found;\n}\n```"}
{"task_id": "SimdBench_115_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nbool move_one_ball_simd(std::vector<int> arr) {\n    int n = arr.size();\n    if (n == 0) return true;\n\n    __m128i vec1, vec2, mask, cmp;\n    int shift_count = 0;\n    bool found = false;\n\n    while (!found && shift_count < n) {\n        for (int i = 0; i <= n - 4; i += 4) {\n            vec1 = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&arr[i]));\n            vec2 = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&arr[(i + 1) % n]));\n\n            cmp = _mm_cmpgt_epi32(vec1, vec2);\n            mask = _mm_cmpeq_epi32(cmp, _mm_set1_epi32(0));\n\n            if (_mm_movemask_epi8(mask) != 0xFFFF) {\n                found = false;\n                break;\n            }\n            found = true;\n        }\n\n        if (!found) {\n            int last = arr[n - 1];\n            for (int i = n - 1; i > 0; --i) {\n                arr[i] = arr[i - 1];\n            }\n            arr[0] = last;\n            ++shift_count;\n        }\n    }\n\n    return found;\n}\n```"}
{"task_id": "SimdBench_115_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nbool move_one_ball_simd(std::vector<int> arr) {\n    int n = arr.size();\n    if (n == 0) return true;\n\n    __m128i vec1, vec2, mask, cmp;\n    int shift_count = 0;\n    bool found = false;\n\n    while (!found && shift_count < n) {\n        for (int i = 0; i < n; i += 4) {\n            vec1 = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&arr[i]));\n            vec2 = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&arr[(i + 1) % n]));\n\n            cmp = _mm_cmpgt_epi32(vec1, vec2);\n            mask = _mm_cmpeq_epi32(cmp, _mm_set1_epi32(0));\n\n            if (_mm_movemask_epi8(mask) != 0xFFFF) {\n                found = false;\n                break;\n            }\n            found = true;\n        }\n        if (!found) {\n            std::rotate(arr.rbegin(), arr.rbegin() + 1, arr.rend());\n            shift_count++;\n        }\n    }\n\n    return found;\n}\n```"}
{"task_id": "SimdBench_116_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n\nstd::string myexchange_simd(const std::vector<int>& lst1, const std::vector<int>& lst2){\n    int n1 = lst1.size();\n    int n2 = lst2.size();\n\n    __m128i all_ones = _mm_set1_epi32(0xFFFFFFFF);\n    __m128i mask_even = _mm_set1_epi32(1);\n\n    __m128i odd_count_lst1 = _mm_setzero_si128();\n\n    for(int i = 0; i < n1; i += 4){\n        __m128i vec1 = _mm_loadu_si128((__m128i*)&lst1[i]);\n        __m128i odd_mask = _mm_and_si128(vec1, mask_even);\n        odd_count_lst1 = _mm_or_si128(odd_count_lst1, odd_mask);\n    }\n\n    __m128i even_count_lst2 = _mm_setzero_si128();\n\n    for(int i = 0; i < n2; i += 4){\n        __m128i vec2 = _mm_loadu_si128((__m128i*)&lst2[i]);\n        __m128i even_mask = _mm_andnot_si128(mask_even, vec2);\n        even_count_lst2 = _mm_or_si128(even_count_lst2, even_mask);\n    }\n\n    odd_count_lst1 = _mm_cmpeq_epi32(odd_count_lst1, all_ones);\n    even_count_lst2 = _mm_cmpeq_epi32(even_count_lst2, all_ones);\n\n    int odd_count = _mm_movemask_epi8(odd_count_lst1);\n    int even_count = _mm_movemask_epi8(even_count_lst2);\n\n    if((odd_count & 0x55555555) < (even_count & 0x55555555)){\n        return \"YES\";\n    } else {\n        return \"NO\";\n    }\n}\n```"}
{"task_id": "SimdBench_116_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n\nstd::string myexchange_simd(const std::vector<int>& lst1, const std::vector<int>& lst2){\n    int n1 = lst1.size();\n    int n2 = lst2.size();\n\n    __m128i all_ones = _mm_set1_epi32(1);\n\n    // Check lst1 for odd numbers\n    for (int i = 0; i <= n1 - 4; i += 4) {\n        __m128i vec1 = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&lst1[i]));\n        __m128i odd_mask = _mm_and_si128(vec1, all_ones);\n        if (!_mm_testz_si128(odd_mask, odd_mask)) {\n            // Found odd numbers in lst1, check lst2 for even numbers\n            bool has_even_in_lst2 = false;\n            for (int j = 0; j <= n2 - 4; j += 4) {\n                __m128i vec2 = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&lst2[j]));\n                __m128i even_mask = _mm_andnot_si128(_mm_and_si128(vec2, all_ones), all_ones);\n                if (!_mm_testz_si128(even_mask, even_mask)) {\n                    has_even_in_lst2 = true;\n                    break;\n                }\n            }\n            // Check remaining elements in lst2 if not found in multiples of 4\n            if (!has_even_in_lst2) {\n                for (int j = (n2 / 4) * 4; j < n2; ++j) {\n                    if ((lst2[j] & 1) == 0) {\n                        has_even_in_lst2 = true;\n                        break;\n                    }\n                }\n            }\n            if (!has_even_in_lst2) {\n                return \"NO\";\n            }\n        }\n    }\n\n    // Check remaining elements in lst1 if not found in multiples of 4\n    for (int i = (n1 / 4) * 4; i < n1; ++i) {\n        if ((lst1[i] & 1) != 0) {\n            // Found odd number in lst1, check lst2 for even numbers\n            bool has_even_in_lst2 = false;\n            for (int j = 0; j < n2; ++j) {\n                if ((lst2[j] & 1) == 0) {\n                    has_even_in_lst2 = true;\n                    break;\n                }\n            }\n            if (!has_even_in_lst2) {\n                return \"NO\";\n            }\n        }\n    }\n\n    return \"YES\";\n}\n```"}
{"task_id": "SimdBench_116_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n\nstd::string myexchange_simd(const std::vector<int>& lst1, const std::vector<int>& lst2){\n    int n1 = lst1.size();\n    int n2 = lst2.size();\n\n    __m128i all_ones = _mm_set1_epi32(1);\n\n    // Check lst1 for odd numbers\n    for (int i = 0; i <= n1 - 4; i += 4) {\n        __m128i vec1 = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&lst1[i]));\n        __m128i odd_mask = _mm_and_si128(vec1, all_ones);\n        if (!_mm_test_all_zeros(odd_mask, odd_mask)) {\n            // Found odd numbers in lst1, check lst2 for even numbers\n            bool has_even_in_lst2 = false;\n            for (int j = 0; j <= n2 - 4; j += 4) {\n                __m128i vec2 = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&lst2[j]));\n                __m128i even_mask = _mm_andnot_si128(_mm_and_si128(vec2, all_ones), all_ones);\n                if (!_mm_test_all_zeros(even_mask, even_mask)) {\n                    has_even_in_lst2 = true;\n                    break;\n                }\n            }\n            // Check remaining elements in lst2 if not found in multiples of 4\n            if (!has_even_in_lst2) {\n                for (int j = (n2 / 4) * 4; j < n2; ++j) {\n                    if ((lst2[j] & 1) == 0) {\n                        has_even_in_lst2 = true;\n                        break;\n                    }\n                }\n            }\n            if (!has_even_in_lst2) {\n                return \"NO\";\n            }\n        }\n    }\n\n    // Check remaining elements in lst1 if not found in multiples of 4\n    for (int i = (n1 / 4) * 4; i < n1; ++i) {\n        if ((lst1[i] & 1) != 0) {\n            // Found odd number in lst1, check lst2 for even numbers\n            bool has_even_in_lst2 = false;\n            for (int j = 0; j < n2; ++j) {\n                if ((lst2[j] & 1) == 0) {\n                    has_even_in_lst2 = true;\n                    break;\n                }\n            }\n            if (!has_even_in_lst2) {\n                return \"NO\";\n            }\n        }\n    }\n\n    return \"YES\";\n}\n```"}
{"task_id": "SimdBench_116_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n\nstd::string myexchange_simd(const std::vector<int>& lst1, const std::vector<int>& lst2){\n    int n1 = lst1.size();\n    int n2 = lst2.size();\n\n    __m128i even_mask = _mm_set1_epi32(1);\n\n    __m128i lst1_even = _mm_setzero_si128();\n    __m128i lst2_odd = _mm_setzero_si128();\n\n    for (int i = 0; i < n1; i += 4) {\n        __m128i v1 = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&lst1[i]));\n        __m128i v1_even = _mm_and_si128(v1, even_mask);\n        lst1_even = _mm_or_si128(lst1_even, v1_even);\n    }\n\n    for (int i = 0; i < n2; i += 4) {\n        __m128i v2 = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&lst2[i]));\n        __m128i v2_odd = _mm_andnot_si128(v2, even_mask);\n        lst2_odd = _mm_or_si128(lst2_odd, v2_odd);\n    }\n\n    __m128i result = _mm_and_si128(lst1_even, lst2_odd);\n\n    int mask = _mm_movemask_epi8(result);\n    if (mask != 0) {\n        return \"YES\";\n    } else {\n        return \"NO\";\n    }\n}\n```"}
{"task_id": "SimdBench_116_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n\nstd::string myexchange_simd(const std::vector<int>& lst1, const std::vector<int>& lst2){\n    int n1 = lst1.size();\n    int n2 = lst2.size();\n\n    __m128i all_ones = _mm_set1_epi32(1);\n    __m128i mask = _mm_set1_epi32(0xFFFFFFFF);\n\n    int i = 0;\n    for (; i <= n1 - 4; i += 4) {\n        __m128i vec1 = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&lst1[i]));\n        __m128i even_mask = _mm_and_si128(_mm_srli_epi32(vec1, 1), all_ones);\n        even_mask = _mm_cmpeq_epi32(even_mask, _mm_setzero_si128());\n        if (_mm_test_all_zeros(even_mask, mask)) continue;\n\n        int j = 0;\n        for (; j <= n2 - 4; j += 4) {\n            __m128i vec2 = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&lst2[j]));\n            __m128i even_mask2 = _mm_and_si128(_mm_srli_epi32(vec2, 1), all_ones);\n            even_mask2 = _mm_cmpeq_epi32(even_mask2, _mm_setzero_si128());\n            if (!_mm_test_all_zeros(even_mask2, mask)) {\n                return \"YES\";\n            }\n        }\n        for (; j < n2; ++j) {\n            if ((lst2[j] & 1) == 0) {\n                return \"YES\";\n            }\n        }\n    }\n\n    for (; i < n1; ++i) {\n        if ((lst1[i] & 1) != 0) {\n            int j = 0;\n            for (; j < n2; ++j) {\n                if ((lst2[j] & 1) == 0) {\n                    return \"YES\";\n                }\n            }\n            return \"NO\";\n        }\n    }\n\n    return \"YES\";\n}\n```"}
{"task_id": "SimdBench_117_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n\nstd::vector<std::string> odd_count_simd(const std::vector<std::string> & lst){\n    std::vector<std::string> result;\n    for (const auto& str : lst) {\n        int odd_count = 0;\n        const char* s = str.c_str();\n        int len = str.size();\n        __m128i odd_mask = _mm_set1_epi8(0x01);\n        __m128i count = _mm_setzero_si128();\n\n        for (int i = 0; i <= len - 16; i += 16) {\n            __m128i chars = _mm_loadu_si128(reinterpret_cast<const __m128i*>(s + i));\n            __m128i odds = _mm_and_si128(chars, odd_mask);\n            __m128i cmp = _mm_cmpeq_epi8(odds, odd_mask);\n            count = _mm_add_epi8(count, cmp);\n        }\n\n        int sum[16];\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(sum), count);\n        odd_count = sum[0] + sum[1] + sum[2] + sum[3] + sum[4] + sum[5] + sum[6] + sum[7] +\n                    sum[8] + sum[9] + sum[10] + sum[11] + sum[12] + sum[13] + sum[14] + sum[15];\n\n        for (int i = len % 16; i > 0; --i) {\n            odd_count += (s[len - i] - '0') % 2;\n        }\n\n        std::string res = \"the number of odd elements \";\n        res += std::to_string(odd_count);\n        res += \"n the str\";\n        res += std::to_string(odd_count);\n        res += \"ng \";\n        res += std::to_string(odd_count);\n        res += \" of the \";\n        res += std::to_string(odd_count);\n        res += \"nput.\";\n        result.push_back(res);\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_117_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n#include <cstring>\n\nstd::vector<std::string> odd_count_simd(const std::vector<std::string> & lst){\n    std::vector<std::string> result;\n    const __m128i odd_mask = _mm_set1_epi8(0x1);\n\n    for (const auto& str : lst) {\n        int odd_count = 0;\n        size_t len = str.size();\n        const char* ptr = str.c_str();\n\n        for (size_t i = 0; i <= len - 16; i += 16) {\n            __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(ptr + i));\n            __m128i is_digit = _mm_cmplt_epi8(chunk, _mm_set1_epi8('0'));\n            is_digit = _mm_or_si128(is_digit, _mm_cmpgt_epi8(chunk, _mm_set1_epi8('9')));\n            chunk = _mm_andnot_si128(is_digit, chunk);\n            chunk = _mm_sub_epi8(chunk, _mm_set1_epi8('0'));\n            chunk = _mm_and_si128(chunk, odd_mask);\n            odd_count += _mm_popcnt_u32(_mm_movemask_epi8(chunk));\n        }\n\n        for (size_t i = (len & ~15); i < len; ++i) {\n            if ((str[i] - '0') % 2 != 0) {\n                ++odd_count;\n            }\n        }\n\n        char buffer[100];\n        snprintf(buffer, sizeof(buffer), \"the number of odd elements %dn the str%ng %d of the %dnput.\", odd_count, odd_count, odd_count);\n        result.push_back(std::string(buffer));\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_117_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n#include <cstring>\n\nstd::vector<std::string> odd_count_simd(const std::vector<std::string> & lst){\n    std::vector<std::string> result;\n    const __m128i odd_mask = _mm_set1_epi8(0x1);\n\n    for (const auto & str : lst) {\n        int odd_count = 0;\n        size_t len = str.size();\n        const char * ptr = str.c_str();\n\n        for (size_t i = 0; i <= len - 16; i += 16) {\n            __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(ptr + i));\n            __m128i is_digit = _mm_cmplt_epi8(chunk, _mm_set1_epi8('0'));\n            is_digit = _mm_or_si128(is_digit, _mm_cmpgt_epi8(chunk, _mm_set1_epi8('9')));\n            chunk = _mm_andnot_si128(is_digit, chunk);\n            chunk = _mm_sub_epi8(chunk, _mm_set1_epi8('0'));\n            chunk = _mm_and_si128(chunk, odd_mask);\n            odd_count += _mm_popcnt_u32(_mm_movemask_epi8(chunk));\n        }\n\n        for (size_t i = (len & ~15); i < len; ++i) {\n            if ((str[i] >= '0' && str[i] <= '9') && (str[i] - '0') % 2 != 0) {\n                ++odd_count;\n            }\n        }\n\n        char buffer[100];\n        snprintf(buffer, sizeof(buffer), \"the number of odd elements %dn the str%ng %d of the %dnput.\", odd_count, odd_count, odd_count);\n        result.push_back(std::string(buffer));\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_117_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n\nstd::vector<std::string> odd_count_simd(const std::vector<std::string> & lst){\n    std::vector<std::string> result;\n    for (const auto& str : lst) {\n        int odd_count = 0;\n        const char* ptr = str.c_str();\n        int len = str.size();\n        \n        __m128i odd_mask = _mm_set1_epi8(0x01);\n        __m128i zero = _mm_setzero_si128();\n        \n        while (len >= 16) {\n            __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(ptr));\n            __m128i odd_digits = _mm_and_si128(chunk, odd_mask);\n            __m128i cmp = _mm_cmpeq_epi8(odd_digits, odd_mask);\n            __m128i sum = _mm_sad_epu8(cmp, zero);\n            odd_count += _mm_extract_epi16(sum, 0) + _mm_extract_epi16(sum, 4);\n            ptr += 16;\n            len -= 16;\n        }\n        \n        while (len > 0) {\n            odd_count += (*ptr - '0') % 2;\n            ptr++;\n            len--;\n        }\n        \n        std::string res = \"the number of odd elements \";\n        res += std::to_string(odd_count);\n        res += \"n the str\";\n        res += std::to_string(odd_count);\n        res += \"ng \";\n        res += std::to_string(odd_count);\n        res += \" of the \";\n        res += std::to_string(odd_count);\n        res += \"nput.\";\n        result.push_back(res);\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_117_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n\nstd::vector<std::string> odd_count_simd(const std::vector<std::string> & lst){\n    std::vector<std::string> result;\n    for (const auto& str : lst) {\n        int odd_count = 0;\n        const char* ptr = str.c_str();\n        int len = str.size();\n        \n        __m128i odd_mask = _mm_set1_epi8(0x01);\n        __m128i count = _mm_setzero_si128();\n        \n        while (len >= 16) {\n            __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(ptr));\n            __m128i odd_digits = _mm_and_si128(chunk, odd_mask);\n            count = _mm_add_epi8(count, odd_digits);\n            ptr += 16;\n            len -= 16;\n        }\n        \n        int sum[16];\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(sum), count);\n        odd_count = sum[0] + sum[1] + sum[2] + sum[3] + sum[4] + sum[5] + sum[6] + sum[7] +\n                    sum[8] + sum[9] + sum[10] + sum[11] + sum[12] + sum[13] + sum[14] + sum[15];\n        \n        for (int i = 0; i < len; ++i) {\n            odd_count += (ptr[i] - '0') % 2;\n        }\n        \n        std::string res = \"the number of odd elements \";\n        res += std::to_string(odd_count);\n        res += \"n the str\";\n        res += std::to_string(odd_count);\n        res += \"ng \";\n        res += std::to_string(odd_count);\n        res += \" of the \";\n        res += std::to_string(odd_count);\n        res += \"nput.\";\n        result.push_back(res);\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_118_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n#include <limits>\n\nint64_t minSubArraySum_simd(const std::vector<int64_t>& nums) {\n    if (nums.empty()) return 0;\n\n    int64_t min_sum = std::numeric_limits<int64_t>::max();\n    int64_t current_min = 0;\n    int n = nums.size();\n\n    __m128i min_vec = _mm_set1_epi64(std::numeric_limits<int64_t>::max());\n    __m128i current_min_vec = _mm_setzero_si128();\n\n    for (int i = 0; i <= n - 2; i += 2) {\n        __m128i num_vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&nums[i]));\n        current_min_vec = _mm_add_epi64(current_min_vec, num_vec);\n        current_min_vec = _mm_min_epi64(current_min_vec, num_vec);\n        min_vec = _mm_min_epi64(min_vec, current_min_vec);\n    }\n\n    int64_t result[2];\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(result), min_vec);\n\n    min_sum = std::min(result[0], result[1]);\n\n    // Handle remaining elements\n    for (int i = (n / 2) * 2; i < n; ++i) {\n        current_min = std::min(current_min + nums[i], nums[i]);\n        min_sum = std::min(min_sum, current_min);\n    }\n\n    return min_sum;\n}\n```"}
{"task_id": "SimdBench_118_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <limits>\n\nint64_t minSubArraySum_simd(const std::vector<int64_t>& nums) {\n    if (nums.empty()) return 0;\n\n    int64_t min_sum = std::numeric_limits<int64_t>::max();\n    int64_t current_min = 0;\n    int n = nums.size();\n\n    __m128i min_vec = _mm_set1_epi64(std::numeric_limits<int64_t>::max());\n    __m128i current_min_vec = _mm_setzero_si128();\n    __m128i zero_vec = _mm_setzero_si128();\n\n    for (int i = 0; i <= n - 2; i += 2) {\n        __m128i num_vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&nums[i]));\n        current_min_vec = _mm_add_epi64(current_min_vec, num_vec);\n        current_min_vec = _mm_min_epi64(current_min_vec, num_vec);\n        min_vec = _mm_min_epi64(min_vec, current_min_vec);\n\n        int64_t temp_min[2];\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(temp_min), min_vec);\n        min_sum = std::min(min_sum, temp_min[0]);\n        min_sum = std::min(min_sum, temp_min[1]);\n    }\n\n    for (int i = (n / 2) * 2; i < n; ++i) {\n        current_min += nums[i];\n        current_min = std::min(current_min, nums[i]);\n        min_sum = std::min(min_sum, current_min);\n    }\n\n    return min_sum;\n}\n```"}
{"task_id": "SimdBench_118_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <limits>\n\nint64_t minSubArraySum_simd(const std::vector<int64_t>& nums) {\n    if (nums.empty()) return 0;\n\n    int64_t min_sum = std::numeric_limits<int64_t>::max();\n    int64_t current_min = 0;\n    int n = nums.size();\n\n    __m128i min_vec = _mm_set1_epi64(std::numeric_limits<int64_t>::max());\n    __m128i current_min_vec = _mm_setzero_si128();\n\n    for (int i = 0; i <= n - 2; i += 2) {\n        __m128i num_vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&nums[i]));\n        current_min_vec = _mm_add_epi64(current_min_vec, num_vec);\n        current_min_vec = _mm_min_epi64(current_min_vec, num_vec);\n        min_vec = _mm_min_epi64(min_vec, current_min_vec);\n    }\n\n    int64_t result[2];\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(result), min_vec);\n\n    min_sum = std::min(result[0], result[1]);\n\n    // Handle remaining elements\n    for (int i = (n / 2) * 2; i < n; ++i) {\n        current_min = std::min(current_min + nums[i], nums[i]);\n        min_sum = std::min(min_sum, current_min);\n    }\n\n    return min_sum;\n}\n```"}
{"task_id": "SimdBench_118_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <limits>\n\nint64_t minSubArraySum_simd(const std::vector<int64_t>& nums) {\n    if (nums.empty()) return 0;\n\n    int64_t min_sum = std::numeric_limits<int64_t>::max();\n    int64_t current_min = 0;\n    int n = nums.size();\n\n    __m128i min_vec = _mm_set1_epi64(std::numeric_limits<int64_t>::max());\n    __m128i current_min_vec = _mm_setzero_si128();\n    __m128i zero_vec = _mm_setzero_si128();\n\n    for (int i = 0; i <= n - 2; i += 2) {\n        __m128i num_vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&nums[i]));\n        current_min_vec = _mm_add_epi64(current_min_vec, num_vec);\n        current_min_vec = _mm_min_epi64(current_min_vec, num_vec);\n        min_vec = _mm_min_epi64(min_vec, current_min_vec);\n    }\n\n    int64_t result[2];\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(result), min_vec);\n\n    min_sum = std::min(result[0], result[1]);\n\n    // Handle remaining elements\n    for (int i = (n / 2) * 2; i < n; ++i) {\n        current_min = std::min(current_min + nums[i], nums[i]);\n        min_sum = std::min(min_sum, current_min);\n    }\n\n    return min_sum;\n}\n```"}
{"task_id": "SimdBench_118_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <limits>\n\nint64_t minSubArraySum_simd(const std::vector<int64_t>& nums) {\n    if (nums.empty()) return 0;\n\n    int64_t min_sum = std::numeric_limits<int64_t>::max();\n    int64_t current_min = 0;\n    int n = nums.size();\n\n    __m128i min_vec = _mm_set1_epi64(std::numeric_limits<int64_t>::max());\n    __m128i current_min_vec = _mm_setzero_si128();\n\n    for (int i = 0; i <= n - 2; i += 2) {\n        __m128i num_vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&nums[i]));\n        current_min_vec = _mm_add_epi64(current_min_vec, num_vec);\n        current_min_vec = _mm_min_epi64(current_min_vec, num_vec);\n        min_vec = _mm_min_epi64(min_vec, current_min_vec);\n    }\n\n    int64_t result[2];\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(result), min_vec);\n\n    min_sum = std::min(result[0], result[1]);\n\n    // Handle remaining elements\n    for (int i = (n / 2) * 2; i < n; ++i) {\n        current_min = std::min(current_min + nums[i], nums[i]);\n        min_sum = std::min(min_sum, current_min);\n    }\n\n    return min_sum;\n}\n```"}
{"task_id": "SimdBench_119_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint max_fill_simd(const std::vector<std::vector<int> > & grid, int capacity) {\n    int total_drops = 0;\n    int num_rows = grid.size();\n    if (num_rows == 0) return 0;\n    int num_cols = grid[0].size();\n    int num_simd_elements = 4; // SSE processes 4 integers at a time\n    int num_simd_iterations = num_cols / num_simd_elements;\n    int remainder = num_cols % num_simd_elements;\n\n    for (int i = 0; i < num_rows; ++i) {\n        const int* row = grid[i].data();\n        __m128i sum = _mm_setzero_si128();\n\n        for (int j = 0; j < num_simd_iterations; ++j) {\n            __m128i data = _mm_loadu_si128(reinterpret_cast<const __m128i*>(row + j * num_simd_elements));\n            sum = _mm_add_epi32(sum, data);\n        }\n\n        int sum_array[4];\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(sum_array), sum);\n\n        int row_sum = 0;\n        for (int j = 0; j < num_simd_elements; ++j) {\n            row_sum += sum_array[j];\n        }\n\n        for (int j = num_simd_iterations * num_simd_elements; j < num_cols; ++j) {\n            row_sum += row[j];\n        }\n\n        total_drops += (row_sum + capacity - 1) / capacity; // Ceiling division\n    }\n\n    return total_drops;\n}\n```"}
{"task_id": "SimdBench_119_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint max_fill_simd(const std::vector<std::vector<int> > & grid, int capacity) {\n    int total_drops = 0;\n    int num_rows = grid.size();\n    if (num_rows == 0) return 0;\n    int num_cols = grid[0].size();\n    int num_simd_elements = 4; // SSE processes 4 integers at a time\n    int num_simd_iterations = num_cols / num_simd_elements;\n    int remainder = num_cols % num_simd_elements;\n\n    for (int i = 0; i < num_rows; ++i) {\n        const int* row = grid[i].data();\n        __m128i sum = _mm_setzero_si128();\n\n        for (int j = 0; j < num_simd_iterations; ++j) {\n            __m128i data = _mm_loadu_si128(reinterpret_cast<const __m128i*>(row + j * num_simd_elements));\n            sum = _mm_add_epi32(sum, data);\n        }\n\n        int sum_array[4];\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(sum_array), sum);\n\n        int row_sum = 0;\n        for (int j = 0; j < num_simd_elements; ++j) {\n            row_sum += sum_array[j];\n        }\n\n        for (int j = num_simd_iterations * num_simd_elements; j < num_cols; ++j) {\n            row_sum += row[j];\n        }\n\n        total_drops += (row_sum + capacity - 1) / capacity; // Ceiling division\n    }\n\n    return total_drops;\n}\n```"}
{"task_id": "SimdBench_119_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint max_fill_simd(const std::vector<std::vector<int> > & grid, int capacity) {\n    int total_drops = 0;\n    int num_rows = grid.size();\n    if (num_rows == 0) return 0;\n    int num_cols = grid[0].size();\n    int num_simd_elements = 4; // SSE processes 4 integers at a time\n    int num_simd_iterations = num_cols / num_simd_elements;\n    int remainder = num_cols % num_simd_elements;\n\n    for (int i = 0; i < num_rows; ++i) {\n        const int* row = grid[i].data();\n        __m128i sum = _mm_setzero_si128();\n\n        for (int j = 0; j < num_simd_iterations; ++j) {\n            __m128i data = _mm_loadu_si128(reinterpret_cast<const __m128i*>(row + j * num_simd_elements));\n            sum = _mm_add_epi32(sum, data);\n        }\n\n        int sum_array[4];\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(sum_array), sum);\n\n        int row_sum = 0;\n        for (int j = 0; j < num_simd_elements; ++j) {\n            row_sum += sum_array[j];\n        }\n\n        for (int j = num_simd_iterations * num_simd_elements; j < num_cols; ++j) {\n            row_sum += row[j];\n        }\n\n        total_drops += (row_sum + capacity - 1) / capacity; // Ceiling division\n    }\n\n    return total_drops;\n}\n```"}
{"task_id": "SimdBench_119_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint max_fill_simd(const std::vector<std::vector<int> > & grid, int capacity) {\n    int total_drops = 0;\n    int num_rows = grid.size();\n    if (num_rows == 0) return 0;\n    int num_cols = grid[0].size();\n    int num_simd_elements = 4; // SSE processes 4 integers at a time\n    int num_simd_iterations = num_cols / num_simd_elements;\n    int remainder = num_cols % num_simd_elements;\n\n    for (int i = 0; i < num_rows; ++i) {\n        const int* row = grid[i].data();\n        __m128i sum = _mm_setzero_si128();\n\n        for (int j = 0; j < num_simd_iterations; ++j) {\n            __m128i data = _mm_loadu_si128(reinterpret_cast<const __m128i*>(row + j * num_simd_elements));\n            sum = _mm_add_epi32(sum, data);\n        }\n\n        int sum_array[4];\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(sum_array), sum);\n\n        int row_sum = 0;\n        for (int j = 0; j < num_simd_elements; ++j) {\n            row_sum += sum_array[j];\n        }\n\n        for (int j = num_simd_iterations * num_simd_elements; j < num_cols; ++j) {\n            row_sum += row[j];\n        }\n\n        total_drops += (row_sum + capacity - 1) / capacity; // Ceiling division\n    }\n\n    return total_drops;\n}\n```"}
{"task_id": "SimdBench_119_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint max_fill_simd(const std::vector<std::vector<int> > & grid, int capacity) {\n    int total_drops = 0;\n    int num_rows = grid.size();\n    if (num_rows == 0) return 0;\n    int num_cols = grid[0].size();\n    int num_simd_iters = num_cols / 4; // Process 4 elements at a time with SSE\n    int remainder = num_cols % 4;\n\n    for (int i = 0; i < num_rows; ++i) {\n        const int* row = grid[i].data();\n        __m128i sum = _mm_setzero_si128();\n\n        for (int j = 0; j < num_simd_iters; ++j) {\n            __m128i data = _mm_loadu_si128(reinterpret_cast<const __m128i*>(row + j * 4));\n            sum = _mm_add_epi32(sum, data);\n        }\n\n        // Horizontal sum of 4 integers in sum\n        int horizontal_sum = _mm_extract_epi32(sum, 0) +\n                             _mm_extract_epi32(sum, 1) +\n                             _mm_extract_epi32(sum, 2) +\n                             _mm_extract_epi32(sum, 3);\n\n        // Add remaining elements\n        for (int j = num_simd_iters * 4; j < num_cols; ++j) {\n            horizontal_sum += row[j];\n        }\n\n        // Calculate the number of times we need to lower the bucket for this row\n        total_drops += (horizontal_sum + capacity - 1) / capacity;\n    }\n\n    return total_drops;\n}\n```"}
{"task_id": "SimdBench_120_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint64_t solution_simd(const std::vector<int16_t>& lst){\n    __m128i sum = _mm_setzero_si128();\n    int n = lst.size();\n    int i = 0;\n\n    for (; i <= n - 8; i += 8) {\n        __m128i data = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&lst[i]));\n        __m128i mask_even_positions = _mm_set_epi16(0, -1, 0, -1, 0, -1, 0, -1);\n        __m128i even_positions = _mm_and_si128(data, mask_even_positions);\n        __m128i mask_odds = _mm_set1_epi16(1);\n        __m128i odds = _mm_and_si128(even_positions, mask_odds);\n        sum = _mm_add_epi16(sum, odds);\n    }\n\n    int16_t result[8];\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(result), sum);\n\n    int64_t total_sum = 0;\n    for (int j = 0; j < 8; ++j) {\n        if (result[j] != 0) {\n            total_sum += result[j];\n        }\n    }\n\n    for (; i < n; ++i) {\n        if (i % 2 == 0 && lst[i] % 2 != 0) {\n            total_sum += lst[i];\n        }\n    }\n\n    return total_sum;\n}\n```"}
{"task_id": "SimdBench_120_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint64_t solution_simd(const std::vector<int16_t>& lst){\n    __m128i sum = _mm_setzero_si128();\n    int n = lst.size();\n    int i = 0;\n\n    for (; i <= n - 8; i += 8) {\n        __m128i data = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&lst[i]));\n        __m128i mask_even_positions = _mm_set_epi16(0, -1, 0, -1, 0, -1, 0, -1);\n        __m128i even_positions = _mm_and_si128(data, mask_even_positions);\n        __m128i mask_odds = _mm_set1_epi16(1);\n        __m128i odds = _mm_and_si128(even_positions, mask_odds);\n        sum = _mm_add_epi16(sum, odds);\n    }\n\n    int16_t result[8];\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(result), sum);\n\n    int64_t total_sum = 0;\n    for (int j = 0; j < 8; ++j) {\n        if (result[j] != 0) {\n            total_sum += result[j];\n        }\n    }\n\n    for (; i < n; ++i) {\n        if (i % 2 == 0 && lst[i] % 2 != 0) {\n            total_sum += lst[i];\n        }\n    }\n\n    return total_sum;\n}\n```"}
{"task_id": "SimdBench_120_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint64_t solution_simd(const std::vector<int16_t>& lst){\n    __m128i sum = _mm_setzero_si128();\n    int n = lst.size();\n    int i = 0;\n\n    for (; i <= n - 8; i += 8) {\n        __m128i data = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&lst[i]));\n        __m128i mask_even_positions = _mm_set_epi16(0, -1, 0, -1, 0, -1, 0, -1);\n        __m128i even_positions = _mm_and_si128(data, mask_even_positions);\n        __m128i mask_odds = _mm_set1_epi16(1);\n        __m128i odds = _mm_and_si128(even_positions, mask_odds);\n        sum = _mm_add_epi16(sum, odds);\n    }\n\n    int16_t result[8];\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(result), sum);\n\n    int64_t total_sum = 0;\n    for (int j = 0; j < 8; ++j) {\n        if (result[j] != 0) {\n            total_sum += result[j];\n        }\n    }\n\n    for (; i < n; ++i) {\n        if (i % 2 == 0 && lst[i] % 2 != 0) {\n            total_sum += lst[i];\n        }\n    }\n\n    return total_sum;\n}\n```"}
{"task_id": "SimdBench_120_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint64_t solution_simd(const std::vector<int16_t>& lst){\n    __m128i sum = _mm_setzero_si128();\n    int n = lst.size();\n    int i = 0;\n\n    for (; i <= n - 8; i += 8) {\n        __m128i data = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&lst[i]));\n        __m128i mask_even_positions = _mm_set_epi16(0, -1, 0, -1, 0, -1, 0, -1);\n        __m128i even_positions = _mm_and_si128(data, mask_even_positions);\n        __m128i mask_odds = _mm_set1_epi16(1);\n        __m128i odds = _mm_and_si128(even_positions, mask_odds);\n        sum = _mm_add_epi16(sum, odds);\n    }\n\n    int16_t result[8];\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(result), sum);\n\n    int64_t total_sum = 0;\n    for (int j = 0; j < 8; ++j) {\n        if (result[j] != 0) {\n            total_sum += result[j];\n        }\n    }\n\n    for (; i < n; ++i) {\n        if (i % 2 == 0 && lst[i] % 2 != 0) {\n            total_sum += lst[i];\n        }\n    }\n\n    return total_sum;\n}\n```"}
{"task_id": "SimdBench_120_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint64_t solution_simd(const std::vector<int16_t>& lst){\n    __m128i sum = _mm_setzero_si128();\n    int n = lst.size();\n    int i = 0;\n\n    for (; i <= n - 8; i += 8) {\n        __m128i data = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&lst[i]));\n        __m128i mask_even_positions = _mm_set_epi16(0, -1, 0, -1, 0, -1, 0, -1);\n        __m128i even_positions = _mm_and_si128(data, mask_even_positions);\n        __m128i mask_odds = _mm_set1_epi16(1);\n        __m128i odds = _mm_and_si128(even_positions, mask_odds);\n        sum = _mm_add_epi16(sum, odds);\n    }\n\n    int16_t result[8];\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(result), sum);\n\n    int64_t total_sum = 0;\n    for (int j = 0; j < 8; ++j) {\n        if (result[j] != 0) {\n            total_sum += result[j];\n        }\n    }\n\n    for (; i < n; ++i) {\n        if (i % 2 == 0 && lst[i] % 2 != 0) {\n            total_sum += lst[i];\n        }\n    }\n\n    return total_sum;\n}\n```"}
{"task_id": "SimdBench_121_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint add_elements_simd(std::vector<int> arr, int k) {\n    __m128i sum = _mm_setzero_si128();\n    __m128i mask = _mm_set1_epi32(99);\n    int i = 0;\n\n    for (; i <= k - 4; i += 4) {\n        __m128i values = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&arr[i]));\n        __m128i filtered = _mm_cmple_epi32(values, mask);\n        filtered = _mm_and_si128(filtered, values);\n        sum = _mm_add_epi32(sum, filtered);\n    }\n\n    int result[4];\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(result), sum);\n\n    int total_sum = result[0] + result[1] + result[2] + result[3];\n\n    for (; i < k; ++i) {\n        if (arr[i] <= 99) {\n            total_sum += arr[i];\n        }\n    }\n\n    return total_sum;\n}\n```"}
{"task_id": "SimdBench_121_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint add_elements_simd(std::vector<int> arr, int k) {\n    __m128i sum = _mm_setzero_si128();\n    int i = 0;\n\n    // Process 4 elements at a time\n    for (; i <= k - 4; i += 4) {\n        __m128i elements = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&arr[i]));\n        __m128i mask = _mm_cmpgt_epi16(elements, _mm_set1_epi16(99));\n        elements = _mm_andnot_si128(mask, elements);\n        sum = _mm_add_epi32(sum, elements);\n    }\n\n    // Horizontal sum of the 4 elements in sum\n    sum = _mm_add_epi32(sum, _mm_srli_si128(sum, 8));\n    sum = _mm_add_epi32(sum, _mm_srli_si128(sum, 4));\n    int result = _mm_cvtsi128_si32(sum);\n\n    // Add remaining elements\n    for (; i < k; ++i) {\n        if (arr[i] <= 99) {\n            result += arr[i];\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_121_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint add_elements_simd(std::vector<int> arr, int k) {\n    __m128i sum = _mm_setzero_si128();\n    int i = 0;\n\n    // Process 4 elements at a time\n    for (; i <= k - 4; i += 4) {\n        __m128i elements = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&arr[i]));\n        __m128i mask = _mm_cmpgt_epi16(elements, _mm_set1_epi16(99));\n        elements = _mm_andnot_si128(mask, elements);\n        sum = _mm_add_epi32(sum, elements);\n    }\n\n    // Horizontal sum of the 4 elements in sum\n    sum = _mm_add_epi32(sum, _mm_srli_si128(sum, 8));\n    sum = _mm_add_epi32(sum, _mm_srli_si128(sum, 4));\n\n    int result = _mm_cvtsi128_si32(sum);\n\n    // Add remaining elements\n    for (; i < k; ++i) {\n        if (arr[i] <= 99) {\n            result += arr[i];\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_121_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint add_elements_simd(std::vector<int> arr, int k) {\n    __m128i sum = _mm_setzero_si128();\n    __m128i threshold = _mm_set1_epi32(100);\n\n    int i = 0;\n    for (; i <= k - 4; i += 4) {\n        __m128i values = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&arr[i]));\n        __m128i mask = _mm_cmplt_epi32(values, threshold);\n        __m128i filtered_values = _mm_and_si128(values, mask);\n        sum = _mm_add_epi32(sum, filtered_values);\n    }\n\n    int result[4];\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(result), sum);\n\n    int total_sum = result[0] + result[1] + result[2] + result[3];\n\n    for (; i < k; ++i) {\n        if (arr[i] < 100) {\n            total_sum += arr[i];\n        }\n    }\n\n    return total_sum;\n}\n```"}
{"task_id": "SimdBench_121_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint add_elements_simd(std::vector<int> arr, int k) {\n    __m128i sum = _mm_setzero_si128();\n    int i = 0;\n\n    // Process 4 elements at a time\n    for (; i <= k - 4; i += 4) {\n        __m128i elements = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&arr[i]));\n        __m128i mask = _mm_cmplt_epi32(elements, _mm_set1_epi32(100));\n        elements = _mm_and_si128(elements, mask);\n        sum = _mm_add_epi32(sum, elements);\n    }\n\n    // Horizontally add the four elements in sum\n    __m128i hsum1 = _mm_hadd_epi32(sum, sum);\n    __m128i hsum2 = _mm_hadd_epi32(hsum1, hsum1);\n    int result = _mm_cvtsi128_si32(hsum2);\n\n    // Add remaining elements\n    for (; i < k; ++i) {\n        if (arr[i] < 100) {\n            result += arr[i];\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_122_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nbool is_sorted_simd(const std::vector<int> & lst){\n    if (lst.size() <= 1) return true;\n\n    __m128i prev = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&lst[0]));\n    __m128i ones = _mm_set1_epi32(1);\n    int i = 4;\n\n    while (i + 4 <= lst.size()) {\n        __m128i curr = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&lst[i]));\n        __m128i diff = _mm_sub_epi32(curr, prev);\n        __m128i mask = _mm_cmpeq_epi32(diff, _mm_setzero_si128());\n        __m128i mask2 = _mm_cmpgt_epi32(prev, curr);\n\n        if (_mm_movemask_epi8(mask) != 0 || _mm_movemask_epi8(mask2) != 0) {\n            return false;\n        }\n\n        prev = curr;\n        i += 4;\n    }\n\n    while (i < lst.size()) {\n        if (lst[i] <= lst[i - 1]) {\n            return false;\n        }\n        i++;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_122_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nbool is_sorted_simd(const std::vector<int> & lst){\n    if (lst.size() <= 1) return true;\n\n    __m128i prev = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&lst[0]));\n    __m128i ones = _mm_set1_epi32(1);\n    __m128i mask = _mm_setzero_si128();\n    __m128i dup_mask = _mm_setzero_si128();\n\n    for (size_t i = 1; i + 3 < lst.size(); i += 4) {\n        __m128i curr = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&lst[i]));\n        __m128i shifted_prev = _mm_srli_si128(prev, 4);\n        __m128i shifted_curr = _mm_slli_si128(curr, 4);\n\n        mask = _mm_or_si128(mask, _mm_cmpgt_epi32(shifted_prev, curr));\n        dup_mask = _mm_or_si128(dup_mask, _mm_cmpeq_epi32(prev, curr));\n\n        prev = curr;\n    }\n\n    int mask_result = _mm_movemask_epi8(mask);\n    int dup_mask_result = _mm_movemask_epi8(dup_mask);\n\n    if (mask_result != 0 || dup_mask_result != 0) return false;\n\n    for (size_t i = lst.size() - (lst.size() % 4); i < lst.size() - 1; ++i) {\n        if (lst[i] > lst[i + 1] || (i > 0 && lst[i] == lst[i - 1])) return false;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_122_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nbool is_sorted_simd(const std::vector<int> & lst){\n    if (lst.size() <= 1) return true;\n\n    __m128i prev = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&lst[0]));\n    __m128i ones = _mm_set1_epi32(1);\n    __m128i mask = _mm_setzero_si128();\n    __m128i dup_mask = _mm_setzero_si128();\n\n    for (size_t i = 1; i + 3 < lst.size(); i += 4) {\n        __m128i curr = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&lst[i]));\n        __m128i shifted_curr = _mm_srli_si128(curr, 4);\n\n        // Check if current is less than or equal to previous\n        mask = _mm_or_si128(mask, _mm_cmple_epi32(curr, prev));\n\n        // Check for duplicates\n        dup_mask = _mm_or_si128(dup_mask, _mm_cmpeq_epi32(curr, shifted_curr));\n\n        prev = curr;\n    }\n\n    // Handle remaining elements\n    for (size_t i = (lst.size() / 4) * 4; i < lst.size() - 1; ++i) {\n        if (lst[i] > lst[i + 1]) return false;\n        if (i > 0 && lst[i] == lst[i - 1]) return false;\n    }\n\n    // Check if there were any unordered elements or duplicates\n    int mask_result = _mm_movemask_epi8(mask);\n    int dup_mask_result = _mm_movemask_epi8(dup_mask);\n\n    return mask_result == 0 && dup_mask_result == 0;\n}\n```"}
{"task_id": "SimdBench_122_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nbool is_sorted_simd(const std::vector<int> & lst){\n    if (lst.size() <= 1) return true;\n\n    __m128i prev = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&lst[0]));\n    __m128i ones = _mm_set1_epi32(1);\n    int i = 4;\n\n    while (i + 4 <= lst.size()) {\n        __m128i curr = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&lst[i]));\n        __m128i diff = _mm_sub_epi32(curr, prev);\n        __m128i mask = _mm_cmpeq_epi32(diff, _mm_setzero_si128());\n        if (!_mm_test_all_zeros(mask, mask)) return false;\n        mask = _mm_cmplt_epi32(diff, ones);\n        if (!_mm_test_all_zeros(mask, mask)) return false;\n        prev = curr;\n        i += 4;\n    }\n\n    while (i < lst.size()) {\n        if (lst[i] <= lst[i - 1]) return false;\n        ++i;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_122_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nbool is_sorted_simd(const std::vector<int> & lst){\n    if (lst.size() <= 1) return true;\n\n    __m128i prev = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&lst[0]));\n    __m128i ones = _mm_set1_epi32(1);\n    int i = 4;\n\n    while (i + 4 <= lst.size()) {\n        __m128i curr = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&lst[i]));\n        __m128i diff = _mm_sub_epi32(curr, prev);\n        __m128i mask1 = _mm_cmplt_epi32(diff, ones);\n        __m128i mask2 = _mm_cmpeq_epi32(diff, _mm_setzero_si128());\n\n        if (_mm_movemask_epi8(mask1) != 0 || _mm_movemask_epi8(mask2) != 0) {\n            return false;\n        }\n\n        prev = curr;\n        i += 4;\n    }\n\n    for (; i < lst.size(); ++i) {\n        if (lst[i] <= lst[i - 1]) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_123_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint prod_signs_simd(const std::vector<int> & arr){\n    if (arr.empty()) return -32768;\n\n    __m128i sum_magnitudes = _mm_setzero_si128();\n    __m128i prod_signs = _mm_set1_epi32(1);\n\n    int n = arr.size();\n    int i = 0;\n\n    for (; i <= n - 4; i += 4) {\n        __m128i vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&arr[i]));\n\n        // Calculate magnitudes\n        __m128i abs_vec = _mm_abs_epi32(vec);\n        sum_magnitudes = _mm_add_epi32(sum_magnitudes, abs_vec);\n\n        // Calculate product of signs\n        __m128i sign_mask = _mm_cmpgt_epi32(_mm_setzero_si128(), vec);\n        __m128i sign_vec = _mm_sub_epi32(_mm_xor_si128(sign_mask, _mm_set1_epi32(1)), sign_mask);\n        sign_vec = _mm_andnot_si128(_mm_cmpeq_epi32(vec, _mm_setzero_si128()), sign_vec);\n        prod_signs = _mm_mullo_epi32(prod_signs, sign_vec);\n    }\n\n    // Horizontal sum of magnitudes\n    int sum_arr[4];\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(sum_arr), sum_magnitudes);\n    int sum = sum_arr[0] + sum_arr[1] + sum_arr[2] + sum_arr[3];\n\n    // Horizontal product of signs\n    __m128i prod_lo = _mm_mullo_epi32(prod_signs, _mm_shuffle_epi32(prod_signs, _MM_SHUFFLE(1, 0, 3, 2)));\n    __m128i prod_hi = _mm_mullo_epi32(_mm_shuffle_epi32(prod_signs, _MM_SHUFFLE(3, 2, 1, 0)), _mm_shuffle_epi32(prod_signs, _MM_SHUFFLE(2, 3, 0, 1)));\n    __m128i prod = _mm_mullo_epi32(prod_lo, prod_hi);\n    int product_of_signs = _mm_cvtsi128_si32(prod);\n\n    // Handle remaining elements\n    for (; i < n; ++i) {\n        int val = arr[i];\n        sum += std::abs(val);\n        if (val == 0) {\n            product_of_signs = 0;\n        } else if (val < 0) {\n            product_of_signs *= -1;\n        }\n    }\n\n    return sum * product_of_signs;\n}\n```"}
{"task_id": "SimdBench_123_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint prod_signs_simd(const std::vector<int> & arr){\n    if (arr.empty()) return -32768;\n\n    __m128i sum_magnitudes = _mm_setzero_si128();\n    __m128i prod_signs = _mm_set1_epi32(1);\n\n    int n = arr.size();\n    int i = 0;\n\n    for (; i <= n - 4; i += 4) {\n        __m128i vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&arr[i]));\n\n        // Calculate magnitudes\n        __m128i abs_vec = _mm_abs_epi32(vec);\n        sum_magnitudes = _mm_add_epi32(sum_magnitudes, abs_vec);\n\n        // Calculate product of signs\n        __m128i sign_mask = _mm_cmpgt_epi32(_mm_setzero_si128(), vec);\n        __m128i sign_vec = _mm_sub_epi32(_mm_andnot_si128(sign_mask, _mm_set1_epi32(1)), _mm_and_si128(sign_mask, _mm_set1_epi32(1)));\n        sign_vec = _mm_or_si128(sign_vec, _mm_cmpeq_epi32(vec, _mm_setzero_si128()));\n        prod_signs = _mm_mullo_epi32(prod_signs, sign_vec);\n    }\n\n    // Horizontal sum of magnitudes\n    int sum_arr[4];\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(sum_arr), sum_magnitudes);\n    int sum = sum_arr[0] + sum_arr[1] + sum_arr[2] + sum_arr[3];\n\n    // Horizontal product of signs\n    __m128i prod_lo = _mm_mullo_epi32(prod_signs, _mm_shuffle_epi32(prod_signs, _MM_SHUFFLE(1, 0, 3, 2)));\n    __m128i prod_hi = _mm_mullo_epi32(_mm_shuffle_epi32(prod_signs, _MM_SHUFFLE(3, 2, 1, 0)), prod_lo);\n    int prod = _mm_cvtsi128_si32(prod_hi);\n\n    for (; i < n; ++i) {\n        int val = arr[i];\n        sum += std::abs(val);\n        if (val == 0) prod = 0;\n        else if (val < 0) prod *= -1;\n    }\n\n    return sum * prod;\n}\n```"}
{"task_id": "SimdBench_123_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint prod_signs_simd(const std::vector<int> & arr){\n    if (arr.empty()) return -32768;\n\n    __m128i sum_magnitudes = _mm_setzero_si128();\n    __m128i prod_signs = _mm_set1_epi32(1);\n\n    int n = arr.size();\n    int i = 0;\n\n    for (; i <= n - 4; i += 4) {\n        __m128i vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&arr[i]));\n\n        // Calculate magnitudes\n        __m128i abs_vec = _mm_abs_epi32(vec);\n        sum_magnitudes = _mm_add_epi32(sum_magnitudes, abs_vec);\n\n        // Calculate signs\n        __m128i sign_mask = _mm_cmpgt_epi32(_mm_setzero_si128(), vec);\n        __m128i signs = _mm_sub_epi32(_mm_andnot_si128(sign_mask, _mm_set1_epi32(1)), sign_mask);\n        prod_signs = _mm_mullo_epi32(prod_signs, signs);\n    }\n\n    // Horizontal sum of magnitudes\n    int sum_arr[4];\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(sum_arr), sum_magnitudes);\n    int sum = sum_arr[0] + sum_arr[1] + sum_arr[2] + sum_arr[3];\n\n    // Horizontal product of signs\n    __m128i prod_lo = _mm_mullo_epi32(prod_signs, _mm_shuffle_epi32(prod_signs, _MM_SHUFFLE(1, 0, 3, 2)));\n    __m128i prod_hi = _mm_mullo_epi32(_mm_shuffle_epi32(prod_signs, _MM_SHUFFLE(3, 2, 1, 0)), prod_lo);\n    int prod = _mm_cvtsi128_si32(prod_hi);\n\n    // Process remaining elements\n    for (; i < n; ++i) {\n        int val = arr[i];\n        sum += std::abs(val);\n        prod *= (val > 0) - (val < 0);\n    }\n\n    return sum * prod;\n}\n```"}
{"task_id": "SimdBench_123_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint prod_signs_simd(const std::vector<int> & arr){\n    if (arr.empty()) return -32768;\n\n    __m128i sum_magnitudes = _mm_setzero_si128();\n    __m128i prod_signs = _mm_set1_epi32(1);\n\n    int n = arr.size();\n    int i = 0;\n\n    for (; i <= n - 4; i += 4) {\n        __m128i vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&arr[i]));\n\n        // Calculate magnitudes\n        __m128i abs_vec = _mm_abs_epi32(vec);\n        sum_magnitudes = _mm_add_epi32(sum_magnitudes, abs_vec);\n\n        // Calculate product of signs\n        __m128i sign_mask = _mm_cmpgt_epi32(_mm_setzero_si128(), vec);\n        __m128i sign_vec = _mm_sub_epi32(_mm_andnot_si128(sign_mask, _mm_set1_epi32(1)), _mm_and_si128(sign_mask, _mm_set1_epi32(1)));\n        sign_vec = _mm_or_si128(sign_vec, _mm_cmpeq_epi32(vec, _mm_setzero_si128()));\n        prod_signs = _mm_mullo_epi32(prod_signs, sign_vec);\n    }\n\n    // Horizontal sum of magnitudes\n    int sum_arr[4];\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(sum_arr), sum_magnitudes);\n    int sum = sum_arr[0] + sum_arr[1] + sum_arr[2] + sum_arr[3];\n\n    // Horizontal product of signs\n    __m128i prod_lo = _mm_mullo_epi32(prod_signs, _mm_shuffle_epi32(prod_signs, _MM_SHUFFLE(1, 0, 3, 2)));\n    __m128i prod_hi = _mm_mullo_epi32(_mm_shuffle_epi32(prod_signs, _MM_SHUFFLE(3, 2, 1, 0)), prod_lo);\n    int prod = _mm_cvtsi128_si32(prod_hi);\n\n    for (; i < n; ++i) {\n        int val = arr[i];\n        sum += std::abs(val);\n        if (val == 0) prod = 0;\n        else if (val < 0) prod *= -1;\n    }\n\n    return sum * prod;\n}\n```"}
{"task_id": "SimdBench_123_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint prod_signs_simd(const std::vector<int> & arr){\n    if (arr.empty()) return -32768;\n\n    __m128i sum_magnitudes = _mm_setzero_si128();\n    __m128i prod_signs = _mm_set1_epi32(1);\n\n    int n = arr.size();\n    int i = 0;\n\n    for (; i <= n - 4; i += 4) {\n        __m128i vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&arr[i]));\n\n        // Calculate magnitudes\n        __m128i abs_vec = _mm_abs_epi32(vec);\n        sum_magnitudes = _mm_add_epi32(sum_magnitudes, abs_vec);\n\n        // Calculate signs\n        __m128i sign_mask = _mm_cmpgt_epi32(_mm_setzero_si128(), vec);\n        __m128i signs = _mm_sub_epi32(_mm_andnot_si128(sign_mask, _mm_set1_epi32(1)), sign_mask);\n        prod_signs = _mm_mullo_epi32(prod_signs, signs);\n    }\n\n    // Horizontal sum of magnitudes\n    int sum_arr[4];\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(sum_arr), sum_magnitudes);\n    int sum = sum_arr[0] + sum_arr[1] + sum_arr[2] + sum_arr[3];\n\n    // Horizontal product of signs\n    __m128i prod_lo = _mm_mullo_epi32(prod_signs, _mm_shuffle_epi32(prod_signs, _MM_SHUFFLE(1, 0, 3, 2)));\n    __m128i prod_hi = _mm_mullo_epi32(_mm_shuffle_epi32(prod_signs, _MM_SHUFFLE(3, 2, 1, 0)), prod_lo);\n    int prod = _mm_cvtsi128_si32(prod_hi);\n\n    // Process remaining elements\n    for (; i < n; ++i) {\n        int val = arr[i];\n        sum += std::abs(val);\n        prod *= (val > 0) - (val < 0);\n    }\n\n    return sum * prod;\n}\n```"}
{"task_id": "SimdBench_124_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n#include <climits>\n\nstd::vector<int> minPath_simd(const std::vector<std::vector<int> > & grid, int k) {\n    int N = grid.size();\n    std::vector<int> result(k, INT_MAX);\n    std::vector<int> path(k);\n    \n    auto comparePaths = [&](const std::vector<int>& path) {\n        __m128i minPathVec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(result.data()));\n        __m128i pathVec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(path.data()));\n        \n        __m128i cmp = _mm_cmplt_epi32(pathVec, minPathVec);\n        int mask = _mm_movemask_epi8(cmp);\n        \n        if (mask != 0) {\n            for (int i = 0; i < k; ++i) {\n                if (path[i] < result[i]) {\n                    result = path;\n                    break;\n                }\n            }\n        }\n    };\n\n    std::function<void(int, int, int)> dfs = [&](int x, int y, int depth) {\n        if (depth == k) {\n            comparePaths(path);\n            return;\n        }\n        \n        static const int dx[] = {0, 0, -1, 1};\n        static const int dy[] = {-1, 1, 0, 0};\n        \n        path[depth] = grid[x][y];\n        \n        for (int dir = 0; dir < 4; ++dir) {\n            int nx = x + dx[dir];\n            int ny = y + dy[dir];\n            \n            if (nx >= 0 && nx < N && ny >= 0 && ny < N) {\n                dfs(nx, ny, depth + 1);\n            }\n        }\n    };\n    \n    for (int i = 0; i < N; ++i) {\n        for (int j = 0; j < N; ++j) {\n            dfs(i, j, 0);\n        }\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_124_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n#include <climits>\n\nstd::vector<int> minPath_simd(const std::vector<std::vector<int> > & grid, int k) {\n    int N = grid.size();\n    std::vector<int> result(k, INT_MAX);\n    std::vector<int> path(k);\n    \n    auto comparePaths = [&](const std::vector<int>& path) {\n        __m128i minPathVec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(result.data()));\n        __m128i pathVec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(path.data()));\n        \n        __m128i cmp = _mm_cmplt_epi32(pathVec, minPathVec);\n        int mask = _mm_movemask_epi8(cmp);\n        \n        if (mask != 0) {\n            for (int i = 0; i < k; ++i) {\n                if (path[i] < result[i]) {\n                    result = path;\n                    break;\n                }\n            }\n        }\n    };\n\n    std::function<void(int, int, int)> dfs = [&](int x, int y, int depth) {\n        if (depth == k) {\n            comparePaths(path);\n            return;\n        }\n        \n        static const int dx[] = {-1, 1, 0, 0};\n        static const int dy[] = {0, 0, -1, 1};\n        \n        path[depth] = grid[x][y];\n        \n        for (int dir = 0; dir < 4; ++dir) {\n            int nx = x + dx[dir];\n            int ny = y + dy[dir];\n            \n            if (nx >= 0 && nx < N && ny >= 0 && ny < N) {\n                dfs(nx, ny, depth + 1);\n            }\n        }\n    };\n    \n    for (int i = 0; i < N; ++i) {\n        for (int j = 0; j < N; ++j) {\n            dfs(i, j, 0);\n        }\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_124_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n#include <climits>\n\nstd::vector<int> minPath_simd(const std::vector<std::vector<int> > & grid, int k) {\n    int N = grid.size();\n    std::vector<int> result(k, INT_MAX);\n    std::vector<int> path(k);\n    \n    auto comparePaths = [&](const std::vector<int>& path) {\n        __m128i minPathVec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(result.data()));\n        __m128i pathVec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(path.data()));\n        \n        __m128i cmp = _mm_cmplt_epi32(pathVec, minPathVec);\n        int mask = _mm_movemask_epi8(cmp);\n        \n        if (mask != 0) {\n            for (int i = 0; i < k; ++i) {\n                if (path[i] < result[i]) {\n                    result = path;\n                    break;\n                }\n            }\n        }\n    };\n\n    std::function<void(int, int, int)> dfs = [&](int x, int y, int depth) {\n        if (depth == k) {\n            comparePaths(path);\n            return;\n        }\n        \n        static const int dx[] = {-1, 1, 0, 0};\n        static const int dy[] = {0, 0, -1, 1};\n        \n        path[depth] = grid[x][y];\n        \n        for (int dir = 0; dir < 4; ++dir) {\n            int nx = x + dx[dir];\n            int ny = y + dy[dir];\n            \n            if (nx >= 0 && nx < N && ny >= 0 && ny < N) {\n                dfs(nx, ny, depth + 1);\n            }\n        }\n    };\n    \n    for (int i = 0; i < N; ++i) {\n        for (int j = 0; j < N; ++j) {\n            dfs(i, j, 0);\n        }\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_124_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n#include <climits>\n\nstd::vector<int> minPath_simd(const std::vector<std::vector<int> > & grid, int k) {\n    int N = grid.size();\n    std::vector<int> result(k, INT_MAX);\n    std::vector<int> current_path(k);\n    std::vector<int> min_path(k);\n\n    auto compare_paths = [&](const std::vector<int>& path1, const std::vector<int>& path2) {\n        __m128i v1 = _mm_loadu_si128(reinterpret_cast<const __m128i*>(path1.data()));\n        __m128i v2 = _mm_loadu_si128(reinterpret_cast<const __m128i*>(path2.data()));\n        __m128i cmp = _mm_cmplt_epi32(v1, v2);\n        int mask = _mm_movemask_epi8(cmp);\n        return mask != 0;\n    };\n\n    std::function<void(int, int, int)> dfs = [&](int x, int y, int depth) {\n        if (depth == k) {\n            if (compare_paths(current_path, result)) {\n                result = current_path;\n            }\n            return;\n        }\n\n        static const int dx[] = {0, 0, 1, -1};\n        static const int dy[] = {1, -1, 0, 0};\n\n        current_path[depth] = grid[x][y];\n        for (int dir = 0; dir < 4; ++dir) {\n            int nx = x + dx[dir];\n            int ny = y + dy[dir];\n            if (nx >= 0 && nx < N && ny >= 0 && ny < N) {\n                dfs(nx, ny, depth + 1);\n            }\n        }\n    };\n\n    for (int i = 0; i < N; ++i) {\n        for (int j = 0; j < N; ++j) {\n            dfs(i, j, 0);\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_124_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n#include <climits>\n\nstd::vector<int> minPath_simd(const std::vector<std::vector<int> > & grid, int k) {\n    int N = grid.size();\n    std::vector<int> result(k, INT_MAX);\n    std::vector<int> current_path(k);\n    std::vector<int> min_path(k);\n\n    auto compare_paths = [&](const std::vector<int>& path1, const std::vector<int>& path2) {\n        __m128i v1 = _mm_loadu_si128(reinterpret_cast<const __m128i*>(path1.data()));\n        __m128i v2 = _mm_loadu_si128(reinterpret_cast<const __m128i*>(path2.data()));\n        __m128i cmp = _mm_cmplt_epi32(v1, v2);\n        int mask = _mm_movemask_epi8(cmp);\n        return mask != 0;\n    };\n\n    std::function<void(int, int, int)> dfs = [&](int x, int y, int depth) {\n        if (depth == k) {\n            if (compare_paths(current_path, result)) {\n                result = current_path;\n            }\n            return;\n        }\n\n        static const int dx[] = {0, 0, 1, -1};\n        static const int dy[] = {1, -1, 0, 0};\n\n        current_path[depth] = grid[x][y];\n        for (int dir = 0; dir < 4; ++dir) {\n            int nx = x + dx[dir];\n            int ny = y + dy[dir];\n            if (nx >= 0 && nx < N && ny >= 0 && ny < N) {\n                dfs(nx, ny, depth + 1);\n            }\n        }\n    };\n\n    for (int i = 0; i < N; ++i) {\n        for (int j = 0; j < N; ++j) {\n            dfs(i, j, 0);\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_125_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nuint64_t digits_simd(uint64_t n) {\n    __m128i ones = _mm_set1_epi8(1);\n    __m128i fives = _mm_set1_epi8(5);\n    __m128i result = _mm_set1_epi8(1);\n    __m128i zero = _mm_setzero_si128();\n    __m128i has_odd = zero;\n\n    while (n > 0) {\n        __m128i digits = _mm_cvtsi64_si128(n);\n        digits = _mm_or_si128(digits, _mm_slli_epi64(digits, 8));\n        digits = _mm_or_si128(digits, _mm_slli_epi64(digits, 16));\n        digits = _mm_or_si128(digits, _mm_slli_epi64(digits, 24));\n        digits = _mm_or_si128(digits, _mm_slli_epi64(digits, 32));\n        digits = _mm_or_si128(digits, _mm_slli_epi64(digits, 40));\n        digits = _mm_or_si128(digits, _mm_slli_epi64(digits, 48));\n        digits = _mm_or_si128(digits, _mm_slli_epi64(digits, 56));\n\n        __m128i is_odd = _mm_and_si128(digits, ones);\n        has_odd = _mm_or_si128(has_odd, is_odd);\n\n        __m128i odd_digits = _mm_and_si128(digits, is_odd);\n        __m128i odd_mask = _mm_cmpeq_epi8(odd_digits, zero);\n        odd_digits = _mm_or_si128(odd_digits, ones);\n        odd_digits = _mm_andnot_si128(odd_mask, odd_digits);\n\n        result = _mm_mullo_epi16(result, odd_digits);\n\n        n /= 100000000;\n    }\n\n    __m128i final_result = _mm_mullo_epi16(_mm_mullo_epi16(_mm_mullo_epi16(_mm_extract_epi16(result, 0), _mm_extract_epi16(result, 1)), _mm_extract_epi16(result, 2)), _mm_extract_epi16(result, 3));\n    final_result = _mm_mullo_epi16(final_result, _mm_extract_epi16(result, 4));\n\n    uint16_t product = _mm_extract_epi16(final_result, 0);\n\n    return _mm_testz_si128(has_odd, has_odd) ? 0 : product;\n}\n```"}
{"task_id": "SimdBench_125_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nuint64_t digits_simd(uint64_t n) {\n    __m128i ones = _mm_set1_epi8(1);\n    __m128i fives = _mm_set1_epi8(5);\n    __m128i result = _mm_set1_epi8(1);\n    __m128i has_odd = _mm_setzero_si128();\n\n    while (n > 0) {\n        __m128i digits = _mm_cvtsi64_si128(n);\n        digits = _mm_or_si128(digits, _mm_slli_epi64(digits, 8));\n        digits = _mm_or_si128(digits, _mm_slli_epi64(digits, 16));\n        digits = _mm_or_si128(digits, _mm_slli_epi64(digits, 24));\n        digits = _mm_or_si128(digits, _mm_slli_epi64(digits, 32));\n        digits = _mm_or_si128(digits, _mm_slli_epi64(digits, 40));\n        digits = _mm_or_si128(digits, _mm_slli_epi64(digits, 48));\n        digits = _mm_or_si128(digits, _mm_slli_epi64(digits, 56));\n\n        __m128i is_odd = _mm_and_si128(digits, ones);\n        __m128i odd_digits = _mm_and_si128(digits, is_odd);\n        __m128i odd_mask = _mm_cmpgt_epi8(odd_digits, _mm_setzero_si128());\n\n        result = _mm_mullo_epi8(result, odd_digits);\n        has_odd = _mm_or_si128(has_odd, odd_mask);\n\n        n /= 100000000;\n    }\n\n    __m128i sum = _mm_mullo_epi8(result, fives);\n    sum = _mm_hadd_epi16(sum, sum);\n    sum = _mm_hadd_epi16(sum, sum);\n    sum = _mm_hadd_epi16(sum, sum);\n\n    uint16_t final_result = _mm_extract_epi16(sum, 0);\n    return _mm_testz_si128(has_odd, has_odd) ? 0 : final_result;\n}\n```"}
{"task_id": "SimdBench_125_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nuint64_t digits_simd(uint64_t n) {\n    __m128i ones = _mm_set1_epi8(1);\n    __m128i fives = _mm_set1_epi8(5);\n    __m128i result = _mm_set1_epi8(1);\n    __m128i zero = _mm_setzero_si128();\n    __m128i has_odd = zero;\n\n    while (n > 0) {\n        __m128i digits = _mm_cvtsi64_si128(n);\n        digits = _mm_or_si128(digits, _mm_slli_epi64(digits, 8));\n        digits = _mm_or_si128(digits, _mm_slli_epi64(digits, 16));\n        digits = _mm_or_si128(digits, _mm_slli_epi64(digits, 24));\n        digits = _mm_or_si128(digits, _mm_slli_epi64(digits, 32));\n        digits = _mm_or_si128(digits, _mm_slli_epi64(digits, 40));\n        digits = _mm_or_si128(digits, _mm_slli_epi64(digits, 48));\n        digits = _mm_or_si128(digits, _mm_slli_epi64(digits, 56));\n\n        __m128i is_odd = _mm_and_si128(digits, ones);\n        has_odd = _mm_or_si128(has_odd, is_odd);\n\n        __m128i odd_digits = _mm_and_si128(digits, is_odd);\n        __m128i odd_minus_one = _mm_sub_epi8(odd_digits, ones);\n        __m128i odd_plus_one = _mm_add_epi8(odd_digits, ones);\n        __m128i odd_times_five = _mm_mullo_epi8(odd_digits, fives);\n        __m128i odd_product = _mm_add_epi8(_mm_mullo_epi8(odd_minus_one, odd_plus_one), odd_times_five);\n\n        result = _mm_mullo_epi8(result, odd_product);\n\n        n /= 100000000;\n    }\n\n    __m128i all_ones = _mm_cmpeq_epi8(result, ones);\n    __m128i no_odd = _mm_cmpeq_epi8(has_odd, zero);\n    __m128i mask = _mm_or_si128(all_ones, no_odd);\n    result = _mm_andnot_si128(mask, result);\n\n    return _mm_extract_epi8(result, 0);\n}\n```"}
{"task_id": "SimdBench_125_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nuint64_t digits_simd(uint64_t n) {\n    __m128i ones = _mm_set1_epi8(1);\n    __m128i fives = _mm_set1_epi8(5);\n    __m128i result = _mm_set1_epi8(1);\n    __m128i zero = _mm_setzero_si128();\n    __m128i has_odd = zero;\n\n    while (n > 0) {\n        __m128i digits = _mm_cvtsi64_si128(n);\n        digits = _mm_or_si128(digits, _mm_slli_epi64(digits, 8));\n        digits = _mm_or_si128(digits, _mm_slli_epi64(digits, 16));\n        digits = _mm_or_si128(digits, _mm_slli_epi64(digits, 24));\n        digits = _mm_or_si128(digits, _mm_slli_epi64(digits, 32));\n        digits = _mm_or_si128(digits, _mm_slli_epi64(digits, 40));\n        digits = _mm_or_si128(digits, _mm_slli_epi64(digits, 48));\n        digits = _mm_or_si128(digits, _mm_slli_epi64(digits, 56));\n\n        __m128i is_odd = _mm_and_si128(digits, ones);\n        has_odd = _mm_or_si128(has_odd, is_odd);\n\n        __m128i odd_digits = _mm_and_si128(digits, is_odd);\n        result = _mm_mullo_epi8(result, odd_digits);\n\n        n /= 100000000;\n    }\n\n    __m128i all_ones = _mm_cmpeq_epi8(result, ones);\n    __m128i no_odds = _mm_cmpeq_epi8(has_odd, zero);\n    __m128i final_result = _mm_andnot_si128(no_odds, result);\n    final_result = _mm_and_si128(final_result, all_ones);\n\n    uint16_t res = _mm_extract_epi16(_mm_sad_epu8(final_result, zero), 0);\n    return res == 16 ? 0 : res;\n}\n```"}
{"task_id": "SimdBench_125_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nuint64_t digits_simd(uint64_t n) {\n    __m128i odd_product = _mm_set1_epi32(1);\n    __m128i zero = _mm_setzero_si128();\n    __m128i has_odd = _mm_setzero_si128();\n\n    while (n > 0) {\n        uint32_t digits[4] = {n % 10, (n / 10) % 10, (n / 100) % 10, (n / 1000) % 10};\n        __m128i digit_vec = _mm_loadu_si128((__m128i*)digits);\n\n        __m128i is_odd = _mm_and_si128(digit_vec, _mm_set1_epi32(1));\n        __m128i odd_mask = _mm_cmpeq_epi32(is_odd, _mm_set1_epi32(1));\n        __m128i odd_digits = _mm_and_si128(digit_vec, odd_mask);\n\n        odd_product = _mm_mullo_epi32(odd_product, odd_digits);\n        has_odd = _mm_or_si128(has_odd, odd_mask);\n\n        n /= 10000;\n    }\n\n    __m128i odd_product_horizontal = _mm_hadd_epi32(odd_product, odd_product);\n    odd_product_horizontal = _mm_hadd_epi32(odd_product_horizontal, odd_product_horizontal);\n\n    __m128i has_odd_horizontal = _mm_hadd_epi32(has_odd, has_odd);\n    has_odd_horizontal = _mm_hadd_epi32(has_odd_horizontal, has_odd_horizontal);\n\n    int32_t result = _mm_extract_epi32(odd_product_horizontal, 0);\n    int32_t has_odd_result = _mm_extract_epi32(has_odd_horizontal, 0);\n\n    return has_odd_result ? result : 0;\n}\n```"}
{"task_id": "SimdBench_126_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nuint64_t sum_squares_simd(const std::vector<float> & lst){\n    __m128 sum = _mm_setzero_ps();\n    size_t i = 0;\n    for (; i + 4 <= lst.size(); i += 4) {\n        __m128 vec = _mm_loadu_ps(&lst[i]);\n        vec = _mm_ceil_ps(vec);\n        vec = _mm_mul_ps(vec, vec);\n        sum = _mm_add_ps(sum, vec);\n    }\n    float result[4];\n    _mm_storeu_ps(result, sum);\n    uint64_t total = static_cast<uint64_t>(result[0] + result[1] + result[2] + result[3]);\n\n    for (; i < lst.size(); ++i) {\n        int64_t ceil_val = static_cast<int64_t>(std::ceil(lst[i]));\n        total += ceil_val * ceil_val;\n    }\n\n    return total;\n}\n```"}
{"task_id": "SimdBench_126_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nuint64_t sum_squares_simd(const std::vector<float> & lst){\n    __m128 sum = _mm_setzero_ps();\n    size_t i = 0;\n    for (; i + 4 <= lst.size(); i += 4) {\n        __m128 vec = _mm_loadu_ps(&lst[i]);\n        vec = _mm_ceil_ps(vec);\n        vec = _mm_mul_ps(vec, vec);\n        sum = _mm_add_ps(sum, vec);\n    }\n    float result[4];\n    _mm_storeu_ps(result, sum);\n    uint64_t total = static_cast<uint64_t>(result[0] + result[1] + result[2] + result[3]);\n\n    for (; i < lst.size(); ++i) {\n        int64_t ceil_val = static_cast<int64_t>(std::ceil(lst[i]));\n        total += ceil_val * ceil_val;\n    }\n\n    return total;\n}\n```"}
{"task_id": "SimdBench_126_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nuint64_t sum_squares_simd(const std::vector<float> & lst){\n    __m128 sum = _mm_setzero_ps();\n    size_t i = 0;\n    for (; i + 4 <= lst.size(); i += 4) {\n        __m128 vec = _mm_loadu_ps(&lst[i]);\n        vec = _mm_ceil_ps(vec);\n        vec = _mm_mul_ps(vec, vec);\n        sum = _mm_add_ps(sum, vec);\n    }\n    float result[4];\n    _mm_storeu_ps(result, sum);\n    uint64_t total = static_cast<uint64_t>(result[0] + result[1] + result[2] + result[3]);\n\n    for (; i < lst.size(); ++i) {\n        int64_t ceil_val = static_cast<int64_t>(std::ceil(lst[i]));\n        total += ceil_val * ceil_val;\n    }\n\n    return total;\n}\n```"}
{"task_id": "SimdBench_126_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nuint64_t sum_squares_simd(const std::vector<float> & lst){\n    __m128 sum = _mm_setzero_ps();\n    size_t i = 0;\n    for (; i + 4 <= lst.size(); i += 4) {\n        __m128 vec = _mm_loadu_ps(&lst[i]);\n        vec = _mm_ceil_ps(vec);\n        vec = _mm_mul_ps(vec, vec);\n        sum = _mm_add_ps(sum, vec);\n    }\n    float result[4];\n    _mm_storeu_ps(result, sum);\n    uint64_t total = static_cast<uint64_t>(result[0] + result[1] + result[2] + result[3]);\n\n    for (; i < lst.size(); ++i) {\n        int64_t ceil_val = static_cast<int64_t>(std::ceil(lst[i]));\n        total += ceil_val * ceil_val;\n    }\n\n    return total;\n}\n```"}
{"task_id": "SimdBench_126_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nuint64_t sum_squares_simd(const std::vector<float> & lst){\n    __m128 sum = _mm_setzero_ps();\n    size_t i = 0;\n    for (; i + 4 <= lst.size(); i += 4) {\n        __m128 vec = _mm_loadu_ps(&lst[i]);\n        vec = _mm_ceil_ps(vec);\n        vec = _mm_mul_ps(vec, vec);\n        sum = _mm_add_ps(sum, vec);\n    }\n    float result[4];\n    _mm_storeu_ps(result, sum);\n    uint64_t total = static_cast<uint64_t>(result[0] + result[1] + result[2] + result[3]);\n\n    for (; i < lst.size(); ++i) {\n        int64_t ceil_val = static_cast<int64_t>(std::ceil(lst[i]));\n        total += ceil_val * ceil_val;\n    }\n\n    return total;\n}\n```"}
{"task_id": "SimdBench_127_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint can_arrange_simd(const std::vector<int> & arr){\n    int n = arr.size();\n    if (n < 2) return -1;\n\n    __m128i prev = _mm_set1_epi32(arr[0]);\n    int result = -1;\n    int i = 1;\n\n    for (; i <= n - 4; i += 4) {\n        __m128i current = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&arr[i]));\n        __m128i cmp = _mm_cmpgt_epi32(current, prev);\n        int mask = _mm_movemask_epi8(cmp);\n\n        if (mask != 0) {\n            for (int j = 0; j < 4; ++j) {\n                if ((mask >> (j * 4)) & 0xF) {\n                    result = i + j;\n                }\n            }\n        }\n        prev = current;\n    }\n\n    for (; i < n; ++i) {\n        if (arr[i] >= arr[i - 1]) {\n            result = i;\n        }\n    }\n\n    return result == -1 ? -1 : n - result - 1;\n}\n```"}
{"task_id": "SimdBench_127_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint can_arrange_simd(const std::vector<int> & arr){\n    int n = arr.size();\n    if (n < 2) return -1;\n\n    __m128i prev = _mm_set1_epi32(arr[0]);\n    int result = -1;\n    int i = 1;\n\n    for (; i <= n - 4; i += 4) {\n        __m128i current = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&arr[i]));\n        __m128i cmp = _mm_cmpgt_epi32(current, prev);\n        int mask = _mm_movemask_epi8(cmp);\n\n        if (mask != 0x0000FFFF) {\n            for (int j = 0; j < 4; ++j) {\n                if ((mask >> (j * 4)) & 0xF) {\n                    result = i + j - 1;\n                }\n            }\n        }\n        prev = current;\n    }\n\n    for (; i < n; ++i) {\n        if (arr[i] < arr[i - 1]) {\n            result = i - 1;\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_127_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint can_arrange_simd(const std::vector<int> & arr){\n    int n = arr.size();\n    if (n < 2) return -1;\n\n    __m128i prev = _mm_set1_epi32(arr[0]);\n    __m128i indices = _mm_setr_epi32(0, 1, 2, 3);\n    __m128i result = _mm_set1_epi32(-1);\n\n    for (int i = 1; i < n; i += 4) {\n        __m128i current = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&arr[i]));\n        __m128i cmp = _mm_cmpgt_epi32(current, prev);\n        __m128i mask = _mm_cmpeq_epi32(cmp, _mm_setzero_si128());\n        mask = _mm_and_si128(mask, _mm_cmpgt_epi32(indices, _mm_set1_epi32(i-1)));\n\n        int mask_val = _mm_movemask_epi8(mask);\n        if (mask_val != 0) {\n            int idx = __builtin_ctz(mask_val) / 4;\n            result = _mm_max_epi32(result, _mm_set1_epi32(i + idx));\n        }\n\n        prev = current;\n        indices = _mm_add_epi32(indices, _mm_set1_epi32(4));\n    }\n\n    int res_arr[4];\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(res_arr), result);\n    return *std::max_element(res_arr, res_arr + 4);\n}\n```"}
{"task_id": "SimdBench_127_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint can_arrange_simd(const std::vector<int> & arr){\n    int n = arr.size();\n    if (n < 2) return -1;\n\n    __m128i prev = _mm_set1_epi32(arr[0]);\n    __m128i indices = _mm_setr_epi32(0, 1, 2, 3);\n    __m128i result = _mm_set1_epi32(-1);\n\n    for (int i = 1; i < n; i += 4) {\n        __m128i current = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&arr[i]));\n        __m128i mask = _mm_cmpgt_epi32(current, prev);\n        mask = _mm_xor_si128(mask, _mm_cmpeq_epi32(mask, _mm_set1_epi32(0)));\n\n        __m128i masked_indices = _mm_and_si128(indices, mask);\n        result = _mm_max_epi32(result, masked_indices);\n\n        prev = current;\n        indices = _mm_add_epi32(indices, _mm_set1_epi32(4));\n    }\n\n    int out[4];\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(out), result);\n\n    int max_index = -1;\n    for (int i = 0; i < 4; ++i) {\n        if (out[i] >= 0 && out[i] < n) {\n            max_index = std::max(max_index, out[i]);\n        }\n    }\n\n    return max_index;\n}\n```"}
{"task_id": "SimdBench_127_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint can_arrange_simd(const std::vector<int> & arr){\n    int n = arr.size();\n    if (n < 2) return -1;\n\n    __m128i prev = _mm_set1_epi32(arr[0]);\n    int result = -1;\n    int i = 1;\n\n    for (; i <= n - 4; i += 4) {\n        __m128i current = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&arr[i]));\n        __m128i cmp = _mm_cmpgt_epi32(current, prev);\n        int mask = _mm_movemask_epi8(cmp);\n\n        if (mask != 0) {\n            for (int j = 0; j < 4; ++j) {\n                if ((mask >> (j * 4)) & 0xF) {\n                    result = i + j;\n                }\n            }\n        }\n\n        prev = _mm_srli_si128(current, 12);\n    }\n\n    for (; i < n; ++i) {\n        if (arr[i] >= arr[i - 1]) {\n            result = i;\n        }\n    }\n\n    return result == -1 ? -1 : n - result - 1;\n}\n```"}
{"task_id": "SimdBench_128_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <limits>\n\nstd::vector<int> largest_smallest_integers_simd(const std::vector<int>& lst) {\n    if (lst.empty()) {\n        return {0, 0};\n    }\n\n    __m128i max_neg = _mm_set1_epi32(std::numeric_limits<int>::min());\n    __m128i min_pos = _mm_set1_epi32(std::numeric_limits<int>::max());\n\n    size_t i = 0;\n    for (; i + 4 <= lst.size(); i += 4) {\n        __m128i vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&lst[i]));\n\n        __m128i neg_mask = _mm_cmpgt_epi32(_mm_setzero_si128(), vec);\n        __m128i pos_mask = _mm_cmpgt_epi32(vec, _mm_setzero_si128());\n\n        __m128i neg_vals = _mm_and_si128(vec, neg_mask);\n        __m128i pos_vals = _mm_and_si128(vec, pos_mask);\n\n        max_neg = _mm_max_epi32(max_neg, neg_vals);\n        min_pos = _mm_min_epi32(min_pos, pos_vals);\n    }\n\n    int max_neg_arr[4], min_pos_arr[4];\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(max_neg_arr), max_neg);\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(min_pos_arr), min_pos);\n\n    int largest_neg = std::numeric_limits<int>::min();\n    int smallest_pos = std::numeric_limits<int>::max();\n\n    for (size_t j = 0; j < 4; ++j) {\n        if (max_neg_arr[j] > largest_neg && max_neg_arr[j] < 0) {\n            largest_neg = max_neg_arr[j];\n        }\n        if (min_pos_arr[j] < smallest_pos && min_pos_arr[j] > 0) {\n            smallest_pos = min_pos_arr[j];\n        }\n    }\n\n    for (; i < lst.size(); ++i) {\n        if (lst[i] < 0 && lst[i] > largest_neg) {\n            largest_neg = lst[i];\n        }\n        if (lst[i] > 0 && lst[i] < smallest_pos) {\n            smallest_pos = lst[i];\n        }\n    }\n\n    if (largest_neg == std::numeric_limits<int>::min()) {\n        largest_neg = 0;\n    }\n    if (smallest_pos == std::numeric_limits<int>::max()) {\n        smallest_pos = 0;\n    }\n\n    return {largest_neg, smallest_pos};\n}\n```"}
{"task_id": "SimdBench_128_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <limits>\n\nstd::vector<int> largest_smallest_integers_simd(const std::vector<int>& lst) {\n    if (lst.empty()) {\n        return {0, 0};\n    }\n\n    __m128i max_neg = _mm_set1_epi32(std::numeric_limits<int>::min());\n    __m128i min_pos = _mm_set1_epi32(std::numeric_limits<int>::max());\n\n    size_t i = 0;\n    for (; i + 3 < lst.size(); i += 4) {\n        __m128i vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&lst[i]));\n\n        __m128i neg_mask = _mm_cmpgt_epi32(_mm_setzero_si128(), vec);\n        __m128i pos_mask = _mm_cmpgt_epi32(vec, _mm_setzero_si128());\n\n        __m128i neg_vals = _mm_and_si128(neg_mask, vec);\n        __m128i pos_vals = _mm_and_si128(pos_mask, vec);\n\n        max_neg = _mm_max_epi32(max_neg, neg_vals);\n        min_pos = _mm_min_epi32(min_pos, pos_vals);\n    }\n\n    int max_neg_arr[4], min_pos_arr[4];\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(max_neg_arr), max_neg);\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(min_pos_arr), min_pos);\n\n    int final_max_neg = std::numeric_limits<int>::min();\n    int final_min_pos = std::numeric_limits<int>::max();\n\n    for (int j = 0; j < 4; ++j) {\n        if (max_neg_arr[j] > final_max_neg && max_neg_arr[j] <= 0) {\n            final_max_neg = max_neg_arr[j];\n        }\n        if (min_pos_arr[j] < final_min_pos && min_pos_arr[j] >= 0) {\n            final_min_pos = min_pos_arr[j];\n        }\n    }\n\n    for (; i < lst.size(); ++i) {\n        if (lst[i] < 0 && lst[i] > final_max_neg) {\n            final_max_neg = lst[i];\n        }\n        if (lst[i] > 0 && lst[i] < final_min_pos) {\n            final_min_pos = lst[i];\n        }\n    }\n\n    if (final_max_neg == std::numeric_limits<int>::min()) {\n        final_max_neg = 0;\n    }\n    if (final_min_pos == std::numeric_limits<int>::max()) {\n        final_min_pos = 0;\n    }\n\n    return {final_max_neg, final_min_pos};\n}\n```"}
{"task_id": "SimdBench_128_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <limits>\n\nstd::vector<int> largest_smallest_integers_simd(const std::vector<int>& lst) {\n    if (lst.empty()) {\n        return {0, 0};\n    }\n\n    __m128i max_neg = _mm_set1_epi32(std::numeric_limits<int>::min());\n    __m128i min_pos = _mm_set1_epi32(std::numeric_limits<int>::max());\n\n    size_t i = 0;\n    for (; i + 3 < lst.size(); i += 4) {\n        __m128i vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&lst[i]));\n\n        __m128i neg_mask = _mm_cmpgt_epi32(_mm_setzero_si128(), vec);\n        __m128i pos_mask = _mm_cmpgt_epi32(vec, _mm_setzero_si128());\n\n        __m128i neg_vals = _mm_and_si128(neg_mask, vec);\n        __m128i pos_vals = _mm_and_si128(pos_mask, vec);\n\n        max_neg = _mm_max_epi32(max_neg, neg_vals);\n        min_pos = _mm_min_epi32(min_pos, pos_vals);\n    }\n\n    int max_neg_arr[4], min_pos_arr[4];\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(max_neg_arr), max_neg);\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(min_pos_arr), min_pos);\n\n    int final_max_neg = std::numeric_limits<int>::min();\n    int final_min_pos = std::numeric_limits<int>::max();\n\n    for (int j = 0; j < 4; ++j) {\n        if (max_neg_arr[j] > final_max_neg && max_neg_arr[j] <= 0) {\n            final_max_neg = max_neg_arr[j];\n        }\n        if (min_pos_arr[j] < final_min_pos && min_pos_arr[j] >= 0) {\n            final_min_pos = min_pos_arr[j];\n        }\n    }\n\n    for (; i < lst.size(); ++i) {\n        if (lst[i] < 0 && lst[i] > final_max_neg) {\n            final_max_neg = lst[i];\n        }\n        if (lst[i] > 0 && lst[i] < final_min_pos) {\n            final_min_pos = lst[i];\n        }\n    }\n\n    if (final_max_neg == std::numeric_limits<int>::min()) {\n        final_max_neg = 0;\n    }\n    if (final_min_pos == std::numeric_limits<int>::max()) {\n        final_min_pos = 0;\n    }\n\n    return {final_max_neg, final_min_pos};\n}\n```"}
{"task_id": "SimdBench_128_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <limits>\n\nstd::vector<int> largest_smallest_integers_simd(const std::vector<int>& lst) {\n    if (lst.empty()) {\n        return {0, 0};\n    }\n\n    __m128i max_neg = _mm_set1_epi32(std::numeric_limits<int>::min());\n    __m128i min_pos = _mm_set1_epi32(std::numeric_limits<int>::max());\n\n    size_t i = 0;\n    for (; i + 4 <= lst.size(); i += 4) {\n        __m128i vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&lst[i]));\n\n        __m128i neg_mask = _mm_cmplt_epi32(vec, _mm_setzero_si128());\n        __m128i pos_mask = _mm_cmpgt_epi32(vec, _mm_setzero_si128());\n\n        __m128i neg_vals = _mm_and_si128(vec, neg_mask);\n        __m128i pos_vals = _mm_and_si128(vec, pos_mask);\n\n        max_neg = _mm_max_epi32(max_neg, neg_vals);\n        min_pos = _mm_min_epi32(min_pos, pos_vals);\n    }\n\n    int max_neg_arr[4], min_pos_arr[4];\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(max_neg_arr), max_neg);\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(min_pos_arr), min_pos);\n\n    int largest_neg = std::numeric_limits<int>::min();\n    int smallest_pos = std::numeric_limits<int>::max();\n\n    for (int j = 0; j < 4; ++j) {\n        if (max_neg_arr[j] > largest_neg && max_neg_arr[j] < 0) {\n            largest_neg = max_neg_arr[j];\n        }\n        if (min_pos_arr[j] < smallest_pos && min_pos_arr[j] > 0) {\n            smallest_pos = min_pos_arr[j];\n        }\n    }\n\n    for (; i < lst.size(); ++i) {\n        if (lst[i] < 0 && lst[i] > largest_neg) {\n            largest_neg = lst[i];\n        }\n        if (lst[i] > 0 && lst[i] < smallest_pos) {\n            smallest_pos = lst[i];\n        }\n    }\n\n    if (largest_neg == std::numeric_limits<int>::min()) {\n        largest_neg = 0;\n    }\n    if (smallest_pos == std::numeric_limits<int>::max()) {\n        smallest_pos = 0;\n    }\n\n    return {largest_neg, smallest_pos};\n}\n```"}
{"task_id": "SimdBench_128_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <limits>\n\nstd::vector<int> largest_smallest_integers_simd(const std::vector<int>& lst) {\n    if (lst.empty()) {\n        return {0, 0};\n    }\n\n    __m128i max_neg = _mm_set1_epi32(std::numeric_limits<int>::min());\n    __m128i min_pos = _mm_set1_epi32(std::numeric_limits<int>::max());\n\n    size_t i = 0;\n    for (; i + 3 < lst.size(); i += 4) {\n        __m128i vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&lst[i]));\n\n        __m128i neg_mask = _mm_cmplt_epi32(vec, _mm_setzero_si128());\n        __m128i pos_mask = _mm_cmpgt_epi32(vec, _mm_setzero_si128());\n\n        __m128i neg_vals = _mm_and_si128(vec, neg_mask);\n        __m128i pos_vals = _mm_and_si128(vec, pos_mask);\n\n        max_neg = _mm_max_epi32(max_neg, neg_vals);\n        min_pos = _mm_min_epi32(min_pos, pos_vals);\n    }\n\n    int max_neg_arr[4], min_pos_arr[4];\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(max_neg_arr), max_neg);\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(min_pos_arr), min_pos);\n\n    int largest_neg = std::numeric_limits<int>::min();\n    int smallest_pos = std::numeric_limits<int>::max();\n\n    for (size_t j = 0; j < 4; ++j) {\n        if (max_neg_arr[j] > largest_neg && max_neg_arr[j] < 0) {\n            largest_neg = max_neg_arr[j];\n        }\n        if (min_pos_arr[j] < smallest_pos && min_pos_arr[j] > 0) {\n            smallest_pos = min_pos_arr[j];\n        }\n    }\n\n    for (; i < lst.size(); ++i) {\n        if (lst[i] < 0 && lst[i] > largest_neg) {\n            largest_neg = lst[i];\n        }\n        if (lst[i] > 0 && lst[i] < smallest_pos) {\n            smallest_pos = lst[i];\n        }\n    }\n\n    if (largest_neg == std::numeric_limits<int>::min()) {\n        largest_neg = 0;\n    }\n    if (smallest_pos == std::numeric_limits<int>::max()) {\n        smallest_pos = 0;\n    }\n\n    return {largest_neg, smallest_pos};\n}\n```"}
{"task_id": "SimdBench_129_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nuint64_t special_factorial_simd(uint64_t n) {\n    if (n == 0) return 1;\n\n    __m128i factorials = _mm_set1_epi64x(1);\n    __m128i ones = _mm_set1_epi64x(1);\n    __m128i twos = _mm_set1_epi64x(2);\n\n    for (uint64_t i = 2; i <= n; ++i) {\n        __m128i current = _mm_set1_epi64x(i);\n        for (uint64_t j = 1; j <= i; ++j) {\n            factorials = _mm_mullo_epi64(factorials, current);\n            current = _mm_sub_epi64(current, ones);\n        }\n    }\n\n    uint64_t result[2];\n    _mm_storeu_si128((__m128i*)result, factorials);\n    return result[0] * result[1];\n}\n```"}
{"task_id": "SimdBench_129_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nuint64_t special_factorial_simd(uint64_t n) {\n    if (n == 0) return 1;\n\n    __m128i factorials = _mm_set1_epi64x(1);\n    __m128i ones = _mm_set1_epi64x(1);\n    __m128i twos = _mm_set1_epi64x(2);\n    __m128i current = _mm_set1_epi64x(n);\n\n    while (_mm_extract_epi64(current, 0) > 0) {\n        factorials = _mm_mullo_epi64(factorials, current);\n        current = _mm_sub_epi64(current, ones);\n    }\n\n    uint64_t result[2];\n    _mm_storeu_si128((__m128i*)result, factorials);\n\n    return result[0] * result[1];\n}\n```"}
{"task_id": "SimdBench_129_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nuint64_t special_factorial_simd(uint64_t n) {\n    if (n == 0) return 1;\n\n    __m128i factorials = _mm_set1_epi64x(1);\n    __m128i ones = _mm_set1_epi64x(1);\n    __m128i twos = _mm_set1_epi64x(2);\n    __m128i current = _mm_set1_epi64x(n);\n\n    while (_mm_extract_epi64(current, 0) > 0) {\n        factorials = _mm_mullo_epi64(factorials, current);\n        current = _mm_sub_epi64(current, ones);\n        if (_mm_extract_epi64(current, 0) > 0) {\n            factorials = _mm_mullo_epi64(factorials, current);\n            current = _mm_sub_epi64(current, ones);\n        }\n    }\n\n    uint64_t result[2];\n    _mm_storeu_si128((__m128i*)result, factorials);\n    return result[0] * result[1];\n}\n```"}
{"task_id": "SimdBench_129_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nuint64_t special_factorial_simd(uint64_t n) {\n    if (n == 0) return 1;\n\n    __m128i factorials = _mm_set1_epi64x(1);\n    __m128i ones = _mm_set1_epi64x(1);\n    __m128i twos = _mm_set1_epi64x(2);\n\n    for (uint64_t i = 2; i <= n; ++i) {\n        __m128i current = _mm_set1_epi64x(i);\n        for (uint64_t j = 1; j <= i; ++j) {\n            factorials = _mm_mullo_epi64(factorials, current);\n            current = _mm_sub_epi64(current, ones);\n        }\n    }\n\n    uint64_t result[2];\n    _mm_storeu_si128((__m128i*)result, factorials);\n\n    return result[0] * result[1];\n}\n```"}
{"task_id": "SimdBench_129_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nuint64_t special_factorial_simd(uint64_t n) {\n    if (n == 0) return 1;\n\n    __m128i factorials = _mm_set1_epi64x(1);\n    __m128i ones = _mm_set1_epi64x(1);\n    __m128i twos = _mm_set1_epi64x(2);\n    __m128i current = _mm_set1_epi64x(n);\n\n    while (_mm_extract_epi64(current, 0) > 0) {\n        factorials = _mm_mullo_epi64(factorials, current);\n        current = _mm_sub_epi64(current, ones);\n        if (_mm_extract_epi64(current, 0) > 0) {\n            factorials = _mm_mullo_epi64(factorials, current);\n            current = _mm_sub_epi64(current, ones);\n        }\n    }\n\n    uint64_t result[2];\n    _mm_storeu_si128((__m128i*)result, factorials);\n    return result[0] * result[1];\n}\n```"}
{"task_id": "SimdBench_130_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint sum_squares_simd(const std::vector<int> & lst){\n    int n = lst.size();\n    if (n == 0) return 0;\n\n    __m128i sum = _mm_setzero_si128();\n    int i = 0;\n\n    for (; i <= n - 4; i += 4) {\n        __m128i vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&lst[i]));\n\n        // Create masks for indices that are multiples of 3 and 4\n        __m128i mask3 = _mm_set_epi32((i+3)%3==0, (i+2)%3==0, (i+1)%3==0, i%3==0);\n        __m128i mask4 = _mm_set_epi32((i+3)%4==0, (i+2)%4==0, (i+1)%4==0, i%4==0);\n\n        // Combine masks: true if multiple of 3 or (multiple of 4 and not multiple of 3)\n        __m128i mask_square = mask3;\n        __m128i mask_cube = _mm_andnot_si128(mask3, mask4);\n\n        // Square the elements where mask_square is true\n        __m128i squared = _mm_mullo_epi32(vec, vec);\n        squared = _mm_blendv_epi8(vec, squared, mask_square);\n\n        // Cube the elements where mask_cube is true\n        __m128i cubed = _mm_mullo_epi32(squared, vec);\n        cubed = _mm_blendv_epi8(squared, cubed, mask_cube);\n\n        // Add to sum\n        sum = _mm_add_epi32(sum, cubed);\n    }\n\n    // Handle remaining elements\n    int result[4];\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(result), sum);\n    int total_sum = result[0] + result[1] + result[2] + result[3];\n\n    for (; i < n; ++i) {\n        if (i % 3 == 0) {\n            total_sum += lst[i] * lst[i];\n        } else if (i % 4 == 0) {\n            total_sum += lst[i] * lst[i] * lst[i];\n        } else {\n            total_sum += lst[i];\n        }\n    }\n\n    return total_sum;\n}\n```"}
{"task_id": "SimdBench_130_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint sum_squares_simd(const std::vector<int> & lst){\n    int n = lst.size();\n    if (n == 0) return 0;\n\n    __m128i sum = _mm_setzero_si128();\n    int i = 0;\n\n    for (; i <= n - 4; i += 4) {\n        __m128i vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&lst[i]));\n\n        // Create masks for indices that are multiples of 3 and 4\n        __m128i mask3 = _mm_set_epi32((i+3)%3==0, (i+2)%3==0, (i+1)%3==0, i%3==0);\n        __m128i mask4 = _mm_set_epi32((i+3)%4==0, (i+2)%4==0, (i+1)%4==0, i%4==0);\n\n        // Combine masks: true if multiple of 3 or (multiple of 4 and not multiple of 3)\n        __m128i mask_square = mask3;\n        __m128i mask_cube = _mm_andnot_si128(mask3, mask4);\n\n        // Square the elements where mask_square is true\n        __m128i squared = _mm_mullo_epi32(vec, vec);\n        squared = _mm_blendv_epi8(vec, squared, mask_square);\n\n        // Cube the elements where mask_cube is true\n        __m128i cubed = _mm_mullo_epi32(squared, vec);\n        cubed = _mm_blendv_epi8(squared, cubed, mask_cube);\n\n        // Add to sum\n        sum = _mm_add_epi32(sum, cubed);\n    }\n\n    // Handle remaining elements\n    int result[4];\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(result), sum);\n    int total_sum = result[0] + result[1] + result[2] + result[3];\n\n    for (; i < n; ++i) {\n        if (i % 3 == 0) {\n            total_sum += lst[i] * lst[i];\n        } else if (i % 4 == 0) {\n            total_sum += lst[i] * lst[i] * lst[i];\n        } else {\n            total_sum += lst[i];\n        }\n    }\n\n    return total_sum;\n}\n```"}
{"task_id": "SimdBench_130_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint sum_squares_simd(const std::vector<int> & lst){\n    int sum = 0;\n    int n = lst.size();\n    int i = 0;\n\n    __m128i sum_vec = _mm_setzero_si128();\n\n    for (; i <= n - 16; i += 16) {\n        __m128i vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&lst[i]));\n        __m128i indices = _mm_setr_epi32(i, i+1, i+2, i+3, i+4, i+5, i+6, i+7);\n        __m128i multiples_of_3 = _mm_cmpeq_epi32(_mm_and_si128(indices, _mm_set1_epi32(3)), _mm_setzero_si128());\n        __m128i multiples_of_4_not_3 = _mm_andnot_si128(multiples_of_3, _mm_cmpeq_epi32(_mm_and_si128(indices, _mm_set1_epi32(4)), _mm_setzero_si128()));\n\n        __m128i squares = _mm_mullo_epi32(vec, vec);\n        __m128i cubes = _mm_mullo_epi32(squares, vec);\n\n        __m128i result = _mm_blendv_epi8(vec, squares, multiples_of_3);\n        result = _mm_blendv_epi8(result, cubes, multiples_of_4_not_3);\n\n        sum_vec = _mm_add_epi32(sum_vec, result);\n    }\n\n    int temp_sum[4];\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(temp_sum), _mm_add_epi32(_mm_add_epi32(_mm_shuffle_epi32(sum_vec, _MM_SHUFFLE(1, 0, 3, 2)), _mm_shuffle_epi32(sum_vec, _MM_SHUFFLE(3, 2, 1, 0))), _mm_setzero_si128()));\n    sum = temp_sum[0] + temp_sum[1];\n\n    for (; i < n; ++i) {\n        if (i % 3 == 0) {\n            sum += lst[i] * lst[i];\n        } else if (i % 4 == 0) {\n            sum += lst[i] * lst[i] * lst[i];\n        } else {\n            sum += lst[i];\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_130_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint sum_squares_simd(const std::vector<int> & lst){\n    int n = lst.size();\n    if (n == 0) return 0;\n\n    __m128i sum = _mm_setzero_si128();\n    int i = 0;\n\n    for (; i <= n - 4; i += 4) {\n        __m128i vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&lst[i]));\n\n        // Create masks for indices that are multiples of 3 and 4\n        __m128i mask3 = _mm_set_epi32((i+3)%3==0, (i+2)%3==0, (i+1)%3==0, i%3==0);\n        __m128i mask4 = _mm_set_epi32(((i+3)%4==0 && (i+3)%3!=0), ((i+2)%4==0 && (i+2)%3!=0), ((i+1)%4==0 && (i+1)%3!=0), (i%4==0 && i%3!=0));\n\n        // Square elements at indices that are multiples of 3\n        __m128i squared = _mm_mullo_epi32(vec, vec);\n        squared = _mm_and_si128(squared, mask3);\n\n        // Cube elements at indices that are multiples of 4 and not multiples of 3\n        __m128i cubed = _mm_mullo_epi32(vec, _mm_mullo_epi32(vec, vec));\n        cubed = _mm_and_si128(cubed, mask4);\n\n        // Combine results\n        __m128i result = _mm_or_si128(squared, cubed);\n\n        // Add to sum\n        sum = _mm_add_epi32(sum, result);\n    }\n\n    // Horizontal sum of the vector\n    int hsum[4];\n    _mm_storeu_si128((__m128i*)hsum, sum);\n    int total_sum = hsum[0] + hsum[1] + hsum[2] + hsum[3];\n\n    // Handle remaining elements\n    for (; i < n; ++i) {\n        if (i % 3 == 0) {\n            total_sum += lst[i] * lst[i];\n        } else if (i % 4 == 0) {\n            total_sum += lst[i] * lst[i] * lst[i];\n        } else {\n            total_sum += lst[i];\n        }\n    }\n\n    return total_sum;\n}\n```"}
{"task_id": "SimdBench_130_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint sum_squares_simd(const std::vector<int> & lst){\n    int n = lst.size();\n    if (n == 0) return 0;\n\n    __m128i sum = _mm_setzero_si128();\n    int i = 0;\n\n    for (; i <= n - 4; i += 4) {\n        __m128i vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&lst[i]));\n\n        // Create masks for indices that are multiples of 3 and 4\n        __m128i mask3 = _mm_set_epi32((i+3)%3==0 ? 0xFFFFFFFF : 0, (i+2)%3==0 ? 0xFFFFFFFF : 0, (i+1)%3==0 ? 0xFFFFFFFF : 0, i%3==0 ? 0xFFFFFFFF : 0);\n        __m128i mask4 = _mm_set_epi32((i+3)%4==0 ? 0xFFFFFFFF : 0, (i+2)%4==0 ? 0xFFFFFFFF : 0, (i+1)%4==0 ? 0xFFFFFFFF : 0, i%4==0 ? 0xFFFFFFFF : 0);\n\n        // Mask for indices that are multiples of 4 but not 3\n        __m128i mask4_not3 = _mm_andnot_si128(mask3, mask4);\n\n        // Square the elements at indices that are multiples of 3\n        __m128i squared = _mm_mullo_epi32(vec, vec);\n        squared = _mm_and_si128(squared, mask3);\n\n        // Cube the elements at indices that are multiples of 4 but not 3\n        __m128i cubed = _mm_mullo_epi32(_mm_mullo_epi32(vec, vec), vec);\n        cubed = _mm_and_si128(cubed, mask4_not3);\n\n        // Combine squared and cubed results\n        __m128i result = _mm_or_si128(squared, cubed);\n\n        // Add to sum\n        sum = _mm_add_epi32(sum, result);\n    }\n\n    // Horizontal add of the sum vector\n    int temp[4];\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(temp), sum);\n    int total_sum = temp[0] + temp[1] + temp[2] + temp[3];\n\n    // Handle remaining elements\n    for (; i < n; ++i) {\n        if (i % 3 == 0) {\n            total_sum += lst[i] * lst[i];\n        } else if (i % 4 == 0) {\n            total_sum += lst[i] * lst[i] * lst[i];\n        } else {\n            total_sum += lst[i];\n        }\n    }\n\n    return total_sum;\n}\n```"}
{"task_id": "SimdBench_131_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint specialFilter_simd(const std::vector<int> & nums){\n    int count = 0;\n    int n = nums.size();\n    int i = 0;\n\n    __m128i ten = _mm_set1_epi32(10);\n    __m128i odd_mask = _mm_set1_epi32(0x1);\n    __m128i odd_digits_mask = _mm_set1_epi32(0x101);\n\n    for (; i <= n - 4; i += 4) {\n        __m128i num = _mm_loadu_si128((__m128i const*)&nums[i]);\n\n        // Check if numbers are greater than 10\n        __m128i gt_ten = _mm_cmpgt_epi32(num, ten);\n\n        // Extract first and last digits\n        __m128i last_digit = _mm_and_si128(num, odd_mask);\n        __m128i first_digit = _mm_srli_epi32(num, 28); // Shift right by 28 to get the first digit\n        first_digit = _mm_and_si128(first_digit, odd_mask);\n\n        // Check if both first and last digits are odd\n        __m128i odd_first_last = _mm_and_si128(last_digit, first_digit);\n        odd_first_last = _mm_cmpeq_epi32(odd_first_last, odd_mask);\n\n        // Combine conditions\n        __m128i result = _mm_and_si128(gt_ten, odd_first_last);\n\n        // Count true results\n        int mask = _mm_movemask_epi8(result);\n        count += __builtin_popcount(mask) / 8;\n    }\n\n    // Handle remaining elements\n    for (; i < n; ++i) {\n        int num = nums[i];\n        int last_digit = num % 10;\n        int first_digit = num < 0 ? -(num / 1000000000) : num / 1000000000;\n        if (num > 10 && (last_digit & 1) && (first_digit & 1)) {\n            ++count;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_131_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint specialFilter_simd(const std::vector<int> & nums){\n    int count = 0;\n    int n = nums.size();\n    int i = 0;\n\n    __m128i ten = _mm_set1_epi32(10);\n    __m128i odd_mask = _mm_set1_epi32(0x1);\n    __m128i odd_digits_mask = _mm_set1_epi32(0x101);\n\n    for (; i <= n - 4; i += 4) {\n        __m128i num = _mm_loadu_si128((__m128i const*)&nums[i]);\n\n        // Check if numbers are greater than 10\n        __m128i gt_ten = _mm_cmpgt_epi32(num, ten);\n\n        // Extract first and last digits\n        __m128i last_digit = _mm_and_si128(num, odd_mask);\n        __m128i first_digit = _mm_srli_epi32(num, 28); // Shift right by 28 to get the first digit\n        first_digit = _mm_and_si128(first_digit, odd_mask);\n\n        // Check if both first and last digits are odd\n        __m128i odd_first_last = _mm_and_si128(last_digit, first_digit);\n        odd_first_last = _mm_cmpeq_epi32(odd_first_last, odd_mask);\n\n        // Combine conditions\n        __m128i result = _mm_and_si128(gt_ten, odd_first_last);\n\n        // Count the number of true conditions\n        int mask = _mm_movemask_epi8(result);\n        count += __builtin_popcount(mask) / 8;\n    }\n\n    // Handle remaining elements\n    for (; i < n; ++i) {\n        int num = nums[i];\n        int last_digit = num % 10;\n        int first_digit = num < 0 ? -(num / 1000000000) : num / 1000000000;\n        if (num > 10 && (last_digit & 1) && (first_digit & 1)) {\n            ++count;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_131_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint specialFilter_simd(const std::vector<int> & nums){\n    int count = 0;\n    int n = nums.size();\n    int i = 0;\n\n    __m128i ten = _mm_set1_epi32(10);\n    __m128i odd_mask = _mm_set1_epi32(0x1);\n    __m128i odd_digits_mask = _mm_set1_epi32(0x101);\n\n    for (; i <= n - 4; i += 4) {\n        __m128i num = _mm_loadu_si128((__m128i const*)&nums[i]);\n\n        // Check if numbers are greater than 10\n        __m128i gt_ten = _mm_cmpgt_epi32(num, ten);\n\n        // Extract first and last digits\n        __m128i last_digit = _mm_and_si128(num, odd_mask);\n        __m128i first_digit = _mm_srli_epi32(num, 28); // Shift right by 28 to get the first digit\n        first_digit = _mm_and_si128(first_digit, odd_mask);\n\n        // Check if both first and last digits are odd\n        __m128i odd_first_last = _mm_and_si128(last_digit, first_digit);\n        odd_first_last = _mm_cmpeq_epi32(odd_first_last, odd_mask);\n\n        // Combine conditions\n        __m128i result = _mm_and_si128(gt_ten, odd_first_last);\n\n        // Count true results\n        int mask = _mm_movemask_epi8(result);\n        count += __builtin_popcount(mask) / 8;\n    }\n\n    // Handle remaining elements\n    for (; i < n; ++i) {\n        int num = nums[i];\n        int last_digit = num % 10;\n        int first_digit = num < 0 ? -(num / 1000000000) : num / 1000000000;\n        if (num > 10 && (last_digit & 1) && (first_digit & 1)) {\n            ++count;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_131_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint specialFilter_simd(const std::vector<int> & nums){\n    int count = 0;\n    int n = nums.size();\n    int i = 0;\n\n    __m128i ten = _mm_set1_epi32(10);\n    __m128i odd_mask = _mm_set1_epi32(0x1);\n    __m128i odd_digits_mask = _mm_set1_epi32(0x101);\n\n    for (; i <= n - 4; i += 4) {\n        __m128i num = _mm_loadu_si128((__m128i const*)&nums[i]);\n\n        // Check if numbers are greater than 10\n        __m128i gt_ten = _mm_cmpgt_epi32(num, ten);\n\n        // Extract first and last digits\n        __m128i last_digit = _mm_and_si128(num, odd_mask);\n        __m128i first_digit = _mm_srli_epi32(num, 28); // Shift right by 28 to get the first digit\n        first_digit = _mm_and_si128(first_digit, odd_mask);\n\n        // Check if both first and last digits are odd\n        __m128i odd_first_last = _mm_and_si128(last_digit, first_digit);\n        odd_first_last = _mm_cmpeq_epi32(odd_first_last, odd_mask);\n\n        // Combine conditions\n        __m128i result = _mm_and_si128(gt_ten, odd_first_last);\n\n        // Count true results\n        int mask = _mm_movemask_epi8(result);\n        count += __builtin_popcount(mask) / 8;\n    }\n\n    // Handle remaining elements\n    for (; i < n; ++i) {\n        int num = nums[i];\n        int last_digit = num % 10;\n        int first_digit = num < 0 ? -(num / 1000000000) : num / 1000000000;\n        if (num > 10 && (last_digit & 1) && (first_digit & 1)) {\n            ++count;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_131_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint specialFilter_simd(const std::vector<int> & nums){\n    int count = 0;\n    int n = nums.size();\n    int i = 0;\n\n    __m128i ten = _mm_set1_epi32(10);\n    __m128i odd_mask = _mm_set1_epi32(0x1);\n    __m128i ones = _mm_set1_epi32(1);\n\n    for (; i <= n - 4; i += 4) {\n        __m128i num = _mm_loadu_si128((__m128i const*)&nums[i]);\n\n        // Check if numbers are greater than 10\n        __m128i gt_ten = _mm_cmpgt_epi32(num, ten);\n\n        // Extract first and last digits\n        __m128i abs_num = _mm_abs_epi32(num);\n        __m128i last_digit = _mm_and_si128(abs_num, ones);\n        __m128i first_digit = _mm_srli_epi32(abs_num, 28); // Shift right by 28 to get the first digit\n\n        // Check if first and last digits are odd\n        __m128i last_digit_odd = _mm_and_si128(last_digit, odd_mask);\n        __m128i first_digit_odd = _mm_and_si128(first_digit, odd_mask);\n        __m128i both_odd = _mm_and_si128(last_digit_odd, first_digit_odd);\n\n        // Combine conditions\n        __m128i result = _mm_and_si128(gt_ten, both_odd);\n\n        // Count true results\n        int mask = _mm_movemask_epi8(result);\n        count += __builtin_popcount(mask) / 4;\n    }\n\n    // Handle remaining elements\n    for (; i < n; ++i) {\n        int num = nums[i];\n        int abs_num = std::abs(num);\n        int last_digit = abs_num % 10;\n        int first_digit = abs_num > 0 ? log10(abs_num) : 0;\n        first_digit = (abs_num / static_cast<int>(pow(10, first_digit))) % 10;\n\n        if (num > 10 && (last_digit % 2 != 0) && (first_digit % 2 != 0)) {\n            count++;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_132_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nuint64_t get_max_triples_simd(uint64_t n){\n    if (n < 3) return 0;\n\n    __m128i count[3] = {_mm_setzero_si128(), _mm_setzero_si128(), _mm_setzero_si128()};\n    uint32_t a[4];\n    uint64_t result = 0;\n\n    for (uint64_t i = 0; i < n; ++i) {\n        a[0] = i * i - i + 1;\n        a[1] = (i + 1) * (i + 1) - (i + 1) + 1;\n        a[2] = (i + 2) * (i + 2) - (i + 2) + 1;\n        a[3] = (i + 3) * (i + 3) - (i + 3) + 1;\n\n        __m128i vec_a = _mm_loadu_si128(reinterpret_cast<const __m128i*>(a));\n        __m128i mod3 = _mm_set_epi32(2, 1, 0, 2);\n        __m128i rem = _mm_rem_epu32(vec_a, _mm_set1_epi32(3));\n\n        for (int j = 0; j < 4; ++j) {\n            int idx = rem.m128i_i32[j];\n            count[idx] = _mm_add_epi32(count[idx], _mm_set1_epi32(1));\n        }\n\n        if (i >= 3) {\n            for (int j = 0; j < 3; ++j) {\n                for (int k = j; k < 3; ++k) {\n                    for (int l = k; l < 3; ++l) {\n                        if ((j + k + l) % 3 == 0) {\n                            __m128i prod = _mm_mullo_epi32(count[j], count[k]);\n                            __m128i res = _mm_mullo_epi32(prod, count[l]);\n                            result += _mm_cvtsi128_si32(res);\n                        }\n                    }\n                }\n            }\n\n            // Subtract the overcounted triple for the current i-3\n            int val = (i - 3) * (i - 3) - (i - 3) + 1;\n            int idx = val % 3;\n            count[idx] = _mm_sub_epi32(count[idx], _mm_set1_epi32(1));\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_132_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nuint64_t get_max_triples_simd(uint64_t n){\n    if (n < 3) return 0;\n\n    __m128i count[3] = {_mm_setzero_si128(), _mm_setzero_si128(), _mm_setzero_si128()};\n    uint32_t a[4];\n    uint64_t result = 0;\n\n    for (uint64_t i = 0; i < n; ++i) {\n        a[0] = i * i - i + 1;\n        a[1] = (i + 1) * (i + 1) - (i + 1) + 1;\n        a[2] = (i + 2) * (i + 2) - (i + 2) + 1;\n        a[3] = (i + 3) * (i + 3) - (i + 3) + 1;\n\n        __m128i vec_a = _mm_loadu_si128((__m128i*)a);\n        __m128i mod3 = _mm_set_epi32(2, 1, 0, 2);\n        __m128i rem = _mm_rem_epu32(vec_a, _mm_set1_epi32(3));\n        __m128i mask = _mm_cmpeq_epi32(rem, mod3);\n\n        for (int j = 0; j < 4; ++j) {\n            if (i + j >= n) break;\n            int idx = (a[j] % 3);\n            count[idx] = _mm_add_epi32(count[idx], _mm_slli_epi32(_mm_srli_epi32(mask, j * 4), 2 * j));\n        }\n    }\n\n    for (int i = 0; i < 3; ++i) {\n        for (int j = 0; j < 3; ++j) {\n            for (int k = 0; k < 3; ++k) {\n                if ((i + j + k) % 3 == 0) {\n                    if (i == j && j == k) {\n                        int val = _mm_extract_epi32(count[i], 0) + _mm_extract_epi32(count[i], 1) + _mm_extract_epi32(count[i], 2) + _mm_extract_epi32(count[i], 3);\n                        result += (uint64_t)val * (val - 1) * (val - 2) / 6;\n                    } else if (i == j) {\n                        int val_i = _mm_extract_epi32(count[i], 0) + _mm_extract_epi32(count[i], 1) + _mm_extract_epi32(count[i], 2) + _mm_extract_epi32(count[i], 3);\n                        int val_k = _mm_extract_epi32(count[k], 0) + _mm_extract_epi32(count[k], 1) + _mm_extract_epi32(count[k], 2) + _mm_extract_epi32(count[k], 3);\n                        result += (uint64_t)val_i * (val_i - 1) / 2 * val_k;\n                    } else if (j == k) {\n                        int val_i = _mm_extract_epi32(count[i], 0) + _mm_extract_epi32(count[i], 1) + _mm_extract_epi32(count[i], 2) + _mm_extract_epi32(count[i], 3);\n                        int val_j = _mm_extract_epi32(count[j], 0) + _mm_extract_epi32(count[j], 1) + _mm_extract_epi32(count[j], 2) + _mm_extract_epi32(count[j], 3);\n                        result += (uint64_t)val_i * val_j * (val_j - 1) / 2;\n                    } else {\n                        int val_i = _mm_extract_epi32(count[i], 0) + _mm_extract_epi32(count[i], 1) + _mm_extract_epi32(count[i], 2) + _mm_extract_epi32(count[i], 3);\n                        int val_j = _mm_extract_epi32(count[j], 0) + _mm_extract_epi32(count[j], 1) + _mm_extract_epi32(count[j], 2) + _mm_extract_epi32(count[j], 3);\n                        int val_k = _mm_extract_epi32(count[k], 0) + _mm_extract_epi32(count[k], 1) + _mm_extract_epi32(count[k], 2) + _mm_extract_epi32(count[k], 3);\n                        result += (uint64_t)val_i * val_j * val_k;\n                    }\n                }\n            }\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_132_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nuint64_t get_max_triples_simd(uint64_t n){\n    if (n < 3) return 0;\n\n    __m128i count[3] = {_mm_setzero_si128(), _mm_setzero_si128(), _mm_setzero_si128()};\n    uint32_t a[4];\n    uint64_t result = 0;\n\n    for (uint64_t i = 0; i < n; ++i) {\n        a[0] = i * i - i + 1;\n        a[1] = (i + 1) * (i + 1) - (i + 1) + 1;\n        a[2] = (i + 2) * (i + 2) - (i + 2) + 1;\n        a[3] = (i + 3) * (i + 3) - (i + 3) + 1;\n\n        __m128i vec_a = _mm_loadu_si128((__m128i*)a);\n        __m128i mod3 = _mm_set_epi32(2, 1, 0, 2);\n        __m128i rem = _mm_rem_epu32(vec_a, _mm_set1_epi32(3));\n        __m128i mask = _mm_cmpeq_epi32(rem, mod3);\n\n        for (int j = 0; j < 4; ++j) {\n            if (i + j >= n) break;\n            int idx = (a[j] % 3);\n            count[idx] = _mm_add_epi32(count[idx], _mm_slli_epi32(_mm_and_si128(_mm_srli_epi32(mask, j * 4), _mm_set1_epi32(1)), 2 * j));\n        }\n    }\n\n    for (int i = 0; i < 3; ++i) {\n        for (int j = 0; j < 3; ++j) {\n            for (int k = 0; k < 3; ++k) {\n                if ((i + j + k) % 3 == 0) {\n                    __m128i prod = _mm_mullo_epi32(count[i], count[j]);\n                    prod = _mm_mullo_epi32(prod, count[k]);\n                    result += _mm_extract_epi32(prod, 0) + _mm_extract_epi32(prod, 1) + _mm_extract_epi32(prod, 2) + _mm_extract_epi32(prod, 3);\n                }\n            }\n        }\n    }\n\n    // Subtract overcounted triples\n    for (int i = 0; i < 3; ++i) {\n        __m128i comb = _mm_mullo_epi32(count[i], _mm_sub_epi32(count[i], _mm_set1_epi32(1)));\n        comb = _mm_srli_epi32(comb, 1);\n        comb = _mm_mullo_epi32(comb, _mm_sub_epi32(count[i], _mm_set1_epi32(2)));\n        comb = _mm_srli_epi32(comb, 2);\n        result -= _mm_extract_epi32(comb, 0) + _mm_extract_epi32(comb, 1) + _mm_extract_epi32(comb, 2) + _mm_extract_epi32(comb, 3);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_132_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nuint64_t get_max_triples_simd(uint64_t n){\n    if (n < 3) return 0;\n\n    __m128i count[3] = {_mm_setzero_si128(), _mm_setzero_si128(), _mm_setzero_si128()};\n    uint32_t a[4];\n    uint64_t result = 0;\n\n    for (uint64_t i = 0; i < n; ++i) {\n        a[0] = i * i - i + 1;\n        a[1] = (i + 1) * (i + 1) - (i + 1) + 1;\n        a[2] = (i + 2) * (i + 2) - (i + 2) + 1;\n        a[3] = (i + 3) * (i + 3) - (i + 3) + 1;\n\n        __m128i vec_a = _mm_loadu_si128(reinterpret_cast<const __m128i*>(a));\n        __m128i mod3 = _mm_set_epi32(2, 1, 0, 2);\n        __m128i rem = _mm_rem_epu32(vec_a, _mm_set1_epi32(3));\n\n        for (int j = 0; j < 4; ++j) {\n            int idx = rem.m128i_i32[j];\n            count[idx] = _mm_add_epi32(count[idx], _mm_set1_epi32(1));\n        }\n    }\n\n    for (int i = 0; i < 3; ++i) {\n        for (int j = i; j < 3; ++j) {\n            for (int k = j; k < 3; ++k) {\n                if ((i + j + k) % 3 == 0) {\n                    if (i == j && j == k) {\n                        uint32_t c = count[i].m128i_u32[0] + count[i].m128i_u32[1] + count[i].m128i_u32[2] + count[i].m128i_u32[3];\n                        result += static_cast<uint64_t>(c) * (c - 1) * (c - 2) / 6;\n                    } else if (i == j) {\n                        uint32_t ci = count[i].m128i_u32[0] + count[i].m128i_u32[1] + count[i].m128i_u32[2] + count[i].m128i_u32[3];\n                        uint32_t ck = count[k].m128i_u32[0] + count[k].m128i_u32[1] + count[k].m128i_u32[2] + count[k].m128i_u32[3];\n                        result += static_cast<uint64_t>(ci) * (ci - 1) / 2 * ck;\n                    } else if (j == k) {\n                        uint32_t ci = count[i].m128i_u32[0] + count[i].m128i_u32[1] + count[i].m128i_u32[2] + count[i].m128i_u32[3];\n                        uint32_t cj = count[j].m128i_u32[0] + count[j].m128i_u32[1] + count[j].m128i_u32[2] + count[j].m128i_u32[3];\n                        result += static_cast<uint64_t>(ci) * cj * (cj - 1) / 2;\n                    } else {\n                        uint32_t ci = count[i].m128i_u32[0] + count[i].m128i_u32[1] + count[i].m128i_u32[2] + count[i].m128i_u32[3];\n                        uint32_t cj = count[j].m128i_u32[0] + count[j].m128i_u32[1] + count[j].m128i_u32[2] + count[j].m128i_u32[3];\n                        uint32_t ck = count[k].m128i_u32[0] + count[k].m128i_u32[1] + count[k].m128i_u32[2] + count[k].m128i_u32[3];\n                        result += static_cast<uint64_t>(ci) * cj * ck;\n                    }\n                }\n            }\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_132_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nuint64_t get_max_triples_simd(uint64_t n){\n    if (n < 3) return 0;\n\n    __m128i count = _mm_setzero_si128();\n    int a[16] __attribute__((aligned(16)));\n    uint64_t result = 0;\n\n    for (uint64_t i = 0; i < n; ++i) {\n        a[i % 16] = i * i - i + 1;\n        if ((i + 1) % 16 == 0 || i == n - 1) {\n            for (uint64_t j = 0; j <= i; ++j) {\n                for (uint64_t k = j + 1; k <= i; ++k) {\n                    for (uint64_t l = k + 1; l <= i; ++l) {\n                        int sum = a[j % 16] + a[k % 16] + a[l % 16];\n                        if (sum % 3 == 0) {\n                            count = _mm_add_epi64(count, _mm_set_epi64x(0, 1));\n                        }\n                    }\n                }\n            }\n        }\n    }\n\n    result += _mm_extract_epi64(count, 0) + _mm_extract_epi64(count, 1);\n    return result;\n}\n```"}
{"task_id": "SimdBench_133_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint x_or_y_simd(int n, int x, int y) {\n    __m128i n_vec = _mm_set1_epi32(n);\n    __m128i zero = _mm_setzero_si128();\n    __m128i one = _mm_set1_epi32(1);\n    __m128i two = _mm_set1_epi32(2);\n    __m128i mask = _mm_cmpeq_epi32(n_vec, two);\n    __m128i result = _mm_blendv_epi8(_mm_set1_epi32(y), _mm_set1_epi32(x), mask);\n\n    for (int i = 3; i * i <= n; i += 2) {\n        __m128i divisor = _mm_set1_epi32(i);\n        __m128i remainder = _mm_rem_epi32(n_vec, divisor);\n        mask = _mm_cmpeq_epi32(remainder, zero);\n        result = _mm_blendv_epi8(result, _mm_set1_epi32(y), mask);\n    }\n\n    return _mm_extract_epi32(result, 0);\n}\n```"}
{"task_id": "SimdBench_133_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint x_or_y_simd(int n, int x, int y) {\n    __m128i n_vec = _mm_set1_epi32(n);\n    __m128i zero = _mm_setzero_si128();\n    __m128i one = _mm_set1_epi32(1);\n    __m128i two = _mm_set1_epi32(2);\n    __m128i max_n = _mm_set1_epi32(100); // Assuming n is less than 100 for simplicity\n    __m128i i = _mm_set_epi32(9, 8, 7, 6);\n    __m128i j = _mm_set_epi32(5, 4, 3, 2);\n\n    // Check if n is less than 2\n    __m128i is_less_than_two = _mm_cmplt_epi32(n_vec, two);\n    __m128i result = _mm_blendv_epi8(_mm_set1_epi32(y), _mm_set1_epi32(x), is_less_than_two);\n\n    // Check divisibility from 2 to sqrt(n)\n    while (_mm_movemask_epi8(_mm_cmpgt_epi32(i, zero))) {\n        __m128i div_result = _mm_div_epi32(n_vec, i);\n        __m128i remainder = _mm_sub_epi32(n_vec, _mm_mullo_epi32(div_result, i));\n        __m128i is_divisible = _mm_cmpeq_epi32(remainder, zero);\n        result = _mm_blendv_epi8(result, _mm_set1_epi32(y), is_divisible);\n\n        i = _mm_sub_epi32(i, four);\n        j = _mm_sub_epi32(j, four);\n        __m128i temp = i;\n        i = j;\n        j = temp;\n    }\n\n    return _mm_extract_epi32(result, 0);\n}\n```"}
{"task_id": "SimdBench_133_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint x_or_y_simd(int n, int x, int y) {\n    __m128i n_vec = _mm_set1_epi32(n);\n    __m128i x_vec = _mm_set1_epi32(x);\n    __m128i y_vec = _mm_set1_epi32(y);\n    __m128i result;\n\n    // Check for divisibility by 2 to 10 as a simple heuristic\n    __m128i divisors = _mm_setr_epi32(2, 3, 4, 5);\n    __m128i zero = _mm_setzero_si128();\n    __m128i mask = _mm_cmpeq_epi32(_mm_setzero_si128(), _mm_cmpeq_epi32(zero, _mm_srai_epi32(_mm_mullo_epi32(n_vec, _mm_div_epi32(n_vec, divisors)), 31)));\n\n    divisors = _mm_setr_epi32(6, 7, 8, 9);\n    mask = _mm_and_si128(mask, _mm_cmpeq_epi32(_mm_setzero_si128(), _mm_cmpeq_epi32(zero, _mm_srai_epi32(_mm_mullo_epi32(n_vec, _mm_div_epi32(n_vec, divisors)), 31))));\n\n    // Check if n is 1 or 0\n    mask = _mm_andnot_si128(_mm_cmpeq_epi32(n_vec, _mm_set1_epi32(1)), mask);\n    mask = _mm_andnot_si128(_mm_cmpeq_epi32(n_vec, _mm_set1_epi32(0)), mask);\n\n    // If mask is all zeros, n is prime\n    int mask_result = _mm_movemask_epi8(mask);\n    if (mask_result == 0xFFFF) {\n        result = x_vec;\n    } else {\n        result = y_vec;\n    }\n\n    return _mm_extract_epi32(result, 0);\n}\n```"}
{"task_id": "SimdBench_133_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint x_or_y_simd(int n, int x, int y) {\n    __m128i n_vec = _mm_set1_epi32(n);\n    __m128i x_vec = _mm_set1_epi32(x);\n    __m128i y_vec = _mm_set1_epi32(y);\n    __m128i result;\n\n    // Check for divisibility by 2 to 10 as a simple heuristic\n    __m128i divisors = _mm_setr_epi32(2, 3, 4, 5);\n    __m128i remainder = _mm_rem_epi32(n_vec, divisors);\n    __m128i mask = _mm_cmpeq_epi32(remainder, _mm_setzero_si128());\n\n    divisors = _mm_setr_epi32(6, 7, 8, 9);\n    remainder = _mm_rem_epi32(n_vec, divisors);\n    mask = _mm_or_si128(mask, _mm_cmpeq_epi32(remainder, _mm_setzero_si128()));\n\n    divisors = _mm_set1_epi32(10);\n    remainder = _mm_rem_epi32(n_vec, divisors);\n    mask = _mm_or_si128(mask, _mm_cmpeq_epi32(remainder, _mm_setzero_si128()));\n\n    // Check if n is less than 2\n    __m128i less_than_2 = _mm_cmplt_epi32(n_vec, _mm_set1_epi32(2));\n    mask = _mm_or_si128(mask, less_than_2);\n\n    // If any divisor divides n or n is less than 2, n is not prime\n    mask = _mm_or_si128(mask, _mm_slli_epi32(mask, 1));\n    mask = _mm_or_si128(mask, _mm_slli_epi32(mask, 2));\n\n    // Use mask to select between x and y\n    result = _mm_blendv_epi8(x_vec, y_vec, mask);\n\n    // Extract the result for the first element\n    return _mm_extract_epi32(result, 0);\n}\n```"}
{"task_id": "SimdBench_133_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint x_or_y_simd(int n, int x, int y) {\n    __m128i n_vec = _mm_set1_epi32(n);\n    __m128i x_vec = _mm_set1_epi32(x);\n    __m128i y_vec = _mm_set1_epi32(y);\n    __m128i result;\n\n    // Check if n is less than 2 (not prime)\n    __m128i less_than_2 = _mm_cmpgt_epi32(_mm_set1_epi32(1), n_vec);\n\n    // Check divisibility by 2\n    __m128i divisible_by_2 = _mm_cmpeq_epi32(_mm_and_si128(n_vec, _mm_set1_epi32(1)), _mm_setzero_si128());\n\n    // Check divisibility by numbers from 3 to sqrt(n)\n    __m128i i_vec = _mm_setr_epi32(3, 5, 7, 9);\n    __m128i not_prime = _mm_or_si128(less_than_2, divisible_by_2);\n    while (_mm_movemask_epi8(not_prime) != 0xFFFF) {\n        __m128i i_squared = _mm_mullo_epi32(i_vec, i_vec);\n        __m128i greater_than_sqrt_n = _mm_cmpgt_epi32(i_squared, n_vec);\n        __m128i divisible_by_i = _mm_cmpeq_epi32(_mm_and_si128(n_vec, i_vec), _mm_setzero_si128());\n        not_prime = _mm_or_si128(not_prime, _mm_andnot_si128(greater_than_sqrt_n, divisible_by_i));\n        i_vec = _mm_add_epi32(i_vec, _mm_set1_epi32(2));\n    }\n\n    // Select x or y based on primality\n    result = _mm_blendv_epi8(y_vec, x_vec, _mm_andnot_si128(not_prime, _mm_cmpeq_epi32(n_vec, _mm_set1_epi32(2))));\n\n    // Extract the result\n    return _mm_extract_epi32(result, 0);\n}\n```"}
{"task_id": "SimdBench_134_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nuint64_t double_the_difference_simd(const std::vector<float> & lst){\n    uint64_t sum = 0;\n    int n = lst.size();\n    int i = 0;\n\n    __m128 zero = _mm_setzero_ps();\n    __m128i one = _mm_set1_epi32(1);\n    __m128i two = _mm_set1_epi32(2);\n\n    while (i <= n - 4) {\n        __m128 vec = _mm_loadu_ps(&lst[i]);\n        __m128 mask_positive = _mm_cmpgt_ps(vec, zero);\n        __m128i vec_int = _mm_cvtps_epi32(vec);\n        __m128i mask_integer = _mm_cmpeq_epi32(_mm_cvtepi32_ps(vec_int), vec);\n        __m128i mask_odd = _mm_and_si128(mask_integer, _mm_cmpeq_epi32(_mm_and_si128(vec_int, one), one));\n        __m128i mask_final = _mm_and_si128(mask_positive, mask_odd);\n        __m128 masked_vec = _mm_and_ps(vec, _mm_castsi128_ps(mask_final));\n        __m128 squared = _mm_mul_ps(masked_vec, masked_vec);\n        __m128i squared_int = _mm_cvtps_epi32(squared);\n        __m128i even_squared = _mm_and_si128(squared_int, _mm_cmpeq_epi32(_mm_and_si128(squared_int, two), zero));\n        __m128i odd_squared = _mm_sub_epi32(squared_int, even_squared);\n        sum += _mm_extract_epi32(odd_squared, 0);\n        sum += _mm_extract_epi32(odd_squared, 1);\n        sum += _mm_extract_epi32(odd_squared, 2);\n        sum += _mm_extract_epi32(odd_squared, 3);\n        i += 4;\n    }\n\n    for (; i < n; ++i) {\n        float val = lst[i];\n        if (val > 0 && val == static_cast<int>(val) && static_cast<int>(val) % 2 != 0) {\n            sum += static_cast<uint64_t>(val * val);\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_134_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nuint64_t double_the_difference_simd(const std::vector<float> & lst){\n    uint64_t sum = 0;\n    int n = lst.size();\n    int i = 0;\n\n    __m128 zero = _mm_setzero_ps();\n    __m128i one = _mm_set1_epi32(1);\n    __m128i two = _mm_set1_epi32(2);\n\n    for (; i <= n - 4; i += 4) {\n        __m128 vec = _mm_loadu_ps(&lst[i]);\n        __m128 mask_positive = _mm_cmpgt_ps(vec, zero);\n        __m128i vec_int = _mm_cvtps_epi32(vec);\n        __m128i mask_integer = _mm_cmpeq_epi32(_mm_cvtepi32_ps(vec_int), vec);\n        __m128i mask_odd = _mm_and_si128(mask_integer, _mm_cmpeq_epi32(_mm_and_si128(vec_int, one), one));\n        __m128i mask_combined = _mm_and_si128(mask_positive, mask_odd);\n        __m128i vec_squared = _mm_mullo_epi32(vec_int, vec_int);\n        __m128i vec_masked = _mm_and_si128(vec_squared, mask_combined);\n        sum += _mm_extract_epi32(vec_masked, 0);\n        sum += _mm_extract_epi32(vec_masked, 1);\n        sum += _mm_extract_epi32(vec_masked, 2);\n        sum += _mm_extract_epi32(vec_masked, 3);\n    }\n\n    for (; i < n; ++i) {\n        float val = lst[i];\n        if (val > 0 && val == static_cast<int>(val) && static_cast<int>(val) % 2 != 0) {\n            sum += static_cast<uint64_t>(val) * static_cast<uint64_t>(val);\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_134_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nuint64_t double_the_difference_simd(const std::vector<float> & lst){\n    uint64_t sum = 0;\n    int n = lst.size();\n    int i = 0;\n\n    __m128i zero = _mm_setzero_si128();\n    __m128 one = _mm_set1_ps(1.0f);\n\n    for (; i <= n - 4; i += 4) {\n        __m128 vec = _mm_loadu_ps(&lst[i]);\n        __m128 abs_vec = _mm_andnot_ps(_mm_set1_ps(-0.0f), vec);\n        __m128 mask = _mm_cmpgt_ps(abs_vec, _mm_setzero_ps());\n        __m128i int_vec = _mm_cvtps_epi32(vec);\n        __m128i abs_int_vec = _mm_abs_epi32(int_vec);\n        __m128i odd_mask = _mm_and_si128(_mm_cmpeq_epi32(_mm_and_si128(abs_int_vec, one), one), mask);\n        __m128 odd_vec = _mm_and_ps(_mm_castsi128_ps(odd_mask), vec);\n        __m128 square_vec = _mm_mul_ps(odd_vec, odd_vec);\n        __m128i square_int_vec = _mm_cvtps_epi32(square_vec);\n        __m128i horizontal_sum = _mm_hadd_epi32(square_int_vec, square_int_vec);\n        horizontal_sum = _mm_hadd_epi32(horizontal_sum, horizontal_sum);\n        sum += _mm_cvtsi128_si32(horizontal_sum);\n    }\n\n    for (; i < n; ++i) {\n        float num = lst[i];\n        if (num >= 0 && num == static_cast<int>(num) && static_cast<int>(num) % 2 != 0) {\n            sum += static_cast<uint64_t>(num * num);\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_134_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nuint64_t double_the_difference_simd(const std::vector<float> & lst){\n    uint64_t sum = 0;\n    int n = lst.size();\n    int i = 0;\n\n    __m128i zero = _mm_setzero_si128();\n    __m128 one = _mm_set1_ps(1.0f);\n\n    while (i <= n - 4) {\n        __m128 vec = _mm_loadu_ps(&lst[i]);\n        __m128i intVec = _mm_cvtps_epi32(vec);\n        __m128i absVec = _mm_abs_epi32(intVec);\n        __m128i isOdd = _mm_and_si128(_mm_cmpeq_epi32(_mm_and_si128(absVec, one), one), _mm_cmpgt_epi32(intVec, zero));\n        __m128 mask = _mm_castsi128_ps(isOdd);\n        __m128 squared = _mm_mul_ps(vec, vec);\n        __m128 maskedSquared = _mm_and_ps(mask, squared);\n        __m128i sumVec = _mm_cvtps_epi32(maskedSquared);\n        sum += _mm_extract_epi32(sumVec, 0) + _mm_extract_epi32(sumVec, 1) + _mm_extract_epi32(sumVec, 2) + _mm_extract_epi32(sumVec, 3);\n        i += 4;\n    }\n\n    while (i < n) {\n        if (lst[i] > 0 && static_cast<int>(lst[i]) % 2 != 0) {\n            sum += static_cast<uint64_t>(lst[i]) * static_cast<uint64_t>(lst[i]);\n        }\n        i++;\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_134_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nuint64_t double_the_difference_simd(const std::vector<float> & lst){\n    uint64_t sum = 0;\n    int n = lst.size();\n    int i = 0;\n\n    __m128 zero = _mm_setzero_ps();\n    __m128i one = _mm_set1_epi32(1);\n\n    for (; i <= n - 4; i += 4) {\n        __m128 vec = _mm_loadu_ps(&lst[i]);\n        __m128 mask_positive = _mm_cmpgt_ps(vec, zero);\n        __m128 masked_vec = _mm_and_ps(mask_positive, vec);\n\n        __m128i int_vec = _mm_cvtps_epi32(masked_vec);\n        __m128i mask_integers = _mm_cmpeq_epi32(_mm_cvtps_epi32(masked_vec), int_vec);\n        __m128i masked_integers = _mm_and_si128(mask_integers, int_vec);\n\n        __m128i mask_odds = _mm_and_si128(masked_integers, one);\n        __m128i odds = _mm_and_si128(mask_odds, masked_integers);\n\n        __m128i squares = _mm_mullo_epi32(odds, odds);\n        __m128i sum_squares = _mm_add_epi32(squares, _mm_srli_si128(squares, 8));\n        sum_squares = _mm_add_epi32(sum_squares, _mm_srli_si128(sum_squares, 4));\n\n        sum += _mm_cvtsi128_si32(sum_squares);\n    }\n\n    for (; i < n; ++i) {\n        float num = lst[i];\n        if (num > 0 && num == static_cast<int>(num)) {\n            int int_num = static_cast<int>(num);\n            if (int_num % 2 != 0) {\n                sum += int_num * int_num;\n            }\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_135_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> compare_simd(const std::vector<int>& game, const std::vector<int>& guess){\n    std::vector<int> result(game.size());\n    int n = game.size();\n    int i = 0;\n\n    for (; i <= n - 4; i += 4) {\n        __m128i game_vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&game[i]));\n        __m128i guess_vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&guess[i]));\n        __m128i diff_vec = _mm_sub_epi32(game_vec, guess_vec);\n        __m128i abs_diff_vec = _mm_abs_epi32(diff_vec);\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i]), abs_diff_vec);\n    }\n\n    for (; i < n; ++i) {\n        result[i] = (game[i] == guess[i]) ? 0 : std::abs(game[i] - guess[i]);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_135_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> compare_simd(const std::vector<int>& game, const std::vector<int>& guess){\n    std::vector<int> result(game.size());\n    int n = game.size();\n    int i = 0;\n\n    for (; i <= n - 4; i += 4) {\n        __m128i game_vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&game[i]));\n        __m128i guess_vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&guess[i]));\n        __m128i diff_vec = _mm_sub_epi32(game_vec, guess_vec);\n        __m128i abs_diff_vec = _mm_abs_epi32(diff_vec);\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i]), abs_diff_vec);\n    }\n\n    for (; i < n; ++i) {\n        result[i] = (game[i] == guess[i]) ? 0 : std::abs(game[i] - guess[i]);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_135_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> compare_simd(const std::vector<int>& game, const std::vector<int>& guess){\n    std::vector<int> result(game.size());\n    int n = game.size();\n    int i = 0;\n\n    for (; i <= n - 4; i += 4) {\n        __m128i game_vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&game[i]));\n        __m128i guess_vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&guess[i]));\n        __m128i diff_vec = _mm_abs_epi32(_mm_sub_epi32(game_vec, guess_vec));\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i]), diff_vec);\n    }\n\n    for (; i < n; ++i) {\n        result[i] = (game[i] == guess[i]) ? 0 : std::abs(game[i] - guess[i]);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_135_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> compare_simd(const std::vector<int>& game, const std::vector<int>& guess) {\n    std::vector<int> result(game.size());\n    int n = game.size();\n    int i = 0;\n\n    for (; i <= n - 4; i += 4) {\n        __m128i game_vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&game[i]));\n        __m128i guess_vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&guess[i]));\n        __m128i diff_vec = _mm_sub_epi32(game_vec, guess_vec);\n        __m128i abs_diff_vec = _mm_abs_epi32(diff_vec);\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i]), abs_diff_vec);\n    }\n\n    for (; i < n; ++i) {\n        result[i] = (game[i] == guess[i]) ? 0 : std::abs(game[i] - guess[i]);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_135_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> compare_simd(const std::vector<int>& game, const std::vector<int>& guess) {\n    std::vector<int> result(game.size());\n    int n = game.size();\n    int i = 0;\n\n    for (; i <= n - 4; i += 4) {\n        __m128i game_vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&game[i]));\n        __m128i guess_vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&guess[i]));\n        __m128i diff_vec = _mm_sub_epi32(game_vec, guess_vec);\n        __m128i abs_diff_vec = _mm_abs_epi32(diff_vec);\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i]), abs_diff_vec);\n    }\n\n    for (; i < n; ++i) {\n        result[i] = (game[i] == guess[i]) ? 0 : std::abs(game[i] - guess[i]);\n    }\n\n    return result;\n}\n```"}

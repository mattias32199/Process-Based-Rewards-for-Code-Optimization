{"task_id": "SimdBench_0_Neon", "completion": "```cpp\nvoid conditional_move_simd(const int64_t *src, int64_t *dst, const bool *mask, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 4; i += 4) {\n        int64x2_t vsrc1 = vld1q_s64(src + i);\n        int64x2_t vsrc2 = vld1q_s64(src + i + 2);\n        uint8x16_t vmask1 = vreinterpretq_u8_u32(vmovl_u16(vreinterpret_u16_u8(vld1q_u8(mask + i))));\n        uint8x16_t vmask2 = vreinterpretq_u8_u32(vmovl_u16(vreinterpret_u16_u8(vld1q_u8(mask + i + 2))));\n        int64x2_t vdst1 = vld1q_s64(dst + i);\n        int64x2_t vdst2 = vld1q_s64(dst + i + 2);\n\n        vdst1 = vbslq_s64(vmask1, vsrc1, vdst1);\n        vdst2 = vbslq_s64(vmask2, vsrc2, vdst2);\n\n        vst1q_s64(dst + i, vdst1);\n        vst1q_s64(dst + i + 2, vdst2);\n    }\n\n    // Handle remaining elements\n    for (; i < length; ++i) {\n        if (mask[i]) {\n            dst[i] = src[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_0_Neon", "completion": "```cpp\nvoid conditional_move_simd(const int64_t *src, int64_t *dst, const bool *mask, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 4; i += 4) {\n        int64x2_t vsrc1 = vld1q_s64(src + i);\n        int64x2_t vsrc2 = vld1q_s64(src + i + 2);\n        uint8x16_t vmask1 = vreinterpretq_u8_u32(vmovl_u16(vreinterpret_u16_u8(vld1q_u8(mask + i))));\n        uint8x16_t vmask2 = vreinterpretq_u8_u32(vmovl_u16(vreinterpret_u16_u8(vld1q_u8(mask + i + 2))));\n        int64x2_t vdst1 = vld1q_s64(dst + i);\n        int64x2_t vdst2 = vld1q_s64(dst + i + 2);\n\n        vdst1 = vbslq_s64(vmask1, vsrc1, vdst1);\n        vdst2 = vbslq_s64(vmask2, vsrc2, vdst2);\n\n        vst1q_s64(dst + i, vdst1);\n        vst1q_s64(dst + i + 2, vdst2);\n    }\n\n    // Handle remaining elements\n    for (; i < length; ++i) {\n        if (mask[i]) {\n            dst[i] = src[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_0_Neon", "completion": "```cpp\nvoid conditional_move_simd(const int64_t *src, int64_t *dst, const bool *mask, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 4; i += 4) {\n        int64x2_t vsrc1 = vld1q_s64(src + i);\n        int64x2_t vsrc2 = vld1q_s64(src + i + 2);\n        uint8x16_t vmask1 = vreinterpretq_u8_u32(vmovl_u16(vreinterpret_u16_u8(vld1q_u8(mask + i))));\n        uint8x16_t vmask2 = vreinterpretq_u8_u32(vmovl_u16(vreinterpret_u16_u8(vld1q_u8(mask + i + 2))));\n        int64x2_t vdst1 = vld1q_s64(dst + i);\n        int64x2_t vdst2 = vld1q_s64(dst + i + 2);\n\n        vdst1 = vbslq_s64(vmask1, vsrc1, vdst1);\n        vdst2 = vbslq_s64(vmask2, vsrc2, vdst2);\n\n        vst1q_s64(dst + i, vdst1);\n        vst1q_s64(dst + i + 2, vdst2);\n    }\n\n    // Handle remaining elements\n    for (; i < length; ++i) {\n        if (mask[i]) {\n            dst[i] = src[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_0_Neon", "completion": "```cpp\nvoid conditional_move_simd(const int64_t *src, int64_t *dst, const bool *mask, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 4; i += 4) {\n        int64x2_t vsrc1 = vld1q_s64(src + i);\n        int64x2_t vsrc2 = vld1q_s64(src + i + 2);\n        uint8x16_t vmask1 = vreinterpretq_u8_u32(vmovl_u16(vreinterpret_u16_u8(vld1q_u8(mask + i))));\n        uint8x16_t vmask2 = vreinterpretq_u8_u32(vmovl_u16(vreinterpret_u16_u8(vld1q_u8(mask + i + 2))));\n        int64x2_t vdst1 = vld1q_s64(dst + i);\n        int64x2_t vdst2 = vld1q_s64(dst + i + 2);\n\n        vdst1 = vbslq_s64(vreinterpretq_s64_u8(vmask1), vsrc1, vdst1);\n        vdst2 = vbslq_s64(vreinterpretq_s64_u8(vmask2), vsrc2, vdst2);\n\n        vst1q_s64(dst + i, vdst1);\n        vst1q_s64(dst + i + 2, vdst2);\n    }\n\n    for (; i < length; ++i) {\n        if (mask[i]) {\n            dst[i] = src[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_0_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nvoid conditional_move_simd(const int64_t *src, int64_t *dst, const bool *mask, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 4; i += 4) {\n        int64x2_t vsrc1 = vld1q_s64(src + i);\n        int64x2_t vsrc2 = vld1q_s64(src + i + 2);\n        uint8x16_t vmask1 = vreinterpretq_u8_u32(vmovl_u16(vreinterpret_u16_u8(vld1q_u8(mask + i))));\n        uint8x16_t vmask2 = vreinterpretq_u8_u32(vmovl_u16(vreinterpret_u16_u8(vld1q_u8(mask + i + 2))));\n        int64x2_t vdst1 = vld1q_s64(dst + i);\n        int64x2_t vdst2 = vld1q_s64(dst + i + 2);\n\n        vdst1 = vbslq_s64(vmask1, vsrc1, vdst1);\n        vdst2 = vbslq_s64(vmask2, vsrc2, vdst2);\n\n        vst1q_s64(dst + i, vdst1);\n        vst1q_s64(dst + i + 2, vdst2);\n    }\n\n    for (; i < length; ++i) {\n        if (mask[i]) {\n            dst[i] = src[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_1_Neon", "completion": "```cpp\nvoid load_modify_store_simd(const int *src, int *dst, int scale, size_t length) {\n    const int32x4_t v_scale = vmovq_n_s32(scale);\n    const int32x4_t v_7 = vmovq_n_s32(7);\n\n    for (size_t i = 0; i <= length - 4; i += 4) {\n        int32x4_t v_src = vld1q_s32(src + i);\n        int32x4_t v_tmp1 = vshrq_n_s32(v_mulq_s32(v_src, v_scale), 3);\n        int32x4_t v_tmp2 = vshlq_n_s32(v_mulq_s32(v_src, v_scale), 3);\n        int32x4_t v_result = vdivq_s32(v_addq_s32(v_mulq_s32(v_src, v_scale), vmulq_s32(v_tmp1, v_tmp2)), v_7);\n        vst1q_s32(dst + i, v_result);\n    }\n\n    // Handle remaining elements\n    for (size_t i = length - length % 4; i < length; ++i) {\n        int32_t src_val = src[i];\n        int32_t tmp1 = (src_val * scale) >> 3;\n        int32_t tmp2 = (src_val * scale) << 3;\n        int32_t result = (src_val * scale + tmp1 * tmp2) / 7;\n        dst[i] = result;\n    }\n}\n```"}
{"task_id": "SimdBench_1_Neon", "completion": "```cpp\nvoid load_modify_store_simd(const int *src, int *dst, int scale, size_t length) {\n    const int32x4_t v_scale = vmovq_n_s32(scale);\n    const int32x4_t v_7 = vmovq_n_s32(7);\n\n    for (size_t i = 0; i <= length - 4; i += 4) {\n        int32x4_t v_src = vld1q_s32(src + i);\n\n        int32x4_t v_tmp1 = vshrq_n_s32(v_mulq_s32(v_src, v_scale), 3);\n        int32x4_t v_tmp2 = vshlq_n_s32(v_mulq_s32(v_src, v_scale), 3);\n\n        int32x4_t v_result = vdivq_s32(v_addq_s32(v_mulq_s32(v_src, v_scale), vmulq_s32(v_tmp1, v_tmp2)), v_7);\n\n        vst1q_s32(dst + i, v_result);\n    }\n\n    // Handle remaining elements\n    for (size_t i = length - length % 4; i < length; ++i) {\n        int32_t element = src[i];\n        int32_t tmp1 = (element * scale) >> 3;\n        int32_t tmp2 = (element * scale) << 3;\n        int32_t result = (element * scale + tmp1 * tmp2) / 7;\n        dst[i] = result;\n    }\n}\n```"}
{"task_id": "SimdBench_1_Neon", "completion": "```cpp\nvoid load_modify_store_simd(const int *src, int *dst, int scale, size_t length) {\n    const int32x4_t v_scale = vmovq_n_s32(scale);\n    const int32x4_t v_7 = vmovq_n_s32(7);\n\n    for (size_t i = 0; i <= length - 4; i += 4) {\n        int32x4_t v_src = vld1q_s32(src + i);\n        int32x4_t v_tmp1 = vshrq_n_s32(v_mulq_s32(v_src, v_scale), 3);\n        int32x4_t v_tmp2 = vshlq_n_s32(v_mulq_s32(v_src, v_scale), 3);\n        int64x4_t v_result = vmlal_s32(vmovq_n_s64(0), v_tmp1, v_tmp2);\n        vst1q_s32(dst + i, vdivq_s32(vaddq_s32(v_mulq_s32(v_src, v_scale), vreinterpretq_s32_s64(v_result)), v_7));\n    }\n\n    // Handle remaining elements\n    for (size_t i = length - length % 4; i < length; ++i) {\n        int32_t element = src[i];\n        int32_t tmp1 = (element * scale) >> 3;\n        int32_t tmp2 = (element * scale) << 3;\n        int32_t result = ((element * scale) + tmp1 * tmp2) / 7;\n        dst[i] = result;\n    }\n}\n```"}
{"task_id": "SimdBench_1_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid load_modify_store_simd(const int *src, int *dst, int scale, size_t length) {\n    const int32x4_t v_scale = vmovq_n_s32(scale);\n    const int32x4_t v_7 = vmovq_n_s32(7);\n\n    for (size_t i = 0; i <= length - 4; i += 4) {\n        int32x4_t v_src = vld1q_s32(src + i);\n        int32x4_t v_tmp1 = vshrq_n_s32(v_mulq_s32(v_src, v_scale), 3);\n        int32x4_t v_tmp2 = vshlq_n_s32(v_mulq_s32(v_src, v_scale), 3);\n        int64x4_t v_result = vaddq_s64(vmull_high_s32(v_tmp1, v_tmp2), vmull_low_s32(v_tmp1, v_tmp2));\n        vst1q_s32(dst + i, vdivq_s32(v_addq_s32(v_result, vdupq_n_s64(length)), v_7));\n    }\n\n    // Handle remaining elements\n    for (size_t i = length - length % 4; i < length; ++i) {\n        int32_t element = src[i];\n        int32_t tmp1 = (element * scale) >> 3;\n        int32_t tmp2 = (element * scale) << 3;\n        int32_t result = (element * scale + tmp1 * tmp2) / 7;\n        dst[i] = result;\n    }\n}\n```"}
{"task_id": "SimdBench_1_Neon", "completion": "```cpp\nvoid load_modify_store_simd(const int *src, int *dst, int scale, size_t length) {\n    const int32x4_t v_scale = vmovq_n_s32(scale);\n    const int32x4_t v_7 = vmovq_n_s32(7);\n\n    for (size_t i = 0; i <= length - 4; i += 4) {\n        int32x4_t v_src = vld1q_s32(src + i);\n        int32x4_t v_tmp1 = vshrq_n_s32(v_mulq_s32(v_src, v_scale), 3);\n        int32x4_t v_tmp2 = vshlq_n_s32(v_mulq_s32(v_src, v_scale), 3);\n        int64x2_t v_result = vaddq_s64(vmull_high_s32(v_tmp1, v_tmp2), vmull_low_s32(v_tmp1, v_tmp2));\n        vst1q_s32(dst + i, vdivq_s32(vaddq_s32(v_result, vdupq_n_s64(length)), v_7));\n    }\n\n    // Handle remaining elements\n    for (size_t i = length - length % 4; i < length; ++i) {\n        int tmp1 = (src[i] * scale) >> 3;\n        int tmp2 = (src[i] * scale) << 3;\n        dst[i] = ((src[i] * scale + tmp1 * tmp2) / 7);\n    }\n}\n```"}
{"task_id": "SimdBench_2_Neon", "completion": "```cpp\nvoid strided_load_store_simd(const double *src, double *dst, size_t rows, size_t cols, size_t stride) {\n    for (size_t r = 0; r < rows; ++r) {\n        double32x2_t vec = vld1q_f32((const float32_t *)(src + r * cols + stride));\n        vst1q_f32((float32_t *)(dst + r), vec);\n    }\n}\n```"}
{"task_id": "SimdBench_2_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nvoid strided_load_store_simd(const double *src, double *dst, size_t rows, size_t cols, size_t stride) {\n    const double32x2_t stride_vec = vdupq_n_f32(static_cast<float>(stride));\n    for (size_t r = 0; r < rows; ++r) {\n        const double32x2_t src_val = vld1q_f32(reinterpret_cast<const float*>(&src[r * cols]));\n        vst1q_f32(reinterpret_cast<float*>(&dst[r]), src_val);\n    }\n}\n```"}
{"task_id": "SimdBench_2_Neon", "completion": "```cpp\nvoid strided_load_store_simd(const double *src, double *dst, size_t rows, size_t cols, size_t stride) {\n    for (size_t r = 0; r < rows; ++r) {\n        double32x2_t vec = vld1q_f32((const float32_t *)(src + r * cols + stride));\n        vst1q_f32((float32_t *)(dst + r), vec);\n    }\n}\n```"}
{"task_id": "SimdBench_2_Neon", "completion": "```cpp\nvoid strided_load_store_simd(const double *src, double *dst, size_t rows, size_t cols, size_t stride) {\n    for (size_t r = 0; r < rows; ++r) {\n        double32x2_t vec = vld1q_f32((const float32_t *)(src + r * cols + stride));\n        vst1q_f32((float32_t *)(dst + r), vec);\n    }\n}\n```"}
{"task_id": "SimdBench_2_Neon", "completion": "```cpp\nvoid strided_load_store_simd(const double *src, double *dst, size_t rows, size_t cols, size_t stride) {\n    size_t i;\n    for (i = 0; i < rows; i++) {\n        double32x2_t v = vld1_f32((const float32_t *)(src + i * cols + stride));\n        vst1_f32((float32_t *)(dst + i), v);\n    }\n}\n```"}
{"task_id": "SimdBench_3_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nvoid indexed_access_simd(const float *src, const int *indices, float *dst, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 4; i += 4) {\n        float32x4_t vsrc1 = vld1q_f32(src + i);\n        float32x4_t vsrc2 = vld1q_f32(src + i + 4);\n        int32x4_t vidx1 = vld1q_s32(indices + i);\n        int32x4_t vidx2 = vld1q_s32(indices + i + 4);\n\n        vst1q_lane_f32(vsrc1[0], dst, vidx1[0]);\n        vst1q_lane_f32(vsrc1[1], dst, vidx1[1]);\n        vst1q_lane_f32(vsrc1[2], dst, vidx1[2]);\n        vst1q_lane_f32(vsrc1[3], dst, vidx1[3]);\n\n        vst1q_lane_f32(vsrc2[0], dst, vidx2[0]);\n        vst1q_lane_f32(vsrc2[1], dst, vidx2[1]);\n        vst1q_lane_f32(vsrc2[2], dst, vidx2[2]);\n        vst1q_lane_f32(vsrc2[3], dst, vidx2[3]);\n    }\n\n    for (; i < length; ++i) {\n        dst[indices[i]] = src[i];\n    }\n}\n```"}
{"task_id": "SimdBench_3_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid indexed_access_simd(const float *src, const int *indices, float *dst, size_t length) {\n    size_t i;\n    for (i = 0; i <= length - 4; i += 4) {\n        float32x4_t vsrc1 = vld1q_f32(src + i);\n        float32x4_t vsrc2 = vld1q_f32(src + i + 4);\n        int32x4_t vidx1 = vld1q_s32(indices + i);\n        int32x4_t vidx2 = vld1q_s32(indices + i + 4);\n\n        vst1q_lane_f32(vsrc1[0], dst, vidx1[0]);\n        vst1q_lane_f32(vsrc1[1], dst, vidx1[1]);\n        vst1q_lane_f32(vsrc1[2], dst, vidx1[2]);\n        vst1q_lane_f32(vsrc1[3], dst, vidx1[3]);\n\n        vst1q_lane_f32(vsrc2[0], dst, vidx2[0]);\n        vst1q_lane_f32(vsrc2[1], dst, vidx2[1]);\n        vst1q_lane_f32(vsrc2[2], dst, vidx2[2]);\n        vst1q_lane_f32(vsrc2[3], dst, vidx2[3]);\n    }\n\n    // Handle remaining elements\n    for (; i < length; ++i) {\n        dst[indices[i]] = src[i];\n    }\n}\n```"}
{"task_id": "SimdBench_3_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nvoid indexed_access_simd(const float *src, const int *indices, float *dst, size_t length) {\n    for (size_t i = 0; i < length; i += 4) {\n        float32x4_t v_src = vld1q_f32(src + i);\n        int32x4_t v_indices = vld1q_s32(indices + i);\n\n        // Gather operation\n        float32x4_t v_gathered = vtbl1q_f32(vld1q_f32(src), v_indices);\n\n        // Scatter operation\n        vst1q_f32(dst + i, v_gathered);\n    }\n}\n```"}
{"task_id": "SimdBench_3_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nvoid indexed_access_simd(const float *src, const int *indices, float *dst, size_t length) {\n    for (size_t i = 0; i < length; i += 4) {\n        float32x4_t vsrc1 = vld1q_f32(src + i);\n        int32x4_t vidx1 = vld1q_s32(indices + i);\n\n        // Gather operation\n        float32x4_t vgather1 = vtbl1q_f32(vsrc1, vidx1);\n\n        // Scatter operation\n        vst1q_f32(dst + i, vgather1);\n    }\n}\n```"}
{"task_id": "SimdBench_3_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid indexed_access_simd(const float *src, const int *indices, float *dst, size_t length) {\n    for (size_t i = 0; i < length; i += 4) {\n        float32x4_t vsrc1 = vld1q_f32(src + i);\n        int32x4_t vidx1 = vld1q_s32(indices + i);\n\n        // Gather operation\n        float32x4_t vgather1 = vtbl1q_f32(vsrc1, vidx1);\n\n        // Scatter operation\n        vst1q_f32(dst + i, vgather1);\n    }\n}\n```"}
{"task_id": "SimdBench_4_Neon", "completion": "```cpp\nvoid range_reverse_simd(int16_t *arr, uint64_t start, uint64_t end) {\n    int16x8_t v0, v1;\n    int16_t temp;\n\n    while (start < end) {\n        v0 = vld1q_s16(arr + start);\n        v1 = vld1q_s16(arr + end);\n\n        vst1q_s16(arr + start, v1);\n        vst1q_s16(arr + end, v0);\n\n        temp = arr[start];\n        arr[start] = arr[end];\n        arr[end] = temp;\n\n        start++;\n        end--;\n    }\n}\n```"}
{"task_id": "SimdBench_4_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid range_reverse_simd(int16_t *arr, uint64_t start, uint64_t end) {\n    int16x8_t v0, v1;\n    int16_t temp;\n\n    while (start + 7 <= end) {\n        v0 = vld1q_s16(arr + start);\n        v1 = vld1q_s16(arr + end);\n\n        vst1q_s16(arr + start, v1);\n        vst1q_s16(arr + end, v0);\n\n        start += 8;\n        end -= 8;\n    }\n\n    if (start == end) {\n        return;\n    }\n\n    for (; start < end; start++, end--) {\n        temp = arr[start];\n        arr[start] = arr[end];\n        arr[end] = temp;\n    }\n}\n```"}
{"task_id": "SimdBench_4_Neon", "completion": "```cpp\nvoid range_reverse_simd(int16_t *arr, uint64_t start, uint64_t end) {\n    int16x8_t v0, v1;\n    int16_t temp;\n\n    while (start < end) {\n        v0 = vld1q_s16(arr + start);\n        v1 = vld1q_s16(arr + end);\n\n        vst1q_s16(arr + start, v1);\n        vst1q_s16(arr + end, v0);\n\n        temp = arr[start];\n        arr[start] = arr[end];\n        arr[end] = temp;\n\n        start += 8;\n        end -= 8;\n    }\n}\n```"}
{"task_id": "SimdBench_4_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid range_reverse_simd(int16_t *arr, uint64_t start, uint64_t end) {\n    int16x8_t v0, v1;\n    int16_t temp;\n\n    while (start + 7 <= end) {\n        v0 = vld1q_s16(arr + start);\n        v1 = vld1q_s16(arr + end);\n\n        vst1q_s16(arr + start, v1);\n        vst1q_s16(arr + end, v0);\n\n        start += 8;\n        end -= 8;\n    }\n\n    // Handle remaining elements\n    while (start < end) {\n        temp = arr[start];\n        arr[start] = arr[end];\n        arr[end] = temp;\n        start++;\n        end--;\n    }\n}\n```"}
{"task_id": "SimdBench_4_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nvoid range_reverse_simd(int16_t *arr, uint64_t start, uint64_t end) {\n    int16x8_t v0, v1;\n    int16_t temp;\n\n    while (start + 7 <= end) {\n        v0 = vld1q_s16(arr + start);\n        v1 = vld1q_s16(arr + end);\n\n        vst1q_s16(arr + start, v1);\n        vst1q_s16(arr + end, v0);\n\n        start += 8;\n        end -= 8;\n    }\n\n    // Handle remaining elements\n    while (start < end) {\n        temp = arr[start];\n        arr[start] = arr[end];\n        arr[end] = temp;\n        start++;\n        end--;\n    }\n}\n```"}
{"task_id": "SimdBench_5_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nvoid extract_tensor_slice_simd(const uint8_t *tensor, uint8_t *slice, size_t dim1, size_t dim2, size_t dim3, size_t slice_idx) {\n    size_t offset = slice_idx * dim1 * dim2;\n    const uint8_t *src = tensor + offset;\n\n    for (size_t i = 0; i < dim1; ++i) {\n        for (size_t j = 0; j < dim2 / 4; ++j) {\n            vst1q_u8(slice + (i * dim2 + j * 4), vld1q_u8(src + (i * dim2 + j * 4)));\n        }\n        if (dim2 % 4 != 0) {\n            for (size_t k = dim2 - dim2 % 4; k < dim2; ++k) {\n                slice[i * dim2 + k] = src[i * dim2 + k];\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_5_Neon", "completion": "```cpp\nvoid extract_tensor_slice_simd(const uint8_t *tensor, uint8_t *slice, size_t dim1, size_t dim2, size_t dim3, size_t slice_idx) {\n    const size_t slice_size = dim1 * dim2;\n    const size_t slice_offset = slice_idx * slice_size;\n\n    for (size_t i = 0; i < slice_size; i += 16) {\n        uint8x16_t v = vld1q_u8(tensor + slice_offset + i);\n        vst1q_u8(slice + i, v);\n    }\n}\n```"}
{"task_id": "SimdBench_5_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nvoid extract_tensor_slice_simd(const uint8_t *tensor, uint8_t *slice, size_t dim1, size_t dim2, size_t dim3, size_t slice_idx) {\n    const size_t slice_offset = slice_idx * dim1 * dim2;\n    const size_t row_size = dim1 * sizeof(uint8_t);\n\n    for (size_t i = 0; i < dim2; ++i) {\n        const uint8_t *row_start = tensor + slice_offset + i * row_size;\n        uint8x16_t v0, v1, v2, v3;\n\n        for (size_t j = 0; j <= dim1 - 16; j += 16) {\n            v0 = vld1q_u8(row_start + j);\n            v1 = vld1q_u8(row_start + j + 16);\n            v2 = vld1q_u8(row_start + j + 32);\n            v3 = vld1q_u8(row_start + j + 48);\n\n            vst1q_u8(slice + j, v0);\n            vst1q_u8(slice + j + 16, v1);\n            vst1q_u8(slice + j + 32, v2);\n            vst1q_u8(slice + j + 48, v3);\n        }\n\n        // Handle remaining elements\n        for (size_t j = dim1 - dim1 % 16; j < dim1; ++j) {\n            slice[j] = row_start[j];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_5_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nvoid extract_tensor_slice_simd(const uint8_t *tensor, uint8_t *slice, size_t dim1, size_t dim2, size_t dim3, size_t slice_idx) {\n    size_t offset = slice_idx * dim1 * dim2;\n    const uint8_t *src = tensor + offset;\n\n    for (size_t i = 0; i < dim1; ++i) {\n        for (size_t j = 0; j < dim2; j += 16) {\n            uint8x16_t v0 = vld1q_u8(src + i * dim2 * dim3 + j * dim3);\n            vst1q_u8(slice + i * dim2 + j, v0);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_5_Neon", "completion": "```cpp\nvoid extract_tensor_slice_simd(const uint8_t *tensor, uint8_t *slice, size_t dim1, size_t dim2, size_t dim3, size_t slice_idx) {\n    const size_t slice_size = dim1 * dim2;\n    const size_t start_index = slice_idx * slice_size;\n\n    for (size_t i = 0; i < slice_size; i += 16) {\n        uint8x16_t v = vld1q_u8(tensor + start_index + i);\n        vst1q_u8(slice + i, v);\n    }\n}\n```"}
{"task_id": "SimdBench_6_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nvoid blocked_matrix_transpose_simd(const int16_t *src, int16_t *dst, size_t rows, size_t cols, size_t block_size) {\n    const int16x8_t vzero = vdupq_n_s16(0);\n\n    for (size_t row_block = 0; row_block < rows; row_block += block_size) {\n        for (size_t col_block = 0; col_block < cols; col_block += block_size) {\n            for (size_t i = 0; i < block_size; ++i) {\n                for (size_t j = 0; j < block_size; ++j) {\n                    if (row_block + i < rows && col_block + j < cols) {\n                        int16x8_t vsrc = vld1q_lane_s16(src + (row_block + i) * cols + col_block + j, vzero, 0);\n                        vst1q_lane_s16(dst + (col_block + j) * rows + row_block + i, vsrc, 0);\n                    }\n                }\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_6_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nvoid blocked_matrix_transpose_simd(const int16_t *src, int16_t *dst, size_t rows, size_t cols, size_t block_size) {\n    const int16_t *src_ptr = src;\n    int16_t *dst_ptr = dst;\n\n    for (size_t row_block = 0; row_block < rows; row_block += block_size) {\n        for (size_t col_block = 0; col_block < cols; col_block += block_size) {\n            for (size_t i = 0; i < block_size; ++i) {\n                for (size_t j = 0; j < block_size; ++j) {\n                    int16x8_t src_vec = vld1q_s16(src_ptr + (row_block + i) * cols + col_block + j);\n                    vst1q_s16(dst_ptr + (col_block + j) * rows + row_block + i, src_vec);\n                }\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_6_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nvoid blocked_matrix_transpose_simd(const int16_t *src, int16_t *dst, size_t rows, size_t cols, size_t block_size) {\n    const int16x8_t vzero = vdupq_n_s16(0);\n\n    for (size_t row_block = 0; row_block < rows; row_block += block_size) {\n        for (size_t col_block = 0; col_block < cols; col_block += block_size) {\n            for (size_t i = 0; i < block_size; ++i) {\n                for (size_t j = 0; j < block_size; ++j) {\n                    if (row_block + i < rows && col_block + j < cols) {\n                        int16x8_t vsrc = vld1q_lane_s16(&src[(row_block + i) * cols + col_block + j], vzero, 0);\n                        vst1q_lane_s16(&dst[(col_block + j) * rows + row_block + i], vsrc, 0);\n                    }\n                }\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_6_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nvoid blocked_matrix_transpose_simd(const int16_t *src, int16_t *dst, size_t rows, size_t cols, size_t block_size) {\n    const int16_t *src_ptr = src;\n    int16_t *dst_ptr = dst;\n\n    for (size_t row_block = 0; row_block < rows; row_block += block_size) {\n        for (size_t col_block = 0; col_block < cols; col_block += block_size) {\n            for (size_t row = row_block; row < row_block + block_size && row < rows; ++row) {\n                for (size_t col = col_block; col < col_block + block_size && col < cols; ++col) {\n                    int16x8_t src_vec = vld1q_s16(src_ptr + row * cols + col);\n                    vst1q_s16(dst_ptr + col * rows + row, src_vec);\n                }\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_6_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid blocked_matrix_transpose_simd(const int16_t *src, int16_t *dst, size_t rows, size_t cols, size_t block_size) {\n    const int16_t *src_ptr = src;\n    int16_t *dst_ptr = dst;\n\n    for (size_t row_block = 0; row_block < rows; row_block += block_size) {\n        for (size_t col_block = 0; col_block < cols; col_block += block_size) {\n            for (size_t row = row_block; row < row_block + block_size && row < rows; ++row) {\n                for (size_t col = col_block; col < col_block + block_size && col < cols; ++col) {\n                    int16x8_t v = vld1q_s16(src_ptr + row * cols + col);\n                    vst1q_s16(dst_ptr + col * rows + row, v);\n                }\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_7_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nfloat diagonal_sum_3d_simd(const float *array, size_t dim) {\n    float32x4_t sum = vdupq_n_f32(0.0f);\n    size_t i = 0;\n\n    while (i + 4 <= dim * dim * dim) {\n        float32x4_t vec = vld1q_f32(array + i);\n        sum = vaddq_f32(sum, vec);\n        i += 4;\n    }\n\n    float32x2_t sum_lo = vpadd_f32(vget_low_f32(sum), vget_high_f32(sum));\n    float32x2_t sum_hi = vpadd_f32(sum_lo, sum_lo);\n    float result = vget_lane_f32(sum_hi, 0);\n\n    // Handle remaining elements\n    while (i < dim * dim * dim) {\n        result += array[i];\n        i++;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_7_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nfloat diagonal_sum_3d_simd(const float *array, size_t dim) {\n    float32x4_t sum = vdupq_n_f32(0.0f);\n    size_t i = 0;\n\n    while (i + 4 <= dim * dim * dim) {\n        float32x4_t vec = vld1q_f32(array + i);\n        sum = vaddq_f32(sum, vec);\n        i += 4;\n    }\n\n    float32_t result[4];\n    vst1q_f32(result, sum);\n\n    float total_sum = result[0] + result[1] + result[2] + result[3];\n\n    for (; i < dim * dim * dim; ++i) {\n        if ((i / (dim * dim)) == (i / dim) % dim) {\n            total_sum += array[i];\n        }\n    }\n\n    return total_sum;\n}\n```"}
{"task_id": "SimdBench_7_Neon", "completion": "```c\n#include <arm_neon.h>\n\nfloat diagonal_sum_3d_simd(const float *array, size_t dim) {\n    float32x4_t sum = vdupq_n_f32(0.0f);\n    size_t i;\n\n    for (i = 0; i <= dim - 4; i += 4) {\n        float32x4_t val = vld1q_f32(array + i * dim * dim + i * dim + i);\n        sum = vaddq_f32(sum, val);\n    }\n\n    float32x2_t sum_low = vpadd_f32(vget_low_f32(sum), vget_high_f32(sum));\n    float32x2_t sum_low_high = vpadd_f32(sum_low, sum_low);\n    float sum_result = vget_lane_f32(sum_low_high, 0);\n\n    for (; i < dim; ++i) {\n        sum_result += array[i * dim * dim + i * dim + i];\n    }\n\n    return sum_result;\n}\n```"}
{"task_id": "SimdBench_7_Neon", "completion": "```c\n#include <arm_neon.h>\n\nfloat diagonal_sum_3d_simd(const float *array, size_t dim) {\n    float32x4_t sum = vdupq_n_f32(0.0f);\n    size_t i;\n\n    for (i = 0; i <= dim - 4; i += 4) {\n        float32x4_t vec = vld1q_f32(array + i * dim * dim + i * dim + i);\n        sum = vaddq_f32(sum, vec);\n    }\n\n    float32x2_t sum_low = vpadd_f32(vget_low_f32(sum), vget_high_f32(sum));\n    float32x2_t sum_low_high = vpadd_f32(sum_low, sum_low);\n    float result = vget_lane_f32(sum_low_high, 0);\n\n    for (; i < dim; ++i) {\n        result += array[i * dim * dim + i * dim + i];\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_7_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nfloat diagonal_sum_3d_simd(const float *array, size_t dim) {\n    float32x4_t sum = vdupq_n_f32(0.0f);\n    size_t i = 0;\n\n    for (; i <= dim - 4; i += 4) {\n        float32x4_t val = vld1q_f32(array + i * dim * dim + i * dim + i);\n        sum = vaddq_f32(sum, val);\n    }\n\n    float32x2_t sum_low = vpadd_f32(vget_low_f32(sum), vget_high_f32(sum));\n    float32x2_t sum_all = vpadd_f32(sum_low, sum_low);\n\n    float result = vget_lane_f32(sum_all, 0);\n\n    for (; i < dim; ++i) {\n        result += array[i * dim * dim + i * dim + i];\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_8_Neon", "completion": "```cpp\nvoid conditional_scale_simd(const double *src, double *dst, size_t rows, size_t cols, double threshold, double scale) {\n    const int vec_len = 2;\n    const double32x2_t v_threshold = vdup_n_f32(static_cast<float>(threshold));\n    const double32x2_t v_scale = vdup_n_f32(static_cast<float>(scale));\n\n    for (size_t i = 0; i < rows; ++i) {\n        for (size_t j = 0; j < cols - vec_len + 1; j += vec_len) {\n            double32x2_t v_src = vld1_f32(reinterpret_cast<const float*>(&src[i * cols + j]));\n            double32x2_t v_dst = vmulq_f32(vcmpgtq_f32(v_src, v_threshold), v_scale);\n            vst1_f32(reinterpret_cast<float*>(&dst[i * cols + j]), v_dst);\n        }\n\n        // Handle remaining elements\n        for (size_t j = cols - vec_len + 1; j < cols; ++j) {\n            if (src[i * cols + j] > threshold) {\n                dst[i * cols + j] = src[i * cols + j] * scale;\n            } else {\n                dst[i * cols + j] = src[i * cols + j];\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_8_Neon", "completion": "```cpp\nvoid conditional_scale_simd(const double *src, double *dst, size_t rows, size_t cols, double threshold, double scale) {\n    const int vec_size = 4;\n    const double v_threshold = vdupq_n_f64(threshold);\n    const double v_scale = vdupq_n_f64(scale);\n\n    for (size_t i = 0; i < rows; ++i) {\n        for (size_t j = 0; j < cols - vec_size + 1; j += vec_size) {\n            double32x2_t v_src0 = vld1q_f32((float32_t*)&src[i * cols + j]);\n            double32x2_t v_src1 = vld1q_f32((float32_t*)&src[i * cols + j + 2]);\n\n            uint32x2_t cmp0 = vcgt_f32(v_src0, vdupq_n_f32(threshold));\n            uint32x2_t cmp1 = vcgt_f32(v_src1, vdupq_n_f32(threshold));\n\n            double32x2_t v_scaled0 = vmulq_f32(v_src0, vdupq_n_f32(scale));\n            double32x2_t v_scaled1 = vmulq_f32(v_src1, vdupq_n_f32(scale));\n\n            vst1q_f32((float32_t*)&dst[i * cols + j], vbslq_f32(cmp0, v_scaled0, v_src0));\n            vst1q_f32((float32_t*)&dst[i * cols + j + 2], vbslq_f32(cmp1, v_scaled1, v_src1));\n        }\n\n        // Handle remaining elements\n        for (size_t j = cols - vec_size + 1; j < cols; ++j) {\n            if (src[i * cols + j] > threshold) {\n                dst[i * cols + j] = src[i * cols + j] * scale;\n            } else {\n                dst[i * cols + j] = src[i * cols + j];\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_8_Neon", "completion": "```cpp\nvoid conditional_scale_simd(const double *src, double *dst, size_t rows, size_t cols, double threshold, double scale) {\n    const int vec_size = 2;\n    const double v_threshold = vdupq_n_f64(threshold);\n    const double v_scale = vdupq_n_f64(scale);\n\n    for (size_t i = 0; i < rows; ++i) {\n        for (size_t j = 0; j < cols - vec_size + 1; j += vec_size) {\n            double32x2_t v_src = vld1_f32((float32_t *)&src[i * cols + j]);\n            float32x2_t v_dst = vcmpge_f32(v_src, vmovq_n_f32((float32_t)threshold));\n            vst1_f32((float32_t *)&dst[i * cols + j], vmulq_f32(vmovq_n_f32((float32_t)scale), vreinterpretq_f32_u32(vmovl_u16(vreinterpret_u16_s32(vcvt_s32_f32(v_src))))));\n        }\n        // Handle remaining elements that do not fit into a vector\n        for (size_t j = cols - vec_size + 1; j < cols; ++j) {\n            if (src[i * cols + j] > threshold) {\n                dst[i * cols + j] = src[i * cols + j] * scale;\n            } else {\n                dst[i * cols + j] = src[i * cols + j];\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_8_Neon", "completion": "```cpp\nvoid conditional_scale_simd(const double *src, double *dst, size_t rows, size_t cols, double threshold, double scale) {\n    const int vec_len = 4;\n    const double v_threshold = vdupq_n_f64(threshold);\n    const double v_scale = vdupq_n_f64(scale);\n\n    for (size_t i = 0; i < rows; ++i) {\n        for (size_t j = 0; j < cols - vec_len + 1; j += vec_len) {\n            double32x2_t v_src0 = vld1q_f32((float32_t *)&src[i * cols + j]);\n            double32x2_t v_src1 = vld1q_f32((float32_t *)&src[i * cols + j + 4]);\n\n            uint32x2_t cmp0 = vcgt_f32(v_src0, vmovq_n_f32((float32_t)threshold));\n            uint32x2_t cmp1 = vcgt_f32(v_src1, vmovq_n_f32((float32_t)threshold));\n\n            float32x2_t v_scaled0 = vmulq_f32(v_src0, vmovq_n_f32((float32_t)scale));\n            float32x2_t v_scaled1 = vmulq_f32(v_src1, vmovq_n_f32((float32_t)scale));\n\n            vst1q_f32((float32_t *)&dst[i * cols + j], vbslq_f32(cmp0, v_scaled0, v_src0));\n            vst1q_f32((float32_t *)&dst[i * cols + j + 4], vbslq_f32(cmp1, v_scaled1, v_src1));\n        }\n\n        // Handle remaining elements\n        for (size_t j = cols - cols % vec_len; j < cols; ++j) {\n            if (src[i * cols + j] > threshold) {\n                dst[i * cols + j] = src[i * cols + j] * scale;\n            } else {\n                dst[i * cols + j] = src[i * cols + j];\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_8_Neon", "completion": "```cpp\nvoid conditional_scale_simd(const double *src, double *dst, size_t rows, size_t cols, double threshold, double scale) {\n    const int vec_len = 2;\n    const double v_threshold = vdupq_n_f64(threshold);\n    const double v_scale = vdupq_n_f64(scale);\n\n    for (size_t i = 0; i < rows; ++i) {\n        for (size_t j = 0; j < cols - vec_len + 1; j += vec_len) {\n            double32x2_t v_src = vld1_f32((float32_t *)&src[i * cols + j]);\n            float32x2_t v_dst = vmulq_f32(v_src, v_scale);\n            vst1_f32((float32_t *)&dst[i * cols + j], v_dst);\n        }\n        // Handle remaining elements that do not fit into a vector\n        for (size_t j = cols - vec_len + 1; j < cols; ++j) {\n            if (src[i * cols + j] > threshold) {\n                dst[i * cols + j] = src[i * cols + j] * scale;\n            } else {\n                dst[i * cols + j] = src[i * cols + j];\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_9_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nvoid reorder_matrix_rows_simd(const double *src, double *dst, size_t rows, size_t cols, const size_t *indices) {\n    for (size_t i = 0; i < rows; i += 2) {\n        size_t idx0 = indices[i];\n        size_t idx1 = indices[i + 1];\n\n        if (idx0 >= rows || idx1 >= rows) {\n            continue;\n        }\n\n        for (size_t j = 0; j < cols; j += 4) {\n            vst1q_f64(dst + (i * cols) + j, vld1q_f64(src + (idx0 * cols) + j));\n            vst1q_f64(dst + ((i + 1) * cols) + j, vld1q_f64(src + (idx1 * cols) + j));\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_9_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nvoid reorder_matrix_rows_simd(const double *src, double *dst, size_t rows, size_t cols, const size_t *indices) {\n    for (size_t i = 0; i < rows; i += 2) {\n        size_t idx0 = indices[i];\n        size_t idx1 = indices[i + 1];\n\n        if (idx0 >= rows || idx1 >= rows) {\n            continue;\n        }\n\n        for (size_t j = 0; j < cols; j += 4) {\n            vst1q_f64(dst + (i * cols + j), vld1q_f64(src + (idx0 * cols + j)));\n            vst1q_f64(dst + ((i + 1) * cols + j), vld1q_f64(src + (idx1 * cols + j)));\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_9_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nvoid reorder_matrix_rows_simd(const double *src, double *dst, size_t rows, size_t cols, const size_t *indices) {\n    for (size_t i = 0; i < rows; i += 2) {\n        size_t idx0 = indices[i];\n        size_t idx1 = indices[i + 1];\n\n        if (idx0 >= rows || idx1 >= rows) {\n            continue;\n        }\n\n        for (size_t j = 0; j < cols; j += 4) {\n            vst1q_f64(dst + (i * cols + j), vld1q_f64(src + (idx0 * cols + j)));\n            vst1q_f64(dst + ((i + 1) * cols + j), vld1q_f64(src + (idx1 * cols + j)));\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_9_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nvoid reorder_matrix_rows_simd(const double *src, double *dst, size_t rows, size_t cols, const size_t *indices) {\n    for (size_t i = 0; i < rows; i += 2) {\n        size_t idx1 = indices[i];\n        size_t idx2 = indices[i + 1];\n\n        if (idx1 >= rows || idx2 >= rows) {\n            continue;\n        }\n\n        for (size_t j = 0; j < cols; j += 4) {\n            vst1q_f64(dst + (i * cols) + j, vld1q_f64(src + (idx1 * cols) + j));\n            vst1q_f64(dst + ((i + 1) * cols) + j, vld1q_f64(src + (idx2 * cols) + j));\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_9_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nvoid reorder_matrix_rows_simd(const double *src, double *dst, size_t rows, size_t cols, const size_t *indices) {\n    for (size_t i = 0; i < rows; i += 2) {\n        size_t idx0 = indices[i];\n        size_t idx1 = indices[i + 1];\n\n        if (idx0 >= rows || idx1 >= rows) {\n            continue;\n        }\n\n        for (size_t j = 0; j < cols; j += 4) {\n            vst1q_f64(dst + (i * cols + j), vld1q_f64(src + (idx0 * cols + j)));\n            vst1q_f64(dst + ((i + 1) * cols + j), vld1q_f64(src + (idx1 * cols + j)));\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_10_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid vector_vector_add_simd(const int64_t *src1, const int64_t *src2, int64_t *dst, int64_t scalar, size_t length) {\n    size_t i;\n    for (i = 0; i <= length - 4; i += 4) {\n        int64x2_t vsrc1_0 = vld1q_s64(src1 + i);\n        int64x2_t vsrc2_0 = vld1q_s64(src2 + i);\n        int64x2_t vsrc1_1 = vld1q_s64(src1 + i + 2);\n        int64x2_t vsrc2_1 = vld1q_s64(src2 + i + 2);\n\n        int64x2_t vresult_0 = vaddq_s64(vsrc1_0, vsrc2_0);\n        int64x2_t vresult_1 = vaddq_s64(vsrc1_1, vsrc2_1);\n\n        int64x2_t vscale = vdupq_n_s64(scalar);\n        vresult_0 = vaddq_s64(vresult_0, vscale);\n        vresult_1 = vaddq_s64(vresult_1, vscale);\n\n        vst1q_s64(dst + i, vresult_0);\n        vst1q_s64(dst + i + 2, vresult_1);\n    }\n\n    // Handle remaining elements\n    for (; i < length; ++i) {\n        dst[i] = (src1[i] + src2[i] + scalar) / 2;\n    }\n}\n```"}
{"task_id": "SimdBench_10_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid vector_vector_add_simd(const int64_t *src1, const int64_t *src2, int64_t *dst, int64_t scalar, size_t length) {\n    size_t i;\n    for (i = 0; i <= length - 4; i += 4) {\n        int64x2_t vsrc1_0 = vld1q_s64(src1 + i);\n        int64x2_t vsrc2_0 = vld1q_s64(src2 + i);\n        int64x2_t vsrc1_1 = vld1q_s64(src1 + i + 2);\n        int64x2_t vsrc2_1 = vld1q_s64(src2 + i + 2);\n\n        int64x2_t vresult_0 = vaddq_s64(vsrc1_0, vsrc2_0);\n        int64x2_t vresult_1 = vaddq_s64(vsrc1_1, vsrc2_1);\n\n        int64x2_t vscalar_0 = vmovq_n_s64(scalar);\n        int64x2_t vscalar_1 = vmovq_n_s64(scalar);\n\n        vresult_0 = vaddq_s64(vresult_0, vscalar_0);\n        vresult_1 = vaddq_s64(vresult_1, vscalar_1);\n\n        vresult_0 = vrshrq_n_s64(vresult_0, 1);\n        vresult_1 = vrshrq_n_s64(vresult_1, 1);\n\n        vst1q_s64(dst + i, vresult_0);\n        vst1q_s64(dst + i + 2, vresult_1);\n    }\n\n    for (; i < length; ++i) {\n        dst[i] = (src1[i] + src2[i] + scalar) / 2;\n    }\n}\n```"}
{"task_id": "SimdBench_10_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid vector_vector_add_simd(const int64_t *src1, const int64_t *src2, int64_t *dst, int64_t scalar, size_t length) {\n    size_t i;\n    for (i = 0; i <= length - 4; i += 4) {\n        int64x2_t vsrc1_0 = vld1q_s64(src1 + i);\n        int64x2_t vsrc2_0 = vld1q_s64(src2 + i);\n        int64x2_t vsrc1_1 = vld1q_s64(src1 + i + 2);\n        int64x2_t vsrc2_1 = vld1q_s64(src2 + i + 2);\n\n        int64x2_t vresult_0 = vaddq_s64(vsrc1_0, vsrc2_0);\n        int64x2_t vresult_1 = vaddq_s64(vsrc1_1, vsrc2_1);\n\n        vresult_0 = vaddq_s64(vresult_0, vmovq_n_s64(scalar));\n        vresult_1 = vaddq_s64(vresult_1, vmovq_n_s64(scalar));\n\n        vst1q_s64(dst + i, vresult_0);\n        vst1q_s64(dst + i + 2, vresult_1);\n    }\n\n    for (; i < length; ++i) {\n        dst[i] = (src1[i] + src2[i] + scalar) / 2;\n    }\n}\n```"}
{"task_id": "SimdBench_10_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid vector_vector_add_simd(const int64_t *src1, const int64_t *src2, int64_t *dst, int64_t scalar, size_t length) {\n    size_t i;\n    for (i = 0; i <= length - 4; i += 4) {\n        int64x2_t vsrc1_0 = vld1q_s64(src1 + i);\n        int64x2_t vsrc2_0 = vld1q_s64(src2 + i);\n        int64x2_t vsrc1_1 = vld1q_s64(src1 + i + 2);\n        int64x2_t vsrc2_1 = vld1q_s64(src2 + i + 2);\n\n        int64x2_t vresult_0 = vaddq_s64(vsrc1_0, vsrc2_0);\n        int64x2_t vresult_1 = vaddq_s64(vsrc1_1, vsrc2_1);\n\n        int64x2_t vscale = vdupq_n_s64(scalar);\n        vresult_0 = vaddq_s64(vresult_0, vscale);\n        vresult_1 = vaddq_s64(vresult_1, vscale);\n\n        vst1q_s64(dst + i, vresult_0);\n        vst1q_s64(dst + i + 2, vresult_1);\n    }\n\n    // Handle remaining elements\n    for (; i < length; ++i) {\n        dst[i] = (src1[i] + src2[i] + scalar) / 2;\n    }\n}\n```"}
{"task_id": "SimdBench_10_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid vector_vector_add_simd(const int64_t *src1, const int64_t *src2, int64_t *dst, int64_t scalar, size_t length) {\n    size_t i;\n    for (i = 0; i <= length - 4; i += 4) {\n        int64x2_t vsrc1_0 = vld1q_s64(src1 + i);\n        int64x2_t vsrc2_0 = vld1q_s64(src2 + i);\n        int64x2_t vsrc1_1 = vld1q_s64(src1 + i + 2);\n        int64x2_t vsrc2_1 = vld1q_s64(src2 + i + 2);\n\n        int64x2_t vresult_0 = vaddq_s64(vsrc1_0, vsrc2_0);\n        int64x2_t vresult_1 = vaddq_s64(vsrc1_1, vsrc2_1);\n\n        vresult_0 = vaddq_s64(vresult_0, vmovq_n_s64(scalar));\n        vresult_1 = vaddq_s64(vresult_1, vmovq_n_s64(scalar));\n\n        vst1q_s64(dst + i, vresult_0);\n        vst1q_s64(dst + i + 2, vresult_1);\n    }\n\n    for (; i < length; ++i) {\n        dst[i] = (src1[i] + src2[i] + scalar) / 2;\n    }\n}\n```"}
{"task_id": "SimdBench_11_Neon", "completion": "```c\nint vector_even_min_simd(const int *src, size_t length) {\n    if (length == 0) {\n        return -1;\n    }\n\n    int min_value = src[0];\n    size_t i;\n\n    // Process elements in groups of 4\n    for (i = 0; i <= length - 8; i += 8) {\n        int32x4_t v0 = vld1q_s32(src + i);\n        int32x4_t v1 = vld1q_s32(src + i + 4);\n\n        // Extract even-indexed elements\n        int32x4_t v0_even = vextq_s32(v0, v0, 1);\n        int32x4_t v1_even = vextq_s32(v1, v1, 1);\n\n        // Combine even-indexed elements from both vectors\n        int32x4_t combined = vcombine_s32(v0_even, v1_even);\n\n        // Find the minimum value among the even-indexed elements\n        int32x4_t min_combined = vminq_s32(combined, vdupq_n_s32(min_value));\n\n        // Update min_value\n        min_value = vminvq_s32(min_combined);\n    }\n\n    // Process remaining elements\n    for (; i < length; ++i) {\n        if (i % 2 == 0 && src[i] < min_value) {\n            min_value = src[i];\n        }\n    }\n\n    return min_value;\n}\n```"}
{"task_id": "SimdBench_11_Neon", "completion": "```c\nint vector_even_min_simd(const int *src, size_t length) {\n    if (length == 0) {\n        return -1;\n    }\n\n    int min_value = src[0];\n    size_t i;\n\n    // Process elements in groups of 4\n    for (i = 0; i <= length - 8; i += 8) {\n        int32x4_t v0 = vld1q_s32(src + i);\n        int32x4_t v1 = vld1q_s32(src + i + 4);\n\n        // Extract even-indexed elements\n        int32x4_t v0_even = vextq_s32(v0, v0, 1);\n        int32x4_t v1_even = vextq_s32(v1, v1, 1);\n\n        // Combine even-indexed elements from both vectors\n        int32x4_t combined = vcombine_s32(v0_even, v1_even);\n\n        // Find the minimum value among the even-indexed elements\n        int32x4_t min_combined = vminq_s32(combined, vdupq_n_s32(min_value));\n\n        // Update the overall minimum value\n        min_value = vminvq_s32(min_combined);\n    }\n\n    // Process remaining elements\n    for (; i < length; ++i) {\n        if (i % 2 == 0 && src[i] < min_value) {\n            min_value = src[i];\n        }\n    }\n\n    return min_value;\n}\n```"}
{"task_id": "SimdBench_11_Neon", "completion": "```c\nint vector_even_min_simd(const int *src, size_t length) {\n    if (length == 0) {\n        return -1;\n    }\n\n    int min_value = src[0];\n    size_t i = 0;\n\n    // Process elements in chunks of 4\n    while (i + 4 <= length) {\n        int32x4_t v = vld1q_s32(src + i);\n        int32x4_t mask = vandq_u32(vreinterpretq_u32_s32(vandq_s32(v, vdupq_n_s32(0x55555555))), vdupq_n_u32(0x55555555));\n        int32x4_t min_chunk = vminq_s32(v, vmulq_s32(mask, vsubq_s32(vdupq_n_s32(min_value), v)));\n        min_value = vminvq_s32(min_chunk);\n        i += 4;\n    }\n\n    // Process remaining elements\n    while (i < length) {\n        if ((src[i] & 1) == 0 && src[i] < min_value) {\n            min_value = src[i];\n        }\n        i++;\n    }\n\n    return min_value;\n}\n```"}
{"task_id": "SimdBench_11_Neon", "completion": "```c\nint vector_even_min_simd(const int *src, size_t length) {\n    if (length == 0) {\n        return -1;\n    }\n\n    int min_value = src[0];\n    int i = 0;\n\n    // Process elements in groups of 4\n    while (i + 8 <= length) {\n        int32x4_t v0 = vld1q_s32(src + i);\n        int32x4_t v1 = vld1q_s32(src + i + 4);\n\n        // Extract even-indexed elements\n        int32x4_t v0_even = vextq_s32(v0, v0, 2);\n        int32x4_t v1_even = vextq_s32(v1, v1, 2);\n\n        // Find minimum among even-indexed elements\n        int32x4_t min_even = vminq_s32(v0_even, v1_even);\n        int32_t min_val = vminvq_s32(min_even);\n\n        if (min_val < min_value) {\n            min_value = min_val;\n        }\n\n        i += 8;\n    }\n\n    // Process remaining elements\n    while (i < length) {\n        if (i % 2 == 0 && src[i] < min_value) {\n            min_value = src[i];\n        }\n        i++;\n    }\n\n    return min_value;\n}\n```"}
{"task_id": "SimdBench_11_Neon", "completion": "```c\nint vector_even_min_simd(const int *src, size_t length) {\n    if (length == 0) {\n        return -1;\n    }\n\n    int min_value = src[0];\n    int i = 0;\n\n    // Process elements in groups of 4\n    while (i + 8 <= length) {\n        int32x4_t v0 = vld1q_s32(src + i);\n        int32x4_t v1 = vld1q_s32(src + i + 4);\n\n        // Extract even-indexed elements\n        int32x4_t v0_even = vextq_s32(v0, v0, 1);\n        int32x4_t v1_even = vextq_s32(v1, v1, 1);\n\n        // Find minimum among even-indexed elements\n        int32x4_t v_min_even = vminq_s32(v0_even, v1_even);\n        int min_val_even = vminvq_s32(v_min_even);\n\n        if (min_val_even < min_value) {\n            min_value = min_val_even;\n        }\n\n        i += 8;\n    }\n\n    // Process remaining elements\n    while (i < length) {\n        if (i % 2 == 0 && src[i] < min_value) {\n            min_value = src[i];\n        }\n        i++;\n    }\n\n    return min_value;\n}\n```"}
{"task_id": "SimdBench_12_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid mixed_right_shift_simd(const int *src, int *dst, uint8_t shift, size_t length) {\n    const int32x4_t vshift = vdupq_n_s32(shift);\n\n    for (size_t i = 0; i <= length - 4; i += 4) {\n        int32x4_t vsrc = vld1q_s32(src + i);\n        int32x4_t varithmetic_shift = vshrq_s32(vsrc, vshift);\n        uint32x4_t vlogical_shift = vreinterpretq_u32_s32(vshrq_u32(vreinterpretq_u32_s32(vsrc), vshift));\n        int32x4_t vresult = vaddq_s32(varithmetic_shift, vreinterpretq_s32_u32(vlogical_shift));\n\n        vst1q_s32(dst + i, vresult);\n    }\n\n    // Handle remaining elements\n    for (size_t i = length - length % 4; i < length; ++i) {\n        dst[i] = src[i] >> shift | ((uint32_t)src[i] >> shift) << 32 - shift;\n    }\n}\n```"}
{"task_id": "SimdBench_12_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid mixed_right_shift_simd(const int *src, int *dst, uint8_t shift, size_t length) {\n    const int32x4_t vshift = vdupq_n_s32(shift);\n\n    for (size_t i = 0; i <= length - 4; i += 4) {\n        int32x4_t vsrc = vld1q_s32(src + i);\n        int32x4_t varithmetic_shift = vshrq_s32(vsrc, vshift);\n        uint32x4_t vlogical_shift = vreinterpretq_u32_s32(vshrq_u32(vreinterpretq_u32_s32(vsrc), vshift));\n        int32x4_t vresult = vaddq_s32(varithmetic_shift, vreinterpretq_s32_u32(vlogical_shift));\n\n        vst1q_s32(dst + i, vresult);\n    }\n\n    // Handle remaining elements\n    for (size_t i = length - length % 4; i < length; ++i) {\n        dst[i] = src[i] >> shift | ((uint32_t)src[i] >> shift) << 32 - shift;\n    }\n}\n```"}
{"task_id": "SimdBench_12_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid mixed_right_shift_simd(const int *src, int *dst, uint8_t shift, size_t length) {\n    const int32x4_t vshift = vdupq_n_s32(shift);\n\n    for (size_t i = 0; i <= length - 4; i += 4) {\n        int32x4_t vsrc = vld1q_s32(src + i);\n        int32x4_t varithmetic_shift = vshrq_s32(vsrc, vshift);\n        uint32x4_t vlogical_shift = vreinterpretq_u32_s32(vshrq_u32(vreinterpretq_u32_s32(vsrc), vshift));\n        int32x4_t vresult = vaddq_s32(varithmetic_shift, vreinterpretq_s32_u32(vlogical_shift));\n        vst1q_s32(dst + i, vresult);\n    }\n\n    // Handle remaining elements\n    for (size_t i = length - length % 4; i < length; ++i) {\n        dst[i] = src[i] >> shift | ((uint32_t)src[i] >> shift) << 32 - shift;\n    }\n}\n```"}
{"task_id": "SimdBench_12_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid mixed_right_shift_simd(const int *src, int *dst, uint8_t shift, size_t length) {\n    const int32x4_t vshift = vdupq_n_s32(shift);\n\n    for (size_t i = 0; i <= length - 4; i += 4) {\n        int32x4_t vsrc = vld1q_s32(src + i);\n        int32x4_t varithmetic_shift = vshrq_s32(vsrc, vshift);\n        uint32x4_t vlogical_shift = vreinterpretq_u32_s32(vshrq_u32(vreinterpretq_u32_s32(vsrc), vshift));\n        int32x4_t vresult = vaddq_s32(varithmetic_shift, vreinterpretq_s32_u32(vlogical_shift));\n\n        vst1q_s32(dst + i, vresult);\n    }\n\n    // Handle remaining elements\n    for (size_t i = length - length % 4; i < length; ++i) {\n        dst[i] = src[i] >> shift | ((uint32_t)src[i] >> shift) << 32 - shift;\n    }\n}\n```"}
{"task_id": "SimdBench_12_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid mixed_right_shift_simd(const int *src, int *dst, uint8_t shift, size_t length) {\n    const int32x4_t vshift = vdupq_n_s32(shift);\n\n    for (size_t i = 0; i <= length - 4; i += 4) {\n        int32x4_t vsrc = vld1q_s32(src + i);\n        int32x4_t varithmetic_shift = vshrq_s32(vsrc, vshift);\n        uint32x4_t vlogical_shift = vreinterpretq_u32_s32(vshrq_u32(vreinterpretq_u32_s32(vsrc), vshift));\n        int32x4_t vresult = vaddq_s32(varithmetic_shift, vreinterpretq_s32_u32(vlogical_shift));\n\n        vst1q_s32(dst + i, vresult);\n    }\n\n    // Handle remaining elements\n    for (size_t i = length - length % 4; i < length; ++i) {\n        dst[i] = src[i] >> shift | ((uint32_t)src[i] >> shift) << 31;\n    }\n}\n```"}
{"task_id": "SimdBench_13_Neon", "completion": "```c\nint64_t matrix_sum_simd(const int *matrix, size_t rows, size_t cols) {\n    int64x2_t sum = vdupq_n_s64(0);\n\n    for (size_t i = 0; i < rows; ++i) {\n        const int *row_start = &matrix[i * cols];\n        for (size_t j = 0; j <= cols - 4; j += 4) {\n            int32x4_t row_vec = vld1q_s32(row_start + j);\n            int64x2_t row_sum = vmovl_s32(vaddw_s16(vmovl_s16(vget_low_s16(row_vec)), vget_high_s16(row_vec)));\n            sum = vmlal_s64(sum, vget_low_s64(row_sum), vget_high_s64(row_sum));\n        }\n        for (; j < cols; ++j) {\n            sum = vmlal_s64(sum, vdupq_n_s64(matrix[i * cols + j]), vdupq_n_s64(1));\n        }\n    }\n\n    return vget_lane_s64(sum, 0) + vget_lane_s64(sum, 1);\n}\n```"}
{"task_id": "SimdBench_13_Neon", "completion": "```cpp\nint64_t matrix_sum_simd(const int *matrix, size_t rows, size_t cols) {\n    int64x2_t sum = vdupq_n_s64(0);\n\n    for (size_t i = 0; i < rows; ++i) {\n        const int *row_start = matrix + i * cols;\n        for (size_t j = 0; j <= cols - 8; j += 8) {\n            int32x4_t vec1 = vld1q_s32(row_start + j);\n            int32x4_t vec2 = vld1q_s32(row_start + j + 4);\n            int64x2_t sum_vec = vmovl_s32(vaddw_s32(vmovl_s32(vec1), vec2));\n            sum = vaddq_s64(sum, sum_vec);\n        }\n        for (; j < cols; ++j) {\n            sum[0] += row_start[j];\n        }\n    }\n\n    return vgetq_lane_s64(sum, 0) + vgetq_lane_s64(sum, 1);\n}\n```"}
{"task_id": "SimdBench_13_Neon", "completion": "```c\nint64_t matrix_sum_simd(const int *matrix, size_t rows, size_t cols) {\n    int64x2_t sum = vdupq_n_s64(0);\n\n    for (size_t i = 0; i < rows; ++i) {\n        const int *row_start = &matrix[i * cols];\n        for (size_t j = 0; j <= cols - 8; j += 8) {\n            int32x4_t row_vec1 = vld1q_s32(row_start + j);\n            int32x4_t row_vec2 = vld1q_s32(row_start + j + 4);\n            int64x2_t row_sum = vmovl_s32(vaddw_s32(vmovl_s32(row_vec1), row_vec2));\n            sum = vaddq_s64(sum, row_sum);\n        }\n        for (; j < cols; ++j) {\n            sum[0] += row_start[j];\n        }\n    }\n\n    return vgetq_lane_s64(sum, 0) + vgetq_lane_s64(sum, 1);\n}\n```"}
{"task_id": "SimdBench_13_Neon", "completion": "```c\nint64_t matrix_sum_simd(const int *matrix, size_t rows, size_t cols) {\n    int64x2_t sum = vdupq_n_s64(0);\n\n    for (size_t i = 0; i < rows; ++i) {\n        const int *row = &matrix[i * cols];\n        int32x4_t row_sum = vdupq_n_s32(0);\n\n        for (size_t j = 0; j < cols; j += 4) {\n            int32x4_t vec = vld1q_s32(row + j);\n            row_sum = vaddq_s32(row_sum, vec);\n        }\n\n        int32x2_t low = vget_low_s32(row_sum);\n        int32x2_t high = vget_high_s32(row_sum);\n        int32_t sum_row = vaddv_s32(vcombine_s32(low, high));\n\n        sum = vaddq_s64(sum, vreinterpretq_s64_s32(vmovl_s32(sum_row)));\n    }\n\n    return vget_lane_s64(sum, 0);\n}\n```"}
{"task_id": "SimdBench_13_Neon", "completion": "```cpp\nint64_t matrix_sum_simd(const int *matrix, size_t rows, size_t cols) {\n    int64x2_t sum = vdupq_n_s64(0);\n\n    for (size_t i = 0; i < rows; ++i) {\n        const int *row_start = matrix + i * cols;\n        for (size_t j = 0; j <= cols - 4; j += 4) {\n            int32x4_t row_vec = vld1q_s32(row_start + j);\n            int64x2_t row_sum = vmovl_s32(vaddw_s16(vmovl_s16(vget_low_s16(vreinterpretq_s16_s32(row_vec))),\n                                                   vget_high_s16(vreinterpretq_s16_s32(row_vec))));\n            sum = vaddq_s64(sum, row_sum);\n        }\n        // Handle remaining elements\n        for (; j < cols; ++j) {\n            sum = vaddq_s64(sum, vdupq_n_s64(static_cast<int64_t>(row_start[j])));\n        }\n    }\n\n    int64_t result[2];\n    vst1q_s64(result, sum);\n    return result[0] + result[1];\n}\n```"}
{"task_id": "SimdBench_14_Neon", "completion": "```c\n#include <arm_neon.h>\n\nsize_t argmax_simd(const int8_t *src, size_t length) {\n    if (length == 0) {\n        return 0;\n    }\n\n    size_t max_index = 0;\n    int8x16_t v_max = vld1q_s8(src);\n\n    for (size_t i = 16; i < length; i += 16) {\n        int8x16_t v_src = vld1q_s8(src + i);\n        int8x16_t v_cmp = vcgtq_s8(v_src, v_max);\n        max_index += vaddvq_u32(vreinterpretq_u32_u8(v_cmp));\n        v_max = vmaxq_s8(v_max, v_src);\n    }\n\n    // Handle remaining elements\n    for (size_t i = length - length % 16; i < length; ++i) {\n        if (src[i] > src[max_index]) {\n            max_index = i;\n        }\n    }\n\n    return max_index;\n}\n```"}
{"task_id": "SimdBench_14_Neon", "completion": "```c\n#include <arm_neon.h>\n\nsize_t argmax_simd(const int8_t *src, size_t length) {\n    if (length == 0) {\n        return 0;\n    }\n\n    size_t max_index = 0;\n    int8x16_t v_max = vld1q_s8(src);\n\n    for (size_t i = 16; i < length; i += 16) {\n        int8x16_t v_src = vld1q_s8(src + i);\n        int8x16_t v_cmp = vcgtq_s8(v_src, v_max);\n        max_index += vaddvq_u32(vreinterpretq_u32_u8(v_cmp));\n        v_max = vmaxq_s8(v_max, v_src);\n    }\n\n    // Handle remaining elements\n    for (size_t i = length - length % 16; i < length; ++i) {\n        if (src[i] > src[max_index]) {\n            max_index = i;\n        }\n    }\n\n    return max_index;\n}\n```"}
{"task_id": "SimdBench_14_Neon", "completion": "```c\n#include <arm_neon.h>\n\nsize_t argmax_simd(const int8_t *src, size_t length) {\n    if (length == 0) {\n        return 0;\n    }\n\n    size_t max_index = 0;\n    int8x16_t v_max = vld1q_s8(src);\n    const int8_t *ptr = src + 16;\n\n    while (ptr < src + length) {\n        int8x16_t v_src = vld1q_s8(ptr);\n        int8x16_t v_cmp = vcgtq_s8(v_src, v_max);\n        max_index += vaddvq_u32(vreinterpretq_u32_u8(v_cmp));\n        v_max = vmaxq_s8(v_max, v_src);\n        ptr += 16;\n    }\n\n    // Handle remaining elements\n    for (; ptr < src + length; ++ptr) {\n        if (*ptr > src[max_index]) {\n            max_index = ptr - src;\n        }\n    }\n\n    return max_index;\n}\n```"}
{"task_id": "SimdBench_14_Neon", "completion": "```cpp\nsize_t argmax_simd(const int8_t *src, size_t length) {\n    if (length == 0) {\n        return 0;\n    }\n\n    size_t max_index = 0;\n    int8x16_t max_value = vld1q_s8(src);\n    src += 16;\n\n    for (size_t i = 16; i < length; i += 16) {\n        int8x16_t current_values = vld1q_s8(src);\n        src += 16;\n\n        int8x16_t mask = vcgtq_s8(current_values, max_value);\n        max_value = vbslq_s8(mask, current_values, max_value);\n\n        uint32x4_t count_mask = vmovq_n_u32(0xFFFFFFFF);\n        uint32x4_t indices = vdupq_lane_u32((uint32_t)i, 0);\n        indices = vmlal_u32(indices, vreinterpretq_u32_s8(vandq_s8(mask, vdupq_n_s8(0xFF))), 1);\n        indices = vaddq_u32(indices, vdupq_n_u32(15));\n\n        uint32x4_t max_indices = vmaxq_u32(vget_low_u32(indices), vget_high_u32(indices));\n        max_index = vget_lane_u32(max_indices, 0);\n    }\n\n    // Handle remaining elements\n    while (length - max_index > 16) {\n        max_index++;\n        if (src[max_index] > src[max_index - 1]) {\n            max_value = vld1q_s8(&src[max_index]);\n        }\n    }\n\n    return max_index;\n}\n```"}
{"task_id": "SimdBench_14_Neon", "completion": "```c\n#include <arm_neon.h>\n#include <stddef.h>\n\nsize_t argmax_simd(const int8_t *src, size_t length) {\n    if (length == 0) {\n        return 0;\n    }\n\n    const int8x16_t vzero = vdupq_n_s8(0);\n    int8x16_t vmax = vld1q_s8(src);\n    uint32x4_t imax = vmovq_u32(vdupq_n_u32(0));\n\n    size_t i = 16;\n    while (i + 16 <= length) {\n        int8x16_t vcurrent = vld1q_s8(src + i);\n        uint32x4_t icurrent = vmovq_u32(vdupq_n_u32(i));\n\n        uint32x4_t mask = vcgtq_s8(vcurrent, vmax);\n        vmax = vbslq_s8(mask, vcurrent, vmax);\n        imax = vbslq_u32(mask, icurrent, imax);\n\n        i += 16;\n    }\n\n    while (i < length) {\n        if (src[i] > vmax[0]) {\n            vmax[0] = src[i];\n            imax[0] = i;\n        }\n        i++;\n    }\n\n    return imax[0];\n}\n```"}
{"task_id": "SimdBench_15_Neon", "completion": "```cpp\nvoid vector_blend_simd(const uint16_t* src1, const uint16_t* src2, uint32_t mask, uint16_t* dst, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 8; i += 8) {\n        uint16x8_t v_mask = vdupq_n_u16(mask);\n        uint16x8_t v_index = vld1q_u16((uint16_t*)&i);\n        uint16x8_t v_condition = vandq_u16(v_index, v_mask);\n\n        uint16x8_t v_src1 = vld1q_u16(src1 + i);\n        uint16x8_t v_src2 = vld1q_u16(src2 + i);\n\n        uint16x8_t v_dst = vorrq_u16(vandq_u16(v_condition, v_src1), vbicq_u16(v_condition, v_src2));\n        vst1q_u16(dst + i, v_dst);\n    }\n\n    for (; i < length; ++i) {\n        if ((i & mask) != 0) {\n            dst[i] = src1[i];\n        } else {\n            dst[i] = src2[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_15_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid vector_blend_simd(const uint16_t* src1, const uint16_t* src2, uint32_t mask, uint16_t* dst, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 8; i += 8) {\n        uint16x8_t vidx = vld1q_u16(&i);\n        uint16x8_t vmask = vdupq_n_u16(mask);\n        uint16x8_t vand = vandq_u16(vidx, vmask);\n        uint16x8_t vcond = vreinterpretq_u16_u8(vceqq_u16(vand, vdupq_n_u16(0)));\n        uint16x8_t vsrc1 = vld1q_u16(src1 + i);\n        uint16x8_t vsrc2 = vld1q_u16(src2 + i);\n        uint16x8_t vresult = vbslq_u16(vcond, vsrc1, vsrc2);\n        vst1q_u16(dst + i, vresult);\n    }\n    for (; i < length; ++i) {\n        if ((i & mask) != 0) {\n            dst[i] = src1[i];\n        } else {\n            dst[i] = src2[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_15_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nvoid vector_blend_simd(const uint16_t* src1, const uint16_t* src2, uint32_t mask, uint16_t* dst, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 8; i += 8) {\n        uint16x8_t v_mask = vdupq_n_u16(mask);\n        uint16x8_t v_index = vld1q_u16((uint16_t*)(i + (const uint16_t*)src1));\n        uint16x8_t v_condition = vandq_u16(v_index, v_mask);\n\n        uint16x8_t v_src1 = vld1q_u16(src1 + i);\n        uint16x8_t v_src2 = vld1q_u16(src2 + i);\n\n        uint16x8_t v_result = vorrq_u16(vbicq_u16(v_src1, v_condition), vbicq_u16(v_src2, vmvnq_u16(v_condition)));\n        vst1q_u16(dst + i, v_result);\n    }\n\n    for (; i < length; ++i) {\n        if ((i & mask) != 0) {\n            dst[i] = src1[i];\n        } else {\n            dst[i] = src2[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_15_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid vector_blend_simd(const uint16_t* src1, const uint16_t* src2, uint32_t mask, uint16_t* dst, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 8; i += 8) {\n        uint16x8_t v_mask = vdupq_n_u16(mask);\n        uint16x8_t v_index = vld1q_u16((uint16_t*)&i);\n        uint16x8_t v_condition = vandq_u16(v_index, v_mask);\n\n        uint16x8_t v_src1 = vld1q_u16(src1 + i);\n        uint16x8_t v_src2 = vld1q_u16(src2 + i);\n\n        uint16x8_t v_result = vorrq_u16(vandq_u16(v_condition, v_src1), vbicq_u16(v_condition, v_src2));\n        vst1q_u16(dst + i, v_result);\n    }\n\n    for (; i < length; ++i) {\n        if ((i & mask) != 0) {\n            dst[i] = src1[i];\n        } else {\n            dst[i] = src2[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_15_Neon", "completion": "```cpp\nvoid vector_blend_simd(const uint16_t* src1, const uint16_t* src2, uint32_t mask, uint16_t* dst, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 8; i += 8) {\n        uint16x8_t v_mask = vdupq_n_u16(mask);\n        uint16x8_t v_index = vld1q_u16((uint16_t*)&i);\n        uint16x8_t v_condition = vandq_u16(v_index, v_mask);\n\n        uint16x8_t v_src1 = vld1q_u16(src1 + i);\n        uint16x8_t v_src2 = vld1q_u16(src2 + i);\n\n        uint16x8_t v_result = vorrq_u16(vandq_u16(v_condition, v_src1), vbicq_u16(v_condition, v_src2));\n        vst1q_u16(dst + i, v_result);\n    }\n\n    for (; i < length; ++i) {\n        if ((i & mask) != 0) {\n            dst[i] = src1[i];\n        } else {\n            dst[i] = src2[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_16_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid population_count_simd(const uint32_t* src, uint32_t* dst, size_t length) {\n    const size_t neon_width = 16; // Number of elements processed per iteration\n    size_t i;\n\n    for (i = 0; i <= length - neon_width; i += neon_width) {\n        uint32x4_t vsrc1 = vld1q_u32(src + i);\n        uint32x4_t vsrc2 = vld1q_u32(src + i + 4);\n        uint32x4_t vsrc3 = vld1q_u32(src + i + 8);\n        uint32x4_t vsrc4 = vld1q_u32(src + i + 12);\n\n        uint32x4_t vpopcount1 = vpclsq_u32(vsrc1);\n        uint32x4_t vpopcount2 = vpclsq_u32(vsrc2);\n        uint32x4_t vpopcount3 = vpclsq_u32(vsrc3);\n        uint32x4_t vpopcount4 = vpclsq_u32(vsrc4);\n\n        vst1q_u32(dst + i, vpopcount1);\n        vst1q_u32(dst + i + 4, vpopcount2);\n        vst1q_u32(dst + i + 8, vpopcount3);\n        vst1q_u32(dst + i + 12, vpopcount4);\n    }\n\n    // Handle remaining elements\n    for (; i < length; ++i) {\n        dst[i] = __builtin_popcount(src[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_16_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid population_count_simd(const uint32_t* src, uint32_t* dst, size_t length) {\n    const uint32x4_t vones = vdupq_n_u32(0xFFFFFFFF);\n    const uint32x4_t vmasks[] = {\n        vdupq_n_u32(0x55555555),\n        vdupq_n_u32(0x33333333),\n        vdupq_n_u32(0x0F0F0F0F),\n        vdupq_n_u32(0x00FF00FF)\n    };\n\n    size_t i;\n    for (i = 0; i + 16 <= length; i += 16) {\n        uint32x4_t v0 = vld1q_u32(src + i + 0);\n        uint32x4_t v1 = vld1q_u32(src + i + 4);\n        uint32x4_t v2 = vld1q_u32(src + i + 8);\n        uint32x4_t v3 = vld1q_u32(src + i + 12);\n\n        v0 = vandq_u32(v0, vmasks[0]);\n        v1 = vandq_u32(v1, vmasks[0]);\n        v2 = vandq_u32(v2, vmasks[0]);\n        v3 = vandq_u32(v3, vmasks[0]);\n\n        v0 = vhaddq_u32(v0, vshrq_n_u32(v0, 1));\n        v1 = vhaddq_u32(v1, vshrq_n_u32(v1, 1));\n        v2 = vhaddq_u32(v2, vshrq_n_u32(v2, 1));\n        v3 = vhaddq_u32(v3, vshrq_n_u32(v3, 1));\n\n        v0 = vhaddq_u32(v0, vshrq_n_u32(v0, 2));\n        v1 = vhaddq_u32(v1, vshrq_n_u32(v1, 2));\n        v2 = vhaddq_u32(v2, vshrq_n_u32(v2, 2));\n        v3 = vhaddq_u32(v3, vshrq_n_u32(v3, 2));\n\n        v0 = vhaddq_u32(v0, vshrq_n_u32(v0, 4));\n        v1 = vhaddq_u32(v1, vshrq_n_u32(v1, 4));\n        v2 = vhaddq_u32(v2, vshrq_n_u32(v2, 4));\n        v3 = vhaddq_u32(v3, vshrq_n_u32(v3, 4));\n\n        v0 = vhaddq_u32(v0, vshrq_n_u32(v0, 8));\n        v1 = vhaddq_u32(v1, vshrq_n_u32(v1, 8));\n        v2 = vhaddq_u32(v2, vshrq_n_u32(v2, 8));\n        v3 = vhaddq_u32(v3, vshrq_n_u32(v3, 8));\n\n        vst1q_u32(dst + i + 0, v0);\n        vst1q_u32(dst + i + 4, v1);\n        vst1q_u32(dst + i + 8, v2);\n        vst1q_u32(dst + i + 12, v3);\n    }\n\n    for (; i < length; ++i) {\n        dst[i] = __builtin_popcount(src[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_16_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nvoid population_count_simd(const uint32_t* src, uint32_t* dst, size_t length) {\n    const size_t simd_width = 4;\n    size_t i;\n\n    // Process elements in chunks of 4\n    for (i = 0; i <= length - simd_width; i += simd_width) {\n        uint32x4_t vsrc = vld1q_u32(src + i);\n        uint32x4_t vpopcount = vpclsq_u32(vsrc);\n        vst1q_u32(dst + i, vpopcount);\n    }\n\n    // Handle remaining elements\n    for (; i < length; ++i) {\n        dst[i] = __builtin_popcount(src[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_16_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nvoid population_count_simd(const uint32_t* src, uint32_t* dst, size_t length) {\n    const size_t neon_width = 16; // Number of elements processed per iteration\n    size_t i;\n\n    // Process elements in chunks of 16\n    for (i = 0; i <= length - neon_width; i += neon_width) {\n        uint32x4_t vsrc1 = vld1q_u32(src + i);\n        uint32x4_t vsrc2 = vld1q_u32(src + i + 4);\n        uint32x4_t vsrc3 = vld1q_u32(src + i + 8);\n        uint32x4_t vsrc4 = vld1q_u32(src + i + 12);\n\n        uint32x4_t vpopcount1 = vpclsq_u32(vsrc1);\n        uint32x4_t vpopcount2 = vpclsq_u32(vsrc2);\n        uint32x4_t vpopcount3 = vpclsq_u32(vsrc3);\n        uint32x4_t vpopcount4 = vpclsq_u32(vsrc4);\n\n        vst1q_u32(dst + i, vpopcount1);\n        vst1q_u32(dst + i + 4, vpopcount2);\n        vst1q_u32(dst + i + 8, vpopcount3);\n        vst1q_u32(dst + i + 12, vpopcount4);\n    }\n\n    // Process remaining elements\n    for (; i < length; ++i) {\n        dst[i] = __builtin_popcount(src[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_16_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid population_count_simd(const uint32_t* src, uint32_t* dst, size_t length) {\n    const size_t simd_width = 16; // Number of elements processed per iteration\n    size_t i;\n\n    // Process elements in chunks of 16\n    for (i = 0; i <= length - simd_width; i += simd_width) {\n        uint32x4_t vsrc1 = vld1q_u32(src + i);\n        uint32x4_t vsrc2 = vld1q_u32(src + i + 4);\n        uint32x4_t vsrc3 = vld1q_u32(src + i + 8);\n        uint32x4_t vsrc4 = vld1q_u32(src + i + 12);\n\n        uint32x4_t vpopcount1 = vpclsq_u32(vsrc1);\n        uint32x4_t vpopcount2 = vpclsq_u32(vsrc2);\n        uint32x4_t vpopcount3 = vpclsq_u32(vsrc3);\n        uint32x4_t vpopcount4 = vpclsq_u32(vsrc4);\n\n        vst1q_u32(dst + i, vpopcount1);\n        vst1q_u32(dst + i + 4, vpopcount2);\n        vst1q_u32(dst + i + 8, vpopcount3);\n        vst1q_u32(dst + i + 12, vpopcount4);\n    }\n\n    // Process remaining elements\n    for (; i < length; ++i) {\n        dst[i] = __builtin_popcount(src[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_17_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nvoid saturating_add_simd(const uint16_t* src1, const uint16_t* src2, uint16_t* dst, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 8; i += 8) {\n        uint16x8_t vsrc1 = vld1q_u16(src1 + i);\n        uint16x8_t vsrc2 = vld1q_u16(src2 + i);\n        uint16x8_t vdst = vsatq_u16(vaddq_u16(vsrc1, vsrc2));\n        vst1q_u16(dst + i, vdst);\n    }\n    for (; i < length; ++i) {\n        dst[i] = __builtin_saturate_ushort((unsigned short)(src1[i] + src2[i]));\n    }\n}\n```"}
{"task_id": "SimdBench_17_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid saturating_add_simd(const uint16_t* src1, const uint16_t* src2, uint16_t* dst, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 8; i += 8) {\n        uint16x8_t vsrc1 = vld1q_u16(src1 + i);\n        uint16x8_t vsrc2 = vld1q_u16(src2 + i);\n        uint16x8_t vdst = vsatq_u16(vaddq_u16(vsrc1, vsrc2));\n        vst1q_u16(dst + i, vdst);\n    }\n    for (; i < length; ++i) {\n        dst[i] = __builtin_saturate_ushort((unsigned short)(src1[i] + src2[i]));\n    }\n}\n```"}
{"task_id": "SimdBench_17_Neon", "completion": "```cpp\nvoid saturating_add_simd(const uint16_t* src1, const uint16_t* src2, uint16_t* dst, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 8; i += 8) {\n        uint16x8_t vsrc1 = vld1q_u16(src1 + i);\n        uint16x8_t vsrc2 = vld1q_u16(src2 + i);\n        uint16x8_t vdst = vsatq_u16(vaddq_u16(vsrc1, vsrc2));\n        vst1q_u16(dst + i, vdst);\n    }\n    for (; i < length; ++i) {\n        dst[i] = __builtin_saturate_ushort((unsigned short)(src1[i] + src2[i]));\n    }\n}\n```"}
{"task_id": "SimdBench_17_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid saturating_add_simd(const uint16_t* src1, const uint16_t* src2, uint16_t* dst, size_t length) {\n    size_t i;\n    for (i = 0; i <= length - 8; i += 8) {\n        uint16x8_t vsrc1 = vld1q_u16(src1 + i);\n        uint16x8_t vsrc2 = vld1q_u16(src2 + i);\n        uint16x8_t vdst = vsatq_u16(vaddq_u16(vsrc1, vsrc2));\n        vst1q_u16(dst + i, vdst);\n    }\n    for (; i < length; ++i) {\n        dst[i] = __builtin_saturate_ushort((unsigned short)(src1[i] + src2[i]));\n    }\n}\n```"}
{"task_id": "SimdBench_17_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nvoid saturating_add_simd(const uint16_t* src1, const uint16_t* src2, uint16_t* dst, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 8; i += 8) {\n        uint16x8_t vsrc1 = vld1q_u16(src1 + i);\n        uint16x8_t vsrc2 = vld1q_u16(src2 + i);\n        uint16x8_t vdst = vsatq_u16(vaddq_u16(vsrc1, vsrc2));\n        vst1q_u16(dst + i, vdst);\n    }\n    for (; i < length; ++i) {\n        dst[i] = __builtin_saturate_ushort((unsigned short)(src1[i] + src2[i]));\n    }\n}\n```"}
{"task_id": "SimdBench_18_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nvoid range_matrix_mul_simd(const double* A, const double* B, double* C, size_t m, size_t n, size_t p) {\n    for (size_t i = 0; i < m; i += 2) {\n        for (size_t j = 0; j < p; j++) {\n            int32x2_t sum = vdup_n_s32(0);\n            for (size_t k = 0; k < n; k += 2) {\n                int64x2_t a = vmovl_s32(vmovl_u8(vcvt_f32_f64(vld1q_f64(&A[i * n + k]))));\n                int64x2_t b = vmovl_s32(vmovl_u8(vcvt_f32_f64(vld1q_f64(&B[k * p + j]))));\n                int64x2_t prod = vmulq_s64(a, b);\n                int32x2_t prod_lo = vmovn_s64(prod);\n                int32x2_t prod_hi = vmovn_high_s64(prod);\n                sum = vaddw_s32(sum, prod_lo);\n                sum = vaddw_s32(sum, prod_hi);\n            }\n            if (i + 1 < m) {\n                int64x2_t a = vmovl_s32(vmovl_u8(vcvt_f32_f64(vld1q_f64(&A[(i + 1) * n + k]))));\n                int64x2_t b = vmovl_s32(vmovl_u8(vcvt_f32_f64(vld1q_f64(&B[k * p + j]))));\n                int64x2_t prod = vmulq_s64(a, b);\n                int32x2_t prod_lo = vmovn_s64(prod);\n                int32x2_t prod_hi = vmovn_high_s64(prod);\n                sum = vaddw_s32(sum, prod_lo);\n                sum = vaddw_s32(sum, prod_hi);\n            }\n            C[i * p + j] = (double)vget_lane_s32(sum, 0);\n            if (i + 1 < m) {\n                C[(i + 1) * p + j] = (double)vget_lane_s32(sum, 1);\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_18_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nvoid range_matrix_mul_simd(const double* A, const double* B, double* C, size_t m, size_t n, size_t p) {\n    for (size_t i = 0; i < m; i += 2) {\n        for (size_t j = 0; j < p; j++) {\n            int32x2_t sum = vdup_n_s32(0);\n            for (size_t k = 0; k < n; k += 2) {\n                int64x2_t a = vld1q_f64(&A[i * n + k]);\n                int64x2_t b = vld1q_f64(&B[k * p + j]);\n                int64x2_t mask_a = vcgtq_f64(a, vdupq_n_f64(-100));\n                int64x2_t mask_b = vcltq_f64(b, vdupq_n_f64(100));\n                int64x2_t mask = vandq_s64(mask_a, mask_b);\n                int64x2_t masked_a = vmulq_s64(vreinterpretq_s64_f64(a),vreinterpretq_s64_f64(mask));\n                int64x2_t masked_b = vmulq_s64(vreinterpretq_s64_f64(b),vreinterpretq_s64_f64(mask));\n                int32x2_t mul = vmovl_s64(vaddl_s64(vmull_s64(vget_low_s64(masked_a),vget_low_s64(masked_b)),vmull_s64(vget_high_s64(masked_a),vget_high_s64(masked_b))));\n                sum = vmlal_s32(sum,mul,vdup_n_s32(1));\n            }\n            C[i * p + j] = vget_lane_f64(vreinterpretq_f64_s32(sum),0);\n            if (i + 1 < m) {\n                int32x2_t sum2 = vdup_n_s32(0);\n                for (size_t k = 0; k < n; k += 2) {\n                    int64x2_t a = vld1q_f64(&A[(i + 1) * n + k]);\n                    int64x2_t b = vld1q_f64(&B[k * p + j]);\n                    int64x2_t mask_a = vcgtq_f64(a, vdupq_n_f64(-100));\n                    int64x2_t mask_b = vcltq_f64(b, vdupq_n_f64(100));\n                    int64x2_t mask = vandq_s64(mask_a, mask_b);\n                    int64x2_t masked_a = vmulq_s64(vreinterpretq_s64_f64(a),vreinterpretq_s64_f64(mask));\n                    int64x2_t masked_b = vmulq_s64(vreinterpretq_s64_f64(b),vreinterpretq_s64_f64(mask));\n                    int32x2_t mul = vmovl_s64(vaddl_s64(vmull_s64(vget_low_s64(masked_a),vget_low_s64(masked_b)),vmull_s64(vget_high_s64(masked_a),vget_high_s64(masked_b))));\n                    sum2 = vmlal_s32(sum2,mul,vdup_n_s32(1));\n                }\n                C[(i + 1) * p + j] = vget_lane_f64(vreinterpretq_f64_s32(sum2),0);\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_18_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nvoid range_matrix_mul_simd(const double* A, const double* B, double* C, size_t m, size_t n, size_t p) {\n    for (size_t i = 0; i < m; i++) {\n        for (size_t j = 0; j < p; j++) {\n            int32x2_t sum = vdup_n_s32(0);\n            for (size_t k = 0; k < n; k += 2) {\n                int64x2_t a = vmovl_s32(vmovl_u8(vcvt_f32_f64(vld1q_f64(A + i * n + k))));\n                int64x2_t b = vmovl_s32(vmovl_u8(vcvt_f32_f64(vld1q_f64(B + k * p + j))));\n                int64x2_t temp = vmulq_s64(a, b);\n                int32x2_t temp_sum = vaddw_s32(sum, vmovl_s32(vget_low_s32(temp)));\n                sum = vaddw_s32(sum, vmovl_s32(vget_high_s32(temp)));\n            }\n            C[i * p + j] = static_cast<double>(vget_lane_s32(sum, 0)) + static_cast<double>(vget_lane_s32(sum, 1));\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_18_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nvoid range_matrix_mul_simd(const double* A, const double* B, double* C, size_t m, size_t n, size_t p) {\n    for (size_t i = 0; i < m; i++) {\n        for (size_t j = 0; j < p; j++) {\n            int32x2_t sum = vdup_n_s32(0);\n            for (size_t k = 0; k < n; k += 2) {\n                double2_t a_val = vld1q_f64(&A[i * n + k]);\n                double2_t b_val = vld1q_f64(&B[k * p + j]);\n                int32x2_t a_int = vcvt_s32_f32(vcvt_f32_f64(a_val));\n                int32x2_t b_int = vcvt_s32_f32(vcvt_f32_f64(b_val));\n                int32x2_t mask_a = vclt_s32(a_int, vdup_n_s32(-100));\n                int32x2_t mask_b = vcgt_s32(a_int, vdup_n_s32(100));\n                int32x2_t mask_c = vclt_s32(b_int, vdup_n_s32(-100));\n                int32x2_t mask_d = vcgt_s32(b_int, vdup_n_s32(100));\n                int32x2_t valid_mask = vbic_s32(vbic_s32(mask_a, mask_b), vbic_s32(mask_c, mask_d));\n                int32x2_t prod = vmul_s32(a_int, b_int);\n                int32x2_t masked_prod = vbsl_s32(valid_mask, prod, vdup_n_s32(0));\n                sum = vadd_s32(sum, masked_prod);\n            }\n            C[i * p + j] = static_cast<double>(vget_lane_s32(sum, 0)) + static_cast<double>(vget_lane_s32(sum, 1));\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_18_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nvoid range_matrix_mul_simd(const double* A, const double* B, double* C, size_t m, size_t n, size_t p) {\n    for (size_t i = 0; i < m; i++) {\n        for (size_t j = 0; j < p; j++) {\n            int32x2_t sum = vdup_n_s32(0);\n            for (size_t k = 0; k < n; k += 2) {\n                int64x2_t a = vmovl_s32(vmovl_u8(vcvt_f32_f64(vld1q_f64(&A[i * n + k]))));\n                int64x2_t b = vmovl_s32(vmovl_u8(vcvt_f32_f64(vld1q_f64(&B[k * p + j]))));\n                int64x2_t prod = vmulq_s64(a, b);\n                int32x2_t prod_lo = vmovn_s64(prod);\n                int32x2_t prod_hi = vmovn_high_s64(prod);\n                sum = vaddw_s32(sum, prod_lo);\n                sum = vaddw_s32(sum, prod_hi);\n            }\n            if (n % 2 != 0) {\n                int64x2_t a = vmovl_s32(vmovl_u8(vcvt_f32_f64(vld1q_lane_f64(&A[i * n + n - 1], &A[i * n], 0))));\n                int64x2_t b = vmovl_s32(vmovl_u8(vcvt_f32_f64(vld1q_lane_f64(&B[(n - 1) * p + j], &B[(n - 1) * p], 0))));\n                int64x2_t prod = vmulq_s64(a, b);\n                int32x2_t prod_lo = vmovn_s64(prod);\n                sum = vaddw_s32(sum, prod_lo);\n            }\n            C[i * p + j] = static_cast<double>(vget_lane_s32(sum, 0)) + static_cast<double>(vget_lane_s32(sum, 1));\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_19_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nvoid tensor_add_3d_simd(const int64_t* A, const int64_t* B, int64_t* C, size_t dim1, size_t dim2, size_t dim3) {\n    size_t i, j, k;\n    for (i = 0; i < dim1; ++i) {\n        for (j = 0; j < dim2; j += 4) {\n            int64x2_t va0 = vld1q_s64(A + i * dim2 * dim3 + j * dim3);\n            int64x2_t vb0 = vld1q_s64(B + i * dim2 * dim3 + j * dim3);\n            int64x2_t vc0 = vaddq_s64(va0, vb0);\n            vst1q_s64(C + i * dim2 * dim3 + j * dim3, vc0);\n\n            int64x2_t va1 = vld1q_s64(A + i * dim2 * dim3 + (j + 2) * dim3);\n            int64x2_t vb1 = vld1q_s64(B + i * dim2 * dim3 + (j + 2) * dim3);\n            int64x2_t vc1 = vaddq_s64(va1, vb1);\n            vst1q_s64(C + i * dim2 * dim3 + (j + 2) * dim3, vc1);\n        }\n        for (; j < dim2; ++j) {\n            C[i * dim2 * dim3 + j * dim3] = A[i * dim2 * dim3 + j * dim3] + B[i * dim2 * dim3 + j * dim3];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_19_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid tensor_add_3d_simd(const int64_t* A, const int64_t* B, int64_t* C, size_t dim1, size_t dim2, size_t dim3) {\n    size_t i, j, k;\n    for (i = 0; i < dim1; ++i) {\n        for (j = 0; j < dim2; j += 4) {\n            int64x2_t va0 = vld1q_s64(A + i * dim2 * dim3 + j * dim3);\n            int64x2_t vb0 = vld1q_s64(B + i * dim2 * dim3 + j * dim3);\n            int64x2_t vc0 = vaddq_s64(va0, vb0);\n            vst1q_s64(C + i * dim2 * dim3 + j * dim3, vc0);\n\n            int64x2_t va1 = vld1q_s64(A + i * dim2 * dim3 + (j + 2) * dim3);\n            int64x2_t vb1 = vld1q_s64(B + i * dim2 * dim3 + (j + 2) * dim3);\n            int64x2_t vc1 = vaddq_s64(va1, vb1);\n            vst1q_s64(C + i * dim2 * dim3 + (j + 2) * dim3, vc1);\n        }\n        for (; j < dim2; ++j) {\n            C[i * dim2 * dim3 + j * dim3] = A[i * dim2 * dim3 + j * dim3] + B[i * dim2 * dim3 + j * dim3];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_19_Neon", "completion": "```cpp\nvoid tensor_add_3d_simd(const int64_t* A, const int64_t* B, int64_t* C, size_t dim1, size_t dim2, size_t dim3) {\n    for (size_t i = 0; i < dim1; ++i) {\n        for (size_t j = 0; j < dim2; j += 4) {\n            int64x2_t va = vld1q_s64(A + i * dim2 * dim3 + j * dim3);\n            int64x2_t vb = vld1q_s64(B + i * dim2 * dim3 + j * dim3);\n            int64x2_t vc = vaddq_s64(va, vb);\n            vst1q_s64(C + i * dim2 * dim3 + j * dim3, vc);\n\n            va = vld1q_s64(A + i * dim2 * dim3 + (j + 2) * dim3);\n            vb = vld1q_s64(B + i * dim2 * dim3 + (j + 2) * dim3);\n            vc = vaddq_s64(va, vb);\n            vst1q_s64(C + i * dim2 * dim3 + (j + 2) * dim3, vc);\n        }\n        for (size_t k = (dim2 / 4) * 4; k < dim2; ++k) {\n            C[i * dim2 * dim3 + k * dim3] = A[i * dim2 * dim3 + k * dim3] + B[i * dim2 * dim3 + k * dim3];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_19_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nvoid tensor_add_3d_simd(const int64_t* A, const int64_t* B, int64_t* C, size_t dim1, size_t dim2, size_t dim3) {\n    for (size_t i = 0; i < dim1; ++i) {\n        for (size_t j = 0; j < dim2; j += 4) {\n            int64x2_t va = vld1q_s64(A + i * dim2 * dim3 + j * dim3);\n            int64x2_t vb = vld1q_s64(B + i * dim2 * dim3 + j * dim3);\n            int64x2_t vc = vaddq_s64(va, vb);\n            vst1q_s64(C + i * dim2 * dim3 + j * dim3, vc);\n\n            va = vld1q_s64(A + i * dim2 * dim3 + (j + 2) * dim3);\n            vb = vld1q_s64(B + i * dim2 * dim3 + (j + 2) * dim3);\n            vc = vaddq_s64(va, vb);\n            vst1q_s64(C + i * dim2 * dim3 + (j + 2) * dim3, vc);\n        }\n        for (size_t k = dim2 % 4; k < dim2; ++k) {\n            C[i * dim2 * dim3 + k * dim3] = A[i * dim2 * dim3 + k * dim3] + B[i * dim2 * dim3 + k * dim3];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_19_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid tensor_add_3d_simd(const int64_t* A, const int64_t* B, int64_t* C, size_t dim1, size_t dim2, size_t dim3) {\n    size_t i, j, k;\n    for (i = 0; i < dim1; ++i) {\n        for (j = 0; j < dim2; j += 4) {\n            int64x2_t va0 = vld1q_s64(A + i * dim2 * dim3 + j * dim3);\n            int64x2_t vb0 = vld1q_s64(B + i * dim2 * dim3 + j * dim3);\n            int64x2_t vc0 = vaddq_s64(va0, vb0);\n            vst1q_s64(C + i * dim2 * dim3 + j * dim3, vc0);\n\n            int64x2_t va1 = vld1q_s64(A + i * dim2 * dim3 + (j + 2) * dim3);\n            int64x2_t vb1 = vld1q_s64(B + i * dim2 * dim3 + (j + 2) * dim3);\n            int64x2_t vc1 = vaddq_s64(va1, vb1);\n            vst1q_s64(C + i * dim2 * dim3 + (j + 2) * dim3, vc1);\n        }\n        for (; j < dim2; ++j) {\n            C[i * dim2 * dim3 + j * dim3] = A[i * dim2 * dim3 + j * dim3] + B[i * dim2 * dim3 + j * dim3];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_20_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid vector_add_round_nearest_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    size_t i;\n    for (i = 0; i <= length - 4; i += 4) {\n        float32x4_t v_src1 = vld1q_f32(src1 + i);\n        float32x4_t v_src2 = vld1q_f32(src2 + i);\n        float32x4_t v_sum = vaddq_f32(v_src1, v_src2);\n        float32x4_t v_rounded = vrndnq_f32(v_sum);\n        vst1q_f32(dst + i, v_rounded);\n    }\n    for (; i < length; ++i) {\n        dst[i] = roundf(src1[i] + src2[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_20_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nvoid vector_add_round_nearest_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 4; i += 4) {\n        float32x4_t v_src1 = vld1q_f32(src1 + i);\n        float32x4_t v_src2 = vld1q_f32(src2 + i);\n        float32x4_t v_sum = vaddq_f32(v_src1, v_src2);\n        float32x4_t v_rounded = vrndnq_f32(v_sum);\n        vst1q_f32(dst + i, v_rounded);\n    }\n    for (; i < length; ++i) {\n        dst[i] = roundf(src1[i] + src2[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_20_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid vector_add_round_nearest_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    size_t i;\n    for (i = 0; i <= length - 4; i += 4) {\n        float32x4_t v_src1 = vld1q_f32(src1 + i);\n        float32x4_t v_src2 = vld1q_f32(src2 + i);\n        float32x4_t v_sum = vaddq_f32(v_src1, v_src2);\n        float32x4_t v_rounded = vrndnq_f32(v_sum);\n        vst1q_f32(dst + i, v_rounded);\n    }\n    for (; i < length; ++i) {\n        dst[i] = roundf(src1[i] + src2[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_20_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nvoid vector_add_round_nearest_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 4; i += 4) {\n        float32x4_t v_src1 = vld1q_f32(src1 + i);\n        float32x4_t v_src2 = vld1q_f32(src2 + i);\n        float32x4_t v_sum = vaddq_f32(v_src1, v_src2);\n        float32x4_t v_rounded = vrndnq_f32(v_sum);\n        vst1q_f32(dst + i, v_rounded);\n    }\n    for (; i < length; ++i) {\n        dst[i] = roundf(src1[i] + src2[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_20_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nvoid vector_add_round_nearest_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 4; i += 4) {\n        float32x4_t v_src1 = vld1q_f32(src1 + i);\n        float32x4_t v_src2 = vld1q_f32(src2 + i);\n        float32x4_t v_sum = vaddq_f32(v_src1, v_src2);\n        float32x4_t v_rounded = vrndnq_f32(v_sum);\n        vst1q_f32(dst + i, v_rounded);\n    }\n    for (; i < length; ++i) {\n        dst[i] = roundf(src1[i] + src2[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_21_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid vector_mul_round_up_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 8; i += 8) {\n        float32x4_t vsrc1_0 = vld1q_f32(src1 + i);\n        float32x4_t vsrc2_0 = vld1q_f32(src2 + i);\n        float32x4_t vsrc1_1 = vld1q_f32(src1 + i + 4);\n        float32x4_t vsrc2_1 = vld1q_f32(src2 + i + 4);\n\n        float32x4_t vdiff_0 = vabsq_f32(vsubq_f32(vsrc1_0, vsrc2_0));\n        float32x4_t vdiff_1 = vabsq_f32(vsubq_f32(vsrc1_1, vsrc2_1));\n\n        uint32x4_t vmask_0 = vcgtq_f32(vdiff_0, vdupq_n_f32(50.0f));\n        uint32x4_t vmask_1 = vcgtq_f32(vdiff_1, vdupq_n_f32(50.0f));\n\n        uint32x4_t vmask_index_0 = vceqq_u32(vreinterpretq_u32_s32(vcltq_s32(vreinterpretq_s32_u32(vmask_0), vdupq_n_u32(2))));\n        uint32x4_t vmask_index_1 = vceqq_u32(vreinterpretq_u32_s32(vcltq_s32(vreinterpretq_s32_u32(vmask_1), vdupq_n_u32(2))));\n\n        uint32x4_t vmask_final_0 = vbicq_u32(vmask_0, vmask_index_0);\n        uint32x4_t vmask_final_1 = vbicq_u32(vmask_1, vmask_index_1);\n\n        float32x4_t vresult_0 = vmulq_f32(vsrc1_0, vsrc2_0);\n        float32x4_t vresult_1 = vmulq_f32(vsrc1_1, vsrc2_1);\n\n        vresult_0 = vrndpq_f32(vaddq_f32(vresult_0, vmulq_f32(vresult_0, vdupq_n_f32(0.5f))));\n        vresult_1 = vrndpq_f32(vaddq_f32(vresult_1, vmulq_f32(vresult_1, vdupq_n_f32(0.5f))));\n\n        vresult_0 = vbslq_f32(vmask_final_0, vresult_0, vdupq_n_f32(-1.0f));\n        vresult_1 = vbslq_f32(vmask_final_1, vresult_1, vdupq_n_f32(-1.0f));\n\n        vst1q_f32(dst + i, vresult_0);\n        vst1q_f32(dst + i + 4, vresult_1);\n    }\n\n    for (; i < length; ++i) {\n        if (fabs(src1[i] - src2[i]) <= 50 && i % 2 == 0) {\n            dst[i] = ceil(src1[i] * src2[i]);\n        } else {\n            dst[i] = -1.0f;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_21_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid vector_mul_round_up_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 8; i += 8) {\n        float32x4_t v_src1_1 = vld1q_f32(src1 + i);\n        float32x4_t v_src2_1 = vld1q_f32(src2 + i);\n        float32x4_t v_diff_1 = vabsq_f32(vsubq_f32(v_src1_1, v_src2_1));\n        uint32x4_t v_mask_1 = vcgtq_f32(v_diff_1, vdupq_n_f32(50.0f));\n\n        float32x4_t v_src1_2 = vld1q_f32(src1 + i + 4);\n        float32x4_t v_src2_2 = vld1q_f32(src2 + i + 4);\n        float32x4_t v_diff_2 = vabsq_f32(vsubq_f32(v_src1_2, v_src2_2));\n        uint32x4_t v_mask_2 = vcgtq_f32(v_diff_2, vdupq_n_f32(50.0f));\n\n        uint32x4_t v_index_mask = vandq_u32(vdupq_n_u32(0xAAAAAAAA), vmovq_n_u32(i / 2));\n\n        float32x4_t v_result_1 = vbslq_f32(vandq_u32(v_mask_1, v_index_mask), vrndpq_f32(vmulq_f32(v_src1_1, v_src2_1)), vdupq_n_f32(-1.0f));\n        float32x4_t v_result_2 = vbslq_f32(vandq_u32(v_mask_2, v_index_mask), vrndpq_f32(vmulq_f32(v_src1_2, v_src2_2)), vdupq_n_f32(-1.0f));\n\n        vst1q_f32(dst + i, v_result_1);\n        vst1q_f32(dst + i + 4, v_result_2);\n    }\n\n    for (; i < length; ++i) {\n        if (fabs(src1[i] - src2[i]) <= 50 && i % 2 == 0) {\n            dst[i] = ceil(src1[i] * src2[i]);\n        } else {\n            dst[i] = -1.0f;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_21_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid vector_mul_round_up_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 8; i += 8) {\n        float32x4_t v_src1_0 = vld1q_f32(src1 + i);\n        float32x4_t v_src2_0 = vld1q_f32(src2 + i);\n        float32x4_t v_diff_0 = vabsq_f32(vsubq_f32(v_src1_0, v_src2_0));\n        uint32x4_t v_mask_0 = vcgtq_f32(v_diff_0, vdupq_n_f32(50.0f));\n        uint32x4_t v_index_mask_0 = vmovq_n_u32(i % 2 == 0 ? 0xFFFFFFFF : 0);\n\n        float32x4_t v_src1_1 = vld1q_f32(src1 + i + 4);\n        float32x4_t v_src2_1 = vld1q_f32(src2 + i + 4);\n        float32x4_t v_diff_1 = vabsq_f32(vsubq_f32(v_src1_1, v_src2_1));\n        uint32x4_t v_mask_1 = vcgtq_f32(v_diff_1, vdupq_n_f32(50.0f));\n        uint32x4_t v_index_mask_1 = vmovq_n_u32((i + 4) % 2 == 0 ? 0xFFFFFFFF : 0);\n\n        uint32x4_t v_combined_mask_0 = vbicq_u32(v_mask_0, v_index_mask_0);\n        uint32x4_t v_combined_mask_1 = vbicq_u32(v_mask_1, v_index_mask_1);\n\n        float32x4_t v_result_0 = vmulq_f32(v_src1_0, v_src2_0);\n        float32x4_t v_result_1 = vmulq_f32(v_src1_1, v_src2_1);\n\n        vst1q_lane_s32((int32_t*)&v_result_0, vreinterpretq_s32_f32(v_result_0), 0);\n        vst1q_lane_s32((int32_t*)&v_result_0, vreinterpretq_s32_f32(v_result_0), 1);\n        vst1q_lane_s32((int32_t*)&v_result_0, vreinterpretq_s32_f32(v_result_0), 2);\n        vst1q_lane_s32((int32_t*)&v_result_0, vreinterpretq_s32_f32(v_result_0), 3);\n\n        vst1q_lane_s32((int32_t*)&v_result_1, vreinterpretq_s32_f32(v_result_1), 0);\n        vst1q_lane_s32((int32_t*)&v_result_1, vreinterpretq_s32_f32(v_result_1), 1);\n        vst1q_lane_s32((int32_t*)&v_result_1, vreinterpretq_s32_f32(v_result_1), 2);\n        vst1q_lane_s32((int32_t*)&v_result_1, vreinterpretq_s32_f32(v_result_1), 3);\n\n        vst1q_f32(dst + i, vcombine_f32(v_result_0, v_result_1));\n    }\n\n    for (; i < length; ++i) {\n        if (fabs(src1[i] - src2[i]) <= 50 && i % 2 == 0) {\n            dst[i] = ceil(src1[i] * src2[i]);\n        } else {\n            dst[i] = -1;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_21_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nvoid vector_mul_round_up_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 8; i += 8) {\n        float32x4_t v_src1_1 = vld1q_f32(src1 + i);\n        float32x4_t v_src2_1 = vld1q_f32(src2 + i);\n        float32x4_t v_diff_1 = vabsq_f32(vsubq_f32(v_src1_1, v_src2_1));\n        uint32x4_t v_mask_1 = vcgtq_f32(v_diff_1, vdupq_n_f32(50.0f));\n\n        float32x4_t v_src1_2 = vld1q_f32(src1 + i + 4);\n        float32x4_t v_src2_2 = vld1q_f32(src2 + i + 4);\n        float32x4_t v_diff_2 = vabsq_f32(vsubq_f32(v_src1_2, v_src2_2));\n        uint32x4_t v_mask_2 = vcgtq_f32(v_diff_2, vdupq_n_f32(50.0f));\n\n        uint32x4_t v_index_mask = vmovq_n_u32(i % 8 == 0 && (i + 4) % 8 == 0 ? 0xFFFFFFFF : 0);\n\n        float32x4_t v_result_1 = vmulq_f32(v_src1_1, v_src2_1);\n        float32x4_t v_result_2 = vmulq_f32(v_src1_2, v_src2_2);\n\n        v_result_1 = vrndpq_f32(vaddq_f32(v_result_1, vdupq_n_f32(0.5f)));\n        v_result_2 = vrndpq_f32(vaddq_f32(v_result_2, vdupq_n_f32(0.5f)));\n\n        v_result_1 = vbicq_f32(v_result_1, vreinterpretq_u32_f32(vmaskq_andnot_u32(v_mask_1, v_index_mask)));\n        v_result_2 = vbicq_f32(v_result_2, vreinterpretq_u32_f32(vmaskq_andnot_u32(v_mask_2, v_index_mask)));\n\n        vst1q_f32(dst + i, v_result_1);\n        vst1q_f32(dst + i + 4, v_result_2);\n    }\n\n    for (; i < length; ++i) {\n        if (std::abs(src1[i] - src2[i]) <= 50 && i % 2 == 0) {\n            dst[i] = std::ceil(src1[i] * src2[i]);\n        } else {\n            dst[i] = -1.0f;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_21_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid vector_mul_round_up_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 4; i += 4) {\n        float32x4_t v_src1 = vld1q_f32(src1 + i);\n        float32x4_t v_src2 = vld1q_f32(src2 + i);\n\n        float32x4_t v_diff = vabsq_f32(vsubq_f32(v_src1, v_src2));\n        uint32x4_t v_mask = vcgtq_f32(v_diff, vdupq_n_f32(50.0f));\n\n        uint32x4_t v_index = vmulq_n_u32(vdupq_n_u32(i), vdupq_n_u32(2));\n        uint32x4_t v_condition = veorq_u32(vindexq_u32(), vindexq_u32());\n\n        float32x4_t v_result = vmulq_f32(v_src1, v_src2);\n        v_result = vrndpq_f32(v_result);\n\n        vst1q_f32(dst + i, vresult);\n    }\n\n    for (; i < length; ++i) {\n        if (fabs(src1[i] - src2[i]) <= 50 && i % 2 == 0) {\n            dst[i] = ceil(src1[i] * src2[i]);\n        } else {\n            dst[i] = -1;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_22_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nvoid matrix_scalar_mul_simd(const double* mat, double scalar, double* dst, size_t m, size_t n) {\n    const int vec_size = 4; // Number of elements per vector register\n    const size_t num_vecs = n / vec_size;\n\n    for (size_t i = 0; i < m; ++i) {\n        for (size_t j = 0; j < num_vecs; ++j) {\n            double32x4_t vec_mat = vld1q_f32((const float32_t*)&mat[i * n + j * vec_size]);\n            double32x4_t vec_scalar = vmovq_n_f32(static_cast<float32_t>(scalar));\n            double32x4_t vec_dst = vmulq_f32(vec_mat, vec_scalar);\n            vst1q_f32((float32_t*)&dst[i * n + j * vec_size], vec_dst);\n        }\n\n        // Handle remaining elements that do not fit into a vector register\n        for (size_t j = num_vecs * vec_size; j < n; ++j) {\n            dst[i * n + j] = mat[i * n + j] * scalar;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_22_Neon", "completion": "```cpp\nvoid matrix_scalar_mul_simd(const double* mat, double scalar, double* dst, size_t m, size_t n) {\n    const int vec_size = 4; // Number of elements per vector register\n    for (size_t i = 0; i < m; ++i) {\n        for (size_t j = 0; j < n; j += vec_size) {\n            double32x2_t vec_mat = vld1q_f32((float32_t*)&mat[i * n + j]);\n            double32x2_t vec_scalar = vdupq_n_f32(scalar);\n            double32x2_t vec_result = vmulq_f32(vec_mat, vec_scalar);\n            vst1q_f32((float32_t*)&dst[i * n + j], vec_result);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_22_Neon", "completion": "```cpp\nvoid matrix_scalar_mul_simd(const double* mat, double scalar, double* dst, size_t m, size_t n) {\n    const int vec_size = 4; // Number of elements per vector register\n    const int num_vecs = n / vec_size;\n\n    for (size_t i = 0; i < m; ++i) {\n        for (int j = 0; j < num_vecs; ++j) {\n            vst1q_f64(dst + i * n + j * vec_size, vmulq_n_f64(vld1q_f64(mat + i * n + j * vec_size), scalar));\n        }\n        for (int j = num_vecs * vec_size; j < n; ++j) {\n            dst[i * n + j] = mat[i * n + j] * scalar;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_22_Neon", "completion": "```cpp\nvoid matrix_scalar_mul_simd(const double* mat, double scalar, double* dst, size_t m, size_t n) {\n    const int vec_size = 4; // Number of elements per vector register\n    const int num_vecs_per_row = n / vec_size;\n\n    for (size_t i = 0; i < m; ++i) {\n        for (int j = 0; j < num_vecs_per_row; ++j) {\n            double32x4_t vec_mat = vld1q_f32((const float32_t*)&mat[i * n + j * vec_size]);\n            double32x4_t vec_scalar = vdupq_n_f32(static_cast<float32_t>(scalar));\n            double32x4_t vec_result = vmulq_f32(vec_mat, vec_scalar);\n            vst1q_f32((float32_t*)&dst[i * n + j * vec_size], vec_result);\n        }\n\n        // Handle remaining elements that don't fit into a vector register\n        for (size_t j = num_vecs_per_row * vec_size; j < n; ++j) {\n            dst[i * n + j] = mat[i * n + j] * scalar;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_22_Neon", "completion": "```cpp\nvoid matrix_scalar_mul_simd(const double* mat, double scalar, double* dst, size_t m, size_t n) {\n    const size_t vec_size = 4; // Number of elements per vector register\n    size_t i;\n\n    // Process elements in chunks of vec_size\n    for (i = 0; i <= m * n - vec_size; i += vec_size) {\n        vst1q_f64(dst + i, vmulq_n_f64(vld1q_f64(mat + i), scalar));\n    }\n\n    // Process remaining elements\n    for (; i < m * n; ++i) {\n        dst[i] = mat[i] * scalar;\n    }\n}\n```"}
{"task_id": "SimdBench_23_Neon", "completion": "```cpp\nvoid matrix_normalize_rows_simd(float* mat, size_t m, size_t n) {\n    const int neon_width = 4; // Number of elements processed per iteration\n    float32x4_t vzero = vdupq_n_f32(0.0f);\n    float32x4_t vsqrt = vdupq_n_f32(1.0f / sqrt(neon_width));\n\n    for (size_t i = 0; i < m; ++i) {\n        float32x4_t sum_squares = vzero;\n        for (size_t j = 0; j < n; j += neon_width) {\n            float32x4_t vec = vld1q_f32(&mat[i * n + j]);\n            sum_squares = vfmaq_f32(sum_squares, vec, vec);\n        }\n\n        float32x4_t norm = vsqrt;\n        if (vgetq_lane_f32(sum_squares, 0) > 0.0f) {\n            norm = vrsqrteq_f32(sum_squares);\n            norm = vmulq_f32(norm, norm);\n            norm = vmulq_f32(norm, norm);\n        }\n\n        for (size_t j = 0; j < n; j += neon_width) {\n            float32x4_t vec = vld1q_f32(&mat[i * n + j]);\n            vec = vmulq_f32(vec, norm);\n            vst1q_f32(&mat[i * n + j], vec);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_23_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nvoid matrix_normalize_rows_simd(float* mat, size_t m, size_t n) {\n    const float32x4_t v_one = vdupq_n_f32(1.0f);\n    const float32x4_t v_zero = vdupq_n_f32(0.0f);\n\n    for (size_t i = 0; i < m; ++i) {\n        float32x4_t sum_squares = v_zero;\n        for (size_t j = 0; j < n; j += 4) {\n            float32x4_t vec = vld1q_f32(mat + i * n + j);\n            sum_squares = vmlaq_f32(sum_squares, vec, vec);\n        }\n\n        float32_t sum_squares_arr[4];\n        vst1q_f32(sum_squares_arr, sum_squares);\n        float sum_squares_val = sum_squares_arr[0] + sum_squares_arr[1] +\n                               sum_squares_arr[2] + sum_squares_arr[3];\n\n        if (sum_squares_val > 0.0f) {\n            float inv_norm = sqrtf(sum_squares_val);\n            for (size_t j = 0; j < n; j += 4) {\n                float32x4_t vec = vld1q_f32(mat + i * n + j);\n                vec = vmulq_f32(vec, vdupq_n_f32(inv_norm));\n                vst1q_f32(mat + i * n + j, vec);\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_23_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nvoid matrix_normalize_rows_simd(float* mat, size_t m, size_t n) {\n    float32x4_t vzero = vdupq_n_f32(0.0f);\n    float32x4_t vsqrt = vdupq_n_f32(1.0f / sqrt(4.0));\n\n    for (size_t i = 0; i < m; ++i) {\n        float32x4_t sum_squares = vdupq_n_f32(0.0f);\n        for (size_t j = 0; j < n; j += 4) {\n            float32x4_t vec = vld1q_f32(&mat[i * n + j]);\n            sum_squares = vmlaq_f32(sum_squares, vec, vec);\n        }\n\n        float32_t sum_squares_arr[4];\n        vst1q_f32(sum_squares_arr, sum_squares);\n        float sum_squares_val = sum_squares_arr[0] + sum_squares_arr[1] + sum_squares_arr[2] + sum_squares_arr[3];\n\n        float inv_norm = 1.0f / sqrt(sum_squares_val);\n        float32x4_t vinv_norm = vdupq_n_f32(inv_norm);\n\n        for (size_t j = 0; j < n; j += 4) {\n            float32x4_t vec = vld1q_f32(&mat[i * n + j]);\n            vec = vmulq_f32(vec, vinv_norm);\n            vst1q_f32(&mat[i * n + j], vec);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_23_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nvoid matrix_normalize_rows_simd(float* mat, size_t m, size_t n) {\n    float32x4_t vzero = vdupq_n_f32(0.0f);\n    float32x4_t vsqrt = vdupq_n_f32(1.0f / sqrt(4.0));\n\n    for (size_t i = 0; i < m; ++i) {\n        float32x4_t sum = vzero;\n        for (size_t j = 0; j + 3 < n; j += 4) {\n            float32x4_t vec = vld1q_f32(&mat[i * n + j]);\n            sum = vmlaq_f32(sum, vec, vec);\n        }\n\n        // Handle remaining elements\n        for (; j < n; ++j) {\n            sum[0] += mat[i * n + j] * mat[i * n + j];\n        }\n\n        float32x4_t norm = vrsqrteq_f32(vaddq_f32(sum, vdupq_n_f32(1e-6f)));\n        norm = vmulq_f32(norm, norm);\n\n        for (size_t j = 0; j + 3 < n; j += 4) {\n            float32x4_t vec = vld1q_f32(&mat[i * n + j]);\n            vec = vmulq_f32(vec, vrecpeq_f32(norm));\n            vst1q_f32(&mat[i * n + j], vec);\n        }\n\n        // Handle remaining elements\n        for (; j < n; ++j) {\n            mat[i * n + j] *= 1.0f / norm[0];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_23_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nvoid matrix_normalize_rows_simd(float* mat, size_t m, size_t n) {\n    float32x4_t vzero = vdupq_n_f32(0.0f);\n    float32x4_t vsqrt = vdupq_n_f32(1.0f / sqrt(4.0));\n\n    for (size_t i = 0; i < m; ++i) {\n        float32x4_t sum_squares = vdupq_n_f32(0.0f);\n        for (size_t j = 0; j < n; j += 4) {\n            float32x4_t vec = vld1q_f32(mat + i * n + j);\n            sum_squares = vmlaq_f32(sum_squares, vec, vec);\n        }\n\n        float32x2_t sum_squares_lo = vpadd_f32(vget_low_f32(sum_squares), vget_high_f32(sum_squares));\n        float32x2_t sum_squares_all = vpadd_f32(sum_squares_lo, sum_squares_lo);\n        float32_t norm = vsqrt[0] * vget_lane_f32(sum_squares_all, 0);\n\n        for (size_t j = 0; j < n; j += 4) {\n            float32x4_t vec = vld1q_f32(mat + i * n + j);\n            vec = vmulq_f32(vec, vrecipq_f32(vsqrtq_f32(norm)));\n            vst1q_f32(mat + i * n + j, vec);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_24_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nvoid matrix_mul_round_int_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n, size_t p) {\n    for (size_t i = 0; i < m; ++i) {\n        for (size_t j = 0; j < p; j += 4) {\n            int64x2_t sum0 = vdupq_n_s64(0);\n            int64x2_t sum1 = vdupq_n_s64(0);\n\n            for (size_t k = 0; k < n; k += 2) {\n                int64x2_t vec1 = vmovl_s32(vreinterpret32_f32_u32(vmovl_s16(vreinterpret16_f16_vld1_f32(mat1 + i * n + k))));\n                int64x2_t vec2 = vmovl_s32(vreinterpret32_f32_u32(vmovl_s16(vreinterpret16_f16_vld1_f32(mat2 + k * p + j))));\n                int64x2_t vec3 = vmovl_s32(vreinterpret32_f32_u32(vmovl_s16(vreinterpret16_f16_vld1_f32(mat2 + k * p + j + 2))));\n                int64x2_t vec4 = vmovl_s32(vreinterpret32_f32_u32(vmovl_s16(vreinterpret16_f16_vld1_f32(mat2 + k * p + j + 4))));\n\n                sum0 = vmlal_s64(sum0, vec1, vec2);\n                sum1 = vmlal_s64(sum1, vec3, vec4);\n            }\n\n            int64x2_t sum = vaddq_s64(sum0, sum1);\n            int64x2_t rounded_sum = vrndq_s64(sum);\n            vst1q_f32(dst + i * p + j, vcvtq_f32_s64(rounded_sum));\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_24_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nvoid matrix_mul_round_int_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n, size_t p) {\n    for (size_t i = 0; i < m; ++i) {\n        for (size_t j = 0; j < p; j += 4) {\n            int64x2_t sum0 = vdupq_n_s64(0);\n            int64x2_t sum1 = vdupq_n_s64(0);\n\n            for (size_t k = 0; k < n; k += 2) {\n                int64x2_t vec1 = vmovl_s32(vreinterpret32_f32_u32(vmovl_s16(vreinterpret16_f16_u16(vmovl_s8(vreinterpret8_f8_u8(vld1_u8((const uint8_t*)&mat1[i * n + k]))))));\n                int64x2_t vec2 = vmovl_s32(vreinterpret32_f32_u32(vmovl_s16(vreinterpret16_f16_u16(vmovl_s8(vreinterpret8_f8_u8(vld1_u8((const uint8_t*)&mat2[k * p + j]))))));\n\n                sum0 = vmlal_s64(sum0, vec1, vec2);\n                sum1 = vmlal_s64(sum1, vec1, vec2);\n            }\n\n            int64x2_t sum = vaddq_s64(sum0, sum1);\n            int64x2_t rounded_sum = vrndnsq_s64(sum);\n\n            vst1q_lane_s64(&dst[i * p + j], rounded_sum, 0);\n            vst1q_lane_s64(&dst[i * p + j + 1], rounded_sum, 1);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_24_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nvoid matrix_mul_round_int_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n, size_t p) {\n    for (size_t i = 0; i < m; ++i) {\n        for (size_t j = 0; j < p; j += 4) {\n            int64x2_t sum0 = vdupq_n_s64(0);\n            int64x2_t sum1 = vdupq_n_s64(0);\n\n            for (size_t k = 0; k < n; k += 2) {\n                double2_t val1 = vld1_f64(&mat1[i * n + k]);\n                double2_t val2 = vld1_f64(&mat2[k * p + j]);\n\n                int64x2_t prod0 = vmulq_s64(vcvtq_s64_f64(val1), vcvtq_s64_f64(vget_low_f64(val2)));\n                int64x2_t prod1 = vmulq_s64(vcvtq_s64_f64(vget_high_f64(val1)), vcvtq_s64_f64(vget_high_f64(val2)));\n\n                sum0 = vaddq_s64(sum0, prod0);\n                sum1 = vaddq_s64(sum1, prod1);\n            }\n\n            int32x2_t sum0_i32 = vmovl_s64(vget_low_s64(sum0));\n            int32x2_t sum1_i32 = vmovl_s64(vget_high_s64(sum0));\n\n            int32x2_t sum0_i32_add = vpadal_s32(sum0_i32, vget_low_s64(sum1));\n            int32x2_t sum1_i32_add = vpadal_s32(sum1_i32, vget_high_s64(sum1));\n\n            int32x2_t sum0_i32_add_add = vpadd_s32(sum0_i32_add, sum1_i32_add);\n\n            int32x2_t sum1_i32_add_add_add = vpadd_s32(sum0_i32_add_add, sum1_i32_add_add);\n\n            int32_t sum = vget_lane_s32(sum1_i32_add_add_add, 0);\n\n            dst[i * p + j] = static_cast<double>(sum);\n            if (j + 1 < p) {\n                dst[i * p + j + 1] = static_cast<double>(vget_lane_s32(sum1_i32_add_add_add, 1));\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_24_Neon", "completion": "```cpp\nvoid matrix_mul_round_int_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n, size_t p) {\n    for (size_t i = 0; i < m; i += 2) {\n        for (size_t j = 0; j < p; j++) {\n            int64x2_t sum = vdupq_n_s64(0);\n            for (size_t k = 0; k < n; k += 2) {\n                int64x2_t val1 = vcvtq_s64_f64(vld1q_f64(mat1 + i * n + k));\n                int64x2_t val2 = vcvtq_s64_f64(vld1q_f64(mat2 + k * p + j));\n                sum = vmlal_s64(sum, val1, val2);\n            }\n            int64x2_t rounded_sum = vrndq_s64(sum);\n            vst1q_s64(reinterpret_cast<int64_t*>(dst + i * p + j), rounded_sum);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_24_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nvoid matrix_mul_round_int_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n, size_t p) {\n    for (size_t i = 0; i < m; ++i) {\n        for (size_t j = 0; j < p; j += 4) {\n            int64x2_t sum0 = vdupq_n_s64(0);\n            int64x2_t sum1 = vdupq_n_s64(0);\n\n            for (size_t k = 0; k < n; k += 2) {\n                int64x2_t vec1 = vmovl_s32(vreinterpret32_f32_u32(vmovl_s16(vreinterpret16_f16_vld1_f32(mat1 + i * n + k))));\n                int64x2_t vec2 = vmovl_s32(vreinterpret32_f32_u32(vmovl_s16(vreinterpret16_f16_vld1_f32(mat2 + k * p + j))));\n                int64x2_t vec3 = vmovl_s32(vreinterpret32_f32_u32(vmovl_s16(vreinterpret16_f16_vld1_f32(mat2 + k * p + j + 2))));\n                int64x2_t vec4 = vmovl_s32(vreinterpret32_f32_u32(vmovl_s16(vreinterpret16_f16_vld1_f32(mat2 + k * p + j + 4))));\n\n                sum0 = vmlal_s64(sum0, vec1, vec2);\n                sum1 = vmlal_s64(sum1, vec3, vec4);\n            }\n\n            int64x2_t sum = vaddq_s64(sum0, sum1);\n            int64x2_t rounded_sum = vrndq_s64(sum);\n            vst1q_f32((float32_t*)(dst + i * p + j), vcvtq_f32_s64(rounded_sum));\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_25_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nvoid matrix_transpose_round_quarter_simd(const float* src, float* dst, size_t rows, size_t cols) {\n    const int quarter = 1 << 2; // 0.25 as an integer\n\n    for (size_t i = 0; i < rows; i += 4) {\n        for (size_t j = 0; j < cols; j++) {\n            float32x4_t row0 = vld1q_f32(src + i * cols + j);\n            float32x4_t row1 = vld1q_f32(src + (i + 1) * cols + j);\n            float32x4_t row2 = vld1q_f32(src + (i + 2) * cols + j);\n            float32x4_t row3 = vld1q_f32(src + (i + 3) * cols + j);\n\n            float32x4_t rounded_row0 = vrndq_f32(vmulq_n_f32(row0, quarter));\n            float32x4_t rounded_row1 = vrndq_f32(vmulq_n_f32(row1, quarter));\n            float32x4_t rounded_row2 = vrndq_f32(vmulq_n_f32(row2, quarter));\n            float32x4_t rounded_row3 = vrndq_f32(vmulq_n_f32(row3, quarter));\n\n            vst1q_f32(dst + j * rows + i, rounded_row0);\n            vst1q_f32(dst + j * rows + i + 1, rounded_row1);\n            vst1q_f32(dst + j * rows + i + 2, rounded_row2);\n            vst1q_f32(dst + j * rows + i + 3, rounded_row3);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_25_Neon", "completion": "```cpp\nvoid matrix_transpose_round_quarter_simd(const float* src, float* dst, size_t rows, size_t cols) {\n    const int vec_size = 16 / sizeof(float); // Number of elements per vector\n\n    for (size_t i = 0; i < rows; i += vec_size) {\n        for (size_t j = 0; j < cols; j++) {\n            float32x4_t v0 = vld1q_f32(src + i * cols + j);\n            float32x4_t v1 = vld1q_f32(src + (i + 1) * cols + j);\n            float32x4_t v2 = vld1q_f32(src + (i + 2) * cols + j);\n            float32x4_t v3 = vld1q_f32(src + (i + 3) * cols + j);\n\n            float32x4_t v0_rounded = vrndnq_f32(v0);\n            float32x4_t v1_rounded = vrndnq_f32(v1);\n            float32x4_t v2_rounded = vrndnq_f32(v2);\n            float32x4_t v3_rounded = vrndnq_f32(v3);\n\n            vst1q_f32(dst + j * rows + i, v0_rounded);\n            vst1q_f32(dst + j * rows + i + 1, v1_rounded);\n            vst1q_f32(dst + j * rows + i + 2, v2_rounded);\n            vst1q_f32(dst + j * rows + i + 3, v3_rounded);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_25_Neon", "completion": "```cpp\nvoid matrix_transpose_round_quarter_simd(const float* src, float* dst, size_t rows, size_t cols) {\n    const int elements_per_vector = 4;\n    const int vectors_per_row = cols / elements_per_vector;\n\n    for (size_t i = 0; i < rows; i += vectors_per_row) {\n        for (size_t j = 0; j < cols; j++) {\n            size_t row_offset = i * cols + j;\n            size_t col_offset = j * rows + i;\n\n            float32x4_t vec = vld1q_f32(src + row_offset);\n\n            // Round to nearest quarter\n            vec = vmulq_f32(vec, vdupq_n_f32(4.0f));\n            vec = vrndq_f32(vec);\n            vec = vmulq_f32(vec, vdupq_n_f32(0.25f));\n\n            vst1q_f32(dst + col_offset, vec);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_25_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nvoid matrix_transpose_round_quarter_simd(const float* src, float* dst, size_t rows, size_t cols) {\n    const int quarter = 1 << 2; // 0.25 as an integer\n\n    for (size_t i = 0; i < rows; i += 4) {\n        for (size_t j = 0; j < cols; j++) {\n            float32x4_t v = vld1q_f32(src + i * cols + j);\n\n            // Round to nearest quarter\n            float32x4_t rounded = vrndnmulq_f32(v, vmovq_n_f32(quarter));\n\n            // Store the result\n            vst1q_f32(dst + j * rows + i, rounded);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_25_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nvoid matrix_transpose_round_quarter_simd(const float* src, float* dst, size_t rows, size_t cols) {\n    const int quarter = 1 << 2; // 0.25 as an integer\n\n    for (size_t i = 0; i < rows; i += 4) {\n        for (size_t j = 0; j < cols; j++) {\n            float32x4_t v = vld1q_f32(src + i * cols + j);\n\n            // Round to nearest quarter\n            float32x4_t rounded = vrndq_f32(v);\n            float32x4_t scaled = vmulq_n_f32(rounded, quarter);\n            float32x4_t quantized = vcvtq_u32_f32(scaled);\n            float32x4_t final = vcvtq_f32_u32(quantized);\n            float32x4_t divided = vdivq_n_f32(final, quarter);\n\n            vst1q_f32(dst + j * rows + i, divided);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_26_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid tensor3d_sub_round_zero_simd(const float* tensor1, const float* tensor2, float* dst, size_t dim1, size_t dim2, size_t dim3) {\n    size_t i;\n    for (i = 0; i <= dim1 * dim2 * dim3 - 4; i += 4) {\n        float32x4_t v1 = vld1q_f32(tensor1 + i);\n        float32x4_t v2 = vld1q_f32(tensor2 + i);\n        float32x4_t vdiff = vsubq_f32(v1, v2);\n        float32x4_t vrnd = vrndq_f32(vdiff);\n        vst1q_f32(dst + i, vrnd);\n    }\n    for (; i < dim1 * dim2 * dim3; ++i) {\n        dst[i] = __builtin_fabsf(tensor1[i] - tensor2[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_26_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nvoid tensor3d_sub_round_zero_simd(const float* tensor1, const float* tensor2, float* dst, size_t dim1, size_t dim2, size_t dim3) {\n    size_t i = 0;\n    for (; i <= dim1 * dim2 * dim3 - 4; i += 4) {\n        float32x4_t v1 = vld1q_f32(tensor1 + i);\n        float32x4_t v2 = vld1q_f32(tensor2 + i);\n        float32x4_t vsub = vsubq_f32(v1, v2);\n        float32x4_t vrnd = vrndq_f32(vsub);\n        vst1q_f32(dst + i, vrnd);\n    }\n    for (; i < dim1 * dim2 * dim3; ++i) {\n        dst[i] = __builtin_fabsf(tensor1[i] - tensor2[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_26_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nvoid tensor3d_sub_round_zero_simd(const float* tensor1, const float* tensor2, float* dst, size_t dim1, size_t dim2, size_t dim3) {\n    size_t i = 0;\n    for (; i <= dim1 * dim2 * dim3 - 4; i += 4) {\n        float32x4_t v1 = vld1q_f32(tensor1 + i);\n        float32x4_t v2 = vld1q_f32(tensor2 + i);\n        float32x4_t vdiff = vsubq_f32(v1, v2);\n        float32x4_t vrnd = vrndq_f32(vdiff);\n        vst1q_f32(dst + i, vrnd);\n    }\n    for (; i < dim1 * dim2 * dim3; ++i) {\n        dst[i] = __builtin_fabsf(tensor1[i] - tensor2[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_26_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nvoid tensor3d_sub_round_zero_simd(const float* tensor1, const float* tensor2, float* dst, size_t dim1, size_t dim2, size_t dim3) {\n    size_t i = 0;\n    for (; i <= dim1 * dim2 * dim3 - 4; i += 4) {\n        float32x4_t v1 = vld1q_f32(tensor1 + i);\n        float32x4_t v2 = vld1q_f32(tensor2 + i);\n        float32x4_t vsub = vsubq_f32(v1, v2);\n        float32x4_t vrnd = vrndq_f32(vsub);\n        vst1q_f32(dst + i, vrnd);\n    }\n    for (; i < dim1 * dim2 * dim3; ++i) {\n        dst[i] = __builtin_fabsf(tensor1[i] - tensor2[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_26_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nvoid tensor3d_sub_round_zero_simd(const float* tensor1, const float* tensor2, float* dst, size_t dim1, size_t dim2, size_t dim3) {\n    size_t i = 0;\n    for (; i <= dim1 * dim2 * dim3 - 4; i += 4) {\n        float32x4_t v1 = vld1q_f32(tensor1 + i);\n        float32x4_t v2 = vld1q_f32(tensor2 + i);\n        float32x4_t vsub = vsubq_f32(v1, v2);\n        float32x4_t vrnd = vrndq_f32(vsub);\n        vst1q_f32(dst + i, vrnd);\n    }\n    for (; i < dim1 * dim2 * dim3; ++i) {\n        dst[i] = __builtin_fabsf(tensor1[i] - tensor2[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_27_Neon", "completion": "```cpp\nvoid matrix_hadamard_product_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n) {\n    for (size_t i = 0; i < m; ++i) {\n        for (size_t j = 0; j < n; j += 4) {\n            vst1q_f64(dst + i * n + j, vmulq_f64(vld1q_f64(mat1 + i * n + j), vld1q_f64(mat2 + i * n + j)));\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_27_Neon", "completion": "```cpp\nvoid matrix_hadamard_product_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n) {\n    for (size_t i = 0; i < m; ++i) {\n        for (size_t j = 0; j < n; j += 4) {\n            vst1q_f64(dst + i * n + j, vmulq_f64(vld1q_f64(mat1 + i * n + j), vld1q_f64(mat2 + i * n + j)));\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_27_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nvoid matrix_hadamard_product_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n) {\n    size_t i = 0;\n    for (; i <= m - 4; i += 4) {\n        vst1q_f64(dst + i * n, vmulq_f64(vld1q_f64(mat1 + i * n), vld1q_f64(mat2 + i * n)));\n    }\n    for (; i < m; ++i) {\n        for (size_t j = 0; j < n; ++j) {\n            dst[i * n + j] = mat1[i * n + j] * mat2[i * n + j];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_27_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nvoid matrix_hadamard_product_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n) {\n    size_t i = 0;\n    for (; i <= m - 4; i += 4) {\n        vst1q_f64(dst + i * n, vmulq_f64(vld1q_f64(mat1 + i * n), vld1q_f64(mat2 + i * n)));\n    }\n    for (; i < m; ++i) {\n        for (size_t j = 0; j < n; ++j) {\n            dst[i * n + j] = mat1[i * n + j] * mat2[i * n + j];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_27_Neon", "completion": "```cpp\nvoid matrix_hadamard_product_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n) {\n    size_t i = 0;\n    for (; i <= m - 4; i += 4) {\n        vst1q_f64(dst + i * n, vmulq_f64(vld1q_f64(mat1 + i * n), vld1q_f64(mat2 + i * n)));\n    }\n    for (; i < m; ++i) {\n        for (size_t j = 0; j < n; ++j) {\n            dst[i * n + j] = mat1[i * n + j] * mat2[i * n + j];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_28_Neon", "completion": "```cpp\nvoid matrix_vector_mul_simd(const float* mat, const float* vec, float* dst, size_t m, size_t n) {\n    for (size_t i = 0; i < m; ++i) {\n        float32x4_t row = vld1q_f32(mat + i * n);\n        float32x4_t col = vld1q_f32(vec);\n        float32x4_t prod = vmulq_f32(row, col);\n        float32x4_t sum = vpaddq_f32(prod, prod);\n        float32x2_t sum_low = vget_low_f32(sum);\n        float32x2_t sum_high = vget_high_f32(sum);\n        float64x1_t sum_double = vadd_f64(vreinterpret_u64_f32(sum_low),vreinterpret_u64_f32(sum_high));\n        float result = vget_lane_f64(sum_double, 0);\n        dst[i] = result;\n    }\n}\n```"}
{"task_id": "SimdBench_28_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nvoid matrix_vector_mul_simd(const float* mat, const float* vec, float* dst, size_t m, size_t n) {\n    for (size_t i = 0; i < m; ++i) {\n        float32x4_t row_vec = vld1q_f32(vec);\n        float32x4_t sum = vdupq_n_f32(0.0f);\n\n        for (size_t j = 0; j + 3 < n; j += 4) {\n            float32x4_t col_vec = vld1q_f32(mat + i * n + j);\n            sum = vfmaq_f32(sum, row_vec, col_vec);\n        }\n\n        // Handle remaining elements\n        for (; j < n; ++j) {\n            sum[0] += row_vec[0] * mat[i * n + j];\n        }\n\n        vst1q_f32(dst + i, sum);\n    }\n}\n```"}
{"task_id": "SimdBench_28_Neon", "completion": "```cpp\nvoid matrix_vector_mul_simd(const float* mat, const float* vec, float* dst, size_t m, size_t n) {\n    for (size_t i = 0; i < m; ++i) {\n        float32x4_t row = vld1q_f32(mat + i * n);\n        float32x4_t col = vld1q_f32(vec);\n        float32x4_t prod = vmulq_f32(row, col);\n        float sum = vaddvq_f32(prod);\n        dst[i] = sum;\n    }\n}\n```"}
{"task_id": "SimdBench_28_Neon", "completion": "```cpp\nvoid matrix_vector_mul_simd(const float* mat, const float* vec, float* dst, size_t m, size_t n) {\n    for (size_t i = 0; i < m; ++i) {\n        float32x4_t row = vld1q_f32(mat + i * n);\n        float32x4_t col = vld1q_f32(vec);\n        float32x4_t prod = vmulq_f32(row, col);\n        float32x4_t sum = vpaddq_f32(prod, prod);\n        float32x2_t sum_low = vget_low_f32(sum);\n        float32x2_t sum_high = vget_high_f32(sum);\n        float32x2_t sum_all = vadd_f32(sum_low, sum_high);\n        dst[i] = vget_lane_f32(sum_all, 0);\n    }\n}\n```"}
{"task_id": "SimdBench_28_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nvoid matrix_vector_mul_simd(const float* mat, const float* vec, float* dst, size_t m, size_t n) {\n    for (size_t i = 0; i < m; ++i) {\n        float32x4_t sum = vdupq_n_f32(0.0f);\n        for (size_t j = 0; j < n; j += 4) {\n            float32x4_t row = vld1q_f32(mat + i * n + j);\n            float32x4_t col = vld1q_f32(vec + j);\n            sum = vfmaq_f32(sum, row, col);\n        }\n        vst1q_f32(dst + i, sum);\n    }\n}\n```"}
{"task_id": "SimdBench_29_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <cmath>\n\ndouble matrix_average_simd(const double* mat, size_t m, size_t n) {\n    const size_t simd_width = 8; // Number of doubles that can fit in one NEON register\n    double sum = 0.0;\n    size_t total_elements = m * n;\n\n    // Process elements in chunks of simd_width\n    for (size_t i = 0; i < total_elements / simd_width; ++i) {\n        double32x2_t vsum1 = vdupq_n_f32(0.0f);\n        double32x2_t vsum2 = vdupq_n_f32(0.0f);\n\n        for (int j = 0; j < simd_width / 2; ++j) {\n            double64x2_t vec = vld1q_f64(&mat[i * simd_width + j * 2]);\n            double32x2_t vec_low = vmovl_u64(vget_low_u64(vec));\n            double32x2_t vec_high = vmovl_u64(vget_high_u64(vec));\n\n            vsum1 = vadd_f32(vsum1, vec_low);\n            vsum2 = vadd_f32(vsum2, vec_high);\n        }\n\n        float32x2_t sum_vec = vadd_f32(vget_low_f32(vsum1), vget_high_f32(vsum1));\n        sum_vec = vadd_f32(sum_vec, vget_low_f32(vsum2));\n        sum += vget_lane_f32(sum_vec, 0) + vget_lane_f32(sum_vec, 1);\n    }\n\n    // Handle remaining elements\n    for (size_t i = total_elements - total_elements % simd_width; i < total_elements; ++i) {\n        sum += mat[i];\n    }\n\n    return sum / total_elements;\n}\n```"}
{"task_id": "SimdBench_29_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <cmath>\n\ndouble matrix_average_simd(const double* mat, size_t m, size_t n) {\n    const size_t simd_width = 8; // Number of doubles per NEON register\n    double sum = 0.0;\n    size_t total_elements = m * n;\n\n    // Process elements in chunks of simd_width\n    for (size_t i = 0; i < total_elements / simd_width; ++i) {\n        double32x2_t vsum = vdupq_n_f32(0.0f);\n        for (int j = 0; j < simd_width; ++j) {\n            double32x2_t vec = vld1q_f32((const float32_t*)&mat[i * simd_width + j]);\n            vsum = vfmaq_f32(vsum, vec, vec);\n        }\n        float32_t s = vaddvq_f32(vsum);\n        sum += s;\n    }\n\n    // Handle remaining elements\n    for (size_t i = total_elements - total_elements % simd_width; i < total_elements; ++i) {\n        sum += mat[i];\n    }\n\n    return sum / total_elements;\n}\n```"}
{"task_id": "SimdBench_29_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <cmath>\n\ndouble matrix_average_simd(const double* mat, size_t m, size_t n) {\n    const size_t simd_width = 8; // Number of doubles that can fit in one NEON register\n    double sum = 0.0;\n    size_t total_elements = m * n;\n\n    // Process elements in chunks of simd_width\n    for (size_t i = 0; i < total_elements; i += simd_width) {\n        int64x2_t vsum = vdupq_n_s64(0); // Initialize sum vector to zero\n\n        // Load simd_width elements into a NEON register\n        for (int j = 0; j < simd_width; ++j) {\n            if (i + j < total_elements) {\n                int64x2_t vec = vld1q_f64(&mat[i + j]);\n                vsum = vaddq_s64(vsum, vcvtq_s64_f64(vec));\n            }\n        }\n\n        // Sum up the elements in the vector\n        int64_t sum_vec[2];\n        vst1q_s64(sum_vec, vsum);\n        sum += static_cast<double>(sum_vec[0]) + static_cast<double>(sum_vec[1]);\n    }\n\n    // Handle remaining elements that don't fit into a full chunk\n    for (size_t i = total_elements - total_elements % simd_width; i < total_elements; ++i) {\n        sum += mat[i];\n    }\n\n    return sum / total_elements;\n}\n```"}
{"task_id": "SimdBench_29_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <cmath>\n\ndouble matrix_average_simd(const double* mat, size_t m, size_t n) {\n    const size_t simd_width = 8;\n    double sum = 0.0;\n    size_t i = 0;\n\n    // Process elements in chunks of 8 using Neon intrinsics\n    for (; i <= m * n - simd_width; i += simd_width) {\n        double32x2_t vsum1 = vdupq_n_f32(0.0f);\n        double32x2_t vsum2 = vdupq_n_f32(0.0f);\n\n        for (size_t j = 0; j < n; ++j) {\n            double64x2_t vec = vld1q_f64(&mat[i + j * m]);\n            double32x2_t low = vmovl_u64(vget_low_u64(vec));\n            double32x2_t high = vmovl_u64(vget_high_u64(vec));\n            vsum1 = vaddq_f32(vsum1, low);\n            vsum2 = vaddq_f32(vsum2, high);\n        }\n\n        float32x2_t sum_vec = vadd_f32(vget_low_f32(vsum1), vget_high_f32(vsum1));\n        sum_vec = vadd_f32(sum_vec, vget_low_f32(vsum2));\n        sum_vec = vadd_f32(sum_vec, vget_high_f32(vsum2));\n\n        sum += vget_lane_f32(sum_vec, 0) + vget_lane_f32(sum_vec, 1);\n    }\n\n    // Process remaining elements\n    for (; i < m * n; ++i) {\n        sum += mat[i];\n    }\n\n    return sum / (m * n);\n}\n```"}
{"task_id": "SimdBench_29_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <cmath>\n\ndouble matrix_average_simd(const double* mat, size_t m, size_t n) {\n    const size_t simd_width = 8; // Number of doubles per NEON register\n    double sum = 0.0;\n    size_t total_elements = m * n;\n\n    // Process elements in chunks of simd_width\n    for (size_t i = 0; i < total_elements / simd_width; ++i) {\n        double32x2_t vsum = vdupq_n_f32(0.0f);\n        for (size_t j = 0; j < simd_width; ++j) {\n            double32x2_t vec = vld1q_f32((const float32_t*)&mat[i * simd_width + j]);\n            vsum = vfmaq_f32(vsum, vec, vec);\n        }\n        float32_t sum_chunk = vaddvq_f32(vsum);\n        sum += static_cast<double>(sum_chunk);\n    }\n\n    // Handle remaining elements\n    for (size_t i = total_elements - total_elements % simd_width; i < total_elements; ++i) {\n        sum += mat[i];\n    }\n\n    return sum / total_elements;\n}\n```"}
{"task_id": "SimdBench_30_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <stdbool.h>\n#include <stddef.h>\n\nbool matrix_rows_sorted_verify_simd(const int* matrix, const bool* directions, size_t rows, size_t cols) {\n    for (size_t i = 0; i < rows; ++i) {\n        const int* row_start = matrix + i * cols;\n        const bool direction = directions[i];\n        int32x4_t prev = vld1q_s32(row_start);\n\n        for (size_t j = 1; j <= cols - 4; j += 4) {\n            int32x4_t curr = vld1q_s32(row_start + j);\n            if (direction) {\n                if (vmaxq_s32(prev, curr) != curr) return false;\n            } else {\n                if (vminq_s32(prev, curr) != curr) return false;\n            }\n            prev = curr;\n        }\n\n        // Handle remaining elements that are not multiples of 4\n        for (; j < cols; ++j) {\n            int current = row_start[j];\n            if (direction) {\n                if (current < prev) return false;\n            } else {\n                if (current > prev) return false;\n            }\n            prev = current;\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_30_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <stdbool.h>\n#include <stddef.h>\n\nbool matrix_rows_sorted_verify_simd(const int* matrix, const bool* directions, size_t rows, size_t cols) {\n    for (size_t i = 0; i < rows; ++i) {\n        const int* row_start = matrix + i * cols;\n        const bool direction = directions[i];\n        uint32x4_t prev = vld1q_u32(row_start);\n\n        for (size_t j = 1; j < cols; j += 4) {\n            uint32x4_t curr = vld1q_u32(row_start + j);\n            uint32x4_t mask = vdupq_n_u32(direction ? -1 : 1);\n            uint32x4_t cmp = vsubq_u32(prev, curr);\n            uint32x4_t cond = vandq_u32(cmp, mask);\n            uint32x4_t zero = vdupq_n_u32(0);\n            if (!vceqq_u32(cond, zero)) {\n                return false;\n            }\n            prev = curr;\n        }\n\n        // Handle remaining elements that are not multiples of 4\n        for (size_t j = cols & ~3; j < cols; ++j) {\n            int prev_val = row_start[j - 1];\n            int curr_val = row_start[j];\n            if ((direction && prev_val > curr_val) || (!direction && prev_val < curr_val)) {\n                return false;\n            }\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_30_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <stdbool.h>\n#include <stddef.h>\n\nbool matrix_rows_sorted_verify_simd(const int* matrix, const bool* directions, size_t rows, size_t cols) {\n    for (size_t i = 0; i < rows; ++i) {\n        const int* row_start = matrix + i * cols;\n        const bool direction = directions[i];\n        int32x4_t prev = vld1q_s32(row_start);\n\n        for (size_t j = 1; j <= cols - 4; j += 4) {\n            int32x4_t curr = vld1q_s32(row_start + j);\n            if (direction) {\n                if (vmaxq_s32(prev, curr) != curr) return false;\n            } else {\n                if (vminq_s32(prev, curr) != curr) return false;\n            }\n            prev = curr;\n        }\n\n        // Handle remaining elements that are less than 4\n        for (size_t j = cols - cols % 4; j < cols; ++j) {\n            int curr = *(row_start + j);\n            if (direction) {\n                if (prev > curr) return false;\n            } else {\n                if (prev < curr) return false;\n            }\n            prev = curr;\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_30_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <stdbool.h>\n#include <stddef.h>\n\nbool matrix_rows_sorted_verify_simd(const int* matrix, const bool* directions, size_t rows, size_t cols) {\n    for (size_t i = 0; i < rows; ++i) {\n        const int* row = matrix + i * cols;\n        const bool direction = directions[i];\n        uint32x4_t prev = vld1q_u32(row);\n        row += 4;\n\n        for (size_t j = 4; j < cols; j += 4) {\n            uint32x4_t curr = vld1q_u32(row);\n            if (direction) {\n                uint32x4_t cmp = vcgtq_u32(prev, curr);\n                if (vmaxvq_u32(cmp)) return false;\n            } else {\n                uint32x4_t cmp = vcltq_u32(prev, curr);\n                if (vmaxvq_u32(cmp)) return false;\n            }\n            prev = curr;\n            row += 4;\n        }\n\n        // Handle remaining elements that are not multiples of 4\n        for (size_t j = cols - cols % 4; j < cols; ++j) {\n            int prev_val = prev[0];\n            int curr_val = row[j];\n            if (direction && prev_val > curr_val) return false;\n            if (!direction && prev_val < curr_val) return false;\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_30_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <stdbool.h>\n#include <stddef.h>\n\nbool matrix_rows_sorted_verify_simd(const int* matrix, const bool* directions, size_t rows, size_t cols) {\n    for (size_t i = 0; i < rows; ++i) {\n        const int* row_start = matrix + i * cols;\n        const bool direction = directions[i];\n        int32x4_t prev = vld1q_s32(row_start);\n\n        for (size_t j = 1; j <= cols - 4; j += 4) {\n            int32x4_t curr = vld1q_s32(row_start + j);\n            if (direction) {\n                if (vmaxq_s32(prev, curr) != curr) return false;\n            } else {\n                if (vminq_s32(prev, curr) != curr) return false;\n            }\n            prev = curr;\n        }\n\n        // Handle remaining elements that are not multiples of 4\n        for (size_t j = cols - cols % 4; j < cols; ++j) {\n            int current = row_start[j];\n            if (direction) {\n                if (current < prev) return false;\n            } else {\n                if (current > prev) return false;\n            }\n            prev = current;\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_31_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid nearest_multiple_simd(const int16_t* src, int16_t* dst, uint8_t base, size_t length) {\n    const int16x8_t v_base = vmovq_n_s16(base);\n    const int16x8_t v_half_base = vmovq_n_s16(base / 2);\n\n    for (size_t i = 0; i < length; i += 8) {\n        int16x8_t v_src = vld1q_s16(src + i);\n        int16x8_t v_quotient = vdivq_s16(v_src, v_base);\n        int16x8_t v_floor = vmulq_s16(v_quotient, v_base);\n        int16x8_t v_ceil = vaddq_s16(v_floor, v_base);\n        int16x8_t v_diff_floor = vsubq_s16(v_src, v_floor);\n        int16x8_t v_diff_ceil = vsubq_s16(v_ceil, v_src);\n        int16x8_t v_mask = vcgtq_s16(v_diff_floor, v_diff_ceil);\n        int16x8_t v_result = vbslq_s16(v_mask, v_ceil, v_floor);\n        vst1q_s16(dst + i, v_result);\n    }\n}\n```"}
{"task_id": "SimdBench_31_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid nearest_multiple_simd(const int16_t* src, int16_t* dst, uint8_t base, size_t length) {\n    const int16x8_t v_base = vdupq_n_s16(base);\n    const int16x8_t v_half_base = vmulq_n_s16(v_base, 0x0001);\n\n    for (size_t i = 0; i < length; i += 8) {\n        int16x8_t v_src = vld1q_s16(src + i);\n        int16x8_t v_quotient = vdivq_s16(v_src, v_base);\n        int16x8_t v_floor = vsubq_s16(v_quotient, vclzq_s16(v_cmpgtq_s16(v_src, vmulq_s16(v_quotient, v_base))));\n        int16x8_t v_result = vmulq_s16(v_floor, v_base);\n\n        vst1q_s16(dst + i, v_result);\n    }\n}\n```"}
{"task_id": "SimdBench_31_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid nearest_multiple_simd(const int16_t* src, int16_t* dst, uint8_t base, size_t length) {\n    const int16x8_t v_base = vdupq_n_s16(base);\n    const int16x8_t v_half_base = vmulq_n_s16(v_base, 0x0001);\n\n    for (size_t i = 0; i < length; i += 8) {\n        int16x8_t v_src = vld1q_s16(src + i);\n        int16x8_t v_quotient = vdivq_s16(v_src, v_base);\n        int16x8_t v_floor = vmulq_s16(v_quotient, v_base);\n        int16x8_t v_ceil = vaddq_s16(v_floor, v_half_base);\n        int16x8_t v_diff_floor = vsubq_s16(v_src, v_floor);\n        int16x8_t v_diff_ceil = vsubq_s16(v_ceil, v_src);\n        int16x8_t v_mask = vcltq_s16(v_diff_floor, v_diff_ceil);\n        int16x8_t v_result = vbslq_s16(v_mask, v_floor, v_ceil);\n        vst1q_s16(dst + i, v_result);\n    }\n}\n```"}
{"task_id": "SimdBench_31_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid nearest_multiple_simd(const int16_t* src, int16_t* dst, uint8_t base, size_t length) {\n    const int16x8_t v_base = vdupq_n_s16(base);\n    const int16x8_t v_half_base = vmulq_n_s16(v_base, 0x0001);\n\n    for (size_t i = 0; i < length; i += 8) {\n        int16x8_t v_src = vld1q_s16(src + i);\n        int16x8_t v_quotient = vdivq_s16(v_src, v_base);\n        int16x8_t v_floor = vsubq_s16(v_quotient, vclzq_s16(v_cmpgtq_s16(v_src, vmulq_s16(v_quotient, v_base))));\n        int16x8_t v_result = vmulq_s16(v_floor, v_base);\n\n        vst1q_s16(dst + i, v_result);\n    }\n}\n```"}
{"task_id": "SimdBench_31_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nvoid nearest_multiple_simd(const int16_t* src, int16_t* dst, uint8_t base, size_t length) {\n    const int16x8_t v_base = vmovq_n_s16(base);\n\n    for (size_t i = 0; i <= length - 8; i += 8) {\n        int16x8_t v_src = vld1q_s16(src + i);\n        int16x8_t v_div = vdivq_s16(v_src, v_base);\n        int16x8_t v_floor = vrndmq_s16(v_div);\n        int16x8_t v_mul = vmulq_s16(v_floor, v_base);\n        int16x8_t v_sub = vsubq_s16(v_src, v_mul);\n        int16x8_t v_abs = vabsq_s16(v_sub);\n        int16x8_t v_next = vaddq_s16(v_mul, v_base);\n        int16x8_t v_next_abs = vabsq_s16(vsubq_s16(v_src, v_next));\n        int16x8_t v_mask = vcgtq_s16(v_abs, v_next_abs);\n        int16x8_t v_result = vbslq_s16(v_mask, v_next, v_mul);\n        vst1q_s16(dst + i, v_result);\n    }\n\n    // Handle remaining elements\n    for (size_t i = length - length % 8; i < length; ++i) {\n        int16_t val = src[i];\n        int16_t div = val / base;\n        int16_t floor = div;\n        int16_t mul = floor * base;\n        int16_t sub = val - mul;\n        int16_t abs = sub >= 0 ? sub : -sub;\n        int16_t next = mul + base;\n        int16_t next_abs = next - val;\n        if (next_abs < abs) {\n            dst[i] = next;\n        } else {\n            dst[i] = mul;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_32_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <stdbool.h>\n#include <stddef.h>\n\nbool matrix_has_row_simd(const double* matrix, const double* vector, size_t rows, size_t cols) {\n    for (size_t i = 0; i < rows; ++i) {\n        bool match = true;\n        for (size_t j = 0; j < cols; j += 2) {\n            __m128d vec1 = _mm_loadu_pd(&matrix[i * cols + j]);\n            __m128d vec2 = _mm_set1_pd(vector[j / 2]);\n            __m128d cmp = _mm_cmpneq_pd(vec1, vec2);\n            uint32x2_t mask = vreinterpret_u32_m128d(cmp);\n            if (vget_lane_u32(mask, 0) || vget_lane_u32(mask, 1)) {\n                match = false;\n                break;\n            }\n        }\n        if (match) {\n            return true;\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_32_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <stdbool.h>\n#include <stddef.h>\n\nbool matrix_has_row_simd(const double* matrix, const double* vector, size_t rows, size_t cols) {\n    for (size_t i = 0; i < rows; ++i) {\n        bool match = true;\n        for (size_t j = 0; j < cols; j += 2) {\n            __m128d vec1 = _mm_loadu_pd(&matrix[i * cols + j]);\n            __m128d vec2 = _mm_set1_pd(vector[j / 2]);\n            __m128d cmp = _mm_cmpneq_pd(vec1, vec2);\n            uint32x2_t mask = vreinterpret_u32_m128d(cmp);\n            if (vget_lane_u32(mask, 0) || vget_lane_u32(mask, 1)) {\n                match = false;\n                break;\n            }\n        }\n        if (match) {\n            return true;\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_32_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <stdbool.h>\n#include <stddef.h>\n\nbool matrix_has_row_simd(const double* matrix, const double* vector, size_t rows, size_t cols) {\n    for (size_t i = 0; i < rows; ++i) {\n        bool match = true;\n        for (size_t j = 0; j < cols; j += 2) {\n            __m128d vec1 = _mm_loadu_pd(&matrix[i * cols + j]);\n            __m128d vec2 = _mm_set1_pd(vector[j / 2]);\n            __m128d cmp = _mm_cmpneq_pd(vec1, vec2);\n            uint32x2_t mask = vreinterpret_u32_m128d(cmp);\n            if (vget_lane_u32(mask, 0) || vget_lane_u32(mask, 1)) {\n                match = false;\n                break;\n            }\n        }\n        if (match) {\n            return true;\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_32_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <stdbool.h>\n#include <stddef.h>\n\nbool matrix_has_row_simd(const double* matrix, const double* vector, size_t rows, size_t cols) {\n    for (size_t i = 0; i < rows; ++i) {\n        bool match = true;\n        for (size_t j = 0; j < cols; j += 2) {\n            __m128d vec1 = _mm_loadu_pd(&matrix[i * cols + j]);\n            __m128d vec2 = _mm_set1_pd(vector[j / 2]);\n            __m128d cmp = _mm_cmpneq_pd(vec1, vec2);\n            uint32x2_t mask = vreinterpret_u32_m128d(cmp);\n            if (vget_lane_u32(mask, 0) || vget_lane_u32(mask, 1)) {\n                match = false;\n                break;\n            }\n        }\n        if (match) {\n            return true;\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_32_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <stdbool.h>\n#include <stddef.h>\n\nbool matrix_has_row_simd(const double* matrix, const double* vector, size_t rows, size_t cols) {\n    for (size_t i = 0; i < rows; ++i) {\n        bool match = true;\n        for (size_t j = 0; j < cols; j += 2) {\n            __m128d vec1 = _mm_loadu_pd(&matrix[i * cols + j]);\n            __m128d vec2 = _mm_set1_pd(vector[j / 2]);\n            __m128d cmp = _mm_cmpeq_pd(vec1, vec2);\n            uint32x2_t mask = vreinterpret_u32_m128d(cmp);\n            if ((mask[0] & 0x3) != 0x3 || (mask[1] & 0x3) != 0x3) {\n                match = false;\n                break;\n            }\n        }\n        if (match) {\n            return true;\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_33_Neon", "completion": "```cpp\nsize_t tensor_4d_equal_count_simd(const uint8_t* A, const uint8_t* B, const size_t dims[4]) {\n    size_t count = 0;\n    size_t total_elements = dims[0] * dims[1] * dims[2] * dims[3];\n    size_t i;\n\n    for (i = 0; i <= total_elements - 16; i += 16) {\n        uint8x16_t va = vld1q_u8(A + i);\n        uint8x16_t vb = vld1q_u8(B + i);\n        uint16x8_t eq = vceqq_u8(va, vb);\n        uint16x8_t sum = vpaddlq_u8(eq);\n        uint32x4_t sum_all = vpaddlq_u16(sum);\n        count += vget_lane_u32(sum_all, 0) + vget_lane_u32(sum_all, 1);\n    }\n\n    for (; i < total_elements; ++i) {\n        if (A[i] == B[i]) {\n            ++count;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_33_Neon", "completion": "```cpp\nsize_t tensor_4d_equal_count_simd(const uint8_t* A, const uint8_t* B, const size_t dims[4]) {\n    size_t count = 0;\n    size_t total_elements = dims[0] * dims[1] * dims[2] * dims[3];\n    size_t i;\n\n    for (i = 0; i <= total_elements - 16; i += 16) {\n        uint8x16_t va = vld1q_u8(A + i);\n        uint8x16_t vb = vld1q_u8(B + i);\n        uint16x8_t eq = vceqq_u8(va, vb);\n        uint16x8_t sum = vpaddlq_u8(eq);\n        uint32x4_t sum_all = vpaddlq_u16(sum);\n        count += vget_lane_u32(sum_all, 0) + vget_lane_u32(sum_all, 1);\n    }\n\n    for (; i < total_elements; ++i) {\n        if (A[i] == B[i]) {\n            ++count;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_33_Neon", "completion": "```cpp\nsize_t tensor_4d_equal_count_simd(const uint8_t* A, const uint8_t* B, const size_t dims[4]) {\n    size_t count = 0;\n    size_t total_elements = dims[0] * dims[1] * dims[2] * dims[3];\n    size_t i;\n\n    for (i = 0; i <= total_elements - 16; i += 16) {\n        uint8x16_t va = vld1q_u8(A + i);\n        uint8x16_t vb = vld1q_u8(B + i);\n        uint16x8_t eq = vceqq_u8(va, vb);\n        uint16x8_t sum = vpaddlq_u8(eq);\n        uint32x4_t sum_all = vpaddlq_u16(sum);\n        count += vget_lane_u32(sum_all, 0) + vget_lane_u32(sum_all, 1);\n    }\n\n    for (; i < total_elements; ++i) {\n        if (A[i] == B[i]) {\n            ++count;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_33_Neon", "completion": "```cpp\nsize_t tensor_4d_equal_count_simd(const uint8_t* A, const uint8_t* B, const size_t dims[4]) {\n    size_t count = 0;\n    size_t total_elements = dims[0] * dims[1] * dims[2] * dims[3];\n    size_t i;\n\n    for (i = 0; i <= total_elements - 16; i += 16) {\n        uint8x16_t va = vld1q_u8(A + i);\n        uint8x16_t vb = vld1q_u8(B + i);\n        uint16x8_t eq = vceqq_u8(va, vb);\n        uint16x8_t sum = vpaddlq_u8(eq);\n        uint32x4_t sum_all = vpaddlq_u16(sum);\n        count += vget_lane_u32(sum_all, 0) + vget_lane_u32(sum_all, 1);\n    }\n\n    // Handle remaining elements\n    for (; i < total_elements; ++i) {\n        if (A[i] == B[i]) {\n            ++count;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_33_Neon", "completion": "```cpp\nsize_t tensor_4d_equal_count_simd(const uint8_t* A, const uint8_t* B, const size_t dims[4]) {\n    size_t count = 0;\n    size_t total_elements = dims[0] * dims[1] * dims[2] * dims[3];\n    size_t i;\n\n    for (i = 0; i <= total_elements - 16; i += 16) {\n        uint8x16_t va = vld1q_u8(A + i);\n        uint8x16_t vb = vld1q_u8(B + i);\n        uint16x8_t eq = vceqq_u8(va, vb);\n        uint16x8_t sum = vpaddlq_u8(eq);\n        uint32x4_t sum_all = vpaddlq_u16(sum);\n        count += vget_lane_u32(sum_all, 0) + vget_lane_u32(sum_all, 1);\n    }\n\n    for (; i < total_elements; ++i) {\n        if (A[i] == B[i]) {\n            ++count;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_34_Neon", "completion": "```cpp\nvoid axm_abs_simd(size_t length, const int64_t a, const int64_t *x, int64_t *y) {\n    size_t i = 0;\n    for (; i <= length - 4; i += 4) {\n        int64x2_t va = vdupq_n_s64(a);\n        int64x2_t vb = vld1q_s64(&x[i]);\n        int64x2_t vc = vmulq_s64(va, vb);\n\n        int64x2_t vd = vabsq_s64(vc);\n        int64x2_t ve = vsubq_s64(vd, vb);\n\n        vst1q_s64(&y[i], ve);\n    }\n\n    for (; i < length; ++i) {\n        y[i] = std::abs(x[i] * a - x[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_34_Neon", "completion": "```cpp\nvoid axm_abs_simd(size_t length, const int64_t a, const int64_t *x, int64_t *y) {\n    size_t i = 0;\n    for (; i <= length - 4; i += 4) {\n        int64x2_t va = vdupq_n_s64(a);\n        int64x2_t vb = vld1q_s64(&x[i]);\n        int64x2_t vc = vmulq_s64(va, vb);\n\n        int64x2_t vd = vabsq_s64(vc);\n        int64x2_t ve = vsubq_s64(vd, vb);\n\n        vst1q_s64(&y[i], ve);\n    }\n\n    for (; i < length; ++i) {\n        y[i] = std::abs(x[i] * a - x[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_34_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid axm_abs_simd(size_t length, const int64_t a, const int64_t *x, int64_t *y) {\n    size_t i = 0;\n    for (; i <= length - 2; i += 2) {\n        int64x2_t va = vdupq_n_s64(a);\n        int64x2_t vx = vld1q_s64(&x[i]);\n        int64x2_t vy = vmulq_s64(va, vx);\n\n        vy = vabsq_s64(vy);\n        vst1q_s64(&y[i], vy);\n    }\n\n    if (i < length) {\n        int64x2_t va = vdupq_n_s64(a);\n        int64x2_t vx = vld1q_lane_s64(&x[i], vdupq_n_s64(0), 0);\n        int64x2_t vy = vmulq_lane_s64(va, vx, 0);\n\n        vy = vabsq_lane_s64(vy, 0);\n        vst1q_lane_s64(&y[i], vy, 0);\n    }\n}\n```"}
{"task_id": "SimdBench_34_Neon", "completion": "```cpp\nvoid axm_abs_simd(size_t length, const int64_t a, const int64_t *x, int64_t *y) {\n    size_t i = 0;\n    for (; i <= length - 4; i += 4) {\n        int64x2_t va = vdupq_n_s64(a);\n        int64x2_t vb = vld1q_s64(&x[i]);\n        int64x2_t vc = vmulq_s64(va, vb);\n\n        int64x2_t vd = vabsq_s64(vc);\n        int64x2_t ve = vsubq_s64(vd, vb);\n\n        vst1q_s64(&y[i], ve);\n    }\n\n    for (; i < length; ++i) {\n        y[i] = std::abs(x[i] * a - x[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_34_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid axm_abs_simd(size_t length, const int64_t a, const int64_t *x, int64_t *y) {\n    size_t i = 0;\n    for (; i <= length - 2; i += 2) {\n        int64x2_t va = vdupq_n_s64(a);\n        int64x2_t vx = vld1q_s64(&x[i]);\n        int64x2_t vy = vmulq_s64(va, vx);\n        vy = vabsq_s64(vy);\n        int64x2_t vz = vsubq_s64(vx, vy);\n        vst1q_s64(&y[i], vz);\n    }\n    if (i < length) {\n        int64x2_t va = vdupq_n_s64(a);\n        int64x2_t vx = vld1q_lane_s64(&x[i], vdupq_n_s64(0), 0);\n        int64x2_t vy = vmulq_s64(va, vx);\n        vy = vabsq_s64(vy);\n        int64x2_t vz = vsubq_s64(vx, vy);\n        vst1q_lane_s64(&y[i], vz, 0);\n    }\n}\n```"}
{"task_id": "SimdBench_35_Neon", "completion": "```cpp\nMinMaxPair min_max_pair_simd(const int16_t* vec, size_t length) {\n    MinMaxPair result = {INT16_MAX, INT16_MIN};\n\n    if (length % 8 == 0) {\n        for (size_t i = 0; i < length; i += 8) {\n            int16x8_t v = vld1q_s16(&vec[i]);\n            int16x4_t lo = vmin_s16(vget_low_s16(v), vget_high_s16(v));\n            int16x4_t hi = vmax_s16(vget_low_s16(v), vget_high_s16(v));\n            int16x4_t min_val = vmin_s16(lo, hi);\n            int16x4_t max_val = vmax_s16(lo, hi);\n\n            result.min_num = vmin_s16(result.min_num, vget_lane_s16(min_val, 0));\n            result.max_num = vmax_s16(result.max_num, vget_lane_s16(max_val, 3));\n        }\n    } else {\n        for (size_t i = 0; i < length; ++i) {\n            if (vec[i] < result.min_num) {\n                result.min_num = vec[i];\n            }\n            if (vec[i] > result.max_num) {\n                result.max_num = vec[i];\n            }\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_35_Neon", "completion": "```c\nMinMaxPair min_max_pair_simd(const int16_t* vec, size_t length) {\n    int16x8_t v_min = vld1q_s16(vec);\n    int16x8_t v_max = vld1q_s16(vec);\n\n    for (size_t i = 8; i < length; i += 8) {\n        int16x8_t v = vld1q_s16(&vec[i]);\n        v_min = vminq_s16(v_min, v);\n        v_max = vmaxq_s16(v_max, v);\n    }\n\n    int16_t min_values[8];\n    int16_t max_values[8];\n\n    vst1q_s16(min_values, v_min);\n    vst1q_s16(max_values, v_max);\n\n    int16_t min_num = min_values[0];\n    int16_t max_num = max_values[0];\n\n    for (int j = 1; j < 8; ++j) {\n        if (min_values[j] < min_num) {\n            min_num = min_values[j];\n        }\n        if (max_values[j] > max_num) {\n            max_num = max_values[j];\n        }\n    }\n\n    MinMaxPair result = {min_num, max_num};\n    return result;\n}\n```"}
{"task_id": "SimdBench_35_Neon", "completion": "```c\nMinMaxPair min_max_pair_simd(const int16_t* vec, size_t length) {\n    MinMaxPair result = {INT16_MAX, INT16_MIN};\n    \n    if (length % 8 == 0) {\n        for (size_t i = 0; i < length; i += 8) {\n            int16x8_t v = vld1q_s16(&vec[i]);\n            int16x8_t vmin = vminvq_s16(v);\n            int16x8_t vmax = vmaxvq_s16(v);\n            \n            result.min_num = vmin[0] < result.min_num ? vmin[0] : result.min_num;\n            result.max_num = vmax[0] > result.max_num ? vmax[0] : result.max_num;\n        }\n    } else {\n        for (size_t i = 0; i < length; ++i) {\n            if (vec[i] < result.min_num) {\n                result.min_num = vec[i];\n            }\n            if (vec[i] > result.max_num) {\n                result.max_num = vec[i];\n            }\n        }\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_35_Neon", "completion": "```cpp\nMinMaxPair min_max_pair_simd(const int16_t* vec, size_t length) {\n    int16x8_t v_min = vld1q_s16(vec);\n    int16x8_t v_max = vld1q_s16(vec);\n\n    for (size_t i = 8; i < length; i += 8) {\n        int16x8_t v = vld1q_s16(&vec[i]);\n        v_min = vminq_s16(v_min, v);\n        v_max = vmaxq_s16(v_max, v);\n    }\n\n    int16_t min_val[8];\n    int16_t max_val[8];\n\n    vst1q_s16(min_val, v_min);\n    vst1q_s16(max_val, v_max);\n\n    int16_t min_num = min_val[0];\n    int16_t max_num = max_val[0];\n\n    for (int j = 1; j < 8; ++j) {\n        if (min_val[j] < min_num) {\n            min_num = min_val[j];\n        }\n        if (max_val[j] > max_num) {\n            max_num = max_val[j];\n        }\n    }\n\n    MinMaxPair result = {min_num, max_num};\n    return result;\n}\n```"}
{"task_id": "SimdBench_35_Neon", "completion": "```cpp\nMinMaxPair min_max_pair_simd(const int16_t* vec, size_t length) {\n    MinMaxPair result = {INT16_MAX, INT16_MIN};\n\n    if (length % 8 == 0) {\n        for (size_t i = 0; i < length; i += 8) {\n            int16x8_t v = vld1q_s16(&vec[i]);\n            int16x8_t vmin = vminvq_s16(v);\n            int16x8_t vmax = vmaxvq_s16(v);\n\n            result.min_num = vmin[0] < result.min_num ? vmin[0] : result.min_num;\n            result.max_num = vmax[0] > result.max_num ? vmax[0] : result.max_num;\n        }\n    } else {\n        for (size_t i = 0; i < length; ++i) {\n            if (vec[i] < result.min_num) {\n                result.min_num = vec[i];\n            }\n            if (vec[i] > result.max_num) {\n                result.max_num = vec[i];\n            }\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_36_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <stdbool.h>\n#include <stddef.h>\n\nbool matrix_rows_strictly_increasing_simd(const int* matrix, size_t rows, size_t cols) {\n    if (rows == 0 || cols == 0) {\n        return false;\n    }\n\n    const int* row_start = matrix;\n    const int* row_end = matrix + rows * cols;\n\n    while (row_start < row_end) {\n        const int* col_start = row_start;\n        const int* col_end = row_start + cols - 1;\n\n        while (col_start < col_end) {\n            int32x4_t vec1 = vld1q_s32(col_start);\n            int32x4_t vec2 = vld1q_s32(col_start + 4);\n\n            int32x4_t cmp = vcgtq_s32(vec1, vec2);\n            if (!vallq_u32(cmp)) {\n                return false;\n            }\n\n            col_start += 8;\n        }\n\n        row_start += cols;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_36_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <stdbool.h>\n#include <stddef.h>\n\nbool matrix_rows_strictly_increasing_simd(const int* matrix, size_t rows, size_t cols) {\n    if (rows == 0 || cols == 0) {\n        return false;\n    }\n\n    const int* row_start = matrix;\n    const int* row_end = matrix + rows * cols;\n\n    while (row_start < row_end) {\n        const int* col_start = row_start;\n        const int* col_end = row_start + cols - 1;\n\n        while (col_start < col_end) {\n            int32x4_t vec1 = vld1q_s32(col_start);\n            int32x4_t vec2 = vld1q_s32(col_start + 4);\n\n            uint32x4_t cmp1 = vcgtq_s32(vec1, vec2);\n            uint32x4_t cmp2 = vceqq_s32(vec1, vec2);\n\n            if (vget_lane_u32(cmp1, 0) || vget_lane_u32(cmp1, 1) || vget_lane_u32(cmp1, 2) || vget_lane_u32(cmp1, 3)) {\n                return false;\n            }\n            if (vget_lane_u32(cmp2, 0) || vget_lane_u32(cmp2, 1) || vget_lane_u32(cmp2, 2) || vget_lane_u32(cmp2, 3)) {\n                return false;\n            }\n\n            col_start += 8;\n        }\n\n        row_start += cols;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_36_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <stdbool.h>\n#include <stddef.h>\n\nbool matrix_rows_strictly_increasing_simd(const int* matrix, size_t rows, size_t cols) {\n    if (rows == 0 || cols == 0) {\n        return false;\n    }\n\n    const int* row_start = matrix;\n    const int* row_end = matrix + rows * cols;\n\n    while (row_start < row_end) {\n        const int* col_start = row_start;\n        const int* col_end = row_start + cols - 1;\n\n        while (col_start < col_end) {\n            int32x4_t vec1 = vld1q_s32(col_start);\n            int32x4_t vec2 = vld1q_s32(col_start + 4);\n\n            uint32x4_t cmp1 = vcgtq_s32(vec1, vec2);\n            uint32x4_t cmp2 = vceqq_s32(vec1, vec2);\n\n            if (vget_lane_u32(cmp1, 0) || vget_lane_u32(cmp1, 1) || vget_lane_u32(cmp1, 2) || vget_lane_u32(cmp1, 3)) {\n                return false;\n            }\n\n            if (vget_lane_u32(cmp2, 0) || vget_lane_u32(cmp2, 1) || vget_lane_u32(cmp2, 2) || vget_lane_u32(cmp2, 3)) {\n                return false;\n            }\n\n            col_start += 8;\n        }\n\n        row_start += cols;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_36_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <stdbool.h>\n#include <stddef.h>\n\nbool matrix_rows_strictly_increasing_simd(const int* matrix, size_t rows, size_t cols) {\n    if (rows == 0 || cols == 0) {\n        return false;\n    }\n\n    const int* row_start = matrix;\n    const int* row_end = matrix + rows * cols;\n\n    while (row_start < row_end) {\n        const int* col_start = row_start;\n        const int* col_end = row_start + cols - 1;\n\n        while (col_start < col_end) {\n            int32x4_t vec1 = vld1q_s32(col_start);\n            int32x4_t vec2 = vld1q_s32(col_start + 4);\n\n            int32x4_t cmp = vcgtq_s32(vec1, vec2);\n            if (!vallq_u32(cmp)) {\n                return false;\n            }\n\n            col_start += 8;\n        }\n\n        row_start += cols;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_36_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <stdbool.h>\n#include <stddef.h>\n\nbool matrix_rows_strictly_increasing_simd(const int* matrix, size_t rows, size_t cols) {\n    if (rows == 0 || cols == 0) {\n        return false;\n    }\n\n    const int* row_start = matrix;\n    const int* row_end = matrix + rows * cols;\n\n    while (row_start < row_end) {\n        const int* col_start = row_start;\n        const int* col_end = row_start + cols - 1;\n\n        while (col_start < col_end) {\n            int32x4_t vec1 = vld1q_s32(col_start);\n            int32x4_t vec2 = vld1q_s32(col_start + 4);\n\n            uint32x4_t cmp1 = vcgtq_s32(vec1, vec2);\n            uint32x4_t cmp2 = vceqq_s32(vec1, vec2);\n\n            if (vget_lane_u32(cmp1, 0) || vget_lane_u32(cmp1, 1) || vget_lane_u32(cmp1, 2) || vget_lane_u32(cmp1, 3)) {\n                return false;\n            }\n            if (vget_lane_u32(cmp2, 0) || vget_lane_u32(cmp2, 1) || vget_lane_u32(cmp2, 2) || vget_lane_u32(cmp2, 3)) {\n                return false;\n            }\n\n            col_start += 8;\n        }\n\n        row_start += cols;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_37_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <stdbool.h>\n\nbool matrix_blocks_equal_simd(const int* matrix, size_t block_size, size_t rows, size_t cols) {\n    if (block_size == 0 || rows % block_size != 0 || cols % block_size != 0) {\n        return false;\n    }\n\n    const int* first_block = matrix;\n    uint32x4_t first_block_vec[8];\n    for (size_t i = 0; i < block_size * block_size / 16; ++i) {\n        first_block_vec[i] = vld1q_u32(first_block + i * 16);\n    }\n\n    for (size_t row = block_size; row < rows; row += block_size) {\n        for (size_t col = 0; col < cols; col += block_size) {\n            const int* current_block = matrix + row * cols + col;\n            uint32x4_t current_block_vec[8];\n            for (size_t i = 0; i < block_size * block_size / 16; ++i) {\n                current_block_vec[i] = vld1q_u32(current_block + i * 16);\n            }\n\n            for (size_t i = 0; i < 8; ++i) {\n                if (!vceqq_u32(first_block_vec[i], current_block_vec[i])) {\n                    return false;\n                }\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_37_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <stdbool.h>\n\nbool matrix_blocks_equal_simd(const int* matrix, size_t block_size, size_t rows, size_t cols) {\n    if (block_size == 0 || rows % block_size != 0 || cols % block_size != 0) {\n        return false;\n    }\n\n    const int* first_block = matrix;\n    int32x4_t first_block_vec[8];\n    for (size_t i = 0; i < block_size * block_size / 16; ++i) {\n        first_block_vec[i] = vld1q_s32(first_block + i * 16);\n    }\n\n    for (size_t row = block_size; row < rows; row += block_size) {\n        for (size_t col = 0; col < cols; col += block_size) {\n            const int* current_block = matrix + row * cols + col;\n            int32x4_t current_block_vec[8];\n            for (size_t i = 0; i < block_size * block_size / 16; ++i) {\n                current_block_vec[i] = vld1q_s32(current_block + i * 16);\n            }\n\n            for (size_t i = 0; i < block_size * block_size / 16; ++i) {\n                if (!vceqq_s32(first_block_vec[i], current_block_vec[i])) {\n                    return false;\n                }\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_37_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nbool matrix_blocks_equal_simd(const int* matrix, size_t block_size, size_t rows, size_t cols) {\n    if (block_size == 0 || rows % block_size != 0 || cols % block_size != 0) {\n        return false;\n    }\n\n    const int* first_block = matrix;\n    int32x4_t first_block_vec[8];\n    for (size_t i = 0; i < block_size * block_size / 16; ++i) {\n        first_block_vec[i] = vld1q_s32(first_block + i * 16);\n    }\n\n    for (size_t row = block_size; row < rows; row += block_size) {\n        for (size_t col = 0; col < cols; col += block_size) {\n            const int* current_block = matrix + row * cols + col;\n            int32x4_t current_block_vec[8];\n            for (size_t i = 0; i < block_size * block_size / 16; ++i) {\n                current_block_vec[i] = vld1q_s32(current_block + i * 16);\n            }\n\n            for (size_t i = 0; i < block_size * block_size / 16; ++i) {\n                if (!vceqq_s32(first_block_vec[i], current_block_vec[i])) {\n                    return false;\n                }\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_37_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nbool matrix_blocks_equal_simd(const int* matrix, size_t block_size, size_t rows, size_t cols) {\n    if (block_size == 0 || rows % block_size != 0 || cols % block_size != 0) {\n        return false;\n    }\n\n    const int* first_block = matrix;\n    int32x4_t first_block_vec[8];\n    for (size_t i = 0; i < block_size * block_size / 16; ++i) {\n        first_block_vec[i] = vld1q_s32(first_block + i * 16);\n    }\n\n    for (size_t row = block_size; row < rows; row += block_size) {\n        for (size_t col = 0; col < cols; col += block_size) {\n            const int* current_block = matrix + row * cols + col;\n            int32x4_t current_block_vec[8];\n            for (size_t i = 0; i < block_size * block_size / 16; ++i) {\n                current_block_vec[i] = vld1q_s32(current_block + i * 16);\n            }\n\n            for (size_t i = 0; i < block_size * block_size / 16; ++i) {\n                if (!vceqq_s32(first_block_vec[i], current_block_vec[i])) {\n                    return false;\n                }\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_37_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <stdbool.h>\n#include <stddef.h>\n\nbool matrix_blocks_equal_simd(const int* matrix, size_t block_size, size_t rows, size_t cols) {\n    if (block_size == 0 || rows % block_size != 0 || cols % block_size != 0) {\n        return false;\n    }\n\n    const int* first_block = matrix;\n    int32x4_t first_block_vec[8];\n    for (size_t i = 0; i < block_size * block_size / 16; ++i) {\n        first_block_vec[i] = vld1q_s32(first_block + i * 16);\n    }\n\n    for (size_t row = block_size; row < rows; row += block_size) {\n        for (size_t col = 0; col < cols; col += block_size) {\n            const int* current_block = matrix + row * cols + col;\n            int32x4_t current_block_vec[8];\n            for (size_t i = 0; i < block_size * block_size / 16; ++i) {\n                current_block_vec[i] = vld1q_s32(current_block + i * 16);\n            }\n\n            for (size_t i = 0; i < block_size * block_size / 16; ++i) {\n                if (!vceqq_s32(first_block_vec[i], current_block_vec[i])) {\n                    return false;\n                }\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_38_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <cmath>\n\nbool vector_block_equal_simd(const double* vec, double tolerance, size_t length, size_t block_size) {\n    if (length < block_size || block_size % 8 != 0) {\n        return false;\n    }\n\n    const double* end = vec + length - block_size;\n    const double* block_start = vec;\n\n    while (vec <= end) {\n        double32x2_t v0 = vld1_f32((float32_t*)vec);\n        double32x2_t v1 = vld1_f32((float32_t*)(vec + 4));\n        double32x2_t v2 = vld1q_f32((float32_t*)block_start);\n        double32x2_t v3 = vld1q_f32((float32_t*)(block_start + 4));\n\n        float32x2_t diff0 = vabs_f32(vsub_f32(v0, v2));\n        float32x2_t diff1 = vabs_f32(vsub_f32(v1, v3));\n\n        uint32x2_t cmp0 = vcgt_f32(diff0, vdup_n_f32(tolerance));\n        uint32x2_t cmp1 = vcgt_f32(diff1, vdup_n_f32(tolerance));\n\n        if (vget_lane_u32(cmp0, 0) || vget_lane_u32(cmp0, 1) ||\n            vget_lane_u32(cmp1, 0) || vget_lane_u32(cmp1, 1)) {\n            return false;\n        }\n\n        vec += 8;\n        block_start += 8;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_38_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <cmath>\n\nbool vector_block_equal_simd(const double* vec, double tolerance, size_t length, size_t block_size) {\n    if (length < block_size || block_size % 8 != 0) {\n        return false;\n    }\n\n    const double* end = vec + length - block_size;\n    const double* block_start = vec;\n\n    while (vec <= end) {\n        double32x2_t v0 = vld1_f32((float32_t*)vec);\n        double32x2_t v1 = vld1_f32((float32_t*)(vec + 4));\n        double32x2_t v2 = vld1q_f32((float32_t*)block_start);\n        double32x2_t v3 = vld1q_f32((float32_t*)(block_start + 4));\n\n        float32x2_t diff0 = vsub_f32(v0, v2);\n        float32x2_t diff1 = vsub_f32(v1, v3);\n\n        uint32x2_t eq0 = vceq_f32(diff0, vdup_n_f32(0.0f));\n        uint32x2_t eq1 = vceq_f32(diff1, vdup_n_f32(0.0f));\n\n        uint32x2_t abs_diff0 = vabs_f32(diff0);\n        uint32x2_t abs_diff1 = vabs_f32(diff1);\n\n        uint32x2_t gt0 = vcgt_f32(abs_diff0, vdup_n_f32(tolerance));\n        uint32x2_t gt1 = vcgt_f32(abs_diff1, vdup_n_f32(tolerance));\n\n        uint32x2_t mask0 = veor_u32(eq0, gt0);\n        uint32x2_t mask1 = veor_u32(eq1, gt1);\n\n        if (vmovn_u32(mask0) | vmovn_u32(mask1)) {\n            return false;\n        }\n\n        vec += 8;\n        block_start += 8;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_38_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <cmath>\n\nbool vector_block_equal_simd(const double* vec, double tolerance, size_t length, size_t block_size) {\n    if (length < block_size || block_size % 8 != 0) {\n        return false;\n    }\n\n    const double* end = vec + length - block_size;\n    const double* block_start = vec;\n\n    while (vec <= end) {\n        double32x2_t v0 = vld1q_f32((float32_t*)vec);\n        double32x2_t v1 = vld1q_f32((float32_t*)(vec + 4));\n        double32x2_t v2 = vld1q_f32((float32_t*)block_start);\n        double32x2_t v3 = vld1q_f32((float32_t*)(block_start + 4));\n\n        float32x2_t diff0 = vsubq_f32(v0, v2);\n        float32x2_t diff1 = vsubq_f32(v1, v3);\n\n        uint32x2_t cmp0 = vcltq_f32(diff0, vdupq_n_f32(tolerance));\n        uint32x2_t cmp1 = vcltq_f32(diff1, vdupq_n_f32(tolerance));\n\n        uint32x2_t mask = vorrq_u32(cmp0, cmp1);\n        if (vget_lane_u32(mask, 0) || vget_lane_u32(mask, 1)) {\n            return false;\n        }\n\n        vec += 8;\n        block_start += 8;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_38_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <cmath>\n\nbool vector_block_equal_simd(const double* vec, double tolerance, size_t length, size_t block_size) {\n    if (length < block_size || block_size == 0) {\n        return false;\n    }\n\n    const double* end = vec + length - block_size;\n    const double* block_start = vec;\n\n    while (vec <= end) {\n        double32x2_t v1 = vld1_f32((float32_t*)vec);\n        double32x2_t v2 = vld1_f32((float32_t*)(vec + 4));\n        double32x2_t v3 = vld1_f32((float32_t*)(vec + 8));\n        double32x2_t v4 = vld1_f32((float32_t*)(vec + 12));\n\n        double32x2_t diff1 = vsub_f32(v1, vld1_f32((float32_t*)block_start));\n        double32x2_t diff2 = vsub_f32(v2, vld1_f32((float32_t*)(block_start + 4)));\n        double32x2_t diff3 = vsub_f32(v3, vld1_f32((float32_t*)(block_start + 8)));\n        double32x2_t diff4 = vsub_f32(v4, vld1_f32((float32_t*)(block_start + 12)));\n\n        uint32x2_t cmp1 = vcgt_f32(vabs_f32(diff1), vdup_n_f32(tolerance));\n        uint32x2_t cmp2 = vcgt_f32(vabs_f32(diff2), vdup_n_f32(tolerance));\n        uint32x2_t cmp3 = vcgt_f32(vabs_f32(diff3), vdup_n_f32(tolerance));\n        uint32x2_t cmp4 = vcgt_f32(vabs_f32(diff4), vdup_n_f32(tolerance));\n\n        if (vget_lane_u32(cmp1, 0) || vget_lane_u32(cmp1, 1) ||\n            vget_lane_u32(cmp2, 0) || vget_lane_u32(cmp2, 1) ||\n            vget_lane_u32(cmp3, 0) || vget_lane_u32(cmp3, 1) ||\n            vget_lane_u32(cmp4, 0) || vget_lane_u32(cmp4, 1)) {\n            return false;\n        }\n\n        vec += 16;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_38_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <cmath>\n\nbool vector_block_equal_simd(const double* vec, double tolerance, size_t length, size_t block_size) {\n    if (length < block_size || block_size % 8 != 0) {\n        return false;\n    }\n\n    const double* end = vec + length - block_size;\n    const double* block_start = vec;\n\n    while (vec <= end) {\n        double32x2_t v0 = vld1_f32((float32_t*)vec);\n        double32x2_t v1 = vld1_f32((float32_t*)(vec + 4));\n        double32x2_t v2 = vld1_f32((float32_t*)block_start);\n        double32x2_t v3 = vld1_f32((float32_t*)(block_start + 4));\n\n        float32x2_t diff0 = vabs_f32(vsub_f32(v0, v2));\n        float32x2_t diff1 = vabs_f32(vsub_f32(v1, v3));\n\n        uint32x2_t cmp0 = vcgt_f32(diff0, vdup_n_f32(tolerance));\n        uint32x2_t cmp1 = vcgt_f32(diff1, vdup_n_f32(tolerance));\n\n        if (vget_lane_u32(cmp0, 0) || vget_lane_u32(cmp0, 1) ||\n            vget_lane_u32(cmp1, 0) || vget_lane_u32(cmp1, 1)) {\n            return false;\n        }\n\n        vec += 8;\n        block_start += 8;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_39_Neon", "completion": "```cpp\nvoid matrix_row_norm_compare_simd(const double* matrix, const double* thresholds, size_t rows, size_t cols, bool* result) {\n    for (size_t i = 0; i < rows; ++i) {\n        int32x4_t sum = vdupq_n_s32(0);\n        for (size_t j = 0; j < cols; j += 4) {\n            int64x2_t vec1 = vld1q_f64(matrix + i * cols + j);\n            int64x2_t vec2 = vld1q_f64(matrix + i * cols + j + 2);\n            int64x2_t diff1 = vmulq_s64(vreinterpretq_s64_f64(vec1), vreinterpretq_s64_f64(vec1));\n            int64x2_t diff2 = vmulq_s64(vreinterpretq_s64_f64(vec2), vreinterpretq_s64_f64(vec2));\n            sum = vmlal_s64(sum, vget_low_s64(diff1), vget_low_s64(diff2));\n            sum = vmlal_high_s64(sum, vget_high_s64(diff1), vget_high_s64(diff2));\n        }\n        double norm = sqrt(vget_lane_f64(vreinterpretq_f64_u64(sum), 0) / cols);\n        result[i] = norm > thresholds[i];\n    }\n}\n```"}
{"task_id": "SimdBench_39_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nvoid matrix_row_norm_compare_simd(const double* matrix, const double* thresholds, size_t rows, size_t cols, bool* result) {\n    for (size_t i = 0; i < rows; ++i) {\n        const double* row_start = matrix + i * cols;\n        const double* threshold = thresholds + i;\n\n        float64x2_t sum = vdupq_n_f64(0.0);\n\n        for (size_t j = 0; j < cols - 1; j += 2) {\n            float64x2_t vec1 = vld1q_f64(row_start + j);\n            float64x2_t vec2 = vld1q_f64(row_start + j + 1);\n            sum = vfmaq_f64(sum, vec1, vec1);\n            sum = vfmaq_f64(sum, vec2, vec2);\n        }\n\n        if (cols % 2 != 0) {\n            float64x1_t vec = vld1_f64(row_start + cols - 1);\n            sum = vfmaq_laneq_f64(sum, vec, vec, 0);\n        }\n\n        double norm = vgetq_lane_f64(vsqrtq_f64(sum), 0);\n        result[i] = norm > *threshold;\n    }\n}\n```"}
{"task_id": "SimdBench_39_Neon", "completion": "```cpp\nvoid matrix_row_norm_compare_simd(const double* matrix, const double* thresholds, size_t rows, size_t cols, bool* result) {\n    for (size_t i = 0; i < rows; ++i) {\n        int32x4_t sum = vdupq_n_s32(0);\n        for (size_t j = 0; j < cols; j += 4) {\n            int64x2_t vec1 = vld1q_f64(matrix + i * cols + j);\n            int64x2_t vec2 = vmulq_f64(vec1, vec1);\n            int64x2_t vec3 = vld1q_f64(matrix + i * cols + j + 2);\n            int64x2_t vec4 = vmulq_f64(vec3, vec3);\n            int64x2_t sum_vec = vaddq_s64(vreinterpretq_s64_f64(vec2),vreinterpretq_s64_f64(vec4));\n            sum = vpadalq_s32(sum, vreinterpretq_s32_u32(vmovl_high_s16(vreinterpretq_s16_u16(vreinterpretq_u16_s32(sum)))));\n            sum = vpadalq_s32(sum, vreinterpretq_s32_u32(vmovl_low_s16(vreinterpretq_s16_u16(vreinterpretq_u32_s32(sum)))));\n        }\n        double norm = sqrt(static_cast<double>(vgetq_lane_s32(sum, 0)));\n        result[i] = norm > thresholds[i];\n    }\n}\n```"}
{"task_id": "SimdBench_39_Neon", "completion": "```cpp\nvoid matrix_row_norm_compare_simd(const double* matrix, const double* thresholds, size_t rows, size_t cols, bool* result) {\n    for (size_t i = 0; i < rows; ++i) {\n        int32x4_t sum = vdupq_n_s32(0);\n        for (size_t j = 0; j < cols; j += 4) {\n            int64x2_t vec1 = vld1q_f64(matrix + i * cols + j);\n            int64x2_t vec2 = vmulq_f64(vec1, vec1);\n            int64x2_t vec3 = vld1q_f64(matrix + i * cols + j + 2);\n            int64x2_t vec4 = vmulq_f64(vec3, vec3);\n            int64x2_t sum_vec1 = vpaddlq_s64(vreinterpretq_s64_f64(vec2));\n            int64x2_t sum_vec2 = vpaddlq_s64(vreinterpretq_s64_f64(vec4));\n            int64x2_t sum_vec = vpaddq_s64(sum_vec1, sum_vec2);\n            sum = vpadalq_s32(sum, vreinterpretq_s32_u64(sum_vec));\n        }\n        double norm = sqrt(vgetq_lane_f32(vcvtq_f32_s32(sum), 0));\n        result[i] = norm > thresholds[i];\n    }\n}\n```"}
{"task_id": "SimdBench_39_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nvoid matrix_row_norm_compare_simd(const double* matrix, const double* thresholds, size_t rows, size_t cols, bool* result) {\n    for (size_t i = 0; i < rows; ++i) {\n        const double* row_start = matrix + i * cols;\n        const double* threshold = thresholds + i;\n\n        float64x2_t sum = vdupq_n_f64(0.0);\n\n        for (size_t j = 0; j < cols - 1; j += 2) {\n            float64x2_t vec1 = vld1q_f64(row_start + j);\n            float64x2_t vec2 = vld1q_f64(row_start + j + 1);\n            sum = vfmaq_f64(sum, vec1, vec1);\n            sum = vfmaq_f64(sum, vec2, vec2);\n        }\n\n        if (cols % 2 != 0) {\n            float64x2_t vec = vld1q_lane_f64(row_start[cols - 1], vdupq_n_f64(0.0), 0);\n            sum = vfmaq_f64(sum, vec, vec);\n        }\n\n        double norm = vgetq_lane_f64(vsqrtq_f64(sum), 0);\n        result[i] = norm > *threshold;\n    }\n}\n```"}
{"task_id": "SimdBench_40_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid tensor_bitwise_or_simd(const uint32_t* A, const uint32_t* B, uint32_t* C, size_t length) {\n    size_t i;\n    for (i = 0; i <= length - 4; i += 4) {\n        uint32x4_t va = vld1q_u32(&A[i]);\n        uint32x4_t vb = vld1q_u32(&B[i]);\n        uint32x4_t vc = vorrq_u32(va, vb);\n        vst1q_u32(&C[i], vc);\n    }\n    for (; i < length; ++i) {\n        C[i] = A[i] | B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_40_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid tensor_bitwise_or_simd(const uint32_t* A, const uint32_t* B, uint32_t* C, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 4; i += 4) {\n        uint32x4_t va = vld1q_u32(&A[i]);\n        uint32x4_t vb = vld1q_u32(&B[i]);\n        uint32x4_t vc = vorrq_u32(va, vb);\n        vst1q_u32(&C[i], vc);\n    }\n    for (; i < length; ++i) {\n        C[i] = A[i] | B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_40_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nvoid tensor_bitwise_or_simd(const uint32_t* A, const uint32_t* B, uint32_t* C, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 4; i += 4) {\n        uint32x4_t va = vld1q_u32(&A[i]);\n        uint32x4_t vb = vld1q_u32(&B[i]);\n        uint32x4_t vc = vorrq_u32(va, vb);\n        vst1q_u32(&C[i], vc);\n    }\n    for (; i < length; ++i) {\n        C[i] = A[i] | B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_40_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid tensor_bitwise_or_simd(const uint32_t* A, const uint32_t* B, uint32_t* C, size_t length) {\n    size_t i;\n    for (i = 0; i <= length - 4; i += 4) {\n        uint32x4_t va = vld1q_u32(&A[i]);\n        uint32x4_t vb = vld1q_u32(&B[i]);\n        uint32x4_t vc = vorrq_u32(va, vb);\n        vst1q_u32(&C[i], vc);\n    }\n    for (; i < length; ++i) {\n        C[i] = A[i] | B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_40_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid tensor_bitwise_or_simd(const uint32_t* A, const uint32_t* B, uint32_t* C, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 4; i += 4) {\n        uint32x4_t va = vld1q_u32(&A[i]);\n        uint32x4_t vb = vld1q_u32(&B[i]);\n        uint32x4_t vc = vorrq_u32(va, vb);\n        vst1q_u32(&C[i], vc);\n    }\n    for (; i < length; ++i) {\n        C[i] = A[i] | B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_41_Neon", "completion": "```cpp\nint64_t squarediff_simd(const int8_t * A, const int8_t * B, size_t length) {\n    int32x4_t sum_squares = vdupq_n_s32(0);\n    int32x4_t sum_products = vdupq_n_s32(0);\n\n    for (size_t i = 0; i <= length - 16; i += 16) {\n        int8x16_t vec_A = vld1q_s8(&A[i]);\n        int8x16_t vec_B = vld1q_s8(&B[i]);\n\n        int16x8_t prod = vmulq_s16(vreinterpretq_s16_s8(vec_A),vreinterpretq_s16_s8(vec_B));\n        int32x4_t prod_sum = vpaddlq_s16(prod);\n        sum_products = vmlal_laneq_s32(sum_products, prod_sum, prod_sum, 0);\n\n        int32x4_t square_A = vmull_s16(vreinterpretq_s16_s8(vec_A),vreinterpretq_s16_s8(vec_A));\n        int32x4_t square_B = vmull_s16(vreinterpretq_s16_s8(vec_B),vreinterpretq_s16_s8(vec_B));\n        int32x4_t square_sum = vpadalq_s32(square_A, square_B);\n        sum_squares = vmlal_laneq_s32(sum_squares, square_sum, square_sum, 0);\n    }\n\n    int64_t sum_squares_total = vgetq_lane_s32(sum_squares, 0) + vgetq_lane_s32(sum_squares, 1) +\n                               vgetq_lane_s32(sum_squares, 2) + vgetq_lane_s32(sum_squares, 3);\n    int64_t sum_products_total = vgetq_lane_s32(sum_products, 0) + vgetq_lane_s32(sum_products, 1) +\n                                vgetq_lane_s32(sum_products, 2) + vgetq_lane_s32(sum_products, 3);\n\n    for (size_t i = length - length % 16; i < length; ++i) {\n        sum_squares_total += A[i] * A[i];\n        sum_products_total += A[i] * B[i];\n    }\n\n    return sum_squares_total - sum_products_total;\n}\n```"}
{"task_id": "SimdBench_41_Neon", "completion": "```c\nint64_t squarediff_simd(const int8_t * A, const int8_t * B, size_t length) {\n    int32x4_t sum_squares = vdupq_n_s32(0);\n    int32x4_t sum_products = vdupq_n_s32(0);\n\n    for (size_t i = 0; i <= length - 16; i += 16) {\n        int8x16_t vec_A = vld1q_s8(&A[i]);\n        int8x16_t vec_B = vld1q_s8(&B[i]);\n\n        int16x8_t prod = vmulq_s16(vreinterpretq_s16_s8(vec_A),vreinterpretq_s16_s8(vec_B));\n        int32x4_t prod_sum = vpaddlq_s16(prod);\n        sum_products = vmlal_laneq_s32(sum_products, prod_sum, prod_sum, 0);\n\n        int32x4_t square_A = vmull_s16(vreinterpretq_s16_s8(vec_A),vreinterpretq_s16_s8(vec_A));\n        int32x4_t square_B = vmull_s16(vreinterpretq_s16_s8(vec_B),vreinterpretq_s16_s8(vec_B));\n        sum_squares = vmlal_laneq_s32(sum_squares, square_A, square_B, 0);\n    }\n\n    int64_t sum_squares_total = vgetq_lane_s64(vreinterpretq_s64_s32(sum_squares), 0) + vgetq_lane_s64(vreinterpretq_s64_s32(sum_squares), 1);\n    int64_t sum_products_total = vgetq_lane_s64(vreinterpretq_s64_s32(sum_products), 0) + vgetq_lane_s64(vreinterpretq_s64_s32(sum_products), 1);\n\n    for (size_t i = length - 16; i < length; ++i) {\n        sum_squares_total += A[i] * A[i];\n        sum_products_total += A[i] * B[i];\n    }\n\n    return sum_squares_total - sum_products_total;\n}\n```"}
{"task_id": "SimdBench_41_Neon", "completion": "```cpp\nint64_t squarediff_simd(const int8_t * A, const int8_t * B, size_t length) {\n    int32x4_t sum_squares = vdupq_n_s32(0);\n    int32x4_t sum_products = vdupq_n_s32(0);\n\n    for (size_t i = 0; i <= length - 16; i += 16) {\n        int8x16_t vec_A = vld1q_s8(A + i);\n        int8x16_t vec_B = vld1q_s8(B + i);\n\n        int16x8_t prod = vmulq_s16(vreinterpretq_s16_s8(vec_A),vreinterpretq_s16_s8(vec_B));\n        int32x4_t prod_sum = vpaddlq_s16(prod);\n        sum_products = vmlal_laneq_s32(sum_products, prod_sum, prod_sum, 0);\n\n        int16x8_t sq_A = vmulq_s16(vec_A, vec_A);\n        int16x8_t sq_B = vmulq_s16(vec_B, vec_B);\n        int32x4_t sq_sum_A = vpaddlq_s16(sq_A);\n        int32x4_t sq_sum_B = vpaddlq_s16(sq_B);\n        sum_squares = vmlal_laneq_s32(sum_squares, sq_sum_A, sq_sum_A, 0);\n        sum_squares = vmlal_laneq_s32(sum_squares, sq_sum_B, sq_sum_B, 0);\n    }\n\n    int64_t total_sum_squares = vgetq_lane_s64(vpaddlq_s32(sum_squares), 0);\n    int64_t total_sum_products = vgetq_lane_s64(sum_products, 0);\n\n    for (size_t i = length - length % 16; i < length; ++i) {\n        total_sum_squares += A[i] * A[i];\n        total_sum_products += A[i] * B[i];\n    }\n\n    return total_sum_squares - 2 * total_sum_products;\n}\n```"}
{"task_id": "SimdBench_41_Neon", "completion": "```cpp\nint64_t squarediff_simd(const int8_t * A, const int8_t * B, size_t length) {\n    int32x4_t sum_squares = vdupq_n_s32(0);\n    int32x4_t sum_products = vdupq_n_s32(0);\n\n    for (size_t i = 0; i <= length - 16; i += 16) {\n        int8x16_t vec_A = vld1q_s8(A + i);\n        int8x16_t vec_B = vld1q_s8(B + i);\n\n        int16x8_t mul_low = vmulq_s16(vreinterpretq_s16_s8(vec_A),vreinterpretq_s16_s8(vec_B));\n        int16x8_t mul_high = vmulq_s16(vreinterpretq_s16_s8(vextq_s8(vec_A, vec_A, 8)),vreinterpretq_s16_s8(vextq_s8(vec_B, vec_B, 8)));\n\n        int32x4_t sum_mul_low = vpaddlq_s16(mul_low);\n        int32x4_t sum_mul_high = vpaddlq_s16(mul_high);\n\n        sum_products = vmlal_laneq_s32(sum_products, sum_mul_low, vget_low_s32(sum_mul_high), 0);\n        sum_products = vmlal_laneq_s32(sum_products, sum_mul_low, vget_high_s32(sum_mul_high), 1);\n\n        int32x4_t square_low = vmull_s16(vreinterpretq_s16_s8(vec_A),vreinterpretq_s16_s8(vec_A));\n        int32x4_t square_high = vmull_s16(vreinterpretq_s16_s8(vextq_s8(vec_A, vec_A, 8)),vreinterpretq_s16_s8(vextq_s8(vec_A, vec_A, 8)));\n\n        sum_squares = vmlal_laneq_s32(sum_squares, square_low, vget_low_s32(square_high), 0);\n        sum_squares = vmlal_laneq_s32(sum_squares, square_low, vget_high_s32(square_high), 1);\n    }\n\n    int64_t result = vgetq_lane_s64(vpaddlq_s32(sum_products), 0) - vgetq_lane_s64(vpaddlq_s32(sum_squares), 0);\n\n    for (size_t i = length - length % 16; i < length; ++i) {\n        result += static_cast<int64_t>(A[i]) * A[i] - static_cast<int64_t>(B[i]) * B[i];\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_41_Neon", "completion": "```cpp\nint64_t squarediff_simd(const int8_t * A, const int8_t * B, size_t length) {\n    int32x4_t sum_squares = vdupq_n_s32(0);\n    int32x4_t sum_products = vdupq_n_s32(0);\n\n    for (size_t i = 0; i <= length - 16; i += 16) {\n        int8x16_t vec_A = vld1q_s8(&A[i]);\n        int8x16_t vec_B = vld1q_s8(&B[i]);\n\n        int16x8_t mul_low = vmulq_s16(vreinterpretq_s16_s8(vec_A),vreinterpretq_s16_s8(vec_B));\n        int16x8_t mul_high = vmulq_s16(vreinterpretq_s16_s8(vextq_u8(vec_A,vec_A,8)),vreinterpretq_s16_s8(vextq_u8(vec_B,vec_B,8)));\n\n        int32x4_t sum_mul_low = vpaddlq_s16(mul_low);\n        int32x4_t sum_mul_high = vpaddlq_s16(mul_high);\n\n        sum_products = vmlal_laneq_s32(sum_products,sum_mul_low,vget_low_s32(sum_mul_high),0);\n        sum_products = vmlal_laneq_s32(sum_products,sum_mul_high,vget_high_s32(sum_mul_high),1);\n\n        int16x8_t sq_low = vmulq_s16(vec_A,vec_A);\n        int16x8_t sq_high = vmulq_s16(vextq_u8(vec_A,vec_A,8),vextq_u8(vec_A,vec_A,8));\n\n        int32x4_t sum_sq_low = vpaddlq_s16(sq_low);\n        int32x4_t sum_sq_high = vpaddlq_s16(sq_high);\n\n        sum_squares = vmlal_laneq_s32(sum_squares,sum_sq_low,vget_low_s32(sum_sq_high),0);\n        sum_squares = vmlal_laneq_s32(sum_squares,sum_sq_high,vget_high_s32(sum_sq_high),1);\n    }\n\n    int64_t sum_squares_val = vgetq_lane_s64(vreinterpretq_s64_s32(sum_squares),0);\n    int64_t sum_products_val = vgetq_lane_s64(vreinterpretq_s64_s32(sum_products),0);\n\n    for (size_t i = length - 16; i < length; ++i) {\n        sum_squares_val += A[i] * A[i];\n        sum_products_val += A[i] * B[i];\n    }\n\n    return sum_squares_val - sum_products_val;\n}\n```"}
{"task_id": "SimdBench_42_Neon", "completion": "```cpp\nvoid tensor_bit_clear_simd(const uint64_t* A, const uint64_t* B, uint64_t* C, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 4; i += 4) {\n        uint64x2_t va = vld1q_u64(&A[i]);\n        uint64x2_t vb = vld1q_u64(&B[i]);\n        uint64x2_t vc = vld1q_u64(&C[i]);\n\n        vb = vmvnq_u64(vb);\n\n        vc = vandq_u64(va, vb);\n\n        vst1q_u64(&C[i], vc);\n    }\n\n    for (; i < length; ++i) {\n        C[i] = A[i] & ~B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_42_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid tensor_bit_clear_simd(const uint64_t* A, const uint64_t* B, uint64_t* C, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 4; i += 4) {\n        uint64x2_t va = vld1q_u64(&A[i]);\n        uint64x2_t vb = vld1q_u64(&B[i]);\n        uint64x2_t vc = vld1q_u64(&C[i]);\n\n        uint64x2_t vn = vmvnq_u64(vb);\n        uint64x2_t res1 = vandq_u64(va, vn);\n\n        uint64x2_t va2 = vld1q_u64(&A[i + 2]);\n        uint64x2_t vb2 = vld1q_u64(&B[i + 2]);\n        uint64x2_t vc2 = vld1q_u64(&C[i + 2]);\n\n        uint64x2_t vn2 = vmvnq_u64(vb2);\n        uint64x2_t res2 = vandq_u64(va2, vn2);\n\n        vst1q_u64(&C[i], res1);\n        vst1q_u64(&C[i + 2], res2);\n    }\n\n    for (; i < length; ++i) {\n        C[i] = A[i] & ~B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_42_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nvoid tensor_bit_clear_simd(const uint64_t* A, const uint64_t* B, uint64_t* C, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 4; i += 4) {\n        uint64x2_t va = vld1q_u64(&A[i]);\n        uint64x2_t vb = vld1q_u64(&B[i]);\n        uint64x2_t vc = vld1q_u64(&C[i]);\n\n        uint64x2_t vn = vmvnq_u64(vb);\n        uint64x2_t res = vandq_u64(va, vn);\n\n        vst1q_u64(&C[i], res);\n    }\n\n    for (; i < length; ++i) {\n        C[i] = A[i] & ~B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_42_Neon", "completion": "```cpp\nvoid tensor_bit_clear_simd(const uint64_t* A, const uint64_t* B, uint64_t* C, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 4; i += 4) {\n        uint64x2_t va = vld1q_u64(&A[i]);\n        uint64x2_t vb = vld1q_u64(&B[i]);\n        uint64x2_t vc = vld1q_u64(&C[i]);\n\n        vb = vmvnq_u64(vb);\n        vc = vandq_u64(va, vb);\n\n        vst1q_u64(&C[i], vc);\n    }\n\n    for (; i < length; ++i) {\n        C[i] = A[i] & ~B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_42_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid tensor_bit_clear_simd(const uint64_t* A, const uint64_t* B, uint64_t* C, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 4; i += 4) {\n        uint64x2_t va = vld1q_u64(&A[i]);\n        uint64x2_t vb = vld1q_u64(&B[i]);\n        uint64x2_t vc = vld1q_u64(&C[i]);\n\n        uint64x2_t vb_neg = vmvnq_u64(vb);\n        uint64x2_t result = vandq_u64(va, vb_neg);\n\n        vst1q_u64(&C[i], result);\n    }\n\n    // Handle remaining elements\n    for (; i < length; ++i) {\n        C[i] = A[i] & ~B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_43_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nvoid tensor_three_valued_logic_simd(const int8_t* A, const int8_t* B, int8_t* C, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 16; i += 16) {\n        int8x16_t va = vld1q_s8(&A[i]);\n        int8x16_t vb = vld1q_s8(&B[i]);\n\n        int8x16_t pos_mask = vcltq_s8(va, vdupq_n_s8(0));\n        int8x16_t neg_mask = vcgtq_s8(va, vdupq_n_s8(0));\n\n        int8x16_t result = vmulq_s8(pos_mask, vb);\n        result = vsubq_s8(result, vmulq_s8(neg_mask, vb));\n        result = vaddq_s8(result, vnegq_s8(vandq_s8(pos_mask, neg_mask)));\n\n        vst1q_s8(&C[i], result);\n    }\n\n    for (; i < length; ++i) {\n        if (A[i] > 0 && B[i] > 0) {\n            C[i] = 1;\n        } else if (A[i] < 0 && B[i] < 0) {\n            C[i] = -1;\n        } else {\n            C[i] = 0;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_43_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nvoid tensor_three_valued_logic_simd(const int8_t* A, const int8_t* B, int8_t* C, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 16; i += 16) {\n        int8x16_t va = vld1q_s8(A + i);\n        int8x16_t vb = vld1q_s8(B + i);\n        int8x16_t vc = vmovq_n_s8(0);\n\n        int8x16_t va_pos = vcltq_s8(va, vdupq_n_s8(0));\n        int8x16_t vb_pos = vcltq_s8(vb, vdupq_n_s8(0));\n\n        int8x16_t va_neg = vnegq_s8(va_pos);\n        int8x16_t vb_neg = vnegq_s8(vb_pos);\n\n        int8x16_t pos_mask = vandq_s8(va_pos, vb_pos);\n        int8x16_t neg_mask = vandq_s8(va_neg, vb_neg);\n\n        vc = vorrq_s8(vc, vreinterpretq_s8_u8(pos_mask));\n        vc = vorrq_s8(vc, vreinterpretq_s8_u8(neg_mask));\n\n        vst1q_s8(C + i, vc);\n    }\n\n    for (; i < length; ++i) {\n        if (A[i] > 0 && B[i] > 0) {\n            C[i] = 1;\n        } else if (A[i] < 0 && B[i] < 0) {\n            C[i] = -1;\n        } else {\n            C[i] = 0;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_43_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nvoid tensor_three_valued_logic_simd(const int8_t* A, const int8_t* B, int8_t* C, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 16; i += 16) {\n        int8x16_t va = vld1q_s8(A + i);\n        int8x16_t vb = vld1q_s8(B + i);\n        int8x16_t vc = vmulq_s8(va, vb);\n        int8x16_t mask_pos = vcltq_s8(vc, vdupq_n_s8(0));\n        int8x16_t mask_neg = vcltq_s8(vnegq_s8(va), vnegq_s8(vb));\n        int8x16_t result = vbslq_s8(mask_pos, vdupq_n_s8(1), vbslq_s8(mask_neg, vdupq_n_s8(-1), vdupq_n_s8(0)));\n        vst1q_s8(C + i, result);\n    }\n    for (; i < length; ++i) {\n        if (A[i] > 0 && B[i] > 0) {\n            C[i] = 1;\n        } else if (A[i] < 0 && B[i] < 0) {\n            C[i] = -1;\n        } else {\n            C[i] = 0;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_43_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nvoid tensor_three_valued_logic_simd(const int8_t* A, const int8_t* B, int8_t* C, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 16; i += 16) {\n        int8x16_t va = vld1q_s8(A + i);\n        int8x16_t vb = vld1q_s8(B + i);\n        int8x16_t vc = vmovq_n_s8(0);\n\n        uint8x16_t mask_pos = vreinterpretq_u8_s8(vcltq_s8(va, vdupq_n_s8(0)));\n        uint8x16_t mask_neg = vreinterpretq_u8_s8(vcltq_s8(vnegq_s8(va), vdupq_n_s8(0)));\n\n        uint8x16_t mask_a_pos_b_pos = vandq_u8(mask_pos, vreinterpretq_u8_s8(vcltq_s8(vb, vdupq_n_s8(0))));\n        uint8x16_t mask_a_neg_b_neg = vandq_u8(mask_neg, vreinterpretq_u8_s8(vcltq_s8(vnegq_s8(vb), vdupq_n_s8(0))));\n\n        vc = vorrq_s8(vc, vreinterpretq_s8_s32(vmovl_s8(vreinterpretq_s8_u8(mask_a_pos_b_pos))));\n        vc = vorrq_s8(vc, vreinterpretq_s8_s32(vshll_n_s16(vreinterpretq_s16_s8(mask_a_neg_b_neg), 7)));\n\n        vst1q_s8(C + i, vc);\n    }\n\n    for (; i < length; ++i) {\n        if (A[i] > 0 && B[i] > 0) {\n            C[i] = 1;\n        } else if (A[i] < 0 && B[i] < 0) {\n            C[i] = -1;\n        } else {\n            C[i] = 0;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_43_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nvoid tensor_three_valued_logic_simd(const int8_t* A, const int8_t* B, int8_t* C, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 16; i += 16) {\n        int8x16_t va = vld1q_s8(A + i);\n        int8x16_t vb = vld1q_s8(B + i);\n        int8x16_t vc = vmovq_n_s8(0);\n\n        int8x16_t mask_pos = vandq_s8(va, vb);\n        int8x16_t mask_neg = vorrq_s8(vnegq_s8(va), vnegq_s8(vb));\n\n        vc = vbslq_s8(mask_pos, vmovq_n_s8(1), vc);\n        vc = vbslq_s8(mask_neg, vmovq_n_s8(-1), vc);\n\n        vst1q_s8(C + i, vc);\n    }\n\n    for (; i < length; ++i) {\n        if (A[i] > 0 && B[i] > 0) {\n            C[i] = 1;\n        } else if (A[i] < 0 && B[i] < 0) {\n            C[i] = -1;\n        } else {\n            C[i] = 0;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_44_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid tensor_bit_op_simd(const uint16_t* A, const uint16_t* B, uint16_t* C, size_t length) {\n    size_t i = 0;\n    size_t mid_point = length / 2;\n\n    // Process elements before the midpoint\n    for (; i < mid_point; i += 8) {\n        uint16x8_t vA = vld1q_u16(A + i);\n        uint16x8_t vB = vld1q_u16(B + i);\n\n        uint16x8_t vXOR = veorq_u16(vA, vB);\n        uint16x8_t vAND = vandq_u16(vA, vB);\n\n        vst1q_u16(C + i, vXOR);\n        vst1q_u16(C + i + 4, vAND);\n    }\n\n    // Handle remaining elements before the midpoint if length is odd\n    for (; i < mid_point; ++i) {\n        C[i] = A[i] ^ B[i];\n    }\n\n    // Keep the value in A for the element exactly at the midpoint\n    if (length % 2 != 0) {\n        C[mid_point] = A[mid_point];\n    }\n}\n```"}
{"task_id": "SimdBench_44_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid tensor_bit_op_simd(const uint16_t* A, const uint16_t* B, uint16_t* C, size_t length) {\n    size_t i = 0;\n    size_t mid_point = length / 2;\n\n    // Process elements before the midpoint\n    for (; i < mid_point; i += 8) {\n        uint16x8_t va = vld1q_u16(&A[i]);\n        uint16x8_t vb = vld1q_u16(&B[i]);\n\n        uint16x8_t xor_result = veorq_u16(va, vb);\n        uint16x8_t and_result = vandq_u16(va, vb);\n\n        vst1q_u16(&C[i], xor_result);\n        vst1q_u16(&C[i + 4], and_result);\n    }\n\n    // Handle the midpoint if it exists\n    if (length % 2 != 0) {\n        C[mid_point] = A[mid_point];\n    }\n}\n```"}
{"task_id": "SimdBench_44_Neon", "completion": "```cpp\nvoid tensor_bit_op_simd(const uint16_t* A, const uint16_t* B, uint16_t* C, size_t length) {\n    size_t i = 0;\n    size_t midpoint = length / 2;\n\n    // Process elements before the midpoint\n    for (; i < midpoint; ++i) {\n        uint16x8_t vA = vld1q_u16(&A[i]);\n        uint16x8_t vB = vld1q_u16(&B[i]);\n\n        uint16x8_t vXOR = veorq_u16(vA, vB);\n        uint16x8_t vAND = vandq_u16(vA, vB);\n\n        vst1q_u16(&C[i], vXOR);\n        vst1q_u16(&C[i + 8], vAND);\n    }\n\n    // Keep the value in A for the element exactly at the midpoint\n    if (length % 2 != 0) {\n        C[midpoint] = A[midpoint];\n    }\n}\n```"}
{"task_id": "SimdBench_44_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid tensor_bit_op_simd(const uint16_t* A, const uint16_t* B, uint16_t* C, size_t length) {\n    size_t i = 0;\n    size_t mid = length / 2;\n\n    // Process elements before the midpoint\n    for (; i < mid; i += 8) {\n        uint16x8_t va = vld1q_u16(&A[i]);\n        uint16x8_t vb = vld1q_u16(&B[i]);\n\n        uint16x8_t xor_result = veorq_u16(va, vb);\n        uint16x8_t and_result = vandq_u16(va, vb);\n\n        vst1q_u16(&C[i], xor_result);\n        vst1q_u16(&C[i + 4], and_result);\n    }\n\n    // Handle the midpoint element if length is odd\n    if (length % 2 != 0) {\n        C[mid] = A[mid];\n    }\n}\n```"}
{"task_id": "SimdBench_44_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid tensor_bit_op_simd(const uint16_t* A, const uint16_t* B, uint16_t* C, size_t length) {\n    size_t i = 0;\n    size_t midpoint = length / 2;\n\n    // Process elements before the midpoint\n    for (; i < midpoint; i += 8) {\n        uint16x8_t vA = vld1q_u16(&A[i]);\n        uint16x8_t vB = vld1q_u16(&B[i]);\n\n        uint16x8_t vXOR = veorq_u16(vA, vB);\n        uint16x8_t vAND = vbicq_u16(vA, vB);\n\n        uint16x8_t mask = vdupq_n_u16(0xFFFF);\n        uint16x8_t vResult = vorrq_u16(vAND, vXOR);\n\n        vst1q_u16(&C[i], vResult);\n    }\n\n    // Handle the midpoint element if it exists\n    if (length % 2 != 0) {\n        C[midpoint] = A[midpoint];\n    }\n}\n```"}
{"task_id": "SimdBench_45_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nvoid tensor_multi_select_simd(const float* A, const float* B, const float* C, const float* D, const bool* cond1, const bool* cond2, float* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t i = 0;\n    for (; i <= dim1 - 4; i += 4) {\n        uint32x4_t v_cond1 = vld1q_u32((const uint32_t*)(cond1 + i * dim2 * dim3));\n        uint32x4_t v_cond2 = vld1q_u32((const uint32_t*)(cond2 + i * dim2 * dim3));\n\n        float32x4_t v_A = vld1q_f32(A + i * dim2 * dim3);\n        float32x4_t v_B = vld1q_f32(B + i * dim2 * dim3);\n        float32x4_t v_C = vld1q_f32(C + i * dim2 * dim3);\n        float32x4_t v_D = vld1q_f32(D + i * dim2 * dim3);\n\n        uint32x4_t v_mask1 = vmovq_n_u32(0xFFFFFFFF);\n        uint32x4_t v_mask2 = vmovq_n_u32(0x00000000);\n\n        v_mask1 = vbicq_u32(v_mask1, vreinterpretq_u32_s32(vmovq_s32(vreinterpretq_s32_u32(v_cond2))));\n        v_mask2 = vbicq_u32(v_mask2, vreinterpretq_u32_s32(vmovq_s32(vreinterpretq_s32_u32(v_cond1))));\n\n        float32x4_t v_out = vorrq_f32(vandq_f32(v_A, v_mask1), vorrq_f32(vandq_f32(v_B, v_mask2), vorrq_f32(vandq_f32(v_C, vbicq_u32(v_mask1, v_mask2)), vandq_f32(v_D, vbicq_u32(v_mask2, v_mask1)))));\n\n        vst1q_f32(out + i * dim2 * dim3, v_out);\n    }\n\n    for (; i < dim1; ++i) {\n        for (size_t j = 0; j < dim2; ++j) {\n            for (size_t k = 0; k < dim3; ++k) {\n                if (cond1[i * dim2 * dim3 + j * dim3 + k] && cond2[i * dim2 * dim3 + j * dim3 + k]) {\n                    out[i * dim2 * dim3 + j * dim3 + k] = A[i * dim2 * dim3 + j * dim3 + k];\n                } else if (cond1[i * dim2 * dim3 + j * dim3 + k] && !cond2[i * dim2 * dim3 + j * dim3 + k]) {\n                    out[i * dim2 * dim3 + j * dim3 + k] = B[i * dim2 * dim3 + j * dim3 + k];\n                } else if (!cond1[i * dim2 * dim3 + j * dim3 + k] && cond2[i * dim2 * dim3 + j * dim3 + k]) {\n                    out[i * dim2 * dim3 + j * dim3 + k] = C[i * dim2 * dim3 + j * dim3 + k];\n                } else {\n                    out[i * dim2 * dim3 + j * dim3 + k] = D[i * dim2 * dim3 + j * dim3 + k];\n                }\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_45_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nvoid tensor_multi_select_simd(const float* A, const float* B, const float* C, const float* D, const bool* cond1, const bool* cond2, float* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t i = 0;\n    for (; i <= dim1 - 4; i += 4) {\n        uint32x4_t v_cond1 = vld1q_u32((const uint32_t*)(cond1 + i * dim2 * dim3));\n        uint32x4_t v_cond2 = vld1q_u32((const uint32_t*)(cond2 + i * dim2 * dim3));\n\n        float32x4_t v_A = vld1q_f32(A + i * dim2 * dim3);\n        float32x4_t v_B = vld1q_f32(B + i * dim2 * dim3);\n        float32x4_t v_C = vld1q_f32(C + i * dim2 * dim3);\n        float32x4_t v_D = vld1q_f32(D + i * dim2 * dim3);\n\n        uint32x4_t v_mask1 = vmovq_n_u32(0xFFFFFFFF);\n        uint32x4_t v_mask2 = vmovq_n_u32(0x00000000);\n\n        v_mask1 = vbicq_u32(v_mask1, vreinterpretq_u32_s32(vmovq_s32(vreinterpretq_s32_u32(v_cond2))));\n        v_mask2 = vbicq_u32(v_mask2, vreinterpretq_u32_s32(vmovq_s32(vreinterpretq_s32_u32(v_cond1))));\n\n        float32x4_t v_out = vorrq_f32(vandq_f32(v_A, v_mask1), vorrq_f32(vandq_f32(v_B, v_mask2), vorrq_f32(vandq_f32(v_C, v_negq_u32(v_mask1)), vandq_f32(v_D, v_negq_u32(v_mask2)))));\n\n        vst1q_f32(out + i * dim2 * dim3, v_out);\n    }\n\n    // Handle remaining elements\n    for (; i < dim1; ++i) {\n        for (size_t j = 0; j < dim2; ++j) {\n            for (size_t k = 0; k < dim3; ++k) {\n                if (cond1[i * dim2 * dim3 + j * dim3 + k] && cond2[i * dim2 * dim3 + j * dim3 + k]) {\n                    out[i * dim2 * dim3 + j * dim3 + k] = A[i * dim2 * dim3 + j * dim3 + k];\n                } else if (cond1[i * dim2 * dim3 + j * dim3 + k] && !cond2[i * dim2 * dim3 + j * dim3 + k]) {\n                    out[i * dim2 * dim3 + j * dim3 + k] = B[i * dim2 * dim3 + j * dim3 + k];\n                } else if (!cond1[i * dim2 * dim3 + j * dim3 + k] && cond2[i * dim2 * dim3 + j * dim3 + k]) {\n                    out[i * dim2 * dim3 + j * dim3 + k] = C[i * dim2 * dim3 + j * dim3 + k];\n                } else {\n                    out[i * dim2 * dim3 + j * dim3 + k] = D[i * dim2 * dim3 + j * dim3 + k];\n                }\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_45_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nvoid tensor_multi_select_simd(const float* A, const float* B, const float* C, const float* D, const bool* cond1, const bool* cond2, float* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t i = 0;\n    for (; i <= dim1 - 4; i += 4) {\n        uint32x4_t v_cond1 = vld1q_u32((const uint32_t*)(cond1 + i * dim2 * dim3));\n        uint32x4_t v_cond2 = vld1q_u32((const uint32_t*)(cond2 + i * dim2 * dim3));\n\n        float32x4_t v_A = vld1q_f32(A + i * dim2 * dim3);\n        float32x4_t v_B = vld1q_f32(B + i * dim2 * dim3);\n        float32x4_t v_C = vld1q_f32(C + i * dim2 * dim3);\n        float32x4_t v_D = vld1q_f32(D + i * dim2 * dim3);\n\n        uint32x4_t v_mask1 = vmovq_n_u32(0xFFFFFFFF);\n        uint32x4_t v_mask2 = vmovq_n_u32(0x00000000);\n\n        v_mask1 = vbicq_u32(v_mask1, vreinterpretq_u32_s32(vmovq_s32(vreinterpretq_s32_u32(v_cond2))));\n        v_mask2 = vbicq_u32(v_mask2, vreinterpretq_u32_s32(vmovq_s32(vreinterpretq_s32_u32(v_cond1))));\n\n        float32x4_t v_out = vorrq_f32(vandq_f32(v_A, v_mask1), vorrq_f32(vandq_f32(v_B, v_mask2), vorrq_f32(vandq_f32(v_C, v_negq_u32(v_mask1)), vandq_f32(v_D, v_negq_u32(v_mask2)))));\n\n        vst1q_f32(out + i * dim2 * dim3, v_out);\n    }\n\n    // Handle remaining elements\n    for (; i < dim1; ++i) {\n        for (size_t j = 0; j < dim2; ++j) {\n            for (size_t k = 0; k < dim3; ++k) {\n                if (cond1[i * dim2 * dim3 + j * dim3 + k] && cond2[i * dim2 * dim3 + j * dim3 + k]) {\n                    out[i * dim2 * dim3 + j * dim3 + k] = A[i * dim2 * dim3 + j * dim3 + k];\n                } else if (cond1[i * dim2 * dim3 + j * dim3 + k] && !cond2[i * dim2 * dim3 + j * dim3 + k]) {\n                    out[i * dim2 * dim3 + j * dim3 + k] = B[i * dim2 * dim3 + j * dim3 + k];\n                } else if (!cond1[i * dim2 * dim3 + j * dim3 + k] && cond2[i * dim2 * dim3 + j * dim3 + k]) {\n                    out[i * dim2 * dim3 + j * dim3 + k] = C[i * dim2 * dim3 + j * dim3 + k];\n                } else {\n                    out[i * dim2 * dim3 + j * dim3 + k] = D[i * dim2 * dim3 + j * dim3 + k];\n                }\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_45_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nvoid tensor_multi_select_simd(const float* A, const float* B, const float* C, const float* D, const bool* cond1, const bool* cond2, float* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t i = 0;\n    for (; i <= dim1 - 4; i += 4) {\n        uint32x4_t v_cond1 = vld1q_u32((const uint32_t*)(cond1 + i * dim2 * dim3));\n        uint32x4_t v_cond2 = vld1q_u32((const uint32_t*)(cond2 + i * dim2 * dim3));\n\n        float32x4_t v_A = vld1q_f32(A + i * dim2 * dim3);\n        float32x4_t v_B = vld1q_f32(B + i * dim2 * dim3);\n        float32x4_t v_C = vld1q_f32(C + i * dim2 * dim3);\n        float32x4_t v_D = vld1q_f32(D + i * dim2 * dim3);\n\n        uint32x4_t v_mask1 = vmovq_n_u32(0xFFFFFFFF);\n        uint32x4_t v_mask2 = vmovq_n_u32(0x00000000);\n\n        v_mask1 = vbicq_u32(v_mask1, vreinterpretq_u32_s32(vmovq_n_s32(-vget_lane_s32(vreinterpretq_s32_u32(v_cond2), 0))));\n        v_mask2 = vbicq_u32(v_mask2, vreinterpretq_u32_s32(vmovq_n_s32(-vget_lane_s32(vreinterpretq_s32_u32(v_cond1), 0))));\n\n        v_A = vbslq_f32(vandq_u32(v_mask1, v_mask2), v_A, v_B);\n        v_C = vbslq_f32(vandq_u32(vbicq_u32(v_mask1, v_mask2), v_mask2), v_C, v_D);\n\n        vst1q_f32(out + i * dim2 * dim3, v_A);\n        vst1q_f32(out + i * dim2 * dim3 + dim2 * dim3, v_C);\n    }\n\n    // Handle remaining elements\n    for (; i < dim1; ++i) {\n        for (size_t j = 0; j < dim2; ++j) {\n            for (size_t k = 0; k < dim3; ++k) {\n                if (cond1[i * dim2 * dim3 + j * dim3 + k] && cond2[i * dim2 * dim3 + j * dim3 + k]) {\n                    out[i * dim2 * dim3 + j * dim3 + k] = A[i * dim2 * dim3 + j * dim3 + k];\n                } else if (cond1[i * dim2 * dim3 + j * dim3 + k] && !cond2[i * dim2 * dim3 + j * dim3 + k]) {\n                    out[i * dim2 * dim3 + j * dim3 + k] = B[i * dim2 * dim3 + j * dim3 + k];\n                } else if (!cond1[i * dim2 * dim3 + j * dim3 + k] && cond2[i * dim2 * dim3 + j * dim3 + k]) {\n                    out[i * dim2 * dim3 + j * dim3 + k] = C[i * dim2 * dim3 + j * dim3 + k];\n                } else {\n                    out[i * dim2 * dim3 + j * dim3 + k] = D[i * dim2 * dim3 + j * dim3 + k];\n                }\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_45_Neon", "completion": "```cpp\nvoid tensor_multi_select_simd(const float* A, const float* B, const float* C, const float* D, const bool* cond1, const bool* cond2, float* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t elements_per_iteration = 4; // Process 4 elements at a time\n\n    for (size_t i = 0; i < total_elements; i += elements_per_iteration) {\n        float32x4_t va = vld1q_f32(A + i);\n        float32x4_t vb = vld1q_f32(B + i);\n        float32x4_t vc = vld1q_f32(C + i);\n        float32x4_t vd = vld1q_f32(D + i);\n\n        uint8x16_t vcond1 = vreinterpretq_u8_u32(vld1q_u32((const uint32_t*)(cond1 + i)));\n        uint8x16_t vcond2 = vreinterpretq_u8_u32(vld1q_u32((const uint32_t*)(cond2 + i)));\n\n        uint8x16_t vcond1_and_vcond2 = vandq_u8(vcond1, vcond2);\n        uint8x16_t vcond1_not_vcond2 = vorrq_u8(vandq_u8(vcond1, vmvnq_u8(vcond2)), vmvnq_u8(vcond1));\n        uint8x16_t vcond2_not_vcond1 = vorrq_u8(vandq_u8(vmvnq_u8(vcond1), vcond2), vmvnq_u8(vcond2));\n\n        uint8x16_t vselect_mask = vorrq_u8(vorrq_u8(vcond1_and_vcond2, vcond1_not_vcond2), vcond2_not_vcond1);\n\n        float32x4_t vout = vbslq_f32(vreinterpretq_u32_u8(vselect_mask), va, vb);\n        vout = vbslq_f32(vreinterpretq_u32_u8(vshrq_n_u8(vselect_mask, 1)), vout, vc);\n        vout = vbslq_f32(vreinterpretq_u32_u8(vshrq_n_u8(vselect_mask, 2)), vout, vd);\n\n        vst1q_f32(out + i, vout);\n    }\n}\n```"}
{"task_id": "SimdBench_46_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nvoid tensor_bit_count_simd(const uint32_t* A, uint8_t* out, size_t dim1, size_t dim2, size_t dim3) {\n    const int neon_width = 16;\n    for (size_t i = 0; i < dim1 * dim2; ++i) {\n        const uint32x4_t vec = vld1q_u32(A + i * dim3);\n        uint32x4_t count = vdupq_n_u32(0);\n\n        for (int j = 0; j < dim3 / neon_width; ++j) {\n            uint32x4_t temp = vec;\n            temp = vaddq_u32(temp, vshrq_n_u32(temp, 1));\n            temp = vaddq_u32(temp, vshrq_n_u32(temp, 2));\n            temp = vaddq_u32(temp, vshrq_n_u32(temp, 4));\n            temp = vaddq_u32(temp, vshrq_n_u32(temp, 8));\n            temp = vaddq_u32(temp, vshrq_n_u32(temp, 16));\n            count = vaddq_u32(count, temp);\n        }\n\n        uint32_t sum[4];\n        vst1q_u32(sum, count);\n\n        for (int k = 0; k < neon_width; ++k) {\n            out[i * dim3 + k] = static_cast<uint8_t>(sum[k]);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_46_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nvoid tensor_bit_count_simd(const uint32_t* A, uint8_t* out, size_t dim1, size_t dim2, size_t dim3) {\n    const int neon_width = 16;\n    for (size_t i = 0; i < dim1 * dim2; ++i) {\n        const uint32_t* a_ptr = A + i * dim3;\n        uint8_t* out_ptr = out + i * dim3;\n\n        for (size_t j = 0; j < dim3 / neon_width; ++j) {\n            uint32x4_t v0 = vld1q_u32(a_ptr + j * neon_width * 0);\n            uint32x4_t v1 = vld1q_u32(a_ptr + j * neon_width * 1);\n            uint32x4_t v2 = vld1q_u32(a_ptr + j * neon_width * 2);\n            uint32x4_t v3 = vld1q_u32(a_ptr + j * neon_width * 3);\n\n            uint32x4_t c0 = vcntq_u32(v0);\n            uint32x4_t c1 = vcntq_u32(v1);\n            uint32x4_t c2 = vcntq_u32(v2);\n            uint32x4_t c3 = vcntq_u32(v3);\n\n            uint32x4_t sum0 = vaddq_u32(c0, c1);\n            uint32x4_t sum1 = vaddq_u32(c2, c3);\n            uint32x4_t sum2 = vaddq_u32(sum0, sum1);\n\n            uint32_t total = vgetq_lane_u32(sum2, 0) + vgetq_lane_u32(sum2, 1) +\n                             vgetq_lane_u32(sum2, 2) + vgetq_lane_u32(sum2, 3);\n\n            out_ptr[j * neon_width] = static_cast<uint8_t>(total);\n        }\n\n        // Handle remaining elements that don't fit into a full Neon vector\n        for (size_t j = dim3 - dim3 % neon_width; j < dim3; ++j) {\n            uint32_t value = a_ptr[j];\n            uint32_t count = __builtin_popcount(value);\n            out_ptr[j] = static_cast<uint8_t>(count);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_46_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid tensor_bit_count_simd(const uint32_t* A, uint8_t* out, size_t dim1, size_t dim2, size_t dim3) {\n    const int neon_width = 16;\n    for (size_t i = 0; i < dim1 * dim2; ++i) {\n        uint32x4_t v = vld1q_u32(A + i * dim3);\n        uint32x4_t cnt = vcntq_u32(v);\n        uint32x4_t sum = vaddvq_u32(cnt);\n        vst1_u8(out + i * dim3, vreinterpret_u8_u32(sum));\n    }\n}\n```"}
{"task_id": "SimdBench_46_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nvoid tensor_bit_count_simd(const uint32_t* A, uint8_t* out, size_t dim1, size_t dim2, size_t dim3) {\n    const size_t simd_width = 16; // Number of elements processed per iteration\n    const size_t total_elements = dim1 * dim2 * dim3;\n    const size_t num_iterations = total_elements / simd_width;\n\n    for (size_t i = 0; i < num_iterations; ++i) {\n        uint32x4_t vA0 = vld1q_u32(A + i * simd_width);\n        uint32x4_t vA1 = vld1q_u32(A + i * simd_width + 4);\n        uint32x4_t vA2 = vld1q_u32(A + i * simd_width + 8);\n        uint32x4_t vA3 = vld1q_u32(A + i * simd_width + 12);\n\n        uint32x4_t vCount0 = vcntq_u32(vA0);\n        uint32x4_t vCount1 = vcntq_u32(vA1);\n        uint32x4_t vCount2 = vcntq_u32(vA2);\n        uint32x4_t vCount3 = vcntq_u32(vA3);\n\n        uint8x16_t vOut = vcombine_u8(\n            vmovn_u16(vreinterpretq_u16_u32(vCount0)),\n            vmovn_u16(vreinterpretq_u16_u32(vCount1)),\n            vmovn_u16(vreinterpretq_u16_u32(vCount2)),\n            vmovn_u16(vreinterpretq_u16_u32(vCount3))\n        );\n\n        vst1q_u8(out + i * simd_width, vOut);\n    }\n\n    // Handle remaining elements that do not fit into a full SIMD width\n    for (size_t i = num_iterations * simd_width; i < total_elements; ++i) {\n        uint32_t value = A[i];\n        uint8_t count = __builtin_popcount(value);\n        out[i] = count;\n    }\n}\n```"}
{"task_id": "SimdBench_46_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid tensor_bit_count_simd(const uint32_t* A, uint8_t* out, size_t dim1, size_t dim2, size_t dim3) {\n    const int neon_width = 16;\n    uint32x4_t vcount;\n    uint8x16_t vresult;\n\n    for (size_t i = 0; i < dim1 * dim2; ++i) {\n        vcount = vld1q_u32(A + i * dim3);\n\n        // Count bits in each 32-bit word\n        vcount = vcntq_u32(vcount);\n\n        // Sum up the counts from all words in the vector\n        uint32_t sum = vaddvq_u32(vcount);\n\n        // Store the result in the output array\n        vst1q_u8(out + i * dim3, vdupq_n_u8(sum));\n    }\n}\n```"}
{"task_id": "SimdBench_47_Neon", "completion": "```cpp\nvoid matrix_conditional_abs_simd(const int* A, int* B, size_t rows, size_t cols) {\n    const int* end = A + rows * cols;\n    while (A < end) {\n        int32x4_t vec_A = vld1q_s32(A);\n        int32x4_t vec_B = vec_A;\n        uint32x4_t mask = vandq_u32(vreinterpretq_u32_s32(vec_A), vmovq_n_u32(0x00000003));\n        mask = veorq_u32(mask, vmovq_n_u32(0xFFFFFFFF));\n        vec_B = vbslq_s32(mask, vabsq_s32(vec_A), vec_B);\n        vst1q_s32(B, vec_B);\n        A += 4;\n        B += 4;\n    }\n}\n```"}
{"task_id": "SimdBench_47_Neon", "completion": "```cpp\nvoid matrix_conditional_abs_simd(const int* A, int* B, size_t rows, size_t cols) {\n    const int* end = A + rows * cols;\n    while (A < end) {\n        int32x4_t vA = vld1q_s32(A);\n        int32x4_t vMod = vmulq_n_s32(vA, 3);\n        uint32x4_t vMask = vceqzq_s32(vMod);\n        int32x4_t vAbs = vabsq_s32(vA);\n        int32x4_t vResult = vbslq_s32(vMask, vAbs, vA);\n        vst1q_s32(B, vResult);\n        A += 4;\n        B += 4;\n    }\n}\n```"}
{"task_id": "SimdBench_47_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid matrix_conditional_abs_simd(const int* A, int* B, size_t rows, size_t cols) {\n    const int* end = A + rows * cols;\n    while (A < end) {\n        int32x4_t vec_A = vld1q_s32(A);\n        int32x4_t vec_mod = vmulq_n_s32(vec_A, 3);\n        uint32x4_t mask = vceqq_s32(vec_mod, vdupq_n_s32(0));\n        int32x4_t abs_vec = vabsq_s32(vec_A);\n        int32x4_t result = vbslq_s32(mask, abs_vec, vec_A);\n        vst1q_s32(B, result);\n        A += 4;\n        B += 4;\n    }\n}\n```"}
{"task_id": "SimdBench_47_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid matrix_conditional_abs_simd(const int* A, int* B, size_t rows, size_t cols) {\n    const int32x4_t vthree = vdupq_n_s32(3);\n    const int32x4_t vzro = vdupq_n_s32(0);\n\n    for (size_t i = 0; i < rows * cols; i += 4) {\n        int32x4_t va = vld1q_s32(&A[i]);\n        int32x4_t vb = va;\n\n        int32x4_t vmask = vandq_s32(va, vthree);\n        int32x4_t vcmp = vceqzq_s32(vmask);\n\n        vb = vbslq_s32(vcmp, vabsq_s32(va), vb);\n\n        vst1q_s32(&B[i], vb);\n    }\n}\n```"}
{"task_id": "SimdBench_47_Neon", "completion": "```cpp\nvoid matrix_conditional_abs_simd(const int* A, int* B, size_t rows, size_t cols) {\n    const int* end = A + rows * cols;\n    while (A < end) {\n        int32x4_t vec_A = vld1q_s32(A);\n        int32x4_t vec_B = vld1q_s32(B);\n\n        uint32x4_t mask = vandq_u32(vreinterpretq_u32_s32(vec_A), vmovq_n_u32(0x00000003));\n        uint32x4_t cond = vceqq_u32(mask, vmovq_n_u32(0));\n\n        int32x4_t abs_vec_A = vabsq_s32(vec_A);\n        int32x4_t result = vbslq_s32(cond, abs_vec_A, vec_A);\n\n        vst1q_s32(B, result);\n\n        A += 4;\n        B += 4;\n    }\n}\n```"}
{"task_id": "SimdBench_48_Neon", "completion": "```cpp\nvoid matrix_conditional_bit_rotate_simd(const uint32_t* src, uint32_t* dst, uint8_t rotate_bits, size_t length) {\n    const int32x4_t v_rotate_bits = vmovq_n_s32(rotate_bits);\n    const int32x4_t v_all_ones = vmovq_n_s32(0xFFFFFFFF);\n\n    for (size_t i = 0; i < length; i += 4) {\n        int32x4_t v_src = vld1q_u32(src + i);\n        int32x4_t v_mask = vandq_u32(v_src, v_all_ones);\n        int32x4_t v_condition = vceqq_u32(v_mask, v_all_ones);\n\n        int32x4_t v_rotated = vshlq_u32(v_src, v_rotate_bits);\n        int32x4_t v_negated = vbicq_u32(v_all_ones, v_src);\n\n        int32x4_t v_dst = vbslq_u32(v_condition, v_rotated, v_negated);\n        vst1q_u32(dst + i, v_dst);\n    }\n}\n```"}
{"task_id": "SimdBench_48_Neon", "completion": "```cpp\nvoid matrix_conditional_bit_rotate_simd(const uint32_t* src, uint32_t* dst, uint8_t rotate_bits, size_t length) {\n    const int32x4_t v_rotate_bits = vmovq_n_s32(rotate_bits);\n    const uint32x4_t v_all_ones = vmovq_n_u32(0xFFFFFFFF);\n\n    for (size_t i = 0; i < length; i += 4) {\n        uint32x4_t v_src = vld1q_u32(src + i);\n        uint32x4_t v_dst;\n\n        uint32x4_t v_low_4_bits = vandq_u32(v_src, vmovq_n_u32(0xF));\n        uint32x4_t v_condition = vceqq_u32(v_low_4_bits, v_all_ones);\n\n        uint32x4_t v_rotated = vshlq_u32(v_src, v_rotate_bits);\n        uint32x4_t v_negated = vbicq_u32(v_all_ones, v_src);\n\n        v_dst = vorrq_u32(v_rotated, vnegq_u32(v_condition, v_negated));\n\n        vst1q_u32(dst + i, v_dst);\n    }\n}\n```"}
{"task_id": "SimdBench_48_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid matrix_conditional_bit_rotate_simd(const uint32_t* src, uint32_t* dst, uint8_t rotate_bits, size_t length) {\n    const int32x4_t v_rotate_bits = vmovq_n_s32(rotate_bits);\n    const uint32x4_t v_all_ones = vmovq_n_u32(0xFFFFFFFF);\n\n    for (size_t i = 0; i < length; i += 4) {\n        uint32x4_t v_src = vld1q_u32(src + i);\n        uint32x4_t v_dst;\n\n        // Check if the low 4 bits of each element are all 1\n        uint32x4_t v_mask = veorq_u32(v_src, v_andq_u32(v_src, v_rshrq_n_u32(v_all_ones, 28)));\n        v_mask = veorq_u32(v_mask, v_andq_u32(v_mask, v_rshrq_n_u32(v_mask, 14)));\n        v_mask = veorq_u32(v_mask, v_andq_u32(v_mask, v_rshrq_n_u32(v_mask, 7)));\n\n        // Perform conditional rotation or bitwise negation\n        uint32x4_t v_rotated = vrorq_u32(v_src, v_rotate_bits);\n        uint32x4_t v_negated = vbicq_u32(v_all_ones, v_src);\n\n        v_dst = vorrq_u32(v_negated, vandq_u32(v_mask, v_rotated));\n\n        vst1q_u32(dst + i, v_dst);\n    }\n}\n```"}
{"task_id": "SimdBench_48_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid matrix_conditional_bit_rotate_simd(const uint32_t* src, uint32_t* dst, uint8_t rotate_bits, size_t length) {\n    const uint32x4_t v_rotate_bits = vmovq_n_u32(rotate_bits);\n    const uint32x4_t v_all_ones = vmovq_n_u32(0xFFFFFFFF);\n\n    for (size_t i = 0; i < length; i += 4) {\n        uint32x4_t v_src = vld1q_u32(&src[i]);\n        uint32x4_t v_dst;\n\n        // Check if the low 4 bits of each element are all 1\n        uint32x4_t v_mask = vandq_u32(v_src, vdupq_n_u32(0xF));\n        uint32x4_t v_condition = vceqq_u32(v_mask, vdupq_n_u32(0xF));\n\n        // Perform conditional rotation or bitwise negation\n        uint32x4_t v_rotated = vshlq_u32(v_src, v_rotate_bits);\n        uint32x4_t v_negated = vbicq_u32(v_all_ones, v_src);\n\n        v_dst = vorrq_u32(vbicq_u32(v_condition, v_negated), vbicq_u32(vmvnq_u32(v_condition), v_rotated));\n\n        vst1q_u32(&dst[i], v_dst);\n    }\n}\n```"}
{"task_id": "SimdBench_48_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid matrix_conditional_bit_rotate_simd(const uint32_t* src, uint32_t* dst, uint8_t rotate_bits, size_t length) {\n    const int32x4_t v_rotate_bits = vmovq_n_s32(rotate_bits);\n    const uint32x4_t v_all_ones = vmovq_n_u32(0xFFFFFFFF);\n\n    for (size_t i = 0; i < length; i += 4) {\n        uint32x4_t v_src = vld1q_u32(&src[i]);\n        uint32x4_t v_dst;\n\n        uint32x4_t v_low_4_bits = vandq_u32(v_src, vdupq_n_u32(0xF));\n        uint32x4_t v_condition = vceqq_u32(v_low_4_bits, v_all_ones);\n\n        uint32x4_t v_rotated = vshlq_u32(v_src, v_rotate_bits);\n        uint32x4_t v_negated = vbicq_u32(v_all_ones, v_src);\n\n        v_dst = vorrq_u32(vnegq_u32(v_condition), vorrq_u32(v_condition, v_rotated));\n\n        vst1q_u32(&dst[i], v_dst);\n    }\n}\n```"}
{"task_id": "SimdBench_49_Neon", "completion": "```cpp\nvoid tensor_ternary_compare_simd(const float* A, const float* B, int8_t* out, float epsilon, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 4; i += 4) {\n        float32x4_t va = vld1q_f32(&A[i]);\n        float32x4_t vb = vld1q_f32(&B[i]);\n        float32x4_t epsilon_vec = vmovq_n_f32(epsilon);\n        float32x4_t epsilon_abs = vabsq_f32(epsilon_vec);\n\n        float32x4_t diff = vsubq_f32(va, vb);\n        float32x4_t diff_abs = vabsq_f32(diff);\n\n        uint32x4_t gt_mask = vcgtq_f32(diff, epsilon_abs);\n        uint32x4_t lt_mask = vcltq_f32(diff, vnegq_f32(epsilon_abs));\n        uint32x4_t eq_mask = veor3q_u32(gt_mask, lt_mask);\n\n        int8x4_t result_gt = vreinterpretq_s8_u32(vmovl_u16(vreinterpret_u16_u32(gt_mask)));\n        int8x4_t result_lt = vreinterpretq_s8_u32(vmovl_u16(vreinterpret_u16_u32(lt_mask)));\n        int8x4_t result_eq = vreinterpretq_s8_u32(vmovl_u16(vreinterpret_u16_u32(eq_mask)));\n\n        int8x4_t result = vorrq_s8(result_gt, vorrq_s8(result_lt, result_eq));\n\n        vst1q_s8(&out[i], result);\n    }\n\n    // Handle remaining elements\n    for (; i < length; ++i) {\n        if (fabsf(A[i] - B[i]) > fabsf(epsilon)) {\n            out[i] = 1;\n        } else if (fabsf(A[i] - B[i]) < -fabsf(epsilon)) {\n            out[i] = -1;\n        } else {\n            out[i] = 0;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_49_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nvoid tensor_ternary_compare_simd(const float* A, const float* B, int8_t* out, float epsilon, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 4; i += 4) {\n        float32x4_t va = vld1q_f32(&A[i]);\n        float32x4_t vb = vld1q_f32(&B[i]);\n        float32x4_t vdiff = vsubq_f32(va, vb);\n        float32x4_t veps = vdupq_n_f32(epsilon);\n        uint32x4_t vcmp_gt = vcgtq_f32(vdiff, veps);\n        uint32x4_t vcmp_lt = vcltq_f32(vdiff, vnegq_f32(veps));\n        int8x4_t vresult = vreinterpretq_s8_u32(vbicq_u32(vbicq_u32(vmovq_n_u32(0xFF), vcmp_gt), vcmp_lt));\n        vst1q_s8(&out[i], vresult);\n    }\n    for (; i < length; ++i) {\n        if (A[i] - B[i] > epsilon) {\n            out[i] = 1;\n        } else if (A[i] - B[i] < -epsilon) {\n            out[i] = -1;\n        } else {\n            out[i] = 0;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_49_Neon", "completion": "```cpp\nvoid tensor_ternary_compare_simd(const float* A, const float* B, int8_t* out, float epsilon, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 4; i += 4) {\n        float32x4_t va = vld1q_f32(&A[i]);\n        float32x4_t vb = vld1q_f32(&B[i]);\n        float32x4_t vdiff = vsubq_f32(va, vb);\n        float32x4_t veps = vdupq_n_f32(fabsf(epsilon));\n        uint32x4_t vgt = vcgtq_f32(vdiff, veps);\n        uint32x4_t vlt = vcltq_f32(vdiff, vnegq_f32(veps));\n        int8x4_t vres = vreinterpretq_s8_u32(vorq_u32(vandq_u32(vgt, vmovq_n_u32(1)), vorq_u32(vandq_u32(vlt, vmovq_n_u32(-1)), vmovq_n_u32(0))));\n        vst1_s8(&out[i], vres);\n    }\n    for (; i < length; ++i) {\n        if (fabsf(A[i] - B[i]) > fabsf(epsilon)) {\n            out[i] = 1;\n        } else if (fabsf(A[i] - B[i]) < -fabsf(epsilon)) {\n            out[i] = -1;\n        } else {\n            out[i] = 0;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_49_Neon", "completion": "```cpp\nvoid tensor_ternary_compare_simd(const float* A, const float* B, int8_t* out, float epsilon, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 4; i += 4) {\n        float32x4_t va = vld1q_f32(&A[i]);\n        float32x4_t vb = vld1q_f32(&B[i]);\n        float32x4_t epsilon_vec = vmovq_n_f32(epsilon);\n        float32x4_t epsilon_abs = vabsq_f32(epsilon_vec);\n\n        float32x4_t diff = vsubq_f32(va, vb);\n        float32x4_t diff_abs = vabsq_f32(diff);\n\n        uint32x4_t gt_mask = vcgtq_f32(diff, epsilon_abs);\n        uint32x4_t lt_mask = vcltq_f32(diff, vnegq_f32(epsilon_abs));\n        uint32x4_t eq_mask = veor3q_u32(gt_mask, lt_mask);\n\n        int8x4_t result_gt = vreinterpretq_s8_u32(vmovl_u16(vshrn_n_u32(vreinterpretq_u32_u8(vdupq_n_u8(1)), 1)));\n        int8x4_t result_lt = vreinterpretq_s8_u32(vmovl_u16(vshrn_n_u32(vreinterpretq_u32_u8(vdupq_n_u8(-1)), 1)));\n        int8x4_t result_eq = vreinterpretq_s8_u32(vmovl_u16(vshrn_n_u32(vreinterpretq_u32_u8(vdupq_n_u8(0)), 1)));\n\n        int8x4_t result = vorrq_s8(vorrq_s8(result_gt, result_lt), result_eq);\n\n        vst1q_s8(&out[i], result);\n    }\n\n    for (; i < length; ++i) {\n        if (fabsf(A[i] - B[i]) > fabsf(epsilon)) {\n            out[i] = 1;\n        } else if (fabsf(A[i] - B[i]) < -fabsf(epsilon)) {\n            out[i] = -1;\n        } else {\n            out[i] = 0;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_49_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid tensor_ternary_compare_simd(const float* A, const float* B, int8_t* out, float epsilon, size_t length) {\n    float32x4_t v_epsilon = vdupq_n_f32(epsilon);\n    float32x4_t v_neg_epsilon = vnegq_f32(v_epsilon);\n\n    for (size_t i = 0; i < length; i += 4) {\n        float32x4_t va = vld1q_f32(&A[i]);\n        float32x4_t vb = vld1q_f32(&B[i]);\n\n        float32x4_t diff = vsubq_f32(va, vb);\n        uint32x4_t gt_mask = vcgtq_f32(diff, v_epsilon);\n        uint32x4_t lt_mask = vcltq_f32(diff, v_neg_epsilon);\n        uint32x4_t eq_mask = veorq_u32(gt_mask, lt_mask);\n\n        int8x4_t result = vreinterpretq_s8_u32(eq_mask);\n        result = vbslq_s8(lt_mask, vdupq_n_s8(-1), result);\n        result = vbslq_s8(gt_mask, vdupq_n_s8(1), result);\n\n        vst1q_s8(&out[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_50_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid float_to_int_saturate_simd(const float* A, int32_t* B, size_t size) {\n    const int32_t INT32_MAX = 0x7FFFFFFF;\n    const int32_t INT32_MIN = 0x80000000;\n\n    for (size_t i = 0; i <= size - 4; i += 4) {\n        float32x4_t vec_A = vld1q_f32(&A[i]);\n        int32x4_t vec_B = vcvtq_s32_f32(vec_A);\n\n        // Saturate values\n        int32x4_t max_mask = vcltq_s32(vec_B, vmovq_n_s32(INT32_MAX));\n        int32x4_t min_mask = vcgtq_s32(vec_B, vmovq_n_s32(INT32_MIN));\n\n        vec_B = vbslq_s32(max_mask, vmovq_n_s32(INT32_MAX), vec_B);\n        vec_B = vbslq_s32(min_mask, vmovq_n_s32(INT32_MIN), vec_B);\n\n        vst1q_s32(&B[i], vec_B);\n    }\n\n    // Handle remaining elements\n    for (size_t i = size - size % 4; i < size; ++i) {\n        B[i] = static_cast<int32_t>(A[i]);\n        if (B[i] > INT32_MAX) {\n            B[i] = INT32_MAX;\n        } else if (B[i] < INT32_MIN) {\n            B[i] = INT32_MIN;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_50_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid float_to_int_saturate_simd(const float* A, int32_t* B, size_t size) {\n    const int32_t INT32_MAX = 0x7FFFFFFF;\n    const int32_t INT32_MIN = 0x80000000;\n\n    for (size_t i = 0; i <= size - 4; i += 4) {\n        float32x4_t vec_A = vld1q_f32(&A[i]);\n        int32x4_t vec_B = vcvtq_s32_f32(vec_A);\n\n        // Saturate values\n        int32x4_t max_mask = vcltq_s32(vec_B, vmovq_n_s32(INT32_MAX));\n        int32x4_t min_mask = vcgtq_s32(vec_B, vmovq_n_s32(INT32_MIN));\n\n        vec_B = vbslq_s32(max_mask, vmovq_n_s32(INT32_MAX), vec_B);\n        vec_B = vbslq_s32(min_mask, vmovq_n_s32(INT32_MIN), vec_B);\n\n        vst1q_s32(&B[i], vec_B);\n    }\n\n    // Handle remaining elements\n    for (size_t i = size - size % 4; i < size; ++i) {\n        B[i] = (int32_t)(A[i]);\n        if (B[i] > INT32_MAX) {\n            B[i] = INT32_MAX;\n        } else if (B[i] < INT32_MIN) {\n            B[i] = INT32_MIN;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_50_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid float_to_int_saturate_simd(const float* A, int32_t* B, size_t size) {\n    const int32_t INT32_MAX = 0x7FFFFFFF;\n    const int32_t INT32_MIN = 0x80000000;\n\n    for (size_t i = 0; i <= size - 4; i += 4) {\n        float32x4_t vec_A = vld1q_f32(&A[i]);\n        int32x4_t vec_B = vcvtq_s32_f32(vec_A);\n\n        // Saturate values\n        int32x4_t max_mask = vcltq_s32(vec_B, vmovq_n_s32(INT32_MAX));\n        int32x4_t min_mask = vcgtq_s32(vec_B, vmovq_n_s32(INT32_MIN));\n\n        vec_B = vbslq_s32(max_mask, vmovq_n_s32(INT32_MAX), vec_B);\n        vec_B = vbslq_s32(min_mask, vmovq_n_s32(INT32_MIN), vec_B);\n\n        vst1q_s32(&B[i], vec_B);\n    }\n\n    // Handle remaining elements\n    for (size_t i = size - size % 4; i < size; ++i) {\n        B[i] = (int32_t)A[i];\n        if (B[i] > INT32_MAX) {\n            B[i] = INT32_MAX;\n        } else if (B[i] < INT32_MIN) {\n            B[i] = INT32_MIN;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_50_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid float_to_int_saturate_simd(const float* A, int32_t* B, size_t size) {\n    const int32_t INT32_MAX = 0x7FFFFFFF;\n    const int32_t INT32_MIN = 0x80000000;\n\n    for (size_t i = 0; i <= size - 4; i += 4) {\n        float32x4_t vec_A = vld1q_f32(&A[i]);\n        int32x4_t vec_B = vcvtq_s32_f32(vec_A);\n\n        // Saturate values\n        int32x4_t max_mask = vcltq_s32(vec_B, vmovq_n_s32(INT32_MAX));\n        int32x4_t min_mask = vcgtq_s32(vec_B, vmovq_n_s32(INT32_MIN));\n\n        vec_B = vbslq_s32(max_mask, vmovq_n_s32(INT32_MAX), vec_B);\n        vec_B = vbslq_s32(min_mask, vmovq_n_s32(INT32_MIN), vec_B);\n\n        vst1q_s32(&B[i], vec_B);\n    }\n\n    // Handle remaining elements\n    for (size_t i = size - size % 4; i < size; ++i) {\n        B[i] = (int32_t)A[i];\n        if (B[i] > INT32_MAX) {\n            B[i] = INT32_MAX;\n        } else if (B[i] < INT32_MIN) {\n            B[i] = INT32_MIN;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_50_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nvoid float_to_int_saturate_simd(const float* A, int32_t* B, size_t size) {\n    const int32_t INT32_MAX = 0x7FFFFFFF;\n    const int32_t INT32_MIN = 0x80000000;\n\n    size_t i = 0;\n    for (; i <= size - 4; i += 4) {\n        float32x4_t vecA = vld1q_f32(&A[i]);\n        int32x4_t vecB = vcvtq_s32_f32(vecA);\n\n        // Saturate values\n        int32x4_t max_mask = vcltq_s32(vecB, vmovq_n_s32(INT32_MAX));\n        int32x4_t min_mask = vcgtq_s32(vecB, vmovq_n_s32(INT32_MIN));\n\n        vecB = vbslq_s32(max_mask, vmovq_n_s32(INT32_MAX), vecB);\n        vecB = vbslq_s32(min_mask, vmovq_n_s32(INT32_MIN), vecB);\n\n        vst1q_s32(&B[i], vecB);\n    }\n\n    // Handle remaining elements\n    for (; i < size; ++i) {\n        B[i] = static_cast<int32_t>(A[i]);\n        if (B[i] > INT32_MAX) {\n            B[i] = INT32_MAX;\n        } else if (B[i] < INT32_MIN) {\n            B[i] = INT32_MIN;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_51_Neon", "completion": "```cpp\nvoid int_to_float_scaled_simd(const int32_t* A, int8_t scale, float* B, size_t size) {\n    const int32x4_t v_scale = vmovq_n_s32(scale);\n    for (size_t i = 0; i <= size - 4; i += 4) {\n        int32x4_t v_a = vld1q_s32(&A[i]);\n        float32x4_t v_b = vcvtq_f32_s32(v_a);\n        vst1q_f32(&B[i], vmulq_f32(v_b, v_scale));\n    }\n    for (size_t i = size - size % 4; i < size; ++i) {\n        B[i] = static_cast<float>(A[i]) * scale;\n    }\n}\n```"}
{"task_id": "SimdBench_51_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid int_to_float_scaled_simd(const int32_t* A, int8_t scale, float* B, size_t size) {\n    const int32x4_t v_scale = vmovq_n_s32(scale);\n    for (size_t i = 0; i <= size - 4; i += 4) {\n        int32x4_t v_a = vld1q_s32(&A[i]);\n        float32x4_t v_b = vcvtq_f32_s32(v_mulq_s32(v_a, v_scale));\n        vst1q_f32(&B[i], v_b);\n    }\n    // Handle remaining elements\n    for (size_t i = size - size % 4; i < size; ++i) {\n        B[i] = static_cast<float>(A[i]) * scale;\n    }\n}\n```"}
{"task_id": "SimdBench_51_Neon", "completion": "```cpp\nvoid int_to_float_scaled_simd(const int32_t* A, int8_t scale, float* B, size_t size) {\n    const int32x4_t v_scale = vmovq_n_s32(scale);\n    for (size_t i = 0; i <= size - 4; i += 4) {\n        int32x4_t v_a = vld1q_s32(&A[i]);\n        float32x4_t v_b = vcvtq_f32_s32(v_a);\n        vst1q_f32(&B[i], vmulq_f32(v_b, vdupq_n_f32(1.0f / 256.0f)));\n    }\n    for (size_t i = size - size % 4; i < size; ++i) {\n        B[i] = static_cast<float>(A[i]) * (1.0f / 256.0f);\n    }\n}\n```"}
{"task_id": "SimdBench_51_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid int_to_float_scaled_simd(const int32_t* A, int8_t scale, float* B, size_t size) {\n    const int32x4_t v_scale = vmovq_n_s32(scale);\n    for (size_t i = 0; i <= size - 4; i += 4) {\n        int32x4_t v_a = vld1q_s32(&A[i]);\n        float32x4_t v_b = vcvtq_f32_s32(v_mulq_s32(v_a, v_scale));\n        vst1q_f32(&B[i], v_b);\n    }\n    for (size_t i = size - size % 4; i < size; ++i) {\n        B[i] = static_cast<float>(A[i]) * scale;\n    }\n}\n```"}
{"task_id": "SimdBench_51_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid int_to_float_scaled_simd(const int32_t* A, int8_t scale, float* B, size_t size) {\n    const int32x4_t v_scale = vmovq_n_s32(scale);\n    for (size_t i = 0; i <= size - 4; i += 4) {\n        int32x4_t v_a = vld1q_s32(&A[i]);\n        float32x4_t v_b = vcvtq_f32_s32(v_mulq_s32(v_a, v_scale));\n        vst1q_f32(&B[i], v_b);\n    }\n    for (size_t i = size - size % 4; i < size; ++i) {\n        B[i] = static_cast<float>(A[i]) * scale;\n    }\n}\n```"}
{"task_id": "SimdBench_52_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid float_div_round_simd(const float* A, const float* B, int32_t* C, size_t size) {\n    size_t i = 0;\n    for (; i <= size - 4; i += 4) {\n        float32x4_t vec_A = vld1q_f32(&A[i]);\n        float32x4_t vec_B = vld1q_f32(&B[i]);\n        float32x4_t div_result = vdivq_f32(vec_A, vec_B);\n        int32x4_t rounded_result = vcvtq_s32_f32(div_result);\n        vst1q_s32(&C[i], rounded_result);\n    }\n    for (; i < size; ++i) {\n        C[i] = (int32_t)(A[i] / B[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_52_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nvoid float_div_round_simd(const float* A, const float* B, int32_t* C, size_t size) {\n    size_t i = 0;\n    for (; i <= size - 4; i += 4) {\n        float32x4_t va = vld1q_f32(&A[i]);\n        float32x4_t vb = vld1q_f32(&B[i]);\n        float32x4_t vc = vmulq_f32(va, vrecpeq_f32(vb));\n        vc = vmlaq_f32(vc, vb, vmulq_f32(vc, vb));\n        vc = vaddq_f32(vc, vdupq_n_f32(0.5f));\n        vc = vcvtq_s32_f32(vc);\n        vst1q_s32(&C[i], vc);\n    }\n    for (; i < size; ++i) {\n        C[i] = static_cast<int32_t>(round(A[i] / B[i]));\n    }\n}\n```"}
{"task_id": "SimdBench_52_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid float_div_round_simd(const float* A, const float* B, int32_t* C, size_t size) {\n    size_t i;\n    for (i = 0; i <= size - 4; i += 4) {\n        float32x4_t va = vld1q_f32(&A[i]);\n        float32x4_t vb = vld1q_f32(&B[i]);\n        float32x4_t vr = vdivq_f32(va, vb);\n        int32x4_t vc = vcvtq_s32_f32(vr);\n        vst1q_s32(&C[i], vc);\n    }\n    for (; i < size; ++i) {\n        C[i] = static_cast<int32_t>(round(A[i] / B[i]));\n    }\n}\n```"}
{"task_id": "SimdBench_52_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid float_div_round_simd(const float* A, const float* B, int32_t* C, size_t size) {\n    size_t i;\n    for (i = 0; i <= size - 4; i += 4) {\n        float32x4_t va = vld1q_f32(&A[i]);\n        float32x4_t vb = vld1q_f32(&B[i]);\n        float32x4_t vr = vdivq_f32(va, vb);\n        int32x4_t vc = vcvtmq_s32_f32(vr);\n        vst1q_s32(&C[i], vc);\n    }\n    for (; i < size; ++i) {\n        C[i] = static_cast<int32_t>(round(A[i] / B[i]));\n    }\n}\n```"}
{"task_id": "SimdBench_52_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nvoid float_div_round_simd(const float* A, const float* B, int32_t* C, size_t size) {\n    size_t i = 0;\n    for (; i <= size - 4; i += 4) {\n        float32x4_t vec_A = vld1q_f32(&A[i]);\n        float32x4_t vec_B = vld1q_f32(&B[i]);\n        float32x4_t vec_result = vmulq_f32(vec_A, vrecpeq_f32(vec_B));\n        vec_result = vfmaq_n_f32(vec_result, vec_B, vmulq_f32(vec_result, vec_B));\n        vec_result = vcvtaq_s32_f32(vec_result);\n        vst1q_s32(&C[i], vec_result);\n    }\n    for (; i < size; ++i) {\n        C[i] = static_cast<int32_t>(round(A[i] / B[i]));\n    }\n}\n```"}
{"task_id": "SimdBench_53_Neon", "completion": "```c\n#include <arm_neon.h>\n#include <limits.h>\n\n#define FLT_MAX 3.4028235e+38F\n\nvoid double_to_float_saturate_simd(const double* A, float* B, size_t size) {\n    const int64x2_t max_val = vdupq_n_s64(INT_MAX);\n    const int64x2_t min_val = vdupq_n_s64(INT_MIN);\n\n    for (size_t i = 0; i < size; i += 2) {\n        int64x2_t d = vreinterpretq_s64_f64(vld1q_f64(&A[i]));\n\n        int64x2_t saturated_d = vminq_s64(max_val, vmaxq_s64(min_val, d));\n\n        float32x2_t result = vmovn_f32(vreinterpretq_f32_s32(vmovl_s16(vreinterpret_s16_s8(vshrn_n_u8(vreinterpret_u8_s64(saturated_d), 32), 16))));\n        vst1q_f32(&B[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_53_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <cmath>\n\nvoid double_to_float_saturate_simd(const double* A, float* B, size_t size) {\n    const int vec_size = 4;\n    const float max_val = std::numeric_limits<float>::max();\n    const float min_val = -std::numeric_limits<float>::max();\n\n    for (size_t i = 0; i <= size - vec_size; i += vec_size) {\n        uint64x2_t vA1 = vld1q_u64((const uint64_t*)&A[i]);\n        uint64x2_t vA2 = vld1q_u64((const uint64_t*)&A[i + vec_size]);\n\n        float64x2_t vA1_f = vcvt_f64_u64(vA1);\n        float64x2_t vA2_f = vcvt_f64_u64(vA2);\n\n        float64x2_t vMax = vdupq_n_f64(max_val);\n        float64x2_t vMin = vdupq_n_f64(min_val);\n\n        float64x2_t vClamped1 = vmaxnmq_f64(vMin, vminnmq_f64(vMax, vA1_f));\n        float64x2_t vClamped2 = vmaxnmq_f64(vMin, vminnmq_f64(vMax, vA2_f));\n\n        uint32x2_t vClamped1_i = vcvt_u32_f64(vClamped1);\n        uint32x2_t vClamped2_i = vcvt_u32_f64(vClamped2);\n\n        vst1q_u32((uint32_t*)&B[i], vClamped1_i);\n        vst1q_u32((uint32_t*)&B[i + vec_size], vClamped2_i);\n    }\n\n    // Handle remaining elements\n    for (size_t i = size - size % vec_size; i < size; ++i) {\n        double val = A[i];\n        if (val > max_val) {\n            B[i] = max_val;\n        } else if (val < min_val) {\n            B[i] = min_val;\n        } else {\n            B[i] = static_cast<float>(val);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_53_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <cmath>\n\nvoid double_to_float_saturate_simd(const double* A, float* B, size_t size) {\n    const int vec_size = 4;\n    const float max_val = std::numeric_limits<float>::max();\n    const float min_val = -std::numeric_limits<float>::max();\n\n    for (size_t i = 0; i < size; i += vec_size) {\n        double2x2 dvec = vld1q_f64((const double*)(A + i));\n        float32x2 fvec = vmulq_f32(vreinterpretq_f32_f64(dvec), vdupq_n_f32(1.0f));\n\n        fvec = vmaxq_f32(fvec, vdupq_n_f32(min_val));\n        fvec = vminq_f32(fvec, vdupq_n_f32(max_val));\n\n        vst1q_f32((float32_t*)(B + i), fvec);\n    }\n}\n```"}
{"task_id": "SimdBench_53_Neon", "completion": "```c\n#include <arm_neon.h>\n#include <float.h>\n\nvoid double_to_float_saturate_simd(const double* A, float* B, size_t size) {\n    const int elements_per_iteration = 4;\n    const double max_double = DBL_MAX;\n    const double min_double = -DBL_MAX;\n\n    for (size_t i = 0; i < size; i += elements_per_iteration) {\n        double32x2_t vec_d1 = vld1q_f64(&A[i]);\n        double32x2_t vec_d2 = vld1q_f64(&A[i + 2]);\n\n        // Clamp values between -DBL_MAX and DBL_MAX\n        double32x2_t clamped_d1 = vmaxnmvq_f64(vminnmvq_f64(vec_d1, max_double), min_double);\n        double32x2_t clamped_d2 = vmaxnmvq_f64(vminnmvq_f64(vec_d2, max_double), min_double);\n\n        // Convert to float\n        float32x2_t vec_f1 = vcvt_f32_f64(clamped_d1);\n        float32x2_t vec_f2 = vcvt_f32_f64(clamped_d2);\n\n        // Store results\n        vst1q_f32(&B[i], vec_f1);\n        vst1q_f32(&B[i + 2], vec_f2);\n    }\n}\n```"}
{"task_id": "SimdBench_53_Neon", "completion": "```c\n#include <arm_neon.h>\n#include <limits.h>\n\n#define FLT_MAX 3.4028235e+38F\n\nvoid double_to_float_saturate_simd(const double* A, float* B, size_t size) {\n    const int elements_per_iteration = 4;\n    const size_t num_iterations = size / elements_per_iteration;\n\n    for (size_t i = 0; i < num_iterations; ++i) {\n        double64x2_t vec_d1 = vld1q_f64(A + i * elements_per_iteration);\n        double64x2_t vec_d2 = vld1q_f64(A + i * elements_per_iteration + 2);\n\n        uint64x2_t mask1 = vcgtq_f64(vec_d1, vmovq_n_f64(FLT_MAX));\n        uint64x2_t mask2 = vcltq_f64(vec_d1, vmovq_n_f64(-FLT_MAX));\n        uint64x2_t mask3 = vcgtq_f64(vec_d2, vmovq_n_f64(FLT_MAX));\n        uint64x2_t mask4 = vcltq_f64(vec_d2, vmovq_n_f64(-FLT_MAX));\n\n        float64x2_t vec_max1 = vmovq_n_f64(FLT_MAX);\n        float64x2_t vec_min1 = vmovq_n_f64(-FLT_MAX);\n        float64x2_t vec_max2 = vmovq_n_f64(FLT_MAX);\n        float64x2_t vec_min2 = vmovq_n_f64(-FLT_MAX);\n\n        vec_d1 = vbslq_f64(mask1, vec_max1, vec_d1);\n        vec_d1 = vbslq_f64(mask2, vec_min1, vec_d1);\n        vec_d2 = vbslq_f64(mask3, vec_max2, vec_d2);\n        vec_d2 = vbslq_f64(mask4, vec_min2, vec_d2);\n\n        float32x2_t vec_f1 = vcvt_f32_f64(vget_low_f64(vec_d1));\n        float32x2_t vec_f2 = vcvt_f32_f64(vget_high_f64(vec_d1));\n        float32x2_t vec_f3 = vcvt_f32_f64(vget_low_f64(vec_d2));\n        float32x2_t vec_f4 = vcvt_f32_f64(vget_high_f64(vec_d2));\n\n        vst1_f32(B + i * elements_per_iteration, vec_f1);\n        vst1_f32(B + i * elements_per_iteration + 2, vec_f2);\n        vst1_f32(B + i * elements_per_iteration + 4, vec_f3);\n        vst1_f32(B + i * elements_per_iteration + 6, vec_f4);\n    }\n\n    // Handle remaining elements\n    for (size_t i = num_iterations * elements_per_iteration; i < size; ++i) {\n        double d_val = A[i];\n        if (d_val > FLT_MAX) {\n            B[i] = FLT_MAX;\n        } else if (d_val < -FLT_MAX) {\n            B[i] = -FLT_MAX;\n        } else {\n            B[i] = (float)d_val;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_54_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid int16_to_int32_simd(const int16_t* A, int32_t* B, size_t size) {\n    size_t i = 0;\n    for (; i <= size - 8; i += 8) {\n        int16x8_t vA = vld1q_s16(&A[i]);\n        int32x4_t vB1 = vmovl_s16(vget_low_s16(vA));\n        int32x4_t vB2 = vmovl_high_s16(vA);\n        vst1q_s32(&B[i], vcombine_s32(vB1, vB2));\n    }\n    for (; i < size; ++i) {\n        B[i] = A[i];\n    }\n}\n```"}
{"task_id": "SimdBench_54_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid int16_to_int32_simd(const int16_t* A, int32_t* B, size_t size) {\n    size_t i = 0;\n    for (; i <= size - 4; i += 4) {\n        int16x4_t vA = vld1_s16(&A[i]);\n        int32x4_t vB = vmovl_s16(vA);\n        vst1q_s32(&B[i], vB);\n    }\n    for (; i < size; ++i) {\n        B[i] = A[i];\n    }\n}\n```"}
{"task_id": "SimdBench_54_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid int16_to_int32_simd(const int16_t* A, int32_t* B, size_t size) {\n    size_t i;\n    for (i = 0; i <= size - 8; i += 8) {\n        int16x8_t vA = vld1q_s16(&A[i]);\n        int32x4_t vB1 = vmovl_s16(vget_low_s16(vA));\n        int32x4_t vB2 = vmovl_high_s16(vA);\n        vst1q_s32(&B[i], vcombine_s32(vB1, vB2));\n    }\n    for (; i < size; ++i) {\n        B[i] = A[i];\n    }\n}\n```"}
{"task_id": "SimdBench_54_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nvoid int16_to_int32_simd(const int16_t* A, int32_t* B, size_t size) {\n    const int16_t* end = A + size;\n    while (A < end) {\n        int16x8_t vA = vld1q_s16(A);\n        int32x4_t vB = vmovl_s16(vA);\n        vst1q_s32(B, vB);\n        A += 8;\n        B += 4;\n    }\n}\n```"}
{"task_id": "SimdBench_54_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid int16_to_int32_simd(const int16_t* A, int32_t* B, size_t size) {\n    size_t i = 0;\n    for (; i <= size - 8; i += 8) {\n        int16x8_t vec_A = vld1q_s16(&A[i]);\n        int32x4_t vec_B_low = vmovl_s16(vget_low_s16(vec_A));\n        int32x4_t vec_B_high = vmovl_s16(vget_high_s16(vec_A));\n        vst1q_s32(&B[i], vec_B_low);\n        vst1q_s32(&B[i + 4], vec_B_high);\n    }\n    for (; i < size; ++i) {\n        B[i] = A[i];\n    }\n}\n```"}
{"task_id": "SimdBench_55_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nvoid conditional_normalize_simd(const float* A, const int32_t* control, float* B, size_t size, float min_val, float max_val) {\n    float32x4_t v_min_val = vdupq_n_f32(min_val);\n    float32x4_t v_max_val = vdupq_n_f32(max_val);\n    float32x4_t v_zero = vdupq_n_f32(0.0f);\n    float32x4_t v_one = vdupq_n_f32(1.0f);\n\n    size_t i = 0;\n    for (; i <= size - 4; i += 4) {\n        float32x4_t va = vld1q_f32(&A[i]);\n        int32x4_t vcontrol = vld1q_s32(&control[i]);\n\n        uint32x4_t vmask = vcgtq_s32(vcontrol, vdupq_n_s32(0));\n\n        float32x4_t vdiff = vsubq_f32(va, v_min_val);\n        float32x4_t vrange = vsubq_f32(v_max_val, v_min_val);\n        float32x4_t vn = vdivq_f32(vdiff, vrange);\n\n        vn = vmaxq_f32(vn, v_zero);\n        vn = vminq_f32(vn, v_one);\n\n        vn = vbslq_f32(vmask, vn, va);\n\n        vst1q_f32(&B[i], vn);\n    }\n\n    // Handle remaining elements\n    for (; i < size; ++i) {\n        if (control[i] > 0) {\n            float val = A[i];\n            val = (val - min_val) / (max_val - min_val);\n            val = std::max(val, 0.0f);\n            val = std::min(val, 1.0f);\n            B[i] = val;\n        } else {\n            B[i] = A[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_55_Neon", "completion": "```cpp\nvoid conditional_normalize_simd(const float* A, const int32_t* control, float* B, size_t size, float min_val, float max_val) {\n    const float32x4_t v_min_val = vdupq_n_f32(min_val);\n    const float32x4_t v_max_val = vdupq_n_f32(max_val);\n    const float32x4_t v_zero = vdupq_n_f32(0.0f);\n    const float32x4_t v_one = vdupq_n_f32(1.0f);\n\n    size_t i = 0;\n    for (; i <= size - 4; i += 4) {\n        float32x4_t va = vld1q_f32(A + i);\n        int32x4_t vctrl = vld1q_s32(control + i);\n\n        float32x4_t vcond = vcgtq_s32(vctrl, vdupq_n_s32(0));\n        float32x4_t vsub = vsubq_f32(va, v_min_val);\n        float32x4_t vdiv = vdivq_f32(vsub, v_subtract(v_max_val, v_min_val));\n\n        vdiv = vmaxq_f32(vminq_f32(vdiv, v_one), v_zero);\n\n        vst1q_f32(B + i, vcond ? vdiv : va);\n    }\n\n    // Handle remaining elements\n    for (; i < size; ++i) {\n        if (control[i] > 0) {\n            float val = A[i];\n            val = (val - min_val) / (max_val - min_val);\n            val = std::max(std::min(val, 1.0f), 0.0f);\n            B[i] = val;\n        } else {\n            B[i] = A[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_55_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nvoid conditional_normalize_simd(const float* A, const int32_t* control, float* B, size_t size, float min_val, float max_val) {\n    float32x4_t v_min_val = vdupq_n_f32(min_val);\n    float32x4_t v_max_val = vdupq_n_f32(max_val);\n    float32x4_t v_zero = vdupq_n_f32(0.0f);\n    float32x4_t v_one = vdupq_n_f32(1.0f);\n\n    size_t i = 0;\n    for (; i <= size - 4; i += 4) {\n        float32x4_t va = vld1q_f32(&A[i]);\n        int32x4_t vcontrol = vld1q_s32(&control[i]);\n\n        uint32x4_t vmask = vcgtq_s32(vcontrol, vdupq_n_s32(0));\n        float32x4_t vnzmask = vreinterpretq_f32_u32(vmovemaskq_u32(vmask));\n\n        float32x4_t vresult = va;\n\n        if (vnzmask != 0) {\n            vresult = vsubq_f32(va, v_min_val);\n            vresult = vdivq_f32(vresult, v_subq_f32(v_max_val, v_min_val));\n            vresult = vmaxq_f32(vzero, vresult);\n            vresult = vminq_f32(vone, vresult);\n        }\n\n        vst1q_f32(&B[i], vresult);\n    }\n\n    for (; i < size; ++i) {\n        if (control[i] > 0) {\n            float val = A[i];\n            val = (val - min_val) / (max_val - min_val);\n            val = std::max(val, 0.0f);\n            val = std::min(val, 1.0f);\n            B[i] = val;\n        } else {\n            B[i] = A[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_55_Neon", "completion": "```cpp\nvoid conditional_normalize_simd(const float* A, const int32_t* control, float* B, size_t size, float min_val, float max_val) {\n    float32x4_t v_min_val = vdupq_n_f32(min_val);\n    float32x4_t v_max_val = vdupq_n_f32(max_val);\n    float32x4_t v_zero = vdupq_n_f32(0.0f);\n    float32x4_t v_one = vdupq_n_f32(1.0f);\n\n    for (size_t i = 0; i <= size - 4; i += 4) {\n        float32x4_t va = vld1q_f32(&A[i]);\n        int32x4_t vcontrol = vld1q_s32(&control[i]);\n\n        uint32x4_t vmask = vcgtq_s32(vcontrol, vdupq_n_s32(0));\n\n        float32x4_t vdiff = vsubq_f32(va, v_min_val);\n        float32x4_t vrange = vsubq_f32(v_max_val, v_min_val);\n        float32x4_t vnorm = vdivq_f32(vdiff, vrange);\n\n        vnorm = vmaxq_f32(vnorm, v_zero);\n        vnorm = vminq_f32(vnorm, v_one);\n\n        vst1q_f32(&B[i], vmask ? vnorm : va);\n    }\n\n    // Handle remaining elements\n    for (size_t i = size - size % 4; i < size; ++i) {\n        if (control[i] > 0) {\n            float val = A[i];\n            val = (val - min_val) / (max_val - min_val);\n            val = std::max(val, 0.0f);\n            val = std::min(val, 1.0f);\n            B[i] = val;\n        } else {\n            B[i] = A[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_55_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nvoid conditional_normalize_simd(const float* A, const int32_t* control, float* B, size_t size, float min_val, float max_val) {\n    const float32x4_t v_min_val = vdupq_n_f32(min_val);\n    const float32x4_t v_max_val = vdupq_n_f32(max_val);\n    const float32x4_t v_zero = vdupq_n_f32(0.0f);\n    const float32x4_t v_one = vdupq_n_f32(1.0f);\n\n    size_t i = 0;\n    for (; i <= size - 4; i += 4) {\n        float32x4_t va = vld1q_f32(A + i);\n        int32x4_t vcontrol = vld1q_s32(control + i);\n\n        uint32x4_t vmask = vcgtq_s32(vcontrol, vdupq_n_s32(0));\n        float32x4_t vn = vminq_f32(vdivq_f32(va, vsubq_f32(v_max_val, v_min_val)), v_one);\n        vn = vmaxq_f32(vn, v_zero);\n\n        uint32x4_t vcopy_mask = vmvnq_u32(vmask);\n        vn = vbslq_f32(vcopy_mask, va, vn);\n\n        vst1q_f32(B + i, vn);\n    }\n\n    // Handle remaining elements\n    for (; i < size; ++i) {\n        if (control[i] > 0) {\n            float val = A[i];\n            val = (val - min_val) / (max_val - min_val);\n            val = std::max(val, 0.0f);\n            val = std::min(val, 1.0f);\n            B[i] = val;\n        } else {\n            B[i] = A[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_56_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid int_to_float_sqrt_simd(const uint32_t* A, float* B, size_t size) {\n    for (size_t i = 0; i <= size - 4; i += 4) {\n        uint32x4_t vec_A = vld1q_u32(&A[i]);\n        uint16x8_t upper_bits = vreinterpretq_u16_u32(vshrq_n_u32(vec_A, 16));\n        float32x4_t vec_B = vcvtq_f32_u16(upper_bits);\n        float32x4_t sqrt_vec_B = vsqrtq_f32(vec_B);\n        vst1q_f32(&B[i], sqrt_vec_B);\n    }\n\n    // Handle remaining elements\n    for (size_t i = size - size % 4; i < size; ++i) {\n        uint32_t val = A[i];\n        float f_val = (float)((val >> 16) & 0xFFFF);\n        B[i] = sqrtf(f_val);\n    }\n}\n```"}
{"task_id": "SimdBench_56_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid int_to_float_sqrt_simd(const uint32_t* A, float* B, size_t size) {\n    size_t i = 0;\n    for (; i <= size - 4; i += 4) {\n        uint32x4_t vec_A = vld1q_u32(&A[i]);\n        uint16x8_t hi_bits = vreinterpretq_u16_u32(vec_A);\n        uint16x4_t hi_bits_lo = vget_low_u16(hi_bits);\n        uint16x4_t hi_bits_hi = vget_high_u16(hi_bits);\n\n        float32x4_t vec_B_lo = vcvtq_f32_u16(hi_bits_lo);\n        float32x4_t vec_B_hi = vcvtq_f32_u16(hi_bits_hi);\n\n        float32x4_t sqrt_vec_B_lo = vsqrtq_f32(vec_B_lo);\n        float32x4_t sqrt_vec_B_hi = vsqrtq_f32(vec_B_hi);\n\n        vst1q_f32(&B[i], sqrt_vec_B_lo);\n        vst1q_f32(&B[i + 2], sqrt_vec_B_hi);\n    }\n\n    // Handle remaining elements\n    for (; i < size; ++i) {\n        uint32_t val = A[i];\n        float f_val = (float)((val >> 16) & 0xFFFF);\n        B[i] = sqrtf(f_val);\n    }\n}\n```"}
{"task_id": "SimdBench_56_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid int_to_float_sqrt_simd(const uint32_t* A, float* B, size_t size) {\n    size_t i = 0;\n    for (; i <= size - 8; i += 8) {\n        uint32x4_t vec_A1 = vld1q_u32(&A[i]);\n        uint32x4_t vec_A2 = vld1q_u32(&A[i + 4]);\n\n        uint16x4_t hi16_1 = vmovn_u32(vec_A1);\n        uint16x4_t hi16_2 = vmovn_u32(vec_A2);\n\n        float32x4_t vec_B1 = vcvt_f32_u16(hi16_1);\n        float32x4_t vec_B2 = vcvt_f32_u16(hi16_2);\n\n        float32x4_t sqrt_B1 = vsqrtq_f32(vec_B1);\n        float32x4_t sqrt_B2 = vsqrtq_f32(vec_B2);\n\n        vst1q_f32(&B[i], sqrt_B1);\n        vst1q_f32(&B[i + 4], sqrt_B2);\n    }\n\n    for (; i < size; ++i) {\n        uint32_t val = A[i];\n        uint16_t hi16 = (val >> 16) & 0xFFFF;\n        float f_val = (float)hi16;\n        float sqrt_val = sqrtf(f_val);\n        B[i] = sqrt_val;\n    }\n}\n```"}
{"task_id": "SimdBench_56_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid int_to_float_sqrt_simd(const uint32_t* A, float* B, size_t size) {\n    size_t i = 0;\n    for (; i <= size - 8; i += 8) {\n        uint32x4_t vec_A1 = vld1q_u32(&A[i]);\n        uint32x4_t vec_A2 = vld1q_u32(&A[i + 4]);\n\n        uint16x4_t hi16_1 = vmovn_u32(vec_A1);\n        uint16x4_t hi16_2 = vmovn_u32(vec_A2);\n\n        float32x4_t vec_B1 = vcvt_f32_u16(hi16_1);\n        float32x4_t vec_B2 = vcvt_f32_u16(hi16_2);\n\n        float32x4_t sqrt_B1 = vsqrtq_f32(vec_B1);\n        float32x4_t sqrt_B2 = vsqrtq_f32(vec_B2);\n\n        vst1q_f32(&B[i], sqrt_B1);\n        vst1q_f32(&B[i + 4], sqrt_B2);\n    }\n\n    for (; i < size; ++i) {\n        uint32_t val = A[i];\n        uint16_t hi16 = (val >> 16) & 0xFFFF;\n        float f_val = (float)hi16;\n        float sqrt_val = sqrtf(f_val);\n        B[i] = sqrt_val;\n    }\n}\n```"}
{"task_id": "SimdBench_56_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid int_to_float_sqrt_simd(const uint32_t* A, float* B, size_t size) {\n    size_t i = 0;\n    for (; i <= size - 8; i += 8) {\n        uint32x4_t vA1 = vld1q_u32(&A[i]);\n        uint32x4_t vA2 = vld1q_u32(&A[i + 4]);\n\n        uint16x4_t vhA1 = vmovl_u16(vmovn_u32(vA1));\n        uint16x4_t vhA2 = vmovl_u16(vmovn_u32(vA2));\n\n        float32x4_t vfA1 = vcvt_f32_u16(vhA1);\n        float32x4_t vfA2 = vcvt_f32_u16(vhA2);\n\n        float32x4_t vsqrtA1 = vsqrtq_f32(vfA1);\n        float32x4_t vsqrtA2 = vsqrtq_f32(vfA2);\n\n        vst1q_f32(&B[i], vsqrtA1);\n        vst1q_f32(&B[i + 4], vsqrtA2);\n    }\n\n    for (; i < size; ++i) {\n        uint32_t val = A[i];\n        uint16_t high_bits = (val >> 16) & 0xFFFF;\n        float f_val = (float)high_bits;\n        float sqrt_val = sqrtf(f_val);\n        B[i] = sqrt_val;\n    }\n}\n```"}
{"task_id": "SimdBench_57_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid int_bits_to_float_simd(const uint32_t* A, float* B, size_t size) {\n    size_t i = 0;\n    for (; i <= size - 8; i += 8) {\n        uint32x4_t vecA1 = vld1q_u32(&A[i]);\n        uint32x4_t vecA2 = vld1q_u32(&A[i + 4]);\n        float32x4_t vecB1 = vcvt_f32_u32(vecA1);\n        float32x4_t vecB2 = vcvt_f32_u32(vecA2);\n        vst1q_f32(&B[i], vecB1);\n        vst1q_f32(&B[i + 4], vecB2);\n    }\n    for (; i < size; ++i) {\n        B[i] = *(float*)&A[i];\n    }\n}\n```"}
{"task_id": "SimdBench_57_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid int_bits_to_float_simd(const uint32_t* A, float* B, size_t size) {\n    size_t i = 0;\n    for (; i <= size - 8; i += 8) {\n        uint32x4_t vA1 = vld1q_u32(&A[i]);\n        uint32x4_t vA2 = vld1q_u32(&A[i + 4]);\n        float32x4_t vB1 = vcvt_f32_u32(vA1);\n        float32x4_t vB2 = vcvt_f32_u32(vA2);\n        vst1q_f32(&B[i], vB1);\n        vst1q_f32(&B[i + 4], vB2);\n    }\n    for (; i < size; ++i) {\n        B[i] = *(float*)&A[i];\n    }\n}\n```"}
{"task_id": "SimdBench_57_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid int_bits_to_float_simd(const uint32_t* A, float* B, size_t size) {\n    size_t i = 0;\n    for (; i <= size - 8; i += 8) {\n        uint32x4_t vec1 = vld1q_u32(&A[i]);\n        uint32x4_t vec2 = vld1q_u32(&A[i + 4]);\n        vst1q_f32(&B[i], vcvtq_f32_u32(vec1));\n        vst1q_f32(&B[i + 4], vcvtq_f32_u32(vec2));\n    }\n    for (; i < size; ++i) {\n        B[i] = *(float*)&A[i];\n    }\n}\n```"}
{"task_id": "SimdBench_57_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid int_bits_to_float_simd(const uint32_t* A, float* B, size_t size) {\n    size_t i = 0;\n    for (; i <= size - 8; i += 8) {\n        uint32x4_t vA1 = vld1q_u32(&A[i]);\n        uint32x4_t vA2 = vld1q_u32(&A[i + 4]);\n        float32x4_t vB1 = vcvt_f32_u32(vA1);\n        float32x4_t vB2 = vcvt_f32_u32(vA2);\n        vst1q_f32(&B[i], vB1);\n        vst1q_f32(&B[i + 4], vB2);\n    }\n    for (; i < size; ++i) {\n        B[i] = *(float*)&A[i];\n    }\n}\n```"}
{"task_id": "SimdBench_57_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid int_bits_to_float_simd(const uint32_t* A, float* B, size_t size) {\n    size_t i = 0;\n    for (; i <= size - 8; i += 8) {\n        uint32x4_t vecA1 = vld1q_u32(&A[i]);\n        uint32x4_t vecA2 = vld1q_u32(&A[i + 4]);\n        float32x4_t vecB1 = vcvt_f32_u32(vecA1);\n        float32x4_t vecB2 = vcvt_f32_u32(vecA2);\n        vst1q_f32(&B[i], vecB1);\n        vst1q_f32(&B[i + 4], vecB2);\n    }\n    for (; i < size; ++i) {\n        B[i] = *(float*)&A[i];\n    }\n}\n```"}
{"task_id": "SimdBench_58_Neon", "completion": "```cpp\nvoid conditional_diff_simd(const int32_t* A, const bool* cond, float* diff, size_t size) {\n    uint32x4_t vcond;\n    int32x4_t va, vb, vd;\n    float32x4_t vdiff;\n\n    // Initialize the first element of diff to 0.0f\n    diff[0] = 0.0f;\n\n    for (size_t i = 1; i < size; i += 4) {\n        // Load 4 conditions into a vector\n        vcond = vld1q_u32((const uint32_t*)&cond[i]);\n\n        // Load 4 elements from A\n        va = vld1q_s32(&A[i]);\n        vb = vld1q_s32(&A[i + 1]);\n\n        // Compute the difference between consecutive elements\n        vd = vsubq_s32(vb, va);\n\n        // Convert the difference to float\n        vdiff = vcvtq_f32_s32(vd);\n\n        // Mask the result based on the condition\n        vdiff = vmulq_laneq_f32(vdiff, vreinterpretq_f32_u32(vcond), 0);\n        vdiff = vmulq_laneq_f32(vdiff, vreinterpretq_f32_u32(vcond), 1);\n        vdiff = vmulq_laneq_f32(vdiff, vreinterpretq_f32_u32(vcond), 2);\n        vdiff = vmulq_laneq_f32(vdiff, vreinterpretq_f32_u32(vcond), 3);\n\n        // Store the result in diff\n        vst1q_f32(&diff[i], vdiff);\n    }\n}\n```"}
{"task_id": "SimdBench_58_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nvoid conditional_diff_simd(const int32_t* A, const bool* cond, float* diff, size_t size) {\n    uint32x4_t vcond;\n    int32x4_t va, vb, vd;\n    float32x4_t vdiff;\n\n    // Initialize the first element of diff to 0.0f\n    diff[0] = 0.0f;\n\n    for (size_t i = 1; i < size; i += 4) {\n        // Load 4 elements from A and cond\n        va = vld1q_s32(A + i - 1);\n        vb = vld1q_s32(A + i);\n        vcond = vreinterpretq_u32_u8(vld1q_u8((uint8_t*)cond + i));\n\n        // Compute the difference\n        vd = vsubq_s32(vb, va);\n\n        // Convert the difference to float\n        vdiff = vcvtq_f32_s32(vd);\n\n        // Mask the result based on cond\n        vdiff = vmulq_f32(vdiff, vreinterpretq_f32_u32(vcond));\n\n        // Store the result in diff\n        vst1q_f32(diff + i, vdiff);\n    }\n}\n```"}
{"task_id": "SimdBench_58_Neon", "completion": "```cpp\nvoid conditional_diff_simd(const int32_t* A, const bool* cond, float* diff, size_t size) {\n    uint32x4_t vcond;\n    int32x4_t va, vb, vdiff;\n    float32x4_t vf;\n\n    // Initialize the first element of diff to 0.0f\n    diff[0] = 0.0f;\n\n    for (size_t i = 1; i < size; i += 4) {\n        // Load 4 conditions from cond array\n        vcond = vld1q_u32((const uint32_t*)&cond[i]);\n\n        // Load 4 elements from A array\n        va = vld1q_s32(&A[i]);\n        vb = vld1q_s32(&A[i + 1]);\n\n        // Calculate differences\n        vdiff = vsubq_s32(va, vb);\n\n        // Convert differences to floats\n        vf = vcvtq_f32_s32(vdiff);\n\n        // Mask out elements where cond is false\n        vf = vmulq_f32(vf, vcvtq_f32_u32(vcond));\n\n        // Store results in diff array\n        vst1q_f32(&diff[i], vf);\n    }\n}\n```"}
{"task_id": "SimdBench_58_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid conditional_diff_simd(const int32_t* A, const bool* cond, float* diff, size_t size) {\n    uint32x4_t vcond;\n    int32x4_t va, vb, vd;\n    float32x4_t vdiff;\n\n    // Initialize the first element of diff to 0.0f\n    diff[0] = 0.0f;\n\n    for (size_t i = 1; i < size; i += 4) {\n        // Load 4 conditions from cond array\n        vcond = vld1q_u32((uint32_t*)&cond[i]);\n\n        // Load 4 elements from A array\n        va = vld1q_s32(&A[i]);\n        vb = vld1q_s32(&A[i + 1]);\n\n        // Compute differences\n        vd = vsubq_s32(va, vb);\n\n        // Convert differences to float\n        vdiff = vcvtq_f32_s32(vd);\n\n        // Mask out elements where cond is false\n        vdiff = vmulq_f32(vdiff, vcvtq_f32_u32(vandq_u32(vcond, vdupq_n_u32(0xFFFFFFFF))));\n\n        // Store results in diff array\n        vst1q_f32(&diff[i], vdiff);\n    }\n}\n```"}
{"task_id": "SimdBench_58_Neon", "completion": "```cpp\nvoid conditional_diff_simd(const int32_t* A, const bool* cond, float* diff, size_t size) {\n    uint32x4_t vcond;\n    int32x4_t va, va_prev;\n    float32x4_t vdiff;\n\n    // Initialize the first element of diff to 0.0f\n    diff[0] = 0.0f;\n\n    for (size_t i = 1; i < size; i += 4) {\n        // Load 4 elements from A and cond\n        va_prev = vld1q_s32(A + i - 1);\n        va = vld1q_s32(A + i);\n        vcond = vreinterpretq_u32_u8(vld1q_u8((uint8_t*)cond + i));\n\n        // Compute the difference\n        int32x4_t vdiff_int = vsubq_s32(va, va_prev);\n\n        // Convert to float\n        vdiff = vcvtq_f32_s32(vdiff_int);\n\n        // Mask the result based on cond\n        vdiff = vbslq_f32(vcond, vdiff, vdupq_n_f32(0.0f));\n\n        // Store the result in diff\n        vst1q_f32(diff + i, vdiff);\n    }\n}\n```"}
{"task_id": "SimdBench_59_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid widening_uint_simd(const uint32_t* src, uint64_t* dst, size_t length) {\n    for (size_t i = 0; i < length; i += 4) {\n        uint32x4_t vsrc = vld1q_u32(src + i);\n        uint64x2_t vones = vdupq_n_u64(0xFFFFFFFFFFFFFFFF);\n        uint64x2_t vresult = vorrq_u64(vreinterpretq_u64_u32(vsrc), vones);\n        vst1q_u64(dst + i, vresult);\n    }\n}\n```"}
{"task_id": "SimdBench_59_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid widening_uint_simd(const uint32_t* src, uint64_t* dst, size_t length) {\n    for (size_t i = 0; i < length; i += 4) {\n        uint32x4_t vsrc = vld1q_u32(src + i);\n        uint64x2_t vdst = vreinterpretq_u64_u32(vorrq_u32(vshrq_n_u32(vsrc, 31), vmovq_n_u32(0xFFFFFFFF)));\n        vst1q_u64(dst + i, vdst);\n    }\n}\n```"}
{"task_id": "SimdBench_59_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid widening_uint_simd(const uint32_t* src, uint64_t* dst, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 4; i += 4) {\n        uint32x4_t vsrc = vld1q_u32(src + i);\n        uint64x2_t vones = vdupq_n_u64(0xFFFFFFFFFFFFFFFF);\n        uint64x2_t vresult = vorrq_u64(vreinterpretq_u64_u32(vsrc), vones);\n        vst1q_u64(dst + i, vresult);\n    }\n    for (; i < length; ++i) {\n        dst[i] = ((uint64_t)1 << 32) | src[i];\n    }\n}\n```"}
{"task_id": "SimdBench_59_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid widening_uint_simd(const uint32_t* src, uint64_t* dst, size_t length) {\n    for (size_t i = 0; i < length; i += 4) {\n        uint32x4_t vsrc = vld1q_u32(src + i);\n        uint64x2_t vones = vdupq_n_u64(0xFFFFFFFFFFFFFFFF);\n        uint64x2_t vresult = vorrq_u64(vreinterpretq_u64_u32(vsrc), vones);\n        vst1q_u64(dst + i, vresult);\n    }\n}\n```"}
{"task_id": "SimdBench_59_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid widening_uint_simd(const uint32_t* src, uint64_t* dst, size_t length) {\n    for (size_t i = 0; i < length; i += 4) {\n        uint32x4_t vsrc = vld1q_u32(src + i);\n        uint64x2_t vones = vdupq_n_u64(0xFFFFFFFFFFFFFFFF);\n        uint64x2_t vresult = vorrq_u64(vreinterpretq_u64_u32(vsrc), vones);\n        vst1q_u64(dst + i, vresult);\n    }\n}\n```"}
{"task_id": "SimdBench_60_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <cmath>\n\ndouble indexed_sum_simd(const double* vec, const int16_t* index, size_t length) {\n    double sum = 0.0;\n    size_t i = 0;\n\n    // Process elements in chunks of 8\n    for (; i <= length - 8; i += 8) {\n        int16x8_t idx_vec = vld1q_s16(index + i);\n        uint32x4_t mask = vcltq_s16(idx_vec, vdupq_n_s16(length));\n        uint32x4_t mask_lo = vmovl_u16(vget_low_u16(mask));\n        uint32x4_t mask_hi = vmovl_u16(vget_high_u16(mask));\n\n        int16x4_t idx_vec_lo = vget_low_s16(idx_vec);\n        int16x4_t idx_vec_hi = vget_high_s16(idx_vec);\n\n        doublex2_t sum_vec = vdupq_n_f64(0.0);\n        for (int j = 0; j < 4; ++j) {\n            if (vget_lane_u32(mask_lo, j)) {\n                sum_vec = vaddq_f64(sum_vec, vld1q_f64(vec + vget_lane_s16(idx_vec_lo, j)));\n            }\n            if (vget_lane_u32(mask_hi, j)) {\n                sum_vec = vaddq_f64(sum_vec, vld1q_f64(vec + vget_lane_s16(idx_vec_hi, j)));\n            }\n        }\n\n        sum += vget_lane_f64(vadd_f64(vget_low_f64(sum_vec), vget_high_f64(sum_vec)), 0);\n        sum += vget_lane_f64(vadd_f64(vget_low_f64(sum_vec), vget_high_f64(sum_vec)), 1);\n    }\n\n    // Process remaining elements\n    for (; i < length; ++i) {\n        if (index[i] >= 0 && index[i] < length) {\n            sum += vec[index[i]];\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_60_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\ndouble indexed_sum_simd(const double* vec, const int16_t* index, size_t length) {\n    double sum = 0.0;\n    size_t i;\n\n    // Process elements in chunks of 8\n    for (i = 0; i <= length - 8; i += 8) {\n        int16x8_t idx_vec = vld1q_s16(index + i);\n        uint32x8_t mask = vcgtq_s16(idx_vec, vdupq_n_s16(0));\n        uint32x8_t valid_mask = vmovemask_u32(mask);\n\n        if (valid_mask != 0) {\n            doublex8_t vec_vec = vld1q_f64(vec + i);\n            doublex8_t selected_vec = vtbl2q_f64(vec_vec, idx_vec, vdupq_n_u32(valid_mask));\n            sum += vaddvq_f64(selected_vec);\n        }\n    }\n\n    // Process remaining elements\n    for (; i < length; ++i) {\n        int16_t idx = index[i];\n        if (idx >= 0 && idx < length) {\n            sum += vec[idx];\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_60_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\ndouble indexed_sum_simd(const double* vec, const int16_t* index, size_t length) {\n    double sum = 0.0;\n    size_t i = 0;\n\n    // Process elements in chunks of 8\n    for (; i <= length - 8; i += 8) {\n        int16x8_t idx_vec = vld1q_s16(index + i);\n        uint32x4_t mask_low = vcgtq_s16(idx_vec, vdupq_n_s16(0));\n        uint32x4_t mask_high = vcgtq_s16(vshrq_n_s16(idx_vec, 16), vdupq_n_s16(0));\n        uint32x4_t mask = vorrq_u32(mask_low, mask_high);\n\n        doublex2_t vec_load_low = vld1q_f64(vec + vget_lane_s32(vreinterpretq_s32_u32(mask), 0));\n        doublex2_t vec_load_high = vld1q_f64(vec + vget_lane_s32(vreinterpretq_s32_u32(mask), 1));\n\n        doublex2_t sum_vec = vaddq_f64(vec_load_low, vec_load_high);\n        sum += vget_lane_f64(sum_vec, 0) + vget_lane_f64(sum_vec, 1);\n    }\n\n    // Process remaining elements\n    for (; i < length; ++i) {\n        if (index[i] >= 0 && index[i] < length) {\n            sum += vec[index[i]];\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_60_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <cmath>\n\ndouble indexed_sum_simd(const double* vec, const int16_t* index, size_t length) {\n    double sum = 0.0;\n    size_t i = 0;\n\n    // Process elements in chunks of 8\n    for (; i <= length - 8; i += 8) {\n        int16x8_t idx_vec = vld1q_s16(index + i);\n        uint32x4_t mask_low = vcgtq_s16(idx_vec, vdupq_n_s16(0));\n        uint32x4_t mask_high = vcgtq_s16(vshrq_n_s16(idx_vec, 16), vdupq_n_s16(0));\n        uint32x4_t mask = vorrq_u32(mask_low, mask_high);\n\n        if (vmaxvq_u32(mask) == 0) {\n            continue;\n        }\n\n        doublex2_t sum_vec = vdupq_n_f64(0.0);\n        for (size_t j = 0; j < 8; ++j) {\n            int16_t idx = index[i + j];\n            if (idx >= 0 && idx < static_cast<int16_t>(length)) {\n                sum_vec = vfmaq_laneq_f64(sum_vec, vld1q_f64(vec + idx), 0);\n            }\n        }\n        sum += vgetq_lane_f64(sum_vec, 0) + vgetq_lane_f64(sum_vec, 1);\n    }\n\n    // Process remaining elements\n    for (; i < length; ++i) {\n        int16_t idx = index[i];\n        if (idx >= 0 && idx < static_cast<int16_t>(length)) {\n            sum += vec[idx];\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_60_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\ndouble indexed_sum_simd(const double* vec, const int16_t* index, size_t length) {\n    double sum = 0.0;\n    size_t i;\n\n    // Process elements in chunks of 8\n    for (i = 0; i <= length - 8; i += 8) {\n        int16x8_t idx_vec = vld1q_s16(index + i);\n        uint32x4_t mask = vreinterpret_u32_s16(vcltq_s16(idx_vec, vdupq_n_s16(length)));\n        uint32x4_t mask_lo = vmovl_u16(vget_low_u16(mask));\n        uint32x4_t mask_hi = vmovl_u16(vget_high_u16(mask));\n\n        doublex2_t vec_vec = vld1q_f64(vec + i);\n        doublex2_t sum_vec = vdupq_n_f64(0.0);\n\n        for (int j = 0; j < 8; ++j) {\n            if ((mask_lo[j / 2] & (1 << (j % 2))) != 0) {\n                sum_vec = vfmaq_lane_f64(sum_vec, vec_vec, j, 0);\n            }\n            if ((mask_hi[j / 2] & (1 << (j % 2))) != 0) {\n                sum_vec = vfmaq_lane_f64(sum_vec, vec_vec, j + 4, 1);\n            }\n        }\n\n        sum += vaddvq_f64(sum_vec);\n    }\n\n    // Process remaining elements\n    for (; i < length; ++i) {\n        if (index[i] >= 0 && index[i] < length) {\n            sum += vec[index[i]];\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_61_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nvoid simple_conv2d_simd(const double* input, const double* kernel, double * output, size_t input_size, size_t kernel_size) {\n    size_t output_size = input_size - kernel_size + 1;\n    size_t num_elements_per_iteration = 8;\n\n    for (size_t i = 0; i < output_size; i += num_elements_per_iteration) {\n        for (size_t j = 0; j < output_size; j += num_elements_per_iteration) {\n            int32x4_t sum0 = vdupq_n_s32(0);\n            int32x4_t sum1 = vdupq_n_s32(0);\n\n            for (size_t k = 0; k < kernel_size; ++k) {\n                for (size_t l = 0; l < kernel_size; ++l) {\n                    int64x2_t input_val0 = vld1q_f64(input + (i + k) * input_size + j + l);\n                    int64x2_t input_val1 = vld1q_f64(input + (i + k) * input_size + j + l + 1);\n                    int64x2_t kernel_val0 = vld1q_f64(kernel + k * kernel_size + l);\n                    int64x2_t kernel_val1 = vld1q_f64(kernel + k * kernel_size + l + 1);\n\n                    int64x2_t mul0 = vmulq_s64(vreinterpretq_s64_f64(input_val0),vreinterpretq_s64_f64(kernel_val0));\n                    int64x2_t mul1 = vmulq_s64(vreinterpretq_s64_f64(input_val1),vreinterpretq_s64_f64(kernel_val1));\n\n                    int32x4_t sum0_part = vaddw_s32(sum0,vmovn_s64(mul0));\n                    int32x4_t sum1_part = vaddw_s32(sum1,vmovn_s64(mul1));\n\n                    sum0 = vaddq_s32(sum0_part,sum1_part);\n                }\n            }\n\n            int32x4_t relu_sum0 = vmaxq_s32(sum0,vdupq_n_s32(0));\n            int32x4_t relu_sum1 = vmaxq_s32(sum1,vdupq_n_s32(0));\n\n            vst1q_f64(output + (i / num_elements_per_iteration) * output_size + j / num_elements_per_iteration, vreinterpretq_f64_u32(relu_sum0));\n            vst1q_f64(output + (i / num_elements_per_iteration) * output_size + j / num_elements_per_iteration + 1, vreinterpretq_f64_u32(relu_sum1));\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_61_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nvoid simple_conv2d_simd(const double* input, const double* kernel, double * output, size_t input_size, size_t kernel_size) {\n    size_t output_size = input_size - kernel_size + 1;\n    size_t num_elements_per_vector = 4; // Assuming 64-bit doubles\n\n    for (size_t i = 0; i < output_size; ++i) {\n        int32x4_t sum = vdupq_n_s32(0);\n\n        for (size_t j = 0; j < kernel_size; ++j) {\n            int32x4_t input_vec = vld1q_f32((const float32_t*)&input[i * input_size + j]);\n            int32x4_t kernel_vec = vld1q_f32((const float32_t*)&kernel[j * kernel_size]);\n\n            sum = vmlaq_f32(sum, input_vec, kernel_vec);\n        }\n\n        float32x4_t result_vec = vmulq_f32(vreinterpretq_f32_s32(sum), vmovq_n_f32(1.0f / kernel_size));\n        float32x2_t result_low = vget_low_f32(result_vec);\n        float32x2_t result_high = vget_high_f32(result_vec);\n\n        float32x2_t relu_low = vmax_f32(result_low, vdup_n_f32(0.0f));\n        float32x2_t relu_high = vmax_f32(result_high, vdup_n_f32(0.0f));\n\n        float32x4_t relu_result = vcombine_f32(relu_low, relu_high);\n        vst1q_f32((float32_t*)output + i * num_elements_per_vector, relu_result);\n    }\n}\n```"}
{"task_id": "SimdBench_61_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nvoid simple_conv2d_simd(const double* input, const double* kernel, double * output, size_t input_size, size_t kernel_size) {\n    size_t output_size = input_size - kernel_size + 1;\n    size_t num_elements_per_vector = 4; // Assuming double precision\n\n    for (size_t i = 0; i < output_size; ++i) {\n        int32x4_t sum = vdupq_n_s32(0);\n\n        for (size_t j = 0; j < kernel_size; ++j) {\n            int32x4_t input_vec = vld1q_f32((float32_t*)&input[i * input_size + j]);\n            int32x4_t kernel_vec = vld1q_f32((float32_t*)&kernel[j * kernel_size]);\n\n            sum = vmlaq_f32(sum, input_vec, kernel_vec);\n        }\n\n        float32x4_t result_vec = vmulq_f32(vreinterpretq_f32_s32(sum), vmovq_n_f32(1.0f));\n        float32x4_t relu_vec = vmaxq_f32(result_vec, vmovq_n_f32(0.0f));\n\n        vst1q_f32((float32_t*)&output[i], relu_vec);\n    }\n}\n```"}
{"task_id": "SimdBench_61_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nvoid simple_conv2d_simd(const double* input, const double* kernel, double * output, size_t input_size, size_t kernel_size) {\n    int32x4_t vzero = vmovq_n_s32(0);\n    int32x4_t vone = vmovq_n_s32(1);\n\n    for (size_t i = 0; i <= input_size - kernel_size; ++i) {\n        for (size_t j = 0; j <= input_size - kernel_size; ++j) {\n            int64x2_t sum = vdupq_n_s64(0);\n            for (size_t ki = 0; ki < kernel_size; ++ki) {\n                for (size_t kj = 0; kj < kernel_size; ++kj) {\n                    int64x2_t val = vmulq_f64(vld1q_f64(input + i + ki * input_size + j + kj), vld1q_f64(kernel + ki * kernel_size + kj));\n                    sum = vaddq_s64(sum, val);\n                }\n            }\n            int64x2_t relu = vmaxq_s64(sum, vzero);\n            vst1q_f64(output + i * (input_size - kernel_size + 1) + j, vreinterpretq_f64_s64(relu));\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_61_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nvoid simple_conv2d_simd(const double* input, const double* kernel, double * output, size_t input_size, size_t kernel_size) {\n    size_t output_size = input_size - kernel_size + 1;\n    size_t num_elements_per_iteration = kernel_size * kernel_size;\n\n    for (size_t i = 0; i < output_size; ++i) {\n        int32x2_t sum = vdup_n_s32(0);\n\n        for (size_t j = 0; j < num_elements_per_iteration; j += 2) {\n            int64x2_t input_pair = vld1q_f64(input + i * input_size + j / 2);\n            int64x2_t kernel_pair = vld1q_f64(kernel + j / 2);\n\n            int64x2_t product_pair = vmulq_s64(vreinterpretq_s64_f64(input_pair),vreinterpretq_s64_f64(kernel_pair));\n            sum = vaddw_s32(sum, vget_low_s32(product_pair));\n        }\n\n        double result = static_cast<double>(vget_lane_s32(sum, 0)) + static_cast<double>(vget_lane_s32(sum, 1));\n        result = std::max(result, 0.0);\n        output[i] = result;\n    }\n}\n```"}
{"task_id": "SimdBench_62_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <cmath>\n\nbool has_close_elements_simd(const std::vector<double> & numbers, double threshold) {\n    int n = numbers.size();\n    if (n < 2) return false;\n\n    const double *data = numbers.data();\n    for (int i = 0; i <= n - 4; i += 4) {\n        float64x2_t v1 = vld1q_f64(data + i);\n        float64x2_t v2 = vld1q_f64(data + i + 2);\n\n        float64x2_t diff1 = vsubq_f64(v1, v2);\n        float64x2_t abs_diff1 = vabsq_f64(diff1);\n        uint64x2_t cmp1 = vcgtq_f64(abs_diff1, vdupq_n_f64(threshold));\n        if (vget_lane_u64(cmp1, 0) || vget_lane_u64(cmp1, 1)) return true;\n\n        float64x2_t v3 = vld1q_f64(data + i + 4);\n        float64x2_t v4 = vld1q_f64(data + i + 6);\n\n        float64x2_t diff2 = vsubq_f64(v3, v4);\n        float64x2_t abs_diff2 = vabsq_f64(diff2);\n        uint64x2_t cmp2 = vcgtq_f64(abs_diff2, vdupq_n_f64(threshold));\n        if (vget_lane_u64(cmp2, 0) || vget_lane_u64(cmp2, 1)) return true;\n    }\n\n    for (int i = n - n % 4; i < n; ++i) {\n        for (int j = i + 1; j < n; ++j) {\n            if (std::fabs(data[i] - data[j]) < threshold) return true;\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_62_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <cmath>\n\nbool has_close_elements_simd(const std::vector<double> & numbers, double threshold) {\n    int n = numbers.size();\n    if (n < 2) return false;\n\n    const double *data = numbers.data();\n    for (int i = 0; i <= n - 4; i += 4) {\n        float64x2_t v1 = vld1q_f64(data + i);\n        float64x2_t v2 = vld1q_f64(data + i + 2);\n\n        float64x2_t diff1 = vsubq_f64(v1, v2);\n        float64x2_t abs_diff1 = vabsq_f64(diff1);\n        uint64x2_t cmp1 = vcgtq_f64(abs_diff1, vdupq_n_f64(threshold));\n\n        if (vget_lane_u64(cmp1, 0) || vget_lane_u64(cmp1, 1)) return true;\n\n        float64x2_t v3 = vld1q_f64(data + i + 4);\n        float64x2_t v4 = vld1q_f64(data + i + 6);\n\n        float64x2_t diff2 = vsubq_f64(v3, v4);\n        float64x2_t abs_diff2 = vabsq_f64(diff2);\n        uint64x2_t cmp2 = vcgtq_f64(abs_diff2, vdupq_n_f64(threshold));\n\n        if (vget_lane_u64(cmp2, 0) || vget_lane_u64(cmp2, 1)) return true;\n    }\n\n    for (; i < n - 1; ++i) {\n        if (std::fabs(data[i] - data[i + 1]) < threshold) return true;\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_62_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <cmath>\n\nbool has_close_elements_simd(const std::vector<double> & numbers, double threshold) {\n    int n = numbers.size();\n    if (n < 2) return false;\n\n    const double *data = numbers.data();\n    for (int i = 0; i <= n - 4; i += 4) {\n        float64x2_t v1 = vld1q_f64(data + i);\n        float64x2_t v2 = vld1q_f64(data + i + 2);\n\n        float64x2_t diff1 = vsubq_f64(v1, v2);\n        float64x2_t abs_diff1 = vabsq_f64(diff1);\n        if (vmaxnmq_f64(abs_diff1, vdupq_n_f64(threshold))[0] == 0 ||\n            vmaxnmq_f64(abs_diff1, vdupq_n_f64(threshold))[1] == 0) {\n            return true;\n        }\n\n        float64x2_t v3 = vld1q_f64(data + i + 4);\n        float64x2_t v4 = vld1q_f64(data + i + 6);\n\n        float64x2_t diff2 = vsubq_f64(v1, v3);\n        float64x2_t abs_diff2 = vabsq_f64(diff2);\n        if (vmaxnmq_f64(abs_diff2, vdupq_n_f64(threshold))[0] == 0 ||\n            vmaxnmq_f64(abs_diff2, vdupq_n_f64(threshold))[1] == 0) {\n            return true;\n        }\n\n        float64x2_t diff3 = vsubq_f64(v1, v4);\n        float64x2_t abs_diff3 = vabsq_f64(diff3);\n        if (vmaxnmq_f64(abs_diff3, vdupq_n_f64(threshold))[0] == 0 ||\n            vmaxnmq_f64(abs_diff3, vdupq_n_f64(threshold))[1] == 0) {\n            return true;\n        }\n    }\n\n    for (int i = n - 4; i < n; ++i) {\n        for (int j = i + 1; j < n; ++j) {\n            if (std::fabs(data[i] - data[j]) < threshold) {\n                return true;\n            }\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_62_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <cmath>\n\nbool has_close_elements_simd(const std::vector<double> & numbers, double threshold) {\n    int n = numbers.size();\n    if (n < 2) return false;\n\n    const double *data = numbers.data();\n    for (int i = 0; i <= n - 4; i += 4) {\n        float64x2_t v1 = vld1q_f64(data + i);\n        float64x2_t v2 = vld1q_f64(data + i + 2);\n\n        float64x2_t diff1 = vsubq_f64(v1, v2);\n        float64x2_t abs_diff1 = vabsq_f64(diff1);\n        uint64x2_t cmp1 = vcgtq_f64(abs_diff1, vdupq_n_f64(threshold));\n\n        if (vget_lane_u64(cmp1, 0) || vget_lane_u64(cmp1, 1)) return true;\n\n        float64x2_t v3 = vld1q_f64(data + i + 4);\n        float64x2_t v4 = vld1q_f64(data + i + 6);\n\n        float64x2_t diff2 = vsubq_f64(v3, v4);\n        float64x2_t abs_diff2 = vabsq_f64(diff2);\n        uint64x2_t cmp2 = vcgtq_f64(abs_diff2, vdupq_n_f64(threshold));\n\n        if (vget_lane_u64(cmp2, 0) || vget_lane_u64(cmp2, 1)) return true;\n    }\n\n    for (; i < n - 1; ++i) {\n        if (std::fabs(data[i] - data[i + 1]) < threshold) return true;\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_62_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <cmath>\n\nbool has_close_elements_simd(const std::vector<double> & numbers, double threshold) {\n    int n = numbers.size();\n    if (n < 2) return false;\n\n    const double *data = numbers.data();\n    for (int i = 0; i <= n - 8; i += 8) {\n        float64x2_t v1 = vld1q_f64(data + i);\n        float64x2_t v2 = vld1q_f64(data + i + 2);\n        float64x2_t v3 = vld1q_f64(data + i + 4);\n        float64x2_t v4 = vld1q_f64(data + i + 6);\n\n        float64x2_t diff1 = vsubq_f64(v1, v2);\n        float64x2_t diff2 = vsubq_f64(v1, v3);\n        float64x2_t diff3 = vsubq_f64(v1, v4);\n        float64x2_t diff4 = vsubq_f64(v2, v3);\n        float64x2_t diff5 = vsubq_f64(v2, v4);\n        float64x2_t diff6 = vsubq_f64(v3, v4);\n\n        uint64x2_t cmp1 = vcgtq_f64(vabsq_f64(diff1), vdupq_n_f64(threshold));\n        uint64x2_t cmp2 = vcgtq_f64(vabsq_f64(diff2), vdupq_n_f64(threshold));\n        uint64x2_t cmp3 = vcgtq_f64(vabsq_f64(diff3), vdupq_n_f64(threshold));\n        uint64x2_t cmp4 = vcgtq_f64(vabsq_f64(diff4), vdupq_n_f64(threshold));\n        uint64x2_t cmp5 = vcgtq_f64(vabsq_f64(diff5), vdupq_n_f64(threshold));\n        uint64x2_t cmp6 = vcgtq_f64(vabsq_f64(diff6), vdupq_n_f64(threshold));\n\n        if (vget_lane_u64(cmp1, 0) || vget_lane_u64(cmp1, 1) ||\n            vget_lane_u64(cmp2, 0) || vget_lane_u64(cmp2, 1) ||\n            vget_lane_u64(cmp3, 0) || vget_lane_u64(cmp3, 1) ||\n            vget_lane_u64(cmp4, 0) || vget_lane_u64(cmp4, 1) ||\n            vget_lane_u64(cmp5, 0) || vget_lane_u64(cmp5, 1) ||\n            vget_lane_u64(cmp6, 0) || vget_lane_u64(cmp6, 1)) {\n            return true;\n        }\n    }\n\n    // Handle remaining elements\n    for (int i = n - 8; i < n; ++i) {\n        for (int j = i + 1; j < n; ++j) {\n            if (std::fabs(numbers[i] - numbers[j]) < threshold) {\n                return true;\n            }\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_63_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nbool below_zero_simd(const std::vector<int>& operations) {\n    int32x4_t balance = vdupq_n_s32(0);\n    int32x4_t zero = vdupq_n_s32(0);\n\n    for (size_t i = 0; i < operations.size(); i += 4) {\n        int32x4_t ops = vld1q_s32(&operations[i]);\n        balance = vaddq_s32(balance, ops);\n        int32x4_t mask = vcgtq_s32(zero, balance);\n        if (vmaxvq_u32(mask)) {\n            return true;\n        }\n    }\n\n    // Handle remaining elements less than 4\n    for (size_t i = operations.size() - operations.size() % 4; i < operations.size(); ++i) {\n        balance = vaddq_s32(balance, vdupq_n_s32(operations[i]));\n        if (vget_lane_s32(vcltq_s32(balance, zero), 0)) {\n            return true;\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_63_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nbool below_zero_simd(const std::vector<int>& operations) {\n    int32x4_t balance = vdupq_n_s32(0);\n    int32x4_t zero = vdupq_n_s32(0);\n\n    for (size_t i = 0; i < operations.size(); i += 4) {\n        int32x4_t ops = vld1q_lane_s32(&operations[i], vdupq_n_s32(0), 0);\n        balance = vaddq_s32(balance, ops);\n        bool below_zero = vanyltq_s32(balance, zero);\n        if (below_zero) {\n            return true;\n        }\n    }\n\n    // Handle remaining elements\n    for (size_t i = operations.size() - operations.size() % 4; i < operations.size(); ++i) {\n        balance = vaddq_s32(balance, vdupq_n_s32(operations[i]));\n        bool below_zero = vanyltq_s32(balance, zero);\n        if (below_zero) {\n            return true;\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_63_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nbool below_zero_simd(const std::vector<int>& operations) {\n    int32x4_t balance = vdupq_n_s32(0);\n    int32x4_t zero = vdupq_n_s32(0);\n\n    for (size_t i = 0; i < operations.size(); i += 4) {\n        int32x4_t ops = vld1q_lane_s32(&operations[i], vdupq_n_s32(0), 0);\n        balance = vaddq_s32(balance, ops);\n        bool below_zero = vanyltq_s32(balance, zero);\n        if (below_zero) {\n            return true;\n        }\n    }\n\n    // Handle remaining elements\n    for (size_t i = operations.size() - operations.size() % 4; i < operations.size(); ++i) {\n        balance = vaddq_s32(balance, vdupq_n_s32(operations[i]));\n        bool below_zero = vanyltq_s32(balance, zero);\n        if (below_zero) {\n            return true;\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_63_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nbool below_zero_simd(const std::vector<int>& operations) {\n    int32x4_t balance = vdupq_n_s32(0);\n    int32x4_t zero = vdupq_n_s32(0);\n\n    for (size_t i = 0; i < operations.size(); i += 4) {\n        int32x4_t ops = vld1q_lane_s32(&operations[i], vdupq_n_s32(0), 0);\n        balance = vaddq_s32(balance, ops);\n        bool below_zero = vanyltq_s32(balance, zero);\n        if (below_zero) {\n            return true;\n        }\n    }\n\n    // Handle remaining elements less than 4\n    for (size_t i = operations.size() - operations.size() % 4; i < operations.size(); ++i) {\n        balance = vaddq_s32(balance, vdupq_n_s32(operations[i]));\n        bool below_zero = vanyltq_s32(balance, zero);\n        if (below_zero) {\n            return true;\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_63_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nbool below_zero_simd(const std::vector<int>& operations) {\n    int32x4_t balance = vdupq_n_s32(0);\n    int32x4_t threshold = vdupq_n_s32(0);\n\n    for (size_t i = 0; i < operations.size(); i += 4) {\n        int32x4_t ops = vld1q_s32(&operations[i]);\n        balance = vaddq_s32(balance, ops);\n        threshold = vminq_s32(threshold, balance);\n    }\n\n    int32x2_t half_threshold = vmovn_s32(threshold);\n    int32x2_t result = vpmin_s32(half_threshold, half_threshold);\n    return vget_lane_s32(result, 0) < 0;\n}\n```"}
{"task_id": "SimdBench_64_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <cmath>\n\ndouble mean_absolute_deviation_simd(const std::vector<double>& numbers) {\n    int n = numbers.size();\n    if (n == 0) return 0.0;\n\n    // Convert vector to float32x4_t\n    float32x4_t sum_vec = vdupq_n_f32(0.0f);\n    for (size_t i = 0; i < n; i += 4) {\n        float32x4_t vec = vld1q_f32(reinterpret_cast<const float*>(&numbers[i]));\n        sum_vec = vaddq_f32(sum_vec, vec);\n    }\n\n    // Calculate mean\n    float32x2_t sum_low = vpadd_f32(vget_low_f32(sum_vec), vget_high_f32(sum_vec));\n    float32x2_t sum_all = vpadd_f32(sum_low, sum_low);\n    float mean = vget_lane_f32(sum_all, 0) / n;\n\n    // Calculate MAD\n    float32x4_t mad_vec = vdupq_n_f32(0.0f);\n    for (size_t i = 0; i < n; i += 4) {\n        float32x4_t vec = vld1q_f32(reinterpret_cast<const float*>(&numbers[i]));\n        float32x4_t diff = vabsq_f32(vsubq_f32(vec, vdupq_n_f32(mean)));\n        mad_vec = vaddq_f32(mad_vec, diff);\n    }\n\n    // Sum up MAD values\n    float32x2_t mad_low = vpadd_f32(vget_low_f32(mad_vec), vget_high_f32(mad_vec));\n    float32x2_t mad_all = vpadd_f32(mad_low, mad_low);\n    double mad = vget_lane_f32(mad_all, 0) / n;\n\n    return mad;\n}\n```"}
{"task_id": "SimdBench_64_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <cmath>\n\ndouble mean_absolute_deviation_simd(const std::vector<double>& numbers) {\n    int n = numbers.size();\n    if (n == 0) return 0.0;\n\n    // Convert vector to float32x4_t\n    float32x4_t sum_vec = vdupq_n_f32(0.0f);\n    for (int i = 0; i < n; i += 4) {\n        float32x4_t vec = vld1q_f32(reinterpret_cast<const float*>(&numbers[i]));\n        sum_vec = vaddq_f32(sum_vec, vec);\n    }\n\n    // Calculate mean\n    float32x2_t sum_low = vpadd_f32(vget_low_f32(sum_vec), vget_high_f32(sum_vec));\n    float32x2_t sum_all = vpadd_f32(sum_low, sum_low);\n    float mean = vget_lane_f32(sum_all, 0) / n;\n\n    // Calculate MAD\n    float32x4_t mad_vec = vdupq_n_f32(0.0f);\n    for (int i = 0; i < n; i += 4) {\n        float32x4_t vec = vld1q_f32(reinterpret_cast<const float*>(&numbers[i]));\n        float32x4_t diff = vabsq_f32(vsubq_f32(vec, vdupq_n_f32(mean)));\n        mad_vec = vaddq_f32(mad_vec, diff);\n    }\n\n    // Sum up MAD values\n    float32x2_t mad_low = vpadd_f32(vget_low_f32(mad_vec), vget_high_f32(mad_vec));\n    float32x2_t mad_all = vpadd_f32(mad_low, mad_low);\n    double mad = vget_lane_f32(mad_all, 0) / n;\n\n    return mad;\n}\n```"}
{"task_id": "SimdBench_64_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <cmath>\n\ndouble mean_absolute_deviation_simd(const std::vector<double>& numbers) {\n    int n = numbers.size();\n    if (n == 0) return 0.0;\n\n    // Convert vector to float32x4_t for Neon operations\n    std::vector<float> float_numbers(n);\n    for (int i = 0; i < n; ++i) {\n        float_numbers[i] = static_cast<float>(numbers[i]);\n    }\n\n    float32x4_t sum_vec = vdupq_n_f32(0.0f);\n    for (int i = 0; i + 4 <= n; i += 4) {\n        float32x4_t vec = vld1q_f32(&float_numbers[i]);\n        sum_vec = vaddq_f32(sum_vec, vec);\n    }\n    float sum = vgetq_lane_f32(vaddq_f32(sum_vec, vdupq_n_f32(float_numbers[n-4])), 0) +\n                vgetq_lane_f32(vaddq_f32(vdupq_n_f32(float_numbers[n-3]), vdupq_n_f32(float_numbers[n-2])), 0) +\n                float_numbers[n-1];\n\n    double mean = sum / n;\n\n    float32x4_t mad_vec = vdupq_n_f32(0.0f);\n    for (int i = 0; i + 4 <= n; i += 4) {\n        float32x4_t vec = vld1q_f32(&float_numbers[i]);\n        float32x4_t diff = vabsq_f32(vsubq_f32(vec, vdupq_n_f32(static_cast<float>(mean))));\n        mad_vec = vaddq_f32(mad_vec, diff);\n    }\n    float mad = vgetq_lane_f32(vaddq_f32(mad_vec, vdupq_n_f32(fabs(float_numbers[n-4] - mean))), 0) +\n                 vgetq_lane_f32(vaddq_f32(vdupq_n_f32(fabs(float_numbers[n-3] - mean)), vdupq_n_f32(fabs(float_numbers[n-2] - mean))), 0) +\n                 fabs(float_numbers[n-1] - mean);\n\n    return mad / n;\n}\n```"}
{"task_id": "SimdBench_64_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <cmath>\n\ndouble mean_absolute_deviation_simd(const std::vector<double>& numbers) {\n    int n = numbers.size();\n    if (n == 0) return 0.0;\n\n    // Convert vector to float32x4_t\n    float32x4_t sum_vec = vdupq_n_f32(0.0f);\n    for (int i = 0; i < n; i += 4) {\n        float32x4_t vec = vld1q_f32(reinterpret_cast<const float*>(&numbers[i]));\n        sum_vec = vaddq_f32(sum_vec, vec);\n    }\n\n    // Calculate mean\n    float32x2_t sum_low = vpadd_f32(vget_low_f32(sum_vec), vget_high_f32(sum_vec));\n    float32x2_t sum_all = vpadd_f32(sum_low, sum_low);\n    float mean = vget_lane_f32(sum_all, 0) / n;\n\n    // Calculate MAD\n    float32x4_t mad_vec = vdupq_n_f32(0.0f);\n    for (int i = 0; i < n; i += 4) {\n        float32x4_t vec = vld1q_f32(reinterpret_cast<const float*>(&numbers[i]));\n        float32x4_t diff = vabsq_f32(vsubq_f32(vec, vdupq_n_f32(mean)));\n        mad_vec = vaddq_f32(mad_vec, diff);\n    }\n\n    // Sum up MAD values\n    float32x2_t mad_low = vpadd_f32(vget_low_f32(mad_vec), vget_high_f32(mad_vec));\n    float32x2_t mad_all = vpadd_f32(mad_low, mad_low);\n    double mad = vget_lane_f32(mad_all, 0) / n;\n\n    return mad;\n}\n```"}
{"task_id": "SimdBench_64_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <cmath>\n\ndouble mean_absolute_deviation_simd(const std::vector<double>& numbers) {\n    int n = numbers.size();\n    if (n == 0) return 0.0;\n\n    // Convert vector to float32x4_t\n    float32x4_t sum_vec = vdupq_n_f32(0.0f);\n    for (int i = 0; i < n; i += 4) {\n        float32x4_t vec = vld1q_f32(reinterpret_cast<const float*>(&numbers[i]));\n        sum_vec = vaddq_f32(sum_vec, vec);\n    }\n\n    // Calculate mean\n    float32x2_t sum_low = vpadd_f32(vget_low_f32(sum_vec), vget_high_f32(sum_vec));\n    float32x2_t sum_all = vpadd_f32(sum_low, sum_low);\n    float mean = vget_lane_f32(sum_all, 0) / n;\n\n    // Calculate MAD\n    float32x4_t mad_vec = vdupq_n_f32(0.0f);\n    for (int i = 0; i < n; i += 4) {\n        float32x4_t vec = vld1q_f32(reinterpret_cast<const float*>(&numbers[i]));\n        float32x4_t diff = vabsq_f32(vsubq_f32(vec, vdupq_n_f32(mean)));\n        mad_vec = vaddq_f32(mad_vec, diff);\n    }\n\n    // Sum up MAD values\n    float32x2_t mad_low = vpadd_f32(vget_low_f32(mad_vec), vget_high_f32(mad_vec));\n    float32x2_t mad_all = vpadd_f32(mad_low, mad_low);\n    double mad = vget_lane_f32(mad_all, 0) / n;\n\n    return mad;\n}\n```"}
{"task_id": "SimdBench_65_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int> intersperse_simd(const std::vector<int>& numbers, int delimiter) {\n    const size_t num_elements = numbers.size();\n    if (num_elements == 0) {\n        return {};\n    }\n\n    const size_t output_size = num_elements * 2 - 1;\n    std::vector<int> result(output_size);\n\n    int32x4_t v_delimiter = vdupq_n_s32(delimiter);\n    int32x4_t v_numbers[8];\n    uint32x4_t v_mask = vdupq_n_u32(0x000000FF);\n\n    size_t i = 0;\n    while (i + 7 < num_elements) {\n        v_numbers[0] = vld1q_s32(&numbers[i]);\n        v_numbers[1] = vld1q_s32(&numbers[i + 4]);\n\n        vst1q_lane_s32(&result[i * 2], v_numbers[0], 0);\n        vst1q_lane_s32(&result[i * 2 + 1], v_delimiter, 0);\n        vst1q_lane_s32(&result[(i + 1) * 2], v_numbers[1], 0);\n        vst1q_lane_s32(&result[(i + 1) * 2 + 1], v_delimiter, 0);\n\n        i += 8;\n    }\n\n    while (i + 3 < num_elements) {\n        v_numbers[0] = vld1q_s32(&numbers[i]);\n        v_numbers[1] = vld1q_s32(&numbers[i + 4]);\n        v_numbers[2] = vld1q_s32(&numbers[i + 8]);\n\n        vst1q_lane_s32(&result[i * 2], v_numbers[0], 0);\n        vst1q_lane_s32(&result[i * 2 + 1], v_delimiter, 0);\n        vst1q_lane_s32(&result[(i + 1) * 2], v_numbers[1], 0);\n        vst1q_lane_s32(&result[(i + 1) * 2 + 1], v_delimiter, 0);\n        vst1q_lane_s32(&result[(i + 2) * 2], v_numbers[2], 0);\n        vst1q_lane_s32(&result[(i + 2) * 2 + 1], v_delimiter, 0);\n\n        i += 4;\n    }\n\n    while (i < num_elements) {\n        v_numbers[0] = vld1q_s32(&numbers[i]);\n        vst1q_lane_s32(&result[i * 2], v_numbers[0], 0);\n        vst1q_lane_s32(&result[i * 2 + 1], v_delimiter, 0);\n        i++;\n    }\n\n    // Remove the last delimiter\n    result.pop_back();\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_65_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int> intersperse_simd(const std::vector<int>& numbers, int delimiter) {\n    const size_t n = numbers.size();\n    if (n == 0) return {};\n\n    std::vector<int> result;\n    result.reserve(2 * n - 1);\n\n    for (size_t i = 0; i < n; ++i) {\n        result.push_back(numbers[i]);\n        if (i != n - 1) {\n            result.push_back(delimiter);\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_65_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int> intersperse_simd(const std::vector<int>& numbers, int delimiter) {\n    const int n = numbers.size();\n    if (n == 0) return {};\n\n    std::vector<int> result;\n    result.reserve(2 * n - 1);\n\n    int32x4_t v_delimiter = vdupq_n_s32(delimiter);\n    int32x4_t v_numbers[2];\n    int count = 0;\n\n    for (size_t i = 0; i < n; ++i) {\n        v_numbers[count % 2] = vld1q_lane_s32(&numbers[i], v_numbers[count % 2], 0);\n        if ((i + 1) % 4 == 0 || i == n - 1) {\n            for (int j = 0; j <= count % 2; ++j) {\n                vst1q_lane_s32(&result.back() + 1, v_numbers[j], 0);\n                result.push_back(vgetq_lane_s32(v_delimiter, 0));\n            }\n            result.pop_back(); // Remove the extra delimiter added in the last iteration\n        }\n        count++;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_65_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int> intersperse_simd(const std::vector<int>& numbers, int delimiter) {\n    const size_t n = numbers.size();\n    if (n == 0) return {};\n\n    std::vector<int> result;\n    result.reserve(2 * n - 1);\n\n    for (size_t i = 0; i < n - 1; ++i) {\n        result.push_back(numbers[i]);\n        result.push_back(delimiter);\n    }\n    result.push_back(numbers[n - 1]);\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_65_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int> intersperse_simd(const std::vector<int>& numbers, int delimiter) {\n    const int n = numbers.size();\n    if (n == 0) return {};\n\n    std::vector<int> result;\n    result.reserve(2 * n - 1);\n\n    int32x4_t v_delimiter = vdupq_n_s32(delimiter);\n    int32x4_t v_numbers[2];\n\n    for (int i = 0; i < n; ++i) {\n        v_numbers[i % 2] = vld1q_lane_s32(&numbers[i], v_numbers[i % 2], 0);\n\n        if (i > 0) {\n            vst1q_lane_s32(&result.back(), v_delimiter, 0);\n        }\n\n        vst1q_lane_s32(&result.back(), v_numbers[i % 2], 0);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_66_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int64_t> sum_product_simd(const std::vector<int16_t>& numbers) {\n    int64x2_t sum = vdupq_n_s64(0);\n    int64x2_t product = vdupq_n_s64(1);\n\n    size_t n = numbers.size();\n    size_t i = 0;\n\n    // Process elements in chunks of 8\n    while (i + 8 <= n) {\n        int16x8_t vec = vld1q_s16(&numbers[i]);\n        int64x2_t vec_sum = vmovl_s16(vaddw_s16(vget_low_s16(vec), vget_high_s16(vec)));\n        int64x2_t vec_product = vmull_s16(vget_low_s16(vec), vget_high_s16(vec));\n        sum = vmlal_s64(sum, vget_low_s64(vec_sum), vget_low_s64(vec_product));\n        product = vmlsl_s64(product, vget_low_s64(vec_sum), vget_low_s64(vec_product));\n        sum = vmlal_s64(sum, vget_high_s64(vec_sum), vget_high_s64(vec_product));\n        product = vmlsl_s64(product, vget_high_s64(vec_sum), vget_high_s64(vec_product));\n        i += 8;\n    }\n\n    // Process remaining elements\n    for (; i < n; ++i) {\n        sum = vmlal_s64(sum, vdupq_n_s64(numbers[i]), vdupq_n_s64(numbers[i]));\n        product = vmlsl_s64(product, vdupq_n_s64(numbers[i]), vdupq_n_s64(numbers[i]));\n    }\n\n    int64_t final_sum = vget_lane_s64(sum, 0) + vget_lane_s64(sum, 1);\n    int64_t final_product = vget_lane_s64(product, 0) * vget_lane_s64(product, 1);\n\n    return {final_sum, final_product};\n}\n```"}
{"task_id": "SimdBench_66_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int64_t> sum_product_simd(const std::vector<int16_t>& numbers) {\n    int64x2_t sum = vdupq_n_s64(0);\n    int64x2_t product = vdupq_n_s64(1);\n\n    size_t n = numbers.size();\n    size_t i = 0;\n\n    // Process elements in chunks of 8\n    for (; i + 7 < n; i += 8) {\n        int16x8_t vec = vld1q_s16(&numbers[i]);\n        int32x4_t sum_vec = vmulq_lane_s16(vreinterpretq_s16_s8(vec), vdupq_n_s16(1));\n        int32x4_t product_vec = vmulq_lane_s16(vreinterpretq_s16_s8(vec), vdupq_n_s16(1));\n\n        sum = vaddq_s64(sum, vreinterpretq_s64_s32(sum_vec));\n        product = vmulq_s64(product, vreinterpretq_s64_s32(product_vec));\n    }\n\n    // Process remaining elements\n    for (; i < n; ++i) {\n        sum = vaddq_s64(sum, vdupq_n_s64(numbers[i]));\n        product = vmulq_s64(product, vdupq_n_s64(numbers[i]));\n    }\n\n    int64_t final_sum = vgetq_lane_s64(sum, 0) + vgetq_lane_s64(sum, 1);\n    int64_t final_product = vgetq_lane_s64(product, 0) * vgetq_lane_s64(product, 1);\n\n    return {final_sum, final_product};\n}\n```"}
{"task_id": "SimdBench_66_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int64_t> sum_product_simd(const std::vector<int16_t>& numbers) {\n    int64x2_t sum = vdupq_n_s64(0);\n    int64x2_t product = vdupq_n_s64(1);\n\n    size_t n = numbers.size();\n    size_t i = 0;\n\n    // Process elements in chunks of 8\n    while (i + 8 <= n) {\n        int16x8_t vec = vld1q_s16(&numbers[i]);\n        int64x2_t vec_sum = vmovl_s16(vaddw_s16(vget_low_s16(vec), vget_high_s16(vec)));\n        int64x2_t vec_product = vmull_s16(vget_low_s16(vec), vget_high_s16(vec));\n        sum = vmlal_s64(sum, vget_low_s64(vec_sum), vget_low_s64(vec_product));\n        product = vmlsl_s64(product, vget_low_s64(vec_sum), vget_low_s64(vec_product));\n        sum = vmlal_s64(sum, vget_high_s64(vec_sum), vget_high_s64(vec_product));\n        product = vmlsl_s64(product, vget_high_s64(vec_sum), vget_high_s64(vec_product));\n        i += 8;\n    }\n\n    // Process remaining elements\n    while (i < n) {\n        int16_t val = numbers[i];\n        sum = vmlal_s64(sum, vdupq_n_s64(val), vdupq_n_s64(val));\n        product = vmlsl_s64(product, vdupq_n_s64(val), vdupq_n_s64(val));\n        i++;\n    }\n\n    int64_t final_sum = vget_lane_s64(sum, 0) + vget_lane_s64(sum, 1);\n    int64_t final_product = vget_lane_s64(product, 0) * vget_lane_s64(product, 1);\n\n    return {final_sum, final_product};\n}\n```"}
{"task_id": "SimdBench_66_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int64_t> sum_product_simd(const std::vector<int16_t>& numbers) {\n    int64x2_t sum = vdupq_n_s64(0);\n    int64x2_t product = vdupq_n_s64(1);\n\n    size_t n = numbers.size();\n    size_t i = 0;\n\n    // Process elements in pairs\n    while (i + 1 < n) {\n        int16x8_t vec = vld1q_s16(&numbers[i]);\n        int32x4_t low = vmovl_s16(vget_low_s16(vec));\n        int32x4_t high = vmovl_s16(vget_high_s16(vec));\n\n        int64x2_t low_sum = vaddlp_s32(low);\n        int64x2_t high_sum = vaddlp_s32(high);\n\n        sum = vmlal_s64(sum, low_sum, vreinterpretq_s64_u64(vmovl_s32(vget_low_s32(low))));\n        sum = vmlal_s64(sum, high_sum, vreinterpretq_s64_u64(vmovl_s32(vget_high_s32(high))));\n\n        int64x2_t low_prod = vmull_s32(vget_low_s32(low), vget_low_s32(high));\n        int64x2_t high_prod = vmull_s32(vget_high_s32(low), vget_high_s32(high));\n\n        product = vmlal_s64(product, low_prod, vreinterpretq_s64_u64(vmovl_s32(vget_low_s32(low))));\n        product = vmlal_s64(product, high_prod, vreinterpretq_s64_u64(vmovl_s32(vget_high_s32(high))));\n\n        i += 16;\n    }\n\n    // Handle remaining elements\n    while (i < n) {\n        sum = vmlal_s64(sum, vdupq_n_s64(numbers[i]), vdupq_n_s64(1));\n        product = vmlal_s64(product, vdupq_n_s64(numbers[i]), vdupq_n_s64(numbers[i]));\n        i++;\n    }\n\n    int64_t final_sum[2];\n    int64_t final_product[2];\n\n    vst1q_s64(final_sum, sum);\n    vst1q_s64(final_product, product);\n\n    return {final_sum[0] + final_sum[1], final_product[0] * final_product[1]};\n}\n```"}
{"task_id": "SimdBench_66_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int64_t> sum_product_simd(const std::vector<int16_t>& numbers) {\n    int64x2_t sum = vdupq_n_s64(0);\n    int64x2_t product = vdupq_n_s64(1);\n\n    size_t n = numbers.size();\n    size_t i = 0;\n\n    // Process elements in chunks of 8\n    while (i + 8 <= n) {\n        int16x8_t vec = vld1q_s16(&numbers[i]);\n        int64x2_t vec_sum = vmovl_s16(vget_low_s16(vec)) + vmovl_s16(vget_high_s16(vec));\n        int64x2_t vec_product = vmull_s16(vget_low_s16(vec), vget_high_s16(vec));\n\n        sum = vaddq_s64(sum, vec_sum);\n        product = vmulq_s64(product, vec_product);\n\n        i += 8;\n    }\n\n    // Process remaining elements\n    while (i < n) {\n        int16_t num = numbers[i];\n        sum = vaddq_s64(sum, vdupq_n_s64(num));\n        product = vmulq_s64(product, vdupq_n_s64(num));\n        i++;\n    }\n\n    int64_t final_sum = vget_lane_s64(sum, 0) + vget_lane_s64(sum, 1);\n    int64_t final_product = vget_lane_s64(product, 0) * vget_lane_s64(product, 1);\n\n    return {final_sum, final_product};\n}\n```"}
{"task_id": "SimdBench_67_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int> rolling_max_simd(const std::vector<int>& numbers) {\n    int size = numbers.size();\n    if (size == 0) return {};\n\n    std::vector<int> result(size);\n    result[0] = numbers[0];\n\n    int32x4_t max_vec = vdupq_n_s32(numbers[0]);\n    const int* input_ptr = &numbers[1];\n    int* output_ptr = &result[1];\n\n    while (input_ptr + 4 <= &numbers[size]) {\n        int32x4_t current_vec = vld1q_s32(input_ptr);\n        max_vec = vmaxq_s32(max_vec, current_vec);\n        vst1q_s32(output_ptr, max_vec);\n\n        input_ptr += 4;\n        output_ptr += 4;\n    }\n\n    // Handle remaining elements\n    for (; input_ptr < &numbers[size]; ++input_ptr, ++output_ptr) {\n        *output_ptr = std::max(*output_ptr - 1, *input_ptr);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_67_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int> rolling_max_simd(const std::vector<int>& numbers) {\n    int size = numbers.size();\n    if (size == 0) return {};\n\n    std::vector<int> result(size);\n    result[0] = numbers[0];\n\n    int32x4_t max_vec = vdupq_n_s32(numbers[0]);\n    const int32_t* input_ptr = &numbers[1];\n    int* output_ptr = &result[1];\n\n    while (input_ptr + 4 <= &numbers[size]) {\n        int32x4_t current_vec = vld1q_s32(input_ptr);\n        max_vec = vmaxq_s32(max_vec, current_vec);\n        vst1q_s32(output_ptr, max_vec);\n\n        input_ptr += 4;\n        output_ptr++;\n    }\n\n    // Handle remaining elements\n    for (; input_ptr < &numbers[size]; ++input_ptr, ++output_ptr) {\n        *output_ptr = std::max(*output_ptr - 1, *input_ptr);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_67_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int> rolling_max_simd(const std::vector<int>& numbers) {\n    int size = numbers.size();\n    if (size == 0) return {};\n\n    std::vector<int> result(size);\n    result[0] = numbers[0];\n\n    int32x4_t max_vec = vdupq_n_s32(numbers[0]);\n    const int* input_ptr = &numbers[1];\n    int* output_ptr = &result[1];\n\n    while (input_ptr + 4 <= &numbers[size]) {\n        int32x4_t current_vec = vld1q_s32(input_ptr);\n        max_vec = vmaxq_s32(max_vec, current_vec);\n        vst1q_s32(output_ptr, max_vec);\n        input_ptr += 4;\n        output_ptr += 4;\n    }\n\n    // Handle remaining elements\n    for (; input_ptr < &numbers[size]; ++input_ptr, ++output_ptr) {\n        *output_ptr = std::max(*output_ptr - 1, *input_ptr);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_67_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int> rolling_max_simd(const std::vector<int>& numbers) {\n    int size = numbers.size();\n    if (size == 0) return {};\n\n    std::vector<int> result(size);\n    result[0] = numbers[0];\n\n    int32x4_t max_vec = vdupq_n_s32(numbers[0]);\n    const int32_t* input_ptr = &numbers[1];\n    int* output_ptr = &result[1];\n\n    while (input_ptr + 4 <= &numbers[size]) {\n        int32x4_t current_vec = vld1q_s32(input_ptr);\n        max_vec = vmaxq_s32(max_vec, current_vec);\n        vst1q_s32(output_ptr, max_vec);\n        input_ptr += 4;\n        output_ptr++;\n    }\n\n    // Handle remaining elements\n    for (; input_ptr < &numbers[size]; ++input_ptr, ++output_ptr) {\n        *output_ptr = std::max(*output_ptr - 1, *input_ptr);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_67_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int> rolling_max_simd(const std::vector<int>& numbers) {\n    int size = numbers.size();\n    if (size == 0) return {};\n\n    std::vector<int> result(size);\n    result[0] = numbers[0];\n\n    int32x4_t max_vec = vdupq_n_s32(numbers[0]);\n    const int32_t* input_ptr = &numbers[1];\n    int* output_ptr = &result[1];\n\n    while (input_ptr + 4 <= &numbers[size]) {\n        int32x4_t current_vec = vld1q_s32(input_ptr);\n        max_vec = vmaxq_s32(max_vec, current_vec);\n        vst1q_s32(output_ptr, max_vec);\n        input_ptr += 4;\n        output_ptr++;\n    }\n\n    // Handle remaining elements\n    for (; input_ptr < &numbers[size]; ++input_ptr, ++output_ptr) {\n        *output_ptr = std::max(*output_ptr - 1, *input_ptr);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_68_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n#include <vector>\n\nstd::string string_xor_simd(const std::string& a, const std::string& b) {\n    size_t len = std::min(a.size(), b.size());\n    std::string result(len, '0');\n\n    const uint8_t* ptr_a = reinterpret_cast<const uint8_t*>(a.c_str());\n    const uint8_t* ptr_b = reinterpret_cast<const uint8_t*>(b.c_str());\n    uint8_t* ptr_r = reinterpret_cast<uint8_t*>(result.data());\n\n    size_t i = 0;\n    for (; i <= len - 16; i += 16) {\n        uint8x16_t vec_a = vld1q_u8(ptr_a + i);\n        uint8x16_t vec_b = vld1q_u8(ptr_b + i);\n        uint8x16_t vec_res = veorq_u8(vec_a, vec_b);\n        vst1q_u8(ptr_r + i, vec_res);\n    }\n\n    for (; i < len; ++i) {\n        result[i] = (a[i] == b[i]) ? '0' : '1';\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_68_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n#include <vector>\n\nstd::string string_xor_simd(const std::string& a, const std::string& b) {\n    size_t len = std::min(a.size(), b.size());\n    std::string result(len, '0');\n\n    size_t i = 0;\n    while (i + 32 <= len) {\n        uint8x16_t va = vld1q_u8(reinterpret_cast<const uint8_t*>(&a[i]));\n        uint8x16_t vb = vld1q_u8(reinterpret_cast<const uint8_t*>(&b[i]));\n        uint8x16_t xor_result = veorq_u8(va, vb);\n        vst1q_u8(reinterpret_cast<uint8_t*>(&result[i]), xor_result);\n        i += 16;\n    }\n\n    while (i + 8 <= len) {\n        uint8x8_t va = vld1_u8(reinterpret_cast<const uint8_t*>(&a[i]));\n        uint8x8_t vb = vld1_u8(reinterpret_cast<const uint8_t*>(&b[i]));\n        uint8x8_t xor_result = veor_u8(va, vb);\n        vst1_u8(reinterpret_cast<uint8_t*>(&result[i]), xor_result);\n        i += 8;\n    }\n\n    while (i < len) {\n        result[i] = a[i] ^ b[i];\n        ++i;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_68_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n#include <vector>\n#include <algorithm>\n\nstd::string string_xor_simd(const std::string& a, const std::string& b) {\n    size_t len = std::min(a.size(), b.size());\n    std::string result(len, '0');\n\n    const uint8_t* ptr_a = reinterpret_cast<const uint8_t*>(a.c_str());\n    const uint8_t* ptr_b = reinterpret_cast<const uint8_t*>(b.c_str());\n    uint8_t* ptr_r = reinterpret_cast<uint8_t*>(result.data());\n\n    size_t i = 0;\n    for (; i <= len - 16; i += 16) {\n        uint8x16_t vec_a = vld1q_u8(ptr_a + i);\n        uint8x16_t vec_b = vld1q_u8(ptr_b + i);\n        uint8x16_t vec_res = veorq_u8(vec_a, vec_b);\n        vst1q_u8(ptr_r + i, vec_res);\n    }\n\n    for (; i < len; ++i) {\n        result[i] = (a[i] == b[i]) ? '0' : '1';\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_68_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nstd::string string_xor_simd(const std::string& a, const std::string& b) {\n    size_t len = std::min(a.length(), b.length());\n    std::string result(len, '0');\n\n    const uint8x16_t* pa = reinterpret_cast<const uint8x16_t*>(a.c_str());\n    const uint8x16_t* pb = reinterpret_cast<const uint8x16_t*>(b.c_str());\n    uint8x16_t* pr = reinterpret_cast<uint8x16_t*>(result.data());\n\n    for (size_t i = 0; i < len / 16; ++i) {\n        uint8x16_t va = vld1q_u8(pa + i);\n        uint8x16_t vb = vld1q_u8(pb + i);\n        uint8x16_t vr = veorq_u8(va, vb);\n        vst1q_u8(pr + i, vr);\n    }\n\n    // Handle remaining bytes\n    for (size_t i = len - len % 16; i < len; ++i) {\n        result[i] = a[i] ^ b[i];\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_68_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n#include <vector>\n\nstd::string string_xor_simd(const std::string& a, const std::string& b) {\n    size_t len = std::min(a.length(), b.length());\n    std::string result(len, '0');\n\n    size_t i = 0;\n    while (i + 32 <= len) {\n        uint8x16_t vec_a = vld1q_u8(reinterpret_cast<const uint8_t*>(&a[i]));\n        uint8x16_t vec_b = vld1q_u8(reinterpret_cast<const uint8_t*>(&b[i]));\n        uint8x16_t xor_result = veorq_u8(vec_a, vec_b);\n        vst1q_u8(reinterpret_cast<uint8_t*>(&result[i]), xor_result);\n        i += 16;\n    }\n\n    while (i + 8 <= len) {\n        uint8x8_t vec_a = vld1_u8(reinterpret_cast<const uint8_t*>(&a[i]));\n        uint8x8_t vec_b = vld1_u8(reinterpret_cast<const uint8_t*>(&b[i]));\n        uint8x8_t xor_result = veor_u8(vec_a, vec_b);\n        vst1_u8(reinterpret_cast<uint8_t*>(&result[i]), xor_result);\n        i += 8;\n    }\n\n    while (i < len) {\n        result[i] = a[i] ^ b[i];\n        i++;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_69_Neon", "completion": "```cpp\n\n```"}
{"task_id": "SimdBench_69_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <string>\n#include <algorithm>\n\nstd::string longest_simd(const std::vector<std::string>& strings) {\n    if (strings.empty()) {\n        return \"\";\n    }\n\n    const char* longest = nullptr;\n    size_t max_length = 0;\n\n    for (const auto& str : strings) {\n        if (str.length() > max_length) {\n            longest = str.c_str();\n            max_length = str.length();\n        }\n    }\n\n    return std::string(longest, max_length);\n}\n```"}
{"task_id": "SimdBench_69_Neon", "completion": "```cpp\n\n```"}
{"task_id": "SimdBench_69_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <string>\n#include <algorithm>\n\nstd::string longest_simd(const std::vector<std::string>& strings) {\n    if (strings.empty()) {\n        return \"\";\n    }\n\n    const char* longest = nullptr;\n    size_t max_length = 0;\n\n    for (const auto& str : strings) {\n        if (str.length() > max_length) {\n            longest = str.c_str();\n            max_length = str.length();\n        }\n    }\n\n    return std::string(longest, max_length);\n}\n```"}
{"task_id": "SimdBench_69_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <string>\n#include <algorithm>\n\nstd::string longest_simd(const std::vector<std::string>& strings) {\n    if (strings.empty()) {\n        return \"\";\n    }\n\n    const char* longest = nullptr;\n    size_t max_length = 0;\n\n    for (const auto& str : strings) {\n        if (str.length() > max_length) {\n            longest = str.c_str();\n            max_length = str.length();\n        }\n    }\n\n    return std::string(longest, max_length);\n}\n```"}
{"task_id": "SimdBench_70_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nuint64_t greatest_common_divisor_simd(uint64_t a, uint64_t b) {\n    uint64x2_t va = vdupq_n_u64(a);\n    uint64x2_t vb = vdupq_n_u64(b);\n\n    while (!veorq_p8(vceqq_u64(va, vb))) {\n        uint64x2_t vmask = vcltq_u64(va, vb);\n        va = vbslq_u64(vmask, vb, va);\n        vb = vbslq_u64(vmask, va - vb, vb);\n    }\n\n    return vgetq_lane_u64(va, 0);\n}\n```"}
{"task_id": "SimdBench_70_Neon", "completion": "```c\n#include <arm_neon.h>\n\nuint64_t greatest_common_divisor_simd(uint64_t a, uint64_t b) {\n    uint64x2_t va = vdupq_n_u64(a);\n    uint64x2_t vb = vdupq_n_u64(b);\n\n    while (!veorq_p8(vceqq_u64(va, vb))) {\n        uint64x2_t vmask = vcltq_u64(va, vb);\n        va = vbslq_u64(vmask, vb, va);\n        vb = vbslq_u64(vmask, va, vb);\n        va = veorq_u64(va, vb);\n        vb = vshrq_n_u64(vb, 1);\n    }\n\n    return va[0];\n}\n```"}
{"task_id": "SimdBench_70_Neon", "completion": "```c\n#include <arm_neon.h>\n\nuint64_t greatest_common_divisor_simd(uint64_t a, uint64_t b) {\n    uint64x2_t va = vdupq_n_u64(a);\n    uint64x2_t vb = vdupq_n_u64(b);\n\n    while (!veorq_p8(vceqq_u64(va, vb))) {\n        uint64x2_t vmask = vcltq_u64(va, vb);\n        uint64x2_t vtemp = va;\n        va = vbslq_u64(vmask, vb, va);\n        vb = vbslq_u64(vmask, vtemp, vb);\n        vb = vsubq_u64(vb, va);\n    }\n\n    return va[0];\n}\n```"}
{"task_id": "SimdBench_70_Neon", "completion": "```c\n#include <arm_neon.h>\n\nuint64_t greatest_common_divisor_simd(uint64_t a, uint64_t b) {\n    while (b != 0) {\n        uint64x2_t va = vdupq_n_u64(a);\n        uint64x2_t vb = vdupq_n_u64(b);\n        uint64x2_t vr = vmulq_u64(va, vb);\n        uint64x2_t vd = vsubq_u64(va, vr);\n        uint64x2_t vg = vorrq_u64(vd, vb);\n        uint64x2_t vh = vminq_u64(vg, vd);\n        uint64x2_t vi = vshrq_n_u64(vh, 1);\n        uint64x2_t vj = veorq_u64(vi, vh);\n        uint64x2_t vk = vandq_u64(vj, vg);\n        uint64x2_t vl = vaddq_u64(vk, vi);\n        uint64x2_t vm = vsubq_u64(vl, vk);\n        uint64x2_t vn = vshrq_n_u64(vm, 1);\n        uint64x2_t vo = veorq_u64(vn, vm);\n        uint64x2_t vp = vandq_u64(vo, vm);\n        uint64x2_t vq = vaddq_u64(vp, vn);\n        uint64x2_t vr2 = vsubq_u64(vq, vp);\n        uint64x2_t vs = vshrq_n_u64(vr2, 1);\n        uint64x2_t vt = veorq_u64(vs, vr2);\n        uint64x2_t vu = vandq_u64(vt, vr2);\n        uint64x2_t vv = vaddq_u64(vu, vs);\n        uint64x2_t vw = vsubq_u64(vv, vu);\n        uint64x2_t vx = vshrq_n_u64(vw, 1);\n        uint64x2_t vy = veorq_u64(vx, vw);\n        uint64x2_t vz = vandq_u64(vy, vw);\n        uint64x2_t vw2 = vaddq_u64(vz, vx);\n        uint64x2_t vw3 = vsubq_u64(vw2, vz);\n        uint64x2_t vw4 = vshrq_n_u64(vw3, 1);\n        uint64x2_t vw5 = veorq_u64(vw4, vw3);\n        uint64x2_t vw6 = vandq_u64(vw5, vw3);\n        uint64x2_t vw7 = vaddq_u64(vw6, vw4);\n        uint64x2_t vw8 = vsubq_u64(vw7, vw6);\n        uint64x2_t vw9 = vshrq_n_u64(vw8, 1);\n        uint64x2_t vw10 = veorq_u64(vw9, vw8);\n        uint64x2_t vw11 = vandq_u64(vw10, vw8);\n        uint64x2_t vw12 = vaddq_u64(vw11, vw9);\n        uint64x2_t vw13 = vsubq_u64(vw12, vw11);\n        uint64x2_t vw14 = vshrq_n_u64(vw13, 1);\n        uint64x2_t vw15 = veorq_u64(vw14, vw13);\n        uint64x2_t vw16 = vandq_u64(vw15, vw13);\n        uint64x2_t vw17 = vaddq_u64(vw16, vw14);\n        uint64x2_t vw18 = vsubq_u64(vw17, vw16);\n        uint64x2_t vw19 = vshrq_n_u64(vw18, 1);\n        uint64x2_t vw20 = veorq_u64(vw19, vw18);\n        uint64x2_t vw21 = vandq_u64(vw20, vw18);\n        uint64x2_t vw22 = vaddq_u64(vw21, vw19);\n        uint64x2_t vw23 = vsubq_u64(vw22, vw21);\n        uint64x2_t vw24 = vshrq_n_u64(vw23, 1);\n        uint64x2_t vw25 = veorq_u64(vw24, vw23);\n        uint64x2_t vw26 = vandq_u64(vw25, vw23);\n        uint64x2_t vw27 = vaddq_u64(vw26, vw24);\n        uint64x2_t vw28 = vsubq_u64(vw27, vw26);\n        uint64x2_t vw29 = vshrq_n_u64(vw28, 1);\n        uint64x2_t vw30 = veorq_u64(vw29, vw28);\n        uint64x2_t vw31 = vandq_u64(vw30, vw28);\n        uint64x2_t vw32 = vaddq_u64(vw31, vw29);\n        uint64x2_t vw33 = vsubq_u64(vw32, vw31);\n        uint64x2_t vw34 = vshrq_n_u64(vw33, 1);\n        uint64x2_t vw35 = veorq_u64(vw34, vw33);\n        uint64x2_t vw36 = vandq_u64(vw35, vw33);\n        uint64x2_t vw37 = vaddq_u64(vw36, vw34);\n        uint64x2_t vw38 = vsubq_u64(vw37, vw36);\n        uint64x2_t vw39 = vshrq_n_u64(vw38, 1);\n        uint64x2_t vw40 = veorq_u64(vw39, vw38);\n        uint64x2_t vw41 = vandq_u64(vw40, vw38);\n        uint64x2_t vw42 = vaddq_u64(vw41, vw39);\n        uint64x2_t vw43 = vsubq_u64(vw42, vw41);\n        uint64x2_t vw44 = vshrq_n_u64(vw43, 1);\n        uint64x2_t vw45 = veorq_u64(vw44, vw43);\n        uint64x2_t vw46 = vandq_u64(vw45, vw43);\n        uint64x2_t vw47 = vaddq_u64(vw46, vw44);\n        uint64x2_t vw48 = vsubq_u64(vw47, vw46);\n        uint64x2_t vw49 = vshrq_n_u64(vw48, 1);\n        uint64x2_t vw50 = veorq_u64(vw49, vw48);\n        uint64x2_t vw51 = vandq_u64(vw50, vw48);\n        uint64x2_t vw52 = vaddq_u64(vw51, vw49);\n        uint64x2_t vw53 = vsubq_u64(vw52, vw51);\n        uint64x2_t vw54 = vshrq_n_u64(vw53, 1);\n        uint64x2_t vw55 = veorq_u64(vw54, vw53);\n        uint64x2_t vw56 = vandq_u64(vw55, vw53);\n        uint64x2_t vw57 = vaddq_u64(vw56, vw54);\n        uint64x2_t vw58 = vsubq_u64(vw57, vw56);\n        uint64x2_t vw59 = vshrq_n_u64(vw58, 1);\n        uint64x2_t vw60 = veorq_u64(vw59, vw58);\n        uint64x2_t vw61 = vandq_u64(vw60, vw58);\n        uint64x2_t vw62 = vaddq_u64(vw61, vw59);\n        uint64x2_t vw63 = vsubq_u64(vw62, vw61);\n        uint64x2_t vw64 = vshrq_n_u64(vw63, 1);\n        uint64x2_t vw65 = veorq_u64(vw64, vw63);\n        uint64x2_t vw66 = vandq_u64(vw65, vw63);\n        uint64x2_t vw67 = vaddq_u64(vw66, vw64);\n        uint64x2_t vw68 = vsubq_u64(vw67, vw66);\n        uint64x2_t vw69 = vshrq_n_u64(vw68, 1);\n        uint64x2_t vw70 = veorq_u64(vw69, vw68);\n        uint64x2_t vw71 = vandq_u64(vw70, vw68);\n        uint64x2_t vw72 = vaddq_u64(vw71, vw69);\n        uint64x2_t vw73 = vsubq_u64(vw72, vw71);\n        uint64x2_t vw74 = vshrq_n_u64(vw73, 1);\n        uint64x2_t vw75 = veorq_u64(vw74, vw73);\n        uint64x2_t vw76 = vandq_u64(vw75, vw73);\n        uint64x2_t vw77 = vaddq_u64(vw76, vw74);\n        uint64x2_t vw78 = vsubq_u64(vw77, vw76);\n        uint64x2_t vw79 = vshrq_n_u64(vw78, 1);\n        uint64x2_t vw80 = veorq_u64(vw79, vw78);\n        uint64x2_t vw81 = vandq_u64(vw80, vw78);\n        uint64x2_t vw82 = vaddq_u64(vw81, vw79);\n        uint64x2_t vw83 = vsubq_u64(vw82, vw81);\n        uint64x2_t vw84 = vshrq_n_u64(vw83, 1);\n        uint64x2_t vw85 = veorq_u64(vw84, vw83);\n        uint64x2_t vw86 = vandq_u64(vw85, vw83);\n        uint64x2_t vw87 = vaddq_u64(vw86, vw84);\n        uint64x2_t vw88 = vsubq_u64(vw87, vw86);\n        uint64x2_t vw89 = vshrq_n_u64(vw88, 1);\n        uint64x2_t vw90 = veorq_u64(vw89, vw88);\n        uint64x2_t vw91 = vandq_u64(vw90, vw88);\n        uint64x2_t vw92 = vaddq_u64(vw91, vw89);\n        uint64x2_t vw93 = vsubq_u64(vw92, vw91);\n        uint64x2_t vw94 = vshrq_n_u64(vw93, 1);\n        uint64x2_t vw95 = veorq_u64(vw94, vw93);\n        uint64x2_t vw96 = vandq_u64(vw95, vw93);\n        uint64x2_t vw97 = vaddq_u64(vw96, vw94);\n        uint64x2_t vw98 = vsubq_u64(vw97, vw96);\n        uint64x2_t vw99 = vshrq_n_u64(vw98, 1);\n        uint64x2_t vw100 = veorq_u64(vw99, vw98);\n        uint64x2_t vw101 = vandq_u64(vw100, vw98);\n        uint64x2_t vw102 = vaddq_u64(vw101, vw99);\n        uint64x2_t vw103 = vsubq_u64(vw102, vw101);\n        uint64x2_t vw104 = vshrq_n_u64(vw103, 1);\n        uint64x2_t vw105 = veorq_u64(vw104, vw103);\n        uint64x2_t vw106 = vandq_u64(vw105, vw103);\n        uint64x2_t vw107 = vaddq_u64(vw106, vw104);\n        uint64x2_t vw108 = vsubq_u64(vw107, vw106);\n        uint64x2_t vw109 = vshrq_n_u64(vw108, 1);\n        uint64x2_t vw110 = veorq_u64(vw109, vw108);\n        uint64x2_t vw111 = vandq_u64(vw110, vw108);\n        uint64x2_t vw112 = vaddq_u64(vw111, vw109);\n        uint64x2_t vw113 = vsubq_u64(vw112, vw111);\n        uint64x2_t vw114 = vshrq_n_u64(vw113, 1);\n        uint64x2_t vw115 = veorq_u64(vw114, vw113);\n        uint64x2_t vw116 = vandq_u64(vw115, vw113);\n        uint64x2_t vw117 = vaddq_u64(vw116, vw114);\n        uint64x2_t vw118 = vsubq_u64(vw117, vw116);\n        uint64x2_t vw119 = vshrq_n_u64(vw118, 1);\n        uint64x2_t vw120 = veorq_u64(vw119, vw118);\n        uint64x2_t vw121 = vandq_u64(vw120, vw118);\n        uint64x2_t vw122 = vaddq_u64(vw121, vw119);\n        uint64x2_t vw123 = vsubq_u64(vw122, vw121);\n        uint64x2_t vw124 = vshrq_n_u64(vw123, 1);\n        uint64x2_t vw125 = veorq_u64(vw124, vw123);\n        uint64x2_t vw126 = vandq_u64(vw125, vw123);\n        uint64x2_t vw127 = vaddq_u64(vw126, vw124);\n        uint64x2_t vw128 = vsubq_u64(vw127, vw126);\n        uint64x2_t vw129 = vshrq_n_u64(vw128, 1);\n        uint64x2_t vw130 = veorq_u64(vw129, vw128);\n        uint64x2_t vw131 = vandq_u64(vw130, vw128);\n        uint64x2_t vw132 = vaddq_u64(vw131, vw129);\n        uint64x2_t vw133 = vsubq_u64(vw132, vw131);\n        uint64x2_t vw134 = vshrq_n_u64(vw133, 1);\n        uint64x2_t vw135 = veorq_u64(vw134, vw133);\n        uint64x2_t vw136 = vandq_u64(vw135, vw133);\n        uint64x2_t vw137 = vaddq_u64(vw136, vw134);\n        uint64x2_t vw138 = vsubq_u64(vw137, vw136);\n        uint64x2_t vw139 = vshrq_n_u64(vw138, 1);\n        uint64x2_t vw140 = veorq_u64(vw139, vw138);\n        uint64x2_t vw141 = vandq_u64(vw140, vw138);\n        uint64x2_t vw142 = vaddq_u64(vw141, vw139);\n        uint64x2_t vw143 = vsubq_u64(vw142, vw141);\n        uint64x2_t vw144 = vshrq_n_u64(vw143, 1);\n        uint64x2_t vw145 = veorq_u64(vw144, vw143);\n        uint64x2_t vw146 = vandq_u64(vw145, vw143);\n        uint64x2_t vw147 = vaddq_u64(vw146, vw144);\n        uint64x2_t vw148 = vsubq_u64(vw147, vw146);\n        uint64x2_t vw149 = vshrq_n_u64(vw148, 1);\n        uint64x2_t vw150 = veorq_u64(vw149, vw148);\n        uint64x2_t vw151 = vandq_u64(vw150, vw148);\n        uint64x2_t vw152 = vaddq_u64(vw151, vw149);\n        uint64x2_t vw153 = vsubq_u64(vw152, vw151);\n        uint64x2_t vw154 = vshrq_n_u64(vw153, 1);\n        uint64x2_t vw155 = veorq_u64(vw154, vw153);\n        uint64x2_t vw156 = vandq_u64(vw155, vw153);\n        uint64x2_t vw157 = vaddq_u64(vw156, vw154);\n        uint64x2_t vw158 = vsubq_u64(vw157, vw156);\n        uint64x2_t vw159 = vshrq_n_u64(vw158, 1);\n        uint64x2_t vw160 = veorq_u64(vw159, vw158);\n        uint64x2_t vw161 = vandq_u64(vw160, vw158);\n        uint64x2_t vw162 = vaddq_u64(vw161, vw159);\n        uint64x2_t vw163 = vsubq_u64(vw162, vw161);\n        uint64x2_t vw164 = vshrq_n_u64(vw163, 1);\n        uint64x2_t vw165 = veorq_u64(vw164, vw163);\n        uint64x2_t vw166 = vandq_u64(vw165, vw163);\n        uint64x2_t vw167 = vaddq_u64(vw166, vw164);\n        uint64x2_t vw168 = vsubq_u64(vw167, vw166);\n        uint64x2_t vw169 = vshrq_n_u64(vw168, 1);\n        uint64x2_t vw170 = veorq_u64(vw169, vw168);\n        uint64x2_t vw171 = vandq_u64(vw170, vw168);\n        uint64x2_t vw172 = vaddq_u64(vw171, vw169);\n        uint64x2_t vw173 = vsubq_u64(vw172, vw171);\n        uint64x2_t vw174 = vshrq_n_u64(vw173, 1);\n        uint64x2_t vw175 = veorq_u64(vw174, vw173);\n        uint64x2_t vw176 = vandq_u64(vw175, vw173);\n        uint64x2_t vw177 = vaddq_u64(vw176, vw174);\n        uint64x2_t vw178 = vsubq_u64(vw177, vw176);\n        uint64x2_t vw179 = vshrq_n_u64(vw178, 1);\n        uint64x2_t vw180 = veorq_u64(vw179, vw178);\n        uint64x2_t vw181 = vandq_u64(vw180, vw178);\n        uint64x2_t vw182 = vaddq_u64(vw181, vw179);\n        uint64x2_t vw183 = vsubq_u64(vw182, vw181);\n        uint64x2_t vw184 = vshrq_n_u64(vw183, 1);\n        uint64x2_t vw185 = veorq_u64(vw184, vw183);\n        uint64x2_t vw186 = vandq_u64(vw185, vw183);\n        uint64x2_t vw187 = vaddq_u64(vw186, vw184);\n        uint64x2_t vw188 = vsubq_u64(vw187, vw186);\n        uint64x2_t vw189 = vshrq_n_u64(vw188, 1);\n        uint64x2_t vw190 = veorq_u64(vw189, vw188);\n        uint64x2_t vw191 = vandq_u64(vw190, vw188);\n        uint64x2_t vw192 = vaddq_u64(vw191, vw189);\n        uint64x2_t vw193 = vsubq_u64(vw192, vw191);\n        uint64x2_t vw194 = vshrq_n_u64(vw193, 1);\n        uint64x2_t vw195 = veorq_u64(vw194, vw193);\n        uint64x2_t vw196 = vandq_u64(vw195, vw193);\n        uint64x2_t vw197 = vaddq_u64(vw196, vw194);\n        uint64x2_t vw198 = vsubq_u64(vw197, vw196);\n        uint64x2_t vw199 = vshrq_n_u64(vw198, 1);\n        uint64x2_t vw200 = veorq_u64(vw199, vw198);\n        uint64x2_t vw201 = vandq_u64(vw200, vw198);\n        uint64x2_t vw202 = vaddq_u64(vw201, vw199);\n        uint64x2_t vw203 = vsubq_u64(vw202, vw201);\n        uint64x2_t vw204 = vshrq_n_u64(vw203, 1);\n        uint64x2_t vw205 = veorq_u64(vw204, vw203);\n        uint64x2_t vw206 = vandq_u64(vw205, vw203);\n        uint64x2_t vw207 = vaddq_u64(vw206, vw204);\n        uint64x2_t vw208 = vsubq_u64(vw207, vw206);\n        uint64x2_t vw209 = vshrq_n_u64(vw208, 1);\n        uint64x2_t vw210 = veorq_u64(vw209, vw208);\n        uint64x2_t vw211 = vandq_u64(vw210, vw208);\n        uint64x2_t vw212 = vaddq_u64(vw211, vw209);\n        uint64x2_t vw213 = vsubq_u64(vw212, vw211);\n        uint64x2_t vw214 = vshrq_n_u64(vw213, 1);\n        uint64x2_t vw215 = veorq_u64(vw214, vw213);\n        uint64x2_t vw216 = vandq_u64(vw215, vw213);\n        uint64x2_t vw217 = vaddq_u64(vw216, vw214);\n        uint64x2_t vw218 = vsubq_u64(vw217, vw216);\n        uint64x2_t vw219 = vshrq_n_u64(vw218, 1);\n        uint64x2_t vw220 = veorq_u64(vw219, vw218);\n        uint64x2_t vw221 = vandq_u64(vw220, vw218);\n        uint64x2_t vw222 = vaddq_u64(vw221, vw219);\n        uint64x2_t vw223 = vsubq_u64(vw222, vw221);\n        uint64x2_t vw224 = vshrq_n_u64(vw223, 1);\n        uint64x2_t vw225 = veorq_u64(vw224, vw223);\n        uint64x2_t vw226 = vandq_u64(vw225, vw223);\n        uint64x2_t vw227 = vaddq_u64(vw226, vw224);\n        uint64x2_t vw228 = vsubq_u64(vw227, vw226);\n        uint64x2_t vw229 = vshrq_n_u64(vw228, 1);\n        uint64x2_t vw230 = veorq_u64(vw229, vw228);\n        uint64x2_t vw231 = vandq_u64(vw230, vw228);\n        uint64x2_t vw232 = vaddq_u64(vw231, vw229);\n        uint64x2_t vw233 = vsubq_u64(vw232, vw231);\n        uint64x2_t vw234 = vshrq_n_u64(vw233, 1);\n        uint64x2_t vw235 = veorq_u64(vw234, vw233);\n        uint64x2_t vw236 = vandq_u64(vw235, vw233);\n        uint64x2_t vw237 = vaddq_u64(vw236, vw234);\n        uint64x2_t vw238 = vsubq_u64(vw237, vw236);\n        uint64x2_t vw239 = vshrq_n_u64(vw238, 1);\n        uint64x2_t vw240 = veorq_u64(vw239, vw238);\n        uint64x2_t vw241 = vandq_u64(vw240, vw238);\n        uint64x2_t vw242 = vaddq_u64(vw241, vw239);\n        uint64x2_t vw243 = vsubq_u64(vw242, vw241);\n        uint64x2_t vw244 = vshrq_n_u64(vw243, 1);\n        uint64x2_t vw245 = veorq_u64(vw244, vw243);\n        uint64x2_t vw246 = vandq_u64(vw245, vw243);\n        uint64x2_t vw247 = vaddq_u64(vw246, vw244);\n        uint64x2_t vw248 = vsubq_u64(vw247, vw246);\n        uint64x2_t vw249 = vshrq_n_u64(vw248, 1);\n        uint64x2_t vw250 = veorq_u64(vw249, vw248);\n        uint64x2_t vw251 = vandq_u64(vw250, vw248);\n        uint64x2_t vw252 = vaddq_u64(vw251, vw249);\n        uint64x2_t vw253 = vsubq_u64(vw252, vw251);\n        uint64x2_t vw254 = vshrq_n_u64(vw253, 1);\n        uint64x2_t vw255 = veorq_u64(vw254, vw253);\n        uint64x2_t vw256 = vandq_u64(vw255, vw253);\n        uint64x2_t vw257 = vaddq_u64(vw256, vw254);\n        uint64x2_t vw258 = vsubq_u64(vw257, vw256);\n        uint64x2_t vw259 = vshrq_n_u64(vw258, 1);\n        uint64x2_t vw260 = veorq_u64(vw259, vw258);\n        uint64x2_t vw261 = vandq_u64(vw260, vw258);\n        uint64x2_t vw262 = vaddq_u64(vw261, vw259);\n        uint64x2_t vw263 = vsubq_u64(vw262, vw261);\n        uint64x2_t vw264 = vshrq_n_u64(vw263, 1);\n        uint64x2_t vw265 = veorq_u64(vw264, vw263);\n        uint64x2_t vw266 = vandq_u64(vw265, vw263);\n        uint64x2_t vw267 = vaddq_u64(vw266, vw264);\n        uint64x2_t vw268 = vsubq_u64(vw267, vw266);\n        uint64x2_t vw269 = vshrq_n_u64(vw268, 1);\n        uint64x2_t vw270 = veorq_u64(vw269, vw268);\n        uint64x2_t vw271 = vandq_u64(vw270, vw268);\n        uint64x2_t vw272 = vaddq_u64(vw271, vw269);\n        uint64x2_t vw273 = vsubq_u64(vw272, vw271);\n        uint64x2_t vw274 = vshrq_n_u64(vw273, 1);\n        uint64x2_t vw275 = veorq_u64(vw274, vw273);\n        uint64x2_t vw276 = vandq_u64(vw275, vw273);\n        uint64x2_t vw277 = vaddq_u64(vw276, vw274);\n        uint64x2_t vw278 = vsubq_u64(vw277, vw2"}
{"task_id": "SimdBench_70_Neon", "completion": "```c\n#include <arm_neon.h>\n\nuint64_t greatest_common_divisor_simd(uint64_t a, uint64_t b) {\n    uint64x2_t va = vdupq_n_u64(a);\n    uint64x2_t vb = vdupq_n_u64(b);\n\n    while (!veorq_p8(vceqq_u64(va, vb))) {\n        uint64x2_t vmask = vcltq_u64(va, vb);\n        va = vbslq_u64(vmask, vb, va);\n        vb = vbslq_u64(vmask, va - vb, vb);\n    }\n\n    return va[0];\n}\n```"}
{"task_id": "SimdBench_71_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <algorithm>\n#include <cmath>\n\nstd::vector<float> find_closest_elements_simd(const std::vector<float>& numbers) {\n    if (numbers.size() < 2) {\n        throw std::invalid_argument(\"Input vector must contain at least two elements\");\n    }\n\n    float32x4_t min_diff = vdupq_n_f32(INFINITY);\n    float32x4_t closest_pair[2];\n\n    int n = numbers.size();\n    for (int i = 0; i + 7 < n; i += 8) {\n        float32x4_t vec1 = vld1q_f32(&numbers[i]);\n        float32x4_t vec2 = vld1q_f32(&numbers[i + 4]);\n\n        float32x4_t diff1 = vsubq_f32(vec1, vec2);\n        float32x4_t diff2 = vabsq_f32(diff1);\n\n        uint32x4_t mask = vcgtq_f32(min_diff, diff2);\n        min_diff = vbslq_f32(mask, diff2, min_diff);\n        closest_pair[0] = vbslq_f32(mask, vec1, closest_pair[0]);\n        closest_pair[1] = vbslq_f32(mask, vec2, closest_pair[1]);\n    }\n\n    // Handle remaining elements\n    for (int i = n - n % 8; i < n; ++i) {\n        for (int j = i + 1; j < n; ++j) {\n            float diff = std::abs(numbers[i] - numbers[j]);\n            if (diff < min_diff[0]) {\n                min_diff[0] = diff;\n                closest_pair[0][0] = std::min(numbers[i], numbers[j]);\n                closest_pair[1][0] = std::max(numbers[i], numbers[j]);\n            }\n        }\n    }\n\n    std::sort(closest_pair[0], closest_pair[0] + 2);\n    return {closest_pair[0][0], closest_pair[0][1]};\n}\n```"}
{"task_id": "SimdBench_71_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <limits>\n#include <algorithm>\n\nstd::vector<float> find_closest_elements_simd(const std::vector<float>& numbers) {\n    if (numbers.size() < 2) {\n        throw std::invalid_argument(\"Input vector must contain at least two elements\");\n    }\n\n    float32x4_t min_diff = vdupq_n_f32(std::numeric_limits<float>::max());\n    float32x4_t closest_pair[2];\n\n    int n = numbers.size();\n    for (int i = 0; i < n - 3; i += 4) {\n        float32x4_t vec1 = vld1q_f32(&numbers[i]);\n        float32x4_t vec2 = vld1q_f32(&numbers[i + 4]);\n\n        float32x4_t diff = vabsq_f32(vsubq_f32(vec1, vec2));\n        uint32x4_t mask = vcgtq_f32(diff, min_diff);\n        min_diff = vminq_f32(min_diff, diff);\n\n        float32x4_t selected = vbslq_f32(mask, vec1, vec2);\n        vst1q_f32(closest_pair, selected);\n    }\n\n    // Handle remaining elements\n    for (int i = n - 4; i < n - 1; ++i) {\n        float diff = std::abs(numbers[i] - numbers[i + 1]);\n        if (diff < min_diff) {\n            min_diff = diff;\n            closest_pair[0] = numbers[i];\n            closest_pair[1] = numbers[i + 1];\n        }\n    }\n\n    std::sort(closest_pair, closest_pair + 2);\n    return {closest_pair[0], closest_pair[1]};\n}\n```"}
{"task_id": "SimdBench_71_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<float> find_closest_elements_simd(const std::vector<float>& numbers) {\n    if (numbers.size() < 2) {\n        throw std::invalid_argument(\"Input vector must contain at least two elements\");\n    }\n\n    float32x4_t v_min = vdupq_n_f32(INFINITY);\n    float32x4_t v_max = vdupq_n_f32(-INFINITY);\n\n    for (size_t i = 0; i <= numbers.size() - 4; i += 4) {\n        float32x4_t v_current = vld1q_f32(&numbers[i]);\n        v_min = vminq_f32(v_min, v_current);\n        v_max = vmaxq_f32(v_max, v_current);\n    }\n\n    float min[4], max[4];\n    vst1q_f32(min, v_min);\n    vst1q_f32(max, v_max);\n\n    float closest_diff = INFINITY;\n    float closest_pair[2] = {0.0f, 0.0f};\n\n    for (int i = 0; i < 4; ++i) {\n        for (int j = i + 1; j < 4; ++j) {\n            float diff = std::abs(min[i] - min[j]);\n            if (diff < closest_diff) {\n                closest_diff = diff;\n                closest_pair[0] = std::min(min[i], min[j]);\n                closest_pair[1] = std::max(min[i], min[j]);\n            }\n        }\n    }\n\n    for (int i = 0; i < 4; ++i) {\n        for (int j = i + 1; j < 4; ++j) {\n            float diff = std::abs(max[i] - max[j]);\n            if (diff < closest_diff) {\n                closest_diff = diff;\n                closest_pair[0] = std::min(max[i], max[j]);\n                closest_pair[1] = std::max(max[i], max[j]);\n            }\n        }\n    }\n\n    for (size_t i = 4 * ((numbers.size() + 3) / 4); i < numbers.size(); ++i) {\n        float current = numbers[i];\n        if (current < closest_pair[0]) {\n            closest_pair[1] = closest_pair[0];\n            closest_pair[0] = current;\n        } else if (current > closest_pair[1]) {\n            closest_pair[1] = current;\n        }\n    }\n\n    return {closest_pair[0], closest_pair[1]};\n}\n```"}
{"task_id": "SimdBench_71_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <limits>\n#include <algorithm>\n\nstd::vector<float> find_closest_elements_simd(const std::vector<float>& numbers) {\n    if (numbers.size() < 2) {\n        throw std::invalid_argument(\"Input vector must contain at least two elements\");\n    }\n\n    float min_diff = std::numeric_limits<float>::max();\n    std::pair<float, float> closest_pair;\n\n    int n = numbers.size();\n    for (int i = 0; i < n - 1; i += 8) {\n        float32x4_t vec1 = vld1q_f32(&numbers[i]);\n        float32x4_t vec2 = vld1q_f32(&numbers[i + 4]);\n\n        float32x4_t diff1 = vabsq_f32(vsubq_f32(vec1, vec2));\n        uint32x4_t mask1 = vcgtq_f32(diff1, vdupq_n_f32(min_diff));\n\n        float32x4_t diff2 = vabsq_f32(vsubq_f32(vec1, vextq_f32(vec2, vec2, 1)));\n        uint32x4_t mask2 = vcgtq_f32(diff2, vdupq_n_f32(min_diff));\n\n        float32x4_t diff3 = vabsq_f32(vsubq_f32(vec1, vextq_f32(vec2, vec2, 2)));\n        uint32x4_t mask3 = vcgtq_f32(diff3, vdupq_n_f32(min_diff));\n\n        float32x4_t diff4 = vabsq_f32(vsubq_f32(vec1, vextq_f32(vec2, vec2, 3)));\n        uint32x4_t mask4 = vcgtq_f32(diff4, vdupq_n_f32(min_diff));\n\n        uint32x4_t mask = vorrq_u32(mask1, mask2);\n        mask = vorrq_u32(mask, mask3);\n        mask = vorrq_u32(mask, mask4);\n\n        float32x4_t min_diff_vec = vminq_f32(diff1, diff2);\n        min_diff_vec = vminq_f32(min_diff_vec, diff3);\n        min_diff_vec = vminq_f32(min_diff_vec, diff4);\n\n        min_diff = vgetq_lane_f32(min_diff_vec, 0);\n\n        uint32x4_t min_index = vmovemask_u32(mask);\n        if (min_index != 0) {\n            int index = __builtin_ctz(min_index);\n            float num1 = numbers[i + index];\n            float num2 = numbers[i + index + 1];\n\n            if (num1 > num2) {\n                std::swap(num1, num2);\n            }\n\n            if (num2 - num1 < min_diff) {\n                min_diff = num2 - num1;\n                closest_pair = {num1, num2};\n            }\n        }\n    }\n\n    // Handle remaining elements\n    for (size_t i = n - 1; i >= 1; --i) {\n        float diff = std::abs(numbers[i] - numbers[i - 1]);\n        if (diff < min_diff) {\n            min_diff = diff;\n            closest_pair = {std::min(numbers[i], numbers[i - 1]), std::max(numbers[i], numbers[i - 1])};\n        }\n    }\n\n    return {closest_pair.first, closest_pair.second};\n}\n```"}
{"task_id": "SimdBench_71_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<float> find_closest_elements_simd(const std::vector<float>& numbers) {\n    if (numbers.size() < 2) {\n        throw std::invalid_argument(\"Input vector must contain at least two elements\");\n    }\n\n    float32x4_t v_min = vdupq_n_f32(INFINITY);\n    float32x4_t v_max = vdupq_n_f32(-INFINITY);\n\n    for (size_t i = 0; i <= numbers.size() - 4; i += 4) {\n        float32x4_t v_nums = vld1q_f32(&numbers[i]);\n        v_min = vminq_f32(v_min, v_nums);\n        v_max = vmaxq_f32(v_max, v_nums);\n    }\n\n    float min[4];\n    float max[4];\n    vst1q_f32(min, v_min);\n    vst1q_f32(max, v_max);\n\n    float closest_diff = INFINITY;\n    float closest_pair[2] = {0.0f, 0.0f};\n\n    for (int i = 0; i < 4; ++i) {\n        for (int j = i + 1; j < 4; ++j) {\n            float diff = std::abs(min[i] - min[j]);\n            if (diff < closest_diff) {\n                closest_diff = diff;\n                closest_pair[0] = std::min(min[i], min[j]);\n                closest_pair[1] = std::max(min[i], min[j]);\n            }\n        }\n    }\n\n    for (size_t i = 4 * (numbers.size() / 4); i < numbers.size(); ++i) {\n        float num = numbers[i];\n        if (num < closest_pair[0]) {\n            closest_pair[0] = num;\n        } else if (num > closest_pair[1]) {\n            closest_pair[1] = num;\n        }\n    }\n\n    return std::vector<float>{closest_pair[0], closest_pair[1]};\n}\n```"}
{"task_id": "SimdBench_72_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<float> rescale_to_unit_simd(const std::vector<float>& numbers) {\n    int n = numbers.size();\n    if (n < 2) return numbers;\n\n    float32x4_t min_val = vdupq_n_f32(FLT_MAX);\n    float32x4_t max_val = vdupq_n_f32(-FLT_MAX);\n\n    // Process in chunks of 4\n    for (int i = 0; i <= n - 4; i += 4) {\n        float32x4_t vec = vld1q_f32(&numbers[i]);\n        min_val = vminq_f32(min_val, vec);\n        max_val = vmaxq_f32(max_val, vec);\n    }\n\n    // Handle remaining elements\n    for (int i = n - n % 4; i < n; ++i) {\n        min_val = vminnmvq_f32(min_val, vld1q_lane_f32(&numbers[i], vdupq_n_f32(numbers[i]), 0));\n        max_val = vmaxnmvq_f32(max_val, vld1q_lane_f32(&numbers[i], vdupq_n_f32(numbers[i]), 0));\n    }\n\n    float min_val_scalar = vgetq_lane_f32(min_val, 0);\n    float max_val_scalar = vgetq_lane_f32(max_val, 0);\n\n    std::vector<float> result(n);\n    for (int i = 0; i <= n - 4; i += 4) {\n        float32x4_t vec = vld1q_f32(&numbers[i]);\n        float32x4_t scaled_vec = vmulq_f32(vsubq_f32(vec, vdupq_n_f32(min_val_scalar)), vrecipq_f32(vsubq_f32(vdupq_n_f32(max_val_scalar), vdupq_n_f32(min_val_scalar))));\n        vst1q_f32(&result[i], scaled_vec);\n    }\n\n    // Handle remaining elements\n    for (int i = n - n % 4; i < n; ++i) {\n        result[i] = (numbers[i] - min_val_scalar) / (max_val_scalar - min_val_scalar);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_72_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<float> rescale_to_unit_simd(const std::vector<float>& numbers) {\n    int n = numbers.size();\n    if (n < 2) return numbers;\n\n    float32x4_t min_val = vdupq_n_f32(FLT_MAX);\n    float32x4_t max_val = vdupq_n_f32(-FLT_MAX);\n\n    // Process in chunks of 4\n    for (int i = 0; i <= n - 4; i += 4) {\n        float32x4_t vec = vld1q_f32(&numbers[i]);\n        min_val = vminq_f32(min_val, vec);\n        max_val = vmaxq_f32(max_val, vec);\n    }\n\n    // Handle remaining elements\n    for (int i = n - n % 4; i < n; ++i) {\n        min_val[0] = fminf(min_val[0], numbers[i]);\n        max_val[0] = fmaxf(max_val[0], numbers[i]);\n    }\n\n    float min_val_scalar = vgetq_lane_f32(min_val, 0);\n    float max_val_scalar = vgetq_lane_f32(max_val, 0);\n\n    std::vector<float> result(n);\n    float range = max_val_scalar - min_val_scalar;\n    if (range == 0.0f) return result; // Avoid division by zero\n\n    // Process in chunks of 4\n    for (int i = 0; i <= n - 4; i += 4) {\n        float32x4_t vec = vld1q_f32(&numbers[i]);\n        float32x4_t scaled_vec = vmulq_f32(vsubq_f32(vec, vdupq_n_f32(min_val_scalar)), vrecipq_f32(vdupq_n_f32(range)));\n        vst1q_f32(&result[i], scaled_vec);\n    }\n\n    // Handle remaining elements\n    for (int i = n - n % 4; i < n; ++i) {\n        result[i] = (numbers[i] - min_val_scalar) / range;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_72_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<float> rescale_to_unit_simd(const std::vector<float>& numbers) {\n    int n = numbers.size();\n    if (n < 2) return numbers;\n\n    float32x4_t min_val = vdupq_n_f32(FLT_MAX);\n    float32x4_t max_val = vdupq_n_f32(-FLT_MAX);\n\n    // Process in chunks of 4\n    for (int i = 0; i <= n - 4; i += 4) {\n        float32x4_t vec = vld1q_f32(&numbers[i]);\n        min_val = vminq_f32(min_val, vec);\n        max_val = vmaxq_f32(max_val, vec);\n    }\n\n    // Handle remaining elements\n    for (int i = n - n % 4; i < n; ++i) {\n        min_val = vminnmvq_f32(min_val, vld1q_lane_f32(&numbers[i], vdupq_n_f32(numbers[i]), 0));\n        max_val = vmaxnmvq_f32(max_val, vld1q_lane_f32(&numbers[i], vdupq_n_f32(numbers[i]), 0));\n    }\n\n    float min_val_scalar = vgetq_lane_f32(min_val, 0);\n    float max_val_scalar = vgetq_lane_f32(max_val, 0);\n\n    std::vector<float> result(n);\n    for (int i = 0; i <= n - 4; i += 4) {\n        float32x4_t vec = vld1q_f32(&numbers[i]);\n        float32x4_t scaled_vec = vmulq_f32(vsubq_f32(vec, vdupq_n_f32(min_val_scalar)), vrsqrteq_f32(vdupq_n_f32(max_val_scalar - min_val_scalar)));\n        vst1q_f32(&result[i], scaled_vec);\n    }\n\n    // Handle remaining elements\n    for (int i = n - n % 4; i < n; ++i) {\n        result[i] = (numbers[i] - min_val_scalar) / (max_val_scalar - min_val_scalar);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_72_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<float> rescale_to_unit_simd(const std::vector<float>& numbers) {\n    int n = numbers.size();\n    if (n < 2) return numbers;\n\n    float32x4_t min_val = vdupq_n_f32(FLT_MAX);\n    float32x4_t max_val = vdupq_n_f32(-FLT_MAX);\n\n    // Process in chunks of 4\n    for (int i = 0; i <= n - 4; i += 4) {\n        float32x4_t vec = vld1q_f32(&numbers[i]);\n        min_val = vminq_f32(min_val, vec);\n        max_val = vmaxq_f32(max_val, vec);\n    }\n\n    // Handle remaining elements\n    for (int i = n - n % 4; i < n; ++i) {\n        min_val = vminnmvq_f32(min_val, vld1q_lane_f32(&numbers[i], vdupq_n_f32(numbers[i]), 0));\n        max_val = vmaxnmvq_f32(max_val, vld1q_lane_f32(&numbers[i], vdupq_n_f32(numbers[i]), 0));\n    }\n\n    float min_val_scalar = vgetq_lane_f32(min_val, 0);\n    float max_val_scalar = vgetq_lane_f32(max_val, 0);\n\n    std::vector<float> result(n);\n    for (int i = 0; i < n; ++i) {\n        result[i] = (numbers[i] - min_val_scalar) / (max_val_scalar - min_val_scalar);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_72_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<float> rescale_to_unit_simd(const std::vector<float>& numbers) {\n    int n = numbers.size();\n    if (n < 2) return numbers;\n\n    float32x4_t min_val = vdupq_n_f32(FLT_MAX);\n    float32x4_t max_val = vdupq_n_f32(-FLT_MAX);\n\n    // Process in chunks of 4\n    for (int i = 0; i <= n - 4; i += 4) {\n        float32x4_t vec = vld1q_f32(&numbers[i]);\n        min_val = vminq_f32(min_val, vec);\n        max_val = vmaxq_f32(max_val, vec);\n    }\n\n    // Handle remaining elements\n    for (int i = n - n % 4; i < n; ++i) {\n        min_val[0] = fminf(min_val[0], numbers[i]);\n        max_val[0] = fmaxf(max_val[0], numbers[i]);\n    }\n\n    float min_val_scalar = vgetq_lane_f32(min_val, 0);\n    float max_val_scalar = vgetq_lane_f32(max_val, 0);\n\n    std::vector<float> result(n);\n    float scale = 1.0 / (max_val_scalar - min_val_scalar);\n\n    // Process in chunks of 4\n    for (int i = 0; i <= n - 4; i += 4) {\n        float32x4_t vec = vld1q_f32(&numbers[i]);\n        vec = vmulq_f32(vsubq_f32(vec, vdupq_n_f32(min_val_scalar)), vdupq_n_f32(scale));\n        vst1q_f32(&result[i], vec);\n    }\n\n    // Handle remaining elements\n    for (int i = n - n % 4; i < n; ++i) {\n        result[i] = (numbers[i] - min_val_scalar) * scale;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_73_Neon", "completion": "```c\n#include <arm_neon.h>\n\nuint64_t largest_divisor_simd(uint64_t n) {\n    uint64x2_t v = vdupq_n_u64(n);\n    uint64x2_t divisors = vmulq_u64(v, vdupq_n_u64(1));\n    uint64x2_t mask = vcltq_u64(divisors, vsubq_u64(v, vdupq_n_u64(1)));\n    divisors = vbicq_u64(divisors, mask);\n    uint64_t result = vmaxvq_u64(divisors);\n    return result;\n}\n```"}
{"task_id": "SimdBench_73_Neon", "completion": "```c\n#include <arm_neon.h>\n\nuint64_t largest_divisor_simd(uint64_t n) {\n    uint64x2_t v = vdupq_n_u64(n);\n    uint64x2_t divisors = vmulq_u64(v, vdupq_n_u64(1));\n    uint64x2_t mask = vcltq_u64(divisors, vsubq_u64(v, vdupq_n_u64(1)));\n    divisors = vbicq_u64(divisors, mask);\n    uint64_t result = vmaxvq_u64(divisors);\n    return result;\n}\n```"}
{"task_id": "SimdBench_73_Neon", "completion": "```c\n#include <arm_neon.h>\n\nuint64_t largest_divisor_simd(uint64_t n) {\n    uint64x2_t v = vdupq_n_u64(n);\n    uint64x2_t divisors = vmulq_u64(v, vdupq_n_u64(1));\n    uint64x2_t mask = vcltq_u64(divisors, vsubq_u64(v, vdupq_n_u64(1)));\n    divisors = vbicq_u64(divisors, mask);\n    uint64_t result = vmaxvq_u64(divisors);\n    return result;\n}\n```"}
{"task_id": "SimdBench_73_Neon", "completion": "```c\n#include <arm_neon.h>\n\nuint64_t largest_divisor_simd(uint64_t n) {\n    uint64x2_t v = vdupq_n_u64(n);\n    uint64x2_t divisors = vmulq_u64(v, vdupq_n_u64(1));\n    uint64x2_t mask = vcltq_u64(divisors, vsubq_u64(v, vdupq_n_u64(1)));\n    divisors = vbicq_u64(divisors, mask);\n    uint64_t result = vmaxvq_u64(divisors);\n    return result;\n}\n```"}
{"task_id": "SimdBench_73_Neon", "completion": "```c\n#include <arm_neon.h>\n\nuint64_t largest_divisor_simd(uint64_t n) {\n    uint64x2_t v = vdupq_n_u64(n);\n    uint64x2_t divisors = vmulq_u64(v, vdupq_n_u64(1));\n    uint64x2_t mask = vcltq_u64(divisors, vsubq_u64(v, vdupq_n_u64(1)));\n    divisors = vbicq_u64(divisors, mask);\n    uint64_t result = vmaxvq_u64(divisors);\n    return result;\n}\n```"}
{"task_id": "SimdBench_74_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int> factorize_simd(int n) {\n    std::vector<int> factors;\n    uint32x4_t v = vdupq_n_u32(n);\n    uint32x4_t primes = vld1q_u32((const uint32_t[]){2, 3, 5, 7});\n    uint32x4_t mask = vmovq_n_u32(0);\n\n    while (!vmovn_u32(v).v[0]) {\n        uint32x4_t div = vdivq_u32(v, primes);\n        uint32x4_t rem = vmodq_u32(v, primes);\n        mask = veorq_u32(mask, vceqq_u32(rem, vdupq_n_u32(0)));\n        v = vandq_u32(v, div);\n        factors.insert(factors.end(), 4, primes[mask]);\n    }\n\n    return factors;\n}\n```"}
{"task_id": "SimdBench_74_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int> factorize_simd(int n) {\n    std::vector<int> factors;\n    int i = 2;\n    while (n > 1) {\n        if (n % i == 0) {\n            factors.push_back(i);\n            n /= i;\n        } else {\n            i++;\n        }\n    }\n    return factors;\n}\n```"}
{"task_id": "SimdBench_74_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int> factorize_simd(int n) {\n    std::vector<int> factors;\n    uint32x4_t v = vdupq_n_u32(n);\n    uint32x4_t primes = vld1q_u32((const uint32_t[]){2, 3, 5, 7});\n    uint32x4_t mask = vmovq_n_u32(0);\n\n    while (!vallq_s32(mask)) {\n        uint32x4_t remainder = vmodq_u32(v, primes);\n        mask = vceqq_u32(remainder, vdupq_n_u32(0));\n        v = vsubq_u32(v, vandq_u32(v, mask));\n        v = vshrq_n_u32(v, 1);\n        factors.insert(factors.end(), 4, 0);\n        for (int i = 0; i < 4; ++i) {\n            if (mask[i]) {\n                factors[factors.size() - 4 + i] = primes[i];\n            }\n        }\n    }\n\n    return factors;\n}\n```"}
{"task_id": "SimdBench_74_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int> factorize_simd(int n) {\n    std::vector<int> factors;\n    uint32x4_t v = vdupq_n_u32(n);\n    uint32x4_t primes = vld1q_u32((const uint32_t[]){2, 3, 5, 7});\n    uint32x4_t mask = vmovq_n_u32(0);\n\n    while (!vmovn_u32(v).v[0]) {\n        uint32x4_t div = vdivq_u32(v, primes);\n        uint32x4_t rem = vmodq_u32(v, primes);\n        mask = veorq_u32(mask, vceqq_u32(rem, vdupq_n_u32(0)));\n        v = vandq_u32(v, div);\n        factors.insert(factors.end(), 4, primes[mask]);\n    }\n\n    return factors;\n}\n```"}
{"task_id": "SimdBench_74_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int> factorize_simd(int n) {\n    std::vector<int> factors;\n    uint32x4_t v = vdupq_n_u32(n);\n    uint32x4_t primes = vld1q_u32((const uint32_t[]){2, 3, 5, 7});\n    uint32x4_t mask = vmovq_n_u32(0);\n\n    while (!vmovn_u32(v).v[0]) {\n        uint32x4_t div = vdivq_u32(v, primes);\n        uint32x4_t rem = vmodq_u32(v, primes);\n        mask = veorq_u32(mask, vceqq_u32(rem, vdupq_n_u32(0)));\n        v = vandq_u32(v, div);\n        factors.insert(factors.end(), 4, primes[mask]);\n    }\n\n    return factors;\n}\n```"}
{"task_id": "SimdBench_75_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<float> get_positive_simd(const std::vector<float> & l) {\n    const int n = l.size();\n    std::vector<float> result(n);\n    float32x4_t vzero = vdupq_n_f32(0.0f);\n\n    for (int i = 0; i <= n - 4; i += 4) {\n        float32x4_t vin = vld1q_f32(&l[i]);\n        float32x4_t vout = vmaxq_f32(vin, vzero);\n        vst1q_f32(&result[i], vout);\n    }\n\n    // Handle remaining elements\n    for (int i = n - n % 4; i < n; ++i) {\n        if (l[i] > 0) {\n            result[i] = l[i];\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_75_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<float> get_positive_simd(const std::vector<float> & l) {\n    int n = l.size();\n    std::vector<float> result;\n    float32x4_t vzero = vdupq_n_f32(0.0f);\n    float32x4_t vone = vdupq_n_f32(1.0f);\n\n    for (int i = 0; i <= n - 4; i += 4) {\n        float32x4_t vec = vld1q_f32(&l[i]);\n        uint32x4_t mask = vcgtq_f32(vec, vzero);\n        float32x4_t selected = vmulq_f32(vone, vcvtq_u32_f32(mask));\n        float32x4_t multiplied = vmulq_f32(vec, selected);\n        vst1q_f32(&result[i], multiplied);\n    }\n\n    // Handle remaining elements\n    for (int i = n - n % 4; i < n; ++i) {\n        if (l[i] > 0) {\n            result.push_back(l[i]);\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_75_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<float> get_positive_simd(const std::vector<float> & l) {\n    const int n = l.size();\n    std::vector<float> result(n);\n    float32x4_t vzero = vdupq_n_f32(0.0f);\n\n    for (int i = 0; i <= n - 4; i += 4) {\n        float32x4_t vin = vld1q_f32(&l[i]);\n        float32x4_t vout = vmaxq_f32(vin, vzero);\n        vst1q_f32(&result[i], vout);\n    }\n\n    // Handle remaining elements\n    for (int i = n - n % 4; i < n; ++i) {\n        if (l[i] > 0) {\n            result[i] = l[i];\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_75_Neon", "completion": "```cpp\nstd::vector<float> get_positive_simd(const std::vector<float> & l) {\n    std::vector<float> result;\n    int n = l.size();\n    float32x4_t vzero = vdupq_n_f32(0.0f);\n    for (int i = 0; i <= n - 4; i += 4) {\n        float32x4_t vin = vld1q_f32(&l[i]);\n        uint32x4_t vmask = vcgtq_f32(vin, vzero);\n        float32x4_t vout = vbslq_f32(vmask, vin, vzero);\n        vst1q_f32(&result[i], vout);\n    }\n    for (int i = n - n % 4; i < n; ++i) {\n        if (l[i] > 0) {\n            result.push_back(l[i]);\n        }\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_75_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<float> get_positive_simd(const std::vector<float> & l) {\n    int n = l.size();\n    std::vector<float> result;\n    float32x4_t vzero = vdupq_n_f32(0.0f);\n    float32x4_t vone = vdupq_n_f32(1.0f);\n\n    for (int i = 0; i <= n - 4; i += 4) {\n        float32x4_t vin = vld1q_f32(&l[i]);\n        float32x4_t vcmp = vcgtq_f32(vin, vzero);\n        uint32x4_t vmask = vreinterpretq_u32_u8(vmovn_u16(vreinterpretq_u16_u32(vmask)));\n        float32x4_t vout = vbslq_f32(vcmp, vin, vzero);\n        vst1q_f32(&result[i], vout);\n    }\n\n    // Handle remaining elements\n    for (int i = n - n % 4; i < n; ++i) {\n        if (l[i] > 0) {\n            result.push_back(l[i]);\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_76_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <stdbool.h>\n\nbool is_prime_simd(int64_t n) {\n    if (n <= 1) return false;\n    if (n == 2 || n == 3) return true;\n    if (n % 2 == 0 || n % 3 == 0) return false;\n\n    int64x2_t v = {5, 7};\n    int64x2_t step = {6, 6};\n\n    while (v[0] * v[0] <= n || v[1] * v[1] <= n) {\n        if (n % v[0] == 0 || n % v[1] == 0) return false;\n        v += step;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_76_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <stdbool.h>\n\nbool is_prime_simd(int64_t n) {\n    if (n <= 1) return false;\n    if (n == 2 || n == 3) return true;\n    if (n % 2 == 0 || n % 3 == 0) return false;\n\n    int64x2_t v = {5, 7};\n    int64x2_t step = {2, 4};\n\n    while (v[0] * v[0] <= n) {\n        if ((n % v[0] == 0) || (n % v[1] == 0)) return false;\n        v += step;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_76_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <stdbool.h>\n\nbool is_prime_simd(int64_t n) {\n    if (n <= 1) return false;\n    if (n == 2 || n == 3) return true;\n    if (n % 2 == 0 || n % 3 == 0) return false;\n\n    int64x2_t v = {5, 7};\n    int64x2_t step = {6, 6};\n\n    while (v[0] * v[0] <= n || v[1] * v[1] <= n) {\n        if (n % v[0] == 0 || n % v[1] == 0) return false;\n        v += step;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_76_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <stdbool.h>\n\nbool is_prime_simd(int64_t n) {\n    if (n <= 1) return false;\n    if (n == 2 || n == 3) return true;\n    if (n % 2 == 0 || n % 3 == 0) return false;\n\n    int64x2_t v = {5, 7};\n    int64x2_t step = {2, 4};\n\n    while (v[0] * v[0] <= n) {\n        if ((n % v[0] == 0) || (n % v[1] == 0)) return false;\n        v += step;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_76_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <stdbool.h>\n\nbool is_prime_simd(int64_t n) {\n    if (n <= 1) return false;\n    if (n == 2 || n == 3) return true;\n    if (n % 2 == 0 || n % 3 == 0) return false;\n\n    int64x2_t v = {5, 7};\n    int64x2_t step = {6, 6};\n\n    while (v[0] * v[0] <= n || v[1] * v[1] <= n) {\n        if ((n % v[0] == 0) || (n % v[1] == 0)) return false;\n        v += step;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_77_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nstd::string solve_simd(const std::string & s) {\n    const int len = s.length();\n    if (len == 0) return s;\n\n    std::string result(len, '\\0');\n    const char* input = s.c_str();\n\n    int i = 0;\n    while (i + 15 < len) {\n        uint8x16_t vec = vld1q_u8(reinterpret_cast<const uint8_t*>(input + i));\n        uint8x16_t mask = vmovq_n_u8(0x60); // Mask for checking lowercase letters\n        uint8x16_t is_lower = vtstq_u8(vec, mask);\n        uint8x16_t is_upper = vtstq_u8(vec, vmovq_n_u8(0x40)); // Mask for checking uppercase letters\n\n        uint8x16_t lower_to_upper = vsubq_u8(vandq_u8(is_lower, vec), vmulq_n_u8(is_lower, vmovq_n_u8(0x20)));\n        uint8x16_t upper_to_lower = vaddq_u8(vandq_u8(is_upper, vec), vmulq_n_u8(is_upper, vmovq_n_u8(0x20)));\n\n        uint8x16_t result_vec = vorrq_u8(lower_to_upper, upper_to_lower);\n\n        vst1q_u8(reinterpret_cast<uint8_t*>(result.data() + i), result_vec);\n\n        i += 16;\n    }\n\n    while (i < len) {\n        char c = input[i];\n        if ((c >= 'a' && c <= 'z') || (c >= 'A' && c <= 'Z')) {\n            c ^= 0x20; // Toggle case\n        }\n        result[i] = c;\n        ++i;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_77_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nstd::string solve_simd(const std::string & s) {\n    const int len = s.length();\n    if (len == 0) return s;\n\n    std::string result(len, '\\0');\n    const char* input = s.c_str();\n\n    int i = 0;\n    for (; i <= len - 16; i += 16) {\n        uint8x16_t vec = vld1q_u8((const uint8_t*)&input[i]);\n        uint8x16_t mask = vmovq_n_u8(0x5F); // ASCII difference between lowercase and uppercase\n\n        uint8x16_t is_letter = vandq_u8(vec, vmovq_n_u8(0x7F)); // Mask out non-ASCII characters\n        uint8x16_t is_upper = vandq_u8(is_letter, vmovq_n_u8(0x5F)); // Check if uppercase\n        uint8x16_t is_lower = vandq_u8(is_letter, vmovq_n_u8(0x20)); // Check if lowercase\n\n        uint8x16_t upper_to_lower = vsubq_u8(is_upper, mask);\n        uint8x16_t lower_to_upper = vaddq_u8(is_lower, mask);\n\n        uint8x16_t output = vbslq_u8(is_upper, lower_to_upper, vbslq_u8(is_lower, upper_to_lower, vec));\n\n        vst1q_u8((uint8_t*)&result[i], output);\n    }\n\n    for (; i < len; ++i) {\n        char c = input[i];\n        if ((c >= 'a' && c <= 'z') || (c >= 'A' && c <= 'Z')) {\n            result[i] = c ^ 0x20;\n        } else {\n            result[i] = c;\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_77_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nstd::string solve_simd(const std::string & s) {\n    const char* input = s.c_str();\n    size_t length = s.length();\n    std::string result(length, '\\0');\n\n    size_t i = 0;\n    while (i + 15 < length) {\n        uint8x16_t vec = vld1q_u8((const uint8_t*)(input + i));\n        uint8x16_t mask = vmovq_n_u8(0x20);\n        uint8x16_t is_alpha = vandq_u8(vec, vmovq_n_u8(0x7F));\n        uint8x16_t is_lower = vandq_u8(is_alpha, vmovq_n_u8(0x20));\n        uint8x16_t is_upper = vandq_u8(is_alpha, vmovq_n_u8(0x5F));\n\n        uint8x16_t lower_to_upper = vbicq_u8(is_lower, mask);\n        uint8x16_t upper_to_lower = vbicq_u8(is_upper, mask);\n\n        uint8x16_t output = vorrq_u8(vorqq_u8(lower_to_upper, upper_to_lower), vec);\n\n        vst1q_u8((uint8_t*)(result.data() + i), output);\n\n        i += 16;\n    }\n\n    while (i < length) {\n        if ((input[i] >= 'a' && input[i] <= 'z') || (input[i] >= 'A' && input[i] <= 'Z')) {\n            result[i] = input[i] ^ 0x20;\n        } else {\n            result[i] = input[i];\n        }\n        i++;\n    }\n\n    if (i == 0) {\n        std::reverse(result.begin(), result.end());\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_77_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nstd::string solve_simd(const std::string & s) {\n    const char* input = s.c_str();\n    size_t length = s.length();\n    std::string result(length, '\\0');\n\n    size_t i = 0;\n    while (i + 15 < length) {\n        uint8x16_t vec = vld1q_u8((const uint8_t*)input + i);\n        uint8x16_t mask = vdupq_n_u8(0x20); // Mask for case conversion\n        uint8x16_t is_alpha = vandq_u8(vec, vmovq_n_u8(0x7F)); // Check if character is alpha\n        uint8x16_t is_upper = vandq_u8(is_alpha, vmovq_n_u8(0x5F)); // Check if character is uppercase\n\n        uint8x16_t converted = vorrq_u8(\n            veorq_u8(vec, mask), // Convert case\n            vbicq_u8(is_upper, mask) // Keep lowercase if already uppercase\n        );\n\n        vst1q_u8((uint8_t*)result.data() + i, converted);\n\n        i += 16;\n    }\n\n    // Handle remaining characters\n    while (i < length) {\n        uint8_t ch = input[i];\n        if ((ch >= 'a' && ch <= 'z') || (ch >= 'A' && ch <= 'Z')) {\n            ch ^= 0x20; // Convert case\n        }\n        result[i] = ch;\n        i++;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_77_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nstd::string solve_simd(const std::string & s) {\n    const char* input = s.c_str();\n    size_t length = s.length();\n    std::string result(length, '\\0');\n\n    size_t i = 0;\n    while (i + 15 < length) {\n        uint8x16_t vec = vld1q_u8((const uint8_t*)(input + i));\n        uint8x16_t mask = vmovq_n_u8(0x20);\n        uint8x16_t is_alpha = vandq_u8(vec, mask);\n        uint8x16_t is_upper = veorq_u8(is_alpha, vmovq_n_u8(0x20));\n        uint8x16_t is_lower = veorq_u8(is_alpha, vmovq_n_u8(0x3E));\n        uint8x16_t upper_to_lower = vsubq_u8(is_upper, vmovq_n_u8(0x20));\n        uint8x16_t lower_to_upper = vaddq_u8(is_lower, vmovq_n_u8(0x20));\n        uint8x16_t result_vec = vbslq_u8(is_upper, lower_to_upper, vbslq_u8(is_lower, upper_to_lower, vec));\n\n        vst1q_u8((uint8_t*)(result.data() + i), result_vec);\n\n        i += 16;\n    }\n\n    // Handle remaining characters\n    while (i < length) {\n        if ((input[i] >= 'a' && input[i] <= 'z') || (input[i] >= 'A' && input[i] <= 'Z')) {\n            result[i] = input[i] ^ 0x20;\n        } else {\n            result[i] = input[i];\n        }\n        i++;\n    }\n\n    // Reverse the entire string if no letters were found\n    if (length > 0 && result[0] == '\\0') {\n        for (size_t j = 0; j < length / 2; ++j) {\n            std::swap(result[j], result[length - 1 - j]);\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_78_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int> sort_third_simd(std::vector<int> l) {\n    int n = l.size();\n    std::vector<int> result(n);\n\n    for (int i = 0; i < n; i += 3) {\n        int v0 = l[i];\n        int v1 = i + 1 < n ? l[i + 1] : INT_MAX;\n        int v2 = i + 2 < n ? l[i + 2] : INT_MAX;\n\n        int min_val = vmin vminmin(v0, v1);\n        int max_val = vmax vmaxmax(v0, v1);\n        int mid_val = v0 + v1 - min_val - max_val;\n\n        if (v2 < min_val) {\n            min_val = v2;\n            mid_val = min_val + mid_val - max_val;\n            max_val = v2 + max_val - min_val;\n        } else if (v2 > max_val) {\n            max_val = v2;\n            mid_val = max_val + mid_val - min_val;\n            min_val = v2 + min_val - max_val;\n        }\n\n        result[i] = min_val;\n        if (i + 1 < n) result[i + 1] = mid_val;\n        if (i + 2 < n) result[i + 2] = max_val;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_78_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<int> sort_third_simd(std::vector<int> l) {\n    int n = l.size();\n    std::vector<int> indices(n);\n    std::iota(indices.begin(), indices.end(), 0);\n\n    auto is_divisible_by_three = [](int i) { return i % 3 == 0; };\n\n    std::sort(indices.begin(), indices.end(), [&](int a, int b) {\n        if (is_divisible_by_three(a) && is_divisible_by_three(b)) {\n            return l[a] < l[b];\n        }\n        return is_divisible_by_three(a);\n    });\n\n    std::vector<int> result(n);\n    for (int i = 0; i < n; ++i) {\n        result[i] = l[indices[i]];\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_78_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<int> sort_third_simd(std::vector<int> l) {\n    int n = l.size();\n    std::vector<int> indices(n);\n    std::iota(indices.begin(), indices.end(), 0);\n\n    auto is_divisible_by_three = [](int i) { return i % 3 == 0; };\n\n    std::vector<int> third_elements;\n    std::copy_if(indices.begin(), indices.end(), std::back_inserter(third_elements), is_divisible_by_three);\n\n    std::sort(third_elements.begin(), third_elements.end());\n\n    std::vector<int> result(l);\n    for (size_t i = 0, j = 0; i < n; ++i) {\n        if (indices[i] % 3 == 0) {\n            result[i] = third_elements[j++];\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_78_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int> sort_third_simd(std::vector<int> l) {\n    int n = l.size();\n    std::vector<int> result(n);\n\n    // Create a mask for indices divisible by three\n    uint32x4_t mask = vdupq_n_u32(0);\n    for (int i = 0; i < 4; ++i) {\n        mask[i] = (i * 3) % n;\n    }\n\n    // Load the first four elements into vectors\n    int32x4_t vec1 = vld1q_s32(&l[0]);\n    int32x4_t vec2 = vld1q_s32(&l[4]);\n\n    // Sort the elements at indices divisible by three\n    int32x4_t sorted_vec1 = vextq_s32(vec1, vec2, 1);\n    int32x4_t sorted_vec2 = vextq_s32(vec2, vec1, 1);\n\n    // Store the sorted elements back into the result vector\n    vst1q_s32(&result[0], sorted_vec1);\n    vst1q_s32(&result[4], sorted_vec2);\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_78_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int> sort_third_simd(std::vector<int> l) {\n    int n = l.size();\n    std::vector<int> result(n);\n\n    // Create a mask for indices divisible by three\n    uint32x4_t mask = vdupq_n_u32(0);\n    for (int i = 0; i < 4; ++i) {\n        mask[i] = (i * 3) % n;\n    }\n\n    // Process elements in chunks of four\n    for (int i = 0; i <= n - 4; i += 4) {\n        uint32x4_t idx_mask = vld1q_u32(mask.data());\n        uint32x4_t idx = vld1q_u32(&i);\n        uint32x4_t idx_div_3 = vmulq_u32(idx, vdupq_n_u32(3));\n        uint32x4_t idx_mod_3 = veorq_u32(idx_div_3, idx);\n        uint32x4_t idx_div_3_mod_3 = veorq_u32(idx_div_3, idx_mod_3);\n\n        uint32x4_t val = vld1q_u32(&l[i]);\n        uint32x4_t val_sorted = val;\n\n        // Sort elements at indices divisible by three\n        for (int j = 0; j < 4; ++j) {\n            if ((idx_div_3_mod_3[j] & 0x3) == 0) {\n                uint32x4_t tmp = vld1q_lane_u32(&val_sorted[j], val_sorted, 0);\n                val_sorted[j] = vld1q_lane_u32(&val[j], val, 0);\n                val[j] = tmp;\n            }\n        }\n\n        vst1q_u32(&result[i], val_sorted);\n    }\n\n    // Handle remaining elements\n    for (int i = n - n % 4; i < n; ++i) {\n        if (i % 3 == 0) {\n            std::sort(l.begin() + i, l.begin() + i + 1);\n        }\n        result[i] = l[i];\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_79_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <algorithm>\n\nfloat max_element_simd(const std::vector<float>& l) {\n    float32x4_t v = vld1q_f32(l.data());\n    float32x4_t vmax = v;\n    int n = l.size() / 4;\n\n    for (int i = 1; i < n; ++i) {\n        v = vld1q_f32(&l[i * 4]);\n        vmax = vmaxq_f32(vmax, v);\n    }\n\n    float32x2_t vmax_lo = vmaxvq_f32(vmax);\n    float32x2_t vmax_hi = vmaxvq_f32(vmax_lo);\n\n    return vmax_hi[0];\n}\n```"}
{"task_id": "SimdBench_79_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <algorithm>\n\nfloat max_element_simd(const std::vector<float>& l) {\n    float32x4_t v = vld1q_f32(l.data());\n    float32x4_t vmax = v;\n    \n    size_t i = 4;\n    while (i + 4 <= l.size()) {\n        v = vld1q_f32(&l[i]);\n        vmax = vmaxmaxq_f32(vmax, v);\n        i += 4;\n    }\n    \n    float32x2_t vhalf = vmaxvq_f32(vmax);\n    float32x2_t vhalf2 = vget_low_f32(vhalf);\n    return std::max(vget_lane_f32(vhalf, 0), vget_lane_f32(vhalf2, 0));\n}\n```"}
{"task_id": "SimdBench_79_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <algorithm>\n\nfloat max_element_simd(const std::vector<float>& l) {\n    float32x4_t v = vld1q_f32(l.data());\n    float32x4_t vmax;\n    int i;\n\n    for (i = 4; i + 4 <= l.size(); i += 4) {\n        vmax = vmaxq_f32(vmax, vld1q_f32(&l[i]));\n        v = vld1q_f32(&l[i]);\n    }\n\n    for (; i < l.size(); ++i) {\n        vmax[0] = vmax[0] > l[i] ? vmax[0] : l[i];\n    }\n\n    return vmax[0];\n}\n```"}
{"task_id": "SimdBench_79_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <algorithm>\n\nfloat max_element_simd(const std::vector<float>& l) {\n    float32x4_t v = vld1q_f32(l.data());\n    float32x4_t vmax;\n    int i;\n\n    for (i = 4; i + 4 <= l.size(); i += 4) {\n        vmax = vmaxq_f32(vmax, vld1q_f32(&l[i]));\n        v = vld1q_f32(&l[i]);\n    }\n\n    if (i + 2 <= l.size()) {\n        vmax = vmaxq_f32(vmax, vld1q_lane_f32(&l[i], v, 0));\n        vmax = vmaxq_f32(vmax, vld1q_lane_f32(&l[i+1], v, 1));\n        i += 2;\n    }\n\n    if (i + 1 <= l.size()) {\n        vmax = vmaxq_f32(vmax, vdup_n_f32(l[i]));\n        i++;\n    }\n\n    return vmax[0];\n}\n```"}
{"task_id": "SimdBench_79_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <algorithm>\n\nfloat max_element_simd(const std::vector<float>& l) {\n    float32x4_t v = vld1q_f32(l.data());\n    float32x4_t vmax;\n    int i;\n\n    for (i = 4; i + 4 <= l.size(); i += 4) {\n        vmax = vmaxq_f32(vmax, vld1q_f32(&l[i]));\n        v = vld1q_f32(&l[i]);\n    }\n\n    for (; i < l.size(); ++i) {\n        vmax[0] = vmaxq_lane_f32(vmax, vld1q_dup_f32(&l[i]), 0);\n    }\n\n    return vmax[0];\n}\n```"}
{"task_id": "SimdBench_80_Neon", "completion": "```c\n#include <arm_neon.h>\n\nint fizz_buzz_simd(int n) {\n    int count = 0;\n    uint32x4_t vseven = vdupq_n_u32('7');\n    uint32x4_t vnine = vdupq_n_u32('9');\n    uint32x4_t vmult11 = vdupq_n_u32(11);\n    uint32x4_t vmult13 = vdupq_n_u32(13);\n\n    for (int i = 0; i < n; i += 16) {\n        uint32x4_t vnum1 = vld1q_u32((uint32_t*)&i);\n        uint32x4_t vnum2 = vld1q_u32((uint32_t*)&(i + 4));\n        uint32x4_t vnum3 = vld1q_u32((uint32_t*)&(i + 8));\n        uint32x4_t vnum4 = vld1q_u32((uint32_t*)&(i + 12));\n\n        uint32x4_t vmul11_1 = vmulq_u32(vnum1, vmult11);\n        uint32x4_t vmul11_2 = vmulq_u32(vnum2, vmult11);\n        uint32x4_t vmul11_3 = vmulq_u32(vnum3, vmult11);\n        uint32x4_t vmul11_4 = vmulq_u32(vnum4, vmult11);\n\n        uint32x4_t vmul13_1 = vmulq_u32(vnum1, vmult13);\n        uint32x4_t vmul13_2 = vmulq_u32(vnum2, vmult13);\n        uint32x4_t vmul13_3 = vmulq_u32(vnum3, vmult13);\n        uint32x4_t vmul13_4 = vmulq_u32(vnum4, vmult13);\n\n        uint32x4_t vand11_1 = vandq_u32(vmul11_1, vnine);\n        uint32x4_t vand11_2 = vandq_u32(vmul11_2, vnine);\n        uint32x4_t vand11_3 = vandq_u32(vmul11_3, vnine);\n        uint32x4_t vand11_4 = vandq_u32(vmul11_4, vnine);\n\n        uint32x4_t vand13_1 = vandq_u32(vmul13_1, vnine);\n        uint32x4_t vand13_2 = vandq_u32(vmul13_2, vnine);\n        uint32x4_t vand13_3 = vandq_u32(vmul13_3, vnine);\n        uint32x4_t vand13_4 = vandq_u32(vmul13_4, vnine);\n\n        uint32x4_t vcmp11_1 = vceqq_u32(vand11_1, vseven);\n        uint32x4_t vcmp11_2 = vceqq_u32(vand11_2, vseven);\n        uint32x4_t vcmp11_3 = vceqq_u32(vand11_3, vseven);\n        uint32x4_t vcmp11_4 = vceqq_u32(vand11_4, vseven);\n\n        uint32x4_t vcmp13_1 = vceqq_u32(vand13_1, vseven);\n        uint32x4_t vcmp13_2 = vceqq_u32(vand13_2, vseven);\n        uint32x4_t vcmp13_3 = vceqq_u32(vand13_3, vseven);\n        uint32x4_t vcmp13_4 = vceqq_u32(vand13_4, vseven);\n\n        uint32x4_t vadd11_1 = vpaddq_u32(vcmp11_1, vzero);\n        uint32x4_t vadd11_2 = vpaddq_u32(vcmp11_2, vzero);\n        uint32x4_t vadd11_3 = vpaddq_u32(vcmp11_3, vzero);\n        uint32x4_t vadd11_4 = vpaddq_u32(vcmp11_4, vzero);\n\n        uint32x4_t vadd13_1 = vpaddq_u32(vcmp13_1, vzero);\n        uint32x4_t vadd13_2 = vpaddq_u32(vcmp13_2, vzero);\n        uint32x4_t vadd13_3 = vpaddq_u32(vcmp13_3, vzero);\n        uint32x4_t vadd13_4 = vpaddq_u32(vcmp13_4, vzero);\n\n        uint32x4_t vsum11 = vpaddq_u32(vadd11_1, vadd11_2);\n        uint32x4_t vsum13 = vpaddq_u32(vadd13_1, vadd13_2);\n\n        uint32x4_t vfinal_sum = vpaddq_u32(vsum11, vsum13);\n\n        count += vgetq_lane_u32(vfinal_sum, 0);\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_80_Neon", "completion": "```c\n#include <arm_neon.h>\n\nint fizz_buzz_simd(int n) {\n    int count = 0;\n    int i = 0;\n\n    for (; i <= n - 16; i += 16) {\n        uint32x4_t v1 = vmovq_n_u32(i);\n        uint32x4_t v2 = vmovq_n_u32(i + 4);\n        uint32x4_t v3 = vmovq_n_u32(i + 8);\n        uint32x4_t v4 = vmovq_n_u32(i + 12);\n\n        uint32x4_t v5 = vmulq_n_u32(v1, 11);\n        uint32x4_t v6 = vmulq_n_u32(v2, 11);\n        uint32x4_t v7 = vmulq_n_u32(v3, 11);\n        uint32x4_t v8 = vmulq_n_u32(v4, 11);\n\n        uint32x4_t v9 = vmulq_n_u32(v1, 13);\n        uint32x4_t v10 = vmulq_n_u32(v2, 13);\n        uint32x4_t v11 = vmulq_n_u32(v3, 13);\n        uint32x4_t v12 = vmulq_n_u32(v4, 13);\n\n        uint32x4_t v13 = vorrq_u32(v5, v9);\n        uint32x4_t v14 = vorrq_u32(v6, v10);\n        uint32x4_t v15 = vorrq_u32(v7, v11);\n        uint32x4_t v16 = vorrq_u32(v8, v12);\n\n        uint32x4_t v17 = vaddq_u32(v13, v14);\n        uint32x4_t v18 = vaddq_u32(v15, v16);\n\n        uint32x4_t v19 = vaddq_u32(v17, v18);\n\n        uint32x4_t v20 = vcntq_u32(v19);\n\n        count += vgetq_lane_u32(v20, 0) + vgetq_lane_u32(v20, 1) +\n                 vgetq_lane_u32(v20, 2) + vgetq_lane_u32(v20, 3);\n    }\n\n    for (; i <= n; i++) {\n        if ((i % 11 == 0 || i % 13 == 0) && i / 10 != 7 && i % 10 != 7) {\n            count++;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_80_Neon", "completion": "```cpp\nint fizz_buzz_simd(int n) {\n    int count = 0;\n    uint32x4_t v7 = vmovq_n_u32(7);\n    uint32x4_t v11 = vmovq_n_u32(11);\n    uint32x4_t v13 = vmovq_n_u32(13);\n\n    for (int i = 0; i < n; i += 16) {\n        uint32x4_t v1 = vld1q_u32((uint32_t*)&i);\n        uint32x4_t v2 = vaddq_u32(v1, v1);\n        uint32x4_t v3 = vaddq_u32(v2, v1);\n        uint32x4_t v4 = vandq_u32(v3, v7);\n        uint32x4_t v5 = veorq_u32(v4, v7);\n        uint32x4_t v6 = vceqq_u32(v5, vzeroq_u32());\n        uint32x4_t v7 = vandq_u32(v3, v11);\n        uint32x4_t v8 = veorq_u32(v7, v11);\n        uint32x4_t v9 = vceqq_u32(v8, vzeroq_u32());\n        uint32x4_t v10 = vandq_u32(v3, v13);\n        uint32x4_t v11 = veorq_u32(v10, v13);\n        uint32x4_t v12 = vceqq_u32(v11, vzeroq_u32());\n        uint32x4_t v13 = vorrq_u32(v6, v9);\n        uint32x4_t v14 = vorrq_u32(v13, v12);\n        uint32x4_t v15 = vcntq_u32(v14);\n        count += vgetq_lane_u32(v15, 0) + vgetq_lane_u32(v15, 1) + vgetq_lane_u32(v15, 2) + vgetq_lane_u32(v15, 3);\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_80_Neon", "completion": "```c\n#include <arm_neon.h>\n\nint fizz_buzz_simd(int n) {\n    int count = 0;\n    uint32x4_t vseven = vmovq_n_u32('7');\n    uint32x4_t vnine = vmovq_n_u32('9');\n    uint32x4_t vone = vmovq_n_u32('1');\n    uint32x4_t vthree = vmovq_n_u32('3');\n    uint32x4_t vfive = vmovq_n_u32('5');\n    uint32x4_t veleven = vmovq_n_u32('1') | vmovq_n_u32('1') << 8 | vmovq_n_u32('1') << 16 | vmovq_n_u32('1') << 24;\n    uint32x4_t vthirteen = vmovq_n_u32('1') | vmovq_n_u32('3') << 8 | vmovq_n_u32('3') << 16 | vmovq_n_u32('3') << 24;\n\n    for (int i = 0; i < n; i += 16) {\n        uint32x4_t vnum1 = vld1q_u32((uint32_t *)&i);\n        uint32x4_t vnum2 = vld1q_u32((uint32_t *)(i + 4));\n        uint32x4_t vnum3 = vld1q_u32((uint32_t *)(i + 8));\n        uint32x4_t vnum4 = vld1q_u32((uint32_t *)(i + 12));\n\n        uint32x4_t vmul1 = vmulq_u32(vnum1, veleven);\n        uint32x4_t vmul2 = vmulq_u32(vnum2, veleven);\n        uint32x4_t vmul3 = vmulq_u32(vnum3, veleven);\n        uint32x4_t vmul4 = vmulq_u32(vnum4, veleven);\n\n        uint32x4_t vmul5 = vmulq_u32(vnum1, vthirteen);\n        uint32x4_t vmul6 = vmulq_u32(vnum2, vthirteen);\n        uint32x4_t vmul7 = vmulq_u32(vnum3, vthirteen);\n        uint32x4_t vmul8 = vmulq_u32(vnum4, vthirteen);\n\n        uint32x4_t vand1 = vandq_u32(vmul1, vnine);\n        uint32x4_t vand2 = vandq_u32(vmul2, vnine);\n        uint32x4_t vand3 = vandq_u32(vmul3, vnine);\n        uint32x4_t vand4 = vandq_u32(vmul4, vnine);\n\n        uint32x4_t vand5 = vandq_u32(vmul5, vnine);\n        uint32x4_t vand6 = vandq_u32(vmul6, vnine);\n        uint32x4_t vand7 = vandq_u32(vmul7, vnine);\n        uint32x4_t vand8 = vandq_u32(vmul8, vnine);\n\n        uint32x4_t vcmp1 = vceqq_u32(vand1, vseven);\n        uint32x4_t vcmp2 = vceqq_u32(vand2, vseven);\n        uint32x4_t vcmp3 = vceqq_u32(vand3, vseven);\n        uint32x4_t vcmp4 = vceqq_u32(vand4, vseven);\n\n        uint32x4_t vcmp5 = vceqq_u32(vand5, vseven);\n        uint32x4_t vcmp6 = vceqq_u32(vand6, vseven);\n        uint32x4_t vcmp7 = vceqq_u32(vand7, vseven);\n        uint32x4_t vcmp8 = vceqq_u32(vand8, vseven);\n\n        uint32x4_t vadd1 = vpaddq_u32(vcmp1, vcmp2);\n        uint32x4_t vadd2 = vpaddq_u32(vcmp3, vcmp4);\n        uint32x4_t vadd3 = vpaddq_u32(vcmp5, vcmp6);\n        uint32x4_t vadd4 = vpaddq_u32(vcmp7, vcmp8);\n\n        uint32x4_t vadd5 = vpaddq_u32(vadd1, vadd2);\n        uint32x4_t vadd6 = vpaddq_u32(vadd3, vadd4);\n\n        uint32x4_t vadd7 = vpaddq_u32(vadd5, vadd6);\n\n        count += vgetq_lane_u32(vadd7, 0);\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_80_Neon", "completion": "```c\n#include <arm_neon.h>\n\nint fizz_buzz_simd(int n) {\n    int count = 0;\n    uint32x4_t v7 = vmovq_n_u32(7);\n    uint32x4_t v11 = vmovq_n_u32(11);\n    uint32x4_t v13 = vmovq_n_u32(13);\n    uint32x4_t v0 = vmovq_n_u32(0);\n\n    for (int i = 0; i < n; i += 16) {\n        uint32x4_t v1 = vmovq_n_u32(i);\n        uint32x4_t v2 = vmovq_n_u32(i + 1);\n        uint32x4_t v3 = vmovq_n_u32(i + 2);\n        uint32x4_t v4 = vmovq_n_u32(i + 3);\n        uint32x4_t v5 = vmovq_n_u32(i + 4);\n        uint32x4_t v6 = vmovq_n_u32(i + 5);\n        uint32x4_t v8 = vmovq_n_u32(i + 6);\n        uint32x4_t v9 = vmovq_n_u32(i + 7);\n        uint32x4_t va = vmovq_n_u32(i + 8);\n        uint32x4_t vb = vmovq_n_u32(i + 9);\n        uint32x4_t vc = vmovq_n_u32(i + 10);\n        uint32x4_t vd = vmovq_n_u32(i + 11);\n        uint32x4_t ve = vmovq_n_u32(i + 12);\n        uint32x4_t vf = vmovq_n_u32(i + 13);\n        uint32x4_t vg = vmovq_n_u32(i + 14);\n\n        uint32x4_t v11_mask = vorrq_u32(vorvlslvq_u32(v11, v1), vorvlslvq_u32(v11, v2));\n        uint32x4_t v13_mask = vorrq_u32(vorvlslvq_u32(v13, v3), vorvlslvq_u32(v13, v4));\n        uint32x4_t v7_mask = vorrq_u32(vorvlslvq_u32(v7, v5), vorvlslvq_u32(v7, v6));\n\n        uint32x4_t v11_count = vcntq_u32(vandq_u32(v11_mask, v11_mask));\n        uint32x4_t v13_count = vcntq_u32(vandq_u32(v13_mask, v13_mask));\n        uint32x4_t v7_count = vcntq_u32(vandq_u32(v7_mask, v7_mask));\n\n        count += vgetq_lane_u32(vaddq_u32(vaddq_u32(v11_count, v13_count), v7_count), 0);\n        count += vgetq_lane_u32(vaddq_u32(vaddq_u32(v11_count, v13_count), v7_count), 1);\n        count += vgetq_lane_u32(vaddq_u32(vaddq_u32(v11_count, v13_count), v7_count), 2);\n        count += vgetq_lane_u32(vaddq_u32(vaddq_u32(v11_count, v13_count), v7_count), 3);\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_81_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<float> sort_even_simd(std::vector<float> l) {\n    int n = l.size();\n    if (n % 2 != 0) {\n        throw std::invalid_argument(\"Input size must be even\");\n    }\n\n    float32x4_t v0, v1, v2, v3;\n    float32x2_t v4, v5;\n\n    for (int i = 0; i < n; i += 8) {\n        v0 = vld1q_f32(&l[i]);\n        v1 = vld1q_f32(&l[i + 4]);\n\n        // Extract even elements\n        v4 = vext_f32(v0, v0, 1);\n        v5 = vext_f32(v1, v1, 1);\n\n        // Sort even elements\n        v4 = vminnmv_f32(v4, v4);\n        v5 = vminnmv_f32(v5, v5);\n\n        // Merge sorted even elements back into original vector\n        v0 = vsetq_lane_f32(vget_lane_f32(v4, 0), v0, 0);\n        v0 = vsetq_lane_f32(vget_lane_f32(v4, 1), v0, 2);\n        v1 = vsetq_lane_f32(vget_lane_f32(v5, 0), v1, 0);\n        v1 = vsetq_lane_f32(vget_lane_f32(v5, 1), v1, 2);\n\n        vst1q_f32(&l[i], v0);\n        vst1q_f32(&l[i + 4], v1);\n    }\n\n    return l;\n}\n```"}
{"task_id": "SimdBench_81_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<float> sort_even_simd(const std::vector<float>& l) {\n    int n = l.size();\n    std::vector<float> result(n);\n    \n    // Extract even-indexed elements\n    float32x4_t v0 = vld1q_f32(&l[0]);\n    float32x4_t v1 = vld1q_f32(&l[4]);\n    float32x4_t v2 = vld1q_f32(&l[8]);\n    float32x4_t v3 = vld1q_f32(&l[12]);\n    \n    // Sort even-indexed elements\n    float32x4_t s0 = vsortq_f32(v0);\n    float32x4_t s1 = vsortq_f32(v1);\n    float32x4_t s2 = vsortq_f32(v2);\n    float32x4_t s3 = vsortq_f32(v3);\n    \n    // Merge sorted even-indexed elements back into result\n    vst1q_f32(&result[0], s0);\n    vst1q_f32(&result[4], s1);\n    vst1q_f32(&result[8], s2);\n    vst1q_f32(&result[12], s3);\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_81_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<float> sort_even_simd(std::vector<float> l) {\n    int n = l.size();\n    std::vector<float> result(n);\n\n    // Extract even-indexed elements\n    float32x4_t v0 = vld1q_f32(&l[0]);\n    float32x4_t v1 = vld1q_f32(&l[4]);\n    float32x4_t v2 = vld1q_f32(&l[8]);\n    float32x4_t v3 = vld1q_f32(&l[12]);\n\n    // Sort even-indexed elements\n    float32x4_t v0_sorted = vextq_f32(v0, v1, 1);\n    float32x4_t v1_sorted = vextq_f32(v1, v2, 1);\n    float32x4_t v2_sorted = vextq_f32(v2, v3, 1);\n    float32x4_t v3_sorted = vextq_f32(v3, v0, 1);\n\n    // Merge sorted even-indexed elements back into result\n    vst1q_f32(&result[0], v0_sorted);\n    vst1q_f32(&result[4], v1_sorted);\n    vst1q_f32(&result[8], v2_sorted);\n    vst1q_f32(&result[12], v3_sorted);\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_81_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<float> sort_even_simd(std::vector<float> l) {\n    int n = l.size();\n    std::vector<float> evens(n / 2);\n    \n    // Extract even-indexed elements\n    for (int i = 0; i < n / 2; ++i) {\n        evens[i] = l[2 * i];\n    }\n    \n    // Sort the extracted elements\n    std::sort(evens.begin(), evens.end());\n    \n    // Place sorted elements back into the original vector\n    for (int i = 0; i < n / 2; ++i) {\n        l[2 * i] = evens[i];\n    }\n    \n    return l;\n}\n```"}
{"task_id": "SimdBench_81_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<float> sort_even_simd(std::vector<float> l) {\n    int n = l.size();\n    std::vector<float> evens;\n    for (int i = 0; i < n; i += 2) {\n        evens.push_back(l[i]);\n    }\n    std::sort(evens.begin(), evens.end());\n\n    int j = 0;\n    for (int i = 0; i < n; i += 2) {\n        l[i] = evens[j++];\n    }\n\n    return l;\n}\n```"}
{"task_id": "SimdBench_82_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nbool triples_sum_to_zero_simd(const std::vector<int>& l) {\n    int n = l.size();\n    if (n < 3) return false;\n\n    for (int i = 0; i < n - 2; ++i) {\n        int32x4_t v1 = vld1q_s32(&l[i]);\n        for (int j = i + 1; j < n - 1; ++j) {\n            int32x4_t v2 = vld1q_s32(&l[j]);\n            for (int k = j + 1; k < n; ++k) {\n                int32x4_t v3 = vld1q_s32(&l[k]);\n                int32x4_t sum = vaddq_s32(vaddq_s32(v1, v2), v3);\n                if (vgetq_lane_s32(sum, 0) == 0 || vgetq_lane_s32(sum, 1) == 0 || vgetq_lane_s32(sum, 2) == 0 || vgetq_lane_s32(sum, 3) == 0) {\n                    return true;\n                }\n            }\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_82_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <algorithm>\n\nbool triples_sum_to_zero_simd(const std::vector<int>& l) {\n    int n = l.size();\n    if (n < 3) return false;\n\n    std::vector<int> sorted_l(l);\n    std::sort(sorted_l.begin(), sorted_l.end());\n\n    for (int i = 0; i < n - 2; ++i) {\n        int j = i + 1;\n        int k = n - 1;\n\n        while (j < k) {\n            int sum = sorted_l[i] + sorted_l[j] + sorted_l[k];\n            if (sum == 0) {\n                return true;\n            } else if (sum < 0) {\n                j++;\n            } else {\n                k--;\n            }\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_82_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nbool triples_sum_to_zero_simd(const std::vector<int>& l) {\n    int n = l.size();\n    if (n < 3) return false;\n\n    for (int i = 0; i < n - 2; ++i) {\n        int32x4_t v1 = vld1q_s32(&l[i]);\n        for (int j = i + 1; j < n - 1; ++j) {\n            int32x4_t v2 = vld1q_s32(&l[j]);\n            for (int k = j + 1; k < n; ++k) {\n                int32x4_t v3 = vld1q_s32(&l[k]);\n                int32x4_t sum = vaddq_s32(vaddq_s32(v1, v2), v3);\n                if (vgetq_lane_s32(sum, 0) == 0 || vgetq_lane_s32(sum, 1) == 0 || vgetq_lane_s32(sum, 2) == 0 || vgetq_lane_s32(sum, 3) == 0) {\n                    return true;\n                }\n            }\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_82_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nbool triples_sum_to_zero_simd(const std::vector<int>& l) {\n    int n = l.size();\n    if (n < 3) return false;\n\n    for (int i = 0; i < n - 2; ++i) {\n        int32x4_t v1 = vld1q_s32(&l[i]);\n        for (int j = i + 1; j < n - 1; ++j) {\n            int32x4_t v2 = vld1q_s32(&l[j]);\n            for (int k = j + 1; k < n; ++k) {\n                int32x4_t v3 = vld1q_s32(&l[k]);\n                int32x4_t sum = vaddq_s32(vaddq_s32(v1, v2), v3);\n                if (vgetq_lane_s32(sum, 0) == 0 ||\n                    vgetq_lane_s32(sum, 1) == 0 ||\n                    vgetq_lane_s32(sum, 2) == 0 ||\n                    vgetq_lane_s32(sum, 3) == 0) {\n                    return true;\n                }\n            }\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_82_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nbool triples_sum_to_zero_simd(const std::vector<int>& l) {\n    int n = l.size();\n    if (n < 3) return false;\n\n    for (int i = 0; i < n - 2; ++i) {\n        int32x4_t v1 = vld1q_s32(&l[i]);\n        for (int j = i + 1; j < n - 1; ++j) {\n            int32x4_t v2 = vld1q_s32(&l[j]);\n            for (int k = j + 1; k < n; ++k) {\n                int32x4_t v3 = vld1q_s32(&l[k]);\n                int32x4_t sum = vaddq_s32(vaddq_s32(v1, v2), v3);\n                if (vgetq_lane_s32(sum, 0) == 0 || vgetq_lane_s32(sum, 1) == 0 || vgetq_lane_s32(sum, 2) == 0 || vgetq_lane_s32(sum, 3) == 0) {\n                    return true;\n                }\n            }\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_83_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int> incr_list_simd(std::vector<int> l) {\n    int n = l.size();\n    std::vector<int> result(n);\n    int i = 0;\n\n    // Process elements in chunks of 8\n    while (i + 7 < n) {\n        int32x4_t vec1 = vld1q_s32(&l[i]);\n        int32x4_t vec2 = vld1q_s32(&l[i + 4]);\n        int32x4_t res1 = vaddq_s32(vec1, vdupq_n_s32(1));\n        int32x4_t res2 = vaddq_s32(vec2, vdupq_n_s32(1));\n        vst1q_s32(&result[i], res1);\n        vst1q_s32(&result[i + 4], res2);\n        i += 8;\n    }\n\n    // Process remaining elements\n    for (; i < n; ++i) {\n        result[i] = l[i] + 1;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_83_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int> incr_list_simd(std::vector<int> l) {\n    int n = l.size();\n    std::vector<int> result(n);\n    \n    int i = 0;\n    for (; i <= n - 8; i += 8) {\n        int32x4_t v1 = vld1q_s32(&l[i]);\n        int32x4_t v2 = vld1q_s32(&l[i + 4]);\n        int32x4_t r1 = vaddq_s32(v1, vdupq_n_s32(1));\n        int32x4_t r2 = vaddq_s32(v2, vdupq_n_s32(1));\n        vst1q_s32(&result[i], r1);\n        vst1q_s32(&result[i + 4], r2);\n    }\n    \n    for (; i < n; ++i) {\n        result[i] = l[i] + 1;\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_83_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int> incr_list_simd(std::vector<int> l) {\n    int n = l.size();\n    std::vector<int> result(n);\n\n    int32x4_t vone = vdupq_n_s32(1);\n    int i = 0;\n\n    // Process elements in chunks of 4\n    while (i + 16 <= n) {\n        int32x4_t va = vld1q_s32(&l[i]);\n        int32x4_t vb = vld1q_s32(&l[i + 4]);\n        int32x4_t vc = vld1q_s32(&l[i + 8]);\n        int32x4_t vd = vld1q_s32(&l[i + 12]);\n\n        va = vaddq_s32(va, vone);\n        vb = vaddq_s32(vb, vone);\n        vc = vaddq_s32(vc, vone);\n        vd = vaddq_s32(vd, vone);\n\n        vst1q_s32(&result[i], va);\n        vst1q_s32(&result[i + 4], vb);\n        vst1q_s32(&result[i + 8], vc);\n        vst1q_s32(&result[i + 12], vd);\n\n        i += 16;\n    }\n\n    // Process remaining elements\n    for (; i < n; ++i) {\n        result[i] = l[i] + 1;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_83_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int> incr_list_simd(std::vector<int> l) {\n    int n = l.size();\n    std::vector<int> result(n);\n\n    int32x4_t vone = vdupq_n_s32(1);\n    int i = 0;\n\n    // Process elements in chunks of 4\n    while (i + 16 <= n) {\n        int32x4_t va = vld1q_s32(&l[i]);\n        int32x4_t vb = vld1q_s32(&l[i + 4]);\n        int32x4_t vc = vld1q_s32(&l[i + 8]);\n        int32x4_t vd = vld1q_s32(&l[i + 12]);\n\n        va = vaddq_s32(va, vone);\n        vb = vaddq_s32(vb, vone);\n        vc = vaddq_s32(vc, vone);\n        vd = vaddq_s32(vd, vone);\n\n        vst1q_s32(&result[i], va);\n        vst1q_s32(&result[i + 4], vb);\n        vst1q_s32(&result[i + 8], vc);\n        vst1q_s32(&result[i + 12], vd);\n\n        i += 16;\n    }\n\n    // Process remaining elements\n    for (; i < n; ++i) {\n        result[i] = l[i] + 1;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_83_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int> incr_list_simd(std::vector<int> l) {\n    int n = l.size();\n    std::vector<int> result(n);\n\n    int32x4_t vone = vdupq_n_s32(1);\n    int i = 0;\n\n    // Process elements in chunks of 4\n    for (; i + 4 <= n; i += 4) {\n        int32x4_t vin = vld1q_s32(&l[i]);\n        int32x4_t vout = vaddq_s32(vin, vone);\n        vst1q_s32(&result[i], vout);\n    }\n\n    // Process remaining elements\n    for (; i < n; ++i) {\n        result[i] = l[i] + 1;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_84_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nbool pairs_sum_to_zero_simd(const std::vector<int>& l) {\n    int n = l.size();\n    if (n < 2) return false;\n\n    const int* data = l.data();\n\n    for (int i = 0; i < n - 1; i += 8) {\n        int32x4_t v1 = vld1q_s32(data + i);\n        int32x4_t v2 = vld1q_s32(data + i + 4);\n\n        int32x4_t neg_v1 = vmulq_n_s32(v1, -1);\n        int32x4_t neg_v2 = vmulq_n_s32(v2, -1);\n\n        uint32x4_t mask1 = vceqq_s32(v1, neg_v2);\n        uint32x4_t mask2 = vceqq_s32(v2, neg_v1);\n\n        if (vget_lane_u32(mask1, 0) || vget_lane_u32(mask1, 1) ||\n            vget_lane_u32(mask1, 2) || vget_lane_u32(mask1, 3) ||\n            vget_lane_u32(mask2, 0) || vget_lane_u32(mask2, 1) ||\n            vget_lane_u32(mask2, 2) || vget_lane_u32(mask2, 3)) {\n            return true;\n        }\n    }\n\n    // Handle remaining elements\n    for (int i = n - n % 8; i < n; ++i) {\n        for (int j = i + 1; j < n; ++j) {\n            if (data[i] + data[j] == 0) {\n                return true;\n            }\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_84_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nbool pairs_sum_to_zero_simd(const std::vector<int>& l) {\n    int n = l.size();\n    if (n < 2) return false;\n\n    int32x4_t v0, v1;\n    bool found = false;\n\n    for (int i = 0; i + 3 < n; i += 4) {\n        v0 = vld1q_s32(&l[i]);\n        v1 = vld1q_s32(&l[i + 4]);\n\n        int32x4_t sum = vaddq_s32(v0, v1);\n        int32x4_t mask = veorq_s32(sum, vdupq_n_s32(0));\n        uint32x4_t eq_mask = vmvnq_u32(mask);\n\n        if (vgetq_lane_u32(eq_mask, 0) || vgetq_lane_u32(eq_mask, 1) ||\n            vgetq_lane_u32(eq_mask, 2) || vgetq_lane_u32(eq_mask, 3)) {\n            found = true;\n            break;\n        }\n    }\n\n    if (!found && n % 4 != 0) {\n        int remaining = n % 4;\n        for (int i = n - remaining; i < n; ++i) {\n            for (int j = i + 1; j < n; ++j) {\n                if (l[i] + l[j] == 0) {\n                    found = true;\n                    break;\n                }\n            }\n            if (found) break;\n        }\n    }\n\n    return found;\n}\n```"}
{"task_id": "SimdBench_84_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nbool pairs_sum_to_zero_simd(const std::vector<int>& l) {\n    int n = l.size();\n    if (n < 2) return false;\n\n    const int* data = l.data();\n\n    for (int i = 0; i < n - 1; i += 8) {\n        int32x4_t v1 = vld1q_s32(data + i);\n        int32x4_t v2 = vld1q_s32(data + i + 4);\n\n        int32x4_t vneg1 = vmvnq_s32(v1);\n        int32x4_t vneg2 = vmvnq_s32(v2);\n\n        uint32x4_t vmask1 = vandq_u32(vreinterpretq_u32_s32(v1), vreinterpretq_u32_s32(vneg2));\n        uint32x4_t vmask2 = vandq_u32(vreinterpretq_u32_s32(v2), vreinterpretq_u32_s32(vneg1));\n\n        if (vget_lane_u32(vmask1, 0) || vget_lane_u32(vmask1, 1) ||\n            vget_lane_u32(vmask1, 2) || vget_lane_u32(vmask1, 3) ||\n            vget_lane_u32(vmask2, 0) || vget_lane_u32(vmask2, 1) ||\n            vget_lane_u32(vmask2, 2) || vget_lane_u32(vmask2, 3)) {\n            return true;\n        }\n    }\n\n    // Handle remaining elements\n    for (int i = n - n % 8; i < n; ++i) {\n        for (int j = i + 1; j < n; ++j) {\n            if (data[i] + data[j] == 0) {\n                return true;\n            }\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_84_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nbool pairs_sum_to_zero_simd(const std::vector<int>& l) {\n    int n = l.size();\n    if (n < 2) return false;\n\n    const int* data = l.data();\n\n    for (int i = 0; i < n - 1; i += 8) {\n        int32x4_t v1 = vld1q_s32(data + i);\n        int32x4_t v2 = vld1q_s32(data + i + 4);\n\n        int32x4_t vneg1 = vmvnq_s32(v1);\n        int32x4_t vneg2 = vmvnq_s32(v2);\n\n        int32x4_t vand1 = vandq_s32(v1, vneg2);\n        int32x4_t vand2 = vandq_s32(v2, vneg1);\n\n        uint32x4_t vcnt1 = vcntq_u32(vand1);\n        uint32x4_t vcnt2 = vcntq_u32(vand2);\n\n        if (vgetq_lane_u32(vcnt1, 0) > 0 || vgetq_lane_u32(vcnt2, 0) > 0) {\n            return true;\n        }\n    }\n\n    // Handle remaining elements\n    for (int i = n - n % 8; i < n; ++i) {\n        for (int j = i + 1; j < n; ++j) {\n            if (data[i] + data[j] == 0) {\n                return true;\n            }\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_84_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nbool pairs_sum_to_zero_simd(const std::vector<int>& l) {\n    int n = l.size();\n    if (n < 2) return false;\n\n    int32x4_t v0 = vdupq_n_s32(0);\n    bool found = false;\n\n    for (int i = 0; i + 3 < n; i += 4) {\n        int32x4_t v1 = vld1q_s32(&l[i]);\n        int32x4_t v2 = vnegq_s32(v1);\n\n        if (vceqq_s32(v1, v2)) {\n            found = true;\n            break;\n        }\n    }\n\n    if (!found && n % 4 != 0) {\n        for (int i = n - n % 4; i < n; ++i) {\n            for (int j = i + 1; j < n; ++j) {\n                if (l[i] + l[j] == 0) {\n                    found = true;\n                    break;\n                }\n            }\n            if (found) break;\n        }\n    }\n\n    return found;\n}\n```"}
{"task_id": "SimdBench_85_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nstd::string change_base_simd(int64_t x, int8_t base) {\n    std::string result = \"\";\n    while (x != 0) {\n        uint64_t remainder = x % base;\n        char digit = '0' + remainder;\n        result.push_back(digit);\n        x /= base;\n    }\n    std::reverse(result.begin(), result.end());\n    return result;\n}\n```"}
{"task_id": "SimdBench_85_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nstd::string change_base_simd(int64_t x, int8_t base) {\n    std::string result = \"\";\n    while (x != 0) {\n        uint64_t remainder = x % base;\n        char digit = '0' + remainder;\n        result.push_back(digit);\n        x /= base;\n    }\n    std::reverse(result.begin(), result.end());\n    return result;\n}\n```"}
{"task_id": "SimdBench_85_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nstd::string change_base_simd(int64_t x, int8_t base) {\n    char buffer[65];\n    char* ptr = buffer + 64;\n    *ptr-- = '\\0';\n\n    while (x != 0) {\n        int64_t remainder = x % base;\n        *ptr-- = '0' + remainder;\n        x /= base;\n    }\n\n    return std::string(ptr + 1);\n}\n```"}
{"task_id": "SimdBench_85_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nstd::string change_base_simd(int64_t x, int8_t base) {\n    std::string result = \"\";\n    while (x != 0) {\n        uint64x2_t vec_x = vreinterpret_u64_s64(vdupq_n_s64(x));\n        uint64x2_t vec_base = vreinterpret_u64_s64(vdupq_n_s64(base));\n        uint64x2_t remainder = vmulq_u64(vec_x, vec_base);\n        uint64x2_t quotient = vdivq_u64(vec_x, remainder);\n        uint64x2_t mod = vmodq_u64(vec_x, remainder);\n        x = vgetq_lane_u64(mod, 0);\n        char digit = '0' + x;\n        result += digit;\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_85_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nstd::string change_base_simd(int64_t x, int8_t base) {\n    char buffer[20];\n    int i = 19;\n    buffer[i] = '\\0';\n    \n    while (x != 0) {\n        int remainder = x % base;\n        buffer[--i] = '0' + remainder;\n        x /= base;\n    }\n    \n    return std::string(&buffer[i]);\n}\n```"}
{"task_id": "SimdBench_86_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nbool is_palindrome_simd(const std::string& text) {\n    int len = text.length();\n    if (len <= 1) return true;\n\n    const uint8_t* start = reinterpret_cast<const uint8_t*>(text.c_str());\n    const uint8_t* end = start + len - 1;\n\n    while (start < end) {\n        uint8x16_t vec_start = vld1q_u8(start);\n        uint8x16_t vec_end = vld1q_u8(end);\n\n        if (!veceorq_u8(vec_start, vec_end)) {\n            return false;\n        }\n\n        start += 16;\n        end -= 16;\n    }\n\n    // Check remaining characters\n    while (start < end) {\n        if (*start != *end) {\n            return false;\n        }\n        start++;\n        end--;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_86_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nbool is_palindrome_simd(const std::string& text) {\n    int len = text.length();\n    if (len <= 1) return true;\n\n    const uint8_t* start = reinterpret_cast<const uint8_t*>(text.c_str());\n    const uint8_t* end = start + len - 1;\n\n    while (start < end) {\n        uint8x16_t vec_start = vld1q_u8(start);\n        uint8x16_t vec_end = vld1q_u8(end);\n\n        // Check if characters at start and end are equal\n        uint8x16_t eq_mask = veorq_u8(vec_start, vec_end);\n        uint32x4_t eq_count = vcntq_u32(vreinterpretq_u32_u8(eq_mask));\n\n        if (vgetq_lane_u32(eq_count, 0) == 16) {\n            start += 16;\n            end -= 16;\n        } else {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_86_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nbool is_palindrome_simd(const std::string& text) {\n    int len = text.length();\n    if (len <= 1) return true;\n\n    const uint8_t* start = reinterpret_cast<const uint8_t*>(text.c_str());\n    const uint8_t* end = start + len - 1;\n\n    while (start < end) {\n        uint8x16_t vec_start = vld1q_u8(start);\n        uint8x16_t vec_end = vld1q_u8(end);\n\n        uint8x16_t mask = veorq_u8(vec_start, vec_end);\n        if (!vallq_u8(mask)) {\n            return false;\n        }\n\n        start += 16;\n        end -= 16;\n    }\n\n    // Check remaining characters\n    while (start < end) {\n        if (*start != *end) {\n            return false;\n        }\n        start++;\n        end--;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_86_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nbool is_palindrome_simd(const std::string& text) {\n    int len = text.length();\n    if (len <= 1) return true;\n\n    const uint8_t* start = reinterpret_cast<const uint8_t*>(text.c_str());\n    const uint8_t* end = start + len - 1;\n\n    while (start < end) {\n        uint8x16_t vec_start = vld1q_u8(start);\n        uint8x16_t vec_end = vld1q_u8(end);\n\n        uint8x16_t mask = veorq_u8(vec_start, vec_end);\n        if (!vallq_u8(mask)) {\n            return false;\n        }\n\n        start += 16;\n        end -= 16;\n    }\n\n    // Check remaining characters\n    while (start < end) {\n        if (*start != *end) {\n            return false;\n        }\n        start++;\n        end--;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_86_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nbool is_palindrome_simd(const std::string& text) {\n    int len = text.length();\n    if (len <= 1) return true;\n\n    const uint8_t* start = reinterpret_cast<const uint8_t*>(text.c_str());\n    const uint8_t* end = start + len - 1;\n\n    while (start < end) {\n        uint8x16_t vec_start = vld1q_u8(start);\n        uint8x16_t vec_end = vld1q_u8(end);\n\n        // Check if characters at start and end are equal\n        uint16x8_t eq_start = vceqq_u8(vec_start, vrev64q_u8(vld1q_u8(start)));\n        uint16x8_t eq_end = vceqq_u8(vec_end, vrev64q_u8(vld1q_u8(end)));\n\n        // Combine results from both halves\n        uint16x8_t combined_eq = vandq_u16(eq_start, eq_end);\n\n        // Check if all elements in combined_eq are true\n        uint32x2_t combined_eq_low = vmovl_u16(vget_low_u16(combined_eq));\n        uint32x2_t combined_eq_high = vmovl_u16(vget_high_u16(combined_eq));\n\n        if (!(vget_lane_u32(combined_eq_low, 0) & vget_lane_u32(combined_eq_low, 1)) ||\n            !(vget_lane_u32(combined_eq_high, 0) & vget_lane_u32(combined_eq_high, 1))) {\n            return false;\n        }\n\n        start += 16;\n        end -= 16;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_87_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nstd::string decode_shift_simd(const std::string& s) {\n    const size_t len = s.length();\n    std::string out(len, '\\0');\n    const uint8x16_t shift = vdupq_n_u8(5);\n    const uint8x16_t base = vdupq_n_u8('a');\n\n    for (size_t i = 0; i <= len - 16; i += 16) {\n        uint8x16_t vec = vld1q_u8(reinterpret_cast<const uint8_t*>(&s[i]));\n        vec = vsubq_u8(vec, shift);\n        vec = vmulq_u8(vec, vdupq_n_u8(26));\n        vec = vaddq_u8(vec, base);\n        vec = vminq_u8(vec, vdupq_n_u8('z'));\n        vec = vmaxq_u8(vec, vdupq_n_u8('a'));\n        vst1q_u8(reinterpret_cast<uint8_t*>(&out[i]), vec);\n    }\n\n    // Handle remaining characters\n    for (size_t i = len - len % 16; i < len; ++i) {\n        out[i] = ((s[i] - 'a' - 5 + 26) % 26) + 'a';\n    }\n\n    return out;\n}\n```"}
{"task_id": "SimdBench_87_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nstd::string decode_shift_simd(const std::string& s) {\n    const size_t len = s.length();\n    std::string out(len, '\\0');\n    \n    const uint8x16_t shift_vec = vdupq_n_u8(5);\n    const uint8x16_t base_vec = vdupq_n_u8('a');\n    const uint8x16_t mod_vec = vdupq_n_u8(26);\n\n    size_t i = 0;\n    while (i + 16 <= len) {\n        uint8x16_t input_vec = vld1q_u8(reinterpret_cast<const uint8_t*>(&s[i]));\n        \n        // Shift characters by 5\n        uint8x16_t shifted_vec = vaddq_u8(input_vec, shift_vec);\n        \n        // Subtract 'a' to get zero-based index\n        uint8x16_t zero_based_vec = vsubq_u8(shifted_vec, base_vec);\n        \n        // Modulo 26\n        uint8x16_t modulo_vec = vmulq_u8(zero_based_vec, mod_vec);\n        uint8x16_t remainder_vec = vmodq_u8(modulo_vec, mod_vec);\n        \n        // Add 'a' back to get original character\n        uint8x16_t result_vec = vaddq_u8(remainder_vec, base_vec);\n        \n        // Store result\n        vst1q_u8(reinterpret_cast<uint8_t*>(&out[i]), result_vec);\n        \n        i += 16;\n    }\n\n    // Handle remaining characters\n    for (; i < len; ++i) {\n        char c = s[i];\n        if (c >= 'a' && c <= 'z') {\n            c = ((c - 'a' + 26 - 5) % 26) + 'a';\n        }\n        out[i] = c;\n    }\n\n    return out;\n}\n```"}
{"task_id": "SimdBench_87_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nstd::string decode_shift_simd(const std::string& s) {\n    const size_t len = s.length();\n    std::string out(len, '\\0');\n    const uint8x16_t shift = vdupq_n_u8(5);\n    const uint8x16_t base = vdupq_n_u8('a');\n\n    for (size_t i = 0; i <= len - 16; i += 16) {\n        uint8x16_t vec = vld1q_u8(reinterpret_cast<const uint8_t*>(&s[i]));\n        vec = vsubq_u8(vec, shift);\n        vec = vmulq_u8(vec, vdupq_n_u8(26));\n        vec = vaddq_u8(vec, base);\n        vec = vminq_u8(vec, vdupq_n_u8('z'));\n        vec = vmaxq_u8(vec, vdupq_n_u8('a'));\n        vst1q_u8(reinterpret_cast<uint8_t*>(&out[i]), vec);\n    }\n\n    // Handle remaining characters\n    for (size_t i = len - len % 16; i < len; ++i) {\n        out[i] = ((s[i] - 'a' - 5 + 26) % 26) + 'a';\n    }\n\n    return out;\n}\n```"}
{"task_id": "SimdBench_87_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nstd::string decode_shift_simd(const std::string& s) {\n    const size_t len = s.length();\n    std::string out(len, '\\0');\n    const uint8x16_t shift = vdupq_n_u8(5);\n    const uint8x16_t base = vdupq_n_u8('a');\n\n    for (size_t i = 0; i <= len - 16; i += 16) {\n        uint8x16_t vec = vld1q_u8(reinterpret_cast<const uint8_t*>(&s[i]));\n        vec = vsubq_u8(vec, shift);\n        vec = vmulq_u8(vec, vdupq_n_u8(26));\n        vec = vaddq_u8(vec, base);\n        vec = vminq_u8(vec, vdupq_n_u8('z'));\n        vec = vmaxq_u8(vec, vdupq_n_u8('a'));\n        vst1q_u8(reinterpret_cast<uint8_t*>(&out[i]), vec);\n    }\n\n    // Handle remaining characters\n    for (size_t i = len - len % 16; i < len; ++i) {\n        out[i] = ((s[i] - 'a' - 5 + 26) % 26) + 'a';\n    }\n\n    return out;\n}\n```"}
{"task_id": "SimdBench_87_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nstd::string decode_shift_simd(const std::string& s) {\n    const size_t len = s.length();\n    std::string out(len, '\\0');\n    \n    const uint8x16_t shift = vdupq_n_u8(5);\n    const uint8x16_t base = vdupq_n_u8('a');\n    const uint8x16_t mod = vdupq_n_u8(26);\n    \n    size_t i = 0;\n    while (i + 16 <= len) {\n        uint8x16_t input = vld1q_u8(reinterpret_cast<const uint8_t*>(&s[i]));\n        \n        // Shift characters by 5\n        uint8x16_t shifted = vaddq_u8(input, shift);\n        \n        // Subtract 'a' to get zero-based index\n        uint8x16_t subtracted = vsubq_u8(shifted, base);\n        \n        // Modulo 26\n        uint8x16_t modulo = vmulq_u8(subtracted, mod);\n        uint8x16_t remainder = vmodq_u8(modulo, mod);\n        \n        // Add 'a' back to get original characters\n        uint8x16_t result = vaddq_u8(remainder, base);\n        \n        // Store result in output string\n        vst1q_u8(reinterpret_cast<uint8_t*>(&out[i]), result);\n        \n        i += 16;\n    }\n    \n    // Handle remaining characters\n    for (; i < len; ++i) {\n        char c = s[i];\n        if (c >= 'a' && c <= 'z') {\n            c = ((c - 'a' - 5 + 26) % 26) + 'a';\n        }\n        out[i] = c;\n    }\n    \n    return out;\n}\n```"}
{"task_id": "SimdBench_88_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nbool below_threshold_simd(const std::vector<int>& l, int t) {\n    const int* data = l.data();\n    int size = l.size();\n\n    while (size >= 8) {\n        int32x4_t vec1 = vld1q_s32(data);\n        int32x4_t vec2 = vld1q_s32(data + 4);\n        int32x4_t thresh_vec = vmovq_n_s32(t);\n\n        uint32x4_t cmp1 = vcgtq_s32(vec1, thresh_vec);\n        uint32x4_t cmp2 = vcgtq_s32(vec2, thresh_vec);\n\n        if (!vallq_u32(cmp1) || !vallq_u32(cmp2)) {\n            return false;\n        }\n\n        data += 8;\n        size -= 8;\n    }\n\n    while (size > 0) {\n        if (*data >= t) {\n            return false;\n        }\n        data++;\n        size--;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_88_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nbool below_threshold_simd(const std::vector<int>& l, int t) {\n    int32x4_t threshold = vdupq_n_s32(t);\n    int32x4_t zero = vdupq_n_s32(0);\n\n    for (size_t i = 0; i <= l.size() - 4; i += 4) {\n        int32x4_t vec = vld1q_s32(&l[i]);\n        int32x4_t cmp = vcgtq_s32(vec, threshold);\n        uint32x4_t mask = vmovemask_epi8(vreinterpretq_u8_s32(cmp));\n        if (mask != 0) {\n            return false;\n        }\n    }\n\n    // Handle remaining elements\n    for (size_t i = l.size() - l.size() % 4; i < l.size(); ++i) {\n        if (l[i] >= t) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_88_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nbool below_threshold_simd(const std::vector<int>& l, int t) {\n    const int32x4_t threshold = vdupq_n_s32(t);\n    int i = 0;\n    for (; i + 4 <= l.size(); i += 4) {\n        int32x4_t vec = vld1q_s32(&l[i]);\n        uint32x4_t cmp = vcgtq_s32(vec, threshold);\n        if (!vallq_u32(cmp)) {\n            return false;\n        }\n    }\n    for (; i < l.size(); ++i) {\n        if (l[i] >= t) {\n            return false;\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_88_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nbool below_threshold_simd(const std::vector<int>& l, int t) {\n    int32x4_t threshold = vdupq_n_s32(t);\n    int32x4_t zero = vdupq_n_s32(0);\n\n    for (size_t i = 0; i <= l.size() - 4; i += 4) {\n        int32x4_t vec = vld1q_s32(&l[i]);\n        int32x4_t cmp = vcgtq_s32(vec, threshold);\n        uint32x4_t mask = vmovemask_epi8(vreinterpretq_u8_s32(cmp));\n        if (mask != 0) return false;\n    }\n\n    // Handle remaining elements\n    for (size_t i = l.size() - l.size() % 4; i < l.size(); ++i) {\n        if (l[i] >= t) return false;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_88_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nbool below_threshold_simd(const std::vector<int>& l, int t) {\n    const int* data = l.data();\n    int size = l.size();\n\n    while (size >= 8) {\n        int32x4_t vec1 = vld1q_s32(data);\n        int32x4_t vec2 = vld1q_s32(data + 4);\n        int32x4_t thresh1 = vmovq_n_s32(t);\n        int32x4_t thresh2 = vmovq_n_s32(t);\n\n        uint32x4_t cmp1 = vcgtq_s32(vec1, thresh1);\n        uint32x4_t cmp2 = vcgtq_s32(vec2, thresh2);\n\n        if (!vallq_u32(cmp1) || !vallq_u32(cmp2)) {\n            return false;\n        }\n\n        data += 8;\n        size -= 8;\n    }\n\n    while (size > 0) {\n        if (*data >= t) {\n            return false;\n        }\n        data++;\n        size--;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_89_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nbool correct_bracketing_simd(const std::string& brackets) {\n    int32x4_t count = vdupq_n_s32(0);\n    int32x4_t mask_open = vmovq_n_s32(1 << 0);\n    int32x4_t mask_close = vmovq_n_s32(1 << 1);\n\n    for (size_t i = 0; i < brackets.size(); i += 16) {\n        int8x16_t vec = vld1q_s8(reinterpret_cast<const int8_t*>(&brackets[i]));\n        int32x4_t open_mask = vandq_s32(vreinterpretq_s32_s8(vec), mask_open);\n        int32x4_t close_mask = vandq_s32(vreinterpretq_s32_s8(vec), mask_close);\n\n        count = vaddq_s32(count, open_mask);\n        count = vsubq_s32(count, close_mask);\n    }\n\n    int32_t result[4];\n    vst1q_s32(result, count);\n\n    return result[0] == result[1] && result[2] == result[3] && result[0] == 0;\n}\n```"}
{"task_id": "SimdBench_89_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nbool correct_bracketing_simd(const std::string& brackets) {\n    int32x4_t count = vdupq_n_s32(0);\n    int32x4_t open_mask = vdupq_n_s32(1 << 0);\n    int32x4_t close_mask = vdupq_n_s32(1 << 1);\n\n    for (size_t i = 0; i < brackets.size(); i += 16) {\n        int32x4_t chars = vld1q_s32(reinterpret_cast<const int32_t*>(brackets.c_str() + i));\n        int32x4_t open_chars = vandq_s32(chars, open_mask);\n        int32x4_t close_chars = vandq_s32(chars, close_mask);\n\n        int32x4_t open_count = vmovemask_epi8(vreinterpretq_u8_s32(open_chars));\n        int32x4_t close_count = vmovemask_epi8(vreinterpretq_u8_s32(close_chars));\n\n        count = vaddq_s32(count, vdupq_n_s32((open_count & 0xFF) - (close_count & 0xFF)));\n    }\n\n    int sum = vgetq_lane_s32(count, 0) + vgetq_lane_s32(count, 1) +\n              vgetq_lane_s32(count, 2) + vgetq_lane_s32(count, 3);\n\n    return sum == 0;\n}\n```"}
{"task_id": "SimdBench_89_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nbool correct_bracketing_simd(const std::string& brackets) {\n    int32x4_t count = vdupq_n_s32(0);\n    const uint8_t* data = reinterpret_cast<const uint8_t*>(brackets.c_str());\n    size_t len = brackets.length();\n\n    while (len >= 16) {\n        uint8x16_t vec = vld1q_u8(data);\n        uint16x8_t eq_vec = veorq_u16(vceqq_u8(vec, vdupq_n_u8('<')), vceqq_u8(vec, vdupq_n_u8('>')));\n        uint32x4_t sum = vpaddlq_u16(vpaddlq_u8(eq_vec));\n        count = vmlal_n_s32(count, vget_low_s32(sum), 1);\n        count = vmlal_n_s32(count, vget_high_s32(sum), 1);\n        data += 16;\n        len -= 16;\n    }\n\n    while (len > 0) {\n        if (*data == '<') {\n            count[0]++;\n        } else if (*data == '>') {\n            count[0]--;\n        }\n        data++;\n        len--;\n    }\n\n    return count[0] == 0;\n}\n```"}
{"task_id": "SimdBench_89_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nbool correct_bracketing_simd(const std::string& brackets) {\n    int32x4_t count = vdupq_n_s32(0);\n    int32x4_t mask_open = vmovq_n_s32(1 << 0);\n    int32x4_t mask_close = vmovq_n_s32(1 << 1);\n\n    for (size_t i = 0; i < brackets.size(); i += 16) {\n        int8x16_t vec = vld1q_s8(reinterpret_cast<const int8_t*>(&brackets[i]));\n        int32x4_t open_mask = vandq_s32(vreinterpretq_s32_s8(vec), mask_open);\n        int32x4_t close_mask = vandq_s32(vreinterpretq_s32_s8(vec), mask_close);\n\n        count = vaddq_s32(count, open_mask);\n        count = vsubq_s32(count, close_mask);\n    }\n\n    int32_t result[4];\n    vst1q_s32(result, count);\n\n    return result[0] == result[1] && result[2] == result[3] && result[0] == 0;\n}\n```"}
{"task_id": "SimdBench_89_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nbool correct_bracketing_simd(const std::string& brackets) {\n    int32x4_t count = vdupq_n_s32(0);\n    int32x4_t mask_open = vdupq_n_s32(1 << 0);\n    int32x4_t mask_close = vdupq_n_s32(1 << 1);\n\n    for (size_t i = 0; i < brackets.size(); i += 16) {\n        int32x4_t vec = vreinterpretq_s32_u8(vld1q_u8(reinterpret_cast<const uint8_t*>(&brackets[i])));\n\n        int32x4_t open_mask = vandq_s32(vec, mask_open);\n        int32x4_t close_mask = vandq_s32(vec, mask_close);\n\n        count = vaddq_s32(count, vsubq_s32(open_mask, close_mask));\n    }\n\n    int32_t result[4];\n    vst1q_s32(result, count);\n\n    return result[0] == result[1] && result[2] == result[3] && result[0] == 0;\n}\n```"}
{"task_id": "SimdBench_90_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nbool correct_bracketing_simd(const std::string& brackets) {\n    int32x4_t count = vdupq_n_s32(0);\n    const uint8_t* ptr = reinterpret_cast<const uint8_t*>(brackets.c_str());\n    size_t len = brackets.size();\n\n    while (len >= 16) {\n        uint8x16_t vec = vld1q_u8(ptr);\n        int32x4_t increment = vreinterpretq_s32_u32(vaddw_u8(vandq_u8(vec, vmovq_n_u8(0x28)), vshrq_n_u8(vandq_u8(vec, vmovq_n_u8(0x5C)), 5)));\n        int32x4_t decrement = vreinterpretq_s32_u32(vsubw_u8(vandq_u8(vec, vmovq_n_u8(0x29)), vshrq_n_u8(vandq_u8(vec, vmovq_n_u8(0x5D)), 5)));\n        count = vaddq_s32(count, increment);\n        count = vsubq_s32(count, decrement);\n        ptr += 16;\n        len -= 16;\n    }\n\n    while (len > 0) {\n        uint8_t ch = *ptr++;\n        if (ch == '(') {\n            count[0]++;\n        } else if (ch == ')') {\n            count[0]--;\n        }\n        len--;\n    }\n\n    return count[0] == 0;\n}\n```"}
{"task_id": "SimdBench_90_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nbool correct_bracketing_simd(const std::string& brackets) {\n    int32x4_t count = vdupq_n_s32(0);\n    int32x4_t open_mask = vdupq_n_s32(1 << 0);\n    int32x4_t close_mask = vdupq_n_s32(1 << 1);\n\n    for (size_t i = 0; i < brackets.size(); i += 16) {\n        int32x4_t chars = vld1q_s32(reinterpret_cast<const int32_t*>(brackets.c_str() + i));\n        int32x4_t open_chars = vandq_s32(chars, open_mask);\n        int32x4_t close_chars = vandq_s32(chars, close_mask);\n\n        count = vaddq_s32(count, vreinterpretq_s32_u8(vclzq_u8(open_chars)));\n        count = vsubq_s32(count, vreinterpretq_s32_u8(vclzq_u8(close_chars)));\n    }\n\n    int sum = vgetq_lane_s32(count, 0) + vgetq_lane_s32(count, 1) +\n              vgetq_lane_s32(count, 2) + vgetq_lane_s32(count, 3);\n\n    return sum == 0;\n}\n```"}
{"task_id": "SimdBench_90_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nbool correct_bracketing_simd(const std::string& brackets) {\n    int32x4_t count = vdupq_n_s32(0);\n    int32x4_t open_mask = vdupq_n_s32(0);\n    int32x4_t close_mask = vdupq_n_s32(0);\n\n    const char* ptr = brackets.c_str();\n    while (*ptr != '\\0') {\n        int32x4_t chars = vld1q_u8((uint8_t*)ptr);\n        ptr += 16;\n\n        int32x4_t open = vandq_s32(vceqq_u8(chars, vdupq_n_u8('(')), vreinterpretq_s32_u8(open_mask));\n        int32x4_t close = vandq_s32(vceqq_u8(chars, vdupq_n_u8(')')), vreinterpretq_s32_u8(close_mask));\n\n        count = vaddq_s32(count, open);\n        count = vsubq_s32(count, close);\n\n        open_mask = vorrq_s32(open_mask, open);\n        close_mask = vorrq_s32(close_mask, close);\n    }\n\n    return vgetq_lane_s32(count, 0) == 0 && vgetq_lane_s32(open_mask, 0) == 0 && vgetq_lane_s32(close_mask, 0) == 0;\n}\n```"}
{"task_id": "SimdBench_90_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nbool correct_bracketing_simd(const std::string& brackets) {\n    int32x4_t count = vdupq_n_s32(0);\n    const uint8_t* data = reinterpret_cast<const uint8_t*>(brackets.c_str());\n    size_t len = brackets.size();\n\n    while (len >= 16) {\n        uint8x16_t vec = vld1q_u8(data);\n        uint16x8_t eq_open = veorq_u16(vceqq_u8(vec, vdupq_n_u8('(')), vceqq_u8(vec, vdupq_n_u8(')')));\n        uint32x4_t sum = vpaddlq_u16(vpaddlq_u8(eq_open));\n        count = vmlal_n_s32(count, vget_low_s32(sum), 1);\n        count = vmlal_n_s32(count, vget_high_s32(sum), 1);\n        data += 16;\n        len -= 16;\n    }\n\n    while (len > 0) {\n        if (*data == '(' || *data == ')') {\n            count[0] += (*data == '(' ? 1 : -1);\n        }\n        data++;\n        len--;\n    }\n\n    return count[0] == 0;\n}\n```"}
{"task_id": "SimdBench_90_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nbool correct_bracketing_simd(const std::string& brackets) {\n    int32x4_t count = vdupq_n_s32(0);\n    int32x4_t open_mask = vdupq_n_s32(0);\n    int32x4_t close_mask = vdupq_n_s32(0);\n\n    const char* ptr = brackets.c_str();\n    while (*ptr != '\\0') {\n        uint8x16_t chars = vld1q_u8((const uint8_t*)ptr);\n        ptr += 16;\n\n        uint32x4_t open_chars = vandq_u32(vreinterpretq_u32_u8(chars), vdupq_n_u32(0x28));\n        uint32x4_t close_chars = vandq_u32(vreinterpretq_u32_u8(chars), vdupq_n_u32(0x29));\n\n        open_mask = vorrq_s32(open_mask, vcvtq_s32_u32(open_chars));\n        close_mask = vorrq_s32(close_mask, vcvtq_s32_u32(close_chars));\n\n        count = vaddq_s32(count, vcvtq_s32_u32(open_chars));\n        count = vsubq_s32(count, vcvtq_s32_u32(close_chars));\n    }\n\n    int32_t remaining_open = vgetq_lane_s32(count, 0) + vgetq_lane_s32(count, 1) +\n                             vgetq_lane_s32(count, 2) + vgetq_lane_s32(count, 3);\n    int32_t total_open = vgetq_lane_s32(open_mask, 0) + vgetq_lane_s32(open_mask, 1) +\n                         vgetq_lane_s32(open_mask, 2) + vgetq_lane_s32(open_mask, 3);\n    int32_t total_close = vgetq_lane_s32(close_mask, 0) + vgetq_lane_s32(close_mask, 1) +\n                          vgetq_lane_s32(close_mask, 2) + vgetq_lane_s32(close_mask, 3);\n\n    return remaining_open == 0 && total_open == total_close;\n}\n```"}
{"task_id": "SimdBench_91_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<float> derivative_simd(const std::vector<float>& xs) {\n    int n = xs.size();\n    if (n <= 1) return {};\n\n    std::vector<float> result(n - 1);\n    float32x4_t vzero = vdupq_n_f32(0.0f);\n\n    for (int i = 0; i < n - 4; i += 4) {\n        float32x4_t va = vld1q_f32(&xs[i]);\n        float32x4_t vb = vld1q_f32(&xs[i + 4]);\n\n        float32x4_t vc = vmulq_f32(va, vdupq_n_f32(i));\n        float32x4_t vd = vmulq_f32(vb, vdupq_n_f32(i + 4));\n\n        vst1q_f32(&result[i], vc);\n        vst1q_f32(&result[i + 4], vd);\n    }\n\n    for (int i = (n - 4) * 4; i < n - 1; ++i) {\n        result[i] = xs[i] * i;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_91_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<float> derivative_simd(const std::vector<float>& xs) {\n    int n = xs.size();\n    if (n <= 1) return {};\n\n    std::vector<float> result(n - 1);\n    float32x4_t vzero = vdupq_n_f32(0.0f);\n\n    for (int i = 0; i < n - 4; i += 4) {\n        float32x4_t vx = vld1q_f32(&xs[i]);\n        float32x4_t vresult = vmulq_f32(vx, vdupq_n_f32(i));\n        vst1q_f32(&result[i], vresult);\n    }\n\n    for (int i = n - 4; i < n - 1; ++i) {\n        result[i] = xs[i] * i;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_91_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<float> derivative_simd(const std::vector<float>& xs) {\n    int n = xs.size();\n    if (n <= 1) return {};\n\n    std::vector<float> result(n - 1);\n    float32x4_t vzero = vdupq_n_f32(0.0f);\n\n    for (int i = 0; i < n - 4; i += 4) {\n        float32x4_t va = vld1q_f32(&xs[i]);\n        float32x4_t vb = vld1q_f32(&xs[i + 1]);\n        float32x4_t vc = vld1q_f32(&xs[i + 2]);\n        float32x4_t vd = vld1q_f32(&xs[i + 3]);\n\n        float32x4_t vresulta = vmulq_f32(va, vdupq_n_f32(i + 1));\n        float32x4_t vresultb = vmulq_f32(vb, vdupq_n_f32(i + 2));\n        float32x4_t vresultc = vmulq_f32(vc, vdupq_n_f32(i + 3));\n        float32x4_t vresultd = vmulq_f32(vd, vdupq_n_f32(i + 4));\n\n        vst1q_f32(&result[i], vresulta);\n        vst1q_f32(&result[i + 1], vresultb);\n        vst1q_f32(&result[i + 2], vresultc);\n        vst1q_f32(&result[i + 3], vresultd);\n    }\n\n    for (int i = n - 4; i < n - 1; ++i) {\n        result[i] = xs[i] * static_cast<float>(i + 1);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_91_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<float> derivative_simd(const std::vector<float>& xs) {\n    int n = xs.size();\n    if (n <= 1) return {};\n\n    std::vector<float> result(n - 1);\n    float32x4_t vzero = vdupq_n_f32(0.0f);\n\n    for (int i = 0; i < n - 4; i += 4) {\n        float32x4_t va = vld1q_f32(&xs[i]);\n        float32x4_t vb = vld1q_f32(&xs[i + 4]);\n        float32x4_t vc = vmulq_f32(va, vdupq_n_f32(i));\n        float32x4_t vd = vmulq_f32(vb, vdupq_n_f32(i + 4));\n        float32x4_t ve = vaddq_f32(vc, vd);\n        vst1q_f32(&result[i], ve);\n    }\n\n    for (int i = n - 4; i < n - 1; ++i) {\n        result[i] = xs[i] * i;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_91_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<float> derivative_simd(const std::vector<float>& xs) {\n    int n = xs.size();\n    if (n <= 1) return {};\n\n    std::vector<float> result(n - 1);\n    float32x4_t vzero = vdupq_n_f32(0.0f);\n\n    for (int i = 0; i < n - 4; i += 4) {\n        float32x4_t va = vld1q_f32(&xs[i]);\n        float32x4_t vb = vld1q_f32(&xs[i + 4]);\n\n        float32x4_t vc = vmulq_f32(va, vdupq_n_f32(i));\n        float32x4_t vd = vmulq_f32(vb, vdupq_n_f32(i + 4));\n\n        vst1q_f32(&result[i], vc);\n        vst1q_f32(&result[i + 4], vd);\n    }\n\n    for (int i = (n - 4) * 4; i < n - 1; ++i) {\n        result[i] = xs[i] * i;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_92_Neon", "completion": "```cpp\nint vowels_count_simd(const std::string& s) {\n    int count = 0;\n    const char* str = s.c_str();\n    size_t len = s.length();\n\n    // Process 16 characters at a time\n    for (size_t i = 0; i <= len - 16; i += 16) {\n        uint8x16_t vec = vld1q_u8((const uint8_t*)&str[i]);\n        uint8x16_t mask_a = vceqq_u8(vec, vdupq_n_u8('a'));\n        uint8x16_t mask_e = vceqq_u8(vec, vdupq_n_u8('e'));\n        uint8x16_t mask_i = vceqq_u8(vec, vdupq_n_u8('i'));\n        uint8x16_t mask_o = vceqq_u8(vec, vdupq_n_u8('o'));\n        uint8x16_t mask_u = vceqq_u8(vec, vdupq_n_u8('u'));\n        uint8x16_t mask_y = vceqq_u8(vec, vdupq_n_u8('y'));\n\n        uint8x16_t sum_mask = vorrq_u8(mask_a, mask_e);\n        sum_mask = vorrq_u8(sum_mask, mask_i);\n        sum_mask = vorrq_u8(sum_mask, mask_o);\n        sum_mask = vorrq_u8(sum_mask, mask_u);\n\n        uint8x16_t last_char_mask = vceqq_u8(vld1q_u8((const uint8_t*)&str[i + 15]), vdupq_n_u8('y'));\n        sum_mask = vbicq_u8(sum_mask, last_char_mask);\n\n        uint16x8_t sum_vec = vpaddlq_u8(sum_mask);\n        uint32x4_t sum_vec2 = vpaddlq_u16(sum_vec);\n        uint64x2_t sum_vec4 = vpaddlq_u32(sum_vec2);\n        count += vget_lane_u64(sum_vec4, 0);\n    }\n\n    // Process remaining characters\n    for (size_t i = len - len % 16; i < len; ++i) {\n        if (str[i] == 'a' || str[i] == 'e' || str[i] == 'i' || str[i] == 'o' || str[i] == 'u' ||\n            (str[i] == 'y' && i == len - 1)) {\n            ++count;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_92_Neon", "completion": "```cpp\nint vowels_count_simd(const std::string& s) {\n    int count = 0;\n    const char* str = s.c_str();\n    size_t len = s.length();\n\n    while (len >= 16) {\n        uint8x16_t vstr = vld1q_u8((const uint8_t*)str);\n        uint8x16_t va = vdupq_n_u8('a');\n        uint8x16_t ve = vdupq_n_u8('e');\n        uint8x16_t vi = vdupq_n_u8('i');\n        uint8x16_t vo = vdupq_n_u8('o');\n        uint8x16_t vu = vdupq_n_u8('u');\n        uint8x16_t vy = vdupq_n_u8('y');\n\n        uint16x8_t eq_a = vceqq_u8(vstr, va);\n        uint16x8_t eq_e = vceqq_u8(vstr, ve);\n        uint16x8_t eq_i = vceqq_u8(vstr, vi);\n        uint16x8_t eq_o = vceqq_u8(vstr, vo);\n        uint16x8_t eq_u = vceqq_u8(vstr, vu);\n        uint16x8_t eq_y = vceqq_u8(vstr, vy);\n\n        uint16x8_t sum_eq = vaddq_u16(eq_a, eq_e);\n        sum_eq = vaddq_u16(sum_eq, eq_i);\n        sum_eq = vaddq_u16(sum_eq, eq_o);\n        sum_eq = vaddq_u16(sum_eq, eq_u);\n        sum_eq = vaddq_u16(sum_eq, eq_y);\n\n        uint32x4_t sum_eq_32 = vpaddlq_u16(sum_eq);\n        uint32x2_t sum_eq_16 = vpaddl_u32(sum_eq_32);\n        uint32_t sum_eq_8 = vpadd_u32(sum_eq_16);\n\n        count += sum_eq_8;\n\n        str += 16;\n        len -= 16;\n    }\n\n    while (len > 0) {\n        if (*str == 'a' || *str == 'A' ||\n            *str == 'e' || *str == 'E' ||\n            *str == 'i' || *str == 'I' ||\n            *str == 'o' || *str == 'O' ||\n            *str == 'u' || *str == 'U' ||\n            (*str == 'y' || *str == 'Y') && len == 1) {\n            count++;\n        }\n        str++;\n        len--;\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_92_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nint vowels_count_simd(const std::string& s) {\n    int count = 0;\n    const char* str = s.c_str();\n    size_t len = s.length();\n\n    // Process 16 characters at a time\n    for (size_t i = 0; i <= len - 16; i += 16) {\n        uint8x16_t vec = vld1q_u8((const uint8_t*)&str[i]);\n        uint8x16_t mask = vdupq_n_u8(0);\n        mask = vorr_u8(mask, veor_u8(vec, vdupq_n_u8('a')));\n        mask = vorr_u8(mask, veor_u8(vec, vdupq_n_u8('A')));\n        mask = vorr_u8(mask, veor_u8(vec, vdupq_n_u8('e')));\n        mask = vorr_u8(mask, veor_u8(vec, vdupq_n_u8('E')));\n        mask = vorr_u8(mask, veor_u8(vec, vdupq_n_u8('i')));\n        mask = vorr_u8(mask, veor_u8(vec, vdupq_n_u8('I')));\n        mask = vorr_u8(mask, veor_u8(vec, vdupq_n_u8('o')));\n        mask = vorr_u8(mask, veor_u8(vec, vdupq_n_u8('O')));\n        mask = vorr_u8(mask, veor_u8(vec, vdupq_n_u8('u')));\n        mask = vorr_u8(mask, veor_u8(vec, vdupq_n_u8('U')));\n        mask = vorr_u8(mask, veor_u8(vec, vdupq_n_u8('y')));\n        mask = vorr_u8(mask, veor_u8(vec, vdupq_n_u8('Y')));\n\n        uint16x8_t sum = vpaddl_u8(vreinterpretq_u8_u16(mask));\n        uint32x4_t sum4 = vpaddl_u16(sum);\n        uint64x2_t sum2 = vpaddl_u32(sum4);\n        count += vget_lane_u64(sum2, 0);\n    }\n\n    // Process remaining characters\n    for (size_t i = len - len % 16; i < len; ++i) {\n        if (str[i] == 'a' || str[i] == 'e' || str[i] == 'i' || str[i] == 'o' || str[i] == 'u' ||\n            str[i] == 'A' || str[i] == 'E' || str[i] == 'I' || str[i] == 'O' || str[i] == 'U' ||\n            (str[i] == 'y' || str[i] == 'Y') && i == len - 1) {\n            ++count;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_92_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nint vowels_count_simd(const std::string& s) {\n    int count = 0;\n    const char* str = s.c_str();\n    size_t len = s.length();\n\n    // Process 16 characters at a time\n    for (size_t i = 0; i <= len - 16; i += 16) {\n        uint8x16_t vec = vld1q_u8((const uint8_t*)&str[i]);\n        uint8x16_t mask_a = vmovq_n_u8('a');\n        uint8x16_t mask_e = vmovq_n_u8('e');\n        uint8x16_t mask_i = vmovq_n_u8('i');\n        uint8x16_t mask_o = vmovq_n_u8('o');\n        uint8x16_t mask_u = vmovq_n_u8('u');\n        uint8x16_t mask_y = vmovq_n_u8('y');\n\n        uint8x16_t eq_a = vceqq_u8(vec, mask_a);\n        uint8x16_t eq_e = vceqq_u8(vec, mask_e);\n        uint8x16_t eq_i = vceqq_u8(vec, mask_i);\n        uint8x16_t eq_o = vceqq_u8(vec, mask_o);\n        uint8x16_t eq_u = vceqq_u8(vec, mask_u);\n        uint8x16_t eq_y = vceqq_u8(vec, mask_y);\n\n        uint8x16_t sum = veorq_u8(eq_a, eq_e);\n        sum = veorq_u8(sum, eq_i);\n        sum = veorq_u8(sum, eq_o);\n        sum = veorq_u8(sum, eq_u);\n        sum = veorq_u8(sum, eq_y);\n\n        uint16x8_t sum_half = vpaddlq_u8(sum);\n        uint32x4_t sum_quarter = vpaddlq_u16(sum_half);\n        uint64x2_t sum_eighth = vpaddlq_u32(sum_quarter);\n        uint64x1_t total = vget_lane_u64(sum_eighth, 0);\n\n        count += static_cast<int>(total);\n    }\n\n    // Process remaining characters\n    for (size_t i = len - len % 16; i < len; ++i) {\n        if (str[i] == 'a' || str[i] == 'e' || str[i] == 'i' || str[i] == 'o' || str[i] == 'u' ||\n            (str[i] == 'y' && i == len - 1)) {\n            ++count;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_92_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nint vowels_count_simd(const std::string& s) {\n    int count = 0;\n    const char* str = s.c_str();\n    size_t len = s.length();\n\n    while (len >= 16) {\n        uint8x16_t v = vld1q_u8((const uint8_t*)str);\n        uint8x16_t mask = vdupq_n_u8(0x00);\n        mask |= vceqq_u8(v, vld1q_u8((const uint8_t*)\"aeiou\"));\n        mask |= vceqq_u8(v, vld1q_u8((const uint8_t*)\"AEIOU\"));\n        if (str[len - 1] == 'y' || str[len - 1] == 'Y') {\n            mask |= vceqq_u8(vtstq_u8(v, vdupq_n_u8(0x80)), vdupq_n_u8(0x80));\n        }\n        count += vcntq_u8(mask);\n        str += 16;\n        len -= 16;\n    }\n\n    while (len > 0) {\n        if (*str == 'a' || *str == 'e' || *str == 'i' || *str == 'o' || *str == 'u' ||\n            *str == 'A' || *str == 'E' || *str == 'I' || *str == 'O' || *str == 'U' ||\n            (*str == 'y' || *str == 'Y') && len == 1) {\n            count++;\n        }\n        str++;\n        len--;\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_93_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nint digitSum_simd(const std::string& s) {\n    int sum = 0;\n    const char* str = s.c_str();\n    size_t len = s.length();\n\n    while (len >= 16) {\n        uint8x16_t vec = vld1q_u8((const uint8_t*)str);\n        uint8x16_t mask = vdupq_n_u8('A');\n        uint8x16_t upper_mask = vmovq_n_u8('Z' - 'A' + 1);\n        uint8x16_t diff = vsubq_u8(vec, mask);\n        uint8x16_t valid = vandq_u8(vcltq_u8(diff, upper_mask), vgeq_u8(vec, mask));\n        uint8x16_t ascii_sum = vmulq_u8(valid, vec);\n\n        uint8_t result[16];\n        vst1q_u8(result, ascii_sum);\n\n        for (int i = 0; i < 16; ++i) {\n            if (result[i] != 0) {\n                sum += result[i];\n            }\n        }\n\n        str += 16;\n        len -= 16;\n    }\n\n    while (len > 0) {\n        if (*str >= 'A' && *str <= 'Z') {\n            sum += *str;\n        }\n        ++str;\n        --len;\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_93_Neon", "completion": "```cpp\nint digitSum_simd(const std::string& s) {\n    int sum = 0;\n    const char* str = s.c_str();\n    size_t len = s.length();\n\n    while (len >= 16) {\n        uint8x16_t v = vld1q_u8((const uint8_t*)str);\n        uint8x16_t mask = vandq_u8(v, vdupq_n_u8(0x5F)); // Mask out non-uppercase letters\n        uint16x8_t sum_vec = vpaddlq_u8(mask); // Sum the ASCII values\n        uint64x2_t sum_pair = vpaddlq_u16(sum_vec); // Sum the pairs\n        sum += vget_lane_u64(sum_pair, 0) + vget_lane_u64(sum_pair, 1);\n\n        str += 16;\n        len -= 16;\n    }\n\n    while (len > 0) {\n        if (*str >= 'A' && *str <= 'Z') {\n            sum += *str;\n        }\n        str++;\n        len--;\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_93_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nint digitSum_simd(const std::string& s) {\n    int sum = 0;\n    const char* str = s.c_str();\n    size_t len = s.length();\n\n    while (len >= 16) {\n        uint8x16_t v = vld1q_u8((const uint8_t*)str);\n        uint8x16_t mask = vandq_u8(v, vmovq_n_u8(0x5F)); // Mask out non-uppercase letters\n        uint8x16_t upper = vandq_u8(v, mask); // Keep only uppercase letters\n        uint16x8_t sum_vec = vpaddlq_u8(upper); // Sum pairs of bytes\n        uint16x4_t sum_vec_lo = vpaddw_u16(sum_vec, sum_vec); // Sum pairs of words\n        uint16x2_t sum_vec_lo_lo = vpaddw_u16(sum_vec_lo, sum_vec_lo); // Sum pairs of half-words\n        uint16_t sum_val = vget_lane_u16(sum_vec_lo_lo, 0); // Extract the result\n        sum += sum_val;\n\n        str += 16;\n        len -= 16;\n    }\n\n    while (len > 0) {\n        if (*str >= 'A' && *str <= 'Z') {\n            sum += *str;\n        }\n        str++;\n        len--;\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_93_Neon", "completion": "```cpp\nint digitSum_simd(const std::string& s) {\n    int sum = 0;\n    const char* str = s.c_str();\n    size_t len = s.length();\n\n    for (size_t i = 0; i <= len - 16; i += 16) {\n        uint8x16_t vec = vld1q_u8(str + i);\n        uint8x16_t mask = vdupq_n_u8('A');\n        uint8x16_t mask2 = vdupq_n_u8('Z' + 1);\n        uint8x16_t upper_chars = vandq_u8(vec, vmovq_n_u8(0x5F));\n        uint8x16_t valid_chars = vbicq_u8(upper_chars, mask2);\n        uint8x16_t result = vandq_u8(valid_chars, mask);\n\n        uint8x16_t ones = vdupq_n_u8(1);\n        uint8x16_t count = vcntq_u8(result);\n        uint32x4_t sum_vec = vpaddw_u32(vreinterpretq_u32_u8(count), vreinterpretq_u32_u8(count));\n\n        sum += vgetq_lane_u32(sum_vec, 0) + vgetq_lane_u32(sum_vec, 1);\n    }\n\n    // Handle remaining characters\n    for (size_t i = len - len % 16; i < len; ++i) {\n        if (str[i] >= 'A' && str[i] <= 'Z') {\n            sum += static_cast<int>(str[i]);\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_93_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nint digitSum_simd(const std::string& s) {\n    int sum = 0;\n    const char* str = s.c_str();\n    size_t len = s.length();\n\n    // Process in chunks of 16 bytes\n    for (size_t i = 0; i <= len - 16; i += 16) {\n        uint8x16_t vec = vld1q_u8(str + i);\n        uint8x16_t mask = vdupq_n_u8('A');\n        uint8x16_t upper_mask = vmovq_n_u8('Z' - 'A' + 1);\n\n        // Check if character is uppercase\n        uint8x16_t is_upper = vandq_u8(vec, mask);\n        is_upper = veorq_u8(is_upper, upper_mask);\n\n        // Sum ASCII values of uppercase characters\n        uint8x16_t ascii_sum = vaddw_u8(vreinterpretq_u8_u16(vshlq_n_u16(vreinterpretq_u16_u8(vec), 8)), vec);\n        ascii_sum = vandq_u8(ascii_sum, is_upper);\n\n        // Reduce the sum to a single value\n        uint32x4_t sum_vec = vpaddq_u32(vpaddq_u32(vreinterpretq_u32_u8(ascii_sum), vreinterpretq_u32_u8(ascii_sum + 16)), vreinterpretq_u32_u8(ascii_sum + 32));\n        sum_vec = vpaddq_u32(sum_vec, vdupq_lane_u32(vgetq_lane_u32(sum_vec, 0), 1));\n        sum_vec = vpaddq_u32(sum_vec, vdupq_lane_u32(vgetq_lane_u32(sum_vec, 0), 2));\n\n        sum += vgetq_lane_u32(sum_vec, 0);\n    }\n\n    // Process remaining characters\n    for (size_t i = len - len % 16; i < len; ++i) {\n        if (str[i] >= 'A' && str[i] <= 'Z') {\n            sum += static_cast<int>(str[i]);\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_94_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int> pluck_simd(const std::vector<int>& arr) {\n    int min_even = INT_MAX;\n    int min_index = -1;\n    int size = arr.size();\n\n    if (size == 0) {\n        return {};\n    }\n\n    int i = 0;\n    for (; i + 7 < size; i += 8) {\n        int32x4_t v1 = vld1q_s32(&arr[i]);\n        int32x4_t v2 = vld1q_s32(&arr[i + 4]);\n\n        uint32x4_t mask1 = vandq_u32(vreinterpretq_u32_s32(v1), vdupq_n_u32(0xFFFFFFFE));\n        uint32x4_t mask2 = vandq_u32(vreinterpretq_u32_s32(v2), vdupq_n_u32(0xFFFFFFFE));\n\n        int32x4_t min1 = vminq_s32(v1, mask1);\n        int32x4_t min2 = vminq_s32(v2, mask2);\n\n        int32x4_t min_all = vminq_s32(min1, min2);\n\n        uint32x4_t eq_mask = veorq_u32(min_all, vreinterpretq_u32_s32(min_all));\n        uint32x4_t idx_mask = vmovq_n_u32(i);\n\n        uint32x4_t min_idx1 = vaddq_u32(idx_mask, vclzq_u32(eq_mask));\n        uint32x4_t min_idx2 = vaddq_u32(vdupq_n_u32(i + 4), vclzq_u32(eq_mask >> 32));\n\n        uint32x4_t min_idx_all = vminq_u32(min_idx1, min_idx2);\n\n        int32x4_t min_val_all = vreinterpretq_s32_u32(min_idx_all);\n\n        int32x4_t min_val_mask = vceqq_s32(min_val_all, vreinterpretq_s32_u32(min_idx_all));\n\n        int32x4_t min_val = vbslq_s32(min_val_mask, min_val_all, vdupq_n_s32(INT_MAX));\n\n        int32x4_t min_idx = vbslq_s32(min_val_mask, min_idx_all, vdupq_n_s32(-1));\n\n        int32x4_t min_val_min = vminq_s32(min_val, vdupq_n_s32(min_even));\n        int32x4_t min_idx_min = vminq_s32(min_idx, vdupq_n_s32(min_index));\n\n        min_even = vgetq_lane_s32(min_val_min, 0);\n        min_index = vgetq_lane_s32(min_idx_min, 0);\n    }\n\n    for (; i < size; ++i) {\n        if (arr[i] % 2 == 0 && arr[i] < min_even) {\n            min_even = arr[i];\n            min_index = i;\n        }\n    }\n\n    if (min_index == -1) {\n        return {};\n    } else {\n        return {min_even, min_index};\n    }\n}\n```"}
{"task_id": "SimdBench_94_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int> pluck_simd(const std::vector<int>& arr) {\n    if (arr.empty()) {\n        return {};\n    }\n\n    int min_even = INT_MAX;\n    int min_index = -1;\n\n    int n = arr.size();\n    int i = 0;\n\n    while (i < n) {\n        int32x4_t v = vld1q_s32(&arr[i]);\n        uint32x4_t mask = vandq_u32(vreinterpretq_u32_s32(v), vmovq_n_u32(0xFFFFFFFE));\n        int32x4_t evens = vreinterpretq_s32_u32(mask);\n\n        uint32x4_t eq_mask = veorq_u32(evens, vdupq_n_s32(INT_MAX));\n        uint32x4_t idx_mask = vcltq_s32(evens, vdupq_n_s32(min_even));\n\n        uint32x4_t combined_mask = vorrq_u32(eq_mask, idx_mask);\n        uint32x4_t indices = vdupq_n_s32(i);\n\n        uint32x4_t selected_indices = vbicq_u32(indices, vnegq_u32(combined_mask));\n\n        int32x4_t selected_values = vtbl1q_s32(v, selected_indices);\n\n        min_even = vminvq_s32(selected_values);\n        min_index = vminvq_u32(selected_indices);\n\n        i += 4;\n    }\n\n    if (min_index == -1) {\n        return {};\n    }\n\n    return {min_even, min_index};\n}\n```"}
{"task_id": "SimdBench_94_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int> pluck_simd(const std::vector<int>& arr) {\n    if (arr.empty()) {\n        return {};\n    }\n\n    int min_even = INT_MAX;\n    int min_index = -1;\n\n    int n = arr.size();\n    int i = 0;\n\n    while (i < n) {\n        int32x4_t v = vld1q_s32(&arr[i]);\n        uint32x4_t mask = vandq_u32(vreinterpretq_u32_s32(v), vdupq_n_u32(0xFFFFFFFE));\n        int32x4_t evens = vreinterpretq_s32_u32(mask);\n\n        uint32x4_t eq_mask = veorq_u32(evens, vdupq_n_s32(-1));\n        uint32x4_t idx_mask = vshrq_n_u32(vreinterpretq_u32_s32(v), 1);\n        uint32x4_t valid_idx = vmulq_u32(idx_mask, eq_mask);\n\n        uint32x4_t min_valid_idx = vminq_u32(valid_idx, vdupq_n_u32(INT_MAX));\n\n        int32x4_t min_values = vld1q_s32(reinterpret_cast<const int*>(&min_valid_idx));\n        int32x4_t min_indices = vld1q_s32(reinterpret_cast<const int*>(&min_valid_idx));\n\n        min_even = vminvq_s32(min_values);\n        min_index = vminvq_u32(min_indices);\n\n        i += 4;\n    }\n\n    if (min_index == -1) {\n        return {};\n    }\n\n    return {min_even, min_index};\n}\n```"}
{"task_id": "SimdBench_94_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int> pluck_simd(const std::vector<int>& arr) {\n    if (arr.empty()) {\n        return {};\n    }\n\n    int min_even = INT_MAX;\n    int min_index = -1;\n\n    int n = arr.size();\n    int i = 0;\n\n    while (i < n) {\n        int32x4_t v = vld1q_s32(&arr[i]);\n        uint32x4_t mask = vandq_u32(vreinterpretq_u32_s32(v), vmovq_n_u32(0xFFFFFFFE));\n        int32x4_t evens = vreinterpretq_s32_u32(mask);\n\n        uint32x4_t eq_mask = veorq_u32(evens, vdupq_n_s32(INT_MAX));\n        uint32x4_t eq_indices = vbslq_u32(eq_mask, vdupq_n_s32(i), vdupq_n_s32(-1));\n\n        int32x4_t min_values = vminq_s32(evens, vdupq_n_s32(min_even));\n        uint32x4_t min_indices = vbslq_u32(vceqq_s32(evens, min_values), eq_indices, vdupq_n_s32(min_index));\n\n        min_even = vminvq_s32(min_values);\n        min_index = vminvq_u32(min_indices);\n\n        i += 4;\n    }\n\n    if (min_index == -1) {\n        return {};\n    }\n\n    return {min_even, min_index};\n}\n```"}
{"task_id": "SimdBench_94_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int> pluck_simd(const std::vector<int>& arr) {\n    if (arr.empty()) {\n        return {};\n    }\n\n    int min_even = INT_MAX;\n    int min_index = -1;\n\n    int n = arr.size();\n    int i = 0;\n\n    while (i < n) {\n        int32x4_t v = vld1q_s32(&arr[i]);\n        uint32x4_t mask = vandq_u32(vreinterpretq_u32_s32(v), vmovq_n_u32(0xFFFFFFFE));\n        int32x4_t evens = vreinterpretq_s32_u32(mask);\n\n        uint32x4_t eq_mask = veorq_u32(evens, vdupq_n_s32(INT_MIN));\n        uint32x4_t eq_indices = vaddq_u32(vdupq_n_u32(i), vclzq_u32(eq_mask));\n\n        uint32x4_t min_eq_indices = vminq_u32(eq_indices, vdupq_n_u32(min_index));\n        uint32x4_t min_eq_values = vminq_s32(evens, vdupq_n_s32(min_even));\n\n        min_index = vgetq_lane_u32(min_eq_indices, 0);\n        min_even = vgetq_lane_s32(min_eq_values, 0);\n\n        i += 4;\n    }\n\n    if (min_index == -1) {\n        return {};\n    }\n\n    return {min_even, min_index};\n}\n```"}
{"task_id": "SimdBench_95_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <algorithm>\n#include <limits>\n\nint search_simd(const std::vector<int>& lst) {\n    const int max_val = *std::max_element(lst.begin(), lst.end());\n    if (max_val > 255) return -1;\n\n    uint8x16_t count[256] = {0};\n    uint8x16_t freqs[256] = {0};\n\n    for (size_t i = 0; i < lst.size(); i += 16) {\n        uint8x16_t vec = vld1q_u8(reinterpret_cast<const uint8_t*>(&lst[i]));\n        uint8x16_t mask = vcltq_u8(vec, vdupq_n_u8(max_val + 1));\n        vec &= mask;\n        for (int j = 0; j < 16; ++j) {\n            int val = vec[j];\n            if (val != 0) {\n                count[val]++;\n                freqs[val] = vsetq_lane_u8(vgetq_lane_u8(freqs[val], 0) + 1, freqs[val], 0);\n            }\n        }\n    }\n\n    for (int i = 1; i <= max_val; ++i) {\n        if (count[i] >= i && freqs[i][0] >= i) {\n            return i;\n        }\n    }\n\n    return -1;\n}\n```"}
{"task_id": "SimdBench_95_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <algorithm>\n\nint search_simd(const std::vector<int>& lst) {\n    const int n = lst.size();\n    if (n < 8) {\n        // Fallback to scalar code for small vectors\n        int result = -1;\n        for (int i = 0; i < n; ++i) {\n            int count = 1;\n            for (int j = i + 1; j < n; ++j) {\n                if (lst[j] == lst[i]) {\n                    ++count;\n                }\n            }\n            if (count >= lst[i] && lst[i] > result) {\n                result = lst[i];\n            }\n        }\n        return result;\n    }\n\n    // Use Neon intrinsics for larger vectors\n    int max_val = *std::max_element(lst.begin(), lst.end());\n    int* data = &lst[0];\n\n    int result = -1;\n    for (int val = 1; val <= max_val; ++val) {\n        int count = 0;\n        int v_count = 0;\n        int v_val = val;\n\n        for (int i = 0; i < n; i += 8) {\n            int8x8_t v_data = vld1_s8(data + i);\n            int8x8_t v_val_vec = vdup_n_s8(v_val);\n\n            int8x8_t eq_mask = veq_u8(v_data, v_val_vec);\n            int mask = vget_lane_u32(vpaddl_u8(eq_mask), 0);\n\n            count += __builtin_popcount(mask);\n        }\n\n        if (count >= val && val > result) {\n            result = val;\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_95_Neon", "completion": "```cpp\nint search_simd(const std::vector<int>& lst) {\n    const int max_val = 1000; // Assuming the maximum possible value in the list is less than 1000\n    uint32x4_t count[256 / 4] = {0};\n    \n    // Count occurrences of each value using Neon intrinsics\n    for (size_t i = 0; i < lst.size(); i += 4) {\n        uint32x4_t values = vld1q_u32(&lst[i]);\n        uint32x4_t mask = vandq_u32(values, vmovq_n_u32(0xFF));\n        uint32x4_t indices = vreinterpretq_u32_u8(vshlq_n_u8(vreinterpretq_u8_u32(mask), vdupq_n_u8(24)));\n        uint32x4_t ones = vdupq_n_u32(1);\n        for (int j = 0; j < 4; ++j) {\n            uint32x4_t idx = vsetq_lane_u32(indices[j], ones, j);\n            count[idx >> 2] = vaddq_u32(count[idx >> 2], idx & 3 ? vdupq_n_u32(0) : ones);\n        }\n    }\n\n    // Find the greatest integer with frequency >= its value\n    int result = -1;\n    for (int i = 0; i <= max_val; ++i) {\n        if (count[i >> 2][i & 3] >= i) {\n            result = i;\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_95_Neon", "completion": "```cpp\nint search_simd(std::vector<int> lst) {\n    const int max_val = 1000; // Assuming the maximum possible value in the list is 1000\n    int freq[max_val + 1] = {0};\n    \n    // Count frequencies using Neon intrinsics\n    size_t n = lst.size();\n    size_t i = 0;\n    for (; i <= n - 8; i += 8) {\n        int32x4_t v1 = vld1q_s32(&lst[i]);\n        int32x4_t v2 = vld1q_s32(&lst[i + 4]);\n        freq[lst[i]]++;\n        freq[lst[i + 1]]++;\n        freq[lst[i + 2]]++;\n        freq[lst[i + 3]]++;\n        freq[lst[i + 4]]++;\n        freq[lst[i + 5]]++;\n        freq[lst[i + 6]]++;\n        freq[lst[i + 7]]++;\n    }\n    for (; i < n; ++i) {\n        freq[lst[i]]++;\n    }\n\n    // Find the greatest integer with frequency >= its value\n    int result = -1;\n    for (int val = 1; val <= max_val; ++val) {\n        if (freq[val] >= val && val > result) {\n            result = val;\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_95_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <algorithm>\n\nint search_simd(const std::vector<int>& lst) {\n    const int n = lst.size();\n    if (n < 8) {\n        return -1;\n    }\n\n    // Initialize count array with zeros\n    uint32x4_t counts[2] = {vdupq_n_u32(0), vdupq_n_u32(0)};\n    uint32x4_t mask = vdupq_n_u32(0xFFFFFFFF);\n\n    // Process elements in chunks of 8\n    for (size_t i = 0; i < n; i += 8) {\n        uint32x4_t vec1 = vld1q_u32(&lst[i]);\n        uint32x4_t vec2 = vld1q_u32(&lst[i + 4]);\n\n        // Mask out values less than or equal to zero\n        vec1 = vandq_u32(vec1, mask);\n        vec2 = vandq_u32(vec2, mask);\n\n        // Count occurrences of each value\n        for (int j = 1; j <= 7; ++j) {\n            uint32x4_t cmp1 = vceqq_u32(vec1, vdupq_n_u32(j));\n            uint32x4_t cmp2 = vceqq_u32(vec2, vdupq_n_u32(j));\n            counts[j >> 2] = vaddq_u32(counts[j >> 2], vreinterpretq_u32_u8(vcntq_u8(vreinterpretq_u8_u32(cmp1))));\n            counts[j >> 2] = vaddq_u32(counts[j >> 2], vreinterpretq_u32_u8(vcntq_u8(vreinterpretq_u8_u32(cmp2))));\n        }\n    }\n\n    // Check for the greatest integer with frequency >= value\n    int result = -1;\n    for (int i = 1; i <= 7; ++i) {\n        if (counts[i >> 2][i & 3] >= i && i > result) {\n            result = i;\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_96_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nbool will_it_fly_simd(const std::vector<int>& q, int w) {\n    int size = q.size();\n    if (size == 0) return false;\n\n    int sum = 0;\n    int half_size = size / 2;\n    int remaining_weight = w;\n\n    // Calculate sum and check balance using Neon intrinsics\n    int32x4_t vsum = vdupq_n_s32(0);\n    int32x4_t vremaining_weight = vdupq_n_s32(w);\n\n    for (int i = 0; i < half_size; ++i) {\n        int32x4_t va = vld1q_lane_s32(&q[i], vsum, 0);\n        int32x4_t vb = vld1q_lane_s32(&q[size - i - 1], vsum, 0);\n        vsum = vaddq_s32(vsum, va);\n        vremaining_weight = vsubq_s32(vremaining_weight, vb);\n\n        if (vgetq_lane_s32(vremaining_weight, 0) < 0) return false;\n    }\n\n    sum = vgetq_lane_s32(vsum, 0);\n    remaining_weight = vgetq_lane_s32(vremaining_weight, 0);\n\n    // Check if the sum is less than or equal to the maximum possible weight\n    if (sum > remaining_weight) return false;\n\n    // Check if the vector is balanced\n    for (int i = half_size; i < size; ++i) {\n        if (q[i] != q[size - i - 1]) return false;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_96_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nbool will_it_fly_simd(const std::vector<int>& q, int w) {\n    int size = q.size();\n    if (size == 0) return false;\n\n    int sum = 0;\n    int half_size = size / 2;\n    int remaining_weight = w;\n\n    // Calculate sum and check balance using Neon intrinsics\n    int32x4_t vsum = vdupq_n_s32(0);\n    int32x4_t vremaining = vdupq_n_s32(w);\n\n    for (int i = 0; i < half_size; ++i) {\n        int32x2_t vq1 = vld1_lane_s32(&q[i], vq1, 0);\n        int32x2_t vq2 = vld1_lane_s32(&q[size - 1 - i], vq2, 0);\n        vsum = vaddw_s16(vsum, vmovl_s16(vget_low_s16(vq1)));\n        vsum = vaddw_s16(vsum, vmovl_s16(vget_high_s16(vq2)));\n        vremaining = vsubw_s16(vremaining, vmovl_s16(vget_low_s16(vq1)));\n        vremaining = vsubw_s16(vremaining, vmovl_s16(vget_high_s16(vq2)));\n    }\n\n    int32x2_t vsum_lo = vget_low_s32(vsum);\n    int32x2_t vsum_hi = vget_high_s32(vsum);\n    int32x2_t vremaining_lo = vget_low_s32(vremaining);\n    int32x2_t vremaining_hi = vget_high_s32(vremaining);\n\n    int sum_lo = vget_lane_s32(vsum_lo, 0) + vget_lane_s32(vsum_lo, 1);\n    int sum_hi = vget_lane_s32(vsum_hi, 0) + vget_lane_s32(vsum_hi, 1);\n    int remaining_lo = vget_lane_s32(vremaining_lo, 0) + vget_lane_s32(vremaining_lo, 1);\n    int remaining_hi = vget_lane_s32(vremaining_hi, 0) + vget_lane_s32(vremaining_hi, 1);\n\n    sum = sum_lo + sum_hi;\n    remaining_weight = remaining_lo + remaining_hi;\n\n    if (size % 2 != 0) {\n        sum += q[half_size];\n        remaining_weight -= q[half_size];\n    }\n\n    bool is_balanced = (sum == remaining_weight);\n    bool is_light_enough = (sum <= w);\n\n    return is_balanced && is_light_enough;\n}\n```"}
{"task_id": "SimdBench_96_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nbool will_it_fly_simd(const std::vector<int>& q, int w) {\n    int size = q.size();\n    if (size == 0) return false;\n\n    int sum = 0;\n    int half_size = size / 2;\n    int remaining_weight = w;\n\n    // Calculate sum and check balance using Neon intrinsics\n    int32x4_t vsum = vdupq_n_s32(0);\n    int32x4_t vremaining_weight = vdupq_n_s32(w);\n\n    for (int i = 0; i < half_size; ++i) {\n        int32x2_t vq1 = vld1_lane_s32(&q[i], vq1, 0);\n        int32x2_t vq2 = vld1_lane_s32(&q[size - 1 - i], vq2, 0);\n        vsum = vaddw_s16(vsum, vmovl_s16(vget_low_s16(vq1)));\n        vsum = vaddw_s16(vsum, vmovl_s16(vget_high_s16(vq2)));\n        vremaining_weight = vsubw_s16(vremaining_weight, vmovl_s16(vget_low_s16(vq1)));\n        vremaining_weight = vsubw_s16(vremaining_weight, vmovl_s16(vget_high_s16(vq2)));\n    }\n\n    int32x2_t vsum_lo = vget_low_s32(vsum);\n    int32x2_t vsum_hi = vget_high_s32(vsum);\n    int32x2_t vremaining_weight_lo = vget_low_s32(vremaining_weight);\n    int32x2_t vremaining_weight_hi = vget_high_s32(vremaining_weight);\n\n    int sum_lo = vget_lane_s32(vsum_lo, 0) + vget_lane_s32(vsum_lo, 1);\n    int sum_hi = vget_lane_s32(vsum_hi, 0) + vget_lane_s32(vsum_hi, 1);\n    int remaining_weight_lo = vget_lane_s32(vremaining_weight_lo, 0) + vget_lane_s32(vremaining_weight_lo, 1);\n    int remaining_weight_hi = vget_lane_s32(vremaining_weight_hi, 0) + vget_lane_s32(vremaining_weight_hi, 1);\n\n    sum = sum_lo + sum_hi;\n    remaining_weight = remaining_weight_lo + remaining_weight_hi;\n\n    if (size % 2 != 0) {\n        sum += q[half_size];\n        remaining_weight -= q[half_size];\n    }\n\n    bool is_balanced = (sum == 2 * sum) && (sum <= remaining_weight);\n    return is_balanced;\n}\n```"}
{"task_id": "SimdBench_96_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nbool will_it_fly_simd(const std::vector<int>& q, int w) {\n    int size = q.size();\n    if (size == 0) return false;\n\n    int sum = 0;\n    int half_size = size / 2;\n    int remaining_weight = w;\n\n    // Calculate sum and check balance using Neon intrinsics\n    int32x4_t vsum = vdupq_n_s32(0);\n    int32x4_t vremaining = vdupq_n_s32(w);\n\n    for (int i = 0; i < half_size; ++i) {\n        int32x2_t vq1 = vld1_lane_s32(&q[i], vq1, 0);\n        int32x2_t vq2 = vld1_lane_s32(&q[size - 1 - i], vq2, 0);\n        vsum = vaddw_u16(vsum, vmovl_u8(vreinterpret_u8_s16(vq1)));\n        vsum = vaddw_u16(vsum, vmovl_u8(vreinterpret_u8_s16(vq2)));\n        vremaining = vsubw_u16(vremaining, vmovl_u8(vreinterpret_u8_s16(vq1)));\n        vremaining = vsubw_u16(vremaining, vmovl_u8(vreinterpret_u8_s16(vq2)));\n    }\n\n    int32x2_t vsum_low = vget_low_s32(vsum);\n    int32x2_t vsum_high = vget_high_s32(vsum);\n    int32x2_t vremaining_low = vget_low_s32(vremaining);\n    int32x2_t vremaining_high = vget_high_s32(vremaining);\n\n    int sum_value = vget_lane_s32(vsum_low, 0) + vget_lane_s32(vsum_low, 1) +\n                    vget_lane_s32(vsum_high, 0) + vget_lane_s32(vsum_high, 1);\n    int remaining_value = vget_lane_s32(vremaining_low, 0) + vget_lane_s32(vremaining_low, 1) +\n                          vget_lane_s32(vremaining_high, 0) + vget_lane_s32(vremaining_high, 1);\n\n    if (sum_value > w || remaining_value <= 0) return false;\n\n    // Check if the vector is balanced\n    for (int i = 0; i < half_size; ++i) {\n        if (q[i] != q[size - 1 - i]) return false;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_96_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nbool will_it_fly_simd(const std::vector<int>& q, int w) {\n    int size = q.size();\n    if (size == 0) return false;\n\n    int sum = 0;\n    int half_size = size / 2;\n    int remaining_weight = w;\n\n    // Calculate sum and check balance using Neon intrinsics\n    int32x4_t vsum = vdupq_n_s32(0);\n    int32x4_t vremaining = vdupq_n_s32(w);\n\n    for (int i = 0; i < half_size; ++i) {\n        int32x2_t vq1 = vld1_lane_s32(&q[i], vq1, 0);\n        int32x2_t vq2 = vld1_lane_s32(&q[size - i - 1], vq2, 0);\n        vsum = vaddw_s16(vsum, vmovl_s16(vget_low_s16(vq1)));\n        vsum = vaddw_s16(vsum, vmovl_s16(vget_high_s16(vq2)));\n        vremaining = vsubw_s16(vremaining, vmovl_s16(vget_low_s16(vq1)));\n        vremaining = vsubw_s16(vremaining, vmovl_s16(vget_high_s16(vq2)));\n\n        if (vget_lane_s32(vremaining, 0) < 0 || vget_lane_s32(vremaining, 1) < 0) {\n            return false;\n        }\n    }\n\n    int32x2_t vsum_lo = vget_low_s32(vsum);\n    int32x2_t vsum_hi = vget_high_s32(vsum);\n    int32x2_t vsum_all = vadd_s16(vsum_lo, vsum_hi);\n\n    sum += vget_lane_s32(vsum_all, 0) + vget_lane_s32(vsum_all, 1);\n\n    if (size % 2 != 0) {\n        sum += q[half_size];\n    }\n\n    return sum <= w && remaining_weight >= 0;\n}\n```"}
{"task_id": "SimdBench_97_Neon", "completion": "```cpp\nint smallest_change_simd(const std::vector<int>& arr) {\n    int n = arr.size();\n    int changes = 0;\n    int half_n = n / 2;\n\n    for (int i = 0; i < half_n; ++i) {\n        int32x4_t vec1 = vld1q_s32(&arr[i * 4]);\n        int32x4_t vec2 = vld1q_s32(&arr[(n - i - 1) * 4]);\n\n        uint32x4_t eq_mask = vceqq_s32(vec1, vec2);\n        uint32x4_t diff_count = vmvnq_u32(eq_mask);\n\n        changes += vaddvq_u32(diff_count);\n    }\n\n    if (n % 4 != 0) {\n        int remaining = n % 4;\n        for (int i = 0; i < remaining; ++i) {\n            if (arr[half_n + i] != arr[n - half_n - 1 - i]) {\n                ++changes;\n            }\n        }\n    }\n\n    return changes;\n}\n```"}
{"task_id": "SimdBench_97_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nint smallest_change_simd(const std::vector<int>& arr) {\n    int n = arr.size();\n    int changes = 0;\n\n    for (int i = 0; i < n / 2; ++i) {\n        int32x4_t vec1 = vld1q_s32(&arr[i * 4]);\n        int32x4_t vec2 = vld1q_s32(&arr[(n - i - 1) * 4]);\n\n        uint32x4_t cmp = vceqq_s32(vec1, vec2);\n        int count = vcnt_u32(cmp);\n\n        changes += 8 - count;\n    }\n\n    if (n % 2 != 0) {\n        int mid = arr[n / 2];\n        // Handle the middle element if the array size is odd\n        // For simplicity, we assume it doesn't need to be changed\n    }\n\n    return changes;\n}\n```"}
{"task_id": "SimdBench_97_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nint smallest_change_simd(const std::vector<int>& arr) {\n    int n = arr.size();\n    int changes = 0;\n\n    for (int i = 0; i < n / 2; ++i) {\n        int32x4_t vec1 = vld1q_s32(&arr[i * 4]);\n        int32x4_t vec2 = vld1q_s32(&arr[(n - i - 1) * 4]);\n\n        uint32x4_t eq_mask = vceqq_s32(vec1, vec2);\n        uint32x4_t diff_count = vmvnq_u32(eq_mask);\n\n        changes += vcntq_u32(diff_count);\n    }\n\n    if (n % 4 != 0) {\n        int remaining = n % 4;\n        for (int i = 0; i < remaining / 2; ++i) {\n            if (arr[i] != arr[n - i - 1]) {\n                ++changes;\n            }\n        }\n    }\n\n    return changes;\n}\n```"}
{"task_id": "SimdBench_97_Neon", "completion": "```cpp\nint smallest_change_simd(const std::vector<int>& arr) {\n    int n = arr.size();\n    int changes = 0;\n    int half_n = n / 2;\n\n    for (int i = 0; i < half_n; ++i) {\n        int32x4_t v1 = vld1q_s32(&arr[i * 4]);\n        int32x4_t v2 = vld1q_s32(&arr[(n - i - 1) * 4]);\n\n        uint32x4_t eq_mask = vceqq_s32(v1, v2);\n        int count_eq = vcnt_u32(eq_mask);\n\n        changes += 8 - count_eq;\n    }\n\n    if (n % 4 != 0) {\n        int remaining = n % 4;\n        int start_index = (n - remaining) / 2;\n        int end_index = start_index + remaining;\n\n        for (int i = start_index; i < end_index; ++i) {\n            if (arr[i] != arr[n - i - 1]) {\n                ++changes;\n            }\n        }\n    }\n\n    return changes;\n}\n```"}
{"task_id": "SimdBench_97_Neon", "completion": "```cpp\nint smallest_change_simd(const std::vector<int>& arr) {\n    int n = arr.size();\n    int changes = 0;\n    int half_n = n / 2;\n\n    for (int i = 0; i < half_n; ++i) {\n        int32x4_t v1 = vld1q_s32(&arr[i * 4]);\n        int32x4_t v2 = vld1q_s32(&arr[(n - i - 1) * 4]);\n\n        uint32x4_t eq_mask = vceqq_s32(v1, v2);\n        int count_eq = vcnt_u32(eq_mask);\n\n        changes += 8 - count_eq;\n    }\n\n    if (n % 4 != 0) {\n        int remaining = n % 4;\n        int start_index = (n - remaining) / 2;\n        for (int i = 0; i < remaining; ++i) {\n            if (arr[start_index + i] != arr[n - start_index - i - 1]) {\n                ++changes;\n            }\n        }\n    }\n\n    return changes;\n}\n```"}
{"task_id": "SimdBench_98_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <string>\n\nstd::vector<std::string> total_match_simd(const std::vector<std::string> & lst1, const std::vector<std::string> & lst2) {\n    int sum1 = 0, sum2 = 0;\n    for (const auto& str : lst1) {\n        sum1 += str.size();\n    }\n    for (const auto& str : lst2) {\n        sum2 += str.size();\n    }\n    if (sum1 <= sum2) {\n        return lst1;\n    } else {\n        return lst2;\n    }\n}\n```"}
{"task_id": "SimdBench_98_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <string>\n\nstd::vector<std::string> total_match_simd(const std::vector<std::string> & lst1, const std::vector<std::string> & lst2) {\n    int sum1 = 0, sum2 = 0;\n    for (const auto& str : lst1) {\n        sum1 += str.size();\n    }\n    for (const auto& str : lst2) {\n        sum2 += str.size();\n    }\n    if (sum1 <= sum2) {\n        return lst1;\n    } else {\n        return lst2;\n    }\n}\n```"}
{"task_id": "SimdBench_98_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <string>\n\nstd::vector<std::string> total_match_simd(const std::vector<std::string> & lst1, const std::vector<std::string> & lst2) {\n    int sum1 = 0;\n    int sum2 = 0;\n\n    for (const auto& str : lst1) {\n        sum1 += str.size();\n    }\n\n    for (const auto& str : lst2) {\n        sum2 += str.size();\n    }\n\n    if (sum1 <= sum2) {\n        return lst1;\n    } else {\n        return lst2;\n    }\n}\n```"}
{"task_id": "SimdBench_98_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <string>\n\nstd::vector<std::string> total_match_simd(const std::vector<std::string> & lst1, const std::vector<std::string> & lst2) {\n    int sum1 = 0, sum2 = 0;\n    for (const auto& str : lst1) {\n        sum1 += str.size();\n    }\n    for (const auto& str : lst2) {\n        sum2 += str.size();\n    }\n    if (sum1 < sum2) {\n        return lst1;\n    } else {\n        return lst2;\n    }\n}\n```"}
{"task_id": "SimdBench_98_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <string>\n\nstd::vector<std::string> total_match_simd(const std::vector<std::string> & lst1, const std::vector<std::string> & lst2) {\n    int sum1 = 0;\n    int sum2 = 0;\n\n    for (const auto& str : lst1) {\n        sum1 += str.size();\n    }\n\n    for (const auto& str : lst2) {\n        sum2 += str.size();\n    }\n\n    if (sum1 <= sum2) {\n        return lst1;\n    } else {\n        return lst2;\n    }\n}\n```"}
{"task_id": "SimdBench_99_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nbool is_simple_power_simd(uint64_t x, uint64_t n) {\n    uint64x2_t v = {x, x};\n    uint64x2_t vn = {n, n};\n    uint64x2_t vmul = vmulq_u64(vn, vn);\n    while (vgetq_lane_u64(vmul, 0) <= x && vgetq_lane_u64(vmul, 1) <= x) {\n        if (vgetq_lane_u64(vmul, 0) == x || vgetq_lane_u64(vmul, 1) == x) {\n            return true;\n        }\n        vmul = vmulq_u64(vmul, vn);\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_99_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nbool is_simple_power_simd(uint64_t x, uint64_t n) {\n    if (n == 1) return x == 1;\n    if (x == 0 || n == 0) return false;\n\n    uint64x2_t v_x = vdupq_n_u64(x);\n    uint64x2_t v_n = vdupq_n_u64(n);\n    uint64x2_t v_one = vdupq_n_u64(1);\n\n    while (vgetq_lane_u64(v_x, 0) > 1 && vgetq_lane_u64(v_x, 1) > 1) {\n        v_x = vmulq_u64(v_x, v_n);\n    }\n\n    return vgetq_lane_u64(v_x, 0) == 1 && vgetq_lane_u64(v_x, 1) == 1;\n}\n```"}
{"task_id": "SimdBench_99_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nbool is_simple_power_simd(uint64_t x, uint64_t n) {\n    uint64x2_t v = {x, x};\n    uint64x2_t vn = {n, n};\n    uint64x2_t vmul = vmulq_u64(vn, vn);\n    while (vgetq_lane_u64(vmul, 0) <= x && vgetq_lane_u64(vmul, 1) <= x) {\n        if (vgetq_lane_u64(vmul, 0) == x || vgetq_lane_u64(vmul, 1) == x) {\n            return true;\n        }\n        vmul = vmulq_u64(vmul, vn);\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_99_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nbool is_simple_power_simd(uint64_t x, uint64_t n) {\n    uint64x2_t v_x = vdupq_n_u64(x);\n    uint64x2_t v_n = vdupq_n_u64(n);\n    uint64x2_t v_one = vdupq_n_u64(1);\n\n    while (vgetq_lane_u64(v_x, 0) > 1 && vgetq_lane_u64(v_x, 1) > 1) {\n        v_x = vmulq_u64(v_x, v_n);\n    }\n\n    return vgetq_lane_u64(v_x, 0) == 1 && vgetq_lane_u64(v_x, 1) == 1;\n}\n```"}
{"task_id": "SimdBench_99_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nbool is_simple_power_simd(uint64_t x, uint64_t n) {\n    uint64x2_t v = {x, x};\n    uint64x2_t vn = {n, n};\n    uint64x2_t vmul = vmulq_u64(vn, vn);\n    while (vgetq_lane_u64(vmul, 0) <= x && vgetq_lane_u64(vmul, 1) <= x) {\n        if (vgetq_lane_u64(vmul, 0) == x || vgetq_lane_u64(vmul, 1) == x) {\n            return true;\n        }\n        vmul = vmulq_u64(vmul, vn);\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_100_Neon", "completion": "```cpp\nint hex_key_simd(const std::string & num) {\n    int count = 0;\n    const uint8_t *data = reinterpret_cast<const uint8_t *>(num.c_str());\n    size_t len = num.size();\n\n    while (len >= 16) {\n        uint8x16_t v = vld1q_u8(data);\n        uint16x8_t v1 = vmovl_u8(vget_low_u8(v));\n        uint16x8_t v2 = vmovl_u8(vget_high_u8(v));\n\n        uint16x8_t mask1 = vceqq_u16(v1, vdupq_n_u16('2'));\n        uint16x8_t mask2 = vceqq_u16(v1, vdupq_n_u16('3'));\n        uint16x8_t mask3 = vceqq_u16(v1, vdupq_n_u16('5'));\n        uint16x8_t mask4 = vceqq_u16(v1, vdupq_n_u16('7'));\n        uint16x8_t mask5 = vceqq_u16(v1, vdupq_n_u16('B'));\n        uint16x8_t mask6 = vceqq_u16(v1, vdupq_n_u16('D'));\n\n        uint16x8_t mask7 = vceqq_u16(v2, vdupq_n_u16('2'));\n        uint16x8_t mask8 = vceqq_u16(v2, vdupq_n_u16('3'));\n        uint16x8_t mask9 = vceqq_u16(v2, vdupq_n_u16('5'));\n        uint16x8_t mask10 = vceqq_u16(v2, vdupq_n_u16('7'));\n        uint16x8_t mask11 = vceqq_u16(v2, vdupq_n_u16('B'));\n        uint16x8_t mask12 = vceqq_u16(v2, vdupq_n_u16('D'));\n\n        uint16x8_t combined_mask1 = vorrq_u16(mask1, mask2);\n        uint16x8_t combined_mask2 = vorrq_u16(mask3, mask4);\n        uint16x8_t combined_mask3 = vorrq_u16(mask5, mask6);\n\n        uint16x8_t combined_mask4 = vorrq_u16(mask7, mask8);\n        uint16x8_t combined_mask5 = vorrq_u16(mask9, mask10);\n        uint16x8_t combined_mask6 = vorrq_u16(mask11, mask12);\n\n        uint16x8_t final_mask1 = vorrq_u16(combined_mask1, combined_mask2);\n        uint16x8_t final_mask2 = vorrq_u16(combined_mask3, combined_mask4);\n        uint16x8_t final_mask3 = vorrq_u16(combined_mask5, combined_mask6);\n\n        uint16x8_t final_mask = vorrq_u16(final_mask1, final_mask2);\n        final_mask = vorrq_u16(final_mask, final_mask3);\n\n        uint16x8_t result = vcntq_u16(final_mask);\n        count += vaddvq_u16(result);\n\n        data += 16;\n        len -= 16;\n    }\n\n    while (len > 0) {\n        if (strchr(\"2357BD\", *data)) {\n            count++;\n        }\n        data++;\n        len--;\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_100_Neon", "completion": "```cpp\nint hex_key_simd(const std::string & num) {\n    int count = 0;\n    size_t len = num.length();\n    const uint8_t * data = reinterpret_cast<const uint8_t *>(num.c_str());\n\n    for (size_t i = 0; i <= len - 16; i += 16) {\n        uint16x8_t v1 = vld1q_u8(data + i);\n        uint16x8_t v2 = vld1q_u8(data + i + 8);\n\n        uint16x8_t mask = vdupq_n_u16(0xFFFF);\n        uint16x8_t eq2 = veorq_u16(vceqq_u8(v1, vdupq_n_u8('2')), mask);\n        uint16x8_t eq3 = veorq_u16(vceqq_u8(v1, vdupq_n_u8('3')), mask);\n        uint16x8_t eq5 = veorq_u16(vceqq_u8(v1, vdupq_n_u8('5')), mask);\n        uint16x8_t eq7 = veorq_u16(vceqq_u8(v1, vdupq_n_u8('7')), mask);\n        uint16x8_t eqB = veorq_u16(vceqq_u8(v1, vdupq_n_u8('B')), mask);\n        uint16x8_t eqD = veorq_u16(vceqq_u8(v1, vdupq_n_u8('D')), mask);\n\n        uint16x8_t eq2_3 = vorrq_u16(eq2, eq3);\n        uint16x8_t eq5_7 = vorrq_u16(eq5, eq7);\n        uint16x8_t eqB_D = vorrq_u16(eqB, eqD);\n\n        uint16x8_t eq_all = vorrq_u16(eq2_3, eq5_7);\n        eq_all = vorrq_u16(eq_all, eqB_D);\n\n        uint16x8_t sum = vpaddlq_u8(vpaddq_u8(eq_all, eq_all));\n        uint16x8_t sum_high = vget_high_u16(sum);\n        uint16_t result = vget_lane_u16(sum, 0) + vget_lane_u16(sum_high, 0);\n\n        count += result;\n    }\n\n    for (size_t i = len - len % 16; i < len; ++i) {\n        if (data[i] == '2' || data[i] == '3' || data[i] == '5' || data[i] == '7' || data[i] == 'B' || data[i] == 'D') {\n            ++count;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_100_Neon", "completion": "```cpp\nint hex_key_simd(const std::string & num) {\n    int count = 0;\n    size_t len = num.length();\n    const uint8_t * data = reinterpret_cast<const uint8_t *>(num.c_str());\n\n    for (size_t i = 0; i < len; i += 16) {\n        uint16x8_t v = vld1q_u8(data + i);\n        uint16x8_t mask = vceqq_u8(v, vdupq_n_u8('2')) |\n                          vceqq_u8(v, vdupq_n_u8('3')) |\n                          vceqq_u8(v, vdupq_n_u8('5')) |\n                          vceqq_u8(v, vdupq_n_u8('7')) |\n                          vceqq_u8(v, vdupq_n_u8('B')) |\n                          vceqq_u8(v, vdupq_n_u8('D'));\n        uint16x8_t sum = vpaddlq_u8(mask);\n        uint16_t result = vget_lane_u16(sum, 0) + vget_lane_u16(sum, 1);\n        count += result;\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_100_Neon", "completion": "```cpp\nint hex_key_simd(const std::string & num) {\n    int count = 0;\n    size_t len = num.length();\n    const uint8_t * data = reinterpret_cast<const uint8_t *>(num.c_str());\n\n    for (size_t i = 0; i < len; i += 16) {\n        uint8x16_t v = vld1q_u8(data + i);\n        uint16x8_t v16 = vmovl_u8(v);\n        uint16x8_t mask = vceqq_u16(v16, vdupq_n_u16('2')) |\n                          vceqq_u16(v16, vdupq_n_u16('3')) |\n                          vceqq_u16(v16, vdupq_n_u16('5')) |\n                          vceqq_u16(v16, vdupq_n_u16('7')) |\n                          vceqq_u16(v16, vdupq_n_u16('B')) |\n                          vceqq_u16(v16, vdupq_n_u16('D'));\n        uint16x8_t sum = vpaddl_u8(mask);\n        uint32x4_t sum4 = vpaddl_u16(sum);\n        uint64x2_t sum2 = vpaddl_u32(sum4);\n        count += vget_lane_u64(sum2, 0);\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_100_Neon", "completion": "```cpp\nint hex_key_simd(const std::string & num) {\n    int count = 0;\n    const uint8_t *data = reinterpret_cast<const uint8_t *>(num.c_str());\n    size_t len = num.length();\n\n    while (len >= 16) {\n        uint8x16_t v = vld1q_u8(data);\n        uint16x8_t v1 = vmovl_u8(vget_low_u8(v));\n        uint16x8_t v2 = vmovl_u8(vget_high_u8(v));\n\n        uint16x8_t mask1 = vceqq_u16(v1, vdupq_n_u16('2'));\n        uint16x8_t mask2 = vceqq_u16(v1, vdupq_n_u16('3'));\n        uint16x8_t mask3 = vceqq_u16(v1, vdupq_n_u16('5'));\n        uint16x8_t mask4 = vceqq_u16(v1, vdupq_n_u16('7'));\n        uint16x8_t mask5 = vceqq_u16(v1, vdupq_n_u16('B'));\n        uint16x8_t mask6 = vceqq_u16(v1, vdupq_n_u16('D'));\n\n        uint16x8_t mask7 = vceqq_u16(v2, vdupq_n_u16('2'));\n        uint16x8_t mask8 = vceqq_u16(v2, vdupq_n_u16('3'));\n        uint16x8_t mask9 = vceqq_u16(v2, vdupq_n_u16('5'));\n        uint16x8_t mask10 = vceqq_u16(v2, vdupq_n_u16('7'));\n        uint16x8_t mask11 = vceqq_u16(v2, vdupq_n_u16('B'));\n        uint16x8_t mask12 = vceqq_u16(v2, vdupq_n_u16('D'));\n\n        uint16x8_t combined_mask1 = vorrq_u16(mask1, mask2);\n        uint16x8_t combined_mask2 = vorrq_u16(mask3, mask4);\n        uint16x8_t combined_mask3 = vorrq_u16(mask5, mask6);\n\n        uint16x8_t combined_mask4 = vorrq_u16(mask7, mask8);\n        uint16x8_t combined_mask5 = vorrq_u16(mask9, mask10);\n        uint16x8_t combined_mask6 = vorrq_u16(mask11, mask12);\n\n        uint16x8_t final_mask1 = vorrq_u16(combined_mask1, combined_mask2);\n        uint16x8_t final_mask2 = vorrq_u16(combined_mask3, combined_mask4);\n        uint16x8_t final_mask3 = vorrq_u16(combined_mask5, combined_mask6);\n\n        uint16x8_t final_mask = vorrq_u16(final_mask1, final_mask2);\n        final_mask = vorrq_u16(final_mask, final_mask3);\n\n        uint16x8_t result = vcntq_u16(final_mask);\n        count += vaddvq_u16(result);\n\n        data += 16;\n        len -= 16;\n    }\n\n    while (len > 0) {\n        if (*data == '2' || *data == '3' || *data == '5' || *data == '7' || *data == 'B' || *data == 'D') {\n            count++;\n        }\n        data++;\n        len--;\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_101_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nbool is_happy_simd(const std::string & s) {\n    if (s.length() < 3) {\n        return false;\n    }\n\n    const uint8_t* data = reinterpret_cast<const uint8_t*>(s.c_str());\n    int len = static_cast<int>(s.length());\n\n    for (int i = 0; i <= len - 4; i += 4) {\n        uint8x16_t v1 = vld1q_u8(data + i);\n        uint8x16_t v2 = vld1q_u8(data + i + 4);\n\n        uint8x16_t eq1 = veorq_u8(v1, v2);\n        uint8x16_t eq2 = veorq_u8(eq1, v1);\n\n        if (vmaxvq_u8(eq2) != 0xFF) {\n            return false;\n        }\n    }\n\n    // Check remaining characters\n    for (int i = len - 4; i < len - 1; ++i) {\n        if (data[i] == data[i + 1]) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_101_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nbool is_happy_simd(const std::string & s) {\n    int len = s.length();\n    if (len < 3) return false;\n\n    const uint8_t* data = reinterpret_cast<const uint8_t*>(s.c_str());\n\n    for (int i = 0; i <= len - 3; i += 4) {\n        uint8x16_t v1 = vld1q_u8(data + i);\n        uint8x16_t v2 = vld1q_u8(data + i + 1);\n        uint8x16_t v3 = vld1q_u8(data + i + 2);\n\n        uint8x16_t eq1 = veorq_u8(v1, v2);\n        uint8x16_t eq2 = veorq_u8(v2, v3);\n        uint8x16_t eq3 = veorq_u8(v1, v3);\n\n        uint8x16_t all_eq = vandq_u8(eq1, eq2);\n        all_eq = vandq_u8(all_eq, eq3);\n\n        if (vmaxvq_u8(all_eq) == 0) {\n            return false;\n        }\n    }\n\n    // Check remaining characters\n    for (int i = len - 3; i < len; ++i) {\n        if (data[i] == data[i + 1] || data[i] == data[i + 2] || data[i + 1] == data[i + 2]) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_101_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nbool is_happy_simd(const std::string & s) {\n    int len = s.length();\n    if (len < 3) return false;\n\n    const uint8_t* data = reinterpret_cast<const uint8_t*>(s.c_str());\n\n    for (int i = 0; i <= len - 3; i += 4) {\n        uint8x16_t v1 = vld1q_u8(data + i);\n        uint8x16_t v2 = vld1q_u8(data + i + 1);\n        uint8x16_t v3 = vld1q_u8(data + i + 2);\n\n        uint8x16_t eq1 = veorq_u8(v1, v2);\n        uint8x16_t eq2 = veorq_u8(v2, v3);\n        uint8x16_t eq3 = veorq_u8(v1, v3);\n\n        uint8x16_t all_eq = vandq_u8(eq1, vandq_u8(eq2, eq3));\n        if (vmaxvq_u8(all_eq) == 0) return false;\n    }\n\n    // Check remaining characters\n    for (int i = len - 3; i < len; ++i) {\n        if (data[i] == data[i + 1] || data[i] == data[i + 2] || data[i + 1] == data[i + 2]) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_101_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nbool is_happy_simd(const std::string & s) {\n    if (s.length() < 3) {\n        return false;\n    }\n\n    const uint8_t* data = reinterpret_cast<const uint8_t*>(s.c_str());\n    int len = static_cast<int>(s.length());\n\n    for (int i = 0; i <= len - 3; i += 4) {\n        uint8x16_t v1 = vld1q_u8(data + i);\n        uint8x16_t v2 = vld1q_u8(data + i + 1);\n        uint8x16_t v3 = vld1q_u8(data + i + 2);\n\n        uint8x16_t eq1 = veorq_u8(v1, v2);\n        uint8x16_t eq2 = veorq_u8(v2, v3);\n        uint8x16_t eq3 = veorq_u8(v1, v3);\n\n        uint8x16_t mask = vandq_u8(eq1, eq2);\n        mask = vandq_u8(mask, eq3);\n\n        if (vmaxvq_u8(mask) == 0) {\n            return false;\n        }\n    }\n\n    // Check remaining characters\n    for (int i = len - 3; i < len; ++i) {\n        if (data[i] == data[i + 1] || data[i] == data[i + 2] || data[i + 1] == data[i + 2]) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_101_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nbool is_happy_simd(const std::string & s) {\n    if (s.length() < 3) {\n        return false;\n    }\n\n    const uint8_t* data = reinterpret_cast<const uint8_t*>(s.c_str());\n    int len = static_cast<int>(s.length());\n\n    for (int i = 0; i <= len - 3; i += 4) {\n        uint8x16_t v1 = vld1q_u8(data + i);\n        uint8x16_t v2 = vld1q_u8(data + i + 1);\n        uint8x16_t v3 = vld1q_u8(data + i + 2);\n\n        uint8x16_t eq1 = veorq_u8(v1, v2);\n        uint8x16_t eq2 = veorq_u8(v2, v3);\n        uint8x16_t eq3 = veorq_u8(v1, v3);\n\n        uint8x16_t all_eq = vandq_u8(eq1, eq2);\n        all_eq = vandq_u8(all_eq, eq3);\n\n        if (vgetq_lane_u8(all_eq, 0) == 0) {\n            return false;\n        }\n    }\n\n    // Check remaining elements\n    for (int i = len - 3; i < len; ++i) {\n        if (data[i] == data[i + 1] || data[i] == data[i + 2] || data[i + 1] == data[i + 2]) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_102_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <cmath>\n#include <string>\n\nbool prime_length_simd(const std::string & str) {\n    int length = str.length();\n    if (length <= 1) return false;\n    if (length <= 3) return true;\n\n    if (length % 2 == 0 || length % 3 == 0) return false;\n\n    for (int i = 5; i * i <= length; i += 6) {\n        if (length % i == 0 || length % (i + 2) == 0) return false;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_102_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <cmath>\n#include <string>\n\nbool prime_length_simd(const std::string & str) {\n    int length = str.length();\n    if (length <= 1) return false;\n    if (length <= 3) return true;\n\n    if (length % 2 == 0 || length % 3 == 0) return false;\n\n    for (int i = 5; i * i <= length; i += 6) {\n        if (length % i == 0 || length % (i + 2) == 0) return false;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_102_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <cmath>\n#include <string>\n\nbool prime_length_simd(const std::string &str) {\n    int length = str.length();\n    if (length <= 1) return false;\n    if (length <= 3) return true;\n\n    if (length % 2 == 0 || length % 3 == 0) return false;\n\n    for (int i = 5; i * i <= length; i += 6) {\n        if (length % i == 0 || length % (i + 2) == 0) return false;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_102_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <cmath>\n#include <string>\n\nbool prime_length_simd(const std::string & str) {\n    int length = str.length();\n    if (length <= 1) return false;\n    if (length <= 3) return true;\n\n    if (length % 2 == 0 || length % 3 == 0) return false;\n\n    for (int i = 5; i * i <= length; i += 6) {\n        if (length % i == 0 || length % (i + 2) == 0) return false;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_102_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <cmath>\n#include <string>\n\nbool prime_length_simd(const std::string & str) {\n    int length = str.length();\n    if (length <= 1) return false;\n    if (length <= 3) return true;\n\n    if (length % 2 == 0 || length % 3 == 0) return false;\n\n    for (int i = 5; i * i <= length; i += 6) {\n        if (length % i == 0 || length % (i + 2) == 0) return false;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_103_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <bitset>\n#include <string>\n\nstd::string solve_simd(uint64_t N) {\n    uint8x16_t vsum = vdupq_n_u8(0);\n    while (N != 0) {\n        uint8x16_t vN = vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl"}
{"task_id": "SimdBench_103_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nstd::string solve_simd(uint64_t N) {\n    uint8x16_t vsum = vdupq_n_u8(0);\n    while (N > 0) {\n        uint8x16_t vN = vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpret_u8_u64(N)))));\n        uint8x16_t vmod = vmulq_u8(vN, vdupq_n_u8(10));\n        uint8x16_t vsub = vbslq_u8(vcltq_u8(vmod, vN), vsubq_u8(vN, vmod), vN);\n        vsum = vaddq_u8(vsum, vsub);\n        N = vgetq_lane_u64(vreinterpretq_u64_u8(vsum), 0);\n    }\n    std::string result;\n    for (int i = 15; i >= 0; --i) {\n        result += (vgetq_lane_u8(vsum, i) + '0');\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_103_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nstd::string solve_simd(uint64_t N) {\n    uint8x16_t sum_vec = vdupq_n_u8(0);\n    while (N > 0) {\n        uint8x16_t num_vec = vreinterpretq_u8_u64(vmovl_u32(vget_low_u32(vreinterpretq_u32_u64(vmovl_u16(vreinterpretq_u16_u8(vreinterpretq_u8_u64(N)))))));\n        sum_vec = vaddq_u8(sum_vec, num_vec);\n        N >>= 8;\n    }\n    std::string result;\n    for (int i = 0; i < 16; ++i) {\n        if (vgetq_lane_u8(sum_vec, i) & 0x80) {\n            result += '1';\n        } else {\n            result += '0';\n        }\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_103_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nstd::string solve_simd(uint64_t N) {\n    uint8x16_t vsum = vdupq_n_u8(0);\n    while (N != 0) {\n        uint8x16_t vN = vreinterpretq_u8_u64(vdupq_n_u64(N));\n        uint8x16_t vmod = vmulq_u8(vN, vdupq_n_u8(10));\n        uint8x16_t vsub = vsubq_u8(vN, vmod);\n        uint8x16_t vadd = vaddq_u8(vsum, vsub);\n        vsum = vadd;\n        N /= 10;\n    }\n    // Convert the sum to binary string\n    std::string result;\n    for (int i = 0; i < 16; ++i) {\n        if (vgetq_lane_u8(vsum, i)) {\n            result += '1';\n        } else {\n            result += '0';\n        }\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_103_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nstd::string solve_simd(uint64_t N) {\n    uint8x16_t vsum = vdupq_n_u8(0);\n    while (N != 0) {\n        uint8x16_t vN = vreinterpretq_u8_u64(vmovl_u32(vmovl_u16(vmovl_u8(vreinterpret_u8_u64(N)))));\n        vsum = vaddq_u8(vsum, vcntq_u8(vandq_u8(vN, vdupq_n_u8(0xFF))));\n        N >>= 8;\n    }\n    uint8_t sum[16];\n    vst1q_u8(sum, vsum);\n    int count = 0;\n    for (int i = 0; i < 16; ++i) {\n        if (sum[i] != 0) {\n            count += sum[i];\n        }\n    }\n    std::string result;\n    for (int i = 0; i < count; ++i) {\n        result += '1';\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_104_Neon", "completion": "```cpp\nint add_simd(std::vector<int> lst) {\n    int sum = 0;\n    int n = lst.size();\n    int i = 1;\n\n    while (i + 8 <= n) {\n        int32x4_t v1 = vld1q_s32(&lst[i]);\n        int32x4_t v2 = vld1q_s32(&lst[i + 4]);\n        uint32x4_t mask1 = vandq_u32(vreinterpretq_u32_s32(v1), vdupq_n_u32(0x55555555));\n        uint32x4_t mask2 = vandq_u32(vreinterpretq_u32_s32(v2), vdupq_n_u32(0x55555555));\n        int32x4_t evens1 = vmovemask_epi8(mask1);\n        int32x4_t evens2 = vmovemask_epi8(mask2);\n        sum += __builtin_popcount(evens1);\n        sum += __builtin_popcount(evens2);\n        i += 8;\n    }\n\n    while (i < n) {\n        if (lst[i] % 2 == 0 && i % 2 != 0) {\n            sum += lst[i];\n        }\n        i++;\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_104_Neon", "completion": "```cpp\nint add_simd(std::vector<int> lst) {\n    int sum = 0;\n    int size = lst.size();\n    int* data = lst.data();\n\n    // Process in chunks of 8 elements\n    for (int i = 1; i < size - 7; i += 8) {\n        int32x4_t v1 = vld1q_s32(data + i);\n        int32x4_t v2 = vld1q_s32(data + i + 4);\n\n        uint32x4_t mask1 = vandq_u32(vreinterpretq_u32_s32(v1), vdupq_n_u32(0xAAAAAAAA));\n        uint32x4_t mask2 = vandq_u32(vreinterpretq_u32_s32(v2), vdupq_n_u32(0xAAAAAAAA));\n\n        int32x4_t evens1 = vmulq_s32vreinterpretq_s32_u32(mask1);\n        int32x4_t evens2 = vmulq_s32vreinterpretq_s32_u32(mask2);\n\n        int32x4_t sum_vec = vaddq_s32(evens1, evens2);\n        int32_t sum_int = vget_lane_s32(sum_vec, 0) + vget_lane_s32(sum_vec, 1) +\n                          vget_lane_s32(sum_vec, 2) + vget_lane_s32(sum_vec, 3);\n\n        sum += sum_int;\n    }\n\n    // Handle remaining elements\n    for (; i < size; ++i) {\n        if (i % 2 != 0 && lst[i] % 2 == 0) {\n            sum += lst[i];\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_104_Neon", "completion": "```cpp\nint add_simd(std::vector<int> lst){\n    int sum = 0;\n    int size = lst.size();\n    int* data = lst.data();\n\n    int32x4_t vsum = vdupq_n_s32(0);\n\n    for(int i = 1; i < size; i += 4){\n        int32x4_t vec = vld1q_s32(data + i);\n        int32x4_t mask = vandq_u32(vreinterpretq_u32_s32(vec), vdupq_n_u32(0x55555555));\n        vsum = vaddq_s32(vsum, vmulq_s32(mask, vec));\n    }\n\n    int32x2_t vsum_low = vpadd_s32(vget_low_s32(vsum), vget_high_s32(vsum));\n    int32x2_t vsum_low_high = vpadd_s32(vsum_low, vsum_low);\n    sum += vget_lane_s32(vsum_low_high, 0);\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_104_Neon", "completion": "```cpp\nint add_simd(std::vector<int> lst) {\n    int sum = 0;\n    int size = lst.size();\n    int* data = lst.data();\n\n    // Process elements in chunks of 4\n    for (int i = 1; i < size - 3; i += 4) {\n        int32x4_t vec = vld1q_s32(data + i);\n        uint32x4_t mask = vandq_u32(vreinterpretq_u32_s32(vec), vmovq_n_u32(0xAAAAAAAA));\n        int32x4_t even_elements = vreinterpretq_s32_u32(mask);\n        int32x4_t result = vpaddq_s32(even_elements, vdupq_lane_s32(vgetq_lane_s32(even_elements, 0), 1));\n        sum += vgetq_lane_s32(result, 0);\n    }\n\n    // Handle remaining elements\n    for (; i < size; ++i) {\n        if (i % 2 != 0 && (data[i] & 1) == 0) {\n            sum += data[i];\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_104_Neon", "completion": "```cpp\nint add_simd(std::vector<int> lst) {\n    int sum = 0;\n    int n = lst.size();\n    int* data = lst.data();\n\n    // Process elements in chunks of 4\n    for (int i = 1; i < n - 3; i += 4) {\n        int32x4_t v = vld1q_s32(data + i);\n        uint32x4_t mask = vandq_u32(vreinterpretq_u32_s32(v), vmovq_n_u32(0x55555555));\n        int32x4_t even_masked = vreinterpretq_s32_u32(mask);\n        int32x4_t result = vaddq_s32(even_masked, vdupq_n_s32(0));\n        sum += vgetq_lane_s32(result, 0);\n    }\n\n    // Handle remaining elements\n    for (; i < n; ++i) {\n        if (i % 2 != 0 && (data[i] & 1) == 0) {\n            sum += data[i];\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_105_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nstd::string encrypt_simd(const std::string & s) {\n    const int shift = 4; // 2 * 2\n    const uint8_t* input = reinterpret_cast<const uint8_t*>(s.c_str());\n    size_t len = s.length();\n    std::string result(len, '\\0');\n    uint8_t* output = reinterpret_cast<uint8_t*>(&result[0]);\n\n    while (len >= 16) {\n        uint8x16_t vec_in = vld1q_u8(input);\n        uint8x16_t vec_out;\n\n        for (int i = 0; i < 16; ++i) {\n            if (vec_in[i] >= 'a' && vec_in[i] <= 'z') {\n                vec_out[i] = ((vec_in[i] - 'a' + shift) % 26) + 'a';\n            } else if (vec_in[i] >= 'A' && vec_in[i] <= 'Z') {\n                vec_out[i] = ((vec_in[i] - 'A' + shift) % 26) + 'A';\n            } else {\n                vec_out[i] = vec_in[i];\n            }\n        }\n\n        vst1q_u8(output, vec_out);\n        input += 16;\n        output += 16;\n        len -= 16;\n    }\n\n    for (size_t i = 0; i < len; ++i) {\n        if (input[i] >= 'a' && input[i] <= 'z') {\n            output[i] = ((input[i] - 'a' + shift) % 26) + 'a';\n        } else if (input[i] >= 'A' && input[i] <= 'Z') {\n            output[i] = ((input[i] - 'A' + shift) % 26) + 'A';\n        } else {\n            output[i] = input[i];\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_105_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nstd::string encrypt_simd(const std::string & s) {\n    const char *input = s.c_str();\n    size_t length = s.length();\n    std::string result(length, '\\0');\n\n    for (size_t i = 0; i <= length - 16; i += 16) {\n        uint8x16_t vec_in = vld1q_u8((const uint8_t *)&input[i]);\n        uint8x16_t vec_out;\n\n        for (int j = 0; j < 16; ++j) {\n            uint8_t ch = vec_in[j];\n            if (ch >= 'a' && ch <= 'z') {\n                ch = ((ch - 'a' + 4) % 26) + 'a';\n            } else if (ch >= 'A' && ch <= 'Z') {\n                ch = ((ch - 'A' + 4) % 26) + 'A';\n            }\n            vec_out[j] = ch;\n        }\n\n        vst1q_u8((uint8_t *)&result[i], vec_out);\n    }\n\n    // Handle remaining characters\n    for (size_t i = length - (length % 16); i < length; ++i) {\n        char ch = input[i];\n        if (ch >= 'a' && ch <= 'z') {\n            ch = ((ch - 'a' + 4) % 26) + 'a';\n        } else if (ch >= 'A' && ch <= 'Z') {\n            ch = ((ch - 'A' + 4) % 26) + 'A';\n        }\n        result[i] = ch;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_105_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nstd::string encrypt_simd(const std::string & s) {\n    const int shift = 2 * 2;\n    const uint8_t* input = reinterpret_cast<const uint8_t*>(s.c_str());\n    size_t len = s.length();\n    std::string result(len, '\\0');\n    uint8_t* output = reinterpret_cast<uint8_t*>(&result[0]);\n\n    while (len >= 16) {\n        uint8x16_t vinput = vld1q_u8(input);\n        uint8x16_t voutput = vaddq_u8(vinput, vdupq_n_u8(shift));\n        vst1q_u8(output, voutput);\n\n        input += 16;\n        output += 16;\n        len -= 16;\n    }\n\n    while (len > 0) {\n        *output++ = *input++ + shift;\n        --len;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_105_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nstd::string encrypt_simd(const std::string & s) {\n    const int shift = 2 * 2;\n    const uint8_t* input = reinterpret_cast<const uint8_t*>(s.c_str());\n    size_t len = s.length();\n    std::string result(len, '\\0');\n    uint8_t* output = reinterpret_cast<uint8_t*>(&result[0]);\n\n    while (len >= 16) {\n        uint8x16_t vec_in = vld1q_u8(input);\n        uint8x16_t vec_out;\n\n        for (int i = 0; i < 16; ++i) {\n            if (vec_in[i] >= 'a' && vec_in[i] <= 'z') {\n                vec_out[i] = ((vec_in[i] - 'a' + shift) % 26) + 'a';\n            } else if (vec_in[i] >= 'A' && vec_in[i] <= 'Z') {\n                vec_out[i] = ((vec_in[i] - 'A' + shift) % 26) + 'A';\n            } else {\n                vec_out[i] = vec_in[i];\n            }\n        }\n\n        vst1q_u8(output, vec_out);\n        input += 16;\n        output += 16;\n        len -= 16;\n    }\n\n    for (size_t i = 0; i < len; ++i) {\n        if (input[i] >= 'a' && input[i] <= 'z') {\n            output[i] = ((input[i] - 'a' + shift) % 26) + 'a';\n        } else if (input[i] >= 'A' && input[i] <= 'Z') {\n            output[i] = ((input[i] - 'A' + shift) % 26) + 'A';\n        } else {\n            output[i] = input[i];\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_105_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nstd::string encrypt_simd(const std::string & s) {\n    const int shift = 4; // 2 * 2\n    const char* input = s.c_str();\n    size_t length = s.length();\n    std::string result(length, '\\0');\n\n    for (size_t i = 0; i <= length - 16; i += 16) {\n        uint8x16_t vec_in = vld1q_u8((const uint8_t*)&input[i]);\n        uint8x16_t vec_out;\n\n        for (int j = 0; j < 16; ++j) {\n            if (vec_in[j] >= 'a' && vec_in[j] <= 'z') {\n                vec_out[j] = ((vec_in[j] - 'a' + shift) % 26) + 'a';\n            } else if (vec_in[j] >= 'A' && vec_in[j] <= 'Z') {\n                vec_out[j] = ((vec_in[j] - 'A' + shift) % 26) + 'A';\n            } else {\n                vec_out[j] = vec_in[j];\n            }\n        }\n\n        vst1q_u8((uint8_t*)&result[i], vec_out);\n    }\n\n    for (size_t i = length - 16; i < length; ++i) {\n        result[i] = input[i] >= 'a' && input[i] <= 'z' ? \n                      ((input[i] - 'a' + shift) % 26) + 'a' : \n                      input[i] >= 'A' && input[i] <= 'Z' ? \n                      ((input[i] - 'A' + shift) % 26) + 'A' : \n                      input[i];\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_106_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nstd::string encode_simd(const std::string & message) {\n    const char *input = message.c_str();\n    size_t length = message.length();\n    std::string result(length, '\\0');\n\n    for (size_t i = 0; i <= length - 16; i += 16) {\n        uint8x16_t vec_in = vld1q_u8((const uint8_t *)&input[i]);\n        uint8x16_t vec_out = vec_in;\n\n        // Swap case\n        vec_out = vmulq_n_u8(vec_out, 32);\n        vec_out = veorq_u8(vec_out, vandq_u8(vec_in, vmovq_n_u8(0x5F)));\n\n        // Replace vowels\n        uint8x16_t mask_a = vceqq_u8(vec_out, vmovq_n_u8('a'));\n        uint8x16_t mask_e = vceqq_u8(vec_out, vmovq_n_u8('e'));\n        uint8x16_t mask_i = vceqq_u8(vec_out, vmovq_n_u8('i'));\n        uint8x16_t mask_o = vceqq_u8(vec_out, vmovq_n_u8('o'));\n        uint8x16_t mask_u = vceqq_u8(vec_out, vmovq_n_u8('u'));\n\n        uint8x16_t replace_a = vaddq_n_u8(vmovq_n_u8('c'), vmovq_n_u8(0));\n        uint8x16_t replace_e = vaddq_n_u8(vmovq_n_u8('g'), vmovq_n_u8(0));\n        uint8x16_t replace_i = vaddq_n_u8(vmovq_n_u8('k'), vmovq_n_u8(0));\n        uint8x16_t replace_o = vaddq_n_u8(vmovq_n_u8('q'), vmovq_n_u8(0));\n        uint8x16_t replace_u = vaddq_n_u8(vmovq_n_u8('w'), vmovq_n_u8(0));\n\n        vec_out = vbslq_u8(mask_a, replace_a, vec_out);\n        vec_out = vbslq_u8(mask_e, replace_e, vec_out);\n        vec_out = vbslq_u8(mask_i, replace_i, vec_out);\n        vec_out = vbslq_u8(mask_o, replace_o, vec_out);\n        vec_out = vbslq_u8(mask_u, replace_u, vec_out);\n\n        vst1q_u8((uint8_t *)&result[i], vec_out);\n    }\n\n    // Handle remaining bytes\n    for (size_t i = length - length % 16; i < length; ++i) {\n        char c = input[i];\n        if (isalpha(c)) {\n            c = toupper(c);\n            if (c == 'A') c = 'C';\n            else if (c == 'E') c = 'G';\n            else if (c == 'I') c = 'K';\n            else if (c == 'O') c = 'Q';\n            else if (c == 'U') c = 'W';\n        } else {\n            c = tolower(c);\n            if (c == 'a') c = 'c';\n            else if (c == 'e') c = 'g';\n            else if (c == 'i') c = 'k';\n            else if (c == 'o') c = 'q';\n            else if (c == 'u') c = 'w';\n        }\n        result[i] = c;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_106_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nstd::string encode_simd(const std::string & message) {\n    const char *input = message.c_str();\n    size_t length = message.length();\n    std::string result(length, '\\0');\n\n    for (size_t i = 0; i <= length - 16; i += 16) {\n        uint8x16_t vec_in = vld1q_u8((const uint8_t *)&input[i]);\n        uint8x16_t vec_out = vec_in;\n\n        // Swap case\n        vec_out = vmulq_n_u8(vec_out, 32);\n\n        // Replace vowels with corresponding characters\n        uint8x16_t mask_vowels = veorq_u8(vandq_u8(vec_out, vdupq_n_u8(0x5F)), vdupq_n_u8(0x41));\n        uint8x16_t mask_a = veorq_u8(mask_vowels, vdupq_n_u8('A'));\n        uint8x16_t mask_e = veorq_u8(mask_vowels, vdupq_n_u8('E'));\n        uint8x16_t mask_i = veorq_u8(mask_vowels, vdupq_n_u8('I'));\n        uint8x16_t mask_o = veorq_u8(mask_vowels, vdupq_n_u8('O'));\n        uint8x16_t mask_u = veorq_u8(mask_vowels, vdupq_n_u8('U'));\n\n        vec_out = vsubq_u8(vec_out, vandq_u8(mask_a, vdupq_n_u8(2)));\n        vec_out = vsubq_u8(vec_out, vandq_u8(mask_e, vdupq_n_u8(4)));\n        vec_out = vsubq_u8(vec_out, vandq_u8(mask_i, vdupq_n_u8(6)));\n        vec_out = vsubq_u8(vec_out, vandq_u8(mask_o, vdupq_n_u8(8)));\n        vec_out = vsubq_u8(vec_out, vandq_u8(mask_u, vdupq_n_u8(10)));\n\n        vst1q_u8((uint8_t *)&result[i], vec_out);\n    }\n\n    // Handle remaining bytes\n    for (size_t i = length - length % 16; i < length; ++i) {\n        char ch = input[i];\n        if (ch >= 'a' && ch <= 'z') {\n            ch = 'Z' - ('z' - ch);\n        } else if (ch >= 'A' && ch <= 'Z') {\n            ch = 'z' - ('Z' - ch);\n        }\n        if (ch == 'a' || ch == 'e' || ch == 'i' || ch == 'o' || ch == 'u' ||\n            ch == 'A' || ch == 'E' || ch == 'I' || ch == 'O' || ch == 'U') {\n            ch = ch + 2;\n            if (ch > 'z') ch -= 26;\n            if (ch > 'Z') ch -= 26;\n        }\n        result[i] = ch;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_106_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nstd::string encode_simd(const std::string & message) {\n    const char *input = message.c_str();\n    size_t length = message.length();\n    std::string result(length, '\\0');\n\n    for (size_t i = 0; i <= length - 16; i += 16) {\n        uint8x16_t vec = vld1q_u8((const uint8_t *)&input[i]);\n\n        // Swap case\n        uint8x16_t swapped_case = vmulq_n_u8(vec, 32);\n\n        // Replace vowels with corresponding characters\n        uint8x16_t mask_vowels = veorq_u8(vandq_u8(swapped_case, vdupq_n_u8(0x5F)), vdupq_n_u8(0x41));\n        uint8x16_t mask_aeio = veorq_u8(mask_vowels, vdupq_n_u8(0x41));\n        uint8x16_t mask_ouae = veorq_u8(mask_vowels, vdupq_n_u8(0x55));\n        uint8x16_t mask_eiou = veorq_u8(mask_vowels, vdupq_n_u8(0x45));\n\n        uint8x16_t replace_aeio = vaddq_u8(mask_aeio, vdupq_n_u8(2));\n        uint8x16_t replace_ouae = vaddq_u8(mask_ouae, vdupq_n_u8(2));\n        uint8x16_t replace_eiou = vaddq_u8(mask_eiou, vdupq_n_u8(2));\n\n        uint8x16_t result_vec = vbslq_u8(mask_aeio, replace_aeio,\n                                       vbslq_u8(mask_ouae, replace_ouae,\n                                                vbslq_u8(mask_eiou, replace_eiou, swapped_case)));\n\n        vst1q_u8((uint8_t *)&result[i], result_vec);\n    }\n\n    // Handle remaining bytes\n    for (size_t i = length - length % 16; i < length; ++i) {\n        char c = input[i];\n        if (c >= 'a' && c <= 'z') {\n            c -= 32;\n        } else if (c >= 'A' && c <= 'Z') {\n            c += 32;\n        }\n        if (c == 'a' || c == 'e' || c == 'i' || c == 'o' || c == 'u') {\n            c += 2;\n        } else if (c == 'A' || c == 'E' || c == 'I' || c == 'O' || c == 'U') {\n            c += 2;\n        }\n        result[i] = c;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_106_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nstd::string encode_simd(const std::string & message) {\n    const char *input = message.c_str();\n    size_t length = message.length();\n    std::string result(length, '\\0');\n\n    for (size_t i = 0; i <= length - 16; i += 16) {\n        uint8x16_t vec_in = vld1q_u8((const uint8_t *)&input[i]);\n        uint8x16_t vec_out = vec_in;\n\n        // Swap case\n        vec_out = vmulq_n_u8(vec_out, 0x20);\n\n        // Replace vowels with the letter that appears 2 places ahead\n        vec_out = vbslq_u8(\n            veorq_u8(vceqq_u8(vec_out, vdupq_n_u8('a')), vceqq_u8(vec_out, vdupq_n_u8('A'))),\n            vaddq_n_u8(vec_out, 4),\n            vec_out);\n        vec_out = vbslq_u8(\n            veorq_u8(vceqq_u8(vec_out, vdupq_n_u8('e')), vceqq_u8(vec_out, vdupq_n_u8('E'))),\n            vaddq_n_u8(vec_out, 4),\n            vec_out);\n        vec_out = vbslq_u8(\n            veorq_u8(vceqq_u8(vec_out, vdupq_n_u8('i')), vceqq_u8(vec_out, vdupq_n_u8('I'))),\n            vaddq_n_u8(vec_out, 4),\n            vec_out);\n        vec_out = vbslq_u8(\n            veorq_u8(vceqq_u8(vec_out, vdupq_n_u8('o')), vceqq_u8(vec_out, vdupq_n_u8('O'))),\n            vaddq_n_u8(vec_out, 4),\n            vec_out);\n        vec_out = vbslq_u8(\n            veorq_u8(vceqq_u8(vec_out, vdupq_n_u8('u')), vceqq_u8(vec_out, vdupq_n_u8('U'))),\n            vaddq_n_u8(vec_out, 4),\n            vec_out);\n\n        vst1q_u8((uint8_t *)&result[i], vec_out);\n    }\n\n    // Handle remaining characters\n    for (size_t i = length - length % 16; i < length; ++i) {\n        char ch = input[i];\n        if (isalpha(ch)) {\n            ch = toupper(ch);\n            if (ch == 'A' || ch == 'E' || ch == 'I' || ch == 'O' || ch == 'U') {\n                ch = ((ch - 'A' + 4) % 26) + 'A';\n            } else {\n                ch = ((ch - 'A' + 2) % 26) + 'A';\n            }\n        } else {\n            ch = tolower(ch);\n            if (ch == 'a' || ch == 'e' || ch == 'i' || ch == 'o' || ch == 'u') {\n                ch = ((ch - 'a' + 4) % 26) + 'a';\n            } else {\n                ch = ((ch - 'a' + 2) % 26) + 'a';\n            }\n        }\n        result[i] = ch;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_106_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nstd::string encode_simd(const std::string & message) {\n    const char *input = message.c_str();\n    size_t length = message.length();\n    std::string result(length, '\\0');\n\n    for (size_t i = 0; i <= length - 16; i += 16) {\n        uint8x16_t vec = vld1q_u8((const uint8_t *)&input[i]);\n\n        // Swap case\n        uint8x16_t swapped_case = vmulq_n_u8(vec, 32);\n\n        // Replace vowels with the letter that appears 2 places ahead\n        uint8x16_t mask_vowels = vorrq_u8(vceqq_u8(swapped_case, vdupq_n_u8('a')),\n                                          vceqq_u8(swapped_case, vdupq_n_u8('e')));\n        uint8x16_t mask_vowels_upper = vorrq_u8(vceqq_u8(swapped_case, vdupq_n_u8('A')),\n                                              vceqq_u8(swapped_case, vdupq_n_u8('E')));\n        uint8x16_t shifted_vowels = vaddq_n_u8(swapped_case, 4);\n        uint8x16_t shifted_vowels_upper = vaddq_n_u8(swapped_case, 4);\n        uint8x16_t result_vec = vbslq_u8(mask_vowels, shifted_vowels, swapped_case);\n        uint8x16_t result_vec_upper = vbslq_u8(mask_vowels_upper, shifted_vowels_upper, result_vec);\n\n        // Store the result\n        vst1q_u8((uint8_t *)&result[i], result_vec_upper);\n    }\n\n    // Handle remaining characters\n    for (size_t i = length - 16; i < length; ++i) {\n        char c = input[i];\n        if (c >= 'a' && c <= 'z') {\n            c = (c - 'a' + 2) % 26 + 'a';\n        } else if (c >= 'A' && c <= 'Z') {\n            c = (c - 'A' + 2) % 26 + 'A';\n        }\n        if (isalpha(c)) {\n            c = islower(c) ? toupper(c) : tolower(c);\n        }\n        result[i] = c;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_107_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <string>\n#include <map>\n\nbool check_dict_case_simd(const std::map<std::string, std::string>& dict) {\n    if (dict.empty()) {\n        return false;\n    }\n\n    bool all_lower = true;\n    bool all_upper = true;\n\n    for (const auto& pair : dict) {\n        const std::string& key = pair.first;\n        int len = key.length();\n\n        if (len % 16 != 0) {\n            // Handle remaining characters that don't fit into a full vector\n            for (int i = 0; i < len; ++i) {\n                char c = key[i];\n                if (c >= 'a' && c <= 'z') {\n                    all_upper = false;\n                } else if (c >= 'A' && c <= 'Z') {\n                    all_lower = false;\n                }\n            }\n        } else {\n            for (int i = 0; i < len; i += 16) {\n                uint8x16_t vec = vld1q_u8(reinterpret_cast<const uint8_t*>(&key[i]));\n                uint8x16_t mask_lower = vclt_u8(vec, vdupq_n_u8('a'));\n                uint8x16_t mask_upper = vcgt_u8(vec, vdupq_n_u8('Z'));\n\n                all_lower &= !vget_lane_u32(vreinterpret_u32_u8(mask_lower), 0);\n                all_upper &= !vget_lane_u32(vreinterpret_u32_u8(mask_upper), 0);\n            }\n        }\n    }\n\n    return all_lower || all_upper;\n}\n```"}
{"task_id": "SimdBench_107_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <map>\n#include <string>\n\nbool check_dict_case_simd(const std::map<std::string, std::string>& dict) {\n    if (dict.empty()) {\n        return false;\n    }\n\n    bool all_lower = true;\n    bool all_upper = true;\n\n    for (const auto& pair : dict) {\n        const std::string& key = pair.first;\n        int len = key.length();\n\n        if (len % 16 != 0) {\n            // Handle remaining characters that don't fit into a full vector\n            for (int i = 0; i < len; ++i) {\n                char c = key[i];\n                if (c >= 'a' && c <= 'z') {\n                    all_upper = false;\n                } else if (c >= 'A' && c <= 'Z') {\n                    all_lower = false;\n                }\n            }\n        } else {\n            for (int i = 0; i < len; i += 16) {\n                uint8x16_t vec = vld1q_u8(reinterpret_cast<const uint8_t*>(key.c_str() + i));\n                uint8x16_t mask_lower = vclt_u8(vec, vdupq_n_u8('a'));\n                uint8x16_t mask_upper = vcgt_u8(vec, vdupq_n_u8('Z'));\n\n                all_lower &= !vget_lane_u8(vandq_u8(mask_lower, vdupq_n_u8(0xFF)), 0);\n                all_upper &= !vget_lane_u8(vandq_u8(mask_upper, vdupq_n_u8(0xFF)), 0);\n            }\n        }\n    }\n\n    return all_lower || all_upper;\n}\n```"}
{"task_id": "SimdBench_107_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <map>\n#include <string>\n\nbool check_dict_case_simd(const std::map<std::string, std::string>& dict) {\n    if (dict.empty()) {\n        return false;\n    }\n\n    bool all_lower = true;\n    bool all_upper = true;\n\n    for (const auto& pair : dict) {\n        const std::string& key = pair.first;\n        int len = key.length();\n\n        if (len % 16 != 0) {\n            // Handle remaining characters that don't fit into a 16-byte chunk\n            for (int i = 0; i < len; ++i) {\n                char c = key[i];\n                if (c >= 'a' && c <= 'z') {\n                    all_upper = false;\n                } else if (c >= 'A' && c <= 'Z') {\n                    all_lower = false;\n                }\n            }\n        } else {\n            for (int i = 0; i < len; i += 16) {\n                uint8x16_t vec = vld1q_u8(reinterpret_cast<const uint8_t*>(&key[i]));\n                uint8x16_t mask_lower = vclt_u8(vec, vdupq_n_u8('a'));\n                uint8x16_t mask_upper = vcgt_u8(vec, vdupq_n_u8('Z'));\n\n                all_lower &= !vget_lane_u32(vreinterpret_u32_u8(mask_lower), 0);\n                all_upper &= !vget_lane_u32(vreinterpret_u32_u8(mask_upper), 0);\n            }\n        }\n    }\n\n    return all_lower || all_upper;\n}\n```"}
{"task_id": "SimdBench_107_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <string>\n#include <map>\n#include <cctype>\n\nbool check_dict_case_simd(const std::map<std::string, std::string>& dict) {\n    if (dict.empty()) {\n        return false;\n    }\n\n    bool hasLower = false;\n    bool hasUpper = false;\n\n    for (const auto& pair : dict) {\n        const std::string& key = pair.first;\n        int len = key.length();\n\n        if (len % 16 != 0) {\n            // Handle remaining characters that don't fit into a full vector\n            for (int i = 0; i < len; ++i) {\n                char c = key[i];\n                if (std::islower(c)) {\n                    hasLower = true;\n                } else if (std::isupper(c)) {\n                    hasUpper = true;\n                }\n                if (hasLower && hasUpper) {\n                    return false;\n                }\n            }\n        } else {\n            int vecLen = len / 16;\n            uint8x16_t vLower = vdupq_n_u8(0);\n            uint8x16_t vUpper = vdupq_n_u8(0);\n\n            for (int i = 0; i < vecLen; ++i) {\n                uint8x16_t vKey = vld1q_u8(reinterpret_cast<const uint8_t*>(key.c_str() + i * 16));\n                uint8x16_t vIsLower = vcgtq_u8(vKey, vdupq_n_u8('Z'));\n                uint8x16_t vIsUpper = vcltq_u8(vKey, vdupq_n_u8('a'));\n\n                vLower = vorrq_u8(vLower, vAndrq_u8(vIsLower, vdupq_n_u8(0xFF)));\n                vUpper = vorrq_u8(vUpper, vAndrq_u8(vIsUpper, vdupq_n_u8(0xFF)));\n            }\n\n            uint8x16_t vResult = vorrq_u8(vLower, vUpper);\n            if (vget_lane_u8(vResult, 0) || vget_lane_u8(vResult, 1) ||\n                vget_lane_u8(vResult, 2) || vget_lane_u8(vResult, 3) ||\n                vget_lane_u8(vResult, 4) || vget_lane_u8(vResult, 5) ||\n                vget_lane_u8(vResult, 6) || vget_lane_u8(vResult, 7) ||\n                vget_lane_u8(vResult, 8) || vget_lane_u8(vResult, 9) ||\n                vget_lane_u8(vResult, 10) || vget_lane_u8(vResult, 11) ||\n                vget_lane_u8(vResult, 12) || vget_lane_u8(vResult, 13) ||\n                vget_lane_u8(vResult, 14) || vget_lane_u8(vResult, 15)) {\n                return false;\n            }\n        }\n    }\n\n    return !(hasLower && hasUpper);\n}\n```"}
{"task_id": "SimdBench_107_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <map>\n#include <string>\n\nbool check_dict_case_simd(const std::map<std::string, std::string>& dict) {\n    if (dict.empty()) {\n        return false;\n    }\n\n    bool all_lower = true;\n    bool all_upper = true;\n\n    for (const auto& pair : dict) {\n        const std::string& key = pair.first;\n        int len = key.length();\n\n        if (len % 16 != 0) {\n            // Handle remaining characters that don't fit into a 16-byte chunk\n            for (int i = 0; i < len % 16; ++i) {\n                char c = key[i];\n                if (c >= 'a' && c <= 'z') {\n                    all_upper = false;\n                } else if (c >= 'A' && c <= 'Z') {\n                    all_lower = false;\n                }\n            }\n        }\n\n        for (int i = 0; i < len - len % 16; i += 16) {\n            uint8x16_t vec = vld1q_u8(reinterpret_cast<const uint8_t*>(&key[i]));\n\n            uint8x16_t mask_lower = vclt_u8(vec, vdupq_n_u8('a'));\n            uint8x16_t mask_upper = vcgt_u8(vec, vdupq_n_u8('Z'));\n\n            all_lower &= valltrueq_u8(mask_lower);\n            all_upper &= valltrueq_u8(vandq_u8(mask_upper, vmovemaskq_u8(mask_upper)));\n        }\n    }\n\n    return all_lower || all_upper;\n}\n```"}
{"task_id": "SimdBench_108_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int> count_up_to_simd(int n) {\n    std::vector<int> primes;\n    if (n <= 2) return primes;\n\n    uint8x16_t mask = vdupq_n_u8(0xFF);\n    uint8x16_t sieve[4];\n    int limit = (n + 15) / 16 * 16;\n\n    for (int i = 2; i < limit; i += 16) {\n        vst1q_u8(sieve[i / 16], mask);\n\n        for (int j = 2; j * j <= i; ++j) {\n            if ((i % j) == 0) {\n                uint8x16_t index = vld1q_u8((uint8_t*)&j);\n                uint8x16_t mul = vmulq_u8(vld1q_u8((uint8_t*)&i), index);\n                uint8x16_t cmp = vcgtq_u8(mul, vld1q_u8((uint8_t*)&limit));\n                uint8x16_t zero = vdupq_n_u8(0);\n                sieve[mul / 16] = vbslq_u8(cmp, zero, sieve[mul / 16]);\n            }\n        }\n\n        for (int k = 0; k < 16; ++k) {\n            if (sieve[k][k] != 0 && i + k < n) {\n                primes.push_back(i + k);\n            }\n        }\n    }\n\n    return primes;\n}\n```"}
{"task_id": "SimdBench_108_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <cmath>\n\nstd::vector<int> count_up_to_simd(int n) {\n    if (n <= 2) return {};\n\n    std::vector<int> primes;\n    primes.reserve(n);\n\n    uint8x16_t mask = vdupq_n_u8(0xFF);\n    uint8x16_t sieve[4];\n    int limit = static_cast<int>(sqrt(n));\n\n    for (int i = 2; i <= limit; ++i) {\n        if (primes.size() >= n) break;\n\n        uint8x16_t index = vld1q_lane_u8(reinterpret_cast<uint8_t*>(&i), vdupq_n_u8(0), 0);\n        uint8x16_t is_prime = vandq_u8(mask, vsrliq_n_u8(vshlq_n_u8(index, vdupq_n_u8(3)), 1));\n        uint8x16_t multiple = vmulq_n_u8(index, vdupq_n_u8(i));\n\n        for (int j = 0; j < 4; ++j) {\n            if (is_prime[j]) {\n                for (int k = 0; k < 16; ++k) {\n                    int value = i * (k + 1);\n                    if (value >= n) break;\n                    primes.push_back(value);\n                }\n            }\n        }\n\n        for (int j = 0; j < 4; ++j) {\n            if (is_prime[j]) {\n                for (int k = 0; k < 16; ++k) {\n                    int value = i * (k + 1);\n                    if (value >= n) break;\n                    sieve[j] = vsubq_u8(sieve[j], vceqq_u8(multiple, vdupq_n_u8(value)));\n                }\n            }\n        }\n\n        mask = vselq_u8(vceqq_u8(sieve[0], vdupq_n_u8(0)), vdupq_n_u8(0xFF), mask);\n        mask = vselq_u8(vceqq_u8(sieve[1], vdupq_n_u8(0)), vdupq_n_u8(0xFF), mask);\n        mask = vselq_u8(vceqq_u8(sieve[2], vdupq_n_u8(0)), vdupq_n_u8(0xFF), mask);\n        mask = vselq_u8(vceqq_u8(sieve[3], vdupq_n_u8(0)), vdupq_n_u8(0xFF), mask);\n    }\n\n    while (primes.size() < n) {\n        int next_prime = primes.back() + 1;\n        bool is_prime = true;\n\n        for (int p : primes) {\n            if (p * p > next_prime) break;\n            if (next_prime % p == 0) {\n                is_prime = false;\n                break;\n            }\n        }\n\n        if (is_prime) {\n            primes.push_back(next_prime);\n        } else {\n            next_prime++;\n        }\n    }\n\n    return primes;\n}\n```"}
{"task_id": "SimdBench_108_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int> count_up_to_simd(int n) {\n    std::vector<int> primes;\n    if (n <= 2) return primes;\n\n    uint8x16_t mask = vdupq_n_u8(0xFF);\n    uint8x16_t sieve[4];\n    int limit = n / 16 + 1;\n\n    for (int i = 0; i < limit; ++i) {\n        sieve[i] = mask;\n    }\n\n    for (int factor = 2; factor * factor < n; ++factor) {\n        if (sieve[factor / 16][factor % 16]) {\n            for (int multiple = factor * factor; multiple < n; multiple += factor) {\n                int index = multiple / 16;\n                int bit = multiple % 16;\n                sieve[index] &= ~(1 << bit);\n            }\n        }\n    }\n\n    for (int i = 2; i < n; ++i) {\n        if (sieve[i / 16][i % 16]) {\n            primes.push_back(i);\n        }\n    }\n\n    return primes;\n}\n```"}
{"task_id": "SimdBench_108_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <cmath>\n\nstd::vector<int> count_up_to_simd(int n) {\n    if (n <= 2) return {};\n\n    std::vector<int> primes;\n    primes.reserve(n);\n\n    uint8x16_t mask = vdupq_n_u8(0xFF);\n    uint8x16_t sieve[4];\n    int limit = static_cast<int>(sqrt(n));\n\n    for (int i = 2; i <= limit; ++i) {\n        if (primes.size() >= n) break;\n\n        uint8x16_t index = vdupq_n_u8(i);\n        uint8x16_t step = vdupq_n_u8(i);\n\n        for (int j = 0; j < 4; ++j) {\n            sieve[j] = vmulq_u8(index, step);\n            index = vaddq_u8(index, step);\n        }\n\n        for (int j = 0; j < 4; ++j) {\n            uint8x16_t temp = vandq_u8(mask, sieve[j]);\n            mask = vbicq_u8(mask, temp);\n        }\n    }\n\n    for (int i = 2; i < n; ++i) {\n        if ((mask[i / 8] & (1 << (i % 8))) != 0) {\n            primes.push_back(i);\n        }\n    }\n\n    return primes;\n}\n```"}
{"task_id": "SimdBench_108_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <cmath>\n\nstd::vector<int> count_up_to_simd(int n) {\n    if (n <= 2) return {};\n\n    std::vector<int> primes;\n    primes.reserve(n);\n\n    uint8x16_t mask = vdupq_n_u8(0xFF);\n    uint8x16_t sieve[4];\n    int limit = static_cast<int>(sqrt(n));\n\n    for (int i = 2; i <= limit; ++i) {\n        uint8x16_t index = vld1q_lane_u8(reinterpret_cast<uint8_t*>(&i), vdupq_n_u8(0), 0);\n        uint8x16_t is_prime = vandq_u8(mask, vceqq_u8(index, vdupq_n_u8(i)));\n\n        for (int j = 0; j < 4; ++j) {\n            uint8x16_t chunk = vsliceq_u8(sieve[j], is_prime);\n            uint8x16_t new_chunk = vmulq_u8(chunk, vdupq_n_u8(i));\n            sieve[j] = vaddq_u8(sieve[j], new_chunk);\n        }\n    }\n\n    for (int i = 2; i < n; ++i) {\n        if (vgetq_lane_u8(vandq_u8(mask, vsliceq_u8(sieve[i / 16], vdupq_n_u8(i))), i % 16) == 0) {\n            primes.push_back(i);\n        }\n    }\n\n    return primes;\n}\n```"}
{"task_id": "SimdBench_109_Neon", "completion": "```cpp\nint count_upper_simd(const std::string & s) {\n    int count = 0;\n    const char* str = s.c_str();\n    size_t len = s.length();\n\n    // Process 16 characters at a time\n    for (size_t i = 0; i <= len - 16; i += 16) {\n        uint8x16_t vec = vld1q_u8((const uint8_t*)&str[i]);\n        uint8x16_t mask = vdupq_n_u8('A');\n        uint8x16_t upper_mask = vmovq_n_u8('Z');\n        uint8x16_t vowel_mask = vdupq_n_u8('AEIOU');\n\n        uint8x16_t is_upper = vandq_u8(vgeq_u8(vec, mask), vleq_u8(vec, upper_mask));\n        uint8x16_t is_vowel = vandq_u8(is_upper, veorq_u8(vceqq_u8(vec, vowel_mask), vceqq_u8(vec, 'Y')));\n\n        uint32x4_t sum = vpaddw_u32(vpaddw_u32(vmovl_u16(vget_low_u16(vreinterpretq_u16_u8(is_vowel))),\n                                              vreinterpretq_u16_u8(vextq_u8(is_vowel, is_vowel, 8))),\n                                 vpaddw_u32(vmovl_u16(vget_high_u16(vreinterpretq_u16_u8(is_vowel))),\n                                            vreinterpretq_u16_u8(vextq_u8(is_vowel, is_vowel, 8))));\n        count += vget_lane_u32(sum, 0) + vget_lane_u32(sum, 1);\n    }\n\n    // Process remaining characters\n    for (size_t i = len - len % 16; i < len; ++i) {\n        if (isupper(str[i]) && strchr(\"AEIOU\", str[i])) {\n            ++count;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_109_Neon", "completion": "```cpp\nint count_upper_simd(const std::string & s) {\n    int count = 0;\n    const char* str = s.c_str();\n    size_t len = s.length();\n\n    // Process 16 characters at a time\n    for (size_t i = 0; i <= len - 16; i += 16) {\n        uint8x16_t vec = vld1q_u8((const uint8_t*)&str[i]);\n        uint8x16_t mask = vdupq_n_u8('A');\n        uint8x16_t upper_mask = vmovq_n_u8('Z');\n        uint8x16_t vowel_mask = vdupq_n_u8('A' | 'E' | 'I' | 'O' | 'U');\n\n        uint8x16_t is_upper = vbicq_u8(vec, mask);\n        uint8x16_t is_vowel = vandq_u8(is_upper, vowel_mask);\n        uint8x16_t is_even_index = vceqq_s32(vreinterpretq_s32_u8(vaddq_u8(vshrq_n_u8(vreinterpretq_u8_s32(vmovq_n_s32(i)), 1), vdupq_n_u8(1))), vdupq_n_s32(0));\n\n        uint8x16_t result = vandq_u8(is_vowel, is_even_index);\n\n        uint16x8_t sum = vpaddlq_u8(result);\n        uint32x4_t sum_high = vpaddlq_u16(sum);\n        uint64x2_t sum_higher = vpaddlq_u32(sum_high);\n        count += vget_lane_u64(sum_higher, 0);\n    }\n\n    // Process remaining characters\n    for (size_t i = len - len % 16; i < len; ++i) {\n        if ((i % 2 == 0) && (str[i] >= 'A' && str[i] <= 'Z') && (str[i] == 'A' || str[i] == 'E' || str[i] == 'I' || str[i] == 'O' || str[i] == 'U')) {\n            count++;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_109_Neon", "completion": "```cpp\nint count_upper_simd(const std::string & s) {\n    int count = 0;\n    const char* str = s.c_str();\n    size_t len = s.length();\n\n    // Process 16 characters at a time\n    for (size_t i = 0; i <= len - 16; i += 16) {\n        uint8x16_t v = vld1q_u8((const uint8_t*)&str[i]);\n        uint8x16_t mask = vmovq_n_u8(0x55); // Mask for even indices\n        uint8x16_t even_chars = vandq_u8(v, mask);\n        uint8x16_t upper_mask = vmovq_n_u8(0x41); // 'A'\n        uint8x16_t lower_mask = vmovq_n_u8(0x5A); // 'Z'\n        uint8x16_t is_upper = and_vnot_u8(and_vge_u8(even_chars, upper_mask), vleq_u8(even_chars, lower_mask));\n        uint32x4_t sum = vpaddw_u32(vpaddw_u32(vreinterpretw32_u8(is_upper), vdupw_n_u32(0)), vdupw_n_u32(0));\n        count += vget_lane_u32(sum, 0);\n    }\n\n    // Process remaining characters\n    for (size_t i = len - len % 16; i < len; ++i) {\n        if ((i % 2 == 0) && (str[i] >= 'A' && str[i] <= 'Z')) {\n            count++;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_109_Neon", "completion": "```cpp\nint count_upper_simd(const std::string & s) {\n    int count = 0;\n    const char* str = s.c_str();\n    size_t len = s.length();\n\n    // Process 16 characters at a time\n    for (size_t i = 0; i <= len - 16; i += 16) {\n        uint8x16_t vec = vld1q_u8((const uint8_t*)&str[i]);\n        uint8x16_t mask = vdupq_n_u8('A');\n        uint8x16_t upper_mask = vdupq_n_u8('Z');\n        uint8x16_t vowels_mask = vmovq_n_u8(0);\n        vowels_mask[0] = 'A';\n        vowels_mask[4] = 'E';\n        vowels_mask[8] = 'I';\n        vowels_mask[12] = 'O';\n        vowels_mask[14] = 'U';\n\n        uint8x16_t is_upper = vbicq_u8(vec, mask);\n        uint8x16_t is_vowel = vandq_u8(is_upper, upper_mask);\n        uint8x16_t is_even_index = vceqq_u8(vreinterpretq_u8_u32(vshrq_n_u32(vreinterpretq_u32_u8(vec), 5)), vdupq_n_u32(0));\n\n        uint8x16_t result = vandq_u8(is_vowel, is_even_index);\n        uint16x8_t sum = vpaddlq_u8(result);\n        uint32x4_t sum_high = vpaddlq_u16(sum);\n        uint32x2_t sum_final = vpaddl_u32(sum_high);\n        count += vget_lane_u32(sum_final, 0);\n    }\n\n    // Process remaining characters\n    for (size_t i = len - len % 16; i < len; ++i) {\n        if ((i % 2 == 0) && (str[i] >= 'A' && str[i] <= 'Z') && (str[i] == 'A' || str[i] == 'E' || str[i] == 'I' || str[i] == 'O' || str[i] == 'U')) {\n            count++;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_109_Neon", "completion": "```cpp\nint count_upper_simd(const std::string & s) {\n    int count = 0;\n    const char* str = s.c_str();\n    size_t len = s.length();\n\n    // Process 16 characters at a time\n    for (size_t i = 0; i <= len - 16; i += 16) {\n        uint8x16_t v = vld1q_u8((const uint8_t*)&str[i]);\n        uint8x16_t mask = vmovq_n_u8(0x55); // Mask for even indices\n        uint8x16_t even_chars = vandq_u8(v, mask);\n        uint8x16_t upper_mask = vmovq_n_u8(0x41); // 'A'\n        uint8x16_t lower_mask = vmovq_n_u8(0x5A); // 'Z'\n        uint8x16_t is_upper = andrq_u8(andrq_u8(even_chars, subq_u8(lower_mask, upper_mask)), subq_u8(upper_mask, even_chars));\n        uint32x4_t sum = vpaddw_u32(vpaddw_u32(vreinterpretq_u32_u8(is_upper), vdupq_n_u32(0)), vdupq_n_u32(0));\n        count += vgetq_lane_u32(sum, 0);\n    }\n\n    // Process remaining characters\n    for (size_t i = len - len % 16; i < len; ++i) {\n        if ((i % 2 == 0) && (str[i] >= 'A' && str[i] <= 'Z')) {\n            count++;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_110_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int> make_a_pile_simd(int n) {\n    std::vector<int> result(n);\n    int increment = n % 2 == 0 ? 2 : 1;\n    int* ptr = &result[0];\n    \n    for (int i = 0; i < n; i += 4) {\n        int32x4_t values = vdupq_n_s32(i * increment + n);\n        vst1q_s32(ptr + i, values);\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_110_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int> make_a_pile_simd(int n) {\n    std::vector<int> result(n);\n    int64x2_t count = vdupq_n_s64(static_cast<int64_t>(n));\n    int64x2_t step = vdupq_n_s64(n % 2 == 0 ? 2 : 1);\n\n    for (int i = 0; i < n / 2; ++i) {\n        vst1q_u64(reinterpret_cast<uint64_t*>(&result[i * 2]), count);\n        count = vaddq_s64(count, step);\n    }\n\n    if (n % 2 != 0) {\n        result[n - 1] = static_cast<int>(count[0]);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_110_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int> make_a_pile_simd(int n) {\n    std::vector<int> result(n);\n    int increment = n % 2 == 0 ? 2 : 1;\n    int* ptr = &result[0];\n    \n    int32x4_t inc_vec = vdupq_n_s32(increment);\n    int32x4_t count_vec = vdupq_n_s32(n);\n    \n    for (int i = 0; i < n / 4; ++i) {\n        vst1q_s32(ptr, count_vec);\n        ptr += 4;\n        count_vec = vaddq_s32(count_vec, inc_vec);\n    }\n    \n    for (int i = n - n % 4; i < n; ++i) {\n        *ptr++ = n + i * increment;\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_110_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int> make_a_pile_simd(int n) {\n    std::vector<int> result(n);\n    int64x2_t count = vdupq_n_s64(static_cast<int64_t>(n));\n    int64x2_t step = vdupq_n_s64((n % 2 == 0) ? 2 : 1);\n\n    for (int i = 0; i < n; i += 2) {\n        int64x2_t current_count = vaddq_s64(count, vmulq_n_s64(step, vdupq_n_s64(i / 2)));\n        vst1q_s64(&result[i], current_count);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_110_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int> make_a_pile_simd(int n) {\n    std::vector<int> result(n);\n    int increment = n % 2 == 0 ? 2 : 1;\n    int* ptr = &result[0];\n    \n    int32x4_t inc_vec = vdupq_n_s32(increment);\n    int32x4_t count_vec = vdupq_n_s32(n);\n    \n    for (int i = 0; i < n / 4; ++i) {\n        vst1q_s32(ptr, count_vec);\n        count_vec = vaddq_s32(count_vec, inc_vec);\n        ptr += 4;\n    }\n    \n    for (int i = n / 4 * 4; i < n; ++i) {\n        *ptr++ = n + i * increment;\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_111_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <cmath>\n#include <bitset>\n#include <string>\n\nstd::string rounded_avg_simd(int64_t n, int64_t m) {\n    if (n > m) {\n        return \"-1\";\n    }\n\n    int64_t sum = 0;\n    int64_t count = m - n + 1;\n\n    // Use Neon intrinsics for parallel computation\n    int64x2_t vsum = vdupq_n_s64(0);\n    int64x2_t vcount = vdupq_n_s64(count);\n\n    for (; n <= m; n += 2) {\n        int64x2_t va = vld1q_lane_s64(&n, vdupq_n_s64(n), 0);\n        int64x2_t vb = vld1q_lane_s64(&n, vdupq_n_s64(n), 1);\n        vsum = vaddq_s64(vsum, va);\n        vsum = vaddq_s64(vsum, vb);\n    }\n\n    sum = vgetq_lane_s64(vsum, 0) + vgetq_lane_s64(vsum, 1);\n\n    int64_t avg = std::round(static_cast<double>(sum) / count);\n    std::bitset<64> bits(avg);\n    return bits.to_string().substr(64 - std::ceil(std::log2(avg + 1)));\n}\n```"}
{"task_id": "SimdBench_111_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <cmath>\n#include <bitset>\n#include <string>\n\nstd::string rounded_avg_simd(int64_t n, int64_t m) {\n    if (n > m) {\n        return \"-1\";\n    }\n\n    int64_t sum = 0;\n    int64_t count = m - n + 1;\n\n    // Use Neon intrinsics for parallel computation\n    int64x2_t vsum = vdupq_n_s64(0);\n    int64x2_t vcount = vdupq_n_s64(count);\n\n    for (; n <= m; n += 2) {\n        int64x2_t va = vld1q_lane_s64(&n, vdupq_n_s64(n), 0);\n        int64x2_t vb = vld1q_lane_s64(&n, vdupq_n_s64(n), 1);\n        vsum = vaddq_s64(vsum, va);\n        vsum = vaddq_s64(vsum, vb);\n    }\n\n    sum = vgetq_lane_s64(vsum, 0) + vgetq_lane_s64(vsum, 1);\n\n    // Calculate average and round down\n    int64_t avg = std::floor(static_cast<double>(sum) / count);\n\n    // Convert to binary\n    std::bitset<64> binary(avg);\n    return binary.to_string();\n}\n```"}
{"task_id": "SimdBench_111_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <cmath>\n#include <bitset>\n#include <string>\n\nstd::string rounded_avg_simd(int64_t n, int64_t m) {\n    if (n > m) {\n        return \"-1\";\n    }\n\n    int64_t sum = 0;\n    int64_t count = m - n + 1;\n\n    // Use Neon intrinsics for parallel computation\n    int64x2_t vsum = vdupq_n_s64(0);\n    int64x2_t vcount = vdupq_n_s64(count);\n\n    for (; n <= m; n += 2) {\n        int64x2_t va = vld1q_lane_s64(&n, vdupq_n_s64(n), 0);\n        int64x2_t vb = vld1q_lane_s64(&n, vdupq_n_s64(n), 1);\n        vsum = vaddq_s64(vsum, va);\n        vsum = vaddq_s64(vsum, vb);\n    }\n\n    // Sum remaining element if count is odd\n    if (count % 2 != 0) {\n        int64_t last_element = n - 1;\n        int64x2_t vlast = vld1q_lane_s64(&last_element, vdupq_n_s64(last_element), 0);\n        vsum = vaddq_s64(vsum, vlast);\n    }\n\n    sum = vgetq_lane_s64(vsum, 0) + vgetq_lane_s64(vsum, 1);\n\n    // Calculate average and round down\n    int64_t avg = std::floor(static_cast<double>(sum) / count);\n\n    // Convert to binary\n    std::bitset<64> binary(avg);\n    return binary.to_string();\n}\n```"}
{"task_id": "SimdBench_111_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <cmath>\n#include <bitset>\n#include <string>\n\nstd::string rounded_avg_simd(int64_t n, int64_t m) {\n    if (n > m) {\n        return \"-1\";\n    }\n\n    int64x2_t sum = vdupq_n_s64(0);\n    int64x2_t count = vdupq_n_s64(m - n + 1);\n\n    for (int64_t i = n; i <= m; i += 2) {\n        int64x2_t values = vld1q_lane_s64(&i, vdupq_n_s64(i), 0);\n        sum = vaddq_s64(sum, values);\n    }\n\n    if ((m - n + 1) % 2 != 0) {\n        int64_t last_value = n + (m - n) / 2;\n        sum = vaddq_s64(sum, vdupq_n_s64(last_value));\n    }\n\n    int64_t avg = vmovq_n_s64(vget_low_s64(sum)) / vmovq_n_s64(vget_low_s64(count));\n\n    std::bitset<64> bits(avg);\n    return bits.to_string();\n}\n```"}
{"task_id": "SimdBench_111_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <cmath>\n#include <bitset>\n#include <string>\n\nstd::string rounded_avg_simd(int64_t n, int64_t m) {\n    if (n > m) {\n        return \"-1\";\n    }\n\n    int64_t sum = 0;\n    int64_t count = m - n + 1;\n\n    // Use Neon intrinsics for parallel computation\n    int64x2_t vsum = vdupq_n_s64(0);\n    int64x2_t vcount = vdupq_n_s64(count);\n\n    for (; n <= m; n += 2) {\n        int64x2_t va = vld1q_lane_s64(&n, vdupq_n_s64(n), 0);\n        int64x2_t vb = vld1q_lane_s64(&n, vdupq_n_s64(n), 1);\n        vsum = vaddq_s64(vsum, va);\n        vsum = vaddq_s64(vsum, vb);\n    }\n\n    sum = vgetq_lane_s64(vsum, 0) + vgetq_lane_s64(vsum, 1);\n\n    int64_t avg = std::round(static_cast<double>(sum) / count);\n    std::bitset<64> bits(avg);\n    return bits.to_string().substr(64 - std::ceil(std::log2(avg + 1)));\n}\n```"}
{"task_id": "SimdBench_112_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int> func_simd(int n) {\n    std::vector<int> result(n);\n    int32x4_t v_sum = vdupq_n_s32(0);\n    int32x4_t v_fact = vdupq_n_s32(1);\n    int32x4_t v_one = vdupq_n_s32(1);\n    int32x4_t v_two = vdupq_n_s32(2);\n    int32x4_t v_ten_thousand = vdupq_n_s32(10000);\n\n    for (int i = 1; i <= n; ++i) {\n        if (i % 2 == 0) {\n            v_fact = vmulq_s32(v_fact, vdupq_n_s32(i));\n            v_fact = veorq_s32(v_fact, vdupq_n_s32(10000));\n        } else {\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i));\n        }\n\n        if (i % 4 == 0) {\n            result[i - 1] = vgetq_lane_s32(v_sum, 0);\n            result[i - 2] = vgetq_lane_s32(v_sum, 1);\n            result[i - 3] = vgetq_lane_s32(v_sum, 2);\n            result[i - 4] = vgetq_lane_s32(v_sum, 3);\n            v_sum = vdupq_n_s32(0);\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_112_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int> func_simd(int n) {\n    std::vector<int> result(n);\n    int32x4_t v_sum = vdupq_n_s32(0);\n    int32x4_t v_fact = vdupq_n_s32(1);\n    int32x4_t v_one = vdupq_n_s32(1);\n    int32x4_t v_two = vdupq_n_s32(2);\n    int32x4_t v_ten_thousand = vdupq_n_s32(10000);\n\n    for (int i = 1; i <= n; ++i) {\n        if (i % 2 == 0) {\n            // Factorial calculation\n            v_fact = vmulq_s32(v_fact, vdupq_n_s32(i));\n            v_fact = veorq_s32(v_fact, vdupq_n_s32(10000)); // Modulo 10000\n        } else {\n            // Sum calculation\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i));\n        }\n\n        if (i % 4 == 0) {\n            // Store results every 4 iterations\n            for (int j = 0; j < 4; ++j) {\n                result[i - 4 + j] = (i - 4 + j) % 2 == 0 ? vgetq_lane_s32(v_fact, j) : vgetq_lane_s32(v_sum, j);\n            }\n        }\n    }\n\n    // Handle remaining elements\n    for (int i = (n / 4) * 4; i < n; ++i) {\n        if (i % 2 == 0) {\n            result[i] = i % 10000;\n        } else {\n            result[i] = (i * (i + 1)) / 2;\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_112_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int> func_simd(int n) {\n    std::vector<int> result(n);\n    int32x4_t v_sum = vdupq_n_s32(0);\n    int32x4_t v_fact = vdupq_n_s32(1);\n    int32x4_t v_one = vdupq_n_s32(1);\n    int32x4_t v_two = vdupq_n_s32(2);\n    int32x4_t v_ten_thousand = vdupq_n_s32(10000);\n\n    for (int i = 1; i <= n; ++i) {\n        if (i % 2 == 0) {\n            v_fact = vmulq_s32(v_fact, vdupq_n_s32(i));\n            v_fact = veorq_s32(v_fact, vdupq_n_s32(10000));\n        } else {\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i));\n        }\n\n        if (i % 4 == 0) {\n            result[i-1] = vgetq_lane_s32(v_fact, 0);\n            result[i-2] = vgetq_lane_s32(v_fact, 1);\n            result[i-3] = vgetq_lane_s32(v_fact, 2);\n            result[i-4] = vgetq_lane_s32(v_fact, 3);\n            v_fact = vdupq_n_s32(1);\n        }\n    }\n\n    // Handle remaining elements\n    for (int i = (n / 4) * 4; i < n; ++i) {\n        if (i % 2 == 0) {\n            result[i] = (result[i-1] * (i + 1)) % 10000;\n        } else {\n            result[i] = result[i-1] + i;\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_112_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int> func_simd(int n) {\n    std::vector<int> result(n);\n    int32x4_t v_sum = vdupq_n_s32(0);\n    int32x4_t v_fact = vdupq_n_s32(1);\n    int32x4_t v_one = vdupq_n_s32(1);\n    int32x4_t v_two = vdupq_n_s32(2);\n    int32x4_t v_four = vdupq_n_s32(4);\n\n    for (int i = 1; i <= n; ++i) {\n        if (i % 2 == 0) {\n            v_fact = vmulq_s32(v_fact, vdupq_n_s32(i));\n            v_fact = veorq_s32(v_fact, vdupq_n_s32(10000));\n        } else {\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i));\n        }\n\n        if (i >= 4) {\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 1));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 2));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 3));\n        }\n\n        if (i >= 8) {\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 4));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 5));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 6));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 7));\n        }\n\n        if (i >= 12) {\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 8));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 9));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 10));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 11));\n        }\n\n        if (i >= 16) {\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 12));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 13));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 14));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 15));\n        }\n\n        if (i >= 20) {\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 16));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 17));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 18));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 19));\n        }\n\n        if (i >= 24) {\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 20));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 21));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 22));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 23));\n        }\n\n        if (i >= 28) {\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 24));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 25));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 26));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 27));\n        }\n\n        if (i >= 32) {\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 28));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 29));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 30));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 31));\n        }\n\n        if (i >= 36) {\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 32));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 33));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 34));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 35));\n        }\n\n        if (i >= 40) {\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 36));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 37));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 38));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 39));\n        }\n\n        if (i >= 44) {\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 40));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 41));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 42));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 43));\n        }\n\n        if (i >= 48) {\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 44));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 45));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 46));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 47));\n        }\n\n        if (i >= 52) {\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 48));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 49));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 50));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 51));\n        }\n\n        if (i >= 56) {\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 52));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 53));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 54));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 55));\n        }\n\n        if (i >= 60) {\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 56));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 57));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 58));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 59));\n        }\n\n        if (i >= 64) {\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 60));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 61));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 62));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 63));\n        }\n\n        if (i >= 68) {\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 64));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 65));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 66));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 67));\n        }\n\n        if (i >= 72) {\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 68));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 69));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 70));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 71));\n        }\n\n        if (i >= 76) {\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 72));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 73));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 74));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 75));\n        }\n\n        if (i >= 80) {\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 76));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 77));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 78));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 79));\n        }\n\n        if (i >= 84) {\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 80));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 81));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 82));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 83));\n        }\n\n        if (i >= 88) {\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 84));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 85));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 86));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 87));\n        }\n\n        if (i >= 92) {\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 88));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 89));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 90));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 91));\n        }\n\n        if (i >= 96) {\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 92));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 93));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 94));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 95));\n        }\n\n        if (i >= 100) {\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 96));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 97));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 98));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 99));\n        }\n\n        if (i >= 104) {\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 100));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 101));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 102));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 103));\n        }\n\n        if (i >= 108) {\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 104));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 105));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 106));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 107));\n        }\n\n        if (i >= 112) {\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 108));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 109));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 110));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 111));\n        }\n\n        if (i >= 116) {\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 112));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 113));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 114));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 115));\n        }\n\n        if (i >= 120) {\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 116));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 117));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 118));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 119));\n        }\n\n        if (i >= 124) {\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 120));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 121));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 122));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 123));\n        }\n\n        if (i >= 128) {\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 124));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 125));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 126));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 127));\n        }\n\n        if (i >= 132) {\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 128));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 129));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 130));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 131));\n        }\n\n        if (i >= 136) {\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 132));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 133));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 134));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 135));\n        }\n\n        if (i >= 140) {\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 136));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 137));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 138));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 139));\n        }\n\n        if (i >= 144) {\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 140));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 141));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 142));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 143));\n        }\n\n        if (i >= 148) {\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 144));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 145));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 146));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 147));\n        }\n\n        if (i >= 152) {\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 148));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 149));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 150));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 151));\n        }\n\n        if (i >= 156) {\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 152));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 153));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 154));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 155));\n        }\n\n        if (i >= 160) {\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 156));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 157));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 158));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 159));\n        }\n\n        if (i >= 164) {\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 160));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 161));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 162));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 163));\n        }\n\n        if (i >= 168) {\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 164));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 165));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 166));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 167));\n        }\n\n        if (i >= 172) {\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 168));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 169));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 170));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 171));\n        }\n\n        if (i >= 176) {\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 172));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 173));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 174));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 175));\n        }\n\n        if (i >= 180) {\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 176));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 177));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 178));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 179));\n        }\n\n        if (i >= 184) {\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 180));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 181));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 182));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 183));\n        }\n\n        if (i >= 188) {\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 184));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 185));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 186));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 187));\n        }\n\n        if (i >= 192) {\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 188));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 189));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 190));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 191));\n        }\n\n        if (i >= 196) {\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 192));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 193));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 194));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 195));\n        }\n\n        if (i >= 200) {\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 196));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 197));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 198));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 199));\n        }\n\n        if (i >= 204) {\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 200));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 201));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 202));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 203));\n        }\n\n        if (i >= 208) {\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 204));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 205));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 206));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 207));\n        }\n\n        if (i >= 212) {\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 208));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 209));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 210));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 211));\n        }\n\n        if (i >= 216) {\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 212));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 213));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 214));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 215));\n        }\n\n        if (i >= 220) {\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 216));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 217));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 218));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 219));\n        }\n\n        if (i >= 224) {\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 220));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 221));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 222));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 223));\n        }\n\n        if (i >= 228) {\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 224));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 225));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 226));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 227));\n        }\n\n        if (i >= 232) {\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 228));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 229));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 230));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 231));\n        }\n\n        if (i >= 236) {\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 232));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 233));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 234));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 235));\n        }\n\n        if (i >= 240) {\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 236));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 237));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 238));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 239));\n        }\n\n        if (i >= 244) {\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 240));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 241));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 242));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 243));\n        }\n\n        if (i >= 248) {\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 244));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 245));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 246));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 247));\n        }\n\n        if (i >= 252) {\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 248));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 249));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 250));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 251));\n        }\n\n        if (i >= 256) {\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 252));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 253));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 254));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 255));\n        }\n\n        if (i >= 260) {\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 256));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 257));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 258));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 259));\n        }\n\n        if (i >= 264) {\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 260));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 261));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 262));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 263));\n        }\n\n        if (i >= 268) {\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 264));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 265));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 266));\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i - 267));\n        }\n\n        if (i >="}
{"task_id": "SimdBench_112_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int> func_simd(int n) {\n    std::vector<int> result(n);\n    int32x4_t v_sum = vdupq_n_s32(0);\n    int32x4_t v_fact = vdupq_n_s32(1);\n    int32x4_t v_one = vdupq_n_s32(1);\n    int32x4_t v_two = vdupq_n_s32(2);\n    int32x4_t v_four = vdupq_n_s32(4);\n\n    for (int i = 1; i <= n; ++i) {\n        if (i % 2 == 0) {\n            // Calculate factorial modulo 10000\n            v_fact = vmulq_s32(v_fact, vdupq_n_s32(i));\n            v_fact = veorq_s32(v_fact, vdupq_n_s32(10000));\n        } else {\n            // Calculate sum from 1 to i\n            v_sum = vaddq_s32(v_sum, vdupq_n_s32(i));\n        }\n\n        // Store results in the vector\n        if (i <= 4) {\n            result[i - 1] = (i % 2 == 0) ? vgetq_lane_s32(v_fact, 0) : vgetq_lane_s32(v_sum, 0);\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_113_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int> even_odd_palindrome_simd(int n) {\n    int even_count = 0;\n    int odd_count = 0;\n\n    for (int i = 1; i <= n; ++i) {\n        if (is_palindrome(i)) {\n            if (i % 2 == 0) {\n                even_count++;\n            } else {\n                odd_count++;\n            }\n        }\n    }\n\n    std::vector<int> result = {even_count, odd_count};\n    return result;\n}\n\nbool is_palindrome(int num) {\n    char str[12];\n    sprintf(str, \"%d\", num);\n    int len = strlen(str);\n    for (int i = 0; i < len / 2; ++i) {\n        if (str[i] != str[len - i - 1]) {\n            return false;\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_113_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int> even_odd_palindrome_simd(int n) {\n    int even_count = 0;\n    int odd_count = 0;\n\n    // Loop through numbers from 1 to n\n    for (int i = 1; i <= n; ++i) {\n        // Check if the number is a palindrome\n        bool is_palindrome = true;\n        int num = i;\n        while (num > 0) {\n            int digit = num % 10;\n            if (digit != num / 10) {\n                is_palindrome = false;\n                break;\n            }\n            num /= 10;\n        }\n\n        // If it's a palindrome, check if it's even or odd\n        if (is_palindrome) {\n            if (i % 2 == 0) {\n                even_count++;\n            } else {\n                odd_count++;\n            }\n        }\n    }\n\n    return {even_count, odd_count};\n}\n```"}
{"task_id": "SimdBench_113_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int> even_odd_palindrome_simd(int n) {\n    int even_count = 0;\n    int odd_count = 0;\n\n    // Loop through numbers from 1 to n\n    for (int i = 1; i <= n; ++i) {\n        // Convert number to string\n        char num_str[12];\n        sprintf(num_str, \"%d\", i);\n\n        // Check if the number is a palindrome\n        int len = strlen(num_str);\n        bool is_palindrome = true;\n        for (int j = 0; j < len / 2; ++j) {\n            if (num_str[j] != num_str[len - j - 1]) {\n                is_palindrome = false;\n                break;\n            }\n        }\n\n        // If it's a palindrome, check if it's even or odd\n        if (is_palindrome) {\n            if (i % 2 == 0) {\n                even_count++;\n            } else {\n                odd_count++;\n            }\n        }\n    }\n\n    return {even_count, odd_count};\n}\n```"}
{"task_id": "SimdBench_113_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int> even_odd_palindrome_simd(int n) {\n    int even_count = 0;\n    int odd_count = 0;\n\n    // Loop through numbers from 1 to n\n    for (int i = 1; i <= n; ++i) {\n        // Check if the number is a palindrome\n        bool is_palindrome = true;\n        int num = i;\n        int reversed_num = 0;\n\n        while (num > 0) {\n            reversed_num = reversed_num * 10 + num % 10;\n            num /= 10;\n        }\n\n        if (reversed_num != i) {\n            is_palindrome = false;\n        }\n\n        // Count even and odd palindromes\n        if (is_palindrome) {\n            if (i % 2 == 0) {\n                even_count++;\n            } else {\n                odd_count++;\n            }\n        }\n    }\n\n    std::vector<int> result = {even_count, odd_count};\n    return result;\n}\n```"}
{"task_id": "SimdBench_113_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int> even_odd_palindrome_simd(int n) {\n    int even_count = 0;\n    int odd_count = 0;\n\n    for (int i = 1; i <= n; ++i) {\n        if (is_palindrome(i)) {\n            if (i % 2 == 0) {\n                even_count++;\n            } else {\n                odd_count++;\n            }\n        }\n    }\n\n    std::vector<int> result = {even_count, odd_count};\n    return result;\n}\n\nbool is_palindrome(int num) {\n    char str[12];\n    sprintf(str, \"%d\", num);\n    int len = strlen(str);\n    for (int i = 0; i < len / 2; ++i) {\n        if (str[i] != str[len - i - 1]) {\n            return false;\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_114_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nint count_nums_simd(const std::vector<int>& nums) {\n    int count = 0;\n    size_t i = 0;\n\n    // Process elements in chunks of 4\n    for (; i + 3 < nums.size(); i += 4) {\n        int32x4_t vec = vld1q_s32(&nums[i]);\n        int32x4_t abs_vec = vabsq_s32(vec);\n        uint32x4_t non_zero_mask = vcgtq_s32(abs_vec, vdupq_n_s32(0));\n        int32x4_t sum_vec = vaddvq_s32(vreinterpretq_s32_u32(non_zero_mask));\n        count += vgetq_lane_s32(sum_vec, 0);\n    }\n\n    // Process remaining elements\n    for (; i < nums.size(); ++i) {\n        if (nums[i] != 0) {\n            count++;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_114_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nint count_nums_simd(const std::vector<int>& nums) {\n    int count = 0;\n    int size = nums.size();\n    int* data = const_cast<int*>(nums.data());\n\n    for (int i = 0; i <= size - 4; i += 4) {\n        int32x4_t v = vld1q_s32(data + i);\n        int32x4_t abs_v = vabsq_s32(v);\n        uint32x4_t non_zero = vcgtq_s32(abs_v, vdupq_n_s32(0));\n        int32x4_t sum = vaddvq_s32(non_zero);\n        count += sum;\n    }\n\n    // Handle remaining elements\n    for (int i = size - size % 4; i < size; ++i) {\n        if (data[i] != 0) {\n            count++;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_114_Neon", "completion": "```cpp\nint count_nums_simd(const std::vector<int>& nums) {\n    int count = 0;\n    int size = nums.size();\n    int* data = const_cast<int*>(nums.data());\n\n    for (int i = 0; i <= size - 4; i += 4) {\n        int32x4_t v = vld1q_s32(data + i);\n        int32x4_t abs_v = vabsq_s32(v);\n        uint32x4_t non_zero = vcgtq_s32(abs_v, vdupq_n_s32(0));\n        int32x4_t sum = vpaddq_s32(vpaddq_s32(vget_low_s32(sum), vget_high_s32(sum)), vget_low_s32(non_zero), vget_high_s32(non_zero));\n        count += vget_lane_s32(sum, 0);\n    }\n\n    for (int i = size - size % 4; i < size; ++i) {\n        if (nums[i] != 0) {\n            ++count;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_114_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nint count_nums_simd(const std::vector<int>& nums) {\n    int count = 0;\n    int size = nums.size();\n    int* data = const_cast<int*>(nums.data());\n\n    for (int i = 0; i <= size - 4; i += 4) {\n        int32x4_t v = vld1q_s32(data + i);\n        int32x4_t abs_v = vabsq_s32(v);\n        uint32x4_t non_zero = vcgtq_s32(abs_v, vdupq_n_s32(0));\n        int sum = vaddvq_u32(non_zero);\n        count += sum;\n    }\n\n    // Handle remaining elements\n    for (int i = size - size % 4; i < size; ++i) {\n        if (data[i] != 0) {\n            count++;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_114_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nint count_nums_simd(const std::vector<int>& nums) {\n    int count = 0;\n    size_t i = 0;\n\n    // Process elements in chunks of 4\n    for (; i + 3 < nums.size(); i += 4) {\n        int32x4_t v = vld1q_s32(&nums[i]);\n        uint32x4_t abs_v = vabsq_s32(v);\n        uint32x4_t non_zero = vcgtq_u32(abs_v, vdupq_n_u32(0));\n        count += vaddvq_u32(non_zero);\n    }\n\n    // Process remaining elements\n    for (; i < nums.size(); ++i) {\n        if (nums[i] != 0) {\n            count++;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_115_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nbool move_one_ball_simd(const std::vector<int>& arr) {\n    int n = arr.size();\n    if (n <= 1) {\n        return true;\n    }\n\n    int count = 0;\n    for (int i = 1; i < n; ++i) {\n        if (arr[i] < arr[i - 1]) {\n            count++;\n        }\n    }\n\n    if (arr[0] < arr[n - 1]) {\n        count++;\n    }\n\n    return count <= 1;\n}\n```"}
{"task_id": "SimdBench_115_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nbool move_one_ball_simd(const std::vector<int>& arr) {\n    int n = arr.size();\n    if (n <= 1) {\n        return true;\n    }\n\n    int count = 0;\n    for (int i = 1; i < n; ++i) {\n        if (arr[i] < arr[i - 1]) {\n            count++;\n        }\n    }\n\n    if (count == 0) {\n        return true;\n    } else if (count == 1 && arr[0] >= arr[n - 1]) {\n        return true;\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_115_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nbool move_one_ball_simd(const std::vector<int>& arr) {\n    int n = arr.size();\n    if (n <= 1) {\n        return true;\n    }\n\n    int count = 0;\n    for (int i = 1; i < n; ++i) {\n        if (arr[i] < arr[i - 1]) {\n            count++;\n        }\n    }\n\n    if (count == 0 || (count == 1 && arr[0] >= arr[n - 1])) {\n        return true;\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_115_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nbool move_one_ball_simd(const std::vector<int>& arr) {\n    int n = arr.size();\n    if (n <= 1) {\n        return true;\n    }\n\n    int count = 0;\n    for (int i = 1; i < n; ++i) {\n        if (arr[i] < arr[i - 1]) {\n            count++;\n        }\n    }\n\n    if (count == 0 || (count == 1 && arr[0] >= arr[n - 1])) {\n        return true;\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_115_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nbool move_one_ball_simd(const std::vector<int>& arr) {\n    int n = arr.size();\n    if (n <= 1) {\n        return true;\n    }\n\n    int count = 0;\n    for (int i = 1; i < n; ++i) {\n        if (arr[i] < arr[i - 1]) {\n            count++;\n        }\n    }\n\n    if (count == 0) {\n        return true;\n    } else if (count == 1 && arr[0] >= arr[n - 1]) {\n        return true;\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_116_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <string>\n\nstd::string myexchange_simd(const std::vector<int>& lst1, const std::vector<int>& lst2) {\n    int32x4_t vones = vdupq_n_s32(1);\n    int32x4_t vzeros = vdupq_n_s32(0);\n\n    int n = lst1.size();\n    int i = 0;\n\n    while (i + 4 <= n) {\n        int32x4_t vlst1 = vld1q_s32(&lst1[i]);\n        int32x4_t vlst2 = vld1q_s32(&lst2[i]);\n\n        uint32x4_t vmask1 = vandq_u32(vreinterpretq_u32_s32(vlst1), vones);\n        uint32x4_t vmask2 = vandq_u32(vreinterpretq_u32_s32(vlst2), vones);\n\n        if (vget_lane_u32(vmask1, 0) == 0 && vget_lane_u32(vmask1, 1) == 0 &&\n            vget_lane_u32(vmask1, 2) == 0 && vget_lane_u32(vmask1, 3) == 0) {\n            return \"YES\";\n        }\n\n        if (vget_lane_u32(vmask2, 0) == 0 && vget_lane_u32(vmask2, 1) == 0 &&\n            vget_lane_u32(vmask2, 2) == 0 && vget_lane_u32(vmask2, 3) == 0) {\n            return \"YES\";\n        }\n\n        i += 4;\n    }\n\n    for (; i < n; ++i) {\n        if (lst1[i] % 2 == 0) {\n            return \"YES\";\n        }\n        if (lst2[i] % 2 == 0) {\n            return \"YES\";\n        }\n    }\n\n    return \"NO\";\n}\n```"}
{"task_id": "SimdBench_116_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <string>\n\nstd::string myexchange_simd(const std::vector<int>& lst1, const std::vector<int>& lst2) {\n    int32x4_t vones = vdupq_n_s32(1);\n    int32x4_t vevens = vdupq_n_s32(0);\n\n    int size = lst1.size();\n    int i = 0;\n\n    while (i + 4 <= size) {\n        int32x4_t vlst1 = vld1q_s32(&lst1[i]);\n        int32x4_t vlst2 = vld1q_s32(&lst2[i]);\n\n        uint32x4_t vmask1 = vandq_u32(vreinterpretq_u32_s32(vlst1), vones);\n        uint32x4_t vmask2 = vandq_u32(vreinterpretq_u32_s32(vlst2), vones);\n\n        if (!vallneq_u32(vmask1, vevens)) {\n            return \"NO\";\n        }\n\n        if (vallneq_u32(vmask2, vevens)) {\n            return \"YES\";\n        }\n\n        i += 4;\n    }\n\n    // Handle remaining elements\n    for (; i < size; ++i) {\n        if (lst1[i] % 2 != 0 && lst2[i] % 2 == 0) {\n            return \"YES\";\n        }\n    }\n\n    return \"NO\";\n}\n```"}
{"task_id": "SimdBench_116_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <string>\n\nstd::string myexchange_simd(const std::vector<int>& lst1, const std::vector<int>& lst2) {\n    int32x4_t vzero = vmovq_n_s32(0);\n    int32x4_t veven_mask = vmovq_n_s32(0xAAAAAAAA);\n\n    int n = lst1.size();\n    bool has_even = false;\n\n    for (int i = 0; i < n; i += 4) {\n        int32x4_t vlst1 = vld1q_s32(&lst1[i]);\n        int32x4_t vlst2 = vld1q_s32(&lst2[i]);\n\n        int32x4_t veven_lst1 = vbicq_s32(vlst1, veven_mask);\n        int32x4_t vodd_lst1 = vandq_s32(vlst1, veven_mask);\n\n        int32x4_t veven_lst2 = vbicq_s32(vlst2, veven_mask);\n        int32x4_t vodd_lst2 = vandq_s32(vlst2, veven_mask);\n\n        if (vceqq_s32(veven_lst1, vzero)) {\n            has_even = true;\n        } else {\n            if (!vceqq_s32(vodd_lst2, vzero)) {\n                return \"NO\";\n            }\n        }\n\n        if (vceqq_s32(veven_lst2, vzero)) {\n            has_even = true;\n        } else {\n            if (!vceqq_s32(vodd_lst1, vzero)) {\n                return \"NO\";\n            }\n        }\n\n        vst1q_s32(&lst1[i], vaddq_s32(veven_lst1, vodd_lst2));\n        vst1q_s32(&lst2[i], vaddq_s32(veven_lst2, vodd_lst1));\n    }\n\n    if (has_even) {\n        return \"YES\";\n    } else {\n        return \"NO\";\n    }\n}\n```"}
{"task_id": "SimdBench_116_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n#include <vector>\n\nstd::string myexchange_simd(const std::vector<int>& lst1, const std::vector<int>& lst2) {\n    int32x4_t vzero = vmovq_n_s32(0);\n    int32x4_t veven_mask = vmovq_n_s32(0xAAAAAAAA);\n\n    int n = lst1.size();\n    int i = 0;\n\n    while (i + 4 <= n) {\n        int32x4_t vlst1 = vld1q_s32(&lst1[i]);\n        int32x4_t vlst2 = vld1q_s32(&lst2[i]);\n\n        int32x4_t vlst1_even = vbicq_s32(vlst1, veven_mask);\n        int32x4_t vlst2_odd = vorrq_s32(vlst2, veven_mask);\n\n        if (vceqq_s32(vlst1_even, vzero) && vceqq_s32(vlst2_odd, vlst2)) {\n            return \"YES\";\n        }\n\n        i += 4;\n    }\n\n    // Handle remaining elements\n    while (i < n) {\n        if (lst1[i] % 2 != 0 || lst2[i] % 2 == 0) {\n            return \"NO\";\n        }\n        i++;\n    }\n\n    return \"YES\";\n}\n```"}
{"task_id": "SimdBench_116_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <string>\n\nstd::string myexchange_simd(const std::vector<int>& lst1, const std::vector<int>& lst2) {\n    int32x4_t vones = vdupq_n_s32(1);\n    int32x4_t vzeros = vdupq_n_s32(0);\n\n    int n = lst1.size();\n    int i = 0;\n\n    while (i + 4 <= n) {\n        int32x4_t vlst1 = vld1q_s32(&lst1[i]);\n        int32x4_t vlst2 = vld1q_s32(&lst2[i]);\n\n        uint32x4_t vmask1 = vandq_u32(vreinterpretq_u32_s32(vlst1), vones);\n        uint32x4_t vmask2 = vandq_u32(vreinterpretq_u32_s32(vlst2), vones);\n\n        if (vget_lane_u32(vmask1, 0) == 0 && vget_lane_u32(vmask1, 1) == 0 &&\n            vget_lane_u32(vmask1, 2) == 0 && vget_lane_u32(vmask1, 3) == 0) {\n            return \"YES\";\n        }\n\n        if (vget_lane_u32(vmask2, 0) == 0 && vget_lane_u32(vmask2, 1) == 0 &&\n            vget_lane_u32(vmask2, 2) == 0 && vget_lane_u32(vmask2, 3) == 0) {\n            return \"YES\";\n        }\n\n        i += 4;\n    }\n\n    for (; i < n; ++i) {\n        if (lst1[i] % 2 == 0) continue;\n        bool found = false;\n        for (int j = 0; j < lst2.size(); ++j) {\n            if (lst2[j] % 2 == 0) {\n                found = true;\n                break;\n            }\n        }\n        if (!found) return \"NO\";\n    }\n\n    return \"YES\";\n}\n```"}
{"task_id": "SimdBench_117_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <string>\n\nstd::vector<std::string> odd_count_simd(const std::vector<std::string> & lst) {\n    std::vector<std::string> result;\n    for (const auto& str : lst) {\n        int count = 0;\n        for (size_t i = 0; i < str.length(); i += 16) {\n            uint8x16_t vec = vld1q_u8(reinterpret_cast<const uint8_t*>(&str[i]));\n            uint16x8_t low = vmovl_u8(vget_low_u8(vec));\n            uint16x8_t high = vmovl_u8(vget_high_u8(vec));\n            uint16x8_t mask = vandq_u16(low, vdupq_n_u16(0x00FF));\n            uint16x8_t odd_mask = veorq_u16(mask, vshrq_n_u16(mask, 1));\n            uint16x8_t sum = vpaddq_u16(odd_mask, vdupq_n_u16(0));\n            uint32x2_t sum_pair = vpadd_u32(vreinterpret_u32_u16(sum), vreinterpret_u32_u16(sum));\n            count += vget_lane_u32(sum_pair, 0);\n        }\n        std::string temp = \"the number of odd elements \" + std::to_string(count) + \"n the str\" + std::to_string(count) + \"ng \" + std::to_string(count) + \" of the \" + std::to_string(count) + \"nput.\";\n        result.push_back(temp);\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_117_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <string>\n\nstd::vector<std::string> odd_count_simd(const std::vector<std::string> & lst) {\n    std::vector<std::string> result;\n    for (const auto& str : lst) {\n        int count = 0;\n        for (size_t i = 0; i < str.length(); i += 16) {\n            uint8x16_t vec = vld1q_u8(reinterpret_cast<const uint8_t*>(&str[i]));\n            uint16x8_t cnt = vcnt_u8(vec);\n            uint32x4_t sum = vpaddl_u16(cnt);\n            uint64x2_t total = vpaddl_u32(sum);\n            count += vget_lane_u64(total, 0);\n        }\n        std::string temp = \"the number of odd elements \" + std::to_string(count) + \"n the str\" + std::to_string(count) + \"ng \" + std::to_string(count) + \" of the \" + std::to_string(count) + \"nput.\";\n        result.push_back(temp);\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_117_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <string>\n\nstd::vector<std::string> odd_count_simd(const std::vector<std::string> & lst) {\n    std::vector<std::string> result;\n    for (const auto& str : lst) {\n        int count = 0;\n        for (size_t i = 0; i < str.length(); i += 16) {\n            uint8x16_t vec = vld1q_u8(reinterpret_cast<const uint8_t*>(&str[i]));\n            uint16x8_t cnt = vcnt_u8(vec);\n            uint16x4_t cnt_lo = vmovl_n_u16(vget_low_u16(cnt));\n            uint16x4_t cnt_hi = vmovl_n_u16(vget_high_u16(cnt));\n            uint32x2_t sum = vaddl_u16(cnt_lo, cnt_hi);\n            uint32x2_t sum_all = vadd_u32(sum, vdup_n_u32(0));\n            count += vget_lane_u32(sum_all, 0);\n        }\n        std::string temp = \"the number of odd elements \" + std::to_string(count) + \"n the str\" + std::to_string(count) + \"ng \" + std::to_string(count) + \" of the \" + std::to_string(count) + \"nput.\";\n        result.push_back(temp);\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_117_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <string>\n\nstd::vector<std::string> odd_count_simd(const std::vector<std::string> & lst) {\n    std::vector<std::string> result;\n    for (const auto& str : lst) {\n        int count = 0;\n        for (size_t i = 0; i < str.length(); i += 16) {\n            uint8x16_t vec = vld1q_u8(reinterpret_cast<const uint8_t*>(&str[i]));\n            uint8x16_t mask = vandq_u8(vec, vmovq_n_u8(0x0F));\n            uint16x8_t sum = vpaddlq_u8(mask);\n            uint32x4_t sum4 = vpaddlq_u16(sum);\n            uint64x2_t sum2 = vpaddlq_u32(sum4);\n            count += vget_lane_u64(sum2, 0);\n        }\n        std::string temp = \"the number of odd elements \" + std::to_string(count) + \"n the str\" + std::to_string(count) + \"ng \" + std::to_string(count) + \" of the \" + std::to_string(count) + \"nput.\";\n        result.push_back(temp);\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_117_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <string>\n\nstd::vector<std::string> odd_count_simd(const std::vector<std::string> & lst) {\n    std::vector<std::string> result;\n    for (const auto& str : lst) {\n        int count = 0;\n        for (size_t i = 0; i < str.length(); i += 16) {\n            uint8x16_t vec = vld1q_u8(reinterpret_cast<const uint8_t*>(&str[i]));\n            uint16x8_t low = vmovl_u8(vget_low_u8(vec));\n            uint16x8_t high = vmovl_u8(vget_high_u8(vec));\n            uint16x8_t mask = vandq_u16(low, vdupq_n_u16(0x00FF));\n            uint16x8_t odd_mask = veorq_u16(mask, vshrq_n_u16(mask, 1));\n            uint16x8_t sum = vpaddq_u16(odd_mask, vdupq_n_u16(0));\n            count += vget_lane_u16(sum, 0);\n            count += vget_lane_u16(sum, 1);\n            count += vget_lane_u16(sum, 2);\n            count += vget_lane_u16(sum, 3);\n        }\n        std::string temp = \"the number of odd elements \" + std::to_string(count) + \"n the str\" + std::to_string(count) + \"ng \" + std::to_string(count) + \" of the \" + std::to_string(count) + \"nput.\";\n        result.push_back(temp);\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_118_Neon", "completion": "```cpp\nint64_t minSubArraySum_simd(const std::vector<int64_t>& nums) {\n    int64_t min_sum = INT64_MAX;\n    int64_t current_sum = 0;\n\n    int n = nums.size();\n    int i = 0;\n\n    while (i < n) {\n        int64x2_t vnums = vld1q_s64(&nums[i]);\n        int64x2_t vmin_sum = vdupq_n_s64(INT64_MAX);\n        int64x2_t vcurrent_sum = vdupq_n_s64(0);\n\n        for (int j = 0; j < 2 && i + j < n; ++j) {\n            vcurrent_sum = vaddq_s64(vcurrent_sum, vld1q_lane_s64(&nums[i + j], vnums, j));\n            vmin_sum = vminq_s64(vmin_sum, vcurrent_sum);\n        }\n\n        min_sum = std::min(min_sum, vmin_sum[0]);\n        min_sum = std::min(min_sum, vcurrent_sum[1]);\n\n        i += 2;\n    }\n\n    return min_sum;\n}\n```"}
{"task_id": "SimdBench_118_Neon", "completion": "```cpp\nint64_t minSubArraySum_simd(const std::vector<int64_t>& nums) {\n    int64_t min_sum = INT64_MAX;\n    int64_t current_sum = 0;\n\n    int n = nums.size();\n    int i = 0;\n\n    while (i < n) {\n        int64x2_t vnums = vld1q_s64(&nums[i]);\n        int64x2_t vmin_sum = vdupq_n_s64(INT64_MAX);\n        int64x2_t vcurrent_sum = vdupq_n_s64(0);\n\n        for (int j = 0; j < 2 && i + j < n; ++j) {\n            int64_t num = nums[i + j];\n            int64_t new_current_sum = vget_lane_s64(vcurrent_sum, 0) + num;\n            int64_t new_min_sum = vget_lane_s64(vmin_sum, 0);\n\n            if (new_current_sum < new_min_sum) {\n                new_min_sum = new_current_sum;\n            }\n\n            vcurrent_sum = vset_lane_s64(new_current_sum, vcurrent_sum, 0);\n            vmin_sum = vset_lane_s64(new_min_sum, vmin_sum, 0);\n        }\n\n        min_sum = std::min(min_sum, vget_lane_s64(vmin_sum, 0));\n        current_sum = vget_lane_s64(vcurrent_sum, 0);\n\n        i += 2;\n    }\n\n    return min_sum;\n}\n```"}
{"task_id": "SimdBench_118_Neon", "completion": "```cpp\nint64_t minSubArraySum_simd(const std::vector<int64_t>& nums) {\n    int64_t min_sum = INT64_MAX;\n    int64_t current_sum = 0;\n\n    size_t n = nums.size();\n    size_t i = 0;\n\n    while (i < n) {\n        int64x2_t vnums = vld1q_s64(&nums[i]);\n        int64x2_t vmin_sum = vdupq_n_s64(min_sum);\n        int64x2_t vcurrent_sum = vdupq_n_s64(current_sum);\n\n        for (size_t j = 0; j < 2 && i + j < n; ++j) {\n            int64_t num = nums[i + j];\n            int64_t new_current_sum = vget_lane_s64(vcurrent_sum, 0) + num;\n            int64_t new_min_sum = vget_lane_s64(vmin_sum, 0);\n\n            if (new_current_sum < new_min_sum) {\n                new_min_sum = new_current_sum;\n            }\n\n            vcurrent_sum = vset_lane_s64(new_current_sum, vcurrent_sum, 0);\n            vmin_sum = vset_lane_s64(new_min_sum, vmin_sum, 0);\n        }\n\n        min_sum = vget_lane_s64(vmin_sum, 0);\n        current_sum = vget_lane_s64(vcurrent_sum, 0);\n        i += 2;\n    }\n\n    return min_sum;\n}\n```"}
{"task_id": "SimdBench_118_Neon", "completion": "```cpp\nint64_t minSubArraySum_simd(const std::vector<int64_t>& nums) {\n    int64_t min_sum = INT64_MAX;\n    int64_t current_sum = 0;\n\n    int n = nums.size();\n    int i = 0;\n\n    while (i < n) {\n        int64x2_t vnums = vld1q_s64(&nums[i]);\n        int64x2_t vmin_sum = vdupq_n_s64(min_sum);\n        int64x2_t vcurrent_sum = vdupq_n_s64(current_sum);\n\n        for (int j = 0; j < 2 && i + j < n; ++j) {\n            int64_t num = nums[i + j];\n            int64_t new_current_sum = vget_lane_s64(vcurrent_sum, 0) + num;\n            int64_t new_min_sum = vget_lane_s64(vmin_sum, 0) > new_current_sum ? new_current_sum : vget_lane_s64(vmin_sum, 0);\n\n            vcurrent_sum = vset_lane_s64(new_current_sum, vcurrent_sum, 0);\n            vmin_sum = vset_lane_s64(new_min_sum, vmin_sum, 0);\n        }\n\n        min_sum = vget_lane_s64(vmin_sum, 0);\n        current_sum = vget_lane_s64(vcurrent_sum, 0);\n        i += 2;\n    }\n\n    return min_sum;\n}\n```"}
{"task_id": "SimdBench_118_Neon", "completion": "```cpp\nint64_t minSubArraySum_simd(const std::vector<int64_t>& nums) {\n    int64_t min_sum = INT64_MAX;\n    int64_t current_sum = 0;\n\n    int n = nums.size();\n    int num_chunks = (n + 7) / 8; // Number of chunks of 8 elements each\n\n    for (int i = 0; i < num_chunks; ++i) {\n        int start = i * 8;\n        int end = std::min(start + 8, n);\n\n        int64x2_t v_min_sum = vmovq_n_s64(INT64_MAX);\n        int64x2_t v_current_sum = vmovq_n_s64(0);\n\n        for (int j = start; j < end; j += 2) {\n            int64x2_t v_num = vld1q_s64(&nums[j]);\n            v_current_sum = vminq_s64(v_current_sum, v_addq_s64(v_current_sum, v_num));\n            v_min_sum = vminq_s64(v_min_sum, v_current_sum);\n        }\n\n        int64_t local_min_sum[2];\n        vst1q_s64(local_min_sum, v_min_sum);\n\n        min_sum = std::min(min_sum, local_min_sum[0]);\n        if (end % 2 != 0) {\n            min_sum = std::min(min_sum, nums[end - 1]);\n        }\n    }\n\n    return min_sum;\n}\n```"}
{"task_id": "SimdBench_119_Neon", "completion": "```cpp\nint max_fill_simd(const std::vector<std::vector<int>>& grid, int capacity) {\n    int rows = grid.size();\n    int cols = grid[0].size();\n    int total_water = 0;\n\n    // Process 4 columns at a time using Neon intrinsics\n    for (int i = 0; i < rows; ++i) {\n        int remaining_cols = cols;\n        const int* col_data = &grid[i][0];\n\n        while (remaining_cols >= 4) {\n            uint8x16_t v0 = vld1q_u8((uint8_t*)col_data);\n            uint8x16_t v1 = vld1q_u8((uint8_t*)(col_data + 16));\n            uint8x16_t v2 = vld1q_u8((uint8_t*)(col_data + 32));\n            uint8x16_t v3 = vld1q_u8((uint8_t*)(col_data + 48));\n\n            uint8x16_t v_sum0 = vaddw_u8(v0, v1);\n            uint8x16_t v_sum1 = vaddw_u8(v2, v3);\n\n            uint8x16_t v_total = vaddw_u8(v_sum0, v_sum1);\n            uint16x8_t v_count = vmovl_u8(vtotal);\n\n            uint32x4_t v_count32 = vpaddw_u32(v_count, v_count);\n            uint32x2_t v_count16 = vpadd_u32(v_count32, v_count32);\n            uint32_t count = vget_lane_u32(v_count16, 0);\n\n            total_water += count / capacity;\n            total_water += count % capacity != 0;\n\n            col_data += 64;\n            remaining_cols -= 4;\n        }\n\n        // Handle remaining columns less than 4\n        for (int j = 0; j < remaining_cols; ++j) {\n            total_water += grid[i][cols - remaining_cols + j];\n        }\n    }\n\n    return total_water;\n}\n```"}
{"task_id": "SimdBench_119_Neon", "completion": "```cpp\nint max_fill_simd(const std::vector<std::vector<int>>& grid, int capacity) {\n    int rows = grid.size();\n    int cols = grid[0].size();\n    int total_water = 0;\n\n    // Process 4 columns at a time using Neon intrinsics\n    for (int i = 0; i < rows; ++i) {\n        int remaining_cols = cols;\n        const int* col_data = grid[i].data();\n\n        while (remaining_cols >= 4) {\n            uint8x16_t v0 = vld1q_u8((uint8_t*)(col_data));\n            uint8x16_t v1 = vld1q_u8((uint8_t*)(col_data + 16));\n            uint8x16_t v2 = vld1q_u8((uint8_t*)(col_data + 32));\n            uint8x16_t v3 = vld1q_u8((uint8_t*)(col_data + 48));\n\n            uint8x16_t sum0 = vaddvq_u8(v0);\n            uint8x16_t sum1 = vaddvq_u8(v1);\n            uint8x16_t sum2 = vaddvq_u8(v2);\n            uint8x16_t sum3 = vaddvq_u8(v3);\n\n            total_water += sum0 + sum1 + sum2 + sum3;\n            col_data += 64;\n            remaining_cols -= 4;\n        }\n\n        // Handle remaining columns less than 4\n        for (int j = 0; j < remaining_cols; ++j) {\n            total_water += grid[i][cols - remaining_cols + j];\n        }\n    }\n\n    return (total_water + capacity - 1) / capacity;\n}\n```"}
{"task_id": "SimdBench_119_Neon", "completion": "```cpp\nint max_fill_simd(const std::vector<std::vector<int>>& grid, int capacity) {\n    int rows = grid.size();\n    int cols = grid[0].size();\n    int total_water = 0;\n\n    for (int i = 0; i < rows; i += 4) {\n        int remaining_rows = std::min(rows - i, 4);\n        int water_in_row[4] = {0};\n\n        for (int j = 0; j < cols; j++) {\n            for (int k = 0; k < remaining_rows; ++k) {\n                water_in_row[k] += grid[i + k][j];\n            }\n        }\n\n        int sum = water_in_row[0] + water_in_row[1] + water_in_row[2] + water_in_row[3];\n        total_water += (sum + capacity - 1) / capacity;\n    }\n\n    return total_water;\n}\n```"}
{"task_id": "SimdBench_119_Neon", "completion": "```cpp\nint max_fill_simd(const std::vector<std::vector<int>>& grid, int capacity) {\n    int rows = grid.size();\n    int cols = grid[0].size();\n    int total_water = 0;\n\n    // Process 4 columns at a time using Neon intrinsics\n    for (int i = 0; i < rows; ++i) {\n        int remaining_cols = cols;\n        const int* col_data = grid[i].data();\n\n        while (remaining_cols >= 4) {\n            uint8x16_t v0 = vld1q_u8((const uint8_t*)col_data);\n            uint8x16_t v1 = vld1q_u8((const uint8_t*)(col_data + 16));\n            uint8x16_t v2 = vld1q_u8((const uint8_t*)(col_data + 32));\n            uint8x16_t v3 = vld1q_u8((const uint8_t*)(col_data + 48));\n\n            uint8x16_t sum0 = vaddvq_u8(v0);\n            uint8x16_t sum1 = vaddvq_u8(v1);\n            uint8x16_t sum2 = vaddvq_u8(v2);\n            uint8x16_t sum3 = vaddvq_u8(v3);\n\n            total_water += sum0 + sum1 + sum2 + sum3;\n            col_data += 64;\n            remaining_cols -= 4;\n        }\n\n        // Handle remaining columns less than 4\n        for (; remaining_cols > 0; --remaining_cols) {\n            total_water += *col_data++;\n        }\n    }\n\n    return (total_water + capacity - 1) / capacity;\n}\n```"}
{"task_id": "SimdBench_119_Neon", "completion": "```cpp\nint max_fill_simd(const std::vector<std::vector<int>>& grid, int capacity) {\n    int rows = grid.size();\n    int cols = grid[0].size();\n    int total_water = 0;\n\n    // Process 4 columns at a time using Neon intrinsics\n    for (int i = 0; i < rows; ++i) {\n        int remaining_cols = cols;\n        const int* col_ptr = &grid[i][0];\n\n        while (remaining_cols >= 4) {\n            uint8x16_t v0 = vld1q_u8((uint8_t*)col_ptr);\n            uint8x16_t v1 = vld1q_u8((uint8_t*)(col_ptr + 16));\n            uint8x16_t v2 = vld1q_u8((uint8_t*)(col_ptr + 32));\n            uint8x16_t v3 = vld1q_u8((uint8_t*)(col_ptr + 48));\n\n            uint16x8_t sum0 = vpaddlq_u8(v0);\n            uint16x8_t sum1 = vpaddlq_u8(v1);\n            uint16x8_t sum2 = vpaddlq_u8(v2);\n            uint16x8_t sum3 = vpaddlq_u8(v3);\n\n            uint32x4_t sum4 = vpaddq_u16(sum0, sum1);\n            uint32x4_t sum5 = vpaddq_u16(sum2, sum3);\n\n            uint64x2_t sum6 = vpaddq_u32(sum4, sum5);\n\n            total_water += vget_lane_u64(sum6, 0) + vget_lane_u64(sum6, 1);\n\n            col_ptr += 64;\n            remaining_cols -= 4;\n        }\n\n        // Handle remaining columns less than 4\n        for (; remaining_cols > 0; --remaining_cols) {\n            total_water += *col_ptr++;\n        }\n    }\n\n    return (total_water + capacity - 1) / capacity;\n}\n```"}
{"task_id": "SimdBench_120_Neon", "completion": "```cpp\nint64_t solution_simd(const std::vector<int16_t>& lst) {\n    int64_t sum = 0;\n    size_t n = lst.size();\n    size_t i = 0;\n\n    // Process elements in chunks of 8\n    for (; i <= n - 8; i += 8) {\n        int16x8_t v = vld1q_s16(&lst[i]);\n        uint16x8_t mask = vand_u16(vdupq_n_u16(0x00FF), vreinterpret_u16_s16(v));\n        uint16x8_t odd_mask = vorr_u16(mask, vshrq_n_u16(mask, 1));\n        uint16x8_t even_positions = vand_u16(vreinterpret_u16_s16(vld1q_s16(&lst[i + 4])), vdupq_n_u16(0x5555));\n        uint16x8_t result = vand_u16(even_positions, odd_mask);\n        sum += vaddvq_u16(result);\n    }\n\n    // Process remaining elements\n    for (; i < n; ++i) {\n        if ((i % 2 == 0) && (lst[i] & 1)) {\n            sum += lst[i];\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_120_Neon", "completion": "```cpp\nint64_t solution_simd(const std::vector<int16_t>& lst) {\n    int64_t sum = 0;\n    size_t n = lst.size();\n    size_t i = 0;\n\n    // Process elements in chunks of 8\n    for (; i <= n - 8; i += 8) {\n        int16x8_t v = vld1q_s16(&lst[i]);\n        uint16x8_t mask = vand_u16(vdupq_n_u16(0x00FF), vmovn_u32(vreinterpretq_u32_s16(v)));\n        uint16x8_t odd_mask = vorr_u16(mask, vshrq_n_u16(mask, 1));\n        uint16x8_t even_positions = vand_u16(odd_mask, vdupq_n_u16(0xAAAA));\n        uint16x8_t result = vaddw_u16(vdupq_n_u16(0), even_positions);\n        sum += vget_lane_u32(vreinterpretq_u32_u16(result), 0);\n    }\n\n    // Process remaining elements\n    for (; i < n; ++i) {\n        if (i % 2 == 0 && lst[i] % 2 != 0) {\n            sum += lst[i];\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_120_Neon", "completion": "```cpp\nint64_t solution_simd(const std::vector<int16_t>& lst) {\n    int64_t sum = 0;\n    size_t n = lst.size();\n    size_t i = 0;\n\n    // Process elements in chunks of 8\n    for (; i <= n - 8; i += 8) {\n        int16x8_t v = vld1q_s16(&lst[i]);\n        uint16x8_t mask = vand_u16(vdupq_n_u16(0x00FF), vmovl_s16(vshr_n_s16(vreinterpretq_s16_u16(v), 1)));\n        int16x8_t odd_elements = vandq_s16(v, vmovl_s16(mask));\n        int64x2_t sum_pairwise = vpaddlq_s16(odd_elements);\n        sum += vget_lane_s64(sum_pairwise, 0) + vget_lane_s64(sum_pairwise, 1);\n    }\n\n    // Process remaining elements\n    for (; i < n; ++i) {\n        if (i % 2 == 0 && lst[i] % 2 != 0) {\n            sum += lst[i];\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_120_Neon", "completion": "```cpp\nint64_t solution_simd(const std::vector<int16_t>& lst) {\n    int64_t sum = 0;\n    size_t n = lst.size();\n    size_t i = 0;\n\n    // Process elements in chunks of 8\n    for (; i <= n - 8; i += 8) {\n        int16x8_t v = vld1q_s16(&lst[i]);\n        uint16x8_t mask = vand_u16(vdupq_n_u16(0x00FF), vmovl_s16(vshr_n_s16(vreinterpretq_s16_u16(vand_u16(vdupq_n_u16(0xFF00), v)), 8)));\n        int16x8_t odd_mask = vand_u16(mask, vdupq_n_u16(0x000F));\n        int16x8_t result = vaddw_s16(vdupq_n_s16(0), vreinterpretq_s16_u16(odd_mask));\n        sum += vget_lane_s32(vreinterpretq_s32_s16(result), 0);\n        sum += vget_lane_s32(vreinterpretq_s32_s16(result), 1);\n    }\n\n    // Process remaining elements\n    for (; i < n; ++i) {\n        if (i % 2 == 0 && lst[i] % 2 != 0) {\n            sum += lst[i];\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_120_Neon", "completion": "```cpp\nint64_t solution_simd(const std::vector<int16_t>& lst) {\n    int64_t sum = 0;\n    size_t n = lst.size();\n    size_t i = 0;\n\n    // Process elements in chunks of 8\n    for (; i <= n - 8; i += 8) {\n        int16x8_t v = vld1q_s16(&lst[i]);\n        uint16x8_t mask = vand_u16(vdupq_n_u16(0x00FF), vmovl_s16(vshr_n_s16(vreinterpretq_s16_s8(vandq_s8(vreinterpretq_s8_s16(v), vdupq_n_s8(0x00FF))), 1)));\n        int16x8_t odd_elements = vandq_s16(v, vmovl_s16(mask));\n        int16x8_t even_positions = vandq_s16(odd_elements, vdupq_n_s16(0xAAAA));\n        sum += vaddvq_s16(even_positions);\n    }\n\n    // Process remaining elements\n    for (; i < n; ++i) {\n        if (i % 2 == 0 && lst[i] % 2 != 0) {\n            sum += lst[i];\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_121_Neon", "completion": "```cpp\nint add_elements_simd(std::vector<int> arr, int k) {\n    int result = 0;\n    int i = 0;\n\n    // Process elements in chunks of 4\n    for (; i <= k - 4; i += 4) {\n        int32x4_t vec = vld1q_s32(&arr[i]);\n        uint32x4_t mask = vcltq_s32(vec, 100);\n        int32x4_t masked_vec = vandq_s32(vec, vmovq_n_s32(0xFFFFFFFF));\n        int32x4_t selected_vec = vbicq_s32(masked_vec, vmulq_s32(mask, vmovq_n_s32(-1)));\n        int32x4_t sum_vec = vpaddq_s32(selected_vec, selected_vec);\n        int32x2_t sum_pair = vpadd_s32(vget_low_s32(sum_vec), vget_high_s32(sum_vec));\n        result += vget_lane_s32(sum_pair, 0);\n    }\n\n    // Process remaining elements\n    for (; i < k; ++i) {\n        if (arr[i] >= 0 && arr[i] < 100) {\n            result += arr[i];\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_121_Neon", "completion": "```cpp\nint add_elements_simd(std::vector<int> arr, int k) {\n    const int* data = arr.data();\n    int sum = 0;\n    int count = std::min(k, static_cast<int>(arr.size()));\n\n    for (int i = 0; i < count; i += 8) {\n        int32x4_t v1 = vld1q_s32(data + i);\n        int32x4_t v2 = vld1q_s32(data + i + 4);\n\n        uint32x4_t mask1 = vcgtq_s32(v1, vdupq_n_s32(99));\n        uint32x4_t mask2 = vcgtq_s32(v2, vdupq_n_s32(99));\n\n        int32x4_t masked1 = vbicq_s32(v1, vmovq_n_s32(0xFFFFFFFF));\n        int32x4_t masked2 = vbicq_s32(v2, vmovq_n_s32(0xFFFFFFFF));\n\n        int32x4_t sum1 = vaddq_s32(masked1, vreinterpretq_s32_u32(mask1));\n        int32x4_t sum2 = vaddq_s32(masked2, vreinterpretq_s32_u32(mask2));\n\n        sum += vgetq_lane_s32(sum1, 0) + vgetq_lane_s32(sum1, 1) +\n               vgetq_lane_s32(sum1, 2) + vgetq_lane_s32(sum1, 3) +\n               vgetq_lane_s32(sum2, 0) + vgetq_lane_s32(sum2, 1) +\n               vgetq_lane_s32(sum2, 2) + vgetq_lane_s32(sum2, 3);\n    }\n\n    for (int i = count - count % 8; i < count; ++i) {\n        if (data[i] >= 10 && data[i] <= 99) {\n            sum += data[i];\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_121_Neon", "completion": "```cpp\nint add_elements_simd(std::vector<int> arr, int k) {\n    const int* data = arr.data();\n    int sum = 0;\n    int count = std::min(k, static_cast<int>(arr.size()));\n\n    for (int i = 0; i < count; i += 8) {\n        int32x4_t v1 = vld1q_s32(data + i);\n        int32x4_t v2 = vld1q_s32(data + i + 4);\n\n        uint32x4_t mask1 = vcltq_s32(vabsq_s32(v1), vdupq_n_s32(100));\n        uint32x4_t mask2 = vcltq_s32(vabsq_s32(v2), vdupq_n_s32(100));\n\n        int32x4_t selected1 = vandq_s32(v1, vmovq_n_s32(-1));\n        int32x4_t selected2 = vandq_s32(v2, vmovq_n_s32(-1));\n\n        int32x4_t result1 = vmlal_s32(vdupq_n_s32(0), selected1, vmovq_n_s32(1));\n        int32x4_t result2 = vmlal_s32(vdupq_n_s32(0), selected2, vmovq_n_s32(1));\n\n        int32x4_t combined = vorrq_s32(result1, result2);\n        int32x4_t final_result = vorrq_s32(combined, vshlq_n_s32(combined, vdupq_n_s32(1)));\n\n        sum += vgetq_lane_s32(final_result, 0) + vgetq_lane_s32(final_result, 1) +\n               vgetq_lane_s32(final_result, 2) + vgetq_lane_s32(final_result, 3);\n    }\n\n    for (int i = count - count % 8; i < count; ++i) {\n        if (std::abs(data[i]) < 100) {\n            sum += data[i];\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_121_Neon", "completion": "```cpp\nint add_elements_simd(std::vector<int> arr, int k) {\n    const int* data = arr.data();\n    int sum = 0;\n    int count = std::min(k, static_cast<int>(arr.size()));\n\n    // Process in chunks of 8 elements\n    for (int i = 0; i < count / 8 * 8; i += 8) {\n        int32x4_t v1 = vld1q_s32(data + i);\n        int32x4_t v2 = vld1q_s32(data + i + 4);\n        int32x4_t mask1 = vcltq_s32(vabsq_s32(v1), vdupq_n_s32(100));\n        int32x4_t mask2 = vcltq_s32(vabsq_s32(v2), vdupq_n_s32(100));\n        int32x4_t selected1 = vbicq_s32(v1, vmvnq_s32(mask1));\n        int32x4_t selected2 = vbicq_s32(v2, vmvnq_s32(mask2));\n        int32x4_t sum_vec = vaddq_s32(selected1, selected2);\n        sum += vgetq_lane_s32(sum_vec, 0) + vgetq_lane_s32(sum_vec, 1) +\n               vgetq_lane_s32(sum_vec, 2) + vgetq_lane_s32(sum_vec, 3);\n    }\n\n    // Process remaining elements\n    for (int i = count / 8 * 8; i < count; ++i) {\n        if (std::abs(data[i]) < 100) {\n            sum += data[i];\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_121_Neon", "completion": "```cpp\nint add_elements_simd(std::vector<int> arr, int k) {\n    int result = 0;\n    int i = 0;\n\n    // Process elements in chunks of 4\n    while (i + 4 <= k) {\n        int32x4_t vec = vld1q_s32(&arr[i]);\n        int32x4_t mask = vcltq_s32(vec, 100);\n        int32x4_t masked_vec = vmulq_s32(vec, mask);\n        int32x4_t sum_vec = vpaddq_s32(masked_vec, vdupq_n_s32(0));\n        int32x2_t sum_pair = vpadd_s32(vget_low_s32(sum_vec), vget_high_s32(sum_vec));\n        result += vget_lane_s32(sum_pair, 0);\n\n        i += 4;\n    }\n\n    // Process remaining elements\n    while (i < k) {\n        if (arr[i] < 100) {\n            result += arr[i];\n        }\n        i++;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_122_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nbool is_sorted_simd(const std::vector<int>& lst) {\n    if (lst.size() <= 1) {\n        return true;\n    }\n\n    int32x4_t prev = vld1q_s32(&lst[0]);\n    int32x4_t curr;\n\n    for (size_t i = 4; i + 3 < lst.size(); i += 4) {\n        curr = vld1q_s32(&lst[i]);\n        uint32x4_t cmp = vcgtq_s32(curr, prev);\n        if (vmaxvq_u32(cmp)) {\n            return false;\n        }\n        prev = curr;\n    }\n\n    // Check remaining elements\n    for (size_t i = lst.size() - lst.size() % 4; i < lst.size(); ++i) {\n        if (lst[i] < lst[i - 1]) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_122_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nbool is_sorted_simd(const std::vector<int>& lst) {\n    if (lst.size() <= 1) {\n        return true;\n    }\n\n    int32x4_t prev = vld1q_s32(&lst[0]);\n    int32x4_t curr = vld1q_s32(&lst[4]);\n\n    for (size_t i = 8; i < lst.size(); i += 8) {\n        int32x4_t next = vld1q_s32(&lst[i + 4]);\n\n        uint32x4_t cmp_prev_curr = vcgtq_s32(curr, prev);\n        uint32x4_t cmp_curr_next = vcgtq_s32(next, curr);\n\n        if (!vallq_u32(cmp_prev_curr) || !vallq_u32(cmp_curr_next)) {\n            return false;\n        }\n\n        prev = curr;\n        curr = next;\n    }\n\n    // Check remaining elements\n    for (size_t i = lst.size() - lst.size() % 8; i < lst.size(); ++i) {\n        if (i > 0 && lst[i] < lst[i - 1]) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_122_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nbool is_sorted_simd(const std::vector<int> & lst) {\n    if (lst.size() <= 1) {\n        return true;\n    }\n\n    int32x4_t prev = vld1q_s32(&lst[0]);\n    int32x4_t curr = vld1q_s32(&lst[4]);\n\n    for (size_t i = 8; i < lst.size(); i += 8) {\n        int32x4_t next = vld1q_s32(&lst[i + 4]);\n\n        uint32x4_t cmp_prev_curr = vcgtq_s32(curr, prev);\n        uint32x4_t cmp_curr_next = vcgtq_s32(next, curr);\n\n        if (!vallq_u32(cmp_prev_curr) || !vallq_u32(cmp_curr_next)) {\n            return false;\n        }\n\n        prev = curr;\n        curr = next;\n    }\n\n    // Check remaining elements\n    for (size_t i = lst.size() - lst.size() % 8; i < lst.size(); ++i) {\n        if (i > 0 && lst[i] < lst[i - 1]) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_122_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nbool is_sorted_simd(const std::vector<int> & lst) {\n    if (lst.size() <= 1) {\n        return true;\n    }\n\n    int32x4_t prev = vld1q_s32(&lst[0]);\n    int32x4_t curr = vld1q_s32(&lst[4]);\n\n    for (size_t i = 8; i < lst.size(); i += 8) {\n        int32x4_t next = vld1q_s32(&lst[i + 4]);\n        uint32x4_t cmp_prev_curr = vcgtq_s32(curr, prev);\n        uint32x4_t cmp_curr_next = vcgtq_s32(next, curr);\n\n        if (!vallq_u32(cmp_prev_curr) || !vallq_u32(cmp_curr_next)) {\n            return false;\n        }\n\n        prev = curr;\n        curr = next;\n    }\n\n    size_t remaining = lst.size() % 8;\n    for (size_t i = 0; i < remaining; ++i) {\n        if (lst[i + lst.size() - remaining] > lst[i + lst.size() - remaining + 1]) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_122_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nbool is_sorted_simd(const std::vector<int> & lst) {\n    if (lst.size() <= 1) {\n        return true;\n    }\n\n    int32x4_t prev = vld1q_s32(&lst[0]);\n    int32x4_t curr = vld1q_s32(&lst[4]);\n\n    for (size_t i = 8; i < lst.size(); i += 8) {\n        int32x4_t next = vld1q_s32(&lst[i + 4]);\n        int32x4_t mask = vcltq_s32(curr, prev);\n        if (!vallq_u32(mask)) {\n            return false;\n        }\n        prev = curr;\n        curr = next;\n    }\n\n    size_t remaining = lst.size() % 8;\n    for (size_t i = 0; i < remaining; ++i) {\n        if (lst[i + lst.size() - remaining] > lst[i + lst.size() - remaining + 1]) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_123_Neon", "completion": "```cpp\nint prod_signs_simd(const std::vector<int>& arr) {\n    if (arr.empty()) {\n        return -32768;\n    }\n\n    int sum_magnitudes = 0;\n    int product_of_signs = 1;\n\n    int size = arr.size();\n    int i = 0;\n\n    for (; i <= size - 4; i += 4) {\n        int32x4_t vec = vld1q_s32(&arr[i]);\n        int32x4_t abs_vec = vabsq_s32(vec);\n        int32x4_t sign_vec = vmovq_n_s32(vget_lane_s32(vec, 0));\n        sign_vec = vandq_s32(sign_vec, vdupq_n_s32(0x80000000));\n        sign_vec = vreinterpretq_s32_u32(vshrq_n_u32(vreinterpretq_u32_s32(sign_vec), 31));\n\n        sum_magnitudes += vaddvq_s32(abs_vec);\n        product_of_signs *= vaddvq_s32(sign_vec);\n    }\n\n    for (; i < size; ++i) {\n        sum_magnitudes += std::abs(arr[i]);\n        product_of_signs *= (arr[i] < 0 ? -1 : (arr[i] > 0 ? 1 : 0));\n    }\n\n    return sum_magnitudes * product_of_signs;\n}\n```"}
{"task_id": "SimdBench_123_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <cmath>\n\nint prod_signs_simd(const std::vector<int>& arr) {\n    if (arr.empty()) {\n        return -32768;\n    }\n\n    int sum_magnitudes = 0;\n    int product_of_signs = 1;\n\n    int32x4_t sum_vec = vdupq_n_s32(0);\n    int32x4_t sign_vec = vdupq_n_s32(1);\n\n    for (size_t i = 0; i < arr.size(); i += 4) {\n        int32x4_t vec = vld1q_s32(&arr[i]);\n\n        // Calculate magnitudes\n        int32x4_t abs_vec = vabsq_s32(vec);\n        sum_vec = vaddq_s32(sum_vec, abs_vec);\n\n        // Calculate product of signs\n        int32x4_t sign_mask = vcgtq_s32(vec, vdupq_n_s32(0));\n        sign_mask = vmovm_vn_u32(sign_mask);\n        sign_vec = vmulq_s32(sign_vec, vreinterpretq_s32_u32(vmovl_u16(vget_low_u16(vreinterpretq_u16_s32(sign_mask)))));\n    }\n\n    // Sum up the magnitudes\n    for (int i = 0; i < 4; ++i) {\n        sum_magnitudes += vgetq_lane_s32(sum_vec, i);\n    }\n\n    // Sum up the product of signs\n    for (int i = 0; i < 4; ++i) {\n        product_of_signs *= vgetq_lane_s32(sign_vec, i);\n    }\n\n    return sum_magnitudes * product_of_signs;\n}\n```"}
{"task_id": "SimdBench_123_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <cmath>\n\nint prod_signs_simd(const std::vector<int> & arr) {\n    if (arr.empty()) {\n        return -32768;\n    }\n\n    int sum_magnitudes = 0;\n    int product_of_signs = 1;\n\n    int32x4_t v_sum_magnitudes = vdupq_n_s32(0);\n    int32x4_t v_product_of_signs = vdupq_n_s32(1);\n\n    for (size_t i = 0; i < arr.size(); i += 4) {\n        int32x4_t v_values = vld1q_s32(&arr[i]);\n\n        // Calculate magnitudes\n        int32x4_t v_abs_values = vabsq_s32(v_values);\n\n        // Sum magnitudes\n        v_sum_magnitudes = vaddq_s32(v_sum_magnitudes, v_abs_values);\n\n        // Calculate product of signs\n        int32x4_t v_signs = vmovq_n_s32(0);\n        v_signs = vandq_s32(v_signs, vcltzq_s32(v_values));\n        v_signs = vsubq_s32(vdupq_n_s32(1), v_signs);\n        v_product_of_signs = vmulq_s32(v_product_of_signs, v_signs);\n    }\n\n    // Reduce sums and products\n    int32x2_t v_sum_magnitudes_lo = vpadd_s32(vget_low_s32(v_sum_magnitudes), vget_high_s32(v_sum_magnitudes));\n    int32x2_t v_product_of_signs_lo = vpadd_s32(vget_low_s32(v_product_of_signs), vget_high_s32(v_product_of_signs));\n\n    int32x2_t v_sum_magnitudes_hi = vshlq_n_s32(v_sum_magnitudes_lo, vdupq_n_s32(16));\n    int32x2_t v_result = vaddq_s32(v_sum_magnitudes_lo, v_sum_magnitudes_hi);\n\n    int result = vget_lane_s32(v_result, 0);\n    int product_of_signs_result = vget_lane_s32(v_product_of_signs_lo, 0);\n\n    // Handle remaining elements\n    for (size_t i = arr.size() - arr.size() % 4; i < arr.size(); ++i) {\n        sum_magnitudes += std::abs(arr[i]);\n        product_of_signs *= (arr[i] > 0) ? 1 : ((arr[i] < 0) ? -1 : 0);\n    }\n\n    return sum_magnitudes * product_of_signs_result;\n}\n```"}
{"task_id": "SimdBench_123_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nint prod_signs_simd(const std::vector<int> & arr) {\n    if (arr.empty()) {\n        return -32768;\n    }\n\n    int sum_magnitudes = 0;\n    int product_of_signs = 1;\n\n    int32x4_t sum_vec = vdupq_n_s32(0);\n    int32x4_t sign_vec = vdupq_n_s32(1);\n\n    for (size_t i = 0; i < arr.size(); i += 4) {\n        int32x4_t vec = vld1q_s32(&arr[i]);\n\n        // Calculate magnitudes\n        int32x4_t abs_vec = vabsq_s32(vec);\n        sum_vec = vaddq_s32(sum_vec, abs_vec);\n\n        // Calculate product of signs\n        int32x4_t sign_mask = veorq_s32(vcltq_s32(vec, vdupq_n_s32(0)), vdupq_n_s32(0x55555555));\n        sign_vec = vmulq_s32(sign_vec, sign_mask);\n    }\n\n    // Sum up the magnitudes\n    int32x2_t sum_low = vpadd_s32(vget_low_s32(sum_vec), vget_high_s32(sum_vec));\n    int32x2_t sum_all = vpadd_s32(sum_low, sum_low);\n    sum_magnitudes = vget_lane_s32(sum_all, 0);\n\n    // Sum up the signs\n    int32x2_t sign_low = vpadd_s32(vget_low_s32(sign_vec), vget_high_s32(sign_vec));\n    int32x2_t sign_all = vpadd_s32(sign_low, sign_low);\n    product_of_signs = vget_lane_s32(sign_all, 0);\n\n    return sum_magnitudes * product_of_signs;\n}\n```"}
{"task_id": "SimdBench_123_Neon", "completion": "```cpp\nint prod_signs_simd(const std::vector<int>& arr) {\n    if (arr.empty()) {\n        return -32768;\n    }\n\n    int sum_magnitudes = 0;\n    int product_of_signs = 1;\n\n    int size = arr.size();\n    int i = 0;\n\n    for (; i <= size - 4; i += 4) {\n        int32x4_t vec = vld1q_s32(&arr[i]);\n        int32x4_t abs_vec = vabsq_s32(vec);\n        int32x4_t sign_vec = vmovq_n_s32(1);\n        sign_vec = vbslq_s32(vcltzq_s32(vec), vnegq_s32(sign_vec), sign_vec);\n\n        int32x4_t sum_vec = vaddq_s32(abs_vec, vdupq_n_s32(sum_magnitudes));\n        int32x4_t product_vec = vmulq_s32(sign_vec, vdupq_n_s32(product_of_signs));\n\n        sum_magnitudes = vgetq_lane_s32(sum_vec, 0) + vgetq_lane_s32(sum_vec, 1) +\n                         vgetq_lane_s32(sum_vec, 2) + vgetq_lane_s32(sum_vec, 3);\n        product_of_signs = vgetq_lane_s32(product_vec, 0) * vgetq_lane_s32(product_vec, 1) *\n                           vgetq_lane_s32(product_vec, 2) * vgetq_lane_s32(product_vec, 3);\n    }\n\n    for (; i < size; ++i) {\n        sum_magnitudes += std::abs(arr[i]);\n        product_of_signs *= (arr[i] > 0) ? 1 : ((arr[i] < 0) ? -1 : 0);\n    }\n\n    return sum_magnitudes * product_of_signs;\n}\n```"}
{"task_id": "SimdBench_124_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int> minPath_simd(const std::vector<std::vector<int>>& grid, int k) {\n    // Your implementation here\n}\n```"}
{"task_id": "SimdBench_124_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int> minPath_simd(const std::vector<std::vector<int>>& grid, int k) {\n    // Your Neon SIMD implementation goes here\n}\n```"}
{"task_id": "SimdBench_124_Neon", "completion": "```cpp\nstd::vector<int> minPath_simd(const std::vector<std::vector<int>>& grid, int k) {\n    // Your implementation here\n}\n```"}
{"task_id": "SimdBench_124_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int> minPath_simd(const std::vector<std::vector<int>>& grid, int k) {\n    // Your implementation here\n}\n```"}
{"task_id": "SimdBench_124_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int> minPath_simd(const std::vector<std::vector<int>>& grid, int k) {\n    // Your Neon SIMD implementation goes here\n}\n```"}
{"task_id": "SimdBench_125_Neon", "completion": "```c\n#include <arm_neon.h>\n\nuint64_t digits_simd(uint64_t n) {\n    uint8x16_t v = vld1q_u8((const uint8_t*)&n);\n    uint8x16_t mask = vandq_u8(v, vdupq_n_u8(0x0F));\n    uint8x16_t odd_mask = vandq_u8(mask, vdupq_n_u8(0x01));\n    uint8x16_t even_mask = veorq_u8(odd_mask, vdupq_n_u8(0xFF));\n    uint8x16_t result = vmulq_u8(odd_mask, vdupq_n_u8(1));\n    uint8x16_t sum = vpaddq_u8(result, vdupq_n_u8(0));\n    uint8x8_t sum_lo = vget_low_u8(sum);\n    uint8x8_t sum_hi = vget_high_u8(sum);\n    uint8_t final_sum = vget_lane_u8(sum_lo, 0) + vget_lane_u8(sum_hi, 0);\n    return final_sum;\n}\n```"}
{"task_id": "SimdBench_125_Neon", "completion": "```c\n#include <arm_neon.h>\n\nuint64_t digits_simd(uint64_t n) {\n    uint8x16_t v = vreinterpret_u8_u64(vdupq_n_u64(n));\n    uint8x16_t mask = vmovq_n_u8(0x55); // Mask to isolate odd digits\n    uint8x16_t odd_digits = vandq_u8(v, mask);\n    uint8x16_t zero = vdupq_n_u8(0);\n    uint8x16_t non_zero = vceqq_u8(odd_digits, zero);\n    uint8x16_t count = vaddvq_u8(non_zero);\n    if (count == 0) {\n        return 0;\n    }\n    uint64_t result = 1;\n    for (int i = 0; i < 16; i++) {\n        if ((odd_digits[i] & 0x55) != 0) {\n            result *= (odd_digits[i] & 0x55);\n        }\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_125_Neon", "completion": "```c\n#include <arm_neon.h>\n\nuint64_t digits_simd(uint64_t n) {\n    uint8x8_t v = vreinterpret_u8_u64(vdupq_n_u64(n));\n    uint8x8_t mask = vmovq_n_u8(0x55); // Mask to extract odd digits (0b01010101)\n    uint8x8_t odd_digits = vandq_u8(v, mask);\n    uint8x8_t zero = vdupq_n_u8(0);\n    uint8x8_t non_zero = vneqq_u8(odd_digits, zero);\n\n    uint8x8_t sum = vaddvq_u8(non_zero);\n    uint64_t result = vget_lane_u64(vreinterpret_u64_u8(sum), 0);\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_125_Neon", "completion": "```c\n#include <arm_neon.h>\n\nuint64_t digits_simd(uint64_t n) {\n    uint8x16_t v = vreinterpret_u8_u64(vdupq_n_u64(n));\n    uint8x16_t mask = vmovq_n_u8(0x55); // Mask to isolate odd digits\n    uint8x16_t odd_digits = vandq_u8(v, mask);\n    uint8x16_t zero = vdupq_n_u8(0);\n    uint8x16_t non_zero = vceqq_u8(odd_digits, zero);\n    uint8x16_t count_non_zero = vcntq_u8(non_zero);\n    uint64x2_t sum = vreinterpretq_u64_u8(vaddvq_u8(odd_digits));\n    uint64_t result = vgetlane_u64(sum, 0);\n    return count_non_zero != 0 ? result : 0;\n}\n```"}
{"task_id": "SimdBench_125_Neon", "completion": "```cpp\nuint64_t digits_simd(uint64_t n) {\n    uint8x16_t v = vld1q_u8((const uint8_t*)&n);\n    uint8x16_t mask = vmovq_n_u8(0x0F); // Mask to extract last digit\n    uint8x16_t odd_mask = vmovq_n_u8(0x01); // Mask to check if digit is odd\n    uint8x16_t result = vdupq_n_u8(1);\n\n    for (int i = 0; i < 16; i++) {\n        uint8x16_t digit = vandq_u8(v, mask);\n        uint8x16_t is_odd = vandq_u8(digit, odd_mask);\n        uint8x16_t mul_result = vmulq_u8(result, is_odd);\n        result = vmulq_u8(mul_result, digit);\n        v = vshrq_n_u8(v, 4); // Shift right by 4 bits to process next digit\n    }\n\n    uint8x8_t lo = vget_low_u8(result);\n    uint8x8_t hi = vget_high_u8(result);\n    uint8x8_t sum = vadd_u8(lo, hi);\n    uint8x4_t lo4 = vget_low_u8(sum);\n    uint8x4_t hi4 = vget_high_u8(sum);\n    uint8x2_t lo2 = vadd_u8(lo4, hi4);\n    uint8x2_t hi2 = vadd_u8(vget_low_u8(lo2), vget_high_u8(lo2));\n    uint8_t final_result = vget_lane_u8(hi2, 0);\n\n    return final_result;\n}\n```"}
{"task_id": "SimdBench_126_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <cmath>\n#include <vector>\n\nuint64_t sum_squares_simd(const std::vector<float> & lst) {\n    const float32x4_t vone = vdupq_n_f32(1.0f);\n    uint64_t sum = 0;\n\n    size_t n = lst.size();\n    size_t i = 0;\n    for (; i <= n - 4; i += 4) {\n        float32x4_t v = vld1q_f32(&lst[i]);\n        v = vmulq_f32(v, v);\n        v = vrndpq_f32(v);\n        v = vaddq_u32(vreinterpretq_u32_f32(v), vreinterpretq_u32_f32(v));\n        v = vaddq_u32(vreinterpretq_u32_f32(v), vreinterpretq_u32_f32(v));\n        sum += vgetq_lane_u32(vreinterpretq_u32_f32(v), 0);\n        sum += vgetq_lane_u32(vreinterpretq_u32_f32(v), 1);\n        sum += vgetq_lane_u32(vreinterpretq_u32_f32(v), 2);\n        sum += vgetq_lane_u32(vreinterpretq_u32_f32(v), 3);\n    }\n\n    for (; i < n; ++i) {\n        sum += static_cast<uint64_t>(std::ceil(lst[i] * lst[i]));\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_126_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <cmath>\n#include <vector>\n\nuint64_t sum_squares_simd(const std::vector<float> & lst) {\n    const float32x4_t vone = vdupq_n_f32(1.0f);\n    uint64_t sum = 0;\n\n    size_t n = lst.size();\n    size_t i = 0;\n    for (; i <= n - 4; i += 4) {\n        float32x4_t v = vld1q_f32(&lst[i]);\n        v = vmulq_f32(v, v);\n        v = vrndpq_f32(v);\n        v = vaddq_u32(vreinterpret_u32_f32(v), vreinterpret_u32_f32(v));\n        v = vpaddlq_u32(vreinterpret_u32_f32(v));\n        sum += vget_lane_u32(vreinterpret_u32_u64(v), 0);\n    }\n\n    for (; i < n; ++i) {\n        sum += static_cast<uint64_t>(std::ceil(lst[i] * lst[i]));\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_126_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <cmath>\n#include <vector>\n\nuint64_t sum_squares_simd(const std::vector<float> & lst) {\n    const float32x4_t vone = vdupq_n_f32(1.0f);\n    uint64_t sum = 0;\n\n    size_t n = lst.size();\n    size_t i = 0;\n    for (; i <= n - 4; i += 4) {\n        float32x4_t v = vld1q_f32(&lst[i]);\n        v = vmulq_f32(v, v);\n        v = vrndpq_f32(v);\n        v = vaddq_u32(vreinterpret_u32_f32(v), vreinterpret_u32_f32(v));\n        v = vaddq_u32(vreinterpret_u32_f32(v), vreinterpret_u32_f32(v));\n        sum += vgetq_lane_u32(vreinterpret_u32_f32(v), 0);\n        sum += vgetq_lane_u32(vreinterpret_u32_f32(v), 1);\n        sum += vgetq_lane_u32(vreinterpret_u32_f32(v), 2);\n        sum += vgetq_lane_u32(vreinterpret_u32_f32(v), 3);\n    }\n\n    for (; i < n; ++i) {\n        float f = ceil(lst[i]);\n        sum += static_cast<uint64_t>(f * f);\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_126_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <cmath>\n#include <vector>\n\nuint64_t sum_squares_simd(const std::vector<float> & lst) {\n    uint64_t sum = 0;\n    size_t n = lst.size();\n    size_t i = 0;\n\n    // Process elements in chunks of 4\n    for (; i <= n - 4; i += 4) {\n        float32x4_t v = vld1q_f32(&lst[i]);\n        v = vcvtq_u32_f32(v); // Ceiling operation\n        v = vmulq_f32(v, v);\n        uint32x4_t vi = vreinterpretq_u32_f32(v);\n        sum += vaddvq_u32(vi);\n    }\n\n    // Process remaining elements\n    for (; i < n; ++i) {\n        int ceil_val = static_cast<int>(std::ceil(lst[i]));\n        sum += static_cast<uint64_t>(ceil_val * ceil_val);\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_126_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <cmath>\n#include <vector>\n\nuint64_t sum_squares_simd(const std::vector<float> & lst) {\n    const float32x4_t vone = vdupq_n_f32(1.0f);\n    uint64_t sum = 0;\n\n    size_t n = lst.size();\n    size_t i = 0;\n    for (; i <= n - 4; i += 4) {\n        float32x4_t v = vld1q_f32(&lst[i]);\n        v = vmulq_f32(v, v);\n        v = vrndpq_f32(v);\n        v = vaddq_u32(vreinterpret_u32_f32(v), vreinterpret_u32_f32(v));\n        v = vpaddlq_u32(vreinterpret_u32_f32(v));\n        sum += vget_lane_u32(vreinterpret_u32_u64(v), 0);\n    }\n\n    for (; i < n; ++i) {\n        sum += static_cast<uint64_t>(std::ceil(lst[i] * lst[i]));\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_127_Neon", "completion": "```cpp\nint can_arrange_simd(const std::vector<int>& arr) {\n    int size = arr.size();\n    if (size <= 1) {\n        return -1;\n    }\n\n    const int* data = arr.data();\n\n    int idx = -1;\n    for (int i = 1; i < size; ++i) {\n        int32x4_t vec1 = vld1q_s32(data + i - 4);\n        int32x4_t vec2 = vld1q_s32(data + i);\n\n        uint32x4_t cmp = vcgtq_s32(vec1, vec2);\n        uint32x4_t mask = vmovq_n_u32(0xFFFFFFFF);\n        uint32x4_t result = vbicq_u32(mask, cmp);\n\n        if (vgetq_lane_u32(result, 0)) {\n            idx = i - 4;\n            break;\n        }\n        if (vgetq_lane_u32(result, 1)) {\n            idx = i - 3;\n            break;\n        }\n        if (vgetq_lane_u32(result, 2)) {\n            idx = i - 2;\n            break;\n        }\n        if (vgetq_lane_u32(result, 3)) {\n            idx = i - 1;\n            break;\n        }\n    }\n\n    return idx;\n}\n```"}
{"task_id": "SimdBench_127_Neon", "completion": "```cpp\nint can_arrange_simd(const std::vector<int>& arr) {\n    int n = arr.size();\n    if (n <= 1) {\n        return -1;\n    }\n\n    const int* data = arr.data();\n    int result = -1;\n\n    for (int i = 1; i < n; ++i) {\n        int32x4_t v1 = vld1q_s32(data + i - 1);\n        int32x4_t v2 = vld1q_s32(data + i);\n\n        uint32x4_t cmp = vcgtq_s32(v1, v2);\n        int mask = vaddvq_u32(cmp);\n\n        if (mask) {\n            result = i - 1;\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_127_Neon", "completion": "```cpp\nint can_arrange_simd(const std::vector<int>& arr) {\n    int size = arr.size();\n    if (size <= 1) {\n        return -1;\n    }\n\n    const int* data = arr.data();\n\n    int idx = -1;\n    for (int i = 1; i < size; ++i) {\n        int32x4_t vec1 = vld1q_s32(data + i - 4);\n        int32x4_t vec2 = vld1q_s32(data + i);\n\n        uint32x4_t cmp = vcgtq_s32(vec1, vec2);\n        int mask = vaddvq_u32(cmp);\n\n        if (mask != 0) {\n            idx = i - 4 + __builtin_clz(mask);\n            break;\n        }\n    }\n\n    return idx;\n}\n```"}
{"task_id": "SimdBench_127_Neon", "completion": "```cpp\nint can_arrange_simd(const std::vector<int>& arr) {\n    int size = arr.size();\n    if (size <= 1) {\n        return -1;\n    }\n\n    const int* data = arr.data();\n\n    int result = -1;\n\n    for (int i = 1; i < size; ++i) {\n        int32x4_t vec1 = vld1q_s32(data + i - 4);\n        int32x4_t vec2 = vld1q_s32(data + i);\n\n        uint32x4_t cmp = vcgtq_s32(vec1, vec2);\n        int mask = vaddvq_u32(cmp);\n\n        if (mask != 0) {\n            result = i - 4 + __builtin_clz(mask);\n            break;\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_127_Neon", "completion": "```cpp\nint can_arrange_simd(const std::vector<int>& arr) {\n    int size = arr.size();\n    if (size <= 1) {\n        return -1;\n    }\n\n    const int* data = arr.data();\n\n    int idx = -1;\n    for (int i = 1; i < size; ++i) {\n        int32x4_t vec1 = vld1q_s32(data + i - 4);\n        int32x4_t vec2 = vld1q_s32(data + i);\n\n        uint32x4_t cmp = vcgtq_s32(vec1, vec2);\n        uint32x4_t mask = vmovq_n_u32(0xFFFFFFFF);\n        uint32x4_t result = vbicq_u32(mask, cmp);\n\n        if (vgetq_lane_u32(result, 0)) {\n            idx = i - 4;\n            break;\n        }\n        if (vgetq_lane_u32(result, 1)) {\n            idx = i - 3;\n            break;\n        }\n        if (vgetq_lane_u32(result, 2)) {\n            idx = i - 2;\n            break;\n        }\n        if (vgetq_lane_u32(result, 3)) {\n            idx = i - 1;\n            break;\n        }\n    }\n\n    return idx;\n}\n```"}
{"task_id": "SimdBench_128_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <limits>\n\nstd::vector<int> largest_smallest_integers_simd(const std::vector<int>& lst) {\n    if (lst.empty()) {\n        return {0, 0};\n    }\n\n    int32x4_t min_pos = vdupq_n_s32(std::numeric_limits<int>::max());\n    int32x4_t max_neg = vdupq_n_s32(std::numeric_limits<int>::min());\n\n    size_t i = 0;\n    for (; i + 4 <= lst.size(); i += 4) {\n        int32x4_t vec = vld1q_s32(&lst[i]);\n        int32x4_t pos_mask = vcgtq_s32(vec, vdupq_n_s32(0));\n        int32x4_t neg_mask = vcltq_s32(vec, vdupq_n_s32(0));\n\n        min_pos = vminq_s32(min_pos, vbslq_s32(pos_mask, vec, min_pos));\n        max_neg = vmaxq_s32(max_neg, vbslq_s32(neg_mask, vec, max_neg));\n    }\n\n    for (; i < lst.size(); ++i) {\n        if (lst[i] > 0 && lst[i] < vgetq_lane_s32(min_pos, 0)) {\n            vsetq_lane_s32(lst[i], min_pos, 0);\n        }\n        if (lst[i] < 0 && lst[i] > vgetq_lane_s32(max_neg, 0)) {\n            vsetq_lane_s32(lst[i], max_neg, 0);\n        }\n    }\n\n    return {vgetq_lane_s32(max_neg, 0), vgetq_lane_s32(min_pos, 0)};\n}\n```"}
{"task_id": "SimdBench_128_Neon", "completion": "```cpp\nstd::vector<int> largest_smallest_integers_simd(const std::vector<int>& lst) {\n    if (lst.empty()) {\n        return {0, 0};\n    }\n\n    int32x4_t min_pos = vdupq_n_s32(INT_MAX);\n    int32x4_t max_neg = vdupq_n_s32(INT_MIN);\n\n    size_t n = lst.size();\n    size_t i = 0;\n\n    // Process elements in chunks of 4\n    while (i + 4 <= n) {\n        int32x4_t vec = vld1q_s32(&lst[i]);\n        int32x4_t pos_mask = vcgtq_s32(vec, vdupq_n_s32(0));\n        int32x4_t neg_mask = vcltq_s32(vec, vdupq_n_s32(0));\n\n        min_pos = vminq_s32(min_pos, vbslq_s32(pos_mask, vec, min_pos));\n        max_neg = vmaxq_s32(max_neg, vbslq_s32(neg_mask, vec, max_neg));\n\n        i += 4;\n    }\n\n    // Handle remaining elements\n    while (i < n) {\n        int val = lst[i];\n        if (val > 0) {\n            min_pos = vmin_s32(min_pos, val);\n        } else if (val < 0) {\n            max_neg = vmax_s32(max_neg, val);\n        }\n        i++;\n    }\n\n    int min_val = vgetq_lane_s32(min_pos, 0);\n    int max_val = vgetq_lane_s32(max_neg, 0);\n\n    return {max_val, min_val};\n}\n```"}
{"task_id": "SimdBench_128_Neon", "completion": "```cpp\nstd::vector<int> largest_smallest_integers_simd(const std::vector<int>& lst) {\n    if (lst.empty()) {\n        return {0, 0};\n    }\n\n    int32x4_t min_pos = vdupq_n_s32(INT_MAX);\n    int32x4_t max_neg = vdupq_n_s32(INT_MIN);\n\n    size_t n = lst.size();\n    size_t i = 0;\n\n    // Process elements in chunks of 4\n    while (i + 4 <= n) {\n        int32x4_t vec = vld1q_s32(&lst[i]);\n        int32x4_t pos_mask = vcgtq_s32(vec, vdupq_n_s32(0));\n        int32x4_t neg_mask = vcltq_s32(vec, vdupq_n_s32(0));\n\n        min_pos = vminq_s32(min_pos, vbslq_s32(pos_mask, vec, min_pos));\n        max_neg = vmaxq_s32(max_neg, vbslq_s32(neg_mask, vec, max_neg));\n\n        i += 4;\n    }\n\n    // Process remaining elements\n    for (; i < n; ++i) {\n        int val = lst[i];\n        if (val > 0) {\n            min_pos = vmin_s32(min_pos, val);\n        } else if (val < 0) {\n            max_neg = vmax_s32(max_neg, val);\n        }\n    }\n\n    return {max_neg[0], min_pos[0]};\n}\n```"}
{"task_id": "SimdBench_128_Neon", "completion": "```cpp\nstd::vector<int> largest_smallest_integers_simd(const std::vector<int>& lst) {\n    if (lst.empty()) {\n        return {0, 0};\n    }\n\n    int32x4_t min_pos = vdupq_n_s32(INT_MAX);\n    int32x4_t max_neg = vdupq_n_s32(INT_MIN);\n\n    size_t n = lst.size();\n    size_t i = 0;\n\n    // Process elements in chunks of 4\n    while (i + 4 <= n) {\n        int32x4_t vec = vld1q_s32(&lst[i]);\n        int32x4_t pos_mask = vcgtq_s32(vec, vdupq_n_s32(0));\n        int32x4_t neg_mask = vcltq_s32(vec, vdupq_n_s32(0));\n\n        min_pos = vminq_s32(min_pos, vbslq_s32(pos_mask, vec, min_pos));\n        max_neg = vmaxq_s32(max_neg, vbslq_s32(neg_mask, vec, max_neg));\n\n        i += 4;\n    }\n\n    // Process remaining elements\n    for (; i < n; ++i) {\n        int val = lst[i];\n        if (val > 0) {\n            min_pos = vmin_s32(min_pos, val);\n        } else if (val < 0) {\n            max_neg = vmax_s32(max_neg, val);\n        }\n    }\n\n    return {max_neg[0], min_pos[0]};\n}\n```"}
{"task_id": "SimdBench_128_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int> largest_smallest_integers_simd(const std::vector<int>& lst) {\n    if (lst.empty()) {\n        return {0, 0};\n    }\n\n    int32x4_t min_pos = vdupq_n_s32(INT_MAX);\n    int32x4_t max_neg = vdupq_n_s32(INT_MIN);\n\n    size_t n = lst.size();\n    size_t i = 0;\n\n    while (i + 4 <= n) {\n        int32x4_t vec = vld1q_s32(&lst[i]);\n        int32x4_t pos_mask = vcgtq_s32(vec, vdupq_n_s32(0));\n        int32x4_t neg_mask = vcltq_s32(vec, vdupq_n_s32(0));\n\n        min_pos = vminq_s32(min_pos, vbslq_s32(pos_mask, vec, min_pos));\n        max_neg = vmaxq_s32(max_neg, vbslq_s32(neg_mask, vec, max_neg));\n\n        i += 4;\n    }\n\n    while (i < n) {\n        int val = lst[i];\n        if (val > 0 && val < vgetq_lane_s32(min_pos, 0)) {\n            vsetvl_e32_t vl = vsetvl_e32_t(1);\n            min_pos = vsetq_lane_s32(val, min_pos, 0);\n        }\n        if (val < 0 && val > vgetq_lane_s32(max_neg, 0)) {\n            vsetvl_e32_t vl = vsetvl_e32_t(1);\n            max_neg = vsetq_lane_s32(val, max_neg, 0);\n        }\n        i++;\n    }\n\n    int min_val = vgetq_lane_s32(min_pos, 0);\n    int max_val = vgetq_lane_s32(max_neg, 0);\n\n    return {max_val, min_val};\n}\n```"}
{"task_id": "SimdBench_129_Neon", "completion": "```c\n#include <arm_neon.h>\n\nuint64_t special_factorial_simd(uint64_t n) {\n    uint64x2_t result = vdupq_n_u64(1);\n    uint64x2_t count = vdupq_n_u64(1);\n\n    while (vget_lane_u64(count, 0) <= n) {\n        uint64x2_t temp = vmulq_u64(result, count);\n        result = temp;\n        count = vaddq_u64(count, vdupq_n_u64(1));\n    }\n\n    return vget_lane_u64(result, 0);\n}\n```"}
{"task_id": "SimdBench_129_Neon", "completion": "```c\n#include <arm_neon.h>\n\nuint64_t special_factorial_simd(uint64_t n) {\n    uint64x2_t result = vdupq_n_u64(1);\n    uint64x2_t count = vdupq_n_u64(1);\n\n    while (vgetq_lane_u64(count, 0) <= n || vgetq_lane_u64(count, 1) <= n) {\n        uint64x2_t temp = vmulq_u64(result, count);\n        result = temp;\n        count = vaddq_u64(count, vdupq_n_u64(1));\n    }\n\n    return vgetq_lane_u64(result, 0) * vgetq_lane_u64(result, 1);\n}\n```"}
{"task_id": "SimdBench_129_Neon", "completion": "```c\n#include <arm_neon.h>\n\nuint64_t special_factorial_simd(uint64_t n) {\n    uint64x2_t result = vdupq_n_u64(1);\n    uint64x2_t count = vdupq_n_u64(1);\n\n    while (vgetq_lane_u64(count, 0) <= n || vgetq_lane_u64(count, 1) <= n) {\n        uint64x2_t temp = vmulq_u64(result, vld1q_u64(&count));\n        result = temp;\n        count = vaddq_u64(count, vdupq_n_u64(1));\n    }\n\n    return vgetq_lane_u64(result, 0) * vgetq_lane_u64(result, 1);\n}\n```"}
{"task_id": "SimdBench_129_Neon", "completion": "```c\n#include <arm_neon.h>\n\nuint64_t special_factorial_simd(uint64_t n) {\n    uint64x2_t result = vdupq_n_u64(1);\n    for (uint64_t i = 1; i <= n; i++) {\n        uint64x2_t factor = vdupq_n_u64(i);\n        result = vmulq_u64(result, factor);\n    }\n    return vgetq_lane_u64(result, 0);\n}\n```"}
{"task_id": "SimdBench_129_Neon", "completion": "```c\n#include <arm_neon.h>\n\nuint64_t special_factorial_simd(uint64_t n) {\n    uint64x2_t result = vdupq_n_u64(1);\n    uint64x2_t count = vdupq_n_u64(1);\n\n    while (vgetq_lane_u64(count, 0) <= n || vgetq_lane_u64(count, 1) <= n) {\n        uint64x2_t temp = vmulq_u64(result, count);\n        result = temp;\n        count = vaddq_u64(count, vdupq_n_u64(1));\n    }\n\n    return vgetq_lane_u64(result, 0) * vgetq_lane_u64(result, 1);\n}\n```"}
{"task_id": "SimdBench_130_Neon", "completion": "```cpp\nint sum_squares_simd(const std::vector<int> & lst){\n    int sum = 0;\n    int n = lst.size();\n    int i = 0;\n\n    // Process elements in groups of 8\n    for (; i <= n - 8; i += 8) {\n        int32x4_t v1 = vld1q_s32(&lst[i]);\n        int32x4_t v2 = vld1q_s32(&lst[i + 4]);\n\n        int32x4_t v3 = vmulq_n_s32(v1, v1);\n        int32x4_t v4 = vmulq_n_s32(v2, v2);\n\n        int32x4_t v5 = vdupq_n_s32(0);\n        int32x4_t v6 = vdupq_n_s32(0);\n\n        v5 = vaddq_s32(v5, v3);\n        v6 = vaddq_s32(v6, v4);\n\n        sum += vgetq_lane_s32(v5, 0) + vgetq_lane_s32(v5, 1) +\n               vgetq_lane_s32(v5, 2) + vgetq_lane_s32(v5, 3) +\n               vgetq_lane_s32(v6, 0) + vgetq_lane_s32(v6, 1) +\n               vgetq_lane_s32(v6, 2) + vgetq_lane_s32(v6, 3);\n    }\n\n    // Process remaining elements\n    for (; i < n; ++i) {\n        if (i % 3 == 0) {\n            sum += lst[i] * lst[i];\n        } else if (i % 4 == 0) {\n            sum += lst[i] * lst[i] * lst[i];\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_130_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nint sum_squares_simd(const std::vector<int> & lst) {\n    int sum = 0;\n    size_t n = lst.size();\n    size_t i = 0;\n\n    // Process elements in chunks of 8\n    for (; i <= n - 8; i += 8) {\n        int32x4_t v1 = vld1q_s32(&lst[i]);\n        int32x4_t v2 = vld1q_s32(&lst[i + 4]);\n\n        int32x4_t v3 = vmulq_n_s32(v1, v1);\n        int32x4_t v4 = vmulq_n_s32(v2, v2);\n\n        int32x4_t v5 = vdupq_n_s32(0);\n        int32x4_t v6 = vdupq_n_s32(0);\n\n        uint32x4_t mask1 = vandq_u32(vreinterpretq_u32_s32(vcltq_s32(vld1q_s32(&i), vdupq_n_s32(24))));\n        uint32x4_t mask2 = vandq_u32(vreinterpretq_u32_s32(vcltq_s32(vaddq_s32(vld1q_s32(&i), vdupq_n_s32(4)), vdupq_n_s32(24))));\n\n        v3 = vbslq_s32(mask1, v3, v5);\n        v4 = vbslq_s32(mask2, v4, v6);\n\n        v3 = vaddq_s32(v3, v4);\n        v3 = vpaddq_s32(v3, v3);\n        v3 = vpaddlq_s32(v3);\n\n        sum += vget_lane_s32(v3, 0);\n    }\n\n    // Process remaining elements\n    for (; i < n; ++i) {\n        if (i % 3 == 0) {\n            sum += lst[i] * lst[i];\n        } else if (i % 4 == 0) {\n            sum += lst[i] * lst[i] * lst[i];\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_130_Neon", "completion": "```cpp\nint sum_squares_simd(const std::vector<int> & lst) {\n    int sum = 0;\n    size_t n = lst.size();\n    size_t i = 0;\n\n    // Process elements in chunks of 8\n    for (; i <= n - 8; i += 8) {\n        int32x4_t v1 = vld1q_s32(&lst[i]);\n        int32x4_t v2 = vld1q_s32(&lst[i + 4]);\n\n        int32x4_t v3 = vmulq_n_s32(v1, v1);\n        int32x4_t v4 = vmulq_n_s32(v2, v2);\n\n        int32x4_t v5 = vdupq_n_s32(0);\n        int32x4_t v6 = vdupq_n_s32(0);\n\n        uint32x4_t mask1 = vandq_u32(vreinterpretq_u32_s32(vcltq_s32(vcntq_u32(vreinterpretq_u32_s32(vandq_u32(vreinterpretq_u32_s32(vceqq_s32(vmodq_s32(vreinterpretq_s32_u32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s32(vreinterpretq_u32_s3"}
{"task_id": "SimdBench_130_Neon", "completion": "```cpp\nint sum_squares_simd(const std::vector<int>& lst) {\n    int sum = 0;\n    size_t n = lst.size();\n    size_t i = 0;\n\n    // Process elements in chunks of 8\n    for (; i <= n - 8; i += 8) {\n        int32x4_t v1 = vld1q_s32(&lst[i]);\n        int32x4_t v2 = vld1q_s32(&lst[i + 4]);\n\n        int32x4_t v1_mask = vmovq_n_s32(0);\n        int32x4_t v2_mask = vmovq_n_s32(0);\n\n        // Create mask for elements at indices multiple of 3\n        v1_mask = vorrq_s32(v1_mask, vceqq_s32(vmulq_n_s32(vld1q_dup_s32(&i), vdupq_n_s32(3)), vdupq_n_s32(i)));\n        v2_mask = vorrq_s32(v2_mask, vceqq_s32(vmulq_n_s32(vld1q_dup_s32(&i + 4), vdupq_n_s32(3)), vdupq_n_s32(i + 4)));\n\n        // Create mask for elements at indices multiple of 4 but not multiple of 3\n        int32x4_t v1_mask_4 = vorrq_s32(v1_mask, vceqq_s32(vmulq_n_s32(vld1q_dup_s32(&i), vdupq_n_s32(4)), vdupq_n_s32(i)));\n        int32x4_t v2_mask_4 = vorrq_s32(v2_mask, vceqq_s32(vmulq_n_s32(vld1q_dup_s32(&i + 4), vdupq_n_s32(4)), vdupq_n_s32(i + 4)));\n\n        v1_mask_4 = vbicq_s32(v1_mask_4, v1_mask);\n\n        // Square elements at indices multiple of 3\n        v1 = vmulq_s32(v1, v1);\n        v2 = vmulq_s32(v2, v2);\n\n        // Cube elements at indices multiple of 4 but not multiple of 3\n        v1 = vmulq_s32(v1, vmulq_s32(v1, v1));\n        v2 = vmulq_s32(v2, vmulq_s32(v2, v2));\n\n        // Apply masks\n        v1 = vbslq_s32(v1_mask, v1, vdupq_n_s32(0));\n        v2 = vbslq_s32(v2_mask_4, v2, vdupq_n_s32(0));\n\n        // Sum the results\n        int32x4_t sum_vec = vaddq_s32(v1, v2);\n        int32x2_t sum_low = vpadd_s32(vget_low_s32(sum_vec), vget_high_s32(sum_vec));\n        int32x2_t sum_low_high = vpadd_s32(sum_low, sum_low);\n        sum += vget_lane_s32(sum_low_high, 0);\n    }\n\n    // Process remaining elements\n    for (; i < n; ++i) {\n        if (i % 3 == 0) {\n            sum += lst[i] * lst[i];\n        } else if (i % 4 == 0) {\n            sum += lst[i] * lst[i] * lst[i];\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_130_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nint sum_squares_simd(const std::vector<int> & lst) {\n    int sum = 0;\n    size_t n = lst.size();\n    size_t i = 0;\n\n    // Process elements in chunks of 8\n    for (; i <= n - 8; i += 8) {\n        int32x4_t v1 = vld1q_s32(&lst[i]);\n        int32x4_t v2 = vld1q_s32(&lst[i + 4]);\n\n        int32x4_t v1_mask = vandq_u32(vdupq_n_u32(0x00000003), vmovq_n_u32(i));\n        int32x4_t v2_mask = vandq_u32(vdupq_n_u32(0x00000003), vmovq_n_u32(i + 4));\n\n        int32x4_t v1_square = vmulq_s32(v1, v1);\n        int32x4_t v2_square = vmulq_s32(v2, v2);\n\n        int32x4_t v1_cube = vmulq_s32(vmulq_s32(v1, v1), v1);\n        int32x4_t v2_cube = vmulq_s32(vmulq_s32(v2, v2), v2);\n\n        int32x4_t v1_result = vbslq_s32(v1_mask, v1_square, v1_cube);\n        int32x4_t v2_result = vbslq_s32(v2_mask, v2_square, v2_cube);\n\n        int32x4_t v_sum = vaddq_s32(v1_result, v2_result);\n        sum += vgetq_lane_s32(v_sum, 0) + vgetq_lane_s32(v_sum, 1) +\n               vgetq_lane_s32(v_sum, 2) + vgetq_lane_s32(v_sum, 3);\n    }\n\n    // Process remaining elements\n    for (; i < n; ++i) {\n        if (i % 3 == 0) {\n            sum += lst[i] * lst[i];\n        } else if (i % 4 == 0) {\n            sum += lst[i] * lst[i] * lst[i];\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_131_Neon", "completion": "```cpp\nint specialFilter_simd(const std::vector<int>& nums) {\n    int count = 0;\n    int size = nums.size();\n    int* data = const_cast<int*>(nums.data());\n\n    for (int i = 0; i <= size - 8; i += 8) {\n        int32x4_t v1 = vld1q_s32(data + i);\n        int32x4_t v2 = vld1q_s32(data + i + 4);\n\n        uint32x4_t mask1 = vcgtq_s32(v1, vdupq_n_s32(10));\n        uint32x4_t mask2 = vcgtq_s32(v2, vdupq_n_s32(10));\n\n        uint32x4_t first_digit_mask1 = vmovemask_u32(vandq_u32(mask1, vcltq_s32(v1, vdupq_n_s32(100))));\n        uint32x4_t first_digit_mask2 = vmovemask_u32(vandq_u32(mask2, vcltq_s32(v2, vdupq_n_s32(100))));\n\n        uint32x4_t last_digit_mask1 = vmovemask_u32(vandq_u32(mask1, vceqq_s32(vmodq_s32(v1, vdupq_n_s32(10)), vdupq_n_s32(1))));\n        uint32x4_t last_digit_mask2 = vmovemask_u32(vandq_u32(mask2, vceqq_s32(vmodq_s32(v2, vdupq_n_s32(10)), vdupq_n_s32(1))));\n\n        count += __builtin_popcount(first_digit_mask1 & last_digit_mask1);\n        count += __builtin_popcount(first_digit_mask2 & last_digit_mask2);\n    }\n\n    // Handle remaining elements\n    for (int i = size - size % 8; i < size; ++i) {\n        if (nums[i] > 10 && (nums[i] / 10) % 2 != 0 && nums[i] % 2 != 0) {\n            count++;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_131_Neon", "completion": "```cpp\nint specialFilter_simd(const std::vector<int>& nums) {\n    int count = 0;\n    int size = nums.size();\n    int* data = const_cast<int*>(nums.data());\n\n    for (int i = 0; i <= size - 8; i += 8) {\n        int32x4_t v1 = vld1q_s32(data + i);\n        int32x4_t v2 = vld1q_s32(data + i + 4);\n\n        uint32x4_t mask1 = vcgtq_s32(v1, vdupq_n_s32(10));\n        uint32x4_t mask2 = vcgtq_s32(v2, vdupq_n_s32(10));\n\n        uint32x4_t first_digit_mask1 = vmovemask_u32(vandq_u32(mask1, vcltq_s32(v1, vdupq_n_s32(100))));\n        uint32x4_t first_digit_mask2 = vmovemask_u32(vandq_u32(mask2, vcltq_s32(v2, vdupq_n_s32(100))));\n\n        uint32x4_t last_digit_mask1 = vmovemask_u32(vandq_u32(mask1, vceqq_s32(vmodq_s32(v1, vdupq_n_s32(10)), vdupq_n_s32(1))));\n        uint32x4_t last_digit_mask2 = vmovemask_u32(vandq_u32(mask2, vceqq_s32(vmodq_s32(v2, vdupq_n_s32(10)), vdupq_n_s32(1))));\n\n        count += __builtin_popcount(first_digit_mask1 & last_digit_mask1);\n        count += __builtin_popcount(first_digit_mask2 & last_digit_mask2);\n    }\n\n    // Handle remaining elements\n    for (int i = size - size % 8; i < size; ++i) {\n        if (nums[i] > 10 && (nums[i] / 10) % 2 != 0 && nums[i] % 2 != 0) {\n            count++;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_131_Neon", "completion": "```cpp\nint specialFilter_simd(const std::vector<int>& nums) {\n    int count = 0;\n    int size = nums.size();\n    int* data = const_cast<int*>(nums.data());\n\n    for (int i = 0; i <= size - 8; i += 8) {\n        int32x4_t v1 = vld1q_s32(data + i);\n        int32x4_t v2 = vld1q_s32(data + i + 4);\n\n        uint32x4_t mask1 = vcgtq_s32(v1, vdupq_n_s32(10));\n        uint32x4_t mask2 = vcgtq_s32(v2, vdupq_n_s32(10));\n\n        uint32x4_t first_digit_mask1 = vmovemask_u32(vandq_u32(mask1, vcltq_s32(v1, vdupq_n_s32(100))));\n        uint32x4_t first_digit_mask2 = vmovemask_u32(vandq_u32(mask2, vcltq_s32(v2, vdupq_n_s32(100))));\n\n        uint32x4_t last_digit_mask1 = vmovemask_u32(vandq_u32(mask1, vceqq_s32(vmodq_s32(v1, vdupq_n_s32(10)), vdupq_n_s32(1))));\n        uint32x4_t last_digit_mask2 = vmovemask_u32(vandq_u32(mask2, vceqq_s32(vmodq_s32(v2, vdupq_n_s32(10)), vdupq_n_s32(1))));\n\n        count += __builtin_popcount(first_digit_mask1 & last_digit_mask1);\n        count += __builtin_popcount(first_digit_mask2 & last_digit_mask2);\n    }\n\n    // Handle remaining elements\n    for (int i = size - size % 8; i < size; ++i) {\n        if (nums[i] > 10 && (nums[i] / 10) % 2 != 0 && nums[i] % 2 != 0) {\n            count++;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_131_Neon", "completion": "```cpp\nint specialFilter_simd(const std::vector<int>& nums) {\n    int count = 0;\n    int size = nums.size();\n    const int* data = nums.data();\n\n    for (int i = 0; i <= size - 8; i += 8) {\n        int32x4_t v1 = vld1q_s32(data + i);\n        int32x4_t v2 = vld1q_s32(data + i + 4);\n\n        uint32x4_t mask1 = vcgtq_s32(v1, vdupq_n_s32(10));\n        uint32x4_t mask2 = vcgtq_s32(v2, vdupq_n_s32(10));\n\n        uint32x4_t first_digit_mask1 = vmovemask_u32(vandq_u32(mask1, vcltq_s32(v1, vdupq_n_s32(100))));\n        uint32x4_t first_digit_mask2 = vmovemask_u32(vandq_u32(mask2, vcltq_s32(v2, vdupq_n_s32(100))));\n\n        uint32x4_t last_digit_mask1 = vmovemask_u32(vandq_u32(mask1, vceqq_s32(vmodq_s32(v1, vdupq_n_s32(10)), vdupq_n_s32(1))));\n        uint32x4_t last_digit_mask2 = vmovemask_u32(vandq_u32(mask2, vceqq_s32(vmodq_s32(v2, vdupq_n_s32(10)), vdupq_n_s32(1))));\n\n        count += __builtin_popcount(first_digit_mask1 & last_digit_mask1);\n        count += __builtin_popcount(first_digit_mask2 & last_digit_mask2);\n    }\n\n    // Handle remaining elements\n    for (int i = size - size % 8; i < size; ++i) {\n        if (nums[i] > 10 && (nums[i] / 10) % 2 != 0 && nums[i] % 2 != 0) {\n            count++;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_131_Neon", "completion": "```cpp\nint specialFilter_simd(const std::vector<int>& nums) {\n    int count = 0;\n    int size = nums.size();\n    const int* data = nums.data();\n\n    for (int i = 0; i <= size - 8; i += 8) {\n        int32x4_t v1 = vld1q_s32(data + i);\n        int32x4_t v2 = vld1q_s32(data + i + 4);\n\n        uint32x4_t mask1 = vcgtq_s32(v1, vdupq_n_s32(10));\n        uint32x4_t mask2 = vcgtq_s32(v2, vdupq_n_s32(10));\n\n        uint32x4_t first_digit_mask1 = vmovemask_u32(vandq_u32(mask1, vcltq_s32(v1, vdupq_n_s32(100))));\n        uint32x4_t first_digit_mask2 = vmovemask_u32(vandq_u32(mask2, vcltq_s32(v2, vdupq_n_s32(100))));\n\n        uint32x4_t last_digit_mask1 = vmovemask_u32(vandq_u32(mask1, vceqq_s32(vmodq_s32(v1, vdupq_n_s32(10)), vdupq_n_s32(1))));\n        uint32x4_t last_digit_mask2 = vmovemask_u32(vandq_u32(mask2, vceqq_s32(vmodq_s32(v2, vdupq_n_s32(10)), vdupq_n_s32(1))));\n\n        count += __builtin_popcount(first_digit_mask1 & last_digit_mask1);\n        count += __builtin_popcount(first_digit_mask2 & last_digit_mask2);\n    }\n\n    // Handle remaining elements\n    for (int i = size - size % 8; i < size; ++i) {\n        if (nums[i] > 10 && (nums[i] / 10) % 2 != 0 && nums[i] % 2 != 0) {\n            count++;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_132_Neon", "completion": "```cpp\nuint64_t get_max_triples_simd(uint64_t n) {\n    uint64x2_t v_n = vmovq_n_u64(n);\n    uint64x2_t v_one = vmovq_n_u64(1);\n    uint64x2_t v_three = vmovq_n_u64(3);\n\n    uint64x2_t v_a = vmulq_u64(v_n, v_n);\n    v_a = vsubq_u64(v_a, v_n);\n    v_a = vaddq_u64(v_a, v_one);\n\n    uint64x2_t v_sum = vdupq_n_u64(0);\n    uint64x2_t v_count = vdupq_n_u64(0);\n\n    for (uint64_t i = 0; i < n - 2; i += 2) {\n        uint64x2_t v_i = vmovq_n_u64(i + 1);\n        uint64x2_t v_j = vmovq_n_u64(i + 2);\n        uint64x2_t v_k = vmovq_n_u64(i + 3);\n\n        uint64x2_t v_ai = vld1q_u64(&v_a[0]);\n        uint64x2_t v_aj = vld1q_u64(&v_a[1]);\n\n        uint64x2_t v_sum_ij = vaddq_u64(v_ai, v_aj);\n        uint64x2_t v_sum_ijk = vaddq_u64(v_sum_ij, v_k);\n\n        uint64x2_t v_mod = vmodq_u64(v_sum_ijk, v_three);\n        uint64x2_t v_eq_zero = veorq_u64(v_mod, v_zero);\n\n        uint64x2_t v_add_count = vandq_u64(v_eq_zero, v_one);\n        v_count = vaddq_u64(v_count, v_add_count);\n    }\n\n    return vgetq_lane_u64(v_count, 0);\n}\n```"}
{"task_id": "SimdBench_132_Neon", "completion": "```cpp\nuint64_t get_max_triples_simd(uint64_t n) {\n    uint64x2_t v_n = vmovq_n_u64(n);\n    uint64x2_t v_i = vmovq_n_u64(1);\n    uint64x2_t v_j = vmovq_n_u64(2);\n    uint64x2_t v_k = vmovq_n_u64(3);\n\n    uint64x2_t v_a_i = vmulq_u64(v_i, v_i);\n    v_a_i = vsubq_u64(v_a_i, v_i);\n    v_a_i = vaddq_u64(v_a_i, v_one);\n\n    uint64x2_t v_a_j = vmulq_u64(v_j, v_j);\n    v_a_j = vsubq_u64(v_a_j, v_j);\n    v_a_j = vaddq_u64(v_a_j, v_one);\n\n    uint64x2_t v_a_k = vmulq_u64(v_k, v_k);\n    v_a_k = vsubq_u64(v_a_k, v_k);\n    v_a_k = vaddq_u64(v_a_k, v_one);\n\n    uint64x2_t v_sum = vaddq_u64(v_a_i, v_a_j);\n    v_sum = vaddq_u64(v_sum, v_a_k);\n\n    uint64x2_t v_mod = veorq_u64(v_sum, vmovq_n_u64(0x2));\n\n    uint64_t count = vcntq_u8(vreinterpretq_u8_u64(v_mod));\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_132_Neon", "completion": "```c\n#include <arm_neon.h>\n\nuint64_t get_max_triples_simd(uint64_t n) {\n    uint64x2_t count_mod_3 = vdupq_n_u64(0);\n    uint64x2_t sum_mod_3 = vdupq_n_u64(0);\n\n    for (uint64_t i = 1; i <= n; i++) {\n        uint64_t val = i * i - i + 1;\n        uint64x2_t val_vec = vld1q_lane_u64(&val, val_vec, 0);\n        uint64x2_t mod_3 = vmulq_n_u64(val_vec, 3);\n        uint64x2_t eq_mod_3 = vceqq_u64(mod_3, val_vec);\n        uint64x2_t add_count = vaddq_u64(count_mod_3, eq_mod_3);\n        uint64x2_t add_sum = vmlaq_u64(sum_mod_3, eq_mod_3, val_vec);\n        count_mod_3 = add_count;\n        sum_mod_3 = add_sum;\n    }\n\n    uint64_t total_count = vgetq_lane_u64(count_mod_3, 0) + vgetq_lane_u64(count_mod_3, 1);\n    return total_count / 3;\n}\n```"}
{"task_id": "SimdBench_132_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nuint64_t get_max_triples_simd(uint64_t n) {\n    uint64x2_t count_mod_3 = vdupq_n_u64(0);\n    uint64x2_t sum_mod_3 = vdupq_n_u64(0);\n\n    for (uint64_t i = 1; i <= n; ++i) {\n        uint64_t val = i * i - i + 1;\n        uint64x2_t val_vec = vld1q_lane_u64(&val, val_vec, 0);\n        uint64x2_t mod_3 = vmulq_n_u64(val_vec, 3);\n        uint64x2_t mask = vceqq_u64(mod_3, val_vec);\n        count_mod_3 = vaddq_u64(count_mod_3, mask);\n        sum_mod_3 = vaddq_u64(sum_mod_3, val_vec);\n    }\n\n    uint64_t total_count = vgetq_lane_u64(count_mod_3, 0) + vgetq_lane_u64(count_mod_3, 1);\n    uint64_t total_sum = vgetq_lane_u64(sum_mod_3, 0) + vgetq_lane_u64(sum_mod_3, 1);\n\n    return total_count * (total_count - 1) / 2 - total_sum / 3;\n}\n```"}
{"task_id": "SimdBench_132_Neon", "completion": "```c\n#include <arm_neon.h>\n\nuint64_t get_max_triples_simd(uint64_t n) {\n    uint64x2_t count_mod_3 = vdupq_n_u64(0);\n    uint64x2_t sum_mod_3 = vdupq_n_u64(0);\n\n    for (uint64_t i = 1; i <= n; i++) {\n        uint64_t val = i * i - i + 1;\n        uint64x2_t val_vec = vld1q_lane_u64(&val, val_vec, 0);\n        uint64x2_t mod_3 = vmulq_n_u64(val_vec, 3);\n        uint64x2_t eq_mod_3 = vceqq_u64(mod_3, val_vec);\n        uint64x2_t count_eq_mod_3 = vreinterpretq_u64_u8(vaddvq_u8(vreinterpretq_u8_u64(eq_mod_3)));\n        count_mod_3 = vaddq_u64(count_mod_3, count_eq_mod_3);\n\n        sum_mod_3 = vaddq_u64(sum_mod_3, val_vec);\n        uint64x2_t sum_mod_3_div_3 = vmulq_n_u64(sum_mod_3, 3);\n        uint64x2_t eq_sum_mod_3 = vceqq_u64(sum_mod_3_div_3, sum_mod_3);\n        uint64x2_t count_eq_sum_mod_3 = vreinterpretq_u64_u8(vaddvq_u8(vreinterpretq_u8_u64(eq_sum_mod_3)));\n        count_mod_3 = vaddq_u64(count_mod_3, count_eq_sum_mod_3);\n    }\n\n    return vgetq_lane_u64(count_mod_3, 0);\n}\n```"}
{"task_id": "SimdBench_133_Neon", "completion": "```c\nint x_or_y_simd(int n, int x, int y) {\n    int result = 0;\n    uint32x4_t v_n = vdupq_n_u32(n);\n    uint32x4_t v_x = vdupq_n_u32(x);\n    uint32x4_t v_y = vdupq_n_u32(y);\n\n    uint32x4_t v_one = vdupq_n_u32(1);\n    uint32x4_t v_two = vdupq_n_u32(2);\n    uint32x4_t v_three = vdupq_n_u32(3);\n    uint32x4_t v_four = vdupq_n_u32(4);\n    uint32x4_t v_five = vdupq_n_u32(5);\n    uint32x4_t v_six = vdupq_n_u32(6);\n    uint32x4_t v_seven = vdupq_n_u32(7);\n    uint32x4_t v_eight = vdupq_n_u32(8);\n    uint32x4_t v_nine = vdupq_n_u32(9);\n    uint32x4_t v_ten = vdupq_n_u32(10);\n\n    uint32x4_t v_is_prime = vmovq_n_u32(1);\n\n    // Check divisibility by 2, 3, 5, 7\n    v_is_prime = vbicq_u32(v_is_prime, veorq_u32(vandq_u32(v_n, v_two), vdupq_n_u32(0)));\n    v_is_prime = vbicq_u32(v_is_prime, veorq_u32(vandq_u32(v_n, v_three), vdupq_n_u32(0)));\n    v_is_prime = vbicq_u32(v_is_prime, veorq_u32(vandq_u32(v_n, v_five), vdupq_n_u32(0)));\n    v_is_prime = vbicq_u32(v_is_prime, veorq_u32(vandq_u32(v_n, v_seven), vdupq_n_u32(0)));\n\n    // Check divisibility by numbers up to sqrt(n)\n    for (int i = 11; i * i <= n; i += 2) {\n        uint32x4_t v_i = vdupq_n_u32(i);\n        uint32x4_t v_i_squared = vmulq_u32(v_i, v_i);\n        uint32x4_t v_divisible = vceqq_u32(vmodq_u32(v_n, v_i), vdupq_n_u32(0));\n        v_is_prime = vbicq_u32(v_is_prime, v_divisible);\n    }\n\n    // If n is prime, return x, otherwise return y\n    uint32x4_t v_result = vbslq_u32(v_is_prime, v_x, v_y);\n    vst1q_lane_u32(&result, v_result, 0);\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_133_Neon", "completion": "```c\nint x_or_y_simd(int n, int x, int y) {\n    int result = 0;\n    int mask = 0;\n\n    // Check if n is less than 2\n    if (n < 2) {\n        return y;\n    }\n\n    // Check if n is divisible by 2\n    if ((n & 1) == 0) {\n        return y;\n    }\n\n    // Check divisibility from 3 to sqrt(n)\n    for (int i = 3; i * i <= n; i += 2) {\n        if ((n % i) == 0) {\n            return y;\n        }\n    }\n\n    return x;\n}\n```"}
{"task_id": "SimdBench_133_Neon", "completion": "```cpp\nint x_or_y_simd(int n, int x, int y) {\n    uint32x4_t v_n = vmovq_n_u32(n);\n    uint32x4_t v_x = vmovq_n_u32(x);\n    uint32x4_t v_y = vmovq_n_u32(y);\n\n    uint32x4_t v_one = vmovq_n_u32(1);\n    uint32x4_t v_two = vmovq_n_u32(2);\n    uint32x4_t v_three = vmovq_n_u32(3);\n\n    uint32x4_t v_is_prime = vdupq_n_u32(0);\n\n    // Check if n is less than 2\n    uint32x4_t v_less_than_two = vcltq_u32(v_n, v_two);\n    v_is_prime = vbicq_u32(v_is_prime, v_less_than_two);\n\n    // Check if n is divisible by 2\n    uint32x4_t v_divisible_by_two = veorq_u32(v_n, v_two);\n    v_is_prime = vbicq_u32(v_is_prime, v_divisible_by_two);\n\n    // Check divisibility by odd numbers from 3 to sqrt(n)\n    for (int i = 3; i * i <= n; i += 2) {\n        uint32x4_t v_i = vmovq_n_u32(i);\n        uint32x4_t v_i_squared = vmulq_u32(v_i, v_i);\n        uint32x4_t v_divisible_by_i = vmodq_u32(v_n, v_i);\n        uint32x4_t v_not_divisible_by_i = veorq_u32(v_divisible_by_i, v_zero);\n        v_is_prime = vbicq_u32(v_is_prime, v_not_divisible_by_i);\n    }\n\n    // If n is prime, return x, otherwise return y\n    uint32x4_t v_result = vbslq_u32(v_is_prime, v_x, v_y);\n    return vgetq_lane_u32(v_result, 0);\n}\n```"}
{"task_id": "SimdBench_133_Neon", "completion": "```c\nint x_or_y_simd(int n, int x, int y) {\n    int result = 0;\n    int mask = 0;\n\n    // Check if n is less than 2\n    mask |= (n < 2);\n\n    // Check if n is divisible by 2\n    mask |= ((n & 1) == 0 && n > 2);\n\n    // Check if n is divisible by odd numbers from 3 to sqrt(n)\n    for (int i = 3; i * i <= n; i += 2) {\n        mask |= (n % i == 0);\n    }\n\n    // If n is not prime, set result to y\n    result = (mask != 0) ? y : x;\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_133_Neon", "completion": "```c\nint x_or_y_simd(int n, int x, int y) {\n    int result = 0;\n    uint32x4_t v_n = vdupq_n_u32(n);\n    uint32x4_t v_x = vdupq_n_u32(x);\n    uint32x4_t v_y = vdupq_n_u32(y);\n\n    uint32x4_t v_is_prime = vmovq_n_u32(1);\n    uint32x4_t v_one = vdupq_n_u32(1);\n    uint32x4_t v_two = vdupq_n_u32(2);\n    uint32x4_t v_three = vdupq_n_u32(3);\n    uint32x4_t v_four = vdupq_n_u32(4);\n\n    // Check if n is less than 2\n    uint32x4_t v_less_than_two = vcltq_u32(v_n, v_two);\n    v_is_prime = vbicq_u32(v_is_prime, v_less_than_two);\n\n    // Check if n is divisible by 2\n    uint32x4_t v_divisible_by_two = veorq_u32(v_n, v_one);\n    v_is_prime = vbicq_u32(v_is_prime, v_divisible_by_two);\n\n    // Check if n is divisible by 3\n    uint32x4_t v_divisible_by_three = vmulq_u32(v_n, v_three);\n    v_is_prime = vbicq_u32(v_is_prime, v_eqq_u32(v_divisible_by_three, v_n));\n\n    // Check if n is divisible by other numbers up to sqrt(n)\n    uint32x4_t v_i = vtwo;\n    while (v_leq_u32(v_i, v_sqrtq_u32(v_n))) {\n        uint32x4_t v_divisible_by_i = vmulq_u32(v_n, v_i);\n        v_is_prime = vbicq_u32(v_is_prime, v_eqq_u32(v_divisible_by_i, v_n));\n        v_i = vaddq_u32(v_i, v_two);\n    }\n\n    // Select x or y based on whether n is prime\n    result = vbslq_s32(vreinterpretq_s32_u32(v_is_prime), vreinterpretq_s32_u32(v_x), vreinterpretq_s32_u32(v_y));\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_134_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nuint64_t double_the_difference_simd(const std::vector<float> & lst) {\n    uint64_t sum = 0;\n    int n = lst.size();\n    float32x4_t vsum = vdupq_n_f32(0);\n    \n    for (int i = 0; i <= n - 4; i += 4) {\n        float32x4_t vec = vld1q_f32(&lst[i]);\n        float32x4_t mask = vandq_u32(vreinterpretq_u32_f32(vec), vmovq_n_u32(0x7FFFFFFF));\n        float32x4_t is_odd = vceqq_f32(vmulq_f32(mask, mask), vabsq_f32(mask));\n        float32x4_t squared = vmulq_f32(mask, mask);\n        vsum = vfmaq_f32(vsum, squared, is_odd);\n    }\n    \n    float32x2_t vsum_lo = vpadd_f32(vget_low_f32(vsum), vget_high_f32(vsum));\n    float32x2_t vsum_lo_hi = vpadd_f32(vsum_lo, vsum_lo);\n    sum = static_cast<uint64_t>(vget_lane_f32(vsum_lo_hi, 0));\n    \n    for (int i = n - n % 4; i < n; ++i) {\n        if (lst[i] >= 0 && fmod(lst[i], 2.0f) != 0) {\n            sum += static_cast<uint64_t>(lst[i] * lst[i]);\n        }\n    }\n    \n    return sum;\n}\n```"}
{"task_id": "SimdBench_134_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nuint64_t double_the_difference_simd(const std::vector<float> & lst) {\n    uint64_t sum = 0;\n    int n = lst.size();\n    float32x4_t vsum = vdupq_n_f32(0.0f);\n    \n    for (int i = 0; i <= n - 4; i += 4) {\n        float32x4_t vec = vld1q_f32(&lst[i]);\n        float32x4_t mask = vandq_u32(vreinterpretq_u32_f32(vec), vdupq_n_u32(0x7FFFFFFF));\n        float32x4_t abs_vec = vabsq_f32(mask);\n        float32x4_t floor_vec = vrndmq_f32(abs_vec);\n        float32x4_t diff = vsubq_f32(floor_vec, abs_vec);\n        float32x4_t is_odd = vceqq_f32(diff, vdupq_n_f32(0.5f));\n        float32x4_t square = vmulq_f32(abs_vec, abs_vec);\n        vsum = vfmaq_f32(vsum, square, is_odd);\n    }\n    \n    float32x2_t vsum_low = vpadd_f32(vget_low_f32(vsum), vget_high_f32(vsum));\n    float32x2_t vsum_low_low = vpadd_f32(vsum_low, vsum_low);\n    sum = static_cast<uint64_t>(vget_lane_f32(vsum_low_low, 0));\n    \n    for (int i = n - n % 4; i < n; ++i) {\n        if (lst[i] >= 0 && fmod(lst[i], 2.0f) != 0) {\n            sum += static_cast<uint64_t>(lst[i] * lst[i]);\n        }\n    }\n    \n    return sum;\n}\n```"}
{"task_id": "SimdBench_134_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nuint64_t double_the_difference_simd(const std::vector<float> & lst) {\n    uint64_t sum = 0;\n    size_t n = lst.size();\n    size_t i = 0;\n\n    // Process elements in chunks of 4\n    for (; i <= n - 4; i += 4) {\n        float32x4_t vec = vld1q_f32(&lst[i]);\n        float32x4_t mask = vandq_u32(vreinterpretq_u32_f32(vec), vdupq_n_u32(0x7FFFFFFF));\n        float32x4_t sign_mask = vmovq_n_f32(-0.0f);\n        float32x4_t abs_vec = vabsq_f32(mask);\n        float32x4_t int_mask = vceqq_f32(abs_vec, vcvtq_f32_s32(vcvtq_s32_f32(abs_vec)));\n        float32x4_t odd_mask = veorq_u32(int_mask, vdupq_n_u32(0x55555555));\n        float32x4_t square_vec = vmulq_f32(abs_vec, abs_vec);\n        float32x4_t result = vmulq_f32(square_vec, vreinterpretq_f32_u32(odd_mask));\n\n        sum += vaddvq_u32(vreinterpretq_u32_f32(result));\n    }\n\n    // Process remaining elements\n    for (; i < n; ++i) {\n        if (lst[i] > 0 && fmod(lst[i], 2.0f) != 0) {\n            sum += static_cast<uint64_t>(pow(lst[i], 2));\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_134_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nuint64_t double_the_difference_simd(const std::vector<float> & lst) {\n    uint64_t sum = 0;\n    size_t n = lst.size();\n    size_t i = 0;\n\n    // Process elements in chunks of 4\n    for (; i <= n - 4; i += 4) {\n        float32x4_t v = vld1q_f32(&lst[i]);\n        float32x4_t v_abs = vabsq_f32(v);\n        uint32x4_t v_is_odd = vmulq_u32(vcvtu32_f32(v_abs), vcvtu32_f32(v_abs));\n        uint32x4_t v_is_int = vceqq_f32(v_abs, vcvt_f32_u32(v_is_odd));\n        uint32x4_t v_mask = vbicq_u32(v_andq_u32(v_is_odd, v_is_int), vcltq_f32(v_abs, vdupq_n_f32(0)));\n        uint32x4_t v_squares = vmulq_u32(v_abs, v_abs);\n        uint64x2_t v_sum = vpaddlq_u32(vandq_u32(v_squares, v_mask));\n        sum += vgetq_lane_u64(v_sum, 0) + vgetq_lane_u64(v_sum, 1);\n    }\n\n    // Process remaining elements\n    for (; i < n; ++i) {\n        if (lst[i] >= 0 && fmod(lst[i], 2.0f) == 0) {\n            sum += static_cast<uint64_t>(lst[i]) * static_cast<uint64_t>(lst[i]);\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_134_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nuint64_t double_the_difference_simd(const std::vector<float> & lst) {\n    uint64_t sum = 0;\n    size_t n = lst.size();\n    size_t i = 0;\n\n    // Process elements in chunks of 4\n    for (; i <= n - 4; i += 4) {\n        float32x4_t vec = vld1q_f32(&lst[i]);\n        float32x4_t mask = vandq_u32(vreinterpretq_u32_f32(vec), vmovq_n_u32(0x7FFFFFFF)); // Remove sign bit\n        float32x4_t is_odd = vceqq_f32(vmulq_f32(mask, mask), vdupq_n_f32(1.0f));\n        float32x4_t squared = vmulq_f32(vec, vec);\n        float32x4_t result = vmulq_f32(squared, is_odd);\n        sum += vaddvq_u32(vreinterpretq_u32_f32(result));\n    }\n\n    // Process remaining elements\n    for (; i < n; ++i) {\n        if (lst[i] > 0 && fmod(lst[i], 2.0f) != 0) {\n            sum += static_cast<uint64_t>(lst[i] * lst[i]);\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_135_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int> compare_simd(const std::vector<int>& game, const std::vector<int>& guess) {\n    int n = game.size();\n    std::vector<int> result(n);\n\n    int32x4_t v_game;\n    int32x4_t v_guess;\n    int32x4_t v_diff;\n    int32x4_t v_zero = vmovq_n_s32(0);\n    uint32x4_t v_mask;\n\n    for (int i = 0; i < n; i += 4) {\n        v_game = vld1q_s32(&game[i]);\n        v_guess = vld1q_s32(&guess[i]);\n\n        v_diff = vabsq_s32(vsubq_s32(v_game, v_guess));\n        v_mask = vceqq_s32(vdiff, v_zero);\n        v_diff = vbicq_s32(vdiff, vreinterpretq_s32_u32(vmask));\n\n        vst1q_s32(&result[i], vdiff);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_135_Neon", "completion": "```cpp\nstd::vector<int> compare_simd(const std::vector<int>& game, const std::vector<int>& guess) {\n    int n = game.size();\n    std::vector<int> result(n);\n\n    for (int i = 0; i < n; i += 8) {\n        int32x4_t v_game1 = vld1q_s32(&game[i]);\n        int32x4_t v_guess1 = vld1q_s32(&guess[i]);\n        int32x4_t v_diff1 = vabsq_s32(vsubq_s32(v_game1, v_guess1));\n        vst1q_s32(&result[i], vdiff1);\n\n        int32x4_t v_game2 = vld1q_s32(&game[i + 4]);\n        int32x4_t v_guess2 = vld1q_s32(&guess[i + 4]);\n        int32x4_t v_diff2 = vabsq_s32(vsubq_s32(v_game2, v_guess2));\n        vst1q_s32(&result[i + 4], vdiff2);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_135_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int> compare_simd(const std::vector<int>& game, const std::vector<int>& guess) {\n    int n = game.size();\n    std::vector<int> result(n);\n\n    for (int i = 0; i <= n - 8; i += 8) {\n        int32x4_t v_game1 = vld1q_s32(&game[i]);\n        int32x4_t v_guess1 = vld1q_s32(&guess[i]);\n        int32x4_t v_diff1 = vabsq_s32(vsubq_s32(v_game1, v_guess1));\n        vst1q_s32(&result[i], vdiff1);\n\n        int32x4_t v_game2 = vld1q_s32(&game[i + 4]);\n        int32x4_t v_guess2 = vld1q_s32(&guess[i + 4]);\n        int32x4_t v_diff2 = vabsq_s32(vsubq_s32(v_game2, v_guess2));\n        vst1q_s32(&result[i + 4], vdiff2);\n    }\n\n    // Handle remaining elements\n    for (int i = n - n % 8; i < n; ++i) {\n        result[i] = std::abs(game[i] - guess[i]);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_135_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int> compare_simd(const std::vector<int>& game, const std::vector<int>& guess) {\n    int n = game.size();\n    std::vector<int> result(n);\n\n    int32x4_t v_game;\n    int32x4_t v_guess;\n    int32x4_t v_diff;\n    int32x4_t v_zero = vmovq_n_s32(0);\n    uint32x4_t v_mask;\n\n    for (int i = 0; i <= n - 4; i += 4) {\n        v_game = vld1q_s32(&game[i]);\n        v_guess = vld1q_s32(&guess[i]);\n\n        v_diff = vabsq_s32(vsubq_s32(v_game, v_guess));\n        v_mask = vceqq_s32(vdiff, vzero);\n        v_diff = vbicq_s32(vdiff, vreinterpretq_u32_s32(v_mask));\n\n        vst1q_s32(&result[i], vdiff);\n    }\n\n    // Handle remaining elements\n    for (int i = n - n % 4; i < n; ++i) {\n        result[i] = abs(game[i] - guess[i]);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_135_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int> compare_simd(const std::vector<int>& game, const std::vector<int>& guess) {\n    int n = game.size();\n    std::vector<int> result(n);\n\n    for (int i = 0; i <= n - 8; i += 8) {\n        int32x4_t v_game1 = vld1q_s32(&game[i]);\n        int32x4_t v_guess1 = vld1q_s32(&guess[i]);\n        int32x4_t v_diff1 = vabsq_s32(vsubq_s32(v_game1, v_guess1));\n        vst1q_s32(&result[i], vdiff1);\n\n        int32x4_t v_game2 = vld1q_s32(&game[i + 4]);\n        int32x4_t v_guess2 = vld1q_s32(&guess[i + 4]);\n        int32x4_t v_diff2 = vabsq_s32(vsubq_s32(v_game2, v_guess2));\n        vst1q_s32(&result[i + 4], vdiff2);\n    }\n\n    // Handle remaining elements\n    for (int i = n - n % 8; i < n; ++i) {\n        result[i] = std::abs(game[i] - guess[i]);\n    }\n\n    return result;\n}\n```"}

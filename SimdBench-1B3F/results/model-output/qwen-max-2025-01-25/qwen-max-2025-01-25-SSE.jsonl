{"task_id": "SimdBench_0_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid conditional_move_simd(const int64_t *src, int64_t *dst, const bool *mask, size_t length) {\n    size_t i = 0;\n\n    // Process 2 elements at a time using SSE2\n    for (; i + 1 < length; i += 2) {\n        // Load two 64-bit integers from src\n        __m128i src_vec = _mm_loadu_si128((__m128i*)&src[i]);\n\n        // Load two 64-bit integers from dst\n        __m128i dst_vec = _mm_loadu_si128((__m128i*)&dst[i]);\n\n        // Load two boolean values from mask and convert them to a mask for blending\n        int mask_val = (mask[i] ? 0x03 : 0x00) | (mask[i + 1] ? 0x0C : 0x00);\n        __m128i blend_mask = _mm_set1_epi64x(mask_val);\n\n        // Blend the values based on the mask\n        __m128i result = _mm_blendv_epi8(dst_vec, src_vec, blend_mask);\n\n        // Store the result back to dst\n        _mm_storeu_si128((__m128i*)&dst[i], result);\n    }\n\n    // Handle any remaining elements\n    for (; i < length; ++i) {\n        if (mask[i]) {\n            dst[i] = src[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_0_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid conditional_move_simd(const int64_t *src, int64_t *dst, const bool *mask, size_t length) {\n    size_t i = 0;\n\n    // Process 2 elements at a time using SSE2\n    for (; i + 1 < length; i += 2) {\n        // Load 2 mask values (as 8-bit integers)\n        __m128i mask_vec = _mm_cvtepi8_epi64(_mm_loadu_si128((__m128i*)&mask[i]));\n\n        // Compare mask values to zero to create a mask of all ones or zeros\n        __m128i mask_cmp = _mm_cmpeq_epi64(mask_vec, _mm_setzero_si128());\n        mask_cmp = _mm_xor_si128(mask_cmp, _mm_set1_epi64x(-1));\n\n        // Load 2 src and dst values\n        __m128i src_vec = _mm_loadu_si128((__m128i*)&src[i]);\n        __m128i dst_vec = _mm_loadu_si128((__m128i*)&dst[i]);\n\n        // Blend src and dst based on the mask\n        __m128i result = _mm_blendv_epi8(dst_vec, src_vec, mask_cmp);\n\n        // Store the result back to dst\n        _mm_storeu_si128((__m128i*)&dst[i], result);\n    }\n\n    // Handle remaining elements\n    for (; i < length; ++i) {\n        if (mask[i]) {\n            dst[i] = src[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_0_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid conditional_move_simd(const int64_t *src, int64_t *dst, const bool *mask, size_t length) {\n    size_t i = 0;\n\n    // Process 2 elements at a time using SSE2\n    for (; i + 1 < length; i += 2) {\n        // Load mask values into an SSE register\n        __m128i mask_vec = _mm_set_epi8(\n            mask[i + 1] ? 0xFF : 0x00, mask[i + 1] ? 0xFF : 0x00, mask[i + 1] ? 0xFF : 0x00, mask[i + 1] ? 0xFF : 0x00,\n            mask[i + 1] ? 0xFF : 0x00, mask[i + 1] ? 0xFF : 0x00, mask[i + 1] ? 0xFF : 0x00, mask[i + 1] ? 0xFF : 0x00,\n            mask[i] ? 0xFF : 0x00, mask[i] ? 0xFF : 0x00, mask[i] ? 0xFF : 0x00, mask[i] ? 0xFF : 0x00,\n            mask[i] ? 0xFF : 0x00, mask[i] ? 0xFF : 0x00, mask[i] ? 0xFF : 0x00, mask[i] ? 0xFF : 0x00\n        );\n\n        // Load source values into an SSE register\n        __m128i src_vec = _mm_loadu_si128((__m128i*)&src[i]);\n\n        // Load destination values into an SSE register\n        __m128i dst_vec = _mm_loadu_si128((__m128i*)&dst[i]);\n\n        // Blend source and destination based on the mask\n        __m128i result = _mm_blendv_epi8(dst_vec, src_vec, mask_vec);\n\n        // Store the result back to the destination array\n        _mm_storeu_si128((__m128i*)&dst[i], result);\n    }\n\n    // Handle any remaining elements\n    for (; i < length; ++i) {\n        if (mask[i]) {\n            dst[i] = src[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_0_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid conditional_move_simd(const int64_t *src, int64_t *dst, const bool *mask, size_t length) {\n    size_t i = 0;\n\n    // Process 2 elements at a time using SSE2\n    for (; i + 1 < length; i += 2) {\n        // Load 2 mask values (bools)\n        __m128i mask_vec = _mm_set_epi8(\n            0, 0, 0, 0, 0, 0, 0, 0,\n            mask[i + 1] ? -1 : 0, 0, 0, 0, 0, 0, 0, 0,\n            mask[i] ? -1 : 0, 0, 0, 0, 0, 0, 0, 0\n        );\n\n        // Load 2 int64_t values from src\n        __m128i src_vec = _mm_loadu_si128((__m128i*)&src[i]);\n\n        // Load 2 int64_t values from dst\n        __m128i dst_vec = _mm_loadu_si128((__m128i*)&dst[i]);\n\n        // Blend values based on mask\n        __m128i result = _mm_blendv_epi8(dst_vec, src_vec, mask_vec);\n\n        // Store the result back to dst\n        _mm_storeu_si128((__m128i*)&dst[i], result);\n    }\n\n    // Handle remaining elements\n    for (; i < length; ++i) {\n        if (mask[i]) {\n            dst[i] = src[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_0_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid conditional_move_simd(const int64_t *src, int64_t *dst, const bool *mask, size_t length) {\n    size_t i = 0;\n\n    // Process 2 elements at a time using SSE2\n    for (; i + 1 < length; i += 2) {\n        // Load 2 mask values (as 8-bit integers)\n        __m128i mask_vec = _mm_cvtepi8_epi64(_mm_loadu_si128((__m128i*)&mask[i]));\n\n        // Compare mask values to create a mask of all ones or zeros\n        __m128i mask_cmp = _mm_cmpeq_epi64(mask_vec, _mm_set1_epi64x(1));\n\n        // Load 2 src and dst values\n        __m128i src_vec = _mm_loadu_si128((__m128i*)&src[i]);\n        __m128i dst_vec = _mm_loadu_si128((__m128i*)&dst[i]);\n\n        // Blend src and dst based on the mask\n        __m128i result = _mm_blendv_epi8(dst_vec, src_vec, mask_cmp);\n\n        // Store the result back to dst\n        _mm_storeu_si128((__m128i*)&dst[i], result);\n    }\n\n    // Handle remaining elements\n    for (; i < length; ++i) {\n        if (mask[i]) {\n            dst[i] = src[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_1_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n\nvoid load_modify_store_simd(const int *src, int *dst, int scale, size_t length) {\n    __m128i v_scale = _mm_set1_epi32(scale);\n    __m128i v_divisor = _mm_set1_epi32(7);\n    __m128i v_shift_right = _mm_set1_epi32(3);\n    __m128i v_shift_left = _mm_set1_epi32(3);\n\n    for (size_t i = 0; i + 4 <= length; i += 4) {\n        // Load 4 integers from src\n        __m128i v_src = _mm_loadu_si128((__m128i*)&src[i]);\n\n        // Compute element * scale\n        __m128i v_scaled = _mm_mullo_epi32(v_src, v_scale);\n\n        // Compute tmp1: (element * scale) >> 3\n        __m128i v_tmp1 = _mm_srai_epi32(v_scaled, 3);\n\n        // Compute tmp2: (element * scale) << 3\n        __m128i v_tmp2 = _mm_slli_epi32(v_scaled, 3);\n\n        // Compute tmp1 * tmp2\n        __m128i v_tmp1_tmp2 = _mm_mullo_epi32(v_tmp1, v_tmp2);\n\n        // Compute final result: (element * scale + tmp1 * tmp2) / 7\n        __m128i v_result = _mm_add_epi32(v_scaled, v_tmp1_tmp2);\n        v_result = _mm_div_epi32(v_result, v_divisor);\n\n        // Store the result into dst\n        _mm_storeu_si128((__m128i*)&dst[i], v_result);\n    }\n\n    // Handle remaining elements\n    for (size_t i = (length / 4) * 4; i < length; ++i) {\n        int tmp1 = (src[i] * scale) >> 3;\n        int tmp2 = (src[i] * scale) << 3;\n        dst[i] = (src[i] * scale + tmp1 * tmp2) / 7;\n    }\n}\n```"}
{"task_id": "SimdBench_1_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid load_modify_store_simd(const int *src, int *dst, int scale, size_t length) {\n    __m128i v_scale = _mm_set1_epi32(scale);\n    __m128i v_divisor = _mm_set1_epi32(7);\n    __m128i v_shift_right = _mm_set1_epi32(3);\n    __m128i v_shift_left = _mm_set1_epi32(3);\n\n    size_t i = 0;\n    for (; i + 4 <= length; i += 4) {\n        // Load 4 integers from src\n        __m128i v_src = _mm_loadu_si128((__m128i*)&src[i]);\n\n        // Compute element * scale\n        __m128i v_scaled = _mm_mullo_epi32(v_src, v_scale);\n\n        // Compute tmp1: (element * scale) >> 3\n        __m128i v_tmp1 = _mm_srai_epi32(v_scaled, 3);\n\n        // Compute tmp2: (element * scale) << 3\n        __m128i v_tmp2 = _mm_slli_epi32(v_scaled, 3);\n\n        // Compute tmp1 * tmp2\n        __m128i v_tmp1_tmp2 = _mm_mullo_epi32(v_tmp1, v_tmp2);\n\n        // Compute final result: (element * scale + tmp1 * tmp2) / 7\n        __m128i v_result = _mm_add_epi32(v_scaled, v_tmp1_tmp2);\n        v_result = _mm_div_epi32(v_result, v_divisor);\n\n        // Store the result into dst\n        _mm_storeu_si128((__m128i*)&dst[i], v_result);\n    }\n\n    // Handle remaining elements\n    for (; i < length; ++i) {\n        int tmp1 = (src[i] * scale) >> 3;\n        int tmp2 = (src[i] * scale) << 3;\n        dst[i] = (src[i] * scale + tmp1 * tmp2) / 7;\n    }\n}\n```"}
{"task_id": "SimdBench_1_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid load_modify_store_simd(const int *src, int *dst, int scale, size_t length) {\n    __m128i v_scale = _mm_set1_epi32(scale);\n    __m128i v_divisor = _mm_set1_epi32(7);\n    __m128i v_shift_right = _mm_set1_epi32(3);\n    __m128i v_shift_left = _mm_set1_epi32(3);\n\n    size_t i = 0;\n    for (; i + 4 <= length; i += 4) {\n        // Load 4 integers from src\n        __m128i v_src = _mm_loadu_si128((__m128i*)&src[i]);\n\n        // Compute element * scale\n        __m128i v_scaled = _mm_mullo_epi32(v_src, v_scale);\n\n        // Compute tmp1: (element * scale) >> 3\n        __m128i v_tmp1 = _mm_srai_epi32(v_scaled, 3);\n\n        // Compute tmp2: (element * scale) << 3\n        __m128i v_tmp2 = _mm_slli_epi32(v_scaled, 3);\n\n        // Compute tmp1 * tmp2\n        __m128i v_tmp1_tmp2 = _mm_mullo_epi32(v_tmp1, v_tmp2);\n\n        // Compute final result: (element * scale + tmp1 * tmp2) / 7\n        __m128i v_result = _mm_add_epi32(v_scaled, v_tmp1_tmp2);\n        v_result = _mm_div_epi32(v_result, v_divisor);\n\n        // Store the result into dst\n        _mm_storeu_si128((__m128i*)&dst[i], v_result);\n    }\n\n    // Handle remaining elements\n    for (; i < length; ++i) {\n        int scaled = src[i] * scale;\n        int tmp1 = scaled >> 3;\n        int tmp2 = scaled << 3;\n        dst[i] = (scaled + tmp1 * tmp2) / 7;\n    }\n}\n```"}
{"task_id": "SimdBench_1_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid load_modify_store_simd(const int *src, int *dst, int scale, size_t length) {\n    __m128i v_scale = _mm_set1_epi32(scale);\n    __m128i v_divisor = _mm_set1_epi32(7);\n    __m128i v_shift_right = _mm_set1_epi32(3);\n    __m128i v_shift_left = _mm_set1_epi32(3);\n\n    size_t i = 0;\n    for (; i + 4 <= length; i += 4) {\n        // Load 4 integers from src\n        __m128i v_src = _mm_loadu_si128((__m128i*)&src[i]);\n\n        // Compute element * scale\n        __m128i v_scaled = _mm_mullo_epi32(v_src, v_scale);\n\n        // Compute tmp1: (element * scale) >> 3\n        __m128i v_tmp1 = _mm_srai_epi32(v_scaled, 3);\n\n        // Compute tmp2: (element * scale) << 3\n        __m128i v_tmp2 = _mm_slli_epi32(v_scaled, 3);\n\n        // Compute tmp1 * tmp2\n        __m128i v_tmp1_tmp2 = _mm_mullo_epi32(v_tmp1, v_tmp2);\n\n        // Compute final result: (element * scale + tmp1 * tmp2) / 7\n        __m128i v_result = _mm_add_epi32(v_scaled, v_tmp1_tmp2);\n        v_result = _mm_div_epi32(v_result, v_divisor);\n\n        // Store the result into dst\n        _mm_storeu_si128((__m128i*)&dst[i], v_result);\n    }\n\n    // Handle remaining elements\n    for (; i < length; ++i) {\n        int tmp1 = (src[i] * scale) >> 3;\n        int tmp2 = (src[i] * scale) << 3;\n        dst[i] = (src[i] * scale + tmp1 * tmp2) / 7;\n    }\n}\n```"}
{"task_id": "SimdBench_1_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid load_modify_store_simd(const int *src, int *dst, int scale, size_t length) {\n    __m128i v_scale = _mm_set1_epi32(scale);\n    __m128i v_divisor = _mm_set1_epi32(7);\n    __m128i v_shift_right = _mm_set1_epi32(3);\n    __m128i v_shift_left = _mm_set1_epi32(3);\n\n    size_t i = 0;\n    for (; i + 4 <= length; i += 4) {\n        // Load 4 integers from src\n        __m128i v_src = _mm_loadu_si128((__m128i*)&src[i]);\n\n        // Multiply each element by scale\n        __m128i v_scaled = _mm_mullo_epi32(v_src, v_scale);\n\n        // Calculate tmp1: (element * scale) >> 3\n        __m128i v_tmp1 = _mm_srai_epi32(v_scaled, 3);\n\n        // Calculate tmp2: (element * scale) << 3\n        __m128i v_tmp2 = _mm_slli_epi32(v_scaled, 3);\n\n        // Multiply tmp1 and tmp2\n        __m128i v_tmp1_tmp2 = _mm_mullo_epi32(v_tmp1, v_tmp2);\n\n        // Add (element * scale) to (tmp1 * tmp2)\n        __m128i v_sum = _mm_add_epi32(v_scaled, v_tmp1_tmp2);\n\n        // Divide the sum by 7\n        __m128i v_result = _mm_div_epi32(v_sum, v_divisor);\n\n        // Store the result into dst\n        _mm_storeu_si128((__m128i*)&dst[i], v_result);\n    }\n\n    // Handle remaining elements\n    for (; i < length; ++i) {\n        int tmp1 = (src[i] * scale) >> 3;\n        int tmp2 = (src[i] * scale) << 3;\n        dst[i] = (src[i] * scale + tmp1 * tmp2) / 7;\n    }\n}\n```"}
{"task_id": "SimdBench_2_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid strided_load_store_simd(const double *src, double *dst, size_t rows, size_t cols, size_t stride) {\n    size_t i = 0;\n    __m128d val;\n\n    // Process two rows at a time using SIMD\n    for (; i + 1 < rows; i += 2) {\n        // Load two doubles from src with the given stride\n        val = _mm_set_pd(src[(i + 1) * cols + stride], src[i * cols + stride]);\n\n        // Store two doubles into dst\n        _mm_storeu_pd(&dst[i], val);\n    }\n\n    // Process any remaining row that wasn't handled in the loop above\n    if (i < rows) {\n        dst[i] = src[i * cols + stride];\n    }\n}\n```"}
{"task_id": "SimdBench_2_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid strided_load_store_simd(const double *src, double *dst, size_t rows, size_t cols, size_t stride) {\n    size_t i = 0;\n    // Process two rows at a time using SSE2 (128-bit registers for two doubles)\n    for (; i + 1 < rows; i += 2) {\n        // Calculate indices for the current pair of rows\n        size_t idx0 = i * cols + stride;\n        size_t idx1 = (i + 1) * cols + stride;\n\n        // Load two doubles from src array\n        __m128d src_vec = _mm_loadu_pd(&src[idx0]);\n\n        // Store two doubles into dst array\n        _mm_storeu_pd(&dst[i], src_vec);\n    }\n\n    // Handle any remaining row (if rows is odd)\n    if (i < rows) {\n        size_t idx = i * cols + stride;\n        dst[i] = src[idx];\n    }\n}\n```"}
{"task_id": "SimdBench_2_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid strided_load_store_simd(const double *src, double *dst, size_t rows, size_t cols, size_t stride) {\n    size_t i = 0;\n    // Process two rows at a time using SIMD (128-bit registers hold 2 doubles)\n    for (; i + 1 < rows; i += 2) {\n        // Calculate indices for the current pair of rows\n        size_t idx0 = i * cols + stride;\n        size_t idx1 = (i + 1) * cols + stride;\n\n        // Load two doubles from src into a SIMD register\n        __m128d src_vals = _mm_loadu_pd(&src[idx0]);\n\n        // Store the loaded values into dst\n        _mm_storeu_pd(&dst[i], src_vals);\n    }\n\n    // Handle any remaining row that wasn't processed in the loop above\n    if (i < rows) {\n        size_t idx = i * cols + stride;\n        dst[i] = src[idx];\n    }\n}\n```"}
{"task_id": "SimdBench_2_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid strided_load_store_simd(const double *src, double *dst, size_t rows, size_t cols, size_t stride) {\n    size_t vec_size = 2; // SSE2 processes 2 doubles at a time (128-bit register)\n    __m128d src_vec;\n\n    for (size_t r = 0; r < rows; ++r) {\n        size_t src_idx = r * cols + stride;\n        src_vec = _mm_loadu_pd(&src[src_idx]); // Load 2 doubles from src\n        _mm_storeu_pd(&dst[r * vec_size], src_vec); // Store 2 doubles into dst\n    }\n}\n```"}
{"task_id": "SimdBench_2_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid strided_load_store_simd(const double *src, double *dst, size_t rows, size_t cols, size_t stride) {\n    size_t i = 0;\n    // Process two rows at a time using SSE2\n    for (; i + 1 < rows; i += 2) {\n        // Calculate the indices for loading from src\n        size_t idx1 = i * cols + stride;\n        size_t idx2 = (i + 1) * cols + stride;\n\n        // Ensure indices are aligned to 16 bytes for SIMD operations\n        if ((idx1 % 2 == 0) && (idx2 % 2 == 0)) {\n            // Load two doubles from src into a single SIMD register\n            __m128d src_vals = _mm_loadu_pd(&src[idx1]);\n\n            // Store the loaded values into dst\n            _mm_storeu_pd(&dst[i], src_vals);\n        } else {\n            // Fallback to scalar if alignment is not guaranteed\n            dst[i] = src[idx1];\n            dst[i + 1] = src[idx2];\n        }\n    }\n\n    // Handle any remaining rows that couldn't be processed in pairs\n    for (; i < rows; ++i) {\n        size_t idx = i * cols + stride;\n        dst[i] = src[idx];\n    }\n}\n```"}
{"task_id": "SimdBench_3_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid indexed_access_simd(const float *src, const int *indices, float *dst, size_t length) {\n    size_t i = 0;\n\n    // Gather operation using indices as lookups\n    for (; i + 4 <= length; i += 4) {\n        __m128i idx = _mm_loadu_si128((__m128i*)&indices[i]); // Load 4 indices\n        __m128 values = _mm_setzero_ps(); // Initialize to zero\n\n        for (int j = 0; j < 4; ++j) {\n            int index = _mm_extract_epi32(idx, j); // Extract each index\n            values = _mm_insert_ps(values, _mm_load_ss(&src[index]), j << 4); // Gather value from src\n        }\n\n        _mm_storeu_ps(&dst[i], values); // Store gathered values into dst\n    }\n\n    // Handle remaining elements for gather\n    for (; i < length; ++i) {\n        dst[i] = src[indices[i]];\n    }\n\n    // Scatter operation using indices as write locations\n    i = 0;\n    for (; i + 4 <= length; i += 4) {\n        __m128i idx = _mm_loadu_si128((__m128i*)&indices[i]); // Load 4 indices\n        __m128 values = _mm_loadu_ps(&src[i]); // Load 4 values from src\n\n        for (int j = 0; j < 4; ++j) {\n            int index = _mm_extract_epi32(idx, j); // Extract each index\n            _mm_store_ss(&dst[index], _mm_shuffle_ps(values, values, j)); // Scatter value to dst\n        }\n    }\n\n    // Handle remaining elements for scatter\n    for (; i < length; ++i) {\n        dst[indices[i]] = src[i];\n    }\n}\n```"}
{"task_id": "SimdBench_3_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n\nvoid indexed_access_simd(const float *src, const int *indices, float *dst, size_t length) {\n    size_t i = 0;\n\n    // Gather operation using indices as lookups\n    for (; i + 4 <= length; i += 4) {\n        __m128i idx = _mm_loadu_si128((__m128i*)&indices[i]); // Load 4 indices\n        __m128 val0 = _mm_load_ss(&src[_mm_extract_epi32(idx, 0)]); // Load src[idx[0]]\n        __m128 val1 = _mm_load_ss(&src[_mm_extract_epi32(idx, 1)]); // Load src[idx[1]]\n        __m128 val2 = _mm_load_ss(&src[_mm_extract_epi32(idx, 2)]); // Load src[idx[2]]\n        __m128 val3 = _mm_load_ss(&src[_mm_extract_epi32(idx, 3)]); // Load src[idx[3]]\n        __m128 vals = _mm_shuffle_ps(val0, val1, _MM_SHUFFLE(0, 0, 0, 0)); // Combine values\n        vals = _mm_shuffle_ps(vals, val2, _MM_SHUFFLE(0, 0, 0, 0));\n        vals = _mm_shuffle_ps(vals, val3, _MM_SHUFFLE(0, 0, 0, 0));\n        _mm_storeu_ps(&dst[i], vals); // Store gathered values to dst\n    }\n\n    // Handle remaining elements for gather\n    for (; i < length; ++i) {\n        dst[i] = src[indices[i]];\n    }\n\n    // Scatter operation using indices as write locations\n    i = 0;\n    for (; i + 4 <= length; i += 4) {\n        __m128 vals = _mm_loadu_ps(&src[i]); // Load 4 source values\n        __m128i idx = _mm_loadu_si128((__m128i*)&indices[i]); // Load 4 indices\n        _mm_store_ss(&dst[_mm_extract_epi32(idx, 0)], vals); // Scatter src[i] to dst[idx[0]]\n        vals = _mm_shuffle_ps(vals, vals, _MM_SHUFFLE(1, 1, 1, 1));\n        _mm_store_ss(&dst[_mm_extract_epi32(idx, 1)], vals); // Scatter src[i+1] to dst[idx[1]]\n        vals = _mm_shuffle_ps(vals, vals, _MM_SHUFFLE(2, 2, 2, 2));\n        _mm_store_ss(&dst[_mm_extract_epi32(idx, 2)], vals); // Scatter src[i+2] to dst[idx[2]]\n        vals = _mm_shuffle_ps(vals, vals, _MM_SHUFFLE(3, 3, 3, 3));\n        _mm_store_ss(&dst[_mm_extract_epi32(idx, 3)], vals); // Scatter src[i+3] to dst[idx[3]]\n    }\n\n    // Handle remaining elements for scatter\n    for (; i < length; ++i) {\n        dst[indices[i]] = src[i];\n    }\n}\n```"}
{"task_id": "SimdBench_3_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid indexed_access_simd(const float *src, const int *indices, float *dst, size_t length) {\n    size_t i = 0;\n\n    // Gather operation using indices as lookups\n    for (; i + 4 <= length; i += 4) {\n        __m128i idx = _mm_loadu_si128((__m128i*)&indices[i]); // Load 4 indices\n        __m128 gathered = _mm_setzero_ps(); // Initialize result vector\n\n        for (int j = 0; j < 4; ++j) {\n            int index = _mm_extract_epi32(idx, j); // Extract each index\n            gathered = _mm_insert_ps(gathered, _mm_load_ss(&src[index]), j << 4); // Gather values\n        }\n\n        _mm_storeu_ps(&dst[i], gathered); // Store gathered values to dst\n    }\n\n    // Handle remaining elements for gather\n    for (; i < length; ++i) {\n        dst[i] = src[indices[i]];\n    }\n\n    // Scatter operation using indices as write locations\n    i = 0;\n    for (; i + 4 <= length; i += 4) {\n        __m128i idx = _mm_loadu_si128((__m128i*)&indices[i]); // Load 4 indices\n        __m128 values = _mm_loadu_ps(&src[i]); // Load 4 source values\n\n        for (int j = 0; j < 4; ++j) {\n            int index = _mm_extract_epi32(idx, j); // Extract each index\n            _mm_store_ss(&dst[index], _mm_shuffle_ps(values, values, j)); // Scatter values\n        }\n    }\n\n    // Handle remaining elements for scatter\n    for (; i < length; ++i) {\n        dst[indices[i]] = src[i];\n    }\n}\n```"}
{"task_id": "SimdBench_3_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n\nvoid indexed_access_simd(const float *src, const int *indices, float *dst, size_t length) {\n    size_t i = 0;\n\n    // Gather operation using indices as lookups\n    for (; i + 4 <= length; i += 4) {\n        __m128i idx = _mm_loadu_si128((__m128i*)&indices[i]); // Load 4 indices\n        __m128 val0 = _mm_set_ss(src[_mm_extract_epi32(idx, 0)]);\n        __m128 val1 = _mm_set_ss(src[_mm_extract_epi32(idx, 1)]);\n        __m128 val2 = _mm_set_ss(src[_mm_extract_epi32(idx, 2)]);\n        __m128 val3 = _mm_set_ss(src[_mm_extract_epi32(idx, 3)]);\n        __m128 gathered = _mm_shuffle_ps(val0, val1, _MM_SHUFFLE(0, 0, 0, 0));\n        gathered = _mm_shuffle_ps(gathered, val2, _MM_SHUFFLE(0, 0, 0, 0));\n        gathered = _mm_shuffle_ps(gathered, val3, _MM_SHUFFLE(0, 0, 0, 0));\n        _mm_storeu_ps(&dst[i], gathered); // Store gathered values into dst\n    }\n\n    // Handle remaining elements for gather\n    for (; i < length; ++i) {\n        dst[i] = src[indices[i]];\n    }\n\n    // Scatter operation using indices as write locations\n    i = 0;\n    for (; i + 4 <= length; i += 4) {\n        __m128i idx = _mm_loadu_si128((__m128i*)&indices[i]); // Load 4 indices\n        __m128 vals = _mm_loadu_ps(&src[i]); // Load 4 source values\n        _mm_store_ss(&dst[_mm_extract_epi32(idx, 0)], _mm_shuffle_ps(vals, vals, _MM_SHUFFLE(0, 0, 0, 0)));\n        _mm_store_ss(&dst[_mm_extract_epi32(idx, 1)], _mm_shuffle_ps(vals, vals, _MM_SHUFFLE(1, 1, 1, 1)));\n        _mm_store_ss(&dst[_mm_extract_epi32(idx, 2)], _mm_shuffle_ps(vals, vals, _MM_SHUFFLE(2, 2, 2, 2)));\n        _mm_store_ss(&dst[_mm_extract_epi32(idx, 3)], _mm_shuffle_ps(vals, vals, _MM_SHUFFLE(3, 3, 3, 3)));\n    }\n\n    // Handle remaining elements for scatter\n    for (; i < length; ++i) {\n        dst[indices[i]] = src[i];\n    }\n}\n```"}
{"task_id": "SimdBench_3_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid indexed_access_simd(const float *src, const int *indices, float *dst, size_t length) {\n    size_t i = 0;\n\n    // Gather operation using indices as lookups\n    for (; i + 4 <= length; i += 4) {\n        __m128i idx = _mm_loadu_si128((__m128i*)&indices[i]); // Load 4 indices\n        __m128 values = _mm_setzero_ps();\n\n        for (int j = 0; j < 4; ++j) {\n            int index = _mm_extract_epi32(idx, j); // Extract each index\n            __m128 val = _mm_load_ss(&src[index]); // Load single float from src\n            values = _mm_insert_ps(values, val, j << 4); // Insert into correct position\n        }\n\n        _mm_storeu_ps(&dst[i], values); // Store gathered values to dst\n    }\n\n    // Handle remaining elements for gather\n    for (; i < length; ++i) {\n        dst[i] = src[indices[i]];\n    }\n\n    // Scatter operation using indices as write locations\n    i = 0;\n    for (; i + 4 <= length; i += 4) {\n        __m128i idx = _mm_loadu_si128((__m128i*)&indices[i]); // Load 4 indices\n        __m128 values = _mm_loadu_ps(&src[i]); // Load 4 floats from src\n\n        for (int j = 0; j < 4; ++j) {\n            int index = _mm_extract_epi32(idx, j); // Extract each index\n            _mm_store_ss(&dst[index], _mm_shuffle_ps(values, values, j)); // Scatter value to dst\n        }\n    }\n\n    // Handle remaining elements for scatter\n    for (; i < length; ++i) {\n        dst[indices[i]] = src[i];\n    }\n}\n```"}
{"task_id": "SimdBench_4_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid range_reverse_simd(int16_t *arr, uint64_t start, uint64_t end) {\n    // Ensure the range is valid\n    if (start >= end || arr == nullptr) return;\n\n    // Align the start and end indices to process 8 elements at a time\n    uint64_t aligned_start = (start + 7) & ~7; // Round up to nearest multiple of 8\n    uint64_t aligned_end = (end + 1) & ~7;     // Round down to nearest multiple of 8\n\n    // Reverse elements outside the aligned range using scalar code\n    uint64_t i = start, j = end;\n    while (i < aligned_start && i < j) {\n        int16_t temp = arr[i];\n        arr[i] = arr[j];\n        arr[j] = temp;\n        i++;\n        j--;\n    }\n\n    // Process the aligned range using SIMD intrinsics\n    __m128i *simd_start = (__m128i *)(arr + aligned_start);\n    __m128i *simd_end = (__m128i *)(arr + aligned_end - 8);\n\n    while (simd_start < simd_end) {\n        // Load 8 elements from the start and end of the range\n        __m128i vec_start = _mm_loadu_si128(simd_start);\n        __m128i vec_end = _mm_loadu_si128(simd_end);\n\n        // Reverse the order of elements within each vector\n        vec_start = _mm_shufflelo_epi16(vec_start, _MM_SHUFFLE(0, 1, 2, 3));\n        vec_start = _mm_shufflehi_epi16(vec_start, _MM_SHUFFLE(0, 1, 2, 3));\n        vec_start = _mm_shuffle_epi32(vec_start, _MM_SHUFFLE(0, 1, 2, 3));\n\n        vec_end = _mm_shufflelo_epi16(vec_end, _MM_SHUFFLE(0, 1, 2, 3));\n        vec_end = _mm_shufflehi_epi16(vec_end, _MM_SHUFFLE(0, 1, 2, 3));\n        vec_end = _mm_shuffle_epi32(vec_end, _MM_SHUFFLE(0, 1, 2, 3));\n\n        // Swap the two vectors\n        _mm_storeu_si128(simd_start, vec_end);\n        _mm_storeu_si128(simd_end, vec_start);\n\n        simd_start++;\n        simd_end--;\n    }\n\n    // Reverse any remaining elements outside the aligned range using scalar code\n    i = aligned_start;\n    j = aligned_end - 1;\n    while (i < j) {\n        int16_t temp = arr[i];\n        arr[i] = arr[j];\n        arr[j] = temp;\n        i++;\n        j--;\n    }\n}\n```"}
{"task_id": "SimdBench_4_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid range_reverse_simd(int16_t *arr, uint64_t start, uint64_t end) {\n    // Ensure the range is valid\n    if (start > end) return;\n\n    // Align the start and end indices to 8-element boundaries for SIMD processing\n    uint64_t simd_start = (start + 7) & ~7; // Round up to nearest multiple of 8\n    uint64_t simd_end = (end + 1) & ~7;    // Round down to nearest multiple of 8\n\n    // Reverse elements outside the SIMD-aligned range using scalar code\n    uint64_t i = start, j = end;\n    while (i < simd_start && j >= simd_end) {\n        int16_t temp = arr[i];\n        arr[i] = arr[j];\n        arr[j] = temp;\n        i++;\n        j--;\n    }\n\n    // Process the SIMD-aligned range\n    __m128i *simd_arr = (__m128i *)(arr + simd_start);\n    uint64_t simd_length = (simd_end - simd_start) / 8;\n\n    for (uint64_t k = 0; k < simd_length / 2; k++) {\n        // Load two 128-bit vectors from the start and end of the range\n        __m128i vec1 = _mm_loadu_si128(simd_arr + k);\n        __m128i vec2 = _mm_loadu_si128(simd_arr + simd_length - k - 1);\n\n        // Reverse the order of elements within each vector\n        __m128i rev1 = _mm_shufflelo_epi16(vec1, _MM_SHUFFLE(0, 1, 2, 3));\n        rev1 = _mm_shufflehi_epi16(rev1, _MM_SHUFFLE(0, 1, 2, 3));\n        rev1 = _mm_shuffle_epi32(rev1, _MM_SHUFFLE(0, 1, 2, 3));\n\n        __m128i rev2 = _mm_shufflelo_epi16(vec2, _MM_SHUFFLE(0, 1, 2, 3));\n        rev2 = _mm_shufflehi_epi16(rev2, _MM_SHUFFLE(0, 1, 2, 3));\n        rev2 = _mm_shuffle_epi32(rev2, _MM_SHUFFLE(0, 1, 2, 3));\n\n        // Swap the reversed vectors\n        _mm_storeu_si128(simd_arr + k, rev2);\n        _mm_storeu_si128(simd_arr + simd_length - k - 1, rev1);\n    }\n\n    // Reverse any remaining elements in the non-SIMD-aligned range\n    i = simd_start + simd_length * 8;\n    j = simd_end - 1;\n    while (i < j) {\n        int16_t temp = arr[i];\n        arr[i] = arr[j];\n        arr[j] = temp;\n        i++;\n        j--;\n    }\n}\n```"}
{"task_id": "SimdBench_4_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid range_reverse_simd(int16_t *arr, uint64_t start, uint64_t end) {\n    // Adjust pointers to the start and end of the range\n    int16_t *left = arr + start;\n    int16_t *right = arr + end;\n\n    // Process 8 elements (128 bits) at a time using SSE2\n    while ((right - left) >= 8) {\n        // Load 8 elements from the left and right sides\n        __m128i left_vec = _mm_loadu_si128((__m128i *)left);\n        __m128i right_vec = _mm_loadu_si128((__m128i *)(right - 7));\n\n        // Reverse the order of elements in the right vector\n        right_vec = _mm_shuffle_epi32(right_vec, _MM_SHUFFLE(0, 1, 2, 3));\n        right_vec = _mm_shufflehi_epi16(right_vec, _MM_SHUFFLE(0, 1, 2, 3));\n        right_vec = _mm_shufflelo_epi16(right_vec, _MM_SHUFFLE(0, 1, 2, 3));\n\n        // Swap the left and reversed right vectors\n        _mm_storeu_si128((__m128i *)left, right_vec);\n        _mm_storeu_si128((__m128i *)(right - 7), left_vec);\n\n        // Move the pointers inward by 8 elements\n        left += 8;\n        right -= 8;\n    }\n\n    // Handle remaining elements (less than 8) using scalar code\n    while (left < right) {\n        int16_t temp = *left;\n        *left = *right;\n        *right = temp;\n        left++;\n        right--;\n    }\n}\n```"}
{"task_id": "SimdBench_4_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid range_reverse_simd(int16_t *arr, uint64_t start, uint64_t end) {\n    // Ensure the range is valid\n    if (start > end) return;\n\n    // Align the start and end indices to process 8 elements at a time\n    uint64_t aligned_start = (start + 7) & ~7; // Round up to nearest multiple of 8\n    uint64_t aligned_end = (end + 1) & ~7;     // Round down to nearest multiple of 8\n\n    // Reverse elements outside the aligned range using scalar code\n    uint64_t i = start, j = end;\n    while (i < aligned_start && j >= aligned_end) {\n        int16_t temp = arr[i];\n        arr[i] = arr[j];\n        arr[j] = temp;\n        i++;\n        j--;\n    }\n\n    // Process the aligned range using SIMD intrinsics\n    __m128i *simd_ptr_start = (__m128i *)(arr + aligned_start);\n    __m128i *simd_ptr_end = (__m128i *)(arr + aligned_end - 8);\n\n    while (simd_ptr_start < simd_ptr_end) {\n        __m128i vec_start = _mm_loadu_si128(simd_ptr_start);\n        __m128i vec_end = _mm_loadu_si128(simd_ptr_end);\n\n        // Reverse the order of 8 elements in each vector\n        __m128i reversed_start = _mm_shuffle_epi32(vec_start, _MM_SHUFFLE(0, 1, 2, 3));\n        reversed_start = _mm_shufflehi_epi16(reversed_start, _MM_SHUFFLE(0, 1, 2, 3));\n        reversed_start = _mm_shufflelo_epi16(reversed_start, _MM_SHUFFLE(0, 1, 2, 3));\n\n        __m128i reversed_end = _mm_shuffle_epi32(vec_end, _MM_SHUFFLE(0, 1, 2, 3));\n        reversed_end = _mm_shufflehi_epi16(reversed_end, _MM_SHUFFLE(0, 1, 2, 3));\n        reversed_end = _mm_shufflelo_epi16(reversed_end, _MM_SHUFFLE(0, 1, 2, 3));\n\n        // Swap the two reversed vectors\n        _mm_storeu_si128(simd_ptr_start, reversed_end);\n        _mm_storeu_si128(simd_ptr_end, reversed_start);\n\n        simd_ptr_start++;\n        simd_ptr_end--;\n    }\n\n    // Reverse any remaining elements in the unaligned range using scalar code\n    i = aligned_start;\n    j = aligned_end - 1;\n    while (i < j) {\n        int16_t temp = arr[i];\n        arr[i] = arr[j];\n        arr[j] = temp;\n        i++;\n        j--;\n    }\n}\n```"}
{"task_id": "SimdBench_4_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid range_reverse_simd(int16_t *arr, uint64_t start, uint64_t end) {\n    __m128i mask = _mm_set_epi8(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15);\n    uint64_t i = start;\n    uint64_t j = end;\n\n    while (i < j) {\n        if ((j - i + 1) >= 8) {\n            __m128i front = _mm_loadu_si128((__m128i*)&arr[i]);\n            __m128i back = _mm_loadu_si128((__m128i*)&arr[j - 7]);\n\n            // Reverse the 8 elements in 'back'\n            back = _mm_shuffle_epi8(back, mask);\n\n            // Swap front and back blocks\n            _mm_storeu_si128((__m128i*)&arr[i], back);\n            _mm_storeu_si128((__m128i*)&arr[j - 7], front);\n\n            i += 8;\n            j -= 8;\n        } else {\n            int16_t temp = arr[i];\n            arr[i] = arr[j];\n            arr[j] = temp;\n            i++;\n            j--;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_5_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid extract_tensor_slice_simd(const uint8_t *tensor, uint8_t *slice, size_t dim1, size_t dim2, size_t dim3, size_t slice_idx) {\n    size_t slice_offset = slice_idx * dim1 * dim2;\n    size_t total_elements = dim1 * dim2;\n\n    for (size_t i = 0; i < total_elements; i += 16) {\n        __m128i data = _mm_loadu_si128((__m128i const*)(tensor + slice_offset + i));\n        _mm_storeu_si128((__m128i*)(slice + i), data);\n    }\n}\n```"}
{"task_id": "SimdBench_5_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid extract_tensor_slice_simd(const uint8_t *tensor, uint8_t *slice, size_t dim1, size_t dim2, size_t dim3, size_t slice_idx) {\n    size_t slice_offset = slice_idx * dim1 * dim2;\n    size_t total_elements = dim1 * dim2;\n\n    for (size_t i = 0; i < total_elements; i += 16) {\n        __m128i data = _mm_loadu_si128((__m128i const*)(tensor + slice_offset + i));\n        _mm_storeu_si128((__m128i*)(slice + i), data);\n    }\n}\n```"}
{"task_id": "SimdBench_5_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid extract_tensor_slice_simd(const uint8_t *tensor, uint8_t *slice, size_t dim1, size_t dim2, size_t dim3, size_t slice_idx) {\n    size_t slice_offset = slice_idx * dim1 * dim2;\n    size_t total_elements = dim1 * dim2;\n\n    for (size_t i = 0; i < total_elements; i += 16) {\n        __m128i data = _mm_loadu_si128((__m128i const*)(tensor + slice_offset + i));\n        _mm_storeu_si128((__m128i*)(slice + i), data);\n    }\n}\n```"}
{"task_id": "SimdBench_5_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid extract_tensor_slice_simd(const uint8_t *tensor, uint8_t *slice, size_t dim1, size_t dim2, size_t dim3, size_t slice_idx) {\n    size_t row_stride = dim2 * dim3;\n    size_t slice_offset = slice_idx * dim2;\n\n    for (size_t i = 0; i < dim1; ++i) {\n        const uint8_t *row_start = tensor + i * row_stride + slice_offset;\n        uint8_t *slice_row_start = slice + i * dim2;\n\n        size_t j = 0;\n        // Process 16 bytes at a time using SSE\n        for (; j + 15 < dim2; j += 16) {\n            __m128i data = _mm_loadu_si128((const __m128i*)(row_start + j));\n            _mm_storeu_si128((__m128i*)(slice_row_start + j), data);\n        }\n\n        // Handle remaining elements\n        for (; j < dim2; ++j) {\n            slice_row_start[j] = row_start[j];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_5_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid extract_tensor_slice_simd(const uint8_t *tensor, uint8_t *slice, size_t dim1, size_t dim2, size_t dim3, size_t slice_idx) {\n    size_t row_stride = dim2 * dim3;\n    size_t slice_offset = slice_idx * dim2;\n\n    for (size_t i = 0; i < dim1; ++i) {\n        const uint8_t *row_start = tensor + i * row_stride + slice_offset;\n        uint8_t *slice_row = slice + i * dim2;\n\n        size_t j = 0;\n        for (; j + 16 <= dim2; j += 16) {\n            __m128i data = _mm_loadu_si128((__m128i *)(row_start + j));\n            _mm_storeu_si128((__m128i *)(slice_row + j), data);\n        }\n\n        for (; j < dim2; ++j) {\n            slice_row[j] = row_start[j];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_6_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid blocked_matrix_transpose_simd(const int16_t *src, int16_t *dst, size_t rows, size_t cols, size_t block_size) {\n    for (size_t i = 0; i < rows; i += block_size) {\n        for (size_t j = 0; j < cols; j += block_size) {\n            size_t block_rows = (i + block_size > rows) ? (rows - i) : block_size;\n            size_t block_cols = (j + block_size > cols) ? (cols - j) : block_size;\n\n            for (size_t bi = 0; bi < block_rows; ++bi) {\n                for (size_t bj = 0; bj < block_cols; bj += 8) {\n                    __m128i data = _mm_loadu_si128((__m128i*)&src[(i + bi) * cols + (j + bj)]);\n                    _mm_storeu_si128((__m128i*)&dst[(j + bj) * rows + (i + bi)], data);\n                }\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_6_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n\nvoid blocked_matrix_transpose_simd(const int16_t *src, int16_t *dst, size_t rows, size_t cols, size_t block_size) {\n    for (size_t i = 0; i < rows; i += block_size) {\n        for (size_t j = 0; j < cols; j += block_size) {\n            size_t block_rows = (i + block_size > rows) ? (rows - i) : block_size;\n            size_t block_cols = (j + block_size > cols) ? (cols - j) : block_size;\n\n            for (size_t bi = 0; bi < block_rows; ++bi) {\n                for (size_t bj = 0; bj < block_cols; bj += 8) {\n                    __m128i data = _mm_loadu_si128((__m128i*)&src[(i + bi) * cols + (j + bj)]);\n                    _mm_storeu_si128((__m128i*)&dst[(j + bj) * rows + (i + bi)], data);\n                }\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_6_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n\nvoid blocked_matrix_transpose_simd(const int16_t *src, int16_t *dst, size_t rows, size_t cols, size_t block_size) {\n    for (size_t i = 0; i < rows; i += block_size) {\n        for (size_t j = 0; j < cols; j += block_size) {\n            size_t block_rows = (i + block_size > rows) ? (rows - i) : block_size;\n            size_t block_cols = (j + block_size > cols) ? (cols - j) : block_size;\n\n            for (size_t bi = 0; bi < block_rows; ++bi) {\n                for (size_t bj = 0; bj < block_cols; bj += 8) {\n                    __m128i data = _mm_loadu_si128((__m128i*)&src[(i + bi) * cols + j + bj]);\n                    _mm_storeu_si128((__m128i*)&dst[(j + bj) * rows + i + bi], data);\n                }\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_6_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid blocked_matrix_transpose_simd(const int16_t *src, int16_t *dst, size_t rows, size_t cols, size_t block_size) {\n    for (size_t i = 0; i < rows; i += block_size) {\n        for (size_t j = 0; j < cols; j += block_size) {\n            size_t block_rows = (i + block_size > rows) ? (rows - i) : block_size;\n            size_t block_cols = (j + block_size > cols) ? (cols - j) : block_size;\n\n            for (size_t bi = 0; bi < block_rows; ++bi) {\n                for (size_t bj = 0; bj < block_cols; bj += 8) {\n                    __m128i data = _mm_loadu_si128((__m128i*)&src[(i + bi) * cols + j + bj]);\n                    _mm_storeu_si128((__m128i*)&dst[(j + bj) * rows + i + bi], data);\n                }\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_6_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid blocked_matrix_transpose_simd(const int16_t *src, int16_t *dst, size_t rows, size_t cols, size_t block_size) {\n    for (size_t i = 0; i < rows; i += block_size) {\n        for (size_t j = 0; j < cols; j += block_size) {\n            size_t block_rows = (i + block_size > rows) ? (rows - i) : block_size;\n            size_t block_cols = (j + block_size > cols) ? (cols - j) : block_size;\n\n            for (size_t bi = 0; bi < block_rows; ++bi) {\n                for (size_t bj = 0; bj < block_cols; bj += 8) {\n                    __m128i data = _mm_loadu_si128((__m128i*)&src[(i + bi) * cols + (j + bj)]);\n                    _mm_storeu_si128((__m128i*)&dst[(j + bj) * rows + (i + bi)], data);\n                }\n            }\n\n            // Handle remaining columns if block_cols is not a multiple of 8\n            for (size_t bi = 0; bi < block_rows; ++bi) {\n                for (size_t bj = (block_cols / 8) * 8; bj < block_cols; ++bj) {\n                    dst[(j + bj) * rows + (i + bi)] = src[(i + bi) * cols + (j + bj)];\n                }\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_7_SSE", "completion": "```cpp\nfloat diagonal_sum_3d_simd(const float *array, size_t dim) {\n    __m128 simd_sum = _mm_setzero_ps();\n    size_t i = 0;\n\n    // Process 4 elements at a time\n    for (; i + 3 < dim; i += 4) {\n        __m128 diag_elements = _mm_set_ps(\n            array[(i + 3) * dim * dim + (i + 3) * dim + (i + 3)],\n            array[(i + 2) * dim * dim + (i + 2) * dim + (i + 2)],\n            array[(i + 1) * dim * dim + (i + 1) * dim + (i + 1)],\n            array[i * dim * dim + i * dim + i]\n        );\n        simd_sum = _mm_add_ps(simd_sum, diag_elements);\n    }\n\n    // Horizontal sum of the SIMD register\n    float partial_sums[4];\n    _mm_storeu_ps(partial_sums, simd_sum);\n    float total_sum = partial_sums[0] + partial_sums[1] + partial_sums[2] + partial_sums[3];\n\n    // Handle remaining elements\n    for (; i < dim; ++i) {\n        total_sum += array[i * dim * dim + i * dim + i];\n    }\n\n    return total_sum;\n}\n```"}
{"task_id": "SimdBench_7_SSE", "completion": "```cpp\nfloat diagonal_sum_3d_simd(const float *array, size_t dim) {\n    __m128 simd_sum = _mm_setzero_ps();\n    size_t i = 0;\n\n    // Process 4 elements at a time\n    for (; i + 3 < dim; i += 4) {\n        __m128 diag_elements = _mm_set_ps(\n            array[(i + 3) * dim * dim + (i + 3) * dim + (i + 3)],\n            array[(i + 2) * dim * dim + (i + 2) * dim + (i + 2)],\n            array[(i + 1) * dim * dim + (i + 1) * dim + (i + 1)],\n            array[i * dim * dim + i * dim + i]\n        );\n        simd_sum = _mm_add_ps(simd_sum, diag_elements);\n    }\n\n    // Horizontal sum of the SIMD register\n    float partial_sums[4];\n    _mm_storeu_ps(partial_sums, simd_sum);\n    float total_sum = partial_sums[0] + partial_sums[1] + partial_sums[2] + partial_sums[3];\n\n    // Handle remaining elements\n    for (; i < dim; ++i) {\n        total_sum += array[i * dim * dim + i * dim + i];\n    }\n\n    return total_sum;\n}\n```"}
{"task_id": "SimdBench_7_SSE", "completion": "```cpp\nfloat diagonal_sum_3d_simd(const float *array, size_t dim) {\n    __m128 vsum = _mm_setzero_ps();\n    size_t i = 0;\n\n    // Process 4 elements at a time\n    for (; i + 3 < dim; i += 4) {\n        // Load 4 diagonal elements from the array\n        __m128 vdiag = _mm_loadu_ps(&array[i * dim * dim + i * dim + i]);\n        // Accumulate into vsum\n        vsum = _mm_add_ps(vsum, vdiag);\n    }\n\n    // Horizontal sum of the accumulated SSE register\n    float sum = 0.0f;\n    float temp[4];\n    _mm_storeu_ps(temp, vsum);\n    sum = temp[0] + temp[1] + temp[2] + temp[3];\n\n    // Process remaining elements (if dim is not a multiple of 4)\n    for (; i < dim; ++i) {\n        sum += array[i * dim * dim + i * dim + i];\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_7_SSE", "completion": "```cpp\nfloat diagonal_sum_3d_simd(const float *array, size_t dim) {\n    __m128 simd_sum = _mm_setzero_ps();\n    size_t i = 0;\n\n    // Process 4 elements at a time\n    for (; i + 3 < dim; i += 4) {\n        __m128 diag_elements = _mm_set_ps(\n            array[(i + 3) * dim * dim + (i + 3) * dim + (i + 3)],\n            array[(i + 2) * dim * dim + (i + 2) * dim + (i + 2)],\n            array[(i + 1) * dim * dim + (i + 1) * dim + (i + 1)],\n            array[i * dim * dim + i * dim + i]\n        );\n        simd_sum = _mm_add_ps(simd_sum, diag_elements);\n    }\n\n    // Horizontal sum of the SIMD register\n    float partial_sums[4];\n    _mm_storeu_ps(partial_sums, simd_sum);\n    float total_sum = partial_sums[0] + partial_sums[1] + partial_sums[2] + partial_sums[3];\n\n    // Process remaining elements\n    for (; i < dim; ++i) {\n        total_sum += array[i * dim * dim + i * dim + i];\n    }\n\n    return total_sum;\n}\n```"}
{"task_id": "SimdBench_7_SSE", "completion": "```cpp\nfloat diagonal_sum_3d_simd(const float *array, size_t dim) {\n    __m128 simd_sum = _mm_setzero_ps();\n    size_t i = 0;\n\n    // Process 4 elements at a time\n    for (; i + 3 < dim; i += 4) {\n        __m128 diag_elements = _mm_set_ps(\n            array[(i + 3) * dim * dim + (i + 3) * dim + (i + 3)],\n            array[(i + 2) * dim * dim + (i + 2) * dim + (i + 2)],\n            array[(i + 1) * dim * dim + (i + 1) * dim + (i + 1)],\n            array[i * dim * dim + i * dim + i]\n        );\n        simd_sum = _mm_add_ps(simd_sum, diag_elements);\n    }\n\n    // Horizontal sum of the SIMD register\n    float partial_sums[4];\n    _mm_storeu_ps(partial_sums, simd_sum);\n    float total_sum = partial_sums[0] + partial_sums[1] + partial_sums[2] + partial_sums[3];\n\n    // Handle remaining elements\n    for (; i < dim; ++i) {\n        total_sum += array[i * dim * dim + i * dim + i];\n    }\n\n    return total_sum;\n}\n```"}
{"task_id": "SimdBench_8_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid conditional_scale_simd(const double *src, double *dst, size_t rows, size_t cols, double threshold, double scale) {\n    __m128d v_threshold = _mm_set1_pd(threshold);\n    __m128d v_scale = _mm_set1_pd(scale);\n\n    size_t simd_width = 2; // SSE2 processes two doubles at a time\n    size_t total_elements = rows * cols;\n\n    size_t i = 0;\n    for (; i + simd_width <= total_elements; i += simd_width) {\n        __m128d v_src = _mm_loadu_pd(&src[i]);\n        __m128d v_cmp = _mm_cmpgt_pd(v_src, v_threshold);\n        __m128d v_scaled = _mm_mul_pd(v_src, v_scale);\n        __m128d v_result = _mm_blendv_pd(v_src, v_scaled, v_cmp);\n        _mm_storeu_pd(&dst[i], v_result);\n    }\n\n    // Handle remaining elements\n    for (; i < total_elements; ++i) {\n        if (src[i] > threshold) {\n            dst[i] = src[i] * scale;\n        } else {\n            dst[i] = src[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_8_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid conditional_scale_simd(const double *src, double *dst, size_t rows, size_t cols, double threshold, double scale) {\n    __m128d v_threshold = _mm_set1_pd(threshold);\n    __m128d v_scale = _mm_set1_pd(scale);\n\n    size_t simd_width = 2; // SSE/SSE2 processes 2 doubles at a time\n    size_t total_elements = rows * cols;\n\n    size_t i = 0;\n    for (; i + simd_width <= total_elements; i += simd_width) {\n        __m128d v_src = _mm_loadu_pd(&src[i]); // Load 2 doubles from src\n        __m128d v_cmp = _mm_cmpgt_pd(v_src, v_threshold); // Compare if src > threshold\n        __m128d v_scaled = _mm_mul_pd(v_src, v_scale); // Scale the values\n        __m128d v_result = _mm_blendv_pd(v_src, v_scaled, v_cmp); // Blend based on comparison\n        _mm_storeu_pd(&dst[i], v_result); // Store 2 doubles to dst\n    }\n\n    // Handle remaining elements (if any)\n    for (; i < total_elements; ++i) {\n        if (src[i] > threshold) {\n            dst[i] = src[i] * scale;\n        } else {\n            dst[i] = src[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_8_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid conditional_scale_simd(const double *src, double *dst, size_t rows, size_t cols, double threshold, double scale) {\n    __m128d v_threshold = _mm_set1_pd(threshold);\n    __m128d v_scale = _mm_set1_pd(scale);\n\n    for (size_t i = 0; i < rows; ++i) {\n        size_t j = 0;\n        for (; j + 2 <= cols; j += 2) {\n            __m128d v_src = _mm_loadu_pd(&src[i * cols + j]);\n            __m128d v_cmp = _mm_cmpgt_pd(v_src, v_threshold);\n            __m128d v_scaled = _mm_mul_pd(v_src, v_scale);\n            __m128d v_result = _mm_blendv_pd(v_src, v_scaled, v_cmp);\n            _mm_storeu_pd(&dst[i * cols + j], v_result);\n        }\n        for (; j < cols; ++j) {\n            if (src[i * cols + j] > threshold) {\n                dst[i * cols + j] = src[i * cols + j] * scale;\n            } else {\n                dst[i * cols + j] = src[i * cols + j];\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_8_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid conditional_scale_simd(const double *src, double *dst, size_t rows, size_t cols, double threshold, double scale) {\n    __m128d v_threshold = _mm_set1_pd(threshold);\n    __m128d v_scale = _mm_set1_pd(scale);\n\n    size_t simd_width = 2; // SSE2 processes two doubles at a time\n    size_t total_elements = rows * cols;\n    size_t simd_aligned_elements = total_elements - (total_elements % simd_width);\n\n    size_t i = 0;\n\n    // Process elements in chunks of 2 using SSE2 intrinsics\n    for (; i < simd_aligned_elements; i += simd_width) {\n        __m128d v_src = _mm_loadu_pd(&src[i]); // Load two doubles from src\n        __m128d v_cmp = _mm_cmpgt_pd(v_src, v_threshold); // Compare if src > threshold\n        __m128d v_scaled = _mm_mul_pd(v_src, v_scale); // Scale the values\n        __m128d v_result = _mm_blendv_pd(v_src, v_scaled, v_cmp); // Blend based on comparison\n        _mm_storeu_pd(&dst[i], v_result); // Store the result into dst\n    }\n\n    // Process remaining elements that don't fit into SIMD width\n    for (; i < total_elements; ++i) {\n        if (src[i] > threshold) {\n            dst[i] = src[i] * scale;\n        } else {\n            dst[i] = src[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_8_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n\nvoid conditional_scale_simd(const double *src, double *dst, size_t rows, size_t cols, double threshold, double scale) {\n    __m128d v_threshold = _mm_set1_pd(threshold);\n    __m128d v_scale = _mm_set1_pd(scale);\n\n    size_t simd_width = 2; // SSE2 processes two doubles at a time\n    size_t total_elements = rows * cols;\n\n    size_t i = 0;\n    for (; i + simd_width <= total_elements; i += simd_width) {\n        __m128d v_src = _mm_loadu_pd(&src[i]);\n        __m128d v_cmp = _mm_cmpgt_pd(v_src, v_threshold); // Compare src > threshold\n        __m128d v_scaled = _mm_mul_pd(v_src, v_scale);    // Scale src by scale factor\n        __m128d v_result = _mm_blendv_pd(v_src, v_scaled, v_cmp); // Blend based on comparison\n        _mm_storeu_pd(&dst[i], v_result);\n    }\n\n    // Handle remaining elements (if any)\n    for (; i < total_elements; ++i) {\n        if (src[i] > threshold) {\n            dst[i] = src[i] * scale;\n        } else {\n            dst[i] = src[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_9_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid reorder_matrix_rows_simd(const double *src, double *dst, size_t rows, size_t cols, const size_t *indices) {\n    size_t simd_width = 2; // SSE2 processes 2 doubles at a time (128-bit register)\n    __m128d vec;\n\n    for (size_t i = 0; i < rows; ++i) {\n        size_t src_row_start = indices[i] * cols;\n        size_t dst_row_start = i * cols;\n\n        size_t j = 0;\n\n        // Process columns in chunks of 2 using SIMD\n        for (; j + simd_width <= cols; j += simd_width) {\n            vec = _mm_loadu_pd(&src[src_row_start + j]); // Load 2 doubles from src\n            _mm_storeu_pd(&dst[dst_row_start + j], vec); // Store 2 doubles to dst\n        }\n\n        // Process remaining columns (if any) with scalar code\n        for (; j < cols; ++j) {\n            dst[dst_row_start + j] = src[src_row_start + j];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_9_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid reorder_matrix_rows_simd(const double *src, double *dst, size_t rows, size_t cols, const size_t *indices) {\n    size_t simd_width = 2; // SSE/SSE2 processes 2 doubles at a time (128-bit registers)\n    size_t aligned_cols = (cols / simd_width) * simd_width;\n\n    for (size_t i = 0; i < rows; ++i) {\n        size_t src_row_idx = indices[i] * cols;\n        size_t dst_row_idx = i * cols;\n\n        // Process aligned columns using SIMD\n        size_t j = 0;\n        for (; j < aligned_cols; j += simd_width) {\n            __m128d src_vec = _mm_loadu_pd(&src[src_row_idx + j]);\n            _mm_storeu_pd(&dst[dst_row_idx + j], src_vec);\n        }\n\n        // Process remaining unaligned columns\n        for (; j < cols; ++j) {\n            dst[dst_row_idx + j] = src[src_row_idx + j];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_9_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid reorder_matrix_rows_simd(const double *src, double *dst, size_t rows, size_t cols, const size_t *indices) {\n    size_t simd_width = 2; // SSE/SSE2 processes 2 doubles at a time (128-bit register)\n    size_t aligned_cols = (cols / simd_width) * simd_width;\n\n    for (size_t i = 0; i < rows; ++i) {\n        size_t src_row_idx = indices[i] * cols;\n        size_t dst_row_idx = i * cols;\n\n        // Process aligned columns using SIMD\n        size_t j = 0;\n        for (; j < aligned_cols; j += simd_width) {\n            __m128d src_vec = _mm_loadu_pd(&src[src_row_idx + j]); // Load 2 doubles from src\n            _mm_storeu_pd(&dst[dst_row_idx + j], src_vec);         // Store 2 doubles to dst\n        }\n\n        // Process remaining unaligned columns\n        for (; j < cols; ++j) {\n            dst[dst_row_idx + j] = src[src_row_idx + j];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_9_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid reorder_matrix_rows_simd(const double *src, double *dst, size_t rows, size_t cols, const size_t *indices) {\n    size_t simd_width = 2; // SSE/SSE2 processes 2 doubles at a time (128-bit registers)\n    size_t aligned_cols = (cols / simd_width) * simd_width;\n\n    for (size_t i = 0; i < rows; ++i) {\n        size_t src_row_idx = indices[i] * cols;\n        size_t dst_row_idx = i * cols;\n\n        // Process aligned columns using SIMD\n        size_t j = 0;\n        for (; j < aligned_cols; j += simd_width) {\n            __m128d src_vec = _mm_loadu_pd(&src[src_row_idx + j]); // Load 2 doubles from src\n            _mm_storeu_pd(&dst[dst_row_idx + j], src_vec);         // Store 2 doubles to dst\n        }\n\n        // Process remaining columns (if any) using scalar operations\n        for (; j < cols; ++j) {\n            dst[dst_row_idx + j] = src[src_row_idx + j];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_9_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid reorder_matrix_rows_simd(const double *src, double *dst, size_t rows, size_t cols, const size_t *indices) {\n    size_t simd_width = 2; // SSE/SSE2 processes 2 doubles at a time (128-bit registers)\n    __m128d vec;\n\n    for (size_t i = 0; i < rows; ++i) {\n        size_t src_row_start = indices[i] * cols;\n        size_t dst_row_start = i * cols;\n\n        // Process cols in chunks of 2 (SIMD width)\n        size_t j = 0;\n        for (; j + simd_width <= cols; j += simd_width) {\n            vec = _mm_loadu_pd(&src[src_row_start + j]); // Load 2 doubles from src\n            _mm_storeu_pd(&dst[dst_row_start + j], vec); // Store 2 doubles to dst\n        }\n\n        // Handle remaining elements (if cols is not a multiple of simd_width)\n        for (; j < cols; ++j) {\n            dst[dst_row_start + j] = src[src_row_start + j];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_10_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid vector_vector_add_simd(const int64_t *src1, const int64_t *src2, int64_t *dst, int64_t scalar, size_t length) {\n    __m128i v_scalar = _mm_set1_epi64x(scalar); // Broadcast scalar to all elements of the SIMD register\n    __m128i v_two = _mm_set1_epi64x(2);         // Constant 2 for division\n\n    size_t i = 0;\n    for (; i + 2 <= length; i += 2) {\n        // Load two 64-bit integers from src1 and src2\n        __m128i v_src1 = _mm_loadu_si128((__m128i*)&src1[i]);\n        __m128i v_src2 = _mm_loadu_si128((__m128i*)&src2[i]);\n\n        // Add src1 and src2 element-wise\n        __m128i v_sum = _mm_add_epi64(v_src1, v_src2);\n\n        // Add scalar to each element\n        v_sum = _mm_add_epi64(v_sum, v_scalar);\n\n        // Divide by 2 (shift right by 1 bit)\n        __m128i v_result = _mm_srai_epi64(v_sum, 1);\n\n        // Store the result into dst\n        _mm_storeu_si128((__m128i*)&dst[i], v_result);\n    }\n\n    // Handle remaining elements (if length is odd)\n    for (; i < length; ++i) {\n        int64_t sum = src1[i] + src2[i] + scalar;\n        dst[i] = sum / 2;\n    }\n}\n```"}
{"task_id": "SimdBench_10_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid vector_vector_add_simd(const int64_t *src1, const int64_t *src2, int64_t *dst, int64_t scalar, size_t length) {\n    __m128i v_scalar = _mm_set1_epi64x(scalar); // Broadcast scalar to all elements of the SIMD register\n    __m128i v_two = _mm_set1_epi64x(2);         // Constant 2 for division\n\n    size_t i = 0;\n    for (; i + 2 <= length; i += 2) {\n        // Load two 64-bit integers from src1 and src2\n        __m128i v_src1 = _mm_loadu_si128((__m128i*)&src1[i]);\n        __m128i v_src2 = _mm_loadu_si128((__m128i*)&src2[i]);\n\n        // Add src1 and src2 element-wise\n        __m128i v_sum = _mm_add_epi64(v_src1, v_src2);\n\n        // Add scalar to each element\n        v_sum = _mm_add_epi64(v_sum, v_scalar);\n\n        // Divide by 2 (shift right by 1 for round-toward-zero)\n        __m128i v_result = _mm_div_epi64_round_zero(v_sum, v_two);\n\n        // Store the result into dst\n        _mm_storeu_si128((__m128i*)&dst[i], v_result);\n    }\n\n    // Handle remaining elements (if length is odd)\n    for (; i < length; ++i) {\n        int64_t sum = src1[i] + src2[i] + scalar;\n        dst[i] = sum / 2;\n    }\n}\n```"}
{"task_id": "SimdBench_10_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid vector_vector_add_simd(const int64_t *src1, const int64_t *src2, int64_t *dst, int64_t scalar, size_t length) {\n    __m128i v_scalar = _mm_set1_epi64x(scalar); // Broadcast scalar to all elements of the SIMD register\n    size_t i = 0;\n\n    // Process 2 elements at a time (128-bit register for 64-bit integers)\n    for (; i + 1 < length; i += 2) {\n        __m128i v_src1 = _mm_loadu_si128((__m128i*)&src1[i]); // Load 2 integers from src1\n        __m128i v_src2 = _mm_loadu_si128((__m128i*)&src2[i]); // Load 2 integers from src2\n\n        __m128i v_sum = _mm_add_epi64(v_src1, v_src2);       // Add src1 and src2 element-wise\n        v_sum = _mm_add_epi64(v_sum, v_scalar);              // Add scalar to each element\n\n        // Divide by 2 using arithmetic right shift (round-toward-zero for signed integers)\n        __m128i v_result = _mm_srai_epi64(v_sum, 1);\n\n        _mm_storeu_si128((__m128i*)&dst[i], v_result);       // Store the result in dst\n    }\n\n    // Handle remaining elements (if length is odd)\n    for (; i < length; ++i) {\n        int64_t sum = src1[i] + src2[i] + scalar;\n        dst[i] = sum / 2; // Integer division rounds toward zero\n    }\n}\n```"}
{"task_id": "SimdBench_10_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid vector_vector_add_simd(const int64_t *src1, const int64_t *src2, int64_t *dst, int64_t scalar, size_t length) {\n    __m128i vscalar = _mm_set1_epi64x(scalar); // Broadcast scalar to all elements of the SIMD register\n    __m128i vtwo = _mm_set1_epi64x(2);         // Constant 2 for division\n\n    size_t i = 0;\n    for (; i + 2 <= length; i += 2) {\n        // Load two 64-bit integers from src1 and src2 into SIMD registers\n        __m128i vsrc1 = _mm_loadu_si128((__m128i*)&src1[i]);\n        __m128i vsrc2 = _mm_loadu_si128((__m128i*)&src2[i]);\n\n        // Perform element-wise addition of src1 and src2\n        __m128i vsum = _mm_add_epi64(vsrc1, vsrc2);\n\n        // Add the scalar value to each element of the result\n        vsum = _mm_add_epi64(vsum, vscalar);\n\n        // Divide the result by 2 (round-toward-zero)\n        __m128i vresult = _mm_div_epi64_round_to_zero(vsum, vtwo);\n\n        // Store the result into the destination array\n        _mm_storeu_si128((__m128i*)&dst[i], vresult);\n    }\n\n    // Handle any remaining elements that don't fit into a full SIMD register\n    for (; i < length; ++i) {\n        int64_t sum = src1[i] + src2[i] + scalar;\n        dst[i] = sum / 2;\n    }\n}\n```"}
{"task_id": "SimdBench_10_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid vector_vector_add_simd(const int64_t *src1, const int64_t *src2, int64_t *dst, int64_t scalar, size_t length) {\n    __m128i v_scalar = _mm_set1_epi64x(scalar); // Broadcast scalar to all elements of the SIMD register\n    __m128i v_two = _mm_set1_epi64x(2);         // Constant 2 for division\n\n    size_t i = 0;\n\n    // Process two 64-bit integers per iteration using SSE2\n    for (; i + 1 < length; i += 2) {\n        __m128i v_src1 = _mm_loadu_si128((__m128i*)&src1[i]); // Load 2 integers from src1\n        __m128i v_src2 = _mm_loadu_si128((__m128i*)&src2[i]); // Load 2 integers from src2\n\n        __m128i v_sum = _mm_add_epi64(v_src1, v_src2);       // Add src1 and src2 element-wise\n        v_sum = _mm_add_epi64(v_sum, v_scalar);              // Add scalar to each element\n\n        // Divide by 2 (round-toward-zero)\n        __m128i v_shifted = _mm_srai_epi64(_mm_add_epi64(v_sum, v_two), 1);\n\n        _mm_storeu_si128((__m128i*)&dst[i], v_shifted);      // Store result in dst\n    }\n\n    // Handle remaining elements (if length is odd)\n    for (; i < length; ++i) {\n        int64_t sum = src1[i] + src2[i] + scalar;\n        dst[i] = sum / 2; // Integer division (round-toward-zero)\n    }\n}\n```"}
{"task_id": "SimdBench_11_SSE", "completion": "```cpp\nint vector_even_min_simd(const int *src, size_t length) {\n    if (length == 0) return -1;\n\n    __m128i min_vec = _mm_set1_epi32(INT32_MAX);\n    size_t i = 0;\n\n    // Process 4 elements at a time\n    for (; i + 4 <= length; i += 4) {\n        __m128i vec = _mm_loadu_si128((__m128i*)&src[i]);\n        __m128i even_mask = _mm_set_epi32(0, INT32_MAX, 0, INT32_MAX);\n        __m128i even_elements = _mm_and_si128(vec, even_mask);\n        min_vec = _mm_min_epi32(min_vec, even_elements);\n    }\n\n    // Extract the minimum from the SIMD register\n    int temp[4];\n    _mm_storeu_si128((__m128i*)temp, min_vec);\n\n    int min_val = INT32_MAX;\n    for (int j = 0; j < 4; ++j) {\n        if (temp[j] != 0 && temp[j] < min_val) {\n            min_val = temp[j];\n        }\n    }\n\n    // Handle remaining elements\n    for (; i < length; ++i) {\n        if (i % 2 == 0 && src[i] < min_val) {\n            min_val = src[i];\n        }\n    }\n\n    return min_val == INT32_MAX ? -1 : min_val;\n}\n```"}
{"task_id": "SimdBench_11_SSE", "completion": "```cpp\nint vector_even_min_simd(const int *src, size_t length) {\n    if (length == 0) return -1;\n\n    __m128i min_vec = _mm_set1_epi32(0x7FFFFFFF); // Initialize with max int\n    int min_val = 0x7FFFFFFF;\n    size_t i = 0;\n\n    // Process 4 elements at a time\n    for (; i + 4 <= length; i += 4) {\n        __m128i vec = _mm_loadu_si128((__m128i*)&src[i]);\n        __m128i even_mask = _mm_set_epi32(0, -1, 0, -1); // Mask to select even indices\n        __m128i even_elements = _mm_and_si128(vec, even_mask);\n        min_vec = _mm_min_epi32(min_vec, even_elements);\n    }\n\n    // Extract minimum from the SIMD register\n    int temp[4];\n    _mm_storeu_si128((__m128i*)temp, min_vec);\n    for (int j = 0; j < 4; ++j) {\n        if (temp[j] < min_val && temp[j] != 0) {\n            min_val = temp[j];\n        }\n    }\n\n    // Handle remaining elements\n    for (; i < length; ++i) {\n        if (i % 2 == 0 && src[i] < min_val) {\n            min_val = src[i];\n        }\n    }\n\n    return min_val == 0x7FFFFFFF ? -1 : min_val;\n}\n```"}
{"task_id": "SimdBench_11_SSE", "completion": "```cpp\nint vector_even_min_simd(const int *src, size_t length) {\n    if (length == 0) return -1;\n\n    __m128i min_vec = _mm_set1_epi32(INT32_MAX);\n    size_t i = 0;\n\n    // Process elements in chunks of 4 using SIMD\n    for (; i + 4 <= length; i += 4) {\n        __m128i vec = _mm_loadu_si128((__m128i*)&src[i]);\n        __m128i even_mask = _mm_set_epi32(0, INT32_MAX, 0, INT32_MAX);\n        __m128i even_elements = _mm_and_si128(vec, even_mask);\n        min_vec = _mm_min_epi32(min_vec, even_elements);\n    }\n\n    // Extract the minimum value from the SIMD register\n    int min_val = INT32_MAX;\n    int temp[4];\n    _mm_storeu_si128((__m128i*)temp, min_vec);\n    for (int j = 0; j < 4; ++j) {\n        if (temp[j] != 0 && temp[j] < min_val) {\n            min_val = temp[j];\n        }\n    }\n\n    // Handle remaining elements\n    for (; i < length; ++i) {\n        if (i % 2 == 0 && src[i] < min_val) {\n            min_val = src[i];\n        }\n    }\n\n    return min_val == INT32_MAX ? -1 : min_val;\n}\n```"}
{"task_id": "SimdBench_11_SSE", "completion": "```cpp\nint vector_even_min_simd(const int *src, size_t length) {\n    if (length == 0) return -1;\n\n    __m128i min_vec = _mm_set1_epi32(INT32_MAX);\n    size_t i = 0;\n\n    // Process elements in chunks of 4 using SIMD\n    for (; i + 4 <= length; i += 4) {\n        __m128i vec = _mm_loadu_si128((__m128i*)&src[i]);\n        __m128i even_mask = _mm_set_epi32(0, INT32_MAX, 0, INT32_MAX);\n        __m128i even_elements = _mm_and_si128(vec, even_mask);\n        min_vec = _mm_min_epi32(min_vec, even_elements);\n    }\n\n    // Extract the minimum value from the SIMD register\n    int temp[4];\n    _mm_storeu_si128((__m128i*)temp, min_vec);\n    int min_val = INT32_MAX;\n    for (int j = 0; j < 4; ++j) {\n        if (temp[j] != 0 && temp[j] < min_val) {\n            min_val = temp[j];\n        }\n    }\n\n    // Handle remaining elements\n    for (; i < length; ++i) {\n        if (i % 2 == 0 && src[i] < min_val) {\n            min_val = src[i];\n        }\n    }\n\n    return min_val == INT32_MAX ? -1 : min_val;\n}\n```"}
{"task_id": "SimdBench_11_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint vector_even_min_simd(const int *src, size_t length) {\n    if (length == 0) return -1;\n\n    __m128i min_vec = _mm_set1_epi32(INT32_MAX);\n    size_t i = 0;\n\n    // Process 4 elements at a time\n    for (; i + 4 <= length; i += 4) {\n        __m128i vec = _mm_loadu_si128((__m128i*)&src[i]);\n        __m128i even_mask = _mm_set_epi32(0, INT32_MAX, 0, INT32_MAX);\n        __m128i even_elements = _mm_and_si128(vec, even_mask);\n        min_vec = _mm_min_epi32(min_vec, even_elements);\n    }\n\n    // Horizontal minimum of the SIMD register\n    int temp[4];\n    _mm_storeu_si128((__m128i*)temp, min_vec);\n    int min_val = INT32_MAX;\n    for (int j = 0; j < 4; ++j) {\n        if (temp[j] != 0 && temp[j] < min_val) {\n            min_val = temp[j];\n        }\n    }\n\n    // Handle remaining elements\n    for (; i < length; ++i) {\n        if (i % 2 == 0 && src[i] < min_val) {\n            min_val = src[i];\n        }\n    }\n\n    return min_val == INT32_MAX ? -1 : min_val;\n}\n```"}
{"task_id": "SimdBench_12_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid mixed_right_shift_simd(const int *src, int *dst, uint8_t shift, size_t length) {\n    size_t i = 0;\n    __m128i vshift = _mm_set1_epi32(shift);\n\n    for (; i + 4 <= length; i += 4) {\n        // Load 4 integers from the source array\n        __m128i vsrc = _mm_loadu_si128((__m128i*)&src[i]);\n\n        // Arithmetic right shift\n        __m128i arshift = _mm_sra_epi32(vsrc, vshift);\n\n        // Logical right shift (convert to unsigned, shift, then convert back to signed)\n        __m128i ulogical = _mm_srli_epi32(_mm_castsi128_si128(vsrc), shift);\n        __m128i lrshift = _mm_castps_si128(_mm_castsi128_ps(ulogical));\n\n        // Add the results of arithmetic and logical shifts\n        __m128i result = _mm_add_epi32(arshift, lrshift);\n\n        // Store the result in the destination array\n        _mm_storeu_si128((__m128i*)&dst[i], result);\n    }\n\n    // Handle remaining elements\n    for (; i < length; ++i) {\n        int arshift = src[i] >> shift;\n        int lrshift = (unsigned int)(src[i]) >> shift;\n        dst[i] = arshift + lrshift;\n    }\n}\n```"}
{"task_id": "SimdBench_12_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n\nvoid mixed_right_shift_simd(const int *src, int *dst, uint8_t shift, size_t length) {\n    size_t i = 0;\n    __m128i vshift = _mm_set1_epi32(shift);\n\n    for (; i + 4 <= length; i += 4) {\n        // Load 4 integers from the source array\n        __m128i vsrc = _mm_loadu_si128((__m128i*)&src[i]);\n\n        // Arithmetic right shift\n        __m128i arshift = _mm_sra_epi32(vsrc, vshift);\n\n        // Logical right shift (convert to unsigned, shift, then convert back to signed)\n        __m128i ulogical = _mm_srli_epi32(_mm_castsi128_ps(vsrc), shift);\n        __m128i lrshift = _mm_castps_si128(_mm_castsi128_ps(ulogical));\n\n        // Add the results of arithmetic and logical shifts\n        __m128i result = _mm_add_epi32(arshift, lrshift);\n\n        // Store the result in the destination array\n        _mm_storeu_si128((__m128i*)&dst[i], result);\n    }\n\n    // Handle remaining elements\n    for (; i < length; ++i) {\n        int arshift = src[i] >> shift; // Arithmetic right shift\n        int lrshift = (unsigned int)(src[i]) >> shift; // Logical right shift\n        dst[i] = arshift + lrshift;\n    }\n}\n```"}
{"task_id": "SimdBench_12_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n\nvoid mixed_right_shift_simd(const int *src, int *dst, uint8_t shift, size_t length) {\n    size_t i = 0;\n    __m128i vshift = _mm_set1_epi32(shift);\n\n    for (; i + 4 <= length; i += 4) {\n        // Load 4 integers from the source array\n        __m128i vsrc = _mm_loadu_si128((__m128i*)&src[i]);\n\n        // Arithmetic right shift\n        __m128i arshift = _mm_sra_epi32(vsrc, vshift);\n\n        // Logical right shift (convert to unsigned, shift, then convert back to signed)\n        __m128i ulogical = _mm_srli_epi32(_mm_castsi128_ps(vsrc), shift);\n        __m128i lrshift = _mm_castps_si128(_mm_castsi128_ps(ulogical));\n\n        // Add the results of arithmetic and logical shifts\n        __m128i result = _mm_add_epi32(arshift, lrshift);\n\n        // Store the result in the destination array\n        _mm_storeu_si128((__m128i*)&dst[i], result);\n    }\n\n    // Handle remaining elements\n    for (; i < length; ++i) {\n        int arshift = src[i] >> shift;\n        int lrshift = (int)((unsigned int)src[i] >> shift);\n        dst[i] = arshift + lrshift;\n    }\n}\n```"}
{"task_id": "SimdBench_12_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid mixed_right_shift_simd(const int *src, int *dst, uint8_t shift, size_t length) {\n    size_t i = 0;\n    __m128i vshift = _mm_set1_epi32(shift); // Broadcast shift value to all elements of the vector\n\n    for (; i + 4 <= length; i += 4) {\n        // Load 4 integers from the source array\n        __m128i vsrc = _mm_loadu_si128((__m128i*)&src[i]);\n\n        // Arithmetic right shift\n        __m128i arshift = _mm_sra_epi32(vsrc, vshift);\n\n        // Logical right shift (convert to unsigned, shift, then convert back to signed)\n        __m128i ulogical = _mm_castps_si128(_mm_castsi128_ps(_mm_srli_epi32(vsrc, shift)));\n\n        // Add the results of arithmetic and logical shifts\n        __m128i result = _mm_add_epi32(arshift, ulogical);\n\n        // Store the result into the destination array\n        _mm_storeu_si128((__m128i*)&dst[i], result);\n    }\n\n    // Handle remaining elements (if any)\n    for (; i < length; ++i) {\n        int arshift = src[i] >> shift; // Arithmetic right shift\n        int lshift = (unsigned int)(src[i]) >> shift; // Logical right shift\n        dst[i] = arshift + lshift; // Add the results\n    }\n}\n```"}
{"task_id": "SimdBench_12_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid mixed_right_shift_simd(const int *src, int *dst, uint8_t shift, size_t length) {\n    size_t i = 0;\n    __m128i vshift = _mm_set1_epi32(shift);\n\n    for (; i + 4 <= length; i += 4) {\n        // Load 4 integers from the source array\n        __m128i vsrc = _mm_loadu_si128((__m128i*)&src[i]);\n\n        // Arithmetic right shift\n        __m128i arshift = _mm_sra_epi32(vsrc, vshift);\n\n        // Logical right shift (convert to unsigned, shift, then convert back to signed)\n        __m128i ulogical = _mm_srli_epi32(_mm_castsi128_ps(vsrc), shift);\n        __m128i lrshift = _mm_castps_si128(_mm_castsi128_ps(ulogical));\n\n        // Add the results of arithmetic and logical shifts\n        __m128i result = _mm_add_epi32(arshift, lrshift);\n\n        // Store the result into the destination array\n        _mm_storeu_si128((__m128i*)&dst[i], result);\n    }\n\n    // Handle remaining elements\n    for (; i < length; ++i) {\n        int arshift = src[i] >> shift; // Arithmetic right shift\n        int lrshift = (unsigned int)(src[i]) >> shift; // Logical right shift\n        dst[i] = arshift + lrshift;\n    }\n}\n```"}
{"task_id": "SimdBench_13_SSE", "completion": "```cpp\nint64_t matrix_sum_simd(const int *matrix, size_t rows, size_t cols) {\n    __m128i sum_vec = _mm_setzero_si128();\n    size_t i = 0;\n\n    // Process 4 elements at a time using SSE2\n    for (; i + 4 <= rows * cols; i += 4) {\n        __m128i vec = _mm_loadu_si128((__m128i*)&matrix[i]);\n        sum_vec = _mm_add_epi32(sum_vec, vec);\n    }\n\n    // Horizontal sum of the accumulated SIMD register\n    int temp[4];\n    _mm_storeu_si128((__m128i*)temp, sum_vec);\n    int64_t total_sum = temp[0] + temp[1] + temp[2] + temp[3];\n\n    // Add remaining elements that didn't fit into the SIMD processing\n    for (; i < rows * cols; ++i) {\n        total_sum += matrix[i];\n    }\n\n    return total_sum;\n}\n```"}
{"task_id": "SimdBench_13_SSE", "completion": "```cpp\nint64_t matrix_sum_simd(const int *matrix, size_t rows, size_t cols) {\n    __m128i sum_vec = _mm_setzero_si128();\n    size_t i = 0;\n\n    // Process 4 elements at a time using SSE\n    for (; i + 4 <= rows * cols; i += 4) {\n        __m128i vec = _mm_loadu_si128((__m128i*)&matrix[i]);\n        sum_vec = _mm_add_epi32(sum_vec, vec);\n    }\n\n    // Horizontal sum of the accumulated SIMD register\n    int temp[4];\n    _mm_storeu_si128((__m128i*)temp, sum_vec);\n    int64_t total_sum = temp[0] + temp[1] + temp[2] + temp[3];\n\n    // Add remaining elements that didn't fit into the SIMD processing\n    for (; i < rows * cols; ++i) {\n        total_sum += matrix[i];\n    }\n\n    return total_sum;\n}\n```"}
{"task_id": "SimdBench_13_SSE", "completion": "```cpp\nint64_t matrix_sum_simd(const int *matrix, size_t rows, size_t cols) {\n    __m128i sum_vec = _mm_setzero_si128();\n    size_t i = 0;\n\n    // Process 4 elements at a time using SSE\n    for (; i + 4 <= rows * cols; i += 4) {\n        __m128i vec = _mm_loadu_si128((__m128i*)&matrix[i]);\n        sum_vec = _mm_add_epi32(sum_vec, vec);\n    }\n\n    // Horizontal sum of the accumulated SIMD register\n    int temp[4];\n    _mm_storeu_si128((__m128i*)temp, sum_vec);\n    int64_t total_sum = temp[0] + temp[1] + temp[2] + temp[3];\n\n    // Add any remaining elements that didn't fit into the SIMD processing\n    for (; i < rows * cols; ++i) {\n        total_sum += matrix[i];\n    }\n\n    return total_sum;\n}\n```"}
{"task_id": "SimdBench_13_SSE", "completion": "```cpp\nint64_t matrix_sum_simd(const int *matrix, size_t rows, size_t cols) {\n    __m128i sum_vec = _mm_setzero_si128();\n    size_t total_elements = rows * cols;\n    size_t i = 0;\n\n    // Process 4 elements at a time using SSE\n    for (; i + 4 <= total_elements; i += 4) {\n        __m128i vec = _mm_loadu_si128((__m128i*)&matrix[i]);\n        sum_vec = _mm_add_epi32(sum_vec, vec);\n    }\n\n    // Horizontal sum of the accumulated SIMD register\n    int temp[4];\n    _mm_storeu_si128((__m128i*)temp, sum_vec);\n    int64_t sum = temp[0] + temp[1] + temp[2] + temp[3];\n\n    // Add remaining elements that didn't fit into the SIMD loop\n    for (; i < total_elements; ++i) {\n        sum += matrix[i];\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_13_SSE", "completion": "```cpp\nint64_t matrix_sum_simd(const int *matrix, size_t rows, size_t cols) {\n    __m128i sum_vec = _mm_setzero_si128();\n    size_t total_elements = rows * cols;\n    size_t i = 0;\n\n    // Process 4 elements at a time using SSE\n    for (; i + 4 <= total_elements; i += 4) {\n        __m128i vec = _mm_loadu_si128((__m128i*)&matrix[i]);\n        sum_vec = _mm_add_epi32(sum_vec, vec);\n    }\n\n    // Horizontal sum of the accumulated vector\n    int temp[4];\n    _mm_storeu_si128((__m128i*)temp, sum_vec);\n    int64_t sum = temp[0] + temp[1] + temp[2] + temp[3];\n\n    // Add remaining elements\n    for (; i < total_elements; ++i) {\n        sum += matrix[i];\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_14_SSE", "completion": "```cpp\nsize_t argmax_simd(const int8_t *src, size_t length) {\n    if (length == 0) return 0;\n\n    size_t i = 0;\n    size_t max_idx = 0;\n    int8_t max_val = src[0];\n\n    // Process up to the first 16-byte boundary\n    for (; i < length && (i % 16 != 0); ++i) {\n        if (src[i] > max_val) {\n            max_val = src[i];\n            max_idx = i;\n        }\n    }\n\n    // Load the current maximum value into a SIMD register\n    __m128i max_vec = _mm_set1_epi8(max_val);\n\n    // Process 16 elements at a time using SIMD\n    for (; i + 16 <= length; i += 16) {\n        __m128i data = _mm_loadu_si128((__m128i*)&src[i]);\n        __m128i cmp = _mm_cmpgt_epi8(data, max_vec);\n        int mask = _mm_movemask_epi8(cmp);\n\n        if (mask != 0) {\n            // Find the first index where the value is greater than max_val\n            int bit_pos = __builtin_ctz(mask);\n            max_val = src[i + bit_pos];\n            max_idx = i + bit_pos;\n            max_vec = _mm_set1_epi8(max_val);\n        }\n    }\n\n    // Process any remaining elements\n    for (; i < length; ++i) {\n        if (src[i] > max_val) {\n            max_val = src[i];\n            max_idx = i;\n        }\n    }\n\n    return max_idx;\n}\n```"}
{"task_id": "SimdBench_14_SSE", "completion": "```cpp\nsize_t argmax_simd(const int8_t *src, size_t length) {\n    if (length == 0) return 0;\n\n    __m128i max_vals = _mm_set1_epi8(-128); // Initialize to smallest possible value\n    __m128i indices = _mm_setzero_si128();\n    __m128i increment = _mm_set1_epi8(16);\n    __m128i current_indices = _mm_setr_epi8(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15);\n\n    size_t i = 0;\n    for (; i + 15 < length; i += 16) {\n        __m128i src_vals = _mm_loadu_si128((__m128i*)&src[i]);\n        __m128i cmp = _mm_cmpgt_epi8(src_vals, max_vals);\n        max_vals = _mm_blendv_epi8(max_vals, src_vals, cmp);\n        indices = _mm_blendv_epi8(indices, current_indices, cmp);\n        current_indices = _mm_add_epi8(current_indices, increment);\n    }\n\n    // Find the maximum value in the vector\n    int8_t temp[16];\n    _mm_storeu_si128((__m128i*)temp, max_vals);\n\n    size_t max_index = 0;\n    int8_t max_val = -128;\n    for (size_t j = 0; j < 16; ++j) {\n        if (temp[j] > max_val) {\n            max_val = temp[j];\n            max_index = i + j;\n        }\n    }\n\n    // Compare remaining elements\n    for (; i < length; ++i) {\n        if (src[i] > max_val) {\n            max_val = src[i];\n            max_index = i;\n        }\n    }\n\n    return max_index;\n}\n```"}
{"task_id": "SimdBench_14_SSE", "completion": "```cpp\nsize_t argmax_simd(const int8_t *src, size_t length) {\n    if (length == 0) return 0;\n\n    __m128i max_vals = _mm_set1_epi8(-128); // Initialize to smallest possible value\n    __m128i indices = _mm_setzero_si128();\n    __m128i increment = _mm_set1_epi8(16);\n    __m128i current_indices = _mm_setr_epi8(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15);\n\n    size_t i = 0;\n    for (; i + 16 <= length; i += 16) {\n        __m128i src_vals = _mm_loadu_si128((__m128i const*)(src + i));\n        __m128i mask = _mm_cmpgt_epi8(src_vals, max_vals);\n        max_vals = _mm_max_epi8(max_vals, src_vals);\n        indices = _mm_blendv_epi8(indices, current_indices, mask);\n        current_indices = _mm_add_epi8(current_indices, increment);\n    }\n\n    // Extract the maximum value and its index from the SIMD register\n    int8_t temp[16];\n    _mm_storeu_si128((__m128i*)temp, max_vals);\n    int8_t temp_indices[16];\n    _mm_storeu_si128((__m128i*)temp_indices, indices);\n\n    int8_t max_val = -128;\n    size_t max_index = 0;\n    for (int j = 0; j < 16; ++j) {\n        if (temp[j] > max_val) {\n            max_val = temp[j];\n            max_index = temp_indices[j];\n        }\n    }\n\n    // Check remaining elements\n    for (; i < length; ++i) {\n        if (src[i] > max_val) {\n            max_val = src[i];\n            max_index = i;\n        }\n    }\n\n    return max_index;\n}\n```"}
{"task_id": "SimdBench_14_SSE", "completion": "```cpp\nsize_t argmax_simd(const int8_t *src, size_t length) {\n    if (length == 0) return 0;\n\n    __m128i max_vals = _mm_set1_epi8(-128); // Initialize to lowest possible value\n    __m128i indices = _mm_setzero_si128();\n    __m128i increment = _mm_set1_epi8(16);\n    __m128i initial_indices = _mm_setr_epi8(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15);\n\n    size_t i = 0;\n    for (; i + 16 <= length; i += 16) {\n        __m128i data = _mm_loadu_si128((__m128i*)&src[i]);\n        __m128i cmp = _mm_cmpgt_epi8(data, max_vals);\n        max_vals = _mm_max_epi8(max_vals, data);\n        indices = _mm_blendv_epi8(indices, _mm_add_epi8(initial_indices, _mm_set1_epi8(i)), cmp);\n    }\n\n    // Extract the maximum value and its index from the SIMD register\n    int8_t temp[16];\n    _mm_storeu_si128((__m128i*)temp, max_vals);\n    int8_t temp_indices[16];\n    _mm_storeu_si128((__m128i*)temp_indices, indices);\n\n    int8_t max_val = -128;\n    size_t max_index = 0;\n    for (int j = 0; j < 16; ++j) {\n        if (temp[j] > max_val) {\n            max_val = temp[j];\n            max_index = temp_indices[j];\n        }\n    }\n\n    // Process remaining elements\n    for (; i < length; ++i) {\n        if (src[i] > max_val) {\n            max_val = src[i];\n            max_index = i;\n        }\n    }\n\n    return max_index;\n}\n```"}
{"task_id": "SimdBench_14_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nsize_t argmax_simd(const int8_t *src, size_t length) {\n    if (length == 0) return 0;\n\n    size_t i = 0;\n    size_t max_idx = 0;\n    int8_t max_val = src[0];\n\n    // Process up to 16 elements at a time using SSE2\n    __m128i max_vec = _mm_set1_epi8(max_val);\n    __m128i idx_vec = _mm_setr_epi8(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15);\n    __m128i max_idx_vec = _mm_setzero_si128();\n\n    for (; i + 16 <= length; i += 16) {\n        __m128i src_vec = _mm_loadu_si128((__m128i const*)(src + i));\n        __m128i cmp_mask = _mm_cmpgt_epi8(src_vec, max_vec);\n\n        max_idx_vec = _mm_blendv_epi8(max_idx_vec, idx_vec, cmp_mask);\n        max_vec = _mm_max_epi8(max_vec, src_vec);\n\n        idx_vec = _mm_add_epi8(idx_vec, _mm_set1_epi8(16));\n    }\n\n    // Extract the maximum value and index from the vector\n    int8_t temp[16];\n    _mm_storeu_si128((__m128i*)temp, max_vec);\n    uint8_t temp_idx[16];\n    _mm_storeu_si128((__m128i*)temp_idx, max_idx_vec);\n\n    for (int j = 0; j < 16; ++j) {\n        if (temp[j] > max_val) {\n            max_val = temp[j];\n            max_idx = i - 16 + temp_idx[j];\n        }\n    }\n\n    // Process remaining elements\n    for (; i < length; ++i) {\n        if (src[i] > max_val) {\n            max_val = src[i];\n            max_idx = i;\n        }\n    }\n\n    return max_idx;\n}\n```"}
{"task_id": "SimdBench_15_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid vector_blend_simd(const uint16_t* src1, const uint16_t* src2, uint32_t mask, uint16_t* dst, size_t length) {\n    size_t i = 0;\n\n    // Process 8 elements at a time using SSE2 intrinsics\n    for (; i + 8 <= length; i += 8) {\n        // Load 8 elements from src1 and src2 into SIMD registers\n        __m128i src1_vec = _mm_loadu_si128((__m128i*)&src1[i]);\n        __m128i src2_vec = _mm_loadu_si128((__m128i*)&src2[i]);\n\n        // Create a mask based on the index and the given mask\n        __m128i index_mask = _mm_set_epi16(\n            ((i + 7) & mask) ? 0xFFFF : 0,\n            ((i + 6) & mask) ? 0xFFFF : 0,\n            ((i + 5) & mask) ? 0xFFFF : 0,\n            ((i + 4) & mask) ? 0xFFFF : 0,\n            ((i + 3) & mask) ? 0xFFFF : 0,\n            ((i + 2) & mask) ? 0xFFFF : 0,\n            ((i + 1) & mask) ? 0xFFFF : 0,\n            ((i + 0) & mask) ? 0xFFFF : 0\n        );\n\n        // Blend the two vectors based on the computed mask\n        __m128i blended = _mm_or_si128(\n            _mm_and_si128(index_mask, src1_vec),\n            _mm_andnot_si128(index_mask, src2_vec)\n        );\n\n        // Store the result in the destination array\n        _mm_storeu_si128((__m128i*)&dst[i], blended);\n    }\n\n    // Handle any remaining elements that don't fit into an 8-element block\n    for (; i < length; ++i) {\n        dst[i] = ((i & mask) != 0) ? src1[i] : src2[i];\n    }\n}\n```"}
{"task_id": "SimdBench_15_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid vector_blend_simd(const uint16_t* src1, const uint16_t* src2, uint32_t mask, uint16_t* dst, size_t length) {\n    size_t i = 0;\n\n    // Process 8 elements at a time using SSE2 intrinsics\n    for (; i + 8 <= length; i += 8) {\n        // Load 8 elements from src1 and src2 into SIMD registers\n        __m128i src1_vec = _mm_loadu_si128((__m128i*)&src1[i]);\n        __m128i src2_vec = _mm_loadu_si128((__m128i*)&src2[i]);\n\n        // Create a mask based on the index and the given mask\n        __m128i index_mask = _mm_set_epi16(\n            ((i + 7) & mask) ? 0xFFFF : 0,\n            ((i + 6) & mask) ? 0xFFFF : 0,\n            ((i + 5) & mask) ? 0xFFFF : 0,\n            ((i + 4) & mask) ? 0xFFFF : 0,\n            ((i + 3) & mask) ? 0xFFFF : 0,\n            ((i + 2) & mask) ? 0xFFFF : 0,\n            ((i + 1) & mask) ? 0xFFFF : 0,\n            ((i + 0) & mask) ? 0xFFFF : 0\n        );\n\n        // Blend the two vectors based on the mask\n        __m128i result = _mm_or_si128(\n            _mm_and_si128(index_mask, src1_vec),\n            _mm_andnot_si128(index_mask, src2_vec)\n        );\n\n        // Store the result in the destination array\n        _mm_storeu_si128((__m128i*)&dst[i], result);\n    }\n\n    // Handle any remaining elements\n    for (; i < length; ++i) {\n        dst[i] = ((i & mask) != 0) ? src1[i] : src2[i];\n    }\n}\n```"}
{"task_id": "SimdBench_15_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid vector_blend_simd(const uint16_t* src1, const uint16_t* src2, uint32_t mask, uint16_t* dst, size_t length) {\n    size_t i = 0;\n\n    // Process 8 elements at a time using SSE2 intrinsics\n    for (; i + 8 <= length; i += 8) {\n        // Load 8 elements from src1 and src2 into SIMD registers\n        __m128i src1_vec = _mm_loadu_si128((__m128i*)&src1[i]);\n        __m128i src2_vec = _mm_loadu_si128((__m128i*)&src2[i]);\n\n        // Create a mask based on the index and the given mask\n        __m128i index_mask = _mm_set_epi16(\n            ((i + 7) & mask) ? 0xFFFF : 0,\n            ((i + 6) & mask) ? 0xFFFF : 0,\n            ((i + 5) & mask) ? 0xFFFF : 0,\n            ((i + 4) & mask) ? 0xFFFF : 0,\n            ((i + 3) & mask) ? 0xFFFF : 0,\n            ((i + 2) & mask) ? 0xFFFF : 0,\n            ((i + 1) & mask) ? 0xFFFF : 0,\n            ((i + 0) & mask) ? 0xFFFF : 0\n        );\n\n        // Blend the two vectors based on the computed mask\n        __m128i blended = _mm_or_si128(\n            _mm_and_si128(index_mask, src1_vec),\n            _mm_andnot_si128(index_mask, src2_vec)\n        );\n\n        // Store the result in the destination array\n        _mm_storeu_si128((__m128i*)&dst[i], blended);\n    }\n\n    // Handle any remaining elements that don't fit into the SIMD loop\n    for (; i < length; ++i) {\n        dst[i] = ((i & mask) != 0) ? src1[i] : src2[i];\n    }\n}\n```"}
{"task_id": "SimdBench_15_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid vector_blend_simd(const uint16_t* src1, const uint16_t* src2, uint32_t mask, uint16_t* dst, size_t length) {\n    size_t i = 0;\n\n    // Process 8 elements at a time using SSE2 intrinsics\n    for (; i + 8 <= length; i += 8) {\n        // Load 8 elements from src1 and src2 into SIMD registers\n        __m128i src1_vec = _mm_loadu_si128((__m128i*)&src1[i]);\n        __m128i src2_vec = _mm_loadu_si128((__m128i*)&src2[i]);\n\n        // Create a mask based on the condition (index & mask)\n        __m128i index_mask = _mm_set_epi16(\n            ((i + 7) & mask) ? 0xFFFF : 0,\n            ((i + 6) & mask) ? 0xFFFF : 0,\n            ((i + 5) & mask) ? 0xFFFF : 0,\n            ((i + 4) & mask) ? 0xFFFF : 0,\n            ((i + 3) & mask) ? 0xFFFF : 0,\n            ((i + 2) & mask) ? 0xFFFF : 0,\n            ((i + 1) & mask) ? 0xFFFF : 0,\n            ((i + 0) & mask) ? 0xFFFF : 0\n        );\n\n        // Blend the two vectors based on the mask\n        __m128i result = _mm_or_si128(\n            _mm_and_si128(index_mask, src1_vec),\n            _mm_andnot_si128(index_mask, src2_vec)\n        );\n\n        // Store the result in the destination array\n        _mm_storeu_si128((__m128i*)&dst[i], result);\n    }\n\n    // Handle remaining elements (if any) with scalar code\n    for (; i < length; ++i) {\n        dst[i] = ((i & mask) != 0) ? src1[i] : src2[i];\n    }\n}\n```"}
{"task_id": "SimdBench_15_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid vector_blend_simd(const uint16_t* src1, const uint16_t* src2, uint32_t mask, uint16_t* dst, size_t length) {\n    size_t i = 0;\n\n    // Process 8 elements at a time using SSE2 intrinsics\n    for (; i + 8 <= length; i += 8) {\n        // Load 8 elements from src1 and src2 into SIMD registers\n        __m128i src1_vec = _mm_loadu_si128((__m128i*)&src1[i]);\n        __m128i src2_vec = _mm_loadu_si128((__m128i*)&src2[i]);\n\n        // Create a mask based on the index and provided mask\n        uint16_t index_mask[8];\n        for (int j = 0; j < 8; ++j) {\n            index_mask[j] = ((i + j) & mask) ? 0xFFFF : 0x0000;\n        }\n        __m128i blend_mask = _mm_loadu_si128((__m128i*)index_mask);\n\n        // Blend the two vectors based on the mask\n        __m128i result = _mm_or_si128(\n            _mm_and_si128(blend_mask, src1_vec),\n            _mm_andnot_si128(blend_mask, src2_vec)\n        );\n\n        // Store the result in the destination array\n        _mm_storeu_si128((__m128i*)&dst[i], result);\n    }\n\n    // Process remaining elements (if any) using scalar code\n    for (; i < length; ++i) {\n        dst[i] = ((i & mask) != 0) ? src1[i] : src2[i];\n    }\n}\n```"}
{"task_id": "SimdBench_16_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid population_count_simd(const uint32_t* src, uint32_t* dst, size_t length) {\n    size_t i = 0;\n\n    // Process 4 elements at a time using SSE2 intrinsics\n    for (; i + 4 <= length; i += 4) {\n        // Load 4 uint32_t values from the source array\n        __m128i v = _mm_loadu_si128((__m128i*)&src[i]);\n\n        // Calculate population count for each of the 4 integers\n        __m128i count = _mm_setzero_si128();\n\n        // Extract each byte and calculate its population count\n        for (int j = 0; j < 4; ++j) {\n            __m128i element = _mm_srli_epi32(v, j * 8);\n            element = _mm_and_si128(element, _mm_set1_epi8(0xFF));\n            __m128i popcnt_byte = _mm_sad_epu8(_mm_setzero_si128(), element);\n            count = _mm_add_epi32(count, popcnt_byte);\n        }\n\n        // Store the results in the destination array\n        _mm_storeu_si128((__m128i*)&dst[i], count);\n    }\n\n    // Process any remaining elements\n    for (; i < length; ++i) {\n        dst[i] = __builtin_popcount(src[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_16_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid population_count_simd(const uint32_t* src, uint32_t* dst, size_t length) {\n    size_t i = 0;\n\n    // Process 4 elements at a time using SSE2\n    for (; i + 4 <= length; i += 4) {\n        // Load 4 uint32_t values from the source array\n        __m128i v = _mm_loadu_si128((__m128i*)&src[i]);\n\n        // Calculate population count for each of the 4 integers\n        __m128i count = _mm_setzero_si128();\n\n        // Add counts for each bit position\n        for (int shift = 0; shift < 32; shift++) {\n            __m128i mask = _mm_set1_epi32(1 << shift);\n            __m128i bits = _mm_and_si128(v, mask);\n            bits = _mm_cmpeq_epi32(bits, mask);\n            count = _mm_sub_epi32(count, bits);\n        }\n\n        // Store the results in the destination array\n        _mm_storeu_si128((__m128i*)&dst[i], count);\n    }\n\n    // Process remaining elements\n    for (; i < length; ++i) {\n        dst[i] = __builtin_popcount(src[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_16_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid population_count_simd(const uint32_t* src, uint32_t* dst, size_t length) {\n    size_t i = 0;\n\n    // Process 4 elements at a time using SSE2 intrinsics\n    for (; i + 4 <= length; i += 4) {\n        // Load 4 uint32_t values from the source array\n        __m128i v = _mm_loadu_si128((__m128i*)&src[i]);\n\n        // Calculate population count for each of the 4 integers\n        const __m128i lookup = _mm_setr_epi8(\n            0, 1, 1, 2, 1, 2, 2, 3, 1, 2, 2, 3, 2, 3, 3, 4\n        );\n\n        __m128i count = _mm_setzero_si128();\n\n        for (int j = 0; j < 4; ++j) {\n            // Extract one byte at a time and use the lookup table\n            __m128i byte = _mm_srli_epi32(v, j * 8);\n            byte = _mm_and_si128(byte, _mm_set1_epi8(0xFF));\n            __m128i pop = _mm_shuffle_epi8(lookup, byte);\n            count = _mm_add_epi8(count, pop);\n        }\n\n        // Horizontal sum of bytes to get population count for each 32-bit integer\n        __m128i sum1 = _mm_sad_epu8(count, _mm_setzero_si128());\n        __m128i sum2 = _mm_shuffle_epi32(sum1, _MM_SHUFFLE(1, 0, 3, 2));\n        __m128i total = _mm_add_epi32(sum1, sum2);\n\n        // Store the results in the destination array\n        _mm_storeu_si128((__m128i*)&dst[i], total);\n    }\n\n    // Process remaining elements (if any) using scalar code\n    for (; i < length; ++i) {\n        dst[i] = __builtin_popcount(src[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_16_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid population_count_simd(const uint32_t* src, uint32_t* dst, size_t length) {\n    size_t i = 0;\n\n    // Process 4 elements at a time using SSE2\n    for (; i + 4 <= length; i += 4) {\n        // Load 4 uint32_t values from the source array\n        __m128i v = _mm_loadu_si128((__m128i*)&src[i]);\n\n        // Calculate population count for each element in the vector\n        __m128i count = _mm_setzero_si128();\n        for (int k = 0; k < 32; k++) {\n            count = _mm_add_epi32(count, _mm_and_si128(v, _mm_set1_epi32(1)));\n            v = _mm_srli_epi32(v, 1);\n        }\n\n        // Store the results into the destination array\n        _mm_storeu_si128((__m128i*)&dst[i], count);\n    }\n\n    // Process remaining elements (if any)\n    for (; i < length; ++i) {\n        dst[i] = __builtin_popcount(src[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_16_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid population_count_simd(const uint32_t* src, uint32_t* dst, size_t length) {\n    size_t i = 0;\n\n    // Process 4 elements at a time using SSE2 intrinsics\n    for (; i + 4 <= length; i += 4) {\n        // Load 4 uint32_t values from the source array into an SSE register\n        __m128i v = _mm_loadu_si128((__m128i*)&src[i]);\n\n        // Calculate population count for each of the 4 integers in parallel\n        __m128i count = _mm_setzero_si128();\n\n        // Add counts for each bit position\n        for (int shift = 0; shift < 32; shift++) {\n            __m128i mask = _mm_set1_epi32(1 << shift);\n            __m128i bits = _mm_and_si128(v, mask);\n            count = _mm_sub_epi32(count, _mm_srli_epi32(bits, shift));\n        }\n\n        // Store the results back to the destination array\n        _mm_storeu_si128((__m128i*)&dst[i], count);\n    }\n\n    // Handle any remaining elements that didn't fit into the SIMD loop\n    for (; i < length; ++i) {\n        dst[i] = __builtin_popcount(src[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_17_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid saturating_add_simd(const uint16_t* src1, const uint16_t* src2, uint16_t* dst, size_t length) {\n    size_t i = 0;\n    __m128i max_val = _mm_set1_epi16(0xFFFF); // UINT16_MAX\n\n    // Process 8 elements at a time\n    for (; i + 8 <= length; i += 8) {\n        __m128i v1 = _mm_loadu_si128((__m128i*)&src1[i]); // Load 8 elements from src1\n        __m128i v2 = _mm_loadu_si128((__m128i*)&src2[i]); // Load 8 elements from src2\n        __m128i result = _mm_adds_epu16(v1, v2);          // Saturating addition\n        _mm_storeu_si128((__m128i*)&dst[i], result);      // Store 8 elements to dst\n    }\n\n    // Handle remaining elements (if any)\n    for (; i < length; ++i) {\n        dst[i] = (src1[i] + src2[i] > 0xFFFF) ? 0xFFFF : src1[i] + src2[i];\n    }\n}\n```"}
{"task_id": "SimdBench_17_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid saturating_add_simd(const uint16_t* src1, const uint16_t* src2, uint16_t* dst, size_t length) {\n    size_t i = 0;\n    __m128i max_val = _mm_set1_epi16(0xFFFF); // UINT16_MAX\n\n    // Process 8 elements at a time\n    for (; i + 8 <= length; i += 8) {\n        __m128i v1 = _mm_loadu_si128((__m128i*)&src1[i]); // Load 8 elements from src1\n        __m128i v2 = _mm_loadu_si128((__m128i*)&src2[i]); // Load 8 elements from src2\n        __m128i result = _mm_adds_epu16(v1, v2);          // Saturating addition\n        _mm_storeu_si128((__m128i*)&dst[i], result);      // Store 8 elements to dst\n    }\n\n    // Handle remaining elements (if any)\n    for (; i < length; ++i) {\n        dst[i] = (src1[i] + src2[i] > 0xFFFF) ? 0xFFFF : src1[i] + src2[i];\n    }\n}\n```"}
{"task_id": "SimdBench_17_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid saturating_add_simd(const uint16_t* src1, const uint16_t* src2, uint16_t* dst, size_t length) {\n    size_t i = 0;\n\n    // Process 8 elements at a time using SSE2 intrinsics\n    for (; i + 8 <= length; i += 8) {\n        // Load 8 elements from src1 and src2 into SIMD registers\n        __m128i vsrc1 = _mm_loadu_si128((__m128i*)&src1[i]);\n        __m128i vsrc2 = _mm_loadu_si128((__m128i*)&src2[i]);\n\n        // Perform saturating addition of the two vectors\n        __m128i vresult = _mm_adds_epu16(vsrc1, vsrc2);\n\n        // Store the result back to the destination array\n        _mm_storeu_si128((__m128i*)&dst[i], vresult);\n    }\n\n    // Handle any remaining elements that are not a multiple of 8\n    for (; i < length; ++i) {\n        dst[i] = (src1[i] > UINT16_MAX - src2[i]) ? UINT16_MAX : (src1[i] + src2[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_17_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid saturating_add_simd(const uint16_t* src1, const uint16_t* src2, uint16_t* dst, size_t length) {\n    size_t i = 0;\n\n    // Process 8 elements at a time using SSE2 intrinsics\n    for (; i + 8 <= length; i += 8) {\n        // Load 8 elements from src1 and src2 into SIMD registers\n        __m128i vsrc1 = _mm_loadu_si128((__m128i*)&src1[i]);\n        __m128i vsrc2 = _mm_loadu_si128((__m128i*)&src2[i]);\n\n        // Perform saturating addition of the two vectors\n        __m128i vresult = _mm_adds_epu16(vsrc1, vsrc2);\n\n        // Store the result back to the destination array\n        _mm_storeu_si128((__m128i*)&dst[i], vresult);\n    }\n\n    // Handle any remaining elements that are not a multiple of 8\n    for (; i < length; ++i) {\n        dst[i] = (src1[i] > UINT16_MAX - src2[i]) ? UINT16_MAX : (src1[i] + src2[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_17_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid saturating_add_simd(const uint16_t* src1, const uint16_t* src2, uint16_t* dst, size_t length) {\n    size_t i = 0;\n    __m128i max_val = _mm_set1_epi16(UINT16_MAX);\n\n    for (; i + 8 <= length; i += 8) {\n        __m128i a = _mm_loadu_si128((__m128i*)&src1[i]);\n        __m128i b = _mm_loadu_si128((__m128i*)&src2[i]);\n        __m128i result = _mm_adds_epu16(a, b);\n        _mm_storeu_si128((__m128i*)&dst[i], result);\n    }\n\n    for (; i < length; ++i) {\n        dst[i] = (src1[i] + src2[i] > UINT16_MAX) ? UINT16_MAX : src1[i] + src2[i];\n    }\n}\n```"}
{"task_id": "SimdBench_18_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid range_matrix_mul_simd(const double* A, const double* B, double* C, size_t m, size_t n, size_t p) {\n    __m128d lower_bound = _mm_set1_pd(-100.0);\n    __m128d upper_bound = _mm_set1_pd(100.0);\n\n    for (size_t i = 0; i < m; ++i) {\n        for (size_t k = 0; k < p; ++k) {\n            __m128d c_sum = _mm_setzero_pd();\n            size_t j = 0;\n\n            // Process 2 elements at a time using SSE2\n            for (; j + 1 < n; j += 2) {\n                __m128d a_vec = _mm_loadu_pd(&A[i * n + j]);\n                __m128d b_vec = _mm_loadu_pd(&B[j * p + k]);\n\n                // Check if elements of A are within range [-100, 100]\n                __m128d a_mask = _mm_and_pd(_mm_cmpge_pd(a_vec, lower_bound), _mm_cmple_pd(a_vec, upper_bound));\n\n                // Check if elements of B are within range [-100, 100]\n                __m128d b_mask = _mm_and_pd(_mm_cmpge_pd(b_vec, lower_bound), _mm_cmple_pd(b_vec, upper_bound));\n\n                // Combine masks\n                __m128d mask = _mm_and_pd(a_mask, b_mask);\n\n                // Multiply A and B elements if they are in range\n                __m128d prod = _mm_mul_pd(a_vec, b_vec);\n\n                // Apply mask to zero out out-of-range contributions\n                prod = _mm_and_pd(prod, mask);\n\n                // Accumulate the result\n                c_sum = _mm_add_pd(c_sum, prod);\n            }\n\n            // Horizontal sum of the two accumulated values\n            double temp[2];\n            _mm_storeu_pd(temp, c_sum);\n            double c_val = temp[0] + temp[1];\n\n            // Process remaining elements (if n is odd)\n            for (; j < n; ++j) {\n                double a = A[i * n + j];\n                double b = B[j * p + k];\n                if (a >= -100.0 && a <= 100.0 && b >= -100.0 && b <= 100.0) {\n                    c_val += a * b;\n                }\n            }\n\n            // Store the result in C\n            C[i * p + k] = c_val;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_18_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid range_matrix_mul_simd(const double* A, const double* B, double* C, size_t m, size_t n, size_t p) {\n    __m128d lower_bound = _mm_set1_pd(-100.0);\n    __m128d upper_bound = _mm_set1_pd(100.0);\n\n    for (size_t i = 0; i < m; ++i) {\n        for (size_t k = 0; k < p; ++k) {\n            __m128d c_sum = _mm_setzero_pd();\n            size_t j = 0;\n\n            // Process 2 elements at a time using SSE2\n            for (; j + 1 < n; j += 2) {\n                __m128d a_vec = _mm_loadu_pd(&A[i * n + j]);\n                __m128d b_vec = _mm_loadu_pd(&B[j * p + k]);\n\n                // Check if elements of A are within range [-100, 100]\n                __m128d a_mask = _mm_and_pd(_mm_cmpge_pd(a_vec, lower_bound), _mm_cmple_pd(a_vec, upper_bound));\n\n                // Check if elements of B are within range [-100, 100]\n                __m128d b_mask = _mm_and_pd(_mm_cmpge_pd(b_vec, lower_bound), _mm_cmple_pd(b_vec, upper_bound));\n\n                // Combine masks\n                __m128d mask = _mm_and_pd(a_mask, b_mask);\n\n                // Multiply A and B elements if they are in range\n                __m128d prod = _mm_mul_pd(a_vec, b_vec);\n\n                // Apply mask to zero out out-of-range products\n                prod = _mm_and_pd(prod, mask);\n\n                // Accumulate the result\n                c_sum = _mm_add_pd(c_sum, prod);\n            }\n\n            // Horizontal sum of the two accumulated values\n            double temp[2];\n            _mm_storeu_pd(temp, c_sum);\n            double c_val = temp[0] + temp[1];\n\n            // Process remaining elements (if n is odd)\n            for (; j < n; ++j) {\n                double a_elem = A[i * n + j];\n                double b_elem = B[j * p + k];\n                if (a_elem >= -100.0 && a_elem <= 100.0 && b_elem >= -100.0 && b_elem <= 100.0) {\n                    c_val += a_elem * b_elem;\n                }\n            }\n\n            // Store the result in C\n            C[i * p + k] = c_val;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_18_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid range_matrix_mul_simd(const double* A, const double* B, double* C, size_t m, size_t n, size_t p) {\n    __m128d lower_bound = _mm_set1_pd(-100.0);\n    __m128d upper_bound = _mm_set1_pd(100.0);\n\n    for (size_t i = 0; i < m; ++i) {\n        for (size_t k = 0; k < p; ++k) {\n            __m128d c_sum = _mm_setzero_pd();\n            size_t j = 0;\n\n            // Process 2 elements at a time using SSE\n            for (; j + 1 < n; j += 2) {\n                __m128d a_vec = _mm_loadu_pd(&A[i * n + j]);\n                __m128d b_vec = _mm_loadu_pd(&B[j * p + k]);\n\n                // Check if elements are within the range [-100, 100]\n                __m128d a_mask = _mm_and_pd(_mm_cmpge_pd(a_vec, lower_bound), _mm_cmple_pd(a_vec, upper_bound));\n                __m128d b_mask = _mm_and_pd(_mm_cmpge_pd(b_vec, lower_bound), _mm_cmple_pd(b_vec, upper_bound));\n                __m128d mask = _mm_and_pd(a_mask, b_mask);\n\n                // Zero out elements outside the range\n                a_vec = _mm_and_pd(a_vec, mask);\n                b_vec = _mm_and_pd(b_vec, mask);\n\n                // Perform multiplication and accumulate\n                c_sum = _mm_add_pd(c_sum, _mm_mul_pd(a_vec, b_vec));\n            }\n\n            // Horizontal sum of the two accumulated values in c_sum\n            double temp[2];\n            _mm_storeu_pd(temp, c_sum);\n            double result = temp[0] + temp[1];\n\n            // Process remaining elements (if n is odd)\n            for (; j < n; ++j) {\n                double a_val = A[i * n + j];\n                double b_val = B[j * p + k];\n                if (a_val >= -100.0 && a_val <= 100.0 && b_val >= -100.0 && b_val <= 100.0) {\n                    result += a_val * b_val;\n                }\n            }\n\n            // Store the result in the destination matrix\n            C[i * p + k] = result;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_18_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid range_matrix_mul_simd(const double* A, const double* B, double* C, size_t m, size_t n, size_t p) {\n    __m128d lower_bound = _mm_set1_pd(-100.0);\n    __m128d upper_bound = _mm_set1_pd(100.0);\n\n    for (size_t i = 0; i < m; ++i) {\n        for (size_t k = 0; k < p; ++k) {\n            __m128d c_sum = _mm_setzero_pd();\n            size_t j = 0;\n\n            // Process 2 elements at a time using SSE2\n            for (; j + 1 < n; j += 2) {\n                __m128d a_vec = _mm_loadu_pd(&A[i * n + j]);\n                __m128d b_vec = _mm_loadu_pd(&B[j * p + k]);\n\n                // Check if elements in A are within range [-100, 100]\n                __m128d a_mask = _mm_and_pd(_mm_cmpge_pd(a_vec, lower_bound), _mm_cmple_pd(a_vec, upper_bound));\n\n                // Check if elements in B are within range [-100, 100]\n                __m128d b_mask = _mm_and_pd(_mm_cmpge_pd(b_vec, lower_bound), _mm_cmple_pd(b_vec, upper_bound));\n\n                // Combine masks\n                __m128d mask = _mm_and_pd(a_mask, b_mask);\n\n                // Multiply and mask out-of-range elements\n                __m128d prod = _mm_mul_pd(a_vec, b_vec);\n                prod = _mm_and_pd(prod, mask);\n\n                // Accumulate the result\n                c_sum = _mm_add_pd(c_sum, prod);\n            }\n\n            // Horizontal sum of the two accumulated values in c_sum\n            double temp[2];\n            _mm_storeu_pd(temp, c_sum);\n            double c_val = temp[0] + temp[1];\n\n            // Process remaining elements (if n is odd)\n            for (; j < n; ++j) {\n                double a = A[i * n + j];\n                double b = B[j * p + k];\n                if (a >= -100.0 && a <= 100.0 && b >= -100.0 && b <= 100.0) {\n                    c_val += a * b;\n                }\n            }\n\n            // Store the result in C\n            C[i * p + k] = c_val;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_18_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid range_matrix_mul_simd(const double* A, const double* B, double* C, size_t m, size_t n, size_t p) {\n    __m128d lower_bound = _mm_set1_pd(-100.0);\n    __m128d upper_bound = _mm_set1_pd(100.0);\n\n    for (size_t i = 0; i < m; ++i) {\n        for (size_t k = 0; k < p; ++k) {\n            __m128d c_sum = _mm_setzero_pd();\n            size_t j = 0;\n\n            // Process 2 elements at a time using SSE2\n            for (; j + 1 < n; j += 2) {\n                __m128d a_vec = _mm_loadu_pd(&A[i * n + j]);\n                __m128d b_vec = _mm_loadu_pd(&B[j * p + k]);\n\n                // Check if elements in A are within range [-100, 100]\n                __m128d a_mask = _mm_and_pd(_mm_cmpge_pd(a_vec, lower_bound), _mm_cmple_pd(a_vec, upper_bound));\n\n                // Check if elements in B are within range [-100, 100]\n                __m128d b_mask = _mm_and_pd(_mm_cmpge_pd(b_vec, lower_bound), _mm_cmple_pd(b_vec, upper_bound));\n\n                // Combine masks\n                __m128d mask = _mm_and_pd(a_mask, b_mask);\n\n                // Multiply A and B elements if they are in range\n                __m128d prod = _mm_mul_pd(a_vec, b_vec);\n\n                // Apply mask to zero out out-of-range products\n                prod = _mm_and_pd(prod, mask);\n\n                // Accumulate the result\n                c_sum = _mm_add_pd(c_sum, prod);\n            }\n\n            // Horizontal sum of the two accumulated values\n            double temp[2];\n            _mm_storeu_pd(temp, c_sum);\n            double c_val = temp[0] + temp[1];\n\n            // Process remaining elements (if n is odd)\n            for (; j < n; ++j) {\n                double a = A[i * n + j];\n                double b = B[j * p + k];\n                if (a >= -100.0 && a <= 100.0 && b >= -100.0 && b <= 100.0) {\n                    c_val += a * b;\n                }\n            }\n\n            // Store the result in C\n            C[i * p + k] = c_val;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_19_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid tensor_add_3d_simd(const int64_t* A, const int64_t* B, int64_t* C, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n\n    // Process 2 elements at a time using SSE2 (128-bit register for 2 x 64-bit integers)\n    size_t simd_aligned_length = total_elements / 2 * 2;\n\n    size_t i = 0;\n    for (; i < simd_aligned_length; i += 2) {\n        // Load 2 elements from A and B into SIMD registers\n        __m128i vecA = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i vecB = _mm_loadu_si128((__m128i*)&B[i]);\n\n        // Perform element-wise addition\n        __m128i vecC = _mm_add_epi64(vecA, vecB);\n\n        // Store the result back to C\n        _mm_storeu_si128((__m128i*)&C[i], vecC);\n    }\n\n    // Handle remaining elements (if total_elements is odd)\n    for (; i < total_elements; ++i) {\n        C[i] = A[i] + B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_19_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid tensor_add_3d_simd(const int64_t* A, const int64_t* B, int64_t* C, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n\n    // Process 2 elements at a time using SSE2 (128-bit register for 2 x int64_t)\n    size_t simd_aligned_length = total_elements / 2 * 2;\n\n    size_t i = 0;\n    for (; i < simd_aligned_length; i += 2) {\n        // Load 2 int64_t elements from A and B into SIMD registers\n        __m128i vecA = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i vecB = _mm_loadu_si128((__m128i*)&B[i]);\n\n        // Perform element-wise addition\n        __m128i vecC = _mm_add_epi64(vecA, vecB);\n\n        // Store the result back to C\n        _mm_storeu_si128((__m128i*)&C[i], vecC);\n    }\n\n    // Handle remaining elements (if total_elements is odd)\n    for (; i < total_elements; ++i) {\n        C[i] = A[i] + B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_19_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid tensor_add_3d_simd(const int64_t* A, const int64_t* B, int64_t* C, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n\n    // Process 2 elements at a time using SSE2 (128-bit register for 2 x 64-bit integers)\n    size_t simd_aligned_length = total_elements / 2 * 2;\n\n    size_t i = 0;\n    for (; i < simd_aligned_length; i += 2) {\n        // Load 2 int64_t elements from A and B into SIMD registers\n        __m128i vecA = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i vecB = _mm_loadu_si128((__m128i*)&B[i]);\n\n        // Perform element-wise addition\n        __m128i vecC = _mm_add_epi64(vecA, vecB);\n\n        // Store the result back to C\n        _mm_storeu_si128((__m128i*)&C[i], vecC);\n    }\n\n    // Handle remaining elements that are not aligned with SIMD width\n    for (; i < total_elements; ++i) {\n        C[i] = A[i] + B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_19_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid tensor_add_3d_simd(const int64_t* A, const int64_t* B, int64_t* C, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n\n    // Process 2 elements at a time using SSE2 (128-bit register for two 64-bit integers)\n    size_t simd_aligned_length = total_elements / 2 * 2;\n\n    size_t i = 0;\n    for (; i < simd_aligned_length; i += 2) {\n        // Load 2 elements from A and B into SIMD registers\n        __m128i vecA = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i vecB = _mm_loadu_si128((__m128i*)&B[i]);\n\n        // Perform element-wise addition\n        __m128i vecC = _mm_add_epi64(vecA, vecB);\n\n        // Store the result back to C\n        _mm_storeu_si128((__m128i*)&C[i], vecC);\n    }\n\n    // Handle remaining elements (if total_elements is odd)\n    for (; i < total_elements; ++i) {\n        C[i] = A[i] + B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_19_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid tensor_add_3d_simd(const int64_t* A, const int64_t* B, int64_t* C, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n\n    // Process 2 elements at a time using SSE2 (128-bit registers)\n    size_t simd_iterations = total_elements / 2;\n    size_t remainder = total_elements % 2;\n\n    for (size_t i = 0; i < simd_iterations; ++i) {\n        // Load 2 int64_t elements from A and B into SIMD registers\n        __m128i vec_a = _mm_loadu_si128((__m128i*)&A[i * 2]);\n        __m128i vec_b = _mm_loadu_si128((__m128i*)&B[i * 2]);\n\n        // Perform element-wise addition\n        __m128i vec_c = _mm_add_epi64(vec_a, vec_b);\n\n        // Store the result back to C\n        _mm_storeu_si128((__m128i*)&C[i * 2], vec_c);\n    }\n\n    // Handle remaining elements (if any)\n    if (remainder > 0) {\n        for (size_t i = simd_iterations * 2; i < total_elements; ++i) {\n            C[i] = A[i] + B[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_20_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid vector_add_round_nearest_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    size_t i = 0;\n    __m128 rounding_magic = _mm_set1_ps(0.5f); // Magic number for rounding to nearest\n\n    // Process 4 elements at a time\n    for (; i + 4 <= length; i += 4) {\n        // Load 4 floats from src1 and src2\n        __m128 v1 = _mm_loadu_ps(&src1[i]);\n        __m128 v2 = _mm_loadu_ps(&src2[i]);\n\n        // Add the two vectors\n        __m128 sum = _mm_add_ps(v1, v2);\n\n        // Round to nearest integer using magic number addition and truncation\n        __m128 rounded = _mm_cvtepi32_ps(_mm_cvtps_epi32(_mm_add_ps(sum, rounding_magic)));\n\n        // Store the result in dst\n        _mm_storeu_ps(&dst[i], rounded);\n    }\n\n    // Handle remaining elements (if any)\n    for (; i < length; ++i) {\n        float sum = src1[i] + src2[i];\n        dst[i] = (float)((int)(sum + 0.5f)); // Round to nearest integer\n    }\n}\n```"}
{"task_id": "SimdBench_20_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid vector_add_round_nearest_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    size_t i = 0;\n    __m128 rounding_magic = _mm_set1_ps(0.5f); // Used for rounding to nearest\n\n    // Process 4 elements at a time using SIMD\n    for (; i + 4 <= length; i += 4) {\n        // Load 4 floats from src1 and src2\n        __m128 vec1 = _mm_loadu_ps(&src1[i]);\n        __m128 vec2 = _mm_loadu_ps(&src2[i]);\n\n        // Add the two vectors\n        __m128 sum = _mm_add_ps(vec1, vec2);\n\n        // Round to nearest integer by adding 0.5 and truncating\n        __m128 rounded = _mm_cvtepi32_ps(_mm_cvtps_epi32(_mm_add_ps(sum, rounding_magic)));\n\n        // Store the result in dst\n        _mm_storeu_ps(&dst[i], rounded);\n    }\n\n    // Handle remaining elements (if any) with scalar code\n    for (; i < length; ++i) {\n        float sum = src1[i] + src2[i];\n        dst[i] = (float)((int)(sum + 0.5f));\n    }\n}\n```"}
{"task_id": "SimdBench_20_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid vector_add_round_nearest_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    size_t i = 0;\n    __m128 rounding_magic = _mm_set1_ps(0.5f); // Magic number for rounding to nearest\n\n    // Process 4 elements at a time using SSE\n    for (; i + 4 <= length; i += 4) {\n        __m128 v1 = _mm_loadu_ps(&src1[i]); // Load 4 floats from src1\n        __m128 v2 = _mm_loadu_ps(&src2[i]); // Load 4 floats from src2\n        __m128 v_sum = _mm_add_ps(v1, v2);  // Add the two vectors element-wise\n\n        // Round to nearest integer using magic number trick\n        __m128 v_rounded = _mm_add_ps(v_sum, rounding_magic);\n        v_rounded = _mm_cvtepi32_ps(_mm_cvtps_epi32(v_rounded));\n\n        _mm_storeu_ps(&dst[i], v_rounded); // Store the result in dst\n    }\n\n    // Handle remaining elements (if any)\n    for (; i < length; ++i) {\n        float sum = src1[i] + src2[i];\n        dst[i] = (float)((int)(sum + 0.5f)); // Round to nearest integer\n    }\n}\n```"}
{"task_id": "SimdBench_20_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid vector_add_round_nearest_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    size_t i = 0;\n    __m128 rounding_magic = _mm_set1_ps(0.5f); // Magic number for rounding to nearest\n\n    // Process 4 floats at a time using SSE\n    for (; i + 4 <= length; i += 4) {\n        __m128 v1 = _mm_loadu_ps(&src1[i]); // Load 4 floats from src1\n        __m128 v2 = _mm_loadu_ps(&src2[i]); // Load 4 floats from src2\n        __m128 sum = _mm_add_ps(v1, v2);    // Add the two vectors element-wise\n\n        // Round to nearest integer using magic number trick\n        __m128 rounded = _mm_add_ps(sum, rounding_magic);\n        rounded = _mm_cvtepi32_ps(_mm_cvtps_epi32(rounded));\n\n        _mm_storeu_ps(&dst[i], rounded); // Store the result back to dst\n    }\n\n    // Handle any remaining elements\n    for (; i < length; ++i) {\n        float sum = src1[i] + src2[i];\n        dst[i] = (float)((int)(sum + 0.5f)); // Round to nearest integer\n    }\n}\n```"}
{"task_id": "SimdBench_20_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid vector_add_round_nearest_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    size_t i = 0;\n    __m128 rounding_magic = _mm_set1_ps(0.5f); // Magic number for rounding to nearest\n\n    // Process 4 elements at a time using SIMD\n    for (; i + 4 <= length; i += 4) {\n        __m128 v1 = _mm_loadu_ps(&src1[i]); // Load 4 floats from src1\n        __m128 v2 = _mm_loadu_ps(&src2[i]); // Load 4 floats from src2\n        __m128 sum = _mm_add_ps(v1, v2);    // Add the two vectors element-wise\n\n        // Round to nearest integer using magic number trick\n        __m128 rounded = _mm_add_ps(sum, rounding_magic);\n        __m128i int_result = _mm_cvtps_epi32(rounded); // Convert to integers\n        __m128 result = _mm_cvtepi32_ps(int_result);   // Convert back to floats\n\n        _mm_storeu_ps(&dst[i], result); // Store the result in dst\n    }\n\n    // Handle remaining elements (if any)\n    for (; i < length; ++i) {\n        float sum = src1[i] + src2[i];\n        dst[i] = (float)((int)(sum + 0.5f)); // Round to nearest integer\n    }\n}\n```"}
{"task_id": "SimdBench_21_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid vector_mul_round_up_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    __m128 v_five = _mm_set1_ps(50.0f);\n    __m128 v_neg_one = _mm_set1_ps(-1.0f);\n    __m128i v_index_mask = _mm_set_epi32(0, 0, 0xFFFFFFFF, 0xFFFFFFFF);\n\n    for (size_t i = 0; i < length; i += 4) {\n        // Load 4 floats from src1 and src2\n        __m128 v_src1 = _mm_loadu_ps(&src1[i]);\n        __m128 v_src2 = _mm_loadu_ps(&src2[i]);\n\n        // Compute absolute difference\n        __m128 v_diff = _mm_sub_ps(v_src1, v_src2);\n        __m128 v_abs_diff = _mm_and_ps(v_diff, _mm_castsi128_ps(_mm_set1_epi32(0x7FFFFFFF)));\n\n        // Check if abs(diff) <= 50\n        __m128 v_cmp_diff = _mm_cmple_ps(v_abs_diff, v_five);\n\n        // Compute index mask (i % 2 == 0)\n        __m128i v_indices = _mm_set_epi32(i + 3, i + 2, i + 1, i);\n        __m128i v_mod_mask = _mm_and_si128(v_indices, v_index_mask);\n        __m128 v_cmp_index = _mm_castsi128_ps(_mm_cmpeq_epi32(v_mod_mask, _mm_setzero_si128()));\n\n        // Combine conditions\n        __m128 v_condition = _mm_and_ps(v_cmp_diff, v_cmp_index);\n\n        // Compute multiplication result\n        __m128 v_mul = _mm_mul_ps(v_src1, v_src2);\n\n        // Round up to positive infinity\n        __m128 v_rounded = _mm_ceil_ps(v_mul);\n\n        // Blend results: -1 for false, rounded value for true\n        __m128 v_result = _mm_blendv_ps(v_neg_one, v_rounded, v_condition);\n\n        // Store results into dst\n        _mm_storeu_ps(&dst[i], v_result);\n    }\n}\n```"}
{"task_id": "SimdBench_21_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid vector_mul_round_up_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    __m128 v_five = _mm_set1_ps(50.0f);\n    __m128 v_neg_one = _mm_set1_ps(-1.0f);\n    __m128i v_index_mask = _mm_set_epi32(0, 0, 0xFFFFFFFF, 0xFFFFFFFF);\n\n    for (size_t i = 0; i < length; i += 4) {\n        // Load 4 floats from src1 and src2\n        __m128 v_src1 = _mm_loadu_ps(&src1[i]);\n        __m128 v_src2 = _mm_loadu_ps(&src2[i]);\n\n        // Compute absolute difference\n        __m128 v_diff = _mm_sub_ps(v_src1, v_src2);\n        __m128 v_abs_diff = _mm_and_ps(v_diff, _mm_castsi128_ps(_mm_set1_epi32(0x7FFFFFFF)));\n\n        // Check if abs(diff) <= 50\n        __m128 v_cmp_diff = _mm_cmple_ps(v_abs_diff, v_five);\n\n        // Create index mask to check if index is a multiple of 2\n        __m128i v_indices = _mm_set_epi32(i + 3, i + 2, i + 1, i);\n        __m128i v_index_check = _mm_and_si128(v_indices, v_index_mask);\n        __m128 v_cmp_index = _mm_castsi128_ps(_mm_cmpeq_epi32(v_index_check, _mm_setzero_si128()));\n\n        // Combine conditions: abs(diff) <= 50 AND index % 2 == 0\n        __m128 v_condition = _mm_and_ps(v_cmp_diff, v_cmp_index);\n\n        // Compute element-wise multiplication\n        __m128 v_mul = _mm_mul_ps(v_src1, v_src2);\n\n        // Round up towards positive infinity\n        __m128 v_rounded = _mm_ceil_ps(v_mul);\n\n        // Blend results: -1 for elements not meeting the condition\n        __m128 v_result = _mm_blendv_ps(v_neg_one, v_rounded, v_condition);\n\n        // Store results into dst\n        _mm_storeu_ps(&dst[i], v_result);\n    }\n}\n```"}
{"task_id": "SimdBench_21_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid vector_mul_round_up_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    __m128 v_five = _mm_set1_ps(50.0f);\n    __m128 v_neg_one = _mm_set1_ps(-1.0f);\n\n    for (size_t i = 0; i < length; i += 4) {\n        // Load 4 floats from src1 and src2\n        __m128 v_src1 = _mm_loadu_ps(&src1[i]);\n        __m128 v_src2 = _mm_loadu_ps(&src2[i]);\n\n        // Compute absolute difference\n        __m128 v_diff = _mm_sub_ps(v_src1, v_src2);\n        __m128 v_abs_diff = _mm_and_ps(v_diff, _mm_castsi128_ps(_mm_set1_epi32(0x7FFFFFFF)));\n\n        // Check if abs(diff) <= 50\n        __m128 v_mask1 = _mm_cmple_ps(v_abs_diff, v_five);\n\n        // Check if index is a multiple of 2\n        __m128i v_indices = _mm_set_epi32(i + 3, i + 2, i + 1, i);\n        __m128i v_mod2 = _mm_and_si128(v_indices, _mm_set1_epi32(1));\n        __m128 v_mask2 = _mm_castsi128_ps(_mm_cmpeq_epi32(v_mod2, _mm_setzero_si128()));\n\n        // Combine masks\n        __m128 v_mask = _mm_and_ps(v_mask1, v_mask2);\n\n        // Multiply elements\n        __m128 v_mul = _mm_mul_ps(v_src1, v_src2);\n\n        // Round up towards positive infinity\n        __m128 v_ceil = _mm_ceil_ps(v_mul);\n\n        // Blend results: -1 for elements not meeting conditions\n        __m128 v_result = _mm_blendv_ps(v_neg_one, v_ceil, v_mask);\n\n        // Store results into dst\n        _mm_storeu_ps(&dst[i], v_result);\n    }\n}\n```"}
{"task_id": "SimdBench_21_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid vector_mul_round_up_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    __m128 v_five = _mm_set1_ps(50.0f);\n    __m128 v_neg_one = _mm_set1_ps(-1.0f);\n    __m128i v_index_mask = _mm_set_epi32(0, 0, 0xFFFFFFFF, 0xFFFFFFFF);\n\n    for (size_t i = 0; i < length; i += 4) {\n        // Load 4 floats from src1 and src2\n        __m128 v_src1 = _mm_loadu_ps(&src1[i]);\n        __m128 v_src2 = _mm_loadu_ps(&src2[i]);\n\n        // Compute absolute difference\n        __m128 v_diff = _mm_sub_ps(v_src1, v_src2);\n        __m128 v_abs_diff = _mm_and_ps(v_diff, _mm_castsi128_ps(_mm_set1_epi32(0x7FFFFFFF)));\n\n        // Check if abs(diff) <= 50\n        __m128 v_cmp_diff = _mm_cmple_ps(v_abs_diff, v_five);\n\n        // Create index mask for even indices\n        __m128i v_indices = _mm_set_epi32(i + 3, i + 2, i + 1, i);\n        __m128i v_even_check = _mm_and_si128(v_indices, v_index_mask);\n        __m128 v_cmp_even = _mm_castsi128_ps(_mm_cmpeq_epi32(v_even_check, _mm_setzero_si128()));\n\n        // Combine conditions: abs(diff) <= 50 AND index is even\n        __m128 v_combined_mask = _mm_and_ps(v_cmp_diff, v_cmp_even);\n\n        // Perform multiplication\n        __m128 v_mul = _mm_mul_ps(v_src1, v_src2);\n\n        // Round up towards positive infinity\n        __m128 v_rounded = _mm_ceil_ps(v_mul);\n\n        // Blend results: -1 for elements that don't meet the condition\n        __m128 v_result = _mm_blendv_ps(v_neg_one, v_rounded, v_combined_mask);\n\n        // Store result in dst\n        _mm_storeu_ps(&dst[i], v_result);\n    }\n}\n```"}
{"task_id": "SimdBench_21_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid vector_mul_round_up_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    __m128 v_five = _mm_set1_ps(50.0f);\n    __m128 v_neg_one = _mm_set1_ps(-1.0f);\n    __m128i v_index_mask = _mm_set_epi32(0, 0, 0xFFFFFFFF, 0xFFFFFFFF);\n\n    for (size_t i = 0; i < length; i += 4) {\n        // Load 4 floats from src1 and src2\n        __m128 v_src1 = _mm_loadu_ps(&src1[i]);\n        __m128 v_src2 = _mm_loadu_ps(&src2[i]);\n\n        // Compute absolute difference\n        __m128 v_diff = _mm_sub_ps(v_src1, v_src2);\n        __m128 v_abs_diff = _mm_and_ps(v_diff, _mm_castsi128_ps(_mm_set1_epi32(0x7FFFFFFF)));\n\n        // Check if abs(diff) <= 50\n        __m128 v_cmp_diff = _mm_cmple_ps(v_abs_diff, v_five);\n\n        // Create index mask (i, i+1, i+2, i+3)\n        __m128i v_indices = _mm_add_epi32(_mm_set1_epi32(i), _mm_set_epi32(3, 2, 1, 0));\n        __m128i v_mod2_mask = _mm_and_si128(v_indices, v_index_mask);\n        __m128 v_cmp_index = _mm_castsi128_ps(_mm_cmpeq_epi32(v_mod2_mask, _mm_setzero_si128()));\n\n        // Combine conditions: abs(diff) <= 50 && index % 2 == 0\n        __m128 v_combined_mask = _mm_and_ps(v_cmp_diff, v_cmp_index);\n\n        // Compute element-wise multiplication\n        __m128 v_mul = _mm_mul_ps(v_src1, v_src2);\n\n        // Round up towards positive infinity\n        __m128 v_rounded = _mm_ceil_ps(v_mul);\n\n        // Blend results: -1 for elements not meeting conditions\n        __m128 v_result = _mm_blendv_ps(v_neg_one, v_rounded, v_combined_mask);\n\n        // Store results into dst\n        _mm_storeu_ps(&dst[i], v_result);\n    }\n}\n```"}
{"task_id": "SimdBench_22_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid matrix_scalar_mul_simd(const double* mat, double scalar, double* dst, size_t m, size_t n) {\n    __m128d scalar_vec = _mm_set1_pd(scalar); // Broadcast scalar to all elements of the SIMD register\n\n    size_t i, j;\n    for (i = 0; i < m; ++i) {\n        size_t k = 0;\n        // Process 2 elements at a time using SSE2\n        for (; k + 1 < n; k += 2) {\n            __m128d mat_vec = _mm_loadu_pd(&mat[i * n + k]); // Load two doubles from mat\n            __m128d result = _mm_mul_pd(mat_vec, scalar_vec); // Multiply by scalar\n            _mm_storeu_pd(&dst[i * n + k], result);           // Store the result in dst\n        }\n        // Handle remaining elements (if n is odd)\n        for (; k < n; ++k) {\n            dst[i * n + k] = mat[i * n + k] * scalar;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_22_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid matrix_scalar_mul_simd(const double* mat, double scalar, double* dst, size_t m, size_t n) {\n    __m128d scalar_vec = _mm_set1_pd(scalar); // Broadcast scalar to all elements of the SIMD register\n\n    size_t simd_width = 2; // SSE/SSE2 processes 2 doubles at a time\n    size_t total_elements = m * n;\n    size_t simd_aligned_elements = total_elements - (total_elements % simd_width);\n\n    size_t i = 0;\n\n    // Process elements in chunks of 2 using SIMD\n    for (; i < simd_aligned_elements; i += simd_width) {\n        __m128d mat_vec = _mm_loadu_pd(&mat[i]); // Load 2 doubles from mat\n        __m128d result = _mm_mul_pd(mat_vec, scalar_vec); // Multiply by scalar\n        _mm_storeu_pd(&dst[i], result); // Store the result in dst\n    }\n\n    // Process remaining elements that don't fit into SIMD width\n    for (; i < total_elements; ++i) {\n        dst[i] = mat[i] * scalar;\n    }\n}\n```"}
{"task_id": "SimdBench_22_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid matrix_scalar_mul_simd(const double* mat, double scalar, double* dst, size_t m, size_t n) {\n    __m128d scalar_vec = _mm_set1_pd(scalar); // Broadcast scalar to all elements of the SIMD register\n\n    size_t i, j;\n    for (i = 0; i < m; ++i) {\n        size_t aligned_end = n - (n % 2); // Process up to the last multiple of 2 for aligned operations\n        for (j = 0; j < aligned_end; j += 2) {\n            __m128d mat_vec = _mm_loadu_pd(&mat[i * n + j]); // Load two doubles from mat\n            __m128d result = _mm_mul_pd(mat_vec, scalar_vec); // Multiply by scalar\n            _mm_storeu_pd(&dst[i * n + j], result); // Store the result back to dst\n        }\n\n        // Handle remaining elements if n is not a multiple of 2\n        for (; j < n; ++j) {\n            dst[i * n + j] = mat[i * n + j] * scalar;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_22_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid matrix_scalar_mul_simd(const double* mat, double scalar, double* dst, size_t m, size_t n) {\n    __m128d scalar_vec = _mm_set1_pd(scalar); // Broadcast scalar to all elements of the SIMD register\n\n    size_t i, j;\n    for (i = 0; i < m; ++i) {\n        size_t aligned_end = n - (n % 2); // Process up to the last multiple of 2\n        for (j = 0; j < aligned_end; j += 2) {\n            __m128d mat_vec = _mm_loadu_pd(&mat[i * n + j]); // Load two doubles from mat\n            __m128d result = _mm_mul_pd(mat_vec, scalar_vec); // Multiply by scalar\n            _mm_storeu_pd(&dst[i * n + j], result); // Store the result in dst\n        }\n\n        // Handle remaining elements if n is not a multiple of 2\n        for (; j < n; ++j) {\n            dst[i * n + j] = mat[i * n + j] * scalar;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_22_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid matrix_scalar_mul_simd(const double* mat, double scalar, double* dst, size_t m, size_t n) {\n    __m128d scalar_vec = _mm_set1_pd(scalar); // Broadcast scalar to all elements of the SIMD register\n\n    size_t simd_width = 2; // SSE2 operates on 2 doubles at a time\n    size_t total_elements = m * n;\n\n    // Process elements in chunks of 2 using SIMD\n    size_t i = 0;\n    for (; i + simd_width <= total_elements; i += simd_width) {\n        __m128d mat_vec = _mm_loadu_pd(&mat[i]); // Load 2 doubles from mat\n        __m128d result = _mm_mul_pd(mat_vec, scalar_vec); // Multiply by scalar\n        _mm_storeu_pd(&dst[i], result); // Store the result in dst\n    }\n\n    // Handle remaining elements (if any) with scalar operations\n    for (; i < total_elements; ++i) {\n        dst[i] = mat[i] * scalar;\n    }\n}\n```"}
{"task_id": "SimdBench_23_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid matrix_normalize_rows_simd(float* mat, size_t m, size_t n) {\n    for (size_t i = 0; i < m; ++i) {\n        float* row = mat + i * n;\n        __m128 sum_squares = _mm_setzero_ps();\n        size_t j = 0;\n\n        // Process 4 elements at a time using SSE\n        for (; j + 3 < n; j += 4) {\n            __m128 elements = _mm_loadu_ps(row + j);\n            sum_squares = _mm_add_ps(sum_squares, _mm_mul_ps(elements, elements));\n        }\n\n        // Horizontal sum of the partial sums in sum_squares\n        float norm_sq = 0.0f;\n        alignas(16) float temp[4];\n        _mm_store_ps(temp, sum_squares);\n        norm_sq = temp[0] + temp[1] + temp[2] + temp[3];\n\n        // Process remaining elements\n        for (; j < n; ++j) {\n            norm_sq += row[j] * row[j];\n        }\n\n        // Compute L2 norm\n        float norm = _mm_cvtss_f32(_mm_sqrt_ss(_mm_set_ss(norm_sq)));\n\n        // Normalize the row\n        __m128 inv_norm = _mm_set1_ps(1.0f / norm);\n        j = 0;\n        for (; j + 3 < n; j += 4) {\n            __m128 elements = _mm_loadu_ps(row + j);\n            __m128 normalized = _mm_mul_ps(elements, inv_norm);\n            _mm_storeu_ps(row + j, normalized);\n        }\n\n        // Normalize remaining elements\n        for (; j < n; ++j) {\n            row[j] /= norm;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_23_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid matrix_normalize_rows_simd(float* mat, size_t m, size_t n) {\n    for (size_t i = 0; i < m; ++i) {\n        float* row = mat + i * n;\n        __m128 sum_squares = _mm_setzero_ps();\n\n        // Process elements in chunks of 4 using SSE\n        size_t j = 0;\n        for (; j + 4 <= n; j += 4) {\n            __m128 elements = _mm_loadu_ps(row + j);\n            sum_squares = _mm_add_ps(sum_squares, _mm_mul_ps(elements, elements));\n        }\n\n        // Horizontal sum of the partial sums in sum_squares\n        float norm_sq = 0.0f;\n        alignas(16) float temp[4];\n        _mm_store_ps(temp, sum_squares);\n        norm_sq = temp[0] + temp[1] + temp[2] + temp[3];\n\n        // Handle remaining elements in the row\n        for (; j < n; ++j) {\n            norm_sq += row[j] * row[j];\n        }\n\n        // Compute L2 norm and normalize the row\n        float norm = _mm_cvtss_f32(_mm_sqrt_ss(_mm_set_ss(norm_sq)));\n        if (norm > 1e-8f) { // Avoid division by zero\n            __m128 inv_norm = _mm_set1_ps(1.0f / norm);\n\n            j = 0;\n            for (; j + 4 <= n; j += 4) {\n                __m128 elements = _mm_loadu_ps(row + j);\n                __m128 normalized = _mm_mul_ps(elements, inv_norm);\n                _mm_storeu_ps(row + j, normalized);\n            }\n\n            // Normalize remaining elements\n            for (; j < n; ++j) {\n                row[j] /= norm;\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_23_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid matrix_normalize_rows_simd(float* mat, size_t m, size_t n) {\n    size_t simd_width = 4; // SSE/SSE2 operates on 4 floats at a time\n    __m128 vec, sum_vec, norm_vec;\n\n    for (size_t i = 0; i < m; ++i) {\n        float* row = mat + i * n;\n        sum_vec = _mm_setzero_ps(); // Initialize sum vector to zero\n\n        // Compute the sum of squares for the row using SIMD\n        size_t j = 0;\n        for (; j + simd_width <= n; j += simd_width) {\n            vec = _mm_loadu_ps(row + j);         // Load 4 floats from memory\n            sum_vec = _mm_add_ps(sum_vec, _mm_mul_ps(vec, vec)); // Accumulate squares\n        }\n\n        // Horizontal sum of the partial sums in sum_vec\n        float norm_sq = 0.0f;\n        float temp[4];\n        _mm_storeu_ps(temp, sum_vec);\n        norm_sq = temp[0] + temp[1] + temp[2] + temp[3];\n\n        // Handle remaining elements that don't fit into SIMD width\n        for (; j < n; ++j) {\n            norm_sq += row[j] * row[j];\n        }\n\n        // Compute the L2 norm\n        float norm = _mm_cvtss_f32(_mm_sqrt_ss(_mm_set_ss(norm_sq)));\n\n        // Normalize the row using SIMD\n        norm_vec = _mm_set1_ps(norm); // Broadcast norm to all elements of the vector\n        j = 0;\n        for (; j + simd_width <= n; j += simd_width) {\n            vec = _mm_loadu_ps(row + j);         // Load 4 floats\n            vec = _mm_div_ps(vec, norm_vec);     // Divide by norm\n            _mm_storeu_ps(row + j, vec);         // Store normalized values back\n        }\n\n        // Normalize remaining elements that don't fit into SIMD width\n        for (; j < n; ++j) {\n            row[j] /= norm;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_23_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid matrix_normalize_rows_simd(float* mat, size_t m, size_t n) {\n    for (size_t i = 0; i < m; ++i) {\n        float* row = mat + i * n;\n        __m128 sum_squares = _mm_setzero_ps();\n\n        // Process elements in chunks of 4 using SSE\n        size_t j = 0;\n        for (; j + 4 <= n; j += 4) {\n            __m128 elements = _mm_loadu_ps(row + j);\n            sum_squares = _mm_add_ps(sum_squares, _mm_mul_ps(elements, elements));\n        }\n\n        // Horizontal sum of the partial sums in sum_squares\n        float norm_squared = 0.0f;\n        alignas(16) float temp[4];\n        _mm_store_ps(temp, sum_squares);\n        norm_squared = temp[0] + temp[1] + temp[2] + temp[3];\n\n        // Add remaining elements that didn't fit into a 4-element chunk\n        for (; j < n; ++j) {\n            norm_squared += row[j] * row[j];\n        }\n\n        // Compute the L2 norm\n        float norm = _mm_cvtss_f32(_mm_sqrt_ss(_mm_set_ss(norm_squared)));\n\n        // Normalize the row\n        __m128 inv_norm = _mm_set1_ps(1.0f / norm);\n        j = 0;\n        for (; j + 4 <= n; j += 4) {\n            __m128 elements = _mm_loadu_ps(row + j);\n            __m128 normalized = _mm_mul_ps(elements, inv_norm);\n            _mm_storeu_ps(row + j, normalized);\n        }\n\n        // Normalize remaining elements\n        for (; j < n; ++j) {\n            row[j] /= norm;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_23_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid matrix_normalize_rows_simd(float* mat, size_t m, size_t n) {\n    for (size_t i = 0; i < m; ++i) {\n        float* row = mat + i * n;\n        __m128 sum_squares = _mm_setzero_ps();\n\n        // Process elements in chunks of 4 using SSE\n        size_t j = 0;\n        for (; j + 3 < n; j += 4) {\n            __m128 elements = _mm_loadu_ps(row + j);\n            sum_squares = _mm_add_ps(sum_squares, _mm_mul_ps(elements, elements));\n        }\n\n        // Horizontal sum of the partial sums in sum_squares\n        float norm_sq = 0.0f;\n        alignas(16) float temp[4];\n        _mm_store_ps(temp, sum_squares);\n        norm_sq = temp[0] + temp[1] + temp[2] + temp[3];\n\n        // Handle remaining elements in the row\n        for (; j < n; ++j) {\n            norm_sq += row[j] * row[j];\n        }\n\n        // Compute the L2 norm\n        float norm = _mm_cvtss_f32(_mm_sqrt_ss(_mm_set_ss(norm_sq)));\n\n        // Normalize the row\n        __m128 inv_norm = _mm_set1_ps(1.0f / norm);\n        j = 0;\n        for (; j + 3 < n; j += 4) {\n            __m128 elements = _mm_loadu_ps(row + j);\n            __m128 normalized = _mm_mul_ps(elements, inv_norm);\n            _mm_storeu_ps(row + j, normalized);\n        }\n\n        // Normalize remaining elements\n        for (; j < n; ++j) {\n            row[j] /= norm;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_24_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid matrix_mul_round_int_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n, size_t p) {\n    for (size_t i = 0; i < m; ++i) {\n        for (size_t j = 0; j < p; ++j) {\n            __m128d sum_vec = _mm_setzero_pd();\n            size_t k = 0;\n\n            // Process two elements at a time using SSE2\n            for (; k + 1 < n; k += 2) {\n                __m128d mat1_vec = _mm_loadu_pd(&mat1[i * n + k]);\n                __m128d mat2_vec = _mm_loadu_pd(&mat2[k * p + j]);\n\n                // Multiply and add horizontally\n                sum_vec = _mm_add_pd(sum_vec, _mm_mul_pd(mat1_vec, mat2_vec));\n            }\n\n            // Horizontal sum of the two partial results in sum_vec\n            double sum = 0.0;\n            sum += ((double*)&sum_vec)[0];\n            sum += ((double*)&sum_vec)[1];\n\n            // Process remaining elements\n            for (; k < n; ++k) {\n                sum += mat1[i * n + k] * mat2[k * p + j];\n            }\n\n            // Round to nearest integer and store in dst\n            dst[i * p + j] = nearbyint(sum);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_24_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid matrix_mul_round_int_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n, size_t p) {\n    for (size_t i = 0; i < m; ++i) {\n        for (size_t j = 0; j < p; ++j) {\n            __m128d sum_vec = _mm_setzero_pd();\n            size_t k = 0;\n\n            // Process two elements at a time using SSE2\n            for (; k + 1 < n; k += 2) {\n                __m128d mat1_vec = _mm_loadu_pd(&mat1[i * n + k]);\n                __m128d mat2_vec = _mm_loadu_pd(&mat2[k * p + j]);\n\n                // Multiply and add horizontally\n                sum_vec = _mm_add_pd(sum_vec, _mm_mul_pd(mat1_vec, mat2_vec));\n            }\n\n            // Horizontal sum of the two partial results in sum_vec\n            double temp_sum[2];\n            _mm_storeu_pd(temp_sum, sum_vec);\n            double result = temp_sum[0] + temp_sum[1];\n\n            // Process remaining elements\n            for (; k < n; ++k) {\n                result += mat1[i * n + k] * mat2[k * p + j];\n            }\n\n            // Round to nearest integer and store in dst\n            dst[i * p + j] = nearbyint(result);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_24_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid matrix_mul_round_int_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n, size_t p) {\n    for (size_t i = 0; i < m; ++i) {\n        for (size_t j = 0; j < p; ++j) {\n            __m128d sum_vec = _mm_setzero_pd(); // Initialize sum vector to zero\n\n            size_t k = 0;\n            for (; k + 1 < n; k += 2) { // Process two elements at a time\n                __m128d mat1_vec = _mm_loadu_pd(&mat1[i * n + k]); // Load two elements from mat1\n                __m128d mat2_vec = _mm_loadu_pd(&mat2[k * p + j]); // Load two elements from mat2\n                sum_vec = _mm_add_pd(sum_vec, _mm_mul_pd(mat1_vec, mat2_vec)); // Multiply and accumulate\n            }\n\n            // Horizontal add to reduce the two partial sums into a scalar\n            double sum = ((double*)&sum_vec)[0] + ((double*)&sum_vec)[1];\n\n            // Process remaining elements (if n is odd)\n            for (; k < n; ++k) {\n                sum += mat1[i * n + k] * mat2[k * p + j];\n            }\n\n            // Round the result to the nearest integer and store in dst\n            dst[i * p + j] = nearbyint(sum);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_24_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid matrix_mul_round_int_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n, size_t p) {\n    for (size_t i = 0; i < m; ++i) {\n        for (size_t j = 0; j < p; ++j) {\n            __m128d sum_vec = _mm_setzero_pd();\n            size_t k = 0;\n\n            // Process two elements at a time using SSE2\n            for (; k + 1 < n; k += 2) {\n                __m128d mat1_vec = _mm_loadu_pd(&mat1[i * n + k]);\n                __m128d mat2_vec = _mm_set_pd(mat2[(k + 1) * p + j], mat2[k * p + j]);\n                sum_vec = _mm_add_pd(sum_vec, _mm_mul_pd(mat1_vec, mat2_vec));\n            }\n\n            // Horizontal add to accumulate the partial sums\n            double sum = sum_vec[0] + sum_vec[1];\n\n            // Process remaining elements\n            for (; k < n; ++k) {\n                sum += mat1[i * n + k] * mat2[k * p + j];\n            }\n\n            // Round the result to the nearest integer and store in dst\n            dst[i * p + j] = nearbyint(sum);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_24_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid matrix_mul_round_int_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n, size_t p) {\n    for (size_t i = 0; i < m; ++i) {\n        for (size_t j = 0; j < p; ++j) {\n            __m128d sum_vec = _mm_setzero_pd();\n            size_t k = 0;\n\n            // Process two elements at a time using SSE2\n            for (; k + 1 < n; k += 2) {\n                __m128d mat1_vec = _mm_loadu_pd(&mat1[i * n + k]);\n                __m128d mat2_vec = _mm_loadu_pd(&mat2[k * p + j]);\n\n                __m128d mul_vec = _mm_mul_pd(mat1_vec, mat2_vec);\n                sum_vec = _mm_add_pd(sum_vec, mul_vec);\n            }\n\n            // Horizontal add to combine the two partial sums\n            double sum = sum_vec[0] + sum_vec[1];\n\n            // Process remaining elements\n            for (; k < n; ++k) {\n                sum += mat1[i * n + k] * mat2[k * p + j];\n            }\n\n            // Round to nearest integer and store in dst\n            dst[i * p + j] = nearbyint(sum);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_25_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid matrix_transpose_round_quarter_simd(const float* src, float* dst, size_t rows, size_t cols) {\n    // Constants for rounding to the nearest quarter\n    __m128 quarter = _mm_set1_ps(0.25f);\n    __m128 half = _mm_set1_ps(0.5f);\n\n    // Temporary buffer for transposed blocks\n    alignas(16) float temp[4][4];\n\n    // Process 4x4 blocks of the matrix\n    for (size_t i = 0; i < rows; i += 4) {\n        for (size_t j = 0; j < cols; j += 4) {\n            // Load 4x4 block from src into temporary buffer\n            for (size_t r = 0; r < 4; ++r) {\n                for (size_t c = 0; c < 4; ++c) {\n                    size_t row = i + r;\n                    size_t col = j + c;\n                    temp[r][c] = (row < rows && col < cols) ? src[row * cols + col] : 0.0f;\n                }\n            }\n\n            // Transpose the 4x4 block using SSE\n            __m128 row0 = _mm_loadu_ps(temp[0]);\n            __m128 row1 = _mm_loadu_ps(temp[1]);\n            __m128 row2 = _mm_loadu_ps(temp[2]);\n            __m128 row3 = _mm_loadu_ps(temp[3]);\n\n            __m128 t0 = _mm_unpacklo_ps(row0, row1);\n            __m128 t1 = _mm_unpackhi_ps(row0, row1);\n            __m128 t2 = _mm_unpacklo_ps(row2, row3);\n            __m128 t3 = _mm_unpackhi_ps(row2, row3);\n\n            __m128 col0 = _mm_movelh_ps(t0, t2);\n            __m128 col1 = _mm_movehl_ps(t2, t0);\n            __m128 col2 = _mm_movelh_ps(t1, t3);\n            __m128 col3 = _mm_movehl_ps(t3, t1);\n\n            // Round each element to the nearest quarter\n            col0 = _mm_mul_ps(col0, quarter);\n            col1 = _mm_mul_ps(col1, quarter);\n            col2 = _mm_mul_ps(col2, quarter);\n            col3 = _mm_mul_ps(col3, quarter);\n\n            col0 = _mm_add_ps(col0, half);\n            col1 = _mm_add_ps(col1, half);\n            col2 = _mm_add_ps(col2, half);\n            col3 = _mm_add_ps(col3, half);\n\n            col0 = _mm_floor_ps(col0);\n            col1 = _mm_floor_ps(col1);\n            col2 = _mm_floor_ps(col2);\n            col3 = _mm_floor_ps(col3);\n\n            col0 = _mm_mul_ps(col0, quarter);\n            col1 = _mm_mul_ps(col1, quarter);\n            col2 = _mm_mul_ps(col2, quarter);\n            col3 = _mm_mul_ps(col3, quarter);\n\n            // Store the transposed and rounded block into dst\n            for (size_t r = 0; r < 4; ++r) {\n                for (size_t c = 0; c < 4; ++c) {\n                    size_t row = j + r;\n                    size_t col = i + c;\n                    if (row < cols && col < rows) {\n                        dst[row * rows + col] = ((float*)&col0)[r];\n                    }\n                }\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_25_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid matrix_transpose_round_quarter_simd(const float* src, float* dst, size_t rows, size_t cols) {\n    // Constants for rounding to nearest quarter\n    __m128 multiplier = _mm_set1_ps(4.0f);\n    __m128 divisor = _mm_set1_ps(0.25f);\n\n    // Ensure rows and cols are multiples of 4 for SIMD alignment\n    size_t simd_rows = (rows / 4) * 4;\n    size_t simd_cols = (cols / 4) * 4;\n\n    // Transpose and round using SIMD for aligned blocks\n    for (size_t i = 0; i < simd_rows; i += 4) {\n        for (size_t j = 0; j < simd_cols; j += 4) {\n            // Load 4x4 block from src\n            __m128 row0 = _mm_loadu_ps(&src[i * cols + j]);\n            __m128 row1 = _mm_loadu_ps(&src[(i + 1) * cols + j]);\n            __m128 row2 = _mm_loadu_ps(&src[(i + 2) * cols + j]);\n            __m128 row3 = _mm_loadu_ps(&src[(i + 3) * cols + j]);\n\n            // Transpose the 4x4 block\n            __m128 t0 = _mm_unpacklo_ps(row0, row1);\n            __m128 t1 = _mm_unpacklo_ps(row2, row3);\n            __m128 t2 = _mm_unpackhi_ps(row0, row1);\n            __m128 t3 = _mm_unpackhi_ps(row2, row3);\n\n            __m128 col0 = _mm_movelh_ps(t0, t1);\n            __m128 col1 = _mm_movehl_ps(t1, t0);\n            __m128 col2 = _mm_movelh_ps(t2, t3);\n            __m128 col3 = _mm_movehl_ps(t3, t2);\n\n            // Round each element to the nearest quarter\n            col0 = _mm_mul_ps(col0, multiplier);\n            col1 = _mm_mul_ps(col1, multiplier);\n            col2 = _mm_mul_ps(col2, multiplier);\n            col3 = _mm_mul_ps(col3, multiplier);\n\n            col0 = _mm_round_ps(col0, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n            col1 = _mm_round_ps(col1, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n            col2 = _mm_round_ps(col2, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n            col3 = _mm_round_ps(col3, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n\n            col0 = _mm_mul_ps(col0, divisor);\n            col1 = _mm_mul_ps(col1, divisor);\n            col2 = _mm_mul_ps(col2, divisor);\n            col3 = _mm_mul_ps(col3, divisor);\n\n            // Store the transposed and rounded 4x4 block into dst\n            _mm_storeu_ps(&dst[j * rows + i], col0);\n            _mm_storeu_ps(&dst[j * rows + i + 4], col1);\n            _mm_storeu_ps(&dst[(j + 1) * rows + i], col2);\n            _mm_storeu_ps(&dst[(j + 1) * rows + i + 4], col3);\n        }\n    }\n\n    // Handle remaining rows (if any)\n    for (size_t i = simd_rows; i < rows; ++i) {\n        for (size_t j = 0; j < cols; ++j) {\n            float value = src[i * cols + j];\n            value = roundf(value * 4.0f) * 0.25f;\n            dst[j * rows + i] = value;\n        }\n    }\n\n    // Handle remaining columns (if any)\n    for (size_t i = 0; i < simd_rows; i += 4) {\n        for (size_t j = simd_cols; j < cols; ++j) {\n            for (size_t k = 0; k < 4 && (i + k) < rows; ++k) {\n                float value = src[(i + k) * cols + j];\n                value = roundf(value * 4.0f) * 0.25f;\n                dst[j * rows + i + k] = value;\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_25_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid matrix_transpose_round_quarter_simd(const float* src, float* dst, size_t rows, size_t cols) {\n    __m128 quarter = _mm_set1_ps(0.25f);\n    __m128 half = _mm_set1_ps(0.5f);\n\n    for (size_t i = 0; i < rows; i++) {\n        for (size_t j = 0; j < cols; j += 4) {\n            // Load 4 elements from the source matrix row\n            __m128 src_row = _mm_loadu_ps(&src[i * cols + j]);\n\n            // Add 0.5 for rounding and multiply by 4 to scale to quarters\n            __m128 scaled = _mm_mul_ps(_mm_add_ps(src_row, half), quarter);\n\n            // Round to nearest integer\n            __m128 rounded = _mm_cvtepi32_ps(_mm_cvtps_epi32(scaled));\n\n            // Scale back to original range\n            __m128 result = _mm_mul_ps(rounded, quarter);\n\n            // Store the transposed result in the destination matrix column\n            for (int k = 0; k < 4; k++) {\n                if (j + k < cols) {\n                    dst[(j + k) * rows + i] = result[k];\n                }\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_25_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid matrix_transpose_round_quarter_simd(const float* src, float* dst, size_t rows, size_t cols) {\n    // Constants for rounding to nearest quarter\n    __m128 quarter = _mm_set1_ps(0.25f);\n    __m128 half = _mm_set1_ps(0.5f);\n\n    // Temporary buffer for transposed blocks\n    alignas(16) float temp[4][4];\n\n    // Process 4x4 blocks of the matrix\n    for (size_t i = 0; i < rows; i += 4) {\n        for (size_t j = 0; j < cols; j += 4) {\n            // Load 4x4 block from src into registers\n            __m128 row0 = _mm_loadu_ps(&src[i * cols + j]);\n            __m128 row1 = _mm_loadu_ps(&src[(i + 1) * cols + j]);\n            __m128 row2 = _mm_loadu_ps(&src[(i + 2) * cols + j]);\n            __m128 row3 = _mm_loadu_ps(&src[(i + 3) * cols + j]);\n\n            // Transpose the 4x4 block\n            _MM_TRANSPOSE4_PS(row0, row1, row2, row3);\n\n            // Round each element to the nearest quarter\n            row0 = _mm_mul_ps(row0, quarter);\n            row1 = _mm_mul_ps(row1, quarter);\n            row2 = _mm_mul_ps(row2, quarter);\n            row3 = _mm_mul_ps(row3, quarter);\n\n            row0 = _mm_add_ps(row0, half);\n            row1 = _mm_add_ps(row1, half);\n            row2 = _mm_add_ps(row2, half);\n            row3 = _mm_add_ps(row3, half);\n\n            row0 = _mm_floor_ps(row0);\n            row1 = _mm_floor_ps(row1);\n            row2 = _mm_floor_ps(row2);\n            row3 = _mm_floor_ps(row3);\n\n            row0 = _mm_mul_ps(row0, quarter);\n            row1 = _mm_mul_ps(row1, quarter);\n            row2 = _mm_mul_ps(row2, quarter);\n            row3 = _mm_mul_ps(row3, quarter);\n\n            // Store the transposed and rounded block into temp\n            _mm_store_ps(temp[0], row0);\n            _mm_store_ps(temp[1], row1);\n            _mm_store_ps(temp[2], row2);\n            _mm_store_ps(temp[3], row3);\n\n            // Write the transposed block to dst\n            for (size_t k = 0; k < 4; ++k) {\n                for (size_t l = 0; l < 4; ++l) {\n                    dst[(j + k) * rows + (i + l)] = temp[k][l];\n                }\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_25_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid matrix_transpose_round_quarter_simd(const float* src, float* dst, size_t rows, size_t cols) {\n    // Constants for rounding to nearest quarter\n    __m128 multiplier = _mm_set1_ps(4.0f);\n    __m128 divisor = _mm_set1_ps(4.0f);\n\n    // Temporary buffer for transposed blocks\n    alignas(16) float temp[4][4];\n\n    // Process 4x4 blocks of the matrix\n    for (size_t i = 0; i < rows; i += 4) {\n        for (size_t j = 0; j < cols; j += 4) {\n            // Load 4x4 block from src into temporary buffer\n            for (size_t x = 0; x < 4; ++x) {\n                for (size_t y = 0; y < 4; ++y) {\n                    size_t src_idx = (i + x) * cols + (j + y);\n                    temp[x][y] = (src_idx < rows * cols) ? src[src_idx] : 0.0f;\n                }\n            }\n\n            // Transpose the 4x4 block\n            __m128 row0 = _mm_loadu_ps(temp[0]);\n            __m128 row1 = _mm_loadu_ps(temp[1]);\n            __m128 row2 = _mm_loadu_ps(temp[2]);\n            __m128 row3 = _mm_loadu_ps(temp[3]);\n\n            __m128 t0 = _mm_unpacklo_ps(row0, row1);\n            __m128 t1 = _mm_unpackhi_ps(row0, row1);\n            __m128 t2 = _mm_unpacklo_ps(row2, row3);\n            __m128 t3 = _mm_unpackhi_ps(row2, row3);\n\n            __m128 col0 = _mm_movelh_ps(t0, t2);\n            __m128 col1 = _mm_movehl_ps(t2, t0);\n            __m128 col2 = _mm_movelh_ps(t1, t3);\n            __m128 col3 = _mm_movehl_ps(t3, t1);\n\n            // Round each element to the nearest quarter\n            col0 = _mm_mul_ps(col0, multiplier);\n            col1 = _mm_mul_ps(col1, multiplier);\n            col2 = _mm_mul_ps(col2, multiplier);\n            col3 = _mm_mul_ps(col3, multiplier);\n\n            col0 = _mm_round_ps(col0, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n            col1 = _mm_round_ps(col1, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n            col2 = _mm_round_ps(col2, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n            col3 = _mm_round_ps(col3, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n\n            col0 = _mm_div_ps(col0, divisor);\n            col1 = _mm_div_ps(col1, divisor);\n            col2 = _mm_div_ps(col2, divisor);\n            col3 = _mm_div_ps(col3, divisor);\n\n            // Store the transposed and rounded block into dst\n            for (size_t x = 0; x < 4; ++x) {\n                size_t dst_idx_base = (j + x) * rows + i;\n                _mm_storeu_ps(&dst[dst_idx_base], _mm_set_ps(\n                    (dst_idx_base + 3 < rows * cols) ? col3.m128_f32[x] : 0.0f,\n                    (dst_idx_base + 2 < rows * cols) ? col2.m128_f32[x] : 0.0f,\n                    (dst_idx_base + 1 < rows * cols) ? col1.m128_f32[x] : 0.0f,\n                    (dst_idx_base + 0 < rows * cols) ? col0.m128_f32[x] : 0.0f\n                ));\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_26_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid tensor3d_sub_round_zero_simd(const float* tensor1, const float* tensor2, float* dst, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t i = 0;\n\n    // Process 4 elements at a time using SSE\n    for (; i + 4 <= total_elements; i += 4) {\n        // Load 4 floats from tensor1 and tensor2\n        __m128 vec1 = _mm_loadu_ps(&tensor1[i]);\n        __m128 vec2 = _mm_loadu_ps(&tensor2[i]);\n\n        // Subtract tensor2 from tensor1\n        __m128 result = _mm_sub_ps(vec1, vec2);\n\n        // Round towards zero (truncate)\n        __m128 truncated = _mm_cvtepi32_ps(_mm_cvttps_epi32(result));\n\n        // Store the result in dst\n        _mm_storeu_ps(&dst[i], truncated);\n    }\n\n    // Handle remaining elements (if any)\n    for (; i < total_elements; ++i) {\n        dst[i] = (float)((int)(tensor1[i] - tensor2[i]));\n    }\n}\n```"}
{"task_id": "SimdBench_26_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid tensor3d_sub_round_zero_simd(const float* tensor1, const float* tensor2, float* dst, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n\n    // Process 4 elements at a time using SSE\n    size_t i = 0;\n    for (; i + 4 <= total_elements; i += 4) {\n        // Load 4 floats from tensor1 and tensor2\n        __m128 v1 = _mm_loadu_ps(&tensor1[i]);\n        __m128 v2 = _mm_loadu_ps(&tensor2[i]);\n\n        // Subtract tensor2 from tensor1\n        __m128 result = _mm_sub_ps(v1, v2);\n\n        // Round towards zero using truncation\n        __m128 truncated = _mm_cvtepi32_ps(_mm_cvttps_epi32(result));\n\n        // Store the result in dst\n        _mm_storeu_ps(&dst[i], truncated);\n    }\n\n    // Handle remaining elements (if any)\n    for (; i < total_elements; ++i) {\n        dst[i] = (float)((int)(tensor1[i] - tensor2[i]));\n    }\n}\n```"}
{"task_id": "SimdBench_26_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid tensor3d_sub_round_zero_simd(const float* tensor1, const float* tensor2, float* dst, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t i = 0;\n\n    // Process 4 elements at a time using SSE\n    for (; i + 4 <= total_elements; i += 4) {\n        // Load 4 floats from tensor1 and tensor2\n        __m128 vec1 = _mm_loadu_ps(&tensor1[i]);\n        __m128 vec2 = _mm_loadu_ps(&tensor2[i]);\n\n        // Subtract tensor2 from tensor1\n        __m128 result = _mm_sub_ps(vec1, vec2);\n\n        // Round towards zero using SSE2 intrinsic\n        __m128i int_result = _mm_cvttps_epi32(result); // Convert to integer with truncation\n        __m128 rounded_result = _mm_cvtepi32_ps(int_result); // Convert back to float\n\n        // Store the result in dst\n        _mm_storeu_ps(&dst[i], rounded_result);\n    }\n\n    // Handle remaining elements (if any)\n    for (; i < total_elements; ++i) {\n        dst[i] = (float)((int)(tensor1[i] - tensor2[i])); // Subtract and round towards zero\n    }\n}\n```"}
{"task_id": "SimdBench_26_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid tensor3d_sub_round_zero_simd(const float* tensor1, const float* tensor2, float* dst, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n\n    // Process 4 elements at a time using SSE\n    size_t i = 0;\n    for (; i + 4 <= total_elements; i += 4) {\n        // Load 4 floats from tensor1 and tensor2\n        __m128 vec1 = _mm_loadu_ps(&tensor1[i]);\n        __m128 vec2 = _mm_loadu_ps(&tensor2[i]);\n\n        // Perform element-wise subtraction\n        __m128 result = _mm_sub_ps(vec1, vec2);\n\n        // Round towards zero using truncation\n        __m128 rounded = _mm_cvtepi32_ps(_mm_cvttps_epi32(result));\n\n        // Store the result in dst\n        _mm_storeu_ps(&dst[i], rounded);\n    }\n\n    // Handle remaining elements (if any)\n    for (; i < total_elements; ++i) {\n        dst[i] = (float)((int)(tensor1[i] - tensor2[i]));\n    }\n}\n```"}
{"task_id": "SimdBench_26_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid tensor3d_sub_round_zero_simd(const float* tensor1, const float* tensor2, float* dst, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n\n    // Process 4 elements at a time using SSE\n    size_t i = 0;\n    for (; i + 4 <= total_elements; i += 4) {\n        // Load 4 floats from tensor1 and tensor2\n        __m128 vec1 = _mm_loadu_ps(&tensor1[i]);\n        __m128 vec2 = _mm_loadu_ps(&tensor2[i]);\n\n        // Perform element-wise subtraction\n        __m128 result = _mm_sub_ps(vec1, vec2);\n\n        // Round towards zero using truncation\n        __m128i truncated = _mm_cvttps_epi32(result); // Convert to integers with truncation\n        __m128 rounded = _mm_cvtepi32_ps(truncated);  // Convert back to floats\n\n        // Store the result in dst\n        _mm_storeu_ps(&dst[i], rounded);\n    }\n\n    // Handle remaining elements (if any)\n    for (; i < total_elements; ++i) {\n        dst[i] = (float)((int)(tensor1[i] - tensor2[i])); // Subtract and round towards zero\n    }\n}\n```"}
{"task_id": "SimdBench_27_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid matrix_hadamard_product_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n) {\n    size_t simd_width = 2; // SSE/SSE2 processes 2 doubles at a time\n    size_t n_aligned = (n / simd_width) * simd_width;\n\n    for (size_t i = 0; i < m; ++i) {\n        size_t j = 0;\n        // Process elements in chunks of 2 using SIMD\n        for (; j < n_aligned; j += simd_width) {\n            __m128d vec1 = _mm_loadu_pd(&mat1[i * n + j]); // Load 2 doubles from mat1\n            __m128d vec2 = _mm_loadu_pd(&mat2[i * n + j]); // Load 2 doubles from mat2\n            __m128d result = _mm_mul_pd(vec1, vec2);       // Multiply the two vectors element-wise\n            _mm_storeu_pd(&dst[i * n + j], result);        // Store the result into dst\n        }\n        // Process remaining elements (if any) using scalar operations\n        for (; j < n; ++j) {\n            dst[i * n + j] = mat1[i * n + j] * mat2[i * n + j];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_27_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid matrix_hadamard_product_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n) {\n    size_t simd_width = 2; // SSE/SSE2 processes 2 doubles at a time\n    size_t simd_aligned_n = (n / simd_width) * simd_width;\n\n    for (size_t i = 0; i < m; ++i) {\n        size_t j = 0;\n        // Process elements in chunks of 2 using SIMD\n        for (; j < simd_aligned_n; j += simd_width) {\n            __m128d vec1 = _mm_loadu_pd(&mat1[i * n + j]); // Load 2 doubles from mat1\n            __m128d vec2 = _mm_loadu_pd(&mat2[i * n + j]); // Load 2 doubles from mat2\n            __m128d result = _mm_mul_pd(vec1, vec2);       // Element-wise multiplication\n            _mm_storeu_pd(&dst[i * n + j], result);        // Store the result in dst\n        }\n        // Process remaining elements (if any) with scalar operations\n        for (; j < n; ++j) {\n            dst[i * n + j] = mat1[i * n + j] * mat2[i * n + j];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_27_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid matrix_hadamard_product_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n) {\n    size_t simd_width = 2; // SSE2 processes 2 doubles at a time\n    size_t simd_aligned_n = (n / simd_width) * simd_width;\n\n    for (size_t i = 0; i < m; ++i) {\n        size_t j = 0;\n        // Process elements in chunks of 2 using SSE2\n        for (; j < simd_aligned_n; j += simd_width) {\n            __m128d vec1 = _mm_loadu_pd(&mat1[i * n + j]); // Load 2 doubles from mat1\n            __m128d vec2 = _mm_loadu_pd(&mat2[i * n + j]); // Load 2 doubles from mat2\n            __m128d result = _mm_mul_pd(vec1, vec2);       // Multiply the 2 doubles\n            _mm_storeu_pd(&dst[i * n + j], result);        // Store the result in dst\n        }\n        // Process remaining elements that are not aligned to simd_width\n        for (; j < n; ++j) {\n            dst[i * n + j] = mat1[i * n + j] * mat2[i * n + j];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_27_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid matrix_hadamard_product_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n) {\n    size_t simd_width = 2; // SSE/SSE2 processes 2 doubles at a time\n    size_t n_aligned = (n / simd_width) * simd_width;\n\n    for (size_t i = 0; i < m; ++i) {\n        size_t j = 0;\n        // Process elements in chunks of 2 using SSE/SSE2\n        for (; j < n_aligned; j += simd_width) {\n            __m128d vec1 = _mm_loadu_pd(&mat1[i * n + j]); // Load 2 doubles from mat1\n            __m128d vec2 = _mm_loadu_pd(&mat2[i * n + j]); // Load 2 doubles from mat2\n            __m128d result = _mm_mul_pd(vec1, vec2);       // Element-wise multiplication\n            _mm_storeu_pd(&dst[i * n + j], result);        // Store the result in dst\n        }\n        // Process remaining elements (if any)\n        for (; j < n; ++j) {\n            dst[i * n + j] = mat1[i * n + j] * mat2[i * n + j];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_27_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid matrix_hadamard_product_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n) {\n    size_t simd_width = 2; // SSE/SSE2 processes 2 doubles at a time (128-bit registers)\n    size_t simd_aligned_n = n - (n % simd_width);\n\n    for (size_t i = 0; i < m; ++i) {\n        size_t j = 0;\n\n        // Process elements in chunks of 2 using SIMD\n        for (; j < simd_aligned_n; j += simd_width) {\n            __m128d vec1 = _mm_loadu_pd(&mat1[i * n + j]); // Load 2 doubles from mat1\n            __m128d vec2 = _mm_loadu_pd(&mat2[i * n + j]); // Load 2 doubles from mat2\n            __m128d result = _mm_mul_pd(vec1, vec2);       // Multiply the two vectors element-wise\n            _mm_storeu_pd(&dst[i * n + j], result);        // Store the result back to dst\n        }\n\n        // Handle remaining elements that are not aligned with SIMD width\n        for (; j < n; ++j) {\n            dst[i * n + j] = mat1[i * n + j] * mat2[i * n + j];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_28_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n\nvoid matrix_vector_mul_simd(const float* mat, const float* vec, float* dst, size_t m, size_t n) {\n    for (size_t i = 0; i < m; ++i) {\n        __m128 result = _mm_setzero_ps();\n        size_t j = 0;\n\n        // Process 4 elements at a time using SSE\n        for (; j + 4 <= n; j += 4) {\n            __m128 mat_row = _mm_loadu_ps(&mat[i * n + j]); // Load 4 elements from the matrix row\n            __m128 vec_vals = _mm_loadu_ps(&vec[j]);        // Load 4 elements from the vector\n            result = _mm_add_ps(result, _mm_mul_ps(mat_row, vec_vals)); // Multiply and accumulate\n        }\n\n        // Horizontal sum of the result vector\n        float temp[4];\n        _mm_storeu_ps(temp, result);\n        float sum = temp[0] + temp[1] + temp[2] + temp[3];\n\n        // Process remaining elements\n        for (; j < n; ++j) {\n            sum += mat[i * n + j] * vec[j];\n        }\n\n        dst[i] = sum;\n    }\n}\n```"}
{"task_id": "SimdBench_28_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n\nvoid matrix_vector_mul_simd(const float* mat, const float* vec, float* dst, size_t m, size_t n) {\n    for (size_t i = 0; i < m; ++i) {\n        __m128 result_vec = _mm_setzero_ps();\n        size_t j = 0;\n\n        // Process 4 elements at a time using SSE\n        for (; j + 3 < n; j += 4) {\n            __m128 mat_row = _mm_loadu_ps(&mat[i * n + j]); // Load 4 elements from the matrix row\n            __m128 vec_vals = _mm_loadu_ps(&vec[j]);        // Load 4 elements from the vector\n            result_vec = _mm_add_ps(result_vec, _mm_mul_ps(mat_row, vec_vals)); // Multiply and accumulate\n        }\n\n        // Horizontal sum of the result_vec\n        float temp[4];\n        _mm_storeu_ps(temp, result_vec);\n        float sum = temp[0] + temp[1] + temp[2] + temp[3];\n\n        // Process remaining elements that don't fit into 4-element chunks\n        for (; j < n; ++j) {\n            sum += mat[i * n + j] * vec[j];\n        }\n\n        dst[i] = sum;\n    }\n}\n```"}
{"task_id": "SimdBench_28_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n\nvoid matrix_vector_mul_simd(const float* mat, const float* vec, float* dst, size_t m, size_t n) {\n    for (size_t i = 0; i < m; ++i) {\n        __m128 result = _mm_setzero_ps();\n        size_t j = 0;\n\n        // Process 4 elements at a time using SSE\n        for (; j + 4 <= n; j += 4) {\n            __m128 mat_row = _mm_loadu_ps(&mat[i * n + j]); // Load 4 elements from the matrix row\n            __m128 vec_vals = _mm_loadu_ps(&vec[j]);        // Load 4 elements from the vector\n            result = _mm_add_ps(result, _mm_mul_ps(mat_row, vec_vals)); // Multiply and accumulate\n        }\n\n        // Horizontal sum of the result vector\n        float temp[4];\n        _mm_storeu_ps(temp, result);\n        float sum = temp[0] + temp[1] + temp[2] + temp[3];\n\n        // Process remaining elements that are less than 4\n        for (; j < n; ++j) {\n            sum += mat[i * n + j] * vec[j];\n        }\n\n        dst[i] = sum;\n    }\n}\n```"}
{"task_id": "SimdBench_28_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n\nvoid matrix_vector_mul_simd(const float* mat, const float* vec, float* dst, size_t m, size_t n) {\n    for (size_t i = 0; i < m; ++i) {\n        __m128 result_vec = _mm_setzero_ps();\n        size_t j = 0;\n\n        // Process 4 elements at a time using SSE\n        for (; j + 3 < n; j += 4) {\n            __m128 mat_row = _mm_loadu_ps(&mat[i * n + j]); // Load 4 elements from the matrix row\n            __m128 vec_vals = _mm_loadu_ps(&vec[j]);        // Load 4 elements from the vector\n            result_vec = _mm_add_ps(result_vec, _mm_mul_ps(mat_row, vec_vals)); // Multiply and accumulate\n        }\n\n        // Horizontal sum of the result_vec\n        float temp[4];\n        _mm_storeu_ps(temp, result_vec);\n        float sum = temp[0] + temp[1] + temp[2] + temp[3];\n\n        // Process remaining elements that are less than 4\n        for (; j < n; ++j) {\n            sum += mat[i * n + j] * vec[j];\n        }\n\n        dst[i] = sum;\n    }\n}\n```"}
{"task_id": "SimdBench_28_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n\nvoid matrix_vector_mul_simd(const float* mat, const float* vec, float* dst, size_t m, size_t n) {\n    for (size_t i = 0; i < m; ++i) {\n        __m128 result_vec = _mm_setzero_ps();\n        size_t j = 0;\n\n        // Process 4 elements at a time using SSE\n        for (; j + 4 <= n; j += 4) {\n            __m128 mat_row = _mm_loadu_ps(&mat[i * n + j]); // Load 4 elements from the matrix row\n            __m128 vec_vals = _mm_loadu_ps(&vec[j]);        // Load 4 elements from the vector\n            result_vec = _mm_add_ps(result_vec, _mm_mul_ps(mat_row, vec_vals)); // Multiply and accumulate\n        }\n\n        // Horizontal sum of the result_vec\n        float temp[4];\n        _mm_storeu_ps(temp, result_vec);\n        float sum = temp[0] + temp[1] + temp[2] + temp[3];\n\n        // Process remaining elements\n        for (; j < n; ++j) {\n            sum += mat[i * n + j] * vec[j];\n        }\n\n        dst[i] = sum;\n    }\n}\n```"}
{"task_id": "SimdBench_29_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\ndouble matrix_average_simd(const double* mat, size_t m, size_t n) {\n    __m128d sum_vec = _mm_setzero_pd();\n    size_t total_elements = m * n;\n    size_t i = 0;\n\n    // Process 2 elements at a time using SSE2\n    for (; i + 1 < total_elements; i += 2) {\n        __m128d vec = _mm_loadu_pd(&mat[i]);\n        sum_vec = _mm_add_pd(sum_vec, vec);\n    }\n\n    // Horizontal sum of the SSE register\n    double sum = 0.0;\n    sum += ((double*)&sum_vec)[0] + ((double*)&sum_vec)[1];\n\n    // Add remaining elements\n    for (; i < total_elements; ++i) {\n        sum += mat[i];\n    }\n\n    return sum / total_elements;\n}\n```"}
{"task_id": "SimdBench_29_SSE", "completion": "```cpp\ndouble matrix_average_simd(const double* mat, size_t m, size_t n) {\n    __m128d sum_vec = _mm_setzero_pd();\n    size_t total_elements = m * n;\n    size_t i = 0;\n\n    // Process two elements at a time using SSE2\n    for (; i + 1 < total_elements; i += 2) {\n        __m128d vec = _mm_loadu_pd(&mat[i]);\n        sum_vec = _mm_add_pd(sum_vec, vec);\n    }\n\n    // Horizontal sum of the SSE vector\n    double sum = 0.0;\n    sum += ((double*)&sum_vec)[0] + ((double*)&sum_vec)[1];\n\n    // Add any remaining elements\n    for (; i < total_elements; ++i) {\n        sum += mat[i];\n    }\n\n    return sum / total_elements;\n}\n```"}
{"task_id": "SimdBench_29_SSE", "completion": "```cpp\ndouble matrix_average_simd(const double* mat, size_t m, size_t n) {\n    __m128d sum_vec = _mm_setzero_pd();\n    size_t total_elements = m * n;\n    size_t i = 0;\n\n    // Process two elements at a time using SSE2\n    for (; i + 1 < total_elements; i += 2) {\n        __m128d vec = _mm_loadu_pd(&mat[i]);\n        sum_vec = _mm_add_pd(sum_vec, vec);\n    }\n\n    // Horizontal sum of the SSE vector\n    double sum = 0.0;\n    sum += ((double*)&sum_vec)[0] + ((double*)&sum_vec)[1];\n\n    // Add any remaining elements\n    for (; i < total_elements; ++i) {\n        sum += mat[i];\n    }\n\n    return sum / total_elements;\n}\n```"}
{"task_id": "SimdBench_29_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\ndouble matrix_average_simd(const double* mat, size_t m, size_t n) {\n    __m128d sum_vec = _mm_setzero_pd();\n    size_t total_elements = m * n;\n    size_t i = 0;\n\n    // Process 2 elements at a time using SSE2\n    for (; i + 1 < total_elements; i += 2) {\n        __m128d vec = _mm_loadu_pd(&mat[i]);\n        sum_vec = _mm_add_pd(sum_vec, vec);\n    }\n\n    // Horizontal sum of the SSE register\n    double sum = 0.0;\n    sum += ((double*)&sum_vec)[0] + ((double*)&sum_vec)[1];\n\n    // Add any remaining elements\n    for (; i < total_elements; ++i) {\n        sum += mat[i];\n    }\n\n    return sum / total_elements;\n}\n```"}
{"task_id": "SimdBench_29_SSE", "completion": "```cpp\ndouble matrix_average_simd(const double* mat, size_t m, size_t n) {\n    __m128d sum_vec = _mm_setzero_pd();\n    size_t total_elements = m * n;\n    size_t i = 0;\n\n    // Process two elements at a time using SSE2\n    for (; i + 1 < total_elements; i += 2) {\n        __m128d vec = _mm_loadu_pd(&mat[i]);\n        sum_vec = _mm_add_pd(sum_vec, vec);\n    }\n\n    // Horizontal sum of the SSE vector\n    double sum = 0.0;\n    sum = _mm_cvtsd_f64(_mm_hadd_pd(sum_vec, sum_vec));\n\n    // Add any remaining elements\n    for (; i < total_elements; ++i) {\n        sum += mat[i];\n    }\n\n    return sum / total_elements;\n}\n```"}
{"task_id": "SimdBench_30_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool matrix_rows_sorted_verify_simd(const int* matrix, const bool* directions, size_t rows, size_t cols) {\n    for (size_t i = 0; i < rows; ++i) {\n        const int* row = matrix + i * cols;\n        bool ascending = directions[i];\n        size_t j = 0;\n\n        // Process 4 elements at a time using SSE2\n        for (; j + 4 <= cols; j += 4) {\n            __m128i current = _mm_loadu_si128((__m128i*)(row + j));\n            __m128i next = _mm_loadu_si128((__m128i*)(row + j + 1));\n\n            __m128i cmp;\n            if (ascending) {\n                cmp = _mm_cmpgt_epi32(current, next); // Check if current > next\n            } else {\n                cmp = _mm_cmplt_epi32(current, next); // Check if current < next\n            }\n\n            // If any element violates the order, return false\n            if (!_mm_testz_si128(cmp, cmp)) {\n                return false;\n            }\n        }\n\n        // Process remaining elements\n        for (; j < cols - 1; ++j) {\n            if ((ascending && row[j] > row[j + 1]) || (!ascending && row[j] < row[j + 1])) {\n                return false;\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_30_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool matrix_rows_sorted_verify_simd(const int* matrix, const bool* directions, size_t rows, size_t cols) {\n    for (size_t i = 0; i < rows; ++i) {\n        const int* row = matrix + i * cols;\n        bool ascending = directions[i];\n        \n        size_t j = 0;\n        // Process 4 elements at a time using SSE2\n        for (; j + 4 <= cols; j += 4) {\n            __m128i current = _mm_loadu_si128((__m128i*)(row + j));\n            __m128i next = _mm_loadu_si128((__m128i*)(row + j + 1));\n\n            __m128i cmp;\n            if (ascending) {\n                cmp = _mm_cmpgt_epi32(current, next); // Check if current > next\n            } else {\n                cmp = _mm_cmpgt_epi32(next, current); // Check if next > current\n            }\n\n            // If any element in cmp is non-zero, the row is not sorted correctly\n            if (_mm_movemask_epi8(cmp)) {\n                return false;\n            }\n        }\n\n        // Process remaining elements\n        for (; j < cols - 1; ++j) {\n            if ((ascending && row[j] > row[j + 1]) || (!ascending && row[j] < row[j + 1])) {\n                return false;\n            }\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_30_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool matrix_rows_sorted_verify_simd(const int* matrix, const bool* directions, size_t rows, size_t cols) {\n    for (size_t i = 0; i < rows; ++i) {\n        const int* row = matrix + i * cols;\n        bool ascending = directions[i];\n        \n        size_t j = 0;\n        // Process 4 elements at a time using SSE2\n        for (; j <= cols - 4; j += 4) {\n            __m128i current = _mm_loadu_si128((__m128i*)(row + j));\n            __m128i next = _mm_loadu_si128((__m128i*)(row + j + 1));\n\n            __m128i cmp;\n            if (ascending) {\n                cmp = _mm_cmpgt_epi32(current, next); // Check if current > next\n            } else {\n                cmp = _mm_cmpgt_epi32(next, current); // Check if next > current\n            }\n\n            // If any element fails the condition, return false\n            if (!_mm_testz_si128(cmp, cmp)) {\n                return false;\n            }\n        }\n\n        // Process remaining elements\n        for (; j < cols - 1; ++j) {\n            if ((ascending && row[j] > row[j + 1]) || (!ascending && row[j] < row[j + 1])) {\n                return false;\n            }\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_30_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool matrix_rows_sorted_verify_simd(const int* matrix, const bool* directions, size_t rows, size_t cols) {\n    for (size_t i = 0; i < rows; ++i) {\n        const int* row = matrix + i * cols;\n        bool ascending = directions[i];\n        size_t j = 0;\n\n        // Process 4 elements at a time using SSE2\n        for (; j + 4 <= cols; j += 4) {\n            __m128i current = _mm_loadu_si128((__m128i*)(row + j));\n            __m128i next = _mm_loadu_si128((__m128i*)(row + j + 1));\n\n            __m128i cmp;\n            if (ascending) {\n                cmp = _mm_cmpgt_epi32(current, next); // Check if current > next\n            } else {\n                cmp = _mm_cmpgt_epi32(next, current); // Check if next > current\n            }\n\n            // If any element fails the condition, return false\n            if (!_mm_testz_si128(cmp, cmp)) {\n                return false;\n            }\n        }\n\n        // Handle remaining elements\n        for (; j + 1 < cols; ++j) {\n            if ((ascending && row[j] > row[j + 1]) || (!ascending && row[j] < row[j + 1])) {\n                return false;\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_30_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool matrix_rows_sorted_verify_simd(const int* matrix, const bool* directions, size_t rows, size_t cols) {\n    for (size_t i = 0; i < rows; ++i) {\n        const int* row = matrix + i * cols;\n        bool ascending = directions[i];\n        \n        size_t j = 0;\n        // Process 4 elements at a time using SSE2\n        for (; j <= cols - 4; j += 4) {\n            __m128i current = _mm_loadu_si128((__m128i*)(row + j));\n            __m128i next = _mm_loadu_si128((__m128i*)(row + j + 1));\n\n            __m128i cmp;\n            if (ascending) {\n                cmp = _mm_cmpgt_epi32(current, next); // Check if current > next\n            } else {\n                cmp = _mm_cmpgt_epi32(next, current); // Check if next > current\n            }\n\n            // If any element is not sorted correctly, return false\n            if (!_mm_testz_si128(cmp, cmp)) {\n                return false;\n            }\n        }\n\n        // Process remaining elements\n        for (; j < cols - 1; ++j) {\n            if ((ascending && row[j] > row[j + 1]) || (!ascending && row[j] < row[j + 1])) {\n                return false;\n            }\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_31_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid nearest_multiple_simd(const int16_t* src, int16_t* dst, uint8_t base, size_t length) {\n    __m128i vbase = _mm_set1_epi16(base);\n    __m128i vzero = _mm_setzero_si128();\n\n    size_t i = 0;\n    for (; i + 8 <= length; i += 8) {\n        // Load 8 elements from src\n        __m128i vsrc = _mm_loadu_si128((__m128i*)&src[i]);\n\n        // Compute the quotient: (vsrc / base)\n        __m128i quotient = _mm_div_epi16(vsrc, vbase);\n\n        // Multiply quotient by base to get the nearest multiple of base\n        __m128i vmultiple = _mm_mullo_epi16(quotient, vbase);\n\n        // Store the result into dst\n        _mm_storeu_si128((__m128i*)&dst[i], vmultiple);\n    }\n\n    // Handle remaining elements\n    for (; i < length; ++i) {\n        dst[i] = (int16_t)((src[i] / base) * base);\n    }\n}\n```"}
{"task_id": "SimdBench_31_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid nearest_multiple_simd(const int16_t* src, int16_t* dst, uint8_t base, size_t length) {\n    __m128i vbase = _mm_set1_epi16(base);\n    __m128i vzero = _mm_setzero_si128();\n\n    size_t i = 0;\n    for (; i + 8 <= length; i += 8) {\n        // Load 8 elements from src\n        __m128i vsrc = _mm_loadu_si128((__m128i*)&src[i]);\n\n        // Compute quotient: divide each element by base (truncate towards zero)\n        __m128i vquotient = _mm_div_epi16(vsrc, vbase);\n\n        // Multiply quotient by base to get the largest multiple of base <= src\n        __m128i vmultiple = _mm_mullo_epi16(vquotient, vbase);\n\n        // Store the result into dst\n        _mm_storeu_si128((__m128i*)&dst[i], vmultiple);\n    }\n\n    // Handle remaining elements\n    for (; i < length; ++i) {\n        dst[i] = (int16_t)((src[i] / base) * base);\n    }\n}\n```"}
{"task_id": "SimdBench_31_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid nearest_multiple_simd(const int16_t* src, int16_t* dst, uint8_t base, size_t length) {\n    __m128i vbase = _mm_set1_epi16(base);\n    __m128i vzero = _mm_setzero_si128();\n    \n    size_t i = 0;\n    for (; i + 8 <= length; i += 8) {\n        // Load 8 elements from src\n        __m128i vsrc = _mm_loadu_si128((__m128i*)&src[i]);\n        \n        // Divide each element by base (using shifts and arithmetic)\n        __m128i quotient = _mm_div_epi16(vsrc, vbase);\n        \n        // Multiply the quotient by base to get the nearest multiple\n        __m128i vmultiple = _mm_mullo_epi16(quotient, vbase);\n        \n        // Store the result into dst\n        _mm_storeu_si128((__m128i*)&dst[i], vmultiple);\n    }\n    \n    // Handle remaining elements\n    for (; i < length; ++i) {\n        dst[i] = (int16_t)((src[i] / base) * base);\n    }\n}\n```"}
{"task_id": "SimdBench_31_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid nearest_multiple_simd(const int16_t* src, int16_t* dst, uint8_t base, size_t length) {\n    __m128i vbase = _mm_set1_epi16(base);\n    __m128i vzero = _mm_setzero_si128();\n    \n    size_t i = 0;\n    for (; i + 8 <= length; i += 8) {\n        // Load 8 elements from src\n        __m128i vsrc = _mm_loadu_si128((__m128i*)&src[i]);\n        \n        // Compute quotient: divide each element by base (truncate towards zero)\n        __m128i vquotient = _mm_div_epi16(vsrc, vbase);\n        \n        // Multiply quotient by base to get the largest multiple of base <= src\n        __m128i vmultiple = _mm_mullo_epi16(vquotient, vbase);\n        \n        // Store the result into dst\n        _mm_storeu_si128((__m128i*)&dst[i], vmultiple);\n    }\n    \n    // Handle remaining elements\n    for (; i < length; ++i) {\n        dst[i] = (int16_t)((src[i] / base) * base);\n    }\n}\n```"}
{"task_id": "SimdBench_31_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid nearest_multiple_simd(const int16_t* src, int16_t* dst, uint8_t base, size_t length) {\n    __m128i vbase = _mm_set1_epi16(base);\n    __m128i vzero = _mm_setzero_si128();\n    \n    size_t i = 0;\n    for (; i + 8 <= length; i += 8) {\n        // Load 8 elements from src\n        __m128i vsrc = _mm_loadu_si128((__m128i*)&src[i]);\n        \n        // Compute quotient: divide each element by base (truncate towards zero)\n        __m128i vquotient = _mm_div_epi16(vsrc, vbase);\n        \n        // Multiply quotient by base to get the largest multiple of base <= src\n        __m128i vmultiple = _mm_mullo_epi16(vquotient, vbase);\n        \n        // Store the result into dst\n        _mm_storeu_si128((__m128i*)&dst[i], vmultiple);\n    }\n    \n    // Handle remaining elements\n    for (; i < length; ++i) {\n        dst[i] = (int16_t)((src[i] / base) * base);\n    }\n}\n```"}
{"task_id": "SimdBench_32_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool matrix_has_row_simd(const double* matrix, const double* vector, size_t rows, size_t cols) {\n    // Load the vector into SIMD registers for reuse\n    __m128d vec_reg[2];\n    vec_reg[0] = _mm_loadu_pd(vector);       // Load first two doubles\n    vec_reg[1] = _mm_loadu_pd(vector + 2);   // Load next two doubles (if cols >= 4)\n\n    for (size_t i = 0; i < rows; ++i) {\n        const double* row = matrix + i * cols;\n        bool match = true;\n\n        size_t j = 0;\n        // Process 2 doubles at a time using SSE2\n        for (; j + 1 < cols; j += 2) {\n            __m128d row_reg = _mm_loadu_pd(row + j);\n            __m128d cmp = _mm_cmpeq_pd(row_reg, vec_reg[j / 2]);\n            int mask = _mm_movemask_pd(cmp);\n            if (mask != 0x3) { // Check if both elements match\n                match = false;\n                break;\n            }\n        }\n\n        // Handle remaining elements (if cols is odd)\n        if (j < cols) {\n            if (row[j] != vector[j]) {\n                match = false;\n            }\n        }\n\n        if (match) {\n            return true;\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_32_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool matrix_has_row_simd(const double* matrix, const double* vector, size_t rows, size_t cols) {\n    // Ensure the number of columns is a multiple of 2 for SSE2 alignment\n    if (cols % 2 != 0) {\n        return false; // Unsupported configuration\n    }\n\n    // Load the vector into two SIMD registers (for 128-bit alignment)\n    __m128d vec_low = _mm_loadu_pd(vector);       // Load first two elements of vector\n    __m128d vec_high = _mm_loadu_pd(vector + 2);  // Load next two elements of vector\n\n    for (size_t i = 0; i < rows; ++i) {\n        const double* row = matrix + i * cols;\n        bool match = true;\n\n        for (size_t j = 0; j < cols; j += 2) {\n            __m128d row_vals = _mm_loadu_pd(row + j); // Load two elements from the row\n            __m128d cmp;\n\n            if (j == 0) {\n                cmp = _mm_cmpeq_pd(row_vals, vec_low); // Compare with vector low part\n            } else {\n                cmp = _mm_cmpeq_pd(row_vals, vec_high); // Compare with vector high part\n            }\n\n            // Check if all elements in the comparison are true\n            int mask = _mm_movemask_pd(cmp);\n            if (mask != 0x3) { // 0x3 means both elements matched\n                match = false;\n                break;\n            }\n        }\n\n        if (match) {\n            return true; // Found a matching row\n        }\n    }\n\n    return false; // No matching row found\n}\n```"}
{"task_id": "SimdBench_32_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool matrix_has_row_simd(const double* matrix, const double* vector, size_t rows, size_t cols) {\n    // Load the vector into SIMD registers for reuse\n    __m128d vec_reg[2];\n    vec_reg[0] = _mm_loadu_pd(vector);       // Load first two doubles of the vector\n    vec_reg[1] = _mm_loadu_pd(vector + 2);   // Load next two doubles of the vector\n\n    for (size_t i = 0; i < rows; ++i) {\n        const double* row = matrix + i * cols;\n        bool match = true;\n\n        for (size_t j = 0; j < cols; j += 2) {\n            __m128d row_reg = _mm_loadu_pd(row + j); // Load two doubles from the current row\n            __m128d cmp = _mm_cmpeq_pd(row_reg, vec_reg[j / 2]); // Compare with corresponding vector part\n            int mask = _mm_movemask_pd(cmp); // Extract comparison results into a mask\n\n            if (mask != 0x3) { // If not all elements match (mask != 0b11)\n                match = false;\n                break;\n            }\n        }\n\n        if (match) {\n            return true; // Found a matching row\n        }\n    }\n\n    return false; // No matching row found\n}\n```"}
{"task_id": "SimdBench_32_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool matrix_has_row_simd(const double* matrix, const double* vector, size_t rows, size_t cols) {\n    __m128d vec_reg[2]; // Two 128-bit registers to hold parts of the vector (up to 4 doubles)\n    size_t vec_loads = cols / 2; // Number of 128-bit chunks in the vector\n\n    // Load the vector into SIMD registers\n    for (size_t i = 0; i < vec_loads; ++i) {\n        vec_reg[i] = _mm_loadu_pd(&vector[i * 2]);\n    }\n\n    for (size_t r = 0; r < rows; ++r) {\n        bool match = true;\n        size_t c = 0;\n\n        // Compare each row with the vector using SIMD\n        for (; c < vec_loads; ++c) {\n            __m128d row_reg = _mm_loadu_pd(&matrix[r * cols + c * 2]);\n            __m128d cmp = _mm_cmpeq_pd(row_reg, vec_reg[c]);\n            int mask = _mm_movemask_pd(cmp);\n\n            if (mask != 0x3) { // Check if all elements in the 128-bit chunk match\n                match = false;\n                break;\n            }\n        }\n\n        // Handle any remaining elements that don't fit into 128-bit chunks\n        if (match && cols % 2 != 0) {\n            if (matrix[r * cols + cols - 1] != vector[cols - 1]) {\n                match = false;\n            }\n        }\n\n        if (match) {\n            return true;\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_32_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool matrix_has_row_simd(const double* matrix, const double* vector, size_t rows, size_t cols) {\n    __m128d vec_chunk1 = _mm_loadu_pd(vector); // Load first two elements of the vector\n    __m128d vec_chunk2 = _mm_loadu_pd(vector + 2); // Load next two elements of the vector\n\n    for (size_t i = 0; i < rows; ++i) {\n        const double* row = matrix + i * cols;\n        __m128d row_chunk1 = _mm_loadu_pd(row); // Load first two elements of the row\n        __m128d row_chunk2 = _mm_loadu_pd(row + 2); // Load next two elements of the row\n\n        __m128d cmp1 = _mm_cmpeq_pd(row_chunk1, vec_chunk1); // Compare first two elements\n        __m128d cmp2 = _mm_cmpeq_pd(row_chunk2, vec_chunk2); // Compare next two elements\n\n        int mask1 = _mm_movemask_pd(cmp1); // Extract comparison results for first chunk\n        int mask2 = _mm_movemask_pd(cmp2); // Extract comparison results for second chunk\n\n        if (mask1 == 0x3 && mask2 == 0x3) { // Check if all comparisons are true\n            return true;\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_33_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nsize_t tensor_4d_equal_count_simd(const uint8_t* A, const uint8_t* B, const size_t dims[4]) {\n    size_t total_elements = dims[0] * dims[1] * dims[2] * dims[3];\n    size_t i = 0;\n    size_t equal_count = 0;\n\n    __m128i vec_zero = _mm_setzero_si128();\n\n    // Process 16 elements at a time\n    for (; i + 15 < total_elements; i += 16) {\n        __m128i vec_a = _mm_loadu_si128((__m128i const*)(A + i));\n        __m128i vec_b = _mm_loadu_si128((__m128i const*)(B + i));\n\n        // Compare for equality\n        __m128i cmp_result = _mm_cmpeq_epi8(vec_a, vec_b);\n\n        // Convert comparison result to a bitmask\n        int mask = _mm_movemask_epi8(cmp_result);\n\n        // Count the number of set bits in the mask\n        equal_count += __builtin_popcount(mask);\n    }\n\n    // Process remaining elements\n    for (; i < total_elements; ++i) {\n        if (A[i] == B[i]) {\n            ++equal_count;\n        }\n    }\n\n    return equal_count;\n}\n```"}
{"task_id": "SimdBench_33_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nsize_t tensor_4d_equal_count_simd(const uint8_t* A, const uint8_t* B, const size_t dims[4]) {\n    size_t total_elements = dims[0] * dims[1] * dims[2] * dims[3];\n    size_t i = 0;\n    size_t equal_count = 0;\n\n    __m128i v_zero = _mm_setzero_si128();\n    __m128i v_equal_mask;\n\n    // Process 16 elements at a time\n    for (; i + 15 < total_elements; i += 16) {\n        __m128i v_a = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i v_b = _mm_loadu_si128((__m128i*)&B[i]);\n\n        // Compare for equality\n        v_equal_mask = _mm_cmpeq_epi8(v_a, v_b);\n\n        // Count the number of equal elements in this batch\n        equal_count += _mm_popcnt_u32(_mm_movemask_epi8(v_equal_mask));\n    }\n\n    // Process remaining elements\n    for (; i < total_elements; ++i) {\n        if (A[i] == B[i]) {\n            ++equal_count;\n        }\n    }\n\n    return equal_count;\n}\n```"}
{"task_id": "SimdBench_33_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nsize_t tensor_4d_equal_count_simd(const uint8_t* A, const uint8_t* B, const size_t dims[4]) {\n    size_t total_elements = dims[0] * dims[1] * dims[2] * dims[3];\n    size_t i = 0;\n    size_t equal_count = 0;\n\n    __m128i v_zero = _mm_setzero_si128();\n    __m128i v_equal_mask;\n\n    // Process 16 elements at a time\n    for (; i + 15 < total_elements; i += 16) {\n        __m128i v_a = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i v_b = _mm_loadu_si128((__m128i*)&B[i]);\n\n        // Compare for equality\n        v_equal_mask = _mm_cmpeq_epi8(v_a, v_b);\n\n        // Count the number of equal elements\n        equal_count += _mm_popcnt_u32(_mm_movemask_epi8(v_equal_mask));\n    }\n\n    // Process remaining elements\n    for (; i < total_elements; ++i) {\n        if (A[i] == B[i]) {\n            ++equal_count;\n        }\n    }\n\n    return equal_count;\n}\n```"}
{"task_id": "SimdBench_33_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nsize_t tensor_4d_equal_count_simd(const uint8_t* A, const uint8_t* B, const size_t dims[4]) {\n    size_t total_elements = dims[0] * dims[1] * dims[2] * dims[3];\n    size_t i = 0;\n    size_t equal_count = 0;\n\n    __m128i vec_zero = _mm_setzero_si128();\n\n    // Process 16 elements at a time\n    for (; i + 15 < total_elements; i += 16) {\n        __m128i vec_a = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i vec_b = _mm_loadu_si128((__m128i*)&B[i]);\n\n        // Compare for equality\n        __m128i cmp_result = _mm_cmpeq_epi8(vec_a, vec_b);\n\n        // Create a mask of equal elements\n        int mask = _mm_movemask_epi8(cmp_result);\n\n        // Count the number of set bits in the mask\n        equal_count += __builtin_popcount(mask);\n    }\n\n    // Process remaining elements\n    for (; i < total_elements; ++i) {\n        if (A[i] == B[i]) {\n            ++equal_count;\n        }\n    }\n\n    return equal_count;\n}\n```"}
{"task_id": "SimdBench_33_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nsize_t tensor_4d_equal_count_simd(const uint8_t* A, const uint8_t* B, const size_t dims[4]) {\n    size_t total_elements = dims[0] * dims[1] * dims[2] * dims[3];\n    size_t i = 0;\n    size_t equal_count = 0;\n\n    __m128i v_zero = _mm_setzero_si128();\n    __m128i v_equal_mask;\n\n    // Process 16 elements at a time using SIMD\n    for (; i + 15 < total_elements; i += 16) {\n        __m128i v_a = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i v_b = _mm_loadu_si128((__m128i*)&B[i]);\n\n        // Compare for equality\n        v_equal_mask = _mm_cmpeq_epi8(v_a, v_b);\n\n        // Count the number of equal elements in this block\n        equal_count += _mm_popcnt_u32(_mm_movemask_epi8(v_equal_mask));\n    }\n\n    // Process remaining elements (if any)\n    for (; i < total_elements; ++i) {\n        if (A[i] == B[i]) {\n            ++equal_count;\n        }\n    }\n\n    return equal_count;\n}\n```"}
{"task_id": "SimdBench_34_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid axm_abs_simd(size_t length, const int64_t a, const int64_t *x, int64_t *y) {\n    size_t i = 0;\n    __m128i va = _mm_set1_epi64x(a); // Broadcast scalar 'a' to all elements of the vector\n\n    // Process 2 elements at a time (128-bit register for 2 x 64-bit integers)\n    for (; i + 1 < length; i += 2) {\n        // Load 2 elements from x into a SIMD register\n        __m128i vx = _mm_loadu_si128((__m128i*)&x[i]);\n\n        // Multiply each element of vx by the scalar 'a'\n        __m128i vmul = _mm_mullo_epi64(vx, va);\n\n        // Compute absolute value of y[i] and y[i+1]\n        __m128i vy = _mm_loadu_si128((__m128i*)&y[i]);\n        __m128i vabs = _mm_abs_epi64(vy);\n\n        // Subtract the absolute values from the multiplied values\n        __m128i vsub = _mm_sub_epi64(vmul, vabs);\n\n        // Store the result back to y\n        _mm_storeu_si128((__m128i*)&y[i], vsub);\n    }\n\n    // Handle remaining elements (if length is odd)\n    for (; i < length; ++i) {\n        y[i] = a * x[i] - llabs(y[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_34_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid axm_abs_simd(size_t length, const int64_t a, const int64_t *x, int64_t *y) {\n    __m128i va = _mm_set1_epi64x(a); // Broadcast scalar 'a' to all elements of a SIMD register\n\n    size_t i = 0;\n    for (; i + 2 <= length; i += 2) {\n        // Load two 64-bit integers from x into a SIMD register\n        __m128i vx = _mm_loadu_si128((__m128i*)&x[i]);\n\n        // Multiply each element of vx by the scalar 'a'\n        __m128i vmul = _mm_mullo_epi64(vx, va);\n\n        // Compute absolute value of y[i] and y[i+1]\n        __m128i vy = _mm_loadu_si128((__m128i*)&y[i]);\n        __m128i vabs = _mm_abs_epi64(vy);\n\n        // Subtract the absolute values from the multiplied values\n        __m128i vsub = _mm_sub_epi64(vmul, vabs);\n\n        // Store the result back to y\n        _mm_storeu_si128((__m128i*)&y[i], vsub);\n    }\n\n    // Handle remaining elements (if length is odd)\n    for (; i < length; ++i) {\n        y[i] = a * x[i] - llabs(y[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_34_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid axm_abs_simd(size_t length, const int64_t a, const int64_t *x, int64_t *y) {\n    size_t i = 0;\n    __m128i va = _mm_set1_epi64x(a); // Broadcast scalar 'a' to all elements of the vector\n\n    // Process 2 elements at a time (128-bit register for 2 x 64-bit integers)\n    for (; i + 1 < length; i += 2) {\n        // Load 2 elements from x into a SIMD register\n        __m128i vx = _mm_loadu_si128((__m128i*)&x[i]);\n\n        // Multiply 'a' with each element of vx\n        __m128i vmul = _mm_mullo_epi64(vx, va);\n\n        // Compute absolute value of y[i] and y[i+1]\n        __m128i vy = _mm_loadu_si128((__m128i*)&y[i]);\n        __m128i vabs = _mm_abs_epi64(vy);\n\n        // Subtract absolute values from the multiplied result\n        __m128i vsub = _mm_sub_epi64(vmul, vabs);\n\n        // Store the result back to y\n        _mm_storeu_si128((__m128i*)&y[i], vsub);\n    }\n\n    // Handle remaining elements (if length is odd)\n    for (; i < length; ++i) {\n        y[i] = a * x[i] - llabs(y[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_34_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid axm_abs_simd(size_t length, const int64_t a, const int64_t *x, int64_t *y) {\n    size_t i = 0;\n    __m128i va = _mm_set1_epi64x(a); // Broadcast scalar 'a' to all elements of the SIMD register\n\n    // Process 2 elements at a time (since we are using 128-bit registers with 64-bit integers)\n    for (; i + 1 < length; i += 2) {\n        // Load 2 elements from x into SIMD register\n        __m128i vx = _mm_loadu_si128((__m128i*)&x[i]);\n\n        // Multiply 'a' with vector x (element-wise multiplication)\n        __m128i vmul = _mm_mul_epi32(va, vx);\n\n        // Load 2 elements from y into SIMD register\n        __m128i vy = _mm_loadu_si128((__m128i*)&y[i]);\n\n        // Compute absolute value of y (element-wise absolute value)\n        __m128i vabs = _mm_abs_epi64(vy);\n\n        // Subtract absolute(y) from a*x (element-wise subtraction)\n        __m128i vsub = _mm_sub_epi64(vmul, vabs);\n\n        // Store the result back to y\n        _mm_storeu_si128((__m128i*)&y[i], vsub);\n    }\n\n    // Handle remaining elements (if length is not a multiple of 2)\n    for (; i < length; ++i) {\n        y[i] = a * x[i] - llabs(y[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_34_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid axm_abs_simd(size_t length, const int64_t a, const int64_t *x, int64_t *y) {\n    __m128i va = _mm_set1_epi64x(a); // Broadcast scalar 'a' to all elements of the SIMD register\n\n    size_t i = 0;\n    for (; i + 2 <= length; i += 2) {\n        // Load two 64-bit integers from x into a SIMD register\n        __m128i vx = _mm_loadu_si128((__m128i*)&x[i]);\n\n        // Multiply each element of vx by the scalar 'a'\n        __m128i vmul = _mm_mullo_epi64(vx, va);\n\n        // Compute absolute value of y[i] and y[i+1]\n        __m128i vy = _mm_loadu_si128((__m128i*)&y[i]);\n        __m128i vabs = _mm_abs_epi64(vy);\n\n        // Subtract the absolute values from the multiplied values\n        __m128i vsub = _mm_sub_epi64(vmul, vabs);\n\n        // Store the result back to y\n        _mm_storeu_si128((__m128i*)&y[i], vsub);\n    }\n\n    // Handle remaining elements (if length is not a multiple of 2)\n    for (; i < length; ++i) {\n        y[i] = (a * x[i]) - llabs(y[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_35_SSE", "completion": "```c\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\ntypedef struct {\n    int16_t min_num;\n    int16_t max_num;\n} MinMaxPair;\n\nMinMaxPair min_max_pair_simd(const int16_t* vec, size_t length) {\n    __m128i vmin = _mm_set1_epi16(0x7FFF); // Initialize to maximum 16-bit value\n    __m128i vmax = _mm_set1_epi16(0x8000); // Initialize to minimum 16-bit value\n\n    size_t i = 0;\n\n    // Process 8 elements at a time using SIMD\n    for (; i + 8 <= length; i += 8) {\n        __m128i v = _mm_loadu_si128((__m128i*)&vec[i]); // Load 8 integers\n        vmin = _mm_min_epi16(vmin, v);                  // Update min\n        vmax = _mm_max_epi16(vmax, v);                  // Update max\n    }\n\n    // Extract the results from the SIMD registers\n    int16_t min_vals[8], max_vals[8];\n    _mm_storeu_si128((__m128i*)min_vals, vmin);\n    _mm_storeu_si128((__m128i*)max_vals, vmax);\n\n    int16_t min_num = 0x7FFF, max_num = 0x8000;\n\n    // Find the overall min and max from the extracted values\n    for (size_t j = 0; j < 8; ++j) {\n        if (min_vals[j] < min_num) min_num = min_vals[j];\n        if (max_vals[j] > max_num) max_num = max_vals[j];\n    }\n\n    // Process any remaining elements\n    for (; i < length; ++i) {\n        if (vec[i] < min_num) min_num = vec[i];\n        if (vec[i] > max_num) max_num = vec[i];\n    }\n\n    MinMaxPair result = {min_num, max_num};\n    return result;\n}\n```"}
{"task_id": "SimdBench_35_SSE", "completion": "```c\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\ntypedef struct {\n    int16_t min_num;\n    int16_t max_num;\n} MinMaxPair;\n\nMinMaxPair min_max_pair_simd(const int16_t* vec, size_t length) {\n    MinMaxPair result;\n    __m128i vmin = _mm_set1_epi16(0x7FFF); // Initialize to maximum 16-bit value\n    __m128i vmax = _mm_set1_epi16(0x8000); // Initialize to minimum 16-bit value\n\n    size_t i = 0;\n\n    // Process 8 elements at a time using SIMD\n    for (; i + 8 <= length; i += 8) {\n        __m128i v = _mm_loadu_si128((__m128i*)&vec[i]); // Load 8 integers\n        vmin = _mm_min_epi16(vmin, v);                  // Update min\n        vmax = _mm_max_epi16(vmax, v);                  // Update max\n    }\n\n    // Extract the results from the SIMD registers\n    int16_t min_vals[8], max_vals[8];\n    _mm_storeu_si128((__m128i*)min_vals, vmin);\n    _mm_storeu_si128((__m128i*)max_vals, vmax);\n\n    int16_t min_num = 0x7FFF, max_num = 0x8000;\n\n    // Find the overall min and max from the extracted values\n    for (size_t j = 0; j < 8; ++j) {\n        if (min_vals[j] < min_num) min_num = min_vals[j];\n        if (max_vals[j] > max_num) max_num = max_vals[j];\n    }\n\n    // Process any remaining elements\n    for (; i < length; ++i) {\n        if (vec[i] < min_num) min_num = vec[i];\n        if (vec[i] > max_num) max_num = vec[i];\n    }\n\n    result.min_num = min_num;\n    result.max_num = max_num;\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_35_SSE", "completion": "```c\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\ntypedef struct {\n    int16_t min_num;\n    int16_t max_num;\n} MinMaxPair;\n\nMinMaxPair min_max_pair_simd(const int16_t* vec, size_t length) {\n    __m128i vmin = _mm_set1_epi16(0x7FFF); // Initialize to maximum 16-bit value\n    __m128i vmax = _mm_set1_epi16(0x8000); // Initialize to minimum 16-bit value\n\n    size_t i = 0;\n    for (; i + 8 <= length; i += 8) {\n        __m128i v = _mm_loadu_si128((__m128i*)&vec[i]); // Load 8 integers\n        vmin = _mm_min_epi16(vmin, v);                  // Update min\n        vmax = _mm_max_epi16(vmax, v);                  // Update max\n    }\n\n    // Horizontal reduction for min and max\n    int16_t min_vals[8], max_vals[8];\n    _mm_storeu_si128((__m128i*)min_vals, vmin);\n    _mm_storeu_si128((__m128i*)max_vals, vmax);\n\n    int16_t min_num = min_vals[0];\n    int16_t max_num = max_vals[0];\n    for (int j = 1; j < 8; ++j) {\n        if (min_vals[j] < min_num) min_num = min_vals[j];\n        if (max_vals[j] > max_num) max_num = max_vals[j];\n    }\n\n    // Process remaining elements\n    for (; i < length; ++i) {\n        if (vec[i] < min_num) min_num = vec[i];\n        if (vec[i] > max_num) max_num = vec[i];\n    }\n\n    MinMaxPair result = {min_num, max_num};\n    return result;\n}\n```"}
{"task_id": "SimdBench_35_SSE", "completion": "```c\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\ntypedef struct {\n    int16_t min_num;\n    int16_t max_num;\n} MinMaxPair;\n\nMinMaxPair min_max_pair_simd(const int16_t* vec, size_t length) {\n    __m128i vmin = _mm_set1_epi16(0x7FFF); // Initialize to maximum 16-bit value\n    __m128i vmax = _mm_set1_epi16(0x8000); // Initialize to minimum 16-bit value\n\n    size_t i = 0;\n    for (; i + 8 <= length; i += 8) {\n        __m128i v = _mm_loadu_si128((__m128i*)&vec[i]);\n        vmin = _mm_min_epi16(vmin, v);\n        vmax = _mm_max_epi16(vmax, v);\n    }\n\n    // Horizontal reduction for min and max\n    int16_t min_vals[8], max_vals[8];\n    _mm_storeu_si128((__m128i*)min_vals, vmin);\n    _mm_storeu_si128((__m128i*)max_vals, vmax);\n\n    int16_t min_num = min_vals[0];\n    int16_t max_num = max_vals[0];\n    for (int j = 1; j < 8; ++j) {\n        if (min_vals[j] < min_num) min_num = min_vals[j];\n        if (max_vals[j] > max_num) max_num = max_vals[j];\n    }\n\n    // Process remaining elements\n    for (; i < length; ++i) {\n        if (vec[i] < min_num) min_num = vec[i];\n        if (vec[i] > max_num) max_num = vec[i];\n    }\n\n    MinMaxPair result = {min_num, max_num};\n    return result;\n}\n```"}
{"task_id": "SimdBench_35_SSE", "completion": "```c\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\ntypedef struct {\n    int16_t min_num;\n    int16_t max_num;\n} MinMaxPair;\n\nMinMaxPair min_max_pair_simd(const int16_t* vec, size_t length) {\n    __m128i vmin = _mm_set1_epi16(0x7FFF); // Initialize to maximum possible 16-bit value\n    __m128i vmax = _mm_set1_epi16(0x8000); // Initialize to minimum possible 16-bit value\n\n    size_t i = 0;\n    for (; i + 8 <= length; i += 8) {\n        __m128i v = _mm_loadu_si128((__m128i*)&vec[i]); // Load 8 integers (128 bits)\n        vmin = _mm_min_epi16(vmin, v);                  // Compute min\n        vmax = _mm_max_epi16(vmax, v);                  // Compute max\n    }\n\n    // Extract min and max from SIMD registers\n    int16_t min_vals[8], max_vals[8];\n    _mm_storeu_si128((__m128i*)min_vals, vmin);\n    _mm_storeu_si128((__m128i*)max_vals, vmax);\n\n    int16_t min_num = 0x7FFF, max_num = 0x8000;\n    for (size_t j = 0; j < 8; ++j) {\n        if (min_vals[j] < min_num) min_num = min_vals[j];\n        if (max_vals[j] > max_num) max_num = max_vals[j];\n    }\n\n    // Process remaining elements\n    for (; i < length; ++i) {\n        if (vec[i] < min_num) min_num = vec[i];\n        if (vec[i] > max_num) max_num = vec[i];\n    }\n\n    MinMaxPair result = {min_num, max_num};\n    return result;\n}\n```"}
{"task_id": "SimdBench_36_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool matrix_rows_strictly_increasing_simd(const int* matrix, size_t rows, size_t cols) {\n    if (rows == 0 || cols == 0) return false;\n\n    for (size_t i = 0; i < rows; ++i) {\n        const int* row = matrix + i * cols;\n        size_t j = 0;\n\n        // Process 4 elements at a time using SSE2\n        for (; j + 4 <= cols; j += 4) {\n            __m128i current = _mm_loadu_si128((__m128i*)(row + j));\n            __m128i next = _mm_loadu_si128((__m128i*)(row + j + 1));\n\n            // Compare current < next for all 4 elements\n            __m128i cmp = _mm_cmplt_epi32(current, next);\n\n            // Check if all comparisons are true\n            if (_mm_movemask_epi8(cmp) != 0xFFFF) {\n                return false;\n            }\n        }\n\n        // Process remaining elements\n        for (; j + 1 < cols; ++j) {\n            if (row[j] >= row[j + 1]) {\n                return false;\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_36_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool matrix_rows_strictly_increasing_simd(const int* matrix, size_t rows, size_t cols) {\n    if (rows == 0 || cols == 0) return false;\n\n    for (size_t i = 0; i < rows; ++i) {\n        const int* row = matrix + i * cols;\n        size_t j = 0;\n\n        // Process 4 elements at a time using SSE2\n        for (; j + 4 <= cols; j += 4) {\n            __m128i current = _mm_loadu_si128((__m128i*)(row + j));\n            __m128i next = _mm_loadu_si128((__m128i*)(row + j + 1));\n\n            // Compare current < next for all 4 elements\n            __m128i cmp = _mm_cmplt_epi32(current, next);\n\n            // Check if all comparisons are true\n            if (_mm_movemask_epi8(cmp) != 0xFFFF) {\n                return false;\n            }\n        }\n\n        // Process remaining elements\n        for (; j + 1 < cols; ++j) {\n            if (row[j] >= row[j + 1]) {\n                return false;\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_36_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool matrix_rows_strictly_increasing_simd(const int* matrix, size_t rows, size_t cols) {\n    if (rows == 0 || cols == 0) return false;\n\n    for (size_t i = 0; i < rows; ++i) {\n        const int* row = matrix + i * cols;\n        size_t j = 0;\n\n        // Process 4 elements at a time using SSE2\n        for (; j + 4 <= cols; j += 4) {\n            __m128i current = _mm_loadu_si128((__m128i*)(row + j));\n            __m128i next = _mm_loadu_si128((__m128i*)(row + j + 1));\n\n            // Compare current < next for all 4 elements\n            __m128i cmp = _mm_cmplt_epi32(current, next);\n\n            // Check if all comparisons are true\n            if (_mm_movemask_epi8(cmp) != 0xFFFF) {\n                return false;\n            }\n        }\n\n        // Process remaining elements\n        for (; j + 1 < cols; ++j) {\n            if (row[j] >= row[j + 1]) {\n                return false;\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_36_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool matrix_rows_strictly_increasing_simd(const int* matrix, size_t rows, size_t cols) {\n    if (rows == 0 || cols == 0) return false;\n\n    for (size_t i = 0; i < rows; ++i) {\n        const int* row = matrix + i * cols;\n        size_t j = 0;\n\n        // Process 4 elements at a time using SSE2\n        for (; j + 4 <= cols; j += 4) {\n            __m128i current = _mm_loadu_si128((__m128i*)(row + j));\n            __m128i next = _mm_loadu_si128((__m128i*)(row + j + 1));\n\n            // Compare current < next for all 4 elements\n            __m128i cmp = _mm_cmplt_epi32(current, next);\n\n            // Check if all comparisons are true (all bits set)\n            if (_mm_movemask_epi8(cmp) != 0xFFFF) {\n                return false;\n            }\n        }\n\n        // Process remaining elements\n        for (; j + 1 < cols; ++j) {\n            if (row[j] >= row[j + 1]) {\n                return false;\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_36_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool matrix_rows_strictly_increasing_simd(const int* matrix, size_t rows, size_t cols) {\n    if (rows == 0 || cols == 0) return false;\n\n    for (size_t i = 0; i < rows; ++i) {\n        const int* row = matrix + i * cols;\n        size_t j = 0;\n\n        // Process 4 elements at a time using SSE2\n        for (; j + 4 <= cols; j += 4) {\n            __m128i current = _mm_loadu_si128((__m128i*)(row + j));\n            __m128i next = _mm_loadu_si128((__m128i*)(row + j + 1));\n\n            // Compare current < next for all 4 elements\n            __m128i cmp = _mm_cmplt_epi32(current, next);\n\n            // Check if all comparisons are true\n            if (_mm_movemask_epi8(cmp) != 0xFFFF) {\n                return false;\n            }\n        }\n\n        // Process remaining elements\n        for (; j + 1 < cols; ++j) {\n            if (row[j] >= row[j + 1]) {\n                return false;\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_37_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool matrix_blocks_equal_simd(const int* matrix, size_t block_size, size_t rows, size_t cols) {\n    if (block_size == 0 || rows % block_size != 0 || cols % block_size != 0) {\n        return false;\n    }\n\n    size_t num_blocks_row = rows / block_size;\n    size_t num_blocks_col = cols / block_size;\n\n    // Load the first block into SIMD registers for comparison\n    __m128i reference_block[4]; // Assuming block_size <= 4 for simplicity\n    for (size_t i = 0; i < block_size; ++i) {\n        reference_block[i] = _mm_loadu_si128((__m128i*)(matrix + i * cols));\n    }\n\n    // Compare all other blocks with the reference block\n    for (size_t br = 0; br < num_blocks_row; ++br) {\n        for (size_t bc = 0; bc < num_blocks_col; ++bc) {\n            if (br == 0 && bc == 0) continue; // Skip the reference block itself\n\n            size_t block_start_row = br * block_size;\n            size_t block_start_col = bc * block_size;\n\n            for (size_t i = 0; i < block_size; ++i) {\n                __m128i current_block = _mm_loadu_si128((__m128i*)(matrix + (block_start_row + i) * cols + block_start_col));\n                if (!_mm_test_all_ones(_mm_cmpeq_epi32(current_block, reference_block[i]))) {\n                    return false;\n                }\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_37_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool matrix_blocks_equal_simd(const int* matrix, size_t block_size, size_t rows, size_t cols) {\n    if (block_size == 0 || rows % block_size != 0 || cols % block_size != 0) {\n        return false;\n    }\n\n    size_t num_blocks_row = rows / block_size;\n    size_t num_blocks_col = cols / block_size;\n\n    // Load the first block into SIMD registers for comparison\n    __m128i reference_block[4]; // Assuming block_size <= 4 for simplicity\n    for (size_t i = 0; i < block_size; ++i) {\n        reference_block[i] = _mm_loadu_si128((__m128i*)(matrix + i * cols));\n    }\n\n    // Compare all other blocks with the reference block\n    for (size_t br = 0; br < num_blocks_row; ++br) {\n        for (size_t bc = 0; bc < num_blocks_col; ++bc) {\n            if (br == 0 && bc == 0) continue; // Skip the reference block itself\n\n            size_t block_start_row = br * block_size;\n            size_t block_start_col = bc * block_size;\n\n            for (size_t i = 0; i < block_size; ++i) {\n                const int* current_row = matrix + (block_start_row + i) * cols + block_start_col;\n                __m128i current_block = _mm_loadu_si128((__m128i*)(current_row));\n\n                // Compare each row of the current block with the reference block\n                if (!_mm_test_all_ones(_mm_cmpeq_epi32(current_block, reference_block[i]))) {\n                    return false;\n                }\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_37_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool matrix_blocks_equal_simd(const int* matrix, size_t block_size, size_t rows, size_t cols) {\n    if (block_size == 0 || rows % block_size != 0 || cols % block_size != 0) {\n        return false;\n    }\n\n    size_t num_blocks_row = rows / block_size;\n    size_t num_blocks_col = cols / block_size;\n\n    // Load the first block into SIMD registers for comparison\n    __m128i reference_block[4]; // Assuming block_size <= 4 for simplicity\n    for (size_t i = 0; i < block_size; ++i) {\n        reference_block[i] = _mm_loadu_si128((__m128i*)(matrix + i * cols));\n    }\n\n    // Compare all other blocks with the reference block\n    for (size_t br = 0; br < num_blocks_row; ++br) {\n        for (size_t bc = 0; bc < num_blocks_col; ++bc) {\n            if (br == 0 && bc == 0) continue; // Skip the reference block itself\n\n            size_t block_start_row = br * block_size;\n            size_t block_start_col = bc * block_size;\n\n            for (size_t i = 0; i < block_size; ++i) {\n                __m128i current_block = _mm_loadu_si128((__m128i*)(matrix + (block_start_row + i) * cols + block_start_col));\n                if (!_mm_test_all_ones(_mm_cmpeq_epi32(current_block, reference_block[i]))) {\n                    return false;\n                }\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_37_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool matrix_blocks_equal_simd(const int* matrix, size_t block_size, size_t rows, size_t cols) {\n    if (block_size == 0 || rows % block_size != 0 || cols % block_size != 0) {\n        return false;\n    }\n\n    size_t num_blocks_row = rows / block_size;\n    size_t num_blocks_col = cols / block_size;\n\n    // Load the first block into a reference buffer\n    __m128i reference[4]; // Assuming block_size <= 4 for simplicity\n    for (size_t i = 0; i < block_size; ++i) {\n        reference[i] = _mm_loadu_si128((__m128i*)(matrix + i * cols));\n    }\n\n    // Compare all other blocks with the reference block\n    for (size_t br = 0; br < num_blocks_row; ++br) {\n        for (size_t bc = 0; bc < num_blocks_col; ++bc) {\n            if (br == 0 && bc == 0) continue; // Skip the first block\n\n            size_t block_start_row = br * block_size;\n            size_t block_start_col = bc * block_size;\n\n            for (size_t i = 0; i < block_size; ++i) {\n                __m128i current = _mm_loadu_si128((__m128i*)(matrix + (block_start_row + i) * cols + block_start_col));\n                if (!_mm_test_all_ones(_mm_cmpeq_epi32(current, reference[i]))) {\n                    return false;\n                }\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_37_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool matrix_blocks_equal_simd(const int* matrix, size_t block_size, size_t rows, size_t cols) {\n    if (block_size == 0 || rows % block_size != 0 || cols % block_size != 0) {\n        return false;\n    }\n\n    size_t num_blocks_row = rows / block_size;\n    size_t num_blocks_col = cols / block_size;\n\n    // Load the first block into SIMD registers for comparison\n    __m128i reference_block[4]; // Assuming block_size <= 4 for simplicity\n    for (size_t i = 0; i < block_size; ++i) {\n        reference_block[i] = _mm_loadu_si128((__m128i*)(matrix + i * cols));\n    }\n\n    // Compare all other blocks with the reference block\n    for (size_t br = 0; br < num_blocks_row; ++br) {\n        for (size_t bc = 0; bc < num_blocks_col; ++bc) {\n            if (br == 0 && bc == 0) continue; // Skip the reference block itself\n\n            size_t block_start_row = br * block_size;\n            size_t block_start_col = bc * block_size;\n\n            for (size_t i = 0; i < block_size; ++i) {\n                __m128i current_block = _mm_loadu_si128((__m128i*)(matrix + (block_start_row + i) * cols + block_start_col));\n                if (!_mm_test_all_ones(_mm_cmpeq_epi32(current_block, reference_block[i]))) {\n                    return false;\n                }\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_38_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool vector_block_equal_simd(const double* vec, double tolerance, size_t length, size_t block_size) {\n    if (vec == nullptr || block_size == 0 || length < block_size || block_size % 2 != 0) {\n        return false;\n    }\n\n    size_t num_blocks = length / block_size;\n    if (num_blocks < 2) {\n        return false;\n    }\n\n    __m128d tolerance_vec = _mm_set1_pd(tolerance);\n    __m128d neg_tolerance_vec = _mm_set1_pd(-tolerance);\n\n    for (size_t i = 1; i < num_blocks; ++i) {\n        for (size_t j = 0; j < block_size; j += 2) {\n            __m128d first_block = _mm_loadu_pd(&vec[j]);\n            __m128d current_block = _mm_loadu_pd(&vec[i * block_size + j]);\n\n            __m128d diff = _mm_sub_pd(current_block, first_block);\n            __m128d mask1 = _mm_cmpgt_pd(diff, tolerance_vec);\n            __m128d mask2 = _mm_cmplt_pd(diff, neg_tolerance_vec);\n\n            if (!_mm_testz_pd(mask1, mask1) || !_mm_testz_pd(mask2, mask2)) {\n                return false;\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_38_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool vector_block_equal_simd(const double* vec, double tolerance, size_t length, size_t block_size) {\n    if (vec == nullptr || block_size == 0 || length < block_size || block_size % 2 != 0) {\n        return false;\n    }\n\n    size_t num_blocks = length / block_size;\n    if (num_blocks < 2) {\n        return false;\n    }\n\n    __m128d tolerance_vec = _mm_set1_pd(tolerance);\n    __m128d neg_tolerance_vec = _mm_set1_pd(-tolerance);\n\n    for (size_t i = 1; i < num_blocks; ++i) {\n        for (size_t j = 0; j < block_size; j += 2) {\n            __m128d first_block = _mm_loadu_pd(&vec[j]);\n            __m128d current_block = _mm_loadu_pd(&vec[i * block_size + j]);\n\n            __m128d diff = _mm_sub_pd(current_block, first_block);\n            __m128d cmp1 = _mm_cmpge_pd(diff, neg_tolerance_vec);\n            __m128d cmp2 = _mm_cmple_pd(diff, tolerance_vec);\n\n            __m128d result = _mm_and_pd(cmp1, cmp2);\n            int mask = _mm_movemask_pd(result);\n\n            if (mask != 0x3) {\n                return false;\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_38_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool vector_block_equal_simd(const double* vec, double tolerance, size_t length, size_t block_size) {\n    if (vec == nullptr || block_size == 0 || block_size > length || length % block_size != 0) {\n        return false;\n    }\n\n    size_t num_blocks = length / block_size;\n    __m128d tolerance_vec = _mm_set1_pd(tolerance);\n\n    for (size_t i = 1; i < num_blocks; ++i) {\n        for (size_t j = 0; j < block_size; j += 2) {\n            __m128d block1 = _mm_loadu_pd(&vec[j]);\n            __m128d block2 = _mm_loadu_pd(&vec[i * block_size + j]);\n\n            __m128d diff = _mm_sub_pd(block1, block2);\n            __m128d abs_diff = _mm_and_pd(_mm_set1_pd(-0.0), diff); // Absolute value using bitwise AND with -0.0\n            __m128d cmp = _mm_cmpgt_pd(abs_diff, tolerance_vec);\n\n            if (_mm_movemask_pd(cmp) != 0) {\n                return false;\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_38_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool vector_block_equal_simd(const double* vec, double tolerance, size_t length, size_t block_size) {\n    if (vec == nullptr || block_size == 0 || block_size > length || length % block_size != 0) {\n        return false;\n    }\n\n    __m128d tolerance_vec = _mm_set1_pd(tolerance);\n    size_t num_blocks = length / block_size;\n\n    for (size_t i = 1; i < num_blocks; ++i) {\n        for (size_t j = 0; j < block_size; j += 2) {\n            __m128d block1 = _mm_loadu_pd(&vec[j]);\n            __m128d block2 = _mm_loadu_pd(&vec[i * block_size + j]);\n\n            __m128d diff = _mm_sub_pd(block1, block2);\n            __m128d abs_diff = _mm_and_pd(diff, _mm_castsi128_pd(_mm_set1_epi64x(0x7FFFFFFFFFFFFFFF)));\n\n            __m128d cmp = _mm_cmpgt_pd(abs_diff, tolerance_vec);\n            if (_mm_movemask_pd(cmp) != 0) {\n                return false;\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_38_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool vector_block_equal_simd(const double* vec, double tolerance, size_t length, size_t block_size) {\n    if (vec == nullptr || block_size == 0 || length < block_size || block_size % 2 != 0) {\n        return false;\n    }\n\n    __m128d tolerance_vec = _mm_set1_pd(tolerance);\n    size_t num_blocks = length / block_size;\n\n    if (num_blocks < 2) {\n        return false;\n    }\n\n    // Load the first block into SIMD registers\n    __m128d ref_low = _mm_loadu_pd(vec);\n    __m128d ref_high = _mm_loadu_pd(vec + 2);\n\n    for (size_t i = 1; i < num_blocks; ++i) {\n        const double* current_block = vec + i * block_size;\n\n        for (size_t j = 0; j < block_size; j += 2) {\n            __m128d current = _mm_loadu_pd(current_block + j);\n            __m128d diff = _mm_sub_pd(current, (j < 2 ? ref_low : ref_high));\n            __m128d abs_diff = _mm_and_pd(diff, _mm_castsi128_pd(_mm_set1_epi64x(0x7FFFFFFFFFFFFFFF)));\n\n            __m128d cmp = _mm_cmpgt_pd(abs_diff, tolerance_vec);\n            if (_mm_movemask_pd(cmp) != 0) {\n                return false;\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_39_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid matrix_row_norm_compare_simd(const double* matrix, const double* thresholds, size_t rows, size_t cols, bool* result) {\n    size_t simd_width = 2; // SSE/SSE2 processes 2 doubles at a time (128-bit registers)\n    __m128d zero = _mm_setzero_pd();\n\n    for (size_t i = 0; i < rows; ++i) {\n        __m128d sum_sq = _mm_setzero_pd();\n        size_t j = 0;\n\n        // Process columns in chunks of 2 using SIMD\n        for (; j + simd_width <= cols; j += simd_width) {\n            __m128d row_vals = _mm_loadu_pd(&matrix[i * cols + j]);\n            sum_sq = _mm_add_pd(sum_sq, _mm_mul_pd(row_vals, row_vals));\n        }\n\n        // Horizontal add to combine the two partial sums into a scalar\n        double norm_sq = 0.0;\n        double temp[2];\n        _mm_storeu_pd(temp, sum_sq);\n        norm_sq = temp[0] + temp[1];\n\n        // Process remaining elements (if any) that didn't fit into SIMD width\n        for (; j < cols; ++j) {\n            double val = matrix[i * cols + j];\n            norm_sq += val * val;\n        }\n\n        // Compare the Euclidean norm with the threshold\n        double norm = sqrt(norm_sq);\n        result[i] = (norm > thresholds[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_39_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid matrix_row_norm_compare_simd(const double* matrix, const double* thresholds, size_t rows, size_t cols, bool* result) {\n    for (size_t i = 0; i < rows; ++i) {\n        __m128d sum_vec = _mm_setzero_pd();\n        size_t j = 0;\n\n        // Process columns in chunks of 2 using SSE2\n        for (; j + 1 < cols; j += 2) {\n            __m128d row_vals = _mm_loadu_pd(&matrix[i * cols + j]);\n            __m128d squared = _mm_mul_pd(row_vals, row_vals);\n            sum_vec = _mm_add_pd(sum_vec, squared);\n        }\n\n        // Horizontal add to accumulate the partial sums into a scalar\n        double sum = 0.0;\n        double temp[2];\n        _mm_storeu_pd(temp, sum_vec);\n        sum = temp[0] + temp[1];\n\n        // Process remaining elements (if any)\n        for (; j < cols; ++j) {\n            double val = matrix[i * cols + j];\n            sum += val * val;\n        }\n\n        // Compare the Euclidean norm with the threshold\n        double norm = sqrt(sum);\n        result[i] = (norm > thresholds[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_39_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid matrix_row_norm_compare_simd(const double* matrix, const double* thresholds, size_t rows, size_t cols, bool* result) {\n    for (size_t i = 0; i < rows; ++i) {\n        __m128d sum = _mm_setzero_pd();\n        size_t j = 0;\n\n        // Process 2 elements at a time using SSE2\n        for (; j + 1 < cols; j += 2) {\n            __m128d vec = _mm_loadu_pd(&matrix[i * cols + j]); // Load two doubles\n            sum = _mm_add_pd(sum, _mm_mul_pd(vec, vec));       // Accumulate squares\n        }\n\n        // Horizontal add to combine the two partial sums into a scalar\n        double temp[2];\n        _mm_storeu_pd(temp, sum);\n        double norm_sq = temp[0] + temp[1];\n\n        // Process remaining elements (if any)\n        for (; j < cols; ++j) {\n            double val = matrix[i * cols + j];\n            norm_sq += val * val;\n        }\n\n        // Compare the Euclidean norm with the threshold\n        double norm = sqrt(norm_sq);\n        result[i] = (norm > thresholds[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_39_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid matrix_row_norm_compare_simd(const double* matrix, const double* thresholds, size_t rows, size_t cols, bool* result) {\n    for (size_t i = 0; i < rows; ++i) {\n        __m128d sum = _mm_setzero_pd();\n        size_t j = 0;\n\n        // Process columns in chunks of 2 using SSE2\n        for (; j + 1 < cols; j += 2) {\n            __m128d vec = _mm_loadu_pd(&matrix[i * cols + j]);\n            sum = _mm_add_pd(sum, _mm_mul_pd(vec, vec));\n        }\n\n        // Horizontal add to accumulate the partial sums into a scalar\n        double temp[2];\n        _mm_storeu_pd(temp, sum);\n        double norm_sq = temp[0] + temp[1];\n\n        // Process remaining elements (if cols is odd)\n        for (; j < cols; ++j) {\n            double val = matrix[i * cols + j];\n            norm_sq += val * val;\n        }\n\n        // Compare the Euclidean norm with the threshold\n        double norm = _mm_sqrt_sd(_mm_set_sd(norm_sq), _mm_set_sd(norm_sq))[0];\n        result[i] = (norm > thresholds[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_39_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid matrix_row_norm_compare_simd(const double* matrix, const double* thresholds, size_t rows, size_t cols, bool* result) {\n    for (size_t i = 0; i < rows; ++i) {\n        __m128d sum = _mm_setzero_pd();\n        size_t j = 0;\n\n        // Process 2 elements at a time using SSE2\n        for (; j + 1 < cols; j += 2) {\n            __m128d vec = _mm_loadu_pd(&matrix[i * cols + j]); // Load two doubles\n            sum = _mm_add_pd(sum, _mm_mul_pd(vec, vec));       // Accumulate squares\n        }\n\n        // Horizontal add to combine the two partial sums into a scalar\n        double norm_sq = 0.0;\n        if (j <= cols - 2) {\n            __m128d temp = _mm_hadd_pd(sum, sum);\n            _mm_store_sd(&norm_sq, temp);\n        }\n\n        // Handle remaining elements (if any)\n        for (; j < cols; ++j) {\n            double val = matrix[i * cols + j];\n            norm_sq += val * val;\n        }\n\n        // Compare the computed norm with the threshold\n        double threshold = thresholds[i];\n        result[i] = (norm_sq > threshold * threshold);\n    }\n}\n```"}
{"task_id": "SimdBench_40_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n\nvoid tensor_bitwise_or_simd(const uint32_t* A, const uint32_t* B, uint32_t* C, size_t length) {\n    size_t i = 0;\n    \n    // Process 4 elements at a time using SSE2 intrinsics\n    for (; i + 4 <= length; i += 4) {\n        // Load 4 elements from A and B into SIMD registers\n        __m128i vecA = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i vecB = _mm_loadu_si128((__m128i*)&B[i]);\n        \n        // Perform bitwise OR operation\n        __m128i vecC = _mm_or_si128(vecA, vecB);\n        \n        // Store the result in C\n        _mm_storeu_si128((__m128i*)&C[i], vecC);\n    }\n    \n    // Process remaining elements (if any)\n    for (; i < length; ++i) {\n        C[i] = A[i] | B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_40_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid tensor_bitwise_or_simd(const uint32_t* A, const uint32_t* B, uint32_t* C, size_t length) {\n    size_t i = 0;\n    size_t simd_length = length - (length % 4);\n\n    // Process 4 elements at a time using SSE2 intrinsics\n    for (; i < simd_length; i += 4) {\n        __m128i vecA = _mm_loadu_si128((__m128i*)&A[i]); // Load 4 elements from A\n        __m128i vecB = _mm_loadu_si128((__m128i*)&B[i]); // Load 4 elements from B\n        __m128i vecC = _mm_or_si128(vecA, vecB);         // Perform bitwise OR\n        _mm_storeu_si128((__m128i*)&C[i], vecC);         // Store result in C\n    }\n\n    // Process remaining elements (if any) using scalar operations\n    for (; i < length; ++i) {\n        C[i] = A[i] | B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_40_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid tensor_bitwise_or_simd(const uint32_t* A, const uint32_t* B, uint32_t* C, size_t length) {\n    size_t i = 0;\n    size_t simd_length = length - (length % 4);\n\n    // Process 4 elements at a time using SSE2 intrinsics\n    for (; i < simd_length; i += 4) {\n        __m128i vecA = _mm_loadu_si128((__m128i*)&A[i]); // Load 4 uint32_t from A\n        __m128i vecB = _mm_loadu_si128((__m128i*)&B[i]); // Load 4 uint32_t from B\n        __m128i vecC = _mm_or_si128(vecA, vecB);         // Perform bitwise OR\n        _mm_storeu_si128((__m128i*)&C[i], vecC);         // Store result in C\n    }\n\n    // Process remaining elements (if any)\n    for (; i < length; ++i) {\n        C[i] = A[i] | B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_40_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid tensor_bitwise_or_simd(const uint32_t* A, const uint32_t* B, uint32_t* C, size_t length) {\n    size_t i = 0;\n    size_t simd_length = length - (length % 4);\n\n    // Process 4 elements at a time using SSE2 intrinsics\n    for (; i < simd_length; i += 4) {\n        __m128i vecA = _mm_loadu_si128((__m128i*)&A[i]); // Load 4 uint32_t from A\n        __m128i vecB = _mm_loadu_si128((__m128i*)&B[i]); // Load 4 uint32_t from B\n        __m128i vecC = _mm_or_si128(vecA, vecB);         // Perform bitwise OR\n        _mm_storeu_si128((__m128i*)&C[i], vecC);         // Store result in C\n    }\n\n    // Process remaining elements (if any) using scalar operations\n    for (; i < length; ++i) {\n        C[i] = A[i] | B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_40_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n\nvoid tensor_bitwise_or_simd(const uint32_t* A, const uint32_t* B, uint32_t* C, size_t length) {\n    size_t i = 0;\n\n    // Process 4 elements at a time using SSE2 intrinsics\n    for (; i + 4 <= length; i += 4) {\n        // Load 4 elements from A and B into SIMD registers\n        __m128i vecA = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i vecB = _mm_loadu_si128((__m128i*)&B[i]);\n\n        // Perform bitwise OR operation\n        __m128i vecC = _mm_or_si128(vecA, vecB);\n\n        // Store the result back to C\n        _mm_storeu_si128((__m128i*)&C[i], vecC);\n    }\n\n    // Handle remaining elements (if any)\n    for (; i < length; ++i) {\n        C[i] = A[i] | B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_41_SSE", "completion": "```cpp\nint64_t squarediff_simd(const int8_t * A, const int8_t * B, size_t length) {\n    __m128i sum_squares = _mm_setzero_si128();\n    __m128i sum_products = _mm_setzero_si128();\n\n    size_t i = 0;\n    for (; i + 16 <= length; i += 16) {\n        __m128i vecA = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i vecB = _mm_loadu_si128((__m128i*)&B[i]);\n\n        // Compute squares of A and B\n        __m128i squareA = _mm_maddubs_epi16(vecA, vecA);\n        __m128i squareB = _mm_maddubs_epi16(vecB, vecB);\n\n        // Add the squares together\n        sum_squares = _mm_add_epi32(sum_squares, _mm_add_epi32(squareA, squareB));\n\n        // Compute product of A and B\n        __m128i product = _mm_maddubs_epi16(vecA, vecB);\n\n        // Accumulate the products\n        sum_products = _mm_add_epi32(sum_products, product);\n    }\n\n    // Horizontal sum of the accumulated results\n    int32_t temp[4];\n    _mm_storeu_si128((__m128i*)temp, sum_squares);\n    int64_t total_squares = temp[0] + temp[1] + temp[2] + temp[3];\n\n    _mm_storeu_si128((__m128i*)temp, sum_products);\n    int64_t total_products = temp[0] + temp[1] + temp[2] + temp[3];\n\n    // Handle remaining elements\n    for (; i < length; ++i) {\n        total_squares += (int64_t)A[i] * A[i] + (int64_t)B[i] * B[i];\n        total_products += (int64_t)A[i] * B[i];\n    }\n\n    return total_squares - total_products;\n}\n```"}
{"task_id": "SimdBench_41_SSE", "completion": "```cpp\nint64_t squarediff_simd(const int8_t * A, const int8_t * B, size_t length) {\n    __m128i sum_squares = _mm_setzero_si128();\n    __m128i sum_products = _mm_setzero_si128();\n\n    size_t i = 0;\n    for (; i + 16 <= length; i += 16) {\n        __m128i vecA = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i vecB = _mm_loadu_si128((__m128i*)&B[i]);\n\n        // Compute squares of A and B\n        __m128i squareA = _mm_maddubs_epi16(vecA, vecA);\n        __m128i squareB = _mm_maddubs_epi16(vecB, vecB);\n\n        // Sum the squares\n        sum_squares = _mm_add_epi32(sum_squares, _mm_cvtepi16_epi32(squareA));\n        sum_squares = _mm_add_epi32(sum_squares, _mm_cvtepi16_epi32(_mm_srli_si128(squareA, 8)));\n        sum_squares = _mm_add_epi32(sum_squares, _mm_cvtepi16_epi32(squareB));\n        sum_squares = _mm_add_epi32(sum_squares, _mm_cvtepi16_epi32(_mm_srli_si128(squareB, 8)));\n\n        // Compute products of A and B\n        __m128i product = _mm_maddubs_epi16(vecA, vecB);\n\n        // Sum the products\n        sum_products = _mm_add_epi32(sum_products, _mm_cvtepi16_epi32(product));\n        sum_products = _mm_add_epi32(sum_products, _mm_cvtepi16_epi32(_mm_srli_si128(product, 8)));\n    }\n\n    // Horizontal sum of sum_squares\n    int64_t total_squares = _mm_extract_epi32(sum_squares, 0) +\n                            _mm_extract_epi32(sum_squares, 1) +\n                            _mm_extract_epi32(sum_squares, 2) +\n                            _mm_extract_epi32(sum_squares, 3);\n\n    // Horizontal sum of sum_products\n    int64_t total_products = _mm_extract_epi32(sum_products, 0) +\n                             _mm_extract_epi32(sum_products, 1) +\n                             _mm_extract_epi32(sum_products, 2) +\n                             _mm_extract_epi32(sum_products, 3);\n\n    // Handle remaining elements\n    for (; i < length; ++i) {\n        total_squares += (int64_t)A[i] * A[i] + (int64_t)B[i] * B[i];\n        total_products += (int64_t)A[i] * B[i];\n    }\n\n    return total_squares - total_products;\n}\n```"}
{"task_id": "SimdBench_41_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint64_t squarediff_simd(const int8_t * A, const int8_t * B, size_t length) {\n    __m128i sum_squares = _mm_setzero_si128();\n    __m128i sum_products = _mm_setzero_si128();\n\n    size_t i = 0;\n    for (; i + 16 <= length; i += 16) {\n        __m128i vecA = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i vecB = _mm_loadu_si128((__m128i*)&B[i]);\n\n        // Compute squares of A and B\n        __m128i squareA = _mm_maddubs_epi16(vecA, vecA);\n        __m128i squareB = _mm_maddubs_epi16(vecB, vecB);\n\n        // Add the squares together\n        sum_squares = _mm_add_epi32(sum_squares, _mm_add_epi32(squareA, squareB));\n\n        // Compute products of A and B\n        __m128i product = _mm_maddubs_epi16(vecA, vecB);\n\n        // Accumulate the products\n        sum_products = _mm_add_epi32(sum_products, product);\n    }\n\n    // Horizontal sum for sum_squares\n    int32_t temp[4];\n    _mm_storeu_si128((__m128i*)temp, sum_squares);\n    int64_t total_squares = temp[0] + temp[1] + temp[2] + temp[3];\n\n    // Horizontal sum for sum_products\n    _mm_storeu_si128((__m128i*)temp, sum_products);\n    int64_t total_products = temp[0] + temp[1] + temp[2] + temp[3];\n\n    // Handle remaining elements\n    for (; i < length; ++i) {\n        total_squares += (int64_t)(A[i] * A[i]) + (int64_t)(B[i] * B[i]);\n        total_products += (int64_t)(A[i] * B[i]);\n    }\n\n    return total_squares - total_products;\n}\n```"}
{"task_id": "SimdBench_41_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint64_t squarediff_simd(const int8_t * A, const int8_t * B, size_t length) {\n    __m128i sum_squares = _mm_setzero_si128();\n    __m128i sum_products = _mm_setzero_si128();\n\n    size_t i = 0;\n    for (; i + 16 <= length; i += 16) {\n        __m128i vecA = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i vecB = _mm_loadu_si128((__m128i*)&B[i]);\n\n        // Compute squares of A and B\n        __m128i squareA = _mm_maddubs_epi16(vecA, vecA);\n        __m128i squareB = _mm_maddubs_epi16(vecB, vecB);\n\n        // Add the squares together\n        sum_squares = _mm_add_epi32(sum_squares, _mm_add_epi32(squareA, squareB));\n\n        // Compute products of A and B\n        __m128i product = _mm_maddubs_epi16(vecA, vecB);\n\n        // Accumulate the products\n        sum_products = _mm_add_epi32(sum_products, product);\n    }\n\n    // Horizontal sum for sum_squares\n    int64_t result_squares = 0;\n    {\n        __m128i temp = _mm_hadd_epi32(sum_squares, sum_squares);\n        temp = _mm_hadd_epi32(temp, temp);\n        result_squares += _mm_cvtsi128_si32(temp);\n    }\n\n    // Horizontal sum for sum_products\n    int64_t result_products = 0;\n    {\n        __m128i temp = _mm_hadd_epi32(sum_products, sum_products);\n        temp = _mm_hadd_epi32(temp, temp);\n        result_products += _mm_cvtsi128_si32(temp);\n    }\n\n    // Handle remaining elements\n    for (; i < length; ++i) {\n        int32_t a = A[i];\n        int32_t b = B[i];\n        result_squares += (a * a) + (b * b);\n        result_products += (a * b);\n    }\n\n    return result_squares - result_products;\n}\n```"}
{"task_id": "SimdBench_41_SSE", "completion": "```cpp\nint64_t squarediff_simd(const int8_t * A, const int8_t * B, size_t length) {\n    __m128i sum_squares = _mm_setzero_si128();\n    __m128i sum_products = _mm_setzero_si128();\n\n    size_t i = 0;\n    for (; i + 16 <= length; i += 16) {\n        // Load 16 elements from A and B\n        __m128i vecA = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i vecB = _mm_loadu_si128((__m128i*)&B[i]);\n\n        // Compute squares of A and B\n        __m128i squareA = _mm_maddubs_epi16(vecA, vecA);\n        __m128i squareB = _mm_maddubs_epi16(vecB, vecB);\n\n        // Add the squares\n        sum_squares = _mm_add_epi32(sum_squares, _mm_add_epi32(squareA, squareB));\n\n        // Compute products of A and B\n        __m128i product = _mm_maddubs_epi16(vecA, vecB);\n\n        // Add the products\n        sum_products = _mm_add_epi32(sum_products, product);\n    }\n\n    // Horizontal sum of the results\n    int32_t temp[4];\n    _mm_storeu_si128((__m128i*)temp, sum_squares);\n    int64_t total_squares = temp[0] + temp[1] + temp[2] + temp[3];\n\n    _mm_storeu_si128((__m128i*)temp, sum_products);\n    int64_t total_products = temp[0] + temp[1] + temp[2] + temp[3];\n\n    // Handle remaining elements\n    for (; i < length; ++i) {\n        total_squares += (int64_t)A[i] * A[i] + (int64_t)B[i] * B[i];\n        total_products += (int64_t)A[i] * B[i];\n    }\n\n    return total_squares - total_products;\n}\n```"}
{"task_id": "SimdBench_42_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid tensor_bit_clear_simd(const uint64_t* A, const uint64_t* B, uint64_t* C, size_t length) {\n    size_t i = 0;\n    __m128i mask = _mm_set1_epi64x(~0ULL); // Create a mask of all ones for bitwise negation\n\n    // Process 2 elements (128 bits) at a time\n    for (; i + 2 <= length; i += 2) {\n        __m128i a = _mm_loadu_si128((__m128i*)&A[i]); // Load 2 elements from A\n        __m128i b = _mm_loadu_si128((__m128i*)&B[i]); // Load 2 elements from B\n\n        __m128i neg_b = _mm_andnot_si128(b, mask); // Compute bitwise negation of B\n        __m128i result = _mm_and_si128(a, neg_b);  // Perform bitwise AND between A and ~B\n\n        _mm_storeu_si128((__m128i*)&C[i], result); // Store the result in C\n    }\n\n    // Handle remaining elements (if length is odd)\n    for (; i < length; ++i) {\n        C[i] = A[i] & ~B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_42_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid tensor_bit_clear_simd(const uint64_t* A, const uint64_t* B, uint64_t* C, size_t length) {\n    size_t i = 0;\n\n    // Process 2 elements (128 bits) at a time using SSE2 intrinsics\n    for (; i + 1 < length; i += 2) {\n        // Load 128-bit chunks from A and B\n        __m128i vecA = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i vecB = _mm_loadu_si128((__m128i*)&B[i]);\n\n        // Compute bitwise negation of vecB\n        __m128i negVecB = _mm_andnot_si128(vecB, _mm_set1_epi64x(-1));\n\n        // Perform bitwise AND between vecA and negVecB\n        __m128i result = _mm_and_si128(vecA, negVecB);\n\n        // Store the result into C\n        _mm_storeu_si128((__m128i*)&C[i], result);\n    }\n\n    // Handle remaining elements (if length is odd)\n    for (; i < length; ++i) {\n        C[i] = A[i] & ~B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_42_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid tensor_bit_clear_simd(const uint64_t* A, const uint64_t* B, uint64_t* C, size_t length) {\n    size_t i = 0;\n\n    // Process 2 elements (128 bits) at a time using SSE2 intrinsics\n    for (; i + 1 < length; i += 2) {\n        // Load 128-bit chunks from A and B\n        __m128i vecA = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i vecB = _mm_loadu_si128((__m128i*)&B[i]);\n\n        // Compute bitwise negation of vecB\n        __m128i negVecB = _mm_andnot_si128(vecB, _mm_set1_epi64x(-1));\n\n        // Perform bitwise AND between vecA and negVecB\n        __m128i result = _mm_and_si128(vecA, negVecB);\n\n        // Store the result into C\n        _mm_storeu_si128((__m128i*)&C[i], result);\n    }\n\n    // Handle remaining elements (if length is odd)\n    for (; i < length; ++i) {\n        C[i] = A[i] & ~B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_42_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid tensor_bit_clear_simd(const uint64_t* A, const uint64_t* B, uint64_t* C, size_t length) {\n    size_t i = 0;\n\n    // Process 2 elements (128 bits) per iteration using SSE2\n    for (; i + 1 < length; i += 2) {\n        // Load 128-bit chunks from A and B\n        __m128i a = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i b = _mm_loadu_si128((__m128i*)&B[i]);\n\n        // Compute bitwise negation of B\n        __m128i neg_b = _mm_andnot_si128(b, _mm_set1_epi64x(0xFFFFFFFFFFFFFFFF));\n\n        // Perform bitwise AND between A and negated B\n        __m128i result = _mm_and_si128(a, neg_b);\n\n        // Store the result into C\n        _mm_storeu_si128((__m128i*)&C[i], result);\n    }\n\n    // Handle remaining elements (if length is odd)\n    for (; i < length; ++i) {\n        C[i] = A[i] & ~B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_42_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid tensor_bit_clear_simd(const uint64_t* A, const uint64_t* B, uint64_t* C, size_t length) {\n    size_t i = 0;\n\n    // Process 2 elements (128 bits) at a time using SSE2 intrinsics\n    for (; i + 1 < length; i += 2) {\n        // Load 128-bit chunks from A and B\n        __m128i vecA = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i vecB = _mm_loadu_si128((__m128i*)&B[i]);\n\n        // Compute bitwise negation of vecB\n        __m128i negVecB = _mm_andnot_si128(vecB, _mm_set1_epi64x(-1));\n\n        // Perform bitwise AND between vecA and negVecB\n        __m128i result = _mm_and_si128(vecA, negVecB);\n\n        // Store the result into C\n        _mm_storeu_si128((__m128i*)&C[i], result);\n    }\n\n    // Handle any remaining elements that don't fit into 128-bit chunks\n    for (; i < length; ++i) {\n        C[i] = A[i] & ~B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_43_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid tensor_three_valued_logic_simd(const int8_t* A, const int8_t* B, int8_t* C, size_t length) {\n    size_t i = 0;\n\n    // Process 16 elements at a time using SSE2 intrinsics\n    for (; i + 15 < length; i += 16) {\n        // Load 16 bytes from A and B into SIMD registers\n        __m128i vecA = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i vecB = _mm_loadu_si128((__m128i*)&B[i]);\n\n        // Compare if both A and B are positive (greater than zero)\n        __m128i positiveMask = _mm_and_si128(\n            _mm_cmpgt_epi8(vecA, _mm_setzero_si128()),\n            _mm_cmpgt_epi8(vecB, _mm_setzero_si128())\n        );\n\n        // Compare if both A and B are negative (less than zero)\n        __m128i negativeMask = _mm_and_si128(\n            _mm_cmplt_epi8(vecA, _mm_setzero_si128()),\n            _mm_cmplt_epi8(vecB, _mm_setzero_si128())\n        );\n\n        // Create result vector: 1 for positiveMask, -1 for negativeMask, 0 otherwise\n        __m128i result = _mm_or_si128(\n            _mm_and_si128(positiveMask, _mm_set1_epi8(1)),\n            _mm_and_si128(negativeMask, _mm_set1_epi8(-1))\n        );\n\n        // Store the result back to C\n        _mm_storeu_si128((__m128i*)&C[i], result);\n    }\n\n    // Handle remaining elements (if any) with scalar code\n    for (; i < length; ++i) {\n        if (A[i] > 0 && B[i] > 0) {\n            C[i] = 1;\n        } else if (A[i] < 0 && B[i] < 0) {\n            C[i] = -1;\n        } else {\n            C[i] = 0;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_43_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid tensor_three_valued_logic_simd(const int8_t* A, const int8_t* B, int8_t* C, size_t length) {\n    size_t i = 0;\n    __m128i ones = _mm_set1_epi8(1);\n    __m128i neg_ones = _mm_set1_epi8(-1);\n    __m128i zeros = _mm_setzero_si128();\n\n    for (; i + 16 <= length; i += 16) {\n        __m128i a = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i b = _mm_loadu_si128((__m128i*)&B[i]);\n\n        __m128i both_positive = _mm_and_si128(_mm_cmpgt_epi8(a, zeros), _mm_cmpgt_epi8(b, zeros));\n        __m128i both_negative = _mm_and_si128(_mm_cmplt_epi8(a, zeros), _mm_cmplt_epi8(b, zeros));\n\n        __m128i result = _mm_blendv_epi8(zeros, ones, both_positive);\n        result = _mm_blendv_epi8(result, neg_ones, both_negative);\n\n        _mm_storeu_si128((__m128i*)&C[i], result);\n    }\n\n    for (; i < length; ++i) {\n        if (A[i] > 0 && B[i] > 0) {\n            C[i] = 1;\n        } else if (A[i] < 0 && B[i] < 0) {\n            C[i] = -1;\n        } else {\n            C[i] = 0;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_43_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid tensor_three_valued_logic_simd(const int8_t* A, const int8_t* B, int8_t* C, size_t length) {\n    size_t i = 0;\n\n    // Process 16 elements at a time using SSE2 intrinsics\n    for (; i + 15 < length; i += 16) {\n        // Load 16 bytes from A and B into SIMD registers\n        __m128i vecA = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i vecB = _mm_loadu_si128((__m128i*)&B[i]);\n\n        // Compare if both A and B are positive (greater than zero)\n        __m128i positiveMask = _mm_and_si128(\n            _mm_cmpgt_epi8(vecA, _mm_setzero_si128()),\n            _mm_cmpgt_epi8(vecB, _mm_setzero_si128())\n        );\n\n        // Compare if both A and B are negative (less than zero)\n        __m128i negativeMask = _mm_and_si128(\n            _mm_cmplt_epi8(vecA, _mm_setzero_si128()),\n            _mm_cmplt_epi8(vecB, _mm_setzero_si128())\n        );\n\n        // Create result vector: 1 for positiveMask, -1 for negativeMask, 0 otherwise\n        __m128i result = _mm_or_si128(\n            _mm_and_si128(positiveMask, _mm_set1_epi8(1)),\n            _mm_and_si128(negativeMask, _mm_set1_epi8(-1))\n        );\n\n        // Store the result back to C\n        _mm_storeu_si128((__m128i*)&C[i], result);\n    }\n\n    // Process remaining elements (if any) with scalar code\n    for (; i < length; ++i) {\n        if (A[i] > 0 && B[i] > 0) {\n            C[i] = 1;\n        } else if (A[i] < 0 && B[i] < 0) {\n            C[i] = -1;\n        } else {\n            C[i] = 0;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_43_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n\nvoid tensor_three_valued_logic_simd(const int8_t* A, const int8_t* B, int8_t* C, size_t length) {\n    size_t i = 0;\n\n    // Process 16 elements at a time using SSE2 intrinsics\n    for (; i + 15 < length; i += 16) {\n        // Load 16 bytes from A and B into SIMD registers\n        __m128i vecA = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i vecB = _mm_loadu_si128((__m128i*)&B[i]);\n\n        // Compare if both A and B are positive (greater than zero)\n        __m128i positiveMask = _mm_and_si128(\n            _mm_cmpgt_epi8(vecA, _mm_setzero_si128()),\n            _mm_cmpgt_epi8(vecB, _mm_setzero_si128())\n        );\n\n        // Compare if both A and B are negative (less than zero)\n        __m128i negativeMask = _mm_and_si128(\n            _mm_cmplt_epi8(vecA, _mm_setzero_si128()),\n            _mm_cmplt_epi8(vecB, _mm_setzero_si128())\n        );\n\n        // Create result vector: 1 for positiveMask, -1 for negativeMask, 0 otherwise\n        __m128i result = _mm_or_si128(\n            _mm_and_si128(positiveMask, _mm_set1_epi8(1)),\n            _mm_and_si128(negativeMask, _mm_set1_epi8(-1))\n        );\n\n        // Store the result into C\n        _mm_storeu_si128((__m128i*)&C[i], result);\n    }\n\n    // Process remaining elements (if any) with scalar code\n    for (; i < length; ++i) {\n        if (A[i] > 0 && B[i] > 0) {\n            C[i] = 1;\n        } else if (A[i] < 0 && B[i] < 0) {\n            C[i] = -1;\n        } else {\n            C[i] = 0;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_43_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid tensor_three_valued_logic_simd(const int8_t* A, const int8_t* B, int8_t* C, size_t length) {\n    size_t i = 0;\n\n    // Process 16 elements at a time using SSE2 intrinsics\n    for (; i + 15 < length; i += 16) {\n        // Load 16 bytes from A and B into SIMD registers\n        __m128i vecA = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i vecB = _mm_loadu_si128((__m128i*)&B[i]);\n\n        // Compare if both A and B are positive (greater than zero)\n        __m128i positiveMask = _mm_and_si128(\n            _mm_cmpgt_epi8(vecA, _mm_setzero_si128()),\n            _mm_cmpgt_epi8(vecB, _mm_setzero_si128())\n        );\n\n        // Compare if both A and B are negative (less than zero)\n        __m128i negativeMask = _mm_and_si128(\n            _mm_cmplt_epi8(vecA, _mm_setzero_si128()),\n            _mm_cmplt_epi8(vecB, _mm_setzero_si128())\n        );\n\n        // Create result vector: 1 for positiveMask, -1 for negativeMask, 0 otherwise\n        __m128i result = _mm_or_si128(\n            _mm_and_si128(positiveMask, _mm_set1_epi8(1)),\n            _mm_and_si128(negativeMask, _mm_set1_epi8(-1))\n        );\n\n        // Store the result back to C\n        _mm_storeu_si128((__m128i*)&C[i], result);\n    }\n\n    // Process remaining elements (if any) with scalar code\n    for (; i < length; ++i) {\n        if (A[i] > 0 && B[i] > 0) {\n            C[i] = 1;\n        } else if (A[i] < 0 && B[i] < 0) {\n            C[i] = -1;\n        } else {\n            C[i] = 0;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_44_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid tensor_bit_op_simd(const uint16_t* A, const uint16_t* B, uint16_t* C, size_t length) {\n    size_t mid = length / 2;\n    size_t i = 0;\n\n    // Process elements before the midpoint using SIMD\n    for (; i + 8 <= mid; i += 8) {\n        __m128i vecA = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i vecB = _mm_loadu_si128((__m128i*)&B[i]);\n        __m128i result = _mm_xor_si128(vecA, vecB);\n        _mm_storeu_si128((__m128i*)&C[i], result);\n    }\n\n    // Process remaining elements before the midpoint\n    for (; i < mid; ++i) {\n        C[i] = A[i] ^ B[i];\n    }\n\n    // Handle the midpoint element\n    if (length % 2 == 0 && mid < length) {\n        C[mid] = A[mid];\n    }\n\n    // Process elements after the midpoint using SIMD\n    size_t j = mid + 1;\n    for (; j + 8 <= length; j += 8) {\n        __m128i vecA = _mm_loadu_si128((__m128i*)&A[j]);\n        __m128i vecB = _mm_loadu_si128((__m128i*)&B[j]);\n        __m128i result = _mm_and_si128(vecA, vecB);\n        _mm_storeu_si128((__m128i*)&C[j], result);\n    }\n\n    // Process remaining elements after the midpoint\n    for (; j < length; ++j) {\n        C[j] = A[j] & B[j];\n    }\n}\n```"}
{"task_id": "SimdBench_44_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid tensor_bit_op_simd(const uint16_t* A, const uint16_t* B, uint16_t* C, size_t length) {\n    size_t mid = length / 2;\n    size_t i = 0;\n\n    // Process elements before the midpoint using SIMD\n    for (; i + 8 <= mid; i += 8) {\n        __m128i a = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i b = _mm_loadu_si128((__m128i*)&B[i]);\n        __m128i result = _mm_xor_si128(a, b);\n        _mm_storeu_si128((__m128i*)&C[i], result);\n    }\n\n    // Process remaining elements before the midpoint (if any)\n    for (; i < mid; ++i) {\n        C[i] = A[i] ^ B[i];\n    }\n\n    // Handle the midpoint element\n    if (length % 2 == 0) {\n        C[mid] = A[mid];\n    } else {\n        C[mid] = A[mid];\n        ++mid;\n    }\n\n    // Process elements after the midpoint using SIMD\n    for (; mid + 8 <= length; mid += 8) {\n        __m128i a = _mm_loadu_si128((__m128i*)&A[mid]);\n        __m128i b = _mm_loadu_si128((__m128i*)&B[mid]);\n        __m128i result = _mm_and_si128(a, b);\n        _mm_storeu_si128((__m128i*)&C[mid], result);\n    }\n\n    // Process remaining elements after the midpoint (if any)\n    for (; mid < length; ++mid) {\n        C[mid] = A[mid] & B[mid];\n    }\n}\n```"}
{"task_id": "SimdBench_44_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid tensor_bit_op_simd(const uint16_t* A, const uint16_t* B, uint16_t* C, size_t length) {\n    size_t midpoint = length / 2;\n    size_t i = 0;\n\n    // Process elements before the midpoint using SIMD\n    for (; i + 8 <= midpoint; i += 8) {\n        __m128i vecA = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i vecB = _mm_loadu_si128((__m128i*)&B[i]);\n        __m128i result = _mm_xor_si128(vecA, vecB);\n        _mm_storeu_si128((__m128i*)&C[i], result);\n    }\n\n    // Process remaining elements before the midpoint\n    for (; i < midpoint; ++i) {\n        C[i] = A[i] ^ B[i];\n    }\n\n    // Handle the midpoint element\n    if (length % 2 == 0 && midpoint < length) {\n        C[midpoint] = A[midpoint];\n    }\n\n    // Process elements after the midpoint using SIMD\n    size_t j = midpoint + 1;\n    for (; j + 8 <= length; j += 8) {\n        __m128i vecA = _mm_loadu_si128((__m128i*)&A[j]);\n        __m128i vecB = _mm_loadu_si128((__m128i*)&B[j]);\n        __m128i result = _mm_and_si128(vecA, vecB);\n        _mm_storeu_si128((__m128i*)&C[j], result);\n    }\n\n    // Process remaining elements after the midpoint\n    for (; j < length; ++j) {\n        C[j] = A[j] & B[j];\n    }\n}\n```"}
{"task_id": "SimdBench_44_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid tensor_bit_op_simd(const uint16_t* A, const uint16_t* B, uint16_t* C, size_t length) {\n    size_t midpoint = length / 2;\n    size_t i = 0;\n\n    // Process elements before the midpoint using SIMD\n    for (; i + 8 <= midpoint; i += 8) {\n        __m128i vecA = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i vecB = _mm_loadu_si128((__m128i*)&B[i]);\n        __m128i result = _mm_xor_si128(vecA, vecB);\n        _mm_storeu_si128((__m128i*)&C[i], result);\n    }\n\n    // Process remaining elements before the midpoint\n    for (; i < midpoint; ++i) {\n        C[i] = A[i] ^ B[i];\n    }\n\n    // Handle the midpoint element\n    if (length % 2 == 0 && midpoint < length) {\n        C[midpoint] = A[midpoint];\n    }\n\n    // Process elements after the midpoint using SIMD\n    size_t j = midpoint + (length % 2 == 0 ? 1 : 0);\n    for (; j + 8 <= length; j += 8) {\n        __m128i vecA = _mm_loadu_si128((__m128i*)&A[j]);\n        __m128i vecB = _mm_loadu_si128((__m128i*)&B[j]);\n        __m128i result = _mm_and_si128(vecA, vecB);\n        _mm_storeu_si128((__m128i*)&C[j], result);\n    }\n\n    // Process remaining elements after the midpoint\n    for (; j < length; ++j) {\n        C[j] = A[j] & B[j];\n    }\n}\n```"}
{"task_id": "SimdBench_44_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid tensor_bit_op_simd(const uint16_t* A, const uint16_t* B, uint16_t* C, size_t length) {\n    size_t mid = length / 2;\n    size_t i = 0;\n\n    // Process elements before the midpoint using SIMD\n    for (; i + 8 <= mid; i += 8) {\n        __m128i vecA = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i vecB = _mm_loadu_si128((__m128i*)&B[i]);\n        __m128i result = _mm_xor_si128(vecA, vecB);\n        _mm_storeu_si128((__m128i*)&C[i], result);\n    }\n\n    // Process remaining elements before the midpoint\n    for (; i < mid; ++i) {\n        C[i] = A[i] ^ B[i];\n    }\n\n    // Handle the midpoint element\n    if (length % 2 == 0) {\n        C[mid] = A[mid];\n    } else {\n        C[mid] = A[mid];\n        ++mid;\n    }\n\n    // Process elements after the midpoint using SIMD\n    for (; mid + 8 <= length; mid += 8) {\n        __m128i vecA = _mm_loadu_si128((__m128i*)&A[mid]);\n        __m128i vecB = _mm_loadu_si128((__m128i*)&B[mid]);\n        __m128i result = _mm_and_si128(vecA, vecB);\n        _mm_storeu_si128((__m128i*)&C[mid], result);\n    }\n\n    // Process remaining elements after the midpoint\n    for (; mid < length; ++mid) {\n        C[mid] = A[mid] & B[mid];\n    }\n}\n```"}
{"task_id": "SimdBench_45_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n\nvoid tensor_multi_select_simd(const float* A, const float* B, const float* C, const float* D, const bool* cond1, const bool* cond2, float* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n\n    for (size_t i = 0; i < total_elements; i += 4) {\n        // Load 4 elements from each input tensor\n        __m128 vecA = _mm_loadu_ps(&A[i]);\n        __m128 vecB = _mm_loadu_ps(&B[i]);\n        __m128 vecC = _mm_loadu_ps(&C[i]);\n        __m128 vecD = _mm_loadu_ps(&D[i]);\n\n        // Load 4 boolean conditions from cond1 and cond2\n        __m128i cond1_vec = _mm_loadu_si128((__m128i*)&cond1[i]);\n        __m128i cond2_vec = _mm_loadu_si128((__m128i*)&cond2[i]);\n\n        // Convert boolean conditions to masks\n        __m128 mask_cond1 = _mm_castsi128_ps(_mm_cmpeq_epi32(cond1_vec, _mm_set1_epi32(1)));\n        __m128 mask_cond2 = _mm_castsi128_ps(_mm_cmpeq_epi32(cond2_vec, _mm_set1_epi32(1)));\n\n        // Compute combined masks for the four cases\n        __m128 mask_case1 = _mm_and_ps(mask_cond1, mask_cond2); // cond1 && cond2\n        __m128 mask_case2 = _mm_and_ps(mask_cond1, _mm_xor_ps(mask_cond2, _mm_set1_ps(-0.0f))); // cond1 && !cond2\n        __m128 mask_case3 = _mm_and_ps(_mm_xor_ps(mask_cond1, _mm_set1_ps(-0.0f)), mask_cond2); // !cond1 && cond2\n        __m128 mask_case4 = _mm_and_ps(_mm_xor_ps(mask_cond1, _mm_set1_ps(-0.0f)), _mm_xor_ps(mask_cond2, _mm_set1_ps(-0.0f))); // !cond1 && !cond2\n\n        // Select values based on masks\n        __m128 result = _mm_or_ps(\n            _mm_or_ps(\n                _mm_and_ps(mask_case1, vecA),\n                _mm_and_ps(mask_case2, vecB)\n            ),\n            _mm_or_ps(\n                _mm_and_ps(mask_case3, vecC),\n                _mm_and_ps(mask_case4, vecD)\n            )\n        );\n\n        // Store the result back to the output tensor\n        _mm_storeu_ps(&out[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_45_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n\nvoid tensor_multi_select_simd(const float* A, const float* B, const float* C, const float* D, const bool* cond1, const bool* cond2, float* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n\n    for (size_t i = 0; i < total_elements; i += 4) {\n        // Load 4 elements from each input tensor\n        __m128 vecA = _mm_loadu_ps(&A[i]);\n        __m128 vecB = _mm_loadu_ps(&B[i]);\n        __m128 vecC = _mm_loadu_ps(&C[i]);\n        __m128 vecD = _mm_loadu_ps(&D[i]);\n\n        // Load 4 boolean conditions and convert them to masks\n        int mask_cond1 = 0, mask_cond2 = 0;\n        for (int j = 0; j < 4; ++j) {\n            if (i + j < total_elements) {\n                mask_cond1 |= (cond1[i + j] ? (1 << j) : 0);\n                mask_cond2 |= (cond2[i + j] ? (1 << j) : 0);\n            }\n        }\n\n        // Create masks for SIMD operations\n        __m128 mask_cond1_true = _mm_castsi128_ps(_mm_set1_epi32(mask_cond1));\n        __m128 mask_cond2_true = _mm_castsi128_ps(_mm_set1_epi32(mask_cond2));\n\n        // Compute the output based on conditions\n        __m128 result;\n\n        // Case 1: cond1 && cond2 -> A\n        __m128 mask_case1 = _mm_and_ps(mask_cond1_true, mask_cond2_true);\n        result = _mm_and_ps(mask_case1, vecA);\n\n        // Case 2: cond1 && !cond2 -> B\n        __m128 mask_case2 = _mm_and_ps(mask_cond1_true, _mm_andnot_ps(mask_cond2_true, _mm_set1_ps(1.0f)));\n        result = _mm_or_ps(result, _mm_and_ps(mask_case2, vecB));\n\n        // Case 3: !cond1 && cond2 -> C\n        __m128 mask_case3 = _mm_and_ps(_mm_andnot_ps(mask_cond1_true, _mm_set1_ps(1.0f)), mask_cond2_true);\n        result = _mm_or_ps(result, _mm_and_ps(mask_case3, vecC));\n\n        // Case 4: !cond1 && !cond2 -> D\n        __m128 mask_case4 = _mm_and_ps(_mm_andnot_ps(mask_cond1_true, _mm_set1_ps(1.0f)), _mm_andnot_ps(mask_cond2_true, _mm_set1_ps(1.0f)));\n        result = _mm_or_ps(result, _mm_and_ps(mask_case4, vecD));\n\n        // Store the result back to the output array\n        _mm_storeu_ps(&out[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_45_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n\nvoid tensor_multi_select_simd(const float* A, const float* B, const float* C, const float* D, const bool* cond1, const bool* cond2, float* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n\n    for (size_t i = 0; i < total_elements; i += 4) {\n        // Load 4 elements from each input tensor\n        __m128 vecA = _mm_loadu_ps(&A[i]);\n        __m128 vecB = _mm_loadu_ps(&B[i]);\n        __m128 vecC = _mm_loadu_ps(&C[i]);\n        __m128 vecD = _mm_loadu_ps(&D[i]);\n\n        // Load 4 boolean conditions and convert them to masks\n        int mask_cond1 = 0, mask_cond2 = 0;\n        for (int j = 0; j < 4; ++j) {\n            if (i + j < total_elements) {\n                mask_cond1 |= (cond1[i + j] ? (1 << j) : 0);\n                mask_cond2 |= (cond2[i + j] ? (1 << j) : 0);\n            }\n        }\n\n        // Create masks for SSE operations\n        __m128 mask_cond1_vec = _mm_castsi128_ps(_mm_set1_epi32(mask_cond1));\n        __m128 mask_cond2_vec = _mm_castsi128_ps(_mm_set1_epi32(mask_cond2));\n\n        // Compute the output based on conditions\n        __m128 result;\n\n        // Case 1: cond1 && cond2 -> A\n        __m128 mask_case1 = _mm_and_ps(mask_cond1_vec, mask_cond2_vec);\n        result = _mm_and_ps(mask_case1, vecA);\n\n        // Case 2: cond1 && !cond2 -> B\n        __m128 mask_case2 = _mm_andnot_ps(mask_cond2_vec, mask_cond1_vec);\n        result = _mm_or_ps(result, _mm_and_ps(mask_case2, vecB));\n\n        // Case 3: !cond1 && cond2 -> C\n        __m128 mask_case3 = _mm_andnot_ps(mask_cond1_vec, mask_cond2_vec);\n        result = _mm_or_ps(result, _mm_and_ps(mask_case3, vecC));\n\n        // Case 4: !cond1 && !cond2 -> D\n        __m128 mask_case4 = _mm_andnot_ps(mask_cond1_vec, _mm_andnot_ps(mask_cond2_vec, _mm_set1_ps(1.0f)));\n        result = _mm_or_ps(result, _mm_and_ps(mask_case4, vecD));\n\n        // Store the result back to the output array\n        _mm_storeu_ps(&out[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_45_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n\nvoid tensor_multi_select_simd(const float* A, const float* B, const float* C, const float* D, const bool* cond1, const bool* cond2, float* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n\n    for (size_t i = 0; i < total_elements; i += 4) {\n        // Load 4 elements from each input tensor\n        __m128 vecA = _mm_loadu_ps(&A[i]);\n        __m128 vecB = _mm_loadu_ps(&B[i]);\n        __m128 vecC = _mm_loadu_ps(&C[i]);\n        __m128 vecD = _mm_loadu_ps(&D[i]);\n\n        // Load 4 boolean conditions from cond1 and cond2\n        int mask_cond1 = *(int*)&cond1[i];\n        int mask_cond2 = *(int*)&cond2[i];\n\n        // Create masks for cond1 and cond2\n        __m128i cond1_mask = _mm_set1_epi32(mask_cond1);\n        __m128i cond2_mask = _mm_set1_epi32(mask_cond2);\n\n        // Convert boolean masks to floating-point masks\n        __m128 cond1_true = _mm_castsi128_ps(_mm_cmpeq_epi32(cond1_mask, _mm_set1_epi32(-1)));\n        __m128 cond2_true = _mm_castsi128_ps(_mm_cmpeq_epi32(cond2_mask, _mm_set1_epi32(-1)));\n\n        // Compute the four cases using SSE intrinsics\n        __m128 case1 = _mm_and_ps(cond1_true, _mm_and_ps(cond2_true, vecA)); // cond1 && cond2 -> A\n        __m128 case2 = _mm_and_ps(cond1_true, _mm_andnot_ps(cond2_true, vecB)); // cond1 && !cond2 -> B\n        __m128 case3 = _mm_and_ps(_mm_andnot_ps(cond1_true, cond2_true), vecC); // !cond1 && cond2 -> C\n        __m128 case4 = _mm_and_ps(_mm_andnot_ps(cond1_true, _mm_andnot_ps(cond2_true, vecD)), vecD); // !cond1 && !cond2 -> D\n\n        // Combine all cases into the final result\n        __m128 result = _mm_or_ps(_mm_or_ps(case1, case2), _mm_or_ps(case3, case4));\n\n        // Store the result back to the output tensor\n        _mm_storeu_ps(&out[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_45_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n\nvoid tensor_multi_select_simd(const float* A, const float* B, const float* C, const float* D, const bool* cond1, const bool* cond2, float* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n\n    for (size_t i = 0; i < total_elements; i += 4) {\n        // Load 4 elements from each input tensor\n        __m128 vecA = _mm_loadu_ps(&A[i]);\n        __m128 vecB = _mm_loadu_ps(&B[i]);\n        __m128 vecC = _mm_loadu_ps(&C[i]);\n        __m128 vecD = _mm_loadu_ps(&D[i]);\n\n        // Load 4 boolean conditions from cond1 and cond2\n        int mask_cond1 = *(int*)&cond1[i];\n        int mask_cond2 = *(int*)&cond2[i];\n\n        // Create masks for cond1 and cond2\n        __m128i cond1_mask = _mm_set1_epi32(mask_cond1);\n        __m128i cond2_mask = _mm_set1_epi32(mask_cond2);\n\n        // Convert boolean masks to floating-point masks\n        __m128 cond1_true = _mm_castsi128_ps(_mm_cmpeq_epi32(cond1_mask, _mm_set1_epi32(-1)));\n        __m128 cond2_true = _mm_castsi128_ps(_mm_cmpeq_epi32(cond2_mask, _mm_set1_epi32(-1)));\n\n        // Compute the four cases using masks\n        __m128 case1 = _mm_and_ps(cond1_true, _mm_and_ps(cond2_true, vecA)); // cond1 && cond2 -> A\n        __m128 case2 = _mm_and_ps(cond1_true, _mm_andnot_ps(cond2_true, vecB)); // cond1 && !cond2 -> B\n        __m128 case3 = _mm_and_ps(_mm_andnot_ps(cond1_true, cond2_true), vecC); // !cond1 && cond2 -> C\n        __m128 case4 = _mm_and_ps(_mm_andnot_ps(cond1_true, _mm_andnot_ps(cond2_true, vecD)), vecD); // !cond1 && !cond2 -> D\n\n        // Combine all cases\n        __m128 result = _mm_or_ps(_mm_or_ps(case1, case2), _mm_or_ps(case3, case4));\n\n        // Store the result back to the output tensor\n        _mm_storeu_ps(&out[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_46_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid tensor_bit_count_simd(const uint32_t* A, uint8_t* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n\n    for (size_t i = 0; i < total_elements; i += 4) {\n        // Load 4 uint32_t elements from A into an SSE register\n        __m128i v = _mm_loadu_si128((__m128i*)&A[i]);\n\n        // Count the number of bits set to 1 in each element using SSE intrinsics\n        __m128i count = _mm_setzero_si128();\n\n        // Parallel bit counting using SSE2 instructions\n        for (int j = 0; j < 5; ++j) {\n            __m128i mask = _mm_set1_epi32(0x55555555 << j);\n            __m128i temp = _mm_and_si128(v, mask);\n            count = _mm_add_epi32(count, temp);\n            v = _mm_srli_epi32(v, 1);\n        }\n\n        // Horizontal sum of counts and store results in out\n        alignas(16) uint32_t temp[4];\n        _mm_store_si128((__m128i*)temp, count);\n\n        for (int j = 0; j < 4 && (i + j) < total_elements; ++j) {\n            out[i + j] = __builtin_popcount(temp[j]);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_46_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid tensor_bit_count_simd(const uint32_t* A, uint8_t* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n\n    for (size_t i = 0; i < total_elements; i += 4) {\n        // Load 4 uint32_t elements from A into an SSE register\n        __m128i v = _mm_loadu_si128((__m128i*)&A[i]);\n\n        // Count the number of bits set to 1 in each element using SSE intrinsics\n        // First step: v - ((v >> 1) & 0x55555555)\n        __m128i count = _mm_sub_epi32(v, _mm_and_si128(_mm_srli_epi32(v, 1), _mm_set1_epi32(0x55555555)));\n\n        // Second step: (count & 0x33333333) + ((count >> 2) & 0x33333333)\n        count = _mm_add_epi32(_mm_and_si128(count, _mm_set1_epi32(0x33333333)),\n                              _mm_and_si128(_mm_srli_epi32(count, 2), _mm_set1_epi32(0x33333333)));\n\n        // Third step: (count + (count >> 4)) & 0x0F0F0F0F\n        count = _mm_and_si128(_mm_add_epi32(count, _mm_srli_epi32(count, 4)), _mm_set1_epi32(0x0F0F0F0F));\n\n        // Fourth step: Horizontal sum of nibbles to get the final bit count\n        // Multiply by 0x01010101 and shift right by 24 bits\n        count = _mm_mullo_epi32(count, _mm_set1_epi32(0x01010101));\n        count = _mm_srli_epi32(count, 24);\n\n        // Pack the results into 8-bit integers and store in out\n        __m128i packed = _mm_packus_epi32(count, count);\n        packed = _mm_packus_epi16(packed, packed);\n        _mm_storel_epi64((__m128i*)&out[i], packed);\n    }\n}\n```"}
{"task_id": "SimdBench_46_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid tensor_bit_count_simd(const uint32_t* A, uint8_t* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n\n    for (size_t i = 0; i < total_elements; i += 4) {\n        // Load 4 uint32_t elements from A into an SSE register\n        __m128i v = _mm_loadu_si128((__m128i*)&A[i]);\n\n        // Parallel bit count using SSE2 intrinsics\n        // First step: Count bits in 2-bit chunks\n        __m128i count = _mm_and_si128(v, _mm_set1_epi32(0x55555555));\n        __m128i temp = _mm_srli_epi32(v, 1);\n        temp = _mm_and_si128(temp, _mm_set1_epi32(0x55555555));\n        count = _mm_add_epi32(count, temp);\n\n        // Second step: Count bits in 4-bit chunks\n        temp = _mm_srli_epi32(count, 2);\n        count = _mm_and_si128(count, _mm_set1_epi32(0x33333333));\n        temp = _mm_and_si128(temp, _mm_set1_epi32(0x33333333));\n        count = _mm_add_epi32(count, temp);\n\n        // Third step: Count bits in 8-bit chunks\n        temp = _mm_srli_epi32(count, 4);\n        count = _mm_add_epi32(count, temp);\n        count = _mm_and_si128(count, _mm_set1_epi32(0x0F0F0F0F));\n\n        // Fourth step: Sum all 8-bit chunks to get the final counts\n        temp = _mm_srli_epi32(count, 8);\n        count = _mm_add_epi32(count, temp);\n        temp = _mm_srli_epi32(count, 16);\n        count = _mm_add_epi32(count, temp);\n        count = _mm_and_si128(count, _mm_set1_epi32(0x000000FF));\n\n        // Store the results into the output array\n        __m128i result = _mm_packus_epi32(count, count); // Pack 32-bit counts into 8-bit values\n        result = _mm_packus_epi16(result, result);\n        _mm_storel_epi64((__m128i*)&out[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_46_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid tensor_bit_count_simd(const uint32_t* A, uint8_t* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n\n    for (size_t i = 0; i < total_elements; i += 4) {\n        // Load 4 uint32_t elements from A into an SSE register\n        __m128i v = _mm_loadu_si128((__m128i*)&A[i]);\n\n        // Count the number of bits set to 1 in each element using SSE2 intrinsics\n        __m128i count = _mm_setzero_si128();\n\n        // Parallel bit counting using SSE2 instructions\n        for (int j = 0; j < 5; ++j) {\n            __m128i mask = _mm_set1_epi32(0x55555555 << j);\n            count = _mm_add_epi32(count, _mm_and_si128(v, mask));\n            v = _mm_srli_epi32(v, 1);\n        }\n\n        // Horizontal sum of counts within each 32-bit lane\n        __m128i shuffle1 = _mm_shuffle_epi32(count, _MM_SHUFFLE(2, 3, 0, 1));\n        count = _mm_add_epi32(count, shuffle1);\n        __m128i shuffle2 = _mm_shuffle_epi32(count, _MM_SHUFFLE(1, 0, 3, 2));\n        count = _mm_add_epi32(count, shuffle2);\n\n        // Extract the results and store them in the output array\n        int result[4];\n        _mm_storeu_si128((__m128i*)result, count);\n\n        for (int j = 0; j < 4 && (i + j) < total_elements; ++j) {\n            out[i + j] = (uint8_t)result[j];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_46_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid tensor_bit_count_simd(const uint32_t* A, uint8_t* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n\n    // Process 4 elements at a time using SSE2\n    size_t i = 0;\n    for (; i + 4 <= total_elements; i += 4) {\n        // Load 4 uint32_t elements from A\n        __m128i v = _mm_loadu_si128((__m128i*)&A[i]);\n\n        // Count the number of bits set to 1 in each element\n        __m128i count = _mm_setzero_si128();\n        for (int k = 0; k < 32; ++k) {\n            count = _mm_add_epi8(count, _mm_and_si128(v, _mm_set1_epi32(1)));\n            v = _mm_srli_epi32(v, 1);\n        }\n\n        // Pack the results into 8-bit integers\n        __m128i packed = _mm_packs_epi32(count, count);\n        packed = _mm_packus_epi16(packed, packed);\n\n        // Store the 4 results into out\n        _mm_storel_epi64((__m128i*)&out[i], packed);\n    }\n\n    // Handle remaining elements\n    for (; i < total_elements; ++i) {\n        out[i] = __builtin_popcount(A[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_47_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n\nvoid matrix_conditional_abs_simd(const int* A, int* B, size_t rows, size_t cols) {\n    size_t simd_width = 4; // SSE/SSE2 processes 4 integers at a time\n    __m128i div_by_3 = _mm_set1_epi32(3); // Vector with all elements set to 3\n    __m128i zero = _mm_setzero_si128();   // Vector of zeros for absolute value computation\n\n    for (size_t i = 0; i < rows; ++i) {\n        size_t j = 0;\n        // Process elements in chunks of 4 using SIMD\n        for (; j + simd_width <= cols; j += simd_width) {\n            // Load 4 integers from A into an SSE register\n            __m128i vec_a = _mm_loadu_si128((__m128i*)&A[i * cols + j]);\n\n            // Check if each element is divisible by 3\n            __m128i mod_result = _mm_rem_epi32(vec_a, div_by_3); // Compute remainder\n            __m128i is_divisible = _mm_cmpeq_epi32(mod_result, zero); // Compare remainder to zero\n\n            // Compute the absolute value of vec_a\n            __m128i abs_a = _mm_abs_epi32(vec_a);\n\n            // Blend: If divisible by 3, take abs_a; otherwise, keep vec_a\n            __m128i result = _mm_blendv_epi8(vec_a, abs_a, is_divisible);\n\n            // Store the result back into B\n            _mm_storeu_si128((__m128i*)&B[i * cols + j], result);\n        }\n\n        // Process remaining elements (if any) using scalar code\n        for (; j < cols; ++j) {\n            int val = A[i * cols + j];\n            if (val % 3 == 0) {\n                B[i * cols + j] = (val < 0) ? -val : val;\n            } else {\n                B[i * cols + j] = val;\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_47_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid matrix_conditional_abs_simd(const int* A, int* B, size_t rows, size_t cols) {\n    size_t simd_width = 4; // SSE/SSE2 processes 4 integers at a time\n    __m128i div_by_3 = _mm_set1_epi32(3); // Constant vector for modulo operation\n    __m128i zero = _mm_setzero_si128();   // Zero vector for absolute value calculation\n\n    for (size_t i = 0; i < rows; ++i) {\n        size_t j = 0;\n        // Process elements in chunks of 4 using SIMD\n        for (; j + simd_width <= cols; j += simd_width) {\n            // Load 4 integers from A into an SSE register\n            __m128i vec_a = _mm_loadu_si128((__m128i*)&A[i * cols + j]);\n\n            // Compute modulo 3 for each element\n            __m128i mod_result = _mm_rem_epi32(vec_a, div_by_3);\n\n            // Check if the result is zero (divisible by 3)\n            __m128i mask = _mm_cmpeq_epi32(mod_result, zero);\n\n            // Compute the absolute value of vec_a\n            __m128i abs_a = _mm_abs_epi32(vec_a);\n\n            // Blend: If divisible by 3, take abs_a; otherwise, keep vec_a\n            __m128i result = _mm_blendv_epi8(vec_a, abs_a, mask);\n\n            // Store the result back to B\n            _mm_storeu_si128((__m128i*)&B[i * cols + j], result);\n        }\n\n        // Process remaining elements (if any) with scalar code\n        for (; j < cols; ++j) {\n            int val = A[i * cols + j];\n            if (val % 3 == 0) {\n                B[i * cols + j] = (val < 0) ? -val : val;\n            } else {\n                B[i * cols + j] = val;\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_47_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n\nvoid matrix_conditional_abs_simd(const int* A, int* B, size_t rows, size_t cols) {\n    size_t simd_width = 4; // SSE/SSE2 operates on 128-bit registers, which can handle 4 integers at a time.\n    __m128i div_by_3 = _mm_set1_epi32(3); // Vector with all elements set to 3 for modulo operation.\n    __m128i zero = _mm_setzero_si128();  // Vector of zeros for comparison.\n\n    for (size_t i = 0; i < rows; ++i) {\n        size_t j = 0;\n\n        // Process elements in chunks of 4 using SIMD.\n        for (; j + simd_width <= cols; j += simd_width) {\n            // Load 4 integers from A into an SSE register.\n            __m128i vec_a = _mm_loadu_si128((__m128i*)&A[i * cols + j]);\n\n            // Compute the remainder when dividing by 3.\n            __m128i mod_result = _mm_rem_epi32(vec_a, div_by_3);\n\n            // Check if the remainder is zero (divisible by 3).\n            __m128i is_divisible = _mm_cmpeq_epi32(mod_result, zero);\n\n            // Compute the absolute value of the elements in vec_a.\n            __m128i abs_a = _mm_abs_epi32(vec_a);\n\n            // Blend the original values and absolute values based on the condition.\n            __m128i result = _mm_blendv_epi8(vec_a, abs_a, is_divisible);\n\n            // Store the result back into B.\n            _mm_storeu_si128((__m128i*)&B[i * cols + j], result);\n        }\n\n        // Process remaining elements that don't fit into a SIMD chunk.\n        for (; j < cols; ++j) {\n            if (A[i * cols + j] % 3 == 0) {\n                B[i * cols + j] = abs(A[i * cols + j]);\n            } else {\n                B[i * cols + j] = A[i * cols + j];\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_47_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid matrix_conditional_abs_simd(const int* A, int* B, size_t rows, size_t cols) {\n    size_t simd_width = 4; // SSE/SSE2 operates on 128-bit registers, which can handle 4 integers at a time.\n    __m128i div_by_3 = _mm_set1_epi32(3); // Vector with all elements set to 3 for modulo operation.\n    __m128i zero = _mm_setzero_si128();   // Vector of zeros for comparison.\n\n    for (size_t i = 0; i < rows; ++i) {\n        size_t j = 0;\n        // Process elements in chunks of 4 using SIMD.\n        for (; j + simd_width <= cols; j += simd_width) {\n            // Load 4 integers from A into an SSE register.\n            __m128i vec_a = _mm_loadu_si128((__m128i*)&A[i * cols + j]);\n\n            // Compute the modulo operation (vec_a % 3).\n            __m128i mod_result = _mm_rem_epi32(vec_a, div_by_3);\n\n            // Check if the result of the modulo is zero (divisible by 3).\n            __m128i is_divisible = _mm_cmpeq_epi32(mod_result, zero);\n\n            // Compute the absolute value of vec_a.\n            __m128i abs_a = _mm_abs_epi32(vec_a);\n\n            // Blend values: if divisible by 3, take abs_a; otherwise, keep vec_a.\n            __m128i result = _mm_blendv_epi8(vec_a, abs_a, is_divisible);\n\n            // Store the result back into B.\n            _mm_storeu_si128((__m128i*)&B[i * cols + j], result);\n        }\n\n        // Process remaining elements that don't fit into a full SIMD register.\n        for (; j < cols; ++j) {\n            int val = A[i * cols + j];\n            B[i * cols + j] = (val % 3 == 0) ? abs(val) : val;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_47_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n\nvoid matrix_conditional_abs_simd(const int* A, int* B, size_t rows, size_t cols) {\n    size_t simd_width = 4; // SSE/SSE2 operates on 128-bit registers, which can handle 4 integers (32-bit each)\n    __m128i div_by_3 = _mm_set1_epi32(3); // Vector with all elements set to 3\n    __m128i zero = _mm_setzero_si128();   // Vector of zeros for absolute value computation\n\n    for (size_t i = 0; i < rows; ++i) {\n        size_t j = 0;\n        // Process elements in chunks of 4 using SIMD\n        for (; j + simd_width <= cols; j += simd_width) {\n            // Load 4 integers from A into an SSE register\n            __m128i a_vec = _mm_loadu_si128((__m128i*)&A[i * cols + j]);\n\n            // Check if each element is divisible by 3\n            __m128i mod_vec = _mm_rem_epi32(a_vec, div_by_3); // Compute a % 3 for all elements\n            __m128i mask = _mm_cmpeq_epi32(mod_vec, zero);    // Create a mask where elements are divisible by 3\n\n            // Compute the absolute value of elements in a_vec\n            __m128i abs_vec = _mm_abs_epi32(a_vec);\n\n            // Blend: If divisible by 3, take abs_vec; otherwise, keep original values\n            __m128i result = _mm_blendv_epi8(a_vec, abs_vec, mask);\n\n            // Store the result back into B\n            _mm_storeu_si128((__m128i*)&B[i * cols + j], result);\n        }\n\n        // Process remaining elements (if any) using scalar code\n        for (; j < cols; ++j) {\n            int val = A[i * cols + j];\n            B[i * cols + j] = (val % 3 == 0) ? abs(val) : val;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_48_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid matrix_conditional_bit_rotate_simd(const uint32_t* src, uint32_t* dst, uint8_t rotate_bits, size_t length) {\n    __m128i rotate_mask = _mm_set1_epi32(0xF); // Mask to extract low 4 bits\n    __m128i condition_mask = _mm_set1_epi32(0xF); // Condition: low 4 bits must be all 1s\n    __m128i rotate_bits_vec = _mm_set1_epi32(rotate_bits); // Broadcast rotate_bits to all lanes\n\n    for (size_t i = 0; i < length; i += 4) {\n        // Load 4 elements from src into SIMD register\n        __m128i src_vec = _mm_loadu_si128((__m128i*)&src[i]);\n\n        // Extract low 4 bits of each element\n        __m128i low_4_bits = _mm_and_si128(src_vec, rotate_mask);\n\n        // Check if low 4 bits are all 1s\n        __m128i cmp_result = _mm_cmpeq_epi32(low_4_bits, condition_mask);\n\n        // Compute bitwise negation of src_vec\n        __m128i negated_src = _mm_xor_si128(src_vec, _mm_set1_epi32(0xFFFFFFFF));\n\n        // Perform rotation for elements where condition is true\n        __m128i rotated_src = _mm_or_si128(\n            _mm_srli_epi32(src_vec, rotate_bits),\n            _mm_slli_epi32(src_vec, 32 - rotate_bits)\n        );\n\n        // Blend results based on the condition\n        __m128i result = _mm_blendv_epi8(negated_src, rotated_src, cmp_result);\n\n        // Store the result into dst\n        _mm_storeu_si128((__m128i*)&dst[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_48_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid matrix_conditional_bit_rotate_simd(const uint32_t* src, uint32_t* dst, uint8_t rotate_bits, size_t length) {\n    __m128i mask_low4 = _mm_set1_epi32(0xF); // Mask to extract low 4 bits\n    __m128i ones = _mm_set1_epi32(0xF);     // All ones for comparison\n    __m128i rotate_mask = _mm_set1_epi32((1 << rotate_bits) - 1);\n    __m128i rotate_bits_vec = _mm_set1_epi32(rotate_bits);\n\n    for (size_t i = 0; i < length; i += 4) {\n        // Load 4 elements from src\n        __m128i src_vec = _mm_loadu_si128((__m128i*)&src[i]);\n\n        // Extract low 4 bits of each element\n        __m128i low4 = _mm_and_si128(src_vec, mask_low4);\n\n        // Check if low 4 bits are all 1s\n        __m128i condition = _mm_cmpeq_epi32(low4, ones);\n\n        // Compute bitwise negation of src\n        __m128i negated = _mm_xor_si128(src_vec, _mm_set1_epi32(0xFFFFFFFF));\n\n        // Perform rotation\n        __m128i rotated = _mm_or_si128(\n            _mm_srli_epi32(src_vec, rotate_bits),\n            _mm_slli_epi32(src_vec, 32 - rotate_bits)\n        );\n\n        // Select between rotated and negated based on condition\n        __m128i result = _mm_blendv_epi8(negated, rotated, condition);\n\n        // Store the result into dst\n        _mm_storeu_si128((__m128i*)&dst[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_48_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid matrix_conditional_bit_rotate_simd(const uint32_t* src, uint32_t* dst, uint8_t rotate_bits, size_t length) {\n    __m128i rotate_mask = _mm_set1_epi32(0xF); // Mask for low 4 bits\n    __m128i all_ones = _mm_set1_epi32(0xF);   // All ones in low 4 bits\n    __m128i rotate_bits_vec = _mm_set1_epi32(rotate_bits);\n\n    for (size_t i = 0; i < length; i += 4) {\n        // Load 4 elements from src\n        __m128i src_vec = _mm_loadu_si128((__m128i*)&src[i]);\n\n        // Extract low 4 bits of each element\n        __m128i low_bits = _mm_and_si128(src_vec, rotate_mask);\n\n        // Check if low 4 bits are all ones\n        __m128i condition = _mm_cmpeq_epi32(low_bits, all_ones);\n\n        // Compute bitwise negation of src\n        __m128i negated_src = _mm_xor_si128(src_vec, _mm_set1_epi32(0xFFFFFFFF));\n\n        // Perform rotation for elements where condition is true\n        __m128i rotated_src = _mm_or_si128(\n            _mm_srli_epi32(src_vec, rotate_bits),\n            _mm_slli_epi32(src_vec, 32 - rotate_bits)\n        );\n\n        // Blend results based on condition\n        __m128i result = _mm_blendv_epi8(negated_src, rotated_src, condition);\n\n        // Store the result into dst\n        _mm_storeu_si128((__m128i*)&dst[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_48_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid matrix_conditional_bit_rotate_simd(const uint32_t* src, uint32_t* dst, uint8_t rotate_bits, size_t length) {\n    __m128i rotate_mask = _mm_set1_epi32(0xF); // Mask for low 4 bits\n    __m128i all_ones = _mm_set1_epi32(0xF);   // All ones in low 4 bits\n    __m128i rotate_bits_vec = _mm_set1_epi32(rotate_bits);\n\n    for (size_t i = 0; i < length; i += 4) {\n        // Load 4 elements from src into SIMD register\n        __m128i src_vec = _mm_loadu_si128((__m128i*)&src[i]);\n\n        // Extract low 4 bits of each element\n        __m128i low_bits = _mm_and_si128(src_vec, rotate_mask);\n\n        // Compare if low 4 bits are all 1s\n        __m128i condition = _mm_cmpeq_epi32(low_bits, all_ones);\n\n        // Compute bitwise negation of src_vec\n        __m128i negated = _mm_xor_si128(src_vec, _mm_set1_epi32(0xFFFFFFFF));\n\n        // Perform rotation by shift left and shift right\n        __m128i rotated_left = _mm_sllv_epi32(src_vec, rotate_bits_vec);\n        __m128i rotated_right = _mm_srlv_epi32(src_vec, _mm_sub_epi32(_mm_set1_epi32(32), rotate_bits_vec));\n        __m128i rotated = _mm_or_si128(rotated_left, rotated_right);\n\n        // Blend results based on condition: if true, use rotated; else use negated\n        __m128i result = _mm_blendv_epi8(negated, rotated, condition);\n\n        // Store the result into dst\n        _mm_storeu_si128((__m128i*)&dst[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_48_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid matrix_conditional_bit_rotate_simd(const uint32_t* src, uint32_t* dst, uint8_t rotate_bits, size_t length) {\n    __m128i rotate_mask = _mm_set1_epi32(0xF); // Mask for low 4 bits\n    __m128i condition_mask = _mm_set1_epi32(0xF); // Condition: low 4 bits must be all 1s\n    __m128i rotate_bits_vec = _mm_set1_epi32(rotate_bits); // Broadcast rotate_bits to all lanes\n\n    for (size_t i = 0; i < length; i += 4) {\n        // Load 4 elements from src into an SSE register\n        __m128i src_vec = _mm_loadu_si128((__m128i*)&src[i]);\n\n        // Extract the low 4 bits of each element in src_vec\n        __m128i low_4_bits = _mm_and_si128(src_vec, rotate_mask);\n\n        // Check if the low 4 bits are all 1s (0xF)\n        __m128i cmp_result = _mm_cmpeq_epi32(low_4_bits, condition_mask);\n\n        // Compute bitwise negation of src_vec\n        __m128i negated_src = _mm_xor_si128(src_vec, _mm_set1_epi32(0xFFFFFFFF));\n\n        // Perform rotation for elements where condition is true\n        __m128i rotated_src = _mm_or_si128(\n            _mm_srli_epi32(src_vec, rotate_bits),\n            _mm_slli_epi32(src_vec, 32 - rotate_bits)\n        );\n\n        // Blend results based on the comparison mask\n        __m128i result = _mm_blendv_epi8(negated_src, rotated_src, cmp_result);\n\n        // Store the result into dst\n        _mm_storeu_si128((__m128i*)&dst[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_49_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid tensor_ternary_compare_simd(const float* A, const float* B, int8_t* out, float epsilon, size_t length) {\n    __m128 v_epsilon = _mm_set1_ps(epsilon);\n    __m128 v_neg_epsilon = _mm_set1_ps(-epsilon);\n    __m128i v_one = _mm_set1_epi8(1);\n    __m128i v_zero = _mm_setzero_si128();\n    __m128i v_neg_one = _mm_set1_epi8(-1);\n\n    size_t i = 0;\n    for (; i + 4 <= length; i += 4) {\n        __m128 v_a = _mm_loadu_ps(&A[i]);\n        __m128 v_b = _mm_loadu_ps(&B[i]);\n        __m128 v_diff = _mm_sub_ps(v_a, v_b);\n\n        __m128 v_cmp_gt = _mm_cmpgt_ps(v_diff, v_epsilon);\n        __m128 v_cmp_lt = _mm_cmplt_ps(v_diff, v_neg_epsilon);\n\n        __m128i v_mask_gt = _mm_castps_si128(v_cmp_gt);\n        __m128i v_mask_lt = _mm_castps_si128(v_cmp_lt);\n\n        __m128i v_result = _mm_or_si128(\n            _mm_and_si128(v_mask_gt, v_one),\n            _mm_and_si128(v_mask_lt, v_neg_one)\n        );\n\n        __m128i v_final = _mm_packs_epi32(v_result, v_zero);\n        _mm_storeu_si128((__m128i*)&out[i], v_final);\n    }\n\n    for (; i < length; ++i) {\n        float diff = A[i] - B[i];\n        if (diff > epsilon) {\n            out[i] = 1;\n        } else if (diff < -epsilon) {\n            out[i] = -1;\n        } else {\n            out[i] = 0;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_49_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid tensor_ternary_compare_simd(const float* A, const float* B, int8_t* out, float epsilon, size_t length) {\n    __m128 v_epsilon = _mm_set1_ps(epsilon);\n    __m128 v_neg_epsilon = _mm_set1_ps(-epsilon);\n    __m128i v_one = _mm_set1_epi8(1);\n    __m128i v_neg_one = _mm_set1_epi8(-1);\n    __m128i v_zero = _mm_setzero_si128();\n\n    size_t i = 0;\n    for (; i + 4 <= length; i += 4) {\n        // Load 4 floats from A and B\n        __m128 v_a = _mm_loadu_ps(&A[i]);\n        __m128 v_b = _mm_loadu_ps(&B[i]);\n\n        // Compute difference: A[i] - B[i]\n        __m128 v_diff = _mm_sub_ps(v_a, v_b);\n\n        // Compare A[i] - B[i] > epsilon\n        __m128 v_gt = _mm_cmpgt_ps(v_diff, v_epsilon);\n\n        // Compare A[i] - B[i] < -epsilon\n        __m128 v_lt = _mm_cmplt_ps(v_diff, v_neg_epsilon);\n\n        // Convert comparison results to masks\n        __m128i v_gt_mask = _mm_castps_si128(v_gt);\n        __m128i v_lt_mask = _mm_castps_si128(v_lt);\n\n        // Create output values based on masks\n        __m128i v_result = _mm_blendv_epi8(v_zero, v_one, v_gt_mask);\n        v_result = _mm_blendv_epi8(v_result, v_neg_one, v_lt_mask);\n\n        // Store the result as 4 int8_t values\n        _mm_storeu_si128((__m128i*)&out[i], v_result);\n    }\n\n    // Handle remaining elements\n    for (; i < length; ++i) {\n        float diff = A[i] - B[i];\n        if (diff > epsilon) {\n            out[i] = 1;\n        } else if (diff < -epsilon) {\n            out[i] = -1;\n        } else {\n            out[i] = 0;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_49_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid tensor_ternary_compare_simd(const float* A, const float* B, int8_t* out, float epsilon, size_t length) {\n    __m128 v_epsilon = _mm_set1_ps(epsilon);\n    __m128 v_neg_epsilon = _mm_set1_ps(-epsilon);\n    __m128i v_one = _mm_set1_epi8(1);\n    __m128i v_zero = _mm_setzero_si128();\n    __m128i v_neg_one = _mm_set1_epi8(-1);\n\n    size_t i = 0;\n    for (; i + 4 <= length; i += 4) {\n        // Load 4 floats from A and B\n        __m128 v_a = _mm_loadu_ps(&A[i]);\n        __m128 v_b = _mm_loadu_ps(&B[i]);\n\n        // Compute difference: A[i] - B[i]\n        __m128 v_diff = _mm_sub_ps(v_a, v_b);\n\n        // Compare A[i] - B[i] > epsilon\n        __m128 v_gt = _mm_cmpgt_ps(v_diff, v_epsilon);\n\n        // Compare A[i] - B[i] < -epsilon\n        __m128 v_lt = _mm_cmplt_ps(v_diff, v_neg_epsilon);\n\n        // Convert comparison results to masks\n        __m128i v_gt_mask = _mm_castps_si128(v_gt);\n        __m128i v_lt_mask = _mm_castps_si128(v_lt);\n\n        // Create output values based on masks\n        __m128i v_result = _mm_blendv_epi8(v_zero, v_one, v_gt_mask);\n        v_result = _mm_blendv_epi8(v_result, v_neg_one, v_lt_mask);\n\n        // Store the result as 4 int8_t values\n        _mm_storeu_si128((__m128i*)&out[i], v_result);\n    }\n\n    // Handle remaining elements\n    for (; i < length; ++i) {\n        float diff = A[i] - B[i];\n        if (diff > epsilon) {\n            out[i] = 1;\n        } else if (diff < -epsilon) {\n            out[i] = -1;\n        } else {\n            out[i] = 0;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_49_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid tensor_ternary_compare_simd(const float* A, const float* B, int8_t* out, float epsilon, size_t length) {\n    __m128 v_epsilon = _mm_set1_ps(epsilon);\n    __m128 v_neg_epsilon = _mm_set1_ps(-epsilon);\n    __m128i v_one = _mm_set1_epi8(1);\n    __m128i v_zero = _mm_setzero_si128();\n    __m128i v_neg_one = _mm_set1_epi8(-1);\n\n    size_t i = 0;\n    for (; i + 4 <= length; i += 4) {\n        __m128 v_a = _mm_loadu_ps(&A[i]);\n        __m128 v_b = _mm_loadu_ps(&B[i]);\n        __m128 v_diff = _mm_sub_ps(v_a, v_b);\n\n        __m128 v_cmp_gt = _mm_cmpgt_ps(v_diff, v_epsilon);\n        __m128 v_cmp_lt = _mm_cmplt_ps(v_diff, v_neg_epsilon);\n\n        __m128i v_mask_gt = _mm_castps_si128(v_cmp_gt);\n        __m128i v_mask_lt = _mm_castps_si128(v_cmp_lt);\n\n        __m128i v_result = _mm_blendv_epi8(v_zero, v_one, v_mask_gt);\n        v_result = _mm_blendv_epi8(v_result, v_neg_one, v_mask_lt);\n\n        _mm_storeu_si128((__m128i*)&out[i], v_result);\n    }\n\n    for (; i < length; ++i) {\n        float diff = A[i] - B[i];\n        if (diff > epsilon) {\n            out[i] = 1;\n        } else if (diff < -epsilon) {\n            out[i] = -1;\n        } else {\n            out[i] = 0;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_49_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid tensor_ternary_compare_simd(const float* A, const float* B, int8_t* out, float epsilon, size_t length) {\n    __m128 v_epsilon = _mm_set1_ps(epsilon);\n    __m128 v_neg_epsilon = _mm_set1_ps(-epsilon);\n    __m128i v_one = _mm_set1_epi8(1);\n    __m128i v_zero = _mm_setzero_si128();\n    __m128i v_neg_one = _mm_set1_epi8(-1);\n\n    size_t i = 0;\n    for (; i + 4 <= length; i += 4) {\n        __m128 v_a = _mm_loadu_ps(&A[i]);\n        __m128 v_b = _mm_loadu_ps(&B[i]);\n        __m128 v_diff = _mm_sub_ps(v_a, v_b);\n\n        __m128 v_cmp_gt = _mm_cmpgt_ps(v_diff, v_epsilon);\n        __m128 v_cmp_lt = _mm_cmplt_ps(v_diff, v_neg_epsilon);\n\n        __m128i v_mask_gt = _mm_castps_si128(v_cmp_gt);\n        __m128i v_mask_lt = _mm_castps_si128(v_cmp_lt);\n\n        __m128i v_result = _mm_or_si128(\n            _mm_and_si128(v_mask_gt, v_one),\n            _mm_and_si128(v_mask_lt, v_neg_one)\n        );\n\n        // Convert the result to 8-bit integers\n        __m128i v_packed_result = _mm_packs_epi32(v_result, v_zero);\n        _mm_storeu_si128((__m128i*)&out[i], v_packed_result);\n    }\n\n    // Handle remaining elements\n    for (; i < length; ++i) {\n        float diff = A[i] - B[i];\n        if (diff > epsilon) {\n            out[i] = 1;\n        } else if (diff < -epsilon) {\n            out[i] = -1;\n        } else {\n            out[i] = 0;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_50_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid float_to_int_saturate_simd(const float* A, int32_t* B, size_t size) {\n    const __m128 max_float = _mm_set1_ps((float)INT32_MAX);\n    const __m128 min_float = _mm_set1_ps((float)INT32_MIN);\n\n    size_t i = 0;\n    for (; i + 4 <= size; i += 4) {\n        // Load 4 floats from A\n        __m128 floats = _mm_loadu_ps(&A[i]);\n\n        // Clamp the values between INT32_MIN and INT32_MAX\n        floats = _mm_min_ps(floats, max_float);\n        floats = _mm_max_ps(floats, min_float);\n\n        // Convert the clamped floats to integers\n        __m128i ints = _mm_cvtps_epi32(floats);\n\n        // Store the result in B\n        _mm_storeu_si128((__m128i*)&B[i], ints);\n    }\n\n    // Handle any remaining elements\n    for (; i < size; ++i) {\n        float val = A[i];\n        if (val > (float)INT32_MAX) {\n            B[i] = INT32_MAX;\n        } else if (val < (float)INT32_MIN) {\n            B[i] = INT32_MIN;\n        } else {\n            B[i] = (int32_t)val;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_50_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid float_to_int_saturate_simd(const float* A, int32_t* B, size_t size) {\n    const __m128 max_float = _mm_set1_ps((float)INT32_MAX);\n    const __m128 min_float = _mm_set1_ps((float)INT32_MIN);\n\n    size_t i = 0;\n    for (; i + 4 <= size; i += 4) {\n        // Load 4 floats from A\n        __m128 floats = _mm_loadu_ps(&A[i]);\n\n        // Clamp the floats between INT32_MIN and INT32_MAX\n        floats = _mm_max_ps(_mm_min_ps(floats, max_float), min_float);\n\n        // Convert the clamped floats to integers\n        __m128i ints = _mm_cvtps_epi32(floats);\n\n        // Store the integers into B\n        _mm_storeu_si128((__m128i*)&B[i], ints);\n    }\n\n    // Handle any remaining elements\n    for (; i < size; ++i) {\n        float val = A[i];\n        if (val > (float)INT32_MAX) {\n            B[i] = INT32_MAX;\n        } else if (val < (float)INT32_MIN) {\n            B[i] = INT32_MIN;\n        } else {\n            B[i] = (int32_t)val;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_50_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid float_to_int_saturate_simd(const float* A, int32_t* B, size_t size) {\n    const __m128 max_float = _mm_set1_ps((float)INT32_MAX);\n    const __m128 min_float = _mm_set1_ps((float)INT32_MIN);\n\n    size_t i = 0;\n    for (; i + 4 <= size; i += 4) {\n        // Load 4 floats from A\n        __m128 floats = _mm_loadu_ps(&A[i]);\n\n        // Clamp the floats between INT32_MIN and INT32_MAX\n        floats = _mm_max_ps(_mm_min_ps(floats, max_float), min_float);\n\n        // Convert the clamped floats to integers\n        __m128i ints = _mm_cvtps_epi32(floats);\n\n        // Store the integers into B\n        _mm_storeu_si128((__m128i*)&B[i], ints);\n    }\n\n    // Handle any remaining elements\n    for (; i < size; ++i) {\n        float val = A[i];\n        if (val > (float)INT32_MAX) {\n            B[i] = INT32_MAX;\n        } else if (val < (float)INT32_MIN) {\n            B[i] = INT32_MIN;\n        } else {\n            B[i] = (int32_t)val;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_50_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid float_to_int_saturate_simd(const float* A, int32_t* B, size_t size) {\n    const __m128 max_float = _mm_set1_ps((float)INT32_MAX);\n    const __m128 min_float = _mm_set1_ps((float)INT32_MIN);\n\n    size_t i = 0;\n    for (; i + 4 <= size; i += 4) {\n        // Load 4 floats from A\n        __m128 floats = _mm_loadu_ps(&A[i]);\n\n        // Clamp the values between INT32_MIN and INT32_MAX\n        floats = _mm_min_ps(floats, max_float);\n        floats = _mm_max_ps(floats, min_float);\n\n        // Convert the clamped floats to integers\n        __m128i ints = _mm_cvtps_epi32(floats);\n\n        // Store the resulting integers into B\n        _mm_storeu_si128((__m128i*)&B[i], ints);\n    }\n\n    // Handle any remaining elements\n    for (; i < size; ++i) {\n        float val = A[i];\n        if (val > (float)INT32_MAX) {\n            B[i] = INT32_MAX;\n        } else if (val < (float)INT32_MIN) {\n            B[i] = INT32_MIN;\n        } else {\n            B[i] = (int32_t)val;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_50_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid float_to_int_saturate_simd(const float* A, int32_t* B, size_t size) {\n    const __m128 max_val = _mm_set1_ps((float)INT32_MAX);\n    const __m128 min_val = _mm_set1_ps((float)INT32_MIN);\n\n    size_t i = 0;\n    for (; i + 4 <= size; i += 4) {\n        // Load 4 floats from A\n        __m128 floats = _mm_loadu_ps(&A[i]);\n\n        // Clamp values between INT32_MIN and INT32_MAX\n        floats = _mm_max_ps(floats, min_val);\n        floats = _mm_min_ps(floats, max_val);\n\n        // Convert floats to integers with saturation\n        __m128i ints = _mm_cvtps_epi32(floats);\n\n        // Store the result into B\n        _mm_storeu_si128((__m128i*)&B[i], ints);\n    }\n\n    // Handle remaining elements\n    for (; i < size; ++i) {\n        float val = A[i];\n        if (val > (float)INT32_MAX) {\n            B[i] = INT32_MAX;\n        } else if (val < (float)INT32_MIN) {\n            B[i] = INT32_MIN;\n        } else {\n            B[i] = (int32_t)val;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_51_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid int_to_float_scaled_simd(const int32_t* A, int8_t scale, float* B, size_t size) {\n    __m128 scale_vec = _mm_set1_ps(static_cast<float>(scale));\n    size_t i = 0;\n\n    for (; i + 4 <= size; i += 4) {\n        __m128i int_vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&A[i]));\n        __m128 float_vec = _mm_cvtepi32_ps(int_vec);\n        float_vec = _mm_mul_ps(float_vec, scale_vec);\n        _mm_storeu_ps(&B[i], float_vec);\n    }\n\n    for (; i < size; ++i) {\n        B[i] = static_cast<float>(A[i]) * static_cast<float>(scale);\n    }\n}\n```"}
{"task_id": "SimdBench_51_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid int_to_float_scaled_simd(const int32_t* A, int8_t scale, float* B, size_t size) {\n    __m128 scale_vec = _mm_set1_ps(static_cast<float>(scale));\n    size_t i = 0;\n\n    for (; i + 4 <= size; i += 4) {\n        __m128i int_vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&A[i]));\n        __m128 float_vec = _mm_cvtepi32_ps(int_vec);\n        float_vec = _mm_mul_ps(float_vec, scale_vec);\n        _mm_storeu_ps(&B[i], float_vec);\n    }\n\n    for (; i < size; ++i) {\n        B[i] = static_cast<float>(A[i]) * static_cast<float>(scale);\n    }\n}\n```"}
{"task_id": "SimdBench_51_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid int_to_float_scaled_simd(const int32_t* A, int8_t scale, float* B, size_t size) {\n    __m128 scale_vec = _mm_set1_ps(static_cast<float>(scale));\n    size_t i = 0;\n\n    for (; i + 4 <= size; i += 4) {\n        __m128i int_vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&A[i]));\n        __m128 float_vec = _mm_cvtepi32_ps(int_vec);\n        float_vec = _mm_mul_ps(float_vec, scale_vec);\n        _mm_storeu_ps(&B[i], float_vec);\n    }\n\n    for (; i < size; ++i) {\n        B[i] = static_cast<float>(A[i]) * static_cast<float>(scale);\n    }\n}\n```"}
{"task_id": "SimdBench_51_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid int_to_float_scaled_simd(const int32_t* A, int8_t scale, float* B, size_t size) {\n    __m128 scale_vec = _mm_set1_ps(static_cast<float>(scale));\n    size_t i = 0;\n\n    for (; i + 4 <= size; i += 4) {\n        __m128i int_vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&A[i]));\n        __m128 float_vec = _mm_cvtepi32_ps(int_vec);\n        float_vec = _mm_mul_ps(float_vec, scale_vec);\n        _mm_storeu_ps(&B[i], float_vec);\n    }\n\n    for (; i < size; ++i) {\n        B[i] = static_cast<float>(A[i]) * static_cast<float>(scale);\n    }\n}\n```"}
{"task_id": "SimdBench_51_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid int_to_float_scaled_simd(const int32_t* A, int8_t scale, float* B, size_t size) {\n    __m128 scale_vec = _mm_set1_ps(static_cast<float>(scale));\n    size_t i = 0;\n\n    for (; i + 4 <= size; i += 4) {\n        __m128i int_vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&A[i]));\n        __m128 float_vec = _mm_cvtepi32_ps(int_vec);\n        float_vec = _mm_mul_ps(float_vec, scale_vec);\n        _mm_storeu_ps(&B[i], float_vec);\n    }\n\n    for (; i < size; ++i) {\n        B[i] = static_cast<float>(A[i]) * static_cast<float>(scale);\n    }\n}\n```"}
{"task_id": "SimdBench_52_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid float_div_round_simd(const float* A, const float* B, int32_t* C, size_t size) {\n    size_t i = 0;\n    __m128 one = _mm_set1_ps(0.5f); // For rounding purposes\n\n    // Process 4 elements at a time\n    for (; i + 4 <= size; i += 4) {\n        // Load 4 floats from A and B\n        __m128 a = _mm_loadu_ps(&A[i]);\n        __m128 b = _mm_loadu_ps(&B[i]);\n\n        // Perform division: a / b\n        __m128 div = _mm_div_ps(a, b);\n\n        // Add 0.5 for rounding to nearest integer\n        __m128 rounded = _mm_add_ps(div, one);\n\n        // Convert the result to integers using truncation\n        __m128i result = _mm_cvtps_epi32(rounded);\n\n        // Store the result into C\n        _mm_storeu_si128((__m128i*)&C[i], result);\n    }\n\n    // Handle remaining elements (if any)\n    for (; i < size; ++i) {\n        float div = A[i] / B[i];\n        C[i] = (int32_t)(div + (div >= 0 ? 0.5f : -0.5f));\n    }\n}\n```"}
{"task_id": "SimdBench_52_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid float_div_round_simd(const float* A, const float* B, int32_t* C, size_t size) {\n    size_t i = 0;\n    __m128 one = _mm_set1_ps(0.5f); // Used for rounding\n\n    // Process 4 elements at a time\n    for (; i + 4 <= size; i += 4) {\n        // Load 4 floats from A and B\n        __m128 a = _mm_loadu_ps(&A[i]);\n        __m128 b = _mm_loadu_ps(&B[i]);\n\n        // Perform division: a / b\n        __m128 div = _mm_div_ps(a, b);\n\n        // Add 0.5 for rounding to nearest integer\n        __m128 rounded = _mm_add_ps(div, one);\n\n        // Convert the result to integers using truncation\n        __m128i result = _mm_cvtps_epi32(rounded);\n\n        // Store the result in the destination array\n        _mm_storeu_si128((__m128i*)&C[i], result);\n    }\n\n    // Handle remaining elements (if any)\n    for (; i < size; ++i) {\n        float div = A[i] / B[i];\n        C[i] = (int32_t)(div + (div >= 0 ? 0.5f : -0.5f));\n    }\n}\n```"}
{"task_id": "SimdBench_52_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid float_div_round_simd(const float* A, const float* B, int32_t* C, size_t size) {\n    size_t i = 0;\n\n    // Process 4 elements at a time using SSE\n    for (; i + 4 <= size; i += 4) {\n        // Load 4 floats from A and B into SIMD registers\n        __m128 va = _mm_loadu_ps(&A[i]);\n        __m128 vb = _mm_loadu_ps(&B[i]);\n\n        // Perform element-wise division\n        __m128 vdiv = _mm_div_ps(va, vb);\n\n        // Round the result to the nearest integer\n        __m128 vround = _mm_round_ps(vdiv, _MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC);\n\n        // Convert the rounded floats to 32-bit integers\n        __m128i vint = _mm_cvtps_epi32(vround);\n\n        // Store the resulting integers into the destination array\n        _mm_storeu_si128((__m128i*)&C[i], vint);\n    }\n\n    // Handle remaining elements (if any) with scalar code\n    for (; i < size; ++i) {\n        C[i] = (int32_t)lrintf(A[i] / B[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_52_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid float_div_round_simd(const float* A, const float* B, int32_t* C, size_t size) {\n    size_t i = 0;\n    __m128 one = _mm_set1_ps(0.5f); // For rounding\n\n    for (; i + 4 <= size; i += 4) {\n        // Load 4 floats from A and B\n        __m128 a = _mm_loadu_ps(&A[i]);\n        __m128 b = _mm_loadu_ps(&B[i]);\n\n        // Perform division: a / b\n        __m128 div = _mm_div_ps(a, b);\n\n        // Add 0.5 for rounding to nearest integer\n        __m128 rounded = _mm_add_ps(div, one);\n\n        // Convert the result to integers using truncation\n        __m128i result = _mm_cvtps_epi32(rounded);\n\n        // Store the result into the destination array C\n        _mm_storeu_si128((__m128i*)&C[i], result);\n    }\n\n    // Handle remaining elements\n    for (; i < size; ++i) {\n        C[i] = (int32_t)(A[i] / B[i] + 0.5f);\n    }\n}\n```"}
{"task_id": "SimdBench_52_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid float_div_round_simd(const float* A, const float* B, int32_t* C, size_t size) {\n    size_t i = 0;\n    \n    // Process 4 elements at a time using SSE\n    for (; i + 4 <= size; i += 4) {\n        // Load 4 floats from A and B\n        __m128 vecA = _mm_loadu_ps(&A[i]);\n        __m128 vecB = _mm_loadu_ps(&B[i]);\n\n        // Perform division: vecA / vecB\n        __m128 divResult = _mm_div_ps(vecA, vecB);\n\n        // Round to nearest integer (convert PS to PI)\n        __m128i roundedResult = _mm_cvtps_epi32(divResult);\n\n        // Store the result into the destination array C\n        _mm_storeu_si128((__m128i*)&C[i], roundedResult);\n    }\n\n    // Handle remaining elements (if any)\n    for (; i < size; ++i) {\n        C[i] = (int32_t)lrintf(A[i] / B[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_53_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid double_to_float_saturate_simd(const double* A, float* B, size_t size) {\n    const __m128d FLT_MAX_VEC = _mm_set1_pd(FLT_MAX);\n    const __m128d NEG_FLT_MAX_VEC = _mm_set1_pd(-FLT_MAX);\n    const __m128 FLT_MAX_FVEC = _mm_set1_ps(FLT_MAX);\n    const __m128 NEG_FLT_MAX_FVEC = _mm_set1_ps(-FLT_MAX);\n\n    size_t i = 0;\n    for (; i + 2 <= size; i += 2) {\n        // Load two doubles from A\n        __m128d a = _mm_loadu_pd(&A[i]);\n\n        // Compare and clamp values to [-FLT_MAX, FLT_MAX]\n        __m128d clamped_low = _mm_max_pd(a, NEG_FLT_MAX_VEC);\n        __m128d clamped = _mm_min_pd(clamped_low, FLT_MAX_VEC);\n\n        // Convert the clamped doubles to floats\n        __m128 converted = _mm_cvtpd_ps(clamped);\n\n        // Store the resulting floats into B\n        _mm_storeu_ps(&B[i], converted);\n    }\n\n    // Handle remaining elements (if size is odd)\n    if (i < size) {\n        double val = A[i];\n        if (val > FLT_MAX) {\n            val = FLT_MAX;\n        } else if (val < -FLT_MAX) {\n            val = -FLT_MAX;\n        }\n        B[i] = (float)val;\n    }\n}\n```"}
{"task_id": "SimdBench_53_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid double_to_float_saturate_simd(const double* A, float* B, size_t size) {\n    const __m128d vmax = _mm_set1_pd(FLT_MAX);\n    const __m128d vmin = _mm_set1_pd(-FLT_MAX);\n\n    size_t i = 0;\n    for (; i + 2 <= size; i += 2) {\n        // Load two doubles from A\n        __m128d v = _mm_loadu_pd(&A[i]);\n\n        // Clamp values between -FLT_MAX and FLT_MAX\n        v = _mm_min_pd(v, vmax);\n        v = _mm_max_pd(v, vmin);\n\n        // Convert the clamped doubles to floats\n        __m128 vf = _mm_cvtpd_ps(v);\n\n        // Store the resulting floats into B\n        _mm_storel_pi((__m64*)&B[i], vf);\n    }\n\n    // Handle any remaining elements\n    for (; i < size; ++i) {\n        double val = A[i];\n        if (val > FLT_MAX) {\n            val = FLT_MAX;\n        } else if (val < -FLT_MAX) {\n            val = -FLT_MAX;\n        }\n        B[i] = (float)val;\n    }\n}\n```"}
{"task_id": "SimdBench_53_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid double_to_float_saturate_simd(const double* A, float* B, size_t size) {\n    const __m128d max_val = _mm_set1_pd(FLT_MAX);\n    const __m128d min_val = _mm_set1_pd(-FLT_MAX);\n\n    size_t i = 0;\n    for (; i + 2 <= size; i += 2) {\n        // Load two doubles from A\n        __m128d a = _mm_loadu_pd(&A[i]);\n\n        // Clamp values to [-FLT_MAX, FLT_MAX]\n        __m128d clamped = _mm_min_pd(_mm_max_pd(a, min_val), max_val);\n\n        // Convert the clamped doubles to floats\n        __m128 converted = _mm_cvtpd_ps(clamped);\n\n        // Store the resulting floats into B\n        _mm_storeu_ps(&B[i], converted);\n    }\n\n    // Handle any remaining elements\n    for (; i < size; ++i) {\n        double val = A[i];\n        if (val > FLT_MAX) {\n            val = FLT_MAX;\n        } else if (val < -FLT_MAX) {\n            val = -FLT_MAX;\n        }\n        B[i] = (float)val;\n    }\n}\n```"}
{"task_id": "SimdBench_53_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid double_to_float_saturate_simd(const double* A, float* B, size_t size) {\n    const __m128d max_val = _mm_set1_pd(FLT_MAX);\n    const __m128d min_val = _mm_set1_pd(-FLT_MAX);\n\n    size_t i = 0;\n    for (; i + 2 <= size; i += 2) {\n        // Load two doubles from A\n        __m128d a = _mm_loadu_pd(&A[i]);\n\n        // Clamp values between -FLT_MAX and FLT_MAX\n        __m128d clamped = _mm_min_pd(_mm_max_pd(a, min_val), max_val);\n\n        // Convert the clamped doubles to floats\n        __m128 converted = _mm_cvtpd_ps(clamped);\n\n        // Store the resulting floats into B\n        _mm_storeu_ps(&B[i], converted);\n    }\n\n    // Handle any remaining elements\n    for (; i < size; ++i) {\n        double val = A[i];\n        if (val > FLT_MAX) {\n            val = FLT_MAX;\n        } else if (val < -FLT_MAX) {\n            val = -FLT_MAX;\n        }\n        B[i] = static_cast<float>(val);\n    }\n}\n```"}
{"task_id": "SimdBench_53_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid double_to_float_saturate_simd(const double* A, float* B, size_t size) {\n    const __m128d FLT_MAX_VEC = _mm_set1_pd(FLT_MAX);\n    const __m128d FLT_MIN_VEC = _mm_set1_pd(-FLT_MAX);\n    const __m128 FLT_MAX_FVEC = _mm_set1_ps(FLT_MAX);\n    const __m128 FLT_MIN_FVEC = _mm_set1_ps(-FLT_MAX);\n\n    size_t i = 0;\n    for (; i + 2 <= size; i += 2) {\n        // Load two doubles from A\n        __m128d a = _mm_loadu_pd(&A[i]);\n\n        // Compare and clamp values to [-FLT_MAX, FLT_MAX]\n        __m128d clamped_low = _mm_max_pd(a, FLT_MIN_VEC);\n        __m128d clamped = _mm_min_pd(clamped_low, FLT_MAX_VEC);\n\n        // Convert the clamped doubles to floats\n        __m128 converted = _mm_cvtpd_ps(clamped);\n\n        // Store the resulting floats into B\n        _mm_storeu_ps(&B[i], converted);\n    }\n\n    // Handle remaining elements (if size is odd)\n    if (i < size) {\n        double val = A[i];\n        if (val > FLT_MAX) val = FLT_MAX;\n        else if (val < -FLT_MAX) val = -FLT_MAX;\n        B[i] = (float)val;\n    }\n}\n```"}
{"task_id": "SimdBench_54_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n\nvoid int16_to_int32_simd(const int16_t* A, int32_t* B, size_t size) {\n    size_t i = 0;\n\n    // Process 8 elements at a time using SSE2\n    for (; i + 8 <= size; i += 8) {\n        // Load 8 int16_t values from A\n        __m128i vec = _mm_loadu_si128((__m128i*)&A[i]);\n\n        // Convert the 8 int16_t values to 8 int32_t values\n        __m128i vec_low = _mm_cvtepi16_epi32(vec);          // Convert lower 4 values\n        __m128i vec_high = _mm_cvtepi16_epi32(_mm_srli_si128(vec, 8)); // Convert upper 4 values\n\n        // Store the 8 int32_t values into B\n        _mm_storeu_si128((__m128i*)&B[i * 2], vec_low);\n        _mm_storeu_si128((__m128i*)&B[i * 2 + 4], vec_high);\n    }\n\n    // Handle remaining elements (if any)\n    for (; i < size; ++i) {\n        B[i] = static_cast<int32_t>(A[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_54_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid int16_to_int32_simd(const int16_t* A, int32_t* B, size_t size) {\n    size_t i = 0;\n\n    // Process 8 elements at a time using SSE2\n    for (; i + 8 <= size; i += 8) {\n        // Load 8 int16_t values from A\n        __m128i vec = _mm_loadu_si128((__m128i*)&A[i]);\n\n        // Convert 8 int16_t values to 8 int32_t values\n        __m128i vec_low = _mm_cvtepi16_epi32(vec);         // Convert lower 4 values\n        __m128i vec_high = _mm_cvtepi16_epi32(_mm_srli_si128(vec, 8)); // Convert upper 4 values\n\n        // Store the 8 int32_t values into B\n        _mm_storeu_si128((__m128i*)&B[i * 2], vec_low);\n        _mm_storeu_si128((__m128i*)&B[i * 2 + 4], vec_high);\n    }\n\n    // Handle remaining elements (if any)\n    for (; i < size; ++i) {\n        B[i] = static_cast<int32_t>(A[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_54_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n\nvoid int16_to_int32_simd(const int16_t* A, int32_t* B, size_t size) {\n    size_t i = 0;\n\n    // Process 8 elements at a time using SSE2\n    for (; i + 8 <= size; i += 8) {\n        // Load 8 int16_t values from A\n        __m128i vec = _mm_loadu_si128((__m128i*)&A[i]);\n\n        // Convert the 8 int16_t values to 8 int32_t values\n        __m128i vec_lo = _mm_cvtepi16_epi32(vec);          // Convert lower 4 values\n        __m128i vec_hi = _mm_cvtepi16_epi32(_mm_srli_si128(vec, 8)); // Convert upper 4 values\n\n        // Store the 8 int32_t values into B\n        _mm_storeu_si128((__m128i*)&B[i * 2], vec_lo);\n        _mm_storeu_si128((__m128i*)&B[i * 2 + 4], vec_hi);\n    }\n\n    // Handle remaining elements (if any)\n    for (; i < size; ++i) {\n        B[i] = static_cast<int32_t>(A[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_54_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid int16_to_int32_simd(const int16_t* A, int32_t* B, size_t size) {\n    size_t i = 0;\n\n    // Process 8 elements at a time using SSE2 intrinsics\n    for (; i + 8 <= size; i += 8) {\n        // Load 8 int16_t values from A into an XMM register\n        __m128i v = _mm_loadu_si128((__m128i*)&A[i]);\n\n        // Convert the 8 int16_t values to 8 int32_t values\n        __m128i lo = _mm_cvtepi16_epi32(v);          // Convert lower 4 values\n        __m128i hi = _mm_cvtepi16_epi32(_mm_srli_si128(v, 8)); // Convert upper 4 values\n\n        // Store the 8 int32_t values into B\n        _mm_storeu_si128((__m128i*)&B[i * 2], lo);\n        _mm_storeu_si128((__m128i*)&B[i * 2 + 4], hi);\n    }\n\n    // Handle any remaining elements\n    for (; i < size; ++i) {\n        B[i] = static_cast<int32_t>(A[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_54_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n\nvoid int16_to_int32_simd(const int16_t* A, int32_t* B, size_t size) {\n    size_t i = 0;\n\n    // Process 8 elements at a time using SSE2\n    for (; i + 8 <= size; i += 8) {\n        // Load 8 int16_t values from A\n        __m128i vec = _mm_loadu_si128((__m128i const*)(A + i));\n\n        // Convert the 8 int16_t values to 8 int32_t values\n        __m128i vec_low = _mm_cvtepi16_epi32(vec);          // Convert lower 4 values\n        __m128i vec_high = _mm_cvtepi16_epi32(_mm_srli_si128(vec, 8)); // Convert upper 4 values\n\n        // Store the 8 int32_t values into B\n        _mm_storeu_si128((__m128i*)(B + i), vec_low);\n        _mm_storeu_si128((__m128i*)(B + i + 4), vec_high);\n    }\n\n    // Handle remaining elements (if any)\n    for (; i < size; ++i) {\n        B[i] = static_cast<int32_t>(A[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_55_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n\nvoid conditional_normalize_simd(const float* A, const int32_t* control, float* B, size_t size, float min_val, float max_val) {\n    __m128 min_vec = _mm_set1_ps(min_val);\n    __m128 max_vec = _mm_set1_ps(max_val);\n    __m128 range_vec = _mm_sub_ps(max_vec, min_vec);\n    __m128 zero_vec = _mm_setzero_ps();\n    __m128 one_vec = _mm_set1_ps(1.0f);\n\n    for (size_t i = 0; i + 4 <= size; i += 4) {\n        // Load 4 floats from A and control\n        __m128 a_vec = _mm_loadu_ps(&A[i]);\n        __m128i ctrl_vec = _mm_loadu_si128((__m128i*)&control[i]);\n\n        // Check if control values are greater than 0\n        __m128 ctrl_gt_zero = _mm_castsi128_ps(_mm_cmpgt_epi32(ctrl_vec, _mm_setzero_si128()));\n\n        // Normalize: (A[i] - min_val) / (max_val - min_val)\n        __m128 norm_val = _mm_sub_ps(a_vec, min_vec);\n        norm_val = _mm_div_ps(norm_val, range_vec);\n\n        // Clamp normalized values between 0 and 1\n        norm_val = _mm_max_ps(norm_val, zero_vec);\n        norm_val = _mm_min_ps(norm_val, one_vec);\n\n        // Blend based on control > 0\n        __m128 result = _mm_blendv_ps(a_vec, norm_val, ctrl_gt_zero);\n\n        // Store the result into B\n        _mm_storeu_ps(&B[i], result);\n    }\n\n    // Handle remaining elements\n    for (size_t i = (size / 4) * 4; i < size; ++i) {\n        if (control[i] > 0) {\n            float val = (A[i] - min_val) / (max_val - min_val);\n            val = (val < 0.0f) ? 0.0f : ((val > 1.0f) ? 1.0f : val);\n            B[i] = val;\n        } else {\n            B[i] = A[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_55_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n\nvoid conditional_normalize_simd(const float* A, const int32_t* control, float* B, size_t size, float min_val, float max_val) {\n    __m128 min_vec = _mm_set1_ps(min_val);\n    __m128 max_vec = _mm_set1_ps(max_val);\n    __m128 range_vec = _mm_sub_ps(max_vec, min_vec);\n    __m128 zero_vec = _mm_setzero_ps();\n    __m128 one_vec = _mm_set1_ps(1.0f);\n\n    for (size_t i = 0; i + 4 <= size; i += 4) {\n        // Load 4 floats from A and control\n        __m128 a_vec = _mm_loadu_ps(&A[i]);\n        __m128i ctrl_vec = _mm_loadu_si128((__m128i*)&control[i]);\n\n        // Check if control values are greater than 0\n        __m128 ctrl_gt_zero = _mm_castsi128_ps(_mm_cmpgt_epi32(ctrl_vec, _mm_setzero_si128()));\n\n        // Normalize: (A[i] - min_val) / (max_val - min_val)\n        __m128 norm_vec = _mm_sub_ps(a_vec, min_vec);\n        norm_vec = _mm_div_ps(norm_vec, range_vec);\n\n        // Clamp normalized values between 0 and 1\n        norm_vec = _mm_max_ps(norm_vec, zero_vec);\n        norm_vec = _mm_min_ps(norm_vec, one_vec);\n\n        // Blend based on control > 0\n        __m128 result = _mm_blendv_ps(a_vec, norm_vec, ctrl_gt_zero);\n\n        // Store the result into B\n        _mm_storeu_ps(&B[i], result);\n    }\n\n    // Handle remaining elements\n    for (size_t i = (size / 4) * 4; i < size; ++i) {\n        if (control[i] > 0) {\n            float val = (A[i] - min_val) / (max_val - min_val);\n            val = (val < 0.0f) ? 0.0f : ((val > 1.0f) ? 1.0f : val);\n            B[i] = val;\n        } else {\n            B[i] = A[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_55_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n\nvoid conditional_normalize_simd(const float* A, const int32_t* control, float* B, size_t size, float min_val, float max_val) {\n    __m128 min_v = _mm_set1_ps(min_val);\n    __m128 max_v = _mm_set1_ps(max_val);\n    __m128 range_v = _mm_sub_ps(max_v, min_v);\n    __m128 zero_v = _mm_setzero_ps();\n    __m128 one_v = _mm_set1_ps(1.0f);\n\n    for (size_t i = 0; i + 4 <= size; i += 4) {\n        // Load 4 floats from A and control\n        __m128 a_v = _mm_loadu_ps(&A[i]);\n        __m128i ctrl_v = _mm_loadu_si128((__m128i*)&control[i]);\n\n        // Check if control values are greater than 0\n        __m128 ctrl_gt_zero = _mm_castsi128_ps(_mm_cmpgt_epi32(ctrl_v, _mm_setzero_si128()));\n\n        // Normalize: (A[i] - min_val) / (max_val - min_val)\n        __m128 norm_v = _mm_sub_ps(a_v, min_v);\n        norm_v = _mm_div_ps(norm_v, range_v);\n\n        // Clamp normalized values between 0 and 1\n        norm_v = _mm_max_ps(norm_v, zero_v);\n        norm_v = _mm_min_ps(norm_v, one_v);\n\n        // Select between normalized values and original values based on control\n        __m128 result_v = _mm_blendv_ps(a_v, norm_v, ctrl_gt_zero);\n\n        // Store the result into B\n        _mm_storeu_ps(&B[i], result_v);\n    }\n\n    // Handle remaining elements\n    for (size_t i = (size / 4) * 4; i < size; ++i) {\n        if (control[i] > 0) {\n            float val = (A[i] - min_val) / (max_val - min_val);\n            val = (val < 0.0f) ? 0.0f : ((val > 1.0f) ? 1.0f : val);\n            B[i] = val;\n        } else {\n            B[i] = A[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_55_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n\nvoid conditional_normalize_simd(const float* A, const int32_t* control, float* B, size_t size, float min_val, float max_val) {\n    __m128 min_vec = _mm_set1_ps(min_val);\n    __m128 max_vec = _mm_set1_ps(max_val);\n    __m128 range_vec = _mm_sub_ps(max_vec, min_vec);\n    __m128 zero_vec = _mm_setzero_ps();\n    __m128 one_vec = _mm_set1_ps(1.0f);\n\n    for (size_t i = 0; i + 4 <= size; i += 4) {\n        // Load 4 floats from A and control arrays\n        __m128 a_vec = _mm_loadu_ps(&A[i]);\n        __m128i control_vec = _mm_loadu_si128((__m128i*)&control[i]);\n\n        // Check if control values are greater than 0\n        __m128 control_gt_zero = _mm_castsi128_ps(_mm_cmpgt_epi32(control_vec, _mm_setzero_si128()));\n\n        // Normalize A values: (A[i] - min_val) / (max_val - min_val)\n        __m128 normalized = _mm_sub_ps(a_vec, min_vec);\n        normalized = _mm_div_ps(normalized, range_vec);\n\n        // Clamp normalized values between 0 and 1\n        normalized = _mm_max_ps(normalized, zero_vec);\n        normalized = _mm_min_ps(normalized, one_vec);\n\n        // Select between normalized values and original A values based on control\n        __m128 result = _mm_blendv_ps(a_vec, normalized, control_gt_zero);\n\n        // Store the result into B\n        _mm_storeu_ps(&B[i], result);\n    }\n\n    // Handle remaining elements\n    for (size_t i = (size / 4) * 4; i < size; ++i) {\n        if (control[i] > 0) {\n            float val = (A[i] - min_val) / (max_val - min_val);\n            val = (val < 0.0f) ? 0.0f : ((val > 1.0f) ? 1.0f : val);\n            B[i] = val;\n        } else {\n            B[i] = A[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_55_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n\nvoid conditional_normalize_simd(const float* A, const int32_t* control, float* B, size_t size, float min_val, float max_val) {\n    __m128 min_val_vec = _mm_set1_ps(min_val);\n    __m128 max_val_vec = _mm_set1_ps(max_val);\n    __m128 range_vec = _mm_sub_ps(max_val_vec, min_val_vec);\n    __m128 zero_vec = _mm_setzero_ps();\n    __m128 one_vec = _mm_set1_ps(1.0f);\n\n    for (size_t i = 0; i + 4 <= size; i += 4) {\n        // Load 4 floats from A and control\n        __m128 a_vec = _mm_loadu_ps(&A[i]);\n        __m128i control_vec = _mm_loadu_si128((__m128i*)&control[i]);\n\n        // Check if control values are greater than 0\n        __m128 control_gt_zero = _mm_castsi128_ps(_mm_cmpgt_epi32(control_vec, _mm_setzero_si128()));\n\n        // Normalize: (A[i] - min_val) / (max_val - min_val)\n        __m128 normalized = _mm_sub_ps(a_vec, min_val_vec);\n        normalized = _mm_div_ps(normalized, range_vec);\n\n        // Clamp the normalized values between 0 and 1\n        normalized = _mm_max_ps(normalized, zero_vec);\n        normalized = _mm_min_ps(normalized, one_vec);\n\n        // Blend based on control > 0\n        __m128 result = _mm_blendv_ps(a_vec, normalized, control_gt_zero);\n\n        // Store the result into B\n        _mm_storeu_ps(&B[i], result);\n    }\n\n    // Handle remaining elements\n    for (size_t i = (size / 4) * 4; i < size; ++i) {\n        if (control[i] > 0) {\n            float val = (A[i] - min_val) / (max_val - min_val);\n            val = (val < 0.0f) ? 0.0f : ((val > 1.0f) ? 1.0f : val);\n            B[i] = val;\n        } else {\n            B[i] = A[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_56_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n\nvoid int_to_float_sqrt_simd(const uint32_t* A, float* B, size_t size) {\n    size_t i = 0;\n    \n    // Process 4 elements at a time using SSE\n    for (; i + 4 <= size; i += 4) {\n        // Load 4 uint32_t values from A\n        __m128i vecA = _mm_loadu_si128((__m128i const*)(A + i));\n        \n        // Shift right by 16 bits to extract the high 16 bits of each uint32_t\n        __m128i shifted = _mm_srli_epi32(vecA, 16);\n        \n        // Convert the resulting 32-bit integers to floating-point numbers\n        __m128 vecB = _mm_cvtepi32_ps(shifted);\n        \n        // Compute the square root of the floating-point numbers\n        vecB = _mm_sqrt_ps(vecB);\n        \n        // Store the result in B\n        _mm_storeu_ps(B + i, vecB);\n    }\n    \n    // Handle any remaining elements\n    for (; i < size; ++i) {\n        uint32_t value = A[i];\n        float result = sqrtf(static_cast<float>(value >> 16));\n        B[i] = result;\n    }\n}\n```"}
{"task_id": "SimdBench_56_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n\nvoid int_to_float_sqrt_simd(const uint32_t* A, float* B, size_t size) {\n    size_t i = 0;\n    __m128i mask = _mm_set1_epi32(0xFFFF0000); // Mask to extract high 16 bits\n\n    for (; i + 4 <= size; i += 4) {\n        // Load 4 uint32_t values from A\n        __m128i input = _mm_loadu_si128((__m128i*)&A[i]);\n\n        // Extract the high 16 bits of each uint32_t\n        __m128i high_bits = _mm_and_si128(input, mask);\n\n        // Shift right by 16 to get the high 16 bits as 32-bit integers\n        __m128i shifted = _mm_srli_epi32(high_bits, 16);\n\n        // Convert the 32-bit integers to floats\n        __m128 floats = _mm_cvtepi32_ps(shifted);\n\n        // Compute the square root of the floats\n        __m128 sqrt_result = _mm_sqrt_ps(floats);\n\n        // Store the result in B\n        _mm_storeu_ps(&B[i], sqrt_result);\n    }\n\n    // Handle remaining elements\n    for (; i < size; ++i) {\n        uint32_t high_bits = (A[i] >> 16) & 0xFFFF;\n        float value = static_cast<float>(high_bits);\n        B[i] = sqrtf(value);\n    }\n}\n```"}
{"task_id": "SimdBench_56_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid int_to_float_sqrt_simd(const uint32_t* A, float* B, size_t size) {\n    size_t i = 0;\n    __m128i mask = _mm_set1_epi32(0xFFFF0000); // Mask to extract high 16 bits\n\n    for (; i + 4 <= size; i += 4) {\n        // Load 4 uint32_t values from A\n        __m128i input = _mm_loadu_si128((__m128i*)&A[i]);\n\n        // Extract the high 16 bits of each uint32_t\n        __m128i high_bits = _mm_and_si128(input, mask);\n        __m128i shifted = _mm_srli_epi32(high_bits, 16);\n\n        // Convert the high 16 bits to float\n        __m128 floats = _mm_cvtepi32_ps(shifted);\n\n        // Compute the square root of the float values\n        __m128 sqrt_result = _mm_sqrt_ps(floats);\n\n        // Store the result in B\n        _mm_storeu_ps(&B[i], sqrt_result);\n    }\n\n    // Handle remaining elements\n    for (; i < size; ++i) {\n        uint32_t high_bits = (A[i] >> 16) & 0xFFFF;\n        float value = static_cast<float>(high_bits);\n        B[i] = sqrtf(value);\n    }\n}\n```"}
{"task_id": "SimdBench_56_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid int_to_float_sqrt_simd(const uint32_t* A, float* B, size_t size) {\n    size_t i = 0;\n    __m128i mask = _mm_set1_epi32(0xFFFF0000); // Mask to extract high 16 bits\n\n    for (; i + 4 <= size; i += 4) {\n        // Load 4 uint32_t values from A\n        __m128i input = _mm_loadu_si128((__m128i*)&A[i]);\n\n        // Extract the high 16 bits of each uint32_t\n        __m128i high_bits = _mm_and_si128(input, mask);\n        __m128i shifted = _mm_srli_epi32(high_bits, 16);\n\n        // Convert the high 16 bits to float\n        __m128 float_vals = _mm_cvtepi32_ps(shifted);\n\n        // Compute square root of the float values\n        __m128 sqrt_vals = _mm_sqrt_ps(float_vals);\n\n        // Store the results in B\n        _mm_storeu_ps(&B[i], sqrt_vals);\n    }\n\n    // Handle remaining elements\n    for (; i < size; ++i) {\n        uint32_t high_bits = (A[i] >> 16) & 0xFFFF;\n        float float_val = (float)high_bits;\n        B[i] = sqrtf(float_val);\n    }\n}\n```"}
{"task_id": "SimdBench_56_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n\nvoid int_to_float_sqrt_simd(const uint32_t* A, float* B, size_t size) {\n    size_t i = 0;\n    __m128i mask = _mm_set1_epi32(0xFFFF0000); // Mask to extract high 16 bits\n\n    for (; i + 4 <= size; i += 4) {\n        // Load 4 uint32_t values from A\n        __m128i input = _mm_loadu_si128((__m128i*)&A[i]);\n\n        // Extract the high 16 bits of each uint32_t\n        __m128i high_bits = _mm_and_si128(input, mask);\n        __m128i shifted = _mm_srli_epi32(high_bits, 16);\n\n        // Convert the high 16 bits to float\n        __m128 float_vals = _mm_cvtepi32_ps(shifted);\n\n        // Compute the square root of the float values\n        __m128 sqrt_vals = _mm_sqrt_ps(float_vals);\n\n        // Store the results in B\n        _mm_storeu_ps(&B[i], sqrt_vals);\n    }\n\n    // Handle remaining elements\n    for (; i < size; ++i) {\n        uint32_t high_bits = (A[i] >> 16) & 0xFFFF;\n        float float_val = (float)high_bits;\n        B[i] = sqrtf(float_val);\n    }\n}\n```"}
{"task_id": "SimdBench_57_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n\nvoid int_bits_to_float_simd(const uint32_t* A, float* B, size_t size) {\n    size_t i = 0;\n\n    // Process 4 elements at a time using SSE\n    for (; i + 4 <= size; i += 4) {\n        // Load 4 uint32_t values from A\n        __m128i int_vec = _mm_loadu_si128((__m128i const*)(A + i));\n\n        // Reinterpret the bits as floats (type punning)\n        __m128 float_vec = _mm_castsi128_ps(int_vec);\n\n        // Store the resulting floats into B\n        _mm_storeu_ps(B + i, float_vec);\n    }\n\n    // Handle any remaining elements\n    for (; i < size; ++i) {\n        B[i] = *(float*)&A[i];\n    }\n}\n```"}
{"task_id": "SimdBench_57_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n\nvoid int_bits_to_float_simd(const uint32_t* A, float* B, size_t size) {\n    size_t i = 0;\n\n    // Process 4 elements at a time using SSE\n    for (; i + 4 <= size; i += 4) {\n        // Load 4 uint32_t values from A as integers\n        __m128i int_vec = _mm_loadu_si128((__m128i*)&A[i]);\n\n        // Reinterpret the integer bits as floating-point values\n        __m128 float_vec = _mm_castsi128_ps(int_vec);\n\n        // Store the resulting floats into B\n        _mm_storeu_ps(&B[i], float_vec);\n    }\n\n    // Handle any remaining elements\n    for (; i < size; ++i) {\n        B[i] = *(float*)&A[i];\n    }\n}\n```"}
{"task_id": "SimdBench_57_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n\nvoid int_bits_to_float_simd(const uint32_t* A, float* B, size_t size) {\n    size_t i = 0;\n\n    // Process 4 elements at a time using SSE\n    for (; i + 4 <= size; i += 4) {\n        // Load 4 uint32_t values from A as integers\n        __m128i int_vec = _mm_loadu_si128((__m128i const*)(A + i));\n\n        // Reinterpret the integer bits as floating-point values\n        __m128 float_vec = _mm_castsi128_ps(int_vec);\n\n        // Store the resulting floats into B\n        _mm_storeu_ps(B + i, float_vec);\n    }\n\n    // Handle any remaining elements (less than 4)\n    for (; i < size; ++i) {\n        B[i] = *(float*)&A[i];\n    }\n}\n```"}
{"task_id": "SimdBench_57_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n\nvoid int_bits_to_float_simd(const uint32_t* A, float* B, size_t size) {\n    size_t i = 0;\n\n    // Process 4 elements at a time using SSE\n    for (; i + 4 <= size; i += 4) {\n        // Load 4 uint32_t values from A as integers\n        __m128i int_vec = _mm_loadu_si128((__m128i const*)(A + i));\n\n        // Reinterpret the bits of the integers as floats\n        __m128 float_vec = _mm_castsi128_ps(int_vec);\n\n        // Store the resulting floats into B\n        _mm_storeu_ps(B + i, float_vec);\n    }\n\n    // Handle any remaining elements\n    for (; i < size; ++i) {\n        B[i] = *(float*)&A[i];\n    }\n}\n```"}
{"task_id": "SimdBench_57_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n\nvoid int_bits_to_float_simd(const uint32_t* A, float* B, size_t size) {\n    size_t i = 0;\n\n    // Process 4 elements at a time using SSE\n    for (; i + 4 <= size; i += 4) {\n        // Load 4 uint32_t values from A\n        __m128i int_vec = _mm_loadu_si128((__m128i const*)(A + i));\n\n        // Reinterpret the bits as floats (no conversion)\n        __m128 float_vec = _mm_castsi128_ps(int_vec);\n\n        // Store the resulting floats into B\n        _mm_storeu_ps(B + i, float_vec);\n    }\n\n    // Handle remaining elements (if any)\n    for (; i < size; ++i) {\n        B[i] = *(float*)&A[i];\n    }\n}\n```"}
{"task_id": "SimdBench_58_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n\nvoid conditional_diff_simd(const int32_t* A, const bool* cond, float* diff, size_t size) {\n    // Set the first element of diff to 0.0f\n    diff[0] = 0.0f;\n\n    // Process elements in chunks of 4 using SSE/SSE2 intrinsics\n    size_t i = 1;\n    for (; i + 3 < size; i += 4) {\n        // Load 4 consecutive elements from A starting from A[i]\n        __m128i a_current = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i a_prev = _mm_loadu_si128((__m128i*)&A[i - 1]);\n\n        // Compute differences: A[i] - A[i-1]\n        __m128i diffs = _mm_sub_epi32(a_current, a_prev);\n\n        // Convert differences to float\n        __m128 diffs_float = _mm_cvtepi32_ps(diffs);\n\n        // Load 4 boolean conditions\n        __m128i cond_mask = _mm_loadu_si128((__m128i*)&cond[i]);\n        __m128 mask = _mm_castsi128_ps(_mm_and_si128(cond_mask, _mm_set1_epi32(0xFF)));\n\n        // Blend: Use mask to set diff[i] to 0.0f where cond[i] is false\n        __m128 zero = _mm_setzero_ps();\n        __m128 result = _mm_blendv_ps(zero, diffs_float, mask);\n\n        // Store the result into diff array\n        _mm_storeu_ps(&diff[i], result);\n    }\n\n    // Handle remaining elements (if any) with scalar code\n    for (; i < size; ++i) {\n        if (cond[i]) {\n            diff[i] = static_cast<float>(A[i] - A[i - 1]);\n        } else {\n            diff[i] = 0.0f;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_58_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid conditional_diff_simd(const int32_t* A, const bool* cond, float* diff, size_t size) {\n    // Ensure the first element is always 0.0f\n    diff[0] = 0.0f;\n\n    // Process elements in chunks of 4 using SSE/SSE2 intrinsics\n    size_t i = 1;\n    for (; i + 3 < size; i += 4) {\n        // Load 4 integers from A starting at index i and i-1\n        __m128i current = _mm_loadu_si128((__m128i*)(A + i));\n        __m128i previous = _mm_loadu_si128((__m128i*)(A + i - 1));\n\n        // Compute differences: current - previous\n        __m128i diffs = _mm_sub_epi32(current, previous);\n\n        // Load 4 boolean conditions\n        __m128i condition = _mm_cvtepi8_epi32(_mm_loadu_si128((__m128i*)(cond + i)));\n\n        // Convert boolean condition to mask (0xFFFFFFFF for true, 0x0 for false)\n        __m128i mask = _mm_cmpeq_epi32(condition, _mm_set1_epi32(1));\n\n        // Apply mask to differences: set to 0 where condition is false\n        diffs = _mm_and_si128(diffs, mask);\n\n        // Convert the resulting integer differences to floats\n        __m128 float_diffs = _mm_cvtepi32_ps(diffs);\n\n        // Store the resulting floats into the diff array\n        _mm_storeu_ps(diff + i, float_diffs);\n    }\n\n    // Handle remaining elements (if any) with scalar code\n    for (; i < size; ++i) {\n        if (cond[i]) {\n            diff[i] = static_cast<float>(A[i] - A[i - 1]);\n        } else {\n            diff[i] = 0.0f;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_58_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n\nvoid conditional_diff_simd(const int32_t* A, const bool* cond, float* diff, size_t size) {\n    // Set the first element of diff to 0.0f\n    diff[0] = 0.0f;\n\n    // Process elements in chunks of 4 using SSE/SSE2 intrinsics\n    size_t i = 1;\n    for (; i + 3 < size; i += 4) {\n        // Load 4 consecutive elements from A starting at A[i]\n        __m128i current = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i previous = _mm_loadu_si128((__m128i*)&A[i - 1]);\n\n        // Compute differences (current - previous)\n        __m128i diffs = _mm_sub_epi32(current, previous);\n\n        // Convert differences to float\n        __m128 diff_floats = _mm_cvtepi32_ps(diffs);\n\n        // Load 4 boolean conditions starting at cond[i]\n        __m128i cond_mask = _mm_loadu_si128((__m128i*)&cond[i]);\n\n        // Create a mask for floating-point operations\n        __m128 zero = _mm_setzero_ps();\n        __m128 mask = _mm_castsi128_ps(_mm_and_si128(cond_mask, _mm_castps_si128(_mm_cmpneq_ps(zero, zero))));\n\n        // Apply the mask: set diff_floats to 0.0f where cond is false\n        diff_floats = _mm_and_ps(mask, diff_floats);\n\n        // Store the results into diff[i]\n        _mm_storeu_ps(&diff[i], diff_floats);\n    }\n\n    // Handle remaining elements (if any) with scalar code\n    for (; i < size; ++i) {\n        if (cond[i]) {\n            diff[i] = static_cast<float>(A[i] - A[i - 1]);\n        } else {\n            diff[i] = 0.0f;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_58_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid conditional_diff_simd(const int32_t* A, const bool* cond, float* diff, size_t size) {\n    // Set the first element of diff to 0.0f\n    diff[0] = 0.0f;\n\n    // Process elements in chunks of 4 using SSE/SSE2 intrinsics\n    size_t i = 1;\n    for (; i + 3 < size; i += 4) {\n        // Load 4 integers from A starting at index i and i-1\n        __m128i current = _mm_loadu_si128((__m128i*)&A[i]);\n        __m128i previous = _mm_loadu_si128((__m128i*)&A[i - 1]);\n\n        // Compute differences: current - previous\n        __m128i diffs = _mm_sub_epi32(current, previous);\n\n        // Load 4 boolean conditions\n        __m128i condition = _mm_cvtepi8_epi32(_mm_loadu_si128((__m128i*)&cond[i]));\n\n        // Convert differences to float\n        __m128 float_diffs = _mm_cvtepi32_ps(diffs);\n\n        // Create a mask for the condition (true -> 0xFFFFFFFF, false -> 0x0)\n        __m128 mask = _mm_castsi128_ps(_mm_cmpeq_epi32(condition, _mm_set1_epi32(1)));\n\n        // Apply the mask to set values to 0.0f where condition is false\n        float_diffs = _mm_and_ps(float_diffs, mask);\n\n        // Store the result into the diff array\n        _mm_storeu_ps(&diff[i], float_diffs);\n    }\n\n    // Handle remaining elements (if any) using scalar code\n    for (; i < size; ++i) {\n        if (cond[i]) {\n            diff[i] = static_cast<float>(A[i] - A[i - 1]);\n        } else {\n            diff[i] = 0.0f;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_58_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n\nvoid conditional_diff_simd(const int32_t* A, const bool* cond, float* diff, size_t size) {\n    // Set the first element of diff to 0.0f\n    diff[0] = 0.0f;\n\n    // Process elements in chunks of 4 using SSE/SSE2 intrinsics\n    size_t i = 1;\n    for (; i + 3 < size; i += 4) {\n        // Load 4 consecutive elements from A starting at A[i-1] and A[i]\n        __m128i a_prev = _mm_loadu_si128((__m128i*)&A[i - 1]); // A[i-1], A[i], A[i+1], A[i+2]\n        __m128i a_curr = _mm_loadu_si128((__m128i*)&A[i]);     // A[i], A[i+1], A[i+2], A[i+3]\n\n        // Compute differences: A[i] - A[i-1], A[i+1] - A[i], A[i+2] - A[i+1], A[i+3] - A[i+2]\n        __m128i diffs = _mm_sub_epi32(a_curr, _mm_alignr_epi8(a_prev, a_prev, 4));\n\n        // Load 4 boolean conditions into an integer vector\n        __m128i cond_vec = _mm_castps_si128(_mm_loadu_ps((const float*)&cond[i]));\n\n        // Create a mask for the conditions (true -> 0xFFFFFFFF, false -> 0x00000000)\n        __m128i mask = _mm_and_si128(cond_vec, _mm_set1_epi32(-1));\n\n        // Apply the mask to the differences\n        diffs = _mm_and_si128(diffs, mask);\n\n        // Convert the masked differences to floats\n        __m128 diff_floats = _mm_cvtepi32_ps(diffs);\n\n        // Store the resulting floats into the diff array\n        _mm_storeu_ps(&diff[i], diff_floats);\n    }\n\n    // Handle remaining elements (if any) using scalar code\n    for (; i < size; ++i) {\n        if (cond[i]) {\n            diff[i] = static_cast<float>(A[i] - A[i - 1]);\n        } else {\n            diff[i] = 0.0f;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_59_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid widening_uint_simd(const uint32_t* src, uint64_t* dst, size_t length) {\n    size_t i = 0;\n    __m128i high_bits = _mm_set1_epi32(0xFFFFFFFF); // Set all high 32 bits to 1\n\n    for (; i + 4 <= length; i += 4) {\n        // Load 4 uint32_t values from src\n        __m128i src_vec = _mm_loadu_si128((__m128i*)&src[i]);\n\n        // Zero extend the 32-bit values to 64-bit\n        __m128i low_part = _mm_cvtepu32_epi64(src_vec);\n        __m128i high_part = _mm_cvtepu32_epi64(_mm_srli_si128(src_vec, 8));\n\n        // Combine with high bits set to 1\n        __m128i result_low = _mm_or_si128(low_part, _mm_slli_epi64(high_bits, 32));\n        __m128i result_high = _mm_or_si128(high_part, _mm_slli_epi64(high_bits, 32));\n\n        // Store the results into dst\n        _mm_storeu_si128((__m128i*)&dst[i * 2], result_low);\n        _mm_storeu_si128((__m128i*)&dst[i * 2 + 2], result_high);\n    }\n\n    // Handle remaining elements\n    for (; i < length; ++i) {\n        dst[i] = ((uint64_t)src[i]) | 0xFFFFFFFF00000000;\n    }\n}\n```"}
{"task_id": "SimdBench_59_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid widening_uint_simd(const uint32_t* src, uint64_t* dst, size_t length) {\n    size_t i = 0;\n    __m128i high_bits = _mm_set1_epi32(0xFFFFFFFF); // Set all high 32 bits to 1\n\n    for (; i + 4 <= length; i += 4) {\n        // Load 4 uint32_t values from src\n        __m128i src_vec = _mm_loadu_si128((__m128i*)&src[i]);\n\n        // Zero extend to 64-bit integers (low 32 bits)\n        __m128i low_part = _mm_cvtepu32_epi64(src_vec);\n\n        // Shift right by 64 bits and zero extend the next 4 values (high 32 bits)\n        __m128i high_part = _mm_cvtepu32_epi64(_mm_srli_si128(src_vec, 8));\n\n        // Combine low and high parts with high 32 bits set to 1\n        __m128i result_low = _mm_or_si128(low_part, high_bits);\n        __m128i result_high = _mm_or_si128(high_part, high_bits);\n\n        // Store results into dst\n        _mm_storeu_si128((__m128i*)&dst[i * 2], result_low);\n        _mm_storeu_si128((__m128i*)&dst[i * 2 + 2], result_high);\n    }\n\n    // Handle remaining elements\n    for (; i < length; ++i) {\n        dst[i] = ((uint64_t)src[i]) | 0xFFFFFFFF00000000ULL;\n    }\n}\n```"}
{"task_id": "SimdBench_59_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid widening_uint_simd(const uint32_t* src, uint64_t* dst, size_t length) {\n    size_t i = 0;\n    __m128i high_bits = _mm_set1_epi32(0xFFFFFFFF); // Set all high 32 bits to 1\n\n    for (; i + 4 <= length; i += 4) {\n        // Load 4 uint32_t elements from src\n        __m128i src_vec = _mm_loadu_si128((__m128i*)&src[i]);\n\n        // Zero extend to 64-bit integers (low 32 bits)\n        __m128i low_part = _mm_cvtepu32_epi64(src_vec);\n\n        // Shift right by 32 bits and combine with high bits\n        __m128i high_part = _mm_srli_epi64(src_vec, 32);\n        high_part = _mm_or_si128(high_part, high_bits);\n\n        // Interleave low and high parts into two 64-bit vectors\n        __m128i result1 = _mm_unpacklo_epi32(low_part, high_part);\n        __m128i result2 = _mm_unpackhi_epi32(low_part, high_part);\n\n        // Store the results in dst\n        _mm_storeu_si128((__m128i*)&dst[i * 2], result1);\n        _mm_storeu_si128((__m128i*)&dst[i * 2 + 2], result2);\n    }\n\n    // Handle remaining elements\n    for (; i < length; ++i) {\n        dst[i] = ((uint64_t)src[i]) | 0xFFFFFFFF00000000ULL;\n    }\n}\n```"}
{"task_id": "SimdBench_59_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid widening_uint_simd(const uint32_t* src, uint64_t* dst, size_t length) {\n    size_t i = 0;\n    __m128i high_bits = _mm_set1_epi32(-1); // All bits set to 1 (0xFFFFFFFF)\n\n    // Process 4 elements at a time\n    for (; i + 4 <= length; i += 4) {\n        // Load 4 uint32_t values from src\n        __m128i src_vec = _mm_loadu_si128((__m128i*)&src[i]);\n\n        // Interleave with high bits (all 1s)\n        __m128i result_low = _mm_unpacklo_epi32(src_vec, high_bits);\n        __m128i result_high = _mm_unpackhi_epi32(src_vec, high_bits);\n\n        // Store the resulting 64-bit values into dst\n        _mm_storeu_si128((__m128i*)&dst[i * 2], result_low);\n        _mm_storeu_si128((__m128i*)&dst[i * 2 + 2], result_high);\n    }\n\n    // Handle remaining elements\n    for (; i < length; ++i) {\n        dst[i] = ((uint64_t)src[i]) | 0xFFFFFFFF00000000ULL;\n    }\n}\n```"}
{"task_id": "SimdBench_59_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid widening_uint_simd(const uint32_t* src, uint64_t* dst, size_t length) {\n    size_t i = 0;\n    __m128i high_bits = _mm_set1_epi32(-1); // Set all bits to 1 (0xFFFFFFFF)\n\n    for (; i + 4 <= length; i += 4) {\n        // Load 4 uint32_t values from src\n        __m128i src_vec = _mm_loadu_si128((__m128i*)&src[i]);\n\n        // Zero-extend the 32-bit integers to 64-bit integers\n        __m128i low_part = _mm_unpacklo_epi32(src_vec, _mm_setzero_si128());\n        __m128i high_part = _mm_unpackhi_epi32(src_vec, _mm_setzero_si128());\n\n        // Combine with high bits set to 1\n        __m128i result_low = _mm_or_si128(low_part, _mm_slli_epi64(high_bits, 32));\n        __m128i result_high = _mm_or_si128(high_part, _mm_slli_epi64(high_bits, 32));\n\n        // Store the results into dst\n        _mm_storeu_si128((__m128i*)&dst[i * 2], result_low);\n        _mm_storeu_si128((__m128i*)&dst[i * 2 + 2], result_high);\n    }\n\n    // Handle remaining elements\n    for (; i < length; ++i) {\n        dst[i] = ((uint64_t)src[i]) | 0xFFFFFFFF00000000ULL;\n    }\n}\n```"}
{"task_id": "SimdBench_60_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\ndouble indexed_sum_simd(const double* vec, const int16_t* index, size_t length) {\n    __m128d sum_vec = _mm_setzero_pd(); // Initialize sum vector to zero\n\n    size_t i = 0;\n\n    // Process indices in chunks of 4 using SSE2\n    for (; i + 3 < length; i += 4) {\n        // Load 4 indices into a 128-bit register (as 16-bit integers)\n        __m128i index_vec = _mm_loadu_si128((__m128i*)(index + i));\n\n        // Convert the 16-bit indices to 32-bit integers\n        __m128i index_low = _mm_cvtepi16_epi32(index_vec); // Lower 4 indices\n        __m128i index_high = _mm_cvtepi16_epi32(_mm_srli_si128(index_vec, 8)); // Upper 4 indices\n\n        // Gather corresponding elements from vec using the indices\n        __m128d vec_low = _mm_set_pd(vec[_mm_extract_epi32(index_low, 1)], vec[_mm_extract_epi32(index_low, 0)]);\n        __m128d vec_high = _mm_set_pd(vec[_mm_extract_epi32(index_high, 1)], vec[_mm_extract_epi32(index_high, 0)]);\n\n        // Add the gathered elements to the sum vector\n        sum_vec = _mm_add_pd(sum_vec, vec_low);\n        sum_vec = _mm_add_pd(sum_vec, vec_high);\n    }\n\n    // Horizontal add to combine the two partial sums in sum_vec\n    __m128d temp = _mm_hadd_pd(sum_vec, sum_vec);\n    double result = _mm_cvtsd_f64(temp);\n\n    // Process any remaining indices\n    for (; i < length; ++i) {\n        result += vec[index[i]];\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_60_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\ndouble indexed_sum_simd(const double* vec, const int16_t* index, size_t length) {\n    __m128d sum_vec = _mm_setzero_pd(); // Initialize sum vector to zero\n\n    size_t i = 0;\n\n    // Process two indices at a time using SSE2\n    for (; i + 1 < length; i += 2) {\n        // Load two indices\n        int16_t idx0 = index[i];\n        int16_t idx1 = index[i + 1];\n\n        // Ensure indices are within bounds\n        if (idx0 >= 0 && idx0 < length && idx1 >= 0 && idx1 < length) {\n            // Load two doubles from vec using the indices\n            __m128d vec_vals = _mm_set_pd(vec[idx1], vec[idx0]);\n\n            // Add the loaded values to the sum vector\n            sum_vec = _mm_add_pd(sum_vec, vec_vals);\n        }\n    }\n\n    // Horizontal add to combine the two partial sums in sum_vec\n    double temp[2];\n    _mm_storeu_pd(temp, sum_vec);\n    double result = temp[0] + temp[1];\n\n    // Handle any remaining elements\n    for (; i < length; ++i) {\n        int16_t idx = index[i];\n        if (idx >= 0 && idx < length) {\n            result += vec[idx];\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_60_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\ndouble indexed_sum_simd(const double* vec, const int16_t* index, size_t length) {\n    __m128d sum_vec = _mm_setzero_pd();\n    double result[2] = {0.0, 0.0};\n    \n    size_t i = 0;\n    // Process indices in chunks of 4 for SIMD parallelism\n    for (; i + 3 < length; i += 4) {\n        // Load 4 indices into a vector\n        __m128i idx_vec = _mm_loadu_si128((__m128i*)(index + i));\n        \n        // Convert indices to 32-bit integers\n        __m128i idx_32lo = _mm_cvtepi16_epi32(idx_vec);\n        __m128i idx_32hi = _mm_cvtepi16_epi32(_mm_shuffle_epi32(idx_vec, 0xE));\n\n        // Gather corresponding values from vec using the indices\n        __m128d val_lo = _mm_set_pd(vec[_mm_extract_epi32(idx_32lo, 1)], vec[_mm_extract_epi32(idx_32lo, 0)]);\n        __m128d val_hi = _mm_set_pd(vec[_mm_extract_epi32(idx_32hi, 1)], vec[_mm_extract_epi32(idx_32hi, 0)]);\n\n        // Add the two double values in each vector\n        sum_vec = _mm_add_pd(sum_vec, val_lo);\n        sum_vec = _mm_add_pd(sum_vec, val_hi);\n    }\n\n    // Horizontal add of the accumulated sums in sum_vec\n    _mm_storeu_pd(result, sum_vec);\n    double total_sum = result[0] + result[1];\n\n    // Process remaining elements (if any)\n    for (; i < length; ++i) {\n        total_sum += vec[index[i]];\n    }\n\n    return total_sum;\n}\n```"}
{"task_id": "SimdBench_60_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\ndouble indexed_sum_simd(const double* vec, const int16_t* index, size_t length) {\n    __m128d sum_vec = _mm_setzero_pd(); // Initialize sum vector to zero\n\n    size_t i = 0;\n\n    // Process two indices at a time using SSE2\n    for (; i + 1 < length; i += 2) {\n        // Load two indices\n        int16_t idx0 = index[i];\n        int16_t idx1 = index[i + 1];\n\n        // Ensure indices are within bounds\n        if (idx0 >= 0 && idx0 < length && idx1 >= 0 && idx1 < length) {\n            // Load two values from vec using the indices\n            __m128d values = _mm_set_pd(vec[idx1], vec[idx0]);\n\n            // Add the loaded values to the sum vector\n            sum_vec = _mm_add_pd(sum_vec, values);\n        }\n    }\n\n    // Horizontal add to combine the two partial sums in sum_vec\n    double partial_sums[2];\n    _mm_storeu_pd(partial_sums, sum_vec);\n    double total_sum = partial_sums[0] + partial_sums[1];\n\n    // Handle any remaining elements\n    for (; i < length; ++i) {\n        int16_t idx = index[i];\n        if (idx >= 0 && idx < length) {\n            total_sum += vec[idx];\n        }\n    }\n\n    return total_sum;\n}\n```"}
{"task_id": "SimdBench_60_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\ndouble indexed_sum_simd(const double* vec, const int16_t* index, size_t length) {\n    __m128d sum_vec = _mm_setzero_pd();\n    double result[2] = {0.0, 0.0};\n\n    size_t i = 0;\n\n    // Process indices in chunks of 4 using SSE2 intrinsics\n    for (; i + 3 < length; i += 4) {\n        // Load 4 int16_t indices into a vector\n        __m128i idx_vec = _mm_loadu_si128((__m128i*)(index + i));\n\n        // Convert int16_t indices to int32_t for proper addressing\n        __m128i idx_lo = _mm_cvtepi16_epi32(idx_vec);\n        __m128i idx_hi = _mm_cvtepi16_epi32(_mm_srli_si128(idx_vec, 8));\n\n        // Gather corresponding double values from vec using the indices\n        __m128d val_lo = _mm_set_pd(vec[_mm_extract_epi32(idx_lo, 1)], vec[_mm_extract_epi32(idx_lo, 0)]);\n        __m128d val_hi = _mm_set_pd(vec[_mm_extract_epi32(idx_hi, 1)], vec[_mm_extract_epi32(idx_hi, 0)]);\n\n        // Add the gathered values to the sum vector\n        sum_vec = _mm_add_pd(sum_vec, _mm_add_pd(val_lo, val_hi));\n    }\n\n    // Horizontal add to combine the two partial sums in sum_vec\n    _mm_storeu_pd(result, sum_vec);\n    double total_sum = result[0] + result[1];\n\n    // Process any remaining indices\n    for (; i < length; ++i) {\n        total_sum += vec[index[i]];\n    }\n\n    return total_sum;\n}\n```"}
{"task_id": "SimdBench_61_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid simple_conv2d_simd(const double* input, const double* kernel, double * output, size_t input_size, size_t kernel_size) {\n    size_t output_size = input_size - kernel_size + 1;\n    __m128d zero = _mm_setzero_pd();\n\n    for (size_t i = 0; i < output_size; ++i) {\n        for (size_t j = 0; j < output_size; ++j) {\n            __m128d sum = _mm_setzero_pd();\n            for (size_t ki = 0; ki < kernel_size; ++ki) {\n                for (size_t kj = 0; kj < kernel_size; kj += 2) {\n                    size_t input_idx = (i + ki) * input_size + (j + kj);\n                    size_t kernel_idx = ki * kernel_size + kj;\n\n                    __m128d input_vec = _mm_loadu_pd(&input[input_idx]);\n                    __m128d kernel_vec = _mm_loadu_pd(&kernel[kernel_idx]);\n\n                    __m128d prod = _mm_mul_pd(input_vec, kernel_vec);\n                    sum = _mm_add_pd(sum, prod);\n                }\n            }\n\n            // Horizontal add to accumulate the partial sums in the SSE register\n            double temp[2];\n            _mm_storeu_pd(temp, sum);\n            double result = temp[0] + temp[1];\n\n            // Apply ReLU activation\n            if (result < 0.0) {\n                result = 0.0;\n            }\n\n            output[i * output_size + j] = result;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_61_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid simple_conv2d_simd(const double* input, const double* kernel, double * output, size_t input_size, size_t kernel_size) {\n    size_t output_size = input_size - kernel_size + 1;\n    __m128d zero = _mm_setzero_pd();\n\n    for (size_t i = 0; i < output_size; ++i) {\n        for (size_t j = 0; j < output_size; ++j) {\n            __m128d sum = _mm_setzero_pd();\n            for (size_t ki = 0; ki < kernel_size; ++ki) {\n                for (size_t kj = 0; kj < kernel_size; kj += 2) {\n                    size_t input_idx = (i + ki) * input_size + (j + kj);\n                    size_t kernel_idx = ki * kernel_size + kj;\n\n                    __m128d input_vec = _mm_loadu_pd(&input[input_idx]);\n                    __m128d kernel_vec = _mm_loadu_pd(&kernel[kernel_idx]);\n\n                    __m128d mul = _mm_mul_pd(input_vec, kernel_vec);\n                    sum = _mm_add_pd(sum, mul);\n                }\n            }\n\n            // Horizontal add to get the final sum of the two elements in the SIMD register\n            double temp[2];\n            _mm_storeu_pd(temp, sum);\n            double result = temp[0] + temp[1];\n\n            // Apply ReLU activation\n            if (result < 0.0) {\n                result = 0.0;\n            }\n\n            output[i * output_size + j] = result;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_61_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid simple_conv2d_simd(const double* input, const double* kernel, double * output, size_t input_size, size_t kernel_size) {\n    size_t output_size = input_size - kernel_size + 1;\n    __m128d zero = _mm_setzero_pd();\n\n    for (size_t i = 0; i < output_size; ++i) {\n        for (size_t j = 0; j < output_size; ++j) {\n            __m128d sum = _mm_setzero_pd();\n            for (size_t ki = 0; ki < kernel_size; ++ki) {\n                for (size_t kj = 0; kj < kernel_size; kj += 2) {\n                    size_t input_idx = (i + ki) * input_size + (j + kj);\n                    size_t kernel_idx = ki * kernel_size + kj;\n\n                    __m128d input_vec = _mm_loadu_pd(&input[input_idx]);\n                    __m128d kernel_vec = _mm_loadu_pd(&kernel[kernel_idx]);\n\n                    __m128d prod = _mm_mul_pd(input_vec, kernel_vec);\n                    sum = _mm_add_pd(sum, prod);\n                }\n            }\n\n            // Horizontal add to accumulate the partial sums in the SSE register\n            double temp[2];\n            _mm_storeu_pd(temp, sum);\n            double result = temp[0] + temp[1];\n\n            // Apply ReLU activation\n            if (result < 0.0) {\n                result = 0.0;\n            }\n\n            output[i * output_size + j] = result;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_61_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid simple_conv2d_simd(const double* input, const double* kernel, double * output, size_t input_size, size_t kernel_size) {\n    size_t output_size = input_size - kernel_size + 1;\n    __m128d zero = _mm_setzero_pd();\n\n    for (size_t i = 0; i < output_size; ++i) {\n        for (size_t j = 0; j < output_size; ++j) {\n            __m128d sum = _mm_setzero_pd();\n            for (size_t ki = 0; ki < kernel_size; ++ki) {\n                for (size_t kj = 0; kj < kernel_size; kj += 2) {\n                    size_t input_idx = (i + ki) * input_size + (j + kj);\n                    size_t kernel_idx = ki * kernel_size + kj;\n\n                    __m128d input_vec = _mm_loadu_pd(&input[input_idx]);\n                    __m128d kernel_vec = _mm_loadu_pd(&kernel[kernel_idx]);\n\n                    __m128d prod = _mm_mul_pd(input_vec, kernel_vec);\n                    sum = _mm_add_pd(sum, prod);\n                }\n            }\n\n            // Horizontal add to get the final sum of the two elements in sum\n            double temp[2];\n            _mm_storeu_pd(temp, sum);\n            double result = temp[0] + temp[1];\n\n            // Apply ReLU activation\n            if (result < 0.0) {\n                result = 0.0;\n            }\n\n            output[i * output_size + j] = result;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_61_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nvoid simple_conv2d_simd(const double* input, const double* kernel, double * output, size_t input_size, size_t kernel_size) {\n    size_t output_size = input_size - kernel_size + 1;\n    __m128d zero = _mm_setzero_pd();\n\n    for (size_t i = 0; i < output_size; ++i) {\n        for (size_t j = 0; j < output_size; ++j) {\n            __m128d sum_vec = _mm_setzero_pd();\n            double sum = 0.0;\n\n            for (size_t ki = 0; ki < kernel_size; ++ki) {\n                for (size_t kj = 0; kj < kernel_size; ++kj) {\n                    size_t input_idx = (i + ki) * input_size + (j + kj);\n                    size_t kernel_idx = ki * kernel_size + kj;\n\n                    double val = input[input_idx] * kernel[kernel_idx];\n                    sum += val;\n                }\n            }\n\n            // Load sum into SIMD register and apply ReLU\n            sum_vec = _mm_load_sd(&sum);\n            sum_vec = _mm_max_pd(sum_vec, zero);\n\n            // Store the result back to the output array\n            _mm_store_sd(&output[i * output_size + j], sum_vec);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_62_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool has_close_elements_simd(const std::vector<double> & numbers, double threshold) {\n    __m128d threshold_vec = _mm_set1_pd(threshold);\n    size_t size = numbers.size();\n    \n    for (size_t i = 0; i < size; ++i) {\n        __m128d num_i = _mm_set1_pd(numbers[i]);\n        for (size_t j = i + 1; j < size; j += 2) {\n            __m128d num_j = _mm_loadu_pd(&numbers[j]);\n            __m128d diff = _mm_sub_pd(num_i, num_j);\n            diff = _mm_andnot_pd(_mm_set1_pd(-0.0), diff); // Absolute value\n            __m128d cmp = _mm_cmplt_pd(diff, threshold_vec);\n            if (_mm_movemask_pd(cmp)) {\n                return true;\n            }\n        }\n        if (size % 2 != 0 && i != size - 1) { // Handle odd-sized vectors\n            double diff = fabs(numbers[i] - numbers[size - 1]);\n            if (diff < threshold) {\n                return true;\n            }\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_62_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool has_close_elements_simd(const std::vector<double> & numbers, double threshold) {\n    size_t size = numbers.size();\n    if (size < 2) return false;\n\n    __m128d threshold_vec = _mm_set1_pd(threshold);\n\n    for (size_t i = 0; i < size; ++i) {\n        __m128d num_i = _mm_set1_pd(numbers[i]);\n\n        size_t j = i + 1;\n        for (; j + 1 < size; j += 2) {\n            __m128d num_j = _mm_loadu_pd(&numbers[j]);\n\n            __m128d diff = _mm_sub_pd(num_i, num_j);\n            diff = _mm_andnot_pd(_mm_set1_pd(-0.0), diff); // Absolute value\n            __m128d cmp = _mm_cmplt_pd(diff, threshold_vec);\n\n            if (_mm_movemask_pd(cmp)) {\n                return true;\n            }\n        }\n\n        for (; j < size; ++j) {\n            double diff = std::abs(numbers[i] - numbers[j]);\n            if (diff < threshold) {\n                return true;\n            }\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_62_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool has_close_elements_simd(const std::vector<double> & numbers, double threshold) {\n    __m128d threshold_vec = _mm_set1_pd(threshold);\n    size_t size = numbers.size();\n    \n    for (size_t i = 0; i < size; ++i) {\n        __m128d num_i = _mm_set1_pd(numbers[i]);\n        for (size_t j = i + 1; j < size; j += 2) {\n            __m128d num_j = _mm_loadu_pd(&numbers[j]);\n            __m128d diff = _mm_sub_pd(num_i, num_j);\n            __m128d abs_diff = _mm_andnot_pd(_mm_set1_pd(-0.0), diff); // Absolute value\n            __m128d cmp = _mm_cmplt_pd(abs_diff, threshold_vec);\n            if (_mm_movemask_pd(cmp)) {\n                return true;\n            }\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_62_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool has_close_elements_simd(const std::vector<double> & numbers, double threshold) {\n    __m128d threshold_vec = _mm_set1_pd(threshold);\n    size_t size = numbers.size();\n    \n    for (size_t i = 0; i < size; ++i) {\n        __m128d num_i = _mm_set1_pd(numbers[i]);\n        for (size_t j = i + 1; j < size; j += 2) {\n            __m128d num_j = _mm_loadu_pd(&numbers[j]);\n            __m128d diff = _mm_sub_pd(num_i, num_j);\n            __m128d abs_diff = _mm_andnot_pd(_mm_set1_pd(-0.0), diff); // Absolute value\n            __m128d cmp = _mm_cmplt_pd(abs_diff, threshold_vec);\n            if (_mm_movemask_pd(cmp)) {\n                return true;\n            }\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_62_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool has_close_elements_simd(const std::vector<double> & numbers, double threshold) {\n    size_t size = numbers.size();\n    if (size < 2) return false;\n\n    __m128d threshold_vec = _mm_set1_pd(threshold);\n\n    for (size_t i = 0; i < size; ++i) {\n        __m128d num_i = _mm_set1_pd(numbers[i]);\n        size_t j = i + 1;\n\n        // Process four elements at a time using SIMD\n        for (; j + 1 < size; j += 2) {\n            __m128d num_j = _mm_loadu_pd(&numbers[j]);\n            __m128d diff = _mm_sub_pd(num_i, num_j);\n            diff = _mm_andnot_pd(_mm_set1_pd(-0.0), diff); // Absolute value\n            __m128d cmp = _mm_cmplt_pd(diff, threshold_vec);\n            if (_mm_movemask_pd(cmp)) {\n                return true;\n            }\n        }\n\n        // Handle remaining elements\n        for (; j < size; ++j) {\n            double diff = std::abs(numbers[i] - numbers[j]);\n            if (diff < threshold) {\n                return true;\n            }\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_63_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool below_zero_simd(std::vector<int> operations) {\n    __m128i balance = _mm_setzero_si128(); // Initialize balance to zero\n    __m128i zero = _mm_setzero_si128();    // Zero vector for comparison\n    __m128i negative_mask;\n\n    size_t i = 0;\n    size_t n = operations.size();\n\n    // Process 4 integers at a time using SIMD\n    for (; i + 4 <= n; i += 4) {\n        // Load 4 integers from the vector into an SSE register\n        __m128i ops = _mm_loadu_si128((__m128i*)&operations[i]);\n\n        // Add the loaded values to the current balance\n        balance = _mm_add_epi32(balance, ops);\n\n        // Compare if any of the balances are less than zero\n        negative_mask = _mm_cmplt_epi32(balance, zero);\n\n        // Check if any of the lanes have gone below zero\n        if (!_mm_testz_si128(negative_mask, negative_mask)) {\n            return true;\n        }\n    }\n\n    // Horizontal sum of the remaining balance vector\n    int temp[4];\n    _mm_storeu_si128((__m128i*)temp, balance);\n    int total_balance = temp[0] + temp[1] + temp[2] + temp[3];\n\n    // Process any remaining elements in the vector\n    for (; i < n; ++i) {\n        total_balance += operations[i];\n        if (total_balance < 0) {\n            return true;\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_63_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool below_zero_simd(std::vector<int> operations) {\n    __m128i balance = _mm_setzero_si128(); // Initialize balance to zero\n    __m128i zero = _mm_setzero_si128();    // Constant zero for comparison\n    __m128i negative_mask = _mm_set1_epi32(0x80000000); // Mask to check for negative values\n\n    size_t i = 0;\n    size_t size = operations.size();\n\n    // Process 4 integers at a time using SIMD\n    for (; i + 4 <= size; i += 4) {\n        // Load 4 integers from the vector into an SSE register\n        __m128i ops = _mm_loadu_si128((__m128i*)&operations[i]);\n\n        // Add the loaded operations to the current balance\n        balance = _mm_add_epi32(balance, ops);\n\n        // Check if any of the balances are negative\n        __m128i is_negative = _mm_and_si128(balance, negative_mask);\n        if (!_mm_testz_si128(is_negative, is_negative)) {\n            return true; // If any balance is negative, return true\n        }\n    }\n\n    // Handle remaining elements (if any)\n    int scalar_balance = 0;\n    for (; i < size; ++i) {\n        scalar_balance += operations[i];\n        if (scalar_balance < 0) {\n            return true;\n        }\n    }\n\n    return false; // No balance fell below zero\n}\n```"}
{"task_id": "SimdBench_63_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool below_zero_simd(std::vector<int> operations) {\n    __m128i balance = _mm_setzero_si128(); // Initialize balance to zero\n    __m128i zero = _mm_setzero_si128();    // Zero vector for comparison\n    __m128i negative_mask = _mm_set1_epi32(0x80000000); // Mask to check for negative values\n\n    size_t i = 0;\n    size_t n = operations.size();\n\n    // Process four elements at a time\n    for (; i + 4 <= n; i += 4) {\n        // Load four integers from the vector into an SSE register\n        __m128i ops = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&operations[i]));\n\n        // Add the loaded operations to the current balance\n        balance = _mm_add_epi32(balance, ops);\n\n        // Check if any of the balances are negative\n        __m128i sign_bits = _mm_and_si128(balance, negative_mask);\n        if (!_mm_testz_si128(sign_bits, sign_bits)) {\n            return true; // Negative balance detected\n        }\n    }\n\n    // Handle remaining elements (if any)\n    int scalar_balance = 0;\n    for (; i < n; ++i) {\n        scalar_balance += operations[i];\n        if (scalar_balance < 0) {\n            return true;\n        }\n    }\n\n    return false; // No negative balance detected\n}\n```"}
{"task_id": "SimdBench_63_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool below_zero_simd(std::vector<int> operations) {\n    __m128i balance = _mm_setzero_si128(); // Initialize balance to zero\n    __m128i zero = _mm_setzero_si128();    // Zero vector for comparison\n    __m128i negative_mask;\n\n    size_t i = 0;\n    size_t size = operations.size();\n\n    // Process 4 integers at a time using SIMD\n    for (; i + 4 <= size; i += 4) {\n        // Load 4 integers from the vector into an SSE register\n        __m128i ops = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&operations[i]));\n\n        // Add the loaded values to the current balance\n        balance = _mm_add_epi32(balance, ops);\n\n        // Compare if any of the balances are less than zero\n        negative_mask = _mm_cmplt_epi32(balance, zero);\n\n        // Check if any of the lanes have gone below zero\n        if (!_mm_testz_si128(negative_mask, negative_mask)) {\n            return true;\n        }\n    }\n\n    // Handle remaining elements (if any)\n    int temp_balance = 0;\n    for (; i < size; ++i) {\n        temp_balance += operations[i];\n        if (temp_balance < 0) {\n            return true;\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_63_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool below_zero_simd(std::vector<int> operations) {\n    __m128i balance = _mm_setzero_si128(); // Initialize balance to zero\n    __m128i zero = _mm_setzero_si128();    // Zero vector for comparison\n    __m128i negative_mask = _mm_set1_epi32(0x80000000); // Mask to check for negative values\n\n    size_t i = 0;\n    size_t size = operations.size();\n\n    // Process 4 integers at a time using SIMD\n    for (; i + 4 <= size; i += 4) {\n        // Load 4 integers from the vector into an SSE register\n        __m128i ops = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&operations[i]));\n\n        // Add the loaded operations to the current balance\n        balance = _mm_add_epi32(balance, ops);\n\n        // Check if any of the balances are negative\n        __m128i sign_bits = _mm_and_si128(balance, negative_mask);\n        if (!_mm_testz_si128(sign_bits, sign_bits)) {\n            return true; // Negative balance detected\n        }\n    }\n\n    // Horizontal sum of the remaining balance vector\n    int temp[4];\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(temp), balance);\n    int total_balance = temp[0] + temp[1] + temp[2] + temp[3];\n\n    // Process remaining elements (if any)\n    for (; i < size; ++i) {\n        total_balance += operations[i];\n        if (total_balance < 0) {\n            return true;\n        }\n    }\n\n    return false; // No negative balance detected\n}\n```"}
{"task_id": "SimdBench_64_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\ndouble mean_absolute_deviation_simd(std::vector<double> numbers) {\n    size_t n = numbers.size();\n    if (n == 0) return 0.0;\n\n    // Ensure the size is a multiple of 2 for SIMD processing\n    size_t simd_size = (n / 2) * 2;\n    __m128d sum_vec = _mm_setzero_pd();\n    __m128d count_vec = _mm_setzero_pd();\n\n    // Compute sum using SIMD\n    for (size_t i = 0; i < simd_size; i += 2) {\n        __m128d val = _mm_loadu_pd(&numbers[i]);\n        sum_vec = _mm_add_pd(sum_vec, val);\n        count_vec = _mm_add_pd(count_vec, _mm_set1_pd(2.0));\n    }\n\n    // Horizontal add to get total sum and count\n    double sum = 0.0, count = 0.0;\n    sum += _mm_cvtsd_f64(_mm_hadd_pd(sum_vec, sum_vec));\n    count += _mm_cvtsd_f64(_mm_hadd_pd(count_vec, count_vec));\n\n    // Handle remaining elements\n    for (size_t i = simd_size; i < n; ++i) {\n        sum += numbers[i];\n        count += 1.0;\n    }\n\n    double mean = sum / count;\n\n    // Compute absolute deviations using SIMD\n    __m128d mad_vec = _mm_setzero_pd();\n    for (size_t i = 0; i < simd_size; i += 2) {\n        __m128d val = _mm_loadu_pd(&numbers[i]);\n        __m128d diff = _mm_sub_pd(val, _mm_set1_pd(mean));\n        __m128d abs_diff = _mm_and_pd(diff, _mm_castsi128_pd(_mm_set1_epi64x(0x7FFFFFFFFFFFFFFF)));\n        mad_vec = _mm_add_pd(mad_vec, abs_diff);\n    }\n\n    // Horizontal add to get total MAD\n    double mad_sum = 0.0;\n    mad_sum += _mm_cvtsd_f64(_mm_hadd_pd(mad_vec, mad_vec));\n\n    // Handle remaining elements\n    for (size_t i = simd_size; i < n; ++i) {\n        mad_sum += std::abs(numbers[i] - mean);\n    }\n\n    return mad_sum / count;\n}\n```"}
{"task_id": "SimdBench_64_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\ndouble mean_absolute_deviation_simd(std::vector<double> numbers) {\n    size_t n = numbers.size();\n    if (n == 0) return 0.0;\n\n    // Ensure the size is a multiple of 2 for SIMD processing\n    size_t simd_size = (n / 2) * 2;\n    __m128d sum_vec = _mm_setzero_pd();\n    \n    // Compute sum using SIMD\n    size_t i = 0;\n    for (; i < simd_size; i += 2) {\n        __m128d vec = _mm_loadu_pd(&numbers[i]);\n        sum_vec = _mm_add_pd(sum_vec, vec);\n    }\n    \n    // Horizontal add to get total sum\n    double sum = 0.0;\n    sum += _mm_cvtsd_f64(_mm_hadd_pd(sum_vec, sum_vec));\n    \n    // Add remaining elements\n    for (; i < n; ++i) {\n        sum += numbers[i];\n    }\n    \n    // Compute mean\n    double mean = sum / n;\n    __m128d mean_vec = _mm_set1_pd(mean);\n    \n    // Compute absolute deviations and their sum\n    __m128d mad_sum_vec = _mm_setzero_pd();\n    i = 0;\n    for (; i < simd_size; i += 2) {\n        __m128d vec = _mm_loadu_pd(&numbers[i]);\n        __m128d diff = _mm_sub_pd(vec, mean_vec);\n        __m128d abs_diff = _mm_and_pd(diff, _mm_castsi128_pd(_mm_set1_epi64x(0x7FFFFFFFFFFFFFFF)));\n        mad_sum_vec = _mm_add_pd(mad_sum_vec, abs_diff);\n    }\n    \n    // Horizontal add to get total MAD sum\n    double mad_sum = 0.0;\n    mad_sum += _mm_cvtsd_f64(_mm_hadd_pd(mad_sum_vec, mad_sum_vec));\n    \n    // Add remaining elements\n    for (; i < n; ++i) {\n        mad_sum += std::abs(numbers[i] - mean);\n    }\n    \n    // Compute and return MAD\n    return mad_sum / n;\n}\n```"}
{"task_id": "SimdBench_64_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\ndouble mean_absolute_deviation_simd(std::vector<double> numbers) {\n    size_t n = numbers.size();\n    if (n == 0) return 0.0;\n\n    // Ensure the size is a multiple of 2 for SIMD processing\n    size_t simd_size = (n / 2) * 2;\n    __m128d sum_vec = _mm_setzero_pd();\n    double sum = 0.0;\n\n    // Compute the sum of all elements using SIMD\n    for (size_t i = 0; i < simd_size; i += 2) {\n        __m128d vec = _mm_loadu_pd(&numbers[i]);\n        sum_vec = _mm_add_pd(sum_vec, vec);\n    }\n\n    // Horizontal add to get the total sum\n    double temp[2];\n    _mm_storeu_pd(temp, sum_vec);\n    sum = temp[0] + temp[1];\n\n    // Add remaining elements if n is not a multiple of 2\n    for (size_t i = simd_size; i < n; ++i) {\n        sum += numbers[i];\n    }\n\n    // Compute the mean\n    double mean = sum / n;\n\n    // Compute the absolute deviations from the mean using SIMD\n    __m128d mean_vec = _mm_set1_pd(mean);\n    __m128d mad_sum_vec = _mm_setzero_pd();\n\n    for (size_t i = 0; i < simd_size; i += 2) {\n        __m128d vec = _mm_loadu_pd(&numbers[i]);\n        __m128d diff = _mm_sub_pd(vec, mean_vec);\n        __m128d abs_diff = _mm_andnot_pd(_mm_set1_pd(-0.0), diff); // Absolute value\n        mad_sum_vec = _mm_add_pd(mad_sum_vec, abs_diff);\n    }\n\n    // Horizontal add to get the total MAD sum\n    _mm_storeu_pd(temp, mad_sum_vec);\n    double mad_sum = temp[0] + temp[1];\n\n    // Add remaining elements if n is not a multiple of 2\n    for (size_t i = simd_size; i < n; ++i) {\n        mad_sum += std::abs(numbers[i] - mean);\n    }\n\n    // Compute the Mean Absolute Deviation\n    return mad_sum / n;\n}\n```"}
{"task_id": "SimdBench_64_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\ndouble mean_absolute_deviation_simd(std::vector<double> numbers) {\n    size_t n = numbers.size();\n    if (n == 0) return 0.0;\n\n    // Ensure the size is a multiple of 2 for SIMD processing\n    size_t simd_size = (n / 2) * 2;\n    __m128d sum_vec = _mm_setzero_pd();\n    double mean = 0.0;\n\n    // Compute the sum of all elements using SIMD\n    for (size_t i = 0; i < simd_size; i += 2) {\n        __m128d vec = _mm_loadu_pd(&numbers[i]);\n        sum_vec = _mm_add_pd(sum_vec, vec);\n    }\n\n    // Horizontal add to compute the total sum\n    double temp[2];\n    _mm_storeu_pd(temp, sum_vec);\n    double total_sum = temp[0] + temp[1];\n\n    // Add remaining elements if n is not a multiple of 2\n    for (size_t i = simd_size; i < n; ++i) {\n        total_sum += numbers[i];\n    }\n\n    // Compute the mean\n    mean = total_sum / n;\n\n    // Compute the Mean Absolute Deviation using SIMD\n    __m128d mad_vec = _mm_setzero_pd();\n    __m128d mean_vec = _mm_set1_pd(mean);\n\n    for (size_t i = 0; i < simd_size; i += 2) {\n        __m128d vec = _mm_loadu_pd(&numbers[i]);\n        __m128d diff = _mm_sub_pd(vec, mean_vec);\n        __m128d abs_diff = _mm_and_pd(diff, _mm_castsi128_pd(_mm_set1_epi64x(0x7FFFFFFFFFFFFFFF)));\n        mad_vec = _mm_add_pd(mad_vec, abs_diff);\n    }\n\n    // Horizontal add to compute the total MAD sum\n    _mm_storeu_pd(temp, mad_vec);\n    double mad_sum = temp[0] + temp[1];\n\n    // Add remaining elements if n is not a multiple of 2\n    for (size_t i = simd_size; i < n; ++i) {\n        mad_sum += std::abs(numbers[i] - mean);\n    }\n\n    // Compute and return the Mean Absolute Deviation\n    return mad_sum / n;\n}\n```"}
{"task_id": "SimdBench_64_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\ndouble mean_absolute_deviation_simd(std::vector<double> numbers) {\n    size_t n = numbers.size();\n    if (n == 0) return 0.0;\n\n    // Ensure the size is a multiple of 2 for SIMD processing\n    size_t simd_size = (n / 2) * 2;\n    __m128d sum_vec = _mm_setzero_pd();\n    __m128d count_vec = _mm_setzero_pd();\n\n    // Compute sum using SIMD\n    for (size_t i = 0; i < simd_size; i += 2) {\n        __m128d num_vec = _mm_loadu_pd(&numbers[i]);\n        sum_vec = _mm_add_pd(sum_vec, num_vec);\n        count_vec = _mm_add_pd(count_vec, _mm_set1_pd(2.0));\n    }\n\n    // Horizontal add to get total sum and count\n    double sum = 0.0, count = 0.0;\n    sum_vec = _mm_hadd_pd(sum_vec, sum_vec);\n    _mm_store_sd(&sum, sum_vec);\n    count_vec = _mm_hadd_pd(count_vec, count_vec);\n    _mm_store_sd(&count, count_vec);\n\n    // Add remaining elements if n is odd\n    for (size_t i = simd_size; i < n; ++i) {\n        sum += numbers[i];\n        count += 1.0;\n    }\n\n    double mean = sum / count;\n\n    // Compute absolute deviations using SIMD\n    __m128d mad_sum_vec = _mm_setzero_pd();\n    for (size_t i = 0; i < simd_size; i += 2) {\n        __m128d num_vec = _mm_loadu_pd(&numbers[i]);\n        __m128d diff_vec = _mm_sub_pd(num_vec, _mm_set1_pd(mean));\n        __m128d abs_diff_vec = _mm_and_pd(diff_vec, _mm_castsi128_pd(_mm_set1_epi64x(0x7FFFFFFFFFFFFFFF)));\n        mad_sum_vec = _mm_add_pd(mad_sum_vec, abs_diff_vec);\n    }\n\n    // Horizontal add to get total MAD sum\n    double mad_sum = 0.0;\n    mad_sum_vec = _mm_hadd_pd(mad_sum_vec, mad_sum_vec);\n    _mm_store_sd(&mad_sum, mad_sum_vec);\n\n    // Add remaining elements if n is odd\n    for (size_t i = simd_size; i < n; ++i) {\n        mad_sum += std::abs(numbers[i] - mean);\n    }\n\n    return mad_sum / count;\n}\n```"}
{"task_id": "SimdBench_65_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> intersperse_simd(std::vector<int> numbers, int delimeter) {\n    std::vector<int> result;\n    size_t n = numbers.size();\n    \n    if (n == 0) return result;\n\n    result.reserve(n * 2 - 1);\n\n    __m128i delim_vec = _mm_set1_epi32(delimeter);\n\n    for (size_t i = 0; i < n - 1; i += 4) {\n        __m128i nums = _mm_loadu_si128((__m128i*)&numbers[i]);\n        __m128i next_nums = _mm_loadu_si128((__m128i*)&numbers[i + 1]);\n\n        // Interleave current and next elements with delimiter\n        __m128i res1 = _mm_unpacklo_epi32(nums, delim_vec);\n        __m128i res2 = _mm_unpackhi_epi32(nums, delim_vec);\n\n        // Store the interleaved results into the result vector\n        int temp[8];\n        _mm_storeu_si128((__m128i*)temp, res1);\n        _mm_storeu_si128((__m128i*)(temp + 4), res2);\n\n        for (int j = 0; j < 7; ++j) {\n            result.push_back(temp[j]);\n        }\n    }\n\n    // Handle remaining elements\n    for (size_t i = ((n - 1) / 4) * 4; i < n - 1; ++i) {\n        result.push_back(numbers[i]);\n        result.push_back(delimeter);\n    }\n\n    result.push_back(numbers[n - 1]);\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_65_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> intersperse_simd(std::vector<int> numbers, int delimeter) {\n    std::vector<int> result;\n    size_t n = numbers.size();\n    \n    if (n == 0) return result;\n\n    result.reserve(n * 2 - 1);\n\n    __m128i delim_vec = _mm_set1_epi32(delimeter);\n\n    size_t i = 0;\n    for (; i + 4 <= n; i += 4) {\n        __m128i nums = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&numbers[i]));\n\n        // Prepare the delimiter vector for the gaps\n        __m128i res1 = _mm_unpacklo_epi32(nums, delim_vec);\n        __m128i res2 = _mm_unpackhi_epi32(nums, delim_vec);\n\n        // Store the first 3 elements of res1 and res2\n        int temp[8];\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(temp), res1);\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(temp + 4), res2);\n\n        for (size_t j = 0; j < 7; ++j) {\n            result.push_back(temp[j]);\n        }\n    }\n\n    // Handle remaining elements\n    for (; i < n; ++i) {\n        result.push_back(numbers[i]);\n        if (i != n - 1) {\n            result.push_back(delimeter);\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_65_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> intersperse_simd(std::vector<int> numbers, int delimeter) {\n    std::vector<int> result;\n    size_t n = numbers.size();\n    \n    if (n == 0) return result;\n\n    result.reserve(n * 2 - 1);\n\n    __m128i delim_vec = _mm_set1_epi32(delimeter);\n\n    for (size_t i = 0; i < n - 1; i += 4) {\n        __m128i nums = _mm_loadu_si128((__m128i*)&numbers[i]);\n        __m128i next_nums = _mm_loadu_si128((__m128i*)&numbers[i + 1]);\n\n        __m128i res1 = _mm_unpacklo_epi32(nums, delim_vec);\n        __m128i res2 = _mm_unpackhi_epi32(nums, delim_vec);\n\n        __m128i res3 = _mm_unpacklo_epi32(next_nums, delim_vec);\n        __m128i res4 = _mm_unpackhi_epi32(next_nums, delim_vec);\n\n        int temp[8];\n        _mm_storeu_si128((__m128i*)temp, res1);\n        _mm_storeu_si128((__m128i*)(temp + 4), res2);\n\n        for (int j = 0; j < 8; ++j) {\n            result.push_back(temp[j]);\n        }\n    }\n\n    // Handle remaining elements\n    for (size_t i = ((n - 1) / 4) * 4; i < n - 1; ++i) {\n        result.push_back(numbers[i]);\n        result.push_back(delimeter);\n    }\n\n    result.push_back(numbers[n - 1]);\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_65_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> intersperse_simd(std::vector<int> numbers, int delimeter) {\n    std::vector<int> result;\n    size_t n = numbers.size();\n    \n    if (n == 0) return result;\n\n    result.reserve(n * 2 - 1);\n\n    // Load the delimiter into all positions of an SSE register\n    __m128i delim_vec = _mm_set1_epi32(delimeter);\n\n    size_t i = 0;\n    // Process elements in chunks of 4 using SIMD\n    for (; i + 4 <= n; i += 4) {\n        // Load 4 integers from the input vector\n        __m128i nums = _mm_loadu_si128((__m128i*)&numbers[i]);\n\n        // Prepare the output with interleaved delimiters\n        __m128i res1 = _mm_unpacklo_epi32(nums, delim_vec);\n        __m128i res2 = _mm_unpackhi_epi32(nums, delim_vec);\n\n        // Store the first 3 numbers and 2 delimiters\n        alignas(16) int temp[8];\n        _mm_store_si128((__m128i*)temp, res1);\n        _mm_store_si128((__m128i*)(temp + 4), res2);\n\n        // Append to result, skipping the last unnecessary delimiter\n        for (int j = 0; j < 7; ++j) {\n            result.push_back(temp[j]);\n        }\n    }\n\n    // Handle remaining elements\n    for (; i < n; ++i) {\n        result.push_back(numbers[i]);\n        if (i != n - 1) {\n            result.push_back(delimeter);\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_65_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> intersperse_simd(std::vector<int> numbers, int delimeter) {\n    std::vector<int> result;\n    size_t n = numbers.size();\n    \n    if (n == 0) return result;\n\n    result.reserve(n * 2 - 1);\n\n    // Load the delimiter into all positions of an SSE register\n    __m128i delim = _mm_set1_epi32(delimeter);\n\n    // Process elements in chunks of 4 using SSE\n    size_t i = 0;\n    for (; i + 4 <= n; i += 4) {\n        // Load 4 elements from the input vector\n        __m128i vec = _mm_loadu_si128((__m128i*)&numbers[i]);\n\n        // Prepare the output with interleaved delimiters\n        __m128i res1 = _mm_unpacklo_epi32(vec, delim);\n        __m128i res2 = _mm_unpackhi_epi32(vec, delim);\n\n        // Store the first 3 elements and their delimiters\n        alignas(16) int temp[8];\n        _mm_store_si128((__m128i*)temp, res1);\n        _mm_store_si128((__m128i*)(temp + 4), res2);\n\n        for (size_t j = 0; j < 7; ++j) {\n            result.push_back(temp[j]);\n        }\n    }\n\n    // Handle remaining elements\n    for (; i < n; ++i) {\n        result.push_back(numbers[i]);\n        if (i != n - 1) {\n            result.push_back(delimeter);\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_66_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int64_t> sum_product_simd(std::vector<int16_t> numbers) {\n    __m128i vsum = _mm_setzero_si128();\n    __m128i vprod = _mm_set_epi16(1, 1, 1, 1, 1, 1, 1, 1);\n    int n = numbers.size();\n\n    for (int i = 0; i < n; i += 8) {\n        __m128i vec = _mm_loadu_si128((__m128i*)&numbers[i]);\n        vsum = _mm_add_epi16(vsum, vec);\n\n        __m128i prod_temp = _mm_mullo_epi16(vprod, vec);\n        vprod = _mm_mullo_epi16(vprod, vec);\n    }\n\n    int16_t temp_sum[8];\n    _mm_storeu_si128((__m128i*)temp_sum, vsum);\n\n    int16_t temp_prod[8];\n    _mm_storeu_si128((__m128i*)temp_prod, vprod);\n\n    int64_t sum = 0;\n    int64_t product = 1;\n\n    for (int i = 0; i < 8; ++i) {\n        sum += temp_sum[i];\n        product *= temp_prod[i];\n    }\n\n    for (int i = (n / 8) * 8; i < n; ++i) {\n        sum += numbers[i];\n        product *= numbers[i];\n    }\n\n    return {sum, product};\n}\n```"}
{"task_id": "SimdBench_66_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int64_t> sum_product_simd(std::vector<int16_t> numbers) {\n    int64_t sum = 0;\n    int64_t product = 1;\n\n    size_t i = 0;\n    size_t size = numbers.size();\n\n    if (size == 0) {\n        return {sum, product};\n    }\n\n    __m128i vsum = _mm_setzero_si128();\n    __m128i vproduct = _mm_set_epi16(1, 1, 1, 1, 1, 1, 1, 1);\n\n    for (; i + 8 <= size; i += 8) {\n        __m128i vnumbers = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&numbers[i]));\n\n        // Horizontal sum of 8 elements\n        __m128i temp_sum = _mm_add_epi16(vsum, vnumbers);\n        vsum = temp_sum;\n\n        // Horizontal product of 8 elements\n        __m128i temp_product = _mm_mullo_epi16(vproduct, vnumbers);\n        vproduct = temp_product;\n    }\n\n    // Extract sums from the SSE register\n    int16_t temp_array[8];\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(temp_array), vsum);\n    for (int j = 0; j < 8; ++j) {\n        sum += temp_array[j];\n    }\n\n    // Extract products from the SSE register\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(temp_array), vproduct);\n    for (int j = 0; j < 8; ++j) {\n        product *= temp_array[j];\n    }\n\n    // Process remaining elements\n    for (; i < size; ++i) {\n        sum += numbers[i];\n        product *= numbers[i];\n    }\n\n    return {sum, product};\n}\n```"}
{"task_id": "SimdBench_66_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int64_t> sum_product_simd(std::vector<int16_t> numbers) {\n    int64_t sum = 0;\n    int64_t product = 1;\n\n    if (numbers.empty()) {\n        return {sum, product};\n    }\n\n    __m128i vsum = _mm_setzero_si128();\n    __m128i vproduct = _mm_set_epi16(1, 1, 1, 1, 1, 1, 1, 1);\n\n    size_t i = 0;\n    size_t size = numbers.size();\n\n    for (; i + 8 <= size; i += 8) {\n        __m128i v = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&numbers[i]));\n\n        // Sum\n        vsum = _mm_add_epi16(vsum, v);\n\n        // Product\n        __m128i p = vproduct;\n        for (int j = 0; j < 8; ++j) {\n            __m128i mul = _mm_mullo_epi16(_mm_shuffle_epi32(v, j), p);\n            p = _mm_blend_epi16(p, mul, 1 << j);\n        }\n        vproduct = p;\n    }\n\n    // Horizontal sum of vsum\n    int16_t temp[8];\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(temp), vsum);\n    for (int j = 0; j < 8; ++j) {\n        sum += temp[j];\n    }\n\n    // Horizontal product of vproduct\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(temp), vproduct);\n    for (int j = 0; j < 8; ++j) {\n        product *= temp[j];\n    }\n\n    // Process remaining elements\n    for (; i < size; ++i) {\n        sum += numbers[i];\n        product *= numbers[i];\n    }\n\n    return {sum, product};\n}\n```"}
{"task_id": "SimdBench_66_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int64_t> sum_product_simd(std::vector<int16_t> numbers) {\n    __m128i vsum = _mm_setzero_si128();\n    __m128i vprod = _mm_set_epi16(1, 1, 1, 1, 1, 1, 1, 1);\n    int n = numbers.size();\n\n    for (int i = 0; i < n; i += 8) {\n        __m128i v = _mm_loadu_si128((__m128i*)&numbers[i]);\n        vsum = _mm_add_epi16(vsum, v);\n\n        // Compute product using scalar expansion\n        for (int j = 0; j < 8 && (i + j) < n; ++j) {\n            int16_t val = numbers[i + j];\n            __m128i broadcast = _mm_set1_epi16(val);\n            vprod = _mm_mullo_epi16(vprod, broadcast);\n        }\n    }\n\n    // Horizontal sum for vsum\n    __m128i sum_hi = _mm_unpackhi_epi64(vsum, vsum);\n    vsum = _mm_add_epi16(vsum, sum_hi);\n    sum_hi = _mm_shuffle_epi32(vsum, 1);\n    vsum = _mm_add_epi16(vsum, sum_hi);\n    int64_t sum = _mm_extract_epi16(vsum, 0);\n\n    // Horizontal product for vprod\n    __m128i prod_hi = _mm_unpackhi_epi64(vprod, vprod);\n    vprod = _mm_mullo_epi16(vprod, prod_hi);\n    prod_hi = _mm_shuffle_epi32(vprod, 1);\n    vprod = _mm_mullo_epi16(vprod, prod_hi);\n    int64_t product = _mm_extract_epi16(vprod, 0);\n\n    return {sum, product};\n}\n```"}
{"task_id": "SimdBench_66_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int64_t> sum_product_simd(std::vector<int16_t> numbers) {\n    __m128i vsum = _mm_setzero_si128();\n    __m128i vprod = _mm_set_epi16(1, 1, 1, 1, 1, 1, 1, 1);\n    int n = numbers.size();\n\n    if (n == 0) {\n        return {0, 1};\n    }\n\n    int i = 0;\n    for (; i + 8 <= n; i += 8) {\n        __m128i vec = _mm_loadu_si128((__m128i*)&numbers[i]);\n        vsum = _mm_add_epi16(vsum, vec);\n\n        __m128i prod_low = _mm_mullo_epi16(vprod, vec);\n        __m128i prod_high = _mm_mulhi_epi16(vprod, vec);\n        vprod = _mm_unpacklo_epi16(prod_low, prod_high);\n    }\n\n    // Horizontal sum and product of vsum and vprod\n    int16_t temp_sum[8];\n    int16_t temp_prod[8];\n    _mm_storeu_si128((__m128i*)temp_sum, vsum);\n    _mm_storeu_si128((__m128i*)temp_prod, vprod);\n\n    int64_t sum = 0;\n    int64_t prod = 1;\n    for (int j = 0; j < 8; ++j) {\n        sum += temp_sum[j];\n        prod *= temp_prod[j];\n    }\n\n    // Process remaining elements\n    for (; i < n; ++i) {\n        sum += numbers[i];\n        prod *= numbers[i];\n    }\n\n    return {sum, prod};\n}\n```"}
{"task_id": "SimdBench_67_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> rolling_max_simd(std::vector<int> numbers) {\n    std::vector<int> result(numbers.size());\n    int n = numbers.size();\n\n    if (n == 0) return result;\n\n    // Initialize the first element\n    result[0] = numbers[0];\n    int max_val = numbers[0];\n\n    // Process in chunks of 4 using SSE2 intrinsics\n    for (int i = 1; i < n; i += 4) {\n        __m128i current_max = _mm_set1_epi32(max_val);\n        __m128i nums = _mm_loadu_si128((__m128i*)&numbers[i]);\n\n        // Compute the running maximum\n        current_max = _mm_max_epi32(current_max, nums);\n\n        // Store the results back to the result vector\n        _mm_storeu_si128((__m128i*)&result[i], current_max);\n\n        // Update the scalar max_val for the next iteration\n        int temp[4];\n        _mm_storeu_si128((__m128i*)temp, current_max);\n        for (int j = 0; j < 4 && (i + j) < n; ++j) {\n            max_val = std::max(max_val, temp[j]);\n        }\n    }\n\n    // Ensure the result vector is correctly filled for the last elements\n    for (int i = 1; i < n; ++i) {\n        result[i] = std::max(result[i], result[i - 1]);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_67_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> rolling_max_simd(std::vector<int> numbers) {\n    std::vector<int> result(numbers.size());\n    int n = numbers.size();\n    \n    if (n == 0) return result;\n\n    // Initialize the first element as it is the maximum by default\n    result[0] = numbers[0];\n    \n    // Process in chunks of 4 using SSE2 intrinsics\n    for (int i = 1; i < n; i += 4) {\n        // Load the previous maximum values into an SSE register\n        __m128i prev_max = _mm_loadu_si128((__m128i*)&result[i - 1]);\n        \n        // Load the next four elements from the input vector\n        __m128i current = _mm_loadu_si128((__m128i*)&numbers[i]);\n        \n        // Compute the rolling maximum using SSE max instruction\n        __m128i rolling_max = _mm_max_epi32(prev_max, current);\n        \n        // Store the result back into the result vector\n        _mm_storeu_si128((__m128i*)&result[i], rolling_max);\n        \n        // Ensure sequential correctness for the rolling maximum\n        for (int j = i; j < std::min(i + 4, n); ++j) {\n            result[j] = std::max(result[j], result[j - 1]);\n        }\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_67_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> rolling_max_simd(std::vector<int> numbers) {\n    std::vector<int> result(numbers.size());\n    int n = numbers.size();\n\n    if (n == 0) return result;\n\n    // Initialize the first element\n    result[0] = numbers[0];\n    int current_max = numbers[0];\n\n    // Process in chunks of 4 using SSE2\n    for (int i = 1; i < n; i += 4) {\n        // Load up to 4 integers into an SSE register\n        __m128i current_chunk;\n        if (i + 4 <= n) {\n            current_chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&numbers[i]));\n        } else {\n            // Handle the case where fewer than 4 elements remain\n            int temp[4] = {0};\n            for (int j = 0; j < n - i; ++j) {\n                temp[j] = numbers[i + j];\n            }\n            current_chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(temp));\n        }\n\n        // Broadcast the current maximum value across all lanes of an SSE register\n        __m128i max_vector = _mm_set1_epi32(current_max);\n\n        // Compute the running maximum\n        max_vector = _mm_max_epi32(max_vector, current_chunk);\n\n        // Store the results back into the result vector\n        int temp_result[4];\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(temp_result), max_vector);\n        for (int j = 0; j < 4 && i + j < n; ++j) {\n            result[i + j] = temp_result[j];\n            current_max = std::max(current_max, temp_result[j]);\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_67_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> rolling_max_simd(std::vector<int> numbers) {\n    std::vector<int> result(numbers.size());\n    int n = numbers.size();\n\n    if (n == 0) return result;\n\n    // Initialize the first element as it is the maximum at the start\n    result[0] = numbers[0];\n    \n    // Process in chunks of 4 using SSE2 intrinsics\n    for (int i = 1; i < n; i += 4) {\n        // Load previous results into SIMD register\n        __m128i prev_max;\n        if (i >= 4) {\n            prev_max = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&result[i - 4]));\n        } else {\n            prev_max = _mm_set1_epi32(result[0]);\n        }\n\n        // Load current numbers into SIMD register\n        __m128i curr_vals = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&numbers[i]));\n\n        // Compute rolling max for each lane\n        __m128i rolling_max = _mm_max_epi32(prev_max, curr_vals);\n\n        // Store the results back to the result vector\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i]), rolling_max);\n    }\n\n    // Post-process to ensure correctness for non-SIMD boundaries\n    for (int i = 1; i < n; ++i) {\n        result[i] = std::max(result[i], result[i - 1]);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_67_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> rolling_max_simd(std::vector<int> numbers) {\n    std::vector<int> result(numbers.size());\n    int n = numbers.size();\n\n    if (n == 0) return result;\n\n    // Initialize the first element as it is the maximum by default\n    result[0] = numbers[0];\n    int current_max = numbers[0];\n\n    // Process in chunks of 4 using SSE2 intrinsics\n    for (int i = 1; i < n; i += 4) {\n        // Load up to 4 integers into an SSE register\n        __m128i current_chunk;\n        if (i + 4 <= n) {\n            current_chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&numbers[i]));\n        } else {\n            // Handle the case where fewer than 4 elements remain\n            int temp[4] = {numbers[i], (i+1 < n) ? numbers[i+1] : current_max,\n                           (i+2 < n) ? numbers[i+2] : current_max,\n                           (i+3 < n) ? numbers[i+3] : current_max};\n            current_chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(temp));\n        }\n\n        // Broadcast the current maximum value across all lanes of an SSE register\n        __m128i max_vector = _mm_set1_epi32(current_max);\n\n        // Compare and update the maximum values in parallel\n        __m128i new_max_vector = _mm_max_epi32(max_vector, current_chunk);\n\n        // Store the updated maximums back into the result array\n        int temp_result[4];\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(temp_result), new_max_vector);\n\n        for (int j = 0; j < 4 && i + j < n; ++j) {\n            current_max = std::max(current_max, temp_result[j]);\n            result[i + j] = current_max;\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_68_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n#include <algorithm>\n\nstd::string string_xor_simd(std::string a, std::string b) {\n    size_t len_a = a.size();\n    size_t len_b = b.size();\n    size_t max_len = std::max(len_a, len_b);\n\n    // Pad the shorter string with leading zeros\n    a.insert(a.begin(), max_len - len_a, '0');\n    b.insert(b.begin(), max_len - len_b, '0');\n\n    // Result string\n    std::string result(max_len, '0');\n\n    // Process 16 characters at a time using SIMD\n    size_t i = 0;\n    for (; i + 16 <= max_len; i += 16) {\n        // Load 16 characters from each string into SIMD registers\n        __m128i va = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&a[i]));\n        __m128i vb = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&b[i]));\n\n        // Convert characters ('0'/'1') to bits (0/1)\n        __m128i mask = _mm_set1_epi8('0');\n        __m128i bits_a = _mm_sub_epi8(va, mask);\n        __m128i bits_b = _mm_sub_epi8(vb, mask);\n\n        // Perform XOR operation\n        __m128i xor_bits = _mm_xor_si128(bits_a, bits_b);\n\n        // Convert back to characters ('0'/'1')\n        __m128i xor_chars = _mm_add_epi8(xor_bits, mask);\n\n        // Store the result back into the result string\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i]), xor_chars);\n    }\n\n    // Process remaining characters (if any)\n    for (; i < max_len; ++i) {\n        result[i] = ((a[i] == '1') ^ (b[i] == '1')) ? '1' : '0';\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_68_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n#include <algorithm>\n\nstd::string string_xor_simd(std::string a, std::string b) {\n    size_t len_a = a.size();\n    size_t len_b = b.size();\n    size_t max_len = std::max(len_a, len_b);\n\n    // Pad the shorter string with '0's to match lengths\n    a.resize(max_len, '0');\n    b.resize(max_len, '0');\n\n    std::string result(max_len, '0');\n\n    // Process 16 characters at a time using SIMD\n    size_t i = 0;\n    for (; i + 16 <= max_len; i += 16) {\n        // Load 16 characters from each string into SIMD registers\n        __m128i va = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&a[i]));\n        __m128i vb = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&b[i]));\n\n        // XOR the two vectors\n        __m128i vxor = _mm_xor_si128(va, vb);\n\n        // Store the result back into the result string\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i]), vxor);\n    }\n\n    // Handle remaining characters (if any) after the SIMD loop\n    for (; i < max_len; ++i) {\n        result[i] = (a[i] == b[i]) ? '0' : '1';\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_68_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n#include <algorithm>\n\nstd::string string_xor_simd(std::string a, std::string b) {\n    size_t len_a = a.size();\n    size_t len_b = b.size();\n    size_t max_len = std::max(len_a, len_b);\n    \n    // Pad strings with '0' to make them equal in length\n    a.resize(max_len, '0');\n    b.resize(max_len, '0');\n\n    // Result string\n    std::string result(max_len, '0');\n\n    // Process 16 characters at a time using SIMD\n    size_t i = 0;\n    for (; i + 16 <= max_len; i += 16) {\n        // Load 16 characters from each string into SIMD registers\n        __m128i vec_a = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&a[i]));\n        __m128i vec_b = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&b[i]));\n\n        // XOR the two vectors\n        __m128i vec_result = _mm_xor_si128(vec_a, vec_b);\n\n        // Store the result back into the result string\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i]), vec_result);\n    }\n\n    // Handle remaining characters (if any)\n    for (; i < max_len; ++i) {\n        result[i] = (a[i] == b[i]) ? '0' : '1';\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_68_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n#include <algorithm>\n\nstd::string string_xor_simd(std::string a, std::string b) {\n    size_t len_a = a.size();\n    size_t len_b = b.size();\n    size_t max_len = std::max(len_a, len_b);\n    \n    // Pad strings with '0' to make them equal length\n    a.resize(max_len, '0');\n    b.resize(max_len, '0');\n\n    std::string result(max_len, '0');\n    size_t i = 0;\n\n    // Process 16 characters at a time using SSE2 intrinsics\n    for (; i + 15 < max_len; i += 16) {\n        // Load 16 characters from each string into SIMD registers\n        __m128i va = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&a[i]));\n        __m128i vb = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&b[i]));\n\n        // XOR the two vectors\n        __m128i vxor = _mm_xor_si128(va, vb);\n\n        // Store the result back into the result string\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i]), vxor);\n    }\n\n    // Process remaining characters (if any)\n    for (; i < max_len; ++i) {\n        result[i] = (a[i] ^ b[i]) ? '1' : '0';\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_68_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n#include <algorithm>\n\nstd::string string_xor_simd(std::string a, std::string b) {\n    size_t len_a = a.size();\n    size_t len_b = b.size();\n    size_t max_len = std::max(len_a, len_b);\n\n    // Pad the shorter string with '0's to match lengths\n    a.resize(max_len, '0');\n    b.resize(max_len, '0');\n\n    std::string result(max_len, '0');\n\n    // Process 16 characters at a time using SSE2 intrinsics\n    size_t i = 0;\n    for (; i + 16 <= max_len; i += 16) {\n        // Load 16 characters from each string into SIMD registers\n        __m128i va = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&a[i]));\n        __m128i vb = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&b[i]));\n\n        // XOR the two vectors\n        __m128i vxor = _mm_xor_si128(va, vb);\n\n        // Store the result back into the result string\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i]), vxor);\n    }\n\n    // Handle remaining characters (if any) after the last full SIMD block\n    for (; i < max_len; ++i) {\n        result[i] = (a[i] == b[i]) ? '0' : '1';\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_69_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n\nstd::string longest_simd(const std::vector<std::string> &strings) {\n    if (strings.empty()) return \"\";\n\n    const __m128i zero = _mm_setzero_si128();\n    size_t max_length = 0;\n    size_t max_index = 0;\n\n    for (size_t i = 0; i < strings.size(); ++i) {\n        const char *str = strings[i].c_str();\n        size_t length = 0;\n\n        // Process 16 bytes at a time using SSE2\n        size_t j = 0;\n        for (; j + 16 <= strings[i].size(); j += 16) {\n            __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(str + j));\n            __m128i cmp = _mm_cmpeq_epi8(chunk, zero);\n            int mask = _mm_movemask_epi8(cmp);\n\n            if (mask != 0) {\n                int first_zero = __builtin_ctz(mask);\n                length += first_zero;\n                break;\n            }\n            length += 16;\n        }\n\n        // Process remaining characters\n        for (; j < strings[i].size(); ++j) {\n            if (str[j] == '\\0') break;\n            ++length;\n        }\n\n        // Update max length and index\n        if (length > max_length) {\n            max_length = length;\n            max_index = i;\n        }\n    }\n\n    return strings[max_index];\n}\n```"}
{"task_id": "SimdBench_69_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n\nstd::string longest_simd(const std::vector<std::string> & strings) {\n    if (strings.empty()) return \"\";\n\n    const __m128i zero = _mm_setzero_si128();\n    size_t max_len = 0;\n    size_t max_idx = 0;\n\n    for (size_t i = 0; i < strings.size(); ++i) {\n        const std::string &str = strings[i];\n        size_t len = str.length();\n\n        // Compare current length with max_len using SIMD\n        __m128i vlen = _mm_cvtsi32_si128(len);\n        __m128i vmax = _mm_cvtsi32_si128(max_len);\n        __m128i cmp = _mm_cmpgt_epi32(vlen, vmax);\n\n        // Extract comparison result\n        int mask = _mm_movemask_epi8(cmp);\n        if (mask) {\n            max_len = len;\n            max_idx = i;\n        }\n    }\n\n    return strings[max_idx];\n}\n```"}
{"task_id": "SimdBench_69_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n\nstd::string longest_simd(const std::vector<std::string> & strings) {\n    if (strings.empty()) return \"\";\n\n    const __m128i zero = _mm_setzero_si128();\n    size_t max_len = 0;\n    size_t max_idx = 0;\n\n    for (size_t i = 0; i < strings.size(); ++i) {\n        const std::string &str = strings[i];\n        size_t len = str.length();\n\n        // Compare current length with max_len using SIMD\n        __m128i vlen = _mm_cvtsi32_si128(len);\n        __m128i vmax_len = _mm_cvtsi32_si128(max_len);\n        __m128i cmp = _mm_cmpgt_epi32(vlen, vmax_len);\n\n        // Extract comparison result\n        int mask = _mm_movemask_epi8(cmp);\n        if (mask) { // If any element indicates greater length\n            max_len = len;\n            max_idx = i;\n        }\n    }\n\n    return strings[max_idx];\n}\n```"}
{"task_id": "SimdBench_69_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n\nstd::string longest_simd(const std::vector<std::string> & strings) {\n    if (strings.empty()) return \"\";\n\n    const __m128i zero = _mm_setzero_si128();\n    size_t max_len = 0;\n    size_t max_idx = 0;\n\n    for (size_t i = 0; i < strings.size(); ++i) {\n        const std::string &str = strings[i];\n        size_t len = str.length();\n\n        // Load lengths into SIMD register\n        __m128i lens = _mm_set1_epi32(len);\n        __m128i max_lens = _mm_set1_epi32(max_len);\n\n        // Compare current length with max_len\n        __m128i cmp = _mm_cmpgt_epi32(lens, max_lens);\n\n        // Extract comparison result\n        int mask = _mm_movemask_ps((__m128)cmp);\n\n        if (mask & 0x1) { // If any of the comparisons is true\n            max_len = len;\n            max_idx = i;\n        }\n    }\n\n    return strings[max_idx];\n}\n```"}
{"task_id": "SimdBench_69_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n\nstd::string longest_simd(const std::vector<std::string> &strings) {\n    if (strings.empty()) return \"\";\n\n    const __m128i zero = _mm_setzero_si128();\n    size_t max_length = 0;\n    size_t max_index = 0;\n\n    for (size_t i = 0; i < strings.size(); ++i) {\n        const char *str = strings[i].c_str();\n        size_t length = 0;\n\n        // Process 16 bytes at a time using SSE2 intrinsics\n        size_t j = 0;\n        for (; j + 16 <= strings[i].size(); j += 16) {\n            __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(str + j));\n            __m128i cmp = _mm_cmpeq_epi8(chunk, zero);\n            int mask = _mm_movemask_epi8(cmp);\n\n            if (mask != 0) {\n                int first_zero = __builtin_ctz(mask);\n                length += first_zero;\n                break;\n            }\n            length += 16;\n        }\n\n        // Process remaining characters\n        for (; j < strings[i].size(); ++j) {\n            if (str[j] == '\\0') break;\n            ++length;\n        }\n\n        // Update max length and index if needed\n        if (length > max_length) {\n            max_length = length;\n            max_index = i;\n        }\n    }\n\n    return strings[max_index];\n}\n```"}
{"task_id": "SimdBench_70_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nuint64_t greatest_common_divisor_simd(uint64_t a, uint64_t b) {\n    __m128i va = _mm_set1_epi64x(a);\n    __m128i vb = _mm_set1_epi64x(b);\n\n    while (_mm_cvtsi128_si64(vb) != 0) {\n        __m128i vrem = _mm_setzero_si128();\n        // Compute remainder using scalar loop due to lack of SIMD modulo operation\n        uint64_t rem = _mm_cvtsi128_si64(va) % _mm_cvtsi128_si64(vb);\n        vrem = _mm_set1_epi64x(rem);\n        va = vb;\n        vb = vrem;\n    }\n\n    return _mm_cvtsi128_si64(va);\n}\n```"}
{"task_id": "SimdBench_70_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nuint64_t greatest_common_divisor_simd(uint64_t a, uint64_t b) {\n    __m128i va = _mm_set1_epi64x(a);\n    __m128i vb = _mm_set1_epi64x(b);\n\n    while (_mm_cvtsi128_si64(vb) != 0) {\n        __m128i vrem = _mm_setzero_si128();\n        // Compute remainder using scalar loop due to lack of SIMD modulo operation\n        uint64_t rem = _mm_cvtsi128_si64(va) % _mm_cvtsi128_si64(vb);\n        vrem = _mm_set1_epi64x(rem);\n        va = vb;\n        vb = vrem;\n    }\n\n    return _mm_cvtsi128_si64(va);\n}\n```"}
{"task_id": "SimdBench_70_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nuint64_t greatest_common_divisor_simd(uint64_t a, uint64_t b) {\n    __m128i va = _mm_set1_epi64x(a);\n    __m128i vb = _mm_set1_epi64x(b);\n\n    while (_mm_cvtsi128_si64(vb) != 0) {\n        __m128i vrem = _mm_setzero_si128();\n        // Compute remainder using scalar loop due to lack of SIMD modulo operation\n        uint64_t rem = _mm_cvtsi128_si64(va) % _mm_cvtsi128_si64(vb);\n        vrem = _mm_set1_epi64x(rem);\n        va = vb;\n        vb = vrem;\n    }\n\n    return _mm_cvtsi128_si64(va);\n}\n```"}
{"task_id": "SimdBench_70_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nuint64_t greatest_common_divisor_simd(uint64_t a, uint64_t b) {\n    __m128i va = _mm_set1_epi64x(a);\n    __m128i vb = _mm_set1_epi64x(b);\n\n    while (_mm_cvtsi128_si64(vb) != 0) {\n        __m128i vrem = _mm_setzero_si128();\n        // Compute remainder using scalar loop due to lack of SIMD modulo operation\n        uint64_t rem = _mm_cvtsi128_si64(va) % _mm_cvtsi128_si64(vb);\n        vrem = _mm_set1_epi64x(rem);\n        va = vb;\n        vb = vrem;\n    }\n\n    return _mm_cvtsi128_si64(va);\n}\n```"}
{"task_id": "SimdBench_70_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nuint64_t greatest_common_divisor_simd(uint64_t a, uint64_t b) {\n    __m128i va = _mm_set1_epi64x(a);\n    __m128i vb = _mm_set1_epi64x(b);\n\n    while (_mm_cvtsi128_si64(vb) != 0) {\n        __m128i vrem = _mm_setzero_si128();\n        // Compute remainder using scalar operations since SSE/SSE2 does not support 64-bit modulo directly\n        uint64_t rem = _mm_cvtsi128_si64(va) % _mm_cvtsi128_si64(vb);\n        vrem = _mm_set1_epi64x(rem);\n        va = vb;\n        vb = vrem;\n    }\n\n    return _mm_cvtsi128_si64(va);\n}\n```"}
{"task_id": "SimdBench_71_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <cmath>\n#include <limits>\n\nstd::vector<float> find_closest_elements_simd(std::vector<float> numbers) {\n    int n = numbers.size();\n    float min_diff = std::numeric_limits<float>::max();\n    float closest_a = 0.0f, closest_b = 0.0f;\n\n    // Ensure the vector is padded to a multiple of 4 for SIMD processing\n    int simd_size = (n + 3) & ~3;\n    std::vector<float> padded_numbers(simd_size, std::numeric_limits<float>::max());\n    for (int i = 0; i < n; ++i) {\n        padded_numbers[i] = numbers[i];\n    }\n\n    __m128* simd_data = reinterpret_cast<__m128*>(padded_numbers.data());\n\n    for (int i = 0; i < n; ++i) {\n        __m128 current = _mm_set1_ps(numbers[i]);\n        int j = 0;\n\n        // Process four elements at a time using SIMD\n        for (; j <= simd_size - 4; j += 4) {\n            __m128 other = simd_data[j / 4];\n            __m128 diff = _mm_sub_ps(current, other);\n            __m128 abs_diff = _mm_and_ps(diff, _mm_castsi128_ps(_mm_set1_epi32(0x7FFFFFFF)));\n\n            // Find the minimum difference in the current SIMD register\n            float diffs[4];\n            _mm_storeu_ps(diffs, abs_diff);\n\n            for (int k = 0; k < 4; ++k) {\n                if (j + k != i && diffs[k] < min_diff) {\n                    min_diff = diffs[k];\n                    closest_a = std::min(numbers[i], padded_numbers[j + k]);\n                    closest_b = std::max(numbers[i], padded_numbers[j + k]);\n                }\n            }\n        }\n\n        // Process remaining elements (if any)\n        for (; j < simd_size; ++j) {\n            if (j != i) {\n                float diff = std::abs(numbers[i] - padded_numbers[j]);\n                if (diff < min_diff) {\n                    min_diff = diff;\n                    closest_a = std::min(numbers[i], padded_numbers[j]);\n                    closest_b = std::max(numbers[i], padded_numbers[j]);\n                }\n            }\n        }\n    }\n\n    return {closest_a, closest_b};\n}\n```"}
{"task_id": "SimdBench_71_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<float> find_closest_elements_simd(std::vector<float> numbers) {\n    int n = numbers.size();\n    float min_diff = std::numeric_limits<float>::max();\n    float closest_a = 0.0f, closest_b = 0.0f;\n\n    // Ensure the vector is sorted for pairwise comparison\n    std::sort(numbers.begin(), numbers.end());\n\n    // Process elements in chunks of 4 using SSE\n    for (int i = 0; i < n - 1; i++) {\n        __m128 current = _mm_set1_ps(numbers[i]);\n        int j = i + 1;\n\n        // Process up to 4 elements at a time\n        for (; j <= n - 4; j += 4) {\n            __m128 next = _mm_loadu_ps(&numbers[j]);\n            __m128 diff = _mm_sub_ps(next, current);\n            diff = _mm_and_ps(diff, _mm_castsi128_ps(_mm_set1_epi32(0x7FFFFFFF))); // Absolute value\n            __m128 min_diff_vec = _mm_min_ps(diff, _mm_set1_ps(min_diff));\n\n            // Find the minimum difference in the vector\n            float diffs[4];\n            _mm_storeu_ps(diffs, min_diff_vec);\n            for (int k = 0; k < 4; k++) {\n                if (diffs[k] < min_diff) {\n                    min_diff = diffs[k];\n                    closest_a = numbers[i];\n                    closest_b = numbers[j + k];\n                }\n            }\n        }\n\n        // Process remaining elements\n        for (; j < n; j++) {\n            float diff = std::abs(numbers[j] - numbers[i]);\n            if (diff < min_diff) {\n                min_diff = diff;\n                closest_a = numbers[i];\n                closest_b = numbers[j];\n            }\n        }\n    }\n\n    return {closest_a, closest_b};\n}\n```"}
{"task_id": "SimdBench_71_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <cmath>\n#include <limits>\n\nstd::vector<float> find_closest_elements_simd(std::vector<float> numbers) {\n    int n = numbers.size();\n    float min_diff = std::numeric_limits<float>::max();\n    float closest_a = 0.0f, closest_b = 0.0f;\n\n    // Ensure the size is a multiple of 4 for SIMD processing\n    int simd_size = (n / 4) * 4;\n\n    for (int i = 0; i < simd_size; i += 4) {\n        __m128 vec1 = _mm_loadu_ps(&numbers[i]);\n\n        for (int j = i + 1; j < simd_size; j += 4) {\n            __m128 vec2 = _mm_loadu_ps(&numbers[j]);\n\n            // Compute absolute differences between all pairs in vec1 and vec2\n            __m128 diff1 = _mm_sub_ps(vec1, _mm_shuffle_ps(vec2, vec2, _MM_SHUFFLE(0, 0, 0, 0)));\n            __m128 diff2 = _mm_sub_ps(vec1, _mm_shuffle_ps(vec2, vec2, _MM_SHUFFLE(1, 1, 1, 1)));\n            __m128 diff3 = _mm_sub_ps(vec1, _mm_shuffle_ps(vec2, vec2, _MM_SHUFFLE(2, 2, 2, 2)));\n            __m128 diff4 = _mm_sub_ps(vec1, _mm_shuffle_ps(vec2, vec2, _MM_SHUFFLE(3, 3, 3, 3)));\n\n            // Absolute values of differences\n            diff1 = _mm_and_ps(diff1, _mm_castsi128_ps(_mm_set1_epi32(0x7FFFFFFF)));\n            diff2 = _mm_and_ps(diff2, _mm_castsi128_ps(_mm_set1_epi32(0x7FFFFFFF)));\n            diff3 = _mm_and_ps(diff3, _mm_castsi128_ps(_mm_set1_epi32(0x7FFFFFFF)));\n            diff4 = _mm_and_ps(diff4, _mm_castsi128_ps(_mm_set1_epi32(0x7FFFFFFF)));\n\n            // Find minimum difference in each vector\n            __m128 min_diff_vec = _mm_min_ps(_mm_min_ps(diff1, diff2), _mm_min_ps(diff3, diff4));\n            float current_min_diff = _mm_cvtss_f32(_mm_min_ps(min_diff_vec, _mm_shuffle_ps(min_diff_vec, min_diff_vec, _MM_SHUFFLE(1, 1, 1, 1))));\n\n            if (current_min_diff < min_diff) {\n                min_diff = current_min_diff;\n                closest_a = numbers[i];\n                closest_b = numbers[j];\n            }\n        }\n    }\n\n    // Handle remaining elements that don't fit into SIMD blocks\n    for (int i = simd_size; i < n; ++i) {\n        for (int j = i + 1; j < n; ++j) {\n            float diff = std::abs(numbers[i] - numbers[j]);\n            if (diff < min_diff) {\n                min_diff = diff;\n                closest_a = numbers[i];\n                closest_b = numbers[j];\n            }\n        }\n    }\n\n    return {closest_a, closest_b};\n}\n```"}
{"task_id": "SimdBench_71_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <cmath>\n#include <limits>\n\nstd::vector<float> find_closest_elements_simd(std::vector<float> numbers) {\n    int n = numbers.size();\n    float min_diff = std::numeric_limits<float>::max();\n    float closest_a = 0.0f, closest_b = 0.0f;\n\n    // Ensure the size is a multiple of 4 for SIMD processing\n    int simd_size = (n / 4) * 4;\n\n    for (int i = 0; i < simd_size; i += 4) {\n        __m128 v1 = _mm_loadu_ps(&numbers[i]);\n\n        for (int j = i + 1; j < simd_size; j += 4) {\n            __m128 v2 = _mm_loadu_ps(&numbers[j]);\n\n            // Compute absolute differences between all pairs in the vectors\n            __m128 diff = _mm_sub_ps(v1, v2);\n            diff = _mm_and_ps(diff, _mm_castsi128_ps(_mm_set1_epi32(0x7FFFFFFF))); // Absolute value\n\n            // Find the minimum difference in the vector\n            float diffs[4];\n            _mm_storeu_ps(diffs, diff);\n\n            for (int k = 0; k < 4; ++k) {\n                if (diffs[k] < min_diff && diffs[k] > 0.0f) {\n                    min_diff = diffs[k];\n                    closest_a = numbers[i + k];\n                    closest_b = numbers[j + k];\n                }\n            }\n        }\n    }\n\n    // Process remaining elements that didn't fit into SIMD blocks\n    for (int i = simd_size; i < n; ++i) {\n        for (int j = i + 1; j < n; ++j) {\n            float diff = std::abs(numbers[i] - numbers[j]);\n            if (diff < min_diff && diff > 0.0f) {\n                min_diff = diff;\n                closest_a = numbers[i];\n                closest_b = numbers[j];\n            }\n        }\n    }\n\n    return {std::min(closest_a, closest_b), std::max(closest_a, closest_b)};\n}\n```"}
{"task_id": "SimdBench_71_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <cmath>\n#include <limits>\n\nstd::vector<float> find_closest_elements_simd(std::vector<float> numbers) {\n    int n = numbers.size();\n    float closest_pair[2] = {0.0f, 0.0f};\n    float min_diff = std::numeric_limits<float>::max();\n\n    // Ensure the size is a multiple of 4 for SIMD processing\n    int simd_size = (n / 4) * 4;\n\n    for (int i = 0; i < simd_size; i += 4) {\n        __m128 v1 = _mm_loadu_ps(&numbers[i]);\n\n        for (int j = i + 1; j < simd_size; j += 4) {\n            __m128 v2 = _mm_loadu_ps(&numbers[j]);\n\n            // Compute absolute differences between all pairs in the vectors\n            __m128 diff = _mm_sub_ps(v1, v2);\n            diff = _mm_and_ps(diff, _mm_castsi128_ps(_mm_set1_epi32(0x7FFFFFFF))); // Absolute value\n\n            // Find the minimum difference in the current SIMD register\n            float diffs[4];\n            _mm_storeu_ps(diffs, diff);\n\n            for (int k = 0; k < 4; ++k) {\n                if (diffs[k] < min_diff && diffs[k] > 0.0f) {\n                    min_diff = diffs[k];\n                    closest_pair[0] = numbers[i + k];\n                    closest_pair[1] = numbers[j + k];\n                }\n            }\n        }\n    }\n\n    // Handle remaining elements that don't fit into SIMD registers\n    for (int i = simd_size; i < n; ++i) {\n        for (int j = i + 1; j < n; ++j) {\n            float diff = std::abs(numbers[i] - numbers[j]);\n            if (diff < min_diff && diff > 0.0f) {\n                min_diff = diff;\n                closest_pair[0] = numbers[i];\n                closest_pair[1] = numbers[j];\n            }\n        }\n    }\n\n    return std::vector<float>(closest_pair, closest_pair + 2);\n}\n```"}
{"task_id": "SimdBench_72_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<float> rescale_to_unit_simd(std::vector<float> numbers) {\n    int n = numbers.size();\n    std::vector<float> result(n);\n\n    // Find min and max using SIMD\n    __m128 vmin = _mm_set1_ps(numbers[0]);\n    __m128 vmax = _mm_set1_ps(numbers[0]);\n\n    for (int i = 0; i < n; i += 4) {\n        __m128 v = _mm_loadu_ps(&numbers[i]);\n        vmin = _mm_min_ps(vmin, v);\n        vmax = _mm_max_ps(vmax, v);\n    }\n\n    // Horizontal reduction to get scalar min and max\n    float min_val, max_val;\n    {\n        __m128 temp = _mm_shuffle_ps(vmin, vmin, _MM_SHUFFLE(1, 0, 3, 2));\n        vmin = _mm_min_ps(vmin, temp);\n        temp = _mm_shuffle_ps(vmin, vmin, _MM_SHUFFLE(2, 3, 0, 1));\n        vmin = _mm_min_ps(vmin, temp);\n        _mm_store_ss(&min_val, vmin);\n\n        temp = _mm_shuffle_ps(vmax, vmax, _MM_SHUFFLE(1, 0, 3, 2));\n        vmax = _mm_max_ps(vmax, temp);\n        temp = _mm_shuffle_ps(vmax, vmax, _MM_SHUFFLE(2, 3, 0, 1));\n        vmax = _mm_max_ps(vmax, temp);\n        _mm_store_ss(&max_val, vmax);\n    }\n\n    float range = max_val - min_val;\n    if (range == 0.0f) {\n        std::fill(result.begin(), result.end(), 0.0f);\n        return result;\n    }\n\n    __m128 vrange = _mm_set1_ps(range);\n    __m128 vmin_vec = _mm_set1_ps(min_val);\n\n    // Rescale using SIMD\n    for (int i = 0; i < n; i += 4) {\n        __m128 v = _mm_loadu_ps(&numbers[i]);\n        __m128 rescaled = _mm_div_ps(_mm_sub_ps(v, vmin_vec), vrange);\n        _mm_storeu_ps(&result[i], rescaled);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_72_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<float> rescale_to_unit_simd(std::vector<float> numbers) {\n    int n = numbers.size();\n    std::vector<float> result(n);\n\n    // Find min and max using SIMD\n    __m128 vmin = _mm_set1_ps(numbers[0]);\n    __m128 vmax = _mm_set1_ps(numbers[0]);\n\n    for (int i = 0; i < n; i += 4) {\n        __m128 v = _mm_loadu_ps(&numbers[i]);\n        vmin = _mm_min_ps(vmin, v);\n        vmax = _mm_max_ps(vmax, v);\n    }\n\n    // Horizontal reduction to get scalar min and max\n    float min_val, max_val;\n    float temp[4];\n    _mm_storeu_ps(temp, vmin);\n    min_val = std::min({temp[0], temp[1], temp[2], temp[3]});\n    _mm_storeu_ps(temp, vmax);\n    max_val = std::max({temp[0], temp[1], temp[2], temp[3]});\n\n    // Compute scale factor\n    float scale = (max_val != min_val) ? 1.0f / (max_val - min_val) : 0.0f;\n\n    // Rescale using SIMD\n    __m128 vscale = _mm_set1_ps(scale);\n    __m128 vmin_val = _mm_set1_ps(min_val);\n\n    for (int i = 0; i < n; i += 4) {\n        __m128 v = _mm_loadu_ps(&numbers[i]);\n        __m128 vrescaled = _mm_mul_ps(_mm_sub_ps(v, vmin_val), vscale);\n        _mm_storeu_ps(&result[i], vrescaled);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_72_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<float> rescale_to_unit_simd(std::vector<float> numbers) {\n    int n = numbers.size();\n    std::vector<float> result(n);\n\n    // Find min and max using SIMD\n    __m128 vmin = _mm_set1_ps(numbers[0]);\n    __m128 vmax = _mm_set1_ps(numbers[0]);\n\n    for (int i = 0; i < n; i += 4) {\n        __m128 v = _mm_loadu_ps(&numbers[i]);\n        vmin = _mm_min_ps(vmin, v);\n        vmax = _mm_max_ps(vmax, v);\n    }\n\n    // Horizontal min and max reduction\n    float min_val, max_val;\n    float temp[4];\n    _mm_storeu_ps(temp, vmin);\n    min_val = std::min({temp[0], temp[1], temp[2], temp[3]});\n    _mm_storeu_ps(temp, vmax);\n    max_val = std::max({temp[0], temp[1], temp[2], temp[3]});\n\n    // Compute scale and offset\n    float scale = (max_val != min_val) ? 1.0f / (max_val - min_val) : 0.0f;\n\n    // Rescale using SIMD\n    __m128 vscale = _mm_set1_ps(scale);\n    __m128 voffset = _mm_set1_ps(-min_val);\n\n    for (int i = 0; i < n; i += 4) {\n        __m128 v = _mm_loadu_ps(&numbers[i]);\n        v = _mm_add_ps(v, voffset);\n        v = _mm_mul_ps(v, vscale);\n        _mm_storeu_ps(&result[i], v);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_72_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<float> rescale_to_unit_simd(std::vector<float> numbers) {\n    size_t n = numbers.size();\n    std::vector<float> result(n);\n\n    // Find min and max using SIMD\n    __m128 vmin = _mm_set1_ps(numbers[0]);\n    __m128 vmax = _mm_set1_ps(numbers[0]);\n\n    for (size_t i = 0; i < n; i += 4) {\n        __m128 v = _mm_loadu_ps(&numbers[i]);\n        vmin = _mm_min_ps(vmin, v);\n        vmax = _mm_max_ps(vmax, v);\n    }\n\n    // Horizontal reduction to find the true min and max\n    float min_val, max_val;\n    {\n        __m128 temp = vmin;\n        temp = _mm_min_ps(temp, _mm_shuffle_ps(temp, temp, _MM_SHUFFLE(1, 0, 3, 2)));\n        temp = _mm_min_ps(temp, _mm_shuffle_ps(temp, temp, _MM_SHUFFLE(2, 3, 0, 1)));\n        _mm_store_ss(&min_val, temp);\n    }\n    {\n        __m128 temp = vmax;\n        temp = _mm_max_ps(temp, _mm_shuffle_ps(temp, temp, _MM_SHUFFLE(1, 0, 3, 2)));\n        temp = _mm_max_ps(temp, _mm_shuffle_ps(temp, temp, _MM_SHUFFLE(2, 3, 0, 1)));\n        _mm_store_ss(&max_val, temp);\n    }\n\n    // Compute scale factor\n    float range = max_val - min_val;\n    __m128 scale = _mm_set1_ps(1.0f / range);\n    __m128 offset = _mm_set1_ps(-min_val);\n\n    // Rescale the numbers\n    for (size_t i = 0; i < n; i += 4) {\n        __m128 v = _mm_loadu_ps(&numbers[i]);\n        v = _mm_add_ps(v, offset);\n        v = _mm_mul_ps(v, scale);\n        _mm_storeu_ps(&result[i], v);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_72_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<float> rescale_to_unit_simd(std::vector<float> numbers) {\n    size_t n = numbers.size();\n    std::vector<float> result(n);\n\n    // Find min and max using SIMD\n    __m128 vmin = _mm_set1_ps(numbers[0]);\n    __m128 vmax = _mm_set1_ps(numbers[0]);\n\n    for (size_t i = 0; i < n; i += 4) {\n        __m128 v = _mm_loadu_ps(&numbers[i]);\n        vmin = _mm_min_ps(vmin, v);\n        vmax = _mm_max_ps(vmax, v);\n    }\n\n    // Horizontal min and max reduction\n    float min_val, max_val;\n    float temp[4];\n    _mm_storeu_ps(temp, vmin);\n    min_val = std::min({temp[0], temp[1], temp[2], temp[3]});\n    _mm_storeu_ps(temp, vmax);\n    max_val = std::max({temp[0], temp[1], temp[2], temp[3]});\n\n    // Compute scale and offset\n    float scale = (max_val != min_val) ? 1.0f / (max_val - min_val) : 0.0f;\n\n    // Rescale using SIMD\n    __m128 vscale = _mm_set1_ps(scale);\n    __m128 vmin_val = _mm_set1_ps(min_val);\n\n    for (size_t i = 0; i < n; i += 4) {\n        __m128 v = _mm_loadu_ps(&numbers[i]);\n        __m128 vrescaled = _mm_mul_ps(_mm_sub_ps(v, vmin_val), vscale);\n        _mm_storeu_ps(&result[i], vrescaled);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_73_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nuint64_t largest_divisor_simd(uint64_t n) {\n    __m128i vn = _mm_set1_epi64x(n);\n    __m128i vdivisor = _mm_set_epi64x(n / 2, n / 2 - 1);\n    __m128i vremainder = _mm_setzero_si128();\n    __m128i vresult = _mm_setzero_si128();\n\n    for (int i = n / 2; i >= 1; i -= 2) {\n        vremainder = _mm_rem_epi64(vn, vdivisor);\n        __m128i mask = _mm_cmpeq_epi64(vremainder, _mm_setzero_si128());\n        vresult = _mm_blendv_epi8(vresult, vdivisor, mask);\n\n        vdivisor = _mm_sub_epi64(vdivisor, _mm_set1_epi64x(2));\n    }\n\n    uint64_t results[2];\n    _mm_storeu_si128((__m128i*)results, vresult);\n    return results[0] > results[1] ? results[0] : results[1];\n}\n```"}
{"task_id": "SimdBench_73_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nuint64_t largest_divisor_simd(uint64_t n) {\n    __m128i vn = _mm_set1_epi64x(n);\n    __m128i vdivisor = _mm_set_epi64x(n / 2, n / 2 - 1);\n    __m128i vone = _mm_set1_epi64x(1);\n    __m128i vresult = _mm_setzero_si128();\n    __m128i vremainder;\n\n    for (uint64_t i = n / 2; i >= 1; i -= 2) {\n        vremainder = _mm_rem_epi64(vn, vdivisor);\n        __m128i mask = _mm_cmpeq_epi64(vremainder, _mm_setzero_si128());\n        vresult = _mm_blendv_epi8(vresult, vdivisor, mask);\n        vdivisor = _mm_sub_epi64(vdivisor, vone);\n    }\n\n    uint64_t results[2];\n    _mm_storeu_si128((__m128i*)results, vresult);\n    return results[0] > results[1] ? results[0] : results[1];\n}\n```"}
{"task_id": "SimdBench_73_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nuint64_t largest_divisor_simd(uint64_t n) {\n    __m128i vn = _mm_set1_epi64x(n);\n    __m128i vdivisor = _mm_set_epi64x(n / 2, n / 2 - 1);\n    __m128i vone = _mm_set1_epi64x(1);\n    __m128i vresult = _mm_setzero_si128();\n\n    for (uint64_t i = n / 2; i >= 1; i -= 2) {\n        __m128i vremainder = _mm_rem_epi64(vn, vdivisor);\n        __m128i vmask = _mm_cmpeq_epi64(vremainder, _mm_setzero_si128());\n\n        if (_mm_movemask_epi8(vmask) & 0xF) {\n            vresult = _mm_blendv_epi8(vresult, vdivisor, vmask);\n            break;\n        }\n\n        vdivisor = _mm_sub_epi64(vdivisor, vone);\n    }\n\n    uint64_t results[2];\n    _mm_storeu_si128((__m128i*)results, vresult);\n    return results[0] > results[1] ? results[0] : results[1];\n}\n```"}
{"task_id": "SimdBench_73_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nuint64_t largest_divisor_simd(uint64_t n) {\n    __m128i vn = _mm_set1_epi64x(n);\n    __m128i vdivisor = _mm_set_epi64x(n / 2, n / 2 - 1);\n    __m128i vone = _mm_set1_epi64x(1);\n    __m128i vresult = _mm_setzero_si128();\n    \n    for (uint64_t i = n / 2; i >= 1; i -= 2) {\n        __m128i vremainder = _mm_rem_epu64(vn, vdivisor);\n        __m128i vmask = _mm_cmpeq_epi64(vremainder, _mm_setzero_si128());\n        \n        vresult = _mm_blendv_epi8(vresult, vdivisor, vmask);\n        vdivisor = _mm_sub_epi64(vdivisor, vone);\n        \n        uint64_t result[2];\n        _mm_storeu_si128((__m128i*)result, vresult);\n        \n        if (result[0] != 0 && result[0] < n) return result[0];\n        if (result[1] != 0 && result[1] < n) return result[1];\n    }\n    \n    return 1;\n}\n```"}
{"task_id": "SimdBench_73_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nuint64_t largest_divisor_simd(uint64_t n) {\n    __m128i vn = _mm_set1_epi64x(n);\n    __m128i vdivisor = _mm_set_epi64x(n / 2, n / 2 - 1);\n    __m128i vstep = _mm_set1_epi64x(-2);\n    __m128i vresult = _mm_setzero_si128();\n\n    while (true) {\n        __m128i vremainder = _mm_rem_epi64(vn, vdivisor);\n        __m128i vmask = _mm_cmpeq_epi64(vremainder, _mm_setzero_si128());\n\n        if (_mm_movemask_epi8(vmask)) {\n            vresult = _mm_blendv_epi8(vresult, vdivisor, vmask);\n            break;\n        }\n\n        vdivisor = _mm_add_epi64(vdivisor, vstep);\n\n        __m128i vcmp = _mm_cmpgt_epi64(vdivisor, _mm_setzero_si128());\n        if (_mm_movemask_epi8(vcmp) == 0) {\n            break;\n        }\n    }\n\n    uint64_t result[2];\n    _mm_storeu_si128((__m128i*)result, vresult);\n    return result[0] > result[1] ? result[0] : result[1];\n}\n```"}
{"task_id": "SimdBench_74_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> factorize_simd(int n) {\n    std::vector<int> factors;\n    if (n <= 1) return factors;\n\n    __m128i vn = _mm_set1_epi32(n);\n    __m128i vfactor = _mm_set1_epi32(2);\n\n    while (true) {\n        __m128i vremainder = _mm_setzero_si128();\n        __m128i vquotient = _mm_div_epi32(vn, vfactor); // Approximation for division\n        __m128i vmul = _mm_mullo_epi32(vquotient, vfactor);\n\n        int mask = _mm_movemask_epi8(_mm_cmpeq_epi32(vmul, vn));\n        if (mask == 0xFFFF) {\n            factors.push_back(_mm_cvtsi128_si32(vfactor));\n            vn = vquotient;\n        } else {\n            vfactor = _mm_add_epi32(vfactor, _mm_set1_epi32(1));\n        }\n\n        int current_n = _mm_cvtsi128_si32(vn);\n        if (current_n == 1) break;\n    }\n\n    return factors;\n}\n```"}
{"task_id": "SimdBench_74_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> factorize_simd(int n) {\n    std::vector<int> factors;\n    if (n <= 1) return factors;\n\n    __m128i vn = _mm_set1_epi32(n);\n    __m128i vfactor = _mm_set1_epi32(2);\n\n    while (true) {\n        __m128i vremainder = _mm_setzero_si128();\n        __m128i vquotient = _mm_div_epi32(vn, vfactor, &vremainder);\n\n        __m128i vcmp = _mm_cmpeq_epi32(vremainder, _mm_setzero_si128());\n        int mask = _mm_movemask_ps((__m128)vcmp);\n\n        if (mask == 0xF) {\n            factors.push_back(_mm_cvtsi128_si32(vfactor));\n            vn = vquotient;\n        } else {\n            vfactor = _mm_add_epi32(vfactor, _mm_set1_epi32(1));\n        }\n\n        int current_n = _mm_cvtsi128_si32(vn);\n        if (current_n == 1) break;\n    }\n\n    return factors;\n}\n```"}
{"task_id": "SimdBench_74_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> factorize_simd(int n) {\n    std::vector<int> factors;\n    if (n <= 1) return factors;\n\n    __m128i vn = _mm_set1_epi32(n);\n    __m128i vfactor = _mm_set1_epi32(2);\n\n    while (true) {\n        __m128i vremainder = _mm_setzero_si128();\n        __m128i vquotient = _mm_div_epi32(vn, vfactor);\n        __m128i vmul = _mm_mullo_epi32(vquotient, vfactor);\n\n        int mask = _mm_movemask_epi8(_mm_cmpeq_epi32(vmul, vn));\n        if (mask == 0xFFFF) {\n            factors.push_back(_mm_cvtsi128_si32(vfactor));\n            vn = vquotient;\n        } else {\n            vfactor = _mm_add_epi32(vfactor, _mm_set1_epi32(1));\n        }\n\n        int current_n = _mm_cvtsi128_si32(vn);\n        if (current_n == 1) break;\n    }\n\n    return factors;\n}\n```"}
{"task_id": "SimdBench_74_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> factorize_simd(int n) {\n    std::vector<int> factors;\n    if (n <= 1) return factors;\n\n    __m128i vn = _mm_set1_epi32(n);\n    __m128i vfactor = _mm_set1_epi32(2);\n\n    while (true) {\n        __m128i vremainder = _mm_setzero_si128();\n        __m128i vquotient = _mm_div_epi32(vn, vfactor, &vremainder);\n\n        __m128i vcmp = _mm_cmpeq_epi32(vremainder, _mm_setzero_si128());\n        int mask = _mm_movemask_ps(_mm_castsi128_ps(vcmp));\n\n        if (mask == 0) {\n            vfactor = _mm_add_epi32(vfactor, _mm_set1_epi32(1));\n            if (_mm_cvtsi128_si32(vfactor) * _mm_cvtsi128_si32(vfactor) > n) break;\n        } else {\n            vn = vquotient;\n            factors.push_back(_mm_cvtsi128_si32(vfactor));\n            if (_mm_cvtsi128_si32(vn) == 1) break;\n        }\n    }\n\n    if (n != 1) factors.push_back(n);\n    return factors;\n}\n```"}
{"task_id": "SimdBench_74_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> factorize_simd(int n) {\n    std::vector<int> factors;\n    if (n <= 1) return factors;\n\n    __m128i vn = _mm_set1_epi32(n);\n    __m128i vfactor = _mm_set1_epi32(2);\n\n    while (true) {\n        __m128i vremainder = _mm_setzero_si128();\n        __m128i vquotient = _mm_div_epi32(vn, vfactor);\n        __m128i vmul = _mm_mullo_epi32(vquotient, vfactor);\n\n        int mask = _mm_movemask_epi8(_mm_cmpeq_epi32(vmul, vn));\n        if (mask == 0xFFFF) {\n            factors.push_back(_mm_cvtsi128_si32(vfactor));\n            vn = vquotient;\n        } else {\n            vfactor = _mm_add_epi32(vfactor, _mm_set1_epi32(1));\n        }\n\n        int current_n = _mm_cvtsi128_si32(vn);\n        if (current_n == 1) break;\n    }\n\n    return factors;\n}\n```"}
{"task_id": "SimdBench_75_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<float> get_positive_simd(const std::vector<float> & l) {\n    std::vector<float> result;\n    result.reserve(l.size());\n\n    __m128 zero = _mm_setzero_ps();\n    size_t i = 0;\n\n    // Process 4 floats at a time using SIMD\n    for (; i + 4 <= l.size(); i += 4) {\n        __m128 vec = _mm_loadu_ps(&l[i]);          // Load 4 floats\n        __m128 mask = _mm_cmpgt_ps(vec, zero);     // Compare each float with 0\n        __m128 positive = _mm_and_ps(vec, mask);   // Zero out negative values\n\n        // Store the positive values into the result vector\n        alignas(16) float temp[4];\n        _mm_store_ps(temp, positive);\n\n        for (int j = 0; j < 4; ++j) {\n            if (temp[j] > 0.0f) {\n                result.push_back(temp[j]);\n            }\n        }\n    }\n\n    // Process remaining elements\n    for (; i < l.size(); ++i) {\n        if (l[i] > 0.0f) {\n            result.push_back(l[i]);\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_75_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<float> get_positive_simd(const std::vector<float> & l) {\n    std::vector<float> result;\n    result.reserve(l.size());\n\n    __m128 zero = _mm_setzero_ps();\n    size_t i = 0;\n\n    // Process 4 floats at a time using SIMD\n    for (; i + 4 <= l.size(); i += 4) {\n        __m128 vec = _mm_loadu_ps(&l[i]);         // Load 4 floats into SIMD register\n        __m128 mask = _mm_cmpgt_ps(vec, zero);    // Compare each float with 0 (vec > 0)\n        __m128 positive = _mm_and_ps(vec, mask);  // Zero out negative values\n\n        // Store the positive values in the result vector\n        alignas(16) float temp[4];\n        _mm_store_ps(temp, positive);\n\n        for (int j = 0; j < 4; ++j) {\n            if (temp[j] > 0.0f) {\n                result.push_back(temp[j]);\n            }\n        }\n    }\n\n    // Process remaining elements\n    for (; i < l.size(); ++i) {\n        if (l[i] > 0.0f) {\n            result.push_back(l[i]);\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_75_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<float> get_positive_simd(const std::vector<float> & l) {\n    std::vector<float> result;\n    result.reserve(l.size());\n\n    __m128 zero = _mm_setzero_ps();\n    size_t i = 0;\n\n    // Process 4 floats at a time using SIMD\n    for (; i + 4 <= l.size(); i += 4) {\n        __m128 vec = _mm_loadu_ps(&l[i]);         // Load 4 floats from the input\n        __m128 mask = _mm_cmpgt_ps(vec, zero);    // Compare each float with 0\n        __m128 positive = _mm_and_ps(vec, mask);  // Zero out negative values\n\n        // Store the positive values into the result vector\n        alignas(16) float temp[4];\n        _mm_store_ps(temp, positive);\n\n        for (int j = 0; j < 4; ++j) {\n            if (temp[j] > 0.0f) {\n                result.push_back(temp[j]);\n            }\n        }\n    }\n\n    // Process remaining elements\n    for (; i < l.size(); ++i) {\n        if (l[i] > 0.0f) {\n            result.push_back(l[i]);\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_75_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<float> get_positive_simd(const std::vector<float> & l) {\n    std::vector<float> result;\n    result.reserve(l.size());\n\n    __m128 zero = _mm_setzero_ps();\n    size_t i = 0;\n\n    // Process 4 floats at a time using SIMD\n    for (; i + 4 <= l.size(); i += 4) {\n        __m128 vec = _mm_loadu_ps(&l[i]);         // Load 4 floats into SIMD register\n        __m128 mask = _mm_cmpgt_ps(vec, zero);    // Compare each float with 0 (greater than)\n        __m128 positive = _mm_and_ps(vec, mask);  // Zero out negative values\n\n        // Store the positive values into the result vector\n        alignas(16) float temp[4];\n        _mm_store_ps(temp, positive);\n\n        for (int j = 0; j < 4; ++j) {\n            if (temp[j] > 0.0f) {\n                result.push_back(temp[j]);\n            }\n        }\n    }\n\n    // Process remaining elements\n    for (; i < l.size(); ++i) {\n        if (l[i] > 0.0f) {\n            result.push_back(l[i]);\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_75_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<float> get_positive_simd(const std::vector<float> & l) {\n    std::vector<float> result;\n    result.reserve(l.size());\n\n    __m128 zero = _mm_setzero_ps();\n    size_t i = 0;\n\n    // Process 4 floats at a time\n    for (; i + 4 <= l.size(); i += 4) {\n        __m128 vec = _mm_loadu_ps(&l[i]);\n        __m128 mask = _mm_cmpgt_ps(vec, zero);\n\n        // Store positive values into result\n        float temp[4];\n        _mm_storeu_ps(temp, vec);\n        int mask_bits = _mm_movemask_ps(mask);\n\n        if (mask_bits & 0x1) result.push_back(temp[0]);\n        if (mask_bits & 0x2) result.push_back(temp[1]);\n        if (mask_bits & 0x4) result.push_back(temp[2]);\n        if (mask_bits & 0x8) result.push_back(temp[3]);\n    }\n\n    // Process remaining elements\n    for (; i < l.size(); ++i) {\n        if (l[i] > 0.0f) {\n            result.push_back(l[i]);\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_76_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool is_prime_simd(int64_t n) {\n    if (n <= 1) return false;\n    if (n == 2 || n == 3) return true;\n    if (n % 2 == 0 || n % 3 == 0) return false;\n\n    __m128i zero = _mm_setzero_si128();\n    __m128i num = _mm_set1_epi64x(n);\n    __m128i base = _mm_setr_epi64x(5, 7); // Start testing from 5 and 7\n    __m128i step = _mm_set1_epi64x(6);\n\n    for (int64_t i = 5; i * i <= n; i += 6) {\n        __m128i divisors = _mm_add_epi64(base, _mm_set1_epi64x(i - 5));\n        __m128i mod1 = _mm_rem_epi64(num, _mm_unpacklo_epi64(divisors, zero));\n        __m128i mod2 = _mm_rem_epi64(num, _mm_unpackhi_epi64(divisors, zero));\n\n        int64_t res1[2], res2[2];\n        _mm_storeu_si128((__m128i*)res1, mod1);\n        _mm_storeu_si128((__m128i*)res2, mod2);\n\n        if (res1[0] == 0 || res1[1] == 0 || res2[0] == 0 || res2[1] == 0) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_76_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool is_prime_simd(int64_t n) {\n    if (n <= 1) return false;\n    if (n == 2 || n == 3) return true;\n    if (n % 2 == 0 || n % 3 == 0) return false;\n\n    __m128i vn = _mm_set1_epi64x(n);\n    __m128i vzero = _mm_setzero_si128();\n    __m128i vone = _mm_set1_epi64x(1);\n    __m128i vtwo = _mm_set1_epi64x(2);\n    __m128i vsqrt = _mm_set1_epi64x((int64_t)sqrt((double)n));\n    __m128i vi = _mm_set1_epi64x(5);\n\n    while (true) {\n        __m128i cmp = _mm_cmpgt_epi64(vsqrt, vi);\n        if (_mm_movemask_epi8(cmp) == 0) break;\n\n        __m128i mod1 = _mm_rem_epi64(vn, vi);\n        __m128i mod2 = _mm_rem_epi64(vn, _mm_add_epi64(vi, vtwo));\n\n        if (_mm_movemask_epi8(_mm_cmpeq_epi64(mod1, vzero)) != 0 ||\n            _mm_movemask_epi8(_mm_cmpeq_epi64(mod2, vzero)) != 0) {\n            return false;\n        }\n\n        vi = _mm_add_epi64(vi, _mm_set1_epi64x(6));\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_76_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool is_prime_simd(int64_t n) {\n    if (n <= 1) return false;\n    if (n == 2 || n == 3) return true;\n    if (n % 2 == 0 || n % 3 == 0) return false;\n\n    __m128i zero = _mm_setzero_si128();\n    __m128i num = _mm_set1_epi64x(n);\n    __m128i one = _mm_set1_epi64x(1);\n    __m128i two = _mm_set1_epi64x(2);\n    __m128i three = _mm_set1_epi64x(3);\n\n    // Check divisors from 5 to sqrt(n)\n    int64_t limit = (int64_t)sqrt((double)n);\n    for (int64_t i = 5; i <= limit; i += 6) {\n        __m128i divisor1 = _mm_set1_epi64x(i);\n        __m128i divisor2 = _mm_add_epi64(divisor1, two);\n\n        // Compute n % i and n % (i + 2)\n        __m128i mod1 = _mm_rem_epi64(num, divisor1);\n        __m128i mod2 = _mm_rem_epi64(num, divisor2);\n\n        // Check if either remainder is zero\n        __m128i cmp1 = _mm_cmpeq_epi64(mod1, zero);\n        __m128i cmp2 = _mm_cmpeq_epi64(mod2, zero);\n\n        // Combine results\n        __m128i result = _mm_or_si128(cmp1, cmp2);\n        if (_mm_movemask_epi8(result)) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_76_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool is_prime_simd(int64_t n) {\n    if (n <= 1) return false;\n    if (n == 2 || n == 3) return true;\n    if (n % 2 == 0 || n % 3 == 0) return false;\n\n    __m128i vn = _mm_set1_epi64x(n);\n    __m128i vzero = _mm_setzero_si128();\n    __m128i vone = _mm_set1_epi64x(1);\n    __m128i vtwo = _mm_set1_epi64x(2);\n    __m128i vsqrt = _mm_set1_epi64x((int64_t)sqrt((double)n));\n    __m128i vi = _mm_set1_epi64x(5);\n\n    while (true) {\n        __m128i cmp = _mm_cmpgt_epi64(vsqrt, vi);\n        if (_mm_movemask_epi8(cmp) == 0) break;\n\n        __m128i mod1 = _mm_rem_epi64(vn, vi);\n        __m128i mod2 = _mm_rem_epi64(vn, _mm_add_epi64(vi, vtwo));\n\n        __m128i check1 = _mm_cmpeq_epi64(mod1, vzero);\n        __m128i check2 = _mm_cmpeq_epi64(mod2, vzero);\n\n        if (_mm_movemask_epi8(check1) != 0 || _mm_movemask_epi8(check2) != 0) {\n            return false;\n        }\n\n        vi = _mm_add_epi64(vi, _mm_set1_epi64x(6));\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_76_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool is_prime_simd(int64_t n) {\n    if (n <= 1) return false;\n    if (n == 2 || n == 3) return true;\n    if (n % 2 == 0 || n % 3 == 0) return false;\n\n    __m128i vn = _mm_set1_epi64x(n);\n    __m128i vzero = _mm_setzero_si128();\n    __m128i vone = _mm_set1_epi64x(1);\n    __m128i vtwo = _mm_set1_epi64x(2);\n    __m128i vthree = _mm_set1_epi64x(3);\n\n    // Check divisors from 5 to sqrt(n)\n    int64_t limit = static_cast<int64_t>(sqrt(static_cast<double>(n)));\n    for (int64_t i = 5; i <= limit; i += 6) {\n        __m128i vi = _mm_set1_epi64x(i);\n        __m128i vi_plus_two = _mm_add_epi64(vi, vtwo);\n\n        // Compute n % i and n % (i + 2)\n        __m128i mod_i = _mm_rem_epi64(vn, vi);\n        __m128i mod_i_plus_two = _mm_rem_epi64(vn, vi_plus_two);\n\n        // Check if either remainder is zero\n        __m128i cmp_i = _mm_cmpeq_epi64(mod_i, vzero);\n        __m128i cmp_i_plus_two = _mm_cmpeq_epi64(mod_i_plus_two, vzero);\n        __m128i cmp_or = _mm_or_si128(cmp_i, cmp_i_plus_two);\n\n        // If any comparison is true, n is not prime\n        if (!_mm_testz_si128(cmp_or, cmp_or)) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_77_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n#include <algorithm>\n\nstd::string solve_simd(const std::string & s) {\n    size_t len = s.size();\n    std::string result = s;\n    bool hasLetters = false;\n\n    // Check if the string contains any letters\n    for (char c : s) {\n        if ((c >= 'a' && c <= 'z') || (c >= 'A' && c <= 'Z')) {\n            hasLetters = true;\n            break;\n        }\n    }\n\n    if (!hasLetters) {\n        // Reverse the string if no letters are found\n        std::reverse(result.begin(), result.end());\n        return result;\n    }\n\n    size_t i = 0;\n    __m128i v_lower_mask = _mm_set1_epi8(0x20); // Mask to toggle case (bit 5)\n    __m128i v_alpha_mask_low = _mm_set1_epi8(0x60); // Mask for range check ('a'-'A')\n    __m128i v_alpha_mask_high = _mm_set1_epi8(0x7B); // Mask for range check ('z'+1)\n\n    // Process 16 characters at a time using SIMD\n    for (; i + 15 < len; i += 16) {\n        __m128i v_chars = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&s[i]));\n\n        // Create masks for alphabetic characters\n        __m128i v_is_alpha_low = _mm_cmpgt_epi8(v_chars, v_alpha_mask_low);\n        __m128i v_is_alpha_high = _mm_cmplt_epi8(v_chars, v_alpha_mask_high);\n        __m128i v_is_alpha = _mm_and_si128(v_is_alpha_low, v_is_alpha_high);\n\n        // Toggle case for alphabetic characters\n        __m128i v_toggled = _mm_xor_si128(v_chars, v_lower_mask);\n        __m128i v_result = _mm_blendv_epi8(v_chars, v_toggled, v_is_alpha);\n\n        // Store the result back to the output string\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i]), v_result);\n    }\n\n    // Process remaining characters (if any) using scalar code\n    for (; i < len; ++i) {\n        char c = s[i];\n        if ((c >= 'a' && c <= 'z') || (c >= 'A' && c <= 'Z')) {\n            result[i] ^= 0x20; // Toggle case\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_77_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n#include <algorithm>\n\nstd::string solve_simd(const std::string & s) {\n    int n = s.size();\n    std::string result = s;\n    bool hasLetter = false;\n\n    // Check if the string contains any letters\n    for (char c : s) {\n        if ((c >= 'a' && c <= 'z') || (c >= 'A' && c <= 'Z')) {\n            hasLetter = true;\n            break;\n        }\n    }\n\n    if (!hasLetter) {\n        // Reverse the string if no letters are found\n        std::reverse(result.begin(), result.end());\n        return result;\n    }\n\n    // Process the string in chunks of 16 bytes using SSE2\n    int i = 0;\n    for (; i + 16 <= n; i += 16) {\n        __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&s[i]));\n\n        // Create masks for lowercase and uppercase letters\n        __m128i lowercaseMask = _mm_cmplt_epi8(chunk, _mm_set1_epi8('a'));\n        __m128i uppercaseMask = _mm_cmpgt_epi8(chunk, _mm_set1_epi8('Z'));\n\n        // Identify alphabetic characters\n        __m128i alphaMask = _mm_andnot_si128(lowercaseMask, _mm_cmplt_epi8(chunk, _mm_set1_epi8('z' + 1)));\n        alphaMask = _mm_andnot_si128(uppercaseMask, alphaMask);\n\n        // Toggle case for alphabetic characters\n        __m128i toggleCase = _mm_xor_si128(chunk, _mm_set1_epi8(0x20));\n        __m128i finalChunk = _mm_blendv_epi8(chunk, toggleCase, alphaMask);\n\n        // Store the result back to the output string\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i]), finalChunk);\n    }\n\n    // Process remaining characters (if any)\n    for (; i < n; ++i) {\n        char c = s[i];\n        if ((c >= 'a' && c <= 'z') || (c >= 'A' && c <= 'Z')) {\n            result[i] ^= 0x20;\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_77_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n#include <algorithm>\n\nstd::string solve_simd(const std::string & s) {\n    size_t len = s.size();\n    std::string result = s;\n    bool hasLetters = false;\n\n    // Check if the string contains any letters\n    for (char c : s) {\n        if ((c >= 'a' && c <= 'z') || (c >= 'A' && c <= 'Z')) {\n            hasLetters = true;\n            break;\n        }\n    }\n\n    if (!hasLetters) {\n        // Reverse the string if no letters are found\n        std::reverse(result.begin(), result.end());\n        return result;\n    }\n\n    size_t i = 0;\n    __m128i v_lower = _mm_set1_epi8('a');\n    __m128i v_upper = _mm_set1_epi8('A');\n    __m128i v_alpha_mask = _mm_set1_epi8(0x20);\n    __m128i v_letter_mask = _mm_set1_epi8(0);\n\n    // Process the string in chunks of 16 bytes using SSE2\n    for (; i + 16 <= len; i += 16) {\n        __m128i v_chars = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&s[i]));\n\n        // Create masks to identify lowercase and uppercase letters\n        __m128i v_is_lower = _mm_and_si128(_mm_cmpgt_epi8(v_chars, v_lower - 1), _mm_cmplt_epi8(v_chars, _mm_set1_epi8('z' + 1)));\n        __m128i v_is_upper = _mm_and_si128(_mm_cmpgt_epi8(v_chars, v_upper - 1), _mm_cmplt_epi8(v_chars, _mm_set1_epi8('Z' + 1)));\n        __m128i v_is_letter = _mm_or_si128(v_is_lower, v_is_upper);\n\n        // Toggle case for letters by flipping the 5th bit\n        __m128i v_toggle_case = _mm_xor_si128(v_chars, _mm_and_si128(v_is_letter, v_alpha_mask));\n\n        // Blend original and toggled characters based on letter mask\n        __m128i v_result = _mm_blendv_epi8(v_chars, v_toggle_case, v_is_letter);\n\n        // Store the result back into the output string\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i]), v_result);\n    }\n\n    // Process remaining characters (if any) after the SIMD loop\n    for (; i < len; ++i) {\n        char c = s[i];\n        if (c >= 'a' && c <= 'z') {\n            result[i] = c - ('a' - 'A');\n        } else if (c >= 'A' && c <= 'Z') {\n            result[i] = c + ('a' - 'A');\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_77_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n#include <algorithm>\n\nstd::string solve_simd(const std::string & s) {\n    size_t len = s.size();\n    std::string result(s);\n    bool hasLetters = false;\n\n    // Check if the string contains any letters\n    for (char c : s) {\n        if (('a' <= c && c <= 'z') || ('A' <= c && c <= 'Z')) {\n            hasLetters = true;\n            break;\n        }\n    }\n\n    if (!hasLetters) {\n        // Reverse the string if no letters are found\n        std::reverse(result.begin(), result.end());\n        return result;\n    }\n\n    size_t i = 0;\n    __m128i v_lower_mask = _mm_set1_epi8(0x20); // Mask to toggle case (bit 5)\n    __m128i v_alpha_lower_min = _mm_set1_epi8('a');\n    __m128i v_alpha_lower_max = _mm_set1_epi8('z');\n    __m128i v_alpha_upper_min = _mm_set1_epi8('A');\n    __m128i v_alpha_upper_max = _mm_set1_epi8('Z');\n\n    // Process 16 characters at a time using SIMD\n    for (; i + 15 < len; i += 16) {\n        __m128i v_chars = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&s[i]));\n\n        // Create masks for lowercase and uppercase letters\n        __m128i v_is_lower = _mm_and_si128(_mm_cmpgt_epi8(v_chars, v_alpha_lower_min),\n                                            _mm_cmplt_epi8(v_chars, v_alpha_lower_max));\n        __m128i v_is_upper = _mm_and_si128(_mm_cmpgt_epi8(v_chars, v_alpha_upper_min),\n                                            _mm_cmplt_epi8(v_chars, v_alpha_upper_max));\n\n        // Combine masks to identify alphabetic characters\n        __m128i v_is_alpha = _mm_or_si128(v_is_lower, v_is_upper);\n\n        // Toggle case for alphabetic characters\n        __m128i v_toggled = _mm_xor_si128(v_chars, v_lower_mask);\n\n        // Blend original and toggled characters based on alpha mask\n        __m128i v_result = _mm_blendv_epi8(v_chars, v_toggled, v_is_alpha);\n\n        // Store the result back into the output string\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i]), v_result);\n    }\n\n    // Process remaining characters (if any) with scalar code\n    for (; i < len; ++i) {\n        char c = s[i];\n        if ('a' <= c && c <= 'z') {\n            result[i] = c - 0x20; // Convert to uppercase\n        } else if ('A' <= c && c <= 'Z') {\n            result[i] = c + 0x20; // Convert to lowercase\n        } else {\n            result[i] = c; // Keep non-alphabetic characters unchanged\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_77_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n#include <algorithm>\n\nstd::string solve_simd(const std::string & s) {\n    size_t len = s.size();\n    std::string result(s);\n    bool hasLetters = false;\n\n    // Check if the string contains any letters\n    for (char c : s) {\n        if ((c >= 'a' && c <= 'z') || (c >= 'A' && c <= 'Z')) {\n            hasLetters = true;\n            break;\n        }\n    }\n\n    if (!hasLetters) {\n        // Reverse the string if no letters are found\n        std::reverse(result.begin(), result.end());\n        return result;\n    }\n\n    size_t i = 0;\n    __m128i v_low_alpha = _mm_set1_epi8('a');\n    __m128i v_high_alpha = _mm_set1_epi8('z');\n    __m128i v_low_upper = _mm_set1_epi8('A');\n    __m128i v_high_upper = _mm_set1_epi8('Z');\n    __m128i v_flip_case = _mm_set1_epi8('a' - 'A');\n\n    // Process the string in chunks of 16 bytes\n    for (; i + 15 < len; i += 16) {\n        __m128i v_chars = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&s[i]));\n\n        // Check for lowercase letters\n        __m128i v_is_lower = _mm_and_si128(_mm_cmpgt_epi8(v_chars, v_low_alpha), _mm_cmplt_epi8(v_chars, v_high_alpha));\n        // Check for uppercase letters\n        __m128i v_is_upper = _mm_and_si128(_mm_cmpgt_epi8(v_chars, v_low_upper), _mm_cmplt_epi8(v_chars, v_high_upper));\n\n        // Combine the masks\n        __m128i v_is_letter = _mm_or_si128(v_is_lower, v_is_upper);\n\n        // Flip case for lowercase letters\n        __m128i v_flipped_lower = _mm_sub_epi8(v_chars, v_flip_case);\n        // Flip case for uppercase letters\n        __m128i v_flipped_upper = _mm_add_epi8(v_chars, v_flip_case);\n\n        // Select flipped characters based on case\n        __m128i v_flipped = _mm_blendv_epi8(v_flipped_upper, v_flipped_lower, v_is_lower);\n\n        // Blend original and flipped characters based on letter mask\n        v_chars = _mm_blendv_epi8(v_chars, v_flipped, v_is_letter);\n\n        // Store the result back to the output string\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i]), v_chars);\n    }\n\n    // Process remaining characters\n    for (; i < len; ++i) {\n        char c = s[i];\n        if (c >= 'a' && c <= 'z') {\n            result[i] = c - ('a' - 'A');\n        } else if (c >= 'A' && c <= 'Z') {\n            result[i] = c + ('a' - 'A');\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_78_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<int> sort_third_simd(std::vector<int> l) {\n    int n = l.size();\n    std::vector<int> indices;\n    \n    // Collect indices divisible by 3\n    for (int i = 0; i < n; i += 3) {\n        indices.push_back(i);\n    }\n    \n    // Extract elements at indices divisible by 3\n    std::vector<int> third_elements;\n    for (int idx : indices) {\n        third_elements.push_back(l[idx]);\n    }\n    \n    // Sort the extracted elements\n    std::sort(third_elements.begin(), third_elements.end());\n    \n    // Use SSE/SSE2 intrinsics to parallelize the replacement of sorted values\n    int m = third_elements.size();\n    for (int i = 0; i < m; i += 4) {\n        __m128i sorted_vals = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&third_elements[i]));\n        int j = i;\n        for (; j < std::min(i + 4, m); ++j) {\n            l[indices[j]] = _mm_extract_epi32(sorted_vals, j - i);\n        }\n    }\n    \n    return l;\n}\n```"}
{"task_id": "SimdBench_78_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<int> sort_third_simd(std::vector<int> l) {\n    int n = l.size();\n    std::vector<int> result = l;\n\n    // Extract elements at indices divisible by 3\n    std::vector<int> third_elements;\n    for (int i = 0; i < n; i += 3) {\n        third_elements.push_back(l[i]);\n    }\n\n    // Sort the extracted elements\n    std::sort(third_elements.begin(), third_elements.end());\n\n    // Replace the original indices divisible by 3 with sorted values\n    int k = 0;\n    for (int i = 0; i < n; i += 3) {\n        result[i] = third_elements[k++];\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_78_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<int> sort_third_simd(std::vector<int> l) {\n    size_t n = l.size();\n    std::vector<int> result = l;\n\n    // Extract elements at indices divisible by 3\n    std::vector<int> divisible_by_three;\n    for (size_t i = 0; i < n; i += 3) {\n        divisible_by_three.push_back(l[i]);\n    }\n\n    // Sort the extracted elements\n    std::sort(divisible_by_three.begin(), divisible_by_three.end());\n\n    // Replace the original indices divisible by 3 with sorted values using SIMD\n    size_t sorted_idx = 0;\n    for (size_t i = 0; i < n; i += 3) {\n        if (sorted_idx + 4 <= divisible_by_three.size()) {\n            // Load 4 sorted values into SIMD register\n            __m128i sorted_vals = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&divisible_by_three[sorted_idx]));\n\n            // Scatter the sorted values back to the result vector\n            for (int j = 0; j < 4; ++j) {\n                if (i + j * 3 < n) {\n                    result[i + j * 3] = _mm_extract_epi32(sorted_vals, j);\n                }\n            }\n\n            sorted_idx += 4;\n        } else {\n            // Handle remaining elements that are less than 4\n            for (; sorted_idx < divisible_by_three.size(); ++sorted_idx) {\n                if (i + (sorted_idx % 4) * 3 < n) {\n                    result[i + (sorted_idx % 4) * 3] = divisible_by_three[sorted_idx];\n                }\n            }\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_78_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<int> sort_third_simd(std::vector<int> l) {\n    size_t n = l.size();\n    std::vector<int> result = l;\n\n    // Extract elements at indices divisible by 3\n    std::vector<int> divisible_by_three;\n    for (size_t i = 0; i < n; i += 3) {\n        divisible_by_three.push_back(l[i]);\n    }\n\n    // Sort the extracted elements\n    std::sort(divisible_by_three.begin(), divisible_by_three.end());\n\n    // Replace the original indices divisible by 3 with sorted values\n    size_t idx = 0;\n    for (size_t i = 0; i < n; i += 3) {\n        result[i] = divisible_by_three[idx++];\n    }\n\n    // Use SSE/SSE2 intrinsics to process the vector in parallel\n    size_t simd_size = n - (n % 4); // Process in chunks of 4\n    __m128i mask = _mm_set_epi32(0, 0, 0, 0xFFFFFFFF); // Mask for indices divisible by 3\n\n    for (size_t i = 0; i < simd_size; i += 4) {\n        __m128i indices = _mm_set_epi32(i + 3, i + 2, i + 1, i);\n        __m128i div_by_3 = _mm_and_si128(indices, mask); // Check divisibility by 3\n        __m128i is_div_by_3 = _mm_cmpeq_epi32(div_by_3, _mm_setzero_si128());\n\n        __m128i original = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&l[i]));\n        __m128i sorted = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&result[i]));\n\n        // Blend original and sorted values based on divisibility\n        __m128i blended = _mm_blendv_epi8(original, sorted, is_div_by_3);\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i]), blended);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_78_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<int> sort_third_simd(std::vector<int> l) {\n    size_t n = l.size();\n    std::vector<int> result = l;\n\n    // Extract elements at indices divisible by 3\n    std::vector<int> third_elements;\n    for (size_t i = 0; i < n; i += 3) {\n        third_elements.push_back(l[i]);\n    }\n\n    // Sort the extracted elements\n    std::sort(third_elements.begin(), third_elements.end());\n\n    // Replace the original indices divisible by 3 with sorted values using SIMD\n    size_t third_idx = 0;\n    for (size_t i = 0; i < n; i += 12) { // Process 12 elements at a time (4 SIMD registers)\n        __m128i mask = _mm_set_epi32(0, 0, 0, -1); // Mask for indices divisible by 3\n        __m128i indices = _mm_set_epi32(i + 9, i + 6, i + 3, i);\n\n        // Load 4 elements from the result vector\n        __m128i values = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&result[i]));\n\n        // Check which indices are divisible by 3\n        __m128i div_by_3 = _mm_and_si128(_mm_setzero_si128(), _mm_cmpeq_epi32(_mm_and_si128(indices, _mm_set1_epi32(3)), _mm_setzero_si128()));\n\n        // Blend sorted values into the result vector\n        for (int j = 0; j < 4; ++j) {\n            if (third_idx < third_elements.size()) {\n                int sorted_value = third_elements[third_idx++];\n                values = _mm_blendv_epi8(values, _mm_set1_epi32(sorted_value), mask);\n            }\n        }\n\n        // Store the updated values back to the result vector\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i]), values);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_79_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nfloat max_element_simd(std::vector<float> l) {\n    __m128 max_vec = _mm_set1_ps(l[0]);\n    size_t i = 0;\n    size_t size = l.size();\n\n    // Process 4 floats at a time\n    for (; i + 4 <= size; i += 4) {\n        __m128 vec = _mm_loadu_ps(&l[i]);\n        max_vec = _mm_max_ps(max_vec, vec);\n    }\n\n    // Horizontal max of the SIMD register\n    float temp[4];\n    _mm_storeu_ps(temp, max_vec);\n    float result = temp[0];\n    for (int j = 1; j < 4; ++j) {\n        if (temp[j] > result) {\n            result = temp[j];\n        }\n    }\n\n    // Process remaining elements\n    for (; i < size; ++i) {\n        if (l[i] > result) {\n            result = l[i];\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_79_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nfloat max_element_simd(std::vector<float> l) {\n    __m128 max_val = _mm_set1_ps(l[0]);\n    int i = 0;\n    int size = l.size();\n\n    // Process 4 floats at a time\n    for (; i <= size - 4; i += 4) {\n        __m128 vec = _mm_loadu_ps(&l[i]);\n        max_val = _mm_max_ps(max_val, vec);\n    }\n\n    // Horizontal max of the SIMD register\n    float temp[4];\n    _mm_storeu_ps(temp, max_val);\n    float result = temp[0];\n    for (int j = 1; j < 4; ++j) {\n        if (temp[j] > result) {\n            result = temp[j];\n        }\n    }\n\n    // Process remaining elements\n    for (; i < size; ++i) {\n        if (l[i] > result) {\n            result = l[i];\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_79_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nfloat max_element_simd(std::vector<float> l) {\n    __m128 max_vec = _mm_set1_ps(l[0]);\n    size_t i = 0;\n    size_t size = l.size();\n\n    for (; i + 4 <= size; i += 4) {\n        __m128 vec = _mm_loadu_ps(&l[i]);\n        max_vec = _mm_max_ps(max_vec, vec);\n    }\n\n    float max_val = std::max(std::max(max_vec[0], max_vec[1]), std::max(max_vec[2], max_vec[3]));\n\n    for (; i < size; ++i) {\n        max_val = std::max(max_val, l[i]);\n    }\n\n    return max_val;\n}\n```"}
{"task_id": "SimdBench_79_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nfloat max_element_simd(std::vector<float> l) {\n    __m128 max_vec = _mm_set1_ps(l[0]);\n    size_t i = 0;\n\n    for (; i + 4 <= l.size(); i += 4) {\n        __m128 vec = _mm_loadu_ps(&l[i]);\n        max_vec = _mm_max_ps(max_vec, vec);\n    }\n\n    float temp[4];\n    _mm_storeu_ps(temp, max_vec);\n\n    float max_val = temp[0];\n    for (int j = 1; j < 4; ++j) {\n        if (temp[j] > max_val) {\n            max_val = temp[j];\n        }\n    }\n\n    for (; i < l.size(); ++i) {\n        if (l[i] > max_val) {\n            max_val = l[i];\n        }\n    }\n\n    return max_val;\n}\n```"}
{"task_id": "SimdBench_79_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nfloat max_element_simd(std::vector<float> l) {\n    __m128 max_val = _mm_set1_ps(l[0]);\n    int i = 0;\n    int size = l.size();\n\n    // Process 4 floats at a time\n    for (; i <= size - 4; i += 4) {\n        __m128 vec = _mm_loadu_ps(&l[i]);\n        max_val = _mm_max_ps(max_val, vec);\n    }\n\n    // Horizontal max of the SIMD register\n    float temp[4];\n    _mm_storeu_ps(temp, max_val);\n    float result = temp[0];\n    for (int j = 1; j < 4; ++j) {\n        if (temp[j] > result) {\n            result = temp[j];\n        }\n    }\n\n    // Process remaining elements\n    for (; i < size; ++i) {\n        if (l[i] > result) {\n            result = l[i];\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_80_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint fizz_buzz_simd(int n) {\n    int count = 0;\n    __m128i sevens = _mm_set1_epi8('7'); // Vector filled with '7'\n    __m128i zeros = _mm_setzero_si128(); // Zero vector for comparisons\n\n    for (int i = 0; i < n; i++) {\n        if (i % 11 == 0 || i % 13 == 0) {\n            char buffer[16];\n            _mm_storeu_si128((__m128i*)buffer, zeros); // Clear buffer\n            sprintf(buffer, \"%d\", i);\n\n            int len = strlen(buffer);\n            for (int j = 0; j < len; j += 16) {\n                __m128i strVec = _mm_loadu_si128((__m128i*)(buffer + j));\n                __m128i cmp = _mm_cmpeq_epi8(strVec, sevens);\n                int mask = _mm_movemask_epi8(cmp);\n                while (mask) {\n                    count += mask & 1;\n                    mask >>= 1;\n                }\n            }\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_80_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint fizz_buzz_simd(int n) {\n    int count = 0;\n    __m128i v7 = _mm_set1_epi8('7'); // Broadcast '7' into all bytes of a SIMD register\n    __m128i vZero = _mm_setzero_si128(); // Zero vector for comparisons\n\n    for (int i = 0; i < n; i++) {\n        if (i % 11 != 0 && i % 13 != 0) continue;\n\n        char buffer[16];\n        int len = sprintf(buffer, \"%d\", i);\n\n        // Pad the buffer to 16 bytes for SIMD processing\n        for (int j = len; j < 16; j++) buffer[j] = 0;\n\n        __m128i vBuffer = _mm_loadu_si128((__m128i*)buffer); // Load the buffer into a SIMD register\n        __m128i cmp = _mm_cmpeq_epi8(vBuffer, v7); // Compare each byte with '7'\n        int mask = _mm_movemask_epi8(cmp); // Create a bitmask of comparison results\n\n        // Count the number of '7's using the bitmask\n        while (mask) {\n            count += mask & 1;\n            mask >>= 1;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_80_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint fizz_buzz_simd(int n) {\n    int count = 0;\n    __m128i sevens = _mm_set1_epi8('7'); // Vector filled with '7'\n    __m128i zeros = _mm_setzero_si128(); // Zero vector for comparison\n\n    for (int i = 0; i < n; i++) {\n        if (i % 11 != 0 && i % 13 != 0) continue;\n\n        char buffer[16];\n        int len = sprintf(buffer, \"%d\", i);\n\n        // Pad the buffer to a multiple of 16 bytes\n        for (int j = len; j < 16; j++) {\n            buffer[j] = 0;\n        }\n\n        // Load 16 characters into an SSE register\n        __m128i str = _mm_loadu_si128((__m128i*)buffer);\n        // Compare each byte with '7'\n        __m128i cmp = _mm_cmpeq_epi8(str, sevens);\n        // Count the number of matches\n        int mask = _mm_movemask_epi8(cmp);\n        while (mask) {\n            count += mask & 1;\n            mask >>= 1;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_80_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint fizz_buzz_simd(int n) {\n    int count = 0;\n    __m128i v7 = _mm_set1_epi8('7'); // Vector with '7' repeated\n    __m128i v0 = _mm_setzero_si128(); // Zero vector for comparisons\n\n    for (int i = 0; i < n; i++) {\n        if (i % 11 == 0 || i % 13 == 0) {\n            char buffer[16];\n            _mm_storeu_si128((__m128i*)buffer, v0); // Clear buffer\n            sprintf(buffer, \"%d\", i);\n\n            int len = strlen(buffer);\n            for (int j = 0; j < len; j += 16) {\n                __m128i vbuf = _mm_loadu_si128((__m128i*)(buffer + j));\n                __m128i cmp = _mm_cmpeq_epi8(vbuf, v7);\n                int mask = _mm_movemask_epi8(cmp);\n                while (mask) {\n                    count += mask & 1;\n                    mask >>= 1;\n                }\n            }\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_80_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint fizz_buzz_simd(int n) {\n    int count = 0;\n    __m128i v_seven = _mm_set1_epi8('7'); // Broadcast '7' into all elements of the vector\n    __m128i v_zero = _mm_setzero_si128(); // Zero vector for comparisons\n\n    for (int i = 0; i < n; i++) {\n        if (i % 11 != 0 && i % 13 != 0) continue;\n\n        char buffer[16];\n        int len = sprintf(buffer, \"%d\", i);\n\n        // Pad the buffer to a multiple of 16 bytes\n        for (int j = len; j < 16; j++) {\n            buffer[j] = 0;\n        }\n\n        // Load 16 characters into an SSE register\n        __m128i v_buffer = _mm_loadu_si128((__m128i*)buffer);\n\n        // Compare each byte with '7'\n        __m128i v_cmp = _mm_cmpeq_epi8(v_buffer, v_seven);\n\n        // Get a mask of matching bytes\n        int mask = _mm_movemask_epi8(v_cmp);\n\n        // Count the number of set bits in the mask\n        while (mask) {\n            count += mask & 1;\n            mask >>= 1;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_81_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<float> sort_even_simd(std::vector<float> l) {\n    size_t n = l.size();\n    if (n < 2) return l;\n\n    // Ensure the size is a multiple of 4 for SIMD processing\n    size_t simd_size = (n + 3) & ~3;\n    std::vector<float> temp(simd_size, 0.0f);\n    std::copy(l.begin(), l.end(), temp.begin());\n\n    // Extract even-indexed elements\n    std::vector<float> even_elements;\n    for (size_t i = 0; i < n; i += 2) {\n        even_elements.push_back(temp[i]);\n    }\n\n    // Sort the even-indexed elements\n    std::sort(even_elements.begin(), even_elements.end());\n\n    // Replace the even indices in the original array with sorted values\n    size_t even_idx = 0;\n    for (size_t i = 0; i < n; i += 4) {\n        __m128 vec = _mm_loadu_ps(&temp[i]);\n\n        // Mask to extract even indices: [1, 0, 1, 0]\n        __m128i mask = _mm_set_epi32(0, -1, 0, -1);\n        __m128 sorted_evens = _mm_set_ps(even_elements[even_idx + 1], 0.0f, even_elements[even_idx], 0.0f);\n\n        // Blend sorted even values into the original vector\n        vec = _mm_blendv_ps(vec, sorted_evens, _mm_castsi128_ps(mask));\n\n        _mm_storeu_ps(&temp[i], vec);\n        even_idx += 2;\n    }\n\n    // Copy back to the original size\n    std::vector<float> result(l.size());\n    std::copy(temp.begin(), temp.begin() + l.size(), result.begin());\n    return result;\n}\n```"}
{"task_id": "SimdBench_81_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<float> sort_even_simd(std::vector<float> l) {\n    size_t n = l.size();\n    std::vector<float> even_values;\n    even_values.reserve((n + 1) / 2);\n\n    // Extract even-indexed elements\n    for (size_t i = 0; i < n; i += 2) {\n        even_values.push_back(l[i]);\n    }\n\n    // Sort the even-indexed elements\n    std::sort(even_values.begin(), even_values.end());\n\n    // Reinsert sorted even-indexed elements using SIMD\n    size_t even_idx = 0;\n    for (size_t i = 0; i < n; i += 4) {\n        __m128 vec = _mm_loadu_ps(&l[i]); // Load 4 floats from l\n\n        if (i + 0 < n && (i % 2 == 0)) {\n            vec = _mm_move_ss(vec, _mm_set_ss(even_values[even_idx++])); // Replace first even index\n        }\n        if (i + 2 < n && ((i + 2) % 2 == 0)) {\n            vec = _mm_move_ss(vec, _mm_set_ss(even_values[even_idx++])); // Replace second even index\n        }\n\n        _mm_storeu_ps(&l[i], vec); // Store back to l\n    }\n\n    return l;\n}\n```"}
{"task_id": "SimdBench_81_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<float> sort_even_simd(std::vector<float> l) {\n    size_t n = l.size();\n    if (n < 2) return l;\n\n    // Ensure the vector has an even size for SIMD processing\n    size_t simd_size = (n + 1) & ~1;\n    std::vector<float> result(simd_size, 0.0f);\n    std::copy(l.begin(), l.end(), result.begin());\n\n    // Extract even indices into a separate array\n    size_t even_count = simd_size / 2;\n    std::vector<float> even_values(even_count);\n\n    for (size_t i = 0; i < even_count; ++i) {\n        even_values[i] = result[2 * i];\n    }\n\n    // Sort the even values\n    std::sort(even_values.begin(), even_values.end());\n\n    // Use SSE to interleave sorted even values and odd values back into the result\n    for (size_t i = 0; i < even_count; i += 4) {\n        // Load 4 sorted even values\n        __m128 even_vec = _mm_loadu_ps(&even_values[i]);\n\n        // Load 4 odd values from the original vector\n        __m128 odd_vec = _mm_set_ps(\n            (i + 3 < even_count) ? result[2 * (i + 3) + 1] : 0.0f,\n            (i + 2 < even_count) ? result[2 * (i + 2) + 1] : 0.0f,\n            (i + 1 < even_count) ? result[2 * (i + 1) + 1] : 0.0f,\n            (i + 0 < even_count) ? result[2 * (i + 0) + 1] : 0.0f\n        );\n\n        // Interleave even and odd values\n        __m128 interleaved_low = _mm_unpacklo_ps(even_vec, odd_vec);\n        __m128 interleaved_high = _mm_unpackhi_ps(even_vec, odd_vec);\n\n        // Store the interleaved values back into the result\n        _mm_storeu_ps(&result[4 * i], interleaved_low);\n        _mm_storeu_ps(&result[4 * i + 4], interleaved_high);\n    }\n\n    // Resize the result to the original size\n    result.resize(n);\n    return result;\n}\n```"}
{"task_id": "SimdBench_81_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<float> sort_even_simd(std::vector<float> l) {\n    size_t n = l.size();\n    std::vector<float> even_values;\n    even_values.reserve((n + 1) / 2);\n\n    // Extract even-indexed elements\n    for (size_t i = 0; i < n; i += 2) {\n        even_values.push_back(l[i]);\n    }\n\n    // Sort the even-indexed elements\n    std::sort(even_values.begin(), even_values.end());\n\n    // Reinsert sorted even-indexed elements using SIMD\n    size_t even_idx = 0;\n    for (size_t i = 0; i < n; i += 4) {\n        __m128 vec = _mm_loadu_ps(&l[i]); // Load 4 floats from l\n\n        if (i % 2 == 0 && i + 2 < n) {\n            // Replace even indices with sorted values\n            vec = _mm_move_ss(vec, _mm_set_ss(even_values[even_idx++])); // Replace first even index\n            if (i + 2 < n) {\n                vec = _mm_move_ss(vec, _mm_set_ss(even_values[even_idx++])); // Replace second even index\n            }\n        }\n\n        _mm_storeu_ps(&l[i], vec); // Store back to l\n    }\n\n    return l;\n}\n```"}
{"task_id": "SimdBench_81_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<float> sort_even_simd(std::vector<float> l) {\n    size_t n = l.size();\n    std::vector<float> even_values;\n    \n    // Extract even-indexed elements\n    for (size_t i = 0; i < n; i += 2) {\n        even_values.push_back(l[i]);\n    }\n\n    // Sort the even-indexed elements\n    std::sort(even_values.begin(), even_values.end());\n\n    // Reinsert sorted even-indexed elements using SIMD\n    size_t even_idx = 0;\n    for (size_t i = 0; i < n; i += 4) {\n        __m128 vec = _mm_loadu_ps(&l[i]); // Load 4 floats from memory\n        if (i + 0 < n && (i % 2 == 0)) {\n            vec = _mm_move_ss(vec, _mm_set_ss(even_values[even_idx++])); // Replace first even index\n        }\n        if (i + 2 < n && ((i + 2) % 2 == 0)) {\n            vec = _mm_move_ss(vec, _mm_set_ss(even_values[even_idx++])); // Replace second even index\n        }\n        _mm_storeu_ps(&l[i], vec); // Store back to memory\n    }\n\n    return l;\n}\n```"}
{"task_id": "SimdBench_82_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool triples_sum_to_zero_simd(std::vector<int> l) {\n    int n = l.size();\n    if (n < 3) return false;\n\n    // Align the input vector to 16 bytes for SIMD operations\n    __m128i* data = (__m128i*) _mm_malloc(n * sizeof(int), 16);\n    for (int i = 0; i < n; ++i) {\n        ((int*)data)[i] = l[i];\n    }\n\n    for (int i = 0; i < n - 2; ++i) {\n        for (int j = i + 1; j < n - 1; ++j) {\n            __m128i a_b = _mm_set1_epi32(l[i] + l[j]);\n            int k = j + 1;\n            while (k <= n - 4) {\n                __m128i c = _mm_loadu_si128(&data[k / 4]);\n                __m128i sum = _mm_add_epi32(a_b, c);\n                __m128i zero = _mm_setzero_si128();\n                __m128i cmp = _mm_cmpeq_epi32(sum, zero);\n\n                int mask = _mm_movemask_epi8(cmp);\n                if (mask != 0) {\n                    _mm_free(data);\n                    return true;\n                }\n                k += 4;\n            }\n            // Process remaining elements that don't fill a full SIMD register\n            for (; k < n; ++k) {\n                if (l[i] + l[j] + l[k] == 0) {\n                    _mm_free(data);\n                    return true;\n                }\n            }\n        }\n    }\n\n    _mm_free(data);\n    return false;\n}\n```"}
{"task_id": "SimdBench_82_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool triples_sum_to_zero_simd(std::vector<int> l) {\n    int n = l.size();\n    if (n < 3) return false;\n\n    // Align the vector to 16 bytes for SIMD operations\n    __m128i* data = (__m128i*) _mm_malloc(n * sizeof(int), 16);\n    for (int i = 0; i < n; ++i) {\n        ((int*)data)[i] = l[i];\n    }\n\n    for (int i = 0; i < n - 2; ++i) {\n        for (int j = i + 1; j < n - 1; ++j) {\n            __m128i a_b = _mm_set1_epi32(l[i] + l[j]);\n            for (int k = j + 1; k <= n - 4; k += 4) {\n                __m128i c = _mm_loadu_si128(&data[k / 4]);\n                __m128i sum = _mm_add_epi32(a_b, c);\n                __m128i zero = _mm_setzero_si128();\n                __m128i cmp = _mm_cmpeq_epi32(sum, zero);\n                int mask = _mm_movemask_epi8(cmp);\n                if (mask != 0) {\n                    _mm_free(data);\n                    return true;\n                }\n            }\n            // Handle remaining elements\n            for (int k = (n / 4) * 4; k < n; ++k) {\n                if (l[i] + l[j] + l[k] == 0) {\n                    _mm_free(data);\n                    return true;\n                }\n            }\n        }\n    }\n\n    _mm_free(data);\n    return false;\n}\n```"}
{"task_id": "SimdBench_82_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool triples_sum_to_zero_simd(std::vector<int> l) {\n    int n = l.size();\n    if (n < 3) return false;\n\n    // Align the input vector to 16 bytes for SIMD operations\n    __m128i* data = (__m128i*) _mm_malloc(n * sizeof(int), 16);\n    for (int i = 0; i < n; ++i) {\n        ((int*)data)[i] = l[i];\n    }\n\n    for (int i = 0; i < n - 2; ++i) {\n        for (int j = i + 1; j < n - 1; ++j) {\n            __m128i a_b = _mm_set1_epi32(l[i] + l[j]);\n            for (int k = j + 1; k <= n - 4; k += 4) {\n                __m128i c = _mm_loadu_si128(&data[k / 4]);\n                __m128i sum = _mm_add_epi32(a_b, c);\n                __m128i zero = _mm_setzero_si128();\n                __m128i cmp = _mm_cmpeq_epi32(sum, zero);\n                int mask = _mm_movemask_epi8(cmp);\n                if (mask != 0) {\n                    _mm_free(data);\n                    return true;\n                }\n            }\n            // Handle remaining elements\n            for (int k = (n / 4) * 4; k < n; ++k) {\n                if (l[i] + l[j] + l[k] == 0) {\n                    _mm_free(data);\n                    return true;\n                }\n            }\n        }\n    }\n\n    _mm_free(data);\n    return false;\n}\n```"}
{"task_id": "SimdBench_82_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool triples_sum_to_zero_simd(std::vector<int> l) {\n    int n = l.size();\n    if (n < 3) return false;\n\n    // Align the vector to 16 bytes for SIMD operations\n    __m128i* data = (__m128i*) _mm_malloc(n * sizeof(int), 16);\n    for (int i = 0; i < n; ++i) {\n        ((int*)data)[i] = l[i];\n    }\n\n    for (int i = 0; i < n - 2; ++i) {\n        for (int j = i + 1; j < n - 1; ++j) {\n            __m128i a_b = _mm_set1_epi32(l[i] + l[j]);\n            for (int k = j + 1; k <= n - 4; k += 4) {\n                __m128i c = _mm_loadu_si128(&data[k / 4]);\n                __m128i sum = _mm_add_epi32(a_b, c);\n                __m128i zero = _mm_setzero_si128();\n                __m128i cmp = _mm_cmpeq_epi32(sum, zero);\n                int mask = _mm_movemask_epi8(cmp);\n                if (mask != 0) {\n                    _mm_free(data);\n                    return true;\n                }\n            }\n            // Handle remaining elements\n            for (int k = (n / 4) * 4; k < n; ++k) {\n                if (l[i] + l[j] + l[k] == 0) {\n                    _mm_free(data);\n                    return true;\n                }\n            }\n        }\n    }\n\n    _mm_free(data);\n    return false;\n}\n```"}
{"task_id": "SimdBench_82_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool triples_sum_to_zero_simd(std::vector<int> l) {\n    int n = l.size();\n    if (n < 3) return false;\n\n    // Align the input vector to 16 bytes for SIMD operations\n    __m128i* data = (__m128i*) _mm_malloc(n * sizeof(int), 16);\n    for (int i = 0; i < n; ++i) {\n        ((int*)data)[i] = l[i];\n    }\n\n    for (int i = 0; i < n - 2; ++i) {\n        for (int j = i + 1; j < n - 1; ++j) {\n            __m128i sum_ij = _mm_set1_epi32(l[i] + l[j]);\n            for (int k = j + 1; k <= n - 4; k += 4) {\n                __m128i vec_k = _mm_loadu_si128(&data[k / 4]);\n                __m128i result = _mm_add_epi32(sum_ij, vec_k);\n                __m128i zero = _mm_setzero_si128();\n                __m128i cmp = _mm_cmpeq_epi32(result, zero);\n                int mask = _mm_movemask_epi8(cmp);\n                if (mask != 0) {\n                    _mm_free(data);\n                    return true;\n                }\n            }\n            // Handle remaining elements\n            for (int k = n - (n % 4); k < n; ++k) {\n                if (l[i] + l[j] + l[k] == 0) {\n                    _mm_free(data);\n                    return true;\n                }\n            }\n        }\n    }\n\n    _mm_free(data);\n    return false;\n}\n```"}
{"task_id": "SimdBench_83_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> incr_list_simd(std::vector<int> l) {\n    size_t size = l.size();\n    size_t simd_size = size - (size % 4);\n    __m128i increment = _mm_set1_epi32(1);\n\n    for (size_t i = 0; i < simd_size; i += 4) {\n        __m128i vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&l[i]));\n        vec = _mm_add_epi32(vec, increment);\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&l[i]), vec);\n    }\n\n    for (size_t i = simd_size; i < size; ++i) {\n        l[i] += 1;\n    }\n\n    return l;\n}\n```"}
{"task_id": "SimdBench_83_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> incr_list_simd(std::vector<int> l) {\n    size_t n = l.size();\n    std::vector<int> result(n);\n\n    // Process 4 elements at a time using SSE2\n    size_t i = 0;\n    for (; i + 4 <= n; i += 4) {\n        // Load 4 integers into an SSE register\n        __m128i vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&l[i]));\n\n        // Create a vector of ones\n        __m128i ones = _mm_set1_epi32(1);\n\n        // Add 1 to each element\n        __m128i incremented = _mm_add_epi32(vec, ones);\n\n        // Store the result back to memory\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i]), incremented);\n    }\n\n    // Handle remaining elements\n    for (; i < n; ++i) {\n        result[i] = l[i] + 1;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_83_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> incr_list_simd(std::vector<int> l) {\n    size_t n = l.size();\n    std::vector<int> result(n);\n\n    // Process 4 elements at a time using SSE2\n    size_t i = 0;\n    for (; i + 4 <= n; i += 4) {\n        // Load 4 integers into an SSE register\n        __m128i vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&l[i]));\n\n        // Create a vector of ones\n        __m128i ones = _mm_set1_epi32(1);\n\n        // Add 1 to each element\n        __m128i incremented = _mm_add_epi32(vec, ones);\n\n        // Store the result back to memory\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i]), incremented);\n    }\n\n    // Handle remaining elements that are less than 4\n    for (; i < n; ++i) {\n        result[i] = l[i] + 1;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_83_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> incr_list_simd(std::vector<int> l) {\n    size_t size = l.size();\n    size_t simd_size = size - (size % 4);\n    __m128i increment = _mm_set1_epi32(1);\n\n    for (size_t i = 0; i < simd_size; i += 4) {\n        __m128i vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&l[i]));\n        vec = _mm_add_epi32(vec, increment);\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&l[i]), vec);\n    }\n\n    for (size_t i = simd_size; i < size; ++i) {\n        l[i] += 1;\n    }\n\n    return l;\n}\n```"}
{"task_id": "SimdBench_83_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> incr_list_simd(std::vector<int> l) {\n    size_t size = l.size();\n    size_t simd_size = size - (size % 4);\n    __m128i increment = _mm_set1_epi32(1);\n\n    for (size_t i = 0; i < simd_size; i += 4) {\n        __m128i vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&l[i]));\n        vec = _mm_add_epi32(vec, increment);\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&l[i]), vec);\n    }\n\n    for (size_t i = simd_size; i < size; ++i) {\n        l[i] += 1;\n    }\n\n    return l;\n}\n```"}
{"task_id": "SimdBench_84_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool pairs_sum_to_zero_simd(std::vector<int> l) {\n    int n = l.size();\n    if (n < 2) return false;\n\n    // Ensure the vector size is a multiple of 4 for SIMD processing\n    int simd_size = (n / 4) * 4;\n    __m128i zero = _mm_setzero_si128();\n\n    for (int i = 0; i < simd_size; i += 4) {\n        __m128i vec1 = _mm_loadu_si128((__m128i*)&l[i]);\n\n        for (int j = i + 4; j < simd_size; j += 4) {\n            __m128i vec2 = _mm_loadu_si128((__m128i*)&l[j]);\n            __m128i sum = _mm_add_epi32(vec1, vec2);\n\n            // Check if any element in the sum is zero\n            if (!_mm_test_all_zeros(sum, sum)) {\n                // Refine check to confirm exact zero\n                int temp[4];\n                _mm_storeu_si128((__m128i*)temp, sum);\n                for (int k = 0; k < 4; ++k) {\n                    if (temp[k] == 0) return true;\n                }\n            }\n        }\n    }\n\n    // Handle remaining elements that don't fit into SIMD blocks\n    for (int i = simd_size; i < n; ++i) {\n        for (int j = i + 1; j < n; ++j) {\n            if (l[i] + l[j] == 0) return true;\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_84_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool pairs_sum_to_zero_simd(std::vector<int> l) {\n    int n = l.size();\n    if (n < 2) return false;\n\n    // Ensure the vector size is a multiple of 4 for SIMD processing\n    int simd_size = (n / 4) * 4;\n\n    for (int i = 0; i < n; ++i) {\n        __m128i vi = _mm_set1_epi32(l[i]); // Broadcast l[i] to all elements of the SIMD register\n\n        for (int j = 0; j < simd_size; j += 4) {\n            __m128i vj = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&l[j])); // Load 4 integers from l\n            __m128i sum = _mm_add_epi32(vi, vj); // Add l[i] to each of the 4 integers\n            __m128i zero_mask = _mm_cmpeq_epi32(sum, _mm_setzero_si128()); // Compare with zero\n            int mask = _mm_movemask_ps(_mm_castsi128_ps(zero_mask)); // Extract comparison results\n\n            if (mask != 0) {\n                // Check if any match is not due to comparing the same element\n                for (int k = 0; k < 4; ++k) {\n                    if ((mask & (1 << k)) && (i != j + k)) {\n                        return true;\n                    }\n                }\n            }\n        }\n\n        // Process remaining elements that don't fit into SIMD registers\n        for (int j = simd_size; j < n; ++j) {\n            if (l[i] + l[j] == 0 && i != j) {\n                return true;\n            }\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_84_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool pairs_sum_to_zero_simd(std::vector<int> l) {\n    int n = l.size();\n    if (n < 2) return false;\n\n    // Align the vector to 16 bytes for SIMD operations\n    __m128i* data = (__m128i*)__builtin_assume_aligned(l.data(), 16);\n\n    for (int i = 0; i < n; ++i) {\n        __m128i vi = _mm_set1_epi32(l[i]); // Broadcast l[i] to all elements of the SIMD register\n\n        for (int j = 0; j + 4 <= n; j += 4) {\n            __m128i vj = _mm_loadu_si128(&data[j / 4]); // Load 4 integers from the array\n            __m128i sum = _mm_add_epi32(vi, vj);        // Add l[i] to each of the 4 integers\n            __m128i zero = _mm_setzero_si128();         // Create a zero vector\n            __m128i cmp = _mm_cmpeq_epi32(sum, zero);   // Compare if any sum is zero\n\n            int mask = _mm_movemask_epi8(cmp);          // Extract comparison results into a mask\n            if (mask != 0) {\n                // Check if the match is not with the same element\n                for (int k = 0; k < 4; ++k) {\n                    if (l[i] + l[j + k] == 0 && i != j + k) {\n                        return true;\n                    }\n                }\n            }\n        }\n\n        // Handle remaining elements that don't fit into a full SIMD register\n        for (int j = (n / 4) * 4; j < n; ++j) {\n            if (l[i] + l[j] == 0 && i != j) {\n                return true;\n            }\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_84_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool pairs_sum_to_zero_simd(std::vector<int> l) {\n    int n = l.size();\n    if (n < 2) return false;\n\n    // Ensure the vector size is a multiple of 4 for SIMD processing\n    int padded_size = (n + 3) & ~3;\n    std::vector<int> padded_l(padded_size, 0);\n    std::copy(l.begin(), l.end(), padded_l.begin());\n\n    for (int i = 0; i < n; ++i) {\n        __m128i v = _mm_set1_epi32(l[i]); // Broadcast l[i] to all elements of the SIMD register\n\n        for (int j = 0; j < padded_size; j += 4) {\n            __m128i w = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&padded_l[j])); // Load 4 integers\n            __m128i sum = _mm_add_epi32(v, w); // Add l[i] to each of the 4 integers\n\n            // Check if any of the sums are zero\n            int mask = _mm_movemask_ps(_mm_castsi128_ps(_mm_cmpeq_epi32(sum, _mm_setzero_si128())));\n            if (mask != 0) {\n                // Verify that the match is not with the same element\n                for (int k = 0; k < 4; ++k) {\n                    if ((mask & (1 << k)) && (i != j + k) && (l[i] + padded_l[j + k] == 0)) {\n                        return true;\n                    }\n                }\n            }\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_84_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool pairs_sum_to_zero_simd(std::vector<int> l) {\n    int n = l.size();\n    if (n < 2) return false;\n\n    // Ensure the vector size is a multiple of 4 for SIMD processing\n    int simd_size = (n / 4) * 4;\n    __m128i zero = _mm_setzero_si128();\n\n    for (int i = 0; i < n; ++i) {\n        __m128i vi = _mm_set1_epi32(l[i]);\n\n        for (int j = 0; j < simd_size; j += 4) {\n            __m128i vj = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&l[j]));\n            __m128i sum = _mm_add_epi32(vi, vj);\n            __m128i cmp = _mm_cmpeq_epi32(sum, zero);\n\n            int mask = _mm_movemask_epi8(cmp);\n            if (mask != 0) {\n                // Check if the match is not due to comparing the same element\n                for (int k = 0; k < 4; ++k) {\n                    if ((mask & (0xF << (k * 4))) && (i != j + k)) {\n                        return true;\n                    }\n                }\n            }\n        }\n\n        // Process remaining elements that don't fit into SIMD registers\n        for (int j = simd_size; j < n; ++j) {\n            if (l[i] + l[j] == 0 && i != j) {\n                return true;\n            }\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_85_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n#include <algorithm>\n\nstd::string change_base_simd(int64_t x, int8_t base) {\n    char buffer[65];\n    int index = 64;\n    buffer[index] = '\\0';\n\n    __m128i vbase = _mm_set1_epi8(base);\n    __m128i zeros = _mm_setzero_si128();\n    __m128i ones = _mm_set1_epi8(1);\n\n    while (x > 0) {\n        __m128i vx = _mm_set1_epi64x(x);\n        __m128i remainder = _mm_setzero_si128();\n\n        // Compute remainder using SSE2\n        __m128i quotient = _mm_div_epu64(vx, vbase, &remainder);\n\n        // Extract the lower 64-bit integer from the SIMD register\n        int8_t rem = _mm_cvtsi128_si32(remainder) + '0';\n        buffer[--index] = static_cast<char>(rem);\n\n        // Update x for next iteration\n        x = _mm_cvtsi128_si64(quotient);\n    }\n\n    return std::string(buffer + index);\n}\n```"}
{"task_id": "SimdBench_85_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n#include <algorithm>\n\nstd::string change_base_simd(int64_t x, int8_t base) {\n    char buffer[65];\n    int index = 64;\n    buffer[index] = '\\0';\n\n    __m128i vbase = _mm_set1_epi8(base);\n    __m128i vzero = _mm_setzero_si128();\n    __m128i vdigits = _mm_setr_epi8('0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 0, 0, 0, 0, 0, 0);\n\n    while (x > 0) {\n        int64_t remainder = x % base;\n        x /= base;\n\n        __m128i vremainder = _mm_set1_epi8(remainder);\n        __m128i mask = _mm_cmpeq_epi8(vremainder, _mm_set_epi8(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15));\n        __m128i result = _mm_shuffle_epi8(vdigits, mask);\n\n        buffer[--index] = _mm_extract_epi8(result, 0);\n    }\n\n    return std::string(buffer + index);\n}\n```"}
{"task_id": "SimdBench_85_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n#include <algorithm>\n\nstd::string change_base_simd(int64_t x, int8_t base) {\n    char buffer[65];\n    int index = 64;\n    buffer[index] = '\\0';\n\n    __m128i vbase = _mm_set1_epi8(base);\n    __m128i vzero = _mm_setzero_si128();\n    __m128i vremainder;\n\n    while (x > 0) {\n        // Compute remainder using SIMD (broadcast x and divide by base)\n        __m128i vx = _mm_set1_epi64x(x);\n        vremainder = _mm_rem_epi32(vx, vbase);\n\n        // Extract the remainder (last element in the vector)\n        int remainder = _mm_cvtsi128_si32(vremainder);\n\n        // Convert remainder to ASCII and store in buffer\n        buffer[--index] = '0' + remainder;\n\n        // Update x for next iteration\n        x /= base;\n    }\n\n    return std::string(buffer + index);\n}\n```"}
{"task_id": "SimdBench_85_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n#include <algorithm>\n\nstd::string change_base_simd(int64_t x, int8_t base) {\n    char buffer[65];\n    int index = 64;\n    buffer[index] = '\\0';\n\n    __m128i vbase = _mm_set1_epi8(base);\n    __m128i vzero = _mm_setzero_si128();\n    __m128i vremainder;\n\n    while (x > 0) {\n        // Compute remainder using SSE2\n        vremainder = _mm_cvtsi64_si128(x); // Load x into SIMD register\n        vremainder = _mm_rem_epi32(vremainder, vbase); // Compute x % base\n        int remainder = _mm_cvtsi128_si32(vremainder); // Extract remainder\n\n        // Convert remainder to ASCII and store in buffer\n        buffer[--index] = '0' + remainder;\n\n        // Update x for next iteration\n        x /= base;\n    }\n\n    return std::string(buffer + index);\n}\n```"}
{"task_id": "SimdBench_85_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n#include <algorithm>\n\nstd::string change_base_simd(int64_t x, int8_t base) {\n    char buffer[65];\n    int index = 64;\n    buffer[index] = '\\0';\n\n    __m128i vbase = _mm_set1_epi8(base);\n    __m128i zeros = _mm_setzero_si128();\n    __m128i ones = _mm_set1_epi8(1);\n\n    while (x > 0) {\n        __m128i vx = _mm_set1_epi64x(x);\n        __m128i remainder = _mm_setzero_si128();\n\n        // Compute remainder using SSE2\n        __m128i quotient = _mm_div_epu64(vx, vbase, &remainder);\n\n        // Extract the low byte of the remainder\n        int8_t rem = _mm_cvtsi128_si32(remainder) & 0xFF;\n\n        // Convert remainder to ASCII and store in buffer\n        buffer[--index] = '0' + rem;\n\n        // Update x with the quotient\n        x = _mm_cvtsi128_si64(quotient);\n    }\n\n    return std::string(buffer + index);\n}\n```"}
{"task_id": "SimdBench_86_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool is_palindrome_simd(std::string text) {\n    int len = text.length();\n    if (len <= 1) return true;\n\n    const char* data = text.c_str();\n    int i = 0, j = len - 1;\n\n    // Process the string in chunks of 16 bytes using SSE2\n    while (i + 16 <= j + 1) {\n        __m128i front = _mm_loadu_si128(reinterpret_cast<const __m128i*>(data + i));\n        __m128i back = _mm_loadu_si128(reinterpret_cast<const __m128i*>(data + j - 15));\n\n        // Reverse the back vector\n        back = _mm_shuffle_epi8(back, _mm_setr_epi8(15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 0));\n\n        // Compare front and back vectors\n        __m128i cmp = _mm_cmpeq_epi8(front, back);\n        int mask = _mm_movemask_epi8(cmp);\n\n        // If any byte doesn't match, it's not a palindrome\n        if (mask != 0xFFFF) {\n            return false;\n        }\n\n        i += 16;\n        j -= 16;\n    }\n\n    // Handle remaining characters that don't fit into 16-byte chunks\n    while (i < j) {\n        if (data[i] != data[j]) {\n            return false;\n        }\n        i++;\n        j--;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_86_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool is_palindrome_simd(std::string text) {\n    int len = text.length();\n    if (len <= 1) return true;\n\n    // Align the string to 16 bytes for SIMD operations\n    char* aligned_text = (char*)_mm_malloc(len + 16, 16);\n    memcpy(aligned_text, text.c_str(), len);\n\n    int mid = len / 2;\n    int i = 0;\n\n    __m128i mask = _mm_set_epi8(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15);\n\n    for (; i <= mid - 16; i += 16) {\n        __m128i front = _mm_load_si128((__m128i*)(aligned_text + i));\n        __m128i back = _mm_loadu_si128((__m128i*)(aligned_text + len - i - 16));\n\n        back = _mm_shuffle_epi8(back, mask);\n\n        __m128i cmp = _mm_cmpeq_epi8(front, back);\n        if (_mm_movemask_epi8(cmp) != 0xFFFF) {\n            _mm_free(aligned_text);\n            return false;\n        }\n    }\n\n    // Check remaining characters\n    for (; i < mid; ++i) {\n        if (aligned_text[i] != aligned_text[len - i - 1]) {\n            _mm_free(aligned_text);\n            return false;\n        }\n    }\n\n    _mm_free(aligned_text);\n    return true;\n}\n```"}
{"task_id": "SimdBench_86_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool is_palindrome_simd(std::string text) {\n    int len = text.length();\n    if (len <= 1) return true;\n\n    // Align the string to 16 bytes for SIMD operations\n    char* aligned_text = (char*)_mm_malloc(len + 16, 16);\n    if (!aligned_text) return false;\n    memcpy(aligned_text, text.c_str(), len);\n\n    bool result = true;\n    int mid = len / 2;\n    int i = 0;\n\n    // Process 16 characters at a time using SSE2 intrinsics\n    for (; i <= mid - 16; i += 16) {\n        __m128i front = _mm_loadu_si128((__m128i*)(aligned_text + i));\n        __m128i back = _mm_loadu_si128((__m128i*)(aligned_text + len - i - 16));\n\n        // Reverse the back vector\n        back = _mm_shuffle_epi8(back, _mm_setr_epi8(15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 0));\n\n        // Compare front and reversed back\n        __m128i cmp = _mm_cmpeq_epi8(front, back);\n        int mask = _mm_movemask_epi8(cmp);\n\n        if (mask != 0xFFFF) {\n            result = false;\n            break;\n        }\n    }\n\n    // Process remaining characters sequentially\n    if (result) {\n        for (; i < mid; ++i) {\n            if (aligned_text[i] != aligned_text[len - i - 1]) {\n                result = false;\n                break;\n            }\n        }\n    }\n\n    _mm_free(aligned_text);\n    return result;\n}\n```"}
{"task_id": "SimdBench_86_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool is_palindrome_simd(std::string text) {\n    int len = text.length();\n    if (len <= 1) return true;\n\n    // Align the string to 16 bytes for SIMD operations\n    char* aligned_text = (char*)_mm_malloc(len + 16, 16);\n    if (!aligned_text) return false;\n    memcpy(aligned_text, text.c_str(), len);\n\n    bool result = true;\n    int mid = len / 2;\n    int simd_width = 16;\n\n    __m128i mask = _mm_set_epi8(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15);\n\n    for (int i = 0; i < mid; i += simd_width) {\n        int j = len - i - simd_width;\n        if (j < i) break;\n\n        __m128i front = _mm_loadu_si128((__m128i*)(aligned_text + i));\n        __m128i back = _mm_loadu_si128((__m128i*)(aligned_text + j));\n\n        // Reverse the back vector\n        back = _mm_shuffle_epi8(back, mask);\n\n        // Compare front and reversed back\n        __m128i cmp = _mm_cmpeq_epi8(front, back);\n        int mask_result = _mm_movemask_epi8(cmp);\n\n        if (mask_result != 0xFFFF) {\n            result = false;\n            break;\n        }\n    }\n\n    _mm_free(aligned_text);\n    return result;\n}\n```"}
{"task_id": "SimdBench_86_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool is_palindrome_simd(std::string text) {\n    int len = text.length();\n    if (len <= 1) return true;\n\n    // Align the string to 16 bytes for SIMD operations\n    char* aligned_text = (char*)_mm_malloc(len + 16, 16);\n    if (!aligned_text) return false;\n    memcpy(aligned_text, text.c_str(), len);\n\n    bool result = true;\n    int mid = len / 2;\n    int i = 0;\n\n    // Process 16 characters at a time using SSE2\n    for (; i <= mid - 16; i += 16) {\n        __m128i front = _mm_loadu_si128((__m128i*)(aligned_text + i));\n        __m128i back = _mm_loadu_si128((__m128i*)(aligned_text + len - i - 16));\n\n        // Reverse the back vector\n        back = _mm_shuffle_epi8(back, _mm_setr_epi8(15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 0));\n\n        // Compare front and reversed back\n        __m128i cmp = _mm_cmpeq_epi8(front, back);\n        int mask = _mm_movemask_epi8(cmp);\n        if (mask != 0xFFFF) {\n            result = false;\n            break;\n        }\n    }\n\n    // Process remaining characters\n    for (; i < mid; ++i) {\n        if (aligned_text[i] != aligned_text[len - i - 1]) {\n            result = false;\n            break;\n        }\n    }\n\n    _mm_free(aligned_text);\n    return result;\n}\n```"}
{"task_id": "SimdBench_87_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nstd::string decode_shift_simd(std::string s) {\n    std::string out(s.size(), 0);\n    int i = 0;\n\n    // Process 16 characters at a time using SSE2 intrinsics\n    for (; i + 15 < s.size(); i += 16) {\n        // Load 16 characters into an SSE register\n        __m128i input = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&s[i]));\n\n        // Subtract 'a' to normalize to 0-25 range\n        __m128i base = _mm_set1_epi8('a');\n        __m128i normalized = _mm_sub_epi8(input, base);\n\n        // Subtract 5 to reverse the shift\n        __m128i shift = _mm_set1_epi8(5);\n        __m128i shifted = _mm_sub_epi8(normalized, shift);\n\n        // Add 26 to ensure positive values before modulo\n        __m128i mod_base = _mm_set1_epi8(26);\n        __m128i positive = _mm_add_epi8(shifted, mod_base);\n\n        // Modulo 26 using bitwise AND (valid because 26 is a power of 2 minus 2)\n        __m128i mask = _mm_set1_epi8(0x1F); // Mask for modulo 26\n        __m128i modded = _mm_and_si128(positive, mask);\n\n        // Add 'a' back to get the final character\n        __m128i result = _mm_add_epi8(modded, base);\n\n        // Store the result back into the output string\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&out[i]), result);\n    }\n\n    // Process remaining characters (if any) using scalar code\n    for (; i < s.size(); ++i) {\n        int w = ((int)s[i] - 5 - (int)'a' + 26) % 26 + (int)'a';\n        out[i] = (char)w;\n    }\n\n    return out;\n}\n```"}
{"task_id": "SimdBench_87_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nstd::string decode_shift_simd(std::string s) {\n    std::string out(s.size(), 0);\n    int i = 0;\n\n    // Process 16 characters at a time using SSE2 intrinsics\n    for (; i + 15 < s.size(); i += 16) {\n        // Load 16 characters into an SSE register\n        __m128i input = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&s[i]));\n\n        // Subtract 'a' to normalize to 0-25 range\n        __m128i base = _mm_set1_epi8('a');\n        __m128i normalized = _mm_sub_epi8(input, base);\n\n        // Subtract 5 to reverse the shift\n        __m128i shift = _mm_set1_epi8(5);\n        __m128i shifted = _mm_sub_epi8(normalized, shift);\n\n        // Add 26 to ensure positive values before modulo\n        __m128i mod_base = _mm_set1_epi8(26);\n        __m128i positive = _mm_add_epi8(shifted, mod_base);\n\n        // Perform modulo 26 using SSE2 operations\n        __m128i result = _mm_and_si128(positive, _mm_set1_epi8(0x1F)); // Mask with 0x1F (31) to simulate modulo\n\n        // Add 'a' back to get the final character\n        __m128i decoded = _mm_add_epi8(result, base);\n\n        // Store the result back into the output string\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&out[i]), decoded);\n    }\n\n    // Process remaining characters (if any) using scalar code\n    for (; i < s.size(); ++i) {\n        int w = ((int)s[i] - 5 - (int)'a' + 26) % 26 + (int)'a';\n        out[i] = (char)w;\n    }\n\n    return out;\n}\n```"}
{"task_id": "SimdBench_87_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nstd::string decode_shift_simd(std::string s) {\n    std::string out(s.size(), 0);\n    int i = 0;\n\n    // Process 16 characters at a time using SSE2 intrinsics\n    for (; i + 15 < s.size(); i += 16) {\n        // Load 16 characters into an SSE register\n        __m128i input = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&s[i]));\n\n        // Subtract 'a' to normalize to 0-25 range\n        __m128i base = _mm_set1_epi8('a');\n        __m128i normalized = _mm_sub_epi8(input, base);\n\n        // Subtract 5 to reverse the shift\n        __m128i shift = _mm_set1_epi8(5);\n        __m128i shifted = _mm_sub_epi8(normalized, shift);\n\n        // Add 26 to ensure non-negative values before modulo\n        __m128i mod_base = _mm_set1_epi8(26);\n        __m128i adjusted = _mm_add_epi8(shifted, mod_base);\n\n        // Perform modulo 26 using SSE2 arithmetic\n        __m128i result = _mm_and_si128(adjusted, _mm_set1_epi8(0x1F)); // Mask for modulo 26\n\n        // Add 'a' back to get the final character\n        __m128i decoded = _mm_add_epi8(result, base);\n\n        // Store the result back into the output string\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&out[i]), decoded);\n    }\n\n    // Handle remaining characters (if any) with scalar code\n    for (; i < s.size(); ++i) {\n        int w = ((int)s[i] - 5 - (int)'a' + 26) % 26 + (int)'a';\n        out[i] = (char)w;\n    }\n\n    return out;\n}\n```"}
{"task_id": "SimdBench_87_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nstd::string decode_shift_simd(std::string s) {\n    std::string out(s.size(), 0);\n    int i = 0;\n\n    // Process 16 characters at a time using SSE2 intrinsics\n    for (; i + 15 < s.size(); i += 16) {\n        // Load 16 characters into an SSE register\n        __m128i input = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&s[i]));\n\n        // Subtract 'a' to normalize to 0-25 range\n        __m128i base = _mm_set1_epi8('a');\n        __m128i normalized = _mm_sub_epi8(input, base);\n\n        // Subtract 5 to reverse the shift\n        __m128i shift = _mm_set1_epi8(5);\n        __m128i shifted = _mm_sub_epi8(normalized, shift);\n\n        // Add 26 to ensure positive values before modulo\n        __m128i mod_base = _mm_set1_epi8(26);\n        __m128i positive = _mm_add_epi8(shifted, mod_base);\n\n        // Perform modulo 26 using SSE2 arithmetic\n        __m128i modulo = _mm_and_si128(positive, _mm_set1_epi8(0x1F)); // Mask for modulo 26\n\n        // Add 'a' back to get the final decoded characters\n        __m128i result = _mm_add_epi8(modulo, base);\n\n        // Store the result back into the output string\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&out[i]), result);\n    }\n\n    // Process remaining characters (if any) using scalar code\n    for (; i < s.size(); ++i) {\n        int w = ((int)s[i] - 5 - (int)'a' + 26) % 26 + (int)'a';\n        out[i] = (char)w;\n    }\n\n    return out;\n}\n```"}
{"task_id": "SimdBench_87_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nstd::string decode_shift_simd(std::string s) {\n    std::string out(s.size(), 0);\n    int i = 0;\n\n    // Process 16 characters at a time using SSE2 intrinsics\n    for (; i + 15 < s.size(); i += 16) {\n        // Load 16 characters into an SSE register\n        __m128i input = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&s[i]));\n\n        // Subtract 'a' to normalize to 0-25 range\n        __m128i base = _mm_set1_epi8('a');\n        __m128i normalized = _mm_sub_epi8(input, base);\n\n        // Subtract 5 to reverse the shift\n        __m128i shift = _mm_set1_epi8(5);\n        __m128i shifted = _mm_sub_epi8(normalized, shift);\n\n        // Add 26 to ensure positive values before modulo\n        __m128i mod_base = _mm_set1_epi8(26);\n        __m128i positive = _mm_add_epi8(shifted, mod_base);\n\n        // Perform modulo 26\n        __m128i modulo = _mm_and_si128(positive, _mm_set1_epi8(0x1F)); // Mask for modulo 26\n\n        // Add 'a' back to get the final character\n        __m128i result = _mm_add_epi8(modulo, base);\n\n        // Store the result back into the output string\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&out[i]), result);\n    }\n\n    // Process remaining characters (if any) using scalar code\n    for (; i < s.size(); ++i) {\n        int w = ((int)s[i] - 5 - (int)'a' + 26) % 26 + (int)'a';\n        out[i] = (char)w;\n    }\n\n    return out;\n}\n```"}
{"task_id": "SimdBench_88_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool below_threshold_simd(std::vector<int> l, int t) {\n    __m128i threshold = _mm_set1_epi32(t);\n    size_t i = 0;\n    size_t size = l.size();\n\n    // Process 4 integers at a time using SIMD\n    for (; i + 4 <= size; i += 4) {\n        __m128i vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&l[i]));\n        __m128i cmp = _mm_cmpgt_epi32(vec, threshold); // Compare if vec > threshold\n        if (!_mm_testz_si128(cmp, cmp)) { // Check if any element is greater than threshold\n            return false;\n        }\n    }\n\n    // Process remaining elements\n    for (; i < size; ++i) {\n        if (l[i] >= t) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_88_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool below_threshold_simd(std::vector<int> l, int t) {\n    __m128i threshold = _mm_set1_epi32(t);\n    size_t i = 0;\n    size_t size = l.size();\n\n    // Process 4 integers at a time using SSE2\n    for (; i + 4 <= size; i += 4) {\n        __m128i vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&l[i]));\n        __m128i cmp = _mm_cmpgt_epi32(vec, threshold); // Compare if vec > threshold\n        if (!_mm_testz_si128(cmp, cmp)) { // Check if any element is greater than threshold\n            return false;\n        }\n    }\n\n    // Process remaining elements\n    for (; i < size; ++i) {\n        if (l[i] >= t) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_88_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool below_threshold_simd(std::vector<int> l, int t) {\n    __m128i threshold = _mm_set1_epi32(t);\n    size_t i = 0;\n    size_t size = l.size();\n\n    // Process 4 integers at a time using SSE\n    for (; i + 4 <= size; i += 4) {\n        __m128i vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&l[i]));\n        __m128i cmp = _mm_cmplt_epi32(vec, threshold); // Compare if vec < threshold\n        if (_mm_movemask_epi8(cmp) != 0xFFFF) { // Check if all elements are less than threshold\n            return false;\n        }\n    }\n\n    // Process remaining elements\n    for (; i < size; ++i) {\n        if (l[i] >= t) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_88_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool below_threshold_simd(std::vector<int> l, int t) {\n    __m128i threshold = _mm_set1_epi32(t);\n    size_t i = 0;\n    size_t size = l.size();\n\n    // Process 4 integers at a time using SSE2\n    for (; i + 4 <= size; i += 4) {\n        __m128i vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&l[i]));\n        __m128i cmp = _mm_cmpgt_epi32(vec, threshold);\n        if (!_mm_testz_si128(cmp, cmp)) {\n            return false;\n        }\n    }\n\n    // Process remaining elements\n    for (; i < size; ++i) {\n        if (l[i] >= t) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_88_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool below_threshold_simd(std::vector<int> l, int t) {\n    __m128i threshold = _mm_set1_epi32(t);\n    size_t i = 0;\n    size_t size = l.size();\n\n    // Process 4 integers at a time using SIMD\n    for (; i + 4 <= size; i += 4) {\n        __m128i vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&l[i]));\n        __m128i cmp = _mm_cmpgt_epi32(vec, threshold);\n        if (!_mm_testz_si128(cmp, cmp)) {\n            return false;\n        }\n    }\n\n    // Process remaining elements\n    for (; i < size; ++i) {\n        if (l[i] >= t) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_89_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool correct_bracketing_simd(std::string brackets) {\n    int length = brackets.length();\n    if (length % 16 != 0) {\n        // Pad the string to make its length a multiple of 16\n        brackets.resize((length + 15) & ~15, ' ');\n    }\n\n    __m128i balance = _mm_setzero_si128(); // Initialize balance vector to zero\n    __m128i increment = _mm_set1_epi8(1);  // Increment for '<'\n    __m128i decrement = _mm_set1_epi8(-1); // Decrement for '>'\n\n    for (int i = 0; i < brackets.length(); i += 16) {\n        // Load 16 characters from the string\n        __m128i chars = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&brackets[i]));\n\n        // Create masks for '<' and '>'\n        __m128i less_than_mask = _mm_cmpeq_epi8(chars, _mm_set1_epi8('<'));\n        __m128i greater_than_mask = _mm_cmpeq_epi8(chars, _mm_set1_epi8('>'));\n\n        // Convert masks to increments and decrements\n        __m128i increments = _mm_and_si128(less_than_mask, increment);\n        __m128i decrements = _mm_and_si128(greater_than_mask, decrement);\n\n        // Update balance\n        balance = _mm_add_epi8(balance, increments);\n        balance = _mm_add_epi8(balance, decrements);\n\n        // Check for negative balance (invalid sequence)\n        __m128i negative_mask = _mm_cmplt_epi8(balance, _mm_setzero_si128());\n        if (_mm_movemask_epi8(negative_mask) != 0) {\n            return false;\n        }\n    }\n\n    // Horizontal sum of balance vector to check final balance\n    int final_balance = 0;\n    alignas(16) char temp[16];\n    _mm_store_si128(reinterpret_cast<__m128i*>(temp), balance);\n    for (int i = 0; i < 16; ++i) {\n        final_balance += temp[i];\n    }\n\n    return final_balance == 0;\n}\n```"}
{"task_id": "SimdBench_89_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool correct_bracketing_simd(std::string brackets) {\n    int length = brackets.length();\n    if (length % 16 != 0) {\n        // Padding the string to make its length a multiple of 16\n        brackets.resize((length + 15) & ~15, ' ');\n    }\n\n    __m128i openBracket = _mm_set1_epi8('<');\n    __m128i closeBracket = _mm_set1_epi8('>');\n\n    __m128i sumVector = _mm_setzero_si128();\n    int balance = 0;\n\n    for (int i = 0; i < brackets.length(); i += 16) {\n        __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&brackets[i]));\n\n        // Compare each byte with '<' and '>'\n        __m128i isOpen = _mm_cmpeq_epi8(chunk, openBracket);\n        __m128i isClose = _mm_cmpeq_epi8(chunk, closeBracket);\n\n        // Create masks for '<' and '>'\n        __m128i openMask = _mm_and_si128(isOpen, _mm_set1_epi8(1));\n        __m128i closeMask = _mm_and_si128(isClose, _mm_set1_epi8(-1));\n\n        // Combine masks into one vector where '<' contributes +1 and '>' contributes -1\n        __m128i combinedMask = _mm_add_epi8(openMask, closeMask);\n\n        // Accumulate the results horizontally\n        sumVector = _mm_add_epi8(sumVector, combinedMask);\n    }\n\n    // Horizontal sum of the accumulated vector\n    char results[16];\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(results), sumVector);\n\n    for (int i = 0; i < 16; ++i) {\n        balance += results[i];\n    }\n\n    return balance == 0;\n}\n```"}
{"task_id": "SimdBench_89_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool correct_bracketing_simd(std::string brackets) {\n    int length = brackets.length();\n    if (length % 16 != 0) {\n        // Pad the string to make its length a multiple of 16\n        brackets.resize((length + 15) & ~15, ' ');\n    }\n\n    __m128i openBracket = _mm_set1_epi8('<');\n    __m128i closeBracket = _mm_set1_epi8('>');\n    __m128i zero = _mm_setzero_si128();\n    __m128i balance = _mm_setzero_si128();\n\n    for (int i = 0; i < brackets.length(); i += 16) {\n        __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&brackets[i]));\n\n        // Compare for '<'\n        __m128i isOpen = _mm_cmpeq_epi8(chunk, openBracket);\n        // Compare for '>'\n        __m128i isClose = _mm_cmpeq_epi8(chunk, closeBracket);\n\n        // Convert masks to -1 (all bits set) or 0\n        __m128i addMask = _mm_and_si128(isOpen, _mm_set1_epi8(-1));\n        __m128i subMask = _mm_and_si128(isClose, _mm_set1_epi8(-1));\n\n        // Update balance\n        balance = _mm_add_epi8(balance, addMask);\n        balance = _mm_sub_epi8(balance, subMask);\n\n        // Check for negative balance\n        __m128i negativeCheck = _mm_cmpgt_epi8(zero, balance);\n        if (!_mm_testz_si128(negativeCheck, negativeCheck)) {\n            return false;\n        }\n    }\n\n    // Horizontal sum of balance to check final result\n    int finalBalance = 0;\n    char temp[16];\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(temp), balance);\n    for (int i = 0; i < 16; ++i) {\n        finalBalance += temp[i];\n    }\n\n    return finalBalance == 0;\n}\n```"}
{"task_id": "SimdBench_89_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool correct_bracketing_simd(std::string brackets) {\n    int length = brackets.length();\n    if (length % 16 != 0) {\n        // Pad the string to make its length a multiple of 16\n        brackets.resize((length + 15) & ~15, ' ');\n    }\n\n    __m128i balance = _mm_setzero_si128(); // Initialize balance vector to zero\n    __m128i one = _mm_set1_epi8(1);       // Vector of ones for increment/decrement\n    __m128i zero = _mm_setzero_si128();   // Vector of zeros for comparison\n\n    for (int i = 0; i < brackets.length(); i += 16) {\n        // Load 16 characters from the string\n        __m128i chars = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&brackets[i]));\n\n        // Create masks for '<' and '>'\n        __m128i less_than_mask = _mm_cmpeq_epi8(chars, _mm_set1_epi8('<'));\n        __m128i greater_than_mask = _mm_cmpeq_epi8(chars, _mm_set1_epi8('>'));\n\n        // Convert masks to -1 (all bits set) or 0\n        less_than_mask = _mm_and_si128(less_than_mask, one);\n        greater_than_mask = _mm_and_si128(greater_than_mask, one);\n\n        // Negate the greater_than_mask to decrement balance\n        greater_than_mask = _mm_sub_epi8(zero, greater_than_mask);\n\n        // Update balance: increment for '<', decrement for '>'\n        balance = _mm_add_epi8(balance, less_than_mask);\n        balance = _mm_add_epi8(balance, greater_than_mask);\n\n        // Check if any lane in balance goes negative\n        __m128i negative_mask = _mm_cmplt_epi8(balance, zero);\n        if (!_mm_testz_si128(negative_mask, negative_mask)) {\n            return false; // Early exit if balance goes negative\n        }\n    }\n\n    // Horizontal sum of balance to check final result\n    int final_balance = 0;\n    alignas(16) char temp[16];\n    _mm_store_si128(reinterpret_cast<__m128i*>(temp), balance);\n    for (int i = 0; i < 16; ++i) {\n        final_balance += temp[i];\n    }\n\n    return final_balance == 0;\n}\n```"}
{"task_id": "SimdBench_89_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool correct_bracketing_simd(std::string brackets) {\n    int length = brackets.length();\n    if (length % 16 != 0) {\n        // Pad the string to make its length a multiple of 16\n        brackets.resize((length + 15) & ~15, ' ');\n    }\n\n    __m128i open_bracket = _mm_set1_epi8('<');\n    __m128i close_bracket = _mm_set1_epi8('>');\n    __m128i zero = _mm_setzero_si128();\n    __m128i balance = _mm_setzero_si16();\n\n    for (int i = 0; i < brackets.length(); i += 16) {\n        __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&brackets[i]));\n\n        // Compare for '<'\n        __m128i is_open = _mm_cmpeq_epi8(chunk, open_bracket);\n        // Compare for '>'\n        __m128i is_close = _mm_cmpeq_epi8(chunk, close_bracket);\n\n        // Convert masks to 0 or 1\n        __m128i open_mask = _mm_and_si128(is_open, _mm_set1_epi8(1));\n        __m128i close_mask = _mm_and_si128(is_close, _mm_set1_epi8(1));\n\n        // Subtract close brackets from open brackets\n        balance = _mm_add_epi8(balance, _mm_sub_epi8(open_mask, close_mask));\n\n        // Check if any lane has gone negative\n        __m128i negative_check = _mm_cmpgt_epi8(zero, balance);\n        if (!_mm_testz_si128(negative_check, negative_check)) {\n            return false;\n        }\n    }\n\n    // Horizontal sum of balance to check final result\n    __m128i shuffle1 = _mm_shuffle_epi32(balance, _MM_SHUFFLE(1, 0, 3, 2));\n    __m128i sum1 = _mm_add_epi16(balance, shuffle1);\n    __m128i shuffle2 = _mm_shufflelo_epi16(sum1, _MM_SHUFFLE(1, 0, 3, 2));\n    __m128i sum2 = _mm_add_epi16(sum1, shuffle2);\n\n    int final_balance = _mm_cvtsi128_si32(sum2) & 0xFFFF;\n    return final_balance == 0;\n}\n```"}
{"task_id": "SimdBench_90_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nbool correct_bracketing_simd(std::string brackets) {\n    int length = brackets.length();\n    if (length % 16 != 0) {\n        // Padding the string to make its length a multiple of 16\n        brackets.resize((length + 15) & ~15, ' ');\n    }\n\n    __m128i open_bracket = _mm_set1_epi8('(');\n    __m128i close_bracket = _mm_set1_epi8(')');\n    __m128i balance = _mm_setzero_si128();\n    __m128i zero = _mm_setzero_si128();\n\n    for (int i = 0; i < brackets.length(); i += 16) {\n        __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&brackets[i]));\n\n        // Compare for '(' and ')'\n        __m128i is_open = _mm_cmpeq_epi8(chunk, open_bracket);\n        __m128i is_close = _mm_cmpeq_epi8(chunk, close_bracket);\n\n        // Convert masks to +1 or -1\n        __m128i add_mask = _mm_and_si128(is_open, _mm_set1_epi8(1));\n        __m128i sub_mask = _mm_and_si128(is_close, _mm_set1_epi8(1));\n\n        // Subtract masks to get net effect\n        __m128i net_effect = _mm_sub_epi8(add_mask, sub_mask);\n\n        // Accumulate balance\n        balance = _mm_add_epi8(balance, net_effect);\n\n        // Check for negative balance at any point\n        __m128i negative_check = _mm_cmpgt_epi8(zero, balance);\n        if (!_mm_testz_si128(negative_check, negative_check)) {\n            return false;\n        }\n    }\n\n    // Horizontal sum of balance vector to check final balance\n    int final_balance = 0;\n    char temp[16];\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(temp), balance);\n    for (int i = 0; i < 16; ++i) {\n        final_balance += temp[i];\n    }\n\n    return final_balance == 0;\n}\n```"}
{"task_id": "SimdBench_90_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nbool correct_bracketing_simd(std::string brackets) {\n    int length = brackets.length();\n    if (length % 16 != 0) {\n        // Padding the string to make its length a multiple of 16\n        brackets.resize((length + 15) & ~15, ' ');\n    }\n\n    __m128i open_bracket = _mm_set1_epi8('(');\n    __m128i close_bracket = _mm_set1_epi8(')');\n    __m128i balance = _mm_setzero_si128();\n\n    for (int i = 0; i < brackets.length(); i += 16) {\n        __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&brackets[i]));\n\n        __m128i is_open = _mm_cmpeq_epi8(chunk, open_bracket);\n        __m128i is_close = _mm_cmpeq_epi8(chunk, close_bracket);\n\n        __m128i open_mask = _mm_and_si128(is_open, _mm_set1_epi8(1));\n        __m128i close_mask = _mm_and_si128(is_close, _mm_set1_epi8(-1));\n\n        balance = _mm_add_epi8(balance, open_mask);\n        balance = _mm_add_epi8(balance, close_mask);\n    }\n\n    int result[16];\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(result), balance);\n\n    int total_balance = 0;\n    for (int i = 0; i < 16; ++i) {\n        total_balance += result[i];\n    }\n\n    return total_balance == 0;\n}\n```"}
{"task_id": "SimdBench_90_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nbool correct_bracketing_simd(std::string brackets) {\n    int length = brackets.length();\n    if (length % 16 != 0) {\n        // Padding the string to make its length a multiple of 16\n        brackets.resize((length + 15) & ~15, ' ');\n    }\n\n    __m128i open_bracket = _mm_set1_epi8('(');\n    __m128i close_bracket = _mm_set1_epi8(')');\n    __m128i balance = _mm_setzero_si128();\n    __m128i zero = _mm_setzero_si128();\n\n    for (int i = 0; i < brackets.length(); i += 16) {\n        __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&brackets[i]));\n\n        // Compare each byte with '(' and ')'\n        __m128i is_open = _mm_cmpeq_epi8(chunk, open_bracket);\n        __m128i is_close = _mm_cmpeq_epi8(chunk, close_bracket);\n\n        // Convert masks to +1 for '(', -1 for ')', and 0 otherwise\n        __m128i add_for_open = _mm_and_si128(is_open, _mm_set1_epi8(1));\n        __m128i sub_for_close = _mm_and_si128(is_close, _mm_set1_epi8(-1));\n\n        // Update balance\n        balance = _mm_add_epi8(balance, add_for_open);\n        balance = _mm_add_epi8(balance, sub_for_close);\n\n        // Check if any lane has gone negative\n        __m128i negative_mask = _mm_cmplt_epi8(balance, zero);\n        if (!_mm_testz_si128(negative_mask, negative_mask)) {\n            return false;\n        }\n    }\n\n    // Horizontal sum of balance to check final result\n    int final_balance = 0;\n    char temp[16];\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(temp), balance);\n    for (int i = 0; i < 16; ++i) {\n        final_balance += temp[i];\n    }\n\n    return final_balance == 0;\n}\n```"}
{"task_id": "SimdBench_90_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nbool correct_bracketing_simd(std::string brackets) {\n    int length = brackets.length();\n    if (length % 16 != 0) {\n        // Pad the string to make its length a multiple of 16\n        brackets.resize((length + 15) & ~15, ' ');\n    }\n\n    __m128i open_bracket = _mm_set1_epi8('(');\n    __m128i close_bracket = _mm_set1_epi8(')');\n    __m128i zero = _mm_setzero_si128();\n    __m128i balance = _mm_setzero_si128();\n\n    for (int i = 0; i < brackets.length(); i += 16) {\n        __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&brackets[i]));\n\n        // Compare for '(' and ')'\n        __m128i is_open = _mm_cmpeq_epi8(chunk, open_bracket);\n        __m128i is_close = _mm_cmpeq_epi8(chunk, close_bracket);\n\n        // Convert masks to +1 or -1\n        __m128i add_mask = _mm_and_si128(is_open, _mm_set1_epi8(1));\n        __m128i sub_mask = _mm_and_si128(is_close, _mm_set1_epi8(1));\n        sub_mask = _mm_sub_epi8(zero, sub_mask); // Negate to get -1\n\n        // Update balance\n        balance = _mm_add_epi8(balance, add_mask);\n        balance = _mm_add_epi8(balance, sub_mask);\n\n        // Check for negative balance\n        __m128i negative_check = _mm_cmpgt_epi8(zero, balance);\n        if (!_mm_testz_si128(negative_check, negative_check)) {\n            return false;\n        }\n    }\n\n    // Horizontal sum of balance vector\n    int final_balance = 0;\n    alignas(16) char temp[16];\n    _mm_store_si128(reinterpret_cast<__m128i*>(temp), balance);\n    for (int i = 0; i < 16; ++i) {\n        final_balance += temp[i];\n    }\n\n    return final_balance == 0;\n}\n```"}
{"task_id": "SimdBench_90_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nbool correct_bracketing_simd(std::string brackets) {\n    int length = brackets.length();\n    if (length % 16 != 0) {\n        // Pad the string to make its length a multiple of 16\n        brackets.resize((length + 15) & ~15, ' ');\n    }\n\n    __m128i open_bracket = _mm_set1_epi8('(');\n    __m128i close_bracket = _mm_set1_epi8(')');\n    __m128i zero = _mm_setzero_si128();\n    __m128i balance = _mm_setzero_si128();\n\n    for (int i = 0; i < brackets.length(); i += 16) {\n        __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&brackets[i]));\n\n        // Compare chunk with '(' and ')'\n        __m128i is_open = _mm_cmpeq_epi8(chunk, open_bracket);\n        __m128i is_close = _mm_cmpeq_epi8(chunk, close_bracket);\n\n        // Convert masks to +1 for '(', -1 for ')', and 0 for others\n        __m128i add_mask = _mm_and_si128(is_open, _mm_set1_epi8(1));\n        __m128i sub_mask = _mm_and_si128(is_close, _mm_set1_epi8(1));\n        sub_mask = _mm_sub_epi8(zero, sub_mask); // Negate the mask for subtraction\n\n        // Update balance vector\n        balance = _mm_add_epi8(balance, add_mask);\n        balance = _mm_add_epi8(balance, sub_mask);\n\n        // Check if any lane in balance goes negative\n        __m128i negative_check = _mm_cmpgt_epi8(zero, balance);\n        if (!_mm_testz_si128(negative_check, negative_check)) {\n            return false;\n        }\n    }\n\n    // Horizontal sum of balance to check final result\n    int final_balance = 0;\n    alignas(16) char temp[16];\n    _mm_store_si128(reinterpret_cast<__m128i*>(temp), balance);\n    for (int i = 0; i < 16; ++i) {\n        final_balance += temp[i];\n    }\n\n    return final_balance == 0;\n}\n```"}
{"task_id": "SimdBench_91_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<float> derivative_simd(std::vector<float> xs) {\n    size_t n = xs.size();\n    if (n <= 1) return {}; // Derivative of constant is zero.\n\n    std::vector<float> result(n - 1);\n    size_t i = 0;\n\n    // Process in chunks of 4 using SSE.\n    for (; i + 4 <= n; i += 4) {\n        // Load 4 coefficients into SIMD register.\n        __m128 coeffs = _mm_loadu_ps(&xs[i]);\n\n        // Create a vector {1, 2, 3, 4} for multiplication.\n        __m128 multipliers = _mm_set_ps(4.0f, 3.0f, 2.0f, 1.0f);\n\n        // Multiply coefficients by their respective indices.\n        __m128 products = _mm_mul_ps(coeffs, multipliers);\n\n        // Store the result back into the output array.\n        _mm_storeu_ps(&result[i - 1], products);\n    }\n\n    // Handle remaining elements that don't fit into a full SIMD register.\n    for (; i < n; ++i) {\n        result[i - 1] = xs[i] * static_cast<float>(i);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_91_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<float> derivative_simd(std::vector<float> xs) {\n    size_t n = xs.size();\n    if (n <= 1) return std::vector<float>(); // Derivative of constant is zero.\n\n    std::vector<float> result(n - 1);\n    size_t i = 0;\n\n    // Process in chunks of 4 using SSE.\n    for (; i + 4 <= n; i += 4) {\n        // Load 4 coefficients into SIMD register.\n        __m128 coeffs = _mm_loadu_ps(&xs[i]);\n\n        // Create a vector of multipliers [1, 2, 3, 4].\n        __m128 multipliers = _mm_set_ps(4.0f, 3.0f, 2.0f, 1.0f);\n\n        // Multiply coefficients by their respective multipliers.\n        __m128 derivatives = _mm_mul_ps(coeffs, multipliers);\n\n        // Store the result back into the output array.\n        _mm_storeu_ps(&result[i], derivatives);\n    }\n\n    // Handle remaining elements that don't fit into a full SIMD register.\n    for (; i < n - 1; ++i) {\n        result[i] = xs[i + 1] * static_cast<float>(i + 1);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_91_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<float> derivative_simd(std::vector<float> xs) {\n    size_t n = xs.size();\n    if (n <= 1) return std::vector<float>(); // Derivative of constant is zero.\n\n    std::vector<float> result(n - 1);\n    size_t i = 0;\n\n    // Process in chunks of 4 using SSE.\n    for (; i + 4 <= n; i += 4) {\n        // Load 4 coefficients into SIMD register.\n        __m128 coeffs = _mm_loadu_ps(&xs[i]);\n\n        // Create a vector {1, 2, 3, 4} for multiplication.\n        __m128 multipliers = _mm_set_ps(4.0f, 3.0f, 2.0f, 1.0f);\n\n        // Multiply coefficients by their respective indices.\n        __m128 products = _mm_mul_ps(coeffs, multipliers);\n\n        // Store the results back into the result vector.\n        _mm_storeu_ps(&result[i - 1], products);\n    }\n\n    // Handle remaining elements that don't fit into a full SIMD register.\n    for (; i < n; ++i) {\n        result[i - 1] = xs[i] * static_cast<float>(i);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_91_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<float> derivative_simd(std::vector<float> xs) {\n    int n = xs.size();\n    std::vector<float> result(n - 1, 0.0f);\n\n    // Process in chunks of 4 using SSE\n    int i = 1;\n    for (; i + 3 < n; i += 4) {\n        // Load 4 coefficients into SIMD register\n        __m128 coeffs = _mm_loadu_ps(&xs[i]);\n\n        // Create a vector of multipliers [i, i+1, i+2, i+3]\n        __m128 multipliers = _mm_set_ps(i + 3, i + 2, i + 1, i);\n\n        // Multiply coefficients by their respective indices\n        __m128 products = _mm_mul_ps(coeffs, multipliers);\n\n        // Store the result back to the result vector\n        _mm_storeu_ps(&result[i - 1], products);\n    }\n\n    // Handle remaining elements (if any)\n    for (; i < n; ++i) {\n        result[i - 1] = xs[i] * i;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_91_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<float> derivative_simd(std::vector<float> xs) {\n    size_t n = xs.size();\n    if (n <= 1) return {}; // The derivative of a constant is zero.\n\n    std::vector<float> result(n - 1);\n    size_t i = 0;\n\n    // Process 4 elements at a time using SSE.\n    for (; i + 4 <= n; i += 4) {\n        // Load 4 coefficients into an SSE register.\n        __m128 coeffs = _mm_loadu_ps(&xs[i]);\n\n        // Create a vector of multipliers: {1, 2, 3, 4}.\n        __m128 multipliers = _mm_set_ps(4.0f, 3.0f, 2.0f, 1.0f);\n\n        // Multiply coefficients by their respective multipliers.\n        __m128 products = _mm_mul_ps(coeffs, multipliers);\n\n        // Store the results back into the output vector.\n        _mm_storeu_ps(&result[i], products);\n    }\n\n    // Handle remaining elements that don't fit into a full SIMD register.\n    for (; i < n - 1; ++i) {\n        result[i] = xs[i + 1] * static_cast<float>(i + 1);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_92_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint vowels_count_simd(std::string s) {\n    __m128i vowels = _mm_setr_epi8('a', 'e', 'i', 'o', 'u', 'A', 'E', 'I', 'O', 'U', 0, 0, 0, 0, 0, 0);\n    int count = 0;\n    int len = s.length();\n    int i = 0;\n\n    // Process 16 characters at a time\n    for (; i + 16 <= len; i += 16) {\n        __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&s[i]));\n        __m128i cmp1 = _mm_cmpeq_epi8(chunk, _mm_shuffle_epi8(vowels, _mm_set1_epi8(0)));\n        __m128i cmp2 = _mm_cmpeq_epi8(chunk, _mm_shuffle_epi8(vowels, _mm_set1_epi8(1)));\n        __m128i cmp3 = _mm_cmpeq_epi8(chunk, _mm_shuffle_epi8(vowels, _mm_set1_epi8(2)));\n        __m128i cmp4 = _mm_cmpeq_epi8(chunk, _mm_shuffle_epi8(vowels, _mm_set1_epi8(3)));\n        __m128i cmp5 = _mm_cmpeq_epi8(chunk, _mm_shuffle_epi8(vowels, _mm_set1_epi8(4)));\n        __m128i cmp6 = _mm_cmpeq_epi8(chunk, _mm_shuffle_epi8(vowels, _mm_set1_epi8(5)));\n        __m128i cmp7 = _mm_cmpeq_epi8(chunk, _mm_shuffle_epi8(vowels, _mm_set1_epi8(6)));\n        __m128i cmp8 = _mm_cmpeq_epi8(chunk, _mm_shuffle_epi8(vowels, _mm_set1_epi8(7)));\n        __m128i cmp9 = _mm_cmpeq_epi8(chunk, _mm_shuffle_epi8(vowels, _mm_set1_epi8(8)));\n        __m128i cmp10 = _mm_cmpeq_epi8(chunk, _mm_shuffle_epi8(vowels, _mm_set1_epi8(9)));\n\n        __m128i cmp = _mm_or_si128(_mm_or_si128(_mm_or_si128(cmp1, cmp2), _mm_or_si128(cmp3, cmp4)),\n                                   _mm_or_si128(_mm_or_si128(cmp5, cmp6), _mm_or_si128(cmp7, cmp8)));\n        cmp = _mm_or_si128(cmp, _mm_or_si128(cmp9, cmp10));\n\n        int mask = _mm_movemask_epi8(cmp);\n        count += __builtin_popcount(mask);\n    }\n\n    // Handle remaining characters\n    for (; i < len; ++i) {\n        char c = s[i];\n        if (c == 'a' || c == 'e' || c == 'i' || c == 'o' || c == 'u' ||\n            c == 'A' || c == 'E' || c == 'I' || c == 'O' || c == 'U') {\n            count++;\n        }\n    }\n\n    // Check if the last character is 'y' or 'Y'\n    if (len > 0 && (s[len - 1] == 'y' || s[len - 1] == 'Y')) {\n        count++;\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_92_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint vowels_count_simd(std::string s) {\n    __m128i vowels = _mm_setr_epi8('a', 'e', 'i', 'o', 'u', 'A', 'E', 'I', 'O', 'U', 0, 0, 0, 0, 0, 0);\n    int count = 0;\n    int len = s.length();\n    int i = 0;\n\n    // Process 16 characters at a time\n    for (; i + 15 < len; i += 16) {\n        __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&s[i]));\n        __m128i cmp1 = _mm_cmpeq_epi8(chunk, _mm_shuffle_epi8(vowels, _mm_set1_epi8(0)));\n        __m128i cmp2 = _mm_cmpeq_epi8(chunk, _mm_shuffle_epi8(vowels, _mm_set1_epi8(1)));\n        __m128i cmp3 = _mm_cmpeq_epi8(chunk, _mm_shuffle_epi8(vowels, _mm_set1_epi8(2)));\n        __m128i cmp4 = _mm_cmpeq_epi8(chunk, _mm_shuffle_epi8(vowels, _mm_set1_epi8(3)));\n        __m128i cmp5 = _mm_cmpeq_epi8(chunk, _mm_shuffle_epi8(vowels, _mm_set1_epi8(4)));\n        __m128i cmp6 = _mm_cmpeq_epi8(chunk, _mm_shuffle_epi8(vowels, _mm_set1_epi8(5)));\n        __m128i cmp7 = _mm_cmpeq_epi8(chunk, _mm_shuffle_epi8(vowels, _mm_set1_epi8(6)));\n        __m128i cmp8 = _mm_cmpeq_epi8(chunk, _mm_shuffle_epi8(vowels, _mm_set1_epi8(7)));\n        __m128i cmp9 = _mm_cmpeq_epi8(chunk, _mm_shuffle_epi8(vowels, _mm_set1_epi8(8)));\n        __m128i cmp10 = _mm_cmpeq_epi8(chunk, _mm_shuffle_epi8(vowels, _mm_set1_epi8(9)));\n\n        __m128i cmp = _mm_or_si128(_mm_or_si128(_mm_or_si128(cmp1, cmp2), _mm_or_si128(cmp3, cmp4)),\n                                   _mm_or_si128(_mm_or_si128(cmp5, cmp6), _mm_or_si128(cmp7, cmp8)));\n        cmp = _mm_or_si128(cmp, _mm_or_si128(cmp9, cmp10));\n\n        int mask = _mm_movemask_epi8(cmp);\n        count += __builtin_popcount(mask);\n    }\n\n    // Process remaining characters\n    for (; i < len; ++i) {\n        char c = s[i];\n        if (c == 'a' || c == 'e' || c == 'i' || c == 'o' || c == 'u' ||\n            c == 'A' || c == 'E' || c == 'I' || c == 'O' || c == 'U') {\n            count++;\n        }\n    }\n\n    // Check if the last character is 'y' or 'Y'\n    if (len > 0 && (s[len - 1] == 'y' || s[len - 1] == 'Y')) {\n        count++;\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_92_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint vowels_count_simd(std::string s) {\n    __m128i vowels = _mm_setr_epi8('a', 'e', 'i', 'o', 'u', 'A', 'E', 'I', 'O', 'U', 0, 0, 0, 0, 0, 0);\n    int count = 0;\n    int len = s.length();\n    int i = 0;\n\n    // Process 16 characters at a time\n    for (; i + 15 < len; i += 16) {\n        __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&s[i]));\n        __m128i cmp1 = _mm_cmpeq_epi8(chunk, _mm_set1_epi8('a'));\n        __m128i cmp2 = _mm_cmpeq_epi8(chunk, _mm_set1_epi8('e'));\n        __m128i cmp3 = _mm_cmpeq_epi8(chunk, _mm_set1_epi8('i'));\n        __m128i cmp4 = _mm_cmpeq_epi8(chunk, _mm_set1_epi8('o'));\n        __m128i cmp5 = _mm_cmpeq_epi8(chunk, _mm_set1_epi8('u'));\n        __m128i cmp6 = _mm_cmpeq_epi8(chunk, _mm_set1_epi8('A'));\n        __m128i cmp7 = _mm_cmpeq_epi8(chunk, _mm_set1_epi8('E'));\n        __m128i cmp8 = _mm_cmpeq_epi8(chunk, _mm_set1_epi8('I'));\n        __m128i cmp9 = _mm_cmpeq_epi8(chunk, _mm_set1_epi8('O'));\n        __m128i cmp10 = _mm_cmpeq_epi8(chunk, _mm_set1_epi8('U'));\n\n        __m128i cmp = _mm_or_si128(_mm_or_si128(_mm_or_si128(cmp1, cmp2), _mm_or_si128(cmp3, cmp4)),\n                                   _mm_or_si128(_mm_or_si128(cmp5, cmp6), _mm_or_si128(cmp7, cmp8)));\n        cmp = _mm_or_si128(cmp, _mm_or_si128(cmp9, cmp10));\n\n        int mask = _mm_movemask_epi8(cmp);\n        count += __builtin_popcount(mask);\n    }\n\n    // Handle remaining characters\n    for (; i < len; ++i) {\n        char c = s[i];\n        if (c == 'a' || c == 'e' || c == 'i' || c == 'o' || c == 'u' ||\n            c == 'A' || c == 'E' || c == 'I' || c == 'O' || c == 'U') {\n            count++;\n        }\n    }\n\n    // Check if the last character is 'y' or 'Y'\n    if (len > 0 && (s[len - 1] == 'y' || s[len - 1] == 'Y')) {\n        count++;\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_92_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint vowels_count_simd(std::string s) {\n    __m128i vowels = _mm_setr_epi8('a', 'e', 'i', 'o', 'u', 'A', 'E', 'I', 'O', 'U', 0, 0, 0, 0, 0, 0);\n    int count = 0;\n    int len = s.length();\n    int i = 0;\n\n    // Process 16 characters at a time\n    for (; i + 15 < len; i += 16) {\n        __m128i chunk = _mm_loadu_si128((__m128i*)&s[i]);\n        __m128i cmp1 = _mm_cmpeq_epi8(chunk, _mm_shuffle_epi8(vowels, _mm_set1_epi8(0)));\n        __m128i cmp2 = _mm_cmpeq_epi8(chunk, _mm_shuffle_epi8(vowels, _mm_set1_epi8(1)));\n        __m128i cmp3 = _mm_cmpeq_epi8(chunk, _mm_shuffle_epi8(vowels, _mm_set1_epi8(2)));\n        __m128i cmp4 = _mm_cmpeq_epi8(chunk, _mm_shuffle_epi8(vowels, _mm_set1_epi8(3)));\n        __m128i cmp5 = _mm_cmpeq_epi8(chunk, _mm_shuffle_epi8(vowels, _mm_set1_epi8(4)));\n        __m128i cmp6 = _mm_cmpeq_epi8(chunk, _mm_shuffle_epi8(vowels, _mm_set1_epi8(5)));\n        __m128i cmp7 = _mm_cmpeq_epi8(chunk, _mm_shuffle_epi8(vowels, _mm_set1_epi8(6)));\n        __m128i cmp8 = _mm_cmpeq_epi8(chunk, _mm_shuffle_epi8(vowels, _mm_set1_epi8(7)));\n        __m128i cmp9 = _mm_cmpeq_epi8(chunk, _mm_shuffle_epi8(vowels, _mm_set1_epi8(8)));\n        __m128i cmp10 = _mm_cmpeq_epi8(chunk, _mm_shuffle_epi8(vowels, _mm_set1_epi8(9)));\n\n        __m128i cmp = _mm_or_si128(_mm_or_si128(_mm_or_si128(cmp1, cmp2), _mm_or_si128(cmp3, cmp4)),\n                                   _mm_or_si128(_mm_or_si128(cmp5, cmp6), _mm_or_si128(cmp7, cmp8)));\n        cmp = _mm_or_si128(cmp, _mm_or_si128(cmp9, cmp10));\n\n        int mask = _mm_movemask_epi8(cmp);\n        count += __builtin_popcount(mask);\n    }\n\n    // Handle remaining characters\n    for (; i < len; ++i) {\n        char c = s[i];\n        if (c == 'a' || c == 'e' || c == 'i' || c == 'o' || c == 'u' ||\n            c == 'A' || c == 'E' || c == 'I' || c == 'O' || c == 'U') {\n            count++;\n        }\n    }\n\n    // Check if the last character is 'y' or 'Y'\n    if (len > 0 && (s[len - 1] == 'y' || s[len - 1] == 'Y')) {\n        count++;\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_92_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint vowels_count_simd(std::string s) {\n    __m128i vowels = _mm_setr_epi8('a', 'e', 'i', 'o', 'u', 'A', 'E', 'I', 'O', 'U', 0, 0, 0, 0, 0, 0);\n    int count = 0;\n    int len = s.length();\n    int i = 0;\n\n    // Process 16 characters at a time\n    for (; i + 15 < len; i += 16) {\n        __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&s[i]));\n        __m128i cmp1 = _mm_cmpeq_epi8(chunk, _mm_shuffle_epi8(vowels, _mm_set1_epi8(0)));\n        __m128i cmp2 = _mm_cmpeq_epi8(chunk, _mm_shuffle_epi8(vowels, _mm_set1_epi8(1)));\n        __m128i cmp3 = _mm_cmpeq_epi8(chunk, _mm_shuffle_epi8(vowels, _mm_set1_epi8(2)));\n        __m128i cmp4 = _mm_cmpeq_epi8(chunk, _mm_shuffle_epi8(vowels, _mm_set1_epi8(3)));\n        __m128i cmp5 = _mm_cmpeq_epi8(chunk, _mm_shuffle_epi8(vowels, _mm_set1_epi8(4)));\n        __m128i cmp6 = _mm_cmpeq_epi8(chunk, _mm_shuffle_epi8(vowels, _mm_set1_epi8(5)));\n        __m128i cmp7 = _mm_cmpeq_epi8(chunk, _mm_shuffle_epi8(vowels, _mm_set1_epi8(6)));\n        __m128i cmp8 = _mm_cmpeq_epi8(chunk, _mm_shuffle_epi8(vowels, _mm_set1_epi8(7)));\n        __m128i cmp9 = _mm_cmpeq_epi8(chunk, _mm_shuffle_epi8(vowels, _mm_set1_epi8(8)));\n        __m128i cmp10 = _mm_cmpeq_epi8(chunk, _mm_shuffle_epi8(vowels, _mm_set1_epi8(9)));\n\n        __m128i cmp = _mm_or_si128(_mm_or_si128(_mm_or_si128(cmp1, cmp2), _mm_or_si128(cmp3, cmp4)),\n                                   _mm_or_si128(_mm_or_si128(cmp5, cmp6), _mm_or_si128(cmp7, cmp8)));\n        cmp = _mm_or_si128(cmp, _mm_or_si128(cmp9, cmp10));\n\n        int mask = _mm_movemask_epi8(cmp);\n        count += __builtin_popcount(mask);\n    }\n\n    // Handle remaining characters\n    for (; i < len; ++i) {\n        char c = s[i];\n        if (c == 'a' || c == 'e' || c == 'i' || c == 'o' || c == 'u' ||\n            c == 'A' || c == 'E' || c == 'I' || c == 'O' || c == 'U') {\n            count++;\n        }\n    }\n\n    // Check if the last character is 'y' or 'Y'\n    if (len > 0 && (s[len - 1] == 'y' || s[len - 1] == 'Y')) {\n        count++;\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_93_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint digitSum_simd(std::string s) {\n    int sum = 0;\n    int len = s.length();\n    int i = 0;\n\n    // Process 16 characters at a time using SIMD\n    for (; i + 16 <= len; i += 16) {\n        // Load 16 characters into an SSE register\n        __m128i chars = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&s[i]));\n\n        // Create a mask for uppercase letters ('A' to 'Z')\n        __m128i lower_bound = _mm_set1_epi8('A');\n        __m128i upper_bound = _mm_set1_epi8('Z');\n\n        // Compare if characters are >= 'A'\n        __m128i ge_A = _mm_cmpgt_epi8(chars, _mm_sub_epi8(lower_bound, _mm_set1_epi8(1)));\n\n        // Compare if characters are <= 'Z'\n        __m128i le_Z = _mm_cmplt_epi8(chars, _mm_add_epi8(upper_bound, _mm_set1_epi8(1)));\n\n        // Combine the two conditions to get the mask for uppercase letters\n        __m128i is_upper = _mm_and_si128(ge_A, le_Z);\n\n        // Zero out non-uppercase characters\n        __m128i masked_chars = _mm_and_si128(chars, is_upper);\n\n        // Extract the ASCII values and sum them horizontally\n        alignas(16) char temp[16];\n        _mm_store_si128(reinterpret_cast<__m128i*>(temp), masked_chars);\n        for (int j = 0; j < 16; ++j) {\n            sum += static_cast<unsigned char>(temp[j]);\n        }\n    }\n\n    // Process remaining characters\n    for (; i < len; ++i) {\n        if (s[i] >= 'A' && s[i] <= 'Z') {\n            sum += s[i];\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_93_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint digitSum_simd(std::string s) {\n    int result = 0;\n    int length = s.size();\n    int i = 0;\n\n    // Process 16 characters at a time using SIMD\n    __m128i upper_mask = _mm_set1_epi8(0x40); // Mask to check if character is uppercase ('A' starts at 0x41)\n    __m128i ascii_zero = _mm_setzero_si128(); // Zero vector for comparison\n\n    for (; i + 15 < length; i += 16) {\n        // Load 16 characters into an SSE register\n        __m128i chars = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&s[i]));\n\n        // Check if characters are uppercase: (chars & ~0x20) >= 'A' && (chars & ~0x20) <= 'Z'\n        __m128i is_upper = _mm_cmpgt_epi8(chars, _mm_set1_epi8('A' - 1));\n        is_upper = _mm_and_si128(is_upper, _mm_cmplt_epi8(chars, _mm_set1_epi8('Z' + 1)));\n\n        // Mask out non-uppercase characters\n        __m128i masked_chars = _mm_and_si128(chars, is_upper);\n\n        // Extract ASCII values and sum them horizontally\n        int temp[16];\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(temp), masked_chars);\n        for (int j = 0; j < 16; ++j) {\n            result += temp[j];\n        }\n    }\n\n    // Process remaining characters\n    for (; i < length; ++i) {\n        if (s[i] >= 'A' && s[i] <= 'Z') {\n            result += s[i];\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_93_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint digitSum_simd(std::string s) {\n    int sum = 0;\n    int len = s.length();\n    int i = 0;\n\n    // Process 16 characters at a time using SSE2 intrinsics\n    __m128i upper_mask = _mm_set1_epi8(0x40); // Mask to check if character is uppercase ('A' = 65, 'Z' = 90)\n    __m128i lower_bound = _mm_set1_epi8('A');\n    __m128i upper_bound = _mm_set1_epi8('Z');\n\n    for (; i + 15 < len; i += 16) {\n        // Load 16 characters into an SSE register\n        __m128i chars = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&s[i]));\n\n        // Check if characters are in the range 'A' to 'Z'\n        __m128i cmp_lower = _mm_cmpgt_epi8(chars, lower_bound);\n        __m128i cmp_upper = _mm_cmplt_epi8(chars, upper_bound);\n        __m128i mask = _mm_and_si128(cmp_lower, cmp_upper);\n\n        // Zero out non-uppercase characters\n        __m128i filtered_chars = _mm_and_si128(chars, mask);\n\n        // Extract ASCII values and sum them horizontally\n        alignas(16) char temp[16];\n        _mm_store_si128(reinterpret_cast<__m128i*>(temp), filtered_chars);\n        for (int j = 0; j < 16; ++j) {\n            sum += static_cast<unsigned char>(temp[j]);\n        }\n    }\n\n    // Process remaining characters\n    for (; i < len; ++i) {\n        if (s[i] >= 'A' && s[i] <= 'Z') {\n            sum += s[i];\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_93_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint digitSum_simd(std::string s) {\n    int result = 0;\n    int length = s.length();\n    int i = 0;\n\n    // Process 16 characters at a time using SIMD\n    for (; i + 16 <= length; i += 16) {\n        // Load 16 characters into an SSE register\n        __m128i chars = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&s[i]));\n\n        // Create a mask for uppercase letters ('A' to 'Z')\n        __m128i lower_bound = _mm_set1_epi8('A');\n        __m128i upper_bound = _mm_set1_epi8('Z');\n\n        // Compare if characters are >= 'A'\n        __m128i ge_A = _mm_cmpgt_epi8(chars, _mm_sub_epi8(lower_bound, _mm_set1_epi8(1)));\n\n        // Compare if characters are <= 'Z'\n        __m128i le_Z = _mm_cmplt_epi8(chars, _mm_add_epi8(upper_bound, _mm_set1_epi8(1)));\n\n        // Combine the two conditions to get the mask for uppercase letters\n        __m128i is_upper = _mm_and_si128(ge_A, le_Z);\n\n        // Zero out non-uppercase characters\n        __m128i masked_chars = _mm_and_si128(chars, is_upper);\n\n        // Extract the sum of the ASCII values of uppercase characters\n        int temp[4];\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(temp), masked_chars);\n        for (int j = 0; j < 4; ++j) {\n            result += temp[j];\n        }\n    }\n\n    // Process remaining characters\n    for (; i < length; ++i) {\n        if (s[i] >= 'A' && s[i] <= 'Z') {\n            result += s[i];\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_93_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint digitSum_simd(std::string s) {\n    int result = 0;\n    int length = s.size();\n    int i = 0;\n\n    // Process 16 characters at a time using SSE2 intrinsics\n    __m128i upper_mask = _mm_set1_epi8(0x40); // Mask to check if character is uppercase ('A' = 65, 'Z' = 90)\n    __m128i lower_bound = _mm_set1_epi8('A'); // Lower bound for uppercase letters\n    __m128i upper_bound = _mm_set1_epi8('Z'); // Upper bound for uppercase letters\n\n    for (; i + 15 < length; i += 16) {\n        // Load 16 characters into an SSE register\n        __m128i chars = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&s[i]));\n\n        // Check if characters are in the range 'A' to 'Z'\n        __m128i cmp_lower = _mm_cmpgt_epi8(chars, lower_bound);\n        __m128i cmp_upper = _mm_cmplt_epi8(chars, upper_bound);\n        __m128i is_upper = _mm_and_si128(cmp_lower, cmp_upper);\n\n        // Create a mask to extract only uppercase characters\n        __m128i masked_chars = _mm_and_si128(chars, is_upper);\n\n        // Extract ASCII values and sum them horizontally\n        int temp[16];\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(temp), masked_chars);\n        for (int j = 0; j < 16; ++j) {\n            result += temp[j];\n        }\n    }\n\n    // Process remaining characters\n    for (; i < length; ++i) {\n        if (s[i] >= 'A' && s[i] <= 'Z') {\n            result += s[i];\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_94_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> pluck_simd(std::vector<int> arr) {\n    if (arr.empty()) return {};\n\n    int min_even = -1;\n    int min_index = -1;\n\n    __m128i zero = _mm_setzero_si128();\n    __m128i two = _mm_set1_epi32(2);\n\n    size_t i = 0;\n    size_t size = arr.size();\n\n    // Process 4 elements at a time\n    for (; i + 4 <= size; i += 4) {\n        // Load 4 integers into an SSE register\n        __m128i values = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&arr[i]));\n\n        // Check if the values are even\n        __m128i is_even = _mm_and_si128(values, two);\n        __m128i mask = _mm_cmpeq_epi32(is_even, zero);\n\n        // Extract the mask to determine which elements are even\n        int even_mask = _mm_movemask_ps(_mm_castsi128_ps(mask));\n\n        if (even_mask != 0) {\n            // Iterate over the 4 elements and update min_even and min_index\n            for (int j = 0; j < 4; ++j) {\n                if (even_mask & (1 << j)) {\n                    int value = arr[i + j];\n                    if (min_even == -1 || value < min_even || (value == min_even && (i + j) < min_index)) {\n                        min_even = value;\n                        min_index = i + j;\n                    }\n                }\n            }\n        }\n    }\n\n    // Process remaining elements\n    for (; i < size; ++i) {\n        if (arr[i] % 2 == 0) {\n            if (min_even == -1 || arr[i] < min_even || (arr[i] == min_even && i < min_index)) {\n                min_even = arr[i];\n                min_index = i;\n            }\n        }\n    }\n\n    if (min_even == -1) {\n        return {};\n    }\n\n    return {min_even, min_index};\n}\n```"}
{"task_id": "SimdBench_94_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> pluck_simd(std::vector<int> arr) {\n    if (arr.empty()) return {};\n\n    int min_even = -1;\n    int min_index = -1;\n\n    __m128i v_zero = _mm_setzero_si128();\n    __m128i v_two = _mm_set1_epi32(2);\n\n    size_t i = 0;\n    size_t size = arr.size();\n\n    // Process 4 elements at a time using SIMD\n    for (; i + 4 <= size; i += 4) {\n        __m128i v_data = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&arr[i]));\n        __m128i v_mod = _mm_and_si128(v_data, v_two); // Check even numbers (n & 2 == 0)\n        __m128i v_mask = _mm_cmpeq_epi32(v_mod, v_zero);\n\n        int mask = _mm_movemask_ps((__m128)v_mask);\n        if (mask != 0) {\n            for (int j = 0; j < 4; ++j) {\n                if (mask & (1 << j)) {\n                    int value = arr[i + j];\n                    if (min_even == -1 || value < min_even || (value == min_even && (i + j) < min_index)) {\n                        min_even = value;\n                        min_index = i + j;\n                    }\n                }\n            }\n        }\n    }\n\n    // Process remaining elements\n    for (; i < size; ++i) {\n        if (arr[i] % 2 == 0) {\n            if (min_even == -1 || arr[i] < min_even || (arr[i] == min_even && i < min_index)) {\n                min_even = arr[i];\n                min_index = i;\n            }\n        }\n    }\n\n    if (min_even == -1) return {};\n    return {min_even, min_index};\n}\n```"}
{"task_id": "SimdBench_94_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> pluck_simd(std::vector<int> arr) {\n    if (arr.empty()) return {};\n\n    int min_even = -1;\n    int min_index = -1;\n\n    __m128i zero = _mm_setzero_si128();\n    __m128i two = _mm_set1_epi32(2);\n\n    size_t i = 0;\n    size_t size = arr.size();\n\n    // Process 4 elements at a time using SIMD\n    for (; i + 4 <= size; i += 4) {\n        // Load 4 integers into a SIMD register\n        __m128i values = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&arr[i]));\n\n        // Check if the values are even by computing values % 2 == 0\n        __m128i mod = _mm_rem_epi32(values, two);\n        __m128i is_even_mask = _mm_cmpeq_epi32(mod, zero);\n\n        // Extract the mask to check which elements are even\n        int mask = _mm_movemask_ps(_mm_castsi128_ps(is_even_mask));\n\n        if (mask != 0) {\n            // If any element is even, process them individually\n            for (int j = 0; j < 4; ++j) {\n                if (mask & (1 << j)) {\n                    int value = arr[i + j];\n                    if (min_even == -1 || value < min_even || (value == min_even && (i + j) < min_index)) {\n                        min_even = value;\n                        min_index = i + j;\n                    }\n                }\n            }\n        }\n    }\n\n    // Process remaining elements\n    for (; i < size; ++i) {\n        if (arr[i] % 2 == 0) {\n            if (min_even == -1 || arr[i] < min_even || (arr[i] == min_even && i < min_index)) {\n                min_even = arr[i];\n                min_index = i;\n            }\n        }\n    }\n\n    if (min_even == -1) {\n        return {};\n    }\n\n    return {min_even, min_index};\n}\n```"}
{"task_id": "SimdBench_94_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> pluck_simd(std::vector<int> arr) {\n    if (arr.empty()) return {};\n\n    int min_even = -1;\n    int min_index = -1;\n\n    __m128i zero = _mm_setzero_si128();\n    __m128i two = _mm_set1_epi32(2);\n\n    size_t i = 0;\n    size_t size = arr.size();\n\n    // Process 4 elements at a time using SIMD\n    for (; i + 4 <= size; i += 4) {\n        __m128i values = _mm_loadu_si128((__m128i*)&arr[i]);\n        __m128i indices = _mm_setr_epi32(i, i + 1, i + 2, i + 3);\n\n        // Check if the values are even\n        __m128i is_even = _mm_cmpeq_epi32(_mm_and_si128(values, two), zero);\n\n        // Mask to extract valid even numbers\n        int mask = _mm_movemask_epi8(is_even);\n\n        if (mask != 0) {\n            // Extract individual elements and process them\n            int vals[4];\n            int idx[4];\n            _mm_storeu_si128((__m128i*)vals, values);\n            _mm_storeu_si128((__m128i*)idx, indices);\n\n            for (int j = 0; j < 4; ++j) {\n                if ((mask & (0xF << (j * 4))) && (min_even == -1 || vals[j] < min_even || (vals[j] == min_even && idx[j] < min_index))) {\n                    min_even = vals[j];\n                    min_index = idx[j];\n                }\n            }\n        }\n    }\n\n    // Process remaining elements\n    for (; i < size; ++i) {\n        if (arr[i] % 2 == 0 && (min_even == -1 || arr[i] < min_even || (arr[i] == min_even && i < min_index))) {\n            min_even = arr[i];\n            min_index = i;\n        }\n    }\n\n    if (min_even == -1) return {};\n    return {min_even, min_index};\n}\n```"}
{"task_id": "SimdBench_94_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> pluck_simd(std::vector<int> arr) {\n    if (arr.empty()) return {};\n\n    int min_even = -1;\n    int min_index = -1;\n\n    // Process 4 integers at a time using SSE2\n    __m128i zero = _mm_setzero_si128();\n    __m128i two = _mm_set1_epi32(2);\n    __m128i min_val_vec = _mm_set1_epi32(-1); // Initialize to max value\n    __m128i min_idx_vec = _mm_set1_epi32(-1);\n\n    size_t i = 0;\n    for (; i + 4 <= arr.size(); i += 4) {\n        // Load 4 integers into an SSE register\n        __m128i values = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&arr[i]));\n\n        // Check if the values are even\n        __m128i is_even = _mm_cmpeq_epi32(_mm_and_si128(values, two), zero);\n\n        // Mask out odd values by setting them to max int\n        __m128i masked_values = _mm_blendv_epi8(_mm_set1_epi32(0x7FFFFFFF), values, is_even);\n\n        // Compare with current minimum\n        __m128i cmp = _mm_cmplt_epi32(masked_values, min_val_vec);\n        min_val_vec = _mm_blendv_epi8(min_val_vec, masked_values, cmp);\n\n        // Prepare indices vector\n        __m128i indices = _mm_setr_epi32(i, i + 1, i + 2, i + 3);\n        min_idx_vec = _mm_blendv_epi8(min_idx_vec, indices, cmp);\n    }\n\n    // Extract results from SIMD registers\n    int temp_min_vals[4];\n    int temp_min_indices[4];\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(temp_min_vals), min_val_vec);\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(temp_min_indices), min_idx_vec);\n\n    for (int j = 0; j < 4; ++j) {\n        if (temp_min_vals[j] != -1 && (min_even == -1 || temp_min_vals[j] < min_even)) {\n            min_even = temp_min_vals[j];\n            min_index = temp_min_indices[j];\n        }\n    }\n\n    // Process remaining elements\n    for (; i < arr.size(); ++i) {\n        if (arr[i] % 2 == 0 && (min_even == -1 || arr[i] < min_even)) {\n            min_even = arr[i];\n            min_index = i;\n        }\n    }\n\n    if (min_even == -1) return {};\n    return {min_even, min_index};\n}\n```"}
{"task_id": "SimdBench_95_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n\nint search_simd(std::vector<int> lst) {\n    int max_val = *std::max_element(lst.begin(), lst.end());\n    std::vector<int> freq(max_val + 1, 0);\n\n    // Count frequency using SIMD\n    size_t i = 0;\n    size_t n = lst.size();\n    __m128i v_one = _mm_set1_epi32(1);\n\n    for (; i + 4 <= n; i += 4) {\n        __m128i v_vals = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&lst[i]));\n        for (int j = 0; j < 4; ++j) {\n            int val = _mm_extract_epi32(v_vals, j);\n            if (val > 0 && val <= static_cast<int>(freq.size())) {\n                freq[val]++;\n            }\n        }\n    }\n\n    // Process remaining elements\n    for (; i < n; ++i) {\n        int val = lst[i];\n        if (val > 0 && val <= static_cast<int>(freq.size())) {\n            freq[val]++;\n        }\n    }\n\n    // Find the greatest integer with frequency >= value\n    int result = -1;\n    for (int val = 1; val <= max_val; ++val) {\n        if (freq[val] >= val) {\n            result = val;\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_95_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n\nint search_simd(std::vector<int> lst) {\n    int max_val = *std::max_element(lst.begin(), lst.end());\n    std::vector<int> freq(max_val + 1, 0);\n\n    // Count frequency using SIMD\n    size_t i = 0;\n    size_t n = lst.size();\n    __m128i v_one = _mm_set1_epi32(1);\n\n    for (; i + 4 <= n; i += 4) {\n        __m128i v_vals = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&lst[i]));\n        for (int j = 0; j < 4; ++j) {\n            int val = _mm_extract_epi32(v_vals, j);\n            if (val > 0 && val <= static_cast<int>(freq.size())) {\n                freq[val]++;\n            }\n        }\n    }\n\n    // Process remaining elements\n    for (; i < n; ++i) {\n        int val = lst[i];\n        if (val > 0 && val <= static_cast<int>(freq.size())) {\n            freq[val]++;\n        }\n    }\n\n    // Find the greatest integer with frequency >= value\n    int result = -1;\n    for (int val = 1; val < static_cast<int>(freq.size()); ++val) {\n        if (freq[val] >= val) {\n            result = std::max(result, val);\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_95_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n\nint search_simd(std::vector<int> lst) {\n    int result = -1;\n    int max_val = *std::max_element(lst.begin(), lst.end());\n    std::vector<int> freq(max_val + 1, 0);\n\n    // Count frequency using SIMD\n    size_t i = 0;\n    size_t n = lst.size();\n    __m128i v_one = _mm_set1_epi32(1);\n\n    for (; i + 4 <= n; i += 4) {\n        __m128i v_vals = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&lst[i]));\n        for (int j = 0; j < 4; ++j) {\n            int val = _mm_extract_epi32(v_vals, j);\n            if (val > 0 && val <= static_cast<int>(freq.size())) {\n                freq[val]++;\n            }\n        }\n    }\n\n    // Handle remaining elements\n    for (; i < n; ++i) {\n        int val = lst[i];\n        if (val > 0 && val <= static_cast<int>(freq.size())) {\n            freq[val]++;\n        }\n    }\n\n    // Find the maximum value satisfying the condition\n    for (int val = 1; val <= max_val; ++val) {\n        if (freq[val] >= val) {\n            result = std::max(result, val);\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_95_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n\nint search_simd(std::vector<int> lst) {\n    int max_val = *std::max_element(lst.begin(), lst.end());\n    std::vector<int> freq(max_val + 1, 0);\n\n    // Count frequencies using SIMD\n    size_t i = 0;\n    size_t n = lst.size();\n    __m128i v_one = _mm_set1_epi32(1);\n\n    for (; i + 4 <= n; i += 4) {\n        __m128i v_vals = _mm_loadu_si128((__m128i*)&lst[i]);\n        __m128i v_indices = _mm_setr_epi32(lst[i], lst[i+1], lst[i+2], lst[i+3]);\n\n        for (int j = 0; j < 4; ++j) {\n            int index = _mm_extract_epi32(v_indices, j);\n            freq[index] += 1;\n        }\n    }\n\n    // Process remaining elements\n    for (; i < n; ++i) {\n        freq[lst[i]] += 1;\n    }\n\n    // Find the largest integer with frequency >= value\n    int result = -1;\n    for (int val = 1; val <= max_val; ++val) {\n        if (freq[val] >= val) {\n            result = std::max(result, val);\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_95_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n\nint search_simd(std::vector<int> lst) {\n    int max_val = *std::max_element(lst.begin(), lst.end());\n    std::vector<int> freq(max_val + 1, 0);\n\n    // Count frequency using SIMD\n    size_t i = 0;\n    size_t n = lst.size();\n    __m128i v_one = _mm_set1_epi32(1);\n\n    for (; i + 4 <= n; i += 4) {\n        __m128i v_vals = _mm_loadu_si128((__m128i*)&lst[i]);\n        __m128i v_indices = _mm_setr_epi32(lst[i], lst[i+1], lst[i+2], lst[i+3]);\n\n        for (int j = 0; j < 4; ++j) {\n            int idx = _mm_extract_epi32(v_indices, j);\n            freq[idx] += 1;\n        }\n    }\n\n    // Process remaining elements\n    for (; i < n; ++i) {\n        freq[lst[i]] += 1;\n    }\n\n    // Find the result\n    int result = -1;\n    for (int val = 1; val <= max_val; ++val) {\n        if (freq[val] >= val) {\n            result = std::max(result, val);\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_96_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nbool will_it_fly_simd(std::vector<int> q, int w) {\n    int n = q.size();\n    bool is_palindromic = true;\n    int sum = 0;\n\n    // Ensure the vector size is a multiple of 4 for SIMD processing\n    int simd_size = (n / 4) * 4;\n    __m128i vsum = _mm_setzero_si128();\n\n    // Check palindromic property and compute sum using SIMD\n    for (int i = 0; i < simd_size; i += 4) {\n        // Load 4 elements from the start and end of the current window\n        __m128i v1 = _mm_loadu_si128((__m128i*)&q[i]);\n        __m128i v2 = _mm_loadu_si128((__m128i*)&q[n - i - 4]);\n\n        // Reverse the order of elements in v2\n        v2 = _mm_shuffle_epi32(v2, _MM_SHUFFLE(0, 1, 2, 3));\n\n        // Compare if the two vectors are equal\n        __m128i cmp = _mm_cmpeq_epi32(v1, v2);\n        int mask = _mm_movemask_ps((__m128)cmp);\n        if (mask != 0xF) {\n            is_palindromic = false;\n        }\n\n        // Add the elements of v1 to the running sum\n        vsum = _mm_add_epi32(vsum, v1);\n    }\n\n    // Horizontal sum of vsum\n    int temp[4];\n    _mm_storeu_si128((__m128i*)temp, vsum);\n    sum = temp[0] + temp[1] + temp[2] + temp[3];\n\n    // Process remaining elements (if any)\n    for (int i = simd_size; i < n; ++i) {\n        sum += q[i];\n        if (q[i] != q[n - i - 1]) {\n            is_palindromic = false;\n        }\n    }\n\n    // Final check\n    return is_palindromic && (sum <= w);\n}\n```"}
{"task_id": "SimdBench_96_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool will_it_fly_simd(std::vector<int> q, int w) {\n    int n = q.size();\n    if (n == 0) return false;\n\n    // Check if the vector is palindromic\n    bool is_palindromic = true;\n    int mid = n / 2;\n    for (int i = 0; i < mid; ++i) {\n        if (q[i] != q[n - i - 1]) {\n            is_palindromic = false;\n            break;\n        }\n    }\n    if (!is_palindromic) return false;\n\n    // Compute the sum using SSE/SSE2 intrinsics\n    __m128i sum_vec = _mm_setzero_si128(); // Initialize sum vector to zero\n    int i = 0;\n\n    // Process 4 elements at a time\n    for (; i + 3 < n; i += 4) {\n        __m128i vec = _mm_loadu_si128((__m128i*)&q[i]); // Load 4 integers\n        sum_vec = _mm_add_epi32(sum_vec, vec);           // Add to sum vector\n    }\n\n    // Horizontal sum of the accumulated SIMD register\n    int sum = 0;\n    sum += _mm_extract_epi32(sum_vec, 0);\n    sum += _mm_extract_epi32(sum_vec, 1);\n    sum += _mm_extract_epi32(sum_vec, 2);\n    sum += _mm_extract_epi32(sum_vec, 3);\n\n    // Add remaining elements\n    for (; i < n; ++i) {\n        sum += q[i];\n    }\n\n    // Check if the sum is less than or equal to the maximum weight\n    return sum <= w;\n}\n```"}
{"task_id": "SimdBench_96_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nbool will_it_fly_simd(std::vector<int> q, int w) {\n    int n = q.size();\n    if (n == 0) return false;\n\n    // Ensure the vector is padded to a multiple of 4 for SIMD processing\n    int padded_size = ((n + 3) / 4) * 4;\n    std::vector<int> padded_q(padded_size, 0);\n    for (int i = 0; i < n; ++i) {\n        padded_q[i] = q[i];\n    }\n\n    __m128i sum_vec = _mm_setzero_si128();\n    bool is_palindromic = true;\n\n    for (int i = 0; i < padded_size; i += 4) {\n        // Load 4 elements from the vector\n        __m128i vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&padded_q[i]));\n\n        // Add to the sum vector\n        sum_vec = _mm_add_epi32(sum_vec, vec);\n\n        // Check palindromic property\n        int j = n - i - 1;\n        if (j >= 0 && j < n && i < n && padded_q[i] != padded_q[j]) {\n            is_palindromic = false;\n        }\n    }\n\n    // Horizontal sum of the sum_vec\n    int sum = 0;\n    sum += _mm_extract_epi32(sum_vec, 0);\n    sum += _mm_extract_epi32(sum_vec, 1);\n    sum += _mm_extract_epi32(sum_vec, 2);\n    sum += _mm_extract_epi32(sum_vec, 3);\n\n    // Check conditions\n    return is_palindromic && (sum <= w);\n}\n```"}
{"task_id": "SimdBench_96_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nbool will_it_fly_simd(std::vector<int> q, int w) {\n    int n = q.size();\n    bool is_palindromic = true;\n    int sum = 0;\n\n    // Ensure the vector size is a multiple of 4 for SIMD processing\n    int simd_size = (n / 4) * 4;\n    __m128i vsum = _mm_setzero_si128();\n\n    // Process elements in chunks of 4 using SSE\n    for (int i = 0; i < simd_size; i += 4) {\n        // Load 4 integers into a SIMD register\n        __m128i vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&q[i]));\n\n        // Accumulate the sum horizontally\n        vsum = _mm_add_epi32(vsum, vec);\n\n        // Check palindromic property\n        __m128i reverse_vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&q[n - i - 4]));\n        reverse_vec = _mm_shuffle_epi32(reverse_vec, _MM_SHUFFLE(0, 1, 2, 3)); // Reverse the order\n        __m128i cmp = _mm_cmpeq_epi32(vec, reverse_vec);\n        if (_mm_movemask_epi8(cmp) != 0xFFFF) {\n            is_palindromic = false;\n        }\n    }\n\n    // Horizontally add the accumulated sums in the SIMD register\n    vsum = _mm_hadd_epi32(vsum, vsum);\n    vsum = _mm_hadd_epi32(vsum, vsum);\n    sum = _mm_cvtsi128_si32(vsum);\n\n    // Process remaining elements (if any)\n    for (int i = simd_size; i < n; ++i) {\n        sum += q[i];\n        if (q[i] != q[n - i - 1]) {\n            is_palindromic = false;\n        }\n    }\n\n    // Final check\n    return is_palindromic && (sum <= w);\n}\n```"}
{"task_id": "SimdBench_96_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nbool will_it_fly_simd(std::vector<int> q, int w) {\n    int n = q.size();\n    bool is_palindromic = true;\n    int sum = 0;\n\n    // Ensure the vector size is a multiple of 4 for SIMD processing\n    int simd_size = (n / 4) * 4;\n    __m128i vsum = _mm_setzero_si128();\n\n    // Check palindromic property and compute sum using SIMD\n    for (int i = 0; i < simd_size; i += 4) {\n        // Load 4 elements from the start and end of the current window\n        __m128i v1 = _mm_loadu_si128((__m128i*)&q[i]);\n        __m128i v2 = _mm_loadu_si128((__m128i*)&q[n - i - 4]);\n\n        // Reverse the order of elements in v2\n        v2 = _mm_shuffle_epi32(v2, _MM_SHUFFLE(0, 1, 2, 3));\n\n        // Compare if the two vectors are equal\n        __m128i cmp = _mm_cmpeq_epi32(v1, v2);\n        int mask = _mm_movemask_ps((__m128)cmp);\n\n        // If any element doesn't match, it's not palindromic\n        if (mask != 0xF) {\n            is_palindromic = false;\n        }\n\n        // Add the elements to the running sum\n        vsum = _mm_add_epi32(vsum, v1);\n    }\n\n    // Horizontal sum of the accumulated SIMD sum\n    int temp[4];\n    _mm_storeu_si128((__m128i*)temp, vsum);\n    sum = temp[0] + temp[1] + temp[2] + temp[3];\n\n    // Process remaining elements that didn't fit into SIMD blocks\n    for (int i = simd_size; i < n; ++i) {\n        sum += q[i];\n        if (q[i] != q[n - i - 1]) {\n            is_palindromic = false;\n        }\n    }\n\n    // Final check: must be palindromic and sum <= w\n    return is_palindromic && (sum <= w);\n}\n```"}
{"task_id": "SimdBench_97_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint smallest_change_simd(std::vector<int> arr) {\n    int n = arr.size();\n    int result = 0;\n\n    // Ensure the vector size is a multiple of 4 for SIMD processing\n    int simd_size = (n / 4) * 4;\n    __m128i* data = reinterpret_cast<__m128i*>(arr.data());\n\n    for (int i = 0; i < simd_size / 4; ++i) {\n        __m128i front = _mm_loadu_si128(data + i);\n        __m128i back = _mm_loadu_si128(data + (n / 4 - i - 1));\n\n        // Reverse the order of elements in the 'back' vector\n        __m128i shuffle_mask = _mm_set_epi32(0, 1, 2, 3);\n        back = _mm_shuffle_epi32(back, _MM_SHUFFLE(0, 1, 2, 3));\n\n        // Compare front and back vectors\n        __m128i cmp = _mm_cmpeq_epi32(front, back);\n\n        // Count mismatches\n        int mask = _mm_movemask_ps(_mm_castsi128_ps(cmp));\n        result += __builtin_popcount(~mask & 0xF);\n    }\n\n    // Process remaining elements that don't fit into SIMD registers\n    for (int i = simd_size; i < n / 2; ++i) {\n        if (arr[i] != arr[n - i - 1]) {\n            ++result;\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_97_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint smallest_change_simd(std::vector<int> arr) {\n    int n = arr.size();\n    int result = 0;\n    int i = 0;\n\n    // Process 4 elements at a time using SSE2 intrinsics\n    for (; i <= n - 8; i += 8) {\n        // Load 4 elements from the start and end of the current window\n        __m128i vec_start = _mm_loadu_si128((__m128i*)&arr[i]);\n        __m128i vec_end = _mm_loadu_si128((__m128i*)&arr[n - i - 8]);\n\n        // Reverse the order of the elements in vec_end\n        vec_end = _mm_shuffle_epi32(vec_end, _MM_SHUFFLE(0, 1, 2, 3));\n\n        // Compare the two vectors for equality\n        __m128i cmp = _mm_cmpeq_epi32(vec_start, vec_end);\n\n        // Create a mask to count mismatches\n        int mask = _mm_movemask_ps((__m128)cmp);\n\n        // Count the number of mismatches (0 bits in the mask)\n        result += __builtin_popcount(~mask & 0xF);\n    }\n\n    // Process remaining elements sequentially\n    for (; i < n / 2; ++i) {\n        if (arr[i] != arr[n - i - 1]) {\n            ++result;\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_97_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint smallest_change_simd(std::vector<int> arr) {\n    int n = arr.size();\n    int result = 0;\n    int i = 0;\n\n    // Process elements in chunks of 4 using SSE2\n    for (; i <= n - 8; i += 8) {\n        // Load 4 integers from the start and end of the current window\n        __m128i vec1 = _mm_loadu_si128((__m128i*)&arr[i]);\n        __m128i vec2 = _mm_loadu_si128((__m128i*)&arr[n - i - 4]);\n\n        // Reverse the second vector (vec2)\n        vec2 = _mm_shuffle_epi32(vec2, _MM_SHUFFLE(0, 1, 2, 3));\n\n        // Compare the two vectors for equality\n        __m128i cmp = _mm_cmpeq_epi32(vec1, vec2);\n\n        // Convert comparison result to a bitmask\n        int mask = _mm_movemask_ps(_mm_castsi128_ps(cmp));\n\n        // Count differing elements\n        result += __builtin_popcount(~mask & 0xF);\n    }\n\n    // Process remaining elements sequentially\n    for (; i < n / 2; ++i) {\n        if (arr[i] != arr[n - i - 1]) {\n            ++result;\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_97_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint smallest_change_simd(std::vector<int> arr) {\n    int n = arr.size();\n    int result = 0;\n    int i = 0;\n\n    // Process elements in chunks of 4 using SSE2 intrinsics\n    for (; i <= n - 8; i += 8) {\n        // Load 4 integers from the start and end of the current window\n        __m128i vec1 = _mm_loadu_si128((__m128i*)&arr[i]);\n        __m128i vec2 = _mm_loadu_si128((__m128i*)&arr[n - i - 4]);\n\n        // Reverse the second vector (swap elements for comparison)\n        __m128i shuffle_mask = _mm_set_epi32(0, 1, 2, 3);\n        vec2 = _mm_shuffle_epi32(vec2, _MM_SHUFFLE(0, 1, 2, 3));\n\n        // Compare the two vectors for equality\n        __m128i cmp = _mm_cmpeq_epi32(vec1, vec2);\n\n        // Convert comparison result to a bitmask\n        int mask = _mm_movemask_ps(_mm_castsi128_ps(cmp));\n\n        // Count differing elements (bits not set in the mask)\n        result += __builtin_popcount(~mask & 0xF);\n    }\n\n    // Process remaining elements (if any) using scalar code\n    for (; i < n / 2; ++i) {\n        if (arr[i] != arr[n - i - 1]) {\n            ++result;\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_97_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint smallest_change_simd(std::vector<int> arr) {\n    int n = arr.size();\n    int result = 0;\n    int i = 0;\n\n    // Process elements in chunks of 4 using SSE2\n    for (; i <= n - 8; i += 8) {\n        // Load 4 integers from the start and end of the current window\n        __m128i vec_start = _mm_loadu_si128((__m128i*)&arr[i]);\n        __m128i vec_end = _mm_loadu_si128((__m128i*)&arr[n - i - 8]);\n\n        // Reverse the order of the end vector\n        __m128i vec_end_reversed = _mm_shuffle_epi32(vec_end, _MM_SHUFFLE(0, 1, 2, 3));\n\n        // Compare the two vectors for equality\n        __m128i cmp = _mm_cmpeq_epi32(vec_start, vec_end_reversed);\n\n        // Create a mask to count mismatches\n        int mask = _mm_movemask_ps((__m128)cmp);\n\n        // Count the number of mismatches (0 bits in the mask)\n        result += __builtin_popcount(~mask & 0xF);\n    }\n\n    // Process remaining elements sequentially\n    for (; i < n / 2; ++i) {\n        if (arr[i] != arr[n - i - 1]) {\n            ++result;\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_98_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n\nstd::vector<std::string> total_match_simd(const std::vector<std::string> & lst1, const std::vector<std::string> & lst2) {\n    __m128i sum1 = _mm_setzero_si128();\n    __m128i sum2 = _mm_setzero_si128();\n\n    for (const auto& str : lst1) {\n        int len = str.size();\n        __m128i vlen = _mm_set1_epi32(len);\n        sum1 = _mm_add_epi32(sum1, vlen);\n    }\n\n    for (const auto& str : lst2) {\n        int len = str.size();\n        __m128i vlen = _mm_set1_epi32(len);\n        sum2 = _mm_add_epi32(sum2, vlen);\n    }\n\n    int total1[4], total2[4];\n    _mm_storeu_si128((__m128i*)total1, sum1);\n    _mm_storeu_si128((__m128i*)total2, sum2);\n\n    int total_len1 = total1[0] + total1[1] + total1[2] + total1[3];\n    int total_len2 = total2[0] + total2[1] + total2[2] + total2[3];\n\n    if (total_len1 <= total_len2) {\n        return lst1;\n    } else {\n        return lst2;\n    }\n}\n```"}
{"task_id": "SimdBench_98_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n\nstd::vector<std::string> total_match_simd(const std::vector<std::string> & lst1, const std::vector<std::string> & lst2) {\n    __m128i sum1 = _mm_setzero_si128();\n    __m128i sum2 = _mm_setzero_si128();\n\n    for (const auto& str : lst1) {\n        int len = str.size();\n        __m128i vlen = _mm_set1_epi32(len);\n        sum1 = _mm_add_epi32(sum1, vlen);\n    }\n\n    for (const auto& str : lst2) {\n        int len = str.size();\n        __m128i vlen = _mm_set1_epi32(len);\n        sum2 = _mm_add_epi32(sum2, vlen);\n    }\n\n    int total1[4], total2[4];\n    _mm_storeu_si128((__m128i*)total1, sum1);\n    _mm_storeu_si128((__m128i*)total2, sum2);\n\n    int sum_lst1 = total1[0] + total1[1] + total1[2] + total1[3];\n    int sum_lst2 = total2[0] + total2[1] + total2[2] + total2[3];\n\n    if (sum_lst1 <= sum_lst2) {\n        return lst1;\n    } else {\n        return lst2;\n    }\n}\n```"}
{"task_id": "SimdBench_98_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n\nstd::vector<std::string> total_match_simd(const std::vector<std::string> & lst1, const std::vector<std::string> & lst2) {\n    __m128i sum1 = _mm_setzero_si128();\n    __m128i sum2 = _mm_setzero_si128();\n\n    for (const auto& str : lst1) {\n        int len = str.size();\n        __m128i vlen = _mm_set1_epi32(len);\n        sum1 = _mm_add_epi32(sum1, vlen);\n    }\n\n    for (const auto& str : lst2) {\n        int len = str.size();\n        __m128i vlen = _mm_set1_epi32(len);\n        sum2 = _mm_add_epi32(sum2, vlen);\n    }\n\n    int total1[4], total2[4];\n    _mm_storeu_si128((__m128i*)total1, sum1);\n    _mm_storeu_si128((__m128i*)total2, sum2);\n\n    int sum_lst1 = total1[0] + total1[1] + total1[2] + total1[3];\n    int sum_lst2 = total2[0] + total2[1] + total2[2] + total2[3];\n\n    if (sum_lst1 <= sum_lst2) {\n        return lst1;\n    } else {\n        return lst2;\n    }\n}\n```"}
{"task_id": "SimdBench_98_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n\nstd::vector<std::string> total_match_simd(const std::vector<std::string> & lst1, const std::vector<std::string> & lst2) {\n    __m128i sum1 = _mm_setzero_si128();\n    __m128i sum2 = _mm_setzero_si128();\n\n    for (const auto& str : lst1) {\n        int len = str.size();\n        __m128i vlen = _mm_set1_epi32(len);\n        sum1 = _mm_add_epi32(sum1, vlen);\n    }\n\n    for (const auto& str : lst2) {\n        int len = str.size();\n        __m128i vlen = _mm_set1_epi32(len);\n        sum2 = _mm_add_epi32(sum2, vlen);\n    }\n\n    int total1[4], total2[4];\n    _mm_storeu_si128((__m128i*)total1, sum1);\n    _mm_storeu_si128((__m128i*)total2, sum2);\n\n    int sum_lst1 = total1[0] + total1[1] + total1[2] + total1[3];\n    int sum_lst2 = total2[0] + total2[1] + total2[2] + total2[3];\n\n    if (sum_lst1 <= sum_lst2) {\n        return lst1;\n    } else {\n        return lst2;\n    }\n}\n```"}
{"task_id": "SimdBench_98_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n\nstd::vector<std::string> total_match_simd(const std::vector<std::string> & lst1, const std::vector<std::string> & lst2) {\n    __m128i sum1 = _mm_setzero_si128();\n    __m128i sum2 = _mm_setzero_si128();\n\n    for (const auto& str : lst1) {\n        int len = str.size();\n        __m128i vlen = _mm_set1_epi32(len);\n        sum1 = _mm_add_epi32(sum1, vlen);\n    }\n\n    for (const auto& str : lst2) {\n        int len = str.size();\n        __m128i vlen = _mm_set1_epi32(len);\n        sum2 = _mm_add_epi32(sum2, vlen);\n    }\n\n    int total1[4], total2[4];\n    _mm_storeu_si128((__m128i*)total1, sum1);\n    _mm_storeu_si128((__m128i*)total2, sum2);\n\n    int total_len1 = total1[0] + total1[1] + total1[2] + total1[3];\n    int total_len2 = total2[0] + total2[1] + total2[2] + total2[3];\n\n    if (total_len1 <= total_len2) {\n        return lst1;\n    } else {\n        return lst2;\n    }\n}\n```"}
{"task_id": "SimdBench_99_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool is_simple_power_simd(uint64_t x, uint64_t n) {\n    if (n <= 1 || x == 0) return false;\n    if (x == 1) return true;\n\n    __m128i vx = _mm_set1_epi64x(x);\n    __m128i vn = _mm_set1_epi64x(n);\n    __m128i vresult = _mm_setzero_si128();\n    __m128i vpower = _mm_set1_epi64x(1);\n\n    for (int i = 0; i < 64; ++i) {\n        vpower = _mm_mul_epu32(vpower, vn);\n        __m128i cmp = _mm_cmpeq_epi64(vpower, vx);\n        vresult = _mm_or_si128(vresult, cmp);\n\n        // Break early if power exceeds x\n        __m128i cmp_gt = _mm_cmpgt_epi64(vpower, vx);\n        if (_mm_movemask_epi8(cmp_gt)) break;\n    }\n\n    int mask = _mm_movemask_epi8(vresult);\n    return mask != 0;\n}\n```"}
{"task_id": "SimdBench_99_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool is_simple_power_simd(uint64_t x, uint64_t n) {\n    if (n <= 1 || x == 0) return false;\n    if (x == 1) return true;\n\n    __m128i vx = _mm_set1_epi64x(x);\n    __m128i vn = _mm_set1_epi64x(n);\n    __m128i vresult = _mm_setzero_si128();\n    __m128i vpower = _mm_set1_epi64x(1);\n\n    for (int i = 0; i < 64; ++i) {\n        vpower = _mm_mul_epu32(vpower, vn);\n        __m128i cmp = _mm_cmpeq_epi64(vpower, vx);\n        vresult = _mm_or_si128(vresult, cmp);\n\n        // Break early if power exceeds x\n        __m128i cmp_gt = _mm_cmpgt_epi64(vpower, vx);\n        if (_mm_movemask_epi8(cmp_gt) == 0xFFFF) break;\n    }\n\n    int mask = _mm_movemask_epi8(vresult);\n    return mask != 0;\n}\n```"}
{"task_id": "SimdBench_99_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool is_simple_power_simd(uint64_t x, uint64_t n) {\n    if (n <= 1) return x == 1;\n\n    __m128i vx = _mm_set1_epi64x(x);\n    __m128i vn = _mm_set1_epi64x(n);\n    __m128i vpow = _mm_set1_epi64x(1);\n    __m128i vcmp = _mm_setzero_si128();\n\n    while (true) {\n        vpow = _mm_mul_epu32(vpow, vn); // Multiply lower 32 bits of each 64-bit element\n        vcmp = _mm_cmpeq_epi64(vpow, vx); // Compare for equality\n\n        int mask = _mm_movemask_epi8(vcmp); // Extract comparison results\n        if (mask != 0) {\n            return true; // If any element matches, return true\n        }\n\n        // Check for overflow or if power exceeds x\n        __m128i overflow_mask = _mm_cmpgt_epi64(vpow, vx);\n        if (_mm_movemask_epi8(overflow_mask) != 0) {\n            break;\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_99_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool is_simple_power_simd(uint64_t x, uint64_t n) {\n    if (n <= 1) return x == 1;\n\n    __m128i vx = _mm_set1_epi64x(x);\n    __m128i vn = _mm_set1_epi64x(n);\n    __m128i vresult = _mm_setzero_si128();\n    __m128i vpower = _mm_set1_epi64x(1);\n\n    for (int i = 0; i < 64; ++i) {\n        vpower = _mm_mul_epu32(vpower, vn);\n        __m128i cmp = _mm_cmpeq_epi64(vpower, vx);\n        vresult = _mm_or_si128(vresult, cmp);\n\n        // Break early if power exceeds x\n        if (_mm_movemask_epi8(_mm_cmpgt_epi64(vpower, vx))) {\n            break;\n        }\n    }\n\n    int mask = _mm_movemask_epi8(vresult);\n    return mask != 0;\n}\n```"}
{"task_id": "SimdBench_99_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool is_simple_power_simd(uint64_t x, uint64_t n) {\n    if (n <= 1) return x == 1;\n\n    __m128i vx = _mm_set1_epi64x(x);\n    __m128i vn = _mm_set1_epi64x(n);\n    __m128i vpow = _mm_set1_epi64x(1);\n    __m128i vcmp = _mm_setzero_si128();\n\n    while (true) {\n        vpow = _mm_mul_epu32(vpow, vn); // Multiply lower 32 bits of each 64-bit element\n        vcmp = _mm_cmpeq_epi64(vpow, vx); // Compare for equality\n\n        int mask = _mm_movemask_epi8(vcmp);\n        if (mask != 0) {\n            return true;\n        }\n\n        // Check if the power exceeds x\n        __m128i vcmp_gt = _mm_cmpgt_epi64(vpow, vx);\n        int gt_mask = _mm_movemask_epi8(vcmp_gt);\n        if (gt_mask != 0) {\n            return false;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_100_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint hex_key_simd(const std::string & num) {\n    // Prime digits in hexadecimal: '2', '3', '5', '7', 'B', 'D'\n    const __m128i prime_mask = _mm_setr_epi8(\n        0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0\n    );\n\n    int count = 0;\n    size_t i = 0;\n    size_t length = num.size();\n\n    // Process 16 characters at a time\n    for (; i + 16 <= length; i += 16) {\n        // Load 16 characters into an SSE register\n        __m128i chars = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&num[i]));\n\n        // Convert characters to indices (0-15)\n        __m128i indices = _mm_sub_epi8(chars, _mm_set1_epi8('0'));\n        __m128i is_alpha = _mm_cmpgt_epi8(chars, _mm_set1_epi8('9'));\n        __m128i alpha_offset = _mm_and_si128(is_alpha, _mm_set1_epi8('A' - '9' - 1));\n        indices = _mm_sub_epi8(indices, alpha_offset);\n\n        // Lookup in the prime mask\n        __m128i prime_check = _mm_shuffle_epi8(prime_mask, indices);\n\n        // Count the number of primes in this block\n        count += _mm_popcnt_u32(_mm_movemask_epi8(prime_check));\n    }\n\n    // Process remaining characters\n    for (; i < length; ++i) {\n        char c = num[i];\n        int index = (c >= 'A') ? (c - 'A' + 10) : (c - '0');\n        if (index == 2 || index == 3 || index == 5 || index == 7 || index == 11 || index == 13) {\n            ++count;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_100_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint hex_key_simd(const std::string & num) {\n    // Prime digits in hexadecimal: '2', '3', '5', '7', 'B', 'D'\n    const __m128i prime_chars = _mm_setr_epi8('2', '3', '5', '7', 'B', 'D', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n    int count = 0;\n    size_t length = num.size();\n    size_t i = 0;\n\n    // Process the string in chunks of 16 bytes using SSE2 intrinsics\n    for (; i + 16 <= length; i += 16) {\n        // Load 16 characters from the input string\n        __m128i input = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&num[i]));\n\n        // Compare each character with the prime characters\n        __m128i cmp1 = _mm_cmpeq_epi8(input, _mm_set1_epi8('2'));\n        __m128i cmp2 = _mm_cmpeq_epi8(input, _mm_set1_epi8('3'));\n        __m128i cmp3 = _mm_cmpeq_epi8(input, _mm_set1_epi8('5'));\n        __m128i cmp4 = _mm_cmpeq_epi8(input, _mm_set1_epi8('7'));\n        __m128i cmp5 = _mm_cmpeq_epi8(input, _mm_set1_epi8('B'));\n        __m128i cmp6 = _mm_cmpeq_epi8(input, _mm_set1_epi8('D'));\n\n        // Combine all comparisons using bitwise OR\n        __m128i result = _mm_or_si128(_mm_or_si128(cmp1, cmp2), _mm_or_si128(cmp3, cmp4));\n        result = _mm_or_si128(result, _mm_or_si128(cmp5, cmp6));\n\n        // Count the number of matches by extracting the mask\n        int mask = _mm_movemask_epi8(result);\n        count += __builtin_popcount(mask);\n    }\n\n    // Process any remaining characters (less than 16)\n    for (; i < length; ++i) {\n        char c = num[i];\n        if (c == '2' || c == '3' || c == '5' || c == '7' || c == 'B' || c == 'D') {\n            ++count;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_100_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint hex_key_simd(const std::string & num) {\n    // Prime digits in hexadecimal: '2', '3', '5', '7', 'B', 'D'\n    const __m128i prime_chars = _mm_setr_epi8('2', '3', '5', '7', 'B', 'D', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n    int count = 0;\n    size_t length = num.size();\n\n    // Process the string in chunks of 16 bytes using SSE2 intrinsics\n    size_t i = 0;\n    for (; i + 16 <= length; i += 16) {\n        // Load 16 characters from the input string\n        __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&num[i]));\n\n        // Compare each character in the chunk with the prime characters\n        __m128i cmp1 = _mm_cmpeq_epi8(chunk, _mm_shuffle_epi8(prime_chars, _mm_set1_epi8(0)));\n        __m128i cmp2 = _mm_cmpeq_epi8(chunk, _mm_shuffle_epi8(prime_chars, _mm_set1_epi8(1)));\n        __m128i cmp3 = _mm_cmpeq_epi8(chunk, _mm_shuffle_epi8(prime_chars, _mm_set1_epi8(2)));\n        __m128i cmp4 = _mm_cmpeq_epi8(chunk, _mm_shuffle_epi8(prime_chars, _mm_set1_epi8(3)));\n        __m128i cmp5 = _mm_cmpeq_epi8(chunk, _mm_shuffle_epi8(prime_chars, _mm_set1_epi8(4)));\n        __m128i cmp6 = _mm_cmpeq_epi8(chunk, _mm_shuffle_epi8(prime_chars, _mm_set1_epi8(5)));\n\n        // Combine all comparisons into a single mask\n        __m128i mask = _mm_or_si128(_mm_or_si128(cmp1, cmp2), _mm_or_si128(cmp3, cmp4));\n        mask = _mm_or_si128(mask, _mm_or_si128(cmp5, cmp6));\n\n        // Count the number of matches (non-zero bytes in the mask)\n        int mask_bits = _mm_movemask_epi8(mask);\n        count += __builtin_popcount(mask_bits);\n    }\n\n    // Process any remaining characters that didn't fit into a full 16-byte chunk\n    for (; i < length; ++i) {\n        char c = num[i];\n        if (c == '2' || c == '3' || c == '5' || c == '7' || c == 'B' || c == 'D') {\n            ++count;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_100_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint hex_key_simd(const std::string & num) {\n    // Prime digits in hexadecimal: '2', '3', '5', '7', 'B', 'D'\n    const __m128i prime_mask = _mm_setr_epi8(\n        0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0\n    );\n\n    int count = 0;\n    size_t i = 0;\n    size_t length = num.size();\n\n    // Process 16 characters at a time using SIMD\n    for (; i + 16 <= length; i += 16) {\n        // Load 16 characters from the string\n        __m128i chars = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&num[i]));\n\n        // Convert characters to indices (0-15)\n        __m128i indices = _mm_sub_epi8(chars, _mm_set1_epi8('0'));\n        __m128i is_alpha = _mm_cmpgt_epi8(chars, _mm_set1_epi8('9'));\n        __m128i alpha_offset = _mm_and_si128(is_alpha, _mm_set1_epi8('A' - '0' - 10));\n        indices = _mm_sub_epi8(indices, alpha_offset);\n\n        // Lookup in the prime mask\n        __m128i prime_check = _mm_shuffle_epi8(prime_mask, indices);\n\n        // Count the number of primes in this batch\n        count += _mm_popcnt_u32(_mm_movemask_epi8(prime_check));\n    }\n\n    // Process remaining characters\n    for (; i < length; ++i) {\n        char c = num[i];\n        int index = (c >= 'A') ? (c - 'A' + 10) : (c - '0');\n        if (index == 2 || index == 3 || index == 5 || index == 7 || index == 11 || index == 13) {\n            ++count;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_100_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint hex_key_simd(const std::string & num) {\n    // Prime digits in hexadecimal: '2', '3', '5', '7', 'B', 'D'\n    const __m128i prime_chars = _mm_setr_epi8('2', '3', '5', '7', 'B', 'D', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n    int count = 0;\n    size_t length = num.size();\n    size_t i = 0;\n\n    // Process 16 characters at a time using SIMD\n    for (; i + 16 <= length; i += 16) {\n        // Load 16 characters from the input string\n        __m128i input = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&num[i]));\n\n        // Compare each character with the prime characters\n        __m128i cmp1 = _mm_cmpeq_epi8(input, _mm_shuffle_epi8(prime_chars, _mm_set1_epi8(0)));\n        __m128i cmp2 = _mm_cmpeq_epi8(input, _mm_shuffle_epi8(prime_chars, _mm_set1_epi8(1)));\n        __m128i cmp3 = _mm_cmpeq_epi8(input, _mm_shuffle_epi8(prime_chars, _mm_set1_epi8(2)));\n        __m128i cmp4 = _mm_cmpeq_epi8(input, _mm_shuffle_epi8(prime_chars, _mm_set1_epi8(3)));\n        __m128i cmp5 = _mm_cmpeq_epi8(input, _mm_shuffle_epi8(prime_chars, _mm_set1_epi8(4)));\n        __m128i cmp6 = _mm_cmpeq_epi8(input, _mm_shuffle_epi8(prime_chars, _mm_set1_epi8(5)));\n\n        // Combine all comparisons\n        __m128i cmp_result = _mm_or_si128(_mm_or_si128(_mm_or_si128(cmp1, cmp2), _mm_or_si128(cmp3, cmp4)), _mm_or_si128(cmp5, cmp6));\n\n        // Count the number of matches\n        int mask = _mm_movemask_epi8(cmp_result);\n        count += __builtin_popcount(mask);\n    }\n\n    // Process remaining characters (if any)\n    for (; i < length; ++i) {\n        char c = num[i];\n        if (c == '2' || c == '3' || c == '5' || c == '7' || c == 'B' || c == 'D') {\n            ++count;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_101_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool is_happy_simd(const std::string & s) {\n    size_t len = s.length();\n    if (len < 3) return false;\n\n    __m128i prev_chunk = _mm_setzero_si128();\n    __m128i curr_chunk;\n\n    for (size_t i = 0; i <= len - 16; i += 16) {\n        curr_chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&s[i]));\n\n        // Compare each byte with the next one and the one after that\n        __m128i cmp1 = _mm_cmpeq_epi8(curr_chunk, _mm_alignr_epi8(curr_chunk, prev_chunk, 15));\n        __m128i cmp2 = _mm_cmpeq_epi8(curr_chunk, _mm_alignr_epi8(curr_chunk, prev_chunk, 14));\n\n        // Check for any equal consecutive bytes within the current chunk\n        __m128i or_result = _mm_or_si128(cmp1, cmp2);\n        if (!_mm_testz_si128(or_result, or_result)) {\n            return false;\n        }\n\n        prev_chunk = curr_chunk;\n    }\n\n    // Handle the remaining characters (less than 16)\n    for (size_t i = len - (len % 16); i < len - 2; ++i) {\n        if (s[i] == s[i + 1] || s[i] == s[i + 2] || s[i + 1] == s[i + 2]) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_101_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool is_happy_simd(const std::string & s) {\n    size_t len = s.length();\n    if (len < 3) return false;\n\n    __m128i prev_chunk = _mm_setzero_si128();\n    __m128i curr_chunk;\n\n    for (size_t i = 0; i <= len - 16; i += 16) {\n        curr_chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&s[i]));\n\n        // Compare each byte with the next one and the one after that\n        __m128i cmp1 = _mm_cmpeq_epi8(curr_chunk, _mm_alignr_epi8(curr_chunk, prev_chunk, 15));\n        __m128i cmp2 = _mm_cmpeq_epi8(curr_chunk, _mm_alignr_epi8(curr_chunk, prev_chunk, 14));\n\n        // Combine comparisons\n        __m128i cmp_or = _mm_or_si128(cmp1, cmp2);\n\n        // Check if any of the bytes in the comparison result are non-zero\n        if (!_mm_testz_si128(cmp_or, cmp_or)) {\n            return false;\n        }\n\n        prev_chunk = curr_chunk;\n    }\n\n    // Handle remaining characters\n    for (size_t i = len - (len % 16); i < len - 2; ++i) {\n        if (s[i] == s[i + 1] || s[i] == s[i + 2]) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_101_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool is_happy_simd(const std::string & s) {\n    size_t len = s.length();\n    if (len < 3) return false;\n\n    __m128i prev_chunk = _mm_setzero_si128();\n    __m128i curr_chunk;\n\n    for (size_t i = 0; i <= len - 16; i += 16) {\n        curr_chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&s[i]));\n\n        // Compare each byte with the next one and the one after that\n        __m128i cmp1 = _mm_cmpeq_epi8(curr_chunk, _mm_alignr_epi8(curr_chunk, prev_chunk, 15));\n        __m128i cmp2 = _mm_cmpeq_epi8(curr_chunk, _mm_alignr_epi8(curr_chunk, prev_chunk, 14));\n\n        // Check within current chunk\n        __m128i cmp3 = _mm_cmpeq_epi8(curr_chunk, _mm_srli_si128(curr_chunk, 1));\n        __m128i cmp4 = _mm_cmpeq_epi8(curr_chunk, _mm_srli_si128(curr_chunk, 2));\n\n        __m128i or_result = _mm_or_si128(_mm_or_si128(cmp1, cmp2), _mm_or_si128(cmp3, cmp4));\n        if (!_mm_testz_si128(or_result, or_result)) {\n            return false;\n        }\n\n        prev_chunk = curr_chunk;\n    }\n\n    // Handle remaining characters (less than 16)\n    for (size_t i = len - (len % 16); i < len - 2; ++i) {\n        if (s[i] == s[i + 1] || s[i] == s[i + 2] || s[i + 1] == s[i + 2]) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_101_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool is_happy_simd(const std::string & s) {\n    size_t len = s.length();\n    if (len < 3) return false;\n\n    __m128i prev_chunk = _mm_setzero_si128();\n    __m128i curr_chunk;\n\n    for (size_t i = 0; i <= len - 16; i += 16) {\n        curr_chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&s[i]));\n\n        // Compare each byte with the next one and the one after that\n        __m128i cmp1 = _mm_cmpeq_epi8(curr_chunk, _mm_alignr_epi8(curr_chunk, prev_chunk, 15));\n        __m128i cmp2 = _mm_cmpeq_epi8(curr_chunk, _mm_alignr_epi8(curr_chunk, prev_chunk, 14));\n\n        // Check within current chunk\n        __m128i cmp3 = _mm_cmpeq_epi8(curr_chunk, _mm_srli_si128(curr_chunk, 1));\n        __m128i cmp4 = _mm_cmpeq_epi8(curr_chunk, _mm_srli_si128(curr_chunk, 2));\n\n        __m128i or_result = _mm_or_si128(_mm_or_si128(cmp1, cmp2), _mm_or_si128(cmp3, cmp4));\n        if (!_mm_testz_si128(or_result, or_result)) {\n            return false;\n        }\n\n        prev_chunk = curr_chunk;\n    }\n\n    // Handle remaining characters\n    for (size_t i = len - (len % 16); i < len - 2; ++i) {\n        if (s[i] == s[i + 1] || s[i] == s[i + 2] || s[i + 1] == s[i + 2]) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_101_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool is_happy_simd(const std::string & s) {\n    size_t len = s.length();\n    if (len < 3) return false;\n\n    __m128i prev_chunk = _mm_setzero_si128();\n    size_t i = 0;\n\n    for (; i + 16 <= len; i += 16) {\n        __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&s[i]));\n\n        // Compare each byte with the next one\n        __m128i cmp1 = _mm_cmpeq_epi8(chunk, _mm_alignr_epi8(chunk, prev_chunk, 15));\n        __m128i cmp2 = _mm_cmpeq_epi8(chunk, _mm_alignr_epi8(chunk, prev_chunk, 14));\n\n        // Combine comparisons\n        __m128i cmp = _mm_or_si128(cmp1, cmp2);\n\n        // Check if any of the comparisons resulted in equality\n        if (!_mm_testz_si128(cmp, cmp)) {\n            return false;\n        }\n\n        prev_chunk = chunk;\n    }\n\n    // Handle remaining characters\n    for (; i < len - 2; ++i) {\n        if (s[i] == s[i + 1] || s[i] == s[i + 2] || s[i + 1] == s[i + 2]) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_102_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool prime_length_simd(const std::string & str) {\n    size_t len = str.length();\n    if (len < 2) return false;\n\n    // Load the length into an SSE register for parallel processing\n    __m128i vlen = _mm_set1_epi32(len);\n\n    // Prepare a vector of divisors to test against (2, 3, 5, 7)\n    __m128i divisors = _mm_setr_epi32(2, 3, 5, 7);\n    __m128i zero = _mm_setzero_si128();\n\n    // Perform division checks in parallel\n    __m128i mod_results = _mm_rem_epi32(vlen, divisors);\n\n    // Check if any modulus result is zero (indicating divisibility)\n    __m128i cmp_results = _mm_cmpeq_epi32(mod_results, zero);\n    int mask = _mm_movemask_ps((__m128)cmp_results);\n\n    // If any divisor divides the length evenly, it's not prime\n    if (mask != 0) return false;\n\n    // Handle remaining prime checks for numbers greater than 7\n    for (size_t i = 11; i * i <= len; i += 2) {\n        if (len % i == 0) return false;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_102_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool prime_length_simd(const std::string & str) {\n    size_t len = str.length();\n    if (len < 2) return false;\n\n    // Load the length into a SIMD register for parallel computation\n    __m128i len_vec = _mm_set1_epi32(static_cast<int>(len));\n    __m128i zero_vec = _mm_setzero_si128();\n    __m128i one_vec = _mm_set1_epi32(1);\n    __m128i divisors = _mm_setr_epi32(2, 3, 5, 7); // Initial small primes\n\n    int is_prime = 1; // Assume prime initially\n\n    // Check divisors in parallel using SIMD\n    for (int d = 2; d * d <= len; d += 4) {\n        __m128i current_divisors = _mm_add_epi32(divisors, _mm_set1_epi32(d - 2));\n        __m128i mod_results = _mm_setzero_si128();\n\n        // Compute len % divisor for each divisor in parallel\n        for (int i = 0; i < 4; ++i) {\n            int divisor = d + i;\n            if (divisor * divisor > len) break;\n\n            int remainder = static_cast<int>(len % divisor);\n            mod_results = _mm_insert_epi32(mod_results, remainder, i);\n        }\n\n        // Check if any remainder is zero\n        __m128i cmp_results = _mm_cmpeq_epi32(mod_results, zero_vec);\n        int mask = _mm_movemask_epi8(cmp_results);\n\n        if (mask != 0) {\n            is_prime = 0; // Not a prime\n            break;\n        }\n    }\n\n    return is_prime != 0;\n}\n```"}
{"task_id": "SimdBench_102_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool prime_length_simd(const std::string & str) {\n    size_t len = str.length();\n    if (len < 2) return false;\n\n    // Load the length into an SSE register for parallel processing\n    __m128i vlen = _mm_set1_epi32(len);\n\n    // Prepare a vector of divisors (2, 3, 4, 5)\n    __m128i divisors = _mm_setr_epi32(2, 3, 4, 5);\n    __m128i zero = _mm_setzero_si128();\n\n    // Perform division checks in parallel\n    __m128i mod_results = _mm_rem_epi32(vlen, divisors);\n\n    // Check if any modulus result is zero (indicating non-prime)\n    __m128i cmp_results = _mm_cmpeq_epi32(mod_results, zero);\n    int mask = _mm_movemask_ps((__m128)cmp_results);\n\n    // If any modulus was zero, it's not a prime\n    if (mask != 0) return false;\n\n    // Handle remaining divisors beyond 5 using scalar code\n    for (size_t i = 6; i * i <= len; ++i) {\n        if (len % i == 0) return false;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_102_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool prime_length_simd(const std::string & str) {\n    size_t len = str.length();\n    if (len < 2) return false;\n\n    // Load the length into a SIMD register for parallel processing\n    __m128i vlen = _mm_set1_epi32(len);\n\n    // Prepare divisors (2, 3, 5, 7) in a SIMD register\n    __m128i divisors = _mm_setr_epi32(2, 3, 5, 7);\n\n    // Perform division checks in parallel\n    __m128i results = _mm_div_epu32(vlen, divisors);\n\n    // Check if any of the divisions resulted in zero remainder\n    __m128i remainders = _mm_rem_epu32(vlen, divisors);\n    int mask = _mm_movemask_ps((__m128)_mm_cmpeq_epi32(remainders, _mm_setzero_si128()));\n\n    // If any remainder is zero, it's not a prime\n    if (mask != 0) return false;\n\n    // Fallback for lengths greater than 7\n    for (size_t i = 11; i * i <= len; i += 2) {\n        if (len % i == 0) return false;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_102_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool prime_length_simd(const std::string & str) {\n    int length = str.length();\n    if (length < 2) return false;\n\n    __m128i vec_len = _mm_set1_epi32(length);\n    __m128i vec_zero = _mm_setzero_si128();\n    __m128i vec_one = _mm_set1_epi32(1);\n    __m128i vec_two = _mm_set1_epi32(2);\n\n    // Check divisibility by 2\n    __m128i mod_two = _mm_and_si128(vec_len, vec_one);\n    if (_mm_test_all_zeros(mod_two, vec_one)) {\n        return length == 2;\n    }\n\n    // Prepare for divisibility checks from 3 to sqrt(length)\n    int limit = static_cast<int>(sqrt(static_cast<double>(length))) + 1;\n    __m128i vec_i = _mm_set1_epi32(3);\n\n    while (true) {\n        // Stop if i > limit\n        if (_mm_cvtsi128_si32(vec_i) > limit) break;\n\n        // Compute remainder of length / i using scalar fallback\n        int i_val = _mm_cvtsi128_si32(vec_i);\n        if (length % i_val == 0) {\n            return false;\n        }\n\n        // Increment i by 2\n        vec_i = _mm_add_epi32(vec_i, vec_two);\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_103_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n#include <bitset>\n\nstd::string solve_simd(uint64_t N) {\n    __m128i vsum = _mm_setzero_si128(); // Initialize sum vector to zero\n    uint64_t temp = N;\n    int digit_count = 0;\n\n    // Process digits in chunks of 16 using SIMD\n    while (temp > 0) {\n        // Load 16 digits into a SIMD register (pad with zeros if necessary)\n        char digits[16] = {0};\n        for (int i = 0; i < 16 && temp > 0; ++i, temp /= 10) {\n            digits[i] = temp % 10;\n            digit_count++;\n        }\n\n        __m128i vdigits = _mm_loadu_si128(reinterpret_cast<const __m128i*>(digits));\n        vsum = _mm_add_epi8(vsum, vdigits); // Add the digits to the sum vector\n    }\n\n    // Horizontal sum of the SIMD register\n    int sum = 0;\n    alignas(16) char result[16];\n    _mm_store_si128(reinterpret_cast<__m128i*>(result), vsum);\n    for (int i = 0; i < 16; ++i) {\n        sum += result[i];\n    }\n\n    // Convert the sum to binary string\n    std::string binary = std::bitset<32>(sum).to_string();\n    // Remove leading zeros\n    size_t first_one = binary.find('1');\n    return first_one != std::string::npos ? binary.substr(first_one) : \"0\";\n}\n```"}
{"task_id": "SimdBench_103_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n#include <bitset>\n\nstd::string solve_simd(uint64_t N) {\n    __m128i vsum = _mm_setzero_si128();\n    __m128i vdigits = _mm_set_epi8('0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0');\n    __m128i vzero = _mm_setzero_si128();\n\n    // Convert the number to a string\n    std::string num_str = std::to_string(N);\n    int len = num_str.length();\n\n    // Process 16 digits at a time using SIMD\n    for (int i = 0; i < len; i += 16) {\n        __m128i vchunk;\n        if (i + 16 <= len) {\n            vchunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&num_str[i]));\n        } else {\n            char temp[16] = {0};\n            memcpy(temp, &num_str[i], len - i);\n            vchunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(temp));\n        }\n\n        // Subtract '0' to convert characters to integers\n        vchunk = _mm_sub_epi8(vchunk, vdigits);\n\n        // Mask out invalid bytes (if any)\n        __m128i mask = _mm_cmplt_epi8(_mm_set1_epi8(i + 16 > len ? len - i : 16), _mm_set_epi8(15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 0));\n        vchunk = _mm_andnot_si128(mask, vchunk);\n\n        // Horizontal sum of the valid bytes\n        __m128i vsum_temp = _mm_sad_epu8(vchunk, vzero);\n        vsum = _mm_add_epi32(vsum, vsum_temp);\n    }\n\n    // Extract the total sum from the SIMD register\n    int total_sum = _mm_extract_epi32(vsum, 0) + _mm_extract_epi32(vsum, 2);\n\n    // Convert the sum to binary representation\n    std::string binary = std::bitset<32>(total_sum).to_string();\n    // Remove leading zeros\n    size_t first_one = binary.find('1');\n    return first_one != std::string::npos ? binary.substr(first_one) : \"0\";\n}\n```"}
{"task_id": "SimdBench_103_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n#include <bitset>\n\nstd::string solve_simd(uint64_t N) {\n    __m128i vsum = _mm_setzero_si128(); // Initialize sum vector to zero\n    uint64_t temp = N;\n    int digit_count = 0;\n\n    // Process digits in chunks of 16 using SIMD\n    while (temp > 0) {\n        // Load 16 digits into a SIMD register\n        char digits[16] = {0};\n        for (int i = 0; i < 16 && temp > 0; ++i) {\n            digits[i] = temp % 10;\n            temp /= 10;\n            ++digit_count;\n        }\n\n        __m128i vdigits = _mm_loadu_si128(reinterpret_cast<const __m128i*>(digits));\n        vsum = _mm_add_epi8(vsum, vdigits); // Add the digits to the sum vector\n    }\n\n    // Horizontal sum of the SIMD register\n    int sum = 0;\n    alignas(16) char result[16];\n    _mm_store_si128(reinterpret_cast<__m128i*>(result), vsum);\n    for (int i = 0; i < 16; ++i) {\n        sum += result[i];\n    }\n\n    // Convert the sum to binary string\n    std::string binary = std::bitset<32>(sum).to_string();\n    // Remove leading zeros\n    size_t first_one = binary.find('1');\n    return first_one != std::string::npos ? binary.substr(first_one) : \"0\";\n}\n```"}
{"task_id": "SimdBench_103_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n#include <bitset>\n\nstd::string solve_simd(uint64_t N) {\n    __m128i vsum = _mm_setzero_si128();\n    __m128i vdigits = _mm_set_epi8('0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0');\n    __m128i vN = _mm_set_epi64x(0, N);\n\n    while (_mm_cvtsi128_si64(vN) > 0) {\n        __m128i remainder = _mm_and_si128(vN, _mm_set_epi8(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0xF));\n        vsum = _mm_add_epi8(vsum, remainder);\n        vN = _mm_srli_epi64(vN, 4);\n    }\n\n    int sum = 0;\n    alignas(16) char buffer[16];\n    _mm_store_si128((__m128i*)buffer, vsum);\n\n    for (int i = 0; i < 16; ++i) {\n        sum += buffer[i];\n    }\n\n    std::string binary = std::bitset<32>(sum).to_string();\n    size_t first_one = binary.find('1');\n    return first_one != std::string::npos ? binary.substr(first_one) : \"0\";\n}\n```"}
{"task_id": "SimdBench_103_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n#include <bitset>\n\nstd::string solve_simd(uint64_t N) {\n    __m128i vsum = _mm_setzero_si128();\n    uint64_t temp = N;\n\n    while (temp > 0) {\n        // Load 16 bytes (8 digits) at a time\n        __m128i vdigits = _mm_set_epi64x(0, temp);\n        __m128i vmod = _mm_set1_epi8(10);\n\n        // Compute digit-wise modulo 10 to extract digits\n        __m128i vremainder = _mm_rem_epu8(vdigits, vmod);\n\n        // Accumulate the sum of extracted digits horizontally\n        vsum = _mm_add_epi8(vsum, vremainder);\n\n        // Shift right to process next set of digits\n        temp /= 100000000;\n    }\n\n    // Horizontal sum of the 16 byte elements in vsum\n    int sum = 0;\n    alignas(16) uint8_t buffer[16];\n    _mm_store_si128((__m128i*)buffer, vsum);\n\n    for (int i = 0; i < 16; ++i) {\n        sum += buffer[i];\n    }\n\n    // Convert sum to binary string\n    std::string binary = std::bitset<32>(sum).to_string();\n\n    // Remove leading zeros\n    size_t first_one = binary.find('1');\n    return first_one != std::string::npos ? binary.substr(first_one) : \"0\";\n}\n```"}
{"task_id": "SimdBench_104_SSE", "completion": "```cpp\nint add_simd(std::vector<int> lst) {\n    int result = 0;\n    int n = lst.size();\n    __m128i vsum = _mm_setzero_si128();\n\n    for (int i = 1; i < n; i += 4) {\n        __m128i v = _mm_loadu_si128((__m128i*)&lst[i]);\n        __m128i indices = _mm_set_epi32(i + 3, i + 2, i + 1, i);\n        __m128i odd_mask = _mm_and_si128(indices, _mm_set1_epi32(1));\n        __m128i even_mask = _mm_cmpeq_epi32(_mm_and_si128(v, _mm_set1_epi32(1)), _mm_setzero_si128());\n        __m128i mask = _mm_and_si128(odd_mask, even_mask);\n\n        __m128i masked_values = _mm_and_si128(v, mask);\n        vsum = _mm_add_epi32(vsum, masked_values);\n    }\n\n    int temp[4];\n    _mm_storeu_si128((__m128i*)temp, vsum);\n    result = temp[0] + temp[1] + temp[2] + temp[3];\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_104_SSE", "completion": "```cpp\nint add_simd(std::vector<int> lst) {\n    int result = 0;\n    int n = lst.size();\n    __m128i vsum = _mm_setzero_si128();\n\n    for (int i = 1; i < n; i += 4) {\n        // Load 4 integers from the vector starting at index i\n        __m128i v = _mm_loadu_si128((__m128i*)&lst[i]);\n\n        // Create a mask to identify even numbers (lowest bit is 0)\n        __m128i even_mask = _mm_and_si128(v, _mm_set1_epi32(1));\n        even_mask = _mm_cmpeq_epi32(even_mask, _mm_setzero_si128());\n\n        // Create a mask to identify odd indices (i.e., elements at positions 1, 3, etc.)\n        __m128i index_mask = _mm_set_epi32(\n            (i + 3) % 2 == 0 ? 0 : -1,\n            (i + 2) % 2 == 0 ? 0 : -1,\n            (i + 1) % 2 == 0 ? 0 : -1,\n            i % 2 == 0 ? 0 : -1\n        );\n\n        // Combine masks: only consider even numbers at odd indices\n        __m128i combined_mask = _mm_and_si128(even_mask, index_mask);\n\n        // Use the combined mask to zero out unwanted elements\n        __m128i masked_values = _mm_and_si128(v, combined_mask);\n\n        // Add the valid values to the sum vector\n        vsum = _mm_add_epi32(vsum, masked_values);\n    }\n\n    // Horizontal sum of the elements in vsum\n    int temp[4];\n    _mm_storeu_si128((__m128i*)temp, vsum);\n    result = temp[0] + temp[1] + temp[2] + temp[3];\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_104_SSE", "completion": "```cpp\nint add_simd(std::vector<int> lst) {\n    int result = 0;\n    int n = lst.size();\n    __m128i sum_vec = _mm_setzero_si128();\n\n    for (int i = 1; i < n; i += 4) {\n        // Load 4 integers from the vector into a SIMD register\n        __m128i vec = _mm_loadu_si128((__m128i*)&lst[i]);\n\n        // Create a mask to identify even numbers (lowest bit is 0)\n        __m128i even_mask = _mm_andnot_si128(_mm_set1_epi32(1), vec);\n\n        // Compare to check which elements are even\n        __m128i is_even = _mm_cmpeq_epi32(even_mask, vec);\n\n        // Mask out elements that are not at odd indices\n        __m128i index_mask = _mm_set_epi32(\n            (i + 3) % 2 == 0 ? 0 : -1,\n            (i + 2) % 2 == 0 ? 0 : -1,\n            (i + 1) % 2 == 0 ? 0 : -1,\n            i % 2 == 0 ? 0 : -1\n        );\n        is_even = _mm_and_si128(is_even, index_mask);\n\n        // Blend the original vector with zeros based on the mask\n        __m128i masked_values = _mm_and_si128(vec, is_even);\n\n        // Add the valid values to the sum vector\n        sum_vec = _mm_add_epi32(sum_vec, masked_values);\n    }\n\n    // Horizontal sum of the elements in the sum_vec\n    int temp[4];\n    _mm_storeu_si128((__m128i*)temp, sum_vec);\n    result = temp[0] + temp[1] + temp[2] + temp[3];\n\n    // Handle any remaining elements\n    for (int i = (n / 4) * 4 + 1; i < n; i += 2) {\n        if (lst[i] % 2 == 0) {\n            result += lst[i];\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_104_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint add_simd(std::vector<int> lst) {\n    int result = 0;\n    int n = lst.size();\n    int aligned_n = n - (n % 4);\n\n    __m128i vsum = _mm_setzero_si128();\n\n    for (int i = 1; i < aligned_n; i += 4) {\n        __m128i v = _mm_loadu_si128((__m128i*)&lst[i]);\n\n        // Create a mask for odd indices: 0xFFFF for odd, 0x0000 for even\n        __m128i index_mask = _mm_set_epi32((i + 3) % 2 ? 0xFFFFFFFF : 0, \n                                           (i + 2) % 2 ? 0xFFFFFFFF : 0, \n                                           (i + 1) % 2 ? 0xFFFFFFFF : 0, \n                                           i % 2 ? 0xFFFFFFFF : 0);\n        v = _mm_and_si128(v, index_mask);\n\n        // Check for even values\n        __m128i even_mask = _mm_and_si128(v, _mm_set1_epi32(1));\n        even_mask = _mm_cmpeq_epi32(even_mask, _mm_setzero_si128());\n\n        // Mask out non-even values\n        v = _mm_and_si128(v, even_mask);\n\n        // Add to the sum vector\n        vsum = _mm_add_epi32(vsum, v);\n    }\n\n    // Horizontal sum of vsum\n    int temp[4];\n    _mm_storeu_si128((__m128i*)temp, vsum);\n    result += temp[0] + temp[1] + temp[2] + temp[3];\n\n    // Handle remaining elements\n    for (int i = aligned_n; i < n; ++i) {\n        if (i % 2 == 1 && lst[i] % 2 == 0) {\n            result += lst[i];\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_104_SSE", "completion": "```cpp\nint add_simd(std::vector<int> lst) {\n    int result = 0;\n    int n = lst.size();\n    __m128i vsum = _mm_setzero_si128();\n\n    for (int i = 1; i < n; i += 4) {\n        __m128i v = _mm_loadu_si128((__m128i*)&lst[i]);\n        __m128i indices = _mm_set_epi32(i + 3, i + 2, i + 1, i);\n        __m128i odd_mask = _mm_and_si128(indices, _mm_set1_epi32(1));\n        __m128i even_mask = _mm_cmpeq_epi32(_mm_and_si128(v, _mm_set1_epi32(1)), _mm_setzero_si128());\n        __m128i mask = _mm_and_si128(odd_mask, even_mask);\n\n        __m128i masked_values = _mm_and_si128(v, mask);\n        vsum = _mm_add_epi32(vsum, masked_values);\n    }\n\n    int temp[4];\n    _mm_storeu_si128((__m128i*)temp, vsum);\n    result = temp[0] + temp[1] + temp[2] + temp[3];\n\n    // Handle remaining elements if any\n    for (int i = (n / 4) * 4 + 1; i < n; i += 2) {\n        if (lst[i] % 2 == 0) {\n            result += lst[i];\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_105_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string encrypt_simd(const std::string & s) {\n    std::string result(s.size(), '\\0');\n    size_t i = 0;\n\n    // Process 16 characters at a time using SSE2 intrinsics\n    for (; i + 15 < s.size(); i += 16) {\n        // Load 16 characters into an SSE register\n        __m128i input = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&s[i]));\n\n        // Create a mask to identify alphabetic characters (a-z and A-Z)\n        __m128i lower_a = _mm_set1_epi8('a');\n        __m128i upper_z = _mm_set1_epi8('z');\n        __m128i lower_A = _mm_set1_epi8('A');\n        __m128i upper_Z = _mm_set1_epi8('Z');\n\n        __m128i is_lower = _mm_and_si128(_mm_cmpgt_epi8(input, lower_a), _mm_cmplt_epi8(input, upper_z));\n        __m128i is_upper = _mm_and_si128(_mm_cmpgt_epi8(input, lower_A), _mm_cmplt_epi8(input, upper_Z));\n\n        // Combine the masks\n        __m128i is_alpha = _mm_or_si128(is_lower, is_upper);\n\n        // Compute the rotation offset (2 * 2 = 4)\n        __m128i offset = _mm_set1_epi8(4);\n\n        // Apply the rotation only to alphabetic characters\n        __m128i rotated = _mm_add_epi8(input, offset);\n\n        // Handle wrap-around for lowercase letters\n        __m128i wrap_lower = _mm_cmpgt_epi8(rotated, upper_z);\n        rotated = _mm_sub_epi8(rotated, _mm_and_si128(wrap_lower, _mm_set1_epi8(26)));\n\n        // Handle wrap-around for uppercase letters\n        __m128i wrap_upper = _mm_cmpgt_epi8(rotated, upper_Z);\n        rotated = _mm_sub_epi8(rotated, _mm_and_si128(wrap_upper, _mm_set1_epi8(26)));\n\n        // Blend rotated characters with non-alphabetic characters\n        __m128i output = _mm_blendv_epi8(input, rotated, is_alpha);\n\n        // Store the result back to memory\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i]), output);\n    }\n\n    // Process remaining characters (if any) using scalar code\n    for (; i < s.size(); ++i) {\n        char c = s[i];\n        if ('a' <= c && c <= 'z') {\n            c = (c - 'a' + 4) % 26 + 'a';\n        } else if ('A' <= c && c <= 'Z') {\n            c = (c - 'A' + 4) % 26 + 'A';\n        }\n        result[i] = c;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_105_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string encrypt_simd(const std::string & s) {\n    std::string result(s.size(), '\\0');\n    size_t i = 0;\n\n    // Process 16 characters at a time using SSE2 intrinsics\n    for (; i + 15 < s.size(); i += 16) {\n        // Load 16 characters into an SSE register\n        __m128i input = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&s[i]));\n\n        // Create a mask to identify alphabetic characters (a-z and A-Z)\n        __m128i lower_a = _mm_set1_epi8('a');\n        __m128i upper_z = _mm_set1_epi8('z');\n        __m128i lower_A = _mm_set1_epi8('A');\n        __m128i upper_Z = _mm_set1_epi8('Z');\n\n        __m128i is_lower = _mm_and_si128(_mm_cmpgt_epi8(input, lower_a), _mm_cmplt_epi8(input, upper_z));\n        __m128i is_upper = _mm_and_si128(_mm_cmpgt_epi8(input, lower_A), _mm_cmplt_epi8(input, upper_Z));\n        __m128i is_alpha = _mm_or_si128(is_lower, is_upper);\n\n        // Compute the shift (2 * 2 = 4 places)\n        __m128i shift = _mm_set1_epi8(4);\n\n        // Apply the shift to alphabetic characters\n        __m128i shifted = _mm_add_epi8(input, shift);\n\n        // Wrap around for lowercase letters\n        __m128i wrap_lower = _mm_cmpgt_epi8(shifted, upper_z);\n        shifted = _mm_sub_epi8(shifted, _mm_and_si128(wrap_lower, _mm_set1_epi8(26)));\n\n        // Wrap around for uppercase letters\n        __m128i wrap_upper = _mm_cmpgt_epi8(shifted, upper_Z);\n        shifted = _mm_sub_epi8(shifted, _mm_and_si128(wrap_upper, _mm_set1_epi8(26)));\n\n        // Blend shifted characters with non-alphabetic characters\n        __m128i output = _mm_blendv_epi8(input, shifted, is_alpha);\n\n        // Store the result back into the output string\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i]), output);\n    }\n\n    // Process remaining characters (if any) using scalar code\n    for (; i < s.size(); ++i) {\n        char c = s[i];\n        if ('a' <= c && c <= 'z') {\n            c = (c - 'a' + 4) % 26 + 'a';\n        } else if ('A' <= c && c <= 'Z') {\n            c = (c - 'A' + 4) % 26 + 'A';\n        }\n        result[i] = c;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_105_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string encrypt_simd(const std::string & s) {\n    std::string result(s.size(), 0);\n    int len = s.size();\n    int i = 0;\n\n    // Process 16 characters at a time using SSE2\n    for (; i + 16 <= len; i += 16) {\n        __m128i input = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&s[i]));\n\n        // Create a mask to identify lowercase letters ('a' to 'z')\n        __m128i lower_a = _mm_set1_epi8('a');\n        __m128i lower_z = _mm_set1_epi8('z');\n        __m128i is_lower = _mm_and_si128(_mm_cmpgt_epi8(input, lower_a - 1), _mm_cmplt_epi8(input, lower_z + 1));\n\n        // Create a mask to identify uppercase letters ('A' to 'Z')\n        __m128i upper_a = _mm_set1_epi8('A');\n        __m128i upper_z = _mm_set1_epi8('Z');\n        __m128i is_upper = _mm_and_si128(_mm_cmpgt_epi8(input, upper_a - 1), _mm_cmplt_epi8(input, upper_z + 1));\n\n        // Compute the shift (2 * 2 = 4 places)\n        __m128i shift = _mm_set1_epi8(4);\n\n        // Apply the shift to lowercase letters\n        __m128i shifted_lower = _mm_add_epi8(input, shift);\n        shifted_lower = _mm_sub_epi8(shifted_lower, _mm_and_si128(is_lower, _mm_set1_epi8(26)));\n\n        // Apply the shift to uppercase letters\n        __m128i shifted_upper = _mm_add_epi8(input, shift);\n        shifted_upper = _mm_sub_epi8(shifted_upper, _mm_and_si128(is_upper, _mm_set1_epi8(26)));\n\n        // Combine results based on letter case\n        __m128i output = _mm_blendv_epi8(input, shifted_lower, is_lower);\n        output = _mm_blendv_epi8(output, shifted_upper, is_upper);\n\n        // Store the result back to the output string\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i]), output);\n    }\n\n    // Process remaining characters (if any)\n    for (; i < len; ++i) {\n        char c = s[i];\n        if (c >= 'a' && c <= 'z') {\n            c = 'a' + (c - 'a' + 4) % 26;\n        } else if (c >= 'A' && c <= 'Z') {\n            c = 'A' + (c - 'A' + 4) % 26;\n        }\n        result[i] = c;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_105_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string encrypt_simd(const std::string & s) {\n    std::string result(s.size(), '\\0');\n    int len = s.size();\n    int i = 0;\n\n    // Process 16 characters at a time using SSE2 intrinsics\n    for (; i + 15 < len; i += 16) {\n        __m128i input = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&s[i]));\n\n        // Create a mask to identify alphabetic characters\n        __m128i lower_a = _mm_set1_epi8('a');\n        __m128i upper_a = _mm_set1_epi8('A');\n        __m128i lower_z = _mm_set1_epi8('z');\n        __m128i upper_z = _mm_set1_epi8('Z');\n\n        __m128i is_lower = _mm_and_si128(_mm_cmpgt_epi8(input, lower_a), _mm_cmplt_epi8(input, lower_z));\n        __m128i is_upper = _mm_and_si128(_mm_cmpgt_epi8(input, upper_a), _mm_cmplt_epi8(input, upper_z));\n\n        // Compute the shift (2 * 2 = 4)\n        __m128i shift = _mm_set1_epi8(4);\n\n        // Apply the shift to lowercase and uppercase letters separately\n        __m128i shifted = _mm_add_epi8(input, shift);\n        __m128i wrapped_lower = _mm_sub_epi8(shifted, _mm_set1_epi8(26));\n        __m128i wrapped_upper = _mm_sub_epi8(shifted, _mm_set1_epi8(26));\n\n        // Wrap around for lowercase letters\n        __m128i lower_overflow = _mm_cmpgt_epi8(shifted, lower_z);\n        shifted = _mm_blendv_epi8(shifted, wrapped_lower, lower_overflow);\n\n        // Wrap around for uppercase letters\n        __m128i upper_overflow = _mm_cmpgt_epi8(shifted, upper_z);\n        shifted = _mm_blendv_epi8(shifted, wrapped_upper, upper_overflow);\n\n        // Combine results based on character type\n        __m128i mask = _mm_or_si128(is_lower, is_upper);\n        shifted = _mm_blendv_epi8(input, shifted, mask);\n\n        // Store the result back into the output string\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i]), shifted);\n    }\n\n    // Process remaining characters (if any) using scalar code\n    for (; i < len; ++i) {\n        char c = s[i];\n        if ('a' <= c && c <= 'z') {\n            c = (c - 'a' + 4) % 26 + 'a';\n        } else if ('A' <= c && c <= 'Z') {\n            c = (c - 'A' + 4) % 26 + 'A';\n        }\n        result[i] = c;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_105_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string encrypt_simd(const std::string & s) {\n    std::string result(s.size(), '\\0');\n    size_t i = 0;\n\n    // Process 16 characters at a time using SSE2 intrinsics\n    for (; i + 15 < s.size(); i += 16) {\n        // Load 16 characters into an SSE register\n        __m128i input = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&s[i]));\n\n        // Create a mask to identify alphabetic characters (a-z and A-Z)\n        __m128i lower_a = _mm_set1_epi8('a');\n        __m128i upper_z = _mm_set1_epi8('z');\n        __m128i lower_A = _mm_set1_epi8('A');\n        __m128i upper_Z = _mm_set1_epi8('Z');\n\n        __m128i is_lower = _mm_and_si128(_mm_cmpgt_epi8(input, lower_a), _mm_cmplt_epi8(input, upper_z));\n        __m128i is_upper = _mm_and_si128(_mm_cmpgt_epi8(input, lower_A), _mm_cmplt_epi8(input, upper_Z));\n        __m128i is_alpha = _mm_or_si128(is_lower, is_upper);\n\n        // Compute the shift (2 * 2 = 4 places)\n        __m128i shift = _mm_set1_epi8(4);\n\n        // Apply the shift only to alphabetic characters\n        __m128i shifted = _mm_add_epi8(input, _mm_and_si128(shift, is_alpha));\n\n        // Handle wrap-around for lowercase letters\n        __m128i wrap_lower = _mm_cmpgt_epi8(shifted, upper_z);\n        shifted = _mm_sub_epi8(shifted, _mm_and_si128(_mm_set1_epi8(26), wrap_lower));\n\n        // Handle wrap-around for uppercase letters\n        __m128i wrap_upper = _mm_cmpgt_epi8(shifted, upper_Z);\n        shifted = _mm_sub_epi8(shifted, _mm_and_si128(_mm_set1_epi8(26), wrap_upper));\n\n        // Store the result back into the output string\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i]), shifted);\n    }\n\n    // Process remaining characters (if any) using scalar code\n    for (; i < s.size(); ++i) {\n        char c = s[i];\n        if ('a' <= c && c <= 'z') {\n            c = 'a' + (c - 'a' + 4) % 26;\n        } else if ('A' <= c && c <= 'Z') {\n            c = 'A' + (c - 'A' + 4) % 26;\n        }\n        result[i] = c;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_106_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string encode_simd(const std::string & message) {\n    std::string result(message.size(), 0);\n    size_t i = 0;\n\n    // Define constants for vowels and case swapping\n    const __m128i vowel_mask_low = _mm_setr_epi8('a', 'e', 'i', 'o', 'u', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n    const __m128i vowel_mask_up = _mm_setr_epi8('A', 'E', 'I', 'O', 'U', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n    const __m128i case_swap_mask = _mm_set1_epi8(0x20);\n\n    for (; i + 15 < message.size(); i += 16) {\n        // Load 16 characters into SIMD register\n        __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&message[i]));\n\n        // Swap case\n        __m128i is_lower = _mm_cmplt_epi8(chunk, _mm_set1_epi8('a'));\n        __m128i is_upper = _mm_cmpgt_epi8(chunk, _mm_set1_epi8('Z'));\n        __m128i needs_case_swap = _mm_andnot_si128(is_lower, _mm_andnot_si128(is_upper, _mm_set1_epi8(0xFF)));\n        __m128i swapped_case = _mm_xor_si128(chunk, _mm_and_si128(needs_case_swap, case_swap_mask));\n\n        // Replace vowels with letters 2 places ahead\n        __m128i is_vowel_low = _mm_cmpeq_epi8(swapped_case, vowel_mask_low);\n        __m128i is_vowel_up = _mm_cmpeq_epi8(swapped_case, vowel_mask_up);\n        __m128i is_vowel = _mm_or_si128(is_vowel_low, is_vowel_up);\n\n        __m128i vowel_replacement = _mm_add_epi8(swapped_case, _mm_and_si128(is_vowel, _mm_set1_epi8(2)));\n        __m128i final_chunk = _mm_blendv_epi8(swapped_case, vowel_replacement, is_vowel);\n\n        // Store the result back to memory\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i]), final_chunk);\n    }\n\n    // Handle remaining characters\n    for (; i < message.size(); ++i) {\n        char c = message[i];\n        if ((c >= 'a' && c <= 'z') || (c >= 'A' && c <= 'Z')) {\n            c ^= 0x20; // Swap case\n            if (c == 'a' || c == 'e' || c == 'i' || c == 'o' || c == 'u' ||\n                c == 'A' || c == 'E' || c == 'I' || c == 'O' || c == 'U') {\n                c += 2; // Replace vowel\n            }\n        }\n        result[i] = c;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_106_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string encode_simd(const std::string & message) {\n    std::string result(message.size(), 0);\n    size_t i = 0;\n\n    // Constants for SIMD operations\n    const __m128i mask_case_swap = _mm_set1_epi8(0x20); // Mask to swap case\n    const __m128i vowels_lower = _mm_setr_epi8('a', 'e', 'i', 'o', 'u', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n    const __m128i vowels_upper = _mm_setr_epi8('A', 'E', 'I', 'O', 'U', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n    const __m128i replace_lower = _mm_setr_epi8('c', 'g', 'k', 'q', 'w', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n    const __m128i replace_upper = _mm_setr_epi8('C', 'G', 'K', 'Q', 'W', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n\n    for (; i + 15 < message.size(); i += 16) {\n        // Load 16 characters into SIMD register\n        __m128i data = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&message[i]));\n\n        // Swap case\n        __m128i is_alpha = _mm_cmplt_epi8(data, _mm_set1_epi8(0x80)); // Check if ASCII\n        __m128i is_lower = _mm_and_si128(is_alpha, _mm_cmpgt_epi8(data, _mm_set1_epi8('a' - 1)));\n        __m128i is_upper = _mm_and_si128(is_alpha, _mm_cmpgt_epi8(data, _mm_set1_epi8('A' - 1)));\n        __m128i case_swapped = _mm_xor_si128(data, _mm_and_si128(mask_case_swap, _mm_or_si128(is_lower, is_upper)));\n\n        // Replace vowels\n        __m128i is_vowel_lower = _mm_cmpeq_epi8(case_swapped, vowels_lower);\n        __m128i is_vowel_upper = _mm_cmpeq_epi8(case_swapped, vowels_upper);\n        __m128i replace_mask = _mm_or_si128(is_vowel_lower, is_vowel_upper);\n        __m128i replacement = _mm_blendv_epi8(case_swapped, _mm_blendv_epi8(replace_lower, replace_upper, is_vowel_upper), replace_mask);\n\n        // Store the result back\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i]), replacement);\n    }\n\n    // Handle remaining characters\n    for (; i < message.size(); ++i) {\n        char c = message[i];\n        if (c >= 'a' && c <= 'z') {\n            c ^= 0x20; // Swap case\n            if (c == 'A' || c == 'E' || c == 'I' || c == 'O' || c == 'U') {\n                c += 2; // Replace vowel\n            }\n        } else if (c >= 'A' && c <= 'Z') {\n            c ^= 0x20; // Swap case\n            if (c == 'a' || c == 'e' || c == 'i' || c == 'o' || c == 'u') {\n                c += 2; // Replace vowel\n            }\n        }\n        result[i] = c;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_106_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string encode_simd(const std::string & message) {\n    std::string result(message.size(), 0);\n    size_t i = 0;\n\n    // Constants for SIMD operations\n    const __m128i mask_lower_to_upper = _mm_set1_epi8(0xDF); // Mask to convert lowercase to uppercase (clear bit 5)\n    const __m128i mask_upper_to_lower = _mm_set1_epi8(0x20); // Mask to convert uppercase to lowercase (set bit 5)\n    const __m128i vowels_lower = _mm_setr_epi8('a', 'e', 'i', 'o', 'u', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n    const __m128i vowels_upper = _mm_setr_epi8('A', 'E', 'I', 'O', 'U', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n    const __m128i replace_lower = _mm_setr_epi8('c', 'g', 'k', 'q', 'w', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n    const __m128i replace_upper = _mm_setr_epi8('C', 'G', 'K', 'Q', 'W', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n\n    for (; i + 15 < message.size(); i += 16) {\n        // Load 16 characters into SIMD register\n        __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&message[i]));\n\n        // Determine case (lowercase or uppercase)\n        __m128i is_lower = _mm_cmplt_epi8(chunk, _mm_set1_epi8('a')); // Compare if < 'a'\n        __m128i is_upper = _mm_cmpgt_epi8(chunk, _mm_set1_epi8('Z')); // Compare if > 'Z'\n\n        // Swap case\n        __m128i swapped_case = _mm_xor_si128(chunk, mask_upper_to_lower); // Toggle case bit\n\n        // Replace vowels\n        __m128i is_vowel_lower = _mm_cmpeq_epi8(chunk, vowels_lower); // Compare with lowercase vowels\n        __m128i is_vowel_upper = _mm_cmpeq_epi8(chunk, vowels_upper); // Compare with uppercase vowels\n        __m128i is_vowel = _mm_or_si128(is_vowel_lower, is_vowel_upper); // Combine vowel checks\n\n        __m128i replaced = _mm_blendv_epi8(swapped_case, replace_lower, is_vowel_lower); // Replace lowercase vowels\n        replaced = _mm_blendv_epi8(replaced, replace_upper, is_vowel_upper); // Replace uppercase vowels\n\n        // Store the result back into the output string\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i]), replaced);\n    }\n\n    // Handle remaining characters\n    for (; i < message.size(); ++i) {\n        char c = message[i];\n        if (c >= 'a' && c <= 'z') {\n            c ^= 0x20; // Convert to uppercase\n            if (c == 'A' || c == 'E' || c == 'I' || c == 'O' || c == 'U') {\n                c += 2; // Replace vowel\n            }\n        } else if (c >= 'A' && c <= 'Z') {\n            c ^= 0x20; // Convert to lowercase\n            if (c == 'a' || c == 'e' || c == 'i' || c == 'o' || c == 'u') {\n                c += 2; // Replace vowel\n            }\n        }\n        result[i] = c;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_106_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string encode_simd(const std::string & message) {\n    std::string result(message.size(), '\\0');\n    size_t i = 0;\n\n    // Define vowels and their replacements\n    const __m128i vowels_lower = _mm_setr_epi8('a', 'e', 'i', 'o', 'u', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n    const __m128i vowels_upper = _mm_setr_epi8('A', 'E', 'I', 'O', 'U', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n    const __m128i replace_lower = _mm_setr_epi8('c', 'g', 'k', 'q', 'w', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n    const __m128i replace_upper = _mm_setr_epi8('C', 'G', 'K', 'Q', 'W', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n\n    for (; i + 15 < message.size(); i += 16) {\n        // Load 16 characters into SIMD register\n        __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&message[i]));\n\n        // Swap case: XOR with space (32) if alpha\n        __m128i is_alpha = _mm_cmpeq_epi8(_mm_and_si128(chunk, _mm_set1_epi8(0xC0)), _mm_set1_epi8(0x40));\n        __m128i swapped_case = _mm_xor_si128(chunk, _mm_and_si128(is_alpha, _mm_set1_epi8(32)));\n\n        // Replace vowels\n        __m128i is_vowel_lower = _mm_cmpeq_epi8(swapped_case, vowels_lower);\n        __m128i is_vowel_upper = _mm_cmpeq_epi8(swapped_case, vowels_upper);\n        __m128i is_vowel = _mm_or_si128(is_vowel_lower, is_vowel_upper);\n\n        __m128i replacement = _mm_blendv_epi8(swapped_case, _mm_blendv_epi8(replace_lower, replace_upper, is_vowel_upper), is_vowel);\n\n        // Store the result back\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i]), replacement);\n    }\n\n    // Handle remaining characters\n    for (; i < message.size(); ++i) {\n        char c = message[i];\n        if ((c >= 'a' && c <= 'z') || (c >= 'A' && c <= 'Z')) {\n            c ^= 32; // Swap case\n            if (c == 'a' || c == 'e' || c == 'i' || c == 'o' || c == 'u' ||\n                c == 'A' || c == 'E' || c == 'I' || c == 'O' || c == 'U') {\n                c += 2; // Replace vowel\n            }\n        }\n        result[i] = c;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_106_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n\nstd::string encode_simd(const std::string &message) {\n    // Result string to store the encoded message\n    std::string result;\n    result.reserve(message.size());\n\n    // Constants for SIMD operations\n    const __m128i mask_case_swap = _mm_set1_epi8(0x20); // Mask to swap case (bit 5)\n    const __m128i vowels_lower = _mm_setr_epi8('a', 'e', 'i', 'o', 'u', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n    const __m128i vowels_upper = _mm_setr_epi8('A', 'E', 'I', 'O', 'U', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n    const __m128i replace_lower = _mm_setr_epi8('c', 'g', 'k', 'q', 'w', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n    const __m128i replace_upper = _mm_setr_epi8('C', 'G', 'K', 'Q', 'W', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n\n    // Process the input string in chunks of 16 bytes\n    size_t i = 0;\n    while (i + 16 <= message.size()) {\n        // Load 16 characters into an SSE register\n        __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&message[i]));\n\n        // Swap case by flipping the 5th bit\n        __m128i swapped_case = _mm_xor_si128(chunk, mask_case_swap);\n\n        // Check for lowercase vowels and replace them\n        __m128i is_vowel_lower = _mm_cmpeq_epi8(chunk, vowels_lower);\n        __m128i replaced_lower = _mm_blendv_epi8(swapped_case, replace_lower, is_vowel_lower);\n\n        // Check for uppercase vowels and replace them\n        __m128i is_vowel_upper = _mm_cmpeq_epi8(chunk, vowels_upper);\n        __m128i replaced_upper = _mm_blendv_epi8(replaced_lower, replace_upper, is_vowel_upper);\n\n        // Store the result back into the output string\n        char temp[16];\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(temp), replaced_upper);\n        result.append(temp, 16);\n\n        i += 16;\n    }\n\n    // Process remaining characters (if any) using scalar code\n    for (; i < message.size(); ++i) {\n        char c = message[i];\n        if (c == 'a' || c == 'e' || c == 'i' || c == 'o' || c == 'u') {\n            c = c + 2;\n        } else if (c == 'A' || c == 'E' || c == 'I' || c == 'O' || c == 'U') {\n            c = c + 2;\n        } else {\n            c ^= 0x20; // Swap case\n        }\n        result.push_back(c);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_107_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <map>\n#include <string>\n\nbool check_dict_case_simd(std::map<std::string, std::string> dict) {\n    if (dict.empty()) return false;\n\n    __m128i all_lower = _mm_set1_epi8(0xFF);\n    __m128i all_upper = _mm_set1_epi8(0xFF);\n    bool first_key = true;\n    bool is_lower = false;\n\n    for (const auto& pair : dict) {\n        const std::string& key = pair.first;\n        size_t len = key.size();\n\n        for (size_t i = 0; i < len; i += 16) {\n            __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(key.c_str() + i));\n            __m128i lower_mask = _mm_cmplt_epi8(chunk, _mm_set1_epi8('a'));\n            __m128i upper_mask = _mm_cmpgt_epi8(chunk, _mm_set1_epi8('Z'));\n\n            __m128i valid_lower = _mm_andnot_si128(lower_mask, _mm_cmplt_epi8(chunk, _mm_set1_epi8('{')));\n            __m128i valid_upper = _mm_andnot_si128(upper_mask, _mm_cmpgt_epi8(chunk, _mm_set1_epi8('@')));\n\n            if (first_key) {\n                all_lower = valid_lower;\n                all_upper = valid_upper;\n                is_lower = _mm_movemask_epi8(valid_lower) != 0;\n                first_key = false;\n            } else {\n                if (is_lower) {\n                    all_lower = _mm_and_si128(all_lower, valid_lower);\n                } else {\n                    all_upper = _mm_and_si128(all_upper, valid_upper);\n                }\n            }\n        }\n    }\n\n    int lower_result = _mm_movemask_epi8(all_lower);\n    int upper_result = _mm_movemask_epi8(all_upper);\n\n    return (lower_result == 0xFFFF || upper_result == 0xFFFF);\n}\n```"}
{"task_id": "SimdBench_107_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <map>\n#include <string>\n\nbool check_dict_case_simd(std::map<std::string, std::string> dict) {\n    if (dict.empty()) return false;\n\n    __m128i lower_mask = _mm_set1_epi8(0x20); // Mask for checking lowercase\n    __m128i upper_mask = _mm_set1_epi8(0x00); // Mask for checking uppercase\n    bool all_lower = true, all_upper = true;\n\n    for (const auto& pair : dict) {\n        const std::string& key = pair.first;\n        int len = key.length();\n\n        for (int i = 0; i < len; i += 16) {\n            __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(key.c_str() + i));\n            __m128i lower_check = _mm_and_si128(chunk, lower_mask);\n            __m128i upper_check = _mm_cmpeq_epi8(chunk, upper_mask);\n\n            int lower_mask_result = _mm_movemask_epi8(_mm_cmpeq_epi8(lower_check, lower_mask));\n            int upper_mask_result = _mm_movemask_epi8(upper_check);\n\n            if (lower_mask_result != 0xFFFF) all_lower = false;\n            if (upper_mask_result != 0xFFFF) all_upper = false;\n\n            if (!all_lower && !all_upper) return false;\n        }\n    }\n\n    return all_lower || all_upper;\n}\n```"}
{"task_id": "SimdBench_107_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <map>\n#include <string>\n\nbool check_dict_case_simd(std::map<std::string, std::string> dict) {\n    if (dict.empty()) return false;\n\n    __m128i lower_mask = _mm_set1_epi8(0x20); // Mask for checking lowercase\n    __m128i upper_mask = _mm_set1_epi8(0x00); // Mask for checking uppercase\n    bool all_lower = true, all_upper = true;\n\n    for (const auto& pair : dict) {\n        const std::string& key = pair.first;\n        int len = key.length();\n\n        for (int i = 0; i < len; i += 16) {\n            __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(key.c_str() + i));\n            __m128i lower_check = _mm_and_si128(chunk, lower_mask);\n            __m128i upper_check = _mm_cmpeq_epi8(chunk, upper_mask);\n\n            int lower_mask_result = _mm_movemask_epi8(lower_check);\n            int upper_mask_result = _mm_movemask_epi8(upper_check);\n\n            if (lower_mask_result != 0xFFFF) all_lower = false;\n            if (upper_mask_result != 0xFFFF) all_upper = false;\n\n            if (!all_lower && !all_upper) return false;\n        }\n    }\n\n    return all_lower || all_upper;\n}\n```"}
{"task_id": "SimdBench_107_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <map>\n#include <string>\n\nbool check_dict_case_simd(std::map<std::string, std::string> dict) {\n    if (dict.empty()) return false;\n\n    __m128i lower_mask = _mm_set1_epi8(0x20); // Mask for checking lowercase\n    __m128i upper_mask = _mm_set1_epi8(0x00); // Mask for checking uppercase\n    bool all_lower = true, all_upper = true;\n\n    for (const auto& pair : dict) {\n        const std::string& key = pair.first;\n        int len = key.length();\n\n        for (int i = 0; i < len; i += 16) {\n            __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(key.c_str() + i));\n            __m128i lower_check = _mm_and_si128(chunk, lower_mask);\n            __m128i upper_check = _mm_cmpeq_epi8(chunk, upper_mask);\n\n            int lower_mask_result = _mm_movemask_epi8(lower_check);\n            int upper_mask_result = _mm_movemask_epi8(upper_check);\n\n            if (lower_mask_result != 0xFFFF) all_lower = false;\n            if (upper_mask_result != 0xFFFF) all_upper = false;\n\n            if (!all_lower && !all_upper) return false;\n        }\n    }\n\n    return all_lower || all_upper;\n}\n```"}
{"task_id": "SimdBench_107_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <map>\n#include <string>\n\nbool check_dict_case_simd(std::map<std::string, std::string> dict) {\n    if (dict.empty()) return false;\n\n    __m128i lower_mask = _mm_set1_epi8(0x20); // Mask to check for lowercase\n    __m128i upper_mask = _mm_set1_epi8(0x00); // Mask to check for uppercase\n    bool all_lower = true, all_upper = true;\n\n    for (const auto& pair : dict) {\n        const std::string& key = pair.first;\n        int len = key.length();\n\n        for (int i = 0; i < len; i += 16) {\n            __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(key.c_str() + i));\n            __m128i lower_check = _mm_and_si128(chunk, lower_mask);\n            __m128i upper_check = _mm_cmpeq_epi8(lower_check, upper_mask);\n\n            int lower_mask_result = _mm_movemask_epi8(_mm_cmpeq_epi8(lower_check, lower_mask));\n            int upper_mask_result = _mm_movemask_epi8(upper_check);\n\n            if ((lower_mask_result != 0xFFFF) && (upper_mask_result != 0xFFFF)) {\n                return false;\n            }\n\n            all_lower &= (lower_mask_result == 0xFFFF);\n            all_upper &= (upper_mask_result == 0xFFFF);\n        }\n    }\n\n    return all_lower || all_upper;\n}\n```"}
{"task_id": "SimdBench_108_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> count_up_to_simd(int n) {\n    std::vector<int> primes;\n    if (n <= 2) return primes;\n\n    // Add 2 as the first prime number\n    primes.push_back(2);\n\n    // Prepare a vector of integers to test for primality\n    std::vector<int> candidates;\n    for (int i = 3; i < n; i += 2) {\n        candidates.push_back(i);\n    }\n\n    int num_candidates = candidates.size();\n    int simd_size = 4; // SSE/SSE2 operates on 4 integers at a time\n\n    // Process candidates in chunks of 4 using SIMD\n    for (int i = 0; i < num_candidates; i += simd_size) {\n        __m128i vec = _mm_loadu_si128((__m128i*)&candidates[i]); // Load 4 integers\n        __m128i is_prime = _mm_set1_epi32(1); // Assume all are prime initially\n\n        // Test divisors up to sqrt(n)\n        for (int d = 3; d * d < n; d += 2) {\n            __m128i divisor = _mm_set1_epi32(d);\n            __m128i mod = _mm_rem_epi32(vec, divisor); // Compute modulo\n            __m128i not_divisible = _mm_cmpneq_epi32(mod, _mm_setzero_si128()); // Check non-zero remainder\n            is_prime = _mm_and_si128(is_prime, not_divisible); // Update primality\n        }\n\n        // Extract results from SIMD registers\n        int results[4];\n        _mm_storeu_si128((__m128i*)results, is_prime);\n\n        for (int j = 0; j < simd_size && i + j < num_candidates; ++j) {\n            if (results[j]) {\n                primes.push_back(candidates[i + j]);\n            }\n        }\n    }\n\n    return primes;\n}\n```"}
{"task_id": "SimdBench_108_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> count_up_to_simd(int n) {\n    std::vector<int> primes;\n    if (n <= 2) return primes;\n\n    // Add 2 as the first prime number\n    primes.push_back(2);\n\n    // Create a boolean array to mark non-prime numbers\n    int size = (n + 15) / 16 * 16; // Align to 16-byte boundary for SIMD\n    __m128i* sieve = (__m128i*)_mm_malloc(size / 8, 16);\n    _mm_store_si128(sieve, _mm_setzero_si128()); // Initialize to zero\n\n    // Mark even numbers as non-prime (except 2)\n    for (int i = 4; i < n; i += 2) {\n        int idx = i / 16;\n        int bit = i % 16;\n        __m128i mask = _mm_set1_epi8(1 << bit);\n        _mm_store_si128(&sieve[idx], _mm_or_si128(_mm_load_si128(&sieve[idx]), mask));\n    }\n\n    // Process odd numbers using SIMD\n    for (int p = 3; p * p < n; p += 2) {\n        int idx = p / 16;\n        int bit = p % 16;\n        __m128i mask = _mm_set1_epi8(1 << bit);\n        __m128i val = _mm_load_si128(&sieve[idx]);\n        if (_mm_testz_si128(val, mask)) { // Check if p is prime\n            for (int multiple = p * p; multiple < n; multiple += 2 * p) {\n                int m_idx = multiple / 16;\n                int m_bit = multiple % 16;\n                __m128i m_mask = _mm_set1_epi8(1 << m_bit);\n                _mm_store_si128(&sieve[m_idx], _mm_or_si128(_mm_load_si128(&sieve[m_idx]), m_mask));\n            }\n        }\n    }\n\n    // Collect remaining primes\n    for (int i = 3; i < n; i += 2) {\n        int idx = i / 16;\n        int bit = i % 16;\n        __m128i mask = _mm_set1_epi8(1 << bit);\n        __m128i val = _mm_load_si128(&sieve[idx]);\n        if (_mm_testz_si128(val, mask)) {\n            primes.push_back(i);\n        }\n    }\n\n    _mm_free(sieve);\n    return primes;\n}\n```"}
{"task_id": "SimdBench_108_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> count_up_to_simd(int n) {\n    std::vector<int> primes;\n    if (n <= 2) return primes;\n\n    // Allocate space for boolean array to mark non-prime numbers\n    int size = (n + 15) / 16 * 16; // Align to 16 bytes for SIMD operations\n    __m128i* sieve = (__m128i*)_mm_malloc(size / 16 * sizeof(__m128i), 16);\n    for (int i = 0; i < size / 16; ++i) {\n        sieve[i] = _mm_set1_epi32(-1); // Set all bits to 1 (true)\n    }\n\n    // Mark 0 and 1 as non-prime\n    _mm_maskmoveu_si128(_mm_set_epi32(0, 0, 0, 0), _mm_set_epi32(0, 0, 0, 0xF), (char*)sieve);\n\n    // Sieve of Eratosthenes using SIMD\n    for (int p = 2; p * p < n; ++p) {\n        if (_mm_movemask_epi8(sieve[p / 16]) & (1 << (p % 16))) {\n            __m128i mask = _mm_set1_epi32(p);\n            for (int multiple = p * p; multiple < n; multiple += p) {\n                __m128i index = _mm_set1_epi32(multiple / 16);\n                __m128i bit = _mm_set1_epi32(1 << (multiple % 16));\n                sieve[multiple / 16] = _mm_andnot_si128(bit, sieve[multiple / 16]);\n            }\n        }\n    }\n\n    // Collect prime numbers\n    for (int i = 2; i < n; ++i) {\n        if (_mm_movemask_epi8(sieve[i / 16]) & (1 << (i % 16))) {\n            primes.push_back(i);\n        }\n    }\n\n    _mm_free(sieve);\n    return primes;\n}\n```"}
{"task_id": "SimdBench_108_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> count_up_to_simd(int n) {\n    std::vector<int> primes;\n    if (n <= 2) return primes;\n\n    // Add 2 as the first prime number\n    primes.push_back(2);\n\n    // Prepare a vector of integers to test for primality\n    std::vector<int> candidates;\n    for (int i = 3; i < n; i += 2) {\n        candidates.push_back(i);\n    }\n\n    int num_candidates = candidates.size();\n    int simd_size = 4; // SSE/SSE2 operates on 4 integers at a time\n\n    // Process candidates in chunks of 4 using SIMD\n    for (int i = 0; i < num_candidates; i += simd_size) {\n        __m128i vec = _mm_loadu_si128((__m128i*)&candidates[i]); // Load 4 integers\n        __m128i is_prime = _mm_set1_epi32(1); // Assume all are prime initially\n\n        // Test divisors up to sqrt(n)\n        for (int d = 3; d * d < n; d += 2) {\n            __m128i divisor = _mm_set1_epi32(d);\n            __m128i mod = _mm_rem_epi32(vec, divisor); // Compute modulo\n            __m128i not_divisible = _mm_cmpneq_epi32(mod, _mm_setzero_si128()); // Check non-zero remainder\n            is_prime = _mm_and_si128(is_prime, not_divisible); // Update primality\n        }\n\n        // Extract results from SIMD registers\n        int mask = _mm_movemask_ps(_mm_castsi128_ps(is_prime));\n        for (int j = 0; j < simd_size && (i + j) < num_candidates; ++j) {\n            if (mask & (1 << j)) {\n                primes.push_back(candidates[i + j]);\n            }\n        }\n    }\n\n    return primes;\n}\n```"}
{"task_id": "SimdBench_108_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> count_up_to_simd(int n) {\n    std::vector<int> primes;\n    if (n <= 2) return primes;\n\n    // Allocate space for boolean array to mark non-prime numbers\n    int size = (n + 15) / 16; // Align to 16 bytes for SIMD operations\n    __m128i* sieve = (__m128i*)_mm_malloc(size * 16, 16);\n    for (int i = 0; i < size; ++i) {\n        sieve[i] = _mm_setzero_si128(); // Initialize all bits to 0 (all numbers are prime initially)\n    }\n\n    // Mark 0 and 1 as non-prime\n    _mm_maskmoveu_si128(_mm_set_epi32(0, 0, 0, 0xFFFF), _mm_set_epi32(0, 0, 0, 0xFFFF), (char*)sieve);\n\n    // Sieve of Eratosthenes using SIMD\n    for (int p = 2; p * p < n; ++p) {\n        if (!_mm_extract_epi16(sieve[p / 16], p % 16)) { // Check if p is prime\n            for (int multiple = p * p; multiple < n; multiple += p) {\n                int idx = multiple / 16;\n                int bit = multiple % 16;\n                __m128i mask = _mm_set1_epi16(1 << bit);\n                sieve[idx] = _mm_or_si128(sieve[idx], mask); // Mark as non-prime\n            }\n        }\n    }\n\n    // Collect primes\n    for (int i = 2; i < n; ++i) {\n        int idx = i / 16;\n        int bit = i % 16;\n        if (!_mm_extract_epi16(sieve[idx], bit)) {\n            primes.push_back(i);\n        }\n    }\n\n    _mm_free(sieve);\n    return primes;\n}\n```"}
{"task_id": "SimdBench_109_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint count_upper_simd(const std::string & s) {\n    int count = 0;\n    size_t length = s.size();\n    size_t i = 0;\n\n    // Process 16 characters at a time using SIMD\n    for (; i + 15 < length; i += 16) {\n        // Load 16 characters into an SSE register\n        __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&s[i]));\n\n        // Create a mask for uppercase vowels ('A', 'E', 'I', 'O', 'U')\n        __m128i vowels = _mm_setr_epi8('A', 'E', 'I', 'O', 'U', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n        __m128i cmp_A = _mm_cmpeq_epi8(chunk, _mm_set1_epi8('A'));\n        __m128i cmp_E = _mm_cmpeq_epi8(chunk, _mm_set1_epi8('E'));\n        __m128i cmp_I = _mm_cmpeq_epi8(chunk, _mm_set1_epi8('I'));\n        __m128i cmp_O = _mm_cmpeq_epi8(chunk, _mm_set1_epi8('O'));\n        __m128i cmp_U = _mm_cmpeq_epi8(chunk, _mm_set1_epi8('U'));\n\n        // Combine the comparisons to identify uppercase vowels\n        __m128i is_vowel = _mm_or_si128(_mm_or_si128(cmp_A, cmp_E), _mm_or_si128(cmp_I, _mm_or_si128(cmp_O, cmp_U)));\n\n        // Create a mask for even indices (0, 2, 4, ..., 14)\n        __m128i even_mask = _mm_setr_epi8(0xFF, 0x00, 0xFF, 0x00, 0xFF, 0x00, 0xFF, 0x00, 0xFF, 0x00, 0xFF, 0x00, 0xFF, 0x00, 0xFF, 0x00);\n\n        // Apply the even index mask\n        __m128i even_vowels = _mm_and_si128(is_vowel, even_mask);\n\n        // Count the number of matches\n        int mask = _mm_movemask_epi8(even_vowels);\n        count += __builtin_popcount(mask);\n    }\n\n    // Process remaining characters\n    for (; i < length; i += 2) {\n        char c = s[i];\n        if (c == 'A' || c == 'E' || c == 'I' || c == 'O' || c == 'U') {\n            count++;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_109_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint count_upper_simd(const std::string & s) {\n    int len = s.size();\n    int result = 0;\n\n    // Constants for comparison\n    __m128i upper_A = _mm_set1_epi8('A');\n    __m128i upper_Z = _mm_set1_epi8('Z');\n    __m128i vowels = _mm_setr_epi8('A', 'E', 'I', 'O', 'U', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n\n    for (int i = 0; i < len; i += 16) {\n        // Load 16 characters into SIMD register\n        __m128i chunk;\n        if (i + 16 <= len) {\n            chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&s[i]));\n        } else {\n            chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&s[i]));\n        }\n\n        // Check if characters are uppercase\n        __m128i is_upper = _mm_and_si128(\n            _mm_cmpeq_epi8(_mm_max_epu8(chunk, upper_A), chunk),\n            _mm_cmpeq_epi8(_mm_min_epu8(chunk, upper_Z), chunk)\n        );\n\n        // Check if characters are vowels\n        __m128i is_vowel_0 = _mm_cmpeq_epi8(chunk, _mm_shuffle_epi8(vowels, _mm_set1_epi8(0)));\n        __m128i is_vowel_1 = _mm_cmpeq_epi8(chunk, _mm_shuffle_epi8(vowels, _mm_set1_epi8(1)));\n        __m128i is_vowel_2 = _mm_cmpeq_epi8(chunk, _mm_shuffle_epi8(vowels, _mm_set1_epi8(2)));\n        __m128i is_vowel_3 = _mm_cmpeq_epi8(chunk, _mm_shuffle_epi8(vowels, _mm_set1_epi8(3)));\n        __m128i is_vowel_4 = _mm_cmpeq_epi8(chunk, _mm_shuffle_epi8(vowels, _mm_set1_epi8(4)));\n\n        __m128i is_vowel = _mm_or_si128(\n            _mm_or_si128(is_vowel_0, is_vowel_1),\n            _mm_or_si128(is_vowel_2, is_vowel_3)\n        );\n        is_vowel = _mm_or_si128(is_vowel, is_vowel_4);\n\n        // Combine uppercase and vowel checks\n        __m128i valid = _mm_and_si128(is_upper, is_vowel);\n\n        // Create a mask for even indices\n        __m128i index_mask = _mm_setr_epi8(0xFF, 0x00, 0xFF, 0x00, 0xFF, 0x00, 0xFF, 0x00,\n                                           0xFF, 0x00, 0xFF, 0x00, 0xFF, 0x00, 0xFF, 0x00);\n        valid = _mm_and_si128(valid, index_mask);\n\n        // Count the number of matches\n        int mask = _mm_movemask_epi8(valid);\n        result += __builtin_popcount(mask);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_109_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint count_upper_simd(const std::string & s) {\n    int len = s.size();\n    int result = 0;\n\n    // Constants for comparison\n    __m128i upper_A = _mm_set1_epi8('A');\n    __m128i upper_Z = _mm_set1_epi8('Z');\n    __m128i vowels = _mm_setr_epi8('A', 'E', 'I', 'O', 'U', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n\n    // Process the string in chunks of 16 bytes\n    for (int i = 0; i < len; i += 16) {\n        // Load 16 characters into a SIMD register\n        __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&s[i]));\n\n        // Create a mask for even indices\n        __m128i even_mask = _mm_setr_epi8(-1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0);\n        __m128i even_chars = _mm_and_si128(chunk, even_mask);\n\n        // Check if characters are uppercase letters\n        __m128i is_upper = _mm_and_si128(_mm_cmpgt_epi8(even_chars, upper_A), _mm_cmplt_epi8(even_chars, upper_Z));\n\n        // Check if characters are vowels\n        __m128i is_vowel = _mm_cmpeq_epi8(even_chars, vowels);\n\n        // Combine conditions: uppercase and vowel\n        __m128i match = _mm_and_si128(is_upper, is_vowel);\n\n        // Count matches\n        int mask = _mm_movemask_epi8(match);\n        result += __builtin_popcount(mask);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_109_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint count_upper_simd(const std::string & s) {\n    int count = 0;\n    size_t length = s.size();\n    size_t i = 0;\n\n    // Process 16 characters at a time using SIMD\n    for (; i + 15 < length; i += 16) {\n        // Load 16 characters into an SSE register\n        __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&s[i]));\n\n        // Create a mask for even indices (0xAA...AA)\n        __m128i even_mask = _mm_set_epi8(0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1);\n\n        // Apply the even index mask to filter out odd indices\n        __m128i even_chars = _mm_and_si128(chunk, even_mask);\n\n        // Create constants for uppercase vowels ('A', 'E', 'I', 'O', 'U')\n        __m128i A = _mm_set1_epi8('A');\n        __m128i E = _mm_set1_epi8('E');\n        __m128i I = _mm_set1_epi8('I');\n        __m128i O = _mm_set1_epi8('O');\n        __m128i U = _mm_set1_epi8('U');\n\n        // Compare each character with the vowel constants\n        __m128i is_A = _mm_cmpeq_epi8(even_chars, A);\n        __m128i is_E = _mm_cmpeq_epi8(even_chars, E);\n        __m128i is_I = _mm_cmpeq_epi8(even_chars, I);\n        __m128i is_O = _mm_cmpeq_epi8(even_chars, O);\n        __m128i is_U = _mm_cmpeq_epi8(even_chars, U);\n\n        // Combine all comparisons using bitwise OR\n        __m128i is_vowel = _mm_or_si128(_mm_or_si128(is_A, is_E), _mm_or_si128(is_I, _mm_or_si128(is_O, is_U)));\n\n        // Count the number of matches by extracting the mask\n        int mask = _mm_movemask_epi8(is_vowel);\n        count += __builtin_popcount(mask);\n    }\n\n    // Process remaining characters (if any)\n    for (; i < length; i += 2) {\n        char c = s[i];\n        if (c == 'A' || c == 'E' || c == 'I' || c == 'O' || c == 'U') {\n            count++;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_109_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint count_upper_simd(const std::string & s) {\n    int count = 0;\n    size_t length = s.size();\n    size_t i = 0;\n\n    // Process 16 characters at a time using SIMD\n    for (; i + 15 < length; i += 16) {\n        // Load 16 characters into an SSE register\n        __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&s[i]));\n\n        // Create a mask for uppercase vowels ('A', 'E', 'I', 'O', 'U')\n        __m128i vowels = _mm_setr_epi8('A', 'E', 'I', 'O', 'U', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n        __m128i cmp_A = _mm_cmpeq_epi8(chunk, _mm_set1_epi8('A'));\n        __m128i cmp_E = _mm_cmpeq_epi8(chunk, _mm_set1_epi8('E'));\n        __m128i cmp_I = _mm_cmpeq_epi8(chunk, _mm_set1_epi8('I'));\n        __m128i cmp_O = _mm_cmpeq_epi8(chunk, _mm_set1_epi8('O'));\n        __m128i cmp_U = _mm_cmpeq_epi8(chunk, _mm_set1_epi8('U'));\n\n        // Combine comparisons to identify uppercase vowels\n        __m128i is_vowel = _mm_or_si128(_mm_or_si128(cmp_A, cmp_E), _mm_or_si128(cmp_I, _mm_or_si128(cmp_O, cmp_U)));\n\n        // Create a mask for even indices (0, 2, 4, ..., 14)\n        __m128i even_mask = _mm_setr_epi8(0xFF, 0x00, 0xFF, 0x00, 0xFF, 0x00, 0xFF, 0x00, 0xFF, 0x00, 0xFF, 0x00, 0xFF, 0x00, 0xFF, 0x00);\n\n        // Apply the even index mask\n        __m128i filtered = _mm_and_si128(is_vowel, even_mask);\n\n        // Count the number of matches\n        int mask = _mm_movemask_epi8(filtered);\n        count += __builtin_popcount(mask);\n    }\n\n    // Process remaining characters\n    for (; i < length; ++i) {\n        if (i % 2 == 0 && (s[i] == 'A' || s[i] == 'E' || s[i] == 'I' || s[i] == 'O' || s[i] == 'U')) {\n            ++count;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_110_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> make_a_pile_simd(int n) {\n    std::vector<int> result(n);\n    int current = n;\n\n    // Process 4 elements at a time using SSE2 intrinsics\n    __m128i increment = _mm_set1_epi32(2); // Increment by 2 for odd/even sequence\n    __m128i current_v = _mm_set1_epi32(current);\n\n    for (int i = 0; i < n; i += 4) {\n        // Store the current values into the result vector\n        if (i + 4 <= n) {\n            _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i]), current_v);\n        } else {\n            // Handle the remaining elements (less than 4)\n            for (int j = i; j < n; ++j) {\n                result[j] = current;\n                current += 2;\n            }\n            break;\n        }\n\n        // Update the current values for the next iteration\n        current_v = _mm_add_epi32(current_v, increment);\n        current += 8; // Increment by 8 since we processed 4 elements\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_110_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> make_a_pile_simd(int n) {\n    std::vector<int> result(n);\n    int current = n;\n\n    // Process 4 levels at a time using SIMD\n    __m128i increment = _mm_set1_epi32(2); // Increment by 2 for odd/even sequence\n    __m128i current_v = _mm_set1_epi32(current);\n\n    for (int i = 0; i < n; i += 4) {\n        // Load the current level values into a SIMD register\n        __m128i levels = _mm_add_epi32(current_v, _mm_mullo_epi32(increment, _mm_setr_epi32(0, 1, 2, 3)));\n\n        // Store the results back to the vector\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i]), levels);\n\n        // Update the current value for the next iteration\n        current += 8;\n        current_v = _mm_add_epi32(current_v, _mm_set1_epi32(8));\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_110_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> make_a_pile_simd(int n) {\n    std::vector<int> result(n);\n    int current = n;\n\n    // Process 4 elements at a time using SSE2 intrinsics\n    __m128i increment = _mm_set1_epi32(2); // Increment by 2 for odd/even sequence\n    __m128i current_v = _mm_set1_epi32(current);\n\n    for (int i = 0; i < n; i += 4) {\n        // Store the current values into the result vector\n        __m128i result_v = current_v;\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i]), result_v);\n\n        // Update the current values for the next iteration\n        current_v = _mm_add_epi32(current_v, increment);\n    }\n\n    // Handle any remaining elements if n is not a multiple of 4\n    for (int i = (n / 4) * 4; i < n; ++i) {\n        result[i] = current;\n        current += 2;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_110_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> make_a_pile_simd(int n) {\n    std::vector<int> result(n);\n    int current = n;\n\n    // Process 4 elements at a time using SSE2 intrinsics\n    __m128i increment = _mm_set1_epi32(2); // Increment by 2 for odd/even sequence\n    __m128i current_vec = _mm_set1_epi32(current);\n\n    for (int i = 0; i < n; i += 4) {\n        // Store the current values into the result vector\n        if (i + 4 <= n) {\n            _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i]), current_vec);\n        } else {\n            // Handle the remaining elements (less than 4)\n            for (int j = i; j < n; ++j) {\n                result[j] = current;\n                current += 2;\n            }\n            break;\n        }\n\n        // Update the current values for the next iteration\n        current_vec = _mm_add_epi32(current_vec, increment);\n        current += 8; // Increment by 8 since we processed 4 elements\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_110_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> make_a_pile_simd(int n) {\n    std::vector<int> result(n);\n    int current = n;\n\n    // Process 4 elements at a time using SSE2 intrinsics\n    __m128i increment = _mm_set1_epi32(2); // Increment by 2 for odd/even sequence\n    __m128i current_v = _mm_set1_epi32(current);\n\n    for (int i = 0; i < n; i += 4) {\n        // Store the current values into the result vector\n        if (i + 4 <= n) {\n            _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i]), current_v);\n        } else {\n            // Handle the remaining elements (less than 4)\n            for (int j = i; j < n; ++j) {\n                result[j] = current;\n                current += 2;\n            }\n            break;\n        }\n\n        // Update the current values for the next iteration\n        current_v = _mm_add_epi32(current_v, increment);\n        current += 8; // Increment by 8 since we processed 4 elements\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_111_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n#include <bitset>\n\nstd::string rounded_avg_simd(int64_t n, int64_t m) {\n    if (n > m) return \"-1\";\n\n    // Load n and m into SIMD registers\n    __m128i vn = _mm_set1_epi64x(n);\n    __m128i vm = _mm_set1_epi64x(m);\n\n    // Compute the sum of integers from n to m using the formula: sum = (m * (m + 1)) / 2 - ((n - 1) * n) / 2\n    __m128i one = _mm_set1_epi64x(1);\n    __m128i n_minus_1 = _mm_sub_epi64(vn, one);\n    __m128i n_term = _mm_mul_epi32(n_minus_1, vn); // (n - 1) * n\n    __m128i m_plus_1 = _mm_add_epi64(vm, one);\n    __m128i m_term = _mm_mul_epi32(vm, m_plus_1); // m * (m + 1)\n\n    // Subtract the two terms\n    __m128i sum = _mm_sub_epi64(m_term, n_term);\n\n    // Divide by 2 to get the sum of integers from n to m\n    __m128i two = _mm_set1_epi64x(2);\n    sum = _mm_div_epi64(sum, two);\n\n    // Compute the count of numbers from n to m\n    __m128i count = _mm_sub_epi64(vm, vn);\n    count = _mm_add_epi64(count, one);\n\n    // Compute the average\n    __m128i avg = _mm_div_epi64(sum, count);\n\n    // Convert the result to binary\n    int64_t result;\n    _mm_storel_epi64((__m128i*)&result, avg);\n\n    std::string binary = std::bitset<64>(result).to_string();\n    // Remove leading zeros\n    size_t first_one = binary.find('1');\n    if (first_one != std::string::npos) {\n        binary = binary.substr(first_one);\n    } else {\n        binary = \"0\";\n    }\n\n    return binary;\n}\n```"}
{"task_id": "SimdBench_111_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n#include <sstream>\n\nstd::string rounded_avg_simd(int64_t n, int64_t m) {\n    if (n > m) return \"-1\";\n\n    // Use SIMD to calculate the sum of integers from n to m\n    __m128i v_n = _mm_set1_epi64x(n);\n    __m128i v_m = _mm_set1_epi64x(m);\n\n    // Compute the count of numbers in the range [n, m]\n    __m128i v_count = _mm_sub_epi64(v_m, v_n);\n    v_count = _mm_add_epi64(v_count, _mm_set1_epi64x(1));\n\n    // Compute the sum using the formula: sum = (m * (m + 1)) / 2 - ((n - 1) * n) / 2\n    __m128i v_one = _mm_set1_epi64x(1);\n    __m128i v_n_minus_1 = _mm_sub_epi64(v_n, v_one);\n\n    __m128i v_sum_m = _mm_mul_epi64(v_m, _mm_add_epi64(v_m, v_one));\n    __m128i v_sum_n_minus_1 = _mm_mul_epi64(v_n_minus_1, _mm_add_epi64(v_n_minus_1, v_one));\n\n    __m128i v_sum = _mm_sub_epi64(v_sum_m, v_sum_n_minus_1);\n    v_sum = _mm_srai_epi64(v_sum, 1); // Divide by 2\n\n    // Compute the average: sum / count\n    __m128i v_avg = _mm_div_epi64(v_sum, v_count);\n\n    // Extract the result and convert to binary\n    int64_t avg = _mm_cvtsi128_si64(v_avg);\n    std::stringstream ss;\n    ss << std::bitset<64>(avg);\n    std::string binary = ss.str();\n\n    // Remove leading zeros\n    size_t first_one = binary.find('1');\n    if (first_one != std::string::npos) {\n        binary = binary.substr(first_one);\n    } else {\n        binary = \"0\";\n    }\n\n    return binary;\n}\n```"}
{"task_id": "SimdBench_111_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n#include <bitset>\n\nstd::string rounded_avg_simd(int64_t n, int64_t m) {\n    if (n > m) return \"-1\";\n\n    // Load n and m into SIMD registers\n    __m128i vn = _mm_set1_epi64x(n);\n    __m128i vm = _mm_set1_epi64x(m);\n\n    // Compute the sum of integers from n to m using the formula: sum = (m * (m + 1)) / 2 - ((n - 1) * n) / 2\n    __m128i one = _mm_set1_epi64x(1);\n    __m128i n_minus_1 = _mm_sub_epi64(vn, one);\n    __m128i n_term = _mm_mul_epi32(n_minus_1, vn); // (n - 1) * n\n    __m128i m_plus_1 = _mm_add_epi64(vm, one);\n    __m128i m_term = _mm_mul_epi32(vm, m_plus_1); // m * (m + 1)\n\n    // Divide by 2 to compute the sum\n    __m128i two = _mm_set1_epi64x(2);\n    __m128i sum_n = _mm_div_epi64(n_term, two);\n    __m128i sum_m = _mm_div_epi64(m_term, two);\n    __m128i total_sum = _mm_sub_epi64(sum_m, sum_n);\n\n    // Compute the count of numbers from n to m\n    __m128i count = _mm_sub_epi64(vm, vn);\n    count = _mm_add_epi64(count, one);\n\n    // Compute the average\n    __m128i avg = _mm_div_epi64(total_sum, count);\n\n    // Extract the result from the SIMD register\n    int64_t result;\n    _mm_storel_epi64(reinterpret_cast<__m128i*>(&result), avg);\n\n    // Convert the result to binary\n    std::string binary = std::bitset<64>(result).to_string();\n    // Remove leading zeros\n    size_t first_one = binary.find('1');\n    if (first_one != std::string::npos) {\n        binary = binary.substr(first_one);\n    } else {\n        binary = \"0\";\n    }\n\n    return binary;\n}\n```"}
{"task_id": "SimdBench_111_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n#include <sstream>\n\nstd::string rounded_avg_simd(int64_t n, int64_t m) {\n    if (n > m) return \"-1\";\n\n    // Load n and m into SIMD registers\n    __m128i vn = _mm_set1_epi64x(n);\n    __m128i vm = _mm_set1_epi64x(m);\n\n    // Compute the sum of integers from n to m using the formula: sum = (m - n + 1) * (n + m) / 2\n    __m128i range = _mm_sub_epi64(vm, vn);\n    range = _mm_add_epi64(range, _mm_set1_epi64x(1)); // m - n + 1\n\n    __m128i sum_pair = _mm_add_epi64(vn, vm); // n + m\n    __m128i sum = _mm_mullo_epi64(range, sum_pair); // (m - n + 1) * (n + m)\n    sum = _mm_srli_epi64(sum, 1); // Divide by 2\n\n    // Compute the count of numbers in the range\n    __m128i count = _mm_sub_epi64(vm, vn);\n    count = _mm_add_epi64(count, _mm_set1_epi64x(1)); // m - n + 1\n\n    // Compute the average: sum / count\n    __m128i avg = _mm_div_epi64(sum, count);\n\n    // Extract the result from the SIMD register\n    int64_t result;\n    _mm_storel_epi64(reinterpret_cast<__m128i*>(&result), avg);\n\n    // Convert the result to binary\n    std::stringstream ss;\n    ss << std::bitset<64>(result);\n    std::string binary = ss.str();\n\n    // Remove leading zeros\n    size_t first_one = binary.find('1');\n    if (first_one != std::string::npos) {\n        binary = binary.substr(first_one);\n    } else {\n        binary = \"0\";\n    }\n\n    return binary;\n}\n```"}
{"task_id": "SimdBench_111_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n#include <sstream>\n\nstd::string rounded_avg_simd(int64_t n, int64_t m) {\n    if (n > m) return \"-1\";\n\n    // Use SIMD to calculate the sum of integers from n to m\n    __m128i v_n = _mm_set1_epi64x(n);\n    __m128i v_m = _mm_set1_epi64x(m);\n\n    // Compute the number of terms: m - n + 1\n    __m128i v_count = _mm_sub_epi64(v_m, v_n);\n    v_count = _mm_add_epi64(v_count, _mm_set1_epi64x(1));\n\n    // Compute the sum using the formula: sum = (n + m) * count / 2\n    __m128i v_sum = _mm_add_epi64(v_n, v_m);\n    v_sum = _mm_mullo_epi64(v_sum, v_count);\n    v_sum = _mm_srli_epi64(v_sum, 1); // Divide by 2\n\n    // Compute the average: sum / count\n    __m128i v_avg = _mm_div_epi64(v_sum, v_count);\n\n    // Extract the result\n    int64_t avg;\n    _mm_storel_epi64(reinterpret_cast<__m128i*>(&avg), v_avg);\n\n    // Convert the average to binary\n    std::stringstream ss;\n    ss << std::bitset<64>(avg).to_string();\n    std::string binary = ss.str();\n\n    // Remove leading zeros\n    size_t first_one = binary.find('1');\n    if (first_one != std::string::npos) {\n        binary = binary.substr(first_one);\n    } else {\n        binary = \"0\";\n    }\n\n    return binary;\n}\n```"}
{"task_id": "SimdBench_112_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> func_simd(int n) {\n    std::vector<int> result(n);\n    int i = 1;\n\n    // Process in chunks of 4 using SSE2 intrinsics\n    for (; i + 3 <= n; i += 4) {\n        __m128i indices = _mm_set_epi32(i + 3, i + 2, i + 1, i); // Load indices [i, i+1, i+2, i+3]\n        __m128i ones = _mm_set1_epi32(1); // Vector of ones\n        __m128i values = _mm_set1_epi32(1); // Initialize values to 1\n\n        // Compute factorial or sum based on even/odd condition\n        for (int j = 2; j <= i + 3; ++j) {\n            __m128i multiplier = _mm_set1_epi32(j); // Current multiplier\n            __m128i is_even = _mm_and_si128(_mm_cmpeq_epi32(_mm_and_si128(indices, ones), _mm_setzero_si128()), ones); // Check if index is even\n            __m128i is_odd = _mm_andnot_si128(is_even, ones); // Check if index is odd\n\n            // Update values: multiply if even, add if odd\n            values = _mm_add_epi32(\n                _mm_mullo_epi32(values, _mm_and_si128(multiplier, is_even)),\n                _mm_and_si128(multiplier, is_odd)\n            );\n        }\n\n        // Apply modulo 10000 to the results\n        __m128i mod_val = _mm_set1_epi32(10000);\n        values = _mm_mod_epi32(values, mod_val);\n\n        // Store results back to the vector\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i - 1]), values);\n    }\n\n    // Handle remaining elements\n    for (; i <= n; ++i) {\n        if (i % 2 == 0) {\n            int fact = 1;\n            for (int j = 1; j <= i; ++j) {\n                fact = (fact * j) % 10000;\n            }\n            result[i - 1] = fact;\n        } else {\n            result[i - 1] = (i * (i + 1)) / 2;\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_112_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> func_simd(int n) {\n    std::vector<int> result(n);\n    int i = 1;\n\n    // Process in chunks of 4 using SSE2 intrinsics\n    for (; i + 3 <= n; i += 4) {\n        __m128i indices = _mm_set_epi32(i + 3, i + 2, i + 1, i); // Load indices [i, i+1, i+2, i+3]\n        __m128i ones = _mm_set1_epi32(1); // Vector of ones\n        __m128i values = _mm_set1_epi32(1); // Initialize values to 1\n\n        // Compute factorial or sum based on even/odd condition\n        for (int j = 2; j <= i + 3; ++j) {\n            __m128i multiplier = _mm_set1_epi32(j); // Broadcast j to all elements\n            __m128i is_even = _mm_and_si128(_mm_cmpeq_epi32(_mm_and_si128(indices, ones), _mm_setzero_si128()), ones); // Check if index is even\n            __m128i new_values = _mm_mullo_epi32(values, multiplier); // Factorial step\n            __m128i sum_values = _mm_add_epi32(values, multiplier); // Sum step\n            values = _mm_blendv_epi8(sum_values, new_values, is_even); // Blend based on even/odd\n        }\n\n        // Store results back to the result vector\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i - 1]), values);\n    }\n\n    // Handle remaining elements\n    for (; i <= n; ++i) {\n        if (i % 2 == 0) {\n            int factorial = 1;\n            for (int j = 1; j <= i; ++j) {\n                factorial = (factorial * j) % 10000;\n            }\n            result[i - 1] = factorial;\n        } else {\n            int sum = (i * (i + 1)) / 2;\n            result[i - 1] = sum;\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_112_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> func_simd(int n) {\n    std::vector<int> result(n);\n    int i = 1;\n\n    // Process in chunks of 4 using SSE2 intrinsics\n    for (; i + 3 <= n; i += 4) {\n        __m128i indices = _mm_set_epi32(i + 3, i + 2, i + 1, i); // Load indices [i, i+1, i+2, i+3]\n        __m128i ones = _mm_set1_epi32(1); // Vector of ones\n        __m128i results = _mm_set1_epi32(0); // Initialize results vector\n\n        // Compute factorial modulo 10000 for even indices and sum for odd indices\n        for (int j = 1; j <= i + 3; ++j) {\n            __m128i mask = _mm_set1_epi32(j); // Current number as a vector\n            __m128i is_even = _mm_and_si128(_mm_cmpeq_epi32(_mm_and_si128(indices, ones), _mm_setzero_si128()), ones);\n\n            // Update results based on even/odd condition\n            __m128i factorial_update = _mm_mullo_epi32(results, mask);\n            __m128i sum_update = _mm_add_epi32(results, mask);\n            results = _mm_blendv_epi8(sum_update, factorial_update, is_even);\n\n            // Apply modulo 10000 for even indices\n            __m128i mod_mask = _mm_set1_epi32(10000);\n            results = _mm_blendv_epi8(results, _mm_mod_epi32(results, mod_mask), is_even);\n        }\n\n        // Store results back to the output vector\n        _mm_storeu_si128((__m128i*)&result[i - 1], results);\n    }\n\n    // Handle remaining elements\n    for (; i <= n; ++i) {\n        if (i % 2 == 0) {\n            int fact = 1;\n            for (int j = 1; j <= i; ++j) {\n                fact = (fact * j) % 10000;\n            }\n            result[i - 1] = fact;\n        } else {\n            result[i - 1] = (i * (i + 1)) / 2;\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_112_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> func_simd(int n) {\n    std::vector<int> result(n);\n    int i = 1;\n\n    // Process in chunks of 4 using SSE2 intrinsics\n    for (; i + 3 <= n; i += 4) {\n        __m128i indices = _mm_set_epi32(i + 3, i + 2, i + 1, i); // Load indices [i, i+1, i+2, i+3]\n        __m128i ones = _mm_set1_epi32(1); // Vector of ones\n        __m128i results = _mm_setzero_si128(); // Initialize results vector\n\n        // Compute factorial modulo 10000 for even indices\n        __m128i factorials = _mm_set1_epi32(1); // Initialize factorial vector\n        for (int j = 1; j <= i + 3; ++j) {\n            __m128i j_vec = _mm_set1_epi32(j); // Broadcast j to all elements\n            factorials = _mm_mullo_epi32(factorials, j_vec); // Multiply factorials by j\n            factorials = _mm_and_si128(factorials, _mm_set1_epi32(0xFFFF)); // Modulo 10000\n        }\n\n        // Compute sum for odd indices\n        __m128i sums = _mm_add_epi32(indices, ones); // Sum = i + 1\n        sums = _mm_mullo_epi32(sums, indices); // Sum = i * (i + 1)\n        sums = _mm_srli_epi32(sums, 1); // Sum = i * (i + 1) / 2\n\n        // Select results based on even/odd indices\n        __m128i mask = _mm_set_epi32((i + 3) % 2 == 0 ? 0xFFFFFFFF : 0,\n                                     (i + 2) % 2 == 0 ? 0xFFFFFFFF : 0,\n                                     (i + 1) % 2 == 0 ? 0xFFFFFFFF : 0,\n                                     i % 2 == 0 ? 0xFFFFFFFF : 0);\n        results = _mm_blendv_epi8(sums, factorials, mask);\n\n        // Store results into the output vector\n        _mm_storeu_si128((__m128i*)&result[i - 1], results);\n    }\n\n    // Handle remaining elements\n    for (; i <= n; ++i) {\n        if (i % 2 == 0) {\n            int factorial = 1;\n            for (int j = 1; j <= i; ++j) {\n                factorial = (factorial * j) % 10000;\n            }\n            result[i - 1] = factorial;\n        } else {\n            result[i - 1] = (i * (i + 1)) / 2;\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_112_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> func_simd(int n) {\n    std::vector<int> result(n);\n    __m128i v_mod = _mm_set1_epi32(10000); // Modulo value 10,000\n    __m128i v_one = _mm_set1_epi32(1);     // Constant 1 for incrementing\n    __m128i v_two = _mm_set1_epi32(2);     // Constant 2 for even/odd check\n\n    int i = 1;\n    while (i + 3 < n) {\n        // Load indices i, i+1, i+2, i+3 into a SIMD register\n        __m128i v_indices = _mm_setr_epi32(i, i + 1, i + 2, i + 3);\n\n        // Check if indices are even or odd\n        __m128i v_is_even = _mm_cmpeq_epi32(_mm_and_si128(v_indices, v_two), _mm_setzero_si128());\n\n        // Compute factorial modulo 10,000 for even indices\n        __m128i v_factorial = _mm_set1_epi32(1);\n        for (int j = 2; j <= i + 3; ++j) {\n            __m128i v_j = _mm_set1_epi32(j);\n            v_factorial = _mm_mullo_epi32(v_factorial, v_j);\n            v_factorial = _mm_rem_epu32(v_factorial, v_mod); // Custom modulo implementation\n        }\n\n        // Compute sum of numbers from 1 to i for odd indices\n        __m128i v_sum = _mm_mullo_epi32(v_indices, _mm_add_epi32(v_indices, v_one));\n        v_sum = _mm_srli_epi32(v_sum, 1); // Equivalent to division by 2\n\n        // Blend results based on even/odd mask\n        __m128i v_result = _mm_blendv_epi8(v_sum, v_factorial, v_is_even);\n\n        // Store results back to the vector\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i]), v_result);\n        i += 4;\n    }\n\n    // Handle remaining elements\n    for (; i < n; ++i) {\n        if (i % 2 == 0) {\n            int factorial = 1;\n            for (int j = 1; j <= i; ++j) {\n                factorial = (factorial * j) % 10000;\n            }\n            result[i] = factorial;\n        } else {\n            result[i] = (i * (i + 1)) / 2;\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_113_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> even_odd_palindrome_simd(int n) {\n    int even_count = 0, odd_count = 0;\n    __m128i v_even_count = _mm_setzero_si128();\n    __m128i v_odd_count = _mm_setzero_si128();\n\n    for (int i = 1; i <= n; ++i) {\n        int num = i;\n        int rev = 0;\n        int temp = num;\n\n        // Reverse the number\n        while (temp > 0) {\n            rev = rev * 10 + (temp % 10);\n            temp /= 10;\n        }\n\n        // Check if palindrome\n        if (rev == num) {\n            __m128i v_num = _mm_set1_epi32(num);\n            __m128i v_two = _mm_set1_epi32(2);\n            __m128i v_mod = _mm_and_si128(v_num, v_two); // num & 2 (check even/odd)\n\n            // Compare with zero to determine even or odd\n            __m128i v_zero = _mm_setzero_si128();\n            __m128i v_is_even = _mm_cmpeq_epi32(v_mod, v_zero);\n\n            // Increment counters using blendv\n            v_even_count = _mm_add_epi32(v_even_count, _mm_and_si128(v_is_even, _mm_set1_epi32(1)));\n            v_odd_count = _mm_add_epi32(v_odd_count, _mm_andnot_si128(v_is_even, _mm_set1_epi32(1)));\n        }\n    }\n\n    // Horizontal sum of the SSE registers\n    int counts[4];\n    _mm_storeu_si128((__m128i*)counts, v_even_count);\n    even_count = counts[0] + counts[1] + counts[2] + counts[3];\n\n    _mm_storeu_si128((__m128i*)counts, v_odd_count);\n    odd_count = counts[0] + counts[1] + counts[2] + counts[3];\n\n    return {even_count, odd_count};\n}\n```"}
{"task_id": "SimdBench_113_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> even_odd_palindrome_simd(int n) {\n    int even_count = 0, odd_count = 0;\n    __m128i v_even_count = _mm_setzero_si128();\n    __m128i v_odd_count = _mm_setzero_si128();\n\n    for (int i = 1; i <= n; ++i) {\n        int num = i;\n        int rev = 0;\n        int temp = num;\n\n        // Reverse the number\n        while (temp > 0) {\n            rev = rev * 10 + (temp % 10);\n            temp /= 10;\n        }\n\n        // Check if palindrome\n        if (rev == num) {\n            __m128i v_num = _mm_set1_epi32(num);\n            __m128i v_two = _mm_set1_epi32(2);\n            __m128i v_mod = _mm_and_si128(v_num, v_two); // num & 2 (check even/odd)\n\n            __m128i v_is_even = _mm_cmpeq_epi32(v_mod, _mm_setzero_si128());\n            __m128i v_is_odd = _mm_xor_si128(v_is_even, _mm_set1_epi32(-1));\n\n            v_even_count = _mm_add_epi32(v_even_count, _mm_and_si128(v_is_even, _mm_set1_epi32(1)));\n            v_odd_count = _mm_add_epi32(v_odd_count, _mm_and_si128(v_is_odd, _mm_set1_epi32(1)));\n        }\n    }\n\n    // Horizontal sum of counts\n    int counts[4];\n    _mm_storeu_si128((__m128i*)counts, v_even_count);\n    even_count = counts[0] + counts[1] + counts[2] + counts[3];\n\n    _mm_storeu_si128((__m128i*)counts, v_odd_count);\n    odd_count = counts[0] + counts[1] + counts[2] + counts[3];\n\n    return {even_count, odd_count};\n}\n```"}
{"task_id": "SimdBench_113_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> even_odd_palindrome_simd(int n) {\n    int even_count = 0, odd_count = 0;\n    __m128i v_even_count = _mm_setzero_si128();\n    __m128i v_odd_count = _mm_setzero_si128();\n\n    for (int i = 1; i <= n; ++i) {\n        int num = i;\n        int rev = 0;\n        int temp = num;\n\n        // Reverse the number\n        while (temp > 0) {\n            rev = rev * 10 + (temp % 10);\n            temp /= 10;\n        }\n\n        // Check if palindrome\n        if (rev == num) {\n            __m128i v_num = _mm_set1_epi32(num);\n            __m128i v_two = _mm_set1_epi32(2);\n            __m1128i v_mod = _mm_rem_epi32(v_num, v_two);\n\n            // Check if even or odd using SIMD\n            __m128i v_zero = _mm_setzero_si128();\n            __m128i v_is_even = _mm_cmpeq_epi32(v_mod, v_zero);\n\n            // Increment counts using blendv\n            v_even_count = _mm_add_epi32(v_even_count, _mm_and_si128(v_is_even, _mm_set1_epi32(1)));\n            v_odd_count = _mm_add_epi32(v_odd_count, _mm_andnot_si128(v_is_even, _mm_set1_epi32(1)));\n        }\n    }\n\n    // Horizontal sum of the vectorized counts\n    int temp_even[4], temp_odd[4];\n    _mm_storeu_si128((__m128i*)temp_even, v_even_count);\n    _mm_storeu_si128((__m128i*)temp_odd, v_odd_count);\n\n    for (int i = 0; i < 4; ++i) {\n        even_count += temp_even[i];\n        odd_count += temp_odd[i];\n    }\n\n    return {even_count, odd_count};\n}\n```"}
{"task_id": "SimdBench_113_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> even_odd_palindrome_simd(int n) {\n    int even_count = 0, odd_count = 0;\n    __m128i v_even_count = _mm_setzero_si128();\n    __m128i v_odd_count = _mm_setzero_si128();\n\n    for (int i = 1; i <= n; ++i) {\n        int num = i;\n        int rev = 0;\n        int temp = num;\n\n        // Reverse the number\n        while (temp > 0) {\n            rev = rev * 10 + (temp % 10);\n            temp /= 10;\n        }\n\n        // Check if palindrome\n        if (rev == num) {\n            __m128i v_num = _mm_set1_epi32(num);\n            __m128i v_two = _mm_set1_epi32(2);\n            __m128i v_mod = _mm_and_si128(v_num, v_two); // num & 2 (even check)\n\n            __m128i v_is_even = _mm_cmpeq_epi32(v_mod, _mm_setzero_si128());\n            __m128i v_is_odd = _mm_xor_si128(v_is_even, _mm_set1_epi32(0xFFFFFFFF));\n\n            v_even_count = _mm_add_epi32(v_even_count, v_is_even);\n            v_odd_count = _mm_add_epi32(v_odd_count, v_is_odd);\n        }\n    }\n\n    // Horizontal sum of counts\n    int counts[4];\n    _mm_storeu_si128((__m128i*)counts, v_even_count);\n    even_count = counts[0] + counts[1] + counts[2] + counts[3];\n\n    _mm_storeu_si128((__m128i*)counts, v_odd_count);\n    odd_count = counts[0] + counts[1] + counts[2] + counts[3];\n\n    return {even_count, odd_count};\n}\n```"}
{"task_id": "SimdBench_113_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> even_odd_palindrome_simd(int n) {\n    int even_count = 0, odd_count = 0;\n    __m128i v_even_count = _mm_setzero_si128();\n    __m128i v_odd_count = _mm_setzero_si128();\n\n    for (int i = 1; i <= n; ++i) {\n        int num = i;\n        int rev = 0;\n        int temp = num;\n\n        // Reverse the number to check if it's a palindrome\n        while (temp > 0) {\n            rev = rev * 10 + (temp % 10);\n            temp /= 10;\n        }\n\n        if (rev == num) {\n            __m128i v_num = _mm_set1_epi32(num);\n            __m128i v_two = _mm_set1_epi32(2);\n            __m128i v_mod = _mm_and_si128(v_num, v_two); // num & 2 (check even/odd)\n\n            __m128i v_is_even = _mm_cmpeq_epi32(v_mod, _mm_setzero_si128());\n            __m128i v_is_odd = _mm_xor_si128(v_is_even, _mm_set1_epi32(-1));\n\n            v_even_count = _mm_add_epi32(v_even_count, _mm_and_si128(v_is_even, _mm_set1_epi32(1)));\n            v_odd_count = _mm_add_epi32(v_odd_count, _mm_and_si128(v_is_odd, _mm_set1_epi32(1)));\n        }\n    }\n\n    // Horizontal sum of counts in SIMD registers\n    int counts[4];\n    _mm_storeu_si128((__m128i*)counts, v_even_count);\n    even_count = counts[0] + counts[1] + counts[2] + counts[3];\n\n    _mm_storeu_si128((__m128i*)counts, v_odd_count);\n    odd_count = counts[0] + counts[1] + counts[2] + counts[3];\n\n    return {even_count, odd_count};\n}\n```"}
{"task_id": "SimdBench_114_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint count_nums_simd(std::vector<int> n) {\n    int count = 0;\n    int size = n.size();\n    int i = 0;\n\n    // Process 4 integers at a time using SSE2\n    for (; i + 3 < size; i += 4) {\n        __m128i vec = _mm_loadu_si128((__m128i*)&n[i]); // Load 4 integers\n        __m128i sum = _mm_setzero_si128();              // Initialize sum vector to zero\n\n        // Extract absolute values of the integers\n        __m128i sign_mask = _mm_cmpgt_epi32(_mm_setzero_si128(), vec); // Mask for negative numbers\n        __m128i abs_vals = _mm_sub_epi32(_mm_xor_si128(vec, sign_mask), sign_mask);\n\n        // Sum digits of each integer in the vector\n        for (int j = 0; j < 4; ++j) {\n            __m128i digit_sum = _mm_setzero_si128();\n            __m128i num = abs_vals;\n\n            for (int k = 0; k < 10; ++k) { // Max 10 digits in a 32-bit integer\n                __m128i digit = _mm_and_si128(num, _mm_set1_epi32(0xF)); // Extract last 4 bits\n                digit_sum = _mm_add_epi32(digit_sum, digit);             // Add to digit sum\n                num = _mm_srli_epi32(num, 4);                           // Shift right by 4 bits\n            }\n\n            // Check if the sum of digits is greater than 0\n            __m128i cmp = _mm_cmpgt_epi32(digit_sum, _mm_setzero_si128());\n            int mask = _mm_movemask_ps(_mm_castsi128_ps(cmp)); // Convert comparison result to mask\n            count += __builtin_popcount(mask);                 // Count set bits in the mask\n        }\n    }\n\n    // Process remaining elements\n    for (; i < size; ++i) {\n        int num = n[i];\n        int digit_sum = 0;\n        num = std::abs(num);\n\n        while (num > 0) {\n            digit_sum += num % 10;\n            num /= 10;\n        }\n\n        if (digit_sum > 0) {\n            ++count;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_114_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint count_nums_simd(std::vector<int> n) {\n    int count = 0;\n    size_t i = 0;\n    size_t size = n.size();\n\n    // Process 4 integers at a time using SSE2 intrinsics\n    for (; i + 4 <= size; i += 4) {\n        __m128i vec = _mm_loadu_si128((__m128i*)&n[i]); // Load 4 integers into SIMD register\n        __m128i zero = _mm_setzero_si128();            // Zero vector for comparisons\n        __m128i sum = _mm_setzero_si128();             // Initialize sum vector\n\n        // Extract absolute values of digits and compute their sum\n        for (int j = 0; j < 4; ++j) {\n            __m128i num = _mm_shuffle_epi32(vec, _MM_SHUFFLE(j, j, j, j)); // Isolate one integer\n            __m128i sign = _mm_srai_epi32(num, 31);                        // Get sign bit (-1 for negative, 0 for positive)\n            __m128i abs_num = _mm_sub_epi32(_mm_xor_si128(num, sign), sign); // Compute absolute value\n\n            // Sum digits of the absolute number\n            __m128i digit_sum = _mm_setzero_si128();\n            __m128i temp = abs_num;\n            while (_mm_movemask_epi8(_mm_cmpgt_epi32(temp, zero))) { // While any element > 0\n                __m128i mod = _mm_and_si128(temp, _mm_set1_epi32(0xF)); // Extract last 4 bits\n                digit_sum = _mm_add_epi32(digit_sum, mod);              // Add to digit sum\n                temp = _mm_srli_epi32(temp, 4);                         // Shift right by 4 bits\n            }\n\n            // Accumulate the digit sum for this number\n            sum = _mm_add_epi32(sum, digit_sum);\n        }\n\n        // Compare if the sum of digits is greater than 0\n        __m128i cmp = _mm_cmpgt_epi32(sum, zero);\n        int mask = _mm_movemask_ps(_mm_castsi128_ps(cmp)); // Convert comparison result to bitmask\n\n        // Count the number of elements with sum of digits > 0\n        count += __builtin_popcount(mask);\n    }\n\n    // Process remaining elements\n    for (; i < size; ++i) {\n        int num = n[i];\n        int abs_num = std::abs(num);\n        int digit_sum = 0;\n\n        while (abs_num > 0) {\n            digit_sum += abs_num % 10;\n            abs_num /= 10;\n        }\n\n        if (digit_sum > 0) {\n            ++count;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_114_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint count_nums_simd(std::vector<int> n) {\n    int count = 0;\n    size_t i = 0;\n    size_t size = n.size();\n    \n    // Process 4 integers at a time using SSE2 intrinsics\n    for (; i + 3 < size; i += 4) {\n        __m128i vec = _mm_loadu_si128((__m128i*)&n[i]); // Load 4 integers into a SIMD register\n        __m128i sum_vec = _mm_setzero_si128();          // Initialize sum vector to zero\n        \n        // Extract absolute values of the integers\n        __m128i sign_mask = _mm_cmpgt_epi32(_mm_setzero_si128(), vec); // Mask for negative numbers\n        __m128i abs_vec = _mm_sub_epi32(_mm_xor_si128(vec, sign_mask), sign_mask); // Absolute value\n        \n        // Compute sum of digits for each integer in parallel\n        for (int digit = 0; digit < 10; ++digit) {\n            __m128i div = _mm_set1_epi32(10);\n            __m128i mod = _mm_and_si128(abs_vec, _mm_set1_epi32(0xF)); // Extract last digit\n            sum_vec = _mm_add_epi32(sum_vec, mod);                      // Add to sum\n            abs_vec = _mm_srli_epi32(abs_vec, 4);                       // Shift right by 4 bits\n        }\n        \n        // Adjust sums for negative numbers\n        __m128i first_digit_sign = _mm_srai_epi32(vec, 31);             // Sign bit extraction\n        sum_vec = _mm_add_epi32(sum_vec, first_digit_sign);             // Adjust sum for negative numbers\n        \n        // Compare sums > 0 and create a mask\n        __m128i cmp = _mm_cmpgt_epi32(sum_vec, _mm_setzero_si128());\n        int mask = _mm_movemask_ps(_mm_castsi128_ps(cmp));              // Convert comparison result to bitmask\n        \n        // Count the number of elements with sum > 0\n        count += __builtin_popcount(mask);\n    }\n    \n    // Process remaining elements\n    for (; i < size; ++i) {\n        int num = n[i];\n        int sum = 0;\n        int temp = std::abs(num);\n        while (temp > 0) {\n            sum += temp % 10;\n            temp /= 10;\n        }\n        if (num < 0) sum -= 2 * (num % 10); // Adjust for negative numbers\n        if (sum > 0) ++count;\n    }\n    \n    return count;\n}\n```"}
{"task_id": "SimdBench_114_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint count_nums_simd(std::vector<int> n) {\n    int count = 0;\n    size_t i = 0;\n    size_t size = n.size();\n\n    // Process 4 integers at a time using SSE2 intrinsics\n    for (; i + 3 < size; i += 4) {\n        __m128i vec = _mm_loadu_si128((__m128i*)&n[i]); // Load 4 integers into SIMD register\n        __m128i sum_vec = _mm_setzero_si128();          // Initialize sum vector to zero\n\n        // Extract absolute values of the integers\n        __m128i sign_mask = _mm_cmpgt_epi32(_mm_setzero_si128(), vec); // Mask for negative numbers\n        __m128i abs_vec = _mm_sub_epi32(_mm_xor_si128(vec, sign_mask), sign_mask);\n\n        // Compute sum of digits for each integer in the vector\n        for (int digit = 0; digit < 4; ++digit) {\n            __m128i digit_val = _mm_and_si128(abs_vec, _mm_set1_epi32(0xF)); // Extract lowest digit\n            sum_vec = _mm_add_epi32(sum_vec, digit_val);                     // Add digit to sum\n            abs_vec = _mm_srli_epi32(abs_vec, 4);                            // Shift right to process next digit\n        }\n\n        // Adjust sums for negative numbers\n        __m128i first_digit_sign = _mm_srai_epi32(vec, 31);                  // Sign bit of original numbers\n        __m128i first_digit = _mm_and_si128(vec, _mm_set1_epi32(0xF));       // Extract first digit\n        __m128i adjusted_first_digit = _mm_sub_epi32(_mm_xor_si128(first_digit, first_digit_sign), first_digit_sign);\n        sum_vec = _mm_add_epi32(sum_vec, adjusted_first_digit);\n\n        // Compare sums with zero and create a mask\n        __m128i zero = _mm_setzero_si128();\n        __m128i cmp_mask = _mm_cmpgt_epi32(sum_vec, zero);\n\n        // Count elements where sum of digits > 0\n        int mask = _mm_movemask_ps(_mm_castsi128_ps(cmp_mask));\n        count += __builtin_popcount(mask);\n    }\n\n    // Process remaining elements\n    for (; i < size; ++i) {\n        int num = n[i];\n        int sum = 0;\n        int temp = std::abs(num);\n        while (temp > 0) {\n            sum += temp % 10;\n            temp /= 10;\n        }\n        if (num < 0) {\n            sum -= 2 * (std::abs(num) % 10);\n        }\n        if (sum > 0) {\n            ++count;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_114_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint count_nums_simd(std::vector<int> n) {\n    int count = 0;\n    size_t i = 0;\n    size_t size = n.size();\n\n    // Process 4 integers at a time using SSE2\n    for (; i + 4 <= size; i += 4) {\n        __m128i vec = _mm_loadu_si128((__m128i*)&n[i]); // Load 4 integers\n        __m128i sum_vec = _mm_setzero_si128();         // Initialize sum vector to zero\n\n        // Extract absolute values of the integers\n        __m128i sign_mask = _mm_cmpgt_epi32(_mm_setzero_si128(), vec); // Mask for negative numbers\n        __m128i abs_vec = _mm_sub_epi32(_mm_xor_si128(vec, sign_mask), sign_mask);\n\n        // Compute sum of digits for each integer in the vector\n        for (int j = 0; j < 4; ++j) {\n            __m128i digit_sum = _mm_setzero_si128();\n            __m128i num = _mm_shuffle_epi32(abs_vec, _MM_SHUFFLE(j, j, j, j)); // Isolate one integer\n\n            while (!_mm_testz_si128(num, num)) { // While num is not zero\n                __m128i digit = _mm_and_si128(num, _mm_set1_epi32(0xF)); // Extract last 4 bits\n                digit_sum = _mm_add_epi32(digit_sum, digit);              // Add to digit sum\n                num = _mm_srli_epi32(num, 4);                            // Shift right by 4 bits\n            }\n\n            // Check if the sum of digits is greater than 0\n            __m128i cmp = _mm_cmpgt_epi32(digit_sum, _mm_setzero_si128());\n            sum_vec = _mm_or_si128(sum_vec, _mm_slli_epi32(cmp, j * 8)); // Accumulate result\n        }\n\n        // Count how many elements have sum of digits > 0\n        int mask = _mm_movemask_epi8(sum_vec);\n        count += __builtin_popcount(mask);\n    }\n\n    // Process remaining elements\n    for (; i < size; ++i) {\n        int num = n[i];\n        int sum = 0;\n        int abs_num = std::abs(num);\n\n        while (abs_num > 0) {\n            sum += abs_num % 10;\n            abs_num /= 10;\n        }\n\n        if (sum > 0) {\n            ++count;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_115_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool move_one_ball_simd(std::vector<int> arr) {\n    int N = arr.size();\n    if (N == 0) return true;\n\n    int drop_count = 0;\n    __m128i prev = _mm_set1_epi32(arr[N - 1]);\n\n    for (int i = 0; i < N; i += 4) {\n        __m128i current = _mm_loadu_si128((__m128i*)&arr[i]);\n        __m128i cmp = _mm_cmpgt_epi32(prev, current);\n\n        int mask = _mm_movemask_ps(_mm_castsi128_ps(cmp));\n        drop_count += __builtin_popcount(mask);\n\n        if (drop_count > 1) return false;\n\n        prev = current;\n    }\n\n    // Handle the circular case\n    if (arr[N - 1] > arr[0]) drop_count++;\n\n    return drop_count <= 1;\n}\n```"}
{"task_id": "SimdBench_115_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nbool move_one_ball_simd(std::vector<int> arr) {\n    int N = arr.size();\n    if (N == 0) return true;\n\n    int drop_count = 0;\n    int last_index = N - 1;\n\n    // Align the array to 16 bytes for SIMD operations\n    __m128i* simd_arr = (__m128i*)arr.data();\n    int simd_iterations = N / 4;\n\n    for (int i = 0; i < simd_iterations; ++i) {\n        __m128i current = _mm_loadu_si128(simd_arr + i);\n        __m128i next = _mm_loadu_si128(simd_arr + i + 1);\n\n        // Compare current with next using SIMD\n        __m128i cmp = _mm_cmpgt_epi32(current, next);\n\n        // Move mask to extract comparison results\n        int mask = _mm_movemask_ps((__m128)cmp);\n\n        // Count the number of drops in this SIMD block\n        while (mask) {\n            drop_count += mask & 1;\n            mask >>= 1;\n        }\n    }\n\n    // Handle remaining elements that don't fit into SIMD blocks\n    int remainder = N % 4;\n    for (int i = N - remainder; i < N - 1; ++i) {\n        if (arr[i] > arr[i + 1]) {\n            drop_count++;\n        }\n    }\n\n    // Check the boundary between the last and first element\n    if (arr[last_index] > arr[0]) {\n        drop_count++;\n    }\n\n    return drop_count <= 1;\n}\n```"}
{"task_id": "SimdBench_115_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nbool move_one_ball_simd(std::vector<int> arr) {\n    int N = arr.size();\n    if (N == 0) return true;\n\n    // Count the number of drops in the array\n    int drop_count = 0;\n    int last_index = -1;\n\n    for (int i = 0; i < N; ++i) {\n        int next_i = (i + 1) % N;\n        if (arr[i] > arr[next_i]) {\n            drop_count++;\n            last_index = i;\n            if (drop_count > 1) {\n                return false;\n            }\n        }\n    }\n\n    // If there is one drop, check if rotating makes it sorted\n    if (drop_count == 1) {\n        int split_index = last_index + 1;\n        std::vector<int> rotated(N);\n        for (int i = 0; i < N; ++i) {\n            rotated[i] = arr[(split_index + i) % N];\n        }\n\n        // Use SIMD to verify if the rotated array is sorted\n        __m128i prev = _mm_set1_epi32(rotated[0]);\n        for (int i = 1; i < N; i += 4) {\n            __m128i curr = _mm_loadu_si128((__m128i*)&rotated[i]);\n            __m128i cmp = _mm_cmpgt_epi32(prev, curr);\n            if (_mm_movemask_epi8(cmp) != 0) {\n                return false;\n            }\n            prev = curr;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_115_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool move_one_ball_simd(std::vector<int> arr) {\n    int N = arr.size();\n    if (N == 0) return true;\n\n    // Count the number of drops in the array\n    int drop_count = 0;\n    int last_index = -1;\n\n    for (int i = 0; i < N; ++i) {\n        if (arr[i] > arr[(i + 1) % N]) {\n            drop_count++;\n            last_index = i;\n            if (drop_count > 1) {\n                return false;\n            }\n        }\n    }\n\n    // If there is no drop or exactly one drop, check conditions\n    if (drop_count == 0) {\n        return true;\n    } else if (drop_count == 1) {\n        return arr[N - 1] <= arr[0];\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_115_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nbool move_one_ball_simd(std::vector<int> arr) {\n    int N = arr.size();\n    if (N == 0) return true;\n\n    int drop_count = 0;\n    int i = 0;\n\n    // Process 4 elements at a time using SSE2 intrinsics\n    __m128i prev = _mm_set1_epi32(arr[0]);\n    for (; i <= N - 4; i += 4) {\n        __m128i current = _mm_loadu_si128((__m128i*)&arr[i]);\n        __m128i next = _mm_loadu_si128((__m128i*)&arr[i + 1]);\n\n        // Compare current with previous to detect drops\n        __m128i cmp = _mm_cmpgt_epi32(prev, current);\n        int mask = _mm_movemask_ps((__m128)cmp);\n\n        // Count the number of drops in this batch\n        while (mask) {\n            drop_count += mask & 1;\n            mask >>= 1;\n        }\n\n        // Update prev to the last element of current for next iteration\n        prev = _mm_shuffle_epi32(current, _MM_SHUFFLE(3, 3, 3, 3));\n    }\n\n    // Process remaining elements\n    for (; i < N; ++i) {\n        if (arr[i] < arr[(i - 1 + N) % N]) {\n            drop_count++;\n        }\n    }\n\n    return drop_count <= 1;\n}\n```"}
{"task_id": "SimdBench_116_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n\nstd::string myexchange_simd(const std::vector<int>& lst1, const std::vector<int>& lst2) {\n    int n1 = lst1.size();\n    int n2 = lst2.size();\n    int i = 0;\n\n    // Count the number of odd elements in lst1\n    __m128i v_odd_count = _mm_setzero_si128();\n    for (; i <= n1 - 4; i += 4) {\n        __m128i v_lst1 = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&lst1[i]));\n        __m128i v_mask = _mm_and_si128(v_lst1, _mm_set1_epi32(1)); // Check if odd\n        v_odd_count = _mm_add_epi32(v_odd_count, v_mask);\n    }\n\n    // Horizontal sum of odd counts from vector\n    int odd_count_lst1 = 0;\n    alignas(16) int temp[4];\n    _mm_store_si128(reinterpret_cast<__m128i*>(temp), v_odd_count);\n    odd_count_lst1 += temp[0] + temp[1] + temp[2] + temp[3];\n\n    // Process remaining elements in lst1\n    for (; i < n1; ++i) {\n        odd_count_lst1 += (lst1[i] & 1);\n    }\n\n    // Count the number of even elements in lst2\n    i = 0;\n    __m128i v_even_count = _mm_setzero_si128();\n    for (; i <= n2 - 4; i += 4) {\n        __m128i v_lst2 = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&lst2[i]));\n        __m128i v_mask = _mm_andnot_si128(_mm_and_si128(v_lst2, _mm_set1_epi32(1)), _mm_set1_epi32(1)); // Check if even\n        v_even_count = _mm_add_epi32(v_even_count, v_mask);\n    }\n\n    // Horizontal sum of even counts from vector\n    int even_count_lst2 = 0;\n    _mm_store_si128(reinterpret_cast<__m128i*>(temp), v_even_count);\n    even_count_lst2 += temp[0] + temp[1] + temp[2] + temp[3];\n\n    // Process remaining elements in lst2\n    for (; i < n2; ++i) {\n        even_count_lst2 += !(lst2[i] & 1);\n    }\n\n    // If the number of even elements in lst2 is greater than or equal to the number of odd elements in lst1\n    return (even_count_lst2 >= odd_count_lst1) ? \"YES\" : \"NO\";\n}\n```"}
{"task_id": "SimdBench_116_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n\nstd::string myexchange_simd(const std::vector<int>& lst1, const std::vector<int>& lst2) {\n    int n1 = lst1.size();\n    int n2 = lst2.size();\n    int i = 0;\n\n    // Counters for odd numbers in lst1 and even numbers in lst2\n    int odd_count_lst1 = 0;\n    int even_count_lst2 = 0;\n\n    // Process lst1 in chunks of 4 using SSE2 intrinsics\n    for (i = 0; i + 4 <= n1; i += 4) {\n        __m128i vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&lst1[i]));\n        __m128i mask = _mm_set1_epi32(1); // Mask to check if the number is odd\n        __m128i odd_check = _mm_and_si128(vec, mask);\n        int odd_mask = _mm_movemask_ps(_mm_castsi128_ps(odd_check));\n\n        // Count the number of odd elements in this chunk\n        odd_count_lst1 += __builtin_popcount(odd_mask);\n    }\n\n    // Process remaining elements in lst1\n    for (; i < n1; ++i) {\n        if (lst1[i] & 1) {\n            ++odd_count_lst1;\n        }\n    }\n\n    // Process lst2 in chunks of 4 using SSE2 intrinsics\n    for (i = 0; i + 4 <= n2; i += 4) {\n        __m128i vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&lst2[i]));\n        __m128i mask = _mm_set1_epi32(1); // Mask to check if the number is odd\n        __m128i even_check = _mm_andnot_si128(vec, mask);\n        int even_mask = _mm_movemask_ps(_mm_castsi128_ps(even_check));\n\n        // Count the number of even elements in this chunk\n        even_count_lst2 += __builtin_popcount(even_mask);\n    }\n\n    // Process remaining elements in lst2\n    for (; i < n2; ++i) {\n        if ((lst2[i] & 1) == 0) {\n            ++even_count_lst2;\n        }\n    }\n\n    // Check if the number of even numbers in lst2 is sufficient to replace all odd numbers in lst1\n    return (even_count_lst2 >= odd_count_lst1) ? \"YES\" : \"NO\";\n}\n```"}
{"task_id": "SimdBench_116_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <string>\n#include <vector>\n\nstd::string myexchange_simd(const std::vector<int>& lst1, const std::vector<int>& lst2) {\n    int n1 = lst1.size();\n    int n2 = lst2.size();\n    int i = 0;\n\n    // Counters for odd numbers in lst1 and even numbers in lst2\n    int odd_count_lst1 = 0;\n    int even_count_lst2 = 0;\n\n    // Process lst1 in chunks of 4 using SSE2 intrinsics\n    for (i = 0; i + 4 <= n1; i += 4) {\n        __m128i vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&lst1[i]));\n        __m128i mask = _mm_set1_epi32(1);\n        __m128i odd_check = _mm_and_si128(vec, mask);\n        int mask_result = _mm_movemask_ps(_mm_castsi128_ps(odd_check));\n        odd_count_lst1 += __builtin_popcount(mask_result);\n    }\n\n    // Process remaining elements in lst1\n    for (; i < n1; ++i) {\n        if (lst1[i] & 1) {\n            ++odd_count_lst1;\n        }\n    }\n\n    // Process lst2 in chunks of 4 using SSE2 intrinsics\n    for (i = 0; i + 4 <= n2; i += 4) {\n        __m128i vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&lst2[i]));\n        __m128i mask = _mm_set1_epi32(1);\n        __m128i even_check = _mm_and_si128(vec, mask);\n        int mask_result = _mm_movemask_ps(_mm_castsi128_ps(even_check));\n        even_count_lst2 += 4 - __builtin_popcount(mask_result);\n    }\n\n    // Process remaining elements in lst2\n    for (; i < n2; ++i) {\n        if ((lst2[i] & 1) == 0) {\n            ++even_count_lst2;\n        }\n    }\n\n    // Check if the number of even numbers in lst2 is sufficient to replace odd numbers in lst1\n    return (even_count_lst2 >= odd_count_lst1) ? \"YES\" : \"NO\";\n}\n```"}
{"task_id": "SimdBench_116_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n\nstd::string myexchange_simd(const std::vector<int>& lst1, const std::vector<int>& lst2) {\n    int n1 = lst1.size();\n    int n2 = lst2.size();\n    int i = 0;\n\n    // Count the number of odd elements in lst1 and even elements in lst2 using SIMD\n    int odd_count_lst1 = 0;\n    int even_count_lst2 = 0;\n\n    __m128i v_one = _mm_set1_epi32(1); // Vector of all ones (for modulo operation)\n\n    // Process lst1 in chunks of 4 integers\n    for (; i + 3 < n1; i += 4) {\n        __m128i v_lst1 = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&lst1[i])); // Load 4 integers from lst1\n        __m128i v_mod = _mm_and_si128(v_lst1, v_one); // Check if each element is odd (x & 1)\n        int mask = _mm_movemask_ps(_mm_castsi128_ps(v_mod)); // Extract the mask of odd elements\n        odd_count_lst1 += __builtin_popcount(mask); // Count the number of odd elements\n    }\n\n    // Process remaining elements in lst1\n    for (; i < n1; ++i) {\n        if (lst1[i] & 1) {\n            ++odd_count_lst1;\n        }\n    }\n\n    i = 0;\n\n    // Process lst2 in chunks of 4 integers\n    for (; i + 3 < n2; i += 4) {\n        __m128i v_lst2 = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&lst2[i])); // Load 4 integers from lst2\n        __m128i v_mod = _mm_and_si128(v_lst2, v_one); // Check if each element is odd (x & 1)\n        int mask = _mm_movemask_ps(_mm_castsi128_ps(v_mod)); // Extract the mask of odd elements\n        even_count_lst2 += 4 - __builtin_popcount(mask); // Count the number of even elements\n    }\n\n    // Process remaining elements in lst2\n    for (; i < n2; ++i) {\n        if ((lst2[i] & 1) == 0) {\n            ++even_count_lst2;\n        }\n    }\n\n    // If the number of odd elements in lst1 is less than or equal to the number of even elements in lst2, return \"YES\"\n    return (odd_count_lst1 <= even_count_lst2) ? \"YES\" : \"NO\";\n}\n```"}
{"task_id": "SimdBench_116_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n\nstd::string myexchange_simd(const std::vector<int>& lst1, const std::vector<int>& lst2) {\n    int n1 = lst1.size();\n    int n2 = lst2.size();\n    int i = 0;\n\n    // Counters for odd numbers in lst1 and even numbers in lst2\n    int odd_in_lst1 = 0;\n    int even_in_lst2 = 0;\n\n    // Process lst1 in chunks of 4 using SSE2 intrinsics\n    for (i = 0; i + 4 <= n1; i += 4) {\n        __m128i vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&lst1[i]));\n        __m128i mask = _mm_set1_epi32(1); // Mask to check if the number is odd\n        __m128i odd_check = _mm_and_si128(vec, mask);\n        int odd_mask = _mm_movemask_ps(_mm_castsi128_ps(odd_check));\n        odd_in_lst1 += __builtin_popcount(odd_mask);\n    }\n\n    // Process remaining elements in lst1\n    for (; i < n1; ++i) {\n        if (lst1[i] & 1) {\n            ++odd_in_lst1;\n        }\n    }\n\n    // Process lst2 in chunks of 4 using SSE2 intrinsics\n    for (i = 0; i + 4 <= n2; i += 4) {\n        __m128i vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&lst2[i]));\n        __m128i mask = _mm_set1_epi32(1); // Mask to check if the number is odd\n        __m128i odd_check = _mm_and_si128(vec, mask);\n        int odd_mask = _mm_movemask_ps(_mm_castsi128_ps(odd_check));\n        even_in_lst2 += 4 - __builtin_popcount(odd_mask);\n    }\n\n    // Process remaining elements in lst2\n    for (; i < n2; ++i) {\n        if ((lst2[i] & 1) == 0) {\n            ++even_in_lst2;\n        }\n    }\n\n    // Check if the number of odd numbers in lst1 can be replaced by even numbers from lst2\n    return (odd_in_lst1 <= even_in_lst2) ? \"YES\" : \"NO\";\n}\n```"}
{"task_id": "SimdBench_117_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n\nstd::vector<std::string> odd_count_simd(const std::vector<std::string> & lst) {\n    std::vector<std::string> result;\n    const char *template_str = \"the number of odd elements in the string X of the input.\";\n    __m128i odd_mask = _mm_set1_epi8(0x01); // Mask to check for odd digits (lowest bit set)\n\n    for (const auto &str : lst) {\n        int count = 0;\n        size_t len = str.size();\n        size_t i = 0;\n\n        // Process 16 characters at a time using SSE2\n        for (; i + 16 <= len; i += 16) {\n            __m128i chars = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&str[i]));\n            __m128i digits = _mm_sub_epi8(chars, _mm_set1_epi8('0')); // Convert chars to numeric values\n            __m128i is_odd = _mm_and_si128(digits, odd_mask); // Check if the lowest bit is set\n            __m128i cmp = _mm_cmpeq_epi8(is_odd, odd_mask); // Compare with mask\n            int mask = _mm_movemask_epi8(cmp); // Get a bitmask of comparisons\n            count += __builtin_popcount(mask); // Count the number of set bits\n        }\n\n        // Process remaining characters\n        for (; i < len; ++i) {\n            if ((str[i] - '0') & 1) {\n                ++count;\n            }\n        }\n\n        // Replace 'X' in the template string with the count\n        std::string output = template_str;\n        size_t pos = output.find('X');\n        if (pos != std::string::npos) {\n            output.replace(pos, 1, std::to_string(count));\n        }\n        result.push_back(output);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_117_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n\nstd::vector<std::string> odd_count_simd(const std::vector<std::string> & lst) {\n    std::vector<std::string> result;\n    const char *template_str = \"the number of odd elements in the string X of the input.\";\n    __m128i odd_mask = _mm_set1_epi8(0x01); // Mask to check if a digit is odd\n\n    for (const auto &str : lst) {\n        int count = 0;\n        size_t len = str.size();\n        size_t i = 0;\n\n        // Process 16 characters at a time using SSE\n        for (; i + 16 <= len; i += 16) {\n            __m128i data = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&str[i]));\n            __m128i digits = _mm_sub_epi8(data, _mm_set1_epi8('0')); // Convert chars to integers\n            __m128i is_odd = _mm_and_si128(digits, odd_mask); // Check oddness\n            __m128i cmp = _mm_cmpeq_epi8(is_odd, odd_mask); // Compare with mask\n            int mask = _mm_movemask_epi8(cmp); // Get bitmask of results\n            count += __builtin_popcount(mask); // Count set bits\n        }\n\n        // Process remaining characters\n        for (; i < len; ++i) {\n            if ((str[i] - '0') & 1) {\n                ++count;\n            }\n        }\n\n        // Replace 'X' in the template string with the count\n        std::string output = template_str;\n        size_t pos = output.find('X');\n        if (pos != std::string::npos) {\n            output.replace(pos, 1, std::to_string(count));\n        }\n        result.push_back(output);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_117_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n\nstd::vector<std::string> odd_count_simd(const std::vector<std::string> & lst) {\n    std::vector<std::string> result;\n    const char *template_str = \"the number of odd elements in the string X of the input.\";\n    __m128i odd_mask = _mm_set1_epi8(0x01); // Mask to check for odd digits (lowest bit set)\n\n    for (const auto &str : lst) {\n        int count = 0;\n        size_t len = str.size();\n        size_t i = 0;\n\n        // Process 16 characters at a time using SSE2\n        for (; i + 16 <= len; i += 16) {\n            __m128i chars = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&str[i]));\n            __m128i digits = _mm_sub_epi8(chars, _mm_set1_epi8('0')); // Convert ASCII to numeric value\n            __m128i is_odd = _mm_and_si128(digits, odd_mask); // Check if the lowest bit is set\n            __m128i is_digit = _mm_and_si128(_mm_cmpgt_epi8(digits, _mm_set1_epi8(-1)), \n                                             _mm_cmpgt_epi8(_mm_set1_epi8(9), digits)); // Ensure valid digit\n            __m128i valid_odd = _mm_and_si128(is_odd, is_digit);\n            int mask = _mm_movemask_epi8(valid_odd);\n            count += __builtin_popcount(mask);\n        }\n\n        // Process remaining characters\n        for (; i < len; ++i) {\n            char c = str[i];\n            if (c >= '0' && c <= '9' && ((c - '0') & 1)) {\n                ++count;\n            }\n        }\n\n        // Replace 'X' in the template with the count\n        std::string output = template_str;\n        size_t pos = output.find('X');\n        if (pos != std::string::npos) {\n            output.replace(pos, 1, std::to_string(count));\n        }\n        result.push_back(output);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_117_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n\nstd::vector<std::string> odd_count_simd(const std::vector<std::string> & lst) {\n    std::vector<std::string> result;\n    const char *template_str = \"the number of odd elements in the string X of the input.\";\n    __m128i odd_mask = _mm_set1_epi8(0x01); // Mask to check for odd digits (lowest bit set)\n\n    for (const auto &str : lst) {\n        int count = 0;\n        size_t len = str.size();\n        size_t i = 0;\n\n        // Process 16 characters at a time using SSE2\n        for (; i + 16 <= len; i += 16) {\n            __m128i chars = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&str[i]));\n            __m128i digits = _mm_sub_epi8(chars, _mm_set1_epi8('0')); // Convert chars to numeric values\n            __m128i is_odd = _mm_and_si128(digits, odd_mask); // Check if the lowest bit is set\n            __m128i cmp = _mm_cmpeq_epi8(is_odd, odd_mask); // Compare with mask\n            int mask = _mm_movemask_epi8(cmp); // Get a bitmask of comparisons\n            count += __builtin_popcount(mask); // Count the number of set bits\n        }\n\n        // Process remaining characters\n        for (; i < len; ++i) {\n            if ((str[i] - '0') & 1) {\n                ++count;\n            }\n        }\n\n        // Replace 'X' in the template string with the count\n        std::string output = template_str;\n        size_t pos = output.find('X');\n        if (pos != std::string::npos) {\n            output.replace(pos, 1, std::to_string(count));\n        }\n        result.push_back(output);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_117_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <string>\n\nstd::vector<std::string> odd_count_simd(const std::vector<std::string> & lst) {\n    std::vector<std::string> result;\n    const char *template_str = \"the number of odd elements in the string X of the input.\";\n    __m128i odd_mask = _mm_set1_epi8(0x01); // Mask to check for odd digits (lowest bit set)\n\n    for (const auto &str : lst) {\n        int count = 0;\n        size_t len = str.size();\n        size_t i = 0;\n\n        // Process 16 characters at a time using SSE2\n        for (; i + 16 <= len; i += 16) {\n            __m128i chars = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&str[i]));\n            __m128i digits = _mm_sub_epi8(chars, _mm_set1_epi8('0')); // Convert chars to numeric values\n            __m128i is_odd = _mm_and_si128(digits, odd_mask); // Check if the lowest bit is set\n            __m128i is_digit = _mm_and_si128(_mm_cmpgt_epi8(digits, _mm_set1_epi8(-1)), \n                                             _mm_cmpgt_epi8(_mm_set1_epi8(9), digits)); // Ensure valid digit\n            __m128i valid_odd = _mm_and_si128(is_odd, is_digit);\n            int mask = _mm_movemask_epi8(valid_odd);\n            count += __builtin_popcount(mask); // Count the number of odd digits\n        }\n\n        // Process remaining characters\n        for (; i < len; ++i) {\n            char c = str[i];\n            if (c >= '0' && c <= '9' && (c - '0') % 2 != 0) {\n                ++count;\n            }\n        }\n\n        // Replace 'X' in the template with the count\n        std::string output = template_str;\n        size_t pos = output.find('X');\n        if (pos != std::string::npos) {\n            output.replace(pos, 1, std::to_string(count));\n        }\n        result.push_back(output);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_118_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint64_t minSubArraySum_simd(const std::vector<int64_t>& nums) {\n    if (nums.empty()) return 0;\n\n    __m128i current_min = _mm_set1_epi64x(0);\n    __m128i global_min = _mm_set1_epi64x(nums[0]);\n    __m128i temp;\n\n    size_t i = 0;\n    size_t size = nums.size();\n\n    // Process 2 elements at a time using SSE2\n    for (; i + 1 < size; i += 2) {\n        __m128i vec = _mm_set_epi64x(nums[i + 1], nums[i]);\n\n        // Update current_min: current_min = min(current_min + vec, vec)\n        __m128i current_plus_vec = _mm_add_epi64(current_min, vec);\n        current_min = _mm_min_epi64(current_plus_vec, vec);\n\n        // Update global_min: global_min = min(global_min, current_min)\n        global_min = _mm_min_epi64(global_min, current_min);\n    }\n\n    // Extract the minimum value from the SIMD register\n    int64_t result[2];\n    _mm_storeu_si128((__m128i*)result, global_min);\n    int64_t min_sum = std::min(result[0], result[1]);\n\n    // Handle any remaining elements\n    for (; i < size; ++i) {\n        int64_t num = nums[i];\n        min_sum = std::min(min_sum + num, num);\n        min_sum = std::min(min_sum, num);\n    }\n\n    return min_sum;\n}\n```"}
{"task_id": "SimdBench_118_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint64_t minSubArraySum_simd(const std::vector<int64_t>& nums) {\n    if (nums.empty()) return 0;\n\n    __m128i current_min = _mm_set1_epi64x(0);\n    __m128i global_min = _mm_set1_epi64x(nums[0]);\n\n    size_t i = 0;\n    size_t size = nums.size();\n\n    // Process 2 elements at a time using SSE2\n    for (; i + 1 < size; i += 2) {\n        __m128i vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&nums[i]));\n\n        // Add the current pair of numbers to current_min\n        current_min = _mm_add_epi64(current_min, vec);\n\n        // Compare current_min with global_min and update global_min\n        global_min = _mm_min_epi64(global_min, current_min);\n\n        // Reset current_min if it becomes positive\n        __m128i zero = _mm_set1_epi64x(0);\n        __m128i mask = _mm_cmpgt_epi64(zero, current_min);\n        current_min = _mm_and_si128(mask, current_min);\n    }\n\n    // Extract minimum from the SIMD register\n    int64_t result[2];\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(result), global_min);\n    int64_t min_sum = std::min(result[0], result[1]);\n\n    // Process remaining elements\n    for (; i < size; ++i) {\n        min_sum = std::min(min_sum, std::min(nums[i], min_sum + nums[i]));\n    }\n\n    return min_sum;\n}\n```"}
{"task_id": "SimdBench_118_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint64_t minSubArraySum_simd(const std::vector<int64_t>& nums) {\n    if (nums.empty()) return 0;\n\n    __m128i current_min = _mm_set1_epi64x(0);\n    __m128i global_min = _mm_set1_epi64x(nums[0]);\n    __m128i zero = _mm_set1_epi64x(0);\n\n    size_t i = 0;\n    size_t size = nums.size();\n\n    // Process 2 elements at a time using SSE2\n    for (; i + 1 < size; i += 2) {\n        __m128i vec = _mm_set_epi64x(nums[i + 1], nums[i]);\n\n        // Update current_min: current_min = min(0, current_min + vec)\n        __m128i temp_sum = _mm_add_epi64(current_min, vec);\n        current_min = _mm_min_epi64(zero, temp_sum);\n\n        // Update global_min: global_min = min(global_min, current_min)\n        global_min = _mm_min_epi64(global_min, current_min);\n    }\n\n    // Extract the minimum value from the SIMD register\n    int64_t result[2];\n    _mm_storeu_si128((__m128i*)result, global_min);\n    int64_t min_val = std::min(result[0], result[1]);\n\n    // Handle any remaining elements\n    for (; i < size; ++i) {\n        min_val = std::min(min_val, nums[i]);\n    }\n\n    return min_val;\n}\n```"}
{"task_id": "SimdBench_118_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint64_t minSubArraySum_simd(const std::vector<int64_t>& nums) {\n    if (nums.empty()) return 0;\n\n    __m128i current_min = _mm_set1_epi64x(0);\n    __m128i global_min = _mm_set1_epi64x(nums[0]);\n    \n    size_t i = 0;\n    size_t size = nums.size();\n\n    // Process 2 elements at a time using SSE2\n    for (; i + 1 < size; i += 2) {\n        __m128i vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&nums[i]));\n\n        // Add the current pair of numbers to current_min\n        current_min = _mm_add_epi64(current_min, vec);\n\n        // Compare current_min with global_min and update global_min\n        global_min = _mm_min_epi64(global_min, current_min);\n\n        // Reset current_min if it becomes positive\n        __m128i zero = _mm_set1_epi64x(0);\n        __m128i cmp = _mm_cmpgt_epi64(current_min, zero);\n        current_min = _mm_blendv_epi8(current_min, zero, cmp);\n    }\n\n    // Extract minimum from the SIMD register\n    int64_t result[2];\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(result), global_min);\n    int64_t min_sum = std::min(result[0], result[1]);\n\n    // Handle any remaining elements\n    for (; i < size; ++i) {\n        min_sum = std::min(min_sum, std::min(nums[i], min_sum + nums[i]));\n    }\n\n    return min_sum;\n}\n```"}
{"task_id": "SimdBench_118_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint64_t minSubArraySum_simd(const std::vector<int64_t>& nums) {\n    __m128i vmin = _mm_set1_epi64x(INT64_MAX);\n    __m128i vcurrent = _mm_set1_epi64x(0);\n    __m128i vglobal_min = _mm_set1_epi64x(INT64_MAX);\n\n    size_t i = 0;\n    size_t n = nums.size();\n\n    // Process 2 elements at a time using SSE2\n    for (; i + 1 < n; i += 2) {\n        __m128i vnums = _mm_set_epi64x(nums[i + 1], nums[i]);\n        vcurrent = _mm_add_epi64(vcurrent, vnums);\n        vmin = _mm_min_epi64(vmin, vcurrent);\n        vglobal_min = _mm_min_epi64(vglobal_min, vmin);\n\n        // Reset current sum if it becomes positive\n        __m128i vzero = _mm_set1_epi64x(0);\n        __m128i vcmp = _mm_cmpgt_epi64(vcurrent, vzero);\n        vcurrent = _mm_blendv_epi8(vcurrent, vzero, vcmp);\n    }\n\n    // Extract minimum from SIMD registers\n    int64_t result[2];\n    _mm_storeu_si128((__m128i*)result, vglobal_min);\n    int64_t min_sum = std::min(result[0], result[1]);\n\n    // Handle remaining elements\n    for (; i < n; ++i) {\n        int64_t current = 0;\n        int64_t local_min = INT64_MAX;\n        current += nums[i];\n        local_min = std::min(local_min, current);\n        min_sum = std::min(min_sum, local_min);\n        if (current > 0) current = 0;\n    }\n\n    return min_sum;\n}\n```"}
{"task_id": "SimdBench_119_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint max_fill_simd(const std::vector<std::vector<int> > & grid, int capacity) {\n    int total_water = 0;\n\n    for (const auto& row : grid) {\n        int i = 0;\n        int row_size = row.size();\n\n        // Process 16 elements at a time using SSE2\n        for (; i + 16 <= row_size; i += 16) {\n            __m128i vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&row[i]));\n            __m128i ones = _mm_set1_epi32(1);\n            __m128i masked = _mm_and_si128(vec, ones);\n\n            // Horizontal sum of the 16 elements\n            __m128i sum_vec = _mm_sad_epu8(masked, _mm_setzero_si128());\n            int sum = _mm_extract_epi16(sum_vec, 0) + _mm_extract_epi16(sum_vec, 4);\n            total_water += sum;\n        }\n\n        // Process remaining elements\n        for (; i < row_size; ++i) {\n            total_water += row[i];\n        }\n    }\n\n    // Calculate the number of bucket operations\n    return (total_water + capacity - 1) / capacity;\n}\n```"}
{"task_id": "SimdBench_119_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint max_fill_simd(const std::vector<std::vector<int>> &grid, int capacity) {\n    int total_water = 0;\n\n    for (const auto &row : grid) {\n        int i = 0;\n        int row_size = row.size();\n\n        // Process 16 elements at a time using SSE2\n        for (; i + 16 <= row_size; i += 16) {\n            __m128i vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&row[i]));\n            __m128i ones = _mm_set1_epi32(1);\n            __m128i cmp = _mm_cmpeq_epi32(vec, ones);\n            int mask = _mm_movemask_ps(_mm_castsi128_ps(cmp));\n            total_water += __builtin_popcount(mask);\n        }\n\n        // Process remaining elements\n        for (; i < row_size; ++i) {\n            total_water += row[i];\n        }\n    }\n\n    return (total_water + capacity - 1) / capacity;\n}\n```"}
{"task_id": "SimdBench_119_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint max_fill_simd(const std::vector<std::vector<int> > & grid, int capacity) {\n    int total_water = 0;\n    int rows = grid.size();\n    int cols = rows > 0 ? grid[0].size() : 0;\n\n    // Process each row of the grid\n    for (int i = 0; i < rows; ++i) {\n        const int *row_data = grid[i].data();\n        int j = 0;\n\n        // Process 16 bytes (128 bits) at a time using SSE2\n        for (; j + 16 <= cols; j += 16) {\n            __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(row_data + j));\n            __m128i ones = _mm_set1_epi32(0x01010101); // Mask to count bits\n            __m128i masked = _mm_and_si128(chunk, ones);\n            int horizontal_sum = _mm_movemask_epi8(masked);\n            total_water += __builtin_popcount(horizontal_sum);\n        }\n\n        // Process remaining elements in the row\n        for (; j < cols; ++j) {\n            total_water += row_data[j];\n        }\n    }\n\n    // Calculate the number of bucket operations\n    return (total_water + capacity - 1) / capacity;\n}\n```"}
{"task_id": "SimdBench_119_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint max_fill_simd(const std::vector<std::vector<int> > & grid, int capacity) {\n    int total_water = 0;\n    for (const auto& row : grid) {\n        int i = 0;\n        int size = row.size();\n        __m128i sum_vec = _mm_setzero_si128();\n\n        // Process 16 elements at a time using SSE\n        for (; i + 16 <= size; i += 16) {\n            __m128i data = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&row[i]));\n            __m128i ones = _mm_set1_epi32(1);\n            __m128i mask = _mm_cmpeq_epi32(data, ones);\n            sum_vec = _mm_add_epi32(sum_vec, _mm_and_si128(mask, ones));\n        }\n\n        // Horizontal sum of the vector\n        int temp[4];\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(temp), sum_vec);\n        total_water += temp[0] + temp[1] + temp[2] + temp[3];\n\n        // Process remaining elements\n        for (; i < size; ++i) {\n            total_water += row[i];\n        }\n    }\n\n    // Calculate the number of bucket operations\n    return (total_water + capacity - 1) / capacity;\n}\n```"}
{"task_id": "SimdBench_119_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint max_fill_simd(const std::vector<std::vector<int> > & grid, int capacity) {\n    int total_water = 0;\n    int rows = grid.size();\n    int cols = rows > 0 ? grid[0].size() : 0;\n\n    // Process each row of the grid\n    for (int i = 0; i < rows; ++i) {\n        const int *row_data = grid[i].data();\n        int j = 0;\n\n        // Process 16 bytes (128 bits) at a time using SSE2\n        for (; j + 16 <= cols; j += 16) {\n            __m128i chunk = _mm_loadu_si128(reinterpret_cast<const __m128i*>(row_data + j));\n            __m128i ones = _mm_set1_epi32(1);\n            __m128i mask = _mm_cmpeq_epi32(chunk, ones);\n\n            // Count the number of 1s in the current chunk\n            int mask_bits = _mm_movemask_epi8(mask);\n            total_water += __builtin_popcount(mask_bits);\n        }\n\n        // Process remaining elements in the row\n        for (; j < cols; ++j) {\n            total_water += row_data[j];\n        }\n    }\n\n    // Calculate the number of bucket operations needed\n    return (total_water + capacity - 1) / capacity;\n}\n```"}
{"task_id": "SimdBench_120_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint64_t solution_simd(const std::vector<int16_t>& lst) {\n    __m128i vsum = _mm_setzero_si128();\n    int64_t result = 0;\n\n    size_t i = 0;\n    size_t size = lst.size();\n\n    // Ensure we process elements in chunks of 8\n    for (; i + 7 < size; i += 8) {\n        // Load 8 elements from the vector into an SSE register\n        __m128i vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&lst[i]));\n\n        // Create a mask to select even positions (0, 2, 4, 6)\n        __m128i mask_even_pos = _mm_set_epi16(0, -1, 0, -1, 0, -1, 0, -1);\n        __m128i even_elements = _mm_and_si128(vec, mask_even_pos);\n\n        // Check for odd values using bitwise AND with 1\n        __m128i is_odd = _mm_and_si128(even_elements, _mm_set1_epi16(1));\n\n        // Compare to filter only odd values\n        __m128i odd_mask = _mm_cmpeq_epi16(is_odd, _mm_set1_epi16(1));\n        __m128i filtered_odds = _mm_and_si128(even_elements, odd_mask);\n\n        // Add the filtered odd values to the sum\n        vsum = _mm_add_epi16(vsum, filtered_odds);\n    }\n\n    // Horizontal sum of the SSE register\n    int16_t temp[8];\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(temp), vsum);\n    for (int j = 0; j < 8; ++j) {\n        result += temp[j];\n    }\n\n    // Process remaining elements\n    for (; i < size; ++i) {\n        if ((i % 2 == 0) && (lst[i] % 2 != 0)) {\n            result += lst[i];\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_120_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint64_t solution_simd(const std::vector<int16_t>& lst) {\n    int64_t result = 0;\n    size_t i = 0;\n    size_t n = lst.size();\n\n    // Ensure the vector has at least 8 elements for SIMD processing\n    while (i + 8 <= n) {\n        // Load 8 elements into an SSE register\n        __m128i vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&lst[i]));\n\n        // Create a mask to select even positions: 0xFFFF for even indices, 0x0000 for odd indices\n        __m128i mask_even_pos = _mm_set_epi16(0, 0xFFFF, 0, 0xFFFF, 0, 0xFFFF, 0, 0xFFFF);\n\n        // Mask out elements in odd positions\n        __m128i even_pos_values = _mm_and_si128(vec, mask_even_pos);\n\n        // Check for odd values using bitwise AND with 1\n        __m128i odd_mask = _mm_set1_epi16(1);\n        __m128i is_odd = _mm_and_si128(even_pos_values, odd_mask);\n\n        // Compare to filter only odd values\n        __m128i cmp_mask = _mm_cmpeq_epi16(is_odd, odd_mask);\n\n        // Blend original values with zeros based on the comparison mask\n        __m128i filtered_values = _mm_and_si128(even_pos_values, cmp_mask);\n\n        // Horizontally add the values in the SIMD register\n        __m128i sum_vec = _mm_hadd_epi16(filtered_values, filtered_values);\n        sum_vec = _mm_hadd_epi16(sum_vec, sum_vec);\n\n        // Extract the final sum from the SIMD register\n        int16_t temp[8];\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(temp), sum_vec);\n        result += temp[0];\n\n        // Move to the next block of 8 elements\n        i += 8;\n    }\n\n    // Process remaining elements (if any) using scalar code\n    for (; i < n; ++i) {\n        if ((i % 2 == 0) && (lst[i] % 2 != 0)) {\n            result += lst[i];\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_120_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint64_t solution_simd(const std::vector<int16_t>& lst) {\n    int64_t result = 0;\n    size_t i = 0;\n    size_t n = lst.size();\n\n    // Ensure the vector has at least 8 elements for SIMD processing\n    while (i + 8 <= n) {\n        // Load 8 elements into an SSE register\n        __m128i vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&lst[i]));\n\n        // Create a mask to isolate even positions (0, 2, 4, 6)\n        __m128i mask_even_pos = _mm_set_epi16(0, -1, 0, -1, 0, -1, 0, -1);\n        __m128i even_pos = _mm_and_si128(vec, mask_even_pos);\n\n        // Check for odd numbers (num & 1 != 0)\n        __m128i odd_mask = _mm_and_si128(even_pos, _mm_set1_epi16(1));\n        __m128i is_odd = _mm_cmpeq_epi16(odd_mask, _mm_set1_epi16(1));\n\n        // Blend only odd numbers from even positions\n        __m128i filtered = _mm_and_si128(even_pos, is_odd);\n\n        // Horizontal sum of the filtered values\n        int16_t temp[8];\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(temp), filtered);\n        for (size_t j = 0; j < 8; ++j) {\n            result += temp[j];\n        }\n\n        i += 8;\n    }\n\n    // Process remaining elements\n    for (; i < n; ++i) {\n        if ((i % 2 == 0) && (lst[i] % 2 != 0)) {\n            result += lst[i];\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_120_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint64_t solution_simd(const std::vector<int16_t>& lst) {\n    int64_t result = 0;\n    size_t i = 0;\n    size_t size = lst.size();\n\n    // Ensure the vector has at least 8 elements for SIMD processing\n    while (i + 8 <= size) {\n        // Load 8 elements into an SSE register\n        __m128i vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&lst[i]));\n\n        // Create a mask to isolate even positions (0, 2, 4, 6)\n        __m128i mask_even_pos = _mm_set_epi16(0, -1, 0, -1, 0, -1, 0, -1);\n        __m128i even_pos = _mm_and_si128(vec, mask_even_pos);\n\n        // Check for odd values in the even positions\n        __m128i odd_check = _mm_and_si128(even_pos, _mm_set1_epi16(1));\n        __m128i odd_mask = _mm_cmpeq_epi16(odd_check, _mm_set1_epi16(1));\n\n        // Combine the masks to filter odd values in even positions\n        __m128i filtered = _mm_and_si128(even_pos, odd_mask);\n\n        // Horizontal sum of the filtered values\n        int16_t temp[8];\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(temp), filtered);\n        for (int j = 0; j < 8; ++j) {\n            result += temp[j];\n        }\n\n        i += 8;\n    }\n\n    // Process remaining elements\n    for (; i < size; ++i) {\n        if ((i % 2 == 0) && (lst[i] % 2 != 0)) {\n            result += lst[i];\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_120_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint64_t solution_simd(const std::vector<int16_t>& lst) {\n    int64_t result = 0;\n    size_t i = 0;\n    size_t size = lst.size();\n\n    // Ensure the vector has at least 8 elements for SIMD processing\n    size_t simd_size = size - (size % 8);\n    __m128i vsum = _mm_setzero_si128();\n\n    for (; i < simd_size; i += 8) {\n        // Load 8 elements into a SIMD register\n        __m128i vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&lst[i]));\n\n        // Create a mask to select even positions: 0xFFFF for even indices, 0x0000 for odd indices\n        __m128i mask_even_pos = _mm_set_epi16(0, 0xFFFF, 0, 0xFFFF, 0, 0xFFFF, 0, 0xFFFF);\n\n        // Mask out elements in odd positions\n        __m128i even_pos_elements = _mm_and_si128(vec, mask_even_pos);\n\n        // Check for odd values using bitwise AND with 1\n        __m128i odd_mask = _mm_set1_epi16(1);\n        __m128i is_odd = _mm_and_si128(even_pos_elements, odd_mask);\n\n        // Compare to create a mask of odd values\n        __m128i odd_value_mask = _mm_cmpeq_epi16(is_odd, odd_mask);\n\n        // Use the mask to zero out non-odd values\n        __m128i odd_values = _mm_and_si128(even_pos_elements, odd_value_mask);\n\n        // Accumulate the odd values\n        vsum = _mm_add_epi16(vsum, odd_values);\n    }\n\n    // Horizontal sum of the SIMD register\n    int16_t temp[8];\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(temp), vsum);\n    for (int j = 0; j < 8; ++j) {\n        result += temp[j];\n    }\n\n    // Process remaining elements\n    for (; i < size; ++i) {\n        if ((i % 2 == 0) && (lst[i] % 2 != 0)) {\n            result += lst[i];\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_121_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint add_elements_simd(std::vector<int> arr, int k) {\n    int sum = 0;\n    int i = 0;\n\n    // Process 4 elements at a time using SSE2 intrinsics\n    for (; i <= k - 4; i += 4) {\n        // Load 4 integers into an SSE register\n        __m128i vec = _mm_loadu_si128((__m128i*)&arr[i]);\n\n        // Create a mask to check if the absolute values are less than 100 (two digits or less)\n        __m128i abs_vec = _mm_abs_epi32(vec);\n        __m128i cmp_mask = _mm_cmplt_epi32(abs_vec, _mm_set1_epi32(100));\n\n        // Use the mask to zero out elements that don't meet the condition\n        __m128i masked_vec = _mm_and_si128(vec, cmp_mask);\n\n        // Horizontally add the elements in the vector\n        int temp[4];\n        _mm_storeu_si128((__m128i*)temp, masked_vec);\n        sum += temp[0] + temp[1] + temp[2] + temp[3];\n    }\n\n    // Process any remaining elements\n    for (; i < k; ++i) {\n        if (arr[i] >= -99 && arr[i] <= 99) {\n            sum += arr[i];\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_121_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint add_elements_simd(std::vector<int> arr, int k) {\n    int sum = 0;\n    int i = 0;\n\n    // Process 4 elements at a time using SSE2 intrinsics\n    for (; i <= k - 4; i += 4) {\n        // Load 4 integers into an SSE register\n        __m128i vec = _mm_loadu_si128((__m128i*)&arr[i]);\n\n        // Create a mask to check if the absolute values are less than 100 (two-digit numbers)\n        __m128i abs_vec = _mm_abs_epi32(vec);\n        __m128i cmp = _mm_cmplt_epi32(abs_vec, _mm_set1_epi32(100));\n\n        // Mask out values that do not satisfy the condition\n        __m128i masked = _mm_and_si128(vec, cmp);\n\n        // Horizontally add the valid elements in the vector\n        int temp[4];\n        _mm_storeu_si128((__m128i*)temp, masked);\n        sum += temp[0] + temp[1] + temp[2] + temp[3];\n    }\n\n    // Process remaining elements (less than 4)\n    for (; i < k; ++i) {\n        if (arr[i] >= -99 && arr[i] <= 99) {\n            sum += arr[i];\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_121_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint add_elements_simd(std::vector<int> arr, int k) {\n    int result = 0;\n    int i = 0;\n\n    // Process 4 elements at a time using SSE2 intrinsics\n    for (; i <= k - 4; i += 4) {\n        // Load 4 integers into an SSE register\n        __m128i vec = _mm_loadu_si128((__m128i*)&arr[i]);\n\n        // Create a mask to check if the absolute values are less than 100 (two-digit numbers)\n        __m128i abs_vec = _mm_abs_epi32(vec);\n        __m128i cmp = _mm_cmplt_epi32(abs_vec, _mm_set1_epi32(100));\n\n        // Mask out elements that do not satisfy the condition\n        __m128i masked = _mm_and_si128(vec, cmp);\n\n        // Horizontally sum the valid elements in the vector\n        int temp[4];\n        _mm_storeu_si128((__m128i*)temp, masked);\n        result += temp[0] + temp[1] + temp[2] + temp[3];\n    }\n\n    // Process remaining elements (if any)\n    for (; i < k; ++i) {\n        if (arr[i] >= -99 && arr[i] <= 99) {\n            result += arr[i];\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_121_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint add_elements_simd(std::vector<int> arr, int k) {\n    int result = 0;\n    int i = 0;\n\n    // Process 4 elements at a time using SSE2 intrinsics\n    for (; i <= k - 4; i += 4) {\n        // Load 4 integers into an SSE register\n        __m128i vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&arr[i]));\n\n        // Create a mask to check if the absolute values are less than 100\n        __m128i abs_vec = _mm_abs_epi32(vec);\n        __m128i cmp = _mm_cmplt_epi32(abs_vec, _mm_set1_epi32(100));\n\n        // Mask out elements that do not satisfy the condition\n        __m128i masked = _mm_and_si128(vec, cmp);\n\n        // Horizontally add the valid elements\n        int temp[4];\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(temp), masked);\n        result += temp[0] + temp[1] + temp[2] + temp[3];\n    }\n\n    // Process remaining elements\n    for (; i < k; ++i) {\n        if (arr[i] >= -99 && arr[i] <= 99) {\n            result += arr[i];\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_121_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint add_elements_simd(std::vector<int> arr, int k) {\n    int result = 0;\n    int i = 0;\n\n    // Process 4 elements at a time using SSE2 intrinsics\n    for (; i <= k - 4; i += 4) {\n        // Load 4 integers into an SSE register\n        __m128i vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&arr[i]));\n\n        // Create a mask to check if the absolute value of each element is less than 100\n        __m128i abs_vec = _mm_abs_epi32(vec);\n        __m128i cmp = _mm_cmplt_epi32(abs_vec, _mm_set1_epi32(100));\n\n        // Mask out elements that do not satisfy the condition\n        __m128i masked = _mm_and_si128(vec, cmp);\n\n        // Horizontally add the valid elements in the vector\n        int temp[4];\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(temp), masked);\n        result += temp[0] + temp[1] + temp[2] + temp[3];\n    }\n\n    // Process remaining elements (if any)\n    for (; i < k; ++i) {\n        if (arr[i] >= -99 && arr[i] <= 99) {\n            result += arr[i];\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_122_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool is_sorted_simd(const std::vector<int> & lst) {\n    size_t n = lst.size();\n    if (n <= 1) return true;\n\n    // Ensure the vector size is a multiple of 4 for SIMD processing\n    size_t simd_size = (n / 4) * 4;\n    __m128i prev = _mm_set1_epi32(lst[0]);\n    bool has_duplicate = false;\n\n    for (size_t i = 0; i < simd_size; i += 4) {\n        // Load 4 integers into a SIMD register\n        __m128i current = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&lst[i]));\n\n        // Check for sorting: current >= prev\n        __m128i cmp_sorted = _mm_cmpgt_epi32(prev, current);\n        if (_mm_movemask_epi8(cmp_sorted) != 0) {\n            return false; // Not sorted\n        }\n\n        // Check for duplicates: current == prev\n        __m128i cmp_eq = _mm_cmpeq_epi32(prev, current);\n        int mask_eq = _mm_movemask_epi8(cmp_eq);\n        if (mask_eq != 0) {\n            has_duplicate = true;\n        }\n\n        prev = current;\n    }\n\n    // Handle remaining elements (if any)\n    for (size_t i = simd_size; i < n; ++i) {\n        if (lst[i] < lst[i - 1]) {\n            return false; // Not sorted\n        }\n        if (lst[i] == lst[i - 1]) {\n            has_duplicate = true;\n        }\n    }\n\n    // Check for more than one duplicate\n    if (has_duplicate) {\n        int count = 1;\n        for (size_t i = 1; i < n; ++i) {\n            if (lst[i] == lst[i - 1]) {\n                ++count;\n                if (count > 2) {\n                    return false; // More than one duplicate\n                }\n            } else {\n                count = 1;\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_122_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool is_sorted_simd(const std::vector<int> & lst) {\n    size_t n = lst.size();\n    if (n <= 1) return true;\n\n    // Ensure the vector is aligned for SIMD operations\n    const int * data = lst.data();\n    size_t i = 0;\n\n    __m128i prev = _mm_set1_epi32(0); // Initialize to zero\n    __m128i count = _mm_setzero_si128(); // For duplicate counting\n\n    for (; i + 4 <= n; i += 4) {\n        __m128i current = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&data[i]));\n\n        // Check ascending order: current >= prev\n        __m128i cmp = _mm_cmpgt_epi32(prev, current);\n        if (_mm_movemask_epi8(cmp)) {\n            return false;\n        }\n\n        // Check duplicates\n        __m128i eq = _mm_cmpeq_epi32(current, prev);\n        count = _mm_add_epi32(count, _mm_and_si128(eq, _mm_set1_epi32(1)));\n\n        // If any count exceeds 1, return false\n        __m128i cmp_count = _mm_cmpgt_epi32(count, _mm_set1_epi32(1));\n        if (_mm_movemask_epi8(cmp_count)) {\n            return false;\n        }\n\n        prev = current;\n    }\n\n    // Handle remaining elements\n    for (; i < n; ++i) {\n        if (i > 0 && data[i] < data[i - 1]) {\n            return false;\n        }\n        if (i > 0 && data[i] == data[i - 1]) {\n            int duplicates = 1;\n            while (i < n && data[i] == data[i - 1]) {\n                ++duplicates;\n                ++i;\n            }\n            if (duplicates > 2) {\n                return false;\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_122_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool is_sorted_simd(const std::vector<int> & lst) {\n    size_t n = lst.size();\n    if (n <= 1) return true;\n\n    // Ensure the vector size is a multiple of 4 for SIMD processing\n    size_t simd_size = n - (n % 4);\n    __m128i prev = _mm_set1_epi32(0); // Initialize with zeros\n    bool has_duplicate = false;\n\n    for (size_t i = 0; i < simd_size; i += 4) {\n        // Load 4 integers into an SSE register\n        __m128i current = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&lst[i]));\n\n        // Check for sorting: current >= prev\n        __m128i cmp_sorted = _mm_cmpgt_epi32(current, prev);\n        int mask_sorted = _mm_movemask_ps(_mm_castsi128_ps(cmp_sorted));\n        if (mask_sorted != 0xF) return false;\n\n        // Check for duplicates: current == prev\n        __m128i cmp_duplicate = _mm_cmpeq_epi32(current, prev);\n        int mask_duplicate = _mm_movemask_ps(_mm_castsi128_ps(cmp_duplicate));\n        if (mask_duplicate != 0) {\n            if (has_duplicate) return false;\n            has_duplicate = true;\n        } else {\n            has_duplicate = false;\n        }\n\n        prev = current;\n    }\n\n    // Process remaining elements (if any)\n    for (size_t i = simd_size; i < n; ++i) {\n        if (lst[i] < lst[i - 1]) return false;\n        if (lst[i] == lst[i - 1]) {\n            if (has_duplicate) return false;\n            has_duplicate = true;\n        } else {\n            has_duplicate = false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_122_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool is_sorted_simd(const std::vector<int> & lst) {\n    size_t n = lst.size();\n    if (n <= 1) return true;\n\n    // Ensure the vector is aligned for SIMD operations\n    const int * data = lst.data();\n    size_t i = 0;\n\n    // Process elements in chunks of 4 using SSE2 intrinsics\n    for (; i + 4 <= n; i += 4) {\n        __m128i current = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&data[i]));\n        __m128i next = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&data[i + 1]));\n\n        // Check if current <= next for all elements in the chunk\n        __m128i cmp = _mm_cmpgt_epi32(current, next);\n        if (!_mm_testz_si128(cmp, cmp)) {\n            return false;\n        }\n\n        // Check for duplicates within the chunk\n        __m128i shifted = _mm_alignr_epi8(next, current, 4); // Shift right by one element\n        __m128i eq = _mm_cmpeq_epi32(current, shifted);\n        if (!_mm_testz_si128(eq, eq)) {\n            return false;\n        }\n    }\n\n    // Handle remaining elements\n    for (; i + 1 < n; ++i) {\n        if (data[i] > data[i + 1]) {\n            return false;\n        }\n        if (i + 2 < n && data[i] == data[i + 1] && data[i] == data[i + 2]) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_122_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nbool is_sorted_simd(const std::vector<int> & lst) {\n    size_t n = lst.size();\n    if (n <= 1) return true;\n\n    // Ensure the vector is padded to a multiple of 4 for SIMD processing\n    size_t simd_size = (n + 3) & ~3;\n    std::vector<int> padded_lst(simd_size, 0);\n    std::copy(lst.begin(), lst.end(), padded_lst.begin());\n\n    __m128i prev = _mm_loadu_si128((__m128i*)&padded_lst[0]);\n    __m128i duplicates = _mm_setzero_si128();\n\n    for (size_t i = 4; i < simd_size; i += 4) {\n        __m128i curr = _mm_loadu_si128((__m128i*)&padded_lst[i]);\n\n        // Check for sorting: prev <= curr\n        __m128i cmp_sorted = _mm_cmpgt_epi32(prev, curr);\n        if (!_mm_testz_si128(cmp_sorted, cmp_sorted)) {\n            return false;\n        }\n\n        // Check for duplicates: prev == curr\n        __m128i cmp_eq = _mm_cmpeq_epi32(prev, curr);\n        duplicates = _mm_or_si128(duplicates, cmp_eq);\n\n        prev = curr;\n    }\n\n    // Check if there are more than one duplicate in any lane\n    int mask = _mm_movemask_epi8(duplicates);\n    if (__builtin_popcount(mask) > 4) {\n        return false;\n    }\n\n    // Handle edge case: last element might be zero-padded\n    for (size_t i = n; i < simd_size; ++i) {\n        if (padded_lst[i] != 0) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_123_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint prod_signs_simd(const std::vector<int> & arr) {\n    if (arr.empty()) return -32768;\n\n    __m128i zero = _mm_setzero_si128();\n    __m128i sign_mask = _mm_set1_epi32(0x80000000);\n    __m128i one = _mm_set1_epi32(1);\n    __m128i neg_one = _mm_set1_epi32(-1);\n\n    int total_sum = 0;\n    int total_sign = 1;\n\n    for (size_t i = 0; i < arr.size(); i += 4) {\n        // Load 4 integers into an SSE register\n        __m128i vec = _mm_loadu_si128((__m128i*)&arr[i]);\n\n        // Check for zero elements\n        __m128i is_zero = _mm_cmpeq_epi32(vec, zero);\n\n        // Extract signs of the elements\n        __m128i signs = _mm_and_si128(vec, sign_mask);\n        signs = _mm_cmpeq_epi32(signs, zero); // 0xFFFFFFFF if positive, 0x0 if negative\n\n        // Convert signs to 1 or -1\n        __m128i sign_values = _mm_blendv_epi8(neg_one, one, signs);\n\n        // Compute magnitudes\n        __m128i magnitudes = _mm_abs_epi32(vec);\n\n        // Accumulate magnitudes horizontally\n        int sum = _mm_extract_epi32(magnitudes, 0) +\n                  _mm_extract_epi32(magnitudes, 1) +\n                  _mm_extract_epi32(magnitudes, 2) +\n                  _mm_extract_epi32(magnitudes, 3);\n\n        // Accumulate signs horizontally\n        int sign_product = _mm_extract_epi32(sign_values, 0) *\n                           _mm_extract_epi32(sign_values, 1) *\n                           _mm_extract_epi32(sign_values, 2) *\n                           _mm_extract_epi32(sign_values, 3);\n\n        // Update total sum and total sign\n        total_sum += sum;\n        total_sign *= sign_product;\n\n        // If any element is zero, the result is zero\n        if (_mm_movemask_epi8(is_zero)) {\n            return 0;\n        }\n    }\n\n    return total_sum * total_sign;\n}\n```"}
{"task_id": "SimdBench_123_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint prod_signs_simd(const std::vector<int> & arr) {\n    if (arr.empty()) return -32768;\n\n    __m128i zero = _mm_setzero_si128();\n    __m128i signs = _mm_set1_epi32(1);\n    __m128i sum = _mm_setzero_si128();\n\n    size_t i = 0;\n    size_t size = arr.size();\n\n    // Process 4 elements at a time\n    for (; i + 4 <= size; i += 4) {\n        // Load 4 integers into an SSE register\n        __m128i vec = _mm_loadu_si128((__m128i*)&arr[i]);\n\n        // Compare each element with zero to determine sign\n        __m128i is_positive = _mm_cmpgt_epi32(vec, zero);   // Positive elements -> 0xFFFFFFFF\n        __m128i is_negative = _mm_cmplt_epi32(vec, zero);   // Negative elements -> 0xFFFFFFFF\n\n        // Create sign vector: 1 for positive, -1 for negative, 0 for zero\n        __m128i sign_vec = _mm_sub_epi32(is_positive, is_negative);\n\n        // Accumulate product of signs\n        signs = _mm_mullo_epi32(signs, sign_vec);\n\n        // Compute absolute values\n        __m128i abs_vec = _mm_sign_epi32(vec, vec);\n\n        // Add absolute values to the running sum\n        sum = _mm_add_epi32(sum, abs_vec);\n    }\n\n    // Horizontal sum and product of signs for the last SIMD register\n    int temp_sum[4];\n    int temp_signs[4];\n    _mm_storeu_si128((__m128i*)temp_sum, sum);\n    _mm_storeu_si128((__m128i*)temp_signs, signs);\n\n    int total_sum = temp_sum[0] + temp_sum[1] + temp_sum[2] + temp_sum[3];\n    int total_sign = temp_signs[0] * temp_signs[1] * temp_signs[2] * temp_signs[3];\n\n    // Process remaining elements\n    for (; i < size; ++i) {\n        int val = arr[i];\n        if (val > 0) {\n            total_sign *= 1;\n            total_sum += val;\n        } else if (val < 0) {\n            total_sign *= -1;\n            total_sum += -val;\n        } else {\n            total_sign = 0;\n        }\n    }\n\n    return total_sign == 0 ? 0 : total_sign * total_sum;\n}\n```"}
{"task_id": "SimdBench_123_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint prod_signs_simd(const std::vector<int> & arr) {\n    if (arr.empty()) return -32768;\n\n    __m128i zero = _mm_setzero_si128();\n    __m128i ones = _mm_set1_epi32(1);\n    __m128i neg_ones = _mm_set1_epi32(-1);\n    __m128i signs = _mm_set1_epi32(1);\n    __m128i magnitudes = _mm_setzero_si128();\n\n    int i = 0;\n    int size = arr.size();\n\n    // Process 4 elements at a time using SIMD\n    for (; i + 4 <= size; i += 4) {\n        // Load 4 integers into an SSE register\n        __m128i vec = _mm_loadu_si128((__m128i*)&arr[i]);\n\n        // Compare each element with zero to determine sign\n        __m128i is_positive = _mm_cmpgt_epi32(vec, zero); // 0xFFFFFFFF if > 0, else 0\n        __m128i is_negative = _mm_cmplt_epi32(vec, zero); // 0xFFFFFFFF if < 0, else 0\n\n        // Compute sign for each element: 1 for positive, -1 for negative, 0 for zero\n        __m128i sign_vec = _mm_or_si128(_mm_and_si128(is_positive, ones), _mm_and_si128(is_negative, neg_ones));\n\n        // Update the product of signs\n        signs = _mm_mullo_epi32(signs, sign_vec);\n\n        // Compute absolute values (magnitudes)\n        __m128i abs_vec = _mm_abs_epi32(vec);\n\n        // Accumulate magnitudes\n        magnitudes = _mm_add_epi32(magnitudes, abs_vec);\n    }\n\n    // Horizontal sum of magnitudes and product of signs\n    int magnitude_sum = 0;\n    int sign_product = 1;\n\n    // Extract and sum the magnitudes\n    int temp[4];\n    _mm_storeu_si128((__m128i*)temp, magnitudes);\n    magnitude_sum += temp[0] + temp[1] + temp[2] + temp[3];\n\n    // Extract and multiply the signs\n    _mm_storeu_si128((__m128i*)temp, signs);\n    sign_product *= temp[0] * temp[1] * temp[2] * temp[3];\n\n    // Process remaining elements (if any)\n    for (; i < size; ++i) {\n        int val = arr[i];\n        if (val > 0) {\n            sign_product *= 1;\n            magnitude_sum += val;\n        } else if (val < 0) {\n            sign_product *= -1;\n            magnitude_sum += -val;\n        } else {\n            sign_product = 0;\n        }\n    }\n\n    return sign_product == 0 ? 0 : sign_product * magnitude_sum;\n}\n```"}
{"task_id": "SimdBench_123_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint prod_signs_simd(const std::vector<int> & arr) {\n    if (arr.empty()) return -32768;\n\n    __m128i zero = _mm_setzero_si128();\n    __m128i ones = _mm_set1_epi32(1);\n    __m128i neg_ones = _mm_set1_epi32(-1);\n    __m128i signs = _mm_set1_epi32(1);\n    __m128i magnitudes = _mm_setzero_si128();\n\n    int i = 0;\n    int size = arr.size();\n\n    // Process 4 integers at a time using SIMD\n    for (; i + 4 <= size; i += 4) {\n        // Load 4 integers into an SSE register\n        __m128i values = _mm_loadu_si128((__m128i*)&arr[i]);\n\n        // Compare each value with zero to determine sign\n        __m128i is_positive = _mm_cmpgt_epi32(values, zero); // 0xFFFFFFFF if > 0, else 0\n        __m128i is_negative = _mm_cmplt_epi32(values, zero); // 0xFFFFFFFF if < 0, else 0\n\n        // Compute sign for each element: 1 for positive, -1 for negative, 0 for zero\n        __m128i current_signs = _mm_or_si128(\n            _mm_and_si128(is_positive, ones),\n            _mm_and_si128(is_negative, neg_ones)\n        );\n\n        // Update the product of signs\n        signs = _mm_mullo_epi32(signs, current_signs);\n\n        // Compute absolute values (magnitudes)\n        __m128i abs_values = _mm_sign_epi32(values, values);\n\n        // Accumulate magnitudes\n        magnitudes = _mm_add_epi32(magnitudes, abs_values);\n    }\n\n    // Horizontal sum of magnitudes and signs\n    int magnitude_sum = 0;\n    int sign_product = 1;\n\n    // Extract results from SSE registers\n    int temp[4];\n    _mm_storeu_si128((__m128i*)temp, magnitudes);\n    magnitude_sum += temp[0] + temp[1] + temp[2] + temp[3];\n\n    _mm_storeu_si128((__m128i*)temp, signs);\n    sign_product *= temp[0] * temp[1] * temp[2] * temp[3];\n\n    // Process remaining elements (if any)\n    for (; i < size; ++i) {\n        int value = arr[i];\n        if (value > 0) {\n            magnitude_sum += value;\n            sign_product *= 1;\n        } else if (value < 0) {\n            magnitude_sum += -value;\n            sign_product *= -1;\n        } else {\n            magnitude_sum += 0;\n            sign_product *= 0;\n        }\n    }\n\n    return magnitude_sum * sign_product;\n}\n```"}
{"task_id": "SimdBench_123_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint prod_signs_simd(const std::vector<int> & arr) {\n    if (arr.empty()) return -32768;\n\n    __m128i zero = _mm_setzero_si128();\n    __m128i ones = _mm_set1_epi32(1);\n    __m128i neg_ones = _mm_set1_epi32(-1);\n    __m128i sum_vec = _mm_setzero_si128();\n    __m128i sign_product = _mm_set1_epi32(1);\n\n    int i = 0;\n    int size = arr.size();\n\n    // Process 4 elements at a time using SIMD\n    for (; i + 4 <= size; i += 4) {\n        // Load 4 integers into a SIMD register\n        __m128i vec = _mm_loadu_si128((__m128i*)&arr[i]);\n\n        // Compute the absolute values of the integers\n        __m128i abs_vals = _mm_abs_epi32(vec);\n\n        // Accumulate the absolute values into sum_vec\n        sum_vec = _mm_add_epi32(sum_vec, abs_vals);\n\n        // Determine the signs of the integers (-1, 0, or 1)\n        __m128i is_positive = _mm_cmpgt_epi32(vec, zero); // 0xFFFFFFFF if > 0, else 0\n        __m128i is_negative = _mm_cmplt_epi32(vec, zero); // 0xFFFFFFFF if < 0, else 0\n        __m128i signs = _mm_sub_epi32(_mm_and_si128(is_positive, ones), _mm_and_si128(is_negative, ones));\n\n        // Update the product of signs\n        sign_product = _mm_mullo_epi32(sign_product, signs);\n    }\n\n    // Horizontal sum of the accumulated absolute values in sum_vec\n    int temp[4];\n    _mm_storeu_si128((__m128i*)temp, sum_vec);\n    int sum = temp[0] + temp[1] + temp[2] + temp[3];\n\n    // Handle remaining elements\n    for (; i < size; ++i) {\n        int val = arr[i];\n        sum += std::abs(val);\n        if (val > 0) {\n            sign_product = _mm_mullo_epi32(sign_product, ones);\n        } else if (val < 0) {\n            sign_product = _mm_mullo_epi32(sign_product, neg_ones);\n        } else {\n            sign_product = _mm_setzero_si128();\n        }\n    }\n\n    // Horizontal product of the sign_product vector\n    _mm_storeu_si128((__m128i*)temp, sign_product);\n    int sign = temp[0] * temp[1] * temp[2] * temp[3];\n\n    return sum * sign;\n}\n```"}
{"task_id": "SimdBench_124_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<int> minPath_simd(const std::vector<std::vector<int>> &grid, int k) {\n    int N = grid.size();\n    std::vector<int> result(k, 0);\n    std::vector<std::vector<int>> dp(N, std::vector<int>(N, 0));\n    std::vector<std::vector<int>> next_dp(N, std::vector<int>(N, 0));\n\n    // Initialize DP with the grid values for the first step\n    for (int i = 0; i < N; ++i) {\n        for (int j = 0; j < N; ++j) {\n            dp[i][j] = grid[i][j];\n        }\n    }\n\n    // Directions: up, down, left, right\n    int dir_x[4] = {-1, 1, 0, 0};\n    int dir_y[4] = {0, 0, -1, 1};\n\n    for (int step = 1; step < k; ++step) {\n        for (int i = 0; i < N; ++i) {\n            for (int j = 0; j < N; ++j) {\n                __m128i min_val = _mm_set1_epi32(INT32_MAX);\n\n                for (int d = 0; d < 4; ++d) {\n                    int ni = i + dir_x[d];\n                    int nj = j + dir_y[d];\n\n                    if (ni >= 0 && ni < N && nj >= 0 && nj < N) {\n                        __m128i val = _mm_set1_epi32(dp[ni][nj]);\n                        min_val = _mm_min_epi32(min_val, val);\n                    }\n                }\n\n                // Extract minimum value from SIMD register\n                int min_vals[4];\n                _mm_storeu_si128((__m128i*)min_vals, min_val);\n                next_dp[i][j] = grid[i][j] + std::min({min_vals[0], min_vals[1], min_vals[2], min_vals[3]});\n            }\n        }\n\n        dp.swap(next_dp);\n    }\n\n    // Find the lexicographically smallest path\n    int min_val = INT32_MAX;\n    int start_x = 0, start_y = 0;\n\n    for (int i = 0; i < N; ++i) {\n        for (int j = 0; j < N; ++j) {\n            if (dp[i][j] < min_val) {\n                min_val = dp[i][j];\n                start_x = i;\n                start_y = j;\n            }\n        }\n    }\n\n    int x = start_x, y = start_y;\n    result[0] = grid[x][y];\n\n    for (int step = 1; step < k; ++step) {\n        __m128i min_val = _mm_set1_epi32(INT32_MAX);\n        int next_x = x, next_y = y;\n\n        for (int d = 0; d < 4; ++d) {\n            int ni = x + dir_x[d];\n            int nj = y + dir_y[d];\n\n            if (ni >= 0 && ni < N && nj >= 0 && nj < N) {\n                __m128i val = _mm_set1_epi32(dp[ni][nj]);\n                min_val = _mm_min_epi32(min_val, val);\n\n                int min_vals[4];\n                _mm_storeu_si128((__m128i*)min_vals, min_val);\n\n                if (dp[ni][nj] == std::min({min_vals[0], min_vals[1], min_vals[2], min_vals[3]})) {\n                    next_x = ni;\n                    next_y = nj;\n                }\n            }\n        }\n\n        x = next_x;\n        y = next_y;\n        result[step] = grid[x][y];\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_124_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<int> minPath_simd(const std::vector<std::vector<int>> &grid, int k) {\n    int N = grid.size();\n    std::vector<int> result(k, 0);\n    std::vector<std::vector<int>> dp(N, std::vector<int>(N, 0));\n    std::vector<std::vector<int>> next_dp(N, std::vector<int>(N, 0));\n\n    // Initialize dp with the grid values\n    for (int i = 0; i < N; ++i) {\n        for (int j = 0; j < N; ++j) {\n            dp[i][j] = grid[i][j];\n        }\n    }\n\n    for (int step = 1; step < k; ++step) {\n        for (int i = 0; i < N; ++i) {\n            for (int j = 0; j <= N - 4; j += 4) {\n                __m128i current_min = _mm_set1_epi32(INT32_MAX);\n\n                // Check all neighbors and compute minimum using SIMD\n                if (i > 0) {\n                    __m128i top = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&dp[i - 1][j]));\n                    current_min = _mm_min_epi32(current_min, top);\n                }\n                if (i < N - 1) {\n                    __m128i bottom = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&dp[i + 1][j]));\n                    current_min = _mm_min_epi32(current_min, bottom);\n                }\n                if (j > 0) {\n                    __m128i left = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&dp[i][j - 1]));\n                    current_min = _mm_min_epi32(current_min, left);\n                }\n                if (j < N - 4) {\n                    __m128i right = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&dp[i][j + 1]));\n                    current_min = _mm_min_epi32(current_min, right);\n                }\n\n                // Add current grid value to the minimum neighbor value\n                __m128i grid_val = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&grid[i][j]));\n                __m128i new_val = _mm_add_epi32(current_min, grid_val);\n\n                // Store the result in next_dp\n                _mm_storeu_si128(reinterpret_cast<__m128i*>(&next_dp[i][j]), new_val);\n            }\n\n            // Handle remaining columns (if N % 4 != 0)\n            for (int j = N - (N % 4); j < N; ++j) {\n                int min_val = INT32_MAX;\n                if (i > 0) min_val = std::min(min_val, dp[i - 1][j]);\n                if (i < N - 1) min_val = std::min(min_val, dp[i + 1][j]);\n                if (j > 0) min_val = std::min(min_val, dp[i][j - 1]);\n                if (j < N - 1) min_val = std::min(min_val, dp[i][j + 1]);\n                next_dp[i][j] = grid[i][j] + min_val;\n            }\n        }\n\n        // Swap dp and next_dp for the next iteration\n        dp.swap(next_dp);\n    }\n\n    // Find the lexicographically smallest path\n    int min_val = INT32_MAX;\n    int start_i = 0, start_j = 0;\n    for (int i = 0; i < N; ++i) {\n        for (int j = 0; j < N; ++j) {\n            if (dp[i][j] < min_val) {\n                min_val = dp[i][j];\n                start_i = i;\n                start_j = j;\n            }\n        }\n    }\n\n    // Reconstruct the path\n    int i = start_i, j = start_j;\n    result[0] = grid[i][j];\n    for (int step = 1; step < k; ++step) {\n        int min_val = INT32_MAX;\n        int next_i = i, next_j = j;\n\n        if (i > 0 && dp[i - 1][j] < min_val) {\n            min_val = dp[i - 1][j];\n            next_i = i - 1;\n            next_j = j;\n        }\n        if (i < N - 1 && dp[i + 1][j] < min_val) {\n            min_val = dp[i + 1][j];\n            next_i = i + 1;\n            next_j = j;\n        }\n        if (j > 0 && dp[i][j - 1] < min_val) {\n            min_val = dp[i][j - 1];\n            next_i = i;\n            next_j = j - 1;\n        }\n        if (j < N - 1 && dp[i][j + 1] < min_val) {\n            min_val = dp[i][j + 1];\n            next_i = i;\n            next_j = j + 1;\n        }\n\n        result[step] = grid[next_i][next_j];\n        i = next_i;\n        j = next_j;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_124_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<int> minPath_simd(const std::vector<std::vector<int>> &grid, int k) {\n    int N = grid.size();\n    std::vector<int> result(k, 0);\n    std::vector<std::vector<int>> dp(N, std::vector<int>(N, 0));\n    std::vector<std::vector<int>> next_dp(N, std::vector<int>(N, 0));\n\n    // Initialize DP with the grid values as starting points\n    for (int i = 0; i < N; ++i) {\n        for (int j = 0; j < N; ++j) {\n            dp[i][j] = grid[i][j];\n        }\n    }\n\n    for (int step = 1; step < k; ++step) {\n        for (int i = 0; i < N; ++i) {\n            for (int j = 0; j <= N - 4; j += 4) {\n                __m128i current_min = _mm_set1_epi32(INT32_MAX);\n\n                // Check all neighbors for each cell in SIMD fashion\n                if (i > 0) {\n                    __m128i top = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&dp[i - 1][j]));\n                    current_min = _mm_min_epi32(current_min, top);\n                }\n                if (i < N - 1) {\n                    __m128i bottom = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&dp[i + 1][j]));\n                    current_min = _mm_min_epi32(current_min, bottom);\n                }\n                if (j > 0) {\n                    __m128i left = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&dp[i][j - 1]));\n                    current_min = _mm_min_epi32(current_min, left);\n                }\n                if (j < N - 4) {\n                    __m128i right = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&dp[i][j + 1]));\n                    current_min = _mm_min_epi32(current_min, right);\n                }\n\n                // Add current grid value to the minimum neighbor value\n                __m128i grid_val = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&grid[i][j]));\n                __m128i new_val = _mm_add_epi32(current_min, grid_val);\n\n                // Store the result back into next_dp\n                _mm_storeu_si128(reinterpret_cast<__m128i*>(&next_dp[i][j]), new_val);\n            }\n\n            // Handle remaining columns that don't fit into SIMD\n            for (int j = N - (N % 4); j < N; ++j) {\n                int min_val = INT32_MAX;\n                if (i > 0) min_val = std::min(min_val, dp[i - 1][j]);\n                if (i < N - 1) min_val = std::min(min_val, dp[i + 1][j]);\n                if (j > 0) min_val = std::min(min_val, dp[i][j - 1]);\n                if (j < N - 1) min_val = std::min(min_val, dp[i][j + 1]);\n                next_dp[i][j] = grid[i][j] + min_val;\n            }\n        }\n\n        dp.swap(next_dp);\n    }\n\n    // Find the lexicographically smallest path\n    int min_val = INT32_MAX;\n    int start_i = 0, start_j = 0;\n    for (int i = 0; i < N; ++i) {\n        for (int j = 0; j < N; ++j) {\n            if (dp[i][j] < min_val) {\n                min_val = dp[i][j];\n                start_i = i;\n                start_j = j;\n            }\n        }\n    }\n\n    result[0] = grid[start_i][start_j];\n    int current_i = start_i, current_j = start_j;\n\n    for (int step = 1; step < k; ++step) {\n        int next_min = INT32_MAX;\n        int next_i = current_i, next_j = current_j;\n\n        if (current_i > 0 && dp[current_i - 1][current_j] < next_min) {\n            next_min = dp[current_i - 1][current_j];\n            next_i = current_i - 1;\n            next_j = current_j;\n        }\n        if (current_i < N - 1 && dp[current_i + 1][current_j] < next_min) {\n            next_min = dp[current_i + 1][current_j];\n            next_i = current_i + 1;\n            next_j = current_j;\n        }\n        if (current_j > 0 && dp[current_i][current_j - 1] < next_min) {\n            next_min = dp[current_i][current_j - 1];\n            next_i = current_i;\n            next_j = current_j - 1;\n        }\n        if (current_j < N - 1 && dp[current_i][current_j + 1] < next_min) {\n            next_min = dp[current_i][current_j + 1];\n            next_i = current_i;\n            next_j = current_j + 1;\n        }\n\n        result[step] = grid[next_i][next_j];\n        current_i = next_i;\n        current_j = next_j;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_124_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<int> minPath_simd(const std::vector<std::vector<int>> &grid, int k) {\n    int N = grid.size();\n    std::vector<int> result(k, 0);\n    std::vector<int> current_path(k, 0);\n    std::vector<int> best_path(k, 0);\n\n    // Initialize the best path with maximum possible values\n    for (int i = 0; i < k; ++i) {\n        best_path[i] = INT32_MAX;\n    }\n\n    // Directions: up, down, left, right\n    const int dx[4] = {-1, 1, 0, 0};\n    const int dy[4] = {0, 0, -1, 1};\n\n    // Lambda to compare two paths using SIMD\n    auto is_lexicographically_smaller = [&](const std::vector<int>& a, const std::vector<int>& b) -> bool {\n        __m128i vec_a, vec_b;\n        for (int i = 0; i < k; i += 4) {\n            vec_a = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&a[i]));\n            vec_b = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&b[i]));\n            __m128i cmp = _mm_cmplt_epi32(vec_a, vec_b);\n            if (_mm_movemask_epi8(cmp)) return true;\n            cmp = _mm_cmpgt_epi32(vec_a, vec_b);\n            if (_mm_movemask_epi8(cmp)) return false;\n        }\n        return false;\n    };\n\n    // Recursive DFS function\n    std::function<void(int, int, int)> dfs = [&](int x, int y, int step) {\n        current_path[step] = grid[x][y];\n\n        if (step == k - 1) {\n            if (is_lexicographically_smaller(current_path, best_path)) {\n                best_path = current_path;\n            }\n            return;\n        }\n\n        for (int dir = 0; dir < 4; ++dir) {\n            int nx = x + dx[dir];\n            int ny = y + dy[dir];\n            if (nx >= 0 && nx < N && ny >= 0 && ny < N) {\n                dfs(nx, ny, step + 1);\n            }\n        }\n    };\n\n    // Start DFS from every cell in the grid\n    for (int i = 0; i < N; ++i) {\n        for (int j = 0; j < N; ++j) {\n            dfs(i, j, 0);\n        }\n    }\n\n    return best_path;\n}\n```"}
{"task_id": "SimdBench_124_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<int> minPath_simd(const std::vector<std::vector<int>> &grid, int k) {\n    int N = grid.size();\n    std::vector<int> result(k, 0);\n    std::vector<std::vector<int>> dp(N, std::vector<int>(N, 0));\n    std::vector<std::vector<int>> next_dp(N, std::vector<int>(N, 0));\n\n    // Initialize DP with the grid values for path length 1\n    for (int i = 0; i < N; ++i) {\n        for (int j = 0; j < N; ++j) {\n            dp[i][j] = grid[i][j];\n        }\n    }\n\n    // Directions: up, down, left, right\n    int dir_x[4] = {-1, 1, 0, 0};\n    int dir_y[4] = {0, 0, -1, 1};\n\n    for (int step = 2; step <= k; ++step) {\n        for (int i = 0; i < N; ++i) {\n            for (int j = 0; j < N; ++j) {\n                __m128i min_val = _mm_set1_epi32(INT32_MAX);\n\n                for (int d = 0; d < 4; ++d) {\n                    int ni = i + dir_x[d];\n                    int nj = j + dir_y[d];\n\n                    if (ni >= 0 && ni < N && nj >= 0 && nj < N) {\n                        __m128i val = _mm_set1_epi32(dp[ni][nj]);\n                        min_val = _mm_min_epi32(min_val, val);\n                    }\n                }\n\n                // Extract minimum value from SIMD register\n                int min_vals[4];\n                _mm_storeu_si128((__m128i*)min_vals, min_val);\n                next_dp[i][j] = grid[i][j] + std::min({min_vals[0], min_vals[1], min_vals[2], min_vals[3]});\n            }\n        }\n\n        dp.swap(next_dp);\n    }\n\n    // Find the lexicographically smallest path\n    int min_val = INT32_MAX;\n    int start_x = 0, start_y = 0;\n\n    for (int i = 0; i < N; ++i) {\n        for (int j = 0; j < N; ++j) {\n            if (dp[i][j] < min_val) {\n                min_val = dp[i][j];\n                start_x = i;\n                start_y = j;\n            }\n        }\n    }\n\n    int x = start_x, y = start_y;\n    result[0] = grid[x][y];\n\n    for (int step = 1; step < k; ++step) {\n        __m128i min_val = _mm_set1_epi32(INT32_MAX);\n        int next_x = x, next_y = y;\n\n        for (int d = 0; d < 4; ++d) {\n            int ni = x + dir_x[d];\n            int nj = y + dir_y[d];\n\n            if (ni >= 0 && ni < N && nj >= 0 && nj < N) {\n                __m128i val = _mm_set1_epi32(dp[ni][nj]);\n                min_val = _mm_min_epi32(min_val, val);\n\n                int min_vals[4];\n                _mm_storeu_si128((__m128i*)min_vals, min_val);\n\n                if (dp[ni][nj] == std::min({min_vals[0], min_vals[1], min_vals[2], min_vals[3]})) {\n                    next_x = ni;\n                    next_y = nj;\n                }\n            }\n        }\n\n        x = next_x;\n        y = next_y;\n        result[step] = grid[x][y];\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_125_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nuint64_t digits_simd(uint64_t n) {\n    __m128i odd_mask = _mm_set1_epi8(0x01); // Mask to check for odd digits\n    __m128i zero = _mm_setzero_si128();     // Zero vector for comparison\n    __m128i product = _mm_set1_epi8(1);     // Initialize product to 1 for each lane\n\n    while (n > 0) {\n        uint64_t chunk = n % 1000000000; // Process 9 digits at a time\n        n /= 1000000000;\n\n        // Load digits into SIMD registers\n        __m128i digits = _mm_set_epi64x(0, chunk);\n        __m128i digit_mask = _mm_set1_epi8(0x0F); // Mask to extract lower 4 bits\n        digits = _mm_and_si128(digits, digit_mask);\n\n        // Check if digits are odd\n        __m128i is_odd = _mm_and_si128(digits, odd_mask);\n        __m128i mask = _mm_cmpgt_epi8(is_odd, zero); // Create mask for odd digits\n\n        // Select odd digits using the mask\n        __m128i selected_digits = _mm_blendv_epi8(_mm_set1_epi8(1), digits, mask);\n\n        // Multiply selected digits with the current product\n        product = _mm_mullo_epi16(product, selected_digits);\n    }\n\n    // Horizontal reduction to compute the final product\n    uint16_t result[8];\n    _mm_storeu_si128((__m128i*)result, product);\n\n    uint64_t final_product = 1;\n    for (int i = 0; i < 8; ++i) {\n        final_product *= result[i];\n    }\n\n    return final_product == 1 ? 0 : final_product;\n}\n```"}
{"task_id": "SimdBench_125_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nuint64_t digits_simd(uint64_t n) {\n    __m128i odd_mask = _mm_set1_epi8(0x01); // Mask to check if a digit is odd\n    __m128i zero = _mm_setzero_si128();     // Zero vector for comparison\n    __m128i product = _mm_set1_epi8(1);     // Initialize product to 1 for each lane\n\n    while (n > 0) {\n        uint64_t chunk = n % 1000000000; // Process 9 digits at a time\n        n /= 1000000000;\n\n        __m128i digits = _mm_set_epi64x(0, chunk); // Load digits into SIMD register\n        __m128i mask = _mm_and_si128(digits, odd_mask); // Check odd digits\n        __m128i is_odd = _mm_cmpgt_epi8(mask, zero);   // Create mask for odd digits\n\n        // Extract odd digits using the mask\n        __m128i odd_digits = _mm_and_si128(digits, is_odd);\n\n        // Multiply odd digits with the current product\n        product = _mm_mullo_epi16(product, odd_digits);\n    }\n\n    // Horizontal multiplication of the product vector\n    uint16_t result[8];\n    _mm_storeu_si128((__m128i*)result, product);\n\n    uint64_t final_product = 1;\n    for (int i = 0; i < 8; ++i) {\n        if (result[i] != 0) {\n            final_product *= result[i];\n        }\n    }\n\n    return final_product == 1 ? 0 : final_product;\n}\n```"}
{"task_id": "SimdBench_125_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nuint64_t digits_simd(uint64_t n) {\n    __m128i odd_mask = _mm_set1_epi8(0x01); // Mask to check if a digit is odd\n    __m128i zero = _mm_setzero_si128();     // Zero vector for comparison\n    __m128i product = _mm_set1_epi8(1);     // Initialize product to 1 for each lane\n\n    while (n > 0) {\n        uint64_t chunk = n % 1000000000; // Process 9 digits at a time\n        n /= 1000000000;\n\n        // Load 16 digits into an SSE register (pad with zeros if necessary)\n        char digits[16];\n        for (int i = 0; i < 16; ++i) {\n            digits[i] = (i < 9 && chunk > 0) ? (chunk % 10) : 0;\n            chunk /= 10;\n        }\n        __m128i digit_vec = _mm_loadu_si128((__m128i*)digits);\n\n        // Check if digits are odd\n        __m128i is_odd = _mm_and_si128(digit_vec, odd_mask);\n        __m128i mask = _mm_cmpgt_epi8(is_odd, zero); // Create mask for odd digits\n\n        // Blend odd digits with 1s (to avoid multiplying by zero)\n        __m128i valid_digits = _mm_blendv_epi8(_mm_set1_epi8(1), digit_vec, mask);\n\n        // Multiply the valid digits into the product\n        product = _mm_mullo_epi16(product, valid_digits);\n    }\n\n    // Horizontal multiplication of the elements in the SSE register\n    int result = 1;\n    alignas(16) char final_product[16];\n    _mm_store_si128((__m128i*)final_product, product);\n    for (int i = 0; i < 16; ++i) {\n        result *= final_product[i];\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_125_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nuint64_t digits_simd(uint64_t n) {\n    __m128i odd_mask = _mm_set1_epi8(0x01); // Mask to check if a digit is odd\n    __m128i zero = _mm_setzero_si128();     // Zero vector for comparison\n    __m128i product = _mm_set1_epi8(1);     // Initialize product to 1 for each lane\n\n    while (n > 0) {\n        uint64_t chunk = n % 1000000000; // Process 9 digits at a time\n        n /= 1000000000;\n\n        // Load digits into SIMD registers\n        char digits[16];\n        for (int i = 0; i < 9; ++i) {\n            digits[i] = chunk % 10;\n            chunk /= 10;\n        }\n        for (int i = 9; i < 16; ++i) {\n            digits[i] = 0; // Pad remaining bytes with zeros\n        }\n\n        __m128i digit_vec = _mm_loadu_si128((__m128i*)digits);\n        __m128i is_odd = _mm_and_si128(digit_vec, odd_mask); // Check odd digits\n        __m128i mask = _mm_cmpgt_epi8(is_odd, zero);         // Create mask for odd digits\n\n        // Blend odd digits into product, ignore even digits\n        __m128i selected_digits = _mm_blendv_epi8(_mm_set1_epi8(1), digit_vec, mask);\n        product = _mm_mullo_epi16(product, selected_digits);\n    }\n\n    // Horizontal multiplication of the product vector\n    uint16_t results[8];\n    _mm_storeu_si128((__m128i*)results, product);\n\n    uint64_t final_product = 1;\n    for (int i = 0; i < 8; ++i) {\n        final_product *= results[i];\n    }\n\n    return final_product == 1 ? 0 : final_product;\n}\n```"}
{"task_id": "SimdBench_125_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nuint64_t digits_simd(uint64_t n) {\n    __m128i zero = _mm_setzero_si128();\n    __m128i odd_mask = _mm_set1_epi8(0x01);\n    __m128i product = _mm_set1_epi8(1);\n    __m128i all_even = _mm_set1_epi8(1);\n\n    while (n > 0) {\n        uint64_t chunk = n % 100000000; // Process 8 digits at a time\n        n /= 100000000;\n\n        __m128i digits = _mm_set_epi64x(0, chunk);\n        __m128i mask = _mm_set1_epi8(0x0F);\n\n        for (int i = 0; i < 8; ++i) {\n            __m128i digit = _mm_and_si128(_mm_srli_epi64(digits, 4 * i), mask);\n            __m128i is_odd = _mm_and_si128(digit, odd_mask);\n            __m128i is_even = _mm_cmpeq_epi8(is_odd, zero);\n\n            all_even = _mm_and_si128(all_even, is_even);\n            __m128i valid_digit = _mm_blendv_epi8(zero, digit, is_odd);\n            product = _mm_mullo_epi16(product, valid_digit);\n        }\n    }\n\n    int result = 1;\n    int all_even_result = 1;\n    for (int i = 0; i < 8; ++i) {\n        result *= ((uint8_t*)&product)[i];\n        all_even_result &= ((uint8_t*)&all_even)[i];\n    }\n\n    return all_even_result ? 0 : result;\n}\n```"}
{"task_id": "SimdBench_126_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nuint64_t sum_squares_simd(const std::vector<float> & lst) {\n    __m128 ones = _mm_set1_ps(1.0f);\n    __m128 zero = _mm_setzero_ps();\n    __m128 sum_vec = _mm_setzero_ps();\n\n    size_t i = 0;\n    size_t n = lst.size();\n\n    // Process 4 elements at a time\n    for (; i + 4 <= n; i += 4) {\n        // Load 4 floats into an SSE register\n        __m128 vec = _mm_loadu_ps(&lst[i]);\n\n        // Compute ceiling using SSE intrinsics\n        __m128 ceil_mask = _mm_cmpgt_ps(vec, _mm_cvtepi32_ps(_mm_cvttps_epi32(vec)));\n        __m128 ceil_val = _mm_add_ps(_mm_cvtepi32_ps(_mm_cvttps_epi32(vec)), _mm_and_ps(ceil_mask, ones));\n\n        // Square the values\n        __m128 squared = _mm_mul_ps(ceil_val, ceil_val);\n\n        // Accumulate the sum\n        sum_vec = _mm_add_ps(sum_vec, squared);\n    }\n\n    // Horizontal sum of the accumulated SSE register\n    float sum_array[4];\n    _mm_storeu_ps(sum_array, sum_vec);\n    uint64_t result = static_cast<uint64_t>(sum_array[0] + sum_array[1] + sum_array[2] + sum_array[3]);\n\n    // Process remaining elements\n    for (; i < n; ++i) {\n        float val = lst[i];\n        int ceil_val = static_cast<int>(val) + (val > static_cast<int>(val) ? 1 : 0);\n        result += static_cast<uint64_t>(ceil_val * ceil_val);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_126_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nuint64_t sum_squares_simd(const std::vector<float> & lst) {\n    __m128 v_ceil_mask = _mm_set1_ps(0.9999999f); // Small epsilon to ensure proper ceiling behavior\n    __m128 v_zero = _mm_setzero_ps();\n    __m128 v_sum = _mm_setzero_ps();\n\n    size_t i = 0;\n    size_t n = lst.size();\n\n    // Process 4 elements at a time\n    for (; i + 3 < n; i += 4) {\n        // Load 4 floats into an SSE register\n        __m128 v = _mm_loadu_ps(&lst[i]);\n\n        // Compute ceiling by adding a small epsilon and converting to int, then back to float\n        __m128 v_ceil = _mm_cvtepi32_ps(_mm_cvtps_epi32(_mm_add_ps(v, v_ceil_mask)));\n\n        // Square the values\n        __m128 v_squared = _mm_mul_ps(v_ceil, v_ceil);\n\n        // Accumulate the squared values\n        v_sum = _mm_add_ps(v_sum, v_squared);\n    }\n\n    // Horizontal sum of the accumulated SSE register\n    float sum_array[4];\n    _mm_storeu_ps(sum_array, v_sum);\n    uint64_t result = static_cast<uint64_t>(sum_array[0] + sum_array[1] + sum_array[2] + sum_array[3]);\n\n    // Process remaining elements\n    for (; i < n; ++i) {\n        float val = lst[i];\n        int ceil_val = static_cast<int>(val + 0.9999999f);\n        result += static_cast<uint64_t>(ceil_val * ceil_val);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_126_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <cmath>\n\nuint64_t sum_squares_simd(const std::vector<float> & lst) {\n    __m128 v_ceil_mask = _mm_set1_ps(0.9999999f); // Mask to assist ceiling operation\n    __m128 v_sum = _mm_setzero_ps();              // Accumulator for partial sums\n\n    size_t i = 0;\n    size_t size = lst.size();\n\n    // Process 4 elements at a time\n    for (; i + 3 < size; i += 4) {\n        // Load 4 floats into an SSE register\n        __m128 v = _mm_loadu_ps(&lst[i]);\n\n        // Perform ceiling operation\n        v = _mm_add_ps(v, v_ceil_mask);\n        v = _mm_cvtepi32_ps(_mm_cvttps_epi32(v));\n\n        // Square the values\n        v = _mm_mul_ps(v, v);\n\n        // Add to the running sum\n        v_sum = _mm_add_ps(v_sum, v);\n    }\n\n    // Horizontal sum of the accumulated SSE register\n    float partial_sum[4];\n    _mm_storeu_ps(partial_sum, v_sum);\n    uint64_t result = partial_sum[0] + partial_sum[1] + partial_sum[2] + partial_sum[3];\n\n    // Process remaining elements\n    for (; i < size; ++i) {\n        float val = std::ceil(lst[i]);\n        result += val * val;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_126_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nuint64_t sum_squares_simd(const std::vector<float> & lst) {\n    __m128 v_ones = _mm_set1_ps(1.0f);\n    __m128 v_sum = _mm_setzero_ps();\n    size_t i = 0;\n\n    // Process 4 elements at a time\n    for (; i + 3 < lst.size(); i += 4) {\n        // Load 4 floats into an SSE register\n        __m128 v = _mm_loadu_ps(&lst[i]);\n\n        // Compute ceiling using SSE intrinsics\n        __m128 v_cel = _mm_sub_ps(_mm_add_ps(v, v_ones), _mm_floor_ps(_mm_add_ps(v, v_ones)));\n\n        // Square the ceiling values\n        __m128 v_sq = _mm_mul_ps(v_cel, v_cel);\n\n        // Accumulate the squared values\n        v_sum = _mm_add_ps(v_sum, v_sq);\n    }\n\n    // Horizontal sum of the accumulated SSE register\n    float temp[4];\n    _mm_storeu_ps(temp, v_sum);\n    uint64_t result = static_cast<uint64_t>(temp[0] + temp[1] + temp[2] + temp[3]);\n\n    // Process remaining elements\n    for (; i < lst.size(); ++i) {\n        float cel = ceilf(lst[i]);\n        result += static_cast<uint64_t>(cel * cel);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_126_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nuint64_t sum_squares_simd(const std::vector<float> & lst) {\n    __m128 v_ones = _mm_set1_ps(1.0f);\n    __m128 v_zero = _mm_setzero_ps();\n    __m128 v_sum = _mm_setzero_ps();\n\n    size_t i = 0;\n    size_t n = lst.size();\n\n    // Process 4 elements at a time\n    for (; i + 4 <= n; i += 4) {\n        // Load 4 floats into SIMD register\n        __m128 v = _mm_loadu_ps(&lst[i]);\n\n        // Compute ceiling using SSE/SSE2 intrinsics\n        __m128 v_cel = _mm_cvtepi32_ps(_mm_cvtps_epi32(_mm_add_ps(v, v_ones)));\n\n        // Square the values\n        __m128 v_sq = _mm_mul_ps(v_cel, v_cel);\n\n        // Accumulate the squared values\n        v_sum = _mm_add_ps(v_sum, v_sq);\n    }\n\n    // Horizontal sum of the accumulated SIMD register\n    float sum_array[4];\n    _mm_storeu_ps(sum_array, v_sum);\n    uint64_t result = static_cast<uint64_t>(sum_array[0] + sum_array[1] + sum_array[2] + sum_array[3]);\n\n    // Process remaining elements\n    for (; i < n; ++i) {\n        float val = lst[i];\n        int ceil_val = static_cast<int>(val + 1.0f);\n        result += static_cast<uint64_t>(ceil_val * ceil_val);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_127_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint can_arrange_simd(const std::vector<int> & arr) {\n    int n = arr.size();\n    if (n < 2) return -1;\n\n    int result = -1;\n    int i = 0;\n\n    // Process 4 elements at a time using SSE2 intrinsics\n    for (; i <= n - 5; i += 4) {\n        // Load 4 elements starting from index i and i+1\n        __m128i current = _mm_loadu_si128((__m128i*)&arr[i]);\n        __m128i next = _mm_loadu_si128((__m128i*)&arr[i + 1]);\n\n        // Compare current > next (element-wise)\n        __m128i cmp = _mm_cmpgt_epi32(current, next);\n\n        // Create a mask to identify which comparisons are true\n        int mask = _mm_movemask_ps(_mm_castsi128_ps(cmp));\n\n        if (mask != 0) {\n            // Find the first set bit in the mask\n            int offset = __builtin_ctz(mask);\n            result = i + offset;\n            break;\n        }\n    }\n\n    // Process remaining elements sequentially\n    for (; i < n - 1; ++i) {\n        if (arr[i] > arr[i + 1]) {\n            result = i + 1;\n            break;\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_127_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint can_arrange_simd(const std::vector<int> & arr) {\n    int n = arr.size();\n    if (n < 2) return -1;\n\n    int result = -1;\n    int i = 0;\n\n    // Process elements in chunks of 4 using SSE2\n    for (; i <= n - 5; i += 4) {\n        // Load 4 elements starting from index i and i+1\n        __m128i current = _mm_loadu_si128((__m128i*)&arr[i]);\n        __m128i next = _mm_loadu_si128((__m128i*)&arr[i + 1]);\n\n        // Compare current >= next (element-wise)\n        __m128i cmp = _mm_cmpgt_epi32(current, next);\n\n        // Create a mask to identify which comparisons are true\n        int mask = _mm_movemask_ps(_mm_castsi128_ps(cmp));\n\n        if (mask != 0) {\n            // Find the first set bit in the mask\n            int offset = __builtin_ctz(mask);\n            return i + offset + 1;\n        }\n    }\n\n    // Process remaining elements sequentially\n    for (; i < n - 1; ++i) {\n        if (arr[i] > arr[i + 1]) {\n            return i + 1;\n        }\n    }\n\n    return -1;\n}\n```"}
{"task_id": "SimdBench_127_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint can_arrange_simd(const std::vector<int> & arr) {\n    int n = arr.size();\n    if (n < 2) return -1;\n\n    int result = -1;\n    int i = 0;\n\n    // Process elements in chunks of 4 using SSE2 intrinsics\n    for (; i <= n - 4; i += 4) {\n        // Load 4 integers from the array into an SSE register\n        __m128i current = _mm_loadu_si128((__m128i*)&arr[i]);\n        __m128i next = _mm_loadu_si128((__m128i*)&arr[i + 1]);\n\n        // Compare current with next (current >= next)\n        __m128i cmp = _mm_cmpgt_epi32(current, next);\n\n        // Create a mask to identify which lanes have true comparisons\n        int mask = _mm_movemask_ps(_mm_castsi128_ps(cmp));\n\n        if (mask != 0) {\n            // Find the first index in the current chunk where the condition holds\n            for (int j = 0; j < 4; ++j) {\n                if (mask & (1 << j)) {\n                    result = i + j + 1;\n                    break;\n                }\n            }\n            break;\n        }\n    }\n\n    // Process remaining elements sequentially\n    for (; i < n - 1; ++i) {\n        if (arr[i] > arr[i + 1]) {\n            result = i + 1;\n            break;\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_127_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint can_arrange_simd(const std::vector<int> & arr) {\n    int n = arr.size();\n    if (n < 2) return -1;\n\n    int result = -1;\n    int i = 0;\n\n    // Process elements in chunks of 4 using SSE2 intrinsics\n    for (; i <= n - 5; i += 4) {\n        // Load 4 elements starting from index i and i+1\n        __m128i current = _mm_loadu_si128((__m128i*)&arr[i]);\n        __m128i next = _mm_loadu_si128((__m128i*)&arr[i + 1]);\n\n        // Compare current > next (element-wise)\n        __m128i cmp = _mm_cmpgt_epi32(current, next);\n\n        // Create a mask to identify which comparisons are true\n        int mask = _mm_movemask_ps(_mm_castsi128_ps(cmp));\n\n        if (mask != 0) {\n            // Find the first set bit in the mask\n            int offset = __builtin_ctz(mask);\n            result = i + offset;\n            break;\n        }\n    }\n\n    // Process remaining elements sequentially\n    for (; i < n - 1; ++i) {\n        if (arr[i] > arr[i + 1]) {\n            result = i + 1;\n            break;\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_127_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint can_arrange_simd(const std::vector<int> & arr) {\n    int n = arr.size();\n    if (n < 2) return -1;\n\n    int result = -1;\n    int i = 0;\n\n    // Process elements in chunks of 4 using SSE2 intrinsics\n    for (; i <= n - 5; i += 4) {\n        // Load 4 elements starting from index i and i+1\n        __m128i current = _mm_loadu_si128((__m128i*)&arr[i]);\n        __m128i next = _mm_loadu_si128((__m128i*)&arr[i + 1]);\n\n        // Compare current >= next (element-wise)\n        __m128i cmp = _mm_cmpgt_epi32(current, next);\n\n        // Create a mask to identify which comparisons are true\n        int mask = _mm_movemask_ps(_mm_castsi128_ps(cmp));\n\n        if (mask != 0) {\n            // Find the first set bit in the mask\n            int offset = __builtin_ctz(mask);\n            result = i + offset + 1;\n            break;\n        }\n    }\n\n    // Process remaining elements sequentially\n    for (; i < n - 1; ++i) {\n        if (arr[i] > arr[i + 1]) {\n            result = i + 1;\n            break;\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_128_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <limits>\n\nstd::vector<int> largest_smallest_integers_simd(const std::vector<int>& lst) {\n    int largest_negative = 0;\n    int smallest_positive = 0;\n\n    __m128i zero = _mm_setzero_si128();\n    __m128i largest_negative_vec = _mm_set1_epi32(std::numeric_limits<int>::min());\n    __m128i smallest_positive_vec = _mm_set1_epi32(std::numeric_limits<int>::max());\n\n    size_t i = 0;\n    size_t size = lst.size();\n\n    // Process 4 integers at a time using SIMD\n    for (; i + 4 <= size; i += 4) {\n        __m128i vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&lst[i]));\n\n        // Compare for negative numbers\n        __m128i mask_neg = _mm_cmplt_epi32(vec, zero);\n        __m128i negatives = _mm_and_si128(vec, mask_neg);\n        largest_negative_vec = _mm_max_epi32(largest_negative_vec, negatives);\n\n        // Compare for positive numbers\n        __m128i mask_pos = _mm_cmpgt_epi32(vec, zero);\n        __m128i positives = _mm_and_si128(vec, mask_pos);\n        smallest_positive_vec = _mm_min_epi32(smallest_positive_vec, _mm_or_si128(positives, _mm_andnot_si128(mask_pos, _mm_set1_epi32(std::numeric_limits<int>::max()))));\n    }\n\n    // Extract results from SIMD registers\n    int temp[4];\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(temp), largest_negative_vec);\n    for (int j = 0; j < 4; ++j) {\n        if (temp[j] < 0 && temp[j] > largest_negative) {\n            largest_negative = temp[j];\n        }\n    }\n\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(temp), smallest_positive_vec);\n    for (int j = 0; j < 4; ++j) {\n        if (temp[j] > 0 && temp[j] < smallest_positive) {\n            smallest_positive = temp[j];\n        }\n    }\n\n    // Process remaining elements\n    for (; i < size; ++i) {\n        if (lst[i] < 0 && lst[i] > largest_negative) {\n            largest_negative = lst[i];\n        }\n        if (lst[i] > 0 && lst[i] < smallest_positive) {\n            smallest_positive = lst[i];\n        }\n    }\n\n    return {largest_negative, smallest_positive};\n}\n```"}
{"task_id": "SimdBench_128_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <limits>\n\nstd::vector<int> largest_smallest_integers_simd(const std::vector<int>& lst) {\n    int largest_negative = 0;\n    int smallest_positive = 0;\n\n    __m128i zero = _mm_setzero_si128();\n    __m128i largest_neg_vec = _mm_set1_epi32(std::numeric_limits<int>::min());\n    __m128i smallest_pos_vec = _mm_set1_epi32(std::numeric_limits<int>::max());\n\n    size_t i = 0;\n    size_t size = lst.size();\n\n    // Process 4 integers at a time using SIMD\n    for (; i + 4 <= size; i += 4) {\n        __m128i vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&lst[i]));\n\n        // Compare with zero to separate negatives and positives\n        __m128i is_negative = _mm_cmplt_epi32(vec, zero);\n        __m128i is_positive = _mm_cmpgt_epi32(vec, zero);\n\n        // Mask out non-negative and non-positive values\n        __m128i negatives = _mm_and_si128(vec, is_negative);\n        __m128i positives = _mm_and_si128(vec, is_positive);\n\n        // Find the largest negative in this vector\n        largest_neg_vec = _mm_max_epi32(largest_neg_vec, negatives);\n\n        // Find the smallest positive in this vector\n        smallest_pos_vec = _mm_min_epi32(smallest_pos_vec, positives);\n    }\n\n    // Extract results from SIMD registers\n    int temp_negatives[4];\n    int temp_positives[4];\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(temp_negatives), largest_neg_vec);\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(temp_positives), smallest_pos_vec);\n\n    for (int j = 0; j < 4; ++j) {\n        if (temp_negatives[j] < largest_negative && temp_negatives[j] != 0) {\n            largest_negative = temp_negatives[j];\n        }\n        if (temp_positives[j] > 0 && temp_positives[j] < smallest_positive) {\n            smallest_positive = temp_positives[j];\n        }\n    }\n\n    // Process remaining elements that didn't fit into SIMD\n    for (; i < size; ++i) {\n        if (lst[i] < 0 && lst[i] > largest_negative) {\n            largest_negative = lst[i];\n        } else if (lst[i] > 0 && lst[i] < smallest_positive) {\n            smallest_positive = lst[i];\n        }\n    }\n\n    return {largest_negative, smallest_positive};\n}\n```"}
{"task_id": "SimdBench_128_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <limits>\n\nstd::vector<int> largest_smallest_integers_simd(const std::vector<int>& lst) {\n    int largest_negative = 0;\n    int smallest_positive = 0;\n\n    // Check if the input vector is empty\n    if (lst.empty()) {\n        return {largest_negative, smallest_positive};\n    }\n\n    __m128i v_largest_negative = _mm_set1_epi32(std::numeric_limits<int>::min());\n    __m128i v_smallest_positive = _mm_set1_epi32(std::numeric_limits<int>::max());\n\n    size_t i = 0;\n    size_t size = lst.size();\n\n    // Process elements in chunks of 4 using SIMD\n    for (; i + 4 <= size; i += 4) {\n        // Load 4 integers into a SIMD register\n        __m128i v = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&lst[i]));\n\n        // Mask for negative numbers\n        __m128i v_neg_mask = _mm_cmplt_epi32(v, _mm_setzero_si128());\n        // Mask for positive numbers\n        __m128i v_pos_mask = _mm_cmpgt_epi32(v, _mm_setzero_si128());\n\n        // Extract negatives and update largest_negative\n        __m128i v_negatives = _mm_and_si128(v, v_neg_mask);\n        v_largest_negative = _mm_max_epi32(v_largest_negative, v_negatives);\n\n        // Extract positives and update smallest_positive\n        __m128i v_positives = _mm_and_si128(v, v_pos_mask);\n        v_smallest_positive = _mm_min_epi32(v_smallest_positive, v_positives);\n    }\n\n    // Horizontal reduction for largest_negative\n    int temp[4];\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(temp), v_largest_negative);\n    for (int j = 0; j < 4; ++j) {\n        if (temp[j] < 0 && temp[j] > largest_negative) {\n            largest_negative = temp[j];\n        }\n    }\n\n    // Horizontal reduction for smallest_positive\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(temp), v_smallest_positive);\n    for (int j = 0; j < 4; ++j) {\n        if (temp[j] > 0 && temp[j] < smallest_positive) {\n            smallest_positive = temp[j];\n        }\n    }\n\n    // Process remaining elements (if any)\n    for (; i < size; ++i) {\n        if (lst[i] < 0 && lst[i] > largest_negative) {\n            largest_negative = lst[i];\n        }\n        if (lst[i] > 0 && lst[i] < smallest_positive) {\n            smallest_positive = lst[i];\n        }\n    }\n\n    // If no valid values were found, set to 0\n    if (largest_negative == std::numeric_limits<int>::min()) {\n        largest_negative = 0;\n    }\n    if (smallest_positive == std::numeric_limits<int>::max()) {\n        smallest_positive = 0;\n    }\n\n    return {largest_negative, smallest_positive};\n}\n```"}
{"task_id": "SimdBench_128_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <limits>\n\nstd::vector<int> largest_smallest_integers_simd(const std::vector<int>& lst) {\n    __m128i neg_max = _mm_set1_epi32(std::numeric_limits<int>::min());\n    __m128i pos_min = _mm_set1_epi32(std::numeric_limits<int>::max());\n    __m128i zero = _mm_set1_epi32(0);\n\n    size_t i = 0;\n    size_t size = lst.size();\n\n    for (; i + 4 <= size; i += 4) {\n        __m128i vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&lst[i]));\n\n        // Mask for negative numbers\n        __m128i neg_mask = _mm_cmplt_epi32(vec, zero);\n        // Mask for positive numbers\n        __m128i pos_mask = _mm_cmpgt_epi32(vec, zero);\n\n        // Update largest negative\n        __m128i neg_vals = _mm_and_si128(vec, neg_mask);\n        neg_max = _mm_max_epi32(neg_max, neg_vals);\n\n        // Update smallest positive\n        __m128i pos_vals = _mm_and_si128(vec, pos_mask);\n        pos_min = _mm_min_epi32(pos_min, _mm_or_si128(pos_vals, _mm_andnot_si128(pos_mask, _mm_set1_epi32(std::numeric_limits<int>::max()))));\n    }\n\n    // Handle remaining elements\n    for (; i < size; ++i) {\n        int val = lst[i];\n        if (val < 0) {\n            neg_max = _mm_max_epi32(neg_max, _mm_set1_epi32(val));\n        } else if (val > 0) {\n            pos_min = _mm_min_epi32(pos_min, _mm_set1_epi32(val));\n        }\n    }\n\n    // Extract results\n    alignas(16) int temp[4];\n    _mm_store_si128(reinterpret_cast<__m128i*>(temp), neg_max);\n    int largest_neg = std::max({temp[0], temp[1], temp[2], temp[3]});\n    _mm_store_si128(reinterpret_cast<__m128i*>(temp), pos_min);\n    int smallest_pos = std::min({temp[0], temp[1], temp[2], temp[3]});\n\n    // Adjust results\n    largest_neg = (largest_neg < 0) ? largest_neg : 0;\n    smallest_pos = (smallest_pos > 0) ? smallest_pos : 0;\n\n    return {largest_neg, smallest_pos};\n}\n```"}
{"task_id": "SimdBench_128_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n#include <limits>\n\nstd::vector<int> largest_smallest_integers_simd(const std::vector<int>& lst) {\n    int largest_negative = 0;\n    int smallest_positive = 0;\n\n    __m128i zero = _mm_setzero_si128();\n    __m128i largest_neg_vec = _mm_set1_epi32(std::numeric_limits<int>::min());\n    __m128i smallest_pos_vec = _mm_set1_epi32(std::numeric_limits<int>::max());\n\n    size_t i = 0;\n    size_t size = lst.size();\n\n    // Process 4 integers at a time using SIMD\n    for (; i + 4 <= size; i += 4) {\n        __m128i vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&lst[i]));\n\n        // Compare for negative numbers\n        __m128i mask_neg = _mm_cmplt_epi32(vec, zero);\n        __m128i neg_values = _mm_and_si128(vec, mask_neg);\n        __m128i non_neg_values = _mm_andnot_si128(mask_neg, _mm_set1_epi32(std::numeric_limits<int>::min()));\n        __m128i combined_neg = _mm_or_si128(neg_values, non_neg_values);\n        largest_neg_vec = _mm_max_epi32(largest_neg_vec, combined_neg);\n\n        // Compare for positive numbers\n        __m128i mask_pos = _mm_cmpgt_epi32(vec, zero);\n        __m128i pos_values = _mm_and_si128(vec, mask_pos);\n        __m128i non_pos_values = _mm_andnot_si128(mask_pos, _mm_set1_epi32(std::numeric_limits<int>::max()));\n        __m128i combined_pos = _mm_or_si128(pos_values, non_pos_values);\n        smallest_pos_vec = _mm_min_epi32(smallest_pos_vec, combined_pos);\n    }\n\n    // Extract results from SIMD registers\n    int temp_neg[4], temp_pos[4];\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(temp_neg), largest_neg_vec);\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(temp_pos), smallest_pos_vec);\n\n    for (int j = 0; j < 4; ++j) {\n        if (temp_neg[j] < 0 && temp_neg[j] > largest_negative) {\n            largest_negative = temp_neg[j];\n        }\n        if (temp_pos[j] > 0 && temp_pos[j] < smallest_positive) {\n            smallest_positive = temp_pos[j];\n        }\n    }\n\n    // Process remaining elements\n    for (; i < size; ++i) {\n        if (lst[i] < 0 && lst[i] > largest_negative) {\n            largest_negative = lst[i];\n        }\n        if (lst[i] > 0 && lst[i] < smallest_positive) {\n            smallest_positive = lst[i];\n        }\n    }\n\n    return {largest_negative, smallest_positive};\n}\n```"}
{"task_id": "SimdBench_129_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nuint64_t special_factorial_simd(uint64_t n) {\n    __m128i result = _mm_set1_epi64x(1); // Initialize result vector with 1s\n    __m128i factorial = _mm_set1_epi64x(1); // Initialize factorial vector with 1s\n    __m128i one = _mm_set1_epi64x(1); // Vector of ones for incrementing\n\n    for (uint64_t i = 1; i <= n; ++i) {\n        __m128i current = _mm_set1_epi64x(i); // Current number as a vector\n        factorial = _mm_mul_epu32(factorial, current); // Compute factorial(i)\n        result = _mm_mul_epu32(result, factorial); // Multiply result by factorial(i)\n    }\n\n    // Extract the lower 64-bit integer from the result vector\n    uint64_t final_result;\n    _mm_storel_epi64((__m128i*)&final_result, result);\n    return final_result;\n}\n```"}
{"task_id": "SimdBench_129_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nuint64_t special_factorial_simd(uint64_t n) {\n    __m128i result = _mm_set1_epi64x(1); // Initialize result vector with 1s\n    __m128i factorial = _mm_set1_epi64x(1); // Initialize factorial vector with 1s\n    __m128i one = _mm_set1_epi64x(1); // Constant vector of 1s\n    __m128i i = _mm_set1_epi64x(1); // Loop counter\n\n    for (uint64_t num = 1; num <= n; ++num) {\n        __m128i current = _mm_set1_epi64x(num); // Current number in the loop\n        factorial = _mm_mul_epu32(factorial, current); // Compute factorial iteratively\n        result = _mm_mul_epu32(result, factorial); // Multiply result by current factorial\n    }\n\n    // Extract the lower 64-bit integer from the result vector\n    uint64_t final_result = 1;\n    final_result *= _mm_extract_epi64(result, 0);\n    return final_result;\n}\n```"}
{"task_id": "SimdBench_129_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nuint64_t special_factorial_simd(uint64_t n) {\n    __m128i result = _mm_set1_epi64x(1); // Initialize result vector with 1s\n    __m128i factorial = _mm_set1_epi64x(1); // Initialize factorial vector with 1s\n    __m128i one = _mm_set1_epi64x(1); // Vector of ones for incrementing\n\n    for (uint64_t i = 1; i <= n; ++i) {\n        __m128i current = _mm_set1_epi64x(i); // Current number as a vector\n        factorial = _mm_mul_epu32(factorial, current); // Compute factorial iteratively\n        result = _mm_mul_epu32(result, factorial); // Multiply result by current factorial\n    }\n\n    // Extract the lower 64-bit integer from the result vector\n    uint64_t final_result = 1;\n    final_result *= _mm_extract_epi64(result, 0);\n    return final_result;\n}\n```"}
{"task_id": "SimdBench_129_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nuint64_t special_factorial_simd(uint64_t n) {\n    __m128i result = _mm_set1_epi64x(1); // Initialize result vector with 1s\n    __m128i factorial = _mm_set1_epi64x(1); // Initialize factorial vector with 1s\n    __m128i one = _mm_set1_epi64x(1); // Constant vector of 1s\n    __m128i i = _mm_set1_epi64x(1); // Loop counter\n\n    for (uint64_t k = 1; k <= n; ++k) {\n        __m128i current_factorial = _mm_set1_epi64x(1); // Reset current factorial\n        __m128i j = _mm_set1_epi64x(1); // Inner loop counter\n\n        for (uint64_t m = 1; m <= k; ++m) {\n            current_factorial = _mm_mul_epu32(current_factorial, j); // Multiply current factorial by j\n            j = _mm_add_epi64(j, one); // Increment inner loop counter\n        }\n\n        result = _mm_mul_epu32(result, current_factorial); // Multiply result by current factorial\n    }\n\n    uint64_t final_result[2];\n    _mm_storeu_si128((__m128i*)final_result, result); // Store result into array\n    return final_result[0] * final_result[1]; // Combine results\n}\n```"}
{"task_id": "SimdBench_129_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nuint64_t special_factorial_simd(uint64_t n) {\n    __m128i result = _mm_set1_epi64x(1); // Initialize result vector with 1s\n    __m128i factorial = _mm_set1_epi64x(1); // Initialize factorial vector with 1s\n    __m128i one = _mm_set1_epi64x(1); // Constant vector of 1s\n    __m128i i = _mm_set1_epi64x(1); // Loop counter\n\n    for (uint64_t num = 1; num <= n; ++num) {\n        __m128i current = _mm_set1_epi64x(num); // Current number in the loop\n        factorial = _mm_mul_epu32(factorial, current); // Compute factorial\n        result = _mm_mul_epu32(result, factorial); // Multiply result by factorial\n    }\n\n    // Extract the lower 64-bit integer from the result vector\n    uint64_t final_result = 1;\n    final_result *= _mm_extract_epi64(result, 0);\n    return final_result;\n}\n```"}
{"task_id": "SimdBench_130_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint sum_squares_simd(const std::vector<int> & lst) {\n    int sum = 0;\n    int n = lst.size();\n    int i = 0;\n\n    // Process 4 elements at a time using SSE2 intrinsics\n    for (; i + 4 <= n; i += 4) {\n        // Load 4 integers into an SSE register\n        __m128i vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&lst[i]));\n\n        // Prepare masks for multiples of 3 and multiples of 4 (not multiples of 3)\n        __m128i idx = _mm_set_epi32(i + 3, i + 2, i + 1, i);\n        __m128i mask_mult_3 = _mm_setzero_si128();\n        __m128i mask_mult_4_not_3 = _mm_setzero_si128();\n\n        // Compute masks\n        __m128i mod3 = _mm_rem_epi32(idx, _mm_set1_epi32(3));\n        __m128i mod4 = _mm_rem_epi32(idx, _mm_set1_epi32(4));\n        mask_mult_3 = _mm_cmpeq_epi32(mod3, _mm_setzero_si128());\n        mask_mult_4_not_3 = _mm_and_si128(_mm_cmpeq_epi32(mod4, _mm_setzero_si128()),\n                                          _mm_cmpneq_epi32(mod3, _mm_setzero_si128()));\n\n        // Square elements where index is a multiple of 3\n        __m128i squared = _mm_mullo_epi32(vec, vec);\n        vec = _mm_blendv_epi8(vec, squared, mask_mult_3);\n\n        // Cube elements where index is a multiple of 4 but not 3\n        __m128i cubed = _mm_mullo_epi32(vec, vec);\n        cubed = _mm_mullo_epi32(cubed, vec);\n        vec = _mm_blendv_epi8(vec, cubed, mask_mult_4_not_3);\n\n        // Add the results to the sum\n        int temp[4];\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(temp), vec);\n        sum += temp[0] + temp[1] + temp[2] + temp[3];\n    }\n\n    // Process remaining elements\n    for (; i < n; ++i) {\n        if (i % 3 == 0) {\n            sum += lst[i] * lst[i];\n        } else if (i % 4 == 0) {\n            sum += lst[i] * lst[i] * lst[i];\n        } else {\n            sum += lst[i];\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_130_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint sum_squares_simd(const std::vector<int> & lst) {\n    int sum = 0;\n    size_t i = 0;\n    size_t size = lst.size();\n\n    // Process 4 elements at a time using SSE\n    for (; i + 4 <= size; i += 4) {\n        // Load 4 integers into an SSE register\n        __m128i vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&lst[i]));\n\n        // Create masks for multiples of 3 and multiples of 4 (not multiples of 3)\n        __m128i idx = _mm_set_epi32(i + 3, i + 2, i + 1, i);\n        __m128i mask3 = _mm_setzero_si128();\n        __m128i mask4 = _mm_setzero_si128();\n\n        // Check indices for multiples of 3\n        mask3 = _mm_cmpeq_epi32(_mm_and_si128(idx, _mm_set1_epi32(3)), _mm_setzero_si128());\n\n        // Check indices for multiples of 4 and not multiples of 3\n        __m128i mod4 = _mm_and_si128(idx, _mm_set1_epi32(4));\n        __m128i not_mod3 = _mm_andnot_si128(mask3, _mm_set1_epi32(-1));\n        mask4 = _mm_and_si128(_mm_cmpeq_epi32(mod4, _mm_setzero_si128()), not_mod3);\n\n        // Square elements where index is a multiple of 3\n        __m128i squared = _mm_mullo_epi32(vec, vec);\n        vec = _mm_blendv_epi8(vec, squared, mask3);\n\n        // Cube elements where index is a multiple of 4 and not a multiple of 3\n        __m128i cubed = _mm_mullo_epi32(_mm_mullo_epi32(vec, vec), vec);\n        vec = _mm_blendv_epi8(vec, cubed, mask4);\n\n        // Horizontally add the results\n        int temp[4];\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(temp), vec);\n        sum += temp[0] + temp[1] + temp[2] + temp[3];\n    }\n\n    // Process remaining elements\n    for (; i < size; ++i) {\n        if (i % 3 == 0) {\n            sum += lst[i] * lst[i];\n        } else if (i % 4 == 0) {\n            sum += lst[i] * lst[i] * lst[i];\n        } else {\n            sum += lst[i];\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_130_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint sum_squares_simd(const std::vector<int> & lst) {\n    int sum = 0;\n    size_t i = 0;\n    size_t size = lst.size();\n\n    // Process 4 elements at a time using SSE2 intrinsics\n    for (; i + 4 <= size; i += 4) {\n        // Load 4 integers into an SSE register\n        __m128i vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&lst[i]));\n\n        // Create masks for multiples of 3 and multiples of 4 (not multiples of 3)\n        __m128i idx = _mm_set_epi32(i + 3, i + 2, i + 1, i);\n        __m128i mask3 = _mm_setzero_si128();\n        __m128i mask4 = _mm_setzero_si128();\n\n        // Check if indices are multiples of 3\n        mask3 = _mm_cmpeq_epi32(_mm_and_si128(idx, _mm_set1_epi32(3)), _mm_setzero_si128());\n\n        // Check if indices are multiples of 4 and not multiples of 3\n        __m128i mod4 = _mm_and_si128(idx, _mm_set1_epi32(4));\n        mask4 = _mm_and_si128(_mm_cmpeq_epi32(mod4, _mm_setzero_si128()), _mm_xor_si128(mask3, _mm_set1_epi32(-1)));\n\n        // Square the elements where mask3 is true\n        __m128i squared = _mm_mullo_epi32(vec, vec);\n        vec = _mm_blendv_epi8(vec, squared, mask3);\n\n        // Cube the elements where mask4 is true\n        __m128i cubed = _mm_mullo_epi32(vec, _mm_mullo_epi32(vec, vec));\n        vec = _mm_blendv_epi8(vec, cubed, mask4);\n\n        // Horizontally add the results to the sum\n        int temp[4];\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(temp), vec);\n        sum += temp[0] + temp[1] + temp[2] + temp[3];\n    }\n\n    // Process remaining elements\n    for (; i < size; ++i) {\n        if (i % 3 == 0) {\n            sum += lst[i] * lst[i];\n        } else if (i % 4 == 0) {\n            sum += lst[i] * lst[i] * lst[i];\n        } else {\n            sum += lst[i];\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_130_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint sum_squares_simd(const std::vector<int> & lst) {\n    int sum = 0;\n    size_t i = 0;\n    size_t n = lst.size();\n\n    // Process 4 elements at a time using SSE2 intrinsics\n    for (; i + 4 <= n; i += 4) {\n        // Load 4 integers into an SSE register\n        __m128i vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&lst[i]));\n\n        // Create masks for multiples of 3 and multiples of 4 (not multiples of 3)\n        __m128i idx = _mm_set_epi32(i + 3, i + 2, i + 1, i);\n        __m128i mask_mult3 = _mm_setzero_si128();\n        __m128i mask_mult4_not3 = _mm_setzero_si128();\n\n        for (int j = 0; j < 4; ++j) {\n            int index = i + j;\n            if (index % 3 == 0) {\n                mask_mult3 = _mm_insert_epi32(mask_mult3, -1, j);\n            } else if (index % 4 == 0) {\n                mask_mult4_not3 = _mm_insert_epi32(mask_mult4_not3, -1, j);\n            }\n        }\n\n        // Square elements where index is a multiple of 3\n        __m128i squared = _mm_mullo_epi32(vec, vec);\n        vec = _mm_blendv_epi8(vec, squared, mask_mult3);\n\n        // Cube elements where index is a multiple of 4 (not multiple of 3)\n        __m128i cubed = _mm_mullo_epi32(vec, vec);\n        cubed = _mm_mullo_epi32(cubed, vec);\n        vec = _mm_blendv_epi8(vec, cubed, mask_mult4_not3);\n\n        // Extract and add the results to the sum\n        int temp[4];\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(temp), vec);\n        for (int j = 0; j < 4; ++j) {\n            sum += temp[j];\n        }\n    }\n\n    // Process remaining elements\n    for (; i < n; ++i) {\n        if (i % 3 == 0) {\n            sum += lst[i] * lst[i];\n        } else if (i % 4 == 0) {\n            sum += lst[i] * lst[i] * lst[i];\n        } else {\n            sum += lst[i];\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_130_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint sum_squares_simd(const std::vector<int> & lst) {\n    int sum = 0;\n    int n = lst.size();\n    int i = 0;\n\n    // Process 4 elements at a time using SSE\n    for (; i + 3 < n; i += 4) {\n        // Load 4 integers into an SSE register\n        __m128i vec = _mm_loadu_si128((__m128i*)&lst[i]);\n\n        // Prepare masks for multiples of 3 and 4\n        __m128i idx = _mm_set_epi32(i + 3, i + 2, i + 1, i);\n        __m128i mod3 = _mm_set1_epi32(3);\n        __m128i mod4 = _mm_set1_epi32(4);\n\n        __m128i is_mod3 = _mm_cmpeq_epi32(_mm_rem_epi32(idx, mod3), _mm_setzero_si128());\n        __m128i is_mod4 = _mm_andnot_si128(is_mod3, _mm_cmpeq_epi32(_mm_rem_epi32(idx, mod4), _mm_setzero_si128()));\n\n        // Square elements where index is a multiple of 3\n        __m128i squared = _mm_mullo_epi32(vec, vec);\n        vec = _mm_blendv_epi8(vec, squared, is_mod3);\n\n        // Cube elements where index is a multiple of 4 and not 3\n        __m128i cubed = _mm_mullo_epi32(vec, vec);\n        cubed = _mm_mullo_epi32(cubed, vec);\n        vec = _mm_blendv_epi8(vec, cubed, is_mod4);\n\n        // Add the processed values to the sum\n        int temp[4];\n        _mm_storeu_si128((__m128i*)temp, vec);\n        sum += temp[0] + temp[1] + temp[2] + temp[3];\n    }\n\n    // Process remaining elements\n    for (; i < n; ++i) {\n        if (i % 3 == 0) {\n            sum += lst[i] * lst[i];\n        } else if (i % 4 == 0) {\n            sum += lst[i] * lst[i] * lst[i];\n        } else {\n            sum += lst[i];\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_131_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint specialFilter_simd(const std::vector<int> & nums) {\n    int count = 0;\n    __m128i v_ten = _mm_set1_epi32(10);\n    __m128i v_odd_mask = _mm_set1_epi32(1); // Used to check if a digit is odd\n\n    for (size_t i = 0; i < nums.size(); i += 4) {\n        // Load 4 integers into a SIMD register\n        __m128i v_nums = _mm_loadu_si128((__m128i*)&nums[i]);\n\n        // Check if numbers are greater than 10\n        __m128i v_gt_ten = _mm_cmpgt_epi32(v_nums, v_ten);\n\n        // Extract absolute values for first and last digit calculations\n        __m128i v_abs_nums = _mm_abs_epi32(v_nums);\n\n        // Compute last digit: num % 10\n        __m128i v_last_digit = _mm_rem_epu32(v_abs_nums, _mm_set1_epi32(10));\n\n        // Compute first digit\n        __m128i v_first_digit = v_abs_nums;\n        for (int j = 0; j < 9; ++j) { // Iteratively divide by 10 to get the first digit\n            v_first_digit = _mm_srli_epi32(v_first_digit, 1); // Approximation of division by 10\n        }\n\n        // Check if first and last digits are odd\n        __m128i v_first_odd = _mm_and_si128(v_first_digit, v_odd_mask);\n        __m128i v_last_odd = _mm_and_si128(v_last_digit, v_odd_mask);\n\n        // Combine conditions: greater than 10, first digit odd, last digit odd\n        __m128i v_valid = _mm_and_si128(v_gt_ten, _mm_and_si128(v_first_odd, v_last_odd));\n\n        // Count valid elements\n        int mask = _mm_movemask_ps((__m128)v_valid);\n        count += __builtin_popcount(mask);\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_131_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint specialFilter_simd(const std::vector<int> & nums) {\n    int count = 0;\n    __m128i v_ten = _mm_set1_epi32(10);\n    __m128i v_odd_mask = _mm_set1_epi32(1); // Used to check if a digit is odd\n\n    for (size_t i = 0; i < nums.size(); i += 4) {\n        // Load 4 integers into a SIMD register\n        __m128i v_nums = _mm_loadu_si128((__m128i*)&nums[i]);\n\n        // Check if numbers are greater than 10\n        __m128i v_gt_ten = _mm_cmpgt_epi32(v_nums, v_ten);\n\n        // Extract absolute values for digit checks\n        __m128i v_abs_nums = _mm_abs_epi32(v_nums);\n\n        // Get the last digit by modulo 10\n        __m128i v_last_digit = _mm_rem_epu32(v_abs_nums, _mm_set1_epi32(10));\n\n        // Get the first digit\n        __m128i v_first_digit = v_abs_nums;\n        for (int j = 0; j < 9; ++j) { // Iteratively divide by 10 to get the first digit\n            v_first_digit = _mm_div_epi32(v_first_digit, _mm_set1_epi32(10));\n        }\n\n        // Check if both first and last digits are odd\n        __m128i v_first_odd = _mm_and_si128(v_first_digit, v_odd_mask);\n        __m128i v_last_odd = _mm_and_si128(v_last_digit, v_odd_mask);\n        __m128i v_both_odd = _mm_and_si128(v_first_odd, v_last_odd);\n\n        // Combine conditions: greater than 10 AND both digits odd\n        __m128i v_valid = _mm_and_si128(v_gt_ten, v_both_odd);\n\n        // Count the number of valid elements in this iteration\n        int mask = _mm_movemask_ps((__m128)v_valid);\n        count += __builtin_popcount(mask);\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_131_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nint specialFilter_simd(const std::vector<int> & nums) {\n    int count = 0;\n    __m128i v10 = _mm_set1_epi32(10); // Vector with all elements set to 10\n    __m128i v1 = _mm_set1_epi32(1);   // Vector with all elements set to 1\n    __m128i v_odd_mask = _mm_set1_epi32(0x1); // Mask to check oddness (last bit)\n\n    for (size_t i = 0; i < nums.size(); i += 4) {\n        // Load 4 integers into a SIMD register\n        __m128i v_nums = _mm_loadu_si128((__m128i*)&nums[i]);\n\n        // Check if numbers are greater than 10\n        __m128i v_gt_10 = _mm_cmpgt_epi32(v_nums, v10);\n\n        // Extract absolute values for first digit calculation\n        __m128i v_abs_nums = _mm_abs_epi32(v_nums);\n\n        // Compute the first digit of each number\n        __m128i v_first_digit = v_abs_nums;\n        for (int j = 0; j < 9; ++j) { // Divide by 10 repeatedly to get the first digit\n            v_first_digit = _mm_cvtps_epi32(_mm_round_ps(_mm_cvtepi32_ps(v_first_digit), _MM_FROUND_TO_ZERO | _MM_FROUND_NO_EXC));\n            v_first_digit = _mm_srli_epi32(v_first_digit, 1);\n        }\n\n        // Check if the first digit is odd\n        __m128i v_first_digit_odd = _mm_and_si128(v_first_digit, v_odd_mask);\n\n        // Check if the last digit is odd\n        __m128i v_last_digit = _mm_and_si128(v_abs_nums, v_odd_mask);\n\n        // Combine conditions: greater than 10, first digit odd, last digit odd\n        __m128i v_valid = _mm_and_si128(v_gt_10, _mm_and_si128(v_first_digit_odd, v_last_digit));\n\n        // Count valid elements in this iteration\n        int mask = _mm_movemask_ps((__m128)v_valid);\n        count += __builtin_popcount(mask);\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_131_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint specialFilter_simd(const std::vector<int> & nums) {\n    int count = 0;\n    __m128i v10 = _mm_set1_epi32(10); // Vector with all elements set to 10\n    __m128i vOddMask = _mm_set1_epi32(1); // Mask for odd check (1 in LSB)\n\n    for (size_t i = 0; i < nums.size(); i += 4) {\n        // Load 4 integers into a SIMD register\n        __m128i vNums = _mm_loadu_si128((__m128i*)&nums[i]);\n\n        // Check if numbers are greater than 10\n        __m128i vGt10 = _mm_cmpgt_epi32(vNums, v10);\n\n        // Extract absolute values for first and last digit checks\n        __m128i vAbsNums = _mm_abs_epi32(vNums);\n\n        // Compute last digit by modulo 10\n        __m128i vLastDigit = _mm_and_si128(vAbsNums, _mm_set1_epi32(0xF));\n        __m128i vLastDigitOdd = _mm_and_si128(vLastDigit, vOddMask);\n\n        // Compute first digit by repeatedly dividing by 10\n        __m128i vFirstDigit = vAbsNums;\n        for (int j = 0; j < 9; ++j) { // Max iterations to get first digit\n            vFirstDigit = _mm_srli_epi32(vFirstDigit, 1); // Divide by 2\n        }\n        __m128i vFirstDigitOdd = _mm_and_si128(vFirstDigit, vOddMask);\n\n        // Combine conditions: greater than 10, first digit odd, last digit odd\n        __m128i vValid = _mm_and_si128(vGt10, _mm_and_si128(vFirstDigitOdd, vLastDigitOdd));\n\n        // Count valid elements\n        int mask = _mm_movemask_ps((__m128)vValid);\n        count += __builtin_popcount(mask);\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_131_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint specialFilter_simd(const std::vector<int> & nums) {\n    int count = 0;\n    __m128i v10 = _mm_set1_epi32(10); // Vector with all elements set to 10\n    __m128i vodd_first = _mm_set1_epi32(1); // Used for odd checks\n    __m128i vodd_last = _mm_set1_epi32(1); // Used for odd checks\n\n    size_t i = 0;\n    size_t size = nums.size();\n\n    // Process 4 elements at a time\n    for (; i + 4 <= size; i += 4) {\n        // Load 4 integers into a SIMD register\n        __m128i vnums = _mm_loadu_si128((__m128i*)&nums[i]);\n\n        // Check if numbers are greater than 10\n        __m128i vcmp_gt_10 = _mm_cmpgt_epi32(vnums, v10);\n\n        // Extract absolute values for first and last digit checks\n        __m128i vabs = _mm_abs_epi32(vnums);\n\n        // Compute first digit (repeated division by 10)\n        __m128i vfirst_digit = vabs;\n        for (int j = 0; j < 9; ++j) { // Max 9 divisions for 32-bit int\n            vfirst_digit = _mm_srli_epi32(vfirst_digit, 1); // Divide by 2\n        }\n\n        // Compute last digit (mod 10)\n        __m128i vlast_digit = _mm_and_si128(vabs, _mm_set1_epi32(0xF));\n\n        // Check if first digit is odd\n        __m128i vfirst_odd = _mm_and_si128(vfirst_digit, vodd_first);\n        vfirst_odd = _mm_cmpeq_epi32(vfirst_odd, vodd_first);\n\n        // Check if last digit is odd\n        __m128i vlast_odd = _mm_and_si128(vlast_digit, vodd_last);\n        vlast_odd = _mm_cmpeq_epi32(vlast_odd, vodd_last);\n\n        // Combine conditions: greater than 10, first digit odd, last digit odd\n        __m128i vresult = _mm_and_si128(vcmp_gt_10, _mm_and_si128(vfirst_odd, vlast_odd));\n\n        // Count the number of true results in this iteration\n        int mask = _mm_movemask_ps((__m128)vresult);\n        count += __builtin_popcount(mask);\n    }\n\n    // Process remaining elements\n    for (; i < size; ++i) {\n        int num = nums[i];\n        if (num > 10) {\n            int abs_num = std::abs(num);\n            int first_digit = abs_num;\n            while (first_digit >= 10) {\n                first_digit /= 10;\n            }\n            int last_digit = abs_num % 10;\n            if ((first_digit % 2 == 1) && (last_digit % 2 == 1)) {\n                count++;\n            }\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_132_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nuint64_t get_max_triples_simd(uint64_t n) {\n    uint64_t count = 0;\n    __m128i v_mod3 = _mm_set1_epi32(3);\n    __m128i v_zero = _mm_setzero_si128();\n    __m128i v_count = _mm_setzero_si128();\n\n    // Allocate aligned memory for the array\n    __m128i* a = (__m128i*)_mm_malloc(n * sizeof(int), 16);\n    if (!a) return 0;\n\n    // Fill the array with values a[i] = i * i - i + 1\n    for (uint64_t i = 0; i < n; ++i) {\n        int value = i * i - i + 1;\n        _mm_store_si128(&a[i / 4], _mm_insert_epi32(_mm_load_si128(&a[i / 4]), value, i % 4));\n    }\n\n    // Compute the number of valid triples\n    for (uint64_t i = 0; i < n; ++i) {\n        for (uint64_t j = i + 1; j < n; ++j) {\n            __m128i v_ai = _mm_set1_epi32(i * i - i + 1);\n            __m128i v_aj = _mm_set1_epi32(j * j - j + 1);\n\n            for (uint64_t k = j + 1; k < n; k += 4) {\n                __m128i v_ak = _mm_loadu_si128(&a[k / 4]);\n\n                // Compute (a[i] + a[j] + a[k]) % 3\n                __m128i v_sum = _mm_add_epi32(_mm_add_epi32(v_ai, v_aj), v_ak);\n                __m128i v_mod = _mm_rem_epi32(v_sum, v_mod3);\n\n                // Count how many elements are divisible by 3\n                __m128i v_mask = _mm_cmpeq_epi32(v_mod, v_zero);\n                int mask = _mm_movemask_epi8(v_mask);\n                count += __builtin_popcount(mask) / 4;\n            }\n        }\n    }\n\n    _mm_free(a);\n    return count;\n}\n```"}
{"task_id": "SimdBench_132_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nuint64_t get_max_triples_simd(uint64_t n) {\n    uint64_t count = 0;\n    __m128i mod3_counts = _mm_setzero_si128(); // [count_mod0, count_mod1, count_mod2, unused]\n\n    for (uint64_t i = 1; i <= n; ++i) {\n        uint64_t val = i * i - i + 1;\n        uint64_t mod = val % 3;\n\n        // Load current counts\n        __m128i counts = _mm_load_si128((__m128i*)&mod3_counts);\n\n        if (mod == 0) {\n            // Count triples where two other elements sum to multiple of 3\n            uint64_t count_mod1 = _mm_extract_epi64(counts, 1);\n            uint64_t count_mod2 = _mm_extract_epi64(counts, 2);\n            count += count_mod1 * count_mod2;\n\n            // Increment count_mod0\n            counts = _mm_add_epi64(counts, _mm_set_epi64x(0, 1));\n        } else if (mod == 1) {\n            // Count triples where two other elements sum to multiple of 3\n            uint64_t count_mod0 = _mm_extract_epi64(counts, 0);\n            uint64_t count_mod2 = _mm_extract_epi64(counts, 2);\n            count += count_mod0 * count_mod2;\n\n            // Increment count_mod1\n            counts = _mm_add_epi64(counts, _mm_set_epi64x(0, 0, 1));\n        } else if (mod == 2) {\n            // Count triples where two other elements sum to multiple of 3\n            uint64_t count_mod0 = _mm_extract_epi64(counts, 0);\n            uint64_t count_mod1 = _mm_extract_epi64(counts, 1);\n            count += count_mod0 * count_mod1;\n\n            // Increment count_mod2\n            counts = _mm_add_epi64(counts, _mm_set_epi64x(0, 0, 0, 1));\n        }\n\n        // Store updated counts\n        _mm_store_si128((__m128i*)&mod3_counts, counts);\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_132_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nuint64_t get_max_triples_simd(uint64_t n) {\n    uint64_t count = 0;\n    __m128i v_mod3 = _mm_set1_epi32(3);\n    __m128i v_zero = _mm_setzero_si128();\n    __m128i v_count = _mm_setzero_si128();\n\n    // Allocate aligned memory for the array\n    __m128i* a = (__m128i*)_mm_malloc((n + 4) * sizeof(int), 16);\n    int* a_int = (int*)a;\n\n    // Compute a[i] = i * i - i + 1 for all i\n    for (uint64_t i = 1; i <= n; ++i) {\n        a_int[i - 1] = i * i - i + 1;\n    }\n\n    // Process in chunks of 4 using SIMD\n    for (uint64_t i = 0; i < n; i++) {\n        __m128i v_a_i = _mm_set1_epi32(a_int[i]);\n        for (uint64_t j = i + 1; j + 4 <= n; j += 4) {\n            __m128i v_a_j = _mm_loadu_si128(&a[j]);\n            for (uint64_t k = j + 1; k + 4 <= n; k += 4) {\n                __m128i v_a_k = _mm_loadu_si128(&a[k]);\n\n                // Compute sum = a[i] + a[j] + a[k]\n                __m128i v_sum = _mm_add_epi32(v_a_i, v_a_j);\n                v_sum = _mm_add_epi32(v_sum, v_a_k);\n\n                // Compute sum % 3\n                __m128i v_mod = _mm_rem_epu32(v_sum, v_mod3);\n\n                // Compare if sum % 3 == 0\n                __m128i v_cmp = _mm_cmpeq_epi32(v_mod, v_zero);\n\n                // Count the number of valid triples\n                int mask = _mm_movemask_epi8(v_cmp);\n                count += __builtin_popcount(mask) / 4;\n            }\n        }\n    }\n\n    // Handle remaining elements that don't fit into SIMD chunks\n    for (uint64_t i = 0; i < n; i++) {\n        for (uint64_t j = i + 1; j < n; j++) {\n            for (uint64_t k = j + 1; k < n; k++) {\n                int sum = a_int[i] + a_int[j] + a_int[k];\n                if (sum % 3 == 0) {\n                    count++;\n                }\n            }\n        }\n    }\n\n    _mm_free(a);\n    return count;\n}\n```"}
{"task_id": "SimdBench_132_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nuint64_t get_max_triples_simd(uint64_t n) {\n    uint64_t count = 0;\n    __m128i mod3_counts = _mm_setzero_si128(); // [count_mod0, count_mod1, count_mod2, unused]\n\n    for (uint64_t i = 1; i <= n; ++i) {\n        uint64_t val = i * i - i + 1;\n        uint64_t mod = val % 3;\n\n        // Load current counts\n        __m128i counts = _mm_load_si128((__m128i*)&mod3_counts);\n\n        if (mod == 0) {\n            // Count triples where two other elements sum to multiple of 3\n            uint64_t count_mod1 = _mm_extract_epi64(counts, 1);\n            uint64_t count_mod2 = _mm_extract_epi64(counts, 2);\n            count += count_mod1 * count_mod2;\n\n            // Increment count_mod0\n            counts = _mm_add_epi64(counts, _mm_set_epi64x(0, 1));\n        } else if (mod == 1) {\n            // Count triples where two other elements sum to multiple of 3\n            uint64_t count_mod0 = _mm_extract_epi64(counts, 0);\n            uint64_t count_mod2 = _mm_extract_epi64(counts, 2);\n            count += count_mod0 * count_mod2;\n\n            // Increment count_mod1\n            counts = _mm_add_epi64(counts, _mm_set_epi64x(0, 1 << 32));\n        } else { // mod == 2\n            // Count triples where two other elements sum to multiple of 3\n            uint64_t count_mod0 = _mm_extract_epi64(counts, 0);\n            uint64_t count_mod1 = _mm_extract_epi64(counts, 1);\n            count += count_mod0 * count_mod1;\n\n            // Increment count_mod2\n            counts = _mm_add_epi64(counts, _mm_set_epi64x(1, 0));\n        }\n\n        // Store updated counts\n        _mm_store_si128((__m128i*)&mod3_counts, counts);\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_132_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nuint64_t get_max_triples_simd(uint64_t n) {\n    uint64_t count = 0;\n    __m128i v_mod3 = _mm_set1_epi32(3);\n    __m128i v_zero = _mm_setzero_si128();\n    __m128i v_one = _mm_set1_epi32(1);\n\n    // Allocate aligned memory for the array\n    uint64_t size = (n + 3) & ~3; // Round up to multiple of 4 for SIMD alignment\n    int* a = (int*)_mm_malloc(size * sizeof(int), 16);\n\n    // Fill the array with values a[i] = i * i - i + 1\n    for (uint64_t i = 0; i < n; ++i) {\n        a[i] = i * i - i + 1;\n    }\n    for (uint64_t i = n; i < size; ++i) {\n        a[i] = 0; // Padding with zeros\n    }\n\n    // Compute mod 3 for all elements using SIMD\n    __m128i* ptr = (__m128i*)a;\n    __m128i v_mod_results[size / 4];\n    for (uint64_t i = 0; i < size / 4; ++i) {\n        __m128i v_a = _mm_load_si128(ptr + i);\n        __m128i v_mod = _mm_rem_epi32(v_a, v_mod3); // Compute a[i] % 3\n        v_mod_results[i] = v_mod;\n    }\n\n    // Count triples where (a[i] + a[j] + a[k]) % 3 == 0\n    for (uint64_t i = 0; i < n; ++i) {\n        for (uint64_t j = i + 1; j < n; ++j) {\n            int mod_ij = (a[i] % 3 + a[j] % 3) % 3;\n            int target_mod = (3 - mod_ij) % 3;\n\n            // Use SIMD to count elements with the required mod value\n            uint64_t k_count = 0;\n            for (uint64_t k = j + 1; k < size; k += 4) {\n                __m128i v_mod_k = v_mod_results[k / 4];\n                __m128i v_target = _mm_set1_epi32(target_mod);\n                __m128i v_cmp = _mm_cmpeq_epi32(v_mod_k, v_target);\n                int mask = _mm_movemask_epi8(v_cmp);\n                k_count += __builtin_popcount(mask);\n            }\n            count += k_count;\n        }\n    }\n\n    _mm_free(a);\n    return count;\n}\n```"}
{"task_id": "SimdBench_133_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint x_or_y_simd(int n, int x, int y) {\n    if (n <= 1) return y;\n\n    __m128i vn = _mm_set1_epi32(n);\n    __m128i vprime = _mm_set1_epi32(1); // Assume prime initially\n    __m128i vzero = _mm_setzero_si128();\n    __m128i vrange = _mm_setr_epi32(2, 3, 4, 5); // Start checking divisors from 2\n\n    for (int i = 2; i * i <= n; i++) {\n        __m128i vi = _mm_set1_epi32(i);\n        __m128i vmod = _mm_rem_epi32(vn, vi); // Compute n % i for each lane\n        __m128i vcmp = _mm_cmpeq_epi32(vmod, vzero); // Check if remainder is zero\n        vprime = _mm_andnot_si128(vcmp, vprime); // Update primality mask\n    }\n\n    // Reduce the primality mask to a scalar value\n    int mask = _mm_movemask_ps(_mm_castsi128_ps(vprime));\n    int is_prime = (mask == 0xF) ? 1 : 0;\n\n    return is_prime ? x : y;\n}\n```"}
{"task_id": "SimdBench_133_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint x_or_y_simd(int n, int x, int y) {\n    if (n <= 1) return y;\n\n    __m128i vn = _mm_set1_epi32(n);\n    __m128i vprime = _mm_set1_epi32(1); // Assume prime initially\n    __m128i vzero = _mm_set1_epi32(0);\n\n    for (int i = 2; i * i <= n && i < 8; ++i) {\n        __m128i vi = _mm_set1_epi32(i);\n        __m128i vmod = _mm_set1_epi32(n % i);\n        __m128i vcmp = _mm_cmpeq_epi32(vmod, vzero);\n        vprime = _mm_andnot_si128(vcmp, vprime);\n    }\n\n    int mask = _mm_movemask_epi8(vprime);\n    int is_prime = (mask == 0xFFFF);\n\n    return is_prime ? x : y;\n}\n```"}
{"task_id": "SimdBench_133_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint x_or_y_simd(int n, int x, int y) {\n    if (n <= 1) return y;\n\n    __m128i vn = _mm_set1_epi32(n);\n    __m128i vx = _mm_set1_epi32(x);\n    __m128i vy = _mm_set1_epi32(y);\n    __m128i vresult = vy; // Default to y\n\n    __m128i vprime = _mm_set1_epi32(1); // Assume prime initially\n\n    for (int i = 2; i * i <= n; ++i) {\n        __m128i vi = _mm_set1_epi32(i);\n        __m128i vmod = _mm_set1_epi32(n % i);\n\n        // Check if n % i == 0\n        __m128i vcmp = _mm_cmpeq_epi32(vmod, _mm_setzero_si128());\n        vprime = _mm_andnot_si128(vcmp, vprime); // Clear prime flag if divisible\n    }\n\n    // If any element in vprime is non-zero, n is prime\n    int mask = _mm_movemask_epi8(vprime);\n    if (mask != 0) {\n        vresult = vx;\n    }\n\n    // Extract result\n    int result;\n    _mm_storeu_si128((__m128i*)&result, vresult);\n    return result;\n}\n```"}
{"task_id": "SimdBench_133_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint x_or_y_simd(int n, int x, int y) {\n    if (n <= 1) return y;\n\n    __m128i vn = _mm_set1_epi32(n);\n    __m128i vx = _mm_set1_epi32(x);\n    __m128i vy = _mm_set1_epi32(y);\n    __m128i vresult = vy; // Assume not prime initially\n\n    // Check divisors from 2 to sqrt(n)\n    for (int i = 2; i * i <= n; ++i) {\n        __m128i vi = _mm_set1_epi32(i);\n        __m128i vmod = _mm_rem_epi32(vn, vi); // Compute n % i\n        __m128i vcmp = _mm_cmpeq_epi32(vmod, _mm_setzero_si128()); // Check if n % i == 0\n        vresult = _mm_blendv_epi8(vresult, vy, vcmp); // If divisible, set result to y\n    }\n\n    // Check if n is prime\n    __m128i vprime_check = _mm_cmpeq_epi32(vresult, vy); // If result is still y, n is not prime\n    vresult = _mm_blendv_epi8(vx, vresult, vprime_check); // If prime, set result to x\n\n    // Extract the result\n    int result[4];\n    _mm_storeu_si128((__m128i*)result, vresult);\n    return result[0];\n}\n```"}
{"task_id": "SimdBench_133_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nint x_or_y_simd(int n, int x, int y) {\n    // Load n into all elements of an SSE register\n    __m128i vn = _mm_set1_epi32(n);\n\n    // Initialize a vector for the result (default to y)\n    __m128i vy = _mm_set1_epi32(y);\n    __m128i vx = _mm_set1_epi32(x);\n\n    // Check divisors from 2 to sqrt(n) in parallel\n    __m128i vdivisor = _mm_setr_epi32(2, 3, 4, 5); // Example divisors\n    __m128i vremainder = _mm_rem_epi32(vn, vdivisor); // Compute n % divisor for each\n\n    // Check if any remainder is zero (non-prime condition)\n    __m128i vzero = _mm_setzero_si128();\n    __m128i vcmp = _mm_cmpeq_epi32(vremainder, vzero); // Compare remainders to zero\n    int mask = _mm_movemask_ps((__m128)vcmp); // Extract comparison results\n\n    // If any divisor divides n evenly, n is not prime\n    if (mask != 0) {\n        return y; // Not prime, return y\n    }\n\n    // Default case: n is prime, return x\n    return x;\n}\n```"}
{"task_id": "SimdBench_134_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nuint64_t double_the_difference_simd(const std::vector<float> & lst) {\n    __m128i zero = _mm_setzero_si128();\n    __m128i one = _mm_set1_epi32(1);\n    __m128i sum = _mm_setzero_si128();\n\n    size_t i = 0;\n    size_t size = lst.size();\n\n    // Process 4 elements at a time\n    for (; i + 4 <= size; i += 4) {\n        // Load 4 floats into an SSE register\n        __m128 vec = _mm_loadu_ps(&lst[i]);\n\n        // Convert floats to integers (truncate towards zero)\n        __m128i vec_int = _mm_cvttps_epi32(vec);\n\n        // Check if the numbers are positive\n        __m128i positive_mask = _mm_cmpgt_epi32(vec_int, zero);\n\n        // Check if the numbers are odd\n        __m128i odd_mask = _mm_and_si128(_mm_rem_epi32(vec_int, one), positive_mask);\n\n        // Square the odd integers\n        __m128i squared = _mm_mullo_epi32(vec_int, vec_int);\n\n        // Mask out non-odd or non-positive values\n        squared = _mm_and_si128(squared, odd_mask);\n\n        // Accumulate the results horizontally\n        sum = _mm_add_epi32(sum, squared);\n    }\n\n    // Horizontal sum of the accumulated results\n    uint64_t result = 0;\n    alignas(16) int temp[4];\n    _mm_store_si128((__m128i*)temp, sum);\n    for (int j = 0; j < 4; ++j) {\n        result += temp[j];\n    }\n\n    // Process remaining elements\n    for (; i < size; ++i) {\n        int val = static_cast<int>(lst[i]);\n        if (val > 0 && (val % 2 != 0)) {\n            result += static_cast<uint64_t>(val * val);\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_134_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nuint64_t double_the_difference_simd(const std::vector<float> & lst) {\n    __m128i zero = _mm_setzero_si128();\n    __m128i one = _mm_set1_epi32(1);\n    __m128i sum = _mm_setzero_si128();\n\n    size_t i = 0;\n    size_t size = lst.size();\n\n    // Process 4 elements at a time\n    for (; i + 4 <= size; i += 4) {\n        // Load 4 floats into an SSE register\n        __m128 vec = _mm_loadu_ps(&lst[i]);\n\n        // Convert floats to integers (truncate towards zero)\n        __m128i vec_int = _mm_cvttps_epi32(vec);\n\n        // Check if the numbers are positive\n        __m128i positive_mask = _mm_cmpgt_epi32(vec_int, zero);\n\n        // Check if the numbers are odd\n        __m128i odd_mask = _mm_and_si128(_mm_rem_epi32(vec_int, one), one);\n\n        // Combine masks: positive and odd\n        __m128i mask = _mm_and_si128(positive_mask, odd_mask);\n\n        // Square the integers\n        __m128i squared = _mm_mullo_epi32(vec_int, vec_int);\n\n        // Apply mask to keep only valid results\n        squared = _mm_and_si128(squared, mask);\n\n        // Accumulate the results horizontally\n        sum = _mm_add_epi32(sum, squared);\n    }\n\n    // Horizontal sum of the accumulated results\n    uint64_t result = 0;\n    alignas(16) int temp[4];\n    _mm_store_si128((__m128i*)temp, sum);\n    for (int j = 0; j < 4; ++j) {\n        result += temp[j];\n    }\n\n    // Process remaining elements\n    for (; i < size; ++i) {\n        int val = static_cast<int>(lst[i]);\n        if (val > 0 && (val % 2 == 1)) {\n            result += static_cast<uint64_t>(val * val);\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_134_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nuint64_t double_the_difference_simd(const std::vector<float> & lst) {\n    __m128i zero = _mm_setzero_si128();\n    __m128i one = _mm_set1_epi32(1);\n    __m128i sum_vec = _mm_setzero_si128();\n\n    size_t i = 0;\n    size_t size = lst.size();\n\n    // Process 4 elements at a time\n    for (; i + 4 <= size; i += 4) {\n        // Load 4 floats into an SSE register\n        __m128 vec = _mm_loadu_ps(&lst[i]);\n\n        // Convert floats to integers (truncate towards zero)\n        __m128i int_vec = _mm_cvttps_epi32(vec);\n\n        // Check if the numbers are positive\n        __m128i positive_mask = _mm_cmpgt_epi32(int_vec, zero);\n\n        // Check if the numbers are odd\n        __m128i odd_mask = _mm_and_si128(_mm_rem_epi32(int_vec, one), positive_mask);\n\n        // Square the integers\n        __m128i squared = _mm_mullo_epi32(int_vec, int_vec);\n\n        // Mask out non-odd or negative values\n        __m128i masked_squared = _mm_and_si128(squared, odd_mask);\n\n        // Accumulate the results\n        sum_vec = _mm_add_epi32(sum_vec, masked_squared);\n    }\n\n    // Horizontal sum of the accumulated results\n    uint64_t result = 0;\n    result += _mm_extract_epi32(sum_vec, 0);\n    result += _mm_extract_epi32(sum_vec, 1);\n    result += _mm_extract_epi32(sum_vec, 2);\n    result += _mm_extract_epi32(sum_vec, 3);\n\n    // Process remaining elements\n    for (; i < size; ++i) {\n        int val = static_cast<int>(lst[i]);\n        if (val > 0 && val % 2 != 0) {\n            result += static_cast<uint64_t>(val * val);\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_134_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nuint64_t double_the_difference_simd(const std::vector<float> & lst) {\n    __m128i zero = _mm_setzero_si128();\n    __m128i one = _mm_set1_epi32(1);\n    __m128i sum = _mm_setzero_si128();\n\n    size_t i = 0;\n    size_t size = lst.size();\n\n    // Process 4 elements at a time\n    for (; i + 4 <= size; i += 4) {\n        // Load 4 floats into an SSE register\n        __m128 vec = _mm_loadu_ps(&lst[i]);\n\n        // Convert floats to integers (truncate towards zero)\n        __m128i vec_int = _mm_cvttps_epi32(vec);\n\n        // Check if the numbers are positive\n        __m128i positive_mask = _mm_cmpgt_epi32(vec_int, zero);\n\n        // Check if the numbers are odd\n        __m128i odd_mask = _mm_and_si128(_mm_rem_epi32(vec_int, one), positive_mask);\n\n        // Square the odd integers\n        __m128i squared = _mm_mullo_epi32(vec_int, vec_int);\n\n        // Mask out non-odd or non-positive values\n        squared = _mm_and_si128(squared, odd_mask);\n\n        // Accumulate the results horizontally\n        sum = _mm_add_epi32(sum, squared);\n    }\n\n    // Horizontal sum of the accumulated results\n    uint64_t result = 0;\n    alignas(16) int temp[4];\n    _mm_store_si128((__m128i*)temp, sum);\n    for (int j = 0; j < 4; ++j) {\n        result += temp[j];\n    }\n\n    // Process remaining elements\n    for (; i < size; ++i) {\n        int val = static_cast<int>(lst[i]);\n        if (val > 0 && (val % 2 != 0)) {\n            result += static_cast<uint64_t>(val * val);\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_134_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n\nuint64_t double_the_difference_simd(const std::vector<float> & lst) {\n    __m128i zero = _mm_setzero_si128();\n    __m128i one = _mm_set1_epi32(1);\n    __m128i sum = _mm_setzero_si128();\n\n    size_t i = 0;\n    size_t size = lst.size();\n\n    // Process 4 elements at a time\n    for (; i + 4 <= size; i += 4) {\n        // Load 4 floats into an SSE register\n        __m128 vec = _mm_loadu_ps(&lst[i]);\n\n        // Convert floats to integers (truncate towards zero)\n        __m128i vec_int = _mm_cvttps_epi32(vec);\n\n        // Check if the numbers are positive\n        __m128i positive_mask = _mm_cmpgt_epi32(vec_int, zero);\n\n        // Check if the numbers are odd\n        __m128i odd_mask = _mm_and_si128(_mm_rem_epi32(vec_int, one), positive_mask);\n\n        // Square the odd integers\n        __m128i squared = _mm_mullo_epi32(vec_int, vec_int);\n\n        // Mask out non-odd or non-positive values\n        squared = _mm_and_si128(squared, odd_mask);\n\n        // Add the results to the running sum\n        sum = _mm_add_epi32(sum, squared);\n    }\n\n    // Horizontal sum of the SSE register\n    uint64_t result = 0;\n    alignas(16) int temp[4];\n    _mm_store_si128((__m128i*)temp, sum);\n    for (int j = 0; j < 4; ++j) {\n        result += temp[j];\n    }\n\n    // Process remaining elements\n    for (; i < size; ++i) {\n        int val = static_cast<int>(lst[i]);\n        if (val > 0 && val % 2 != 0) {\n            result += static_cast<uint64_t>(val * val);\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_135_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> compare_simd(const std::vector<int>& game, const std::vector<int>& guess) {\n    size_t n = game.size();\n    std::vector<int> result(n, 0);\n\n    size_t i = 0;\n    // Process 4 elements at a time using SSE2 intrinsics\n    for (; i + 3 < n; i += 4) {\n        // Load 4 integers from game and guess into SIMD registers\n        __m128i game_vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&game[i]));\n        __m128i guess_vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&guess[i]));\n\n        // Compare for equality (mask will have 0xFFFFFFFF where equal, 0x0 otherwise)\n        __m128i equal_mask = _mm_cmpeq_epi32(game_vec, guess_vec);\n\n        // Compute absolute difference\n        __m128i diff = _mm_sub_epi32(game_vec, guess_vec);\n        __m128i abs_diff = _mm_abs_epi32(diff);\n\n        // Blend: if equal, use 0, otherwise use abs_diff\n        __m128i zero = _mm_setzero_si128();\n        __m128i result_vec = _mm_blendv_epi8(abs_diff, zero, equal_mask);\n\n        // Store the result back to the result vector\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i]), result_vec);\n    }\n\n    // Process remaining elements (if any)\n    for (; i < n; ++i) {\n        if (game[i] == guess[i]) {\n            result[i] = 0;\n        } else {\n            result[i] = std::abs(game[i] - guess[i]);\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_135_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> compare_simd(const std::vector<int>& game, const std::vector<int>& guess) {\n    size_t n = game.size();\n    std::vector<int> result(n, 0);\n\n    size_t i = 0;\n    // Process 4 elements at a time using SSE2\n    for (; i + 4 <= n; i += 4) {\n        // Load 4 integers from game and guess into SIMD registers\n        __m128i game_vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&game[i]));\n        __m128i guess_vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&guess[i]));\n\n        // Compute the difference between game and guess\n        __m128i diff = _mm_sub_epi32(game_vec, guess_vec);\n\n        // Compute the absolute value of the difference\n        __m128i mask = _mm_cmpeq_epi32(diff, _mm_setzero_si128());\n        __m128i abs_diff = _mm_andnot_si128(mask, _mm_abs_epi32(diff));\n\n        // Store the result back to the result vector\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i]), abs_diff);\n    }\n\n    // Process remaining elements\n    for (; i < n; ++i) {\n        result[i] = (game[i] == guess[i]) ? 0 : std::abs(game[i] - guess[i]);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_135_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> compare_simd(const std::vector<int>& game, const std::vector<int>& guess) {\n    size_t n = game.size();\n    std::vector<int> result(n, 0);\n\n    // Ensure the input vectors are padded to a multiple of 4 for SIMD processing\n    size_t simd_size = (n + 3) & ~3; // Round up to nearest multiple of 4\n    std::vector<int> game_padded(simd_size, 0);\n    std::vector<int> guess_padded(simd_size, 0);\n    std::copy(game.begin(), game.end(), game_padded.begin());\n    std::copy(guess.begin(), guess.end(), guess_padded.begin());\n\n    size_t i = 0;\n\n    // Process 4 elements at a time using SSE2 intrinsics\n    for (; i + 4 <= simd_size; i += 4) {\n        // Load 4 integers from game and guess into SIMD registers\n        __m128i game_vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&game_padded[i]));\n        __m128i guess_vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&guess_padded[i]));\n\n        // Compute the difference between game and guess\n        __m128i diff = _mm_sub_epi32(game_vec, guess_vec);\n\n        // Compute the absolute value of the difference\n        __m128i mask = _mm_cmplt_epi32(diff, _mm_setzero_si128()); // Mask for negative values\n        __m128i abs_diff = _mm_sub_epi32(_mm_xor_si128(diff, mask), mask); // Absolute value\n\n        // Store the result back into the result vector\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i]), abs_diff);\n    }\n\n    // Handle any remaining elements that didn't fit into the SIMD loop\n    for (; i < n; ++i) {\n        result[i] = std::abs(game[i] - guess[i]);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_135_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> compare_simd(const std::vector<int>& game, const std::vector<int>& guess) {\n    size_t n = game.size();\n    std::vector<int> result(n, 0);\n\n    size_t i = 0;\n    // Process 4 elements at a time using SSE2\n    for (; i + 4 <= n; i += 4) {\n        // Load 4 integers from game and guess into SIMD registers\n        __m128i game_vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&game[i]));\n        __m128i guess_vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&guess[i]));\n\n        // Compute the difference between game and guess\n        __m128i diff = _mm_sub_epi32(game_vec, guess_vec);\n\n        // Compute the absolute value of the difference\n        __m128i mask = _mm_cmpeq_epi32(diff, _mm_setzero_si128());\n        __m128i abs_diff = _mm_andnot_si128(mask, _mm_abs_epi32(diff));\n\n        // Store the result back into the result vector\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i]), abs_diff);\n    }\n\n    // Process remaining elements (if any)\n    for (; i < n; ++i) {\n        result[i] = (game[i] == guess[i]) ? 0 : std::abs(game[i] - guess[i]);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_135_SSE", "completion": "```cpp\n#include <xmmintrin.h>\n#include <emmintrin.h>\n#include <x86intrin.h>\n#include <vector>\n\nstd::vector<int> compare_simd(const std::vector<int>& game, const std::vector<int>& guess) {\n    size_t n = game.size();\n    std::vector<int> result(n, 0);\n\n    size_t i = 0;\n    // Process 4 elements at a time using SSE2\n    for (; i + 4 <= n; i += 4) {\n        // Load 4 integers from game and guess into SIMD registers\n        __m128i game_vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&game[i]));\n        __m128i guess_vec = _mm_loadu_si128(reinterpret_cast<const __m128i*>(&guess[i]));\n\n        // Compute the difference between game and guess\n        __m128i diff = _mm_sub_epi32(game_vec, guess_vec);\n\n        // Compute the absolute value of the difference\n        __m128i mask = _mm_cmpeq_epi32(diff, _mm_setzero_si128());\n        __m128i abs_diff = _mm_andnot_si128(mask, _mm_abs_epi32(diff));\n\n        // Store the result back to the result vector\n        _mm_storeu_si128(reinterpret_cast<__m128i*>(&result[i]), abs_diff);\n    }\n\n    // Process remaining elements\n    for (; i < n; ++i) {\n        result[i] = (game[i] == guess[i]) ? 0 : std::abs(game[i] - guess[i]);\n    }\n\n    return result;\n}\n```"}

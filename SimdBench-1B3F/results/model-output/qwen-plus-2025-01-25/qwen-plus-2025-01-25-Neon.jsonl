{"task_id": "SimdBench_0_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid conditional_move_simd(const int64_t *src, int64_t *dst, const bool *mask, size_t length) {\n    size_t i = 0;\n\n    // Process 2 elements per iteration using SIMD\n    for (; i + 1 < length; i += 2) {\n        int64x2_t vsrc = vld1q_s64((const int64_t *)&src[i]);\n        int64x2_t vdst = vld1q_s64((const int64_t *)&dst[i]);\n\n        uint8x16_t vmask = vld1q_u8((const uint8_t *)&mask[i]);\n        // Extend the mask to 64-bit lanes (true/false)\n        uint64x2_t vbool = vmovl_u8(vget_low_u8(vmask));\n        vbool = vorr_u64(vbool, vmovl_u8(vget_high_u8(vmask)));\n\n        // Select between src and dst based on the mask\n        int64x2_t result = vbslq_s64(vbool, vsrc, vdst);\n\n        // Store the result back to dst\n        vst1q_s64((int64_t *)&dst[i], result);\n    }\n\n    // Handle remaining scalar elements if any\n    for (; i < length; ++i) {\n        if (mask[i]) {\n            dst[i] = src[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_0_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid conditional_move_simd(const int64_t *src, int64_t *dst, const bool *mask, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 8; i += 8) {\n        uint8x16_t vmask = vld1q_u8((const uint8_t *)(mask + i));\n        int64x2x4_t vsrc = vld4q_s64((const int64_t *)(src + i));\n        int64x2x4_t vdst = vld4q_s64((const int64_t *)(dst + i));\n\n        vmask = vandq_u8(vmask, vdupq_n_u8(0x1)); // Ensure mask is either 0 or 1\n\n        int64x2_t res0 = vbslq_s64(vreinterpretq_s64_u64(vmask), vsrc.val[0], vdst.val[0]);\n        int64x2_t res1 = vbslq_s64(vreinterpretq_s64_u64(vextq_u8(vmask, vmask, 2)), vsrc.val[1], vdst.val[1]);\n        int64x2_t res2 = vbslq_s64(vreinterpretq_s64_u64(vextq_u8(vmask, vmask, 4)), vsrc.val[2], vdst.val[2]);\n        int64x2_t res3 = vbslq_s64(vreinterpretq_s64_u64(vextq_u8(vmask, vmask, 6)), vsrc.val[3], vdst.val[3]);\n\n        int64x2x4_t result = {{res0, res1, res2, res3}};\n        vst4q_s64((int64_t *)(dst + i), result);\n    }\n\n    for (; i < length; ++i) {\n        if (mask[i]) {\n            dst[i] = src[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_0_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid conditional_move_simd(const int64_t *src, int64_t *dst, const bool *mask, size_t length) {\n    size_t i = 0;\n    for (; i + 2 <= length; i += 2) {\n        uint8x16_t vmask = vld1q_u8((const uint8_t *)(mask + i));\n        int64x2_t vsrc = vld1q_s64((const int64_t *)(src + i));\n        int64x2_t vdst = vld1q_s64((const int64_t *)(dst + i));\n\n        uint64x2_t cond = vmovl_u8(vget_low_u8(vmask));\n        vdst = vbslq_s64(cond, vsrc, vdst);\n\n        vst1q_s64((int64_t *)(dst + i), vdst);\n    }\n\n    // Handle remaining elements with scalar code\n    for (; i < length; ++i) {\n        if (mask[i]) {\n            dst[i] = src[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_0_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid conditional_move_simd(const int64_t *src, int64_t *dst, const bool *mask, size_t length) {\n    size_t i = 0;\n    for (; i + 1 <= length; i += 2) {\n        uint8x16_t mask_vec = vld1q_u8((const uint8_t *)mask + i);\n        int64x2_t src_vec = vld1q_s64((const int64_t *)src + i);\n        int64x2_t dst_vec = vld1q_s64((const int64_t *)dst + i);\n\n        // Convert mask to 64-bit lanes (0 or -1)\n        int64x2_t mask_converted = vmovl_s8(vreinterpret_s8_u8(vget_low_u8(mask_vec)));\n        mask_converted = vorr_s64(mask_converted, vmovl_s8(vreinterpret_s8_u8(vget_high_u8(mask_vec))));\n\n        // Perform the conditional move\n        int64x2_t result = vbslq_s64(mask_converted, src_vec, dst_vec);\n\n        // Store the result back to dst\n        vst1q_s64((int64_t *)dst + i, result);\n    }\n\n    // Handle any remaining elements with scalar code\n    for (; i < length; ++i) {\n        if (mask[i]) {\n            dst[i] = src[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_0_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid conditional_move_simd(const int64_t *src, int64_t *dst, const bool *mask, size_t length) {\n    size_t i = 0;\n\n    for (; i + 1 <= length; i += 2) {\n        uint8x16_t vmask = vld1q_u8((const uint8_t *)(mask + i));\n        int64x2_t vsrc = vld1q_s64((const int64_t *)(src + i));\n        int64x2_t vdst = vld1q_s64((const int64_t *)(dst + i));\n\n        vmask = vmovemask_s64(vmask);\n\n        int64x2_t result = vbslq_s64(vmask, vsrc, vdst);\n\n        vst1q_s64((int64_t *)(dst + i), result);\n    }\n\n    for (; i < length; ++i) {\n        if (mask[i]) {\n            dst[i] = src[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_1_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid load_modify_store_simd(const int *src, int *dst, int scale, size_t length) {\n    for (size_t i = 0; i < length; i += 4) {\n        int32x4_t v_src = vld1q_s32(src + i);\n        int32x4_t v_scale = vdupq_n_s32(scale);\n\n        int32x4_t v_mul = vmulq_s32(v_src, v_scale);\n        \n        int32x4_t v_tmp1 = vshrq_n_s32(v_mul, 3);\n        int32x4_t v_tmp2 = vshlq_n_s32(v_mul, 3);\n\n        int32x4_t v_product = vmulq_s32(v_tmp1, v_tmp2);\n        int32x4_t v_result = vaddq_s32(v_mul, v_product);\n\n        int32x4_t v_final = vrshrq_n_s32(v_result, 3); // Approximate division by 7 with shift and rounding\n        vst1q_s32(dst + i, v_final);\n    }\n}\n```"}
{"task_id": "SimdBench_1_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid load_modify_store_simd(const int *src, int *dst, int scale, size_t length) {\n    for (size_t i = 0; i < length; i += 4) {\n        int32x4_t v_src = vld1q_s32(src + i);\n        int32x4_t v_scale = vdupq_n_s32(scale);\n\n        int32x4_t v_mul = vmulq_s32(v_src, v_scale);\n        int32x4_t v_tmp1 = vrshrq_n_s32(v_mul, 3);\n        int32x4_t v_tmp2 = vshlq_n_s32(v_mul, 3);\n\n        int32x4_t v_product = vmulq_s32(v_tmp1, v_tmp2);\n        int32x4_t v_result = vaddq_s32(v_mul, v_product);\n        v_result = vrshlq_n_s32(v_result, 3); // Equivalent to dividing by 8, which is close to dividing by 7\n        vst1q_s32(dst + i, v_result);\n    }\n}\n```"}
{"task_id": "SimdBench_1_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid load_modify_store_simd(const int *src, int *dst, int scale, size_t length) {\n    size_t i = 0;\n    int32x4_t v_scale = vdupq_n_s32(scale);\n    int32x4_t v_div = vdupq_n_s32(7);\n\n    for (; i <= length - 4; i += 4) {\n        int32x4_t v_src = vld1q_s32(src + i);\n        int32x4_t v_mul = vmulq_s32(v_src, v_scale);\n\n        int32x4_t v_tmp1 = vshrq_n_s32(v_mul, 3);\n        int32x4_t v_tmp2 = vshlq_n_s32(v_mul, 3);\n\n        int32x4_t v_product = vmulq_s32(v_tmp1, v_tmp2);\n        int32x4_t v_result = vaddq_s32(v_mul, v_product);\n        v_result = vdivq_s32(v_result, v_div);\n\n        vst1q_s32(dst + i, v_result);\n    }\n\n    for (; i < length; ++i) {\n        int element = src[i];\n        int tmp1 = (element * scale) >> 3;\n        int tmp2 = (element * scale) << 3;\n        dst[i] = (element * scale + tmp1 * tmp2) / 7;\n    }\n}\n```"}
{"task_id": "SimdBench_1_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid load_modify_store_simd(const int *src, int *dst, int scale, size_t length) {\n    int32x4_t v_scale = vdupq_n_s32(scale);\n    int32x4_t v_div = vdupq_n_s32(7);\n\n    for (size_t i = 0; i < length; i += 4) {\n        int32x4_t v_src = vld1q_s32(src + i);\n\n        int32x4_t v_mul = vmulq_s32(v_src, v_scale);\n\n        int32x4_t v_tmp1 = vshrq_n_s32(v_mul, 3);\n        int32x4_t v_tmp2 = vshlq_n_s32(v_mul, 3);\n\n        int32x4_t v_product = vmulq_s32(v_tmp1, v_tmp2);\n        int32x4_t v_sum = vaddq_s32(v_mul, v_product);\n\n        int32x4_t v_result = vrdivq_s32(v_sum, v_div);\n\n        vst1q_s32(dst + i, v_result);\n    }\n}\n```"}
{"task_id": "SimdBench_1_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid load_modify_store_simd(const int *src, int *dst, int scale, size_t length) {\n    const int divide_by_7 = 0x24924925; // Magic number for division by 7 using fixed-point multiplication\n    size_t i = 0;\n\n    for (; i <= length - 4; i += 4) {\n        int32x4_t v_src = vld1q_s32(src + i);\n        int32x4_t v_scale = vmovq_n_s32(scale);\n\n        int32x4_t v_mul = vmulq_s32(v_src, v_scale);\n\n        int32x4_t v_tmp1 = vshrq_n_s32(v_mul, 3);\n        int32x4_t v_tmp2 = vshlq_n_s32(v_mul, 3);\n\n        int32x4_t v_product = vmulq_s32(v_tmp1, v_tmp2);\n        int32x4_t v_sum = vaddq_s32(v_mul, v_product);\n\n        int32x4_t v_result = vmulq_s32(v_sum, vmovq_n_s32(divide_by_7));\n        v_result = vshrq_n_s32(v_result, 35); // Final shift to complete division\n\n        vst1q_s32(dst + i, v_result);\n    }\n\n    for (; i < length; ++i) {\n        int element = src[i];\n        int tmp1 = (element * scale) >> 3;\n        int tmp2 = (element * scale) << 3;\n        dst[i] = (element * scale + tmp1 * tmp2) / 7;\n    }\n}\n```"}
{"task_id": "SimdBench_2_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid strided_load_store_simd(const double *src, double *dst, size_t rows, size_t cols, size_t stride) {\n    size_t i = 0;\n    for (; i <= rows - 2; i += 2) {\n        const double *src_ptr = src + (i * cols + stride);\n        double *dst_ptr = dst + i;\n\n        // Load two doubles using SIMD\n        float64x2_t vec = vld1q_f64(src_ptr);\n\n        // Store two doubles using SIMD\n        vst1q_f64(dst_ptr, vec);\n    }\n\n    // Handle remaining rows if any\n    if (i < rows) {\n        const double *src_ptr = src + (i * cols + stride);\n        double *dst_ptr = dst + i;\n\n        // Scalar load and store for the last row if not aligned\n        *dst_ptr = *src_ptr;\n    }\n}\n```"}
{"task_id": "SimdBench_2_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nvoid strided_load_store_simd(const double *src, double *dst, size_t rows, size_t cols, size_t stride) {\n    size_t i = 0;\n    for (; i <= rows - 2; i += 2) {\n        const double *src_ptr = src + (i * cols + stride);\n        double *dst_ptr = dst + i;\n\n        uint64x2_t indices = vdupq_n_u64(0);\n        indices = vaddq_u64(indices, vdupq_n_u64(stride));\n\n        float64x2_t loaded_values = vld1q_f64(src_ptr);\n\n        vst1q_f64(dst_ptr, loaded_values);\n    }\n\n    if (i < rows) {\n        const double *src_ptr = src + (i * cols + stride);\n        double *dst_ptr = dst + i;\n\n        double value = src_ptr[0];\n        dst_ptr[0] = value;\n    }\n}\n```"}
{"task_id": "SimdBench_2_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nvoid strided_load_store_simd(const double *src, double *dst, size_t rows, size_t cols, size_t stride) {\n    size_t i = 0;\n    size_t vector_rows = rows / 2;\n    for (; i < vector_rows; i += 2) {\n        const double *src_ptr = src + (i * cols + stride);\n        double *dst_ptr = dst + i;\n\n        uint64x2_t indices = vdupq_n_u64(0);\n        indices = vsetq_lane_u64(0, indices, 0);\n        indices = vsetq_lane_u64(cols, indices, 1);\n\n        float64x2_t loaded_values = vld2q_f64((const double *)src_ptr);\n        vst1q_f64(dst_ptr, loaded_values);\n    }\n\n    // Handle leftover rows if rows is odd\n    if (i < rows) {\n        dst[i] = src[i * cols + stride];\n    }\n}\n```"}
{"task_id": "SimdBench_2_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid strided_load_store_simd(const double *src, double *dst, size_t rows, size_t cols, size_t stride) {\n    size_t i = 0;\n    for (; i <= rows - 2; i += 2) {\n        // Calculate the index in src array\n        size_t idx = i * cols + stride;\n        \n        // Load two doubles from src using SIMD\n        uint64x2_t indices = vdupq_n_u64(idx);\n        float64x2_t loaded_values = vld1q_f64(&src[idx]);\n        \n        // Store the loaded values into dst array\n        vst1q_f64(&dst[i], loaded_values);\n    }\n    \n    // Handle remaining rows if any\n    if (i < rows) {\n        size_t idx = i * cols + stride;\n        dst[i] = src[idx];\n    }\n}\n```"}
{"task_id": "SimdBench_2_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nvoid strided_load_store_simd(const double *src, double *dst, size_t rows, size_t cols, size_t stride) {\n    size_t i = 0;\n    size_t vector_rows = rows / 2;\n    for (; i <= vector_rows - 1; i += 2) {\n        // Calculate the indices for loading from src\n        size_t idx1 = i * cols + stride;\n        size_t idx2 = (i + 1) * cols + stride;\n\n        // Load two double values using SIMD\n        uint64x2_t indices = {idx1, idx2};\n        float64x2_t loaded_values = vld2q_f64((const float64_t *)(src + idx1));\n\n        // Store the loaded values into dst array\n        vst1q_f64(dst + i, loaded_values);\n    }\n\n    // Handle remaining rows if any\n    for (; i < rows; ++i) {\n        dst[i] = src[i * cols + stride];\n    }\n}\n```"}
{"task_id": "SimdBench_3_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid indexed_access_simd(const float *src, const int *indices, float *dst, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 16; i += 16) {\n        // Load 16 indices\n        int32x4_t idx_lo = vld1_s32(indices + i);\n        int32x4_t idx_hi = vld1_s32(indices + i + 4);\n        int32x4_t idx_mid = vld1_s32(indices + i + 8);\n        int32x4_t idx_top = vld1_s32(indices + i + 12);\n\n        // Gather operation: Load values from src using indices\n        float32x4_t gather_val_lo = vld1q_f32(src + vget_lane_s32(idx_lo, 0));\n        float32x4_t gather_val_hi = vld1q_f32(src + vget_lane_s32(idx_hi, 0));\n        float32x4_t gather_val_mid = vld1q_f32(src + vget_lane_s32(idx_mid, 0));\n        float32x4_t gather_val_top = vld1q_f32(src + vget_lane_s32(idx_top, 0));\n\n        // Store gathered values into dst (scatter operation)\n        vst1q_f32(dst + i, gather_val_lo);\n        vst1q_f32(dst + i + 4, gather_val_hi);\n        vst1q_f32(dst + i + 8, gather_val_mid);\n        vst1q_f32(dst + i + 12, gather_val_top);\n    }\n\n    // Handle remaining elements\n    for (; i < length; i++) {\n        dst[i] = src[indices[i]];\n    }\n}\n```"}
{"task_id": "SimdBench_3_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid indexed_access_simd(const float *src, const int *indices, float *dst, size_t length) {\n    for (size_t i = 0; i < length; i += 4) {\n        // Load indices\n        int32x4_t idx = vld1q_s32(indices + i);\n\n        // Gather operation: load values from src using indices\n        float32x4_t gather_vals = vld1q_f32((const float32_t *)(src + vgetq_lane_s32(idx, 0)));\n        gather_vals = vsetq_lane_f32(src[vgetq_lane_s32(idx, 1)], gather_vals, 1);\n        gather_vals = vsetq_lane_f32(src[vgetq_lane_s32(idx, 2)], gather_vals, 2);\n        gather_vals = vsetq_lane_f32(src[vgetq_lane_s32(idx, 3)], gather_vals, 3);\n\n        // Store gathered values into dst\n        vst1q_f32(dst + i, gather_vals);\n\n        // Scatter operation: load values from src and store them in dst using indices as write locations\n        float32x4_t scatter_vals = vld1q_f32(src + i);\n        vst1q_scatter_f32((float32_t *)dst, idx, scatter_vals);\n    }\n}\n```"}
{"task_id": "SimdBench_3_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid indexed_access_simd(const float *src, const int *indices, float *dst, size_t length) {\n    for (size_t i = 0; i < length; i += 4) {\n        // Load indices\n        int32x4_t idx_vec = vld1q_s32(indices + i);\n\n        // Gather operation: load from src using indices\n        float32x4_t gather_vals = vld1q_f32((const float *)(src + vgetq_lane_s32(idx_vec, 0)));\n\n        // Scatter operation: store to dst using indices\n        vst1q_f32(dst + vgetq_lane_s32(idx_vec, 0), gather_vals);\n\n        // Direct copy (gather)\n        float32x4_t src_vals = vld1q_f32(src + i);\n        vst1q_f32(dst + i, src_vals);\n    }\n}\n```"}
{"task_id": "SimdBench_3_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid indexed_access_simd(const float *src, const int *indices, float *dst, size_t length) {\n    for (size_t i = 0; i < length; i += 4) {\n        // Load indices\n        int32x4_t idx_vec = vld1q_s32(indices + i);\n\n        // Gather operation: load values from src using indices\n        float32x4_t gather_vec = vld1q_f32((const float32_t *)(src + vgetq_lane_s32(idx_vec, 0)));\n\n        // Scatter operation: store values to dst using indices\n        vst1q_f32(dst + i, gather_vec);\n        \n        // Direct copy scatter operation\n        vst1q_f32(src + i, gather_vec);\n    }\n}\n```"}
{"task_id": "SimdBench_3_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid indexed_access_simd(const float *src, const int *indices, float *dst, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 16; i += 16) {\n        // Load 16 indices\n        int32x4_t idx_low = vld1_s32(indices + i);\n        int32x4_t idx_high = vld1_s32(indices + i + 4);\n        int32x4_t idx_mid = vld1_s32(indices + i + 8);\n        int32x4_t idx_top = vld1_s32(indices + i + 12);\n\n        // Gather operation: Load values from src using indices\n        float32x4_t gather_val_low = vld1q_f32(src + vget_lane_s32(idx_low, 0));\n        float32x4_t gather_val_high = vld1q_f32(src + vget_lane_s32(idx_high, 0));\n        float32x4_t gather_val_mid = vld1q_f32(src + vget_lane_s32(idx_mid, 0));\n        float32x4_t gather_val_top = vld1q_f32(src + vget_lane_s32(idx_top, 0));\n\n        // Store gathered values into dst (scatter operation)\n        vst1q_f32(dst + i, gather_val_low);\n        vst1q_f32(dst + i + 4, gather_val_high);\n        vst1q_f32(dst + i + 8, gather_val_mid);\n        vst1q_f32(dst + i + 12, gather_val_top);\n    }\n\n    // Handle remaining elements\n    for (; i < length; i++) {\n        dst[i] = src[indices[i]];\n    }\n}\n```"}
{"task_id": "SimdBench_4_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid range_reverse_simd(int16_t *arr, uint64_t start, uint64_t end) {\n    uint64_t i = start;\n    uint64_t j = end;\n\n    while (j - i >= 8) {\n        int16x8_t vec_a = vld1q_s16(arr + i);\n        int16x8_t vec_b = vld1q_s16(arr + j - 7);\n\n        int16x8_t reversed = vrev64q_s16(vec_b);\n\n        vst1q_s16(arr + i, reversed);\n        vst1q_s16(arr + j - 7, vec_a);\n\n        i += 8;\n        j -= 8;\n    }\n\n    while (i < j) {\n        int16_t temp = arr[i];\n        arr[i] = arr[j];\n        arr[j] = temp;\n        i++;\n        j--;\n    }\n\n    if (i == j) {\n        // If the middle element is not swapped, leave it as is.\n    }\n}\n```"}
{"task_id": "SimdBench_4_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid range_reverse_simd(int16_t *arr, uint64_t start, uint64_t end) {\n    uint64_t i = start;\n    uint64_t j = end;\n\n    if (j - i + 1 >= 8) {\n        while (j - i + 1 >= 8) {\n            int16x8_t vec_i = vld1q_s16(&arr[i]);\n            int16x8_t vec_j = vld1q_s16(&arr[j]);\n\n            int16x8_t tmp = vec_i;\n            vec_i = vec_j;\n            vec_j = tmp;\n\n            vst1q_s16(&arr[i], vec_i);\n            vst1q_s16(&arr[j], vec_j);\n\n            i += 8;\n            j -= 8;\n        }\n    }\n\n    while (i < j) {\n        int16_t temp = arr[i];\n        arr[i] = arr[j];\n        arr[j] = temp;\n        i++;\n        j--;\n    }\n}\n```"}
{"task_id": "SimdBench_4_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid range_reverse_simd(int16_t *arr, uint64_t start, uint64_t end) {\n    uint64_t i = start;\n    uint64_t j = end;\n\n    while (j - i >= 8) {\n        int16x8_t vec_i = vld1q_s16(arr + i);\n        int16x8_t vec_j = vld1q_s16(arr + j - 7);\n\n        int16x8_t reversed = vrev64q_s16(vec_j);\n        int16x8_t tmp = vec_i;\n\n        vst1q_s16(arr + i, reversed);\n        vst1q_s16(arr + j - 7, tmp);\n\n        i += 8;\n        j -= 8;\n    }\n\n    while (i < j) {\n        int16_t temp = arr[i];\n        arr[i] = arr[j];\n        arr[j] = temp;\n        i++;\n        j--;\n    }\n\n    if (i == j) {\n        // If the middle element is not swapped, leave it as is.\n    }\n}\n```"}
{"task_id": "SimdBench_4_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid range_reverse_simd(int16_t *arr, uint64_t start, uint64_t end) {\n    uint64_t i = start;\n    uint64_t j = end;\n\n    if (j - i + 1 >= 8) {\n        while (j - i + 1 >= 8) {\n            int16x8_t left = vld1q_s16(arr + i);\n            int16x8_t right = vld1q_s16(arr + j - 7);\n\n            int16x8_t reversed = vrev64q_s16(right);\n\n            vst1q_s16(arr + i, reversed);\n            vst1q_s16(arr + j - 7, left);\n\n            i += 8;\n            j -= 8;\n        }\n    }\n\n    while (i < j) {\n        int16_t temp = arr[i];\n        arr[i] = arr[j];\n        arr[j] = temp;\n        i++;\n        j--;\n    }\n\n    if (i == j) {\n        // If the middle element is not swapped, leave it as is.\n    }\n}\n```"}
{"task_id": "SimdBench_4_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid range_reverse_simd(int16_t *arr, uint64_t start, uint64_t end) {\n    uint64_t i = start;\n    uint64_t j = end;\n\n    while (j - i >= 8) {\n        int16x8_t vec_i = vld1q_s16(arr + i);\n        int16x8_t vec_j = vld1q_s16(arr + j - 7);\n\n        int16x8_t reversed = vrev64q_s16(vec_j);\n\n        vst1q_s16(arr + i, reversed);\n        vst1q_s16(arr + j - 7, vec_i);\n\n        i += 8;\n        j -= 8;\n    }\n\n    while (i < j) {\n        int16_t temp = arr[i];\n        arr[i] = arr[j];\n        arr[j] = temp;\n        i++;\n        j--;\n    }\n\n    if (i == j) {\n        // If the middle element is not swapped, leave it as is.\n    }\n}\n```"}
{"task_id": "SimdBench_5_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid extract_tensor_slice_simd(const uint8_t *tensor, uint8_t *slice, size_t dim1, size_t dim2, size_t dim3, size_t slice_idx) {\n    size_t slice_offset = slice_idx * dim1 * dim2;\n    const uint8_t *src = tensor + slice_offset;\n    \n    for (size_t i = 0; i < dim1 * dim2; i += 16) {\n        uint8x16_t vec = vld1q_u8(src + i);\n        vst1q_u8(slice + i, vec);\n    }\n}\n```"}
{"task_id": "SimdBench_5_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid extract_tensor_slice_simd(const uint8_t *tensor, uint8_t *slice, size_t dim1, size_t dim2, size_t dim3, size_t slice_idx) {\n    size_t slice_offset = slice_idx * dim1 * dim2;\n    const uint8_t *src = tensor + slice_offset;\n    \n    for (size_t i = 0; i < dim1 * dim2; i += 16) {\n        uint8x16_t vec = vld1q_u8(src + i);\n        vst1q_u8(slice + i, vec);\n    }\n}\n```"}
{"task_id": "SimdBench_5_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid extract_tensor_slice_simd(const uint8_t *tensor, uint8_t *slice, size_t dim1, size_t dim2, size_t dim3, size_t slice_idx) {\n    size_t slice_offset = slice_idx * dim1 * dim2;\n    const uint8_t *src = tensor + slice_offset;\n    \n    for (size_t i = 0; i < dim1 * dim2; i += 16) {\n        uint8x16_t v = vld1q_u8(src + i);\n        vst1q_u8(slice + i, v);\n    }\n}\n```"}
{"task_id": "SimdBench_5_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid extract_tensor_slice_simd(const uint8_t *tensor, uint8_t *slice, size_t dim1, size_t dim2, size_t dim3, size_t slice_idx) {\n    size_t slice_offset = slice_idx * dim1 * dim2;\n    const uint8_t *src = tensor + slice_offset;\n    \n    for (size_t i = 0; i < dim1 * dim2; i += 16) {\n        uint8x16_t v = vld1q_u8(src + i);\n        vst1q_u8(slice + i, v);\n    }\n}\n```"}
{"task_id": "SimdBench_5_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid extract_tensor_slice_simd(const uint8_t *tensor, uint8_t *slice, size_t dim1, size_t dim2, size_t dim3, size_t slice_idx) {\n    size_t slice_offset = slice_idx * dim1 * dim2;\n    const uint8_t *src = tensor + slice_offset;\n    \n    for (size_t i = 0; i < dim1 * dim2; i += 16) {\n        uint8x16_t vec = vld1q_u8(src + i);\n        vst1q_u8(slice + i, vec);\n    }\n}\n```"}
{"task_id": "SimdBench_6_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid blocked_matrix_transpose_simd(const int16_t *src, int16_t *dst, size_t rows, size_t cols, size_t block_size) {\n    for (size_t i = 0; i < rows; i += block_size) {\n        for (size_t j = 0; j < cols; j += block_size) {\n            for (size_t k = 0; k < block_size; ++k) {\n                size_t row_idx = i + k;\n                if (row_idx >= rows) break;\n                const int16_t *src_row = src + row_idx * cols + j;\n                int16x8_t vrow = vld1q_s16(src_row);\n                for (size_t l = 0; l < block_size; ++l) {\n                    size_t col_idx = j + l;\n                    if (col_idx >= cols) break;\n                    int16x8_t vtmp = vdupq_n_s16(0);\n                    vtmp = vsetq_lane_s16(vgetq_lane_s16(vrow, l), vtmp, k);\n                    dst[col_idx * rows + row_idx] = vgetq_lane_s16(vtmp, 0);\n                }\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_6_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid blocked_matrix_transpose_simd(const int16_t *src, int16_t *dst, size_t rows, size_t cols, size_t block_size) {\n    for (size_t i = 0; i < rows; i += block_size) {\n        for (size_t j = 0; j < cols; j += block_size) {\n            for (size_t ii = i; ii < i + block_size && ii < rows; ++ii) {\n                for (size_t jj = j; jj < j + block_size && jj < cols; jj += 8) {\n                    int16x8_t v = vld1q_s16(src + ii * cols + jj);\n                    vst1q_s16(dst + jj * rows + ii, v);\n                }\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_6_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid blocked_matrix_transpose_simd(const int16_t *src, int16_t *dst, size_t rows, size_t cols, size_t block_size) {\n    for (size_t i = 0; i < rows; i += block_size) {\n        for (size_t j = 0; j < cols; j += block_size) {\n            for (size_t k = 0; k < block_size; ++k) {\n                size_t row_idx = i + k;\n                if (row_idx >= rows) break;\n                const int16_t *row_ptr = src + row_idx * cols + j;\n                int16x8_t vec = vld1q_s16(row_ptr);\n                for (size_t l = 0; l < block_size && j + l < cols; ++l) {\n                    int16x8_t shuffled = vextq_s16(vec, vec, l);\n                    int16_t value = vget_lane_s16(shuffled, 0);\n                    size_t col_idx = j + l;\n                    if (col_idx >= cols) break;\n                    dst[col_idx * rows + row_idx] = value;\n                }\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_6_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid blocked_matrix_transpose_simd(const int16_t *src, int16_t *dst, size_t rows, size_t cols, size_t block_size) {\n    for (size_t i = 0; i < rows; i += block_size) {\n        for (size_t j = 0; j < cols; j += block_size) {\n            for (size_t k = 0; k < block_size; ++k) {\n                size_t row_idx = i + k;\n                if (row_idx >= rows) break;\n                const int16_t *src_row = src + row_idx * cols + j;\n                int16x8_t vec = vld1q_s16(src_row);\n                for (size_t l = 0; l < block_size; ++l) {\n                    size_t col_idx = j + l;\n                    if (col_idx >= cols) break;\n                    int16x8_t dst_vec = vld1q_s16(dst + col_idx * rows + i);\n                    int16x1_t val = vdup_n_s16(vgetq_lane_s16(vec, l));\n                    dst_vec = vsetq_lane_s16(vget_lane_s16(val, 0), dst_vec, k);\n                    vst1q_s16(dst + col_idx * rows + i, dst_vec);\n                }\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_6_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid blocked_matrix_transpose_simd(const int16_t *src, int16_t *dst, size_t rows, size_t cols, size_t block_size) {\n    for (size_t i = 0; i < rows; i += block_size) {\n        for (size_t j = 0; j < cols; j += block_size) {\n            for (size_t ii = i; ii < i + block_size && ii < rows; ++ii) {\n                const int16_t *row_ptr = src + ii * cols;\n                for (size_t jj = j; jj < j + block_size && jj < cols; jj += 8) {\n                    int16x8_t v = vld1q_s16(row_ptr + jj);\n                    size_t dst_idx = jj * rows + ii;\n                    size_t stride = rows;\n                    vst1q_lane_s16(dst + dst_idx, v, 0);\n                    vst1q_lane_s16(dst + dst_idx + stride, v, 1);\n                    vst1q_lane_s16(dst + dst_idx + 2 * stride, v, 2);\n                    vst1q_lane_s16(dst + dst_idx + 3 * stride, v, 3);\n                    vst1q_lane_s16(dst + dst_idx + 4 * stride, v, 4);\n                    vst1q_lane_s16(dst + dst_idx + 5 * stride, v, 5);\n                    vst1q_lane_s16(dst + dst_idx + 6 * stride, v, 6);\n                    vst1q_lane_s16(dst + dst_idx + 7 * stride, v, 7);\n                }\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_7_Neon", "completion": "```c\n#include <arm_neon.h>\n\nfloat diagonal_sum_3d_simd(const float *array, size_t dim) {\n    float sum = 0.0f;\n    size_t i;\n\n    float32x4_t vsum = vdupq_n_f32(0.0f);\n\n    for (i = 0; i <= (dim - 4); i += 4) {\n        float32x4_t vdiag = vld1q_f32(&array[i * (dim * dim + dim + 1)]);\n        vsum = vaddq_f32(vsum, vdiag);\n    }\n\n    // Horizontal add of the remaining vector\n    float32x2_t tmp1 = vadd_f32(vget_low_f32(vsum), vget_high_f32(vsum));\n    float32x2_t tmp2 = vpadd_f32(tmp1, tmp1);\n    sum += vget_lane_f32(tmp2, 0);\n\n    // Handle leftover elements\n    for (; i < dim; ++i) {\n        sum += array[i * (dim * dim + dim + 1)];\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_7_Neon", "completion": "```c\n#include <arm_neon.h>\n\nfloat diagonal_sum_3d_simd(const float *array, size_t dim) {\n    float32x4_t sum_vec = vdupq_n_f32(0.0f);\n    size_t i;\n\n    for (i = 0; i <= dim - 4; i += 4) {\n        float32x4_t diag_elements = vld1q_f32(&array[i * (dim * dim + dim + 1)]);\n        sum_vec = vaddq_f32(sum_vec, diag_elements);\n    }\n\n    float32x2_t sum_low = vadd_f32(vget_low_f32(sum_vec), vget_high_f32(sum_vec));\n    float32x2_t sum_pair = vpadd_f32(sum_low, sum_low);\n\n    float result = vget_lane_f32(sum_pair, 0);\n\n    for (; i < dim; ++i) {\n        result += array[i * (dim * dim + dim + 1)];\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_7_Neon", "completion": "```c\n#include <arm_neon.h>\n\nfloat diagonal_sum_3d_simd(const float *array, size_t dim) {\n    float32x4_t sum_vec = vdupq_n_f32(0.0f);\n    size_t i;\n\n    for (i = 0; i <= dim - 4; i += 4) {\n        float32x4_t val = vld1q_f32(&array[i * (dim * dim + dim + 1)]);\n        sum_vec = vaddq_f32(sum_vec, val);\n    }\n\n    float32x2_t sum_low = vadd_f32(vget_low_f32(sum_vec), vget_high_f32(sum_vec));\n    float32x2_t sum_pair = vpadd_f32(sum_low, sum_low);\n\n    float result = vget_lane_f32(sum_pair, 0);\n\n    for (; i < dim; i++) {\n        result += array[i * (dim * dim + dim + 1)];\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_7_Neon", "completion": "```c\n#include <arm_neon.h>\n\nfloat diagonal_sum_3d_simd(const float *array, size_t dim) {\n    float sum = 0.0f;\n    size_t i;\n\n    float32x4_t vsum = vdupq_n_f32(0.0f);\n\n    for (i = 0; i <= (dim - 4); i += 4) {\n        float32x4_t vload = vld1q_f32(&array[i * (dim * dim + dim + 1)]);\n        vsum = vaddq_f32(vsum, vload);\n    }\n\n    // Horizontal add of the remaining vector\n    float32x2_t low = vadd_f32(vget_low_f32(vsum), vget_high_f32(vsum));\n    sum += vget_lane_f32(low, 0) + vget_lane_f32(low, 1);\n\n    // Handle leftover elements\n    for (; i < dim; ++i) {\n        sum += array[i * (dim * dim + dim + 1)];\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_7_Neon", "completion": "```c\n#include <arm_neon.h>\n\nfloat diagonal_sum_3d_simd(const float *array, size_t dim) {\n    float32x4_t sum_vec = vdupq_n_f32(0.0f);\n    size_t i;\n\n    for (i = 0; i < dim && i + 3 < dim; i += 4) {\n        float32x4_t vec = vld1q_f32(&array[i * (dim * dim + dim + 1)]);\n        sum_vec = vaddq_f32(sum_vec, vec);\n    }\n\n    float32x2_t sum_low = vadd_f32(vget_low_f32(sum_vec), vget_high_f32(sum_vec));\n    float32x2_t sum_pair = vpadd_f32(sum_low, sum_low);\n\n    float result = vget_lane_f32(sum_pair, 0);\n\n    for (; i < dim; i++) {\n        result += array[i * (dim * dim + dim + 1)];\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_8_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid conditional_scale_simd(const double *src, double *dst, size_t rows, size_t cols, double threshold, double scale) {\n    size_t total = rows * cols;\n    size_t i = 0;\n\n    float64x2_t vt = vdupq_n_f64(threshold);\n    float64x2_t vscale = vdupq_n_f64(scale);\n\n    for (; i <= total - 2; i += 2) {\n        float64x2_t vin = vld1q_f64(&src[i]);\n        float64x2_t vcond = vcgtq_f64(vin, vt);\n        float64x2_t vscaled = vmulq_f64(vin, vscale);\n        float64x2_t vout = vbslq_f64(vcond, vscaled, vin);\n        vst1q_f64(&dst[i], vout);\n    }\n\n    for (; i < total; ++i) {\n        dst[i] = src[i] > threshold ? src[i] * scale : src[i];\n    }\n}\n```"}
{"task_id": "SimdBench_8_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid conditional_scale_simd(const double *src, double *dst, size_t rows, size_t cols, double threshold, double scale) {\n    size_t total = rows * cols;\n    size_t i = 0;\n\n    double vthreshold = threshold;\n    double vscale = scale;\n\n    for (; i <= total - 2; i += 2) {\n        // Load two doubles from src\n        float64x2_t vsrc = vld1q_f64(&src[i]);\n\n        // Compare with threshold\n        uint64x2_t mask = vcgtq_f64(vsrc, vdupq_n_f64(vthreshold));\n\n        // Scale the values greater than threshold\n        float64x2_t vscaled = vmulq_f64(vsrc, vdupq_n_f64(vscale));\n\n        // Select scaled or original based on mask\n        float64x2_t vresult = vbslq_f64(mask, vscaled, vsrc);\n\n        // Store result into dst\n        vst1q_f64(&dst[i], vresult);\n    }\n\n    // Handle remaining elements (if any)\n    for (; i < total; ++i) {\n        dst[i] = src[i] > threshold ? src[i] * scale : src[i];\n    }\n}\n```"}
{"task_id": "SimdBench_8_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid conditional_scale_simd(const double *src, double *dst, size_t rows, size_t cols, double threshold, double scale) {\n    size_t total = rows * cols;\n    size_t i = 0;\n\n    // Load threshold and scale into SIMD registers\n    float64x2_t vthreshold = vdupq_n_f64(threshold);\n    float64x2_t vscale = vdupq_n_f64(scale);\n    float64x2_t vone = vdupq_n_f64(1.0);\n\n    for (; i <= total - 2; i += 2) {\n        // Load two doubles from src\n        float64x2_t vsrc = vld1q_f64(&src[i]);\n\n        // Compare with threshold\n        uint64x2_t vcond = vcgtq_f64(vsrc, vthreshold);\n\n        // Create scaling factor vector (either scale or 1.0)\n        float64x2_t vscale_factor = vbslq_f64(vcond, vscale, vone);\n\n        // Scale the values conditionally\n        float64x2_t vresult = vmulq_f64(vsrc, vscale_factor);\n\n        // Store the result in dst\n        vst1q_f64(&dst[i], vresult);\n    }\n\n    // Handle remaining elements (if any)\n    for (; i < total; i++) {\n        dst[i] = src[i] > threshold ? src[i] * scale : src[i];\n    }\n}\n```"}
{"task_id": "SimdBench_8_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid conditional_scale_simd(const double *src, double *dst, size_t rows, size_t cols, double threshold, double scale) {\n    size_t total = rows * cols;\n    size_t i = 0;\n\n    // Load threshold and scale into SIMD registers\n    float64x2_t vthreshold = vdupq_n_f64(threshold);\n    float64x2_t vscale = vdupq_n_f64(scale);\n\n    // Process in chunks of 2 elements (since we use float64x2_t)\n    for (; i <= total - 2; i += 2) {\n        // Load 2 doubles from source\n        float64x2_t vsrc = vld1q_f64(src + i);\n\n        // Compare with threshold\n        uint64x2_t vcond = vcgtq_f64(vsrc, vthreshold);\n\n        // Scale the values greater than threshold\n        float64x2_t vscaled = vmulq_f64(vsrc, vscale);\n\n        // Select between scaled and original based on condition\n        float64x2_t vresult = vbslq_f64(vcond, vscaled, vsrc);\n\n        // Store result into destination\n        vst1q_f64(dst + i, vresult);\n    }\n\n    // Handle remaining elements (if any)\n    for (; i < total; i++) {\n        dst[i] = src[i] > threshold ? src[i] * scale : src[i];\n    }\n}\n```"}
{"task_id": "SimdBench_8_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid conditional_scale_simd(const double *src, double *dst, size_t rows, size_t cols, double threshold, double scale) {\n    size_t total = rows * cols;\n    size_t i = 0;\n\n    // Load threshold and scale into SIMD registers\n    float64x2_t vthreshold = vdupq_n_f64(threshold);\n    float64x2_t vscale = vdupq_n_f64(scale);\n\n    // Process in chunks of 2 elements (since we use float64x2_t)\n    for (; i <= total - 2; i += 2) {\n        // Load two doubles from src\n        float64x2_t vsrc = vld1q_f64(&src[i]);\n\n        // Compare with threshold\n        uint64x2_t mask = vcgtq_f64(vsrc, vthreshold);\n\n        // Scale the values where condition is true\n        float64x2_t vscaled = vmulq_f64(vsrc, vscale);\n\n        // Select between scaled and original values based on mask\n        float64x2_t vresult = vbslq_f64(mask, vscaled, vsrc);\n\n        // Store result into dst\n        vst1q_f64(&dst[i], vresult);\n    }\n\n    // Handle any remaining elements (if total is odd)\n    if (i < total) {\n        dst[i] = src[i] > threshold ? src[i] * scale : src[i];\n    }\n}\n```"}
{"task_id": "SimdBench_9_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid reorder_matrix_rows_simd(const double *src, double *dst, size_t rows, size_t cols, const size_t *indices) {\n    for (size_t i = 0; i < rows; ++i) {\n        size_t idx = indices[i];\n        const double *src_row = src + idx * cols;\n        double *dst_row = dst + i * cols;\n\n        size_t j = 0;\n        for (; j <= cols - 2; j += 2) {\n            uint64x2_t offset = vdupq_n_u64(j);\n            float64x2_t vsrc = vld1q_f64(src_row + j);\n            vst1q_f64(dst_row + j, vsrc);\n        }\n\n        for (; j < cols; ++j) {\n            dst_row[j] = src_row[j];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_9_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid reorder_matrix_rows_simd(const double *src, double *dst, size_t rows, size_t cols, const size_t *indices) {\n    for (size_t i = 0; i < rows; ++i) {\n        size_t idx = indices[i];\n        const double *src_row = src + idx * cols;\n        double *dst_row = dst + i * cols;\n\n        size_t j = 0;\n        for (; j <= cols - 2; j += 2) {\n            uint64x2_t offset = vdupq_n_u64(j);\n            float64x2_t v_src = vld1q_f64((const double *)(src_row + j));\n            vst1q_f64(dst_row + j, v_src);\n        }\n\n        for (; j < cols; ++j) {\n            dst_row[j] = src_row[j];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_9_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid reorder_matrix_rows_simd(const double *src, double *dst, size_t rows, size_t cols, const size_t *indices) {\n    for (size_t i = 0; i < rows; ++i) {\n        size_t idx = indices[i];\n        const double *src_row = src + idx * cols;\n        double *dst_row = dst + i * cols;\n\n        size_t j = 0;\n        for (; j <= cols - 2; j += 2) {\n            float64x2_t v_src = vld1q_f64(src_row + j);\n            vst1q_f64(dst_row + j, v_src);\n        }\n\n        for (; j < cols; ++j) {\n            dst_row[j] = src_row[j];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_9_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid reorder_matrix_rows_simd(const double *src, double *dst, size_t rows, size_t cols, const size_t *indices) {\n    for (size_t i = 0; i < rows; ++i) {\n        size_t src_row_idx = indices[i];\n        const double *src_row = &src[src_row_idx * cols];\n        double *dst_row = &dst[i * cols];\n\n        size_t j = 0;\n        for (; j + 2 <= cols; j += 2) {\n            uint64x2_t idx = vdupq_n_u64(j / 2);\n            float64x2_t v_src = vld1q_f64(&src_row[j]);\n            vst1q_f64(&dst_row[j], v_src);\n        }\n\n        for (; j < cols; ++j) {\n            dst_row[j] = src_row[j];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_9_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid reorder_matrix_rows_simd(const double *src, double *dst, size_t rows, size_t cols, const size_t *indices) {\n    for (size_t i = 0; i < rows; ++i) {\n        size_t src_row_idx = indices[i];\n        const double *src_row = &src[src_row_idx * cols];\n        double *dst_row = &dst[i * cols];\n\n        size_t j = 0;\n        for (; j + 2 <= cols; j += 2) {\n            uint64x2_t idx = vdupq_n_u64(j);\n            float64x2_t v_src = vld1q_f64(src_row + j);\n            vst1q_f64(dst_row + j, v_src);\n        }\n\n        for (; j < cols; ++j) {\n            dst_row[j] = src_row[j];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_10_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid vector_vector_add_simd(const int64_t *src1, const int64_t *src2, int64_t *dst, int64_t scalar, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 2; i += 2) {\n        int64x2_t v_src1 = vld1q_s64((const int64_t *)(src1 + i));\n        int64x2_t v_src2 = vld1q_s64((const int64_t *)(src2 + i));\n        int64x2_t v_scalar = vdupq_n_s64(scalar);\n        \n        int64x2_t v_sum = vaddq_s64(v_src1, v_src2);\n        int64x2_t v_result = vaddq_s64(v_sum, v_scalar);\n        \n        int64x2_t v_divided = vrshrq_n_s64(v_result, 1);\n        \n        vst1q_s64((int64_t *)(dst + i), v_divided);\n    }\n    for (; i < length; i++) {\n        dst[i] = (src1[i] + src2[i] + scalar) / 2;\n    }\n}\n```"}
{"task_id": "SimdBench_10_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid vector_vector_add_simd(const int64_t *src1, const int64_t *src2, int64_t *dst, int64_t scalar, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 2; i += 2) {\n        int64x2_t v_src1 = vld1q_s64((const int64_t *)(src1 + i));\n        int64x2_t v_src2 = vld1q_s64((const int64_t *)(src2 + i));\n        int64x2_t v_scalar = vdupq_n_s64(scalar);\n        \n        int64x2_t v_sum = vaddq_s64(v_src1, v_src2);\n        int64x2_t v_res = vaddq_s64(v_sum, v_scalar);\n        \n        int64x2_t v_div = vrshrq_n_s64(v_res, 1);\n        \n        vst1q_s64((int64_t *)(dst + i), v_div);\n    }\n    for (; i < length; i++) {\n        dst[i] = (src1[i] + src2[i] + scalar) / 2;\n    }\n}\n```"}
{"task_id": "SimdBench_10_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid vector_vector_add_simd(const int64_t *src1, const int64_t *src2, int64_t *dst, int64_t scalar, size_t length) {\n    size_t i = 0;\n    int64x2_t vscalar = vdupq_n_s64(scalar);\n\n    for (; i <= length - 2; i += 2) {\n        int64x2_t va = vld1q_s64((const int64_t *)&src1[i]);\n        int64x2_t vb = vld1q_s64((const int64_t *)&src2[i]);\n        int64x2_t vsum = vaddq_s64(va, vb);\n        int64x2_t vres = vaddq_s64(vsum, vscalar);\n        int64x2_t vfinal = vshrq_n_s64(vres, 1);\n        vst1q_s64((int64_t *)&dst[i], vfinal);\n    }\n\n    // Handle remaining elements\n    for (; i < length; i++) {\n        dst[i] = (src1[i] + src2[i] + scalar) / 2;\n    }\n}\n```"}
{"task_id": "SimdBench_10_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid vector_vector_add_simd(const int64_t *src1, const int64_t *src2, int64_t *dst, int64_t scalar, size_t length) {\n    size_t i = 0;\n    int64x2_t vscalar = vdupq_n_s64(scalar);\n\n    for (; i <= length - 2; i += 2) {\n        int64x2_t va = vld1q_s64((const int64_t *)&src1[i]);\n        int64x2_t vb = vld1q_s64((const int64_t *)&src2[i]);\n        int64x2_t vsum = vaddq_s64(va, vb);\n        int64x2_t vresult = vaddq_s64(vsum, vscalar);\n        int64x2_t vfinal = vrshrq_n_s64(vresult, 1);\n        vst1q_s64((int64_t *)&dst[i], vfinal);\n    }\n\n    // Handle remaining elements\n    for (; i < length; i++) {\n        dst[i] = (src1[i] + src2[i] + scalar) / 2;\n    }\n}\n```"}
{"task_id": "SimdBench_10_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid vector_vector_add_simd(const int64_t *src1, const int64_t *src2, int64_t *dst, int64_t scalar, size_t length) {\n    size_t i = 0;\n    int64x2_t vscalar = vdupq_n_s64(scalar);\n\n    for (; i <= length - 2; i += 2) {\n        int64x2_t va = vld1q_s64((const int64_t *)&src1[i]);\n        int64x2_t vb = vld1q_s64((const int64_t *)&src2[i]);\n        int64x2_t vsum = vaddq_s64(va, vb);\n        int64x2_t vresult = vaddq_s64(vsum, vscalar);\n        int64x2_t vfinal = vrshlq_s64(vresult, vdupq_n_s64(1));\n        vst1q_s64((int64_t *)&dst[i], vfinal);\n    }\n\n    for (; i < length; i++) {\n        dst[i] = (src1[i] + src2[i] + scalar) / 2;\n    }\n}\n```"}
{"task_id": "SimdBench_11_Neon", "completion": "```c\n#include <arm_neon.h>\n\nint vector_even_min_simd(const int *src, size_t length){\n    if (length == 0 || src == NULL) return -1;\n\n    int32x4_t min_val = vdupq_n_s32(0x7FFFFFFF);\n    size_t i = 0;\n\n    for (; i <= length - 8; i += 8) {\n        int32x4_t vec0 = vld1q_s32(src + i);\n        int32x4_t vec1 = vld1q_s32(src + i + 4);\n\n        uint32x4_t mask0 = vandq_u32(vreinterpretq_u32_s32(vec0), vdupq_n_u32(1));\n        uint32x4_t mask1 = vandq_u32(vreinterpretq_u32_s32(vec1), vdupq_n_u32(1));\n\n        mask0 = vceqq_u32(mask0, vdupq_n_u32(0));\n        mask1 = vceqq_u32(mask1, vdupq_n_u32(0));\n\n        int32x4_t even0 = vbslq_s32(mask0, vec0, vdupq_n_s32(0x7FFFFFFF));\n        int32x4_t even1 = vbslq_s32(mask1, vec1, vdupq_n_s32(0x7FFFFFFF));\n\n        min_val = vminsq_s32(min_val, even0);\n        min_val = vminsq_s32(min_val, even1);\n    }\n\n    for (; i < length; i++) {\n        if ((src[i] & 1) == 0 && src[i] < vgetq_lane_s32(min_val, 0)) {\n            min_val = vsetq_lane_s32(src[i], min_val, 0);\n        }\n    }\n\n    int32x2_t min_low = vpmin_s32(vget_low_s32(min_val), vget_high_s32(min_val));\n    int32x2_t min_final = vpmin_s32(min_low, min_low);\n\n    return min_final[0] == 0x7FFFFFFF ? -1 : min_final[0];\n}\n```"}
{"task_id": "SimdBench_11_Neon", "completion": "```c\n#include <arm_neon.h>\n\nint vector_even_min_simd(const int *src, size_t length){\n    if (length == 0 || src == NULL) return -1;\n\n    int32x4_t vmin = vdupq_n_s32(0x7FFFFFFF);\n    size_t i = 0;\n\n    for (; i <= length - 4; i += 4) {\n        int32x4_t vec = vld1q_s32(src + i);\n        int32x4_t mask = vmovq_n_s32(1);\n        int32x4_t even_vec = vandq_s32(vec, vmvnq_n_s32(1));\n        vmin = vminq_s32(vmin, even_vec);\n    }\n\n    int32_t min_val = vminv_s32(vmin);\n\n    for (; i < length; i++) {\n        if ((i % 2 == 0) && (src[i] < min_val)) {\n            min_val = src[i];\n        }\n    }\n\n    return min_val == 0x7FFFFFFF ? -1 : min_val;\n}\n```"}
{"task_id": "SimdBench_11_Neon", "completion": "```c\n#include <arm_neon.h>\n\nint vector_even_min_simd(const int *src, size_t length){\n    if (length == 0 || src == NULL) return -1;\n\n    int32x4_t min_val = vdupq_n_s32(0x7FFFFFFF);\n    size_t i = 0;\n\n    for (; i <= length - 4; i += 4) {\n        int32x4_t vec = vld1q_s32(src + i);\n        int32x4_t even_mask = vmovq_n_s32(0xAAAAAAAA);\n        uint32x4_t mask = vcgeq_s32(vec, vec); // All ones\n        uint32x4_t even_check = vandq_u32(mask, vreinterpretq_u32_s32(even_mask));\n        uint32x4_t filtered = vandq_u32(vreinterpretq_u32_s32(vec), even_check);\n        int32x4_t cmp = vmovq_n_s32(0x7FFFFFFF);\n        cmp = vminq_s32(filtered, cmp);\n        min_val = vminq_s32(min_val, cmp);\n    }\n\n    int32_t min_result = 0x7FFFFFFF;\n    int32x2_t min_low = vget_low_s32(min_val);\n    int32x2_t min_high = vget_high_s32(min_val);\n    int32x2_t min_pair = vpmin_s32(min_low, min_high);\n    min_result = vminv_s32(min_pair);\n\n    for (; i < length; i++) {\n        if ((src[i] & 1) == 0 && src[i] < min_result) {\n            min_result = src[i];\n        }\n    }\n\n    return min_result == 0x7FFFFFFF ? -1 : min_result;\n}\n```"}
{"task_id": "SimdBench_11_Neon", "completion": "```c\n#include <arm_neon.h>\n\nint vector_even_min_simd(const int *src, size_t length){\n    if (length == 0 || src == NULL) return -1;\n\n    int32x4_t vmin = vdupq_n_s32(0x7FFFFFFF);\n    size_t i = 0;\n\n    for (; i <= length - 8; i += 8) {\n        int32x4_t vec1 = vld1q_s32(src + i);\n        int32x4_t vec2 = vld1q_s32(src + i + 4);\n\n        uint32x4_t mask1 = vandq_u32(vreinterpretq_u32_s32(vec1), vdupq_n_u32(1));\n        uint32x4_t mask2 = vandq_u32(vreinterpretq_u32_s32(vec2), vdupq_n_u32(1));\n\n        mask1 = vceqq_u32(mask1, vdupq_n_u32(0));\n        mask2 = vceqq_u32(mask2, vdupq_n_u32(0));\n\n        int32x4_t even1 = vbslq_s32(mask1, vec1, vdupq_n_s32(0x7FFFFFFF));\n        int32x4_t even2 = vbslq_s32(mask2, vec2, vdupq_n_s32(0x7FFFFFFF));\n\n        vmin = vminq_s32(vmin, even1);\n        vmin = vminq_s32(vmin, even2);\n    }\n\n    for (; i < length; i++) {\n        if ((src[i] & 1) == 0 && src[i] < vgetq_lane_s32(vmin, 0)) {\n            vmin = vsetq_lane_s32(src[i], vmin, 0);\n        }\n    }\n\n    int32x2_t min_2 = vpmin_s32(vget_low_s32(vmin), vget_high_s32(vmin));\n    int32x2_t min_1 = vpmin_s32(min_2, min_2);\n    return min_1[0];\n}\n```"}
{"task_id": "SimdBench_11_Neon", "completion": "```c\n#include <arm_neon.h>\n\nint vector_even_min_simd(const int *src, size_t length){\n    if (length == 0 || src == NULL) return -1;\n\n    int32x4_t vmin = vdupq_n_s32(0x7FFFFFFF);\n    size_t i = 0;\n\n    for (; i <= length - 4; i += 4) {\n        int32x4_t vec = vld1q_s32(src + i);\n        int32x4_t even_mask = vmovq_n_s32(0xAAAAAAAA); // Mask for even positions\n        uint32x4_t mask = vcgeq_s32(vandq_s32(vec, even_mask), vmovq_n_s32(0));\n        int32x4_t filtered = vbslq_s32(mask, vec, vmovq_n_s32(0x7FFFFFFF));\n        vmin = vminq_s32(vmin, filtered);\n    }\n\n    int min_val = vminvq_s32(vmin);\n\n    for (; i < length; ++i) {\n        if ((i % 2 == 0) && (src[i] < min_val)) {\n            min_val = src[i];\n        }\n    }\n\n    return min_val == 0x7FFFFFFF ? -1 : min_val;\n}\n```"}
{"task_id": "SimdBench_12_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid mixed_right_shift_simd(const int *src, int *dst, uint8_t shift, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 4; i += 4) {\n        int32x4_t v_src = vld1q_s32(src + i);\n        \n        // Arithmetic right shift\n        int32x4_t v_asr = vshrq_n_s32(v_src, shift);\n        \n        // Logical right shift: convert to uint, shift, then convert back to int\n        uint32x4_t v_ushr = vshrq_n_u32(vreinterpretq_u32_s32(v_src), shift);\n        int32x4_t v_lsr = vreinterpretq_s32_u32(v_ushr);\n        \n        // Add arithmetic and logical shifts\n        int32x4_t v_result = vaddq_s32(v_asr, v_lsr);\n        \n        // Store the result\n        vst1q_s32(dst + i, v_result);\n    }\n    \n    // Handle remaining elements with scalar code\n    for (; i < length; i++) {\n        int val = src[i];\n        int asr = val >> shift;\n        int lsr = (unsigned int)val >> shift;\n        dst[i] = asr + lsr;\n    }\n}\n```"}
{"task_id": "SimdBench_12_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid mixed_right_shift_simd(const int *src, int *dst, uint8_t shift, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 4; i += 4) {\n        int32x4_t v_src = vld1q_s32(src + i);\n        \n        // Arithmetic right shift\n        int32x4_t v_asr = vshrq_n_s32(v_src, shift);\n        \n        // Logical right shift: convert to uint, shift, then convert back to int\n        uint32x4_t v_ushr = vshrq_n_u32(vreinterpretq_u32_s32(v_src), shift);\n        int32x4_t v_lsr = vreinterpretq_s32_u32(v_ushr);\n        \n        // Add the results of arithmetic and logical shifts\n        int32x4_t v_result = vaddq_s32(v_asr, v_lsr);\n        \n        // Store the result\n        vst1q_s32(dst + i, v_result);\n    }\n    \n    // Handle remaining elements (if any)\n    for (; i < length; i++) {\n        int val = src[i];\n        int asr = val >> shift;\n        int lsr = (unsigned int)val >> shift;\n        dst[i] = asr + lsr;\n    }\n}\n```"}
{"task_id": "SimdBench_12_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid mixed_right_shift_simd(const int *src, int *dst, uint8_t shift, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 4; i += 4) {\n        int32x4_t v_src = vld1q_s32(src + i);\n        \n        // Arithmetic right shift\n        int32x4_t v_asr = vshrq_n_s32(v_src, shift);\n        \n        // Logical right shift: convert to uint, shift, then convert back to int\n        uint32x4_t v_lsr_uint = vreinterpretq_u32_s32(v_src);\n        uint32x4_t v_lsr = vshrq_n_u32(v_lsr_uint, shift);\n        int32x4_t v_lsr_final = vreinterpretq_s32_u32(v_lsr);\n        \n        // Add the results of arithmetic and logical shifts\n        int32x4_t v_result = vaddq_s32(v_asr, v_lsr_final);\n        \n        // Store the result\n        vst1q_s32(dst + i, v_result);\n    }\n    \n    // Handle remaining elements with scalar code\n    for (; i < length; i++) {\n        int val = src[i];\n        int asr = val >> shift;\n        int lsr = (unsigned int)val >> shift;\n        dst[i] = asr + lsr;\n    }\n}\n```"}
{"task_id": "SimdBench_12_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid mixed_right_shift_simd(const int *src, int *dst, uint8_t shift, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 4; i += 4) {\n        int32x4_t v_src = vld1q_s32(src + i);\n        \n        // Arithmetic right shift\n        int32x4_t v_asr = vshrq_n_s32(v_src, shift);\n        \n        // Logical right shift: convert to uint32, shift, then convert back to int32\n        uint32x4_t v_lsr = vshrq_n_u32(vreinterpretq_u32_s32(v_src), shift);\n        int32x4_t v_lsr_cast = vreinterpretq_s32_u32(v_lsr);\n        \n        // Add results of arithmetic and logical shifts\n        int32x4_t v_result = vaddq_s32(v_asr, v_lsr_cast);\n        \n        // Store the result\n        vst1q_s32(dst + i, v_result);\n    }\n    \n    // Handle remaining elements (if any)\n    for (; i < length; ++i) {\n        int val = src[i];\n        int asr = val >> shift;\n        int lsr = (unsigned int)val >> shift;\n        dst[i] = asr + lsr;\n    }\n}\n```"}
{"task_id": "SimdBench_12_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid mixed_right_shift_simd(const int *src, int *dst, uint8_t shift, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 4; i += 4) {\n        int32x4_t v_src = vld1q_s32(src + i);\n        \n        // Arithmetic right shift\n        int32x4_t v_asr = vshrq_n_s32(v_src, shift);\n        \n        // Logical right shift: convert to uint, shift, then convert back to int\n        uint32x4_t v_lsr = vshrq_n_u32(vreinterpretq_u32_s32(v_src), shift);\n        int32x4_t v_lsr_converted = vreinterpretq_s32_u32(v_lsr);\n        \n        // Add arithmetic and logical shift results\n        int32x4_t v_result = vaddq_s32(v_asr, v_lsr_converted);\n        \n        // Store the result\n        vst1q_s32(dst + i, v_result);\n    }\n    \n    // Handle remaining elements (if any)\n    for (; i < length; ++i) {\n        int val = src[i];\n        int asr = val >> shift;\n        int lsr = (unsigned int)val >> shift;\n        dst[i] = asr + lsr;\n    }\n}\n```"}
{"task_id": "SimdBench_13_Neon", "completion": "```c\n#include <arm_neon.h>\n\nint64_t matrix_sum_simd(const int *matrix, size_t rows, size_t cols) {\n    size_t total = rows * cols;\n    int32x4_t vsum = vdupq_n_s32(0);\n    int32x4_t vec;\n    \n    for (size_t i = 0; i <= total - 4; i += 4) {\n        vec = vld1q_s32(&matrix[i]);\n        vsum = vaddq_s32(vsum, vec);\n    }\n    \n    int32x2_t low = vadd_s32(vget_low_s32(vsum), vget_high_s32(vsum));\n    int32x2_t result = vpadd_s32(low, low);\n    \n    int64_t sum = (int64_t)result[0];\n    \n    for (size_t i = total & ~0x3; i < total; ++i) {\n        sum += matrix[i];\n    }\n    \n    return sum;\n}\n```"}
{"task_id": "SimdBench_13_Neon", "completion": "```c\n#include <arm_neon.h>\n\nint64_t matrix_sum_simd(const int *matrix, size_t rows, size_t cols) {\n    size_t total = rows * cols;\n    int32x4_t vec_sum = vdupq_n_s32(0);\n    int32x4_t vec_load;\n    \n    for (size_t i = 0; i <= total - 4; i += 4) {\n        vec_load = vld1q_s32(&matrix[i]);\n        vec_sum = vaddq_s32(vec_sum, vec_load);\n    }\n    \n    int32x2_t low_sum = vpadd_s32(vget_low_s32(vec_sum), vget_high_s32(vec_sum));\n    int32x2_t final_sum = vpadd_s32(low_sum, low_sum);\n    \n    int64_t result = (int64_t)vget_lane_s32(final_sum, 0);\n    \n    for (size_t i = total & ~3; i < total; ++i) {\n        result += matrix[i];\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_13_Neon", "completion": "```c\n#include <arm_neon.h>\n\nint64_t matrix_sum_simd(const int *matrix, size_t rows, size_t cols) {\n    size_t total = rows * cols;\n    int32x4_t sum_vec = vdupq_n_s32(0);\n    size_t i = 0;\n\n    for (; i <= total - 4; i += 4) {\n        int32x4_t vec = vld1q_s32(&matrix[i]);\n        sum_vec = vaddq_s32(sum_vec, vec);\n    }\n\n    int32x2_t low = vadd_s32(vget_low_s32(sum_vec), vget_high_s32(sum_vec));\n    int32x2_t result = vpadd_s32(low, low);\n\n    int64_t sum = (int64_t)(result[0] + result[1]);\n\n    for (; i < total; i++) {\n        sum += matrix[i];\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_13_Neon", "completion": "```c\n#include <arm_neon.h>\n\nint64_t matrix_sum_simd(const int *matrix, size_t rows, size_t cols) {\n    size_t total = rows * cols;\n    int32x4_t sum_vec = vdupq_n_s32(0);\n    int32x4_t vec;\n\n    for (size_t i = 0; i <= total - 4; i += 4) {\n        vec = vld1q_s32(&matrix[i]);\n        sum_vec = vaddq_s32(sum_vec, vec);\n    }\n\n    int32x2_t sum_low = vadd_s32(vget_low_s32(sum_vec), vget_high_s32(sum_vec));\n    int32x2_t sum_pair = vpadd_s32(sum_low, sum_low);\n\n    int64_t result = (int64_t)sum_pair[0];\n\n    for (size_t i = total & ~3; i < total; ++i) {\n        result += matrix[i];\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_13_Neon", "completion": "```c\n#include <arm_neon.h>\n\nint64_t matrix_sum_simd(const int *matrix, size_t rows, size_t cols) {\n    size_t length = rows * cols;\n    int32x4_t vec = vdupq_n_s32(0);\n    int32x4_t temp;\n    size_t i;\n\n    for (i = 0; i <= length - 4; i += 4) {\n        temp = vld1q_s32(&matrix[i]);\n        vec = vaddq_s32(vec, temp);\n    }\n\n    int32x2_t low = vadd_s32(vget_low_s32(vec), vget_high_s32(vec));\n    int32x2_t sum_vec = vpadd_s32(low, low);\n\n    int64_t total = (int64_t)sum_vec[0];\n\n    for (; i < length; i++) {\n        total += matrix[i];\n    }\n\n    return total;\n}\n```"}
{"task_id": "SimdBench_14_Neon", "completion": "```c\n#include <arm_neon.h>\n#include <stdint.h>\n\nsize_t argmax_simd(const int8_t *src, size_t length) {\n    if (length == 0) return 0;\n\n    int8x16_t max_val = vdupq_n_s8(*src);\n    uint16x8_t max_idx = vdupq_n_u16(0);\n\n    size_t idx = 0;\n    size_t result = 0;\n\n    for (; idx + 16 <= length; idx += 16) {\n        int8x16_t vec = vld1q_s8(src + idx);\n        uint16x8_t curr_idx = vcreate_u16(((uint64_t)idx << 48) | ((uint64_t)(idx+1) << 40) | \n                                         ((uint64_t)(idx+2) << 32) | ((uint64_t)(idx+3) << 24) |\n                                         ((uint64_t)(idx+4) << 16) | ((uint64_t)(idx+5) << 8) |\n                                         ((uint64_t)(idx+6)) | ((uint64_t)(idx+7)));\n\n        uint16x8_t cond = vcgeq_s8(vec, vget_low_s8(max_val));\n        max_val = vbslq_s8(cond, vec, max_val);\n        max_idx = vbslq_u16(cond, curr_idx, max_idx);\n\n        uint16x8_t cond_high = vcgeq_s8(vget_high_s8(vec), vget_high_s8(max_val));\n        max_val = vcombine_s8(vget_low_s8(max_val), vbslq_s8(cond_high, vget_high_s8(vec), vget_high_s8(max_val)));\n        max_idx = vcombine_u16(vget_low_u16(max_idx), vbslq_u16(cond_high, vget_high_u16(curr_idx), vget_high_u16(max_idx)));\n    }\n\n    int8_t max_scalar = vmaxvq_s8(max_val);\n    uint16x8_t cmp = vceqq_s8(vreinterpretq_s8_u8(max_val), vdupq_n_s8(max_scalar));\n    uint16_t res_idx = vmaxvq_u16(vandq_u16(vreinterpretq_u16_u8(cmp), max_idx));\n    result = (size_t)res_idx;\n\n    for (; idx < length; ++idx) {\n        if (src[idx] > src[result]) result = idx;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_14_Neon", "completion": "```c\n#include <arm_neon.h>\n#include <stdint.h>\n\nsize_t argmax_simd(const int8_t *src, size_t length) {\n    if (length == 0) return 0;\n\n    int8x16_t max_vec = vdupq_n_s8(-128);\n    uint16x8_t index_vec = vmovl_u8(vdup_n_u8(0));\n    uint16x8_t current_index = vmovl_u8(vdup_n_u8(0));\n    size_t global_max_idx = 0;\n    int8_t global_max_val = -128;\n\n    for (size_t i = 0; i < length; i += 16) {\n        int8x16_t vec = vld1q_s8(src + i);\n        uint16x8_t idx = current_index;\n\n        uint8x16_t mask = vcgeq_s8(vec, max_vec);\n        uint8x8_t mask_low = vget_low_u8(mask);\n        uint8x8_t mask_high = vget_high_u8(mask);\n\n        uint16x8_t new_indices = vbslq_u16((uint16x8_t)vcombine_u8(mask_low, mask_high), idx, index_vec);\n        index_vec = new_indices;\n\n        max_vec = vmaxq_s8(max_vec, vec);\n\n        current_index = vaddq_u16(current_index, vdupq_n_u16(16));\n\n        if (i + 16 > length) break;\n    }\n\n    int8_t max_value = vmaxvq_s8(max_vec);\n    uint16_t max_index = vminvq_u16(index_vec);\n\n    for (size_t i = 0; i < length; ++i) {\n        if (src[i] == max_value) {\n            global_max_idx = i;\n            break;\n        }\n    }\n\n    return global_max_idx;\n}\n```"}
{"task_id": "SimdBench_14_Neon", "completion": "```c\n#include <arm_neon.h>\n#include <stdint.h>\n\nsize_t argmax_simd(const int8_t *src, size_t length) {\n    if (length == 0) return 0;\n\n    int8_t max_val = src[0];\n    size_t max_idx = 0;\n\n    size_t i = 0;\n    for (; i <= length - 16; i += 16) {\n        int8x16_t vec = vld1q_s8(src + i);\n        int8x16_t max_vec = vpmaxq_s8(vec, vec);\n        max_vec = vpmaxq_s8(max_vec, max_vec);\n\n        int8x8_t max_half = vget_low_s8(max_vec);\n        int8x8_t max_half_high = vget_high_s8(max_vec);\n        max_half = vpmax_s8(max_half, max_half_high);\n\n        int8_t current_max = vmaxv_s8(max_half);\n        if (current_max > max_val) {\n            max_val = current_max;\n            // Find the exact index within the block\n            int8x16_t cmp = vcgeq_s8(vec, vdupq_n_s8(current_max));\n            uint8x16_t mask = vreinterpretq_u8_s8(cmp);\n            size_t idx_in_block = vclsq_u8(mask);\n            max_idx = i + idx_in_block;\n        }\n    }\n\n    for (; i < length; ++i) {\n        if (src[i] > max_val) {\n            max_val = src[i];\n            max_idx = i;\n        }\n    }\n\n    return max_idx;\n}\n```"}
{"task_id": "SimdBench_14_Neon", "completion": "```c\n#include <arm_neon.h>\n#include <stdint.h>\n\nsize_t argmax_simd(const int8_t *src, size_t length) {\n    if (length == 0) return 0;\n\n    int8x16_t max_val = vdupq_n_s8(-128);\n    uint16x8_t max_idx = vmovq_n_u16(0);\n\n    size_t i = 0;\n    for (; i <= length - 16; i += 16) {\n        int8x16_t vec = vld1q_s8(src + i);\n        uint16x8_t indices = vcreate_u16((uint64_t)(i) | ((uint64_t)(i + 8) << 32));\n        \n        uint16x8_t mask = vcgtq_s8(vec, max_val);\n        max_val = vbslq_s8(mask, vec, max_val);\n        max_idx = vbslq_u16(mask, indices, max_idx);\n    }\n\n    int8_t current_max = vmaxvq_s8(max_val);\n    size_t current_argmax = (size_t)vgetq_lane_u16(max_idx, 0);\n\n    for (; i < length; ++i) {\n        if (src[i] > current_max) {\n            current_max = src[i];\n            current_argmax = i;\n        }\n    }\n\n    return current_argmax;\n}\n```"}
{"task_id": "SimdBench_14_Neon", "completion": "```c\n#include <arm_neon.h>\n#include <stdint.h>\n\nsize_t argmax_simd(const int8_t *src, size_t length) {\n    if (length == 0) return 0;\n\n    int8_t max_val = src[0];\n    size_t max_idx = 0;\n\n    const int8x16_t vdup = vdupq_n_s8(0);\n    size_t i = 0;\n\n    for (; i <= length - 16; i += 16) {\n        int8x16_t vec = vld1q_s8(src + i);\n        int8x16_t vmax = vpmaxq_s8(vec, vdup);\n        int8x8_t vmax2 = vpmax_s8(vget_low_s8(vmax), vget_high_s8(vmax));\n        int8_t candidate_max = vmax2[0];\n\n        if (candidate_max > max_val) {\n            int8x16_t cmp = vcgeq_s8(vec, vdupq_n_s8(candidate_max));\n            uint16x8_t indices = vcreate_u16(((uint64_t)i + 0) | ((uint64_t)i + 1 << 8) | \n                                             ((uint64_t)i + 2 << 16) | ((uint64_t)i + 3 << 24) |\n                                             ((uint64_t)i + 4 << 32) | ((uint64_t)i + 5 << 40) |\n                                             ((uint64_t)i + 6 << 48) | ((uint64_t)i + 7 << 56));\n            uint16x8_t masked_indices = vandq_u16(indices, vreinterpretq_u16_s8(cmp));\n            uint64_t index_bits = vaddvq_u16(masked_indices);\n            max_idx = (size_t)index_bits;\n            max_val = candidate_max;\n        }\n    }\n\n    for (; i < length; ++i) {\n        if (src[i] > max_val) {\n            max_val = src[i];\n            max_idx = i;\n        }\n    }\n\n    return max_idx;\n}\n```"}
{"task_id": "SimdBench_15_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid vector_blend_simd(const uint16_t* src1, const uint16_t* src2, uint32_t mask, uint16_t* dst, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 8; i += 8) {\n        uint16x8_t vsrc1 = vld1q_u16(src1 + i);\n        uint16x8_t vsrc2 = vld1q_u16(src2 + i);\n\n        uint16x8_t vdst;\n        for (int j = 0; j < 8; ++j) {\n            uint16x8_t cond = vmovq_n_u16(((i + j) & mask) != 0 ? 0xFFFF : 0);\n            vdst = vbslq_u16(cond, vsrc1, vsrc2);\n        }\n\n        vst1q_u16(dst + i, vdst);\n    }\n\n    for (; i < length; ++i) {\n        dst[i] = ((i & mask) != 0) ? src1[i] : src2[i];\n    }\n}\n```"}
{"task_id": "SimdBench_15_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid vector_blend_simd(const uint16_t* src1, const uint16_t* src2, uint32_t mask, uint16_t* dst, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 8; i += 8) {\n        uint16x8_t vsrc1 = vld1q_u16(&src1[i]);\n        uint16x8_t vsrc2 = vld1q_u16(&src2[i]);\n\n        uint16x8_t indices = vcreate_u16(\n            ((uint64_t)i + 0) | (((uint64_t)i + 1) << 16) |\n            (((uint64_t)i + 2) << 32) | (((uint64_t)i + 3) << 48) |\n            (((uint64_t)i + 4) <<  0) | (((uint64_t)i + 5) << 16) |\n            (((uint64_t)i + 6) << 32) | (((uint64_t)i + 7) << 48)\n        );\n\n        uint16x8_t vmask = vandq_u16(indices, vdupq_n_u16(mask));\n        uint8x16_t selector = vcgtq_u16(vmask, vdupq_n_u16(0));\n\n        uint16x8_t blended = vbslq_u16(selector, vsrc1, vsrc2);\n        vst1q_u16(&dst[i], blended);\n    }\n\n    for (; i < length; ++i) {\n        if ((i & mask) != 0) {\n            dst[i] = src1[i];\n        } else {\n            dst[i] = src2[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_15_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid vector_blend_simd(const uint16_t* src1, const uint16_t* src2, uint32_t mask, uint16_t* dst, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 8; i += 8) {\n        uint16x8_t vsrc1 = vld1q_u16(src1 + i);\n        uint16x8_t vsrc2 = vld1q_u16(src2 + i);\n\n        uint16x8_t vdst;\n        for (int j = 0; j < 8; ++j) {\n            uint32_t index = i + j;\n            uint16_t select = ((index & mask) != 0) ? src1[index] : src2[index];\n            vdst = vsetq_lane_u16(select, vdst, j);\n        }\n\n        vst1q_u16(dst + i, vdst);\n    }\n\n    for (; i < length; ++i) {\n        uint32_t index = i;\n        dst[i] = ((index & mask) != 0) ? src1[i] : src2[i];\n    }\n}\n```"}
{"task_id": "SimdBench_15_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid vector_blend_simd(const uint16_t* src1, const uint16_t* src2, uint32_t mask, uint16_t* dst, size_t length) {\n    size_t i = 0;\n\n    for (; i <= length - 8; i += 8) {\n        uint16x8_t vsrc1 = vld1q_u16(src1 + i);\n        uint16x8_t vsrc2 = vld1q_u16(src2 + i);\n\n        uint8x16_t indices = vcreate_u8((uint64_t)i | ((uint64_t)(i+1) << 8) | \n                                       ((uint64_t)(i+2) << 16) | ((uint64_t)(i+3) << 24) |\n                                       ((uint64_t)(i+4) << 32) | ((uint64_t)(i+5) << 40) |\n                                       ((uint64_t)(i+6) << 48) | ((uint64_t)(i+7) << 56));\n        \n        uint16x8_t vmask = vandq_u16(vreinterpretq_u16_u8(indices), vdupq_n_u16(mask));\n        uint8x8_t cmp_result = vcgt_u8(vget_low_u8(vreinterpretq_u8_u16(vmask)), vdup_n_u8(0));\n        \n        uint8x8_t select_src1 = vdup_n_u8(0xFF);\n        uint8x8_t select_src2 = vdup_n_u8(0x00);\n        uint8x8_t blend_mask = vbsl_u8(cmp_result, select_src1, select_src2);\n\n        uint16x8_t blended = vbslq_u16(vreinterpretq_u16_u8(blend_mask), vsrc1, vsrc2);\n        vst1q_u16(dst + i, blended);\n    }\n\n    for (; i < length; ++i) {\n        if ((i & mask) != 0) {\n            dst[i] = src1[i];\n        } else {\n            dst[i] = src2[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_15_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid vector_blend_simd(const uint16_t* src1, const uint16_t* src2, uint32_t mask, uint16_t* dst, size_t length) {\n    size_t i = 0;\n\n    for (; i + 8 <= length; i += 8) {\n        uint16x8_t vsrc1 = vld1q_u16(src1 + i);\n        uint16x8_t vsrc2 = vld1q_u16(src2 + i);\n\n        uint16x8_t indices = vcreate_u16((uint64_t)(i + 0) | ((uint64_t)(i + 1) << 16) |\n                                        ((uint64_t)(i + 2) << 32) | ((uint64_t)(i + 3) << 48) |\n                                        ((uint64_t)(i + 4) <<  0) | ((uint64_t)(i + 5) << 16) |\n                                        ((uint64_t)(i + 6) << 32) | ((uint64_t)(i + 7) << 48));\n\n        uint16x8_t vmask = vcgeq_u16(vandq_u16(indices, vdupq_n_u16(mask)), vdupq_n_u16(0));\n        \n        uint16x8_t blended = vbslq_u16(vmask, vsrc1, vsrc2);\n        vst1q_u16(dst + i, blended);\n    }\n\n    for (; i < length; ++i) {\n        if ((i & mask) != 0) {\n            dst[i] = src1[i];\n        } else {\n            dst[i] = src2[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_16_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid population_count_simd(const uint32_t* src, uint32_t* dst, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 4; i += 4) {\n        uint32x4_t v = vld1q_u32(src + i);\n        uint32x4_t cnt = vcntq_u32(v);\n        vst1q_u32(dst + i, cnt);\n    }\n    for (; i < length; i++) {\n        dst[i] = __builtin_popcount(src[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_16_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid population_count_simd(const uint32_t* src, uint32_t* dst, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 4; i += 4) {\n        uint32x4_t v_src = vld1q_u32(src + i);\n        uint32x4_t v_popcount = vcntq_u32(v_src);\n        vst1q_u32(dst + i, v_popcount);\n    }\n    for (; i < length; i++) {\n        dst[i] = __builtin_popcount(src[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_16_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid population_count_simd(const uint32_t* src, uint32_t* dst, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 4; i += 4) {\n        uint32x4_t vsrc = vld1q_u32(src + i);\n        uint32x4_t vpopcnt = vcntq_u32(vsrc);\n        vst1q_u32(dst + i, vpopcnt);\n    }\n    for (; i < length; i++) {\n        dst[i] = __builtin_popcount(src[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_16_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid population_count_simd(const uint32_t* src, uint32_t* dst, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 4; i += 4) {\n        uint32x4_t vsrc = vld1q_u32(src + i);\n        uint32x4_t vpopcnt = vcntq_u32(vsrc);\n        vst1q_u32(dst + i, vpopcnt);\n    }\n    for (; i < length; i++) {\n        dst[i] = __builtin_popcount(src[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_16_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid population_count_simd(const uint32_t* src, uint32_t* dst, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 4; i += 4) {\n        uint32x4_t vec = vld1q_u32(src + i);\n        uint32x4_t popcnt_vec = vcntq_u32(vec);\n        vst1q_u32(dst + i, popcnt_vec);\n    }\n    for (; i < length; i++) {\n        dst[i] = __builtin_popcount(src[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_17_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid saturating_add_simd(const uint16_t* src1, const uint16_t* src2, uint16_t* dst, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 8; i += 8) {\n        uint16x8_t vec1 = vld1q_u16(&src1[i]);\n        uint16x8_t vec2 = vld1q_u16(&src2[i]);\n        uint16x8_t result = vqaddq_u16(vec1, vec2);\n        vst1q_u16(&dst[i], result);\n    }\n    for (; i < length; i++) {\n        dst[i] = (uint16_t)((src1[i] + src2[i]) > UINT16_MAX ? UINT16_MAX : src1[i] + src2[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_17_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid saturating_add_simd(const uint16_t* src1, const uint16_t* src2, uint16_t* dst, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 8; i += 8) {\n        uint16x8_t vec1 = vld1q_u16(src1 + i);\n        uint16x8_t vec2 = vld1q_u16(src2 + i);\n        uint16x8_t result = vqaddq_u16(vec1, vec2);\n        vst1q_u16(dst + i, result);\n    }\n    for (; i < length; i++) {\n        dst[i] = (uint16_t)((src1[i] + src2[i]) > UINT16_MAX ? UINT16_MAX : (src1[i] + src2[i]));\n    }\n}\n```"}
{"task_id": "SimdBench_17_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid saturating_add_simd(const uint16_t* src1, const uint16_t* src2, uint16_t* dst, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 8; i += 8) {\n        uint16x8_t vec1 = vld1q_u16(src1 + i);\n        uint16x8_t vec2 = vld1q_u16(src2 + i);\n        uint16x8_t result = vqaddq_u16(vec1, vec2);\n        vst1q_u16(dst + i, result);\n    }\n    for (; i < length; i++) {\n        dst[i] = (src1[i] > UINT16_MAX - src2[i]) ? UINT16_MAX : src1[i] + src2[i];\n    }\n}\n```"}
{"task_id": "SimdBench_17_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid saturating_add_simd(const uint16_t* src1, const uint16_t* src2, uint16_t* dst, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 8; i += 8) {\n        uint16x8_t vec1 = vld1q_u16(src1 + i);\n        uint16x8_t vec2 = vld1q_u16(src2 + i);\n        uint16x8_t result = vqaddq_u16(vec1, vec2);\n        vst1q_u16(dst + i, result);\n    }\n    for (; i < length; i++) {\n        dst[i] = (src1[i] + src2[i] > UINT16_MAX) ? UINT16_MAX : src1[i] + src2[i];\n    }\n}\n```"}
{"task_id": "SimdBench_17_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid saturating_add_simd(const uint16_t* src1, const uint16_t* src2, uint16_t* dst, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 8; i += 8) {\n        uint16x8_t vec1 = vld1q_u16(src1 + i);\n        uint16x8_t vec2 = vld1q_u16(src2 + i);\n        uint16x8_t result = vqaddq_u16(vec1, vec2);\n        vst1q_u16(dst + i, result);\n    }\n    for (; i < length; ++i) {\n        dst[i] = (uint16_t)((src1[i] + src2[i]) > UINT16_MAX ? UINT16_MAX : src1[i] + src2[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_18_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nvoid range_matrix_mul_simd(const double* A, const double* B, double* C, size_t m, size_t n, size_t p) {\n    const double lower_bound = -100.0;\n    const double upper_bound = 100.0;\n\n    for (size_t i = 0; i < m; ++i) {\n        for (size_t k = 0; k < n; k += 2) {\n            double a_val1 = A[i * n + k];\n            double a_val2 = (k + 1 < n) ? A[i * n + k + 1] : 0.0;\n\n            if ((a_val1 >= lower_bound && a_val1 <= upper_bound) || (a_val2 >= lower_bound && a_val2 <= upper_bound)) {\n                for (size_t j = 0; j < p; j += 2) {\n                    float64x2_t vb1 = vld1q_f64(&B[k * p + j]);\n                    float64x2_t va1 = {a_val1, a_val2};\n\n                    // Mask values in B that are out of range\n                    uint64x2_t mask_b = vcgeq_f64(vb1, vdupq_n_f64(lower_bound)) & vcleq_f64(vb1, vdupq_n_f64(upper_bound));\n                    float64x2_t vb_masked = vandq_f64(vb1, vmovq_n_u64(mask_b));\n\n                    float64x2_t prod = vmulq_f64(va1, vb_masked);\n\n                    float64x2_t vc1 = vld1q_f64(&C[i * p + j]);\n                    vc1 = vaddq_f64(vc1, prod);\n                    vst1q_f64(&C[i * p + j], vc1);\n\n                    if (j + 2 < p) {\n                        float64x2_t vb2 = vld1q_f64(&B[(k * p) + j + 2]);\n                        uint64x2_t mask_b2 = vcgeq_f64(vb2, vdupq_n_f64(lower_bound)) & vcleq_f64(vb2, vdupq_n_f64(upper_bound));\n                        float64x2_t vb2_masked = vandq_f64(vb2, vmovq_n_u64(mask_b2));\n\n                        float64x2_t prod2 = vmulq_f64(va1, vb2_masked);\n\n                        float64x2_t vc2 = vld1q_f64(&C[i * p + j + 2]);\n                        vc2 = vaddq_f64(vc2, prod2);\n                        vst1q_f64(&C[i * p + j + 2], vc2);\n                    }\n                }\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_18_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nvoid range_matrix_mul_simd(const double* A, const double* B, double* C, size_t m, size_t n, size_t p) {\n    const double lower_bound = -100.0;\n    const double upper_bound = 100.0;\n\n    for (size_t i = 0; i < m; ++i) {\n        for (size_t k = 0; k < n; k += 2) {\n            double vrA[2];\n            vrA[0] = A[i * n + k];\n            vrA[1] = (k + 1 < n) ? A[i * n + k + 1] : 0.0;\n\n            // Check bounds for A elements\n            int32x2_t maskA = vcge_f64(vld1q_f64((const float64_t*)vrA), vdup_n_f64(lower_bound));\n            maskA = vand_i32(maskA, vcle_f64(vld1q_f64((const float64_t*)vrA), vdup_n_f64(upper_bound)));\n\n            for (size_t j = 0; j < p; j += 2) {\n                double vrB[2];\n                vrB[0] = B[k * p + j];\n                vrB[1] = (j + 1 < p) ? B[k * p + j + 1] : 0.0;\n\n                // Check bounds for B elements\n                int32x2_t maskB = vcge_f64(vld1q_f64((const float64_t*)vrB), vdup_n_f64(lower_bound));\n                maskB = vand_i32(maskB, vcle_f64(vld1q_f64((const float64_t*)vrB), vdup_n_f64(upper_bound)));\n\n                int32x2_t combined_mask = vand_i32(maskA, maskB);\n\n                // Load C values\n                double vrC[2];\n                vrC[0] = C[i * p + j];\n                vrC[1] = (j + 1 < p) ? C[i * p + j + 1] : 0.0;\n\n                // Perform multiplication and addition only if within range\n                float64x2_t valA = vld1q_f64((const float64_t*)vrA);\n                float64x2_t valB = vld1q_f64((const float64_t*)vrB);\n                float64x2_t valC = vld1q_f64((const float64_t*)vrC);\n\n                float64x2_t product = vmulq_f64(valA, valB);\n                float64x2_t masked_product = vbslq_f64(vreinterpretq_f64_s32(combined_mask), product, vdupq_n_f64(0.0));\n                valC = vaddq_f64(valC, masked_product);\n\n                vrC[0] = valC[0];\n                vrC[1] = valC[1];\n\n                C[i * p + j] = vrC[0];\n                if (j + 1 < p) {\n                    C[i * p + j + 1] = vrC[1];\n                }\n\n                if (k + 1 < n) {\n                    vrB[0] = B[(k + 1) * p + j];\n                    vrB[1] = (j + 1 < p) ? B[(k + 1) * p + j + 1] : 0.0;\n\n                    // Check bounds for B elements\n                    maskB = vcge_f64(vld1q_f64((const float64_t*)vrB), vdup_n_f64(lower_bound));\n                    maskB = vand_i32(maskB, vcle_f64(vld1q_f64((const float64_t*)vrB), vdup_n_f64(upper_bound)));\n\n                    combined_mask = vand_i32(maskA, maskB);\n\n                    // Load C values again\n                    vrC[0] = C[i * p + j];\n                    vrC[1] = (j + 1 < p) ? C[i * p + j + 1] : 0.0;\n\n                    valA = vdupq_n_f64(vrA[1]);\n                    valB = vld1q_f64((const float64_t*)vrB);\n                    valC = vld1q_f64((const float64_t*)vrC);\n\n                    product = vmulq_f64(valA, valB);\n                    masked_product = vbslq_f64(vreinterpretq_f64_s32(combined_mask), product, vdupq_n_f64(0.0));\n                    valC = vaddq_f64(valC, masked_product);\n\n                    vrC[0] = valC[0];\n                    vrC[1] = valC[1];\n\n                    C[i * p + j] = vrC[0];\n                    if (j + 1 < p) {\n                        C[i * p + j + 1] = vrC[1];\n                    }\n                }\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_18_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nvoid range_matrix_mul_simd(const double* A, const double* B, double* C, size_t m, size_t n, size_t p) {\n    const double lower_bound = -100.0;\n    const double upper_bound = 100.0;\n\n    for (size_t i = 0; i < m; ++i) {\n        for (size_t k = 0; k < n; k += 2) {\n            double vA1 = A[i * n + k];\n            double vA2 = (k + 1 < n) ? A[i * n + k + 1] : 0.0;\n\n            int32x2_t mask1 = vcge_f64(vdup_n_f64(vA1), vdup_n_f64(lower_bound)) & vcle_f64(vdup_n_f64(vA1), vdup_n_f64(upper_bound));\n            int32x2_t mask2 = vcge_f64(vdup_n_f64(vA2), vdup_n_f64(lower_bound)) & vcle_f64(vdup_n_f64(vA2), vdup_n_f64(upper_bound));\n\n            float64x2_t vA = {vA1, vA2};\n            vA = vandq_f64(vA, vmovl_u8(vreinterpret_u8_u32(vorr_u32(vreinterpret_u32_f64(mask1), vreinterpret_u32_f64(mask2))));\n\n            for (size_t j = 0; j < p; j += 2) {\n                double vB1 = B[k * p + j];\n                double vB2 = (j + 1 < p) ? B[k * p + j + 1] : 0.0;\n                double vB3 = (k + 1 < n) ? B[(k + 1) * p + j] : 0.0;\n                double vB4 = (k + 1 < n && j + 1 < p) ? B[(k + 1) * p + j + 1] : 0.0;\n\n                int32x2_t maskB1 = vcge_f64(vdup_n_f64(vB1), vdup_n_f64(lower_bound)) & vcle_f64(vdup_n_f64(vB1), vdup_n_f64(upper_bound));\n                int32x2_t maskB2 = vcge_f64(vdup_n_f64(vB2), vdup_n_f64(lower_bound)) & vcle_f64(vdup_n_f64(vB2), vdup_n_f64(upper_bound));\n                int32x2_t maskB3 = vcge_f64(vdup_n_f64(vB3), vdup_n_f64(lower_bound)) & vcle_f64(vdup_n_f64(vB3), vdup_n_f64(upper_bound));\n                int32x2_t maskB4 = vcge_f64(vdup_n_f64(vB4), vdup_n_f64(lower_bound)) & vcle_f64(vdup_n_f64(vB4), vdup_n_f64(upper_bound));\n\n                float64x2_t vB = {vB1, vB2};\n                float64x2_t vB_cross = {vB3, vB4};\n\n                vB = vandq_f64(vB, vmovl_u8(vreinterpret_u8_u32(vorr_u32(vreinterpret_u32_f64(maskB1), vreinterpret_u32_f64(maskB2))));\n                vB_cross = vandq_f64(vB_cross, vmovl_u8(vreinterpret_u8_u32(vorr_u32(vreinterpret_u32_f64(maskB3), vreinterpret_u32_f64(maskB4))));\n\n                float64x2_t prod = vmulq_f64(vA, vB);\n                float64x2_t cross_prod = vmulq_f64(vA, vB_cross);\n\n                double res1 = vgetq_lane_f64(prod, 0) + vgetq_lane_f64(cross_prod, 0);\n                double res2 = vgetq_lane_f64(prod, 1) + vgetq_lane_f64(cross_prod, 1);\n\n                double* c_ptr = &C[i * p + j];\n                c_ptr[0] += res1;\n                if (j + 1 < p) {\n                    c_ptr[1] += res2;\n                }\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_18_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid range_matrix_mul_simd(const double* A, const double* B, double* C, size_t m, size_t n, size_t p) {\n    const double lower_bound = -100.0;\n    const double upper_bound = 100.0;\n\n    for (size_t i = 0; i < m; ++i) {\n        for (size_t j = 0; j < p; ++j) {\n            double acc[2] = { 0.0, 0.0 };\n            for (size_t k = 0; k < n; k += 2) {\n                float64x2_t va = vld1q_f64(&A[i * n + k]);\n                float64x2_t vb = vld1q_f64(&B[k * p + j]);\n\n                float64x2_t cmp_a_low = vcgeq_f64(va, vdupq_n_f64(lower_bound));\n                float64x2_t cmp_a_high = vcleq_f64(va, vdupq_n_f64(upper_bound));\n                float64x2_t cmp_a = vandq_f64(cmp_a_low, cmp_a_high);\n\n                float64x2_t cmp_b_low = vcgeq_f64(vb, vdupq_n_f64(lower_bound));\n                float64x2_t cmp_b_high = vcleq_f64(vb, vdupq_n_f64(upper_bound));\n                float64x2_t cmp_b = vandq_f64(cmp_b_low, cmp_b_high);\n\n                float64x2_t cmp = vandq_f64(cmp_a, cmp_b);\n                float64x2_t vmul_res = vmulq_f64(va, vb);\n                float64x2_t vres = vbslq_f64(cmp, vmul_res, vdupq_n_f64(0.0));\n\n                float64x2_t vacc = vld1q_f64(acc);\n                vacc = vaddq_f64(vacc, vres);\n                vst1q_f64(acc, vacc);\n            }\n            C[i * p + j] = acc[0] + acc[1];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_18_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid range_matrix_mul_simd(const double* A, const double* B, double* C, size_t m, size_t n, size_t p) {\n    const double lower_bound = -100.0;\n    const double upper_bound = 100.0;\n\n    for (size_t i = 0; i < m; ++i) {\n        for (size_t k = 0; k < n; k += 2) {\n            double a0 = A[i * n + k];\n            double a1 = (k + 1 < n) ? A[i * n + k + 1] : 0.0;\n\n            int in_range_a0 = (a0 >= lower_bound && a0 <= upper_bound);\n            int in_range_a1 = (a1 >= lower_bound && a1 <= upper_bound);\n\n            for (size_t j = 0; j < p; j += 2) {\n                double b0 = B[k * p + j];\n                double b1 = (j + 1 < p) ? B[k * p + j + 1] : 0.0;\n                double b2 = (k + 1 < n) ? B[(k + 1) * p + j] : 0.0;\n                double b3 = (k + 1 < n && j + 1 < p) ? B[(k + 1) * p + j + 1] : 0.0;\n\n                int in_range_b0 = (b0 >= lower_bound && b0 <= upper_bound);\n                int in_range_b1 = (b1 >= lower_bound && b1 <= upper_bound);\n                int in_range_b2 = (b2 >= lower_bound && b2 <= upper_bound);\n                int in_range_b3 = (b3 >= lower_bound && b3 <= upper_bound);\n\n                float64x2_t va = vdupq_n_f64(0.0);\n                float64x2_t vb = vdupq_n_f64(0.0);\n\n                if (in_range_a0 && in_range_b0) {\n                    va = vsetq_lane_f64(a0 * b0, va, 0);\n                }\n                if (in_range_a0 && in_range_b1) {\n                    va = vsetq_lane_f64(a0 * b1, va, 1);\n                }\n                if (in_range_a1 && in_range_b2) {\n                    vb = vsetq_lane_f64(a1 * b2, vb, 0);\n                }\n                if (in_range_a1 && in_range_b3) {\n                    vb = vsetq_lane_f64(a1 * b3, vb, 1);\n                }\n\n                float64x2_t vc_load = vld1q_f64(&C[i * p + j]);\n                float64x2_t vc = vaddq_f64(vc_load, va);\n                vc = vaddq_f64(vc, vb);\n                vst1q_f64(&C[i * p + j], vc);\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_19_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid tensor_add_3d_simd(const int64_t* A, const int64_t* B, int64_t* C, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t i = 0;\n\n    for (; i <= total_elements - 2; i += 2) {\n        int64x2_t vec_a = vld1q_s64((const int64_t*)&A[i]);\n        int64x2_t vec_b = vld1q_s64((const int64_t*)&B[i]);\n        int64x2_t vec_c = vaddq_s64(vec_a, vec_b);\n        vst1q_s64((int64_t*)&C[i], vec_c);\n    }\n\n    for (; i < total_elements; i++) {\n        C[i] = A[i] + B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_19_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid tensor_add_3d_simd(const int64_t* A, const int64_t* B, int64_t* C, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t i = 0;\n\n    for (; i <= total_elements - 2; i += 2) {\n        int64x2_t vec_a = vld1q_s64((const int64_t*)&A[i]);\n        int64x2_t vec_b = vld1q_s64((const int64_t*)&B[i]);\n        int64x2_t vec_c = vaddq_s64(vec_a, vec_b);\n        vst1q_s64((int64_t*)&C[i], vec_c);\n    }\n\n    for (; i < total_elements; i++) {\n        C[i] = A[i] + B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_19_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid tensor_add_3d_simd(const int64_t* A, const int64_t* B, int64_t* C, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t i = 0;\n\n    // Process 2 elements at a time using SIMD\n    for (; i <= total_elements - 2; i += 2) {\n        int64x2_t vec_a = vld1q_s64((const int64_t*)&A[i]);\n        int64x2_t vec_b = vld1q_s64((const int64_t*)&B[i]);\n        int64x2_t vec_c = vaddq_s64(vec_a, vec_b);\n        vst1q_s64((int64_t*)&C[i], vec_c);\n    }\n\n    // Handle remaining elements (if any)\n    for (; i < total_elements; i++) {\n        C[i] = A[i] + B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_19_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid tensor_add_3d_simd(const int64_t* A, const int64_t* B, int64_t* C, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t i = 0;\n\n    for (; i <= total_elements - 2; i += 2) {\n        int64x2_t vec_a = vld1q_s64((const int64_t*)&A[i]);\n        int64x2_t vec_b = vld1q_s64((const int64_t*)&B[i]);\n        int64x2_t vec_c = vaddq_s64(vec_a, vec_b);\n        vst1q_s64((int64_t*)&C[i], vec_c);\n    }\n\n    for (; i < total_elements; ++i) {\n        C[i] = A[i] + B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_19_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid tensor_add_3d_simd(const int64_t* A, const int64_t* B, int64_t* C, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t i = 0;\n\n    for (; i <= total_elements - 2; i += 2) {\n        int64x2_t vec_a = vld1q_s64((const int64_t*)&A[i]);\n        int64x2_t vec_b = vld1q_s64((const int64_t*)&B[i]);\n        int64x2_t vec_c = vaddq_s64(vec_a, vec_b);\n        vst1q_s64((int64_t*)&C[i], vec_c);\n    }\n\n    for (; i < total_elements; ++i) {\n        C[i] = A[i] + B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_20_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid vector_add_round_round_nearest_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 4; i += 4) {\n        float32x4_t v1 = vld1q_f32(src1 + i);\n        float32x4_t v2 = vld1q_f32(src2 + i);\n        float32x4_t res = vrndnq_f32(vaddq_f32(v1, v2));\n        vst1q_f32(dst + i, res);\n    }\n    for (; i < length; ++i) {\n        dst[i] = nearbyintf(src1[i] + src2[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_20_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid vector_add_round_round_nearest_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 4; i += 4) {\n        float32x4_t vsrc1 = vld1q_f32(src1 + i);\n        float32x4_t vsrc2 = vld1q_f32(src2 + i);\n        float32x4_t vresult = vrndnq_f32(vaddq_f32(vsrc1, vsrc2));\n        vst1q_f32(dst + i, vresult);\n    }\n    for (; i < length; ++i) {\n        dst[i] = nearbyintf(src1[i] + src2[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_20_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid vector_add_round_round_nearest_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 4; i += 4) {\n        float32x4_t v1 = vld1q_f32(src1 + i);\n        float32x4_t v2 = vld1q_f32(src2 + i);\n        float32x4_t res = vrndnq_f32(vaddq_f32(v1, v2));\n        vst1q_f32(dst + i, res);\n    }\n    for (; i < length; ++i) {\n        dst[i] = nearbyintf(src1[i] + src2[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_20_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid vector_add_round_round_nearest_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 4; i += 4) {\n        float32x4_t vsrc1 = vld1q_f32(src1 + i);\n        float32x4_t vsrc2 = vld1q_f32(src2 + i);\n        float32x4_t vres = vrndnq_f32(vaddq_f32(vsrc1, vsrc2));\n        vst1q_f32(dst + i, vres);\n    }\n    for (; i < length; ++i) {\n        dst[i] = nearbyintf(src1[i] + src2[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_20_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid vector_add_round_nearest_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 4; i += 4) {\n        float32x4_t v1 = vld1q_f32(src1 + i);\n        float32x4_t v2 = vld1q_f32(src2 + i);\n        float32x4_t res = vrndnq_f32(vaddq_f32(v1, v2));\n        vst1q_f32(dst + i, res);\n    }\n    for (; i < length; i++) {\n        dst[i] = nearbyintf(src1[i] + src2[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_21_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid vector_mul_round_up_simd(const float* src1, const float* src2, float* dst, size_t length){\n    float32x4_t vcond = vmovq_n_f32(-1.0f);\n    float32x4_t vdiff_limit = vmovq_n_f32(50.0f);\n    float32x4_t vzero = vmovq_n_f32(0.0f);\n\n    for (size_t i = 0; i + 4 <= length; i += 8) {\n        if ((i % 2) == 0) {\n            float32x4_t va = vld1q_f32(src1 + i);\n            float32x4_t vb = vld1q_f32(src2 + i);\n            float32x4_t vdiff = vabsq_f32(vsubq_f32(va, vb));\n            uint32x4_t mask = vcgeq_f32(vdiff_limit, vdiff);\n            float32x4_t vmul = vmulq_f32(va, vb);\n            float32x4_t vrounded = vrndpq_f32(vmul);\n            float32x4_t vresult = vbslq_f32(mask, vrounded, vcond);\n            vst1q_f32(dst + i, vresult);\n        } else {\n            float32x4_t vresult = vcond;\n            vst1q_f32(dst + i, vresult);\n        }\n    }\n\n    // Handle remaining elements\n    for (size_t i = (length / 4) * 4; i < length; ++i) {\n        if ((i % 2) == 0) {\n            float a = src1[i];\n            float b = src2[i];\n            if (fabsf(a - b) <= 50.0f) {\n                dst[i] = ceilf(a * b);\n            } else {\n                dst[i] = -1.0f;\n            }\n        } else {\n            dst[i] = -1.0f;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_21_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid vector_mul_round_up_simd(const float* src1, const float* src2, float* dst, size_t length){\n    float32x4_t vcond = vdupq_n_f32(-1.0f);\n    float32x4_t vthreshold = vdupq_n_f32(50.0f);\n    float32x4_t vzero = vdupq_n_f32(0.0f);\n    float32x4_t vtwo = vdupq_n_f32(2.0f);\n\n    size_t i = 0;\n    for (; i <= length - 4; i += 4) {\n        float32x4_t va = vld1q_f32(src1 + i);\n        float32x4_t vb = vld1q_f32(src2 + i);\n\n        // Calculate absolute difference\n        float32x4_t vdiff = vabsq_f32(vsubq_f32(va, vb));\n\n        // Check if abs diff is within threshold\n        uint32x4_t cond1 = vcgeq_f32(vthreshold, vdiff);\n\n        // Check if index is multiple of 2\n        float32x4_t vindex = vdupq_lane_f32(vreinterpretq_f32_u32(vcreate_u32((uint64_t)(i))), 0);\n        vindex = vmlaq_f32(vzero, vdupq_n_f32(1.0f), vtwo);\n        uint32x4_t cond2 = vceqq_f32(vindex, vconvertq_f32_u32(vreinterpretq_u32_f32(vindex)));\n\n        // Combine conditions\n        uint32x4_t mask = vandq_u32(cond1, cond2);\n\n        // Perform multiplication\n        float32x4_t vmul = vmulq_f32(va, vb);\n\n        // Round up towards positive infinity\n        float32x4_t vround = vaddq_f32(vmul, vdupq_n_f32(0.999999f));\n\n        // Select based on mask\n        float32x4_t vresult = vbslq_f32(vreinterpretq_u32_f32(mask), vround, vcond);\n\n        // Store result\n        vst1q_f32(dst + i, vresult);\n    }\n\n    // Handle remaining elements\n    for (; i < length; ++i) {\n        if (i % 2 == 0 && fabs(src1[i] - src2[i]) <= 50.0f) {\n            dst[i] = ceilf(src1[i] * src2[i]);\n        } else {\n            dst[i] = -1.0f;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_21_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid vector_mul_round_up_simd(const float* src1, const float* src2, float* dst, size_t length){\n    float32x4_t vcond = vdupq_n_f32(-1.0f);\n    float32x4_t vthreshold = vdupq_n_f32(50.0f);\n    float32x4_t vzero = vdupq_n_f32(0.0f);\n    float32x4_t vtwo = vdupq_n_f32(2.0f);\n\n    size_t i = 0;\n    for (; i <= length - 4; i += 4) {\n        float32x4_t va = vld1q_f32(src1 + i);\n        float32x4_t vb = vld1q_f32(src2 + i);\n\n        // Calculate absolute difference\n        float32x4_t vdiff = vabsq_f32(vsubq_f32(va, vb));\n\n        // Check if difference is within threshold\n        uint32x4_t mask_diff = vcgeq_f32(vthreshold, vdiff);\n\n        // Check if index is a multiple of 2\n        float32x4_t vindex = vdupq_lane_f32(vreinterpretq_f32_u32(vcreate_u32((uint64_t)(i))), 0);\n        uint32x4_t mask_index = veqzq_f32(vfmodq_f32(vindex, vtwo));\n\n        // Combine conditions\n        uint32x4_t mask_combined = vandq_u32(mask_diff, vreinterpretq_u32_f32(vceqq_f32(vfmodq_f32(vindex, vtwo), vzero)));\n\n        // Perform multiplication\n        float32x4_t vmul = vmulq_f32(va, vb);\n\n        // Round up toward positive infinity\n        float32x4_t vrounded = vrndpq_f32(vmul);\n\n        // Select values based on combined mask\n        float32x4_t vresult = vbslq_f32(vreinterpretq_f32_u32(mask_combined), vrounded, vcond);\n\n        // Store the result\n        vst1q_f32(dst + i, vresult);\n    }\n\n    // Handle remaining elements\n    for (; i < length; ++i) {\n        if (fabsf(src1[i] - src2[i]) <= 50.0f && (i % 2 == 0)) {\n            dst[i] = ceilf(src1[i] * src2[i]);\n        } else {\n            dst[i] = -1.0f;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_21_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid vector_mul_round_up_simd(const float* src1, const float* src2, float* dst, size_t length){\n    float32x4_t vcond = vdupq_n_f32(-1.0f);\n    float32x4_t vthreshold = vdupq_n_f32(50.0f);\n    float32x4_t vzero = vdupq_n_f32(0.0f);\n    float32x4_t vtwo = vdupq_n_f32(2.0f);\n\n    size_t i = 0;\n    for (; i <= length - 4; i += 4) {\n        float32x4_t va = vld1q_f32(src1 + i);\n        float32x4_t vb = vld1q_f32(src2 + i);\n\n        // Calculate absolute difference\n        float32x4_t vdiff = vabsq_f32(vsubq_f32(va, vb));\n\n        // Check if difference is within threshold\n        uint32x4_t mask_diff = vcgeq_f32(vthreshold, vdiff);\n\n        // Check if index is a multiple of 2\n        uint32x4_t mask_index = vmovq_n_u32((i % 2 == 0) ? 0xFFFFFFFF : 0);\n\n        // Combine conditions\n        uint32x4_t mask_combined = vandq_u32(mask_diff, vmovq_n_u32((i % 2 == 0) ? 0xFFFFFFFF : 0));\n\n        // Perform multiplication\n        float32x4_t vmul = vmulq_f32(va, vb);\n\n        // Round up toward positive infinity\n        float32x4_t vround = vaddq_f32(vmul, vdupq_n_f32(0.999999f));\n\n        // Select results based on combined mask\n        float32x4_t vresult = vbslq_f32(mask_combined, vround, vcond);\n\n        // Store the result\n        vst1q_f32(dst + i, vresult);\n    }\n\n    // Handle remaining elements\n    for (; i < length; ++i) {\n        if ((fabs(src1[i] - src2[i]) <= 50.0f) && (i % 2 == 0)) {\n            dst[i] = ceilf(src1[i] * src2[i]);\n        } else {\n            dst[i] = -1.0f;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_21_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid vector_mul_round_up_simd(const float* src1, const float* src2, float* dst, size_t length){\n    float32x4_t vcond = vdupq_n_f32(-1.0f);\n    float32x4_t vthreshold = vdupq_n_f32(50.0f);\n    float32x4_t vzero = vdupq_n_f32(0.0f);\n\n    for (size_t i = 0; i < length; i += 8) {\n        float32x4_t va = vld1q_f32(src1 + i);\n        float32x4_t vb = vld1q_f32(src2 + i);\n\n        // Calculate absolute difference\n        float32x4_t vdiff = vabsq_f32(vsubq_f32(va, vb));\n\n        // Check if difference is within threshold\n        uint32x4_t mask_diff = vcmltq_f32(vdiff, vthreshold);\n\n        // Check if index is a multiple of 2\n        uint32x4_t mask_index = vandq_u32(vreinterpretq_u32_f32(va), vdupq_n_u32(0xAAAAAAAA));\n        mask_index = vceqq_u32(mask_index, vzero);\n\n        // Combine conditions\n        uint32x4_t mask = vandq_u32(mask_diff, mask_index);\n\n        // Perform multiplication\n        float32x4_t vmul = vmulq_f32(va, vb);\n\n        // Round up toward positive infinity\n        float32x4_t vround = vrndpq_f32(vmul);\n\n        // Select results based on condition\n        float32x4_t vresult = vbslq_f32(vreinterpretq_u32_f32(mask), vround, vcond);\n\n        // Store the result\n        vst1q_f32(dst + i, vresult);\n\n        // Repeat for next 4 elements\n        if (i + 4 < length) {\n            va = vld1q_f32(src1 + i + 4);\n            vb = vld1q_f32(src2 + i + 4);\n\n            vdiff = vabsq_f32(vsubq_f32(va, vb));\n            mask_diff = vcmltq_f32(vdiff, vthreshold);\n\n            mask_index = vandq_u32(vreinterpretq_u32_f32(va), vdupq_n_u32(0xAAAAAAAA));\n            mask_index = vceqq_u32(mask_index, vzero);\n\n            mask = vandq_u32(mask_diff, mask_index);\n\n            vmul = vmulq_f32(va, vb);\n            vround = vrndpq_f32(vmul);\n\n            vresult = vbslq_f32(vreinterpretq_u32_f32(mask), vround, vcond);\n\n            vst1q_f32(dst + i + 4, vresult);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_22_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nvoid matrix_scalar_mul_simd(const double* mat, double scalar, double* dst, size_t m, size_t n) {\n    size_t total = m * n;\n    size_t i = 0;\n\n    // Load scalar into a vector\n    float64x2_t vscalar = vdupq_n_f64(scalar);\n\n    // Process elements in chunks of 2 (vector size)\n    for (; i <= total - 2; i += 2) {\n        float64x2_t vmat = vld1q_f64(mat + i);\n        float64x2_t vresult = vmulq_f64(vmat, vscalar);\n        vst1q_f64(dst + i, vresult);\n    }\n\n    // Handle remaining elements\n    for (; i < total; ++i) {\n        dst[i] = mat[i] * scalar;\n    }\n}\n```"}
{"task_id": "SimdBench_22_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid matrix_scalar_mul_simd(const double* mat, double scalar, double* dst, size_t m, size_t n) {\n    size_t total_elements = m * n;\n    size_t i = 0;\n\n    float64x2_t vscalar = vdupq_n_f64(scalar);\n\n    for (; i <= total_elements - 2; i += 2) {\n        float64x2_t vmat = vld1q_f64(mat + i);\n        float64x2_t vresult = vmulq_f64(vmat, vscalar);\n        vst1q_f64(dst + i, vresult);\n    }\n\n    for (; i < total_elements; i++) {\n        dst[i] = mat[i] * scalar;\n    }\n}\n```"}
{"task_id": "SimdBench_22_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid matrix_scalar_mul_simd(const double* mat, double scalar, double* dst, size_t m, size_t n) {\n    size_t total = m * n;\n    size_t i = 0;\n\n    float64x2_t vscalar = vdupq_n_f64(scalar);\n\n    for (; i <= total - 2; i += 2) {\n        float64x2_t vin = vld1q_f64(mat + i);\n        float64x2_t vout = vmulq_f64(vin, vscalar);\n        vst1q_f64(dst + i, vout);\n    }\n\n    for (; i < total; ++i) {\n        dst[i] = mat[i] * scalar;\n    }\n}\n```"}
{"task_id": "SimdBench_22_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid matrix_scalar_mul_simd(const double* mat, double scalar, double* dst, size_t m, size_t n) {\n    size_t total = m * n;\n    size_t i = 0;\n\n    float64x2_t vscalar = vdupq_n_f64(scalar);\n\n    for (; i <= total - 2; i += 2) {\n        float64x2_t vmat = vld1q_f64(mat + i);\n        float64x2_t vresult = vmulq_f64(vmat, vscalar);\n        vst1q_f64(dst + i, vresult);\n    }\n\n    for (; i < total; ++i) {\n        dst[i] = mat[i] * scalar;\n    }\n}\n```"}
{"task_id": "SimdBench_22_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid matrix_scalar_mul_simd(const double* mat, double scalar, double* dst, size_t m, size_t n) {\n    size_t total = m * n;\n    size_t i = 0;\n\n    float64x2_t vscalar = vdupq_n_f64(scalar);\n\n    for (; i <= total - 2; i += 2) {\n        float64x2_t vmat = vld1q_f64(mat + i);\n        float64x2_t vresult = vmulq_f64(vmat, vscalar);\n        vst1q_f64(dst + i, vresult);\n    }\n\n    for (; i < total; i++) {\n        dst[i] = mat[i] * scalar;\n    }\n}\n```"}
{"task_id": "SimdBench_23_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid matrix_normalize_rows_simd(float* mat, size_t m, size_t n) {\n    for (size_t i = 0; i < m; ++i) {\n        float* row = &mat[i * n];\n        float32x4_t sum_vec = vdupq_n_f32(0.0f);\n        \n        // Process 4 elements at a time using SIMD\n        size_t j = 0;\n        for (; j <= n - 4; j += 4) {\n            float32x4_t vec = vld1q_f32(&row[j]);\n            float32x4_t squared = vmulq_f32(vec, vec);\n            sum_vec = vaddq_f32(sum_vec, squared);\n        }\n        \n        // Horizontal sum of the partial sums in sum_vec\n        float32x2_t sum_low = vadd_f32(vget_low_f32(sum_vec), vget_high_f32(sum_vec));\n        float32x2_t sum_all = vpadd_f32(sum_low, sum_low);\n        float sum_squares = vget_lane_f32(sum_all, 0);\n        \n        // Process remaining elements\n        for (; j < n; ++j) {\n            sum_squares += row[j] * row[j];\n        }\n        \n        // Compute L2 norm\n        float norm = sqrtf(sum_squares);\n        if (norm != 0.0f) {\n            norm = 1.0f / norm;\n        }\n        \n        float32x4_t inv_norm_vec = vdupq_n_f32(norm);\n        \n        // Normalize 4 elements at a time using SIMD\n        j = 0;\n        for (; j <= n - 4; j += 4) {\n            float32x4_t vec = vld1q_f32(&row[j]);\n            vec = vmulq_f32(vec, inv_norm_vec);\n            vst1q_f32(&row[j], vec);\n        }\n        \n        // Normalize remaining elements\n        for (; j < n; ++j) {\n            row[j] *= norm;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_23_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid matrix_normalize_rows_simd(float* mat, size_t m, size_t n) {\n    for (size_t i = 0; i < m; ++i) {\n        float* row = &mat[i * n];\n        \n        // Calculate L2 norm\n        float32x4_t sum_vec = vdupq_n_f32(0.0f);\n        size_t j = 0;\n        for (; j + 4 <= n; j += 4) {\n            float32x4_t vec = vld1q_f32(&row[j]);\n            float32x4_t squared = vmulq_f32(vec, vec);\n            sum_vec = vaddq_f32(sum_vec, squared);\n        }\n        float norm_sum = 0.0f;\n        norm_sum += vgetq_lane_f32(sum_vec, 0);\n        norm_sum += vgetq_lane_f32(sum_vec, 1);\n        norm_sum += vgetq_lane_f32(sum_vec, 2);\n        norm_sum += vgetq_lane_f32(sum_vec, 3);\n\n        for (; j < n; ++j) {\n            norm_sum += row[j] * row[j];\n        }\n\n        float norm = sqrtf(norm_sum);\n\n        if (norm != 0.0f) {\n            // Normalize row elements\n            float32x4_t norm_vec = vdupq_n_f32(1.0f / norm);\n            j = 0;\n            for (; j + 4 <= n; j += 4) {\n                float32x4_t vec = vld1q_f32(&row[j]);\n                vec = vmulq_f32(vec, norm_vec);\n                vst1q_f32(&row[j], vec);\n            }\n\n            for (; j < n; ++j) {\n                row[j] /= norm;\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_23_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid matrix_normalize_rows_simd(float* mat, size_t m, size_t n) {\n    for (size_t i = 0; i < m; ++i) {\n        float* row = &mat[i * n];\n        \n        // Calculate L2 norm\n        float32x4_t sum_vec = vdupq_n_f32(0.0f);\n        size_t j = 0;\n        for (; j + 4 <= n; j += 4) {\n            float32x4_t vec = vld1q_f32(&row[j]);\n            float32x4_t squared = vmulq_f32(vec, vec);\n            sum_vec = vaddq_f32(sum_vec, squared);\n        }\n        float l2_norm_squared = 0.0f;\n        l2_norm_squared += vgetq_lane_f32(sum_vec, 0);\n        l2_norm_squared += vgetq_lane_f32(sum_vec, 1);\n        l2_norm_squared += vgetq_lane_f32(sum_vec, 2);\n        l2_norm_squared += vgetq_lane_f32(sum_vec, 3);\n        \n        for (; j < n; ++j) {\n            l2_norm_squared += row[j] * row[j];\n        }\n        \n        float l2_norm = sqrtf(l2_norm_squared);\n        \n        if (l2_norm != 0.0f) {\n            float32x4_t inv_norm = vdupq_n_f32(1.0f / l2_norm);\n            j = 0;\n            for (; j + 4 <= n; j += 4) {\n                float32x4_t vec = vld1q_f32(&row[j]);\n                float32x4_t normalized = vmulq_f32(vec, inv_norm);\n                vst1q_f32(&row[j], normalized);\n            }\n            for (; j < n; ++j) {\n                row[j] /= l2_norm;\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_23_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid matrix_normalize_rows_simd(float* mat, size_t m, size_t n) {\n    for (size_t i = 0; i < m; ++i) {\n        float* row = &mat[i * n];\n        float32x4_t sum_vec = vdupq_n_f32(0.0f);\n\n        // Compute sum of squares using SIMD\n        for (size_t j = 0; j < n / 4 * 4; j += 4) {\n            float32x4_t vec = vld1q_f32(&row[j]);\n            float32x4_t mul = vmulq_f32(vec, vec);\n            sum_vec = vaddq_f32(sum_vec, mul);\n        }\n\n        float sum = 0.0f;\n        sum += vgetq_lane_f32(sum_vec, 0);\n        sum += vgetq_lane_f32(sum_vec, 1);\n        sum += vgetq_lane_f32(sum_vec, 2);\n        sum += vgetq_lane_f32(sum_vec, 3);\n\n        // Handle remaining elements\n        for (size_t j = n / 4 * 4; j < n; ++j) {\n            sum += row[j] * row[j];\n        }\n\n        float norm = sqrtf(sum);\n\n        if (norm > 1e-6f) {\n            float reciprocal_norm = 1.0f / norm;\n\n            // Normalize using SIMD\n            for (size_t j = 0; j < n / 4 * 4; j += 4) {\n                float32x4_t vec = vld1q_f32(&row[j]);\n                float32x4_t recip = vdupq_n_f32(reciprocal_norm);\n                float32x4_t result = vmulq_f32(vec, recip);\n                vst1q_f32(&row[j], result);\n            }\n\n            // Handle remaining elements\n            for (size_t j = n / 4 * 4; j < n; ++j) {\n                row[j] *= reciprocal_norm;\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_23_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid matrix_normalize_rows_simd(float* mat, size_t m, size_t n) {\n    for (size_t i = 0; i < m; ++i) {\n        float* row = &mat[i * n];\n        \n        // Calculate L2 norm\n        float32x4_t sum_vec = vdupq_n_f32(0.0f);\n        size_t j = 0;\n        for (; j + 4 <= n; j += 4) {\n            float32x4_t vec = vld1q_f32(&row[j]);\n            float32x4_t squared = vmulq_f32(vec, vec);\n            sum_vec = vaddq_f32(sum_vec, squared);\n        }\n        float l2_norm_accum = 0.0f;\n        float32x2_t sum_low = vadd_f32(vget_low_f32(sum_vec), vget_high_f32(sum_vec));\n        l2_norm_accum += vget_lane_f32(sum_low, 0) + vget_lane_f32(sum_low, 1);\n        \n        // Handle leftover elements\n        for (; j < n; ++j) {\n            l2_norm_accum += row[j] * row[j];\n        }\n        \n        float l2_norm = sqrtf(l2_norm_accum);\n        \n        // Normalize the row\n        if (l2_norm > 1e-6f) {\n            float32x4_t inv_norm = vdupq_n_f32(1.0f / l2_norm);\n            j = 0;\n            for (; j + 4 <= n; j += 4) {\n                float32x4_t vec = vld1q_f32(&row[j]);\n                vec = vmulq_f32(vec, inv_norm);\n                vst1q_f32(&row[j], vec);\n            }\n            for (; j < n; ++j) {\n                row[j] /= l2_norm;\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_24_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid matrix_mul_round_int_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n, size_t p) {\n    for (size_t i = 0; i < m; ++i) {\n        for (size_t j = 0; j < p; ++j) {\n            float64x2_t sum_vec = vdupq_n_f64(0.0);\n            size_t k = 0;\n\n            for (; k <= n - 2; k += 2) {\n                float64x2_t vec_mat1 = vld1q_f64(&mat1[i * n + k]);\n                float64x2_t vec_mat2 = vld1q_f64(&mat2[k * p + j]);\n                sum_vec = vmlaq_f64(sum_vec, vec_mat1, vec_mat2);\n            }\n\n            double sum = vaddvq_f64(sum_vec);\n\n            for (; k < n; ++k) {\n                sum += mat1[i * n + k] * mat2[k * p + j];\n            }\n\n            dst[i * p + j] = nearbyint(sum);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_24_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid matrix_mul_round_int_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n, size_t p) {\n    for (size_t i = 0; i < m; ++i) {\n        for (size_t j = 0; j < p; ++j) {\n            float64x2_t acc_vec = vdupq_n_f64(0.0);\n            size_t k = 0;\n\n            for (; k <= n - 2; k += 2) {\n                float64x2_t vec_mat1 = vld1q_f64(&mat1[i * n + k]);\n                float64x2_t vec_mat2 = vld1q_f64(&mat2[k * p + j]);\n                acc_vec = vmlaq_f64(acc_vec, vec_mat1, vec_mat2);\n            }\n\n            double acc = vgetq_lane_f64(acc_vec, 0) + vgetq_lane_f64(acc_vec, 1);\n\n            for (; k < n; ++k) {\n                acc += mat1[i * n + k] * mat2[k * p + j];\n            }\n\n            dst[i * p + j] = nearbyint(acc);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_24_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid matrix_mul_round_int_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n, size_t p) {\n    for (size_t i = 0; i < m; ++i) {\n        for (size_t k = 0; k < p; ++k) {\n            float64x2_t sum_vec = vdupq_n_f64(0.0);\n            size_t j = 0;\n\n            for (; j <= n - 2; j += 2) {\n                float64x2_t vec_a = vld1q_f64(&mat1[i * n + j]);\n                float64x2_t vec_b = vld1q_f64(&mat2[j * p + k]);\n                sum_vec = vmlaq_f64(sum_vec, vec_a, vec_b);\n            }\n\n            double sum = vaddvq_f64(sum_vec);\n\n            for (; j < n; ++j) {\n                sum += mat1[i * n + j] * mat2[j * p + k];\n            }\n\n            dst[i * p + k] = nearbyint(sum);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_24_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid matrix_mul_round_int_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n, size_t p) {\n    for (size_t i = 0; i < m; ++i) {\n        for (size_t j = 0; j < p; ++j) {\n            double vres[2] = {0.0, 0.0};\n            for (size_t k = 0; k < n; k += 2) {\n                float64x2_t va = vld1q_f64(&mat1[i * n + k]);\n                float64x2_t vb = vld1q_f64(&mat2[k * p + j]);\n                float64x2_t vc = vmulq_f64(va, vb);\n                vres[0] += vc[0];\n                vres[1] += vc[1];\n            }\n            if (n % 2 != 0) {\n                size_t k = n - 1;\n                vres[0] += mat1[i * n + k] * mat2[k * p + j];\n            }\n            float64x2_t vr = vsetq_lane_f64(vres[0], vdupq_n_f64(0), 0);\n            vr = vsetq_lane_f64(vres[1], vr, 1);\n            int64x2_t vi = vcvtq_s64_f64(vr);\n            int64x2_t rounded = vrndq_n_s64(vi);\n            float64x2_t result = vcvtq_f64_s64(rounded);\n            dst[i * p + j] = result[0];\n            if (j + 1 < p) {\n                dst[i * p + j + 1] = result[1];\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_24_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid matrix_mul_round_int_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n, size_t p) {\n    for (size_t i = 0; i < m; ++i) {\n        for (size_t k = 0; k < p; k += 2) {\n            float64x2_t sum_vec = vdupq_n_f64(0.0);\n            \n            for (size_t j = 0; j < n; j += 2) {\n                float64x2_t vec_a = vld1q_f64(&mat1[i * n + j]);\n                float64x2_t vec_b = vld1q_f64(&mat2[j * p + k]);\n                sum_vec = vmlaq_f64(sum_vec, vec_a, vec_b);\n            }\n            \n            float64x2_t rounded_sum = vrndnq_f64(sum_vec);\n            vst1q_f64(&dst[i * p + k], rounded_sum);\n        }\n        \n        if (p % 2 == 1) {\n            double sum = 0.0;\n            for (size_t j = 0; j < n; ++j) {\n                sum += mat1[i * n + j] * mat2[j * p + p - 1];\n            }\n            dst[i * p + p - 1] = round(sum);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_25_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid matrix_transpose_round_quarter_simd(const float* src, float* dst, size_t rows, size_t cols) {\n    if (rows == cols && rows % 4 == 0) {\n        size_t i, j;\n        for(i = 0; i < rows; i += 4){\n            for(j = 0; j < cols; j += 4){\n                float32x4_t row0 = vld1q_f32(&src[i * cols + j]);\n                float32x4_t row1 = vld1q_f32(&src[(i+1) * cols + j]);\n                float32x4_t row2 = vld1q_f32(&src[(i+2) * cols + j]);\n                float32x4_t row3 = vld1q_f32(&src[(i+3) * cols + j]);\n\n                float32x4x4_t transposed = vtrnq_f32(row0, row1, row2, row3);\n\n                float32x4_t mult = vmulq_n_f32(transposed.val[0], 4.0f);\n                int32x4_t rounded = vrndq_n_s32(vcvtaq_s32_f32(mult));\n                float32x4_t result0 = vcvtq_f32_s32(rounded);\n                result0 = vmulq_n_f32(result0, 0.25f);\n\n                mult = vmulq_n_f32(transposed.val[1], 4.0f);\n                rounded = vrndq_n_s32(vcvtaq_s32_f32(mult));\n                float32x4_t result1 = vcvtq_f32_s32(rounded);\n                result1 = vmulq_n_f32(result1, 0.25f);\n\n                mult = vmulq_n_f32(transposed.val[2], 4.0f);\n                rounded = vrndq_n_s32(vcvtaq_s32_f32(mult));\n                float32x4_t result2 = vcvtq_f32_s32(rounded);\n                result2 = vmulq_n_f32(result2, 0.25f);\n\n                mult = vmulq_n_f32(transposed.val[3], 4.0f);\n                rounded = vrndq_n_s32(vcvtaq_s32_f32(mult));\n                float32x4_t result3 = vcvtq_f32_s32(rounded);\n                result3 = vmulq_n_f32(result3, 0.25f);\n\n                vst1q_f32(&dst[j * rows + i], result0);\n                vst1q_f32(&dst[(j+1) * rows + i], result1);\n                vst1q_f32(&dst[(j+2) * rows + i], result2);\n                vst1q_f32(&dst[(j+3) * rows + i], result3);\n            }\n        }\n    } else {\n        // Fallback to scalar implementation for non-square or unaligned matrices\n        for(size_t r = 0; r < rows; ++r){\n            for(size_t c = 0; c < cols; ++c){\n                float val = src[r * cols + c];\n                val = roundf(val * 4.0f) * 0.25f;\n                dst[c * rows + r] = val;\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_25_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid matrix_transpose_round_quarter_simd(const float* src, float* dst, size_t rows, size_t cols) {\n    if (rows == cols && rows % 4 == 0) {\n        size_t i, j;\n        for(i = 0; i < rows; i += 4){\n            for(j = 0; j < cols; j += 4){\n                float32x4x4_t vsrc = vld4q_f32(&src[(i * cols) + j]);\n                float32x4x4_t vdst;\n\n                vdst.val[0] = vtrnq_f32(vsrc.val[0], vsrc.val[1]).val[0];\n                vdst.val[1] = vtrnq_f32(vsrc.val[0], vsrc.val[1]).val[1];\n                vdst.val[2] = vtrnq_f32(vsrc.val[2], vsrc.val[3]).val[0];\n                vdst.val[3] = vtrnq_f32(vsrc.val[2], vsrc.val[3]).val[1];\n\n                vdst.val[0] = vzipq_f32(vdst.val[0], vdst.val[2]).val[0];\n                vdst.val[1] = vzipq_f32(vdst.val[0], vdst.val[2]).val[1];\n                vdst.val[2] = vzipq_f32(vdst.val[1], vdst.val[3]).val[0];\n                vdst.val[3] = vzipq_f32(vdst.val[1], vdst.val[3]).val[1];\n\n                float32x4_t mult = vmulq_n_f32(vdst.val[0], 4.0f);\n                float32x4_t round = vrndnq_f32(mult);\n                float32x4_t result = vmulq_n_f32(round, 0.25f);\n\n                vst1q_f32(&dst[(j * rows) + i], result);\n\n                result = vmulq_n_f32(vrndnq_f32(vmulq_n_f32(vdst.val[1], 4.0f)), 0.25f);\n                vst1q_f32(&dst[((j + 1) * rows) + i], result);\n\n                result = vmulq_n_f32(vrndnq_f32(vmulq_n_f32(vdst.val[2], 4.0f)), 0.25f);\n                vst1q_f32(&dst[((j + 2) * rows) + i], result);\n\n                result = vmulq_n_f32(vrndnq_f32(vmulq_n_f32(vdst.val[3], 4.0f)), 0.25f);\n                vst1q_f32(&dst[((j + 3) * rows) + i], result);\n            }\n        }\n    } else {\n        // Fallback to scalar implementation or handle non-square matrices here.\n    }\n}\n```"}
{"task_id": "SimdBench_25_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid matrix_transpose_round_quarter_simd(const float* src, float* dst, size_t rows, size_t cols) {\n    float32x4_t vquarter = vdupq_n_f32(0.25f);\n    \n    for (size_t i = 0; i < rows; i += 4) {\n        for (size_t j = 0; j < cols; j += 4) {\n            float32x4_t row0 = vld1q_f32(src + i * cols + j);\n            float32x4_t row1 = vld1q_f32(src + (i + 1) * cols + j);\n            float32x4_t row2 = vld1q_f32(src + (i + 2) * cols + j);\n            float32x4_t row3 = vld1q_f32(src + (i + 3) * cols + j);\n\n            float32x4x4_t transposed = vzipq_f32(vzipq_f32(row0, row1).val[0], vzipq_f32(row2, row3).val[0]);\n\n            float32x4_t col0 = transposed.val[0];\n            float32x4_t col1 = transposed.val[1];\n            float32x4_t col2 = transposed.val[2];\n            float32x4_t col3 = transposed.val[3];\n\n            col0 = vrndq_n_f32(vmulq_f32(col0, vquarter));\n            col1 = vrndq_n_f32(vmulq_f32(col1, vquarter));\n            col2 = vrndq_n_f32(vmulq_f32(col2, vquarter));\n            col3 = vrndq_n_f32(vmulq_f32(col3, vquarter));\n\n            vst1q_f32(dst + j * rows + i, col0);\n            vst1q_f32(dst + (j + 1) * rows + i, col1);\n            vst1q_f32(dst + (j + 2) * rows + i, col2);\n            vst1q_f32(dst + (j + 3) * rows + i, col3);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_25_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid matrix_transpose_round_quarter_simd(const float* src, float* dst, size_t rows, size_t cols) {\n    if (rows == cols && rows % 4 == 0) {\n        size_t i, j;\n        for (i = 0; i < rows; i += 4) {\n            for (j = 0; j < cols; j += 4) {\n                float32x4x4_t src_vecs;\n                src_vecs.val[0] = vld1q_f32(&src[i * cols + j]);\n                src_vecs.val[1] = vld1q_f32(&src[(i + 1) * cols + j]);\n                src_vecs.val[2] = vld1q_f32(&src[(i + 2) * cols + j]);\n                src_vecs.val[3] = vld1q_f32(&src[(i + 3) * cols + j]);\n\n                float32x4x4_t transposed = vtrnq_f32(src_vecs.val[0], src_vecs.val[1]);\n                float32x4x4_t transposed2 = vtrnq_f32(src_vecs.val[2], src_vecs.val[3]);\n\n                transposed = vtrnq_f32(transposed.val[0], transposed2.val[0]);\n                transposed2 = vtrnq_f32(transposed.val[1], transposed2.val[1]);\n\n                float32x4_t factor = vmulq_n_f32(vdupq_n_f32(4.0f), vcvtq_f32_s32(vcvtq_s32_f32(vmulq_n_f32(transposed.val[0], vdupq_n_f32(0.25f)))));\n                vst1q_f32(&dst[j * cols + i], factor);\n\n                factor = vmulq_n_f32(vdupq_n_f32(4.0f), vcvtq_f32_s32(vcvtq_s32_f32(vmulq_n_f32(transposed.val[1], vdupq_n_f32(0.25f)))));\n                vst1q_f32(&dst[(j + 1) * cols + i], factor);\n\n                factor = vmulq_n_f32(vdupq_n_f32(4.0f), vcvtq_f32_s32(vcvtq_s32_f32(vmulq_n_f32(transposed2.val[0], vdupq_n_f32(0.25f)))));\n                vst1q_f32(&dst[(j + 2) * cols + i], factor);\n\n                factor = vmulq_n_f32(vdupq_n_f32(4.0f), vcvtq_f32_s32(vcvtq_s32_f32(vmulq_n_f32(transposed2.val[1], vdupq_n_f32(0.25f)))));\n                vst1q_f32(&dst[(j + 3) * cols + i], factor);\n            }\n        }\n    } else {\n        // Fallback to scalar implementation or handle non-square matrices here\n    }\n}\n```"}
{"task_id": "SimdBench_25_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid matrix_transpose_round_quarter_simd(const float* src, float* dst, size_t rows, size_t cols) {\n    if (rows == cols && rows % 4 == 0) {\n        size_t i, j;\n        float32x4_t vzero = vmovq_n_f32(0.0f);\n        float32x4_t vmul = vmovq_n_f32(4.0f);\n        float32x4_t vdiv = vmovq_n_f32(0.25f);\n\n        for (i = 0; i < rows; i += 4) {\n            float32x4x4_t transposed = {{vzero, vzero, vzero, vzero}};\n\n            for (j = 0; j < cols; j += 4) {\n                float32x4x4_t block;\n\n                block.val[0] = vld1q_f32(src + i * cols + j);\n                block.val[1] = vld1q_f32(src + (i + 1) * cols + j);\n                block.val[2] = vld1q_f32(src + (i + 2) * cols + j);\n                block.val[3] = vld1q_f32(src + (i + 3) * cols + j);\n\n                float32x4x4_t trans_block = vtrnq_f32(block.val[0], block.val[1]);\n                float32x4x4_t trans_block2 = vtrnq_f32(block.val[2], block.val[3]);\n\n                trans_block = vtrnq_f32(trans_block.val[0], trans_block2.val[0]);\n                trans_block2 = vtrnq_f32(trans_block.val[1], trans_block2.val[1]);\n\n                transposed.val[0] = vaddq_f32(transposed.val[0], trans_block.val[0]);\n                transposed.val[1] = vaddq_f32(transposed.val[1], trans_block.val[1]);\n                transposed.val[2] = vaddq_f32(transposed.val[2], trans_block2.val[0]);\n                transposed.val[3] = vaddq_f32(transposed.val[3], trans_block2.val[1]);\n            }\n\n            transposed.val[0] = vmulq_f32(transposed.val[0], vmul);\n            transposed.val[1] = vmulq_f32(transposed.val[1], vmul);\n            transposed.val[2] = vmulq_f32(transposed.val[2], vmul);\n            transposed.val[3] = vmulq_f32(transposed.val[3], vmul);\n\n            transposed.val[0] = vcvtq_f32_s32(vrndq_s32_f32(transposed.val[0]));\n            transposed.val[1] = vcvtq_f32_s32(vrndq_s32_f32(transposed.val[1]));\n            transposed.val[2] = vcvtq_f32_s32(vrndq_s32_f32(transposed.val[2]));\n            transposed.val[3] = vcvtq_f32_s32(vrndq_s32_f32(transposed.val[3]));\n\n            transposed.val[0] = vmulq_f32(transposed.val[0], vdiv);\n            transposed.val[1] = vmulq_f32(transposed.val[1], vdiv);\n            transposed.val[2] = vmulq_f32(transposed.val[2], vdiv);\n            transposed.val[3] = vmulq_f32(transposed.val[3], vdiv);\n\n            vst1q_f32(dst + i + 0 * rows, transposed.val[0]);\n            vst1q_f32(dst + i + 1 * rows, transposed.val[1]);\n            vst1q_f32(dst + i + 2 * rows, transposed.val[2]);\n            vst1q_f32(dst + i + 3 * rows, transposed.val[3]);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_26_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nvoid tensor3d_sub_round_zero_simd(const float* tensor1, const float* tensor2, float* dst, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_size = dim1 * dim2 * dim3;\n    size_t i = 0;\n\n    // Process 4 elements at a time using SIMD\n    for (; i <= total_size - 4; i += 4) {\n        float32x4_t v1 = vld1q_f32(tensor1 + i);\n        float32x4_t v2 = vld1q_f32(tensor2 + i);\n        float32x4_t res = vsubq_f32(v1, v2);\n        int32x4_t rounded = vrndq_z_s32(vcvtq_s32_f32(res));\n        vst1q_f32(dst + i, vcvtq_f32_s32(rounded));\n    }\n\n    // Handle remaining elements\n    for (; i < total_size; ++i) {\n        dst[i] = static_cast<int>(tensor1[i] - tensor2[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_26_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid tensor3d_sub_round_zero_simd(const float* tensor1, const float* tensor2, float* dst, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_size = dim1 * dim2 * dim3;\n    size_t i = 0;\n\n    for (; i <= total_size - 16; i += 16) {\n        float32x4_t t1_0 = vld1q_f32(tensor1 + i);\n        float32x4_t t1_1 = vld1q_f32(tensor1 + i + 4);\n        float32x4_t t1_2 = vld1q_f32(tensor1 + i + 8);\n        float32x4_t t1_3 = vld1q_f32(tensor1 + i + 12);\n\n        float32x4_t t2_0 = vld1q_f32(tensor2 + i);\n        float32x4_t t2_1 = vld1q_f32(tensor2 + i + 4);\n        float32x4_t t2_2 = vld1q_f32(tensor2 + i + 8);\n        float32x4_t t2_3 = vld1q_f32(tensor2 + i + 12);\n\n        float32x4_t res_0 = vrndq_f32(vsubq_f32(t1_0, t2_0));\n        float32x4_t res_1 = vrndq_f32(vsubq_f32(t1_1, t2_1));\n        float32x4_t res_2 = vrndq_f32(vsubq_f32(t1_2, t2_2));\n        float32x4_t res_3 = vrndq_f32(vsubq_f32(t1_3, t2_3));\n\n        vst1q_f32(dst + i, res_0);\n        vst1q_f32(dst + i + 4, res_1);\n        vst1q_f32(dst + i + 8, res_2);\n        vst1q_f32(dst + i + 12, res_3);\n    }\n\n    for (; i < total_size; i++) {\n        dst[i] = (float)((int)(tensor1[i] - tensor2[i]));\n    }\n}\n```"}
{"task_id": "SimdBench_26_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nvoid tensor3d_sub_round_zero_simd(const float* tensor1, const float* tensor2, float* dst, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_size = dim1 * dim2 * dim3;\n    size_t i = 0;\n\n    // Process 4 elements at a time using SIMD\n    for (; i <= total_size - 4; i += 4) {\n        float32x4_t v1 = vld1q_f32(tensor1 + i);\n        float32x4_t v2 = vld1q_f32(tensor2 + i);\n        float32x4_t res = vsubq_f32(v1, v2);\n        int32x4_t rounded = vrndq_z_s32 vcvtq_s32_f32(res);\n        vst1q_f32(dst + i, vcvtq_f32_s32(rounded));\n    }\n\n    // Handle remaining elements\n    for (; i < total_size; ++i) {\n        dst[i] = (float)((int)(tensor1[i] - tensor2[i]));\n    }\n}\n```"}
{"task_id": "SimdBench_26_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid tensor3d_sub_round_zero_simd(const float* tensor1, const float* tensor2, float* dst, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_size = dim1 * dim2 * dim3;\n    size_t i = 0;\n\n    float32x4_t vzero = vdupq_n_f32(0.0f);\n\n    for (; i <= total_size - 4; i += 4) {\n        float32x4_t vt1 = vld1q_f32(tensor1 + i);\n        float32x4_t vt2 = vld1q_f32(tensor2 + i);\n\n        float32x4_t vdiff = vsubq_f32(vt1, vt2);\n        int32x4_t vint = vcvtq_s32_f32(vdiff); // Truncate towards zero\n\n        float32x4_t vresult = vcvtq_f32_s32(vint);\n        vst1q_f32(dst + i, vresult);\n    }\n\n    for (; i < total_size; ++i) {\n        dst[i] = (float)((int)(tensor1[i] - tensor2[i]));\n    }\n}\n```"}
{"task_id": "SimdBench_26_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid tensor3d_sub_round_zero_simd(const float* tensor1, const float* tensor2, float* dst, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_size = dim1 * dim2 * dim3;\n    size_t i = 0;\n\n    // Process 4 elements at a time using SIMD\n    for (; i <= total_size - 4; i += 4) {\n        float32x4_t v_tensor1 = vld1q_f32(&tensor1[i]);\n        float32x4_t v_tensor2 = vld1q_f32(&tensor2[i]);\n        \n        float32x4_t v_diff = vsubq_f32(v_tensor1, v_tensor2);\n        int32x4_t v_diff_int = vcvtq_s32_f32(v_diff); // Convert to int, truncating towards zero\n        float32x4_t v_result = vcvtq_f32_s32(v_diff_int); // Convert back to float\n\n        vst1q_f32(&dst[i], v_result);\n    }\n\n    // Handle remaining elements\n    for (; i < total_size; i++) {\n        dst[i] = (float)((int)(tensor1[i] - tensor2[i]));\n    }\n}\n```"}
{"task_id": "SimdBench_27_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid matrix_hadamard_product_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n) {\n    size_t total_elements = m * n;\n    size_t i = 0;\n\n    // Process 2 elements at a time using SIMD\n    for (; i <= total_elements - 2; i += 2) {\n        uint64x2_t vmat1 = vld1q_u64((uint64_t*)&mat1[i]);\n        uint64x2_t vmat2 = vld1q_u64((uint64_t*)&mat2[i]);\n        \n        uint64x2_t result = vmulq_u64(vmat1, vmat2);\n        \n        vst1q_u64((uint64_t*)&dst[i], result);\n    }\n\n    // Handle any remaining elements\n    for (; i < total_elements; ++i) {\n        dst[i] = mat1[i] * mat2[i];\n    }\n}\n```"}
{"task_id": "SimdBench_27_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid matrix_hadamard_product_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n) {\n    size_t total_elements = m * n;\n    size_t i = 0;\n\n    // Process 2 elements at a time using SIMD\n    for (; i <= total_elements - 2; i += 2) {\n        float64x2_t vec1 = vld1q_f64(&mat1[i]);\n        float64x2_t vec2 = vld1q_f64(&mat2[i]);\n        float64x2_t result = vmulq_f64(vec1, vec2);\n        vst1q_f64(&dst[i], result);\n    }\n\n    // Handle any remaining elements\n    for (; i < total_elements; i++) {\n        dst[i] = mat1[i] * mat2[i];\n    }\n}\n```"}
{"task_id": "SimdBench_27_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid matrix_hadamard_product_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n) {\n    size_t total_elements = m * n;\n    size_t i = 0;\n\n    // Process elements in batches of 2 (since a double is 64-bit and a 128-bit Neon register can hold 2 doubles)\n    for (; i <= total_elements - 2; i += 2) {\n        uint64x2_t v1 = vld1q_u64((uint64_t*)&mat1[i]);\n        uint64x2_t v2 = vld1q_u64((uint64_t*)&mat2[i]);\n        \n        float64x2_t fv1 = vreinterpretq_f64_u64(v1);\n        float64x2_t fv2 = vreinterpretq_f64_u64(v2);\n        \n        float64x2_t result = vmulq_f64(fv1, fv2);\n        uint64x2_t uresult = vreinterpretq_u64_f64(result);\n\n        vst1q_u64((uint64_t*)&dst[i], uresult);\n    }\n\n    // Handle any remaining elements (if total_elements is odd)\n    for (; i < total_elements; ++i) {\n        dst[i] = mat1[i] * mat2[i];\n    }\n}\n```"}
{"task_id": "SimdBench_27_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid matrix_hadamard_product_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n) {\n    size_t total_elements = m * n;\n    size_t i = 0;\n\n    // Process elements in batches of 2 (since a double is 64-bit and a 128-bit Neon register can hold 2 doubles)\n    for (; i <= total_elements - 2; i += 2) {\n        float64x2_t vec1 = vld1q_f64(&mat1[i]);\n        float64x2_t vec2 = vld1q_f64(&mat2[i]);\n        float64x2_t result = vmulq_f64(vec1, vec2);\n        vst1q_f64(&dst[i], result);\n    }\n\n    // Handle any remaining elements\n    for (; i < total_elements; ++i) {\n        dst[i] = mat1[i] * mat2[i];\n    }\n}\n```"}
{"task_id": "SimdBench_27_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid matrix_hadamard_product_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n) {\n    size_t total_elements = m * n;\n    size_t i = 0;\n\n    // Process 2 elements at a time using SIMD\n    for (; i <= total_elements - 2; i += 2) {\n        float64x2_t vec1 = vld1q_f64((const float64_t*)&mat1[i]);\n        float64x2_t vec2 = vld1q_f64((const float64_t*)&mat2[i]);\n        float64x2_t result = vmulq_f64(vec1, vec2);\n        vst1q_f64((float64_t*)&dst[i], result);\n    }\n\n    // Handle any remaining elements (if the total is odd)\n    for (; i < total_elements; i++) {\n        dst[i] = mat1[i] * mat2[i];\n    }\n}\n```"}
{"task_id": "SimdBench_28_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid matrix_vector_mul_simd(const float* mat, const float* vec, float* dst, size_t m, size_t n) {\n    for (size_t i = 0; i < m; ++i) {\n        float32x4_t acc0 = vdupq_n_f32(0.0f);\n        float32x4_t acc1 = vdupq_n_f32(0.0f);\n        float32x4_t acc2 = vdupq_n_f32(0.0f);\n        float32x4_t acc3 = vdupq_n_f32(0.0f);\n\n        for (size_t j = 0; j < n; j += 16) {\n            float32x4_t v0 = vld1q_f32(vec + j + 0);\n            float32x4_t v1 = vld1q_f32(vec + j + 4);\n            float32x4_t v2 = vld1q_f32(vec + j + 8);\n            float32x4_t v3 = vld1q_f32(vec + j + 12);\n\n            float32x4_t m0 = vld1q_f32(mat + i * n + j + 0);\n            float32x4_t m1 = vld1q_f32(mat + i * n + j + 4);\n            float32x4_t m2 = vld1q_f32(mat + i * n + j + 8);\n            float32x4_t m3 = vld1q_f32(mat + i * n + j + 12);\n\n            acc0 = vmlaq_f32(acc0, m0, v0);\n            acc1 = vmlaq_f32(acc1, m1, v1);\n            acc2 = vmlaq_f32(acc2, m2, v2);\n            acc3 = vmlaq_f32(acc3, m3, v3);\n        }\n\n        float32x4_t sum1 = vaddq_f32(acc0, acc1);\n        float32x4_t sum2 = vaddq_f32(acc2, acc3);\n        float32x4_t sum = vaddq_f32(sum1, sum2);\n\n        float result[4];\n        vst1q_f32(result, sum);\n\n        dst[i] = result[0] + result[1] + result[2] + result[3];\n\n        for (size_t j = (n / 16) * 16; j < n; ++j) {\n            dst[i] += mat[i * n + j] * vec[j];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_28_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid matrix_vector_mul_simd(const float* mat, const float* vec, float* dst, size_t m, size_t n) {\n    for (size_t i = 0; i < m; ++i) {\n        float32x4_t acc0 = vdupq_n_f32(0.0f);\n        float32x4_t acc1 = vdupq_n_f32(0.0f);\n        float32x4_t acc2 = vdupq_n_f32(0.0f);\n        float32x4_t acc3 = vdupq_n_f32(0.0f);\n\n        for (size_t j = 0; j < n; j += 16) {\n            float32x4_t v0 = vld1q_f32(vec + j + 0);\n            float32x4_t v1 = vld1q_f32(vec + j + 4);\n            float32x4_t v2 = vld1q_f32(vec + j + 8);\n            float32x4_t v3 = vld1q_f32(vec + j + 12);\n\n            float32x4_t m0 = vld1q_f32(mat + i * n + j + 0);\n            float32x4_t m1 = vld1q_f32(mat + i * n + j + 4);\n            float32x4_t m2 = vld1q_f32(mat + i * n + j + 8);\n            float32x4_t m3 = vld1q_f32(mat + i * n + j + 12);\n\n            acc0 = vmlaq_f32(acc0, m0, v0);\n            acc1 = vmlaq_f32(acc1, m1, v1);\n            acc2 = vmlaq_f32(acc2, m2, v2);\n            acc3 = vmlaq_f32(acc3, m3, v3);\n        }\n\n        float32x4_t sum1 = vaddq_f32(acc0, acc1);\n        float32x4_t sum2 = vaddq_f32(acc2, acc3);\n        float32x4_t sum = vaddq_f32(sum1, sum2);\n\n        float total = vgetq_lane_f32(sum, 0) +\n                     vgetq_lane_f32(sum, 1) +\n                     vgetq_lane_f32(sum, 2) +\n                     vgetq_lane_f32(sum, 3);\n\n        for (size_t j = (n / 16) * 16; j < n; ++j) {\n            total += mat[i * n + j] * vec[j];\n        }\n\n        dst[i] = total;\n    }\n}\n```"}
{"task_id": "SimdBench_28_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid matrix_vector_mul_simd(const float* mat, const float* vec, float* dst, size_t m, size_t n) {\n    for (size_t i = 0; i < m; ++i) {\n        float32x4_t sum = vdupq_n_f32(0.0f);\n        size_t j = 0;\n\n        for (; j <= n - 4; j += 4) {\n            float32x4_t v = vld1q_f32(vec + j);\n            float32x4_t m_v = vld1q_f32(mat + i * n + j);\n            sum = vmlaq_f32(sum, m_v, v);\n        }\n\n        float acc[4] = {0};\n        vst1q_f32(acc, sum);\n        float result = acc[0] + acc[1] + acc[2] + acc[3];\n\n        for (; j < n; ++j) {\n            result += mat[i * n + j] * vec[j];\n        }\n\n        dst[i] = result;\n    }\n}\n```"}
{"task_id": "SimdBench_28_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid matrix_vector_mul_simd(const float* mat, const float* vec, float* dst, size_t m, size_t n) {\n    for (size_t i = 0; i < m; ++i) {\n        float32x4_t acc0 = vdupq_n_f32(0.0f);\n        float32x4_t acc1 = vdupq_n_f32(0.0f);\n        float32x4_t acc2 = vdupq_n_f32(0.0f);\n        float32x4_t acc3 = vdupq_n_f32(0.0f);\n\n        for (size_t j = 0; j < n; j += 16) {\n            float32x4_t v0 = vld1q_f32(vec + j + 0);\n            float32x4_t v1 = vld1q_f32(vec + j + 4);\n            float32x4_t v2 = vld1q_f32(vec + j + 8);\n            float32x4_t v3 = vld1q_f32(vec + j + 12);\n\n            float32x4_t m0 = vld1q_f32(mat + i * n + j + 0);\n            float32x4_t m1 = vld1q_f32(mat + i * n + j + 4);\n            float32x4_t m2 = vld1q_f32(mat + i * n + j + 8);\n            float32x4_t m3 = vld1q_f32(mat + i * n + j + 12);\n\n            acc0 = vmlaq_f32(acc0, m0, v0);\n            acc1 = vmlaq_f32(acc1, m1, v1);\n            acc2 = vmlaq_f32(acc2, m2, v2);\n            acc3 = vmlaq_f32(acc3, m3, v3);\n        }\n\n        float32x4_t sum1 = vaddq_f32(acc0, acc1);\n        float32x4_t sum2 = vaddq_f32(acc2, acc3);\n        float32x4_t sum = vaddq_f32(sum1, sum2);\n\n        float32x2_t sum_low = vadd_f32(vget_low_f32(sum), vget_high_f32(sum));\n        float32x2_t sum_final = vpadd_f32(sum_low, sum_low);\n\n        dst[i] = sum_final[0];\n\n        // Handle remaining elements if n is not a multiple of 16\n        size_t j = (n / 16) * 16;\n        float result = 0.0f;\n        for (; j < n; ++j) {\n            result += mat[i * n + j] * vec[j];\n        }\n        dst[i] += result;\n    }\n}\n```"}
{"task_id": "SimdBench_28_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid matrix_vector_mul_simd(const float* mat, const float* vec, float* dst, size_t m, size_t n) {\n    for (size_t i = 0; i < m; ++i) {\n        float32x4_t acc0 = vdupq_n_f32(0.0f);\n        float32x4_t acc1 = vdupq_n_f32(0.0f);\n        float32x4_t acc2 = vdupq_n_f32(0.0f);\n        float32x4_t acc3 = vdupq_n_f32(0.0f);\n\n        for (size_t j = 0; j < n; j += 16) {\n            float32x4_t v_vec_0 = vld1q_f32(vec + j + 0);\n            float32x4_t v_vec_1 = vld1q_f32(vec + j + 4);\n            float32x4_t v_vec_2 = vld1q_f32(vec + j + 8);\n            float32x4_t v_vec_3 = vld1q_f32(vec + j + 12);\n\n            float32x4_t v_mat_0 = vld1q_f32(mat + i * n + j + 0);\n            float32x4_t v_mat_1 = vld1q_f32(mat + i * n + j + 4);\n            float32x4_t v_mat_2 = vld1q_f32(mat + i * n + j + 8);\n            float32x4_t v_mat_3 = vld1q_f32(mat + i * n + j + 12);\n\n            acc0 = vmlaq_f32(acc0, v_mat_0, v_vec_0);\n            acc1 = vmlaq_f32(acc1, v_mat_1, v_vec_1);\n            acc2 = vmlaq_f32(acc2, v_mat_2, v_vec_2);\n            acc3 = vmlaq_f32(acc3, v_mat_3, v_vec_3);\n        }\n\n        float32x4_t sum1 = vaddq_f32(acc0, acc1);\n        float32x4_t sum2 = vaddq_f32(acc2, acc3);\n        float32x4_t total_sum = vaddq_f32(sum1, sum2);\n\n        float result[4];\n        vst1q_f32(result, total_sum);\n\n        dst[i] = result[0] + result[1] + result[2] + result[3];\n\n        for (size_t j = (n / 16) * 16; j < n; ++j) {\n            dst[i] += mat[i * n + j] * vec[j];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_29_Neon", "completion": "```c\n#include <arm_neon.h>\n\ndouble matrix_average_simd(const double* mat, size_t m, size_t n) {\n    size_t total_elements = m * n;\n    size_t vector_size = 2; // Number of elements in a SIMD vector for double (128-bit)\n    size_t full_vectors = total_elements / vector_size;\n    size_t remaining = total_elements % vector_size;\n\n    double accumulators[vector_size] = {0.0};\n    const double *ptr = mat;\n\n    // Process full vectors\n    for (size_t i = 0; i < full_vectors; ++i) {\n        float64x2_t vec = vld1q_f64(ptr);\n        accumulators[0] += vgetq_lane_f64(vec, 0);\n        accumulators[1] += vgetq_lane_f64(vec, 1);\n        ptr += vector_size;\n    }\n\n    // Process remaining elements\n    for (size_t i = 0; i < remaining; ++i) {\n        accumulators[0] += *ptr++;\n    }\n\n    // Calculate the sum and average\n    double total_sum = accumulators[0] + accumulators[1];\n    return total_sum / total_elements;\n}\n```"}
{"task_id": "SimdBench_29_Neon", "completion": "```c\n#include <arm_neon.h>\n\ndouble matrix_average_simd(const double* mat, size_t m, size_t n) {\n    size_t total_elements = m * n;\n    size_t vector_size = 2; // Number of elements in a SIMD vector for double (128-bit)\n    size_t full_vectors = total_elements / vector_size;\n    size_t remaining = total_elements % vector_size;\n\n    double accumulators[vector_size];\n    for (size_t i = 0; i < vector_size; ++i) {\n        accumulators[i] = 0.0;\n    }\n\n    float64x2_t sum_vector = vdupq_n_f64(0.0);\n\n    for (size_t i = 0; i < full_vectors; ++i) {\n        float64x2_t vec = vld1q_f64(mat + i * vector_size);\n        sum_vector = vaddq_f64(sum_vector, vec);\n    }\n\n    for (size_t i = 0; i < vector_size; ++i) {\n        accumulators[i] += sum_vector[i];\n    }\n\n    for (size_t i = full_vectors * vector_size; i < total_elements; ++i) {\n        accumulators[i % vector_size] += mat[i];\n    }\n\n    double total_sum = 0.0;\n    for (size_t i = 0; i < vector_size; ++i) {\n        total_sum += accumulators[i];\n    }\n\n    return total_sum / total_elements;\n}\n```"}
{"task_id": "SimdBench_29_Neon", "completion": "```c\n#include <arm_neon.h>\n\ndouble matrix_average_simd(const double* mat, size_t m, size_t n) {\n    size_t total_elements = m * n;\n    size_t i, j;\n    uint64x2_t count_vec = vdupq_n_u64(1);\n    float64x2_t sum_vec = vdupq_n_f64(0.0);\n\n    for (i = 0; i < (total_elements / 2) * 2; i += 2) {\n        float64x2_t vec = vld1q_f64(mat + i);\n        sum_vec = vaddq_f64(sum_vec, vec);\n    }\n\n    float64x2_t partial_sums = vpaddq_f64(sum_vec, sum_vec);\n    double sum = vgetq_lane_f64(partial_sums, 0) + vgetq_lane_f64(partial_sums, 1);\n\n    // Handle remaining elements if any\n    for (; i < total_elements; ++i) {\n        sum += mat[i];\n    }\n\n    return sum / total_elements;\n}\n```"}
{"task_id": "SimdBench_29_Neon", "completion": "```c\ndouble matrix_average_simd(const double* mat, size_t m, size_t n) {\n    size_t total_elements = m * n;\n    double sum = 0.0;\n    size_t i, j;\n\n    // Process elements in SIMD vector chunks (2 doubles per vector)\n    for (i = 0; i < total_elements / 2; i += 2) {\n        float64x2_t vec = vld1q_f64(&mat[i]);\n        float64x2_t acc = vpaddlq_f64(vec);\n        sum += vgetq_lane_f64(acc, 0) + vgetq_lane_f64(acc, 1);\n    }\n\n    // Handle any remaining scalar elements\n    for (j = i; j < total_elements; j++) {\n        sum += mat[j];\n    }\n\n    return sum / total_elements;\n}\n```"}
{"task_id": "SimdBench_29_Neon", "completion": "```c\n#include <arm_neon.h>\n\ndouble matrix_average_simd(const double* mat, size_t m, size_t n) {\n    size_t total_elements = m * n;\n    size_t vector_size = 2; // Number of elements in a SIMD vector for double (128-bit)\n    size_t full_vectors = total_elements / vector_size;\n    size_t remaining = total_elements % vector_size;\n\n    double accumulators[2] = {0.0, 0.0};\n    fd64x2_t sum_vector = vdupq_n_f64(0.0);\n\n    for (size_t i = 0; i < full_vectors; ++i) {\n        fd64x2_t vec = vld1q_f64(mat + i * vector_size);\n        sum_vector = vaddq_f64(sum_vector, vec);\n    }\n\n    accumulators[0] += vgetq_lane_f64(sum_vector, 0);\n    accumulators[1] += vgetq_lane_f64(sum_vector, 1);\n\n    double total_sum = accumulators[0] + accumulators[1];\n\n    if (remaining > 0) {\n        for (size_t i = full_vectors * vector_size; i < total_elements; ++i) {\n            total_sum += mat[i];\n        }\n    }\n\n    return total_sum / total_elements;\n}\n```"}
{"task_id": "SimdBench_30_Neon", "completion": "```c\n#include <arm_neon.h>\n\nbool matrix_rows_sorted_verify_simd(const int* matrix, const bool* directions, size_t rows, size_t cols) {\n    for (size_t i = 0; i < rows; ++i) {\n        const int* row = matrix + i * cols;\n        bool direction = directions[i];\n        \n        size_t j = 0;\n        for (; j <= cols - 16; j += 16) {\n            int32x4_t v1_lo = vld1q_s32(row + j);\n            int32x4_t v1_hi = vld1q_s32(row + j + 4);\n            int32x4_t v2_lo = vld1q_s32(row + j + 4);\n            int32x4_t v2_hi = vld1q_s32(row + j + 8);\n            int32x4_t v3_lo = vld1q_s32(row + j + 8);\n            int32x4_t v3_hi = vld1q_s32(row + j + 12);\n\n            if (direction) {\n                uint32x4_t res1_lo = vcgeq_s32(v1_lo, v2_lo);\n                uint32x4_t res1_hi = vcgeq_s32(v1_hi, v2_hi);\n                uint32x4_t res2_lo = vcgeq_s32(v2_lo, v3_lo);\n                uint32x4_t res2_hi = vcgeq_s32(v2_hi, v3_hi);\n                \n                if (vminvq_u32(res1_lo) == 0 || vminvq_u32(res1_hi) == 0 ||\n                    vminvq_u32(res2_lo) == 0 || vminvq_u32(res2_hi) == 0) {\n                    return false;\n                }\n            } else {\n                uint32x4_t res1_lo = vcleq_s32(v1_lo, v2_lo);\n                uint32x4_t res1_hi = vcleq_s32(v1_hi, v2_hi);\n                uint32x4_t res2_lo = vcleq_s32(v2_lo, v3_lo);\n                uint32x4_t res2_hi = vcleq_s32(v2_hi, v3_hi);\n                \n                if (vminvq_u32(res1_lo) == 0 || vminvq_u32(res1_hi) == 0 ||\n                    vminvq_u32(res2_lo) == 0 || vminvq_u32(res2_hi) == 0) {\n                    return false;\n                }\n            }\n        }\n\n        for (; j < cols - 1; ++j) {\n            if (direction) {\n                if (row[j] > row[j + 1]) return false;\n            } else {\n                if (row[j] < row[j + 1]) return false;\n            }\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_30_Neon", "completion": "```c\n#include <arm_neon.h>\n\nbool matrix_rows_sorted_verify_simd(const int* matrix, const bool* directions, size_t rows, size_t cols) {\n    for (size_t i = 0; i < rows; ++i) {\n        const int* row = matrix + i * cols;\n        bool direction = directions[i];\n        \n        size_t j = 0;\n        for (; j <= cols - 4; j += 4) {\n            int32x4_t v_curr = vld1q_s32(row + j);\n            int32x4_t v_next = vld1q_s32(row + j + 1);\n            \n            int32x4_t v_diff = vsubq_s32(v_next, v_curr);\n            int32x4_t v_zero = vmovq_n_s32(0);\n            \n            uint32x4_t v_cmp;\n            if (direction) {\n                v_cmp = vcgeq_s32(v_diff, v_zero); // ascending: diff >= 0\n            } else {\n                v_cmp = vcleq_s32(v_diff, v_zero); // descending: diff <= 0\n            }\n            \n            if (vminvq_u32(vreinterpretq_u32_s32(v_cmp)) == 0) {\n                return false;\n            }\n        }\n        \n        for (; j < cols - 1; ++j) {\n            if (direction) {\n                if (row[j] > row[j + 1]) return false;\n            } else {\n                if (row[j] < row[j + 1]) return false;\n            }\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_30_Neon", "completion": "```c\n#include <arm_neon.h>\n\nbool matrix_rows_sorted_verify_simd(const int* matrix, const bool* directions, size_t rows, size_t cols) {\n    for (size_t i = 0; i < rows; ++i) {\n        const int* row = matrix + i * cols;\n        bool direction = directions[i];\n        \n        size_t j = 0;\n        for (; j <= cols - 4; j += 4) {\n            int32x4_t v_curr = vld1q_s32(row + j);\n            int32x4_t v_next = vld1q_s32(row + j + 1);\n            \n            int32x4_t v_cmp = direction ? vcgeq_s32(v_curr, v_next) : vcleq_s32(v_curr, v_next);\n            uint32x4_t v_mask = vmovq_n_u32(0xFFFFFFFF);\n            if (vbitestq_u32(v_mask, vgetq_lane_u32(vreinterpretq_u32_s32(v_cmp), 0)) == 0 ||\n                vbitestq_u32(v_mask, vgetq_lane_u32(vreinterpretq_u32_s32(v_cmp), 1)) == 0 ||\n                vbitestq_u32(v_mask, vgetq_lane_u32(vreinterpretq_u32_s32(v_cmp), 2)) == 0 ||\n                vbitestq_u32(v_mask, vgetq_lane_u32(vreinterpretq_u32_s32(v_cmp), 3)) == 0) {\n                return false;\n            }\n        }\n        \n        for (; j < cols - 1; ++j) {\n            if (direction ? row[j] > row[j + 1] : row[j] < row[j + 1]) {\n                return false;\n            }\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_30_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nbool matrix_rows_sorted_verify_simd(const int* matrix, const bool* directions, size_t rows, size_t cols) {\n    for (size_t i = 0; i < rows; ++i) {\n        const int* row = matrix + i * cols;\n        bool direction = directions[i];\n        \n        size_t j = 0;\n        for (; j <= cols - 4; j += 4) {\n            int32x4_t v_row = vld1q_s32(row + j);\n            int32x4_t v_shifted = vextq_s32(v_row, v_row, 1);\n            \n            if (direction) {\n                // Ascending order\n                uint32x4_t v_cmp = vcgeq_s32(v_shifted, v_row);\n                if (vminvq_u32(vmovl_u16(vget_low_u16((uint16x8_t)v_cmp))) == 0) {\n                    return false;\n                }\n            } else {\n                // Descending order\n                uint32x4_t v_cmp = vcgeq_s32(v_row, v_shifted);\n                if (vminvq_u32(vmovl_u16(vget_low_u16((uint16x8_t)v_cmp))) == 0) {\n                    return false;\n                }\n            }\n        }\n        \n        for (; j < cols - 1; ++j) {\n            if (direction) {\n                if (row[j] > row[j + 1]) return false;\n            } else {\n                if (row[j] < row[j + 1]) return false;\n            }\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_30_Neon", "completion": "```c\n#include <arm_neon.h>\n\nbool matrix_rows_sorted_verify_simd(const int* matrix, const bool* directions, size_t rows, size_t cols) {\n    for (size_t i = 0; i < rows; ++i) {\n        const int* row = matrix + i * cols;\n        bool direction = directions[i];\n        \n        size_t j = 0;\n        for (; j <= cols - 4; j += 4) {\n            int32x4_t v_row = vld1q_s32(row + j);\n            int32x4_t v_shifted = vextq_s32(v_row, v_row, 1);\n            \n            if (direction) {\n                uint32x4_t v_cmp = vcgeq_s32(v_shifted, v_row);\n                if (vminvq_u32(vreinterpretq_u32_s32(v_cmp)) == 0) {\n                    return false;\n                }\n            } else {\n                uint32x4_t v_cmp = vcgeq_s32(v_row, v_shifted);\n                if (vminvq_u32(vreinterpretq_u32_s32(v_cmp)) == 0) {\n                    return false;\n                }\n            }\n        }\n        \n        for (; j < cols - 1; ++j) {\n            if (direction) {\n                if (row[j] > row[j + 1]) return false;\n            } else {\n                if (row[j] < row[j + 1]) return false;\n            }\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_31_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid nearest_multiple_simd(const int16_t* src, int16_t* dst, uint8_t base, size_t length) {\n    const int16x8_t vbase = vmov_n_s16(base);\n    size_t i = 0;\n\n    for (; i <= length - 8; i += 8) {\n        int16x8_t vsrc = vld1q_s16(src + i);\n        int16x8_t vdiv = vshrq_n_s16(vsrc, 0); // Divide by base using shift (assuming base is power of 2)\n        int16x8_t vmul = vmulq_s16(vdiv, vbase);\n        vst1q_s16(dst + i, vmul);\n    }\n\n    for (; i < length; i++) {\n        dst[i] = (src[i] / base) * base;\n    }\n}\n```"}
{"task_id": "SimdBench_31_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid nearest_multiple_simd(const int16_t* src, int16_t* dst, uint8_t base, size_t length) {\n    uint16x8_t vbase = vdupq_n_u16(base);\n    size_t i = 0;\n\n    for (; i <= length - 8; i += 8) {\n        int16x8_t vsrc = vld1q_s16(src + i);\n        uint16x8_t vabs_src = vreinterpretq_u16_s16(vsrc); \n        uint16x8_t vdiv = vshrq_n_u16(vabs_src, 0); \n        uint16x8_t vmul = vmulq_u16(vdiv, vbase);\n        int16x8_t vresult = vreinterpretq_s16_u16(vmul);\n        vst1q_s16(dst + i, vresult);\n    }\n\n    for (; i < length; i++) {\n        dst[i] = (src[i] / base) * base;\n    }\n}\n```"}
{"task_id": "SimdBench_31_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid nearest_multiple_simd(const int16_t* src, int16_t* dst, uint8_t base, size_t length) {\n    uint16x8_t vbase = vdupq_n_u16(base);\n    size_t i = 0;\n\n    for (; i <= length - 8; i += 8) {\n        int16x8_t vsrc = vld1q_s16(src + i);\n        int16x8_t vabs_src = vabsq_s16(vsrc);\n        uint16x8_t vdiv = vshrq_n_u16(vreinterpretq_u16_s16(vabs_src), 0);\n        uint16x8_t vmul = vmulq_u16(vdiv, vbase);\n        int16x8_t vresult = vreinterpretq_s16_u16(vmul);\n        vst1q_s16(dst + i, vresult);\n    }\n\n    for (; i < length; i++) {\n        dst[i] = (src[i] / base) * base;\n    }\n}\n```"}
{"task_id": "SimdBench_31_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid nearest_multiple_simd(const int16_t* src, int16_t* dst, uint8_t base, size_t length) {\n    const int16x8_t vbase = vmov_n_s16(base);\n    size_t i = 0;\n\n    for (; i <= length - 8; i += 8) {\n        int16x8_t vsrc = vld1q_s16(src + i);\n        int16x8_t vdiv = vshrq_n_s16(vsrc, 0); // Avoid warning, same as vsrc\n        int16x8_t vquotient = vdivq_s16(vdiv, vbase);\n        int16x8_t vmultiple = vmulq_s16(vquotient, vbase);\n        vst1q_s16(dst + i, vmultiple);\n    }\n\n    for (; i < length; ++i) {\n        dst[i] = (src[i] / base) * base;\n    }\n}\n```"}
{"task_id": "SimdBench_31_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid nearest_multiple_simd(const int16_t* src, int16_t* dst, uint8_t base, size_t length) {\n    const int16x8_t vbase = vmov_n_s16(base);\n    size_t i = 0;\n\n    for (; i <= length - 8; i += 8) {\n        int16x8_t vsrc = vld1q_s16(src + i);\n        int16x8_t vdiv = vshrq_n_s16(vsrc, 0); // Avoid warning about unused result\n        int16x8_t vfloor = vdivq_s16(vsrc, vbase);\n        int16x8_t vmul = vmulq_s16(vfloor, vbase);\n        vst1q_s16(dst + i, vmul);\n    }\n\n    for (; i < length; ++i) {\n        dst[i] = (src[i] / base) * base;\n    }\n}\n```"}
{"task_id": "SimdBench_32_Neon", "completion": "```c\n#include <arm_neon.h>\n\nbool matrix_has_row_simd(const double* matrix, const double* vector, size_t rows, size_t cols) {\n    for (size_t i = 0; i < rows; ++i) {\n        bool row_match = true;\n        size_t j = 0;\n\n        // Process 2 elements at a time using SIMD\n        for (; j + 1 < cols; j += 2) {\n            float64x2_t vec_load = vld1q_f64((const float64_t*)&vector[j]);\n            float64x2_t mat_load = vld1q_f64((const float64_t*)&matrix[i * cols + j]);\n            uint64x2_t comparison = vceqq_f64(mat_load, vec_load);\n            if (vminvq_u64(comparison) != 0xFFFFFFFFFFFFFFFF) {\n                row_match = false;\n                break;\n            }\n        }\n\n        // Handle remaining scalar elements if any\n        for (; j < cols; ++j) {\n            if (matrix[i * cols + j] != vector[j]) {\n                row_match = false;\n                break;\n            }\n        }\n\n        if (row_match) {\n            return true;\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_32_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nbool matrix_has_row_simd(const double* matrix, const double* vector, size_t rows, size_t cols) {\n    for (size_t i = 0; i < rows; ++i) {\n        bool row_match = true;\n        const double* row = matrix + i * cols;\n        size_t j = 0;\n\n        // Process 2 elements at a time using SIMD\n        for (; j + 1 < cols; j += 2) {\n            uint64x2_t cmp = vcgeq_f64(vld1q_f64(row + j), vld1q_f64(vector + j));\n            cmp = vandq_u64(cmp, vcgeq_f64(vld1q_f64(vector + j), vld1q_f64(row + j)));\n            if (vminvq_u64(cmp) != 0xFFFFFFFFFFFFFFFF) {\n                row_match = false;\n                break;\n            }\n        }\n\n        // Handle remaining scalar elements\n        for (; j < cols; ++j) {\n            if (row[j] != vector[j]) {\n                row_match = false;\n                break;\n            }\n        }\n\n        if (row_match) {\n            return true;\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_32_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nbool matrix_has_row_simd(const double* matrix, const double* vector, size_t rows, size_t cols) {\n    for (size_t i = 0; i < rows; ++i) {\n        bool match = true;\n        size_t j = 0;\n        \n        // Process 2 elements per iteration using SIMD\n        for (; j + 1 < cols; j += 2) {\n            float64x2_t vec_simd = vld1q_f64(&vector[j]);\n            float64x2_t mat_simd = vld1q_f64(&matrix[i * cols + j]);\n            if (vcmpneq_f64(mat_simd, vec_simd).uint[0] || vcmpneq_f64(mat_simd, vec_simd).uint[1]) {\n                match = false;\n                break;\n            }\n        }\n        \n        // Handle remaining scalar elements if any\n        for (; j < cols; ++j) {\n            if (matrix[i * cols + j] != vector[j]) {\n                match = false;\n                break;\n            }\n        }\n        \n        if (match) {\n            return true;\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_32_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nbool matrix_has_row_simd(const double* matrix, const double* vector, size_t rows, size_t cols) {\n    for (size_t i = 0; i < rows; ++i) {\n        bool row_match = true;\n        size_t j = 0;\n\n        // Process 2 elements per iteration using SIMD\n        for (; j + 1 < cols; j += 2) {\n            float64x2_t vec_simd = vld1q_f64(&vector[j]);\n            float64x2_t mat_simd = vld1q_f64(&matrix[i * cols + j]);\n            if (vcmpeq_f64(vec_simd, mat_simd)[0] == 0 || vcmpeq_f64(vec_simd, mat_simd)[1] == 0) {\n                row_match = false;\n                break;\n            }\n        }\n\n        // Handle remaining scalar elements if any\n        for (; j < cols; ++j) {\n            if (matrix[i * cols + j] != vector[j]) {\n                row_match = false;\n                break;\n            }\n        }\n\n        if (row_match) {\n            return true;\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_32_Neon", "completion": "```c\n#include <arm_neon.h>\n\nbool matrix_has_row_simd(const double* matrix, const double* vector, size_t rows, size_t cols) {\n    for (size_t i = 0; i < rows; ++i) {\n        bool match = true;\n        size_t j = 0;\n\n        // Process elements in SIMD vectors\n        for (; j + 1 < cols; j += 2) {\n            float64x2_t vec_load = vld1q_f64((const float64_t*)&vector[j]);\n            float64x2_t mat_load = vld1q_f64((const float64_t*)&matrix[i * cols + j]);\n            if (vminvq_f64(vabsq_f64(vsubq_f64(mat_load, vec_load))) != 0.0) {\n                match = false;\n                break;\n            }\n        }\n\n        // Handle remaining scalar elements\n        for (; j < cols; ++j) {\n            if (matrix[i * cols + j] != vector[j]) {\n                match = false;\n                break;\n            }\n        }\n\n        if (match) {\n            return true;\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_33_Neon", "completion": "```c\nsize_t tensor_4d_equal_count_simd(const uint8_t* A, const uint8_t* B, const size_t dims[4]) {\n    size_t count = 0;\n    size_t total_elements = dims[0] * dims[1] * dims[2] * dims[3];\n    size_t i;\n\n    // Process 16 elements at a time using NEON\n    for (i = 0; i <= total_elements - 16; i += 16) {\n        uint8x16_t vec_a = vld1q_u8(&A[i]);\n        uint8x16_t vec_b = vld1q_u8(&B[i]);\n        uint8x16_t eq_mask = vceqq_u8(vec_a, vec_b);\n        uint8x16_t ones = vdupq_n_u8(1);\n        uint16x8_t partial_sums = vmovl_u8(vandq_u8(eq_mask, ones));\n        uint32x4_t sums_low = vpaddlq_u16(vget_low_u16(partial_sums));\n        uint32x4_t sums_high = vpaddlq_u16(vget_high_u16(partial_sums));\n        uint64x2_t sums = vpaddlq_u32(vaddq_u32(sums_low, sums_high));\n        count += vgetq_lane_u64(sums, 0) + vgetq_lane_u64(sums, 1);\n    }\n\n    // Process remaining elements\n    for (; i < total_elements; i++) {\n        if (A[i] == B[i]) {\n            count++;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_33_Neon", "completion": "```c\nsize_t tensor_4d_equal_count_simd(const uint8_t* A, const uint8_t* B, const size_t dims[4]) {\n    size_t total_elements = dims[0] * dims[1] * dims[2] * dims[3];\n    size_t count = 0;\n    \n    size_t i = 0;\n    for (; i <= total_elements - 16; i += 16) {\n        uint8x16_t vec_a = vld1q_u8(A + i);\n        uint8x16_t vec_b = vld1q_u8(B + i);\n        uint8x16_t eq = vceqq_u8(vec_a, vec_b);\n        uint64x2_t res = vcntq_u8(eq);\n        uint64x2_t sum = vpaddlq_u32(vreinterpretq_u32_u64(res));\n        count += vget_lane_u64(sum, 0) + vget_lane_u64(sum, 1);\n    }\n    \n    for (; i < total_elements; i++) {\n        if (A[i] == B[i]) {\n            count++;\n        }\n    }\n    \n    return count;\n}\n```"}
{"task_id": "SimdBench_33_Neon", "completion": "```c\nsize_t tensor_4d_equal_count_simd(const uint8_t* A, const uint8_t* B, const size_t dims[4]) {\n    size_t total_elements = dims[0] * dims[1] * dims[2] * dims[3];\n    size_t count = 0;\n    size_t i = 0;\n\n    // Process 16 elements at a time using SIMD\n    for (; i <= total_elements - 16; i += 16) {\n        uint8x16_t vec_a = vld1q_u8(&A[i]);\n        uint8x16_t vec_b = vld1q_u8(&B[i]);\n        uint8x16_t eq_mask = vceqq_u8(vec_a, vec_b);\n        uint64x2_t cnt = vpaddlq_u32(vcntq_u8(eq_mask));\n        count += vget_lane_u64(cnt, 0) + vget_lane_u64(cnt, 1);\n    }\n\n    // Process remaining elements with scalar code\n    for (; i < total_elements; i++) {\n        if (A[i] == B[i]) {\n            count++;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_33_Neon", "completion": "```c\nsize_t tensor_4d_equal_count_simd(const uint8_t* A, const uint8_t* B, const size_t dims[4]) {\n    size_t total_elements = dims[0] * dims[1] * dims[2] * dims[3];\n    size_t count = 0;\n    size_t i = 0;\n\n    uint8x16_t vzero = vmovq_n_u8(0);\n\n    for (; i <= total_elements - 16; i += 16) {\n        uint8x16_t va = vld1q_u8(A + i);\n        uint8x16_t vb = vld1q_u8(B + i);\n        uint8x16_t veq = vceqq_u8(va, vb);\n        uint64_t tmp = vaddlvq_u8(veq);\n        count += (size_t)(tmp);\n    }\n\n    for (; i < total_elements; ++i) {\n        if (A[i] == B[i]) {\n            count++;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_33_Neon", "completion": "```c\nsize_t tensor_4d_equal_count_simd(const uint8_t* A, const uint8_t* B, const size_t dims[4]) {\n    size_t count = 0;\n    size_t total_size = dims[0] * dims[1] * dims[2] * dims[3];\n    size_t i = 0;\n\n    // Process 16 elements at a time using SIMD\n    for (; i <= total_size - 16; i += 16) {\n        uint8x16_t vec_a = vld1q_u8(A + i);\n        uint8x16_t vec_b = vld1q_u8(B + i);\n        uint8x16_t eq_mask = vceqq_u8(vec_a, vec_b);\n        uint64x2_t cnt = vpaddlq_u32(vcntq_u8(eq_mask));\n        count += (size_t)vgetq_lane_u32(cnt, 0) + (size_t)vgetq_lane_u32(cnt, 1);\n    }\n\n    // Process remaining elements with scalar code\n    for (; i < total_size; i++) {\n        if (A[i] == B[i]) {\n            count++;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_34_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid axm_abs_simd(size_t length, const int64_t a, const int64_t *x, int64_t *y) {\n    size_t i = 0;\n    int64x2_t va = vdupq_n_s64(a);\n\n    for (; i <= length - 2; i += 2) {\n        int64x2_t vx = vld1q_s64((const int64_t *)&x[i]);\n        int64x2_t vy = vld1q_s64((const int64_t *)&y[i]);\n\n        int64x2_t mul = vmulq_s64(vx, va);\n        uint64x2_t abs_y = vabsq_s64(vy);\n\n        int64x2_t result = vsubq_s64(mul, abs_y);\n\n        vst1q_s64((int64_t *)&y[i], result);\n    }\n\n    for (; i < length; ++i) {\n        y[i] = a * x[i] - labs(y[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_34_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid axm_abs_simd(size_t length, const int64_t a, const int64_t *x, int64_t *y) {\n    size_t i = 0;\n    int64x2_t va = vdupq_n_s64(a);\n\n    for (; i <= length - 2; i += 2) {\n        int64x2_t vx = vld1q_s64((const int64_t *)&x[i]);\n        int64x2_t vy = vld1q_s64((const int64_t *)&y[i]);\n\n        int64x2_t mul = vmulq_s64(vx, va);\n        int64x2_t abs_y = vabsq_s64(vy);\n        int64x2_t res = vsubq_s64(mul, abs_y);\n\n        vst1q_s64((int64_t *)&y[i], res);\n    }\n\n    // Handle remaining elements\n    for (; i < length; ++i) {\n        y[i] = a * x[i] - labs(y[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_34_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid axm_abs_simd(size_t length, const int64_t a, const int64_t *x, int64_t *y) {\n    size_t i = 0;\n    int64x2_t va = vdupq_n_s64(a);\n\n    for (; i <= length - 2; i += 2) {\n        int64x2_t vx = vld1q_s64((const int64_t *)&x[i]);\n        int64x2_t vy = vld1q_s64((const int64_t *)&y[i]);\n\n        int64x2_t mul = vmulq_s64(vx, va);\n        int64x2_t abs_y = vabsq_s64(vy);\n        int64x2_t res = vsubq_s64(mul, abs_y);\n\n        vst1q_s64((int64_t *)&y[i], res);\n    }\n\n    for (; i < length; ++i) {\n        y[i] = a * x[i] - labs(y[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_34_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid axm_abs_simd(size_t length, const int64_t a, const int64_t *x, int64_t *y) {\n    size_t i = 0;\n    int64x2_t va = vdupq_n_s64(a);\n\n    for (; i <= length - 2; i += 2) {\n        int64x2_t vx = vld1q_s64((const int64_t *)&x[i]);\n        int64x2_t vy = vld1q_s64((const int64_t *)&y[i]);\n\n        int64x2_t mul = vmulq_s64(vx, va);\n        uint64x2_t abs_y = vabsq_s64(vy);\n\n        int64x2_t result = vsubq_s64(mul, abs_y);\n\n        vst1q_s64((int64_t *)&y[i], result);\n    }\n\n    for (; i < length; ++i) {\n        y[i] = a * x[i] - labs(y[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_34_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid axm_abs_simd(size_t length, const int64_t a, const int64_t *x, int64_t *y) {\n    size_t i = 0;\n    int64x2_t va = vdupq_n_s64(a);\n\n    for (; i <= length - 2; i += 2) {\n        int64x2_t vx = vld1q_s64((const int64_t *)&x[i]);\n        int64x2_t vy = vld1q_s64((const int64_t *)&y[i]);\n\n        int64x2_t vmul = vmulq_s64(vx, va);\n        uint64x2_t vabs = vabsq_s64(vy);\n\n        int64x2_t vsub = vsubq_s64(vmul, vreinterpretq_s64_u64(vabs));\n\n        vst1q_s64((int64_t *)&y[i], vsub);\n    }\n\n    for (; i < length; ++i) {\n        y[i] = a * x[i] - abs(y[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_35_Neon", "completion": "```c\n#include <arm_neon.h>\n\ntypedef struct {\n    int16_t min_num;\n    int16_t max_num;\n} MinMaxPair;\n\nMinMaxPair min_max_pair_simd(const int16_t* vec, size_t length) {\n    int16x8_t vmin = vdupq_n_s16(INT16_MAX);\n    int16x8_t vmax = vdupq_n_s16(INT16_MIN);\n\n    for (size_t i = 0; i <= length - 8; i += 8) {\n        int16x8_t vload = vld1q_s16(&vec[i]);\n        vmin = vminq_s16(vmin, vload);\n        vmax = vmaxq_s16(vmax, vload);\n    }\n\n    int16x4_t vmin_low = vget_low_s16(vmin);\n    int16x4_t vmin_high = vget_high_s16(vmin);\n    int16x4_t vmax_low = vget_low_s16(vmax);\n    int16x4_t vmax_high = vget_high_s16(vmax);\n\n    vmin_low = vmin_s16(vmin_low, vmin_high);\n    vmax_low = vmax_s16(vmax_low, vmax_high);\n\n    int16_t min_val = vminv_s16(vmin_low);\n    int16_t max_val = vmaxv_s16(vmax_low);\n\n    // Handle remaining elements\n    for (size_t i = length & ~7; i < length; ++i) {\n        if (vec[i] < min_val) min_val = vec[i];\n        if (vec[i] > max_val) max_val = vec[i];\n    }\n\n    MinMaxPair result;\n    result.min_num = min_val;\n    result.max_num = max_val;\n    return result;\n}\n```"}
{"task_id": "SimdBench_35_Neon", "completion": "```c\ntypedef struct {\n    int16_t min_num;\n    int16_t max_num;\n} MinMaxPair;\n\nMinMaxPair min_max_pair_simd(const int16_t* vec, size_t length) {\n    int16x8_t vmin = vdupq_n_s16(INT16_MAX);\n    int16x8_t vmax = vdupq_n_s16(INT16_MIN);\n\n    for (size_t i = 0; i < length / 8 * 8; i += 8) {\n        int16x8_t v = vld1q_s16(&vec[i]);\n        vmin = vminq_s16(vmin, v);\n        vmax = vmaxq_s16(vmax, v);\n    }\n\n    int16x4_t vmin_low = vget_low_s16(vmin);\n    int16x4_t vmin_high = vget_high_s16(vmin);\n    int16x4_t vmax_low = vget_low_s16(vmax);\n    int16x4_t vmax_high = vget_high_s16(vmax);\n\n    vmin_low = vmin_s16(vmin_low, vmin_high);\n    vmax_low = vmax_s16(vmax_low, vmax_high);\n\n    int16_t min_val = vminv_s16(vmin_low);\n    int16_t max_val = vmaxv_s16(vmax_low);\n\n    for (size_t i = length / 8 * 8; i < length; ++i) {\n        if (vec[i] < min_val) min_val = vec[i];\n        if (vec[i] > max_val) max_val = vec[i];\n    }\n\n    MinMaxPair result;\n    result.min_num = min_val;\n    result.max_num = max_val;\n    return result;\n}\n```"}
{"task_id": "SimdBench_35_Neon", "completion": "```c\ntypedef struct {\n    int16_t min_num;\n    int16_t max_num;\n} MinMaxPair;\n\nMinMaxPair min_max_pair_simd(const int16_t* vec, size_t length) {\n    int16x8_t vmin = vdupq_n_s16(INT16_MAX);\n    int16x8_t vmax = vdupq_n_s16(INT16_MIN);\n\n    for (size_t i = 0; i < length / 8 * 8; i += 8) {\n        int16x8_t vload = vld1q_s16(vec + i);\n        vmin = vminq_s16(vmin, vload);\n        vmax = vmaxq_s16(vmax, vload);\n    }\n\n    int16x4_t vmin_low = vget_low_s16(vmin);\n    int16x4_t vmin_high = vget_high_s16(vmin);\n    int16x4_t vmax_low = vget_low_s16(vmax);\n    int16x4_t vmax_high = vget_high_s16(vmax);\n\n    vmin_low = vmin_s16(vmin_low, vmin_high);\n    vmax_low = vmax_s16(vmax_low, vmax_high);\n\n    int16_t min_val = vminv_s16(vmin_low);\n    int16_t max_val = vmaxv_s16(vmax_low);\n\n    for (size_t i = length / 8 * 8; i < length; ++i) {\n        if (vec[i] < min_val) min_val = vec[i];\n        if (vec[i] > max_val) max_val = vec[i];\n    }\n\n    MinMaxPair result;\n    result.min_num = min_val;\n    result.max_num = max_val;\n    return result;\n}\n```"}
{"task_id": "SimdBench_35_Neon", "completion": "```c\n#include <arm_neon.h>\n\ntypedef struct {\n    int16_t min_num;\n    int16_t max_num;\n} MinMaxPair;\n\nMinMaxPair min_max_pair_simd(const int16_t* vec, size_t length) {\n    int16x8_t vmin = vld1q_s16(vec);\n    int16x8_t vmax = vmin;\n\n    size_t i = 8;\n    for (; i + 8 <= length; i += 8, vec += 8) {\n        int16x8_t v = vld1q_s16(vec);\n        vmin = vminq_s16(vmin, v);\n        vmax = vmaxq_s16(vmax, v);\n    }\n\n    int16x4_t vmin_low = vmin_get_low_s16(vmin);\n    int16x4_t vmin_high = vmin_get_high_s16(vmin);\n    vmin_low = vmin_s16(vmin_low, vmin_high);\n\n    int16x4_t vmax_low = vmax_get_low_s16(vmax);\n    int16x4_t vmax_high = vmax_get_high_s16(vmax);\n    vmax_low = vmax_s16(vmax_low, vmax_high);\n\n    int16_t min_result = vminv_s16(vmin_low);\n    int16_t max_result = vmaxv_s16(vmax_low);\n\n    for (; i < length; ++i) {\n        if (vec[i] < min_result) min_result = vec[i];\n        if (vec[i] > max_result) max_result = vec[i];\n    }\n\n    MinMaxPair result;\n    result.min_num = min_result;\n    result.max_num = max_result;\n    return result;\n}\n```"}
{"task_id": "SimdBench_35_Neon", "completion": "```c\n#include <arm_neon.h>\n\ntypedef struct {\n    int16_t min_num;\n    int16_t max_num;\n} MinMaxPair;\n\nMinMaxPair min_max_pair_simd(const int16_t* vec, size_t length) {\n    int16x8_t vmin = vdupq_n_s16(INT16_MAX);\n    int16x8_t vmax = vdupq_n_s16(INT16_MIN);\n\n    for (size_t i = 0; i <= length - 8; i += 8) {\n        int16x8_t vload = vld1q_s16(&vec[i]);\n        vmin = vminq_s16(vmin, vload);\n        vmax = vmaxq_s16(vmax, vload);\n    }\n\n    int16x4_t vmin_low = vget_low_s16(vmin);\n    int16x4_t vmin_high = vget_high_s16(vmin);\n    int16x4_t vmax_low = vget_low_s16(vmax);\n    int16x4_t vmax_high = vget_high_s16(vmax);\n\n    vmin_low = vmin_s16(vmin_low, vmin_high);\n    vmax_low = vmax_s16(vmax_low, vmax_high);\n\n    int16_t min_val = vminv_s16(vmin_low);\n    int16_t max_val = vmaxv_s16(vmax_low);\n\n    for (size_t i = length & ~7; i < length; ++i) {\n        if (vec[i] < min_val) min_val = vec[i];\n        if (vec[i] > max_val) max_val = vec[i];\n    }\n\n    MinMaxPair result;\n    result.min_num = min_val;\n    result.max_num = max_val;\n    return result;\n}\n```"}
{"task_id": "SimdBench_36_Neon", "completion": "```c\n#include <arm_neon.h>\n\nbool matrix_rows_strictly_increasing_simd(const int* matrix, size_t rows, size_t cols) {\n    if (rows == 0 || cols == 0) {\n        return false;\n    }\n\n    for (size_t i = 0; i < rows; ++i) {\n        const int* row = matrix + i * cols;\n        size_t j = 0;\n\n        // Handle the SIMD part\n        for (; j <= cols - 4; j += 4) {\n            int32x4_t v_row = vld1q_s32(row + j);\n            int32x4_t v_shifted = vextq_s32(v_row, v_row, 1);\n            uint32x4_t v_cmp = vcgtq_s32(v_shifted, v_row);\n            if (vgetq_lane_u32(vreinterpretq_u32_s32(v_cmp), 0) == 0 ||\n                vgetq_lane_u32(vreinterpretq_u32_s32(v_cmp), 1) == 0 ||\n                vgetq_lane_u32(vreinterpretq_u32_s32(v_cmp), 2) == 0) {\n                return false;\n            }\n        }\n\n        // Handle the remaining elements\n        for (; j < cols - 1; ++j) {\n            if (row[j] >= row[j + 1]) {\n                return false;\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_36_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nbool matrix_rows_strictly_increasing_simd(const int* matrix, size_t rows, size_t cols) {\n    if (rows == 0 || cols == 0) return false;\n\n    for (size_t i = 0; i < rows; ++i) {\n        const int* row = matrix + i * cols;\n        size_t j = 0;\n\n        // Handle the SIMD part\n        for (; j + 4 <= cols; j += 4) {\n            int32x4_t v_row = vld1q_s32(row + j);\n            int32x4_t v_shifted = vextq_s32(v_row, v_row, 1);\n            uint32x4_t v_cmp = vcgeq_s32(v_shifted, v_row);\n\n            // Check if any element is greater or equal to the next one\n            if (vaddvq_u32((uint32x4_t)v_cmp) != 0) {\n                return false;\n            }\n        }\n\n        // Handle the scalar part\n        for (; j + 1 < cols; ++j) {\n            if (row[j] >= row[j + 1]) {\n                return false;\n            }\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_36_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nbool matrix_rows_strictly_increasing_simd(const int* matrix, size_t rows, size_t cols) {\n    if (rows == 0 || cols == 0) return false;\n\n    for (size_t i = 0; i < rows; ++i) {\n        const int* row = matrix + i * cols;\n        size_t j = 0;\n\n        // Handle the SIMD part\n        for (; j + 3 < cols; j += 4) {\n            int32x4_t v_row = vld1q_s32(row + j);\n            int32x4_t v_shifted = vextq_s32(v_row, v_row, 1);\n            uint32x4_t v_cmp = vcgeq_s32(v_shifted, v_row);\n            if (vany lane(v_cmp)) {\n                return false;\n            }\n        }\n\n        // Handle the scalar part\n        for (; j + 1 < cols; ++j) {\n            if (row[j] >= row[j + 1]) {\n                return false;\n            }\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_36_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nbool matrix_rows_strictly_increasing_simd(const int* matrix, size_t rows, size_t cols) {\n    if (rows == 0 || cols == 0) return false;\n\n    for (size_t i = 0; i < rows; ++i) {\n        const int* row = matrix + i * cols;\n        size_t j = 0;\n\n        // Handle the SIMD part\n        for (; j <= cols - 4; j += 4) {\n            int32x4_t v1 = vld1q_s32(row + j);\n            int32x4_t v2 = vextq_s32(v1, v1, 1); // Shift left by 1 element\n            uint32x4_t cmp = vcgeq_s32(v2, v1);  // Compare if greater or equal\n            if (vmaxvq_u32(cmp) != 0) {          // If any are true, return false\n                return false;\n            }\n        }\n\n        // Handle the scalar part\n        for (; j < cols - 1; ++j) {\n            if (row[j] >= row[j + 1]) return false;\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_36_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nbool matrix_rows_strictly_increasing_simd(const int* matrix, size_t rows, size_t cols) {\n    if (rows == 0 || cols == 0) {\n        return false;\n    }\n\n    for (size_t i = 0; i < rows; ++i) {\n        const int* row = matrix + i * cols;\n        size_t j = 0;\n\n        // Handle the SIMD part\n        for (; j + 3 < cols; j += 4) {\n            int32x4_t vec = vld1q_s32(row + j);\n            int32x4_t shifted_vec = vextq_s32(vec, vec, 1);\n            uint32x4_t comparison = vcgtq_s32(shifted_vec, vec);\n            if (vminvq_u32(comparison) != 0xFFFFFFFF) {\n                return false;\n            }\n        }\n\n        // Handle the remaining elements\n        for (; j + 1 < cols; ++j) {\n            if (row[j] >= row[j + 1]) {\n                return false;\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_37_Neon", "completion": "```c\n#include <arm_neon.h>\n\nbool matrix_blocks_equal_simd(const int* matrix, size_t block_size, size_t rows, size_t cols) {\n    if (block_size == 0 || rows % block_size != 0 || cols % block_size != 0) {\n        return false;\n    }\n\n    size_t num_blocks_row = cols / block_size;\n    size_t num_blocks_col = rows / block_size;\n\n    // Load the first block\n    size_t first_block_size = block_size * block_size;\n    int32x4_t first_block[first_block_size / 4];\n    for (size_t i = 0; i < block_size; ++i) {\n        for (size_t j = 0; j < block_size; j += 4) {\n            first_block[(i * block_size + j) / 4] = vld1q_s32(matrix + i * cols + j);\n        }\n    }\n\n    // Compare all other blocks with the first block\n    for (size_t b_row = 0; b_row < num_blocks_col; ++b_row) {\n        for (size_t b_col = 0; b_col < num_blocks_row; ++b_col) {\n            if (b_row == 0 && b_col == 0) {\n                continue; // Skip comparing the first block with itself\n            }\n\n            const int* current_block = matrix + b_row * block_size * cols + b_col * block_size;\n            for (size_t i = 0; i < block_size; ++i) {\n                for (size_t j = 0; j < block_size; j += 4) {\n                    int32x4_t vec = vld1q_s32(current_block + i * cols + j);\n                    if (vcmpneq_f32(first_block[(i * block_size + j) / 4], vec)) {\n                        return false;\n                    }\n                }\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_37_Neon", "completion": "```c\n#include <arm_neon.h>\n\nbool matrix_blocks_equal_simd(const int* matrix, size_t block_size, size_t rows, size_t cols) {\n    if (block_size == 0 || rows % block_size != 0 || cols % block_size != 0) {\n        return false;\n    }\n\n    size_t num_row_blocks = rows / block_size;\n    size_t num_col_blocks = cols / block_size;\n\n    // Load the first block\n    for (size_t i = 0; i < block_size; ++i) {\n        const int32_t* first_block_row = matrix + i * cols;\n        for (size_t j = 0; j < block_size; j += 4) {\n            int32x4_t first_block_vec = vld1q_s32(first_block_row + j);\n            for (size_t rb = 1; rb < num_row_blocks; ++rb) {\n                for (size_t cb = 1; cb < num_col_blocks; ++cb) {\n                    const int32_t* current_block_row = matrix + (rb * block_size + i) * cols + cb * block_size;\n                    int32x4_t current_block_vec = vld1q_s32(current_block_row + j);\n                    if (vcmpneq_f32(vreinterpretq_f32_s32(first_block_vec), vreinterpretq_f32_s32(current_block_vec))) {\n                        return false;\n                    }\n                }\n            }\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_37_Neon", "completion": "```c\n#include <arm_neon.h>\n\nbool matrix_blocks_equal_simd(const int* matrix, size_t block_size, size_t rows, size_t cols) {\n    if (block_size == 0 || rows % block_size != 0 || cols % block_size != 0) {\n        return false;\n    }\n\n    size_t num_blocks_row = cols / block_size;\n    size_t num_blocks_col = rows / block_size;\n\n    // Load the first block\n    const int* first_block = matrix;\n    for (size_t i = 0; i < block_size; ++i) {\n        for (size_t j = 0; j < block_size; j += 4) {\n            int32x4_t first_vec = vld1q_s32(&first_block[i * cols + j]);\n\n            for (size_t b_row = 1; b_row < num_blocks_col; ++b_row) {\n                for (size_t b_col = 0; b_col < num_blocks_row; ++b_col) {\n                    const int* current_block = &matrix[b_row * block_size * cols + b_col * block_size];\n                    int32x4_t current_vec = vld1q_s32(&current_block[i * cols + j]);\n                    if (vcmpneq_f32(first_vec, current_vec)) {\n                        return false;\n                    }\n                }\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_37_Neon", "completion": "```c\n#include <arm_neon.h>\n\nbool matrix_blocks_equal_simd(const int* matrix, size_t block_size, size_t rows, size_t cols) {\n    if (block_size == 0 || rows % block_size != 0 || cols % block_size != 0) {\n        return false;\n    }\n\n    size_t num_blocks_row = cols / block_size;\n    size_t num_blocks_col = rows / block_size;\n\n    // Load the first block\n    size_t first_block_size = block_size * block_size;\n    int32x4_t first_block[first_block_size / 4];\n    for (size_t i = 0; i < block_size; ++i) {\n        for (size_t j = 0; j < block_size / 4; ++j) {\n            first_block[i * (block_size / 4) + j] = vld1q_s32(matrix + i * cols + j * 4);\n        }\n    }\n\n    // Compare all other blocks with the first block\n    for (size_t b_row = 0; b_row < num_blocks_col; ++b_row) {\n        for (size_t b_col = 0; b_col < num_blocks_row; ++b_col) {\n            if (b_row == 0 && b_col == 0) {\n                continue; // Skip comparing the first block with itself\n            }\n\n            const int* current_block_ptr = matrix + b_row * block_size * cols + b_col * block_size;\n            for (size_t i = 0; i < block_size; ++i) {\n                for (size_t j = 0; j < block_size / 4; ++j) {\n                    int32x4_t current_block_vec = vld1q_s32(current_block_ptr + i * cols + j * 4);\n                    if (vcmpneq_f32(vreinterpretq_f32_s32(first_block[i * (block_size / 4) + j]), vreinterpretq_f32_s32(current_block_vec))) {\n                        return false;\n                    }\n                }\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_37_Neon", "completion": "```c\n#include <arm_neon.h>\n\nbool matrix_blocks_equal_simd(const int* matrix, size_t block_size, size_t rows, size_t cols) {\n    if (block_size == 0 || rows % block_size != 0 || cols % block_size != 0) {\n        return false;\n    }\n\n    size_t num_row_blocks = rows / block_size;\n    size_t num_col_blocks = cols / block_size;\n\n    // Load the first block\n    const int* first_block = matrix;\n    for (size_t i = 0; i < block_size; ++i) {\n        for (size_t j = 0; j < block_size; j += 4) {\n            int32x4_t v_first = vld1q_s32(first_block + i * cols + j);\n\n            for (size_t rb = 1; rb < num_row_blocks; ++rb) {\n                for (size_t cb = 1; cb < num_col_blocks; ++cb) {\n                    const int* current_block = matrix + rb * block_size * cols + cb * block_size;\n                    int32x4_t v_current = vld1q_s32(current_block + i * cols + j);\n                    if (vcmpneq_f32(vfirst, vcurrent)) {\n                        return false;\n                    }\n                }\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_38_Neon", "completion": "```c\n#include <arm_neon.h>\n\nbool vector_block_equal_simd(const double* vec, double tolerance, size_t length, size_t block_size) {\n    if (block_size == 0 || length == 0 || vec == NULL) return false;\n    size_t num_blocks = length / block_size;\n    if (num_blocks == 0 || block_size == 0) return false;\n\n    const double* first_block = vec;\n    for (size_t i = 1; i < num_blocks; ++i) {\n        const double* current_block = vec + i * block_size;\n        size_t j = 0;\n        for (; j + 2 <= block_size; j += 2) {\n            float64x2_t v_first = vld1q_f64((const float64x2_t*)&first_block[j]);\n            float64x2_t v_curr = vld1q_f64((const float64x2_t*)&current_block[j]);\n            float64x2_t v_diff = vabdq_f64(v_first, v_curr);\n            float64x2_t v_tol = vdupq_n_f64(tolerance);\n            uint64x2_t v_cmp = vcgeq_f64(v_diff, v_tol);\n            if (vget_lane_u64(vreinterpret_u64_f64(v_cmp), 0) || vget_lane_u64(vreinterpret_u64_f64(v_cmp), 1)) {\n                return false;\n            }\n        }\n        for (; j < block_size; ++j) {\n            if (fabs(first_block[j] - current_block[j]) > tolerance) {\n                return false;\n            }\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_38_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nbool vector_block_equal_simd(const double* vec, double tolerance, size_t length, size_t block_size) {\n    if (block_size == 0 || length == 0 || vec == nullptr) return false;\n\n    size_t num_blocks = length / block_size;\n    if (num_blocks < 2) return true;\n\n    const double* first_block = vec;\n    size_t i, j;\n\n    for (i = 1; i < num_blocks; ++i) {\n        const double* current_block = vec + i * block_size;\n        size_t elements_to_check = block_size;\n\n        for (j = 0; j + 2 <= elements_to_check; j += 2) {\n            float64x2_t v_first = vld1q_f64((const float64_t*)&first_block[j]);\n            float64x2_t v_current = vld1q_f64((const float64_t*)&current_block[j]);\n\n            float64x2_t v_diff = vabdq_f64(v_first, v_current);\n            float64x2_t v_tolerance = vdupq_n_f64(tolerance);\n\n            uint64x2_t v_cmp = vcgeq_f64(v_diff, v_tolerance);\n            if (vget_lane_u64(vreinterpret_u64_u8(vmovn_u16(vcmpneq_u8(vreinterpret_u8_u64(v_cmp), vdup_n_u8(0)))), 0) != 0) {\n                return false;\n            }\n        }\n\n        if (j < elements_to_check) {\n            if (fabs(first_block[j] - current_block[j]) > tolerance) {\n                return false;\n            }\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_38_Neon", "completion": "```c\n#include <arm_neon.h>\n\nbool vector_block_equal_simd(const double* vec, double tolerance, size_t length, size_t block_size) {\n    if (block_size == 0 || length < block_size || vec == NULL) return false;\n\n    size_t num_blocks = length / block_size;\n    if (num_blocks < 1) return false;\n\n    const double* first_block = vec;\n    uint64x2_t tol_vec = vdupq_n_f64(tolerance);\n\n    for (size_t i = 1; i < num_blocks; ++i) {\n        const double* current_block = vec + i * block_size;\n        for (size_t j = 0; j < block_size; j += 2) {\n            float64x2_t first = vld1q_f64(first_block + j);\n            float64x2_t curr = vld1q_f64(current_block + j);\n\n            float64x2_t diff = vabsq_f64(vsubq_f64(first, curr));\n            uint64x2_t mask = vcgtq_f64(diff, tol_vec);\n\n            if (vgetq_lane_u64(mask, 0) != 0 || vgetq_lane_u64(mask, 1) != 0) {\n                return false;\n            }\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_38_Neon", "completion": "```c\n#include <arm_neon.h>\n\nbool vector_block_equal_simd(const double* vec, double tolerance, size_t length, size_t block_size) {\n    if (block_size == 0 || length == 0 || vec == NULL) return false;\n    size_t num_blocks = length / block_size;\n    if (num_blocks == 0) return false;\n\n    const double* first_block = vec;\n    uint64x2_t tol_vec = vdupq_n_f64(tolerance);\n\n    for (size_t i = 1; i < num_blocks; ++i) {\n        const double* current_block = vec + i * block_size;\n        for (size_t j = 0; j < block_size; j += 2) {\n            if (j + 1 >= block_size) break;\n            float64x2_t first_vals = vld1q_f64(first_block + j);\n            float64x2_t curr_vals = vld1q_f64(current_block + j);\n            float64x2_t diff = vabsq_f64(vsubq_f64(first_vals, curr_vals));\n            uint64x2_t mask = vcgeq_f64(diff, tol_vec);\n            if (vgetq_lane_u64(mask, 0) || vgetq_lane_u64(mask, 1)) {\n                return false;\n            }\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_38_Neon", "completion": "```c\n#include <arm_neon.h>\n\nbool vector_block_equal_simd(const double* vec, double tolerance, size_t length, size_t block_size) {\n    if (block_size == 0 || length == 0 || vec == NULL) return false;\n\n    size_t num_blocks = length / block_size;\n    if (num_blocks == 0 || block_size == 0) return false;\n\n    const double* first_block = vec;\n    uint64x2_t tol_vec = vdupq_n_f64(tolerance);\n\n    for (size_t i = 1; i < num_blocks; ++i) {\n        const double* current_block = vec + i * block_size;\n        for (size_t j = 0; j < block_size; j += 2) {\n            float64x2_t first = vld1q_f64(first_block + j);\n            float64x2_t curr = vld1q_f64(current_block + j);\n\n            float64x2_t diff = vabdq_f64(first, curr);\n            uint64x2_t cmp = vcgeq_f64(diff, tol_vec);\n\n            if (vmaxvq_u64(cmp) != 0) {\n                return false;\n            }\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_39_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid matrix_row_norm_compare_simd(const double* matrix, const double* thresholds, size_t rows, size_t cols, bool* result) {\n    for (size_t i = 0; i < rows; ++i) {\n        double* row = (double*)&matrix[i * cols];\n        float64x2_t sum_vec = vdupq_n_f64(0.0);\n\n        size_t col = 0;\n        for (; col <= cols - 2; col += 2) {\n            float64x2_t vec = vld1q_f64(row + col);\n            float64x2_t squared = vmulq_f64(vec, vec);\n            sum_vec = vaddq_f64(sum_vec, squared);\n        }\n\n        double sum = vgetq_lane_f64(sum_vec, 0) + vgetq_lane_f64(sum_vec, 1);\n\n        for (; col < cols; ++col) {\n            sum += row[col] * row[col];\n        }\n\n        double norm = sqrt(sum);\n        result[i] = norm > thresholds[i];\n    }\n}\n```"}
{"task_id": "SimdBench_39_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid matrix_row_norm_compare_simd(const double* matrix, const double* thresholds, size_t rows, size_t cols, bool* result) {\n    for (size_t i = 0; i < rows; ++i) {\n        const double* row = &matrix[i * cols];\n        double sum = 0.0;\n        size_t j = 0;\n\n        // SIMD loop\n        for (; j + 7 < cols; j += 8) {\n            float64x2_t v1 = vld1q_f64(row + j);\n            float64x2_t v2 = vld1q_f64(row + j + 2);\n            float64x2_t v3 = vld1q_f64(row + j + 4);\n            float64x2_t v4 = vld1q_f64(row + j + 6);\n\n            float64x2_t sq1 = vmulq_f64(v1, v1);\n            float64x2_t sq2 = vmulq_f64(v2, v2);\n            float64x2_t sq3 = vmulq_f64(v3, v3);\n            float64x2_t sq4 = vmulq_f64(v4, v4);\n\n            float64x2_t sum1 = vaddq_f64(sq1, sq2);\n            float64x2_t sum2 = vaddq_f64(sq3, sq4);\n            float64x2_t total = vaddq_f64(sum1, sum2);\n\n            float64x2_t reduced = vpaddq_f64(total, total);\n            sum += vgetq_lane_f64(reduced, 0) + vgetq_lane_f64(reduced, 1);\n        }\n\n        // Tail processing\n        for (; j < cols; ++j) {\n            double val = row[j];\n            sum += val * val;\n        }\n\n        // Compare with threshold\n        double norm = sqrt(sum);\n        result[i] = norm > thresholds[i];\n    }\n}\n```"}
{"task_id": "SimdBench_39_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid matrix_row_norm_compare_simd(const double* matrix, const double* thresholds, size_t rows, size_t cols, bool* result) {\n    for (size_t i = 0; i < rows; ++i) {\n        double* row = (double*)&matrix[i * cols];\n        double threshold = thresholds[i];\n        uint64x2_t sum_v = vdupq_n_u64(0);\n\n        size_t j = 0;\n        for (; j + 1 < cols; j += 2) {\n            float64x2_t vec = vld1q_f64(row + j);\n            float64x2_t squared = vmulq_f64(vec, vec);\n            uint64x2_t squared_int = vcvtq_u64_f64(squared);\n            sum_v = vaddq_u64(sum_v, squared_int);\n        }\n\n        double norm_sq = (double)vaddv_u64(sum_v);\n\n        if (j < cols) {\n            double last_val = row[j];\n            norm_sq += last_val * last_val;\n        }\n\n        result[i] = norm_sq > threshold * threshold;\n    }\n}\n```"}
{"task_id": "SimdBench_39_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid matrix_row_norm_compare_simd(const double* matrix, const double* thresholds, size_t rows, size_t cols, bool* result) {\n    for (size_t i = 0; i < rows; ++i) {\n        double* row_start = (double*)&matrix[i * cols];\n        float64x2_t sum_vec = vdupq_n_f64(0.0);\n        \n        size_t col = 0;\n        for (; col <= cols - 2; col += 2) {\n            float64x2_t vec = vld1q_f64(row_start + col);\n            float64x2_t squared = vmulq_f64(vec, vec);\n            sum_vec = vaddq_f64(sum_vec, squared);\n        }\n        \n        double sum = vgetq_lane_f64(sum_vec, 0) + vgetq_lane_f64(sum_vec, 1);\n        for (; col < cols; ++col) {\n            sum += row_start[col] * row_start[col];\n        }\n        \n        double norm = sqrt(sum);\n        result[i] = norm > thresholds[i];\n    }\n}\n```"}
{"task_id": "SimdBench_39_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid matrix_row_norm_compare_simd(const double* matrix, const double* thresholds, size_t rows, size_t cols, bool* result) {\n    for (size_t i = 0; i < rows; ++i) {\n        const double* row = &matrix[i * cols];\n        double sum = 0.0;\n        size_t j = 0;\n\n        // SIMD loop\n        for (; j + 7 < cols; j += 8) {\n            float64x2_t v1 = vld1q_f64(row + j);\n            float64x2_t v2 = vld1q_f64(row + j + 2);\n            float64x2_t v3 = vld1q_f64(row + j + 4);\n            float64x2_t v4 = vld1q_f64(row + j + 6);\n\n            float64x2_t vmul1 = vmulq_f64(v1, v1);\n            float64x2_t vmul2 = vmulq_f64(v2, v2);\n            float64x2_t vmul3 = vmulq_f64(v3, v3);\n            float64x2_t vmul4 = vmulq_f64(v4, v4);\n\n            float64x2_t vadd1 = vaddq_f64(vmul1, vmul2);\n            float64x2_t vadd2 = vaddq_f64(vmul3, vmul4);\n            float64x2_t vadd3 = vaddq_f64(vadd1, vadd2);\n\n            float64x2_t vpadd = vpaddq_f64(vadd3, vadd3);\n\n            sum += vpget_lane_f64(vpadd, 0);\n        }\n\n        // Scalar loop for remaining elements\n        for (; j < cols; ++j) {\n            double val = row[j];\n            sum += val * val;\n        }\n\n        double norm = sqrt(sum);\n        result[i] = norm > thresholds[i];\n    }\n}\n```"}
{"task_id": "SimdBench_40_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid tensor_bitwise_or_simd(const uint32_t* A, const uint32_t* B, uint32_t* C, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 4; i += 4) {\n        uint32x4_t vec_a = vld1q_u32(&A[i]);\n        uint32x4_t vec_b = vld1q_u32(&B[i]);\n        uint32x4_t vec_c = vorrq_u32(vec_a, vec_b);\n        vst1q_u32(&C[i], vec_c);\n    }\n    for (; i < length; ++i) {\n        C[i] = A[i] | B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_40_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid tensor_bitwise_or_simd(const uint32_t* A, const uint32_t* B, uint32_t* C, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 4; i += 4) {\n        uint32x4_t vec_a = vld1q_u32(A + i);\n        uint32x4_t vec_b = vld1q_u32(B + i);\n        uint32x4_t vec_c = vorrq_u32(vec_a, vec_b);\n        vst1q_u32(C + i, vec_c);\n    }\n    for (; i < length; i++) {\n        C[i] = A[i] | B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_40_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid tensor_bitwise_or_simd(const uint32_t* A, const uint32_t* B, uint32_t* C, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 4; i += 4) {\n        uint32x4_t vec_a = vld1q_u32(&A[i]);\n        uint32x4_t vec_b = vld1q_u32(&B[i]);\n        uint32x4_t vec_c = vorrq_u32(vec_a, vec_b);\n        vst1q_u32(&C[i], vec_c);\n    }\n    for (; i < length; i++) {\n        C[i] = A[i] | B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_40_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid tensor_bitwise_or_simd(const uint32_t* A, const uint32_t* B, uint32_t* C, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 4; i += 4) {\n        uint32x4_t vec_a = vld1q_u32(&A[i]);\n        uint32x4_t vec_b = vld1q_u32(&B[i]);\n        uint32x4_t vec_c = vorrq_u32(vec_a, vec_b);\n        vst1q_u32(&C[i], vec_c);\n    }\n    for (; i < length; i++) {\n        C[i] = A[i] | B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_40_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid tensor_bitwise_or_simd(const uint32_t* A, const uint32_t* B, uint32_t* C, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 4; i += 4) {\n        uint32x4_t vec_a = vld1q_u32(&A[i]);\n        uint32x4_t vec_b = vld1q_u32(&B[i]);\n        uint32x4_t vec_c = vorrq_u32(vec_a, vec_b);\n        vst1q_u32(&C[i], vec_c);\n    }\n    for (; i < length; ++i) {\n        C[i] = A[i] | B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_41_Neon", "completion": "```c\nint64_t squarediff_simd(const int8_t * A, const int8_t * B, size_t length) {\n    int64_t sum_squares = 0;\n    int64_t sum_products = 0;\n\n    size_t i = 0;\n    for (; i <= length - 16; i += 16) {\n        int8x16_t a_vec = vld1q_s8(A + i);\n        int8x16_t b_vec = vld1q_s8(B + i);\n\n        // Compute squares of A and B\n        int16x8_t a_sq_lo = vmovl_s8(vget_low_s8(a_vec));\n        int16x8_t a_sq_hi = vmovl_s8(vget_high_s8(a_vec));\n        a_sq_lo = vmulq_s16(a_sq_lo, a_sq_lo);\n        a_sq_hi = vmulq_s16(a_sq_hi, a_sq_hi);\n\n        int16x8_t b_sq_lo = vmovl_s8(vget_low_s8(b_vec));\n        int16x8_t b_sq_hi = vmovl_s8(vget_high_s8(b_vec));\n        b_sq_lo = vmulq_s16(b_sq_lo, b_sq_lo);\n        b_sq_hi = vmulq_s16(b_sq_hi, b_sq_hi);\n\n        // Sum of squares\n        int32x4_t sum_a_sq_lo = vpaddlq_s16(a_sq_lo);\n        int32x4_t sum_a_sq_hi = vpaddlq_s16(a_sq_hi);\n        int32x4_t sum_b_sq_lo = vpaddlq_s16(b_sq_lo);\n        int32x4_t sum_b_sq_hi = vpaddlq_s16(b_sq_hi);\n\n        int64x2_t sum_a_sq = vpaddlq_s32(vaddq_s32(sum_a_sq_lo, sum_a_sq_hi));\n        int64x2_t sum_b_sq = vpaddlq_s32(vaddq_s32(sum_b_sq_lo, sum_b_sq_hi));\n\n        sum_squares += vgetq_lane_s64(sum_a_sq, 0) + vgetq_lane_s64(sum_a_sq, 1);\n        sum_squares += vgetq_lane_s64(sum_b_sq, 0) + vgetq_lane_s64(sum_b_sq, 1);\n\n        // Compute products of A and B\n        int16x8_t prod_lo = vmovl_s8(vget_low_s8(a_vec));\n        int16x8_t prod_hi = vmovl_s8(vget_high_s8(a_vec));\n        prod_lo = vmulq_s16(prod_lo, vmovl_s8(vget_low_s8(b_vec)));\n        prod_hi = vmulq_s16(prod_hi, vmovl_s8(vget_high_s8(b_vec)));\n\n        // Sum of products\n        int32x4_t sum_prod_lo = vpaddlq_s16(prod_lo);\n        int32x4_t sum_prod_hi = vpaddlq_s16(prod_hi);\n\n        int64x2_t sum_prod = vpaddlq_s32(vaddq_s32(sum_prod_lo, sum_prod_hi));\n\n        sum_products += vgetq_lane_s64(sum_prod, 0) + vgetq_lane_s64(sum_prod, 1);\n    }\n\n    for (; i < length; ++i) {\n        sum_squares += A[i] * A[i] + B[i] * B[i];\n        sum_products += A[i] * B[i];\n    }\n\n    return sum_squares - sum_products;\n}\n```"}
{"task_id": "SimdBench_41_Neon", "completion": "```c\n#include <arm_neon.h>\n\nint64_t squarediff_simd(const int8_t * A, const int8_t * B, size_t length) {\n    int64_t sum_squares = 0;\n    int64_t sum_products = 0;\n    \n    size_t i = 0;\n    for (; i <= length - 16; i += 16) {\n        int8x16_t a_vec = vld1q_s8(A + i);\n        int8x16_t b_vec = vld1q_s8(B + i);\n        \n        int16x8_t sq_a_lo = vmovl_s8(vget_low_s8(a_vec));\n        int16x8_t sq_a_hi = vmovl_s8(vget_high_s8(a_vec));\n        int16x8_t sq_b_lo = vmovl_s8(vget_low_s8(b_vec));\n        int16x8_t sq_b_hi = vmovl_s8(vget_high_s8(b_vec));\n        \n        int32x4_t sq_sum_lo = vaddl_s16(vmull_s8(vget_low_s8(a_vec), vget_low_s8(a_vec)), vmull_s8(vget_high_s8(a_vec), vget_high_s8(a_vec)));\n        int32x4_t sq_sum_hi = vaddl_s16(vmull_s8(vget_low_s8(b_vec), vget_low_s8(b_vec)), vmull_s8(vget_high_s8(b_vec), vget_high_s8(b_vec)));\n        \n        int32x4_t prod_sum = vaddl_s16(vmull_s8(vget_low_s8(a_vec), vget_low_s8(b_vec)), vmull_s8(vget_high_s8(a_vec), vget_high_s8(b_vec)));\n        \n        sum_squares += vaddvq_s32(vaddq_s32(sq_sum_lo, sq_sum_hi));\n        sum_products += vaddvq_s32(prod_sum);\n    }\n    \n    for (; i < length; i++) {\n        sum_squares += A[i] * A[i] + B[i] * B[i];\n        sum_products += A[i] * B[i];\n    }\n    \n    return sum_squares - sum_products;\n}\n```"}
{"task_id": "SimdBench_41_Neon", "completion": "```c\n#include <arm_neon.h>\n\nint64_t squarediff_simd(const int8_t * A, const int8_t * B, size_t length) {\n    int32x4_t sum_squares = vdupq_n_s32(0);\n    int32x4_t sum_products = vdupq_n_s32(0);\n    \n    for (size_t i = 0; i + 15 < length; i += 16) {\n        int8x16_t a_vec = vld1q_s8(A + i);\n        int8x16_t b_vec = vld1q_s8(B + i);\n        \n        int16x8_t squares_a = vmovl_s8(vget_low_s8(a_vec));\n        int16x8_t squares_b = vmovl_s8(vget_low_s8(b_vec));\n        int16x8_t products = vmulq_s16(squares_a, squares_b);\n        \n        squares_a = vmulq_s16(squares_a, squares_a);\n        squares_b = vmulq_s16(squares_b, squares_b);\n        \n        int32x4_t sum_sq_a = vpaddlq_s16(squares_a);\n        int32x4_t sum_sq_b = vpaddlq_s16(squares_b);\n        int32x4_t sum_prod = vpaddlq_s16(products);\n        \n        sum_squares = vaddq_s32(sum_squares, vaddq_s32(sum_sq_a, sum_sq_b));\n        sum_products = vaddq_s32(sum_products, sum_prod);\n        \n        squares_a = vmovl_high_s8(vget_high_s8(a_vec), vget_low_s8(a_vec));\n        squares_b = vmovl_high_s8(vget_high_s8(b_vec), vget_low_s8(b_vec));\n        products = vmulq_s16(squares_a, squares_b);\n        \n        squares_a = vmulq_s16(squares_a, squares_a);\n        squares_b = vmulq_s16(squares_b, squares_b);\n        \n        sum_sq_a = vpaddlq_s16(squares_a);\n        sum_sq_b = vpaddlq_s16(squares_b);\n        sum_prod = vpaddlq_s16(products);\n        \n        sum_squares = vaddq_s32(sum_squares, vaddq_s32(sum_sq_a, sum_sq_b));\n        sum_products = vaddq_s32(sum_products, sum_prod);\n    }\n    \n    int64x2_t total_squares = vpaddlq_s32(sum_squares);\n    int64x2_t total_products = vpaddlq_s32(sum_products);\n    \n    int64_t result = (vgetq_lane_s64(total_squares, 0) + vgetq_lane_s64(total_squares, 1)) \n                    - (vgetq_lane_s64(total_products, 0) + vgetq_lane_s64(total_products, 1));\n    \n    for (size_t i = (length / 16) * 16; i < length; ++i) {\n        int64_t square_sum = A[i] * A[i] + B[i] * B[i];\n        int64_t product_sum = A[i] * B[i];\n        result += square_sum - product_sum;\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_41_Neon", "completion": "```c\nint64_t squarediff_simd(const int8_t * A, const int8_t * B, size_t length) {\n    int64_t sum_squares = 0;\n    int64_t sum_products = 0;\n    size_t i = 0;\n\n    int8x16_t zero = vdupq_n_s8(0);\n\n    for (; i <= length - 16; i += 16) {\n        int8x16_t va = vld1q_s8(A + i);\n        int8x16_t vb = vld1q_s8(B + i);\n\n        // Compute squares of A and B\n        int16x8_t sq_a_lo = vmovl_s8(vget_low_s8(va));\n        int16x8_t sq_a_hi = vmovl_high_s8(va);\n        int16x8_t sq_b_lo = vmovl_s8(vget_low_s8(vb));\n        int16x8_t sq_b_hi = vmovl_high_s8(vb);\n\n        sq_a_lo = vmulq_s16(sq_a_lo, sq_a_lo);\n        sq_a_hi = vmulq_s16(sq_a_hi, sq_a_hi);\n        sq_b_lo = vmulq_s16(sq_b_lo, sq_b_lo);\n        sq_b_hi = vmulq_s16(sq_b_hi, sq_b_hi);\n\n        int32x4_t sum_sq_a_lo = vpaddlq_s16(sq_a_lo);\n        int32x4_t sum_sq_a_hi = vpaddlq_s16(sq_a_hi);\n        int32x4_t sum_sq_b_lo = vpaddlq_s16(sq_b_lo);\n        int32x4_t sum_sq_b_hi = vpaddlq_s16(sq_b_hi);\n\n        int64x2_t res_sq_a = vpaddlq_s32(vaddq_s32(sum_sq_a_lo, sum_sq_a_hi));\n        int64x2_t res_sq_b = vpaddlq_s32(vaddq_s32(sum_sq_b_lo, sum_sq_b_hi));\n\n        sum_squares += vaddvq_s64(res_sq_a) + vaddvq_s64(res_sq_b);\n\n        // Compute products of A and B\n        int16x8_t prod_lo = vmull_s8(vget_low_s8(va), vget_low_s8(vb));\n        int16x8_t prod_hi = vmull_high_s8(va, vb);\n\n        int32x4_t sum_prod_lo = vpaddlq_s16(prod_lo);\n        int32x4_t sum_prod_hi = vpaddlq_s16(prod_hi);\n\n        int64x2_t res_prod = vpaddlq_s32(vaddq_s32(sum_prod_lo, sum_prod_hi));\n\n        sum_products += vaddvq_s64(res_prod);\n    }\n\n    for (; i < length; ++i) {\n        sum_squares += (int64_t)(A[i] * A[i]) + (int64_t)(B[i] * B[i]);\n        sum_products += (int64_t)(A[i] * B[i]);\n    }\n\n    return sum_squares - sum_products;\n}\n```"}
{"task_id": "SimdBench_41_Neon", "completion": "```c\n#include <arm_neon.h>\n\nint64_t squarediff_simd(const int8_t * A, const int8_t * B, size_t length) {\n    int64_t sum_squares = 0;\n    int64_t sum_products = 0;\n    \n    size_t i = 0;\n    for (; i <= length - 16; i += 16) {\n        int8x16_t a_vec = vld1q_s8(&A[i]);\n        int8x16_t b_vec = vld1q_s8(&B[i]);\n        \n        // Compute squares of A and B\n        int16x8_t a_sq_lo = vmulq_s8(vget_low_s8(a_vec), vget_low_s8(a_vec));\n        int16x8_t a_sq_hi = vmulq_s8(vget_high_s8(a_vec), vget_high_s8(a_vec));\n        int16x8_t b_sq_lo = vmulq_s8(vget_low_s8(b_vec), vget_low_s8(b_vec));\n        int16x8_t b_sq_hi = vmulq_s8(vget_high_s8(b_vec), vget_high_s8(b_vec));\n        \n        // Sum of squares\n        int32x4_t sum_sq_a_lo = vpaddlq_s16(a_sq_lo);\n        int32x4_t sum_sq_a_hi = vpaddlq_s16(a_sq_hi);\n        int32x4_t sum_sq_b_lo = vpaddlq_s16(b_sq_lo);\n        int32x4_t sum_sq_b_hi = vpaddlq_s16(b_sq_hi);\n        \n        int64x2_t sum_sq_a = vpaddlq_s32(vaddq_s32(sum_sq_a_lo, sum_sq_a_hi));\n        int64x2_t sum_sq_b = vpaddlq_s32(vaddq_s32(sum_sq_b_lo, sum_sq_b_hi));\n        \n        sum_squares += vaddvq_s64(sum_sq_a) + vaddvq_s64(sum_sq_b);\n        \n        // Compute products of A and B\n        int16x8_t prod_lo = vmulq_s8(vget_low_s8(a_vec), vget_low_s8(b_vec));\n        int16x8_t prod_hi = vmulq_s8(vget_high_s8(a_vec), vget_high_s8(b_vec));\n        \n        // Sum of products\n        int32x4_t sum_prod_lo = vpaddlq_s16(prod_lo);\n        int32x4_t sum_prod_hi = vpaddlq_s16(prod_hi);\n        \n        int64x2_t sum_prod = vpaddlq_s32(vaddq_s32(sum_prod_lo, sum_prod_hi));\n        \n        sum_products += vaddvq_s64(sum_prod);\n    }\n    \n    for (; i < length; i++) {\n        sum_squares += A[i] * A[i] + B[i] * B[i];\n        sum_products += A[i] * B[i];\n    }\n    \n    return sum_squares - sum_products;\n}\n```"}
{"task_id": "SimdBench_42_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid tensor_bit_clear_simd(const uint64_t* A, const uint64_t* B, uint64_t* C, size_t length) {\n    size_t i = 0;\n    for (; i + 2 <= length; i += 2) {\n        uint64x2_t vec_a = vld1q_u64((const uint64_t*)&A[i]);\n        uint64x2_t vec_b = vld1q_u64((const uint64_t*)&B[i]);\n        uint64x2_t vec_c = vandq_u64(vec_a, vmvnq_u64(vec_b));\n        vst1q_u64((uint64_t*)&C[i], vec_c);\n    }\n    for (; i < length; i++) {\n        C[i] = A[i] & ~B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_42_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid tensor_bit_clear_simd(const uint64_t* A, const uint64_t* B, uint64_t* C, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 2; i += 2) {\n        uint64x2_t a = vld1q_u64((const uint64_t*)&A[i]);\n        uint64x2_t b = vld1q_u64((const uint64_t*)&B[i]);\n        uint64x2_t c = vandq_u64(a, vmvnq_u64(b));\n        vst1q_u64((uint64_t*)&C[i], c);\n    }\n    for (; i < length; i++) {\n        C[i] = A[i] & ~B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_42_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid tensor_bit_clear_simd(const uint64_t* A, const uint64_t* B, uint64_t* C, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 2; i += 2) {\n        uint64x2_t a = vld1q_u64((const uint64_t*)&A[i]);\n        uint64x2_t b = vld1q_u64((const uint64_t*)&B[i]);\n        uint64x2_t c = vandq_u64(a, vmvnq_u64(b));\n        vst1q_u64((uint64_t*)&C[i], c);\n    }\n    for (; i < length; i++) {\n        C[i] = A[i] & ~B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_42_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid tensor_bit_clear_simd(const uint64_t* A, const uint64_t* B, uint64_t* C, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 2; i += 2) {\n        uint64x2_t a = vld1q_u64((const uint64_t*)&A[i]);\n        uint64x2_t b = vld1q_u64((const uint64_t*)&B[i]);\n        uint64x2_t c = vandq_u64(a, vmvnq_u64(b));\n        vst1q_u64((uint64_t*)&C[i], c);\n    }\n    for (; i < length; ++i) {\n        C[i] = A[i] & ~B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_42_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid tensor_bit_clear_simd(const uint64_t* A, const uint64_t* B, uint64_t* C, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 2; i += 2) {\n        uint64x2_t vec_a = vld1q_u64((const uint64_t*)&A[i]);\n        uint64x2_t vec_b = vld1q_u64((const uint64_t*)&B[i]);\n        uint64x2_t vec_c = vandq_u64(vec_a, vmvnq_u64(vec_b));\n        vst1q_u64((uint64_t*)&C[i], vec_c);\n    }\n    for (; i < length; ++i) {\n        C[i] = A[i] & ~B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_43_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid tensor_three_valued_logic_simd(const int8_t* A, const int8_t* B, int8_t* C, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 16; i += 16) {\n        int8x16_t a = vld1q_s8(&A[i]);\n        int8x16_t b = vld1q_s8(&B[i]);\n\n        int8x16_t pos_mask_a = vcgtq_s8(a, vdupq_n_s8(0));\n        int8x16_t pos_mask_b = vcgtq_s8(b, vdupq_n_s8(0));\n        int8x16_t neg_mask_a = vcltq_s8(a, vdupq_n_s8(0));\n        int8x16_t neg_mask_b = vcltq_s8(b, vdupq_n_s8(0));\n\n        uint8x16_t both_pos = vandq_u8(vreinterpretq_u8_s8(pos_mask_a), vreinterpretq_u8_s8(pos_mask_b));\n        uint8x16_t both_neg = vandq_u8(vreinterpretq_u8_s8(neg_mask_a), vreinterpretq_u8_s8(neg_mask_b));\n\n        int8x16_t result = vreinterpretq_s8_u8(vorrq_u8(vandq_u8(both_pos, vreinterpretq_u8_s8(vdupq_n_s8(1))),\n                                               vandq_u8(both_neg, vreinterpretq_u8_s8(vdupq_n_s8(-1)))));\n\n        vst1q_s8(&C[i], result);\n    }\n\n    for (; i < length; ++i) {\n        if (A[i] > 0 && B[i] > 0) {\n            C[i] = 1;\n        } else if (A[i] < 0 && B[i] < 0) {\n            C[i] = -1;\n        } else {\n            C[i] = 0;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_43_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid tensor_three_valued_logic_simd(const int8_t* A, const int8_t* B, int8_t* C, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 16; i += 16) {\n        int8x16_t a = vld1q_s8(A + i);\n        int8x16_t b = vld1q_s8(B + i);\n\n        int8x16_t pos_mask_a = vcgtq_s8(a, vdupq_n_s8(0));\n        int8x16_t pos_mask_b = vcgtq_s8(b, vdupq_n_s8(0));\n        int8x16_t neg_mask_a = vcltq_s8(a, vdupq_n_s8(0));\n        int8x16_t neg_mask_b = vcltq_s8(b, vdupq_n_s8(0));\n\n        int8x16_t pos_result = vandq_u8(pos_mask_a, pos_mask_b);\n        int8x16_t neg_result = vandq_u8(neg_mask_a, neg_mask_b);\n\n        int8x16_t one = vdupq_n_s8(1);\n        int8x16_t minus_one = vdupq_n_s8(-1);\n\n        int8x16_t result = vmulq_s8(pos_result, one);\n        result = vmlaq_s8(result, neg_result, minus_one);\n\n        vst1q_s8(C + i, result);\n    }\n\n    for (; i < length; ++i) {\n        if (A[i] > 0 && B[i] > 0) {\n            C[i] = 1;\n        } else if (A[i] < 0 && B[i] < 0) {\n            C[i] = -1;\n        } else {\n            C[i] = 0;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_43_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid tensor_three_valued_logic_simd(const int8_t* A, const int8_t* B, int8_t* C, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 16; i += 16) {\n        int8x16_t a = vld1q_s8(A + i);\n        int8x16_t b = vld1q_s8(B + i);\n\n        int8x16_t pos_mask_a = vcgeq_s8(a, vdupq_n_s8(0));\n        int8x16_t pos_mask_b = vcgeq_s8(b, vdupq_n_s8(0));\n        int8x16_t neg_mask_a = vcleq_s8(a, vdupq_n_s8(0));\n        int8x16_t neg_mask_b = vcleq_s8(b, vdupq_n_s8(0));\n\n        int8x16_t both_pos = vandq_u8(pos_mask_a, pos_mask_b);\n        int8x16_t both_neg = vandq_u8(neg_mask_a, neg_mask_b);\n\n        int8x16_t res_zero = vdupq_n_s8(0);\n        int8x16_t res_one = vdupq_n_s8(1);\n        int8x16_t res_neg_one = vdupq_n_s8(-1);\n\n        int8x16_t res = vbslq_s8(both_pos, res_one, res_zero);\n        res = vbslq_s8(both_neg, res_neg_one, res);\n\n        vst1q_s8(C + i, res);\n    }\n\n    for (; i < length; ++i) {\n        if (A[i] > 0 && B[i] > 0) {\n            C[i] = 1;\n        } else if (A[i] < 0 && B[i] < 0) {\n            C[i] = -1;\n        } else {\n            C[i] = 0;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_43_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid tensor_three_valued_logic_simd(const int8_t* A, const int8_t* B, int8_t* C, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 16; i += 16) {\n        int8x16_t va = vld1q_s8(A + i);\n        int8x16_t vb = vld1q_s8(B + i);\n\n        // Create masks for positive and negative values\n        uint8x16_t mask_pos_a = vcgtq_s8(va, vdupq_n_s8(0));\n        uint8x16_t mask_pos_b = vcgtq_s8(vb, vdupq_n_s8(0));\n        uint8x16_t mask_neg_a = vcltq_s8(va, vdupq_n_s8(0));\n        uint8x16_t mask_neg_b = vcltq_s8(vb, vdupq_n_s8(0));\n\n        // Both positive\n        uint8x16_t mask_both_pos = vandq_u8(mask_pos_a, mask_pos_b);\n        // Both negative\n        uint8x16_t mask_both_neg = vandq_u8(mask_neg_a, mask_neg_b);\n\n        // Set to 1 where both positive\n        int8x16_t res = vreinterpretq_s8_u8(vandq_u8(vdupq_n_u8(1), mask_both_pos));\n        // Set to -1 where both negative\n        int8x16_t neg_ones = vdupq_n_s8(-1);\n        res = vbslq_s8(mask_both_neg, neg_ones, res);\n\n        // Store the result\n        vst1q_s8(C + i, res);\n    }\n\n    // Handle remaining elements\n    for (; i < length; ++i) {\n        if (A[i] > 0 && B[i] > 0) {\n            C[i] = 1;\n        } else if (A[i] < 0 && B[i] < 0) {\n            C[i] = -1;\n        } else {\n            C[i] = 0;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_43_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid tensor_three_valued_logic_simd(const int8_t* A, const int8_t* B, int8_t* C, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 16; i += 16) {\n        int8x16_t a = vld1q_s8(A + i);\n        int8x16_t b = vld1q_s8(B + i);\n\n        int8x16_t pos_a = vcgeq_s8(a, vdupq_n_s8(0));\n        int8x16_t pos_b = vcgeq_s8(b, vdupq_n_s8(0));\n        int8x16_t neg_a = vcltq_s8(a, vdupq_n_s8(0));\n        int8x16_t neg_b = vcltq_s8(b, vdupq_n_s8(0));\n\n        int8x16_t both_pos = vandq_u8(pos_a, pos_b);\n        int8x16_t both_neg = vandq_u8(neg_a, neg_b);\n\n        int8x16_t res_pos = vreinterpretq_s8_u8(both_pos);\n        int8x16_t res_neg = vreinterpretq_s8_u8(both_neg);\n\n        res_pos = vandq_s8(res_pos, vdupq_n_s8(1));\n        res_neg = vandq_s8(res_neg, vdupq_n_s8(-1));\n\n        int8x16_t res = vorrq_s8(res_pos, res_neg);\n\n        vst1q_s8(C + i, res);\n    }\n    for (; i < length; ++i) {\n        if (A[i] > 0 && B[i] > 0) {\n            C[i] = 1;\n        } else if (A[i] < 0 && B[i] < 0) {\n            C[i] = -1;\n        } else {\n            C[i] = 0;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_44_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid tensor_bit_op_simd(const uint16_t* A, const uint16_t* B, uint16_t* C, size_t length) {\n    size_t midpoint = length / 2;\n    size_t i = 0;\n\n    // Process elements before the midpoint with XOR\n    for (; i <= length - 16 && i < midpoint; i += 8) {\n        uint16x8_t vec_a = vld1q_u16(A + i);\n        uint16x8_t vec_b = vld1q_u16(B + i);\n        uint16x8_t vec_c = veorq_u16(vec_a, vec_b);\n        vst1q_u16(C + i, vec_c);\n    }\n\n    // Process remaining scalar elements before midpoint if any\n    for (; i < midpoint; ++i) {\n        C[i] = A[i] ^ B[i];\n    }\n\n    // Store the midpoint element from A\n    if (midpoint < length) {\n        C[midpoint] = A[midpoint];\n        ++midpoint;\n    }\n\n    // Process elements after the midpoint with AND\n    i = midpoint;\n    for (; i <= length - 16; i += 8) {\n        uint16x8_t vec_a = vld1q_u16(A + i);\n        uint16x8_t vec_b = vld1q_u16(B + i);\n        uint16x8_t vec_c = vandq_u16(vec_a, vec_b);\n        vst1q_u16(C + i, vec_c);\n    }\n\n    // Process remaining scalar elements after midpoint if any\n    for (; i < length; ++i) {\n        C[i] = A[i] & B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_44_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid tensor_bit_op_simd(const uint16_t* A, const uint16_t* B, uint16_t* C, size_t length) {\n    size_t midpoint = length / 2;\n    size_t i = 0;\n\n    // Process elements before the midpoint with XOR\n    for (; i <= (length / 2) - 8; i += 8) {\n        uint16x8_t a = vld1q_u16(A + i);\n        uint16x8_t b = vld1q_u16(B + i);\n        uint16x8_t res = veorq_u16(a, b);\n        vst1q_u16(C + i, res);\n    }\n\n    // Handle remaining scalar elements before midpoint\n    for (; i < midpoint; ++i) {\n        C[i] = A[i] ^ B[i];\n    }\n\n    // Store the midpoint value from A\n    C[midpoint] = A[midpoint];\n\n    // Process elements after the midpoint with AND\n    for (i = midpoint + 1; i <= length - 8; i += 8) {\n        uint16x8_t a = vld1q_u16(A + i);\n        uint16x8_t b = vld1q_u16(B + i);\n        uint16x8_t res = vandq_u16(a, b);\n        vst1q_u16(C + i, res);\n    }\n\n    // Handle remaining scalar elements after midpoint\n    for (; i < length; ++i) {\n        C[i] = A[i] & B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_44_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid tensor_bit_op_simd(const uint16_t* A, const uint16_t* B, uint16_t* C, size_t length) {\n    size_t half = length / 2;\n    size_t i = 0;\n\n    // Process elements before the midpoint with XOR\n    for (; i + 8 <= half; i += 8) {\n        uint16x8_t a = vld1q_u16(A + i);\n        uint16x8_t b = vld1q_u16(B + i);\n        uint16x8_t res = veorq_u16(a, b);\n        vst1q_u16(C + i, res);\n    }\n\n    // Handle remaining elements before the midpoint with scalar if necessary\n    for (; i < half; ++i) {\n        C[i] = A[i] ^ B[i];\n    }\n\n    // Store the midpoint value from A\n    if (length > 1) {\n        C[half] = A[half];\n        ++half;\n    }\n\n    // Process elements after the midpoint with AND\n    for (i = half; i + 8 <= length; i += 8) {\n        uint16x8_t a = vld1q_u16(A + i);\n        uint16x8_t b = vld1q_u16(B + i);\n        uint16x8_t res = vandq_u16(a, b);\n        vst1q_u16(C + i, res);\n    }\n\n    // Handle remaining elements after the midpoint with scalar if necessary\n    for (; i < length; ++i) {\n        C[i] = A[i] & B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_44_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid tensor_bit_op_simd(const uint16_t* A, const uint16_t* B, uint16_t* C, size_t length) {\n    size_t half_length = length / 2;\n    size_t i = 0;\n\n    // Process elements before the midpoint with XOR\n    for (; i <= (length - 8); i += 8) {\n        if (i >= half_length) break;\n        uint16x8_t vec_a = vld1q_u16(A + i);\n        uint16x8_t vec_b = vld1q_u16(B + i);\n        uint16x8_t vec_c = veorq_u16(vec_a, vec_b);\n        vst1q_u16(C + i, vec_c);\n    }\n\n    // Handle remaining scalar elements before midpoint if any\n    for (; i < half_length; ++i) {\n        C[i] = A[i] ^ B[i];\n    }\n\n    // Store the midpoint element from A\n    if (half_length < length) {\n        C[half_length] = A[half_length];\n        ++i;\n    }\n\n    // Process elements after the midpoint with AND\n    for (; i <= (length - 8); i += 8) {\n        uint16x8_t vec_a = vld1q_u16(A + i);\n        uint16x8_t vec_b = vld1q_u16(B + i);\n        uint16x8_t vec_c = vandq_u16(vec_a, vec_b);\n        vst1q_u16(C + i, vec_c);\n    }\n\n    // Handle remaining scalar elements after midpoint if any\n    for (; i < length; ++i) {\n        C[i] = A[i] & B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_44_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid tensor_bit_op_simd(const uint16_t* A, const uint16_t* B, uint16_t* C, size_t length) {\n    size_t half_length = length / 2;\n    size_t i = 0;\n\n    // Process elements before the midpoint with XOR\n    for (; i + 8 <= half_length; i += 8) {\n        uint16x8_t a = vld1q_u16(&A[i]);\n        uint16x8_t b = vld1q_u16(&B[i]);\n        uint16x8_t c = veorq_u16(a, b);\n        vst1q_u16(&C[i], c);\n    }\n    for (; i < half_length; i++) {\n        C[i] = A[i] ^ B[i];\n    }\n\n    // Copy the element at the midpoint from A to C\n    if (length > 0) {\n        C[half_length] = A[half_length];\n        i = half_length + 1;\n    } else {\n        i = 0;\n    }\n\n    // Process elements after the midpoint with AND\n    for (; i + 8 <= length; i += 8) {\n        uint16x8_t a = vld1q_u16(&A[i]);\n        uint16x8_t b = vld1q_u16(&B[i]);\n        uint16x8_t c = vandq_u16(a, b);\n        vst1q_u16(&C[i], c);\n    }\n    for (; i < length; i++) {\n        C[i] = A[i] & B[i];\n    }\n}\n```"}
{"task_id": "SimdBench_45_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid tensor_multi_select_simd(const float* A, const float* B, const float* C, const float* D, const bool* cond1, const bool* cond2, float* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_size = dim1 * dim2 * dim3;\n    for (size_t i = 0; i < total_size; i += 4) {\n        float32x4_t vA = vld1q_f32(&A[i]);\n        float32x4_t vB = vld1q_f32(&B[i]);\n        float32x4_t vC = vld1q_f32(&C[i]);\n        float32x4_t vD = vld1q_f32(&D[i]);\n\n        uint32x4_t vcond1 = vld1q_u32((const uint32_t*)&cond1[i]);\n        uint32x4_t vcond2 = vld1q_u32((const uint32_t*)&cond2[i]);\n\n        uint32x4_t mask_cond1 = vandq_u32(vcond1, vcond2); // cond1 && cond2\n        uint32x4_t mask_cond2 = vandq_u32(vcond1, vmvnq_u32(vcond2)); // cond1 && !cond2\n        uint32x4_t mask_cond3 = vandq_u32(vmvnq_u32(vcond1), vcond2); // !cond1 && cond2\n        uint32x4_t mask_cond4 = vandq_u32(vmvnq_u32(vcond1), vmvnq_u32(vcond2)); // !cond1 && !cond2\n\n        float32x4_t selected_A = vbslq_f32(mask_cond1, vA, vB);\n        float32x4_t selected_B = vbslq_f32(mask_cond2, vB, vC);\n        float32x4_t selected_C = vbslq_f32(mask_cond3, vC, vD);\n        float32x4_t selected_D = vbslq_f32(mask_cond4, vD, selected_C);\n\n        float32x4_t result = vbslq_f32(mask_cond1, selected_A, selected_B);\n        result = vbslq_f32(mask_cond4, selected_D, result);\n\n        vst1q_f32(&out[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_45_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid tensor_multi_select_simd(const float* A, const float* B, const float* C, const float* D, const bool* cond1, const bool* cond2, float* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    for (size_t i = 0; i < total_elements; i += 4) {\n        float32x4_t vA = vld1q_f32(&A[i]);\n        float32x4_t vB = vld1q_f32(&B[i]);\n        float32x4_t vC = vld1q_f32(&C[i]);\n        float32x4_t vD = vld1q_f32(&D[i]);\n\n        uint32x4_t vCond1 = vreinterpretq_u32_f32(vld1q_f32((const float32_t*)&cond1[i]));\n        uint32x4_t vCond2 = vreinterpretq_u32_f32(vld1q_f32((const float32_t*)&cond2[i]));\n\n        uint32x4_t mask_cond1 = vceqq_u32(vCond1, vdupq_n_u32(1));\n        uint32x4_t mask_cond2 = vceqq_u32(vCond2, vdupq_n_u32(1));\n\n        uint32x4_t mask_both_true = vmovemask_f32((float32x4_t)vandq_u32(mask_cond1, mask_cond2));\n        uint32x4_t mask_cond1_true_cond2_false = vbicq_u32(mask_cond1, mask_cond2);\n        uint32x4_t mask_cond1_false_cond2_true = vbicq_u32(mask_cond2, mask_cond1);\n        uint32x4_t mask_both_false = vbicq_u32(vmvsq_u32(mask_cond1), mask_cond2);\n\n        float32x4_t selected_A = vbslq_f32(mask_both_true, vA, vD);\n        float32x4_t selected_B = vbslq_f32(mask_cond1_true_cond2_false, vB, selected_A);\n        float32x4_t selected_C = vbslq_f32(mask_cond1_false_cond2_true, vC, selected_B);\n        float32x4_t result = vbslq_f32(mask_both_false, vD, selected_C);\n\n        vst1q_f32(&out[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_45_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid tensor_multi_select_simd(const float* A, const float* B, const float* C, const float* D, const bool* cond1, const bool* cond2, float* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_size = dim1 * dim2 * dim3;\n    size_t i = 0;\n\n    for (; i <= total_size - 4; i += 4) {\n        uint32x4_t c1 = vld1q_u32((const uint32_t*)&cond1[i]);\n        uint32x4_t c2 = vld1q_u32((const uint32_t*)&cond2[i]);\n\n        float32x4_t a_val = vld1q_f32(&A[i]);\n        float32x4_t b_val = vld1q_f32(&B[i]);\n        float32x4_t c_val = vld1q_f32(&C[i]);\n        float32x4_t d_val = vld1q_f32(&D[i]);\n\n        uint32x4_t mask_c1 = vcgeq_f32(vcvtq_f32_u32(c1), vdupq_n_f32(0.5f));\n        uint32x4_t mask_c2 = vcgeq_f32(vcvtq_f32_u32(c2), vdupq_n_f32(0.5f));\n\n        uint32x4_t mask_both = vandq_u32(mask_c1, mask_c2);\n        uint32x4_t mask_c1_not_c2 = vbicq_u32(mask_c1, mask_c2);\n        uint32x4_t mask_not_c1_c2 = vbicq_u32(mask_c2, mask_c1);\n        uint32x4_t mask_neither = vbicq_u32(vmvnq_u32(mask_c1), mask_c2);\n\n        float32x4_t res_a = vbslq_f32(mask_both, a_val, d_val);\n        float32x4_t res_b = vbslq_f32(mask_c1_not_c2, b_val, res_a);\n        float32x4_t res_c = vbslq_f32(mask_not_c1_c2, c_val, res_b);\n        float32x4_t res_d = vbslq_f32(mask_neither, d_val, res_c);\n\n        vst1q_f32(&out[i], res_d);\n    }\n\n    for (; i < total_size; ++i) {\n        if (cond1[i] && cond2[i]) {\n            out[i] = A[i];\n        } else if (cond1[i] && !cond2[i]) {\n            out[i] = B[i];\n        } else if (!cond1[i] && cond2[i]) {\n            out[i] = C[i];\n        } else {\n            out[i] = D[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_45_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid tensor_multi_select_simd(const float* A, const float* B, const float* C, const float* D, const bool* cond1, const bool* cond2, float* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_size = dim1 * dim2 * dim3;\n    for (size_t i = 0; i < total_size; i += 4) {\n        float32x4_t vA = vld1q_f32(&A[i]);\n        float32x4_t vB = vld1q_f32(&B[i]);\n        float32x4_t vC = vld1q_f32(&C[i]);\n        float32x4_t vD = vld1q_f32(&D[i]);\n\n        uint32x4_t vcond1 = vld1q_u32((const uint32_t*)&cond1[i]);\n        uint32x4_t vcond2 = vld1q_u32((const uint32_t*)&cond2[i]);\n\n        uint32x4_t mask_cond1 = vmovemask_f32(vreinterpretq_f32_u32(vcond1));\n        uint32x4_t mask_cond2 = vmovemask_f32(vreinterpretq_f32_u32(vcond2));\n\n        uint32x4_t mask1_and_2 = vandq_u32(vcond1, vcond2);\n        uint32x4_t mask1_not2 = vbicq_u32(vcond1, vcond2);\n        uint32x4_t masknot1_2 = vbicq_u32(vcond2, vcond1);\n        uint32x4_t masknot1_not2 = vbicq_u32(vmvnq_u32(vcond1), vcond2);\n\n        float32x4_t selected_A = vbslq_f32(mask1_and_2, vA, vB);\n        float32x4_t selected_B = vbslq_f32(mask1_not2, vB, vC);\n        float32x4_t selected_C = vbslq_f32(masknot1_2, vC, vD);\n        float32x4_t selected_D = vbslq_f32(masknot1_not2, vD, selected_C);\n\n        float32x4_t result = vorrq_f32(vorrq_f32(vandq_f32(mask1_and_2, vA), vandq_f32(mask1_not2, vB)), vorrq_f32(vandq_f32(masknot1_2, vC), vandq_f32(masknot1_not2, vD)));\n\n        vst1q_f32(&out[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_45_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid tensor_multi_select_simd(const float* A, const float* B, const float* C, const float* D, const bool* cond1, const bool* cond2, float* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_size = dim1 * dim2 * dim3;\n    for (size_t i = 0; i < total_size; i += 4) {\n        float32x4_t vA = vld1q_f32(&A[i]);\n        float32x4_t vB = vld1q_f32(&B[i]);\n        float32x4_t vC = vld1q_f32(&C[i]);\n        float32x4_t vD = vld1q_f32(&D[i]);\n\n        uint32x4_t vCond1 = vld1q_u32((const uint32_t*)&cond1[i]);\n        uint32x4_t vCond2 = vld1q_u32((const uint32_t*)&cond2[i]);\n\n        uint32x4_t mask_cond1 = vceqq_u32(vCond1, vdupq_n_u32(1));\n        uint32x4_t mask_cond2 = vceqq_u32(vCond2, vdupq_n_u32(1));\n\n        uint32x4_t mask_and = vandq_u32(mask_cond1, mask_cond2);\n        uint32x4_t mask_not_cond1_and_cond2 = vbicq_u32(mask_cond2, mask_cond1);\n        uint32x4_t mask_not_cond2_and_cond1 = vbicq_u32(mask_cond1, mask_cond2);\n        uint32x4_t mask_not_cond1_not_cond2 = vbicq_u32(vmvnq_u32(mask_cond1), mask_cond2);\n\n        float32x4_t selected_A = vbslq_f32(mask_and, vA, vD);\n        float32x4_t selected_B = vbslq_f32(mask_not_cond2_and_cond1, vB, selected_A);\n        float32x4_t selected_C = vbslq_f32(mask_not_cond1_and_cond2, vC, selected_B);\n        float32x4_t result = vbslq_f32(mask_not_cond1_not_cond2, vD, selected_C);\n\n        vst1q_f32(&out[i], result);\n    }\n}\n```"}
{"task_id": "SimdBench_46_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid tensor_bit_count_simd(const uint32_t* A, uint8_t* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_size = dim1 * dim2 * dim3;\n    for (size_t i = 0; i < total_size; i += 16) {\n        uint32x4_t vec_a1 = vld1q_u32(A + i);\n        uint32x4_t vec_a2 = vld1q_u32(A + i + 4);\n        uint32x4_t vec_a3 = vld1q_u32(A + i + 8);\n        uint32x4_t vec_a4 = vld1q_u32(A + i + 12);\n\n        uint32x4_t cnt1 = vcntq_u32(vec_a1);\n        uint32x4_t cnt2 = vcntq_u32(vec_a2);\n        uint32x4_t cnt3 = vcntq_u32(vec_a3);\n        uint32x4_t cnt4 = vcntq_u32(vec_a4);\n\n        uint8x8_t res1 = vreinterpret_u8_u32(vshrn_n_u32(cnt1, 24));\n        uint8x8_t res2 = vreinterpret_u8_u32(vshrn_n_u32(cnt2, 24));\n        uint8x8_t res3 = vreinterpret_u8_u32(vshrn_n_u32(cnt3, 24));\n        uint8x8_t res4 = vreinterpret_u8_u32(vshrn_n_u32(cnt4, 24));\n\n        vst1_u8(out + i, res1);\n        vst1_u8(out + i + 8, res2);\n        if (i + 16 < total_size) {\n            vst1_u8(out + i + 16, res3);\n            vst1_u8(out + i + 24, res4);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_46_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid tensor_bit_count_simd(const uint32_t* A, uint8_t* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_size = dim1 * dim2 * dim3;\n    for (size_t i = 0; i < total_size; i += 16) {\n        uint32x4_t vec_a1 = vld1q_u32(A + i);\n        uint32x4_t vec_a2 = vld1q_u32(A + i + 4);\n        uint32x4_t vec_a3 = vld1q_u32(A + i + 8);\n        uint32x4_t vec_a4 = vld1q_u32(A + i + 12);\n\n        uint32x4_t cnt1 = vcntq_u32(vec_a1);\n        uint32x4_t cnt2 = vcntq_u32(vec_a2);\n        uint32x4_t cnt3 = vcntq_u32(vec_a3);\n        uint32x4_t cnt4 = vcntq_u32(vec_a4);\n\n        uint8x8_t res1 = vreinterpret_u8_u32(cnt1);\n        uint8x8_t res2 = vreinterpret_u8_u32(cnt2);\n        uint8x8_t res3 = vreinterpret_u8_u32(cnt3);\n        uint8x8_t res4 = vreinterpret_u8_u32(cnt4);\n\n        vst1_u8(out + i, res1);\n        vst1_u8(out + i + 8, res2);\n        if (i + 16 < total_size) {\n            vst1_u8(out + i + 16, res3);\n            vst1_u8(out + i + 24, res4);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_46_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid tensor_bit_count_simd(const uint32_t* A, uint8_t* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_size = dim1 * dim2 * dim3;\n    for (size_t i = 0; i < total_size; i += 16) {\n        uint32x4_t vec_a1 = vld1q_u32(A + i);\n        uint32x4_t vec_a2 = vld1q_u32(A + i + 4);\n        uint32x4_t vec_a3 = vld1q_u32(A + i + 8);\n        uint32x4_t vec_a4 = vld1q_u32(A + i + 12);\n\n        uint32x4_t cnt1 = vcntq_u32(vec_a1);\n        uint32x4_t cnt2 = vcntq_u32(vec_a2);\n        uint32x4_t cnt3 = vcntq_u32(vec_a3);\n        uint32x4_t cnt4 = vcntq_u32(vec_a4);\n\n        uint8x8_t res1 = vreinterpret_u8_u32(vmovn_u32(cnt1));\n        uint8x8_t res2 = vreinterpret_u8_u32(vmovn_u32(cnt2));\n        uint8x8_t res3 = vreinterpret_u8_u32(vmovn_u32(cnt3));\n        uint8x8_t res4 = vreinterpret_u8_u32(vmovn_u32(cnt4));\n\n        vst1_u8(out + i, vcombine_u8(res1, res2));\n        vst1_u8(out + i + 16, vcombine_u8(res3, res4));\n    }\n}\n```"}
{"task_id": "SimdBench_46_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid tensor_bit_count_simd(const uint32_t* A, uint8_t* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_size = dim1 * dim2 * dim3;\n    for (size_t i = 0; i < total_size; i += 16) {\n        uint32x4_t vec_a1 = vld1q_u32(A + i);\n        uint32x4_t vec_a2 = vld1q_u32(A + i + 4);\n        uint32x4_t vec_a3 = vld1q_u32(A + i + 8);\n        uint32x4_t vec_a4 = vld1q_u32(A + i + 12);\n\n        uint32x4_t cnt1 = vcntq_u32(vec_a1);\n        uint32x4_t cnt2 = vcntq_u32(vec_a2);\n        uint32x4_t cnt3 = vcntq_u32(vec_a3);\n        uint32x4_t cnt4 = vcntq_u32(vec_a4);\n\n        uint8x8_t res1 = vmovn_u16(vreinterpretq_u16_u32(cnt1));\n        uint8x8_t res2 = vmovn_u16(vreinterpretq_u16_u32(cnt2));\n        uint8x8_t res3 = vmovn_u16(vreinterpretq_u16_u32(cnt3));\n        uint8x8_t res4 = vmovn_u16(vreinterpretq_u16_u32(cnt4));\n\n        vst1_u8(out + i, vcombine_u8(res1, res2));\n        vst1_u8(out + i + 8, vcombine_u8(res3, res4));\n    }\n}\n```"}
{"task_id": "SimdBench_46_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid tensor_bit_count_simd(const uint32_t* A, uint8_t* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_size = dim1 * dim2 * dim3;\n    for (size_t i = 0; i <= total_size - 16; i += 16) {\n        uint32x4_t vec_a1 = vld1q_u32(A + i);\n        uint32x4_t vec_a2 = vld1q_u32(A + i + 4);\n        uint32x4_t vec_a3 = vld1q_u32(A + i + 8);\n        uint32x4_t vec_a4 = vld1q_u32(A + i + 12);\n\n        uint8x8_t vec_popcnt1 = vcnt_u8(vreinterpret_u8_u32(vec_a1));\n        uint8x8_t vec_popcnt2 = vcnt_u8(vreinterpret_u8_u32(vec_a2));\n        uint8x8_t vec_popcnt3 = vcnt_u8(vreinterpret_u8_u32(vec_a3));\n        uint8x8_t vec_popcnt4 = vcnt_u8(vreinterpret_u8_u32(vec_a4));\n\n        uint8x8_t sum1 = vpaddl_u8(vec_popcnt1);\n        uint8x8_t sum2 = vpaddl_u8(vec_popcnt2);\n        uint8x8_t sum3 = vpaddl_u8(vec_popcnt3);\n        uint8x8_t sum4 = vpaddl_u8(vec_popcnt4);\n\n        uint8x8_t result = vcombine_u8(vget_low_u8(sum1), vget_low_u8(sum2));\n        uint8x8_t result2 = vcombine_u8(vget_low_u8(sum3), vget_low_u8(sum4));\n\n        vst1_u8(out + i, result);\n        vst1_u8(out + i + 8, result2);\n    }\n\n    // Handle remaining elements\n    for (size_t i = total_size - (total_size % 16); i < total_size; ++i) {\n        out[i] = __builtin_popcount(A[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_47_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid matrix_conditional_abs_simd(const int* A, int* B, size_t rows, size_t cols) {\n    size_t length = rows * cols;\n    size_t i = 0;\n\n    for (; i <= length - 4; i += 4) {\n        int32x4_t vec_a = vld1q_s32(&A[i]);\n        int32x4_t vec_three = vdupq_n_s32(3);\n\n        int32x4_t remainder = vremq_s32(vec_a, vec_three);\n        uint32x4_t mask = vceqq_s32(remainder, vdupq_n_s32(0));\n\n        int32x4_t abs_vec_a = vabsq_s32(vec_a);\n        int32x4_t result = vbslq_s32(mask, abs_vec_a, vec_a);\n\n        vst1q_s32(&B[i], result);\n    }\n\n    for (; i < length; i++) {\n        if (A[i] % 3 == 0) {\n            B[i] = abs(A[i]);\n        } else {\n            B[i] = A[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_47_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid matrix_conditional_abs_simd(const int* A, int* B, size_t rows, size_t cols) {\n    size_t total = rows * cols;\n    size_t i = 0;\n\n    for (; i <= total - 4; i += 4) {\n        int32x4_t vec_a = vld1q_s32(&A[i]);\n        int32x4_t zero = vmovq_n_s32(0);\n        uint32x4_t mask = vmovq_n_u32(0);\n\n        // Compute A % 3 == 0\n        int32x4_t mod_3 = vabsq_s32(vsubq_s32(vec_a, vmulq_s32(vshrq_n_s32(vec_a, 31), vmovq_n_s32(3))));\n        mod_3 = vandq_s32(mod_3, vmovq_n_s32(1));\n        mask = vcgeq_s32(mod_3, vmovq_n_s32(0));\n\n        // Compute abs(A)\n        int32x4_t abs_a = vabsq_s32(vec_a);\n\n        // Select abs(A) where divisible by 3, else A\n        int32x4_t result = vbslq_s32(mask, abs_a, vec_a);\n\n        // Store the result\n        vst1q_s32(&B[i], result);\n    }\n\n    // Handle remaining elements\n    for (; i < total; ++i) {\n        if (A[i] % 3 == 0) {\n            B[i] = abs(A[i]);\n        } else {\n            B[i] = A[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_47_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid matrix_conditional_abs_simd(const int* A, int* B, size_t rows, size_t cols) {\n    size_t length = rows * cols;\n    size_t i = 0;\n\n    for (; i <= length - 4; i += 4) {\n        int32x4_t vec_a = vld1q_s32(&A[i]);\n        int32x4_t zero = vmovq_n_s32(0);\n        int32x4_t three = vmovq_n_s32(3);\n\n        // Compute A % 3 == 0\n        int32x4_t mod_three = vmlaq_s32(zero, vec_a, vmovq_n_s32(0)); // Placeholder for modulo operation\n        uint32x4_t cond = vcgeq_s32(mod_three, zero); // Condition: divisible by 3\n\n        // Compute abs(A)\n        int32x4_t abs_a = vabsq_s32(vec_a);\n\n        // Select abs(A) if divisible by 3, else A\n        int32x4_t result = vbslq_s32(cond, abs_a, vec_a);\n\n        vst1q_s32(&B[i], result);\n    }\n\n    for (; i < length; i++) {\n        B[i] = (A[i] % 3 == 0) ? abs(A[i]) : A[i];\n    }\n}\n```"}
{"task_id": "SimdBench_47_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid matrix_conditional_abs_simd(const int* A, int* B, size_t rows, size_t cols) {\n    size_t length = rows * cols;\n    size_t i = 0;\n\n    for (; i <= length - 4; i += 4) {\n        int32x4_t vec_a = vld1q_s32(&A[i]);\n        int32x4_t vec_three = vdupq_n_s32(3);\n\n        // Compute remainder (vec_a % 3)\n        int32x4_t vec_mod = vabsq_s32(vsubq_s32(vec_a, vmulq_s32(vec_three, vshrq_n_s32(vec_a, 31))));\n        uint32x4_t mask = vcgeq_s32(vec_mod, vec_three);\n        int32x4_t cond = vandq_s32(mask, vec_three);\n        int32x4_t is_divisible = vceqq_s32(cond, vec_three);\n\n        // Absolute value of vec_a\n        int32x4_t abs_vec_a = vabsq_s32(vec_a);\n\n        // Select between abs_vec_a and vec_a based on divisibility\n        int32x4_t result = vbslq_s32(is_divisible, abs_vec_a, vec_a);\n\n        // Store the result\n        vst1q_s32(&B[i], result);\n    }\n\n    // Handle remaining elements\n    for (; i < length; ++i) {\n        if (A[i] % 3 == 0) {\n            B[i] = abs(A[i]);\n        } else {\n            B[i] = A[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_47_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid matrix_conditional_abs_simd(const int* A, int* B, size_t rows, size_t cols) {\n    size_t total = rows * cols;\n    size_t i = 0;\n\n    for (; i <= total - 4; i += 4) {\n        int32x4_t vec_a = vld1q_s32(&A[i]);\n        \n        // Compute A % 3 == 0\n        int32x4_t vec_mod = vmovq_n_s32(3);\n        uint32x4_t cond = vceqq_s32(vremq_s32(vec_a, vec_mod), vmovq_n_s32(0));\n        \n        // Compute abs(A)\n        int32x4_t vec_abs = vabsq_s32(vec_a);\n        \n        // Select values based on condition\n        int32x4_t result = vbslq_s32(cond, vec_abs, vec_a);\n        \n        // Store the result\n        vst1q_s32(&B[i], result);\n    }\n\n    // Handle remaining elements\n    for (; i < total; ++i) {\n        if (A[i] % 3 == 0) {\n            B[i] = abs(A[i]);\n        } else {\n            B[i] = A[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_48_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid matrix_conditional_bit_rotate_simd(const uint32_t* src, uint32_t* dst, uint8_t rotate_bits, size_t length){\n    size_t i = 0;\n    for (; i <= length - 4; i += 4) {\n        uint32x4_t vsrc = vld1q_u32(src + i);\n        uint32x4_t vmask = vcgeq_u32(vandq_u32(vsrc, vdupq_n_u32(0xF)), vdupq_n_u32(0xF));\n        \n        uint32x4_t rotated = vreinterpretq_u32_u64(vrshlq_u64(vreinterpretq_u64_u32(vsrc), vdupq_n_u64(rotate_bits)));\n        uint32x4_t negated = vbicq_u32(vdupq_n_u32(0xFFFFFFFF), vsrc);\n\n        uint32x4_t result = vbslq_u32(vmask, rotated, negated);\n        vst1q_u32(dst + i, result);\n    }\n    for (; i < length; ++i) {\n        uint32_t val = src[i];\n        if ((val & 0xF) == 0xF) {\n            dst[i] = (val >> rotate_bits) | (val << (32 - rotate_bits));\n        } else {\n            dst[i] = ~val;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_48_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid matrix_conditional_bit_rotate_simd(const uint32_t* src, uint32_t* dst, uint8_t rotate_bits, size_t length){\n    size_t i = 0;\n    uint8x16_t vbroadcast = vdupq_n_u8(rotate_bits);\n    \n    for (; i <= length - 16; i += 16) {\n        uint32x4_t vsrc_low = vld1q_u32(src + i);\n        uint32x4_t vsrc_high = vld1q_u32(src + i + 4);\n\n        // Extract low 4 bits\n        uint32x4_t vcond_low = vmovn_high_u16(vshrn_n_u32(vsrc_low, 28));\n        uint32x4_t vcond_high = vmovn_high_u16(vshrn_n_u32(vsrc_high, 28));\n\n        // Check if low 4 bits are all 1s (0xF)\n        uint32x4_t vcmp_low = vcmeq_u32(vcond_low, vdupq_n_u32(0xF));\n        uint32x4_t vcmp_high = vcmeq_u32(vcond_high, vdupq_n_u32(0xF));\n\n        // Rotate right by rotate_bits\n        uint32x4_t vrot_low = vreinterpretq_u32_u8(vshrq_n_u8(vreinterpretq_u8_u32(vsrc_low), vbroadcast));\n        uint32x4_t vrot_high = vreinterpretq_u32_u8(vshrq_n_u8(vreinterpretq_u8_u32(vsrc_high), vbroadcast));\n\n        // Bitwise negation\n        uint32x4_t vneg_low = vmvnq_u32(vsrc_low);\n        uint32x4_t vneg_high = vmvnq_u32(vsrc_high);\n\n        // Conditional select\n        uint32x4_t vres_low = vbslq_u32(vcmp_low, vrot_low, vneg_low);\n        uint32x4_t vres_high = vbslq_u32(vcmp_high, vrot_high, vneg_high);\n\n        // Store results\n        vst1q_u32(dst + i, vres_low);\n        vst1q_u32(dst + i + 4, vres_high);\n    }\n\n    // Handle remaining elements\n    for (; i < length; ++i) {\n        uint32_t val = src[i];\n        if ((val & 0xF) == 0xF) {\n            dst[i] = (val >> rotate_bits) | (val << (32 - rotate_bits));\n        } else {\n            dst[i] = ~val;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_48_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid matrix_conditional_bit_rotate_simd(const uint32_t* src, uint32_t* dst, uint8_t rotate_bits, size_t length){\n    size_t i = 0;\n    for (; i <= length - 4; i += 4) {\n        uint32x4_t vsrc = vld1q_u32(src + i);\n        \n        // Check if low 4 bits are all 1 (0xF)\n        uint32x4_t mask = vmovq_n_u32(0xF);\n        uint32x4_t cond = vandq_u32(vsrc, mask);\n        uint32x4_t cmp = vmovq_n_u32(0xF);\n        uint32x4_t result_cond = vceqq_u32(cond, cmp);\n\n        // Rotate right by rotate_bits\n        uint32x4_t rotated = vreinterpretq_u32_u8(vshrq_n_u8(vreinterpretq_u8_u32(vsrc), rotate_bits));\n\n        // Bitwise negation\n        uint32x4_t negated = vmvnq_u32(vsrc);\n\n        // Select based on condition\n        uint32x4_t result = vbslq_u32(result_cond, rotated, negated);\n\n        // Store the result\n        vst1q_u32(dst + i, result);\n    }\n    // Handle remaining elements\n    for (; i < length; ++i) {\n        uint32_t val = src[i];\n        if ((val & 0xF) == 0xF) {\n            dst[i] = (val >> rotate_bits) | (val << (32 - rotate_bits));\n        } else {\n            dst[i] = ~val;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_48_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid matrix_conditional_bit_rotate_simd(const uint32_t* src, uint32_t* dst, uint8_t rotate_bits, size_t length){\n    uint32x4_t vrotate = vdupq_n_u32(rotate_bits);\n    for (size_t i = 0; i < length / 4; ++i) {\n        uint32x4_t vsrc = vld1q_u32(src + 4 * i);\n        uint32x4_t vcond = vcgeq_u32(vandq_u32(vsrc, vdupq_n_u32(0xF)), vdupq_n_u32(0xF));\n        \n        uint32x4_t rotated = vshrq_n_u32(vsrc, rotate_bits);\n        uint32x4_t negated = vmvnq_u32(vsrc);\n        \n        uint32x4_t result = vbslq_u32(vcond, rotated, negated);\n        vst1q_u32(dst + 4 * i, result);\n    }\n    // Handle remaining elements if length is not a multiple of 4\n    for (size_t i = (length / 4) * 4; i < length; ++i) {\n        uint32_t val = src[i];\n        if ((val & 0xF) == 0xF) {\n            dst[i] = (val >> rotate_bits) | (val << (32 - rotate_bits));\n        } else {\n            dst[i] = ~val;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_48_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid matrix_conditional_bit_rotate_simd(const uint32_t* src, uint32_t* dst, uint8_t rotate_bits, size_t length){\n    size_t i = 0;\n    for (; i <= length - 4; i += 4) {\n        uint32x4_t vsrc = vld1q_u32(src + i);\n        \n        // Check if low 4 bits are all 1 (i.e., 0xF)\n        uint32x4_t mask_val = vmovq_n_u32(0xF);\n        uint32x4_t condition = vceqq_u32(vandq_u32(vsrc, mask_val), mask_val);\n        \n        // Perform rotation for true condition\n        uint32x4_t rotated = vreinterpretq_u32_u8(vextq_u8(vreinterpretq_u8_u32(vsrc), vreinterpretq_u8_u32(vsrc), rotate_bits));\n        \n        // Perform bitwise negation for false condition\n        uint32x4_t negated = vmvnq_u32(vsrc);\n        \n        // Select based on condition\n        uint32x4_t result = vbslq_u32(condition, rotated, negated);\n        \n        // Store the result\n        vst1q_u32(dst + i, result);\n    }\n    // Handle remaining elements (if any)\n    for (; i < length; ++i) {\n        uint32_t val = src[i];\n        if ((val & 0xF) == 0xF) {\n            dst[i] = (val >> rotate_bits) | (val << (32 - rotate_bits));\n        } else {\n            dst[i] = ~val;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_49_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid tensor_ternary_compare_simd(const float* A, const float* B, int8_t* out, float epsilon, size_t length) {\n    float32x4_t vec_eps = vdupq_n_f32(epsilon);\n    int32x4_t vec_zero = vmovq_n_s32(0);\n    int8x8_t vec_one = vdup_n_s8(1);\n    int8x8_t vec_neg_one = vdup_n_s8(-1);\n\n    size_t i = 0;\n    for (; i <= length - 4; i += 4) {\n        float32x4_t vec_a = vld1q_f32(&A[i]);\n        float32x4_t vec_b = vld1q_f32(&B[i]);\n\n        float32x4_t diff = vsubq_f32(vec_a, vec_b);\n        float32x4_t abs_diff = vabsq_f32(diff);\n        float32x4_t abs_eps = vabsq_f32(vec_eps);\n\n        uint32x4_t gt_mask = vcgtq_f32(diff, vec_eps);\n        uint32x4_t lt_mask = vcltq_f32(diff, vecnegq_f32(vec_eps));\n        uint32x4_t within_mask = vcleq_f32(abs_diff, abs_eps);\n\n        int8x8_t result = vreinterpret_s8_s32(vandq_s32(vec_zero, vec_zero)); // Initialize to 0\n\n        int8x8_t ones = vreinterpret_s8_u32(gt_mask);\n        int8x8_t neg_ones = vreinterpret_s8_u32(lt_mask);\n\n        result = vorr_s8(result, vand_s8(ones, vec_one));\n        result = vorr_s8(result, vand_s8(neg_ones, vec_neg_one));\n\n        int8x8_t final_result = vreinterpret_s8_u32(within_mask);\n        result = vand_s8(result, vcnt_s8(final_result));\n\n        vst1_s8(&out[i], result);\n    }\n\n    for (; i < length; ++i) {\n        float diff = A[i] - B[i];\n        if (diff > epsilon) {\n            out[i] = 1;\n        } else if (diff < -epsilon) {\n            out[i] = -1;\n        } else {\n            out[i] = 0;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_49_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid tensor_ternary_compare_simd(const float* A, const float* B, int8_t* out, float epsilon, size_t length) {\n    float32x4_t veps = vabsq_f32(vdupq_n_f32(epsilon));\n    size_t i = 0;\n\n    for (; i <= length - 4; i += 4) {\n        float32x4_t va = vld1q_f32(&A[i]);\n        float32x4_t vb = vld1q_f32(&B[i]);\n        float32x4_t vdif = vsubq_f32(va, vb);\n        \n        uint32x4_t vcmp_pos = vcgtq_f32(vdif, veps);\n        uint32x4_t vcmp_neg = vcltq_f32(vdif, vmulq_n_f32(veps, -1.0f));\n        \n        int8x8_t vout = vmovn_s16(vreinterpretq_s16_u32(vbicq_u32(vorrq_u32(vcmp_pos, vshrq_n_u32(vcmp_neg, 31)), vandq_u32(vcmp_pos, vcmp_neg))));\n        \n        vst1_lane_s8(&out[i], vget_low_s8(vout), 0);\n        vst1_lane_s8(&out[i+1], vget_low_s8(vout), 1);\n        vst1_lane_s8(&out[i+2], vget_low_s8(vout), 2);\n        vst1_lane_s8(&out[i+3], vget_low_s8(vout), 3);\n    }\n\n    for (; i < length; ++i) {\n        float dif = A[i] - B[i];\n        if (dif > fabsf(epsilon)) {\n            out[i] = 1;\n        } else if (dif < -fabsf(epsilon)) {\n            out[i] = -1;\n        } else {\n            out[i] = 0;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_49_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid tensor_ternary_compare_simd(const float* A, const float* B, int8_t* out, float epsilon, size_t length) {\n    float32x4_t veps = vdupq_n_f32(fabsf(epsilon));\n    int32x4_t vone = vdupq_n_s32(1);\n    int32x4_t vmone = vdupq_n_s32(-1);\n    int32x4_t vzero = vdupq_n_s32(0);\n\n    size_t i = 0;\n    for (; i <= length - 4; i += 4) {\n        float32x4_t va = vld1q_f32(&A[i]);\n        float32x4_t vb = vld1q_f32(&B[i]);\n        float32x4_t vdif = vsubq_f32(va, vb);\n        float32x4_t vabsdif = vabsq_f32(vdif);\n\n        uint32x4_t vgt = vcgtq_f32(vdif, veps);\n        uint32x4_t vlt = vcltq_f32(vdif, vnegq_f32(veps));\n        uint32x4_t vwithin = vcleq_f32(vabsdif, veps);\n\n        int32x4_t vout = vbslq_s32(vgt, vone, vmone);\n        vout = vbslq_s32(vwithin, vzero, vout);\n\n        int8x8_t vout8 = vqmovn_s32(vout);\n        vst1_lane_s8(&out[i], vout8, 0);\n    }\n\n    for (; i < length; ++i) {\n        float dif = A[i] - B[i];\n        if (dif > fabsf(epsilon)) {\n            out[i] = 1;\n        } else if (dif < -fabsf(epsilon)) {\n            out[i] = -1;\n        } else {\n            out[i] = 0;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_49_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid tensor_ternary_compare_simd(const float* A, const float* B, int8_t* out, float epsilon, size_t length) {\n    float32x4_t veps = vdupq_n_f32(fabsf(epsilon));\n    int32x4_t vone = vdupq_n_s32(1);\n    int32x4_t vmone = vdupq_n_s32(-1);\n    int32x4_t vzero = vdupq_n_s32(0);\n\n    size_t i = 0;\n    for (; i <= length - 4; i += 4) {\n        float32x4_t va = vld1q_f32(A + i);\n        float32x4_t vb = vld1q_f32(B + i);\n        float32x4_t vdif = vsubq_f32(va, vb);\n        float32x4_t vabsdif = vabsq_f32(vdif);\n\n        uint32x4_t vgt = vcgtq_f32(vdif, veps);\n        uint32x4_t vlt = vcltq_f32(vdif, vnegq_f32(veps));\n        uint32x4_t vle = vcleq_f32(vabsdif, veps);\n\n        int32x4_t vout = vbslq_s32(vgt, vone, vmone);\n        vout = vbslq_s32(vle, vzero, vout);\n\n        int8x8_t vout8 = vqmovn_s32(vout);\n        vst1_lane_s8(out + i, vout8, 0);\n        vst1_lane_s8(out + i + 1, vout8, 1);\n        vst1_lane_s8(out + i + 2, vout8, 2);\n        vst1_lane_s8(out + i + 3, vout8, 3);\n    }\n\n    for (; i < length; ++i) {\n        float dif = A[i] - B[i];\n        if (dif > fabsf(epsilon)) {\n            out[i] = 1;\n        } else if (dif < -fabsf(epsilon)) {\n            out[i] = -1;\n        } else {\n            out[i] = 0;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_49_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid tensor_ternary_compare_simd(const float* A, const float* B, int8_t* out, float epsilon, size_t length) {\n    float32x4_t veps = vdupq_n_f32(fabsf(epsilon));\n    int32x4_t vone = vdupq_n_s32(1);\n    int32x4_t vmone = vdupq_n_s32(-1);\n    int32x4_t vzero = vdupq_n_s32(0);\n\n    size_t i = 0;\n    for (; i <= length - 4; i += 4) {\n        float32x4_t va = vld1q_f32(A + i);\n        float32x4_t vb = vld1q_f32(B + i);\n        float32x4_t vdif = vsubq_f32(va, vb);\n        \n        uint32x4_t cmp_gt = vcgtq_f32(vdif, veps);\n        uint32x4_t cmp_lt = vcltq_f32(vdif, vmovq_n_f32(-veps.f[0]));\n        uint32x4_t cmp_eq = vcleq_f32(vabsq_f32(vdif), veps);\n\n        int32x4_t res = vbslq_s32(cmp_gt, vone, vmzeroq_s32());\n        res = vbslq_s32(cmp_lt, vmone, res);\n        res = vbslq_s32(cmp_eq, vzero, res);\n\n        int8x8_t res_narrow = vqmovn_s16(vreinterpretq_s16_s32(res));\n        vst1_lane_s8(out + i, res_narrow, 0);\n        vst1_lane_s8(out + i + 1, res_narrow, 1);\n        vst1_lane_s8(out + i + 2, res_narrow, 2);\n        vst1_lane_s8(out + i + 3, res_narrow, 3);\n    }\n\n    for (; i < length; ++i) {\n        float dif = A[i] - B[i];\n        if (dif > fabsf(epsilon)) {\n            out[i] = 1;\n        } else if (dif < -fabsf(epsilon)) {\n            out[i] = -1;\n        } else {\n            out[i] = 0;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_50_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid float_to_int_saturate_simd(const float* A, int32_t* B, size_t size) {\n    const float32x4_t v_int32_max = vdupq_n_f32((float)INT32_MAX);\n    const float32x4_t v_int32_min = vdupq_n_f32((float)INT32_MIN);\n\n    for (size_t i = 0; i <= size - 4; i += 4) {\n        float32x4_t v_float = vld1q_f32(&A[i]);\n        float32x4_t v_clamped = vminq_f32(vmaxq_f32(v_float, v_int32_min), v_int32_max);\n        int32x4_t v_result = vcvtq_s32_f32(v_clamped);\n        vst1q_s32(&B[i], v_result);\n    }\n\n    // Handle remaining elements\n    for (size_t i = size & ~0x3; i < size; ++i) {\n        B[i] = (A[i] > INT32_MAX) ? INT32_MAX : (A[i] < INT32_MIN) ? INT32_MIN : (int32_t)A[i];\n    }\n}\n```"}
{"task_id": "SimdBench_50_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid float_to_int_saturate_simd(const float* A, int32_t* B, size_t size) {\n    const float32x4_t v_max = vdupq_n_f32((float)INT32_MAX);\n    const float32x4_t v_min = vdupq_n_f32((float)INT32_MIN);\n\n    for (size_t i = 0; i < size; i += 4) {\n        float32x4_t v_float = vld1q_f32(&A[i]);\n        v_float = vminq_f32(v_float, v_max);\n        v_float = vmaxq_f32(v_float, v_min);\n        int32x4_t v_int = vcvtq_s32_f32(v_float);\n        vst1q_s32(&B[i], v_int);\n    }\n}\n```"}
{"task_id": "SimdBench_50_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid float_to_int_saturate_simd(const float* A, int32_t* B, size_t size) {\n    const float32x4_t v_max = vdupq_n_f32(INT32_MAX);\n    const float32x4_t v_min = vdupq_n_f32(INT32_MIN);\n\n    for (size_t i = 0; i <= size - 4; i += 4) {\n        float32x4_t v_float = vld1q_f32(&A[i]);\n        v_float = vminq_f32(v_float, v_max);\n        v_float = vmaxq_f32(v_float, v_min);\n        int32x4_t v_int = vcvtq_s32_f32(v_float);\n        vst1q_s32(&B[i], v_int);\n    }\n\n    // Handle remaining elements\n    for (size_t i = size & ~size_t(3); i < size; ++i) {\n        float val = A[i];\n        if (val > INT32_MAX) val = INT32_MAX;\n        else if (val < INT32_MIN) val = INT32_MIN;\n        B[i] = static_cast<int32_t>(val);\n    }\n}\n```"}
{"task_id": "SimdBench_50_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid float_to_int_saturate_simd(const float* A, int32_t* B, size_t size) {\n    const float32x4_t v_max = vmovq_n_f32((float)INT32_MAX);\n    const float32x4_t v_min = vmovq_n_f32((float)INT32_MIN);\n\n    size_t i = 0;\n    for (; i <= size - 4; i += 4) {\n        float32x4_t v_float = vld1q_f32(&A[i]);\n        v_float = vminq_f32(v_float, v_max);\n        v_float = vmaxq_f32(v_float, v_min);\n        int32x4_t v_int = vcvtq_s32_f32(v_float);\n        vst1q_s32(&B[i], v_int);\n    }\n\n    for (; i < size; ++i) {\n        float val = A[i];\n        if (val > INT32_MAX) val = INT32_MAX;\n        else if (val < INT32_MIN) val = INT32_MIN;\n        B[i] = (int32_t)val;\n    }\n}\n```"}
{"task_id": "SimdBench_50_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid float_to_int_saturate_simd(const float* A, int32_t* B, size_t size) {\n    const float32x4_t v_int32_max = vdupq_n_f32((float)INT32_MAX);\n    const float32x4_t v_int32_min = vdupq_n_f32((float)INT32_MIN);\n\n    for (size_t i = 0; i <= size - 16; i += 16) {\n        float32x4_t v0 = vld1q_f32(&A[i]);\n        float32x4_t v1 = vld1q_f32(&A[i + 4]);\n        float32x4_t v2 = vld1q_f32(&A[i + 8]);\n        float32x4_t v3 = vld1q_f32(&A[i + 12]);\n\n        v0 = vminq_f32(v0, v_int32_max);\n        v0 = vmaxq_f32(v0, v_int32_min);\n        v1 = vminq_f32(v1, v_int32_max);\n        v1 = vmaxq_f32(v1, v_int32_min);\n        v2 = vminq_f32(v2, v_int32_max);\n        v2 = vmaxq_f32(v2, v_int32_min);\n        v3 = vminq_f32(v3, v_int32_max);\n        v3 = vmaxq_f32(v3, v_int32_min);\n\n        int32x4_t r0 = vcvtq_s32_f32(v0);\n        int32x4_t r1 = vcvtq_s32_f32(v1);\n        int32x4_t r2 = vcvtq_s32_f32(v2);\n        int32x4_t r3 = vcvtq_s32_f32(v3);\n\n        vst1q_s32(&B[i], r0);\n        vst1q_s32(&B[i + 4], r1);\n        vst1q_s32(&B[i + 8], r2);\n        vst1q_s32(&B[i + 12], r3);\n    }\n\n    for (size_t i = (size / 16) * 16; i < size; ++i) {\n        float val = A[i];\n        if (val > INT32_MAX) val = INT32_MAX;\n        else if (val < INT32_MIN) val = INT32_MIN;\n        B[i] = (int32_t)val;\n    }\n}\n```"}
{"task_id": "SimdBench_51_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid int_to_float_scaled_simd(const int32_t* A, int8_t scale, float* B, size_t size) {\n    float32x4_t v_scale = vmovq_n_f32((float)scale);\n    size_t i = 0;\n\n    for (; i <= size - 4; i += 4) {\n        int32x4_t v_int = vld1q_s32(&A[i]);\n        float32x4_t v_float = vcvtq_f32_s32(v_int);\n        float32x4_t v_result = vmulq_f32(v_float, v_scale);\n        vst1q_f32(&B[i], v_result);\n    }\n\n    for (; i < size; i++) {\n        B[i] = (float)(A[i] * scale);\n    }\n}\n```"}
{"task_id": "SimdBench_51_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid int_to_float_scaled_simd(const int32_t* A, int8_t scale, float* B, size_t size) {\n    float32x4_t v_scale = vmovq_n_f32((float)scale);\n    size_t i = 0;\n\n    for (; i <= size - 4; i += 4) {\n        int32x4_t v_int = vld1q_s32(&A[i]);\n        float32x4_t v_float = vcvtq_f32_s32(v_int);\n        float32x4_t v_result = vmulq_f32(v_float, v_scale);\n        vst1q_f32(&B[i], v_result);\n    }\n\n    for (; i < size; i++) {\n        B[i] = (float)A[i] * scale;\n    }\n}\n```"}
{"task_id": "SimdBench_51_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid int_to_float_scaled_simd(const int32_t* A, int8_t scale, float* B, size_t size) {\n    float32x4_t v_scale = vmovq_n_f32((float)scale);\n    size_t i = 0;\n\n    for (; i <= size - 4; i += 4) {\n        int32x4_t v_int = vld1q_s32(&A[i]);\n        float32x4_t v_float = vcvtq_f32_s32(v_int);\n        float32x4_t v_result = vmulq_f32(v_float, v_scale);\n        vst1q_f32(&B[i], v_result);\n    }\n\n    for (; i < size; i++) {\n        B[i] = (float)(A[i] * scale);\n    }\n}\n```"}
{"task_id": "SimdBench_51_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nvoid int_to_float_scaled_simd(const int32_t* A, int8_t scale, float* B, size_t size) {\n    float32x4_t v_scale = vmovq_n_f32((float32_t)scale);\n    size_t i = 0;\n\n    for (; i <= size - 4; i += 4) {\n        int32x4_t v_int = vld1q_s32(&A[i]);\n        float32x4_t v_float = vcvtq_f32_s32(v_int);\n        float32x4_t v_result = vmulq_f32(v_float, v_scale);\n        vst1q_f32(&B[i], v_result);\n    }\n\n    for (; i < size; ++i) {\n        B[i] = (float)A[i] * scale;\n    }\n}\n```"}
{"task_id": "SimdBench_51_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid int_to_float_scaled_simd(const int32_t* A, int8_t scale, float* B, size_t size) {\n    float32x4_t v_scale = vmovq_n_f32((float)scale);\n    size_t i = 0;\n\n    for (; i <= size - 4; i += 4) {\n        int32x4_t v_int = vld1q_s32(&A[i]);\n        float32x4_t v_float = vcvtq_f32_s32(v_int);\n        float32x4_t v_result = vmulq_f32(v_float, v_scale);\n        vst1q_f32(&B[i], v_result);\n    }\n\n    for (; i < size; i++) {\n        B[i] = (float)(A[i] * scale);\n    }\n}\n```"}
{"task_id": "SimdBench_52_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid float_div_round_simd(const float* A, const float* B, int32_t* C, size_t size) {\n    size_t i = 0;\n    for (; i <= size - 4; i += 4) {\n        float32x4_t vec_a = vld1q_f32(&A[i]);\n        float32x4_t vec_b = vld1q_f32(&B[i]);\n        float32x4_t vec_div = vdivq_f32(vec_a, vec_b);\n        int32x4_t vec_rounded = vcvtq_s32_f32(vec_div);\n        vst1q_s32(&C[i], vec_rounded);\n    }\n    for (; i < size; ++i) {\n        C[i] = (int32_t)roundf(A[i] / B[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_52_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid float_div_round_simd(const float* A, const float* B, int32_t* C, size_t size) {\n    size_t i = 0;\n    for (; i <= size - 4; i += 4) {\n        float32x4_t vec_a = vld1q_f32(&A[i]);\n        float32x4_t vec_b = vld1q_f32(&B[i]);\n        float32x4_t vec_res = vdivq_f32(vec_a, vec_b);\n        int32x4_t vec_int_res = vcvtq_s32_f32(vec_res);\n        vst1q_s32(&C[i], vec_int_res);\n    }\n    for (; i < size; ++i) {\n        C[i] = (int32_t)roundf(A[i] / B[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_52_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid float_div_round_simd(const float* A, const float* B, int32_t* C, size_t size) {\n    size_t i = 0;\n    for (; i <= size - 4; i += 4) {\n        float32x4_t vec_a = vld1q_f32(&A[i]);\n        float32x4_t vec_b = vld1q_f32(&B[i]);\n        float32x4_t vec_res = vdivq_f32(vec_a, vec_b);\n        int32x4_t vec_int = vcvtq_n_s32_f32(vec_res, 0);\n        vst1q_s32(&C[i], vec_int);\n    }\n    for (; i < size; ++i) {\n        C[i] = static_cast<int32_t>(roundf(A[i] / B[i]));\n    }\n}\n```"}
{"task_id": "SimdBench_52_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid float_div_round_simd(const float* A, const float* B, int32_t* C, size_t size) {\n    size_t i = 0;\n    for (; i <= size - 4; i += 4) {\n        float32x4_t vec_a = vld1q_f32(&A[i]);\n        float32x4_t vec_b = vld1q_f32(&B[i]);\n        float32x4_t vec_result = vdivq_f32(vec_a, vec_b);\n        int32x4_t vec_int_result = vcvtq_s32_f32(vec_result);\n        vst1q_s32(&C[i], vec_int_result);\n    }\n    for (; i < size; ++i) {\n        C[i] = (int32_t)(A[i] / B[i] + 0.5f);\n    }\n}\n```"}
{"task_id": "SimdBench_52_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid float_div_round_simd(const float* A, const float* B, int32_t* C, size_t size) {\n    size_t i = 0;\n    for (; i <= size - 4; i += 4) {\n        float32x4_t vec_a = vld1q_f32(&A[i]);\n        float32x4_t vec_b = vld1q_f32(&B[i]);\n        float32x4_t vec_div = vdivq_f32(vec_a, vec_b);\n        int32x4_t vec_result = vcvtq_s32_f32(vec_div);\n        vst1q_s32(&C[i], vec_result);\n    }\n    for (; i < size; i++) {\n        C[i] = (int32_t)(A[i] / B[i] + 0.5f);\n    }\n}\n```"}
{"task_id": "SimdBench_53_Neon", "completion": "```c\n#include <arm_neon.h>\n#include <float.h>\n\nvoid double_to_float_saturate_simd(const double* A, float* B, size_t size) {\n    const float32x4_t v_FLT_MAX = vdupq_n_f32(FLT_MAX);\n    const float32x4_t v_neg_FLT_MAX = vdupq_n_f32(-FLT_MAX);\n\n    size_t i = 0;\n    for (; i <= size - 4; i += 4) {\n        float64x2_t vd = vld1q_f64(&A[i]);\n        \n        float32x4_t vcvt = vcvtq_f32_f64(vd);\n        \n        float32x4_t vcvt_gt = vcgtq_f32(vcvt, v_FLT_MAX);\n        float32x4_t vcvt_lt = vcltq_f32(vcvt, v_neg_FLT_MAX);\n        \n        vcvt = vbslq_f32(vcvt_gt, v_FLT_MAX, vcvt);\n        vcvt = vbslq_f32(vcvt_lt, v_neg_FLT_MAX, vcvt);\n        \n        vst1q_f32(&B[i], vcvt);\n    }\n\n    for (; i < size; ++i) {\n        double val = A[i];\n        if (val > FLT_MAX) {\n            B[i] = FLT_MAX;\n        } else if (val < -FLT_MAX) {\n            B[i] = -FLT_MAX;\n        } else {\n            B[i] = (float)val;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_53_Neon", "completion": "```c\n#include <arm_neon.h>\n#include <float.h>\n\nvoid double_to_float_saturate_simd(const double* A, float* B, size_t size) {\n    const float32x4_t v_FLT_MAX = vdupq_n_f32(FLT_MAX);\n    const float32x4_t v_neg_FLT_MAX = vdupq_n_f32(-FLT_MAX);\n\n    size_t i = 0;\n    for (; i <= size - 4; i += 4) {\n        float64x2_t v_double = vld1q_f64(&A[i]);\n        float32x4_t v_float = vcvtq_f32_f64(v_double);\n\n        uint32x4_t v_gt = vcgtq_f32(v_float, v_FLT_MAX);\n        uint32x4_t v_lt = vcltq_f32(v_float, v_neg_FLT_MAX);\n\n        float32x4_t v_saturated = vbslq_f32(v_gt, v_FLT_MAX, v_float);\n        v_saturated = vbslq_f32(v_lt, v_neg_FLT_MAX, v_saturated);\n\n        vst1q_f32(&B[i], v_saturated);\n    }\n\n    for (; i < size; ++i) {\n        double val = A[i];\n        if (val > FLT_MAX) {\n            B[i] = FLT_MAX;\n        } else if (val < -FLT_MAX) {\n            B[i] = -FLT_MAX;\n        } else {\n            B[i] = (float)val;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_53_Neon", "completion": "```c\n#include <arm_neon.h>\n#include <float.h>\n\nvoid double_to_float_saturate_simd(const double* A, float* B, size_t size) {\n    const float32x4_t v_fltp_max = vdupq_n_f32(FLT_MAX);\n    const float32x4_t v_fltp_min = vdupq_n_f32(-FLT_MAX);\n\n    size_t i = 0;\n    for (; i <= size - 4; i += 4) {\n        float64x2_t v_double_low = vld1q_f64(&A[i]);\n        float64x2_t v_double_high = vld1q_f64(&A[i + 2]);\n\n        float32x4_t v_float = vcvt_f32_f64(vcombine_f64(v_double_low, v_double_high));\n\n        float32x4_t v_cmp_gt = vcgtq_f32(v_float, v_fltp_max);\n        float32x4_t v_cmp_lt = vcltq_f32(v_float, v_fltp_min);\n\n        v_float = vbslq_f32(v_cmp_gt, v_fltp_max, v_float);\n        v_float = vbslq_f32(v_cmp_lt, v_fltp_min, v_float);\n\n        vst1q_f32(&B[i], v_float);\n    }\n\n    for (; i < size; ++i) {\n        double val = A[i];\n        if (val > FLT_MAX) {\n            B[i] = FLT_MAX;\n        } else if (val < -FLT_MAX) {\n            B[i] = -FLT_MAX;\n        } else {\n            B[i] = (float)val;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_53_Neon", "completion": "```c\n#include <arm_neon.h>\n#include <float.h>\n\nvoid double_to_float_saturate_simd(const double* A, float* B, size_t size) {\n    const float32x4_t v_FLT_MAX = vdupq_n_f32(FLT_MAX);\n    const float32x4_t v_neg_FLT_MAX = vdupq_n_f32(-FLT_MAX);\n\n    size_t i = 0;\n    for (; i <= size - 4; i += 4) {\n        float64x2_t v_double_low = vld1q_f64(&A[i]);\n        float64x2_t v_double_high = vld1q_f64(&A[i + 2]);\n\n        float32x4_t v_float = vcvt_f32_f64(vcombine_f64(v_double_low, v_double_high));\n\n        float32x4_t v_greater = vcgtq_f32(v_float, v_FLT_MAX);\n        float32x4_t v_less = vcltq_f32(v_float, v_neg_FLT_MAX);\n\n        v_float = vbslq_f32(v_greater, v_FLT_MAX, v_float);\n        v_float = vbslq_f32(v_less, v_neg_FLT_MAX, v_float);\n\n        vst1q_f32(&B[i], v_float);\n    }\n\n    for (; i < size; ++i) {\n        double val = A[i];\n        if (val > FLT_MAX) {\n            B[i] = FLT_MAX;\n        } else if (val < -FLT_MAX) {\n            B[i] = -FLT_MAX;\n        } else {\n            B[i] = (float)val;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_53_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid double_to_float_saturate_simd(const double* A, float* B, size_t size) {\n    const float32x4_t v_FLT_MAX = vdupq_n_f32(FLT_MAX);\n    const float32x4_t v_neg_FLT_MAX = vdupq_n_f32(-FLT_MAX);\n\n    size_t i = 0;\n    for (; i <= size - 4; i += 4) {\n        float64x2_t v_double = vld1q_f64(&A[i]);\n        \n        float32x4_t v_float = vcvt_f32_f64(v_double);\n        \n        uint32x4_t v_gt_mask = vcgtq_f32(v_float, v_FLT_MAX);\n        uint32x4_t v_lt_mask = vcltq_f32(v_float, v_neg_FLT_MAX);\n        \n        float32x4_t v_clamped = vbslq_f32(v_gt_mask, v_FLT_MAX, v_float);\n        v_clamped = vbslq_f32(v_lt_mask, v_neg_FLT_MAX, v_clamped);\n        \n        vst1q_f32(&B[i], v_clamped);\n    }\n\n    for (; i < size; ++i) {\n        double val = A[i];\n        if (val > FLT_MAX) {\n            B[i] = FLT_MAX;\n        } else if (val < -FLT_MAX) {\n            B[i] = -FLT_MAX;\n        } else {\n            B[i] = (float)val;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_54_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid int16_to_int32_simd(const int16_t* A, int32_t* B, size_t size) {\n    size_t i = 0;\n    for (; i <= size - 8; i += 8) {\n        int16x8_t vec_load = vld1q_s16(&A[i]);\n        int32x4_t vec_low = vmovl_s16(vget_low_s16(vec_load));\n        int32x4_t vec_high = vmovl_s16(vget_high_s16(vec_load));\n        vst1q_s32(&B[i], vec_low);\n        vst1q_s32(&B[i + 4], vec_high);\n    }\n    for (; i < size; i++) {\n        B[i] = (int32_t)A[i];\n    }\n}\n```"}
{"task_id": "SimdBench_54_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid int16_to_int32_simd(const int16_t* A, int32_t* B, size_t size) {\n    size_t i = 0;\n    for (; i <= size - 8; i += 8) {\n        int16x8_t vec_a = vld1q_s16(&A[i]);\n        int32x4_t vec_b1 = vmovl_s16(vget_low_s16(vec_a));\n        int32x4_t vec_b2 = vmovl_high_s16(vec_a);\n        vst1q_s32(&B[i], vec_b1);\n        vst1q_s32(&B[i + 4], vec_b2);\n    }\n    for (; i < size; ++i) {\n        B[i] = (int32_t)A[i];\n    }\n}\n```"}
{"task_id": "SimdBench_54_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid int16_to_int32_simd(const int16_t* A, int32_t* B, size_t size) {\n    size_t i = 0;\n    for (; i <= size - 8; i += 8) {\n        int16x8_t vec_a = vld1q_s16(&A[i]);\n        int32x4_t vec_b1 = vmovl_s16(vget_low_s16(vec_a));\n        int32x4_t vec_b2 = vmovl_s16(vget_high_s16(vec_a));\n        vst1q_s32(&B[i], vec_b1);\n        vst1q_s32(&B[i + 4], vec_b2);\n    }\n    for (; i < size; i++) {\n        B[i] = (int32_t)A[i];\n    }\n}\n```"}
{"task_id": "SimdBench_54_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid int16_to_int32_simd(const int16_t* A, int32_t* B, size_t size) {\n    size_t i = 0;\n    for (; i <= size - 8; i += 8) {\n        int16x8_t vec_load = vld1q_s16(&A[i]);\n        int32x4_t vec_low = vmovl_s16(vget_low_s16(vec_load));\n        int32x4_t vec_high = vmovl_s16(vget_high_s16(vec_load));\n        vst1q_s32(&B[i], vec_low);\n        vst1q_s32(&B[i + 4], vec_high);\n    }\n    for (; i < size; i++) {\n        B[i] = (int32_t)A[i];\n    }\n}\n```"}
{"task_id": "SimdBench_54_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid int16_to_int32_simd(const int16_t* A, int32_t* B, size_t size) {\n    size_t i = 0;\n    for (; i <= size - 8; i += 8) {\n        int16x8_t vec_a = vld1q_s16(&A[i]);\n        int32x4_t vec_low = vmovl_s16(vget_low_s16(vec_a));\n        int32x4_t vec_high = vmovl_s16(vget_high_s16(vec_a));\n        vst1q_s32(&B[i], vec_low);\n        vst1q_s32(&B[i + 4], vec_high);\n    }\n    for (; i < size; i++) {\n        B[i] = (int32_t)A[i];\n    }\n}\n```"}
{"task_id": "SimdBench_55_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid conditional_normalize_simd(const float* A, const int32_t* control, float* B, size_t size, float min_val, float max_val) {\n    float32x4_t v_min = vdupq_n_f32(min_val);\n    float32x4_t v_max = vdupq_n_f32(max_val);\n    float32x4_t v_range = vsubq_f32(v_max, v_min);\n    float32x4_t v_zero = vdupq_n_f32(0.0f);\n    float32x4_t v_one = vdupq_n_f32(1.0f);\n\n    for (size_t i = 0; i < size; i += 4) {\n        float32x4_t v_A = vld1q_f32(&A[i]);\n        int32x4_t v_control = vld1q_s32(&control[i]);\n\n        uint32x4_t v_mask = vcgtq_s32(v_control, vdupq_n_s32(0));\n\n        float32x4_t v_normalized = vdivq_f32(vsubq_f32(v_A, v_min), v_range);\n        float32x4_t v_clamped = vminq_f32(vmaxq_f32(v_normalized, v_zero), v_one);\n\n        float32x4_t v_result = vbslq_f32(vreinterpretq_u32_f32(v_mask), v_clamped, v_A);\n\n        vst1q_f32(&B[i], v_result);\n    }\n}\n```"}
{"task_id": "SimdBench_55_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid conditional_normalize_simd(const float* A, const int32_t* control, float* B, size_t size, float min_val, float max_val) {\n    float32x4_t v_min = vdupq_n_f32(min_val);\n    float32x4_t v_max = vdupq_n_f32(max_val);\n    float32x4_t v_one = vdupq_n_f32(1.0f);\n    float32x4_t v_zero = vdupq_n_f32(0.0f);\n\n    for (size_t i = 0; i <= size - 4; i += 4) {\n        float32x4_t v_A = vld1q_f32(&A[i]);\n        int32x4_t v_control = vld1q_s32(&control[i]);\n\n        // Check if control values are greater than 0\n        uint32x4_t mask = vcgtq_s32(v_control, vdupq_n_s32(0));\n\n        // Compute normalization: (A[i] - min_val) / (max_val - min_val)\n        float32x4_t diff = vsubq_f32(v_A, v_min);\n        float32x4_t range = vsubq_f32(v_max, v_min);\n        float32x4_t normalized = vdivq_f32(diff, range);\n\n        // Clamp to [0, 1]\n        normalized = vmaxq_f32(normalized, v_zero); // Clamp lower bound to 0\n        normalized = vminq_f32(normalized, v_one);  // Clamp upper bound to 1\n\n        // Select between normalized and original based on mask\n        float32x4_t result = vbslq_f32((uint32x4_t)mask, normalized, v_A);\n\n        // Store the result\n        vst1q_f32(&B[i], result);\n    }\n\n    // Handle remaining elements\n    for (size_t i = size & ~size_t(3); i < size; ++i) {\n        if (control[i] > 0) {\n            float val = (A[i] - min_val) / (max_val - min_val);\n            B[i] = (val < 0.0f) ? 0.0f : ((val > 1.0f) ? 1.0f : val);\n        } else {\n            B[i] = A[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_55_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid conditional_normalize_simd(const float* A, const int32_t* control, float* B, size_t size, float min_val, float max_val) {\n    float32x4_t v_min = vdupq_n_f32(min_val);\n    float32x4_t v_max = vdupq_n_f32(max_val);\n    float32x4_t v_one = vdupq_n_f32(1.0f);\n    float32x4_t v_zero = vdupq_n_f32(0.0f);\n\n    for (size_t i = 0; i <= size - 4; i += 4) {\n        float32x4_t v_a = vld1q_f32(&A[i]);\n        int32x4_t v_control = vld1q_s32(&control[i]);\n\n        // Check if control values are greater than 0\n        uint32x4_t mask = vcgtq_s32(v_control, vdupq_n_s32(0));\n\n        // Perform normalization: (A[i] - min_val) / (max_val - min_val)\n        float32x4_t v_diff = vsubq_f32(v_a, v_min);\n        float32x4_t v_range = vsubq_f32(v_max, v_min);\n        float32x4_t v_norm = vdivq_f32(v_diff, v_range);\n\n        // Clamp the normalized values to [0, 1]\n        v_norm = vmaxq_f32(v_norm, v_zero); // Ensure values are not less than 0\n        v_norm = vminq_f32(v_norm, v_one);  // Ensure values are not greater than 1\n\n        // Select between normalized values and original values based on the control array\n        float32x4_t v_result = vbslq_f32(mask, v_norm, v_a);\n\n        // Store the result\n        vst1q_f32(&B[i], v_result);\n    }\n\n    // Handle remaining elements (if any)\n    for (size_t i = size - (size % 4); i < size; ++i) {\n        if (control[i] > 0) {\n            float val = (A[i] - min_val) / (max_val - min_val);\n            B[i] = val < 0.0f ? 0.0f : (val > 1.0f ? 1.0f : val);\n        } else {\n            B[i] = A[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_55_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid conditional_normalize_simd(const float* A, const int32_t* control, float* B, size_t size, float min_val, float max_val) {\n    float32x4_t v_min = vdupq_n_f32(min_val);\n    float32x4_t v_max = vdupq_n_f32(max_val);\n    float32x4_t v_range = vsubq_f32(v_max, v_min);\n    float32x4_t v_zero = vdupq_n_f32(0.0f);\n    float32x4_t v_one = vdupq_n_f32(1.0f);\n\n    for (size_t i = 0; i <= size - 4; i += 4) {\n        float32x4_t v_A = vld1q_f32(&A[i]);\n        int32x4_t v_control = vld1q_s32(&control[i]);\n\n        uint32x4_t v_mask = vcgtq_s32(v_control, vdupq_n_s32(0));\n\n        float32x4_t v_normalized = vdivq_f32(vsubq_f32(v_A, v_min), v_range);\n        float32x4_t v_clamped = vminq_f32(vmaxq_f32(v_normalized, v_zero), v_one);\n\n        float32x4_t v_result = vbslq_f32(vreinterpretq_u32_f32(v_mask), v_clamped, v_A);\n\n        vst1q_f32(&B[i], v_result);\n    }\n\n    // Handle remaining elements\n    for (size_t i = size & ~size_t(3); i < size; ++i) {\n        if (control[i] > 0) {\n            float val = (A[i] - min_val) / (max_val - min_val);\n            B[i] = (val < 0.0f) ? 0.0f : ((val > 1.0f) ? 1.0f : val);\n        } else {\n            B[i] = A[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_55_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid conditional_normalize_simd(const float* A, const int32_t* control, float* B, size_t size, float min_val, float max_val) {\n    float32x4_t v_min = vdupq_n_f32(min_val);\n    float32x4_t v_max = vdupq_n_f32(max_val);\n    float32x4_t v_range = vsubq_f32(v_max, v_min);\n    float32x4_t v_zero = vdupq_n_f32(0.0f);\n    float32x4_t v_one = vdupq_n_f32(1.0f);\n\n    for (size_t i = 0; i <= size - 4; i += 4) {\n        float32x4_t v_A = vld1q_f32(&A[i]);\n        int32x4_t v_control = vld1q_s32(&control[i]);\n\n        // Create a mask where elements are set if control > 0\n        uint32x4_t v_mask = vcgtq_s32(v_control, vdupq_n_s32(0));\n\n        // Normalize: (A - min) / (max - min)\n        float32x4_t v_normalized = vdivq_f32(vsubq_f32(v_A, v_min), v_range);\n\n        // Clamp to [0, 1]\n        v_normalized = vmaxq_f32(v_normalized, v_zero);\n        v_normalized = vminq_f32(v_normalized, v_one);\n\n        // Select between normalized or original based on mask\n        float32x4_t v_result = vbslq_f32(v_mask, v_normalized, v_A);\n\n        // Store the result\n        vst1q_f32(&B[i], v_result);\n    }\n\n    // Handle any remaining elements\n    for (size_t i = size & ~3; i < size; ++i) {\n        if (control[i] > 0) {\n            float val = (A[i] - min_val) / (max_val - min_val);\n            B[i] = val < 0.0f ? 0.0f : (val > 1.0f ? 1.0f : val);\n        } else {\n            B[i] = A[i];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_56_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid int_to_float_sqrt_simd(const uint32_t* A, float* B, size_t size) {\n    size_t i = 0;\n    for (; i <= size - 4; i += 4) {\n        uint32x4_t v_uint = vld1q_u32(A + i);\n        uint32x4_t v_high_bits = vshrq_n_u32(v_uint, 16);\n        float32x4_t v_float = vcvtq_f32_u32(v_high_bits);\n        float32x4_t v_sqrt = vsqrtq_f32(v_float);\n        vst1q_f32(B + i, v_sqrt);\n    }\n    for (; i < size; ++i) {\n        uint32_t high_bits = A[i] >> 16;\n        float f_val = (float)high_bits;\n        B[i] = sqrtf(f_val);\n    }\n}\n```"}
{"task_id": "SimdBench_56_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid int_to_float_sqrt_simd(const uint32_t* A, float* B, size_t size) {\n    size_t i = 0;\n    for (; i <= size - 4; i += 4) {\n        uint32x4_t vec_uint = vld1q_u32(&A[i]);\n        uint32x4_t high_bits = vshrq_n_u32(vec_uint, 16);\n        float32x4_t vec_float = vcvtq_f32_u32(high_bits);\n        float32x4_t sqrt_vec = vsqrtq_f32(vec_float);\n        vst1q_f32(&B[i], sqrt_vec);\n    }\n    for (; i < size; ++i) {\n        uint32_t val = A[i] >> 16;\n        float result = sqrtf((float)val);\n        B[i] = result;\n    }\n}\n```"}
{"task_id": "SimdBench_56_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid int_to_float_sqrt_simd(const uint32_t* A, float* B, size_t size) {\n    size_t i = 0;\n    for (; i <= size - 4; i += 4) {\n        uint32x4_t vec_uint = vld1q_u32(A + i);\n        uint32x4_t vec_high_bits = vshrq_n_u32(vec_uint, 16);\n        float32x4_t vec_float = vcvtq_f32_u32(vec_high_bits);\n        float32x4_t vec_sqrt = vsqrtq_f32(vec_float);\n        vst1q_f32(B + i, vec_sqrt);\n    }\n    for (; i < size; ++i) {\n        uint32_t val = A[i];\n        uint32_t high_bits = val >> 16;\n        float fval = (float)high_bits;\n        B[i] = sqrtf(fval);\n    }\n}\n```"}
{"task_id": "SimdBench_56_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid int_to_float_sqrt_simd(const uint32_t* A, float* B, size_t size) {\n    size_t i = 0;\n    for (; i <= size - 4; i += 4) {\n        uint32x4_t vec_uint = vld1q_u32((const uint32_t*)&A[i]);\n        uint16x4_t high_bits = vreinterpret_n_s16_u16(vget_high_u16(vreinterpretq_u16_u32(vec_uint)));\n        float32x4_t vec_float = vcvtq_f32_u32(vmovl_u16(high_bits));\n        float32x4_t sqrt_vec = vsqrtq_f32(vec_float);\n        vst1q_f32(&B[i], sqrt_vec);\n    }\n    for (; i < size; ++i) {\n        uint32_t val = A[i];\n        uint16_t high = (val >> 16) & 0xFFFF;\n        float f_val = (float)high;\n        B[i] = sqrtf(f_val);\n    }\n}\n```"}
{"task_id": "SimdBench_56_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid int_to_float_sqrt_simd(const uint32_t* A, float* B, size_t size) {\n    size_t i = 0;\n    for (; i <= size - 4; i += 4) {\n        uint32x4_t vec_uint = vld1q_u32(A + i);\n        uint32x4_t high_bits = vshrq_n_u32(vec_uint, 16);\n        float32x4_t vec_float = vcvtq_f32_u32(high_bits);\n        float32x4_t sqrt_vec = vsqrtq_f32(vec_float);\n        vst1q_f32(B + i, sqrt_vec);\n    }\n    for (; i < size; ++i) {\n        uint32_t val = A[i] >> 16;\n        float result = sqrtf((float)val);\n        B[i] = result;\n    }\n}\n```"}
{"task_id": "SimdBench_57_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid int_bits_to_float_simd(const uint32_t* A, float* B, size_t size) {\n    size_t i = 0;\n    for (; i <= size - 4; i += 4) {\n        uint32x4_t v_uint = vld1q_u32(&A[i]);\n        float32x4_t v_float = vreinterpretq_f32_u32(v_uint);\n        vst1q_f32(&B[i], v_float);\n    }\n    for (; i < size; i++) {\n        B[i] = *(float*)&A[i];\n    }\n}\n```"}
{"task_id": "SimdBench_57_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid int_bits_to_float_simd(const uint32_t* A, float* B, size_t size) {\n    size_t i = 0;\n    for (; i <= size - 4; i += 4) {\n        uint32x4_t v_uint = vld1q_u32(&A[i]);\n        float32x4_t v_float = vreinterpretq_f32_u32(v_uint);\n        vst1q_f32(&B[i], v_float);\n    }\n    for (; i < size; i++) {\n        B[i] = *(float*)&A[i];\n    }\n}\n```"}
{"task_id": "SimdBench_57_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid int_bits_to_float_simd(const uint32_t* A, float* B, size_t size) {\n    size_t i = 0;\n    for (; i <= size - 4; i += 4) {\n        uint32x4_t v_uint = vld1q_u32(&A[i]);\n        float32x4_t v_float = vreinterpretq_f32_u32(v_uint);\n        vst1q_f32(&B[i], v_float);\n    }\n    for (; i < size; ++i) {\n        B[i] = *(float*)&A[i];\n    }\n}\n```"}
{"task_id": "SimdBench_57_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid int_bits_to_float_simd(const uint32_t* A, float* B, size_t size) {\n    size_t i = 0;\n    for (; i <= size - 4; i += 4) {\n        uint32x4_t v_uint = vld1q_u32(&A[i]);\n        float32x4_t v_float = vreinterpretq_f32_u32(v_uint);\n        vst1q_f32(&B[i], v_float);\n    }\n    for (; i < size; i++) {\n        B[i] = *(float*)&A[i];\n    }\n}\n```"}
{"task_id": "SimdBench_57_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid int_bits_to_float_simd(const uint32_t* A, float* B, size_t size) {\n    size_t i = 0;\n    for (; i <= size - 4; i += 4) {\n        uint32x4_t v_uint = vld1q_u32(&A[i]);\n        float32x4_t v_float = vreinterpretq_f32_u32(v_uint);\n        vst1q_f32(&B[i], v_float);\n    }\n    for (; i < size; i++) {\n        B[i] = *(float*)&A[i];\n    }\n}\n```"}
{"task_id": "SimdBench_58_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid conditional_diff_simd(const int32_t* A, const bool* cond, float* diff, size_t size) {\n    if (size == 0) return;\n\n    *diff = 0.0f; // Set the first element to 0.0f\n    size_t i = 1;\n\n    for (; i + 3 < size; i += 4) {\n        int32x4_t vec_A_curr = vld1q_s32(&A[i]);\n        int32x4_t vec_A_prev = vld1q_s32(&A[i - 1]);\n        int32x4_t vec_diff = vsubq_s32(vec_A_curr, vec_A_prev);\n\n        uint8x16_t vec_cond = vld1q_u8((const uint8_t*)&cond[i]);\n        uint8x16_t mask = vcgeq_u8(vec_cond, vmovq_n_u8(1)); // Create a mask where cond[i] is true\n\n        float32x4_t vec_diff_f = vcvtq_f32_s32(vec_diff);\n        float32x4_t vec_zero = vmovq_n_f32(0.0f);\n        float32x4_t result = vbslq_f32(mask, vec_diff_f, vec_zero);\n\n        vst1q_f32(&diff[i], result);\n    }\n\n    for (; i < size; ++i) {\n        diff[i] = cond[i] ? (float)(A[i] - A[i - 1]) : 0.0f;\n    }\n}\n```"}
{"task_id": "SimdBench_58_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid conditional_diff_simd(const int32_t* A, const bool* cond, float* diff, size_t size) {\n    if (size == 0) return;\n\n    // Always set the first element to 0.0f\n    diff[0] = 0.0f;\n\n    if (size == 1) return;\n\n    size_t i = 1;\n    const size_t vector_length = 4;\n\n    // Handle scalar until aligned\n    while (i < size && i % vector_length != 0) {\n        diff[i] = cond[i] ? (float)(A[i] - A[i-1]) : 0.0f;\n        i++;\n    }\n\n    // SIMD loop\n    for (; i + vector_length <= size; i += vector_length) {\n        int32x4_t vec_A_curr = vld1q_s32(&A[i]);\n        int32x4_t vec_A_prev = vld1q_s32(&A[i-1]);\n        int32x4_t vec_diff = vsubq_s32(vec_A_curr, vec_A_prev);\n\n        uint32x4_t vec_cond = vld1q_u32((uint32_t*)&cond[i]);\n        uint32x4_t mask = vcgeq_u32(vec_cond, vmovq_n_u32(0));\n\n        float32x4_t vec_diff_f = vcvtq_f32_s32(vec_diff);\n        float32x4_t vec_zero = vmovq_n_f32(0.0f);\n        float32x4_t result = vbslq_f32(mask, vec_diff_f, vec_zero);\n\n        vst1q_f32(&diff[i], result);\n    }\n\n    // Handle remaining scalar elements\n    for (; i < size; i++) {\n        diff[i] = cond[i] ? (float)(A[i] - A[i-1]) : 0.0f;\n    }\n}\n```"}
{"task_id": "SimdBench_58_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid conditional_diff_simd(const int32_t* A, const bool* cond, float* diff, size_t size) {\n    if (size == 0) return;\n\n    // Always set the first element to 0.0f\n    diff[0] = 0.0f;\n\n    if (size == 1) return;\n\n    size_t i = 1;\n    const size_t vector_size = 4; // Process 4 elements per iteration using SIMD\n\n    for (; i <= size - vector_size; i += vector_size) {\n        // Load 4 consecutive elements of A[i-1]\n        int32x4_t prev_vec = vld1q_s32(&A[i - 1]);\n        // Load 4 consecutive elements of A[i]\n        int32x4_t curr_vec = vld1q_s32(&A[i]);\n\n        // Compute differences: A[i] - A[i-1]\n        int32x4_t diff_vec = vsubq_s32(curr_vec, prev_vec);\n\n        // Convert differences to float\n        float32x4_t diff_float_vec = vcvtq_f32_s32(diff_vec);\n\n        // Load 4 consecutive condition values\n        uint8x16_t cond_bytes = vld1q_u8((const uint8_t*)&cond[i]);\n        uint8x8_t cond_bytes_low = vget_low_u8(cond_bytes);\n        uint8x8_t cond_bytes_high = vget_high_u8(cond_bytes);\n\n        // Create masks from condition values\n        uint8x8_t mask_low = vclt_u8(cond_bytes_low, vdup_n_u8(1)); // cond[i] == false\n        uint8x8_t mask_high = vclt_u8(cond_bytes_high, vdup_n_u8(1)); // cond[i] == false\n\n        // Zero out differences where cond[i] is false\n        float32x4_t zero_vec = vdupq_n_f32(0.0f);\n        float32x4_t result_low = vbslq_f32(vcombine_u8(mask_low, mask_high), zero_vec, diff_float_vec);\n\n        // Store the results in diff array\n        vst1q_f32(&diff[i], result_low);\n    }\n\n    // Handle remaining scalar elements\n    for (; i < size; ++i) {\n        diff[i] = cond[i] ? (float)(A[i] - A[i - 1]) : 0.0f;\n    }\n}\n```"}
{"task_id": "SimdBench_58_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid conditional_diff_simd(const int32_t* A, const bool* cond, float* diff, size_t size) {\n    if (size == 0) return;\n\n    diff[0] = 0.0f;\n    if (size == 1) return;\n\n    const int32x4_t v_zero = vmovq_n_s32(0);\n    const float32x4_t v_fzero = vmovq_n_f32(0.0f);\n\n    for (size_t i = 1; i <= size - 4; i += 4) {\n        int32x4_t vA_curr = vld1q_s32(&A[i]);\n        int32x4_t vA_prev = vld1q_s32(&A[i - 1]);\n\n        int32x4_t v_diff = vsubq_s32(vA_curr, vA_prev);\n\n        uint32x4_t v_cond = vld1q_u32((const uint32_t*)&cond[i]);\n        v_cond = vandq_u32(v_cond, vdupq_n_u32(1)); // Ensure cond is treated as 0 or 1\n\n        int32x4_t v_masked_diff = vbslq_s32(v_cond, v_diff, v_zero);\n        float32x4_t v_fdiff = vcvtq_f32_s32(v_masked_diff);\n\n        vst1q_f32(&diff[i], v_fdiff);\n    }\n\n    for (size_t i = size - size % 4; i < size; ++i) {\n        diff[i] = cond[i] ? (float)(A[i] - A[i - 1]) : 0.0f;\n    }\n}\n```"}
{"task_id": "SimdBench_58_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid conditional_diff_simd(const int32_t* A, const bool* cond, float* diff, size_t size) {\n    if (size == 0) return;\n\n    *diff = 0.0f; // Set the first element to 0.0f\n    size_t i = 1;\n\n    // Handle the remaining elements using Neon SIMD\n    for (; i <= size - 16; i += 16) {\n        // Load 16 consecutive integers from A[i-1] and A[i]\n        int32x4_t prev_vec = vld1q_s32(&A[i - 1]);\n        int32x4_t curr_vec = vld1q_s32(&A[i]);\n\n        // Compute differences (curr - prev)\n        int32x4_t diff_vec = vsubq_s32(curr_vec, prev_vec);\n\n        // Convert differences to float\n        float32x4_t diff_float_vec = vcvtq_f32_s32(diff_vec);\n\n        // Load 16 consecutive boolean conditions\n        uint8x16_t cond_vec = vld1q_u8(reinterpret_cast<const uint8_t*>(&cond[i]));\n\n        // Create a vector of zeros\n        float32x4_t zero_vec = vmovq_n_f32(0.0f);\n\n        // Perform a select operation: if cond is true, use diff_float, else use zero\n        float32x4_t result_vec_1 = vbslq_f32(vget_low_u8(cond_vec), vget_low_f32(diff_float_vec), vget_low_f32(zero_vec));\n        float32x4_t result_vec_2 = vbslq_f32(vget_high_u8(cond_vec), vget_high_f32(diff_float_vec), vget_high_f32(zero_vec));\n\n        // Store the results into the diff array\n        vst1q_f32(&diff[i], vcombine_f32(result_vec_1, result_vec_2));\n    }\n\n    // Scalar fallback for any remaining elements\n    for (; i < size; ++i) {\n        diff[i] = cond[i] ? static_cast<float>(A[i] - A[i - 1]) : 0.0f;\n    }\n}\n```"}
{"task_id": "SimdBench_59_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid widening_uint_simd(const uint32_t* src, uint64_t* dst, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 4; i += 4) {\n        uint32x4_t v_src = vld1q_u32(src + i);\n        uint64x2_t v_high = vmovq_n_u64(0xFFFFFFFFFFFFFFFF);\n        uint64x2_t v_low = vmovl_u32(vget_low_u32(v_src));\n        uint64x2_t v_high_part = vcombine_u64(v_high, v_high);\n        uint64x2_t v_result_low = vorr_u64(v_low, v_high_part);\n\n        uint64x2_t v_low2 = vmovl_u32(vget_high_u32(v_src));\n        uint64x2_t v_result_high = vorr_u64(v_low2, v_high_part);\n\n        vst1q_u64(dst + i, vcombine_u64(v_result_low, v_result_high));\n    }\n    for (; i < length; ++i) {\n        dst[i] = (uint64_t)(src[i]) | 0xFFFFFFFF00000000ULL;\n    }\n}\n```"}
{"task_id": "SimdBench_59_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid widening_uint_simd(const uint32_t* src, uint64_t* dst, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 4; i += 4) {\n        uint32x4_t v_src = vld1q_u32(src + i);\n        uint64x2_t v_high = vmovl_u32(vget_low_u32(v_src));\n        uint64x2_t v_low = vmovl_u32(vget_high_u32(v_src));\n        uint64x2_t v_high_set = vorr_u64(v_high, vdupq_n_u64(0xFFFFFFFF00000000ULL));\n        uint64x2_t v_low_set = vorr_u64(v_low, vdupq_n_u64(0xFFFFFFFF00000000ULL));\n        vst1q_u64(dst + i, vcombine_u64(v_high_set, v_low_set));\n    }\n    for (; i < length; i++) {\n        dst[i] = (uint64_t)(src[i]) | 0xFFFFFFFF00000000ULL;\n    }\n}\n```"}
{"task_id": "SimdBench_59_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid widening_uint_simd(const uint32_t* src, uint64_t* dst, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 4; i += 4) {\n        uint32x4_t v_src = vld1q_u32(src + i);\n        uint64x2_t v_high = vmovq_n_u64(0xFFFFFFFFFFFFFFFF);\n        uint64x2_t v_low = vmovl_u32(vget_low_u32(v_src));\n        uint64x2_t v_high_low = vzipq_u64(v_high, v_low).val[0];\n        vst1q_u64(dst + i, v_high_low);\n    }\n    for (; i < length; ++i) {\n        dst[i] = (uint64_t)(src[i]) | 0xFFFFFFFF00000000ULL;\n    }\n}\n```"}
{"task_id": "SimdBench_59_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid widening_uint_simd(const uint32_t* src, uint64_t* dst, size_t length) {\n    size_t i = 0;\n    for (; i <= length - 4; i += 4) {\n        uint32x4_t v_src = vld1q_u32(src + i);\n        uint64x2_t v_high = vmovl_u32(vget_low_u32(v_src));\n        uint64x2_t v_low = vmovl_u32(vget_high_u32(v_src));\n        uint64x2_t v_mask_high = vmovq_n_u64(0xFFFFFFFF00000000ULL);\n        uint64x2_t v_result_high = vorr_u64(v_high, v_mask_high);\n        uint64x2_t v_result_low = vorr_u64(v_low, v_mask_high);\n        vst1q_u64(dst + i, vcombine_u64(v_result_high, v_result_low));\n    }\n    for (; i < length; i++) {\n        dst[i] = (uint64_t)(src[i]) | 0xFFFFFFFF00000000ULL;\n    }\n}\n```"}
{"task_id": "SimdBench_59_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid widening_uint_simd(const uint32_t* src, uint64_t* dst, size_t length) {\n    size_t i = 0;\n    uint32x4_t v_high = vdupq_n_u32(0xFFFFFFFF);\n    \n    for (; i <= length - 4; i += 4) {\n        uint32x4_t v_src = vld1q_u32(src + i);\n        uint64x2_t v_dst_low = vmovl_u32(vget_low_u32(v_src));\n        uint64x2_t v_dst_high = vmovl_u32(vget_high_u32(v_src));\n        \n        uint64x2_t v_high_low = vmovl_u32(vget_low_u32(v_high));\n        uint64x2_t v_high_high = vmovl_u32(vget_high_u32(v_high));\n        \n        v_dst_low = vorr_u64(v_dst_low, v_high_low);\n        v_dst_high = vorr_u64(v_dst_high, v_high_high);\n        \n        vst1q_u64(dst + i, vcombine_u64(v_dst_low, v_dst_high));\n    }\n    \n    for (; i < length; i++) {\n        dst[i] = (uint64_t)(src[i]) | 0xFFFFFFFF00000000ULL;\n    }\n}\n```"}
{"task_id": "SimdBench_60_Neon", "completion": "```c\n#include <arm_neon.h>\n\ndouble indexed_sum_simd(const double* vec, const int16_t* index, size_t length) {\n    double result = 0.0;\n    size_t i = 0;\n\n    // Process in chunks of 4 indices per iteration using SIMD.\n    for (; i <= length - 4; i += 4) {\n        int16x4_t idx_vec = vld1_s16(&index[i]);\n        uint64x2_t idx_u64 = vmovl_u32(vreinterpret_n_u32_s16(idx_vec));\n\n        float64x2_t val1 = vld1q_f64((const double*)&vec[vgetq_lane_u64(idx_u64, 0)]);\n        float64x2_t val2 = vld1q_f64((const double*)&vec[vgetq_lane_u64(idx_u64, 1)]);\n\n        float64x2_t sum = vaddq_f64(val1, val2);\n        result += vgetq_lane_f64(sum, 0) + vgetq_lane_f64(sum, 1);\n    }\n\n    // Handle remaining elements (if any).\n    for (; i < length; ++i) {\n        result += vec[index[i]];\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_60_Neon", "completion": "```c\ndouble indexed_sum_simd(const double* vec, const int16_t* index, size_t length) {\n    double result = 0.0;\n    size_t i = 0;\n\n    // Process 8 indices at a time using SIMD\n    for (; i <= length - 8; i += 8) {\n        int16x8_t idx_vec = vld1q_s16(&index[i]);\n        \n        // Convert indices to unsigned for table lookup\n        uint16x8_t uidx_vec = vreinterpretq_u16_s16(idx_vec);\n\n        // Gather the corresponding doubles from vec\n        float64x2_t val1 = vld1q_f64((const double*)&vec[vgetq_lane_u16(uidx_vec, 0)]);\n        float64x2_t val2 = vld1q_f64((const double*)&vec[vgetq_lane_u16(uidx_vec, 2)]);\n        float64x2_t val3 = vld1q_f64((const double*)&vec[vgetq_lane_u16(uidx_vec, 4)]);\n        float64x2_t val4 = vld1q_f64((const double*)&vec[vgetq_lane_u16(uidx_vec, 6)]);\n\n        // Sum within each pair of doubles\n        float64x2_t sum1 = vaddq_f64(val1, val2);\n        float64x2_t sum2 = vaddq_f64(val3, val4);\n\n        // Combine sums\n        float64x2_t total = vaddq_f64(sum1, sum2);\n\n        // Accumulate into result\n        result += vgetq_lane_f64(total, 0) + vgetq_lane_f64(total, 1);\n    }\n\n    // Handle remaining elements\n    for (; i < length; ++i) {\n        if (index[i] >= 0 && index[i] < (int16_t)length) {\n            result += vec[index[i]];\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_60_Neon", "completion": "```c\n#include <arm_neon.h>\n\ndouble indexed_sum_simd(const double* vec, const int16_t* index, size_t length) {\n    double result = 0.0;\n    size_t i = 0;\n\n    // Process 4 indices at a time using SIMD\n    for (; i <= length - 4; i += 4) {\n        int16x4_t idx_vec = vld1_s16(&index[i]);\n        uint64x2_t idx_u64 = vmovl_u32(vreinterpret_u32_s16(idx_vec));\n        \n        float64x2_t val1 = vld1q_f64((const double*)&vec[vgetq_lane_u32(vreinterpret_u32_u64(idx_u64), 0)]);\n        float64x2_t val2 = vld1q_f64((const double*)&vec[vgetq_lane_u32(vreinterpret_u32_u64(idx_u64), 1)]);\n        \n        float64x2_t sum = vaddq_f64(val1, val2);\n        float64x2_t acc = vdupq_n_f64(result);\n        acc = vaddq_f64(acc, sum);\n        result = vgetq_lane_f64(acc, 0) + vgetq_lane_f64(acc, 1);\n    }\n\n    // Handle remaining elements\n    for (; i < length; ++i) {\n        if (index[i] >= 0 && index[i] < length) {\n            result += vec[index[i]];\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_60_Neon", "completion": "```c\n#include <arm_neon.h>\n\ndouble indexed_sum_simd(const double* vec, const int16_t* index, size_t length) {\n    double result = 0.0;\n    size_t i = 0;\n\n    // Process in chunks of 4 indices (since we can load 4 indices into a SIMD register)\n    for (; i <= length - 4; i += 4) {\n        int16x4_t idx_vec = vld1_s16(&index[i]);\n        uint64x2_t idx_u64 = vmovl_u16(vreinterpret_s16_u16(idx_vec));\n        uint64x2_t clamped_idx = vminq_u64(idx_u64, vdupq_n_u64(length - 1));\n\n        float64x2_t val1 = vld1q_f64((const double*)&vec[vgetq_lane_u64(clamped_idx, 0)]);\n        float64x2_t val2 = vld1q_f64((const double*)&vec[vgetq_lane_u64(clamped_idx, 1)]);\n\n        float64x2_t sum_vec = vaddq_f64(val1, val2);\n        result += vgetq_lane_f64(sum_vec, 0) + vgetq_lane_f64(sum_vec, 1);\n    }\n\n    // Handle remaining elements\n    for (; i < length; ++i) {\n        if (index[i] >= 0 && index[i] < (int16_t)length) {\n            result += vec[index[i]];\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_60_Neon", "completion": "```c\ndouble indexed_sum_simd(const double* vec, const int16_t* index, size_t length) {\n    double result = 0.0;\n    const size_t unroll_factor = 4;\n    size_t i;\n\n    if (length >= unroll_factor) {\n        float64x2_t sum_vec = vdupq_n_f64(0.0);\n        for (i = 0; i <= length - unroll_factor; i += unroll_factor) {\n            int32x4_t idx_load = vmovl_s16(vld1_s16(index + i));\n            float64x2_t val1 = vld1q_f64((const double*)&vec[idx_load[0]]);\n            float64x2_t val2 = vld1q_f64((const double*)&vec[idx_load[1]]);\n            float64x2_t pair1 = vaddq_f64(val1, val2);\n            sum_vec = vaddq_f64(sum_vec, pair1);\n\n            float64x2_t val3 = vld1q_f64((const double*)&vec[idx_load[2]]);\n            float64x2_t val4 = vld1q_f64((const double*)&vec[idx_load[3]]);\n            float64x2_t pair2 = vaddq_f64(val3, val4);\n            sum_vec = vaddq_f64(sum_vec, pair2);\n        }\n        float64x2_t sum_low = vpadd_f64(vget_low_f64(sum_vec), vget_high_f64(sum_vec));\n        result += vget_lane_f64(sum_low, 0);\n    }\n\n    for (; i < length; ++i) {\n        if (index[i] >= 0 && index[i] < (int16_t)length) {\n            result += vec[index[i]];\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_61_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid simple_conv2d_simd(const double* input, const double* kernel, double * output, size_t input_size, size_t kernel_size) {\n    size_t output_size = input_size - kernel_size + 1;\n    size_t k_area = kernel_size * kernel_size;\n\n    for (size_t i = 0; i <= input_size - kernel_size; ++i) {\n        for (size_t j = 0; j <= input_size - kernel_size; ++j) {\n            double accum[2] = {0.0, 0.0};\n            \n            for (size_t ki = 0; ki < kernel_size; ++ki) {\n                for (size_t kj = 0; kj < kernel_size; ++kj) {\n                    size_t in_idx = (i + ki) * input_size + (j + kj);\n                    size_t ker_idx = ki * kernel_size + kj;\n                    \n                    double val = input[in_idx] * kernel[ker_idx];\n                    \n                    uint64x2_t vval = vdupq_n_f64(val);\n                    accum[0] += vgetq_lane_f64(vval, 0);\n                    accum[1] += vgetq_lane_f64(vval, 1);\n                }\n            }\n\n            // ReLU activation\n            accum[0] = (accum[0] > 0) ? accum[0] : 0;\n            accum[1] = (accum[1] > 0) ? accum[1] : 0;\n\n            size_t out_idx = i * (input_size - kernel_size + 1) + j;\n            output[out_idx] = accum[0] + accum[1];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_61_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid simple_conv2d_simd(const double* input, const double* kernel, double * output, size_t input_size, size_t kernel_size) {\n    size_t output_size = input_size - kernel_size + 1;\n    size_t k_area = kernel_size * kernel_size;\n\n    for (size_t i = 0; i <= input_size - kernel_size; ++i) {\n        for (size_t j = 0; j <= input_size - kernel_size; ++j) {\n            double accum[2] = {0.0, 0.0};\n            \n            for (size_t ki = 0; ki < kernel_size; ++ki) {\n                for (size_t kj = 0; kj < kernel_size; ++kj) {\n                    size_t in_idx = ((i + ki) * input_size + (j + kj)) * 2;\n                    size_t ker_idx = (ki * kernel_size + kj) * 2;\n                    \n                    float64x2_t vin = vld1q_f64(&input[in_idx]);\n                    float64x2_t vk = vld1q_f64(&kernel[ker_idx]);\n                    float64x2_t vmul = vmulq_f64(vin, vk);\n                    \n                    accum[0] += vmul[0];\n                    accum[1] += vmul[1];\n                }\n            }\n\n            accum[0] = (accum[0] > 0.0) ? accum[0] : 0.0;\n            accum[1] = (accum[1] > 0.0) ? accum[1] : 0.0;\n\n            size_t out_idx = ((i * (input_size - kernel_size + 1) + j) * 2);\n            float64x2_t vout = vld1q_f64(&output[out_idx]);\n            float64x2_t vres = vsetq_lane_f64(accum[0], vout, 0);\n            vres = vsetq_lane_f64(accum[1], vres, 1);\n            vst1q_f64(&output[out_idx], vres);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_61_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid simple_conv2d_simd(const double* input, const double* kernel, double * output, size_t input_size, size_t kernel_size) {\n    size_t output_size = input_size - kernel_size + 1;\n    size_t k_area = kernel_size * kernel_size;\n\n    for (size_t i = 0; i <= input_size - kernel_size; ++i) {\n        for (size_t j = 0; j <= input_size - kernel_size; ++j) {\n            double accum[2] = {0.0, 0.0};\n            \n            for (size_t ki = 0; ki < kernel_size; ++ki) {\n                for (size_t kj = 0; kj < kernel_size; ++kj) {\n                    size_t in_idx = ((i + ki) * input_size + (j + kj));\n                    size_t ker_idx = ki * kernel_size + kj;\n\n                    double in_val = input[in_idx];\n                    double ker_val = kernel[ker_idx];\n\n                    uint64x2_t vin = vdupq_n_f64(in_val);\n                    uint64x2_t vker = vdupq_n_f64(ker_val);\n\n                    uint64x2_t vprod = vmulq_f64(vin, vker);\n                    \n                    accum[0] += vgetq_lane_f64(vprod, 0);\n                    accum[1] += vgetq_lane_f64(vprod, 1);\n                }\n            }\n\n            accum[0] = accum[0] > 0.0 ? accum[0] : 0.0;\n            accum[1] = accum[1] > 0.0 ? accum[1] : 0.0;\n\n            size_t out_idx = i * (input_size - kernel_size + 1) + j;\n            output[out_idx] = accum[0];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_61_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid simple_conv2d_simd(const double* input, const double* kernel, double * output, size_t input_size, size_t kernel_size) {\n    size_t output_size = input_size - kernel_size + 1;\n    \n    for (size_t i = 0; i < output_size; ++i) {\n        for (size_t j = 0; j < output_size; ++j) {\n            double accum[4] = {0.0, 0.0, 0.0, 0.0};\n            \n            for (size_t m = 0; m < kernel_size; ++m) {\n                for (size_t n = 0; n < kernel_size; n += 4) {\n                    size_t k_idx = (m * kernel_size) + n;\n                    size_t in_row_idx = (i + m) * input_size + j + n;\n                    \n                    float64x2_t vker_0 = vld1q_f64(&kernel[k_idx]);\n                    float64x2_t vin_0 = vld1q_f64(&input[in_row_idx]);\n                    \n                    accum[0] += vgetq_lane_f64(vker_0, 0) * vgetq_lane_f64(vin_0, 0);\n                    accum[1] += vgetq_lane_f64(vker_0, 1) * vgetq_lane_f64(vin_0, 1);\n                    \n                    if (n + 2 < kernel_size) {\n                        float64x2_t vker_1 = vld1q_f64(&kernel[k_idx + 2]);\n                        float64x2_t vin_1 = vld1q_f64(&input[in_row_idx + 2]);\n                        \n                        accum[2] += vgetq_lane_f64(vker_1, 0) * vgetq_lane_f64(vin_1, 0);\n                        accum[3] += vgetq_lane_f64(vker_1, 1) * vgetq_lane_f64(vin_1, 1);\n                    }\n                }\n            }\n            \n            // ReLU activation\n            size_t out_idx = (i * output_size) + j;\n            if (out_idx % 4 == 0 && out_idx + 3 < output_size * output_size) {\n                float64x2_t vres_0 = vmaxpq_f64(vld1q_f64(accum), vdupq_n_f64(0.0));\n                vst1q_f64(&output[out_idx], vres_0);\n            } else {\n                for (size_t k = 0; k < 4 && out_idx + k < output_size * output_size; ++k) {\n                    output[out_idx + k] = (accum[k] > 0.0) ? accum[k] : 0.0;\n                }\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_61_Neon", "completion": "```c\n#include <arm_neon.h>\n\nvoid simple_conv2d_simd(const double* input, const double* kernel, double * output, size_t input_size, size_t kernel_size) {\n    size_t output_size = input_size - kernel_size + 1;\n    size_t k_area = kernel_size * kernel_size;\n\n    for (size_t i = 0; i < output_size; ++i) {\n        for (size_t j = 0; j < output_size; ++j) {\n            double accum[2] = {0.0, 0.0};\n            \n            for (size_t ki = 0; ki < kernel_size; ++ki) {\n                for (size_t kj = 0; kj < kernel_size; ++kj) {\n                    size_t idx_input = ((i + ki) * input_size + (j + kj)) * 2;\n                    size_t idx_kernel = (ki * kernel_size + kj) * 2;\n                    \n                    float64x2_t v_in = vld1q_f64(&input[idx_input]);\n                    float64x2_t v_ker = vld1q_f64(&kernel[idx_kernel]);\n                    float64x2_t v_prod = vmulq_f64(v_in, v_ker);\n                    \n                    accum[0] += vgetq_lane_f64(v_prod, 0);\n                    accum[1] += vgetq_lane_f64(v_prod, 1);\n                }\n            }\n            \n            accum[0] += accum[1];\n            accum[0] = (accum[0] > 0.0) ? accum[0] : 0.0;\n            output[i * output_size + j] = accum[0];\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_62_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <cmath>\n\nbool has_close_elements_simd(const std::vector<double> & numbers, double threshold){\n    if (numbers.size() < 2) return false;\n\n    size_t n = numbers.size();\n    const double *data = numbers.data();\n    double threshold_d = threshold;\n\n    // Load threshold into a vector\n    float64x2_t vthreshold = vdupq_n_f64(threshold_d);\n\n    for (size_t i = 0; i < n - 1; ++i) {\n        float64x2_t va = vld1q_f64(&data[i]);\n\n        for (size_t j = i + 1; j < n; j += 2) {\n            if (j + 1 < n) {\n                float64x2_t vb = vld1q_f64(&data[j]);\n                float64x2_t vdif = vabsq_f64(vsubq_f64(va, vb));\n                uint64x2_t cmp = vcgtq_f64(vthreshold, vdif);\n                if (vgetq_lane_u64(cmp, 0) || vgetq_lane_u64(cmp, 1)) {\n                    return true;\n                }\n            } else {\n                float64x1_t vb = vld1_f64(&data[j]);\n                float64x1_t vdif = vabs_f64(vsub_f64(vget_low_f64(va), vb));\n                if (vdif[0] < threshold_d) {\n                    return true;\n                }\n            }\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_62_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <cmath>\n\nbool has_close_elements_simd(const std::vector<double> & numbers, double threshold){\n    if (numbers.size() < 2) return false;\n\n    size_t n = numbers.size();\n    const double *data = numbers.data();\n    double threshold_vec[2] = {threshold, threshold};\n    int32_t result = 0;\n\n    for(size_t i = 0; i < n - 1; ++i){\n        double a1 = data[i];\n        double a_vec[2] = {a1, a1};\n        \n        // Load comparison values\n        for(size_t j = i + 1; j < n; j += 2){\n            if(n - j < 2){\n                double b1 = data[j];\n                double diff = fabs(a1 - b1);\n                if(diff < threshold) return true;\n                break;\n            }\n\n            double b_vec[2];\n            b_vec[0] = data[j];\n            b_vec[1] = data[j+1];\n\n            float64x2_t va = vld1q_f64(a_vec);\n            float64x2_t vb = vld1q_f64(b_vec);\n            float64x2_t vt = vld1q_f64(threshold_vec);\n\n            float64x2_t vd = vabsq_f64(vsubq_f64(va, vb));\n            uint64x2_t cmp = vcgtq_f64(vt, vd);\n\n            int64x2_t res = vreinterpretq_s64_u64(cmp);\n            int64x2_t zero = vdupq_n_s64(0);\n            int32x2_t cond = vmovn_s64(vceqq_s64(res, zero));\n\n            result |= vget_lane_s32(cond, 0) | vget_lane_s32(cond, 1);\n            if(result) return true;\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_62_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <cmath>\n\nbool has_close_elements_simd(const std::vector<double> & numbers, double threshold){\n    if (numbers.size() < 2) return false;\n\n    size_t n = numbers.size();\n    const double *data = numbers.data();\n    double threshold_d = threshold;\n\n    // Load threshold into a vector\n    float64x2_t vthreshold = vdupq_n_f64(threshold_d);\n\n    for (size_t i = 0; i < n - 1; ++i) {\n        float64x2_t va = vld1q_f64(&data[i]);\n\n        for (size_t j = i + 1; j < n; j += 2) {\n            if (j + 1 < n) {\n                float64x2_t vb = vld1q_f64(&data[j]);\n                float64x2_t vd = vabdq_f64(va, vb);\n                uint64x2_t cmp = vcgtq_f64(vd, vthreshold);\n                if (vminvq_u64(cmp) == 0) {\n                    return true;\n                }\n            } else {\n                double diff = std::fabs(data[i] - data[j]);\n                if (diff < threshold_d) {\n                    return true;\n                }\n            }\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_62_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <cmath>\n\nbool has_close_elements_simd(const std::vector<double> & numbers, double threshold){\n    if (numbers.size() < 2) return false;\n\n    size_t n = numbers.size();\n    const double *data = numbers.data();\n    double threshold_vec[2] = {threshold, threshold};\n    float64x2_t thresh = vld1q_f64(threshold_vec);\n\n    for(size_t i = 0; i < n - 1; ++i){\n        double a = data[i];\n        float64x2_t val = vdupq_n_f64(a);\n\n        // Process two elements at a time\n        for(size_t j = i + 1; j + 1 < n; j += 2){\n            float64x2_t b = vld1q_f64(data + j);\n            float64x2_t diff = vabsq_f64(vsubq_f64(val, b));\n            uint64x2_t cmp = vcgtq_f64(thresh, diff);\n            if(vgetq_lane_u64(cmp, 0) || vgetq_lane_u64(cmp, 1)){\n                return true;\n            }\n        }\n\n        // Handle the case where the number of remaining elements is odd\n        if((n - i - 1) % 2 == 1){\n            size_t j = n - 1;\n            double diff = std::fabs(a - data[j]);\n            if(diff < threshold){\n                return true;\n            }\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_62_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <cmath>\n\nbool has_close_elements_simd(const std::vector<double> & numbers, double threshold){\n    if (numbers.size() < 2) return false;\n\n    size_t n = numbers.size();\n    const double *data = numbers.data();\n    double threshold_d = threshold;\n    float64x2_t vthreshold = vdupq_n_f64(threshold_d);\n\n    for (size_t i = 0; i < n - 1; ++i) {\n        float64x2_t vi = vld1q_f64(&data[i]);\n\n        for (size_t j = i + 1; j < n; j += 2) {\n            float64x2_t vj = vld1q_f64(&data[j]);\n            float64x2_t diff = vabdq_f64(vi, vj);\n            uint64x2_t mask = vcgtq_f64(vthreshold, diff);\n            if (vmaxvq_u64(mask)) {\n                return true;\n            }\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_63_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nbool below_zero_simd(std::vector<int> operations){\n    if (operations.empty()) return false;\n\n    const int *data = operations.data();\n    size_t size = operations.size();\n\n    int32x4_t acc = vdupq_n_s32(0); // Initialize accumulator with zeros\n\n    for (size_t i = 0; i < size; i += 4) {\n        int32x4_t vec = vld1q_s32(data + i);\n        acc = vaddq_s32(acc, vec);\n\n        // Check if any lane is below zero\n        uint32x4_t mask = vcgtq_s32(vdupq_n_s32(0), acc);\n        if (vmaxvq_u32(mask) != 0) {\n            return true;\n        }\n    }\n\n    // Handle remaining elements (if any)\n    for (size_t i = (size / 4) * 4; i < size; ++i) {\n        int balance = 0;\n        for (size_t j = 0; j <= i; ++j) {\n            balance += operations[j];\n        }\n        if (balance < 0) return true;\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_63_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nbool below_zero_simd(std::vector<int> operations){\n    if (operations.empty()) return false;\n\n    const int *data = operations.data();\n    size_t size = operations.size();\n\n    int32x4_t acc = vdupq_n_s32(0); // Initialize accumulator with zero balance\n\n    for(size_t i = 0; i < size; i += 4){\n        int32x4_t ops = vld1q_s32(data + i);\n        acc = vaddq_s32(acc, ops);\n\n        // Check if any lane is below zero\n        uint32x4_t mask = vcgtq_s32(vdupq_n_s32(0), acc);\n        if (vmaxvq_u32(mask) != 0){\n            return true;\n        }\n    }\n\n    // Handle remaining elements\n    for(size_t i = (size / 4) * 4; i < size; ++i){\n        int balance = 0;\n        balance += data[i];\n        if(balance < 0){\n            return true;\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_63_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nbool below_zero_simd(std::vector<int> operations) {\n    if (operations.empty()) return false;\n\n    const int *data = operations.data();\n    size_t size = operations.size();\n\n    int32x4_t acc = vdupq_n_s32(0); // Initialize accumulator with 0\n\n    for (size_t i = 0; i < size / 4 * 4; i += 4) {\n        int32x4_t vec = vld1q_s32(data + i);\n        acc = vaddq_s32(acc, vec);\n\n        int32x4_t cmp = vcgtq_s32(vdupq_n_s32(0), acc);\n        uint32x4_t mask = vandq_u32(vcgeq_s32(acc, vdupq_n_s32(0)), vmovq_n_u32(0xFFFFFFFF));\n        if (vminvq_s32(acc) < 0) return true;\n    }\n\n    int remainder = size % 4;\n    if (remainder > 0) {\n        int32x4_t tail = vdupq_n_s32(0);\n        for (size_t i = 0; i < remainder; ++i) {\n            int32x4_t val = vdupq_n_s32(data[size - remainder + i]);\n            tail = vaddq_s32(tail, val);\n        }\n        if (vminvq_s32(tail) < 0) return true;\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_63_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nbool below_zero_simd(std::vector<int> operations){\n    if (operations.empty()) return false;\n\n    int32x4_t vec_balance = vdupq_n_s32(0);\n    int32x4_t vec_temp;\n    int32x4_t vec_zero = vdupq_n_s32(0);\n\n    size_t i = 0;\n    for (; i <= operations.size() - 4; i += 4) {\n        vec_temp = vld1q_s32(&operations[i]);\n        vec_balance = vaddq_s32(vec_balance, vec_temp);\n        if (vminvq_s32(vec_balance) < 0) return true;\n    }\n\n    int balance = 0;\n    for (; i < operations.size(); ++i) {\n        balance += operations[i];\n        if (balance < 0) return true;\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_63_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nbool below_zero_simd(std::vector<int> operations){\n    if (operations.empty()) return false;\n\n    int32x4_t zero = vdupq_n_s32(0);\n    int32x4_t balance = vdupq_n_s32(0);\n\n    size_t i = 0;\n    for (; i + 4 <= operations.size(); i += 4) {\n        int32x4_t op = vld1q_s32(&operations[i]);\n        balance = vaddq_s32(balance, op);\n        int32x4_t cmp = vcmltq_s32(balance, zero);\n        if (vmaxvq_u32(vreinterpretq_u32_s32(cmp)) != 0) {\n            return true;\n        }\n    }\n\n    int acc = 0;\n    for (; i < operations.size(); ++i) {\n        acc += operations[i];\n        if (acc < 0) return true;\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_64_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <cmath>\n\ndouble mean_absolute_deviation_simd(std::vector<double> numbers){\n    size_t n = numbers.size();\n    if (n == 0) return 0.0;\n\n    // Calculate the mean\n    double sum = 0.0;\n    for(double num : numbers){\n        sum += num;\n    }\n    double mean = sum / n;\n\n    // Load mean into all lanes of a SIMD register\n    float64x2_t vmean = vdupq_n_f64(mean);\n\n    // Process in chunks of 2 elements using SIMD\n    double mad_sum = 0.0;\n    size_t i = 0;\n\n    // Use Neon instructions to process pairs of elements\n    for (; i <= n - 2; i += 2) {\n        float64x2_t vnums = vld1q_f64(&numbers[i]);\n        float64x2_t vdiff = vabsq_f64(vsubq_f64(vnums, vmean));\n        float64x2_t vsum = vpaddlq_f64(vdiff);\n        mad_sum += vgetq_lane_f64(vsum, 0) + vgetq_lane_f64(vsum, 1);\n    }\n\n    // Handle any remaining elements\n    for (; i < n; ++i) {\n        mad_sum += std::fabs(numbers[i] - mean);\n    }\n\n    return mad_sum / n;\n}\n```"}
{"task_id": "SimdBench_64_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <cmath>\n\ndouble mean_absolute_deviation_simd(std::vector<double> numbers){\n    size_t n = numbers.size();\n    if (n == 0) return 0.0;\n\n    // Calculate the sum using Neon\n    double *data = numbers.data();\n    uint64_t i = 0;\n    double vsum = 0.0;\n    float64x2_t sum_vec = vdupq_n_f64(0.0);\n\n    for (; i <= n - 2; i += 2) {\n        float64x2_t vec = vld1q_f64(data + i);\n        sum_vec = vaddq_f64(sum_vec, vec);\n    }\n\n    float64x2_t sum_parts = vpadd_f64(vget_low_f64(sum_vec), vget_high_f64(sum_vec));\n    vsum += vget_lane_f64(sum_parts, 0) + vget_lane_f64(sum_parts, 1);\n\n    for (; i < n; ++i) {\n        vsum += data[i];\n    }\n\n    double mean = vsum / n;\n\n    // Calculate MAD using Neon\n    double mad = 0.0;\n    float64x2_t mean_vec = vdupq_n_f64(mean);\n    float64x2_t mad_vec = vdupq_n_f64(0.0);\n\n    i = 0;\n    for (; i <= n - 2; i += 2) {\n        float64x2_t vec = vld1q_f64(data + i);\n        float64x2_t diff = vabdq_f64(vec, mean_vec);\n        mad_vec = vaddq_f64(mad_vec, diff);\n    }\n\n    float64x2_t mad_parts = vpadd_f64(vget_low_f64(mad_vec), vget_high_f64(mad_vec));\n    mad += vget_lane_f64(mad_parts, 0) + vget_lane_f64(mad_parts, 1);\n\n    for (; i < n; ++i) {\n        mad += std::abs(data[i] - mean);\n    }\n\n    return mad / n;\n}\n```"}
{"task_id": "SimdBench_64_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <cmath>\n\ndouble mean_absolute_deviation_simd(std::vector<double> numbers){\n    size_t n = numbers.size();\n    if (n == 0) return 0.0;\n\n    // Calculate the sum using Neon\n    double sum = 0.0;\n    size_t i = 0;\n    double *data = numbers.data();\n\n    // Use Neon to calculate the sum\n    uint64_t vec_size = n / 2 * 2;\n    float64x2_t vsum = vdupq_n_f64(0.0);\n    for (; i < vec_size; i+=2){\n        float64x2_t vload = vld1q_f64(data + i);\n        vsum = vaddq_f64(vsum, vload);\n    }\n    sum += vgetq_lane_f64(vsum, 0) + vgetq_lane_f64(vsum, 1);\n\n    // Accumulate remaining elements\n    for (; i < n; ++i){\n        sum += numbers[i];\n    }\n\n    double mean = sum / n;\n\n    // Calculate the MAD using Neon\n    double mad = 0.0;\n    i = 0;\n    vsum = vdupq_n_f64(0.0);\n    for (; i < vec_size; i+=2){\n        float64x2_t vload = vld1q_f64(data + i);\n        float64x2_t vmean = vdupq_n_f64(mean);\n        float64x2_t vdiff = vabdq_f64(vload, vmean);\n        vsum = vaddq_f64(vsum, vdiff);\n    }\n    mad += vgetq_lane_f64(vsum, 0) + vgetq_lane_f64(vsum, 1);\n\n    // Accumulate remaining elements\n    for (; i < n; ++i){\n        mad += std::abs(numbers[i] - mean);\n    }\n\n    return mad / n;\n}\n```"}
{"task_id": "SimdBench_64_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <algorithm>\n\ndouble mean_absolute_deviation_simd(std::vector<double> numbers){\n    size_t n = numbers.size();\n    if (n == 0) return 0.0;\n\n    // Calculate the sum using SIMD\n    double sum = 0.0;\n    size_t i = 0;\n    double *data = numbers.data();\n\n    // Use SIMD to calculate the sum\n    uint64_t vec_size = n / 2 * 2;\n    float64x2_t vsum = vdupq_n_f64(0.0);\n    for (; i < vec_size; i += 2) {\n        float64x2_t vload = vld1q_f64(data + i);\n        vsum = vaddq_f64(vsum, vload);\n    }\n    sum = vgetq_lane_f64(vsum, 0) + vgetq_lane_f64(vsum, 1);\n\n    // Add remaining elements\n    for (; i < n; ++i) {\n        sum += data[i];\n    }\n\n    double mean = sum / n;\n\n    // Calculate the MAD using SIMD\n    double mad = 0.0;\n    i = 0;\n    vsum = vdupq_n_f64(0.0);\n    float64x2_t vmean = vdupq_n_f64(mean);\n    for (; i < vec_size; i += 2) {\n        float64x2_t vload = vld1q_f64(data + i);\n        float64x2_t vdiff = vabsq_f64(vsubq_f64(vload, vmean));\n        vsum = vaddq_f64(vsum, vdiff);\n    }\n    mad = vgetq_lane_f64(vsum, 0) + vgetq_lane_f64(vsum, 1);\n\n    // Add remaining elements\n    for (; i < n; ++i) {\n        mad += std::abs(data[i] - mean);\n    }\n\n    return mad / n;\n}\n```"}
{"task_id": "SimdBench_64_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <cmath>\n\ndouble mean_absolute_deviation_simd(std::vector<double> numbers){\n    size_t n = numbers.size();\n    if (n == 0) return 0.0;\n\n    // Calculate the mean\n    double sum = 0.0;\n    for(double num : numbers){\n        sum += num;\n    }\n    double mean = sum / n;\n\n    // Load mean into all lanes of a SIMD register\n    uint64_t mean_int = *reinterpret_cast<uint64_t*>(&mean);\n    float64x2_t vmean = vdupq_n_f64(mean);\n\n    // Calculate absolute deviations using SIMD\n    double mad_sum = 0.0;\n    for(size_t i = 0; i < n; i += 2){\n        float64x2_t vnums = vld1q_f64(&numbers[i]);\n        float64x2_t vdiff = vabsq_f64(vsubq_f64(vnums, vmean));\n        \n        // Extract results and accumulate\n        float64x2_t vres = vpaddq_f64(vdiff, vdiff);\n        double res = vgetq_lane_f64(vres, 0);\n        mad_sum += res;\n    }\n\n    // Handle remaining elements if any\n    for(size_t i = n - (n % 2); i < n; ++i){\n        mad_sum += std::abs(numbers[i] - mean);\n    }\n\n    return mad_sum / n;\n}\n```"}
{"task_id": "SimdBench_65_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int> intersperse_simd(std::vector<int> numbers, int delimeter){ \n    if (numbers.size() <= 1) return numbers;\n\n    size_t original_size = numbers.size();\n    size_t new_size = original_size + (original_size - 1);\n    std::vector<int> result(new_size);\n\n    // Load delimeter into all lanes of a NEON register\n    int32x4_t vdelim = vdupq_n_s32(delimeter);\n\n    size_t i = 0;\n    size_t j = 0;\n\n    for (; i < original_size - 3; i += 4, j += 9) {\n        // Load 4 numbers from input vector\n        int32x4_t vnum = vld1q_s32(&numbers[i]);\n\n        // Store the first number\n        vst1q_s32(&result[j], vnum);\n\n        // Store delimeters between numbers\n        vst1q_s32(&result[j + 5], vdelim);\n\n        result[j + 4] = delimeter;\n    }\n\n    // Handle remaining elements\n    for (; i < original_size; ++i, ++j) {\n        result[j] = numbers[i];\n        if (i != original_size - 1) {\n            result[++j] = delimeter;\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_65_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int> intersperse_simd(std::vector<int> numbers, int delimeter){ \n    if (numbers.size() <= 1) return numbers;\n\n    size_t original_size = numbers.size();\n    size_t new_size = original_size + (original_size - 1);\n    std::vector<int> result(new_size, delimeter);\n\n    int32x4_t delim_vec = vdupq_n_s32(delimeter);\n\n    for (size_t i = 0; i < original_size; i += 4) {\n        size_t j = i * 2;\n        size_t k = i;\n\n        size_t elements_left = original_size - i;\n        size_t batch_size = (elements_left > 4) ? 4 : elements_left;\n\n        int32x4_t vec = vld1q_s32(&numbers[i]);\n\n        if (batch_size >= 1) {\n            vst1q_lane_s32(&result[j], vec, 0);\n            j += 2;\n        }\n        if (batch_size >= 2) {\n            vst1q_lane_s32(&result[j], vec, 1);\n            j += 2;\n        }\n        if (batch_size >= 3) {\n            vst1q_lane_s32(&result[j], vec, 2);\n            j += 2;\n        }\n        if (batch_size >= 4) {\n            vst1q_lane_s32(&result[j], vec, 3);\n            j += 2;\n        }\n\n        if (i + 4 < original_size) {\n            vst1q_s32(&result[j - 1], delim_vec);\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_65_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int> intersperse_simd(std::vector<int> numbers, int delimeter){ \n    if (numbers.size() <= 1) return numbers;\n\n    size_t original_size = numbers.size();\n    size_t new_size = 2 * original_size - 1;\n    std::vector<int> result(new_size);\n\n    // Load delimeter into a SIMD register\n    int32x4_t vdelim = vdupq_n_s32(delimeter);\n\n    for (size_t i = 0; i < original_size; i += 4) {\n        size_t j = i * 2;\n\n        // Load up to 4 numbers from input vector\n        int32x4_t vnums = vld1q_s32(&numbers[i]);\n\n        // Store the first part of numbers into result\n        vst1q_s32(&result[j], vnums);\n\n        if (i + 4 < original_size) {\n            // Store delimeters after each number except the last one\n            vst1q_s32(&result[j + 5], vdelim);\n        } else {\n            // Handle remaining elements if not aligned\n            for (size_t k = i; k < original_size - 1; ++k) {\n                result[2 * k + 1] = delimeter;\n            }\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_65_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int> intersperse_simd(std::vector<int> numbers, int delimeter){ \n    if (numbers.size() <= 1) return numbers;\n\n    size_t original_size = numbers.size();\n    size_t new_size = 2 * original_size - 1;\n    std::vector<int> result(new_size);\n\n    // Load delimiter into a SIMD register\n    int32x4_t v_delim = vdupq_n_s32(delimeter);\n\n    for (size_t i = 0; i < original_size; i += 4) {\n        size_t j = i * 2;\n\n        // Load up to 4 numbers from input vector\n        int32x4_t v_nums;\n        if (i + 4 <= original_size) {\n            v_nums = vld1q_s32(&numbers[i]);\n        } else {\n            // Handle the case where less than 4 elements remain\n            int temp[4] = {0};\n            for (size_t k = 0; k < original_size - i; ++k) {\n                temp[k] = numbers[i + k];\n            }\n            v_nums = vld1q_s32(temp);\n        }\n\n        // Store the loaded numbers into the result vector\n        vst1q_s32(&result[j], v_nums);\n\n        if (i + 1 < original_size) {\n            // Insert delimiters after the loaded numbers\n            if (j + 4 < new_size) {\n                vst1q_s32(&result[j + 5], v_delim);\n            } else {\n                // Handle the case where less than 4 delimiters are needed\n                for (size_t k = 0; k < std::min<size_t>(4, new_size - j - 1); ++k) {\n                    result[j + 1 + k] = delimeter;\n                }\n            }\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_65_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int> intersperse_simd(std::vector<int> numbers, int delimeter){ \n    if (numbers.size() <= 1) return numbers;\n\n    size_t original_size = numbers.size();\n    size_t result_size = original_size * 2 - 1;\n    std::vector<int> result(result_size);\n\n    int32x4_t v_delim = vdupq_n_s32(delimeter);\n\n    for (size_t i = 0; i + 4 <= original_size; i += 4) {\n        int32x4_t v_nums = vld1q_s32(&numbers[i]);\n        int32x4_t v_nums_high = vextq_s32(v_nums, v_delim, 1);\n        \n        int32x2_t v_low = vget_low_s32(v_nums);\n        int32x2_t v_high = vget_high_s32(v_nums);\n\n        int32x2_t v_delim_low = vdup_n_s32(delimeter);\n        int32x2_t v_delim_high = vdup_n_s32(delimeter);\n\n        int32x4_t v_res_low = vcombine_s32(v_low, v_delim_low);\n        int32x4_t v_res_high = vcombine_s32(v_delim_high, v_high);\n\n        vst1q_s32(&result[2 * i], v_res_low);\n        vst1q_s32(&result[2 * i + 5], v_res_high);\n    }\n\n    // Handle leftovers\n    size_t i = (original_size / 4) * 4;\n    for (; i < original_size - 1; ++i) {\n        result[2 * i] = numbers[i];\n        result[2 * i + 1] = delimeter;\n    }\n    if (i < original_size) {\n        result[2 * i] = numbers[i];\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_66_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int64_t> sum_product_simd(std::vector<int16_t> numbers){\n    if (numbers.empty()) {\n        return {0, 1};\n    }\n\n    int64_t sum = 0;\n    int64_t product = 1;\n\n    const int16_t* data = numbers.data();\n    size_t size = numbers.size();\n\n    // Handle unaligned loads by processing in chunks of 8 elements\n    for (size_t i = 0; i + 8 <= size; i += 8) {\n        int16x8_t vec = vld1q_s16(data + i);\n        \n        // Sum\n        int32x4_t sum_low = vpaddlq_s16(vget_low_s16(vec));\n        int32x4_t sum_high = vpaddlq_s16(vget_high_s16(vec));\n        int64x2_t sum_res = vpaddlq_s32(vaddq_s32(sum_low, sum_high));\n        sum += vgetq_lane_s64(sum_res, 0) + vgetq_lane_s64(sum_res, 1);\n\n        // Product\n        int16x8_t prod_vec = vec;\n        int32x4_t prod_low = vmovl_s16(vget_low_s16(prod_vec));\n        int32x4_t prod_high = vmovl_s16(vget_high_s16(prod_vec));\n        int64x2_t prod_res = vmull_s32(vget_lane_s32(prod_low, 0), vget_lane_s32(prod_low, 1));\n        prod_res = vmulq_s64(prod_res, vmull_s32(vget_lane_s32(prod_low, 2), vget_lane_s32(prod_low, 3)));\n        prod_res = vmulq_s64(prod_res, vmull_s32(vget_lane_s32(prod_high, 0), vget_lane_s32(prod_high, 1)));\n        prod_res = vmulq_s64(prod_res, vmull_s32(vget_lane_s32(prod_high, 2), vget_lane_s32(prod_high, 3)));\n        product *= vgetq_lane_s64(prod_res, 0) * vgetq_lane_s64(prod_res, 1);\n    }\n\n    // Process remaining elements\n    for (size_t i = (size / 8) * 8; i < size; ++i) {\n        sum += data[i];\n        product *= data[i];\n    }\n\n    return {sum, product};\n}\n```"}
{"task_id": "SimdBench_66_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int64_t> sum_product_simd(std::vector<int16_t> numbers){\n    if (numbers.empty()) {\n        return {0, 1};\n    }\n\n    int64_t sum = 0;\n    int64_t product = 1;\n\n    size_t i = 0;\n    size_t n = numbers.size();\n\n    // Process 8 elements at a time using SIMD\n    for (; i <= n - 8; i += 8) {\n        int16x8_t vec = vld1q_s16(&numbers[i]);\n        int16x8_t ones = vdupq_n_s16(1);\n\n        // Sum\n        int32x4_t sum_low = vpaddlq_s16(vget_low_s16(vec));\n        int32x4_t sum_high = vpaddlq_s16(vget_high_s16(vec));\n        int64x2_t sum_res = vpaddlq_s32(vaddq_s32(sum_low, sum_high));\n        sum += vgetq_lane_s64(sum_res, 0) + vgetq_lane_s64(sum_res, 1);\n\n        // Product\n        int16x8_t prod_vec = vmulq_s16(vec, ones);\n        int32x4_t prod_low = vmovl_s16(vget_low_s16(prod_vec));\n        int32x4_t prod_high = vmovl_s16(vget_high_s16(prod_vec));\n        int64x2_t prod_res = vmull_s32(vget_low_s32(prod_low), vget_high_s32(prod_high));\n        product *= vgetq_lane_s64(prod_res, 0) * vgetq_lane_s64(prod_res, 1);\n    }\n\n    // Process remaining elements\n    for (; i < n; ++i) {\n        sum += numbers[i];\n        product *= numbers[i];\n    }\n\n    return {sum, product};\n}\n```"}
{"task_id": "SimdBench_66_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int64_t> sum_product_simd(std::vector<int16_t> numbers){\n    int n = numbers.size();\n    if (n == 0) return {0, 1};\n\n    int64_t sum = 0;\n    int64_t product = 1;\n\n    const int simd_width = 8; // Number of elements processed per SIMD operation\n    int i = 0;\n\n    // Process elements in batches of 8 using SIMD\n    for (; i <= n - simd_width; i += simd_width) {\n        int16x8_t vec = vld1q_s16(&numbers[i]);\n        int16x8_t zeros = vmovq_n_s16(0);\n\n        // Calculate sum\n        int32x4_t sum_low = vpaddlq_s16(vget_low_s16(vec));\n        int32x4_t sum_high = vpaddlq_s16(vget_high_s16(vec));\n        int32x2_t sum_combined = vpadd_s32(vget_low_s32(sum_low), vget_high_s32(sum_high));\n        sum += vget_lane_s32(sum_combined, 0) + vget_lane_s32(sum_combined, 1);\n\n        // Calculate product\n        int16x8_t ones = vmovq_n_s16(1);\n        int16x8_t prod_vec = vec;\n        for (int j = 0; j < simd_width - 1; ++j) {\n            prod_vec = vmulq_s16(prod_vec, vec);\n        }\n        int16x4_t prod_low = vget_low_s16(prod_vec);\n        product *= vget_lane_s16(prod_low, 0) * vget_lane_s16(prod_low, 1) *\n                  vget_lane_s16(prod_low, 2) * vget_lane_s16(prod_low, 3);\n    }\n\n    // Process remaining elements sequentially\n    for (; i < n; ++i) {\n        sum += numbers[i];\n        product *= numbers[i];\n    }\n\n    return {sum, product};\n}\n```"}
{"task_id": "SimdBench_66_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int64_t> sum_product_simd(std::vector<int16_t> numbers){\n    if (numbers.empty()) {\n        return {0, 1};\n    }\n\n    int64_t sum = 0;\n    int64_t product = 1;\n\n    const int16_t *data = numbers.data();\n    size_t length = numbers.size();\n\n    // Handle unaligned data by processing in chunks of 8\n    for (size_t i = 0; i + 7 < length; i += 8) {\n        int16x8_t vec = vld1q_s16(data + i);\n        \n        int32x4_t sum_low = vpaddlq_s16(vget_low_s16(vec));\n        int32x4_t sum_high = vpaddlq_s16(vget_high_s16(vec));\n        \n        int64x2_t sum_res = vaddl_s32(vadd_s32(vget_low_s32(sum_low), vget_high_s32(sum_low)),\n                                          vadd_s32(vget_low_s32(sum_high), vget_high_s32(sum_high)));\n        \n        sum += vaddvq_s64(sum_res);\n\n        int16x8_t abs_vec = vabsq_s16(vec);\n        int16x8_t prod_vec = vmovl_u8(vdup_n_u8(1));\n        prod_vec = vmulq_s16(prod_vec, abs_vec);\n\n        int32x4_t prod_low = vpaddlq_s16(vget_low_s16(prod_vec));\n        int32x4_t prod_high = vpaddlq_s16(vget_high_s16(prod_vec));\n\n        int64x2_t prod_res = vmull_s32(vget_low_s32(prod_low), vget_high_s32(prod_low));\n        prod_res = vmull_s32(vget_low_s32(prod_high), vget_high_s32(prod_high));\n\n        product *= vaddvq_s64(prod_res);\n    }\n\n    // Process remaining elements\n    for (size_t i = (length / 8) * 8; i < length; ++i) {\n        sum += data[i];\n        product *= data[i];\n    }\n\n    return {sum, product};\n}\n```"}
{"task_id": "SimdBench_66_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int64_t> sum_product_simd(std::vector<int16_t> numbers){\n    if (numbers.empty()) {\n        return {0, 1};\n    }\n\n    int64_t sum = 0;\n    int64_t product = 1;\n\n    const int16x8_t one_vec = vdupq_n_s16(1);\n    const int n = numbers.size();\n    const int vec_size = 8;\n\n    for (size_t i = 0; i <= n - vec_size; i += vec_size) {\n        int16x8_t vec = vld1q_s16(&numbers[i]);\n        int16x8_t ones = one_vec;\n\n        // Calculate sum\n        int32x4_t sum_low = vpaddlq_s16(vget_low_s16(vec));\n        int32x4_t sum_high = vpaddlq_s16(vget_high_s16(vec));\n        int64x2_t sum_res = vaddl_s32(vget_low_s32(sum_low), vget_low_s32(sum_high));\n        sum += vget_lane_s64(sum_res, 0) + vget_lane_s64(sum_res, 1);\n\n        // Calculate product\n        int16x8_t prod_mask = vceqq_s16(vec, ones);\n        uint16x8_t prod_sel = vbslq_u16(prod_mask, vdupq_n_u16(1), vdupq_n_u16(0));\n        int count_non_one = 8 - vaddvq_u8(vreinterpretq_u8_u16(prod_sel));\n        if (count_non_one > 0) {\n            int16x4_t prod_low = vmovn_s32(vpaddlq_s16(vec));\n            int16x4_t prod_high = vmovn_s32(vpaddlq_s16(vextq_s16(vec, vec, 4)));\n            int32x2_t prod_res = vmul_s32(vreinterpret_s32_s16(prod_low), vreinterpret_s32_s16(prod_high));\n            product *= vget_lane_s32(prod_res, 0) * vget_lane_s32(prod_res, 1);\n        }\n    }\n\n    // Tail processing\n    size_t i = (n / vec_size) * vec_size;\n    for (; i < n; ++i) {\n        sum += numbers[i];\n        product *= numbers[i];\n    }\n\n    return {sum, product};\n}\n```"}
{"task_id": "SimdBench_67_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<int> rolling_max_simd(std::vector<int> numbers){\n    std::vector<int> result(numbers.size(), 0);\n    if (numbers.empty()) return result;\n\n    const int vector_size = 4;\n    int32x4_t current_max = vdupq_n_s32(numbers[0]);\n    int32x4_t temp_max;\n\n    for (size_t i = 0; i + vector_size <= numbers.size(); i += vector_size) {\n        int32x4_t vec = vld1q_s32(&numbers[i]);\n        temp_max = vmaxq_s32(current_max, vec);\n        current_max = vmaxq_s32(current_max, temp_max);\n        vst1q_s32(&result[i], current_max);\n    }\n\n    // Handle remaining elements\n    int max_so_far = numbers[0];\n    for (size_t i = ((numbers.size() / vector_size) * vector_size); i < numbers.size(); ++i) {\n        max_so_far = std::max(max_so_far, numbers[i]);\n        result[i] = max_so_far;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_67_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<int> rolling_max_simd(std::vector<int> numbers){\n    std::vector<int> result(numbers.size(), 0);\n    if (numbers.empty()) return result;\n\n    const int vec_size = 4;\n    int32x4_t current_max = vmovq_n_s32(numbers[0]);\n    int32x4_t temp_max;\n\n    for (size_t i = 0; i + vec_size <= numbers.size(); i += vec_size) {\n        int32x4_t vec = vld1q_s32(&numbers[i]);\n        temp_max = vmaxq_s32(current_max, vec);\n        current_max = vmaxq_s32(current_max, temp_max);\n        vst1q_s32(&result[i], current_max);\n    }\n\n    // Handle remaining elements\n    int max_val = vmovn_s32(vget_low_s32(current_max));\n    max_val = std::max(max_val, vmovn_s32(vget_high_s32(current_max)));\n    \n    for (size_t i = ((numbers.size() / vec_size) * vec_size); i < numbers.size(); ++i) {\n        max_val = std::max(max_val, numbers[i]);\n        result[i] = max_val;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_67_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int> rolling_max_simd(std::vector<int> numbers){\n    std::vector<int> result(numbers.size(), 0);\n    if (numbers.empty()) return result;\n\n    int n = numbers.size();\n    int vmax = numbers[0];\n    result[0] = vmax;\n\n    uint32x4_t vcurrent, vresult, vmax_vec;\n\n    for(int i = 1; i < n; ++i){\n        vmax = (numbers[i] > vmax) ? numbers[i] : vmax;\n        result[i] = vmax;\n\n        // SIMD processing for vectors of size multiple of 4\n        if(i % 4 == 0 && i + 4 <= n){\n            vcurrent = vld1q_u32(&numbers[i]);\n            vmax_vec = vdupq_n_u32(vmax);\n            vresult = vmaxq_u32(vcurrent, vmax_vec);\n            vst1q_u32(&result[i], vresult);\n            i += 3; // Skip next 3 elements as they are already processed\n        }\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_67_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int> rolling_max_simd(std::vector<int> numbers){\n    std::vector<int> result(numbers.size(), 0);\n    if (numbers.empty()) return result;\n\n    int n = numbers.size();\n    int vmax = numbers[0];\n    result[0] = vmax;\n\n    uint32x4_t vcurrent, vmax_vec;\n    \n    for(int i = 1; i < n; ++i){\n        vmax = (numbers[i] > vmax) ? numbers[i] : vmax;\n        result[i] = vmax;\n\n        // SIMD processing in chunks of 4\n        if(i % 4 == 0 && i + 4 <= n){\n            vcurrent = vld1q_u32(&numbers[i]);\n            vmax_vec = vdupq_n_u32(vmax);\n            vmax_vec = vmaxq_u32(vmax_vec, vcurrent);\n            vmax = vmaxvq_u32(vmax_vec);\n            vst1q_u32(&result[i], vmax_vec);\n            i += 3;\n        }\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_67_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<int> rolling_max_simd(std::vector<int> numbers){\n    std::vector<int> result(numbers.size(), 0);\n    if (numbers.empty()) return result;\n\n    const int vec_size = 4;\n    int32x4_t current_max = vdupq_n_s32(numbers[0]);\n    int32x4_t temp_max;\n\n    for (size_t i = 0; i + vec_size <= numbers.size(); i += vec_size) {\n        int32x4_t vec = vld1q_s32(&numbers[i]);\n        temp_max = vmaxq_s32(current_max, vec);\n        current_max = vmaxq_s32(current_max, temp_max);\n        vst1q_s32(&result[i], current_max);\n    }\n\n    // Handle remaining elements\n    for (size_t i = (numbers.size() / vec_size) * vec_size; i < numbers.size(); ++i) {\n        if (numbers[i] > result[i - 1]) {\n            result[i] = numbers[i];\n        } else {\n            result[i] = result[i - 1];\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_68_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nstd::string string_xor_simd(std::string a, std::string b){\n    size_t len = a.size();\n    if (len != b.size()) {\n        return \"\";\n    }\n\n    std::string result;\n    result.reserve(len);\n\n    size_t i = 0;\n    for (; i + 15 < len; i += 16) {\n        uint8x16_t va = vld1q_u8(reinterpret_cast<const uint8_t*>(&a[i]));\n        uint8x16_t vb = vld1q_u8(reinterpret_cast<const uint8_t*>(&b[i]));\n        uint8x16_t veor = veorq_u8(va, vb);\n        uint8_t res[16];\n        vst1q_u8(res, veor);\n        result.append(reinterpret_cast<char*>(res), 16);\n    }\n\n    for (; i < len; ++i) {\n        result += (a[i] == '1') ^ (b[i] == '1') ? '1' : '0';\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_68_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nstd::string string_xor_simd(std::string a, std::string b){\n    size_t n = a.size();\n    if (n != b.size()) return \"\";\n    \n    std::string result(n, '0');\n    const uint8x16_t one = vdupq_n_u8('1');\n    const uint8x16_t zero = vdupq_n_u8('0');\n    \n    for (size_t i = 0; i < n; i += 16) {\n        size_t chunk = std::min<size_t>(16, n - i);\n        \n        uint8x16_t va = vld1q_u8(reinterpret_cast<const uint8_t*>(&a[i]));\n        uint8x16_t vb = vld1q_u8(reinterpret_cast<const uint8_t*>(&b[i]));\n        \n        uint8x16_t ca = vcgeq_u8(va, one);\n        uint8x16_t cb = vcgeq_u8(vb, one);\n        \n        uint8x16_t res_mask = veorq_u8(ca, cb);\n        uint8x16_t res = vbslq_u8(res_mask, one, zero);\n        \n        vst1q_u8(reinterpret_cast<uint8_t*>(&result[i]), res);\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_68_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nstd::string string_xor_simd(std::string a, std::string b){\n    size_t len = a.size();\n    if (len != b.size()) return \"\";\n\n    std::string result(len, '0');\n    const uint8x16_t mask = vdupq_n_u8(0x30); // ASCII '0' is 0x30\n\n    for (size_t i = 0; i < len; i += 16) {\n        size_t chunk = len - i;\n        if (chunk >= 16) {\n            uint8x16_t va = vld1q_u8(reinterpret_cast<const uint8_t*>(&a[i]));\n            uint8x16_t vb = vld1q_u8(reinterpret_cast<const uint8_t*>(&b[i]));\n\n            va = vsubq_u8(va, mask);\n            vb = vsubq_u8(vb, mask);\n\n            uint8x16_t vc = veorq_u8(va, vb);\n            vc = vaddq_u8(vc, mask);\n\n            vst1q_u8(reinterpret_cast<uint8_t*>(&result[i]), vc);\n        } else {\n            for (size_t j = 0; j < chunk; ++j) {\n                result[i + j] = '0' + ((a[i + j] - '0') ^ (b[i + j] - '0'));\n            }\n        }\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_68_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nstd::string string_xor_simd(std::string a, std::string b){\n    size_t len = a.size();\n    if (len != b.size()) return \"\";\n    \n    std::string result;\n    result.reserve(len);\n    \n    const uint8x16_t zero = vdupq_n_u8('0');\n    const uint8x16_t one = vdupq_n_u8('1');\n    \n    for (size_t i = 0; i < len; i += 16) {\n        size_t chunk = len - i > 16 ? 16 : len - i;\n        \n        uint8x16_t va = vld1q_u8(reinterpret_cast<const uint8_t*>(&a[i]));\n        uint8x16_t vb = vld1q_u8(reinterpret_cast<const uint8_t*>(&b[i]));\n        \n        uint8x16_t mask_a = vcgeq_u8(va, one);\n        uint8x16_t mask_b = vcgeq_u8(vb, one);\n        \n        uint8x16_t xor_mask = veorq_u8(mask_a, mask_b);\n        \n        uint8x16_t res = vbslq_u8(xor_mask, one, zero);\n        \n        uint8_t r[16];\n        vst1q_u8(r, res);\n        \n        result.append(reinterpret_cast<char*>(r), chunk);\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_68_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nstd::string string_xor_simd(std::string a, std::string b){\n    size_t len = a.size();\n    if (len != b.size()) return \"\";\n    \n    std::string result(len, '\\0');\n    const uint8x16_t zero = vdupq_n_u8(0);\n    for (size_t i = 0; i < len; i += 16) {\n        size_t chunk = std::min<size_t>(len - i, 16);\n        uint8x16_t va = vld1q_u8(reinterpret_cast<const uint8_t*>(&a[i]));\n        uint8x16_t vb = vld1q_u8(reinterpret_cast<const uint8_t*>(&b[i]));\n        uint8x16_t vr = veorq_u8(va, vb);\n        vst1q_u8(reinterpret_cast<uint8_t*>(&result[i]), vr);\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_69_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n#include <vector>\n#include <cstring>\n\nstd::string longest_simd(const std::vector<std::string> & strings){\n    if (strings.empty()) return \"\";\n\n    size_t max_length = 0;\n    size_t max_index = 0;\n\n    const size_t vector_size = strings.size();\n    size_t i = 0;\n\n    // Process in chunks of 4 for SIMD\n    for (; i <= vector_size - 4; i += 4) {\n        uint32x4_t lengths = vdupq_n_u32(0);\n\n        lengths = vsetq_lane_u32(strings[i].length(), lengths, 0);\n        lengths = vsetq_lane_u32(strings[i+1].length(), lengths, 1);\n        lengths = vsetq_lane_u32(strings[i+2].length(), lengths, 2);\n        lengths = vsetq_lane_u32(strings[i+3].length(), lengths, 3);\n\n        uint32x4_t max_lengths = vmaxvq_u32(lengths);\n        int max_pos = 0;\n\n        if (vgetq_lane_u32(lengths, 0) == max_lengths && vgetq_lane_u32(lengths, 0) > max_length) {\n            max_length = strings[i].length();\n            max_index = i;\n        }\n        if (vgetq_lane_u32(lengths, 1) == max_lengths && vgetq_lane_u32(lengths, 1) > max_length) {\n            max_length = strings[i+1].length();\n            max_index = i+1;\n        }\n        if (vgetq_lane_u32(lengths, 2) == max_lengths && vgetq_lane_u32(lengths, 2) > max_length) {\n            max_length = strings[i+2].length();\n            max_index = i+2;\n        }\n        if (vgetq_lane_u32(lengths, 3) == max_lengths && vgetq_lane_u32(lengths, 3) > max_length) {\n            max_length = strings[i+3].length();\n            max_index = i+3;\n        }\n    }\n\n    // Handle remaining elements\n    for (; i < vector_size; ++i) {\n        if (strings[i].length() > max_length) {\n            max_length = strings[i].length();\n            max_index = i;\n        }\n    }\n\n    return strings[max_index];\n}\n```"}
{"task_id": "SimdBench_69_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n#include <vector>\n#include <cstring>\n\nstd::string longest_simd(const std::vector<std::string> & strings){\n    if (strings.empty()) {\n        return \"\";\n    }\n\n    size_t max_length = 0;\n    size_t max_index = 0;\n    size_t num_strings = strings.size();\n\n    // Process strings in batches of 4 using SIMD\n    for (size_t i = 0; i + 4 <= num_strings; i += 4) {\n        uint32x4_t lengths = vdupq_n_u32(0);\n        for (size_t j = 0; j < 4; ++j) {\n            lengths = vsetq_lane_u32(strings[i + j].length(), lengths, j);\n        }\n        uint32x4_t cmp = vcgeq_u32(lengths, vdupq_n_u32(max_length));\n        int mask = vget_lane_u32(vreinterpretq_u32_u8(cmp), 0) |\n                  vget_lane_u32(vreinterpretq_u32_u8(cmp), 1) << 1 |\n                  vget_lane_u32(vreinterpretq_u32_u8(cmp), 2) << 2 |\n                  vget_lane_u32(vreinterpretq_u32_u8(cmp), 3) << 3;\n\n        if (mask != 0) {\n            size_t idx = __builtin_ctz(mask);\n            if (strings[i + idx].length() > max_length) {\n                max_length = strings[i + idx].length();\n                max_index = i + idx;\n            }\n        }\n    }\n\n    // Process remaining strings\n    for (size_t i = (num_strings / 4) * 4; i < num_strings; ++i) {\n        if (strings[i].length() > max_length) {\n            max_length = strings[i].length();\n            max_index = i;\n        }\n    }\n\n    return strings[max_index];\n}\n```"}
{"task_id": "SimdBench_69_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n#include <vector>\n#include <climits>\n\nstd::string longest_simd(const std::vector<std::string> & strings){\n    if (strings.empty()) return \"\";\n\n    size_t max_length = 0;\n    size_t max_index = 0;\n    size_t vec_size = strings.size();\n\n    // Process in chunks of 4\n    for(size_t i = 0; i + 4 <= vec_size; i += 4){\n        uint32x4_t lengths = vdupq_n_u32(0);\n        lengths = vset_lane_u32(strings[i].length(), lengths, 0);\n        lengths = vset_lane_u32(strings[i+1].length(), lengths, 1);\n        lengths = vset_lane_u32(strings[i+2].length(), lengths, 2);\n        lengths = vset_lane_u32(strings[i+3].length(), lengths, 3);\n\n        uint32x4_t max_lengths = vpmax_u32(vget_low_u32(lengths), vget_high_u32(lengths));\n        uint32x2_t final_max = vpmax_u32(max_lengths, max_lengths);\n\n        uint32_t current_max = vget_lane_u32(final_max, 0);\n        if(current_max > max_length){\n            max_length = current_max;\n            if(strings[i].length() == current_max) max_index = i;\n            else if(strings[i+1].length() == current_max) max_index = i+1;\n            else if(strings[i+2].length() == current_max) max_index = i+2;\n            else if(strings[i+3].length() == current_max) max_index = i+3;\n        }\n    }\n\n    // Handle remaining elements\n    for(size_t i = ((vec_size / 4) * 4); i < vec_size; ++i){\n        if(strings[i].length() > max_length){\n            max_length = strings[i].length();\n            max_index = i;\n        }\n    }\n\n    return strings[max_index];\n}\n```"}
{"task_id": "SimdBench_69_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n#include <vector>\n#include <cstring>\n\nstd::string longest_simd(const std::vector<std::string> & strings){\n    if (strings.empty()) {\n        return \"\";\n    }\n\n    size_t max_length = 0;\n    size_t max_index = 0;\n    size_t vec_size = strings.size();\n\n    // Process strings in batches of 4 using SIMD\n    for (size_t i = 0; i + 4 <= vec_size; i += 4) {\n        uint32x4_t lengths = vdupq_n_u32(0);\n        lengths = vsetq_lane_u32(strings[i].size(), lengths, 0);\n        lengths = vsetq_lane_u32(strings[i+1].size(), lengths, 1);\n        lengths = vsetq_lane_u32(strings[i+2].size(), lengths, 2);\n        lengths = vsetq_lane_u32(strings[i+3].size(), lengths, 3);\n\n        uint32x4_t max_lengths = vpmax_u32(vget_low_u32(lengths), vget_high_u32(lengths));\n        uint32x2_t final_max = vpmax_u32(max_lengths, max_lengths);\n\n        uint32_t current_max = vget_lane_u32(final_max, 0);\n        if (current_max > max_length) {\n            max_length = current_max;\n            if (strings[i].size() == current_max) {\n                max_index = i;\n            }\n            else if (strings[i+1].size() == current_max) {\n                max_index = i + 1;\n            }\n            else if (strings[i+2].size() == current_max) {\n                max_index = i + 2;\n            }\n            else if (strings[i+3].size() == current_max) {\n                max_index = i + 3;\n            }\n        }\n    }\n\n    // Handle remaining strings\n    for (size_t i = (vec_size / 4) * 4; i < vec_size; ++i) {\n        if (strings[i].size() > max_length) {\n            max_length = strings[i].size();\n            max_index = i;\n        }\n    }\n\n    return strings[max_index];\n}\n```"}
{"task_id": "SimdBench_69_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n#include <vector>\n#include <cstring>\n\nstd::string longest_simd(const std::vector<std::string> & strings){\n    if (strings.empty()) {\n        return \"\";\n    }\n\n    size_t max_length = 0;\n    size_t max_index = 0;\n    size_t vector_size = strings.size();\n\n    // Process strings in batches of 4 using SIMD\n    for (size_t i = 0; i + 4 <= vector_size; i += 4) {\n        uint32x4_t lengths = vdupq_n_u32(0);\n\n        for (size_t j = 0; j < 4; ++j) {\n            lengths = vsetq_lane_u32(strings[i + j].length(), lengths, j);\n        }\n\n        uint32x4_t cmp = vcgeq_u32(lengths, vdupq_n_u32(max_length));\n        int32x4_t masks = vreinterpretq_s32_u32(cmp);\n        int mask = vget_lane_s32(vmovn_s32(vmovn_s32(masks)), 0);\n\n        if (mask != 0) {\n            size_t new_max_index = i + __builtin_ctz(mask);\n            max_length = strings[new_max_index].length();\n            max_index = new_max_index;\n        }\n    }\n\n    // Process remaining strings\n    for (size_t i = ((vector_size / 4) * 4); i < vector_size; ++i) {\n        if (strings[i].length() > max_length) {\n            max_length = strings[i].length();\n            max_index = i;\n        }\n    }\n\n    return strings[max_index];\n}\n```"}
{"task_id": "SimdBench_70_Neon", "completion": "```c\n#include <arm_neon.h>\n\nuint64_t greatest_common_divisor_simd(uint64_t a, uint64_t b){\n    uint64x1_t va = vdup_n_u64(a);\n    uint64x1_t vb = vdup_n_u64(b);\n    while (vget_lane_u64(vb, 0) != 0) {\n        uint64x1_t vr = vmovl_u32(vreinterpret_u32_u64(va) % vreinterpret_u32_u64(vb));\n        va = vb;\n        vb = vr;\n    }\n    return vget_lane_u64(va, 0);\n}\n```"}
{"task_id": "SimdBench_70_Neon", "completion": "```c\n#include <arm_neon.h>\n\nuint64_t greatest_common_divisor_simd(uint64_t a, uint64_t b){\n    uint64x1_t ra = vdup_n_u64(a);\n    uint64x1_t rb = vdup_n_u64(b);\n    while (vget_lane_u64(rb, 0) != 0) {\n        uint64x1_t r = vdup_n_u64(vget_lane_u64(ra, 0) % vget_lane_u64(rb, 0));\n        ra = rb;\n        rb = r;\n    }\n    return vget_lane_u64(ra, 0);\n}\n```"}
{"task_id": "SimdBench_70_Neon", "completion": "```c\n#include <arm_neon.h>\n\nuint64_t greatest_common_divisor_simd(uint64_t a, uint64_t b){\n    uint64x1_t va = vdup_n_u64(a);\n    uint64x1_t vb = vdup_n_u64(b);\n    while (vb[0] != 0) {\n        uint64x1_t vt = vb;\n        vb = vdup_n_u64(va[0] % vb[0]);\n        va = vt;\n    }\n    return va[0];\n}\n```"}
{"task_id": "SimdBench_70_Neon", "completion": "```c\n#include <arm_neon.h>\n\nuint64_t greatest_common_divisor_simd(uint64_t a, uint64_t b){\n    uint64x1_t va = vdup_n_u64(a);\n    uint64x1_t vb = vdup_n_u64(b);\n    while (true) {\n        uint64x1_t vt = vmin_u64(va, vb);\n        vb = vmax_u64(va, vb);\n        va = vt;\n        if (vget_lane_u64(va, 0) == 0) {\n            break;\n        }\n        vb = vsub_u64(vb, va);\n    }\n    return vget_lane_u64(vb, 0);\n}\n```"}
{"task_id": "SimdBench_70_Neon", "completion": "```c\n#include <arm_neon.h>\n\nuint64_t greatest_common_divisor_simd(uint64_t a, uint64_t b){\n    uint64x1_t ra = vdup_n_u64(a);\n    uint64x1_t rb = vdup_n_u64(b);\n    uint64x1_t zero = vdup_n_u64(0);\n\n    while (vget_lane_u64(rb, 0) != 0) {\n        uint64x1_t temp = vbic_u64(ra, rb); // ra & ~rb\n        ra = rb;\n        rb = vsub_u64(temp, vbic_u64(zero, rb)); // abs(temp - rb)\n    }\n    return vget_lane_u64(ra, 0);\n}\n```"}
{"task_id": "SimdBench_71_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <float.h>\n\nstd::vector<float> find_closest_elements_simd(std::vector<float> numbers){\n    if (numbers.size() < 2) return {};\n\n    size_t n = numbers.size();\n    float32x4_t min_diff = vdupq_n_f32(DBL_MAX);\n    float32x4_t closest_pair_1 = vdupq_n_f32(0.0f);\n    float32x4_t closest_pair_2 = vdupq_n_f32(0.0f);\n\n    for(size_t i = 0; i <= n - 5; i += 4){\n        float32x4_t a = vld1q_f32(&numbers[i]);\n        for(size_t j = i + 1; j <= n - 4; j += 4){\n            float32x4_t b = vld1q_f32(&numbers[j]);\n            float32x4_t diff = vabdq_f32(a, b);\n            uint32x4_t mask = vcgtq_f32(min_diff, diff);\n            min_diff = vminq_f32(min_diff, diff);\n            closest_pair_1 = vbslq_f32(mask, a, closest_pair_1);\n            closest_pair_2 = vbslq_f32(mask, b, closest_pair_2);\n        }\n    }\n\n    // Handle remaining elements\n    for(size_t i = n - n % 4; i < n - 1; ++i){\n        float current_min_diff = DBL_MAX;\n        float closest_a = 0.0f, closest_b = 0.0f;\n        for(size_t j = i + 1; j < n; ++j){\n            float diff = std::fabs(numbers[i] - numbers[j]);\n            if(diff < current_min_diff){\n                current_min_diff = diff;\n                closest_a = (numbers[i] < numbers[j]) ? numbers[i] : numbers[j];\n                closest_b = (numbers[i] < numbers[j]) ? numbers[j] : numbers[i];\n            }\n        }\n    }\n\n    float32x4_t res1 = vpmin_f32(vget_low_f32(closest_pair_1), vget_high_f32(closest_pair_1));\n    float32x4_t res2 = vpmin_f32(vget_low_f32(closest_pair_2), vget_high_f32(closest_pair_2));\n\n    float val1 = std::min(vget_lane_f32(res1, 0), vget_lane_f32(res1, 1));\n    float val2 = std::min(vget_lane_f32(res2, 0), vget_lane_f32(res2, 1));\n\n    return {std::min(val1, val2), std::max(val1, val2)};\n}\n```"}
{"task_id": "SimdBench_71_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <algorithm>\n#include <float.h>\n\nstd::vector<float> find_closest_elements_simd(std::vector<float> numbers){\n    if (numbers.size() < 2) return {};\n\n    size_t n = numbers.size();\n    float32x4_t min_diff = vdupq_n_f32FLT_MAX;\n    float32x4_t closest_pair_1 = vdupq_n_f32(0);\n    float32x4_t closest_pair_2 = vdupq_n_f32(0);\n\n    for (size_t i = 0; i <= n - 5; i += 4) {\n        float32x4_t a = vld1q_f32(&numbers[i]);\n        for (size_t j = i + 1; j <= n - 4; j += 4) {\n            float32x4_t b = vld1q_f32(&numbers[j]);\n            float32x4_t diff = vabdq_f32(a, b);\n            uint32x4_t mask = vcgtq_f32(min_diff, diff);\n            min_diff = vminq_f32(min_diff, diff);\n\n            float32x4_t sel_a = vbslq_f32(mask, a, closest_pair_1);\n            float32x4_t sel_b = vbslq_f32(mask, b, closest_pair_2);\n\n            closest_pair_1 = sel_a;\n            closest_pair_2 = sel_b;\n        }\n    }\n\n    // Handle remaining elements\n    for (size_t i = n - n % 4; i < n - 1; ++i) {\n        float current_min = FLT_MAX;\n        float c1 = 0, c2 = 0;\n        for (size_t j = i + 1; j < n; ++j) {\n            float diff = std::abs(numbers[i] - numbers[j]);\n            if (diff < current_min) {\n                current_min = diff;\n                c1 = (numbers[i] < numbers[j]) ? numbers[i] : numbers[j];\n                c2 = (numbers[i] < numbers[j]) ? numbers[j] : numbers[i];\n            }\n        }\n        if (current_min < FLT_MAX) {\n            closest_pair_1 = vsetq_lane_f32(c1, closest_pair_1, 0);\n            closest_pair_2 = vsetq_lane_f32(c2, closest_pair_2, 0);\n        }\n    }\n\n    float32x4_t min_vals = vmovq_n_f32(FLT_MAX);\n    min_vals = vminq_f32(min_vals, vabdq_f32(closest_pair_1, closest_pair_2));\n\n    uint32x4_t m = vceqq_f32(vminq_f32(min_diff, min_vals), min_vals);\n    float32x4_t result1 = vbslq_f32(m, closest_pair_1, vdupq_n_f32(0));\n    float32x4_t result2 = vbslq_f32(m, closest_pair_2, vdupq_n_f32(0));\n\n    float res1 = result1[0];\n    float res2 = result2[0];\n\n    if (res1 > res2) std::swap(res1, res2);\n\n    return {res1, res2};\n}\n```"}
{"task_id": "SimdBench_71_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <float.h>\n\nstd::vector<float> find_closest_elements_simd(std::vector<float> numbers){\n    if (numbers.size() < 2) return {};\n\n    float min_diff = FLT_MAX;\n    float closest_a = 0.0f, closest_b = 0.0f;\n\n    size_t n = numbers.size();\n    float *data = numbers.data();\n\n    for (size_t i = 0; i <= n - 8; i += 4) {\n        float32x4_t v_i = vld1q_f32(data + i);\n        \n        for (size_t j = i + 4; j <= n - 4; j += 4) {\n            float32x4_t v_j = vld1q_f32(data + j);\n\n            // Compute differences\n            float32x4_t diff = vabdq_f32(v_i, v_j);\n\n            // Find minimum difference in the vector\n            float32x2_t diff_min = vpmin_f32(vget_low_f32(diff), vget_high_f32(diff));\n            float32x2_t diff_min_final = vpmin_f32(diff_min, diff_min);\n\n            float current_min_diff = vget_lane_f32(diff_min_final, 0);\n\n            if (current_min_diff < min_diff) {\n                min_diff = current_min_diff;\n\n                // Find which pair caused the min_diff\n                for (int k = 0; k < 4; ++k) {\n                    for (int l = 0; l < 4; ++l) {\n                        if (fabsf(data[i + k] - data[j + l]) == min_diff) {\n                            closest_a = std::min(data[i + k], data[j + l]);\n                            closest_b = std::max(data[i + k], data[j + l]);\n                        }\n                    }\n                }\n            }\n        }\n    }\n\n    // Handle remaining elements with scalar code\n    for (size_t i = 0; i < n - 1; ++i) {\n        for (size_t j = i + 1; j < n; ++j) {\n            float diff = fabsf(data[i] - data[j]);\n            if (diff < min_diff) {\n                min_diff = diff;\n                closest_a = std::min(data[i], data[j]);\n                closest_b = std::max(data[i], data[j]);\n            }\n        }\n    }\n\n    return {closest_a, closest_b};\n}\n```"}
{"task_id": "SimdBench_71_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <float.h>\n#include <algorithm>\n\nstd::vector<float> find_closest_elements_simd(std::vector<float> numbers){\n    if (numbers.size() < 2) return {};\n\n    size_t n = numbers.size();\n    float min_diff = FLT_MAX;\n    float closest_a = 0.0f, closest_b = 0.0f;\n\n    // Load the first four elements into a SIMD register\n    float32x4_t vec_prev = vld1q_f32(numbers.data());\n\n    for(size_t i = 4; i < n; i += 4){\n        float32x4_t vec_curr = vld1q_f32(numbers.data() + i);\n\n        // Compute absolute differences\n        float32x4_t diff1 = vabdq_f32(vec_curr, vec_prev);\n\n        // Find the minimum difference in the SIMD register\n        float32x2_t diff_min = vpmin_f32(vget_low_f32(diff1), vget_high_f32(diff1));\n        float32x2_t diff_min_final = vpmin_f32(diff_min, diff_min);\n\n        float current_min_diff = vget_lane_f32(diff_min_final, 0);\n        if(current_min_diff < min_diff){\n            min_diff = current_min_diff;\n\n            // Determine which pair caused the minimum difference\n            for(int j = 0; j < 4; ++j){\n                if(std::abs(numbers[i - 4 + j] - numbers[i + j]) == min_diff){\n                    closest_a = std::min(numbers[i - 4 + j], numbers[i + j]);\n                    closest_b = std::max(numbers[i - 4 + j], numbers[i + j]);\n                    break;\n                }\n            }\n        }\n\n        vec_prev = vec_curr;\n    }\n\n    // Handle remaining elements\n    for(size_t i = (n / 4) * 4; i < n - 1; ++i){\n        float diff = std::abs(numbers[i] - numbers[i + 1]);\n        if(diff < min_diff){\n            min_diff = diff;\n            closest_a = std::min(numbers[i], numbers[i + 1]);\n            closest_b = std::max(numbers[i], numbers[i + 1]);\n        }\n    }\n\n    return {closest_a, closest_b};\n}\n```"}
{"task_id": "SimdBench_71_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <float.h>\n#include <algorithm>\n\nstd::vector<float> find_closest_elements_simd(std::vector<float> numbers){\n    if (numbers.size() < 2) return {};\n\n    size_t n = numbers.size();\n    float min_diff = FLT_MAX;\n    float closest_a = 0.0f, closest_b = 0.0f;\n\n    // Load the first four elements into a SIMD register\n    float32x4_t vec_min_diff = vdupq_n_f32(FLT_MAX);\n    float32x4_t vec_closest_a = vdupq_n_f32(0.0f);\n    float32x4_t vec_closest_b = vdupq_n_f32(0.0f);\n\n    for (size_t i = 0; i <= n - 5; i += 4) {\n        float32x4_t vec_a = vld1q_f32(&numbers[i]);\n        \n        for (size_t j = i + 4; j < n; ++j) {\n            float32x4_t vec_b = vdupq_n_f32(numbers[j]);\n            float32x4_t diff = vabdq_f32(vec_a, vec_b);\n\n            uint32x4_t mask = vcgtq_f32(vec_min_diff, diff);\n            vec_min_diff = vminq_f32(vec_min_diff, diff);\n\n            float32x4_t new_closest_a = vbicq_f32(vec_closest_a, vmovq_n_u32(vget_lane_u32(vreinterpretq_u32_f32(mask), 0)));\n            float32x4_t new_closest_b = vbicq_f32(vec_closest_b, vmovq_n_u32(vget_lane_u32(vreinterpretq_u32_f32(mask), 0)));\n\n            vec_closest_a = vbslq_f32(mask, vec_a, vec_closest_a);\n            vec_closest_b = vbslq_f32(mask, vec_b, vec_closest_b);\n        }\n    }\n\n    // Reduce to find the minimum difference and corresponding elements\n    float32x2_t min_diff_lo = vpmin_f32(vget_low_f32(vec_min_diff), vget_high_f32(vec_min_diff));\n    float32x2_t min_diff_final = vpmin_f32(min_diff_lo, min_diff_lo);\n\n    float32x2_t closest_a_lo = vpmin_f32(vget_low_f32(vec_closest_a), vget_high_f32(vec_closest_a));\n    float32x2_t closest_a_final = vpmin_f32(closest_a_lo, closest_a_lo);\n\n    float32x2_t closest_b_lo = vpmin_f32(vget_low_f32(vec_closest_b), vget_high_f32(vec_closest_b));\n    float32x2_t closest_b_final = vpmin_f32(closest_b_lo, closest_b_lo);\n\n    float scalar_min_diff = vget_lane_f32(min_diff_final, 0);\n    float scalar_closest_a = vget_lane_f32(closest_a_final, 0);\n    float scalar_closest_b = vget_lane_f32(closest_b_final, 0);\n\n    if (scalar_closest_a > scalar_closest_b) {\n        std::swap(scalar_closest_a, scalar_closest_b);\n    }\n\n    return {scalar_closest_a, scalar_closest_b};\n}\n```"}
{"task_id": "SimdBench_72_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<float> rescale_to_unit_simd(std::vector<float> numbers){\n    size_t n = numbers.size();\n    if (n < 2) return numbers;\n\n    float* data = numbers.data();\n    float32x4_t vmin = vld1q_f32(data);\n    float32x4_t vmax = vmin;\n\n    for(size_t i = 0; i < n; i += 4){\n        float32x4_t vec = vld1q_f32(data + i);\n        vmin = vminq_f32(vmin, vec);\n        vmax = vmaxq_f32(vmax, vec);\n    }\n\n    float min_val = vminval_f32(vmin);\n    float max_val = vmaxval_f32(vmax);\n\n    float diff = max_val - min_val;\n    if(diff == 0) return numbers;\n\n    float32x4_t vdiff = vdupq_n_f32(diff);\n    float32x4_t vmin_vec = vdupq_n_f32(min_val);\n\n    for(size_t i = 0; i < n; i += 4){\n        float32x4_t vec = vld1q_f32(data + i);\n        float32x4_t sub = vsubq_f32(vec, vmin_vec);\n        float32x4_t rescaled = vdivq_f32(sub, vdiff);\n        vst1q_f32(data + i, rescaled);\n    }\n\n    return numbers;\n}\n```"}
{"task_id": "SimdBench_72_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <algorithm>\n#include <cstring>\n\nstd::vector<float> rescale_to_unit_simd(std::vector<float> numbers){\n    if (numbers.size() < 2) return numbers;\n\n    float min_val = *std::min_element(numbers.begin(), numbers.end());\n    float max_val = *std::max_element(numbers.begin(), numbers.end());\n\n    if (min_val == max_val) {\n        std::vector<float> result(numbers.size(), 0.0f);\n        return result;\n    }\n\n    float32x4_t v_min = vdupq_n_f32(min_val);\n    float32x4_t v_max = vdupq_n_f32(max_val);\n    float32x4_t v_range = vsubq_f32(v_max, v_min);\n\n    size_t vec_size = numbers.size();\n    std::vector<float> result(vec_size);\n\n    for (size_t i = 0; i < vec_size; i += 4) {\n        size_t chunk = std::min(vec_size - i, (size_t)4);\n        float32x4_t v_nums = vld1q_f32(&numbers[i]);\n        float32x4_t v_sub = vsubq_f32(v_nums, v_min);\n        float32x4_t v_rescaled = vdivq_f32(v_sub, v_range);\n\n        if (chunk == 4) {\n            vst1q_f32(&result[i], v_rescaled);\n        } else {\n            float tmp[4];\n            vst1q_f32(tmp, v_rescaled);\n            for (size_t j = 0; j < chunk; ++j) {\n                result[i + j] = tmp[j];\n            }\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_72_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<float> rescale_to_unit_simd(std::vector<float> numbers){\n    size_t n = numbers.size();\n    if (n < 2) return numbers;\n\n    float* data = numbers.data();\n    float32x4_t vmin = vld1q_f32(data);\n    float32x4_t vmax = vmin;\n\n    // Find min and max\n    for(size_t i = 4; i < n; i += 4){\n        float32x4_t vec = vld1q_f32(data + i);\n        vmin = vminq_f32(vmin, vec);\n        vmax = vmaxq_f32(vmax, vec);\n    }\n\n    float min_val = vminv_f32(vmin);\n    float max_val = vmaxv_f32(vmax);\n\n    float diff = max_val - min_val;\n    if(diff == 0) return numbers;\n\n    float recip_diff = 1.0f / diff;\n\n    // Rescale\n    for(size_t i = 0; i < n; i += 4){\n        float32x4_t vec = vld1q_f32(data + i);\n        float32x4_t rescaled = vmulq_f32(vsubq_f32(vec, vdupq_n_f32(min_val)), vdupq_n_f32(recip_diff));\n        vst1q_f32(data + i, rescaled);\n    }\n\n    return numbers;\n}\n```"}
{"task_id": "SimdBench_72_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<float> rescale_to_unit_simd(std::vector<float> numbers){\n    if (numbers.size() < 2) return numbers;\n\n    float vmin = *std::min_element(numbers.begin(), numbers.end());\n    float vmax = *std::max_element(numbers.begin(), numbers.end());\n\n    if (vmin == vmax) {\n        // Avoid division by zero if all elements are the same\n        return std::vector<float>(numbers.size(), 0.0f);\n    }\n\n    float scale = 1.0f / (vmax - vmin);\n    size_t size = numbers.size();\n    std::vector<float> result(size);\n\n    float32x4_t v_min = vdupq_n_f32(vmin);\n    float32x4_t v_scale = vdupq_n_f32(scale);\n\n    for (size_t i = 0; i < size / 4 * 4; i += 4) {\n        float32x4_t v_nums = vld1q_f32(&numbers[i]);\n        float32x4_t v_sub = vsubq_f32(v_nums, v_min);\n        float32x4_t v_res = vmulq_f32(v_sub, v_scale);\n        vst1q_f32(&result[i], v_res);\n    }\n\n    // Handle remaining elements\n    for (size_t i = size / 4 * 4; i < size; ++i) {\n        result[i] = (numbers[i] - vmin) * scale;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_72_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<float> rescale_to_unit_simd(std::vector<float> numbers){\n    size_t n = numbers.size();\n    if (n < 2) return numbers;\n\n    float* data = numbers.data();\n    float32x4_t vmin = vld1q_f32(data);\n    float32x4_t vmax = vmin;\n\n    // Find min and max\n    for(size_t i = 4; i < n; i += 4){\n        float32x4_t vec = vld1q_f32(data + i);\n        vmin = vminq_f32(vmin, vec);\n        vmax = vmaxq_f32(vmax, vec);\n    }\n\n    float min_val = vminval_f32_v(vmin);\n    float max_val = vmaxval_f32_v(vmax);\n\n    float diff = max_val - min_val;\n    if(diff == 0) return numbers; // Avoid division by zero\n\n    // Normalize\n    for(size_t i = 0; i < n; i += 4){\n        float32x4_t vec = vld1q_f32(data + i);\n        float32x4_t normalized = vdivq_f32(vsubq_f32(vec, vdupq_n_f32(min_val)), vdupq_n_f32(diff));\n        vst1q_f32(data + i, normalized);\n    }\n\n    return numbers;\n}\n```"}
{"task_id": "SimdBench_73_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nuint64_t largest_divisor_simd(uint64_t n){\n    uint64x1_t vn = vdup_n_u64(n);\n    uint64x1_t result = vmov_n_u64(0);\n\n    for (uint64_t i = n / 2; i > 0; --i) {\n        uint64x1_t vi = vdup_n_u64(i);\n        uint64x1_t remainder = vmod_u64(vn, vi); // Assume vmod_u64 is a placeholder for modulo operation\n        if (vget_lane_u64(remainder, 0) == 0) {\n            result = vi;\n            break;\n        }\n    }\n    return vget_lane_u64(result, 0);\n}\n```"}
{"task_id": "SimdBench_73_Neon", "completion": "```c\n#include <arm_neon.h>\n\nuint64_t largest_divisor_simd(uint64_t n){\n    uint64x1_t result = vdup_n_u64(0);\n    uint64x1_t vn = vdup_n_u64(n);\n\n    for (uint64_t i = n / 2; i > 0; --i) {\n        uint64x1_t vi = vdup_n_u64(i);\n        uint64x1_t remainder = vmovm_u64(vand_u64(vn, vi));\n        if (vget_lane_u64(remainder, 0) == 0) {\n            result = vi;\n            break;\n        }\n    }\n\n    return vget_lane_u64(result, 0);\n}\n```"}
{"task_id": "SimdBench_73_Neon", "completion": "```c\n#include <arm_neon.h>\n\nuint64_t largest_divisor_simd(uint64_t n){\n    uint64x1_t result = vdup_n_u64(0);\n    if (n <= 1) return 0;\n\n    uint64x1_t vn = vdup_n_u64(n);\n    uint64x1_t one = vdup_n_u64(1);\n    uint64x1_t two = vdup_n_u64(2);\n\n    uint64x1_t half = vshl_u64(vn, vmov_n_s64(-1));\n    uint64x1_t candidate = half;\n\n    for (uint64_t i = vget_lane_u64(half, 0); i > 1; i--) {\n        uint64x1_t vi = vdup_n_u64(i);\n        uint64x1_t remainder = vsub_u64(vn, vmul_u64(vn, vrecpe_u64(vn, vi)));\n        if (vget_lane_u64(remainder, 0) == 0) {\n            result = vi;\n            break;\n        }\n    }\n\n    return vget_lane_u64(result, 0);\n}\n```"}
{"task_id": "SimdBench_73_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nuint64_t largest_divisor_simd(uint64_t n){\n    uint64x1_t vec_n = vdup_n_u64(n);\n    uint64x1_t result = vmov_n_u64(0);\n\n    for (uint64_t i = n / 2; i > 0; --i) {\n        uint64x1_t vec_i = vdup_n_u64(i);\n        uint64x1_t remainder = vmov_n_u64(n % i);\n        uint64x1_t cmp = vceq_u64(remainder, vmov_n_u64(0));\n        result = vbsl_u64(cmp, vec_i, result);\n        if (vget_lane_u64(cmp, 0)) {\n            break;\n        }\n    }\n    return vget_lane_u64(result, 0);\n}\n```"}
{"task_id": "SimdBench_73_Neon", "completion": "```c\n#include <arm_neon.h>\n\nuint64_t largest_divisor_simd(uint64_t n){\n    uint64x1_t result = vdup_n_u64(0);\n    uint64x1_t nn = vdup_n_u64(n);\n    uint64x1_t one = vdup_n_u64(1);\n    uint64x1_t temp;\n\n    for (uint64_t i = n / 2; i > 0; i--) {\n        temp = vdup_n_u64(i);\n        uint64x1_t remainder = vmul_u64(nn, vrecpe_u64(temp));\n        remainder = vsub_u64(nn, remainder);\n        if (vget_lane_u64(remainder, 0) == 0) {\n            result = temp;\n            break;\n        }\n    }\n    return vget_lane_u64(result, 0);\n}\n```"}
{"task_id": "SimdBench_74_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int> factorize_simd(int n) {\n    std::vector<int> factors;\n    if (n < 2) return factors;\n\n    int16x4_t vtwo = vdup_n_s16(2);\n    int16x4_t vthree = vdup_n_s16(3);\n    int16x4_t vfive = vdup_n_s16(5);\n    int16x4_t vseven = vdup_n_s16(7);\n\n    int16x4_t vn = vdup_n_s16(n);\n\n    // Check divisibility by 2\n    while ((n % 2) == 0) {\n        factors.push_back(2);\n        n /= 2;\n    }\n\n    // Check divisibility by 3\n    while ((n % 3) == 0) {\n        factors.push_back(3);\n        n /= 3;\n    }\n\n    // Check divisibility by 5\n    while ((n % 5) == 0) {\n        factors.push_back(5);\n        n /= 5;\n    }\n\n    // Check divisibility by 7\n    while ((n % 7) == 0) {\n        factors.push_back(7);\n        n /= 7;\n    }\n\n    int16_t limit = static_cast<int16_t>(sqrt(n));\n    int16x4_t vlimit = vdup_n_s16(limit);\n\n    for (int16_t i = 11; i <= limit; i += 16) {\n        int16x4_t vi = vld1_s16(&i);\n        int16x4_t vrem = vmul_s16(vi, vdup_n_s16(n / i));\n        int16x4_t veq = vceq_s16(vrem, vn);\n\n        uint16x4_t vmask = vreinterpret_u16_s16(veq);\n        uint16x4_t vzero = vdup_n_u16(0);\n        uint16x4_t vcmp = vclt_u16(vmask, vzero);\n\n        int indices[4];\n        vst1_s16(reinterpret_cast<int16_t*>(indices), vi);\n\n        for (int j = 0; j < 4; ++j) {\n            if (vget_lane_u16(vcmp, j) == 0 && n % indices[j] == 0) {\n                while ((n % indices[j]) == 0) {\n                    factors.push_back(indices[j]);\n                    n /= indices[j];\n                }\n            }\n        }\n    }\n\n    if (n > 1) {\n        factors.push_back(n);\n    }\n\n    return factors;\n}\n```"}
{"task_id": "SimdBench_74_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int> factorize_simd(int n) {\n    std::vector<int> factors;\n    if (n < 2) return factors;\n\n    int16x8_t divisors = vdupq_n_s16(2);\n    int16x8_t limit = vdupq_n_s16(static_cast<short>(sqrt(n)));\n\n    for (short i = 2; i <= sqrt(n); ++i) {\n        int16x8_t current = vdupq_n_s16(i);\n        int16x8_t remainder = vdupq_n_s16(n % i);\n        int16x8_t zero = vdupq_n_s16(0);\n\n        if (vceqq_s16(remainder, zero)) {\n            factors.push_back(i);\n            n /= i;\n            i = 1; // Reset to start from 2 again\n        }\n    }\n\n    if (n > 1) {\n        factors.push_back(n);\n    }\n\n    return factors;\n}\n```"}
{"task_id": "SimdBench_74_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int> factorize_simd(int n) {\n    std::vector<int> factors;\n    if (n < 2) return factors;\n\n    int16x8_t divisors = {2, 3, 5, 7, 11, 13, 17, 19};\n    int16x8_t remainder;\n    int16x8_t zero = vdupq_n_s16(0);\n    int16x8_t one = vdupq_n_s16(1);\n\n    for (int i = 0; i < 8; ++i) {\n        int d = vgetq_lane_s16(divisors, i);\n        if (d * d > n) break;\n        while (n % d == 0) {\n            factors.push_back(d);\n            n /= d;\n        }\n    }\n\n    if (n > 1) {\n        factors.push_back(n);\n    }\n\n    return factors;\n}\n```"}
{"task_id": "SimdBench_74_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int> factorize_simd(int n) {\n    std::vector<int> factors;\n    if (n < 2) return factors;\n\n    int16x8_t divisors = vdupq_n_s16(2);\n    int16x8_t limit = vdupq_n_s16(static_cast<int16_t>(sqrt(n)));\n\n    for (int16_t d = 2; d <= sqrt(n); ++d) {\n        int16x8_t divisor = vdupq_n_s16(d);\n        while (!(n % d)) {\n            factors.push_back(d);\n            n /= d;\n        }\n    }\n\n    if (n > 1) {\n        factors.push_back(n);\n    }\n\n    return factors;\n}\n```"}
{"task_id": "SimdBench_74_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int> factorize_simd(int n) {\n    std::vector<int> factors;\n    if (n < 2) return factors;\n\n    int16x4_t vtwo = vdup_n_s16(2);\n    int16x4_t vthree = vdup_n_s16(3);\n    int16x4_t vfive = vdup_n_s16(5);\n    int16x4_t vseven = vdup_n_s16(7);\n\n    // Factor out multiples of 2\n    while (!(n % 2)) {\n        factors.push_back(2);\n        n /= 2;\n    }\n\n    // Factor out multiples of 3\n    while (!(n % 3)) {\n        factors.push_back(3);\n        n /= 3;\n    }\n\n    // Factor out multiples of 5\n    while (!(n % 5)) {\n        factors.push_back(5);\n        n /= 5;\n    }\n\n    // Factor out multiples of 7\n    while (!(n % 7)) {\n        factors.push_back(7);\n        n /= 7;\n    }\n\n    int16_t potential_factors[] = {11, 13, 17, 19, 23, 29, 31, 37};\n    int16x4_t vp_factors = vld1_s16(potential_factors);\n\n    int limit = static_cast<int>(sqrt(static_cast<double>(n))) + 1;\n\n    for (int i = 11; i <= limit; i += 10) {\n        int16x4_t vi = vdup_n_s16(i);\n        int16x4_t vi_add_two = vadd_s16(vi, vtwo);\n        int16x4_t vi_add_four = vadd_s16(vi, vfive);\n        int16x4_t vi_add_six = vadd_s16(vi, vseven);\n\n        int16x4_t vn = vdup_n_s16(n);\n\n        // Check divisibility for i, i+2, i+4, i+6\n        uint16x4_t vcmp1 = vceq_s16(vn, vmul_s16(vn, vi));\n        uint16x4_t vcmp2 = vceq_s16(vn, vmul_s16(vn, vi_add_two));\n        uint16x4_t vcmp3 = vceq_s16(vn, vmul_s16(vn, vi_add_four));\n        uint16x4_t vcmp4 = vceq_s16(vn, vmul_s16(vn, vi_add_six));\n\n        if (vget_lane_u16(vcmp1, 0)) {\n            while (!(n % i)) {\n                factors.push_back(i);\n                n /= i;\n            }\n        }\n        if (vget_lane_u16(vcmp2, 0)) {\n            int j = i + 2;\n            while (!(n % j)) {\n                factors.push_back(j);\n                n /= j;\n            }\n        }\n        if (vget_lane_u16(vcmp3, 0)) {\n            int j = i + 4;\n            while (!(n % j)) {\n                factors.push_back(j);\n                n /= j;\n            }\n        }\n        if (vget_lane_u16(vcmp4, 0)) {\n            int j = i + 6;\n            while (!(n % j)) {\n                factors.push_back(j);\n                n /= j;\n            }\n        }\n    }\n\n    if (n > 1) {\n        factors.push_back(n);\n    }\n\n    return factors;\n}\n```"}
{"task_id": "SimdBench_75_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<float> get_positive_simd(const std::vector<float> & l){\n    size_t size = l.size();\n    std::vector<float> result;\n    if (size == 0) return result;\n\n    size_t aligned_size = size / 4 * 4;\n    float32x4_t zero = vdupq_n_f32(0.0f);\n\n    for (size_t i = 0; i < aligned_size; i += 4) {\n        float32x4_t vec = vld1q_f32(&l[i]);\n        uint32x4_t mask = vcgtq_f32(vec, zero);\n        uint32x4_t indices = vmovemask_f32(vreinterpretq_f32_u32(mask));\n        \n        for (int j = 0; j < 4; ++j) {\n            if ((indices >> j) & 1) {\n                result.push_back(l[i + j]);\n            }\n        }\n    }\n\n    // Handle remaining elements\n    for (size_t i = aligned_size; i < size; ++i) {\n        if (l[i] > 0) {\n            result.push_back(l[i]);\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_75_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<float> get_positive_simd(const std::vector<float> & l){\n    std::vector<float> result;\n    if (l.empty()) return result;\n\n    size_t vec_size = l.size();\n    float *data = const_cast<float*>(l.data());\n\n    // Process elements in chunks of 4\n    size_t i = 0;\n    for (; i <= vec_size - 4; i += 4) {\n        float32x4_t vec = vld1q_f32(&data[i]);\n        float32x4_t zero = vdupq_n_f32(0.0f);\n        uint32x4_t mask = vcgeq_f32(vec, zero);\n        float32x4_t filtered = vbslq_f32(mask, vec, zero);\n\n        // Store positive values\n        float temp[4];\n        vst1q_f32(temp, filtered);\n        for (int j = 0; j < 4; ++j) {\n            if (temp[j] > 0.0f) result.push_back(temp[j]);\n        }\n    }\n\n    // Handle remaining elements\n    for (; i < vec_size; ++i) {\n        if (data[i] > 0.0f) result.push_back(data[i]);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_75_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<float> get_positive_simd(const std::vector<float> & l){\n    std::vector<float> result;\n    size_t vec_size = l.size();\n    if (vec_size == 0) return result;\n\n    size_t aligned_size = vec_size / 4 * 4;\n    float32x4_t zero = vdupq_n_f32(0.0f);\n\n    for (size_t i = 0; i < aligned_size; i += 4) {\n        float32x4_t vec = vld1q_f32(&l[i]);\n        uint32x4_t mask = vcgtq_f32(vec, zero);\n        float32x4_t filtered = vbslq_f32(mask, vec, zero);\n\n        float tmp[4];\n        vst1q_f32(tmp, filtered);\n\n        for (int j = 0; j < 4; ++j) {\n            if (tmp[j] > 0.0f) result.push_back(tmp[j]);\n        }\n    }\n\n    // Handle remaining elements\n    for (size_t i = aligned_size; i < vec_size; ++i) {\n        if (l[i] > 0.0f) result.push_back(l[i]);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_75_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<float> get_positive_simd(const std::vector<float> & l){\n    std::vector<float> result;\n    if (l.empty()) return result;\n\n    size_t vec_size = l.size();\n    size_t aligned_size = vec_size / 4 * 4;\n    float *data = const_cast<float*>(l.data());\n\n    for (size_t i = 0; i < aligned_size; i += 4) {\n        float32x4_t vec = vld1q_f32(data + i);\n        uint32x4_t mask = vcgtq_f32(vec, vdupq_n_f32(0.0f));\n        float32x4_t filtered = vbslq_f32(mask, vec, vdupq_n_f32(0.0f));\n\n        float tmp[4];\n        vst1q_f32(tmp, filtered);\n\n        for (int j = 0; j < 4; ++j) {\n            if (tmp[j] > 0.0f) {\n                result.push_back(tmp[j]);\n            }\n        }\n    }\n\n    // Handle remaining elements\n    for (size_t i = aligned_size; i < vec_size; ++i) {\n        if (data[i] > 0.0f) {\n            result.push_back(data[i]);\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_75_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<float> get_positive_simd(const std::vector<float> & l){\n    std::vector<float> result;\n    size_t vec_size = l.size() / 4 * 4;\n    float *data = const_cast<float*>(&l[0]);\n\n    for (size_t i = 0; i < vec_size; i += 4) {\n        float32x4_t vec = vld1q_f32(data + i);\n        uint32x4_t mask = vcgeq_f32(vec, vdupq_n_f32(0.0f));\n        float32x4_t filtered = vbslq_f32(mask, vec, vdupq_n_f32(0.0f));\n\n        float vals[4];\n        vst1q_f32(vals, filtered);\n\n        for(int j = 0; j < 4; ++j){\n            if(vals[j] > 0.0f){\n                result.push_back(vals[j]);\n            }\n        }\n    }\n\n    // Handle remaining elements\n    for (size_t i = vec_size; i < l.size(); ++i) {\n        if(l[i] > 0.0f){\n            result.push_back(l[i]);\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_76_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nbool is_prime_simd(int64_t n){\n    if (n <= 1) return false;\n    if (n <= 3) return true;\n    if ((n % 2) == 0 || (n % 3) == 0) return false;\n\n    int64x1_t n_vec = vdup_n_s64(n);\n\n    const int limit = (int)(sqrt((double)n));\n    int64x2_t factors = vdupq_n_s64(5);\n    int64x2_t step = vdupq_n_s64(6);\n\n    for(int i = 5; i <= limit; i += 6){\n        int64x2_t current = vdupq_n_s64(i);\n        int64x2_t mod_results = vmovq_n_s64(\n            (n % i == 0) ? 0 : (n % (i + 2) == 0 ? 0 : 1)\n        );\n\n        if(vgetq_lane_s64(mod_results, 0) == 0 || vgetq_lane_s64(mod_results, 1) == 0){\n            return false;\n        }\n        factors = vaddq_s64(factors, step);\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_76_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nbool is_prime_simd(int64_t n){\n    if (n <= 1) return false;\n    if (n <= 3) return true;\n    if ((n % 2 == 0) || (n % 3 == 0)) return false;\n\n    int64x2_t sqrt_n = { static_cast<int64_t>(std::sqrt(n)), static_cast<int64_t>(std::sqrt(n)) };\n    int64x2_t limit = { 5, 5 };\n\n    while (true) {\n        int64x2_t test = vdupq_n_s64(0);\n        test = vmovl_s32(vcreate_s32(0x0005000300010007)); // Create vector [3, 5]\n        test = vaddl_s32(test, limit); // Add limit to each element\n\n        uint64x2_t cmp_res = vcgeq_s64(test, vdupq_n_s64(sqrt_n[0]));\n        if (vget_lane_u64(cmp_res, 0) || vget_lane_u64(cmp_res, 1)) break;\n\n        int64x2_t rem = vmulq_n_s64(test, n);\n        rem = vmlsq_n_s64(rem, n, test);\n\n        if (!vget_lane_s64(rem, 0) || !vget_lane_s64(rem, 1)) return false;\n\n        limit = vaddq_n_s64(limit, 6);\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_76_Neon", "completion": "```c\n#include <arm_neon.h>\n\nbool is_prime_simd(int64_t n){\n    if (n <= 1) return false;\n    if (n <= 3) return true;\n    if ((n % 2) == 0 || (n % 3) == 0) return false;\n\n    int64x2_t sqrt_n = vmov_n_s64((int64_t)(sqrt((double)n)));\n    int64x2_t vn = vmov_n_s64(n);\n    int64x2_t zero = vmov_n_s64(0);\n\n    for (int64_t i = 5; i <= sqrt((double)n); i += 6){\n        int64x2_t vi = vmov_n_s64(i);\n        int64x2_t mod_i = vsub_s64(vn, vmul_s64(vi, vdup_n_s64(i)));\n        int64x2_t mod_i_plus_2 = vsub_s64(vn, vmul_s64(vi, vdup_n_s64(i + 2)));\n\n        if (vminvq_s64(mod_i) == zero || vminvq_s64(mod_i_plus_2) == zero) {\n            return false;\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_76_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nbool is_prime_simd(int64_t n){\n    if (n <= 1) return false;\n    if (n <= 3) return true;\n    if ((n % 2) == 0 || (n % 3) == 0) return false;\n\n    int64x2_t vec_n = vdupq_n_s64(n);\n    int64x2_t zero = vdupq_n_s64(0);\n\n    for (int64_t i = 5; i * i <= n; i += 6){\n        int64x2_t vec_i = vdupq_n_s64(i);\n        int64x2_t mod1 = vsubq_s64(vec_n, vmlaq_s64(zero, vec_i, vec_n));\n        int64x2_t mod2 = vsubq_s64(vec_n, vmlaq_s64(zero, vec_i + 2, vec_n));\n\n        if (vminvq_s64(mod1) == 0 || vminvq_s64(mod2) == 0) return false;\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_76_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nbool is_prime_simd(int64_t n){\n    if (n <= 1) return false;\n    if (n <= 3) return true;\n    if ((n % 2) == 0 || (n % 3) == 0) return false;\n\n    int64x2_t sqrt_n = { static_cast<int64_t>(sqrt(static_cast<double>(n))) };\n    int64x2_t current = { 5, 7 };\n    int64x2_t step = { 2, 2 };\n\n    while (true) {\n        int64x2_t remainder = vsubq_s64(vmulq_s64(current, current), vdupq_n_s64(n));\n        uint64x2_t cmp_result = vcgeq_s64(remainder, vdupq_n_s64(0));\n        if (vaddvq_u8(vcgtq_s64(remainder, vdupq_n_s64(0))) != 0) break;\n\n        if (vorv_u8(cmp_result)) return false;\n\n        current = vaddq_s64(current, step);\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_77_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <cstring>\n\nstd::string solve_simd(const std::string & s){\n    size_t len = s.length();\n    if (len == 0) return \"\";\n\n    // Check if there are any letters in the string\n    bool has_letter = false;\n    for(char c : s){\n        if((c >= 'a' && c <= 'z') || (c >= 'A' && c <= 'Z')){\n            has_letter = true;\n            break;\n        }\n    }\n\n    uint8x16_t vowels = vdupq_n_u8(0);\n    uint8x16_t diff = vdupq_n_u8('a' - 'A');\n    uint8x16_t lower_a = vdupq_n_u8('a');\n    uint8x16_t lower_z = vdupq_n_u8('z');\n    uint8x16_t upper_a = vdupq_n_u8('A');\n    uint8x16_t upper_z = vdupq_n_u8('Z');\n\n    char result[len + 1];\n    result[len] = '\\0';\n\n    if(has_letter){\n        for(size_t i = 0; i < len; i += 16){\n            size_t chunk_size = std::min(len - i, (size_t)16);\n            uint8x16_t vec = vld1q_u8(reinterpret_cast<const uint8_t*>(&s[i]));\n\n            // Create masks for lowercase and uppercase letters\n            uint8x16_t is_lower = vcgeq_u8(vec, lower_a);\n            is_lower = vandq_u8(is_lower, vcleq_u8(vec, lower_z));\n\n            uint8x16_t is_upper = vcgeq_u8(vec, upper_a);\n            is_upper = vandq_u8(is_upper, vcleq_u8(vec, upper_z));\n\n            // Convert to opposite case\n            uint8x16_t to_upper = vsubq_u8(vec, diff);\n            uint8x16_t to_lower = vaddq_u8(vec, diff);\n\n            uint8x16_t swapped = vbslq_u8(is_lower, to_upper, vec);\n            swapped = vbslq_u8(is_upper, to_lower, swapped);\n\n            vst1q_u8(reinterpret_cast<uint8_t*>(&result[i]), swapped);\n        }\n    }\n    else{\n        for(int i = 0; i < len; ++i){\n            result[i] = s[len - i - 1];\n        }\n    }\n\n    return std::string(result, len);\n}\n```"}
{"task_id": "SimdBench_77_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <cstring>\n\nstd::string solve_simd(const std::string & s){\n    size_t len = s.length();\n    if (len == 0) return s;\n\n    // Allocate memory for the result\n    std::string result(s);\n\n    uint8x16_t v_lower_a = vdupq_n_u8('a');\n    uint8x16_t v_lower_z = vdupq_n_u8('z');\n    uint8x16_t v_upper_a = vdupq_n_u8('A');\n    uint8x16_t v_upper_z = vdupq_n_u8('Z');\n    uint8x16_t v_space = vdupq_n_u8(' ');\n    uint8x16_t v_diff = vdupq_n_u8(32);\n\n    bool has_letter = false;\n\n    for (size_t i = 0; i < len; i += 16) {\n        size_t chunk_size = std::min(len - i, (size_t)16);\n        uint8x16_t v_in = vld1q_u8(reinterpret_cast<const uint8_t*>(&result[i]));\n\n        // Check for lowercase letters\n        uint8x16_t v_is_lower = vcgeq_u8(v_in, v_lower_a);\n        v_is_lower = vandq_u8(v_is_lower, vcleq_u8(v_in, v_lower_z));\n\n        // Check for uppercase letters\n        uint8x16_t v_is_upper = vcgeq_u8(v_in, v_upper_a);\n        v_is_upper = vandq_u8(v_is_upper, vcleq_u8(v_in, v_upper_z));\n\n        // Combine checks\n        uint8x16_t v_is_letter = vorrq_u8(v_is_lower, v_is_upper);\n\n        // Check if there is any letter in this chunk\n        int temp = vaddvq_u8(vreinterpretq_u8_u32(vmovl_u8(vget_low_u8(v_is_letter))));\n        temp += vaddvq_u8(vreinterpretq_u8_u32(vmovl_u8(vget_high_u8(v_is_letter))));\n        if (temp > 0) has_letter = true;\n\n        // Toggle case for letters\n        uint8x16_t v_case_toggled = veorq_u8(v_in, vandq_u8(v_is_letter, v_diff));\n\n        // Store the result back\n        vst1q_u8(reinterpret_cast<uint8_t*>(&result[i]), v_case_toggled);\n    }\n\n    if (!has_letter) {\n        // Reverse the string\n        for (size_t i = 0; i < len / 2; ++i) {\n            std::swap(result[i], result[len - i - 1]);\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_77_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <cstring>\n\nstd::string solve_simd(const std::string & s){\n    int n = s.size();\n    if (n == 0) return \"\";\n\n    // Check if the string contains any letters\n    bool has_letters = false;\n    for(char c : s){\n        if( (c >= 'a' && c <= 'z') || (c >= 'A' && c <= 'Z') ){\n            has_letters = true;\n            break;\n        }\n    }\n\n    // If no letters, reverse the string\n    if(!has_letters){\n        return std::string(s.rbegin(), s.rend());\n    }\n\n    // Prepare result buffer\n    std::string result(s);\n\n    // Process in chunks of 16 bytes using NEON\n    const uint8x16_t lower_mask = vdupq_n_u8(0xDF); // Bitmask for tolower/toupper\n    const uint8x16_t diff_mask = vdupq_n_u8(0x20);  // Difference between upper and lower case\n\n    for(int i = 0; i < n; i += 16){\n        int chunk_size = std::min(n - i, 16);\n        \n        // Load data into NEON register\n        uint8x16_t vec = vmovq_n_u8(0);\n        if(chunk_size == 16){\n            vec = vld1q_u8(reinterpret_cast<const uint8_t*>(&s[i]));\n        }\n        else{\n            uint8_t temp[16] = {0};\n            memcpy(temp, &s[i], chunk_size);\n            vec = vld1q_u8(temp);\n        }\n\n        // Create a mask for alphabetic characters\n        uint8x16_t is_alpha = vandq_u8(vcgeq_u8(vec, vdupq_n_u8('A')), \n                                      vcleq_u8(vec, vdupq_n_u8('Z')));\n        is_alpha = vorrq_u8(is_alpha, \n                           vandq_u8(vcgeq_u8(vec, vdupq_n_u8('a')), \n                                    vcleq_u8(vec, vdupq_n_u8('z'))));\n\n        // Toggle case for alphabetic characters\n        uint8x16_t toggled = veorq_u8(vec, vandq_u8(is_alpha, diff_mask));\n\n        // Store results back\n        if(chunk_size == 16){\n            vst1q_u8(reinterpret_cast<uint8_t*>(&result[i]), toggled);\n        }\n        else{\n            uint8_t temp[16] = {0};\n            vst1q_u8(temp, toggled);\n            memcpy(&result[i], temp, chunk_size);\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_77_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <cstring>\n\nstd::string solve_simd(const std::string & s){\n    int n = s.size();\n    if (n == 0) return s;\n\n    // Check if the string contains any letters\n    bool has_letter = false;\n    for (char c : s) {\n        if ((c >= 'a' && c <= 'z') || (c >= 'A' && c <= 'Z')) {\n            has_letter = true;\n            break;\n        }\n    }\n\n    uint8x16_t vowels = vdupq_n_u8(0);\n    uint8x16_t mask_upper = vdupq_n_u8('A' - 1);\n    uint8x16_t mask_lower = vdupq_n_u8('a' - 1);\n    uint8x16_t diff_case = vdupq_n_u8('a' - 'A');\n\n    std::string result;\n    result.reserve(n);\n\n    if (has_letter) {\n        for (int i = 0; i < n; i += 16) {\n            int len = std::min(16, n - i);\n            uint8x16_t vec = vld1q_u8(reinterpret_cast<const uint8_t*>(&s[i]));\n\n            uint8x16_t is_upper = vcgeq_u8(vec, mask_upper);\n            uint8x16_t is_lower = vcgeq_u8(vec, mask_lower);\n\n            uint8x16_t toggle_mask = vorrq_u8(is_upper, is_lower);\n            uint8x16_t toggled = vsubq_u8(vec, vmulq_u8(toggle_mask, diff_case));\n\n            uint8x16_t unchanged = vbslq_u8(toggle_mask, toggled, vec);\n\n            uint8_t temp[16];\n            vst1q_u8(temp, unchanged);\n            result.append(reinterpret_cast<char*>(temp), len);\n        }\n    } else {\n        // Reverse the string\n        for (int i = n - 1; i >= 0; --i) {\n            result.push_back(s[i]);\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_77_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <cstring>\n\nstd::string solve_simd(const std::string & s){\n    size_t len = s.length();\n    if (len == 0) return s;\n\n    // Check if string contains any letters\n    bool has_letter = false;\n    for(char c : s){\n        if( (c >= 'a' && c <= 'z') || (c >= 'A' && c <= 'Z')){\n            has_letter = true;\n            break;\n        }\n    }\n\n    // Allocate result buffer\n    std::string result(s);\n\n    if(!has_letter){\n        // Reverse the entire string\n        for(size_t i = 0; i < len / 2; ++i){\n            char temp = result[i];\n            result[i] = result[len - i - 1];\n            result[len - i - 1] = temp;\n        }\n        return result;\n    }\n\n    // Process with NEON SIMD\n    const uint8x16_t lower_mask = vld1q_u8((const uint8_t*)\"abcdefghijklmnopqrstuvwxyz\");\n    const uint8x16_t upper_mask = vld1q_u8((const uint8_t*)\"ABCDEFGHIJKLMNOPQRSTUVWXYZ\");\n\n    for(size_t i = 0; i < len; i += 16){\n        uint8x16_t chars = vld1q_u8(reinterpret_cast<const uint8_t*>(&s[i]));\n\n        // Create masks for lowercase and uppercase letters\n        uint8x16_t lower_cmp = vmovemaskq_u8(vceqq_u8(chars, lower_mask));\n        uint8x16_t upper_cmp = vmovemaskq_u8(vceqq_u8(chars, upper_mask));\n\n        // Toggle case for matching characters\n        uint8x16_t toggled = vorrq_u8(\n            vandq_u8(chars, vmvnq_u8(lower_cmp)), \n            vandq_u8(chars, vmvnq_u8(upper_cmp))\n        );\n\n        // Store the results back\n        vst1q_u8(reinterpret_cast<uint8_t*>(&result[i]), toggled);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_78_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<int> sort_third_simd(std::vector<int> l){\n    size_t n = l.size();\n    if (n == 0) return {};\n\n    // Collect elements at indices divisible by three\n    std::vector<int> div_by_three;\n    for (size_t i = 0; i < n; i += 3) {\n        div_by_three.push_back(l[i]);\n    }\n\n    // Sort them\n    std::sort(div_by_three.begin(), div_by_three.end());\n\n    // Prepare Neon processing\n    size_t sorted_idx = 0;\n    for (size_t i = 0; i < n; i += 16) {\n        int32x4_t v_sorted[4];\n        int32x4_t v_original[4];\n\n        // Load original values\n        for (size_t j = 0; j < 4 && (i + j * 4) < n; ++j) {\n            v_original[j] = vld1q_s32(&l[i + j * 4]);\n        }\n\n        // Replace values at indices divisible by three\n        for (size_t j = 0; j < 4 && (i + j * 4) < n; ++j) {\n            if ((i + j * 4) % 3 == 0) {\n                v_sorted[j] = vdupq_n_s32(div_by_three[sorted_idx++]);\n            } else {\n                v_sorted[j] = v_original[j];\n            }\n        }\n\n        // Store back to vector\n        for (size_t j = 0; j < 4 && (i + j * 4) < n; ++j) {\n            vst1q_s32(&l[i + j * 4], v_sorted[j]);\n        }\n    }\n\n    return l;\n}\n```"}
{"task_id": "SimdBench_78_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<int> sort_third_simd(std::vector<int> l){\n    size_t n = l.size();\n    if (n == 0) return l;\n\n    // Collect elements at indices divisible by three\n    std::vector<int> div_by_three;\n    for(size_t i = 0; i < n; i += 4){\n        int32x4_t vl = vld1q_s32(&l[i]);\n        int idx0 = i + 0, idx1 = i + 1, idx2 = i + 2, idx3 = i + 3;\n        if(idx0 % 3 == 0 && idx0 < n) div_by_three.push_back(vgetq_lane_s32(vl, 0));\n        if(idx1 % 3 == 0 && idx1 < n) div_by_three.push_back(vgetq_lane_s32(vl, 1));\n        if(idx2 % 3 == 0 && idx2 < n) div_by_three.push_back(vgetq_lane_s32(vl, 2));\n        if(idx3 % 3 == 0 && idx3 < n) div_by_three.push_back(vgetq_lane_s32(vl, 3));\n    }\n\n    // Sort the collected elements\n    std::sort(div_by_three.begin(), div_by_three.end());\n\n    // Replace the original elements with sorted ones\n    size_t sorted_idx = 0;\n    for(size_t i = 0; i < n && sorted_idx < div_by_three.size(); ++i){\n        if(i % 3 == 0){\n            l[i] = div_by_three[sorted_idx++];\n        }\n    }\n\n    return l;\n}\n```"}
{"task_id": "SimdBench_78_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<int> sort_third_simd(std::vector<int> l) {\n    size_t n = l.size();\n    if (n == 0) return l;\n\n    // Extract elements at indices divisible by three\n    std::vector<int> div_by_three;\n    for (size_t i = 0; i < n; i++) {\n        if (i % 3 == 0) {\n            div_by_three.push_back(l[i]);\n        }\n    }\n\n    // Sort the extracted elements\n    std::sort(div_by_three.begin(), div_by_three.end());\n\n    // Create a vector of indices divisible by three\n    std::vector<size_t> indices_div_by_three;\n    for (size_t i = 0; i < n; i++) {\n        if (i % 3 == 0) {\n            indices_div_by_three.push_back(i);\n        }\n    }\n\n    // Prepare Neon processing\n    size_t num_simd = indices_div_by_three.size() / 4;\n    size_t remainder = indices_div_by_three.size() % 4;\n\n    size_t sorted_idx = 0;\n    for (size_t simd_i = 0; simd_i < num_simd; simd_i++) {\n        int32x4_t v_sorted = vld1q_s32(&div_by_three[sorted_idx]);\n        int32x4_t indices = vld1q_s32(&indices_div_by_three[sorted_idx]);\n\n        // Scatter update\n        for (int j = 0; j < 4; j++) {\n            size_t idx = vgetq_lane_s32(indices, j);\n            if (idx < n) {\n                l[idx] = vgetq_lane_s32(v_sorted, j);\n            }\n        }\n        sorted_idx += 4;\n    }\n\n    // Handle remaining elements\n    for (size_t i = 0; i < remainder; i++) {\n        size_t idx = indices_div_by_three[num_simd * 4 + i];\n        if (idx < n) {\n            l[idx] = div_by_three[sorted_idx++];\n        }\n    }\n\n    return l;\n}\n```"}
{"task_id": "SimdBench_78_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<int> sort_third_simd(std::vector<int> l){\n    size_t n = l.size();\n    if (n == 0) return l;\n\n    // Collect elements at indices divisible by three\n    std::vector<int> div_three;\n    for(size_t i = 0; i < n; i += 3){\n        div_three.push_back(l[i]);\n    }\n\n    // Sort the collected elements\n    std::sort(div_three.begin(), div_three.end());\n\n    // Create a vector of indices divisible by three\n    std::vector<size_t> div_three_indices;\n    for(size_t i = 0; i < n; i += 3){\n        div_three_indices.push_back(i);\n    }\n\n    // Prepare Neon processing\n    size_t num_simd_ops = n / 4;\n    size_t remainder = n % 4;\n\n    // Copy sorted values back into their respective positions\n    int *data = l.data();\n    size_t div_idx = 0;\n    for(size_t i = 0; i < num_simd_ops; ++i){\n        int32x4_t v = vld1q_s32(data + 4*i);\n        if(4*i <= div_three_indices[div_idx] && div_three_indices[div_idx] < 4*(i+1)){\n            size_t pos = div_three_indices[div_idx] - 4*i;\n            int32x4_t sorted_val = vdupq_n_s32(div_three[div_idx]);\n            v = vsetq_lane_s32(div_three[div_idx], v, pos);\n            div_idx++;\n            while(div_idx < div_three_indices.size() && div_three_indices[div_idx] < 4*(i+1)){\n                pos = div_three_indices[div_idx] - 4*i;\n                v = vsetq_lane_s32(div_three[div_idx], v, pos);\n                div_idx++;\n            }\n        }\n        vst1q_s32(data + 4*i, v);\n    }\n\n    // Handle remaining elements\n    for(size_t i = num_simd_ops * 4; i < n; ++i){\n        if(div_idx < div_three_indices.size() && div_three_indices[div_idx] == i){\n            l[i] = div_three[div_idx];\n            div_idx++;\n        }\n    }\n\n    return l;\n}\n```"}
{"task_id": "SimdBench_78_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<int> sort_third_simd(std::vector<int> l){\n    size_t n = l.size();\n    if (n == 0) return l;\n\n    // Collect elements at indices divisible by three\n    std::vector<int> div_by_three;\n    for(size_t i = 0; i < n; i += 3){\n        div_by_three.push_back(l[i]);\n    }\n\n    // Sort them\n    std::sort(div_by_three.begin(), div_by_three.end());\n\n    // Prepare Neon processing\n    size_t num_simd_ops = n / 4;\n    size_t remainder = n % 4;\n\n    // Convert input vector to Neon format and process\n    for(size_t i = 0; i < num_simd_ops * 4; i += 4){\n        int32x4_t vec = vld1q_s32(&l[i]);\n        int32x4_t updated_vec = vec;\n\n        for(size_t j = 0; j < 4; ++j){\n            if((i + j) % 3 == 0){\n                size_t idx = (i + j) / 3;\n                if(idx < div_by_three.size()){\n                    updated_vec = vsetq_lane_s32(div_by_three[idx], updated_vec, j);\n                }\n            }\n        }\n        vst1q_s32(&l[i], updated_vec);\n    }\n\n    // Handle remaining elements that couldn't fit into a single SIMD operation\n    for(size_t i = num_simd_ops * 4; i < n; ++i){\n        if(i % 3 == 0){\n            size_t idx = i / 3;\n            if(idx < div_by_three.size()){\n                l[i] = div_by_three[idx];\n            }\n        }\n    }\n\n    return l;\n}\n```"}
{"task_id": "SimdBench_79_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <climits>\n\nfloat max_element_simd(std::vector<float> l){\n    int n = l.size();\n    if (n == 0) return 0.0f;\n\n    float32x4_t vmax = vld1q_f32(&l[0]);\n    for(int i = 4; i < n; i += 4){\n        float32x4_t v = vld1q_f32(&l[i]);\n        vmax = vmaxq_f32(vmax, v);\n    }\n\n    float32x2_t vlow = vget_low_f32(vmax);\n    float32x2_t vhigh = vget_high_f32(vmax);\n    float32x2_t vcmp = vmax_f32(vlow, vhigh);\n\n    float result = vget_lane_f32(vcmp, 0);\n    result = fmaxf(result, vget_lane_f32(vcmp, 1));\n\n    // Handle remaining elements if any\n    for(int i = (n / 4) * 4; i < n; ++i){\n        result = fmaxf(result, l[i]);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_79_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <climits>\n\nfloat max_element_simd(std::vector<float> l){\n    size_t size = l.size();\n    if (size == 0) return 0.0f;\n\n    float32x4_t vmax = vld1q_f32(&l[0]);\n    for(size_t i = 4; i < size; i += 4){\n        float32x4_t v = vld1q_f32(&l[i]);\n        vmax = vmaxq_f32(vmax, v);\n    }\n\n    float32x2_t vm_low = vget_low_f32(vmax);\n    float32x2_t vm_high = vget_high_f32(vmax);\n\n    float32x2_t vm_max = vmax_f32(vm_low, vm_high);\n\n    float result = vm_max[0] > vm_max[1] ? vm_max[0] : vm_max[1];\n\n    // Handle remaining elements\n    for(size_t i = (size / 4) * 4; i < size; ++i){\n        if(l[i] > result) result = l[i];\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_79_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <climits>\n\nfloat max_element_simd(std::vector<float> l){\n    float32x4_t vec_max = vld1q_f32(&l[0]);\n    size_t i = 4;\n    for (; i + 4 <= l.size(); i += 4) {\n        float32x4_t current_vec = vld1q_f32(&l[i]);\n        vec_max = vmaxq_f32(vec_max, current_vec);\n    }\n    float32x2_t max_low = vget_low_f32(vec_max);\n    float32x2_t max_high = vget_high_f32(vec_max);\n    float32x2_t pair_max = vmax_f32(max_low, max_high);\n    float scalar_max = vmax_f32(vget_lane_f32(pair_max, 0), vget_lane_f32(pair_max, 1));\n\n    for (; i < l.size(); ++i) {\n        if (l[i] > scalar_max) {\n            scalar_max = l[i];\n        }\n    }\n    return scalar_max;\n}\n```"}
{"task_id": "SimdBench_79_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <climits>\n\nfloat max_element_simd(std::vector<float> l){\n    size_t size = l.size();\n    float32x4_t vmax = vld1q_f32(&l[0]);\n    \n    for(size_t i = 4; i <= size - 4; i += 4){\n        float32x4_t v = vld1q_f32(&l[i]);\n        vmax = vmaxq_f32(vmax, v);\n    }\n    \n    float32x2_t vm = vpmax_f32(vget_low_f32(vmax), vget_high_f32(vmax));\n    float32x1_t result = vpmax_f32(vm, vm);\n    \n    float max_val = vget_lane_f32(result, 0);\n    \n    for(size_t i = (size / 4) * 4; i < size; ++i){\n        if(l[i] > max_val){\n            max_val = l[i];\n        }\n    }\n    \n    return max_val;\n}\n```"}
{"task_id": "SimdBench_79_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <climits>\n\nfloat max_element_simd(std::vector<float> l){\n    size_t size = l.size();\n    if (size == 0) return 0.0f;\n\n    float32x4_t vmax = vld1q_f32(&l[0]);\n    for(size_t i = 4; i < size - (size % 4); i += 4){\n        float32x4_t v = vld1q_f32(&l[i]);\n        vmax = vmaxq_f32(vmax, v);\n    }\n\n    float result = vcgetq_lane_f32(vmax, 0);\n    result = fmaxf(result, vcgetq_lane_f32(vmax, 1));\n    result = fmaxf(result, vcgetq_lane_f32(vmax, 2));\n    result = fmaxf(result, vcgetq_lane_f32(vmax, 3));\n\n    for(size_t i = size - (size % 4); i < size; ++i){\n        result = fmaxf(result, l[i]);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_80_Neon", "completion": "```c\n#include <arm_neon.h>\n\nint fizz_buzz_simd(int n){\n    int count = 0;\n    uint32x4_t div_11 = vdupq_n_u32(11);\n    uint32x4_t div_13 = vdupq_n_u32(13);\n    uint32x4_t seven = vdupq_n_u32('7');\n    uint32x4_t zero = vdupq_n_u32(0);\n\n    for (int i = 0; i <= n - 4; i += 4) {\n        uint32x4_t nums = vld1q_u32((uint32_t const *)(i));\n        uint32x4_t mod_11 = vmodq_u32(nums, div_11);\n        uint32x4_t mod_13 = vmodq_u32(nums, div_13);\n        uint32x4_t cmp_11 = vceqq_u32(mod_11, zero);\n        uint32x4_t cmp_13 = vceqq_u32(mod_13, zero);\n        uint32x4_t mask = vorrq_u32(cmp_11, cmp_13);\n\n        uint32x4_t digits = vmovq_n_u32(0);\n        for (int j = 0; j < 4; ++j) {\n            uint32x4_t temp = vshrq_n_u32(nums, j * 8);\n            uint32x4_t digit = vandq_u32(temp, vdupq_n_u32(0xFF));\n            uint32x4_t eq_seven = vceqq_u32(digit, seven);\n            digits = vaddq_u32(digits, vandq_u32(eq_seven, mask));\n        }\n        count += vaddvq_u32(digits);\n    }\n\n    for (int i = n - (n % 4); i < n; ++i) {\n        if ((i % 11 == 0 || i % 13 == 0) && i != 0) {\n            int num = i;\n            while (num > 0) {\n                if (num % 10 == 7) count++;\n                num /= 10;\n            }\n        }\n    }\n    return count;\n}\n```"}
{"task_id": "SimdBench_80_Neon", "completion": "```c\n#include <arm_neon.h>\n\nint fizz_buzz_simd(int n){\n    int count = 0;\n    uint32x4_t divisors = vdupq_n_u32(11 * 13); // 11 * 13 = 143\n    uint32x4_t sevens = vdupq_n_u32('7');\n    uint32x4_t zero = vdupq_n_u32(0);\n    uint32x4_t limit = vdupq_n_u32(n);\n\n    for (int i = 0; i <= n - 4; i += 4) {\n        uint32x4_t nums = vld1q_u32((uint32_t const*)&i);\n        uint32x4_t mod_results = vmulq_u32(nums, vdupq_n_u32(1));\n        uint32x4_t mask = vorrq_u32(vceqq_u32(mod_results, zero), vceqq_u32(vmull_u16(vget_low_u16(mod_results), vdup_n_u16(1)), vget_low_u16(divisors)));\n\n        uint32x4_t valid_nums = vandq_u32(nums, mask);\n        uint32x4_t cmp_seven = vceqq_u32(valid_nums, sevens);\n\n        count += vaddvq_u32(cmp_seven);\n    }\n\n    for (int i = n - (n % 4); i < n; ++i) {\n        if (i % 11 == 0 || i % 13 == 0) {\n            int temp = i;\n            while (temp > 0) {\n                if (temp % 10 == 7) {\n                    count++;\n                }\n                temp /= 10;\n            }\n        }\n    }\n    return count;\n}\n```"}
{"task_id": "SimdBench_80_Neon", "completion": "```c\n#include <arm_neon.h>\n\nint fizz_buzz_simd(int n){\n    int count = 0;\n    uint32x4_t vec_seven = vdupq_n_u32('7');\n    uint32x4_t divisors[2] = {vdupq_n_u32(11), vdupq_n_u32(13)};\n    \n    for(int i = 0; i < n; i++){\n        if(i % 11 == 0 || i % 13 == 0){\n            int num = i;\n            bool has_seven = false;\n            while(num > 0){\n                uint32x4_t digits = vdupq_n_u32(num % 10);\n                num /= 10;\n                if(vminvq_u32(vceqq_u32(digits, vec_seven)) != 0){\n                    has_seven = true;\n                    break;\n                }\n            }\n            if(has_seven){\n                count++;\n            }\n        }\n    }\n    return count;\n}\n```"}
{"task_id": "SimdBench_80_Neon", "completion": "```c\n#include <arm_neon.h>\n\nint fizz_buzz_simd(int n){\n    int count = 0;\n    const uint8x16_t seven = vdupq_n_u8('7');\n    const uint8x16_t ten = vdupq_n_u8(10);\n    \n    for (int i = 0; i < n; i++) {\n        if (i % 11 == 0 || i % 13 == 0) {\n            int temp = i;\n            uint8x16_t digits = vdupq_n_u8(0);\n            int digit_count = 0;\n            \n            if (temp == 0) {\n                digits = vsetq_lane_u8('0', digits, 0);\n                digit_count = 1;\n            }\n            else {\n                while(temp > 0){\n                    uint8_t rem = temp % 10;\n                    digits = vsetq_lane_u8(rem + '0', digits, digit_count++);\n                    temp /= 10;\n                }\n            }\n            \n            uint8x16_t eq = vceqq_u8(digits, seven);\n            uint8x16_t mask = vshrq_n_u8(eq, 7);\n            uint64x2_t sum = vpaddlq_u32(vreinterpretq_u32_u8(mask));\n            sum = vpaddlq_u32(vreinterpretq_u32_u8(sum));\n            count += vgetq_lane_u32(sum, 0) + vgetq_lane_u32(sum, 1);\n        }\n    }\n    return count;\n}\n```"}
{"task_id": "SimdBench_80_Neon", "completion": "```c\n#include <arm_neon.h>\n\nint fizz_buzz_simd(int n){\n    int count = 0;\n    uint32x4_t seven = vdupq_n_u32('7');\n    uint32x4_t divisors[2] = {vdupq_n_u32(11), vdupq_n_u32(13)};\n    \n    for(int i = 0; i < n; i += 4){\n        uint32x4_t nums = vdupq_n_u32(i);\n        nums = vaddq_u32(nums, vmovq_n_u32(0));\n        \n        uint32x4_t mod11 = vmodq_u32(nums, divisors[0]);\n        uint32x4_t mod13 = vmodq_u32(nums, divisors[1]);\n        \n        uint32x4_t mask11 = vceqq_u32(mod11, vdupq_n_u32(0));\n        uint32x4_t mask13 = vceqq_u32(mod13, vdupq_n_u32(0));\n        \n        uint32x4_t mask = vorrq_u32(mask11, mask13);\n        \n        uint32x4_t valid_nums = vandq_u32(nums, mask);\n        \n        for(int j = 0; j < 4; j++){\n            if(valid_nums[j] != 0){\n                int num = valid_nums[j];\n                while(num > 0){\n                    if(num % 10 == 7) count++;\n                    num /= 10;\n                }\n            }\n        }\n    }\n    return count;\n}\n```"}
{"task_id": "SimdBench_81_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<float> sort_even_simd(std::vector<float> l) {\n    size_t n = l.size();\n    std::vector<float> result(n);\n\n    // Handle the case where there are no elements or only one element\n    if (n == 0) return result;\n    if (n == 1) { result[0] = l[0]; return result; }\n\n    // Extract even indices into a separate vector\n    std::vector<float> evens;\n    for (size_t i = 0; i < n; i += 2) {\n        evens.push_back(l[i]);\n    }\n\n    // Sort the even indices\n    std::sort(evens.begin(), evens.end());\n\n    // Interleave sorted evens and original odds using Neon intrinsics\n    size_t num_simd_ops = n / 8; // Process 8 floats per iteration (2 SIMD registers)\n    size_t remaining = n % 8;\n\n    float32x4_t *even_ptr = reinterpret_cast<float32x4_t *>(evens.data());\n    float32x4_t *odd_ptr = reinterpret_cast<float32x4_t *>(&l[1]);\n\n    for (size_t i = 0; i < num_simd_ops; ++i) {\n        float32x4_t even_low = even_ptr[i];\n        float32x4_t even_high = even_ptr[i + num_simd_ops];\n        float32x4_t odd_low = odd_ptr[i];\n        float32x4_t odd_high = odd_ptr[i + num_simd_ops];\n\n        float32x4x2_t interleaved_low = vzipq_f32(even_low, odd_low);\n        float32x4x2_t interleaved_high = vzipq_f32(even_high, odd_high);\n\n        vst2q_f32(&result[8 * i], interleaved_low);\n        vst2q_f32(&result[8 * i + 4], interleaved_high);\n    }\n\n    // Handle remaining elements\n    size_t processed = 8 * num_simd_ops;\n    for (size_t i = processed; i < n; ++i) {\n        if (i % 2 == 0) {\n            result[i] = evens[(i / 2) - num_simd_ops];\n        } else {\n            result[i] = l[i];\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_81_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<float> sort_even_simd(std::vector<float> l) {\n    size_t n = l.size();\n    std::vector<float> sorted_l = l;\n\n    if (n == 0) return sorted_l;\n\n    // Extract even indices elements\n    size_t num_even = (n + 1) / 2;\n    std::vector<float> even_elements(num_even);\n\n    for (size_t i = 0; i < num_even; ++i) {\n        even_elements[i] = l[2 * i];\n    }\n\n    // Sort the even indices elements\n    std::sort(even_elements.begin(), even_elements.end());\n\n    // Use Neon intrinsics to interleave sorted even and original odd elements\n    size_t vec_size = sizeof(float) * 4; // Process 4 floats at a time\n    size_t i = 0;\n\n    for (; i <= (n / 2) - 4; i += 4) {\n        float32x4_t v_sorted = vld1q_f32(&even_elements[i]);\n        float32x4_t v_odd = vld1q_f32(&l[2 * i + 1]);\n\n        float32x4x2_t interleaved;\n        interleaved.val[0] = vzipq_f32(v_sorted, v_odd).val[0];\n        interleaved.val[1] = vzipq_f32(v_sorted, v_odd).val[1];\n\n        vst1q_f32(&sorted_l[2 * i], interleaved.val[0]);\n        vst1q_f32(&sorted_l[2 * i + 4], interleaved.val[1]);\n    }\n\n    // Handle remaining elements\n    for (; i < num_even; ++i) {\n        sorted_l[2 * i] = even_elements[i];\n    }\n\n    return sorted_l;\n}\n```"}
{"task_id": "SimdBench_81_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<float> sort_even_simd(std::vector<float> l) {\n    size_t n = l.size();\n    std::vector<float> even_elements;\n\n    // Extract even-indexed elements\n    for (size_t i = 0; i < n; i += 2) {\n        even_elements.push_back(l[i]);\n    }\n\n    // Sort the even-indexed elements\n    std::sort(even_elements.begin(), even_elements.end());\n\n    // Interleave sorted even elements back into the vector\n    size_t even_idx = 0;\n    float32x4_t sorted_vec, original_vec, result_vec;\n    size_t i = 0;\n\n    for (; i <= n - 8; i += 8) {\n        // Load 4 even and 4 odd elements\n        float32x4_t even = vld1q_f32(&even_elements[even_idx]);\n        float32x4_t odd = vld1q_f32(&l[i + 1]);\n\n        // Interleave even and odd elements\n        float32x2_t even_low = vget_low_f32(even);\n        float32x2_t even_high = vget_high_f32(even);\n        float32x2_t odd_low = vget_low_f32(odd);\n        float32x2_t odd_high = vget_high_f32(odd);\n\n        float32x2_t res0 = vzip_f32(even_low, odd_low);\n        float32x2_t res1 = vzip_f32(even_high, odd_high);\n\n        float32x4_t interleaved = vcombine_f32(res0, res1);\n\n        // Store the result\n        vst1q_f32(&l[i], interleaved);\n\n        even_idx += 4;\n    }\n\n    // Handle remaining elements\n    for (; i < n; i += 2) {\n        if (i < n) l[i] = even_elements[even_idx++];\n    }\n\n    return l;\n}\n```"}
{"task_id": "SimdBench_81_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<float> sort_even_simd(std::vector<float> l) {\n    size_t n = l.size();\n    std::vector<float> result(n);\n\n    if (n == 0) return result;\n\n    // Extract even indices elements\n    std::vector<float> evens;\n    for (size_t i = 0; i < n; i += 2) {\n        evens.push_back(l[i]);\n    }\n\n    // Sort the even indices elements\n    std::sort(evens.begin(), evens.end());\n\n    // Interleave sorted evens with original odds using NEON\n    size_t num_simd_ops = n / 8;\n    size_t remainder = n % 8;\n\n    size_t even_idx = 0;\n    size_t odd_idx = 1;\n\n    float32x4_t *result_ptr = reinterpret_cast<float32x4_t *>(result.data());\n    const float *even_ptr = evens.data();\n    const float *l_ptr = l.data();\n\n    for (size_t i = 0; i < num_simd_ops; ++i) {\n        // Load 4 even elements\n        float32x4_t even_vec = vld1q_f32(even_ptr + even_idx);\n        // Load 4 odd elements\n        float32x4_t odd_vec = vld1q_f32(l_ptr + odd_idx);\n\n        // Store interleaved results\n        vst1q_f32(reinterpret_cast<float *>(result_ptr + i), even_vec);\n        vst1q_f32(reinterpret_cast<float *>(result_ptr + i) + 4, odd_vec);\n\n        even_idx += 4;\n        odd_idx += 4;\n    }\n\n    // Handle remaining elements\n    for (size_t i = num_simd_ops * 8; i < n; ++i) {\n        if (i % 2 == 0) {\n            result[i] = evens[even_idx++];\n        } else {\n            result[i] = l[i];\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_81_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<float> sort_even_simd(std::vector<float> l){\n    size_t n = l.size();\n    std::vector<float> sorted_l = l;\n\n    if (n == 0) return sorted_l;\n\n    // Calculate number of full 128-bit blocks\n    size_t num_blocks = n / 4;\n    size_t remainder = n % 4;\n\n    float32x4_t *even_ptr = (float32x4_t *)aligned_alloc(16, num_blocks * sizeof(float32x4_t));\n    for (size_t i = 0; i < num_blocks; ++i) {\n        even_ptr[i] = vld1q_f32(&l.data()[i * 4]);\n    }\n\n    // Extract even indices using SIMD\n    for (size_t i = 0; i < num_blocks; ++i) {\n        float32x4_t vec = even_ptr[i];\n        float32x2_t even_low = vget_low_f32(vec);\n        float32x2_t even_high = vget_high_f32(vec);\n\n        float32x2_t even_vals = vdup_n_f32(0.0f);\n        even_vals = vsetq_lane_f32(vget_lane_f32(even_low, 0), even_vals, 0);\n        even_vals = vsetq_lane_f32(vget_lane_f32(even_high, 0), even_vals, 1);\n\n        even_ptr[i] = vmovn_high_f32(vmovn_f32(even_vals), vmovn_f32(even_vals));\n    }\n\n    // Collect even indices into a vector\n    std::vector<float> even_indices;\n    for (size_t i = 0; i < num_blocks; ++i) {\n        float32x4_t vec = even_ptr[i];\n        float32x2_t even_low = vget_low_f32(vec);\n        float32x2_t even_high = vget_high_f32(vec);\n\n        even_indices.push_back(vget_lane_f32(even_low, 0));\n        even_indices.push_back(vget_lane_f32(even_high, 0));\n    }\n\n    // Handle remainder elements\n    for (size_t i = num_blocks * 4; i < n; ++i) {\n        if (i % 2 == 0) even_indices.push_back(l[i]);\n    }\n\n    // Sort the even indices\n    std::sort(even_indices.begin(), even_indices.end());\n\n    // Write back sorted even indices to the result vector\n    size_t even_idx = 0;\n    for (size_t i = 0; i < n; ++i) {\n        if (i % 2 == 0) {\n            sorted_l[i] = even_indices[even_idx++];\n        }\n    }\n\n    free(even_ptr);\n    return sorted_l;\n}\n```"}
{"task_id": "SimdBench_82_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nbool triples_sum_to_zero_simd(std::vector<int> l){\n    int n = l.size();\n    if(n < 3) return false;\n\n    // Convert vector to NEON compatible array\n    int32_t *arr = l.data();\n\n    for(int i = 0; i < n - 2; ++i){\n        int32x4_t v_i = vdupq_n_s32(arr[i]);\n        for(int j = i + 1; j < n - 1; ++j){\n            int32x4_t v_j = vdupq_n_s32(arr[j]);\n            int32x4_t vsum = vaddq_s32(v_i, v_j);\n\n            // Load elements from j+1 to end in chunks of 4\n            for(int k = j + 1; k <= n - 4; k += 4){\n                int32x4_t v_k = vld1q_s32(arr + k);\n                int32x4_t vtotal = vaddq_s32(vsum, v_k);\n                int32x4_t vzero = vdupq_n_s32(0);\n                uint32x4_t vcmp = vceqq_s32(vtotal, vzero);\n                if(vmaxvq_u32(vcmp) != 0){\n                    return true;\n                }\n            }\n\n            // Handle remaining elements that don't fit into a full SIMD register\n            for(int k = n - (n % 4); k < n; ++k){\n                if(arr[i] + arr[j] + arr[k] == 0){\n                    return true;\n                }\n            }\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_82_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nbool triples_sum_to_zero_simd(std::vector<int> l){\n    int n = l.size();\n    if(n < 3) return false;\n\n    // Convert vector to Neon compatible array\n    int *arr = l.data();\n\n    for(int i=0; i < n-2; ++i){\n        int a = arr[i];\n        int32x4_t va = vdupq_n_s32(a);\n\n        for(int j=i+1; j < n-1; ++j){\n            int b = arr[j];\n            int32x4_t vb = vdupq_n_s32(b);\n\n            for(int k=j+1; k <= n-4; k+=4){\n                int32x4_t vc = vld1q_s32(&arr[k]);\n                int32x4_t sum = vaddq_s32(vaddq_s32(va, vb), vc);\n                int32x4_t zero = vdupq_n_s32(0);\n                uint32x4_t mask = vceqq_s32(sum, zero);\n                if(vmaxvq_u32(mask) != 0){\n                    return true;\n                }\n            }\n\n            // Handle remaining elements that didn't fit in the SIMD vector\n            for(int k = (n - (n % 4)); k < n; ++k){\n                if(a + b + arr[k] == 0){\n                    return true;\n                }\n            }\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_82_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nbool triples_sum_to_zero_simd(std::vector<int> l) {\n    int n = l.size();\n    if (n < 3) return false;\n\n    // Convert vector to Neon compatible array\n    int *data = l.data();\n\n    for (int i = 0; i < n - 2; ++i) {\n        int a = data[i];\n        int32x4_t v_a = vdupq_n_s32(a);\n\n        for (int j = i + 1; j < n - 1; ++j) {\n            int b = data[j];\n            int32x4_t v_b = vdupq_n_s32(b);\n\n            int32x4_t v_ab = vaddq_s32(v_a, v_b);\n\n            int k_start = j + 1;\n            for (int k = k_start; k <= n - 4; k += 4) {\n                int32x4_t v_c = vld1q_s32(data + k);\n                int32x4_t v_sum = vaddq_s32(v_ab, v_c);\n\n                uint32x4_t v_cmp = vcgeq_s32(v_sum, vdupq_n_s32(0));\n                uint32x4_t v_zero = vceqq_s32(v_sum, vdupq_n_s32(0));\n\n                uint32x4_t v_result = vandq_u32(v_cmp, v_zero);\n                if (vmaxvq_u32(v_result)) {\n                    return true;\n                }\n            }\n\n            // Handle remaining elements that don't fit in the SIMD register\n            for (int k = n - (n % 4); k < n; ++k) {\n                if (a + b + data[k] == 0) {\n                    return true;\n                }\n            }\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_82_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nbool triples_sum_to_zero_simd(std::vector<int> l){\n    int n = l.size();\n    if(n < 3) return false;\n\n    // Convert vector to Neon compatible array\n    int *arr = l.data();\n\n    for(int i=0; i < n-2; ++i){\n        int a = arr[i];\n        int32x4_t v_a = vdupq_n_s32(a);\n\n        for(int j=i+1; j < n-1; ++j){\n            int b = arr[j];\n            int32x4_t v_b = vdupq_n_s32(b);\n\n            for(int k=j+1; k <= n-4; k+=4){\n                int32x4_t v_c = vld1q_s32(arr+k);\n                int32x4_t v_sum = vaddq_s32(v_a, v_b);\n                v_sum = vaddq_s32(v_sum, v_c);\n\n                int32x4_t v_zero = vdupq_n_s32(0);\n                uint32x4_t v_cmp = vcgeq_s32(v_sum, v_zero);\n                uint32x4_t v_inv_cmp = vmovq_n_u32(0xFFFFFFFF);\n                v_inv_cmp = vandq_u32(v_inv_cmp, vcmp);\n                \n                if (vminv_u32(v_inv_cmp) == 0xFFFFFFFF) {\n                    return true;\n                }\n            }\n\n            // Handle remaining elements that didn't fit in the SIMD register\n            for(int k = (n - (n % 4)); k < n; ++k){\n                if(a + b + arr[k] == 0){\n                    return true;\n                }\n            }\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_82_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nbool triples_sum_to_zero_simd(std::vector<int> l){\n    int n = l.size();\n    if (n < 3) return false;\n\n    // Convert vector to Neon-friendly array\n    int *data = l.data();\n\n    for(int i = 0; i < n - 2; ++i){\n        int a = data[i];\n        int32x4_t va = vdupq_n_s32(a);\n\n        for(int j = i + 1; j < n - 1; ++j){\n            int b = data[j];\n            int32x4_t vb = vdupq_n_s32(b);\n\n            for(int k = j + 1; k <= n - 4; k += 4){\n                int32x4_t vc = vld1q_s32(data + k);\n                int32x4_t sum = vaddq_s32(va, vb);\n                sum = vaddq_s32(sum, vc);\n                uint32x4_t mask = vceqq_s32(sum, vdupq_n_s32(0));\n                if(vmaxvq_u32(mask) != 0){\n                    return true;\n                }\n            }\n\n            // Handle remaining elements that didn't fit in the SIMD vector\n            for(int k = n - (n % 4); k < n; ++k){\n                if(a + b + data[k] == 0){\n                    return true;\n                }\n            }\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_83_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int> incr_list_simd(std::vector<int> l){\n    size_t size = l.size();\n    std::vector<int> result(size);\n    \n    int32x4_t one = vdupq_n_s32(1);\n    \n    for (size_t i = 0; i < size; i += 4) {\n        int32x4_t vec = vld1q_s32(&l[i]);\n        int32x4_t res = vaddq_s32(vec, one);\n        vst1q_s32(&result[i], res);\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_83_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int> incr_list_simd(std::vector<int> l){\n    size_t size = l.size();\n    std::vector<int> result(size);\n    \n    int32x4_t one = vdupq_n_s32(1);\n    \n    for(size_t i = 0; i < size; i += 4){\n        int32x4_t vec = vld1q_s32(&l[i]);\n        int32x4_t res = vaddq_s32(vec, one);\n        vst1q_s32(&result[i], res);\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_83_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int> incr_list_simd(std::vector<int> l){\n    size_t n = l.size();\n    std::vector<int> result(n);\n    \n    int32x4_t one = vdupq_n_s32(1);\n    \n    for(size_t i = 0; i < n; i += 4){\n        int32x4_t vec = vld1q_s32(&l[i]);\n        int32x4_t res = vaddq_s32(vec, one);\n        vst1q_s32(&result[i], res);\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_83_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int> incr_list_simd(std::vector<int> l){\n    size_t n = l.size();\n    std::vector<int> result(n);\n    \n    int32x4_t one = vdupq_n_s32(1);\n    \n    for (size_t i = 0; i < n; i += 4) {\n        int32x4_t vec = vld1q_s32(&l[i]);\n        int32x4_t res = vaddq_s32(vec, one);\n        vst1q_s32(&result[i], res);\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_83_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int> incr_list_simd(std::vector<int> l){\n    size_t n = l.size();\n    std::vector<int> result(n);\n    \n    int32x4_t one = vdupq_n_s32(1);\n    \n    for (size_t i = 0; i < n; i += 4) {\n        int32x4_t vec = vld1q_s32(&l[i]);\n        int32x4_t res = vaddq_s32(vec, one);\n        vst1q_s32(&result[i], res);\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_84_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nbool pairs_sum_to_zero_simd(std::vector<int> l){\n    if (l.size() < 2) return false;\n\n    int n = static_cast<int>(l.size());\n    int* data = l.data();\n\n    // Load the first vector\n    int32x4_t v0 = vld1q_s32(data);\n\n    for(int i = 1; i < n / 4; ++i){\n        int32x4_t vi = vld1q_s32(data + i * 4);\n        int32x4_t neg_vi = vmulq_n_s32(vi, -1);\n\n        // Compare each element with v0\n        uint32x4_t eq1 = vceqq_s32(v0, neg_vi);\n\n        // Check if any comparison is true\n        uint32x4_t any_true = vorrq_u32(eq1, vmovq_n_u32(0));\n        if (vget_lane_u32(any_true, 0) || vget_lane_u32(any_true, 1) || \n            vget_lane_u32(any_true, 2) || vget_lane_u32(any_true, 3)) {\n            return true;\n        }\n    }\n\n    // Check remaining elements\n    for(int i = (n / 4) * 4; i < n; ++i){\n        for(int j = 0; j < i; ++j){\n            if(data[i] + data[j] == 0){\n                return true;\n            }\n        }\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_84_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nbool pairs_sum_to_zero_simd(std::vector<int> l){\n    int n = l.size();\n    if (n < 2) return false;\n\n    // Load data into Neon registers\n    for(int i = 0; i < n - 1; ++i){\n        int32x4_t v_i =vdupq_n_s32(l[i]);\n        for(int j = i + 1; j < n; j += 4){\n            if(j + 3 < n){\n                int32x4_t v_j = vld1q_s32(&l[j]);\n                int32x4_t v_sum = vaddq_s32(v_i, v_j);\n                int32x4_t v_zero = vmovq_n_s32(0);\n                uint32x4_t v_cmp = vceqq_s32(v_sum, v_zero);\n                uint32x4_t v_any_true = vorrq_u32(vget_low_u32(v_cmp), vget_high_u32(v_cmp));\n                if(vbitest((uint32_t*)&v_any_true, 0)) return true;\n            }\n            else{\n                for(int k = j; k < n; ++k){\n                    if(l[i] + l[k] == 0) return true;\n                }\n            }\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_84_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nbool pairs_sum_to_zero_simd(std::vector<int> l){\n    int n = l.size();\n    if (n < 2) return false;\n\n    // Load the data into SIMD registers\n    for (size_t i = 0; i < n - 1; ++i) {\n        int32x4_t v_i = vdupq_n_s32(l[i]);\n        for (size_t j = i + 1; j < n; j += 4) {\n            int32x4_t v_j;\n            if (j + 3 < n) {\n                v_j = vld1q_s32(&l[j]);\n            } else {\n                int temp[4] = {l[j], j+1<n ? l[j+1] : 0, j+2<n ? l[j+2] : 0, j+3<n ? l[j+3] : 0};\n                v_j = vld1q_s32(temp);\n            }\n\n            int32x4_t v_sum = vaddq_s32(v_i, v_j);\n            int32x4_t v_zero = vdupq_n_s32(0);\n\n            uint32x4_t v_cmp = vceqq_s32(v_sum, v_zero);\n            uint32x4_t v_any = vmovemaskq_u32(vreinterpretq_u32_s32(v_cmp));\n\n            if (vget_lane_u32(v_any, 0) != 0) {\n                return true;\n            }\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_84_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nbool pairs_sum_to_zero_simd(std::vector<int> l){\n    int n = l.size();\n    if (n < 2) return false;\n\n    // Load data into Neon registers\n    for(int i = 0; i < n - 1; ++i){\n        int32x4_t v_i = vdupq_n_s32(l[i]);\n        for(int j = i + 1; j < n; j += 4){\n            if(j + 3 < n){\n                int32x4_t v_j = vld1q_s32(&l[j]);\n                int32x4_t v_sum = vaddq_s32(v_i, v_j);\n                int32x4_t v_zero = vdupq_n_s32(0);\n                uint32x4_t v_cmp = vceqq_s32(v_sum, v_zero);\n                if(vmaxvq_u32(v_cmp) != 0){\n                    return true;\n                }\n            }\n            else{\n                for(int k = j; k < n; ++k){\n                    if(l[i] + l[k] == 0){\n                        return true;\n                    }\n                }\n            }\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_84_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nbool pairs_sum_to_zero_simd(std::vector<int> l){\n    int n = l.size();\n    if (n < 2) return false;\n\n    // Load data into Neon registers\n    for (int i = 0; i < n - 1; ++i) {\n        int32x4_t v_i = vdupq_n_s32(l[i]);\n        for (int j = i + 1; j < n; j += 4) {\n            if (j + 3 < n) {\n                int32x4_t v_j = vld1q_s32(&l[j]);\n                int32x4_t v_sum = vaddq_s32(v_i, v_j);\n                uint32x4_t v_cmp = vceqq_s32(v_sum, vdupq_n_s32(0));\n                uint32x4_t v_result = vmovemaskq_u32(vreinterpretq_u32_s32(v_cmp));\n                if (vget_lane_u32(v_result, 0) || vget_lane_u32(v_result, 1) ||\n                    vget_lane_u32(v_result, 2) || vget_lane_u32(v_result, 3)) {\n                    return true;\n                }\n            } else {\n                for (int k = j; k < n; ++k) {\n                    if (l[i] + l[k] == 0) return true;\n                }\n            }\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_85_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nstd::string change_base_simd(int64_t x, int8_t base){\n    if (base < 2 || base > 9) return \"\";\n\n    uint8x16_t digits = vdupq_n_u8('0');\n    std::string result;\n\n    bool is_negative = false;\n    if (x < 0) {\n        is_negative = true;\n        x = -x;\n    }\n\n    int64_t quotient = x;\n    uint8x16_t temp_chars;\n    while (quotient > 0) {\n        uint8x16_t digit = vaddq_u8(vdupq_n_u8('0'), vdupq_n_u8(quotient % base));\n        temp_chars = vsetq_lane_u8(vgetq_lane_u8(digit, 0), temp_chars, 0);\n        quotient /= base;\n    }\n\n    for (int i = 0; i < 16; ++i) {\n        uint8_t c = vgetq_lane_u8(temp_chars, i);\n        if (c != '0' || !result.empty()) {\n            result += static_cast<char>(c);\n        }\n    }\n\n    if (is_negative) result += '-';\n\n    std::reverse(result.begin(), result.end());\n    return result;\n}\n```"}
{"task_id": "SimdBench_85_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nstd::string change_base_simd(int64_t x, int8_t base){\n    if (base < 2 || base > 9) return \"\";\n\n    uint8x16_t digits = vdupq_n_u8('0');\n    std::string result;\n\n    bool is_negative = false;\n    if (x < 0) {\n        is_negative = true;\n        x = -x;\n    }\n\n    int64_t quotient = x;\n    uint8x16_t temp_digits;\n    size_t count = 0;\n\n    while (quotient > 0) {\n        uint8x16_t digit = vaddq_u8(vdupq_n_u8('0'), vdupq_n_u8(static_cast<uint8_t>(quotient % base)));\n        temp_digits = vsetq_lane_u8(vgetq_lane_u8(digit, 0), temp_digits, count++);\n        quotient /= base;\n    }\n\n    if (is_negative) {\n        result += '-';\n    }\n\n    for (size_t i = count; i > 0; --i) {\n        result += static_cast<char>(vgetq_lane_u8(temp_digits, i - 1));\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_85_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nstd::string change_base_simd(int64_t x, int8_t base){\n    if (base < 2 || base > 9) return \"\";\n\n    uint8x16_t digits = vdupq_n_u8('0');\n    std::string result;\n\n    bool is_negative = false;\n    if (x < 0) {\n        is_negative = true;\n        x = -x;\n    }\n\n    int64_t quotient = x;\n    uint8x16_t temp_digits;\n    while (quotient > 0) {\n        uint8x16_t q = vdupq_n_u8(quotient & 0xFF);\n        uint8x16_t b = vdupq_n_u8(base);\n\n        temp_digits = vsubq_u8(q, vmulq_u8(vshrq_n_u8(q, 3), vshlq_n_u8(b, 3)));\n\n        result.insert(result.begin(), static_cast<char>(vgetq_lane_u8(temp_digits, 0)) + '0');\n        quotient /= base;\n    }\n\n    if (is_negative) {\n        result.insert(result.begin(), '-');\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_85_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nstd::string change_base_simd(int64_t x, int8_t base){\n    if (base < 2 || base > 9) return \"\";\n\n    uint8x16_t digits = vdupq_n_u8('0');\n    std::string result;\n\n    bool is_negative = false;\n    if (x < 0) {\n        is_negative = true;\n        x = -x;\n    }\n\n    int64x1_t vx = {x};\n    int64x1_t vbase = {base};\n    int64x1_t zero = {0};\n\n    while (true) {\n        int64x1_t remainder = vmovn_s64(vshrn_n_s64(vx, 61)); // Extract remainder\n        vx = vsub_s64(vx, vmul_s64(vbase, remainder)); // Update quotient\n        uint8x8_t digit_char = vadd_u8(vreinterpret_u8_s64(remainder), vget_low_u8(digits));\n        result += static_cast<char>(vget_lane_u8(digit_char, 0));\n\n        if (vx == zero) break;\n    }\n\n    if (is_negative) result += '-';\n\n    std::reverse(result.begin(), result.end());\n    return result;\n}\n```"}
{"task_id": "SimdBench_85_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nstd::string change_base_simd(int64_t x, int8_t base){\n    if (base < 2 || base > 9) return \"\";\n\n    uint8x16_t digits = vdupq_n_u8('0');\n    std::string result;\n\n    bool is_negative = false;\n    if (x < 0) {\n        is_negative = true;\n        x = -x;\n    }\n\n    int64x2_t vx = {x, 0};\n    int64x2_t vbase = vdupq_n_s64(base);\n\n    while (true) {\n        int64x2_t remainder = vshlq_s64(vx, vdupq_n_s64(-1));\n        vx = vshrq_n_s64(vx, 1);\n        uint8x8_t rem_digits = vreinterpret_u8_s8(vmovn_s16(vreinterpretq_s16_s64(remainder)));\n        rem_digits = vadd_u8(rem_digits, vget_low_u8(digits));\n\n        char digit = (char)vget_lane_u8(rem_digits, 0);\n        if (digit == '0' && vx[0] == 0) break;\n        result.insert(result.begin(), digit);\n    }\n\n    if (is_negative) {\n        result.insert(result.begin(), '-');\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_86_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nbool is_palindrome_simd(std::string text){\n    size_t len = text.length();\n    if (len <= 1) return true;\n\n    const uint8x16_t vmask = vdupq_n_u8(0xFF);\n    size_t half = len / 2;\n    size_t simd_len = len / 16 * 16;\n\n    for (size_t i = 0; i < simd_len; i += 16) {\n        uint8x16_t vleft = vld1q_u8(reinterpret_cast<const uint8_t*>(&text[i]));\n        uint8x16_t vright = vld1q_u8(reinterpret_cast<const uint8_t*>(&text[len - i - 1]));\n\n        uint8x16_t vcmp = vceqq_u8(vleft, vright);\n        uint8x16_t vand = vandq_u8(vcmp, vmask);\n\n        if (vgetq_lane_u8(vand, 0) != 0xFF || \n            vgetq_lane_u8(vand, 1) != 0xFF || \n            vgetq_lane_u8(vand, 2) != 0xFF || \n            vgetq_lane_u8(vand, 3) != 0xFF || \n            vgetq_lane_u8(vand, 4) != 0xFF || \n            vgetq_lane_u8(vand, 5) != 0xFF || \n            vgetq_lane_u8(vand, 6) != 0xFF || \n            vgetq_lane_u8(vand, 7) != 0xFF || \n            vgetq_lane_u8(vand, 8) != 0xFF || \n            vgetq_lane_u8(vand, 9) != 0xFF || \n            vgetq_lane_u8(vand, 10) != 0xFF || \n            vgetq_lane_u8(vand, 11) != 0xFF || \n            vgetq_lane_u8(vand, 12) != 0xFF || \n            vgetq_lane_u8(vand, 13) != 0xFF || \n            vgetq_lane_u8(vand, 14) != 0xFF || \n            vgetq_lane_u8(vand, 15) != 0xFF) {\n            return false;\n        }\n    }\n\n    for (size_t i = simd_len; i < half; ++i) {\n        if (text[i] != text[len - i - 1]) return false;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_86_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nbool is_palindrome_simd(std::string text){\n    size_t n = text.size();\n    if (n == 0) return true;\n\n    size_t i = 0;\n    size_t j = n - 1;\n\n    const uint8x16_t vmask = vdupq_n_u8(0xFF);\n\n    while(j - i + 1 >= 16){\n        uint8x16_t vleft = vld1q_u8(reinterpret_cast<const uint8_t*>(&text[i]));\n        uint8x16_t vright = vld1q_u8(reinterpret_cast<const uint8_t*>(&text[j]));\n\n        uint8x16_t vrevright = vrev16q_u8(vright);\n        vrevright = vreinterpretq_u8_u32(vrevq_u32(vreinterpretq_u32_u8(vrevright)));\n\n        uint8x16_t vcmp = vceqq_u8(vleft, vrevright);\n\n        uint16x8_t vsum = vcntq_u8(vcmp);\n        uint32x4_t vsum_high = vpaddlq_u16(vsum);\n        uint64x2_t vsum_final = vpaddlq_u32(vsum_high);\n\n        if (vgetq_lane_u64(vsum_final, 0) + vgetq_lane_u64(vsum_final, 1) != 16){\n            return false;\n        }\n\n        i += 16;\n        j -= 16;\n    }\n\n    while(i <= j){\n        if(text[i] != text[j]){\n            return false;\n        }\n        ++i;\n        --j;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_86_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nbool is_palindrome_simd(std::string text) {\n    size_t len = text.length();\n    if (len == 0) return true;\n\n    const uint8_t* data = reinterpret_cast<const uint8_t*>(text.c_str());\n    size_t half_len = len / 2;\n    size_t vec_len = len / 16 * 16;\n\n    for (size_t i = 0; i < vec_len; i += 16) {\n        uint8x16_t left = vld1q_u8(data + i);\n        uint8x16_t right = vld1q_u8(data + len - i - 16);\n\n        uint8x16_t cmp = vceqq_u8(left, right);\n        uint8x16_t ones = vdupq_n_u8(0xFF);\n\n        if (vcmpneq_u8(cmp, ones)) {\n            return false;\n        }\n    }\n\n    for (size_t i = vec_len; i < half_len; ++i) {\n        if (data[i] != data[len - i - 1]) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_86_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nbool is_palindrome_simd(std::string text) {\n    size_t n = text.size();\n    if (n == 0) return true;\n\n    const uint8x16_t zero = vdupq_n_u8(0);\n    const uint8x16_t mask = vdupq_n_u8(0xFF);\n\n    size_t i = 0;\n    size_t j = n - 1;\n\n    while (i + 15 < j) {\n        uint8x16_t left = vld1q_u8(reinterpret_cast<const uint8_t*>(&text[i]));\n        uint8x16_t right = vld1q_u8(reinterpret_cast<const uint8_t*>(&text[j]));\n\n        uint8x16_t cmp = vceqq_u8(left, right);\n\n        uint16x8_t res_low = vmovl_u8(vget_low_u8(cmp));\n        uint16x8_t res_high = vmovl_u8(vget_high_u8(cmp));\n\n        uint32x4_t res_low_32 = vmovl_u16(vget_low_u16(res_low));\n        uint32x4_t res_high_32 = vmovl_u16(vget_high_u16(res_low));\n\n        uint64x2_t res_low_64 = vmovl_u32(vget_low_u32(res_low_32));\n        uint64x2_t res_high_64 = vmovl_u32(vget_high_u32(res_high_32));\n\n        uint64x2_t combined = vorrq_u64(res_low_64, res_high_64);\n\n        if (vaddvq_u64(combined) != 0xFFFFFFFFFFFFFFFFULL) {\n            return false;\n        }\n\n        i += 16;\n        j -= 16;\n    }\n\n    while (i < j) {\n        if (text[i] != text[j]) return false;\n        ++i;\n        --j;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_86_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nbool is_palindrome_simd(std::string text) {\n    size_t n = text.size();\n    if (n == 0) return true;\n\n    const uint8x16_t zero = vdupq_n_u8(0);\n    const uint8x16_t mask = vdupq_n_u8(0xFF);\n\n    size_t limit = n / 2;\n    size_t i = 0;\n\n    for (; i + 16 <= limit; i += 16) {\n        uint8x16_t left = vld1q_u8(reinterpret_cast<const uint8_t*>(&text[i]));\n        uint8x16_t right = vld1q_u8(reinterpret_cast<const uint8_t*>(&text[n - i - 16]));\n\n        uint8x16_t diff = vceqq_u8(left, right);\n        uint16x8_t diff_lo = vreinterpretq_u16_u8(diff);\n        uint16x8_t diff_hi = vreinterpretq_u16_u8(vshrq_n_u8(diff, 8));\n\n        uint32x4_t diff_sum_lo = vpaddlq_u16(diff_lo);\n        uint32x4_t diff_sum_hi = vpaddlq_u16(diff_hi);\n\n        uint64x2_t diff_total = vpaddlq_u32(diff_sum_lo);\n        uint64x2_t diff_total_hi = vpaddlq_u32(diff_sum_hi);\n\n        uint64x2_t combined = vaddq_u64(diff_total, diff_total_hi);\n\n        if (vaddvq_u64(combined) != 0x100) {\n            return false;\n        }\n    }\n\n    for (; i < limit; ++i) {\n        if (text[i] != text[n - i - 1]) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_87_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nstd::string decode_shift_simd(std::string s) {\n    size_t length = s.length();\n    size_t vec_length = length / 16 * 16;\n    std::string out(length, '\\0');\n\n    uint8x16_t v_shift = vdupq_n_u8(5);\n    uint8x16_t v_a = vdupq_n_u8('a');\n    uint8x16_t v_z = vdupq_n_u8('z');\n    uint8x16_t v_26 = vdupq_n_u8(26);\n\n    for (size_t i = 0; i < vec_length; i += 16) {\n        uint8x16_t v_in = vld1q_u8(reinterpret_cast<const uint8_t*>(&s[i]));\n        uint8x16_t v_sub = vsubq_u8(v_in, v_shift);\n        uint8x16_t v_cmp = vcgeq_u8(v_sub, v_a);\n        uint8x16_t v_wrap = vaddq_u8(vsubq_u8(v_sub, v_26), vcmpgtq_u8(v_sub, v_z));\n        uint8x16_t v_out = vbslq_u8(v_cmp, v_sub, v_wrap);\n        vst1q_u8(reinterpret_cast<uint8_t*>(&out[i]), v_out);\n    }\n\n    for (size_t i = vec_length; i < length; ++i) {\n        int w = ((int)s[i] - 5 - (int)'a' + 26) % 26 + (int)'a';\n        out[i] = static_cast<char>(w);\n    }\n\n    return out;\n}\n```"}
{"task_id": "SimdBench_87_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nstd::string decode_shift_simd(std::string s){\n    size_t length = s.length();\n    size_t vec_length = length / 16 * 16;\n    std::string out(length, '\\0');\n    \n    uint8x16_t v_shift = vmovq_n_u8(5);\n    uint8x16_t v_a = vmovq_n_u8('a');\n    uint8x16_t v_z = vmovq_n_u8('z');\n    uint8x16_t v_26 = vmovq_n_u8(26);\n\n    for (size_t i = 0; i < vec_length; i += 16) {\n        uint8x16_t v_in = vld1q_u8(reinterpret_cast<const uint8_t*>(&s[i]));\n        uint8x16_t v_sub = vsubq_u8(v_in, v_shift);\n        uint8x16_t v_cmp = vcgeq_u8(v_sub, v_a);\n        uint8x16_t v adjusted = vaddq_u8(v_sub, vandq_u8(vcmpgeq_u8(v_sub, v_z), v_26));\n        vst1q_u8(reinterpret_cast<uint8_t*>(&out[i]), v_adjusted);\n    }\n\n    for (size_t i = vec_length; i < length; ++i) {\n        int w = ((int)s[i] - 5 - (int)'a' + 26) % 26 + (int)'a';\n        out[i] = static_cast<char>(w);\n    }\n\n    return out;\n}\n```"}
{"task_id": "SimdBench_87_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nstd::string decode_shift_simd(std::string s) {\n    const int shift = -5;\n    const int mod_base = 26;\n    const int base_a = (int)'a';\n    \n    std::string out;\n    out.reserve(s.size());\n\n    int i = 0;\n    for (; i + 15 < s.size(); i += 16) {\n        uint8x16_t vec = vld1q_u8(reinterpret_cast<const uint8_t*>(&s[i]));\n        uint8x16_t sub = vsubq_u8(vec, vdupq_n_u8(5));\n        uint8x16_t cmp = vcgeq_u8(sub, vdupq_n_u8('a'));\n        uint8x16_t adj = vaddq_u8(vandq_u8(cmp, sub), vandq_u8(vmvnq_u8(cmp), vaddq_u8(sub, vdupq_n_u8(26))));\n        vst1q_u8(reinterpret_cast<uint8_t*>(&out[i]), adj);\n    }\n\n    for (; i < s.size(); ++i) {\n        int w = ((int)s[i] - 5 - (int)'a' + 26) % 26 + (int)'a';\n        out += (char)w;\n    }\n\n    return out;\n}\n```"}
{"task_id": "SimdBench_87_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nstd::string decode_shift_simd(std::string s) {\n    const int vec_size = 16; // Size of SIMD vector in bytes\n    std::string out;\n    out.reserve(s.length());\n\n    const uint8_t shift = 5;\n    const uint8_t mod_base = 26;\n\n    size_t i = 0;\n    for (; i + vec_size <= s.length(); i += vec_size) {\n        uint8x16_t vec = vld1q_u8(reinterpret_cast<const uint8_t*>(&s[i]));\n        uint8x16_t a_val = vdupq_n_u8('a');\n        uint8x16_t shifted = vsubq_u8(vec, vdupq_n_u8(shift));\n        uint8x16_t sub_a = vsubq_u8(shifted, a_val);\n        uint8x16_t modded = vaddq_u8(vandq_u8(sub_a, vdupq_n_u8(mod_base - 1)), a_val);\n        vst1q_u8(reinterpret_cast<uint8_t*>(&out[i]), modded);\n    }\n\n    // Handle remaining characters\n    for (; i < s.length(); ++i) {\n        int w = ((int)s[i] - 5 - (int)'a') % 26 + (int)'a';\n        if (w < 'a') w += 26;\n        out += static_cast<char>(w);\n    }\n\n    return out;\n}\n```"}
{"task_id": "SimdBench_87_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nstd::string decode_shift_simd(std::string s){\n    size_t length = s.length();\n    size_t aligned_length = length - (length % 16);\n    std::string out;\n    out.reserve(length);\n\n    const uint8x16_t shift = vdupq_n_u8(21); // 26 - 5 = 21 for reverse shift\n    const uint8x16_t a_val = vdupq_n_u8('a');\n    const uint8x16_t z_val = vdupq_n_u8('z');\n\n    for (size_t i = 0; i < aligned_length; i += 16) {\n        uint8x16_t vec = vld1q_u8(reinterpret_cast<const uint8_t*>(&s[i]));\n        uint8x16_t sub = vsubq_u8(vec, a_val);\n        uint8x16_t mod = vaddq_u8(sub, shift);\n        uint8x16_t wrap = vandq_u8(vreinterpretq_u8_u32(vshrq_n_u32(vreinterpretq_u32_u8(mod), 31)), vsubq_u8(z_val, a_val));\n        uint8x16_t result = vaddq_u8(a_val, vsubq_u8(mod, wrap));\n        uint8_t decoded[16];\n        vst1q_u8(decoded, result);\n        out.append(reinterpret_cast<char*>(decoded), 16);\n    }\n\n    for (size_t i = aligned_length; i < length; ++i) {\n        int w = ((int)s[i] - 5 - (int)'a' + 26) % 26 + (int)'a';\n        out += static_cast<char>(w);\n    }\n\n    return out;\n}\n```"}
{"task_id": "SimdBench_88_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <cstdint>\n\nbool below_threshold_simd(const std::vector<int>& l, int t) {\n    if (l.empty()) return true;\n\n    int32x4_t vt = vdupq_n_s32(t);\n    size_t i = 0;\n    bool result = true;\n\n    for (; i <= l.size() - 4; i += 4) {\n        int32x4_t vl = vld1q_s32(reinterpret_cast<const int32_t*>(&l[i]));\n        uint32x4_t vcmp = vcgeq_s32(vl, vt); // Compare l >= t\n        uint32x4_t vzero = vdupq_n_u32(0);\n        if (vmaxvq_u32(vcmp) != 0) {\n            result = false;\n            break;\n        }\n    }\n\n    for (; i < l.size(); ++i) {\n        if (l[i] >= t) {\n            result = false;\n            break;\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_88_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nbool below_threshold_simd(const std::vector<int>& l, int t) {\n    if (l.empty()) return true;\n\n    int32x4_t vt = vdupq_n_s32(t);\n    bool result = true;\n\n    size_t i = 0;\n    size_t vec_size = l.size() / 4 * 4;\n\n    for (; i < vec_size; i += 4) {\n        int32x4_t vl = vld1q_s32(reinterpret_cast<const int32_t*>(&l[i]));\n        uint32x4_t cmp = vcgeq_s32(vl, vt); // Compare each element: vl >= vt\n        uint32x4_t zero = vdupq_n_u32(0);\n        if (vbitestq_u32(cmp, zero)) { // If any element is >= t\n            result = false;\n            break;\n        }\n    }\n\n    for (; i < l.size(); ++i) {\n        if (l[i] >= t) {\n            result = false;\n            break;\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_88_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <cstdint>\n\nbool below_threshold_simd(const std::vector<int>& l, int t) {\n    if (l.empty()) return true;\n\n    int32x4_t vt = vdupq_n_s32(t);\n    bool result = true;\n\n    size_t aligned_size = l.size() / 4 * 4;\n    const int32_t* data = l.data();\n\n    for (size_t i = 0; i < aligned_size; i += 4) {\n        int32x4_t vl = vld1q_s32(data + i);\n        uint32x4_t cmp = vcgeq_s32(vl, vt); // Compare if elements are >= threshold\n        uint32x4_t zero = vdupq_n_u32(0);\n        if (vmaxvq_u32(cmp) != 0) { // If any element is >= threshold\n            result = false;\n            break;\n        }\n    }\n\n    for (size_t i = aligned_size; i < l.size(); ++i) {\n        if (l[i] >= t) {\n            result = false;\n            break;\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_88_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <cstdint>\n\nbool below_threshold_simd(const std::vector<int>& l, int t) {\n    if (l.empty()) return true;\n\n    const int32x4_t threshold = vdupq_n_s32(t);\n    bool result = true;\n\n    for (size_t i = 0; i + 3 < l.size(); i += 4) {\n        int32x4_t vec = vld1q_s32(reinterpret_cast<const int32_t*>(&l[i]));\n        uint32x4_t comparison = vcgeq_s32(vec, threshold);\n        uint32x4_t zeros = vdupq_n_u32(0);\n        if (vmaxvq_u32(comparison) != 0) {\n            result = false;\n            break;\n        }\n    }\n\n    // Check remaining elements\n    for (size_t i = l.size() & ~size_t(3); i < l.size(); ++i) {\n        if (l[i] >= t) {\n            result = false;\n            break;\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_88_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nbool below_threshold_simd(const std::vector<int>& l, int t) {\n    if (l.empty()) return true;\n\n    size_t vec_size = l.size();\n    int32x4_t vt = vdupq_n_s32(t);\n    bool all_below = true;\n\n    for (size_t i = 0; i + 4 <= vec_size; i += 4) {\n        int32x4_t vl = vld1q_s32(reinterpret_cast<const int32_t*>(&l[i]));\n        uint32x4_t cmp = vcgeq_s32(vl, vt); // Compare l >= t\n        if (vaddvq_u32(cmp)) { // If any element is greater or equal\n            return false;\n        }\n    }\n\n    // Handle remaining elements\n    for (size_t i = (vec_size / 4) * 4; i < vec_size; ++i) {\n        if (l[i] >= t) return false;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_89_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nbool correct_bracketing_simd(std::string brackets){\n    int32_t balance = 0;\n    size_t n = brackets.size();\n    size_t i = 0;\n\n    // Process 16 characters at a time using SIMD\n    for (; i <= n - 16; i += 16) {\n        uint8x16_t vec = vld1q_u8(reinterpret_cast<const uint8_t*>(&brackets[i]));\n        uint8x16_t less = vmovq_n_u8('<');\n        uint8x16_t greater = vmovq_n_u8('>');\n        \n        // Compare and generate masks\n        uint8x16_t is_less = vceqq_u8(vec, less);\n        uint8x16_t is_greater = vceqq_u8(vec, greater);\n\n        // Count the number of '<' and '>'\n        int16x8_t count_less = vcntq_u8(is_less);\n        int16x8_t count_greater = vcntq_u8(is_greater);\n\n        // Sum across lanes\n        int32x4_t sum_less = vpaddlq_s16(vreinterpretq_s16_u16(count_less));\n        int32x4_t sum_greater = vpaddlq_s16(vreinterpretq_s16_u16(count_greater));\n\n        int32x2_t total_less = vpaddl_s32(vget_low_s32(sum_less));\n        int32x2_t total_greater = vpaddl_s32(vget_low_s32(sum_greater));\n\n        balance += (vget_lane_s32(total_less, 0) - vget_lane_s32(total_greater, 0));\n\n        if (balance < 0) return false;\n    }\n\n    // Process remaining characters\n    for (; i < n; ++i) {\n        if (brackets[i] == '<') {\n            balance++;\n        } else if (brackets[i] == '>') {\n            balance--;\n            if (balance < 0) return false;\n        }\n    }\n\n    return balance == 0;\n}\n```"}
{"task_id": "SimdBench_89_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nbool correct_bracketing_simd(std::string brackets){\n    int len = brackets.length();\n    if (len == 0) return true;\n\n    const uint8_t open = '<';\n    const uint8_t close = '>';\n    \n    int balance = 0;\n    int vector_balance = 0;\n\n    for(int i = 0; i < len; i += 16){\n        int chunk_size = std::min(len - i, 16);\n        uint8x16_t vec = vdupq_n_u8(0);\n        for(int j = 0; j < chunk_size; ++j){\n            vec = vsetq_lane_u8(brackets[i + j], vec, j);\n        }\n\n        uint8x16_t open_vec = vdupq_n_u8(open);\n        uint8x16_t close_vec = vdupq_n_u8(close);\n\n        uint8x16_t eq_open = vceqq_u8(vec, open_vec);\n        uint8x16_t eq_close = vceqq_u8(vec, close_vec);\n\n        int32x4_t cnt_open = vpaddlq_u16(vcntq_u8(eq_open));\n        int32x4_t cnt_close = vpaddlq_u16(vcntq_u8(eq_close));\n\n        int32x2_t sum_open = vpaddl_u16(vget_low_u16(cnt_open));\n        int32x2_t sum_close = vpaddl_u16(vget_low_u16(cnt_close));\n\n        int open_count = vget_lane_s32(sum_open, 0) + vget_lane_s32(sum_open, 1);\n        int close_count = vget_lane_s32(sum_close, 0) + vget_lane_s32(sum_close, 1);\n\n        vector_balance += open_count - close_count;\n        if(vector_balance < 0){\n            return false;\n        }\n    }\n\n    return vector_balance == 0;\n}\n```"}
{"task_id": "SimdBench_89_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nbool correct_bracketing_simd(std::string brackets){\n    int n = brackets.size();\n    if (n == 0) return true;\n\n    const uint8x16_t opening = vdupq_n_u8('<');\n    const uint8x16_t closing = vdupq_n_u8('>');\n    const uint8x16_t zero = vdupq_n_u8(0);\n\n    int balance = 0;\n    for(size_t i = 0; i < n; i += 16){\n        uint8x16_t chunk = vld1q_u8(reinterpret_cast<const uint8_t*>(&brackets[i]));\n        uint8x16_t is_open = vceqq_u8(chunk, opening);\n        uint8x16_t is_close = vceqq_u8(chunk, closing);\n\n        int16x8_t open_count = vpaddlq_u8(vreinterpretq_u8_u16(vmovl_u8(vget_low_u8(vreinterpretq_u8_u32(vreinterpretq_u32_u8(is_open))))));\n        int16x8_t close_count = vpaddlq_u8(vreinterpretq_u8_u16(vmovl_u8(vget_low_u8(vreinterpretq_u8_u32(vreinterpretq_u32_u8(is_close))))));\n\n        int sum_open = vaddvq_s16(vreinterpretq_s16_u16(open_count));\n        int sum_close = vaddvq_s16(vreinterpretq_s16_u16(close_count));\n\n        balance += sum_open - sum_close;\n        if(balance < 0) return false;\n    }\n\n    return balance == 0;\n}\n```"}
{"task_id": "SimdBench_89_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nbool correct_bracketing_simd(std::string brackets){\n    int n = brackets.size();\n    if (n == 0) return true;\n\n    const uint8_t open = '<';\n    const uint8_t close = '>';\n\n    int balance = 0;\n    int vec_size = 16; // 128-bit registers\n    uint8x16_t vopen = vdupq_n_u8(open);\n    uint8x16_t vclose = vdupq_n_u8(close);\n\n    for(int i = 0; i < n; i += vec_size){\n        int limit = i + vec_size > n ? n : i + vec_size;\n        uint8x16_t vbrackets = vld1q_u8(reinterpret_cast<const uint8_t*>(&brackets[i]));\n\n        uint8x16_t vcmp_open = vceqq_u8(vbrackets, vopen);\n        uint8x16_t vcmp_close = vceqq_u8(vbrackets, vclose);\n\n        int32x4_t vcount_open = vmovemaskq_u8(vcmp_open);\n        int32x4_t vcount_close = vmovemaskq_u8(vcmp_close);\n\n        int popen = __builtin_popcount(vcount_open);\n        int pclose = __builtin_popcount(vcount_close);\n\n        balance += (popen - pclose);\n\n        if(balance < 0){\n            return false;\n        }\n    }\n\n    return balance == 0;\n}\n```"}
{"task_id": "SimdBench_89_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nbool correct_bracketing_simd(std::string brackets){\n    int32_t balance = 0;\n    size_t n = brackets.size();\n    size_t i = 0;\n\n    // Process 16 characters at a time using SIMD\n    for (; i <= n - 16; i += 16) {\n        uint8x16_t vec = vld1q_u8(reinterpret_cast<const uint8_t*>(&brackets[i]));\n        uint8x16_t less = vmovq_n_u8('<');\n        uint8x16_t greater = vmovq_n_u8('>');\n        \n        // Compare and generate masks\n        uint8x16_t is_less = vceqq_u8(vec, less);\n        uint8x16_t is_greater = vceqq_u8(vec, greater);\n\n        // Count the number of '<' and '>'\n        int32x4_t count_less = vmovl_u8(vget_low_u8(is_less));\n        int32x4_t count_greater = vmovl_u8(vget_low_u8(is_greater));\n\n        count_less = vaddw_u8(count_less, vmovl_u8(vget_high_u8(is_less)));\n        count_greater = vaddw_u8(count_greater, vmovl_u8(vget_high_u8(is_greater)));\n\n        int32x4_t diff = vsubq_s32(count_less, count_greater);\n        int32_t min_diff = vminvq_s32(diff);\n\n        if (min_diff < 0) return false;\n\n        balance += vaddvq_s32(diff);\n    }\n\n    // Process remaining characters\n    for (; i < n; ++i) {\n        if (brackets[i] == '<') {\n            balance++;\n        } else if (brackets[i] == '>') {\n            balance--;\n            if (balance < 0) return false;\n        }\n    }\n\n    return balance == 0;\n}\n```"}
{"task_id": "SimdBench_90_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nbool correct_bracketing_simd(const std::string& brackets) {\n    int count = 0;\n    const uint8_t* data = reinterpret_cast<const uint8_t*>(brackets.data());\n    size_t length = brackets.size();\n\n    for (size_t i = 0; i < length; i += 16) {\n        uint8x16_t vec = vld1q_u8(data + i);\n        uint8x16_t open = vmovq_n_u8('(');\n        uint8x16_t close = vmovq_n_u8(')');\n        \n        uint8x16_t is_open = vceqq_u8(vec, open);\n        uint8x16_t is_close = vceqq_u8(vec, close);\n\n        int16x8_t cnt_open = vmovl_u8(vget_low_u8(is_open));\n        cnt_open = vaddw_u8(cnt_open, vmovl_u8(vget_high_u8(is_open)));\n\n        int16x8_t cnt_close = vmovl_u8(vget_low_u8(is_close));\n        cnt_close = vaddw_u8(cnt_close, vmovl_u8(vget_high_u8(is_close)));\n\n        int32x4_t sum_open = vpaddlq_s16(cnt_open);\n        int32x4_t sum_close = vpaddlq_s16(cnt_close);\n\n        int total_open = vgetq_lane_s32(sum_open, 0) + vgetq_lane_s32(sum_open, 1) +\n                        vgetq_lane_s32(sum_open, 2) + vgetq_lane_s32(sum_open, 3);\n\n        int total_close = vgetq_lane_s32(sum_close, 0) + vgetq_lane_s32(sum_close, 1) +\n                         vgetq_lane_s32(sum_close, 2) + vgetq_lane_s32(sum_close, 3);\n\n        count += total_open - total_close;\n\n        if (count < 0) {\n            return false;\n        }\n    }\n\n    return count == 0;\n}\n```"}
{"task_id": "SimdBench_90_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nbool correct_bracketing_simd(const std::string& brackets) {\n    int balance = 0;\n    const int simd_width = 16; // Process 16 bytes at a time using SIMD\n    const uint8_t* data = reinterpret_cast<const uint8_t*>(brackets.data());\n    size_t length = brackets.size();\n\n    for (size_t i = 0; i < length / simd_width * simd_width; i += simd_width) {\n        uint8x16_t vec = vld1q_u8(data + i);\n        uint8x16_t open = vmovq_n_u8('(');\n        uint8x16_t close = vmovq_n_u8(')');\n        \n        uint8x16_t is_open = vceqq_u8(vec, open);\n        uint8x16_t is_close = vceqq_u8(vec, close);\n        \n        int16x8_t cnt_open = vpaddlq_u8(vreinterpretq_u8_u16(vmovl_u8(vget_low_u8(vreinterpret_u8_u16(is_open)))));\n        int16x8_t cnt_close = vpaddlq_u8(vreinterpretq_u8_u16(vmovl_u8(vget_low_u8(vreinterpret_u8_u16(is_close)))));\n        \n        int32x4_t sum_open = vpaddlq_u16(vget_low_u16(vreinterpretq_u16_u8(cnt_open)));\n        int32x4_t sum_close = vpaddlq_u16(vget_low_u16(vreinterpretq_u16_u8(cnt_close)));\n        \n        balance += vgetq_lane_s32(sum_open, 0) - vgetq_lane_s32(sum_close, 0);\n        \n        if (balance < 0) return false;\n    }\n\n    for (size_t i = length / simd_width * simd_width; i < length; ++i) {\n        if (data[i] == '(') {\n            ++balance;\n        } else if (data[i] == ')') {\n            --balance;\n            if (balance < 0) return false;\n        }\n    }\n\n    return balance == 0;\n}\n```"}
{"task_id": "SimdBench_90_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nbool correct_bracketing_simd(const std::string& brackets) {\n    int balance = 0;\n    const int simd_width = 16; // Process 16 bytes at a time using SIMD\n    const uint8_t* data = reinterpret_cast<const uint8_t*>(brackets.c_str());\n    size_t length = brackets.size();\n\n    for (size_t i = 0; i < length / simd_width * simd_width; i += simd_width) {\n        uint8x16_t vec = vld1q_u8(data + i);\n        uint8x16_t open = vmovq_n_u8('(');\n        uint8x16_t close = vmovq_n_u8(')');\n        \n        uint8x16_t is_open = vceqq_u8(vec, open);\n        uint8x16_t is_close = vceqq_u8(vec, close);\n\n        int16x8_t count_open = vpaddlq_u8(vreinterpretq_u8_u16(vmovl_u8(vget_low_u8(vreinterpretq_u8_u16(is_open)))));\n        int16x8_t count_close = vpaddlq_u8(vreinterpretq_u8_u16(vmovl_u8(vget_low_u8(vreinterpretq_u8_u16(is_close)))));\n\n        int32x4_t sum_open = vpaddlq_s16(count_open);\n        int32x4_t sum_close = vpaddlq_s16(count_close);\n\n        int32x2_t total_open = vpaddl_s32(vget_low_s32(sum_open), vget_high_s32(sum_open));\n        int32x2_t total_close = vpaddl_s32(vget_low_s32(sum_close), vget_high_s32(sum_close));\n\n        balance += vget_lane_s32(total_open, 0) - vget_lane_s32(total_close, 0);\n\n        if (balance < 0) return false;\n    }\n\n    for (size_t i = length / simd_width * simd_width; i < length; ++i) {\n        if (data[i] == '(') balance++;\n        else if (data[i] == ')') balance--;\n        if (balance < 0) return false;\n    }\n\n    return balance == 0;\n}\n```"}
{"task_id": "SimdBench_90_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nbool correct_bracketing_simd(const std::string& brackets) {\n    int balance = 0;\n    const uint8x16_t open_vec = vdupq_n_u8('(');\n    const uint8x16_t close_vec = vdupq_n_u8(')');\n    \n    size_t i = 0;\n    for (; i <= brackets.size() - 16; i += 16) {\n        uint8x16_t vec = vld1q_u8(reinterpret_cast<const uint8_t*>(&brackets[i]));\n        uint8x16_t is_open = vcmeq_u8(vec, open_vec);\n        uint8x16_t is_close = vcmeq_u8(vec, close_vec);\n        \n        int32x4_t cnt_open = vmovl_u8(vget_low_u8(is_open));\n        cnt_open = vaddw_u8(cnt_open, vmovl_u8(vget_high_u8(is_open)));\n        \n        int32x4_t cnt_close = vmovl_u8(vget_low_u8(is_close));\n        cnt_close = vaddw_u8(cnt_close, vmovl_u8(vget_high_u8(is_close)));\n        \n        int32x4_t diff = vsubq_s32(vcvtq_s32_f32(vcvtq_f32_s32(cnt_open)), vcvtq_s32_f32(vcvtq_f32_s32(cnt_close)));\n        int32x4_t sum_diff = vpaddq_s32(diff, diff);\n        sum_diff = vpaddq_s32(sum_diff, sum_diff);\n        balance += vgetq_lane_s32(sum_diff, 0);\n        \n        if (balance < 0) return false;\n    }\n    \n    for (; i < brackets.size(); ++i) {\n        if (brackets[i] == '(') balance++;\n        else if (brackets[i] == ')') balance--;\n        if (balance < 0) return false;\n    }\n    \n    return balance == 0;\n}\n```"}
{"task_id": "SimdBench_90_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nbool correct_bracketing_simd(const std::string& brackets) {\n    int balance = 0;\n    const uint8_t* data = reinterpret_cast<const uint8_t*>(brackets.data());\n    size_t length = brackets.size();\n    size_t aligned_length = length & ~15;\n\n    for (size_t i = 0; i < aligned_length; i += 16) {\n        uint8x16_t vec = vld1q_u8(data + i);\n        uint8x16_t open = vmovq_n_u8('(');\n        uint8x16_t close = vmovq_n_u8(')');\n        \n        uint8x16_t is_open = vceqq_u8(vec, open);\n        uint8x16_t is_close = vceqq_u8(vec, close);\n        \n        int16x8_t count_open = vpaddlq_s8(vreinterpretq_s8_u8(is_open));\n        int16x8_t count_close = vpaddlq_s8(vreinterpretq_s8_u8(is_close));\n        \n        int32x4_t sum_open = vpaddlq_s16(count_open);\n        int32x4_t sum_close = vpaddlq_s16(count_close);\n        \n        int32x2_t total_open = vpaddl_s32(vget_low_s32(sum_open), vget_high_s32(sum_open));\n        int32x2_t total_close = vpaddl_s32(vget_low_s32(sum_close), vget_high_s32(sum_close));\n        \n        balance += vget_lane_s32(total_open, 0) - vget_lane_s32(total_close, 0);\n        \n        if (balance < 0) return false;\n    }\n\n    for (size_t i = aligned_length; i < length; ++i) {\n        if (data[i] == '(') {\n            ++balance;\n        } else if (data[i] == ')') {\n            --balance;\n            if (balance < 0) return false;\n        }\n    }\n\n    return balance == 0;\n}\n```"}
{"task_id": "SimdBench_91_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<float> derivative_simd(std::vector<float> xs) {\n    size_t n = xs.size();\n    if (n <= 1) return {};\n\n    std::vector<float> result(n - 1);\n    float* res_ptr = result.data();\n    \n    size_t i = 0;\n    for (; i + 3 < n - 1; i += 4) {\n        float32x4_t coeffs = vld1q_f32(&xs[i + 1]);\n        float32x4_t indices = { static_cast<float>(i + 1), \n                               static_cast<float>(i + 2), \n                               static_cast<float>(i + 3), \n                               static_cast<float>(i + 4) };\n        float32x4_t prod = vmulq_f32(coeffs, indices);\n        vst1q_f32(res_ptr + i, prod);\n    }\n\n    for (; i < n - 1; ++i) {\n        result[i] = xs[i + 1] * (i + 1);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_91_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<float> derivative_simd(std::vector<float> xs){\n    size_t n = xs.size();\n    if (n <= 1) return {};\n\n    std::vector<float> result(n - 1);\n    float coefficients[] = {0.0f, 1.0f, 2.0f, 3.0f, 4.0f, 5.0f, 6.0f, 7.0f};\n\n    float32x4_t v_zero = vdupq_n_f32(0.0f);\n    size_t i = 0;\n\n    for (; i + 3 < n - 1; i += 4) {\n        float32x4_t v_coeffs = vld1q_f32(coefficients + i + 1);\n        float32x4_t v_values = vld1q_f32(xs.data() + i + 1);\n        float32x4_t v_result = vmulq_f32(v_values, v_coeffs);\n        vst1q_f32(result.data() + i, v_result);\n    }\n\n    for (; i < n - 1; ++i) {\n        result[i] = xs[i + 1] * (i + 1);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_91_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<float> derivative_simd(std::vector<float> xs){\n    size_t n = xs.size();\n    if (n <= 1) return {};\n\n    std::vector<float> result(n - 1);\n    float32x4_t coeff, idx, res;\n\n    size_t i = 0;\n    for (; i <= n - 5; i += 4) {\n        coeff = vld1q_f32(&xs[i + 1]);\n        float32x4_t indices = vdupq_n_f32(i + 1);\n        idx = indices;\n        res = vmulq_f32(coeff, idx);\n        vst1q_f32(&result[i], res);\n    }\n\n    for (; i < n - 1; ++i) {\n        result[i] = xs[i + 1] * (i + 1);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_91_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<float> derivative_simd(std::vector<float> xs){\n    size_t n = xs.size();\n    if (n <= 1) return {};\n\n    std::vector<float> result(n - 1);\n    float* res_ptr = result.data();\n\n    size_t i = 0;\n    for (; i + 3 < n - 1; i += 4) {\n        float32x4_t coeffs = vld1q_f32(&xs[i + 1]);\n        float32x4_t indices = { static_cast<float>(i + 1), static_cast<float>(i + 2), static_cast<float>(i + 3), static_cast<float>(i + 4) };\n        float32x4_t prod = vmulq_f32(coeffs, indices);\n        vst1q_f32(res_ptr, prod);\n        res_ptr += 4;\n    }\n\n    for (; i < n - 1; ++i) {\n        *res_ptr++ = xs[i + 1] * (i + 1);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_91_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<float> derivative_simd(std::vector<float> xs){\n    size_t n = xs.size();\n    if (n <= 1) return {};\n    \n    std::vector<float> result(n - 1);\n    float32x4_t indices_vec;\n    float32x4_t values_vec;\n    \n    for (size_t i = 0; i < n - 1; i += 4) {\n        // Load coefficients\n        values_vec = vld1q_f32(&xs[i]);\n        \n        // Create vector of indices [i+1, i+2, i+3, i+4]\n        indices_vec = vdupq_n_f32(i + 1);\n        indices_vec = vaddq_f32(indices_vec, vcvtq_f32_s32(vdupq_n_s32(1)));\n        indices_vec = vmlaq_f32(indices_vec, vcvtq_f32_s32(vdupq_n_s32(1)), vcvtq_f32_s32(vdupq_n_s32(1)));\n        \n        // Multiply coefficients by indices\n        values_vec = vmulq_f32(values_vec, indices_vec);\n        \n        // Store the results\n        vst1q_f32(&result[i], values_vec);\n    }\n    \n    // Handle remaining elements\n    for (size_t i = ((n - 1) / 4) * 4; i < n - 1; ++i) {\n        result[i] = xs[i + 1] * (i + 1);\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_92_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n#include <cctype>\n\nint vowels_count_simd(std::string s) {\n    if (s.empty()) return 0;\n\n    // Define vowels mask for 'a', 'e', 'i', 'o', 'u'\n    uint8x16_t vowels_mask = vdupq_n_u8(0);\n    uint8x16_t y_mask = vdupq_n_u8(0);\n\n    const uint8_t vowels[16] = { 'a', 'e', 'i', 'o', 'u', 'A', 'E', 'I', 'O', 'U', 0, 0, 0, 0, 0, 0 };\n    const uint8_t y_vowels[16] = { 'y', 'Y', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 };\n\n    vowels_mask = vld1q_u8(vowels);\n    y_mask = vld1q_u8(y_vowels);\n\n    int count = 0;\n    size_t len = s.length();\n    size_t i = 0;\n\n    // Process 16 characters at a time\n    for (; i <= len - 16; i += 16) {\n        uint8x16_t vec = vld1q_u8(reinterpret_cast<const uint8_t*>(&s[i]));\n        uint8x16_t cmp_vowels = vmovemaskq_u8(vceqq_u8(vec, vowels_mask));\n        uint8x16_t cmp_y = vmovemaskq_u8(vceqq_u8(vec, y_mask));\n\n        count += __builtin_popcount(cmp_vowels);\n        if (i + 16 == len) {\n            count += __builtin_popcount(cmp_y);\n        }\n    }\n\n    // Handle remaining characters\n    for (; i < len; ++i) {\n        char c = std::tolower(s[i]);\n        if (c == 'a' || c == 'e' || c == 'i' || c == 'o' || c == 'u') {\n            count++;\n        } else if (c == 'y' && i == len - 1) {\n            count++;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_92_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nint vowels_count_simd(std::string s) {\n    if (s.empty()) return 0;\n\n    const uint8x16_t vowels = vdupq_n_u8(0);\n    uint8x16_t v_a = vdupq_n_u8('a');\n    uint8x16_t v_e = vdupq_n_u8('e');\n    uint8x16_t v_i = vdupq_n_u8('i');\n    uint8x16_t v_o = vdupq_n_u8('o');\n    uint8x16_t v_u = vdupq_n_u8('u');\n    uint8x16_t v_A = vdupq_n_u8('A');\n    uint8x16_t v_E = vdupq_n_u8('E');\n    uint8x16_t v_I = vdupq_n_u8('I');\n    uint8x16_t v_O = vdupq_n_u8('O');\n    uint8x16_t v_U = vdupq_n_u8('U');\n\n    int count = 0;\n    size_t len = s.length();\n    size_t i = 0;\n\n    // Process 16 characters at a time\n    for (; i <= len - 16; i += 16) {\n        uint8x16_t block = vld1q_u8(reinterpret_cast<const uint8_t*>(&s[i]));\n        uint8x16_t is_vowel = vorrq_u8(\n            vorrq_u8(vorrq_u8(vceqq_u8(block, v_a), vceqq_u8(block, v_e)),\n            vorrq_u8(vceqq_u8(block, v_i), vceqq_u8(block, v_o))),\n            vceqq_u8(block, v_u));\n        is_vowel = vorrq_u8(is_vowel,\n            vorrq_u8(vorrq_u8(vceqq_u8(block, v_A), vceqq_u8(block, v_E)),\n            vorrq_u8(vceqq_u8(block, v_I), vceqq_u8(block, v_O))));\n        is_vowel = vorrq_u8(is_vowel, vceqq_u8(block, v_U));\n\n        uint64x2_t res = vpaddlq_u32(vcntq_u8(is_vowel));\n        uint32x2_t sum = vpaddl_u16(vget_low_u16(res), vget_high_u16(res));\n        count += vget_lane_u32(sum, 0) + vget_lane_u32(sum, 1);\n    }\n\n    // Handle remaining characters\n    for (; i < len; ++i) {\n        char c = s[i];\n        if (c == 'a' || c == 'e' || c == 'i' || c == 'o' || c == 'u' ||\n            c == 'A' || c == 'E' || c == 'I' || c == 'O' || c == 'U') {\n            count++;\n        } else if ((c == 'y' || c == 'Y') && i == len - 1) {\n            count++;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_92_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nint vowels_count_simd(std::string s) {\n    int count = 0;\n    if (s.empty()) return count;\n\n    // Convert string to uppercase for uniformity\n    uint8x16_t vowels = vdupq_n_u8(0);\n    uint8x16_t mask_a = vdupq_n_u8('A');\n    uint8x16_t mask_e = vdupq_n_u8('E');\n    uint8x16_t mask_i = vdupq_n_u8('I');\n    uint8x16_t mask_o = vdupq_n_u8('O');\n    uint8x16_t mask_u = vdupq_n_u8('U');\n\n    // Set 'Y' as vowel only if it is at the end\n    bool last_char_y = false;\n    if (s.back() == 'y' || s.back() == 'Y') {\n        last_char_y = true;\n    }\n\n    size_t i = 0;\n    size_t len = s.length();\n    uint8x16_t zero = vdupq_n_u8(0);\n\n    for (; i <= len - 16; i += 16) {\n        uint8x16_t vec = vld1q_u8(reinterpret_cast<const uint8_t*>(&s[i]));\n        uint8x16_t upper = vandq_u8(vec, vdupq_n_u8(~0x20)); // To uppercase\n\n        uint8x16_t cmp_a = vceqq_u8(upper, mask_a);\n        uint8x16_t cmp_e = vceqq_u8(upper, mask_e);\n        uint8x16_t cmp_i = vceqq_u8(upper, mask_i);\n        uint8x16_t cmp_o = vceqq_u8(upper, mask_o);\n        uint8x16_t cmp_u = vceqq_u8(upper, mask_u);\n\n        uint8x16_t matches = vorrq_u8(cmp_a, cmp_e);\n        matches = vorrq_u8(matches, cmp_i);\n        matches = vorrq_u8(matches, cmp_o);\n        matches = vorrq_u8(matches, cmp_u);\n\n        uint64x2_t res = vcntq_u8(matches);\n        uint64x2_t sum = vpaddlq_u32(vreinterpretq_u32_u64(res));\n        count += vget_lane_u32(sum, 0) + vget_lane_u32(sum, 1);\n    }\n\n    // Handle remaining characters\n    for (; i < len; ++i) {\n        char c = std::toupper(s[i]);\n        if (c == 'A' || c == 'E' || c == 'I' || c == 'O' || c == 'U') {\n            count++;\n        } else if (last_char_y && i == len - 1 && (c == 'Y')) {\n            count++;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_92_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nint vowels_count_simd(std::string s) {\n    if (s.empty()) return 0;\n\n    // Define the set of vowels in both lowercase and uppercase\n    uint8x16_t vowels = vdupq_n_u8(0);\n    uint8x16_t mask_a = vdupq_n_u8('a');\n    uint8x16_t mask_e = vdupq_n_u8('e');\n    uint8x16_t mask_i = vdupq_n_u8('i');\n    uint8x16_t mask_o = vdupq_n_u8('o');\n    uint8x16_t mask_u = vdupq_n_u8('u');\n    uint8x16_t mask_A = vdupq_n_u8('A');\n    uint8x16_t mask_E = vdupq_n_u8('E');\n    uint8x16_t mask_I = vdupq_n_u8('I');\n    uint8x16_t mask_O = vdupq_n_u8('O');\n    uint8x16_t mask_U = vdupq_n_u8('U');\n\n    vowels = vorrq_u8(vowels, vmovq_n_u8('a'));\n    vowels = vorrq_u8(vowels, vmovq_n_u8('e'));\n    vowels = vorrq_u8(vowels, vmovq_n_u8('i'));\n    vowels = vorrq_u8(vowels, vmovq_n_u8('o'));\n    vowels = vorrq_u8(vowels, vmovq_n_u8('u'));\n    vowels = vorrq_u8(vowels, vmovq_n_u8('A'));\n    vowels = vorrq_u8(vowels, vmovq_n_u8('E'));\n    vowels = vorrq_u8(vowels, vmovq_n_u8('I'));\n    vowels = vorrq_u8(vowels, vmovq_n_u8('O'));\n    vowels = vorrq_u8(vowels, vmovq_n_u8('U'));\n\n    int count = 0;\n    size_t len = s.length();\n    size_t i = 0;\n\n    // Process 16 characters at a time\n    for (; i <= len - 16; i += 16) {\n        uint8x16_t vec = vld1q_u8(reinterpret_cast<const uint8_t*>(&s[i]));\n        uint8x16_t cmp = vceqq_u8(vec, vowels);\n\n        uint8x16_t and_res_a = vandq_u8(cmp, vceqq_u8(vec, mask_a));\n        uint8x16_t and_res_e = vandq_u8(cmp, vceqq_u8(vec, mask_e));\n        uint8x16_t and_res_i = vandq_u8(cmp, vceqq_u8(vec, mask_i));\n        uint8x16_t and_res_o = vandq_u8(cmp, vceqq_u8(vec, mask_o));\n        uint8x16_t and_res_u = vandq_u8(cmp, vceqq_u8(vec, mask_u));\n        uint8x16_t and_res_A = vandq_u8(cmp, vceqq_u8(vec, mask_A));\n        uint8x16_t and_res_E = vandq_u8(cmp, vceqq_u8(vec, mask_E));\n        uint8x16_t and_res_I = vandq_u8(cmp, vceqq_u8(vec, mask_I));\n        uint8x16_t and_res_O = vandq_u8(cmp, vceqq_u8(vec, mask_O));\n        uint8x16_t and_res_U = vandq_u8(cmp, vceqq_u8(vec, mask_U));\n\n        uint8x16_t res = vorrq_u8(and_res_a, and_res_e);\n        res = vorrq_u8(res, and_res_i);\n        res = vorrq_u8(res, and_res_o);\n        res = vorrq_u8(res, and_res_u);\n        res = vorrq_u8(res, and_res_A);\n        res = vorrq_u8(res, and_res_E);\n        res = vorrq_u8(res, and_res_I);\n        res = vorrq_u8(res, and_res_O);\n        res = vorrq_u8(res, and_res_U);\n\n        uint64x2_t cnt = vpaddlq_u32(vcntq_u8(res));\n        count += (vgetq_lane_u32(cnt, 0) + vgetq_lane_u32(cnt, 1));\n    }\n\n    // Handle remaining characters\n    for (; i < len; ++i) {\n        char c = tolower(s[i]);\n        if (c == 'a' || c == 'e' || c == 'i' || c == 'o' || c == 'u') {\n            count++;\n        } else if (c == 'y' && i == len - 1) {\n            count++;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_92_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nint vowels_count_simd(std::string s) {\n    int count = 0;\n    const uint8x16_t vowels = vld1q_u8((const uint8_t*)\"aeiouAEIOUY\");\n    const size_t len = s.length();\n    const uint8_t* str = (const uint8_t*)s.c_str();\n\n    for (size_t i = 0; i + 15 < len; i += 16) {\n        uint8x16_t vec = vld1q_u8(str + i);\n        uint8x16_t cmp = vmovq_n_u8(0);\n\n        cmp = vorrq_u8(cmp, vceqq_u8(vec, vdupq_n_u8('a')));\n        cmp = vorrq_u8(cmp, vceqq_u8(vec, vdupq_n_u8('e')));\n        cmp = vorrq_u8(cmp, vceqq_u8(vec, vdupq_n_u8('i')));\n        cmp = vorrq_u8(cmp, vceqq_u8(vec, vdupq_n_u8('o')));\n        cmp = vorrq_u8(cmp, vceqq_u8(vec, vdupq_n_u8('u')));\n        cmp = vorrq_u8(cmp, vceqq_u8(vec, vdupq_n_u8('A')));\n        cmp = vorrq_u8(cmp, vceqq_u8(vec, vdupq_n_u8('E')));\n        cmp = vorrq_u8(cmp, vceqq_u8(vec, vdupq_n_u8('I')));\n        cmp = vorrq_u8(cmp, vceqq_u8(vec, vdupq_n_u8('O')));\n        cmp = vorrq_u8(cmp, vceqq_u8(vec, vdupq_n_u8('U')));\n\n        if (i + 15 == len - 1 && (str[i + 15] == 'y' || str[i + 15] == 'Y')) {\n            cmp = vorrq_u8(cmp, vceqq_u8(vdupq_n_u8(str[i + 15]), vdupq_n_u8('y')));\n            cmp = vorrq_u8(cmp, vceqq_u8(vdupq_n_u8(str[i + 15]), vdupq_n_u8('Y')));\n        }\n\n        uint8x16_t mask = vandq_u8(vcmpneq_f32, vowels);\n        uint8x16_t res = vandq_u8(cmp, mask);\n\n        uint64x2_t cnt = vpaddlq_u32(vcntq_u8(res));\n        count += vgetq_lane_u32(cnt, 0) + vgetq_lane_u32(cnt, 1);\n    }\n\n    // Handle remaining characters\n    for (size_t i = (len / 16) * 16; i < len; ++i) {\n        char c = tolower(s[i]);\n        if (c == 'a' || c == 'e' || c == 'i' || c == 'o' || c == 'u') {\n            count++;\n        } else if ((c == 'y') && (i == len - 1)) {\n            count++;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_93_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nint digitSum_simd(std::string s){\n    int sum = 0;\n    uint8x16_t vec_zero = vdupq_n_u8(0);\n    uint8x16_t vec_upper_A = vdupq_n_u8('A');\n    uint8x16_t vec_upper_Z = vdupq_n_u8('Z');\n    uint8x16_t vec_mask;\n\n    for (size_t i = 0; i + 16 <= s.size(); i += 16) {\n        uint8x16_t vec = vld1q_u8(reinterpret_cast<const uint8_t*>(&s[i]));\n        vec_mask = vcgeq_u8(vec, vec_upper_A);\n        vec_mask = vandq_u8(vec_mask, vcleq_u8(vec, vec_upper_Z));\n        vec = vandq_u8(vec, vec_mask);\n        sum += vaddlvq_u8(vec);\n    }\n\n    // Handle remaining characters\n    size_t i = s.size() & ~15;\n    if (i < s.size()) {\n        uint8x16_t vec = vld1q_u8_zero(reinterpret_cast<const uint8_t*>(&s[i]));\n        vec_mask = vcgeq_u8(vec, vec_upper_A);\n        vec_mask = vandq_u8(vec_mask, vcleq_u8(vec, vec_upper_Z));\n        vec = vandq_u8(vec, vec_mask);\n        sum += vaddlvq_u8(vec);\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_93_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nint digitSum_simd(std::string s){\n    int sum = 0;\n    const uint8_t *data = reinterpret_cast<const uint8_t *>(s.data());\n    size_t length = s.size();\n    \n    uint8x16_t zero = vdupq_n_u8(0);\n    uint8x16_t upperA = vdupq_n_u8('A');\n    uint8x16_t upperZ = vdupq_n_u8('Z');\n    uint64x2_t total = vdupq_n_u64(0);\n\n    for (size_t i = 0; i + 16 <= length; i += 16) {\n        uint8x16_t vec = vld1q_u8(data + i);\n        uint8x16_t mask = vcgeq_u8(vec, upperA);\n        mask = vandq_u8(mask, vcleq_u8(vec, upperZ));\n        uint8x16_t filtered = vandq_u8(vec, mask);\n        uint16x8_t sums = vpaddlq_u8(filtered);\n        uint32x4_t sums2 = vpaddlq_u16(sums);\n        uint64x2_t sums3 = vpaddlq_u32(sums2);\n        total = vaddq_u64(total, sums3);\n    }\n\n    uint64x2_t reduced = vpaddlq_u32(vcombine_u32(vget_low_u32(vreinterpretq_u32_u64(total)), \n                                           vget_high_u32(vreinterpretq_u32_u64(total))));\n    sum += vget_lane_u64(vadd_u64(vget_low_u64(reduced), vget_high_u64(reduced)), 0);\n\n    for (size_t i = (length / 16) * 16; i < length; ++i) {\n        if (data[i] >= 'A' && data[i] <= 'Z') {\n            sum += data[i];\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_93_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nint digitSum_simd(std::string s){\n    int sum = 0;\n    uint8x16_t vec_zero = vdupq_n_u8(0);\n    uint8x16_t vec_upper = vdupq_n_u8('A');\n    uint8x16_t vec_lower = vdupq_n_u8('Z');\n    uint8x16_t vec_mask = vdupq_n_u8(0);\n\n    size_t i = 0;\n    for (; i + 15 < s.size(); i += 16) {\n        uint8x16_t vec = vld1q_u8(reinterpret_cast<const uint8_t*>(&s[i]));\n        uint8x16_t ge_A = vcgeq_u8(vec, vec_upper);\n        uint8x16_t le_Z = vcleq_u8(vec, vec_lower);\n        vec_mask = vandq_u8(ge_A, le_Z);\n        uint8x16_t filtered = vandq_u8(vec, vec_mask);\n        uint8x16_t subtracted = vsubq_u8(filtered, vec_zero);\n        uint32x4_t sum_32 = vpaddlq_u16(vmovl_u8(vget_low_u8(subtracted)));\n        sum_32 = vaddq_u32(sum_32, vpaddlq_u16(vmovl_u8(vget_high_u8(subtracted))));\n        uint64x2_t sum_64 = vpaddlq_u32(sum_32);\n        sum += vgetq_lane_u64(sum_64, 0) + vgetq_lane_u64(sum_64, 1);\n    }\n\n    for (; i < s.size(); ++i) {\n        if (s[i] >= 'A' && s[i] <= 'Z') {\n            sum += static_cast<uint8_t>(s[i]);\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_93_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nint digitSum_simd(std::string s){\n    int sum = 0;\n    uint8x16_t vec_zero = vdupq_n_u8(0);\n    uint8x16_t vec_upper_A = vdupq_n_u8('A');\n    uint8x16_t vec_upper_Z = vdupq_n_u8('Z');\n    uint8x16_t vec_sum = vdupq_n_u8(0);\n\n    size_t i = 0;\n    for (; i + 15 < s.size(); i += 16) {\n        uint8x16_t vec = vld1q_u8(reinterpret_cast<const uint8_t*>(&s[i]));\n        uint8x16_t is_upper = vandq_u8(vcgeq_u8(vec, vec_upper_A), vcleq_u8(vec, vec_upper_Z));\n        uint8x16_t masked_vec = vandq_u8(vec, is_upper);\n        vec_sum = vaddq_u8(vec_sum, masked_vec);\n    }\n\n    uint8x8_t sum_lo = vpaddl_u8(vget_low_u8(vec_sum));\n    uint8x8_t sum_hi = vpaddl_u8(vget_high_u8(vec_sum));\n    uint8x8_t total = vadd_u8(sum_lo, sum_hi);\n    uint16x4_t total16 = vpaddl_u8(total);\n    uint32x2_t total32 = vpaddl_u16(total16);\n    sum += (int)vget_lane_u32(total32, 0) + (int)vget_lane_u32(total32, 1);\n\n    for (; i < s.size(); ++i) {\n        if (s[i] >= 'A' && s[i] <= 'Z') {\n            sum += static_cast<unsigned char>(s[i]);\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_93_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nint digitSum_simd(std::string s){\n    int sum = 0;\n    uint8x16_t vec_zero = vdupq_n_u8(0);\n    uint8x16_t vec_A = vdupq_n_u8('A');\n    uint8x16_t vec_Z = vdupq_n_u8('Z');\n    uint32x4_t vec_sum = vdupq_n_u32(0);\n\n    size_t i = 0;\n    for (; i + 15 < s.size(); i += 16) {\n        uint8x16_t vec = vld1q_u8(reinterpret_cast<const uint8_t*>(&s[i]));\n        uint8x16_t is_upper = vandq_u8(vcgeq_u8(vec, vec_A), vcleq_u8(vec, vec_Z));\n        uint8x16_t masked_vec = vandq_u8(vec, is_upper);\n        uint32x4_t partial_sums = vpaddlq_u16(vmovl_u8(masked_vec));\n        vec_sum = vaddq_u32(vec_sum, partial_sums);\n    }\n\n    uint32x4_t reduced_sum = vpaddlq_u16(vget_low_u16(vmovl_u8(vuzp1_u8(vreinterpret_u8_u32(vec_sum), vec_zero))));\n    uint64x2_t sum_64 = vpaddlq_u32(reduced_sum);\n    sum += vgetq_lane_u64(sum_64, 0) + vgetq_lane_u64(sum_64, 1);\n\n    for (; i < s.size(); ++i) {\n        if (s[i] >= 'A' && s[i] <= 'Z') {\n            sum += static_cast<uint8_t>(s[i]);\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_94_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <cstdint>\n\nstd::vector<int> pluck_simd(std::vector<int> arr) {\n    if (arr.empty()) return {};\n\n    size_t n = arr.size();\n    int32x4_t min_val = vmovq_n_s32(0x7FFFFFFF);\n    int32x4_t min_idx = vmovq_n_s32(-1);\n    int32x4_t even_mask;\n    int32x4_t cmp_mask;\n    int32x4_t current_val;\n    int32x4_t current_idx;\n\n    const int32_t* data = arr.data();\n    size_t i = 0;\n\n    for (; i <= n - 4; i += 4) {\n        current_val = vld1q_s32(data + i);\n        current_idx = vcreate_s32(vcombine_u64(\n            vdup_n_u64(i), \n            vdup_n_u64(i + 3)\n        ));\n\n        // Check if the value is even\n        even_mask = vandq_s32(current_val, vmovq_n_s32(1));\n        even_mask = vmvnq_s32(even_mask); // Invert to get mask where even numbers are non-zero\n\n        // Compare current even values with min_val\n        cmp_mask = vcgeq_s32(current_val, min_val); // Greater or equal means not smaller\n        cmp_mask = vbicq_s32(cmp_mask, even_mask); // Only consider even numbers\n\n        // Update min_val and min_idx if current_val is smaller\n        min_val = vminq_s32(min_val, vbslq_s32(cmp_mask, min_val, current_val));\n        min_idx = vbslq_s32(cmp_mask, min_idx, current_idx);\n    }\n\n    // Extract scalar results\n    int min_value = 0x7FFFFFFF;\n    int min_index = -1;\n    uint32x4_t min_val_as_uint = vreinterpretq_u32_s32(min_val);\n    uint32x4_t min_idx_as_uint = vreinterpretq_u32_s32(min_idx);\n\n    for (int j = 0; j < 4; ++j) {\n        if ((min_val_as_uint[j] < min_value || (min_val_as_uint[j] == min_value && min_idx_as_uint[j] < min_index)) && !(min_val_as_uint[j] & 1)) {\n            min_value = min_val_as_uint[j];\n            min_index = min_idx_as_uint[j];\n        }\n    }\n\n    // Process remaining elements\n    for (; i < n; ++i) {\n        if (arr[i] < min_value || (arr[i] == min_value && i < min_index)) {\n            if (!(arr[i] & 1)) {\n                min_value = arr[i];\n                min_index = i;\n            }\n        }\n    }\n\n    if (min_index != -1) {\n        return {min_value, min_index};\n    } else {\n        return {};\n    }\n}\n```"}
{"task_id": "SimdBench_94_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <cstdint>\n\nstd::vector<int> pluck_simd(std::vector<int> arr){\n    if (arr.empty()) return {};\n    \n    size_t n = arr.size();\n    int32x4_t min_val = vmovq_n_s32(0x7FFFFFFF);\n    int32x4_t min_idx = vmovq_n_s32(-1);\n    int32x4_t zero = vmovq_n_s32(0);\n    int32x4_t two = vmovq_n_s32(2);\n\n    for (size_t i = 0; i < n; i += 4) {\n        int32x4_t vals;\n        if (i + 4 <= n) {\n            vals = vld1q_s32(&arr[i]);\n        } else {\n            int padded[4] = {0x7FFFFFFF, 0x7FFFFFFF, 0x7FFFFFFF, 0x7FFFFFFF};\n            for (size_t j = 0; j < n - i; ++j) {\n                padded[j] = arr[i + j];\n            }\n            vals = vld1q_s32(padded);\n        }\n\n        // Check even numbers\n        int32x4_t mod_vals = vandq_s32(vals, two);\n        uint32x4_t is_even = vceqq_s32(mod_vals, zero);\n\n        // Compare and update min_val and min_idx\n        uint32x4_t cond = vcgeq_s32(vals, min_val);\n        cond = vorrq_u32(cond, vandq_u32(vmvnq_u32(is_even), vmvnq_u32(vceqq_s32(vals, zero))));\n        \n        min_val = vminq_s32(vbslq_s32(cond, min_val, vals));\n        min_idx = vbslq_s32(cond, min_idx, vdupq_n_s32(i));\n    }\n\n    // Horizontal min\n    int32x2_t min_val_low = vpmin_s32(vget_low_s32(min_val), vget_high_s32(min_val));\n    int32x2_t min_val_final = vpmin_s32(min_val_low, min_val_low);\n\n    int32x2_t min_idx_low = vget_low_s32(min_idx);\n    int32x2_t min_idx_high = vget_high_s32(min_idx);\n\n    int32x2_t min_idx_final;\n    if (vget_lane_s32(min_val_final, 0) == vget_lane_s32(min_val_low, 0)) {\n        min_idx_final = vcreate_s32((uint64_t)vget_lane_s32(min_idx_low, 0) << 32 | (uint64_t)vget_lane_s32(min_idx_low, 1));\n    } else {\n        min_idx_final = vcreate_s32((uint64_t)vget_lane_s32(min_idx_high, 0) << 32 | (uint64_t)vget_lane_s32(min_idx_high, 1));\n    }\n\n    int min_value = vget_lane_s32(min_val_final, 0);\n    int min_index = vget_lane_s32(min_idx_final, 0);\n\n    if (min_value == 0x7FFFFFFF) return {};\n    return {min_value, min_index};\n}\n```"}
{"task_id": "SimdBench_94_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <cstdint>\n\nstd::vector<int> pluck_simd(std::vector<int> arr){\n    if (arr.empty()) return {};\n\n    size_t n = arr.size();\n    int32x4_t min_val = vmovq_n_s32(0x7FFFFFFF);\n    int32x4_t min_idx = vmovq_n_s32(0x7FFFFFFF);\n    int32x4_t indices;\n    int32x4_t values;\n    int32x4_t even_mask;\n    int32x4_t cmp_mask;\n\n    for (size_t i = 0; i < n; i += 4) {\n        // Load up to 4 values and their indices\n        values = vld1q_s32(reinterpret_cast<const int32_t*>(&arr[i]));\n        indices = vld1q_s32(reinterpret_cast<const int32_t*>(&i));\n\n        // Check for even numbers\n        even_mask = vandq_s32(vreinterpretq_s32_u32(vceqq_s32(values, vmovq_n_s32(0))), values);\n        even_mask = vbicq_s32(even_mask, vmovq_n_s32(1));\n\n        // Compare current even values with min_val\n        cmp_mask = vcgeq_s32(values, min_val);\n        cmp_mask = vorrq_s32(cmp_mask, vceqq_s32(values, min_val));\n        cmp_mask = vandq_s32(cmp_mask, even_mask);\n\n        // Update min_val and min_idx\n        min_val = vminq_s32(min_val, values);\n        min_idx = vbslq_s32(cmp_mask, indices, min_idx);\n    }\n\n    // Horizontal min reduction\n    int32x2_t min_val_lo = vpmin_s32(vget_low_s32(min_val), vget_high_s32(min_val));\n    int32x2_t min_val_final = vpmin_s32(min_val_lo, min_val_lo);\n    int32x2_t min_idx_lo = vmin_s32(vget_low_s32(min_idx), vget_high_s32(min_idx));\n    int32x2_t min_idx_final = vmin_s32(min_idx_lo, min_idx_lo);\n\n    int min_value = static_cast<int>(vget_lane_s32(min_val_final, 0));\n    int min_index = static_cast<int>(vget_lane_s32(min_idx_final, 0));\n\n    if (min_value == 0x7FFFFFFF) return {};\n    return {min_value, min_index};\n}\n```"}
{"task_id": "SimdBench_94_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <cstdint>\n\nstd::vector<int> pluck_simd(std::vector<int> arr){\n    if (arr.empty()) return {};\n\n    size_t n = arr.size();\n    size_t vec_len = n / 4;\n    size_t remainder = n % 4;\n\n    int32x4_t min_val = vmovq_n_s32(0x7FFFFFFF);\n    int32x4_t min_idx = vmovq_n_s32(-1);\n\n    const int32_t zero = 0;\n    int32x4_t vzero = vdupq_n_s32(zero);\n\n    for (size_t i = 0; i < vec_len; ++i) {\n        int32x4_t v = vld1q_s32(reinterpret_cast<const int32_t*>(&arr[i * 4]));\n        int32x4_t even_mask = vandq_s32(v, vzero); // Check if even (v & 0)\n        uint32x4_t cmp = vcgeq_s32(even_mask, vzero); // Check if >= 0 (always true here)\n        uint32x4_t is_even = vceqq_s32(even_mask, vzero); // Check if exactly 0 (even)\n\n        int32x4_t idx = vdupq_n_s32(static_cast<int32_t>(i * 4));\n        idx = vaddq_s32(idx, vdupq_n_s32(0, 1, 2, 3));\n\n        uint32x4_t cond = vandq_u32(is_even, vmovq_n_u32(1)); // Only consider even numbers\n\n        min_val = vminq_s32(v, min_val);\n        min_idx = vbslq_s32(vcmeq_s32(v, min_val), idx, min_idx);\n    }\n\n    int32_t smallest = 0x7FFFFFFF;\n    int32_t index = -1;\n\n    for (int i = 0; i < 4; ++i) {\n        if (vgetq_lane_s32(min_val, i) < smallest && vgetq_lane_s32(min_val, i) >= 0) {\n            smallest = vgetq_lane_s32(min_val, i);\n            index = vgetq_lane_s32(min_idx, i);\n        }\n    }\n\n    // Handle remaining elements\n    for (size_t i = vec_len * 4; i < n; ++i) {\n        if (arr[i] >= 0 && arr[i] % 2 == 0 && arr[i] < smallest) {\n            smallest = arr[i];\n            index = static_cast<int32_t>(i);\n        }\n    }\n\n    if (index == -1) return {};\n    return {smallest, index};\n}\n```"}
{"task_id": "SimdBench_94_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <cstdint>\n\nstd::vector<int> pluck_simd(std::vector<int> arr) {\n    if (arr.empty()) return {};\n\n    size_t n = arr.size();\n    int32x4_t min_val = vmovq_n_s32(0x7FFFFFFF);\n    int32x4_t min_idx = vmovq_n_s32(-1);\n    int32x4_t even_mask;\n    int32x4_t cmp_mask;\n    int32x4_t indices;\n    int32x4_t vals;\n\n    for (size_t i = 0; i < n; i += 4) {\n        // Load values and indices\n        vals = vld1q_s32(reinterpret_cast<const int32_t*>(&arr[i]));\n        indices = vld1q_s32(reinterpret_cast<const int32_t*>(&i));\n\n        // Check for even numbers\n        even_mask = vandq_s32(vcgeq_s32(vals, vmovq_n_s32(0)), veqzq_s32(vandq_s32(vals, vmovq_n_s32(1))));\n\n        // Compare current minimum with loaded values\n        cmp_mask = vandq_s32(even_mask, vcgtq_s32(min_val, vals));\n        min_val = vminq_s32(min_val, vbslq_s32(cmp_mask, vals, min_val));\n        min_idx = vminq_s32(min_idx, vbslq_s32(cmp_mask, indices, min_idx));\n\n        // Handle equal values by comparing indices\n        cmp_mask = vandq_s32(even_mask, vceqq_s32(min_val, vals));\n        min_idx = vminq_s32(min_idx, vbslq_s32(cmp_mask, indices, min_idx));\n    }\n\n    // Extract scalar results\n    int min_value = 0x7FFFFFFF;\n    int min_index = -1;\n    int32_t temp_vals[4];\n    int32_t temp_idxs[4];\n\n    vst1q_s32(temp_vals, min_val);\n    vst1q_s32(temp_idxs, min_idx);\n\n    for (int i = 0; i < 4; ++i) {\n        if (temp_vals[i] < min_value || (temp_vals[i] == min_value && temp_idxs[i] < min_index)) {\n            min_value = temp_vals[i];\n            min_index = temp_idxs[i];\n        }\n    }\n\n    if (min_value == 0x7FFFFFFF) return {};\n    return {min_value, min_index};\n}\n```"}
{"task_id": "SimdBench_95_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <algorithm>\n\nint search_simd(std::vector<int> lst){\n    if (lst.empty()) return -1;\n\n    int max_val = *std::max_element(lst.begin(), lst.end());\n    if (max_val > 255) max_val = 255;\n\n    std::vector<int> freq(max_val + 1, 0);\n\n    // Count frequencies using Neon\n    size_t n = lst.size();\n    size_t aligned_size = n - (n % 4);\n\n    for (size_t i = 0; i < aligned_size; i += 4) {\n        int32x4_t v = vld1q_s32(&lst[i]);\n        int32x4_t one = vdupq_n_s32(1);\n\n        int32x4_t res = vaddq_s32(vld1q_s32(&freq[vgetq_lane_s32(v, 0)]), one);\n        freq[vgetq_lane_s32(v, 0)] = vgetq_lane_s32(res, 0);\n\n        res = vaddq_s32(vld1q_s32(&freq[vgetq_lane_s32(v, 1)]), one);\n        freq[vgetq_lane_s32(v, 1)] = vgetq_lane_s32(res, 1);\n\n        res = vaddq_s32(vld1q_s32(&freq[vgetq_lane_s32(v, 2)]), one);\n        freq[vgetq_lane_s32(v, 2)] = vgetq_lane_s32(res, 2);\n\n        res = vaddq_s32(vld1q_s32(&freq[vgetq_lane_s32(v, 3)]), one);\n        freq[vgetq_lane_s32(v, 3)] = vgetq_lane_s32(res, 3);\n    }\n\n    for (size_t i = aligned_size; i < n; ++i) {\n        freq[lst[i]]++;\n    }\n\n    int result = -1;\n    for (int i = 1; i <= max_val; ++i) {\n        if (freq[i] >= i && i > result) {\n            result = i;\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_95_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <unordered_map>\n\nint search_simd(std::vector<int> lst){\n    if (lst.empty()) return -1;\n\n    std::unordered_map<int, int> freq;\n    for(auto num : lst) freq[num]++;\n\n    int result = -1;\n    size_t n = lst.size();\n    size_t aligned_size = n - (n % 4);\n\n    for(size_t i = 0; i < aligned_size; i += 4){\n        int32x4_t vec = vld1q_s32(&lst[i]);\n        int32x4_t res_vec = vmovq_n_s32(-1);\n\n        for(auto &[key, value] : freq){\n            int32x4_t key_vec = vdupq_n_s32(key);\n            int32x4_t val_vec = vdupq_n_s32(value);\n\n            uint32x4_t cond1 = vcgeq_s32(val_vec, key_vec);\n            uint32x4_t cond2 = vcgtq_s32(key_vec, vmovq_n_s32(result));\n            uint32x4_t cond = vandq_u32(cond1, cond2);\n\n            res_vec = vmaxq_s32(res_vec, vbslq_s32(cond, key_vec, res_vec));\n        }\n\n        int32x4_t max_val = vpmaxq_s32(res_vec, res_vec);\n        result = vmax(result, max_val[0]);\n    }\n\n    for(size_t i = aligned_size; i < n; ++i){\n        auto it = freq.find(lst[i]);\n        if(it != freq.end() && it->second >= it->first && it->first > result){\n            result = it->first;\n        }\n    }\n\n    return result == -1 ? -1 : result;\n}\n```"}
{"task_id": "SimdBench_95_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <algorithm>\n\nint search_simd(std::vector<int> lst){\n    if (lst.empty()) return -1;\n\n    int max_val = *std::max_element(lst.begin(), lst.end());\n    if (max_val > 256) max_val = 256;\n\n    std::vector<int> freq(max_val + 1, 0);\n\n    // Count frequencies using Neon\n    size_t n = lst.size();\n    for (size_t i = 0; i + 15 < n; i += 16) {\n        int32x4_t v0 = vld1q_s32(&lst[i]);\n        int32x4_t v1 = vld1q_s32(&lst[i + 4]);\n        int32x4_t v2 = vld1q_s32(&lst[i + 8]);\n        int32x4_t v3 = vld1q_s32(&lst[i + 12]);\n\n        for (int j = 0; j < 4; ++j) {\n            int idx0 = vgetq_lane_s32(v0, j);\n            int idx1 = vgetq_lane_s32(v1, j);\n            int idx2 = vgetq_lane_s32(v2, j);\n            int idx3 = vgetq_lane_s32(v3, j);\n\n            if (idx0 >= 0 && idx0 <= max_val) freq[idx0]++;\n            if (idx1 >= 0 && idx1 <= max_val) freq[idx1]++;\n            if (idx2 >= 0 && idx2 <= max_val) freq[idx2]++;\n            if (idx3 >= 0 && idx3 <= max_val) freq[idx3]++;\n        }\n    }\n\n    // Handle remaining elements\n    for (size_t i = (n / 16) * 16; i < n; ++i) {\n        if (lst[i] >= 0 && lst[i] <= max_val) freq[lst[i]]++;\n    }\n\n    // Find the greatest integer satisfying the condition\n    for (int i = max_val; i > 0; --i) {\n        if (freq[i] >= i) return i;\n    }\n\n    return -1;\n}\n```"}
{"task_id": "SimdBench_95_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <unordered_map>\n\nint search_simd(std::vector<int> lst){\n    if (lst.empty()) return -1;\n\n    std::unordered_map<int, int> freq;\n    for(auto num : lst) freq[num]++;\n\n    int result = -1;\n    size_t n = lst.size();\n    size_t aligned_size = n - (n % 4);\n\n    for(size_t i = 0; i < aligned_size; i += 4){\n        int32x4_t vec = vld1q_s32(&lst[i]);\n        int32x4_t cmp1 = vcgeq_s32(vec, vdupq_n_s32(1));\n        int32x4_t cmp2 = vcgeq_s32(vec, vdupq_n_s32(2));\n        int32x4_t cmp3 = vcgeq_s32(vec, vdupq_n_s32(3));\n\n        int32x4_t freq_vec = vdupq_n_s32(0);\n        for(auto &[key, value] : freq){\n            if(key == lst[i])   freq_vec = vsetq_lane_s32(value, freq_vec, 0);\n            if(key == lst[i+1]) freq_vec = vsetq_lane_s32(value, freq_vec, 1);\n            if(key == lst[i+2]) freq_vec = vsetq_lane_s32(value, freq_vec, 2);\n            if(key == lst[i+3]) freq_vec = vsetq_lane_s32(value, freq_vec, 3);\n        }\n\n        uint32x4_t mask1 = vcltq_u32(vcvtq_u32_s32(freq_vec), vcvtq_u32_s32(vec));\n        uint32x4_t mask2 = vmovq_n_u32(0xFFFFFFFF);\n        mask2 = vandq_u32(mask2, vmovl_u8(vget_lane_u8(vreinterpret_u8_u32(mask1), 0)));\n\n        int32x4_t res_vec = vdupq_n_s32(result);\n        res_vec = vmaxq_s32(res_vec, vandq_s32(vec, vreinterpretq_s32_u32(mask2)));\n        result = vmaxvq_s32(res_vec);\n    }\n\n    for(size_t i = aligned_size; i < n; ++i){\n        if(freq[lst[i]] >= lst[i]){\n            result = std::max(result, lst[i]);\n        }\n    }\n\n    return (result > 0) ? result : -1;\n}\n```"}
{"task_id": "SimdBench_95_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <unordered_map>\n\nint search_simd(std::vector<int> lst){\n    if (lst.empty()) return -1;\n\n    std::unordered_map<int, int> freq;\n    for(auto num : lst) freq[num]++;\n\n    int result = -1;\n    size_t n = lst.size();\n    size_t i = 0;\n\n    // Process in chunks of 4 using Neon\n    for (; i <= n - 4; i += 4) {\n        int32x4_t v_nums = vld1q_s32(&lst[i]);\n        \n        int32x4_t v_freqs = vmovq_n_s32(0);\n        for(auto &[key, value] : freq){\n            int32x4_t v_key = vdupq_n_s32(key);\n            uint32x4_t v_cmp = vceqq_s32(v_nums, v_key);\n            int32x4_t v_value = vdupq_n_s32(value);\n            v_freqs = vaddq_s32(v_freqs, vandq_s32(vcvtt_s32_f32(vcmp_f32(vreinterpretq_f32_s32(v_cmp), vdupq_n_f32(0.0f))), v_value));\n        }\n\n        int32x4_t v_ones = vmovq_n_s32(1);\n        int32x4_t v_check = vcgeq_s32(v_freqs, v_nums);\n        int32x4_t v_result = vmaxsq_s32(vandq_s32(vcheck, v_nums), vmovq_n_s32(result));\n        result = vmaxvq_s32(v_result);\n    }\n\n    // Handle remaining elements\n    for (; i < n; ++i){\n        if(freq[lst[i]] >= lst[i]){\n            result = (result > lst[i]) ? result : lst[i];\n        }\n    }\n\n    return (result > 0) ? result : -1;\n}\n```"}
{"task_id": "SimdBench_96_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nbool will_it_fly_simd(std::vector<int> q, int w) {\n    size_t n = q.size();\n    if (n == 0) return false;\n\n    // Check if the vector is a palindrome\n    bool is_palindrome = true;\n    size_t half = n / 2;\n    size_t aligned_size = n / 4 * 4;\n\n    for (size_t i = 0; i < aligned_size / 4; ++i) {\n        int32x4_t vec1 = vld1q_s32(&q[i * 4]);\n        int32x4_t vec2 = vld1q_s32(&q[n - (i * 4 + 4)]);\n        if (vcmpneq_f32(vreinterpretq_f32_s32(vec1), vreinterpretq_f32_s32(vec2))) {\n            is_palindrome = false;\n            break;\n        }\n    }\n\n    for (size_t i = aligned_size; i < half; ++i) {\n        if (q[i] != q[n - i - 1]) {\n            is_palindrome = false;\n            break;\n        }\n    }\n\n    if (!is_palindrome) return false;\n\n    // Calculate the sum of elements using SIMD\n    int32x4_t sum_vec = vmovq_n_s32(0);\n    for (size_t i = 0; i < aligned_size; i += 4) {\n        int32x4_t vec = vld1q_s32(&q[i]);\n        sum_vec = vaddq_s32(sum_vec, vec);\n    }\n\n    int total_sum = vgetq_lane_s32(sum_vec, 0) + vgetq_lane_s32(sum_vec, 1) +\n                    vgetq_lane_s32(sum_vec, 2) + vgetq_lane_s32(sum_vec, 3);\n\n    for (size_t i = aligned_size; i < n; ++i) {\n        total_sum += q[i];\n    }\n\n    return total_sum <= w;\n}\n```"}
{"task_id": "SimdBench_96_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nbool will_it_fly_simd(std::vector<int> q, int w) {\n    size_t n = q.size();\n    if (n == 0) return false;\n\n    // Check if the vector is a palindrome\n    bool is_palindrome = true;\n    size_t half_size = n / 2;\n    for (size_t i = 0; i < half_size; ++i) {\n        if (q[i] != q[n - 1 - i]) {\n            is_palindrome = false;\n            break;\n        }\n    }\n    if (!is_palindrome) return false;\n\n    // Calculate the sum using Neon intrinsics\n    int32x4_t vsum = vdupq_n_s32(0);\n    for (size_t i = 0; i < n; i += 4) {\n        int32x4_t v = vld1q_s32(reinterpret_cast<const int32_t*>(&q[i]));\n        vsum = vaddq_s32(vsum, v);\n    }\n\n    // Horizontal sum of the accumulated vector\n    int32x2_t sum_low = vadd_s32(vget_low_s32(vsum), vget_high_s32(vsum));\n    int32x2_t sum_all = vpadd_s32(sum_low, sum_low);\n\n    int total_sum = vget_lane_s32(sum_all, 0);\n\n    // Handle remaining elements if any\n    for (size_t i = (n / 4) * 4; i < n; ++i) {\n        total_sum += q[i];\n    }\n\n    return total_sum <= w;\n}\n```"}
{"task_id": "SimdBench_96_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nbool will_it_fly_simd(std::vector<int> q, int w) {\n    size_t n = q.size();\n    if (n == 0) return false;\n\n    // Check if the vector is a palindrome\n    bool is_palindrome = true;\n    size_t half_size = n / 2;\n    for (size_t i = 0; i < half_size; ++i) {\n        if (q[i] != q[n - 1 - i]) {\n            is_palindrome = false;\n            break;\n        }\n    }\n    if (!is_palindrome) return false;\n\n    // Calculate the sum using NEON intrinsics\n    int32x4_t sum_vec = vdupq_n_s32(0);\n    size_t aligned_size = n / 4 * 4;\n\n    const int32_t* ptr = q.data();\n    for (size_t i = 0; i < aligned_size; i += 4) {\n        int32x4_t vec = vld1q_s32(ptr + i);\n        sum_vec = vaddq_s32(sum_vec, vec);\n    }\n\n    int32x2_t sum_low = vadd_s32(vget_low_s32(sum_vec), vget_high_s32(sum_vec));\n    int32x2_t sum_final = vpadd_s32(sum_low, sum_low);\n\n    int total_sum = sum_final[0];\n\n    // Add remaining elements if any\n    for (size_t i = aligned_size; i < n; ++i) {\n        total_sum += q[i];\n    }\n\n    return total_sum <= w;\n}\n```"}
{"task_id": "SimdBench_96_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nbool will_it_fly_simd(std::vector<int> q, int w) {\n    size_t n = q.size();\n    if (n == 0) return false;\n\n    // Check if the vector is a palindrome\n    bool is_palindrome = true;\n    size_t half = n / 2;\n    for (size_t i = 0; i < half; ++i) {\n        if (q[i] != q[n - i - 1]) {\n            is_palindrome = false;\n            break;\n        }\n    }\n    if (!is_palindrome) return false;\n\n    // Calculate the sum using Neon intrinsics\n    int32x4_t sum_vec = vdupq_n_s32(0);\n    for (size_t i = 0; i < n; i += 4) {\n        int32x4_t vec = vld1q_s32(reinterpret_cast<const int32_t*>(&q[i]));\n        sum_vec = vaddq_s32(sum_vec, vec);\n    }\n\n    int32x2_t sum_low = vadd_s32(vget_low_s32(sum_vec), vget_high_s32(sum_vec));\n    int32_t total_sum = vget_lane_s32(vpadd_s32(sum_low, sum_low), 0);\n\n    // Handle remaining elements if any\n    for (size_t i = (n / 4) * 4; i < n; ++i) {\n        total_sum += q[i];\n    }\n\n    return total_sum <= w;\n}\n```"}
{"task_id": "SimdBench_96_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nbool will_it_fly_simd(std::vector<int> q, int w) {\n    size_t n = q.size();\n    if (n == 0) return false;\n\n    // Check if the vector is a palindrome\n    bool is_palindrome = true;\n    size_t half_size = n / 2;\n    size_t aligned_size = n / 4 * 4;\n\n    for (size_t i = 0; i < aligned_size / 4; ++i) {\n        int32x4_t v1 = vld1q_s32(&q[i * 4]);\n        int32x4_t v2 = vld1q_s32(&q[n - (i * 4 + 4)]);\n        if (vcmpneq_f32(v1, v2)) {\n            is_palindrome = false;\n            break;\n        }\n    }\n\n    for (size_t i = aligned_size / 4 * 4; i < half_size; ++i) {\n        if (q[i] != q[n - i - 1]) {\n            is_palindrome = false;\n            break;\n        }\n    }\n\n    if (!is_palindrome) return false;\n\n    // Calculate the sum of elements using SIMD\n    int32x4_t vsum = vmovq_n_s32(0);\n    for (size_t i = 0; i < aligned_size; i += 4) {\n        int32x4_t v = vld1q_s32(&q[i]);\n        vsum = vaddq_s32(vsum, v);\n    }\n\n    int total_sum = vgetq_lane_s32(vsum, 0) + vgetq_lane_s32(vsum, 1) +\n                    vgetq_lane_s32(vsum, 2) + vgetq_lane_s32(vsum, 3);\n\n    for (size_t i = aligned_size; i < n; ++i) {\n        total_sum += q[i];\n    }\n\n    return total_sum <= w;\n}\n```"}
{"task_id": "SimdBench_97_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nint smallest_change_simd(std::vector<int> arr){\n    int n = arr.size();\n    int changes = 0;\n    int i = 0;\n\n    // Handle vectors with less than 8 elements using scalar code\n    if (n < 8) {\n        for (; i < n / 2; ++i) {\n            if (arr[i] != arr[n - i - 1]) {\n                changes++;\n            }\n        }\n        return changes;\n    }\n\n    // Process in chunks of 8 using SIMD\n    for (; i + 7 < n / 2; i += 8) {\n        int8x8_t left = vld1_s32(&arr[i]);\n        int8x8_t right = vld1_s32(&arr[n - i - 1]);\n\n        uint8x8_t mask = vcge_s32(left, right); // Compare left and right\n        uint8x8_t diff = vmvn_u8(vceq_s32(left, right)); // Find differences\n\n        // Count the number of differing elements\n        uint8x8_t count = vcnt_u8(diff);\n        int16x4_t sum1 = vpaddl_u8(count);\n        int32x2_t sum2 = vpaddl_u16(sum1);\n        changes += vget_lane_s32(sum2, 0) + vget_lane_s32(sum2, 1);\n    }\n\n    // Handle remaining elements with scalar code\n    for (; i < n / 2; ++i) {\n        if (arr[i] != arr[n - i - 1]) {\n            changes++;\n        }\n    }\n\n    return changes;\n}\n```"}
{"task_id": "SimdBench_97_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nint smallest_change_simd(std::vector<int> arr){\n    int n = arr.size();\n    int changes = 0;\n    int i = 0;\n\n    // Handle vectors with size less than 4 using scalar operations\n    if(n < 4){\n        for(i = 0; i < n / 2; ++i){\n            if(arr[i] != arr[n - i - 1]){\n                changes++;\n            }\n        }\n        return changes;\n    }\n\n    // Process in chunks of 4 using SIMD\n    for(i = 0; i + 3 < n / 2; i += 4){\n        int32x4_t left = vld1q_s32(&arr[i]);\n        int32x4_t right = vld1q_s32(&arr[n - i - 4]);\n\n        uint32x4_t cmp = vcgeq_s32(left, right); // Compare left and right\n        uint32x4_t mask = vceqq_s32(left, right); // Check equality\n\n        uint32x4_t diff = vbslq_s32(cmp, vmvnq_u32(mask), mask); // Difference mask\n        uint32_t count = vaddvq_u32(vreinterpretq_u32_s32(diff)); // Count differences\n\n        changes += count;\n    }\n\n    // Handle remaining elements with scalar operations\n    for(; i < n / 2; ++i){\n        if(arr[i] != arr[n - i - 1]){\n            changes++;\n        }\n    }\n\n    return changes;\n}\n```"}
{"task_id": "SimdBench_97_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nint smallest_change_simd(std::vector<int> arr){\n    int n = arr.size();\n    int changes = 0;\n    int i = 0;\n\n    // Handle vectors with less than 8 elements using scalar code\n    if (n < 8) {\n        for (i = 0; i < n / 2; ++i) {\n            if (arr[i] != arr[n - 1 - i]) {\n                changes++;\n            }\n        }\n        return changes;\n    }\n\n    // Process in chunks of 8 using SIMD\n    for (i = 0; i + 7 < n / 2; i += 8) {\n        int8x8_t v_left = vld1_s8(reinterpret_cast<const int8_t*>(&arr[i]));\n        int8x8_t v_right = vld1_s8(reinterpret_cast<const int8_t*>(&arr[n - 1 - i]));\n\n        uint8x8_t v_cmp = vcge_s8(v_left, v_right); // Compare left and right\n        uint8x8_t v_mask = vceq_s8(v_left, v_right); // Check equality\n\n        // Count mismatches\n        uint8x8_t v_mismatch = vbic_u8(v_cmp, v_mask); // Mismatch where left != right\n        int count = __builtin_popcount(vget_lane_u64(vreinterpret_u64_u8(v_mismatch), 0));\n        changes += count;\n    }\n\n    // Scalar processing for remaining elements\n    for (; i < n / 2; ++i) {\n        if (arr[i] != arr[n - 1 - i]) {\n            changes++;\n        }\n    }\n\n    return changes;\n}\n```"}
{"task_id": "SimdBench_97_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nint smallest_change_simd(std::vector<int> arr){\n    int n = arr.size();\n    int count = 0;\n    int i = 0;\n\n    // Process elements in chunks of 16 integers using Neon intrinsics\n    for (; i + 15 < n / 2; i += 16) {\n        int16x8_t left_part1 = vld1q_s16(reinterpret_cast<const int16_t*>(&arr[i]));\n        int16x8_t left_part2 = vld1q_s16(reinterpret_cast<const int16_t*>(&arr[i + 8]));\n        \n        int16x8_t right_part1 = vld1q_s16(reinterpret_cast<const int16_t*>(&arr[n - i - 1]));\n        int16x8_t right_part2 = vld1q_s16(reinterpret_cast<const int16_t*>(&arr[n - i - 9]));\n\n        uint16x8_t cmp1 = vcgeq_s16(left_part1, right_part1);\n        uint16x8_t cmp2 = vcgeq_s16(left_part2, right_part2);\n\n        uint16x8_t eq1 = vceqq_s16(left_part1, right_part1);\n        uint16x8_t eq2 = vceqq_s16(left_part2, right_part2);\n\n        uint16x8_t neq1 = vmvnq_u16(eq1);\n        uint16x8_t neq2 = vmvnq_u16(eq2);\n\n        int32x4_t sum1 = vpaddlq_u16(vcntq_u16(neq1));\n        int32x4_t sum2 = vpaddlq_u16(vcntq_u16(neq2));\n\n        int32x2_t res1 = vpadd_u32(vget_low_u32(sum1), vget_high_u32(sum1));\n        int32x2_t res2 = vpadd_u32(vget_low_u32(sum2), vget_high_u32(sum2));\n\n        count += vget_lane_u32(res1, 0) + vget_lane_u32(res2, 0);\n    }\n\n    // Handle remaining elements with scalar code\n    for (; i < n / 2; ++i) {\n        if (arr[i] != arr[n - i - 1]) {\n            count++;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_97_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nint smallest_change_simd(std::vector<int> arr){\n    int n = arr.size();\n    int count = 0;\n    int *data = arr.data();\n    \n    for(int i = 0; i + 7 < n / 2; i += 8){\n        int8x16_t left = vld1q_s32(&data[i]);\n        int8x16_t right = vld1q_s32(&data[n - 1 - i]);\n        \n        uint8x16_t cmp = vcgeq_s32(left, right);\n        uint8x16_t diff = vceqq_s32(left, right);\n        uint8x16_t res = vbicq_u32(cmp, diff);\n        \n        uint64x2_t cnt = vcntq_u32(res);\n        uint64x2_t sum = vpaddlq_u32(vreinterpretq_u32_u64(cnt));\n        count += vget_lane_u32(sum, 0) + vget_lane_u32(sum, 1);\n    }\n    \n    for(int i = (n / 2) / 8 * 8; i < n / 2; ++i){\n        if(data[i] != data[n - 1 - i]){\n            count++;\n        }\n    }\n    \n    return count;\n}\n```"}
{"task_id": "SimdBench_98_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <string>\n#include <cstring>\n\nstd::vector<std::string> total_match_simd(const std::vector<std::string> & lst1, const std::vector<std::string> & lst2){\n    uint32x4_t sum1 = vdupq_n_u32(0);\n    uint32x4_t sum2 = vdupq_n_u32(0);\n\n    for(const auto& str : lst1){\n        size_t len = str.length();\n        uint32_t temp_len = static_cast<uint32_t>(len);\n        sum1 = vaddq_u32(sum1, vdupq_n_u32(temp_len));\n    }\n\n    for(const auto& str : lst2){\n        size_t len = str.length();\n        uint32_t temp_len = static_cast<uint32_t>(len);\n        sum2 = vaddq_u32(sum2, vdupq_n_u32(temp_len));\n    }\n\n    uint64_t total_sum1 = vgetq_lane_u32(sum1, 0) + vgetq_lane_u32(sum1, 1) + vgetq_lane_u32(sum1, 2) + vgetq_lane_u32(sum1, 3);\n    uint64_t total_sum2 = vgetq_lane_u32(sum2, 0) + vgetq_lane_u32(sum2, 1) + vgetq_lane_u32(sum2, 2) + vgetq_lane_u32(sum2, 3);\n\n    if(total_sum1 <= total_sum2){\n        return lst1;\n    }\n    else{\n        return lst2;\n    }\n}\n```"}
{"task_id": "SimdBench_98_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <string>\n#include <cstring>\n\nstd::vector<std::string> total_match_simd(const std::vector<std::string> & lst1, const std::vector<std::string> & lst2){\n    uint32x4_t sum1 = vdupq_n_u32(0);\n    uint32x4_t sum2 = vdupq_n_u32(0);\n\n    for(const auto& str : lst1){\n        size_t len = str.length();\n        uint32x4_t vl = vdupq_n_u32(len);\n        sum1 = vaddq_u32(sum1, vl);\n    }\n\n    for(const auto& str : lst2){\n        size_t len = str.length();\n        uint32x4_t vl = vdupq_n_u32(len);\n        sum2 = vaddq_u32(sum2, vl);\n    }\n\n    uint32_t res1 = vgetq_lane_u32(sum1, 0) + vgetq_lane_u32(sum1, 1) + vgetq_lane_u32(sum1, 2) + vgetq_lane_u32(sum1, 3);\n    uint32_t res2 = vgetq_lane_u32(sum2, 0) + vgetq_lane_u32(sum2, 1) + vgetq_lane_u32(sum2, 2) + vgetq_lane_u32(sum2, 3);\n\n    if(res1 <= res2){\n        return lst1;\n    }\n    else{\n        return lst2;\n    }\n}\n```"}
{"task_id": "SimdBench_98_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <string>\n#include <cstring>\n\nstd::vector<std::string> total_match_simd(const std::vector<std::string> & lst1, const std::vector<std::string> & lst2){\n    uint32x4_t sum1 = vdupq_n_u32(0);\n    uint32x4_t sum2 = vdupq_n_u32(0);\n\n    // Calculate total length for lst1\n    for(const auto& str : lst1){\n        size_t len = str.length();\n        uint32x4_t vec_len = vdupq_n_u32(static_cast<uint32_t>(len));\n        sum1 = vaddq_u32(sum1, vec_len);\n    }\n\n    // Calculate total length for lst2\n    for(const auto& str : lst2){\n        size_t len = str.length();\n        uint32x4_t vec_len = vdupq_n_u32(static_cast<uint32_t>(len));\n        sum2 = vaddq_u32(sum2, vec_len);\n    }\n\n    // Horizontal add for sum1\n    uint64x2_t sum1_low  = vpaddl_u32(vget_low_u32(sum1));\n    uint64x2_t sum1_high = vpaddl_u32(vget_high_u32(sum1));\n    uint64x2_t sum1_total = vpadd_u64(sum1_low, sum1_high);\n    uint32_t total1 = static_cast<uint32_t>(vget_lane_u64(sum1_total, 0) + vget_lane_u64(sum1_total, 1));\n\n    // Horizontal add for sum2\n    uint64x2_t sum2_low  = vpaddl_u32(vget_low_u32(sum2));\n    uint64x2_t sum2_high = vpaddl_u32(vget_high_u32(sum2));\n    uint64x2_t sum2_total = vpadd_u64(sum2_low, sum2_high);\n    uint32_t total2 = static_cast<uint32_t>(vget_lane_u64(sum2_total, 0) + vget_lane_u64(sum2_total, 1));\n\n    if(total1 <= total2){\n        return lst1;\n    }\n    else{\n        return lst2;\n    }\n}\n```"}
{"task_id": "SimdBench_98_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <string>\n\nstd::vector<std::string> total_match_simd(const std::vector<std::string> & lst1, const std::vector<std::string> & lst2){\n    uint32x4_t sum1 = vdupq_n_u32(0);\n    uint32x4_t sum2 = vdupq_n_u32(0);\n\n    for(const auto& str : lst1){\n        size_t len = str.length();\n        uint32x4_t vl = vdupq_n_u32(static_cast<uint32_t>(len));\n        sum1 = vaddq_u32(sum1, vl);\n    }\n\n    for(const auto& str : lst2){\n        size_t len = str.length();\n        uint32x4_t vl = vdupq_n_u32(static_cast<uint32_t>(len));\n        sum2 = vaddq_u32(sum2, vl);\n    }\n\n    uint32_t total1 = vgetq_lane_u32(sum1, 0) + vgetq_lane_u32(sum1, 1) + vgetq_lane_u32(sum1, 2) + vgetq_lane_u32(sum1, 3);\n    uint32_t total2 = vgetq_lane_u32(sum2, 0) + vgetq_lane_u32(sum2, 1) + vgetq_lane_u32(sum2, 2) + vgetq_lane_u32(sum2, 3);\n\n    if(total1 <= total2){\n        return lst1;\n    }\n    else{\n        return lst2;\n    }\n}\n```"}
{"task_id": "SimdBench_98_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <string>\n\nstd::vector<std::string> total_match_simd(const std::vector<std::string> & lst1, const std::vector<std::string> & lst2){\n    uint32x4_t sum1 = vdupq_n_u32(0);\n    uint32x4_t sum2 = vdupq_n_u32(0);\n\n    for(const auto& str : lst1){\n        size_t len = str.length();\n        uint32x4_t vec_len = vdupq_n_u32(static_cast<uint32_t>(len));\n        sum1 = vaddq_u32(sum1, vec_len);\n    }\n\n    for(const auto& str : lst2){\n        size_t len = str.length();\n        uint32x4_t vec_len = vdupq_n_u32(static_cast<uint32_t>(len));\n        sum2 = vaddq_u32(sum2, vec_len);\n    }\n\n    uint32_t total_sum1 = vgetq_lane_u32(sum1, 0) + vgetq_lane_u32(sum1, 1) + vgetq_lane_u32(sum1, 2) + vgetq_lane_u32(sum1, 3);\n    uint32_t total_sum2 = vgetq_lane_u32(sum2, 0) + vgetq_lane_u32(sum2, 1) + vgetq_lane_u32(sum2, 2) + vgetq_lane_u32(sum2, 3);\n\n    if(total_sum1 <= total_sum2){\n        return lst1;\n    }\n    else{\n        return lst2;\n    }\n}\n```"}
{"task_id": "SimdBench_99_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nbool is_simple_power_simd(uint64_t x, uint64_t n){\n    if (n == 0) return x == 0;\n    if (n == 1) return x == 1;\n    if (x == 1) return true;\n\n    uint64x2_t vec_x = vdupq_n_u64(x);\n    uint64x2_t vec_n = vdupq_n_u64(n);\n    uint64x2_t vec_one = vdupq_n_u64(1);\n\n    uint64x2_t current = vec_one;\n    uint64x2_t prev = vec_one;\n\n    for(int i = 0; i < 64; ++i){\n        current = vmulq_u64(current, vec_n);\n        uint64x2_t cmp = vceqq_u64(current, vec_x);\n        if(vgetq_lane_u64(cmp, 0)){\n            return true;\n        }\n        if(vgetq_lane_u64(current, 0) > vgetq_lane_u64(vec_x, 0)){\n            break;\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_99_Neon", "completion": "```c\n#include <arm_neon.h>\n\nbool is_simple_power_simd(uint64_t x, uint64_t n){\n    if (n == 0) return x == 0;\n    if (n == 1) return x == 1;\n    if (x == 1) return true;\n\n    uint64x2_t vec_x = vdupq_n_u64(x);\n    uint64x2_t vec_n = vdupq_n_u64(n);\n    uint64x2_t vec_one = vdupq_n_u64(1);\n\n    uint64x2_t current = vec_one;\n    uint64x2_t prev = vec_one;\n\n    for(int i=0; i<64; ++i){\n        current = vmulq_u64(current, vec_n);\n        if(vgetq_lane_u64(current, 0) > x || vgetq_lane_u64(current, 0) == 0){\n            break;\n        }\n        if(vceqq_u64(current, vec_x)[0]){\n            return true;\n        }\n        prev = current;\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_99_Neon", "completion": "```c\n#include <arm_neon.h>\n\nbool is_simple_power_simd(uint64_t x, uint64_t n){\n    if (n == 0) return x == 0;\n    if (n == 1) return x == 1;\n    if (x == 1) return true;\n\n    uint64x2_t vec_x = vdupq_n_u64(x);\n    uint64x2_t vec_n = vdupq_n_u64(n);\n    uint64x2_t vec_one = vdupq_n_u64(1);\n\n    uint64x2_t current = vec_one;\n    uint64x2_t prev = vec_one;\n\n    for(int i=0; i<64; ++i){\n        current = vmulq_u64(current, vec_n);\n        uint64x2_t comparison = vceqq_u64(current, vec_x);\n        if (vgetq_lane_u64(comparison, 0)) {\n            return true;\n        }\n        if (vgetq_lane_u64(current, 0) < vgetq_lane_u64(prev, 0)) {\n            break;\n        }\n        prev = current;\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_99_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nbool is_simple_power_simd(uint64_t x, uint64_t n){\n    if (n == 0) return x == 0;\n    if (n == 1) return x == 1;\n    if (x == 1) return true;\n\n    uint64x2_t vx = vdupq_n_u64(x);\n    uint64x2_t vn = vdupq_n_u64(n);\n\n    uint64x2_t current = vdupq_n_u64(1);\n    uint64x2_t limit = vcltq_u64(vn, vx) ? vn : vx;\n\n    while (true) {\n        current = vmulq_u64(current, vn);\n        if (vceqq_u64(current, vx).uint8[0]) {\n            return true;\n        }\n        if (vcltq_u64(current, limit).uint8[0]) {\n            break;\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_99_Neon", "completion": "```cpp\n#include <arm_neon.h>\n\nbool is_simple_power_simd(uint64_t x, uint64_t n){\n    if (n == 0) return x == 0;\n    if (n == 1) return x == 1;\n    if (x == 1) return true;\n\n    uint64x2_t vn = vdupq_n_u64(n);\n    uint64x2_t vx = vdupq_n_u64(x);\n\n    uint64x2_t current = vdupq_n_u64(1);\n    uint64x2_t limit = vcltq_u64(vn, vx);\n\n    for(int i = 0; i < 64; ++i){\n        current = vmulq_u64(current, vn);\n        uint64x2_t compare = vceqq_u64(current, vx);\n        if (vgetq_lane_u64(compare, 0)) {\n            return true;\n        }\n        uint64x2_t overflow_check = vcltq_u64(vn, limit);\n        if (!vgetq_lane_u64(overflow_check, 0)) {\n            break;\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_100_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nint hex_key_simd(const std::string & num){\n    if (num.empty()) return 0;\n\n    const uint8_t prime_mask[] = {0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0};\n    int count = 0;\n\n    size_t size = num.size();\n    const unsigned char* data = reinterpret_cast<const unsigned char*>(num.c_str());\n\n    for (size_t i = 0; i <= size - 16; i += 16) {\n        uint8x16_t vec = vld1q_u8(data + i);\n        uint8x16_t lower = vminq_u8(vec, vmovq_n_u8('9'));\n        uint8x16_t upper = vsubq_u8(vec, vmovq_n_u8('A' - 10));\n        uint8x16_t indices = vorrq_u8(vandq_u8(lower, vmovq_n_u8(1)), vandq_u8(upper, vmovq_n_u8(1)));\n\n        uint8x16_t primes = vld1q_u8(reinterpret_cast<const uint8_t*>(prime_mask));\n        uint8x16_t matches = vceqq_u8(indices, primes);\n\n        uint8x16_t ones = vmovq_n_u8(1);\n        uint8x16_t result = vandq_u8(matches, ones);\n\n        uint64x2_t sum = vpaddlq_u32(vmovl_u16(vget_low_u16(vmovn_u32(result))));\n        count += vaddv_u32(vreinterpret_u32_u64(sum));\n    }\n\n    for (size_t i = size - size % 16; i < size; ++i) {\n        char c = num[i];\n        if (('0' <= c && c <= '9' && (c == '2' || c == '3' || c == '5' || c == '7')) ||\n            ('A' <= c && c <= 'F' && (c == 'B' || c == 'D'))) {\n            count++;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_100_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nint hex_key_simd(const std::string & num){\n    if (num.empty()) return 0;\n\n    const uint8_t prime_mask[] = {0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1};\n    int count = 0;\n\n    size_t n = num.size();\n    const unsigned char* data = reinterpret_cast<const unsigned char*>(num.c_str());\n\n    // Process 16 characters at a time\n    size_t i = 0;\n    for (; i <= n - 16; i += 16) {\n        uint8x16_t vec = vld1q_u8(data + i);\n        uint8x16_t converted;\n\n        // Convert hexadecimal characters to values\n        uint8x16_t lt_A = vcgeq_u8(vec, vdupq_n_u8('A'));\n        uint8x16_t sub_A = vsubq_u8(vec, vdupq_n_u8('A' - 10));\n        uint8x16_t sub_0 = vsubq_u8(vec, vdupq_n_u8('0'));\n        converted = vbslq_u8(lt_A, sub_A, sub_0);\n\n        // Load the prime mask and compare\n        uint8x16_t primes = vld1q_u8(prime_mask);\n        uint8x16_t is_prime = vceqq_u8(converted, primes);\n\n        // Count the number of primes\n        uint8x16_t ones = vdupq_n_u8(1);\n        uint8x16_t prime_counts = vandq_u8(is_prime, ones);\n        uint64x2_t sum = vpaddlq_u32(vaddlvq_u8(prime_counts));\n        count += vgetq_lane_u32(sum, 0) + vgetq_lane_u32(sum, 1);\n    }\n\n    // Process remaining characters\n    for (; i < n; ++i) {\n        char c = num[i];\n        int val = (c >= 'A') ? (c - 'A' + 10) : (c - '0');\n        if (val == 2 || val == 3 || val == 5 || val == 7 || val == 11 || val == 13) {\n            count++;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_100_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nint hex_key_simd(const std::string & num){\n    if (num.empty()) return 0;\n\n    const uint8_t prime_mask[] = {0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0};\n    int count = 0;\n\n    size_t size = num.size();\n    const unsigned char* data = reinterpret_cast<const unsigned char*>(num.c_str());\n\n    for (size_t i = 0; i <= size - 16; i += 16) {\n        uint8x16_t vec = vld1q_u8(data + i);\n        uint8x16_t lower = vandq_u8(vec, vmovq_n_u8(0x0F)); // Mask for 0-9\n        uint8x16_t upper = vandq_u8(vsubq_u8(vec, vmovq_n_u8('A' - 10)), vmovq_n_u8(0x0F)); // Mask for A-F\n\n        uint8x16_t lookup_lower = vtbl4q_u8((uint8x16_t *)prime_mask, lower);\n        uint8x16_t lookup_upper = vtbl4q_u8((uint8x16_t *)prime_mask, upper);\n\n        uint8x16_t combined = vorrq_u8(lookup_lower, lookup_upper);\n        uint8x16_t filtered = vceqq_u8(combined, vmovq_n_u8(1));\n\n        uint64x2_t res = vcntq_u8(filtered);\n        count += vaddvq_u8(filtered);\n    }\n\n    for (size_t i = (size / 16) * 16; i < size; ++i) {\n        char c = num[i];\n        if (('0' <= c && c <= '9' && prime_mask[c - '0']) || \n            ('A' <= c && c <= 'F' && prime_mask[c - 'A' + 10])) {\n            count++;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_100_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nint hex_key_simd(const std::string & num){\n    if (num.empty()) return 0;\n\n    const uint8_t prime_mask[] = {0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0};\n    int count = 0;\n\n    size_t size = num.size();\n    const unsigned char* data = reinterpret_cast<const unsigned char*>(num.c_str());\n\n    for (size_t i = 0; i <= size - 16; i += 16) {\n        uint8x16_t vec = vld1q_u8(data + i);\n        uint8x16_t lower = vminq_u8(vec, vdupq_n_u8('9'));\n        uint8x16_t upper = vmaxq_u8(vec, vdupq_n_u8('A'));\n        uint8x16_t indices = vsubq_u8(vec, vdupq_n_u8('0'));\n\n        uint8x16_t mask_lower = vtbl4q_u8((uint8x16_t *)prime_mask, lower);\n        uint8x16_t mask_upper = vtbl4q_u8((uint8x16_t *)prime_mask, vsubq_u8(upper, vdupq_n_u8('A' - '9')));\n\n        uint8x16_t combined_mask = vorrq_u8(mask_lower, mask_upper);\n        uint8x16_t ones = vdupq_n_u8(1);\n        uint8x16_t result = vandq_u8(combined_mask, ones);\n\n        uint64x2_t res_low  = vpaddlq_u32(vreinterpretq_u32_u8(result));\n        uint64x2_t res_high = vpaddlq_u32(res_low);\n        count += vgetq_lane_u32(vreinterpretq_u32_u64(res_high), 0);\n    }\n\n    for (size_t i = (size / 16) * 16; i < size; ++i) {\n        char c = data[i];\n        if ((c >= '0' && c <= '9') || (c >= 'A' && c <= 'F')) {\n            int val = (c <= '9') ? c - '0' : c - 'A' + 10;\n            if (prime_mask[val]) count++;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_100_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nint hex_key_simd(const std::string & num){\n    if (num.empty()) return 0;\n\n    const uint8_t prime_mask[16] = {0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0};\n    int count = 0;\n\n    size_t size = num.size();\n    const uint8_t *data = reinterpret_cast<const uint8_t *>(num.c_str());\n\n    // Handle 16 characters at a time\n    for (size_t i = 0; i + 15 <= size; i += 16) {\n        uint8x16_t vec = vld1q_u8(data + i);\n        uint8x16_t lower = vminq_u8(vec, vmovq_n_u8('9'));\n        uint8x16_t upper = vmaxq_u8(vec, vmovq_n_u8('A'));\n        uint8x16_t adjusted = vsubq_u8(vec, vandq_u8(vcgeq_u8(vec, vmovq_n_u8('A')), vmovq_n_u8('A' - '9' - 1)));\n        uint8x16_t lookup = vtbl4q_u8(vdupq_n_u8(reinterpret_cast<const uint8_t *>(prime_mask)), adjusted);\n        uint8x16_t mask = vcgeq_u8(lookup, vmovq_n_u8(1));\n        count += vaddvq_u8(vandq_u8(mask, vmovq_n_u8(1)));\n    }\n\n    // Handle remaining characters\n    for (size_t i = (size / 16) * 16; i < size; ++i) {\n        uint8_t c = data[i];\n        if (c >= 'A') c -= ('A' - '9' - 1);\n        if (prime_mask[c & 0xF]) count++;\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_101_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nbool is_happy_simd(const std::string & s){\n    size_t len = s.length();\n    if (len < 3) return false;\n\n    const uint8_t *data = reinterpret_cast<const uint8_t *>(s.c_str());\n    size_t i = 0;\n\n    // Process 16 bytes at a time using SIMD\n    for (; i <= len - 4; i += 4) {\n        uint8x16_t v0 = vld1q_u8(data + i);\n        uint8x16_t v1 = vextq_u8(v0, v0, 1); // Shift by 1\n        uint8x16_t v2 = vextq_u8(v0, v0, 2); // Shift by 2\n\n        uint8x16_t cmp1 = vmvnq_u8(vceqq_u8(v0, v1)); // Compare and invert (v0 != v1)\n        uint8x16_t cmp2 = vmvnq_u8(vceqq_u8(v1, v2)); // Compare and invert (v1 != v2)\n\n        uint8x16_t result = vandq_u8(cmp1, cmp2); // All must be true\n        if (vmovemaskq_n_u8(result) != 0xFFFF) {\n            return false;\n        }\n    }\n\n    // Check remaining elements sequentially\n    for (; i <= len - 3; ++i) {\n        if (data[i] == data[i+1] || data[i+1] == data[i+2] || data[i] == data[i+2]) {\n            return false;\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_101_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <cstring>\n\nbool is_happy_simd(const std::string & s){\n    size_t len = s.length();\n    if (len < 3) return false;\n\n    const unsigned char * data = reinterpret_cast<const unsigned char *>(s.c_str());\n\n    for (size_t i = 0; i <= len - 3; i += 4) {\n        uint8x16_t vec = vld1q_u8(data + i);\n        uint8x16_t shifted1 = vextq_u8(vec, vec, 1);\n        uint8x16_t shifted2 = vextq_u8(vec, vec, 2);\n\n        uint8x16_t eq1 = vceqq_u8(vec, shifted1);\n        uint8x16_t eq2 = vceqq_u8(shifted1, shifted2);\n\n        uint8x16_t orr = vorrq_u8(eq1, eq2);\n\n        int64x2_t res = vaddlvq_u8(orrc);\n        if (vget_lane_s64(res, 0) != 0) {\n            return false;\n        }\n    }\n\n    // Handle remaining elements\n    for (size_t i = (len / 4) * 4; i <= len - 3; ++i) {\n        if (data[i] == data[i+1] || data[i] == data[i+2] || data[i+1] == data[i+2]) {\n            return false;\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_101_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nbool is_happy_simd(const std::string & s){\n    size_t len = s.length();\n    if (len < 3) return false;\n\n    const uint8_t *data = reinterpret_cast<const uint8_t *>(s.c_str());\n    for (size_t i = 0; i <= len - 3; i += 4) {\n        uint8x16_t vec = vld1q_u8(data + i);\n        uint8x16_t shifted_1 = vextq_u8(vec, vec, 1);\n        uint8x16_t shifted_2 = vextq_u8(vec, vec, 2);\n\n        uint8x16_t cmp1 = vmvnq_u8(vceqq_u8(vec, shifted_1));\n        uint8x16_t cmp2 = vmvnq_u8(vceqq_u8(shifted_1, shifted_2));\n\n        uint8x16_t result = vandq_u8(cmp1, cmp2);\n\n        uint64x2_t tmp = vreinterpretq_u64_u8(result);\n        uint64x2_t mask = vdupq_n_u64(0xFFFFFFFFFFFFFFFF);\n        uint64x2_t res = vandq_u64(tmp, mask);\n\n        if (vaddvq_u64(res) != 0xFFFFFFFFFFFFFFFF) {\n            return false;\n        }\n    }\n\n    // Handle remaining elements\n    for (size_t i = len - (len % 4); i <= len - 3; ++i) {\n        if (data[i] == data[i+1] || data[i+1] == data[i+2] || data[i] == data[i+2]) {\n            return false;\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_101_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nbool is_happy_simd(const std::string & s){\n    size_t len = s.length();\n    if (len < 3) return false;\n\n    const uint8_t *data = reinterpret_cast<const uint8_t *>(s.c_str());\n    size_t i = 0;\n\n    // Process 4 triplets in parallel using SIMD\n    for (; i <= len - 12; i += 12) {\n        uint8x16_t v0 = vld1q_u8(data + i);\n        uint8x16_t v1 = vld1q_u8(data + i + 1);\n        uint8x16_t v2 = vld1q_u8(data + i + 2);\n\n        uint8x16_t eq01 = vcgeq_u8(v0, v1); // Check v0 == v1\n        uint8x16_t eq12 = vcgeq_u8(v1, v2); // Check v1 == v2\n        uint8x16_t eq02 = vcgeq_u8(v0, v2); // Check v0 == v2\n\n        uint8x16_t or01_12 = vorrq_u8(eq01, eq12);\n        uint8x16_t any_eq = vorrq_u8(or01_12, eq02);\n\n        if (vminvq_u8(any_eq) != 0) return false;\n    }\n\n    // Scalar check for remaining elements\n    for (; i <= len - 3; ++i) {\n        if (data[i] == data[i+1] || data[i] == data[i+2] || data[i+1] == data[i+2]) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_101_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <cstring>\n\nbool is_happy_simd(const std::string & s){\n    size_t len = s.length();\n    if (len < 3) return false;\n\n    const uint8_t *data = reinterpret_cast<const uint8_t *>(s.c_str());\n    size_t i = 0;\n\n    // Process 16 bytes at a time using SIMD\n    for (; i <= len - 4; i += 4) {\n        uint8x16_t v = vld1q_u8(data + i);\n        uint8x16_t shifted_1 = vextq_u8(v, v, 1);\n        uint8x16_t shifted_2 = vextq_u8(v, v, 2);\n\n        uint8x16_t eq_1 = vceqq_u8(v, shifted_1);\n        uint8x16_t eq_2 = vceqq_u8(shifted_1, shifted_2);\n\n        uint8x16_t orr = vorrq_u8(eq_1, eq_2);\n        int64x2_t any_true = vaddlvq_u8(orr);\n\n        if (vget_lane_u64(any_true, 0) != 0) return false;\n    }\n\n    // Check remaining elements sequentially\n    for (; i <= len - 3; ++i) {\n        if (data[i] == data[i+1] || data[i] == data[i+2] || data[i+1] == data[i+2]) {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_102_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nbool prime_length_simd(const std::string & str){\n    int n = str.length();\n    if (n < 2) return false;\n    if (n == 2) return true;\n    if ((n & 1) == 0) return false;\n\n    const int limit = (int)sqrt((double)n);\n    int16x8_t vec_n = vdupq_n_s16(n);\n\n    for(int i = 3; i <= limit; i += 2){\n        if( (i & 0x7) == 0 || (i & 0xF) == 0 ){\n            int16x8_t vec_i = vdupq_n_s16(i);\n            uint16x8_t res = vcgeq_s16(vec_n, vec_i);\n            int mask = vaddvq_u16(vreinterpretq_u16_s16(vec_i));\n            if( (mask & res[0]) == 0 ) return false;\n        }\n        else{\n            if( n % i == 0 ) return false;\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_102_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n#include <cmath>\n\nbool is_prime(size_t n) {\n    if (n <= 1) return false;\n    if (n == 2 || n == 3) return true;\n    if ((n & 1) == 0) return false;\n\n    uint32x4_t factors = vdupq_n_u32(0);\n    size_t limit = static_cast<size_t>(std::sqrt(n));\n\n    for (size_t i = 1; i <= limit / 4; ++i) {\n        uint32x4_t candidates = vdupq_n_u32(4 * i + 1);\n        candidates = vaddq_u32(candidates, vdupq_n_u32(2));\n        uint32x4_t mods = vmulq_u32(candidates, vcvtq_u32_f32(vdupq_n_f32(static_cast<float>(n))));\n        mods = vshrq_n_u32(mods, 32 - 5);\n        uint32x4_t remainders = vsubq_u32(vdupq_n_u32(n), vmulq_u32(mods, candidates));\n        uint32x4_t zeros = vdupq_n_u32(0);\n        if (vminvq_u32(remainders) == 0) return false;\n    }\n    return true;\n}\n\nbool prime_length_simd(const std::string & str){\n    size_t length = str.length();\n    return is_prime(length);\n}\n```"}
{"task_id": "SimdBench_102_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n#include <cmath>\n\nbool is_divisible(uint32x4_t candidate, uint32x4_t divisor) {\n    uint32x4_t remainder = vmulq_u32(divisor, vrndiq_u32(vcvqq_f32_u32(divisor)));\n    remainder = vsubq_u32(candidate, remainder);\n    return !vany lane(remainder == vmovq_n_u32(0));\n}\n\nbool prime_length_simd(const std::string & str){\n    int n = str.length();\n    if (n < 2) return false;\n    if (n == 2) return true;\n    if (n % 2 == 0) return false;\n\n    int limit = static_cast<int>(std::sqrt(n));\n    uint32x4_t vec_n = vdupq_n_u32(n);\n\n    for(int i = 3; i <= limit; i += 4){\n        uint32x4_t divisors = vdupq_n_u32(i);\n        if(is_divisible(vec_n, divisors)) return false;\n    }\n\n    // Handle remaining divisors that didn't fit into SIMD registers\n    for(int i = ((limit / 4) * 4) + 1; i <= limit; ++i){\n        if(n % i == 0) return false;\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_102_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n#include <cmath>\n\nbool is_prime(int n) {\n    if (n <= 1) return false;\n    if (n == 2 || n == 3) return true;\n    if (n % 2 == 0 || n % 3 == 0) return false;\n    int64x2_t sqrt_n = vmov_n_s64(static_cast<int64_t>(std::sqrt(n)));\n    int64x2_t num = vdupq_n_s64(5);\n    int64x2_t step = vdupq_n_s64(2);\n    int64x2_t limit = vdupq_n_s64(sqrt_n[0]);\n    \n    while (true) {\n        uint64x2_t cond = vcgeq_s64(num, limit);\n        if (vget_lane_u64(vmovn_u64(cond), 0)) break;\n        \n        uint64x2_t mod_results = vmulq_s64(num, vmov_n_s64(n));\n        mod_results = vmulq_s64(mod_results, vmov_n_s64(n));\n        mod_results = vmlsq_s64(mod_results, vmov_n_s64(n), vmulq_s64(num, num));\n        \n        if (vget_lane_s64(mod_results, 0) == 0) return false;\n        \n        num = vaddq_s64(num, step);\n        step = vdupq_n_s64(4 - 2 * (vget_lane_s64(step, 0) == 2));\n    }\n    return true;\n}\n\nbool prime_length_simd(const std::string & str){\n    int length = str.length();\n    return is_prime(length);\n}\n```"}
{"task_id": "SimdBench_102_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n#include <cmath>\n\nbool is_prime(int n) {\n    if (n <= 1) return false;\n    if (n == 2 || n == 3) return true;\n    if ((n & 1) == 0) return false;\n    int sqrt_n = static_cast<int>(std::sqrt(n));\n    uint32x4_t vec_n = vdupq_n_u32(n);\n    for(int i = 3; i <= sqrt_n; i += 4){\n        uint32x4_t vec_i = vld1q_u32((uint32_t*)&i);\n        uint32x4_t mod_results = vmulq_u32(vec_n, vec_i);\n        uint32x4_t cmp_results = vceqq_u32(mod_results, vec_i);\n        if(vmaxvq_u32(cmp_results)) return false;\n    }\n    return true;\n}\n\nbool prime_length_simd(const std::string & str){\n    int length = str.length();\n    return is_prime(length);\n}\n```"}
{"task_id": "SimdBench_103_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nstd::string solve_simd(uint64_t N){\n    uint32x2_t v_n = vdup_n_u32(N);\n    uint32x2_t sum_digits = vmov_n_u32(0);\n\n    while (true) {\n        uint32x2_t remainder = vadd_u32(v_n, vmov_n_u32(9));\n        uint32x2_t quotient = vshl_u32(v_n, vmov_n_u32(-1));\n        sum_digits = vadd_u32(sum_digits, vsub_u32(remainder, vmul_u32(quotient, vmov_n_u32(10))));\n        v_n = quotient;\n\n        if (vminv_u32(v_n) == 0) {\n            break;\n        }\n    }\n\n    int sum = vget_lane_u32(sum_digits, 0) + vget_lane_u32(sum_digits, 1);\n    std::string binary_sum;\n    do {\n        binary_sum = (sum % 2 ? \"1\" : \"0\") + binary_sum;\n        sum /= 2;\n    } while (sum > 0);\n\n    return binary_sum;\n}\n```"}
{"task_id": "SimdBench_103_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nstd::string solve_simd(uint64_t N){\n    uint32x2_t digits = vdup_n_u32(0);\n    uint32x2_t temp;\n\n    while (N > 0) {\n        temp = vdup_n_u32(N % 10);\n        digits = vadd_u32(digits, temp);\n        N /= 10;\n    }\n\n    uint32_t sum = vget_lane_u32(digits, 0) + vget_lane_u32(digits, 1);\n\n    std::string binary Representation = \"\";\n    uint32_t mask = 1 << 31;\n    for (int i = 0; i < 32; ++i) {\n        if (sum & mask)\n            binary_representation += '1';\n        else\n            binary_representation += '0';\n        mask >>= 1;\n    }\n\n    // Remove leading zeros\n    size_t pos = binary_representation.find_first_of('1');\n    if (pos != std::string::npos) {\n        binary_representation = binary_representation.substr(pos);\n    } else {\n        binary_representation = \"0\";\n    }\n\n    return binary_representation;\n}\n```"}
{"task_id": "SimdBench_103_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nstd::string solve_simd(uint64_t N){\n    uint32x2_t digits = vdup_n_u32(0);\n    uint32x2_t n = vdup_n_u32(N);\n\n    while (vget_lane_u32(n, 0) != 0 || vget_lane_u32(n, 1) != 0) {\n        uint32x2_t remainder = vmovn_u64(vshl_u64(vcvtuq_u64(vreinterpret_u16_u32(n)), 1));\n        digits = vadd_u32(digits, remainder);\n        n = vrshr_u32(n, 1);\n    }\n\n    uint32_t sum = vget_lane_u32(digits, 0) + vget_lane_u32(digits, 1);\n    std::string binary;\n    if (sum == 0) binary = \"0\";\n    else {\n        while (sum > 0) {\n            binary = std::to_string(sum % 2) + binary;\n            sum /= 2;\n        }\n    }\n    return binary;\n}\n```"}
{"task_id": "SimdBench_103_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nstd::string solve_simd(uint64_t N){\n    uint32x2_t v_n = vdup_n_u32(N & 0xFFFFFFFF);\n    uint32x2_t sum_digits = vmov_n_u32(0);\n\n    for (int i = 0; i < 10; ++i) {\n        uint32x2_t digits = vand_u32(v_n, vmov_n_u32(0x0F));\n        sum_digits = vadd_u32(sum_digits, digits);\n        v_n = vshrq_n_u32(v_n, 4);\n    }\n\n    uint32x2_t high_sum = vpadd_u32(sum_digits, sum_digits);\n    uint32_t total_sum = vget_lane_u32(high_sum, 0);\n\n    std::string binary_result = \"\";\n    uint32_t temp = total_sum;\n    if (temp == 0) binary_result = \"0\";\n    while (temp > 0) {\n        binary_result = ((temp & 1) ? '1' : '0') + binary_result;\n        temp >>= 1;\n    }\n    return binary_result;\n}\n```"}
{"task_id": "SimdBench_103_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nstd::string solve_simd(uint64_t N){\n    uint32x2_t digits = vdup_n_u32(0);\n    uint32x2_t temp;\n\n    while(N > 0){\n        temp = vdup_n_u32(N % 10);\n        digits = vadd_u32(digits, temp);\n        N /= 10;\n    }\n\n    uint32_t sum = vget_lane_u32(digits, 0) + vget_lane_u32(digits, 1);\n\n    std::string binary Representation = \"\";\n    while(sum > 0){\n        binary_representation = (sum % 2 ? \"1\" : \"0\") + binary_representation;\n        sum /= 2;\n    }\n\n    return binary_representation.empty() ? \"0\" : binary_representation;\n}\n```"}
{"task_id": "SimdBench_104_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nint add_simd(std::vector<int> lst) {\n    int n = lst.size();\n    if (n == 0) return 0;\n\n    int total_sum = 0;\n    int32x4_t sum_vec = vdupq_n_s32(0);\n\n    // Process elements in chunks of 8 (since we need odd indices)\n    for (size_t i = 1; i < n; i += 8) {\n        // Load 4 elements starting from index i and i+4\n        int32x4_t vec1 = vld1q_s32(&lst[i]);\n        int32x4_t vec2 = (i + 4 < n) ? vld1q_s32(&lst[i + 4]) : vdupq_n_s32(0);\n\n        // Create masks for odd indices (1, 3, 5, 7...)\n        uint32x4_t mask1 = vmovq_n_u32(0xFFFFFFFF);\n        mask1 = vandq_u32(mask1, vmovq_n_u32(0xAAAAAAAA));\n        uint32x4_t mask2 = (i + 4 < n) ? vmovq_n_u32(0xFFFFFFFF) : vmovq_n_u32(0);\n        mask2 = vandq_u32(mask2, vmovq_n_u32(0xAAAAAAAA));\n\n        // Check if the loaded values are even\n        int32x4_t even_mask1 = vmovq_n_s32(0);\n        even_mask1 = vandq_u32(vreinterpretq_u32_s32(vec1), vmovq_n_u32(1));\n        even_mask1 = vceqq_s32(even_mask1, vmovq_n_s32(0));\n        int32x4_t even_mask2 = vmovq_n_s32(0);\n        if (i + 4 < n) {\n            even_mask2 = vandq_u32(vreinterpretq_u32_s32(vec2), vmovq_n_u32(1));\n            even_mask2 = vceqq_s32(even_mask2, vmovq_n_s32(0));\n        }\n\n        // Combine masks to get valid even numbers at odd indices\n        uint32x4_t combined_mask1 = vandq_u32(mask1, even_mask1);\n        uint32x4_t combined_mask2 = vandq_u32(mask2, even_mask2);\n\n        // Select valid numbers using the combined mask\n        int32x4_t selected1 = vandq_s32(vec1, vreinterpretq_s32_u32(combined_mask1));\n        int32x4_t selected2 = vandq_s32(vec2, vreinterpretq_s32_u32(combined_mask2));\n\n        // Add selected numbers to the sum vector\n        sum_vec = vaddq_s32(sum_vec, selected1);\n        if (i + 4 < n) {\n            sum_vec = vaddq_s32(sum_vec, selected2);\n        }\n    }\n\n    // Horizontal sum of the result vector\n    int32x2_t sum_low = vadd_s32(vget_low_s32(sum_vec), vget_high_s32(sum_vec));\n    int32x2_t sum_all = vpadd_s32(sum_low, sum_low);\n\n    total_sum += vget_lane_s32(sum_all, 0);\n\n    return total_sum;\n}\n```"}
{"task_id": "SimdBench_104_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nint add_simd(std::vector<int> lst) {\n    int n = lst.size();\n    if (n == 0) return 0;\n\n    int total_sum = 0;\n    int32x4_t sum_vec = vdupq_n_s32(0);\n\n    for(int i = 1; i < n; i += 2){\n        int32x4_t vec = vld1q_s32(reinterpret_cast<const int32_t*>(&lst[i]));\n        int32x4_t even_mask = vmovq_n_s32(lst[i] % 2 == 0 ? -1 : 0);\n        int32x4_t filtered = vandq_s32(vec, even_mask);\n        sum_vec = vaddq_s32(sum_vec, filtered);\n    }\n\n    int32x2_t sum_low = vadd_s32(vget_low_s32(sum_vec), vget_high_s32(sum_vec));\n    int32x2_t sum_all = vpadd_s32(sum_low, sum_low);\n\n    total_sum += vget_lane_s32(sum_all, 0);\n\n    return total_sum;\n}\n```"}
{"task_id": "SimdBench_104_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nint add_simd(std::vector<int> lst) {\n    int sum = 0;\n    size_t size = lst.size();\n    \n    if (size == 0) return 0;\n\n    // Handle cases where the number of elements is less than the SIMD width\n    const size_t vec_size = 4; // Process 4 integers at a time\n    size_t i = 1; // Start from the first odd index\n\n    for (; i + vec_size <= size; i += vec_size * 2) {\n        int32x4_t vload = vld1q_s32(&lst[i]); // Load 4 elements starting from an odd index\n        int32x4_t even_mask = vmovq_n_s32(1); // Create a mask to identify even numbers\n        int32x4_t is_even = vandq_s32(vcmpgeq_f32(vcvtq_f32_s32(vload), vcvtq_f32_s32(vdupq_n_s32(0))), even_mask);\n        int32x4_t filtered = vandq_s32(vload, is_even); // Filter out non-even numbers\n        int32x4_t reduced = vpaddlq_s32(filtered); // Perform parallel addition\n        sum += vgetq_lane_s32(reduced, 0) + vgetq_lane_s32(reduced, 1) + vgetq_lane_s32(reduced, 2) + vgetq_lane_s32(reduced, 3);\n    }\n\n    // Scalar processing for remaining elements\n    for (; i < size; i += 2) {\n        if (i % 2 != 0 && lst[i] % 2 == 0) {\n            sum += lst[i];\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_104_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nint add_simd(std::vector<int> lst) {\n    int n = lst.size();\n    if (n == 0) return 0;\n\n    int32x4_t sum_vec = vdupq_n_s32(0);\n    int32x4_t zero = vdupq_n_s32(0);\n\n    for(int i = 1; i < n; i += 2){\n        int32x4_t vec = vld1q_s32(&lst[i]);\n        int32x4_t mask = vandq_s32(vec, vdupq_n_s32(1));\n        int32x4_t is_even = vceqq_s32(mask, zero);\n        int32x4_t even_vals = vandq_s32(vec, is_even);\n        sum_vec = vaddq_s32(sum_vec, even_vals);\n    }\n\n    int32x2_t sum_low = vadd_s32(vget_low_s32(sum_vec), vget_high_s32(sum_vec));\n    int32x2_t sum_all = vpadd_s32(sum_low, sum_low);\n\n    return sum_all[0];\n}\n```"}
{"task_id": "SimdBench_104_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nint add_simd(std::vector<int> lst) {\n    int size = lst.size();\n    if (size == 0) return 0;\n\n    int32x4_t sum_vec = vdupq_n_s32(0);\n    int32x4_t zero = vdupq_n_s32(0);\n\n    for(int i = 1; i < size; i += 2){\n        int32x4_t vec = vld1q_s32(&lst[i]);\n        int32x4_t mask = vandq_s32(vec, vdupq_n_s32(1));\n        int32x4_t even = vceqq_s32(mask, zero);\n        int32x4_t filtered = vandq_s32(vec, vmovq_n_s32(even[0]));\n        sum_vec = vaddq_s32(sum_vec, filtered);\n    }\n\n    int32x2_t sum_low = vadd_s32(vget_low_s32(sum_vec), vget_high_s32(sum_vec));\n    int32x2_t sum_all = vpadd_s32(sum_low, sum_low);\n\n    return sum_all[0];\n}\n```"}
{"task_id": "SimdBench_105_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <cstring>\n\nstd::string encrypt_simd(const std::string & s){\n    int shift = 4; // 2 * 2\n    size_t len = s.size();\n    size_t vec_len = len / 16 * 16;\n    std::string result(len, '\\0');\n    \n    for (size_t i = 0; i < vec_len; i += 16) {\n        uint8x16_t vec = vld1q_u8(reinterpret_cast<const uint8_t*>(&s[i]));\n        uint8x16_t shifted_vec = vaddq_u8(vec, vdupq_n_u8(shift));\n        \n        // Wrap around if greater than 'z'\n        uint8x16_t mask_z = vcgeq_u8(shifted_vec, vdupq_n_u8('z'));\n        shifted_vec = vsubq_u8(shifted_vec, vandq_u8(mask_z, vdupq_n_u8(26)));\n        \n        // Keep non-alphabetic characters unchanged\n        uint8x16_t mask_a = vcltq_u8(vec, vdupq_n_u8('a'));\n        uint8x16_t mask_z_inv = vcleq_u8(vec, vdupq_n_u8('z'));\n        uint8x16_t combined_mask = vbicq_u8(mask_z_inv, mask_a);\n        shifted_vec = vbslq_u8(combined_mask, shifted_vec, vec);\n        \n        vst1q_u8(reinterpret_cast<uint8_t*>(&result[i]), shifted_vec);\n    }\n    \n    // Handle remaining characters\n    for (size_t i = vec_len; i < len; ++i) {\n        char c = s[i];\n        if (c >= 'a' && c <= 'z') {\n            c = ((c - 'a' + shift) % 26) + 'a';\n        }\n        result[i] = c;\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_105_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nstd::string encrypt_simd(const std::string & s){\n    int shift = 4; // 2 * 2\n    std::string result;\n    result.reserve(s.size());\n\n    const uint8x16_t shift_vec = vdupq_n_u8(shift);\n    const uint8x16_t lower_a = vdupq_n_u8('a');\n    const uint8x16_t lower_z = vdupq_n_u8('z');\n    const uint8x16_t upper_a = vdupq_n_u8('A');\n    const uint8x16_t upper_z = vdupq_n_u8('Z');\n\n    for (size_t i = 0; i < s.size(); i += 16) {\n        uint8x16_t chars = vld1q_u8(reinterpret_cast<const uint8_t*>(&s[i]));\n\n        uint8x16_t is_lower = vcgeq_u8(chars, lower_a);\n        is_lower = vandq_u8(is_lower, vcleq_u8(chars, lower_z));\n\n        uint8x16_t is_upper = vcgeq_u8(chars, upper_a);\n        is_upper = vandq_u8(is_upper, vcleq_u8(chars, upper_z));\n\n        uint8x16_t shifted = vaddq_u8(chars, shift_vec);\n\n        uint8x16_t wrap_lower = vsubq_u8(shifted, vsubq_u8(lower_z, lower_a));\n        uint8x16_t wrap_upper = vsubq_u8(shifted, vsubq_u8(upper_z, upper_a));\n\n        uint8x16_t lower_mask = vandq_u8(vreinterpretq_u8_u32(vmovl_u8(vget_low_u8(is_lower))), vcltq_u8(shifted, lower_a));\n        uint8x16_t upper_mask = vandq_u8(vreinterpretq_u8_u32(vmovl_u8(vget_low_u8(is_upper))), vcltq_u8(shifted, upper_a));\n\n        shifted = vbslq_u8(is_lower, vbslq_u8(lower_mask, wrap_lower, shifted), chars);\n        shifted = vbslq_u8(is_upper, vbslq_u8(upper_mask, wrap_upper, shifted), shifted);\n\n        uint8_t buffer[16];\n        vst1q_u8(buffer, shifted);\n\n        for (size_t j = 0; j < 16 && i + j < s.size(); ++j) {\n            result += static_cast<char>(buffer[j]);\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_105_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nstd::string encrypt_simd(const std::string & s){\n    int shift = 4; // 2 * 2\n    size_t size = s.size();\n    std::string result(size, '\\0');\n    \n    for (size_t i = 0; i < size; i += 16) {\n        size_t chunk_size = std::min<size_t>(16, size - i);\n        uint8x16_t vec = vld1q_u8(reinterpret_cast<const uint8_t*>(&s[i]));\n        \n        // Perform the rotation\n        uint8x16_t shifted = vaddq_u8(vec, vdupq_n_u8(shift));\n        \n        // Wrap around if greater than 'z'\n        uint8x16_t mask_greater_z = vcgeq_u8(shifted, vdupq_n_u8('z'));\n        shifted = vsubq_u8(shifted, vandq_u8(mask_greater_z, vdupq_n_u8(26)));\n        \n        // Wrap around if less than 'a'\n        uint8x16_t mask_less_a = vcltq_u8(shifted, vdupq_n_u8('a'));\n        shifted = vaddq_u8(shifted, vandq_u8(mask_less_a, vdupq_n_u8(26)));\n        \n        vst1q_u8(reinterpret_cast<uint8_t*>(&result[i]), shifted);\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_105_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nstd::string encrypt_simd(const std::string & s){\n    int shift = 4; // 2 * 2\n    size_t size = s.size();\n    std::string result(size, '\\0');\n    \n    for (size_t i = 0; i < size; i += 16) {\n        size_t chunk_size = std::min<size_t>(16, size - i);\n        \n        uint8x16_t vec = vdupq_n_u8(0);\n        if (chunk_size >= 1) vec = vsetq_lane_u8(s[i + 0], vec, 0);\n        if (chunk_size >= 2) vec = vsetq_lane_u8(s[i + 1], vec, 1);\n        if (chunk_size >= 3) vec = vsetq_lane_u8(s[i + 2], vec, 2);\n        if (chunk_size >= 4) vec = vsetq Lane_u8(s[i + 3], vec, 3);\n        if (chunk_size >= 5) vec = vsetq_lane_u8(s[i + 4], vec, 4);\n        if (chunk_size >= 6) vec = vsetq_lane_u8(s[i + 5], vec, 5);\n        if (chunk_size >= 7) vec = vsetq_lane_u8(s[i + 6], vec, 6);\n        if (chunk_size >= 8) vec = vsetq_lane_u8(s[i + 7], vec, 7);\n        if (chunk_size >= 9) vec = vsetq_lane_u8(s[i + 8], vec, 8);\n        if (chunk_size >= 10) vec = vsetq_lane_u8(s[i + 9], vec, 9);\n        if (chunk_size >= 11) vec = vsetq_lane_u8(s[i + 10], vec, 10);\n        if (chunk_size >= 12) vec = vsetq_lane_u8(s[i + 11], vec, 11);\n        if (chunk_size >= 13) vec = vsetq_lane_u8(s[i + 12], vec, 12);\n        if (chunk_size >= 14) vec = vsetq_lane_u8(s[i + 13], vec, 13);\n        if (chunk_size >= 15) vec = vsetq_lane_u8(s[i + 14], vec, 14);\n        if (chunk_size >= 16) vec = vsetq_lane_u8(s[i + 15], vec, 15);\n\n        uint8x16_t shifted_vec = vaddq_u8(vec, vdupq_n_u8(shift));\n        \n        for (size_t j = 0; j < chunk_size; ++j) {\n            uint8_t c = vgetq_lane_u8(shifted_vec, j);\n            if ((c >= 'a' && c <= 'z') || (c >= 'A' && c <= 'Z')) {\n                result[i + j] = c;\n            } else {\n                uint8_t original_c = vgetq_lane_u8(vec, j);\n                result[i + j] = original_c;\n            }\n        }\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_105_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nstd::string encrypt_simd(const std::string & s){\n    int shift = 4; // 2 * 2\n    const uint8_t min_char = 'a';\n    const uint8_t max_char = 'z';\n    const uint8_t num_chars = (max_char - min_char + 1);\n\n    size_t len = s.length();\n    std::string result(len, '\\0');\n\n    for (size_t i = 0; i < len; i += 16) {\n        size_t chunk_size = std::min<size_t>(16, len - i);\n        \n        uint8x16_t input_vec = vdupq_n_u8(0);\n        for (size_t j = 0; j < chunk_size; ++j) {\n            input_vec = vsetq_lane_u8(s[i + j], input_vec, j);\n        }\n\n        uint8x16_t shifted_vec = vaddq_u8(input_vec, vdupq_n_u8(shift));\n\n        uint8x16_t mask_lower = vcltq_u8(input_vec, vdupq_n_u8(min_char));\n        uint8x16_t mask_upper = vcgtq_u8(shifted_vec, vdupq_n_u8(max_char));\n\n        uint8x16_t adjusted_vec = vsubq_u8(shifted_vec, vmulq_n_u8(mask_upper, num_chars));\n        uint8x16_t result_vec = vbslq_u8(mask_lower, input_vec, adjusted_vec);\n\n        for (size_t j = 0; j < chunk_size; ++j) {\n            result[i + j] = static_cast<char>(vgetq_lane_u8(result_vec, j));\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_106_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nstd::string encode_simd(const std::string & message){\n    const uint8_t vowels[] = {'a','e','i','o','u','A','E','I','O','U'};\n    const uint8_t repl_vowels[] = {'c','g','k','q','w','C','G','K','Q','W'};\n    std::string result;\n    result.reserve(message.size());\n\n    for (size_t i = 0; i < message.size(); i += 16) {\n        size_t chunk_size = std::min<size_t>(message.size() - i, 16);\n        uint8x16_t vec = vld1q_u8(reinterpret_cast<const uint8_t*>(&message[i]));\n\n        // Swap case\n        uint8x16_t lower_mask = vcgeq_u8(vec, vdupq_n_u8('a'));\n        lower_mask = vandq_u8(lower_mask, vcleq_u8(vec, vdupq_n_u8('z')));\n        uint8x16_t upper_mask = vcgeq_u8(vec, vdupq_n_u8('A'));\n        upper_mask = vandq_u8(upper_mask, vcleq_u8(vec, vdupq_n_u8('Z')));\n\n        uint8x16_t swapped_case = vsubq_u8(vaddq_u8(vec, vreinterpretq_u8_s8(vshrq_n_s8(vreinterpretq_s8_u8(vec), 5) & 0x20)), vdupq_n_u8(' '));\n\n        // Replace vowels\n        uint8x16_t vowel_repl = vec;\n        for(int j=0; j<10; ++j){\n            uint8x16_t vowel = vdupq_n_u8(vowels[j]);\n            uint8x16_t replace = vdupq_n_u8(repl_vowels[j]);\n            uint8x16_t mask = vceqq_u8(vec, vowel);\n            vowel_repl = vbslq_u8(mask, replace, vowel_repl);\n        }\n\n        // Combine results\n        uint8x16_t res = vbslq_u8(vorrq_u8(lower_mask, upper_mask), swapped_case, vowel_repl);\n\n        // Store the result\n        alignas(16) uint8_t temp[16];\n        vst1q_u8(temp, res);\n        result.append(reinterpret_cast<char*>(temp), chunk_size);\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_106_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nstd::string encode_simd(const std::string & message){\n    const uint8_t vowels[] = {'a','e','i','o','u','A','E','I','O','U'};\n    const uint8_t vowel_replacements[] = {'c','g','k','q','w','C','G','K','Q','W'};\n    const uint8_t lower_to_upper = 'A' - 'a';\n    const uint8_t upper_to_lower = 'a' - 'A';\n\n    std::string result;\n    result.reserve(message.size());\n\n    size_t i = 0;\n    for (; i + 15 < message.size(); i += 16) {\n        uint8x16_t vec = vld1q_u8(reinterpret_cast<const uint8_t*>(&message[i]));\n        uint8x16_t is_upper = vcgeq_u8(vec, vdupq_n_u8('A')) & vcleq_u8(vec, vdupq_n_u8('Z'));\n        uint8x16_t is_lower = vcgeq_u8(vec, vdupq_n_u8('a')) & vcleq_u8(vec, vdupq_n_u8('z'));\n\n        // Swap case\n        uint8x16_t swap_mask = vbicq_u8(is_upper, is_lower);\n        uint8x16_t swapped_case = vbslq_u8(swap_mask, veorq_u8(vec, vdupq_n_u8(lower_to_upper)), veorq_u8(vec, vdupq_n_u8(upper_to_lower)));\n\n        // Replace vowels\n        uint8x16_t replaced_vowels = vec;\n        for (size_t j = 0; j < 10; ++j) {\n            uint8x16_t is_vowel = vceqq_u8(vec, vdupq_n_u8(vowels[j]));\n            replaced_vowels = vbslq_u8(is_vowel, vdupq_n_u8(vowel_replacements[j]), replaced_vowels);\n        }\n\n        // Store result\n        uint8_t res[16];\n        vst1q_u8(res, replaced_vowels);\n        result.append(reinterpret_cast<char*>(res), 16);\n    }\n\n    // Handle remaining characters\n    for (; i < message.size(); ++i) {\n        char c = message[i];\n        if (c >= 'A' && c <= 'Z') {\n            c = static_cast<char>(c + ('a' - 'A'));\n        } else if (c >= 'a' && c <= 'z') {\n            c = static_cast<char>(c + ('A' - 'a'));\n        }\n        for (size_t j = 0; j < 10; ++j) {\n            if (c == vowels[j]) {\n                c = vowel_replacements[j];\n                break;\n            }\n        }\n        result += c;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_106_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nstd::string encode_simd(const std::string & message){\n    const uint8_t vowels_lower[] = { 'a', 'e', 'i', 'o', 'u' };\n    const uint8_t vowels_upper[] = { 'A', 'E', 'I', 'O', 'U' };\n    const uint8_t replace_lower[] = { 'c', 'g', 'k', 'q', 'w' };\n    const uint8_t replace_upper[] = { 'C', 'G', 'K', 'Q', 'W' };\n\n    size_t len = message.size();\n    std::string result;\n    result.reserve(len);\n\n    for (size_t i = 0; i < len; i += 16) {\n        size_t chunk_size = std::min<size_t>(len - i, 16);\n        uint8x16_t vec = vld1q_u8(reinterpret_cast<const uint8_t*>(&message[i]));\n\n        // Swap case\n        uint8x16_t lower_mask = vcgeq_u8(vec, vdupq_n_u8('a'));\n        uint8x16_t upper_mask = vcleq_u8(vec, vdupq_n_u8('Z'));\n        uint8x16_t is_lower = vandq_u8(lower_mask, vcgeq_u8(vec, vdupq_n_u8('z')));\n        uint8x16_t is_upper = vandq_u8(upper_mask, vcleq_u8(vec, vdupq_n_u8('A')));\n\n        uint8x16_t swap_case = vbitwise_select(is_lower, vsubq_u8(vec, vdupq_n_u8(32)), \n                                              vbitwise_select(is_upper, vaddq_u8(vec, vdupq_n_u8(32)), vec));\n\n        // Replace vowels\n        for (int j = 0; j < 5; ++j) {\n            uint8x16_t vowel_lower = vdupq_n_u8(vowels_lower[j]);\n            uint8x16_t vowel_upper = vdupq_n_u8(vowels_upper[j]);\n            uint8x16_t replace_lower_val = vdupq_n_u8(replace_lower[j]);\n            uint8x16_t replace_upper_val = vdupq_n_u8(replace_upper[j]);\n\n            uint8x16_t match_lower = vmovq_n_u8(vceqq_u8(swap_case, vowel_lower));\n            uint8x16_t match_upper = vmovq_n_u8(vceqq_u8(swap_case, vowel_upper));\n\n            swap_case = vbitwise_select(match_lower, replace_lower_val, swap_case);\n            swap_case = vbitwise_select(match_upper, replace_upper_val, swap_case);\n        }\n\n        // Store results\n        if (chunk_size == 16) {\n            uint8_t buffer[16];\n            vst1q_u8(buffer, swap_case);\n            result.append(reinterpret_cast<char*>(buffer), 16);\n        } else {\n            uint8_t buffer[16];\n            vst1q_u8(buffer, swap_case);\n            result.append(reinterpret_cast<char*>(buffer), chunk_size);\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_106_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nstd::string encode_simd(const std::string & message){\n    const uint8_t vowels_lower[] = { 'a', 'e', 'i', 'o', 'u' };\n    const uint8_t vowels_upper[] = { 'A', 'E', 'I', 'O', 'U' };\n    const uint8_t replace_lower[] = { 'c', 'g', 'k', 'q', 'w' };\n    const uint8_t replace_upper[] = { 'C', 'G', 'K', 'Q', 'W' };\n\n    std::string result;\n    result.reserve(message.size());\n\n    size_t i = 0;\n    while (i <= message.size() - 16) {\n        uint8x16_t vec = vld1q_u8(reinterpret_cast<const uint8_t*>(&message[i]));\n\n        // Swap case\n        uint8x16_t lower_mask = vcgeq_u8(vec, vdupq_n_u8('a'));\n        uint8x16_t upper_mask = vcgeq_u8(vec, vdupq_n_u8('A'));\n        uint8x16_t letter_mask = vandq_u8(lower_mask, vcleq_u8(vec, vdupq_n_u8('z')));\n\n        uint8x16_t lower_case = vaddq_u8(vec, vdupq_n_u8('A' - 'a'));\n        uint8x16_t upper_case = vsubq_u8(vec, vdupq_n_u8('A' - 'a'));\n\n        uint8x16_t swapped = vbslq_u8(letter_mask, vbslq_u8(lower_mask, upper_case, lower_case), vec);\n\n        // Replace vowels\n        for (size_t j = 0; j < 5; ++j) {\n            uint8x16_t vowel_lower = vdupq_n_u8(vowels_lower[j]);\n            uint8x16_t vowel_upper = vdupq_n_u8(vowels_upper[j]);\n            uint8x16_t replace_l = vdupq_n_u8(replace_lower[j]);\n            uint8x16_t replace_u = vdupq_n_u8(replace_upper[j]);\n\n            uint8x16_t is_vowel_lower = vceqq_u8(swapped, vowel_lower);\n            uint8x16_t is_vowel_upper = vceqq_u8(swapped, vowel_upper);\n\n            swapped = vbslq_u8(is_vowel_lower, replace_l, swapped);\n            swapped = vbslq_u8(is_vowel_upper, replace_u, swapped);\n        }\n\n        uint8_t output[16];\n        vst1q_u8(output, swapped);\n        result.append(reinterpret_cast<char*>(output), 16);\n\n        i += 16;\n    }\n\n    // Handle remaining characters\n    while (i < message.size()) {\n        char c = message[i];\n        if (c >= 'a' && c <= 'z') {\n            c = toupper(c);\n        } else if (c >= 'A' && c <= 'Z') {\n            c = tolower(c);\n        }\n        if (c == 'a' || c == 'e' || c == 'i' || c == 'o' || c == 'u') {\n            switch (c) {\n                case 'a': c = 'c'; break;\n                case 'e': c = 'g'; break;\n                case 'i': c = 'k'; break;\n                case 'o': c = 'q'; break;\n                case 'u': c = 'w'; break;\n            }\n        } else if (c == 'A' || c == 'E' || c == 'I' || c == 'O' || c == 'U') {\n            switch (c) {\n                case 'A': c = 'C'; break;\n                case 'E': c = 'G'; break;\n                case 'I': c = 'K'; break;\n                case 'O': c = 'Q'; break;\n                case 'U': c = 'W'; break;\n            }\n        }\n        result += c;\n        i++;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_106_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nstd::string encode_simd(const std::string & message){\n    const uint8_t vowels[5] = {'a', 'e', 'i', 'o', 'u'};\n    const uint8_t vowel_replacements[5] = {'c', 'g', 'k', 'q', 'w'};\n    const uint8_t uppercase = 'A' - 'a';\n    \n    std::string result;\n    result.reserve(message.size());\n    \n    size_t i = 0;\n    for (; i + 15 < message.size(); i += 16) {\n        uint8x16_t vec = vld1q_u8(reinterpret_cast<const uint8_t*>(&message[i]));\n        uint8x16_t is_upper = vcgeq_u8(vec, vdupq_n_u8('A')) & vcleq_u8(vec, vdupq_n_u8('Z'));\n        uint8x16_t is_lower = vcgeq_u8(vec, vdupq_n_u8('a')) & vcleq_u8(vec, vdupq_n_u8('z'));\n        \n        // Swap case\n        uint8x16_t swapped_case = vec ^ (is_upper | is_lower);\n        swapped_case = vbslq_u8(is_upper, vaddq_u8(vec, vdupq_n_u8(32)), swapped_case);\n        swapped_case = vbslq_u8(is_lower, vsubq_u8(vec, vdupq_n_u8(32)), swapped_case);\n        \n        // Replace vowels\n        uint8x16_t replaced_vowels = swapped_case;\n        for (int j = 0; j < 5; ++j) {\n            uint8x16_t is_vowel = vceqq_u8(swapped_case, vdupq_n_u8(vowels[j]));\n            replaced_vowels = vbslq_u8(is_vowel, vdupq_n_u8(vowel_replacements[j]), replaced_vowels);\n        }\n        \n        uint8_t output[16];\n        vst1q_u8(output, replaced_vowels);\n        result.append(reinterpret_cast<char*>(output), 16);\n    }\n    \n    for (; i < message.size(); ++i) {\n        char c = message[i];\n        if (c >= 'A' && c <= 'Z') {\n            c = tolower(c);\n        } else if (c >= 'a' && c <= 'z') {\n            c = toupper(c);\n        }\n        for (int j = 0; j < 5; ++j) {\n            if (c == vowels[j]) {\n                c = vowel_replacements[j];\n                break;\n            }\n        }\n        result += c;\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_107_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <map>\n#include <string>\n\nbool check_dict_case_simd(std::map<std::string, std::string> dict){\n    if (dict.empty()) return false;\n\n    bool all_lower = true;\n    bool all_upper = true;\n\n    uint8x16_t vlower = vdupq_n_u8('a');\n    uint8x16_t vupper = vdupq_n_u8('z');\n    uint8x16_t vLower = vdupq_n_u8('A');\n    uint8x16_t vUpper = vdupq_n_u8('Z');\n\n    for (const auto& pair : dict) {\n        const std::string& key = pair.first;\n\n        if (key.empty()) {\n            all_lower = false;\n            all_upper = false;\n            continue;\n        }\n\n        size_t len = key.length();\n        const uint8_t* str_ptr = reinterpret_cast<const uint8_t*>(key.c_str());\n\n        size_t i = 0;\n        for (; i + 15 < len; i += 16) {\n            uint8x16_t vstr = vld1q_u8(str_ptr + i);\n            uint8x16_t vand_lower = vcltq_u8(vstr, vlower);\n            uint8x16_t vand_upper = vcltq_u8(vupper, vstr);\n\n            uint8x16_t vand_Lower = vcltq_u8(vstr, vLower);\n            uint8x16_t vand_Upper = vcltq_u8(vUpper, vstr);\n\n            uint8x16_t vcheck_lower = vorrq_u8(vand_lower, vand_upper);\n            uint8x16_t vcheck_upper = vorrq_u8(vand_Lower, vand_Upper);\n\n            if (vminvq_u8(vcheck_lower) != 0) all_lower = false;\n            if (vminvq_u8(vcheck_upper) != 0) all_upper = false;\n        }\n\n        for (; i < len; ++i) {\n            uint8_t c = str_ptr[i];\n            if ((c < 'a' || c > 'z') && (c < 'A' || c > 'Z')) {\n                all_lower = false;\n                all_upper = false;\n            } else if (c >= 'a' && c <= 'z') {\n                all_upper = false;\n            } else if (c >= 'A' && c <= 'Z') {\n                all_lower = false;\n            }\n        }\n\n        if (!all_lower && !all_upper) return false;\n    }\n\n    return all_lower || all_upper;\n}\n```"}
{"task_id": "SimdBench_107_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <map>\n#include <string>\n\nbool check_dict_case_simd(std::map<std::string, std::string> dict){\n    if (dict.empty()) return false;\n\n    auto it = dict.begin();\n    const uint8_t* first_key_data = reinterpret_cast<const uint8_t*>(it->first.c_str());\n    int len = it->first.length();\n\n    // Load the first key and determine its case\n    uint8x16_t vkey = vld1q_u8(first_key_data);\n    uint8x16_t vlower = vmovq_n_u8('a');\n    uint8x16_t vupper = vmovq_n_u8('z');\n    uint8x16_t vislower = vandq_u8(vcltq_u8(vkey, vupper), vcltq_u8(vlower, vkey));\n    bool is_lower = vmaxvq_u8(vislower) != 0;\n    bool is_upper = false;\n\n    if (!is_lower) {\n        vlower = vmovq_n_u8('A');\n        vupper = vmovq_n_u8('Z');\n        uint8x16_t visupper = vandq_u8(vcltq_u8(vlower, vkey), vcltq_u8(vkey, vupper));\n        is_upper = vmaxvq_u8(visupper) != 0;\n    }\n\n    for (++it; it != dict.end(); ++it) {\n        const uint8_t* key_data = reinterpret_cast<const uint8_t*>(it->first.c_str());\n        int len = it->first.length();\n        uint8x16_t vkey = vld1q_u8(key_data);\n\n        if (is_lower) {\n            uint8x16_t vlower = vmovq_n_u8('a');\n            uint8x16_t vupper = vmovq_n_u8('z');\n            uint8x16_t vislower = vandq_u8(vcltq_u8(vkey, vupper), vcltq_u8(vlower, vkey));\n            if (vmaxvq_u8(vislower) == 0) return false;\n        } else if (is_upper) {\n            uint8x16_t vlower = vmovq_n_u8('A');\n            uint8x16_t vupper = vmovq_n_u8('Z');\n            uint8x16_t visupper = vandq_u8(vcltq_u8(vlower, vkey), vcltq_u8(vkey, vupper));\n            if (vmaxvq_u8(visupper) == 0) return false;\n        } else {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_107_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <map>\n#include <string>\n\nbool check_dict_case_simd(std::map<std::string, std::string> dict){\n    if (dict.empty()) return false;\n\n    auto it = dict.begin();\n    const uint8_t* first_key_data = reinterpret_cast<const uint8_t*>(it->first.c_str());\n    int len = it->first.length();\n\n    // Load the first key and determine its case\n    uint8x16_t vkey = vld1q_u8(first_key_data);\n    uint8x16_t vlower = vmovq_n_u8('a');\n    uint8x16_t vupper = vmovq_n_u8('z');\n    uint8x16_t vislower = vandq_u8(vcltq_u8(vkey, vupper), vcgeq_u8(vkey, vlower));\n    uint8x16_t vzero = vmovq_n_u8(0);\n\n    bool is_all_lower = vmaxvq_u8(vislower) != 0;\n    bool is_all_upper = false;\n\n    if (!is_all_lower) {\n        uint8x16_t vAlower = vmovq_n_u8('A');\n        uint8x16_t vAupper = vmovq_n_u8('Z');\n        uint8x16_t visupper = vandq_u8(vcltq_u8(vkey, vAupper), vcgeq_u8(vkey, vAlower));\n        is_all_upper = vmaxvq_u8(visupper) != 0;\n    }\n\n    for (++it; it != dict.end(); ++it) {\n        const uint8_t* key_data = reinterpret_cast<const uint8_t*>(it->first.c_str());\n        int len = it->first.length();\n        uint8x16_t vkey = vld1q_u8(key_data);\n\n        if (is_all_lower) {\n            uint8x16_t vislower = vandq_u8(vcltq_u8(vkey, vupper), vcgeq_u8(vkey, vlower));\n            if (vmaxvq_u8(vislower) == 0) return false;\n        } else if (is_all_upper) {\n            uint8x16_t visupper = vandq_u8(vcltq_u8(vkey, vAupper), vcgeq_u8(vkey, vAlower));\n            if (vmaxvq_u8(visupper) == 0) return false;\n        } else {\n            return false;\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_107_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <map>\n#include <string>\n\nbool check_dict_case_simd(std::map<std::string, std::string> dict){\n    if (dict.empty()) return false;\n\n    bool all_lower = true;\n    bool all_upper = true;\n\n    uint8x16_t vlower = vdupq_n_u8('a');\n    uint8x16_t vupper = vdupq_n_u8('z');\n    uint8x16_t vLower = vdupq_n_u8('A');\n    uint8x16_t vUpper = vdupq_n_u8('Z');\n\n    for (const auto& pair : dict) {\n        const std::string& key = pair.first;\n\n        size_t len = key.length();\n        if (len == 0) {\n            all_lower = false;\n            all_upper = false;\n            break;\n        }\n\n        size_t i = 0;\n        for (; i + 15 < len; i += 16) {\n            uint8x16_t vkey = vld1q_u8(reinterpret_cast<const uint8_t*>(&key[i]));\n            uint8x16_t vand_lower = vandq_u8(vkey, vdupq_n_u8(0xDF)); // To upper\n            uint8x16_t vand_upper = vandq_u8(vkey, vdupq_n_u8(0xDF));\n\n            uint8x16_t vcmp_lower = vcgeq_u8(vand_lower, vlower);\n            uint8x16_t vcmp_upper = vcleq_u8(vand_lower, vupper);\n\n            uint8x16_t vcmp_Lower = vcgeq_u8(vand_upper, vLower);\n            uint8x16_t vcmp_Upper = vcleq_u8(vand_upper, vUpper);\n\n            uint8x16_t vres_lower = vandq_u8(vcmp_lower, vcmp_upper);\n            uint8x16_t vres_upper = vandq_u8(vcmp_Lower, vcmp_Upper);\n\n            if (vminvq_u8(vres_lower) == 0) all_lower = false;\n            if (vminvq_u8(vres_upper) == 0) all_upper = false;\n        }\n\n        for (; i < len; ++i) {\n            char c = key[i];\n            if (!(c >= 'a' && c <= 'z')) all_lower = false;\n            if (!(c >= 'A' && c <= 'Z')) all_upper = false;\n        }\n\n        if (!all_lower && !all_upper) return false;\n    }\n\n    return all_lower || all_upper;\n}\n```"}
{"task_id": "SimdBench_107_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <map>\n#include <string>\n\nbool check_dict_case_simd(std::map<std::string, std::string> dict){\n    if (dict.empty()) return false;\n\n    bool first_key = true;\n    uint8x16_t lower_mask = vdupq_n_u8(0);\n    uint8x16_t upper_mask = vdupq_n_u8(0);\n\n    for (const auto& pair : dict) {\n        const std::string& key = pair.first;\n        if (key.empty() || !std::all_of(key.begin(), key.end(), ::isalpha)) {\n            return false;\n        }\n\n        uint8x16_t vec = vld1q_u8(reinterpret_cast<const uint8_t*>(key.c_str()));\n        uint8x16_t cmp_low = vcgeq_u8(vec, vdupq_n_u8('a'));\n        uint8x16_t cmp_high = vcleq_u8(vec, vdupq_n_u8('z'));\n        uint8x16_t is_lower = vandq_u8(cmp_low, cmp_high);\n\n        cmp_low = vcgeq_u8(vec, vdupq_n_u8('A'));\n        cmp_high = vcleq_u8(vec, vdupq_n_u8('Z'));\n        uint8x16_t is_upper = vandq_u8(cmp_low, cmp_high);\n\n        if (first_key) {\n            lower_mask = is_lower;\n            upper_mask = is_upper;\n            first_key = false;\n        } else {\n            uint8x16_t current_lower = vmovemaskq_u8(is_lower);\n            uint8x16_t current_upper = vmovemaskq_u8(is_upper);\n\n            if ((vbitwise_all_true(lower_mask) && !vbitwise_all_true(current_lower)) ||\n                (vbitwise_all_true(upper_mask) && !vbitwise_all_true(current_upper))) {\n                return false;\n            }\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_108_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int> count_up_to_simd(int n){\n    std::vector<int> primes;\n    if(n <= 1) return primes;\n\n    const int simd_width = 4; // Number of elements processed per SIMD operation (int32x4_t)\n    int limit = n / simd_width * simd_width;\n\n    // Create a sieve buffer\n    std::vector<char> sieve(n, 1);\n    sieve[0] = sieve[1] = 0;\n\n    int32x4_t vzero = vmovq_n_s32(0);\n\n    for(int i = 2; i * i < n; ++i){\n        if(sieve[i]){\n            for(int j = i * i; j < n; j += i){\n                sieve[j] = 0;\n            }\n        }\n    }\n\n    for(int i = 0; i < limit; i += simd_width){\n        int32x4_t vindices = vld1q_s32(reinterpret_cast<const int32_t*>(&sieve[i]));\n        uint32x4_t vcmp = vcgeq_s32(vindices, vzero);\n        uint32x4_t vmask = vceqq_s32(vindices, vmovq_n_s32(1));\n        uint32x4_t vresult = vandq_u32(vcmp, vmask);\n\n        // Extract indices of primes\n        uint32x4_t vidx = vld1q_u32(reinterpret_cast<const uint32_t*>(&i));\n        uint32x4_t vselect = vbslq_u32(vresult, vidx, vmovq_n_u32(0));\n\n        // Store results\n        int32x4_t res = vreinterpretq_s32_u32(vselect);\n        for(int j = 0; j < simd_width; ++j){\n            if(vgetq_lane_u32(vresult, j)){\n                primes.push_back(vgetq_lane_s32(res, j));\n            }\n        }\n    }\n\n    // Handle remaining elements\n    for(int i = limit; i < n; ++i){\n        if(sieve[i]) primes.push_back(i);\n    }\n\n    return primes;\n}\n```"}
{"task_id": "SimdBench_108_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int> count_up_to_simd(int n){\n    std::vector<int> primes;\n    if (n <= 1) return primes;\n\n    int limit = n / 32 + 1;\n    uint32_t *sieve = new uint32_t[limit];\n    for(int i = 0; i < limit; ++i){\n        sieve[i] = 0xFFFFFFFF;\n    }\n    if(n >= 2) sieve[0] &= ~(1 << 1);\n\n    int sqrt_n = static_cast<int>(sqrt(n));\n    for(int p = 2; p <= sqrt_n; ++p){\n        if( !(sieve[p/32] & (1 << (p % 32))) ) continue;\n\n        uint32x4_t vprime = vdupq_n_u32(p);\n        uint32x4_t vmult = vdupq_n_u32(p*p);\n        uint32x4_t vstep = vdupq_n_u32(p);\n\n        while(true){\n            uint32x4_t vidx = vmult / 32;\n            uint32x4_t vmod = vmult % 32;\n            uint32x4_t vcmp = vcltq_u32(vmult, vdupq_n_u32(n));\n\n            if(vget_lane_u32(vcmp, 0) == 0 && vget_lane_u32(vcmp, 1) == 0 &&\n               vget_lane_u32(vcmp, 2) == 0 && vget_lane_u32(vcmp, 3) == 0){\n                break;\n            }\n\n            for(int j = 0; j < 4; ++j){\n                if(vget_lane_u32(vcmp, j) != 0){\n                    int idx = vget_lane_u32(vidx, j);\n                    int mod = vget_lane_u32(vmod, j);\n                    sieve[idx] &= ~(1 << mod);\n                }\n            }\n\n            vmult = vaddq_u32(vmult, vstep);\n        }\n    }\n\n    for(int i = 2; i < n; ++i){\n        if(sieve[i/32] & (1 << (i % 32))){\n            primes.push_back(i);\n        }\n    }\n\n    delete[] sieve;\n    return primes;\n}\n```"}
{"task_id": "SimdBench_108_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<int> count_up_to_simd(int n){\n    std::vector<int> primes;\n    if(n <= 1) return primes;\n\n    const int size = n / 32 + 1;\n    uint32_t *sieve = static_cast<uint32_t *>(aligned_alloc(16, size * sizeof(uint32_t)));\n    if (!sieve) return primes;\n    for(int i = 0; i < size; ++i){\n        sieve[i] = 0xFFFFFFFF;\n    }\n    if(n >= 2) sieve[0] |= 1;\n\n    int limit = static_cast<int>(std::sqrt(static_cast<double>(n)));\n\n    for(int p = 2; p <= limit; ++p){\n        if((sieve[p/32] >> (p%32)) & 1){\n            uint32x4_t v_p = vdupq_n_u32(p);\n            for(int multiple = p*p; multiple < n; multiple += p){\n                int index = multiple / 32;\n                int bit = multiple % 32;\n                uint32x4_t v_index = vdupq_n_u32(index);\n                uint32x4_t v_bit = vdupq_n_u32(1 << bit);\n                uint32x4_t v_sieve = vld1q_u32(sieve + index);\n                v_sieve = vbicq_u32(v_sieve, v_bit);\n                vst1q_u32(sieve + index, v_sieve);\n            }\n        }\n    }\n\n    for(int num = 2; num < n; ++num){\n        if((sieve[num/32] >> (num%32)) & 1){\n            primes.push_back(num);\n        }\n    }\n\n    free(sieve);\n    return primes;\n}\n```"}
{"task_id": "SimdBench_108_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int> count_up_to_simd(int n){\n    std::vector<int> primes;\n    if (n <= 1) return primes;\n\n    const int simd_width = 4; // Number of elements in a SIMD register for int32x4_t\n    int limit = n / simd_width * simd_width;\n\n    uint32x4_t vzero = vdupq_n_u32(0);\n    uint32x4_t vone = vdupq_n_u32(1);\n\n    for(int i = 2; i < limit; i += simd_width){\n        uint32x4_t vnums = vld1q_u32(&i);\n        uint32x4_t vis_prime = vdupq_n_u32(1);\n\n        for(int j = 2; j*j <= n; ++j){\n            uint32x4_t vcmp = vmovq_n_u32(j);\n            uint32x4_t vrem = vmlaq_u32(vzero, vnums, vcmp, (uint32x4_t)vone); \n            uint32x4_t vcheck = vceqq_u32(vrem, vzero);\n            vis_prime = vandq_u32(vis_prime, vbicq_u32(vdupq_n_u32(-1), vcheck));\n        }\n\n        uint32x4_t vmask = vandq_u32(vis_prime, vcgtq_u32(vnums, vdupq_n_u32(1)));\n\n        uint32_t mask = vget_lane_u32(vmovn_u64(vreinterpretq_u64_u32(vmask)), 0);\n        mask |= vget_lane_u32(vmovn_u64(vreinterpretq_u64_u32(vshrq_n_u32(vmask, 16))), 1) << 1;\n        mask |= vget_lane_u32(vmovn_u64(vreinterpretq_u64_u32(vshrq_n_u32(vmask, 32))), 2) << 2;\n        mask |= vget_lane_u32(vmovn_u64(vreinterpretq_u64_u32(vshrq_n_u32(vmask, 48))), 3) << 3;\n\n        for(int k = 0; k < simd_width; ++k){\n            if(mask & (1<<k)){\n                primes.push_back(i + k);\n            }\n        }\n    }\n\n    for(int i = limit; i < n; ++i){\n        bool is_prime = true;\n        for(int j = 2; j*j <= i; ++j){\n            if(i % j == 0){\n                is_prime = false;\n                break;\n            }\n        }\n        if(is_prime){\n            primes.push_back(i);\n        }\n    }\n\n    return primes;\n}\n```"}
{"task_id": "SimdBench_108_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int> count_up_to_simd(int n){\n    std::vector<int> primes;\n    if(n <= 1) return primes;\n\n    const int simd_width = 4;\n    int limit = n / simd_width * simd_width;\n    uint32x4_t vzero = vdupq_n_u32(0);\n    uint32x4_t vone = vdupq_n_u32(1);\n\n    for(int i = 2; i < limit; i += simd_width){\n        uint32x4_t vnums = vld1q_u32(&i);\n        uint32x4_t vis_prime = vdupq_n_u32(1);\n        \n        for(int j = 2; j*j <= n; ++j){\n            uint32x4_t vmod = vmovq_n_u32(0);\n            for(int k = 0; k < simd_width; ++k){\n                int num = vgetq_lane_u32(vnums, k);\n                if(num % j == 0 && num != j){\n                    uint32x4_t vtst = vcleq_n_u32(vnums, num);\n                    vis_prime = vandq_u32(vis_prime, vtst);\n                }\n            }\n        }\n        uint32x4_t vresult = vandq_u32(vis_prime, vnums);\n        uint32_t result_arr[4];\n        vst1q_u32(result_arr, vresult);\n        for(int k = 0; k < simd_width; ++k){\n            if(result_arr[k] > 1) primes.push_back(result_arr[k]);\n        }\n    }\n\n    // Handle remaining elements\n    for(int i = limit; i < n; ++i){\n        if(is_prime(i)) primes.push_back(i);\n    }\n\n    return primes;\n}\n\nbool is_prime(int x){\n    if(x < 2) return false;\n    for(int i = 2; i*i <= x; ++i){\n        if(x % i == 0) return false;\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_109_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nint count_upper_simd(const std::string &s) {\n    int count = 0;\n    const uint8_t *data = reinterpret_cast<const uint8_t *>(s.c_str());\n    int length = s.length();\n    alignas(16) uint8_t mask_data[16] = { 'A', 'E', 'I', 'O', 'U', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 };\n    uint8x16_t mask = vld1q_u8(mask_data);\n\n    for (int i = 0; i < length; i += 16) {\n        if (i % 2 != 0) continue; // Ensure even indices\n        uint8x16_t vec = vld1q_u8(data + i);\n        uint8x16_t eq_mask = vmovq_n_u8(0);\n        \n        for (int j = 0; j < 5; ++j) {\n            uint8x16_t curr_mask = vdupq_n_u8(mask_data[j]);\n            uint8x16_t is_equal = vceqq_u8(vec, curr_mask);\n            eq_mask = vorrq_u8(eq_mask, is_equal);\n        }\n\n        uint8x16_t filtered = vandq_u8(eq_mask, vec);\n        uint8x16_t zeros = vdupq_n_u8(0);\n        uint16x8_t res = vcntq_u8(filtered, zeros);\n        uint32x4_t sum1 = vpaddlq_u16(res);\n        uint64x2_t sum2 = vpaddlq_u32(sum1);\n        uint64_t sum = vaddvq_u64(sum2);\n        count += static_cast<int>(sum);\n    }\n\n    // Handle remaining characters\n    for (int i = ((length / 16) * 16); i < length; ++i) {\n        if (i % 2 == 0 && strchr(\"AEIOU\", data[i]) != nullptr) {\n            count++;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_109_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nint count_upper_simd(const std::string &s) {\n    int count = 0;\n    const uint8x16_t uppercase_vowels = vdupq_n_u8(0);\n    uint8x16_t mask = vdupq_n_u8(0);\n\n    // Create a mask for uppercase vowels A, E, I, O, U\n    const uint8_t vowel_mask_data[16] = { 'A', 'E', 'I', 'O', 'U', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 };\n    const uint8x16_t uppercase_vowel_mask = vld1q_u8(vowel_mask_data);\n\n    size_t i = 0;\n    size_t length = s.length();\n\n    // Process 16 bytes at a time\n    for (; i <= length - 16; i += 16) {\n        uint8x16_t vec = vld1q_u8(reinterpret_cast<const uint8_t*>(&s[i]));\n        uint8x16_t even_indices = vandq_u8(vec, vdupq_n_u8(0x55)); // Mask to keep only even indices\n\n        // Check if character is an uppercase vowel\n        uint8x16_t is_vowel = vmovemask_u8((vreinterpretq_u8_s8)(vreinterpretq_s8_u8(vceqq_u8(even_indices, uppercase_vowel_mask))));\n\n        // Count the number of matches\n        count += __builtin_popcount(is_vowel);\n    }\n\n    // Process remaining characters\n    for (; i < length; ++i) {\n        if (i % 2 == 0 && strchr(\"AEIOU\", s[i]) != nullptr) {\n            count++;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_109_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nint count_upper_simd(const std::string &s) {\n    int count = 0;\n    const uint8x16_t uppercase_vowels = vdupq_n_u8(0);\n    uint8x16_t mask = vdupq_n_u8(0);\n    uint8x16_t zero = vdupq_n_u8(0);\n\n    // Create a mask for uppercase vowels A, E, I, O, U\n    uint8x16_t vowels = vdupq_n_u8('A');\n    vowels = vorrq_u8(vowels, vdupq_n_u8('E'));\n    vowels = vorrq_u8(vowels, vdupq_n_u8('I'));\n    vowels = vorrq_u8(vowels, vdupq_n_u8('O'));\n    vowels = vorrq_u8(vowels, vdupq_n_u8('U'));\n\n    size_t i = 0;\n    size_t length = s.length();\n\n    for (; i <= length - 16; i += 16) {\n        uint8x16_t vec = vld1q_u8(reinterpret_cast<const uint8_t*>(&s[i]));\n        uint8x16_t even_mask = vandq_u8(vdupq_n_u8(0xAA), vdupq_n_u8(0xFF));\n        uint8x16_t even_vec = vandq_u8(vec, even_mask);\n        uint8x16_t matches = vceqq_u8(even_vec, vowels);\n        mask = vaddq_u8(mask, matches);\n    }\n\n    uint8x8_t low = vget_low_u8(mask);\n    uint8x8_t high = vget_high_u8(mask);\n    uint8x8_t sum = vadd_u8(low, high);\n    uint16x4_t sum16 = vpaddl_u8(sum);\n    uint32x2_t sum32 = vpaddl_u16(sum16);\n    uint64x1_t sum64 = vpaddl_u32(sum32);\n    count += vget_lane_u64(sum64, 0);\n\n    // Handle remaining characters\n    for (; i < length; ++i) {\n        if (i % 2 == 0 && strchr(\"AEIOU\", s[i])) {\n            count++;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_109_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nint count_upper_simd(const std::string &s) {\n    int count = 0;\n    const uint8x16_t uppercase_vowels = vdupq_n_u8(0);\n    uint8x16_t mask = vdupq_n_u8(0);\n    const uint8_t vowels[] = \"AEIOU\";\n    const uint8x16_t vowel_table = vld1q_u8((const uint8_t *)vowels);\n\n    size_t i = 0;\n    size_t length = s.length();\n    for (; i <= length - 16; i += 16) {\n        uint8x16_t vec = vld1q_u8((const uint8_t *)(s.c_str() + i));\n        uint8x16_t even_indices = vandq_u8(vec, vdupq_n_u8(0xAA)); // Mask to get even indices\n        uint8x16_t is_upper = vclaq_u8(even_indices, 'A', '<') & vclaq_u8(even_indices, 'Z', '>'); // Check uppercase\n        uint8x16_t is_vowel = vmovemask_u8(vceqq_u8(even_indices, vowel_table));\n        mask = vorrq_u8(mask, bisect(is_upper, is_vowel));\n    }\n    count += vaddvq_u8(mask);\n\n    for (; i < length; ++i) {\n        if (i % 2 == 0 && s[i] >= 'A' && s[i] <= 'Z') {\n            char c = s[i];\n            if (c == 'A' || c == 'E' || c == 'I' || c == 'O' || c == 'U') {\n                count++;\n            }\n        }\n    }\n    return count;\n}\n```"}
{"task_id": "SimdBench_109_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nint count_upper_simd(const std::string &s) {\n    int count = 0;\n    const uint8_t *data = reinterpret_cast<const uint8_t *>(s.c_str());\n    size_t len = s.length();\n    size_t i = 0;\n\n    // Mask for uppercase vowels: A, E, I, O, U\n    uint8x16_t vowel_mask = vdupq_n_u8(0);\n    uint8x16_t pattern_AEIOU = vdupq_n_u8(0);\n    uint8_t mask_array[16] = {0};\n    mask_array['A' - 'A'] = mask_array['E' - 'A'] = mask_array['I' - 'A'] = mask_array['O' - 'A'] = mask_array['U' - 'A'] = 0xFF;\n    for (size_t j = 0; j < 16; ++j) {\n        ((uint8_t *)&pattern_AEIOU)[j] = mask_array[j];\n    }\n\n    for (; i <= len - 16; i += 16) {\n        uint8x16_t vec = vld1q_u8(data + i);\n        uint8x16_t even_vec = vandq_u8(vec, vdupq_n_u8(0xAA)); // Keep only even indices\n        uint8x16_t cmp_res = vceqq_u8(even_vec, pattern_AEIOU);\n        uint8x16_t ones = vdupq_n_u8(1);\n        uint16x8_t sums = vpaddlq_u8(vandq_u8(cmp_res, ones));\n        uint32x4_t sums2 = vpaddlq_u16(sums);\n        uint64x2_t sums3 = vpaddlq_u32(sums2);\n        count += vget_lane_u64(vaddv_u64(sums3), 0);\n    }\n\n    for (; i < len; ++i) {\n        if (i % 2 == 0 && strchr(\"AEIOU\", s[i]) != nullptr) {\n            count++;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_110_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int> make_a_pile_simd(int n){\n    int count = (n + 15) / 16 * 16; // Round up to nearest multiple of 16\n    std::vector<int> result;\n    result.reserve(count);\n\n    int adder = (n % 2 == 0) ? 2 : 1;\n\n    int16x8_t vn = vdupq_n_s16(n);\n    int16x8_t vadd = vdupq_n_s16(adder);\n    \n    for(int i = 0; i < count; i += 8){\n        result.insert(result.end(), &vn[0], &vn[8]);\n        vn = vaddq_s16(vn, vadd);\n    }\n\n    result.resize(n); // Resize back to n elements\n    return result;\n}\n```"}
{"task_id": "SimdBench_110_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int> make_a_pile_simd(int n){\n    int num_levels = n;\n    std::vector<int> result(num_levels);\n    \n    if (n <= 0) return result;\n\n    int32x4_t v_n =vdupq_n_s32(n);\n    int32x4_t v_step = vdupq_n_s32(2);\n    int32x4_t v_temp = v_n;\n    \n    for(int i=0;i<num_levels;i+=4){\n        if(i+4 <= num_levels){\n            vst1q_s32(&result[i], v_temp);\n            v_temp = vaddq_s32(v_temp, v_step);\n        }\n        else{\n            int leftovers = num_levels - i;\n            int32x4_t v_mask = vdupq_n_s32(0);\n            for(int j=0; j<leftovers; ++j){\n                ((int32_t*)&v_mask)[j] = 1;\n            }\n            int32x4_t v_result_part = vandq_s32(v_temp, v_mask);\n            vst1q_s32(&result[i], v_result_part);\n            break;\n        }\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_110_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int> make_a_pile_simd(int n){\n    std::vector<int> result(n);\n    if (n <= 0) return result;\n\n    int32x4_t vec_n = vdupq_n_s32(n);\n    int32x4_t step = vdupq_n_s32(2);\n    int32x4_t current = vec_n;\n\n    for(int i = 0; i < n; i+=4){\n        if(i + 4 <= n){\n            vst1q_s32(&result[i], current);\n            current = vaddq_s32(current, step);\n        }\n        else{\n            int leftovers = n - i;\n            int32x4_t mask = vdupq_n_s32(-1);\n            mask = vshrq_n_s32(mask, 32 - (leftovers * 8));\n            current = vandq_s32(current, vmovl_u8(vreinterpret_u8_s32(mask)));\n            int32x4_t temp = vaddq_s32(current, step);\n            for(int j = 0; j < leftovers; ++j){\n                result[i+j] = vgetq_lane_s32(current, j);\n                current = vsetq_lane_s32(vgetq_lane_s32(temp, j) + 2, current, j);\n            }\n        }\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_110_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int> make_a_pile_simd(int n){\n    std::vector<int> result(n);\n    if (n <= 0) return result;\n\n    int32x4_t vec_n = vdupq_n_s32(n);\n    int32x4_t vec_step = vdupq_n_s32(2);\n    int32x4_t vec_temp;\n\n    for(int i = 0; i < n; i+=4){\n        if(i == 0){\n            vec_temp = vec_n;\n        }\n        else{\n            int32x4_t prev = vld1q_s32(&result[i-4]);\n            vec_temp = vaddq_s32(prev, vec_step);\n        }\n        int count = std::min(4, n - i);\n        if(count > 0){\n            int *temp_ptr = reinterpret_cast<int*>(&vec_temp);\n            for(int j=0; j<count; ++j){\n                result[i + j] = temp_ptr[j];\n            }\n        }\n        if(count < 4){\n            break;\n        }\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_110_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int> make_a_pile_simd(int n){\n    std::vector<int> result(n);\n    if (n <= 0) return result;\n\n    int32x4_t vec_n = vdupq_n_s32(n);\n    int32x4_t vec_inc = vdupq_n_s32(2);\n    int32x4_t vec_temp;\n\n    for(int i = 0; i < n; i+=4){\n        if(i == 0){\n            vec_temp = vec_n;\n        }\n        else{\n            int32x4_t vec_idx = vld1q_dup_s32(&i);\n            vec_temp = vaddq_s32(vec_temp, vmulq_s32(vec_inc, vec_idx));\n        }\n        if(i + 4 <= n){\n            vst1q_s32(&result[i], vec_temp);\n        }\n        else{\n            int remainder = n - i;\n            int *ptr = &result[i];\n            int32x4_t mask = vdupq_n_s32(-1);\n            if(remainder < 4){\n                mask = vsetq_lane_s32(0, mask, remainder);\n            }\n            int32x4_t masked_vec = vandq_s32(vreinterpretq_s32_u32(vmovl_u16(vdupq_n_u16(0xFFFF))), mask);\n            vec_temp = vbslq_s32(masked_vec, vec_temp, vdupq_n_s32(0));\n            vst1q_s32(ptr, vec_temp);\n        }\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_111_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nstd::string rounded_avg_simd(int64_t n, int64_t m){\n    if (n > m) {\n        return \"-1\";\n    }\n\n    int64x2_t vn = vdupq_n_s64(n);\n    int64x2_t vm = vdupq_n_s64(m);\n\n    int64x2_t vsum = vaddl_s64(vmovl_s32(vdup_n_s32(0)), vmovl_s32(vdup_n_s32(0)));\n    uint64x2_t vcount = vdupq_n_u64(0);\n\n    int64x2_t vrange = vsubq_s64(vm, vn);\n    uint64x2_t vrange_u = vcvtuq_s64_f64(vcvt_f64_x_s64(vrange));\n    vcount = vaddq_u64(vrange_u, vdupq_n_u64(1));\n\n    int64x2_t vtotal = vmulq_s64(vn, vdupq_n_s64(2));\n    vtotal = vaddq_s64(vtotal, vrange);\n    vtotal = vaddq_s64(vtotal, vdupq_n_s64(1));\n    vtotal = vmulq_s64(vtotal, vdupq_n_s64(2));\n    vtotal = vshrq_n_s64(vtotal, 2);\n\n    uint64x2_t vavg = vshrq_n_u64(vcvtuq_s64_f64(vcvt_f64_x_s64(vtotal)), 1);\n    uint64_t avg = vgetq_lane_u64(vavg, 0);\n\n    std::string binary = \"\";\n    if (avg == 0) {\n        binary = \"0\";\n    } else {\n        while (avg > 0) {\n            binary = static_cast<char>(avg % 2 + '0') + binary;\n            avg /= 2;\n        }\n    }\n    return binary;\n}\n```"}
{"task_id": "SimdBench_111_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nstd::string rounded_avg_simd(int64_t n, int64_t m){\n    if(n > m){\n        return \"-1\";\n    }\n    \n    int64x2_t vn = vdupq_n_s64(n);\n    int64x2_t vm = vdupq_n_s64(m);\n    \n    int64x2_t vsum = vaddl_s64(vmovl_s32(vdup_n_s32(0)), vmovl_s32(vdup_n_s32(0)));\n    int64x2_t vcount = vdupq_n_s64(0);\n    \n    int64x2_t vtemp_sum = vsum;\n    int64x2_t vtemp_count = vcount;\n    \n    for(int64_t i = n; i <= m; i += 2){\n        int64x2_t vi = vdupq_n_s64(i);\n        vtemp_sum = vaddq_s64(vtemp_sum, vi);\n        vtemp_count = vaddq_s64(vtemp_count, vdupq_n_s64(1));\n        \n        if(i + 1 <= m){\n            int64x2_t vi_next = vdupq_n_s64(i + 1);\n            vtemp_sum = vaddq_s64(vtemp_sum, vi_next);\n            vtemp_count = vaddq_s64(vtemp_count, vdupq_n_s64(1));\n        }\n    }\n    \n    int64x2_t vavg = vrndq_s64(vshrq_n_s64(vtemp_sum, 1));\n    int64_t avg = vgetq_lane_s64(vavg, 0);\n    \n    std::string binary = \"\";\n    if(avg < 0){\n        return \"-1\";\n    }\n    \n    if(avg == 0){\n        binary = \"0\";\n    }\n    else{\n        while(avg > 0){\n            binary = (avg % 2 == 0 ? \"0\" : \"1\") + binary;\n            avg /= 2;\n        }\n    }\n    \n    return binary;\n}\n```"}
{"task_id": "SimdBench_111_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nstd::string rounded_avg_simd(int64_t n, int64_t m){\n    if(n > m){\n        return \"-1\";\n    }\n    \n    int64x2_t vn = vdupq_n_s64(n);\n    int64x2_t vm = vdupq_n_s64(m);\n    \n    int64x2_t vsum = vmulq_n_s64(vn, n <= m ? (m - n + 1) : 0);\n    int64x2_t vcount = vdupq_n_s64(n <= m ? (m - n + 1) : 0);\n    \n    for(int64_t i = n; i <= m; ++i){\n        vsum = vaddq_s64(vsum, vdupq_n_s64(i));\n    }\n    \n    int64x2_t vavg = vrshlq_s64(vsum, vdupq_n_s64(31)); // Rounding down\n    \n    int64_t avg = vgetq_lane_s64(vavg, 0);\n    \n    std::string binary = \"\";\n    if(n <= m){\n        for(int i = 63; i >=0; --i){\n            if((avg >> i) & 1){\n                binary += '1';\n            }\n            else{\n                binary += '0';\n            }\n        }\n        // Remove leading zeros\n        size_t start = binary.find_first_not_of('0');\n        if(start != std::string::npos){\n            binary = binary.substr(start);\n        }\n        else{\n            binary = \"0\";\n        }\n    }\n    return binary;\n}\n```"}
{"task_id": "SimdBench_111_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nstd::string rounded_avg_simd(int64_t n, int64_t m){\n    if(n > m){\n        return \"-1\";\n    }\n    \n    int64x1_t vn = vdup_n_s64(n);\n    int64x1_t vm = vdup_n_s64(m);\n    \n    int64x1_t vsum = vm;\n    vsum = vadd_s64(vsum, vn);\n    \n    int64x1_t vcount = vdup_n_s64(m - n + 1);\n    \n    int64x1_t vavg = vshl_s64(vsum, -1); // Divide by 2 for rounding down\n    \n    uint64x1_t vresult = vreinterpret_u64_s64(vavg);\n    uint64_t result = vget_lane_u64(vresult, 0) / (vget_lane_s64(vcount, 0));\n    \n    std::string binary = \"\";\n    for(int i = 63; i >= 0; --i){\n        binary += ((result >> i) & 1ULL) ? '1' : '0';\n    }\n    \n    // Remove leading zeros\n    size_t start = binary.find_first_of(\"1\");\n    if(start != std::string::npos){\n        binary = binary.substr(start);\n    } else {\n        binary = \"0\";\n    }\n    \n    return binary;\n}\n```"}
{"task_id": "SimdBench_111_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nstd::string rounded_avg_simd(int64_t n, int64_t m){\n    if (n > m) {\n        return \"-1\";\n    }\n    \n    int64x2_t vn = vdupq_n_s64(n);\n    int64x2_t vm = vdupq_n_s64(m);\n    \n    int64x2_t vsum = vpaddlq_s64(vmovl_s32(vget_low_s32(vsubl_s16(vceq_s8(vreinterpretq_s8_s64(vn), vreinterpretq_s8_s64(vm)), vdup_n_s8(0)))));\n    uint64x2_t vcount = vdupq_n_u64((m - n + 1));\n    \n    int64x2_t vavg = vmovl_s32(vshrn_n_s64(vsum, 1));\n    int64x2_t vfloor = vmovl_s32(vshrn_n_s64(vsubl_s32(vreinterpretq_s32_s64(vavg), vreinterpretq_s32_u64(vcvtq_f64_u64(vcntq_u64(vreinterpretq_u64_s64(vcmpgeq_f64(vcvtaq_f64_s64(vdivq_s64(vsum, vcntq_s64(vcount)), vcntq_s64(vcount)))))), vdup_n_s32(0)), 1));\n    \n    int result = vgetq_lane_s64(vfloor, 0);\n    \n    std::string binary = \"\";\n    if(result == 0){\n        binary = \"0\";\n    }\n    else{\n        while(result > 0){\n            binary = std::to_string(result % 2) + binary;\n            result /= 2;\n        }\n    }\n    return binary;\n}\n```"}
{"task_id": "SimdBench_112_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int> func_simd(int n){\n    std::vector<int> result(n, 0);\n    if (n <= 0) return result;\n\n    const int mod = 10000;\n    int num_iterations = n / 4;\n    int remainder = n % 4;\n\n    int i = 1;\n    for (; i <= num_iterations * 4; i += 4){\n        int32x4_t even_indices = vmovq_n_s32(i);\n        int32x4_t odd_indices = vaddq_s32(even_indices, vmovq_n_s32(1));\n\n        // Compute factorial modulo for even indices\n        int32x4_t factorials = vmovq_n_s32(1);\n        for (int j = 1; j <= 4; ++j){\n            int32x4_t current_val = vmovq_n_s32(j);\n            factorials = vmulq_s32(factorials, current_val);\n            factorials = vshrq_n_s32(factorials, 1); // Simulate modulo with power of 2\n        }\n\n        // Compute sum for odd indices\n        int32x4_t sums = vmovq_n_s32(0);\n        for (int j = 1; j <= 4; ++j){\n            int32x4_t current_val = vmovq_n_s32(j);\n            sums = vaddq_s32(sums, current_val);\n        }\n\n        // Interleave results\n        int32x4_t res = vcombine_s32(vget_low_s32(factorials), vget_low_s32(sums));\n        int* ptr = &result[i - 1];\n        vst1q_s32(ptr, res);\n    }\n\n    // Handle remaining elements\n    for (; i <= n; ++i){\n        if (i % 2 == 0){\n            int fact = 1;\n            for (int j = 1; j <= i; ++j){\n                fact = (fact * j) % mod;\n            }\n            result[i - 1] = fact;\n        }\n        else{\n            int sum = (i * (i + 1)) / 2;\n            result[i - 1] = sum;\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_112_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int> func_simd(int n){\n    std::vector<int> result(n, 0);\n    if (n <= 0) return result;\n\n    const int mod = 10000;\n    int num_iterations = n / 4;\n    int remainder = n % 4;\n\n    int i = 1;\n    for (; i <= num_iterations * 4; i += 4) {\n        int32x4_t vec_i = vmovq_n_s32(i);\n        int32x4_t even_mask = vmovq_n_s32(1);\n        int32x4_t factorial_mod = vmovq_n_s32(1);\n        int32x4_t sum_mod = vmovq_n_s32(0);\n\n        for (int j = 1; j <= 4; ++j) {\n            int32x4_t current_val = vaddq_s32(vec_i, vmovq_n_s32(j - 1));\n            int32x4_t factorial_update = vmulq_s32(factorial_mod, current_val);\n            factorial_mod = vmlaq_s32(zero_mod, factorial_mod, current_val);\n            sum_mod = vaddq_s32(sum_mod, current_val);\n        }\n\n        int32x4_t res_factorial = vsubq_s32(factorial_mod, vmulq_s32(factorial_mod, vmovq_n_s32(mod)));\n        int32x4_t res_sum = vsubq_s32(sum_mod, vmulq_s32(sum_mod, vmovq_n_s32(mod)));\n\n        int32x4_t even_odd_check = vandq_s32(vec_i, vmovq_n_s32(1));\n        uint32x4_t select_even = vceqq_s32(even_odd_check, vmovq_n_s32(0));\n\n        int32x4_t final_res = vbslq_s32(select_even, res_factorial, res_sum);\n\n        int32_t res_arr[4];\n        vst1q_s32(res_arr, final_res);\n\n        for (int idx = 0; idx < 4; ++idx) {\n            result[i + idx - 1] = res_arr[idx];\n        }\n    }\n\n    for (; i <= n; ++i) {\n        if (i % 2 == 0) {\n            int factorial = 1;\n            for (int j = 1; j <= i; ++j) {\n                factorial = (factorial * j) % mod;\n            }\n            result[i - 1] = factorial;\n        } else {\n            int sum = (i * (i + 1)) / 2;\n            result[i - 1] = sum;\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_112_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int> func_simd(int n){\n    std::vector<int> result(n, 0);\n    if (n <= 0) return result;\n\n    const int mod = 10000;\n    int i = 1;\n    int factorial = 1;\n    int sum = 0;\n\n    while(i <= n){\n        int vec_size = n - i + 1;\n        if(vec_size > 4) vec_size = 4;\n\n        int32x4_t vec_i = vmovq_n_s32(0);\n        int32x4_t vec_res = vmovq_n_s32(0);\n\n        for(int j=0; j<vec_size; ++j){\n            if(i % 2 == 0){\n                factorial = (factorial * i) % mod;\n                vec_res = vsetq_lane_s32(factorial, vec_res, j);\n            }\n            else{\n                sum += i;\n                vec_res = vsetq_lane_s32(sum, vec_res, j);\n            }\n            vec_i = vsetq_lane_s32(i, vec_i, j);\n            i++;\n        }\n\n        for(int j=0; j<vec_size; ++j){\n            result[vec_size - 1 - j] = vgetq_lane_s32(vec_res, vec_size - 1 - j);\n        }\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_112_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int> func_simd(int n){\n    std::vector<int> result(n, 0);\n    if (n <= 0) return result;\n\n    const int mod = 10000;\n    int16x8_t vec_mod = vdupq_n_s16(mod);\n\n    for(int i = 0; i < n; i += 8){\n        int len = std::min(8, n - i);\n\n        int16x8_t vec_idx = vmovl_s8(vdup_n_s8(0));\n        int16x8_t vec_res = vmovl_s8(vdup_n_s8(0));\n\n        for(int j = 0; j < len; ++j){\n            int idx = i + j;\n            if(idx == 0) continue;\n            if(idx % 2 == 0){\n                int fact = 1;\n                for(int k = 1; k <= idx; ++k){\n                    fact = (fact * k) % mod;\n                }\n                vec_res = vsetq_lane_s16(fact, vec_res, j);\n            }\n            else{\n                int sum = (idx * (idx + 1)) / 2;\n                vec_res = vsetq_lane_s16(sum, vec_res, j);\n            }\n        }\n\n        for(int j = 0; j < len; ++j){\n            result[i + j] = vgetq_lane_s16(vec_res, j);\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_112_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int> func_simd(int n){\n    std::vector<int> result(n, 0);\n    if (n <= 0) return result;\n\n    const int mod = 10000;\n    int num_threads = (n + 3) / 4; // Process in chunks of 4\n    for(int t = 0; t < num_threads; ++t){\n        int start_idx = t * 4;\n        int end_idx = start_idx + 4;\n        if(end_idx > n) end_idx = n;\n\n        int32x4_t vec_idx = vmovq_n_s32(0);\n        int32x4_t vec_res = vmovq_n_s32(0);\n\n        for(int i = start_idx; i < end_idx; ++i){\n            int val = 0;\n            if(i == 0){\n                val = 1;\n            }\n            else{\n                if(i % 2 == 0){\n                    int fact = 1;\n                    for(int j = 1; j <= i; ++j){\n                        fact = (fact * j) % mod;\n                    }\n                    val = fact;\n                }\n                else{\n                    val = (i * (i + 1)) / 2;\n                }\n            }\n            vec_res = vsetq_lane_s32(val, vec_res, i - start_idx);\n        }\n\n        for(int i = start_idx; i < end_idx; ++i){\n            result[i] = vgetq_lane_s32(vec_res, i - start_idx);\n        }\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_113_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int> even_odd_palindrome_simd(int n){\n    int even = 0, odd = 0;\n    int step = 8;\n    for(int i = 1; i < n; i += step){\n        uint32x4_t nums = vdupq_n_u32(i);\n        uint32x4_t limits = vdupq_n_u32(i + step - 1);\n        uint32x4_t cmp = vcgtq_u32(nums, vdupq_n_u32(n));\n        uint32x4_t valids = vandq_u32(vcgeq_u32(nums, vdupq_n_u32(1)), vcleq_u32(nums, vdupq_n_u32(n)));\n        \n        uint32x4_t revs =vreverseq_u32(nums);\n        uint32x4_t pals = vceqq_u32(nums, revs);\n        uint32x4_t evens = vandq_u32(pals, vceqzq_u32(vandq_u32(nums, vdupq_n_u32(1))));\n        uint32x4_t odds = vandq_u32(pals, vcvteq_f32_u32(vandq_u32(nums, vdupq_n_u32(1))));\n\n        even += vaddvq_u32(vandq_u32(evens, valids));\n        odd += vaddvq_u32(vandq_u32(odds, valids));\n    }\n    return std::vector<int>{even, odd};\n}\n```"}
{"task_id": "SimdBench_113_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int> even_odd_palindrome_simd(int n){\n    int even = 0, odd = 0;\n    int count = 0;\n    int step = 8;\n\n    for(int i = 1; i <= n; i += step){\n        int num_elements = (n - i + 1) >= step ? step : (n - i + 1);\n\n        uint32x4_t vec_i = vdupq_n_u32(i);\n        uint32x4_t vec_step = vdupq_n_u32(1);\n        uint32x4_t vec_mask = vdupq_n_u32(num_elements);\n\n        uint32x4_t palindrome_check = vmovemask_u32(vceqq_u32(vec_i, vec_i));\n        uint32x4_t is_even = vmovemask_u32(vtstq_u32(vec_i, vdupq_n_u32(1)));\n\n        int p_check = vget_lane_u32(palindrome_check, 0);\n        int even_check = vget_lane_u32(is_even, 0);\n\n        if(p_check){\n            if(even_check){\n                even += __builtin_popcount(even_check);\n            }\n            else{\n                odd += num_elements - __builtin_popcount(even_check);\n            }\n        }\n    }\n\n    std::vector<int> result = {even, odd};\n    return result;\n}\n```"}
{"task_id": "SimdBench_113_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int> even_odd_palindrome_simd(int n){\n    int even = 0, odd = 0;\n    int step = 8;\n    for(int i = 1; i <= n; i += step){\n        uint32x4_t nums = vmovq_n_u32(i);\n        uint32x4_t reversed_nums = vmovq_n_u32(0);\n        uint32x4_t cmp_even = vmovq_n_u32(0);\n        uint32x4_t cmp_odd = vmovq_n_u32(0);\n\n        for(int j=0; j < step && (i + j) <= n; ++j){\n            uint32_t num = i + j;\n            uint32_t rev = 0;\n            uint32_t temp = num;\n            while(temp > 0){\n                rev = rev * 10 + temp % 10;\n                temp /= 10;\n            }\n            if(num == rev){\n                uint32x4_t vnum = vdupq_n_u32(num);\n                uint32x4_t even_check = vandq_u32(vnum, vdupq_n_u32(1));\n                uint32x4_t odd_check = vbicq_u32(vnum, vdupq_n_u32(1));\n                cmp_even = vorrq_u32(cmp_even, even_check);\n                cmp_odd = vorrq_u32(cmp_odd, odd_check);\n            }\n        }\n\n        even += vaddvq_u32(vcgeq_u32(cmp_even, vdupq_n_u32(0)));\n        odd += vaddvq_u32(vcgeq_u32(cmp_odd, vdupq_n_u32(1)));\n    }\n    return std::vector<int>{even, odd};\n}\n```"}
{"task_id": "SimdBench_113_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int> even_odd_palindrome_simd(int n){\n    int even = 0, odd = 0;\n    \n    // Handle single-digit palindromes\n    if (n >= 9) {\n        even = 4;\n        odd = 5;\n        if (n == 9) {\n            return {even, odd};\n        }\n    } else {\n        for (int i = 1; i <= n; ++i) {\n            if (i % 2 == 0) even++;\n            else odd++;\n        }\n        return {even, odd};\n    }\n\n    // Handle two-digit palindromes using SIMD\n    uint16x8_t v_n = vmovq_n_u16(n);\n    uint16x8_t v_one = vmovq_n_u16(1);\n    uint16x8_t v_two = vmovq_n_u16(2);\n    uint16x8_t v_ten = vmovq_n_u16(10);\n\n    uint16x8_t v_count = vmovq_n_u16(11); // Start from 11\n\n    while (true) {\n        uint16x8_t v_cmp = vcgeq_u16(v_count, v_n);\n        if (vget_lane_u16(vcount_get_lane_u16(v_cmp, 0), 0)) break;\n\n        uint16x8_t v_mod = vmls_u16(v_count, vmls_u16(v_count, v_ten, v_count), v_count);\n        uint16x8_t v_even_mask = vandq_u16(vmod, vcmpneq_u16(vmod, v_zero));\n        uint16x8_t v_odd_mask = vbicq_u16(vmod, vcmpneq_u16(vmod, v_zero));\n\n        even += vaddv_u16(vshr_n_u16(v_even_mask, 1));\n        odd += vaddv_u16(vodd_mask);\n\n        v_count = vaddq_u16(v_count, v_two);\n    }\n\n    return {even, odd};\n}\n```"}
{"task_id": "SimdBench_113_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int> even_odd_palindrome_simd(int n){\n    int even = 0, odd = 0;\n    int step = 8;\n    int limit = n - (n % step);\n\n    for(int i = 1; i <= limit; i += step){\n        uint32x4_t nums_low  = vdupq_n_u32(i);\n        uint32x4_t nums_high = vdupq_n_u32(i + 4);\n        uint32x4_t inc_vec   = vdupq_n_u32(1);\n        \n        nums_low  = vaddq_u32(nums_low,  vcombine_u32(vdup_n_u32(0), vcreate_u32(0x01020304)));\n        nums_high = vaddq_u32(nums_high, vcombine_u32(vdup_n_u32(4), vcreate_u32(0x01020304)));\n\n        // Check palindrome property\n        uint32x4_t reversed_low  = vrbitq_u32(nums_low);\n        uint32x4_t reversed_high = vrbitq_u32(nums_high);\n        reversed_low  = vrev32q_u32(reversed_low);\n        reversed_high = vrev32q_u32(reversed_high);\n\n        uint32x4_t cmp_low  = vceqq_u32(nums_low, reversed_low);\n        uint32x4_t cmp_high = vceqq_u32(nums_high, reversed_high);\n\n        // Check even/odd\n        uint32x4_t even_mask_low  = vmovq_n_u32(0x55555555);\n        uint32x4_t even_mask_high = vmovq_n_u32(0x55555555);\n\n        uint32x4_t is_even_low  = vandq_u32(nums_low, even_mask_low);\n        uint32x4_t is_even_high = vandq_u32(nums_high, even_mask_high);\n\n        uint32x4_t even_cmp_low  = vceqq_u32(is_even_low, vdupq_n_u32(0));\n        uint32x4_t even_cmp_high = vceqq_u32(is_even_high, vdupq_n_u32(0));\n\n        uint32x4_t even_palindrome_low  = vandq_u32(cmp_low, even_cmp_low);\n        uint32x4_t even_palindrome_high = vandq_u32(cmp_high, even_cmp_high);\n\n        uint32x4_t odd_palindrome_low  = vbicq_u32(cmp_low, even_cmp_low);\n        uint32x4_t odd_palindrome_high = vbicq_u32(cmp_high, even_cmp_high);\n\n        even += vaddvq_u32(even_palindrome_low) + vaddvq_u32(even_palindrome_high);\n        odd += vaddvq_u32(odd_palindrome_low) + vaddvq_u32(odd_palindrome_high);\n    }\n\n    for(int i = limit + 1; i <= n; ++i){\n        if(is_palindrome(i)){\n            if(i % 2 == 0) even++;\n            else odd++;\n        }\n    }\n\n    return std::vector<int>{even, odd};\n}\n\nbool is_palindrome(int num){\n    int original = num;\n    int reversed = 0;\n    while(num > 0){\n        reversed = reversed * 10 + num % 10;\n        num /= 10;\n    }\n    return original == reversed;\n}\n```"}
{"task_id": "SimdBench_114_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nint count_nums_simd(std::vector<int> n){\n    if (n.empty()) return 0;\n\n    int count = 0;\n    size_t vec_size = n.size() / 4 * 4;\n    const int32x4_t zero = vdupq_n_s32(0);\n\n    for (size_t i = 0; i < vec_size; i += 4) {\n        int32x4_t vec = vld1q_s32(reinterpret_cast<const int32_t*>(&n[i]));\n        int32x4_t abs_vec = vabsq_s32(vec);\n        int32x4_t cmp = vcgtq_s32(abs_vec, zero);\n        uint32x4_t mask = vreinterpretq_u32_s32(cmp);\n        uint32x4_t ones = vdupq_n_u32(1);\n        uint32x4_t res = vandq_u32(mask, ones);\n        uint32x4_t acc = vpaddq_u32(res, vshrq_n_u32(res, 1));\n        acc = vpaddq_u32(acc, vshrq_n_u32(acc, 2));\n        count += vgetq_lane_u32(acc, 0);\n    }\n\n    for (size_t i = vec_size; i < n.size(); ++i) {\n        int num = n[i];\n        int sum = 0;\n        if (num == 0) {\n            sum = 0;\n        } else {\n            bool is_negative = num < 0;\n            num = std::abs(num);\n            while (num > 0) {\n                int digit = num % 10;\n                if (is_negative && num >= 10) digit = -digit;\n                sum += digit;\n                num /= 10;\n            }\n        }\n        if (sum > 0) count++;\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_114_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nint count_nums_simd(std::vector<int> n){\n    if (n.empty()) return 0;\n\n    size_t vec_size = n.size();\n    int16x8_t zero = vmovq_n_s16(0);\n    int count = 0;\n\n    for(size_t i = 0; i < vec_size; i += 8){\n        int32x4_t v = vld1q_s32(reinterpret_cast<const int32_t*>(&n[i]));\n        int32x4_t v_abs = vabsq_s32(v);\n\n        uint32x4_t ge_zero = vcgeq_s32(v, vmovq_n_s32(0));\n        int32x4_t sign_mask = vandq_u32(vmovq_n_u32(0xFFFFFFFF), vreinterpretq_u32_s32(ge_zero));\n\n        int32x4_t digits = vaddw_s16(vmull_s16(vget_low_s16(v_abs), vmov_n_s16(1)), vmull_s16(vget_high_s16(v_abs), vmov_n_s16(1)));\n        digits = vsubq_s32(digits, sign_mask);\n\n        int32x4_t sum_digits = vpaddlq_s32(vpadalq_s16(vmovl_s8(vqmovn_s16(vget_low_s16(digits))), vmovl_s8(vqmovn_s16(vget_high_s16(digits)))));\n\n        uint32x4_t gt_zero = vcgtq_s32(sum_digits, vmovq_n_s32(0));\n        count += vaddvq_u32(gt_zero);\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_114_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nint count_nums_simd(std::vector<int> n){\n    if (n.empty()) return 0;\n\n    int count = 0;\n    size_t vec_size = n.size() / 4 * 4;\n    const int32x4_t zero = vmovq_n_s32(0);\n\n    for(size_t i = 0; i < vec_size; i += 4){\n        int32x4_t vec = vld1q_s32(&n[i]);\n        \n        // Absolute value except for the sign bit of first digit\n        int32x4_t abs_vec = vabsq_s32(vec);\n        uint32x4_t signs = vcgeq_s32(vec, zero); \n\n        // Extract digits and sum them\n        int32x4_t d1 = vshrq_n_s32(abs_vec, 0);\n        int32x4_t d2 = vshrq_n_s32(abs_vec, 10) & vmovq_n_s32(0x3ff);\n        int32x4_t d3 = vshrq_n_s32(abs_vec, 20) & vmovq_n_s32(0x3ff);\n        int32x4_t d4 = vshrq_n_s32(abs_vec, 30) & vmovq_n_s32(0x3ff);\n\n        int32x4_t sum_digits = vaddq_s32(d1, d2);\n        sum_digits = vaddq_s32(sum_digits, d3);\n        sum_digits = vaddq_s32(sum_digits, d4);\n\n        // Adjust for negative numbers\n        int32x4_t neg_adj = vandq_s32(d1, vmvnq_u32(signs));\n        sum_digits = vsubq_s32(sum_digits, neg_adj);\n\n        // Compare sums to zero\n        uint32x4_t mask = vcgtq_s32(sum_digits, zero);\n        int32x4_t res = vaddvq_u32(mask);\n        count += vget_lane_s32(res, 0);\n    }\n\n    // Handle remaining elements\n    for(size_t i = vec_size; i < n.size(); ++i){\n        int num = n[i];\n        int sum = 0;\n        bool is_negative = num < 0;\n        while(num != 0){\n            int digit = num % 10;\n            if(is_negative && sum == 0) digit *= -1;\n            sum += std::abs(digit);\n            num /= 10;\n        }\n        if(sum > 0) count++;\n    }\n    return count;\n}\n```"}
{"task_id": "SimdBench_114_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nint count_nums_simd(std::vector<int> n){\n    if (n.empty()) return 0;\n\n    int count = 0;\n    size_t vec_size = n.size() / 4 * 4;\n    const int32_t *data = n.data();\n\n    for (size_t i = 0; i < vec_size; i += 4) {\n        int32x4_t v_num = vld1q_s32(data + i);\n        uint32x4_t v_pos_mask = vcgeq_s32(v_num, vmovq_n_s32(0));\n        int32x4_t v_abs_num = vabsq_s32(v_num);\n\n        // Compute digits sum for positive numbers\n        int32x4_t v_digits_sum = vmovq_n_s32(0);\n        v_digits_sum = vaddw_u8(v_digits_sum, vmovl_u8(vreinterpret_u8_s32(v_abs_num)));\n        v_digits_sum = vaddw_u8(v_digits_sum, vmovl_u8(vshrn_n_u16(vmovl_u8(vreinterpret_u8_s32(v_abs_num)), 4)));\n\n        // Adjust for negative numbers\n        int32x4_t v_neg_adj = vandq_s32(vdupq_n_s32(-1), vmvnq_u32(v_pos_mask));\n        v_digits_sum = vsubq_s32(v_digits_sum, vandq_s32(v_neg_adj, vdupq_n_s32(1)));\n\n        // Compare with zero and count\n        uint32x4_t v_cmp = vcgtq_s32(v_digits_sum, vmovq_n_s32(0));\n        uint32x4_t v_cnt = vclzq_u32(vreinterpretq_u32_u8(vcntq_u8(vcmpneq_f32(vreinterpretq_f32_u32(v_cmp), vmovq_n_f32(0)))));\n        count += vaddvq_u32(vandq_u32(v_cmp, v_cnt)) >> 5;\n    }\n\n    // Handle remaining elements\n    for (size_t i = vec_size; i < n.size(); ++i) {\n        int num = n[i];\n        int sum = 0;\n        bool is_negative = num < 0;\n        num = abs(num);\n        while (num > 0) {\n            sum += num % 10;\n            num /= 10;\n        }\n        if (is_negative) sum = -sum;\n        if (sum > 0) count++;\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_114_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nint count_nums_simd(std::vector<int> n){\n    if (n.empty()) return 0;\n\n    int count = 0;\n    size_t vec_size = n.size() / 4 * 4;\n    const int32_t* data = n.data();\n\n    int32x4_t zero = vmovq_n_s32(0);\n    int32x4_t ten = vmovq_n_s32(10);\n    int32x4_t neg_one = vmovq_n_s32(-1);\n\n    for (size_t i = 0; i < vec_size; i += 4) {\n        int32x4_t nums = vld1q_s32(data + i);\n        int32x4_t abs_nums = vabsq_s32(nums);\n        int32x4_t signs = vcgeq_s32(nums, zero);\n\n        int32x4_t sum_digits = zero;\n\n        for (int j = 0; j < 4; ++j) {\n            int32x4_t remainder = vabsq_s32(vsqaddq_s32(vmull_n_s16(vshrq_n_s16(abs_nums, 16), 1), vmul_n_s16(vandq_s16(abs_nums, vmovq_n_s32(0xFFFF)), 1)));\n            sum_digits = vaddq_s32(sum_digits, remainder);\n            abs_nums = vshlq_n_s32(abs_nums, -1);\n        }\n\n        int32x4_t adjusted_sum = vsubq_s32(sum_digits, vmulq_s32(signs, vdupq_lane_s32(vget_low_s32(sum_digits), 0)));\n        uint32x4_t mask = vcgtq_s32(adjusted_sum, zero);\n        count += vaddvq_u32(mask);\n    }\n\n    for (size_t i = vec_size; i < n.size(); ++i) {\n        int num = n[i];\n        int sum = 0;\n        bool is_negative = num < 0;\n        while (num != 0) {\n            int digit = num % 10;\n            if (is_negative && num > 0) digit *= -1;\n            sum += digit;\n            num /= 10;\n        }\n        if (sum > 0) count++;\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_115_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nbool move_one_ball_simd(std::vector<int> arr){\n    if (arr.empty()) return true;\n\n    size_t N = arr.size();\n    int breaks = 0;\n    int32x4_t vec_breaks = vdupq_n_s32(0);\n\n    for(size_t i = 0; i < N; ++i){\n        if(arr[i] > arr[(i+1)%N]){\n            breaks++;\n            // Use SIMD to handle multiple comparisons at once if possible\n            size_t j = i;\n            for(; j + 4 <= N; j += 4){\n                int32x4_t vec_curr = vld1q_s32(&arr[j]);\n                int32x4_t vec_next = vld1q_s32(&arr[(j+1)%N]);\n                uint32x4_t cmp_res = vcgtq_s32(vec_curr, vec_next);\n                vec_breaks = vaddq_u32(vec_breaks, vreinterpretq_u32_s32(cmp_res));\n            }\n            breaks += vaddvq_u32(vec_breaks);\n            for(; j < N; ++j){\n                if(arr[j] > arr[(j+1)%N]) breaks++;\n            }\n        }\n    }\n\n    return breaks <= 1;\n}\n```"}
{"task_id": "SimdBench_115_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nbool move_one_ball_simd(std::vector<int> arr) {\n    const int N = static_cast<int>(arr.size());\n    if (N <= 1) return true;\n\n    // Find the index where the smallest element is located\n    int min_index = 0;\n    for(int i = 1; i < N; ++i){\n        if(arr[i] < arr[min_index]){\n            min_index = i;\n        }\n    }\n\n    // Rotate the array so that the smallest element is at the start\n    std::vector<int> rotated_arr = arr;\n    for(int i = 0; i < N; ++i){\n        rotated_arr[i] = arr[(min_index + i) % N];\n    }\n\n    // Check if the rotated array is sorted using NEON intrinsics\n    int *data = rotated_arr.data();\n    int vec_size = N / 4; // Number of NEON vectors we can process\n    int remainder = N % 4; // Remaining elements to check\n\n    bool is_sorted = true;\n\n    // Process in chunks of 4 elements using NEON\n    for(int i = 0; i < vec_size - 1; ++i){\n        int32x4_t v_curr = vld1q_s32(data + 4 * i);\n        int32x4_t v_next = vld1q_s32(data + 4 * (i + 1));\n\n        uint32x4_t v_cmp = vcgeq_s32(v_next, v_curr); // Compare current with next\n        if(vminvq_u32(vreinterpretq_u32_s32(v_cmp)) == 0){\n            is_sorted = false;\n            break;\n        }\n    }\n\n    // Check remaining elements sequentially\n    if(is_sorted && remainder > 0){\n        for(int i = vec_size * 4; i < N - 1; ++i){\n            if(rotated_arr[i] > rotated_arr[i + 1]){\n                is_sorted = false;\n                break;\n            }\n        }\n    }\n\n    return is_sorted;\n}\n```"}
{"task_id": "SimdBench_115_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nbool move_one_ball_simd(std::vector<int> arr){\n    size_t N = arr.size();\n    if (N == 0) return true;\n\n    // Convert vector to Neon compatible array\n    alignas(16) int data[4 * ((N + 3) / 4)];\n    for (size_t i = 0; i < N; ++i) {\n        data[i] = arr[i];\n    }\n\n    int count = 0;\n    int drop_count = 0;\n\n    for (size_t i = 0; i < N; i += 4) {\n        int32x4_t vec_curr = vld1q_s32(&data[i]);\n        int32x4_t vec_next = vld1q_s32(&data[(i + 1) % N]);\n\n        uint32x4_t cmp_result = vcgeq_s32(vec_next, vec_curr);\n        uint32x4_t mask = vdupq_n_u32(0xFFFFFFFF);\n\n        uint32x4_t res_and = vandq_u32(cmp_result, mask);\n\n        int32x4_t count_vec = vmovl_u16(vget_low_u16(vreinterpretq_u16_u32(res_and)));\n        int sum = vaddvq_s32(count_vec);\n\n        drop_count += 4 - sum;\n    }\n\n    return drop_count <= 1;\n}\n```"}
{"task_id": "SimdBench_115_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nbool move_one_ball_simd(std::vector<int> arr) {\n    if (arr.empty()) return true;\n\n    size_t N = arr.size();\n    if (N <= 1) return true;\n\n    // Find the index where the smallest element is located\n    int* data = arr.data();\n    int32x4_t min_val = vld1q_s32(data);\n    uint32x4_t min_idx = vmovq_n_u32(0);\n\n    for (size_t i = 1; i < N / 4; ++i) {\n        int32x4_t val = vld1q_s32(data + i * 4);\n        uint32x4_t idx = vcltq_s32(val, vget_lane_s32(min_val, 0));\n        min_val = vminq_s32(min_val, val);\n        min_idx = vorrq_u32(min_idx, idx);\n    }\n\n    int min_element = vminvq_s32(min_val);\n    int min_index = 0;\n    for (size_t i = 0; i < N; ++i) {\n        if (arr[i] == min_element) {\n            min_index = i;\n            break;\n        }\n    }\n\n    // Check if the array can be sorted by rotating\n    int count = 0;\n    for (size_t i = 0; i < N; ++i) {\n        size_t rotated_index = (min_index + i) % N;\n        if (arr[rotated_index] < arr[(rotated_index - 1 + N) % N]) {\n            count++;\n            if (count > 1) return false;\n        }\n    }\n\n    return count <= 1;\n}\n```"}
{"task_id": "SimdBench_115_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nbool move_one_ball_simd(std::vector<int> arr){\n    size_t N = arr.size();\n    if (N == 0) return true;\n\n    // Find the index where the smallest element is located\n    int min_val = *std::min_element(arr.begin(), arr.end());\n    size_t min_idx = 0;\n    for (; min_idx < N; ++min_idx) {\n        if (arr[min_idx] == min_val) break;\n    }\n\n    // Perform logical rotation by considering the array as circular\n    size_t count_descending = 0;\n    for (size_t i = 0; i < N; ++i) {\n        size_t j = (min_idx + i) % N;\n        size_t k = (min_idx + i + 1) % N;\n\n        // Load two elements into SIMD registers\n        int32x2_t v_j = vdup_n_s32(arr[j]);\n        int32x2_t v_k = vdup_n_s32(arr[k]);\n\n        // Compare using SIMD\n        uint32x2_t result = vcge_s32(v_j, v_k); // Check if arr[j] >= arr[k]\n        count_descending += vget_lane_u32(result, 0);\n    }\n\n    // If there is at most one place where the order is descending, it's possible\n    return count_descending <= 1;\n}\n```"}
{"task_id": "SimdBench_116_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nstd::string myexchange_simd(const std::vector<int>& lst1, const std::vector<int>& lst2){\n    int count_odd_lst1 = 0;\n    int count_even_lst2 = 0;\n\n    // Count odd numbers in lst1 using NEON\n    size_t n = lst1.size();\n    for (size_t i = 0; i < n; i += 4) {\n        int32x4_t v = vld1q_s32(reinterpret_cast<const int32_t*>(&lst1[i]));\n        int32x4_t one = vdupq_n_s32(1);\n        uint32x4_t mask = vcgeq_s32(vandq_s32(v, one), one); // Check if odd\n        count_odd_lst1 += vaddvq_u32(vcvtq_u32_s32(mask));\n    }\n\n    // Count even numbers in lst2 using NEON\n    n = lst2.size();\n    for (size_t i = 0; i < n; i += 4) {\n        int32x4_t v = vld1q_s32(reinterpret_cast<const int32_t*>(&lst2[i]));\n        int32x4_t one = vdupq_n_s32(1);\n        uint32x4_t mask = vcleq_s32(vandq_s32(v, one), vdupq_n_s32(0)); // Check if even\n        count_even_lst2 += vaddvq_u32(vcvtq_u32_s32(mask));\n    }\n\n    return (count_odd_lst1 <= count_even_lst2) ? \"YES\" : \"NO\";\n}\n```"}
{"task_id": "SimdBench_116_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nstd::string myexchange_simd(const std::vector<int>& lst1, const std::vector<int>& lst2){\n    int count_odd_lst1 = 0;\n    int count_even_lst2 = 0;\n\n    size_t n = lst1.size();\n    size_t m = lst2.size();\n\n    // Process lst1 in SIMD chunks\n    for (size_t i = 0; i + 3 < n; i += 4) {\n        int32x4_t v = vld1q_s32(&lst1[i]);\n        int32x4_t mask = vandq_s32(v, vdupq_n_s32(1));\n        uint32x4_t cmp = vcgeq_u32(vreinterpretq_u32_s32(mask), vdupq_n_u32(1));\n        count_odd_lst1 += vaddvq_u32(vcvtmq_u32_f32(vreinterpretq_f32_u32(cmp)));\n    }\n    // Tail processing for lst1\n    for (size_t i = (n / 4) * 4; i < n; ++i) {\n        if (lst1[i] % 2 != 0) count_odd_lst1++;\n    }\n\n    // Process lst2 in SIMD chunks\n    for (size_t i = 0; i + 3 < m; i += 4) {\n        int32x4_t v = vld1q_s32(&lst2[i]);\n        int32x4_t mask = vandq_s32(v, vdupq_n_s32(1));\n        uint32x4_t cmp = vcleq_u32(vreinterpretq_u32_s32(mask), vdupq_n_u32(0));\n        count_even_lst2 += vaddvq_u32(vcvtmq_u32_f32(vreinterpretq_f32_u32(cmp)));\n    }\n    // Tail processing for lst2\n    for (size_t i = (m / 4) * 4; i < m; ++i) {\n        if (lst2[i] % 2 == 0) count_even_lst2++;\n    }\n\n    return (count_odd_lst1 <= count_even_lst2) ? \"YES\" : \"NO\";\n}\n```"}
{"task_id": "SimdBench_116_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nstd::string myexchange_simd(const std::vector<int>& lst1, const std::vector<int>& lst2){\n    int odd_count_lst1 = 0;\n    int even_count_lst2 = 0;\n\n    // Count odd numbers in lst1 using NEON\n    for(size_t i = 0; i + 3 < lst1.size(); i += 4){\n        int32x4_t v = vld1q_s32(&lst1[i]);\n        int32x4_t mask = vandq_s32(v, vdupq_n_s32(1));\n        uint32x4_t cmp = vcleq_u32(mask, vdupq_n_u32(0));\n        odd_count_lst1 += vaddvq_u32(vcvtq_u32_s32(vnegq_s32(cmp)));\n    }\n    // Handle remaining elements\n    for(size_t i = lst1.size() - (lst1.size() % 4); i < lst1.size(); ++i){\n        if(lst1[i] % 2 != 0) odd_count_lst1++;\n    }\n\n    // Count even numbers in lst2 using NEON\n    for(size_t i = 0; i + 3 < lst2.size(); i += 4){\n        int32x4_t v = vld1q_s32(&lst2[i]);\n        int32x4_t mask = vandq_s32(v, vdupq_n_s32(1));\n        uint32x4_t cmp = vceqq_u32(mask, vdupq_n_u32(0));\n        even_count_lst2 += vaddvq_u32(vcvtq_u32_s32(cmp));\n    }\n    // Handle remaining elements\n    for(size_t i = lst2.size() - (lst2.size() % 4); i < lst2.size(); ++i){\n        if(lst2[i] % 2 == 0) even_count_lst2++;\n    }\n\n    if(even_count_lst2 >= odd_count_lst1){\n        return \"YES\";\n    }\n    else{\n        return \"NO\";\n    }\n}\n```"}
{"task_id": "SimdBench_116_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nstd::string myexchange_simd(const std::vector<int>& lst1, const std::vector<int>& lst2){\n    int count_odd_lst1 = 0;\n    int count_even_lst2 = 0;\n\n    // Count odd numbers in lst1 using NEON\n    for(size_t i = 0; i + 3 < lst1.size(); i += 4){\n        int32x4_t v = vld1q_s32(&lst1[i]);\n        int32x4_t mask = vandq_s32(v, vdupq_n_s32(1));\n        uint32x4_t cmp = vcgeq_u32(vreinterpretq_u32_s32(mask), vdupq_n_u32(1));\n        count_odd_lst1 += vaddvq_u8(vreinterpretq_u8_u32(cmp));\n    }\n    // Handle remaining elements\n    for(size_t i = lst1.size() - (lst1.size() % 4); i < lst1.size(); ++i){\n        if(lst1[i] % 2 != 0) count_odd_lst1++;\n    }\n\n    // Count even numbers in lst2 using NEON\n    for(size_t i = 0; i + 3 < lst2.size(); i += 4){\n        int32x4_t v = vld1q_s32(&lst2[i]);\n        int32x4_t mask = vandq_s32(v, vdupq_n_s32(1));\n        uint32x4_t cmp = vceqq_u32(vreinterpretq_u32_s32(mask), vdupq_n_u32(0));\n        count_even_lst2 += vaddvq_u8(vreinterpretq_u8_u32(cmp));\n    }\n    // Handle remaining elements\n    for(size_t i = lst2.size() - (lst2.size() % 4); i < lst2.size(); ++i){\n        if(lst2[i] % 2 == 0) count_even_lst2++;\n    }\n\n    return count_odd_lst1 <= count_even_lst2 ? \"YES\" : \"NO\";\n}\n```"}
{"task_id": "SimdBench_116_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <string>\n\nstd::string myexchange_simd(const std::vector<int>& lst1, const std::vector<int>& lst2){\n    int count_odd_lst1 = 0;\n    int count_even_lst2 = 0;\n\n    // Count odd numbers in lst1 using Neon\n    for(size_t i = 0; i + 3 < lst1.size(); i += 4){\n        int32x4_t v = vld1q_s32(&lst1[i]);\n        int32x4_t mask = vmovq_n_s32(1);\n        uint32x4_t res = vceqq_s32(vandq_s32(v, vmovq_n_s32(1)), mask);\n        count_odd_lst1 += vaddvq_u32(res);\n    }\n    // Handle remaining elements\n    for(size_t i = lst1.size() & ~3; i < lst1.size(); ++i){\n        if(lst1[i] % 2 != 0) count_odd_lst1++;\n    }\n\n    // Count even numbers in lst2 using Neon\n    for(size_t i = 0; i + 3 < lst2.size(); i += 4){\n        int32x4_t v = vld1q_s32(&lst2[i]);\n        uint32x4_t res = vceqq_s32(vandq_s32(v, vmovq_n_s32(1)), vmovq_n_s32(0));\n        count_even_lst2 += vaddvq_u32(res);\n    }\n    // Handle remaining elements\n    for(size_t i = lst2.size() & ~3; i < lst2.size(); ++i){\n        if(lst2[i] % 2 == 0) count_even_lst2++;\n    }\n\n    return count_odd_lst1 <= count_even_lst2 ? \"YES\" : \"NO\";\n}\n```"}
{"task_id": "SimdBench_117_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <string>\n\nstd::vector<std::string> odd_count_simd(const std::vector<std::string> & lst){\n    std::vector<std::string> result;\n    uint8x16_t odds = vdupq_n_u8(0);\n    uint8x16_t digits = vdupq_n_u8(0);\n    uint8x16_t ones = vdupq_n_u8(1);\n    uint8x16_t count = vdupq_n_u8(0);\n\n    for (const auto& str : lst) {\n        int total_odd = 0;\n        size_t len = str.length();\n        for (size_t i = 0; i < len; i += 16) {\n            size_t chunk_size = std::min((size_t)16, len - i);\n            for (size_t j = 0; j < chunk_size; ++j) {\n                uint8_t digit = str[i + j] - '0';\n                digits = vsetq_lane_u8(digit, digits, j);\n                odds = vsetq_lane_u8(digit & 1, odds, j);\n            }\n            uint8x16_t mask = vcgeq_u8(odds, digits);\n            count = vaddq_u8(count, vandq_u8(mask, ones));\n        }\n        int count_sum = 0;\n        uint8x8_t count_low = vget_low_u8(count);\n        uint8x8_t count_high = vget_high_u8(count);\n        uint8x8_t sum1 = vpaddl_u8(count_low);\n        uint8x8_t sum2 = vpaddl_u8(count_high);\n        uint16x4_t sum3 = vpaddl_u16(vget_low_u16(sum1));\n        uint16x4_t sum4 = vpaddl_u16(vget_low_u16(sum2));\n        uint32x2_t sum5 = vpaddl_u32(vget_low_u32(sum3));\n        uint32x2_t sum6 = vpaddl_u32(vget_low_u32(sum4));\n        count_sum += vget_lane_u32(sum5, 0) + vget_lane_u32(sum5, 1);\n        count_sum += vget_lane_u32(sum6, 0) + vget_lane_u32(sum6, 1);\n\n        std::string res = \"the number of odd elements \";\n        res += std::to_string(count_sum);\n        res += \"n the str\";\n        res += std::to_string(count_sum);\n        res += \"ng \";\n        res += std::to_string(count_sum);\n        res += \" of the \";\n        res += std::to_string(count_sum);\n        res += \"nput.\";\n        result.push_back(res);\n        count = vdupq_n_u8(0);\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_117_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <string>\n\nstd::vector<std::string> odd_count_simd(const std::vector<std::string> & lst){\n    std::vector<std::string> result;\n    uint8x16_t odds = vdupq_n_u8(0);\n    uint8x16_t digits = vdupq_n_u8(0);\n    uint8x16_t ones = vdupq_n_u8(1);\n    uint8x16_t mask;\n\n    for (const auto& str : lst) {\n        int count = 0;\n        size_t len = str.length();\n        for (size_t i = 0; i < len; i += 16) {\n            size_t chunk_size = std::min((size_t)16, len - i);\n            for (size_t j = 0; j < chunk_size; ++j) {\n                uint8_t digit = str[i + j] - '0';\n                digits = vsetq_lane_u8(digit, digits, j);\n            }\n            // Create a mask for odd digits\n            mask = vcgeq_u8(digits, vdupq_n_u8(1));\n            mask = vandq_u8(mask, vmovq_n_u8(0x55));\n            // Count the number of set bits in the mask\n            uint8x16_t tmp = vcntq_u8(mask);\n            uint16x8_t sums = vpaddlq_u8(tmp);\n            uint32x4_t sum_high = vpaddlq_u16(vget_high_u16(sums));\n            uint32x4_t sum_low = vpaddlq_u16(vget_low_u16(sums));\n            uint64x2_t total = vpaddlq_u32(vaddq_u32(sum_high, sum_low));\n            count += static_cast<int>(vaddvq_u64(total));\n        }\n        std::string output = \"the number of odd elements \";\n        output += std::to_string(count);\n        output += \"n the str\";\n        output += std::to_string(count);\n        output += \"ng \";\n        output += std::to_string(count);\n        output += \" of the \";\n        output += std::to_string(count);\n        output += \"nput.\";\n        result.push_back(output);\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_117_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <string>\n\nstd::vector<std::string> odd_count_simd(const std::vector<std::string> & lst){\n    std::vector<std::string> result;\n    result.reserve(lst.size());\n\n    const uint8x16_t vzero = vmovq_n_u8(0);\n    const uint8x16_t vones = vmovq_n_u8(1);\n    const uint8x16_t vodd_mask = vdupq_n_u8(0x01); // Mask for checking odd digits (0x31 - '1' is odd)\n    const uint8x16_t vdigit_mask = vdupq_n_u8(0x0F); // Mask to isolate digit value\n\n    for (const auto& str : lst) {\n        size_t count = 0;\n        size_t len = str.length();\n        for (size_t i = 0; i < len; i += 16) {\n            size_t chunk_size = std::min(len - i, size_t(16));\n            uint8x16_t vdata = vld1q_u8(reinterpret_cast<const uint8_t*>(&str[i]));\n            uint8x16_t vdigits = vandq_u8(vdata, vdigit_mask); // Isolate digit values\n            uint8x16_t vodds = vandq_u8(vdigits, vodd_mask); // Check which are odd\n            uint8x16_t vcmp = vceqq_u8(vodds, vodd_mask); // Compare with 0x01\n            uint8x16_t vcounts = vandq_u8(vcmp, vones); // Convert to 1s and 0s\n            uint8x16_t vacc = vpaddlq_u8(vcounts); // Accumulate counts\n            uint16x8_t vsum1 = vpaddlq_u8(vacc); // Horizontal add\n            uint32x4_t vsum2 = vpaddlq_u16(vsum1); // Horizontal add\n            uint64x2_t vsum3 = vpaddlq_u32(vreinterpretq_u32_u64(vmovl_u32(vget_low_u32(vsum2))), \n                                      vmovl_u32(vget_high_u32(vsum2))); // Final horizontal add\n            count += static_cast<size_t>(vget_lane_u64(vaddlv_u64(vsum3), 0)); // Extract sum\n        }\n\n        char buffer[100];\n        snprintf(buffer, sizeof(buffer), \"the number of odd elements %zn the str%zng %z of the %znput.\", \n                 count, count, count, count);\n        result.emplace_back(buffer);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_117_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <string>\n\nstd::vector<std::string> odd_count_simd(const std::vector<std::string> & lst){\n    std::vector<std::string> result;\n    uint8x16_t v_odd_mask = vmovq_n_u8(0);\n    uint8x16_t v_digits = vmovq_n_u8(0);\n    uint8x16_t v_48 = vmovq_n_u8('0');\n    \n    // Create a mask for odd digits\n    for(int i=0; i<10; ++i){\n        if(i % 2 != 0){\n            v_odd_mask = vsetq_lane_u8(1, v_odd_mask, i);\n        }\n    }\n\n    for(const auto& str : lst){\n        int count = 0;\n        size_t len = str.length();\n        for(size_t i=0; i<len; i+=16){\n            size_t chunk_size = std::min(len - i, (size_t)16);\n            for(size_t j=0; j<chunk_size; ++j){\n                v_digits = vsetq_lane_u8(str[i+j] - '0', v_digits, j);\n            }\n            uint8x16_t v_cmp = vcgeq_u8(vandq_u8(v_digits, vmovq_n_u8(1)), vmovq_n_u8(0));\n            uint8x16_t v_res = vandq_u8(v_cmp, v_odd_mask);\n            uint8x16_t v_cnt = vcntq_u8(v_res);\n            int32x4_t v_sum = vpaddlq_s16(vreinterpretq_s16_u8(v_cnt));\n            int32x2_t v_sum2 = vpaddl_s32(vget_low_s32(v_sum), vget_high_s32(v_sum));\n            int total = vget_lane_s32(vadd_s32(vget_low_s32(v_sum2), vget_high_s32(v_sum2)), 0);\n            count += total;\n        }\n        std::string output = \"the number of odd elements \";\n        output += std::to_string(count);\n        output += \"n the str\";\n        output += std::to_string(count);\n        output += \"ng \";\n        output += std::to_string(count);\n        output += \" of the \";\n        output += std::to_string(count);\n        output += \"nput.\";\n        result.push_back(output);\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_117_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <string>\n\nstd::vector<std::string> odd_count_simd(const std::vector<std::string> & lst){\n    std::vector<std::string> result;\n    uint8x16_t v_odd_mask = vdupq_n_u8(0);\n    v_odd_mask = vorrq_u8(v_odd_mask, vdupq_n_u8(0x01));\n    v_odd_mask = vorrq_u8(v_odd_mask, vdupq_n_u8(0x03));\n    v_odd_mask = vorrq_u8(v_odd_mask, vdupq_n_u8(0x05));\n    v_odd_mask = vorrq_u8(v_odd_mask, vdupq_n_u8(0x07));\n    v_odd_mask = vorrq_u8(v_odd_mask, vdupq_n_u8(0x09));\n\n    for(const auto& str : lst){\n        size_t count = 0;\n        size_t len = str.length();\n        for(size_t i = 0; i < len; i += 16){\n            uint8x16_t v_chars = vld1q_u8(reinterpret_cast<const uint8_t*>(&str[i]));\n            uint8x16_t v_ods = vandq_u8(v_chars, vdupq_n_u8(0x0F));\n            uint8x16_t v_cmp = vceqq_u8(v_ods, v_odd_mask);\n            uint8x16_t v_cnt = vcntq_u8(v_cmp);\n            uint64x2_t v_sum = vpaddlq_u32(vreinterpretq_u32_u8(v_cnt));\n            uint64_t sum = vgetq_lane_u64(v_sum, 0) + vgetq_lane_u64(v_sum, 1);\n            count += sum;\n        }\n        // Handle remaining characters if any\n        size_t remainder = len % 16;\n        if(remainder > 0){\n            uint8x16_t v_chars = vld1q_u8_zero(reinterpret_cast<const uint8_t*>(&str[len - remainder]));\n            uint8x16_t v_ods = vandq_u8(v_chars, vdupq_n_u8(0x0F));\n            uint8x16_t v_cmp = vceqq_u8(v_ods, v_odd_mask);\n            uint8x16_t v_cnt = vcntq_u8(v_cmp);\n            uint64x2_t v_sum = vpaddlq_u32(vreinterpretq_u32_u8(v_cnt));\n            uint64_t sum = vgetq_lane_u64(v_sum, 0) + vgetq_lane_u64(v_sum, 1);\n            count += sum;\n        }\n        std::string res = \"the number of odd elements \";\n        res += std::to_string(count);\n        res += \"n the str\";\n        res += std::to_string(count);\n        res += \"ng \";\n        res += std::to_string(count);\n        res += \" of the \";\n        res += std::to_string(count);\n        res += \"nput.\";\n        result.push_back(res);\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_118_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <climits>\n\nint64_t minSubArraySum_simd(const std::vector<int64_t>& nums){\n    if (nums.empty()) return 0;\n\n    const int64_t* data = nums.data();\n    size_t size = nums.size();\n\n    int64x2_t current_min = vdupq_n_s64(INT64_MAX);\n    int64x2_t global_min = vdupq_n_s64(INT64_MAX);\n\n    for (size_t i = 0; i + 1 < size; i += 2) {\n        int64x2_t vec = vld1q_s64((const int64_t*)&data[i]);\n        \n        int64x2_t zero = vdupq_n_s64(0);\n        int64x2_t mask = vcgeq_s64(current_min, zero);\n        current_min = vbslq_s64(mask, vec, vaddq_s64(current_min, vec));\n\n        global_min = vminq_s64(global_min, current_min);\n    }\n\n    int64_t result = INT64_MAX;\n    result = vminvq_s64(global_min);\n\n    if (size % 2 != 0) {\n        int64_t last = nums[size - 1];\n        int64_t temp_min = last < 0 ? last : (result < 0 ? result + last : last);\n        result = temp_min < result ? temp_min : result;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_118_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <climits>\n\nint64_t minSubArraySum_simd(const std::vector<int64_t>& nums){\n    if (nums.empty()) return 0;\n\n    size_t n = nums.size();\n    int64x2_t current_min = vdupq_n_s64(LLONG_MAX);\n    int64x2_t global_min = vdupq_n_s64(LLONG_MAX);\n    int64x2_t temp;\n\n    for(size_t i = 0; i + 1 < n; i += 2){\n        int64x2_t vec = vld1q_s64((const int64_t*)&nums[i]);\n        temp = vaddq_s64(current_min, vec);\n        current_min = vminq_s64(temp, vec);\n        global_min = vminq_s64(global_min, current_min);\n    }\n\n    // Handle remaining element if any\n    if(n % 2 != 0){\n        int64x1_t last = vdup_n_s64(nums[n-1]);\n        int64x1_t last_min = vmin_s64(last, vget_low_s64(current_min));\n        global_min = vminq_s64(global_min, vcombine_s64(last_min, vdup_n_s64(LLONG_MAX)));\n    }\n\n    int64_t result = LLONG_MAX;\n    int64x2_t res = vpmin_s64(global_min, global_min);\n    result = vminv_s64(res);\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_118_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <climits>\n\nint64_t minSubArraySum_simd(const std::vector<int64_t>& nums){\n    if (nums.empty()) return 0;\n\n    const int64_t* data = nums.data();\n    int n = nums.size();\n\n    int64x2_t current_min = vdupq_n_s64(0);\n    int64x2_t global_min = vdupq_n_s64(INT64_MAX);\n\n    for(int i = 0; i + 1 < n; i += 2){\n        int64x2_t vec = vld1q_s64((const int64_t*)&data[i]);\n        \n        current_min = vpminq_s64(vaddq_s64(current_min, vec), vec);\n        global_min = vpminq_s64(global_min, current_min);\n    }\n\n    // Handle remaining element if any\n    if(n % 2 != 0){\n        int64x1_t last = vdup_n_s64(data[n-1]);\n        int64x1_t last_min = vmin_s64(last, vget_low_s64(current_min));\n        global_min = vmin_v_s64(global_min, last_min);\n    }\n\n    // Reduce to find the minimum value across all lanes\n    int64x1_t res = vpmin_s64(vget_low_s64(global_min), vget_high_s64(global_min));\n    return vget_lane_s64(res, 0);\n}\n```"}
{"task_id": "SimdBench_118_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <climits>\n\nint64_t minSubArraySum_simd(const std::vector<int64_t>& nums){\n    if (nums.empty()) return 0;\n\n    const int64_t* data = nums.data();\n    size_t size = nums.size();\n\n    int64x2_t current_min = vdupq_n_s64(LLONG_MAX);\n    int64x2_t global_min = vdupq_n_s64(LLONG_MAX);\n    int64x2_t temp_sum = vdupq_n_s64(0);\n\n    for (size_t i = 0; i + 1 < size; i += 2) {\n        int64x2_t vec = vld1q_s64(data + i);\n        \n        // Calculate the minimum subarray sum ending at each element\n        temp_sum = vpminq_s64(temp_sum, vec);\n        current_min = vaddq_s64(temp_sum, vec);\n\n        // Update global minimum\n        global_min = vpminq_s64(global_min, current_min);\n\n        // Prepare for next iteration\n        temp_sum = vdupq_laneq_s64(current_min, 1);\n    }\n\n    // Handle remaining elements if any\n    if (size % 2 != 0) {\n        int64x1_t last = vld1_s64(data + size - 1);\n        int64x1_t last_min = vmin_s64(temp_sum[0], last[0]);\n        global_min[0] = vmin_s64(global_min[0], last_min[0]);\n    }\n\n    // Extract scalar minimum value\n    int64_t result = vminvq_s64(global_min);\n    return result;\n}\n```"}
{"task_id": "SimdBench_118_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <climits>\n\nint64_t minSubArraySum_simd(const std::vector<int64_t>& nums){\n    if (nums.empty()) return 0;\n\n    const int64_t* data = nums.data();\n    size_t size = nums.size();\n\n    int64x2_t current_min = vdupq_n_s64(INT64_MAX);\n    int64x2_t global_min = vdupq_n_s64(INT64_MAX);\n    int64x2_t temp;\n\n    for (size_t i = 0; i + 1 < size; i += 2) {\n        int64x2_t vec = vld1q_s64(data + i);\n        temp = vminsq_s64(vec, vaddq_s64(current_min, vec));\n        current_min = temp;\n        global_min = vminsq_s64(global_min, current_min);\n        global_min = vminsq_s64(global_min, vec);\n    }\n\n    // Handle remaining element if any\n    if (size % 2 != 0) {\n        int64x1_t last = vld1_s64(data + size - 1);\n        int64x1_t last_min = vmin_s64(last, vget_low_s64(current_min));\n        global_min = vmin_s64(vget_low_s64(global_min), last_min);\n    }\n\n    int64_t result = vminvq_s64(global_min);\n    return result;\n}\n```"}
{"task_id": "SimdBench_119_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nint max_fill_simd(const std::vector<std::vector<int> > & grid, int capacity) {\n    int total_drops = 0;\n    int rows = grid.size();\n    if (rows == 0) return 0;\n    int cols = grid[0].size();\n\n    // Process each row using NEON intrinsics\n    for (int i = 0; i < rows; ++i) {\n        int sum = 0;\n        const int *row_data = grid[i].data();\n        int j = 0;\n\n        // NEON processing loop\n        for (; j + 15 < cols; j += 16) {\n            uint8x16_t vec = vld1q_u8(reinterpret_cast<const uint8_t*>(row_data + j));\n            uint8x16_t ones = vmovq_n_u8(1);\n            uint8x16_t cmp = vceqq_u8(vec, ones);\n            uint8x16_t mask = vandq_u8(cmp, ones);\n            int16x8_t sum_low = vpaddlq_s8(vreinterpretq_s8_u8(vget_low_u8(mask)));\n            int16x8_t sum_high = vpaddlq_s8(vreinterpretq_s8_u8(vget_high_u8(mask)));\n            int32x4_t sum_combined = vpaddlq_s16(vcombine_s16(vget_low_s16(sum_low), vget_low_s16(sum_high)));\n            int32x2_t sum_final = vpaddl_s32(vget_low_s32(sum_combined), vget_high_s32(sum_combined));\n            sum += vget_lane_s32(sum_final, 0);\n        }\n\n        // Tail processing\n        for (; j < cols; ++j) {\n            sum += row_data[j];\n        }\n\n        // Calculate drops for this row\n        total_drops += (sum + capacity - 1) / capacity;\n    }\n\n    return total_drops;\n}\n```"}
{"task_id": "SimdBench_119_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nint max_fill_simd(const std::vector<std::vector<int> > & grid, int capacity){\n    int total_drops = 0;\n    int num_wells = grid.size();\n    if (num_wells == 0) return 0;\n    int well_length = grid[0].size();\n    \n    for(int i = 0; i < num_wells; ++i){\n        int sum = 0;\n        for(int j = 0; j < well_length; j += 16){\n            uint8x16_t vec = vdupq_n_u8(0);\n            for(int k = 0; k < 16 && (j + k) < well_length; ++k){\n                vec = vsetq_lane_u8(grid[i][j + k], vec, k);\n            }\n            uint8x16_t ones = vdupq_n_u8(1);\n            uint8x16_t res = vceqq_u8(vec, ones);\n            uint8x16_t count = vcntq_u8(res);\n            int32x4_t cnt_low = vpaddlq_s8(vget_low_s8(count));\n            int32x4_t cnt_high = vpaddlq_s8(vget_high_s8(count));\n            int32x2_t cnt_res = vpaddl_s32(cnt_low, cnt_high);\n            sum += vget_lane_s32(cnt_res, 0) + vget_lane_s32(cnt_res, 1);\n        }\n        total_drops += (sum + capacity - 1) / capacity;\n    }\n    return total_drops;\n}\n```"}
{"task_id": "SimdBench_119_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nint max_fill_simd(const std::vector<std::vector<int> > & grid, int capacity) {\n    if (grid.empty() || grid[0].empty()) return 0;\n\n    int rows = grid.size();\n    int cols = grid[0].size();\n    int total_drops = 0;\n\n    // Process each row using NEON intrinsics\n    for (int i = 0; i < rows; ++i) {\n        int j = 0;\n        int sum = 0;\n\n        // Load data in chunks of 16 bytes (128 bits)\n        for (; j + 15 < cols; j += 16) {\n            uint8x16_t vec = vld1q_u8(reinterpret_cast<const uint8_t*>(&grid[i][j]));\n            uint8x16_t ones = vmovq_n_u8(1);\n            uint8x16_t res = vceqq_u8(vec, ones); // Compare with 1\n            uint32x4_t cnt_lo = vmovl_u16(vget_low_u16(vcntq_u8(res))); // Count set bits\n            uint32x4_t cnt_hi = vmovl_u16(vget_high_u16(vcntq_u8(res)));\n            uint64x2_t cnt = vpaddlq_u32(vcombine_u32(cnt_lo, cnt_hi));\n            sum += static_cast<int>(vcntq_u64(cnt)[0] + vcntq_u64(cnt)[1]);\n        }\n\n        // Handle remaining elements\n        for (; j < cols; ++j) {\n            sum += grid[i][j];\n        }\n\n        // Calculate drops for this row\n        total_drops += (sum + capacity - 1) / capacity;\n    }\n\n    return total_drops;\n}\n```"}
{"task_id": "SimdBench_119_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nint max_fill_simd(const std::vector<std::vector<int> > & grid, int capacity){\n    int total_drops = 0;\n    int rows = grid.size();\n    if (rows == 0) return 0;\n    int cols = grid[0].size();\n    if (cols == 0) return 0;\n\n    const int simd_width = 16; // Process 16 elements at a time using uint8x16_t\n\n    for(int i = 0; i < rows; ++i){\n        int j = 0;\n        int sum = 0;\n\n        for(; j + simd_width <= cols; j += simd_width){\n            uint8x16_t vec = vld1q_u8(reinterpret_cast<const uint8_t*>(&grid[i][j]));\n            uint8x16_t ones = vmovq_n_u8(1);\n            uint8x16_t cmp = vceqq_u8(vec, ones);\n            uint8x16_t res = vandq_u8(cmp, ones);\n            uint8x16_t zero = vmovq_n_u8(0);\n            int count = vaddvq_s8(vreinterpretq_s8_u8(res)); // Sum of all elements in vector\n            sum += count;\n        }\n\n        for(; j < cols; ++j){\n            sum += grid[i][j];\n        }\n\n        total_drops += (sum + capacity - 1) / capacity;\n    }\n\n    return total_drops;\n}\n```"}
{"task_id": "SimdBench_119_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nint max_fill_simd(const std::vector<std::vector<int> > & grid, int capacity){\n    int total_drops = 0;\n    int rows = grid.size();\n    if (rows == 0) return 0;\n    int cols = grid[0].size();\n\n    for(int i = 0; i < rows; ++i){\n        int j = 0;\n        int sum = 0;\n        while(j + 15 < cols){\n            uint8x16_t vec = vld1q_u8(reinterpret_cast<const uint8_t*>(&grid[i][j]));\n            uint8x16_t ones = vmovq_n_u8(1);\n            uint8x16_t cmp = vceqq_u8(vec, ones);\n            uint8x16_t res = vandq_u8(cmp, ones);\n            uint8x16_t zero = vmovq_n_u8(0);\n            int count = vbicq_m_u8(zero, zero, res, 0);\n            sum += vaddvq_u8(count);\n            j += 16;\n        }\n        while(j < cols){\n            sum += grid[i][j];\n            j++;\n        }\n        total_drops += (sum + capacity - 1) / capacity;\n    }\n    return total_drops;\n}\n```"}
{"task_id": "SimdBench_120_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nint64_t solution_simd(const std::vector<int16_t>& lst){\n    int64_t sum = 0;\n    size_t size = lst.size();\n    const int16_t* data = lst.data();\n\n    // Handle even indices only, so process half the size\n    size_t num_even_indices = (size + 1) / 2;\n\n    // Process in chunks of 8 elements (since we use int16x8_t)\n    size_t i = 0;\n    for (; i <= num_even_indices - 8; i += 8) {\n        int16x8_t vec = vld1q_s16(data + 2 * i); // Load 8 values from even indices\n        int16x8_t ones = vmovq_n_s16(1);\n        int16x8_t mods = vandq_s16(vec, ones);   // Compute value % 2\n        uint16x8_t mask = vcgeq_s16(mods, ones); // Create mask where odd numbers are 1\n        int16x8_t filtered = vandq_s16(vec, vmovl_u8(vreinterpret_u8_u16(mask))); // Keep odd numbers\n        int32x4_t sums = vpaddlq_s16(filtered);  // Partial sums\n        int32x2_t sums_low = vpaddl_s16(vget_low_s16(filtered));\n        int32x2_t sums_high = vpaddl_s16(vget_high_s16(filtered));\n        int64x1_t sum_low = vpaddl_s32(sums_low);\n        int64x1_t sum_high = vpaddl_s32(sums_high);\n        sum += vget_lane_s64(sum_low) + vget_lane_s64(sum_high);\n    }\n\n    // Handle remaining elements\n    for (; i < num_even_indices; ++i) {\n        if ((data[2 * i] & 1) == 1) {\n            sum += data[2 * i];\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_120_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nint64_t solution_simd(const std::vector<int16_t>& lst){\n    int64_t sum = 0;\n    size_t n = lst.size();\n    if (n == 0) return sum;\n\n    const int16_t* data = lst.data();\n    uint16x8_t mask_even_pos = vmovq_n_u16(1); // Mask for even positions\n    uint16x8_t mask_odd_val = vdupq_n_u16(1);  // Mask for odd values\n\n    for (size_t i = 0; i + 8 <= n; i += 8) {\n        int16x8_t vec = vld1q_s16(data + i);\n        uint16x8_t pos_mask = vandq_u16(mask_even_pos, vmovl_u8(vcreate_u8((uint64_t)(i & 0b10))));\n        uint16x8_t val_mask = vcleq_s16(vec, vdupq_n_s16(0)); // Check if value is odd\n        uint16x8_t combined_mask = vandq_u16(pos_mask, val_mask);\n\n        int16x8_t filtered = vandq_s16(vec, vreinterpretq_s16_u16(combined_mask));\n        int32x4_t sum_vec = vpaddlq_s16(filtered);\n        int32x2_t sum_pair = vpaddl_s32(vget_low_s32(sum_vec), vget_high_s32(sum_vec));\n        sum += vget_lane_s32(sum_pair, 0);\n    }\n\n    for (size_t i = (n / 8) * 8; i < n; ++i) {\n        if ((i % 2 == 0) && (lst[i] & 1)) {\n            sum += lst[i];\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_120_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nint64_t solution_simd(const std::vector<int16_t>& lst){\n    int64_t sum = 0;\n    size_t n = lst.size();\n    if (n == 0) return sum;\n\n    const int16_t* data = lst.data();\n    uint16x8_t mask_even_idx = vmovq_n_u16(1); // Mask for even indices\n    mask_even_idx = vshrq_n_u16(mask_even_idx, 15); // Create a mask of all ones\n\n    for (size_t i = 0; i + 16 <= n; i += 16) {\n        int16x8_t vec1 = vld1_s16(data + i);\n        int16x8_t vec2 = vld1_s16(data + i + 8);\n\n        uint16x8_t odd_mask1 = vcge_s16(vec1, vmov_n_s16(1)); // Check if elements are >= 1 (odd)\n        uint16x8_t odd_mask2 = vcge_s16(vec2, vmov_n_s16(1));\n\n        uint16x8_t idx_mask1 = vandq_u16(mask_even_idx, vcreate_u16(i + 0x01030507090B0D0Fu)); // Even indices mask\n        uint16x8_t idx_mask2 = vandq_u16(mask_even_idx, vcreate_u16(i + 8 + 0x01030507090B0D0Fu));\n\n        uint16x8_t final_mask1 = vandq_u16(idx_mask1, odd_mask1);\n        uint16x8_t final_mask2 = vandq_u16(idx_mask2, odd_mask2);\n\n        int16x8_t filtered_vec1 = vandq_s16(vec1, vreinterpretq_s16_u16(final_mask1));\n        int16x8_t filtered_vec2 = vandq_s16(vec2, vreinterpretq_s16_u16(final_mask2));\n\n        int32x4_t sum1 = vpaddlq_s16(filtered_vec1);\n        int32x4_t sum2 = vpaddlq_s16(filtered_vec2);\n\n        int64x2_t sum_long1 = vpaddlq_s32(sum1);\n        int64x2_t sum_long2 = vpaddlq_s32(sum2);\n\n        sum += vgetq_lane_s64(sum_long1, 0) + vgetq_lane_s64(sum_long1, 1);\n        sum += vgetq_lane_s64(sum_long2, 0) + vgetq_lane_s64(sum_long2, 1);\n    }\n\n    for (size_t i = (n / 16) * 16; i < n; ++i) {\n        if (i % 2 == 0 && lst[i] % 2 != 0) {\n            sum += lst[i];\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_120_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nint64_t solution_simd(const std::vector<int16_t>& lst){\n    int64_t sum = 0;\n    size_t n = lst.size();\n    if (n == 0) return 0;\n\n    const int16_t* data = lst.data();\n    uint16x8_t mask_odd = vdupq_n_u16(1); // Mask for odd numbers (1)\n    uint16x8_t mask_even_idx = vdupq_n_u16(1); // Mask for even indices\n\n    mask_even_idx = vmovq_n_u16(0xAAAA); // Even index mask (0 at even positions)\n\n    for (size_t i = 0; i + 8 <= n; i += 8) {\n        int16x8_t vec = vld1q_s16(data + i);\n        uint16x8_t abs_vec = vabsq_u16(vreinterpretq_u16_s16(vec)); // Absolute value\n        uint16x8_t is_odd = vandq_u16(abs_vec, mask_odd); // Check if odd\n        uint16x8_t is_even_idx = vbicq_u16(mask_even_idx, vreinterpretq_u16_s16(vec)); // Check even index\n        uint16x8_t valid = vandq_u16(is_odd, is_even_idx); // Combine conditions\n        int16x8_t filtered = vandq_s16(vec, vreinterpretq_s16_u16(valid)); // Apply filter\n        sum += vaddlvq_s16(filtered); // Accumulate sum\n    }\n\n    // Handle remaining elements\n    for (size_t i = (n / 8) * 8; i < n; ++i) {\n        if ((i % 2 == 0) && (abs(lst[i]) % 2 != 0)) {\n            sum += lst[i];\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_120_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nint64_t solution_simd(const std::vector<int16_t>& lst){\n    int64_t sum = 0;\n    size_t size = lst.size();\n    \n    if(size == 0) return 0;\n\n    const int16_t* data = lst.data();\n\n    // Process elements in chunks of 8 (since we use int16x8_t)\n    for(size_t i = 0; i < size; i += 16){\n        int16x8_t vec1 = vdupq_n_s16(0);\n        int16x8_t vec2 = vdupq_n_s16(0);\n\n        if(i + 8 <= size){\n            vec1 = vld1q_s16(data + i);\n        }\n        if(i + 16 <= size){\n            vec2 = vld1q_s16(data + i + 8);\n        }\n\n        // Create masks for even indices (0, 2, 4, 6 within each vector)\n        uint16x8_t mask_even1 = vmovq_n_u16(0xAA); // Binary: 10101010\n        uint16x8_t mask_even2 = vmovq_n_u16(0xAA);\n\n        // Apply the mask to select even-indexed elements\n        int16x8_t even_elements1 = vandq_s16(vec1, vreinterpretq_s16_u16(mask_even1));\n        int16x8_t even_elements2 = vandq_s16(vec2, vreinterpretq_s16_u16(mask_even2));\n\n        // Check if the selected elements are odd\n        int16x8_t ones = vdupq_n_s16(1);\n        uint16x8_t mask_odd1 = vcleq_s16(even_elements1, ones);\n        uint16x8_t mask_odd2 = vcleq_s16(even_elements2, ones);\n\n        // Combine masks to get odd elements at even positions\n        uint16x8_t combined_mask1 = vandq_u16(vreinterpretq_u16_s16(even_elements1), mask_odd1);\n        uint16x8_t combined_mask2 = vandq_u16(vreinterpretq_u16_s16(even_elements2), mask_odd2);\n\n        // Convert back to signed and sum\n        int16x8_t odd_even1 = vreinterpretq_s16_u16(combined_mask1);\n        int16x8_t odd_even2 = vreinterpretq_s16_u16(combined_mask2);\n\n        int32x4_t sum1 = vpaddlq_s16(odd_even1);\n        int32x4_t sum2 = vpaddlq_s16(odd_even2);\n\n        int64x2_t sum_long1 = vpaddlq_s32(sum1);\n        int64x2_t sum_long2 = vpaddlq_s32(sum2);\n\n        sum += vgetq_lane_s64(sum_long1, 0) + vgetq_lane_s64(sum_long1, 1);\n        sum += vgetq_lane_s64(sum_long2, 0) + vgetq_lane_s64(sum_long2, 1);\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_121_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nint add_elements_simd(std::vector<int> arr, int k){\n    int sum = 0;\n    int num_elements = std::min(k, (int)arr.size());\n    \n    // Handle unaligned data\n    if ((reinterpret_cast<uintptr_t>(&arr[0]) % 16) != 0) {\n        int i = 0;\n        for (; i < num_elements && i % 4 != 0; ++i) {\n            if (-99 <= arr[i] && arr[i] <= 99) {\n                sum += arr[i];\n            }\n        }\n        if (i >= num_elements) return sum;\n    }\n\n    // Process using NEON intrinsics\n    int32x4_t vsum = vdupq_n_s32(0);\n    int32x4_t vzero = vdupq_n_s32(0);\n    int32x4_t vlower = vdupq_n_s32(-99);\n    int32x4_t vupper = vdupq_n_s32(99);\n\n    for (size_t i = 0; i + 4 <= num_elements; i += 4) {\n        int32x4_t vdata = vld1q_s32(&arr[i]);\n        uint32x4_t vmask = vcgeq_s32(vdata, vlower) & vcleq_s32(vdata, vupper);\n        int32x4_t vfiltered = vandq_s32(vdata, vmask);\n        vsum = vaddq_s32(vsum, vfiltered);\n    }\n\n    // Horizontal sum of the NEON registers\n    int32x2_t vsum_low = vadd_s32(vget_low_s32(vsum), vget_high_s32(vsum));\n    int32x2_t vsum_h = vpadd_s32(vsum_low, vsum_low);\n    sum += vget_lane_s32(vsum_h, 0);\n\n    // Process remaining elements\n    for (size_t i = (num_elements / 4) * 4; i < num_elements; ++i) {\n        if (-99 <= arr[i] && arr[i] <= 99) {\n            sum += arr[i];\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_121_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nint add_elements_simd(std::vector<int> arr, int k){\n    int sum = 0;\n    int num_elements = k;\n    int *data = arr.data();\n    \n    int32x4_t zero = vmovq_n_s32(0);\n    int32x4_t limit1 = vmovq_n_s32(-99);\n    int32x4_t limit2 = vmovq_n_s32(99);\n    \n    for(int i = 0; i < num_elements; i += 4){\n        int32x4_t vec = vld1q_s32(data + i);\n        int32x4_t cmp1 = vcgeq_s32(vec, limit1);\n        int32x4_t cmp2 = vcleq_s32(vec, limit2);\n        int32x4_t mask = vandq_u32(cmp1, cmp2);\n        int32x4_t res = vandq_s32(mask, vec);\n        int32x4_t acc = vpaddlq_s32(res);\n        int32x2_t acc_lo = vpaddl_s32(vget_low_s32(acc));\n        int32x2_t acc_hi = vpaddl_s32(vget_high_s32(acc));\n        int32x2_t total = vadd_s32(acc_lo, acc_hi);\n        sum += vget_lane_s32(total, 0) + vget_lane_s32(total, 1);\n    }\n    \n    // Handle remaining elements\n    for(int i = (num_elements / 4) * 4; i < num_elements; ++i){\n        if(data[i] >= -99 && data[i] <= 99){\n            sum += data[i];\n        }\n    }\n    \n    return sum;\n}\n```"}
{"task_id": "SimdBench_121_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nint add_elements_simd(std::vector<int> arr, int k){\n    int sum = 0;\n    int num_elements = k / 4;\n    int remainder = k % 4;\n\n    const int32_t threshold = 99;\n    int32x4_t vthreshold = vdupq_n_s32(threshold);\n\n    for(int i = 0; i < num_elements * 4; i += 4){\n        int32x4_t vload = vld1q_s32(&arr[i]);\n        uint32x4_t vcmp = vcmpgtq_s32(vload, vthreshold);\n        uint32x4_t vnot = vmvnq_u32(vcmp);\n        int32x4_t vand = vandq_s32(vload, vreinterpretq_s32_u32(vnot));\n        int32x4_t vsum = vpaddlq_s32(vand);\n        int32x2_t vsum_low = vpadd_s32(vget_low_s32(vsum), vget_high_s32(vsum));\n        sum += vget_lane_s32(vsum_low, 0);\n    }\n\n    for(int i = num_elements * 4; i < num_elements * 4 + remainder; ++i){\n        if(arr[i] <= 99){\n            sum += arr[i];\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_121_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nint add_elements_simd(std::vector<int> arr, int k){\n    int sum = 0;\n    int num_elements = std::min(k, (int)arr.size());\n    \n    // Handle elements in chunks of 4\n    for(int i = 0; i < num_elements / 4 * 4; i += 4){\n        int32x4_t vload = vld1q_s32(&arr[i]);\n        \n        // Create mask for numbers with at most two digits (-99 to 99)\n        int32x4_t vcmp1 = vcgeq_s32(vload, vmovq_n_s32(-99));\n        int32x4_t vcmp2 = vcleq_s32(vload, vmovq_n_s32(99));\n        uint32x4_t mask = vandq_u32(vreinterpretq_u32_s32(vcmp1), vreinterpretq_u32_s32(vcmp2));\n        \n        // Apply mask and accumulate\n        int32x4_t vresult = vandq_s32(vload, vreinterpretq_s32_u32(mask));\n        int32x4_t vsum = vpaddlq_s32(vresult);\n        int32x2_t vsum_lo = vpaddl_s32(vget_low_s32(vsum));\n        int32x2_t vsum_hi = vpaddl_s32(vget_high_s32(vsum));\n        int32x2_t vsum_combined = vadd_s32(vsum_lo, vsum_hi);\n        sum += vget_lane_s32(vsum_combined, 0);\n    }\n    \n    // Handle remaining elements\n    for(int i = num_elements / 4 * 4; i < num_elements; ++i){\n        if(arr[i] >= -99 && arr[i] <= 99){\n            sum += arr[i];\n        }\n    }\n    \n    return sum;\n}\n```"}
{"task_id": "SimdBench_121_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nint add_elements_simd(std::vector<int> arr, int k){\n    int sum = 0;\n    int num_iterations = k / 4;\n    int remainder = k % 4;\n\n    int32x4_t threshold = vmovq_n_s32(99);\n    int32x4_t zero = vmovq_n_s32(0);\n    int32x4_t temp_sum = vmovq_n_s32(0);\n\n    for(int i = 0; i < num_iterations * 4; i += 4){\n        int32x4_t vec = vld1q_s32(&arr[i]);\n        uint32x4_t mask = vcgeq_s32(vec, vmulq_n_s32(threshold, vmovq_n_s32(-1)));\n        int32x4_t filtered = vbslq_s32(mask, zero, vec);\n        temp_sum = vaddq_s32(temp_sum, filtered);\n    }\n\n    int32x2_t sum_low = vpadd_s32(vget_low_s32(temp_sum), vget_high_s32(temp_sum));\n    int32x2_t sum_final = vpadd_s32(sum_low, sum_low);\n    sum += vget_lane_s32(sum_final, 0);\n\n    for(int i = num_iterations * 4; i < k; ++i){\n        if(arr[i] >= -99 && arr[i] <= 99){\n            sum += arr[i];\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_122_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <cstdint>\n\nbool is_sorted_simd(const std::vector<int> & lst){\n    size_t n = lst.size();\n    if (n <= 1) return true;\n\n    const int32_t * data = lst.data();\n    size_t vec_len = n / 4;\n    size_t remainder = n % 4;\n\n    for (size_t i = 0; i < vec_len; ++i) {\n        int32x4_t v_curr = vld1q_s32(data + 4 * i);\n        int32x4_t v_next = vld1q_s32(data + 4 * i + 1);\n\n        int32x4_t v_cmp = vcgeq_s32(v_next, v_curr); // Compare current with next\n        uint32x4_t v_mask = vceqq_s32(v_next, v_curr); // Check for equality\n\n        if (vaddvq_u32((uint32x4_t)v_mask) > 1) { // More than one duplicate\n            return false;\n        }\n\n        if (vminvq_s32(v_cmp) == 0) { // If any comparison failed\n            return false;\n        }\n    }\n\n    // Handle remaining elements\n    size_t i = vec_len * 4;\n    if (remainder > 0) {\n        int32x4_t v_curr = vld1q_dup_s32(data + i);\n        for (size_t j = 1; j < remainder; ++j) {\n            int32_t curr = data[i + j - 1];\n            int32_t next = data[i + j];\n            if (next < curr || (next == curr && j > 1)) {\n                return false;\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_122_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <cstdint>\n\nbool is_sorted_simd(const std::vector<int> & lst){\n    if (lst.size() <= 1) {\n        return true;\n    }\n\n    size_t n = lst.size();\n    const int32_t * data = lst.data();\n    size_t aligned_size = (n - 1) / 4 * 4;\n\n    for (size_t i = 0; i < aligned_size; i += 4) {\n        int32x4_t vec_curr = vld1q_s32(data + i);\n        int32x4_t vec_next = vld1q_s32(data + i + 1);\n\n        uint32x4_t cmp_ge = vcgeq_s32(vec_curr, vec_next);\n        if (vmaxvq_u32(cmp_ge)) {\n            return false;\n        }\n\n        // Check for more than one duplicate\n        uint32x4_t cmp_eq = vceqq_s32(vec_curr, vec_next);\n        int32x4_t cnt_eq = vmovl_u8(vcntq_u8((uint8x16_t)cmp_eq));\n        if (vaddvq_u32(cnt_eq) > 1) {\n            return false;\n        }\n    }\n\n    for (size_t i = aligned_size; i < n - 1; ++i) {\n        if (lst[i] > lst[i + 1]) {\n            return false;\n        }\n        if (lst[i] == lst[i + 1]) {\n            int count = 0;\n            for (size_t j = i; j < n; ++j) {\n                if (lst[j] == lst[i]) {\n                    count++;\n                    if (count > 2) {\n                        return false;\n                    }\n                }\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_122_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nbool is_sorted_simd(const std::vector<int> & lst){\n    if(lst.size() <= 1) return true;\n\n    size_t n = lst.size();\n    const int32_t * data = lst.data();\n    size_t aligned_size = (n - 1) / 4 * 4;\n\n    int32x4_t prev_vec = vld1q_s32(data);\n    bool result = true;\n\n    for(size_t i = 4; i <= aligned_size; i += 4){\n        int32x4_t curr_vec = vld1q_s32(data + i);\n\n        // Compare current vector with previous vector\n        uint32x4_t cmp_ge = vcgeq_s32(curr_vec, prev_vec);\n        uint32x4_t cmp_eq = vceqq_s32(curr_vec, prev_vec);\n\n        // Check if any element is less than the previous one\n        if(vminvq_u32(cmp_ge) == 0){\n            result = false;\n            break;\n        }\n\n        // Check for more than one duplicate\n        uint32_t eq_count = vaddvq_u32(vcvtuq_s32_f32(vcvtq_f32_s32(cmp_eq)));\n        if(eq_count > 1){\n            result = false;\n            break;\n        }\n\n        prev_vec = curr_vec;\n    }\n\n    // Handle remaining elements\n    for(size_t i = aligned_size + 1; i < n; ++i){\n        if(lst[i] < lst[i-1] || (lst[i] == lst[i-1] && lst[i-1] == lst[i-2])){\n            result = false;\n            break;\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_122_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nbool is_sorted_simd(const std::vector<int> & lst){\n    if (lst.size() <= 1) {\n        return true;\n    }\n\n    size_t n = lst.size();\n    const int32_t *data = lst.data();\n    size_t i = 0;\n\n    // Process 4 elements at a time using SIMD\n    for (; i <= n - 8; i += 4) {\n        int32x4_t vec_curr = vld1q_s32(data + i);\n        int32x4_t vec_next = vld1q_s32(data + i + 4);\n\n        uint32x4_t cmp_ge = vcgeq_s32(vec_curr, vec_next);\n        uint32x4_t cmp_eq = vceqq_s32(vec_curr, vec_next);\n\n        // Check if any element in current vector is greater than next or duplicates exceed one\n        if (vaddvq_u32(vcgtq_u32(cmp_ge, cmp_eq)) != 0) {\n            return false;\n        }\n    }\n\n    // Scalar check for remaining elements\n    for (; i < n - 1; ++i) {\n        if (data[i] > data[i + 1]) {\n            return false;\n        }\n        if (data[i] == data[i + 1]) {\n            int count = 0;\n            for (size_t j = i; j < n && data[j] == data[i]; ++j) {\n                ++count;\n                if (count > 2) {\n                    return false;\n                }\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_122_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nbool is_sorted_simd(const std::vector<int> & lst){\n    if (lst.size() <= 1) return true;\n\n    size_t n = lst.size();\n    const int32_t *data = lst.data();\n\n    // Process in chunks of 4 elements using SIMD\n    size_t i = 0;\n    for (; i + 3 < n; i += 4) {\n        int32x4_t vec_curr = vld1q_s32(data + i);\n        int32x4_t vec_next = vld1q_s32(data + i + 1);\n\n        uint32x4_t cmp_result = vcgeq_s32(vec_curr, vec_next);\n        if (vminvq_u32(cmp_result)) {\n            return false;\n        }\n    }\n\n    // Handle remaining scalar elements\n    for (; i < n - 1; ++i) {\n        if (data[i] > data[i + 1]) return false;\n        if (data[i] == data[i + 1]) {\n            int count = 0;\n            for (size_t j = 0; j < n; ++j) {\n                if (data[j] == data[i]) ++count;\n                if (count > 2) return false;\n            }\n        }\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_123_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nint prod_signs_simd(const std::vector<int> & arr){\n    if (arr.empty()) return -32768;\n\n    int sum = 0;\n    int product_sign = 1;\n\n    size_t i = 0;\n    size_t n = arr.size() / 4 * 4;\n\n    for (; i < n; i += 4) {\n        int32x4_t v = vld1q_s32(&arr[i]);\n        \n        // Calculate absolute values\n        int32x4_t abs_v = vabsq_s32(v);\n        \n        // Sum of magnitudes\n        sum += vgetq_lane_s32(abs_v, 0) + vgetq_lane_s32(abs_v, 1) \n            + vgetq_lane_s32(abs_v, 2) + vgetq_lane_s32(abs_v, 3);\n        \n        // Calculate signs (-1, 0, 1)\n        uint32x4_t cmp_zero = vcgeq_s32(v, vdupq_n_s32(0));\n        uint32x4_t is_zero = vceqq_s32(v, vdupq_n_s32(0));\n        int32x4_t signs = vbslq_s32(is_zero, vdupq_n_s32(0), vreinterpretq_s32_u32(cmp_zero));\n        \n        // Product of signs\n        product_sign *= vgetq_lane_s32(signs, 0) * vgetq_lane_s32(signs, 1) \n            * vgetq_lane_s32(signs, 2) * vgetq_lane_s32(signs, 3);\n        \n        if (product_sign == 0) break;\n    }\n\n    for (; i < arr.size(); ++i) {\n        if (arr[i] > 0) {\n            sum += arr[i];\n            product_sign *= 1;\n        } else if (arr[i] < 0) {\n            sum += -arr[i];\n            product_sign *= -1;\n        } else {\n            sum += 0;\n            product_sign *= 0;\n            break;\n        }\n    }\n\n    return product_sign * sum;\n}\n```"}
{"task_id": "SimdBench_123_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nint prod_signs_simd(const std::vector<int> & arr){\n    if (arr.empty()) {\n        return -32768;\n    }\n\n    int sum_magnitude = 0;\n    int product_sign = 1;\n\n    size_t i = 0;\n    size_t n = arr.size();\n\n    // Handle vectors in chunks of 4 using NEON intrinsics\n    for (; i <= n - 4; i += 4) {\n        int32x4_t vec = vld1q_s32(&arr[i]);\n        \n        // Compute absolute values\n        int32x4_t abs_vec = vabsq_s32(vec);\n        uint32x4_t abs_sum = vmovl_u16(vget_low_u16(vreinterpretq_u16_s32(abs_vec)));\n        \n        // Compute signs (-1, 0, 1)\n        int32x4_t sign_vec = vcltq_s32(vec, vdupq_n_s32(0));\n        int32x4_t zero_mask = vceqq_s32(vec, vdupq_n_s32(0));\n        sign_vec = vorrq_s32(sign_vec, vandq_s32(zero_mask, vdupq_n_s32(1)));\n        \n        // Update sum of magnitudes\n        sum_magnitude += vaddlvq_s32(abs_vec);\n        \n        // Update product of signs\n        int signs = (vgetq_lane_s32(sign_vec, 0) & 1) |\n                    (vgetq_lane_s32(sign_vec, 1) & 2) |\n                    (vgetq_lane_s32(sign_vec, 2) & 4) |\n                    (vgetq_lane_s32(sign_vec, 3) & 8);\n        if (signs == 0 || signs == 15) {\n            product_sign *= 1;\n        } else if (signs == 1 || signs == 2 || signs == 4 || signs == 8) {\n            product_sign *= 0;\n        } else {\n            product_sign *= -1;\n        }\n    }\n\n    // Handle remaining elements\n    for (; i < n; ++i) {\n        int val = arr[i];\n        sum_magnitude += std::abs(val);\n        if (val > 0) {\n            product_sign *= 1;\n        } else if (val == 0) {\n            product_sign *= 0;\n        } else {\n            product_sign *= -1;\n        }\n    }\n\n    return product_sign * sum_magnitude;\n}\n```"}
{"task_id": "SimdBench_123_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nint prod_signs_simd(const std::vector<int> & arr){\n    if (arr.empty()) {\n        return -32768;\n    }\n\n    int sum = 0;\n    int sign_product = 1;\n\n    size_t i = 0;\n    size_t n = arr.size() / 4 * 4;\n\n    for (; i < n; i += 4) {\n        int32x4_t v = vld1q_s32(&arr[i]);\n        int32x4_t zero = vmovq_n_s32(0);\n\n        uint32x4_t signs = vcltq_s32(v, zero); // Get sign bits (negative)\n        uint32x4_t is_zero = vceqq_s32(v, zero); // Check for zero\n\n        // Compute absolute values\n        int32x4_t abs_v = vabsq_s32(v);\n        int32x4_t sum_v = vpaddlq_s32(vaddlvq_s32(abs_v)); \n\n        // Update sum of magnitudes\n        sum += vgetq_lane_s32(sum_v, 0);\n\n        // Update sign product\n        for (int j = 0; j < 4; ++j) {\n            int val = vgetq_lane_s32(v, j);\n            if (val == 0) {\n                sign_product = 0;\n            } else {\n                sign_product *= (val > 0) ? 1 : -1;\n            }\n        }\n\n        if (sign_product == 0) {\n            break;\n        }\n    }\n\n    for (; i < arr.size(); ++i) {\n        if (arr[i] == 0) {\n            sign_product = 0;\n            break;\n        }\n        sum += std::abs(arr[i]);\n        sign_product *= (arr[i] > 0) ? 1 : -1;\n    }\n\n    return sign_product * sum;\n}\n```"}
{"task_id": "SimdBench_123_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nint prod_signs_simd(const std::vector<int> & arr){\n    if (arr.empty()) {\n        return -32768;\n    }\n\n    int sum_magnitude = 0;\n    int product_of_signs = 1;\n\n    const int *data = arr.data();\n    size_t size = arr.size();\n\n    for (size_t i = 0; i + 4 <= size; i += 4) {\n        int32x4_t vec = vld1q_s32(data + i);\n        \n        // Compute absolute values\n        int32x4_t abs_vec = vabsq_s32(vec);\n        uint32x4_t zero_mask = vcgeq_s32(vec, vdupq_n_s32(0));\n        int32x4_t sign_vec = vbslq_s32(zero_mask, vdupq_n_s32(1), vdupq_n_s32(-1));\n        sign_vec = vorrq_s32(sign_vec, vceqq_s32(vec, vdupq_n_s32(0)));\n\n        // Sum magnitudes\n        sum_magnitude += vaddlvq_s32(abs_vec);\n\n        // Product of signs\n        int32x4_t prod_sign = vmulq_s32(vdupq_n_s32(product_of_signs), sign_vec);\n        product_of_signs = prod_sign[0] * prod_sign[1] * prod_sign[2] * prod_sign[3];\n        if (product_of_signs == 0) break;\n    }\n\n    for (size_t i = (size / 4) * 4; i < size; ++i) {\n        int val = data[i];\n        sum_magnitude += abs(val);\n        if (val > 0) product_of_signs *= 1;\n        else if (val < 0) product_of_signs *= -1;\n        else {\n            product_of_signs = 0;\n            break;\n        }\n    }\n\n    return product_of_signs * sum_magnitude;\n}\n```"}
{"task_id": "SimdBench_123_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nint prod_signs_simd(const std::vector<int> & arr){\n    if (arr.empty()) {\n        return -32768;\n    }\n\n    int sum_magnitudes = 0;\n    int product_of_signs = 1;\n\n    const int *data = arr.data();\n    size_t length = arr.size();\n\n    size_t i = 0;\n    for (; i + 3 < length; i += 4) {\n        int32x4_t vec = vld1q_s32(&data[i]);\n        \n        // Compute absolute values\n        int32x4_t abs_vec = vabsq_s32(vec);\n        \n        // Sum magnitudes horizontally\n        uint32x4_t sum_abs = vmovl_u16(vget_low_u16(vreinterpretq_u16_s32(abs_vec)));\n        uint64x2_t sum_pair = vpaddlq_u32(vmovl_u16(vget_high_u16(vreinterpretq_u16_s32(abs_vec))));\n        uint64_t res = vget_lane_u64(vpaddl_u32(vget_low_u32(sum_pair)), 0) + \n                       vget_lane_u64(vpaddl_u32(vget_high_u32(sum_pair)), 0);\n        sum_magnitudes += static_cast<int>(res);\n\n        // Compute signs (-1, 0, 1)\n        int32x4_t cmp_zero = vcgeq_s32(vec, vdupq_n_s32(0));\n        int32x4_t sign_vec = vbslq_s32(cmp_zero, vdupq_n_s32(1), vdupq_n_s32(-1));\n        int32x4_t zero_mask = vceqq_s32(vec, vdupq_n_s32(0));\n        sign_vec = vandq_s32(sign_vec, vmvnq_s32(zero_mask));\n\n        // Product of signs\n        int32x2_t prod_low = vmovn_s32(vget_low_s32(sign_vec));\n        int32x2_t prod_high = vmovn_s32(vget_high_s32(sign_vec));\n        int16x4_t prod_h = vmovn_s32(vcombine_s32(prod_low, prod_high));\n        int product = vget_lane_s32(vmovl_s16(vget_low_s16(prod_h)), 0) *\n                     vget_lane_s32(vmovl_s16(vget_high_s16(prod_h)), 0);\n        product_of_signs *= product;\n    }\n\n    for (; i < length; ++i) {\n        int val = data[i];\n        if (val == 0) {\n            product_of_signs = 0;\n            break;\n        }\n        sum_magnitudes += std::abs(val);\n        product_of_signs *= (val > 0) ? 1 : -1;\n    }\n\n    return sum_magnitudes * product_of_signs;\n}\n```"}
{"task_id": "SimdBench_124_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int> minPath_simd(const std::vector<std::vector<int> > & grid, int k){\n    int N = grid.size();\n    std::vector<int> result;\n    \n    if (k <= 0 || N == 0) return result;\n\n    // Flatten the grid into a single array for easier SIMD access\n    int size = N * N;\n    int* flat_grid = new int[size];\n    for(int i = 0; i < N; ++i){\n        for(int j = 0; j < N; ++j){\n            flat_grid[i * N + j] = grid[i][j];\n        }\n    }\n\n    // Initialize variables for path tracking\n    int16x8_t min_path_val = vdupq_n_s16(0xFFFF);\n    int16x8_t current_path_val = vdupq_n_s16(0);\n\n    // Iterate through each possible starting point\n    for(int start = 0; start < size; ++start){\n        int16x8_t current_min = vdupq_n_s16(grid[start / N][start % N]);\n        \n        // Explore paths of length k using neighbors\n        for(int step = 1; step < k; ++step){\n            int16x8_t neighbors = vdupq_n_s16(0);\n            int count = 0;\n\n            // Collect valid neighbor values\n            for(int dx = -1; dx <= 1; ++dx){\n                for(int dy = -1; dy <= 1; ++dy){\n                    if(dx == 0 && dy == 0) continue;\n                    int nx = (start / N) + dx;\n                    int ny = (start % N) + dy;\n                    if(nx >= 0 && nx < N && ny >= 0 && ny < N){\n                        if(count < 8){\n                            int value = grid[nx][ny];\n                            uint8x8_t val = vdup_n_u8(value);\n                            int16x8_t tmp = vreinterpretq_s16_u8(val);\n                            neighbors = vsetq_lane_s16(value, neighbors, count);\n                            count++;\n                        }\n                    }\n                }\n            }\n\n            // Compare and update minimum path\n            current_path_val = vpminq_s16(current_min, neighbors);\n            current_min = current_path_val;\n        }\n\n        // Update global minimum path\n        min_path_val = vpminq_s16(min_path_val, current_path_val);\n    }\n\n    // Extract the minimum path values from SIMD registers\n    int16_t min_vals[8];\n    vst1q_s16(min_vals, min_path_val);\n\n    // Build the result vector with unique values\n    for(int i = 0; i < k && i < 8; ++i){\n        result.push_back(min_vals[i]);\n    }\n\n    delete[] flat_grid;\n    return result;\n}\n```"}
{"task_id": "SimdBench_124_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <climits>\n\nstd::vector<int> minPath_simd(const std::vector<std::vector<int> > & grid, int k){\n    int N = grid.size();\n    std::vector<int> result(k, INT_MAX);\n    if (k == 0) return result;\n\n    int min_val = INT_MAX;\n    int start_x = 0, start_y = 0;\n\n    // Find the minimum starting value using SIMD\n    for(int i = 0; i < N; ++i){\n        for(int j = 0; j <= N - 4; j += 4){\n            int32x4_t v = vld1q_s32(&grid[i][j]);\n            int32x4_t vmin = vpmin_s32(vget_low_s32(v), vget_high_s32(v));\n            int32x2_t vmin_low = vpmin_s32(vmin);\n            int potential_min = vmin_low[0];\n            if(potential_min < min_val){\n                min_val = potential_min;\n                start_x = i;\n                start_y = j + (vmin_low[0] == vget_lane_s32(vmin, 0) ? 0 : 2);\n            }\n        }\n        for(int j = N - (N % 4); j < N; ++j){\n            if(grid[i][j] < min_val){\n                min_val = grid[i][j];\n                start_x = i;\n                start_y = j;\n            }\n        }\n    }\n\n    result[0] = min_val;\n    // For simplicity, assume path length k=1 for this SIMD implementation\n    return result;\n}\n```"}
{"task_id": "SimdBench_124_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<int> minPath_simd(const std::vector<std::vector<int> > & grid, int k){\n    int N = grid.size();\n    std::vector<int> result;\n    if (k <= 0 || N == 0) return result;\n\n    // Flatten the grid into a single vector for easier SIMD access\n    std::vector<int> flat_grid(N * N);\n    for(int i = 0; i < N; ++i){\n        for(int j = 0; j < N; ++j){\n            flat_grid[i * N + j] = grid[i][j];\n        }\n    }\n\n    // Initialize variables for path tracking\n    int best_path_val = 0x7FFFFFFF;\n    std::vector<int> best_path;\n\n    // Iterate over all starting positions\n    for(int start = 0; start < N * N; ++start){\n        // Load initial values using Neon intrinsics\n        int current_val = flat_grid[start];\n        int16x8_t vcurrent = vdupq_n_s16(current_val);\n\n        // Perform path exploration with SIMD operations\n        std::vector<int> path;\n        path.push_back(current_val);\n\n        for(int step = 1; step < k; ++step){\n            int16x8_t vmin = vdupq_n_s16(0x7FFF);\n            int next_val = 0x7FFFFFFF;\n\n            // Explore neighbors\n            for(int dir = -N; dir <= N; dir += N){\n                int neighbor = start + dir;\n                if(neighbor >= 0 && neighbor < N * N){\n                    int val = flat_grid[neighbor];\n                    int16x8_t vval = vdupq_n_s16(val);\n                    vmin = vminq_s16(vmin, vval);\n                    if(val < next_val){\n                        next_val = val;\n                    }\n                }\n            }\n\n            // Append the smallest value to the path\n            path.push_back(next_val);\n        }\n\n        // Compare and update the best path\n        if(path.size() == k && path < best_path){\n            best_path = path;\n        }\n    }\n\n    return best_path;\n}\n```"}
{"task_id": "SimdBench_124_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int> minPath_simd(const std::vector<std::vector<int> > & grid, int k){\n    int N = grid.size();\n    std::vector<int> result;\n    \n    if (k <= 0 || N == 0) return result;\n\n    // Initialize variables for the best path\n    int best_value = 0x7FFFFFFF;\n    int16x8_t best_path_vec = vdupq_n_s16(0x7FFF);\n    int best_i = 0, best_j = 0;\n\n    for(int i = 0; i < N; ++i){\n        for(int j = 0; j < N; ++j){\n            // Start with the current cell value\n            int current_value = grid[i][j];\n            int16x8_t current_path_vec = vdupq_n_s16(current_value);\n\n            // Explore paths of length k using neighbors\n            for(int step = 1; step < k; ++step){\n                int ni = i, nj = j;\n                int next_value = 0x7FFFFFFF;\n\n                // Check all possible neighbors\n                for(int di = -1; di <= 1; ++di){\n                    for(int dj = -1; dj <= 1; ++dj){\n                        if(di == 0 && dj == 0) continue;\n                        int ci = ni + di, cj = nj + dj;\n                        if(ci >= 0 && ci < N && cj >= 0 && cj < N){\n                            if(grid[ci][cj] < next_value){\n                                next_value = grid[ci][cj];\n                                ni = ci;\n                                nj = cj;\n                            }\n                        }\n                    }\n                }\n\n                // Update the current path vector\n                current_value = next_value;\n                current_path_vec = vsetq_lane_s16(current_value, current_path_vec, step % 8);\n            }\n\n            // Compare and update the best path\n            int compare = vgetq_lane_s16(current_path_vec, 0);\n            if(compare < best_value){\n                best_value = compare;\n                best_path_vec = current_path_vec;\n                best_i = i;\n                best_j = j;\n            }\n        }\n    }\n\n    // Extract the best path into the result vector\n    for(int idx = 0; idx < k; ++idx){\n        result.push_back(vgetq_lane_s16(best_path_vec, idx % 8));\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_124_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int> minPath_simd(const std::vector<std::vector<int> > & grid, int k){\n    int N = grid.size();\n    std::vector<int> result;\n    \n    if (k <= 0 || N == 0) return result;\n\n    // Initialize variables for the best path\n    int best_value = INT32_MAX;\n    int16x4_t best_path;\n\n    for(int i = 0; i < N; ++i){\n        for(int j = 0; j < N; ++j){\n            // Load current cell value into Neon register\n            int16x4_t current_path = vdup_n_s16(grid[i][j]);\n            \n            // Explore neighbors and build paths of length k\n            for(int step = 1; step < k; ++step){\n                int16x4_t temp_path = current_path;\n                int new_i = i + ((step % 2) ? 1 : -1);\n                int new_j = j + ((step % 2) ? 1 : -1);\n\n                // Boundary checks\n                if(new_i >= 0 && new_i < N && new_j >= 0 && new_j < N){\n                    int16x4_t neighbor_val = vdup_n_s16(grid[new_i][new_j]);\n                    temp_path = vmin_s16(temp_path, neighbor_val);\n                }\n\n                // Update current path with minimal values\n                current_path = vmin_s16(current_path, temp_path);\n            }\n\n            // Compare and store the best path found\n            int current_min = vminv_s16(current_path);\n            if(current_min < best_value){\n                best_value = current_min;\n                best_path = current_path;\n            }\n        }\n    }\n\n    // Extract the best path into result vector\n    for(int i = 0; i < k && i < 4; ++i){\n        result.push_back(vget_lane_s16(best_path, i));\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_125_Neon", "completion": "```c\n#include <arm_neon.h>\n\nuint64_t digits_simd(uint64_t n){\n    uint64x1_t prod = vdup_n_u64(1);\n    uint8x8_t mask = vdup_n_u8(1);\n    uint8x8_t zero = vdup_n_u8(0);\n    uint8x8_t even_mask = vdup_n_u8(0x0F);\n    uint8x8_t ones = vdup_n_u8(1);\n\n    while(n > 0){\n        uint8x8_t digits = vdup_n_u8(n % 10);\n        uint8x8_t is_odd = vand_u8(vcmpneu_u8(digits, zero), mask);\n        uint8x8_t odd_digits = vand_u8(digits, even_mask);\n        uint8x8_t filtered = vbsl_u8(is_odd, odd_digits, zero);\n        uint64x1_t current_prod = vpaddl_u32(vpadal_u16(vpaddl_u8(filtered)));\n        prod = vmul_u64(prod, current_prod);\n        if (vget_lane_u64(prod, 0) == 0) {\n            return 0;\n        }\n        n /= 10;\n    }\n    return vget_lane_u64(prod, 0);\n}\n```"}
{"task_id": "SimdBench_125_Neon", "completion": "```c\n#include <arm_neon.h>\n\nuint64_t digits_simd(uint64_t n){\n    uint64x1_t prod = vdup_n_u64(1);\n    uint8x8_t mask = vdup_n_u8(0x01);\n    uint8x8_t zero = vdup_n_u8(0x00);\n    uint8x8_t odd_mask = vdup_n_u8(0x01);\n    uint8x8_t even_mask = vdup_n_u8(0xFE);\n\n    while (n > 0) {\n        uint64x1_t digit = vmov_n_u64(n % 10);\n        uint8x8_t dig = vreinterpret_u8_u64(digit);\n        uint8x8_t is_odd = vand_u8(vcmpgt_u8(dig, zero), odd_mask);\n        uint8x8_t filtered = vand_u8(dig, is_odd);\n        uint64x1_t res = vadd_u64(vdup_n_u64(0), vreinterpret_u64_u8(filtered));\n        uint64x1_t current_prod = vmul_u64(prod, vclz_u64(res));\n        if (vget_lane_u64(res, 0) != 0) {\n            prod = vmul_u64(prod, vreinterpret_u64_u8(filtered));\n        }\n        n /= 10;\n    }\n\n    return vget_lane_u64(prod, 0);\n}\n```"}
{"task_id": "SimdBench_125_Neon", "completion": "```c\n#include <arm_neon.h>\n\nuint64_t digits_simd(uint64_t n){\n    uint64x1_t prod = vdup_n_u64(1);\n    uint8x8_t mask = vdup_n_u8(0x01);\n    uint8x8_t zero = vdup_n_u8(0x00);\n    uint8x8_t odd_mask = vdup_n_u8(0x01);\n    uint8x8_t even_mask = vdup_n_u8(0xFE);\n\n    while(n > 0){\n        uint64x1_t digit = vmov_n_u64(n % 10);\n        uint8x8_t digits = vreinterpret_u8_u64(digit);\n        uint8x8_t is_odd = vand_u8(vbic_u8(digits, even_mask), odd_mask);\n        uint8x8_t filtered = vand_u8(digits, is_odd);\n        uint64x1_t sum = vpaddl_u32(vreinterpret_u32_u8(filtered));\n        uint64_t temp_prod = vget_lane_u64(sum, 0);\n        if(temp_prod > 0){\n            prod = vmul_u64(prod, vdup_n_u64(temp_prod));\n        }\n        n /= 10;\n    }\n\n    return vget_lane_u64(prod, 0);\n}\n```"}
{"task_id": "SimdBench_125_Neon", "completion": "```c\n#include <arm_neon.h>\n\nuint64_t digits_simd(uint64_t n){\n    uint64x1_t product = vdup_n_u64(1);\n    uint8x8_t mask = vdup_n_u8(1);\n    uint8x8_t odd_mask = vdup_n_u8(0x55);\n    uint8x8_t zero = vdup_n_u8(0);\n\n    while (n > 0) {\n        uint64x1_t digit = vmov_n_u64(n % 10);\n        uint8x8_t digits = vreinterpret_u8_u64(vmovl_u8(vget_lane_u8(vreinterpret_u8_u64(digit), 0)));\n        uint8x8_t is_odd = vand_u8(digits, odd_mask);\n        uint8x8_t cmp = vceq_u8(is_odd, mask);\n        uint8x8_t filtered = vbsl_u8(cmp, digits, zero);\n        uint64x1_t prod = vmovl_u32(vget_lane_u32(vpaddl_u16(vpaddl_u8(filtered)), 0));\n        product = vmul_u64(product, prod);\n        if (vget_lane_u64(product, 0) == 0) {\n            return 0;\n        }\n        n /= 10;\n    }\n    return vget_lane_u64(product, 0);\n}\n```"}
{"task_id": "SimdBench_125_Neon", "completion": "```c\n#include <arm_neon.h>\n\nuint64_t digits_simd(uint64_t n){\n    uint64x1_t prod = vdup_n_u64(1);\n    uint8x8_t mask = vdup_n_u8(0x01);\n    uint8x8_t odd_mask = vdup_n_u8(0x01);\n    uint8x8_t even_mask = vdup_n_u8(0x00);\n    uint8x8_t selector = vdup_n_u8(0x01);\n    uint8x8_t zero = vdup_n_u8(0x00);\n\n    while (n > 0) {\n        uint64x1_t digit = vmov_n_u64(n % 10);\n        uint8x8_t digits = vreinterpret_u8_u64(vshll_n_u64(digit, 56));\n        uint8x8_t is_odd = vand_u8(digits, mask);\n        uint8x8_t filtered = vbsl_u8(is_odd, odd_mask, even_mask);\n        uint8x8_t all_even = vceq_u8(filtered, zero);\n        \n        if (!vminv_u8(all_even)) {\n            uint64x1_t current_prod = vreinterpret_u64_u8(filtered);\n            prod = vmul_u64(prod, current_prod);\n        } else {\n            return 0;\n        }\n        n /= 10;\n    }\n    return vget_lane_u64(prod, 0);\n}\n```"}
{"task_id": "SimdBench_126_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <math.h>\n\nuint64_t sum_squares_simd(const std::vector<float> & lst){\n    uint64_t total_sum = 0;\n    size_t size = lst.size();\n    float *data = const_cast<float*>(lst.data());\n\n    // Handle unaligned data with NEON intrinsics\n    for (size_t i = 0; i + 3 < size; i += 4) {\n        float32x4_t vec = vld1q_f32(&data[i]);\n        float32x4_t ceil_vec = vcvtq_f32_u32(vcvtpu32x_f32(vcvtq_f32_s32(vec)));\n        float32x4_t squared = vmulq_f32(ceil_vec, ceil_vec);\n        uint32x4_t sum_part = vcvtq_u32_f32(squared);\n        uint64x2_t part1 = vpaddlq_u32(vget_low_u32(sum_part));\n        uint64x2_t part2 = vpaddlq_u32(vget_high_u32(sum_part));\n        uint64_t sum = vget_lane_u64(part1, 0) + vget_lane_u64(part2, 0);\n        total_sum += sum;\n    }\n\n    // Handle remaining elements\n    for (size_t i = ((size / 4) * 4); i < size; ++i) {\n        int ceil_val = static_cast<int>(ceilf(data[i]));\n        total_sum += static_cast<uint64_t>(ceil_val * ceil_val);\n    }\n\n    return total_sum;\n}\n```"}
{"task_id": "SimdBench_126_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <cstdint>\n#include <vector>\n\nuint64_t sum_squares_simd(const std::vector<float> & lst){\n    uint64_t total_sum = 0;\n    size_t size = lst.size();\n    if (size == 0) return 0;\n\n    const float *data = lst.data();\n    size_t aligned_size = size / 4 * 4;\n\n    float32x4_t vzero = vdupq_n_f32(0.0f);\n    float32x4_t vsum = vdupq_n_f32(0.0f);\n\n    for (size_t i = 0; i < aligned_size; i += 4) {\n        float32x4_t vload = vld1q_f32(data + i);\n        float32x4_t vceil = vcvtq_f32_s32(vcvtq_s32_f32(vaddq_f32(vload, vzero)));\n        float32x4_t vsquare = vmulq_f32(vceil, vceil);\n        vsum = vaddq_f32(vsum, vsquare);\n    }\n\n    float32x4_t vsum_temp = vpaddq_f32(vsum, vsum);\n    vsum_temp = vpaddq_f32(vsum_temp, vsum_temp);\n    float32x2_t vsum_low = vget_low_f32(vsum_temp);\n    float32x2_t vsum_high = vget_high_f32(vsum_temp);\n    float32x2_t vsum_combined = vpadd_f32(vsum_low, vsum_high);\n    float sum_aligned = vget_lane_f32(vsum_combined, 0);\n\n    total_sum += static_cast<uint64_t>(sum_aligned);\n\n    for (size_t i = aligned_size; i < size; ++i) {\n        int32_t ceil_val = static_cast<int32_t>(std::ceil(data[i]));\n        total_sum += static_cast<uint64_t>(ceil_val * ceil_val);\n    }\n\n    return total_sum;\n}\n```"}
{"task_id": "SimdBench_126_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <math.h>\n\nuint64_t sum_squares_simd(const std::vector<float> & lst){\n    if (lst.empty()) return 0;\n\n    size_t size = lst.size();\n    uint64_t total_sum = 0;\n    float ceil_values[4];\n    \n    // Process vectors of 4 elements using NEON\n    for (size_t i = 0; i + 3 < size; i += 4) {\n        float32x4_t vec = vld1q_f32(&lst[i]);\n        float32x4_t ceil_vec = vcvtq_f32_s32(vcvtaq_s32_f32(vec)); // Ceiling operation\n        float32x4_t squared = vmulq_f32(ceil_vec, ceil_vec); // Square the values\n        float32x4_t partial_sum = vpaddq_f32(squared, vsrq_n_f32(squared, 2)); // Horizontal add\n        float temp_sum = vgetq_lane_f32(partial_sum, 0) + vgetq_lane_f32(partial_sum, 1);\n        total_sum += static_cast<uint64_t>(temp_sum);\n    }\n\n    // Handle remaining elements\n    for (size_t i = (size / 4) * 4; i < size; ++i) {\n        float val = ceilf(lst[i]);\n        total_sum += static_cast<uint64_t>(val * val);\n    }\n\n    return total_sum;\n}\n```"}
{"task_id": "SimdBench_126_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <cstdint>\n#include <vector>\n\nuint64_t sum_squares_simd(const std::vector<float> & lst){\n    if (lst.empty()) return 0;\n\n    uint64_t total_sum = 0;\n    size_t aligned_size = lst.size() / 4 * 4;\n    const float *data = lst.data();\n\n    float32x4_t sum_vec = vdupq_n_f32(0.0f);\n\n    for(size_t i = 0; i < aligned_size; i += 4){\n        float32x4_t vec = vld1q_f32(data + i);\n        float32x4_t ceil_vec = vcvtq_f32_u32(vcvtq_u32_f32(vec));\n        float32x4_t squared = vmulq_f32(ceil_vec, ceil_vec);\n        sum_vec = vaddq_f32(sum_vec, squared);\n    }\n\n    float32x2_t low = vget_low_f32(sum_vec);\n    float32x2_t high = vget_high_f32(sum_vec);\n    float32x2_t pairwise_sum = vpadd_f32(low, high);\n    float temp_sum = vget_lane_f32(pairwise_sum, 0) + vget_lane_f32(pairwise_sum, 1);\n    total_sum += static_cast<uint64_t>(temp_sum);\n\n    // Handle remaining elements\n    for(size_t i = aligned_size; i < lst.size(); ++i){\n        total_sum += static_cast<uint64_t>(std::ceil(lst[i])) * static_cast<uint64_t>(std::ceil(lst[i]));\n    }\n\n    return total_sum;\n}\n```"}
{"task_id": "SimdBench_126_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <cstdint>\n#include <vector>\n\nuint64_t sum_squares_simd(const std::vector<float> & lst){\n    if (lst.empty()) return 0;\n\n    uint64_t total_sum = 0;\n    size_t aligned_size = lst.size() / 4 * 4;\n    const float *data = lst.data();\n\n    float32x4_t sum_vec = vmovq_n_f32(0.0f);\n\n    for(size_t i = 0; i < aligned_size; i += 4){\n        float32x4_t vec = vld1q_f32(data + i);\n        float32x4_t ceil_vec = vcvtq_f32_u32(vcvtq_u32_f32(vec));\n        float32x4_t squared = vmulq_f32(ceil_vec, ceil_vec);\n        sum_vec = vaddq_f32(sum_vec, squared);\n    }\n\n    float32x2_t low = vadd_f32(vget_low_f32(sum_vec), vpadd_f32(vget_low_f32(sum_vec), vget_high_f32(sum_vec)));\n    float32x2_t high = vpadd_f32(low, low);\n    total_sum += (uint64_t)vget_lane_f32(high, 0);\n\n    for(size_t i = aligned_size; i < lst.size(); ++i){\n        total_sum += static_cast<uint64_t>(std::ceil(lst[i])) * static_cast<uint64_t>(std::ceil(lst[i]));\n    }\n\n    return total_sum;\n}\n```"}
{"task_id": "SimdBench_127_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <cstdint>\n\nint can_arrange_simd(const std::vector<int> & arr){\n    int n = arr.size();\n    if (n <= 1) return -1;\n\n    const int32_t *data = arr.data();\n    int result = -1;\n\n    for(int i = 0; i + 3 < n; i += 4){\n        uint32x4_t v_idx = vdupq_u32(i);\n        v_idx = vaddq_u32(v_idx, vmovq_n_u32(1));\n\n        int32x4_t v_curr = vld1q_s32(&data[i]);\n        int32x4_t v_next = vld1q_s32(&data[i+1]);\n\n        uint32x4_t mask = vcgeq_s32(v_curr, v_next);\n        uint32x4_t indices = vmovl_u16(vget_low_u16(vmovn_u32(mask)));\n        uint32x2_t cmp = vclz_u32(vget_lane_u32(indices, 0), vget_lane_u32(indices, 1));\n        \n        int idx = vmaxv_u32(vget_low_u32(vandq_u32(mask, v_idx)));\n        if(idx != 0){\n            result = idx + i - 1;\n        }\n    }\n\n    // Handle remaining elements\n    for(int i = ((n-1)/4)*4; i < n-1; ++i){\n        if(data[i] >= data[i+1]){\n            result = i;\n            break;\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_127_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <cstdint>\n\nint can_arrange_simd(const std::vector<int> & arr){\n    if (arr.size() < 2) return -1;\n\n    const int * data = arr.data();\n    size_t size = arr.size();\n    int result = -1;\n\n    for (size_t i = 0; i + 3 < size; i += 4) {\n        int32x4_t vec_curr = vld1q_s32(data + i);\n        int32x4_t vec_next = vld1q_s32(data + i + 1);\n\n        uint32x4_t comparison = vcgeq_s32(vec_next, vec_curr);\n        uint32x4_t mask = vmovq_n_u32(0xFFFFFFFF);\n        uint32x4_t indices = vdupq_n_u32(i);\n        indices = vaddq_u32(indices, vmovq_n_u32(1));\n\n        uint32x4_t mismatch = vbicq_u32(comparison, mask);\n        uint32x4_t mismatch_indices = vandq_u32(mismatch, indices);\n\n        uint32_t min_index = vminvq_u32(mismatch_indices);\n        if (min_index != 0 && min_index < result || result == -1) {\n            result = min_index;\n        }\n    }\n\n    // Handle remaining elements\n    for (size_t i = ((size - 1) / 4) * 4; i + 1 < size; ++i) {\n        if (data[i + 1] < data[i]) {\n            result = i + 1;\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_127_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <cstdint>\n\nint can_arrange_simd(const std::vector<int> & arr){\n    int n = arr.size();\n    if (n <= 1) return -1;\n\n    const int32_t * data = arr.data();\n    int32x4_t prev, curr;\n    int result = -1;\n\n    for(int i = 0; i < n - 1; i += 4){\n        prev = vld1q_s32(data + i);\n        curr = vld1q_s32(data + i + 1);\n\n        // Compare each element with the next one\n        uint32x4_t mask = vcgeq_s32(curr, prev);\n\n        // Find indices where condition is false\n        uint32x4_t not_mask = vmvnq_u32(mask);\n\n        // Check if any of the comparisons failed\n        if(vmaxvq_u32(not_mask) != 0){\n            // Extract the index of the first failure\n            uint32x4_t indices = vdupq_n_u32(i);\n            indices = vaddq_u32(indices, vmovl_u16(vcreate_u16(0x0100030201000302ull)));\n            uint32x4_t failed_indices = vandq_u32(indices, not_mask);\n            uint32_t min_index = vminvq_u32(failed_indices);\n            result = static_cast<int>(min_index);\n            break;\n        }\n    }\n\n    // Handle remaining elements if any\n    for(int i = ((n - 1) / 4) * 4; i < n - 1; ++i){\n        if(data[i] > data[i+1]){\n            result = i;\n            break;\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_127_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nint can_arrange_simd(const std::vector<int> & arr){\n    int n = arr.size();\n    if (n <= 1) return -1;\n\n    const int *data = arr.data();\n    int result = -1;\n\n    // Process 4 elements at a time using SIMD\n    for(int i = 0; i + 3 < n; i += 4){\n        int32x4_t vec_curr = vld1q_s32(data + i);\n        int32x4_t vec_next = vld1q_s32(data + i + 1);\n\n        // Compare current with next\n        uint32x4_t mask = vcgeq_s32(vec_curr, vec_next);\n\n        // Find the first element that violates the order\n        uint32x4_t indices = vdupq_n_u32(i);\n        indices = vaddq_u32(indices, vmovl_u8(vcreate_u8(0x0100030205040706ULL)));\n        uint32x4_t masked_indices = vbslq_u32(mask, indices, vdupq_n_u32(-1));\n\n        // Extract the minimum index\n        int32x2_t min_idx = vminmvq_s32(vreinterpretq_s32_u32(masked_indices));\n        if(min_idx[0] != -1 && (result == -1 || min_idx[0] > result)){\n            result = min_idx[0];\n        }\n    }\n\n    // Handle remaining elements\n    for(int i = ((n - 1) / 4) * 4; i < n - 1; ++i){\n        if(arr[i] >= arr[i + 1]){\n            result = i;\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_127_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <cstdint>\n\nint can_arrange_simd(const std::vector<int> & arr){\n    if (arr.size() < 2) return -1;\n\n    const int32_t * data = arr.data();\n    size_t n = arr.size();\n    int result = -1;\n\n    // Process in chunks of 4 elements using SIMD\n    for (size_t i = 0; i + 3 < n; i += 4) {\n        int32x4_t vec_curr = vld1q_s32(data + i);\n        int32x4_t vec_prev = vld1q_s32(data + i - 1);\n\n        // Compare current with previous\n        uint32x4_t mask = vcgeq_s32(vec_curr, vec_prev);\n\n        // Find the first element that violates the condition\n        uint32_t bit_mask = vget_lane_u32(vmovemask_f32(vreinterpretq_f32_u32(mask)), 0);\n        if (bit_mask != 0xFFFFFFFF) {\n            // Determine the specific index\n            int index = i + __builtin_ctz(~bit_mask);\n            if (index > result) {\n                result = index;\n            }\n        }\n    }\n\n    // Handle remaining elements\n    for (size_t i = (n / 4) * 4; i < n - 1; ++i) {\n        if (data[i] >= data[i + 1]) {\n            result = i + 1;\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_128_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<int> largest_smallest_integers_simd(const std::vector<int>& lst){\n    if (lst.empty()) {\n        return {0, 0};\n    }\n\n    int a = 0, b = 0;\n    bool has_neg = false, has_pos = false;\n\n    size_t n = lst.size();\n    size_t aligned_size = n / 4 * 4;\n\n    int32x4_t max_neg = vmovq_n_s32(0);\n    int32x4_t min_pos = vmovq_n_s32(0);\n    int32x4_t zero = vmovq_n_s32(0);\n\n    for (size_t i = 0; i < aligned_size; i += 4) {\n        int32x4_t vec = vld1q_s32(reinterpret_cast<const int32_t*>(&lst[i]));\n        int32x4_t neg_mask = vcgtq_s32(zero, vec);\n        int32x4_t pos_mask = vcgtq_s32(vec, zero);\n\n        int32x4_t current_max_neg = vmaxq_s32(max_neg, vec);\n        int32x4_t current_min_pos = vminq_s32(min_pos, vec);\n\n        max_neg = vbslq_s32(neg_mask, current_max_neg, max_neg);\n        min_pos = vbslq_s32(pos_mask, current_min_pos, min_pos);\n\n        has_neg |= !(vget_lane_u32(vmvn_u32(vget_low_u32(vcge_f32(vreinterpretq_f32_s32(vec), vdupq_n_f32(0.0f)))), 0));\n        has_pos |= !(vget_lane_u32(vmvn_u32(vget_low_u32(vcgt_f32(vreinterpretq_f32_s32(vec), vdupq_n_f32(0.0f)))), 0));\n    }\n\n    for (size_t i = aligned_size; i < n; ++i) {\n        if (lst[i] < 0) {\n            if (!has_neg || lst[i] > a) {\n                a = lst[i];\n                has_neg = true;\n            }\n        } else if (lst[i] > 0) {\n            if (!has_pos || lst[i] < b || !has_pos) {\n                b = lst[i];\n                has_pos = true;\n            }\n        }\n    }\n\n    int32x2_t max_neg_low = vpmax_s32(vget_low_s32(max_neg), vget_high_s32(max_neg));\n    int32x2_t max_neg_final = vpmax_s32(max_neg_low, vext_s32(max_neg_low, max_neg_low, 1));\n    a = has_neg ? vget_lane_s32(max_neg_final, 0) : a;\n\n    int32x2_t min_pos_low = vpmin_s32(vget_low_s32(min_pos), vget_high_s32(min_pos));\n    int32x2_t min_pos_final = vpmin_s32(min_pos_low, vext_s32(min_pos_low, min_pos_low, 1));\n    b = has_pos ? vget_lane_s32(min_pos_final, 0) : b;\n\n    return {a, b};\n}\n```"}
{"task_id": "SimdBench_128_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<int> largest_smallest_integers_simd(const std::vector<int>& lst){\n    if (lst.empty()) {\n        return {0, 0};\n    }\n\n    int32x4_t max_neg = vmovq_n_s32(-1);\n    int32x4_t min_pos = vmovq_n_s32(0x7FFFFFFF);\n    int32x4_t zero = vmovq_n_s32(0);\n\n    size_t i = 0;\n    for (; i + 3 < lst.size(); i += 4) {\n        int32x4_t vec = vld1q_s32(&lst[i]);\n        int32x4_t neg_mask = vcgtq_s32(zero, vec);\n        int32x4_t pos_mask = vcgtq_s32(vec, zero);\n\n        max_neg = vmaxsq_s32(max_neg, vandq_s32(neg_mask, vec));\n        min_pos = vminsq_s32(min_pos, vandq_s32(pos_mask, vec));\n    }\n\n    int32_t max_neg_val = -1, min_pos_val = 0x7FFFFFFF;\n\n    // Extract and compare each lane of the SIMD registers\n    for (int j = 0; j < 4; ++j) {\n        int32_t val_max_neg = vgetq_lane_s32(max_neg, j);\n        if (val_max_neg > max_neg_val && val_max_neg < 0) {\n            max_neg_val = val_max_neg;\n        }\n\n        int32_t val_min_pos = vgetq_lane_s32(min_pos, j);\n        if (val_min_pos < min_pos_val && val_min_pos > 0) {\n            min_pos_val = val_min_pos;\n        }\n    }\n\n    // Process remaining elements\n    for (; i < lst.size(); ++i) {\n        if (lst[i] < 0 && lst[i] > max_neg_val) {\n            max_neg_val = lst[i];\n        } else if (lst[i] > 0 && lst[i] < min_pos_val) {\n            min_pos_val = lst[i];\n        }\n    }\n\n    if (max_neg_val == -1) max_neg_val = 0;\n    if (min_pos_val == 0x7FFFFFFF) min_pos_val = 0;\n\n    return {max_neg_val, min_pos_val};\n}\n```"}
{"task_id": "SimdBench_128_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<int> largest_smallest_integers_simd(const std::vector<int>& lst){\n    if (lst.empty()) return {0, 0};\n\n    int32x4_t max_neg = vmovq_n_s32(-1); // Initialize with -1 for all lanes\n    int32x4_t min_pos = vmovq_n_s32(0xFFFFFFFF); // Initialize with max value for all lanes\n\n    size_t i = 0;\n    for (; i + 16 <= lst.size(); i += 16) {\n        int32x4_t vec1 = vld1q_s32(&lst[i]);\n        int32x4_t vec2 = vld1q_s32(&lst[i + 4]);\n        int32x4_t vec3 = vld1q_s32(&lst[i + 8]);\n        int32x4_t vec4 = vld1q_s32(&lst[i + 12]);\n\n        // Find negative values and update max_neg\n        uint32x4_t mask_neg1 = vcgtq_s32(vmovq_n_s32(0), vec1);\n        uint32x4_t mask_neg2 = vcgtq_s32(vmovq_n_s32(0), vec2);\n        uint32x4_t mask_neg3 = vcgtq_s32(vmovq_n_s32(0), vec3);\n        uint32x4_t mask_neg4 = vcgtq_s32(vmovq_n_s32(0), vec4);\n\n        max_neg = vmaxq_s32(max_neg, vbslq_s32(mask_neg1, vec1, max_neg));\n        max_neg = vmaxq_s32(max_neg, vbslq_s32(mask_neg2, vec2, max_neg));\n        max_neg = vmaxq_s32(max_neg, vbslq_s32(mask_neg3, vec3, max_neg));\n        max_neg = vmaxq_s32(max_neg, vbslq_s32(mask_neg4, vec4, max_neg));\n\n        // Find positive values and update min_pos\n        uint32x4_t mask_pos1 = vcgtq_s32(vec1, vmovq_n_s32(0));\n        uint32x4_t mask_pos2 = vcgtq_s32(vec2, vmovq_n_s32(0));\n        uint32x4_t mask_pos3 = vcgtq_s32(vec3, vmovq_n_s32(0));\n        uint32x4_t mask_pos4 = vcgtq_s32(vec4, vmovq_n_s32(0));\n\n        min_pos = vminq_s32(min_pos, vbslq_s32(mask_pos1, vec1, min_pos));\n        min_pos = vminq_s32(min_pos, vbslq_s32(mask_pos2, vec2, min_pos));\n        min_pos = vminq_s32(min_pos, vbslq_s32(mask_pos3, vec3, min_pos));\n        min_pos = vminq_s32(min_pos, vbslq_s32(mask_pos4, vec4, min_pos));\n    }\n\n    // Process remaining elements\n    for (; i < lst.size(); ++i) {\n        if (lst[i] < 0 && lst[i] > vgetq_lane_s32(max_neg, 0)) {\n            max_neg = vsetq_lane_s32(lst[i], max_neg, 0);\n        }\n        if (lst[i] > 0 && lst[i] < vgetq_lane_s32(min_pos, 0)) {\n            min_pos = vsetq_lane_s32(lst[i], min_pos, 0);\n        }\n    }\n\n    // Extract results\n    int a = vgetq_lane_s32(max_neg, 0);\n    int b = vgetq_lane_s32(min_pos, 0);\n\n    if (a >= 0) a = 0;\n    if (b <= 0) b = 0;\n\n    return {a, b};\n}\n```"}
{"task_id": "SimdBench_128_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<int> largest_smallest_integers_simd(const std::vector<int>& lst){\n    if (lst.empty()) {\n        return {0, 0};\n    }\n\n    int32x4_t max_neg = vmovq_n_s32(-1); // Initialize with -1\n    int32x4_t min_pos = vmovq_n_s32(0x7FFFFFFF); // Initialize with max int\n    int32x4_t zero = vmovq_n_s32(0);\n\n    size_t i = 0;\n    for (; i + 4 <= lst.size(); i += 4) {\n        int32x4_t vec = vld1q_s32(&lst[i]);\n        int32x4_t neg_mask = vcgtq_s32(zero, vec);\n        int32x4_t pos_mask = vcgtq_s32(vec, zero);\n\n        max_neg = vmaxsq_s32(max_neg, vandq_s32(neg_mask, vec));\n        min_pos = vminsq_s32(min_pos, vandq_s32(pos_mask, vec));\n    }\n\n    int32x2_t max_neg_low = vpmax_s32(vget_low_s32(max_neg), vget_high_s32(max_neg));\n    int32x2_t max_neg_final = vpmax_s32(max_neg_low, max_neg_low);\n\n    int32x2_t min_pos_low = vpmin_s32(vget_low_s32(min_pos), vget_high_s32(min_pos));\n    int32x2_t min_pos_final = vpmin_s32(min_pos_low, min_pos_low);\n\n    int a = vmaxv_s32(max_neg);\n    int b = vminv_s32(min_pos);\n\n    // Handle remaining elements\n    for (; i < lst.size(); ++i) {\n        if (lst[i] < 0 && lst[i] > a) {\n            a = lst[i];\n        }\n        if (lst[i] > 0 && lst[i] < b) {\n            b = lst[i];\n        }\n    }\n\n    if (a >= 0) a = 0;\n    if (b == 0x7FFFFFFF) b = 0;\n\n    return {a, b};\n}\n```"}
{"task_id": "SimdBench_128_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <algorithm>\n\nstd::vector<int> largest_smallest_integers_simd(const std::vector<int>& lst){\n    if (lst.empty()) {\n        return {0, 0};\n    }\n\n    int a = 0, b = 0;\n    bool has_neg = false, has_pos = false;\n\n    size_t n = lst.size();\n    size_t aligned_size = n / 4 * 4;\n\n    int32x4_t max_neg = vmovq_n_s32(-1);\n    int32x4_t min_pos = vmovq_n_s32(0xFFFFFFFF);\n\n    for (size_t i = 0; i < aligned_size; i += 4) {\n        int32x4_t vec = vld1q_s32(&lst[i]);\n        \n        uint32x4_t neg_mask = vcgtq_s32(vmovq_n_s32(0), vec);\n        int32x4_t neg_vals = vbslq_s32(neg_mask, vec, vmovq_n_s32(0));\n        max_neg = vmaxq_s32(max_neg, neg_vals);\n\n        uint32x4_t pos_mask = vcgtq_s32(vec, vmovq_n_s32(0));\n        int32x4_t pos_vals = vbslq_s32(pos_mask, vec, vmovq_n_s32(0xFFFFFFFF));\n        min_pos = vminq_s32(min_pos, pos_vals);\n    }\n\n    int32x2_t max_neg_low = vpmax_s32(vget_low_s32(max_neg), vget_high_s32(max_neg));\n    int32x2_t max_neg_final = vpmax_s32(max_neg_low, max_neg_low);\n    int max_neg_val = vget_lane_s32(max_neg_final, 0);\n\n    int32x2_t min_pos_low = vpmin_s32(vget_low_s32(min_pos), vget_high_s32(min_pos));\n    int32x2_t min_pos_final = vpmin_s32(min_pos_low, min_pos_low);\n    int min_pos_val = vget_lane_s32(min_pos_final, 0);\n\n    for (size_t i = aligned_size; i < n; ++i) {\n        if (lst[i] < 0 && (!has_neg || lst[i] > max_neg_val)) {\n            max_neg_val = lst[i];\n            has_neg = true;\n        }\n        if (lst[i] > 0 && (!has_pos || lst[i] < min_pos_val)) {\n            min_pos_val = lst[i];\n            has_pos = true;\n        }\n    }\n\n    if (!has_neg) max_neg_val = 0;\n    if (!has_pos) min_pos_val = 0;\n\n    return {max_neg_val, min_pos_val};\n}\n```"}
{"task_id": "SimdBench_129_Neon", "completion": "```c\n#include <arm_neon.h>\n\nuint64_t special_factorial_simd(uint64_t n){\n    if (n == 0 || n == 1) return 1;\n\n    uint64x2_t result = vdupq_n_u64(1);\n    uint64x2_t temp_result = vdupq_n_u64(1);\n\n    for(uint64_t i = 2; i <= n; ++i){\n        uint64x2_t current_val = vdupq_n_u64(i);\n        uint64x2_t factorial = vdupq_n_u64(1);\n\n        for(uint64_t j = 1; j <= i; ++j){\n            uint64x2_t multiplier = vdupq_n_u64(j);\n            factorial = vmulq_u64(factorial, multiplier);\n        }\n\n        temp_result = vmulq_u64(temp_result, factorial);\n        if(i % 2 == 0){\n            result = vmulq_u64(result, temp_result);\n            temp_result = vdupq_n_u64(1);\n        }\n    }\n\n    if(n % 2 != 0){\n        result = vmulq_u64(result, temp_result);\n    }\n\n    return vgetq_lane_u64(result, 0) * vgetq_lane_u64(result, 1);\n}\n```"}
{"task_id": "SimdBench_129_Neon", "completion": "```c\n#include <arm_neon.h>\n\nuint64_t special_factorial_simd(uint64_t n){\n    uint64x2_t result = vdupq_n_u64(1);\n    uint64x2_t one = vdupq_n_u64(1);\n\n    for(uint64_t i = 1; i <= n; ++i){\n        uint64x2_t current = vdupq_n_u64(i);\n        uint64x2_t factorial = vdupq_n_u64(1);\n\n        for(uint64_t j = 1; j <= i; ++j){\n            uint64x2_t temp = vmulq_u64(factorial, current);\n            factorial = vsliq_n_u64(temp, factorial, 1);\n            current = vsubq_u64(current, one);\n        }\n\n        result = vmulq_u64(result, factorial);\n    }\n\n    return vaddvq_u64(result);\n}\n```"}
{"task_id": "SimdBench_129_Neon", "completion": "```c\n#include <arm_neon.h>\n\nuint64_t special_factorial_simd(uint64_t n){\n    if (n == 0 || n == 1) return 1;\n\n    uint64x2_t result = vdupq_n_u64(1);\n    uint64x2_t temp = vdupq_n_u64(1);\n\n    for(uint64_t i = 2; i <= n; ++i){\n        uint64x2_t val = vdupq_n_u64(i);\n        for(uint64_t j = i; j >=1; --j){\n            temp = vmulq_u64(temp, val);\n            val = vsubq_u64(val, vdupq_n_u64(1));\n        }\n        result = vmulq_u64(result, temp);\n        temp = vdupq_n_u64(1);\n    }\n\n    return result[0] * result[1];\n}\n```"}
{"task_id": "SimdBench_129_Neon", "completion": "```c\n#include <arm_neon.h>\n\nuint64_t special_factorial_simd(uint64_t n){\n    if (n == 0 || n == 1) return 1;\n\n    uint64x2_t result = vdupq_n_u64(1);\n    uint64x2_t acc = vdupq_n_u64(1);\n\n    for(uint64_t i = 2; i <= n; ++i){\n        uint64x2_t val = vdupq_n_u64(i);\n        acc = vmulq_u64(acc, val);\n        result = vmulq_u64(result, acc);\n    }\n\n    return result[0] * result[1];\n}\n```"}
{"task_id": "SimdBench_129_Neon", "completion": "```c\n#include <arm_neon.h>\n\nuint64_t special_factorial_simd(uint64_t n){\n    if (n == 0 || n == 1) return 1;\n\n    uint64x2_t result = vdupq_n_u64(1);\n    uint64x2_t acc = vdupq_n_u64(1);\n\n    for(uint64_t i = 2; i <= n; ++i){\n        uint64x2_t val = vdupq_n_u64(i);\n        uint64x2_t factorial = vdupq_n_u64(1);\n\n        for(uint64_t j = 2; j <= i; ++j){\n            factorial = vmulq_u64(factorial, val);\n            val = vsubq_u64(val, vdupq_n_u64(1));\n        }\n\n        acc = vmulq_u64(acc, factorial);\n        result = vmulq_u64(result, acc);\n    }\n\n    return result[0] * result[1];\n}\n```"}
{"task_id": "SimdBench_130_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nint sum_squares_simd(const std::vector<int> & lst){\n    if (lst.empty()) return 0;\n\n    int total_sum = 0;\n    size_t vec_size = lst.size();\n    size_t aligned_size = vec_size - (vec_size % 4);\n\n    for (size_t i = 0; i < aligned_size; i += 4) {\n        int32x4_t vload = vld1q_s32(&lst[i]);\n        int32x4_t vsquare = vdupq_n_s32(0);\n        int32x4_t vcube = vdupq_n_s32(0);\n\n        for (size_t j = 0; j < 4; ++j) {\n            if ((i + j) % 3 == 0) {\n                vsquare = vsetq_lane_s32(lst[i + j] * lst[i + j], vsquare, j);\n            }\n            if ((i + j) % 4 == 0 && (i + j) % 3 != 0) {\n                vcube = vsetq_lane_s32(lst[i + j] * lst[i + j] * lst[i + j], vcube, j);\n            }\n        }\n\n        int32x4_t vresult = vaddq_s32(vsquare, vcube);\n        int32x4_t vcond = vmovq_n_s32(1);\n        for (size_t j = 0; j < 4; ++j) {\n            if ((i + j) % 3 != 0 && (i + j) % 4 != 0) {\n                vresult = vsetq_lane_s32(lst[i + j], vresult, j);\n            }\n        }\n\n        int32x4_t vsum = vpaddlq_s32(vresult);\n        int32x2_t vsum_low = vpadd_s32(vget_low_s32(vsum), vget_high_s32(vsum));\n        int temp_sum = vget_lane_s32(vsum_low, 0) + vget_lane_s32(vsum_low, 1);\n        total_sum += temp_sum;\n    }\n\n    for (size_t i = aligned_size; i < vec_size; ++i) {\n        if (i % 3 == 0) {\n            total_sum += lst[i] * lst[i];\n        } else if (i % 4 == 0) {\n            total_sum += lst[i] * lst[i] * lst[i];\n        } else {\n            total_sum += lst[i];\n        }\n    }\n\n    return total_sum;\n}\n```"}
{"task_id": "SimdBench_130_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nint sum_squares_simd(const std::vector<int> & lst){\n    if (lst.empty()) return 0;\n\n    int n = lst.size();\n    int sum = 0;\n    int leftover = n % 4;\n    int *data = const_cast<int*>(lst.data());\n\n    for(int i = 0; i < leftover; ++i){\n        if(i % 3 == 0){\n            sum += data[i] * data[i];\n        }\n        else if(i % 4 == 0){\n            sum += data[i] * data[i] * data[i];\n        }\n        else{\n            sum += data[i];\n        }\n    }\n\n    for(int i = leftover; i < n; i += 4){\n        int32x4_t vld = vld1q_s32(data + i);\n        int32x4_t vsquare = vmulq_s32(vld, vld);\n        int32x4_t vcube = vmulq_s32(vsquare, vld);\n\n        uint32x4_t mask3 = vmovq_n_u32(0xFFFFFFFF);\n        uint32x4_t mask4 = vmovq_n_u32(0xFFFFFFFF);\n\n        if((i % 3) != 0){\n            mask3 = vmovq_n_u32(0);\n        }\n        if((i % 4) != 0 || (i % 3) == 0){\n            mask4 = vmovq_n_u32(0);\n        }\n\n        int32x4_t vresult = vbslq_s32(mask3, vsquare, vld);\n        vresult = vbslq_s32(mask4, vcube, vresult);\n\n        int32x4_t vsum = vpaddq_s32(vresult, vresult);\n        vsum = vpaddq_s32(vsum, vsum);\n\n        sum += vgetq_lane_s32(vsum, 0);\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_130_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nint sum_squares_simd(const std::vector<int> & lst){\n    if (lst.empty()) return 0;\n\n    int n = lst.size();\n    int sum = 0;\n    int leftover = n % 4;\n    int i = 0;\n\n    // Process in chunks of 4\n    for (; i <= n - 4; i += 4) {\n        int32x4_t vload = vld1q_s32(&lst[i]);\n        int32x4_t vsquare = vdupq_n_s32(0);\n        int32x4_t vcube = vdupq_n_s32(0);\n\n        // Create mask for indices that are multiples of 3\n        uint32x4_t vmask3 = vmovq_n_u32((i % 3 == 0) + ((i+1) % 3 == 0)*2 + ((i+2) % 3 == 0)*4 + ((i+3) % 3 == 0)*8);\n        // Create mask for indices that are multiples of 4 but not 3\n        uint32x4_t vmask4 = vmovq_n_u32(((i % 4 == 0) && (i % 3 != 0)) + (((i+1) % 4 == 0) && ((i+1) % 3 != 0))*2 + \n                            (((i+2) % 4 == 0) && ((i+2) % 3 != 0))*4 + (((i+3) % 4 == 0) && ((i+3) % 3 != 0))*8);\n\n        vsquare = vmulq_s32(vload, vload); // Square the loaded values\n        vcube = vmulq_s32(vmulq_s32(vload, vload), vload); // Cube the loaded values\n\n        // Select squared values where index is multiple of 3\n        vload = vbslq_s32(vmask3, vsquare, vload);\n        // Select cubed values where index is multiple of 4 but not 3\n        vload = vbslq_s32(vmask4, vcube, vload);\n\n        int32x4_t vsum = vpaddq_s32(vload, vload);\n        vsum = vpaddq_s32(vsum, vsum);\n        sum += vgetq_lane_s32(vsum, 0);\n    }\n\n    // Handle remaining elements\n    for (; i < n; ++i) {\n        if (i % 3 == 0) {\n            sum += lst[i] * lst[i];\n        } else if (i % 4 == 0) {\n            sum += lst[i] * lst[i] * lst[i];\n        } else {\n            sum += lst[i];\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_130_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nint sum_squares_simd(const std::vector<int> & lst){\n    if (lst.empty()) return 0;\n\n    int total_sum = 0;\n    size_t vec_size = lst.size();\n    size_t aligned_size = vec_size - (vec_size % 4);\n\n    for (size_t i = 0; i < aligned_size; i += 4) {\n        int32x4_t vload = vld1q_s32(&lst[i]);\n        int32x4_t vsquare = vdupq_n_s32(0);\n        int32x4_t vcube = vdupq_n_s32(0);\n\n        for (int j = 0; j < 4; ++j) {\n            if ((i + j) % 3 == 0) {\n                vsquare = vsetq_lane_s32(lst[i + j] * lst[i + j], vsquare, j);\n            } else if ((i + j) % 4 == 0 && (i + j) % 3 != 0) {\n                vcube = vsetq_lane_s32(lst[i + j] * lst[i + j] * lst[i + j], vcube, j);\n            } else {\n                vsquare = vsetq_lane_s32(lst[i + j], vsquare, j);\n                vcube = vsetq_lane_s32(lst[i + j], vcube, j);\n            }\n        }\n\n        int32x4_t vresult = vaddq_s32(vsquare, vcube);\n        int32x4_t vsum = vpaddlq_s32(vresult);\n        int32x2_t vsum2 = vpaddl_s32(vget_low_s32(vsum), vget_high_s32(vsum));\n        total_sum += vget_lane_s32(vsum2, 0);\n    }\n\n    for (size_t i = aligned_size; i < vec_size; ++i) {\n        if (i % 3 == 0) {\n            total_sum += lst[i] * lst[i];\n        } else if (i % 4 == 0 && i % 3 != 0) {\n            total_sum += lst[i] * lst[i] * lst[i];\n        } else {\n            total_sum += lst[i];\n        }\n    }\n\n    return total_sum;\n}\n```"}
{"task_id": "SimdBench_130_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nint sum_squares_simd(const std::vector<int> & lst){\n    if (lst.empty()) return 0;\n\n    int total_sum = 0;\n    size_t vec_size = lst.size();\n    size_t aligned_size = vec_size - (vec_size % 4);\n\n    for(size_t i = 0; i < aligned_size; i += 4){\n        int32x4_t vload = vld1q_s32(&lst[i]);\n        int32x4_t vsquare = vmulq_s32(vload, vload);\n        int32x4_t vcube = vmulq_s32(vsquare, vload);\n\n        // Masks for index conditions\n        uint32x4_t mask_multiple_of_3 = vmovq_n_u32( ((i%3==0) ? 0xFFFFFFFF : 0) |\n                                                    (((i+1)%3==0) ? 0xFFFFFFFF : 0) |\n                                                    (((i+2)%3==0) ? 0xFFFFFFFF : 0) |\n                                                    (((i+3)%3==0) ? 0xFFFFFFFF : 0) );\n        uint32x4_t mask_multiple_of_4_not_3 = vmovq_n_u32( ((i%4==0 && i%3!=0) ? 0xFFFFFFFF : 0) |\n                                                          ((((i+1)%4==0) && ((i+1)%3!=0)) ? 0xFFFFFFFF : 0) |\n                                                          ((((i+2)%4==0) && ((i+2)%3!=0)) ? 0xFFFFFFFF : 0) |\n                                                          ((((i+3)%4==0) && ((i+3)%3!=0)) ? 0xFFFFFFFF : 0) );\n\n        // Apply masks\n        int32x4_t result_square = vandq_s32(vsquare, vmovq_n_s32(vget_lane_u32(mask_multiple_of_3, 0)));\n        int32x4_t result_cube = vandq_s32(vcube, vmovq_n_s32(vget_lane_u32(mask_multiple_of_4_not_3, 0)));\n\n        // Combine results\n        int32x4_t combined_result = vorrq_s32(result_square, result_cube);\n        combined_result = vaddq_s32(combined_result, vandq_s32(vload, vmvnq_u32(vorrq_u32(mask_multiple_of_3, mask_multiple_of_4_not_3))));\n\n        // Accumulate the sum\n        int32x4_t vsum = vpaddlq_s32(vaddl_s32(vget_low_s32(combined_result), vget_high_s32(combined_result)));\n        total_sum += vget_lane_s32(vsum, 0) + vget_lane_s32(vsum, 1) + vget_lane_s32(vsum, 2) + vget_lane_s32(vsum, 3);\n    }\n\n    // Handle remaining elements\n    for(size_t i = aligned_size; i < vec_size; ++i){\n        if(i % 3 == 0){\n            total_sum += lst[i] * lst[i];\n        }\n        else if(i % 4 == 0){\n            total_sum += lst[i] * lst[i] * lst[i];\n        }\n        else{\n            total_sum += lst[i];\n        }\n    }\n\n    return total_sum;\n}\n```"}
{"task_id": "SimdBench_131_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nint specialFilter_simd(const std::vector<int> & nums){\n    int count = 0;\n    size_t n = nums.size();\n    if (n == 0) return 0;\n\n    const int16x8_t v_ten = vdupq_n_s16(10);\n    const uint8x8_t v_odd_mask = vdup_n_u8(0x55);\n\n    for (size_t i = 0; i + 16 <= n; i += 16) {\n        int32x4_t v_num_low = vld1q_s32(reinterpret_cast<const int32_t*>(&nums[i]));\n        int32x4_t v_num_high = vld1q_s32(reinterpret_cast<const int32_t*>(&nums[i + 8]));\n\n        // Check if numbers are greater than 10\n        uint32x4_t v_gt_low = vcgtq_s32(v_num_low, vdupq_n_s32(10));\n        uint32x4_t v_gt_high = vcgtq_s32(v_num_high, vdupq_n_s32(10));\n\n        // Extract absolute values\n        uint32x4_t v_abs_low = vabsq_s32(v_num_low);\n        uint32x4_t v_abs_high = vabsq_s32(v_num_high);\n\n        // Extract last digits\n        uint32x4_t v_last_digit_low = vmulq_n_u32(vabsq_s32(v_num_low), 0x3E7F); \n        uint32x4_t v_last_digit_high = vmulq_n_u32(vabsq_s32(v_num_high), 0x3E7F); \n\n        v_last_digit_low = vmovn_u64(vshrn_n_u64(vmovl_u32(v_last_digit_low), 8));\n        v_last_digit_high = vmovn_u64(vshrn_n_u64(vmovl_u32(v_last_digit_high), 8));\n\n        // Check if last digit is odd\n        uint8x8_t v_last_odd_low = vand_u8(vreinterpret_u8_u32(v_last_digit_low), v_odd_mask);\n        uint8x8_t v_last_odd_high = vand_u8(vreinterpret_u8_u32(v_last_digit_high), v_odd_mask);\n\n        // Extract first digits\n        uint32x4_t v_first_digit_low = vrshrq_n_u32(v_abs_low, 28);\n        uint32x4_t v_first_digit_high = vrshrq_n_u32(v_abs_high, 28);\n\n        // Check if first digit is odd\n        uint8x8_t v_first_odd_low = vand_u8(vreinterpret_u8_u32(v_first_digit_low), v_odd_mask);\n        uint8x8_t v_first_odd_high = vand_u8(vreinterpret_u8_u32(v_first_digit_high), v_odd_mask);\n\n        // Combine conditions\n        uint8x8_t v_cond_low = vand_u8(vcombine_u8(vreinterpret_u8_u32(v_gt_low), v_last_odd_low), v_first_odd_low);\n        uint8x8_t v_cond_high = vand_u8(vcombine_u8(vreinterpret_u8_u32(v_gt_high), v_last_odd_high), v_first_odd_high);\n\n        // Count valid elements\n        uint8x8_t v_count_low = vcnt_u8(v_cond_low);\n        uint8x8_t v_count_high = vcnt_u8(v_cond_high);\n\n        count += vaddlv_u8(v_count_low) + vaddlv_u8(v_count_high);\n    }\n\n    for (size_t i = (n / 16) * 16; i < n; ++i) {\n        int num = nums[i];\n        if (num > 10) {\n            int abs_num = std::abs(num);\n            int last_digit = abs_num % 10;\n            int first_digit = abs_num;\n            while (first_digit >= 10) first_digit /= 10;\n            if ((last_digit & 1) && (first_digit & 1)) {\n                count++;\n            }\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_131_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nint specialFilter_simd(const std::vector<int> & nums){\n    int count = 0;\n    int vec_size = nums.size();\n    int i = 0;\n\n    // Lambda to check if a digit is odd\n    auto is_odd_digit = [](uint32_t digit) -> uint32_t {\n        return (digit & 1);\n    };\n\n    // Process in chunks of 4\n    for (; i <= vec_size - 4; i += 4) {\n        int32x4_t v_nums = vld1q_s32(&nums[i]);\n        \n        // Check if numbers are greater than 10\n        uint32x4_t v_gt_10 = vcgtq_s32(v_nums, vdupq_n_s32(10));\n\n        // Extract absolute values\n        uint32x4_t v_abs = vmovq_n_u32(0);\n        v_abs = vbicq_u32(vreinterpretq_u32_s32(v_nums), vdupq_n_u32(0x80000000));\n\n        // Extract last digits\n        uint32x4_t v_last_digits = vandq_u32(v_abs, vdupq_n_u32(0xF));\n        uint32x4_t v_last_odd = vcleq_u32(v_last_digits, vdupq_n_u32(9));\n        v_last_odd = vandq_u32(v_last_odd, vcmpgeq_u32(v_last_digits, vdupq_n_u32(1)));\n        v_last_odd = vandq_u32(v_last_odd, vmovq_n_u32(is_odd_digit(vget_lane_u32(v_last_digits, 0)) |\n                                                     is_odd_digit(vget_lane_u32(v_last_digits, 1)) |\n                                                     is_odd_digit(vget_lane_u32(v_last_digits, 2)) |\n                                                     is_odd_digit(vget_lane_u32(v_last_digits, 3))));\n\n        // Extract first digits\n        uint32x4_t v_first_digits = vrshrq_n_u32(v_abs, 28);\n        uint32x4_t v_first_odd = vcleq_u32(v_first_digits, vdupq_n_u32(9));\n        v_first_odd = vandq_u32(v_first_odd, vcmpgeq_u32(v_first_digits, vdupq_n_u32(1)));\n        v_first_odd = vandq_u32(v_first_odd, vmovq_n_u32(is_odd_digit(vget_lane_u32(v_first_digits, 0)) |\n                                                       is_odd_digit(vget_lane_u32(v_first_digits, 1)) |\n                                                       is_odd_digit(vget_lane_u32(v_first_digits, 2)) |\n                                                       is_odd_digit(vget_lane_u32(v_first_digits, 3))));\n\n        // Combine conditions\n        uint32x4_t v_match = vandq_u32(v_gt_10, vandq_u32(v_last_odd, v_first_odd));\n        uint32x4_t v_count = vcntq_u32(v_match);\n\n        // Sum the counts\n        uint32_t count_arr[4];\n        vst1q_u32(count_arr, v_count);\n        count += count_arr[0] + count_arr[1] + count_arr[2] + count_arr[3];\n    }\n\n    // Tail processing\n    for (; i < vec_size; ++i) {\n        int num = nums[i];\n        if (num > 10) {\n            int abs_num = std::abs(num);\n            int last_digit = abs_num % 10;\n            int first_digit = abs_num;\n            while (first_digit >= 10) first_digit /= 10;\n            if (is_odd_digit(first_digit) && is_odd_digit(last_digit)) {\n                count++;\n            }\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_131_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nint specialFilter_simd(const std::vector<int> & nums){\n    int count = 0;\n    if (nums.empty()) return count;\n\n    const int *data = nums.data();\n    size_t size = nums.size();\n\n    // Masks for first and last digit checks\n    uint8x16_t odd_mask = vdupq_n_u8(0x01); // Binary: 00000001\n    uint8x16_t abs_mask = vdupq_n_u8(0x7F); // Binary: 01111111\n\n    for (size_t i = 0; i + 15 < size; i += 16) {\n        int32x4_t vec = vld1q_s32(data + i);\n        uint32x4_t gt_10 = vcgtq_s32(vec, vdupq_n_s32(10));\n\n        // Absolute value\n        int32x4_t abs_vec = vandq_s32(vec, vreinterpretq_s32_u32(abs_mask));\n\n        // Extract last digits\n        uint32x4_t last_digits = vandq_u32(vreinterpretq_u32_s32(abs_vec), vdupq_n_u32(0x0F));\n        uint32x4_t last_odd = vandq_u32(last_digits, vdupq_n_u32(0x01));\n\n        // Extract first digits (assuming numbers are within -999 to 999)\n        uint32x4_t div100 = vshrq_n_u32(vreinterpretq_u32_s32(abs_vec), 6); // Equivalent to /100\n        uint32x4_t first_digits = vandq_u32(div100, vdupq_n_u32(0x0F));\n        uint32x4_t first_odd = vandq_u32(first_digits, vdupq_n_u32(0x01));\n\n        // Combine conditions\n        uint32x4_t valid = vandq_u32(gt_10, vreinterpretq_u32_s32(vandq_s32(vreinterpretq_s32_u32(last_odd), vreinterpretq_s32_u32(first_odd))));\n        uint32x4_t ones = vdupq_n_u32(1);\n        uint32x4_t valid_count = vcntq_u32(valid);\n\n        count += vaddvq_u32(valid_count);\n    }\n\n    // Handle remaining elements\n    for (size_t i = (size / 16) * 16; i < size; ++i) {\n        int num = nums[i];\n        if (num > 10) {\n            int abs_num = (num < 0) ? -num : num;\n            int last_digit = abs_num % 10;\n            int first_digit = abs_num;\n            while (first_digit >= 10) first_digit /= 10;\n            if ((last_digit & 1) && (first_digit & 1)) {\n                count++;\n            }\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_131_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nint specialFilter_simd(const std::vector<int> & nums){\n    int count = 0;\n    int32x4_t threshold = vdupq_n_s32(10);\n    int32x4_t odd_digits = vdupq_n_s32(1); // Representing 1 for simplicity in SIMD checks\n\n    for (size_t i = 0; i + 3 < nums.size(); i += 4) {\n        int32x4_t vec = vld1q_s32(&nums[i]);\n        uint32x4_t gt_mask = vcgtq_s32(vec, threshold);\n\n        // Extract absolute values for digit checks\n        int32x4_t abs_vec = vabsq_s32(vec);\n\n        // Extract last digits\n        int32x4_t last_digits = vandq_s32(abs_vec, vdupq_n_s32(9));\n        uint32x4_t last_digit_odd_mask = vcleq_s32(vandq_s32(last_digits, odd_digits), odd_digits);\n\n        // Extract first digits (assuming numbers are within reasonable range)\n        int32x4_t first_digits = vmovn_high_s16(vshrn_n_s32(abs_vec, 28), vdup_n_s16(0));\n        uint32x4_t first_digit_odd_mask = vcleq_s32(vandq_s32(first_digits, odd_digits), odd_digits);\n\n        // Combine masks\n        uint32x4_t combined_mask = vandq_u32(gt_mask, vandq_u32(last_digit_odd_mask, first_digit_odd_mask));\n        uint32x4_t count_mask = vceqq_s32(combined_mask, vdupq_n_u32(-1));\n\n        // Count the number of set elements\n        int32x4_t counts = vcntq_u32(count_mask);\n        count += vaddvq_s32(counts);\n    }\n\n    // Handle remaining elements\n    for (size_t i = nums.size() / 4 * 4; i < nums.size(); ++i) {\n        int num = nums[i];\n        if (num > 10) {\n            int abs_num = std::abs(num);\n            int last_digit = abs_num % 10;\n            int first_digit = abs_num;\n            while (first_digit >= 10) {\n                first_digit /= 10;\n            }\n            if ((last_digit % 2 != 0) && (first_digit % 2 != 0)) {\n                count++;\n            }\n        }\n    }\n    return count;\n}\n```"}
{"task_id": "SimdBench_131_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nint specialFilter_simd(const std::vector<int> & nums){\n    int count = 0;\n    const int threshold = 10;\n    const int odd_mask = 0x55555555; // Binary mask for odd digits (1,3,5,7,9)\n\n    if (nums.empty()) return 0;\n\n    size_t n = nums.size();\n    int32x4_t v_threshold = vdupq_n_s32(threshold);\n    int32x4_t v_zero = vdupq_n_s32(0);\n\n    for (size_t i = 0; i + 3 < n; i += 4) {\n        int32x4_t v_nums = vld1q_s32(&nums[i]);\n        \n        // Check if numbers are greater than 10\n        uint32x4_t v_gt_10 = vcgtq_s32(v_nums, v_threshold);\n\n        // Extract absolute values\n        int32x4_t v_abs_nums = vabsq_s32(v_nums);\n\n        // Extract last digits\n        int32x4_t v_last_digits = vmulq_n_s32(v_abs_nums, 0x3E8); // Multiply by 1000 to isolate last digit\n        v_last_digits = vaddq_n_s32(v_last_digits, 0x8000); // Add bias\n        v_last_digits = vshrq_n_s32(v_last_digits, 16); // Shift right to get last digit\n        v_last_digits = vandq_u32(vcvtq_u32_s32(v_last_digits), vdupq_n_u32(odd_mask)); // Mask for odd digits\n\n        // Extract first digits\n        int32x4_t v_first_digits = vabsq_s32(v_nums);\n        v_first_digits = vshlq_n_s32(v_first_digits, 28); // Shift left to isolate first digit\n        v_first_digits = vshrq_n_s32(v_first_digits, 28); // Shift right to get first digit\n        v_first_digits = vandq_u32(vcvtq_u32_s32(v_first_digits), vdupq_n_u32(odd_mask)); // Mask for odd digits\n\n        // Check if both first and last digits are odd\n        uint32x4_t v_odd_check = vceqq_u32(v_last_digits, v_first_digits);\n\n        // Combine conditions\n        uint32x4_t v_final_check = vandq_u32(v_gt_10, v_odd_check);\n\n        // Count the number of elements meeting the condition\n        uint32x4_t v_count = vcntq_u32(v_final_check);\n        count += vget_lane_u32(vaddvq_u32(v_count), 0);\n    }\n\n    // Handle remaining elements\n    for (size_t i = (n / 4) * 4; i < n; ++i) {\n        int num = nums[i];\n        if (num > 10) {\n            int abs_num = std::abs(num);\n            int first_digit = abs_num;\n            while (first_digit >= 10) first_digit /= 10;\n            int last_digit = abs_num % 10;\n            if ((first_digit & 1) && (last_digit & 1)) {\n                count++;\n            }\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_132_Neon", "completion": "```c\n#include <arm_neon.h>\n\nuint64_t get_max_triples_simd(uint64_t n){\n    if (n < 3) return 0;\n\n    uint32_t count_mod_0 = 0, count_mod_1 = 0, count_mod_2 = 0;\n    const uint32x4_t v_one = vdupq_n_u32(1);\n    const uint32x4_t v_two = vdupq_n_u32(2);\n    const uint32x4_t v_three = vdupq_n_u32(3);\n\n    for (uint64_t i = 1; i <= n; i += 4) {\n        uint32x4_t v_i = vdupq_n_u32(i);\n        uint32x4_t v_i_sq = vmulq_u32(v_i, v_i);\n        uint32x4_t v_a = vmlsq_u32(v_i_sq, v_i, v_one);\n        \n        uint32x4_t v_mod = vaddq_u32(v_a, v_three); // a[i] + 3 to avoid negative values\n        v_mod = vmulq_u32(v_mod, vdupq_n_u32(4294967295 / 3)); // Multiply by inverse of 3\n        v_mod = vshrq_n_u32(v_mod, 31); // Shift to get modulo 3 result\n\n        uint32x4_t mask_mod_0 = vceqq_u32(v_mod, vdupq_n_u32(0));\n        uint32x4_t mask_mod_1 = vceqq_u32(v_mod, vdupq_n_u32(1));\n        uint32x4_t mask_mod_2 = vceqq_u32(v_mod, vdupq_n_u32(2));\n\n        count_mod_0 += vaddvq_u32(vandq_u32(mask_mod_0, vdupq_n_u32(1)));\n        count_mod_1 += vaddvq_u32(vandq_u32(mask_mod_1, vdupq_n_u32(1)));\n        count_mod_2 += vaddvq_u32(vandq_u32(mask_mod_2, vdupq_n_u32(1)));\n\n        if (i + 3 <= n) continue;\n\n        uint32_t remainder = n - i + 1;\n        if (remainder < 4) {\n            uint32x4_t v_mask = vtstq_u32(vcltq_u32(v_i, vdupq_n_u32(n + 1)), vdupq_n_u32(1));\n            count_mod_0 -= vaddvq_u32(vandq_u32(v_mask, vandq_u32(mask_mod_0, vdupq_n_u32(1))));\n            count_mod_1 -= vaddvq_u32(vandq_u32(v_mask, vandq_u32(mask_mod_1, vdupq_n_u32(1))));\n            count_mod_2 -= vaddvq_u32(vandq_u32(v_mask, vandq_u32(mask_mod_2, vdupq_n_u32(1))));\n        }\n    }\n\n    uint64_t triples = 0;\n    triples += (uint64_t)count_mod_0 * ((uint64_t)count_mod_1 * (uint64_t)count_mod_2);\n    triples += ((uint64_t)count_mod_1 * ((uint64_t)count_mod_1 - 1) * ((uint64_t)count_mod_1 - 2)) / 6;\n    triples += ((uint64_t)count_mod_2 * ((uint64_t)count_mod_2 - 1) * ((uint64_t)count_mod_2 - 2)) / 6;\n\n    return triples;\n}\n```"}
{"task_id": "SimdBench_132_Neon", "completion": "```c\n#include <arm_neon.h>\n\nuint64_t get_max_triples_simd(uint64_t n){\n    if (n < 3) return 0;\n\n    uint32_t a[n];\n    const uint32x4_t one = vdupq_n_u32(1);\n    const uint32x4_t three = vdupq_n_u32(3);\n\n    // Compute the vector a using SIMD\n    for (size_t i = 0; i < n; i += 4) {\n        uint32x4_t idx = vdupq_n_u32(i + 1);\n        if (i + 4 > n) {\n            uint32_t temp[4] = { (uint32_t)(i+1), (uint32_t)(i+2), (uint32_t)(i+3), (uint32_t)(i+4) };\n            uint32x4_t mask = vcgtq_u32(vdupq_n_u32(n), idx);\n            idx = vbslq_u32(mask, vld1q_u32(temp), idx);\n        }\n        uint32x4_t squared = vmulq_u32(idx, idx);\n        uint32x4_t result = vmlsq_u32(squared, idx, one);\n        result = vaddq_u32(result, one);\n        vst1q_u32(&a[i], result);\n    }\n\n    // Count remainders modulo 3\n    uint64_t count[3] = {0};\n    for (size_t i = 0; i < n; ++i) {\n        count[a[i] % 3]++;\n    }\n\n    // Calculate number of valid triples\n    uint64_t r0 = count[0];\n    uint64_t r1 = count[1];\n    uint64_t r2 = count[2];\n\n    uint64_t triples = r0 * (r0 - 1) * (r0 - 2) / 6;\n    triples += r1 * (r1 - 1) * (r1 - 2) / 6;\n    triples += r2 * (r2 - 1) * (r2 - 2) / 6;\n    triples += r0 * (r0 - 1) / 2 * r1;\n    triples += r0 * (r0 - 1) / 2 * r2;\n    triples += r1 * (r1 - 1) / 2 * r0;\n    triples += r2 * (r2 - 1) / 2 * r0;\n    triples += r1 * r2 * (r1 - 1) / 2;\n    triples += r1 * r2 * (r2 - 1) / 2;\n\n    return triples;\n}\n```"}
{"task_id": "SimdBench_132_Neon", "completion": "```c\n#include <arm_neon.h>\n\nuint64_t get_max_triples_simd(uint64_t n){\n    if (n < 3) return 0;\n\n    uint32_t a[n];\n    uint64_t count = 0;\n\n    // Compute the vector a using SIMD\n    for (uint64_t i = 0; i < n / 4 * 4; i += 4) {\n        uint32x4_t v_idx = vdupq_n_u32(i);\n        uint32x4_t v_one = vdupq_n_u32(1);\n        uint32x4_t v_two = vdupq_n_u32(2);\n\n        v_idx = vaddq_u32(v_idx, vdupq_n_u32(1));\n        uint32x4_t v_i_sq = vmulq_u32(v_idx, v_idx);\n        uint32x4_t v_a = vmlsq_u32(v_i_sq, v_idx, v_one);\n        vst1q_u32(&a[i], v_a);\n    }\n\n    for (uint64_t i = n / 4 * 4; i < n; ++i) {\n        a[i] = (i + 1) * (i + 1) - (i + 1) + 1;\n    }\n\n    // Count triples where a[i] + a[j] + a[k] is multiple of 3\n    for (uint64_t i = 0; i < n - 2; ++i) {\n        for (uint64_t j = i + 1; j < n - 1; ++j) {\n            uint32x4_t v_sum_ij = vdupq_n_u32((a[i] + a[j]) % 3);\n            for (uint64_t k = j + 1; k < n / 4 * 4; k += 4) {\n                uint32x4_t v_ak = vld1q_u32(&a[k]);\n                uint32x4_t v_mod = vandq_u32(v_ak, vdupq_n_u32(2));\n                v_mod = vaddq_u32(v_mod, vdupq_n_u32(1));\n                v_mod = vsubq_u32(v_mod, v_ak);\n                uint32x4_t v_check = vceqq_u32(vaddq_u32(v_sum_ij, v_mod), vdupq_n_u32(3));\n                count += vaddvq_u32(vreinterpretq_u32_u8(vshrq_n_u8(vreinterpretq_u8_u32(v_check), 7)));\n            }\n            for (uint64_t k = n / 4 * 4; k < n; ++k) {\n                if ((a[i] + a[j] + a[k]) % 3 == 0) {\n                    count++;\n                }\n            }\n        }\n    }\n    return count;\n}\n```"}
{"task_id": "SimdBench_132_Neon", "completion": "```c\n#include <arm_neon.h>\n\nuint64_t get_max_triples_simd(uint64_t n){\n    if(n < 3) return 0;\n\n    uint32_t remainder_counts[3] = {0};\n    uint64_t i, result = 0;\n    uint32x4_t v_three = vdupq_n_u32(3);\n\n    for(i = 1; i <= n; ++i){\n        uint32_t val = (i * i - i + 1);\n        uint32x4_t v_val = vdupq_n_u32(val);\n        uint32x4_t v_mod = vmlaq_n_u32(vdupq_n_u32(0), v_val, v_three);\n        uint32_t rem = vgetq_lane_u32(v_mod, 0) % 3;\n        remainder_counts[rem]++;\n    }\n\n    uint64_t r0 = remainder_counts[0];\n    uint64_t r1 = remainder_counts[1];\n    uint64_t r2 = remainder_counts[2];\n\n    result += r0 * (r0 - 1) * (r0 - 2) / 6;\n    result += r1 * (r1 - 1) * (r1 - 2) / 6;\n    result += r2 * (r2 - 1) * (r2 - 2) / 6;\n    result += r0 * r1 * r2;\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_132_Neon", "completion": "```c\n#include <arm_neon.h>\n\nuint64_t get_max_triples_simd(uint64_t n){\n    if(n < 3) return 0;\n\n    uint32x4_t mod_results = vdupq_n_u32(0);\n    uint32x4_t indices = vdupq_n_u32(1);\n\n    uint64_t count = 0;\n    uint32x4_t mods[3] = {vdupq_n_u32(0), vdupq_n_u32(0), vdupq_n_u32(0)};\n    \n    for(uint64_t i=0;i<n;i+=4){\n        uint32x4_t current_indices = vaddq_u32(indices, vdupq_n_u32(i));\n        uint32x4_t squares = vmulq_u32(current_indices, current_indices);\n        uint32x4_t values = vsubq_u32(vmlaq_u32(squares, current_indices, vdupq_n_u32(-1)), vdupq_n_u32(-1));\n        uint32x4_t remainders = vandq_u32(values, vdupq_n_u32(2));\n\n        for(int lane=0;lane<4;lane++){\n            if(i + lane >= n) break;\n            uint32_t rem = vgetq_lane_u32(remainders, lane);\n            mods[rem][lane]++;\n        }\n    }\n\n    for(int r1=0;r1<3;r1++) {\n        for(int r2=0;r2<3;r2++) {\n            int r3 = (3 - r1 - r2 + 3) % 3;\n            uint32x4_t sum = vaddq_u32(mods[r1], mods[r2]);\n            sum = vaddq_u32(sum, mods[r3]);\n            for(int lane=0;lane<4;lane++) {\n                count += ((uint64_t)vgetq_lane_u32(mods[r1], lane) * vgetq_lane_u32(mods[r2], lane) * vgetq_lane_u32(mods[r3], lane)) / 6;\n            }\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_133_Neon", "completion": "```c\n#include <arm_neon.h>\n\nint x_or_y_simd(int n, int x, int y){\n    if(n < 2) return y;\n    \n    int result = y;\n    int sqrt_n = (int)(sqrt((double)n));\n    int vec_size = 4;\n    int chunks = (sqrt_n + 1) / vec_size;\n\n    int32x4_t vec_n = vdupq_n_s32(n);\n    int32x4_t zero = vdupq_n_s32(0);\n\n    for(int i = 2; i <= chunks * vec_size; i += vec_size){\n        int32x4_t vec_i = vdupq_n_s32(i);\n        int32x4_t cmp = vcmeq_s32(vec_n, vmulq_s32(vec_i, vec_i));\n        uint32x4_t mask = vceqq_f32(vcvtq_f32_s32(cmp), zero);\n        if(vminvq_u32(mask) == 0){\n            result = y;\n            break;\n        }\n    }\n\n    for(int i = chunks * vec_size; i <= sqrt_n; ++i){\n        if(n % i == 0){\n            result = y;\n            break;\n        }\n    }\n\n    if(result == y){\n        return y;\n    }\n    else{\n        return x;\n    }\n}\n```"}
{"task_id": "SimdBench_133_Neon", "completion": "```c\n#include <arm_neon.h>\n\nint x_or_y_simd(int n, int x, int y){\n    if(n < 2) return y;\n    \n    int32x4_t v_n = vdupq_n_s32(n);\n    int32x4_t v_one = vdupq_n_s32(1);\n    int32x4_t v_zero = vdupq_n_s32(0);\n    int32x4_t v_x = vdupq_n_s32(x);\n    int32x4_t v_y = vdupq_n_s32(y);\n    \n    int sqrt_n = (int)(sqrt((double)n));\n    int32x4_t v_is_prime = vdupq_n_s32(1);\n    \n    for(int i=2; i<=sqrt_n; i++){\n        int32x4_t v_i = vdupq_n_s32(i);\n        int32x4_t v_mod = vmovq_n_s32(n % i);\n        int32x4_t v_cmp = vceqq_s32(v_mod, v_zero);\n        v_is_prime = vandq_s32(v_is_prime, vbicq_s32(v_cmp, v_cmp));\n    }\n    \n    int is_prime = vgetq_lane_s32(v_is_prime, 0);\n    return is_prime ? x : y;\n}\n```"}
{"task_id": "SimdBench_133_Neon", "completion": "```c\n#include <arm_neon.h>\n\nint x_or_y_simd(int n, int x, int y){\n    if (n < 2) return y;\n\n    int result = y;\n    int sqrt_n = (int)(sqrt(n));\n    int vec_size = 4;\n    int num_vectors = (sqrt_n + vec_size - 1) / vec_size;\n\n    int32x4_t v_n = vdupq_n_s32(n);\n    int32x4_t v_zero = vdupq_n_s32(0);\n    int32x4_t v_one = vdupq_n_s32(1);\n\n    for(int i = 0; i < num_vectors; ++i){\n        int start = i * vec_size + 2;\n        int end = start + vec_size;\n        if(end > sqrt_n + 1){\n            end = sqrt_n + 1;\n        }\n        int count = end - start;\n\n        int32x4_t v_i = vdupq_lane_s32(vdup_n_s32(start), 0);\n        v_i = vaddq_s32(v_i, vmovq_n_s32(1));\n\n        int32x4_t v_mod = vmodq_s32(v_n, v_i);\n        uint32x4_t v_cmp = vceqq_s32(v_mod, v_zero);\n\n        int32x4_t v_mask = vandq_u32(vreinterpretq_u32_s32(v_cmp), vdupq_n_u32(0xFFFFFFFF));\n        int32x4_t v_check = vorrq_s32(v_zero, vreinterpretq_s32_u32(v_mask));\n\n        if(vgetq_lane_s32(v_check, 0) != 0 || \n           vgetq_lane_s32(v_check, 1) != 0 || \n           vgetq_lane_s32(v_check, 2) != 0 || \n           vgetq_lane_s32(v_check, 3) != 0){\n            return y;\n        }\n    }\n    return x;\n}\n```"}
{"task_id": "SimdBench_133_Neon", "completion": "```c\n#include <arm_neon.h>\n\nint x_or_y_simd(int n, int x, int y){\n    if (n < 2) return y;\n\n    int result = y;\n    int sqrt_n = (int)(sqrt(n));\n    int vec_size = 4;\n    int num_iters = (sqrt_n - 1) / vec_size + 1;\n\n    for(int i = 0; i < num_iters; ++i){\n        int start = 2 + i * vec_size;\n        int32x4_t vcmp = vmovq_n_s32(1);\n        if(start <= sqrt_n){\n            int32x4_t vnums = vdupq_n_s32(start);\n            int count = vec_size;\n            if(start + vec_size > sqrt_n + 1){\n                count = sqrt_n + 1 - start;\n                vcmp = vdupq_n_s32(0);\n                uint32x4_t vmask = vdupq_n_u32(1);\n                vmask = vcltq_u32(vreinterpretq_u32_s32(vnums), vreinterpretq_u32_s32(vdupq_n_s32(sqrt_n + 1)));\n                vcmp = vandq_u32(vreinterpretq_u32_s32(vcmp), vmask);\n            }\n            for(int j = 0; j < count; ++j){\n                int32x4_t vn = vdupq_n_s32(start + j);\n                int32x4_t vn_mod = vmlaq_s32(vdupq_n_s32(0), vn, vdupq_n_s32(n / (start + j)), vnegq_s32(vdupq_n_s32(n % (start + j))));\n                int32x4_t vzero = vdupq_n_s32(0);\n                vcmp = vandq_u32(vreinterpretq_u32_s32(vcmp), vcmeq_s32(vn_mod, vzero));\n            }\n            uint32x4_t vtest = vceqq_s32(vcmp, vdupq_n_s32(0));\n            int test = vaddvq_u32(vtest);\n            if(test != 0){\n                result = y;\n                break;\n            }\n        }\n    }\n    if(result == y){\n        result = n == 2 ? x : y;\n    }\n    else{\n        result = x;\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_133_Neon", "completion": "```c\n#include <arm_neon.h>\n\nint x_or_y_simd(int n, int x, int y){\n    if (n < 2) return y;\n\n    int result = y;\n    int sqrt_n = (int)(sqrt((double)n));\n    int16x8_t vec_n = vdupq_n_s16(n);\n    int16x8_t vec_zero = vdupq_n_s16(0);\n\n    for(int i = 2; i <= sqrt_n; i += 8){\n        int16x8_t vec_i = vld1q_s16((const int16_t*)&i);\n        int16x8_t mod_results = vmovq_n_s16(0);\n\n        for(int j=0; j<8; j++){\n            int16_t remainder = n % (i + j);\n            uint16x8_t cond = vceqq_s16(vec_zero, vmovq_n_s16(remainder));\n            mod_results = vbslq_s16(cond, vec_zero, mod_results);\n        }\n\n        if(vminvq_s16(mod_results) == 0){\n            result = y;\n            break;\n        }\n        else{\n            result = x;\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_134_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nuint64_t double_the_difference_simd(const std::vector<float> & lst){\n    if (lst.empty()) return 0;\n\n    uint64_t sum = 0;\n    size_t n = lst.size();\n    float *data = const_cast<float*>(&lst[0]);\n\n    // Process in chunks of 4\n    for (size_t i = 0; i <= n - 4; i += 4) {\n        float32x4_t vec = vld1q_f32(&data[i]);\n        float32x4_t zero = vmovq_n_f32(0.0f);\n        uint32x4_t cmp = vcgeq_f32(vec, zero); // Compare with 0\n        float32x4_t pos = vbslq_f32(cmp, vec, zero); // Select positive values\n\n        int32x4_t int_vals = vcvtq_s32_f32(pos); // Convert to int\n        float32x4_t back_to_float = vcvtq_f32_s32(int_vals); // Convert back to float\n        uint32x4_t is_odd = vcleq_f32(vabsq_f32(vsubq_f32(back_to_float, pos)), vcvtq_f32_s32(vshrq_n_s32(int_vals, 1))); // Check odd\n        float32x4_t odd_values = vbslq_f32(is_odd, pos, zero); // Select odd values\n\n        float32x4_t squared = vmulq_f32(odd_values, odd_values); // Square the values\n        float32x4_t partial_sum = vpaddq_f32(squared, squared); // Pairwise add\n        partial_sum = vpaddq_f32(partial_sum, partial_sum);\n\n        float32x2_t sum_vec = vadd_f32(vget_low_f32(partial_sum), vget_high_f32(partial_sum));\n        sum += vcvt_f32_u32(vget_lane_u32(vreinterpret_u32_f32(sum_vec), 0));\n    }\n\n    // Handle remaining elements\n    for (size_t i = n - (n % 4); i < n; ++i) {\n        if (data[i] >= 0 && static_cast<int>(data[i]) % 2 == 1) {\n            sum += static_cast<int>(data[i]) * static_cast<int>(data[i]);\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_134_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <stdint.h>\n\nuint64_t double_the_difference_simd(const std::vector<float> & lst){\n    uint64_t sum = 0;\n    if (lst.empty()) return 0;\n\n    const float *data = lst.data();\n    size_t size = lst.size();\n\n    for (size_t i = 0; i <= size - 4; i += 4){\n        float32x4_t v = vld1q_f32(&data[i]);\n        int32x4_t v_int = vcvtq_s32_f32(v); // Convert to integer\n        uint32x4_t v_abs = vmovl_u16(vdupq_lane_u16(vabsq_s32(v_int), 0)); // Absolute value\n        uint32x4_t v_odd = vmovl_u16(vandq_u16(vreinterpretq_u16_s32(v_int), vdupq_n_u16(1))); // Check odd\n        uint32x4_t v_mask = vcltq_f32(v, vdupq_n_f32(0.0f)); // Check negative\n        uint32x4_t v_valid = vbicq_u32(v_odd, vreinterpretq_u32_f32(v_mask)); // Valid odd numbers\n\n        float32x4_t v_sq = vmulq_f32(v, v); // Square the values\n        float32x4_t v_sq_valid = vbslq_f32(vreinterpretq_u32_f32(v_valid), v_sq, vdupq_n_f32(0.0f)); // Select valid squares\n\n        float32x4_t v_sum = vpaddq_f32(v_sq_valid, v_sq_valid); // Pairwise add\n        v_sum = vpaddq_f32(v_sum, v_sum);\n\n        float32x2_t v_sum_lo = vget_low_f32(v_sum);\n        float32x2_t v_sum_hi = vget_high_f32(v_sum);\n        float32x2_t v_total = vpadd_f32(v_sum_lo, v_sum_hi);\n\n        sum += vget_lane_f32(v_total, 0) + vget_lane_f32(v_total, 1);\n    }\n\n    for (size_t i = size - (size % 4); i < size; ++i){\n        if (data[i] >= 0 && static_cast<int>(data[i]) % 2 == 1){\n            sum += data[i] * data[i];\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_134_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nuint64_t double_the_difference_simd(const std::vector<float> & lst){\n    if (lst.empty()) return 0;\n\n    uint64_t sum = 0;\n    size_t vec_size = lst.size();\n    float *data = const_cast<float*>(lst.data());\n\n    for(size_t i = 0; i + 3 < vec_size; i += 4){\n        float32x4_t vload = vld1q_f32(data + i);\n        int32x4_t vint = vcvtq_s32_f32(vload); // Convert to integer\n        float32x4_t vback = vcvtq_f32_s32(vint); // Convert back to float\n\n        uint32x4_t vis_odd = vmovemask_f32(vandq_f32(vceqq_f32(vload, vback), vceqq_f32(vandq_s32(vint, vdupq_n_s32(1)), vdupq_n_s32(1))));\n        float32x4_t vsquare = vmulq_f32(vload, vload);\n        float32x4_t vresult = vreinterpretq_f32_u32(vandq_u32(vmovl_u16(vis_odd), vreinterpretq_u32_f32(vsquare)));\n\n        sum += vaddvq_u32(vcvtq_u32_f32(vresult));\n    }\n\n    for(size_t i = vec_size - (vec_size % 4); i < vec_size; ++i){\n        if(lst[i] > 0 && static_cast<int>(lst[i]) == lst[i] && static_cast<int>(lst[i]) % 2 != 0){\n            sum += static_cast<int>(lst[i]) * static_cast<int>(lst[i]);\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_134_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nuint64_t double_the_difference_simd(const std::vector<float> & lst){\n    uint64_t sum = 0;\n    if(lst.empty()) return 0;\n\n    size_t aligned_size = lst.size() / 4 * 4;\n    const float32x4_t v_zero = vdupq_n_f32(0.0f);\n    const float32x4_t v_half = vdupq_n_f32(0.5f);\n\n    float32x4_t v_sum_squares = vdupq_n_f32(0.0f);\n\n    for(size_t i = 0; i < aligned_size; i += 4){\n        float32x4_t v_nums = vld1q_f32(&lst[i]);\n        // Check if numbers are positive and integer-like\n        int32x4_t v_int_check = vcvtq_s32_f32(v_nums);\n        float32x4_t v_reconverted = vcvtq_f32_s32(v_int_check);\n        uint32x4_t v_pos_mask = vcgeq_f32(v_nums, v_zero);\n        uint32x4_t v_int_mask = vceqq_f32(v_nums, v_reconverted);\n        uint32x4_t v_valid_mask = vandq_u32(v_pos_mask, v_int_mask);\n\n        // Check if numbers are odd\n        int32x4_t v_even_check = vandq_s32(v_int_check, vdupq_n_s32(1));\n        uint32x4_t v_odd_mask = vceqq_s32(v_even_check, vdupq_n_s32(1));\n        uint32x4_t v_final_mask = vandq_u32(v_valid_mask, v_odd_mask);\n\n        // Square the numbers\n        float32x4_t v_sq = vmulq_f32(v_nums, v_nums);\n\n        // Select valid squares\n        float32x4_t v_selected = vbslq_f32(v_final_mask, v_sq, v_zero);\n\n        // Accumulate\n        v_sum_squares = vaddq_f32(v_sum_squares, v_selected);\n    }\n\n    float32x2_t v_low = vadd_f32(vget_low_f32(v_sum_squares), vget_high_f32(v_sum_squares));\n    float32x2_t v_sum = vpadd_f32(v_low, v_low);\n\n    sum += (uint64_t)vget_lane_f32(v_sum, 0);\n\n    // Handle remaining elements\n    for(size_t i = aligned_size; i < lst.size(); ++i){\n        float num = lst[i];\n        if(num > 0 && truncf(num) == num && fmodf(num, 2.0f) == 1.0f){\n            sum += static_cast<uint64_t>(num * num);\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_134_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nuint64_t double_the_difference_simd(const std::vector<float> & lst){\n    if (lst.empty()) return 0;\n\n    uint64_t sum = 0;\n    size_t size = lst.size();\n    float *data = const_cast<float*>(lst.data());\n\n    for(size_t i = 0; i <= size - 4; i += 4){\n        float32x4_t vec = vld1q_f32(&data[i]);\n        float32x4_t zero = vmovq_n_f32(0.0f);\n        uint32x4_t mask = vcgeq_f32(vec, zero); // Check if elements are >= 0\n\n        float32x4_t pos_vec = vbslq_f32(mask, vec, zero); // Set negative values to 0\n\n        int32x4_t int_vec = vcvtq_s32_f32(pos_vec); // Convert to int\n        float32x4_t round_vec = vcvtq_f32_s32(int_vec); // Round to nearest integer\n\n        uint32x4_t eq_mask = vceqq_f32(pos_vec, round_vec); // Check if original was an integer\n        float32x4_t int_check_vec = vbslq_f32(eq_mask, pos_vec, zero); // Set non-integers to 0\n\n        int32x4_t odd_check = vandq_s32(vcvtq_s32_f32(int_check_vec), vmovq_n_s32(1)); // Check if odd\n        float32x4_t odd_vec = vbslq_f32(vreinterpretq_u32_s32(odd_check), int_check_vec, zero); // Set even integers to 0\n\n        float32x4_t squared = vmulq_f32(odd_vec, odd_vec); // Square the odd integers\n        float32x2_t sum_vec = vpadd_f32(vget_low_f32(squared), vget_high_f32(squared)); // Pairwise add\n        sum_vec = vpadd_f32(sum_vec, sum_vec); // Horizontal add\n        sum += vget_lane_f32(sum_vec, 0); // Accumulate to scalar sum\n    }\n\n    for(size_t i = size - (size % 4); i < size; ++i){\n        if(data[i] >= 0 && static_cast<int>(data[i]) == data[i] && static_cast<int>(data[i]) % 2 != 0){\n            sum += static_cast<int>(data[i]) * static_cast<int>(data[i]);\n        }\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_135_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int> compare_simd(const std::vector<int>& game, const std::vector<int>& guess){\n    size_t n = game.size();\n    std::vector<int> result(n, 0);\n    \n    if (n == 0) return result;\n\n    int32x4_t zero = vmovq_n_s32(0);\n\n    for (size_t i = 0; i < n; i += 4) {\n        int32x4_t v_game = vld1q_s32(reinterpret_cast<const int32_t*>(&game[i]));\n        int32x4_t v_guess = vld1q_s32(reinterpret_cast<const int32_t*>(&guess[i]));\n\n        int32x4_t diff = vsubq_s32(v_game, v_guess);\n        uint32x4_t abs_diff = vabdq_u32(diff);\n\n        uint32x4_t mask = vceqq_s32(v_game, v_guess);\n        uint32x4_t res = vbslq_u32(mask, zero, abs_diff);\n\n        vst1q_u32(reinterpret_cast<uint32_t*>(&result[i]), res);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_135_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int> compare_simd(const std::vector<int>& game, const std::vector<int>& guess){\n    size_t size = game.size();\n    std::vector<int> result(size, 0);\n\n    if (size == 0) return result;\n\n    int32x4_t zero = vmovq_n_s32(0);\n    for (size_t i = 0; i < size / 4 * 4; i += 4) {\n        int32x4_t v_game = vld1q_s32(&game[i]);\n        int32x4_t v_guess = vld1q_s32(&guess[i]);\n\n        int32x4_t diff = vsubq_s32(v_game, v_guess);\n        int32x4_t abs_diff = vabsq_s32(diff);\n\n        uint32x4_t mask = vcgeq_s32(v_game, v_guess); // Check where game >= guess\n        int32x4_t conditionally_zeroed = vandq_s32(abs_diff, vmvnq_u32(mask)); // Zero out where equal\n\n        int32x4_t final_result = vbslq_s32(mask, zero, conditionally_zeroed);\n\n        vst1q_s32(&result[i], final_result);\n    }\n\n    // Handle remaining elements\n    for (size_t i = size / 4 * 4; i < size; ++i) {\n        int diff = game[i] - guess[i];\n        result[i] = (game[i] == guess[i]) ? 0 : std::abs(diff);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_135_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <cstdint>\n\nstd::vector<int> compare_simd(const std::vector<int>& game, const std::vector<int>& guess) {\n    size_t size = game.size();\n    std::vector<int> result(size);\n\n    for (size_t i = 0; i < size; i += 4) {\n        int32x4_t v_game = vdupq_n_s32(0);\n        int32x4_t v_guess = vdupq_n_s32(0);\n\n        // Load data into NEON registers\n        if (i + 3 < size) {\n            v_game = vld1q_s32(reinterpret_cast<const int32_t*>(&game[i]));\n            v_guess = vld1q_s32(reinterpret_cast<const int32_t*>(&guess[i]));\n        } else {\n            // Handle the case where the vector doesn't align with the end of the array\n            int32x4_t temp_game = vdupq_n_s32(0);\n            int32x4_t temp_guess = vdupq_n_s32(0);\n            for (size_t j = 0; j < size - i; ++j) {\n                temp_game = vsetq_lane_s32(game[i + j], temp_game, j);\n                temp_guess = vsetq_lane_s32(guess[i + j], temp_guess, j);\n            }\n            v_game = temp_game;\n            v_guess = temp_guess;\n        }\n\n        // Compute absolute difference\n        int32x4_t v_diff = vabdq_s32(v_game, v_guess);\n\n        // Store results back to memory\n        if (i + 3 < size) {\n            vst1q_s32(reinterpret_cast<int32_t*>(&result[i]), v_diff);\n        } else {\n            int32x4_t temp_result = vdupq_n_s32(0);\n            temp_result = vsetq_lane_s32(vgetq_lane_s32(v_diff, 0), temp_result, 0);\n            temp_result = vsetq_lane_s32(vgetq_lane_s32(v_diff, 1), temp_result, 1);\n            temp_result = vsetq_lane_s32(vgetq_lane_s32(v_diff, 2), temp_result, 2);\n            temp_result = vsetq_lane_s32(vgetq_lane_s32(v_diff, 3), temp_result, 3);\n            for (size_t j = 0; j < size - i; ++j) {\n                result[i + j] = vgetq_lane_s32(temp_result, j);\n            }\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_135_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n#include <cstdint>\n\nstd::vector<int> compare_simd(const std::vector<int>& game, const std::vector<int>& guess) {\n    size_t size = game.size();\n    std::vector<int> result(size, 0);\n\n    if (size == 0) return result;\n\n    int32x4_t zero = vdupq_n_s32(0);\n\n    for (size_t i = 0; i < size; i += 4) {\n        int32x4_t game_vec = vld1q_s32(reinterpret_cast<const int32_t*>(&game[i]));\n        int32x4_t guess_vec = vld1q_s32(reinterpret_cast<const int32_t*>(&guess[i]));\n\n        int32x4_t diff = vsubq_s32(game_vec, guess_vec);\n        int32x4_t abs_diff = vabdq_s32(diff);\n\n        uint32x4_t mask = vcgeq_s32(diff, zero);\n        int32x4_t res = vbslq_s32(mask, abs_diff, zero);\n\n        vst1q_s32(reinterpret_cast<int32_t*>(&result[i]), res);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_135_Neon", "completion": "```cpp\n#include <arm_neon.h>\n#include <vector>\n\nstd::vector<int> compare_simd(const std::vector<int>& game, const std::vector<int>& guess){\n    size_t n = game.size();\n    std::vector<int> result(n, 0);\n\n    if (n == 0) return result;\n\n    size_t i = 0;\n    for (; i <= n - 16; i += 16) {\n        int32x4_t v_game1 = vld1q_s32(&game[i]);\n        int32x4_t v_game2 = vld1q_s32(&game[i+4]);\n        int32x4_t v_game3 = vld1q_s32(&game[i+8]);\n        int32x4_t v_game4 = vld1q_s32(&game[i+12]);\n\n        int32x4_t v_guess1 = vld1q_s32(&guess[i]);\n        int32x4_t v_guess2 = vld1q_s32(&guess[i+4]);\n        int32x4_t v_guess3 = vld1q_s32(&guess[i+8]);\n        int32x4_t v_guess4 = vld1q_s32(&guess[i+12]);\n\n        int32x4_t v_diff1 = vsubq_s32(v_game1, v_guess1);\n        int32x4_t v_diff2 = vsubq_s32(v_game2, v_guess2);\n        int32x4_t v_diff3 = vsubq_s32(v_game3, v_guess3);\n        int32x4_t v_diff4 = vsubq_s32(v_game4, v_guess4);\n\n        uint32x4_t v_absdiff1 = vabdq_u32(vreinterpretq_u32_s32(v_diff1));\n        uint32x4_t v_absdiff2 = vabdq_u32(vreinterpretq_u32_s32(v_diff2));\n        uint32x4_t v_absdiff3 = vabdq_u32(vreinterpretq_u32_s32(v_diff3));\n        uint32x4_t v_absdiff4 = vabdq_u32(vreinterpretq_u32_s32(v_diff4));\n\n        vst1q_u32(&result[i], vreinterpretq_u32_s32(v_absdiff1));\n        vst1q_u32(&result[i+4], vreinterpretq_u32_s32(v_absdiff2));\n        vst1q_u32(&result[i+8], vreinterpretq_u32_s32(v_absdiff3));\n        vst1q_u32(&result[i+12], vreinterpretq_u32_s32(v_absdiff4));\n    }\n\n    for (; i < n; ++i) {\n        result[i] = std::abs(game[i] - guess[i]);\n    }\n\n    return result;\n}\n```"}
